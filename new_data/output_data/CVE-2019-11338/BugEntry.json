{"buggy_code": ["/*\n * HEVC video Decoder\n *\n * Copyright (C) 2012 - 2013 Guillaume Martres\n * Copyright (C) 2012 - 2013 Mickael Raulet\n * Copyright (C) 2012 - 2013 Gildas Cocherel\n * Copyright (C) 2012 - 2013 Wassim Hamidouche\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"libavutil/attributes.h\"\n#include \"libavutil/common.h\"\n#include \"libavutil/display.h\"\n#include \"libavutil/internal.h\"\n#include \"libavutil/mastering_display_metadata.h\"\n#include \"libavutil/md5.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/pixdesc.h\"\n#include \"libavutil/stereo3d.h\"\n\n#include \"bswapdsp.h\"\n#include \"bytestream.h\"\n#include \"cabac_functions.h\"\n#include \"golomb.h\"\n#include \"hevc.h\"\n#include \"hevc_data.h\"\n#include \"hevc_parse.h\"\n#include \"hevcdec.h\"\n#include \"hwaccel.h\"\n#include \"profiles.h\"\n\nconst uint8_t ff_hevc_pel_weight[65] = { [2] = 0, [4] = 1, [6] = 2, [8] = 3, [12] = 4, [16] = 5, [24] = 6, [32] = 7, [48] = 8, [64] = 9 };\n\n/**\n * NOTE: Each function hls_foo correspond to the function foo in the\n * specification (HLS stands for High Level Syntax).\n */\n\n/**\n * Section 5.7\n */\n\n/* free everything allocated  by pic_arrays_init() */\nstatic void pic_arrays_free(HEVCContext *s)\n{\n    av_freep(&s->sao);\n    av_freep(&s->deblock);\n\n    av_freep(&s->skip_flag);\n    av_freep(&s->tab_ct_depth);\n\n    av_freep(&s->tab_ipm);\n    av_freep(&s->cbf_luma);\n    av_freep(&s->is_pcm);\n\n    av_freep(&s->qp_y_tab);\n    av_freep(&s->tab_slice_address);\n    av_freep(&s->filter_slice_edges);\n\n    av_freep(&s->horizontal_bs);\n    av_freep(&s->vertical_bs);\n\n    av_freep(&s->sh.entry_point_offset);\n    av_freep(&s->sh.size);\n    av_freep(&s->sh.offset);\n\n    av_buffer_pool_uninit(&s->tab_mvf_pool);\n    av_buffer_pool_uninit(&s->rpl_tab_pool);\n}\n\n/* allocate arrays that depend on frame dimensions */\nstatic int pic_arrays_init(HEVCContext *s, const HEVCSPS *sps)\n{\n    int log2_min_cb_size = sps->log2_min_cb_size;\n    int width            = sps->width;\n    int height           = sps->height;\n    int pic_size_in_ctb  = ((width  >> log2_min_cb_size) + 1) *\n                           ((height >> log2_min_cb_size) + 1);\n    int ctb_count        = sps->ctb_width * sps->ctb_height;\n    int min_pu_size      = sps->min_pu_width * sps->min_pu_height;\n\n    s->bs_width  = (width  >> 2) + 1;\n    s->bs_height = (height >> 2) + 1;\n\n    s->sao           = av_mallocz_array(ctb_count, sizeof(*s->sao));\n    s->deblock       = av_mallocz_array(ctb_count, sizeof(*s->deblock));\n    if (!s->sao || !s->deblock)\n        goto fail;\n\n    s->skip_flag    = av_malloc_array(sps->min_cb_height, sps->min_cb_width);\n    s->tab_ct_depth = av_malloc_array(sps->min_cb_height, sps->min_cb_width);\n    if (!s->skip_flag || !s->tab_ct_depth)\n        goto fail;\n\n    s->cbf_luma = av_malloc_array(sps->min_tb_width, sps->min_tb_height);\n    s->tab_ipm  = av_mallocz(min_pu_size);\n    s->is_pcm   = av_malloc_array(sps->min_pu_width + 1, sps->min_pu_height + 1);\n    if (!s->tab_ipm || !s->cbf_luma || !s->is_pcm)\n        goto fail;\n\n    s->filter_slice_edges = av_mallocz(ctb_count);\n    s->tab_slice_address  = av_malloc_array(pic_size_in_ctb,\n                                      sizeof(*s->tab_slice_address));\n    s->qp_y_tab           = av_malloc_array(pic_size_in_ctb,\n                                      sizeof(*s->qp_y_tab));\n    if (!s->qp_y_tab || !s->filter_slice_edges || !s->tab_slice_address)\n        goto fail;\n\n    s->horizontal_bs = av_mallocz_array(s->bs_width, s->bs_height);\n    s->vertical_bs   = av_mallocz_array(s->bs_width, s->bs_height);\n    if (!s->horizontal_bs || !s->vertical_bs)\n        goto fail;\n\n    s->tab_mvf_pool = av_buffer_pool_init(min_pu_size * sizeof(MvField),\n                                          av_buffer_allocz);\n    s->rpl_tab_pool = av_buffer_pool_init(ctb_count * sizeof(RefPicListTab),\n                                          av_buffer_allocz);\n    if (!s->tab_mvf_pool || !s->rpl_tab_pool)\n        goto fail;\n\n    return 0;\n\nfail:\n    pic_arrays_free(s);\n    return AVERROR(ENOMEM);\n}\n\nstatic int pred_weight_table(HEVCContext *s, GetBitContext *gb)\n{\n    int i = 0;\n    int j = 0;\n    uint8_t luma_weight_l0_flag[16];\n    uint8_t chroma_weight_l0_flag[16];\n    uint8_t luma_weight_l1_flag[16];\n    uint8_t chroma_weight_l1_flag[16];\n    int luma_log2_weight_denom;\n\n    luma_log2_weight_denom = get_ue_golomb_long(gb);\n    if (luma_log2_weight_denom < 0 || luma_log2_weight_denom > 7) {\n        av_log(s->avctx, AV_LOG_ERROR, \"luma_log2_weight_denom %d is invalid\\n\", luma_log2_weight_denom);\n        return AVERROR_INVALIDDATA;\n    }\n    s->sh.luma_log2_weight_denom = av_clip_uintp2(luma_log2_weight_denom, 3);\n    if (s->ps.sps->chroma_format_idc != 0) {\n        int64_t chroma_log2_weight_denom = luma_log2_weight_denom + (int64_t)get_se_golomb(gb);\n        if (chroma_log2_weight_denom < 0 || chroma_log2_weight_denom > 7) {\n            av_log(s->avctx, AV_LOG_ERROR, \"chroma_log2_weight_denom %\"PRId64\" is invalid\\n\", chroma_log2_weight_denom);\n            return AVERROR_INVALIDDATA;\n        }\n        s->sh.chroma_log2_weight_denom = chroma_log2_weight_denom;\n    }\n\n    for (i = 0; i < s->sh.nb_refs[L0]; i++) {\n        luma_weight_l0_flag[i] = get_bits1(gb);\n        if (!luma_weight_l0_flag[i]) {\n            s->sh.luma_weight_l0[i] = 1 << s->sh.luma_log2_weight_denom;\n            s->sh.luma_offset_l0[i] = 0;\n        }\n    }\n    if (s->ps.sps->chroma_format_idc != 0) {\n        for (i = 0; i < s->sh.nb_refs[L0]; i++)\n            chroma_weight_l0_flag[i] = get_bits1(gb);\n    } else {\n        for (i = 0; i < s->sh.nb_refs[L0]; i++)\n            chroma_weight_l0_flag[i] = 0;\n    }\n    for (i = 0; i < s->sh.nb_refs[L0]; i++) {\n        if (luma_weight_l0_flag[i]) {\n            int delta_luma_weight_l0 = get_se_golomb(gb);\n            s->sh.luma_weight_l0[i] = (1 << s->sh.luma_log2_weight_denom) + delta_luma_weight_l0;\n            s->sh.luma_offset_l0[i] = get_se_golomb(gb);\n        }\n        if (chroma_weight_l0_flag[i]) {\n            for (j = 0; j < 2; j++) {\n                int delta_chroma_weight_l0 = get_se_golomb(gb);\n                int delta_chroma_offset_l0 = get_se_golomb(gb);\n\n                if (   (int8_t)delta_chroma_weight_l0 != delta_chroma_weight_l0\n                    || delta_chroma_offset_l0 < -(1<<17) || delta_chroma_offset_l0 > (1<<17)) {\n                    return AVERROR_INVALIDDATA;\n                }\n\n                s->sh.chroma_weight_l0[i][j] = (1 << s->sh.chroma_log2_weight_denom) + delta_chroma_weight_l0;\n                s->sh.chroma_offset_l0[i][j] = av_clip((delta_chroma_offset_l0 - ((128 * s->sh.chroma_weight_l0[i][j])\n                                                                                    >> s->sh.chroma_log2_weight_denom) + 128), -128, 127);\n            }\n        } else {\n            s->sh.chroma_weight_l0[i][0] = 1 << s->sh.chroma_log2_weight_denom;\n            s->sh.chroma_offset_l0[i][0] = 0;\n            s->sh.chroma_weight_l0[i][1] = 1 << s->sh.chroma_log2_weight_denom;\n            s->sh.chroma_offset_l0[i][1] = 0;\n        }\n    }\n    if (s->sh.slice_type == HEVC_SLICE_B) {\n        for (i = 0; i < s->sh.nb_refs[L1]; i++) {\n            luma_weight_l1_flag[i] = get_bits1(gb);\n            if (!luma_weight_l1_flag[i]) {\n                s->sh.luma_weight_l1[i] = 1 << s->sh.luma_log2_weight_denom;\n                s->sh.luma_offset_l1[i] = 0;\n            }\n        }\n        if (s->ps.sps->chroma_format_idc != 0) {\n            for (i = 0; i < s->sh.nb_refs[L1]; i++)\n                chroma_weight_l1_flag[i] = get_bits1(gb);\n        } else {\n            for (i = 0; i < s->sh.nb_refs[L1]; i++)\n                chroma_weight_l1_flag[i] = 0;\n        }\n        for (i = 0; i < s->sh.nb_refs[L1]; i++) {\n            if (luma_weight_l1_flag[i]) {\n                int delta_luma_weight_l1 = get_se_golomb(gb);\n                s->sh.luma_weight_l1[i] = (1 << s->sh.luma_log2_weight_denom) + delta_luma_weight_l1;\n                s->sh.luma_offset_l1[i] = get_se_golomb(gb);\n            }\n            if (chroma_weight_l1_flag[i]) {\n                for (j = 0; j < 2; j++) {\n                    int delta_chroma_weight_l1 = get_se_golomb(gb);\n                    int delta_chroma_offset_l1 = get_se_golomb(gb);\n\n                    if (   (int8_t)delta_chroma_weight_l1 != delta_chroma_weight_l1\n                        || delta_chroma_offset_l1 < -(1<<17) || delta_chroma_offset_l1 > (1<<17)) {\n                        return AVERROR_INVALIDDATA;\n                    }\n\n                    s->sh.chroma_weight_l1[i][j] = (1 << s->sh.chroma_log2_weight_denom) + delta_chroma_weight_l1;\n                    s->sh.chroma_offset_l1[i][j] = av_clip((delta_chroma_offset_l1 - ((128 * s->sh.chroma_weight_l1[i][j])\n                                                                                        >> s->sh.chroma_log2_weight_denom) + 128), -128, 127);\n                }\n            } else {\n                s->sh.chroma_weight_l1[i][0] = 1 << s->sh.chroma_log2_weight_denom;\n                s->sh.chroma_offset_l1[i][0] = 0;\n                s->sh.chroma_weight_l1[i][1] = 1 << s->sh.chroma_log2_weight_denom;\n                s->sh.chroma_offset_l1[i][1] = 0;\n            }\n        }\n    }\n    return 0;\n}\n\nstatic int decode_lt_rps(HEVCContext *s, LongTermRPS *rps, GetBitContext *gb)\n{\n    const HEVCSPS *sps = s->ps.sps;\n    int max_poc_lsb    = 1 << sps->log2_max_poc_lsb;\n    int prev_delta_msb = 0;\n    unsigned int nb_sps = 0, nb_sh;\n    int i;\n\n    rps->nb_refs = 0;\n    if (!sps->long_term_ref_pics_present_flag)\n        return 0;\n\n    if (sps->num_long_term_ref_pics_sps > 0)\n        nb_sps = get_ue_golomb_long(gb);\n    nb_sh = get_ue_golomb_long(gb);\n\n    if (nb_sps > sps->num_long_term_ref_pics_sps)\n        return AVERROR_INVALIDDATA;\n    if (nb_sh + (uint64_t)nb_sps > FF_ARRAY_ELEMS(rps->poc))\n        return AVERROR_INVALIDDATA;\n\n    rps->nb_refs = nb_sh + nb_sps;\n\n    for (i = 0; i < rps->nb_refs; i++) {\n        uint8_t delta_poc_msb_present;\n\n        if (i < nb_sps) {\n            uint8_t lt_idx_sps = 0;\n\n            if (sps->num_long_term_ref_pics_sps > 1)\n                lt_idx_sps = get_bits(gb, av_ceil_log2(sps->num_long_term_ref_pics_sps));\n\n            rps->poc[i]  = sps->lt_ref_pic_poc_lsb_sps[lt_idx_sps];\n            rps->used[i] = sps->used_by_curr_pic_lt_sps_flag[lt_idx_sps];\n        } else {\n            rps->poc[i]  = get_bits(gb, sps->log2_max_poc_lsb);\n            rps->used[i] = get_bits1(gb);\n        }\n\n        delta_poc_msb_present = get_bits1(gb);\n        if (delta_poc_msb_present) {\n            int64_t delta = get_ue_golomb_long(gb);\n            int64_t poc;\n\n            if (i && i != nb_sps)\n                delta += prev_delta_msb;\n\n            poc = rps->poc[i] + s->poc - delta * max_poc_lsb - s->sh.pic_order_cnt_lsb;\n            if (poc != (int32_t)poc)\n                return AVERROR_INVALIDDATA;\n            rps->poc[i] = poc;\n            prev_delta_msb = delta;\n        }\n    }\n\n    return 0;\n}\n\nstatic void export_stream_params(AVCodecContext *avctx, const HEVCParamSets *ps,\n                                 const HEVCSPS *sps)\n{\n    const HEVCVPS *vps = (const HEVCVPS*)ps->vps_list[sps->vps_id]->data;\n    const HEVCWindow *ow = &sps->output_window;\n    unsigned int num = 0, den = 0;\n\n    avctx->pix_fmt             = sps->pix_fmt;\n    avctx->coded_width         = sps->width;\n    avctx->coded_height        = sps->height;\n    avctx->width               = sps->width  - ow->left_offset - ow->right_offset;\n    avctx->height              = sps->height - ow->top_offset  - ow->bottom_offset;\n    avctx->has_b_frames        = sps->temporal_layer[sps->max_sub_layers - 1].num_reorder_pics;\n    avctx->profile             = sps->ptl.general_ptl.profile_idc;\n    avctx->level               = sps->ptl.general_ptl.level_idc;\n\n    ff_set_sar(avctx, sps->vui.sar);\n\n    if (sps->vui.video_signal_type_present_flag)\n        avctx->color_range = sps->vui.video_full_range_flag ? AVCOL_RANGE_JPEG\n                                                            : AVCOL_RANGE_MPEG;\n    else\n        avctx->color_range = AVCOL_RANGE_MPEG;\n\n    if (sps->vui.colour_description_present_flag) {\n        avctx->color_primaries = sps->vui.colour_primaries;\n        avctx->color_trc       = sps->vui.transfer_characteristic;\n        avctx->colorspace      = sps->vui.matrix_coeffs;\n    } else {\n        avctx->color_primaries = AVCOL_PRI_UNSPECIFIED;\n        avctx->color_trc       = AVCOL_TRC_UNSPECIFIED;\n        avctx->colorspace      = AVCOL_SPC_UNSPECIFIED;\n    }\n\n    if (vps->vps_timing_info_present_flag) {\n        num = vps->vps_num_units_in_tick;\n        den = vps->vps_time_scale;\n    } else if (sps->vui.vui_timing_info_present_flag) {\n        num = sps->vui.vui_num_units_in_tick;\n        den = sps->vui.vui_time_scale;\n    }\n\n    if (num != 0 && den != 0)\n        av_reduce(&avctx->framerate.den, &avctx->framerate.num,\n                  num, den, 1 << 30);\n}\n\nstatic enum AVPixelFormat get_format(HEVCContext *s, const HEVCSPS *sps)\n{\n#define HWACCEL_MAX (CONFIG_HEVC_DXVA2_HWACCEL + \\\n                     CONFIG_HEVC_D3D11VA_HWACCEL * 2 + \\\n                     CONFIG_HEVC_NVDEC_HWACCEL + \\\n                     CONFIG_HEVC_VAAPI_HWACCEL + \\\n                     CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL + \\\n                     CONFIG_HEVC_VDPAU_HWACCEL)\n    enum AVPixelFormat pix_fmts[HWACCEL_MAX + 2], *fmt = pix_fmts;\n\n    switch (sps->pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUVJ420P:\n#if CONFIG_HEVC_DXVA2_HWACCEL\n        *fmt++ = AV_PIX_FMT_DXVA2_VLD;\n#endif\n#if CONFIG_HEVC_D3D11VA_HWACCEL\n        *fmt++ = AV_PIX_FMT_D3D11VA_VLD;\n        *fmt++ = AV_PIX_FMT_D3D11;\n#endif\n#if CONFIG_HEVC_VAAPI_HWACCEL\n        *fmt++ = AV_PIX_FMT_VAAPI;\n#endif\n#if CONFIG_HEVC_VDPAU_HWACCEL\n        *fmt++ = AV_PIX_FMT_VDPAU;\n#endif\n#if CONFIG_HEVC_NVDEC_HWACCEL\n        *fmt++ = AV_PIX_FMT_CUDA;\n#endif\n#if CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL\n        *fmt++ = AV_PIX_FMT_VIDEOTOOLBOX;\n#endif\n        break;\n    case AV_PIX_FMT_YUV420P10:\n#if CONFIG_HEVC_DXVA2_HWACCEL\n        *fmt++ = AV_PIX_FMT_DXVA2_VLD;\n#endif\n#if CONFIG_HEVC_D3D11VA_HWACCEL\n        *fmt++ = AV_PIX_FMT_D3D11VA_VLD;\n        *fmt++ = AV_PIX_FMT_D3D11;\n#endif\n#if CONFIG_HEVC_VAAPI_HWACCEL\n        *fmt++ = AV_PIX_FMT_VAAPI;\n#endif\n#if CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL\n        *fmt++ = AV_PIX_FMT_VIDEOTOOLBOX;\n#endif\n#if CONFIG_HEVC_NVDEC_HWACCEL\n        *fmt++ = AV_PIX_FMT_CUDA;\n#endif\n        break;\n    case AV_PIX_FMT_YUV420P12:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_YUV444P10:\n    case AV_PIX_FMT_YUV444P12:\n#if CONFIG_HEVC_NVDEC_HWACCEL\n        *fmt++ = AV_PIX_FMT_CUDA;\n#endif\n        break;\n    }\n\n    *fmt++ = sps->pix_fmt;\n    *fmt = AV_PIX_FMT_NONE;\n\n    return ff_thread_get_format(s->avctx, pix_fmts);\n}\n\nstatic int set_sps(HEVCContext *s, const HEVCSPS *sps,\n                   enum AVPixelFormat pix_fmt)\n{\n    int ret, i;\n\n    pic_arrays_free(s);\n    s->ps.sps = NULL;\n    s->ps.vps = NULL;\n\n    if (!sps)\n        return 0;\n\n    ret = pic_arrays_init(s, sps);\n    if (ret < 0)\n        goto fail;\n\n    export_stream_params(s->avctx, &s->ps, sps);\n\n    s->avctx->pix_fmt = pix_fmt;\n\n    ff_hevc_pred_init(&s->hpc,     sps->bit_depth);\n    ff_hevc_dsp_init (&s->hevcdsp, sps->bit_depth);\n    ff_videodsp_init (&s->vdsp,    sps->bit_depth);\n\n    for (i = 0; i < 3; i++) {\n        av_freep(&s->sao_pixel_buffer_h[i]);\n        av_freep(&s->sao_pixel_buffer_v[i]);\n    }\n\n    if (sps->sao_enabled && !s->avctx->hwaccel) {\n        int c_count = (sps->chroma_format_idc != 0) ? 3 : 1;\n        int c_idx;\n\n        for(c_idx = 0; c_idx < c_count; c_idx++) {\n            int w = sps->width >> sps->hshift[c_idx];\n            int h = sps->height >> sps->vshift[c_idx];\n            s->sao_pixel_buffer_h[c_idx] =\n                av_malloc((w * 2 * sps->ctb_height) <<\n                          sps->pixel_shift);\n            s->sao_pixel_buffer_v[c_idx] =\n                av_malloc((h * 2 * sps->ctb_width) <<\n                          sps->pixel_shift);\n        }\n    }\n\n    s->ps.sps = sps;\n    s->ps.vps = (HEVCVPS*) s->ps.vps_list[s->ps.sps->vps_id]->data;\n\n    return 0;\n\nfail:\n    pic_arrays_free(s);\n    s->ps.sps = NULL;\n    return ret;\n}\n\nstatic int hls_slice_header(HEVCContext *s)\n{\n    GetBitContext *gb = &s->HEVClc->gb;\n    SliceHeader *sh   = &s->sh;\n    int i, ret;\n\n    // Coded parameters\n    sh->first_slice_in_pic_flag = get_bits1(gb);\n    if ((IS_IDR(s) || IS_BLA(s)) && sh->first_slice_in_pic_flag) {\n        s->seq_decode = (s->seq_decode + 1) & 0xff;\n        s->max_ra     = INT_MAX;\n        if (IS_IDR(s))\n            ff_hevc_clear_refs(s);\n    }\n    sh->no_output_of_prior_pics_flag = 0;\n    if (IS_IRAP(s))\n        sh->no_output_of_prior_pics_flag = get_bits1(gb);\n\n    sh->pps_id = get_ue_golomb_long(gb);\n    if (sh->pps_id >= HEVC_MAX_PPS_COUNT || !s->ps.pps_list[sh->pps_id]) {\n        av_log(s->avctx, AV_LOG_ERROR, \"PPS id out of range: %d\\n\", sh->pps_id);\n        return AVERROR_INVALIDDATA;\n    }\n    if (!sh->first_slice_in_pic_flag &&\n        s->ps.pps != (HEVCPPS*)s->ps.pps_list[sh->pps_id]->data) {\n        av_log(s->avctx, AV_LOG_ERROR, \"PPS changed between slices.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    s->ps.pps = (HEVCPPS*)s->ps.pps_list[sh->pps_id]->data;\n    if (s->nal_unit_type == HEVC_NAL_CRA_NUT && s->last_eos == 1)\n        sh->no_output_of_prior_pics_flag = 1;\n\n    if (s->ps.sps != (HEVCSPS*)s->ps.sps_list[s->ps.pps->sps_id]->data) {\n        const HEVCSPS *sps = (HEVCSPS*)s->ps.sps_list[s->ps.pps->sps_id]->data;\n        const HEVCSPS *last_sps = s->ps.sps;\n        enum AVPixelFormat pix_fmt;\n\n        if (last_sps && IS_IRAP(s) && s->nal_unit_type != HEVC_NAL_CRA_NUT) {\n            if (sps->width != last_sps->width || sps->height != last_sps->height ||\n                sps->temporal_layer[sps->max_sub_layers - 1].max_dec_pic_buffering !=\n                last_sps->temporal_layer[last_sps->max_sub_layers - 1].max_dec_pic_buffering)\n                sh->no_output_of_prior_pics_flag = 0;\n        }\n        ff_hevc_clear_refs(s);\n\n        ret = set_sps(s, sps, sps->pix_fmt);\n        if (ret < 0)\n            return ret;\n\n        pix_fmt = get_format(s, sps);\n        if (pix_fmt < 0)\n            return pix_fmt;\n        s->avctx->pix_fmt = pix_fmt;\n\n        s->seq_decode = (s->seq_decode + 1) & 0xff;\n        s->max_ra     = INT_MAX;\n    }\n\n    sh->dependent_slice_segment_flag = 0;\n    if (!sh->first_slice_in_pic_flag) {\n        int slice_address_length;\n\n        if (s->ps.pps->dependent_slice_segments_enabled_flag)\n            sh->dependent_slice_segment_flag = get_bits1(gb);\n\n        slice_address_length = av_ceil_log2(s->ps.sps->ctb_width *\n                                            s->ps.sps->ctb_height);\n        sh->slice_segment_addr = get_bitsz(gb, slice_address_length);\n        if (sh->slice_segment_addr >= s->ps.sps->ctb_width * s->ps.sps->ctb_height) {\n            av_log(s->avctx, AV_LOG_ERROR,\n                   \"Invalid slice segment address: %u.\\n\",\n                   sh->slice_segment_addr);\n            return AVERROR_INVALIDDATA;\n        }\n\n        if (!sh->dependent_slice_segment_flag) {\n            sh->slice_addr = sh->slice_segment_addr;\n            s->slice_idx++;\n        }\n    } else {\n        sh->slice_segment_addr = sh->slice_addr = 0;\n        s->slice_idx           = 0;\n        s->slice_initialized   = 0;\n    }\n\n    if (!sh->dependent_slice_segment_flag) {\n        s->slice_initialized = 0;\n\n        for (i = 0; i < s->ps.pps->num_extra_slice_header_bits; i++)\n            skip_bits(gb, 1);  // slice_reserved_undetermined_flag[]\n\n        sh->slice_type = get_ue_golomb_long(gb);\n        if (!(sh->slice_type == HEVC_SLICE_I ||\n              sh->slice_type == HEVC_SLICE_P ||\n              sh->slice_type == HEVC_SLICE_B)) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Unknown slice type: %d.\\n\",\n                   sh->slice_type);\n            return AVERROR_INVALIDDATA;\n        }\n        if (IS_IRAP(s) && sh->slice_type != HEVC_SLICE_I) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Inter slices in an IRAP frame.\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        // when flag is not present, picture is inferred to be output\n        sh->pic_output_flag = 1;\n        if (s->ps.pps->output_flag_present_flag)\n            sh->pic_output_flag = get_bits1(gb);\n\n        if (s->ps.sps->separate_colour_plane_flag)\n            sh->colour_plane_id = get_bits(gb, 2);\n\n        if (!IS_IDR(s)) {\n            int poc, pos;\n\n            sh->pic_order_cnt_lsb = get_bits(gb, s->ps.sps->log2_max_poc_lsb);\n            poc = ff_hevc_compute_poc(s->ps.sps, s->pocTid0, sh->pic_order_cnt_lsb, s->nal_unit_type);\n            if (!sh->first_slice_in_pic_flag && poc != s->poc) {\n                av_log(s->avctx, AV_LOG_WARNING,\n                       \"Ignoring POC change between slices: %d -> %d\\n\", s->poc, poc);\n                if (s->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_INVALIDDATA;\n                poc = s->poc;\n            }\n            s->poc = poc;\n\n            sh->short_term_ref_pic_set_sps_flag = get_bits1(gb);\n            pos = get_bits_left(gb);\n            if (!sh->short_term_ref_pic_set_sps_flag) {\n                ret = ff_hevc_decode_short_term_rps(gb, s->avctx, &sh->slice_rps, s->ps.sps, 1);\n                if (ret < 0)\n                    return ret;\n\n                sh->short_term_rps = &sh->slice_rps;\n            } else {\n                int numbits, rps_idx;\n\n                if (!s->ps.sps->nb_st_rps) {\n                    av_log(s->avctx, AV_LOG_ERROR, \"No ref lists in the SPS.\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n\n                numbits = av_ceil_log2(s->ps.sps->nb_st_rps);\n                rps_idx = numbits > 0 ? get_bits(gb, numbits) : 0;\n                sh->short_term_rps = &s->ps.sps->st_rps[rps_idx];\n            }\n            sh->short_term_ref_pic_set_size = pos - get_bits_left(gb);\n\n            pos = get_bits_left(gb);\n            ret = decode_lt_rps(s, &sh->long_term_rps, gb);\n            if (ret < 0) {\n                av_log(s->avctx, AV_LOG_WARNING, \"Invalid long term RPS.\\n\");\n                if (s->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_INVALIDDATA;\n            }\n            sh->long_term_ref_pic_set_size = pos - get_bits_left(gb);\n\n            if (s->ps.sps->sps_temporal_mvp_enabled_flag)\n                sh->slice_temporal_mvp_enabled_flag = get_bits1(gb);\n            else\n                sh->slice_temporal_mvp_enabled_flag = 0;\n        } else {\n            s->sh.short_term_rps = NULL;\n            s->poc               = 0;\n        }\n\n        /* 8.3.1 */\n        if (sh->first_slice_in_pic_flag && s->temporal_id == 0 &&\n            s->nal_unit_type != HEVC_NAL_TRAIL_N &&\n            s->nal_unit_type != HEVC_NAL_TSA_N   &&\n            s->nal_unit_type != HEVC_NAL_STSA_N  &&\n            s->nal_unit_type != HEVC_NAL_RADL_N  &&\n            s->nal_unit_type != HEVC_NAL_RADL_R  &&\n            s->nal_unit_type != HEVC_NAL_RASL_N  &&\n            s->nal_unit_type != HEVC_NAL_RASL_R)\n            s->pocTid0 = s->poc;\n\n        if (s->ps.sps->sao_enabled) {\n            sh->slice_sample_adaptive_offset_flag[0] = get_bits1(gb);\n            if (s->ps.sps->chroma_format_idc) {\n                sh->slice_sample_adaptive_offset_flag[1] =\n                sh->slice_sample_adaptive_offset_flag[2] = get_bits1(gb);\n            }\n        } else {\n            sh->slice_sample_adaptive_offset_flag[0] = 0;\n            sh->slice_sample_adaptive_offset_flag[1] = 0;\n            sh->slice_sample_adaptive_offset_flag[2] = 0;\n        }\n\n        sh->nb_refs[L0] = sh->nb_refs[L1] = 0;\n        if (sh->slice_type == HEVC_SLICE_P || sh->slice_type == HEVC_SLICE_B) {\n            int nb_refs;\n\n            sh->nb_refs[L0] = s->ps.pps->num_ref_idx_l0_default_active;\n            if (sh->slice_type == HEVC_SLICE_B)\n                sh->nb_refs[L1] = s->ps.pps->num_ref_idx_l1_default_active;\n\n            if (get_bits1(gb)) { // num_ref_idx_active_override_flag\n                sh->nb_refs[L0] = get_ue_golomb_long(gb) + 1;\n                if (sh->slice_type == HEVC_SLICE_B)\n                    sh->nb_refs[L1] = get_ue_golomb_long(gb) + 1;\n            }\n            if (sh->nb_refs[L0] > HEVC_MAX_REFS || sh->nb_refs[L1] > HEVC_MAX_REFS) {\n                av_log(s->avctx, AV_LOG_ERROR, \"Too many refs: %d/%d.\\n\",\n                       sh->nb_refs[L0], sh->nb_refs[L1]);\n                return AVERROR_INVALIDDATA;\n            }\n\n            sh->rpl_modification_flag[0] = 0;\n            sh->rpl_modification_flag[1] = 0;\n            nb_refs = ff_hevc_frame_nb_refs(s);\n            if (!nb_refs) {\n                av_log(s->avctx, AV_LOG_ERROR, \"Zero refs for a frame with P or B slices.\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n\n            if (s->ps.pps->lists_modification_present_flag && nb_refs > 1) {\n                sh->rpl_modification_flag[0] = get_bits1(gb);\n                if (sh->rpl_modification_flag[0]) {\n                    for (i = 0; i < sh->nb_refs[L0]; i++)\n                        sh->list_entry_lx[0][i] = get_bits(gb, av_ceil_log2(nb_refs));\n                }\n\n                if (sh->slice_type == HEVC_SLICE_B) {\n                    sh->rpl_modification_flag[1] = get_bits1(gb);\n                    if (sh->rpl_modification_flag[1] == 1)\n                        for (i = 0; i < sh->nb_refs[L1]; i++)\n                            sh->list_entry_lx[1][i] = get_bits(gb, av_ceil_log2(nb_refs));\n                }\n            }\n\n            if (sh->slice_type == HEVC_SLICE_B)\n                sh->mvd_l1_zero_flag = get_bits1(gb);\n\n            if (s->ps.pps->cabac_init_present_flag)\n                sh->cabac_init_flag = get_bits1(gb);\n            else\n                sh->cabac_init_flag = 0;\n\n            sh->collocated_ref_idx = 0;\n            if (sh->slice_temporal_mvp_enabled_flag) {\n                sh->collocated_list = L0;\n                if (sh->slice_type == HEVC_SLICE_B)\n                    sh->collocated_list = !get_bits1(gb);\n\n                if (sh->nb_refs[sh->collocated_list] > 1) {\n                    sh->collocated_ref_idx = get_ue_golomb_long(gb);\n                    if (sh->collocated_ref_idx >= sh->nb_refs[sh->collocated_list]) {\n                        av_log(s->avctx, AV_LOG_ERROR,\n                               \"Invalid collocated_ref_idx: %d.\\n\",\n                               sh->collocated_ref_idx);\n                        return AVERROR_INVALIDDATA;\n                    }\n                }\n            }\n\n            if ((s->ps.pps->weighted_pred_flag   && sh->slice_type == HEVC_SLICE_P) ||\n                (s->ps.pps->weighted_bipred_flag && sh->slice_type == HEVC_SLICE_B)) {\n                int ret = pred_weight_table(s, gb);\n                if (ret < 0)\n                    return ret;\n            }\n\n            sh->max_num_merge_cand = 5 - get_ue_golomb_long(gb);\n            if (sh->max_num_merge_cand < 1 || sh->max_num_merge_cand > 5) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"Invalid number of merging MVP candidates: %d.\\n\",\n                       sh->max_num_merge_cand);\n                return AVERROR_INVALIDDATA;\n            }\n        }\n\n        sh->slice_qp_delta = get_se_golomb(gb);\n\n        if (s->ps.pps->pic_slice_level_chroma_qp_offsets_present_flag) {\n            sh->slice_cb_qp_offset = get_se_golomb(gb);\n            sh->slice_cr_qp_offset = get_se_golomb(gb);\n        } else {\n            sh->slice_cb_qp_offset = 0;\n            sh->slice_cr_qp_offset = 0;\n        }\n\n        if (s->ps.pps->chroma_qp_offset_list_enabled_flag)\n            sh->cu_chroma_qp_offset_enabled_flag = get_bits1(gb);\n        else\n            sh->cu_chroma_qp_offset_enabled_flag = 0;\n\n        if (s->ps.pps->deblocking_filter_control_present_flag) {\n            int deblocking_filter_override_flag = 0;\n\n            if (s->ps.pps->deblocking_filter_override_enabled_flag)\n                deblocking_filter_override_flag = get_bits1(gb);\n\n            if (deblocking_filter_override_flag) {\n                sh->disable_deblocking_filter_flag = get_bits1(gb);\n                if (!sh->disable_deblocking_filter_flag) {\n                    int beta_offset_div2 = get_se_golomb(gb);\n                    int tc_offset_div2   = get_se_golomb(gb) ;\n                    if (beta_offset_div2 < -6 || beta_offset_div2 > 6 ||\n                        tc_offset_div2   < -6 || tc_offset_div2   > 6) {\n                        av_log(s->avctx, AV_LOG_ERROR,\n                            \"Invalid deblock filter offsets: %d, %d\\n\",\n                            beta_offset_div2, tc_offset_div2);\n                        return AVERROR_INVALIDDATA;\n                    }\n                    sh->beta_offset = beta_offset_div2 * 2;\n                    sh->tc_offset   =   tc_offset_div2 * 2;\n                }\n            } else {\n                sh->disable_deblocking_filter_flag = s->ps.pps->disable_dbf;\n                sh->beta_offset                    = s->ps.pps->beta_offset;\n                sh->tc_offset                      = s->ps.pps->tc_offset;\n            }\n        } else {\n            sh->disable_deblocking_filter_flag = 0;\n            sh->beta_offset                    = 0;\n            sh->tc_offset                      = 0;\n        }\n\n        if (s->ps.pps->seq_loop_filter_across_slices_enabled_flag &&\n            (sh->slice_sample_adaptive_offset_flag[0] ||\n             sh->slice_sample_adaptive_offset_flag[1] ||\n             !sh->disable_deblocking_filter_flag)) {\n            sh->slice_loop_filter_across_slices_enabled_flag = get_bits1(gb);\n        } else {\n            sh->slice_loop_filter_across_slices_enabled_flag = s->ps.pps->seq_loop_filter_across_slices_enabled_flag;\n        }\n    } else if (!s->slice_initialized) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Independent slice segment missing.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    sh->num_entry_point_offsets = 0;\n    if (s->ps.pps->tiles_enabled_flag || s->ps.pps->entropy_coding_sync_enabled_flag) {\n        unsigned num_entry_point_offsets = get_ue_golomb_long(gb);\n        // It would be possible to bound this tighter but this here is simpler\n        if (num_entry_point_offsets > get_bits_left(gb)) {\n            av_log(s->avctx, AV_LOG_ERROR, \"num_entry_point_offsets %d is invalid\\n\", num_entry_point_offsets);\n            return AVERROR_INVALIDDATA;\n        }\n\n        sh->num_entry_point_offsets = num_entry_point_offsets;\n        if (sh->num_entry_point_offsets > 0) {\n            int offset_len = get_ue_golomb_long(gb) + 1;\n\n            if (offset_len < 1 || offset_len > 32) {\n                sh->num_entry_point_offsets = 0;\n                av_log(s->avctx, AV_LOG_ERROR, \"offset_len %d is invalid\\n\", offset_len);\n                return AVERROR_INVALIDDATA;\n            }\n\n            av_freep(&sh->entry_point_offset);\n            av_freep(&sh->offset);\n            av_freep(&sh->size);\n            sh->entry_point_offset = av_malloc_array(sh->num_entry_point_offsets, sizeof(unsigned));\n            sh->offset = av_malloc_array(sh->num_entry_point_offsets, sizeof(int));\n            sh->size = av_malloc_array(sh->num_entry_point_offsets, sizeof(int));\n            if (!sh->entry_point_offset || !sh->offset || !sh->size) {\n                sh->num_entry_point_offsets = 0;\n                av_log(s->avctx, AV_LOG_ERROR, \"Failed to allocate memory\\n\");\n                return AVERROR(ENOMEM);\n            }\n            for (i = 0; i < sh->num_entry_point_offsets; i++) {\n                unsigned val = get_bits_long(gb, offset_len);\n                sh->entry_point_offset[i] = val + 1; // +1; // +1 to get the size\n            }\n            if (s->threads_number > 1 && (s->ps.pps->num_tile_rows > 1 || s->ps.pps->num_tile_columns > 1)) {\n                s->enable_parallel_tiles = 0; // TODO: you can enable tiles in parallel here\n                s->threads_number = 1;\n            } else\n                s->enable_parallel_tiles = 0;\n        } else\n            s->enable_parallel_tiles = 0;\n    }\n\n    if (s->ps.pps->slice_header_extension_present_flag) {\n        unsigned int length = get_ue_golomb_long(gb);\n        if (length*8LL > get_bits_left(gb)) {\n            av_log(s->avctx, AV_LOG_ERROR, \"too many slice_header_extension_data_bytes\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        for (i = 0; i < length; i++)\n            skip_bits(gb, 8);  // slice_header_extension_data_byte\n    }\n\n    // Inferred parameters\n    sh->slice_qp = 26U + s->ps.pps->pic_init_qp_minus26 + sh->slice_qp_delta;\n    if (sh->slice_qp > 51 ||\n        sh->slice_qp < -s->ps.sps->qp_bd_offset) {\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"The slice_qp %d is outside the valid range \"\n               \"[%d, 51].\\n\",\n               sh->slice_qp,\n               -s->ps.sps->qp_bd_offset);\n        return AVERROR_INVALIDDATA;\n    }\n\n    sh->slice_ctb_addr_rs = sh->slice_segment_addr;\n\n    if (!s->sh.slice_ctb_addr_rs && s->sh.dependent_slice_segment_flag) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Impossible slice segment.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (get_bits_left(gb) < 0) {\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"Overread slice header by %d bits\\n\", -get_bits_left(gb));\n        return AVERROR_INVALIDDATA;\n    }\n\n    s->HEVClc->first_qp_group = !s->sh.dependent_slice_segment_flag;\n\n    if (!s->ps.pps->cu_qp_delta_enabled_flag)\n        s->HEVClc->qp_y = s->sh.slice_qp;\n\n    s->slice_initialized = 1;\n    s->HEVClc->tu.cu_qp_offset_cb = 0;\n    s->HEVClc->tu.cu_qp_offset_cr = 0;\n\n    return 0;\n}\n\n#define CTB(tab, x, y) ((tab)[(y) * s->ps.sps->ctb_width + (x)])\n\n#define SET_SAO(elem, value)                            \\\ndo {                                                    \\\n    if (!sao_merge_up_flag && !sao_merge_left_flag)     \\\n        sao->elem = value;                              \\\n    else if (sao_merge_left_flag)                       \\\n        sao->elem = CTB(s->sao, rx-1, ry).elem;         \\\n    else if (sao_merge_up_flag)                         \\\n        sao->elem = CTB(s->sao, rx, ry-1).elem;         \\\n    else                                                \\\n        sao->elem = 0;                                  \\\n} while (0)\n\nstatic void hls_sao_param(HEVCContext *s, int rx, int ry)\n{\n    HEVCLocalContext *lc    = s->HEVClc;\n    int sao_merge_left_flag = 0;\n    int sao_merge_up_flag   = 0;\n    SAOParams *sao          = &CTB(s->sao, rx, ry);\n    int c_idx, i;\n\n    if (s->sh.slice_sample_adaptive_offset_flag[0] ||\n        s->sh.slice_sample_adaptive_offset_flag[1]) {\n        if (rx > 0) {\n            if (lc->ctb_left_flag)\n                sao_merge_left_flag = ff_hevc_sao_merge_flag_decode(s);\n        }\n        if (ry > 0 && !sao_merge_left_flag) {\n            if (lc->ctb_up_flag)\n                sao_merge_up_flag = ff_hevc_sao_merge_flag_decode(s);\n        }\n    }\n\n    for (c_idx = 0; c_idx < (s->ps.sps->chroma_format_idc ? 3 : 1); c_idx++) {\n        int log2_sao_offset_scale = c_idx == 0 ? s->ps.pps->log2_sao_offset_scale_luma :\n                                                 s->ps.pps->log2_sao_offset_scale_chroma;\n\n        if (!s->sh.slice_sample_adaptive_offset_flag[c_idx]) {\n            sao->type_idx[c_idx] = SAO_NOT_APPLIED;\n            continue;\n        }\n\n        if (c_idx == 2) {\n            sao->type_idx[2] = sao->type_idx[1];\n            sao->eo_class[2] = sao->eo_class[1];\n        } else {\n            SET_SAO(type_idx[c_idx], ff_hevc_sao_type_idx_decode(s));\n        }\n\n        if (sao->type_idx[c_idx] == SAO_NOT_APPLIED)\n            continue;\n\n        for (i = 0; i < 4; i++)\n            SET_SAO(offset_abs[c_idx][i], ff_hevc_sao_offset_abs_decode(s));\n\n        if (sao->type_idx[c_idx] == SAO_BAND) {\n            for (i = 0; i < 4; i++) {\n                if (sao->offset_abs[c_idx][i]) {\n                    SET_SAO(offset_sign[c_idx][i],\n                            ff_hevc_sao_offset_sign_decode(s));\n                } else {\n                    sao->offset_sign[c_idx][i] = 0;\n                }\n            }\n            SET_SAO(band_position[c_idx], ff_hevc_sao_band_position_decode(s));\n        } else if (c_idx != 2) {\n            SET_SAO(eo_class[c_idx], ff_hevc_sao_eo_class_decode(s));\n        }\n\n        // Inferred parameters\n        sao->offset_val[c_idx][0] = 0;\n        for (i = 0; i < 4; i++) {\n            sao->offset_val[c_idx][i + 1] = sao->offset_abs[c_idx][i];\n            if (sao->type_idx[c_idx] == SAO_EDGE) {\n                if (i > 1)\n                    sao->offset_val[c_idx][i + 1] = -sao->offset_val[c_idx][i + 1];\n            } else if (sao->offset_sign[c_idx][i]) {\n                sao->offset_val[c_idx][i + 1] = -sao->offset_val[c_idx][i + 1];\n            }\n            sao->offset_val[c_idx][i + 1] *= 1 << log2_sao_offset_scale;\n        }\n    }\n}\n\n#undef SET_SAO\n#undef CTB\n\nstatic int hls_cross_component_pred(HEVCContext *s, int idx) {\n    HEVCLocalContext *lc    = s->HEVClc;\n    int log2_res_scale_abs_plus1 = ff_hevc_log2_res_scale_abs(s, idx);\n\n    if (log2_res_scale_abs_plus1 !=  0) {\n        int res_scale_sign_flag = ff_hevc_res_scale_sign_flag(s, idx);\n        lc->tu.res_scale_val = (1 << (log2_res_scale_abs_plus1 - 1)) *\n                               (1 - 2 * res_scale_sign_flag);\n    } else {\n        lc->tu.res_scale_val = 0;\n    }\n\n\n    return 0;\n}\n\nstatic int hls_transform_unit(HEVCContext *s, int x0, int y0,\n                              int xBase, int yBase, int cb_xBase, int cb_yBase,\n                              int log2_cb_size, int log2_trafo_size,\n                              int blk_idx, int cbf_luma, int *cbf_cb, int *cbf_cr)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    const int log2_trafo_size_c = log2_trafo_size - s->ps.sps->hshift[1];\n    int i;\n\n    if (lc->cu.pred_mode == MODE_INTRA) {\n        int trafo_size = 1 << log2_trafo_size;\n        ff_hevc_set_neighbour_available(s, x0, y0, trafo_size, trafo_size);\n\n        s->hpc.intra_pred[log2_trafo_size - 2](s, x0, y0, 0);\n    }\n\n    if (cbf_luma || cbf_cb[0] || cbf_cr[0] ||\n        (s->ps.sps->chroma_format_idc == 2 && (cbf_cb[1] || cbf_cr[1]))) {\n        int scan_idx   = SCAN_DIAG;\n        int scan_idx_c = SCAN_DIAG;\n        int cbf_chroma = cbf_cb[0] || cbf_cr[0] ||\n                         (s->ps.sps->chroma_format_idc == 2 &&\n                         (cbf_cb[1] || cbf_cr[1]));\n\n        if (s->ps.pps->cu_qp_delta_enabled_flag && !lc->tu.is_cu_qp_delta_coded) {\n            lc->tu.cu_qp_delta = ff_hevc_cu_qp_delta_abs(s);\n            if (lc->tu.cu_qp_delta != 0)\n                if (ff_hevc_cu_qp_delta_sign_flag(s) == 1)\n                    lc->tu.cu_qp_delta = -lc->tu.cu_qp_delta;\n            lc->tu.is_cu_qp_delta_coded = 1;\n\n            if (lc->tu.cu_qp_delta < -(26 + s->ps.sps->qp_bd_offset / 2) ||\n                lc->tu.cu_qp_delta >  (25 + s->ps.sps->qp_bd_offset / 2)) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"The cu_qp_delta %d is outside the valid range \"\n                       \"[%d, %d].\\n\",\n                       lc->tu.cu_qp_delta,\n                       -(26 + s->ps.sps->qp_bd_offset / 2),\n                        (25 + s->ps.sps->qp_bd_offset / 2));\n                return AVERROR_INVALIDDATA;\n            }\n\n            ff_hevc_set_qPy(s, cb_xBase, cb_yBase, log2_cb_size);\n        }\n\n        if (s->sh.cu_chroma_qp_offset_enabled_flag && cbf_chroma &&\n            !lc->cu.cu_transquant_bypass_flag  &&  !lc->tu.is_cu_chroma_qp_offset_coded) {\n            int cu_chroma_qp_offset_flag = ff_hevc_cu_chroma_qp_offset_flag(s);\n            if (cu_chroma_qp_offset_flag) {\n                int cu_chroma_qp_offset_idx  = 0;\n                if (s->ps.pps->chroma_qp_offset_list_len_minus1 > 0) {\n                    cu_chroma_qp_offset_idx = ff_hevc_cu_chroma_qp_offset_idx(s);\n                    av_log(s->avctx, AV_LOG_ERROR,\n                        \"cu_chroma_qp_offset_idx not yet tested.\\n\");\n                }\n                lc->tu.cu_qp_offset_cb = s->ps.pps->cb_qp_offset_list[cu_chroma_qp_offset_idx];\n                lc->tu.cu_qp_offset_cr = s->ps.pps->cr_qp_offset_list[cu_chroma_qp_offset_idx];\n            } else {\n                lc->tu.cu_qp_offset_cb = 0;\n                lc->tu.cu_qp_offset_cr = 0;\n            }\n            lc->tu.is_cu_chroma_qp_offset_coded = 1;\n        }\n\n        if (lc->cu.pred_mode == MODE_INTRA && log2_trafo_size < 4) {\n            if (lc->tu.intra_pred_mode >= 6 &&\n                lc->tu.intra_pred_mode <= 14) {\n                scan_idx = SCAN_VERT;\n            } else if (lc->tu.intra_pred_mode >= 22 &&\n                       lc->tu.intra_pred_mode <= 30) {\n                scan_idx = SCAN_HORIZ;\n            }\n\n            if (lc->tu.intra_pred_mode_c >=  6 &&\n                lc->tu.intra_pred_mode_c <= 14) {\n                scan_idx_c = SCAN_VERT;\n            } else if (lc->tu.intra_pred_mode_c >= 22 &&\n                       lc->tu.intra_pred_mode_c <= 30) {\n                scan_idx_c = SCAN_HORIZ;\n            }\n        }\n\n        lc->tu.cross_pf = 0;\n\n        if (cbf_luma)\n            ff_hevc_hls_residual_coding(s, x0, y0, log2_trafo_size, scan_idx, 0);\n        if (s->ps.sps->chroma_format_idc && (log2_trafo_size > 2 || s->ps.sps->chroma_format_idc == 3)) {\n            int trafo_size_h = 1 << (log2_trafo_size_c + s->ps.sps->hshift[1]);\n            int trafo_size_v = 1 << (log2_trafo_size_c + s->ps.sps->vshift[1]);\n            lc->tu.cross_pf  = (s->ps.pps->cross_component_prediction_enabled_flag && cbf_luma &&\n                                (lc->cu.pred_mode == MODE_INTER ||\n                                 (lc->tu.chroma_mode_c ==  4)));\n\n            if (lc->tu.cross_pf) {\n                hls_cross_component_pred(s, 0);\n            }\n            for (i = 0; i < (s->ps.sps->chroma_format_idc == 2 ? 2 : 1); i++) {\n                if (lc->cu.pred_mode == MODE_INTRA) {\n                    ff_hevc_set_neighbour_available(s, x0, y0 + (i << log2_trafo_size_c), trafo_size_h, trafo_size_v);\n                    s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0 + (i << log2_trafo_size_c), 1);\n                }\n                if (cbf_cb[i])\n                    ff_hevc_hls_residual_coding(s, x0, y0 + (i << log2_trafo_size_c),\n                                                log2_trafo_size_c, scan_idx_c, 1);\n                else\n                    if (lc->tu.cross_pf) {\n                        ptrdiff_t stride = s->frame->linesize[1];\n                        int hshift = s->ps.sps->hshift[1];\n                        int vshift = s->ps.sps->vshift[1];\n                        int16_t *coeffs_y = (int16_t*)lc->edge_emu_buffer;\n                        int16_t *coeffs   = (int16_t*)lc->edge_emu_buffer2;\n                        int size = 1 << log2_trafo_size_c;\n\n                        uint8_t *dst = &s->frame->data[1][(y0 >> vshift) * stride +\n                                                              ((x0 >> hshift) << s->ps.sps->pixel_shift)];\n                        for (i = 0; i < (size * size); i++) {\n                            coeffs[i] = ((lc->tu.res_scale_val * coeffs_y[i]) >> 3);\n                        }\n                        s->hevcdsp.add_residual[log2_trafo_size_c-2](dst, coeffs, stride);\n                    }\n            }\n\n            if (lc->tu.cross_pf) {\n                hls_cross_component_pred(s, 1);\n            }\n            for (i = 0; i < (s->ps.sps->chroma_format_idc == 2 ? 2 : 1); i++) {\n                if (lc->cu.pred_mode == MODE_INTRA) {\n                    ff_hevc_set_neighbour_available(s, x0, y0 + (i << log2_trafo_size_c), trafo_size_h, trafo_size_v);\n                    s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0 + (i << log2_trafo_size_c), 2);\n                }\n                if (cbf_cr[i])\n                    ff_hevc_hls_residual_coding(s, x0, y0 + (i << log2_trafo_size_c),\n                                                log2_trafo_size_c, scan_idx_c, 2);\n                else\n                    if (lc->tu.cross_pf) {\n                        ptrdiff_t stride = s->frame->linesize[2];\n                        int hshift = s->ps.sps->hshift[2];\n                        int vshift = s->ps.sps->vshift[2];\n                        int16_t *coeffs_y = (int16_t*)lc->edge_emu_buffer;\n                        int16_t *coeffs   = (int16_t*)lc->edge_emu_buffer2;\n                        int size = 1 << log2_trafo_size_c;\n\n                        uint8_t *dst = &s->frame->data[2][(y0 >> vshift) * stride +\n                                                          ((x0 >> hshift) << s->ps.sps->pixel_shift)];\n                        for (i = 0; i < (size * size); i++) {\n                            coeffs[i] = ((lc->tu.res_scale_val * coeffs_y[i]) >> 3);\n                        }\n                        s->hevcdsp.add_residual[log2_trafo_size_c-2](dst, coeffs, stride);\n                    }\n            }\n        } else if (s->ps.sps->chroma_format_idc && blk_idx == 3) {\n            int trafo_size_h = 1 << (log2_trafo_size + 1);\n            int trafo_size_v = 1 << (log2_trafo_size + s->ps.sps->vshift[1]);\n            for (i = 0; i < (s->ps.sps->chroma_format_idc == 2 ? 2 : 1); i++) {\n                if (lc->cu.pred_mode == MODE_INTRA) {\n                    ff_hevc_set_neighbour_available(s, xBase, yBase + (i << log2_trafo_size),\n                                                    trafo_size_h, trafo_size_v);\n                    s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase + (i << log2_trafo_size), 1);\n                }\n                if (cbf_cb[i])\n                    ff_hevc_hls_residual_coding(s, xBase, yBase + (i << log2_trafo_size),\n                                                log2_trafo_size, scan_idx_c, 1);\n            }\n            for (i = 0; i < (s->ps.sps->chroma_format_idc == 2 ? 2 : 1); i++) {\n                if (lc->cu.pred_mode == MODE_INTRA) {\n                    ff_hevc_set_neighbour_available(s, xBase, yBase + (i << log2_trafo_size),\n                                                trafo_size_h, trafo_size_v);\n                    s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase + (i << log2_trafo_size), 2);\n                }\n                if (cbf_cr[i])\n                    ff_hevc_hls_residual_coding(s, xBase, yBase + (i << log2_trafo_size),\n                                                log2_trafo_size, scan_idx_c, 2);\n            }\n        }\n    } else if (s->ps.sps->chroma_format_idc && lc->cu.pred_mode == MODE_INTRA) {\n        if (log2_trafo_size > 2 || s->ps.sps->chroma_format_idc == 3) {\n            int trafo_size_h = 1 << (log2_trafo_size_c + s->ps.sps->hshift[1]);\n            int trafo_size_v = 1 << (log2_trafo_size_c + s->ps.sps->vshift[1]);\n            ff_hevc_set_neighbour_available(s, x0, y0, trafo_size_h, trafo_size_v);\n            s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0, 1);\n            s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0, 2);\n            if (s->ps.sps->chroma_format_idc == 2) {\n                ff_hevc_set_neighbour_available(s, x0, y0 + (1 << log2_trafo_size_c),\n                                                trafo_size_h, trafo_size_v);\n                s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0 + (1 << log2_trafo_size_c), 1);\n                s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0 + (1 << log2_trafo_size_c), 2);\n            }\n        } else if (blk_idx == 3) {\n            int trafo_size_h = 1 << (log2_trafo_size + 1);\n            int trafo_size_v = 1 << (log2_trafo_size + s->ps.sps->vshift[1]);\n            ff_hevc_set_neighbour_available(s, xBase, yBase,\n                                            trafo_size_h, trafo_size_v);\n            s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase, 1);\n            s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase, 2);\n            if (s->ps.sps->chroma_format_idc == 2) {\n                ff_hevc_set_neighbour_available(s, xBase, yBase + (1 << (log2_trafo_size)),\n                                                trafo_size_h, trafo_size_v);\n                s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase + (1 << (log2_trafo_size)), 1);\n                s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase + (1 << (log2_trafo_size)), 2);\n            }\n        }\n    }\n\n    return 0;\n}\n\nstatic void set_deblocking_bypass(HEVCContext *s, int x0, int y0, int log2_cb_size)\n{\n    int cb_size          = 1 << log2_cb_size;\n    int log2_min_pu_size = s->ps.sps->log2_min_pu_size;\n\n    int min_pu_width     = s->ps.sps->min_pu_width;\n    int x_end = FFMIN(x0 + cb_size, s->ps.sps->width);\n    int y_end = FFMIN(y0 + cb_size, s->ps.sps->height);\n    int i, j;\n\n    for (j = (y0 >> log2_min_pu_size); j < (y_end >> log2_min_pu_size); j++)\n        for (i = (x0 >> log2_min_pu_size); i < (x_end >> log2_min_pu_size); i++)\n            s->is_pcm[i + j * min_pu_width] = 2;\n}\n\nstatic int hls_transform_tree(HEVCContext *s, int x0, int y0,\n                              int xBase, int yBase, int cb_xBase, int cb_yBase,\n                              int log2_cb_size, int log2_trafo_size,\n                              int trafo_depth, int blk_idx,\n                              const int *base_cbf_cb, const int *base_cbf_cr)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    uint8_t split_transform_flag;\n    int cbf_cb[2];\n    int cbf_cr[2];\n    int ret;\n\n    cbf_cb[0] = base_cbf_cb[0];\n    cbf_cb[1] = base_cbf_cb[1];\n    cbf_cr[0] = base_cbf_cr[0];\n    cbf_cr[1] = base_cbf_cr[1];\n\n    if (lc->cu.intra_split_flag) {\n        if (trafo_depth == 1) {\n            lc->tu.intra_pred_mode   = lc->pu.intra_pred_mode[blk_idx];\n            if (s->ps.sps->chroma_format_idc == 3) {\n                lc->tu.intra_pred_mode_c = lc->pu.intra_pred_mode_c[blk_idx];\n                lc->tu.chroma_mode_c     = lc->pu.chroma_mode_c[blk_idx];\n            } else {\n                lc->tu.intra_pred_mode_c = lc->pu.intra_pred_mode_c[0];\n                lc->tu.chroma_mode_c     = lc->pu.chroma_mode_c[0];\n            }\n        }\n    } else {\n        lc->tu.intra_pred_mode   = lc->pu.intra_pred_mode[0];\n        lc->tu.intra_pred_mode_c = lc->pu.intra_pred_mode_c[0];\n        lc->tu.chroma_mode_c     = lc->pu.chroma_mode_c[0];\n    }\n\n    if (log2_trafo_size <= s->ps.sps->log2_max_trafo_size &&\n        log2_trafo_size >  s->ps.sps->log2_min_tb_size    &&\n        trafo_depth     < lc->cu.max_trafo_depth       &&\n        !(lc->cu.intra_split_flag && trafo_depth == 0)) {\n        split_transform_flag = ff_hevc_split_transform_flag_decode(s, log2_trafo_size);\n    } else {\n        int inter_split = s->ps.sps->max_transform_hierarchy_depth_inter == 0 &&\n                          lc->cu.pred_mode == MODE_INTER &&\n                          lc->cu.part_mode != PART_2Nx2N &&\n                          trafo_depth == 0;\n\n        split_transform_flag = log2_trafo_size > s->ps.sps->log2_max_trafo_size ||\n                               (lc->cu.intra_split_flag && trafo_depth == 0) ||\n                               inter_split;\n    }\n\n    if (s->ps.sps->chroma_format_idc && (log2_trafo_size > 2 || s->ps.sps->chroma_format_idc == 3)) {\n        if (trafo_depth == 0 || cbf_cb[0]) {\n            cbf_cb[0] = ff_hevc_cbf_cb_cr_decode(s, trafo_depth);\n            if (s->ps.sps->chroma_format_idc == 2 && (!split_transform_flag || log2_trafo_size == 3)) {\n                cbf_cb[1] = ff_hevc_cbf_cb_cr_decode(s, trafo_depth);\n            }\n        }\n\n        if (trafo_depth == 0 || cbf_cr[0]) {\n            cbf_cr[0] = ff_hevc_cbf_cb_cr_decode(s, trafo_depth);\n            if (s->ps.sps->chroma_format_idc == 2 && (!split_transform_flag || log2_trafo_size == 3)) {\n                cbf_cr[1] = ff_hevc_cbf_cb_cr_decode(s, trafo_depth);\n            }\n        }\n    }\n\n    if (split_transform_flag) {\n        const int trafo_size_split = 1 << (log2_trafo_size - 1);\n        const int x1 = x0 + trafo_size_split;\n        const int y1 = y0 + trafo_size_split;\n\n#define SUBDIVIDE(x, y, idx)                                                    \\\ndo {                                                                            \\\n    ret = hls_transform_tree(s, x, y, x0, y0, cb_xBase, cb_yBase, log2_cb_size, \\\n                             log2_trafo_size - 1, trafo_depth + 1, idx,         \\\n                             cbf_cb, cbf_cr);                                   \\\n    if (ret < 0)                                                                \\\n        return ret;                                                             \\\n} while (0)\n\n        SUBDIVIDE(x0, y0, 0);\n        SUBDIVIDE(x1, y0, 1);\n        SUBDIVIDE(x0, y1, 2);\n        SUBDIVIDE(x1, y1, 3);\n\n#undef SUBDIVIDE\n    } else {\n        int min_tu_size      = 1 << s->ps.sps->log2_min_tb_size;\n        int log2_min_tu_size = s->ps.sps->log2_min_tb_size;\n        int min_tu_width     = s->ps.sps->min_tb_width;\n        int cbf_luma         = 1;\n\n        if (lc->cu.pred_mode == MODE_INTRA || trafo_depth != 0 ||\n            cbf_cb[0] || cbf_cr[0] ||\n            (s->ps.sps->chroma_format_idc == 2 && (cbf_cb[1] || cbf_cr[1]))) {\n            cbf_luma = ff_hevc_cbf_luma_decode(s, trafo_depth);\n        }\n\n        ret = hls_transform_unit(s, x0, y0, xBase, yBase, cb_xBase, cb_yBase,\n                                 log2_cb_size, log2_trafo_size,\n                                 blk_idx, cbf_luma, cbf_cb, cbf_cr);\n        if (ret < 0)\n            return ret;\n        // TODO: store cbf_luma somewhere else\n        if (cbf_luma) {\n            int i, j;\n            for (i = 0; i < (1 << log2_trafo_size); i += min_tu_size)\n                for (j = 0; j < (1 << log2_trafo_size); j += min_tu_size) {\n                    int x_tu = (x0 + j) >> log2_min_tu_size;\n                    int y_tu = (y0 + i) >> log2_min_tu_size;\n                    s->cbf_luma[y_tu * min_tu_width + x_tu] = 1;\n                }\n        }\n        if (!s->sh.disable_deblocking_filter_flag) {\n            ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_trafo_size);\n            if (s->ps.pps->transquant_bypass_enable_flag &&\n                lc->cu.cu_transquant_bypass_flag)\n                set_deblocking_bypass(s, x0, y0, log2_trafo_size);\n        }\n    }\n    return 0;\n}\n\nstatic int hls_pcm_sample(HEVCContext *s, int x0, int y0, int log2_cb_size)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    GetBitContext gb;\n    int cb_size   = 1 << log2_cb_size;\n    ptrdiff_t stride0 = s->frame->linesize[0];\n    ptrdiff_t stride1 = s->frame->linesize[1];\n    ptrdiff_t stride2 = s->frame->linesize[2];\n    uint8_t *dst0 = &s->frame->data[0][y0 * stride0 + (x0 << s->ps.sps->pixel_shift)];\n    uint8_t *dst1 = &s->frame->data[1][(y0 >> s->ps.sps->vshift[1]) * stride1 + ((x0 >> s->ps.sps->hshift[1]) << s->ps.sps->pixel_shift)];\n    uint8_t *dst2 = &s->frame->data[2][(y0 >> s->ps.sps->vshift[2]) * stride2 + ((x0 >> s->ps.sps->hshift[2]) << s->ps.sps->pixel_shift)];\n\n    int length         = cb_size * cb_size * s->ps.sps->pcm.bit_depth +\n                         (((cb_size >> s->ps.sps->hshift[1]) * (cb_size >> s->ps.sps->vshift[1])) +\n                          ((cb_size >> s->ps.sps->hshift[2]) * (cb_size >> s->ps.sps->vshift[2]))) *\n                          s->ps.sps->pcm.bit_depth_chroma;\n    const uint8_t *pcm = skip_bytes(&lc->cc, (length + 7) >> 3);\n    int ret;\n\n    if (!s->sh.disable_deblocking_filter_flag)\n        ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_cb_size);\n\n    ret = init_get_bits(&gb, pcm, length);\n    if (ret < 0)\n        return ret;\n\n    s->hevcdsp.put_pcm(dst0, stride0, cb_size, cb_size,     &gb, s->ps.sps->pcm.bit_depth);\n    if (s->ps.sps->chroma_format_idc) {\n        s->hevcdsp.put_pcm(dst1, stride1,\n                           cb_size >> s->ps.sps->hshift[1],\n                           cb_size >> s->ps.sps->vshift[1],\n                           &gb, s->ps.sps->pcm.bit_depth_chroma);\n        s->hevcdsp.put_pcm(dst2, stride2,\n                           cb_size >> s->ps.sps->hshift[2],\n                           cb_size >> s->ps.sps->vshift[2],\n                           &gb, s->ps.sps->pcm.bit_depth_chroma);\n    }\n\n    return 0;\n}\n\n/**\n * 8.5.3.2.2.1 Luma sample unidirectional interpolation process\n *\n * @param s HEVC decoding context\n * @param dst target buffer for block data at block position\n * @param dststride stride of the dst buffer\n * @param ref reference picture buffer at origin (0, 0)\n * @param mv motion vector (relative to block position) to get pixel data from\n * @param x_off horizontal position of block from origin (0, 0)\n * @param y_off vertical position of block from origin (0, 0)\n * @param block_w width of block\n * @param block_h height of block\n * @param luma_weight weighting factor applied to the luma prediction\n * @param luma_offset additive offset applied to the luma prediction value\n */\n\nstatic void luma_mc_uni(HEVCContext *s, uint8_t *dst, ptrdiff_t dststride,\n                        AVFrame *ref, const Mv *mv, int x_off, int y_off,\n                        int block_w, int block_h, int luma_weight, int luma_offset)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    uint8_t *src         = ref->data[0];\n    ptrdiff_t srcstride  = ref->linesize[0];\n    int pic_width        = s->ps.sps->width;\n    int pic_height       = s->ps.sps->height;\n    int mx               = mv->x & 3;\n    int my               = mv->y & 3;\n    int weight_flag      = (s->sh.slice_type == HEVC_SLICE_P && s->ps.pps->weighted_pred_flag) ||\n                           (s->sh.slice_type == HEVC_SLICE_B && s->ps.pps->weighted_bipred_flag);\n    int idx              = ff_hevc_pel_weight[block_w];\n\n    x_off += mv->x >> 2;\n    y_off += mv->y >> 2;\n    src   += y_off * srcstride + (x_off * (1 << s->ps.sps->pixel_shift));\n\n    if (x_off < QPEL_EXTRA_BEFORE || y_off < QPEL_EXTRA_AFTER ||\n        x_off >= pic_width - block_w - QPEL_EXTRA_AFTER ||\n        y_off >= pic_height - block_h - QPEL_EXTRA_AFTER) {\n        const ptrdiff_t edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset     = QPEL_EXTRA_BEFORE * srcstride       + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n        int buf_offset = QPEL_EXTRA_BEFORE * edge_emu_stride + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer, src - offset,\n                                 edge_emu_stride, srcstride,\n                                 block_w + QPEL_EXTRA,\n                                 block_h + QPEL_EXTRA,\n                                 x_off - QPEL_EXTRA_BEFORE, y_off - QPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n        src = lc->edge_emu_buffer + buf_offset;\n        srcstride = edge_emu_stride;\n    }\n\n    if (!weight_flag)\n        s->hevcdsp.put_hevc_qpel_uni[idx][!!my][!!mx](dst, dststride, src, srcstride,\n                                                      block_h, mx, my, block_w);\n    else\n        s->hevcdsp.put_hevc_qpel_uni_w[idx][!!my][!!mx](dst, dststride, src, srcstride,\n                                                        block_h, s->sh.luma_log2_weight_denom,\n                                                        luma_weight, luma_offset, mx, my, block_w);\n}\n\n/**\n * 8.5.3.2.2.1 Luma sample bidirectional interpolation process\n *\n * @param s HEVC decoding context\n * @param dst target buffer for block data at block position\n * @param dststride stride of the dst buffer\n * @param ref0 reference picture0 buffer at origin (0, 0)\n * @param mv0 motion vector0 (relative to block position) to get pixel data from\n * @param x_off horizontal position of block from origin (0, 0)\n * @param y_off vertical position of block from origin (0, 0)\n * @param block_w width of block\n * @param block_h height of block\n * @param ref1 reference picture1 buffer at origin (0, 0)\n * @param mv1 motion vector1 (relative to block position) to get pixel data from\n * @param current_mv current motion vector structure\n */\n static void luma_mc_bi(HEVCContext *s, uint8_t *dst, ptrdiff_t dststride,\n                       AVFrame *ref0, const Mv *mv0, int x_off, int y_off,\n                       int block_w, int block_h, AVFrame *ref1, const Mv *mv1, struct MvField *current_mv)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    ptrdiff_t src0stride  = ref0->linesize[0];\n    ptrdiff_t src1stride  = ref1->linesize[0];\n    int pic_width        = s->ps.sps->width;\n    int pic_height       = s->ps.sps->height;\n    int mx0              = mv0->x & 3;\n    int my0              = mv0->y & 3;\n    int mx1              = mv1->x & 3;\n    int my1              = mv1->y & 3;\n    int weight_flag      = (s->sh.slice_type == HEVC_SLICE_P && s->ps.pps->weighted_pred_flag) ||\n                           (s->sh.slice_type == HEVC_SLICE_B && s->ps.pps->weighted_bipred_flag);\n    int x_off0           = x_off + (mv0->x >> 2);\n    int y_off0           = y_off + (mv0->y >> 2);\n    int x_off1           = x_off + (mv1->x >> 2);\n    int y_off1           = y_off + (mv1->y >> 2);\n    int idx              = ff_hevc_pel_weight[block_w];\n\n    uint8_t *src0  = ref0->data[0] + y_off0 * src0stride + (int)((unsigned)x_off0 << s->ps.sps->pixel_shift);\n    uint8_t *src1  = ref1->data[0] + y_off1 * src1stride + (int)((unsigned)x_off1 << s->ps.sps->pixel_shift);\n\n    if (x_off0 < QPEL_EXTRA_BEFORE || y_off0 < QPEL_EXTRA_AFTER ||\n        x_off0 >= pic_width - block_w - QPEL_EXTRA_AFTER ||\n        y_off0 >= pic_height - block_h - QPEL_EXTRA_AFTER) {\n        const ptrdiff_t edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset     = QPEL_EXTRA_BEFORE * src0stride       + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n        int buf_offset = QPEL_EXTRA_BEFORE * edge_emu_stride + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer, src0 - offset,\n                                 edge_emu_stride, src0stride,\n                                 block_w + QPEL_EXTRA,\n                                 block_h + QPEL_EXTRA,\n                                 x_off0 - QPEL_EXTRA_BEFORE, y_off0 - QPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n        src0 = lc->edge_emu_buffer + buf_offset;\n        src0stride = edge_emu_stride;\n    }\n\n    if (x_off1 < QPEL_EXTRA_BEFORE || y_off1 < QPEL_EXTRA_AFTER ||\n        x_off1 >= pic_width - block_w - QPEL_EXTRA_AFTER ||\n        y_off1 >= pic_height - block_h - QPEL_EXTRA_AFTER) {\n        const ptrdiff_t edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset     = QPEL_EXTRA_BEFORE * src1stride       + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n        int buf_offset = QPEL_EXTRA_BEFORE * edge_emu_stride + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer2, src1 - offset,\n                                 edge_emu_stride, src1stride,\n                                 block_w + QPEL_EXTRA,\n                                 block_h + QPEL_EXTRA,\n                                 x_off1 - QPEL_EXTRA_BEFORE, y_off1 - QPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n        src1 = lc->edge_emu_buffer2 + buf_offset;\n        src1stride = edge_emu_stride;\n    }\n\n    s->hevcdsp.put_hevc_qpel[idx][!!my0][!!mx0](lc->tmp, src0, src0stride,\n                                                block_h, mx0, my0, block_w);\n    if (!weight_flag)\n        s->hevcdsp.put_hevc_qpel_bi[idx][!!my1][!!mx1](dst, dststride, src1, src1stride, lc->tmp,\n                                                       block_h, mx1, my1, block_w);\n    else\n        s->hevcdsp.put_hevc_qpel_bi_w[idx][!!my1][!!mx1](dst, dststride, src1, src1stride, lc->tmp,\n                                                         block_h, s->sh.luma_log2_weight_denom,\n                                                         s->sh.luma_weight_l0[current_mv->ref_idx[0]],\n                                                         s->sh.luma_weight_l1[current_mv->ref_idx[1]],\n                                                         s->sh.luma_offset_l0[current_mv->ref_idx[0]],\n                                                         s->sh.luma_offset_l1[current_mv->ref_idx[1]],\n                                                         mx1, my1, block_w);\n\n}\n\n/**\n * 8.5.3.2.2.2 Chroma sample uniprediction interpolation process\n *\n * @param s HEVC decoding context\n * @param dst1 target buffer for block data at block position (U plane)\n * @param dst2 target buffer for block data at block position (V plane)\n * @param dststride stride of the dst1 and dst2 buffers\n * @param ref reference picture buffer at origin (0, 0)\n * @param mv motion vector (relative to block position) to get pixel data from\n * @param x_off horizontal position of block from origin (0, 0)\n * @param y_off vertical position of block from origin (0, 0)\n * @param block_w width of block\n * @param block_h height of block\n * @param chroma_weight weighting factor applied to the chroma prediction\n * @param chroma_offset additive offset applied to the chroma prediction value\n */\n\nstatic void chroma_mc_uni(HEVCContext *s, uint8_t *dst0,\n                          ptrdiff_t dststride, uint8_t *src0, ptrdiff_t srcstride, int reflist,\n                          int x_off, int y_off, int block_w, int block_h, struct MvField *current_mv, int chroma_weight, int chroma_offset)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    int pic_width        = s->ps.sps->width >> s->ps.sps->hshift[1];\n    int pic_height       = s->ps.sps->height >> s->ps.sps->vshift[1];\n    const Mv *mv         = &current_mv->mv[reflist];\n    int weight_flag      = (s->sh.slice_type == HEVC_SLICE_P && s->ps.pps->weighted_pred_flag) ||\n                           (s->sh.slice_type == HEVC_SLICE_B && s->ps.pps->weighted_bipred_flag);\n    int idx              = ff_hevc_pel_weight[block_w];\n    int hshift           = s->ps.sps->hshift[1];\n    int vshift           = s->ps.sps->vshift[1];\n    intptr_t mx          = av_mod_uintp2(mv->x, 2 + hshift);\n    intptr_t my          = av_mod_uintp2(mv->y, 2 + vshift);\n    intptr_t _mx         = mx << (1 - hshift);\n    intptr_t _my         = my << (1 - vshift);\n\n    x_off += mv->x >> (2 + hshift);\n    y_off += mv->y >> (2 + vshift);\n    src0  += y_off * srcstride + (x_off * (1 << s->ps.sps->pixel_shift));\n\n    if (x_off < EPEL_EXTRA_BEFORE || y_off < EPEL_EXTRA_AFTER ||\n        x_off >= pic_width - block_w - EPEL_EXTRA_AFTER ||\n        y_off >= pic_height - block_h - EPEL_EXTRA_AFTER) {\n        const int edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset0 = EPEL_EXTRA_BEFORE * (srcstride + (1 << s->ps.sps->pixel_shift));\n        int buf_offset0 = EPEL_EXTRA_BEFORE *\n                          (edge_emu_stride + (1 << s->ps.sps->pixel_shift));\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer, src0 - offset0,\n                                 edge_emu_stride, srcstride,\n                                 block_w + EPEL_EXTRA, block_h + EPEL_EXTRA,\n                                 x_off - EPEL_EXTRA_BEFORE,\n                                 y_off - EPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n\n        src0 = lc->edge_emu_buffer + buf_offset0;\n        srcstride = edge_emu_stride;\n    }\n    if (!weight_flag)\n        s->hevcdsp.put_hevc_epel_uni[idx][!!my][!!mx](dst0, dststride, src0, srcstride,\n                                                  block_h, _mx, _my, block_w);\n    else\n        s->hevcdsp.put_hevc_epel_uni_w[idx][!!my][!!mx](dst0, dststride, src0, srcstride,\n                                                        block_h, s->sh.chroma_log2_weight_denom,\n                                                        chroma_weight, chroma_offset, _mx, _my, block_w);\n}\n\n/**\n * 8.5.3.2.2.2 Chroma sample bidirectional interpolation process\n *\n * @param s HEVC decoding context\n * @param dst target buffer for block data at block position\n * @param dststride stride of the dst buffer\n * @param ref0 reference picture0 buffer at origin (0, 0)\n * @param mv0 motion vector0 (relative to block position) to get pixel data from\n * @param x_off horizontal position of block from origin (0, 0)\n * @param y_off vertical position of block from origin (0, 0)\n * @param block_w width of block\n * @param block_h height of block\n * @param ref1 reference picture1 buffer at origin (0, 0)\n * @param mv1 motion vector1 (relative to block position) to get pixel data from\n * @param current_mv current motion vector structure\n * @param cidx chroma component(cb, cr)\n */\nstatic void chroma_mc_bi(HEVCContext *s, uint8_t *dst0, ptrdiff_t dststride, AVFrame *ref0, AVFrame *ref1,\n                         int x_off, int y_off, int block_w, int block_h, struct MvField *current_mv, int cidx)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    uint8_t *src1        = ref0->data[cidx+1];\n    uint8_t *src2        = ref1->data[cidx+1];\n    ptrdiff_t src1stride = ref0->linesize[cidx+1];\n    ptrdiff_t src2stride = ref1->linesize[cidx+1];\n    int weight_flag      = (s->sh.slice_type == HEVC_SLICE_P && s->ps.pps->weighted_pred_flag) ||\n                           (s->sh.slice_type == HEVC_SLICE_B && s->ps.pps->weighted_bipred_flag);\n    int pic_width        = s->ps.sps->width >> s->ps.sps->hshift[1];\n    int pic_height       = s->ps.sps->height >> s->ps.sps->vshift[1];\n    Mv *mv0              = &current_mv->mv[0];\n    Mv *mv1              = &current_mv->mv[1];\n    int hshift = s->ps.sps->hshift[1];\n    int vshift = s->ps.sps->vshift[1];\n\n    intptr_t mx0 = av_mod_uintp2(mv0->x, 2 + hshift);\n    intptr_t my0 = av_mod_uintp2(mv0->y, 2 + vshift);\n    intptr_t mx1 = av_mod_uintp2(mv1->x, 2 + hshift);\n    intptr_t my1 = av_mod_uintp2(mv1->y, 2 + vshift);\n    intptr_t _mx0 = mx0 << (1 - hshift);\n    intptr_t _my0 = my0 << (1 - vshift);\n    intptr_t _mx1 = mx1 << (1 - hshift);\n    intptr_t _my1 = my1 << (1 - vshift);\n\n    int x_off0 = x_off + (mv0->x >> (2 + hshift));\n    int y_off0 = y_off + (mv0->y >> (2 + vshift));\n    int x_off1 = x_off + (mv1->x >> (2 + hshift));\n    int y_off1 = y_off + (mv1->y >> (2 + vshift));\n    int idx = ff_hevc_pel_weight[block_w];\n    src1  += y_off0 * src1stride + (int)((unsigned)x_off0 << s->ps.sps->pixel_shift);\n    src2  += y_off1 * src2stride + (int)((unsigned)x_off1 << s->ps.sps->pixel_shift);\n\n    if (x_off0 < EPEL_EXTRA_BEFORE || y_off0 < EPEL_EXTRA_AFTER ||\n        x_off0 >= pic_width - block_w - EPEL_EXTRA_AFTER ||\n        y_off0 >= pic_height - block_h - EPEL_EXTRA_AFTER) {\n        const int edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset1 = EPEL_EXTRA_BEFORE * (src1stride + (1 << s->ps.sps->pixel_shift));\n        int buf_offset1 = EPEL_EXTRA_BEFORE *\n                          (edge_emu_stride + (1 << s->ps.sps->pixel_shift));\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer, src1 - offset1,\n                                 edge_emu_stride, src1stride,\n                                 block_w + EPEL_EXTRA, block_h + EPEL_EXTRA,\n                                 x_off0 - EPEL_EXTRA_BEFORE,\n                                 y_off0 - EPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n\n        src1 = lc->edge_emu_buffer + buf_offset1;\n        src1stride = edge_emu_stride;\n    }\n\n    if (x_off1 < EPEL_EXTRA_BEFORE || y_off1 < EPEL_EXTRA_AFTER ||\n        x_off1 >= pic_width - block_w - EPEL_EXTRA_AFTER ||\n        y_off1 >= pic_height - block_h - EPEL_EXTRA_AFTER) {\n        const int edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset1 = EPEL_EXTRA_BEFORE * (src2stride + (1 << s->ps.sps->pixel_shift));\n        int buf_offset1 = EPEL_EXTRA_BEFORE *\n                          (edge_emu_stride + (1 << s->ps.sps->pixel_shift));\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer2, src2 - offset1,\n                                 edge_emu_stride, src2stride,\n                                 block_w + EPEL_EXTRA, block_h + EPEL_EXTRA,\n                                 x_off1 - EPEL_EXTRA_BEFORE,\n                                 y_off1 - EPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n\n        src2 = lc->edge_emu_buffer2 + buf_offset1;\n        src2stride = edge_emu_stride;\n    }\n\n    s->hevcdsp.put_hevc_epel[idx][!!my0][!!mx0](lc->tmp, src1, src1stride,\n                                                block_h, _mx0, _my0, block_w);\n    if (!weight_flag)\n        s->hevcdsp.put_hevc_epel_bi[idx][!!my1][!!mx1](dst0, s->frame->linesize[cidx+1],\n                                                       src2, src2stride, lc->tmp,\n                                                       block_h, _mx1, _my1, block_w);\n    else\n        s->hevcdsp.put_hevc_epel_bi_w[idx][!!my1][!!mx1](dst0, s->frame->linesize[cidx+1],\n                                                         src2, src2stride, lc->tmp,\n                                                         block_h,\n                                                         s->sh.chroma_log2_weight_denom,\n                                                         s->sh.chroma_weight_l0[current_mv->ref_idx[0]][cidx],\n                                                         s->sh.chroma_weight_l1[current_mv->ref_idx[1]][cidx],\n                                                         s->sh.chroma_offset_l0[current_mv->ref_idx[0]][cidx],\n                                                         s->sh.chroma_offset_l1[current_mv->ref_idx[1]][cidx],\n                                                         _mx1, _my1, block_w);\n}\n\nstatic void hevc_await_progress(HEVCContext *s, HEVCFrame *ref,\n                                const Mv *mv, int y0, int height)\n{\n    if (s->threads_type == FF_THREAD_FRAME ) {\n        int y = FFMAX(0, (mv->y >> 2) + y0 + height + 9);\n\n        ff_thread_await_progress(&ref->tf, y, 0);\n    }\n}\n\nstatic void hevc_luma_mv_mvp_mode(HEVCContext *s, int x0, int y0, int nPbW,\n                                  int nPbH, int log2_cb_size, int part_idx,\n                                  int merge_idx, MvField *mv)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    enum InterPredIdc inter_pred_idc = PRED_L0;\n    int mvp_flag;\n\n    ff_hevc_set_neighbour_available(s, x0, y0, nPbW, nPbH);\n    mv->pred_flag = 0;\n    if (s->sh.slice_type == HEVC_SLICE_B)\n        inter_pred_idc = ff_hevc_inter_pred_idc_decode(s, nPbW, nPbH);\n\n    if (inter_pred_idc != PRED_L1) {\n        if (s->sh.nb_refs[L0])\n            mv->ref_idx[0]= ff_hevc_ref_idx_lx_decode(s, s->sh.nb_refs[L0]);\n\n        mv->pred_flag = PF_L0;\n        ff_hevc_hls_mvd_coding(s, x0, y0, 0);\n        mvp_flag = ff_hevc_mvp_lx_flag_decode(s);\n        ff_hevc_luma_mv_mvp_mode(s, x0, y0, nPbW, nPbH, log2_cb_size,\n                                 part_idx, merge_idx, mv, mvp_flag, 0);\n        mv->mv[0].x += lc->pu.mvd.x;\n        mv->mv[0].y += lc->pu.mvd.y;\n    }\n\n    if (inter_pred_idc != PRED_L0) {\n        if (s->sh.nb_refs[L1])\n            mv->ref_idx[1]= ff_hevc_ref_idx_lx_decode(s, s->sh.nb_refs[L1]);\n\n        if (s->sh.mvd_l1_zero_flag == 1 && inter_pred_idc == PRED_BI) {\n            AV_ZERO32(&lc->pu.mvd);\n        } else {\n            ff_hevc_hls_mvd_coding(s, x0, y0, 1);\n        }\n\n        mv->pred_flag += PF_L1;\n        mvp_flag = ff_hevc_mvp_lx_flag_decode(s);\n        ff_hevc_luma_mv_mvp_mode(s, x0, y0, nPbW, nPbH, log2_cb_size,\n                                 part_idx, merge_idx, mv, mvp_flag, 1);\n        mv->mv[1].x += lc->pu.mvd.x;\n        mv->mv[1].y += lc->pu.mvd.y;\n    }\n}\n\nstatic void hls_prediction_unit(HEVCContext *s, int x0, int y0,\n                                int nPbW, int nPbH,\n                                int log2_cb_size, int partIdx, int idx)\n{\n#define POS(c_idx, x, y)                                                              \\\n    &s->frame->data[c_idx][((y) >> s->ps.sps->vshift[c_idx]) * s->frame->linesize[c_idx] + \\\n                           (((x) >> s->ps.sps->hshift[c_idx]) << s->ps.sps->pixel_shift)]\n    HEVCLocalContext *lc = s->HEVClc;\n    int merge_idx = 0;\n    struct MvField current_mv = {{{ 0 }}};\n\n    int min_pu_width = s->ps.sps->min_pu_width;\n\n    MvField *tab_mvf = s->ref->tab_mvf;\n    RefPicList  *refPicList = s->ref->refPicList;\n    HEVCFrame *ref0 = NULL, *ref1 = NULL;\n    uint8_t *dst0 = POS(0, x0, y0);\n    uint8_t *dst1 = POS(1, x0, y0);\n    uint8_t *dst2 = POS(2, x0, y0);\n    int log2_min_cb_size = s->ps.sps->log2_min_cb_size;\n    int min_cb_width     = s->ps.sps->min_cb_width;\n    int x_cb             = x0 >> log2_min_cb_size;\n    int y_cb             = y0 >> log2_min_cb_size;\n    int x_pu, y_pu;\n    int i, j;\n\n    int skip_flag = SAMPLE_CTB(s->skip_flag, x_cb, y_cb);\n\n    if (!skip_flag)\n        lc->pu.merge_flag = ff_hevc_merge_flag_decode(s);\n\n    if (skip_flag || lc->pu.merge_flag) {\n        if (s->sh.max_num_merge_cand > 1)\n            merge_idx = ff_hevc_merge_idx_decode(s);\n        else\n            merge_idx = 0;\n\n        ff_hevc_luma_mv_merge_mode(s, x0, y0, nPbW, nPbH, log2_cb_size,\n                                   partIdx, merge_idx, &current_mv);\n    } else {\n        hevc_luma_mv_mvp_mode(s, x0, y0, nPbW, nPbH, log2_cb_size,\n                              partIdx, merge_idx, &current_mv);\n    }\n\n    x_pu = x0 >> s->ps.sps->log2_min_pu_size;\n    y_pu = y0 >> s->ps.sps->log2_min_pu_size;\n\n    for (j = 0; j < nPbH >> s->ps.sps->log2_min_pu_size; j++)\n        for (i = 0; i < nPbW >> s->ps.sps->log2_min_pu_size; i++)\n            tab_mvf[(y_pu + j) * min_pu_width + x_pu + i] = current_mv;\n\n    if (current_mv.pred_flag & PF_L0) {\n        ref0 = refPicList[0].ref[current_mv.ref_idx[0]];\n        if (!ref0)\n            return;\n        hevc_await_progress(s, ref0, &current_mv.mv[0], y0, nPbH);\n    }\n    if (current_mv.pred_flag & PF_L1) {\n        ref1 = refPicList[1].ref[current_mv.ref_idx[1]];\n        if (!ref1)\n            return;\n        hevc_await_progress(s, ref1, &current_mv.mv[1], y0, nPbH);\n    }\n\n    if (current_mv.pred_flag == PF_L0) {\n        int x0_c = x0 >> s->ps.sps->hshift[1];\n        int y0_c = y0 >> s->ps.sps->vshift[1];\n        int nPbW_c = nPbW >> s->ps.sps->hshift[1];\n        int nPbH_c = nPbH >> s->ps.sps->vshift[1];\n\n        luma_mc_uni(s, dst0, s->frame->linesize[0], ref0->frame,\n                    &current_mv.mv[0], x0, y0, nPbW, nPbH,\n                    s->sh.luma_weight_l0[current_mv.ref_idx[0]],\n                    s->sh.luma_offset_l0[current_mv.ref_idx[0]]);\n\n        if (s->ps.sps->chroma_format_idc) {\n            chroma_mc_uni(s, dst1, s->frame->linesize[1], ref0->frame->data[1], ref0->frame->linesize[1],\n                          0, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n                          s->sh.chroma_weight_l0[current_mv.ref_idx[0]][0], s->sh.chroma_offset_l0[current_mv.ref_idx[0]][0]);\n            chroma_mc_uni(s, dst2, s->frame->linesize[2], ref0->frame->data[2], ref0->frame->linesize[2],\n                          0, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n                          s->sh.chroma_weight_l0[current_mv.ref_idx[0]][1], s->sh.chroma_offset_l0[current_mv.ref_idx[0]][1]);\n        }\n    } else if (current_mv.pred_flag == PF_L1) {\n        int x0_c = x0 >> s->ps.sps->hshift[1];\n        int y0_c = y0 >> s->ps.sps->vshift[1];\n        int nPbW_c = nPbW >> s->ps.sps->hshift[1];\n        int nPbH_c = nPbH >> s->ps.sps->vshift[1];\n\n        luma_mc_uni(s, dst0, s->frame->linesize[0], ref1->frame,\n                    &current_mv.mv[1], x0, y0, nPbW, nPbH,\n                    s->sh.luma_weight_l1[current_mv.ref_idx[1]],\n                    s->sh.luma_offset_l1[current_mv.ref_idx[1]]);\n\n        if (s->ps.sps->chroma_format_idc) {\n            chroma_mc_uni(s, dst1, s->frame->linesize[1], ref1->frame->data[1], ref1->frame->linesize[1],\n                          1, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n                          s->sh.chroma_weight_l1[current_mv.ref_idx[1]][0], s->sh.chroma_offset_l1[current_mv.ref_idx[1]][0]);\n\n            chroma_mc_uni(s, dst2, s->frame->linesize[2], ref1->frame->data[2], ref1->frame->linesize[2],\n                          1, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n                          s->sh.chroma_weight_l1[current_mv.ref_idx[1]][1], s->sh.chroma_offset_l1[current_mv.ref_idx[1]][1]);\n        }\n    } else if (current_mv.pred_flag == PF_BI) {\n        int x0_c = x0 >> s->ps.sps->hshift[1];\n        int y0_c = y0 >> s->ps.sps->vshift[1];\n        int nPbW_c = nPbW >> s->ps.sps->hshift[1];\n        int nPbH_c = nPbH >> s->ps.sps->vshift[1];\n\n        luma_mc_bi(s, dst0, s->frame->linesize[0], ref0->frame,\n                   &current_mv.mv[0], x0, y0, nPbW, nPbH,\n                   ref1->frame, &current_mv.mv[1], &current_mv);\n\n        if (s->ps.sps->chroma_format_idc) {\n            chroma_mc_bi(s, dst1, s->frame->linesize[1], ref0->frame, ref1->frame,\n                         x0_c, y0_c, nPbW_c, nPbH_c, &current_mv, 0);\n\n            chroma_mc_bi(s, dst2, s->frame->linesize[2], ref0->frame, ref1->frame,\n                         x0_c, y0_c, nPbW_c, nPbH_c, &current_mv, 1);\n        }\n    }\n}\n\n/**\n * 8.4.1\n */\nstatic int luma_intra_pred_mode(HEVCContext *s, int x0, int y0, int pu_size,\n                                int prev_intra_luma_pred_flag)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    int x_pu             = x0 >> s->ps.sps->log2_min_pu_size;\n    int y_pu             = y0 >> s->ps.sps->log2_min_pu_size;\n    int min_pu_width     = s->ps.sps->min_pu_width;\n    int size_in_pus      = pu_size >> s->ps.sps->log2_min_pu_size;\n    int x0b              = av_mod_uintp2(x0, s->ps.sps->log2_ctb_size);\n    int y0b              = av_mod_uintp2(y0, s->ps.sps->log2_ctb_size);\n\n    int cand_up   = (lc->ctb_up_flag || y0b) ?\n                    s->tab_ipm[(y_pu - 1) * min_pu_width + x_pu] : INTRA_DC;\n    int cand_left = (lc->ctb_left_flag || x0b) ?\n                    s->tab_ipm[y_pu * min_pu_width + x_pu - 1]   : INTRA_DC;\n\n    int y_ctb = (y0 >> (s->ps.sps->log2_ctb_size)) << (s->ps.sps->log2_ctb_size);\n\n    MvField *tab_mvf = s->ref->tab_mvf;\n    int intra_pred_mode;\n    int candidate[3];\n    int i, j;\n\n    // intra_pred_mode prediction does not cross vertical CTB boundaries\n    if ((y0 - 1) < y_ctb)\n        cand_up = INTRA_DC;\n\n    if (cand_left == cand_up) {\n        if (cand_left < 2) {\n            candidate[0] = INTRA_PLANAR;\n            candidate[1] = INTRA_DC;\n            candidate[2] = INTRA_ANGULAR_26;\n        } else {\n            candidate[0] = cand_left;\n            candidate[1] = 2 + ((cand_left - 2 - 1 + 32) & 31);\n            candidate[2] = 2 + ((cand_left - 2 + 1) & 31);\n        }\n    } else {\n        candidate[0] = cand_left;\n        candidate[1] = cand_up;\n        if (candidate[0] != INTRA_PLANAR && candidate[1] != INTRA_PLANAR) {\n            candidate[2] = INTRA_PLANAR;\n        } else if (candidate[0] != INTRA_DC && candidate[1] != INTRA_DC) {\n            candidate[2] = INTRA_DC;\n        } else {\n            candidate[2] = INTRA_ANGULAR_26;\n        }\n    }\n\n    if (prev_intra_luma_pred_flag) {\n        intra_pred_mode = candidate[lc->pu.mpm_idx];\n    } else {\n        if (candidate[0] > candidate[1])\n            FFSWAP(uint8_t, candidate[0], candidate[1]);\n        if (candidate[0] > candidate[2])\n            FFSWAP(uint8_t, candidate[0], candidate[2]);\n        if (candidate[1] > candidate[2])\n            FFSWAP(uint8_t, candidate[1], candidate[2]);\n\n        intra_pred_mode = lc->pu.rem_intra_luma_pred_mode;\n        for (i = 0; i < 3; i++)\n            if (intra_pred_mode >= candidate[i])\n                intra_pred_mode++;\n    }\n\n    /* write the intra prediction units into the mv array */\n    if (!size_in_pus)\n        size_in_pus = 1;\n    for (i = 0; i < size_in_pus; i++) {\n        memset(&s->tab_ipm[(y_pu + i) * min_pu_width + x_pu],\n               intra_pred_mode, size_in_pus);\n\n        for (j = 0; j < size_in_pus; j++) {\n            tab_mvf[(y_pu + j) * min_pu_width + x_pu + i].pred_flag = PF_INTRA;\n        }\n    }\n\n    return intra_pred_mode;\n}\n\nstatic av_always_inline void set_ct_depth(HEVCContext *s, int x0, int y0,\n                                          int log2_cb_size, int ct_depth)\n{\n    int length = (1 << log2_cb_size) >> s->ps.sps->log2_min_cb_size;\n    int x_cb   = x0 >> s->ps.sps->log2_min_cb_size;\n    int y_cb   = y0 >> s->ps.sps->log2_min_cb_size;\n    int y;\n\n    for (y = 0; y < length; y++)\n        memset(&s->tab_ct_depth[(y_cb + y) * s->ps.sps->min_cb_width + x_cb],\n               ct_depth, length);\n}\n\nstatic const uint8_t tab_mode_idx[] = {\n     0,  1,  2,  2,  2,  2,  3,  5,  7,  8, 10, 12, 13, 15, 17, 18, 19, 20,\n    21, 22, 23, 23, 24, 24, 25, 25, 26, 27, 27, 28, 28, 29, 29, 30, 31};\n\nstatic void intra_prediction_unit(HEVCContext *s, int x0, int y0,\n                                  int log2_cb_size)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    static const uint8_t intra_chroma_table[4] = { 0, 26, 10, 1 };\n    uint8_t prev_intra_luma_pred_flag[4];\n    int split   = lc->cu.part_mode == PART_NxN;\n    int pb_size = (1 << log2_cb_size) >> split;\n    int side    = split + 1;\n    int chroma_mode;\n    int i, j;\n\n    for (i = 0; i < side; i++)\n        for (j = 0; j < side; j++)\n            prev_intra_luma_pred_flag[2 * i + j] = ff_hevc_prev_intra_luma_pred_flag_decode(s);\n\n    for (i = 0; i < side; i++) {\n        for (j = 0; j < side; j++) {\n            if (prev_intra_luma_pred_flag[2 * i + j])\n                lc->pu.mpm_idx = ff_hevc_mpm_idx_decode(s);\n            else\n                lc->pu.rem_intra_luma_pred_mode = ff_hevc_rem_intra_luma_pred_mode_decode(s);\n\n            lc->pu.intra_pred_mode[2 * i + j] =\n                luma_intra_pred_mode(s, x0 + pb_size * j, y0 + pb_size * i, pb_size,\n                                     prev_intra_luma_pred_flag[2 * i + j]);\n        }\n    }\n\n    if (s->ps.sps->chroma_format_idc == 3) {\n        for (i = 0; i < side; i++) {\n            for (j = 0; j < side; j++) {\n                lc->pu.chroma_mode_c[2 * i + j] = chroma_mode = ff_hevc_intra_chroma_pred_mode_decode(s);\n                if (chroma_mode != 4) {\n                    if (lc->pu.intra_pred_mode[2 * i + j] == intra_chroma_table[chroma_mode])\n                        lc->pu.intra_pred_mode_c[2 * i + j] = 34;\n                    else\n                        lc->pu.intra_pred_mode_c[2 * i + j] = intra_chroma_table[chroma_mode];\n                } else {\n                    lc->pu.intra_pred_mode_c[2 * i + j] = lc->pu.intra_pred_mode[2 * i + j];\n                }\n            }\n        }\n    } else if (s->ps.sps->chroma_format_idc == 2) {\n        int mode_idx;\n        lc->pu.chroma_mode_c[0] = chroma_mode = ff_hevc_intra_chroma_pred_mode_decode(s);\n        if (chroma_mode != 4) {\n            if (lc->pu.intra_pred_mode[0] == intra_chroma_table[chroma_mode])\n                mode_idx = 34;\n            else\n                mode_idx = intra_chroma_table[chroma_mode];\n        } else {\n            mode_idx = lc->pu.intra_pred_mode[0];\n        }\n        lc->pu.intra_pred_mode_c[0] = tab_mode_idx[mode_idx];\n    } else if (s->ps.sps->chroma_format_idc != 0) {\n        chroma_mode = ff_hevc_intra_chroma_pred_mode_decode(s);\n        if (chroma_mode != 4) {\n            if (lc->pu.intra_pred_mode[0] == intra_chroma_table[chroma_mode])\n                lc->pu.intra_pred_mode_c[0] = 34;\n            else\n                lc->pu.intra_pred_mode_c[0] = intra_chroma_table[chroma_mode];\n        } else {\n            lc->pu.intra_pred_mode_c[0] = lc->pu.intra_pred_mode[0];\n        }\n    }\n}\n\nstatic void intra_prediction_unit_default_value(HEVCContext *s,\n                                                int x0, int y0,\n                                                int log2_cb_size)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    int pb_size          = 1 << log2_cb_size;\n    int size_in_pus      = pb_size >> s->ps.sps->log2_min_pu_size;\n    int min_pu_width     = s->ps.sps->min_pu_width;\n    MvField *tab_mvf     = s->ref->tab_mvf;\n    int x_pu             = x0 >> s->ps.sps->log2_min_pu_size;\n    int y_pu             = y0 >> s->ps.sps->log2_min_pu_size;\n    int j, k;\n\n    if (size_in_pus == 0)\n        size_in_pus = 1;\n    for (j = 0; j < size_in_pus; j++)\n        memset(&s->tab_ipm[(y_pu + j) * min_pu_width + x_pu], INTRA_DC, size_in_pus);\n    if (lc->cu.pred_mode == MODE_INTRA)\n        for (j = 0; j < size_in_pus; j++)\n            for (k = 0; k < size_in_pus; k++)\n                tab_mvf[(y_pu + j) * min_pu_width + x_pu + k].pred_flag = PF_INTRA;\n}\n\nstatic int hls_coding_unit(HEVCContext *s, int x0, int y0, int log2_cb_size)\n{\n    int cb_size          = 1 << log2_cb_size;\n    HEVCLocalContext *lc = s->HEVClc;\n    int log2_min_cb_size = s->ps.sps->log2_min_cb_size;\n    int length           = cb_size >> log2_min_cb_size;\n    int min_cb_width     = s->ps.sps->min_cb_width;\n    int x_cb             = x0 >> log2_min_cb_size;\n    int y_cb             = y0 >> log2_min_cb_size;\n    int idx              = log2_cb_size - 2;\n    int qp_block_mask    = (1<<(s->ps.sps->log2_ctb_size - s->ps.pps->diff_cu_qp_delta_depth)) - 1;\n    int x, y, ret;\n\n    lc->cu.x                = x0;\n    lc->cu.y                = y0;\n    lc->cu.pred_mode        = MODE_INTRA;\n    lc->cu.part_mode        = PART_2Nx2N;\n    lc->cu.intra_split_flag = 0;\n\n    SAMPLE_CTB(s->skip_flag, x_cb, y_cb) = 0;\n    for (x = 0; x < 4; x++)\n        lc->pu.intra_pred_mode[x] = 1;\n    if (s->ps.pps->transquant_bypass_enable_flag) {\n        lc->cu.cu_transquant_bypass_flag = ff_hevc_cu_transquant_bypass_flag_decode(s);\n        if (lc->cu.cu_transquant_bypass_flag)\n            set_deblocking_bypass(s, x0, y0, log2_cb_size);\n    } else\n        lc->cu.cu_transquant_bypass_flag = 0;\n\n    if (s->sh.slice_type != HEVC_SLICE_I) {\n        uint8_t skip_flag = ff_hevc_skip_flag_decode(s, x0, y0, x_cb, y_cb);\n\n        x = y_cb * min_cb_width + x_cb;\n        for (y = 0; y < length; y++) {\n            memset(&s->skip_flag[x], skip_flag, length);\n            x += min_cb_width;\n        }\n        lc->cu.pred_mode = skip_flag ? MODE_SKIP : MODE_INTER;\n    } else {\n        x = y_cb * min_cb_width + x_cb;\n        for (y = 0; y < length; y++) {\n            memset(&s->skip_flag[x], 0, length);\n            x += min_cb_width;\n        }\n    }\n\n    if (SAMPLE_CTB(s->skip_flag, x_cb, y_cb)) {\n        hls_prediction_unit(s, x0, y0, cb_size, cb_size, log2_cb_size, 0, idx);\n        intra_prediction_unit_default_value(s, x0, y0, log2_cb_size);\n\n        if (!s->sh.disable_deblocking_filter_flag)\n            ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_cb_size);\n    } else {\n        int pcm_flag = 0;\n\n        if (s->sh.slice_type != HEVC_SLICE_I)\n            lc->cu.pred_mode = ff_hevc_pred_mode_decode(s);\n        if (lc->cu.pred_mode != MODE_INTRA ||\n            log2_cb_size == s->ps.sps->log2_min_cb_size) {\n            lc->cu.part_mode        = ff_hevc_part_mode_decode(s, log2_cb_size);\n            lc->cu.intra_split_flag = lc->cu.part_mode == PART_NxN &&\n                                      lc->cu.pred_mode == MODE_INTRA;\n        }\n\n        if (lc->cu.pred_mode == MODE_INTRA) {\n            if (lc->cu.part_mode == PART_2Nx2N && s->ps.sps->pcm_enabled_flag &&\n                log2_cb_size >= s->ps.sps->pcm.log2_min_pcm_cb_size &&\n                log2_cb_size <= s->ps.sps->pcm.log2_max_pcm_cb_size) {\n                pcm_flag = ff_hevc_pcm_flag_decode(s);\n            }\n            if (pcm_flag) {\n                intra_prediction_unit_default_value(s, x0, y0, log2_cb_size);\n                ret = hls_pcm_sample(s, x0, y0, log2_cb_size);\n                if (s->ps.sps->pcm.loop_filter_disable_flag)\n                    set_deblocking_bypass(s, x0, y0, log2_cb_size);\n\n                if (ret < 0)\n                    return ret;\n            } else {\n                intra_prediction_unit(s, x0, y0, log2_cb_size);\n            }\n        } else {\n            intra_prediction_unit_default_value(s, x0, y0, log2_cb_size);\n            switch (lc->cu.part_mode) {\n            case PART_2Nx2N:\n                hls_prediction_unit(s, x0, y0, cb_size, cb_size, log2_cb_size, 0, idx);\n                break;\n            case PART_2NxN:\n                hls_prediction_unit(s, x0, y0,               cb_size, cb_size / 2, log2_cb_size, 0, idx);\n                hls_prediction_unit(s, x0, y0 + cb_size / 2, cb_size, cb_size / 2, log2_cb_size, 1, idx);\n                break;\n            case PART_Nx2N:\n                hls_prediction_unit(s, x0,               y0, cb_size / 2, cb_size, log2_cb_size, 0, idx - 1);\n                hls_prediction_unit(s, x0 + cb_size / 2, y0, cb_size / 2, cb_size, log2_cb_size, 1, idx - 1);\n                break;\n            case PART_2NxnU:\n                hls_prediction_unit(s, x0, y0,               cb_size, cb_size     / 4, log2_cb_size, 0, idx);\n                hls_prediction_unit(s, x0, y0 + cb_size / 4, cb_size, cb_size * 3 / 4, log2_cb_size, 1, idx);\n                break;\n            case PART_2NxnD:\n                hls_prediction_unit(s, x0, y0,                   cb_size, cb_size * 3 / 4, log2_cb_size, 0, idx);\n                hls_prediction_unit(s, x0, y0 + cb_size * 3 / 4, cb_size, cb_size     / 4, log2_cb_size, 1, idx);\n                break;\n            case PART_nLx2N:\n                hls_prediction_unit(s, x0,               y0, cb_size     / 4, cb_size, log2_cb_size, 0, idx - 2);\n                hls_prediction_unit(s, x0 + cb_size / 4, y0, cb_size * 3 / 4, cb_size, log2_cb_size, 1, idx - 2);\n                break;\n            case PART_nRx2N:\n                hls_prediction_unit(s, x0,                   y0, cb_size * 3 / 4, cb_size, log2_cb_size, 0, idx - 2);\n                hls_prediction_unit(s, x0 + cb_size * 3 / 4, y0, cb_size     / 4, cb_size, log2_cb_size, 1, idx - 2);\n                break;\n            case PART_NxN:\n                hls_prediction_unit(s, x0,               y0,               cb_size / 2, cb_size / 2, log2_cb_size, 0, idx - 1);\n                hls_prediction_unit(s, x0 + cb_size / 2, y0,               cb_size / 2, cb_size / 2, log2_cb_size, 1, idx - 1);\n                hls_prediction_unit(s, x0,               y0 + cb_size / 2, cb_size / 2, cb_size / 2, log2_cb_size, 2, idx - 1);\n                hls_prediction_unit(s, x0 + cb_size / 2, y0 + cb_size / 2, cb_size / 2, cb_size / 2, log2_cb_size, 3, idx - 1);\n                break;\n            }\n        }\n\n        if (!pcm_flag) {\n            int rqt_root_cbf = 1;\n\n            if (lc->cu.pred_mode != MODE_INTRA &&\n                !(lc->cu.part_mode == PART_2Nx2N && lc->pu.merge_flag)) {\n                rqt_root_cbf = ff_hevc_no_residual_syntax_flag_decode(s);\n            }\n            if (rqt_root_cbf) {\n                const static int cbf[2] = { 0 };\n                lc->cu.max_trafo_depth = lc->cu.pred_mode == MODE_INTRA ?\n                                         s->ps.sps->max_transform_hierarchy_depth_intra + lc->cu.intra_split_flag :\n                                         s->ps.sps->max_transform_hierarchy_depth_inter;\n                ret = hls_transform_tree(s, x0, y0, x0, y0, x0, y0,\n                                         log2_cb_size,\n                                         log2_cb_size, 0, 0, cbf, cbf);\n                if (ret < 0)\n                    return ret;\n            } else {\n                if (!s->sh.disable_deblocking_filter_flag)\n                    ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_cb_size);\n            }\n        }\n    }\n\n    if (s->ps.pps->cu_qp_delta_enabled_flag && lc->tu.is_cu_qp_delta_coded == 0)\n        ff_hevc_set_qPy(s, x0, y0, log2_cb_size);\n\n    x = y_cb * min_cb_width + x_cb;\n    for (y = 0; y < length; y++) {\n        memset(&s->qp_y_tab[x], lc->qp_y, length);\n        x += min_cb_width;\n    }\n\n    if(((x0 + (1<<log2_cb_size)) & qp_block_mask) == 0 &&\n       ((y0 + (1<<log2_cb_size)) & qp_block_mask) == 0) {\n        lc->qPy_pred = lc->qp_y;\n    }\n\n    set_ct_depth(s, x0, y0, log2_cb_size, lc->ct_depth);\n\n    return 0;\n}\n\nstatic int hls_coding_quadtree(HEVCContext *s, int x0, int y0,\n                               int log2_cb_size, int cb_depth)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    const int cb_size    = 1 << log2_cb_size;\n    int ret;\n    int split_cu;\n\n    lc->ct_depth = cb_depth;\n    if (x0 + cb_size <= s->ps.sps->width  &&\n        y0 + cb_size <= s->ps.sps->height &&\n        log2_cb_size > s->ps.sps->log2_min_cb_size) {\n        split_cu = ff_hevc_split_coding_unit_flag_decode(s, cb_depth, x0, y0);\n    } else {\n        split_cu = (log2_cb_size > s->ps.sps->log2_min_cb_size);\n    }\n    if (s->ps.pps->cu_qp_delta_enabled_flag &&\n        log2_cb_size >= s->ps.sps->log2_ctb_size - s->ps.pps->diff_cu_qp_delta_depth) {\n        lc->tu.is_cu_qp_delta_coded = 0;\n        lc->tu.cu_qp_delta          = 0;\n    }\n\n    if (s->sh.cu_chroma_qp_offset_enabled_flag &&\n        log2_cb_size >= s->ps.sps->log2_ctb_size - s->ps.pps->diff_cu_chroma_qp_offset_depth) {\n        lc->tu.is_cu_chroma_qp_offset_coded = 0;\n    }\n\n    if (split_cu) {\n        int qp_block_mask = (1<<(s->ps.sps->log2_ctb_size - s->ps.pps->diff_cu_qp_delta_depth)) - 1;\n        const int cb_size_split = cb_size >> 1;\n        const int x1 = x0 + cb_size_split;\n        const int y1 = y0 + cb_size_split;\n\n        int more_data = 0;\n\n        more_data = hls_coding_quadtree(s, x0, y0, log2_cb_size - 1, cb_depth + 1);\n        if (more_data < 0)\n            return more_data;\n\n        if (more_data && x1 < s->ps.sps->width) {\n            more_data = hls_coding_quadtree(s, x1, y0, log2_cb_size - 1, cb_depth + 1);\n            if (more_data < 0)\n                return more_data;\n        }\n        if (more_data && y1 < s->ps.sps->height) {\n            more_data = hls_coding_quadtree(s, x0, y1, log2_cb_size - 1, cb_depth + 1);\n            if (more_data < 0)\n                return more_data;\n        }\n        if (more_data && x1 < s->ps.sps->width &&\n            y1 < s->ps.sps->height) {\n            more_data = hls_coding_quadtree(s, x1, y1, log2_cb_size - 1, cb_depth + 1);\n            if (more_data < 0)\n                return more_data;\n        }\n\n        if(((x0 + (1<<log2_cb_size)) & qp_block_mask) == 0 &&\n            ((y0 + (1<<log2_cb_size)) & qp_block_mask) == 0)\n            lc->qPy_pred = lc->qp_y;\n\n        if (more_data)\n            return ((x1 + cb_size_split) < s->ps.sps->width ||\n                    (y1 + cb_size_split) < s->ps.sps->height);\n        else\n            return 0;\n    } else {\n        ret = hls_coding_unit(s, x0, y0, log2_cb_size);\n        if (ret < 0)\n            return ret;\n        if ((!((x0 + cb_size) %\n               (1 << (s->ps.sps->log2_ctb_size))) ||\n             (x0 + cb_size >= s->ps.sps->width)) &&\n            (!((y0 + cb_size) %\n               (1 << (s->ps.sps->log2_ctb_size))) ||\n             (y0 + cb_size >= s->ps.sps->height))) {\n            int end_of_slice_flag = ff_hevc_end_of_slice_flag_decode(s);\n            return !end_of_slice_flag;\n        } else {\n            return 1;\n        }\n    }\n\n    return 0;\n}\n\nstatic void hls_decode_neighbour(HEVCContext *s, int x_ctb, int y_ctb,\n                                 int ctb_addr_ts)\n{\n    HEVCLocalContext *lc  = s->HEVClc;\n    int ctb_size          = 1 << s->ps.sps->log2_ctb_size;\n    int ctb_addr_rs       = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts];\n    int ctb_addr_in_slice = ctb_addr_rs - s->sh.slice_addr;\n\n    s->tab_slice_address[ctb_addr_rs] = s->sh.slice_addr;\n\n    if (s->ps.pps->entropy_coding_sync_enabled_flag) {\n        if (x_ctb == 0 && (y_ctb & (ctb_size - 1)) == 0)\n            lc->first_qp_group = 1;\n        lc->end_of_tiles_x = s->ps.sps->width;\n    } else if (s->ps.pps->tiles_enabled_flag) {\n        if (ctb_addr_ts && s->ps.pps->tile_id[ctb_addr_ts] != s->ps.pps->tile_id[ctb_addr_ts - 1]) {\n            int idxX = s->ps.pps->col_idxX[x_ctb >> s->ps.sps->log2_ctb_size];\n            lc->end_of_tiles_x   = x_ctb + (s->ps.pps->column_width[idxX] << s->ps.sps->log2_ctb_size);\n            lc->first_qp_group   = 1;\n        }\n    } else {\n        lc->end_of_tiles_x = s->ps.sps->width;\n    }\n\n    lc->end_of_tiles_y = FFMIN(y_ctb + ctb_size, s->ps.sps->height);\n\n    lc->boundary_flags = 0;\n    if (s->ps.pps->tiles_enabled_flag) {\n        if (x_ctb > 0 && s->ps.pps->tile_id[ctb_addr_ts] != s->ps.pps->tile_id[s->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs - 1]])\n            lc->boundary_flags |= BOUNDARY_LEFT_TILE;\n        if (x_ctb > 0 && s->tab_slice_address[ctb_addr_rs] != s->tab_slice_address[ctb_addr_rs - 1])\n            lc->boundary_flags |= BOUNDARY_LEFT_SLICE;\n        if (y_ctb > 0 && s->ps.pps->tile_id[ctb_addr_ts] != s->ps.pps->tile_id[s->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs - s->ps.sps->ctb_width]])\n            lc->boundary_flags |= BOUNDARY_UPPER_TILE;\n        if (y_ctb > 0 && s->tab_slice_address[ctb_addr_rs] != s->tab_slice_address[ctb_addr_rs - s->ps.sps->ctb_width])\n            lc->boundary_flags |= BOUNDARY_UPPER_SLICE;\n    } else {\n        if (ctb_addr_in_slice <= 0)\n            lc->boundary_flags |= BOUNDARY_LEFT_SLICE;\n        if (ctb_addr_in_slice < s->ps.sps->ctb_width)\n            lc->boundary_flags |= BOUNDARY_UPPER_SLICE;\n    }\n\n    lc->ctb_left_flag = ((x_ctb > 0) && (ctb_addr_in_slice > 0) && !(lc->boundary_flags & BOUNDARY_LEFT_TILE));\n    lc->ctb_up_flag   = ((y_ctb > 0) && (ctb_addr_in_slice >= s->ps.sps->ctb_width) && !(lc->boundary_flags & BOUNDARY_UPPER_TILE));\n    lc->ctb_up_right_flag = ((y_ctb > 0)  && (ctb_addr_in_slice+1 >= s->ps.sps->ctb_width) && (s->ps.pps->tile_id[ctb_addr_ts] == s->ps.pps->tile_id[s->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs+1 - s->ps.sps->ctb_width]]));\n    lc->ctb_up_left_flag = ((x_ctb > 0) && (y_ctb > 0)  && (ctb_addr_in_slice-1 >= s->ps.sps->ctb_width) && (s->ps.pps->tile_id[ctb_addr_ts] == s->ps.pps->tile_id[s->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs-1 - s->ps.sps->ctb_width]]));\n}\n\nstatic int hls_decode_entry(AVCodecContext *avctxt, void *isFilterThread)\n{\n    HEVCContext *s  = avctxt->priv_data;\n    int ctb_size    = 1 << s->ps.sps->log2_ctb_size;\n    int more_data   = 1;\n    int x_ctb       = 0;\n    int y_ctb       = 0;\n    int ctb_addr_ts = s->ps.pps->ctb_addr_rs_to_ts[s->sh.slice_ctb_addr_rs];\n    int ret;\n\n    if (!ctb_addr_ts && s->sh.dependent_slice_segment_flag) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Impossible initial tile.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (s->sh.dependent_slice_segment_flag) {\n        int prev_rs = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts - 1];\n        if (s->tab_slice_address[prev_rs] != s->sh.slice_addr) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Previous slice segment missing\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    while (more_data && ctb_addr_ts < s->ps.sps->ctb_size) {\n        int ctb_addr_rs = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts];\n\n        x_ctb = (ctb_addr_rs % ((s->ps.sps->width + ctb_size - 1) >> s->ps.sps->log2_ctb_size)) << s->ps.sps->log2_ctb_size;\n        y_ctb = (ctb_addr_rs / ((s->ps.sps->width + ctb_size - 1) >> s->ps.sps->log2_ctb_size)) << s->ps.sps->log2_ctb_size;\n        hls_decode_neighbour(s, x_ctb, y_ctb, ctb_addr_ts);\n\n        ret = ff_hevc_cabac_init(s, ctb_addr_ts);\n        if (ret < 0) {\n            s->tab_slice_address[ctb_addr_rs] = -1;\n            return ret;\n        }\n\n        hls_sao_param(s, x_ctb >> s->ps.sps->log2_ctb_size, y_ctb >> s->ps.sps->log2_ctb_size);\n\n        s->deblock[ctb_addr_rs].beta_offset = s->sh.beta_offset;\n        s->deblock[ctb_addr_rs].tc_offset   = s->sh.tc_offset;\n        s->filter_slice_edges[ctb_addr_rs]  = s->sh.slice_loop_filter_across_slices_enabled_flag;\n\n        more_data = hls_coding_quadtree(s, x_ctb, y_ctb, s->ps.sps->log2_ctb_size, 0);\n        if (more_data < 0) {\n            s->tab_slice_address[ctb_addr_rs] = -1;\n            return more_data;\n        }\n\n\n        ctb_addr_ts++;\n        ff_hevc_save_states(s, ctb_addr_ts);\n        ff_hevc_hls_filters(s, x_ctb, y_ctb, ctb_size);\n    }\n\n    if (x_ctb + ctb_size >= s->ps.sps->width &&\n        y_ctb + ctb_size >= s->ps.sps->height)\n        ff_hevc_hls_filter(s, x_ctb, y_ctb, ctb_size);\n\n    return ctb_addr_ts;\n}\n\nstatic int hls_slice_data(HEVCContext *s)\n{\n    int arg[2];\n    int ret[2];\n\n    arg[0] = 0;\n    arg[1] = 1;\n\n    s->avctx->execute(s->avctx, hls_decode_entry, arg, ret , 1, sizeof(int));\n    return ret[0];\n}\nstatic int hls_decode_entry_wpp(AVCodecContext *avctxt, void *input_ctb_row, int job, int self_id)\n{\n    HEVCContext *s1  = avctxt->priv_data, *s;\n    HEVCLocalContext *lc;\n    int ctb_size    = 1<< s1->ps.sps->log2_ctb_size;\n    int more_data   = 1;\n    int *ctb_row_p    = input_ctb_row;\n    int ctb_row = ctb_row_p[job];\n    int ctb_addr_rs = s1->sh.slice_ctb_addr_rs + ctb_row * ((s1->ps.sps->width + ctb_size - 1) >> s1->ps.sps->log2_ctb_size);\n    int ctb_addr_ts = s1->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs];\n    int thread = ctb_row % s1->threads_number;\n    int ret;\n\n    s = s1->sList[self_id];\n    lc = s->HEVClc;\n\n    if(ctb_row) {\n        ret = init_get_bits8(&lc->gb, s->data + s->sh.offset[ctb_row - 1], s->sh.size[ctb_row - 1]);\n        if (ret < 0)\n            goto error;\n        ff_init_cabac_decoder(&lc->cc, s->data + s->sh.offset[(ctb_row)-1], s->sh.size[ctb_row - 1]);\n    }\n\n    while(more_data && ctb_addr_ts < s->ps.sps->ctb_size) {\n        int x_ctb = (ctb_addr_rs % s->ps.sps->ctb_width) << s->ps.sps->log2_ctb_size;\n        int y_ctb = (ctb_addr_rs / s->ps.sps->ctb_width) << s->ps.sps->log2_ctb_size;\n\n        hls_decode_neighbour(s, x_ctb, y_ctb, ctb_addr_ts);\n\n        ff_thread_await_progress2(s->avctx, ctb_row, thread, SHIFT_CTB_WPP);\n\n        if (atomic_load(&s1->wpp_err)) {\n            ff_thread_report_progress2(s->avctx, ctb_row , thread, SHIFT_CTB_WPP);\n            return 0;\n        }\n\n        ret = ff_hevc_cabac_init(s, ctb_addr_ts);\n        if (ret < 0)\n            goto error;\n        hls_sao_param(s, x_ctb >> s->ps.sps->log2_ctb_size, y_ctb >> s->ps.sps->log2_ctb_size);\n        more_data = hls_coding_quadtree(s, x_ctb, y_ctb, s->ps.sps->log2_ctb_size, 0);\n\n        if (more_data < 0) {\n            ret = more_data;\n            goto error;\n        }\n\n        ctb_addr_ts++;\n\n        ff_hevc_save_states(s, ctb_addr_ts);\n        ff_thread_report_progress2(s->avctx, ctb_row, thread, 1);\n        ff_hevc_hls_filters(s, x_ctb, y_ctb, ctb_size);\n\n        if (!more_data && (x_ctb+ctb_size) < s->ps.sps->width && ctb_row != s->sh.num_entry_point_offsets) {\n            atomic_store(&s1->wpp_err, 1);\n            ff_thread_report_progress2(s->avctx, ctb_row ,thread, SHIFT_CTB_WPP);\n            return 0;\n        }\n\n        if ((x_ctb+ctb_size) >= s->ps.sps->width && (y_ctb+ctb_size) >= s->ps.sps->height ) {\n            ff_hevc_hls_filter(s, x_ctb, y_ctb, ctb_size);\n            ff_thread_report_progress2(s->avctx, ctb_row , thread, SHIFT_CTB_WPP);\n            return ctb_addr_ts;\n        }\n        ctb_addr_rs       = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts];\n        x_ctb+=ctb_size;\n\n        if(x_ctb >= s->ps.sps->width) {\n            break;\n        }\n    }\n    ff_thread_report_progress2(s->avctx, ctb_row ,thread, SHIFT_CTB_WPP);\n\n    return 0;\nerror:\n    s->tab_slice_address[ctb_addr_rs] = -1;\n    atomic_store(&s1->wpp_err, 1);\n    ff_thread_report_progress2(s->avctx, ctb_row ,thread, SHIFT_CTB_WPP);\n    return ret;\n}\n\nstatic int hls_slice_data_wpp(HEVCContext *s, const H2645NAL *nal)\n{\n    const uint8_t *data = nal->data;\n    int length          = nal->size;\n    HEVCLocalContext *lc = s->HEVClc;\n    int *ret = av_malloc_array(s->sh.num_entry_point_offsets + 1, sizeof(int));\n    int *arg = av_malloc_array(s->sh.num_entry_point_offsets + 1, sizeof(int));\n    int64_t offset;\n    int64_t startheader, cmpt = 0;\n    int i, j, res = 0;\n\n    if (!ret || !arg) {\n        av_free(ret);\n        av_free(arg);\n        return AVERROR(ENOMEM);\n    }\n\n    if (s->sh.slice_ctb_addr_rs + s->sh.num_entry_point_offsets * s->ps.sps->ctb_width >= s->ps.sps->ctb_width * s->ps.sps->ctb_height) {\n        av_log(s->avctx, AV_LOG_ERROR, \"WPP ctb addresses are wrong (%d %d %d %d)\\n\",\n            s->sh.slice_ctb_addr_rs, s->sh.num_entry_point_offsets,\n            s->ps.sps->ctb_width, s->ps.sps->ctb_height\n        );\n        res = AVERROR_INVALIDDATA;\n        goto error;\n    }\n\n    ff_alloc_entries(s->avctx, s->sh.num_entry_point_offsets + 1);\n\n    if (!s->sList[1]) {\n        for (i = 1; i < s->threads_number; i++) {\n            s->sList[i] = av_malloc(sizeof(HEVCContext));\n            memcpy(s->sList[i], s, sizeof(HEVCContext));\n            s->HEVClcList[i] = av_mallocz(sizeof(HEVCLocalContext));\n            s->sList[i]->HEVClc = s->HEVClcList[i];\n        }\n    }\n\n    offset = (lc->gb.index >> 3);\n\n    for (j = 0, cmpt = 0, startheader = offset + s->sh.entry_point_offset[0]; j < nal->skipped_bytes; j++) {\n        if (nal->skipped_bytes_pos[j] >= offset && nal->skipped_bytes_pos[j] < startheader) {\n            startheader--;\n            cmpt++;\n        }\n    }\n\n    for (i = 1; i < s->sh.num_entry_point_offsets; i++) {\n        offset += (s->sh.entry_point_offset[i - 1] - cmpt);\n        for (j = 0, cmpt = 0, startheader = offset\n             + s->sh.entry_point_offset[i]; j < nal->skipped_bytes; j++) {\n            if (nal->skipped_bytes_pos[j] >= offset && nal->skipped_bytes_pos[j] < startheader) {\n                startheader--;\n                cmpt++;\n            }\n        }\n        s->sh.size[i - 1] = s->sh.entry_point_offset[i] - cmpt;\n        s->sh.offset[i - 1] = offset;\n\n    }\n    if (s->sh.num_entry_point_offsets != 0) {\n        offset += s->sh.entry_point_offset[s->sh.num_entry_point_offsets - 1] - cmpt;\n        if (length < offset) {\n            av_log(s->avctx, AV_LOG_ERROR, \"entry_point_offset table is corrupted\\n\");\n            res = AVERROR_INVALIDDATA;\n            goto error;\n        }\n        s->sh.size[s->sh.num_entry_point_offsets - 1] = length - offset;\n        s->sh.offset[s->sh.num_entry_point_offsets - 1] = offset;\n\n    }\n    s->data = data;\n\n    for (i = 1; i < s->threads_number; i++) {\n        s->sList[i]->HEVClc->first_qp_group = 1;\n        s->sList[i]->HEVClc->qp_y = s->sList[0]->HEVClc->qp_y;\n        memcpy(s->sList[i], s, sizeof(HEVCContext));\n        s->sList[i]->HEVClc = s->HEVClcList[i];\n    }\n\n    atomic_store(&s->wpp_err, 0);\n    ff_reset_entries(s->avctx);\n\n    for (i = 0; i <= s->sh.num_entry_point_offsets; i++) {\n        arg[i] = i;\n        ret[i] = 0;\n    }\n\n    if (s->ps.pps->entropy_coding_sync_enabled_flag)\n        s->avctx->execute2(s->avctx, hls_decode_entry_wpp, arg, ret, s->sh.num_entry_point_offsets + 1);\n\n    for (i = 0; i <= s->sh.num_entry_point_offsets; i++)\n        res += ret[i];\nerror:\n    av_free(ret);\n    av_free(arg);\n    return res;\n}\n\nstatic int set_side_data(HEVCContext *s)\n{\n    AVFrame *out = s->ref->frame;\n\n    if (s->sei.frame_packing.present &&\n        s->sei.frame_packing.arrangement_type >= 3 &&\n        s->sei.frame_packing.arrangement_type <= 5 &&\n        s->sei.frame_packing.content_interpretation_type > 0 &&\n        s->sei.frame_packing.content_interpretation_type < 3) {\n        AVStereo3D *stereo = av_stereo3d_create_side_data(out);\n        if (!stereo)\n            return AVERROR(ENOMEM);\n\n        switch (s->sei.frame_packing.arrangement_type) {\n        case 3:\n            if (s->sei.frame_packing.quincunx_subsampling)\n                stereo->type = AV_STEREO3D_SIDEBYSIDE_QUINCUNX;\n            else\n                stereo->type = AV_STEREO3D_SIDEBYSIDE;\n            break;\n        case 4:\n            stereo->type = AV_STEREO3D_TOPBOTTOM;\n            break;\n        case 5:\n            stereo->type = AV_STEREO3D_FRAMESEQUENCE;\n            break;\n        }\n\n        if (s->sei.frame_packing.content_interpretation_type == 2)\n            stereo->flags = AV_STEREO3D_FLAG_INVERT;\n\n        if (s->sei.frame_packing.arrangement_type == 5) {\n            if (s->sei.frame_packing.current_frame_is_frame0_flag)\n                stereo->view = AV_STEREO3D_VIEW_LEFT;\n            else\n                stereo->view = AV_STEREO3D_VIEW_RIGHT;\n        }\n    }\n\n    if (s->sei.display_orientation.present &&\n        (s->sei.display_orientation.anticlockwise_rotation ||\n         s->sei.display_orientation.hflip || s->sei.display_orientation.vflip)) {\n        double angle = s->sei.display_orientation.anticlockwise_rotation * 360 / (double) (1 << 16);\n        AVFrameSideData *rotation = av_frame_new_side_data(out,\n                                                           AV_FRAME_DATA_DISPLAYMATRIX,\n                                                           sizeof(int32_t) * 9);\n        if (!rotation)\n            return AVERROR(ENOMEM);\n\n        av_display_rotation_set((int32_t *)rotation->data, angle);\n        av_display_matrix_flip((int32_t *)rotation->data,\n                               s->sei.display_orientation.hflip,\n                               s->sei.display_orientation.vflip);\n    }\n\n    // Decrement the mastering display flag when IRAP frame has no_rasl_output_flag=1\n    // so the side data persists for the entire coded video sequence.\n    if (s->sei.mastering_display.present > 0 &&\n        IS_IRAP(s) && s->no_rasl_output_flag) {\n        s->sei.mastering_display.present--;\n    }\n    if (s->sei.mastering_display.present) {\n        // HEVC uses a g,b,r ordering, which we convert to a more natural r,g,b\n        const int mapping[3] = {2, 0, 1};\n        const int chroma_den = 50000;\n        const int luma_den = 10000;\n        int i;\n        AVMasteringDisplayMetadata *metadata =\n            av_mastering_display_metadata_create_side_data(out);\n        if (!metadata)\n            return AVERROR(ENOMEM);\n\n        for (i = 0; i < 3; i++) {\n            const int j = mapping[i];\n            metadata->display_primaries[i][0].num = s->sei.mastering_display.display_primaries[j][0];\n            metadata->display_primaries[i][0].den = chroma_den;\n            metadata->display_primaries[i][1].num = s->sei.mastering_display.display_primaries[j][1];\n            metadata->display_primaries[i][1].den = chroma_den;\n        }\n        metadata->white_point[0].num = s->sei.mastering_display.white_point[0];\n        metadata->white_point[0].den = chroma_den;\n        metadata->white_point[1].num = s->sei.mastering_display.white_point[1];\n        metadata->white_point[1].den = chroma_den;\n\n        metadata->max_luminance.num = s->sei.mastering_display.max_luminance;\n        metadata->max_luminance.den = luma_den;\n        metadata->min_luminance.num = s->sei.mastering_display.min_luminance;\n        metadata->min_luminance.den = luma_den;\n        metadata->has_luminance = 1;\n        metadata->has_primaries = 1;\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"Mastering Display Metadata:\\n\");\n        av_log(s->avctx, AV_LOG_DEBUG,\n               \"r(%5.4f,%5.4f) g(%5.4f,%5.4f) b(%5.4f %5.4f) wp(%5.4f, %5.4f)\\n\",\n               av_q2d(metadata->display_primaries[0][0]),\n               av_q2d(metadata->display_primaries[0][1]),\n               av_q2d(metadata->display_primaries[1][0]),\n               av_q2d(metadata->display_primaries[1][1]),\n               av_q2d(metadata->display_primaries[2][0]),\n               av_q2d(metadata->display_primaries[2][1]),\n               av_q2d(metadata->white_point[0]), av_q2d(metadata->white_point[1]));\n        av_log(s->avctx, AV_LOG_DEBUG,\n               \"min_luminance=%f, max_luminance=%f\\n\",\n               av_q2d(metadata->min_luminance), av_q2d(metadata->max_luminance));\n    }\n    // Decrement the mastering display flag when IRAP frame has no_rasl_output_flag=1\n    // so the side data persists for the entire coded video sequence.\n    if (s->sei.content_light.present > 0 &&\n        IS_IRAP(s) && s->no_rasl_output_flag) {\n        s->sei.content_light.present--;\n    }\n    if (s->sei.content_light.present) {\n        AVContentLightMetadata *metadata =\n            av_content_light_metadata_create_side_data(out);\n        if (!metadata)\n            return AVERROR(ENOMEM);\n        metadata->MaxCLL  = s->sei.content_light.max_content_light_level;\n        metadata->MaxFALL = s->sei.content_light.max_pic_average_light_level;\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"Content Light Level Metadata:\\n\");\n        av_log(s->avctx, AV_LOG_DEBUG, \"MaxCLL=%d, MaxFALL=%d\\n\",\n               metadata->MaxCLL, metadata->MaxFALL);\n    }\n\n    if (s->sei.a53_caption.a53_caption) {\n        AVFrameSideData* sd = av_frame_new_side_data(out,\n                                                     AV_FRAME_DATA_A53_CC,\n                                                     s->sei.a53_caption.a53_caption_size);\n        if (sd)\n            memcpy(sd->data, s->sei.a53_caption.a53_caption, s->sei.a53_caption.a53_caption_size);\n        av_freep(&s->sei.a53_caption.a53_caption);\n        s->sei.a53_caption.a53_caption_size = 0;\n        s->avctx->properties |= FF_CODEC_PROPERTY_CLOSED_CAPTIONS;\n    }\n\n    if (s->sei.alternative_transfer.present &&\n        av_color_transfer_name(s->sei.alternative_transfer.preferred_transfer_characteristics) &&\n        s->sei.alternative_transfer.preferred_transfer_characteristics != AVCOL_TRC_UNSPECIFIED) {\n        s->avctx->color_trc = out->color_trc = s->sei.alternative_transfer.preferred_transfer_characteristics;\n    }\n\n    return 0;\n}\n\nstatic int hevc_frame_start(HEVCContext *s)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    int pic_size_in_ctb  = ((s->ps.sps->width  >> s->ps.sps->log2_min_cb_size) + 1) *\n                           ((s->ps.sps->height >> s->ps.sps->log2_min_cb_size) + 1);\n    int ret;\n\n    memset(s->horizontal_bs, 0, s->bs_width * s->bs_height);\n    memset(s->vertical_bs,   0, s->bs_width * s->bs_height);\n    memset(s->cbf_luma,      0, s->ps.sps->min_tb_width * s->ps.sps->min_tb_height);\n    memset(s->is_pcm,        0, (s->ps.sps->min_pu_width + 1) * (s->ps.sps->min_pu_height + 1));\n    memset(s->tab_slice_address, -1, pic_size_in_ctb * sizeof(*s->tab_slice_address));\n\n    s->is_decoded        = 0;\n    s->first_nal_type    = s->nal_unit_type;\n\n    s->no_rasl_output_flag = IS_IDR(s) || IS_BLA(s) || (s->nal_unit_type == HEVC_NAL_CRA_NUT && s->last_eos);\n\n    if (s->ps.pps->tiles_enabled_flag)\n        lc->end_of_tiles_x = s->ps.pps->column_width[0] << s->ps.sps->log2_ctb_size;\n\n    ret = ff_hevc_set_new_ref(s, &s->frame, s->poc);\n    if (ret < 0)\n        goto fail;\n\n    ret = ff_hevc_frame_rps(s);\n    if (ret < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Error constructing the frame RPS.\\n\");\n        goto fail;\n    }\n\n    s->ref->frame->key_frame = IS_IRAP(s);\n\n    ret = set_side_data(s);\n    if (ret < 0)\n        goto fail;\n\n    s->frame->pict_type = 3 - s->sh.slice_type;\n\n    if (!IS_IRAP(s))\n        ff_hevc_bump_frame(s);\n\n    av_frame_unref(s->output_frame);\n    ret = ff_hevc_output_frame(s, s->output_frame, 0);\n    if (ret < 0)\n        goto fail;\n\n    if (!s->avctx->hwaccel)\n        ff_thread_finish_setup(s->avctx);\n\n    return 0;\n\nfail:\n    if (s->ref)\n        ff_hevc_unref_frame(s, s->ref, ~0);\n    s->ref = NULL;\n    return ret;\n}\n\nstatic int decode_nal_unit(HEVCContext *s, const H2645NAL *nal)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    GetBitContext *gb    = &lc->gb;\n    int ctb_addr_ts, ret;\n\n    *gb              = nal->gb;\n    s->nal_unit_type = nal->type;\n    s->temporal_id   = nal->temporal_id;\n\n    switch (s->nal_unit_type) {\n    case HEVC_NAL_VPS:\n        if (s->avctx->hwaccel && s->avctx->hwaccel->decode_params) {\n            ret = s->avctx->hwaccel->decode_params(s->avctx,\n                                                   nal->type,\n                                                   nal->raw_data,\n                                                   nal->raw_size);\n            if (ret < 0)\n                goto fail;\n        }\n        ret = ff_hevc_decode_nal_vps(gb, s->avctx, &s->ps);\n        if (ret < 0)\n            goto fail;\n        break;\n    case HEVC_NAL_SPS:\n        if (s->avctx->hwaccel && s->avctx->hwaccel->decode_params) {\n            ret = s->avctx->hwaccel->decode_params(s->avctx,\n                                                   nal->type,\n                                                   nal->raw_data,\n                                                   nal->raw_size);\n            if (ret < 0)\n                goto fail;\n        }\n        ret = ff_hevc_decode_nal_sps(gb, s->avctx, &s->ps,\n                                     s->apply_defdispwin);\n        if (ret < 0)\n            goto fail;\n        break;\n    case HEVC_NAL_PPS:\n        if (s->avctx->hwaccel && s->avctx->hwaccel->decode_params) {\n            ret = s->avctx->hwaccel->decode_params(s->avctx,\n                                                   nal->type,\n                                                   nal->raw_data,\n                                                   nal->raw_size);\n            if (ret < 0)\n                goto fail;\n        }\n        ret = ff_hevc_decode_nal_pps(gb, s->avctx, &s->ps);\n        if (ret < 0)\n            goto fail;\n        break;\n    case HEVC_NAL_SEI_PREFIX:\n    case HEVC_NAL_SEI_SUFFIX:\n        if (s->avctx->hwaccel && s->avctx->hwaccel->decode_params) {\n            ret = s->avctx->hwaccel->decode_params(s->avctx,\n                                                   nal->type,\n                                                   nal->raw_data,\n                                                   nal->raw_size);\n            if (ret < 0)\n                goto fail;\n        }\n        ret = ff_hevc_decode_nal_sei(gb, s->avctx, &s->sei, &s->ps, s->nal_unit_type);\n        if (ret < 0)\n            goto fail;\n        break;\n    case HEVC_NAL_TRAIL_R:\n    case HEVC_NAL_TRAIL_N:\n    case HEVC_NAL_TSA_N:\n    case HEVC_NAL_TSA_R:\n    case HEVC_NAL_STSA_N:\n    case HEVC_NAL_STSA_R:\n    case HEVC_NAL_BLA_W_LP:\n    case HEVC_NAL_BLA_W_RADL:\n    case HEVC_NAL_BLA_N_LP:\n    case HEVC_NAL_IDR_W_RADL:\n    case HEVC_NAL_IDR_N_LP:\n    case HEVC_NAL_CRA_NUT:\n    case HEVC_NAL_RADL_N:\n    case HEVC_NAL_RADL_R:\n    case HEVC_NAL_RASL_N:\n    case HEVC_NAL_RASL_R:\n        ret = hls_slice_header(s);\n        if (ret < 0)\n            return ret;\n\n        if (\n            (s->avctx->skip_frame >= AVDISCARD_BIDIR && s->sh.slice_type == HEVC_SLICE_B) ||\n            (s->avctx->skip_frame >= AVDISCARD_NONINTRA && s->sh.slice_type != HEVC_SLICE_I) ||\n            (s->avctx->skip_frame >= AVDISCARD_NONKEY && !IS_IRAP(s))) {\n            break;\n        }\n\n        if (s->sh.first_slice_in_pic_flag) {\n            if (s->ref) {\n                av_log(s->avctx, AV_LOG_ERROR, \"Two slices reporting being the first in the same frame.\\n\");\n                goto fail;\n            }\n            if (s->max_ra == INT_MAX) {\n                if (s->nal_unit_type == HEVC_NAL_CRA_NUT || IS_BLA(s)) {\n                    s->max_ra = s->poc;\n                } else {\n                    if (IS_IDR(s))\n                        s->max_ra = INT_MIN;\n                }\n            }\n\n            if ((s->nal_unit_type == HEVC_NAL_RASL_R || s->nal_unit_type == HEVC_NAL_RASL_N) &&\n                s->poc <= s->max_ra) {\n                s->is_decoded = 0;\n                break;\n            } else {\n                if (s->nal_unit_type == HEVC_NAL_RASL_R && s->poc > s->max_ra)\n                    s->max_ra = INT_MIN;\n            }\n\n            s->overlap ++;\n            ret = hevc_frame_start(s);\n            if (ret < 0)\n                return ret;\n        } else if (!s->ref) {\n            av_log(s->avctx, AV_LOG_ERROR, \"First slice in a frame missing.\\n\");\n            goto fail;\n        }\n\n        if (s->nal_unit_type != s->first_nal_type) {\n            av_log(s->avctx, AV_LOG_ERROR,\n                   \"Non-matching NAL types of the VCL NALUs: %d %d\\n\",\n                   s->first_nal_type, s->nal_unit_type);\n            return AVERROR_INVALIDDATA;\n        }\n\n        if (!s->sh.dependent_slice_segment_flag &&\n            s->sh.slice_type != HEVC_SLICE_I) {\n            ret = ff_hevc_slice_rpl(s);\n            if (ret < 0) {\n                av_log(s->avctx, AV_LOG_WARNING,\n                       \"Error constructing the reference lists for the current slice.\\n\");\n                goto fail;\n            }\n        }\n\n        if (s->sh.first_slice_in_pic_flag && s->avctx->hwaccel) {\n            ret = s->avctx->hwaccel->start_frame(s->avctx, NULL, 0);\n            if (ret < 0)\n                goto fail;\n        }\n\n        if (s->avctx->hwaccel) {\n            ret = s->avctx->hwaccel->decode_slice(s->avctx, nal->raw_data, nal->raw_size);\n            if (ret < 0)\n                goto fail;\n        } else {\n            if (s->threads_number > 1 && s->sh.num_entry_point_offsets > 0)\n                ctb_addr_ts = hls_slice_data_wpp(s, nal);\n            else\n                ctb_addr_ts = hls_slice_data(s);\n            if (ctb_addr_ts >= (s->ps.sps->ctb_width * s->ps.sps->ctb_height)) {\n                s->is_decoded = 1;\n            }\n\n            if (ctb_addr_ts < 0) {\n                ret = ctb_addr_ts;\n                goto fail;\n            }\n        }\n        break;\n    case HEVC_NAL_EOS_NUT:\n    case HEVC_NAL_EOB_NUT:\n        s->seq_decode = (s->seq_decode + 1) & 0xff;\n        s->max_ra     = INT_MAX;\n        break;\n    case HEVC_NAL_AUD:\n    case HEVC_NAL_FD_NUT:\n        break;\n    default:\n        av_log(s->avctx, AV_LOG_INFO,\n               \"Skipping NAL unit %d\\n\", s->nal_unit_type);\n    }\n\n    return 0;\nfail:\n    if (s->avctx->err_recognition & AV_EF_EXPLODE)\n        return ret;\n    return 0;\n}\n\nstatic int decode_nal_units(HEVCContext *s, const uint8_t *buf, int length)\n{\n    int i, ret = 0;\n    int eos_at_start = 1;\n\n    s->ref = NULL;\n    s->last_eos = s->eos;\n    s->eos = 0;\n    s->overlap = 0;\n\n    /* split the input packet into NAL units, so we know the upper bound on the\n     * number of slices in the frame */\n    ret = ff_h2645_packet_split(&s->pkt, buf, length, s->avctx, s->is_nalff,\n                                s->nal_length_size, s->avctx->codec_id, 1, 0);\n    if (ret < 0) {\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"Error splitting the input into NAL units.\\n\");\n        return ret;\n    }\n\n    for (i = 0; i < s->pkt.nb_nals; i++) {\n        if (s->pkt.nals[i].type == HEVC_NAL_EOB_NUT ||\n            s->pkt.nals[i].type == HEVC_NAL_EOS_NUT) {\n            if (eos_at_start) {\n                s->last_eos = 1;\n            } else {\n                s->eos = 1;\n            }\n        } else {\n            eos_at_start = 0;\n        }\n    }\n\n    /* decode the NAL units */\n    for (i = 0; i < s->pkt.nb_nals; i++) {\n        H2645NAL *nal = &s->pkt.nals[i];\n\n        if (s->avctx->skip_frame >= AVDISCARD_ALL ||\n            (s->avctx->skip_frame >= AVDISCARD_NONREF\n            && ff_hevc_nal_is_nonref(nal->type)))\n            continue;\n\n        ret = decode_nal_unit(s, nal);\n        if (ret >= 0 && s->overlap > 2)\n            ret = AVERROR_INVALIDDATA;\n        if (ret < 0) {\n            av_log(s->avctx, AV_LOG_WARNING,\n                   \"Error parsing NAL unit #%d.\\n\", i);\n            goto fail;\n        }\n    }\n\nfail:\n    if (s->ref && s->threads_type == FF_THREAD_FRAME)\n        ff_thread_report_progress(&s->ref->tf, INT_MAX, 0);\n\n    return ret;\n}\n\nstatic void print_md5(void *log_ctx, int level, uint8_t md5[16])\n{\n    int i;\n    for (i = 0; i < 16; i++)\n        av_log(log_ctx, level, \"%02\"PRIx8, md5[i]);\n}\n\nstatic int verify_md5(HEVCContext *s, AVFrame *frame)\n{\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frame->format);\n    int pixel_shift;\n    int i, j;\n\n    if (!desc)\n        return AVERROR(EINVAL);\n\n    pixel_shift = desc->comp[0].depth > 8;\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"Verifying checksum for frame with POC %d: \",\n           s->poc);\n\n    /* the checksums are LE, so we have to byteswap for >8bpp formats\n     * on BE arches */\n#if HAVE_BIGENDIAN\n    if (pixel_shift && !s->checksum_buf) {\n        av_fast_malloc(&s->checksum_buf, &s->checksum_buf_size,\n                       FFMAX3(frame->linesize[0], frame->linesize[1],\n                              frame->linesize[2]));\n        if (!s->checksum_buf)\n            return AVERROR(ENOMEM);\n    }\n#endif\n\n    for (i = 0; frame->data[i]; i++) {\n        int width  = s->avctx->coded_width;\n        int height = s->avctx->coded_height;\n        int w = (i == 1 || i == 2) ? (width  >> desc->log2_chroma_w) : width;\n        int h = (i == 1 || i == 2) ? (height >> desc->log2_chroma_h) : height;\n        uint8_t md5[16];\n\n        av_md5_init(s->md5_ctx);\n        for (j = 0; j < h; j++) {\n            const uint8_t *src = frame->data[i] + j * frame->linesize[i];\n#if HAVE_BIGENDIAN\n            if (pixel_shift) {\n                s->bdsp.bswap16_buf((uint16_t *) s->checksum_buf,\n                                    (const uint16_t *) src, w);\n                src = s->checksum_buf;\n            }\n#endif\n            av_md5_update(s->md5_ctx, src, w << pixel_shift);\n        }\n        av_md5_final(s->md5_ctx, md5);\n\n        if (!memcmp(md5, s->sei.picture_hash.md5[i], 16)) {\n            av_log   (s->avctx, AV_LOG_DEBUG, \"plane %d - correct \", i);\n            print_md5(s->avctx, AV_LOG_DEBUG, md5);\n            av_log   (s->avctx, AV_LOG_DEBUG, \"; \");\n        } else {\n            av_log   (s->avctx, AV_LOG_ERROR, \"mismatching checksum of plane %d - \", i);\n            print_md5(s->avctx, AV_LOG_ERROR, md5);\n            av_log   (s->avctx, AV_LOG_ERROR, \" != \");\n            print_md5(s->avctx, AV_LOG_ERROR, s->sei.picture_hash.md5[i]);\n            av_log   (s->avctx, AV_LOG_ERROR, \"\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"\\n\");\n\n    return 0;\n}\n\nstatic int hevc_decode_extradata(HEVCContext *s, uint8_t *buf, int length, int first)\n{\n    int ret, i;\n\n    ret = ff_hevc_decode_extradata(buf, length, &s->ps, &s->sei, &s->is_nalff,\n                                   &s->nal_length_size, s->avctx->err_recognition,\n                                   s->apply_defdispwin, s->avctx);\n    if (ret < 0)\n        return ret;\n\n    /* export stream parameters from the first SPS */\n    for (i = 0; i < FF_ARRAY_ELEMS(s->ps.sps_list); i++) {\n        if (first && s->ps.sps_list[i]) {\n            const HEVCSPS *sps = (const HEVCSPS*)s->ps.sps_list[i]->data;\n            export_stream_params(s->avctx, &s->ps, sps);\n            break;\n        }\n    }\n\n    return 0;\n}\n\nstatic int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,\n                             AVPacket *avpkt)\n{\n    int ret;\n    int new_extradata_size;\n    uint8_t *new_extradata;\n    HEVCContext *s = avctx->priv_data;\n\n    if (!avpkt->size) {\n        ret = ff_hevc_output_frame(s, data, 1);\n        if (ret < 0)\n            return ret;\n\n        *got_output = ret;\n        return 0;\n    }\n\n    new_extradata = av_packet_get_side_data(avpkt, AV_PKT_DATA_NEW_EXTRADATA,\n                                            &new_extradata_size);\n    if (new_extradata && new_extradata_size > 0) {\n        ret = hevc_decode_extradata(s, new_extradata, new_extradata_size, 0);\n        if (ret < 0)\n            return ret;\n    }\n\n    s->ref = NULL;\n    ret    = decode_nal_units(s, avpkt->data, avpkt->size);\n    if (ret < 0)\n        return ret;\n\n    if (avctx->hwaccel) {\n        if (s->ref && (ret = avctx->hwaccel->end_frame(avctx)) < 0) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"hardware accelerator failed to decode picture\\n\");\n            ff_hevc_unref_frame(s, s->ref, ~0);\n            return ret;\n        }\n    } else {\n        /* verify the SEI checksum */\n        if (avctx->err_recognition & AV_EF_CRCCHECK && s->is_decoded &&\n            s->sei.picture_hash.is_md5) {\n            ret = verify_md5(s, s->ref->frame);\n            if (ret < 0 && avctx->err_recognition & AV_EF_EXPLODE) {\n                ff_hevc_unref_frame(s, s->ref, ~0);\n                return ret;\n            }\n        }\n    }\n    s->sei.picture_hash.is_md5 = 0;\n\n    if (s->is_decoded) {\n        av_log(avctx, AV_LOG_DEBUG, \"Decoded frame with POC %d.\\n\", s->poc);\n        s->is_decoded = 0;\n    }\n\n    if (s->output_frame->buf[0]) {\n        av_frame_move_ref(data, s->output_frame);\n        *got_output = 1;\n    }\n\n    return avpkt->size;\n}\n\nstatic int hevc_ref_frame(HEVCContext *s, HEVCFrame *dst, HEVCFrame *src)\n{\n    int ret;\n\n    ret = ff_thread_ref_frame(&dst->tf, &src->tf);\n    if (ret < 0)\n        return ret;\n\n    dst->tab_mvf_buf = av_buffer_ref(src->tab_mvf_buf);\n    if (!dst->tab_mvf_buf)\n        goto fail;\n    dst->tab_mvf = src->tab_mvf;\n\n    dst->rpl_tab_buf = av_buffer_ref(src->rpl_tab_buf);\n    if (!dst->rpl_tab_buf)\n        goto fail;\n    dst->rpl_tab = src->rpl_tab;\n\n    dst->rpl_buf = av_buffer_ref(src->rpl_buf);\n    if (!dst->rpl_buf)\n        goto fail;\n\n    dst->poc        = src->poc;\n    dst->ctb_count  = src->ctb_count;\n    dst->flags      = src->flags;\n    dst->sequence   = src->sequence;\n\n    if (src->hwaccel_picture_private) {\n        dst->hwaccel_priv_buf = av_buffer_ref(src->hwaccel_priv_buf);\n        if (!dst->hwaccel_priv_buf)\n            goto fail;\n        dst->hwaccel_picture_private = dst->hwaccel_priv_buf->data;\n    }\n\n    return 0;\nfail:\n    ff_hevc_unref_frame(s, dst, ~0);\n    return AVERROR(ENOMEM);\n}\n\nstatic av_cold int hevc_decode_free(AVCodecContext *avctx)\n{\n    HEVCContext       *s = avctx->priv_data;\n    int i;\n\n    pic_arrays_free(s);\n\n    av_freep(&s->md5_ctx);\n\n    av_freep(&s->cabac_state);\n\n    for (i = 0; i < 3; i++) {\n        av_freep(&s->sao_pixel_buffer_h[i]);\n        av_freep(&s->sao_pixel_buffer_v[i]);\n    }\n    av_frame_free(&s->output_frame);\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {\n        ff_hevc_unref_frame(s, &s->DPB[i], ~0);\n        av_frame_free(&s->DPB[i].frame);\n    }\n\n    ff_hevc_ps_uninit(&s->ps);\n\n    av_freep(&s->sh.entry_point_offset);\n    av_freep(&s->sh.offset);\n    av_freep(&s->sh.size);\n\n    for (i = 1; i < s->threads_number; i++) {\n        HEVCLocalContext *lc = s->HEVClcList[i];\n        if (lc) {\n            av_freep(&s->HEVClcList[i]);\n            av_freep(&s->sList[i]);\n        }\n    }\n    if (s->HEVClc == s->HEVClcList[0])\n        s->HEVClc = NULL;\n    av_freep(&s->HEVClcList[0]);\n\n    ff_h2645_packet_uninit(&s->pkt);\n\n    return 0;\n}\n\nstatic av_cold int hevc_init_context(AVCodecContext *avctx)\n{\n    HEVCContext *s = avctx->priv_data;\n    int i;\n\n    s->avctx = avctx;\n\n    s->HEVClc = av_mallocz(sizeof(HEVCLocalContext));\n    if (!s->HEVClc)\n        goto fail;\n    s->HEVClcList[0] = s->HEVClc;\n    s->sList[0] = s;\n\n    s->cabac_state = av_malloc(HEVC_CONTEXTS);\n    if (!s->cabac_state)\n        goto fail;\n\n    s->output_frame = av_frame_alloc();\n    if (!s->output_frame)\n        goto fail;\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {\n        s->DPB[i].frame = av_frame_alloc();\n        if (!s->DPB[i].frame)\n            goto fail;\n        s->DPB[i].tf.f = s->DPB[i].frame;\n    }\n\n    s->max_ra = INT_MAX;\n\n    s->md5_ctx = av_md5_alloc();\n    if (!s->md5_ctx)\n        goto fail;\n\n    ff_bswapdsp_init(&s->bdsp);\n\n    s->context_initialized = 1;\n    s->eos = 0;\n\n    ff_hevc_reset_sei(&s->sei);\n\n    return 0;\n\nfail:\n    hevc_decode_free(avctx);\n    return AVERROR(ENOMEM);\n}\n\n#if HAVE_THREADS\nstatic int hevc_update_thread_context(AVCodecContext *dst,\n                                      const AVCodecContext *src)\n{\n    HEVCContext *s  = dst->priv_data;\n    HEVCContext *s0 = src->priv_data;\n    int i, ret;\n\n    if (!s->context_initialized) {\n        ret = hevc_init_context(dst);\n        if (ret < 0)\n            return ret;\n    }\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {\n        ff_hevc_unref_frame(s, &s->DPB[i], ~0);\n        if (s0->DPB[i].frame->buf[0]) {\n            ret = hevc_ref_frame(s, &s->DPB[i], &s0->DPB[i]);\n            if (ret < 0)\n                return ret;\n        }\n    }\n\n    if (s->ps.sps != s0->ps.sps)\n        s->ps.sps = NULL;\n    for (i = 0; i < FF_ARRAY_ELEMS(s->ps.vps_list); i++) {\n        av_buffer_unref(&s->ps.vps_list[i]);\n        if (s0->ps.vps_list[i]) {\n            s->ps.vps_list[i] = av_buffer_ref(s0->ps.vps_list[i]);\n            if (!s->ps.vps_list[i])\n                return AVERROR(ENOMEM);\n        }\n    }\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->ps.sps_list); i++) {\n        av_buffer_unref(&s->ps.sps_list[i]);\n        if (s0->ps.sps_list[i]) {\n            s->ps.sps_list[i] = av_buffer_ref(s0->ps.sps_list[i]);\n            if (!s->ps.sps_list[i])\n                return AVERROR(ENOMEM);\n        }\n    }\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->ps.pps_list); i++) {\n        av_buffer_unref(&s->ps.pps_list[i]);\n        if (s0->ps.pps_list[i]) {\n            s->ps.pps_list[i] = av_buffer_ref(s0->ps.pps_list[i]);\n            if (!s->ps.pps_list[i])\n                return AVERROR(ENOMEM);\n        }\n    }\n\n    if (s->ps.sps != s0->ps.sps)\n        if ((ret = set_sps(s, s0->ps.sps, src->pix_fmt)) < 0)\n            return ret;\n\n    s->seq_decode = s0->seq_decode;\n    s->seq_output = s0->seq_output;\n    s->pocTid0    = s0->pocTid0;\n    s->max_ra     = s0->max_ra;\n    s->eos        = s0->eos;\n    s->no_rasl_output_flag = s0->no_rasl_output_flag;\n\n    s->is_nalff        = s0->is_nalff;\n    s->nal_length_size = s0->nal_length_size;\n\n    s->threads_number      = s0->threads_number;\n    s->threads_type        = s0->threads_type;\n\n    if (s0->eos) {\n        s->seq_decode = (s->seq_decode + 1) & 0xff;\n        s->max_ra = INT_MAX;\n    }\n\n    s->sei.frame_packing        = s0->sei.frame_packing;\n    s->sei.display_orientation  = s0->sei.display_orientation;\n    s->sei.mastering_display    = s0->sei.mastering_display;\n    s->sei.content_light        = s0->sei.content_light;\n    s->sei.alternative_transfer = s0->sei.alternative_transfer;\n\n    return 0;\n}\n#endif\n\nstatic av_cold int hevc_decode_init(AVCodecContext *avctx)\n{\n    HEVCContext *s = avctx->priv_data;\n    int ret;\n\n    avctx->internal->allocate_progress = 1;\n\n    ret = hevc_init_context(avctx);\n    if (ret < 0)\n        return ret;\n\n    s->enable_parallel_tiles = 0;\n    s->sei.picture_timing.picture_struct = 0;\n    s->eos = 1;\n\n    atomic_init(&s->wpp_err, 0);\n\n    if(avctx->active_thread_type & FF_THREAD_SLICE)\n        s->threads_number = avctx->thread_count;\n    else\n        s->threads_number = 1;\n\n    if (avctx->extradata_size > 0 && avctx->extradata) {\n        ret = hevc_decode_extradata(s, avctx->extradata, avctx->extradata_size, 1);\n        if (ret < 0) {\n            hevc_decode_free(avctx);\n            return ret;\n        }\n    }\n\n    if((avctx->active_thread_type & FF_THREAD_FRAME) && avctx->thread_count > 1)\n            s->threads_type = FF_THREAD_FRAME;\n        else\n            s->threads_type = FF_THREAD_SLICE;\n\n    return 0;\n}\n\n#if HAVE_THREADS\nstatic av_cold int hevc_init_thread_copy(AVCodecContext *avctx)\n{\n    HEVCContext *s = avctx->priv_data;\n    int ret;\n\n    memset(s, 0, sizeof(*s));\n\n    ret = hevc_init_context(avctx);\n    if (ret < 0)\n        return ret;\n\n    return 0;\n}\n#endif\n\nstatic void hevc_decode_flush(AVCodecContext *avctx)\n{\n    HEVCContext *s = avctx->priv_data;\n    ff_hevc_flush_dpb(s);\n    s->max_ra = INT_MAX;\n    s->eos = 1;\n}\n\n#define OFFSET(x) offsetof(HEVCContext, x)\n#define PAR (AV_OPT_FLAG_DECODING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)\n\nstatic const AVOption options[] = {\n    { \"apply_defdispwin\", \"Apply default display window from VUI\", OFFSET(apply_defdispwin),\n        AV_OPT_TYPE_BOOL, {.i64 = 0}, 0, 1, PAR },\n    { \"strict-displaywin\", \"stricly apply default display window size\", OFFSET(apply_defdispwin),\n        AV_OPT_TYPE_BOOL, {.i64 = 0}, 0, 1, PAR },\n    { NULL },\n};\n\nstatic const AVClass hevc_decoder_class = {\n    .class_name = \"HEVC decoder\",\n    .item_name  = av_default_item_name,\n    .option     = options,\n    .version    = LIBAVUTIL_VERSION_INT,\n};\n\nAVCodec ff_hevc_decoder = {\n    .name                  = \"hevc\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"HEVC (High Efficiency Video Coding)\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_HEVC,\n    .priv_data_size        = sizeof(HEVCContext),\n    .priv_class            = &hevc_decoder_class,\n    .init                  = hevc_decode_init,\n    .close                 = hevc_decode_free,\n    .decode                = hevc_decode_frame,\n    .flush                 = hevc_decode_flush,\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(hevc_update_thread_context),\n    .init_thread_copy      = ONLY_IF_THREADS_ENABLED(hevc_init_thread_copy),\n    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_DELAY |\n                             AV_CODEC_CAP_SLICE_THREADS | AV_CODEC_CAP_FRAME_THREADS,\n    .caps_internal         = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_EXPORTS_CROPPING,\n    .profiles              = NULL_IF_CONFIG_SMALL(ff_hevc_profiles),\n    .hw_configs            = (const AVCodecHWConfigInternal*[]) {\n#if CONFIG_HEVC_DXVA2_HWACCEL\n                               HWACCEL_DXVA2(hevc),\n#endif\n#if CONFIG_HEVC_D3D11VA_HWACCEL\n                               HWACCEL_D3D11VA(hevc),\n#endif\n#if CONFIG_HEVC_D3D11VA2_HWACCEL\n                               HWACCEL_D3D11VA2(hevc),\n#endif\n#if CONFIG_HEVC_NVDEC_HWACCEL\n                               HWACCEL_NVDEC(hevc),\n#endif\n#if CONFIG_HEVC_VAAPI_HWACCEL\n                               HWACCEL_VAAPI(hevc),\n#endif\n#if CONFIG_HEVC_VDPAU_HWACCEL\n                               HWACCEL_VDPAU(hevc),\n#endif\n#if CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL\n                               HWACCEL_VIDEOTOOLBOX(hevc),\n#endif\n                               NULL\n                           },\n};\n"], "fixing_code": ["/*\n * HEVC video Decoder\n *\n * Copyright (C) 2012 - 2013 Guillaume Martres\n * Copyright (C) 2012 - 2013 Mickael Raulet\n * Copyright (C) 2012 - 2013 Gildas Cocherel\n * Copyright (C) 2012 - 2013 Wassim Hamidouche\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"libavutil/attributes.h\"\n#include \"libavutil/common.h\"\n#include \"libavutil/display.h\"\n#include \"libavutil/internal.h\"\n#include \"libavutil/mastering_display_metadata.h\"\n#include \"libavutil/md5.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/pixdesc.h\"\n#include \"libavutil/stereo3d.h\"\n\n#include \"bswapdsp.h\"\n#include \"bytestream.h\"\n#include \"cabac_functions.h\"\n#include \"golomb.h\"\n#include \"hevc.h\"\n#include \"hevc_data.h\"\n#include \"hevc_parse.h\"\n#include \"hevcdec.h\"\n#include \"hwaccel.h\"\n#include \"profiles.h\"\n\nconst uint8_t ff_hevc_pel_weight[65] = { [2] = 0, [4] = 1, [6] = 2, [8] = 3, [12] = 4, [16] = 5, [24] = 6, [32] = 7, [48] = 8, [64] = 9 };\n\n/**\n * NOTE: Each function hls_foo correspond to the function foo in the\n * specification (HLS stands for High Level Syntax).\n */\n\n/**\n * Section 5.7\n */\n\n/* free everything allocated  by pic_arrays_init() */\nstatic void pic_arrays_free(HEVCContext *s)\n{\n    av_freep(&s->sao);\n    av_freep(&s->deblock);\n\n    av_freep(&s->skip_flag);\n    av_freep(&s->tab_ct_depth);\n\n    av_freep(&s->tab_ipm);\n    av_freep(&s->cbf_luma);\n    av_freep(&s->is_pcm);\n\n    av_freep(&s->qp_y_tab);\n    av_freep(&s->tab_slice_address);\n    av_freep(&s->filter_slice_edges);\n\n    av_freep(&s->horizontal_bs);\n    av_freep(&s->vertical_bs);\n\n    av_freep(&s->sh.entry_point_offset);\n    av_freep(&s->sh.size);\n    av_freep(&s->sh.offset);\n\n    av_buffer_pool_uninit(&s->tab_mvf_pool);\n    av_buffer_pool_uninit(&s->rpl_tab_pool);\n}\n\n/* allocate arrays that depend on frame dimensions */\nstatic int pic_arrays_init(HEVCContext *s, const HEVCSPS *sps)\n{\n    int log2_min_cb_size = sps->log2_min_cb_size;\n    int width            = sps->width;\n    int height           = sps->height;\n    int pic_size_in_ctb  = ((width  >> log2_min_cb_size) + 1) *\n                           ((height >> log2_min_cb_size) + 1);\n    int ctb_count        = sps->ctb_width * sps->ctb_height;\n    int min_pu_size      = sps->min_pu_width * sps->min_pu_height;\n\n    s->bs_width  = (width  >> 2) + 1;\n    s->bs_height = (height >> 2) + 1;\n\n    s->sao           = av_mallocz_array(ctb_count, sizeof(*s->sao));\n    s->deblock       = av_mallocz_array(ctb_count, sizeof(*s->deblock));\n    if (!s->sao || !s->deblock)\n        goto fail;\n\n    s->skip_flag    = av_malloc_array(sps->min_cb_height, sps->min_cb_width);\n    s->tab_ct_depth = av_malloc_array(sps->min_cb_height, sps->min_cb_width);\n    if (!s->skip_flag || !s->tab_ct_depth)\n        goto fail;\n\n    s->cbf_luma = av_malloc_array(sps->min_tb_width, sps->min_tb_height);\n    s->tab_ipm  = av_mallocz(min_pu_size);\n    s->is_pcm   = av_malloc_array(sps->min_pu_width + 1, sps->min_pu_height + 1);\n    if (!s->tab_ipm || !s->cbf_luma || !s->is_pcm)\n        goto fail;\n\n    s->filter_slice_edges = av_mallocz(ctb_count);\n    s->tab_slice_address  = av_malloc_array(pic_size_in_ctb,\n                                      sizeof(*s->tab_slice_address));\n    s->qp_y_tab           = av_malloc_array(pic_size_in_ctb,\n                                      sizeof(*s->qp_y_tab));\n    if (!s->qp_y_tab || !s->filter_slice_edges || !s->tab_slice_address)\n        goto fail;\n\n    s->horizontal_bs = av_mallocz_array(s->bs_width, s->bs_height);\n    s->vertical_bs   = av_mallocz_array(s->bs_width, s->bs_height);\n    if (!s->horizontal_bs || !s->vertical_bs)\n        goto fail;\n\n    s->tab_mvf_pool = av_buffer_pool_init(min_pu_size * sizeof(MvField),\n                                          av_buffer_allocz);\n    s->rpl_tab_pool = av_buffer_pool_init(ctb_count * sizeof(RefPicListTab),\n                                          av_buffer_allocz);\n    if (!s->tab_mvf_pool || !s->rpl_tab_pool)\n        goto fail;\n\n    return 0;\n\nfail:\n    pic_arrays_free(s);\n    return AVERROR(ENOMEM);\n}\n\nstatic int pred_weight_table(HEVCContext *s, GetBitContext *gb)\n{\n    int i = 0;\n    int j = 0;\n    uint8_t luma_weight_l0_flag[16];\n    uint8_t chroma_weight_l0_flag[16];\n    uint8_t luma_weight_l1_flag[16];\n    uint8_t chroma_weight_l1_flag[16];\n    int luma_log2_weight_denom;\n\n    luma_log2_weight_denom = get_ue_golomb_long(gb);\n    if (luma_log2_weight_denom < 0 || luma_log2_weight_denom > 7) {\n        av_log(s->avctx, AV_LOG_ERROR, \"luma_log2_weight_denom %d is invalid\\n\", luma_log2_weight_denom);\n        return AVERROR_INVALIDDATA;\n    }\n    s->sh.luma_log2_weight_denom = av_clip_uintp2(luma_log2_weight_denom, 3);\n    if (s->ps.sps->chroma_format_idc != 0) {\n        int64_t chroma_log2_weight_denom = luma_log2_weight_denom + (int64_t)get_se_golomb(gb);\n        if (chroma_log2_weight_denom < 0 || chroma_log2_weight_denom > 7) {\n            av_log(s->avctx, AV_LOG_ERROR, \"chroma_log2_weight_denom %\"PRId64\" is invalid\\n\", chroma_log2_weight_denom);\n            return AVERROR_INVALIDDATA;\n        }\n        s->sh.chroma_log2_weight_denom = chroma_log2_weight_denom;\n    }\n\n    for (i = 0; i < s->sh.nb_refs[L0]; i++) {\n        luma_weight_l0_flag[i] = get_bits1(gb);\n        if (!luma_weight_l0_flag[i]) {\n            s->sh.luma_weight_l0[i] = 1 << s->sh.luma_log2_weight_denom;\n            s->sh.luma_offset_l0[i] = 0;\n        }\n    }\n    if (s->ps.sps->chroma_format_idc != 0) {\n        for (i = 0; i < s->sh.nb_refs[L0]; i++)\n            chroma_weight_l0_flag[i] = get_bits1(gb);\n    } else {\n        for (i = 0; i < s->sh.nb_refs[L0]; i++)\n            chroma_weight_l0_flag[i] = 0;\n    }\n    for (i = 0; i < s->sh.nb_refs[L0]; i++) {\n        if (luma_weight_l0_flag[i]) {\n            int delta_luma_weight_l0 = get_se_golomb(gb);\n            s->sh.luma_weight_l0[i] = (1 << s->sh.luma_log2_weight_denom) + delta_luma_weight_l0;\n            s->sh.luma_offset_l0[i] = get_se_golomb(gb);\n        }\n        if (chroma_weight_l0_flag[i]) {\n            for (j = 0; j < 2; j++) {\n                int delta_chroma_weight_l0 = get_se_golomb(gb);\n                int delta_chroma_offset_l0 = get_se_golomb(gb);\n\n                if (   (int8_t)delta_chroma_weight_l0 != delta_chroma_weight_l0\n                    || delta_chroma_offset_l0 < -(1<<17) || delta_chroma_offset_l0 > (1<<17)) {\n                    return AVERROR_INVALIDDATA;\n                }\n\n                s->sh.chroma_weight_l0[i][j] = (1 << s->sh.chroma_log2_weight_denom) + delta_chroma_weight_l0;\n                s->sh.chroma_offset_l0[i][j] = av_clip((delta_chroma_offset_l0 - ((128 * s->sh.chroma_weight_l0[i][j])\n                                                                                    >> s->sh.chroma_log2_weight_denom) + 128), -128, 127);\n            }\n        } else {\n            s->sh.chroma_weight_l0[i][0] = 1 << s->sh.chroma_log2_weight_denom;\n            s->sh.chroma_offset_l0[i][0] = 0;\n            s->sh.chroma_weight_l0[i][1] = 1 << s->sh.chroma_log2_weight_denom;\n            s->sh.chroma_offset_l0[i][1] = 0;\n        }\n    }\n    if (s->sh.slice_type == HEVC_SLICE_B) {\n        for (i = 0; i < s->sh.nb_refs[L1]; i++) {\n            luma_weight_l1_flag[i] = get_bits1(gb);\n            if (!luma_weight_l1_flag[i]) {\n                s->sh.luma_weight_l1[i] = 1 << s->sh.luma_log2_weight_denom;\n                s->sh.luma_offset_l1[i] = 0;\n            }\n        }\n        if (s->ps.sps->chroma_format_idc != 0) {\n            for (i = 0; i < s->sh.nb_refs[L1]; i++)\n                chroma_weight_l1_flag[i] = get_bits1(gb);\n        } else {\n            for (i = 0; i < s->sh.nb_refs[L1]; i++)\n                chroma_weight_l1_flag[i] = 0;\n        }\n        for (i = 0; i < s->sh.nb_refs[L1]; i++) {\n            if (luma_weight_l1_flag[i]) {\n                int delta_luma_weight_l1 = get_se_golomb(gb);\n                s->sh.luma_weight_l1[i] = (1 << s->sh.luma_log2_weight_denom) + delta_luma_weight_l1;\n                s->sh.luma_offset_l1[i] = get_se_golomb(gb);\n            }\n            if (chroma_weight_l1_flag[i]) {\n                for (j = 0; j < 2; j++) {\n                    int delta_chroma_weight_l1 = get_se_golomb(gb);\n                    int delta_chroma_offset_l1 = get_se_golomb(gb);\n\n                    if (   (int8_t)delta_chroma_weight_l1 != delta_chroma_weight_l1\n                        || delta_chroma_offset_l1 < -(1<<17) || delta_chroma_offset_l1 > (1<<17)) {\n                        return AVERROR_INVALIDDATA;\n                    }\n\n                    s->sh.chroma_weight_l1[i][j] = (1 << s->sh.chroma_log2_weight_denom) + delta_chroma_weight_l1;\n                    s->sh.chroma_offset_l1[i][j] = av_clip((delta_chroma_offset_l1 - ((128 * s->sh.chroma_weight_l1[i][j])\n                                                                                        >> s->sh.chroma_log2_weight_denom) + 128), -128, 127);\n                }\n            } else {\n                s->sh.chroma_weight_l1[i][0] = 1 << s->sh.chroma_log2_weight_denom;\n                s->sh.chroma_offset_l1[i][0] = 0;\n                s->sh.chroma_weight_l1[i][1] = 1 << s->sh.chroma_log2_weight_denom;\n                s->sh.chroma_offset_l1[i][1] = 0;\n            }\n        }\n    }\n    return 0;\n}\n\nstatic int decode_lt_rps(HEVCContext *s, LongTermRPS *rps, GetBitContext *gb)\n{\n    const HEVCSPS *sps = s->ps.sps;\n    int max_poc_lsb    = 1 << sps->log2_max_poc_lsb;\n    int prev_delta_msb = 0;\n    unsigned int nb_sps = 0, nb_sh;\n    int i;\n\n    rps->nb_refs = 0;\n    if (!sps->long_term_ref_pics_present_flag)\n        return 0;\n\n    if (sps->num_long_term_ref_pics_sps > 0)\n        nb_sps = get_ue_golomb_long(gb);\n    nb_sh = get_ue_golomb_long(gb);\n\n    if (nb_sps > sps->num_long_term_ref_pics_sps)\n        return AVERROR_INVALIDDATA;\n    if (nb_sh + (uint64_t)nb_sps > FF_ARRAY_ELEMS(rps->poc))\n        return AVERROR_INVALIDDATA;\n\n    rps->nb_refs = nb_sh + nb_sps;\n\n    for (i = 0; i < rps->nb_refs; i++) {\n        uint8_t delta_poc_msb_present;\n\n        if (i < nb_sps) {\n            uint8_t lt_idx_sps = 0;\n\n            if (sps->num_long_term_ref_pics_sps > 1)\n                lt_idx_sps = get_bits(gb, av_ceil_log2(sps->num_long_term_ref_pics_sps));\n\n            rps->poc[i]  = sps->lt_ref_pic_poc_lsb_sps[lt_idx_sps];\n            rps->used[i] = sps->used_by_curr_pic_lt_sps_flag[lt_idx_sps];\n        } else {\n            rps->poc[i]  = get_bits(gb, sps->log2_max_poc_lsb);\n            rps->used[i] = get_bits1(gb);\n        }\n\n        delta_poc_msb_present = get_bits1(gb);\n        if (delta_poc_msb_present) {\n            int64_t delta = get_ue_golomb_long(gb);\n            int64_t poc;\n\n            if (i && i != nb_sps)\n                delta += prev_delta_msb;\n\n            poc = rps->poc[i] + s->poc - delta * max_poc_lsb - s->sh.pic_order_cnt_lsb;\n            if (poc != (int32_t)poc)\n                return AVERROR_INVALIDDATA;\n            rps->poc[i] = poc;\n            prev_delta_msb = delta;\n        }\n    }\n\n    return 0;\n}\n\nstatic void export_stream_params(AVCodecContext *avctx, const HEVCParamSets *ps,\n                                 const HEVCSPS *sps)\n{\n    const HEVCVPS *vps = (const HEVCVPS*)ps->vps_list[sps->vps_id]->data;\n    const HEVCWindow *ow = &sps->output_window;\n    unsigned int num = 0, den = 0;\n\n    avctx->pix_fmt             = sps->pix_fmt;\n    avctx->coded_width         = sps->width;\n    avctx->coded_height        = sps->height;\n    avctx->width               = sps->width  - ow->left_offset - ow->right_offset;\n    avctx->height              = sps->height - ow->top_offset  - ow->bottom_offset;\n    avctx->has_b_frames        = sps->temporal_layer[sps->max_sub_layers - 1].num_reorder_pics;\n    avctx->profile             = sps->ptl.general_ptl.profile_idc;\n    avctx->level               = sps->ptl.general_ptl.level_idc;\n\n    ff_set_sar(avctx, sps->vui.sar);\n\n    if (sps->vui.video_signal_type_present_flag)\n        avctx->color_range = sps->vui.video_full_range_flag ? AVCOL_RANGE_JPEG\n                                                            : AVCOL_RANGE_MPEG;\n    else\n        avctx->color_range = AVCOL_RANGE_MPEG;\n\n    if (sps->vui.colour_description_present_flag) {\n        avctx->color_primaries = sps->vui.colour_primaries;\n        avctx->color_trc       = sps->vui.transfer_characteristic;\n        avctx->colorspace      = sps->vui.matrix_coeffs;\n    } else {\n        avctx->color_primaries = AVCOL_PRI_UNSPECIFIED;\n        avctx->color_trc       = AVCOL_TRC_UNSPECIFIED;\n        avctx->colorspace      = AVCOL_SPC_UNSPECIFIED;\n    }\n\n    if (vps->vps_timing_info_present_flag) {\n        num = vps->vps_num_units_in_tick;\n        den = vps->vps_time_scale;\n    } else if (sps->vui.vui_timing_info_present_flag) {\n        num = sps->vui.vui_num_units_in_tick;\n        den = sps->vui.vui_time_scale;\n    }\n\n    if (num != 0 && den != 0)\n        av_reduce(&avctx->framerate.den, &avctx->framerate.num,\n                  num, den, 1 << 30);\n}\n\nstatic enum AVPixelFormat get_format(HEVCContext *s, const HEVCSPS *sps)\n{\n#define HWACCEL_MAX (CONFIG_HEVC_DXVA2_HWACCEL + \\\n                     CONFIG_HEVC_D3D11VA_HWACCEL * 2 + \\\n                     CONFIG_HEVC_NVDEC_HWACCEL + \\\n                     CONFIG_HEVC_VAAPI_HWACCEL + \\\n                     CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL + \\\n                     CONFIG_HEVC_VDPAU_HWACCEL)\n    enum AVPixelFormat pix_fmts[HWACCEL_MAX + 2], *fmt = pix_fmts;\n\n    switch (sps->pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUVJ420P:\n#if CONFIG_HEVC_DXVA2_HWACCEL\n        *fmt++ = AV_PIX_FMT_DXVA2_VLD;\n#endif\n#if CONFIG_HEVC_D3D11VA_HWACCEL\n        *fmt++ = AV_PIX_FMT_D3D11VA_VLD;\n        *fmt++ = AV_PIX_FMT_D3D11;\n#endif\n#if CONFIG_HEVC_VAAPI_HWACCEL\n        *fmt++ = AV_PIX_FMT_VAAPI;\n#endif\n#if CONFIG_HEVC_VDPAU_HWACCEL\n        *fmt++ = AV_PIX_FMT_VDPAU;\n#endif\n#if CONFIG_HEVC_NVDEC_HWACCEL\n        *fmt++ = AV_PIX_FMT_CUDA;\n#endif\n#if CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL\n        *fmt++ = AV_PIX_FMT_VIDEOTOOLBOX;\n#endif\n        break;\n    case AV_PIX_FMT_YUV420P10:\n#if CONFIG_HEVC_DXVA2_HWACCEL\n        *fmt++ = AV_PIX_FMT_DXVA2_VLD;\n#endif\n#if CONFIG_HEVC_D3D11VA_HWACCEL\n        *fmt++ = AV_PIX_FMT_D3D11VA_VLD;\n        *fmt++ = AV_PIX_FMT_D3D11;\n#endif\n#if CONFIG_HEVC_VAAPI_HWACCEL\n        *fmt++ = AV_PIX_FMT_VAAPI;\n#endif\n#if CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL\n        *fmt++ = AV_PIX_FMT_VIDEOTOOLBOX;\n#endif\n#if CONFIG_HEVC_NVDEC_HWACCEL\n        *fmt++ = AV_PIX_FMT_CUDA;\n#endif\n        break;\n    case AV_PIX_FMT_YUV420P12:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_YUV444P10:\n    case AV_PIX_FMT_YUV444P12:\n#if CONFIG_HEVC_NVDEC_HWACCEL\n        *fmt++ = AV_PIX_FMT_CUDA;\n#endif\n        break;\n    }\n\n    *fmt++ = sps->pix_fmt;\n    *fmt = AV_PIX_FMT_NONE;\n\n    return ff_thread_get_format(s->avctx, pix_fmts);\n}\n\nstatic int set_sps(HEVCContext *s, const HEVCSPS *sps,\n                   enum AVPixelFormat pix_fmt)\n{\n    int ret, i;\n\n    pic_arrays_free(s);\n    s->ps.sps = NULL;\n    s->ps.vps = NULL;\n\n    if (!sps)\n        return 0;\n\n    ret = pic_arrays_init(s, sps);\n    if (ret < 0)\n        goto fail;\n\n    export_stream_params(s->avctx, &s->ps, sps);\n\n    s->avctx->pix_fmt = pix_fmt;\n\n    ff_hevc_pred_init(&s->hpc,     sps->bit_depth);\n    ff_hevc_dsp_init (&s->hevcdsp, sps->bit_depth);\n    ff_videodsp_init (&s->vdsp,    sps->bit_depth);\n\n    for (i = 0; i < 3; i++) {\n        av_freep(&s->sao_pixel_buffer_h[i]);\n        av_freep(&s->sao_pixel_buffer_v[i]);\n    }\n\n    if (sps->sao_enabled && !s->avctx->hwaccel) {\n        int c_count = (sps->chroma_format_idc != 0) ? 3 : 1;\n        int c_idx;\n\n        for(c_idx = 0; c_idx < c_count; c_idx++) {\n            int w = sps->width >> sps->hshift[c_idx];\n            int h = sps->height >> sps->vshift[c_idx];\n            s->sao_pixel_buffer_h[c_idx] =\n                av_malloc((w * 2 * sps->ctb_height) <<\n                          sps->pixel_shift);\n            s->sao_pixel_buffer_v[c_idx] =\n                av_malloc((h * 2 * sps->ctb_width) <<\n                          sps->pixel_shift);\n        }\n    }\n\n    s->ps.sps = sps;\n    s->ps.vps = (HEVCVPS*) s->ps.vps_list[s->ps.sps->vps_id]->data;\n\n    return 0;\n\nfail:\n    pic_arrays_free(s);\n    s->ps.sps = NULL;\n    return ret;\n}\n\nstatic int hls_slice_header(HEVCContext *s)\n{\n    GetBitContext *gb = &s->HEVClc->gb;\n    SliceHeader *sh   = &s->sh;\n    int i, ret;\n\n    // Coded parameters\n    sh->first_slice_in_pic_flag = get_bits1(gb);\n    if (s->ref && sh->first_slice_in_pic_flag) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Two slices reporting being the first in the same frame.\\n\");\n        return 1; // This slice will be skiped later, do not corrupt state\n    }\n\n    if ((IS_IDR(s) || IS_BLA(s)) && sh->first_slice_in_pic_flag) {\n        s->seq_decode = (s->seq_decode + 1) & 0xff;\n        s->max_ra     = INT_MAX;\n        if (IS_IDR(s))\n            ff_hevc_clear_refs(s);\n    }\n    sh->no_output_of_prior_pics_flag = 0;\n    if (IS_IRAP(s))\n        sh->no_output_of_prior_pics_flag = get_bits1(gb);\n\n    sh->pps_id = get_ue_golomb_long(gb);\n    if (sh->pps_id >= HEVC_MAX_PPS_COUNT || !s->ps.pps_list[sh->pps_id]) {\n        av_log(s->avctx, AV_LOG_ERROR, \"PPS id out of range: %d\\n\", sh->pps_id);\n        return AVERROR_INVALIDDATA;\n    }\n    if (!sh->first_slice_in_pic_flag &&\n        s->ps.pps != (HEVCPPS*)s->ps.pps_list[sh->pps_id]->data) {\n        av_log(s->avctx, AV_LOG_ERROR, \"PPS changed between slices.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    s->ps.pps = (HEVCPPS*)s->ps.pps_list[sh->pps_id]->data;\n    if (s->nal_unit_type == HEVC_NAL_CRA_NUT && s->last_eos == 1)\n        sh->no_output_of_prior_pics_flag = 1;\n\n    if (s->ps.sps != (HEVCSPS*)s->ps.sps_list[s->ps.pps->sps_id]->data) {\n        const HEVCSPS *sps = (HEVCSPS*)s->ps.sps_list[s->ps.pps->sps_id]->data;\n        const HEVCSPS *last_sps = s->ps.sps;\n        enum AVPixelFormat pix_fmt;\n\n        if (last_sps && IS_IRAP(s) && s->nal_unit_type != HEVC_NAL_CRA_NUT) {\n            if (sps->width != last_sps->width || sps->height != last_sps->height ||\n                sps->temporal_layer[sps->max_sub_layers - 1].max_dec_pic_buffering !=\n                last_sps->temporal_layer[last_sps->max_sub_layers - 1].max_dec_pic_buffering)\n                sh->no_output_of_prior_pics_flag = 0;\n        }\n        ff_hevc_clear_refs(s);\n\n        ret = set_sps(s, sps, sps->pix_fmt);\n        if (ret < 0)\n            return ret;\n\n        pix_fmt = get_format(s, sps);\n        if (pix_fmt < 0)\n            return pix_fmt;\n        s->avctx->pix_fmt = pix_fmt;\n\n        s->seq_decode = (s->seq_decode + 1) & 0xff;\n        s->max_ra     = INT_MAX;\n    }\n\n    sh->dependent_slice_segment_flag = 0;\n    if (!sh->first_slice_in_pic_flag) {\n        int slice_address_length;\n\n        if (s->ps.pps->dependent_slice_segments_enabled_flag)\n            sh->dependent_slice_segment_flag = get_bits1(gb);\n\n        slice_address_length = av_ceil_log2(s->ps.sps->ctb_width *\n                                            s->ps.sps->ctb_height);\n        sh->slice_segment_addr = get_bitsz(gb, slice_address_length);\n        if (sh->slice_segment_addr >= s->ps.sps->ctb_width * s->ps.sps->ctb_height) {\n            av_log(s->avctx, AV_LOG_ERROR,\n                   \"Invalid slice segment address: %u.\\n\",\n                   sh->slice_segment_addr);\n            return AVERROR_INVALIDDATA;\n        }\n\n        if (!sh->dependent_slice_segment_flag) {\n            sh->slice_addr = sh->slice_segment_addr;\n            s->slice_idx++;\n        }\n    } else {\n        sh->slice_segment_addr = sh->slice_addr = 0;\n        s->slice_idx           = 0;\n        s->slice_initialized   = 0;\n    }\n\n    if (!sh->dependent_slice_segment_flag) {\n        s->slice_initialized = 0;\n\n        for (i = 0; i < s->ps.pps->num_extra_slice_header_bits; i++)\n            skip_bits(gb, 1);  // slice_reserved_undetermined_flag[]\n\n        sh->slice_type = get_ue_golomb_long(gb);\n        if (!(sh->slice_type == HEVC_SLICE_I ||\n              sh->slice_type == HEVC_SLICE_P ||\n              sh->slice_type == HEVC_SLICE_B)) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Unknown slice type: %d.\\n\",\n                   sh->slice_type);\n            return AVERROR_INVALIDDATA;\n        }\n        if (IS_IRAP(s) && sh->slice_type != HEVC_SLICE_I) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Inter slices in an IRAP frame.\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        // when flag is not present, picture is inferred to be output\n        sh->pic_output_flag = 1;\n        if (s->ps.pps->output_flag_present_flag)\n            sh->pic_output_flag = get_bits1(gb);\n\n        if (s->ps.sps->separate_colour_plane_flag)\n            sh->colour_plane_id = get_bits(gb, 2);\n\n        if (!IS_IDR(s)) {\n            int poc, pos;\n\n            sh->pic_order_cnt_lsb = get_bits(gb, s->ps.sps->log2_max_poc_lsb);\n            poc = ff_hevc_compute_poc(s->ps.sps, s->pocTid0, sh->pic_order_cnt_lsb, s->nal_unit_type);\n            if (!sh->first_slice_in_pic_flag && poc != s->poc) {\n                av_log(s->avctx, AV_LOG_WARNING,\n                       \"Ignoring POC change between slices: %d -> %d\\n\", s->poc, poc);\n                if (s->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_INVALIDDATA;\n                poc = s->poc;\n            }\n            s->poc = poc;\n\n            sh->short_term_ref_pic_set_sps_flag = get_bits1(gb);\n            pos = get_bits_left(gb);\n            if (!sh->short_term_ref_pic_set_sps_flag) {\n                ret = ff_hevc_decode_short_term_rps(gb, s->avctx, &sh->slice_rps, s->ps.sps, 1);\n                if (ret < 0)\n                    return ret;\n\n                sh->short_term_rps = &sh->slice_rps;\n            } else {\n                int numbits, rps_idx;\n\n                if (!s->ps.sps->nb_st_rps) {\n                    av_log(s->avctx, AV_LOG_ERROR, \"No ref lists in the SPS.\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n\n                numbits = av_ceil_log2(s->ps.sps->nb_st_rps);\n                rps_idx = numbits > 0 ? get_bits(gb, numbits) : 0;\n                sh->short_term_rps = &s->ps.sps->st_rps[rps_idx];\n            }\n            sh->short_term_ref_pic_set_size = pos - get_bits_left(gb);\n\n            pos = get_bits_left(gb);\n            ret = decode_lt_rps(s, &sh->long_term_rps, gb);\n            if (ret < 0) {\n                av_log(s->avctx, AV_LOG_WARNING, \"Invalid long term RPS.\\n\");\n                if (s->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_INVALIDDATA;\n            }\n            sh->long_term_ref_pic_set_size = pos - get_bits_left(gb);\n\n            if (s->ps.sps->sps_temporal_mvp_enabled_flag)\n                sh->slice_temporal_mvp_enabled_flag = get_bits1(gb);\n            else\n                sh->slice_temporal_mvp_enabled_flag = 0;\n        } else {\n            s->sh.short_term_rps = NULL;\n            s->poc               = 0;\n        }\n\n        /* 8.3.1 */\n        if (sh->first_slice_in_pic_flag && s->temporal_id == 0 &&\n            s->nal_unit_type != HEVC_NAL_TRAIL_N &&\n            s->nal_unit_type != HEVC_NAL_TSA_N   &&\n            s->nal_unit_type != HEVC_NAL_STSA_N  &&\n            s->nal_unit_type != HEVC_NAL_RADL_N  &&\n            s->nal_unit_type != HEVC_NAL_RADL_R  &&\n            s->nal_unit_type != HEVC_NAL_RASL_N  &&\n            s->nal_unit_type != HEVC_NAL_RASL_R)\n            s->pocTid0 = s->poc;\n\n        if (s->ps.sps->sao_enabled) {\n            sh->slice_sample_adaptive_offset_flag[0] = get_bits1(gb);\n            if (s->ps.sps->chroma_format_idc) {\n                sh->slice_sample_adaptive_offset_flag[1] =\n                sh->slice_sample_adaptive_offset_flag[2] = get_bits1(gb);\n            }\n        } else {\n            sh->slice_sample_adaptive_offset_flag[0] = 0;\n            sh->slice_sample_adaptive_offset_flag[1] = 0;\n            sh->slice_sample_adaptive_offset_flag[2] = 0;\n        }\n\n        sh->nb_refs[L0] = sh->nb_refs[L1] = 0;\n        if (sh->slice_type == HEVC_SLICE_P || sh->slice_type == HEVC_SLICE_B) {\n            int nb_refs;\n\n            sh->nb_refs[L0] = s->ps.pps->num_ref_idx_l0_default_active;\n            if (sh->slice_type == HEVC_SLICE_B)\n                sh->nb_refs[L1] = s->ps.pps->num_ref_idx_l1_default_active;\n\n            if (get_bits1(gb)) { // num_ref_idx_active_override_flag\n                sh->nb_refs[L0] = get_ue_golomb_long(gb) + 1;\n                if (sh->slice_type == HEVC_SLICE_B)\n                    sh->nb_refs[L1] = get_ue_golomb_long(gb) + 1;\n            }\n            if (sh->nb_refs[L0] > HEVC_MAX_REFS || sh->nb_refs[L1] > HEVC_MAX_REFS) {\n                av_log(s->avctx, AV_LOG_ERROR, \"Too many refs: %d/%d.\\n\",\n                       sh->nb_refs[L0], sh->nb_refs[L1]);\n                return AVERROR_INVALIDDATA;\n            }\n\n            sh->rpl_modification_flag[0] = 0;\n            sh->rpl_modification_flag[1] = 0;\n            nb_refs = ff_hevc_frame_nb_refs(s);\n            if (!nb_refs) {\n                av_log(s->avctx, AV_LOG_ERROR, \"Zero refs for a frame with P or B slices.\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n\n            if (s->ps.pps->lists_modification_present_flag && nb_refs > 1) {\n                sh->rpl_modification_flag[0] = get_bits1(gb);\n                if (sh->rpl_modification_flag[0]) {\n                    for (i = 0; i < sh->nb_refs[L0]; i++)\n                        sh->list_entry_lx[0][i] = get_bits(gb, av_ceil_log2(nb_refs));\n                }\n\n                if (sh->slice_type == HEVC_SLICE_B) {\n                    sh->rpl_modification_flag[1] = get_bits1(gb);\n                    if (sh->rpl_modification_flag[1] == 1)\n                        for (i = 0; i < sh->nb_refs[L1]; i++)\n                            sh->list_entry_lx[1][i] = get_bits(gb, av_ceil_log2(nb_refs));\n                }\n            }\n\n            if (sh->slice_type == HEVC_SLICE_B)\n                sh->mvd_l1_zero_flag = get_bits1(gb);\n\n            if (s->ps.pps->cabac_init_present_flag)\n                sh->cabac_init_flag = get_bits1(gb);\n            else\n                sh->cabac_init_flag = 0;\n\n            sh->collocated_ref_idx = 0;\n            if (sh->slice_temporal_mvp_enabled_flag) {\n                sh->collocated_list = L0;\n                if (sh->slice_type == HEVC_SLICE_B)\n                    sh->collocated_list = !get_bits1(gb);\n\n                if (sh->nb_refs[sh->collocated_list] > 1) {\n                    sh->collocated_ref_idx = get_ue_golomb_long(gb);\n                    if (sh->collocated_ref_idx >= sh->nb_refs[sh->collocated_list]) {\n                        av_log(s->avctx, AV_LOG_ERROR,\n                               \"Invalid collocated_ref_idx: %d.\\n\",\n                               sh->collocated_ref_idx);\n                        return AVERROR_INVALIDDATA;\n                    }\n                }\n            }\n\n            if ((s->ps.pps->weighted_pred_flag   && sh->slice_type == HEVC_SLICE_P) ||\n                (s->ps.pps->weighted_bipred_flag && sh->slice_type == HEVC_SLICE_B)) {\n                int ret = pred_weight_table(s, gb);\n                if (ret < 0)\n                    return ret;\n            }\n\n            sh->max_num_merge_cand = 5 - get_ue_golomb_long(gb);\n            if (sh->max_num_merge_cand < 1 || sh->max_num_merge_cand > 5) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"Invalid number of merging MVP candidates: %d.\\n\",\n                       sh->max_num_merge_cand);\n                return AVERROR_INVALIDDATA;\n            }\n        }\n\n        sh->slice_qp_delta = get_se_golomb(gb);\n\n        if (s->ps.pps->pic_slice_level_chroma_qp_offsets_present_flag) {\n            sh->slice_cb_qp_offset = get_se_golomb(gb);\n            sh->slice_cr_qp_offset = get_se_golomb(gb);\n        } else {\n            sh->slice_cb_qp_offset = 0;\n            sh->slice_cr_qp_offset = 0;\n        }\n\n        if (s->ps.pps->chroma_qp_offset_list_enabled_flag)\n            sh->cu_chroma_qp_offset_enabled_flag = get_bits1(gb);\n        else\n            sh->cu_chroma_qp_offset_enabled_flag = 0;\n\n        if (s->ps.pps->deblocking_filter_control_present_flag) {\n            int deblocking_filter_override_flag = 0;\n\n            if (s->ps.pps->deblocking_filter_override_enabled_flag)\n                deblocking_filter_override_flag = get_bits1(gb);\n\n            if (deblocking_filter_override_flag) {\n                sh->disable_deblocking_filter_flag = get_bits1(gb);\n                if (!sh->disable_deblocking_filter_flag) {\n                    int beta_offset_div2 = get_se_golomb(gb);\n                    int tc_offset_div2   = get_se_golomb(gb) ;\n                    if (beta_offset_div2 < -6 || beta_offset_div2 > 6 ||\n                        tc_offset_div2   < -6 || tc_offset_div2   > 6) {\n                        av_log(s->avctx, AV_LOG_ERROR,\n                            \"Invalid deblock filter offsets: %d, %d\\n\",\n                            beta_offset_div2, tc_offset_div2);\n                        return AVERROR_INVALIDDATA;\n                    }\n                    sh->beta_offset = beta_offset_div2 * 2;\n                    sh->tc_offset   =   tc_offset_div2 * 2;\n                }\n            } else {\n                sh->disable_deblocking_filter_flag = s->ps.pps->disable_dbf;\n                sh->beta_offset                    = s->ps.pps->beta_offset;\n                sh->tc_offset                      = s->ps.pps->tc_offset;\n            }\n        } else {\n            sh->disable_deblocking_filter_flag = 0;\n            sh->beta_offset                    = 0;\n            sh->tc_offset                      = 0;\n        }\n\n        if (s->ps.pps->seq_loop_filter_across_slices_enabled_flag &&\n            (sh->slice_sample_adaptive_offset_flag[0] ||\n             sh->slice_sample_adaptive_offset_flag[1] ||\n             !sh->disable_deblocking_filter_flag)) {\n            sh->slice_loop_filter_across_slices_enabled_flag = get_bits1(gb);\n        } else {\n            sh->slice_loop_filter_across_slices_enabled_flag = s->ps.pps->seq_loop_filter_across_slices_enabled_flag;\n        }\n    } else if (!s->slice_initialized) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Independent slice segment missing.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    sh->num_entry_point_offsets = 0;\n    if (s->ps.pps->tiles_enabled_flag || s->ps.pps->entropy_coding_sync_enabled_flag) {\n        unsigned num_entry_point_offsets = get_ue_golomb_long(gb);\n        // It would be possible to bound this tighter but this here is simpler\n        if (num_entry_point_offsets > get_bits_left(gb)) {\n            av_log(s->avctx, AV_LOG_ERROR, \"num_entry_point_offsets %d is invalid\\n\", num_entry_point_offsets);\n            return AVERROR_INVALIDDATA;\n        }\n\n        sh->num_entry_point_offsets = num_entry_point_offsets;\n        if (sh->num_entry_point_offsets > 0) {\n            int offset_len = get_ue_golomb_long(gb) + 1;\n\n            if (offset_len < 1 || offset_len > 32) {\n                sh->num_entry_point_offsets = 0;\n                av_log(s->avctx, AV_LOG_ERROR, \"offset_len %d is invalid\\n\", offset_len);\n                return AVERROR_INVALIDDATA;\n            }\n\n            av_freep(&sh->entry_point_offset);\n            av_freep(&sh->offset);\n            av_freep(&sh->size);\n            sh->entry_point_offset = av_malloc_array(sh->num_entry_point_offsets, sizeof(unsigned));\n            sh->offset = av_malloc_array(sh->num_entry_point_offsets, sizeof(int));\n            sh->size = av_malloc_array(sh->num_entry_point_offsets, sizeof(int));\n            if (!sh->entry_point_offset || !sh->offset || !sh->size) {\n                sh->num_entry_point_offsets = 0;\n                av_log(s->avctx, AV_LOG_ERROR, \"Failed to allocate memory\\n\");\n                return AVERROR(ENOMEM);\n            }\n            for (i = 0; i < sh->num_entry_point_offsets; i++) {\n                unsigned val = get_bits_long(gb, offset_len);\n                sh->entry_point_offset[i] = val + 1; // +1; // +1 to get the size\n            }\n            if (s->threads_number > 1 && (s->ps.pps->num_tile_rows > 1 || s->ps.pps->num_tile_columns > 1)) {\n                s->enable_parallel_tiles = 0; // TODO: you can enable tiles in parallel here\n                s->threads_number = 1;\n            } else\n                s->enable_parallel_tiles = 0;\n        } else\n            s->enable_parallel_tiles = 0;\n    }\n\n    if (s->ps.pps->slice_header_extension_present_flag) {\n        unsigned int length = get_ue_golomb_long(gb);\n        if (length*8LL > get_bits_left(gb)) {\n            av_log(s->avctx, AV_LOG_ERROR, \"too many slice_header_extension_data_bytes\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        for (i = 0; i < length; i++)\n            skip_bits(gb, 8);  // slice_header_extension_data_byte\n    }\n\n    // Inferred parameters\n    sh->slice_qp = 26U + s->ps.pps->pic_init_qp_minus26 + sh->slice_qp_delta;\n    if (sh->slice_qp > 51 ||\n        sh->slice_qp < -s->ps.sps->qp_bd_offset) {\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"The slice_qp %d is outside the valid range \"\n               \"[%d, 51].\\n\",\n               sh->slice_qp,\n               -s->ps.sps->qp_bd_offset);\n        return AVERROR_INVALIDDATA;\n    }\n\n    sh->slice_ctb_addr_rs = sh->slice_segment_addr;\n\n    if (!s->sh.slice_ctb_addr_rs && s->sh.dependent_slice_segment_flag) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Impossible slice segment.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (get_bits_left(gb) < 0) {\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"Overread slice header by %d bits\\n\", -get_bits_left(gb));\n        return AVERROR_INVALIDDATA;\n    }\n\n    s->HEVClc->first_qp_group = !s->sh.dependent_slice_segment_flag;\n\n    if (!s->ps.pps->cu_qp_delta_enabled_flag)\n        s->HEVClc->qp_y = s->sh.slice_qp;\n\n    s->slice_initialized = 1;\n    s->HEVClc->tu.cu_qp_offset_cb = 0;\n    s->HEVClc->tu.cu_qp_offset_cr = 0;\n\n    return 0;\n}\n\n#define CTB(tab, x, y) ((tab)[(y) * s->ps.sps->ctb_width + (x)])\n\n#define SET_SAO(elem, value)                            \\\ndo {                                                    \\\n    if (!sao_merge_up_flag && !sao_merge_left_flag)     \\\n        sao->elem = value;                              \\\n    else if (sao_merge_left_flag)                       \\\n        sao->elem = CTB(s->sao, rx-1, ry).elem;         \\\n    else if (sao_merge_up_flag)                         \\\n        sao->elem = CTB(s->sao, rx, ry-1).elem;         \\\n    else                                                \\\n        sao->elem = 0;                                  \\\n} while (0)\n\nstatic void hls_sao_param(HEVCContext *s, int rx, int ry)\n{\n    HEVCLocalContext *lc    = s->HEVClc;\n    int sao_merge_left_flag = 0;\n    int sao_merge_up_flag   = 0;\n    SAOParams *sao          = &CTB(s->sao, rx, ry);\n    int c_idx, i;\n\n    if (s->sh.slice_sample_adaptive_offset_flag[0] ||\n        s->sh.slice_sample_adaptive_offset_flag[1]) {\n        if (rx > 0) {\n            if (lc->ctb_left_flag)\n                sao_merge_left_flag = ff_hevc_sao_merge_flag_decode(s);\n        }\n        if (ry > 0 && !sao_merge_left_flag) {\n            if (lc->ctb_up_flag)\n                sao_merge_up_flag = ff_hevc_sao_merge_flag_decode(s);\n        }\n    }\n\n    for (c_idx = 0; c_idx < (s->ps.sps->chroma_format_idc ? 3 : 1); c_idx++) {\n        int log2_sao_offset_scale = c_idx == 0 ? s->ps.pps->log2_sao_offset_scale_luma :\n                                                 s->ps.pps->log2_sao_offset_scale_chroma;\n\n        if (!s->sh.slice_sample_adaptive_offset_flag[c_idx]) {\n            sao->type_idx[c_idx] = SAO_NOT_APPLIED;\n            continue;\n        }\n\n        if (c_idx == 2) {\n            sao->type_idx[2] = sao->type_idx[1];\n            sao->eo_class[2] = sao->eo_class[1];\n        } else {\n            SET_SAO(type_idx[c_idx], ff_hevc_sao_type_idx_decode(s));\n        }\n\n        if (sao->type_idx[c_idx] == SAO_NOT_APPLIED)\n            continue;\n\n        for (i = 0; i < 4; i++)\n            SET_SAO(offset_abs[c_idx][i], ff_hevc_sao_offset_abs_decode(s));\n\n        if (sao->type_idx[c_idx] == SAO_BAND) {\n            for (i = 0; i < 4; i++) {\n                if (sao->offset_abs[c_idx][i]) {\n                    SET_SAO(offset_sign[c_idx][i],\n                            ff_hevc_sao_offset_sign_decode(s));\n                } else {\n                    sao->offset_sign[c_idx][i] = 0;\n                }\n            }\n            SET_SAO(band_position[c_idx], ff_hevc_sao_band_position_decode(s));\n        } else if (c_idx != 2) {\n            SET_SAO(eo_class[c_idx], ff_hevc_sao_eo_class_decode(s));\n        }\n\n        // Inferred parameters\n        sao->offset_val[c_idx][0] = 0;\n        for (i = 0; i < 4; i++) {\n            sao->offset_val[c_idx][i + 1] = sao->offset_abs[c_idx][i];\n            if (sao->type_idx[c_idx] == SAO_EDGE) {\n                if (i > 1)\n                    sao->offset_val[c_idx][i + 1] = -sao->offset_val[c_idx][i + 1];\n            } else if (sao->offset_sign[c_idx][i]) {\n                sao->offset_val[c_idx][i + 1] = -sao->offset_val[c_idx][i + 1];\n            }\n            sao->offset_val[c_idx][i + 1] *= 1 << log2_sao_offset_scale;\n        }\n    }\n}\n\n#undef SET_SAO\n#undef CTB\n\nstatic int hls_cross_component_pred(HEVCContext *s, int idx) {\n    HEVCLocalContext *lc    = s->HEVClc;\n    int log2_res_scale_abs_plus1 = ff_hevc_log2_res_scale_abs(s, idx);\n\n    if (log2_res_scale_abs_plus1 !=  0) {\n        int res_scale_sign_flag = ff_hevc_res_scale_sign_flag(s, idx);\n        lc->tu.res_scale_val = (1 << (log2_res_scale_abs_plus1 - 1)) *\n                               (1 - 2 * res_scale_sign_flag);\n    } else {\n        lc->tu.res_scale_val = 0;\n    }\n\n\n    return 0;\n}\n\nstatic int hls_transform_unit(HEVCContext *s, int x0, int y0,\n                              int xBase, int yBase, int cb_xBase, int cb_yBase,\n                              int log2_cb_size, int log2_trafo_size,\n                              int blk_idx, int cbf_luma, int *cbf_cb, int *cbf_cr)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    const int log2_trafo_size_c = log2_trafo_size - s->ps.sps->hshift[1];\n    int i;\n\n    if (lc->cu.pred_mode == MODE_INTRA) {\n        int trafo_size = 1 << log2_trafo_size;\n        ff_hevc_set_neighbour_available(s, x0, y0, trafo_size, trafo_size);\n\n        s->hpc.intra_pred[log2_trafo_size - 2](s, x0, y0, 0);\n    }\n\n    if (cbf_luma || cbf_cb[0] || cbf_cr[0] ||\n        (s->ps.sps->chroma_format_idc == 2 && (cbf_cb[1] || cbf_cr[1]))) {\n        int scan_idx   = SCAN_DIAG;\n        int scan_idx_c = SCAN_DIAG;\n        int cbf_chroma = cbf_cb[0] || cbf_cr[0] ||\n                         (s->ps.sps->chroma_format_idc == 2 &&\n                         (cbf_cb[1] || cbf_cr[1]));\n\n        if (s->ps.pps->cu_qp_delta_enabled_flag && !lc->tu.is_cu_qp_delta_coded) {\n            lc->tu.cu_qp_delta = ff_hevc_cu_qp_delta_abs(s);\n            if (lc->tu.cu_qp_delta != 0)\n                if (ff_hevc_cu_qp_delta_sign_flag(s) == 1)\n                    lc->tu.cu_qp_delta = -lc->tu.cu_qp_delta;\n            lc->tu.is_cu_qp_delta_coded = 1;\n\n            if (lc->tu.cu_qp_delta < -(26 + s->ps.sps->qp_bd_offset / 2) ||\n                lc->tu.cu_qp_delta >  (25 + s->ps.sps->qp_bd_offset / 2)) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"The cu_qp_delta %d is outside the valid range \"\n                       \"[%d, %d].\\n\",\n                       lc->tu.cu_qp_delta,\n                       -(26 + s->ps.sps->qp_bd_offset / 2),\n                        (25 + s->ps.sps->qp_bd_offset / 2));\n                return AVERROR_INVALIDDATA;\n            }\n\n            ff_hevc_set_qPy(s, cb_xBase, cb_yBase, log2_cb_size);\n        }\n\n        if (s->sh.cu_chroma_qp_offset_enabled_flag && cbf_chroma &&\n            !lc->cu.cu_transquant_bypass_flag  &&  !lc->tu.is_cu_chroma_qp_offset_coded) {\n            int cu_chroma_qp_offset_flag = ff_hevc_cu_chroma_qp_offset_flag(s);\n            if (cu_chroma_qp_offset_flag) {\n                int cu_chroma_qp_offset_idx  = 0;\n                if (s->ps.pps->chroma_qp_offset_list_len_minus1 > 0) {\n                    cu_chroma_qp_offset_idx = ff_hevc_cu_chroma_qp_offset_idx(s);\n                    av_log(s->avctx, AV_LOG_ERROR,\n                        \"cu_chroma_qp_offset_idx not yet tested.\\n\");\n                }\n                lc->tu.cu_qp_offset_cb = s->ps.pps->cb_qp_offset_list[cu_chroma_qp_offset_idx];\n                lc->tu.cu_qp_offset_cr = s->ps.pps->cr_qp_offset_list[cu_chroma_qp_offset_idx];\n            } else {\n                lc->tu.cu_qp_offset_cb = 0;\n                lc->tu.cu_qp_offset_cr = 0;\n            }\n            lc->tu.is_cu_chroma_qp_offset_coded = 1;\n        }\n\n        if (lc->cu.pred_mode == MODE_INTRA && log2_trafo_size < 4) {\n            if (lc->tu.intra_pred_mode >= 6 &&\n                lc->tu.intra_pred_mode <= 14) {\n                scan_idx = SCAN_VERT;\n            } else if (lc->tu.intra_pred_mode >= 22 &&\n                       lc->tu.intra_pred_mode <= 30) {\n                scan_idx = SCAN_HORIZ;\n            }\n\n            if (lc->tu.intra_pred_mode_c >=  6 &&\n                lc->tu.intra_pred_mode_c <= 14) {\n                scan_idx_c = SCAN_VERT;\n            } else if (lc->tu.intra_pred_mode_c >= 22 &&\n                       lc->tu.intra_pred_mode_c <= 30) {\n                scan_idx_c = SCAN_HORIZ;\n            }\n        }\n\n        lc->tu.cross_pf = 0;\n\n        if (cbf_luma)\n            ff_hevc_hls_residual_coding(s, x0, y0, log2_trafo_size, scan_idx, 0);\n        if (s->ps.sps->chroma_format_idc && (log2_trafo_size > 2 || s->ps.sps->chroma_format_idc == 3)) {\n            int trafo_size_h = 1 << (log2_trafo_size_c + s->ps.sps->hshift[1]);\n            int trafo_size_v = 1 << (log2_trafo_size_c + s->ps.sps->vshift[1]);\n            lc->tu.cross_pf  = (s->ps.pps->cross_component_prediction_enabled_flag && cbf_luma &&\n                                (lc->cu.pred_mode == MODE_INTER ||\n                                 (lc->tu.chroma_mode_c ==  4)));\n\n            if (lc->tu.cross_pf) {\n                hls_cross_component_pred(s, 0);\n            }\n            for (i = 0; i < (s->ps.sps->chroma_format_idc == 2 ? 2 : 1); i++) {\n                if (lc->cu.pred_mode == MODE_INTRA) {\n                    ff_hevc_set_neighbour_available(s, x0, y0 + (i << log2_trafo_size_c), trafo_size_h, trafo_size_v);\n                    s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0 + (i << log2_trafo_size_c), 1);\n                }\n                if (cbf_cb[i])\n                    ff_hevc_hls_residual_coding(s, x0, y0 + (i << log2_trafo_size_c),\n                                                log2_trafo_size_c, scan_idx_c, 1);\n                else\n                    if (lc->tu.cross_pf) {\n                        ptrdiff_t stride = s->frame->linesize[1];\n                        int hshift = s->ps.sps->hshift[1];\n                        int vshift = s->ps.sps->vshift[1];\n                        int16_t *coeffs_y = (int16_t*)lc->edge_emu_buffer;\n                        int16_t *coeffs   = (int16_t*)lc->edge_emu_buffer2;\n                        int size = 1 << log2_trafo_size_c;\n\n                        uint8_t *dst = &s->frame->data[1][(y0 >> vshift) * stride +\n                                                              ((x0 >> hshift) << s->ps.sps->pixel_shift)];\n                        for (i = 0; i < (size * size); i++) {\n                            coeffs[i] = ((lc->tu.res_scale_val * coeffs_y[i]) >> 3);\n                        }\n                        s->hevcdsp.add_residual[log2_trafo_size_c-2](dst, coeffs, stride);\n                    }\n            }\n\n            if (lc->tu.cross_pf) {\n                hls_cross_component_pred(s, 1);\n            }\n            for (i = 0; i < (s->ps.sps->chroma_format_idc == 2 ? 2 : 1); i++) {\n                if (lc->cu.pred_mode == MODE_INTRA) {\n                    ff_hevc_set_neighbour_available(s, x0, y0 + (i << log2_trafo_size_c), trafo_size_h, trafo_size_v);\n                    s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0 + (i << log2_trafo_size_c), 2);\n                }\n                if (cbf_cr[i])\n                    ff_hevc_hls_residual_coding(s, x0, y0 + (i << log2_trafo_size_c),\n                                                log2_trafo_size_c, scan_idx_c, 2);\n                else\n                    if (lc->tu.cross_pf) {\n                        ptrdiff_t stride = s->frame->linesize[2];\n                        int hshift = s->ps.sps->hshift[2];\n                        int vshift = s->ps.sps->vshift[2];\n                        int16_t *coeffs_y = (int16_t*)lc->edge_emu_buffer;\n                        int16_t *coeffs   = (int16_t*)lc->edge_emu_buffer2;\n                        int size = 1 << log2_trafo_size_c;\n\n                        uint8_t *dst = &s->frame->data[2][(y0 >> vshift) * stride +\n                                                          ((x0 >> hshift) << s->ps.sps->pixel_shift)];\n                        for (i = 0; i < (size * size); i++) {\n                            coeffs[i] = ((lc->tu.res_scale_val * coeffs_y[i]) >> 3);\n                        }\n                        s->hevcdsp.add_residual[log2_trafo_size_c-2](dst, coeffs, stride);\n                    }\n            }\n        } else if (s->ps.sps->chroma_format_idc && blk_idx == 3) {\n            int trafo_size_h = 1 << (log2_trafo_size + 1);\n            int trafo_size_v = 1 << (log2_trafo_size + s->ps.sps->vshift[1]);\n            for (i = 0; i < (s->ps.sps->chroma_format_idc == 2 ? 2 : 1); i++) {\n                if (lc->cu.pred_mode == MODE_INTRA) {\n                    ff_hevc_set_neighbour_available(s, xBase, yBase + (i << log2_trafo_size),\n                                                    trafo_size_h, trafo_size_v);\n                    s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase + (i << log2_trafo_size), 1);\n                }\n                if (cbf_cb[i])\n                    ff_hevc_hls_residual_coding(s, xBase, yBase + (i << log2_trafo_size),\n                                                log2_trafo_size, scan_idx_c, 1);\n            }\n            for (i = 0; i < (s->ps.sps->chroma_format_idc == 2 ? 2 : 1); i++) {\n                if (lc->cu.pred_mode == MODE_INTRA) {\n                    ff_hevc_set_neighbour_available(s, xBase, yBase + (i << log2_trafo_size),\n                                                trafo_size_h, trafo_size_v);\n                    s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase + (i << log2_trafo_size), 2);\n                }\n                if (cbf_cr[i])\n                    ff_hevc_hls_residual_coding(s, xBase, yBase + (i << log2_trafo_size),\n                                                log2_trafo_size, scan_idx_c, 2);\n            }\n        }\n    } else if (s->ps.sps->chroma_format_idc && lc->cu.pred_mode == MODE_INTRA) {\n        if (log2_trafo_size > 2 || s->ps.sps->chroma_format_idc == 3) {\n            int trafo_size_h = 1 << (log2_trafo_size_c + s->ps.sps->hshift[1]);\n            int trafo_size_v = 1 << (log2_trafo_size_c + s->ps.sps->vshift[1]);\n            ff_hevc_set_neighbour_available(s, x0, y0, trafo_size_h, trafo_size_v);\n            s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0, 1);\n            s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0, 2);\n            if (s->ps.sps->chroma_format_idc == 2) {\n                ff_hevc_set_neighbour_available(s, x0, y0 + (1 << log2_trafo_size_c),\n                                                trafo_size_h, trafo_size_v);\n                s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0 + (1 << log2_trafo_size_c), 1);\n                s->hpc.intra_pred[log2_trafo_size_c - 2](s, x0, y0 + (1 << log2_trafo_size_c), 2);\n            }\n        } else if (blk_idx == 3) {\n            int trafo_size_h = 1 << (log2_trafo_size + 1);\n            int trafo_size_v = 1 << (log2_trafo_size + s->ps.sps->vshift[1]);\n            ff_hevc_set_neighbour_available(s, xBase, yBase,\n                                            trafo_size_h, trafo_size_v);\n            s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase, 1);\n            s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase, 2);\n            if (s->ps.sps->chroma_format_idc == 2) {\n                ff_hevc_set_neighbour_available(s, xBase, yBase + (1 << (log2_trafo_size)),\n                                                trafo_size_h, trafo_size_v);\n                s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase + (1 << (log2_trafo_size)), 1);\n                s->hpc.intra_pred[log2_trafo_size - 2](s, xBase, yBase + (1 << (log2_trafo_size)), 2);\n            }\n        }\n    }\n\n    return 0;\n}\n\nstatic void set_deblocking_bypass(HEVCContext *s, int x0, int y0, int log2_cb_size)\n{\n    int cb_size          = 1 << log2_cb_size;\n    int log2_min_pu_size = s->ps.sps->log2_min_pu_size;\n\n    int min_pu_width     = s->ps.sps->min_pu_width;\n    int x_end = FFMIN(x0 + cb_size, s->ps.sps->width);\n    int y_end = FFMIN(y0 + cb_size, s->ps.sps->height);\n    int i, j;\n\n    for (j = (y0 >> log2_min_pu_size); j < (y_end >> log2_min_pu_size); j++)\n        for (i = (x0 >> log2_min_pu_size); i < (x_end >> log2_min_pu_size); i++)\n            s->is_pcm[i + j * min_pu_width] = 2;\n}\n\nstatic int hls_transform_tree(HEVCContext *s, int x0, int y0,\n                              int xBase, int yBase, int cb_xBase, int cb_yBase,\n                              int log2_cb_size, int log2_trafo_size,\n                              int trafo_depth, int blk_idx,\n                              const int *base_cbf_cb, const int *base_cbf_cr)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    uint8_t split_transform_flag;\n    int cbf_cb[2];\n    int cbf_cr[2];\n    int ret;\n\n    cbf_cb[0] = base_cbf_cb[0];\n    cbf_cb[1] = base_cbf_cb[1];\n    cbf_cr[0] = base_cbf_cr[0];\n    cbf_cr[1] = base_cbf_cr[1];\n\n    if (lc->cu.intra_split_flag) {\n        if (trafo_depth == 1) {\n            lc->tu.intra_pred_mode   = lc->pu.intra_pred_mode[blk_idx];\n            if (s->ps.sps->chroma_format_idc == 3) {\n                lc->tu.intra_pred_mode_c = lc->pu.intra_pred_mode_c[blk_idx];\n                lc->tu.chroma_mode_c     = lc->pu.chroma_mode_c[blk_idx];\n            } else {\n                lc->tu.intra_pred_mode_c = lc->pu.intra_pred_mode_c[0];\n                lc->tu.chroma_mode_c     = lc->pu.chroma_mode_c[0];\n            }\n        }\n    } else {\n        lc->tu.intra_pred_mode   = lc->pu.intra_pred_mode[0];\n        lc->tu.intra_pred_mode_c = lc->pu.intra_pred_mode_c[0];\n        lc->tu.chroma_mode_c     = lc->pu.chroma_mode_c[0];\n    }\n\n    if (log2_trafo_size <= s->ps.sps->log2_max_trafo_size &&\n        log2_trafo_size >  s->ps.sps->log2_min_tb_size    &&\n        trafo_depth     < lc->cu.max_trafo_depth       &&\n        !(lc->cu.intra_split_flag && trafo_depth == 0)) {\n        split_transform_flag = ff_hevc_split_transform_flag_decode(s, log2_trafo_size);\n    } else {\n        int inter_split = s->ps.sps->max_transform_hierarchy_depth_inter == 0 &&\n                          lc->cu.pred_mode == MODE_INTER &&\n                          lc->cu.part_mode != PART_2Nx2N &&\n                          trafo_depth == 0;\n\n        split_transform_flag = log2_trafo_size > s->ps.sps->log2_max_trafo_size ||\n                               (lc->cu.intra_split_flag && trafo_depth == 0) ||\n                               inter_split;\n    }\n\n    if (s->ps.sps->chroma_format_idc && (log2_trafo_size > 2 || s->ps.sps->chroma_format_idc == 3)) {\n        if (trafo_depth == 0 || cbf_cb[0]) {\n            cbf_cb[0] = ff_hevc_cbf_cb_cr_decode(s, trafo_depth);\n            if (s->ps.sps->chroma_format_idc == 2 && (!split_transform_flag || log2_trafo_size == 3)) {\n                cbf_cb[1] = ff_hevc_cbf_cb_cr_decode(s, trafo_depth);\n            }\n        }\n\n        if (trafo_depth == 0 || cbf_cr[0]) {\n            cbf_cr[0] = ff_hevc_cbf_cb_cr_decode(s, trafo_depth);\n            if (s->ps.sps->chroma_format_idc == 2 && (!split_transform_flag || log2_trafo_size == 3)) {\n                cbf_cr[1] = ff_hevc_cbf_cb_cr_decode(s, trafo_depth);\n            }\n        }\n    }\n\n    if (split_transform_flag) {\n        const int trafo_size_split = 1 << (log2_trafo_size - 1);\n        const int x1 = x0 + trafo_size_split;\n        const int y1 = y0 + trafo_size_split;\n\n#define SUBDIVIDE(x, y, idx)                                                    \\\ndo {                                                                            \\\n    ret = hls_transform_tree(s, x, y, x0, y0, cb_xBase, cb_yBase, log2_cb_size, \\\n                             log2_trafo_size - 1, trafo_depth + 1, idx,         \\\n                             cbf_cb, cbf_cr);                                   \\\n    if (ret < 0)                                                                \\\n        return ret;                                                             \\\n} while (0)\n\n        SUBDIVIDE(x0, y0, 0);\n        SUBDIVIDE(x1, y0, 1);\n        SUBDIVIDE(x0, y1, 2);\n        SUBDIVIDE(x1, y1, 3);\n\n#undef SUBDIVIDE\n    } else {\n        int min_tu_size      = 1 << s->ps.sps->log2_min_tb_size;\n        int log2_min_tu_size = s->ps.sps->log2_min_tb_size;\n        int min_tu_width     = s->ps.sps->min_tb_width;\n        int cbf_luma         = 1;\n\n        if (lc->cu.pred_mode == MODE_INTRA || trafo_depth != 0 ||\n            cbf_cb[0] || cbf_cr[0] ||\n            (s->ps.sps->chroma_format_idc == 2 && (cbf_cb[1] || cbf_cr[1]))) {\n            cbf_luma = ff_hevc_cbf_luma_decode(s, trafo_depth);\n        }\n\n        ret = hls_transform_unit(s, x0, y0, xBase, yBase, cb_xBase, cb_yBase,\n                                 log2_cb_size, log2_trafo_size,\n                                 blk_idx, cbf_luma, cbf_cb, cbf_cr);\n        if (ret < 0)\n            return ret;\n        // TODO: store cbf_luma somewhere else\n        if (cbf_luma) {\n            int i, j;\n            for (i = 0; i < (1 << log2_trafo_size); i += min_tu_size)\n                for (j = 0; j < (1 << log2_trafo_size); j += min_tu_size) {\n                    int x_tu = (x0 + j) >> log2_min_tu_size;\n                    int y_tu = (y0 + i) >> log2_min_tu_size;\n                    s->cbf_luma[y_tu * min_tu_width + x_tu] = 1;\n                }\n        }\n        if (!s->sh.disable_deblocking_filter_flag) {\n            ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_trafo_size);\n            if (s->ps.pps->transquant_bypass_enable_flag &&\n                lc->cu.cu_transquant_bypass_flag)\n                set_deblocking_bypass(s, x0, y0, log2_trafo_size);\n        }\n    }\n    return 0;\n}\n\nstatic int hls_pcm_sample(HEVCContext *s, int x0, int y0, int log2_cb_size)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    GetBitContext gb;\n    int cb_size   = 1 << log2_cb_size;\n    ptrdiff_t stride0 = s->frame->linesize[0];\n    ptrdiff_t stride1 = s->frame->linesize[1];\n    ptrdiff_t stride2 = s->frame->linesize[2];\n    uint8_t *dst0 = &s->frame->data[0][y0 * stride0 + (x0 << s->ps.sps->pixel_shift)];\n    uint8_t *dst1 = &s->frame->data[1][(y0 >> s->ps.sps->vshift[1]) * stride1 + ((x0 >> s->ps.sps->hshift[1]) << s->ps.sps->pixel_shift)];\n    uint8_t *dst2 = &s->frame->data[2][(y0 >> s->ps.sps->vshift[2]) * stride2 + ((x0 >> s->ps.sps->hshift[2]) << s->ps.sps->pixel_shift)];\n\n    int length         = cb_size * cb_size * s->ps.sps->pcm.bit_depth +\n                         (((cb_size >> s->ps.sps->hshift[1]) * (cb_size >> s->ps.sps->vshift[1])) +\n                          ((cb_size >> s->ps.sps->hshift[2]) * (cb_size >> s->ps.sps->vshift[2]))) *\n                          s->ps.sps->pcm.bit_depth_chroma;\n    const uint8_t *pcm = skip_bytes(&lc->cc, (length + 7) >> 3);\n    int ret;\n\n    if (!s->sh.disable_deblocking_filter_flag)\n        ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_cb_size);\n\n    ret = init_get_bits(&gb, pcm, length);\n    if (ret < 0)\n        return ret;\n\n    s->hevcdsp.put_pcm(dst0, stride0, cb_size, cb_size,     &gb, s->ps.sps->pcm.bit_depth);\n    if (s->ps.sps->chroma_format_idc) {\n        s->hevcdsp.put_pcm(dst1, stride1,\n                           cb_size >> s->ps.sps->hshift[1],\n                           cb_size >> s->ps.sps->vshift[1],\n                           &gb, s->ps.sps->pcm.bit_depth_chroma);\n        s->hevcdsp.put_pcm(dst2, stride2,\n                           cb_size >> s->ps.sps->hshift[2],\n                           cb_size >> s->ps.sps->vshift[2],\n                           &gb, s->ps.sps->pcm.bit_depth_chroma);\n    }\n\n    return 0;\n}\n\n/**\n * 8.5.3.2.2.1 Luma sample unidirectional interpolation process\n *\n * @param s HEVC decoding context\n * @param dst target buffer for block data at block position\n * @param dststride stride of the dst buffer\n * @param ref reference picture buffer at origin (0, 0)\n * @param mv motion vector (relative to block position) to get pixel data from\n * @param x_off horizontal position of block from origin (0, 0)\n * @param y_off vertical position of block from origin (0, 0)\n * @param block_w width of block\n * @param block_h height of block\n * @param luma_weight weighting factor applied to the luma prediction\n * @param luma_offset additive offset applied to the luma prediction value\n */\n\nstatic void luma_mc_uni(HEVCContext *s, uint8_t *dst, ptrdiff_t dststride,\n                        AVFrame *ref, const Mv *mv, int x_off, int y_off,\n                        int block_w, int block_h, int luma_weight, int luma_offset)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    uint8_t *src         = ref->data[0];\n    ptrdiff_t srcstride  = ref->linesize[0];\n    int pic_width        = s->ps.sps->width;\n    int pic_height       = s->ps.sps->height;\n    int mx               = mv->x & 3;\n    int my               = mv->y & 3;\n    int weight_flag      = (s->sh.slice_type == HEVC_SLICE_P && s->ps.pps->weighted_pred_flag) ||\n                           (s->sh.slice_type == HEVC_SLICE_B && s->ps.pps->weighted_bipred_flag);\n    int idx              = ff_hevc_pel_weight[block_w];\n\n    x_off += mv->x >> 2;\n    y_off += mv->y >> 2;\n    src   += y_off * srcstride + (x_off * (1 << s->ps.sps->pixel_shift));\n\n    if (x_off < QPEL_EXTRA_BEFORE || y_off < QPEL_EXTRA_AFTER ||\n        x_off >= pic_width - block_w - QPEL_EXTRA_AFTER ||\n        y_off >= pic_height - block_h - QPEL_EXTRA_AFTER) {\n        const ptrdiff_t edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset     = QPEL_EXTRA_BEFORE * srcstride       + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n        int buf_offset = QPEL_EXTRA_BEFORE * edge_emu_stride + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer, src - offset,\n                                 edge_emu_stride, srcstride,\n                                 block_w + QPEL_EXTRA,\n                                 block_h + QPEL_EXTRA,\n                                 x_off - QPEL_EXTRA_BEFORE, y_off - QPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n        src = lc->edge_emu_buffer + buf_offset;\n        srcstride = edge_emu_stride;\n    }\n\n    if (!weight_flag)\n        s->hevcdsp.put_hevc_qpel_uni[idx][!!my][!!mx](dst, dststride, src, srcstride,\n                                                      block_h, mx, my, block_w);\n    else\n        s->hevcdsp.put_hevc_qpel_uni_w[idx][!!my][!!mx](dst, dststride, src, srcstride,\n                                                        block_h, s->sh.luma_log2_weight_denom,\n                                                        luma_weight, luma_offset, mx, my, block_w);\n}\n\n/**\n * 8.5.3.2.2.1 Luma sample bidirectional interpolation process\n *\n * @param s HEVC decoding context\n * @param dst target buffer for block data at block position\n * @param dststride stride of the dst buffer\n * @param ref0 reference picture0 buffer at origin (0, 0)\n * @param mv0 motion vector0 (relative to block position) to get pixel data from\n * @param x_off horizontal position of block from origin (0, 0)\n * @param y_off vertical position of block from origin (0, 0)\n * @param block_w width of block\n * @param block_h height of block\n * @param ref1 reference picture1 buffer at origin (0, 0)\n * @param mv1 motion vector1 (relative to block position) to get pixel data from\n * @param current_mv current motion vector structure\n */\n static void luma_mc_bi(HEVCContext *s, uint8_t *dst, ptrdiff_t dststride,\n                       AVFrame *ref0, const Mv *mv0, int x_off, int y_off,\n                       int block_w, int block_h, AVFrame *ref1, const Mv *mv1, struct MvField *current_mv)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    ptrdiff_t src0stride  = ref0->linesize[0];\n    ptrdiff_t src1stride  = ref1->linesize[0];\n    int pic_width        = s->ps.sps->width;\n    int pic_height       = s->ps.sps->height;\n    int mx0              = mv0->x & 3;\n    int my0              = mv0->y & 3;\n    int mx1              = mv1->x & 3;\n    int my1              = mv1->y & 3;\n    int weight_flag      = (s->sh.slice_type == HEVC_SLICE_P && s->ps.pps->weighted_pred_flag) ||\n                           (s->sh.slice_type == HEVC_SLICE_B && s->ps.pps->weighted_bipred_flag);\n    int x_off0           = x_off + (mv0->x >> 2);\n    int y_off0           = y_off + (mv0->y >> 2);\n    int x_off1           = x_off + (mv1->x >> 2);\n    int y_off1           = y_off + (mv1->y >> 2);\n    int idx              = ff_hevc_pel_weight[block_w];\n\n    uint8_t *src0  = ref0->data[0] + y_off0 * src0stride + (int)((unsigned)x_off0 << s->ps.sps->pixel_shift);\n    uint8_t *src1  = ref1->data[0] + y_off1 * src1stride + (int)((unsigned)x_off1 << s->ps.sps->pixel_shift);\n\n    if (x_off0 < QPEL_EXTRA_BEFORE || y_off0 < QPEL_EXTRA_AFTER ||\n        x_off0 >= pic_width - block_w - QPEL_EXTRA_AFTER ||\n        y_off0 >= pic_height - block_h - QPEL_EXTRA_AFTER) {\n        const ptrdiff_t edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset     = QPEL_EXTRA_BEFORE * src0stride       + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n        int buf_offset = QPEL_EXTRA_BEFORE * edge_emu_stride + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer, src0 - offset,\n                                 edge_emu_stride, src0stride,\n                                 block_w + QPEL_EXTRA,\n                                 block_h + QPEL_EXTRA,\n                                 x_off0 - QPEL_EXTRA_BEFORE, y_off0 - QPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n        src0 = lc->edge_emu_buffer + buf_offset;\n        src0stride = edge_emu_stride;\n    }\n\n    if (x_off1 < QPEL_EXTRA_BEFORE || y_off1 < QPEL_EXTRA_AFTER ||\n        x_off1 >= pic_width - block_w - QPEL_EXTRA_AFTER ||\n        y_off1 >= pic_height - block_h - QPEL_EXTRA_AFTER) {\n        const ptrdiff_t edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset     = QPEL_EXTRA_BEFORE * src1stride       + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n        int buf_offset = QPEL_EXTRA_BEFORE * edge_emu_stride + (QPEL_EXTRA_BEFORE << s->ps.sps->pixel_shift);\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer2, src1 - offset,\n                                 edge_emu_stride, src1stride,\n                                 block_w + QPEL_EXTRA,\n                                 block_h + QPEL_EXTRA,\n                                 x_off1 - QPEL_EXTRA_BEFORE, y_off1 - QPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n        src1 = lc->edge_emu_buffer2 + buf_offset;\n        src1stride = edge_emu_stride;\n    }\n\n    s->hevcdsp.put_hevc_qpel[idx][!!my0][!!mx0](lc->tmp, src0, src0stride,\n                                                block_h, mx0, my0, block_w);\n    if (!weight_flag)\n        s->hevcdsp.put_hevc_qpel_bi[idx][!!my1][!!mx1](dst, dststride, src1, src1stride, lc->tmp,\n                                                       block_h, mx1, my1, block_w);\n    else\n        s->hevcdsp.put_hevc_qpel_bi_w[idx][!!my1][!!mx1](dst, dststride, src1, src1stride, lc->tmp,\n                                                         block_h, s->sh.luma_log2_weight_denom,\n                                                         s->sh.luma_weight_l0[current_mv->ref_idx[0]],\n                                                         s->sh.luma_weight_l1[current_mv->ref_idx[1]],\n                                                         s->sh.luma_offset_l0[current_mv->ref_idx[0]],\n                                                         s->sh.luma_offset_l1[current_mv->ref_idx[1]],\n                                                         mx1, my1, block_w);\n\n}\n\n/**\n * 8.5.3.2.2.2 Chroma sample uniprediction interpolation process\n *\n * @param s HEVC decoding context\n * @param dst1 target buffer for block data at block position (U plane)\n * @param dst2 target buffer for block data at block position (V plane)\n * @param dststride stride of the dst1 and dst2 buffers\n * @param ref reference picture buffer at origin (0, 0)\n * @param mv motion vector (relative to block position) to get pixel data from\n * @param x_off horizontal position of block from origin (0, 0)\n * @param y_off vertical position of block from origin (0, 0)\n * @param block_w width of block\n * @param block_h height of block\n * @param chroma_weight weighting factor applied to the chroma prediction\n * @param chroma_offset additive offset applied to the chroma prediction value\n */\n\nstatic void chroma_mc_uni(HEVCContext *s, uint8_t *dst0,\n                          ptrdiff_t dststride, uint8_t *src0, ptrdiff_t srcstride, int reflist,\n                          int x_off, int y_off, int block_w, int block_h, struct MvField *current_mv, int chroma_weight, int chroma_offset)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    int pic_width        = s->ps.sps->width >> s->ps.sps->hshift[1];\n    int pic_height       = s->ps.sps->height >> s->ps.sps->vshift[1];\n    const Mv *mv         = &current_mv->mv[reflist];\n    int weight_flag      = (s->sh.slice_type == HEVC_SLICE_P && s->ps.pps->weighted_pred_flag) ||\n                           (s->sh.slice_type == HEVC_SLICE_B && s->ps.pps->weighted_bipred_flag);\n    int idx              = ff_hevc_pel_weight[block_w];\n    int hshift           = s->ps.sps->hshift[1];\n    int vshift           = s->ps.sps->vshift[1];\n    intptr_t mx          = av_mod_uintp2(mv->x, 2 + hshift);\n    intptr_t my          = av_mod_uintp2(mv->y, 2 + vshift);\n    intptr_t _mx         = mx << (1 - hshift);\n    intptr_t _my         = my << (1 - vshift);\n\n    x_off += mv->x >> (2 + hshift);\n    y_off += mv->y >> (2 + vshift);\n    src0  += y_off * srcstride + (x_off * (1 << s->ps.sps->pixel_shift));\n\n    if (x_off < EPEL_EXTRA_BEFORE || y_off < EPEL_EXTRA_AFTER ||\n        x_off >= pic_width - block_w - EPEL_EXTRA_AFTER ||\n        y_off >= pic_height - block_h - EPEL_EXTRA_AFTER) {\n        const int edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset0 = EPEL_EXTRA_BEFORE * (srcstride + (1 << s->ps.sps->pixel_shift));\n        int buf_offset0 = EPEL_EXTRA_BEFORE *\n                          (edge_emu_stride + (1 << s->ps.sps->pixel_shift));\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer, src0 - offset0,\n                                 edge_emu_stride, srcstride,\n                                 block_w + EPEL_EXTRA, block_h + EPEL_EXTRA,\n                                 x_off - EPEL_EXTRA_BEFORE,\n                                 y_off - EPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n\n        src0 = lc->edge_emu_buffer + buf_offset0;\n        srcstride = edge_emu_stride;\n    }\n    if (!weight_flag)\n        s->hevcdsp.put_hevc_epel_uni[idx][!!my][!!mx](dst0, dststride, src0, srcstride,\n                                                  block_h, _mx, _my, block_w);\n    else\n        s->hevcdsp.put_hevc_epel_uni_w[idx][!!my][!!mx](dst0, dststride, src0, srcstride,\n                                                        block_h, s->sh.chroma_log2_weight_denom,\n                                                        chroma_weight, chroma_offset, _mx, _my, block_w);\n}\n\n/**\n * 8.5.3.2.2.2 Chroma sample bidirectional interpolation process\n *\n * @param s HEVC decoding context\n * @param dst target buffer for block data at block position\n * @param dststride stride of the dst buffer\n * @param ref0 reference picture0 buffer at origin (0, 0)\n * @param mv0 motion vector0 (relative to block position) to get pixel data from\n * @param x_off horizontal position of block from origin (0, 0)\n * @param y_off vertical position of block from origin (0, 0)\n * @param block_w width of block\n * @param block_h height of block\n * @param ref1 reference picture1 buffer at origin (0, 0)\n * @param mv1 motion vector1 (relative to block position) to get pixel data from\n * @param current_mv current motion vector structure\n * @param cidx chroma component(cb, cr)\n */\nstatic void chroma_mc_bi(HEVCContext *s, uint8_t *dst0, ptrdiff_t dststride, AVFrame *ref0, AVFrame *ref1,\n                         int x_off, int y_off, int block_w, int block_h, struct MvField *current_mv, int cidx)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    uint8_t *src1        = ref0->data[cidx+1];\n    uint8_t *src2        = ref1->data[cidx+1];\n    ptrdiff_t src1stride = ref0->linesize[cidx+1];\n    ptrdiff_t src2stride = ref1->linesize[cidx+1];\n    int weight_flag      = (s->sh.slice_type == HEVC_SLICE_P && s->ps.pps->weighted_pred_flag) ||\n                           (s->sh.slice_type == HEVC_SLICE_B && s->ps.pps->weighted_bipred_flag);\n    int pic_width        = s->ps.sps->width >> s->ps.sps->hshift[1];\n    int pic_height       = s->ps.sps->height >> s->ps.sps->vshift[1];\n    Mv *mv0              = &current_mv->mv[0];\n    Mv *mv1              = &current_mv->mv[1];\n    int hshift = s->ps.sps->hshift[1];\n    int vshift = s->ps.sps->vshift[1];\n\n    intptr_t mx0 = av_mod_uintp2(mv0->x, 2 + hshift);\n    intptr_t my0 = av_mod_uintp2(mv0->y, 2 + vshift);\n    intptr_t mx1 = av_mod_uintp2(mv1->x, 2 + hshift);\n    intptr_t my1 = av_mod_uintp2(mv1->y, 2 + vshift);\n    intptr_t _mx0 = mx0 << (1 - hshift);\n    intptr_t _my0 = my0 << (1 - vshift);\n    intptr_t _mx1 = mx1 << (1 - hshift);\n    intptr_t _my1 = my1 << (1 - vshift);\n\n    int x_off0 = x_off + (mv0->x >> (2 + hshift));\n    int y_off0 = y_off + (mv0->y >> (2 + vshift));\n    int x_off1 = x_off + (mv1->x >> (2 + hshift));\n    int y_off1 = y_off + (mv1->y >> (2 + vshift));\n    int idx = ff_hevc_pel_weight[block_w];\n    src1  += y_off0 * src1stride + (int)((unsigned)x_off0 << s->ps.sps->pixel_shift);\n    src2  += y_off1 * src2stride + (int)((unsigned)x_off1 << s->ps.sps->pixel_shift);\n\n    if (x_off0 < EPEL_EXTRA_BEFORE || y_off0 < EPEL_EXTRA_AFTER ||\n        x_off0 >= pic_width - block_w - EPEL_EXTRA_AFTER ||\n        y_off0 >= pic_height - block_h - EPEL_EXTRA_AFTER) {\n        const int edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset1 = EPEL_EXTRA_BEFORE * (src1stride + (1 << s->ps.sps->pixel_shift));\n        int buf_offset1 = EPEL_EXTRA_BEFORE *\n                          (edge_emu_stride + (1 << s->ps.sps->pixel_shift));\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer, src1 - offset1,\n                                 edge_emu_stride, src1stride,\n                                 block_w + EPEL_EXTRA, block_h + EPEL_EXTRA,\n                                 x_off0 - EPEL_EXTRA_BEFORE,\n                                 y_off0 - EPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n\n        src1 = lc->edge_emu_buffer + buf_offset1;\n        src1stride = edge_emu_stride;\n    }\n\n    if (x_off1 < EPEL_EXTRA_BEFORE || y_off1 < EPEL_EXTRA_AFTER ||\n        x_off1 >= pic_width - block_w - EPEL_EXTRA_AFTER ||\n        y_off1 >= pic_height - block_h - EPEL_EXTRA_AFTER) {\n        const int edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n        int offset1 = EPEL_EXTRA_BEFORE * (src2stride + (1 << s->ps.sps->pixel_shift));\n        int buf_offset1 = EPEL_EXTRA_BEFORE *\n                          (edge_emu_stride + (1 << s->ps.sps->pixel_shift));\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer2, src2 - offset1,\n                                 edge_emu_stride, src2stride,\n                                 block_w + EPEL_EXTRA, block_h + EPEL_EXTRA,\n                                 x_off1 - EPEL_EXTRA_BEFORE,\n                                 y_off1 - EPEL_EXTRA_BEFORE,\n                                 pic_width, pic_height);\n\n        src2 = lc->edge_emu_buffer2 + buf_offset1;\n        src2stride = edge_emu_stride;\n    }\n\n    s->hevcdsp.put_hevc_epel[idx][!!my0][!!mx0](lc->tmp, src1, src1stride,\n                                                block_h, _mx0, _my0, block_w);\n    if (!weight_flag)\n        s->hevcdsp.put_hevc_epel_bi[idx][!!my1][!!mx1](dst0, s->frame->linesize[cidx+1],\n                                                       src2, src2stride, lc->tmp,\n                                                       block_h, _mx1, _my1, block_w);\n    else\n        s->hevcdsp.put_hevc_epel_bi_w[idx][!!my1][!!mx1](dst0, s->frame->linesize[cidx+1],\n                                                         src2, src2stride, lc->tmp,\n                                                         block_h,\n                                                         s->sh.chroma_log2_weight_denom,\n                                                         s->sh.chroma_weight_l0[current_mv->ref_idx[0]][cidx],\n                                                         s->sh.chroma_weight_l1[current_mv->ref_idx[1]][cidx],\n                                                         s->sh.chroma_offset_l0[current_mv->ref_idx[0]][cidx],\n                                                         s->sh.chroma_offset_l1[current_mv->ref_idx[1]][cidx],\n                                                         _mx1, _my1, block_w);\n}\n\nstatic void hevc_await_progress(HEVCContext *s, HEVCFrame *ref,\n                                const Mv *mv, int y0, int height)\n{\n    if (s->threads_type == FF_THREAD_FRAME ) {\n        int y = FFMAX(0, (mv->y >> 2) + y0 + height + 9);\n\n        ff_thread_await_progress(&ref->tf, y, 0);\n    }\n}\n\nstatic void hevc_luma_mv_mvp_mode(HEVCContext *s, int x0, int y0, int nPbW,\n                                  int nPbH, int log2_cb_size, int part_idx,\n                                  int merge_idx, MvField *mv)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    enum InterPredIdc inter_pred_idc = PRED_L0;\n    int mvp_flag;\n\n    ff_hevc_set_neighbour_available(s, x0, y0, nPbW, nPbH);\n    mv->pred_flag = 0;\n    if (s->sh.slice_type == HEVC_SLICE_B)\n        inter_pred_idc = ff_hevc_inter_pred_idc_decode(s, nPbW, nPbH);\n\n    if (inter_pred_idc != PRED_L1) {\n        if (s->sh.nb_refs[L0])\n            mv->ref_idx[0]= ff_hevc_ref_idx_lx_decode(s, s->sh.nb_refs[L0]);\n\n        mv->pred_flag = PF_L0;\n        ff_hevc_hls_mvd_coding(s, x0, y0, 0);\n        mvp_flag = ff_hevc_mvp_lx_flag_decode(s);\n        ff_hevc_luma_mv_mvp_mode(s, x0, y0, nPbW, nPbH, log2_cb_size,\n                                 part_idx, merge_idx, mv, mvp_flag, 0);\n        mv->mv[0].x += lc->pu.mvd.x;\n        mv->mv[0].y += lc->pu.mvd.y;\n    }\n\n    if (inter_pred_idc != PRED_L0) {\n        if (s->sh.nb_refs[L1])\n            mv->ref_idx[1]= ff_hevc_ref_idx_lx_decode(s, s->sh.nb_refs[L1]);\n\n        if (s->sh.mvd_l1_zero_flag == 1 && inter_pred_idc == PRED_BI) {\n            AV_ZERO32(&lc->pu.mvd);\n        } else {\n            ff_hevc_hls_mvd_coding(s, x0, y0, 1);\n        }\n\n        mv->pred_flag += PF_L1;\n        mvp_flag = ff_hevc_mvp_lx_flag_decode(s);\n        ff_hevc_luma_mv_mvp_mode(s, x0, y0, nPbW, nPbH, log2_cb_size,\n                                 part_idx, merge_idx, mv, mvp_flag, 1);\n        mv->mv[1].x += lc->pu.mvd.x;\n        mv->mv[1].y += lc->pu.mvd.y;\n    }\n}\n\nstatic void hls_prediction_unit(HEVCContext *s, int x0, int y0,\n                                int nPbW, int nPbH,\n                                int log2_cb_size, int partIdx, int idx)\n{\n#define POS(c_idx, x, y)                                                              \\\n    &s->frame->data[c_idx][((y) >> s->ps.sps->vshift[c_idx]) * s->frame->linesize[c_idx] + \\\n                           (((x) >> s->ps.sps->hshift[c_idx]) << s->ps.sps->pixel_shift)]\n    HEVCLocalContext *lc = s->HEVClc;\n    int merge_idx = 0;\n    struct MvField current_mv = {{{ 0 }}};\n\n    int min_pu_width = s->ps.sps->min_pu_width;\n\n    MvField *tab_mvf = s->ref->tab_mvf;\n    RefPicList  *refPicList = s->ref->refPicList;\n    HEVCFrame *ref0 = NULL, *ref1 = NULL;\n    uint8_t *dst0 = POS(0, x0, y0);\n    uint8_t *dst1 = POS(1, x0, y0);\n    uint8_t *dst2 = POS(2, x0, y0);\n    int log2_min_cb_size = s->ps.sps->log2_min_cb_size;\n    int min_cb_width     = s->ps.sps->min_cb_width;\n    int x_cb             = x0 >> log2_min_cb_size;\n    int y_cb             = y0 >> log2_min_cb_size;\n    int x_pu, y_pu;\n    int i, j;\n\n    int skip_flag = SAMPLE_CTB(s->skip_flag, x_cb, y_cb);\n\n    if (!skip_flag)\n        lc->pu.merge_flag = ff_hevc_merge_flag_decode(s);\n\n    if (skip_flag || lc->pu.merge_flag) {\n        if (s->sh.max_num_merge_cand > 1)\n            merge_idx = ff_hevc_merge_idx_decode(s);\n        else\n            merge_idx = 0;\n\n        ff_hevc_luma_mv_merge_mode(s, x0, y0, nPbW, nPbH, log2_cb_size,\n                                   partIdx, merge_idx, &current_mv);\n    } else {\n        hevc_luma_mv_mvp_mode(s, x0, y0, nPbW, nPbH, log2_cb_size,\n                              partIdx, merge_idx, &current_mv);\n    }\n\n    x_pu = x0 >> s->ps.sps->log2_min_pu_size;\n    y_pu = y0 >> s->ps.sps->log2_min_pu_size;\n\n    for (j = 0; j < nPbH >> s->ps.sps->log2_min_pu_size; j++)\n        for (i = 0; i < nPbW >> s->ps.sps->log2_min_pu_size; i++)\n            tab_mvf[(y_pu + j) * min_pu_width + x_pu + i] = current_mv;\n\n    if (current_mv.pred_flag & PF_L0) {\n        ref0 = refPicList[0].ref[current_mv.ref_idx[0]];\n        if (!ref0)\n            return;\n        hevc_await_progress(s, ref0, &current_mv.mv[0], y0, nPbH);\n    }\n    if (current_mv.pred_flag & PF_L1) {\n        ref1 = refPicList[1].ref[current_mv.ref_idx[1]];\n        if (!ref1)\n            return;\n        hevc_await_progress(s, ref1, &current_mv.mv[1], y0, nPbH);\n    }\n\n    if (current_mv.pred_flag == PF_L0) {\n        int x0_c = x0 >> s->ps.sps->hshift[1];\n        int y0_c = y0 >> s->ps.sps->vshift[1];\n        int nPbW_c = nPbW >> s->ps.sps->hshift[1];\n        int nPbH_c = nPbH >> s->ps.sps->vshift[1];\n\n        luma_mc_uni(s, dst0, s->frame->linesize[0], ref0->frame,\n                    &current_mv.mv[0], x0, y0, nPbW, nPbH,\n                    s->sh.luma_weight_l0[current_mv.ref_idx[0]],\n                    s->sh.luma_offset_l0[current_mv.ref_idx[0]]);\n\n        if (s->ps.sps->chroma_format_idc) {\n            chroma_mc_uni(s, dst1, s->frame->linesize[1], ref0->frame->data[1], ref0->frame->linesize[1],\n                          0, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n                          s->sh.chroma_weight_l0[current_mv.ref_idx[0]][0], s->sh.chroma_offset_l0[current_mv.ref_idx[0]][0]);\n            chroma_mc_uni(s, dst2, s->frame->linesize[2], ref0->frame->data[2], ref0->frame->linesize[2],\n                          0, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n                          s->sh.chroma_weight_l0[current_mv.ref_idx[0]][1], s->sh.chroma_offset_l0[current_mv.ref_idx[0]][1]);\n        }\n    } else if (current_mv.pred_flag == PF_L1) {\n        int x0_c = x0 >> s->ps.sps->hshift[1];\n        int y0_c = y0 >> s->ps.sps->vshift[1];\n        int nPbW_c = nPbW >> s->ps.sps->hshift[1];\n        int nPbH_c = nPbH >> s->ps.sps->vshift[1];\n\n        luma_mc_uni(s, dst0, s->frame->linesize[0], ref1->frame,\n                    &current_mv.mv[1], x0, y0, nPbW, nPbH,\n                    s->sh.luma_weight_l1[current_mv.ref_idx[1]],\n                    s->sh.luma_offset_l1[current_mv.ref_idx[1]]);\n\n        if (s->ps.sps->chroma_format_idc) {\n            chroma_mc_uni(s, dst1, s->frame->linesize[1], ref1->frame->data[1], ref1->frame->linesize[1],\n                          1, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n                          s->sh.chroma_weight_l1[current_mv.ref_idx[1]][0], s->sh.chroma_offset_l1[current_mv.ref_idx[1]][0]);\n\n            chroma_mc_uni(s, dst2, s->frame->linesize[2], ref1->frame->data[2], ref1->frame->linesize[2],\n                          1, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n                          s->sh.chroma_weight_l1[current_mv.ref_idx[1]][1], s->sh.chroma_offset_l1[current_mv.ref_idx[1]][1]);\n        }\n    } else if (current_mv.pred_flag == PF_BI) {\n        int x0_c = x0 >> s->ps.sps->hshift[1];\n        int y0_c = y0 >> s->ps.sps->vshift[1];\n        int nPbW_c = nPbW >> s->ps.sps->hshift[1];\n        int nPbH_c = nPbH >> s->ps.sps->vshift[1];\n\n        luma_mc_bi(s, dst0, s->frame->linesize[0], ref0->frame,\n                   &current_mv.mv[0], x0, y0, nPbW, nPbH,\n                   ref1->frame, &current_mv.mv[1], &current_mv);\n\n        if (s->ps.sps->chroma_format_idc) {\n            chroma_mc_bi(s, dst1, s->frame->linesize[1], ref0->frame, ref1->frame,\n                         x0_c, y0_c, nPbW_c, nPbH_c, &current_mv, 0);\n\n            chroma_mc_bi(s, dst2, s->frame->linesize[2], ref0->frame, ref1->frame,\n                         x0_c, y0_c, nPbW_c, nPbH_c, &current_mv, 1);\n        }\n    }\n}\n\n/**\n * 8.4.1\n */\nstatic int luma_intra_pred_mode(HEVCContext *s, int x0, int y0, int pu_size,\n                                int prev_intra_luma_pred_flag)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    int x_pu             = x0 >> s->ps.sps->log2_min_pu_size;\n    int y_pu             = y0 >> s->ps.sps->log2_min_pu_size;\n    int min_pu_width     = s->ps.sps->min_pu_width;\n    int size_in_pus      = pu_size >> s->ps.sps->log2_min_pu_size;\n    int x0b              = av_mod_uintp2(x0, s->ps.sps->log2_ctb_size);\n    int y0b              = av_mod_uintp2(y0, s->ps.sps->log2_ctb_size);\n\n    int cand_up   = (lc->ctb_up_flag || y0b) ?\n                    s->tab_ipm[(y_pu - 1) * min_pu_width + x_pu] : INTRA_DC;\n    int cand_left = (lc->ctb_left_flag || x0b) ?\n                    s->tab_ipm[y_pu * min_pu_width + x_pu - 1]   : INTRA_DC;\n\n    int y_ctb = (y0 >> (s->ps.sps->log2_ctb_size)) << (s->ps.sps->log2_ctb_size);\n\n    MvField *tab_mvf = s->ref->tab_mvf;\n    int intra_pred_mode;\n    int candidate[3];\n    int i, j;\n\n    // intra_pred_mode prediction does not cross vertical CTB boundaries\n    if ((y0 - 1) < y_ctb)\n        cand_up = INTRA_DC;\n\n    if (cand_left == cand_up) {\n        if (cand_left < 2) {\n            candidate[0] = INTRA_PLANAR;\n            candidate[1] = INTRA_DC;\n            candidate[2] = INTRA_ANGULAR_26;\n        } else {\n            candidate[0] = cand_left;\n            candidate[1] = 2 + ((cand_left - 2 - 1 + 32) & 31);\n            candidate[2] = 2 + ((cand_left - 2 + 1) & 31);\n        }\n    } else {\n        candidate[0] = cand_left;\n        candidate[1] = cand_up;\n        if (candidate[0] != INTRA_PLANAR && candidate[1] != INTRA_PLANAR) {\n            candidate[2] = INTRA_PLANAR;\n        } else if (candidate[0] != INTRA_DC && candidate[1] != INTRA_DC) {\n            candidate[2] = INTRA_DC;\n        } else {\n            candidate[2] = INTRA_ANGULAR_26;\n        }\n    }\n\n    if (prev_intra_luma_pred_flag) {\n        intra_pred_mode = candidate[lc->pu.mpm_idx];\n    } else {\n        if (candidate[0] > candidate[1])\n            FFSWAP(uint8_t, candidate[0], candidate[1]);\n        if (candidate[0] > candidate[2])\n            FFSWAP(uint8_t, candidate[0], candidate[2]);\n        if (candidate[1] > candidate[2])\n            FFSWAP(uint8_t, candidate[1], candidate[2]);\n\n        intra_pred_mode = lc->pu.rem_intra_luma_pred_mode;\n        for (i = 0; i < 3; i++)\n            if (intra_pred_mode >= candidate[i])\n                intra_pred_mode++;\n    }\n\n    /* write the intra prediction units into the mv array */\n    if (!size_in_pus)\n        size_in_pus = 1;\n    for (i = 0; i < size_in_pus; i++) {\n        memset(&s->tab_ipm[(y_pu + i) * min_pu_width + x_pu],\n               intra_pred_mode, size_in_pus);\n\n        for (j = 0; j < size_in_pus; j++) {\n            tab_mvf[(y_pu + j) * min_pu_width + x_pu + i].pred_flag = PF_INTRA;\n        }\n    }\n\n    return intra_pred_mode;\n}\n\nstatic av_always_inline void set_ct_depth(HEVCContext *s, int x0, int y0,\n                                          int log2_cb_size, int ct_depth)\n{\n    int length = (1 << log2_cb_size) >> s->ps.sps->log2_min_cb_size;\n    int x_cb   = x0 >> s->ps.sps->log2_min_cb_size;\n    int y_cb   = y0 >> s->ps.sps->log2_min_cb_size;\n    int y;\n\n    for (y = 0; y < length; y++)\n        memset(&s->tab_ct_depth[(y_cb + y) * s->ps.sps->min_cb_width + x_cb],\n               ct_depth, length);\n}\n\nstatic const uint8_t tab_mode_idx[] = {\n     0,  1,  2,  2,  2,  2,  3,  5,  7,  8, 10, 12, 13, 15, 17, 18, 19, 20,\n    21, 22, 23, 23, 24, 24, 25, 25, 26, 27, 27, 28, 28, 29, 29, 30, 31};\n\nstatic void intra_prediction_unit(HEVCContext *s, int x0, int y0,\n                                  int log2_cb_size)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    static const uint8_t intra_chroma_table[4] = { 0, 26, 10, 1 };\n    uint8_t prev_intra_luma_pred_flag[4];\n    int split   = lc->cu.part_mode == PART_NxN;\n    int pb_size = (1 << log2_cb_size) >> split;\n    int side    = split + 1;\n    int chroma_mode;\n    int i, j;\n\n    for (i = 0; i < side; i++)\n        for (j = 0; j < side; j++)\n            prev_intra_luma_pred_flag[2 * i + j] = ff_hevc_prev_intra_luma_pred_flag_decode(s);\n\n    for (i = 0; i < side; i++) {\n        for (j = 0; j < side; j++) {\n            if (prev_intra_luma_pred_flag[2 * i + j])\n                lc->pu.mpm_idx = ff_hevc_mpm_idx_decode(s);\n            else\n                lc->pu.rem_intra_luma_pred_mode = ff_hevc_rem_intra_luma_pred_mode_decode(s);\n\n            lc->pu.intra_pred_mode[2 * i + j] =\n                luma_intra_pred_mode(s, x0 + pb_size * j, y0 + pb_size * i, pb_size,\n                                     prev_intra_luma_pred_flag[2 * i + j]);\n        }\n    }\n\n    if (s->ps.sps->chroma_format_idc == 3) {\n        for (i = 0; i < side; i++) {\n            for (j = 0; j < side; j++) {\n                lc->pu.chroma_mode_c[2 * i + j] = chroma_mode = ff_hevc_intra_chroma_pred_mode_decode(s);\n                if (chroma_mode != 4) {\n                    if (lc->pu.intra_pred_mode[2 * i + j] == intra_chroma_table[chroma_mode])\n                        lc->pu.intra_pred_mode_c[2 * i + j] = 34;\n                    else\n                        lc->pu.intra_pred_mode_c[2 * i + j] = intra_chroma_table[chroma_mode];\n                } else {\n                    lc->pu.intra_pred_mode_c[2 * i + j] = lc->pu.intra_pred_mode[2 * i + j];\n                }\n            }\n        }\n    } else if (s->ps.sps->chroma_format_idc == 2) {\n        int mode_idx;\n        lc->pu.chroma_mode_c[0] = chroma_mode = ff_hevc_intra_chroma_pred_mode_decode(s);\n        if (chroma_mode != 4) {\n            if (lc->pu.intra_pred_mode[0] == intra_chroma_table[chroma_mode])\n                mode_idx = 34;\n            else\n                mode_idx = intra_chroma_table[chroma_mode];\n        } else {\n            mode_idx = lc->pu.intra_pred_mode[0];\n        }\n        lc->pu.intra_pred_mode_c[0] = tab_mode_idx[mode_idx];\n    } else if (s->ps.sps->chroma_format_idc != 0) {\n        chroma_mode = ff_hevc_intra_chroma_pred_mode_decode(s);\n        if (chroma_mode != 4) {\n            if (lc->pu.intra_pred_mode[0] == intra_chroma_table[chroma_mode])\n                lc->pu.intra_pred_mode_c[0] = 34;\n            else\n                lc->pu.intra_pred_mode_c[0] = intra_chroma_table[chroma_mode];\n        } else {\n            lc->pu.intra_pred_mode_c[0] = lc->pu.intra_pred_mode[0];\n        }\n    }\n}\n\nstatic void intra_prediction_unit_default_value(HEVCContext *s,\n                                                int x0, int y0,\n                                                int log2_cb_size)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    int pb_size          = 1 << log2_cb_size;\n    int size_in_pus      = pb_size >> s->ps.sps->log2_min_pu_size;\n    int min_pu_width     = s->ps.sps->min_pu_width;\n    MvField *tab_mvf     = s->ref->tab_mvf;\n    int x_pu             = x0 >> s->ps.sps->log2_min_pu_size;\n    int y_pu             = y0 >> s->ps.sps->log2_min_pu_size;\n    int j, k;\n\n    if (size_in_pus == 0)\n        size_in_pus = 1;\n    for (j = 0; j < size_in_pus; j++)\n        memset(&s->tab_ipm[(y_pu + j) * min_pu_width + x_pu], INTRA_DC, size_in_pus);\n    if (lc->cu.pred_mode == MODE_INTRA)\n        for (j = 0; j < size_in_pus; j++)\n            for (k = 0; k < size_in_pus; k++)\n                tab_mvf[(y_pu + j) * min_pu_width + x_pu + k].pred_flag = PF_INTRA;\n}\n\nstatic int hls_coding_unit(HEVCContext *s, int x0, int y0, int log2_cb_size)\n{\n    int cb_size          = 1 << log2_cb_size;\n    HEVCLocalContext *lc = s->HEVClc;\n    int log2_min_cb_size = s->ps.sps->log2_min_cb_size;\n    int length           = cb_size >> log2_min_cb_size;\n    int min_cb_width     = s->ps.sps->min_cb_width;\n    int x_cb             = x0 >> log2_min_cb_size;\n    int y_cb             = y0 >> log2_min_cb_size;\n    int idx              = log2_cb_size - 2;\n    int qp_block_mask    = (1<<(s->ps.sps->log2_ctb_size - s->ps.pps->diff_cu_qp_delta_depth)) - 1;\n    int x, y, ret;\n\n    lc->cu.x                = x0;\n    lc->cu.y                = y0;\n    lc->cu.pred_mode        = MODE_INTRA;\n    lc->cu.part_mode        = PART_2Nx2N;\n    lc->cu.intra_split_flag = 0;\n\n    SAMPLE_CTB(s->skip_flag, x_cb, y_cb) = 0;\n    for (x = 0; x < 4; x++)\n        lc->pu.intra_pred_mode[x] = 1;\n    if (s->ps.pps->transquant_bypass_enable_flag) {\n        lc->cu.cu_transquant_bypass_flag = ff_hevc_cu_transquant_bypass_flag_decode(s);\n        if (lc->cu.cu_transquant_bypass_flag)\n            set_deblocking_bypass(s, x0, y0, log2_cb_size);\n    } else\n        lc->cu.cu_transquant_bypass_flag = 0;\n\n    if (s->sh.slice_type != HEVC_SLICE_I) {\n        uint8_t skip_flag = ff_hevc_skip_flag_decode(s, x0, y0, x_cb, y_cb);\n\n        x = y_cb * min_cb_width + x_cb;\n        for (y = 0; y < length; y++) {\n            memset(&s->skip_flag[x], skip_flag, length);\n            x += min_cb_width;\n        }\n        lc->cu.pred_mode = skip_flag ? MODE_SKIP : MODE_INTER;\n    } else {\n        x = y_cb * min_cb_width + x_cb;\n        for (y = 0; y < length; y++) {\n            memset(&s->skip_flag[x], 0, length);\n            x += min_cb_width;\n        }\n    }\n\n    if (SAMPLE_CTB(s->skip_flag, x_cb, y_cb)) {\n        hls_prediction_unit(s, x0, y0, cb_size, cb_size, log2_cb_size, 0, idx);\n        intra_prediction_unit_default_value(s, x0, y0, log2_cb_size);\n\n        if (!s->sh.disable_deblocking_filter_flag)\n            ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_cb_size);\n    } else {\n        int pcm_flag = 0;\n\n        if (s->sh.slice_type != HEVC_SLICE_I)\n            lc->cu.pred_mode = ff_hevc_pred_mode_decode(s);\n        if (lc->cu.pred_mode != MODE_INTRA ||\n            log2_cb_size == s->ps.sps->log2_min_cb_size) {\n            lc->cu.part_mode        = ff_hevc_part_mode_decode(s, log2_cb_size);\n            lc->cu.intra_split_flag = lc->cu.part_mode == PART_NxN &&\n                                      lc->cu.pred_mode == MODE_INTRA;\n        }\n\n        if (lc->cu.pred_mode == MODE_INTRA) {\n            if (lc->cu.part_mode == PART_2Nx2N && s->ps.sps->pcm_enabled_flag &&\n                log2_cb_size >= s->ps.sps->pcm.log2_min_pcm_cb_size &&\n                log2_cb_size <= s->ps.sps->pcm.log2_max_pcm_cb_size) {\n                pcm_flag = ff_hevc_pcm_flag_decode(s);\n            }\n            if (pcm_flag) {\n                intra_prediction_unit_default_value(s, x0, y0, log2_cb_size);\n                ret = hls_pcm_sample(s, x0, y0, log2_cb_size);\n                if (s->ps.sps->pcm.loop_filter_disable_flag)\n                    set_deblocking_bypass(s, x0, y0, log2_cb_size);\n\n                if (ret < 0)\n                    return ret;\n            } else {\n                intra_prediction_unit(s, x0, y0, log2_cb_size);\n            }\n        } else {\n            intra_prediction_unit_default_value(s, x0, y0, log2_cb_size);\n            switch (lc->cu.part_mode) {\n            case PART_2Nx2N:\n                hls_prediction_unit(s, x0, y0, cb_size, cb_size, log2_cb_size, 0, idx);\n                break;\n            case PART_2NxN:\n                hls_prediction_unit(s, x0, y0,               cb_size, cb_size / 2, log2_cb_size, 0, idx);\n                hls_prediction_unit(s, x0, y0 + cb_size / 2, cb_size, cb_size / 2, log2_cb_size, 1, idx);\n                break;\n            case PART_Nx2N:\n                hls_prediction_unit(s, x0,               y0, cb_size / 2, cb_size, log2_cb_size, 0, idx - 1);\n                hls_prediction_unit(s, x0 + cb_size / 2, y0, cb_size / 2, cb_size, log2_cb_size, 1, idx - 1);\n                break;\n            case PART_2NxnU:\n                hls_prediction_unit(s, x0, y0,               cb_size, cb_size     / 4, log2_cb_size, 0, idx);\n                hls_prediction_unit(s, x0, y0 + cb_size / 4, cb_size, cb_size * 3 / 4, log2_cb_size, 1, idx);\n                break;\n            case PART_2NxnD:\n                hls_prediction_unit(s, x0, y0,                   cb_size, cb_size * 3 / 4, log2_cb_size, 0, idx);\n                hls_prediction_unit(s, x0, y0 + cb_size * 3 / 4, cb_size, cb_size     / 4, log2_cb_size, 1, idx);\n                break;\n            case PART_nLx2N:\n                hls_prediction_unit(s, x0,               y0, cb_size     / 4, cb_size, log2_cb_size, 0, idx - 2);\n                hls_prediction_unit(s, x0 + cb_size / 4, y0, cb_size * 3 / 4, cb_size, log2_cb_size, 1, idx - 2);\n                break;\n            case PART_nRx2N:\n                hls_prediction_unit(s, x0,                   y0, cb_size * 3 / 4, cb_size, log2_cb_size, 0, idx - 2);\n                hls_prediction_unit(s, x0 + cb_size * 3 / 4, y0, cb_size     / 4, cb_size, log2_cb_size, 1, idx - 2);\n                break;\n            case PART_NxN:\n                hls_prediction_unit(s, x0,               y0,               cb_size / 2, cb_size / 2, log2_cb_size, 0, idx - 1);\n                hls_prediction_unit(s, x0 + cb_size / 2, y0,               cb_size / 2, cb_size / 2, log2_cb_size, 1, idx - 1);\n                hls_prediction_unit(s, x0,               y0 + cb_size / 2, cb_size / 2, cb_size / 2, log2_cb_size, 2, idx - 1);\n                hls_prediction_unit(s, x0 + cb_size / 2, y0 + cb_size / 2, cb_size / 2, cb_size / 2, log2_cb_size, 3, idx - 1);\n                break;\n            }\n        }\n\n        if (!pcm_flag) {\n            int rqt_root_cbf = 1;\n\n            if (lc->cu.pred_mode != MODE_INTRA &&\n                !(lc->cu.part_mode == PART_2Nx2N && lc->pu.merge_flag)) {\n                rqt_root_cbf = ff_hevc_no_residual_syntax_flag_decode(s);\n            }\n            if (rqt_root_cbf) {\n                const static int cbf[2] = { 0 };\n                lc->cu.max_trafo_depth = lc->cu.pred_mode == MODE_INTRA ?\n                                         s->ps.sps->max_transform_hierarchy_depth_intra + lc->cu.intra_split_flag :\n                                         s->ps.sps->max_transform_hierarchy_depth_inter;\n                ret = hls_transform_tree(s, x0, y0, x0, y0, x0, y0,\n                                         log2_cb_size,\n                                         log2_cb_size, 0, 0, cbf, cbf);\n                if (ret < 0)\n                    return ret;\n            } else {\n                if (!s->sh.disable_deblocking_filter_flag)\n                    ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_cb_size);\n            }\n        }\n    }\n\n    if (s->ps.pps->cu_qp_delta_enabled_flag && lc->tu.is_cu_qp_delta_coded == 0)\n        ff_hevc_set_qPy(s, x0, y0, log2_cb_size);\n\n    x = y_cb * min_cb_width + x_cb;\n    for (y = 0; y < length; y++) {\n        memset(&s->qp_y_tab[x], lc->qp_y, length);\n        x += min_cb_width;\n    }\n\n    if(((x0 + (1<<log2_cb_size)) & qp_block_mask) == 0 &&\n       ((y0 + (1<<log2_cb_size)) & qp_block_mask) == 0) {\n        lc->qPy_pred = lc->qp_y;\n    }\n\n    set_ct_depth(s, x0, y0, log2_cb_size, lc->ct_depth);\n\n    return 0;\n}\n\nstatic int hls_coding_quadtree(HEVCContext *s, int x0, int y0,\n                               int log2_cb_size, int cb_depth)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    const int cb_size    = 1 << log2_cb_size;\n    int ret;\n    int split_cu;\n\n    lc->ct_depth = cb_depth;\n    if (x0 + cb_size <= s->ps.sps->width  &&\n        y0 + cb_size <= s->ps.sps->height &&\n        log2_cb_size > s->ps.sps->log2_min_cb_size) {\n        split_cu = ff_hevc_split_coding_unit_flag_decode(s, cb_depth, x0, y0);\n    } else {\n        split_cu = (log2_cb_size > s->ps.sps->log2_min_cb_size);\n    }\n    if (s->ps.pps->cu_qp_delta_enabled_flag &&\n        log2_cb_size >= s->ps.sps->log2_ctb_size - s->ps.pps->diff_cu_qp_delta_depth) {\n        lc->tu.is_cu_qp_delta_coded = 0;\n        lc->tu.cu_qp_delta          = 0;\n    }\n\n    if (s->sh.cu_chroma_qp_offset_enabled_flag &&\n        log2_cb_size >= s->ps.sps->log2_ctb_size - s->ps.pps->diff_cu_chroma_qp_offset_depth) {\n        lc->tu.is_cu_chroma_qp_offset_coded = 0;\n    }\n\n    if (split_cu) {\n        int qp_block_mask = (1<<(s->ps.sps->log2_ctb_size - s->ps.pps->diff_cu_qp_delta_depth)) - 1;\n        const int cb_size_split = cb_size >> 1;\n        const int x1 = x0 + cb_size_split;\n        const int y1 = y0 + cb_size_split;\n\n        int more_data = 0;\n\n        more_data = hls_coding_quadtree(s, x0, y0, log2_cb_size - 1, cb_depth + 1);\n        if (more_data < 0)\n            return more_data;\n\n        if (more_data && x1 < s->ps.sps->width) {\n            more_data = hls_coding_quadtree(s, x1, y0, log2_cb_size - 1, cb_depth + 1);\n            if (more_data < 0)\n                return more_data;\n        }\n        if (more_data && y1 < s->ps.sps->height) {\n            more_data = hls_coding_quadtree(s, x0, y1, log2_cb_size - 1, cb_depth + 1);\n            if (more_data < 0)\n                return more_data;\n        }\n        if (more_data && x1 < s->ps.sps->width &&\n            y1 < s->ps.sps->height) {\n            more_data = hls_coding_quadtree(s, x1, y1, log2_cb_size - 1, cb_depth + 1);\n            if (more_data < 0)\n                return more_data;\n        }\n\n        if(((x0 + (1<<log2_cb_size)) & qp_block_mask) == 0 &&\n            ((y0 + (1<<log2_cb_size)) & qp_block_mask) == 0)\n            lc->qPy_pred = lc->qp_y;\n\n        if (more_data)\n            return ((x1 + cb_size_split) < s->ps.sps->width ||\n                    (y1 + cb_size_split) < s->ps.sps->height);\n        else\n            return 0;\n    } else {\n        ret = hls_coding_unit(s, x0, y0, log2_cb_size);\n        if (ret < 0)\n            return ret;\n        if ((!((x0 + cb_size) %\n               (1 << (s->ps.sps->log2_ctb_size))) ||\n             (x0 + cb_size >= s->ps.sps->width)) &&\n            (!((y0 + cb_size) %\n               (1 << (s->ps.sps->log2_ctb_size))) ||\n             (y0 + cb_size >= s->ps.sps->height))) {\n            int end_of_slice_flag = ff_hevc_end_of_slice_flag_decode(s);\n            return !end_of_slice_flag;\n        } else {\n            return 1;\n        }\n    }\n\n    return 0;\n}\n\nstatic void hls_decode_neighbour(HEVCContext *s, int x_ctb, int y_ctb,\n                                 int ctb_addr_ts)\n{\n    HEVCLocalContext *lc  = s->HEVClc;\n    int ctb_size          = 1 << s->ps.sps->log2_ctb_size;\n    int ctb_addr_rs       = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts];\n    int ctb_addr_in_slice = ctb_addr_rs - s->sh.slice_addr;\n\n    s->tab_slice_address[ctb_addr_rs] = s->sh.slice_addr;\n\n    if (s->ps.pps->entropy_coding_sync_enabled_flag) {\n        if (x_ctb == 0 && (y_ctb & (ctb_size - 1)) == 0)\n            lc->first_qp_group = 1;\n        lc->end_of_tiles_x = s->ps.sps->width;\n    } else if (s->ps.pps->tiles_enabled_flag) {\n        if (ctb_addr_ts && s->ps.pps->tile_id[ctb_addr_ts] != s->ps.pps->tile_id[ctb_addr_ts - 1]) {\n            int idxX = s->ps.pps->col_idxX[x_ctb >> s->ps.sps->log2_ctb_size];\n            lc->end_of_tiles_x   = x_ctb + (s->ps.pps->column_width[idxX] << s->ps.sps->log2_ctb_size);\n            lc->first_qp_group   = 1;\n        }\n    } else {\n        lc->end_of_tiles_x = s->ps.sps->width;\n    }\n\n    lc->end_of_tiles_y = FFMIN(y_ctb + ctb_size, s->ps.sps->height);\n\n    lc->boundary_flags = 0;\n    if (s->ps.pps->tiles_enabled_flag) {\n        if (x_ctb > 0 && s->ps.pps->tile_id[ctb_addr_ts] != s->ps.pps->tile_id[s->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs - 1]])\n            lc->boundary_flags |= BOUNDARY_LEFT_TILE;\n        if (x_ctb > 0 && s->tab_slice_address[ctb_addr_rs] != s->tab_slice_address[ctb_addr_rs - 1])\n            lc->boundary_flags |= BOUNDARY_LEFT_SLICE;\n        if (y_ctb > 0 && s->ps.pps->tile_id[ctb_addr_ts] != s->ps.pps->tile_id[s->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs - s->ps.sps->ctb_width]])\n            lc->boundary_flags |= BOUNDARY_UPPER_TILE;\n        if (y_ctb > 0 && s->tab_slice_address[ctb_addr_rs] != s->tab_slice_address[ctb_addr_rs - s->ps.sps->ctb_width])\n            lc->boundary_flags |= BOUNDARY_UPPER_SLICE;\n    } else {\n        if (ctb_addr_in_slice <= 0)\n            lc->boundary_flags |= BOUNDARY_LEFT_SLICE;\n        if (ctb_addr_in_slice < s->ps.sps->ctb_width)\n            lc->boundary_flags |= BOUNDARY_UPPER_SLICE;\n    }\n\n    lc->ctb_left_flag = ((x_ctb > 0) && (ctb_addr_in_slice > 0) && !(lc->boundary_flags & BOUNDARY_LEFT_TILE));\n    lc->ctb_up_flag   = ((y_ctb > 0) && (ctb_addr_in_slice >= s->ps.sps->ctb_width) && !(lc->boundary_flags & BOUNDARY_UPPER_TILE));\n    lc->ctb_up_right_flag = ((y_ctb > 0)  && (ctb_addr_in_slice+1 >= s->ps.sps->ctb_width) && (s->ps.pps->tile_id[ctb_addr_ts] == s->ps.pps->tile_id[s->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs+1 - s->ps.sps->ctb_width]]));\n    lc->ctb_up_left_flag = ((x_ctb > 0) && (y_ctb > 0)  && (ctb_addr_in_slice-1 >= s->ps.sps->ctb_width) && (s->ps.pps->tile_id[ctb_addr_ts] == s->ps.pps->tile_id[s->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs-1 - s->ps.sps->ctb_width]]));\n}\n\nstatic int hls_decode_entry(AVCodecContext *avctxt, void *isFilterThread)\n{\n    HEVCContext *s  = avctxt->priv_data;\n    int ctb_size    = 1 << s->ps.sps->log2_ctb_size;\n    int more_data   = 1;\n    int x_ctb       = 0;\n    int y_ctb       = 0;\n    int ctb_addr_ts = s->ps.pps->ctb_addr_rs_to_ts[s->sh.slice_ctb_addr_rs];\n    int ret;\n\n    if (!ctb_addr_ts && s->sh.dependent_slice_segment_flag) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Impossible initial tile.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (s->sh.dependent_slice_segment_flag) {\n        int prev_rs = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts - 1];\n        if (s->tab_slice_address[prev_rs] != s->sh.slice_addr) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Previous slice segment missing\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    while (more_data && ctb_addr_ts < s->ps.sps->ctb_size) {\n        int ctb_addr_rs = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts];\n\n        x_ctb = (ctb_addr_rs % ((s->ps.sps->width + ctb_size - 1) >> s->ps.sps->log2_ctb_size)) << s->ps.sps->log2_ctb_size;\n        y_ctb = (ctb_addr_rs / ((s->ps.sps->width + ctb_size - 1) >> s->ps.sps->log2_ctb_size)) << s->ps.sps->log2_ctb_size;\n        hls_decode_neighbour(s, x_ctb, y_ctb, ctb_addr_ts);\n\n        ret = ff_hevc_cabac_init(s, ctb_addr_ts);\n        if (ret < 0) {\n            s->tab_slice_address[ctb_addr_rs] = -1;\n            return ret;\n        }\n\n        hls_sao_param(s, x_ctb >> s->ps.sps->log2_ctb_size, y_ctb >> s->ps.sps->log2_ctb_size);\n\n        s->deblock[ctb_addr_rs].beta_offset = s->sh.beta_offset;\n        s->deblock[ctb_addr_rs].tc_offset   = s->sh.tc_offset;\n        s->filter_slice_edges[ctb_addr_rs]  = s->sh.slice_loop_filter_across_slices_enabled_flag;\n\n        more_data = hls_coding_quadtree(s, x_ctb, y_ctb, s->ps.sps->log2_ctb_size, 0);\n        if (more_data < 0) {\n            s->tab_slice_address[ctb_addr_rs] = -1;\n            return more_data;\n        }\n\n\n        ctb_addr_ts++;\n        ff_hevc_save_states(s, ctb_addr_ts);\n        ff_hevc_hls_filters(s, x_ctb, y_ctb, ctb_size);\n    }\n\n    if (x_ctb + ctb_size >= s->ps.sps->width &&\n        y_ctb + ctb_size >= s->ps.sps->height)\n        ff_hevc_hls_filter(s, x_ctb, y_ctb, ctb_size);\n\n    return ctb_addr_ts;\n}\n\nstatic int hls_slice_data(HEVCContext *s)\n{\n    int arg[2];\n    int ret[2];\n\n    arg[0] = 0;\n    arg[1] = 1;\n\n    s->avctx->execute(s->avctx, hls_decode_entry, arg, ret , 1, sizeof(int));\n    return ret[0];\n}\nstatic int hls_decode_entry_wpp(AVCodecContext *avctxt, void *input_ctb_row, int job, int self_id)\n{\n    HEVCContext *s1  = avctxt->priv_data, *s;\n    HEVCLocalContext *lc;\n    int ctb_size    = 1<< s1->ps.sps->log2_ctb_size;\n    int more_data   = 1;\n    int *ctb_row_p    = input_ctb_row;\n    int ctb_row = ctb_row_p[job];\n    int ctb_addr_rs = s1->sh.slice_ctb_addr_rs + ctb_row * ((s1->ps.sps->width + ctb_size - 1) >> s1->ps.sps->log2_ctb_size);\n    int ctb_addr_ts = s1->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs];\n    int thread = ctb_row % s1->threads_number;\n    int ret;\n\n    s = s1->sList[self_id];\n    lc = s->HEVClc;\n\n    if(ctb_row) {\n        ret = init_get_bits8(&lc->gb, s->data + s->sh.offset[ctb_row - 1], s->sh.size[ctb_row - 1]);\n        if (ret < 0)\n            goto error;\n        ff_init_cabac_decoder(&lc->cc, s->data + s->sh.offset[(ctb_row)-1], s->sh.size[ctb_row - 1]);\n    }\n\n    while(more_data && ctb_addr_ts < s->ps.sps->ctb_size) {\n        int x_ctb = (ctb_addr_rs % s->ps.sps->ctb_width) << s->ps.sps->log2_ctb_size;\n        int y_ctb = (ctb_addr_rs / s->ps.sps->ctb_width) << s->ps.sps->log2_ctb_size;\n\n        hls_decode_neighbour(s, x_ctb, y_ctb, ctb_addr_ts);\n\n        ff_thread_await_progress2(s->avctx, ctb_row, thread, SHIFT_CTB_WPP);\n\n        if (atomic_load(&s1->wpp_err)) {\n            ff_thread_report_progress2(s->avctx, ctb_row , thread, SHIFT_CTB_WPP);\n            return 0;\n        }\n\n        ret = ff_hevc_cabac_init(s, ctb_addr_ts);\n        if (ret < 0)\n            goto error;\n        hls_sao_param(s, x_ctb >> s->ps.sps->log2_ctb_size, y_ctb >> s->ps.sps->log2_ctb_size);\n        more_data = hls_coding_quadtree(s, x_ctb, y_ctb, s->ps.sps->log2_ctb_size, 0);\n\n        if (more_data < 0) {\n            ret = more_data;\n            goto error;\n        }\n\n        ctb_addr_ts++;\n\n        ff_hevc_save_states(s, ctb_addr_ts);\n        ff_thread_report_progress2(s->avctx, ctb_row, thread, 1);\n        ff_hevc_hls_filters(s, x_ctb, y_ctb, ctb_size);\n\n        if (!more_data && (x_ctb+ctb_size) < s->ps.sps->width && ctb_row != s->sh.num_entry_point_offsets) {\n            atomic_store(&s1->wpp_err, 1);\n            ff_thread_report_progress2(s->avctx, ctb_row ,thread, SHIFT_CTB_WPP);\n            return 0;\n        }\n\n        if ((x_ctb+ctb_size) >= s->ps.sps->width && (y_ctb+ctb_size) >= s->ps.sps->height ) {\n            ff_hevc_hls_filter(s, x_ctb, y_ctb, ctb_size);\n            ff_thread_report_progress2(s->avctx, ctb_row , thread, SHIFT_CTB_WPP);\n            return ctb_addr_ts;\n        }\n        ctb_addr_rs       = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts];\n        x_ctb+=ctb_size;\n\n        if(x_ctb >= s->ps.sps->width) {\n            break;\n        }\n    }\n    ff_thread_report_progress2(s->avctx, ctb_row ,thread, SHIFT_CTB_WPP);\n\n    return 0;\nerror:\n    s->tab_slice_address[ctb_addr_rs] = -1;\n    atomic_store(&s1->wpp_err, 1);\n    ff_thread_report_progress2(s->avctx, ctb_row ,thread, SHIFT_CTB_WPP);\n    return ret;\n}\n\nstatic int hls_slice_data_wpp(HEVCContext *s, const H2645NAL *nal)\n{\n    const uint8_t *data = nal->data;\n    int length          = nal->size;\n    HEVCLocalContext *lc = s->HEVClc;\n    int *ret = av_malloc_array(s->sh.num_entry_point_offsets + 1, sizeof(int));\n    int *arg = av_malloc_array(s->sh.num_entry_point_offsets + 1, sizeof(int));\n    int64_t offset;\n    int64_t startheader, cmpt = 0;\n    int i, j, res = 0;\n\n    if (!ret || !arg) {\n        av_free(ret);\n        av_free(arg);\n        return AVERROR(ENOMEM);\n    }\n\n    if (s->sh.slice_ctb_addr_rs + s->sh.num_entry_point_offsets * s->ps.sps->ctb_width >= s->ps.sps->ctb_width * s->ps.sps->ctb_height) {\n        av_log(s->avctx, AV_LOG_ERROR, \"WPP ctb addresses are wrong (%d %d %d %d)\\n\",\n            s->sh.slice_ctb_addr_rs, s->sh.num_entry_point_offsets,\n            s->ps.sps->ctb_width, s->ps.sps->ctb_height\n        );\n        res = AVERROR_INVALIDDATA;\n        goto error;\n    }\n\n    ff_alloc_entries(s->avctx, s->sh.num_entry_point_offsets + 1);\n\n    if (!s->sList[1]) {\n        for (i = 1; i < s->threads_number; i++) {\n            s->sList[i] = av_malloc(sizeof(HEVCContext));\n            memcpy(s->sList[i], s, sizeof(HEVCContext));\n            s->HEVClcList[i] = av_mallocz(sizeof(HEVCLocalContext));\n            s->sList[i]->HEVClc = s->HEVClcList[i];\n        }\n    }\n\n    offset = (lc->gb.index >> 3);\n\n    for (j = 0, cmpt = 0, startheader = offset + s->sh.entry_point_offset[0]; j < nal->skipped_bytes; j++) {\n        if (nal->skipped_bytes_pos[j] >= offset && nal->skipped_bytes_pos[j] < startheader) {\n            startheader--;\n            cmpt++;\n        }\n    }\n\n    for (i = 1; i < s->sh.num_entry_point_offsets; i++) {\n        offset += (s->sh.entry_point_offset[i - 1] - cmpt);\n        for (j = 0, cmpt = 0, startheader = offset\n             + s->sh.entry_point_offset[i]; j < nal->skipped_bytes; j++) {\n            if (nal->skipped_bytes_pos[j] >= offset && nal->skipped_bytes_pos[j] < startheader) {\n                startheader--;\n                cmpt++;\n            }\n        }\n        s->sh.size[i - 1] = s->sh.entry_point_offset[i] - cmpt;\n        s->sh.offset[i - 1] = offset;\n\n    }\n    if (s->sh.num_entry_point_offsets != 0) {\n        offset += s->sh.entry_point_offset[s->sh.num_entry_point_offsets - 1] - cmpt;\n        if (length < offset) {\n            av_log(s->avctx, AV_LOG_ERROR, \"entry_point_offset table is corrupted\\n\");\n            res = AVERROR_INVALIDDATA;\n            goto error;\n        }\n        s->sh.size[s->sh.num_entry_point_offsets - 1] = length - offset;\n        s->sh.offset[s->sh.num_entry_point_offsets - 1] = offset;\n\n    }\n    s->data = data;\n\n    for (i = 1; i < s->threads_number; i++) {\n        s->sList[i]->HEVClc->first_qp_group = 1;\n        s->sList[i]->HEVClc->qp_y = s->sList[0]->HEVClc->qp_y;\n        memcpy(s->sList[i], s, sizeof(HEVCContext));\n        s->sList[i]->HEVClc = s->HEVClcList[i];\n    }\n\n    atomic_store(&s->wpp_err, 0);\n    ff_reset_entries(s->avctx);\n\n    for (i = 0; i <= s->sh.num_entry_point_offsets; i++) {\n        arg[i] = i;\n        ret[i] = 0;\n    }\n\n    if (s->ps.pps->entropy_coding_sync_enabled_flag)\n        s->avctx->execute2(s->avctx, hls_decode_entry_wpp, arg, ret, s->sh.num_entry_point_offsets + 1);\n\n    for (i = 0; i <= s->sh.num_entry_point_offsets; i++)\n        res += ret[i];\nerror:\n    av_free(ret);\n    av_free(arg);\n    return res;\n}\n\nstatic int set_side_data(HEVCContext *s)\n{\n    AVFrame *out = s->ref->frame;\n\n    if (s->sei.frame_packing.present &&\n        s->sei.frame_packing.arrangement_type >= 3 &&\n        s->sei.frame_packing.arrangement_type <= 5 &&\n        s->sei.frame_packing.content_interpretation_type > 0 &&\n        s->sei.frame_packing.content_interpretation_type < 3) {\n        AVStereo3D *stereo = av_stereo3d_create_side_data(out);\n        if (!stereo)\n            return AVERROR(ENOMEM);\n\n        switch (s->sei.frame_packing.arrangement_type) {\n        case 3:\n            if (s->sei.frame_packing.quincunx_subsampling)\n                stereo->type = AV_STEREO3D_SIDEBYSIDE_QUINCUNX;\n            else\n                stereo->type = AV_STEREO3D_SIDEBYSIDE;\n            break;\n        case 4:\n            stereo->type = AV_STEREO3D_TOPBOTTOM;\n            break;\n        case 5:\n            stereo->type = AV_STEREO3D_FRAMESEQUENCE;\n            break;\n        }\n\n        if (s->sei.frame_packing.content_interpretation_type == 2)\n            stereo->flags = AV_STEREO3D_FLAG_INVERT;\n\n        if (s->sei.frame_packing.arrangement_type == 5) {\n            if (s->sei.frame_packing.current_frame_is_frame0_flag)\n                stereo->view = AV_STEREO3D_VIEW_LEFT;\n            else\n                stereo->view = AV_STEREO3D_VIEW_RIGHT;\n        }\n    }\n\n    if (s->sei.display_orientation.present &&\n        (s->sei.display_orientation.anticlockwise_rotation ||\n         s->sei.display_orientation.hflip || s->sei.display_orientation.vflip)) {\n        double angle = s->sei.display_orientation.anticlockwise_rotation * 360 / (double) (1 << 16);\n        AVFrameSideData *rotation = av_frame_new_side_data(out,\n                                                           AV_FRAME_DATA_DISPLAYMATRIX,\n                                                           sizeof(int32_t) * 9);\n        if (!rotation)\n            return AVERROR(ENOMEM);\n\n        av_display_rotation_set((int32_t *)rotation->data, angle);\n        av_display_matrix_flip((int32_t *)rotation->data,\n                               s->sei.display_orientation.hflip,\n                               s->sei.display_orientation.vflip);\n    }\n\n    // Decrement the mastering display flag when IRAP frame has no_rasl_output_flag=1\n    // so the side data persists for the entire coded video sequence.\n    if (s->sei.mastering_display.present > 0 &&\n        IS_IRAP(s) && s->no_rasl_output_flag) {\n        s->sei.mastering_display.present--;\n    }\n    if (s->sei.mastering_display.present) {\n        // HEVC uses a g,b,r ordering, which we convert to a more natural r,g,b\n        const int mapping[3] = {2, 0, 1};\n        const int chroma_den = 50000;\n        const int luma_den = 10000;\n        int i;\n        AVMasteringDisplayMetadata *metadata =\n            av_mastering_display_metadata_create_side_data(out);\n        if (!metadata)\n            return AVERROR(ENOMEM);\n\n        for (i = 0; i < 3; i++) {\n            const int j = mapping[i];\n            metadata->display_primaries[i][0].num = s->sei.mastering_display.display_primaries[j][0];\n            metadata->display_primaries[i][0].den = chroma_den;\n            metadata->display_primaries[i][1].num = s->sei.mastering_display.display_primaries[j][1];\n            metadata->display_primaries[i][1].den = chroma_den;\n        }\n        metadata->white_point[0].num = s->sei.mastering_display.white_point[0];\n        metadata->white_point[0].den = chroma_den;\n        metadata->white_point[1].num = s->sei.mastering_display.white_point[1];\n        metadata->white_point[1].den = chroma_den;\n\n        metadata->max_luminance.num = s->sei.mastering_display.max_luminance;\n        metadata->max_luminance.den = luma_den;\n        metadata->min_luminance.num = s->sei.mastering_display.min_luminance;\n        metadata->min_luminance.den = luma_den;\n        metadata->has_luminance = 1;\n        metadata->has_primaries = 1;\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"Mastering Display Metadata:\\n\");\n        av_log(s->avctx, AV_LOG_DEBUG,\n               \"r(%5.4f,%5.4f) g(%5.4f,%5.4f) b(%5.4f %5.4f) wp(%5.4f, %5.4f)\\n\",\n               av_q2d(metadata->display_primaries[0][0]),\n               av_q2d(metadata->display_primaries[0][1]),\n               av_q2d(metadata->display_primaries[1][0]),\n               av_q2d(metadata->display_primaries[1][1]),\n               av_q2d(metadata->display_primaries[2][0]),\n               av_q2d(metadata->display_primaries[2][1]),\n               av_q2d(metadata->white_point[0]), av_q2d(metadata->white_point[1]));\n        av_log(s->avctx, AV_LOG_DEBUG,\n               \"min_luminance=%f, max_luminance=%f\\n\",\n               av_q2d(metadata->min_luminance), av_q2d(metadata->max_luminance));\n    }\n    // Decrement the mastering display flag when IRAP frame has no_rasl_output_flag=1\n    // so the side data persists for the entire coded video sequence.\n    if (s->sei.content_light.present > 0 &&\n        IS_IRAP(s) && s->no_rasl_output_flag) {\n        s->sei.content_light.present--;\n    }\n    if (s->sei.content_light.present) {\n        AVContentLightMetadata *metadata =\n            av_content_light_metadata_create_side_data(out);\n        if (!metadata)\n            return AVERROR(ENOMEM);\n        metadata->MaxCLL  = s->sei.content_light.max_content_light_level;\n        metadata->MaxFALL = s->sei.content_light.max_pic_average_light_level;\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"Content Light Level Metadata:\\n\");\n        av_log(s->avctx, AV_LOG_DEBUG, \"MaxCLL=%d, MaxFALL=%d\\n\",\n               metadata->MaxCLL, metadata->MaxFALL);\n    }\n\n    if (s->sei.a53_caption.a53_caption) {\n        AVFrameSideData* sd = av_frame_new_side_data(out,\n                                                     AV_FRAME_DATA_A53_CC,\n                                                     s->sei.a53_caption.a53_caption_size);\n        if (sd)\n            memcpy(sd->data, s->sei.a53_caption.a53_caption, s->sei.a53_caption.a53_caption_size);\n        av_freep(&s->sei.a53_caption.a53_caption);\n        s->sei.a53_caption.a53_caption_size = 0;\n        s->avctx->properties |= FF_CODEC_PROPERTY_CLOSED_CAPTIONS;\n    }\n\n    if (s->sei.alternative_transfer.present &&\n        av_color_transfer_name(s->sei.alternative_transfer.preferred_transfer_characteristics) &&\n        s->sei.alternative_transfer.preferred_transfer_characteristics != AVCOL_TRC_UNSPECIFIED) {\n        s->avctx->color_trc = out->color_trc = s->sei.alternative_transfer.preferred_transfer_characteristics;\n    }\n\n    return 0;\n}\n\nstatic int hevc_frame_start(HEVCContext *s)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    int pic_size_in_ctb  = ((s->ps.sps->width  >> s->ps.sps->log2_min_cb_size) + 1) *\n                           ((s->ps.sps->height >> s->ps.sps->log2_min_cb_size) + 1);\n    int ret;\n\n    memset(s->horizontal_bs, 0, s->bs_width * s->bs_height);\n    memset(s->vertical_bs,   0, s->bs_width * s->bs_height);\n    memset(s->cbf_luma,      0, s->ps.sps->min_tb_width * s->ps.sps->min_tb_height);\n    memset(s->is_pcm,        0, (s->ps.sps->min_pu_width + 1) * (s->ps.sps->min_pu_height + 1));\n    memset(s->tab_slice_address, -1, pic_size_in_ctb * sizeof(*s->tab_slice_address));\n\n    s->is_decoded        = 0;\n    s->first_nal_type    = s->nal_unit_type;\n\n    s->no_rasl_output_flag = IS_IDR(s) || IS_BLA(s) || (s->nal_unit_type == HEVC_NAL_CRA_NUT && s->last_eos);\n\n    if (s->ps.pps->tiles_enabled_flag)\n        lc->end_of_tiles_x = s->ps.pps->column_width[0] << s->ps.sps->log2_ctb_size;\n\n    ret = ff_hevc_set_new_ref(s, &s->frame, s->poc);\n    if (ret < 0)\n        goto fail;\n\n    ret = ff_hevc_frame_rps(s);\n    if (ret < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Error constructing the frame RPS.\\n\");\n        goto fail;\n    }\n\n    s->ref->frame->key_frame = IS_IRAP(s);\n\n    ret = set_side_data(s);\n    if (ret < 0)\n        goto fail;\n\n    s->frame->pict_type = 3 - s->sh.slice_type;\n\n    if (!IS_IRAP(s))\n        ff_hevc_bump_frame(s);\n\n    av_frame_unref(s->output_frame);\n    ret = ff_hevc_output_frame(s, s->output_frame, 0);\n    if (ret < 0)\n        goto fail;\n\n    if (!s->avctx->hwaccel)\n        ff_thread_finish_setup(s->avctx);\n\n    return 0;\n\nfail:\n    if (s->ref)\n        ff_hevc_unref_frame(s, s->ref, ~0);\n    s->ref = NULL;\n    return ret;\n}\n\nstatic int decode_nal_unit(HEVCContext *s, const H2645NAL *nal)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    GetBitContext *gb    = &lc->gb;\n    int ctb_addr_ts, ret;\n\n    *gb              = nal->gb;\n    s->nal_unit_type = nal->type;\n    s->temporal_id   = nal->temporal_id;\n\n    switch (s->nal_unit_type) {\n    case HEVC_NAL_VPS:\n        if (s->avctx->hwaccel && s->avctx->hwaccel->decode_params) {\n            ret = s->avctx->hwaccel->decode_params(s->avctx,\n                                                   nal->type,\n                                                   nal->raw_data,\n                                                   nal->raw_size);\n            if (ret < 0)\n                goto fail;\n        }\n        ret = ff_hevc_decode_nal_vps(gb, s->avctx, &s->ps);\n        if (ret < 0)\n            goto fail;\n        break;\n    case HEVC_NAL_SPS:\n        if (s->avctx->hwaccel && s->avctx->hwaccel->decode_params) {\n            ret = s->avctx->hwaccel->decode_params(s->avctx,\n                                                   nal->type,\n                                                   nal->raw_data,\n                                                   nal->raw_size);\n            if (ret < 0)\n                goto fail;\n        }\n        ret = ff_hevc_decode_nal_sps(gb, s->avctx, &s->ps,\n                                     s->apply_defdispwin);\n        if (ret < 0)\n            goto fail;\n        break;\n    case HEVC_NAL_PPS:\n        if (s->avctx->hwaccel && s->avctx->hwaccel->decode_params) {\n            ret = s->avctx->hwaccel->decode_params(s->avctx,\n                                                   nal->type,\n                                                   nal->raw_data,\n                                                   nal->raw_size);\n            if (ret < 0)\n                goto fail;\n        }\n        ret = ff_hevc_decode_nal_pps(gb, s->avctx, &s->ps);\n        if (ret < 0)\n            goto fail;\n        break;\n    case HEVC_NAL_SEI_PREFIX:\n    case HEVC_NAL_SEI_SUFFIX:\n        if (s->avctx->hwaccel && s->avctx->hwaccel->decode_params) {\n            ret = s->avctx->hwaccel->decode_params(s->avctx,\n                                                   nal->type,\n                                                   nal->raw_data,\n                                                   nal->raw_size);\n            if (ret < 0)\n                goto fail;\n        }\n        ret = ff_hevc_decode_nal_sei(gb, s->avctx, &s->sei, &s->ps, s->nal_unit_type);\n        if (ret < 0)\n            goto fail;\n        break;\n    case HEVC_NAL_TRAIL_R:\n    case HEVC_NAL_TRAIL_N:\n    case HEVC_NAL_TSA_N:\n    case HEVC_NAL_TSA_R:\n    case HEVC_NAL_STSA_N:\n    case HEVC_NAL_STSA_R:\n    case HEVC_NAL_BLA_W_LP:\n    case HEVC_NAL_BLA_W_RADL:\n    case HEVC_NAL_BLA_N_LP:\n    case HEVC_NAL_IDR_W_RADL:\n    case HEVC_NAL_IDR_N_LP:\n    case HEVC_NAL_CRA_NUT:\n    case HEVC_NAL_RADL_N:\n    case HEVC_NAL_RADL_R:\n    case HEVC_NAL_RASL_N:\n    case HEVC_NAL_RASL_R:\n        ret = hls_slice_header(s);\n        if (ret < 0)\n            return ret;\n        if (ret == 1) {\n            ret = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n\n\n        if (\n            (s->avctx->skip_frame >= AVDISCARD_BIDIR && s->sh.slice_type == HEVC_SLICE_B) ||\n            (s->avctx->skip_frame >= AVDISCARD_NONINTRA && s->sh.slice_type != HEVC_SLICE_I) ||\n            (s->avctx->skip_frame >= AVDISCARD_NONKEY && !IS_IRAP(s))) {\n            break;\n        }\n\n        if (s->sh.first_slice_in_pic_flag) {\n            if (s->max_ra == INT_MAX) {\n                if (s->nal_unit_type == HEVC_NAL_CRA_NUT || IS_BLA(s)) {\n                    s->max_ra = s->poc;\n                } else {\n                    if (IS_IDR(s))\n                        s->max_ra = INT_MIN;\n                }\n            }\n\n            if ((s->nal_unit_type == HEVC_NAL_RASL_R || s->nal_unit_type == HEVC_NAL_RASL_N) &&\n                s->poc <= s->max_ra) {\n                s->is_decoded = 0;\n                break;\n            } else {\n                if (s->nal_unit_type == HEVC_NAL_RASL_R && s->poc > s->max_ra)\n                    s->max_ra = INT_MIN;\n            }\n\n            s->overlap ++;\n            ret = hevc_frame_start(s);\n            if (ret < 0)\n                return ret;\n        } else if (!s->ref) {\n            av_log(s->avctx, AV_LOG_ERROR, \"First slice in a frame missing.\\n\");\n            goto fail;\n        }\n\n        if (s->nal_unit_type != s->first_nal_type) {\n            av_log(s->avctx, AV_LOG_ERROR,\n                   \"Non-matching NAL types of the VCL NALUs: %d %d\\n\",\n                   s->first_nal_type, s->nal_unit_type);\n            return AVERROR_INVALIDDATA;\n        }\n\n        if (!s->sh.dependent_slice_segment_flag &&\n            s->sh.slice_type != HEVC_SLICE_I) {\n            ret = ff_hevc_slice_rpl(s);\n            if (ret < 0) {\n                av_log(s->avctx, AV_LOG_WARNING,\n                       \"Error constructing the reference lists for the current slice.\\n\");\n                goto fail;\n            }\n        }\n\n        if (s->sh.first_slice_in_pic_flag && s->avctx->hwaccel) {\n            ret = s->avctx->hwaccel->start_frame(s->avctx, NULL, 0);\n            if (ret < 0)\n                goto fail;\n        }\n\n        if (s->avctx->hwaccel) {\n            ret = s->avctx->hwaccel->decode_slice(s->avctx, nal->raw_data, nal->raw_size);\n            if (ret < 0)\n                goto fail;\n        } else {\n            if (s->threads_number > 1 && s->sh.num_entry_point_offsets > 0)\n                ctb_addr_ts = hls_slice_data_wpp(s, nal);\n            else\n                ctb_addr_ts = hls_slice_data(s);\n            if (ctb_addr_ts >= (s->ps.sps->ctb_width * s->ps.sps->ctb_height)) {\n                s->is_decoded = 1;\n            }\n\n            if (ctb_addr_ts < 0) {\n                ret = ctb_addr_ts;\n                goto fail;\n            }\n        }\n        break;\n    case HEVC_NAL_EOS_NUT:\n    case HEVC_NAL_EOB_NUT:\n        s->seq_decode = (s->seq_decode + 1) & 0xff;\n        s->max_ra     = INT_MAX;\n        break;\n    case HEVC_NAL_AUD:\n    case HEVC_NAL_FD_NUT:\n        break;\n    default:\n        av_log(s->avctx, AV_LOG_INFO,\n               \"Skipping NAL unit %d\\n\", s->nal_unit_type);\n    }\n\n    return 0;\nfail:\n    if (s->avctx->err_recognition & AV_EF_EXPLODE)\n        return ret;\n    return 0;\n}\n\nstatic int decode_nal_units(HEVCContext *s, const uint8_t *buf, int length)\n{\n    int i, ret = 0;\n    int eos_at_start = 1;\n\n    s->ref = NULL;\n    s->last_eos = s->eos;\n    s->eos = 0;\n    s->overlap = 0;\n\n    /* split the input packet into NAL units, so we know the upper bound on the\n     * number of slices in the frame */\n    ret = ff_h2645_packet_split(&s->pkt, buf, length, s->avctx, s->is_nalff,\n                                s->nal_length_size, s->avctx->codec_id, 1, 0);\n    if (ret < 0) {\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"Error splitting the input into NAL units.\\n\");\n        return ret;\n    }\n\n    for (i = 0; i < s->pkt.nb_nals; i++) {\n        if (s->pkt.nals[i].type == HEVC_NAL_EOB_NUT ||\n            s->pkt.nals[i].type == HEVC_NAL_EOS_NUT) {\n            if (eos_at_start) {\n                s->last_eos = 1;\n            } else {\n                s->eos = 1;\n            }\n        } else {\n            eos_at_start = 0;\n        }\n    }\n\n    /* decode the NAL units */\n    for (i = 0; i < s->pkt.nb_nals; i++) {\n        H2645NAL *nal = &s->pkt.nals[i];\n\n        if (s->avctx->skip_frame >= AVDISCARD_ALL ||\n            (s->avctx->skip_frame >= AVDISCARD_NONREF\n            && ff_hevc_nal_is_nonref(nal->type)))\n            continue;\n\n        ret = decode_nal_unit(s, nal);\n        if (ret >= 0 && s->overlap > 2)\n            ret = AVERROR_INVALIDDATA;\n        if (ret < 0) {\n            av_log(s->avctx, AV_LOG_WARNING,\n                   \"Error parsing NAL unit #%d.\\n\", i);\n            goto fail;\n        }\n    }\n\nfail:\n    if (s->ref && s->threads_type == FF_THREAD_FRAME)\n        ff_thread_report_progress(&s->ref->tf, INT_MAX, 0);\n\n    return ret;\n}\n\nstatic void print_md5(void *log_ctx, int level, uint8_t md5[16])\n{\n    int i;\n    for (i = 0; i < 16; i++)\n        av_log(log_ctx, level, \"%02\"PRIx8, md5[i]);\n}\n\nstatic int verify_md5(HEVCContext *s, AVFrame *frame)\n{\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frame->format);\n    int pixel_shift;\n    int i, j;\n\n    if (!desc)\n        return AVERROR(EINVAL);\n\n    pixel_shift = desc->comp[0].depth > 8;\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"Verifying checksum for frame with POC %d: \",\n           s->poc);\n\n    /* the checksums are LE, so we have to byteswap for >8bpp formats\n     * on BE arches */\n#if HAVE_BIGENDIAN\n    if (pixel_shift && !s->checksum_buf) {\n        av_fast_malloc(&s->checksum_buf, &s->checksum_buf_size,\n                       FFMAX3(frame->linesize[0], frame->linesize[1],\n                              frame->linesize[2]));\n        if (!s->checksum_buf)\n            return AVERROR(ENOMEM);\n    }\n#endif\n\n    for (i = 0; frame->data[i]; i++) {\n        int width  = s->avctx->coded_width;\n        int height = s->avctx->coded_height;\n        int w = (i == 1 || i == 2) ? (width  >> desc->log2_chroma_w) : width;\n        int h = (i == 1 || i == 2) ? (height >> desc->log2_chroma_h) : height;\n        uint8_t md5[16];\n\n        av_md5_init(s->md5_ctx);\n        for (j = 0; j < h; j++) {\n            const uint8_t *src = frame->data[i] + j * frame->linesize[i];\n#if HAVE_BIGENDIAN\n            if (pixel_shift) {\n                s->bdsp.bswap16_buf((uint16_t *) s->checksum_buf,\n                                    (const uint16_t *) src, w);\n                src = s->checksum_buf;\n            }\n#endif\n            av_md5_update(s->md5_ctx, src, w << pixel_shift);\n        }\n        av_md5_final(s->md5_ctx, md5);\n\n        if (!memcmp(md5, s->sei.picture_hash.md5[i], 16)) {\n            av_log   (s->avctx, AV_LOG_DEBUG, \"plane %d - correct \", i);\n            print_md5(s->avctx, AV_LOG_DEBUG, md5);\n            av_log   (s->avctx, AV_LOG_DEBUG, \"; \");\n        } else {\n            av_log   (s->avctx, AV_LOG_ERROR, \"mismatching checksum of plane %d - \", i);\n            print_md5(s->avctx, AV_LOG_ERROR, md5);\n            av_log   (s->avctx, AV_LOG_ERROR, \" != \");\n            print_md5(s->avctx, AV_LOG_ERROR, s->sei.picture_hash.md5[i]);\n            av_log   (s->avctx, AV_LOG_ERROR, \"\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"\\n\");\n\n    return 0;\n}\n\nstatic int hevc_decode_extradata(HEVCContext *s, uint8_t *buf, int length, int first)\n{\n    int ret, i;\n\n    ret = ff_hevc_decode_extradata(buf, length, &s->ps, &s->sei, &s->is_nalff,\n                                   &s->nal_length_size, s->avctx->err_recognition,\n                                   s->apply_defdispwin, s->avctx);\n    if (ret < 0)\n        return ret;\n\n    /* export stream parameters from the first SPS */\n    for (i = 0; i < FF_ARRAY_ELEMS(s->ps.sps_list); i++) {\n        if (first && s->ps.sps_list[i]) {\n            const HEVCSPS *sps = (const HEVCSPS*)s->ps.sps_list[i]->data;\n            export_stream_params(s->avctx, &s->ps, sps);\n            break;\n        }\n    }\n\n    return 0;\n}\n\nstatic int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,\n                             AVPacket *avpkt)\n{\n    int ret;\n    int new_extradata_size;\n    uint8_t *new_extradata;\n    HEVCContext *s = avctx->priv_data;\n\n    if (!avpkt->size) {\n        ret = ff_hevc_output_frame(s, data, 1);\n        if (ret < 0)\n            return ret;\n\n        *got_output = ret;\n        return 0;\n    }\n\n    new_extradata = av_packet_get_side_data(avpkt, AV_PKT_DATA_NEW_EXTRADATA,\n                                            &new_extradata_size);\n    if (new_extradata && new_extradata_size > 0) {\n        ret = hevc_decode_extradata(s, new_extradata, new_extradata_size, 0);\n        if (ret < 0)\n            return ret;\n    }\n\n    s->ref = NULL;\n    ret    = decode_nal_units(s, avpkt->data, avpkt->size);\n    if (ret < 0)\n        return ret;\n\n    if (avctx->hwaccel) {\n        if (s->ref && (ret = avctx->hwaccel->end_frame(avctx)) < 0) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"hardware accelerator failed to decode picture\\n\");\n            ff_hevc_unref_frame(s, s->ref, ~0);\n            return ret;\n        }\n    } else {\n        /* verify the SEI checksum */\n        if (avctx->err_recognition & AV_EF_CRCCHECK && s->is_decoded &&\n            s->sei.picture_hash.is_md5) {\n            ret = verify_md5(s, s->ref->frame);\n            if (ret < 0 && avctx->err_recognition & AV_EF_EXPLODE) {\n                ff_hevc_unref_frame(s, s->ref, ~0);\n                return ret;\n            }\n        }\n    }\n    s->sei.picture_hash.is_md5 = 0;\n\n    if (s->is_decoded) {\n        av_log(avctx, AV_LOG_DEBUG, \"Decoded frame with POC %d.\\n\", s->poc);\n        s->is_decoded = 0;\n    }\n\n    if (s->output_frame->buf[0]) {\n        av_frame_move_ref(data, s->output_frame);\n        *got_output = 1;\n    }\n\n    return avpkt->size;\n}\n\nstatic int hevc_ref_frame(HEVCContext *s, HEVCFrame *dst, HEVCFrame *src)\n{\n    int ret;\n\n    ret = ff_thread_ref_frame(&dst->tf, &src->tf);\n    if (ret < 0)\n        return ret;\n\n    dst->tab_mvf_buf = av_buffer_ref(src->tab_mvf_buf);\n    if (!dst->tab_mvf_buf)\n        goto fail;\n    dst->tab_mvf = src->tab_mvf;\n\n    dst->rpl_tab_buf = av_buffer_ref(src->rpl_tab_buf);\n    if (!dst->rpl_tab_buf)\n        goto fail;\n    dst->rpl_tab = src->rpl_tab;\n\n    dst->rpl_buf = av_buffer_ref(src->rpl_buf);\n    if (!dst->rpl_buf)\n        goto fail;\n\n    dst->poc        = src->poc;\n    dst->ctb_count  = src->ctb_count;\n    dst->flags      = src->flags;\n    dst->sequence   = src->sequence;\n\n    if (src->hwaccel_picture_private) {\n        dst->hwaccel_priv_buf = av_buffer_ref(src->hwaccel_priv_buf);\n        if (!dst->hwaccel_priv_buf)\n            goto fail;\n        dst->hwaccel_picture_private = dst->hwaccel_priv_buf->data;\n    }\n\n    return 0;\nfail:\n    ff_hevc_unref_frame(s, dst, ~0);\n    return AVERROR(ENOMEM);\n}\n\nstatic av_cold int hevc_decode_free(AVCodecContext *avctx)\n{\n    HEVCContext       *s = avctx->priv_data;\n    int i;\n\n    pic_arrays_free(s);\n\n    av_freep(&s->md5_ctx);\n\n    av_freep(&s->cabac_state);\n\n    for (i = 0; i < 3; i++) {\n        av_freep(&s->sao_pixel_buffer_h[i]);\n        av_freep(&s->sao_pixel_buffer_v[i]);\n    }\n    av_frame_free(&s->output_frame);\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {\n        ff_hevc_unref_frame(s, &s->DPB[i], ~0);\n        av_frame_free(&s->DPB[i].frame);\n    }\n\n    ff_hevc_ps_uninit(&s->ps);\n\n    av_freep(&s->sh.entry_point_offset);\n    av_freep(&s->sh.offset);\n    av_freep(&s->sh.size);\n\n    for (i = 1; i < s->threads_number; i++) {\n        HEVCLocalContext *lc = s->HEVClcList[i];\n        if (lc) {\n            av_freep(&s->HEVClcList[i]);\n            av_freep(&s->sList[i]);\n        }\n    }\n    if (s->HEVClc == s->HEVClcList[0])\n        s->HEVClc = NULL;\n    av_freep(&s->HEVClcList[0]);\n\n    ff_h2645_packet_uninit(&s->pkt);\n\n    return 0;\n}\n\nstatic av_cold int hevc_init_context(AVCodecContext *avctx)\n{\n    HEVCContext *s = avctx->priv_data;\n    int i;\n\n    s->avctx = avctx;\n\n    s->HEVClc = av_mallocz(sizeof(HEVCLocalContext));\n    if (!s->HEVClc)\n        goto fail;\n    s->HEVClcList[0] = s->HEVClc;\n    s->sList[0] = s;\n\n    s->cabac_state = av_malloc(HEVC_CONTEXTS);\n    if (!s->cabac_state)\n        goto fail;\n\n    s->output_frame = av_frame_alloc();\n    if (!s->output_frame)\n        goto fail;\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {\n        s->DPB[i].frame = av_frame_alloc();\n        if (!s->DPB[i].frame)\n            goto fail;\n        s->DPB[i].tf.f = s->DPB[i].frame;\n    }\n\n    s->max_ra = INT_MAX;\n\n    s->md5_ctx = av_md5_alloc();\n    if (!s->md5_ctx)\n        goto fail;\n\n    ff_bswapdsp_init(&s->bdsp);\n\n    s->context_initialized = 1;\n    s->eos = 0;\n\n    ff_hevc_reset_sei(&s->sei);\n\n    return 0;\n\nfail:\n    hevc_decode_free(avctx);\n    return AVERROR(ENOMEM);\n}\n\n#if HAVE_THREADS\nstatic int hevc_update_thread_context(AVCodecContext *dst,\n                                      const AVCodecContext *src)\n{\n    HEVCContext *s  = dst->priv_data;\n    HEVCContext *s0 = src->priv_data;\n    int i, ret;\n\n    if (!s->context_initialized) {\n        ret = hevc_init_context(dst);\n        if (ret < 0)\n            return ret;\n    }\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {\n        ff_hevc_unref_frame(s, &s->DPB[i], ~0);\n        if (s0->DPB[i].frame->buf[0]) {\n            ret = hevc_ref_frame(s, &s->DPB[i], &s0->DPB[i]);\n            if (ret < 0)\n                return ret;\n        }\n    }\n\n    if (s->ps.sps != s0->ps.sps)\n        s->ps.sps = NULL;\n    for (i = 0; i < FF_ARRAY_ELEMS(s->ps.vps_list); i++) {\n        av_buffer_unref(&s->ps.vps_list[i]);\n        if (s0->ps.vps_list[i]) {\n            s->ps.vps_list[i] = av_buffer_ref(s0->ps.vps_list[i]);\n            if (!s->ps.vps_list[i])\n                return AVERROR(ENOMEM);\n        }\n    }\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->ps.sps_list); i++) {\n        av_buffer_unref(&s->ps.sps_list[i]);\n        if (s0->ps.sps_list[i]) {\n            s->ps.sps_list[i] = av_buffer_ref(s0->ps.sps_list[i]);\n            if (!s->ps.sps_list[i])\n                return AVERROR(ENOMEM);\n        }\n    }\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->ps.pps_list); i++) {\n        av_buffer_unref(&s->ps.pps_list[i]);\n        if (s0->ps.pps_list[i]) {\n            s->ps.pps_list[i] = av_buffer_ref(s0->ps.pps_list[i]);\n            if (!s->ps.pps_list[i])\n                return AVERROR(ENOMEM);\n        }\n    }\n\n    if (s->ps.sps != s0->ps.sps)\n        if ((ret = set_sps(s, s0->ps.sps, src->pix_fmt)) < 0)\n            return ret;\n\n    s->seq_decode = s0->seq_decode;\n    s->seq_output = s0->seq_output;\n    s->pocTid0    = s0->pocTid0;\n    s->max_ra     = s0->max_ra;\n    s->eos        = s0->eos;\n    s->no_rasl_output_flag = s0->no_rasl_output_flag;\n\n    s->is_nalff        = s0->is_nalff;\n    s->nal_length_size = s0->nal_length_size;\n\n    s->threads_number      = s0->threads_number;\n    s->threads_type        = s0->threads_type;\n\n    if (s0->eos) {\n        s->seq_decode = (s->seq_decode + 1) & 0xff;\n        s->max_ra = INT_MAX;\n    }\n\n    s->sei.frame_packing        = s0->sei.frame_packing;\n    s->sei.display_orientation  = s0->sei.display_orientation;\n    s->sei.mastering_display    = s0->sei.mastering_display;\n    s->sei.content_light        = s0->sei.content_light;\n    s->sei.alternative_transfer = s0->sei.alternative_transfer;\n\n    return 0;\n}\n#endif\n\nstatic av_cold int hevc_decode_init(AVCodecContext *avctx)\n{\n    HEVCContext *s = avctx->priv_data;\n    int ret;\n\n    avctx->internal->allocate_progress = 1;\n\n    ret = hevc_init_context(avctx);\n    if (ret < 0)\n        return ret;\n\n    s->enable_parallel_tiles = 0;\n    s->sei.picture_timing.picture_struct = 0;\n    s->eos = 1;\n\n    atomic_init(&s->wpp_err, 0);\n\n    if(avctx->active_thread_type & FF_THREAD_SLICE)\n        s->threads_number = avctx->thread_count;\n    else\n        s->threads_number = 1;\n\n    if (avctx->extradata_size > 0 && avctx->extradata) {\n        ret = hevc_decode_extradata(s, avctx->extradata, avctx->extradata_size, 1);\n        if (ret < 0) {\n            hevc_decode_free(avctx);\n            return ret;\n        }\n    }\n\n    if((avctx->active_thread_type & FF_THREAD_FRAME) && avctx->thread_count > 1)\n            s->threads_type = FF_THREAD_FRAME;\n        else\n            s->threads_type = FF_THREAD_SLICE;\n\n    return 0;\n}\n\n#if HAVE_THREADS\nstatic av_cold int hevc_init_thread_copy(AVCodecContext *avctx)\n{\n    HEVCContext *s = avctx->priv_data;\n    int ret;\n\n    memset(s, 0, sizeof(*s));\n\n    ret = hevc_init_context(avctx);\n    if (ret < 0)\n        return ret;\n\n    return 0;\n}\n#endif\n\nstatic void hevc_decode_flush(AVCodecContext *avctx)\n{\n    HEVCContext *s = avctx->priv_data;\n    ff_hevc_flush_dpb(s);\n    s->max_ra = INT_MAX;\n    s->eos = 1;\n}\n\n#define OFFSET(x) offsetof(HEVCContext, x)\n#define PAR (AV_OPT_FLAG_DECODING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)\n\nstatic const AVOption options[] = {\n    { \"apply_defdispwin\", \"Apply default display window from VUI\", OFFSET(apply_defdispwin),\n        AV_OPT_TYPE_BOOL, {.i64 = 0}, 0, 1, PAR },\n    { \"strict-displaywin\", \"stricly apply default display window size\", OFFSET(apply_defdispwin),\n        AV_OPT_TYPE_BOOL, {.i64 = 0}, 0, 1, PAR },\n    { NULL },\n};\n\nstatic const AVClass hevc_decoder_class = {\n    .class_name = \"HEVC decoder\",\n    .item_name  = av_default_item_name,\n    .option     = options,\n    .version    = LIBAVUTIL_VERSION_INT,\n};\n\nAVCodec ff_hevc_decoder = {\n    .name                  = \"hevc\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"HEVC (High Efficiency Video Coding)\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_HEVC,\n    .priv_data_size        = sizeof(HEVCContext),\n    .priv_class            = &hevc_decoder_class,\n    .init                  = hevc_decode_init,\n    .close                 = hevc_decode_free,\n    .decode                = hevc_decode_frame,\n    .flush                 = hevc_decode_flush,\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(hevc_update_thread_context),\n    .init_thread_copy      = ONLY_IF_THREADS_ENABLED(hevc_init_thread_copy),\n    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_DELAY |\n                             AV_CODEC_CAP_SLICE_THREADS | AV_CODEC_CAP_FRAME_THREADS,\n    .caps_internal         = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_EXPORTS_CROPPING,\n    .profiles              = NULL_IF_CONFIG_SMALL(ff_hevc_profiles),\n    .hw_configs            = (const AVCodecHWConfigInternal*[]) {\n#if CONFIG_HEVC_DXVA2_HWACCEL\n                               HWACCEL_DXVA2(hevc),\n#endif\n#if CONFIG_HEVC_D3D11VA_HWACCEL\n                               HWACCEL_D3D11VA(hevc),\n#endif\n#if CONFIG_HEVC_D3D11VA2_HWACCEL\n                               HWACCEL_D3D11VA2(hevc),\n#endif\n#if CONFIG_HEVC_NVDEC_HWACCEL\n                               HWACCEL_NVDEC(hevc),\n#endif\n#if CONFIG_HEVC_VAAPI_HWACCEL\n                               HWACCEL_VAAPI(hevc),\n#endif\n#if CONFIG_HEVC_VDPAU_HWACCEL\n                               HWACCEL_VDPAU(hevc),\n#endif\n#if CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL\n                               HWACCEL_VIDEOTOOLBOX(hevc),\n#endif\n                               NULL\n                           },\n};\n"], "filenames": ["libavcodec/hevcdec.c"], "buggy_code_start_loc": [490], "buggy_code_end_loc": [2934], "fixing_code_start_loc": [491], "fixing_code_end_loc": [2939], "type": "CWE-476", "message": "libavcodec/hevcdec.c in FFmpeg 3.4 and 4.1.2 mishandles detection of duplicate first slices, which allows remote attackers to cause a denial of service (NULL pointer dereference and out-of-array access) or possibly have unspecified other impact via crafted HEVC data.", "other": {"cve": {"id": "CVE-2019-11338", "sourceIdentifier": "cve@mitre.org", "published": "2019-04-19T00:29:00.230", "lastModified": "2022-10-07T17:50:49.737", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "libavcodec/hevcdec.c in FFmpeg 3.4 and 4.1.2 mishandles detection of duplicate first slices, which allows remote attackers to cause a denial of service (NULL pointer dereference and out-of-array access) or possibly have unspecified other impact via crafted HEVC data."}, {"lang": "es", "value": "libavcodec/hevcdec.c en FFmpeg versi\u00f3n 3.4 y versi\u00f3n 4.1.2 maneja de forma incorrecta la detecci\u00f3n de los primeros cortes duplicados, lo que permite a los atacantes remotos causar una denegaci\u00f3n de servicio (desreferencia de puntero NULL y acceso fuera de l\u00edmites) o posiblemente tener otro impacto no especificado a trav\u00e9s de datos HEVC dise\u00f1ados."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:3.4:*:*:*:*:*:*:*", "matchCriteriaId": "4BFDA7F5-FE3F-4D4A-AE46-43251194C127"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:4.1.2:*:*:*:*:*:*:*", "matchCriteriaId": "E5CE572B-0FDD-4EB6-BB86-AD793CAF40BA"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:novell:suse_package_hub_for_suse_linux_enterprise:12:*:*:*:*:*:*:*", "matchCriteriaId": "B5BEF8F1-A70F-455C-BFDD-09E0A658F702"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:16.04:*:*:*:esm:*:*:*", "matchCriteriaId": "7A5301BF-1402-4BE0-A0F8-69FBE79BC6D6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:18.04:*:*:*:lts:*:*:*", "matchCriteriaId": "23A7C53F-B80F-4E6A-AFA9-58EEA84BE11D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:18.10:*:*:*:*:*:*:*", "matchCriteriaId": "07C312A0-CD2C-4B9C-B064-6409B25C278F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:19.04:*:*:*:*:*:*:*", "matchCriteriaId": "CD783B0C-9246-47D9-A937-6144FE8BFF0F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:20.04:*:*:*:lts:*:*:*", "matchCriteriaId": "902B8056-9E37-443B-8905-8AA93E2447FB"}]}]}], "references": [{"url": "http://lists.opensuse.org/opensuse-security-announce/2020-01/msg00012.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/108034", "source": "cve@mitre.org", "tags": ["Broken Link"]}, {"url": "https://github.com/FFmpeg/FFmpeg/commit/54655623a82632e7624714d7b2a3e039dc5faa7e", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/FFmpeg/FFmpeg/commit/9ccc633068c6fe76989f487c8932bd11886ad65b", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2019/05/msg00043.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://seclists.org/bugtraq/2019/May/60", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3967-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4431-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.debian.org/security/2019/dsa-4449", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/FFmpeg/FFmpeg/commit/54655623a82632e7624714d7b2a3e039dc5faa7e"}}
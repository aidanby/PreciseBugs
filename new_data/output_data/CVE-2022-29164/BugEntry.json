{"buggy_code": ["package apiserver\n\nimport (\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/gorilla/handlers\"\n\tgrpc_middleware \"github.com/grpc-ecosystem/go-grpc-middleware\"\n\tgrpc_logrus \"github.com/grpc-ecosystem/go-grpc-middleware/logging/logrus\"\n\tgrpc_prometheus \"github.com/grpc-ecosystem/go-grpc-prometheus\"\n\t\"github.com/grpc-ecosystem/grpc-gateway/runtime\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"github.com/soheilhy/cmux\"\n\t\"golang.org/x/net/context\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/credentials\"\n\t\"google.golang.org/grpc/credentials/insecure\"\n\t\"google.golang.org/grpc/metadata\"\n\tv1 \"k8s.io/api/core/v1\"\n\t\"k8s.io/apimachinery/pkg/util/wait\"\n\t\"k8s.io/client-go/rest\"\n\t\"k8s.io/utils/env\"\n\n\t\"github.com/argoproj/argo-workflows/v3\"\n\t\"github.com/argoproj/argo-workflows/v3/config\"\n\t\"github.com/argoproj/argo-workflows/v3/persist/sqldb\"\n\tclusterwftemplatepkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/clusterworkflowtemplate\"\n\tcronworkflowpkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/cronworkflow\"\n\teventpkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/event\"\n\teventsourcepkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/eventsource\"\n\tinfopkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/info\"\n\tpipelinepkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/pipeline\"\n\tsensorpkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/sensor\"\n\tworkflowpkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/workflow\"\n\tworkflowarchivepkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/workflowarchive\"\n\tworkflowtemplatepkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/workflowtemplate\"\n\t\"github.com/argoproj/argo-workflows/v3/pkg/apis/workflow/v1alpha1\"\n\t\"github.com/argoproj/argo-workflows/v3/server/apiserver/accesslog\"\n\t\"github.com/argoproj/argo-workflows/v3/server/artifacts\"\n\t\"github.com/argoproj/argo-workflows/v3/server/auth\"\n\t\"github.com/argoproj/argo-workflows/v3/server/auth/sso\"\n\t\"github.com/argoproj/argo-workflows/v3/server/auth/webhook\"\n\t\"github.com/argoproj/argo-workflows/v3/server/cache\"\n\t\"github.com/argoproj/argo-workflows/v3/server/clusterworkflowtemplate\"\n\t\"github.com/argoproj/argo-workflows/v3/server/cronworkflow\"\n\t\"github.com/argoproj/argo-workflows/v3/server/event\"\n\t\"github.com/argoproj/argo-workflows/v3/server/eventsource\"\n\t\"github.com/argoproj/argo-workflows/v3/server/info\"\n\tpipeline \"github.com/argoproj/argo-workflows/v3/server/pipeline\"\n\t\"github.com/argoproj/argo-workflows/v3/server/sensor\"\n\t\"github.com/argoproj/argo-workflows/v3/server/static\"\n\t\"github.com/argoproj/argo-workflows/v3/server/types\"\n\t\"github.com/argoproj/argo-workflows/v3/server/workflow\"\n\t\"github.com/argoproj/argo-workflows/v3/server/workflowarchive\"\n\t\"github.com/argoproj/argo-workflows/v3/server/workflowtemplate\"\n\tgrpcutil \"github.com/argoproj/argo-workflows/v3/util/grpc\"\n\t\"github.com/argoproj/argo-workflows/v3/util/instanceid\"\n\t\"github.com/argoproj/argo-workflows/v3/util/json\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/artifactrepositories\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/events\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/hydrator\"\n)\n\nvar MaxGRPCMessageSize int\n\ntype argoServer struct {\n\tbaseHRef string\n\t// https://itnext.io/practical-guide-to-securing-grpc-connections-with-go-and-tls-part-1-f63058e9d6d1\n\ttlsConfig                *tls.Config\n\thsts                     bool\n\tnamespace                string\n\tmanagedNamespace         string\n\tclients                  *types.Clients\n\tgatekeeper               auth.Gatekeeper\n\toAuth2Service            sso.Interface\n\tconfigController         config.Controller\n\tstopCh                   chan struct{}\n\teventQueueSize           int\n\teventWorkerCount         int\n\teventAsyncDispatch       bool\n\txframeOptions            string\n\taccessControlAllowOrigin string\n\tcache                    *cache.ResourceCache\n}\n\ntype ArgoServerOpts struct {\n\tBaseHRef   string\n\tTLSConfig  *tls.Config\n\tNamespaced bool\n\tNamespace  string\n\tClients    *types.Clients\n\tRestConfig *rest.Config\n\tAuthModes  auth.Modes\n\t// config map name\n\tConfigName               string\n\tManagedNamespace         string\n\tSSONameSpace             string\n\tHSTS                     bool\n\tEventOperationQueueSize  int\n\tEventWorkerCount         int\n\tEventAsyncDispatch       bool\n\tXFrameOptions            string\n\tAccessControlAllowOrigin string\n}\n\nfunc init() {\n\tvar err error\n\tMaxGRPCMessageSize, err = env.GetInt(\"GRPC_MESSAGE_SIZE\", 100*1024*1024)\n\tif err != nil {\n\t\tlog.Fatalf(\"GRPC_MESSAGE_SIZE environment variable must be set as an integer: %v\", err)\n\t}\n}\n\nfunc getResourceCacheNamespace(opts ArgoServerOpts) string {\n\tif opts.Namespaced {\n\t\treturn opts.SSONameSpace\n\t}\n\treturn v1.NamespaceAll\n}\n\nfunc NewArgoServer(ctx context.Context, opts ArgoServerOpts) (*argoServer, error) {\n\tconfigController := config.NewController(opts.Namespace, opts.ConfigName, opts.Clients.Kubernetes)\n\tvar resourceCache *cache.ResourceCache = nil\n\tssoIf := sso.NullSSO\n\tif opts.AuthModes[auth.SSO] {\n\t\tc, err := configController.Get(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tssoIf, err = sso.New(c.SSO, opts.Clients.Kubernetes.CoreV1().Secrets(opts.Namespace), opts.BaseHRef, opts.TLSConfig != nil)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tresourceCache = cache.NewResourceCache(opts.Clients.Kubernetes, ctx, getResourceCacheNamespace(opts))\n\t\tlog.Info(\"SSO enabled\")\n\t} else {\n\t\tlog.Info(\"SSO disabled\")\n\t}\n\tgatekeeper, err := auth.NewGatekeeper(opts.AuthModes, opts.Clients, opts.RestConfig, ssoIf, auth.DefaultClientForAuthorization, opts.Namespace, opts.SSONameSpace, opts.Namespaced, resourceCache)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &argoServer{\n\t\tbaseHRef:                 opts.BaseHRef,\n\t\ttlsConfig:                opts.TLSConfig,\n\t\thsts:                     opts.HSTS,\n\t\tnamespace:                opts.Namespace,\n\t\tmanagedNamespace:         opts.ManagedNamespace,\n\t\tclients:                  opts.Clients,\n\t\tgatekeeper:               gatekeeper,\n\t\toAuth2Service:            ssoIf,\n\t\tconfigController:         configController,\n\t\tstopCh:                   make(chan struct{}),\n\t\teventQueueSize:           opts.EventOperationQueueSize,\n\t\teventWorkerCount:         opts.EventWorkerCount,\n\t\teventAsyncDispatch:       opts.EventAsyncDispatch,\n\t\txframeOptions:            opts.XFrameOptions,\n\t\taccessControlAllowOrigin: opts.AccessControlAllowOrigin,\n\t\tcache:                    resourceCache,\n\t}, nil\n}\n\nvar backoff = wait.Backoff{\n\tSteps:    5,\n\tDuration: 500 * time.Millisecond,\n\tFactor:   1.0,\n\tJitter:   0.1,\n}\n\nfunc (as *argoServer) Run(ctx context.Context, port int, browserOpenFunc func(string)) {\n\tconfig, err := as.configController.Get(ctx)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlog.WithFields(log.Fields{\"version\": argo.GetVersion().Version, \"instanceID\": config.InstanceID}).Info(\"Starting Argo Server\")\n\tinstanceIDService := instanceid.NewService(config.InstanceID)\n\toffloadRepo := sqldb.ExplosiveOffloadNodeStatusRepo\n\twfArchive := sqldb.NullWorkflowArchive\n\tpersistence := config.Persistence\n\tif persistence != nil {\n\t\tsession, tableName, err := sqldb.CreateDBSession(as.clients.Kubernetes, as.namespace, persistence)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\t// we always enable node offload, as this is read-only for the Argo Server, i.e. you can turn it off if you\n\t\t// like and the controller won't offload newly created workflows, but you can still read them\n\t\toffloadRepo, err = sqldb.NewOffloadNodeStatusRepo(session, persistence.GetClusterName(), tableName)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\t// we always enable the archive for the Argo Server, as the Argo Server does not write records, so you can\n\t\t// disable the archiving - and still read old records\n\t\twfArchive = sqldb.NewWorkflowArchive(session, persistence.GetClusterName(), as.managedNamespace, instanceIDService)\n\t}\n\teventRecorderManager := events.NewEventRecorderManager(as.clients.Kubernetes)\n\tartifactRepositories := artifactrepositories.New(as.clients.Kubernetes, as.managedNamespace, &config.ArtifactRepository)\n\tartifactServer := artifacts.NewArtifactServer(as.gatekeeper, hydrator.New(offloadRepo), wfArchive, instanceIDService, artifactRepositories)\n\teventServer := event.NewController(instanceIDService, eventRecorderManager, as.eventQueueSize, as.eventWorkerCount, as.eventAsyncDispatch)\n\tgrpcServer := as.newGRPCServer(instanceIDService, offloadRepo, wfArchive, eventServer, config.Links, config.NavColor)\n\thttpServer := as.newHTTPServer(ctx, port, artifactServer)\n\n\t// Start listener\n\tvar conn net.Listener\n\tvar listerErr error\n\taddress := fmt.Sprintf(\":%d\", port)\n\terr = wait.ExponentialBackoff(backoff, func() (bool, error) {\n\t\tconn, listerErr = net.Listen(\"tcp\", address)\n\t\tif listerErr != nil {\n\t\t\tlog.Warnf(\"failed to listen: %v\", listerErr)\n\t\t\treturn false, nil\n\t\t}\n\t\treturn true, nil\n\t})\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn\n\t}\n\n\tif as.tlsConfig != nil {\n\t\tconn = tls.NewListener(conn, as.tlsConfig)\n\t}\n\n\t// Cmux is used to support servicing gRPC and HTTP1.1+JSON on the same port\n\ttcpm := cmux.New(conn)\n\thttpL := tcpm.Match(cmux.HTTP1Fast())\n\tgrpcL := tcpm.Match(cmux.Any())\n\n\tgo eventServer.Run(as.stopCh)\n\tgo func() { as.checkServeErr(\"grpcServer\", grpcServer.Serve(grpcL)) }()\n\tgo func() { as.checkServeErr(\"httpServer\", httpServer.Serve(httpL)) }()\n\tgo func() { as.checkServeErr(\"tcpm\", tcpm.Serve()) }()\n\turl := \"http://localhost\" + address\n\tif as.tlsConfig != nil {\n\t\turl = \"https://localhost\" + address\n\t}\n\tlog.WithFields(log.Fields{\n\t\t\"GRPC_MESSAGE_SIZE\": MaxGRPCMessageSize,\n\t}).Info(\"GRPC Server Max Message Size, MaxGRPCMessageSize, is set\")\n\tlog.Infof(\"Argo Server started successfully on %s\", url)\n\tbrowserOpenFunc(url)\n\n\t<-as.stopCh\n}\n\nfunc (as *argoServer) newGRPCServer(instanceIDService instanceid.Service, offloadNodeStatusRepo sqldb.OffloadNodeStatusRepo, wfArchive sqldb.WorkflowArchive, eventServer *event.Controller, links []*v1alpha1.Link, navColor string) *grpc.Server {\n\tserverLog := log.NewEntry(log.StandardLogger())\n\n\t// \"Prometheus histograms are a great way to measure latency distributions of your RPCs. However, since it is bad practice to have metrics of high cardinality the latency monitoring metrics are disabled by default. To enable them please call the following in your server initialization code:\"\n\tgrpc_prometheus.EnableHandlingTimeHistogram()\n\n\tsOpts := []grpc.ServerOption{\n\t\t// Set both the send and receive the bytes limit to be 100MB or GRPC_MESSAGE_SIZE\n\t\t// The proper way to achieve high performance is to have pagination\n\t\t// while we work toward that, we can have high limit first\n\t\tgrpc.MaxRecvMsgSize(MaxGRPCMessageSize),\n\t\tgrpc.MaxSendMsgSize(MaxGRPCMessageSize),\n\t\tgrpc.ConnectionTimeout(300 * time.Second),\n\t\tgrpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer(\n\t\t\tgrpc_prometheus.UnaryServerInterceptor,\n\t\t\tgrpc_logrus.UnaryServerInterceptor(serverLog),\n\t\t\tgrpcutil.PanicLoggerUnaryServerInterceptor(serverLog),\n\t\t\tgrpcutil.ErrorTranslationUnaryServerInterceptor,\n\t\t\tas.gatekeeper.UnaryServerInterceptor(),\n\t\t)),\n\t\tgrpc.StreamInterceptor(grpc_middleware.ChainStreamServer(\n\t\t\tgrpc_prometheus.StreamServerInterceptor,\n\t\t\tgrpc_logrus.StreamServerInterceptor(serverLog),\n\t\t\tgrpcutil.PanicLoggerStreamServerInterceptor(serverLog),\n\t\t\tgrpcutil.ErrorTranslationStreamServerInterceptor,\n\t\t\tas.gatekeeper.StreamServerInterceptor(),\n\t\t)),\n\t}\n\n\tgrpcServer := grpc.NewServer(sOpts...)\n\n\tinfopkg.RegisterInfoServiceServer(grpcServer, info.NewInfoServer(as.managedNamespace, links, navColor))\n\teventpkg.RegisterEventServiceServer(grpcServer, eventServer)\n\teventsourcepkg.RegisterEventSourceServiceServer(grpcServer, eventsource.NewEventSourceServer())\n\tpipelinepkg.RegisterPipelineServiceServer(grpcServer, pipeline.NewPipelineServer())\n\tsensorpkg.RegisterSensorServiceServer(grpcServer, sensor.NewSensorServer())\n\tworkflowpkg.RegisterWorkflowServiceServer(grpcServer, workflow.NewWorkflowServer(instanceIDService, offloadNodeStatusRepo))\n\tworkflowtemplatepkg.RegisterWorkflowTemplateServiceServer(grpcServer, workflowtemplate.NewWorkflowTemplateServer(instanceIDService))\n\tcronworkflowpkg.RegisterCronWorkflowServiceServer(grpcServer, cronworkflow.NewCronWorkflowServer(instanceIDService))\n\tworkflowarchivepkg.RegisterArchivedWorkflowServiceServer(grpcServer, workflowarchive.NewWorkflowArchiveServer(wfArchive))\n\tclusterwftemplatepkg.RegisterClusterWorkflowTemplateServiceServer(grpcServer, clusterworkflowtemplate.NewClusterWorkflowTemplateServer(instanceIDService))\n\tgrpc_prometheus.Register(grpcServer)\n\treturn grpcServer\n}\n\n// newHTTPServer returns the HTTP server to serve HTTP/HTTPS requests. This is implemented\n// using grpc-gateway as a proxy to the gRPC server.\nfunc (as *argoServer) newHTTPServer(ctx context.Context, port int, artifactServer *artifacts.ArtifactServer) *http.Server {\n\tendpoint := fmt.Sprintf(\"localhost:%d\", port)\n\n\tmux := http.NewServeMux()\n\thttpServer := http.Server{\n\t\tAddr:      endpoint,\n\t\tHandler:   accesslog.Interceptor(mux),\n\t\tTLSConfig: as.tlsConfig,\n\t}\n\tdialOpts := []grpc.DialOption{\n\t\tgrpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(MaxGRPCMessageSize)),\n\t}\n\tif as.tlsConfig != nil {\n\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(credentials.NewTLS(as.tlsConfig)))\n\t} else {\n\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(insecure.NewCredentials()))\n\t}\n\n\twebhookInterceptor := webhook.Interceptor(as.clients.Kubernetes)\n\n\t// HTTP 1.1+JSON Server\n\t// grpc-ecosystem/grpc-gateway is used to proxy HTTP requests to the corresponding gRPC call\n\t// NOTE: if a marshaller option is not supplied, grpc-gateway will default to the jsonpb from\n\t// golang/protobuf. Which does not support types such as time.Time. gogo/protobuf does support\n\t// time.Time, but does not support custom UnmarshalJSON() and MarshalJSON() methods. Therefore\n\t// we use our own Marshaler\n\tgwMuxOpts := runtime.WithMarshalerOption(runtime.MIMEWildcard, new(json.JSONMarshaler))\n\tgwmux := runtime.NewServeMux(gwMuxOpts,\n\t\truntime.WithIncomingHeaderMatcher(func(key string) (string, bool) { return key, true }),\n\t\truntime.WithProtoErrorHandler(runtime.DefaultHTTPProtoErrorHandler),\n\t)\n\tmustRegisterGWHandler(infopkg.RegisterInfoServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(eventpkg.RegisterEventServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(eventsourcepkg.RegisterEventSourceServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(sensorpkg.RegisterSensorServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(pipelinepkg.RegisterPipelineServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(workflowpkg.RegisterWorkflowServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(workflowtemplatepkg.RegisterWorkflowTemplateServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(cronworkflowpkg.RegisterCronWorkflowServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(workflowarchivepkg.RegisterArchivedWorkflowServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(clusterwftemplatepkg.RegisterClusterWorkflowTemplateServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\n\tmux.HandleFunc(\"/api/\", func(w http.ResponseWriter, r *http.Request) {\n\t\t// we must delete this header for API request to prevent \"stream terminated by RST_STREAM with error code: PROTOCOL_ERROR\" error\n\t\tr.Header.Del(\"Connection\")\n\t\twebhookInterceptor(w, r, gwmux)\n\t})\n\tmux.HandleFunc(\"/artifacts/\", artifactServer.GetOutputArtifact)\n\tmux.HandleFunc(\"/input-artifacts/\", artifactServer.GetInputArtifact)\n\tmux.HandleFunc(\"/artifacts-by-uid/\", artifactServer.GetOutputArtifactByUID)\n\tmux.HandleFunc(\"/input-artifacts-by-uid/\", artifactServer.GetInputArtifactByUID)\n\tmux.HandleFunc(\"/artifact-files/\", artifactServer.GetArtifactFile)\n\tmux.Handle(\"/oauth2/redirect\", handlers.ProxyHeaders(http.HandlerFunc(as.oAuth2Service.HandleRedirect)))\n\tmux.Handle(\"/oauth2/callback\", handlers.ProxyHeaders(http.HandlerFunc(as.oAuth2Service.HandleCallback)))\n\tmux.HandleFunc(\"/metrics\", func(w http.ResponseWriter, r *http.Request) {\n\t\tif os.Getenv(\"ARGO_SERVER_METRICS_AUTH\") != \"false\" {\n\t\t\theader := metadata.New(map[string]string{\"authorization\": r.Header.Get(\"Authorization\")})\n\t\t\tctx := metadata.NewIncomingContext(context.Background(), header)\n\t\t\tif _, err := as.gatekeeper.Context(ctx); err != nil {\n\t\t\t\tlog.WithError(err).Error(\"failed to authenticate /metrics endpoint\")\n\t\t\t\tw.WriteHeader(403)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tpromhttp.Handler().ServeHTTP(w, r)\n\n\t})\n\t// we only enable HTST if we are secure mode, otherwise you would never be able access the UI\n\tmux.HandleFunc(\"/\", static.NewFilesServer(as.baseHRef, as.tlsConfig != nil && as.hsts, as.xframeOptions, as.accessControlAllowOrigin).ServerFiles)\n\treturn &httpServer\n}\n\ntype registerFunc func(ctx context.Context, mux *runtime.ServeMux, endpoint string, opts []grpc.DialOption) error\n\n// mustRegisterGWHandler is a convenience function to register a gateway handler\nfunc mustRegisterGWHandler(register registerFunc, ctx context.Context, mux *runtime.ServeMux, endpoint string, opts []grpc.DialOption) {\n\terr := register(ctx, mux, endpoint, opts)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\n// checkServeErr checks the error from a .Serve() call to decide if it was a graceful shutdown\nfunc (as *argoServer) checkServeErr(name string, err error) {\n\tif err != nil {\n\t\tif as.stopCh == nil {\n\t\t\t// a nil stopCh indicates a graceful shutdown\n\t\t\tlog.Infof(\"graceful shutdown %s: %v\", name, err)\n\t\t} else {\n\t\t\tlog.Fatalf(\"%s: %v\", name, err)\n\t\t}\n\t} else {\n\t\tlog.Infof(\"graceful shutdown %s\", name)\n\t}\n}\n", "package artifacts\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"mime\"\n\t\"net/http\"\n\t\"path\"\n\t\"strings\"\n\n\tlog \"github.com/sirupsen/logrus\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/metadata\"\n\t\"google.golang.org/grpc/status\"\n\tapierr \"k8s.io/apimachinery/pkg/api/errors\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\n\t\"github.com/argoproj/argo-workflows/v3/persist/sqldb\"\n\twfv1 \"github.com/argoproj/argo-workflows/v3/pkg/apis/workflow/v1alpha1\"\n\t\"github.com/argoproj/argo-workflows/v3/server/auth\"\n\t\"github.com/argoproj/argo-workflows/v3/server/types\"\n\t\"github.com/argoproj/argo-workflows/v3/util/instanceid\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/artifactrepositories\"\n\tartifact \"github.com/argoproj/argo-workflows/v3/workflow/artifacts\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/artifacts/common\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/hydrator\"\n)\n\ntype ArtifactServer struct {\n\tgatekeeper           auth.Gatekeeper\n\thydrator             hydrator.Interface\n\twfArchive            sqldb.WorkflowArchive\n\tinstanceIDService    instanceid.Service\n\tartDriverFactory     artifact.NewDriverFunc\n\tartifactRepositories artifactrepositories.Interface\n}\n\nfunc NewArtifactServer(authN auth.Gatekeeper, hydrator hydrator.Interface, wfArchive sqldb.WorkflowArchive, instanceIDService instanceid.Service, artifactRepositories artifactrepositories.Interface) *ArtifactServer {\n\treturn newArtifactServer(authN, hydrator, wfArchive, instanceIDService, artifact.NewDriver, artifactRepositories)\n}\n\nfunc newArtifactServer(authN auth.Gatekeeper, hydrator hydrator.Interface, wfArchive sqldb.WorkflowArchive, instanceIDService instanceid.Service, artDriverFactory artifact.NewDriverFunc, artifactRepositories artifactrepositories.Interface) *ArtifactServer {\n\treturn &ArtifactServer{authN, hydrator, wfArchive, instanceIDService, artDriverFactory, artifactRepositories}\n}\n\nfunc (a *ArtifactServer) GetOutputArtifact(w http.ResponseWriter, r *http.Request) {\n\ta.getArtifact(w, r, false)\n}\n\nfunc (a *ArtifactServer) GetInputArtifact(w http.ResponseWriter, r *http.Request) {\n\ta.getArtifact(w, r, true)\n}\n\n// single endpoint to be able to handle serving directories as well as files, both those that have been archived and those that haven't\n// Valid requests:\n//  /artifact-files/{namespace}/[archived-workflows|workflows]/{id}/{nodeId}/outputs/{artifactName}\n//  /artifact-files/{namespace}/[archived-workflows|workflows]/{id}/{nodeId}/outputs/{artifactName}/{fileName}\n//  /artifact-files/{namespace}/[archived-workflows|workflows]/{id}/{nodeId}/outputs/{artifactName}/{fileDir}/.../{fileName}\n// 'id' field represents 'uid' for archived workflows and 'name' for non-archived\nfunc (a *ArtifactServer) GetArtifactFile(w http.ResponseWriter, r *http.Request) {\n\n\tconst (\n\t\tnamespaceIndex      = 2\n\t\tarchiveDiscrimIndex = 3\n\t\tidIndex             = 4\n\t\tnodeIdIndex         = 5\n\t\tdirectionIndex      = 6\n\t\tartifactNameIndex   = 7\n\t\tfileNameFirstIndex  = 8\n\t)\n\n\tvar fileName *string\n\trequestPath := strings.Split(r.URL.Path, \"/\")\n\tif len(requestPath) >= fileNameFirstIndex+1 { // they included a file path in the URL (not just artifact name)\n\t\tjoined := strings.Join(requestPath[fileNameFirstIndex:], \"/\")\n\t\t// sanitize file name\n\t\tcleanedPath := path.Clean(joined)\n\t\tfileName = &cleanedPath\n\t} else if len(requestPath) < artifactNameIndex+1 {\n\t\ta.httpBadRequestError(w)\n\t\treturn\n\t}\n\n\tnamespace := requestPath[namespaceIndex]\n\tarchiveDiscriminator := requestPath[archiveDiscrimIndex]\n\tid := requestPath[idIndex] // if archiveDiscriminator == \"archived-workflows\", this represents workflow UID; if archiveDiscriminator == \"workflows\", this represents workflow name\n\tnodeId := requestPath[nodeIdIndex]\n\tdirection := requestPath[directionIndex]\n\tartifactName := requestPath[artifactNameIndex]\n\n\tif direction != \"outputs\" { // for now we just handle output artifacts\n\t\ta.httpBadRequestError(w)\n\t\treturn\n\t}\n\n\t// verify user is authorized\n\tctx, err := a.gateKeeping(r, types.NamespaceHolder(namespace))\n\tif err != nil {\n\t\ta.unauthorizedError(w)\n\t\treturn\n\t}\n\n\tvar wf *wfv1.Workflow\n\n\t// retrieve the Workflow\n\tswitch archiveDiscriminator {\n\tcase \"workflows\":\n\t\tworkflowName := id\n\t\tlog.WithFields(log.Fields{\"namespace\": namespace, \"workflowName\": workflowName, \"nodeId\": nodeId, \"artifactName\": artifactName}).Info(\"Get artifact file\")\n\n\t\twf, err = a.getWorkflowAndValidate(ctx, namespace, workflowName)\n\t\tif err != nil {\n\t\t\ta.serverInternalError(err, w)\n\t\t\treturn\n\t\t}\n\tcase \"archived-workflows\":\n\t\tuid := id\n\t\tlog.WithFields(log.Fields{\"namespace\": namespace, \"uid\": uid, \"nodeId\": nodeId, \"artifactName\": artifactName}).Info(\"Get artifact file\")\n\n\t\twf, err = a.wfArchive.GetWorkflow(uid)\n\t\tif err != nil {\n\t\t\ta.serverInternalError(err, w)\n\t\t\treturn\n\t\t}\n\n\t\t// check that the namespace passed in matches this workflow's namespace\n\t\tif wf.GetNamespace() != namespace {\n\t\t\ta.httpBadRequestError(w)\n\t\t\treturn\n\t\t}\n\n\t\t// return 401 if the client does not have permission to get wf\n\t\terr = a.validateAccess(ctx, wf)\n\t\tif err != nil {\n\t\t\ta.unauthorizedError(w)\n\t\t\treturn\n\t\t}\n\tdefault:\n\t\ta.httpBadRequestError(w)\n\t\treturn\n\t}\n\n\tartifact, driver, err := a.getArtifactAndDriver(ctx, nodeId, artifactName, false, wf, fileName)\n\tif err != nil {\n\t\ta.serverInternalError(err, w)\n\t\treturn\n\t}\n\n\tisDir := strings.HasSuffix(r.URL.Path, \"/\")\n\n\tif !isDir {\n\t\tisDir, err := driver.IsDirectory(artifact)\n\t\tif err != nil {\n\t\t\ta.serverInternalError(err, w)\n\t\t\treturn\n\t\t}\n\t\tif isDir {\n\t\t\thttp.Redirect(w, r, r.URL.String()+\"/\", http.StatusTemporaryRedirect)\n\t\t\treturn\n\t\t}\n\t}\n\n\tif isDir {\n\t\t// return an html page to the user\n\n\t\tobjects, err := driver.ListObjects(artifact)\n\t\tif err != nil {\n\t\t\ta.serverInternalError(err, w)\n\t\t\treturn\n\t\t}\n\t\tlog.Debugf(\"this is a directory, artifact: %+v; files: %v\", artifact, objects)\n\n\t\tkey, _ := artifact.GetKey()\n\t\tfor _, object := range objects {\n\n\t\t\t// object is prefixed the key, we must trim it\n\t\t\tdir, file := path.Split(strings.TrimPrefix(object, key+\"/\"))\n\n\t\t\t// if dir is empty string, we are in the root dir\n\t\t\t// we found in index.html, abort and redirect there\n\t\t\tif dir == \"\" && file == \"index.html\" {\n\t\t\t\tw.Header().Set(\"Location\", r.URL.String()+\"index.html\")\n\t\t\t\tw.WriteHeader(http.StatusTemporaryRedirect)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tw.WriteHeader(http.StatusOK)\n\t\t_, _ = w.Write([]byte(\"<html><body><ul>\\n\"))\n\n\t\tdirs := map[string]bool{} // to de-dupe sub-dirs\n\n\t\t_, _ = w.Write([]byte(fmt.Sprintf(\"<li><a href=\\\"%s\\\">%s</a></li>\\n\", \"..\", \"..\")))\n\n\t\tfor _, object := range objects {\n\n\t\t\t// object is prefixed the key, we must trim it\n\t\t\tdir, file := path.Split(strings.TrimPrefix(object, key+\"/\"))\n\n\t\t\t// if dir is empty string, we are in the root dir\n\t\t\tif dir == \"\" {\n\t\t\t\t_, _ = w.Write([]byte(fmt.Sprintf(\"<li><a href=\\\"%s\\\">%s</a></li>\\n\", file, file)))\n\t\t\t} else if dirs[dir] {\n\t\t\t\tcontinue\n\t\t\t} else {\n\t\t\t\t_, _ = w.Write([]byte(fmt.Sprintf(\"<li><a href=\\\"%s\\\">%s</a></li>\\n\", dir, dir)))\n\t\t\t\tdirs[dir] = true\n\t\t\t}\n\t\t}\n\t\t_, _ = w.Write([]byte(\"</ul></body></html>\"))\n\n\t} else { // stream the file itself\n\t\tlog.Debugf(\"not a directory, artifact: %+v\", artifact)\n\t\terr = a.returnArtifact(w, artifact, driver)\n\n\t\tif err != nil {\n\t\t\ta.serverInternalError(err, w)\n\t\t\treturn\n\t\t}\n\t}\n\n}\n\nfunc (a *ArtifactServer) getArtifact(w http.ResponseWriter, r *http.Request, isInput bool) {\n\trequestPath := strings.SplitN(r.URL.Path, \"/\", 6)\n\tif len(requestPath) != 6 {\n\t\ta.httpBadRequestError(w)\n\t\treturn\n\t}\n\tnamespace := requestPath[2]\n\tworkflowName := requestPath[3]\n\tnodeId := requestPath[4]\n\tartifactName := requestPath[5]\n\n\tctx, err := a.gateKeeping(r, types.NamespaceHolder(namespace))\n\tif err != nil {\n\t\ta.unauthorizedError(w)\n\t\treturn\n\t}\n\n\tlog.WithFields(log.Fields{\"namespace\": namespace, \"workflowName\": workflowName, \"nodeId\": nodeId, \"artifactName\": artifactName, \"isInput\": isInput}).Info(\"Download artifact\")\n\n\twf, err := a.getWorkflowAndValidate(ctx, namespace, workflowName)\n\tif err != nil {\n\t\ta.httpFromError(err, w)\n\t\treturn\n\t}\n\tart, driver, err := a.getArtifactAndDriver(ctx, nodeId, artifactName, isInput, wf, nil)\n\tif err != nil {\n\t\ta.serverInternalError(err, w)\n\t\treturn\n\t}\n\n\terr = a.returnArtifact(w, art, driver)\n\n\tif err != nil {\n\t\ta.httpFromError(err, w)\n\t\treturn\n\t}\n}\n\nfunc (a *ArtifactServer) GetOutputArtifactByUID(w http.ResponseWriter, r *http.Request) {\n\ta.getArtifactByUID(w, r, false)\n}\n\nfunc (a *ArtifactServer) GetInputArtifactByUID(w http.ResponseWriter, r *http.Request) {\n\ta.getArtifactByUID(w, r, true)\n}\n\nfunc (a *ArtifactServer) getArtifactByUID(w http.ResponseWriter, r *http.Request, isInput bool) {\n\trequestPath := strings.SplitN(r.URL.Path, \"/\", 5)\n\tif len(requestPath) != 5 {\n\t\ta.httpBadRequestError(w)\n\t\treturn\n\t}\n\tuid := requestPath[2]\n\tnodeId := requestPath[3]\n\tartifactName := requestPath[4]\n\n\t// We need to know the namespace before we can do gate keeping\n\twf, err := a.wfArchive.GetWorkflow(uid)\n\tif err != nil {\n\t\ta.httpFromError(err, w)\n\t\treturn\n\t}\n\n\tctx, err := a.gateKeeping(r, types.NamespaceHolder(wf.GetNamespace()))\n\tif err != nil {\n\t\ta.unauthorizedError(w)\n\t\treturn\n\t}\n\n\t// return 401 if the client does not have permission to get wf\n\terr = a.validateAccess(ctx, wf)\n\tif err != nil {\n\t\ta.unauthorizedError(w)\n\t\treturn\n\t}\n\tart, driver, err := a.getArtifactAndDriver(ctx, nodeId, artifactName, isInput, wf, nil)\n\tif err != nil {\n\t\ta.serverInternalError(err, w)\n\t\treturn\n\t}\n\n\tlog.WithFields(log.Fields{\"uid\": uid, \"nodeId\": nodeId, \"artifactName\": artifactName, \"isInput\": isInput}).Info(\"Download artifact\")\n\terr = a.returnArtifact(w, art, driver)\n\n\tif err != nil {\n\t\ta.httpFromError(err, w)\n\t\treturn\n\t}\n}\n\nfunc (a *ArtifactServer) gateKeeping(r *http.Request, ns types.NamespacedRequest) (context.Context, error) {\n\ttoken := r.Header.Get(\"Authorization\")\n\tif token == \"\" {\n\t\tcookie, err := r.Cookie(\"authorization\")\n\t\tif err != nil {\n\t\t\tif err != http.ErrNoCookie {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t} else {\n\t\t\ttoken = cookie.Value\n\t\t}\n\t}\n\tctx := metadata.NewIncomingContext(r.Context(), metadata.MD{\"authorization\": []string{token}})\n\treturn a.gatekeeper.ContextWithRequest(ctx, ns)\n}\n\nfunc (a *ArtifactServer) unauthorizedError(w http.ResponseWriter) {\n\thttp.Error(w, http.StatusText(http.StatusUnauthorized), http.StatusUnauthorized)\n}\n\nfunc (a *ArtifactServer) serverInternalError(err error, w http.ResponseWriter) {\n\thttp.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError)\n\tlog.WithError(err).Error(\"Artifact Server returned internal error\")\n}\n\nfunc (a *ArtifactServer) httpBadRequestError(w http.ResponseWriter) {\n\thttp.Error(w, http.StatusText(http.StatusBadRequest), http.StatusBadRequest)\n}\n\nfunc (a *ArtifactServer) httpFromError(err error, w http.ResponseWriter) {\n\te := &apierr.StatusError{}\n\tif errors.As(err, &e) {\n\t\t// There is a http error code somewhere in the error stack\n\t\tstatusCode := int(e.Status().Code)\n\t\thttp.Error(w, http.StatusText(statusCode), statusCode)\n\t} else {\n\t\t// Unknown error - return internal error\n\t\ta.serverInternalError(err, w)\n\t}\n}\n\nfunc (a *ArtifactServer) getArtifactAndDriver(ctx context.Context, nodeId, artifactName string, isInput bool, wf *wfv1.Workflow, fileName *string) (*wfv1.Artifact, common.ArtifactDriver, error) {\n\n\tkubeClient := auth.GetKubeClient(ctx)\n\n\tvar art *wfv1.Artifact\n\tif isInput {\n\t\tart = wf.Status.Nodes[nodeId].Inputs.GetArtifactByName(artifactName)\n\t} else {\n\t\tart = wf.Status.Nodes[nodeId].Outputs.GetArtifactByName(artifactName)\n\t}\n\tif art == nil {\n\t\treturn nil, nil, fmt.Errorf(\"artifact not found: %s\", artifactName)\n\t}\n\n\tar, err := a.artifactRepositories.Get(ctx, wf.Status.ArtifactRepositoryRef)\n\tif err != nil {\n\t\treturn art, nil, err\n\t}\n\tl := ar.ToArtifactLocation()\n\terr = art.Relocate(l)\n\tif err != nil {\n\t\treturn art, nil, err\n\t}\n\tif fileName != nil {\n\t\terr = art.AppendToKey(*fileName)\n\t\tif err != nil {\n\t\t\treturn art, nil, fmt.Errorf(\"error appending filename %s to key of artifact %+v: err: %v\", *fileName, art, err)\n\t\t}\n\t\tlog.Debugf(\"appended key %s to artifact %+v\", *fileName, art)\n\t}\n\n\tdriver, err := a.artDriverFactory(ctx, art, resources{kubeClient, wf.Namespace})\n\tif err != nil {\n\t\treturn art, nil, err\n\t}\n\tlog.Debugf(\"successfully located driver associated with artifact %+v\", art)\n\n\treturn art, driver, nil\n}\n\nfunc (a *ArtifactServer) returnArtifact(w http.ResponseWriter, art *wfv1.Artifact, driver common.ArtifactDriver) error {\n\tstream, err := driver.OpenStream(art)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer func() {\n\t\tif err := stream.Close(); err != nil {\n\t\t\tlog.Warningf(\"Error closing stream[%s]: %v\", stream, err)\n\t\t}\n\t}()\n\n\tkey, _ := art.GetKey()\n\tw.Header().Add(\"Content-Disposition\", fmt.Sprintf(`filename=\"%s\"`, path.Base(key)))\n\tw.Header().Add(\"Content-Type\", mime.TypeByExtension(path.Ext(key)))\n\n\t_, err = io.Copy(w, stream)\n\tif err != nil {\n\t\thttp.Error(w, fmt.Sprintf(\"failed to stream artifact: %v\", err), http.StatusInternalServerError)\n\t} else {\n\t\tw.WriteHeader(http.StatusOK)\n\t}\n\n\treturn nil\n}\n\nfunc (a *ArtifactServer) getWorkflowAndValidate(ctx context.Context, namespace string, workflowName string) (*wfv1.Workflow, error) {\n\twfClient := auth.GetWfClient(ctx)\n\twf, err := wfClient.ArgoprojV1alpha1().Workflows(namespace).Get(ctx, workflowName, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = a.instanceIDService.Validate(wf)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = a.hydrator.Hydrate(wf)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn wf, nil\n}\n\nfunc (a *ArtifactServer) validateAccess(ctx context.Context, wf *wfv1.Workflow) error {\n\tallowed, err := auth.CanI(ctx, \"get\", \"workflows\", wf.Namespace, wf.Name)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !allowed {\n\t\treturn status.Error(codes.PermissionDenied, \"permission denied\")\n\t}\n\treturn nil\n}\n", "//go:build api\n// +build api\n\npackage e2e\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"os\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/gavv/httpexpect/v2\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/suite\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\trbacv1 \"k8s.io/api/rbac/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/types\"\n\n\t\"github.com/argoproj/argo-workflows/v3/pkg/apis/workflow\"\n\twfv1 \"github.com/argoproj/argo-workflows/v3/pkg/apis/workflow/v1alpha1\"\n\t\"github.com/argoproj/argo-workflows/v3/test/e2e/fixtures\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/common\"\n)\n\nconst baseUrl = \"http://localhost:2746\"\n\n// ensure basic HTTP functionality works,\n// testing behaviour really is a non-goal\ntype ArgoServerSuite struct {\n\tfixtures.E2ESuite\n\tusername    string\n\tbearerToken string\n}\n\nfunc (s *ArgoServerSuite) BeforeTest(suiteName, testName string) {\n\ts.E2ESuite.BeforeTest(suiteName, testName)\n\tvar err error\n\ts.bearerToken, err = s.GetServiceAccountToken()\n\ts.CheckError(err)\n}\n\nfunc (s *ArgoServerSuite) e() *httpexpect.Expect {\n\treturn httpexpect.\n\t\tWithConfig(httpexpect.Config{\n\t\t\tBaseURL:  baseUrl,\n\t\t\tReporter: httpexpect.NewRequireReporter(s.T()),\n\t\t\tPrinters: []httpexpect.Printer{\n\t\t\t\thttpexpect.NewDebugPrinter(s.T(), true),\n\t\t\t},\n\t\t\tClient: httpClient,\n\t\t}).\n\t\tBuilder(func(req *httpexpect.Request) {\n\t\t\tif s.username != \"\" {\n\t\t\t\treq.WithBasicAuth(s.username, \"garbage\")\n\t\t\t} else if s.bearerToken != \"\" {\n\t\t\t\treq.WithHeader(\"Authorization\", \"Bearer \"+s.bearerToken)\n\t\t\t}\n\t\t})\n}\n\nfunc (s *ArgoServerSuite) TestInfo() {\n\ts.Run(\"Get\", func() {\n\t\tjson := s.e().GET(\"/api/v1/info\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tjson.\n\t\t\tPath(\"$.managedNamespace\").\n\t\t\tEqual(\"argo\")\n\t\tjson.\n\t\t\tPath(\"$.links[0].name\").\n\t\t\tEqual(\"Workflow Link\")\n\t\tjson.\n\t\t\tPath(\"$.links[0].scope\").\n\t\t\tEqual(\"workflow\")\n\t\tjson.\n\t\t\tPath(\"$.links[0].url\").\n\t\t\tEqual(\"http://logging-facility?namespace=${metadata.namespace}&workflowName=${metadata.name}&startedAt=${status.startedAt}&finishedAt=${status.finishedAt}\")\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestVersion() {\n\ts.Run(\"Version\", func() {\n\t\ts.e().GET(\"/api/v1/version\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.version\").\n\t\t\tNotNull()\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestMetricsForbidden() {\n\ts.bearerToken = \"\"\n\ts.e().\n\t\tGET(\"/metrics\").\n\t\tExpect().\n\t\tStatus(403)\n}\n\nfunc (s *ArgoServerSuite) TestMetricsOK() {\n\tbody := s.e().\n\t\tGET(\"/metrics\").\n\t\tExpect().\n\t\tStatus(200).\n\t\tBody()\n\tbody.\n\t\t// https://blog.netsil.com/the-4-golden-signals-of-api-health-and-performance-in-cloud-native-applications-a6e87526e74\n\t\t// Latency: The time it takes to service a request, with a focus on distinguishing between the latency of successful requests and the latency of failed requests\n\t\tContains(`grpc_server_handling_seconds_bucket`).\n\t\t// Traffic: A measure of how much demand is being placed on the service. This is measured using a high-level service-specific metric, like HTTP requests per second in the case of an HTTP REST API.\n\t\tContains(`promhttp_metric_handler_requests_in_flight`).\n\t\t// Errors: The rate of requests that fail. The failures can be explicit (e.g., HTTP 500 errors) or implicit (e.g., an HTTP 200 OK response with a response body having too few items).\n\t\tContains(`promhttp_metric_handler_requests_total{code=\"500\"}`)\n\n\tif os.Getenv(\"CI\") == \"true\" {\n\t\tbody.\n\t\t\t// Saturation: How \u201cfull\u201d is the service. This is a measure of the system utilization, emphasizing the resources that are most constrained (e.g., memory, I/O or CPU). Services degrade in performance as they approach high saturation.\n\t\t\tContains(`process_cpu_seconds_total`).\n\t\t\tContains(`process_resident_memory_bytes`)\n\t}\n}\n\nfunc (s *ArgoServerSuite) TestSubmitWorkflowTemplateFromGithubWebhook() {\n\ts.bearerToken = \"\"\n\n\tdata, err := ioutil.ReadFile(\"testdata/github-webhook-payload.json\")\n\tassert.NoError(s.T(), err)\n\n\ts.Given().\n\t\tWorkflowTemplate(`\nmetadata:\n  name: github-webhook\nspec:\n  entrypoint: main\n  workflowMetadata:\n    labels:\n      workflows.argoproj.io/test: \"true\"\n  templates:\n    - name: main\n      container:\n         image: argoproj/argosay:v2\n`).\n\t\tWorkflowEventBinding(`\nmetadata:\n  name: github-webhook\nspec:\n  event:\n    selector: metadata[\"x-github-event\"] == [\"push\"]\n  submit:\n    workflowTemplateRef:\n      name: github-webhook\n`).\n\t\tWhen().\n\t\tCreateWorkflowTemplates().\n\t\tCreateWorkflowEventBinding().\n\t\tAnd(func() {\n\t\t\ts.e().\n\t\t\t\tPOST(\"/api/v1/events/argo/\").\n\t\t\t\tWithHeader(\"X-Github-Event\", \"push\").\n\t\t\t\tWithHeader(\"X-Hub-Signature\", \"sha1=c09e61386e81c2669e015049350500448148205c\").\n\t\t\t\tWithBytes(data).\n\t\t\t\tExpect().\n\t\t\t\tStatus(200)\n\t\t}).\n\t\tWaitForWorkflow().\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, _ *wfv1.WorkflowStatus) {\n\t\t\tassert.Equal(t, \"github-webhook\", metadata.GetLabels()[common.LabelKeyWorkflowTemplate])\n\t\t})\n}\n\nfunc (s *ArgoServerSuite) TestSubmitWorkflowTemplateFromEvent() {\n\ts.Given().\n\t\tWorkflowTemplate(`\nmetadata:\n  name: event-consumer\nspec:\n  entrypoint: main\n  workflowMetadata:\n    labels:\n      workflows.argoproj.io/test: \"true\"\n  arguments:\n    parameters:\n      - name: salutation\n        value: \"hello\"\n  templates:\n    - name: main\n      steps:\n      - - name: a\n          template: argosay\n          arguments:\n            parameters:\n            - name: salutation\n              value: \"{{workflow.parameters.salutation}}\"\n            - name: appellation\n              value: \"{{workflow.parameters.appellation}}\"\n\n    - name: argosay\n      inputs:\n        parameters:\n          - name: salutation\n          - name: appellation\n      container:\n         image: argoproj/argosay:v2\n         args: [echo, \"{{inputs.parameters.salutation}} {{inputs.parameters.appellation}}\"]\n`).\n\t\tWorkflowEventBinding(`\nmetadata:\n  name: event-consumer\nspec:\n  event:\n    selector: payload.appellation != \"\" && metadata[\"x-argo-e2e\"] == [\"true\"]\n  submit:\n    workflowTemplateRef:\n      name: event-consumer\n    arguments:\n      parameters:\n        - name: appellation\n          valueFrom:\n            event: payload.appellation\n`).\n\t\tWhen().\n\t\tCreateWorkflowEventBinding().\n\t\tCreateWorkflowTemplates().\n\t\tAnd(func() {\n\t\t\ts.e().\n\t\t\t\tPOST(\"/api/v1/events/argo/\").\n\t\t\t\tWithHeader(\"X-Argo-E2E\", \"true\").\n\t\t\t\tWithBytes([]byte(`{\"appellation\": \"Mr Chips\"}`)).\n\t\t\t\tExpect().\n\t\t\t\tStatus(200)\n\t\t}).\n\t\tWaitForWorkflow().\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, _ *wfv1.WorkflowStatus) {\n\t\t\tassert.Equal(t, \"event-consumer\", metadata.GetLabels()[common.LabelKeyWorkflowTemplate])\n\t\t})\n}\n\nfunc (s *ArgoServerSuite) TestSubmitClusterWorkflowTemplateFromEvent() {\n\ts.Given().\n\t\tClusterWorkflowTemplate(`\nmetadata:\n  name: event-consumer\nspec:\n  entrypoint: main\n  workflowMetadata:\n    labels:\n      workflows.argoproj.io/test: \"true\"\n  templates:\n    - name: main\n      container:\n         image: argoproj/argosay:v2\n`).\n\t\tWorkflowEventBinding(`\nmetadata:\n  name: event-consumer\nspec:\n  event:\n    selector: true\n  submit:\n    workflowTemplateRef:\n      name: event-consumer\n      clusterScope: true\n`).\n\t\tWhen().\n\t\tCreateWorkflowEventBinding().\n\t\tCreateClusterWorkflowTemplates().\n\t\tAnd(func() {\n\t\t\ts.e().\n\t\t\t\tPOST(\"/api/v1/events/argo/\").\n\t\t\t\tWithBytes([]byte(`{}`)).\n\t\t\t\tExpect().\n\t\t\t\tStatus(200)\n\t\t}).\n\t\tWaitForWorkflow().\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, _ *wfv1.WorkflowStatus) {\n\t\t\tassert.Equal(t, \"event-consumer\", metadata.GetLabels()[common.LabelKeyClusterWorkflowTemplate])\n\t\t})\n}\n\nfunc (s *ArgoServerSuite) TestEventOnMalformedWorkflowEventBinding() {\n\ts.Given().\n\t\tWorkflowEventBinding(`\nmetadata:\n  name: malformed\n`).\n\t\tWhen().\n\t\tCreateWorkflowEventBinding().\n\t\tAnd(func() {\n\t\t\ts.e().\n\t\t\t\tPOST(\"/api/v1/events/argo/\").\n\t\t\t\tWithBytes([]byte(`{}`)).\n\t\t\t\tExpect().\n\t\t\t\tStatus(500)\n\t\t}).\n\t\tThen().\n\t\tExpectAuditEvents(\n\t\t\tfunc(event corev1.Event) bool {\n\t\t\t\treturn event.InvolvedObject.Name == \"malformed\" && event.InvolvedObject.Kind == workflow.WorkflowEventBindingKind\n\t\t\t}, 1,\n\t\t\tfunc(t *testing.T, e []corev1.Event) {\n\t\t\t\tassert.Equal(t, \"argo\", e[0].InvolvedObject.Namespace)\n\t\t\t\tassert.Equal(t, \"WorkflowEventBindingError\", e[0].Reason)\n\t\t\t\tassert.Equal(t, \"failed to dispatch event: failed to evaluate workflow template expression: unable to evaluate expression '': unexpected token EOF (1:1)\", e[0].Message)\n\t\t\t},\n\t\t)\n}\n\nfunc (s *ArgoServerSuite) TestGetUserInfo() {\n\ts.e().GET(\"/api/v1/userinfo\").\n\t\tExpect().\n\t\tStatus(200)\n}\n\n// we can only really tests these endpoint respond, not worthwhile checking more\nfunc (s *ArgoServerSuite) TestOauth() {\n\ts.Run(\"Redirect\", func() {\n\t\ts.e().GET(\"/oauth2/redirect\").\n\t\t\tExpect().\n\t\t\tStatus(501)\n\t})\n\ts.Run(\"Callback\", func() {\n\t\ts.e().GET(\"/oauth2/callback\").\n\t\t\tExpect().\n\t\t\tStatus(501)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestUnauthorized() {\n\ttoken := s.bearerToken\n\ts.T().Run(\"Bearer\", func(t *testing.T) {\n\t\ts.bearerToken = \"test-token\"\n\t\tdefer func() { s.bearerToken = token }()\n\t\ts.e().GET(\"/api/v1/workflows/argo\").\n\t\t\tExpect().\n\t\t\tStatus(401)\n\t})\n\ts.T().Run(\"Basic\", func(t *testing.T) {\n\t\ts.username = \"garbage\"\n\t\tdefer func() { s.username = \"\" }()\n\t\ts.e().GET(\"/api/v1/workflows/argo\").\n\t\t\tExpect().\n\t\t\tStatus(401)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestCookieAuth() {\n\ttoken := s.bearerToken\n\tdefer func() { s.bearerToken = token }()\n\ts.bearerToken = \"\"\n\ts.e().GET(\"/api/v1/workflows/argo\").\n\t\tWithHeader(\"Cookie\", \"authorization=Bearer \"+token).\n\t\tExpect().\n\t\tStatus(200)\n}\n\n// You could have multiple authorization headers, set by wildcard domain cookies in the case of some SSO implementations\nfunc (s *ArgoServerSuite) TestMultiCookieAuth() {\n\ttoken := s.bearerToken\n\tdefer func() { s.bearerToken = token }()\n\ts.bearerToken = \"\"\n\ts.e().GET(\"/api/v1/workflows/argo\").\n\t\tWithCookie(\"authorization\", \"invalid1\").\n\t\tWithCookie(\"authorization\", \"Bearer \"+token).\n\t\tWithCookie(\"authorization\", \"invalid2\").\n\t\tExpect().\n\t\tStatus(200)\n}\n\nfunc (s *ArgoServerSuite) TestPermission() {\n\tnsName := fixtures.Namespace\n\t// Create good serviceaccount\n\tgoodSaName := \"argotestgood\"\n\tgoodSa := &corev1.ServiceAccount{ObjectMeta: metav1.ObjectMeta{Name: goodSaName}}\n\tctx := context.Background()\n\ts.Run(\"CreateGoodSA\", func() {\n\t\t_, err := s.KubeClient.CoreV1().ServiceAccounts(nsName).Create(ctx, goodSa, metav1.CreateOptions{})\n\t\tassert.NoError(s.T(), err)\n\t})\n\tdefer func() {\n\t\t// Clean up created sa\n\t\t_ = s.KubeClient.CoreV1().ServiceAccounts(nsName).Delete(ctx, goodSaName, metav1.DeleteOptions{})\n\t}()\n\n\t// Create bad serviceaccount\n\tbadSaName := \"argotestbad\"\n\tbadSa := &corev1.ServiceAccount{ObjectMeta: metav1.ObjectMeta{Name: badSaName}}\n\ts.Run(\"CreateBadSA\", func() {\n\t\t_, err := s.KubeClient.CoreV1().ServiceAccounts(nsName).Create(ctx, badSa, metav1.CreateOptions{})\n\t\tassert.NoError(s.T(), err)\n\t})\n\tdefer func() {\n\t\t_ = s.KubeClient.CoreV1().ServiceAccounts(nsName).Delete(ctx, badSaName, metav1.DeleteOptions{})\n\t}()\n\n\t// Create RBAC Role\n\tvar roleName string\n\ts.Run(\"LoadRoleYaml\", func() {\n\t\tobj, err := fixtures.LoadObject(\"@testdata/argo-server-test-role.yaml\")\n\t\tassert.NoError(s.T(), err)\n\t\trole, _ := obj.(*rbacv1.Role)\n\t\troleName = role.Name\n\t\t_, err = s.KubeClient.RbacV1().Roles(nsName).Create(ctx, role, metav1.CreateOptions{})\n\t\tassert.NoError(s.T(), err)\n\t})\n\tdefer func() {\n\t\t_ = s.KubeClient.RbacV1().Roles(nsName).Delete(ctx, roleName, metav1.DeleteOptions{})\n\t}()\n\n\t// Create RBAC RoleBinding\n\troleBindingName := \"argotest-role-binding\"\n\troleBinding := &rbacv1.RoleBinding{\n\t\tObjectMeta: metav1.ObjectMeta{Name: roleBindingName},\n\t\tSubjects:   []rbacv1.Subject{{Kind: \"ServiceAccount\", Name: goodSaName}},\n\t\tRoleRef: rbacv1.RoleRef{\n\t\t\tAPIGroup: \"rbac.authorization.k8s.io\",\n\t\t\tKind:     \"Role\",\n\t\t\tName:     roleName,\n\t\t},\n\t}\n\ts.Run(\"CreateRoleBinding\", func() {\n\t\t_, err := s.KubeClient.RbacV1().RoleBindings(nsName).Create(ctx, roleBinding, metav1.CreateOptions{})\n\t\tassert.NoError(s.T(), err)\n\t})\n\tdefer func() {\n\t\t_ = s.KubeClient.RbacV1().RoleBindings(nsName).Delete(ctx, roleBindingName, metav1.DeleteOptions{})\n\t}()\n\n\t// Sleep 2 seconds to wait for serviceaccount token created.\n\t// The secret creation slowness is seen in k3d.\n\ttime.Sleep(2 * time.Second)\n\n\t// Get token of good serviceaccount\n\tvar goodToken string\n\ts.Run(\"GetGoodSAToken\", func() {\n\t\tsAccount, err := s.KubeClient.CoreV1().ServiceAccounts(nsName).Get(ctx, goodSaName, metav1.GetOptions{})\n\t\tif assert.NoError(s.T(), err) {\n\t\t\tsecretName := sAccount.Secrets[0].Name\n\t\t\tsecret, err := s.KubeClient.CoreV1().Secrets(nsName).Get(ctx, secretName, metav1.GetOptions{})\n\t\t\tassert.NoError(s.T(), err)\n\t\t\tgoodToken = string(secret.Data[\"token\"])\n\t\t}\n\t})\n\n\t// Get token of bad serviceaccount\n\tvar badToken string\n\ts.Run(\"GetBadSAToken\", func() {\n\t\tsAccount, err := s.KubeClient.CoreV1().ServiceAccounts(nsName).Get(ctx, badSaName, metav1.GetOptions{})\n\t\tassert.NoError(s.T(), err)\n\t\tsecretName := sAccount.Secrets[0].Name\n\t\tsecret, err := s.KubeClient.CoreV1().Secrets(nsName).Get(ctx, secretName, metav1.GetOptions{})\n\t\tassert.NoError(s.T(), err)\n\t\tbadToken = string(secret.Data[\"token\"])\n\t})\n\n\ttoken := s.bearerToken\n\tdefer func() { s.bearerToken = token }()\n\n\t// Test creating workflow with good token\n\tvar uid string\n\ts.bearerToken = goodToken\n\ts.Run(\"CreateWFGoodToken\", func() {\n\t\tuid = s.e().POST(\"/api/v1/workflows/\" + nsName).\n\t\t\tWithBytes([]byte(`{\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"test-wf-good\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"main\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\"\n          }\n        }\n      ],\n      \"entrypoint\": \"main\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.uid\").\n\t\t\tRaw().(string)\n\t})\n\n\t// Test list workflows with good token\n\ts.Run(\"ListWFsGoodToken\", func() {\n\t\ts.e().GET(\"/api/v1/workflows/\"+nsName).\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\n\ts.Given().\n\t\tWhen().\n\t\tWaitForWorkflow(fixtures.ToBeArchived)\n\n\t// Test creating workflow with bad token\n\ts.bearerToken = badToken\n\ts.Run(\"CreateWFBadToken\", func() {\n\t\ts.e().POST(\"/api/v1/workflows/\" + nsName).\n\t\t\tWithBytes([]byte(`{\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"test-wf-bad\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"main\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\"\n          }\n        }\n      ],\n      \"entrypoint\": \"main\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\n\t// Test list workflows with bad token\n\ts.Run(\"ListWFsBadToken\", func() {\n\t\ts.e().GET(\"/api/v1/workflows/\" + nsName).\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\t// Test delete workflow with bad token\n\ts.Run(\"DeleteWFWithBadToken\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflows/\" + nsName + \"/test-wf-good\").\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\n\t// Test delete workflow with good token\n\ts.bearerToken = goodToken\n\ts.Run(\"DeleteWFWithGoodToken\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflows/\" + nsName + \"/test-wf-good\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\t// we've now deleted the workflow, but it is still in the archive, testing the archive\n\t// after deleting the workflow makes sure that we are no dependant of the workflow for authorization\n\n\t// Test list archived WFs with good token\n\ts.Run(\"ListArchivedWFsGoodToken\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tWithQuery(\"listOptions.fieldSelector\", \"metadata.namespace=\"+nsName).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().Length().Gt(0)\n\t})\n\n\ts.bearerToken = badToken\n\ts.Run(\"ListArchivedWFsBadToken\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tWithQuery(\"listOptions.fieldSelector\", \"metadata.namespace=\"+nsName).\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\n\t// Test get archived wf with good token\n\ts.bearerToken = goodToken\n\ts.Run(\"GetArchivedWFsGoodToken\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows/\"+uid).\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\t// Test get archived wf with bad token\n\ts.bearerToken = badToken\n\ts.Run(\"GetArchivedWFsBadToken\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows/\" + uid).\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\n\t// Test deleting archived wf with bad token\n\ts.Run(\"DeleteArchivedWFsBadToken\", func() {\n\t\ts.e().DELETE(\"/api/v1/archived-workflows/\" + uid).\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\n\t// Test deleting archived wf with good token\n\ts.bearerToken = goodToken\n\ts.Run(\"DeleteArchivedWFsGoodToken\", func() {\n\t\ts.e().DELETE(\"/api/v1/archived-workflows/\" + uid).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestLintWorkflow() {\n\ts.e().POST(\"/api/v1/workflows/argo/lint\").\n\t\tWithBytes([]byte((`{\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`))).\n\t\tExpect().\n\t\tStatus(200)\n}\n\nfunc (s *ArgoServerSuite) TestHintWhenWorkflowExists() {\n\ts.e().POST(\"/api/v1/workflows/argo\").\n\t\tWithBytes([]byte((`{\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"hint\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"entrypoint\": \"whalesay\",\n      \"templates\": [\n        {\n          \"name\": \"whalesay\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\"\n          }\n        }\n      ]\n    }\n  }\n}`))).\n\t\tExpect().\n\t\tStatus(200)\n\n\ts.e().POST(\"/api/v1/workflows/argo\").\n\t\tWithBytes([]byte((`{\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"hint\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"entrypoint\": \"whalesay\",\n      \"templates\": [\n        {\n          \"name\": \"whalesay\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\"\n          }\n        }\n      ]\n    }\n  }\n}`))).\n\t\tExpect().\n\t\tStatus(409).\n\t\tBody().\n\t\tContains(\"already exists\")\n}\n\nfunc (s *ArgoServerSuite) TestCreateWorkflowDryRun() {\n\ts.e().POST(\"/api/v1/workflows/argo\").\n\t\tWithBytes([]byte(`{\n  \"createOptions\": {\n    \"dryRun\": [\"All\"]\n  },\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).\n\t\tExpect().\n\t\tStatus(200).\n\t\tJSON().\n\t\tPath(\"$.metadata\").\n\t\tObject().\n\t\tNotContainsKey(\"uid\")\n}\n\nfunc (s *ArgoServerSuite) TestWorkflowService() {\n\tvar name string\n\ts.Run(\"Create\", func() {\n\t\tname = s.e().POST(\"/api/v1/workflows/argo\").\n\t\t\tWithBytes([]byte(`{\n  \"workflow\": {\n    \"metadata\": {\n      \"generateName\": \"test-\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"subject-1\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\",\n            \"args\": [\"sleep\", \"10s\"]   \n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tNotNull().\n\t\t\tString().\n\t\t\tRaw()\n\t})\n\n\ts.Given().\n\t\tWhen().\n\t\tWaitForWorkflow(fixtures.ToBeRunning)\n\n\ts.Run(\"List\", func() {\n\t\tj := s.e().GET(\"/api/v1/workflows/argo\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test=subject-1\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t\tj.Path(\"$.items[0].status.nodes\").\n\t\t\tNotNull()\n\t})\n\n\ts.Run(\"ListWithFields\", func() {\n\t\tj := s.e().GET(\"/api/v1/workflows/argo\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test=subject-1\").\n\t\t\tWithQuery(\"fields\", \"-items.status.nodes,items.status.finishedAt,items.status.startedAt\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.Path(\"$.metadata\").\n\t\t\tNotNull()\n\t\tj.\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t\tj.Path(\"$.items[0].status\").Object().ContainsKey(\"phase\").NotContainsKey(\"nodes\")\n\t})\n\n\ts.Run(\"Get\", func() {\n\t\tj := s.e().GET(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.Path(\"$.status.nodes\").\n\t\t\tNotNull()\n\t\ts.e().GET(\"/api/v1/workflows/argo/not-found\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t})\n\n\ts.Run(\"GetWithFields\", func() {\n\t\tj := s.e().GET(\"/api/v1/workflows/argo/\"+name).\n\t\t\tWithQuery(\"fields\", \"status.phase\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.Path(\"$.status\").Object().ContainsKey(\"phase\").NotContainsKey(\"nodes\")\n\t})\n\n\ts.Run(\"Suspend\", func() {\n\t\ts.e().PUT(\"/api/v1/workflows/argo/\" + name + \"/suspend\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\ts.e().GET(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec.suspend\").\n\t\t\tEqual(true)\n\t})\n\n\ts.Run(\"Resume\", func() {\n\t\ts.e().PUT(\"/api/v1/workflows/argo/\" + name + \"/resume\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\ts.e().GET(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec\").\n\t\t\tObject().\n\t\t\tNotContainsKey(\"suspend\")\n\t})\n\n\ts.Run(\"Terminate\", func() {\n\t\ts.e().PUT(\"/api/v1/workflows/argo/\" + name + \"/terminate\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\ts.Given().\n\t\t\tWorkflowName(name).\n\t\t\tWhen().\n\t\t\tWaitForWorkflow()\n\n\t\ts.e().GET(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.status.message\").\n\t\t\tEqual(\"Stopped with strategy 'Terminate'\")\n\t})\n\n\ts.Run(\"Resubmit\", func() {\n\t\ts.e().PUT(\"/api/v1/workflows/argo/\" + name + \"/resubmit\").\n\t\t\tWithBytes([]byte(`{\"memoized\": true}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tNotNull()\n\t})\n\n\ts.Run(\"Delete\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t\ts.e().DELETE(\"/api/v1/workflows/argo/not-found\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestCronWorkflowService() {\n\ts.Run(\"Create\", func() {\n\t\ts.e().POST(\"/api/v1/cron-workflows/argo\").\n\t\t\tWithBytes([]byte(`{\n  \"cronWorkflow\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"subject-2\"\n      }\n    },\n    \"spec\": {\n      \"schedule\": \"* * * * *\",\n      \"workflowSpec\": {\n        \"entrypoint\": \"whalesay\",\n        \"templates\": [\n          {\n            \"name\": \"whalesay\",\n            \"container\": {\n              \"image\": \"argoproj/argosay:v2\",\n              \"imagePullPolicy\": \"IfNotPresent\"\n            }\n          }\n        ]\n      }\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"Suspend\", func() {\n\t\ts.e().PUT(\"/api/v1/cron-workflows/argo/test/suspend\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec.suspend\").\n\t\t\tEqual(true)\n\t})\n\n\ts.Run(\"Resume\", func() {\n\t\ts.e().PUT(\"/api/v1/cron-workflows/argo/test/resume\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec\").\n\t\t\tObject().\n\t\t\tNotContainsKey(\"suspend\")\n\t})\n\n\ts.Run(\"List\", func() {\n\t\t// make sure list options work correctly\n\t\ts.Given().\n\t\t\tCronWorkflow(`apiVersion: argoproj.io/v1alpha1\nkind: CronWorkflow\nmetadata:\n  name: test-cron-wf-basic\nspec:\n  schedule: \"* * * * *\"\n  concurrencyPolicy: \"Allow\"\n  startingDeadlineSeconds: 0\n  successfulJobsHistoryLimit: 4\n  failedJobsHistoryLimit: 2\n  workflowSpec:\n    podGC:\n      strategy: OnPodCompletion\n    entrypoint: whalesay\n    templates:\n      - name: whalesay\n        container:\n          image: argoproj/argosay:v2\n          imagePullPolicy: IfNotPresent\n          command: [\"sh\", -c]\n          args: [\"echo hello\"]\n`)\n\n\t\ts.e().GET(\"/api/v1/cron-workflows/argo\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test=subject-2\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\n\tvar resourceVersion string\n\ts.Run(\"Get\", func() {\n\t\ts.e().GET(\"/api/v1/cron-workflows/argo/not-found\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t\tresourceVersion = s.e().GET(\"/api/v1/cron-workflows/argo/test\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.resourceVersion\").\n\t\t\tString().\n\t\t\tRaw()\n\t})\n\n\ts.Run(\"Update\", func() {\n\t\ts.e().PUT(\"/api/v1/cron-workflows/argo/test\").\n\t\t\tWithBytes([]byte(`{\"cronWorkflow\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"resourceVersion\": \"` + resourceVersion + `\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"schedule\": \"1 * * * *\",\n      \"workflowMetadata\": {\n        \"labels\": {\"workflows.argoproj.io/test\": \"true\"}\n      },\n      \"workflowSpec\": {\n        \"entrypoint\": \"whalesay\",\n        \"templates\": [\n          {\n            \"name\": \"whalesay\",\n            \"container\": {\n              \"image\": \"argoproj/argosay:v2\",\n              \"imagePullPolicy\": \"IfNotPresent\"\n            }\n          }\n        ]\n      }\n    }\n  }}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec.schedule\").\n\t\t\tEqual(\"1 * * * *\")\n\t})\n\n\ts.Run(\"Delete\", func() {\n\t\ts.e().DELETE(\"/api/v1/cron-workflows/argo/test\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\n// make sure we can download an artifact\nfunc (s *ArgoServerSuite) TestArtifactServer() {\n\tvar uid types.UID\n\tvar name string\n\ts.Given().\n\t\tWorkflow(`@testdata/artifact-workflow.yaml`).\n\t\tWhen().\n\t\tSubmitWorkflow().\n\t\tWaitForWorkflow(fixtures.ToBeArchived).\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, status *wfv1.WorkflowStatus) {\n\t\t\tname = metadata.Name\n\t\t\tuid = metadata.UID\n\t\t})\n\n\ts.Run(\"GetArtifact\", func() {\n\t\tresp := s.e().GET(\"/artifacts/argo/\" + name + \"/\" + name + \"/main-file\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\tresp.Body().\n\t\t\tContains(\":) Hello Argo!\")\n\n\t})\n\n\t// In this case, the artifact name is a file\n\ts.Run(\"GetArtifactFile\", func() {\n\t\tresp := s.e().GET(\"/artifact-files/argo/workflows/\" + name + \"/\" + name + \"/outputs/main-file\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\tresp.Body().\n\t\t\tContains(\":) Hello Argo!\")\n\n\t})\n\n\t// In this case, the artifact name is a directory\n\ts.Run(\"GetArtifactFileDirectory\", func() {\n\t\tresp := s.e().GET(\"/artifact-files/argo/workflows/\" + name + \"/\" + name + \"/outputs/out/\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\tresp.Body().\n\t\t\tContains(\"<a href=\\\"subdirectory/\\\">subdirectory/</a>\")\n\n\t})\n\n\t// In this case, the filename specified in the request is actually a directory\n\ts.Run(\"GetArtifactFileSubdirectory\", func() {\n\t\tresp := s.e().GET(\"/artifact-files/argo/workflows/\" + name + \"/\" + name + \"/outputs/out/subdirectory/\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\tresp.Body().\n\t\t\tContains(\"<a href=\\\"sub-file-1\\\">sub-file-1</a>\").\n\t\t\tContains(\"<a href=\\\"sub-file-2\\\">sub-file-2</a>\")\n\n\t})\n\n\t// In this case, the filename specified in the request is a subdirectory file\n\ts.Run(\"GetArtifactSubfile\", func() {\n\t\tresp := s.e().GET(\"/artifact-files/argo/workflows/\" + name + \"/\" + name + \"/outputs/out/subdirectory/sub-file-1\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\tresp.Body().\n\t\t\tContains(\":) Hello Argo!\")\n\n\t})\n\n\t// In this case, the artifact name is a file\n\ts.Run(\"GetArtifactBadFile\", func() {\n\t\t_ = s.e().GET(\"/artifact-files/argo/workflows/\" + name + \"/\" + name + \"/outputs/not-a-file\").\n\t\t\tExpect().\n\t\t\tStatus(500)\n\t})\n\n\ts.Run(\"GetArtifactByUID\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\ts.e().GET(\"/artifacts-by-uid/{uid}/{name}/main-file\", uid, name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tBody().\n\t\t\tContains(\":) Hello Argo!\")\n\t})\n\n\t// as the artifact server has some special code for cookies, we best test that too\n\ts.Run(\"GetArtifactByUIDUsingCookie\", func() {\n\t\ttoken := s.bearerToken\n\t\tdefer func() { s.bearerToken = token }()\n\t\ts.bearerToken = \"\"\n\t\ts.e().GET(\"/artifacts-by-uid/{uid}/{name}/main-file\", uid, name).\n\t\t\tWithHeader(\"Cookie\", \"authorization=Bearer \"+token).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"GetArtifactFileByUID\", func() {\n\t\ts.e().GET(\"/artifact-files/argo/archived-workflows/{uid}/{name}/outputs/main-file\", uid, name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tBody().\n\t\t\tContains(\":) Hello Argo!\")\n\t})\n}\n\nfunc (s *ArgoServerSuite) stream(url string, f func(t *testing.T, line string) (done bool)) {\n\tt := s.T()\n\treq, err := http.NewRequest(\"GET\", baseUrl+url, nil)\n\tassert.NoError(t, err)\n\treq.Header.Set(\"Accept\", \"text/event-stream\")\n\treq.Header.Set(\"Authorization\", \"Bearer \"+s.bearerToken)\n\treq.Close = true\n\tresp, err := httpClient.Do(req)\n\tassert.NoError(t, err)\n\tdefer func() {\n\t\tif resp != nil && resp.Body != nil {\n\t\t\t_ = resp.Body.Close()\n\t\t}\n\t}()\n\tassert.Equal(t, 200, resp.StatusCode)\n\tassert.Equal(t, \"text/event-stream\", resp.Header.Get(\"Content-Type\"))\n\tif t.Failed() {\n\t\tt.FailNow()\n\t}\n\tif f == nil {\n\t\treturn\n\t}\n\tscanner := bufio.NewScanner(resp.Body)\n\tfor scanner.Scan() {\n\t\tline := scanner.Text()\n\t\tlog.WithField(\"line\", line).Debug()\n\t\t// make sure we have this enabled\n\t\tif line == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tif f(t, line) || t.Failed() {\n\t\t\treturn\n\t\t}\n\t}\n}\n\n// do some basic testing on the stream methods\nfunc (s *ArgoServerSuite) TestWorkflowServiceStream() {\n\tvar name string\n\ts.Given().\n\t\tWorkflow(\"@smoke/basic.yaml\").\n\t\tWhen().\n\t\tSubmitWorkflow().\n\t\tWaitForWorkflow(fixtures.ToStart).\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, status *wfv1.WorkflowStatus) {\n\t\t\tname = metadata.Name\n\t\t})\n\n\t// use the watch to make sure that the workflow has succeeded\n\ts.Run(\"Watch\", func() {\n\t\ts.stream(\"/api/v1/workflow-events/argo?listOptions.fieldSelector=metadata.name=\"+name, func(t *testing.T, line string) (done bool) {\n\t\t\tif strings.Contains(line, `status:`) {\n\t\t\t\tassert.Contains(t, line, `\"offloadNodeStatus\":true`)\n\t\t\t\t// so that we get this\n\t\t\t\tassert.Contains(t, line, `\"nodes\":`)\n\t\t\t}\n\t\t\treturn strings.Contains(line, \"Succeeded\")\n\t\t})\n\t})\n\n\t// then,  lets see what events we got\n\ts.Run(\"WatchEvents\", func() {\n\t\ts.stream(\"/api/v1/stream/events/argo?listOptions.fieldSelector=involvedObject.kind=Workflow,involvedObject.name=\"+name, func(t *testing.T, line string) (done bool) {\n\t\t\treturn strings.Contains(line, \"WorkflowRunning\")\n\t\t})\n\t})\n\n\t// then,  lets check the logs\n\tfor _, tt := range []struct {\n\t\tname string\n\t\tpath string\n\t}{\n\t\t{\"PodLogs\", \"/\" + name + \"/log?logOptions.container=main&logOptions.tailLines=3\"},\n\t\t{\"WorkflowLogs\", \"/log?podName=\" + name + \"&logOptions.container=main&logOptions.tailLines=3\"},\n\t} {\n\t\ts.Run(tt.name, func() {\n\t\t\ts.stream(\"/api/v1/workflows/argo/\"+name+tt.path, func(t *testing.T, line string) (done bool) {\n\t\t\t\tif strings.Contains(line, \"data: \") {\n\t\t\t\t\tassert.Contains(t, line, fmt.Sprintf(`\"podName\":\"%s\"`, name))\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t\treturn false\n\t\t\t})\n\t\t})\n\t}\n}\n\nfunc (s *ArgoServerSuite) TestArchivedWorkflowService() {\n\tvar uid types.UID\n\ts.Given().\n\t\tWorkflow(`\nmetadata:\n  generateName: archie-\n  labels:\n    foo: 1\nspec:\n  entrypoint: run-archie\n  templates:\n    - name: run-archie\n      container:\n        image: argoproj/argosay:v2`).\n\t\tWhen().\n\t\tSubmitWorkflow().\n\t\tWaitForWorkflow(fixtures.ToBeArchived).\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, status *wfv1.WorkflowStatus) {\n\t\t\tuid = metadata.UID\n\t\t})\n\tvar failedUid types.UID\n\tvar failedName string\n\ts.Given().\n\t\tWorkflow(`\nmetadata:\n  generateName: jughead-\n  labels:\n    foo: 3\nspec:\n  entrypoint: run-jughead\n  templates:\n    - name: run-jughead\n      container:\n        image: argoproj/argosay:v2\n        command: [sh, -c]\n        args: [\"echo intentional failure; exit 1\"]`).\n\t\tWhen().\n\t\tSubmitWorkflow().\n\t\tWaitForWorkflow(fixtures.ToBeArchived).\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, status *wfv1.WorkflowStatus) {\n\t\t\tfailedUid = metadata.UID\n\t\t\tfailedName = metadata.Name\n\t\t})\n\ts.Given().\n\t\tWorkflow(`\nmetadata:\n  generateName: betty-\n  labels:\n    foo: 2\nspec:\n  entrypoint: run-betty\n  templates:\n    - name: run-betty\n      container:\n        image: argoproj/argosay:v2`).\n\t\tWhen().\n\t\tSubmitWorkflow().\n\t\tWaitForWorkflow(fixtures.ToBeArchived)\n\n\tfor _, tt := range []struct {\n\t\tname     string\n\t\tselector string\n\t\twantLen  int\n\t}{\n\t\t{\"ListDoesNotExist\", \"!foo\", 0},\n\t\t{\"ListEquals\", \"foo=1\", 1},\n\t\t{\"ListDoubleEquals\", \"foo==1\", 1},\n\t\t{\"ListIn\", \"foo in (1)\", 1},\n\t\t{\"ListNotEquals\", \"foo!=1\", 2},\n\t\t{\"ListNotIn\", \"foo notin (1)\", 2},\n\t\t{\"ListExists\", \"foo\", 3},\n\t\t{\"ListGreaterThan0\", \"foo>0\", 3},\n\t\t{\"ListGreaterThan1\", \"foo>1\", 2},\n\t\t{\"ListLessThan1\", \"foo<1\", 0},\n\t\t{\"ListLessThan2\", \"foo<2\", 1},\n\t} {\n\t\ts.Run(tt.name, func() {\n\t\t\tpath := s.e().GET(\"/api/v1/archived-workflows\").\n\t\t\t\tWithQuery(\"listOptions.fieldSelector\", \"metadata.namespace=argo\").\n\t\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test,\"+tt.selector).\n\t\t\t\tExpect().\n\t\t\t\tStatus(200).\n\t\t\t\tJSON().\n\t\t\t\tPath(\"$.items\")\n\n\t\t\tif tt.wantLen == 0 {\n\t\t\t\tpath.Null()\n\t\t\t} else {\n\t\t\t\tpath.Array().\n\t\t\t\t\tLength().\n\t\t\t\t\tEqual(tt.wantLen)\n\t\t\t}\n\t\t})\n\t}\n\n\ts.Run(\"ListWithLimitAndOffset\", func() {\n\t\tj := s.e().GET(\"/api/v1/archived-workflows\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tWithQuery(\"listOptions.fieldSelector\", \"metadata.namespace=argo\").\n\t\t\tWithQuery(\"listOptions.limit\", 1).\n\t\t\tWithQuery(\"listOptions.offset\", 1).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t\tj.\n\t\t\tPath(\"$.metadata.continue\").\n\t\t\tEqual(\"1\")\n\t})\n\n\ts.Run(\"ListWithMinStartedAtGood\", func() {\n\t\tfieldSelector := \"metadata.namespace=argo,spec.startedAt>\" + time.Now().Add(-1*time.Hour).Format(time.RFC3339) + \",spec.startedAt<\" + time.Now().Add(1*time.Hour).Format(time.RFC3339)\n\t\ts.e().GET(\"/api/v1/archived-workflows\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tWithQuery(\"listOptions.fieldSelector\", fieldSelector).\n\t\t\tWithQuery(\"listOptions.limit\", 2).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(2)\n\t})\n\n\ts.Run(\"ListWithMinStartedAtBad\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tWithQuery(\"listOptions.fieldSelector\", \"metadata.namespace=argo,spec.startedAt>\"+time.Now().Add(1*time.Hour).Format(time.RFC3339)).\n\t\t\tWithQuery(\"listOptions.limit\", 2).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").Null()\n\t})\n\n\ts.Run(\"Get\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows/not-found\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t\ts.e().GET(\"/api/v1/archived-workflows/{uid}\", uid).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tNotNull()\n\t})\n\n\ts.Run(\"DeleteForRetry\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflows/argo/\" + failedName).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"Retry\", func() {\n\t\ts.e().PUT(\"/api/v1/archived-workflows/{uid}/retry\", failedUid).\n\t\t\tWithBytes([]byte(`{\"namespace\": \"argo\"}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tNotNull()\n\t\ts.e().PUT(\"/api/v1/archived-workflows/{uid}/retry\", failedUid).\n\t\t\tWithBytes([]byte(`{\"namespace\": \"argo\"}`)).\n\t\t\tExpect().\n\t\t\tStatus(409)\n\t})\n\n\ts.Run(\"Resubmit\", func() {\n\t\ts.e().PUT(\"/api/v1/archived-workflows/{uid}/resubmit\", uid).\n\t\t\tWithBytes([]byte(`{\"namespace\": \"argo\", \"memoized\": false}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tNotNull()\n\t})\n\n\ts.Run(\"Delete\", func() {\n\t\ts.e().DELETE(\"/api/v1/archived-workflows/{uid}\", uid).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t\ts.e().DELETE(\"/api/v1/archived-workflows/{uid}\", uid).\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t})\n\n\ts.Run(\"ListLabelKeys\", func() {\n\t\tj := s.e().GET(\"/api/v1/archived-workflows-label-keys\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tGt(0)\n\t})\n\n\ts.Run(\"ListLabelValues\", func() {\n\t\tj := s.e().GET(\"/api/v1/archived-workflows-label-values\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\n}\n\nfunc (s *ArgoServerSuite) TestWorkflowTemplateService() {\n\ts.Run(\"Lint\", func() {\n\t\ts.e().POST(\"/api/v1/workflow-templates/argo/lint\").\n\t\t\tWithBytes([]byte(`{\n  \"template\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"name\": \"\",\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"Create\", func() {\n\t\ts.e().POST(\"/api/v1/workflow-templates/argo\").\n\t\t\tWithBytes([]byte(`{\n  \"template\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"subject-3\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"name\": \"\",\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"List\", func() {\n\t\t// make sure list options work correctly\n\t\ts.Given().\n\t\t\tWorkflowTemplate(\"@smoke/workflow-template-whalesay-template.yaml\").\n\t\t\tWhen().\n\t\t\tCreateWorkflowTemplates()\n\n\t\ts.e().GET(\"/api/v1/workflow-templates/argo\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test=subject-3\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\n\tvar resourceVersion string\n\ts.Run(\"Get\", func() {\n\t\ts.e().GET(\"/api/v1/workflow-templates/argo/not-found\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\n\t\tresourceVersion = s.e().GET(\"/api/v1/workflow-templates/argo/test\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.resourceVersion\").\n\t\t\tString().\n\t\t\tRaw()\n\t})\n\n\ts.Run(\"Update\", func() {\n\t\ts.e().PUT(\"/api/v1/workflow-templates/argo/test\").\n\t\t\tWithBytes([]byte(`{\"template\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"resourceVersion\": \"` + resourceVersion + `\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"name\": \"\",\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec.templates[0].container.image\").\n\t\t\tEqual(\"argoproj/argosay:v2\")\n\t})\n\n\ts.Run(\"Delete\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflow-templates/argo/test\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestSubmitWorkflowFromResource() {\n\ts.Run(\"CreateWFT\", func() {\n\t\ts.e().POST(\"/api/v1/workflow-templates/argo\").\n\t\t\tWithBytes([]byte(`{\n  \"template\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"subject-4\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"name\": \"\",\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).Expect().Status(200)\n\t})\n\n\ts.Run(\"SubmitWFT\", func() {\n\t\ts.e().POST(\"/api/v1/workflows/argo/submit\").\n\t\t\tWithBytes([]byte(`{\n\t\t\t  \"resourceKind\": \"WorkflowTemplate\",\n\t\t\t  \"resourceName\": \"test\",\n\t\t\t  \"submitOptions\": {\n                \"labels\": \"workflows.argoproj.io/test=true\"\n              }\n\t\t\t}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"CreateCronWF\", func() {\n\t\ts.e().POST(\"/api/v1/cron-workflows/argo\").\n\t\t\tWithBytes([]byte(`{\n  \"cronWorkflow\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"subject-5\"\n      }\n    },\n    \"spec\": {\n      \"schedule\": \"* * * * *\",\n      \"workflowSpec\": {\n        \"entrypoint\": \"whalesay\",\n        \"templates\": [\n          {\n            \"name\": \"whalesay\",\n            \"container\": {\n              \"image\": \"argoproj/argosay:v2\",\n              \"imagePullPolicy\": \"IfNotPresent\"\n            }\n          }\n        ]\n      }\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\ts.Run(\"SubmitWFT\", func() {\n\t\ts.e().POST(\"/api/v1/workflows/argo/submit\").\n\t\t\tWithBytes([]byte(`{\n\t\t\t  \"resourceKind\": \"cronworkflow\",\n\t\t\t  \"resourceName\": \"test\",\n\t\t\t  \"submitOptions\": {\n                \"labels\": \"workflows.argoproj.io/test=true\"\n              }\n\t\t\t}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"CreateCWFT\", func() {\n\t\ts.e().POST(\"/api/v1/cluster-workflow-templates\").\n\t\t\tWithBytes([]byte(`{\n  \"template\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"subject-6\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"name\": \"\",\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).Expect().Status(200)\n\t})\n\n\ts.Run(\"SubmitCWFT\", func() {\n\t\ts.e().POST(\"/api/v1/workflows/argo/submit\").\n\t\t\tWithBytes([]byte(`{\n\t\t\t  \"resourceKind\": \"ClusterWorkflowTemplate\",\n\t\t\t  \"resourceName\": \"test\",\n\t\t\t  \"submitOptions\": {\n                \"labels\": \"workflows.argoproj.io/test=true\"\n              }\n\t\t\t}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestEventSourcesService() {\n\ts.Run(\"CreateEventSource\", func() {\n\t\ts.e().POST(\"/api/v1/event-sources/argo\").\n\t\t\tWithBytes([]byte(`\n{\n  \"eventsource\": {\n    \"metadata\": {\n      \"name\": \"test-event-source\", \n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"calendar\": {\n        \"example-with-interval\": {\n          \"interval\": \"10s\"\n        }\n      }\n    }\n  }\n}\n`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.resourceVersion\").\n\t\t\tNotNull().\n\t\t\tString().\n\t\t\tRaw()\n\t})\n\ts.Run(\"ListEventSources\", func() {\n\t\ts.e().GET(\"/api/v1/event-sources/argo\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\ts.Run(\"WatchEventSources\", func() {\n\t\ts.stream(\"/api/v1/stream/event-sources/argo\", func(t *testing.T, line string) (done bool) {\n\t\t\tassert.Contains(t, line, \"test-event-source\")\n\t\t\treturn true\n\t\t})\n\t})\n\ts.Run(\"EventSourcesLogs\", func() {\n\t\ts.T().Skip(\"we do not install the controllers, so we won't get any logs\")\n\t\ts.stream(\"/api/v1/stream/event-sources/argo/logs\", func(t *testing.T, line string) (done bool) {\n\t\t\tassert.Contains(t, line, \"test-event-source\")\n\t\t\treturn true\n\t\t})\n\t})\n\tvar resourceVersion string\n\ts.Run(\"GetEventSource\", func() {\n\t\tresourceVersion = s.e().GET(\"/api/v1/event-sources/argo/test-event-source\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.resourceVersion\").\n\t\t\tNotNull().\n\t\t\tString().\n\t\t\tRaw()\n\t})\n\ts.Run(\"UpdateEventSource\", func() {\n\t\ts.e().PUT(\"/api/v1/event-sources/argo/test-event-source\").\n\t\t\tWithBytes([]byte(`\n{\n  \"eventsource\": {\n    \"metadata\": {\n      \"name\": \"test-event-source\", \n      \"resourceVersion\": \"` + resourceVersion + `\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"calendar\": {\n        \"example-with-interval\": {\n          \"interval\": \"10s\"\n        }\n      }\n    }\n  }\n}\n`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\ts.Run(\"DeleteEventSource\", func() {\n\t\ts.e().DELETE(\"/api/v1/event-sources/argo/test-event-source\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestPipelineService() {\n\ts.T().SkipNow()\n\ts.Run(\"GetPipeline\", func() {\n\t\ts.e().GET(\"/api/v1/pipelines/argo/not-exists\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t})\n\ts.Run(\"ListPipelines\", func() {\n\t\ts.e().GET(\"/api/v1/pipelines/argo\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestSensorService() {\n\ts.Run(\"CreateSensor\", func() {\n\t\ts.e().POST(\"/api/v1/sensors/argo\").\n\t\t\tWithBytes([]byte(`\n{\n\t\"sensor\":{\n\t\t\"metadata\":{\n\t\t\t\"name\":\"test-sensor\",\n\t\t\t\"labels\": {\n\t\t\t\t\"workflows.argoproj.io/test\": \"true\"\n\t\t\t}\n\t\t},\n\t\t\"spec\":{\n\t\t\t\"dependencies\":[\n\t\t\t\t{\n\t\t\t\t\t\"name\":\"test-dep\",\n\t\t\t\t\t\"eventSourceName\":\"calendar\",\n\t\t\t\t\t\"eventName\":\"example-with-interval\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"triggers\":[\n\t\t\t\t{\n\t\t\t\t\t\"template\":{\n\t\t\t\t\t\t\"name\":\"log-trigger\",\n\t\t\t\t\t\t\"log\":{\n\t\t\t\t\t\t\t\"intervalSeconds\":20\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t}\n}\n`)).Expect().\n\t\t\tStatus(200)\n\t})\n\ts.Run(\"ListSensors\", func() {\n\t\ts.e().GET(\"/api/v1/sensors/argo\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\ts.Run(\"GetSensor\", func() {\n\t\ts.e().GET(\"/api/v1/sensors/argo/test-sensor\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tEqual(\"test-sensor\")\n\t})\n\ts.Run(\"WatchSensors\", func() {\n\t\ts.stream(\"/api/v1/stream/sensors/argo\", func(t *testing.T, line string) (done bool) {\n\t\t\tassert.Contains(t, line, \"test-sensor\")\n\t\t\treturn true\n\t\t})\n\t})\n\ts.Run(\"SensorsLogs\", func() {\n\t\ts.T().Skip(\"we do not install the controllers, so we won't get any logs\")\n\t\ts.stream(\"/api/v1/stream/sensors/argo/logs\", func(t *testing.T, line string) (done bool) {\n\t\t\tassert.Contains(t, line, \"test-sensor\")\n\t\t\treturn true\n\t\t})\n\t})\n\tresourceVersion := s.e().GET(\"/api/v1/sensors/argo/test-sensor\").\n\t\tExpect().\n\t\tStatus(200).\n\t\tJSON().\n\t\tPath(\"$.metadata.resourceVersion\").\n\t\tString().\n\t\tRaw()\n\ts.Run(\"UpdateSensor\", func() {\n\t\ts.e().PUT(\"/api/v1/sensors/argo/test-sensor\").\n\t\t\tWithBytes([]byte(`\n{\n\t\"sensor\":{\n\t\t\"metadata\":{\n\t\t\t\"name\":\"test-sensor\",\n\t\t\t\"resourceVersion\": \"` + resourceVersion + `\",\n\t\t\t\"labels\": {\n\t\t\t\t\"workflows.argoproj.io/test\": \"true\"\n\t\t\t}\n\t\t},\n\t\t\"spec\": {\n\t\t\t\"template\": {\n\t\t\t\t\"serviceAccountName\": \"default\"\n\t\t\t},\n\t\t\t\"dependencies\":[\n\t\t\t\t{\n\t\t\t\t\t\"name\":\"test-dep\",\n\t\t\t\t\t\"eventSourceName\":\"calendar\",\n\t\t\t\t\t\"eventName\":\"example-with-interval\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"triggers\":[\n\t\t\t\t{\n\t\t\t\t\t\"template\":{\n\t\t\t\t\t\t\"name\":\"log-trigger\",\n\t\t\t\t\t\t\"log\":{\n\t\t\t\t\t\t\t\"intervalSeconds\":20\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t}\n}\n`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\ts.Run(\"GetSensorAfterUpdating\", func() {\n\t\ts.e().GET(\"/api/v1/sensors/argo/test-sensor\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec.template.serviceAccountName\").\n\t\t\tEqual(\"default\")\n\t})\n\ts.Run(\"DeleteSensor\", func() {\n\t\ts.e().DELETE(\"/api/v1/sensors/argo/test-sensor\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc TestArgoServerSuite(t *testing.T) {\n\tsuite.Run(t, new(ArgoServerSuite))\n}\n"], "fixing_code": ["package apiserver\n\nimport (\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/gorilla/handlers\"\n\tgrpc_middleware \"github.com/grpc-ecosystem/go-grpc-middleware\"\n\tgrpc_logrus \"github.com/grpc-ecosystem/go-grpc-middleware/logging/logrus\"\n\tgrpc_prometheus \"github.com/grpc-ecosystem/go-grpc-prometheus\"\n\t\"github.com/grpc-ecosystem/grpc-gateway/runtime\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"github.com/soheilhy/cmux\"\n\t\"golang.org/x/net/context\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/credentials\"\n\t\"google.golang.org/grpc/credentials/insecure\"\n\t\"google.golang.org/grpc/metadata\"\n\tv1 \"k8s.io/api/core/v1\"\n\t\"k8s.io/apimachinery/pkg/util/wait\"\n\t\"k8s.io/client-go/rest\"\n\t\"k8s.io/utils/env\"\n\n\t\"github.com/argoproj/argo-workflows/v3\"\n\t\"github.com/argoproj/argo-workflows/v3/config\"\n\t\"github.com/argoproj/argo-workflows/v3/persist/sqldb\"\n\tclusterwftemplatepkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/clusterworkflowtemplate\"\n\tcronworkflowpkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/cronworkflow\"\n\teventpkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/event\"\n\teventsourcepkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/eventsource\"\n\tinfopkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/info\"\n\tpipelinepkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/pipeline\"\n\tsensorpkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/sensor\"\n\tworkflowpkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/workflow\"\n\tworkflowarchivepkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/workflowarchive\"\n\tworkflowtemplatepkg \"github.com/argoproj/argo-workflows/v3/pkg/apiclient/workflowtemplate\"\n\t\"github.com/argoproj/argo-workflows/v3/pkg/apis/workflow/v1alpha1\"\n\t\"github.com/argoproj/argo-workflows/v3/server/apiserver/accesslog\"\n\t\"github.com/argoproj/argo-workflows/v3/server/artifacts\"\n\t\"github.com/argoproj/argo-workflows/v3/server/auth\"\n\t\"github.com/argoproj/argo-workflows/v3/server/auth/sso\"\n\t\"github.com/argoproj/argo-workflows/v3/server/auth/webhook\"\n\t\"github.com/argoproj/argo-workflows/v3/server/cache\"\n\t\"github.com/argoproj/argo-workflows/v3/server/clusterworkflowtemplate\"\n\t\"github.com/argoproj/argo-workflows/v3/server/cronworkflow\"\n\t\"github.com/argoproj/argo-workflows/v3/server/event\"\n\t\"github.com/argoproj/argo-workflows/v3/server/eventsource\"\n\t\"github.com/argoproj/argo-workflows/v3/server/info\"\n\tpipeline \"github.com/argoproj/argo-workflows/v3/server/pipeline\"\n\t\"github.com/argoproj/argo-workflows/v3/server/sensor\"\n\t\"github.com/argoproj/argo-workflows/v3/server/static\"\n\t\"github.com/argoproj/argo-workflows/v3/server/types\"\n\t\"github.com/argoproj/argo-workflows/v3/server/workflow\"\n\t\"github.com/argoproj/argo-workflows/v3/server/workflowarchive\"\n\t\"github.com/argoproj/argo-workflows/v3/server/workflowtemplate\"\n\tgrpcutil \"github.com/argoproj/argo-workflows/v3/util/grpc\"\n\t\"github.com/argoproj/argo-workflows/v3/util/instanceid\"\n\t\"github.com/argoproj/argo-workflows/v3/util/json\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/artifactrepositories\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/events\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/hydrator\"\n)\n\nvar MaxGRPCMessageSize int\n\ntype argoServer struct {\n\tbaseHRef string\n\t// https://itnext.io/practical-guide-to-securing-grpc-connections-with-go-and-tls-part-1-f63058e9d6d1\n\ttlsConfig                *tls.Config\n\thsts                     bool\n\tnamespace                string\n\tmanagedNamespace         string\n\tclients                  *types.Clients\n\tgatekeeper               auth.Gatekeeper\n\toAuth2Service            sso.Interface\n\tconfigController         config.Controller\n\tstopCh                   chan struct{}\n\teventQueueSize           int\n\teventWorkerCount         int\n\teventAsyncDispatch       bool\n\txframeOptions            string\n\taccessControlAllowOrigin string\n\tcache                    *cache.ResourceCache\n}\n\ntype ArgoServerOpts struct {\n\tBaseHRef   string\n\tTLSConfig  *tls.Config\n\tNamespaced bool\n\tNamespace  string\n\tClients    *types.Clients\n\tRestConfig *rest.Config\n\tAuthModes  auth.Modes\n\t// config map name\n\tConfigName               string\n\tManagedNamespace         string\n\tSSONameSpace             string\n\tHSTS                     bool\n\tEventOperationQueueSize  int\n\tEventWorkerCount         int\n\tEventAsyncDispatch       bool\n\tXFrameOptions            string\n\tAccessControlAllowOrigin string\n}\n\nfunc init() {\n\tvar err error\n\tMaxGRPCMessageSize, err = env.GetInt(\"GRPC_MESSAGE_SIZE\", 100*1024*1024)\n\tif err != nil {\n\t\tlog.Fatalf(\"GRPC_MESSAGE_SIZE environment variable must be set as an integer: %v\", err)\n\t}\n}\n\nfunc getResourceCacheNamespace(opts ArgoServerOpts) string {\n\tif opts.Namespaced {\n\t\treturn opts.SSONameSpace\n\t}\n\treturn v1.NamespaceAll\n}\n\nfunc NewArgoServer(ctx context.Context, opts ArgoServerOpts) (*argoServer, error) {\n\tconfigController := config.NewController(opts.Namespace, opts.ConfigName, opts.Clients.Kubernetes)\n\tvar resourceCache *cache.ResourceCache = nil\n\tssoIf := sso.NullSSO\n\tif opts.AuthModes[auth.SSO] {\n\t\tc, err := configController.Get(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tssoIf, err = sso.New(c.SSO, opts.Clients.Kubernetes.CoreV1().Secrets(opts.Namespace), opts.BaseHRef, opts.TLSConfig != nil)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tresourceCache = cache.NewResourceCache(opts.Clients.Kubernetes, ctx, getResourceCacheNamespace(opts))\n\t\tlog.Info(\"SSO enabled\")\n\t} else {\n\t\tlog.Info(\"SSO disabled\")\n\t}\n\tgatekeeper, err := auth.NewGatekeeper(opts.AuthModes, opts.Clients, opts.RestConfig, ssoIf, auth.DefaultClientForAuthorization, opts.Namespace, opts.SSONameSpace, opts.Namespaced, resourceCache)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &argoServer{\n\t\tbaseHRef:                 opts.BaseHRef,\n\t\ttlsConfig:                opts.TLSConfig,\n\t\thsts:                     opts.HSTS,\n\t\tnamespace:                opts.Namespace,\n\t\tmanagedNamespace:         opts.ManagedNamespace,\n\t\tclients:                  opts.Clients,\n\t\tgatekeeper:               gatekeeper,\n\t\toAuth2Service:            ssoIf,\n\t\tconfigController:         configController,\n\t\tstopCh:                   make(chan struct{}),\n\t\teventQueueSize:           opts.EventOperationQueueSize,\n\t\teventWorkerCount:         opts.EventWorkerCount,\n\t\teventAsyncDispatch:       opts.EventAsyncDispatch,\n\t\txframeOptions:            opts.XFrameOptions,\n\t\taccessControlAllowOrigin: opts.AccessControlAllowOrigin,\n\t\tcache:                    resourceCache,\n\t}, nil\n}\n\nvar backoff = wait.Backoff{\n\tSteps:    5,\n\tDuration: 500 * time.Millisecond,\n\tFactor:   1.0,\n\tJitter:   0.1,\n}\n\nfunc (as *argoServer) Run(ctx context.Context, port int, browserOpenFunc func(string)) {\n\tconfig, err := as.configController.Get(ctx)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlog.WithFields(log.Fields{\"version\": argo.GetVersion().Version, \"instanceID\": config.InstanceID}).Info(\"Starting Argo Server\")\n\tinstanceIDService := instanceid.NewService(config.InstanceID)\n\toffloadRepo := sqldb.ExplosiveOffloadNodeStatusRepo\n\twfArchive := sqldb.NullWorkflowArchive\n\tpersistence := config.Persistence\n\tif persistence != nil {\n\t\tsession, tableName, err := sqldb.CreateDBSession(as.clients.Kubernetes, as.namespace, persistence)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\t// we always enable node offload, as this is read-only for the Argo Server, i.e. you can turn it off if you\n\t\t// like and the controller won't offload newly created workflows, but you can still read them\n\t\toffloadRepo, err = sqldb.NewOffloadNodeStatusRepo(session, persistence.GetClusterName(), tableName)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\t// we always enable the archive for the Argo Server, as the Argo Server does not write records, so you can\n\t\t// disable the archiving - and still read old records\n\t\twfArchive = sqldb.NewWorkflowArchive(session, persistence.GetClusterName(), as.managedNamespace, instanceIDService)\n\t}\n\teventRecorderManager := events.NewEventRecorderManager(as.clients.Kubernetes)\n\tartifactRepositories := artifactrepositories.New(as.clients.Kubernetes, as.managedNamespace, &config.ArtifactRepository)\n\tartifactServer := artifacts.NewArtifactServer(as.gatekeeper, hydrator.New(offloadRepo), wfArchive, instanceIDService, artifactRepositories)\n\teventServer := event.NewController(instanceIDService, eventRecorderManager, as.eventQueueSize, as.eventWorkerCount, as.eventAsyncDispatch)\n\tgrpcServer := as.newGRPCServer(instanceIDService, offloadRepo, wfArchive, eventServer, config.Links, config.NavColor)\n\thttpServer := as.newHTTPServer(ctx, port, artifactServer)\n\n\t// Start listener\n\tvar conn net.Listener\n\tvar listerErr error\n\taddress := fmt.Sprintf(\":%d\", port)\n\terr = wait.ExponentialBackoff(backoff, func() (bool, error) {\n\t\tconn, listerErr = net.Listen(\"tcp\", address)\n\t\tif listerErr != nil {\n\t\t\tlog.Warnf(\"failed to listen: %v\", listerErr)\n\t\t\treturn false, nil\n\t\t}\n\t\treturn true, nil\n\t})\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn\n\t}\n\n\tif as.tlsConfig != nil {\n\t\tconn = tls.NewListener(conn, as.tlsConfig)\n\t}\n\n\t// Cmux is used to support servicing gRPC and HTTP1.1+JSON on the same port\n\ttcpm := cmux.New(conn)\n\thttpL := tcpm.Match(cmux.HTTP1Fast())\n\tgrpcL := tcpm.Match(cmux.Any())\n\n\tgo eventServer.Run(as.stopCh)\n\tgo func() { as.checkServeErr(\"grpcServer\", grpcServer.Serve(grpcL)) }()\n\tgo func() { as.checkServeErr(\"httpServer\", httpServer.Serve(httpL)) }()\n\tgo func() { as.checkServeErr(\"tcpm\", tcpm.Serve()) }()\n\turl := \"http://localhost\" + address\n\tif as.tlsConfig != nil {\n\t\turl = \"https://localhost\" + address\n\t}\n\tlog.WithFields(log.Fields{\n\t\t\"GRPC_MESSAGE_SIZE\": MaxGRPCMessageSize,\n\t}).Info(\"GRPC Server Max Message Size, MaxGRPCMessageSize, is set\")\n\tlog.Infof(\"Argo Server started successfully on %s\", url)\n\tbrowserOpenFunc(url)\n\n\t<-as.stopCh\n}\n\nfunc (as *argoServer) newGRPCServer(instanceIDService instanceid.Service, offloadNodeStatusRepo sqldb.OffloadNodeStatusRepo, wfArchive sqldb.WorkflowArchive, eventServer *event.Controller, links []*v1alpha1.Link, navColor string) *grpc.Server {\n\tserverLog := log.NewEntry(log.StandardLogger())\n\n\t// \"Prometheus histograms are a great way to measure latency distributions of your RPCs. However, since it is bad practice to have metrics of high cardinality the latency monitoring metrics are disabled by default. To enable them please call the following in your server initialization code:\"\n\tgrpc_prometheus.EnableHandlingTimeHistogram()\n\n\tsOpts := []grpc.ServerOption{\n\t\t// Set both the send and receive the bytes limit to be 100MB or GRPC_MESSAGE_SIZE\n\t\t// The proper way to achieve high performance is to have pagination\n\t\t// while we work toward that, we can have high limit first\n\t\tgrpc.MaxRecvMsgSize(MaxGRPCMessageSize),\n\t\tgrpc.MaxSendMsgSize(MaxGRPCMessageSize),\n\t\tgrpc.ConnectionTimeout(300 * time.Second),\n\t\tgrpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer(\n\t\t\tgrpc_prometheus.UnaryServerInterceptor,\n\t\t\tgrpc_logrus.UnaryServerInterceptor(serverLog),\n\t\t\tgrpcutil.PanicLoggerUnaryServerInterceptor(serverLog),\n\t\t\tgrpcutil.ErrorTranslationUnaryServerInterceptor,\n\t\t\tas.gatekeeper.UnaryServerInterceptor(),\n\t\t)),\n\t\tgrpc.StreamInterceptor(grpc_middleware.ChainStreamServer(\n\t\t\tgrpc_prometheus.StreamServerInterceptor,\n\t\t\tgrpc_logrus.StreamServerInterceptor(serverLog),\n\t\t\tgrpcutil.PanicLoggerStreamServerInterceptor(serverLog),\n\t\t\tgrpcutil.ErrorTranslationStreamServerInterceptor,\n\t\t\tas.gatekeeper.StreamServerInterceptor(),\n\t\t)),\n\t}\n\n\tgrpcServer := grpc.NewServer(sOpts...)\n\n\tinfopkg.RegisterInfoServiceServer(grpcServer, info.NewInfoServer(as.managedNamespace, links, navColor))\n\teventpkg.RegisterEventServiceServer(grpcServer, eventServer)\n\teventsourcepkg.RegisterEventSourceServiceServer(grpcServer, eventsource.NewEventSourceServer())\n\tpipelinepkg.RegisterPipelineServiceServer(grpcServer, pipeline.NewPipelineServer())\n\tsensorpkg.RegisterSensorServiceServer(grpcServer, sensor.NewSensorServer())\n\tworkflowpkg.RegisterWorkflowServiceServer(grpcServer, workflow.NewWorkflowServer(instanceIDService, offloadNodeStatusRepo))\n\tworkflowtemplatepkg.RegisterWorkflowTemplateServiceServer(grpcServer, workflowtemplate.NewWorkflowTemplateServer(instanceIDService))\n\tcronworkflowpkg.RegisterCronWorkflowServiceServer(grpcServer, cronworkflow.NewCronWorkflowServer(instanceIDService))\n\tworkflowarchivepkg.RegisterArchivedWorkflowServiceServer(grpcServer, workflowarchive.NewWorkflowArchiveServer(wfArchive))\n\tclusterwftemplatepkg.RegisterClusterWorkflowTemplateServiceServer(grpcServer, clusterworkflowtemplate.NewClusterWorkflowTemplateServer(instanceIDService))\n\tgrpc_prometheus.Register(grpcServer)\n\treturn grpcServer\n}\n\n// newHTTPServer returns the HTTP server to serve HTTP/HTTPS requests. This is implemented\n// using grpc-gateway as a proxy to the gRPC server.\nfunc (as *argoServer) newHTTPServer(ctx context.Context, port int, artifactServer *artifacts.ArtifactServer) *http.Server {\n\tendpoint := fmt.Sprintf(\"localhost:%d\", port)\n\n\tmux := http.NewServeMux()\n\thttpServer := http.Server{\n\t\tAddr:      endpoint,\n\t\tHandler:   accesslog.Interceptor(mux),\n\t\tTLSConfig: as.tlsConfig,\n\t}\n\tdialOpts := []grpc.DialOption{\n\t\tgrpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(MaxGRPCMessageSize)),\n\t}\n\tif as.tlsConfig != nil {\n\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(credentials.NewTLS(as.tlsConfig)))\n\t} else {\n\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(insecure.NewCredentials()))\n\t}\n\n\twebhookInterceptor := webhook.Interceptor(as.clients.Kubernetes)\n\n\t// HTTP 1.1+JSON Server\n\t// grpc-ecosystem/grpc-gateway is used to proxy HTTP requests to the corresponding gRPC call\n\t// NOTE: if a marshaller option is not supplied, grpc-gateway will default to the jsonpb from\n\t// golang/protobuf. Which does not support types such as time.Time. gogo/protobuf does support\n\t// time.Time, but does not support custom UnmarshalJSON() and MarshalJSON() methods. Therefore\n\t// we use our own Marshaler\n\tgwMuxOpts := runtime.WithMarshalerOption(runtime.MIMEWildcard, new(json.JSONMarshaler))\n\tgwmux := runtime.NewServeMux(gwMuxOpts,\n\t\truntime.WithIncomingHeaderMatcher(func(key string) (string, bool) { return key, true }),\n\t\truntime.WithProtoErrorHandler(runtime.DefaultHTTPProtoErrorHandler),\n\t)\n\tmustRegisterGWHandler(infopkg.RegisterInfoServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(eventpkg.RegisterEventServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(eventsourcepkg.RegisterEventSourceServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(sensorpkg.RegisterSensorServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(pipelinepkg.RegisterPipelineServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(workflowpkg.RegisterWorkflowServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(workflowtemplatepkg.RegisterWorkflowTemplateServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(cronworkflowpkg.RegisterCronWorkflowServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(workflowarchivepkg.RegisterArchivedWorkflowServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(clusterwftemplatepkg.RegisterClusterWorkflowTemplateServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\n\tmux.HandleFunc(\"/api/\", func(w http.ResponseWriter, r *http.Request) {\n\t\t// we must delete this header for API request to prevent \"stream terminated by RST_STREAM with error code: PROTOCOL_ERROR\" error\n\t\tr.Header.Del(\"Connection\")\n\t\twebhookInterceptor(w, r, gwmux)\n\t})\n\n\t// emergency environment variable that allows you to disable the artifact service in case of problems\n\tif os.Getenv(\"ARGO_ARTIFACT_SERVER\") != \"false\" {\n\t\tmux.HandleFunc(\"/artifacts/\", artifactServer.GetOutputArtifact)\n\t\tmux.HandleFunc(\"/input-artifacts/\", artifactServer.GetInputArtifact)\n\t\tmux.HandleFunc(\"/artifacts-by-uid/\", artifactServer.GetOutputArtifactByUID)\n\t\tmux.HandleFunc(\"/input-artifacts-by-uid/\", artifactServer.GetInputArtifactByUID)\n\t\tmux.HandleFunc(\"/artifact-files/\", artifactServer.GetArtifactFile)\n\t}\n\tmux.Handle(\"/oauth2/redirect\", handlers.ProxyHeaders(http.HandlerFunc(as.oAuth2Service.HandleRedirect)))\n\tmux.Handle(\"/oauth2/callback\", handlers.ProxyHeaders(http.HandlerFunc(as.oAuth2Service.HandleCallback)))\n\tmux.HandleFunc(\"/metrics\", func(w http.ResponseWriter, r *http.Request) {\n\t\tif os.Getenv(\"ARGO_SERVER_METRICS_AUTH\") != \"false\" {\n\t\t\theader := metadata.New(map[string]string{\"authorization\": r.Header.Get(\"Authorization\")})\n\t\t\tctx := metadata.NewIncomingContext(context.Background(), header)\n\t\t\tif _, err := as.gatekeeper.Context(ctx); err != nil {\n\t\t\t\tlog.WithError(err).Error(\"failed to authenticate /metrics endpoint\")\n\t\t\t\tw.WriteHeader(403)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tpromhttp.Handler().ServeHTTP(w, r)\n\n\t})\n\t// we only enable HTST if we are secure mode, otherwise you would never be able access the UI\n\tmux.HandleFunc(\"/\", static.NewFilesServer(as.baseHRef, as.tlsConfig != nil && as.hsts, as.xframeOptions, as.accessControlAllowOrigin).ServerFiles)\n\treturn &httpServer\n}\n\ntype registerFunc func(ctx context.Context, mux *runtime.ServeMux, endpoint string, opts []grpc.DialOption) error\n\n// mustRegisterGWHandler is a convenience function to register a gateway handler\nfunc mustRegisterGWHandler(register registerFunc, ctx context.Context, mux *runtime.ServeMux, endpoint string, opts []grpc.DialOption) {\n\terr := register(ctx, mux, endpoint, opts)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\n// checkServeErr checks the error from a .Serve() call to decide if it was a graceful shutdown\nfunc (as *argoServer) checkServeErr(name string, err error) {\n\tif err != nil {\n\t\tif as.stopCh == nil {\n\t\t\t// a nil stopCh indicates a graceful shutdown\n\t\t\tlog.Infof(\"graceful shutdown %s: %v\", name, err)\n\t\t} else {\n\t\t\tlog.Fatalf(\"%s: %v\", name, err)\n\t\t}\n\t} else {\n\t\tlog.Infof(\"graceful shutdown %s\", name)\n\t}\n}\n", "package artifacts\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"mime\"\n\t\"net/http\"\n\t\"path\"\n\t\"strings\"\n\n\tlog \"github.com/sirupsen/logrus\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/metadata\"\n\t\"google.golang.org/grpc/status\"\n\tapierr \"k8s.io/apimachinery/pkg/api/errors\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/utils/env\"\n\n\t\"github.com/argoproj/argo-workflows/v3/persist/sqldb\"\n\twfv1 \"github.com/argoproj/argo-workflows/v3/pkg/apis/workflow/v1alpha1\"\n\t\"github.com/argoproj/argo-workflows/v3/server/auth\"\n\t\"github.com/argoproj/argo-workflows/v3/server/types\"\n\t\"github.com/argoproj/argo-workflows/v3/util/instanceid\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/artifactrepositories\"\n\tartifact \"github.com/argoproj/argo-workflows/v3/workflow/artifacts\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/artifacts/common\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/hydrator\"\n)\n\ntype ArtifactServer struct {\n\tgatekeeper           auth.Gatekeeper\n\thydrator             hydrator.Interface\n\twfArchive            sqldb.WorkflowArchive\n\tinstanceIDService    instanceid.Service\n\tartDriverFactory     artifact.NewDriverFunc\n\tartifactRepositories artifactrepositories.Interface\n}\n\nfunc NewArtifactServer(authN auth.Gatekeeper, hydrator hydrator.Interface, wfArchive sqldb.WorkflowArchive, instanceIDService instanceid.Service, artifactRepositories artifactrepositories.Interface) *ArtifactServer {\n\treturn newArtifactServer(authN, hydrator, wfArchive, instanceIDService, artifact.NewDriver, artifactRepositories)\n}\n\nfunc newArtifactServer(authN auth.Gatekeeper, hydrator hydrator.Interface, wfArchive sqldb.WorkflowArchive, instanceIDService instanceid.Service, artDriverFactory artifact.NewDriverFunc, artifactRepositories artifactrepositories.Interface) *ArtifactServer {\n\treturn &ArtifactServer{authN, hydrator, wfArchive, instanceIDService, artDriverFactory, artifactRepositories}\n}\n\nfunc (a *ArtifactServer) GetOutputArtifact(w http.ResponseWriter, r *http.Request) {\n\ta.getArtifact(w, r, false)\n}\n\nfunc (a *ArtifactServer) GetInputArtifact(w http.ResponseWriter, r *http.Request) {\n\ta.getArtifact(w, r, true)\n}\n\n// single endpoint to be able to handle serving directories as well as files, both those that have been archived and those that haven't\n// Valid requests:\n//  /artifact-files/{namespace}/[archived-workflows|workflows]/{id}/{nodeId}/outputs/{artifactName}\n//  /artifact-files/{namespace}/[archived-workflows|workflows]/{id}/{nodeId}/outputs/{artifactName}/{fileName}\n//  /artifact-files/{namespace}/[archived-workflows|workflows]/{id}/{nodeId}/outputs/{artifactName}/{fileDir}/.../{fileName}\n// 'id' field represents 'uid' for archived workflows and 'name' for non-archived\nfunc (a *ArtifactServer) GetArtifactFile(w http.ResponseWriter, r *http.Request) {\n\n\tconst (\n\t\tnamespaceIndex      = 2\n\t\tarchiveDiscrimIndex = 3\n\t\tidIndex             = 4\n\t\tnodeIdIndex         = 5\n\t\tdirectionIndex      = 6\n\t\tartifactNameIndex   = 7\n\t\tfileNameFirstIndex  = 8\n\t)\n\n\tvar fileName *string\n\trequestPath := strings.Split(r.URL.Path, \"/\")\n\tif len(requestPath) >= fileNameFirstIndex+1 { // they included a file path in the URL (not just artifact name)\n\t\tjoined := strings.Join(requestPath[fileNameFirstIndex:], \"/\")\n\t\t// sanitize file name\n\t\tcleanedPath := path.Clean(joined)\n\t\tfileName = &cleanedPath\n\t} else if len(requestPath) < artifactNameIndex+1 {\n\t\ta.httpBadRequestError(w)\n\t\treturn\n\t}\n\n\tnamespace := requestPath[namespaceIndex]\n\tarchiveDiscriminator := requestPath[archiveDiscrimIndex]\n\tid := requestPath[idIndex] // if archiveDiscriminator == \"archived-workflows\", this represents workflow UID; if archiveDiscriminator == \"workflows\", this represents workflow name\n\tnodeId := requestPath[nodeIdIndex]\n\tdirection := requestPath[directionIndex]\n\tartifactName := requestPath[artifactNameIndex]\n\n\tif direction != \"outputs\" { // for now we just handle output artifacts\n\t\ta.httpBadRequestError(w)\n\t\treturn\n\t}\n\n\t// verify user is authorized\n\tctx, err := a.gateKeeping(r, types.NamespaceHolder(namespace))\n\tif err != nil {\n\t\ta.unauthorizedError(w)\n\t\treturn\n\t}\n\n\tvar wf *wfv1.Workflow\n\n\t// retrieve the Workflow\n\tswitch archiveDiscriminator {\n\tcase \"workflows\":\n\t\tworkflowName := id\n\t\tlog.WithFields(log.Fields{\"namespace\": namespace, \"workflowName\": workflowName, \"nodeId\": nodeId, \"artifactName\": artifactName}).Info(\"Get artifact file\")\n\n\t\twf, err = a.getWorkflowAndValidate(ctx, namespace, workflowName)\n\t\tif err != nil {\n\t\t\ta.serverInternalError(err, w)\n\t\t\treturn\n\t\t}\n\tcase \"archived-workflows\":\n\t\tuid := id\n\t\tlog.WithFields(log.Fields{\"namespace\": namespace, \"uid\": uid, \"nodeId\": nodeId, \"artifactName\": artifactName}).Info(\"Get artifact file\")\n\n\t\twf, err = a.wfArchive.GetWorkflow(uid)\n\t\tif err != nil {\n\t\t\ta.serverInternalError(err, w)\n\t\t\treturn\n\t\t}\n\n\t\t// check that the namespace passed in matches this workflow's namespace\n\t\tif wf.GetNamespace() != namespace {\n\t\t\ta.httpBadRequestError(w)\n\t\t\treturn\n\t\t}\n\n\t\t// return 401 if the client does not have permission to get wf\n\t\terr = a.validateAccess(ctx, wf)\n\t\tif err != nil {\n\t\t\ta.unauthorizedError(w)\n\t\t\treturn\n\t\t}\n\tdefault:\n\t\ta.httpBadRequestError(w)\n\t\treturn\n\t}\n\n\tartifact, driver, err := a.getArtifactAndDriver(ctx, nodeId, artifactName, false, wf, fileName)\n\tif err != nil {\n\t\ta.serverInternalError(err, w)\n\t\treturn\n\t}\n\n\tisDir := strings.HasSuffix(r.URL.Path, \"/\")\n\n\tif !isDir {\n\t\tisDir, err := driver.IsDirectory(artifact)\n\t\tif err != nil {\n\t\t\ta.serverInternalError(err, w)\n\t\t\treturn\n\t\t}\n\t\tif isDir {\n\t\t\thttp.Redirect(w, r, r.URL.String()+\"/\", http.StatusTemporaryRedirect)\n\t\t\treturn\n\t\t}\n\t}\n\n\tif isDir {\n\t\t// return an html page to the user\n\n\t\tobjects, err := driver.ListObjects(artifact)\n\t\tif err != nil {\n\t\t\ta.serverInternalError(err, w)\n\t\t\treturn\n\t\t}\n\t\tlog.Debugf(\"this is a directory, artifact: %+v; files: %v\", artifact, objects)\n\n\t\tkey, _ := artifact.GetKey()\n\t\tfor _, object := range objects {\n\n\t\t\t// object is prefixed the key, we must trim it\n\t\t\tdir, file := path.Split(strings.TrimPrefix(object, key+\"/\"))\n\n\t\t\t// if dir is empty string, we are in the root dir\n\t\t\t// we found in index.html, abort and redirect there\n\t\t\tif dir == \"\" && file == \"index.html\" {\n\t\t\t\tw.Header().Set(\"Location\", r.URL.String()+\"index.html\")\n\t\t\t\tw.WriteHeader(http.StatusTemporaryRedirect)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tw.WriteHeader(http.StatusOK)\n\t\t_, _ = w.Write([]byte(\"<html><body><ul>\\n\"))\n\n\t\tdirs := map[string]bool{} // to de-dupe sub-dirs\n\n\t\t_, _ = w.Write([]byte(fmt.Sprintf(\"<li><a href=\\\"%s\\\">%s</a></li>\\n\", \"..\", \"..\")))\n\n\t\tfor _, object := range objects {\n\n\t\t\t// object is prefixed the key, we must trim it\n\t\t\tdir, file := path.Split(strings.TrimPrefix(object, key+\"/\"))\n\n\t\t\t// if dir is empty string, we are in the root dir\n\t\t\tif dir == \"\" {\n\t\t\t\t_, _ = w.Write([]byte(fmt.Sprintf(\"<li><a href=\\\"%s\\\">%s</a></li>\\n\", file, file)))\n\t\t\t} else if dirs[dir] {\n\t\t\t\tcontinue\n\t\t\t} else {\n\t\t\t\t_, _ = w.Write([]byte(fmt.Sprintf(\"<li><a href=\\\"%s\\\">%s</a></li>\\n\", dir, dir)))\n\t\t\t\tdirs[dir] = true\n\t\t\t}\n\t\t}\n\t\t_, _ = w.Write([]byte(\"</ul></body></html>\"))\n\n\t} else { // stream the file itself\n\t\tlog.Debugf(\"not a directory, artifact: %+v\", artifact)\n\t\terr = a.returnArtifact(w, artifact, driver)\n\n\t\tif err != nil {\n\t\t\ta.serverInternalError(err, w)\n\t\t\treturn\n\t\t}\n\t}\n\n}\n\nfunc (a *ArtifactServer) getArtifact(w http.ResponseWriter, r *http.Request, isInput bool) {\n\trequestPath := strings.SplitN(r.URL.Path, \"/\", 6)\n\tif len(requestPath) != 6 {\n\t\ta.httpBadRequestError(w)\n\t\treturn\n\t}\n\tnamespace := requestPath[2]\n\tworkflowName := requestPath[3]\n\tnodeId := requestPath[4]\n\tartifactName := requestPath[5]\n\n\tctx, err := a.gateKeeping(r, types.NamespaceHolder(namespace))\n\tif err != nil {\n\t\ta.unauthorizedError(w)\n\t\treturn\n\t}\n\n\tlog.WithFields(log.Fields{\"namespace\": namespace, \"workflowName\": workflowName, \"nodeId\": nodeId, \"artifactName\": artifactName, \"isInput\": isInput}).Info(\"Download artifact\")\n\n\twf, err := a.getWorkflowAndValidate(ctx, namespace, workflowName)\n\tif err != nil {\n\t\ta.httpFromError(err, w)\n\t\treturn\n\t}\n\tart, driver, err := a.getArtifactAndDriver(ctx, nodeId, artifactName, isInput, wf, nil)\n\tif err != nil {\n\t\ta.serverInternalError(err, w)\n\t\treturn\n\t}\n\n\terr = a.returnArtifact(w, art, driver)\n\n\tif err != nil {\n\t\ta.httpFromError(err, w)\n\t\treturn\n\t}\n}\n\nfunc (a *ArtifactServer) GetOutputArtifactByUID(w http.ResponseWriter, r *http.Request) {\n\ta.getArtifactByUID(w, r, false)\n}\n\nfunc (a *ArtifactServer) GetInputArtifactByUID(w http.ResponseWriter, r *http.Request) {\n\ta.getArtifactByUID(w, r, true)\n}\n\nfunc (a *ArtifactServer) getArtifactByUID(w http.ResponseWriter, r *http.Request, isInput bool) {\n\trequestPath := strings.SplitN(r.URL.Path, \"/\", 5)\n\tif len(requestPath) != 5 {\n\t\ta.httpBadRequestError(w)\n\t\treturn\n\t}\n\tuid := requestPath[2]\n\tnodeId := requestPath[3]\n\tartifactName := requestPath[4]\n\n\t// We need to know the namespace before we can do gate keeping\n\twf, err := a.wfArchive.GetWorkflow(uid)\n\tif err != nil {\n\t\ta.httpFromError(err, w)\n\t\treturn\n\t}\n\n\tctx, err := a.gateKeeping(r, types.NamespaceHolder(wf.GetNamespace()))\n\tif err != nil {\n\t\ta.unauthorizedError(w)\n\t\treturn\n\t}\n\n\t// return 401 if the client does not have permission to get wf\n\terr = a.validateAccess(ctx, wf)\n\tif err != nil {\n\t\ta.unauthorizedError(w)\n\t\treturn\n\t}\n\tart, driver, err := a.getArtifactAndDriver(ctx, nodeId, artifactName, isInput, wf, nil)\n\tif err != nil {\n\t\ta.serverInternalError(err, w)\n\t\treturn\n\t}\n\n\tlog.WithFields(log.Fields{\"uid\": uid, \"nodeId\": nodeId, \"artifactName\": artifactName, \"isInput\": isInput}).Info(\"Download artifact\")\n\terr = a.returnArtifact(w, art, driver)\n\n\tif err != nil {\n\t\ta.httpFromError(err, w)\n\t\treturn\n\t}\n}\n\nfunc (a *ArtifactServer) gateKeeping(r *http.Request, ns types.NamespacedRequest) (context.Context, error) {\n\ttoken := r.Header.Get(\"Authorization\")\n\tif token == \"\" {\n\t\tcookie, err := r.Cookie(\"authorization\")\n\t\tif err != nil {\n\t\t\tif err != http.ErrNoCookie {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t} else {\n\t\t\ttoken = cookie.Value\n\t\t}\n\t}\n\tctx := metadata.NewIncomingContext(r.Context(), metadata.MD{\"authorization\": []string{token}})\n\treturn a.gatekeeper.ContextWithRequest(ctx, ns)\n}\n\nfunc (a *ArtifactServer) unauthorizedError(w http.ResponseWriter) {\n\thttp.Error(w, http.StatusText(http.StatusUnauthorized), http.StatusUnauthorized)\n}\n\nfunc (a *ArtifactServer) serverInternalError(err error, w http.ResponseWriter) {\n\thttp.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError)\n\tlog.WithError(err).Error(\"Artifact Server returned internal error\")\n}\n\nfunc (a *ArtifactServer) httpBadRequestError(w http.ResponseWriter) {\n\thttp.Error(w, http.StatusText(http.StatusBadRequest), http.StatusBadRequest)\n}\n\nfunc (a *ArtifactServer) httpFromError(err error, w http.ResponseWriter) {\n\te := &apierr.StatusError{}\n\tif errors.As(err, &e) {\n\t\t// There is a http error code somewhere in the error stack\n\t\tstatusCode := int(e.Status().Code)\n\t\thttp.Error(w, http.StatusText(statusCode), statusCode)\n\t} else {\n\t\t// Unknown error - return internal error\n\t\ta.serverInternalError(err, w)\n\t}\n}\n\nfunc (a *ArtifactServer) getArtifactAndDriver(ctx context.Context, nodeId, artifactName string, isInput bool, wf *wfv1.Workflow, fileName *string) (*wfv1.Artifact, common.ArtifactDriver, error) {\n\n\tkubeClient := auth.GetKubeClient(ctx)\n\n\tvar art *wfv1.Artifact\n\tif isInput {\n\t\tart = wf.Status.Nodes[nodeId].Inputs.GetArtifactByName(artifactName)\n\t} else {\n\t\tart = wf.Status.Nodes[nodeId].Outputs.GetArtifactByName(artifactName)\n\t}\n\tif art == nil {\n\t\treturn nil, nil, fmt.Errorf(\"artifact not found: %s\", artifactName)\n\t}\n\n\tar, err := a.artifactRepositories.Get(ctx, wf.Status.ArtifactRepositoryRef)\n\tif err != nil {\n\t\treturn art, nil, err\n\t}\n\tl := ar.ToArtifactLocation()\n\terr = art.Relocate(l)\n\tif err != nil {\n\t\treturn art, nil, err\n\t}\n\tif fileName != nil {\n\t\terr = art.AppendToKey(*fileName)\n\t\tif err != nil {\n\t\t\treturn art, nil, fmt.Errorf(\"error appending filename %s to key of artifact %+v: err: %v\", *fileName, art, err)\n\t\t}\n\t\tlog.Debugf(\"appended key %s to artifact %+v\", *fileName, art)\n\t}\n\n\tdriver, err := a.artDriverFactory(ctx, art, resources{kubeClient, wf.Namespace})\n\tif err != nil {\n\t\treturn art, nil, err\n\t}\n\tlog.Debugf(\"successfully located driver associated with artifact %+v\", art)\n\n\treturn art, driver, nil\n}\n\nfunc (a *ArtifactServer) returnArtifact(w http.ResponseWriter, art *wfv1.Artifact, driver common.ArtifactDriver) error {\n\tstream, err := driver.OpenStream(art)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer func() {\n\t\tif err := stream.Close(); err != nil {\n\t\t\tlog.Warningf(\"Error closing stream[%s]: %v\", stream, err)\n\t\t}\n\t}()\n\n\tkey, _ := art.GetKey()\n\tw.Header().Add(\"Content-Disposition\", fmt.Sprintf(`filename=\"%s\"`, path.Base(key)))\n\tw.Header().Add(\"Content-Type\", mime.TypeByExtension(path.Ext(key)))\n\tw.Header().Add(\"Content-Security-Policy\", env.GetString(\"ARGO_ARTIFACT_CONTENT_SECURITY_POLICY\", \"sandbox; base-uri 'none'; default-src 'none'; img-src 'self'; style-src 'self'\"))\n\tw.Header().Add(\"X-Frame-Options\", env.GetString(\"ARGO_ARTIFACT_X_FRAME_OPTIONS\", \"SAMEORIGIN\"))\n\n\t_, err = io.Copy(w, stream)\n\tif err != nil {\n\t\thttp.Error(w, fmt.Sprintf(\"failed to stream artifact: %v\", err), http.StatusInternalServerError)\n\t} else {\n\t\tw.WriteHeader(http.StatusOK)\n\t}\n\n\treturn nil\n}\n\nfunc (a *ArtifactServer) getWorkflowAndValidate(ctx context.Context, namespace string, workflowName string) (*wfv1.Workflow, error) {\n\twfClient := auth.GetWfClient(ctx)\n\twf, err := wfClient.ArgoprojV1alpha1().Workflows(namespace).Get(ctx, workflowName, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = a.instanceIDService.Validate(wf)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = a.hydrator.Hydrate(wf)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn wf, nil\n}\n\nfunc (a *ArtifactServer) validateAccess(ctx context.Context, wf *wfv1.Workflow) error {\n\tallowed, err := auth.CanI(ctx, \"get\", \"workflows\", wf.Namespace, wf.Name)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !allowed {\n\t\treturn status.Error(codes.PermissionDenied, \"permission denied\")\n\t}\n\treturn nil\n}\n", "//go:build api\n// +build api\n\npackage e2e\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"os\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/gavv/httpexpect/v2\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/suite\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\trbacv1 \"k8s.io/api/rbac/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/types\"\n\n\t\"github.com/argoproj/argo-workflows/v3/pkg/apis/workflow\"\n\twfv1 \"github.com/argoproj/argo-workflows/v3/pkg/apis/workflow/v1alpha1\"\n\t\"github.com/argoproj/argo-workflows/v3/test/e2e/fixtures\"\n\t\"github.com/argoproj/argo-workflows/v3/workflow/common\"\n)\n\nconst baseUrl = \"http://localhost:2746\"\n\n// ensure basic HTTP functionality works,\n// testing behaviour really is a non-goal\ntype ArgoServerSuite struct {\n\tfixtures.E2ESuite\n\tusername    string\n\tbearerToken string\n}\n\nfunc (s *ArgoServerSuite) BeforeTest(suiteName, testName string) {\n\ts.E2ESuite.BeforeTest(suiteName, testName)\n\tvar err error\n\ts.bearerToken, err = s.GetServiceAccountToken()\n\ts.CheckError(err)\n}\n\nfunc (s *ArgoServerSuite) e() *httpexpect.Expect {\n\treturn httpexpect.\n\t\tWithConfig(httpexpect.Config{\n\t\t\tBaseURL:  baseUrl,\n\t\t\tReporter: httpexpect.NewRequireReporter(s.T()),\n\t\t\tPrinters: []httpexpect.Printer{\n\t\t\t\thttpexpect.NewDebugPrinter(s.T(), true),\n\t\t\t},\n\t\t\tClient: httpClient,\n\t\t}).\n\t\tBuilder(func(req *httpexpect.Request) {\n\t\t\tif s.username != \"\" {\n\t\t\t\treq.WithBasicAuth(s.username, \"garbage\")\n\t\t\t} else if s.bearerToken != \"\" {\n\t\t\t\treq.WithHeader(\"Authorization\", \"Bearer \"+s.bearerToken)\n\t\t\t}\n\t\t})\n}\n\nfunc (s *ArgoServerSuite) TestInfo() {\n\ts.Run(\"Get\", func() {\n\t\tjson := s.e().GET(\"/api/v1/info\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tjson.\n\t\t\tPath(\"$.managedNamespace\").\n\t\t\tEqual(\"argo\")\n\t\tjson.\n\t\t\tPath(\"$.links[0].name\").\n\t\t\tEqual(\"Workflow Link\")\n\t\tjson.\n\t\t\tPath(\"$.links[0].scope\").\n\t\t\tEqual(\"workflow\")\n\t\tjson.\n\t\t\tPath(\"$.links[0].url\").\n\t\t\tEqual(\"http://logging-facility?namespace=${metadata.namespace}&workflowName=${metadata.name}&startedAt=${status.startedAt}&finishedAt=${status.finishedAt}\")\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestVersion() {\n\ts.Run(\"Version\", func() {\n\t\ts.e().GET(\"/api/v1/version\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.version\").\n\t\t\tNotNull()\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestMetricsForbidden() {\n\ts.bearerToken = \"\"\n\ts.e().\n\t\tGET(\"/metrics\").\n\t\tExpect().\n\t\tStatus(403)\n}\n\nfunc (s *ArgoServerSuite) TestMetricsOK() {\n\tbody := s.e().\n\t\tGET(\"/metrics\").\n\t\tExpect().\n\t\tStatus(200).\n\t\tBody()\n\tbody.\n\t\t// https://blog.netsil.com/the-4-golden-signals-of-api-health-and-performance-in-cloud-native-applications-a6e87526e74\n\t\t// Latency: The time it takes to service a request, with a focus on distinguishing between the latency of successful requests and the latency of failed requests\n\t\tContains(`grpc_server_handling_seconds_bucket`).\n\t\t// Traffic: A measure of how much demand is being placed on the service. This is measured using a high-level service-specific metric, like HTTP requests per second in the case of an HTTP REST API.\n\t\tContains(`promhttp_metric_handler_requests_in_flight`).\n\t\t// Errors: The rate of requests that fail. The failures can be explicit (e.g., HTTP 500 errors) or implicit (e.g., an HTTP 200 OK response with a response body having too few items).\n\t\tContains(`promhttp_metric_handler_requests_total{code=\"500\"}`)\n\n\tif os.Getenv(\"CI\") == \"true\" {\n\t\tbody.\n\t\t\t// Saturation: How \u201cfull\u201d is the service. This is a measure of the system utilization, emphasizing the resources that are most constrained (e.g., memory, I/O or CPU). Services degrade in performance as they approach high saturation.\n\t\t\tContains(`process_cpu_seconds_total`).\n\t\t\tContains(`process_resident_memory_bytes`)\n\t}\n}\n\nfunc (s *ArgoServerSuite) TestSubmitWorkflowTemplateFromGithubWebhook() {\n\ts.bearerToken = \"\"\n\n\tdata, err := ioutil.ReadFile(\"testdata/github-webhook-payload.json\")\n\tassert.NoError(s.T(), err)\n\n\ts.Given().\n\t\tWorkflowTemplate(`\nmetadata:\n  name: github-webhook\nspec:\n  entrypoint: main\n  workflowMetadata:\n    labels:\n      workflows.argoproj.io/test: \"true\"\n  templates:\n    - name: main\n      container:\n         image: argoproj/argosay:v2\n`).\n\t\tWorkflowEventBinding(`\nmetadata:\n  name: github-webhook\nspec:\n  event:\n    selector: metadata[\"x-github-event\"] == [\"push\"]\n  submit:\n    workflowTemplateRef:\n      name: github-webhook\n`).\n\t\tWhen().\n\t\tCreateWorkflowTemplates().\n\t\tCreateWorkflowEventBinding().\n\t\tAnd(func() {\n\t\t\ts.e().\n\t\t\t\tPOST(\"/api/v1/events/argo/\").\n\t\t\t\tWithHeader(\"X-Github-Event\", \"push\").\n\t\t\t\tWithHeader(\"X-Hub-Signature\", \"sha1=c09e61386e81c2669e015049350500448148205c\").\n\t\t\t\tWithBytes(data).\n\t\t\t\tExpect().\n\t\t\t\tStatus(200)\n\t\t}).\n\t\tWaitForWorkflow().\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, _ *wfv1.WorkflowStatus) {\n\t\t\tassert.Equal(t, \"github-webhook\", metadata.GetLabels()[common.LabelKeyWorkflowTemplate])\n\t\t})\n}\n\nfunc (s *ArgoServerSuite) TestSubmitWorkflowTemplateFromEvent() {\n\ts.Given().\n\t\tWorkflowTemplate(`\nmetadata:\n  name: event-consumer\nspec:\n  entrypoint: main\n  workflowMetadata:\n    labels:\n      workflows.argoproj.io/test: \"true\"\n  arguments:\n    parameters:\n      - name: salutation\n        value: \"hello\"\n  templates:\n    - name: main\n      steps:\n      - - name: a\n          template: argosay\n          arguments:\n            parameters:\n            - name: salutation\n              value: \"{{workflow.parameters.salutation}}\"\n            - name: appellation\n              value: \"{{workflow.parameters.appellation}}\"\n\n    - name: argosay\n      inputs:\n        parameters:\n          - name: salutation\n          - name: appellation\n      container:\n         image: argoproj/argosay:v2\n         args: [echo, \"{{inputs.parameters.salutation}} {{inputs.parameters.appellation}}\"]\n`).\n\t\tWorkflowEventBinding(`\nmetadata:\n  name: event-consumer\nspec:\n  event:\n    selector: payload.appellation != \"\" && metadata[\"x-argo-e2e\"] == [\"true\"]\n  submit:\n    workflowTemplateRef:\n      name: event-consumer\n    arguments:\n      parameters:\n        - name: appellation\n          valueFrom:\n            event: payload.appellation\n`).\n\t\tWhen().\n\t\tCreateWorkflowEventBinding().\n\t\tCreateWorkflowTemplates().\n\t\tAnd(func() {\n\t\t\ts.e().\n\t\t\t\tPOST(\"/api/v1/events/argo/\").\n\t\t\t\tWithHeader(\"X-Argo-E2E\", \"true\").\n\t\t\t\tWithBytes([]byte(`{\"appellation\": \"Mr Chips\"}`)).\n\t\t\t\tExpect().\n\t\t\t\tStatus(200)\n\t\t}).\n\t\tWaitForWorkflow().\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, _ *wfv1.WorkflowStatus) {\n\t\t\tassert.Equal(t, \"event-consumer\", metadata.GetLabels()[common.LabelKeyWorkflowTemplate])\n\t\t})\n}\n\nfunc (s *ArgoServerSuite) TestSubmitClusterWorkflowTemplateFromEvent() {\n\ts.Given().\n\t\tClusterWorkflowTemplate(`\nmetadata:\n  name: event-consumer\nspec:\n  entrypoint: main\n  workflowMetadata:\n    labels:\n      workflows.argoproj.io/test: \"true\"\n  templates:\n    - name: main\n      container:\n         image: argoproj/argosay:v2\n`).\n\t\tWorkflowEventBinding(`\nmetadata:\n  name: event-consumer\nspec:\n  event:\n    selector: true\n  submit:\n    workflowTemplateRef:\n      name: event-consumer\n      clusterScope: true\n`).\n\t\tWhen().\n\t\tCreateWorkflowEventBinding().\n\t\tCreateClusterWorkflowTemplates().\n\t\tAnd(func() {\n\t\t\ts.e().\n\t\t\t\tPOST(\"/api/v1/events/argo/\").\n\t\t\t\tWithBytes([]byte(`{}`)).\n\t\t\t\tExpect().\n\t\t\t\tStatus(200)\n\t\t}).\n\t\tWaitForWorkflow().\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, _ *wfv1.WorkflowStatus) {\n\t\t\tassert.Equal(t, \"event-consumer\", metadata.GetLabels()[common.LabelKeyClusterWorkflowTemplate])\n\t\t})\n}\n\nfunc (s *ArgoServerSuite) TestEventOnMalformedWorkflowEventBinding() {\n\ts.Given().\n\t\tWorkflowEventBinding(`\nmetadata:\n  name: malformed\n`).\n\t\tWhen().\n\t\tCreateWorkflowEventBinding().\n\t\tAnd(func() {\n\t\t\ts.e().\n\t\t\t\tPOST(\"/api/v1/events/argo/\").\n\t\t\t\tWithBytes([]byte(`{}`)).\n\t\t\t\tExpect().\n\t\t\t\tStatus(500)\n\t\t}).\n\t\tThen().\n\t\tExpectAuditEvents(\n\t\t\tfunc(event corev1.Event) bool {\n\t\t\t\treturn event.InvolvedObject.Name == \"malformed\" && event.InvolvedObject.Kind == workflow.WorkflowEventBindingKind\n\t\t\t}, 1,\n\t\t\tfunc(t *testing.T, e []corev1.Event) {\n\t\t\t\tassert.Equal(t, \"argo\", e[0].InvolvedObject.Namespace)\n\t\t\t\tassert.Equal(t, \"WorkflowEventBindingError\", e[0].Reason)\n\t\t\t\tassert.Equal(t, \"failed to dispatch event: failed to evaluate workflow template expression: unable to evaluate expression '': unexpected token EOF (1:1)\", e[0].Message)\n\t\t\t},\n\t\t)\n}\n\nfunc (s *ArgoServerSuite) TestGetUserInfo() {\n\ts.e().GET(\"/api/v1/userinfo\").\n\t\tExpect().\n\t\tStatus(200)\n}\n\n// we can only really tests these endpoint respond, not worthwhile checking more\nfunc (s *ArgoServerSuite) TestOauth() {\n\ts.Run(\"Redirect\", func() {\n\t\ts.e().GET(\"/oauth2/redirect\").\n\t\t\tExpect().\n\t\t\tStatus(501)\n\t})\n\ts.Run(\"Callback\", func() {\n\t\ts.e().GET(\"/oauth2/callback\").\n\t\t\tExpect().\n\t\t\tStatus(501)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestUnauthorized() {\n\ttoken := s.bearerToken\n\ts.T().Run(\"Bearer\", func(t *testing.T) {\n\t\ts.bearerToken = \"test-token\"\n\t\tdefer func() { s.bearerToken = token }()\n\t\ts.e().GET(\"/api/v1/workflows/argo\").\n\t\t\tExpect().\n\t\t\tStatus(401)\n\t})\n\ts.T().Run(\"Basic\", func(t *testing.T) {\n\t\ts.username = \"garbage\"\n\t\tdefer func() { s.username = \"\" }()\n\t\ts.e().GET(\"/api/v1/workflows/argo\").\n\t\t\tExpect().\n\t\t\tStatus(401)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestCookieAuth() {\n\ttoken := s.bearerToken\n\tdefer func() { s.bearerToken = token }()\n\ts.bearerToken = \"\"\n\ts.e().GET(\"/api/v1/workflows/argo\").\n\t\tWithHeader(\"Cookie\", \"authorization=Bearer \"+token).\n\t\tExpect().\n\t\tStatus(200)\n}\n\n// You could have multiple authorization headers, set by wildcard domain cookies in the case of some SSO implementations\nfunc (s *ArgoServerSuite) TestMultiCookieAuth() {\n\ttoken := s.bearerToken\n\tdefer func() { s.bearerToken = token }()\n\ts.bearerToken = \"\"\n\ts.e().GET(\"/api/v1/workflows/argo\").\n\t\tWithCookie(\"authorization\", \"invalid1\").\n\t\tWithCookie(\"authorization\", \"Bearer \"+token).\n\t\tWithCookie(\"authorization\", \"invalid2\").\n\t\tExpect().\n\t\tStatus(200)\n}\n\nfunc (s *ArgoServerSuite) TestPermission() {\n\tnsName := fixtures.Namespace\n\t// Create good serviceaccount\n\tgoodSaName := \"argotestgood\"\n\tgoodSa := &corev1.ServiceAccount{ObjectMeta: metav1.ObjectMeta{Name: goodSaName}}\n\tctx := context.Background()\n\ts.Run(\"CreateGoodSA\", func() {\n\t\t_, err := s.KubeClient.CoreV1().ServiceAccounts(nsName).Create(ctx, goodSa, metav1.CreateOptions{})\n\t\tassert.NoError(s.T(), err)\n\t})\n\tdefer func() {\n\t\t// Clean up created sa\n\t\t_ = s.KubeClient.CoreV1().ServiceAccounts(nsName).Delete(ctx, goodSaName, metav1.DeleteOptions{})\n\t}()\n\n\t// Create bad serviceaccount\n\tbadSaName := \"argotestbad\"\n\tbadSa := &corev1.ServiceAccount{ObjectMeta: metav1.ObjectMeta{Name: badSaName}}\n\ts.Run(\"CreateBadSA\", func() {\n\t\t_, err := s.KubeClient.CoreV1().ServiceAccounts(nsName).Create(ctx, badSa, metav1.CreateOptions{})\n\t\tassert.NoError(s.T(), err)\n\t})\n\tdefer func() {\n\t\t_ = s.KubeClient.CoreV1().ServiceAccounts(nsName).Delete(ctx, badSaName, metav1.DeleteOptions{})\n\t}()\n\n\t// Create RBAC Role\n\tvar roleName string\n\ts.Run(\"LoadRoleYaml\", func() {\n\t\tobj, err := fixtures.LoadObject(\"@testdata/argo-server-test-role.yaml\")\n\t\tassert.NoError(s.T(), err)\n\t\trole, _ := obj.(*rbacv1.Role)\n\t\troleName = role.Name\n\t\t_, err = s.KubeClient.RbacV1().Roles(nsName).Create(ctx, role, metav1.CreateOptions{})\n\t\tassert.NoError(s.T(), err)\n\t})\n\tdefer func() {\n\t\t_ = s.KubeClient.RbacV1().Roles(nsName).Delete(ctx, roleName, metav1.DeleteOptions{})\n\t}()\n\n\t// Create RBAC RoleBinding\n\troleBindingName := \"argotest-role-binding\"\n\troleBinding := &rbacv1.RoleBinding{\n\t\tObjectMeta: metav1.ObjectMeta{Name: roleBindingName},\n\t\tSubjects:   []rbacv1.Subject{{Kind: \"ServiceAccount\", Name: goodSaName}},\n\t\tRoleRef: rbacv1.RoleRef{\n\t\t\tAPIGroup: \"rbac.authorization.k8s.io\",\n\t\t\tKind:     \"Role\",\n\t\t\tName:     roleName,\n\t\t},\n\t}\n\ts.Run(\"CreateRoleBinding\", func() {\n\t\t_, err := s.KubeClient.RbacV1().RoleBindings(nsName).Create(ctx, roleBinding, metav1.CreateOptions{})\n\t\tassert.NoError(s.T(), err)\n\t})\n\tdefer func() {\n\t\t_ = s.KubeClient.RbacV1().RoleBindings(nsName).Delete(ctx, roleBindingName, metav1.DeleteOptions{})\n\t}()\n\n\t// Sleep 2 seconds to wait for serviceaccount token created.\n\t// The secret creation slowness is seen in k3d.\n\ttime.Sleep(2 * time.Second)\n\n\t// Get token of good serviceaccount\n\tvar goodToken string\n\ts.Run(\"GetGoodSAToken\", func() {\n\t\tsAccount, err := s.KubeClient.CoreV1().ServiceAccounts(nsName).Get(ctx, goodSaName, metav1.GetOptions{})\n\t\tif assert.NoError(s.T(), err) {\n\t\t\tsecretName := sAccount.Secrets[0].Name\n\t\t\tsecret, err := s.KubeClient.CoreV1().Secrets(nsName).Get(ctx, secretName, metav1.GetOptions{})\n\t\t\tassert.NoError(s.T(), err)\n\t\t\tgoodToken = string(secret.Data[\"token\"])\n\t\t}\n\t})\n\n\t// Get token of bad serviceaccount\n\tvar badToken string\n\ts.Run(\"GetBadSAToken\", func() {\n\t\tsAccount, err := s.KubeClient.CoreV1().ServiceAccounts(nsName).Get(ctx, badSaName, metav1.GetOptions{})\n\t\tassert.NoError(s.T(), err)\n\t\tsecretName := sAccount.Secrets[0].Name\n\t\tsecret, err := s.KubeClient.CoreV1().Secrets(nsName).Get(ctx, secretName, metav1.GetOptions{})\n\t\tassert.NoError(s.T(), err)\n\t\tbadToken = string(secret.Data[\"token\"])\n\t})\n\n\ttoken := s.bearerToken\n\tdefer func() { s.bearerToken = token }()\n\n\t// Test creating workflow with good token\n\tvar uid string\n\ts.bearerToken = goodToken\n\ts.Run(\"CreateWFGoodToken\", func() {\n\t\tuid = s.e().POST(\"/api/v1/workflows/\" + nsName).\n\t\t\tWithBytes([]byte(`{\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"test-wf-good\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"main\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\"\n          }\n        }\n      ],\n      \"entrypoint\": \"main\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.uid\").\n\t\t\tRaw().(string)\n\t})\n\n\t// Test list workflows with good token\n\ts.Run(\"ListWFsGoodToken\", func() {\n\t\ts.e().GET(\"/api/v1/workflows/\"+nsName).\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\n\ts.Given().\n\t\tWhen().\n\t\tWaitForWorkflow(fixtures.ToBeArchived)\n\n\t// Test creating workflow with bad token\n\ts.bearerToken = badToken\n\ts.Run(\"CreateWFBadToken\", func() {\n\t\ts.e().POST(\"/api/v1/workflows/\" + nsName).\n\t\t\tWithBytes([]byte(`{\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"test-wf-bad\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"main\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\"\n          }\n        }\n      ],\n      \"entrypoint\": \"main\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\n\t// Test list workflows with bad token\n\ts.Run(\"ListWFsBadToken\", func() {\n\t\ts.e().GET(\"/api/v1/workflows/\" + nsName).\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\t// Test delete workflow with bad token\n\ts.Run(\"DeleteWFWithBadToken\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflows/\" + nsName + \"/test-wf-good\").\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\n\t// Test delete workflow with good token\n\ts.bearerToken = goodToken\n\ts.Run(\"DeleteWFWithGoodToken\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflows/\" + nsName + \"/test-wf-good\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\t// we've now deleted the workflow, but it is still in the archive, testing the archive\n\t// after deleting the workflow makes sure that we are no dependant of the workflow for authorization\n\n\t// Test list archived WFs with good token\n\ts.Run(\"ListArchivedWFsGoodToken\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tWithQuery(\"listOptions.fieldSelector\", \"metadata.namespace=\"+nsName).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().Length().Gt(0)\n\t})\n\n\ts.bearerToken = badToken\n\ts.Run(\"ListArchivedWFsBadToken\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tWithQuery(\"listOptions.fieldSelector\", \"metadata.namespace=\"+nsName).\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\n\t// Test get archived wf with good token\n\ts.bearerToken = goodToken\n\ts.Run(\"GetArchivedWFsGoodToken\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows/\"+uid).\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\t// Test get archived wf with bad token\n\ts.bearerToken = badToken\n\ts.Run(\"GetArchivedWFsBadToken\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows/\" + uid).\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\n\t// Test deleting archived wf with bad token\n\ts.Run(\"DeleteArchivedWFsBadToken\", func() {\n\t\ts.e().DELETE(\"/api/v1/archived-workflows/\" + uid).\n\t\t\tExpect().\n\t\t\tStatus(403)\n\t})\n\n\t// Test deleting archived wf with good token\n\ts.bearerToken = goodToken\n\ts.Run(\"DeleteArchivedWFsGoodToken\", func() {\n\t\ts.e().DELETE(\"/api/v1/archived-workflows/\" + uid).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestLintWorkflow() {\n\ts.e().POST(\"/api/v1/workflows/argo/lint\").\n\t\tWithBytes([]byte((`{\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`))).\n\t\tExpect().\n\t\tStatus(200)\n}\n\nfunc (s *ArgoServerSuite) TestHintWhenWorkflowExists() {\n\ts.e().POST(\"/api/v1/workflows/argo\").\n\t\tWithBytes([]byte((`{\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"hint\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"entrypoint\": \"whalesay\",\n      \"templates\": [\n        {\n          \"name\": \"whalesay\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\"\n          }\n        }\n      ]\n    }\n  }\n}`))).\n\t\tExpect().\n\t\tStatus(200)\n\n\ts.e().POST(\"/api/v1/workflows/argo\").\n\t\tWithBytes([]byte((`{\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"hint\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"entrypoint\": \"whalesay\",\n      \"templates\": [\n        {\n          \"name\": \"whalesay\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\"\n          }\n        }\n      ]\n    }\n  }\n}`))).\n\t\tExpect().\n\t\tStatus(409).\n\t\tBody().\n\t\tContains(\"already exists\")\n}\n\nfunc (s *ArgoServerSuite) TestCreateWorkflowDryRun() {\n\ts.e().POST(\"/api/v1/workflows/argo\").\n\t\tWithBytes([]byte(`{\n  \"createOptions\": {\n    \"dryRun\": [\"All\"]\n  },\n  \"workflow\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).\n\t\tExpect().\n\t\tStatus(200).\n\t\tJSON().\n\t\tPath(\"$.metadata\").\n\t\tObject().\n\t\tNotContainsKey(\"uid\")\n}\n\nfunc (s *ArgoServerSuite) TestWorkflowService() {\n\tvar name string\n\ts.Run(\"Create\", func() {\n\t\tname = s.e().POST(\"/api/v1/workflows/argo\").\n\t\t\tWithBytes([]byte(`{\n  \"workflow\": {\n    \"metadata\": {\n      \"generateName\": \"test-\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"subject-1\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"image\": \"argoproj/argosay:v2\",\n            \"args\": [\"sleep\", \"10s\"]   \n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tNotNull().\n\t\t\tString().\n\t\t\tRaw()\n\t})\n\n\ts.Given().\n\t\tWhen().\n\t\tWaitForWorkflow(fixtures.ToBeRunning)\n\n\ts.Run(\"List\", func() {\n\t\tj := s.e().GET(\"/api/v1/workflows/argo\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test=subject-1\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t\tj.Path(\"$.items[0].status.nodes\").\n\t\t\tNotNull()\n\t})\n\n\ts.Run(\"ListWithFields\", func() {\n\t\tj := s.e().GET(\"/api/v1/workflows/argo\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test=subject-1\").\n\t\t\tWithQuery(\"fields\", \"-items.status.nodes,items.status.finishedAt,items.status.startedAt\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.Path(\"$.metadata\").\n\t\t\tNotNull()\n\t\tj.\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t\tj.Path(\"$.items[0].status\").Object().ContainsKey(\"phase\").NotContainsKey(\"nodes\")\n\t})\n\n\ts.Run(\"Get\", func() {\n\t\tj := s.e().GET(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.Path(\"$.status.nodes\").\n\t\t\tNotNull()\n\t\ts.e().GET(\"/api/v1/workflows/argo/not-found\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t})\n\n\ts.Run(\"GetWithFields\", func() {\n\t\tj := s.e().GET(\"/api/v1/workflows/argo/\"+name).\n\t\t\tWithQuery(\"fields\", \"status.phase\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.Path(\"$.status\").Object().ContainsKey(\"phase\").NotContainsKey(\"nodes\")\n\t})\n\n\ts.Run(\"Suspend\", func() {\n\t\ts.e().PUT(\"/api/v1/workflows/argo/\" + name + \"/suspend\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\ts.e().GET(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec.suspend\").\n\t\t\tEqual(true)\n\t})\n\n\ts.Run(\"Resume\", func() {\n\t\ts.e().PUT(\"/api/v1/workflows/argo/\" + name + \"/resume\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\ts.e().GET(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec\").\n\t\t\tObject().\n\t\t\tNotContainsKey(\"suspend\")\n\t})\n\n\ts.Run(\"Terminate\", func() {\n\t\ts.e().PUT(\"/api/v1/workflows/argo/\" + name + \"/terminate\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\ts.Given().\n\t\t\tWorkflowName(name).\n\t\t\tWhen().\n\t\t\tWaitForWorkflow()\n\n\t\ts.e().GET(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.status.message\").\n\t\t\tEqual(\"Stopped with strategy 'Terminate'\")\n\t})\n\n\ts.Run(\"Resubmit\", func() {\n\t\ts.e().PUT(\"/api/v1/workflows/argo/\" + name + \"/resubmit\").\n\t\t\tWithBytes([]byte(`{\"memoized\": true}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tNotNull()\n\t})\n\n\ts.Run(\"Delete\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t\ts.e().DELETE(\"/api/v1/workflows/argo/not-found\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestCronWorkflowService() {\n\ts.Run(\"Create\", func() {\n\t\ts.e().POST(\"/api/v1/cron-workflows/argo\").\n\t\t\tWithBytes([]byte(`{\n  \"cronWorkflow\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"subject-2\"\n      }\n    },\n    \"spec\": {\n      \"schedule\": \"* * * * *\",\n      \"workflowSpec\": {\n        \"entrypoint\": \"whalesay\",\n        \"templates\": [\n          {\n            \"name\": \"whalesay\",\n            \"container\": {\n              \"image\": \"argoproj/argosay:v2\",\n              \"imagePullPolicy\": \"IfNotPresent\"\n            }\n          }\n        ]\n      }\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"Suspend\", func() {\n\t\ts.e().PUT(\"/api/v1/cron-workflows/argo/test/suspend\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec.suspend\").\n\t\t\tEqual(true)\n\t})\n\n\ts.Run(\"Resume\", func() {\n\t\ts.e().PUT(\"/api/v1/cron-workflows/argo/test/resume\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec\").\n\t\t\tObject().\n\t\t\tNotContainsKey(\"suspend\")\n\t})\n\n\ts.Run(\"List\", func() {\n\t\t// make sure list options work correctly\n\t\ts.Given().\n\t\t\tCronWorkflow(`apiVersion: argoproj.io/v1alpha1\nkind: CronWorkflow\nmetadata:\n  name: test-cron-wf-basic\nspec:\n  schedule: \"* * * * *\"\n  concurrencyPolicy: \"Allow\"\n  startingDeadlineSeconds: 0\n  successfulJobsHistoryLimit: 4\n  failedJobsHistoryLimit: 2\n  workflowSpec:\n    podGC:\n      strategy: OnPodCompletion\n    entrypoint: whalesay\n    templates:\n      - name: whalesay\n        container:\n          image: argoproj/argosay:v2\n          imagePullPolicy: IfNotPresent\n          command: [\"sh\", -c]\n          args: [\"echo hello\"]\n`)\n\n\t\ts.e().GET(\"/api/v1/cron-workflows/argo\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test=subject-2\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\n\tvar resourceVersion string\n\ts.Run(\"Get\", func() {\n\t\ts.e().GET(\"/api/v1/cron-workflows/argo/not-found\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t\tresourceVersion = s.e().GET(\"/api/v1/cron-workflows/argo/test\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.resourceVersion\").\n\t\t\tString().\n\t\t\tRaw()\n\t})\n\n\ts.Run(\"Update\", func() {\n\t\ts.e().PUT(\"/api/v1/cron-workflows/argo/test\").\n\t\t\tWithBytes([]byte(`{\"cronWorkflow\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"resourceVersion\": \"` + resourceVersion + `\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"schedule\": \"1 * * * *\",\n      \"workflowMetadata\": {\n        \"labels\": {\"workflows.argoproj.io/test\": \"true\"}\n      },\n      \"workflowSpec\": {\n        \"entrypoint\": \"whalesay\",\n        \"templates\": [\n          {\n            \"name\": \"whalesay\",\n            \"container\": {\n              \"image\": \"argoproj/argosay:v2\",\n              \"imagePullPolicy\": \"IfNotPresent\"\n            }\n          }\n        ]\n      }\n    }\n  }}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec.schedule\").\n\t\t\tEqual(\"1 * * * *\")\n\t})\n\n\ts.Run(\"Delete\", func() {\n\t\ts.e().DELETE(\"/api/v1/cron-workflows/argo/test\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\n// make sure we can download an artifact\nfunc (s *ArgoServerSuite) TestArtifactServer() {\n\tvar uid types.UID\n\tvar name string\n\ts.Given().\n\t\tWorkflow(`@testdata/artifact-workflow.yaml`).\n\t\tWhen().\n\t\tSubmitWorkflow().\n\t\tWaitForWorkflow(fixtures.ToBeArchived).\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, status *wfv1.WorkflowStatus) {\n\t\t\tname = metadata.Name\n\t\t\tuid = metadata.UID\n\t\t})\n\n\ts.Run(\"GetArtifact\", func() {\n\t\tresp := s.e().GET(\"/artifacts/argo/\" + name + \"/\" + name + \"/main-file\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\tresp.Body().\n\t\t\tContains(\":) Hello Argo!\")\n\n\t\tresp.Header(\"Content-Security-Policy\").\n\t\t\tEqual(\"sandbox; base-uri 'none'; default-src 'none'; img-src 'self'; style-src 'self'\") // MSB\n\n\t\tresp.Header(\"X-Frame-Options\").\n\t\t\tEqual(\"SAMEORIGIN\")\n\t})\n\n\t// In this case, the artifact name is a file\n\ts.Run(\"GetArtifactFile\", func() {\n\t\tresp := s.e().GET(\"/artifact-files/argo/workflows/\" + name + \"/\" + name + \"/outputs/main-file\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\tresp.Body().\n\t\t\tContains(\":) Hello Argo!\")\n\n\t\tresp.Header(\"Content-Security-Policy\").\n\t\t\tEqual(\"sandbox; base-uri 'none'; default-src 'none'; img-src 'self'; style-src 'self'\") // MSB\n\n\t\tresp.Header(\"X-Frame-Options\").\n\t\t\tEqual(\"SAMEORIGIN\")\n\t})\n\n\t// In this case, the artifact name is a directory\n\ts.Run(\"GetArtifactFileDirectory\", func() {\n\t\tresp := s.e().GET(\"/artifact-files/argo/workflows/\" + name + \"/\" + name + \"/outputs/out/\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\tresp.Body().\n\t\t\tContains(\"<a href=\\\"subdirectory/\\\">subdirectory/</a>\")\n\n\t})\n\n\t// In this case, the filename specified in the request is actually a directory\n\ts.Run(\"GetArtifactFileSubdirectory\", func() {\n\t\tresp := s.e().GET(\"/artifact-files/argo/workflows/\" + name + \"/\" + name + \"/outputs/out/subdirectory/\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\tresp.Body().\n\t\t\tContains(\"<a href=\\\"sub-file-1\\\">sub-file-1</a>\").\n\t\t\tContains(\"<a href=\\\"sub-file-2\\\">sub-file-2</a>\")\n\n\t})\n\n\t// In this case, the filename specified in the request is a subdirectory file\n\ts.Run(\"GetArtifactSubfile\", func() {\n\t\tresp := s.e().GET(\"/artifact-files/argo/workflows/\" + name + \"/\" + name + \"/outputs/out/subdirectory/sub-file-1\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\tresp.Body().\n\t\t\tContains(\":) Hello Argo!\")\n\n\t\tresp.Header(\"Content-Security-Policy\").\n\t\t\tEqual(\"sandbox; base-uri 'none'; default-src 'none'; img-src 'self'; style-src 'self'\") // MSB\n\n\t\tresp.Header(\"X-Frame-Options\").\n\t\t\tEqual(\"SAMEORIGIN\")\n\t})\n\n\t// In this case, the artifact name is a file\n\ts.Run(\"GetArtifactBadFile\", func() {\n\t\t_ = s.e().GET(\"/artifact-files/argo/workflows/\" + name + \"/\" + name + \"/outputs/not-a-file\").\n\t\t\tExpect().\n\t\t\tStatus(500)\n\t})\n\n\ts.Run(\"GetArtifactByUID\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflows/argo/\" + name).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\n\t\ts.e().GET(\"/artifacts-by-uid/{uid}/{name}/main-file\", uid, name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tBody().\n\t\t\tContains(\":) Hello Argo!\")\n\t})\n\n\t// as the artifact server has some special code for cookies, we best test that too\n\ts.Run(\"GetArtifactByUIDUsingCookie\", func() {\n\t\ttoken := s.bearerToken\n\t\tdefer func() { s.bearerToken = token }()\n\t\ts.bearerToken = \"\"\n\t\ts.e().GET(\"/artifacts-by-uid/{uid}/{name}/main-file\", uid, name).\n\t\t\tWithHeader(\"Cookie\", \"authorization=Bearer \"+token).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"GetArtifactFileByUID\", func() {\n\t\ts.e().GET(\"/artifact-files/argo/archived-workflows/{uid}/{name}/outputs/main-file\", uid, name).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tBody().\n\t\t\tContains(\":) Hello Argo!\")\n\t})\n}\n\nfunc (s *ArgoServerSuite) stream(url string, f func(t *testing.T, line string) (done bool)) {\n\tt := s.T()\n\treq, err := http.NewRequest(\"GET\", baseUrl+url, nil)\n\tassert.NoError(t, err)\n\treq.Header.Set(\"Accept\", \"text/event-stream\")\n\treq.Header.Set(\"Authorization\", \"Bearer \"+s.bearerToken)\n\treq.Close = true\n\tresp, err := httpClient.Do(req)\n\tassert.NoError(t, err)\n\tdefer func() {\n\t\tif resp != nil && resp.Body != nil {\n\t\t\t_ = resp.Body.Close()\n\t\t}\n\t}()\n\tassert.Equal(t, 200, resp.StatusCode)\n\tassert.Equal(t, \"text/event-stream\", resp.Header.Get(\"Content-Type\"))\n\tif t.Failed() {\n\t\tt.FailNow()\n\t}\n\tif f == nil {\n\t\treturn\n\t}\n\tscanner := bufio.NewScanner(resp.Body)\n\tfor scanner.Scan() {\n\t\tline := scanner.Text()\n\t\tlog.WithField(\"line\", line).Debug()\n\t\t// make sure we have this enabled\n\t\tif line == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tif f(t, line) || t.Failed() {\n\t\t\treturn\n\t\t}\n\t}\n}\n\n// do some basic testing on the stream methods\nfunc (s *ArgoServerSuite) TestWorkflowServiceStream() {\n\tvar name string\n\ts.Given().\n\t\tWorkflow(\"@smoke/basic.yaml\").\n\t\tWhen().\n\t\tSubmitWorkflow().\n\t\tWaitForWorkflow(fixtures.ToStart).\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, status *wfv1.WorkflowStatus) {\n\t\t\tname = metadata.Name\n\t\t})\n\n\t// use the watch to make sure that the workflow has succeeded\n\ts.Run(\"Watch\", func() {\n\t\ts.stream(\"/api/v1/workflow-events/argo?listOptions.fieldSelector=metadata.name=\"+name, func(t *testing.T, line string) (done bool) {\n\t\t\tif strings.Contains(line, `status:`) {\n\t\t\t\tassert.Contains(t, line, `\"offloadNodeStatus\":true`)\n\t\t\t\t// so that we get this\n\t\t\t\tassert.Contains(t, line, `\"nodes\":`)\n\t\t\t}\n\t\t\treturn strings.Contains(line, \"Succeeded\")\n\t\t})\n\t})\n\n\t// then,  lets see what events we got\n\ts.Run(\"WatchEvents\", func() {\n\t\ts.stream(\"/api/v1/stream/events/argo?listOptions.fieldSelector=involvedObject.kind=Workflow,involvedObject.name=\"+name, func(t *testing.T, line string) (done bool) {\n\t\t\treturn strings.Contains(line, \"WorkflowRunning\")\n\t\t})\n\t})\n\n\t// then,  lets check the logs\n\tfor _, tt := range []struct {\n\t\tname string\n\t\tpath string\n\t}{\n\t\t{\"PodLogs\", \"/\" + name + \"/log?logOptions.container=main&logOptions.tailLines=3\"},\n\t\t{\"WorkflowLogs\", \"/log?podName=\" + name + \"&logOptions.container=main&logOptions.tailLines=3\"},\n\t} {\n\t\ts.Run(tt.name, func() {\n\t\t\ts.stream(\"/api/v1/workflows/argo/\"+name+tt.path, func(t *testing.T, line string) (done bool) {\n\t\t\t\tif strings.Contains(line, \"data: \") {\n\t\t\t\t\tassert.Contains(t, line, fmt.Sprintf(`\"podName\":\"%s\"`, name))\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t\treturn false\n\t\t\t})\n\t\t})\n\t}\n}\n\nfunc (s *ArgoServerSuite) TestArchivedWorkflowService() {\n\tvar uid types.UID\n\ts.Given().\n\t\tWorkflow(`\nmetadata:\n  generateName: archie-\n  labels:\n    foo: 1\nspec:\n  entrypoint: run-archie\n  templates:\n    - name: run-archie\n      container:\n        image: argoproj/argosay:v2`).\n\t\tWhen().\n\t\tSubmitWorkflow().\n\t\tWaitForWorkflow(fixtures.ToBeArchived).\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, status *wfv1.WorkflowStatus) {\n\t\t\tuid = metadata.UID\n\t\t})\n\tvar failedUid types.UID\n\tvar failedName string\n\ts.Given().\n\t\tWorkflow(`\nmetadata:\n  generateName: jughead-\n  labels:\n    foo: 3\nspec:\n  entrypoint: run-jughead\n  templates:\n    - name: run-jughead\n      container:\n        image: argoproj/argosay:v2\n        command: [sh, -c]\n        args: [\"echo intentional failure; exit 1\"]`).\n\t\tWhen().\n\t\tSubmitWorkflow().\n\t\tWaitForWorkflow(fixtures.ToBeArchived).\n\t\tThen().\n\t\tExpectWorkflow(func(t *testing.T, metadata *metav1.ObjectMeta, status *wfv1.WorkflowStatus) {\n\t\t\tfailedUid = metadata.UID\n\t\t\tfailedName = metadata.Name\n\t\t})\n\ts.Given().\n\t\tWorkflow(`\nmetadata:\n  generateName: betty-\n  labels:\n    foo: 2\nspec:\n  entrypoint: run-betty\n  templates:\n    - name: run-betty\n      container:\n        image: argoproj/argosay:v2`).\n\t\tWhen().\n\t\tSubmitWorkflow().\n\t\tWaitForWorkflow(fixtures.ToBeArchived)\n\n\tfor _, tt := range []struct {\n\t\tname     string\n\t\tselector string\n\t\twantLen  int\n\t}{\n\t\t{\"ListDoesNotExist\", \"!foo\", 0},\n\t\t{\"ListEquals\", \"foo=1\", 1},\n\t\t{\"ListDoubleEquals\", \"foo==1\", 1},\n\t\t{\"ListIn\", \"foo in (1)\", 1},\n\t\t{\"ListNotEquals\", \"foo!=1\", 2},\n\t\t{\"ListNotIn\", \"foo notin (1)\", 2},\n\t\t{\"ListExists\", \"foo\", 3},\n\t\t{\"ListGreaterThan0\", \"foo>0\", 3},\n\t\t{\"ListGreaterThan1\", \"foo>1\", 2},\n\t\t{\"ListLessThan1\", \"foo<1\", 0},\n\t\t{\"ListLessThan2\", \"foo<2\", 1},\n\t} {\n\t\ts.Run(tt.name, func() {\n\t\t\tpath := s.e().GET(\"/api/v1/archived-workflows\").\n\t\t\t\tWithQuery(\"listOptions.fieldSelector\", \"metadata.namespace=argo\").\n\t\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test,\"+tt.selector).\n\t\t\t\tExpect().\n\t\t\t\tStatus(200).\n\t\t\t\tJSON().\n\t\t\t\tPath(\"$.items\")\n\n\t\t\tif tt.wantLen == 0 {\n\t\t\t\tpath.Null()\n\t\t\t} else {\n\t\t\t\tpath.Array().\n\t\t\t\t\tLength().\n\t\t\t\t\tEqual(tt.wantLen)\n\t\t\t}\n\t\t})\n\t}\n\n\ts.Run(\"ListWithLimitAndOffset\", func() {\n\t\tj := s.e().GET(\"/api/v1/archived-workflows\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tWithQuery(\"listOptions.fieldSelector\", \"metadata.namespace=argo\").\n\t\t\tWithQuery(\"listOptions.limit\", 1).\n\t\t\tWithQuery(\"listOptions.offset\", 1).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t\tj.\n\t\t\tPath(\"$.metadata.continue\").\n\t\t\tEqual(\"1\")\n\t})\n\n\ts.Run(\"ListWithMinStartedAtGood\", func() {\n\t\tfieldSelector := \"metadata.namespace=argo,spec.startedAt>\" + time.Now().Add(-1*time.Hour).Format(time.RFC3339) + \",spec.startedAt<\" + time.Now().Add(1*time.Hour).Format(time.RFC3339)\n\t\ts.e().GET(\"/api/v1/archived-workflows\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tWithQuery(\"listOptions.fieldSelector\", fieldSelector).\n\t\t\tWithQuery(\"listOptions.limit\", 2).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(2)\n\t})\n\n\ts.Run(\"ListWithMinStartedAtBad\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tWithQuery(\"listOptions.fieldSelector\", \"metadata.namespace=argo,spec.startedAt>\"+time.Now().Add(1*time.Hour).Format(time.RFC3339)).\n\t\t\tWithQuery(\"listOptions.limit\", 2).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").Null()\n\t})\n\n\ts.Run(\"Get\", func() {\n\t\ts.e().GET(\"/api/v1/archived-workflows/not-found\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t\ts.e().GET(\"/api/v1/archived-workflows/{uid}\", uid).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tNotNull()\n\t})\n\n\ts.Run(\"DeleteForRetry\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflows/argo/\" + failedName).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"Retry\", func() {\n\t\ts.e().PUT(\"/api/v1/archived-workflows/{uid}/retry\", failedUid).\n\t\t\tWithBytes([]byte(`{\"namespace\": \"argo\"}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tNotNull()\n\t\ts.e().PUT(\"/api/v1/archived-workflows/{uid}/retry\", failedUid).\n\t\t\tWithBytes([]byte(`{\"namespace\": \"argo\"}`)).\n\t\t\tExpect().\n\t\t\tStatus(409)\n\t})\n\n\ts.Run(\"Resubmit\", func() {\n\t\ts.e().PUT(\"/api/v1/archived-workflows/{uid}/resubmit\", uid).\n\t\t\tWithBytes([]byte(`{\"namespace\": \"argo\", \"memoized\": false}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tNotNull()\n\t})\n\n\ts.Run(\"Delete\", func() {\n\t\ts.e().DELETE(\"/api/v1/archived-workflows/{uid}\", uid).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t\ts.e().DELETE(\"/api/v1/archived-workflows/{uid}\", uid).\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t})\n\n\ts.Run(\"ListLabelKeys\", func() {\n\t\tj := s.e().GET(\"/api/v1/archived-workflows-label-keys\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tGt(0)\n\t})\n\n\ts.Run(\"ListLabelValues\", func() {\n\t\tj := s.e().GET(\"/api/v1/archived-workflows-label-values\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON()\n\t\tj.\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\n}\n\nfunc (s *ArgoServerSuite) TestWorkflowTemplateService() {\n\ts.Run(\"Lint\", func() {\n\t\ts.e().POST(\"/api/v1/workflow-templates/argo/lint\").\n\t\t\tWithBytes([]byte(`{\n  \"template\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"name\": \"\",\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"Create\", func() {\n\t\ts.e().POST(\"/api/v1/workflow-templates/argo\").\n\t\t\tWithBytes([]byte(`{\n  \"template\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"subject-3\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"name\": \"\",\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"List\", func() {\n\t\t// make sure list options work correctly\n\t\ts.Given().\n\t\t\tWorkflowTemplate(\"@smoke/workflow-template-whalesay-template.yaml\").\n\t\t\tWhen().\n\t\t\tCreateWorkflowTemplates()\n\n\t\ts.e().GET(\"/api/v1/workflow-templates/argo\").\n\t\t\tWithQuery(\"listOptions.labelSelector\", \"workflows.argoproj.io/test=subject-3\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\n\tvar resourceVersion string\n\ts.Run(\"Get\", func() {\n\t\ts.e().GET(\"/api/v1/workflow-templates/argo/not-found\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\n\t\tresourceVersion = s.e().GET(\"/api/v1/workflow-templates/argo/test\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.resourceVersion\").\n\t\t\tString().\n\t\t\tRaw()\n\t})\n\n\ts.Run(\"Update\", func() {\n\t\ts.e().PUT(\"/api/v1/workflow-templates/argo/test\").\n\t\t\tWithBytes([]byte(`{\"template\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"resourceVersion\": \"` + resourceVersion + `\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"name\": \"\",\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec.templates[0].container.image\").\n\t\t\tEqual(\"argoproj/argosay:v2\")\n\t})\n\n\ts.Run(\"Delete\", func() {\n\t\ts.e().DELETE(\"/api/v1/workflow-templates/argo/test\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestSubmitWorkflowFromResource() {\n\ts.Run(\"CreateWFT\", func() {\n\t\ts.e().POST(\"/api/v1/workflow-templates/argo\").\n\t\t\tWithBytes([]byte(`{\n  \"template\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"subject-4\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"name\": \"\",\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).Expect().Status(200)\n\t})\n\n\ts.Run(\"SubmitWFT\", func() {\n\t\ts.e().POST(\"/api/v1/workflows/argo/submit\").\n\t\t\tWithBytes([]byte(`{\n\t\t\t  \"resourceKind\": \"WorkflowTemplate\",\n\t\t\t  \"resourceName\": \"test\",\n\t\t\t  \"submitOptions\": {\n                \"labels\": \"workflows.argoproj.io/test=true\"\n              }\n\t\t\t}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"CreateCronWF\", func() {\n\t\ts.e().POST(\"/api/v1/cron-workflows/argo\").\n\t\t\tWithBytes([]byte(`{\n  \"cronWorkflow\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"subject-5\"\n      }\n    },\n    \"spec\": {\n      \"schedule\": \"* * * * *\",\n      \"workflowSpec\": {\n        \"entrypoint\": \"whalesay\",\n        \"templates\": [\n          {\n            \"name\": \"whalesay\",\n            \"container\": {\n              \"image\": \"argoproj/argosay:v2\",\n              \"imagePullPolicy\": \"IfNotPresent\"\n            }\n          }\n        ]\n      }\n    }\n  }\n}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\ts.Run(\"SubmitWFT\", func() {\n\t\ts.e().POST(\"/api/v1/workflows/argo/submit\").\n\t\t\tWithBytes([]byte(`{\n\t\t\t  \"resourceKind\": \"cronworkflow\",\n\t\t\t  \"resourceName\": \"test\",\n\t\t\t  \"submitOptions\": {\n                \"labels\": \"workflows.argoproj.io/test=true\"\n              }\n\t\t\t}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\n\ts.Run(\"CreateCWFT\", func() {\n\t\ts.e().POST(\"/api/v1/cluster-workflow-templates\").\n\t\t\tWithBytes([]byte(`{\n  \"template\": {\n    \"metadata\": {\n      \"name\": \"test\",\n      \"labels\": {\n         \"workflows.argoproj.io/test\": \"subject-6\"\n      }\n    },\n    \"spec\": {\n      \"templates\": [\n        {\n          \"name\": \"run-workflow\",\n          \"container\": {\n            \"name\": \"\",\n            \"image\": \"argoproj/argosay:v2\",\n            \"imagePullPolicy\": \"IfNotPresent\"\n          }\n        }\n      ],\n      \"entrypoint\": \"run-workflow\"\n    }\n  }\n}`)).Expect().Status(200)\n\t})\n\n\ts.Run(\"SubmitCWFT\", func() {\n\t\ts.e().POST(\"/api/v1/workflows/argo/submit\").\n\t\t\tWithBytes([]byte(`{\n\t\t\t  \"resourceKind\": \"ClusterWorkflowTemplate\",\n\t\t\t  \"resourceName\": \"test\",\n\t\t\t  \"submitOptions\": {\n                \"labels\": \"workflows.argoproj.io/test=true\"\n              }\n\t\t\t}`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestEventSourcesService() {\n\ts.Run(\"CreateEventSource\", func() {\n\t\ts.e().POST(\"/api/v1/event-sources/argo\").\n\t\t\tWithBytes([]byte(`\n{\n  \"eventsource\": {\n    \"metadata\": {\n      \"name\": \"test-event-source\", \n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"calendar\": {\n        \"example-with-interval\": {\n          \"interval\": \"10s\"\n        }\n      }\n    }\n  }\n}\n`)).\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.resourceVersion\").\n\t\t\tNotNull().\n\t\t\tString().\n\t\t\tRaw()\n\t})\n\ts.Run(\"ListEventSources\", func() {\n\t\ts.e().GET(\"/api/v1/event-sources/argo\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\ts.Run(\"WatchEventSources\", func() {\n\t\ts.stream(\"/api/v1/stream/event-sources/argo\", func(t *testing.T, line string) (done bool) {\n\t\t\tassert.Contains(t, line, \"test-event-source\")\n\t\t\treturn true\n\t\t})\n\t})\n\ts.Run(\"EventSourcesLogs\", func() {\n\t\ts.T().Skip(\"we do not install the controllers, so we won't get any logs\")\n\t\ts.stream(\"/api/v1/stream/event-sources/argo/logs\", func(t *testing.T, line string) (done bool) {\n\t\t\tassert.Contains(t, line, \"test-event-source\")\n\t\t\treturn true\n\t\t})\n\t})\n\tvar resourceVersion string\n\ts.Run(\"GetEventSource\", func() {\n\t\tresourceVersion = s.e().GET(\"/api/v1/event-sources/argo/test-event-source\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.resourceVersion\").\n\t\t\tNotNull().\n\t\t\tString().\n\t\t\tRaw()\n\t})\n\ts.Run(\"UpdateEventSource\", func() {\n\t\ts.e().PUT(\"/api/v1/event-sources/argo/test-event-source\").\n\t\t\tWithBytes([]byte(`\n{\n  \"eventsource\": {\n    \"metadata\": {\n      \"name\": \"test-event-source\", \n      \"resourceVersion\": \"` + resourceVersion + `\",\n      \"labels\": {\n        \"workflows.argoproj.io/test\": \"true\"\n      }\n    },\n    \"spec\": {\n      \"calendar\": {\n        \"example-with-interval\": {\n          \"interval\": \"10s\"\n        }\n      }\n    }\n  }\n}\n`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\ts.Run(\"DeleteEventSource\", func() {\n\t\ts.e().DELETE(\"/api/v1/event-sources/argo/test-event-source\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestPipelineService() {\n\ts.T().SkipNow()\n\ts.Run(\"GetPipeline\", func() {\n\t\ts.e().GET(\"/api/v1/pipelines/argo/not-exists\").\n\t\t\tExpect().\n\t\t\tStatus(404)\n\t})\n\ts.Run(\"ListPipelines\", func() {\n\t\ts.e().GET(\"/api/v1/pipelines/argo\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc (s *ArgoServerSuite) TestSensorService() {\n\ts.Run(\"CreateSensor\", func() {\n\t\ts.e().POST(\"/api/v1/sensors/argo\").\n\t\t\tWithBytes([]byte(`\n{\n\t\"sensor\":{\n\t\t\"metadata\":{\n\t\t\t\"name\":\"test-sensor\",\n\t\t\t\"labels\": {\n\t\t\t\t\"workflows.argoproj.io/test\": \"true\"\n\t\t\t}\n\t\t},\n\t\t\"spec\":{\n\t\t\t\"dependencies\":[\n\t\t\t\t{\n\t\t\t\t\t\"name\":\"test-dep\",\n\t\t\t\t\t\"eventSourceName\":\"calendar\",\n\t\t\t\t\t\"eventName\":\"example-with-interval\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"triggers\":[\n\t\t\t\t{\n\t\t\t\t\t\"template\":{\n\t\t\t\t\t\t\"name\":\"log-trigger\",\n\t\t\t\t\t\t\"log\":{\n\t\t\t\t\t\t\t\"intervalSeconds\":20\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t}\n}\n`)).Expect().\n\t\t\tStatus(200)\n\t})\n\ts.Run(\"ListSensors\", func() {\n\t\ts.e().GET(\"/api/v1/sensors/argo\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.items\").\n\t\t\tArray().\n\t\t\tLength().\n\t\t\tEqual(1)\n\t})\n\ts.Run(\"GetSensor\", func() {\n\t\ts.e().GET(\"/api/v1/sensors/argo/test-sensor\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.metadata.name\").\n\t\t\tEqual(\"test-sensor\")\n\t})\n\ts.Run(\"WatchSensors\", func() {\n\t\ts.stream(\"/api/v1/stream/sensors/argo\", func(t *testing.T, line string) (done bool) {\n\t\t\tassert.Contains(t, line, \"test-sensor\")\n\t\t\treturn true\n\t\t})\n\t})\n\ts.Run(\"SensorsLogs\", func() {\n\t\ts.T().Skip(\"we do not install the controllers, so we won't get any logs\")\n\t\ts.stream(\"/api/v1/stream/sensors/argo/logs\", func(t *testing.T, line string) (done bool) {\n\t\t\tassert.Contains(t, line, \"test-sensor\")\n\t\t\treturn true\n\t\t})\n\t})\n\tresourceVersion := s.e().GET(\"/api/v1/sensors/argo/test-sensor\").\n\t\tExpect().\n\t\tStatus(200).\n\t\tJSON().\n\t\tPath(\"$.metadata.resourceVersion\").\n\t\tString().\n\t\tRaw()\n\ts.Run(\"UpdateSensor\", func() {\n\t\ts.e().PUT(\"/api/v1/sensors/argo/test-sensor\").\n\t\t\tWithBytes([]byte(`\n{\n\t\"sensor\":{\n\t\t\"metadata\":{\n\t\t\t\"name\":\"test-sensor\",\n\t\t\t\"resourceVersion\": \"` + resourceVersion + `\",\n\t\t\t\"labels\": {\n\t\t\t\t\"workflows.argoproj.io/test\": \"true\"\n\t\t\t}\n\t\t},\n\t\t\"spec\": {\n\t\t\t\"template\": {\n\t\t\t\t\"serviceAccountName\": \"default\"\n\t\t\t},\n\t\t\t\"dependencies\":[\n\t\t\t\t{\n\t\t\t\t\t\"name\":\"test-dep\",\n\t\t\t\t\t\"eventSourceName\":\"calendar\",\n\t\t\t\t\t\"eventName\":\"example-with-interval\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"triggers\":[\n\t\t\t\t{\n\t\t\t\t\t\"template\":{\n\t\t\t\t\t\t\"name\":\"log-trigger\",\n\t\t\t\t\t\t\"log\":{\n\t\t\t\t\t\t\t\"intervalSeconds\":20\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t}\n}\n`)).\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n\ts.Run(\"GetSensorAfterUpdating\", func() {\n\t\ts.e().GET(\"/api/v1/sensors/argo/test-sensor\").\n\t\t\tExpect().\n\t\t\tStatus(200).\n\t\t\tJSON().\n\t\t\tPath(\"$.spec.template.serviceAccountName\").\n\t\t\tEqual(\"default\")\n\t})\n\ts.Run(\"DeleteSensor\", func() {\n\t\ts.e().DELETE(\"/api/v1/sensors/argo/test-sensor\").\n\t\t\tExpect().\n\t\t\tStatus(200)\n\t})\n}\n\nfunc TestArgoServerSuite(t *testing.T) {\n\tsuite.Run(t, new(ArgoServerSuite))\n}\n"], "filenames": ["server/apiserver/argoserver.go", "server/artifacts/artifact_server.go", "test/e2e/argo_server_test.go"], "buggy_code_start_loc": [344, 18, 1067], "buggy_code_end_loc": [349, 411, 1112], "fixing_code_start_loc": [344, 19, 1068], "fixing_code_end_loc": [353, 415, 1128], "type": "NVD-CWE-noinfo", "message": "Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. In affected versions an attacker can create a workflow which produces a HTML artifact containing an HTML file that contains a script which uses XHR calls to interact with the Argo Server API. The attacker emails the deep-link to the artifact to their victim. The victim opens the link, the script starts running. As the script has access to the Argo Server API (as the victim), so may read information about the victim\u2019s workflows, or create and delete workflows. Note the attacker must be an insider: they must have access to the same cluster as the victim and must already be able to run their own workflows. The attacker must have an understanding of the victim\u2019s system. We have seen no evidence of this in the wild. We urge all users to upgrade to the fixed versions.", "other": {"cve": {"id": "CVE-2022-29164", "sourceIdentifier": "security-advisories@github.com", "published": "2022-05-06T00:15:07.990", "lastModified": "2022-05-17T13:49:04.013", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. In affected versions an attacker can create a workflow which produces a HTML artifact containing an HTML file that contains a script which uses XHR calls to interact with the Argo Server API. The attacker emails the deep-link to the artifact to their victim. The victim opens the link, the script starts running. As the script has access to the Argo Server API (as the victim), so may read information about the victim\u2019s workflows, or create and delete workflows. Note the attacker must be an insider: they must have access to the same cluster as the victim and must already be able to run their own workflows. The attacker must have an understanding of the victim\u2019s system. We have seen no evidence of this in the wild. We urge all users to upgrade to the fixed versions."}, {"lang": "es", "value": "Argo Workflows es un motor de flujo de trabajo nativo de contenedores de c\u00f3digo abierto para orquestar trabajos paralelos en Kubernetes. En las versiones afectadas, un atacante puede crear un flujo de trabajo que produzca un artefacto HTML que contenga un archivo HTML con un script que use llamadas XHR para interactuar con la API del servidor Argo. El atacante env\u00eda por correo electr\u00f3nico el enlace profundo al artefacto a su v\u00edctima. La v\u00edctima abre el enlace y el script comienza a ejecutarse. Como el script presenta acceso a la API del Servidor Argo (como la v\u00edctima), puede leer informaci\u00f3n sobre los flujos de trabajo de la v\u00edctima, o crear y eliminar flujos de trabajo. Tenga en cuenta que el atacante debe ser un insider: debe tener acceso al mismo cluster que la v\u00edctima y debe ser capaz de ejecutar sus propios flujos de trabajo. El atacante debe conocer el sistema de la v\u00edctima. No hemos visto ninguna evidencia de esto en la naturaleza. Instamos a todos los usuarios a actualizar a las versiones corregidas"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.2, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.2, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:H/Au:S/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "HIGH", "authentication": "SINGLE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 4.6}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-269"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:argo_workflows_project:argo_workflows:*:*:*:*:*:kubernetes:*:*", "versionStartIncluding": "2.6.0", "versionEndExcluding": "3.2.11", "matchCriteriaId": "EAC92A3D-08DC-462A-8ADF-8EADD0D6589A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:argo_workflows_project:argo_workflows:*:*:*:*:*:kubernetes:*:*", "versionStartIncluding": "3.3.0", "versionEndExcluding": "3.3.5", "matchCriteriaId": "974CEC07-D4DF-4CE1-B58D-190A83E22A53"}]}]}], "references": [{"url": "https://github.com/argoproj/argo-workflows/commit/87470e1c2bf703a9110e97bb755614ce8757fdcc", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/argoproj/argo-workflows/pull/8585", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/argoproj/argo-workflows/security/advisories/GHSA-cmv8-6362-r5w9", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/argoproj/argo-workflows/commit/87470e1c2bf703a9110e97bb755614ce8757fdcc"}}
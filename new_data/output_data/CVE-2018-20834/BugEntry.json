{"buggy_code": ["'use strict'\n\nconst assert = require('assert')\nconst EE = require('events').EventEmitter\nconst Parser = require('./parse.js')\nconst fs = require('fs')\nconst fsm = require('fs-minipass')\nconst path = require('path')\nconst mkdir = require('./mkdir.js')\nconst mkdirSync = mkdir.sync\nconst wc = require('./winchars.js')\n\nconst ONENTRY = Symbol('onEntry')\nconst CHECKFS = Symbol('checkFs')\nconst MAKEFS = Symbol('makeFs')\nconst FILE = Symbol('file')\nconst DIRECTORY = Symbol('directory')\nconst LINK = Symbol('link')\nconst SYMLINK = Symbol('symlink')\nconst HARDLINK = Symbol('hardlink')\nconst UNSUPPORTED = Symbol('unsupported')\nconst UNKNOWN = Symbol('unknown')\nconst CHECKPATH = Symbol('checkPath')\nconst MKDIR = Symbol('mkdir')\nconst ONERROR = Symbol('onError')\nconst PENDING = Symbol('pending')\nconst PEND = Symbol('pend')\nconst UNPEND = Symbol('unpend')\nconst ENDED = Symbol('ended')\nconst MAYBECLOSE = Symbol('maybeClose')\nconst SKIP = Symbol('skip')\nconst DOCHOWN = Symbol('doChown')\nconst UID = Symbol('uid')\nconst GID = Symbol('gid')\n\n// this.gid, entry.gid, this.processUid\nconst uint32 = (a, b, c) =>\n  a === a >>> 0 ? a\n  : b === b >>> 0 ? b\n  : c\n\nclass Unpack extends Parser {\n  constructor (opt) {\n    if (!opt)\n      opt = {}\n\n    opt.ondone = _ => {\n      this[ENDED] = true\n      this[MAYBECLOSE]()\n    }\n\n    super(opt)\n\n    this.transform = typeof opt.transform === 'function' ? opt.transform : null\n\n    this.writable = true\n    this.readable = false\n\n    this[PENDING] = 0\n    this[ENDED] = false\n\n    this.dirCache = opt.dirCache || new Map()\n\n    if (typeof opt.uid === 'number' || typeof opt.gid === 'number') {\n      // need both or neither\n      if (typeof opt.uid !== 'number' || typeof opt.gid !== 'number')\n        throw new TypeError('cannot set owner without number uid and gid')\n      if (opt.preserveOwner)\n        throw new TypeError(\n          'cannot preserve owner in archive and also set owner explicitly')\n      this.uid = opt.uid\n      this.gid = opt.gid\n      this.setOwner = true\n    } else {\n      this.uid = null\n      this.gid = null\n      this.setOwner = false\n    }\n\n    // default true for root\n    if (opt.preserveOwner === undefined && typeof opt.uid !== 'number')\n      this.preserveOwner = process.getuid && process.getuid() === 0\n    else\n      this.preserveOwner = !!opt.preserveOwner\n\n    this.processUid = (this.preserveOwner || this.setOwner) && process.getuid ?\n      process.getuid() : null\n    this.processGid = (this.preserveOwner || this.setOwner) && process.getgid ?\n      process.getgid() : null\n\n    // mostly just for testing, but useful in some cases.\n    // Forcibly trigger a chown on every entry, no matter what\n    this.forceChown = opt.forceChown === true\n\n    // turn ><?| in filenames into 0xf000-higher encoded forms\n    this.win32 = !!opt.win32 || process.platform === 'win32'\n\n    // do not unpack over files that are newer than what's in the archive\n    this.newer = !!opt.newer\n\n    // do not unpack over ANY files\n    this.keep = !!opt.keep\n\n    // do not set mtime/atime of extracted entries\n    this.noMtime = !!opt.noMtime\n\n    // allow .., absolute path entries, and unpacking through symlinks\n    // without this, warn and skip .., relativize absolutes, and error\n    // on symlinks in extraction path\n    this.preservePaths = !!opt.preservePaths\n\n    // unlink files and links before writing. This breaks existing hard\n    // links, and removes symlink directories rather than erroring\n    this.unlink = !!opt.unlink\n\n    this.cwd = path.resolve(opt.cwd || process.cwd())\n    this.strip = +opt.strip || 0\n    this.processUmask = process.umask()\n    this.umask = typeof opt.umask === 'number' ? opt.umask : this.processUmask\n    // default mode for dirs created as parents\n    this.dmode = opt.dmode || (0o0777 & (~this.umask))\n    this.fmode = opt.fmode || (0o0666 & (~this.umask))\n    this.on('entry', entry => this[ONENTRY](entry))\n  }\n\n  [MAYBECLOSE] () {\n    if (this[ENDED] && this[PENDING] === 0) {\n      this.emit('prefinish')\n      this.emit('finish')\n      this.emit('end')\n      this.emit('close')\n    }\n  }\n\n  [CHECKPATH] (entry) {\n    if (this.strip) {\n      const parts = entry.path.split(/\\/|\\\\/)\n      if (parts.length < this.strip)\n        return false\n      entry.path = parts.slice(this.strip).join('/')\n    }\n\n    if (!this.preservePaths) {\n      const p = entry.path\n      if (p.match(/(^|\\/|\\\\)\\.\\.(\\\\|\\/|$)/)) {\n        this.warn('path contains \\'..\\'', p)\n        return false\n      }\n\n      // absolutes on posix are also absolutes on win32\n      // so we only need to test this one to get both\n      if (path.win32.isAbsolute(p)) {\n        const parsed = path.win32.parse(p)\n        this.warn('stripping ' + parsed.root + ' from absolute path', p)\n        entry.path = p.substr(parsed.root.length)\n      }\n    }\n\n    // only encode : chars that aren't drive letter indicators\n    if (this.win32) {\n      const parsed = path.win32.parse(entry.path)\n      entry.path = parsed.root === '' ? wc.encode(entry.path)\n        : parsed.root + wc.encode(entry.path.substr(parsed.root.length))\n    }\n\n    if (path.isAbsolute(entry.path))\n      entry.absolute = entry.path\n    else\n      entry.absolute = path.resolve(this.cwd, entry.path)\n\n    return true\n  }\n\n  [ONENTRY] (entry) {\n    if (!this[CHECKPATH](entry))\n      return entry.resume()\n\n    assert.equal(typeof entry.absolute, 'string')\n\n    switch (entry.type) {\n      case 'Directory':\n      case 'GNUDumpDir':\n        if (entry.mode)\n          entry.mode = entry.mode | 0o700\n\n      case 'File':\n      case 'OldFile':\n      case 'ContiguousFile':\n      case 'Link':\n      case 'SymbolicLink':\n        return this[CHECKFS](entry)\n\n      case 'CharacterDevice':\n      case 'BlockDevice':\n      case 'FIFO':\n        return this[UNSUPPORTED](entry)\n    }\n  }\n\n  [ONERROR] (er, entry) {\n    // Cwd has to exist, or else nothing works. That's serious.\n    // Other errors are warnings, which raise the error in strict\n    // mode, but otherwise continue on.\n    if (er.name === 'CwdError')\n      this.emit('error', er)\n    else {\n      this.warn(er.message, er)\n      this[UNPEND]()\n      entry.resume()\n    }\n  }\n\n  [MKDIR] (dir, mode, cb) {\n    mkdir(dir, {\n      uid: this.uid,\n      gid: this.gid,\n      processUid: this.processUid,\n      processGid: this.processGid,\n      umask: this.processUmask,\n      preserve: this.preservePaths,\n      unlink: this.unlink,\n      cache: this.dirCache,\n      cwd: this.cwd,\n      mode: mode\n    }, cb)\n  }\n\n  [DOCHOWN] (entry) {\n    // in preserve owner mode, chown if the entry doesn't match process\n    // in set owner mode, chown if setting doesn't match process\n    return this.forceChown ||\n      this.preserveOwner &&\n      ( typeof entry.uid === 'number' && entry.uid !== this.processUid ||\n        typeof entry.gid === 'number' && entry.gid !== this.processGid )\n      ||\n      ( typeof this.uid === 'number' && this.uid !== this.processUid ||\n        typeof this.gid === 'number' && this.gid !== this.processGid )\n  }\n\n  [UID] (entry) {\n    return uint32(this.uid, entry.uid, this.processUid)\n  }\n\n  [GID] (entry) {\n    return uint32(this.gid, entry.gid, this.processGid)\n  }\n\n  [FILE] (entry) {\n    const mode = entry.mode & 0o7777 || this.fmode\n    const stream = new fsm.WriteStream(entry.absolute, {\n      mode: mode,\n      autoClose: false\n    })\n    stream.on('error', er => this[ONERROR](er, entry))\n\n    let actions = 1\n    const done = er => {\n      if (er)\n        return this[ONERROR](er, entry)\n\n      if (--actions === 0)\n        fs.close(stream.fd, _ => this[UNPEND]())\n    }\n\n    stream.on('finish', _ => {\n      // if futimes fails, try utimes\n      // if utimes fails, fail with the original error\n      // same for fchown/chown\n      const abs = entry.absolute\n      const fd = stream.fd\n\n      if (entry.mtime && !this.noMtime) {\n        actions++\n        const atime = entry.atime || new Date()\n        const mtime = entry.mtime\n        fs.futimes(fd, atime, mtime, er =>\n          er ? fs.utimes(abs, atime, mtime, er2 => done(er2 && er))\n          : done())\n      }\n\n      if (this[DOCHOWN](entry)) {\n        actions++\n        const uid = this[UID](entry)\n        const gid = this[GID](entry)\n        fs.fchown(fd, uid, gid, er =>\n          er ? fs.chown(abs, uid, gid, er2 => done(er2 && er))\n          : done())\n      }\n\n      done()\n    })\n\n    const tx = this.transform ? this.transform(entry) || entry : entry\n    if (tx !== entry)\n      entry.pipe(tx)\n    tx.pipe(stream)\n  }\n\n  [DIRECTORY] (entry) {\n    const mode = entry.mode & 0o7777 || this.dmode\n    this[MKDIR](entry.absolute, mode, er => {\n      if (er)\n        return this[ONERROR](er, entry)\n\n      let actions = 1\n      const done = _ => {\n        if (--actions === 0) {\n          this[UNPEND]()\n          entry.resume()\n        }\n      }\n\n      if (entry.mtime && !this.noMtime) {\n        actions++\n        fs.utimes(entry.absolute, entry.atime || new Date(), entry.mtime, done)\n      }\n\n      if (this[DOCHOWN](entry)) {\n        actions++\n        fs.chown(entry.absolute, this[UID](entry), this[GID](entry), done)\n      }\n\n      done()\n    })\n  }\n\n  [UNSUPPORTED] (entry) {\n    this.warn('unsupported entry type: ' + entry.type, entry)\n    entry.resume()\n  }\n\n  [SYMLINK] (entry) {\n    this[LINK](entry, entry.linkpath, 'symlink')\n  }\n\n  [HARDLINK] (entry) {\n    this[LINK](entry, path.resolve(this.cwd, entry.linkpath), 'link')\n  }\n\n  [PEND] () {\n    this[PENDING]++\n  }\n\n  [UNPEND] () {\n    this[PENDING]--\n    this[MAYBECLOSE]()\n  }\n\n  [SKIP] (entry) {\n    this[UNPEND]()\n    entry.resume()\n  }\n\n  // check if a thing is there, and if so, try to clobber it\n  [CHECKFS] (entry) {\n    this[PEND]()\n    this[MKDIR](path.dirname(entry.absolute), this.dmode, er => {\n      if (er)\n        return this[ONERROR](er, entry)\n      fs.lstat(entry.absolute, (er, st) => {\n        if (st && (this.keep || this.newer && st.mtime > entry.mtime))\n          this[SKIP](entry)\n        else if (er || (entry.type === 'File' && !this.unlink && st.isFile()))\n          this[MAKEFS](null, entry)\n        else if (st.isDirectory()) {\n          if (entry.type === 'Directory') {\n            if (!entry.mode || (st.mode & 0o7777) === entry.mode)\n              this[MAKEFS](null, entry)\n            else\n              fs.chmod(entry.absolute, entry.mode, er => this[MAKEFS](er, entry))\n          } else\n            fs.rmdir(entry.absolute, er => this[MAKEFS](er, entry))\n        } else\n          fs.unlink(entry.absolute, er => this[MAKEFS](er, entry))\n      })\n    })\n  }\n\n  [MAKEFS] (er, entry) {\n    if (er)\n      return this[ONERROR](er, entry)\n\n    switch (entry.type) {\n      case 'File':\n      case 'OldFile':\n      case 'ContiguousFile':\n        return this[FILE](entry)\n\n      case 'Link':\n        return this[HARDLINK](entry)\n\n      case 'SymbolicLink':\n        return this[SYMLINK](entry)\n\n      case 'Directory':\n      case 'GNUDumpDir':\n        return this[DIRECTORY](entry)\n    }\n  }\n\n  [LINK] (entry, linkpath, link) {\n    // XXX: get the type ('file' or 'dir') for windows\n    fs[link](linkpath, entry.absolute, er => {\n      if (er)\n        return this[ONERROR](er, entry)\n      this[UNPEND]()\n      entry.resume()\n    })\n  }\n}\n\nclass UnpackSync extends Unpack {\n  constructor (opt) {\n    super(opt)\n  }\n\n  [CHECKFS] (entry) {\n    const er = this[MKDIR](path.dirname(entry.absolute), this.dmode)\n    if (er)\n      return this[ONERROR](er, entry)\n    try {\n      const st = fs.lstatSync(entry.absolute)\n      if (this.keep || this.newer && st.mtime > entry.mtime)\n        return this[SKIP](entry)\n      else if (entry.type === 'File' && !this.unlink && st.isFile())\n        return this[MAKEFS](null, entry)\n      else {\n        try {\n          if (st.isDirectory()) {\n            if (entry.type === 'Directory') {\n              if (entry.mode && (st.mode & 0o7777) !== entry.mode)\n                fs.chmodSync(entry.absolute, entry.mode)\n            } else\n              fs.rmdirSync(entry.absolute)\n          } else\n            fs.unlinkSync(entry.absolute)\n          return this[MAKEFS](null, entry)\n        } catch (er) {\n          return this[ONERROR](er, entry)\n        }\n      }\n    } catch (er) {\n      return this[MAKEFS](null, entry)\n    }\n  }\n\n  [FILE] (entry) {\n    const mode = entry.mode & 0o7777 || this.fmode\n\n    const oner = er => {\n      try { fs.closeSync(fd) } catch (_) {}\n      if (er)\n        this[ONERROR](er, entry)\n    }\n\n    let stream\n    let fd\n    try {\n      fd = fs.openSync(entry.absolute, 'w', mode)\n    } catch (er) {\n      return oner(er)\n    }\n    const tx = this.transform ? this.transform(entry) || entry : entry\n    if (tx !== entry)\n      entry.pipe(tx)\n\n    tx.on('data', chunk => {\n      try {\n        fs.writeSync(fd, chunk, 0, chunk.length)\n      } catch (er) {\n        oner(er)\n      }\n    })\n\n    tx.on('end', _ => {\n      let er = null\n      // try both, falling futimes back to utimes\n      // if either fails, handle the first error\n      if (entry.mtime && !this.noMtime) {\n        const atime = entry.atime || new Date()\n        const mtime = entry.mtime\n        try {\n          fs.futimesSync(fd, atime, mtime)\n        } catch (futimeser) {\n          try {\n            fs.utimesSync(entry.absolute, atime, mtime)\n          } catch (utimeser) {\n            er = futimeser\n          }\n        }\n      }\n\n      if (this[DOCHOWN](entry)) {\n        const uid = this[UID](entry)\n        const gid = this[GID](entry)\n\n        try {\n          fs.fchownSync(fd, uid, gid)\n        } catch (fchowner) {\n          try {\n            fs.chownSync(entry.absolute, uid, gid)\n          } catch (chowner) {\n            er = er || fchowner\n          }\n        }\n      }\n\n      oner(er)\n    })\n  }\n\n  [DIRECTORY] (entry) {\n    const mode = entry.mode & 0o7777 || this.dmode\n    const er = this[MKDIR](entry.absolute, mode)\n    if (er)\n      return this[ONERROR](er, entry)\n    if (entry.mtime && !this.noMtime) {\n      try {\n        fs.utimesSync(entry.absolute, entry.atime || new Date(), entry.mtime)\n      } catch (er) {}\n    }\n    if (this[DOCHOWN](entry)) {\n      try {\n        fs.chownSync(entry.absolute, this[UID](entry), this[GID](entry))\n      } catch (er) {}\n    }\n    entry.resume()\n  }\n\n  [MKDIR] (dir, mode) {\n    try {\n      return mkdir.sync(dir, {\n        uid: this.uid,\n        gid: this.gid,\n        processUid: this.processUid,\n        processGid: this.processGid,\n        umask: this.processUmask,\n        preserve: this.preservePaths,\n        unlink: this.unlink,\n        cache: this.dirCache,\n        cwd: this.cwd,\n        mode: mode\n      })\n    } catch (er) {\n      return er\n    }\n  }\n\n  [LINK] (entry, linkpath, link) {\n    try {\n      fs[link + 'Sync'](linkpath, entry.absolute)\n      entry.resume()\n    } catch (er) {\n      return this[ONERROR](er, entry)\n    }\n  }\n}\n\nUnpack.Sync = UnpackSync\nmodule.exports = Unpack\n", "'use strict'\n\nprocess.umask(0o022)\n\nconst Unpack = require('../lib/unpack.js')\nconst UnpackSync = Unpack.Sync\nconst t = require('tap')\nconst MiniPass = require('minipass')\n\nconst makeTar = require('./make-tar.js')\nconst Header = require('../lib/header.js')\nconst z = require('minizlib')\nconst fs = require('fs')\nconst path = require('path')\nconst fixtures = path.resolve(__dirname, 'fixtures')\nconst files = path.resolve(fixtures, 'files')\nconst tars = path.resolve(fixtures, 'tars')\nconst parses = path.resolve(fixtures, 'parse')\nconst unpackdir = path.resolve(fixtures, 'unpack')\nconst rimraf = require('rimraf')\nconst mkdirp = require('mkdirp')\nconst mutateFS = require('mutate-fs')\nconst eos = require('end-of-stream')\n\nt.teardown(_ => rimraf.sync(unpackdir))\n\nt.test('setup', t => {\n  rimraf.sync(unpackdir)\n  mkdirp.sync(unpackdir)\n  t.end()\n})\n\nt.test('basic file unpack tests', t => {\n  const basedir = path.resolve(unpackdir, 'basic')\n  t.teardown(_ => rimraf.sync(basedir))\n\n  const cases = {\n    'emptypax.tar': {\n      '\ud83c\udf1f.txt': '\ud83c\udf1f\u2727\u2729\u2b50\ufe0e\u272a\u272b\u272c\u272d\u272e\u269d\u272f\u2730\u2735\u2736\u2737\u2738\u2739\u2742\u2b51\u2b52\u2605\u2606\u2721\u262a\u2734\ufe0e\u2726\u2721\ufe0f\ud83d\udd2f\u2734\ufe0f\ud83c\udf20\\n',\n      'one-byte.txt': 'a'\n    },\n    'body-byte-counts.tar': {\n      '1024-bytes.txt': new Array(1024).join('x') + '\\n',\n      '512-bytes.txt': new Array(512).join('x') + '\\n',\n      'one-byte.txt': 'a',\n      'zero-byte.txt': ''\n    },\n    'utf8.tar': {\n      '\ud83c\udf1f.txt': '\ud83c\udf1f\u2727\u2729\u2b50\ufe0e\u272a\u272b\u272c\u272d\u272e\u269d\u272f\u2730\u2735\u2736\u2737\u2738\u2739\u2742\u2b51\u2b52\u2605\u2606\u2721\u262a\u2734\ufe0e\u2726\u2721\ufe0f\ud83d\udd2f\u2734\ufe0f\ud83c\udf20\\n',\n      '\u03a9.txt': '\u03a9',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/\u03a9.txt': '\u03a9'\n    },\n    'file.tar': {\n      'one-byte.txt': 'a'\n    },\n    'global-header.tar': {\n      'one-byte.txt': 'a'\n    },\n    'long-pax.tar': {\n      '120-byte-filename-cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n    },\n    'long-paths.tar': {\n      '100-byte-filename-cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      '120-byte-filename-cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      '170-byte-filename-cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/a.txt': 'short\\n',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/\u03a9.txt': '\u03a9'\n    }\n  }\n\n  const tarfiles = Object.keys(cases)\n  t.plan(tarfiles.length)\n  t.jobs = tarfiles.length\n\n  tarfiles.forEach(tarfile => {\n    t.test(tarfile, t => {\n      const tf = path.resolve(tars, tarfile)\n      const dir = path.resolve(basedir, tarfile)\n      t.beforeEach(cb => {\n        rimraf.sync(dir)\n        mkdirp.sync(dir)\n        cb()\n      })\n\n      const check = t => {\n        const expect = cases[tarfile]\n        Object.keys(expect).forEach(file => {\n          const f = path.resolve(dir, file)\n          t.equal(fs.readFileSync(f, 'utf8'), expect[file], file)\n        })\n        t.end()\n      }\n\n      t.plan(2)\n\n      t.test('async unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          const unpack = new Unpack({ cwd: dir, strict: true })\n          fs.createReadStream(tf).pipe(unpack)\n          eos(unpack, _ => check(t))\n        })\n        t.test('loose', t => {\n          const unpack = new Unpack({ cwd: dir })\n          fs.createReadStream(tf).pipe(unpack)\n          eos(unpack, _ => check(t))\n        })\n      })\n\n      t.test('sync unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          const unpack = new UnpackSync({ cwd: dir })\n          unpack.end(fs.readFileSync(tf))\n          check(t)\n        })\n        t.test('loose', t => {\n          const unpack = new UnpackSync({ cwd: dir })\n          unpack.end(fs.readFileSync(tf))\n          check(t)\n        })\n      })\n    })\n  })\n})\n\nt.test('cwd default to process cwd', t => {\n  const u = new Unpack()\n  const us = new UnpackSync()\n  const cwd = process.cwd()\n  t.equal(u.cwd, cwd)\n  t.equal(us.cwd, cwd)\n  t.end()\n})\n\nt.test('links!', t => {\n  const dir = path.resolve(unpackdir, 'links')\n  const data = fs.readFileSync(tars + '/links.tar')\n\n  t.plan(2)\n  t.beforeEach(cb => mkdirp(dir, cb))\n  t.afterEach(cb => rimraf(dir, cb))\n\n  const check = t => {\n    const hl1 = fs.lstatSync(dir + '/hardlink-1')\n    const hl2 = fs.lstatSync(dir + '/hardlink-2')\n    t.equal(hl1.dev, hl2.dev)\n    t.equal(hl1.ino, hl2.ino)\n    t.equal(hl1.nlink, 2)\n    t.equal(hl2.nlink, 2)\n    const sym = fs.lstatSync(dir + '/symlink')\n    t.ok(sym.isSymbolicLink())\n    t.equal(fs.readlinkSync(dir + '/symlink'), 'hardlink-2')\n    t.end()\n  }\n\n  t.test('async', t => {\n    const unpack = new Unpack({ cwd: dir })\n    let finished = false\n    unpack.on('finish', _ => finished = true)\n    unpack.on('close', _ => t.ok(finished, 'emitted finish before close'))\n    unpack.on('close', _ => check(t))\n    unpack.end(data)\n  })\n\n  t.test('sync', t => {\n    const unpack = new UnpackSync({ cwd: dir })\n    unpack.end(data)\n    check(t)\n  })\n})\n\nt.test('links without cleanup (exercise clobbering code)', t => {\n  const dir = path.resolve(unpackdir, 'links')\n  const data = fs.readFileSync(tars + '/links.tar')\n\n  t.plan(6)\n  mkdirp.sync(dir)\n  t.teardown(_ => rimraf.sync(dir))\n\n  t.beforeEach(cb => {\n    // clobber this junk\n    try {\n      mkdirp.sync(dir + '/hardlink-1')\n      mkdirp.sync(dir + '/hardlink-2')\n      fs.writeFileSync(dir + '/symlink', 'not a symlink')\n    } catch (er) {}\n    cb()\n  })\n\n  const check = t => {\n    const hl1 = fs.lstatSync(dir + '/hardlink-1')\n    const hl2 = fs.lstatSync(dir + '/hardlink-2')\n    t.equal(hl1.dev, hl2.dev)\n    t.equal(hl1.ino, hl2.ino)\n    t.equal(hl1.nlink, 2)\n    t.equal(hl2.nlink, 2)\n    const sym = fs.lstatSync(dir + '/symlink')\n    t.ok(sym.isSymbolicLink())\n    t.equal(fs.readlinkSync(dir + '/symlink'), 'hardlink-2')\n    t.end()\n  }\n\n  t.test('async', t => {\n    const unpack = new Unpack({ cwd: dir })\n    let prefinished = false\n    unpack.on('prefinish', _ => prefinished = true)\n    unpack.on('finish', _ =>\n      t.ok(prefinished, 'emitted prefinish before finish'))\n    unpack.on('close', _ => check(t))\n    unpack.end(data)\n  })\n\n  t.test('sync', t => {\n    const unpack = new UnpackSync({ cwd: dir })\n    unpack.end(data)\n    check(t)\n  })\n\n  t.test('async again', t => {\n    const unpack = new Unpack({ cwd: dir })\n    eos(unpack, _ => check(t))\n    unpack.end(data)\n  })\n\n  t.test('sync again', t => {\n    const unpack = new UnpackSync({ cwd: dir })\n    unpack.end(data)\n    check(t)\n  })\n\n  t.test('async unlink', t => {\n    const unpack = new Unpack({ cwd: dir, unlink: true })\n    unpack.on('close', _ => check(t))\n    unpack.end(data)\n  })\n\n  t.test('sync unlink', t => {\n    const unpack = new UnpackSync({ cwd: dir, unlink: true })\n    unpack.end(data)\n    check(t)\n  })\n})\n\nt.test('nested dir dupe', t => {\n  const dir = path.resolve(unpackdir, 'nested-dir')\n  mkdirp.sync(dir + '/d/e/e/p')\n  t.teardown(_ => rimraf.sync(dir))\n  const expect = {\n    'd/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/a.txt': 'short\\n',\n    'd/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n    'd/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n    'd/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n    'd/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/\u03a9.txt': '\u03a9'\n  }\n\n  const check = t => {\n    const entries = fs.readdirSync(dir)\n    t.equal(entries.length, 1)\n    t.equal(entries[0], 'd')\n    Object.keys(expect).forEach(f => {\n      const file = dir + '/' + f\n      t.equal(fs.readFileSync(file, 'utf8'), expect[f])\n    })\n    t.end()\n  }\n\n  const unpack = new Unpack({ cwd: dir, strip: 8 })\n  const data = fs.readFileSync(tars + '/long-paths.tar')\n  // while we're at it, why not use gzip too?\n  const zip = new z.Gzip()\n  zip.pipe(unpack)\n  unpack.on('close', _ => check(t))\n  zip.end(data)\n})\n\nt.test('symlink in dir path', t => {\n  const dir = path.resolve(unpackdir, 'symlink-junk')\n\n  t.teardown(_ => rimraf.sync(dir))\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'd/i',\n      type: 'Directory'\n    },\n    {\n      path: 'd/i/r/dir',\n      type: 'Directory',\n      mode: 0o751,\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/file',\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'a',\n    {\n      path: 'd/i/r/link',\n      type: 'Link',\n      linkpath: 'd/i/r/file',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/symlink',\n      type: 'SymbolicLink',\n      linkpath: './dir',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/symlink/x',\n      type: 'File',\n      size: 0,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    '',\n    ''\n  ])\n\n  t.test('no clobbering', t => {\n    const warnings = []\n    const u = new Unpack({ cwd: dir, onwarn: (w,d) => warnings.push([w,d]) })\n    u.on('close', _ => {\n      t.equal(fs.lstatSync(dir + '/d/i').mode & 0o7777, 0o755)\n      t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n      t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n      t.throws(_ => fs.statSync(dir + '/d/i/r/symlink/x'))\n      t.equal(warnings.length, 1)\n      t.equal(warnings[0][0], 'Cannot extract through symbolic link')\n      t.match(warnings[0][1], {\n        name: 'SylinkError',\n        path: dir + '/d/i/r/symlink/',\n        symlink: dir + '/d/i/r/symlink'\n      })\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('no clobbering, sync', t => {\n    const warnings = []\n    const u = new UnpackSync({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d])\n    })\n    u.end(data)\n    t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n    t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n    t.throws(_ => fs.statSync(dir + '/d/i/r/symlink/x'))\n    t.equal(warnings.length, 1)\n    t.equal(warnings[0][0], 'Cannot extract through symbolic link')\n    t.match(warnings[0][1], {\n      name: 'SylinkError',\n      path: dir + '/d/i/r/symlink/',\n      symlink: dir + '/d/i/r/symlink'\n    })\n    t.end()\n  })\n\n  t.test('extract through symlink', t => {\n    const warnings = []\n    const u = new Unpack({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d]),\n      preservePaths: true\n    })\n    u.on('close', _ => {\n      t.same(warnings, [])\n      t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n      t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n      t.ok(fs.lstatSync(dir + '/d/i/r/dir/x').isFile(), 'x thru link')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink/x').isFile(), 'x thru link')\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('extract through symlink sync', t => {\n    const warnings = []\n    const u = new UnpackSync({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d]),\n      preservePaths: true\n    })\n    u.end(data)\n    t.same(warnings, [])\n    t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n    t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n    t.ok(fs.lstatSync(dir + '/d/i/r/dir/x').isFile(), 'x thru link')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink/x').isFile(), 'x thru link')\n    t.end()\n  })\n\n  t.test('clobber through symlink', t => {\n    const warnings = []\n    const u = new Unpack({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d]),\n      unlink: true\n    })\n    u.on('close', _ => {\n      t.same(warnings, [])\n      t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n      t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n      t.notok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'no link')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isDirectory(), 'sym is dir')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink/x').isFile(), 'x thru link')\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('clobber through symlink with busted unlink', t => {\n    const poop = new Error('poop')\n    t.teardown(mutateFS.fail('unlink', poop))\n    const warnings = []\n    const u = new Unpack({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d]),\n      unlink: true\n    })\n    u.on('close', _ => {\n      t.same(warnings, [[ 'poop', poop ]])\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('clobber through symlink sync', t => {\n    const warnings = []\n    const u = new UnpackSync({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d]),\n      unlink: true\n    })\n    u.end(data)\n    t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n    t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n    t.notok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'no link')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isDirectory(), 'sym is dir')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink/x').isFile(), 'x thru link')\n    t.end()\n  })\n\n  t.test('clobber dirs', t => {\n    mkdirp.sync(dir + '/d/i/r/dir')\n    mkdirp.sync(dir + '/d/i/r/file')\n    mkdirp.sync(dir + '/d/i/r/link')\n    mkdirp.sync(dir + '/d/i/r/symlink')\n    const warnings = []\n    const u = new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => {\n        warnings.push([w,d])\n      }\n    })\n    u.on('close', _ => {\n      t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n      t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n      t.throws(_ => fs.statSync(dir + '/d/i/r/symlink/x'))\n      t.equal(warnings.length, 1)\n      t.equal(warnings[0][0], 'Cannot extract through symbolic link')\n      t.match(warnings[0][1], {\n        name: 'SylinkError',\n        path: dir + '/d/i/r/symlink/',\n        symlink: dir + '/d/i/r/symlink'\n      })\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('clobber dirs sync', t => {\n    mkdirp.sync(dir + '/d/i/r/dir')\n    mkdirp.sync(dir + '/d/i/r/file')\n    mkdirp.sync(dir + '/d/i/r/link')\n    mkdirp.sync(dir + '/d/i/r/symlink')\n    const warnings = []\n    const u = new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => {\n        warnings.push([w,d])\n      }\n    })\n    u.end(data)\n    t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n    t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n    t.throws(_ => fs.statSync(dir + '/d/i/r/symlink/x'))\n    t.equal(warnings.length, 1)\n    t.equal(warnings[0][0], 'Cannot extract through symbolic link')\n    t.match(warnings[0][1], {\n      name: 'SylinkError',\n      path: dir + '/d/i/r/symlink/',\n      symlink: dir + '/d/i/r/symlink'\n    })\n    t.end()\n  })\n\n  t.end()\n})\n\nt.test('unsupported entries', t => {\n  const dir = path.resolve(unpackdir, 'unsupported-entries')\n  mkdirp.sync(dir)\n  t.teardown(_ => rimraf.sync(dir))\n  const unknown = new Header({ path: 'qux', type: 'File', size: 4 })\n  unknown.type = 'Z'\n  unknown.encode()\n  const data = makeTar([\n    {\n      path: 'dev/random',\n      type: 'CharacterDevice'\n    },\n    {\n      path: 'dev/hd0',\n      type: 'BlockDevice'\n    },\n    {\n      path: 'dev/fifo0',\n      type: 'FIFO'\n    },\n    unknown.block,\n    'asdf',\n    '',\n    ''\n  ])\n\n  t.test('basic, warns', t => {\n    const warnings = []\n    const u = new Unpack({ cwd: dir, onwarn: (w,d) => warnings.push([w,d]) })\n    const expect = [\n      ['unsupported entry type: CharacterDevice', { path: 'dev/random' }],\n      ['unsupported entry type: BlockDevice', { path: 'dev/hd0' }],\n      ['unsupported entry type: FIFO', { path: 'dev/fifo0' }]\n    ]\n    u.on('close', _ => {\n      t.equal(fs.readdirSync(dir).length, 0)\n      t.match(warnings, expect)\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('strict, throws', t => {\n    const warnings = []\n    const errors = []\n    const u = new Unpack({\n      cwd: dir,\n      strict: true,\n      onwarn: (w,d) => warnings.push([w,d])\n    })\n    u.on('error', e => errors.push(e))\n    u.on('close', _ => {\n      t.equal(fs.readdirSync(dir).length, 0)\n      t.same(warnings, [])\n      t.match(errors, [\n        {\n          message: 'unsupported entry type: CharacterDevice',\n          data: { path: 'dev/random' }\n        },\n        {\n          message: 'unsupported entry type: BlockDevice',\n          data: { path: 'dev/hd0' }\n        },\n        {\n          message: 'unsupported entry type: FIFO',\n          data: { path: 'dev/fifo0' }\n        }\n      ])\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.end()\n})\n\n\nt.test('file in dir path', t => {\n  const dir = path.resolve(unpackdir, 'file-junk')\n\n  t.teardown(_ => rimraf.sync(dir))\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'd/i/r/file',\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'a',\n    {\n      path: 'd/i/r/file/a/b/c',\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'b',\n    '',\n    ''\n  ])\n\n  t.test('fail because of file', t => {\n    const check = t => {\n      t.equal(fs.readFileSync(dir + '/d/i/r/file', 'utf8'), 'a')\n      t.throws(_ => fs.statSync(dir + '/d/i/r/file/a/b/c'))\n      t.end()\n    }\n\n    t.plan(2)\n\n    t.test('async', t => {\n      new Unpack({ cwd: dir }).on('close', _ => check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      new UnpackSync({ cwd: dir }).end(data)\n      check(t)\n    })\n  })\n\n  t.test('clobber on through', t => {\n    const check = t => {\n      t.ok(fs.statSync(dir + '/d/i/r/file').isDirectory())\n      t.equal(fs.readFileSync(dir + '/d/i/r/file/a/b/c', 'utf8'), 'b')\n      t.end()\n    }\n\n    t.plan(2)\n\n    t.test('async', t => {\n      new Unpack({ cwd: dir, unlink: true }).on('close', _ => check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      new UnpackSync({ cwd: dir, unlink: true }).end(data)\n      check(t)\n    })\n  })\n\n  t.end()\n})\n\nt.test('set umask option', t => {\n  const dir = path.resolve(unpackdir, 'umask')\n  mkdirp.sync(dir)\n  t.tearDown(_ => rimraf.sync(dir))\n\n  const data = makeTar([\n    {\n      path: 'd/i/r/dir',\n      type: 'Directory',\n      mode: 0o751\n    },\n    '',\n    ''\n  ])\n\n  new Unpack({\n    umask: 0o027,\n    cwd: dir\n  }).on('close', _ => {\n    t.equal(fs.statSync(dir + '/d/i/r').mode & 0o7777, 0o750)\n    t.equal(fs.statSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n    t.end()\n  }).end(data)\n})\n\nt.test('absolute paths', t => {\n  const dir = path.join(unpackdir, 'absolute-paths')\n  t.teardown(_ => rimraf.sync(dir))\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const absolute = path.resolve(dir, 'd/i/r/absolute')\n  t.ok(path.isAbsolute(absolute))\n  const parsed = path.parse(absolute)\n  const relative = absolute.substr(parsed.root.length)\n  t.notOk(path.isAbsolute(relative))\n\n  const data = makeTar([\n    {\n      path: absolute,\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'a',\n    '',\n    ''\n  ])\n\n  t.test('warn and correct', t => {\n    const check = t => {\n      t.same(warnings, [[\n        'stripping / from absolute path',\n        absolute\n      ]])\n      t.ok(fs.lstatSync(path.resolve(dir, relative)).isFile(), 'is file')\n      t.end()\n    }\n\n    const warnings = []\n\n    t.test('async', t => {\n      warnings.length = 0\n      new Unpack({\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).on('close', _=> check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      warnings.length = 0\n      new UnpackSync({\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).end(data)\n      check(t)\n    })\n\n    t.end()\n  })\n\n  t.test('preserve absolute path', t => {\n    const check = t => {\n      t.same(warnings, [])\n      t.ok(fs.lstatSync(absolute).isFile(), 'is file')\n      t.end()\n    }\n\n    const warnings = []\n\n    t.test('async', t => {\n      warnings.length = 0\n      new Unpack({\n        preservePaths: true,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).on('close', _=> check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      warnings.length = 0\n      new UnpackSync({\n        preservePaths: true,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).end(data)\n      check(t)\n    })\n\n    t.end()\n  })\n\n  t.end()\n})\n\nt.test('.. paths', t => {\n  const dir = path.join(unpackdir, 'dotted-paths')\n  t.teardown(_ => rimraf.sync(dir))\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const fmode = 0o755\n  const dotted = 'a/b/c/../d'\n  const resolved = path.resolve(dir, dotted)\n\n  const data = makeTar([\n    {\n      path: dotted,\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'd',\n    '',\n    ''\n  ])\n\n  t.test('warn and skip', t => {\n    const check = t => {\n      t.same(warnings, [[\n        'path contains \\'..\\'',\n        dotted\n      ]])\n      t.throws(_=>fs.lstatSync(resolved))\n      t.end()\n    }\n\n    const warnings = []\n\n    t.test('async', t => {\n      warnings.length = 0\n      new Unpack({\n        fmode: fmode,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).on('close', _=> check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      warnings.length = 0\n      new UnpackSync({\n        fmode: fmode,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).end(data)\n      check(t)\n    })\n\n    t.end()\n  })\n\n  t.test('preserve dotted path', t => {\n    const check = t => {\n      t.same(warnings, [])\n      t.ok(fs.lstatSync(resolved).isFile(), 'is file')\n      t.equal(fs.lstatSync(resolved).mode & 0o777, fmode, 'mode is 0755')\n      t.end()\n    }\n\n    const warnings = []\n\n    t.test('async', t => {\n      warnings.length = 0\n      new Unpack({\n        fmode: fmode,\n        preservePaths: true,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).on('close', _=> check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      warnings.length = 0\n      new UnpackSync({\n        fmode: fmode,\n        preservePaths: true,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).end(data)\n      check(t)\n    })\n\n    t.end()\n  })\n\n  t.end()\n})\n\nt.test('fail all stats', t => {\n  const poop = new Error('poop')\n  poop.code = 'EPOOP'\n  let unmutate\n  const dir = path.join(unpackdir, 'stat-fail')\n\n  const warnings = []\n  t.beforeEach(cb => {\n    warnings.length = 0\n    mkdirp.sync(dir)\n    unmutate = mutateFS.statFail(poop)\n    cb()\n  })\n  t.afterEach(cb => {\n    unmutate()\n    rimraf.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'd/i/r/file/',\n      type: 'Directory',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/dir/',\n      type: 'Directory',\n      mode: 0o751,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/file',\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'a',\n    {\n      path: 'd/i/r/link',\n      type: 'Link',\n      linkpath: 'd/i/r/file',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/symlink',\n      type: 'SymbolicLink',\n      linkpath: './dir',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    '',\n    ''\n  ])\n\n  const check = (t, expect) => {\n    t.match(warnings, expect)\n    warnings.forEach(w => t.equal(w[0], w[1].message))\n    t.end()\n  }\n\n  t.test('async', t => {\n    const expect = [\n      ['poop', poop],\n      ['poop', poop]\n    ]\n    new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).on('close', _ => check(t, expect)).end(data)\n  })\n\n  t.test('sync', t => {\n    const expect = [\n      [\n        String,\n        {\n          code: 'EISDIR',\n          path: path.resolve(dir, 'd/i/r/file'),\n          syscall: 'open'\n        }\n      ],\n      [\n        String,\n        {\n          dest: path.resolve(dir, 'd/i/r/link'),\n          path: path.resolve(dir, 'd/i/r/file'),\n          syscall: 'link'\n        }\n      ]\n    ]\n    new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).end(data)\n    check(t, expect)\n  })\n\n  t.end()\n})\n\nt.test('fail symlink', t => {\n  const poop = new Error('poop')\n  poop.code = 'EPOOP'\n  const unmutate = mutateFS.fail('symlink', poop)\n  const dir = path.join(unpackdir, 'symlink-fail')\n  t.teardown(_ => (unmutate(), rimraf.sync(dir)))\n\n  const warnings = []\n  t.beforeEach(cb => {\n    warnings.length = 0\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'd/i/r/dir/',\n      type: 'Directory',\n      mode: 0o751,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/symlink',\n      type: 'SymbolicLink',\n      linkpath: './dir',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    '',\n    ''\n  ])\n\n  const check = (t, expect) => {\n    t.match(warnings, expect)\n    warnings.forEach(w => t.equal(w[0], w[1].message))\n    t.end()\n  }\n\n  t.test('async', t => {\n    const expect = [['poop', poop]]\n    new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).on('close', _ => check(t, expect)).end(data)\n  })\n\n  t.test('sync', t => {\n    const expect = [['poop', poop]]\n    new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).end(data)\n    check(t, expect)\n  })\n\n  t.end()\n})\n\nt.test('fail chmod', t => {\n  const poop = new Error('poop')\n  poop.code = 'EPOOP'\n  const unmutate = mutateFS.fail('chmod', poop)\n  const dir = path.join(unpackdir, 'chmod-fail')\n  t.teardown(_ => (unmutate(), rimraf.sync(dir)))\n\n  const warnings = []\n  t.beforeEach(cb => {\n    warnings.length = 0\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'd/i/r/dir/',\n      type: 'Directory',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/dir/',\n      type: 'Directory',\n      mode: 0o751,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    '',\n    ''\n  ])\n\n  const check = (t, expect) => {\n    t.match(warnings, expect)\n    warnings.forEach(w => t.equal(w[0], w[1].message))\n    t.end()\n  }\n\n  t.test('async', t => {\n    const expect = [['poop', poop]]\n    new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).on('close', _ => check(t, expect)).end(data)\n  })\n\n  t.test('sync', t => {\n    const expect = [['poop', poop]]\n    new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).end(data)\n    check(t, expect)\n  })\n\n  t.end()\n})\n\nt.test('fail mkdir', t => {\n  const poop = new Error('poop')\n  poop.code = 'EPOOP'\n  let unmutate\n  const dir = path.join(unpackdir, 'mkdir-fail')\n  t.teardown(_ => rimraf.sync(dir))\n\n  const warnings = []\n  t.beforeEach(cb => {\n    warnings.length = 0\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    unmutate = mutateFS.fail('mkdir', poop)\n    cb()\n  })\n  t.afterEach(cb => {\n    unmutate()\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'dir/',\n      type: 'Directory',\n      mode: 0o751,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    '',\n    ''\n  ])\n\n  const expect = [ [\n    'ENOENT: no such file or directory, lstat \\'' +\n    path.resolve(dir, 'dir') + '\\'',\n    {\n      code: 'ENOENT',\n      syscall: 'lstat',\n      path: path.resolve(dir, 'dir')\n    }\n  ] ]\n\n  const check = t => {\n    t.match(warnings, expect)\n    warnings.forEach(w => t.equal(w[0], w[1].message))\n    t.end()\n  }\n\n  t.test('async', t => {\n    new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).on('close', _ => check(t)).end(data)\n  })\n\n  t.test('sync', t => {\n    new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('fail write', t => {\n  const poop = new Error('poop')\n  poop.code = 'EPOOP'\n  const unmutate = mutateFS.fail('write', poop)\n  const dir = path.join(unpackdir, 'write-fail')\n  t.teardown(_ => (unmutate(), rimraf.sync(dir)))\n\n  const warnings = []\n  t.beforeEach(cb => {\n    warnings.length = 0\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'x',\n      type: 'File',\n      size: 1,\n      mode: 0o751,\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'x',\n    '',\n    ''\n  ])\n\n  const expect = [ [ 'poop', poop ] ]\n\n  const check = t => {\n    t.match(warnings, expect)\n    warnings.forEach(w => t.equal(w[0], w[1].message))\n    t.end()\n  }\n\n  t.test('async', t => {\n    new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).on('close', _ => check(t)).end(data)\n  })\n\n  t.test('sync', t => {\n    new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('skip existing', t => {\n  const dir = path.join(unpackdir, 'skip-newer')\n  t.teardown(_ => rimraf.sync(dir))\n\n  const date = new Date('2011-03-27T22:16:31.000Z')\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    fs.writeFileSync(dir + '/x', 'y')\n    fs.utimesSync(dir + '/x', date, date)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'x',\n      type: 'File',\n      size: 1,\n      mode: 0o751,\n      mtime: new Date('2013-12-19T17:00:00.000Z')\n    },\n    'x',\n    '',\n    ''\n  ])\n\n  const check = t => {\n    const st = fs.lstatSync(dir + '/x')\n    t.equal(st.atime.toISOString(), date.toISOString())\n    t.equal(st.mtime.toISOString(), date.toISOString())\n    const data = fs.readFileSync(dir + '/x', 'utf8')\n    t.equal(data, 'y')\n    t.end()\n  }\n\n  t.test('async', t => {\n    new Unpack({\n      cwd: dir,\n      keep: true\n    }).on('close', _ => check(t)).end(data)\n  })\n\n  t.test('sync', t => {\n    new UnpackSync({\n      cwd: dir,\n      keep: true\n    }).end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('skip newer', t => {\n  const dir = path.join(unpackdir, 'skip-newer')\n  t.teardown(_ => rimraf.sync(dir))\n\n  const date = new Date('2013-12-19T17:00:00.000Z')\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    fs.writeFileSync(dir + '/x', 'y')\n    fs.utimesSync(dir + '/x', date, date)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'x',\n      type: 'File',\n      size: 1,\n      mode: 0o751,\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'x',\n    '',\n    ''\n  ])\n\n  const check = t => {\n    const st = fs.lstatSync(dir + '/x')\n    t.equal(st.atime.toISOString(), date.toISOString())\n    t.equal(st.mtime.toISOString(), date.toISOString())\n    const data = fs.readFileSync(dir + '/x', 'utf8')\n    t.equal(data, 'y')\n    t.end()\n  }\n\n  t.test('async', t => {\n    new Unpack({\n      cwd: dir,\n      newer: true\n    }).on('close', _ => check(t)).end(data)\n  })\n\n  t.test('sync', t => {\n    new UnpackSync({\n      cwd: dir,\n      newer: true\n    }).end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('no mtime', t => {\n  const dir = path.join(unpackdir, 'skip-newer')\n  t.teardown(_ => rimraf.sync(dir))\n\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const date = new Date('2011-03-27T22:16:31.000Z')\n  const data = makeTar([\n    {\n      path: 'x/',\n      type: 'Directory',\n      size: 0,\n      atime: date,\n      ctime: date,\n      mtime: date\n    },\n    {\n      path: 'x/y',\n      type: 'File',\n      size: 1,\n      mode: 0o751,\n      atime: date,\n      ctime: date,\n      mtime: date\n    },\n    'x',\n    '',\n    ''\n  ])\n\n  const check = t => {\n    // this may fail if it's run on March 27, 2011\n    const stx = fs.lstatSync(dir + '/x')\n    t.notEqual(stx.atime.toISOString(), date.toISOString())\n    t.notEqual(stx.mtime.toISOString(), date.toISOString())\n    const sty = fs.lstatSync(dir + '/x/y')\n    t.notEqual(sty.atime.toISOString(), date.toISOString())\n    t.notEqual(sty.mtime.toISOString(), date.toISOString())\n    const data = fs.readFileSync(dir + '/x/y', 'utf8')\n    t.equal(data, 'x')\n    t.end()\n  }\n\n  t.test('async', t => {\n    new Unpack({\n      cwd: dir,\n      noMtime: true\n    }).on('close', _ => check(t)).end(data)\n  })\n\n  t.test('sync', t => {\n    new UnpackSync({\n      cwd: dir,\n      noMtime: true\n    }).end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('unpack big enough to pause/drain', t => {\n  const dir = path.resolve(unpackdir, 'drain-clog')\n  mkdirp.sync(dir)\n  t.tearDown(_ => rimraf.sync(dir))\n  const stream = fs.createReadStream(fixtures + '/parses.tar')\n  const u = new Unpack({\n    cwd: dir,\n    strip: 3,\n    strict: true\n  })\n\n  u.on('ignoredEntry', entry =>\n    t.fail('should not get ignored entry: ' + entry.path))\n\n  u.on('close', _ => {\n    t.pass('extraction finished')\n    const actual = fs.readdirSync(dir)\n    const expected = fs.readdirSync(parses)\n    t.same(actual, expected)\n    t.end()\n  })\n\n  stream.pipe(u)\n})\n\nt.test('set owner', t => {\n  // fake it on platforms that don't have getuid\n  const myUid = 501\n  const myGid = 1024\n  const getuid = process.getuid\n  const getgid = process.getgid\n  process.getuid = _ => myUid\n  process.getgid = _ => myGid\n  t.teardown(_ => (process.getuid = getuid, process.getgid = getgid))\n\n  // can't actually do this because it requires root, but we can\n  // verify that chown gets called.\n  t.test('as root, defaults to true', t => {\n    const getuid = process.getuid\n    process.getuid = _ => 0\n    const u = new Unpack()\n    t.equal(u.preserveOwner, true, 'preserveOwner enabled')\n    process.getuid = getuid\n    t.end()\n  })\n\n  t.test('as non-root, defaults to false', t => {\n    const getuid = process.getuid\n    process.getuid = _ => 501\n    const u = new Unpack()\n    t.equal(u.preserveOwner, false, 'preserveOwner disabled')\n    process.getuid = getuid\n    t.end()\n  })\n\n  const data = makeTar([\n    {\n      uid: 2456124561,\n      gid: 813708013,\n      path: 'foo/',\n      type: 'Directory'\n    },\n    {\n      uid: myUid,\n      gid: 813708013,\n      path: 'foo/my-uid-different-gid',\n      type: 'File',\n      size: 3\n    },\n    'qux',\n    {\n      uid: 2456124561,\n      path: 'foo/different-uid-nogid',\n      type: 'Directory'\n    },\n    {\n      uid: 2456124561,\n      path: 'foo/different-uid-nogid/bar',\n      type: 'File',\n      size: 3\n    },\n    'qux',\n    {\n      gid: 813708013,\n      path: 'foo/different-gid-nouid/bar',\n      type: 'File',\n      size: 3\n    },\n    'qux',\n    {\n      uid: myUid,\n      gid: myGid,\n      path: 'foo-mine/',\n      type: 'Directory'\n    },\n    {\n      uid: myUid,\n      gid: myGid,\n      path: 'foo-mine/bar',\n      type: 'File',\n      size: 3\n    },\n    'qux',\n    {\n      uid: myUid,\n      path: 'foo-mine/nogid',\n      type: 'Directory'\n    },\n    {\n      uid: myUid,\n      path: 'foo-mine/nogid/bar',\n      type: 'File',\n      size: 3\n    },\n    'qux',\n    '',\n    ''\n  ])\n\n  t.test('chown failure results in unpack failure', t => {\n    const dir = path.resolve(unpackdir, 'chown')\n    const poop = new Error('expected chown failure')\n    const un = mutateFS.fail('chown', poop)\n    const unf = mutateFS.fail('fchown', poop)\n\n    t.teardown(_ => (un(), unf()))\n\n    t.test('sync', t => {\n      mkdirp.sync(dir)\n      t.teardown(_ => rimraf.sync(dir))\n      let warned = false\n      const u = new Unpack.Sync({\n        cwd: dir,\n        preserveOwner: true,\n        onwarn: (m, er) => {\n          if (!warned) {\n            warned = true\n            t.equal(er, poop)\n            t.end()\n          }\n        }\n      })\n      u.end(data)\n    })\n\n    t.test('async', t => {\n      mkdirp.sync(dir)\n      t.teardown(_ => rimraf.sync(dir))\n      let warned = false\n      const u = new Unpack({\n        cwd: dir,\n        preserveOwner: true,\n        onwarn: (m, er) => {\n          if (!warned) {\n            warned = true\n            t.equal(er, poop)\n            t.end()\n          }\n        }\n      })\n      u.end(data)\n    })\n\n    t.test('cleanup', t => {\n      rimraf.sync(dir)\n      t.end()\n    })\n\n    t.end()\n  })\n\n  t.test('chown when true', t => {\n    const dir = path.resolve(unpackdir, 'chown')\n    const chown = fs.chown\n    const chownSync = fs.chownSync\n    const fchownSync = fs.fchownSync\n    let called = 0\n    fs.fchown = fs.chown = (path, owner, group, cb) => {\n      called ++\n      cb()\n    }\n    fs.chownSync = fs.fchownSync = _ => called++\n\n    t.teardown(_ => {\n      fs.chown = chown\n      fs.chownSync = chownSync\n      fs.fchownSync = fchownSync\n    })\n\n    t.test('sync', t => {\n      mkdirp.sync(dir)\n      t.teardown(_ => rimraf.sync(dir))\n      called = 0\n      const u = new Unpack.Sync({ cwd: dir, preserveOwner: true })\n      u.end(data)\n      t.ok(called >= 5, 'called chowns')\n      t.end()\n    })\n\n    t.test('async', t => {\n      mkdirp.sync(dir)\n      t.teardown(_ => rimraf.sync(dir))\n      called = 0\n      const u = new Unpack({ cwd: dir, preserveOwner: true })\n      u.end(data)\n      u.on('close', _ => {\n        t.ok(called >= 5, 'called chowns')\n        t.end()\n      })\n    })\n\n    t.end()\n  })\n\n  t.test('no chown when false', t => {\n    const dir = path.resolve(unpackdir, 'nochown')\n    const poop = new Error('poop')\n    const un = mutateFS.fail('chown', poop)\n    const unf = mutateFS.fail('fchown', poop)\n    t.teardown(_ => {\n      rimraf.sync(dir)\n      un()\n      unf()\n    })\n\n    t.beforeEach(cb => mkdirp(dir, cb))\n    t.afterEach(cb => rimraf(dir, cb))\n\n    const check = t => {\n      const dirStat = fs.statSync(dir + '/foo')\n      t.notEqual(dirStat.uid, 2456124561)\n      t.notEqual(dirStat.gid, 813708013)\n      const fileStat = fs.statSync(dir + '/foo/my-uid-different-gid')\n      t.notEqual(fileStat.uid, 2456124561)\n      t.notEqual(fileStat.gid, 813708013)\n      const dirStat2 = fs.statSync(dir + '/foo/different-uid-nogid')\n      t.notEqual(dirStat2.uid, 2456124561)\n      const fileStat2 = fs.statSync(dir + '/foo/different-uid-nogid/bar')\n      t.notEqual(fileStat2.uid, 2456124561)\n      t.end()\n    }\n\n    t.test('sync', t => {\n      const u = new Unpack.Sync({ cwd: dir, preserveOwner: false })\n      u.end(data)\n      check(t)\n    })\n\n    t.test('async', t => {\n      const u = new Unpack({ cwd: dir, preserveOwner: false })\n      u.end(data)\n      u.on('close', _ => check(t))\n    })\n\n    t.end()\n  })\n\n  t.end()\n})\n\nt.test('unpack when dir is not writable', t => {\n  const data = makeTar([\n    {\n      path: 'a/',\n      type: 'Directory',\n      mode: 0o444\n    },\n    {\n      path: 'a/b',\n      type: 'File',\n      size: 1\n    },\n    'a',\n    '',\n    ''\n  ])\n\n  const dir = path.resolve(unpackdir, 'nowrite-dir')\n  t.beforeEach(cb => mkdirp(dir, cb))\n  t.afterEach(cb => rimraf(dir, cb))\n\n  const check = t => {\n    t.equal(fs.statSync(dir + '/a').mode & 0o7777, 0o744)\n    t.equal(fs.readFileSync(dir + '/a/b', 'utf8'), 'a')\n    t.end()\n  }\n\n  t.test('sync', t => {\n    const u = new Unpack.Sync({ cwd: dir, strict: true })\n    u.end(data)\n    check(t)\n  })\n\n  t.test('async', t => {\n    const u = new Unpack({ cwd: dir, strict: true })\n    u.end(data)\n    u.on('close', _ => check(t))\n  })\n\n  t.end()\n})\n\nt.test('transmute chars on windows', t => {\n  const data = makeTar([\n    {\n      path: '<|>?:.txt',\n      size: 5,\n      type: 'File'\n    },\n    '<|>?:',\n    '',\n    ''\n  ])\n\n  const dir = path.resolve(unpackdir, 'winchars')\n  t.beforeEach(cb => mkdirp(dir, cb))\n  t.afterEach(cb => rimraf(dir, cb))\n\n  const hex = 'ef80bcef81bcef80beef80bfef80ba2e747874'\n  const uglyName = Buffer.from(hex, 'hex').toString()\n  const ugly = path.resolve(dir, uglyName)\n\n  const check = t => {\n    t.same(fs.readdirSync(dir), [ uglyName ])\n    t.equal(fs.readFileSync(ugly, 'utf8'), '<|>?:')\n    t.end()\n  }\n\n  t.test('async', t => {\n    const u = new Unpack({\n      cwd: dir,\n      win32: true\n    })\n    u.end(data)\n    u.on('close', _ => check(t))\n  })\n\n  t.test('sync', t => {\n    const u = new Unpack.Sync({\n      cwd: dir,\n      win32: true\n    })\n    u.end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('safely transmute chars on windows with absolutes', t => {\n  // don't actually make the directory\n  const poop = new Error('poop')\n  t.teardown(mutateFS.fail('mkdir', poop))\n\n  const data = makeTar([\n    {\n      path: 'c:/x/y/z/<|>?:.txt',\n      size: 5,\n      type: 'File'\n    },\n    '<|>?:',\n    '',\n    ''\n  ])\n\n  const hex = 'ef80bcef81bcef80beef80bfef80ba2e747874'\n  const uglyName = Buffer.from(hex, 'hex').toString()\n  const uglyPath = 'c:/x/y/z/' + uglyName\n\n  const u = new Unpack({\n    win32: true,\n    preservePaths: true\n  })\n  u.on('entry', entry => {\n    t.equal(entry.path, uglyPath)\n    t.end()\n  })\n\n  u.end(data)\n})\n\nt.test('use explicit chmod when required by umask', t => {\n  process.umask(0o022)\n\n  const basedir = path.resolve(unpackdir, 'umask-chmod')\n\n  const data = makeTar([\n    {\n      path: 'x/y/z',\n      mode: 0o775,\n      type: 'Directory'\n    },\n    '',\n    ''\n  ])\n\n  const check = t => {\n    const st = fs.statSync(basedir + '/x/y/z')\n    t.equal(st.mode & 0o777, 0o775)\n    rimraf.sync(basedir)\n    t.end()\n  }\n\n  t.test('async', t => {\n    mkdirp.sync(basedir)\n    const unpack = new Unpack({ cwd: basedir })\n    unpack.on('close', _ => check(t))\n    unpack.end(data)\n  })\n\n  return t.test('sync', t => {\n    mkdirp.sync(basedir)\n    const unpack = new Unpack.Sync({ cwd: basedir })\n    unpack.end(data)\n    check(t)\n  })\n})\n\nt.test('chown implicit dirs and also the entries', t => {\n  const basedir = path.resolve(unpackdir, 'chownr')\n\n  // club these so that the test can run as non-root\n  const chown = fs.chown\n  const chownSync = fs.chownSync\n\n  const getuid = process.getuid\n  const getgid = process.getgid\n  t.teardown(_ => {\n    fs.chown = chown\n    fs.chownSync = chownSync\n    process.getgid = getgid\n  })\n\n  let chowns = 0\n\n  let currentTest = null\n  fs.fchown = fs.chown = (path, uid, gid, cb) => {\n    currentTest.equal(uid, 420, 'chown(' + path + ') uid')\n    currentTest.equal(gid, 666, 'chown(' + path + ') gid')\n    chowns ++\n    cb()\n  }\n\n  fs.chownSync = fs.fchownSync = (path, uid, gid) => {\n    currentTest.equal(uid, 420, 'chownSync(' + path + ') uid')\n    currentTest.equal(gid, 666, 'chownSync(' + path + ') gid')\n    chowns ++\n  }\n\n  const data = makeTar([\n    {\n      path: 'a/b/c',\n      mode: 0o775,\n      type: 'File',\n      size: 1,\n      uid: null,\n      gid: null\n    },\n    '.',\n    {\n      path: 'x/y/z',\n      mode: 0o775,\n      uid: 12345,\n      gid: 54321,\n      type: 'File',\n      size: 1\n    },\n    '.',\n    '',\n    ''\n  ])\n\n  const check = t => {\n    currentTest = null\n    t.equal(chowns, 6)\n    chowns = 0\n    rimraf.sync(basedir)\n    t.end()\n  }\n\n  t.test('throws when setting uid/gid improperly', t => {\n    t.throws(_ => new Unpack({ uid: 420 }),\n      TypeError('cannot set owner without number uid and gid'))\n    t.throws(_ => new Unpack({ gid: 666 }),\n      TypeError('cannot set owner without number uid and gid'))\n    t.throws(_ => new Unpack({ uid: 1, gid: 2, preserveOwner: true }),\n      TypeError('cannot preserve owner in archive and also set owner explicitly'))\n    t.end()\n  })\n\n  const tests = () =>\n    t.test('async', t => {\n      currentTest = t\n      mkdirp.sync(basedir)\n      const unpack = new Unpack({ cwd: basedir, uid: 420, gid: 666 })\n      unpack.on('close', _ => check(t))\n      unpack.end(data)\n    }).then(t.test('sync', t => {\n      currentTest = t\n      mkdirp.sync(basedir)\n      const unpack = new Unpack.Sync({ cwd: basedir, uid: 420, gid: 666 })\n      unpack.end(data)\n      check(t)\n    }))\n\n  tests()\n\n  t.test('make it look like processUid is 420', t => {\n    process.getuid = () => 420\n    t.end()\n  })\n\n  tests()\n\n  t.test('make it look like processGid is 666', t => {\n    process.getuid = getuid\n    process.getgid = () => 666\n    t.end()\n  })\n\n  return tests()\n})\n\nt.test('bad cwd setting', t => {\n  const basedir = path.resolve(unpackdir, 'bad-cwd')\n  mkdirp.sync(basedir)\n  t.teardown(_ => rimraf.sync(basedir))\n\n  const cases = [\n    // the cwd itself\n    {\n      path: './',\n      type: 'Directory'\n    },\n    // a file directly in the cwd\n    {\n      path: 'a',\n      type: 'File'\n    },\n    // a file nested within a subdir of the cwd\n    {\n      path: 'a/b/c',\n      type: 'File'\n    }\n  ]\n\n  fs.writeFileSync(basedir + '/file', 'xyz')\n\n  cases.forEach(c => t.test(c.type + ' ' + c.path, t => {\n    const data = makeTar([\n      {\n        path: c.path,\n        mode: 0o775,\n        type: c.type,\n        size: 0,\n        uid: null,\n        gid: null\n      },\n      '',\n      ''\n    ])\n\n    t.test('cwd is a file', t => {\n      const cwd = basedir + '/file'\n      const opt = { cwd: cwd }\n\n      t.throws(_ => new Unpack.Sync(opt).end(data), {\n        name: 'CwdError',\n        message: 'ENOTDIR: Cannot cd into \\'' + cwd + '\\'',\n        path: cwd,\n        code: 'ENOTDIR'\n      })\n\n      new Unpack(opt).on('error', er => {\n        t.match(er, {\n          name: 'CwdError',\n          message: 'ENOTDIR: Cannot cd into \\'' + cwd + '\\'',\n          path: cwd,\n          code: 'ENOTDIR'\n        })\n        t.end()\n      }).end(data)\n    })\n\n    return t.test('cwd is missing', t => {\n      const cwd = basedir + '/asdf/asdf/asdf'\n      const opt = { cwd: cwd }\n\n      t.throws(_ => new Unpack.Sync(opt).end(data), {\n        name: 'CwdError',\n        message: 'ENOENT: Cannot cd into \\'' + cwd + '\\'',\n        path: cwd,\n        code: 'ENOENT'\n      })\n\n      new Unpack(opt).on('error', er => {\n        t.match(er, {\n          name: 'CwdError',\n          message: 'ENOENT: Cannot cd into \\'' + cwd + '\\'',\n          path: cwd,\n          code: 'ENOENT'\n        })\n        t.end()\n      }).end(data)\n    })\n  }))\n\n  t.end()\n})\n\nt.test('transform', t => {\n  const basedir = path.resolve(unpackdir, 'transform')\n  t.teardown(_ => rimraf.sync(basedir))\n\n  const cases = {\n    'emptypax.tar': {\n      '\ud83c\udf1f.txt': '\ud83c\udf1f\u2727\u2729\u2b50\ufe0e\u272a\u272b\u272c\u272d\u272e\u269d\u272f\u2730\u2735\u2736\u2737\u2738\u2739\u2742\u2b51\u2b52\u2605\u2606\u2721\u262a\u2734\ufe0e\u2726\u2721\ufe0f\ud83d\udd2f\u2734\ufe0f\ud83c\udf20\\n',\n      'one-byte.txt': '[a]'\n    },\n    'body-byte-counts.tar': {\n      '1024-bytes.txt': new Array(1024).join('[x]') + '[\\n]',\n      '512-bytes.txt': new Array(512).join('[x]') + '[\\n]',\n      'one-byte.txt': '[a]',\n      'zero-byte.txt': ''\n    },\n    'utf8.tar': {\n      '\ud83c\udf1f.txt': '\ud83c\udf1f\u2727\u2729\u2b50\ufe0e\u272a\u272b\u272c\u272d\u272e\u269d\u272f\u2730\u2735\u2736\u2737\u2738\u2739\u2742\u2b51\u2b52\u2605\u2606\u2721\u262a\u2734\ufe0e\u2726\u2721\ufe0f\ud83d\udd2f\u2734\ufe0f\ud83c\udf20\\n',\n      '\u03a9.txt': '[\u03a9]',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/\u03a9.txt': '[\u03a9]'\n    }\n  }\n\n  const txFn = entry => {\n    switch (path.basename(entry.path)) {\n      case 'zero-bytes.txt':\n        return entry\n\n      case 'one-byte.txt':\n      case '1024-bytes.txt':\n      case '512-bytes.txt':\n      case '\u03a9.txt':\n        return new Bracer()\n    }\n  }\n\n  class Bracer extends MiniPass {\n    write (data) {\n      const d = data.toString().split('').map(c => '[' + c + ']').join('')\n      return super.write(d)\n    }\n  }\n\n  const tarfiles = Object.keys(cases)\n  t.plan(tarfiles.length)\n  t.jobs = tarfiles.length\n\n  tarfiles.forEach(tarfile => {\n    t.test(tarfile, t => {\n      const tf = path.resolve(tars, tarfile)\n      const dir = path.resolve(basedir, tarfile)\n      t.beforeEach(cb => {\n        rimraf.sync(dir)\n        mkdirp.sync(dir)\n        cb()\n      })\n\n      const check = t => {\n        const expect = cases[tarfile]\n        Object.keys(expect).forEach(file => {\n          const f = path.resolve(dir, file)\n          t.equal(fs.readFileSync(f, 'utf8'), expect[file], file)\n        })\n        t.end()\n      }\n\n      t.plan(2)\n\n      t.test('async unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          const unpack = new Unpack({ cwd: dir, strict: true, transform: txFn })\n          fs.createReadStream(tf).pipe(unpack)\n          eos(unpack, _ => check(t))\n        })\n        t.test('loose', t => {\n          const unpack = new Unpack({ cwd: dir, transform: txFn })\n          fs.createReadStream(tf).pipe(unpack)\n          eos(unpack, _ => check(t))\n        })\n      })\n\n      t.test('sync unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          const unpack = new UnpackSync({ cwd: dir, transform: txFn })\n          unpack.end(fs.readFileSync(tf))\n          check(t)\n        })\n        t.test('loose', t => {\n          const unpack = new UnpackSync({ cwd: dir, transform: txFn })\n          unpack.end(fs.readFileSync(tf))\n          check(t)\n        })\n      })\n    })\n  })\n})\n\nt.test('futimes/fchown failures', t => {\n  const archive = path.resolve(tars, 'utf8.tar')\n  const dir = path.resolve(unpackdir, 'futimes-fchown-fails')\n  const tardata = fs.readFileSync(archive)\n\n  const poop = new Error('poop')\n  const second = new Error('second error')\n\n  const reset = cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n  }\n\n  reset()\n  t.teardown(() => rimraf.sync(dir))\n\n  const methods = ['utimes', 'chown']\n  methods.forEach(method => {\n    const fc = method === 'chown'\n    t.test(method +' fallback', t => {\n      t.teardown(mutateFS.fail('f' + method, poop))\n      // forceChown will fail on systems where the user is not root\n      // and/or the uid/gid in the archive aren't valid. We're just\n      // verifying coverage here, so make the method auto-pass.\n      t.teardown(mutateFS.pass(method))\n      t.plan(2)\n      t.test('async unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          reset()\n          const unpack = new Unpack({ cwd: dir, strict: true, forceChown: fc })\n          unpack.on('finish', t.end)\n          unpack.end(tardata)\n        })\n        t.test('loose', t => {\n          reset()\n          const unpack = new Unpack({ cwd: dir, forceChown: fc })\n          unpack.on('finish', t.end)\n          unpack.on('warn', t.fail)\n          unpack.end(tardata)\n        })\n      })\n      t.test('sync unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          reset()\n          const unpack = new Unpack.Sync({ cwd: dir, strict: true, forceChown: fc })\n          unpack.end(tardata)\n          t.end()\n        })\n        t.test('loose', t => {\n          reset()\n          const unpack = new Unpack.Sync({ cwd: dir, forceChown: fc })\n          unpack.on('warn', t.fail)\n          unpack.end(tardata)\n          t.end()\n        })\n      })\n    })\n\n    t.test('also fail ' + method, t => {\n      const unmutate = mutateFS.fail('f' + method, poop)\n      const unmutate2 = mutateFS.fail(method, second)\n      t.teardown(() => {\n        unmutate()\n        unmutate2()\n      })\n      t.plan(2)\n      t.test('async unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          reset()\n          const unpack = new Unpack({ cwd: dir, strict: true, forceChown: fc })\n          t.plan(3)\n          unpack.on('error', er => t.equal(er, poop))\n          unpack.end(tardata)\n        })\n        t.test('loose', t => {\n          reset()\n          const unpack = new Unpack({ cwd: dir, forceChown: fc })\n          t.plan(3)\n          unpack.on('warn', (m, er) => t.equal(er, poop))\n          unpack.end(tardata)\n        })\n      })\n      t.test('sync unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          reset()\n          const unpack = new Unpack.Sync({ cwd: dir, strict: true, forceChown: fc })\n          t.plan(3)\n          unpack.on('error', er => t.equal(er, poop))\n          unpack.end(tardata)\n        })\n        t.test('loose', t => {\n          reset()\n          const unpack = new Unpack.Sync({ cwd: dir, forceChown: fc })\n          t.plan(3)\n          unpack.on('warn', (m, er) => t.equal(er, poop))\n          unpack.end(tardata)\n        })\n      })\n    })\n  })\n\n  t.end()\n})\n\nt.test('onentry option is preserved', t => {\n  const basedir = path.resolve(unpackdir, 'onentry-method')\n  mkdirp.sync(basedir)\n  t.teardown(() => rimraf.sync(basedir))\n\n  let oecalls = 0\n  const onentry = entry => oecalls++\n  const data = makeTar([\n    {\n      path: 'd/i',\n      type: 'Directory'\n    },\n    {\n      path: 'd/i/r/dir',\n      type: 'Directory',\n      mode: 0o751,\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/file',\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'a',\n    '',\n    ''\n  ])\n\n  const check = t => {\n    t.equal(oecalls, 3)\n    oecalls = 0\n    t.end()\n  }\n\n  t.test('sync', t => {\n    const dir = path.join(basedir, 'sync')\n    mkdirp.sync(dir)\n    const unpack = new UnpackSync({ cwd: dir, onentry })\n    unpack.end(data)\n    check(t)\n  })\n\n  t.test('async', t => {\n    const dir = path.join(basedir, 'async')\n    mkdirp.sync(dir)\n    const unpack = new Unpack({ cwd: dir, onentry })\n    unpack.on('finish', () => check(t))\n    unpack.end(data)\n  })\n\n  t.end()\n})\n"], "fixing_code": ["'use strict'\n\nconst assert = require('assert')\nconst EE = require('events').EventEmitter\nconst Parser = require('./parse.js')\nconst fs = require('fs')\nconst fsm = require('fs-minipass')\nconst path = require('path')\nconst mkdir = require('./mkdir.js')\nconst mkdirSync = mkdir.sync\nconst wc = require('./winchars.js')\n\nconst ONENTRY = Symbol('onEntry')\nconst CHECKFS = Symbol('checkFs')\nconst ISREUSABLE = Symbol('isReusable')\nconst MAKEFS = Symbol('makeFs')\nconst FILE = Symbol('file')\nconst DIRECTORY = Symbol('directory')\nconst LINK = Symbol('link')\nconst SYMLINK = Symbol('symlink')\nconst HARDLINK = Symbol('hardlink')\nconst UNSUPPORTED = Symbol('unsupported')\nconst UNKNOWN = Symbol('unknown')\nconst CHECKPATH = Symbol('checkPath')\nconst MKDIR = Symbol('mkdir')\nconst ONERROR = Symbol('onError')\nconst PENDING = Symbol('pending')\nconst PEND = Symbol('pend')\nconst UNPEND = Symbol('unpend')\nconst ENDED = Symbol('ended')\nconst MAYBECLOSE = Symbol('maybeClose')\nconst SKIP = Symbol('skip')\nconst DOCHOWN = Symbol('doChown')\nconst UID = Symbol('uid')\nconst GID = Symbol('gid')\n\n// this.gid, entry.gid, this.processUid\nconst uint32 = (a, b, c) =>\n  a === a >>> 0 ? a\n  : b === b >>> 0 ? b\n  : c\n\nclass Unpack extends Parser {\n  constructor (opt) {\n    if (!opt)\n      opt = {}\n\n    opt.ondone = _ => {\n      this[ENDED] = true\n      this[MAYBECLOSE]()\n    }\n\n    super(opt)\n\n    this.transform = typeof opt.transform === 'function' ? opt.transform : null\n\n    this.writable = true\n    this.readable = false\n\n    this[PENDING] = 0\n    this[ENDED] = false\n\n    this.dirCache = opt.dirCache || new Map()\n\n    if (typeof opt.uid === 'number' || typeof opt.gid === 'number') {\n      // need both or neither\n      if (typeof opt.uid !== 'number' || typeof opt.gid !== 'number')\n        throw new TypeError('cannot set owner without number uid and gid')\n      if (opt.preserveOwner)\n        throw new TypeError(\n          'cannot preserve owner in archive and also set owner explicitly')\n      this.uid = opt.uid\n      this.gid = opt.gid\n      this.setOwner = true\n    } else {\n      this.uid = null\n      this.gid = null\n      this.setOwner = false\n    }\n\n    // default true for root\n    if (opt.preserveOwner === undefined && typeof opt.uid !== 'number')\n      this.preserveOwner = process.getuid && process.getuid() === 0\n    else\n      this.preserveOwner = !!opt.preserveOwner\n\n    this.processUid = (this.preserveOwner || this.setOwner) && process.getuid ?\n      process.getuid() : null\n    this.processGid = (this.preserveOwner || this.setOwner) && process.getgid ?\n      process.getgid() : null\n\n    // mostly just for testing, but useful in some cases.\n    // Forcibly trigger a chown on every entry, no matter what\n    this.forceChown = opt.forceChown === true\n\n    // turn ><?| in filenames into 0xf000-higher encoded forms\n    this.win32 = !!opt.win32 || process.platform === 'win32'\n\n    // do not unpack over files that are newer than what's in the archive\n    this.newer = !!opt.newer\n\n    // do not unpack over ANY files\n    this.keep = !!opt.keep\n\n    // do not set mtime/atime of extracted entries\n    this.noMtime = !!opt.noMtime\n\n    // allow .., absolute path entries, and unpacking through symlinks\n    // without this, warn and skip .., relativize absolutes, and error\n    // on symlinks in extraction path\n    this.preservePaths = !!opt.preservePaths\n\n    // unlink files and links before writing. This breaks existing hard\n    // links, and removes symlink directories rather than erroring\n    this.unlink = !!opt.unlink\n\n    this.cwd = path.resolve(opt.cwd || process.cwd())\n    this.strip = +opt.strip || 0\n    this.processUmask = process.umask()\n    this.umask = typeof opt.umask === 'number' ? opt.umask : this.processUmask\n    // default mode for dirs created as parents\n    this.dmode = opt.dmode || (0o0777 & (~this.umask))\n    this.fmode = opt.fmode || (0o0666 & (~this.umask))\n    this.on('entry', entry => this[ONENTRY](entry))\n  }\n\n  [MAYBECLOSE] () {\n    if (this[ENDED] && this[PENDING] === 0) {\n      this.emit('prefinish')\n      this.emit('finish')\n      this.emit('end')\n      this.emit('close')\n    }\n  }\n\n  [CHECKPATH] (entry) {\n    if (this.strip) {\n      const parts = entry.path.split(/\\/|\\\\/)\n      if (parts.length < this.strip)\n        return false\n      entry.path = parts.slice(this.strip).join('/')\n    }\n\n    if (!this.preservePaths) {\n      const p = entry.path\n      if (p.match(/(^|\\/|\\\\)\\.\\.(\\\\|\\/|$)/)) {\n        this.warn('path contains \\'..\\'', p)\n        return false\n      }\n\n      // absolutes on posix are also absolutes on win32\n      // so we only need to test this one to get both\n      if (path.win32.isAbsolute(p)) {\n        const parsed = path.win32.parse(p)\n        this.warn('stripping ' + parsed.root + ' from absolute path', p)\n        entry.path = p.substr(parsed.root.length)\n      }\n    }\n\n    // only encode : chars that aren't drive letter indicators\n    if (this.win32) {\n      const parsed = path.win32.parse(entry.path)\n      entry.path = parsed.root === '' ? wc.encode(entry.path)\n        : parsed.root + wc.encode(entry.path.substr(parsed.root.length))\n    }\n\n    if (path.isAbsolute(entry.path))\n      entry.absolute = entry.path\n    else\n      entry.absolute = path.resolve(this.cwd, entry.path)\n\n    return true\n  }\n\n  [ONENTRY] (entry) {\n    if (!this[CHECKPATH](entry))\n      return entry.resume()\n\n    assert.equal(typeof entry.absolute, 'string')\n\n    switch (entry.type) {\n      case 'Directory':\n      case 'GNUDumpDir':\n        if (entry.mode)\n          entry.mode = entry.mode | 0o700\n\n      case 'File':\n      case 'OldFile':\n      case 'ContiguousFile':\n      case 'Link':\n      case 'SymbolicLink':\n        return this[CHECKFS](entry)\n\n      case 'CharacterDevice':\n      case 'BlockDevice':\n      case 'FIFO':\n        return this[UNSUPPORTED](entry)\n    }\n  }\n\n  [ONERROR] (er, entry) {\n    // Cwd has to exist, or else nothing works. That's serious.\n    // Other errors are warnings, which raise the error in strict\n    // mode, but otherwise continue on.\n    if (er.name === 'CwdError')\n      this.emit('error', er)\n    else {\n      this.warn(er.message, er)\n      this[UNPEND]()\n      entry.resume()\n    }\n  }\n\n  [MKDIR] (dir, mode, cb) {\n    mkdir(dir, {\n      uid: this.uid,\n      gid: this.gid,\n      processUid: this.processUid,\n      processGid: this.processGid,\n      umask: this.processUmask,\n      preserve: this.preservePaths,\n      unlink: this.unlink,\n      cache: this.dirCache,\n      cwd: this.cwd,\n      mode: mode\n    }, cb)\n  }\n\n  [DOCHOWN] (entry) {\n    // in preserve owner mode, chown if the entry doesn't match process\n    // in set owner mode, chown if setting doesn't match process\n    return this.forceChown ||\n      this.preserveOwner &&\n      ( typeof entry.uid === 'number' && entry.uid !== this.processUid ||\n        typeof entry.gid === 'number' && entry.gid !== this.processGid )\n      ||\n      ( typeof this.uid === 'number' && this.uid !== this.processUid ||\n        typeof this.gid === 'number' && this.gid !== this.processGid )\n  }\n\n  [UID] (entry) {\n    return uint32(this.uid, entry.uid, this.processUid)\n  }\n\n  [GID] (entry) {\n    return uint32(this.gid, entry.gid, this.processGid)\n  }\n\n  [FILE] (entry) {\n    const mode = entry.mode & 0o7777 || this.fmode\n    const stream = new fsm.WriteStream(entry.absolute, {\n      mode: mode,\n      autoClose: false\n    })\n    stream.on('error', er => this[ONERROR](er, entry))\n\n    let actions = 1\n    const done = er => {\n      if (er)\n        return this[ONERROR](er, entry)\n\n      if (--actions === 0)\n        fs.close(stream.fd, _ => this[UNPEND]())\n    }\n\n    stream.on('finish', _ => {\n      // if futimes fails, try utimes\n      // if utimes fails, fail with the original error\n      // same for fchown/chown\n      const abs = entry.absolute\n      const fd = stream.fd\n\n      if (entry.mtime && !this.noMtime) {\n        actions++\n        const atime = entry.atime || new Date()\n        const mtime = entry.mtime\n        fs.futimes(fd, atime, mtime, er =>\n          er ? fs.utimes(abs, atime, mtime, er2 => done(er2 && er))\n          : done())\n      }\n\n      if (this[DOCHOWN](entry)) {\n        actions++\n        const uid = this[UID](entry)\n        const gid = this[GID](entry)\n        fs.fchown(fd, uid, gid, er =>\n          er ? fs.chown(abs, uid, gid, er2 => done(er2 && er))\n          : done())\n      }\n\n      done()\n    })\n\n    const tx = this.transform ? this.transform(entry) || entry : entry\n    if (tx !== entry)\n      entry.pipe(tx)\n    tx.pipe(stream)\n  }\n\n  [DIRECTORY] (entry) {\n    const mode = entry.mode & 0o7777 || this.dmode\n    this[MKDIR](entry.absolute, mode, er => {\n      if (er)\n        return this[ONERROR](er, entry)\n\n      let actions = 1\n      const done = _ => {\n        if (--actions === 0) {\n          this[UNPEND]()\n          entry.resume()\n        }\n      }\n\n      if (entry.mtime && !this.noMtime) {\n        actions++\n        fs.utimes(entry.absolute, entry.atime || new Date(), entry.mtime, done)\n      }\n\n      if (this[DOCHOWN](entry)) {\n        actions++\n        fs.chown(entry.absolute, this[UID](entry), this[GID](entry), done)\n      }\n\n      done()\n    })\n  }\n\n  [UNSUPPORTED] (entry) {\n    this.warn('unsupported entry type: ' + entry.type, entry)\n    entry.resume()\n  }\n\n  [SYMLINK] (entry) {\n    this[LINK](entry, entry.linkpath, 'symlink')\n  }\n\n  [HARDLINK] (entry) {\n    this[LINK](entry, path.resolve(this.cwd, entry.linkpath), 'link')\n  }\n\n  [PEND] () {\n    this[PENDING]++\n  }\n\n  [UNPEND] () {\n    this[PENDING]--\n    this[MAYBECLOSE]()\n  }\n\n  [SKIP] (entry) {\n    this[UNPEND]()\n    entry.resume()\n  }\n\n  // Check if we can reuse an existing filesystem entry safely and\n  // overwrite it, rather than unlinking and recreating\n  // Windows doesn't report a useful nlink, so we just never reuse entries\n  [ISREUSABLE] (entry, st) {\n    return entry.type === 'File' &&\n      !this.unlink &&\n      st.isFile() &&\n      st.nlink <= 1 &&\n      process.platform !== 'win32'\n  }\n\n  // check if a thing is there, and if so, try to clobber it\n  [CHECKFS] (entry) {\n    this[PEND]()\n    this[MKDIR](path.dirname(entry.absolute), this.dmode, er => {\n      if (er)\n        return this[ONERROR](er, entry)\n      fs.lstat(entry.absolute, (er, st) => {\n        if (st && (this.keep || this.newer && st.mtime > entry.mtime))\n          this[SKIP](entry)\n        else if (er || this[ISREUSABLE](entry, st))\n          this[MAKEFS](null, entry)\n        else if (st.isDirectory()) {\n          if (entry.type === 'Directory') {\n            if (!entry.mode || (st.mode & 0o7777) === entry.mode)\n              this[MAKEFS](null, entry)\n            else\n              fs.chmod(entry.absolute, entry.mode, er => this[MAKEFS](er, entry))\n          } else\n            fs.rmdir(entry.absolute, er => this[MAKEFS](er, entry))\n        } else\n          fs.unlink(entry.absolute, er => this[MAKEFS](er, entry))\n      })\n    })\n  }\n\n  [MAKEFS] (er, entry) {\n    if (er)\n      return this[ONERROR](er, entry)\n\n    switch (entry.type) {\n      case 'File':\n      case 'OldFile':\n      case 'ContiguousFile':\n        return this[FILE](entry)\n\n      case 'Link':\n        return this[HARDLINK](entry)\n\n      case 'SymbolicLink':\n        return this[SYMLINK](entry)\n\n      case 'Directory':\n      case 'GNUDumpDir':\n        return this[DIRECTORY](entry)\n    }\n  }\n\n  [LINK] (entry, linkpath, link) {\n    // XXX: get the type ('file' or 'dir') for windows\n    fs[link](linkpath, entry.absolute, er => {\n      if (er)\n        return this[ONERROR](er, entry)\n      this[UNPEND]()\n      entry.resume()\n    })\n  }\n}\n\nclass UnpackSync extends Unpack {\n  constructor (opt) {\n    super(opt)\n  }\n\n  [CHECKFS] (entry) {\n    const er = this[MKDIR](path.dirname(entry.absolute), this.dmode)\n    if (er)\n      return this[ONERROR](er, entry)\n    try {\n      const st = fs.lstatSync(entry.absolute)\n      if (this.keep || this.newer && st.mtime > entry.mtime)\n        return this[SKIP](entry)\n      else if (this[ISREUSABLE](entry, st))\n        return this[MAKEFS](null, entry)\n      else {\n        try {\n          if (st.isDirectory()) {\n            if (entry.type === 'Directory') {\n              if (entry.mode && (st.mode & 0o7777) !== entry.mode)\n                fs.chmodSync(entry.absolute, entry.mode)\n            } else\n              fs.rmdirSync(entry.absolute)\n          } else\n            fs.unlinkSync(entry.absolute)\n          return this[MAKEFS](null, entry)\n        } catch (er) {\n          return this[ONERROR](er, entry)\n        }\n      }\n    } catch (er) {\n      return this[MAKEFS](null, entry)\n    }\n  }\n\n  [FILE] (entry) {\n    const mode = entry.mode & 0o7777 || this.fmode\n\n    const oner = er => {\n      try { fs.closeSync(fd) } catch (_) {}\n      if (er)\n        this[ONERROR](er, entry)\n    }\n\n    let stream\n    let fd\n    try {\n      fd = fs.openSync(entry.absolute, 'w', mode)\n    } catch (er) {\n      return oner(er)\n    }\n    const tx = this.transform ? this.transform(entry) || entry : entry\n    if (tx !== entry)\n      entry.pipe(tx)\n\n    tx.on('data', chunk => {\n      try {\n        fs.writeSync(fd, chunk, 0, chunk.length)\n      } catch (er) {\n        oner(er)\n      }\n    })\n\n    tx.on('end', _ => {\n      let er = null\n      // try both, falling futimes back to utimes\n      // if either fails, handle the first error\n      if (entry.mtime && !this.noMtime) {\n        const atime = entry.atime || new Date()\n        const mtime = entry.mtime\n        try {\n          fs.futimesSync(fd, atime, mtime)\n        } catch (futimeser) {\n          try {\n            fs.utimesSync(entry.absolute, atime, mtime)\n          } catch (utimeser) {\n            er = futimeser\n          }\n        }\n      }\n\n      if (this[DOCHOWN](entry)) {\n        const uid = this[UID](entry)\n        const gid = this[GID](entry)\n\n        try {\n          fs.fchownSync(fd, uid, gid)\n        } catch (fchowner) {\n          try {\n            fs.chownSync(entry.absolute, uid, gid)\n          } catch (chowner) {\n            er = er || fchowner\n          }\n        }\n      }\n\n      oner(er)\n    })\n  }\n\n  [DIRECTORY] (entry) {\n    const mode = entry.mode & 0o7777 || this.dmode\n    const er = this[MKDIR](entry.absolute, mode)\n    if (er)\n      return this[ONERROR](er, entry)\n    if (entry.mtime && !this.noMtime) {\n      try {\n        fs.utimesSync(entry.absolute, entry.atime || new Date(), entry.mtime)\n      } catch (er) {}\n    }\n    if (this[DOCHOWN](entry)) {\n      try {\n        fs.chownSync(entry.absolute, this[UID](entry), this[GID](entry))\n      } catch (er) {}\n    }\n    entry.resume()\n  }\n\n  [MKDIR] (dir, mode) {\n    try {\n      return mkdir.sync(dir, {\n        uid: this.uid,\n        gid: this.gid,\n        processUid: this.processUid,\n        processGid: this.processGid,\n        umask: this.processUmask,\n        preserve: this.preservePaths,\n        unlink: this.unlink,\n        cache: this.dirCache,\n        cwd: this.cwd,\n        mode: mode\n      })\n    } catch (er) {\n      return er\n    }\n  }\n\n  [LINK] (entry, linkpath, link) {\n    try {\n      fs[link + 'Sync'](linkpath, entry.absolute)\n      entry.resume()\n    } catch (er) {\n      return this[ONERROR](er, entry)\n    }\n  }\n}\n\nUnpack.Sync = UnpackSync\nmodule.exports = Unpack\n", "'use strict'\n\nprocess.umask(0o022)\n\nconst Unpack = require('../lib/unpack.js')\nconst UnpackSync = Unpack.Sync\nconst t = require('tap')\nconst MiniPass = require('minipass')\n\nconst makeTar = require('./make-tar.js')\nconst Header = require('../lib/header.js')\nconst z = require('minizlib')\nconst fs = require('fs')\nconst path = require('path')\nconst fixtures = path.resolve(__dirname, 'fixtures')\nconst files = path.resolve(fixtures, 'files')\nconst tars = path.resolve(fixtures, 'tars')\nconst parses = path.resolve(fixtures, 'parse')\nconst unpackdir = path.resolve(fixtures, 'unpack')\nconst rimraf = require('rimraf')\nconst mkdirp = require('mkdirp')\nconst mutateFS = require('mutate-fs')\nconst eos = require('end-of-stream')\n\nt.teardown(_ => rimraf.sync(unpackdir))\n\nt.test('setup', t => {\n  rimraf.sync(unpackdir)\n  mkdirp.sync(unpackdir)\n  t.end()\n})\n\nt.test('basic file unpack tests', t => {\n  const basedir = path.resolve(unpackdir, 'basic')\n  t.teardown(_ => rimraf.sync(basedir))\n\n  const cases = {\n    'emptypax.tar': {\n      '\ud83c\udf1f.txt': '\ud83c\udf1f\u2727\u2729\u2b50\ufe0e\u272a\u272b\u272c\u272d\u272e\u269d\u272f\u2730\u2735\u2736\u2737\u2738\u2739\u2742\u2b51\u2b52\u2605\u2606\u2721\u262a\u2734\ufe0e\u2726\u2721\ufe0f\ud83d\udd2f\u2734\ufe0f\ud83c\udf20\\n',\n      'one-byte.txt': 'a'\n    },\n    'body-byte-counts.tar': {\n      '1024-bytes.txt': new Array(1024).join('x') + '\\n',\n      '512-bytes.txt': new Array(512).join('x') + '\\n',\n      'one-byte.txt': 'a',\n      'zero-byte.txt': ''\n    },\n    'utf8.tar': {\n      '\ud83c\udf1f.txt': '\ud83c\udf1f\u2727\u2729\u2b50\ufe0e\u272a\u272b\u272c\u272d\u272e\u269d\u272f\u2730\u2735\u2736\u2737\u2738\u2739\u2742\u2b51\u2b52\u2605\u2606\u2721\u262a\u2734\ufe0e\u2726\u2721\ufe0f\ud83d\udd2f\u2734\ufe0f\ud83c\udf20\\n',\n      '\u03a9.txt': '\u03a9',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/\u03a9.txt': '\u03a9'\n    },\n    'file.tar': {\n      'one-byte.txt': 'a'\n    },\n    'global-header.tar': {\n      'one-byte.txt': 'a'\n    },\n    'long-pax.tar': {\n      '120-byte-filename-cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n    },\n    'long-paths.tar': {\n      '100-byte-filename-cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      '120-byte-filename-cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      '170-byte-filename-cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/a.txt': 'short\\n',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/\u03a9.txt': '\u03a9'\n    }\n  }\n\n  const tarfiles = Object.keys(cases)\n  t.plan(tarfiles.length)\n  t.jobs = tarfiles.length\n\n  tarfiles.forEach(tarfile => {\n    t.test(tarfile, t => {\n      const tf = path.resolve(tars, tarfile)\n      const dir = path.resolve(basedir, tarfile)\n      t.beforeEach(cb => {\n        rimraf.sync(dir)\n        mkdirp.sync(dir)\n        cb()\n      })\n\n      const check = t => {\n        const expect = cases[tarfile]\n        Object.keys(expect).forEach(file => {\n          const f = path.resolve(dir, file)\n          t.equal(fs.readFileSync(f, 'utf8'), expect[file], file)\n        })\n        t.end()\n      }\n\n      t.plan(2)\n\n      t.test('async unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          const unpack = new Unpack({ cwd: dir, strict: true })\n          fs.createReadStream(tf).pipe(unpack)\n          eos(unpack, _ => check(t))\n        })\n        t.test('loose', t => {\n          const unpack = new Unpack({ cwd: dir })\n          fs.createReadStream(tf).pipe(unpack)\n          eos(unpack, _ => check(t))\n        })\n      })\n\n      t.test('sync unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          const unpack = new UnpackSync({ cwd: dir })\n          unpack.end(fs.readFileSync(tf))\n          check(t)\n        })\n        t.test('loose', t => {\n          const unpack = new UnpackSync({ cwd: dir })\n          unpack.end(fs.readFileSync(tf))\n          check(t)\n        })\n      })\n    })\n  })\n})\n\nt.test('cwd default to process cwd', t => {\n  const u = new Unpack()\n  const us = new UnpackSync()\n  const cwd = process.cwd()\n  t.equal(u.cwd, cwd)\n  t.equal(us.cwd, cwd)\n  t.end()\n})\n\nt.test('links!', t => {\n  const dir = path.resolve(unpackdir, 'links')\n  const data = fs.readFileSync(tars + '/links.tar')\n\n  t.plan(2)\n  t.beforeEach(cb => mkdirp(dir, cb))\n  t.afterEach(cb => rimraf(dir, cb))\n\n  const check = t => {\n    const hl1 = fs.lstatSync(dir + '/hardlink-1')\n    const hl2 = fs.lstatSync(dir + '/hardlink-2')\n    t.equal(hl1.dev, hl2.dev)\n    t.equal(hl1.ino, hl2.ino)\n    t.equal(hl1.nlink, 2)\n    t.equal(hl2.nlink, 2)\n    const sym = fs.lstatSync(dir + '/symlink')\n    t.ok(sym.isSymbolicLink())\n    t.equal(fs.readlinkSync(dir + '/symlink'), 'hardlink-2')\n    t.end()\n  }\n\n  t.test('async', t => {\n    const unpack = new Unpack({ cwd: dir })\n    let finished = false\n    unpack.on('finish', _ => finished = true)\n    unpack.on('close', _ => t.ok(finished, 'emitted finish before close'))\n    unpack.on('close', _ => check(t))\n    unpack.end(data)\n  })\n\n  t.test('sync', t => {\n    const unpack = new UnpackSync({ cwd: dir })\n    unpack.end(data)\n    check(t)\n  })\n})\n\nt.test('links without cleanup (exercise clobbering code)', t => {\n  const dir = path.resolve(unpackdir, 'links')\n  const data = fs.readFileSync(tars + '/links.tar')\n\n  t.plan(6)\n  mkdirp.sync(dir)\n  t.teardown(_ => rimraf.sync(dir))\n\n  t.beforeEach(cb => {\n    // clobber this junk\n    try {\n      mkdirp.sync(dir + '/hardlink-1')\n      mkdirp.sync(dir + '/hardlink-2')\n      fs.writeFileSync(dir + '/symlink', 'not a symlink')\n    } catch (er) {}\n    cb()\n  })\n\n  const check = t => {\n    const hl1 = fs.lstatSync(dir + '/hardlink-1')\n    const hl2 = fs.lstatSync(dir + '/hardlink-2')\n    t.equal(hl1.dev, hl2.dev)\n    t.equal(hl1.ino, hl2.ino)\n    t.equal(hl1.nlink, 2)\n    t.equal(hl2.nlink, 2)\n    const sym = fs.lstatSync(dir + '/symlink')\n    t.ok(sym.isSymbolicLink())\n    t.equal(fs.readlinkSync(dir + '/symlink'), 'hardlink-2')\n    t.end()\n  }\n\n  t.test('async', t => {\n    const unpack = new Unpack({ cwd: dir })\n    let prefinished = false\n    unpack.on('prefinish', _ => prefinished = true)\n    unpack.on('finish', _ =>\n      t.ok(prefinished, 'emitted prefinish before finish'))\n    unpack.on('close', _ => check(t))\n    unpack.end(data)\n  })\n\n  t.test('sync', t => {\n    const unpack = new UnpackSync({ cwd: dir })\n    unpack.end(data)\n    check(t)\n  })\n\n  t.test('async again', t => {\n    const unpack = new Unpack({ cwd: dir })\n    eos(unpack, _ => check(t))\n    unpack.end(data)\n  })\n\n  t.test('sync again', t => {\n    const unpack = new UnpackSync({ cwd: dir })\n    unpack.end(data)\n    check(t)\n  })\n\n  t.test('async unlink', t => {\n    const unpack = new Unpack({ cwd: dir, unlink: true })\n    unpack.on('close', _ => check(t))\n    unpack.end(data)\n  })\n\n  t.test('sync unlink', t => {\n    const unpack = new UnpackSync({ cwd: dir, unlink: true })\n    unpack.end(data)\n    check(t)\n  })\n})\n\nt.test('nested dir dupe', t => {\n  const dir = path.resolve(unpackdir, 'nested-dir')\n  mkdirp.sync(dir + '/d/e/e/p')\n  t.teardown(_ => rimraf.sync(dir))\n  const expect = {\n    'd/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/a.txt': 'short\\n',\n    'd/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n    'd/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n    'd/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc': 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n    'd/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/\u03a9.txt': '\u03a9'\n  }\n\n  const check = t => {\n    const entries = fs.readdirSync(dir)\n    t.equal(entries.length, 1)\n    t.equal(entries[0], 'd')\n    Object.keys(expect).forEach(f => {\n      const file = dir + '/' + f\n      t.equal(fs.readFileSync(file, 'utf8'), expect[f])\n    })\n    t.end()\n  }\n\n  const unpack = new Unpack({ cwd: dir, strip: 8 })\n  const data = fs.readFileSync(tars + '/long-paths.tar')\n  // while we're at it, why not use gzip too?\n  const zip = new z.Gzip()\n  zip.pipe(unpack)\n  unpack.on('close', _ => check(t))\n  zip.end(data)\n})\n\nt.test('symlink in dir path', t => {\n  const dir = path.resolve(unpackdir, 'symlink-junk')\n\n  t.teardown(_ => rimraf.sync(dir))\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'd/i',\n      type: 'Directory'\n    },\n    {\n      path: 'd/i/r/dir',\n      type: 'Directory',\n      mode: 0o751,\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/file',\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'a',\n    {\n      path: 'd/i/r/link',\n      type: 'Link',\n      linkpath: 'd/i/r/file',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/symlink',\n      type: 'SymbolicLink',\n      linkpath: './dir',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/symlink/x',\n      type: 'File',\n      size: 0,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    '',\n    ''\n  ])\n\n  t.test('no clobbering', t => {\n    const warnings = []\n    const u = new Unpack({ cwd: dir, onwarn: (w,d) => warnings.push([w,d]) })\n    u.on('close', _ => {\n      t.equal(fs.lstatSync(dir + '/d/i').mode & 0o7777, 0o755)\n      t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n      t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n      t.throws(_ => fs.statSync(dir + '/d/i/r/symlink/x'))\n      t.equal(warnings.length, 1)\n      t.equal(warnings[0][0], 'Cannot extract through symbolic link')\n      t.match(warnings[0][1], {\n        name: 'SylinkError',\n        path: dir + '/d/i/r/symlink/',\n        symlink: dir + '/d/i/r/symlink'\n      })\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('no clobbering, sync', t => {\n    const warnings = []\n    const u = new UnpackSync({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d])\n    })\n    u.end(data)\n    t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n    t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n    t.throws(_ => fs.statSync(dir + '/d/i/r/symlink/x'))\n    t.equal(warnings.length, 1)\n    t.equal(warnings[0][0], 'Cannot extract through symbolic link')\n    t.match(warnings[0][1], {\n      name: 'SylinkError',\n      path: dir + '/d/i/r/symlink/',\n      symlink: dir + '/d/i/r/symlink'\n    })\n    t.end()\n  })\n\n  t.test('extract through symlink', t => {\n    const warnings = []\n    const u = new Unpack({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d]),\n      preservePaths: true\n    })\n    u.on('close', _ => {\n      t.same(warnings, [])\n      t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n      t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n      t.ok(fs.lstatSync(dir + '/d/i/r/dir/x').isFile(), 'x thru link')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink/x').isFile(), 'x thru link')\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('extract through symlink sync', t => {\n    const warnings = []\n    const u = new UnpackSync({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d]),\n      preservePaths: true\n    })\n    u.end(data)\n    t.same(warnings, [])\n    t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n    t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n    t.ok(fs.lstatSync(dir + '/d/i/r/dir/x').isFile(), 'x thru link')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink/x').isFile(), 'x thru link')\n    t.end()\n  })\n\n  t.test('clobber through symlink', t => {\n    const warnings = []\n    const u = new Unpack({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d]),\n      unlink: true\n    })\n    u.on('close', _ => {\n      t.same(warnings, [])\n      t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n      t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n      t.notok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'no link')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isDirectory(), 'sym is dir')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink/x').isFile(), 'x thru link')\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('clobber through symlink with busted unlink', t => {\n    const poop = new Error('poop')\n    t.teardown(mutateFS.fail('unlink', poop))\n    const warnings = []\n    const u = new Unpack({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d]),\n      unlink: true\n    })\n    u.on('close', _ => {\n      t.same(warnings, [[ 'poop', poop ]])\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('clobber through symlink sync', t => {\n    const warnings = []\n    const u = new UnpackSync({\n      cwd: dir,\n      onwarn: (w,d) => warnings.push([w,d]),\n      unlink: true\n    })\n    u.end(data)\n    t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n    t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n    t.notok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'no link')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isDirectory(), 'sym is dir')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink/x').isFile(), 'x thru link')\n    t.end()\n  })\n\n  t.test('clobber dirs', t => {\n    mkdirp.sync(dir + '/d/i/r/dir')\n    mkdirp.sync(dir + '/d/i/r/file')\n    mkdirp.sync(dir + '/d/i/r/link')\n    mkdirp.sync(dir + '/d/i/r/symlink')\n    const warnings = []\n    const u = new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => {\n        warnings.push([w,d])\n      }\n    })\n    u.on('close', _ => {\n      t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n      t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n      t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n      t.throws(_ => fs.statSync(dir + '/d/i/r/symlink/x'))\n      t.equal(warnings.length, 1)\n      t.equal(warnings[0][0], 'Cannot extract through symbolic link')\n      t.match(warnings[0][1], {\n        name: 'SylinkError',\n        path: dir + '/d/i/r/symlink/',\n        symlink: dir + '/d/i/r/symlink'\n      })\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('clobber dirs sync', t => {\n    mkdirp.sync(dir + '/d/i/r/dir')\n    mkdirp.sync(dir + '/d/i/r/file')\n    mkdirp.sync(dir + '/d/i/r/link')\n    mkdirp.sync(dir + '/d/i/r/symlink')\n    const warnings = []\n    const u = new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => {\n        warnings.push([w,d])\n      }\n    })\n    u.end(data)\n    t.equal(fs.lstatSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n    t.ok(fs.lstatSync(dir + '/d/i/r/file').isFile(), 'got file')\n    t.ok(fs.lstatSync(dir + '/d/i/r/symlink').isSymbolicLink(), 'got symlink')\n    t.throws(_ => fs.statSync(dir + '/d/i/r/symlink/x'))\n    t.equal(warnings.length, 1)\n    t.equal(warnings[0][0], 'Cannot extract through symbolic link')\n    t.match(warnings[0][1], {\n      name: 'SylinkError',\n      path: dir + '/d/i/r/symlink/',\n      symlink: dir + '/d/i/r/symlink'\n    })\n    t.end()\n  })\n\n  t.end()\n})\n\nt.test('unsupported entries', t => {\n  const dir = path.resolve(unpackdir, 'unsupported-entries')\n  mkdirp.sync(dir)\n  t.teardown(_ => rimraf.sync(dir))\n  const unknown = new Header({ path: 'qux', type: 'File', size: 4 })\n  unknown.type = 'Z'\n  unknown.encode()\n  const data = makeTar([\n    {\n      path: 'dev/random',\n      type: 'CharacterDevice'\n    },\n    {\n      path: 'dev/hd0',\n      type: 'BlockDevice'\n    },\n    {\n      path: 'dev/fifo0',\n      type: 'FIFO'\n    },\n    unknown.block,\n    'asdf',\n    '',\n    ''\n  ])\n\n  t.test('basic, warns', t => {\n    const warnings = []\n    const u = new Unpack({ cwd: dir, onwarn: (w,d) => warnings.push([w,d]) })\n    const expect = [\n      ['unsupported entry type: CharacterDevice', { path: 'dev/random' }],\n      ['unsupported entry type: BlockDevice', { path: 'dev/hd0' }],\n      ['unsupported entry type: FIFO', { path: 'dev/fifo0' }]\n    ]\n    u.on('close', _ => {\n      t.equal(fs.readdirSync(dir).length, 0)\n      t.match(warnings, expect)\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.test('strict, throws', t => {\n    const warnings = []\n    const errors = []\n    const u = new Unpack({\n      cwd: dir,\n      strict: true,\n      onwarn: (w,d) => warnings.push([w,d])\n    })\n    u.on('error', e => errors.push(e))\n    u.on('close', _ => {\n      t.equal(fs.readdirSync(dir).length, 0)\n      t.same(warnings, [])\n      t.match(errors, [\n        {\n          message: 'unsupported entry type: CharacterDevice',\n          data: { path: 'dev/random' }\n        },\n        {\n          message: 'unsupported entry type: BlockDevice',\n          data: { path: 'dev/hd0' }\n        },\n        {\n          message: 'unsupported entry type: FIFO',\n          data: { path: 'dev/fifo0' }\n        }\n      ])\n      t.end()\n    })\n    u.end(data)\n  })\n\n  t.end()\n})\n\n\nt.test('file in dir path', t => {\n  const dir = path.resolve(unpackdir, 'file-junk')\n\n  t.teardown(_ => rimraf.sync(dir))\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'd/i/r/file',\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'a',\n    {\n      path: 'd/i/r/file/a/b/c',\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'b',\n    '',\n    ''\n  ])\n\n  t.test('fail because of file', t => {\n    const check = t => {\n      t.equal(fs.readFileSync(dir + '/d/i/r/file', 'utf8'), 'a')\n      t.throws(_ => fs.statSync(dir + '/d/i/r/file/a/b/c'))\n      t.end()\n    }\n\n    t.plan(2)\n\n    t.test('async', t => {\n      new Unpack({ cwd: dir }).on('close', _ => check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      new UnpackSync({ cwd: dir }).end(data)\n      check(t)\n    })\n  })\n\n  t.test('clobber on through', t => {\n    const check = t => {\n      t.ok(fs.statSync(dir + '/d/i/r/file').isDirectory())\n      t.equal(fs.readFileSync(dir + '/d/i/r/file/a/b/c', 'utf8'), 'b')\n      t.end()\n    }\n\n    t.plan(2)\n\n    t.test('async', t => {\n      new Unpack({ cwd: dir, unlink: true }).on('close', _ => check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      new UnpackSync({ cwd: dir, unlink: true }).end(data)\n      check(t)\n    })\n  })\n\n  t.end()\n})\n\nt.test('set umask option', t => {\n  const dir = path.resolve(unpackdir, 'umask')\n  mkdirp.sync(dir)\n  t.tearDown(_ => rimraf.sync(dir))\n\n  const data = makeTar([\n    {\n      path: 'd/i/r/dir',\n      type: 'Directory',\n      mode: 0o751\n    },\n    '',\n    ''\n  ])\n\n  new Unpack({\n    umask: 0o027,\n    cwd: dir\n  }).on('close', _ => {\n    t.equal(fs.statSync(dir + '/d/i/r').mode & 0o7777, 0o750)\n    t.equal(fs.statSync(dir + '/d/i/r/dir').mode & 0o7777, 0o751)\n    t.end()\n  }).end(data)\n})\n\nt.test('absolute paths', t => {\n  const dir = path.join(unpackdir, 'absolute-paths')\n  t.teardown(_ => rimraf.sync(dir))\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const absolute = path.resolve(dir, 'd/i/r/absolute')\n  t.ok(path.isAbsolute(absolute))\n  const parsed = path.parse(absolute)\n  const relative = absolute.substr(parsed.root.length)\n  t.notOk(path.isAbsolute(relative))\n\n  const data = makeTar([\n    {\n      path: absolute,\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'a',\n    '',\n    ''\n  ])\n\n  t.test('warn and correct', t => {\n    const check = t => {\n      t.same(warnings, [[\n        'stripping / from absolute path',\n        absolute\n      ]])\n      t.ok(fs.lstatSync(path.resolve(dir, relative)).isFile(), 'is file')\n      t.end()\n    }\n\n    const warnings = []\n\n    t.test('async', t => {\n      warnings.length = 0\n      new Unpack({\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).on('close', _=> check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      warnings.length = 0\n      new UnpackSync({\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).end(data)\n      check(t)\n    })\n\n    t.end()\n  })\n\n  t.test('preserve absolute path', t => {\n    const check = t => {\n      t.same(warnings, [])\n      t.ok(fs.lstatSync(absolute).isFile(), 'is file')\n      t.end()\n    }\n\n    const warnings = []\n\n    t.test('async', t => {\n      warnings.length = 0\n      new Unpack({\n        preservePaths: true,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).on('close', _=> check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      warnings.length = 0\n      new UnpackSync({\n        preservePaths: true,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).end(data)\n      check(t)\n    })\n\n    t.end()\n  })\n\n  t.end()\n})\n\nt.test('.. paths', t => {\n  const dir = path.join(unpackdir, 'dotted-paths')\n  t.teardown(_ => rimraf.sync(dir))\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const fmode = 0o755\n  const dotted = 'a/b/c/../d'\n  const resolved = path.resolve(dir, dotted)\n\n  const data = makeTar([\n    {\n      path: dotted,\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'd',\n    '',\n    ''\n  ])\n\n  t.test('warn and skip', t => {\n    const check = t => {\n      t.same(warnings, [[\n        'path contains \\'..\\'',\n        dotted\n      ]])\n      t.throws(_=>fs.lstatSync(resolved))\n      t.end()\n    }\n\n    const warnings = []\n\n    t.test('async', t => {\n      warnings.length = 0\n      new Unpack({\n        fmode: fmode,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).on('close', _=> check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      warnings.length = 0\n      new UnpackSync({\n        fmode: fmode,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).end(data)\n      check(t)\n    })\n\n    t.end()\n  })\n\n  t.test('preserve dotted path', t => {\n    const check = t => {\n      t.same(warnings, [])\n      t.ok(fs.lstatSync(resolved).isFile(), 'is file')\n      t.equal(fs.lstatSync(resolved).mode & 0o777, fmode, 'mode is 0755')\n      t.end()\n    }\n\n    const warnings = []\n\n    t.test('async', t => {\n      warnings.length = 0\n      new Unpack({\n        fmode: fmode,\n        preservePaths: true,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).on('close', _=> check(t)).end(data)\n    })\n\n    t.test('sync', t => {\n      warnings.length = 0\n      new UnpackSync({\n        fmode: fmode,\n        preservePaths: true,\n        cwd: dir,\n        onwarn: (w, d) => warnings.push([w, d])\n      }).end(data)\n      check(t)\n    })\n\n    t.end()\n  })\n\n  t.end()\n})\n\nt.test('fail all stats', t => {\n  const poop = new Error('poop')\n  poop.code = 'EPOOP'\n  let unmutate\n  const dir = path.join(unpackdir, 'stat-fail')\n\n  const warnings = []\n  t.beforeEach(cb => {\n    warnings.length = 0\n    mkdirp.sync(dir)\n    unmutate = mutateFS.statFail(poop)\n    cb()\n  })\n  t.afterEach(cb => {\n    unmutate()\n    rimraf.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'd/i/r/file/',\n      type: 'Directory',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/dir/',\n      type: 'Directory',\n      mode: 0o751,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/file',\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'a',\n    {\n      path: 'd/i/r/link',\n      type: 'Link',\n      linkpath: 'd/i/r/file',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/symlink',\n      type: 'SymbolicLink',\n      linkpath: './dir',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    '',\n    ''\n  ])\n\n  const check = (t, expect) => {\n    t.match(warnings, expect)\n    warnings.forEach(w => t.equal(w[0], w[1].message))\n    t.end()\n  }\n\n  t.test('async', t => {\n    const expect = [\n      ['poop', poop],\n      ['poop', poop]\n    ]\n    new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).on('close', _ => check(t, expect)).end(data)\n  })\n\n  t.test('sync', t => {\n    const expect = [\n      [\n        String,\n        {\n          code: 'EISDIR',\n          path: path.resolve(dir, 'd/i/r/file'),\n          syscall: 'open'\n        }\n      ],\n      [\n        String,\n        {\n          dest: path.resolve(dir, 'd/i/r/link'),\n          path: path.resolve(dir, 'd/i/r/file'),\n          syscall: 'link'\n        }\n      ]\n    ]\n    new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).end(data)\n    check(t, expect)\n  })\n\n  t.end()\n})\n\nt.test('fail symlink', t => {\n  const poop = new Error('poop')\n  poop.code = 'EPOOP'\n  const unmutate = mutateFS.fail('symlink', poop)\n  const dir = path.join(unpackdir, 'symlink-fail')\n  t.teardown(_ => (unmutate(), rimraf.sync(dir)))\n\n  const warnings = []\n  t.beforeEach(cb => {\n    warnings.length = 0\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'd/i/r/dir/',\n      type: 'Directory',\n      mode: 0o751,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/symlink',\n      type: 'SymbolicLink',\n      linkpath: './dir',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    '',\n    ''\n  ])\n\n  const check = (t, expect) => {\n    t.match(warnings, expect)\n    warnings.forEach(w => t.equal(w[0], w[1].message))\n    t.end()\n  }\n\n  t.test('async', t => {\n    const expect = [['poop', poop]]\n    new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).on('close', _ => check(t, expect)).end(data)\n  })\n\n  t.test('sync', t => {\n    const expect = [['poop', poop]]\n    new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).end(data)\n    check(t, expect)\n  })\n\n  t.end()\n})\n\nt.test('fail chmod', t => {\n  const poop = new Error('poop')\n  poop.code = 'EPOOP'\n  const unmutate = mutateFS.fail('chmod', poop)\n  const dir = path.join(unpackdir, 'chmod-fail')\n  t.teardown(_ => (unmutate(), rimraf.sync(dir)))\n\n  const warnings = []\n  t.beforeEach(cb => {\n    warnings.length = 0\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'd/i/r/dir/',\n      type: 'Directory',\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/dir/',\n      type: 'Directory',\n      mode: 0o751,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    '',\n    ''\n  ])\n\n  const check = (t, expect) => {\n    t.match(warnings, expect)\n    warnings.forEach(w => t.equal(w[0], w[1].message))\n    t.end()\n  }\n\n  t.test('async', t => {\n    const expect = [['poop', poop]]\n    new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).on('close', _ => check(t, expect)).end(data)\n  })\n\n  t.test('sync', t => {\n    const expect = [['poop', poop]]\n    new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).end(data)\n    check(t, expect)\n  })\n\n  t.end()\n})\n\nt.test('fail mkdir', t => {\n  const poop = new Error('poop')\n  poop.code = 'EPOOP'\n  let unmutate\n  const dir = path.join(unpackdir, 'mkdir-fail')\n  t.teardown(_ => rimraf.sync(dir))\n\n  const warnings = []\n  t.beforeEach(cb => {\n    warnings.length = 0\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    unmutate = mutateFS.fail('mkdir', poop)\n    cb()\n  })\n  t.afterEach(cb => {\n    unmutate()\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'dir/',\n      type: 'Directory',\n      mode: 0o751,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z'),\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    '',\n    ''\n  ])\n\n  const expect = [ [\n    'ENOENT: no such file or directory, lstat \\'' +\n    path.resolve(dir, 'dir') + '\\'',\n    {\n      code: 'ENOENT',\n      syscall: 'lstat',\n      path: path.resolve(dir, 'dir')\n    }\n  ] ]\n\n  const check = t => {\n    t.match(warnings, expect)\n    warnings.forEach(w => t.equal(w[0], w[1].message))\n    t.end()\n  }\n\n  t.test('async', t => {\n    new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).on('close', _ => check(t)).end(data)\n  })\n\n  t.test('sync', t => {\n    new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('fail write', t => {\n  const poop = new Error('poop')\n  poop.code = 'EPOOP'\n  const unmutate = mutateFS.fail('write', poop)\n  const dir = path.join(unpackdir, 'write-fail')\n  t.teardown(_ => (unmutate(), rimraf.sync(dir)))\n\n  const warnings = []\n  t.beforeEach(cb => {\n    warnings.length = 0\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'x',\n      type: 'File',\n      size: 1,\n      mode: 0o751,\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'x',\n    '',\n    ''\n  ])\n\n  const expect = [ [ 'poop', poop ] ]\n\n  const check = t => {\n    t.match(warnings, expect)\n    warnings.forEach(w => t.equal(w[0], w[1].message))\n    t.end()\n  }\n\n  t.test('async', t => {\n    new Unpack({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).on('close', _ => check(t)).end(data)\n  })\n\n  t.test('sync', t => {\n    new UnpackSync({\n      cwd: dir,\n      onwarn: (w, d) => warnings.push([w, d])\n    }).end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('skip existing', t => {\n  const dir = path.join(unpackdir, 'skip-newer')\n  t.teardown(_ => rimraf.sync(dir))\n\n  const date = new Date('2011-03-27T22:16:31.000Z')\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    fs.writeFileSync(dir + '/x', 'y')\n    fs.utimesSync(dir + '/x', date, date)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'x',\n      type: 'File',\n      size: 1,\n      mode: 0o751,\n      mtime: new Date('2013-12-19T17:00:00.000Z')\n    },\n    'x',\n    '',\n    ''\n  ])\n\n  const check = t => {\n    const st = fs.lstatSync(dir + '/x')\n    t.equal(st.atime.toISOString(), date.toISOString())\n    t.equal(st.mtime.toISOString(), date.toISOString())\n    const data = fs.readFileSync(dir + '/x', 'utf8')\n    t.equal(data, 'y')\n    t.end()\n  }\n\n  t.test('async', t => {\n    new Unpack({\n      cwd: dir,\n      keep: true\n    }).on('close', _ => check(t)).end(data)\n  })\n\n  t.test('sync', t => {\n    new UnpackSync({\n      cwd: dir,\n      keep: true\n    }).end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('skip newer', t => {\n  const dir = path.join(unpackdir, 'skip-newer')\n  t.teardown(_ => rimraf.sync(dir))\n\n  const date = new Date('2013-12-19T17:00:00.000Z')\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    fs.writeFileSync(dir + '/x', 'y')\n    fs.utimesSync(dir + '/x', date, date)\n    cb()\n  })\n\n  const data = makeTar([\n    {\n      path: 'x',\n      type: 'File',\n      size: 1,\n      mode: 0o751,\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'x',\n    '',\n    ''\n  ])\n\n  const check = t => {\n    const st = fs.lstatSync(dir + '/x')\n    t.equal(st.atime.toISOString(), date.toISOString())\n    t.equal(st.mtime.toISOString(), date.toISOString())\n    const data = fs.readFileSync(dir + '/x', 'utf8')\n    t.equal(data, 'y')\n    t.end()\n  }\n\n  t.test('async', t => {\n    new Unpack({\n      cwd: dir,\n      newer: true\n    }).on('close', _ => check(t)).end(data)\n  })\n\n  t.test('sync', t => {\n    new UnpackSync({\n      cwd: dir,\n      newer: true\n    }).end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('no mtime', t => {\n  const dir = path.join(unpackdir, 'skip-newer')\n  t.teardown(_ => rimraf.sync(dir))\n\n  t.beforeEach(cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n    cb()\n  })\n\n  const date = new Date('2011-03-27T22:16:31.000Z')\n  const data = makeTar([\n    {\n      path: 'x/',\n      type: 'Directory',\n      size: 0,\n      atime: date,\n      ctime: date,\n      mtime: date\n    },\n    {\n      path: 'x/y',\n      type: 'File',\n      size: 1,\n      mode: 0o751,\n      atime: date,\n      ctime: date,\n      mtime: date\n    },\n    'x',\n    '',\n    ''\n  ])\n\n  const check = t => {\n    // this may fail if it's run on March 27, 2011\n    const stx = fs.lstatSync(dir + '/x')\n    t.notEqual(stx.atime.toISOString(), date.toISOString())\n    t.notEqual(stx.mtime.toISOString(), date.toISOString())\n    const sty = fs.lstatSync(dir + '/x/y')\n    t.notEqual(sty.atime.toISOString(), date.toISOString())\n    t.notEqual(sty.mtime.toISOString(), date.toISOString())\n    const data = fs.readFileSync(dir + '/x/y', 'utf8')\n    t.equal(data, 'x')\n    t.end()\n  }\n\n  t.test('async', t => {\n    new Unpack({\n      cwd: dir,\n      noMtime: true\n    }).on('close', _ => check(t)).end(data)\n  })\n\n  t.test('sync', t => {\n    new UnpackSync({\n      cwd: dir,\n      noMtime: true\n    }).end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('unpack big enough to pause/drain', t => {\n  const dir = path.resolve(unpackdir, 'drain-clog')\n  mkdirp.sync(dir)\n  t.tearDown(_ => rimraf.sync(dir))\n  const stream = fs.createReadStream(fixtures + '/parses.tar')\n  const u = new Unpack({\n    cwd: dir,\n    strip: 3,\n    strict: true\n  })\n\n  u.on('ignoredEntry', entry =>\n    t.fail('should not get ignored entry: ' + entry.path))\n\n  u.on('close', _ => {\n    t.pass('extraction finished')\n    const actual = fs.readdirSync(dir)\n    const expected = fs.readdirSync(parses)\n    t.same(actual, expected)\n    t.end()\n  })\n\n  stream.pipe(u)\n})\n\nt.test('set owner', t => {\n  // fake it on platforms that don't have getuid\n  const myUid = 501\n  const myGid = 1024\n  const getuid = process.getuid\n  const getgid = process.getgid\n  process.getuid = _ => myUid\n  process.getgid = _ => myGid\n  t.teardown(_ => (process.getuid = getuid, process.getgid = getgid))\n\n  // can't actually do this because it requires root, but we can\n  // verify that chown gets called.\n  t.test('as root, defaults to true', t => {\n    const getuid = process.getuid\n    process.getuid = _ => 0\n    const u = new Unpack()\n    t.equal(u.preserveOwner, true, 'preserveOwner enabled')\n    process.getuid = getuid\n    t.end()\n  })\n\n  t.test('as non-root, defaults to false', t => {\n    const getuid = process.getuid\n    process.getuid = _ => 501\n    const u = new Unpack()\n    t.equal(u.preserveOwner, false, 'preserveOwner disabled')\n    process.getuid = getuid\n    t.end()\n  })\n\n  const data = makeTar([\n    {\n      uid: 2456124561,\n      gid: 813708013,\n      path: 'foo/',\n      type: 'Directory'\n    },\n    {\n      uid: myUid,\n      gid: 813708013,\n      path: 'foo/my-uid-different-gid',\n      type: 'File',\n      size: 3\n    },\n    'qux',\n    {\n      uid: 2456124561,\n      path: 'foo/different-uid-nogid',\n      type: 'Directory'\n    },\n    {\n      uid: 2456124561,\n      path: 'foo/different-uid-nogid/bar',\n      type: 'File',\n      size: 3\n    },\n    'qux',\n    {\n      gid: 813708013,\n      path: 'foo/different-gid-nouid/bar',\n      type: 'File',\n      size: 3\n    },\n    'qux',\n    {\n      uid: myUid,\n      gid: myGid,\n      path: 'foo-mine/',\n      type: 'Directory'\n    },\n    {\n      uid: myUid,\n      gid: myGid,\n      path: 'foo-mine/bar',\n      type: 'File',\n      size: 3\n    },\n    'qux',\n    {\n      uid: myUid,\n      path: 'foo-mine/nogid',\n      type: 'Directory'\n    },\n    {\n      uid: myUid,\n      path: 'foo-mine/nogid/bar',\n      type: 'File',\n      size: 3\n    },\n    'qux',\n    '',\n    ''\n  ])\n\n  t.test('chown failure results in unpack failure', t => {\n    const dir = path.resolve(unpackdir, 'chown')\n    const poop = new Error('expected chown failure')\n    const un = mutateFS.fail('chown', poop)\n    const unf = mutateFS.fail('fchown', poop)\n\n    t.teardown(_ => (un(), unf()))\n\n    t.test('sync', t => {\n      mkdirp.sync(dir)\n      t.teardown(_ => rimraf.sync(dir))\n      let warned = false\n      const u = new Unpack.Sync({\n        cwd: dir,\n        preserveOwner: true,\n        onwarn: (m, er) => {\n          if (!warned) {\n            warned = true\n            t.equal(er, poop)\n            t.end()\n          }\n        }\n      })\n      u.end(data)\n    })\n\n    t.test('async', t => {\n      mkdirp.sync(dir)\n      t.teardown(_ => rimraf.sync(dir))\n      let warned = false\n      const u = new Unpack({\n        cwd: dir,\n        preserveOwner: true,\n        onwarn: (m, er) => {\n          if (!warned) {\n            warned = true\n            t.equal(er, poop)\n            t.end()\n          }\n        }\n      })\n      u.end(data)\n    })\n\n    t.test('cleanup', t => {\n      rimraf.sync(dir)\n      t.end()\n    })\n\n    t.end()\n  })\n\n  t.test('chown when true', t => {\n    const dir = path.resolve(unpackdir, 'chown')\n    const chown = fs.chown\n    const chownSync = fs.chownSync\n    const fchownSync = fs.fchownSync\n    let called = 0\n    fs.fchown = fs.chown = (path, owner, group, cb) => {\n      called ++\n      cb()\n    }\n    fs.chownSync = fs.fchownSync = _ => called++\n\n    t.teardown(_ => {\n      fs.chown = chown\n      fs.chownSync = chownSync\n      fs.fchownSync = fchownSync\n    })\n\n    t.test('sync', t => {\n      mkdirp.sync(dir)\n      t.teardown(_ => rimraf.sync(dir))\n      called = 0\n      const u = new Unpack.Sync({ cwd: dir, preserveOwner: true })\n      u.end(data)\n      t.ok(called >= 5, 'called chowns')\n      t.end()\n    })\n\n    t.test('async', t => {\n      mkdirp.sync(dir)\n      t.teardown(_ => rimraf.sync(dir))\n      called = 0\n      const u = new Unpack({ cwd: dir, preserveOwner: true })\n      u.end(data)\n      u.on('close', _ => {\n        t.ok(called >= 5, 'called chowns')\n        t.end()\n      })\n    })\n\n    t.end()\n  })\n\n  t.test('no chown when false', t => {\n    const dir = path.resolve(unpackdir, 'nochown')\n    const poop = new Error('poop')\n    const un = mutateFS.fail('chown', poop)\n    const unf = mutateFS.fail('fchown', poop)\n    t.teardown(_ => {\n      rimraf.sync(dir)\n      un()\n      unf()\n    })\n\n    t.beforeEach(cb => mkdirp(dir, cb))\n    t.afterEach(cb => rimraf(dir, cb))\n\n    const check = t => {\n      const dirStat = fs.statSync(dir + '/foo')\n      t.notEqual(dirStat.uid, 2456124561)\n      t.notEqual(dirStat.gid, 813708013)\n      const fileStat = fs.statSync(dir + '/foo/my-uid-different-gid')\n      t.notEqual(fileStat.uid, 2456124561)\n      t.notEqual(fileStat.gid, 813708013)\n      const dirStat2 = fs.statSync(dir + '/foo/different-uid-nogid')\n      t.notEqual(dirStat2.uid, 2456124561)\n      const fileStat2 = fs.statSync(dir + '/foo/different-uid-nogid/bar')\n      t.notEqual(fileStat2.uid, 2456124561)\n      t.end()\n    }\n\n    t.test('sync', t => {\n      const u = new Unpack.Sync({ cwd: dir, preserveOwner: false })\n      u.end(data)\n      check(t)\n    })\n\n    t.test('async', t => {\n      const u = new Unpack({ cwd: dir, preserveOwner: false })\n      u.end(data)\n      u.on('close', _ => check(t))\n    })\n\n    t.end()\n  })\n\n  t.end()\n})\n\nt.test('unpack when dir is not writable', t => {\n  const data = makeTar([\n    {\n      path: 'a/',\n      type: 'Directory',\n      mode: 0o444\n    },\n    {\n      path: 'a/b',\n      type: 'File',\n      size: 1\n    },\n    'a',\n    '',\n    ''\n  ])\n\n  const dir = path.resolve(unpackdir, 'nowrite-dir')\n  t.beforeEach(cb => mkdirp(dir, cb))\n  t.afterEach(cb => rimraf(dir, cb))\n\n  const check = t => {\n    t.equal(fs.statSync(dir + '/a').mode & 0o7777, 0o744)\n    t.equal(fs.readFileSync(dir + '/a/b', 'utf8'), 'a')\n    t.end()\n  }\n\n  t.test('sync', t => {\n    const u = new Unpack.Sync({ cwd: dir, strict: true })\n    u.end(data)\n    check(t)\n  })\n\n  t.test('async', t => {\n    const u = new Unpack({ cwd: dir, strict: true })\n    u.end(data)\n    u.on('close', _ => check(t))\n  })\n\n  t.end()\n})\n\nt.test('transmute chars on windows', t => {\n  const data = makeTar([\n    {\n      path: '<|>?:.txt',\n      size: 5,\n      type: 'File'\n    },\n    '<|>?:',\n    '',\n    ''\n  ])\n\n  const dir = path.resolve(unpackdir, 'winchars')\n  t.beforeEach(cb => mkdirp(dir, cb))\n  t.afterEach(cb => rimraf(dir, cb))\n\n  const hex = 'ef80bcef81bcef80beef80bfef80ba2e747874'\n  const uglyName = Buffer.from(hex, 'hex').toString()\n  const ugly = path.resolve(dir, uglyName)\n\n  const check = t => {\n    t.same(fs.readdirSync(dir), [ uglyName ])\n    t.equal(fs.readFileSync(ugly, 'utf8'), '<|>?:')\n    t.end()\n  }\n\n  t.test('async', t => {\n    const u = new Unpack({\n      cwd: dir,\n      win32: true\n    })\n    u.end(data)\n    u.on('close', _ => check(t))\n  })\n\n  t.test('sync', t => {\n    const u = new Unpack.Sync({\n      cwd: dir,\n      win32: true\n    })\n    u.end(data)\n    check(t)\n  })\n\n  t.end()\n})\n\nt.test('safely transmute chars on windows with absolutes', t => {\n  // don't actually make the directory\n  const poop = new Error('poop')\n  t.teardown(mutateFS.fail('mkdir', poop))\n\n  const data = makeTar([\n    {\n      path: 'c:/x/y/z/<|>?:.txt',\n      size: 5,\n      type: 'File'\n    },\n    '<|>?:',\n    '',\n    ''\n  ])\n\n  const hex = 'ef80bcef81bcef80beef80bfef80ba2e747874'\n  const uglyName = Buffer.from(hex, 'hex').toString()\n  const uglyPath = 'c:/x/y/z/' + uglyName\n\n  const u = new Unpack({\n    win32: true,\n    preservePaths: true\n  })\n  u.on('entry', entry => {\n    t.equal(entry.path, uglyPath)\n    t.end()\n  })\n\n  u.end(data)\n})\n\nt.test('use explicit chmod when required by umask', t => {\n  process.umask(0o022)\n\n  const basedir = path.resolve(unpackdir, 'umask-chmod')\n\n  const data = makeTar([\n    {\n      path: 'x/y/z',\n      mode: 0o775,\n      type: 'Directory'\n    },\n    '',\n    ''\n  ])\n\n  const check = t => {\n    const st = fs.statSync(basedir + '/x/y/z')\n    t.equal(st.mode & 0o777, 0o775)\n    rimraf.sync(basedir)\n    t.end()\n  }\n\n  t.test('async', t => {\n    mkdirp.sync(basedir)\n    const unpack = new Unpack({ cwd: basedir })\n    unpack.on('close', _ => check(t))\n    unpack.end(data)\n  })\n\n  return t.test('sync', t => {\n    mkdirp.sync(basedir)\n    const unpack = new Unpack.Sync({ cwd: basedir })\n    unpack.end(data)\n    check(t)\n  })\n})\n\nt.test('chown implicit dirs and also the entries', t => {\n  const basedir = path.resolve(unpackdir, 'chownr')\n\n  // club these so that the test can run as non-root\n  const chown = fs.chown\n  const chownSync = fs.chownSync\n\n  const getuid = process.getuid\n  const getgid = process.getgid\n  t.teardown(_ => {\n    fs.chown = chown\n    fs.chownSync = chownSync\n    process.getgid = getgid\n  })\n\n  let chowns = 0\n\n  let currentTest = null\n  fs.fchown = fs.chown = (path, uid, gid, cb) => {\n    currentTest.equal(uid, 420, 'chown(' + path + ') uid')\n    currentTest.equal(gid, 666, 'chown(' + path + ') gid')\n    chowns ++\n    cb()\n  }\n\n  fs.chownSync = fs.fchownSync = (path, uid, gid) => {\n    currentTest.equal(uid, 420, 'chownSync(' + path + ') uid')\n    currentTest.equal(gid, 666, 'chownSync(' + path + ') gid')\n    chowns ++\n  }\n\n  const data = makeTar([\n    {\n      path: 'a/b/c',\n      mode: 0o775,\n      type: 'File',\n      size: 1,\n      uid: null,\n      gid: null\n    },\n    '.',\n    {\n      path: 'x/y/z',\n      mode: 0o775,\n      uid: 12345,\n      gid: 54321,\n      type: 'File',\n      size: 1\n    },\n    '.',\n    '',\n    ''\n  ])\n\n  const check = t => {\n    currentTest = null\n    t.equal(chowns, 6)\n    chowns = 0\n    rimraf.sync(basedir)\n    t.end()\n  }\n\n  t.test('throws when setting uid/gid improperly', t => {\n    t.throws(_ => new Unpack({ uid: 420 }),\n      TypeError('cannot set owner without number uid and gid'))\n    t.throws(_ => new Unpack({ gid: 666 }),\n      TypeError('cannot set owner without number uid and gid'))\n    t.throws(_ => new Unpack({ uid: 1, gid: 2, preserveOwner: true }),\n      TypeError('cannot preserve owner in archive and also set owner explicitly'))\n    t.end()\n  })\n\n  const tests = () =>\n    t.test('async', t => {\n      currentTest = t\n      mkdirp.sync(basedir)\n      const unpack = new Unpack({ cwd: basedir, uid: 420, gid: 666 })\n      unpack.on('close', _ => check(t))\n      unpack.end(data)\n    }).then(t.test('sync', t => {\n      currentTest = t\n      mkdirp.sync(basedir)\n      const unpack = new Unpack.Sync({ cwd: basedir, uid: 420, gid: 666 })\n      unpack.end(data)\n      check(t)\n    }))\n\n  tests()\n\n  t.test('make it look like processUid is 420', t => {\n    process.getuid = () => 420\n    t.end()\n  })\n\n  tests()\n\n  t.test('make it look like processGid is 666', t => {\n    process.getuid = getuid\n    process.getgid = () => 666\n    t.end()\n  })\n\n  return tests()\n})\n\nt.test('bad cwd setting', t => {\n  const basedir = path.resolve(unpackdir, 'bad-cwd')\n  mkdirp.sync(basedir)\n  t.teardown(_ => rimraf.sync(basedir))\n\n  const cases = [\n    // the cwd itself\n    {\n      path: './',\n      type: 'Directory'\n    },\n    // a file directly in the cwd\n    {\n      path: 'a',\n      type: 'File'\n    },\n    // a file nested within a subdir of the cwd\n    {\n      path: 'a/b/c',\n      type: 'File'\n    }\n  ]\n\n  fs.writeFileSync(basedir + '/file', 'xyz')\n\n  cases.forEach(c => t.test(c.type + ' ' + c.path, t => {\n    const data = makeTar([\n      {\n        path: c.path,\n        mode: 0o775,\n        type: c.type,\n        size: 0,\n        uid: null,\n        gid: null\n      },\n      '',\n      ''\n    ])\n\n    t.test('cwd is a file', t => {\n      const cwd = basedir + '/file'\n      const opt = { cwd: cwd }\n\n      t.throws(_ => new Unpack.Sync(opt).end(data), {\n        name: 'CwdError',\n        message: 'ENOTDIR: Cannot cd into \\'' + cwd + '\\'',\n        path: cwd,\n        code: 'ENOTDIR'\n      })\n\n      new Unpack(opt).on('error', er => {\n        t.match(er, {\n          name: 'CwdError',\n          message: 'ENOTDIR: Cannot cd into \\'' + cwd + '\\'',\n          path: cwd,\n          code: 'ENOTDIR'\n        })\n        t.end()\n      }).end(data)\n    })\n\n    return t.test('cwd is missing', t => {\n      const cwd = basedir + '/asdf/asdf/asdf'\n      const opt = { cwd: cwd }\n\n      t.throws(_ => new Unpack.Sync(opt).end(data), {\n        name: 'CwdError',\n        message: 'ENOENT: Cannot cd into \\'' + cwd + '\\'',\n        path: cwd,\n        code: 'ENOENT'\n      })\n\n      new Unpack(opt).on('error', er => {\n        t.match(er, {\n          name: 'CwdError',\n          message: 'ENOENT: Cannot cd into \\'' + cwd + '\\'',\n          path: cwd,\n          code: 'ENOENT'\n        })\n        t.end()\n      }).end(data)\n    })\n  }))\n\n  t.end()\n})\n\nt.test('transform', t => {\n  const basedir = path.resolve(unpackdir, 'transform')\n  t.teardown(_ => rimraf.sync(basedir))\n\n  const cases = {\n    'emptypax.tar': {\n      '\ud83c\udf1f.txt': '\ud83c\udf1f\u2727\u2729\u2b50\ufe0e\u272a\u272b\u272c\u272d\u272e\u269d\u272f\u2730\u2735\u2736\u2737\u2738\u2739\u2742\u2b51\u2b52\u2605\u2606\u2721\u262a\u2734\ufe0e\u2726\u2721\ufe0f\ud83d\udd2f\u2734\ufe0f\ud83c\udf20\\n',\n      'one-byte.txt': '[a]'\n    },\n    'body-byte-counts.tar': {\n      '1024-bytes.txt': new Array(1024).join('[x]') + '[\\n]',\n      '512-bytes.txt': new Array(512).join('[x]') + '[\\n]',\n      'one-byte.txt': '[a]',\n      'zero-byte.txt': ''\n    },\n    'utf8.tar': {\n      '\ud83c\udf1f.txt': '\ud83c\udf1f\u2727\u2729\u2b50\ufe0e\u272a\u272b\u272c\u272d\u272e\u269d\u272f\u2730\u2735\u2736\u2737\u2738\u2739\u2742\u2b51\u2b52\u2605\u2606\u2721\u262a\u2734\ufe0e\u2726\u2721\ufe0f\ud83d\udd2f\u2734\ufe0f\ud83c\udf20\\n',\n      '\u03a9.txt': '[\u03a9]',\n      'long-path/r/e/a/l/l/y/-/d/e/e/p/-/f/o/l/d/e/r/-/p/a/t/h/\u03a9.txt': '[\u03a9]'\n    }\n  }\n\n  const txFn = entry => {\n    switch (path.basename(entry.path)) {\n      case 'zero-bytes.txt':\n        return entry\n\n      case 'one-byte.txt':\n      case '1024-bytes.txt':\n      case '512-bytes.txt':\n      case '\u03a9.txt':\n        return new Bracer()\n    }\n  }\n\n  class Bracer extends MiniPass {\n    write (data) {\n      const d = data.toString().split('').map(c => '[' + c + ']').join('')\n      return super.write(d)\n    }\n  }\n\n  const tarfiles = Object.keys(cases)\n  t.plan(tarfiles.length)\n  t.jobs = tarfiles.length\n\n  tarfiles.forEach(tarfile => {\n    t.test(tarfile, t => {\n      const tf = path.resolve(tars, tarfile)\n      const dir = path.resolve(basedir, tarfile)\n      t.beforeEach(cb => {\n        rimraf.sync(dir)\n        mkdirp.sync(dir)\n        cb()\n      })\n\n      const check = t => {\n        const expect = cases[tarfile]\n        Object.keys(expect).forEach(file => {\n          const f = path.resolve(dir, file)\n          t.equal(fs.readFileSync(f, 'utf8'), expect[file], file)\n        })\n        t.end()\n      }\n\n      t.plan(2)\n\n      t.test('async unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          const unpack = new Unpack({ cwd: dir, strict: true, transform: txFn })\n          fs.createReadStream(tf).pipe(unpack)\n          eos(unpack, _ => check(t))\n        })\n        t.test('loose', t => {\n          const unpack = new Unpack({ cwd: dir, transform: txFn })\n          fs.createReadStream(tf).pipe(unpack)\n          eos(unpack, _ => check(t))\n        })\n      })\n\n      t.test('sync unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          const unpack = new UnpackSync({ cwd: dir, transform: txFn })\n          unpack.end(fs.readFileSync(tf))\n          check(t)\n        })\n        t.test('loose', t => {\n          const unpack = new UnpackSync({ cwd: dir, transform: txFn })\n          unpack.end(fs.readFileSync(tf))\n          check(t)\n        })\n      })\n    })\n  })\n})\n\nt.test('futimes/fchown failures', t => {\n  const archive = path.resolve(tars, 'utf8.tar')\n  const dir = path.resolve(unpackdir, 'futimes-fchown-fails')\n  const tardata = fs.readFileSync(archive)\n\n  const poop = new Error('poop')\n  const second = new Error('second error')\n\n  const reset = cb => {\n    rimraf.sync(dir)\n    mkdirp.sync(dir)\n  }\n\n  reset()\n  t.teardown(() => rimraf.sync(dir))\n\n  const methods = ['utimes', 'chown']\n  methods.forEach(method => {\n    const fc = method === 'chown'\n    t.test(method +' fallback', t => {\n      t.teardown(mutateFS.fail('f' + method, poop))\n      // forceChown will fail on systems where the user is not root\n      // and/or the uid/gid in the archive aren't valid. We're just\n      // verifying coverage here, so make the method auto-pass.\n      t.teardown(mutateFS.pass(method))\n      t.plan(2)\n      t.test('async unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          reset()\n          const unpack = new Unpack({ cwd: dir, strict: true, forceChown: fc })\n          unpack.on('finish', t.end)\n          unpack.end(tardata)\n        })\n        t.test('loose', t => {\n          reset()\n          const unpack = new Unpack({ cwd: dir, forceChown: fc })\n          unpack.on('finish', t.end)\n          unpack.on('warn', t.fail)\n          unpack.end(tardata)\n        })\n      })\n      t.test('sync unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          reset()\n          const unpack = new Unpack.Sync({ cwd: dir, strict: true, forceChown: fc })\n          unpack.end(tardata)\n          t.end()\n        })\n        t.test('loose', t => {\n          reset()\n          const unpack = new Unpack.Sync({ cwd: dir, forceChown: fc })\n          unpack.on('warn', t.fail)\n          unpack.end(tardata)\n          t.end()\n        })\n      })\n    })\n\n    t.test('also fail ' + method, t => {\n      const unmutate = mutateFS.fail('f' + method, poop)\n      const unmutate2 = mutateFS.fail(method, second)\n      t.teardown(() => {\n        unmutate()\n        unmutate2()\n      })\n      t.plan(2)\n      t.test('async unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          reset()\n          const unpack = new Unpack({ cwd: dir, strict: true, forceChown: fc })\n          t.plan(3)\n          unpack.on('error', er => t.equal(er, poop))\n          unpack.end(tardata)\n        })\n        t.test('loose', t => {\n          reset()\n          const unpack = new Unpack({ cwd: dir, forceChown: fc })\n          t.plan(3)\n          unpack.on('warn', (m, er) => t.equal(er, poop))\n          unpack.end(tardata)\n        })\n      })\n      t.test('sync unpack', t => {\n        t.plan(2)\n        t.test('strict', t => {\n          reset()\n          const unpack = new Unpack.Sync({ cwd: dir, strict: true, forceChown: fc })\n          t.plan(3)\n          unpack.on('error', er => t.equal(er, poop))\n          unpack.end(tardata)\n        })\n        t.test('loose', t => {\n          reset()\n          const unpack = new Unpack.Sync({ cwd: dir, forceChown: fc })\n          t.plan(3)\n          unpack.on('warn', (m, er) => t.equal(er, poop))\n          unpack.end(tardata)\n        })\n      })\n    })\n  })\n\n  t.end()\n})\n\nt.test('onentry option is preserved', t => {\n  const basedir = path.resolve(unpackdir, 'onentry-method')\n  mkdirp.sync(basedir)\n  t.teardown(() => rimraf.sync(basedir))\n\n  let oecalls = 0\n  const onentry = entry => oecalls++\n  const data = makeTar([\n    {\n      path: 'd/i',\n      type: 'Directory'\n    },\n    {\n      path: 'd/i/r/dir',\n      type: 'Directory',\n      mode: 0o751,\n      mtime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    {\n      path: 'd/i/r/file',\n      type: 'File',\n      size: 1,\n      atime: new Date('1979-07-01T19:10:00.000Z'),\n      ctime: new Date('2011-03-27T22:16:31.000Z')\n    },\n    'a',\n    '',\n    ''\n  ])\n\n  const check = t => {\n    t.equal(oecalls, 3)\n    oecalls = 0\n    t.end()\n  }\n\n  t.test('sync', t => {\n    const dir = path.join(basedir, 'sync')\n    mkdirp.sync(dir)\n    const unpack = new UnpackSync({ cwd: dir, onentry })\n    unpack.end(data)\n    check(t)\n  })\n\n  t.test('async', t => {\n    const dir = path.join(basedir, 'async')\n    mkdirp.sync(dir)\n    const unpack = new Unpack({ cwd: dir, onentry })\n    unpack.on('finish', () => check(t))\n    unpack.end(data)\n  })\n\n  t.end()\n})\n\nt.test('do not reuse hardlinks, only nlink=1 files', t => {\n  const basedir = path.resolve(unpackdir, 'hardlink-reuse')\n  mkdirp.sync(basedir)\n  t.teardown(() => rimraf.sync(basedir))\n\n  const now = new Date('2018-04-30T18:30:39.025Z')\n\n  const data = makeTar([\n    {\n      path: 'overwriteme',\n      type: 'File',\n      size: 4,\n      mode: 0o644,\n      mtime: now\n    },\n    'foo\\n',\n    {\n      path: 'link',\n      linkpath: 'overwriteme',\n      type: 'Link',\n      mode: 0o644,\n      mtime: now\n    },\n    {\n      path: 'link',\n      type: 'File',\n      size: 4,\n      mode: 0o644,\n      mtime: now\n    },\n    'bar\\n',\n    '',\n    ''\n  ])\n\n  const checks = {\n    'link': 'bar\\n',\n    'overwriteme': 'foo\\n'\n  }\n\n  const check = t => {\n    for (let f in checks) {\n      t.equal(fs.readFileSync(basedir + '/' + f, 'utf8'), checks[f], f)\n      t.equal(fs.statSync(basedir + '/' + f).nlink, 1, f)\n    }\n    t.end()\n  }\n\n  t.test('async', t => {\n    const u = new Unpack({ cwd: basedir })\n    u.on('close', () => check(t))\n    u.end(data)\n  })\n\n  t.test('sync', t => {\n    const u = new UnpackSync({ cwd: basedir })\n    u.end(data)\n    check(t)\n  })\n\n  t.end()\n})\n"], "filenames": ["lib/unpack.js", "test/unpack.js"], "buggy_code_start_loc": [14, 2288], "buggy_code_end_loc": [426, 2288], "fixing_code_start_loc": [15, 2289], "fixing_code_end_loc": [438, 2352], "type": "CWE-59", "message": "A vulnerability was found in node-tar before version 4.4.2 (excluding version 2.2.2). An Arbitrary File Overwrite issue exists when extracting a tarball containing a hardlink to a file that already exists on the system, in conjunction with a later plain file with the same name as the hardlink. This plain file content replaces the existing file content. A patch has been applied to node-tar v2.2.2).", "other": {"cve": {"id": "CVE-2018-20834", "sourceIdentifier": "cve@mitre.org", "published": "2019-04-30T19:29:03.327", "lastModified": "2019-09-04T20:15:10.403", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "A vulnerability was found in node-tar before version 4.4.2 (excluding version 2.2.2). An Arbitrary File Overwrite issue exists when extracting a tarball containing a hardlink to a file that already exists on the system, in conjunction with a later plain file with the same name as the hardlink. This plain file content replaces the existing file content. A patch has been applied to node-tar v2.2.2)."}, {"lang": "es", "value": "Se detecto una vulnerabilidad en node-tar en versiones anteriores a la 4.4.2 (excluyendo la versi\u00f3n 2.2.2). Existe un problema de sobrescritura arbitraria de archivos cuando se extrae un tarball que contiene un enlace f\u00edsico a un archivo que ya existe en el sistema, junto con un archivo plano posterior con el mismo nombre que el enlace f\u00edsico. Este contenido de archivo simple reemplaza el contenido de archivo existente. Se ha aplicado un parche a node-tar v2.2.2)."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.4}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-59"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:node-tar_project:node-tar:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.2.2", "matchCriteriaId": "25114F61-BC5B-4B8E-B991-01EE8F6E8B1B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:node-tar_project:node-tar:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.0.0", "versionEndExcluding": "4.4.2", "matchCriteriaId": "80C2038D-E008-44E4-89B9-210B0612BE3F"}]}]}], "references": [{"url": "https://access.redhat.com/errata/RHSA-2019:1821", "source": "cve@mitre.org"}, {"url": "https://github.com/npm/node-tar/commit/7ecef07da6a9e72cc0c4d0c9c6a8e85b6b52395d", "source": "cve@mitre.org"}, {"url": "https://github.com/npm/node-tar/commit/b0c58433c22f5e7fe8b1c76373f27e3f81dcd4c8", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/npm/node-tar/commits/v2.2.2", "source": "cve@mitre.org"}, {"url": "https://github.com/npm/node-tar/compare/58a8d43...a5f7779", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://hackerone.com/reports/344595", "source": "cve@mitre.org", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://nvd.nist.gov/vuln/detail/CVE-2018-20834", "source": "cve@mitre.org"}]}, "github_commit_url": "https://github.com/npm/node-tar/commit/b0c58433c22f5e7fe8b1c76373f27e3f81dcd4c8"}}
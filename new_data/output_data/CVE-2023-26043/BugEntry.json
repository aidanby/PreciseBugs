{"buggy_code": ["#########################################################################\n#\n# Copyright (C) 2016 OSGeo\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n#\n#########################################################################\nimport os\nimport re\nimport sys\nimport copy\nimport time\nimport uuid\nimport json\nimport errno\nimport typing\nimport logging\nimport datetime\nimport tempfile\nimport traceback\nimport dataclasses\n\nfrom shutil import copyfile\nfrom itertools import cycle\nfrom collections import defaultdict\nfrom os.path import basename, splitext, isfile\nfrom urllib.parse import urlparse, urlencode, urlsplit, urljoin\nfrom pinax.ratings.models import OverallRating\nfrom bs4 import BeautifulSoup\nimport xml.etree.ElementTree as ET\n\nfrom django.conf import settings\nfrom django.utils import timezone\nfrom django.db import transaction\nfrom django.contrib.auth import get_user_model\nfrom django.utils.module_loading import import_string\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.template.loader import render_to_string\nfrom django.utils.translation import ugettext as _\n\nfrom geoserver.catalog import Catalog, FailedRequestError\nfrom geoserver.resource import FeatureType, Coverage\nfrom geoserver.store import CoverageStore, DataStore, datastore_from_index, \\\n    coveragestore_from_index, wmsstore_from_index\nfrom geoserver.support import DimensionInfo\nfrom geoserver.workspace import Workspace\nfrom gsimporter import Client\nfrom lxml import etree, objectify\nfrom owslib.etree import etree as dlxml\nfrom owslib.wcs import WebCoverageService\n\nfrom geonode import GeoNodeException\nfrom geonode.base.models import Link\nfrom geonode.base.models import ResourceBase\nfrom geonode.security.views import _perms_info_json\nfrom geonode.catalogue.models import catalogue_post_save\nfrom geonode.layers.models import Dataset, Attribute, Style\nfrom geonode.layers.enumerations import LAYER_ATTRIBUTE_NUMERIC_DATA_TYPES\n\nfrom geonode.utils import (\n    OGC_Servers_Handler,\n    http_client,\n    get_legend_url,\n    is_monochromatic_image,\n    set_resource_default_links)\n\nfrom .security import set_geowebcache_invalidate_cache\n\nlogger = logging.getLogger(__name__)\n\ntemp_style_name_regex = r'[a-zA-Z0-9]{8}-[a-zA-Z0-9]{4}-[a-zA-Z0-9]{4}-[a-zA-Z0-9]{4}-[a-zA-Z0-9]{12}_ms_.*'\n\nLAYER_SUBTYPES = {\n    \"dataStore\": \"vector\",\n    \"coverageStore\": \"raster\",\n    \"remoteStore\": \"remote\",\n    \"vectorTimeSeries\": \"vector_time\"\n}\n\nWPS_ACCEPTABLE_FORMATS = [\n    ('application/json', 'vector'),\n    ('application/arcgrid', 'raster'),\n    ('image/tiff', 'raster'),\n    ('image/png', 'raster'),\n    ('image/jpeg', 'raster'),\n    ('application/wfs-collection-1.0', 'vector'),\n    ('application/wfs-collection-1.1', 'vector'),\n    ('application/zip', 'vector'),\n    ('text/csv', 'vector')\n]\n\nDEFAULT_STYLE_NAME = ['generic', 'line', 'point', 'polygon', 'raster']\n\n\nif not hasattr(settings, 'OGC_SERVER'):\n    msg = (\n        'Please configure OGC_SERVER when enabling geonode.geoserver.'\n        ' More info can be found at '\n        'http://docs.geonode.org/en/2.10.x/basic/settings/index.html#ogc-server')\n    raise ImproperlyConfigured(msg)\n\n\ndef check_geoserver_is_up():\n    \"\"\"Verifies all geoserver is running,\n       this is needed to be able to upload.\n    \"\"\"\n    url = f\"{ogc_server_settings.LOCATION}\"\n    req, content = http_client.get(url, user=_user)\n    msg = f'Cannot connect to the GeoServer at {url}\\nPlease make sure you have started it.'\n    logger.debug(req)\n    assert req.status_code == 200, msg\n\n\ndef _add_sld_boilerplate(symbolizer):\n    \"\"\"\n    Wrap an XML snippet representing a single symbolizer in the appropriate\n    elements to make it a valid SLD which applies that symbolizer to all features,\n    including format strings to allow interpolating a \"name\" variable in.\n    \"\"\"\n    return \"\"\"\n<StyledLayerDescriptor version=\"1.0.0\" xmlns=\"http://www.opengis.net/sld\" xmlns:ogc=\"http://www.opengis.net/ogc\"\n  xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://www.opengis.net/sld http://schemas.opengis.net/sld/1.0.0/StyledLayerDescriptor.xsd\">\n  <NamedLayer>\n    <Name>%(name)s</Name>\n    <UserStyle>\n    <Name>%(name)s</Name>\n    <Title>%(name)s</Title>\n      <FeatureTypeStyle>\n        <Rule>\n\"\"\" + symbolizer + \"\"\"\n        </Rule>\n      </FeatureTypeStyle>\n    </UserStyle>\n  </NamedLayer>\n</StyledLayerDescriptor>\n\"\"\"\n\n\n_raster_template = \"\"\"\n<RasterSymbolizer>\n    <Opacity>1.0</Opacity>\n</RasterSymbolizer>\n\"\"\"\n\n_polygon_template = \"\"\"\n<PolygonSymbolizer>\n  <Fill>\n    <CssParameter name=\"fill\">%(bg)s</CssParameter>\n  </Fill>\n  <Stroke>\n    <CssParameter name=\"stroke\">%(fg)s</CssParameter>\n    <CssParameter name=\"stroke-width\">0.7</CssParameter>\n  </Stroke>\n</PolygonSymbolizer>\n\"\"\"\n\n_line_template = \"\"\"\n<LineSymbolizer>\n  <Stroke>\n    <CssParameter name=\"stroke\">%(bg)s</CssParameter>\n    <CssParameter name=\"stroke-width\">3</CssParameter>\n  </Stroke>\n</LineSymbolizer>\n</Rule>\n</FeatureTypeStyle>\n<FeatureTypeStyle>\n<Rule>\n<LineSymbolizer>\n  <Stroke>\n    <CssParameter name=\"stroke\">%(fg)s</CssParameter>\n  </Stroke>\n</LineSymbolizer>\n\"\"\"\n\n_point_template = \"\"\"\n<PointSymbolizer>\n  <Graphic>\n    <Mark>\n      <WellKnownName>%(mark)s</WellKnownName>\n      <Fill>\n        <CssParameter name=\"fill\">%(bg)s</CssParameter>\n      </Fill>\n      <Stroke>\n        <CssParameter name=\"stroke\">%(fg)s</CssParameter>\n      </Stroke>\n    </Mark>\n    <Size>10</Size>\n  </Graphic>\n</PointSymbolizer>\n\"\"\"\n\n_style_templates = dict(\n    raster=_add_sld_boilerplate(_raster_template),\n    polygon=_add_sld_boilerplate(_polygon_template),\n    line=_add_sld_boilerplate(_line_template),\n    point=_add_sld_boilerplate(_point_template)\n)\n\nSTYLES_VERSION = {\n    \"1.0.0\": \"sld10\",\n    \"1.1.0\": \"sld11\"\n}\n\n\ndef _extract_style_version_from_sld(sld):\n    \"\"\"\n        Assume: SLD as a byte\n    \"\"\"\n    root = objectify.fromstring(sld)\n    try:\n        return STYLES_VERSION[root.attrib[\"version\"].strip()]\n    except Exception:\n        return STYLES_VERSION[\"1.0.0\"]\n\n\ndef _style_name(resource):\n    return _punc.sub(\"_\", f\"{resource.store.workspace.name}:{resource.name}\")\n\n\ndef extract_name_from_sld(gs_catalog, sld, sld_file=None):\n    try:\n        if sld:\n            if isfile(sld):\n                with open(sld, \"rb\") as sld_file:\n                    sld = sld_file.read()\n            if isinstance(sld, str):\n                sld = sld.encode('utf-8')\n            dom = etree.XML(sld)\n        elif sld_file and isfile(sld_file):\n            with open(sld_file, \"rb\") as sld_file:\n                sld = sld_file.read()\n            if isinstance(sld, str):\n                sld = sld.encode('utf-8')\n            dom = dlxml.parse(sld)\n    except Exception:\n        logger.exception(\"The uploaded SLD file is not valid XML\")\n        raise Exception(\n            \"The uploaded SLD file is not valid XML\")\n\n    named_dataset = dom.findall(\n        \"{http://www.opengis.net/sld}NamedLayer\")\n    user_dataset = dom.findall(\n        \"{http://www.opengis.net/sld}UserLayer\")\n\n    el = None\n    if named_dataset and len(named_dataset) > 0:\n        user_style = named_dataset[0].findall(\"{http://www.opengis.net/sld}UserStyle\")\n        if user_style and len(user_style) > 0:\n            el = user_style[0].findall(\"{http://www.opengis.net/sld}Name\")\n            if len(el) == 0:\n                el = user_style[0].findall(\"{http://www.opengis.net/se}Name\")\n\n        if len(el) == 0:\n            el = named_dataset[0].findall(\"{http://www.opengis.net/sld}Name\")\n        if len(el) == 0:\n            el = named_dataset[0].findall(\"{http://www.opengis.net/se}Name\")\n\n    if not el or len(el) == 0:\n        if user_dataset and len(user_dataset) > 0:\n            user_style = user_dataset[0].findall(\"{http://www.opengis.net/sld}UserStyle\")\n            if user_style and len(user_style) > 0:\n                el = user_style[0].findall(\"{http://www.opengis.net/sld}Name\")\n                if len(el) == 0:\n                    el = user_style[0].findall(\"{http://www.opengis.net/se}Name\")\n\n            if len(el) == 0:\n                el = user_dataset[0].findall(\"{http://www.opengis.net/sld}Name\")\n            if len(el) == 0:\n                el = user_dataset[0].findall(\"{http://www.opengis.net/se}Name\")\n\n    if not el or len(el) == 0:\n        if sld_file:\n            return splitext(basename(sld_file))[0]\n        else:\n            raise Exception(\n                \"Please provide a name, unable to extract one from the SLD.\")\n\n    return el[0].text\n\n\ndef get_sld_for(gs_catalog, layer):\n    name = None\n    gs_dataset = None\n    gs_style = None\n\n    _default_style = None\n    _max_retries, _tries = getattr(ogc_server_settings, \"MAX_RETRIES\", 2), 0\n    try:\n        gs_dataset = gs_catalog.get_layer(layer.name)\n        if gs_dataset.default_style:\n            gs_style = gs_dataset.default_style.sld_body\n            set_dataset_style(layer, layer.alternate, gs_style)\n        name = gs_dataset.default_style.name\n        _default_style = gs_dataset.default_style\n    except Exception as e:\n        logger.debug(e)\n        name = None\n\n    while not name and _tries < _max_retries:\n        try:\n            gs_dataset = gs_catalog.get_layer(layer.name)\n            if gs_dataset:\n                if gs_dataset.default_style:\n                    gs_style = gs_dataset.default_style.sld_body\n                    set_dataset_style(layer, layer.alternate, gs_style)\n                name = gs_dataset.default_style.name\n                if name:\n                    break\n        except Exception as e:\n            logger.exception(e)\n            name = None\n        _tries += 1\n        time.sleep(3)\n\n    if not _default_style:\n        _default_style = layer.default_style if layer else None\n        name = _default_style.name if _default_style else None\n        gs_style = _default_style.sld_body if _default_style else None\n\n    if not name:\n        msg = \"\"\"\n            GeoServer didn't return a default style for this layer.\n            Consider increasing OGC_SERVER MAX_RETRIES value.''\n        \"\"\"\n        raise GeoNodeException(msg)\n\n    # Detect geometry type if it is a FeatureType\n    res = gs_dataset.resource if gs_dataset else None\n    if res and res.resource_type == 'featureType':\n        res.fetch()\n        ft = res.store.get_resources(name=res.name)\n        ft.fetch()\n        for attr in ft.dom.find(\"attributes\"):\n            attr_binding = attr.find(\"binding\")\n            if \"jts.geom\" in attr_binding.text:\n                if \"Polygon\" in attr_binding.text:\n                    name = \"polygon\"\n                elif \"Line\" in attr_binding.text:\n                    name = \"line\"\n                else:\n                    name = \"point\"\n\n    # FIXME: When gsconfig.py exposes the default geometry type for vector\n    # layers we should use that rather than guessing based on the auto-detected\n    # style.\n    if name in _style_templates:\n        fg, bg, mark = next(_style_contexts)\n        return _style_templates[name] % dict(\n            name=layer.name,\n            fg=fg,\n            bg=bg,\n            mark=mark)\n    else:\n        return gs_style\n\n\ndef set_dataset_style(saved_dataset, title, sld, base_file=None):\n    # Check SLD is valid\n    try:\n        if sld:\n            if isfile(sld):\n                with open(sld, \"rb\") as sld_file:\n                    sld = sld_file.read()\n\n            elif isinstance(sld, str):\n                sld = sld.strip('b\\'\\n')\n                sld = re.sub(r'(\\\\r)|(\\\\n)', '', sld).encode(\"UTF-8\")\n            etree.XML(sld)\n        elif base_file and isfile(base_file):\n            with open(base_file, \"rb\") as sld_file:\n                sld = sld_file.read()\n            dlxml.parse(base_file)\n    except Exception:\n        logger.exception(\"The uploaded SLD file is not valid XML\")\n        raise Exception(\"The uploaded SLD file is not valid XML\")\n\n    # Check Dataset's available styles\n    match = None\n    styles = list(saved_dataset.styles.all()) + [\n        saved_dataset.default_style]\n    for style in styles:\n        if style and style.name == saved_dataset.name:\n            match = style\n            break\n    layer = gs_catalog.get_layer(title)\n    style = None\n    if match is None:\n        try:\n            style = gs_catalog.get_style(saved_dataset.name, workspace=saved_dataset.workspace) or \\\n                gs_catalog.get_style(saved_dataset.name)\n            if not style:\n                style = gs_catalog.create_style(\n                    saved_dataset.name, sld, overwrite=False, raw=True, workspace=saved_dataset.workspace)\n        except Exception as e:\n            logger.exception(e)\n    else:\n        try:\n            _sld_format = _extract_style_version_from_sld(sld)\n            style = gs_catalog.create_style(\n                saved_dataset.name, sld,\n                overwrite=True, raw=True, style_format=_sld_format,\n                workspace=saved_dataset.workspace)\n        except Exception as e:\n            logger.exception(e)\n\n    if layer and style:\n        _old_styles = []\n        _old_styles.append(gs_catalog.get_style(\n            name=saved_dataset.name))\n        _old_styles.append(gs_catalog.get_style(\n            name=f\"{saved_dataset.workspace}_{saved_dataset.name}\"))\n        if layer.default_style and layer.default_style.name:\n            _old_styles.append(gs_catalog.get_style(\n                name=layer.default_style.name))\n            _old_styles.append(gs_catalog.get_style(\n                name=layer.default_style.name,\n                workspace=layer.default_style.workspace))\n        layer.default_style = style\n        gs_catalog.save(layer)\n        for _s in _old_styles:\n            try:\n                gs_catalog.delete(_s)\n                Link.objects.filter(\n                    resource=saved_dataset.resourcebase_ptr,\n                    name='Legend',\n                    url__contains=f'STYLE={_s.name}').delete()\n            except Exception as e:\n                logger.debug(e)\n        set_styles(saved_dataset, gs_catalog)\n\n\ndef cascading_delete(dataset_name=None, catalog=None):\n    if not dataset_name:\n        return\n    cat = catalog or gs_catalog\n    resource = None\n    workspace = None\n    try:\n        if dataset_name.find(':') != -1 and len(dataset_name.split(':')) == 2:\n            workspace, name = dataset_name.split(':')\n            ws = cat.get_workspace(workspace)\n            store = None\n            try:\n                store = get_store(cat, name, workspace=ws)\n            except FailedRequestError:\n                if ogc_server_settings.DATASTORE:\n                    try:\n                        layers = Dataset.objects.filter(alternate=dataset_name)\n                        for layer in layers:\n                            store = get_store(cat, layer.store, workspace=ws)\n                    except FailedRequestError:\n                        logger.debug(\n                            'the store was not found in geoserver')\n                else:\n                    logger.debug(\n                        'the store was not found in geoserver')\n            if ws is None or store is None:\n                logger.debug(\n                    'cascading delete was called on a layer where the workspace was not found')\n            resource = cat.get_resource(name=name, store=store, workspace=workspace)\n        else:\n            resource = cat.get_resource(name=dataset_name)\n    except OSError as e:\n        if e.errno == errno.ECONNREFUSED:\n            msg = (f'Could not connect to geoserver at \"{ogc_server_settings.LOCATION}\"'\n                   f'to save information for layer \"{dataset_name}\"')\n            logger.error(msg)\n            return None\n        else:\n            raise e\n    finally:\n        # Let's reset the connections first\n        cat._cache.clear()\n        cat.reset()\n        cat.reload()\n\n    if resource is None:\n        # If there is no associated resource,\n        # this method can not delete anything.\n        # Let's return and make a note in the log.\n        logger.debug(\n            'cascading_delete was called with a non existent resource')\n        return\n    resource_name = resource.name\n    lyr = None\n    try:\n        lyr = cat.get_layer(resource_name)\n    except Exception as e:\n        logger.debug(e)\n    if lyr is not None:  # Already deleted\n        store = resource.store\n        styles = lyr.styles\n        try:\n            styles = styles + [lyr.default_style]\n        except Exception:\n            pass\n        if workspace:\n            gs_styles = [x for x in cat.get_styles(names=[f\"{workspace}_{resource_name}\"])]\n            styles = styles + gs_styles\n        if settings.DEFAULT_WORKSPACE and settings.DEFAULT_WORKSPACE != workspace:\n            gs_styles = [x for x in cat.get_styles(names=[f\"{settings.DEFAULT_WORKSPACE}_{resource_name}\"])]\n            styles = styles + gs_styles\n        cat.delete(lyr)\n        for s in styles:\n            if s is not None and s.name not in _default_style_names:\n                try:\n                    logger.debug(f\"Trying to delete Style [{s.name}]\")\n                    cat.delete(s, purge='true')\n                except Exception as e:\n                    # Trying to delete a shared style will fail\n                    # We'll catch the exception and log it.\n                    logger.debug(e)\n\n        # Due to a possible bug of geoserver, we need this trick for now\n        # TODO: inspect the issue reported by this hack. Should be solved\n        #       with GS 2.7+\n        try:\n            cat.delete(resource, recurse=True)  # This may fail\n        except Exception:\n            pass\n\n        if store.resource_type == 'dataStore' and 'dbtype' in store.connection_parameters and \\\n                store.connection_parameters['dbtype'] == 'postgis':\n            delete_from_postgis(resource_name, store)\n        else:\n            # AF: for the time being this one mitigates the issue #8671\n            # until we find a suitable solution for the GeoTools ImageMosaic plugin\n            # ref: https://github.com/geotools/geotools/blob/main/modules/plugin/imagemosaic/src/main/java/org/geotools/gce/imagemosaic/catalog/AbstractGTDataStoreGranuleCatalog.java#L753\n            if store.resource_type == 'coverageStore' and store.type != 'ImageMosaic':\n                try:\n                    logger.debug(f\" - Going to purge the {store.resource_type} : {store.href}\")\n                    cat.reset()  # this resets the coverage readers and unlocks the files\n                    cat.delete(store, purge='all', recurse=True)\n                    # cat.reload()  # this preservers the integrity of geoserver\n                except Exception as e:\n                    # Trying to recursively purge a store may fail\n                    # We'll catch the exception and log it.\n                    logger.debug(e)\n            else:\n                try:\n                    if not store.get_resources():\n                        cat.delete(store, recurse=True)\n                except Exception as e:\n                    # Catch the exception and log it.\n                    logger.debug(e)\n\n\ndef delete_from_postgis(dataset_name, store):\n    \"\"\"\n    Delete a table from PostGIS (because Geoserver won't do it yet);\n    to be used after deleting a layer from the system.\n    \"\"\"\n    import psycopg2\n\n    # we will assume that store/database may change (when using shard for example)\n    # but user and password are the ones from settings (DATASTORE_URL)\n    db = ogc_server_settings.datastore_db\n    db_name = store.connection_parameters['database']\n    user = db['USER']\n    password = db['PASSWORD']\n    host = store.connection_parameters['host']\n    port = store.connection_parameters['port']\n    conn = None\n    try:\n        conn = psycopg2.connect(dbname=db_name, user=user, host=host, port=port, password=password)\n        cur = conn.cursor()\n        cur.execute(f\"SELECT DropGeometryTable ('{dataset_name}')\")\n        conn.commit()\n    except Exception as e:\n        logger.error(\n            \"Error deleting PostGIS table %s:%s\",\n            dataset_name,\n            str(e))\n    finally:\n        try:\n            if conn:\n                conn.close()\n        except Exception as e:\n            logger.error(\"Error closing PostGIS conn %s:%s\", dataset_name, str(e))\n\n\ndef gs_slurp(\n        ignore_errors=False,\n        verbosity=1,\n        console=None,\n        owner=None,\n        workspace=None,\n        store=None,\n        filter=None,\n        skip_unadvertised=False,\n        skip_geonode_registered=False,\n        remove_deleted=False,\n        permissions=None,\n        execute_signals=False):\n    \"\"\"Configure the layers available in GeoServer in GeoNode.\n       It returns a list of dictionaries with the name of the layer,\n       the result of the operation and the errors and traceback if it failed.\n    \"\"\"\n    from geonode.resource.manager import resource_manager\n\n    if console is None:\n        console = open(os.devnull, 'w')\n\n    if verbosity > 0:\n        print(\"Inspecting the available layers in GeoServer ...\", file=console)\n\n    cat = gs_catalog\n\n    if workspace is not None and workspace:\n        workspace = cat.get_workspace(workspace)\n        if workspace is None:\n            resources = []\n        else:\n            # obtain the store from within the workspace. if it exists, obtain resources\n            # directly from store, otherwise return an empty list:\n            if store is not None:\n                store = get_store(cat, store, workspace=workspace)\n                if store is None:\n                    resources = []\n                else:\n                    resources = cat.get_resources(stores=[store])\n            else:\n                resources = cat.get_resources(workspaces=[workspace])\n    elif store is not None:\n        store = get_store(cat, store)\n        resources = cat.get_resources(stores=[store])\n    else:\n        resources = cat.get_resources()\n\n    if remove_deleted:\n        resources_for_delete_compare = resources[:]\n        workspace_for_delete_compare = workspace\n        # filter out layers for delete comparison with GeoNode layers by following criteria:\n        # enabled = true, if --skip-unadvertised: advertised = true, but\n        # disregard the filter parameter in the case of deleting layers\n        try:\n            resources_for_delete_compare = [\n                k for k in resources_for_delete_compare if k.enabled in {\"true\", True}]\n            if skip_unadvertised:\n                resources_for_delete_compare = [\n                    k for k in resources_for_delete_compare if k.advertised in {\"true\", True}]\n        except Exception:\n            if ignore_errors:\n                pass\n            else:\n                raise\n\n    if filter:\n        resources = [k for k in resources if filter in k.name]\n\n    # filter out layers depending on enabled, advertised status:\n    _resources = []\n    for k in resources:\n        try:\n            if k.enabled in {\"true\", True}:\n                _resources.append(k)\n        except Exception:\n            if ignore_errors:\n                continue\n            else:\n                raise\n    # resources = [k for k in resources if k.enabled in {\"true\", True}]\n    resources = _resources\n    if skip_unadvertised:\n        try:\n            resources = [k for k in resources if k.advertised in {\"true\", True}]\n        except Exception:\n            if ignore_errors:\n                pass\n            else:\n                raise\n\n    # filter out layers already registered in geonode\n    dataset_names = Dataset.objects.values_list('alternate', flat=True)\n    if skip_geonode_registered:\n        try:\n            resources = [k for k in resources\n                         if f'{k.workspace.name}:{k.name}' not in dataset_names]\n        except Exception:\n            if ignore_errors:\n                pass\n            else:\n                raise\n\n    # TODO: Should we do something with these?\n    # i.e. look for matching layers in GeoNode and also disable?\n    # disabled_resources = [k for k in resources if k.enabled == \"false\"]\n\n    number = len(resources)\n    if verbosity > 0:\n        msg = \"Found %d layers, starting processing\" % number\n        print(msg, file=console)\n    output = {\n        'stats': {\n            'failed': 0,\n            'updated': 0,\n            'created': 0,\n            'deleted': 0,\n        },\n        'layers': [],\n        'deleted_datasets': []\n    }\n    start = datetime.datetime.now(timezone.get_current_timezone())\n    for i, resource in enumerate(resources):\n        name = resource.name\n        the_store = resource.store\n        workspace = the_store.workspace\n        layer = None\n        try:\n            created = False\n            layer = Dataset.objects.filter(name=name, workspace=workspace.name).first()\n            if not layer:\n                layer = resource_manager.create(\n                    str(uuid.uuid4()),\n                    resource_type=Dataset,\n                    defaults=dict(\n                        name=name,\n                        workspace=workspace.name,\n                        store=the_store.name,\n                        subtype=get_dataset_storetype(the_store.resource_type),\n                        alternate=f\"{workspace.name}:{resource.name}\",\n                        title=resource.title or _('No title provided'),\n                        abstract=resource.abstract or _('No abstract provided'),\n                        owner=owner\n                    )\n                )\n                created = True\n            # Hide the resource until finished\n            layer.set_processing_state(\"RUNNING\")\n            bbox = resource.native_bbox\n            ll_bbox = resource.latlon_bbox\n            try:\n                layer.set_bbox_polygon([bbox[0], bbox[2], bbox[1], bbox[3]], resource.projection)\n            except GeoNodeException as e:\n                if not ll_bbox:\n                    raise\n                else:\n                    logger.exception(e)\n                    layer.srid = 'EPSG:4326'\n            layer.set_ll_bbox_polygon([ll_bbox[0], ll_bbox[2], ll_bbox[1], ll_bbox[3]])\n\n            # sync permissions in GeoFence\n            perm_spec = json.loads(_perms_info_json(layer))\n            resource_manager.set_permissions(\n                layer.uuid,\n                permissions=perm_spec)\n\n            # recalculate the layer statistics\n            set_attributes_from_geoserver(layer, overwrite=True)\n\n            # in some cases we need to explicitily save the resource to execute the signals\n            # (for sure when running updatelayers)\n            resource_manager.update(\n                layer.uuid,\n                instance=layer,\n                notify=execute_signals)\n\n            # Creating the Thumbnail\n            resource_manager.set_thumbnail(\n                layer.uuid,\n                overwrite=True, check_bbox=False\n            )\n\n        except Exception as e:\n            # Hide the resource until finished\n            if layer:\n                layer.set_processing_state(\"FAILED\")\n            if ignore_errors:\n                status = 'failed'\n                exception_type, error, traceback = sys.exc_info()\n            else:\n                if verbosity > 0:\n                    msg = \"Stopping process because --ignore-errors was not set and an error was found.\"\n                    print(msg, file=sys.stderr)\n                raise Exception(f\"Failed to process {resource.name}\") from e\n        if layer is None:\n            if ignore_errors:\n                status = 'failed'\n                exception_type, error, traceback = sys.exc_info()\n            else:\n                if verbosity > 0:\n                    msg = \"Stopping process because --ignore-errors was not set and an error was found.\"\n                    print(msg, file=sys.stderr)\n                raise Exception(f\"Failed to process {resource.name}\")\n        else:\n            if created:\n                if not permissions:\n                    layer.set_default_permissions()\n                else:\n                    layer.set_permissions(permissions)\n\n                status = 'created'\n                output['stats']['created'] += 1\n            else:\n                status = 'updated'\n                output['stats']['updated'] += 1\n\n        msg = f\"[{status}] Dataset {name} ({(i + 1)}/{number})\"\n        info = {'name': name, 'status': status}\n        if status == 'failed':\n            output['stats']['failed'] += 1\n            info['traceback'] = traceback\n            info['exception_type'] = exception_type\n            info['error'] = error\n        output['layers'].append(info)\n        if verbosity > 0:\n            print(msg, file=console)\n\n    if remove_deleted:\n        q = Dataset.objects.filter()\n        if workspace_for_delete_compare is not None:\n            if isinstance(workspace_for_delete_compare, Workspace):\n                q = q.filter(\n                    workspace__exact=workspace_for_delete_compare.name)\n            else:\n                q = q.filter(workspace__exact=workspace_for_delete_compare)\n        if store is not None:\n            if isinstance(\n                    store,\n                    CoverageStore) or isinstance(\n                    store,\n                    DataStore):\n                q = q.filter(store__exact=store.name)\n            else:\n                q = q.filter(store__exact=store)\n        logger.debug(\"Executing 'remove_deleted' logic\")\n        logger.debug(\"GeoNode Layers Found:\")\n\n        # compare the list of GeoNode layers obtained via query/filter with valid resources found in GeoServer\n        # filtered per options passed to updatelayers: --workspace, --store, --skip-unadvertised\n        # add any layers not found in GeoServer to deleted_datasets (must match\n        # workspace and store as well):\n        deleted_datasets = []\n        for layer in q:\n            logger.debug(\n                \"GeoNode Dataset info: name: %s, workspace: %s, store: %s\",\n                layer.name,\n                layer.workspace,\n                layer.store)\n            dataset_found_in_geoserver = False\n            for resource in resources_for_delete_compare:\n                # if layer.name matches a GeoServer resource, check also that\n                # workspace and store match, mark valid:\n                if layer.name == resource.name:\n                    if layer.workspace == resource.workspace.name and layer.store == resource.store.name:\n                        logger.debug(\n                            \"Matches GeoServer layer: name: %s, workspace: %s, store: %s\",\n                            resource.name,\n                            resource.workspace.name,\n                            resource.store.name)\n                        dataset_found_in_geoserver = True\n            if not dataset_found_in_geoserver:\n                logger.debug(\n                    \"----- Dataset %s not matched, marked for deletion ---------------\",\n                    layer.name)\n                deleted_datasets.append(layer)\n\n        number_deleted = len(deleted_datasets)\n        if verbosity > 0:\n            msg = \"\\nFound %d layers to delete, starting processing\" % number_deleted if number_deleted > 0 else \\\n                \"\\nFound %d layers to delete\" % number_deleted\n            print(msg, file=console)\n\n        for i, layer in enumerate(deleted_datasets):\n            logger.debug(\n                \"GeoNode Dataset to delete: name: %s, workspace: %s, store: %s\",\n                layer.name,\n                layer.workspace,\n                layer.store)\n            try:\n                # delete ratings, and taggit tags:\n                ct = ContentType.objects.get_for_model(layer)\n                OverallRating.objects.filter(\n                    content_type=ct,\n                    object_id=layer.id).delete()\n                layer.keywords.clear()\n\n                layer.delete()\n                output['stats']['deleted'] += 1\n                status = \"delete_succeeded\"\n            except Exception:\n                status = \"delete_failed\"\n\n            msg = f\"[{status}] Dataset {layer.name} ({(i + 1)}/{number_deleted})\"\n            info = {'name': layer.name, 'status': status}\n            if status == \"delete_failed\":\n                exception_type, error, traceback = sys.exc_info()\n                info['traceback'] = traceback\n                info['exception_type'] = exception_type\n                info['error'] = error\n            output['deleted_datasets'].append(info)\n            if verbosity > 0:\n                print(msg, file=console)\n\n    finish = datetime.datetime.now(timezone.get_current_timezone())\n    td = finish - start\n    output['stats']['duration_sec'] = td.microseconds / \\\n        1000000 + td.seconds + td.days * 24 * 3600\n    return output\n\n\ndef get_stores(store_type=None):\n    cat = gs_catalog\n    stores = cat.get_stores()\n    store_list = []\n    for store in stores:\n        store.fetch()\n        stype = store.dom.find('type').text.lower()\n        if store_type and store_type.lower() == stype:\n            store_list.append({'name': store.name, 'type': stype})\n        elif store_type is None:\n            store_list.append({'name': store.name, 'type': stype})\n    return store_list\n\n\ndef set_attributes(\n        layer,\n        attribute_map,\n        overwrite=False,\n        attribute_stats=None):\n    \"\"\" *layer*: a geonode.layers.models.Dataset instance\n        *attribute_map*: a list of 2-lists specifying attribute names and types,\n            example: [ ['id', 'Integer'], ... ]\n        *overwrite*: replace existing attributes with new values if name/type matches.\n        *attribute_stats*: dictionary of return values from get_attribute_statistics(),\n            of the form to get values by referencing attribute_stats[<dataset_name>][<field_name>].\n    \"\"\"\n    # we need 3 more items; description, attribute_label, and display_order\n    attribute_map_dict = {\n        'field': 0,\n        'ftype': 1,\n        'description': 2,\n        'label': 3,\n        'display_order': 4,\n    }\n    for attribute in attribute_map:\n        if len(attribute) == 2:\n            attribute.extend((None, None, 0))\n\n    attributes = layer.attribute_set.all()\n    # Delete existing attributes if they no longer exist in an updated layer\n    for la in attributes:\n        lafound = False\n        for attribute in attribute_map:\n            field, ftype, description, label, display_order = attribute\n            if field == la.attribute:\n                lafound = True\n                # store description and attribute_label in attribute_map\n                attribute[attribute_map_dict['description']] = la.description\n                attribute[attribute_map_dict['label']] = la.attribute_label\n                attribute[attribute_map_dict['display_order']] = la.display_order\n        if overwrite or not lafound:\n            logger.debug(\n                \"Going to delete [%s] for [%s]\",\n                la.attribute,\n                layer.name)\n            la.delete()\n\n    # Add new layer attributes if they doesn't exist already\n    if attribute_map:\n        iter = len(Attribute.objects.filter(dataset=layer)) + 1\n        for attribute in attribute_map:\n            field, ftype, description, label, display_order = attribute\n            if field:\n                _gs_attrs = Attribute.objects.filter(dataset=layer, attribute=field)\n                if _gs_attrs.count() == 1:\n                    la = _gs_attrs.get()\n                else:\n                    if _gs_attrs.exists():\n                        _gs_attrs.delete()\n                    la = Attribute.objects.create(dataset=layer, attribute=field)\n                    la.visible = ftype.find(\"gml:\") != 0\n                    la.attribute_type = ftype\n                    la.description = description\n                    la.attribute_label = label\n                    la.display_order = iter\n                    iter += 1\n                if (not attribute_stats or layer.name not in attribute_stats or\n                        field not in attribute_stats[layer.name]):\n                    result = None\n                else:\n                    result = attribute_stats[layer.name][field]\n                if result:\n                    logger.debug(\"Generating layer attribute statistics\")\n                    la.count = result['Count']\n                    la.min = result['Min']\n                    la.max = result['Max']\n                    la.average = result['Average']\n                    la.median = result['Median']\n                    la.stddev = result['StandardDeviation']\n                    la.sum = result['Sum']\n                    la.unique_values = result['unique_values']\n                    la.last_stats_updated = datetime.datetime.now(timezone.get_current_timezone())\n                try:\n                    la.save()\n                except Exception as e:\n                    logger.exception(e)\n    else:\n        logger.debug(\"No attributes found\")\n\n\ndef set_attributes_from_geoserver(layer, overwrite=False):\n    \"\"\"\n    Retrieve layer attribute names & types from Geoserver,\n    then store in GeoNode database using Attribute model\n    \"\"\"\n    attribute_map = []\n    if getattr(layer, 'remote_service') and layer.remote_service:\n        server_url = layer.remote_service.service_url\n        if layer.remote_service.operations.get('GetCapabilities', None) and layer.remote_service.operations.get('GetCapabilities').get('methods'):\n            for _method in layer.remote_service.operations.get('GetCapabilities').get('methods'):\n                if _method.get('type', '').upper() == 'GET':\n                    server_url = _method.get('url', server_url)\n                    break\n    else:\n        server_url = ogc_server_settings.LOCATION\n    if layer.subtype in ['tileStore', 'remote'] and layer.remote_service.ptype == \"gxp_arcrestsource\":\n        dft_url = f\"{server_url}{(layer.alternate or layer.typename)}?f=json\"\n        try:\n            # The code below will fail if http_client cannot be imported\n            req, body = http_client.get(dft_url, user=_user)\n            body = json.loads(body)\n            attribute_map = [[n[\"name\"], _esri_types[n[\"type\"]]]\n                             for n in body[\"fields\"] if n.get(\"name\") and n.get(\"type\")]\n        except Exception:\n            tb = traceback.format_exc()\n            logger.debug(tb)\n            attribute_map = []\n    elif layer.subtype in {\"vector\", \"tileStore\", \"remote\", \"wmsStore\", \"vector_time\"}:\n        typename = layer.alternate if layer.alternate else layer.typename\n        dft_url_path = re.sub(r\"\\/wms\\/?$\", \"/\", server_url)\n        dft_query = urlencode(\n            {\n                \"service\": \"wfs\",\n                \"version\": \"1.0.0\",\n                \"request\": \"DescribeFeatureType\",\n                \"typename\": typename\n            }\n        )\n        dft_url = urljoin(dft_url_path, f\"ows?{dft_query}\")\n        try:\n            # The code below will fail if http_client cannot be imported or WFS not supported\n            req, body = http_client.get(dft_url, user=_user)\n            doc = dlxml.fromstring(body.encode())\n            xsd = \"{http://www.w3.org/2001/XMLSchema}\"\n            path = f\".//{xsd}extension/{xsd}sequence/{xsd}element\"\n            attribute_map = [[n.attrib[\"name\"], n.attrib[\"type\"]] for n in doc.findall(\n                path) if n.attrib.get(\"name\") and n.attrib.get(\"type\")]\n        except Exception:\n            tb = traceback.format_exc()\n            logger.debug(tb)\n            attribute_map = []\n            # Try WMS instead\n            dft_url = server_url + \"?\" + urlencode({\n                \"service\": \"wms\",\n                \"version\": \"1.0.0\",\n                \"request\": \"GetFeatureInfo\",\n                \"bbox\": ','.join([str(x) for x in layer.bbox]),\n                \"LAYERS\": layer.alternate,\n                \"QUERY_LAYERS\": typename,\n                \"feature_count\": 1,\n                \"width\": 1,\n                \"height\": 1,\n                \"srs\": \"EPSG:4326\",\n                \"info_format\": \"text/html\",\n                \"x\": 1,\n                \"y\": 1\n            })\n            try:\n                req, body = http_client.get(dft_url, user=_user)\n                soup = BeautifulSoup(body, features=\"lxml\")\n                for field in soup.findAll('th'):\n                    if field.string is None:\n                        field_name = field.contents[0].string\n                    else:\n                        field_name = field.string\n                    attribute_map.append([field_name, \"xsd:string\"])\n            except Exception:\n                tb = traceback.format_exc()\n                logger.debug(tb)\n                attribute_map = []\n    elif layer.subtype in [\"raster\"]:\n        typename = layer.alternate if layer.alternate else layer.typename\n        dc_url = f\"{server_url}wcs?{urlencode({'service': 'wcs', 'version': '1.1.0', 'request': 'DescribeCoverage', 'identifiers': typename})}\"\n        try:\n            req, body = http_client.get(dc_url, user=_user)\n            doc = dlxml.fromstring(body.encode())\n            wcs = \"{http://www.opengis.net/wcs/1.1.1}\"\n            path = f\".//{wcs}Axis/{wcs}AvailableKeys/{wcs}Key\"\n            attribute_map = [[n.text, \"raster\"] for n in doc.findall(path)]\n        except Exception:\n            tb = traceback.format_exc()\n            logger.debug(tb)\n            attribute_map = []\n    # Get attribute statistics & package for call to really_set_attributes()\n    attribute_stats = defaultdict(dict)\n    # Add new layer attributes if they don't already exist\n    for attribute in attribute_map:\n        field, ftype = attribute\n        if field is not None:\n            if Attribute.objects.filter(dataset=layer, attribute=field).exists():\n                continue\n            elif is_dataset_attribute_aggregable(\n                    layer.subtype,\n                    field,\n                    ftype):\n                logger.debug(\"Generating layer attribute statistics\")\n                result = get_attribute_statistics(layer.alternate or layer.typename, field)\n            else:\n                result = None\n            attribute_stats[layer.name][field] = result\n    set_attributes(\n        layer, attribute_map, overwrite=overwrite, attribute_stats=attribute_stats\n    )\n\n\ndef get_dataset(layer, gs_catalog: Catalog):\n    gs_catalog.reset()\n    gs_dataset = None\n    try:\n        gs_dataset = gs_catalog.get_layer(layer.name)\n    except Exception:\n        tb = traceback.format_exc()\n        logger.exception(tb)\n\n    if not gs_dataset:\n        try:\n            gs_dataset = gs_catalog.get_layer(layer.alternate or layer.typename)\n        except Exception:\n            tb = traceback.format_exc()\n            logger.error(tb)\n            logger.exception(\"No GeoServer Dataset found!\")\n    return gs_dataset\n\n\ndef clean_styles(layer, gs_catalog: Catalog):\n    try:\n        # Cleanup Styles without a Workspace\n        gs_catalog.reset()\n        gs_dataset = get_dataset(layer, gs_catalog)\n        logger.debug(f'clean_styles: Retrieving style \"{gs_dataset.default_style.name}\" for cleanup')\n        style = gs_catalog.get_style(\n            name=gs_dataset.default_style.name,\n            workspace=None,\n            recursive=True)\n        if style:\n            gs_catalog.delete(style, purge=True, recurse=False)\n            logger.debug(f'clean_styles: Style removed: {gs_dataset.default_style.name}')\n        else:\n            logger.debug(f'clean_styles: Style does not exist: {gs_dataset.default_style.name}')\n    except Exception as e:\n        logger.warning(f'Could not clean style for layer {layer.name}', exc_info=e)\n        logger.debug(f'Could not clean style for layer {layer.name} - STACK INFO', stack_info=True)\n\n\ndef set_styles(layer, gs_catalog: Catalog):\n    style_set = []\n    gs_dataset = get_dataset(layer, gs_catalog)\n    if gs_dataset:\n        default_style = gs_dataset.get_full_default_style()\n        if default_style:\n            # make sure we are not using a default SLD (which won't be editable)\n            layer.default_style, _gs_default_style = save_style(default_style, layer)\n            try:\n                if default_style.name != _gs_default_style.name or default_style.workspace != _gs_default_style.workspace:\n                    logger.debug(f'set_style: Setting default style \"{_gs_default_style.name}\" for layer \"{layer.name}')\n\n                    gs_dataset.default_style = _gs_default_style\n                    gs_catalog.save(gs_dataset)\n                    if default_style.name not in DEFAULT_STYLE_NAME:\n                        logger.debug(f'set_style: Retrieving no-workspace default style \"{default_style.name}\" for deletion')\n                        style_to_delete = gs_catalog.get_style(name=default_style.name, workspace=None, recursive=True)\n                        if style_to_delete:\n                            gs_catalog.delete(style_to_delete, purge=True, recurse=False)\n                            logger.debug(f'set_style: No-ws default style deleted: {default_style.name}')\n                        else:\n                            logger.debug(f'set_style: No-ws default style does not exist: {default_style.name}')\n            except Exception as e:\n                logger.error(f'Error setting default style \"{_gs_default_style.name}\" for layer \"{layer.name}', exc_info=e)\n\n            style_set.append(layer.default_style)\n\n        try:\n            if gs_dataset.styles:\n                alt_styles = gs_dataset.styles\n                for alt_style in alt_styles:\n                    if alt_style and alt_style.name and alt_style.name != layer.default_style.name and alt_style.workspace != layer.default_style.workspace:\n                        _s, _ = save_style(alt_style, layer)\n                        style_set.append(_s)\n        except Exception as e:\n            logger.exception(e)\n\n    if style_set:\n        # Remove duplicates\n        style_set = list(dict.fromkeys(style_set))\n        layer.styles.set(style_set)\n\n    clean_styles(layer, gs_catalog)\n\n    # Update default style to database\n    to_update = {\n        'default_style': layer.default_style\n    }\n\n    Dataset.objects.filter(id=layer.id).update(**to_update)\n    layer.refresh_from_db()\n\n    # Legend links\n    logger.debug(f\" -- Resource Links[Legend link] for layer {layer.name}...\")\n    try:\n        from geonode.base.models import Link\n        dataset_legends = Link.objects.filter(resource=layer.resourcebase_ptr, name='Legend')\n        for style in set(list(layer.styles.all()) + [layer.default_style, ]):\n            if style:\n                style_name = os.path.basename(\n                    urlparse(style.sld_url).path).split('.')[0]\n                legend_url = get_legend_url(layer, style_name)\n                if dataset_legends.filter(resource=layer.resourcebase_ptr, name='Legend', url=legend_url).count() < 2:\n                    Link.objects.update_or_create(\n                        resource=layer.resourcebase_ptr,\n                        name='Legend',\n                        url=legend_url,\n                        defaults=dict(\n                            extension='png',\n                            url=legend_url,\n                            mime='image/png',\n                            link_type='image',\n                        )\n                    )\n        logger.debug(\" -- Resource Links[Legend link]...done!\")\n    except Exception as e:\n        logger.debug(f\" -- Resource Links[Legend link]...error: {e}\")\n\n    try:\n        set_geowebcache_invalidate_cache(layer.alternate or layer.typename, cat=gs_catalog)\n    except Exception:\n        tb = traceback.format_exc()\n        logger.debug(tb)\n\n\ndef save_style(gs_style, layer):\n    style_name = os.path.basename(\n        urlparse(gs_style.body_href).path).split('.')[0]\n    sld_name = copy.copy(gs_style.name)\n    sld_body = copy.copy(gs_style.sld_body)\n    _gs_style = None\n    if not gs_style.workspace:\n        logger.debug(f'save_style: Copying style \"{sld_name}\" to \"{layer.workspace}:{layer.name}')\n        _gs_style = gs_catalog.create_style(\n            layer.name, sld_body,\n            raw=True, overwrite=True,\n            workspace=layer.workspace)\n    else:\n        logger.debug(f'save_style: Retrieving style \"{layer.workspace}:{sld_name}\" for layer \"{layer.workspace}:{layer.name}')\n        _gs_style = gs_catalog.get_style(\n            name=sld_name,\n            workspace=layer.workspace\n        )\n\n    style = None\n    try:\n        style, _ = Style.objects.get_or_create(name=style_name)\n        style.workspace = _gs_style.workspace\n        style.sld_title = _gs_style.sld_title if _gs_style.style_format != 'css' and _gs_style.sld_title else sld_name\n        style.sld_body = _gs_style.sld_body\n        style.sld_url = _gs_style.body_href\n        style.save()\n    except Exception as e:\n        tb = traceback.format_exc()\n        logger.debug(tb)\n        raise e\n    return (style, _gs_style)\n\n\ndef is_dataset_attribute_aggregable(store_type, field_name, field_type):\n    \"\"\"\n    Decipher whether layer attribute is suitable for statistical derivation\n    \"\"\"\n\n    # must be vector layer\n    if store_type != 'dataStore':\n        return False\n    # must be a numeric data type\n    if field_type not in LAYER_ATTRIBUTE_NUMERIC_DATA_TYPES:\n        return False\n    # must not be an identifier type field\n    if field_name.lower() in {'id', 'identifier'}:\n        return False\n\n    return True\n\n\ndef get_attribute_statistics(dataset_name, field):\n    \"\"\"\n    Generate statistics (range, mean, median, standard deviation, unique values)\n    for layer attribute\n    \"\"\"\n\n    logger.debug('Deriving aggregate statistics for attribute %s', field)\n\n    if not ogc_server_settings.WPS_ENABLED:\n        return None\n    try:\n        return wps_execute_dataset_attribute_statistics(dataset_name, field)\n    except Exception:\n        tb = traceback.format_exc()\n        logger.debug(tb)\n        logger.exception('Error generating layer aggregate statistics')\n\n\ndef get_wcs_record(instance, retry=True):\n    wcs = WebCoverageService(f\"{ogc_server_settings.LOCATION}wcs\", '1.0.0')\n    key = f\"{instance.workspace}:{instance.name}\"\n    logger.debug(wcs.contents)\n    if key in wcs.contents:\n        return wcs.contents[key]\n    else:\n        msg = (f\"Dataset '{key}' was not found in WCS service at {ogc_server_settings.public_url}.\"\n               )\n        if retry:\n            logger.debug(\n                f\"{msg} Waiting a couple of seconds before trying again.\")\n            time.sleep(2)\n            return get_wcs_record(instance, retry=False)\n        else:\n            raise GeoNodeException(msg)\n\n\ndef get_coverage_grid_extent(instance):\n    \"\"\"\n        Returns a list of integers with the size of the coverage\n        extent in pixels\n    \"\"\"\n    instance_wcs = get_wcs_record(instance)\n    grid = instance_wcs.grid\n    return [(int(h) - int(l) + 1) for\n            h, l in zip(grid.highlimits, grid.lowlimits)]\n\n\nGEOSERVER_LAYER_TYPES = {\n    'vector': FeatureType.resource_type,\n    'raster': Coverage.resource_type,\n}\n\n\ndef cleanup(name, uuid):\n    \"\"\"Deletes GeoServer and Catalogue records for a given name.\n       Useful to clean the mess when something goes terribly wrong.\n       It also verifies if the Django record existed, in which case\n       it performs no action.\n    \"\"\"\n    try:\n        Dataset.objects.get(name=name)\n    except Dataset.DoesNotExist:\n        pass\n    else:\n        msg = f'Not doing any cleanup because the layer {name} exists in the Django db.'\n        raise GeoNodeException(msg)\n\n    cat = gs_catalog\n    gs_store = None\n    gs_dataset = None\n    gs_resource = None\n    # FIXME: Could this lead to someone deleting for example a postgis db\n    # with the same name of the uploaded file?.\n    try:\n        gs_store = cat.get_store(name)\n        if gs_store is not None:\n            gs_dataset = cat.get_layer(name)\n            if gs_dataset is not None:\n                gs_resource = gs_dataset.resource\n        else:\n            gs_dataset = None\n            gs_resource = None\n    except FailedRequestError as e:\n        msg = ('Couldn\\'t connect to GeoServer while cleaning up layer '\n               '[%s] !!', str(e))\n        logger.warning(msg)\n\n    if gs_dataset is not None:\n        try:\n            cat.delete(gs_dataset)\n        except Exception:\n            logger.warning(\"Couldn't delete GeoServer layer during cleanup()\")\n    if gs_resource is not None:\n        try:\n            cat.delete(gs_resource)\n        except Exception:\n            msg = 'Couldn\\'t delete GeoServer resource during cleanup()'\n            logger.warning(msg)\n    if gs_store is not None:\n        try:\n            cat.delete(gs_store)\n        except Exception:\n            logger.warning(\"Couldn't delete GeoServer store during cleanup()\")\n\n    logger.warning('Deleting dangling Catalogue record for [%s] '\n                   '(no Django record to match)', name)\n\n    if 'geonode.catalogue' in settings.INSTALLED_APPS:\n        from geonode.catalogue import get_catalogue\n        catalogue = get_catalogue()\n        catalogue.remove_record(uuid)\n        logger.warning('Finished cleanup after failed Catalogue/Django '\n                       'import for layer: %s', name)\n\n\ndef create_geoserver_db_featurestore(\n        store_type=None, store_name=None,\n        author_name='admin', author_email='admin@geonode.org',\n        charset=\"UTF-8\", workspace=None):\n    cat = gs_catalog\n    dsname = store_name or ogc_server_settings.DATASTORE\n    # get or create datastore\n    ds_exists = False\n    try:\n        if dsname:\n            ds = cat.get_store(dsname, workspace=workspace)\n        else:\n            return None\n        if ds is None:\n            raise FailedRequestError\n        ds_exists = True\n    except FailedRequestError:\n        logger.debug(\n            f'Creating target datastore {dsname}')\n        ds = cat.create_datastore(dsname, workspace=workspace)\n        db = ogc_server_settings.datastore_db\n        db_engine = 'postgis' if \\\n            'postgis' in db['ENGINE'] else db['ENGINE']\n        ds.connection_parameters.update(\n            {'Evictor run periodicity': 300,\n             'Estimated extends': 'true',\n             'fetch size': 100000,\n             'encode functions': 'false',\n             'Expose primary keys': 'true',\n             'validate connections': 'true',\n             'Support on the fly geometry simplification': 'false',\n             'Connection timeout': 10,\n             'create database': 'false',\n             'Batch insert size': 30,\n             'preparedStatements': 'true',\n             'min connections': 10,\n             'max connections': 100,\n             'Evictor tests per run': 3,\n             'Max connection idle time': 300,\n             'Loose bbox': 'true',\n             'Test while idle': 'true',\n             'host': db['HOST'],\n             'port': db['PORT'] if isinstance(\n                 db['PORT'], str) else str(db['PORT']) or '5432',\n             'database': db['NAME'],\n             'user': db['USER'],\n             'passwd': db['PASSWORD'],\n             'dbtype': db_engine}\n        )\n\n    if ds_exists:\n        ds.save_method = \"PUT\"\n    else:\n        logger.debug('Updating target datastore % s' % dsname)\n        try:\n            cat.save(ds)\n        except FailedRequestError as e:\n            if 'already exists in workspace' not in e.args[0]:\n                raise e\n            logger.warning(\"The store was already present in the workspace selected\")\n\n    logger.debug('Reloading target datastore % s' % dsname)\n    ds = get_store(cat, dsname, workspace=workspace)\n    assert ds.enabled\n\n    return ds\n\n\ndef _create_featurestore(name, data, overwrite=False, charset=\"UTF-8\", workspace=None):\n\n    cat = gs_catalog\n    cat.create_featurestore(name, data, workspace=workspace, overwrite=overwrite, charset=charset)\n    store = get_store(cat, name, workspace=workspace)\n    return store, cat.get_resource(name=name, store=store, workspace=workspace)\n\n\ndef _create_coveragestore(name, data, overwrite=False, charset=\"UTF-8\", workspace=None):\n    cat = gs_catalog\n    cat.create_coveragestore(name, path=data, workspace=workspace, overwrite=overwrite, upload_data=True)\n    store = get_store(cat, name, workspace=workspace)\n    return store, cat.get_resource(name=name, store=store, workspace=workspace)\n\n\ndef _create_db_featurestore(name, data, overwrite=False, charset=\"UTF-8\", workspace=None):\n    \"\"\"Create a database store then use it to import a shapefile.\n\n    If the import into the database fails then delete the store\n    (and delete the PostGIS table for it).\n    \"\"\"\n    cat = gs_catalog\n    db = ogc_server_settings.datastore_db\n    # dsname = ogc_server_settings.DATASTORE\n    dsname = db['NAME']\n    ds = create_geoserver_db_featurestore(store_name=dsname, workspace=workspace)\n\n    try:\n        cat.add_data_to_store(ds,\n                              name,\n                              data,\n                              overwrite=overwrite,\n                              workspace=workspace,\n                              charset=charset)\n        resource = cat.get_resource(name=name, store=ds, workspace=workspace)\n        assert resource is not None\n        return ds, resource\n    except Exception:\n        msg = _(\"An exception occurred loading data to PostGIS\")\n        msg += f\"- {sys.exc_info()[1]}\"\n        try:\n            delete_from_postgis(name, ds)\n        except Exception:\n            msg += _(\" Additionally an error occured during database cleanup\")\n            msg += f\"- {sys.exc_info()[1]}\"\n        raise GeoNodeException(msg)\n\n\ndef get_store(cat, name, workspace=None):\n    # Make sure workspace is a workspace object and not a string.\n    # If the workspace does not exist, continue as if no workspace had been defined.\n    if isinstance(workspace, str):\n        workspace = cat.get_workspace(workspace)\n\n    if workspace is None:\n        workspace = cat.get_default_workspace()\n\n    if workspace:\n        try:\n            store = cat.get_xml(f'{workspace.datastore_url[:-4]}/{name}.xml')\n        except FailedRequestError:\n            try:\n                store = cat.get_xml(f'{workspace.coveragestore_url[:-4]}/{name}.xml')\n            except FailedRequestError:\n                try:\n                    store = cat.get_xml(f'{workspace.wmsstore_url[:-4]}/{name}.xml')\n                except FailedRequestError:\n                    raise FailedRequestError(f\"No store found named: {name}\")\n        if store:\n            if store.tag == 'dataStore':\n                store = datastore_from_index(cat, workspace, store)\n            elif store.tag == 'coverageStore':\n                store = coveragestore_from_index(cat, workspace, store)\n            elif store.tag == 'wmsStore':\n                store = wmsstore_from_index(cat, workspace, store)\n            return store\n        else:\n            raise FailedRequestError(f\"No store found named: {name}\")\n    else:\n        raise FailedRequestError(f\"No store found named: {name}\")\n\n\ndef fetch_gs_resource(instance, values, tries):\n    _max_tries = getattr(ogc_server_settings, \"MAX_RETRIES\", 2)\n    try:\n        gs_resource = gs_catalog.get_resource(\n            name=instance.name,\n            store=instance.store,\n            workspace=instance.workspace)\n    except Exception:\n        try:\n            gs_resource = gs_catalog.get_resource(\n                name=instance.alternate,\n                store=instance.store,\n                workspace=instance.workspace)\n        except Exception:\n            try:\n                gs_resource = gs_catalog.get_resource(\n                    name=instance.alternate or instance.typename)\n            except Exception:\n                gs_resource = None\n    if gs_resource:\n        if values:\n            gs_resource.title = values.get('title', '')\n            gs_resource.abstract = values.get('abstract', '')\n        else:\n            values = {}\n\n        _subtype = gs_resource.store.resource_type\n        if getattr(gs_resource, 'metadata', None) and gs_resource.metadata.get('time', False) and gs_resource.metadata.get('time').enabled:\n            _subtype = \"vectorTimeSeries\"\n\n        values.update(dict(store=gs_resource.store.name,\n                           subtype=_subtype,\n                           alternate=f\"{gs_resource.store.workspace.name}:{gs_resource.name}\",\n                           title=gs_resource.title or gs_resource.store.name,\n                           abstract=gs_resource.abstract or '',\n                           owner=instance.owner))\n    else:\n        msg = f\"There isn't a geoserver resource for this layer: {instance.name}\"\n        logger.debug(msg)\n        if tries >= _max_tries:\n            # raise GeoNodeException(msg)\n            return (values, None)\n        gs_resource = None\n    return (values, gs_resource)\n\n\ndef wps_execute_dataset_attribute_statistics(dataset_name, field):\n    \"\"\"Derive aggregate statistics from WPS endpoint\"\"\"\n\n    # generate statistics using WPS\n    url = urljoin(ogc_server_settings.LOCATION, 'ows')\n\n    request = render_to_string('layers/wps_execute_gs_aggregate.xml', {\n                               'dataset_name': dataset_name,\n                               'field': field\n                               })\n    u = urlsplit(url)\n\n    headers = {\n        'User-Agent': 'OWSLib (https://geopython.github.io/OWSLib)',\n        'Content-type': 'text/xml',\n        'Accept': 'text/xml',\n        'Accept-Language': 'en-US',\n        'Accept-Encoding': 'gzip,deflate',\n        'Host': u.netloc,\n    }\n\n    response, content = http_client.request(\n        url,\n        method='POST',\n        data=request,\n        headers=headers,\n        user=_user,\n        timeout=5,\n        retries=1)\n\n    exml = dlxml.fromstring(content.encode())\n\n    result = {}\n\n    for f in ['Min', 'Max', 'Average', 'Median', 'StandardDeviation', 'Sum']:\n        fr = exml.find(f)\n        if fr is not None:\n            result[f] = fr.text\n        else:\n            result[f] = 'NA'\n\n    count = exml.find('Count')\n    if count is not None:\n        result['Count'] = int(count.text)\n    else:\n        result['Count'] = 0\n\n    result['unique_values'] = 'NA'\n\n    return result\n\n\ndef _stylefilterparams_geowebcache_dataset(dataset_name):\n    headers = {\n        \"Content-Type\": \"text/xml\"\n    }\n    url = f'{ogc_server_settings.LOCATION}gwc/rest/layers/{dataset_name}.xml'\n\n    # read GWC configuration\n    req, content = http_client.get(\n        url,\n        headers=headers,\n        user=_user)\n    if req.status_code != 200:\n        logger.error(\n            f\"Error {req.status_code} reading Style Filter Params GeoWebCache at {url}\"\n        )\n        return\n\n    # check/write GWC filter parameters\n    body = None\n    tree = dlxml.fromstring(_)\n    param_filters = tree.findall('parameterFilters')\n    if param_filters and len(param_filters) > 0:\n        if not param_filters[0].findall('styleParameterFilter'):\n            style_filters_xml = \"<styleParameterFilter><key>STYLES</key>\\\n                <defaultValue></defaultValue></styleParameterFilter>\"\n            style_filters_elem = dlxml.fromstring(style_filters_xml)\n            param_filters[0].append(style_filters_elem)\n            body = ET.tostring(tree)\n    if body:\n        req, content = http_client.post(\n            url,\n            data=body,\n            headers=headers,\n            user=_user)\n        if req.status_code != 200:\n            logger.error(\n                f\"Error {req.status_code} writing Style Filter Params GeoWebCache at {url}\"\n            )\n\n\ndef _invalidate_geowebcache_dataset(dataset_name, url=None):\n    # http.add_credentials(username, password)\n    headers = {\n        \"Content-Type\": \"text/xml\",\n    }\n    body = f\"\"\"\n        <truncateLayer><layerName>{dataset_name}</layerName></truncateLayer>\n        \"\"\".strip()\n    if not url:\n        url = f'{ogc_server_settings.LOCATION}gwc/rest/masstruncate'\n    req, content = http_client.post(\n        url,\n        data=body,\n        headers=headers,\n        user=_user)\n\n    if req.status_code != 200:\n        logger.debug(\n            f\"Error {req.status_code} invalidating GeoWebCache at {url}\"\n        )\n\n\ndef style_update(request, url, workspace=None):\n    \"\"\"\n    Sync style stuff from GS to GN.\n    Ideally we should call this from a view straight from GXP, and we should use\n    gsConfig, that at this time does not support styles updates. Before gsConfig\n    is updated, for now we need to parse xml.\n    In case of a DELETE, we need to query request.path to get the style name,\n    and then remove it.\n    In case of a POST or PUT, we need to parse the xml from\n    request.body, which is in this format:\n    \"\"\"\n    affected_datasets = []\n    if request.method in ('POST', 'PUT', 'DELETE'):  # we need to parse xml\n        # Need to remove NSx from IE11\n        if \"HTTP_USER_AGENT\" in request.META:\n            if ('Trident/7.0' in request.META['HTTP_USER_AGENT'] and\n                    'rv:11.0' in request.META['HTTP_USER_AGENT']):\n                txml = re.sub(r'xmlns:NS[0-9]=\"\"', '', request.body)\n                txml = re.sub(r'NS[0-9]:', '', txml)\n                request._body = txml\n        style_name = os.path.basename(request.path)\n        sld_title = style_name\n        sld_body = None\n        sld_url = url\n        dataset_name = None\n        if 'name' in request.GET:\n            style_name = request.GET['name']\n            sld_body = request.body\n        elif request.method == 'DELETE':\n            style_name = os.path.basename(request.path)\n        else:\n            sld_body = request.body\n            gs_style = gs_catalog.get_style(name=style_name) or gs_catalog.get_style(name=style_name, workspace=workspace)\n            if gs_style:\n                sld_title = gs_style.sld_title if gs_style.style_format != 'css' and gs_style.sld_title else style_name\n                sld_body = gs_style.sld_body\n                sld_url = gs_style.body_href\n            else:\n                try:\n                    tree = ET.ElementTree(dlxml.fromstring(request.body))\n                    elm_nameddataset_name = tree.findall(\n                        './/{http://www.opengis.net/sld}Name')[0]\n                    elm_user_style_name = tree.findall(\n                        './/{http://www.opengis.net/sld}Name')[1]\n                    elm_user_style_title = tree.find(\n                        './/{http://www.opengis.net/sld}Title')\n                    dataset_name = elm_nameddataset_name.text\n                    if elm_user_style_title is None:\n                        sld_title = elm_user_style_name.text\n                    else:\n                        sld_title = elm_user_style_title.text\n                    sld_body = f'<?xml version=\"1.0\" encoding=\"UTF-8\"?>{request.body}'\n                except Exception:\n                    logger.warn(\"Could not recognize Style and Dataset name from Request!\")\n\n        # add style in GN and associate it to layer\n        if request.method == 'DELETE':\n            if style_name:\n                Style.objects.filter(name=style_name).delete()\n        if request.method == 'POST':\n            style = None\n            if style_name and not re.match(temp_style_name_regex, style_name):\n                style, created = Style.objects.get_or_create(name=style_name)\n                style.workspace = workspace\n                style.sld_body = sld_body\n                style.sld_url = sld_url\n                style.sld_title = sld_title\n                style.save()\n            layer = None\n            if dataset_name:\n                try:\n                    layer = Dataset.objects.get(name=dataset_name)\n                except Exception:\n                    try:\n                        layer = Dataset.objects.get(alternate=dataset_name)\n                    except Exception:\n                        pass\n            if layer:\n                if style:\n                    style.dataset_styles.add(layer)\n                    style.save()\n                affected_datasets.append(layer)\n        elif request.method == 'PUT':  # update style in GN\n            if style_name and not re.match(temp_style_name_regex, style_name):\n                style, created = Style.objects.get_or_create(name=style_name)\n                style.workspace = workspace\n                style.sld_body = sld_body\n                style.sld_url = sld_url\n                style.sld_title = sld_title\n                style.save()\n                for layer in style.dataset_styles.all():\n                    affected_datasets.append(layer)\n\n        # Invalidate GeoWebCache so it doesn't retain old style in tiles\n        try:\n            if dataset_name:\n                _stylefilterparams_geowebcache_dataset(dataset_name)\n                _invalidate_geowebcache_dataset(dataset_name)\n        except Exception:\n            pass\n    return affected_datasets\n\n\ndef set_time_info(layer, attribute, end_attribute, presentation,\n                  precision_value, precision_step, enabled=True):\n    '''Configure the time dimension for a layer.\n\n    :param layer: the layer to configure\n    :param attribute: the attribute used to represent the instant or period\n                      start\n    :param end_attribute: the optional attribute used to represent the end\n                          period\n    :param presentation: either 'LIST', 'DISCRETE_INTERVAL', or\n                         'CONTINUOUS_INTERVAL'\n    :param precision_value: number representing number of steps\n    :param precision_step: one of 'seconds', 'minutes', 'hours', 'days',\n                           'months', 'years'\n    :param enabled: defaults to True\n    '''\n    layer = gs_catalog.get_layer(layer.name)\n    if layer is None:\n        raise ValueError(f'no such layer: {layer.name}')\n    resource = layer.resource if layer else None\n    if not resource:\n        resources = gs_catalog.get_resources(stores=[layer.name])\n        if resources:\n            resource = resources[0]\n\n    resolution = None\n    if precision_value and precision_step:\n        resolution = f'{precision_value} {precision_step}'\n    info = DimensionInfo(\"time\", enabled, presentation, resolution, \"ISO8601\",\n                         None, attribute=attribute, end_attribute=end_attribute)\n    if resource and resource.metadata:\n        metadata = dict(resource.metadata or {})\n    else:\n        metadata = dict({})\n    metadata['time'] = info\n\n    if resource and resource.metadata:\n        resource.metadata = metadata\n    if resource:\n        gs_catalog.save(resource)\n\n\ndef get_time_info(layer):\n    '''Get the configured time dimension metadata for the layer as a dict.\n\n    The keys of the dict will be those of the parameters of `set_time_info`.\n\n    :returns: dict of values or None if not configured\n    '''\n    layer = gs_catalog.get_layer(layer.name)\n    if layer is None:\n        raise ValueError(f'no such layer: {layer.name}')\n    resource = layer.resource if layer else None\n    if not resource:\n        resources = gs_catalog.get_resources(stores=[layer.name])\n        if resources:\n            resource = resources[0]\n\n    info = resource.metadata.get('time', None) if resource.metadata else None\n    vals = None\n    if info:\n        value = step = None\n        resolution = info.resolution_str()\n        if resolution:\n            value, step = resolution.split()\n        vals = dict(\n            enabled=info.enabled,\n            attribute=info.attribute,\n            end_attribute=info.end_attribute,\n            presentation=info.presentation,\n            precision_value=value,\n            precision_step=step,\n        )\n    return vals\n\n\nogc_server_settings = OGC_Servers_Handler(settings.OGC_SERVER)['default']\n\n_wms = None\n_csw = None\n_user, _password = ogc_server_settings.credentials\n\nurl = ogc_server_settings.rest\ngs_catalog = Catalog(url, _user, _password,\n                     retries=ogc_server_settings.MAX_RETRIES,\n                     backoff_factor=ogc_server_settings.BACKOFF_FACTOR)\ngs_uploader = Client(url, _user, _password)\n\n_punc = re.compile(r\"[\\.:]\")  # regex for punctuation that confuses restconfig\n_foregrounds = [\n    \"#ffbbbb\",\n    \"#bbffbb\",\n    \"#bbbbff\",\n    \"#ffffbb\",\n    \"#bbffff\",\n    \"#ffbbff\"]\n_backgrounds = [\n    \"#880000\",\n    \"#008800\",\n    \"#000088\",\n    \"#888800\",\n    \"#008888\",\n    \"#880088\"]\n_marks = [\"square\", \"circle\", \"cross\", \"x\", \"triangle\"]\n_style_contexts = zip(cycle(_foregrounds), cycle(_backgrounds), cycle(_marks))\n_default_style_names = [\"point\", \"line\", \"polygon\", \"raster\"]\n_esri_types = {\n    \"esriFieldTypeDouble\": \"xsd:double\",\n    \"esriFieldTypeString\": \"xsd:string\",\n    \"esriFieldTypeSmallInteger\": \"xsd:int\",\n    \"esriFieldTypeInteger\": \"xsd:int\",\n    \"esriFieldTypeDate\": \"xsd:dateTime\",\n    \"esriFieldTypeOID\": \"xsd:long\",\n    \"esriFieldTypeGeometry\": \"xsd:geometry\",\n    \"esriFieldTypeBlob\": \"xsd:base64Binary\",\n    \"esriFieldTypeRaster\": \"raster\",\n    \"esriFieldTypeGUID\": \"xsd:string\",\n    \"esriFieldTypeGlobalID\": \"xsd:string\",\n    \"esriFieldTypeXML\": \"xsd:anyType\"}\n\n\ndef _dump_image_spec(request_body, image_spec):\n    millis = int(round(time.time() * 1000))\n    try:\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            _request_body_file_name = os.path.join(\n                tmp_dir,\n                f\"request_body_{millis}.dump\")\n            _image_spec_file_name = os.path.join(\n                tmp_dir,\n                f\"image_spec_{millis}.dump\")\n            with open(_request_body_file_name, \"w\") as _request_body_file:\n                _request_body_file.write(f\"{request_body}\")\n            copyfile(\n                _request_body_file_name,\n                os.path.join(tempfile.gettempdir(), f\"request_body_{millis}.dump\"))\n            with open(_image_spec_file_name, \"w\") as _image_spec_file:\n                _image_spec_file.write(f\"{image_spec}\")\n            copyfile(\n                _image_spec_file_name,\n                os.path.join(tempfile.gettempdir(), f\"image_spec_{millis}.dump\"))\n        return f\"Dumping image_spec to: {os.path.join(tempfile.gettempdir(), f'image_spec_{millis}.dump')}\"\n    except Exception as e:\n        logger.exception(e)\n        return f\"Unable to dump image_spec for request: {request_body}\"\n\n\ndef mosaic_delete_first_granule(cat, layer):\n    # - since GeoNode will uploade the first granule again through the Importer, we need to /\n    #   delete the one created by the gs_config\n    cat._cache.clear()\n    store = cat.get_store(layer)\n    coverages = cat.mosaic_coverages(store)\n\n    granule_id = f\"{layer}.1\"\n\n    cat.mosaic_delete_granule(coverages['coverages']['coverage'][0]['name'], store, granule_id)\n\n\ndef set_time_dimension(cat, name, workspace, time_presentation, time_presentation_res, time_presentation_default_value,\n                       time_presentation_reference_value):\n    # configure the layer time dimension as LIST\n    presentation = time_presentation\n    if not presentation:\n        presentation = \"LIST\"\n\n    resolution = None\n    if time_presentation == 'DISCRETE_INTERVAL':\n        resolution = time_presentation_res\n\n    strategy = None\n    if time_presentation_default_value and not time_presentation_default_value == \"\":\n        strategy = time_presentation_default_value\n\n    timeInfo = DimensionInfo(\"time\", \"true\", presentation, resolution, \"ISO8601\", None, attribute=\"time\",\n                             strategy=strategy, reference_value=time_presentation_reference_value)\n\n    layer = cat.get_layer(name)\n    resource = layer.resource if layer else None\n    if not resource:\n        resources = cat.get_resources(stores=[name]) or cat.get_resources(stores=[name], workspaces=[workspace])\n        if resources:\n            resource = resources[0]\n\n    if not resource:\n        logger.exception(f\"No resource could be found on GeoServer with name {name}\")\n        raise Exception(f\"No resource could be found on GeoServer with name {name}\")\n\n    resource.metadata = {'time': timeInfo}\n    cat.save(resource)\n\n\n# main entry point to create a thumbnail - will use implementation\n# defined in settings.THUMBNAIL_GENERATOR (see settings.py)\ndef create_gs_thumbnail(instance, overwrite=False, check_bbox=False):\n    implementation = import_string(settings.THUMBNAIL_GENERATOR)\n    return implementation(instance, overwrite, check_bbox)\n\n\ndef sync_instance_with_geoserver(\n        instance_id,\n        *args, **kwargs):\n    \"\"\"\n    Synchronizes the Django Instance with GeoServer layers.\n    \"\"\"\n    updatebbox = kwargs.get('updatebbox', True)\n    updatemetadata = kwargs.get('updatemetadata', True)\n\n    instance = None\n    try:\n        instance = Dataset.objects.get(id=instance_id)\n    except Dataset.DoesNotExist:\n        logger.error(f\"Dataset id {instance_id} does not exist yet!\")\n        raise\n\n    if isinstance(instance, ResourceBase):\n        if hasattr(instance, 'dataset'):\n            instance = instance.dataset\n        else:\n            return instance\n\n    try:\n        instance.set_processing_state(\"RUNNING\")\n        if updatemetadata:\n            # Save layer attributes\n            logger.debug(f\"... Refresh GeoServer attributes list for Dataset {instance.title}\")\n            try:\n                set_attributes_from_geoserver(instance)\n            except Exception as e:\n                logger.warning(e)\n\n        # Don't run this signal handler if it is a tile layer or a remote store (Service)\n        #    Currently only gpkg files containing tiles will have this type & will be served via MapProxy.\n        _is_remote_instance = hasattr(instance, 'subtype') and getattr(instance, 'subtype') in ['tileStore', 'remote']\n\n        # Let's reset the connections first\n        gs_catalog._cache.clear()\n        gs_catalog.reset()\n\n        gs_resource = None\n        if not _is_remote_instance:\n            values = None\n            _tries = 0\n            _max_tries = getattr(ogc_server_settings, \"MAX_RETRIES\", 3)\n\n            # If the store in None then it's a new instance from an upload,\n            # only in this case run the geoserver_upload method\n            if getattr(instance, 'overwrite', False):\n                base_file, info = instance.get_base_file()\n\n                # There is no need to process it if there is no file.\n                if base_file:\n                    from geonode.geoserver.upload import geoserver_upload\n                    gs_name, workspace, values, gs_resource = geoserver_upload(\n                        instance,\n                        base_file.file.path,\n                        instance.owner,\n                        instance.name,\n                        overwrite=True,\n                        title=instance.title,\n                        abstract=instance.abstract,\n                        charset=instance.charset\n                    )\n\n            values, gs_resource = fetch_gs_resource(instance, values, _tries)\n            while not gs_resource and _tries < _max_tries:\n                values, gs_resource = fetch_gs_resource(instance, values, _tries)\n                _tries += 1\n                time.sleep(3)\n\n            # Get metadata links\n            metadata_links = []\n            for link in instance.link_set.metadata():\n                metadata_links.append((link.mime, link.name, link.url))\n\n            if gs_resource:\n                logger.debug(f\"Found geoserver resource for this dataset: {instance.name}\")\n                instance.gs_resource = gs_resource\n\n                # Iterate over values from geoserver.\n                for key in ['alternate', 'store', 'subtype']:\n                    # attr_name = key if 'typename' not in key else 'alternate'\n                    # print attr_name\n                    setattr(instance, key, get_dataset_storetype(values[key]))\n\n                if updatemetadata:\n                    gs_resource.metadata_links = metadata_links\n\n                    # Update Attribution link\n                    if instance.poc:\n                        # gsconfig now utilizes an attribution dictionary\n                        gs_resource.attribution = {\n                            'title': str(instance.poc),\n                            'width': None,\n                            'height': None,\n                            'href': None,\n                            'url': None,\n                            'type': None}\n                        profile = get_user_model().objects.get(username=instance.poc.username)\n                        site_url = settings.SITEURL.rstrip('/') if settings.SITEURL.startswith('http') else settings.SITEURL\n                        gs_resource.attribution_link = site_url + profile.get_absolute_url()\n\n                    try:\n                        if settings.RESOURCE_PUBLISHING:\n                            if instance.is_published != gs_resource.advertised:\n                                gs_resource.advertised = 'true'\n\n                        if any(instance.keyword_list()):\n                            keywords = gs_resource.keywords + instance.keyword_list()\n                            gs_resource.keywords = list(set(keywords))\n\n                        # gs_resource should only be called if\n                        # ogc_server_settings.BACKEND_WRITE_ENABLED == True\n                        if getattr(ogc_server_settings, \"BACKEND_WRITE_ENABLED\", True):\n                            gs_catalog.save(gs_resource)\n                    except Exception as e:\n                        msg = (f'Error while trying to save resource named {gs_resource} in GeoServer, try to use: \"{e}\"')\n                        e.args = (msg,)\n                        logger.warning(e)\n\n                if updatebbox:\n                    # store the resource to avoid another geoserver call in the post_save\n                    \"\"\"Get information from geoserver.\n                    The attributes retrieved include:\n                    * Bounding Box\n                    * SRID\n                    \"\"\"\n                    # This is usually done in Dataset.pre_save, however if the hooks\n                    # are bypassed by custom create/updates we need to ensure the\n                    # bbox is calculated properly.\n                    srid = gs_resource.projection\n                    bbox = gs_resource.native_bbox\n                    ll_bbox = gs_resource.latlon_bbox\n                    try:\n                        instance.set_bbox_polygon([bbox[0], bbox[2], bbox[1], bbox[3]], srid)\n                    except GeoNodeException as e:\n                        if not ll_bbox:\n                            raise\n                        else:\n                            logger.exception(e)\n                            instance.srid = 'EPSG:4326'\n                            Dataset.objects.filter(id=instance.id).update(srid=instance.srid)\n                    instance.set_ll_bbox_polygon([ll_bbox[0], ll_bbox[2], ll_bbox[1], ll_bbox[3]])\n\n                    if instance.srid:\n                        instance.srid_url = f\"http://www.spatialreference.org/ref/{instance.srid.replace(':', '/').lower()}/\"\n                    else:\n                        raise GeoNodeException(_(\"Invalid Projection. Dataset is missing CRS!\"))\n\n                # Update the instance\n                to_update = {}\n                if updatemetadata:\n                    to_update = {\n                        'title': instance.title or instance.name,\n                        'abstract': instance.abstract or \"\",\n                        'alternate': instance.alternate\n                    }\n\n                if updatebbox and is_monochromatic_image(instance.thumbnail_url):\n                    to_update['thumbnail_url'] = None\n\n                # Save all the modified information in the instance without triggering signals.\n                with transaction.atomic():\n                    ResourceBase.objects.filter(\n                        id=instance.resourcebase_ptr.id).update(\n                        **to_update)\n\n                    # to_update['name'] = instance.name,\n                    to_update['workspace'] = gs_resource.store.workspace.name\n                    to_update['store'] = gs_resource.store.name\n                    to_update['subtype'] = instance.subtype\n                    to_update['typename'] = instance.alternate\n                    to_update['srid'] = instance.srid\n                    Dataset.objects.filter(id=instance.id).update(**to_update)\n\n                    # Refresh from DB\n                    instance.refresh_from_db()\n\n                if updatemetadata:\n                    # Save dataset styles\n                    logger.debug(f\"... Refresh Legend links for Dataset {instance.title}\")\n                    try:\n                        set_styles(instance, gs_catalog)\n                    except Exception as e:\n                        logger.warning(e)\n\n                    # Invalidate GeoWebCache for the updated resource\n                    try:\n                        _stylefilterparams_geowebcache_dataset(instance.alternate)\n                        _invalidate_geowebcache_dataset(instance.alternate)\n                    except Exception as e:\n                        logger.warning(e)\n\n        # Refreshing dataset links\n        logger.debug(f\"... Creating Default Resource Links for Dataset {instance.title}\")\n        set_resource_default_links(instance, instance, prune=_is_remote_instance)\n\n        # Refreshing CSW records\n        logger.debug(f\"... Updating the Catalogue entries for Dataset {instance.title}\")\n        catalogue_post_save(instance=instance, sender=instance.__class__)\n        instance.set_processing_state(\"PROCESSED\")\n    except Exception as e:\n        logger.exception(e)\n        instance.set_processing_state(\"FAILED\")\n        raise GeoNodeException(e)\n    return instance\n\n\ndef get_dataset_storetype(element):\n    return LAYER_SUBTYPES.get(element, element)\n\n\ndef write_uploaded_files_to_disk(target_dir, files):\n    result = []\n    for django_file in files:\n        path = os.path.join(target_dir, django_file.name)\n        with open(path, 'wb') as fh:\n            for chunk in django_file.chunks():\n                fh.write(chunk)\n        result = path\n    return result\n\n\ndef select_relevant_files(allowed_extensions, files):\n    \"\"\"Filter the input files list for relevant files only\n\n    Relevant files are those whose extension is in the ``allowed_extensions``\n    iterable.\n\n    :param allowed_extensions: list of strings with the extensions to keep\n    :param files: list of django files with the files to be filtered\n    \"\"\"\n    from geonode.upload.files import get_scan_hint\n\n    result = []\n    if files:\n        for django_file in files:\n            _django_file_name = django_file if isinstance(django_file, str) else django_file.name\n            extension = os.path.splitext(_django_file_name)[-1].lower()[1:]\n            if extension in allowed_extensions or get_scan_hint(allowed_extensions):\n                already_selected = _django_file_name in (f if isinstance(f, str) else f.name for f in result)\n                if not already_selected:\n                    result.append(django_file)\n    return result\n\n\n@dataclasses.dataclass()\nclass SpatialFilesLayerType:\n    base_file: str\n    scan_hint: str\n    spatial_files: typing.List\n    dataset_type: typing.Optional[str] = None\n\n\ndef get_spatial_files_dataset_type(allowed_extensions, files, charset='UTF-8') -> SpatialFilesLayerType:\n    \"\"\"Reutnrs 'vector' or 'raster' whether a file from the allowed extensins has been identified.\n    \"\"\"\n    from geonode.upload.files import get_scan_hint, scan_file\n\n    allowed_file = select_relevant_files(allowed_extensions, files)\n    if not allowed_file or len(allowed_file) != 1:\n        return None\n    base_file = allowed_file[0]\n    scan_hint = get_scan_hint(allowed_extensions)\n    spatial_files = scan_file(\n        base_file,\n        scan_hint=scan_hint,\n        charset=charset\n    )\n    the_dataset_type = get_dataset_type(spatial_files)\n    if the_dataset_type not in (FeatureType.resource_type, Coverage.resource_type):\n        return None\n    spatial_files_type = SpatialFilesLayerType(\n        base_file=base_file,\n        scan_hint=scan_hint,\n        spatial_files=spatial_files,\n        dataset_type='vector' if the_dataset_type == FeatureType.resource_type else 'raster')\n\n    return spatial_files_type\n\n\ndef get_dataset_type(spatial_files):\n    \"\"\"Returns 'FeatureType.resource_type' or 'Coverage.resource_type' accordingly to the provided SpatialFiles\n    \"\"\"\n    if spatial_files.archive is not None:\n        the_dataset_type = FeatureType.resource_type\n    else:\n        the_dataset_type = spatial_files[0].file_type.dataset_type\n    return the_dataset_type\n\n\ndef wps_format_is_supported(_format, dataset_type):\n    return (_format, dataset_type) in WPS_ACCEPTABLE_FORMATS\n", "#########################################################################\n#\n# Copyright (C) 2019 OSGeo\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n#\n#########################################################################\nimport re\nimport logging\n\nfrom urllib.parse import urljoin\n\nfrom django.conf import settings\nfrom django.urls import reverse\n\nfrom geonode import geoserver\nfrom geonode.decorators import on_ogc_backend\nfrom geonode.tests.base import GeoNodeBaseTestSupport\nfrom geonode.geoserver.views import _response_callback\nfrom geonode.geoserver.helpers import get_dataset_storetype\nfrom geonode.layers.populate_datasets_data import create_dataset_data\n\nfrom geonode.geoserver.ows import (\n    _wcs_link,\n    _wfs_link,\n    _wms_link)\n\nfrom geonode.base.populate_test_data import (\n    all_public,\n    create_models,\n    remove_models)\n\nlogger = logging.getLogger(__name__)\n\n\nclass HelperTest(GeoNodeBaseTestSupport):\n\n    type = 'dataset'\n\n    fixtures = [\n        'initial_data.json',\n        'group_test_data.json',\n        'default_oauth_apps.json'\n    ]\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        create_models(type=cls.get_type, integration=cls.get_integration)\n        all_public()\n\n    @classmethod\n    def tearDownClass(cls):\n        super().tearDownClass()\n        remove_models(cls.get_obj_ids, type=cls.get_type, integration=cls.get_integration)\n\n    def setUp(self):\n        super().setUp()\n        self.user = 'admin'\n        self.passwd = 'admin'\n        create_dataset_data()\n\n    @on_ogc_backend(geoserver.BACKEND_PACKAGE)\n    def test_replace_callback(self):\n        content = f\"\"\"<Layer>\n      <Title>GeoNode Local GeoServer</Title>\n      <Abstract>This is a description of your Web Map Server.</Abstract>\n      <!--Limited list of EPSG projections:-->\n      <CRS>EPSG:4326</CRS>\n      <CRS>EPSG:3785</CRS>\n      <CRS>EPSG:3857</CRS>\n      <CRS>EPSG:900913</CRS>\n      <CRS>EPSG:32647</CRS>\n      <CRS>EPSG:32736</CRS>\n      <CRS>CRS:84</CRS>\n      <EX_GeographicBoundingBox>\n        <westBoundLongitude>-124.731422</westBoundLongitude>\n        <eastBoundLongitude>12.512771464573753</eastBoundLongitude>\n        <southBoundLatitude>12.4801497</southBoundLatitude>\n        <northBoundLatitude>49.371735</northBoundLatitude>\n      </EX_GeographicBoundingBox>\n      <BoundingBox CRS=\"CRS:84\" ..../>\n      <BoundingBox CRS=\"EPSG:4326\" ..../>\n      <BoundingBox CRS=\"EPSG:3785\" ..../>\n      <BoundingBox CRS=\"EPSG:3857\" ..../>\n      <BoundingBox CRS=\"EPSG:900913\" ..../>\n      <BoundingBox CRS=\"EPSG:32647\" ..../>\n      <BoundingBox CRS=\"EPSG:32736\" ..../>\n      <Layer queryable=\"1\" opaque=\"0\">\n        <Name>geonode:DE_USNG_UTM18</Name>\n        <Title>DE_USNG_UTM18</Title>\n        <Abstract>No abstract provided</Abstract>\n        <KeywordList>\n          <Keyword>DE_USNG_UTM18</Keyword>\n          <Keyword>features</Keyword>\n        </KeywordList>\n        <CRS>EPSG:26918</CRS>\n        <CRS>CRS:84</CRS>\n        <EX_GeographicBoundingBox>\n          <westBoundLongitude>-75.93570725669369</westBoundLongitude>\n          <eastBoundLongitude>-75.00000000000001</eastBoundLongitude>\n          <southBoundLatitude>38.3856300861002</southBoundLatitude>\n          <northBoundLatitude>39.89406880610797</northBoundLatitude>\n        </EX_GeographicBoundingBox>\n        <BoundingBox CRS=\"CRS:84\" .01\" maxy=\"39.89406880610797\"/>\n        <BoundingBox CRS=\"EPSG:26918\" ..../>\n        <BoundingBox CRS=\"EPSG:4326\" ..../>\n        <BoundingBox CRS=\"EPSG:3785\" ..../>\n        <BoundingBox CRS=\"EPSG:3857\" ..../>\n        <BoundingBox CRS=\"EPSG:900913\" ..../>\n        <BoundingBox CRS=\"EPSG:32647\" ..../>\n        <BoundingBox CRS=\"EPSG:32736\" ..../>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"FGDC\">\n          <Format>text/xml</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}showmetadata/xsl/584\"/>\n        </MetadataURL>\n        <Style>\n          <Name>geonode:DE_USNG_UTM18</Name>\n          <Title>Default Polygon</Title>\n          <Abstract>A sample style that draws a polygon</Abstract>\n          <LegendURL width=\"20\" height=\"20\">\n            <Format>image/png</Format>\n            <OnlineResource\nxmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}ows?service=WMS&amp;request=GetLegendGraphic&....\"/>\n          </LegendURL>\n        </Style>\n      </Layer>\"\"\"\n        kwargs = {\n            'content': content,\n            'status': 200,\n            'content_type': 'application/xml'\n        }\n        _content = _response_callback(**kwargs).content\n        self.assertTrue(re.findall(f'{urljoin(settings.SITEURL, \"/gs/\")}ows', str(_content)))\n\n        kwargs = {\n            'content': content,\n            'status': 200,\n            'content_type': 'text/xml; charset=UTF-8'\n        }\n        _content = _response_callback(**kwargs).content\n        self.assertTrue(re.findall(f'{urljoin(settings.SITEURL, \"/gs/\")}ows', str(_content)))\n\n    def test_return_element_if_not_exists_in_the_subtypes(self):\n        el = get_dataset_storetype('not-existing-type')\n        self.assertEqual('not-existing-type', el)\n\n    def test_datastore_should_return_vector(self):\n        el = get_dataset_storetype('dataStore')\n        self.assertEqual('vector', el)\n\n    def test_coverageStore_should_return_raster(self):\n        el = get_dataset_storetype('coverageStore')\n        self.assertEqual('raster', el)\n\n    def test_remoteStore_should_return_remote(self):\n        el = get_dataset_storetype('remoteStore')\n        self.assertEqual('remote', el)\n\n    @on_ogc_backend(geoserver.BACKEND_PACKAGE)\n    def test_geoserver_proxy_strip_paths(self):\n        response = self.client.get(f\"{reverse('gs_layers')}?service=WFS&version=1.1.0&request=DescribeFeatureType&typeName=geonode:tipi_forestali&outputFormat=application/json&access_token=something\")\n        self.assertEqual(response.status_code, 200)\n\n        response = self.client.get(f\"{reverse('ows_endpoint')}?service=WFS&version=1.1.0&request=DescribeFeatureType&typeName=geonode:tipi_forestali&outputFormat=image/png&access_token=something\")\n        self.assertEqual(response.status_code, 200)\n\n    @on_ogc_backend(geoserver.BACKEND_PACKAGE)\n    def test_ows_links(self):\n        ows_url = 'http://foo.org/ows'\n        identifier = 'foo:fake_alternate'\n        min_x, min_y, max_x, max_y = -1, -1, 1, 1\n        expected_url = f'{ows_url}?service=WCS&request=GetCoverage&coverageid=foo__fake_alternate&format=image%2Ftiff&version=2.0.1&compression=DEFLATE&tileWidth=512&tileHeight=512&outputCrs=4326'\n        download_url = _wcs_link(\n            ows_url,\n            identifier,\n            \"image/tiff\",\n            srid='4326',\n            bbox=[min_x, min_y, max_x, max_y],\n            compression=\"DEFLATE\",\n            tile_size=512)\n        self.assertEqual(download_url, expected_url, download_url)\n\n        expected_url = f'{ows_url}?service=WFS&version=1.0.0&request=GetFeature&typename=foo%3Afake_alternate&outputFormat=application%2Fzip&srs=4326&bbox=%5B-1%2C+-1%2C+1%2C+1%5D'\n        download_url = _wfs_link(\n            ows_url,\n            identifier,\n            \"application/zip\",\n            {},\n            srid='4326',\n            bbox=[min_x, min_y, max_x, max_y])\n        self.assertEqual(download_url, expected_url, download_url)\n\n        expected_url = f'{ows_url}?service=WMS&request=GetMap&layers=foo%3Afake_alternate&format=image%2Fpng&height=512&width=512&srs=4326&bbox=%5B-1%2C+-1%2C+1%2C+1%5D'\n        download_url = _wms_link(\n            ows_url,\n            identifier,\n            \"image/png\",\n            512, 512,\n            srid='4326',\n            bbox=[min_x, min_y, max_x, max_y])\n        self.assertEqual(download_url, expected_url, download_url)\n", "#########################################################################\n#\n# Copyright (C) 2016 OSGeo\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n#\n#########################################################################\n\nimport os\nimport re\nimport json\nimport logging\nimport traceback\nfrom lxml import etree\nfrom owslib.etree import etree as dlxml\nfrom os.path import isfile\n\nfrom urllib.parse import (\n    urlsplit,\n    urljoin,\n    unquote,\n    parse_qsl)\n\nfrom django.contrib.auth import authenticate\nfrom django.http import HttpResponse, HttpResponseRedirect\nfrom django.views.decorators.http import require_POST\nfrom django.shortcuts import render\nfrom django.conf import settings\nfrom django.contrib.auth.decorators import user_passes_test\nfrom django.contrib.auth import get_user_model\nfrom django.contrib.auth.decorators import login_required\nfrom django.template.loader import get_template\nfrom django.utils.datastructures import MultiValueDictKeyError\nfrom django.utils.translation import ugettext as _\n\nfrom guardian.shortcuts import get_objects_for_user\n\nfrom geonode.base.models import ResourceBase\nfrom geonode.client.hooks import hookset\nfrom geonode.compat import ensure_string\nfrom geonode.base.auth import get_auth_user, get_or_create_token\nfrom geonode.decorators import logged_in_or_basicauth\nfrom geonode.layers.forms import LayerStyleUploadForm\nfrom geonode.layers.models import Dataset, Style\nfrom geonode.layers.views import _resolve_dataset, _PERMISSION_MSG_MODIFY\nfrom geonode.maps.models import Map\nfrom geonode.proxy.views import (\n    proxy,\n    fetch_response_headers)\nfrom .tasks import geoserver_update_datasets\nfrom geonode.utils import (\n    json_response,\n    _get_basic_auth_info,\n    http_client,\n    get_headers,\n    get_dataset_workspace)\nfrom geoserver.catalog import FailedRequestError\nfrom geonode.geoserver.signals import (\n    gs_catalog,\n    geoserver_post_save_local)\nfrom .helpers import (\n    get_stores,\n    ogc_server_settings,\n    extract_name_from_sld,\n    set_styles,\n    style_update,\n    set_dataset_style,\n    temp_style_name_regex,\n    _stylefilterparams_geowebcache_dataset,\n    _invalidate_geowebcache_dataset)\n\nfrom django.views.decorators.csrf import csrf_exempt\n\nlogger = logging.getLogger(__name__)\n\n\ndef stores(request, store_type=None):\n    stores = get_stores(store_type)\n    data = json.dumps(stores)\n    return HttpResponse(data)\n\n\n@user_passes_test(lambda u: u.is_superuser)\ndef updatelayers(request):\n    params = request.GET\n    # Get the owner specified in the request if any, otherwise used the logged\n    # user\n    owner = params.get('owner', None)\n    owner = get_user_model().objects.get(\n        username=owner) if owner is not None else request.user\n    workspace = params.get('workspace', None)\n    store = params.get('store', None)\n    filter = params.get('filter', None)\n    result = geoserver_update_datasets.delay(\n        ignore_errors=False, owner=owner, workspace=workspace,\n        store=store, filter=filter)\n    # Attempt to run task synchronously\n    result.get()\n\n    return HttpResponseRedirect(hookset.dataset_list_url())\n\n\n@login_required\n@require_POST\ndef dataset_style(request, layername):\n    layer = _resolve_dataset(\n        request,\n        layername,\n        'base.change_resourcebase',\n        _PERMISSION_MSG_MODIFY)\n\n    style_name = request.POST.get('defaultStyle')\n\n    # would be nice to implement\n    # better handling of default style switching\n    # in layer model or deeper (gsconfig.py, REST API)\n\n    old_default = layer.default_style\n    if old_default.name == style_name:\n        return HttpResponse(\n            f\"Default style for {layer.name} remains {style_name}\", status=200)\n\n    # This code assumes without checking\n    # that the new default style name is included\n    # in the list of possible styles.\n\n    new_style = next(style for style in layer.styles if style.name == style_name)\n\n    # Does this change this in geoserver??\n    layer.default_style = new_style\n    layer.styles = [\n        s for s in layer.styles if s.name != style_name] + [old_default]\n    layer.save(notify=True)\n\n    # Invalidate GeoWebCache for the updated resource\n    try:\n        _stylefilterparams_geowebcache_dataset(layer.alternate)\n        _invalidate_geowebcache_dataset(layer.alternate)\n    except Exception:\n        pass\n\n    return HttpResponse(\n        f\"Default style for {layer.name} changed to {style_name}\", status=200)\n\n\n@login_required\ndef dataset_style_upload(request, layername):\n    def respond(*args, **kw):\n        kw['content_type'] = 'text/html'\n        return json_response(*args, **kw)\n    form = LayerStyleUploadForm(request.POST, request.FILES)\n    if not form.is_valid():\n        return respond(errors=\"Please provide an SLD file.\")\n\n    data = form.cleaned_data\n    layer = _resolve_dataset(\n        request,\n        layername,\n        'base.change_resourcebase',\n        _PERMISSION_MSG_MODIFY)\n\n    sld = request.FILES['sld'].read()\n    sld_name = None\n    try:\n        # Check SLD is valid\n        try:\n            if sld:\n                if isfile(sld):\n                    with open(sld) as sld_file:\n                        sld = sld_file.read()\n                etree.XML(sld)\n        except Exception:\n            logger.exception(\"The uploaded SLD file is not valid XML\")\n            raise Exception(\n                \"The uploaded SLD file is not valid XML\")\n\n        sld_name = extract_name_from_sld(\n            gs_catalog, sld, sld_file=request.FILES['sld'])\n    except Exception as e:\n        respond(errors=f\"The uploaded SLD file is not valid XML: {e}\")\n\n    name = data.get('name') or sld_name\n\n    set_dataset_style(layer, data.get('title') or name, sld)\n\n    return respond(\n        body={\n            'success': True,\n            'style': data.get('title') or name,\n            'updated': data['update']})\n\n\n@login_required\ndef dataset_style_manage(request, layername):\n    layer = _resolve_dataset(\n        request,\n        layername,\n        'layers.change_dataset_style',\n        _PERMISSION_MSG_MODIFY)\n\n    if request.method == 'GET':\n        try:\n            cat = gs_catalog\n\n            # First update the layer style info from GS to GeoNode's DB\n            try:\n                set_styles(layer, cat)\n            except AttributeError:\n                logger.warn(\n                    'Unable to set the default style.  Ensure Geoserver is running and that this layer exists.')\n\n            gs_styles = []\n            # Temporary Hack to remove GeoServer temp styles from the list\n            Style.objects.filter(name__iregex=r'\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}_(ms)_\\d{13}').delete()\n            for style in Style.objects.values('name', 'sld_title'):\n                gs_styles.append((style['name'], style['sld_title']))\n            current_dataset_styles = layer.styles.all()\n            dataset_styles = []\n            for style in current_dataset_styles:\n                sld_title = style.name\n                try:\n                    if style.sld_title:\n                        sld_title = style.sld_title\n                except Exception:\n                    tb = traceback.format_exc()\n                    logger.debug(tb)\n                dataset_styles.append((style.name, sld_title))\n\n            # Render the form\n            def_sld_name = None  # noqa\n            def_sld_title = None  # noqa\n            default_style = None\n            if layer.default_style:\n                def_sld_name = layer.default_style.name  # noqa\n                def_sld_title = layer.default_style.name  # noqa\n                try:\n                    if layer.default_style.sld_title:\n                        def_sld_title = layer.default_style.sld_title\n                except Exception:\n                    tb = traceback.format_exc()\n                    logger.debug(tb)\n                default_style = (def_sld_name, def_sld_title)\n\n            return render(\n                request,\n                'datasets/dataset_style_manage.html',\n                context={\n                    \"layer\": layer,\n                    \"gs_styles\": gs_styles,\n                    \"dataset_styles\": dataset_styles,\n                    \"dataset_style_names\": [s[0] for s in dataset_styles],\n                    \"default_style\": default_style\n                }\n            )\n        except (FailedRequestError, OSError):\n            tb = traceback.format_exc()\n            logger.debug(tb)\n            msg = (f'Could not connect to geoserver at \"{ogc_server_settings.LOCATION}\"'\n                   f'to manage style information for layer \"{layer.name}\"')\n            logger.debug(msg)\n            # If geoserver is not online, return an error\n            return render(\n                request,\n                'datasets/dataset_style_manage.html',\n                context={\n                    \"layer\": layer,\n                    \"error\": msg\n                }\n            )\n    elif request.method in ('POST', 'PUT', 'DELETE'):\n        try:\n            workspace = get_dataset_workspace(layer) or settings.DEFAULT_WORKSPACE\n            selected_styles = request.POST.getlist('style-select')\n            default_style = request.POST['default_style']\n\n            # Save to GeoServer\n            cat = gs_catalog\n            try:\n                gs_dataset = cat.get_layer(layer.name)\n            except Exception:\n                gs_dataset = None\n\n            if not gs_dataset:\n                gs_dataset = cat.get_layer(layer.alternate)\n\n            if gs_dataset:\n                _default_style = cat.get_style(default_style) or \\\n                    cat.get_style(default_style, workspace=workspace)\n                if _default_style:\n                    gs_dataset.default_style = _default_style\n                elif cat.get_style(default_style, workspace=settings.DEFAULT_WORKSPACE):\n                    gs_dataset.default_style = cat.get_style(default_style, workspace=settings.DEFAULT_WORKSPACE)\n                styles = []\n                for style in selected_styles:\n                    _gs_sld = cat.get_style(style) or cat.get_style(style, workspace=workspace)\n                    if _gs_sld:\n                        styles.append(_gs_sld)\n                    elif cat.get_style(style, workspace=settings.DEFAULT_WORKSPACE):\n                        styles.append(cat.get_style(style, workspace=settings.DEFAULT_WORKSPACE))\n                    else:\n                        Style.objects.filter(name=style).delete()\n                gs_dataset.styles = styles\n                cat.save(gs_dataset)\n\n            # Save to Django\n            set_styles(layer, cat)\n\n            # Invalidate GeoWebCache for the updated resource\n            try:\n                _stylefilterparams_geowebcache_dataset(layer.alternate)\n                _invalidate_geowebcache_dataset(layer.alternate)\n            except Exception:\n                pass\n\n            return HttpResponseRedirect(layer.get_absolute_url())\n        except (FailedRequestError, OSError, MultiValueDictKeyError):\n            tb = traceback.format_exc()\n            logger.debug(tb)\n            msg = (f'Error Saving Styles for Dataset \"{layer.name}\"')\n            logger.warn(msg)\n            return render(\n                request,\n                'datasets/dataset_style_manage.html',\n                context={\n                    \"layer\": layer,\n                    \"error\": msg\n                }\n            )\n\n\ndef style_change_check(request, path, style_name=None, access_token=None):\n    \"\"\"\n    If the layer has not change_dataset_style permission, return a status of\n    401 (unauthorized)\n    \"\"\"\n    # a new style is created with a POST and then a PUT,\n    # a style is updated with a PUT\n    # a layer is updated with a style with a PUT\n    # in both case we need to check permissions here\n    # for PUT path is /gs/rest/styles/san_andres_y_providencia_water_a452004b.xml\n    # or /ge/rest/layers/geonode:san_andres_y_providencia_coastline.json\n    # for POST path is /gs/rest/styles\n    # we will suppose that a user can create a new style only if he is an\n    # authenticated (we need to discuss about it)\n    authorized = True\n    if request.method in ('PUT', 'POST'):\n        if not request.user.is_authenticated and not access_token:\n            authorized = False\n        elif re.match(r'^.*(?<!/rest/)/rest/.*/?styles.*', path):\n            # style new/update\n            # we will iterate all layers (should be just one if not using GS)\n            # to which the posted style is associated\n            # and check if the user has change_style_dataset permissions on each\n            # of them\n            if style_name == 'styles' and 'raw' in request.GET:\n                authorized = True\n            elif re.match(temp_style_name_regex, style_name):\n                authorized = True\n            else:\n                try:\n                    user = request.user\n                    if user.is_anonymous and access_token:\n                        user = get_auth_user(access_token)\n                    if not user or user.is_anonymous:\n                        authorized = False\n                    else:\n                        style = Style.objects.get(name=style_name)\n                        for dataset in style.dataset_styles.all():\n                            if not user.has_perm('change_dataset_style', obj=dataset):\n                                authorized = False\n                                break\n                            else:\n                                authorized = True\n                                break\n                except Style.DoesNotExist:\n                    if request.method != 'POST':\n                        logger.warn(f'There is not a style with such a name: {style_name}.')\n                except Exception as e:\n                    logger.exception(e)\n                    authorized = (request.method == 'POST')  # The user is probably trying to create a new style\n    return authorized\n\n\ndef check_geoserver_access(request,\n                           proxy_path,\n                           downstream_path,\n                           workspace=None,\n                           layername=None,\n                           allowed_hosts=[]):\n    def strip_prefix(path, prefix):\n        if prefix not in path:\n            _s_prefix = prefix.split('/', 3)\n            _s_path = path.split('/', 3)\n            assert _s_prefix[1] == _s_path[1]\n            _prefix = f'/{_s_path[1]}/{_s_path[2]}'\n        else:\n            _prefix = prefix\n        assert _prefix in path\n        prefix_idx = path.index(_prefix)\n        _prefix = path[:prefix_idx] + _prefix\n        full_prefix = f\"{_prefix}/{layername}/{downstream_path}\" if layername else _prefix\n        return path[len(full_prefix):]\n\n    path = strip_prefix(request.get_full_path(), proxy_path)\n\n    raw_url = str(\n        \"\".join([ogc_server_settings.LOCATION, downstream_path, path]))\n\n    if settings.DEFAULT_WORKSPACE or workspace:\n        ws = (workspace or settings.DEFAULT_WORKSPACE)\n        if ws and ws in path:\n            # Strip out WS from PATH\n            try:\n                path = f'/{strip_prefix(path, f\"/{ws}:\")}'\n            except Exception:\n                ws = None\n\n        if proxy_path == f'/gs/{settings.DEFAULT_WORKSPACE}' and layername:\n            import posixpath\n            raw_url = urljoin(ogc_server_settings.LOCATION,\n                              posixpath.join(workspace, layername, downstream_path, path))\n\n        if downstream_path in ('rest/styles') and len(request.body) > 0:\n            if ws:\n                # Lets try\n                # http://localhost:8080/geoserver/rest/workspaces/<ws>/styles/<style>.xml\n                _url = str(\"\".join([ogc_server_settings.LOCATION,\n                                    'rest/workspaces/', ws, '/styles',\n                                    path]))\n            else:\n                _url = str(\"\".join([ogc_server_settings.LOCATION,\n                                    'rest/styles',\n                                    path]))\n            raw_url = _url\n\n    if downstream_path in 'ows' and (\n        re.match(r'/(rest).*$', path, re.IGNORECASE) or\n            re.match(r'/(w.*s).*$', path, re.IGNORECASE) or\n            re.match(r'/(ows).*$', path, re.IGNORECASE)):\n        _url = str(\"\".join([ogc_server_settings.LOCATION, '', path[1:]]))\n        raw_url = _url\n    url = urlsplit(raw_url)\n\n    if f'{ws}/layers' in path:\n        downstream_path = 'rest/layers'\n    elif f'{ws}/styles' in path:\n        downstream_path = 'rest/styles'\n\n    # Collecting headers and cookies\n    headers, access_token = get_headers(request, url, unquote(raw_url), allowed_hosts=allowed_hosts)\n    return (raw_url, headers, access_token, downstream_path)\n\n\n@csrf_exempt\ndef geoserver_proxy(request,\n                    proxy_path,\n                    downstream_path,\n                    workspace=None,\n                    layername=None):\n    \"\"\"\n    WARNING: Decorators are applied in the order they appear in the source.\n    \"\"\"\n    affected_datasets = None\n    allowed_hosts = [urlsplit(ogc_server_settings.public_url).hostname, ]\n\n    raw_url, headers, access_token, downstream_path = check_geoserver_access(\n        request,\n        proxy_path,\n        downstream_path,\n        workspace=workspace,\n        layername=layername,\n        allowed_hosts=allowed_hosts)\n    url = urlsplit(raw_url)\n\n    if re.match(r'^.*/rest/', url.path) and request.method in (\"POST\", \"PUT\", \"DELETE\"):\n        if re.match(r'^.*(?<!/rest/)/rest/.*/?styles.*', url.path):\n            logger.debug(\n                f\"[geoserver_proxy] Updating Style ---> url {url.geturl()}\")\n            _style_name, _style_ext = os.path.splitext(os.path.basename(urlsplit(url.geturl()).path))\n            _parsed_get_args = dict(parse_qsl(urlsplit(url.geturl()).query))\n            if _style_name == 'styles.json' and request.method == \"PUT\":\n                if _parsed_get_args.get('name'):\n                    _style_name, _style_ext = os.path.splitext(_parsed_get_args.get('name'))\n            else:\n                _style_name, _style_ext = os.path.splitext(_style_name)\n\n            if not style_change_check(request, url.path, style_name=_style_name, access_token=access_token):\n                return HttpResponse(\n                    _(\"You don't have permissions to change style for this layer\"),\n                    content_type=\"text/plain\",\n                    status=401)\n            if _style_name != 'style-check' and (_style_ext == '.json' or _parsed_get_args.get('raw')) and \\\n                    not re.match(temp_style_name_regex, _style_name):\n                affected_datasets = style_update(request, raw_url, workspace)\n        elif re.match(r'^.*(?<!/rest/)/rest/.*/?layers.*', url.path):\n            logger.debug(f\"[geoserver_proxy] Updating Dataset ---> url {url.geturl()}\")\n            try:\n                _dataset_name = os.path.splitext(os.path.basename(request.path))[0]\n                _dataset = Dataset.objects.get(name=_dataset_name)\n                affected_datasets = [_dataset]\n            except Exception:\n                logger.warn(f\"Could not find any Dataset {os.path.basename(request.path)} on DB\")\n\n    kwargs = {'affected_datasets': affected_datasets}\n    raw_url = unquote(raw_url)\n    timeout = getattr(ogc_server_settings, 'TIMEOUT') or 60\n    response = proxy(request, url=raw_url, response_callback=_response_callback,\n                     timeout=timeout, allowed_hosts=allowed_hosts,\n                     headers=headers, access_token=access_token, **kwargs)\n    return response\n\n\ndef _response_callback(**kwargs):\n    status = kwargs.get('status')\n    content = kwargs.get('content')\n    content_type = kwargs.get('content_type')\n    response_headers = kwargs.get('response_headers', None)\n    content_type_list = ['application/xml', 'text/xml', 'text/plain', 'application/json', 'text/json']\n\n    if content:\n        if not content_type:\n            if isinstance(content, bytes):\n                content = content.decode('UTF-8')\n            if (re.match(r'^<.+>$', content)):\n                content_type = 'application/xml'\n            elif (re.match(r'^({|[).+(}|])$', content)):\n                content_type = 'application/json'\n            else:\n                content_type = 'text/plain'\n\n        # Replace Proxy URL\n        try:\n            if isinstance(content, bytes):\n                try:\n                    _content = content.decode('UTF-8')\n                except UnicodeDecodeError:\n                    _content = content\n            else:\n                _content = content\n            if re.findall(f\"(?=(\\\\b{'|'.join(content_type_list)}\\\\b))\", content_type):\n                _gn_proxy_url = urljoin(settings.SITEURL, '/gs/')\n                content = _content\\\n                    .replace(ogc_server_settings.LOCATION, _gn_proxy_url)\\\n                    .replace(ogc_server_settings.PUBLIC_LOCATION, _gn_proxy_url)\n                for _ows_endpoint in list(dict.fromkeys(re.findall(rf'{_gn_proxy_url}w\\ws', content, re.IGNORECASE))):\n                    content = content.replace(_ows_endpoint, f'{_gn_proxy_url}ows')\n        except Exception as e:\n            logger.exception(e)\n\n    if 'affected_datasets' in kwargs and kwargs['affected_datasets']:\n        for layer in kwargs['affected_datasets']:\n            geoserver_post_save_local(layer)\n\n    _response = HttpResponse(\n        content=content,\n        status=status,\n        content_type=content_type)\n    return fetch_response_headers(_response, response_headers)\n\n\ndef resolve_user(request):\n    user = None\n    geoserver = False\n    superuser = False\n    acl_user = request.user\n    if 'HTTP_AUTHORIZATION' in request.META:\n        username, password = _get_basic_auth_info(request)\n        acl_user = authenticate(username=username, password=password)\n        if acl_user:\n            user = acl_user.username\n            superuser = acl_user.is_superuser\n        elif _get_basic_auth_info(request) == ogc_server_settings.credentials:\n            geoserver = True\n            superuser = True\n        else:\n            return HttpResponse(_(\"Bad HTTP Authorization Credentials.\"),\n                                status=401,\n                                content_type=\"text/plain\")\n\n    if not any([user, geoserver, superuser]\n               ) and not request.user.is_anonymous:\n        user = request.user.username\n        superuser = request.user.is_superuser\n\n    resp = {\n        'user': user,\n        'geoserver': geoserver,\n        'superuser': superuser,\n    }\n\n    if acl_user and acl_user.is_authenticated:\n        resp['fullname'] = acl_user.get_full_name()\n        resp['email'] = acl_user.email\n    return HttpResponse(json.dumps(resp), content_type=\"application/json\")\n\n\n@logged_in_or_basicauth(realm=\"GeoNode\")\ndef dataset_acls(request):\n    \"\"\"\n    returns json-encoded lists of layer identifiers that\n    represent the sets of read-write and read-only layers\n    for the currently authenticated user.\n    \"\"\"\n    # the dataset_acls view supports basic auth, and a special\n    # user which represents the geoserver administrator that\n    # is not present in django.\n    acl_user = request.user\n    if 'HTTP_AUTHORIZATION' in request.META:\n        try:\n            username, password = _get_basic_auth_info(request)\n            acl_user = authenticate(username=username, password=password)\n\n            # Nope, is it the special geoserver user?\n            if (acl_user is None and\n                    username == ogc_server_settings.USER and\n                    password == ogc_server_settings.PASSWORD):\n                # great, tell geoserver it's an admin.\n                result = {\n                    'rw': [],\n                    'ro': [],\n                    'name': username,\n                    'is_superuser': True,\n                    'is_anonymous': False\n                }\n                return HttpResponse(\n                    json.dumps(result),\n                    content_type=\"application/json\")\n        except Exception:\n            pass\n\n        if acl_user is None:\n            return HttpResponse(_(\"Bad HTTP Authorization Credentials.\"),\n                                status=401,\n                                content_type=\"text/plain\")\n\n    # Include permissions on the anonymous user\n    # use of polymorphic selectors/functions to optimize performances\n    resources_readable = get_objects_for_user(\n        acl_user, 'view_resourcebase',\n        ResourceBase.objects.filter(polymorphic_ctype__model='dataset')).values_list('id', flat=True)\n    dataset_writable = get_objects_for_user(\n        acl_user, 'change_dataset_data',\n        Dataset.objects.all())\n\n    _read = set(\n        Dataset.objects.filter(\n            id__in=resources_readable).values_list(\n            'alternate',\n            flat=True))\n    _write = set(dataset_writable.values_list('alternate', flat=True))\n\n    read_only = _read ^ _write\n    read_write = _read & _write\n\n    result = {\n        'rw': list(read_write),\n        'ro': list(read_only),\n        'name': acl_user.username,\n        'is_superuser': acl_user.is_superuser,\n        'is_anonymous': acl_user.is_anonymous,\n    }\n    if acl_user.is_authenticated:\n        result['fullname'] = acl_user.get_full_name()\n        result['email'] = acl_user.email\n\n    return HttpResponse(json.dumps(result), content_type=\"application/json\")\n\n\n# capabilities\ndef get_dataset_capabilities(layer, version='1.3.0', access_token=None, tolerant=False):\n    \"\"\"\n    Retrieve a layer-specific GetCapabilities document\n    \"\"\"\n    workspace, layername = layer.alternate.split(\":\") if \":\" in layer.alternate else (None, layer.alternate)\n    if not layer.remote_service:\n        wms_url = f'{ogc_server_settings.LOCATION}{workspace}/{layername}/wms?service=wms&version={version}&request=GetCapabilities'  # noqa\n        if access_token:\n            wms_url += f'&access_token={access_token}'\n    else:\n        wms_url = f'{layer.remote_service.service_url}?service=wms&version={version}&request=GetCapabilities'\n\n    _user, _password = ogc_server_settings.credentials\n    req, content = http_client.get(wms_url, user=_user)\n    getcap = ensure_string(content)\n    if not getattr(settings, 'DELAYED_SECURITY_SIGNALS', False):\n        if tolerant and ('ServiceException' in getcap or req.status_code == 404):\n            # WARNING Please make sure to have enabled DJANGO CACHE as per\n            # https://docs.djangoproject.com/en/2.0/topics/cache/#filesystem-caching\n            wms_url = f'{ogc_server_settings.public_url}{workspace}/ows?service=wms&version={version}&request=GetCapabilities&layers={layer}'  # noqa\n            if access_token:\n                wms_url += f'&access_token={access_token}'\n            req, content = http_client.get(wms_url, user=_user)\n            getcap = ensure_string(content)\n\n    if 'ServiceException' in getcap or req.status_code == 404:\n        return None\n    return getcap.encode('UTF-8')\n\n\ndef format_online_resource(workspace, layer, element, namespaces):\n    \"\"\"\n    Replace workspace/layer-specific OnlineResource links with the more\n    generic links returned by a site-wide GetCapabilities document\n    \"\"\"\n    layerName = element.find('.//wms:Capability/wms:Layer/wms:Layer/wms:Name',\n                             namespaces)\n    if layerName is None:\n        return\n\n    layerName.text = f\"{workspace}:{layer}\" if workspace else layer\n    layerresources = element.findall('.//wms:OnlineResource', namespaces)\n    if layerresources is None:\n        return\n\n    for resource in layerresources:\n        wtf = resource.attrib['{http://www.w3.org/1999/xlink}href']\n        replace_string = f\"/{workspace}/{layer}\" if workspace else f\"/{layer}\"\n        resource.attrib['{http://www.w3.org/1999/xlink}href'] = wtf.replace(\n            replace_string, \"\")\n\n\ndef get_capabilities(request, layerid=None, user=None,\n                     mapid=None, category=None, tolerant=False):\n    \"\"\"\n    Compile a GetCapabilities document containing public layers\n    filtered by layer, user, map, or category\n    \"\"\"\n\n    rootdoc = None\n    layers = None\n    cap_name = ' Capabilities - '\n    if layerid is not None:\n        dataset_obj = Dataset.objects.get(id=layerid)\n        cap_name += dataset_obj.title\n        layers = Dataset.objects.filter(id=layerid)\n    elif user is not None:\n        layers = Dataset.objects.filter(owner__username=user)\n        cap_name += user\n    elif category is not None:\n        layers = Dataset.objects.filter(category__identifier=category)\n        cap_name += category\n    elif mapid is not None:\n        map_obj = Map.objects.get(id=mapid)\n        cap_name += map_obj.title\n        alternates = []\n        for layer in map_obj.maplayers.iterator():\n            if layer.local:\n                alternates.append(layer.name)\n        layers = Dataset.objects.filter(alternate__in=alternates)\n\n    for layer in layers:\n        if request.user.has_perm('view_resourcebase',\n                                 layer.get_self_resource()):\n            access_token = get_or_create_token(request.user)\n            if access_token and not access_token.is_expired():\n                access_token = access_token.token\n            else:\n                access_token = None\n            try:\n                workspace, layername = layer.alternate.split(\":\") if \":\" in layer.alternate else (None, layer.alternate)\n                layercap = get_dataset_capabilities(layer, access_token=access_token, tolerant=tolerant)\n                if layercap is not None:  # 1st one, seed with real GetCapabilities doc\n                    try:\n                        namespaces = {'wms': 'http://www.opengis.net/wms',\n                                      'xlink': 'http://www.w3.org/1999/xlink',\n                                      'xsi': 'http://www.w3.org/2001/XMLSchema-instance'}\n                        layercap = dlxml.fromstring(layercap)\n                        rootdoc = etree.ElementTree(layercap)\n                        format_online_resource(workspace, layername, rootdoc, namespaces)\n                        service_name = rootdoc.find('.//wms:Service/wms:Name', namespaces)\n                        if service_name is not None:\n                            service_name.text = cap_name\n                        rootdoc = rootdoc.find('.//wms:Capability/wms:Layer/wms:Layer', namespaces)\n                    except Exception as e:\n                        import traceback\n                        traceback.print_exc()\n                        logger.error(\n                            f\"Error occurred creating GetCapabilities for {layer.typename}: {str(e)}\")\n                        rootdoc = None\n                if layercap is None or not len(layercap) or rootdoc is None or not len(rootdoc):\n                    # Get the required info from layer model\n                    # TODO: store time dimension on DB also\n                    tpl = get_template(\"geoserver/layer.xml\")\n                    ctx = {\n                        'layer': layer,\n                        'geoserver_public_url': ogc_server_settings.public_url,\n                        'catalogue_url': settings.CATALOGUE['default']['URL'],\n                    }\n                    gc_str = tpl.render(ctx)\n                    gc_str = gc_str.encode(\"utf-8\", \"replace\")\n                    layerelem = etree.XML(gc_str)\n                    rootdoc = etree.ElementTree(layerelem)\n            except Exception as e:\n                import traceback\n                traceback.print_exc()\n                logger.error(\n                    f\"Error occurred creating GetCapabilities for {layer.typename}:{str(e)}\")\n                rootdoc = None\n    if rootdoc is not None:\n        capabilities = etree.tostring(\n            rootdoc,\n            xml_declaration=True,\n            encoding='UTF-8',\n            pretty_print=True)\n        return HttpResponse(capabilities, content_type=\"text/xml\")\n    return HttpResponse(status=200)\n\n\ndef server_online(request):\n    \"\"\"\n    Returns {success} whenever the LOCAL_GEOSERVER is up and running\n    \"\"\"\n    from .helpers import check_geoserver_is_up\n    try:\n        check_geoserver_is_up()\n        return HttpResponse(json.dumps({'online': True}), content_type=\"application/json\")\n    except Exception:\n        return HttpResponse(json.dumps({'online': False}), content_type=\"application/json\")\n"], "fixing_code": ["#########################################################################\n#\n# Copyright (C) 2016 OSGeo\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n#\n#########################################################################\nimport os\nimport re\nimport sys\nimport copy\nimport time\nimport uuid\nimport json\nimport errno\nimport typing\nimport logging\nimport datetime\nimport tempfile\nimport traceback\nimport dataclasses\n\nfrom shutil import copyfile\nfrom itertools import cycle\nfrom collections import defaultdict\nfrom os.path import basename, splitext, isfile\nfrom urllib.parse import urlparse, urlencode, urlsplit, urljoin\nfrom pinax.ratings.models import OverallRating\nfrom bs4 import BeautifulSoup\nimport xml.etree.ElementTree as ET\n\nfrom django.conf import settings\nfrom django.utils import timezone\nfrom django.db import transaction\nfrom django.contrib.auth import get_user_model\nfrom django.utils.module_loading import import_string\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.template.loader import render_to_string\nfrom django.utils.translation import ugettext as _\n\nfrom geoserver.catalog import Catalog, FailedRequestError\nfrom geoserver.resource import FeatureType, Coverage\nfrom geoserver.store import CoverageStore, DataStore, datastore_from_index, \\\n    coveragestore_from_index, wmsstore_from_index\nfrom geoserver.support import DimensionInfo\nfrom geoserver.workspace import Workspace\nfrom gsimporter import Client\nfrom lxml import etree, objectify\nfrom owslib.etree import etree as dlxml\nfrom owslib.wcs import WebCoverageService\n\nfrom geonode import GeoNodeException\nfrom geonode.base.models import Link\nfrom geonode.base.models import ResourceBase\nfrom geonode.security.views import _perms_info_json\nfrom geonode.catalogue.models import catalogue_post_save\nfrom geonode.layers.models import Dataset, Attribute, Style\nfrom geonode.layers.enumerations import LAYER_ATTRIBUTE_NUMERIC_DATA_TYPES\n\nfrom geonode.utils import (\n    OGC_Servers_Handler,\n    http_client,\n    get_legend_url,\n    is_monochromatic_image,\n    set_resource_default_links)\n\nfrom .security import set_geowebcache_invalidate_cache\n\nlogger = logging.getLogger(__name__)\n\ntemp_style_name_regex = r'[a-zA-Z0-9]{8}-[a-zA-Z0-9]{4}-[a-zA-Z0-9]{4}-[a-zA-Z0-9]{4}-[a-zA-Z0-9]{12}_ms_.*'\n\nLAYER_SUBTYPES = {\n    \"dataStore\": \"vector\",\n    \"coverageStore\": \"raster\",\n    \"remoteStore\": \"remote\",\n    \"vectorTimeSeries\": \"vector_time\"\n}\n\nWPS_ACCEPTABLE_FORMATS = [\n    ('application/json', 'vector'),\n    ('application/arcgrid', 'raster'),\n    ('image/tiff', 'raster'),\n    ('image/png', 'raster'),\n    ('image/jpeg', 'raster'),\n    ('application/wfs-collection-1.0', 'vector'),\n    ('application/wfs-collection-1.1', 'vector'),\n    ('application/zip', 'vector'),\n    ('text/csv', 'vector')\n]\n\nDEFAULT_STYLE_NAME = ['generic', 'line', 'point', 'polygon', 'raster']\n\n\nif not hasattr(settings, 'OGC_SERVER'):\n    msg = (\n        'Please configure OGC_SERVER when enabling geonode.geoserver.'\n        ' More info can be found at '\n        'http://docs.geonode.org/en/2.10.x/basic/settings/index.html#ogc-server')\n    raise ImproperlyConfigured(msg)\n\n\ndef check_geoserver_is_up():\n    \"\"\"Verifies all geoserver is running,\n       this is needed to be able to upload.\n    \"\"\"\n    url = f\"{ogc_server_settings.LOCATION}\"\n    req, content = http_client.get(url, user=_user)\n    msg = f'Cannot connect to the GeoServer at {url}\\nPlease make sure you have started it.'\n    logger.debug(req)\n    assert req.status_code == 200, msg\n\n\ndef _add_sld_boilerplate(symbolizer):\n    \"\"\"\n    Wrap an XML snippet representing a single symbolizer in the appropriate\n    elements to make it a valid SLD which applies that symbolizer to all features,\n    including format strings to allow interpolating a \"name\" variable in.\n    \"\"\"\n    return \"\"\"\n<StyledLayerDescriptor version=\"1.0.0\" xmlns=\"http://www.opengis.net/sld\" xmlns:ogc=\"http://www.opengis.net/ogc\"\n  xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://www.opengis.net/sld http://schemas.opengis.net/sld/1.0.0/StyledLayerDescriptor.xsd\">\n  <NamedLayer>\n    <Name>%(name)s</Name>\n    <UserStyle>\n    <Name>%(name)s</Name>\n    <Title>%(name)s</Title>\n      <FeatureTypeStyle>\n        <Rule>\n\"\"\" + symbolizer + \"\"\"\n        </Rule>\n      </FeatureTypeStyle>\n    </UserStyle>\n  </NamedLayer>\n</StyledLayerDescriptor>\n\"\"\"\n\n\n_raster_template = \"\"\"\n<RasterSymbolizer>\n    <Opacity>1.0</Opacity>\n</RasterSymbolizer>\n\"\"\"\n\n_polygon_template = \"\"\"\n<PolygonSymbolizer>\n  <Fill>\n    <CssParameter name=\"fill\">%(bg)s</CssParameter>\n  </Fill>\n  <Stroke>\n    <CssParameter name=\"stroke\">%(fg)s</CssParameter>\n    <CssParameter name=\"stroke-width\">0.7</CssParameter>\n  </Stroke>\n</PolygonSymbolizer>\n\"\"\"\n\n_line_template = \"\"\"\n<LineSymbolizer>\n  <Stroke>\n    <CssParameter name=\"stroke\">%(bg)s</CssParameter>\n    <CssParameter name=\"stroke-width\">3</CssParameter>\n  </Stroke>\n</LineSymbolizer>\n</Rule>\n</FeatureTypeStyle>\n<FeatureTypeStyle>\n<Rule>\n<LineSymbolizer>\n  <Stroke>\n    <CssParameter name=\"stroke\">%(fg)s</CssParameter>\n  </Stroke>\n</LineSymbolizer>\n\"\"\"\n\n_point_template = \"\"\"\n<PointSymbolizer>\n  <Graphic>\n    <Mark>\n      <WellKnownName>%(mark)s</WellKnownName>\n      <Fill>\n        <CssParameter name=\"fill\">%(bg)s</CssParameter>\n      </Fill>\n      <Stroke>\n        <CssParameter name=\"stroke\">%(fg)s</CssParameter>\n      </Stroke>\n    </Mark>\n    <Size>10</Size>\n  </Graphic>\n</PointSymbolizer>\n\"\"\"\n\n_style_templates = dict(\n    raster=_add_sld_boilerplate(_raster_template),\n    polygon=_add_sld_boilerplate(_polygon_template),\n    line=_add_sld_boilerplate(_line_template),\n    point=_add_sld_boilerplate(_point_template)\n)\n\nSTYLES_VERSION = {\n    \"1.0.0\": \"sld10\",\n    \"1.1.0\": \"sld11\"\n}\n\n\ndef _extract_style_version_from_sld(sld):\n    \"\"\"\n        Assume: SLD as a byte\n    \"\"\"\n    root = objectify.fromstring(sld)\n    try:\n        return STYLES_VERSION[root.attrib[\"version\"].strip()]\n    except Exception:\n        return STYLES_VERSION[\"1.0.0\"]\n\n\ndef _style_name(resource):\n    return _punc.sub(\"_\", f\"{resource.store.workspace.name}:{resource.name}\")\n\n\ndef extract_name_from_sld(gs_catalog, sld, sld_file=None):\n    try:\n        if sld:\n            if isfile(sld):\n                with open(sld, \"rb\") as sld_file:\n                    sld = sld_file.read()\n            if isinstance(sld, str):\n                sld = sld.encode('utf-8')\n            dom = etree.XML(sld, parser=etree.XMLParser(resolve_entities=False))\n        elif sld_file and isfile(sld_file):\n            with open(sld_file, \"rb\") as sld_file:\n                sld = sld_file.read()\n            if isinstance(sld, str):\n                sld = sld.encode('utf-8')\n            dom = dlxml.parse(sld)\n    except Exception:\n        logger.exception(\"The uploaded SLD file is not valid XML\")\n        raise Exception(\n            \"The uploaded SLD file is not valid XML\")\n\n    named_dataset = dom.findall(\n        \"{http://www.opengis.net/sld}NamedLayer\")\n    user_dataset = dom.findall(\n        \"{http://www.opengis.net/sld}UserLayer\")\n\n    el = None\n    if named_dataset and len(named_dataset) > 0:\n        user_style = named_dataset[0].findall(\"{http://www.opengis.net/sld}UserStyle\")\n        if user_style and len(user_style) > 0:\n            el = user_style[0].findall(\"{http://www.opengis.net/sld}Name\")\n            if len(el) == 0:\n                el = user_style[0].findall(\"{http://www.opengis.net/se}Name\")\n\n        if len(el) == 0:\n            el = named_dataset[0].findall(\"{http://www.opengis.net/sld}Name\")\n        if len(el) == 0:\n            el = named_dataset[0].findall(\"{http://www.opengis.net/se}Name\")\n\n    if not el or len(el) == 0:\n        if user_dataset and len(user_dataset) > 0:\n            user_style = user_dataset[0].findall(\"{http://www.opengis.net/sld}UserStyle\")\n            if user_style and len(user_style) > 0:\n                el = user_style[0].findall(\"{http://www.opengis.net/sld}Name\")\n                if len(el) == 0:\n                    el = user_style[0].findall(\"{http://www.opengis.net/se}Name\")\n\n            if len(el) == 0:\n                el = user_dataset[0].findall(\"{http://www.opengis.net/sld}Name\")\n            if len(el) == 0:\n                el = user_dataset[0].findall(\"{http://www.opengis.net/se}Name\")\n\n    if not el or len(el) == 0:\n        if sld_file:\n            return splitext(basename(sld_file))[0]\n        else:\n            raise Exception(\n                \"Please provide a name, unable to extract one from the SLD.\")\n\n    return el[0].text\n\n\ndef get_sld_for(gs_catalog, layer):\n    name = None\n    gs_dataset = None\n    gs_style = None\n\n    _default_style = None\n    _max_retries, _tries = getattr(ogc_server_settings, \"MAX_RETRIES\", 2), 0\n    try:\n        gs_dataset = gs_catalog.get_layer(layer.name)\n        if gs_dataset.default_style:\n            gs_style = gs_dataset.default_style.sld_body\n            set_dataset_style(layer, layer.alternate, gs_style)\n        name = gs_dataset.default_style.name\n        _default_style = gs_dataset.default_style\n    except Exception as e:\n        logger.debug(e)\n        name = None\n\n    while not name and _tries < _max_retries:\n        try:\n            gs_dataset = gs_catalog.get_layer(layer.name)\n            if gs_dataset:\n                if gs_dataset.default_style:\n                    gs_style = gs_dataset.default_style.sld_body\n                    set_dataset_style(layer, layer.alternate, gs_style)\n                name = gs_dataset.default_style.name\n                if name:\n                    break\n        except Exception as e:\n            logger.exception(e)\n            name = None\n        _tries += 1\n        time.sleep(3)\n\n    if not _default_style:\n        _default_style = layer.default_style if layer else None\n        name = _default_style.name if _default_style else None\n        gs_style = _default_style.sld_body if _default_style else None\n\n    if not name:\n        msg = \"\"\"\n            GeoServer didn't return a default style for this layer.\n            Consider increasing OGC_SERVER MAX_RETRIES value.''\n        \"\"\"\n        raise GeoNodeException(msg)\n\n    # Detect geometry type if it is a FeatureType\n    res = gs_dataset.resource if gs_dataset else None\n    if res and res.resource_type == 'featureType':\n        res.fetch()\n        ft = res.store.get_resources(name=res.name)\n        ft.fetch()\n        for attr in ft.dom.find(\"attributes\"):\n            attr_binding = attr.find(\"binding\")\n            if \"jts.geom\" in attr_binding.text:\n                if \"Polygon\" in attr_binding.text:\n                    name = \"polygon\"\n                elif \"Line\" in attr_binding.text:\n                    name = \"line\"\n                else:\n                    name = \"point\"\n\n    # FIXME: When gsconfig.py exposes the default geometry type for vector\n    # layers we should use that rather than guessing based on the auto-detected\n    # style.\n    if name in _style_templates:\n        fg, bg, mark = next(_style_contexts)\n        return _style_templates[name] % dict(\n            name=layer.name,\n            fg=fg,\n            bg=bg,\n            mark=mark)\n    else:\n        return gs_style\n\n\ndef set_dataset_style(saved_dataset, title, sld, base_file=None):\n    # Check SLD is valid\n    try:\n        if sld:\n            if isfile(sld):\n                with open(sld, \"rb\") as sld_file:\n                    sld = sld_file.read()\n\n            elif isinstance(sld, str):\n                sld = sld.strip('b\\'\\n')\n                sld = re.sub(r'(\\\\r)|(\\\\n)', '', sld).encode(\"UTF-8\")\n            etree.XML(sld, parser=etree.XMLParser(resolve_entities=False))\n        elif base_file and isfile(base_file):\n            with open(base_file, \"rb\") as sld_file:\n                sld = sld_file.read()\n            dlxml.parse(base_file)\n    except Exception:\n        logger.exception(\"The uploaded SLD file is not valid XML\")\n        raise Exception(\"The uploaded SLD file is not valid XML\")\n\n    # Check Dataset's available styles\n    match = None\n    styles = list(saved_dataset.styles.all()) + [\n        saved_dataset.default_style]\n    for style in styles:\n        if style and style.name == saved_dataset.name:\n            match = style\n            break\n    layer = gs_catalog.get_layer(title)\n    style = None\n    if match is None:\n        try:\n            style = gs_catalog.get_style(saved_dataset.name, workspace=saved_dataset.workspace) or \\\n                gs_catalog.get_style(saved_dataset.name)\n            if not style:\n                style = gs_catalog.create_style(\n                    saved_dataset.name, sld, overwrite=False, raw=True, workspace=saved_dataset.workspace)\n        except Exception as e:\n            logger.exception(e)\n    else:\n        try:\n            _sld_format = _extract_style_version_from_sld(sld)\n            style = gs_catalog.create_style(\n                saved_dataset.name, sld,\n                overwrite=True, raw=True, style_format=_sld_format,\n                workspace=saved_dataset.workspace)\n        except Exception as e:\n            logger.exception(e)\n\n    if layer and style:\n        _old_styles = []\n        _old_styles.append(gs_catalog.get_style(\n            name=saved_dataset.name))\n        _old_styles.append(gs_catalog.get_style(\n            name=f\"{saved_dataset.workspace}_{saved_dataset.name}\"))\n        if layer.default_style and layer.default_style.name:\n            _old_styles.append(gs_catalog.get_style(\n                name=layer.default_style.name))\n            _old_styles.append(gs_catalog.get_style(\n                name=layer.default_style.name,\n                workspace=layer.default_style.workspace))\n        layer.default_style = style\n        gs_catalog.save(layer)\n        for _s in _old_styles:\n            try:\n                gs_catalog.delete(_s)\n                Link.objects.filter(\n                    resource=saved_dataset.resourcebase_ptr,\n                    name='Legend',\n                    url__contains=f'STYLE={_s.name}').delete()\n            except Exception as e:\n                logger.debug(e)\n        set_styles(saved_dataset, gs_catalog)\n\n\ndef cascading_delete(dataset_name=None, catalog=None):\n    if not dataset_name:\n        return\n    cat = catalog or gs_catalog\n    resource = None\n    workspace = None\n    try:\n        if dataset_name.find(':') != -1 and len(dataset_name.split(':')) == 2:\n            workspace, name = dataset_name.split(':')\n            ws = cat.get_workspace(workspace)\n            store = None\n            try:\n                store = get_store(cat, name, workspace=ws)\n            except FailedRequestError:\n                if ogc_server_settings.DATASTORE:\n                    try:\n                        layers = Dataset.objects.filter(alternate=dataset_name)\n                        for layer in layers:\n                            store = get_store(cat, layer.store, workspace=ws)\n                    except FailedRequestError:\n                        logger.debug(\n                            'the store was not found in geoserver')\n                else:\n                    logger.debug(\n                        'the store was not found in geoserver')\n            if ws is None or store is None:\n                logger.debug(\n                    'cascading delete was called on a layer where the workspace was not found')\n            resource = cat.get_resource(name=name, store=store, workspace=workspace)\n        else:\n            resource = cat.get_resource(name=dataset_name)\n    except OSError as e:\n        if e.errno == errno.ECONNREFUSED:\n            msg = (f'Could not connect to geoserver at \"{ogc_server_settings.LOCATION}\"'\n                   f'to save information for layer \"{dataset_name}\"')\n            logger.error(msg)\n            return None\n        else:\n            raise e\n    finally:\n        # Let's reset the connections first\n        cat._cache.clear()\n        cat.reset()\n        cat.reload()\n\n    if resource is None:\n        # If there is no associated resource,\n        # this method can not delete anything.\n        # Let's return and make a note in the log.\n        logger.debug(\n            'cascading_delete was called with a non existent resource')\n        return\n    resource_name = resource.name\n    lyr = None\n    try:\n        lyr = cat.get_layer(resource_name)\n    except Exception as e:\n        logger.debug(e)\n    if lyr is not None:  # Already deleted\n        store = resource.store\n        styles = lyr.styles\n        try:\n            styles = styles + [lyr.default_style]\n        except Exception:\n            pass\n        if workspace:\n            gs_styles = [x for x in cat.get_styles(names=[f\"{workspace}_{resource_name}\"])]\n            styles = styles + gs_styles\n        if settings.DEFAULT_WORKSPACE and settings.DEFAULT_WORKSPACE != workspace:\n            gs_styles = [x for x in cat.get_styles(names=[f\"{settings.DEFAULT_WORKSPACE}_{resource_name}\"])]\n            styles = styles + gs_styles\n        cat.delete(lyr)\n        for s in styles:\n            if s is not None and s.name not in _default_style_names:\n                try:\n                    logger.debug(f\"Trying to delete Style [{s.name}]\")\n                    cat.delete(s, purge='true')\n                except Exception as e:\n                    # Trying to delete a shared style will fail\n                    # We'll catch the exception and log it.\n                    logger.debug(e)\n\n        # Due to a possible bug of geoserver, we need this trick for now\n        # TODO: inspect the issue reported by this hack. Should be solved\n        #       with GS 2.7+\n        try:\n            cat.delete(resource, recurse=True)  # This may fail\n        except Exception:\n            pass\n\n        if store.resource_type == 'dataStore' and 'dbtype' in store.connection_parameters and \\\n                store.connection_parameters['dbtype'] == 'postgis':\n            delete_from_postgis(resource_name, store)\n        else:\n            # AF: for the time being this one mitigates the issue #8671\n            # until we find a suitable solution for the GeoTools ImageMosaic plugin\n            # ref: https://github.com/geotools/geotools/blob/main/modules/plugin/imagemosaic/src/main/java/org/geotools/gce/imagemosaic/catalog/AbstractGTDataStoreGranuleCatalog.java#L753\n            if store.resource_type == 'coverageStore' and store.type != 'ImageMosaic':\n                try:\n                    logger.debug(f\" - Going to purge the {store.resource_type} : {store.href}\")\n                    cat.reset()  # this resets the coverage readers and unlocks the files\n                    cat.delete(store, purge='all', recurse=True)\n                    # cat.reload()  # this preservers the integrity of geoserver\n                except Exception as e:\n                    # Trying to recursively purge a store may fail\n                    # We'll catch the exception and log it.\n                    logger.debug(e)\n            else:\n                try:\n                    if not store.get_resources():\n                        cat.delete(store, recurse=True)\n                except Exception as e:\n                    # Catch the exception and log it.\n                    logger.debug(e)\n\n\ndef delete_from_postgis(dataset_name, store):\n    \"\"\"\n    Delete a table from PostGIS (because Geoserver won't do it yet);\n    to be used after deleting a layer from the system.\n    \"\"\"\n    import psycopg2\n\n    # we will assume that store/database may change (when using shard for example)\n    # but user and password are the ones from settings (DATASTORE_URL)\n    db = ogc_server_settings.datastore_db\n    db_name = store.connection_parameters['database']\n    user = db['USER']\n    password = db['PASSWORD']\n    host = store.connection_parameters['host']\n    port = store.connection_parameters['port']\n    conn = None\n    try:\n        conn = psycopg2.connect(dbname=db_name, user=user, host=host, port=port, password=password)\n        cur = conn.cursor()\n        cur.execute(f\"SELECT DropGeometryTable ('{dataset_name}')\")\n        conn.commit()\n    except Exception as e:\n        logger.error(\n            \"Error deleting PostGIS table %s:%s\",\n            dataset_name,\n            str(e))\n    finally:\n        try:\n            if conn:\n                conn.close()\n        except Exception as e:\n            logger.error(\"Error closing PostGIS conn %s:%s\", dataset_name, str(e))\n\n\ndef gs_slurp(\n        ignore_errors=False,\n        verbosity=1,\n        console=None,\n        owner=None,\n        workspace=None,\n        store=None,\n        filter=None,\n        skip_unadvertised=False,\n        skip_geonode_registered=False,\n        remove_deleted=False,\n        permissions=None,\n        execute_signals=False):\n    \"\"\"Configure the layers available in GeoServer in GeoNode.\n       It returns a list of dictionaries with the name of the layer,\n       the result of the operation and the errors and traceback if it failed.\n    \"\"\"\n    from geonode.resource.manager import resource_manager\n\n    if console is None:\n        console = open(os.devnull, 'w')\n\n    if verbosity > 0:\n        print(\"Inspecting the available layers in GeoServer ...\", file=console)\n\n    cat = gs_catalog\n\n    if workspace is not None and workspace:\n        workspace = cat.get_workspace(workspace)\n        if workspace is None:\n            resources = []\n        else:\n            # obtain the store from within the workspace. if it exists, obtain resources\n            # directly from store, otherwise return an empty list:\n            if store is not None:\n                store = get_store(cat, store, workspace=workspace)\n                if store is None:\n                    resources = []\n                else:\n                    resources = cat.get_resources(stores=[store])\n            else:\n                resources = cat.get_resources(workspaces=[workspace])\n    elif store is not None:\n        store = get_store(cat, store)\n        resources = cat.get_resources(stores=[store])\n    else:\n        resources = cat.get_resources()\n\n    if remove_deleted:\n        resources_for_delete_compare = resources[:]\n        workspace_for_delete_compare = workspace\n        # filter out layers for delete comparison with GeoNode layers by following criteria:\n        # enabled = true, if --skip-unadvertised: advertised = true, but\n        # disregard the filter parameter in the case of deleting layers\n        try:\n            resources_for_delete_compare = [\n                k for k in resources_for_delete_compare if k.enabled in {\"true\", True}]\n            if skip_unadvertised:\n                resources_for_delete_compare = [\n                    k for k in resources_for_delete_compare if k.advertised in {\"true\", True}]\n        except Exception:\n            if ignore_errors:\n                pass\n            else:\n                raise\n\n    if filter:\n        resources = [k for k in resources if filter in k.name]\n\n    # filter out layers depending on enabled, advertised status:\n    _resources = []\n    for k in resources:\n        try:\n            if k.enabled in {\"true\", True}:\n                _resources.append(k)\n        except Exception:\n            if ignore_errors:\n                continue\n            else:\n                raise\n    # resources = [k for k in resources if k.enabled in {\"true\", True}]\n    resources = _resources\n    if skip_unadvertised:\n        try:\n            resources = [k for k in resources if k.advertised in {\"true\", True}]\n        except Exception:\n            if ignore_errors:\n                pass\n            else:\n                raise\n\n    # filter out layers already registered in geonode\n    dataset_names = Dataset.objects.values_list('alternate', flat=True)\n    if skip_geonode_registered:\n        try:\n            resources = [k for k in resources\n                         if f'{k.workspace.name}:{k.name}' not in dataset_names]\n        except Exception:\n            if ignore_errors:\n                pass\n            else:\n                raise\n\n    # TODO: Should we do something with these?\n    # i.e. look for matching layers in GeoNode and also disable?\n    # disabled_resources = [k for k in resources if k.enabled == \"false\"]\n\n    number = len(resources)\n    if verbosity > 0:\n        msg = \"Found %d layers, starting processing\" % number\n        print(msg, file=console)\n    output = {\n        'stats': {\n            'failed': 0,\n            'updated': 0,\n            'created': 0,\n            'deleted': 0,\n        },\n        'layers': [],\n        'deleted_datasets': []\n    }\n    start = datetime.datetime.now(timezone.get_current_timezone())\n    for i, resource in enumerate(resources):\n        name = resource.name\n        the_store = resource.store\n        workspace = the_store.workspace\n        layer = None\n        try:\n            created = False\n            layer = Dataset.objects.filter(name=name, workspace=workspace.name).first()\n            if not layer:\n                layer = resource_manager.create(\n                    str(uuid.uuid4()),\n                    resource_type=Dataset,\n                    defaults=dict(\n                        name=name,\n                        workspace=workspace.name,\n                        store=the_store.name,\n                        subtype=get_dataset_storetype(the_store.resource_type),\n                        alternate=f\"{workspace.name}:{resource.name}\",\n                        title=resource.title or _('No title provided'),\n                        abstract=resource.abstract or _('No abstract provided'),\n                        owner=owner\n                    )\n                )\n                created = True\n            # Hide the resource until finished\n            layer.set_processing_state(\"RUNNING\")\n            bbox = resource.native_bbox\n            ll_bbox = resource.latlon_bbox\n            try:\n                layer.set_bbox_polygon([bbox[0], bbox[2], bbox[1], bbox[3]], resource.projection)\n            except GeoNodeException as e:\n                if not ll_bbox:\n                    raise\n                else:\n                    logger.exception(e)\n                    layer.srid = 'EPSG:4326'\n            layer.set_ll_bbox_polygon([ll_bbox[0], ll_bbox[2], ll_bbox[1], ll_bbox[3]])\n\n            # sync permissions in GeoFence\n            perm_spec = json.loads(_perms_info_json(layer))\n            resource_manager.set_permissions(\n                layer.uuid,\n                permissions=perm_spec)\n\n            # recalculate the layer statistics\n            set_attributes_from_geoserver(layer, overwrite=True)\n\n            # in some cases we need to explicitily save the resource to execute the signals\n            # (for sure when running updatelayers)\n            resource_manager.update(\n                layer.uuid,\n                instance=layer,\n                notify=execute_signals)\n\n            # Creating the Thumbnail\n            resource_manager.set_thumbnail(\n                layer.uuid,\n                overwrite=True, check_bbox=False\n            )\n\n        except Exception as e:\n            # Hide the resource until finished\n            if layer:\n                layer.set_processing_state(\"FAILED\")\n            if ignore_errors:\n                status = 'failed'\n                exception_type, error, traceback = sys.exc_info()\n            else:\n                if verbosity > 0:\n                    msg = \"Stopping process because --ignore-errors was not set and an error was found.\"\n                    print(msg, file=sys.stderr)\n                raise Exception(f\"Failed to process {resource.name}\") from e\n        if layer is None:\n            if ignore_errors:\n                status = 'failed'\n                exception_type, error, traceback = sys.exc_info()\n            else:\n                if verbosity > 0:\n                    msg = \"Stopping process because --ignore-errors was not set and an error was found.\"\n                    print(msg, file=sys.stderr)\n                raise Exception(f\"Failed to process {resource.name}\")\n        else:\n            if created:\n                if not permissions:\n                    layer.set_default_permissions()\n                else:\n                    layer.set_permissions(permissions)\n\n                status = 'created'\n                output['stats']['created'] += 1\n            else:\n                status = 'updated'\n                output['stats']['updated'] += 1\n\n        msg = f\"[{status}] Dataset {name} ({(i + 1)}/{number})\"\n        info = {'name': name, 'status': status}\n        if status == 'failed':\n            output['stats']['failed'] += 1\n            info['traceback'] = traceback\n            info['exception_type'] = exception_type\n            info['error'] = error\n        output['layers'].append(info)\n        if verbosity > 0:\n            print(msg, file=console)\n\n    if remove_deleted:\n        q = Dataset.objects.filter()\n        if workspace_for_delete_compare is not None:\n            if isinstance(workspace_for_delete_compare, Workspace):\n                q = q.filter(\n                    workspace__exact=workspace_for_delete_compare.name)\n            else:\n                q = q.filter(workspace__exact=workspace_for_delete_compare)\n        if store is not None:\n            if isinstance(\n                    store,\n                    CoverageStore) or isinstance(\n                    store,\n                    DataStore):\n                q = q.filter(store__exact=store.name)\n            else:\n                q = q.filter(store__exact=store)\n        logger.debug(\"Executing 'remove_deleted' logic\")\n        logger.debug(\"GeoNode Layers Found:\")\n\n        # compare the list of GeoNode layers obtained via query/filter with valid resources found in GeoServer\n        # filtered per options passed to updatelayers: --workspace, --store, --skip-unadvertised\n        # add any layers not found in GeoServer to deleted_datasets (must match\n        # workspace and store as well):\n        deleted_datasets = []\n        for layer in q:\n            logger.debug(\n                \"GeoNode Dataset info: name: %s, workspace: %s, store: %s\",\n                layer.name,\n                layer.workspace,\n                layer.store)\n            dataset_found_in_geoserver = False\n            for resource in resources_for_delete_compare:\n                # if layer.name matches a GeoServer resource, check also that\n                # workspace and store match, mark valid:\n                if layer.name == resource.name:\n                    if layer.workspace == resource.workspace.name and layer.store == resource.store.name:\n                        logger.debug(\n                            \"Matches GeoServer layer: name: %s, workspace: %s, store: %s\",\n                            resource.name,\n                            resource.workspace.name,\n                            resource.store.name)\n                        dataset_found_in_geoserver = True\n            if not dataset_found_in_geoserver:\n                logger.debug(\n                    \"----- Dataset %s not matched, marked for deletion ---------------\",\n                    layer.name)\n                deleted_datasets.append(layer)\n\n        number_deleted = len(deleted_datasets)\n        if verbosity > 0:\n            msg = \"\\nFound %d layers to delete, starting processing\" % number_deleted if number_deleted > 0 else \\\n                \"\\nFound %d layers to delete\" % number_deleted\n            print(msg, file=console)\n\n        for i, layer in enumerate(deleted_datasets):\n            logger.debug(\n                \"GeoNode Dataset to delete: name: %s, workspace: %s, store: %s\",\n                layer.name,\n                layer.workspace,\n                layer.store)\n            try:\n                # delete ratings, and taggit tags:\n                ct = ContentType.objects.get_for_model(layer)\n                OverallRating.objects.filter(\n                    content_type=ct,\n                    object_id=layer.id).delete()\n                layer.keywords.clear()\n\n                layer.delete()\n                output['stats']['deleted'] += 1\n                status = \"delete_succeeded\"\n            except Exception:\n                status = \"delete_failed\"\n\n            msg = f\"[{status}] Dataset {layer.name} ({(i + 1)}/{number_deleted})\"\n            info = {'name': layer.name, 'status': status}\n            if status == \"delete_failed\":\n                exception_type, error, traceback = sys.exc_info()\n                info['traceback'] = traceback\n                info['exception_type'] = exception_type\n                info['error'] = error\n            output['deleted_datasets'].append(info)\n            if verbosity > 0:\n                print(msg, file=console)\n\n    finish = datetime.datetime.now(timezone.get_current_timezone())\n    td = finish - start\n    output['stats']['duration_sec'] = td.microseconds / \\\n        1000000 + td.seconds + td.days * 24 * 3600\n    return output\n\n\ndef get_stores(store_type=None):\n    cat = gs_catalog\n    stores = cat.get_stores()\n    store_list = []\n    for store in stores:\n        store.fetch()\n        stype = store.dom.find('type').text.lower()\n        if store_type and store_type.lower() == stype:\n            store_list.append({'name': store.name, 'type': stype})\n        elif store_type is None:\n            store_list.append({'name': store.name, 'type': stype})\n    return store_list\n\n\ndef set_attributes(\n        layer,\n        attribute_map,\n        overwrite=False,\n        attribute_stats=None):\n    \"\"\" *layer*: a geonode.layers.models.Dataset instance\n        *attribute_map*: a list of 2-lists specifying attribute names and types,\n            example: [ ['id', 'Integer'], ... ]\n        *overwrite*: replace existing attributes with new values if name/type matches.\n        *attribute_stats*: dictionary of return values from get_attribute_statistics(),\n            of the form to get values by referencing attribute_stats[<dataset_name>][<field_name>].\n    \"\"\"\n    # we need 3 more items; description, attribute_label, and display_order\n    attribute_map_dict = {\n        'field': 0,\n        'ftype': 1,\n        'description': 2,\n        'label': 3,\n        'display_order': 4,\n    }\n    for attribute in attribute_map:\n        if len(attribute) == 2:\n            attribute.extend((None, None, 0))\n\n    attributes = layer.attribute_set.all()\n    # Delete existing attributes if they no longer exist in an updated layer\n    for la in attributes:\n        lafound = False\n        for attribute in attribute_map:\n            field, ftype, description, label, display_order = attribute\n            if field == la.attribute:\n                lafound = True\n                # store description and attribute_label in attribute_map\n                attribute[attribute_map_dict['description']] = la.description\n                attribute[attribute_map_dict['label']] = la.attribute_label\n                attribute[attribute_map_dict['display_order']] = la.display_order\n        if overwrite or not lafound:\n            logger.debug(\n                \"Going to delete [%s] for [%s]\",\n                la.attribute,\n                layer.name)\n            la.delete()\n\n    # Add new layer attributes if they doesn't exist already\n    if attribute_map:\n        iter = len(Attribute.objects.filter(dataset=layer)) + 1\n        for attribute in attribute_map:\n            field, ftype, description, label, display_order = attribute\n            if field:\n                _gs_attrs = Attribute.objects.filter(dataset=layer, attribute=field)\n                if _gs_attrs.count() == 1:\n                    la = _gs_attrs.get()\n                else:\n                    if _gs_attrs.exists():\n                        _gs_attrs.delete()\n                    la = Attribute.objects.create(dataset=layer, attribute=field)\n                    la.visible = ftype.find(\"gml:\") != 0\n                    la.attribute_type = ftype\n                    la.description = description\n                    la.attribute_label = label\n                    la.display_order = iter\n                    iter += 1\n                if (not attribute_stats or layer.name not in attribute_stats or\n                        field not in attribute_stats[layer.name]):\n                    result = None\n                else:\n                    result = attribute_stats[layer.name][field]\n                if result:\n                    logger.debug(\"Generating layer attribute statistics\")\n                    la.count = result['Count']\n                    la.min = result['Min']\n                    la.max = result['Max']\n                    la.average = result['Average']\n                    la.median = result['Median']\n                    la.stddev = result['StandardDeviation']\n                    la.sum = result['Sum']\n                    la.unique_values = result['unique_values']\n                    la.last_stats_updated = datetime.datetime.now(timezone.get_current_timezone())\n                try:\n                    la.save()\n                except Exception as e:\n                    logger.exception(e)\n    else:\n        logger.debug(\"No attributes found\")\n\n\ndef set_attributes_from_geoserver(layer, overwrite=False):\n    \"\"\"\n    Retrieve layer attribute names & types from Geoserver,\n    then store in GeoNode database using Attribute model\n    \"\"\"\n    attribute_map = []\n    if getattr(layer, 'remote_service') and layer.remote_service:\n        server_url = layer.remote_service.service_url\n        if layer.remote_service.operations.get('GetCapabilities', None) and layer.remote_service.operations.get('GetCapabilities').get('methods'):\n            for _method in layer.remote_service.operations.get('GetCapabilities').get('methods'):\n                if _method.get('type', '').upper() == 'GET':\n                    server_url = _method.get('url', server_url)\n                    break\n    else:\n        server_url = ogc_server_settings.LOCATION\n    if layer.subtype in ['tileStore', 'remote'] and layer.remote_service.ptype == \"gxp_arcrestsource\":\n        dft_url = f\"{server_url}{(layer.alternate or layer.typename)}?f=json\"\n        try:\n            # The code below will fail if http_client cannot be imported\n            req, body = http_client.get(dft_url, user=_user)\n            body = json.loads(body)\n            attribute_map = [[n[\"name\"], _esri_types[n[\"type\"]]]\n                             for n in body[\"fields\"] if n.get(\"name\") and n.get(\"type\")]\n        except Exception:\n            tb = traceback.format_exc()\n            logger.debug(tb)\n            attribute_map = []\n    elif layer.subtype in {\"vector\", \"tileStore\", \"remote\", \"wmsStore\", \"vector_time\"}:\n        typename = layer.alternate if layer.alternate else layer.typename\n        dft_url_path = re.sub(r\"\\/wms\\/?$\", \"/\", server_url)\n        dft_query = urlencode(\n            {\n                \"service\": \"wfs\",\n                \"version\": \"1.0.0\",\n                \"request\": \"DescribeFeatureType\",\n                \"typename\": typename\n            }\n        )\n        dft_url = urljoin(dft_url_path, f\"ows?{dft_query}\")\n        try:\n            # The code below will fail if http_client cannot be imported or WFS not supported\n            req, body = http_client.get(dft_url, user=_user)\n            doc = dlxml.fromstring(body.encode())\n            xsd = \"{http://www.w3.org/2001/XMLSchema}\"\n            path = f\".//{xsd}extension/{xsd}sequence/{xsd}element\"\n            attribute_map = [[n.attrib[\"name\"], n.attrib[\"type\"]] for n in doc.findall(\n                path) if n.attrib.get(\"name\") and n.attrib.get(\"type\")]\n        except Exception:\n            tb = traceback.format_exc()\n            logger.debug(tb)\n            attribute_map = []\n            # Try WMS instead\n            dft_url = server_url + \"?\" + urlencode({\n                \"service\": \"wms\",\n                \"version\": \"1.0.0\",\n                \"request\": \"GetFeatureInfo\",\n                \"bbox\": ','.join([str(x) for x in layer.bbox]),\n                \"LAYERS\": layer.alternate,\n                \"QUERY_LAYERS\": typename,\n                \"feature_count\": 1,\n                \"width\": 1,\n                \"height\": 1,\n                \"srs\": \"EPSG:4326\",\n                \"info_format\": \"text/html\",\n                \"x\": 1,\n                \"y\": 1\n            })\n            try:\n                req, body = http_client.get(dft_url, user=_user)\n                soup = BeautifulSoup(body, features=\"lxml\")\n                for field in soup.findAll('th'):\n                    if field.string is None:\n                        field_name = field.contents[0].string\n                    else:\n                        field_name = field.string\n                    attribute_map.append([field_name, \"xsd:string\"])\n            except Exception:\n                tb = traceback.format_exc()\n                logger.debug(tb)\n                attribute_map = []\n    elif layer.subtype in [\"raster\"]:\n        typename = layer.alternate if layer.alternate else layer.typename\n        dc_url = f\"{server_url}wcs?{urlencode({'service': 'wcs', 'version': '1.1.0', 'request': 'DescribeCoverage', 'identifiers': typename})}\"\n        try:\n            req, body = http_client.get(dc_url, user=_user)\n            doc = dlxml.fromstring(body.encode())\n            wcs = \"{http://www.opengis.net/wcs/1.1.1}\"\n            path = f\".//{wcs}Axis/{wcs}AvailableKeys/{wcs}Key\"\n            attribute_map = [[n.text, \"raster\"] for n in doc.findall(path)]\n        except Exception:\n            tb = traceback.format_exc()\n            logger.debug(tb)\n            attribute_map = []\n    # Get attribute statistics & package for call to really_set_attributes()\n    attribute_stats = defaultdict(dict)\n    # Add new layer attributes if they don't already exist\n    for attribute in attribute_map:\n        field, ftype = attribute\n        if field is not None:\n            if Attribute.objects.filter(dataset=layer, attribute=field).exists():\n                continue\n            elif is_dataset_attribute_aggregable(\n                    layer.subtype,\n                    field,\n                    ftype):\n                logger.debug(\"Generating layer attribute statistics\")\n                result = get_attribute_statistics(layer.alternate or layer.typename, field)\n            else:\n                result = None\n            attribute_stats[layer.name][field] = result\n    set_attributes(\n        layer, attribute_map, overwrite=overwrite, attribute_stats=attribute_stats\n    )\n\n\ndef get_dataset(layer, gs_catalog: Catalog):\n    gs_catalog.reset()\n    gs_dataset = None\n    try:\n        gs_dataset = gs_catalog.get_layer(layer.name)\n    except Exception:\n        tb = traceback.format_exc()\n        logger.exception(tb)\n\n    if not gs_dataset:\n        try:\n            gs_dataset = gs_catalog.get_layer(layer.alternate or layer.typename)\n        except Exception:\n            tb = traceback.format_exc()\n            logger.error(tb)\n            logger.exception(\"No GeoServer Dataset found!\")\n    return gs_dataset\n\n\ndef clean_styles(layer, gs_catalog: Catalog):\n    try:\n        # Cleanup Styles without a Workspace\n        gs_catalog.reset()\n        gs_dataset = get_dataset(layer, gs_catalog)\n        logger.debug(f'clean_styles: Retrieving style \"{gs_dataset.default_style.name}\" for cleanup')\n        style = gs_catalog.get_style(\n            name=gs_dataset.default_style.name,\n            workspace=None,\n            recursive=True)\n        if style:\n            gs_catalog.delete(style, purge=True, recurse=False)\n            logger.debug(f'clean_styles: Style removed: {gs_dataset.default_style.name}')\n        else:\n            logger.debug(f'clean_styles: Style does not exist: {gs_dataset.default_style.name}')\n    except Exception as e:\n        logger.warning(f'Could not clean style for layer {layer.name}', exc_info=e)\n        logger.debug(f'Could not clean style for layer {layer.name} - STACK INFO', stack_info=True)\n\n\ndef set_styles(layer, gs_catalog: Catalog):\n    style_set = []\n    gs_dataset = get_dataset(layer, gs_catalog)\n    if gs_dataset:\n        default_style = gs_dataset.get_full_default_style()\n        if default_style:\n            # make sure we are not using a default SLD (which won't be editable)\n            layer.default_style, _gs_default_style = save_style(default_style, layer)\n            try:\n                if default_style.name != _gs_default_style.name or default_style.workspace != _gs_default_style.workspace:\n                    logger.debug(f'set_style: Setting default style \"{_gs_default_style.name}\" for layer \"{layer.name}')\n\n                    gs_dataset.default_style = _gs_default_style\n                    gs_catalog.save(gs_dataset)\n                    if default_style.name not in DEFAULT_STYLE_NAME:\n                        logger.debug(f'set_style: Retrieving no-workspace default style \"{default_style.name}\" for deletion')\n                        style_to_delete = gs_catalog.get_style(name=default_style.name, workspace=None, recursive=True)\n                        if style_to_delete:\n                            gs_catalog.delete(style_to_delete, purge=True, recurse=False)\n                            logger.debug(f'set_style: No-ws default style deleted: {default_style.name}')\n                        else:\n                            logger.debug(f'set_style: No-ws default style does not exist: {default_style.name}')\n            except Exception as e:\n                logger.error(f'Error setting default style \"{_gs_default_style.name}\" for layer \"{layer.name}', exc_info=e)\n\n            style_set.append(layer.default_style)\n\n        try:\n            if gs_dataset.styles:\n                alt_styles = gs_dataset.styles\n                for alt_style in alt_styles:\n                    if alt_style and alt_style.name and alt_style.name != layer.default_style.name and alt_style.workspace != layer.default_style.workspace:\n                        _s, _ = save_style(alt_style, layer)\n                        style_set.append(_s)\n        except Exception as e:\n            logger.exception(e)\n\n    if style_set:\n        # Remove duplicates\n        style_set = list(dict.fromkeys(style_set))\n        layer.styles.set(style_set)\n\n    clean_styles(layer, gs_catalog)\n\n    # Update default style to database\n    to_update = {\n        'default_style': layer.default_style\n    }\n\n    Dataset.objects.filter(id=layer.id).update(**to_update)\n    layer.refresh_from_db()\n\n    # Legend links\n    logger.debug(f\" -- Resource Links[Legend link] for layer {layer.name}...\")\n    try:\n        from geonode.base.models import Link\n        dataset_legends = Link.objects.filter(resource=layer.resourcebase_ptr, name='Legend')\n        for style in set(list(layer.styles.all()) + [layer.default_style, ]):\n            if style:\n                style_name = os.path.basename(\n                    urlparse(style.sld_url).path).split('.')[0]\n                legend_url = get_legend_url(layer, style_name)\n                if dataset_legends.filter(resource=layer.resourcebase_ptr, name='Legend', url=legend_url).count() < 2:\n                    Link.objects.update_or_create(\n                        resource=layer.resourcebase_ptr,\n                        name='Legend',\n                        url=legend_url,\n                        defaults=dict(\n                            extension='png',\n                            url=legend_url,\n                            mime='image/png',\n                            link_type='image',\n                        )\n                    )\n        logger.debug(\" -- Resource Links[Legend link]...done!\")\n    except Exception as e:\n        logger.debug(f\" -- Resource Links[Legend link]...error: {e}\")\n\n    try:\n        set_geowebcache_invalidate_cache(layer.alternate or layer.typename, cat=gs_catalog)\n    except Exception:\n        tb = traceback.format_exc()\n        logger.debug(tb)\n\n\ndef save_style(gs_style, layer):\n    style_name = os.path.basename(\n        urlparse(gs_style.body_href).path).split('.')[0]\n    sld_name = copy.copy(gs_style.name)\n    sld_body = copy.copy(gs_style.sld_body)\n    _gs_style = None\n    if not gs_style.workspace:\n        logger.debug(f'save_style: Copying style \"{sld_name}\" to \"{layer.workspace}:{layer.name}')\n        _gs_style = gs_catalog.create_style(\n            layer.name, sld_body,\n            raw=True, overwrite=True,\n            workspace=layer.workspace)\n    else:\n        logger.debug(f'save_style: Retrieving style \"{layer.workspace}:{sld_name}\" for layer \"{layer.workspace}:{layer.name}')\n        _gs_style = gs_catalog.get_style(\n            name=sld_name,\n            workspace=layer.workspace\n        )\n\n    style = None\n    try:\n        style, _ = Style.objects.get_or_create(name=style_name)\n        style.workspace = _gs_style.workspace\n        style.sld_title = _gs_style.sld_title if _gs_style.style_format != 'css' and _gs_style.sld_title else sld_name\n        style.sld_body = _gs_style.sld_body\n        style.sld_url = _gs_style.body_href\n        style.save()\n    except Exception as e:\n        tb = traceback.format_exc()\n        logger.debug(tb)\n        raise e\n    return (style, _gs_style)\n\n\ndef is_dataset_attribute_aggregable(store_type, field_name, field_type):\n    \"\"\"\n    Decipher whether layer attribute is suitable for statistical derivation\n    \"\"\"\n\n    # must be vector layer\n    if store_type != 'dataStore':\n        return False\n    # must be a numeric data type\n    if field_type not in LAYER_ATTRIBUTE_NUMERIC_DATA_TYPES:\n        return False\n    # must not be an identifier type field\n    if field_name.lower() in {'id', 'identifier'}:\n        return False\n\n    return True\n\n\ndef get_attribute_statistics(dataset_name, field):\n    \"\"\"\n    Generate statistics (range, mean, median, standard deviation, unique values)\n    for layer attribute\n    \"\"\"\n\n    logger.debug('Deriving aggregate statistics for attribute %s', field)\n\n    if not ogc_server_settings.WPS_ENABLED:\n        return None\n    try:\n        return wps_execute_dataset_attribute_statistics(dataset_name, field)\n    except Exception:\n        tb = traceback.format_exc()\n        logger.debug(tb)\n        logger.exception('Error generating layer aggregate statistics')\n\n\ndef get_wcs_record(instance, retry=True):\n    wcs = WebCoverageService(f\"{ogc_server_settings.LOCATION}wcs\", '1.0.0')\n    key = f\"{instance.workspace}:{instance.name}\"\n    logger.debug(wcs.contents)\n    if key in wcs.contents:\n        return wcs.contents[key]\n    else:\n        msg = (f\"Dataset '{key}' was not found in WCS service at {ogc_server_settings.public_url}.\"\n               )\n        if retry:\n            logger.debug(\n                f\"{msg} Waiting a couple of seconds before trying again.\")\n            time.sleep(2)\n            return get_wcs_record(instance, retry=False)\n        else:\n            raise GeoNodeException(msg)\n\n\ndef get_coverage_grid_extent(instance):\n    \"\"\"\n        Returns a list of integers with the size of the coverage\n        extent in pixels\n    \"\"\"\n    instance_wcs = get_wcs_record(instance)\n    grid = instance_wcs.grid\n    return [(int(h) - int(l) + 1) for\n            h, l in zip(grid.highlimits, grid.lowlimits)]\n\n\nGEOSERVER_LAYER_TYPES = {\n    'vector': FeatureType.resource_type,\n    'raster': Coverage.resource_type,\n}\n\n\ndef cleanup(name, uuid):\n    \"\"\"Deletes GeoServer and Catalogue records for a given name.\n       Useful to clean the mess when something goes terribly wrong.\n       It also verifies if the Django record existed, in which case\n       it performs no action.\n    \"\"\"\n    try:\n        Dataset.objects.get(name=name)\n    except Dataset.DoesNotExist:\n        pass\n    else:\n        msg = f'Not doing any cleanup because the layer {name} exists in the Django db.'\n        raise GeoNodeException(msg)\n\n    cat = gs_catalog\n    gs_store = None\n    gs_dataset = None\n    gs_resource = None\n    # FIXME: Could this lead to someone deleting for example a postgis db\n    # with the same name of the uploaded file?.\n    try:\n        gs_store = cat.get_store(name)\n        if gs_store is not None:\n            gs_dataset = cat.get_layer(name)\n            if gs_dataset is not None:\n                gs_resource = gs_dataset.resource\n        else:\n            gs_dataset = None\n            gs_resource = None\n    except FailedRequestError as e:\n        msg = ('Couldn\\'t connect to GeoServer while cleaning up layer '\n               '[%s] !!', str(e))\n        logger.warning(msg)\n\n    if gs_dataset is not None:\n        try:\n            cat.delete(gs_dataset)\n        except Exception:\n            logger.warning(\"Couldn't delete GeoServer layer during cleanup()\")\n    if gs_resource is not None:\n        try:\n            cat.delete(gs_resource)\n        except Exception:\n            msg = 'Couldn\\'t delete GeoServer resource during cleanup()'\n            logger.warning(msg)\n    if gs_store is not None:\n        try:\n            cat.delete(gs_store)\n        except Exception:\n            logger.warning(\"Couldn't delete GeoServer store during cleanup()\")\n\n    logger.warning('Deleting dangling Catalogue record for [%s] '\n                   '(no Django record to match)', name)\n\n    if 'geonode.catalogue' in settings.INSTALLED_APPS:\n        from geonode.catalogue import get_catalogue\n        catalogue = get_catalogue()\n        catalogue.remove_record(uuid)\n        logger.warning('Finished cleanup after failed Catalogue/Django '\n                       'import for layer: %s', name)\n\n\ndef create_geoserver_db_featurestore(\n        store_type=None, store_name=None,\n        author_name='admin', author_email='admin@geonode.org',\n        charset=\"UTF-8\", workspace=None):\n    cat = gs_catalog\n    dsname = store_name or ogc_server_settings.DATASTORE\n    # get or create datastore\n    ds_exists = False\n    try:\n        if dsname:\n            ds = cat.get_store(dsname, workspace=workspace)\n        else:\n            return None\n        if ds is None:\n            raise FailedRequestError\n        ds_exists = True\n    except FailedRequestError:\n        logger.debug(\n            f'Creating target datastore {dsname}')\n        ds = cat.create_datastore(dsname, workspace=workspace)\n        db = ogc_server_settings.datastore_db\n        db_engine = 'postgis' if \\\n            'postgis' in db['ENGINE'] else db['ENGINE']\n        ds.connection_parameters.update(\n            {'Evictor run periodicity': 300,\n             'Estimated extends': 'true',\n             'fetch size': 100000,\n             'encode functions': 'false',\n             'Expose primary keys': 'true',\n             'validate connections': 'true',\n             'Support on the fly geometry simplification': 'false',\n             'Connection timeout': 10,\n             'create database': 'false',\n             'Batch insert size': 30,\n             'preparedStatements': 'true',\n             'min connections': 10,\n             'max connections': 100,\n             'Evictor tests per run': 3,\n             'Max connection idle time': 300,\n             'Loose bbox': 'true',\n             'Test while idle': 'true',\n             'host': db['HOST'],\n             'port': db['PORT'] if isinstance(\n                 db['PORT'], str) else str(db['PORT']) or '5432',\n             'database': db['NAME'],\n             'user': db['USER'],\n             'passwd': db['PASSWORD'],\n             'dbtype': db_engine}\n        )\n\n    if ds_exists:\n        ds.save_method = \"PUT\"\n    else:\n        logger.debug('Updating target datastore % s' % dsname)\n        try:\n            cat.save(ds)\n        except FailedRequestError as e:\n            if 'already exists in workspace' not in e.args[0]:\n                raise e\n            logger.warning(\"The store was already present in the workspace selected\")\n\n    logger.debug('Reloading target datastore % s' % dsname)\n    ds = get_store(cat, dsname, workspace=workspace)\n    assert ds.enabled\n\n    return ds\n\n\ndef _create_featurestore(name, data, overwrite=False, charset=\"UTF-8\", workspace=None):\n\n    cat = gs_catalog\n    cat.create_featurestore(name, data, workspace=workspace, overwrite=overwrite, charset=charset)\n    store = get_store(cat, name, workspace=workspace)\n    return store, cat.get_resource(name=name, store=store, workspace=workspace)\n\n\ndef _create_coveragestore(name, data, overwrite=False, charset=\"UTF-8\", workspace=None):\n    cat = gs_catalog\n    cat.create_coveragestore(name, path=data, workspace=workspace, overwrite=overwrite, upload_data=True)\n    store = get_store(cat, name, workspace=workspace)\n    return store, cat.get_resource(name=name, store=store, workspace=workspace)\n\n\ndef _create_db_featurestore(name, data, overwrite=False, charset=\"UTF-8\", workspace=None):\n    \"\"\"Create a database store then use it to import a shapefile.\n\n    If the import into the database fails then delete the store\n    (and delete the PostGIS table for it).\n    \"\"\"\n    cat = gs_catalog\n    db = ogc_server_settings.datastore_db\n    # dsname = ogc_server_settings.DATASTORE\n    dsname = db['NAME']\n    ds = create_geoserver_db_featurestore(store_name=dsname, workspace=workspace)\n\n    try:\n        cat.add_data_to_store(ds,\n                              name,\n                              data,\n                              overwrite=overwrite,\n                              workspace=workspace,\n                              charset=charset)\n        resource = cat.get_resource(name=name, store=ds, workspace=workspace)\n        assert resource is not None\n        return ds, resource\n    except Exception:\n        msg = _(\"An exception occurred loading data to PostGIS\")\n        msg += f\"- {sys.exc_info()[1]}\"\n        try:\n            delete_from_postgis(name, ds)\n        except Exception:\n            msg += _(\" Additionally an error occured during database cleanup\")\n            msg += f\"- {sys.exc_info()[1]}\"\n        raise GeoNodeException(msg)\n\n\ndef get_store(cat, name, workspace=None):\n    # Make sure workspace is a workspace object and not a string.\n    # If the workspace does not exist, continue as if no workspace had been defined.\n    if isinstance(workspace, str):\n        workspace = cat.get_workspace(workspace)\n\n    if workspace is None:\n        workspace = cat.get_default_workspace()\n\n    if workspace:\n        try:\n            store = cat.get_xml(f'{workspace.datastore_url[:-4]}/{name}.xml')\n        except FailedRequestError:\n            try:\n                store = cat.get_xml(f'{workspace.coveragestore_url[:-4]}/{name}.xml')\n            except FailedRequestError:\n                try:\n                    store = cat.get_xml(f'{workspace.wmsstore_url[:-4]}/{name}.xml')\n                except FailedRequestError:\n                    raise FailedRequestError(f\"No store found named: {name}\")\n        if store:\n            if store.tag == 'dataStore':\n                store = datastore_from_index(cat, workspace, store)\n            elif store.tag == 'coverageStore':\n                store = coveragestore_from_index(cat, workspace, store)\n            elif store.tag == 'wmsStore':\n                store = wmsstore_from_index(cat, workspace, store)\n            return store\n        else:\n            raise FailedRequestError(f\"No store found named: {name}\")\n    else:\n        raise FailedRequestError(f\"No store found named: {name}\")\n\n\ndef fetch_gs_resource(instance, values, tries):\n    _max_tries = getattr(ogc_server_settings, \"MAX_RETRIES\", 2)\n    try:\n        gs_resource = gs_catalog.get_resource(\n            name=instance.name,\n            store=instance.store,\n            workspace=instance.workspace)\n    except Exception:\n        try:\n            gs_resource = gs_catalog.get_resource(\n                name=instance.alternate,\n                store=instance.store,\n                workspace=instance.workspace)\n        except Exception:\n            try:\n                gs_resource = gs_catalog.get_resource(\n                    name=instance.alternate or instance.typename)\n            except Exception:\n                gs_resource = None\n    if gs_resource:\n        if values:\n            gs_resource.title = values.get('title', '')\n            gs_resource.abstract = values.get('abstract', '')\n        else:\n            values = {}\n\n        _subtype = gs_resource.store.resource_type\n        if getattr(gs_resource, 'metadata', None) and gs_resource.metadata.get('time', False) and gs_resource.metadata.get('time').enabled:\n            _subtype = \"vectorTimeSeries\"\n\n        values.update(dict(store=gs_resource.store.name,\n                           subtype=_subtype,\n                           alternate=f\"{gs_resource.store.workspace.name}:{gs_resource.name}\",\n                           title=gs_resource.title or gs_resource.store.name,\n                           abstract=gs_resource.abstract or '',\n                           owner=instance.owner))\n    else:\n        msg = f\"There isn't a geoserver resource for this layer: {instance.name}\"\n        logger.debug(msg)\n        if tries >= _max_tries:\n            # raise GeoNodeException(msg)\n            return (values, None)\n        gs_resource = None\n    return (values, gs_resource)\n\n\ndef wps_execute_dataset_attribute_statistics(dataset_name, field):\n    \"\"\"Derive aggregate statistics from WPS endpoint\"\"\"\n\n    # generate statistics using WPS\n    url = urljoin(ogc_server_settings.LOCATION, 'ows')\n\n    request = render_to_string('layers/wps_execute_gs_aggregate.xml', {\n                               'dataset_name': dataset_name,\n                               'field': field\n                               })\n    u = urlsplit(url)\n\n    headers = {\n        'User-Agent': 'OWSLib (https://geopython.github.io/OWSLib)',\n        'Content-type': 'text/xml',\n        'Accept': 'text/xml',\n        'Accept-Language': 'en-US',\n        'Accept-Encoding': 'gzip,deflate',\n        'Host': u.netloc,\n    }\n\n    response, content = http_client.request(\n        url,\n        method='POST',\n        data=request,\n        headers=headers,\n        user=_user,\n        timeout=5,\n        retries=1)\n\n    exml = dlxml.fromstring(content.encode())\n\n    result = {}\n\n    for f in ['Min', 'Max', 'Average', 'Median', 'StandardDeviation', 'Sum']:\n        fr = exml.find(f)\n        if fr is not None:\n            result[f] = fr.text\n        else:\n            result[f] = 'NA'\n\n    count = exml.find('Count')\n    if count is not None:\n        result['Count'] = int(count.text)\n    else:\n        result['Count'] = 0\n\n    result['unique_values'] = 'NA'\n\n    return result\n\n\ndef _stylefilterparams_geowebcache_dataset(dataset_name):\n    headers = {\n        \"Content-Type\": \"text/xml\"\n    }\n    url = f'{ogc_server_settings.LOCATION}gwc/rest/layers/{dataset_name}.xml'\n\n    # read GWC configuration\n    req, content = http_client.get(\n        url,\n        headers=headers,\n        user=_user)\n    if req.status_code != 200:\n        logger.error(\n            f\"Error {req.status_code} reading Style Filter Params GeoWebCache at {url}\"\n        )\n        return\n\n    # check/write GWC filter parameters\n    body = None\n    tree = dlxml.fromstring(_)\n    param_filters = tree.findall('parameterFilters')\n    if param_filters and len(param_filters) > 0:\n        if not param_filters[0].findall('styleParameterFilter'):\n            style_filters_xml = \"<styleParameterFilter><key>STYLES</key>\\\n                <defaultValue></defaultValue></styleParameterFilter>\"\n            style_filters_elem = dlxml.fromstring(style_filters_xml)\n            param_filters[0].append(style_filters_elem)\n            body = ET.tostring(tree)\n    if body:\n        req, content = http_client.post(\n            url,\n            data=body,\n            headers=headers,\n            user=_user)\n        if req.status_code != 200:\n            logger.error(\n                f\"Error {req.status_code} writing Style Filter Params GeoWebCache at {url}\"\n            )\n\n\ndef _invalidate_geowebcache_dataset(dataset_name, url=None):\n    # http.add_credentials(username, password)\n    headers = {\n        \"Content-Type\": \"text/xml\",\n    }\n    body = f\"\"\"\n        <truncateLayer><layerName>{dataset_name}</layerName></truncateLayer>\n        \"\"\".strip()\n    if not url:\n        url = f'{ogc_server_settings.LOCATION}gwc/rest/masstruncate'\n    req, content = http_client.post(\n        url,\n        data=body,\n        headers=headers,\n        user=_user)\n\n    if req.status_code != 200:\n        logger.debug(\n            f\"Error {req.status_code} invalidating GeoWebCache at {url}\"\n        )\n\n\ndef style_update(request, url, workspace=None):\n    \"\"\"\n    Sync style stuff from GS to GN.\n    Ideally we should call this from a view straight from GXP, and we should use\n    gsConfig, that at this time does not support styles updates. Before gsConfig\n    is updated, for now we need to parse xml.\n    In case of a DELETE, we need to query request.path to get the style name,\n    and then remove it.\n    In case of a POST or PUT, we need to parse the xml from\n    request.body, which is in this format:\n    \"\"\"\n    affected_datasets = []\n    if request.method in ('POST', 'PUT', 'DELETE'):  # we need to parse xml\n        # Need to remove NSx from IE11\n        if \"HTTP_USER_AGENT\" in request.META:\n            if ('Trident/7.0' in request.META['HTTP_USER_AGENT'] and\n                    'rv:11.0' in request.META['HTTP_USER_AGENT']):\n                txml = re.sub(r'xmlns:NS[0-9]=\"\"', '', request.body)\n                txml = re.sub(r'NS[0-9]:', '', txml)\n                request._body = txml\n        style_name = os.path.basename(request.path)\n        sld_title = style_name\n        sld_body = None\n        sld_url = url\n        dataset_name = None\n        if 'name' in request.GET:\n            style_name = request.GET['name']\n            sld_body = request.body\n        elif request.method == 'DELETE':\n            style_name = os.path.basename(request.path)\n        else:\n            sld_body = request.body\n            gs_style = gs_catalog.get_style(name=style_name) or gs_catalog.get_style(name=style_name, workspace=workspace)\n            if gs_style:\n                sld_title = gs_style.sld_title if gs_style.style_format != 'css' and gs_style.sld_title else style_name\n                sld_body = gs_style.sld_body\n                sld_url = gs_style.body_href\n            else:\n                try:\n                    tree = ET.ElementTree(dlxml.fromstring(request.body))\n                    elm_nameddataset_name = tree.findall(\n                        './/{http://www.opengis.net/sld}Name')[0]\n                    elm_user_style_name = tree.findall(\n                        './/{http://www.opengis.net/sld}Name')[1]\n                    elm_user_style_title = tree.find(\n                        './/{http://www.opengis.net/sld}Title')\n                    dataset_name = elm_nameddataset_name.text\n                    if elm_user_style_title is None:\n                        sld_title = elm_user_style_name.text\n                    else:\n                        sld_title = elm_user_style_title.text\n                    sld_body = f'<?xml version=\"1.0\" encoding=\"UTF-8\"?>{request.body}'\n                except Exception:\n                    logger.warn(\"Could not recognize Style and Dataset name from Request!\")\n\n        # add style in GN and associate it to layer\n        if request.method == 'DELETE':\n            if style_name:\n                Style.objects.filter(name=style_name).delete()\n        if request.method == 'POST':\n            style = None\n            if style_name and not re.match(temp_style_name_regex, style_name):\n                style, created = Style.objects.get_or_create(name=style_name)\n                style.workspace = workspace\n                style.sld_body = sld_body\n                style.sld_url = sld_url\n                style.sld_title = sld_title\n                style.save()\n            layer = None\n            if dataset_name:\n                try:\n                    layer = Dataset.objects.get(name=dataset_name)\n                except Exception:\n                    try:\n                        layer = Dataset.objects.get(alternate=dataset_name)\n                    except Exception:\n                        pass\n            if layer:\n                if style:\n                    style.dataset_styles.add(layer)\n                    style.save()\n                affected_datasets.append(layer)\n        elif request.method == 'PUT':  # update style in GN\n            if style_name and not re.match(temp_style_name_regex, style_name):\n                style, created = Style.objects.get_or_create(name=style_name)\n                style.workspace = workspace\n                style.sld_body = sld_body\n                style.sld_url = sld_url\n                style.sld_title = sld_title\n                style.save()\n                for layer in style.dataset_styles.all():\n                    affected_datasets.append(layer)\n\n        # Invalidate GeoWebCache so it doesn't retain old style in tiles\n        try:\n            if dataset_name:\n                _stylefilterparams_geowebcache_dataset(dataset_name)\n                _invalidate_geowebcache_dataset(dataset_name)\n        except Exception:\n            pass\n    return affected_datasets\n\n\ndef set_time_info(layer, attribute, end_attribute, presentation,\n                  precision_value, precision_step, enabled=True):\n    '''Configure the time dimension for a layer.\n\n    :param layer: the layer to configure\n    :param attribute: the attribute used to represent the instant or period\n                      start\n    :param end_attribute: the optional attribute used to represent the end\n                          period\n    :param presentation: either 'LIST', 'DISCRETE_INTERVAL', or\n                         'CONTINUOUS_INTERVAL'\n    :param precision_value: number representing number of steps\n    :param precision_step: one of 'seconds', 'minutes', 'hours', 'days',\n                           'months', 'years'\n    :param enabled: defaults to True\n    '''\n    layer = gs_catalog.get_layer(layer.name)\n    if layer is None:\n        raise ValueError(f'no such layer: {layer.name}')\n    resource = layer.resource if layer else None\n    if not resource:\n        resources = gs_catalog.get_resources(stores=[layer.name])\n        if resources:\n            resource = resources[0]\n\n    resolution = None\n    if precision_value and precision_step:\n        resolution = f'{precision_value} {precision_step}'\n    info = DimensionInfo(\"time\", enabled, presentation, resolution, \"ISO8601\",\n                         None, attribute=attribute, end_attribute=end_attribute)\n    if resource and resource.metadata:\n        metadata = dict(resource.metadata or {})\n    else:\n        metadata = dict({})\n    metadata['time'] = info\n\n    if resource and resource.metadata:\n        resource.metadata = metadata\n    if resource:\n        gs_catalog.save(resource)\n\n\ndef get_time_info(layer):\n    '''Get the configured time dimension metadata for the layer as a dict.\n\n    The keys of the dict will be those of the parameters of `set_time_info`.\n\n    :returns: dict of values or None if not configured\n    '''\n    layer = gs_catalog.get_layer(layer.name)\n    if layer is None:\n        raise ValueError(f'no such layer: {layer.name}')\n    resource = layer.resource if layer else None\n    if not resource:\n        resources = gs_catalog.get_resources(stores=[layer.name])\n        if resources:\n            resource = resources[0]\n\n    info = resource.metadata.get('time', None) if resource.metadata else None\n    vals = None\n    if info:\n        value = step = None\n        resolution = info.resolution_str()\n        if resolution:\n            value, step = resolution.split()\n        vals = dict(\n            enabled=info.enabled,\n            attribute=info.attribute,\n            end_attribute=info.end_attribute,\n            presentation=info.presentation,\n            precision_value=value,\n            precision_step=step,\n        )\n    return vals\n\n\nogc_server_settings = OGC_Servers_Handler(settings.OGC_SERVER)['default']\n\n_wms = None\n_csw = None\n_user, _password = ogc_server_settings.credentials\n\nurl = ogc_server_settings.rest\ngs_catalog = Catalog(url, _user, _password,\n                     retries=ogc_server_settings.MAX_RETRIES,\n                     backoff_factor=ogc_server_settings.BACKOFF_FACTOR)\ngs_uploader = Client(url, _user, _password)\n\n_punc = re.compile(r\"[\\.:]\")  # regex for punctuation that confuses restconfig\n_foregrounds = [\n    \"#ffbbbb\",\n    \"#bbffbb\",\n    \"#bbbbff\",\n    \"#ffffbb\",\n    \"#bbffff\",\n    \"#ffbbff\"]\n_backgrounds = [\n    \"#880000\",\n    \"#008800\",\n    \"#000088\",\n    \"#888800\",\n    \"#008888\",\n    \"#880088\"]\n_marks = [\"square\", \"circle\", \"cross\", \"x\", \"triangle\"]\n_style_contexts = zip(cycle(_foregrounds), cycle(_backgrounds), cycle(_marks))\n_default_style_names = [\"point\", \"line\", \"polygon\", \"raster\"]\n_esri_types = {\n    \"esriFieldTypeDouble\": \"xsd:double\",\n    \"esriFieldTypeString\": \"xsd:string\",\n    \"esriFieldTypeSmallInteger\": \"xsd:int\",\n    \"esriFieldTypeInteger\": \"xsd:int\",\n    \"esriFieldTypeDate\": \"xsd:dateTime\",\n    \"esriFieldTypeOID\": \"xsd:long\",\n    \"esriFieldTypeGeometry\": \"xsd:geometry\",\n    \"esriFieldTypeBlob\": \"xsd:base64Binary\",\n    \"esriFieldTypeRaster\": \"raster\",\n    \"esriFieldTypeGUID\": \"xsd:string\",\n    \"esriFieldTypeGlobalID\": \"xsd:string\",\n    \"esriFieldTypeXML\": \"xsd:anyType\"}\n\n\ndef _dump_image_spec(request_body, image_spec):\n    millis = int(round(time.time() * 1000))\n    try:\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            _request_body_file_name = os.path.join(\n                tmp_dir,\n                f\"request_body_{millis}.dump\")\n            _image_spec_file_name = os.path.join(\n                tmp_dir,\n                f\"image_spec_{millis}.dump\")\n            with open(_request_body_file_name, \"w\") as _request_body_file:\n                _request_body_file.write(f\"{request_body}\")\n            copyfile(\n                _request_body_file_name,\n                os.path.join(tempfile.gettempdir(), f\"request_body_{millis}.dump\"))\n            with open(_image_spec_file_name, \"w\") as _image_spec_file:\n                _image_spec_file.write(f\"{image_spec}\")\n            copyfile(\n                _image_spec_file_name,\n                os.path.join(tempfile.gettempdir(), f\"image_spec_{millis}.dump\"))\n        return f\"Dumping image_spec to: {os.path.join(tempfile.gettempdir(), f'image_spec_{millis}.dump')}\"\n    except Exception as e:\n        logger.exception(e)\n        return f\"Unable to dump image_spec for request: {request_body}\"\n\n\ndef mosaic_delete_first_granule(cat, layer):\n    # - since GeoNode will uploade the first granule again through the Importer, we need to /\n    #   delete the one created by the gs_config\n    cat._cache.clear()\n    store = cat.get_store(layer)\n    coverages = cat.mosaic_coverages(store)\n\n    granule_id = f\"{layer}.1\"\n\n    cat.mosaic_delete_granule(coverages['coverages']['coverage'][0]['name'], store, granule_id)\n\n\ndef set_time_dimension(cat, name, workspace, time_presentation, time_presentation_res, time_presentation_default_value,\n                       time_presentation_reference_value):\n    # configure the layer time dimension as LIST\n    presentation = time_presentation\n    if not presentation:\n        presentation = \"LIST\"\n\n    resolution = None\n    if time_presentation == 'DISCRETE_INTERVAL':\n        resolution = time_presentation_res\n\n    strategy = None\n    if time_presentation_default_value and not time_presentation_default_value == \"\":\n        strategy = time_presentation_default_value\n\n    timeInfo = DimensionInfo(\"time\", \"true\", presentation, resolution, \"ISO8601\", None, attribute=\"time\",\n                             strategy=strategy, reference_value=time_presentation_reference_value)\n\n    layer = cat.get_layer(name)\n    resource = layer.resource if layer else None\n    if not resource:\n        resources = cat.get_resources(stores=[name]) or cat.get_resources(stores=[name], workspaces=[workspace])\n        if resources:\n            resource = resources[0]\n\n    if not resource:\n        logger.exception(f\"No resource could be found on GeoServer with name {name}\")\n        raise Exception(f\"No resource could be found on GeoServer with name {name}\")\n\n    resource.metadata = {'time': timeInfo}\n    cat.save(resource)\n\n\n# main entry point to create a thumbnail - will use implementation\n# defined in settings.THUMBNAIL_GENERATOR (see settings.py)\ndef create_gs_thumbnail(instance, overwrite=False, check_bbox=False):\n    implementation = import_string(settings.THUMBNAIL_GENERATOR)\n    return implementation(instance, overwrite, check_bbox)\n\n\ndef sync_instance_with_geoserver(\n        instance_id,\n        *args, **kwargs):\n    \"\"\"\n    Synchronizes the Django Instance with GeoServer layers.\n    \"\"\"\n    updatebbox = kwargs.get('updatebbox', True)\n    updatemetadata = kwargs.get('updatemetadata', True)\n\n    instance = None\n    try:\n        instance = Dataset.objects.get(id=instance_id)\n    except Dataset.DoesNotExist:\n        logger.error(f\"Dataset id {instance_id} does not exist yet!\")\n        raise\n\n    if isinstance(instance, ResourceBase):\n        if hasattr(instance, 'dataset'):\n            instance = instance.dataset\n        else:\n            return instance\n\n    try:\n        instance.set_processing_state(\"RUNNING\")\n        if updatemetadata:\n            # Save layer attributes\n            logger.debug(f\"... Refresh GeoServer attributes list for Dataset {instance.title}\")\n            try:\n                set_attributes_from_geoserver(instance)\n            except Exception as e:\n                logger.warning(e)\n\n        # Don't run this signal handler if it is a tile layer or a remote store (Service)\n        #    Currently only gpkg files containing tiles will have this type & will be served via MapProxy.\n        _is_remote_instance = hasattr(instance, 'subtype') and getattr(instance, 'subtype') in ['tileStore', 'remote']\n\n        # Let's reset the connections first\n        gs_catalog._cache.clear()\n        gs_catalog.reset()\n\n        gs_resource = None\n        if not _is_remote_instance:\n            values = None\n            _tries = 0\n            _max_tries = getattr(ogc_server_settings, \"MAX_RETRIES\", 3)\n\n            # If the store in None then it's a new instance from an upload,\n            # only in this case run the geoserver_upload method\n            if getattr(instance, 'overwrite', False):\n                base_file, info = instance.get_base_file()\n\n                # There is no need to process it if there is no file.\n                if base_file:\n                    from geonode.geoserver.upload import geoserver_upload\n                    gs_name, workspace, values, gs_resource = geoserver_upload(\n                        instance,\n                        base_file.file.path,\n                        instance.owner,\n                        instance.name,\n                        overwrite=True,\n                        title=instance.title,\n                        abstract=instance.abstract,\n                        charset=instance.charset\n                    )\n\n            values, gs_resource = fetch_gs_resource(instance, values, _tries)\n            while not gs_resource and _tries < _max_tries:\n                values, gs_resource = fetch_gs_resource(instance, values, _tries)\n                _tries += 1\n                time.sleep(3)\n\n            # Get metadata links\n            metadata_links = []\n            for link in instance.link_set.metadata():\n                metadata_links.append((link.mime, link.name, link.url))\n\n            if gs_resource:\n                logger.debug(f\"Found geoserver resource for this dataset: {instance.name}\")\n                instance.gs_resource = gs_resource\n\n                # Iterate over values from geoserver.\n                for key in ['alternate', 'store', 'subtype']:\n                    # attr_name = key if 'typename' not in key else 'alternate'\n                    # print attr_name\n                    setattr(instance, key, get_dataset_storetype(values[key]))\n\n                if updatemetadata:\n                    gs_resource.metadata_links = metadata_links\n\n                    # Update Attribution link\n                    if instance.poc:\n                        # gsconfig now utilizes an attribution dictionary\n                        gs_resource.attribution = {\n                            'title': str(instance.poc),\n                            'width': None,\n                            'height': None,\n                            'href': None,\n                            'url': None,\n                            'type': None}\n                        profile = get_user_model().objects.get(username=instance.poc.username)\n                        site_url = settings.SITEURL.rstrip('/') if settings.SITEURL.startswith('http') else settings.SITEURL\n                        gs_resource.attribution_link = site_url + profile.get_absolute_url()\n\n                    try:\n                        if settings.RESOURCE_PUBLISHING:\n                            if instance.is_published != gs_resource.advertised:\n                                gs_resource.advertised = 'true'\n\n                        if any(instance.keyword_list()):\n                            keywords = gs_resource.keywords + instance.keyword_list()\n                            gs_resource.keywords = list(set(keywords))\n\n                        # gs_resource should only be called if\n                        # ogc_server_settings.BACKEND_WRITE_ENABLED == True\n                        if getattr(ogc_server_settings, \"BACKEND_WRITE_ENABLED\", True):\n                            gs_catalog.save(gs_resource)\n                    except Exception as e:\n                        msg = (f'Error while trying to save resource named {gs_resource} in GeoServer, try to use: \"{e}\"')\n                        e.args = (msg,)\n                        logger.warning(e)\n\n                if updatebbox:\n                    # store the resource to avoid another geoserver call in the post_save\n                    \"\"\"Get information from geoserver.\n                    The attributes retrieved include:\n                    * Bounding Box\n                    * SRID\n                    \"\"\"\n                    # This is usually done in Dataset.pre_save, however if the hooks\n                    # are bypassed by custom create/updates we need to ensure the\n                    # bbox is calculated properly.\n                    srid = gs_resource.projection\n                    bbox = gs_resource.native_bbox\n                    ll_bbox = gs_resource.latlon_bbox\n                    try:\n                        instance.set_bbox_polygon([bbox[0], bbox[2], bbox[1], bbox[3]], srid)\n                    except GeoNodeException as e:\n                        if not ll_bbox:\n                            raise\n                        else:\n                            logger.exception(e)\n                            instance.srid = 'EPSG:4326'\n                            Dataset.objects.filter(id=instance.id).update(srid=instance.srid)\n                    instance.set_ll_bbox_polygon([ll_bbox[0], ll_bbox[2], ll_bbox[1], ll_bbox[3]])\n\n                    if instance.srid:\n                        instance.srid_url = f\"http://www.spatialreference.org/ref/{instance.srid.replace(':', '/').lower()}/\"\n                    else:\n                        raise GeoNodeException(_(\"Invalid Projection. Dataset is missing CRS!\"))\n\n                # Update the instance\n                to_update = {}\n                if updatemetadata:\n                    to_update = {\n                        'title': instance.title or instance.name,\n                        'abstract': instance.abstract or \"\",\n                        'alternate': instance.alternate\n                    }\n\n                if updatebbox and is_monochromatic_image(instance.thumbnail_url):\n                    to_update['thumbnail_url'] = None\n\n                # Save all the modified information in the instance without triggering signals.\n                with transaction.atomic():\n                    ResourceBase.objects.filter(\n                        id=instance.resourcebase_ptr.id).update(\n                        **to_update)\n\n                    # to_update['name'] = instance.name,\n                    to_update['workspace'] = gs_resource.store.workspace.name\n                    to_update['store'] = gs_resource.store.name\n                    to_update['subtype'] = instance.subtype\n                    to_update['typename'] = instance.alternate\n                    to_update['srid'] = instance.srid\n                    Dataset.objects.filter(id=instance.id).update(**to_update)\n\n                    # Refresh from DB\n                    instance.refresh_from_db()\n\n                if updatemetadata:\n                    # Save dataset styles\n                    logger.debug(f\"... Refresh Legend links for Dataset {instance.title}\")\n                    try:\n                        set_styles(instance, gs_catalog)\n                    except Exception as e:\n                        logger.warning(e)\n\n                    # Invalidate GeoWebCache for the updated resource\n                    try:\n                        _stylefilterparams_geowebcache_dataset(instance.alternate)\n                        _invalidate_geowebcache_dataset(instance.alternate)\n                    except Exception as e:\n                        logger.warning(e)\n\n        # Refreshing dataset links\n        logger.debug(f\"... Creating Default Resource Links for Dataset {instance.title}\")\n        set_resource_default_links(instance, instance, prune=_is_remote_instance)\n\n        # Refreshing CSW records\n        logger.debug(f\"... Updating the Catalogue entries for Dataset {instance.title}\")\n        catalogue_post_save(instance=instance, sender=instance.__class__)\n        instance.set_processing_state(\"PROCESSED\")\n    except Exception as e:\n        logger.exception(e)\n        instance.set_processing_state(\"FAILED\")\n        raise GeoNodeException(e)\n    return instance\n\n\ndef get_dataset_storetype(element):\n    return LAYER_SUBTYPES.get(element, element)\n\n\ndef write_uploaded_files_to_disk(target_dir, files):\n    result = []\n    for django_file in files:\n        path = os.path.join(target_dir, django_file.name)\n        with open(path, 'wb') as fh:\n            for chunk in django_file.chunks():\n                fh.write(chunk)\n        result = path\n    return result\n\n\ndef select_relevant_files(allowed_extensions, files):\n    \"\"\"Filter the input files list for relevant files only\n\n    Relevant files are those whose extension is in the ``allowed_extensions``\n    iterable.\n\n    :param allowed_extensions: list of strings with the extensions to keep\n    :param files: list of django files with the files to be filtered\n    \"\"\"\n    from geonode.upload.files import get_scan_hint\n\n    result = []\n    if files:\n        for django_file in files:\n            _django_file_name = django_file if isinstance(django_file, str) else django_file.name\n            extension = os.path.splitext(_django_file_name)[-1].lower()[1:]\n            if extension in allowed_extensions or get_scan_hint(allowed_extensions):\n                already_selected = _django_file_name in (f if isinstance(f, str) else f.name for f in result)\n                if not already_selected:\n                    result.append(django_file)\n    return result\n\n\n@dataclasses.dataclass()\nclass SpatialFilesLayerType:\n    base_file: str\n    scan_hint: str\n    spatial_files: typing.List\n    dataset_type: typing.Optional[str] = None\n\n\ndef get_spatial_files_dataset_type(allowed_extensions, files, charset='UTF-8') -> SpatialFilesLayerType:\n    \"\"\"Reutnrs 'vector' or 'raster' whether a file from the allowed extensins has been identified.\n    \"\"\"\n    from geonode.upload.files import get_scan_hint, scan_file\n\n    allowed_file = select_relevant_files(allowed_extensions, files)\n    if not allowed_file or len(allowed_file) != 1:\n        return None\n    base_file = allowed_file[0]\n    scan_hint = get_scan_hint(allowed_extensions)\n    spatial_files = scan_file(\n        base_file,\n        scan_hint=scan_hint,\n        charset=charset\n    )\n    the_dataset_type = get_dataset_type(spatial_files)\n    if the_dataset_type not in (FeatureType.resource_type, Coverage.resource_type):\n        return None\n    spatial_files_type = SpatialFilesLayerType(\n        base_file=base_file,\n        scan_hint=scan_hint,\n        spatial_files=spatial_files,\n        dataset_type='vector' if the_dataset_type == FeatureType.resource_type else 'raster')\n\n    return spatial_files_type\n\n\ndef get_dataset_type(spatial_files):\n    \"\"\"Returns 'FeatureType.resource_type' or 'Coverage.resource_type' accordingly to the provided SpatialFiles\n    \"\"\"\n    if spatial_files.archive is not None:\n        the_dataset_type = FeatureType.resource_type\n    else:\n        the_dataset_type = spatial_files[0].file_type.dataset_type\n    return the_dataset_type\n\n\ndef wps_format_is_supported(_format, dataset_type):\n    return (_format, dataset_type) in WPS_ACCEPTABLE_FORMATS\n", "#########################################################################\n#\n# Copyright (C) 2019 OSGeo\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n#\n#########################################################################\nimport re\nimport logging\n\nfrom urllib.parse import urljoin\n\nfrom django.conf import settings\nfrom django.urls import reverse\n\nfrom geonode import geoserver\nfrom geonode.decorators import on_ogc_backend\nfrom geonode.tests.base import GeoNodeBaseTestSupport\nfrom geonode.geoserver.views import _response_callback\nfrom geonode.geoserver.helpers import (\n    gs_catalog,\n    get_dataset_storetype,\n    extract_name_from_sld)\nfrom geonode.layers.populate_datasets_data import create_dataset_data\n\nfrom geonode.geoserver.ows import (\n    _wcs_link,\n    _wfs_link,\n    _wms_link)\n\nfrom geonode.base.populate_test_data import (\n    all_public,\n    create_models,\n    remove_models)\n\nlogger = logging.getLogger(__name__)\n\n\nclass HelperTest(GeoNodeBaseTestSupport):\n\n    type = 'dataset'\n\n    fixtures = [\n        'initial_data.json',\n        'group_test_data.json',\n        'default_oauth_apps.json'\n    ]\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        create_models(type=cls.get_type, integration=cls.get_integration)\n        all_public()\n\n    @classmethod\n    def tearDownClass(cls):\n        super().tearDownClass()\n        remove_models(cls.get_obj_ids, type=cls.get_type, integration=cls.get_integration)\n\n    def setUp(self):\n        super().setUp()\n        self.user = 'admin'\n        self.passwd = 'admin'\n        create_dataset_data()\n\n    @on_ogc_backend(geoserver.BACKEND_PACKAGE)\n    def test_extract_name_from_sld(self):\n        content = \"\"\"<?xml version=\"1.0\" standalone=\"yes\"?>\n<!DOCTYPE foo [ <!ENTITY ent SYSTEM \"/etc/passwd\" > ]>\n<foo xmlns=\"http://www.opengis.net/sld\">\n<NamedLayer>\n    <UserStyle>\n        <Name>&ent;</Name>\n    </UserStyle>\n</NamedLayer>\n</foo>\"\"\"\n        self.assertIsNone(extract_name_from_sld(gs_catalog, content))\n\n    @on_ogc_backend(geoserver.BACKEND_PACKAGE)\n    def test_replace_callback(self):\n        content = f\"\"\"<Layer>\n      <Title>GeoNode Local GeoServer</Title>\n      <Abstract>This is a description of your Web Map Server.</Abstract>\n      <!--Limited list of EPSG projections:-->\n      <CRS>EPSG:4326</CRS>\n      <CRS>EPSG:3785</CRS>\n      <CRS>EPSG:3857</CRS>\n      <CRS>EPSG:900913</CRS>\n      <CRS>EPSG:32647</CRS>\n      <CRS>EPSG:32736</CRS>\n      <CRS>CRS:84</CRS>\n      <EX_GeographicBoundingBox>\n        <westBoundLongitude>-124.731422</westBoundLongitude>\n        <eastBoundLongitude>12.512771464573753</eastBoundLongitude>\n        <southBoundLatitude>12.4801497</southBoundLatitude>\n        <northBoundLatitude>49.371735</northBoundLatitude>\n      </EX_GeographicBoundingBox>\n      <BoundingBox CRS=\"CRS:84\" ..../>\n      <BoundingBox CRS=\"EPSG:4326\" ..../>\n      <BoundingBox CRS=\"EPSG:3785\" ..../>\n      <BoundingBox CRS=\"EPSG:3857\" ..../>\n      <BoundingBox CRS=\"EPSG:900913\" ..../>\n      <BoundingBox CRS=\"EPSG:32647\" ..../>\n      <BoundingBox CRS=\"EPSG:32736\" ..../>\n      <Layer queryable=\"1\" opaque=\"0\">\n        <Name>geonode:DE_USNG_UTM18</Name>\n        <Title>DE_USNG_UTM18</Title>\n        <Abstract>No abstract provided</Abstract>\n        <KeywordList>\n          <Keyword>DE_USNG_UTM18</Keyword>\n          <Keyword>features</Keyword>\n        </KeywordList>\n        <CRS>EPSG:26918</CRS>\n        <CRS>CRS:84</CRS>\n        <EX_GeographicBoundingBox>\n          <westBoundLongitude>-75.93570725669369</westBoundLongitude>\n          <eastBoundLongitude>-75.00000000000001</eastBoundLongitude>\n          <southBoundLatitude>38.3856300861002</southBoundLatitude>\n          <northBoundLatitude>39.89406880610797</northBoundLatitude>\n        </EX_GeographicBoundingBox>\n        <BoundingBox CRS=\"CRS:84\" .01\" maxy=\"39.89406880610797\"/>\n        <BoundingBox CRS=\"EPSG:26918\" ..../>\n        <BoundingBox CRS=\"EPSG:4326\" ..../>\n        <BoundingBox CRS=\"EPSG:3785\" ..../>\n        <BoundingBox CRS=\"EPSG:3857\" ..../>\n        <BoundingBox CRS=\"EPSG:900913\" ..../>\n        <BoundingBox CRS=\"EPSG:32647\" ..../>\n        <BoundingBox CRS=\"EPSG:32736\" ..../>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"FGDC\">\n          <Format>text/xml</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}catalogue/csw?outputschema=....\"/>\n        </MetadataURL>\n        <MetadataURL type=\"other\">\n          <Format>other</Format>\n          <OnlineResource xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}showmetadata/xsl/584\"/>\n        </MetadataURL>\n        <Style>\n          <Name>geonode:DE_USNG_UTM18</Name>\n          <Title>Default Polygon</Title>\n          <Abstract>A sample style that draws a polygon</Abstract>\n          <LegendURL width=\"20\" height=\"20\">\n            <Format>image/png</Format>\n            <OnlineResource\nxmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:type=\"simple\"\nxlink:href=\"{settings.GEOSERVER_LOCATION}ows?service=WMS&amp;request=GetLegendGraphic&....\"/>\n          </LegendURL>\n        </Style>\n      </Layer>\"\"\"\n        kwargs = {\n            'content': content,\n            'status': 200,\n            'content_type': 'application/xml'\n        }\n        _content = _response_callback(**kwargs).content\n        self.assertTrue(re.findall(f'{urljoin(settings.SITEURL, \"/gs/\")}ows', str(_content)))\n\n        kwargs = {\n            'content': content,\n            'status': 200,\n            'content_type': 'text/xml; charset=UTF-8'\n        }\n        _content = _response_callback(**kwargs).content\n        self.assertTrue(re.findall(f'{urljoin(settings.SITEURL, \"/gs/\")}ows', str(_content)))\n\n    def test_return_element_if_not_exists_in_the_subtypes(self):\n        el = get_dataset_storetype('not-existing-type')\n        self.assertEqual('not-existing-type', el)\n\n    def test_datastore_should_return_vector(self):\n        el = get_dataset_storetype('dataStore')\n        self.assertEqual('vector', el)\n\n    def test_coverageStore_should_return_raster(self):\n        el = get_dataset_storetype('coverageStore')\n        self.assertEqual('raster', el)\n\n    def test_remoteStore_should_return_remote(self):\n        el = get_dataset_storetype('remoteStore')\n        self.assertEqual('remote', el)\n\n    @on_ogc_backend(geoserver.BACKEND_PACKAGE)\n    def test_geoserver_proxy_strip_paths(self):\n        response = self.client.get(f\"{reverse('gs_layers')}?service=WFS&version=1.1.0&request=DescribeFeatureType&typeName=geonode:tipi_forestali&outputFormat=application/json&access_token=something\")\n        self.assertEqual(response.status_code, 200)\n\n        response = self.client.get(f\"{reverse('ows_endpoint')}?service=WFS&version=1.1.0&request=DescribeFeatureType&typeName=geonode:tipi_forestali&outputFormat=image/png&access_token=something\")\n        self.assertEqual(response.status_code, 200)\n\n    @on_ogc_backend(geoserver.BACKEND_PACKAGE)\n    def test_ows_links(self):\n        ows_url = 'http://foo.org/ows'\n        identifier = 'foo:fake_alternate'\n        min_x, min_y, max_x, max_y = -1, -1, 1, 1\n        expected_url = f'{ows_url}?service=WCS&request=GetCoverage&coverageid=foo__fake_alternate&format=image%2Ftiff&version=2.0.1&compression=DEFLATE&tileWidth=512&tileHeight=512&outputCrs=4326'\n        download_url = _wcs_link(\n            ows_url,\n            identifier,\n            \"image/tiff\",\n            srid='4326',\n            bbox=[min_x, min_y, max_x, max_y],\n            compression=\"DEFLATE\",\n            tile_size=512)\n        self.assertEqual(download_url, expected_url, download_url)\n\n        expected_url = f'{ows_url}?service=WFS&version=1.0.0&request=GetFeature&typename=foo%3Afake_alternate&outputFormat=application%2Fzip&srs=4326&bbox=%5B-1%2C+-1%2C+1%2C+1%5D'\n        download_url = _wfs_link(\n            ows_url,\n            identifier,\n            \"application/zip\",\n            {},\n            srid='4326',\n            bbox=[min_x, min_y, max_x, max_y])\n        self.assertEqual(download_url, expected_url, download_url)\n\n        expected_url = f'{ows_url}?service=WMS&request=GetMap&layers=foo%3Afake_alternate&format=image%2Fpng&height=512&width=512&srs=4326&bbox=%5B-1%2C+-1%2C+1%2C+1%5D'\n        download_url = _wms_link(\n            ows_url,\n            identifier,\n            \"image/png\",\n            512, 512,\n            srid='4326',\n            bbox=[min_x, min_y, max_x, max_y])\n        self.assertEqual(download_url, expected_url, download_url)\n", "#########################################################################\n#\n# Copyright (C) 2016 OSGeo\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n#\n#########################################################################\n\nimport os\nimport re\nimport json\nimport logging\nimport traceback\nfrom lxml import etree\nfrom owslib.etree import etree as dlxml\nfrom os.path import isfile\n\nfrom urllib.parse import (\n    urlsplit,\n    urljoin,\n    unquote,\n    parse_qsl)\n\nfrom django.contrib.auth import authenticate\nfrom django.http import HttpResponse, HttpResponseRedirect\nfrom django.views.decorators.http import require_POST\nfrom django.shortcuts import render\nfrom django.conf import settings\nfrom django.contrib.auth.decorators import user_passes_test\nfrom django.contrib.auth import get_user_model\nfrom django.contrib.auth.decorators import login_required\nfrom django.template.loader import get_template\nfrom django.utils.datastructures import MultiValueDictKeyError\nfrom django.utils.translation import ugettext as _\n\nfrom guardian.shortcuts import get_objects_for_user\n\nfrom geonode.base.models import ResourceBase\nfrom geonode.client.hooks import hookset\nfrom geonode.compat import ensure_string\nfrom geonode.base.auth import get_auth_user, get_or_create_token\nfrom geonode.decorators import logged_in_or_basicauth\nfrom geonode.layers.forms import LayerStyleUploadForm\nfrom geonode.layers.models import Dataset, Style\nfrom geonode.layers.views import _resolve_dataset, _PERMISSION_MSG_MODIFY\nfrom geonode.maps.models import Map\nfrom geonode.proxy.views import (\n    proxy,\n    fetch_response_headers)\nfrom .tasks import geoserver_update_datasets\nfrom geonode.utils import (\n    json_response,\n    _get_basic_auth_info,\n    http_client,\n    get_headers,\n    get_dataset_workspace)\nfrom geoserver.catalog import FailedRequestError\nfrom geonode.geoserver.signals import (\n    gs_catalog,\n    geoserver_post_save_local)\nfrom .helpers import (\n    get_stores,\n    ogc_server_settings,\n    extract_name_from_sld,\n    set_styles,\n    style_update,\n    set_dataset_style,\n    temp_style_name_regex,\n    _stylefilterparams_geowebcache_dataset,\n    _invalidate_geowebcache_dataset)\n\nfrom django.views.decorators.csrf import csrf_exempt\n\nlogger = logging.getLogger(__name__)\n\n\ndef stores(request, store_type=None):\n    stores = get_stores(store_type)\n    data = json.dumps(stores)\n    return HttpResponse(data)\n\n\n@user_passes_test(lambda u: u.is_superuser)\ndef updatelayers(request):\n    params = request.GET\n    # Get the owner specified in the request if any, otherwise used the logged\n    # user\n    owner = params.get('owner', None)\n    owner = get_user_model().objects.get(\n        username=owner) if owner is not None else request.user\n    workspace = params.get('workspace', None)\n    store = params.get('store', None)\n    filter = params.get('filter', None)\n    result = geoserver_update_datasets.delay(\n        ignore_errors=False, owner=owner, workspace=workspace,\n        store=store, filter=filter)\n    # Attempt to run task synchronously\n    result.get()\n\n    return HttpResponseRedirect(hookset.dataset_list_url())\n\n\n@login_required\n@require_POST\ndef dataset_style(request, layername):\n    layer = _resolve_dataset(\n        request,\n        layername,\n        'base.change_resourcebase',\n        _PERMISSION_MSG_MODIFY)\n\n    style_name = request.POST.get('defaultStyle')\n\n    # would be nice to implement\n    # better handling of default style switching\n    # in layer model or deeper (gsconfig.py, REST API)\n\n    old_default = layer.default_style\n    if old_default.name == style_name:\n        return HttpResponse(\n            f\"Default style for {layer.name} remains {style_name}\", status=200)\n\n    # This code assumes without checking\n    # that the new default style name is included\n    # in the list of possible styles.\n\n    new_style = next(style for style in layer.styles if style.name == style_name)\n\n    # Does this change this in geoserver??\n    layer.default_style = new_style\n    layer.styles = [\n        s for s in layer.styles if s.name != style_name] + [old_default]\n    layer.save(notify=True)\n\n    # Invalidate GeoWebCache for the updated resource\n    try:\n        _stylefilterparams_geowebcache_dataset(layer.alternate)\n        _invalidate_geowebcache_dataset(layer.alternate)\n    except Exception:\n        pass\n\n    return HttpResponse(\n        f\"Default style for {layer.name} changed to {style_name}\", status=200)\n\n\n@login_required\ndef dataset_style_upload(request, layername):\n    def respond(*args, **kw):\n        kw['content_type'] = 'text/html'\n        return json_response(*args, **kw)\n    form = LayerStyleUploadForm(request.POST, request.FILES)\n    if not form.is_valid():\n        return respond(errors=\"Please provide an SLD file.\")\n\n    data = form.cleaned_data\n    layer = _resolve_dataset(\n        request,\n        layername,\n        'base.change_resourcebase',\n        _PERMISSION_MSG_MODIFY)\n\n    sld = request.FILES['sld'].read()\n    sld_name = None\n    try:\n        # Check SLD is valid\n        try:\n            if sld:\n                if isfile(sld):\n                    with open(sld) as sld_file:\n                        sld = sld_file.read()\n                etree.XML(sld, parser=etree.XMLParser(resolve_entities=False))\n        except Exception:\n            logger.exception(\"The uploaded SLD file is not valid XML\")\n            raise Exception(\n                \"The uploaded SLD file is not valid XML\")\n\n        sld_name = extract_name_from_sld(\n            gs_catalog, sld, sld_file=request.FILES['sld'])\n    except Exception as e:\n        respond(errors=f\"The uploaded SLD file is not valid XML: {e}\")\n\n    name = data.get('name') or sld_name\n\n    set_dataset_style(layer, data.get('title') or name, sld)\n\n    return respond(\n        body={\n            'success': True,\n            'style': data.get('title') or name,\n            'updated': data['update']})\n\n\n@login_required\ndef dataset_style_manage(request, layername):\n    layer = _resolve_dataset(\n        request,\n        layername,\n        'layers.change_dataset_style',\n        _PERMISSION_MSG_MODIFY)\n\n    if request.method == 'GET':\n        try:\n            cat = gs_catalog\n\n            # First update the layer style info from GS to GeoNode's DB\n            try:\n                set_styles(layer, cat)\n            except AttributeError:\n                logger.warn(\n                    'Unable to set the default style.  Ensure Geoserver is running and that this layer exists.')\n\n            gs_styles = []\n            # Temporary Hack to remove GeoServer temp styles from the list\n            Style.objects.filter(name__iregex=r'\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}_(ms)_\\d{13}').delete()\n            for style in Style.objects.values('name', 'sld_title'):\n                gs_styles.append((style['name'], style['sld_title']))\n            current_dataset_styles = layer.styles.all()\n            dataset_styles = []\n            for style in current_dataset_styles:\n                sld_title = style.name\n                try:\n                    if style.sld_title:\n                        sld_title = style.sld_title\n                except Exception:\n                    tb = traceback.format_exc()\n                    logger.debug(tb)\n                dataset_styles.append((style.name, sld_title))\n\n            # Render the form\n            def_sld_name = None  # noqa\n            def_sld_title = None  # noqa\n            default_style = None\n            if layer.default_style:\n                def_sld_name = layer.default_style.name  # noqa\n                def_sld_title = layer.default_style.name  # noqa\n                try:\n                    if layer.default_style.sld_title:\n                        def_sld_title = layer.default_style.sld_title\n                except Exception:\n                    tb = traceback.format_exc()\n                    logger.debug(tb)\n                default_style = (def_sld_name, def_sld_title)\n\n            return render(\n                request,\n                'datasets/dataset_style_manage.html',\n                context={\n                    \"layer\": layer,\n                    \"gs_styles\": gs_styles,\n                    \"dataset_styles\": dataset_styles,\n                    \"dataset_style_names\": [s[0] for s in dataset_styles],\n                    \"default_style\": default_style\n                }\n            )\n        except (FailedRequestError, OSError):\n            tb = traceback.format_exc()\n            logger.debug(tb)\n            msg = (f'Could not connect to geoserver at \"{ogc_server_settings.LOCATION}\"'\n                   f'to manage style information for layer \"{layer.name}\"')\n            logger.debug(msg)\n            # If geoserver is not online, return an error\n            return render(\n                request,\n                'datasets/dataset_style_manage.html',\n                context={\n                    \"layer\": layer,\n                    \"error\": msg\n                }\n            )\n    elif request.method in ('POST', 'PUT', 'DELETE'):\n        try:\n            workspace = get_dataset_workspace(layer) or settings.DEFAULT_WORKSPACE\n            selected_styles = request.POST.getlist('style-select')\n            default_style = request.POST['default_style']\n\n            # Save to GeoServer\n            cat = gs_catalog\n            try:\n                gs_dataset = cat.get_layer(layer.name)\n            except Exception:\n                gs_dataset = None\n\n            if not gs_dataset:\n                gs_dataset = cat.get_layer(layer.alternate)\n\n            if gs_dataset:\n                _default_style = cat.get_style(default_style) or \\\n                    cat.get_style(default_style, workspace=workspace)\n                if _default_style:\n                    gs_dataset.default_style = _default_style\n                elif cat.get_style(default_style, workspace=settings.DEFAULT_WORKSPACE):\n                    gs_dataset.default_style = cat.get_style(default_style, workspace=settings.DEFAULT_WORKSPACE)\n                styles = []\n                for style in selected_styles:\n                    _gs_sld = cat.get_style(style) or cat.get_style(style, workspace=workspace)\n                    if _gs_sld:\n                        styles.append(_gs_sld)\n                    elif cat.get_style(style, workspace=settings.DEFAULT_WORKSPACE):\n                        styles.append(cat.get_style(style, workspace=settings.DEFAULT_WORKSPACE))\n                    else:\n                        Style.objects.filter(name=style).delete()\n                gs_dataset.styles = styles\n                cat.save(gs_dataset)\n\n            # Save to Django\n            set_styles(layer, cat)\n\n            # Invalidate GeoWebCache for the updated resource\n            try:\n                _stylefilterparams_geowebcache_dataset(layer.alternate)\n                _invalidate_geowebcache_dataset(layer.alternate)\n            except Exception:\n                pass\n\n            return HttpResponseRedirect(layer.get_absolute_url())\n        except (FailedRequestError, OSError, MultiValueDictKeyError):\n            tb = traceback.format_exc()\n            logger.debug(tb)\n            msg = (f'Error Saving Styles for Dataset \"{layer.name}\"')\n            logger.warn(msg)\n            return render(\n                request,\n                'datasets/dataset_style_manage.html',\n                context={\n                    \"layer\": layer,\n                    \"error\": msg\n                }\n            )\n\n\ndef style_change_check(request, path, style_name=None, access_token=None):\n    \"\"\"\n    If the layer has not change_dataset_style permission, return a status of\n    401 (unauthorized)\n    \"\"\"\n    # a new style is created with a POST and then a PUT,\n    # a style is updated with a PUT\n    # a layer is updated with a style with a PUT\n    # in both case we need to check permissions here\n    # for PUT path is /gs/rest/styles/san_andres_y_providencia_water_a452004b.xml\n    # or /ge/rest/layers/geonode:san_andres_y_providencia_coastline.json\n    # for POST path is /gs/rest/styles\n    # we will suppose that a user can create a new style only if he is an\n    # authenticated (we need to discuss about it)\n    authorized = True\n    if request.method in ('PUT', 'POST'):\n        if not request.user.is_authenticated and not access_token:\n            authorized = False\n        elif re.match(r'^.*(?<!/rest/)/rest/.*/?styles.*', path):\n            # style new/update\n            # we will iterate all layers (should be just one if not using GS)\n            # to which the posted style is associated\n            # and check if the user has change_style_dataset permissions on each\n            # of them\n            if style_name == 'styles' and 'raw' in request.GET:\n                authorized = True\n            elif re.match(temp_style_name_regex, style_name):\n                authorized = True\n            else:\n                try:\n                    user = request.user\n                    if user.is_anonymous and access_token:\n                        user = get_auth_user(access_token)\n                    if not user or user.is_anonymous:\n                        authorized = False\n                    else:\n                        style = Style.objects.get(name=style_name)\n                        for dataset in style.dataset_styles.all():\n                            if not user.has_perm('change_dataset_style', obj=dataset):\n                                authorized = False\n                                break\n                            else:\n                                authorized = True\n                                break\n                except Style.DoesNotExist:\n                    if request.method != 'POST':\n                        logger.warn(f'There is not a style with such a name: {style_name}.')\n                except Exception as e:\n                    logger.exception(e)\n                    authorized = (request.method == 'POST')  # The user is probably trying to create a new style\n    return authorized\n\n\ndef check_geoserver_access(request,\n                           proxy_path,\n                           downstream_path,\n                           workspace=None,\n                           layername=None,\n                           allowed_hosts=[]):\n    def strip_prefix(path, prefix):\n        if prefix not in path:\n            _s_prefix = prefix.split('/', 3)\n            _s_path = path.split('/', 3)\n            assert _s_prefix[1] == _s_path[1]\n            _prefix = f'/{_s_path[1]}/{_s_path[2]}'\n        else:\n            _prefix = prefix\n        assert _prefix in path\n        prefix_idx = path.index(_prefix)\n        _prefix = path[:prefix_idx] + _prefix\n        full_prefix = f\"{_prefix}/{layername}/{downstream_path}\" if layername else _prefix\n        return path[len(full_prefix):]\n\n    path = strip_prefix(request.get_full_path(), proxy_path)\n\n    raw_url = str(\n        \"\".join([ogc_server_settings.LOCATION, downstream_path, path]))\n\n    if settings.DEFAULT_WORKSPACE or workspace:\n        ws = (workspace or settings.DEFAULT_WORKSPACE)\n        if ws and ws in path:\n            # Strip out WS from PATH\n            try:\n                path = f'/{strip_prefix(path, f\"/{ws}:\")}'\n            except Exception:\n                ws = None\n\n        if proxy_path == f'/gs/{settings.DEFAULT_WORKSPACE}' and layername:\n            import posixpath\n            raw_url = urljoin(ogc_server_settings.LOCATION,\n                              posixpath.join(workspace, layername, downstream_path, path))\n\n        if downstream_path in ('rest/styles') and len(request.body) > 0:\n            if ws:\n                # Lets try\n                # http://localhost:8080/geoserver/rest/workspaces/<ws>/styles/<style>.xml\n                _url = str(\"\".join([ogc_server_settings.LOCATION,\n                                    'rest/workspaces/', ws, '/styles',\n                                    path]))\n            else:\n                _url = str(\"\".join([ogc_server_settings.LOCATION,\n                                    'rest/styles',\n                                    path]))\n            raw_url = _url\n\n    if downstream_path in 'ows' and (\n        re.match(r'/(rest).*$', path, re.IGNORECASE) or\n            re.match(r'/(w.*s).*$', path, re.IGNORECASE) or\n            re.match(r'/(ows).*$', path, re.IGNORECASE)):\n        _url = str(\"\".join([ogc_server_settings.LOCATION, '', path[1:]]))\n        raw_url = _url\n    url = urlsplit(raw_url)\n\n    if f'{ws}/layers' in path:\n        downstream_path = 'rest/layers'\n    elif f'{ws}/styles' in path:\n        downstream_path = 'rest/styles'\n\n    # Collecting headers and cookies\n    headers, access_token = get_headers(request, url, unquote(raw_url), allowed_hosts=allowed_hosts)\n    return (raw_url, headers, access_token, downstream_path)\n\n\n@csrf_exempt\ndef geoserver_proxy(request,\n                    proxy_path,\n                    downstream_path,\n                    workspace=None,\n                    layername=None):\n    \"\"\"\n    WARNING: Decorators are applied in the order they appear in the source.\n    \"\"\"\n    affected_datasets = None\n    allowed_hosts = [urlsplit(ogc_server_settings.public_url).hostname, ]\n\n    raw_url, headers, access_token, downstream_path = check_geoserver_access(\n        request,\n        proxy_path,\n        downstream_path,\n        workspace=workspace,\n        layername=layername,\n        allowed_hosts=allowed_hosts)\n    url = urlsplit(raw_url)\n\n    if re.match(r'^.*/rest/', url.path) and request.method in (\"POST\", \"PUT\", \"DELETE\"):\n        if re.match(r'^.*(?<!/rest/)/rest/.*/?styles.*', url.path):\n            logger.debug(\n                f\"[geoserver_proxy] Updating Style ---> url {url.geturl()}\")\n            _style_name, _style_ext = os.path.splitext(os.path.basename(urlsplit(url.geturl()).path))\n            _parsed_get_args = dict(parse_qsl(urlsplit(url.geturl()).query))\n            if _style_name == 'styles.json' and request.method == \"PUT\":\n                if _parsed_get_args.get('name'):\n                    _style_name, _style_ext = os.path.splitext(_parsed_get_args.get('name'))\n            else:\n                _style_name, _style_ext = os.path.splitext(_style_name)\n\n            if not style_change_check(request, url.path, style_name=_style_name, access_token=access_token):\n                return HttpResponse(\n                    _(\"You don't have permissions to change style for this layer\"),\n                    content_type=\"text/plain\",\n                    status=401)\n            if _style_name != 'style-check' and (_style_ext == '.json' or _parsed_get_args.get('raw')) and \\\n                    not re.match(temp_style_name_regex, _style_name):\n                affected_datasets = style_update(request, raw_url, workspace)\n        elif re.match(r'^.*(?<!/rest/)/rest/.*/?layers.*', url.path):\n            logger.debug(f\"[geoserver_proxy] Updating Dataset ---> url {url.geturl()}\")\n            try:\n                _dataset_name = os.path.splitext(os.path.basename(request.path))[0]\n                _dataset = Dataset.objects.get(name=_dataset_name)\n                affected_datasets = [_dataset]\n            except Exception:\n                logger.warn(f\"Could not find any Dataset {os.path.basename(request.path)} on DB\")\n\n    kwargs = {'affected_datasets': affected_datasets}\n    raw_url = unquote(raw_url)\n    timeout = getattr(ogc_server_settings, 'TIMEOUT') or 60\n    response = proxy(request, url=raw_url, response_callback=_response_callback,\n                     timeout=timeout, allowed_hosts=allowed_hosts,\n                     headers=headers, access_token=access_token, **kwargs)\n    return response\n\n\ndef _response_callback(**kwargs):\n    status = kwargs.get('status')\n    content = kwargs.get('content')\n    content_type = kwargs.get('content_type')\n    response_headers = kwargs.get('response_headers', None)\n    content_type_list = ['application/xml', 'text/xml', 'text/plain', 'application/json', 'text/json']\n\n    if content:\n        if not content_type:\n            if isinstance(content, bytes):\n                content = content.decode('UTF-8')\n            if (re.match(r'^<.+>$', content)):\n                content_type = 'application/xml'\n            elif (re.match(r'^({|[).+(}|])$', content)):\n                content_type = 'application/json'\n            else:\n                content_type = 'text/plain'\n\n        # Replace Proxy URL\n        try:\n            if isinstance(content, bytes):\n                try:\n                    _content = content.decode('UTF-8')\n                except UnicodeDecodeError:\n                    _content = content\n            else:\n                _content = content\n            if re.findall(f\"(?=(\\\\b{'|'.join(content_type_list)}\\\\b))\", content_type):\n                _gn_proxy_url = urljoin(settings.SITEURL, '/gs/')\n                content = _content\\\n                    .replace(ogc_server_settings.LOCATION, _gn_proxy_url)\\\n                    .replace(ogc_server_settings.PUBLIC_LOCATION, _gn_proxy_url)\n                for _ows_endpoint in list(dict.fromkeys(re.findall(rf'{_gn_proxy_url}w\\ws', content, re.IGNORECASE))):\n                    content = content.replace(_ows_endpoint, f'{_gn_proxy_url}ows')\n        except Exception as e:\n            logger.exception(e)\n\n    if 'affected_datasets' in kwargs and kwargs['affected_datasets']:\n        for layer in kwargs['affected_datasets']:\n            geoserver_post_save_local(layer)\n\n    _response = HttpResponse(\n        content=content,\n        status=status,\n        content_type=content_type)\n    return fetch_response_headers(_response, response_headers)\n\n\ndef resolve_user(request):\n    user = None\n    geoserver = False\n    superuser = False\n    acl_user = request.user\n    if 'HTTP_AUTHORIZATION' in request.META:\n        username, password = _get_basic_auth_info(request)\n        acl_user = authenticate(username=username, password=password)\n        if acl_user:\n            user = acl_user.username\n            superuser = acl_user.is_superuser\n        elif _get_basic_auth_info(request) == ogc_server_settings.credentials:\n            geoserver = True\n            superuser = True\n        else:\n            return HttpResponse(_(\"Bad HTTP Authorization Credentials.\"),\n                                status=401,\n                                content_type=\"text/plain\")\n\n    if not any([user, geoserver, superuser]\n               ) and not request.user.is_anonymous:\n        user = request.user.username\n        superuser = request.user.is_superuser\n\n    resp = {\n        'user': user,\n        'geoserver': geoserver,\n        'superuser': superuser,\n    }\n\n    if acl_user and acl_user.is_authenticated:\n        resp['fullname'] = acl_user.get_full_name()\n        resp['email'] = acl_user.email\n    return HttpResponse(json.dumps(resp), content_type=\"application/json\")\n\n\n@logged_in_or_basicauth(realm=\"GeoNode\")\ndef dataset_acls(request):\n    \"\"\"\n    returns json-encoded lists of layer identifiers that\n    represent the sets of read-write and read-only layers\n    for the currently authenticated user.\n    \"\"\"\n    # the dataset_acls view supports basic auth, and a special\n    # user which represents the geoserver administrator that\n    # is not present in django.\n    acl_user = request.user\n    if 'HTTP_AUTHORIZATION' in request.META:\n        try:\n            username, password = _get_basic_auth_info(request)\n            acl_user = authenticate(username=username, password=password)\n\n            # Nope, is it the special geoserver user?\n            if (acl_user is None and\n                    username == ogc_server_settings.USER and\n                    password == ogc_server_settings.PASSWORD):\n                # great, tell geoserver it's an admin.\n                result = {\n                    'rw': [],\n                    'ro': [],\n                    'name': username,\n                    'is_superuser': True,\n                    'is_anonymous': False\n                }\n                return HttpResponse(\n                    json.dumps(result),\n                    content_type=\"application/json\")\n        except Exception:\n            pass\n\n        if acl_user is None:\n            return HttpResponse(_(\"Bad HTTP Authorization Credentials.\"),\n                                status=401,\n                                content_type=\"text/plain\")\n\n    # Include permissions on the anonymous user\n    # use of polymorphic selectors/functions to optimize performances\n    resources_readable = get_objects_for_user(\n        acl_user, 'view_resourcebase',\n        ResourceBase.objects.filter(polymorphic_ctype__model='dataset')).values_list('id', flat=True)\n    dataset_writable = get_objects_for_user(\n        acl_user, 'change_dataset_data',\n        Dataset.objects.all())\n\n    _read = set(\n        Dataset.objects.filter(\n            id__in=resources_readable).values_list(\n            'alternate',\n            flat=True))\n    _write = set(dataset_writable.values_list('alternate', flat=True))\n\n    read_only = _read ^ _write\n    read_write = _read & _write\n\n    result = {\n        'rw': list(read_write),\n        'ro': list(read_only),\n        'name': acl_user.username,\n        'is_superuser': acl_user.is_superuser,\n        'is_anonymous': acl_user.is_anonymous,\n    }\n    if acl_user.is_authenticated:\n        result['fullname'] = acl_user.get_full_name()\n        result['email'] = acl_user.email\n\n    return HttpResponse(json.dumps(result), content_type=\"application/json\")\n\n\n# capabilities\ndef get_dataset_capabilities(layer, version='1.3.0', access_token=None, tolerant=False):\n    \"\"\"\n    Retrieve a layer-specific GetCapabilities document\n    \"\"\"\n    workspace, layername = layer.alternate.split(\":\") if \":\" in layer.alternate else (None, layer.alternate)\n    if not layer.remote_service:\n        wms_url = f'{ogc_server_settings.LOCATION}{workspace}/{layername}/wms?service=wms&version={version}&request=GetCapabilities'  # noqa\n        if access_token:\n            wms_url += f'&access_token={access_token}'\n    else:\n        wms_url = f'{layer.remote_service.service_url}?service=wms&version={version}&request=GetCapabilities'\n\n    _user, _password = ogc_server_settings.credentials\n    req, content = http_client.get(wms_url, user=_user)\n    getcap = ensure_string(content)\n    if not getattr(settings, 'DELAYED_SECURITY_SIGNALS', False):\n        if tolerant and ('ServiceException' in getcap or req.status_code == 404):\n            # WARNING Please make sure to have enabled DJANGO CACHE as per\n            # https://docs.djangoproject.com/en/2.0/topics/cache/#filesystem-caching\n            wms_url = f'{ogc_server_settings.public_url}{workspace}/ows?service=wms&version={version}&request=GetCapabilities&layers={layer}'  # noqa\n            if access_token:\n                wms_url += f'&access_token={access_token}'\n            req, content = http_client.get(wms_url, user=_user)\n            getcap = ensure_string(content)\n\n    if 'ServiceException' in getcap or req.status_code == 404:\n        return None\n    return getcap.encode('UTF-8')\n\n\ndef format_online_resource(workspace, layer, element, namespaces):\n    \"\"\"\n    Replace workspace/layer-specific OnlineResource links with the more\n    generic links returned by a site-wide GetCapabilities document\n    \"\"\"\n    layerName = element.find('.//wms:Capability/wms:Layer/wms:Layer/wms:Name',\n                             namespaces)\n    if layerName is None:\n        return\n\n    layerName.text = f\"{workspace}:{layer}\" if workspace else layer\n    layerresources = element.findall('.//wms:OnlineResource', namespaces)\n    if layerresources is None:\n        return\n\n    for resource in layerresources:\n        wtf = resource.attrib['{http://www.w3.org/1999/xlink}href']\n        replace_string = f\"/{workspace}/{layer}\" if workspace else f\"/{layer}\"\n        resource.attrib['{http://www.w3.org/1999/xlink}href'] = wtf.replace(\n            replace_string, \"\")\n\n\ndef get_capabilities(request, layerid=None, user=None,\n                     mapid=None, category=None, tolerant=False):\n    \"\"\"\n    Compile a GetCapabilities document containing public layers\n    filtered by layer, user, map, or category\n    \"\"\"\n\n    rootdoc = None\n    layers = None\n    cap_name = ' Capabilities - '\n    if layerid is not None:\n        dataset_obj = Dataset.objects.get(id=layerid)\n        cap_name += dataset_obj.title\n        layers = Dataset.objects.filter(id=layerid)\n    elif user is not None:\n        layers = Dataset.objects.filter(owner__username=user)\n        cap_name += user\n    elif category is not None:\n        layers = Dataset.objects.filter(category__identifier=category)\n        cap_name += category\n    elif mapid is not None:\n        map_obj = Map.objects.get(id=mapid)\n        cap_name += map_obj.title\n        alternates = []\n        for layer in map_obj.maplayers.iterator():\n            if layer.local:\n                alternates.append(layer.name)\n        layers = Dataset.objects.filter(alternate__in=alternates)\n\n    for layer in layers:\n        if request.user.has_perm('view_resourcebase',\n                                 layer.get_self_resource()):\n            access_token = get_or_create_token(request.user)\n            if access_token and not access_token.is_expired():\n                access_token = access_token.token\n            else:\n                access_token = None\n            try:\n                workspace, layername = layer.alternate.split(\":\") if \":\" in layer.alternate else (None, layer.alternate)\n                layercap = get_dataset_capabilities(layer, access_token=access_token, tolerant=tolerant)\n                if layercap is not None:  # 1st one, seed with real GetCapabilities doc\n                    try:\n                        namespaces = {'wms': 'http://www.opengis.net/wms',\n                                      'xlink': 'http://www.w3.org/1999/xlink',\n                                      'xsi': 'http://www.w3.org/2001/XMLSchema-instance'}\n                        layercap = dlxml.fromstring(layercap)\n                        rootdoc = etree.ElementTree(layercap)\n                        format_online_resource(workspace, layername, rootdoc, namespaces)\n                        service_name = rootdoc.find('.//wms:Service/wms:Name', namespaces)\n                        if service_name is not None:\n                            service_name.text = cap_name\n                        rootdoc = rootdoc.find('.//wms:Capability/wms:Layer/wms:Layer', namespaces)\n                    except Exception as e:\n                        import traceback\n                        traceback.print_exc()\n                        logger.error(\n                            f\"Error occurred creating GetCapabilities for {layer.typename}: {str(e)}\")\n                        rootdoc = None\n                if layercap is None or not len(layercap) or rootdoc is None or not len(rootdoc):\n                    # Get the required info from layer model\n                    # TODO: store time dimension on DB also\n                    tpl = get_template(\"geoserver/layer.xml\")\n                    ctx = {\n                        'layer': layer,\n                        'geoserver_public_url': ogc_server_settings.public_url,\n                        'catalogue_url': settings.CATALOGUE['default']['URL'],\n                    }\n                    gc_str = tpl.render(ctx)\n                    gc_str = gc_str.encode(\"utf-8\", \"replace\")\n                    layerelem = etree.XML(gc_str, parser=etree.XMLParser(resolve_entities=False))\n                    rootdoc = etree.ElementTree(layerelem)\n            except Exception as e:\n                import traceback\n                traceback.print_exc()\n                logger.error(\n                    f\"Error occurred creating GetCapabilities for {layer.typename}:{str(e)}\")\n                rootdoc = None\n    if rootdoc is not None:\n        capabilities = etree.tostring(\n            rootdoc,\n            xml_declaration=True,\n            encoding='UTF-8',\n            pretty_print=True)\n        return HttpResponse(capabilities, content_type=\"text/xml\")\n    return HttpResponse(status=200)\n\n\ndef server_online(request):\n    \"\"\"\n    Returns {success} whenever the LOCAL_GEOSERVER is up and running\n    \"\"\"\n    from .helpers import check_geoserver_is_up\n    try:\n        check_geoserver_is_up()\n        return HttpResponse(json.dumps({'online': True}), content_type=\"application/json\")\n    except Exception:\n        return HttpResponse(json.dumps({'online': False}), content_type=\"application/json\")\n"], "filenames": ["geonode/geoserver/helpers.py", "geonode/geoserver/tests/test_helpers.py", "geonode/geoserver/views.py"], "buggy_code_start_loc": [241, 31, 182], "buggy_code_end_loc": [382, 72, 803], "fixing_code_start_loc": [241, 31, 182], "fixing_code_end_loc": [382, 89, 803], "type": "CWE-611", "message": "GeoNode is an open source platform that facilitates the creation, sharing, and collaborative use of geospatial data. GeoNode is vulnerable to an XML External Entity (XXE) injection in the style upload functionality of GeoServer leading to Arbitrary File Read. This issue has been patched in version 4.0.3.", "other": {"cve": {"id": "CVE-2023-26043", "sourceIdentifier": "security-advisories@github.com", "published": "2023-02-27T21:15:12.103", "lastModified": "2023-06-01T14:03:36.337", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "GeoNode is an open source platform that facilitates the creation, sharing, and collaborative use of geospatial data. GeoNode is vulnerable to an XML External Entity (XXE) injection in the style upload functionality of GeoServer leading to Arbitrary File Read. This issue has been patched in version 4.0.3."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-611"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-611"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:geosolutionsgroup:geonode:*:*:*:*:*:*:*:*", "versionEndExcluding": "4.0.3", "matchCriteriaId": "FF65F806-F0DC-43AE-BA82-D15F8BB2F5B8"}]}]}], "references": [{"url": "https://github.com/GeoNode/geonode/commit/2fdfe919f299b21f1609bf898f9dcfde58770ac0", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/GeoNode/geonode/security/advisories/GHSA-mcmc-c59m-pqq8", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/GeoNode/geonode/commit/2fdfe919f299b21f1609bf898f9dcfde58770ac0"}}
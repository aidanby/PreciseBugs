{"buggy_code": ["# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Functional tests for pooling operations.\"\"\"\n\nimport numpy as np\n\nfrom tensorflow.compiler.tests import xla_test\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gen_nn_ops\nfrom tensorflow.python.ops import nn_ops\nfrom tensorflow.python.platform import googletest\n\n\ndef NHWCToNCHW(input_tensor):\n  \"\"\"Convert the input from NHWC format to NCHW.\n\n  Args:\n    input_tensor:  a 4-D tensor, or a 4-element array representing the same.\n\n  Returns:\n    the converted tensor or a shape array\n  \"\"\"\n  if isinstance(input_tensor, ops.Tensor):\n    return array_ops.transpose(input_tensor, [0, 3, 1, 2])\n  else:\n    return [input_tensor[0], input_tensor[3], input_tensor[1], input_tensor[2]]\n\n\ndef NCHWToNHWC(input_tensor):\n  \"\"\"Convert the input from NCHW format to NHWC.\n\n  Args:\n    input_tensor:  a 4-D tensor, or a 4-element array representing the same.\n\n  Returns:\n    the converted tensor or a shape array\n  \"\"\"\n  if isinstance(input_tensor, ops.Tensor):\n    return array_ops.transpose(input_tensor, [0, 2, 3, 1])\n  else:\n    return [input_tensor[0], input_tensor[2], input_tensor[3], input_tensor[1]]\n\n\ndef GetTestConfigs():\n  \"\"\"Get all the valid tests configs to run.\n\n  Returns:\n    all the valid test configs\n  \"\"\"\n  test_configs = [\"NHWC\", \"NCHW\"]\n  return test_configs\n\n\nclass PoolingTest(xla_test.XLATestCase):\n\n  def _VerifyOneTest(self, pool_func, input_sizes, ksize, strides, padding,\n                     data_format, expected):\n    \"\"\"Verifies the output values of the pooling function.\n\n    Args:\n      pool_func: Function to be called, currently only co.MaxPool.\n      input_sizes: Input tensor dimensions.\n      ksize: The kernel size dimensions\n      strides: The stride dimensions\n      padding: Padding type.\n      data_format: The data format we use to run the pooling operation.\n      expected: An array containing the expected operation outputs.\n    \"\"\"\n    total_size = np.prod(input_sizes)\n    # Initializes the input tensor with array containing incrementing\n    # numbers from 1.\n    x = np.array([f * 1.0 for f in range(1, total_size + 1)], dtype=np.float32)\n    x = x.reshape(input_sizes)\n    with self.session() as sess:\n      with self.test_scope():\n        inputs = array_ops.placeholder(dtypes.float32)\n        t = inputs\n        if data_format == \"NCHW\":\n          t = NHWCToNCHW(t)\n          ksize = NHWCToNCHW(ksize)\n          strides = NHWCToNCHW(strides)\n        t = pool_func(t,\n                      ksize=ksize,\n                      strides=strides,\n                      padding=padding,\n                      data_format=data_format)\n        if data_format == \"NCHW\":\n          t = NCHWToNHWC(t)\n      actual = sess.run(t, {inputs: x})\n      self.assertAllClose(expected, actual.flatten(), rtol=1e-5, atol=1e-6)\n\n  def _VerifyValues(self, pool_func, input_sizes, ksize, strides, padding,\n                    expected):\n    \"\"\"Verifies the output values of the pooling function.\n\n    Args:\n      pool_func: Function to be called, co.MaxPool, co.AvgPool,\n        or the Lua version.\n      input_sizes: Input tensor dimensions.\n      ksize: The kernel size dimensions\n      strides: The stride dimensions\n      padding: Padding type.\n      expected: An array containing the expected operation outputs.\n    \"\"\"\n    for data_format in GetTestConfigs():\n      self._VerifyOneTest(pool_func, input_sizes, ksize, strides, padding,\n                          data_format, expected)\n\n  def testMaxPoolValidPadding(self):\n    expected_output = [13.0, 14.0, 15.0]\n    self._VerifyValues(nn_ops.max_pool,\n                       input_sizes=[1, 3, 3, 3],\n                       ksize=[1, 2, 2, 1],\n                       strides=[1, 2, 2, 1],\n                       padding=\"VALID\",\n                       expected=expected_output)\n\n  def testMaxPoolSamePadding(self):\n    expected_output = [13.0, 14.0, 15.0, 16.0, 17.0, 18.0]\n    self._VerifyValues(nn_ops.max_pool,\n                       input_sizes=[1, 2, 3, 3],\n                       ksize=[1, 2, 2, 1],\n                       strides=[1, 2, 2, 1],\n                       padding=\"SAME\",\n                       expected=expected_output)\n\n  def testMaxPoolSamePaddingNonSquareWindow(self):\n    # input is:\n    # [1.0, 2.0\n    #  3.0  4.0]\n    #\n    # Window of [x, x] should do:\n    #\n    #  [max(1.0, 2.0), max(2.0, padded0),\n    #   max(3.0, 4.0), max(4.0, padded0)]\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 2, 2, 1],\n        ksize=[1, 1, 2, 1],\n        strides=[1, 1, 1, 1],\n        padding=\"SAME\",\n        expected=[2.0, 2.0, 4.0, 4.0])\n\n  def testMaxPoolValidPaddingUnevenStride(self):\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 1, 2, 1],\n        padding=\"VALID\",\n        expected=[6.0, 8.0, 10.0, 12.0, 14.0, 16.0])\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 1, 1],\n        padding=\"VALID\",\n        expected=[6.0, 7.0, 8.0, 14.0, 15.0, 16.0])\n\n  def testMaxPoolSamePaddingFilter4(self):\n    expected_output = [\n        21.0, 22.0, 23.0, 24.0, 29.0, 30.0, 31.0, 32.0, 53.0, 54.0, 55.0, 56.0,\n        61.0, 62.0, 63.0, 64.0\n    ]\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 4, 4, 4],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        expected=expected_output)\n\n  def testMaxPoolSamePaddingFilter8(self):\n    expected_output = [\n        145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 161.0, 162.0,\n        163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 177.0, 178.0, 179.0, 180.0,\n        181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0,\n        191.0, 192.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0,\n        289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 305.0, 306.0,\n        307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0,\n        317.0, 318.0, 319.0, 320.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0,\n        407.0, 408.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0,\n        433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0,\n        443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 465.0, 466.0, 467.0, 468.0,\n        469.0, 470.0, 471.0, 472.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0,\n        487.0, 488.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0,\n        505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0\n    ]\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 8, 8, 8],\n        ksize=[1, 3, 3, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        expected=expected_output)\n\n  # Tests for DepthwiseMaxPooling on CPU only.\n  def testDepthwiseMaxPool1x1DepthWindow1(self):\n    # input is:\n    # [1.0, ..., 10.0] along depth,\n    #\n    # We maxpool by depth in patches of 2.\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 1, 1, 10],\n        ksize=[1, 1, 1, 2],\n        strides=[1, 1, 1, 2],\n        padding=\"SAME\",\n        expected=[2.0, 4.0, 6.0, 8.0, 10.0])\n\n  def testDepthwiseMaxPool2x2DepthWindow3(self):\n    # input is:\n    #\n    # a 2x2x6 cube, and we depthwise max across 3 to produce a 2x2x2\n    # output.  Each node has contiguous values, so the depthwise max\n    # should be multiples of 3.0.\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 2, 2, 6],\n        ksize=[1, 1, 1, 3],\n        strides=[1, 1, 1, 3],\n        padding=\"SAME\",\n        expected=[3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n\n  def testKernelSmallerThanStrideValid(self):\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 7, 7, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 3, 3, 1],\n        padding=\"VALID\",\n        expected=[9, 12, 30, 33])\n\n  def testKernelSmallerThanStrideSame(self):\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 3, 3, 1],\n        ksize=[1, 1, 1, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        expected=[1, 3, 7, 9])\n\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 1, 1, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        expected=[1, 3, 9, 11])\n\n  # Average pooling\n  def testAvgPoolValidPadding(self):\n    expected_output = [7, 8, 9]\n    self._VerifyValues(\n        nn_ops.avg_pool,\n        input_sizes=[1, 3, 3, 3],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"VALID\",\n        expected=expected_output)\n\n  def testAvgPoolSamePadding(self):\n    expected_output = [7., 8., 9., 11.5, 12.5, 13.5]\n    self._VerifyValues(\n        nn_ops.avg_pool,\n        input_sizes=[1, 2, 3, 3],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        expected=expected_output)\n\n\nclass PoolGradTest(xla_test.XLATestCase):\n\n  CPU_DEVICE = \"/job:localhost/replica:0/task:0/cpu:0\"\n\n  def _VerifyOneTest(self,\n                     pool_func,\n                     pool_grad_func,\n                     input_sizes,\n                     ksize,\n                     strides,\n                     padding,\n                     data_format,\n                     pool_grad_grad_func=None):\n    \"\"\"Verifies the output values of the pooling gradient function.\n\n    Args:\n      pool_func: Forward pooling function\n      pool_grad_func: Pooling gradient function for pool_grad_func\n      input_sizes: Input tensor dimensions.\n      ksize: The kernel size dimensions\n      strides: The stride dimensions\n      padding: Padding type.\n      data_format: The data format we use to run the pooling operation.\n      pool_grad_grad_func: Second-order gradient function, if available.\n    \"\"\"\n    total_size = np.prod(input_sizes)\n    # TODO(b/73062247): MaxPoolGradGrad can confuse gradients when x is equally\n    # maximal at 16 bits. Switch to np.random.randn when resolved.\n    x = np.arange(1, total_size + 1, dtype=np.float32)\n    x *= (np.random.randint(2, size=total_size) * 2 - 1)  # Flip signs randomly\n    # Verify some specifically interesting values...\n    x[np.random.choice(total_size)] = np.inf\n    x[np.random.choice(total_size)] = -np.inf\n    # TODO(b/74222344): Fix nan handling for max pool grad.\n    # x[np.random.choice(total_size)] = np.nan\n    x = x.reshape(input_sizes)\n    with self.session() as sess:\n      # Use the forward pool function to compute some corresponding outputs\n      # (needed for the CPU device, and we need the shape in both cases).\n      with ops.device(self.CPU_DEVICE):\n        inputs = array_ops.placeholder(dtypes.float32, shape=input_sizes)\n        outputs = pool_func(\n            inputs,\n            ksize=ksize,\n            strides=strides,\n            padding=padding,\n            data_format=\"NHWC\")\n\n      output_vals = np.array(sess.run(outputs, {inputs: x}))\n      output_gradient_vals = np.arange(\n          1, output_vals.size + 1, dtype=np.float32)\n      output_gradient_vals = output_gradient_vals.reshape(output_vals.shape)\n      output_grad_grad_vals = np.arange(1, x.size + 1, dtype=np.float32)\n      output_grad_grad_vals = output_grad_grad_vals.reshape(x.shape)\n\n      # Use the Tensorflow CPU pooling gradient to compute the expected input\n      # gradients.\n      with ops.device(self.CPU_DEVICE):\n        output_gradients = array_ops.placeholder(\n            dtypes.float32, shape=output_vals.shape)\n        expected_input_gradients = pool_grad_func(\n            inputs,\n            outputs,\n            output_gradients,\n            ksize=ksize,\n            strides=strides,\n            padding=padding,\n            data_format=\"NHWC\")\n        expected_input_gradient_vals = sess.run(\n            expected_input_gradients,\n            {inputs: x,\n             output_gradients: output_gradient_vals})\n\n        output_grad_gradients = array_ops.placeholder(\n            dtypes.float32, shape=expected_input_gradient_vals.shape)\n        if pool_grad_grad_func is not None:\n          expected_grad_gradients = pool_grad_grad_func(\n              inputs,\n              outputs,\n              output_grad_gradients,\n              ksize=ksize,\n              strides=strides,\n              padding=padding,\n              data_format=\"NHWC\")\n          expected_grad_gradients_vals = sess.run(expected_grad_gradients, {\n              inputs: x,\n              output_grad_gradients: output_grad_grad_vals\n          })\n\n      # Run the gradient op on the XLA device\n      with self.test_scope():\n        outputs = array_ops.placeholder(dtypes.float32, shape=output_vals.shape)\n        xla_inputs = inputs\n        xla_outputs = outputs\n        xla_output_gradients = output_gradients\n        xla_output_grad_gradients = output_grad_gradients\n        xla_ksize = ksize\n        xla_strides = strides\n        if data_format == \"NCHW\":\n          xla_inputs = NHWCToNCHW(inputs)\n          xla_outputs = NHWCToNCHW(outputs)\n          xla_output_gradients = NHWCToNCHW(output_gradients)\n          xla_output_grad_gradients = NHWCToNCHW(output_grad_gradients)\n          xla_ksize = NHWCToNCHW(ksize)\n          xla_strides = NHWCToNCHW(strides)\n        actual_input_gradients = pool_grad_func(\n            xla_inputs,\n            xla_outputs,\n            xla_output_gradients,\n            ksize=xla_ksize,\n            strides=xla_strides,\n            padding=padding,\n            data_format=data_format)\n        if data_format == \"NCHW\":\n          actual_input_gradients = NCHWToNHWC(actual_input_gradients)\n        if pool_grad_grad_func is not None:\n          actual_grad_gradients = pool_grad_grad_func(\n              xla_inputs,\n              xla_outputs,\n              xla_output_grad_gradients,\n              ksize=xla_ksize,\n              strides=xla_strides,\n              padding=padding,\n              data_format=data_format)\n          if data_format == \"NCHW\":\n            actual_grad_gradients = NCHWToNHWC(actual_grad_gradients)\n      actual_input_gradients_vals = sess.run(actual_input_gradients, {\n          inputs: x,\n          outputs: output_vals,\n          output_gradients: output_gradient_vals\n      })\n      # Compare the Tensorflow and XLA results.\n      self.assertAllClose(\n          expected_input_gradient_vals,\n          actual_input_gradients_vals,\n          rtol=1e-4,\n          atol=1e-6)\n      self.assertShapeEqual(actual_input_gradients_vals, inputs)\n\n      if pool_grad_grad_func is not None:\n        actual_grad_gradients_vals = sess.run(\n            actual_grad_gradients, {\n                inputs: x,\n                outputs: output_vals,\n                output_grad_gradients: output_grad_grad_vals\n            })\n\n        # Compare the Tensorflow and XLA results.\n        self.assertAllClose(\n            expected_grad_gradients_vals,\n            actual_grad_gradients_vals,\n            rtol=1e-4,\n            atol=1e-6)\n        self.assertShapeEqual(actual_grad_gradients_vals, outputs)\n\n  def _VerifyValues(self,\n                    pool_func,\n                    pool_grad_func,\n                    input_sizes,\n                    ksize,\n                    strides,\n                    padding,\n                    pool_grad_grad_func=None):\n    \"\"\"Verifies the output values of the pooling function.\n\n    Args:\n      pool_func: Pooling function to be called, e.g., tf.nn.max_pool2d\n      pool_grad_func: Corresponding pooling gradient function.\n      input_sizes: Input tensor dimensions.\n      ksize: The kernel size dimensions\n      strides: The stride dimensions\n      padding: Padding type.\n      pool_grad_grad_func: Second-order gradient function, if available.\n    \"\"\"\n    for data_format in GetTestConfigs():\n      self._VerifyOneTest(\n          pool_func,\n          pool_grad_func,\n          input_sizes,\n          ksize,\n          strides,\n          padding,\n          data_format,\n          pool_grad_grad_func=pool_grad_grad_func)\n\n  def _TestPooling(self, forward_op, backward_op, pool_grad_grad_func=None):\n    # VALID padding\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 3, 3, 3],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"VALID\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n    # SAME padding\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 2, 3, 3],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n    # SAME padding, non square window\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 2, 2, 1],\n        ksize=[1, 1, 2, 1],\n        strides=[1, 1, 1, 1],\n        padding=\"SAME\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n    # VALID padding, uneven stride\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 1, 2, 1],\n        padding=\"VALID\",\n        pool_grad_grad_func=pool_grad_grad_func)\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 1, 1],\n        padding=\"VALID\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n    # SAME padding, size 4 input\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 4, 4, 4],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n    # SAME padding, size 8 input\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 8, 8, 8],\n        ksize=[1, 3, 3, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n  def testMaxPool(self):\n    self._TestPooling(\n        nn_ops.max_pool,\n        gen_nn_ops.max_pool_grad,\n        pool_grad_grad_func=gen_nn_ops.max_pool_grad_grad)\n\n  def testAvgPool(self):\n    # Wrapper around AvgPoolGrad that ignores extra arguments needed by\n    # MaxPoolGrad.\n    def AvgPoolGrad(inputs, outputs, output_gradients, ksize, strides, padding,\n                    data_format):\n      del outputs  # Unused by average-pooling gradients.\n      return gen_nn_ops.avg_pool_grad(\n          inputs.get_shape().as_list(),\n          output_gradients,\n          ksize=ksize,\n          strides=strides,\n          padding=padding,\n          data_format=data_format)\n\n    self._TestPooling(nn_ops.avg_pool, AvgPoolGrad)\n\n  # The CPU implementation of AvgPoolGrad doesn't accept kernels smaller than\n  # the stride size, so we only run the following tests on MaxPoolGrad.\n\n  def testMaxPoolKernelSmallerThanStrideValid(self):\n    self._VerifyValues(\n        nn_ops.max_pool,\n        gen_nn_ops.max_pool_grad,\n        input_sizes=[1, 7, 7, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 3, 3, 1],\n        padding=\"VALID\")\n\n  def testMaxPoolKernelSmallerThanStrideSame(self):\n    self._VerifyValues(\n        nn_ops.max_pool,\n        gen_nn_ops.max_pool_grad,\n        input_sizes=[1, 3, 3, 1],\n        ksize=[1, 1, 1, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\")\n\n    self._VerifyValues(\n        nn_ops.max_pool,\n        gen_nn_ops.max_pool_grad,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 1, 1, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\")\n\n\nif __name__ == \"__main__\":\n  googletest.main()\n", "/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// XLA specific pooling ops.\n\n#include <string>\n\n#include \"tensorflow/compiler/tf2xla/mlir_xla_op_kernel.h\"\n#include \"tensorflow/compiler/tf2xla/shape_util.h\"\n#include \"tensorflow/compiler/tf2xla/type_util.h\"\n#include \"tensorflow/compiler/tf2xla/xla_helpers.h\"\n#include \"tensorflow/compiler/tf2xla/xla_op_kernel.h\"\n#include \"tensorflow/compiler/tf2xla/xla_op_registry.h\"\n#include \"tensorflow/compiler/xla/client/lib/arithmetic.h\"\n#include \"tensorflow/compiler/xla/client/lib/constants.h\"\n#include \"tensorflow/compiler/xla/client/lib/pooling.h\"\n#include \"tensorflow/compiler/xla/client/value_inference.h\"\n#include \"tensorflow/compiler/xla/client/xla_builder.h\"\n#include \"tensorflow/compiler/xla/client/xla_computation.h\"\n#include \"tensorflow/compiler/xla/literal.h\"\n#include \"tensorflow/compiler/xla/util.h\"\n#include \"tensorflow/core/framework/bounds_check.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/util/determinism.h\"\n#include \"tensorflow/core/util/tensor_format.h\"\n\nnamespace tensorflow {\nnamespace {\n\n// Superclass of pooling ops.\nclass PoolingOp : public XlaOpKernel {\n public:\n  PoolingOp(OpKernelConstruction* ctx, int num_spatial_dims,\n            const DataType reduction_type)\n      : XlaOpKernel(ctx),\n        num_spatial_dims_(num_spatial_dims),\n        reduction_type_(reduction_type) {\n    if (ctx->num_inputs() == 1) {\n      std::vector<int32> ksize_int;\n      std::vector<int32> stride_int;\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"ksize\", &ksize_int));\n      OP_REQUIRES(ctx, ksize_int.size() == num_dims(),\n                  errors::InvalidArgument(\"Sliding window ksize field must \"\n                                          \"specify \",\n                                          num_dims(), \" dimensions\"));\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"strides\", &stride_int));\n      OP_REQUIRES(ctx, stride_int.size() == num_dims(),\n                  errors::InvalidArgument(\"Sliding window stride field must \"\n                                          \"specify \",\n                                          num_dims(), \" dimensions\"));\n      for (int i = 0; i < num_dims(); ++i) {\n        ksize_.push_back(ksize_int[i]);\n        stride_.push_back(stride_int[i]);\n      }\n    }\n    Padding padding;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padding\", &padding));\n    OP_REQUIRES(ctx, padding != EXPLICIT,\n                errors::Unimplemented(\n                    \"XLA does not support pooling ops with explicit padding.\"));\n    padding_ = (padding == VALID) ? xla::Padding::kValid : xla::Padding::kSame;\n\n    OP_REQUIRES_OK(\n        ctx, DataTypeToPrimitiveType(reduction_type_, &xla_reduction_type_));\n  }\n\n  int num_dims() const { return num_spatial_dims_ + 2; }\n\n protected:\n  StatusOr<std::vector<int64_t>> GetKernelSize(XlaOpKernelContext* ctx) {\n    if (ctx->num_inputs() == 1) {\n      return ksize_;\n    }\n    const TensorShape ksize_shape = ctx->InputShape(1);\n    // Validate input sizes.\n    if (!TensorShapeUtils::IsVector(ksize_shape)) {\n      return errors::InvalidArgument(\"ksize must be a vector, not shape \",\n                                     ksize_shape.DebugString());\n    }\n    if (ksize_shape.num_elements() != num_dims()) {\n      return errors::InvalidArgument(\n          \"Sliding window ksize field must \"\n          \"specify \",\n          num_dims(), \" dimensions\");\n    }\n    std::vector<int64_t> ksize;\n    auto status = ctx->ConstantInputAsIntVector(1, &ksize);\n    if (!status.ok()) {\n      return status;\n    }\n    return ksize;\n  }\n\n  StatusOr<std::vector<int64_t>> GetStride(XlaOpKernelContext* ctx) {\n    if (ctx->num_inputs() == 1) {\n      return stride_;\n    }\n    const TensorShape stride_shape = ctx->InputShape(2);\n    // Validate input sizes.\n    if (!TensorShapeUtils::IsVector(stride_shape)) {\n      return errors::InvalidArgument(\"stride must be a vector, not shape \",\n                                     stride_shape.DebugString());\n    }\n    if (stride_shape.num_elements() != num_dims()) {\n      return errors::InvalidArgument(\n          \"Sliding window stride field must \"\n          \"specify \",\n          num_dims(), \" dimensions\");\n    }\n    std::vector<int64_t> stride;\n    auto status = ctx->ConstantInputAsIntVector(2, &stride);\n    if (!status.ok()) {\n      return status;\n    }\n    return stride;\n  }\n\n protected:\n  const int num_spatial_dims_;\n  std::vector<int64_t> ksize_;\n  std::vector<int64_t> stride_;\n  xla::Padding padding_;\n  TensorFormat data_format_ = FORMAT_NHWC;\n  DataType reduction_type_;\n  xla::PrimitiveType xla_reduction_type_;\n};\n\n// Converts the tensor data format to the one required by the XLA pooling\n// library.\nxla::TensorFormat XlaTensorFormat(tensorflow::TensorFormat data_format,\n                                  int num_spatial_dims) {\n  int num_dims = num_spatial_dims + 2;\n  int batch_dimension = GetTensorBatchDimIndex(num_dims, data_format);\n  int feature_dimension = GetTensorFeatureDimIndex(num_dims, data_format);\n  absl::InlinedVector<int64_t, 4> spatial_dimensions(num_spatial_dims);\n  for (int spatial_dim = 0; spatial_dim < num_spatial_dims; ++spatial_dim) {\n    spatial_dimensions[spatial_dim] =\n        GetTensorSpatialDimIndex(num_dims, data_format, spatial_dim);\n  }\n  return xla::TensorFormat(/*batch_dimension=*/batch_dimension,\n                           /*feature_dimension=*/feature_dimension,\n                           /*spatial_dimensions=*/spatial_dimensions);\n}\n\nclass MaxPoolOp : public PoolingOp {\n public:\n  MaxPoolOp(OpKernelConstruction* ctx, int num_spatial_dims)\n      : PoolingOp(ctx, /*num_spatial_dims=*/num_spatial_dims,\n                  /*reduction_type=*/ctx->input_type(0)) {\n    std::string data_format_str;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format_str));\n    OP_REQUIRES(ctx, FormatFromString(data_format_str, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n    OP_REQUIRES(ctx, data_format_ != FORMAT_NHWC_VECT_W,\n                errors::Unimplemented(\n                    \"XLA does not support the VECT_NHWC_VECT_W data format. \"\n                    \"Returning unimplemented from MaxPool to keep \"\n                    \"Tensorflow's intended optimized MaxPool here.\"));\n  }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    auto ksize_or_error = GetKernelSize(ctx);\n    OP_REQUIRES_OK(ctx, ksize_or_error.status());\n    std::vector<int64_t> ksize = ksize_or_error.value();\n\n    auto stride_or_error = GetStride(ctx);\n    OP_REQUIRES_OK(ctx, stride_or_error.status());\n    std::vector<int64_t> stride = stride_or_error.value();\n\n    xla::XlaOp input = ctx->Input(0);\n\n    StatusOr<xla::Shape> input_shape = ctx->builder()->GetShape(input);\n    OP_REQUIRES_OK(ctx, input_shape.status());\n\n    // For VECT_C max-pool ops, transpose to plain NCHW, do the max-pool, and\n    // transpose back.  This isn't necessarily the most efficient algorithm, but\n    // it's ok for starters.\n    std::optional<int64_t> vect_width;\n    if (data_format_ == FORMAT_NCHW_VECT_C) {\n      vect_width = input_shape->dimensions().back();\n      input = xla::Collapse(xla::Transpose(input, {0, 1, 4, 2, 3}), {1, 2});\n\n      input_shape = ctx->builder()->GetShape(input);\n      OP_REQUIRES_OK(ctx, input_shape.status());\n    }\n\n    OP_REQUIRES(ctx, input_shape->dimensions_size() == num_dims(),\n                errors::InvalidArgument(\"Input to \", type_string(),\n                                        \" operator must have \", num_dims(),\n                                        \" dimensions\"));\n    auto pooling = xla::MaxPool(\n        input, ksize, stride, padding_,\n        XlaTensorFormat(\n            data_format_ == FORMAT_NCHW_VECT_C ? FORMAT_NCHW : data_format_,\n            input_shape->dimensions_size() - 2));\n\n    if (data_format_ == FORMAT_NCHW_VECT_C) {\n      StatusOr<xla::Shape> result_shape = ctx->builder()->GetShape(pooling);\n      OP_REQUIRES_OK(ctx, result_shape.status());\n\n      int64 num_channels = result_shape->dimensions(1);\n      OP_REQUIRES(\n          ctx, num_channels % *vect_width == 0,\n          errors::FailedPrecondition(\"Result of NCHW_VECT_C op must have \"\n                                     \"channels multiple of \",\n                                     *vect_width, \", but was \", num_channels));\n\n      absl::InlinedVector<int64, 5> new_dims(result_shape->dimensions().begin(),\n                                             result_shape->dimensions().end());\n      new_dims[1] /= *vect_width;\n      new_dims.insert(new_dims.begin() + 2, *vect_width);\n      pooling =\n          xla::Transpose(xla::Reshape(pooling, new_dims), {0, 1, 3, 4, 2});\n    }\n\n    ctx->SetOutput(0, pooling);\n  }\n};\n\nclass MaxPool2DOp : public MaxPoolOp {\n public:\n  explicit MaxPool2DOp(OpKernelConstruction* ctx)\n      : MaxPoolOp(ctx, /*num_spatial_dims=*/2) {}\n};\nREGISTER_XLA_OP(Name(\"MaxPool\"), MaxPool2DOp);\nREGISTER_XLA_OP(Name(\"MaxPoolV2\")\n                    .CompileTimeConstantInput(\"ksize\")\n                    .CompileTimeConstantInput(\"strides\"),\n                MaxPool2DOp);\n\nclass MaxPool3DOp : public MaxPoolOp {\n public:\n  explicit MaxPool3DOp(OpKernelConstruction* ctx)\n      : MaxPoolOp(ctx, /*num_spatial_dims=*/3) {}\n};\nREGISTER_XLA_OP(Name(\"MaxPool3D\"), MaxPool3DOp);\n\nclass AvgPoolOp : public PoolingOp {\n public:\n  AvgPoolOp(OpKernelConstruction* ctx, int num_spatial_dims)\n      : PoolingOp(ctx, /*num_spatial_dims=*/num_spatial_dims,\n                  /*reduction_type=*/\n                  XlaHelpers::SumAccumulationType(ctx->input_type(0))) {\n    string data_format_str;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format_str));\n    OP_REQUIRES(ctx, FormatFromString(data_format_str, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n  }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    auto ksize_or_error = GetKernelSize(ctx);\n    OP_REQUIRES_OK(ctx, ksize_or_error.status());\n    std::vector<int64_t> ksize = ksize_or_error.value();\n\n    auto stride_or_error = GetStride(ctx);\n    OP_REQUIRES_OK(ctx, stride_or_error.status());\n    std::vector<int64_t> stride = stride_or_error.value();\n\n    const TensorShape input_shape = ctx->InputShape(0);\n    OP_REQUIRES(ctx, input_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"Input to \", type_string(),\n                                        \" operator must have \", num_dims(),\n                                        \" dimensions\"));\n\n    auto xla_data_format =\n        XlaTensorFormat(data_format_, input_shape.dims() - 2);\n    auto spatial_padding = MakeSpatialPadding(\n        input_shape.dim_sizes(), ksize, stride, padding_, xla_data_format);\n\n    // Convert the input to the reduction type.\n    auto converted_input =\n        ConvertElementType(ctx->Input(0), xla_reduction_type_);\n    auto pooling =\n        xla::AvgPool(converted_input, ksize, stride, spatial_padding,\n                     xla_data_format, padding_ == xla::Padding::kValid);\n    // Convert the pooling result back to the input type before returning it.\n    ctx->SetOutput(0, ConvertElementType(pooling, ctx->input_xla_type(0)));\n  }\n};\n\nclass AvgPool2DOp : public AvgPoolOp {\n public:\n  explicit AvgPool2DOp(OpKernelConstruction* ctx)\n      : AvgPoolOp(ctx, /*num_spatial_dims=*/2) {}\n};\nREGISTER_XLA_OP(Name(\"AvgPool\"), AvgPool2DOp);\n\nREGISTER_XLA_OP(Name(\"AvgPool3D\"), MlirXlaOpKernel);\n\n// The operation to compute MaxPool gradients.\n// It takes three inputs:\n//   - The original input tensor\n//   - The original output tensor\n//   - Backprop tensor for output\n// It produces one output: backprop tensor for input.\nclass MaxPoolGradOp : public XlaOpKernel {\n public:\n  MaxPoolGradOp(OpKernelConstruction* ctx, int num_spatial_dims)\n      : XlaOpKernel(ctx), num_spatial_dims_(num_spatial_dims) {\n    if (ctx->num_inputs() == 3) {\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"ksize\", &ksize_));\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"strides\", &stride_));\n    }\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(ctx, padding_ != EXPLICIT,\n                errors::Unimplemented(\n                    \"XLA does not support maxpoolgrad with explicit padding.\"));\n    // When determinism is enabled, the use of SelectAndScatter causes a generic\n    // error to be raised. We raise a more informative error here before\n    // SelectAndScatter is used.\n    OP_REQUIRES(\n        ctx, !tensorflow::OpDeterminismRequired(),\n        errors::Unimplemented(\"GPU MaxPool gradient ops do not yet have a \"\n                              \"deterministic XLA implementation.\"));\n  }\n\n  int num_dims() const { return num_spatial_dims_ + 2; }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    if (ctx->num_inputs() != 3) {\n      OP_REQUIRES(\n          ctx, ctx->num_inputs() == 5,\n          errors::InvalidArgument(\"Must supply ksize and stride arguments.\"));\n      const TensorShape ksize_shape = ctx->InputShape(3);\n      // Validate input sizes.\n      OP_REQUIRES(ctx, TensorShapeUtils::IsVector(ksize_shape),\n                  errors::InvalidArgument(\"ksize must be a vector, not shape \",\n                                          ksize_shape.DebugString()));\n      OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(3, &ksize_));\n\n      const TensorShape stride_shape = ctx->InputShape(4);\n      // Validate input sizes.\n      OP_REQUIRES(ctx, TensorShapeUtils::IsVector(stride_shape),\n                  errors::InvalidArgument(\"stride must be a vector, not shape \",\n                                          stride_shape.DebugString()));\n      OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(4, &stride_));\n    }\n\n    OP_REQUIRES(ctx, ksize_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n    OP_REQUIRES(ctx, stride_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window strides field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n\n    const TensorShape tensor_in_shape = ctx->InputShape(0);\n    const TensorShape tensor_out_shape = ctx->InputShape(1);\n    const TensorShape out_backprop_shape = ctx->InputShape(2);\n\n    // For maxpooling, tensor_in should have num_dims() dimensions.\n    OP_REQUIRES(ctx, tensor_in_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"tensor_in must be \", num_dims(),\n                                        \"-dimensional\"));\n    OP_REQUIRES(ctx, tensor_out_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"tensor_out must be \", num_dims(),\n                                        \"-dimensional\"));\n    // For maxpooling, out_backprop should have num_dims() dimensions.\n    OP_REQUIRES(ctx, out_backprop_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"out_backprop must be \", num_dims(),\n                                        \"-dimensional\"));\n\n    // TODO(phawkins): The XLA version doesn't need tensor_out. Investigate\n    // whether this is a good time/space tradeoff.\n    auto input = ctx->Input(0);\n    auto out_backprop = ctx->Input(2);\n    // We ensured padding_ is not EXPLICIT in the constructor.\n    xla::Padding xla_padding =\n        (padding_ == VALID) ? xla::Padding::kValid : xla::Padding::kSame;\n\n    // Create a MaxPool operation to check the expected resulting shape, and\n    // then throw away the operation because we don't actually need it here.\n    TensorShape expected_out_shape;\n    auto pooling =\n        xla::MaxPool(ctx->Input(0), ksize_, stride_, xla_padding,\n                     XlaTensorFormat(data_format_, tensor_in_shape.dims() - 2));\n    auto status_or_shape = pooling.builder()->GetShape(pooling);\n    OP_REQUIRES_OK(ctx, status_or_shape.status());\n    OP_REQUIRES_OK(ctx, XLAShapeToTensorShape(status_or_shape.value(),\n                                              &expected_out_shape));\n    OP_REQUIRES(ctx, expected_out_shape == out_backprop_shape,\n                errors::Unimplemented(\"The output dimensions do not match the \"\n                                      \"other input values.\"));\n\n    xla::PrimitiveType element_type;\n    OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(input_type(2), &element_type));\n    xla::XlaOp init_value = XlaHelpers::Zero(ctx->builder(), input_type(2));\n    auto select = CreateScalarGeComputation(element_type, ctx->builder());\n    auto scatter = CreateScalarAddComputation(element_type, ctx->builder());\n    xla::XlaOp gradients =\n        xla::SelectAndScatter(input, select, ksize_, stride_, xla_padding,\n                              out_backprop, init_value, scatter);\n\n    ctx->SetOutput(0, gradients);\n  }\n\n protected:\n  const int num_spatial_dims_;\n  std::vector<int64_t> ksize_;\n  std::vector<int64_t> stride_;\n  Padding padding_;\n  TensorFormat data_format_ = FORMAT_NHWC;\n};\n\nclass MaxPool2DGradOp : public MaxPoolGradOp {\n public:\n  explicit MaxPool2DGradOp(OpKernelConstruction* ctx)\n      : MaxPoolGradOp(ctx, /*num_spatial_dims=*/2) {\n    string data_format;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n  }\n};\nREGISTER_XLA_OP(Name(\"MaxPoolGrad\"), MaxPool2DGradOp);\nREGISTER_XLA_OP(Name(\"MaxPoolGradV2\")\n                    .CompileTimeConstantInput(\"ksize\")\n                    .CompileTimeConstantInput(\"strides\"),\n                MaxPool2DGradOp);\n\nREGISTER_XLA_OP(Name(\"MaxPool3DGrad\"), MlirXlaOpKernel);\n\n// Average-pooling gradient\nclass AvgPoolGradOp : public XlaOpKernel {\n public:\n  AvgPoolGradOp(OpKernelConstruction* ctx, int num_spatial_dims)\n      : XlaOpKernel(ctx), num_spatial_dims_(num_spatial_dims) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"ksize\", &ksize_));\n    OP_REQUIRES(ctx, ksize_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"strides\", &stride_));\n    OP_REQUIRES(ctx, stride_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window strides field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(ctx, padding_ != EXPLICIT,\n                errors::Unimplemented(\n                    \"XLA does not support avgpoolgrad with explicit padding.\"));\n    OP_REQUIRES(ctx, ksize_[0] == 1 && stride_[0] == 1,\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the batch dimension.\"));\n\n    string data_format;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n  }\n\n  int num_dims() const { return num_spatial_dims_ + 2; }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    TensorShape gradients_shape;\n    OP_REQUIRES_OK(\n        ctx, ctx->ConstantInputAsShape(0, &gradients_shape,\n                                       xla::ValueInferenceMode::kUpperBound));\n\n    const TensorShape out_backprop_shape = ctx->InputShape(1);\n\n    // For avgpooling, tensor_in_shape should have num_dims() dimensions.\n    OP_REQUIRES(ctx, gradients_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"orig_input_shape must be \", num_dims(),\n                                        \"-dimensional\"));\n\n    // For avgpooling, out_backprop should have num_dims() dimensions.\n    OP_REQUIRES(ctx, out_backprop_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"out_backprop must be \", num_dims(),\n                                        \"-dimensional\"));\n\n    auto out_backprop = ctx->Input(1);\n    std::vector<int64_t> stride_int64s(stride_.begin(), stride_.end());\n    xla::Padding xla_padding =\n        (padding_ == VALID) ? xla::Padding::kValid : xla::Padding::kSame;\n    xla::PrimitiveType xla_reduction_type;\n    auto reduction_type = XlaHelpers::SumAccumulationType(ctx->input_type(1));\n    OP_REQUIRES_OK(\n        ctx, DataTypeToPrimitiveType(reduction_type, &xla_reduction_type));\n    auto converted_out_backprop =\n        xla::ConvertElementType(out_backprop, xla_reduction_type);\n    auto xla_data_format =\n        XlaTensorFormat(data_format_, gradients_shape.dims() - 2);\n    auto padding_values =\n        MakeSpatialPadding(gradients_shape.dim_sizes(), ksize_, stride_int64s,\n                           xla_padding, xla_data_format);\n    auto in_backprop =\n        xla::AvgPoolGrad(converted_out_backprop, gradients_shape.dim_sizes(),\n                         ksize_, stride_int64s, padding_values, xla_data_format,\n                         /*counts_include_padding=*/padding_ == VALID);\n    // Convert the pooling result back to the input type before returning it.\n    xla::PrimitiveType xla_out_backprop_type;\n    OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(ctx->input_type(1),\n                                                &xla_out_backprop_type));\n    ctx->SetOutput(0,\n                   xla::ConvertElementType(in_backprop, xla_out_backprop_type));\n  }\n\n protected:\n  const int num_spatial_dims_;\n  std::vector<int64_t> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;\n  TensorFormat data_format_ = FORMAT_NHWC;\n};\n\nclass AvgPool2DGradOp : public AvgPoolGradOp {\n public:\n  explicit AvgPool2DGradOp(OpKernelConstruction* ctx)\n      : AvgPoolGradOp(ctx, /*num_spatial_dims=*/2) {}\n};\nREGISTER_XLA_OP(\n    Name(\"AvgPoolGrad\").CompileTimeConstantInput(\"orig_input_shape\"),\n    AvgPool2DGradOp);\n\nclass AvgPool3DGradOp : public AvgPoolGradOp {\n public:\n  explicit AvgPool3DGradOp(OpKernelConstruction* ctx)\n      : AvgPoolGradOp(ctx, /*num_spatial_dims=*/3) {}\n};\nREGISTER_XLA_OP(\n    Name(\"AvgPool3DGrad\").CompileTimeConstantInput(\"orig_input_shape\"),\n    AvgPool3DGradOp);\n\nclass MaxPoolGradGradOp : public XlaOpKernel {\n public:\n  MaxPoolGradGradOp(OpKernelConstruction* ctx, int num_spatial_dims)\n      : XlaOpKernel(ctx), num_spatial_dims_(num_spatial_dims) {\n    if (ctx->num_inputs() == 3) {\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"ksize\", &ksize_));\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"strides\", &stride_));\n    }\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(\n        ctx, padding_ != EXPLICIT,\n        errors::Unimplemented(\n            \"XLA does not support maxpoolgradgrad with explicit padding.\"));\n  }\n\n  int num_dims() const { return num_spatial_dims_ + 2; }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    if (ctx->num_inputs() != 3) {\n      OP_REQUIRES(\n          ctx, ctx->num_inputs() == 5,\n          errors::InvalidArgument(\"Must supply ksize and stride arguments.\"));\n      const TensorShape ksize_shape = ctx->InputShape(3);\n      // Validate input sizes.\n      OP_REQUIRES(ctx, TensorShapeUtils::IsVector(ksize_shape),\n                  errors::InvalidArgument(\"ksize must be a vector, not shape \",\n                                          ksize_shape.DebugString()));\n      OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(3, &ksize_));\n\n      const TensorShape stride_shape = ctx->InputShape(4);\n      // Validate input sizes.\n      OP_REQUIRES(ctx, TensorShapeUtils::IsVector(stride_shape),\n                  errors::InvalidArgument(\"stride must be a vector, not shape \",\n                                          stride_shape.DebugString()));\n      OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(4, &stride_));\n    }\n\n    OP_REQUIRES(ctx, ksize_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n    OP_REQUIRES(ctx, stride_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window strides field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n\n    const TensorShape tensor_in_shape = ctx->InputShape(0);\n    const TensorShape tensor_out_shape = ctx->InputShape(1);\n    const TensorShape out_backprop_shape = ctx->InputShape(2);\n\n    // For maxpooling, tensor_in should have num_dims() dimensions.\n    OP_REQUIRES(ctx, tensor_in_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"tensor_in must be \", num_dims(),\n                                        \"-dimensional\"));\n    OP_REQUIRES(ctx, tensor_out_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"tensor_out must be \", num_dims(),\n                                        \"-dimensional\"));\n    // For maxpooling, out_backprop should have num_dims() dimensions.\n    OP_REQUIRES(ctx, out_backprop_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"out_backprop must be \", num_dims(),\n                                        \"-dimensional\"));\n\n    // What we want to compute:\n    // Given y = MaxPool(x), and xs_grad = MaxPoolGrad(x, y, ys_grad)\n    // MaxPoolGradGrad computes {ys_grad}_grad given x, y, and {xs_grad}_grad.\n    //\n    // In the regular TF op, this amounts to selecting for each window the\n    // incoming backprop value from xs_grad_grad that corresponds to the maximal\n    // value in the corresponding window of x.\n    //\n    // TODO(b/73062247): What we really want is a ReduceWindow with different\n    // arrays for index selection vs return value selection--a select-to-gather.\n    //\n    // Here, we implement a bitwise hack: we use the hi 16 bits of input for\n    // separate max pooling alongside each of the hi and lo 16 bits of\n    // out_backprop packed into 16 lo bits, which we then glue back together at\n    // the end to get a full 32 bits of gradient.\n    //\n    // This could select the wrong backprop value for two x values that are\n    // equally maximal up to the first 16 bits, in which case we are taking the\n    // latter.\n    //\n    // Note that in principle we could use 32 separate maxpools to recover each\n    // of 32 bits of the gradient while preserving 31 bits of input for the max\n    // pooling criteria; here, we just truncate to the first 16 bits of input.\n\n    auto input = ctx->Input(0);\n    auto out_backprop = ctx->Input(2);\n\n    auto b = ctx->builder();\n\n    auto sixteen = xla::ConstantR0<uint32>(b, 16);\n    // in (f32) -> round to 7 mantissa bits (bf16)-> 16-high-bit u32.\n    //\n    // NOTE: Use a ReducePrecision operation instead of a cast to BF16 and back\n    // to F32 since the XLA compiler may ignore narrowing casts to floating\n    // point types if the debug option xla_allow_excess_precision is set.\n    auto in_hi = xla::BitcastConvertType(\n        xla::ReducePrecision(input, /*exponent_bits=*/8, /*mantissa_bits=*/7),\n        xla::U32);\n    auto bp_int = xla::BitcastConvertType(out_backprop, xla::U32);\n    auto bp_hi = xla::ShiftRightLogical(bp_int, sixteen);\n    auto bp_lo =\n        xla::ShiftRightLogical(xla::ShiftLeft(bp_int, sixteen), sixteen);\n    auto in_hi_bp_hi = xla::Add(in_hi, bp_hi);  // Want an unsigned add.\n    auto in_hi_bp_lo = xla::Add(in_hi, bp_lo);  // Want an unsigned add.\n\n    auto init_value = xla::MinValue(b, xla::F32);\n    // We will reduce by taking the maximal value up to 16 bits (ignoring the lo\n    // 16 bits of packed-in hi/lo backprop value).\n    auto rb = b->CreateSubBuilder(\"GreaterOrEqOf_ByFirst16Bits\");\n    {\n      // F32 parameters to satisfy lowering type restriction for reduce opcode.\n      const xla::Shape scalar = xla::ShapeUtil::MakeShape(xla::F32, {});\n      auto lhs = xla::Parameter(rb.get(), 0, scalar, \"lhs\");\n      auto rhs = xla::Parameter(rb.get(), 1, scalar, \"rhs\");\n      auto sixteen = xla::ConstantR0<int32>(rb.get(), 16);\n      auto lhs_criteria =\n          xla::ShiftLeft(xla::ShiftRightLogical(\n                             xla::BitcastConvertType(lhs, xla::S32), sixteen),\n                         sixteen);\n      auto rhs_criteria =\n          xla::ShiftLeft(xla::ShiftRightLogical(\n                             xla::BitcastConvertType(rhs, xla::S32), sixteen),\n                         sixteen);\n      // Must use a F32 comparison, because S32 would not work for negatives.\n      xla::Select(xla::Ge(xla::BitcastConvertType(lhs_criteria, xla::F32),\n                          xla::BitcastConvertType(rhs_criteria, xla::F32)),\n                  lhs, rhs);\n    }\n    auto reduce = rb->BuildAndNoteError();\n    xla::Padding xla_padding =\n        (padding_ == VALID) ? xla::Padding::kValid : xla::Padding::kSame;\n    auto pooled_hi =\n        xla::ReduceWindow(xla::BitcastConvertType(in_hi_bp_hi, xla::F32),\n                          init_value, reduce, ksize_, stride_, xla_padding);\n    auto pooled_lo =\n        xla::ReduceWindow(xla::BitcastConvertType(in_hi_bp_lo, xla::F32),\n                          init_value, reduce, ksize_, stride_, xla_padding);\n    auto grads_hi =\n        xla::ShiftLeft(xla::BitcastConvertType(pooled_hi, xla::U32), sixteen);\n    auto grads_lo = xla::ShiftRightLogical(\n        xla::ShiftLeft(xla::BitcastConvertType(pooled_lo, xla::U32), sixteen),\n        sixteen);\n    auto grads = xla::Add(grads_hi, grads_lo);  // Want an unsigned add.\n\n    xla::PrimitiveType element_type;\n    OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(input_type(2), &element_type));\n    ctx->SetOutput(0, xla::BitcastConvertType(grads, element_type));\n  }\n\n protected:\n  const int num_spatial_dims_;\n  std::vector<int64_t> ksize_;\n  std::vector<int64_t> stride_;\n  Padding padding_;\n  TensorFormat data_format_ = FORMAT_NHWC;\n};\n\nclass MaxPool2DGradGradOp : public MaxPoolGradGradOp {\n public:\n  explicit MaxPool2DGradGradOp(OpKernelConstruction* ctx)\n      : MaxPoolGradGradOp(ctx, /*num_spatial_dims=*/2) {\n    string data_format;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n  }\n};\nREGISTER_XLA_OP(Name(\"MaxPoolGradGrad\").TypeConstraint(\"T\", DT_FLOAT),\n                MaxPool2DGradGradOp);\nREGISTER_XLA_OP(Name(\"MaxPoolGradGradV2\")\n                    .TypeConstraint(\"T\", DT_FLOAT)\n                    .CompileTimeConstantInput(\"ksize\")\n                    .CompileTimeConstantInput(\"strides\"),\n                MaxPool2DGradGradOp);\n\nclass MaxPool3DGradGradOp : public MaxPoolGradGradOp {\n public:\n  explicit MaxPool3DGradGradOp(OpKernelConstruction* ctx)\n      : MaxPoolGradGradOp(ctx, /*num_spatial_dims=*/3) {\n    string data_format;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n  }\n};\nREGISTER_XLA_OP(Name(\"MaxPool3DGradGrad\").TypeConstraint(\"T\", DT_FLOAT),\n                MaxPool3DGradGradOp);\n\n}  // anonymous namespace\n}  // namespace tensorflow\n", "/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/compiler/xla/client/padding.h\"\n\n#include <algorithm>\n\n#include \"tensorflow/compiler/xla/util.h\"\n#include \"tensorflow/tsl/lib/math/math_util.h\"\n#include \"tensorflow/tsl/platform/logging.h\"\n\nnamespace xla {\n\nStatus ValidatePaddingValues(absl::Span<const int64_t> input_dimensions,\n                             absl::Span<const int64_t> window_dimensions,\n                             absl::Span<const int64_t> window_strides) {\n  bool ok = input_dimensions.size() == window_dimensions.size() &&\n            input_dimensions.size() == window_strides.size();\n  if (!ok) {\n    return InvalidArgument(\n        \"Want input dimensions size %u = window dimensions size %u = window \"\n        \"strides size %u\",\n        input_dimensions.size(), window_dimensions.size(),\n        window_strides.size());\n  }\n  return OkStatus();\n}\n\nstd::vector<std::pair<int64_t, int64_t>> MakePadding(\n    absl::Span<const int64_t> input_dimensions,\n    absl::Span<const int64_t> window_dimensions,\n    absl::Span<const int64_t> window_strides, Padding padding) {\n  TF_CHECK_OK(ValidatePaddingValues(input_dimensions, window_dimensions,\n                                    window_strides));\n  std::vector<std::pair<int64_t, int64_t>> low_high_padding;\n  switch (padding) {\n    case Padding::kValid:\n      low_high_padding.resize(window_dimensions.size(), {0, 0});\n      return low_high_padding;\n\n    case Padding::kSame:\n      for (size_t i = 0; i < input_dimensions.size(); ++i) {\n        int64_t input_dimension = input_dimensions[i];\n        int64_t window_dimension = window_dimensions[i];\n        int64_t window_stride = window_strides[i];\n        // We follow the same convention as in Tensorflow, such that\n        // output dimension := ceil(input_dimension / window_stride).\n        // See tensorflow/tensorflow/python/ops/nn.py\n        // for the reference. See also tensorflow/core/kernels/ops_util.cc\n        // for the part where we avoid negative padding using max(0, x).\n        //\n        //\n        // For an odd sized window dimension 2N+1 with stride 1, the middle\n        // element is always inside the base area, so we can see it as N + 1 +\n        // N elements. In the example below, we have a kernel of size\n        // 2*3+1=7 so that the center element is 4 with 123 to the\n        // left and 567 to the right.\n        //\n        //  base area:           ------------------------\n        //  kernel at left:   1234567\n        //  kernel at right:                         1234567\n        //\n        // We can see visually here that we need to pad the base area\n        // by 3 on each side:\n        //\n        //  padded base area: 000------------------------000\n        //\n        // For an even number 2N, there are two options:\n        //\n        // *** Option A\n        //\n        // We view 2N as (N - 1) + 1 + N, so for N=3 we have 12 to the\n        // left, 3 is the center and 456 is to the right, like this:\n        //\n        //  base area:           ------------------------\n        //  kernel at left:    123456\n        //  kernel at right:                          123456\n        //  padded base area:  00------------------------000\n        //\n        // Note how we pad by one more to the right than to the left.\n        //\n        // *** Option B\n        //\n        // We view 2N as N + 1 + (N - 1), so for N=3 we have 123 to\n        // the left, 4 is the center and 56 is to the right, like\n        // this:\n        //\n        //  base area:           ------------------------\n        //  kernel at left:   123456\n        //  kernel at right:                         123456\n        //  padded base area: 000------------------------00\n        //\n        // The choice here is arbitrary. We choose option A as this is\n        // what DistBelief and Tensorflow do.\n        //\n        // When the stride is greater than 1, the output size is smaller than\n        // the input base size. The base area is padded such that the last\n        // window fully fits in the padded base area, and the padding amount is\n        // evenly divided between the left and the right (or 1 more on the right\n        // if odd size padding is required). The example below shows the\n        // required padding when the base size is 10, the kernel size is 5, and\n        // the stride is 3. In this example, the output size is 4.\n        //\n        // base area:           ----------\n        // 1'st kernel:       12345\n        // 2'nd kernel:          12345\n        // 3'rd kernel:             12345\n        // 4'th kernel:                12345\n        // padded base area:  00----------00\n        int64_t output_dimension =\n            tsl::MathUtil::CeilOfRatio(input_dimension, window_stride);\n        int64_t padding_size =\n            std::max<int64_t>((output_dimension - 1) * window_stride +\n                                  window_dimension - input_dimension,\n                              0);\n        low_high_padding.emplace_back(\n            tsl::MathUtil::FloorOfRatio(padding_size, int64_t{2}),\n            tsl::MathUtil::CeilOfRatio(padding_size, int64_t{2}));\n      }\n      break;\n  }\n\n  return low_high_padding;\n}\n\n}  // namespace xla\n"], "fixing_code": ["# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Functional tests for pooling operations.\"\"\"\n\nimport numpy as np\n\nfrom tensorflow.compiler.tests import xla_test\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gen_nn_ops\nfrom tensorflow.python.ops import nn_ops\nfrom tensorflow.python.platform import googletest\n\n\ndef NHWCToNCHW(input_tensor):\n  \"\"\"Convert the input from NHWC format to NCHW.\n\n  Args:\n    input_tensor:  a 4-D tensor, or a 4-element array representing the same.\n\n  Returns:\n    the converted tensor or a shape array\n  \"\"\"\n  if isinstance(input_tensor, ops.Tensor):\n    return array_ops.transpose(input_tensor, [0, 3, 1, 2])\n  else:\n    return [input_tensor[0], input_tensor[3], input_tensor[1], input_tensor[2]]\n\n\ndef NCHWToNHWC(input_tensor):\n  \"\"\"Convert the input from NCHW format to NHWC.\n\n  Args:\n    input_tensor:  a 4-D tensor, or a 4-element array representing the same.\n\n  Returns:\n    the converted tensor or a shape array\n  \"\"\"\n  if isinstance(input_tensor, ops.Tensor):\n    return array_ops.transpose(input_tensor, [0, 2, 3, 1])\n  else:\n    return [input_tensor[0], input_tensor[2], input_tensor[3], input_tensor[1]]\n\n\ndef GetTestConfigs():\n  \"\"\"Get all the valid tests configs to run.\n\n  Returns:\n    all the valid test configs\n  \"\"\"\n  test_configs = [\"NHWC\", \"NCHW\"]\n  return test_configs\n\n\nclass PoolingTest(xla_test.XLATestCase):\n\n  def _VerifyOneTest(self, pool_func, input_sizes, ksize, strides, padding,\n                     data_format, expected):\n    \"\"\"Verifies the output values of the pooling function.\n\n    Args:\n      pool_func: Function to be called, currently only co.MaxPool.\n      input_sizes: Input tensor dimensions.\n      ksize: The kernel size dimensions\n      strides: The stride dimensions\n      padding: Padding type.\n      data_format: The data format we use to run the pooling operation.\n      expected: An array containing the expected operation outputs.\n    \"\"\"\n    total_size = np.prod(input_sizes)\n    # Initializes the input tensor with array containing incrementing\n    # numbers from 1.\n    x = np.array([f * 1.0 for f in range(1, total_size + 1)], dtype=np.float32)\n    x = x.reshape(input_sizes)\n    with self.session() as sess:\n      with self.test_scope():\n        inputs = array_ops.placeholder(dtypes.float32)\n        t = inputs\n        if data_format == \"NCHW\":\n          t = NHWCToNCHW(t)\n          ksize = NHWCToNCHW(ksize)\n          strides = NHWCToNCHW(strides)\n        t = pool_func(t,\n                      ksize=ksize,\n                      strides=strides,\n                      padding=padding,\n                      data_format=data_format)\n        if data_format == \"NCHW\":\n          t = NCHWToNHWC(t)\n      actual = sess.run(t, {inputs: x})\n      self.assertAllClose(expected, actual.flatten(), rtol=1e-5, atol=1e-6)\n\n  def _VerifyValues(self, pool_func, input_sizes, ksize, strides, padding,\n                    expected):\n    \"\"\"Verifies the output values of the pooling function.\n\n    Args:\n      pool_func: Function to be called, co.MaxPool, co.AvgPool,\n        or the Lua version.\n      input_sizes: Input tensor dimensions.\n      ksize: The kernel size dimensions\n      strides: The stride dimensions\n      padding: Padding type.\n      expected: An array containing the expected operation outputs.\n    \"\"\"\n    for data_format in GetTestConfigs():\n      self._VerifyOneTest(pool_func, input_sizes, ksize, strides, padding,\n                          data_format, expected)\n\n  def testMaxPoolValidPadding(self):\n    expected_output = [13.0, 14.0, 15.0]\n    self._VerifyValues(nn_ops.max_pool,\n                       input_sizes=[1, 3, 3, 3],\n                       ksize=[1, 2, 2, 1],\n                       strides=[1, 2, 2, 1],\n                       padding=\"VALID\",\n                       expected=expected_output)\n\n  def testMaxPoolSamePadding(self):\n    expected_output = [13.0, 14.0, 15.0, 16.0, 17.0, 18.0]\n    self._VerifyValues(nn_ops.max_pool,\n                       input_sizes=[1, 2, 3, 3],\n                       ksize=[1, 2, 2, 1],\n                       strides=[1, 2, 2, 1],\n                       padding=\"SAME\",\n                       expected=expected_output)\n\n  def testMaxPoolSamePaddingNonSquareWindow(self):\n    # input is:\n    # [1.0, 2.0\n    #  3.0  4.0]\n    #\n    # Window of [x, x] should do:\n    #\n    #  [max(1.0, 2.0), max(2.0, padded0),\n    #   max(3.0, 4.0), max(4.0, padded0)]\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 2, 2, 1],\n        ksize=[1, 1, 2, 1],\n        strides=[1, 1, 1, 1],\n        padding=\"SAME\",\n        expected=[2.0, 2.0, 4.0, 4.0])\n\n  def testMaxPoolValidPaddingUnevenStride(self):\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 1, 2, 1],\n        padding=\"VALID\",\n        expected=[6.0, 8.0, 10.0, 12.0, 14.0, 16.0])\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 1, 1],\n        padding=\"VALID\",\n        expected=[6.0, 7.0, 8.0, 14.0, 15.0, 16.0])\n\n  def testMaxPoolSamePaddingFilter4(self):\n    expected_output = [\n        21.0, 22.0, 23.0, 24.0, 29.0, 30.0, 31.0, 32.0, 53.0, 54.0, 55.0, 56.0,\n        61.0, 62.0, 63.0, 64.0\n    ]\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 4, 4, 4],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        expected=expected_output)\n\n  def testMaxPoolSamePaddingFilter8(self):\n    expected_output = [\n        145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 161.0, 162.0,\n        163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 177.0, 178.0, 179.0, 180.0,\n        181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0,\n        191.0, 192.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0,\n        289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 305.0, 306.0,\n        307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0,\n        317.0, 318.0, 319.0, 320.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0,\n        407.0, 408.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0,\n        433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0,\n        443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 465.0, 466.0, 467.0, 468.0,\n        469.0, 470.0, 471.0, 472.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0,\n        487.0, 488.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0,\n        505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0\n    ]\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 8, 8, 8],\n        ksize=[1, 3, 3, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        expected=expected_output)\n\n  # Tests for DepthwiseMaxPooling on CPU only.\n  def testDepthwiseMaxPool1x1DepthWindow1(self):\n    # input is:\n    # [1.0, ..., 10.0] along depth,\n    #\n    # We maxpool by depth in patches of 2.\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 1, 1, 10],\n        ksize=[1, 1, 1, 2],\n        strides=[1, 1, 1, 2],\n        padding=\"SAME\",\n        expected=[2.0, 4.0, 6.0, 8.0, 10.0])\n\n  def testDepthwiseMaxPool2x2DepthWindow3(self):\n    # input is:\n    #\n    # a 2x2x6 cube, and we depthwise max across 3 to produce a 2x2x2\n    # output.  Each node has contiguous values, so the depthwise max\n    # should be multiples of 3.0.\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 2, 2, 6],\n        ksize=[1, 1, 1, 3],\n        strides=[1, 1, 1, 3],\n        padding=\"SAME\",\n        expected=[3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n\n  def testKernelSmallerThanStrideValid(self):\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 7, 7, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 3, 3, 1],\n        padding=\"VALID\",\n        expected=[9, 12, 30, 33])\n\n  def testKernelSmallerThanStrideSame(self):\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 3, 3, 1],\n        ksize=[1, 1, 1, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        expected=[1, 3, 7, 9])\n\n    self._VerifyValues(\n        nn_ops.max_pool,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 1, 1, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        expected=[1, 3, 9, 11])\n\n  # Average pooling\n  def testAvgPoolValidPadding(self):\n    expected_output = [7, 8, 9]\n    self._VerifyValues(\n        nn_ops.avg_pool,\n        input_sizes=[1, 3, 3, 3],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"VALID\",\n        expected=expected_output)\n\n  def testAvgPoolSamePadding(self):\n    expected_output = [7., 8., 9., 11.5, 12.5, 13.5]\n    self._VerifyValues(\n        nn_ops.avg_pool,\n        input_sizes=[1, 2, 3, 3],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        expected=expected_output)\n\n\nclass PoolGradTest(xla_test.XLATestCase):\n\n  CPU_DEVICE = \"/job:localhost/replica:0/task:0/cpu:0\"\n\n  def _VerifyOneTest(self,\n                     pool_func,\n                     pool_grad_func,\n                     input_sizes,\n                     ksize,\n                     strides,\n                     padding,\n                     data_format,\n                     pool_grad_grad_func=None):\n    \"\"\"Verifies the output values of the pooling gradient function.\n\n    Args:\n      pool_func: Forward pooling function\n      pool_grad_func: Pooling gradient function for pool_grad_func\n      input_sizes: Input tensor dimensions.\n      ksize: The kernel size dimensions\n      strides: The stride dimensions\n      padding: Padding type.\n      data_format: The data format we use to run the pooling operation.\n      pool_grad_grad_func: Second-order gradient function, if available.\n    \"\"\"\n    total_size = np.prod(input_sizes)\n    # TODO(b/73062247): MaxPoolGradGrad can confuse gradients when x is equally\n    # maximal at 16 bits. Switch to np.random.randn when resolved.\n    x = np.arange(1, total_size + 1, dtype=np.float32)\n    x *= (np.random.randint(2, size=total_size) * 2 - 1)  # Flip signs randomly\n    # Verify some specifically interesting values...\n    x[np.random.choice(total_size)] = np.inf\n    x[np.random.choice(total_size)] = -np.inf\n    # TODO(b/74222344): Fix nan handling for max pool grad.\n    # x[np.random.choice(total_size)] = np.nan\n    x = x.reshape(input_sizes)\n    with self.session() as sess:\n      # Use the forward pool function to compute some corresponding outputs\n      # (needed for the CPU device, and we need the shape in both cases).\n      with ops.device(self.CPU_DEVICE):\n        inputs = array_ops.placeholder(dtypes.float32, shape=input_sizes)\n        outputs = pool_func(\n            inputs,\n            ksize=ksize,\n            strides=strides,\n            padding=padding,\n            data_format=\"NHWC\")\n\n      output_vals = np.array(sess.run(outputs, {inputs: x}))\n      output_gradient_vals = np.arange(\n          1, output_vals.size + 1, dtype=np.float32)\n      output_gradient_vals = output_gradient_vals.reshape(output_vals.shape)\n      output_grad_grad_vals = np.arange(1, x.size + 1, dtype=np.float32)\n      output_grad_grad_vals = output_grad_grad_vals.reshape(x.shape)\n\n      # Use the Tensorflow CPU pooling gradient to compute the expected input\n      # gradients.\n      with ops.device(self.CPU_DEVICE):\n        output_gradients = array_ops.placeholder(\n            dtypes.float32, shape=output_vals.shape)\n        expected_input_gradients = pool_grad_func(\n            inputs,\n            outputs,\n            output_gradients,\n            ksize=ksize,\n            strides=strides,\n            padding=padding,\n            data_format=\"NHWC\")\n        expected_input_gradient_vals = sess.run(\n            expected_input_gradients,\n            {inputs: x,\n             output_gradients: output_gradient_vals})\n\n        output_grad_gradients = array_ops.placeholder(\n            dtypes.float32, shape=expected_input_gradient_vals.shape)\n        if pool_grad_grad_func is not None:\n          expected_grad_gradients = pool_grad_grad_func(\n              inputs,\n              outputs,\n              output_grad_gradients,\n              ksize=ksize,\n              strides=strides,\n              padding=padding,\n              data_format=\"NHWC\")\n          expected_grad_gradients_vals = sess.run(expected_grad_gradients, {\n              inputs: x,\n              output_grad_gradients: output_grad_grad_vals\n          })\n\n      # Run the gradient op on the XLA device\n      with self.test_scope():\n        outputs = array_ops.placeholder(dtypes.float32, shape=output_vals.shape)\n        xla_inputs = inputs\n        xla_outputs = outputs\n        xla_output_gradients = output_gradients\n        xla_output_grad_gradients = output_grad_gradients\n        xla_ksize = ksize\n        xla_strides = strides\n        if data_format == \"NCHW\":\n          xla_inputs = NHWCToNCHW(inputs)\n          xla_outputs = NHWCToNCHW(outputs)\n          xla_output_gradients = NHWCToNCHW(output_gradients)\n          xla_output_grad_gradients = NHWCToNCHW(output_grad_gradients)\n          xla_ksize = NHWCToNCHW(ksize)\n          xla_strides = NHWCToNCHW(strides)\n        actual_input_gradients = pool_grad_func(\n            xla_inputs,\n            xla_outputs,\n            xla_output_gradients,\n            ksize=xla_ksize,\n            strides=xla_strides,\n            padding=padding,\n            data_format=data_format)\n        if data_format == \"NCHW\":\n          actual_input_gradients = NCHWToNHWC(actual_input_gradients)\n        if pool_grad_grad_func is not None:\n          actual_grad_gradients = pool_grad_grad_func(\n              xla_inputs,\n              xla_outputs,\n              xla_output_grad_gradients,\n              ksize=xla_ksize,\n              strides=xla_strides,\n              padding=padding,\n              data_format=data_format)\n          if data_format == \"NCHW\":\n            actual_grad_gradients = NCHWToNHWC(actual_grad_gradients)\n      actual_input_gradients_vals = sess.run(actual_input_gradients, {\n          inputs: x,\n          outputs: output_vals,\n          output_gradients: output_gradient_vals\n      })\n      # Compare the Tensorflow and XLA results.\n      self.assertAllClose(\n          expected_input_gradient_vals,\n          actual_input_gradients_vals,\n          rtol=1e-4,\n          atol=1e-6)\n      self.assertShapeEqual(actual_input_gradients_vals, inputs)\n\n      if pool_grad_grad_func is not None:\n        actual_grad_gradients_vals = sess.run(\n            actual_grad_gradients, {\n                inputs: x,\n                outputs: output_vals,\n                output_grad_gradients: output_grad_grad_vals\n            })\n\n        # Compare the Tensorflow and XLA results.\n        self.assertAllClose(\n            expected_grad_gradients_vals,\n            actual_grad_gradients_vals,\n            rtol=1e-4,\n            atol=1e-6)\n        self.assertShapeEqual(actual_grad_gradients_vals, outputs)\n\n  def _VerifyValues(self,\n                    pool_func,\n                    pool_grad_func,\n                    input_sizes,\n                    ksize,\n                    strides,\n                    padding,\n                    pool_grad_grad_func=None):\n    \"\"\"Verifies the output values of the pooling function.\n\n    Args:\n      pool_func: Pooling function to be called, e.g., tf.nn.max_pool2d\n      pool_grad_func: Corresponding pooling gradient function.\n      input_sizes: Input tensor dimensions.\n      ksize: The kernel size dimensions\n      strides: The stride dimensions\n      padding: Padding type.\n      pool_grad_grad_func: Second-order gradient function, if available.\n    \"\"\"\n    for data_format in GetTestConfigs():\n      self._VerifyOneTest(\n          pool_func,\n          pool_grad_func,\n          input_sizes,\n          ksize,\n          strides,\n          padding,\n          data_format,\n          pool_grad_grad_func=pool_grad_grad_func)\n\n  def _TestPooling(self, forward_op, backward_op, pool_grad_grad_func=None):\n    # VALID padding\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 3, 3, 3],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"VALID\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n    # SAME padding\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 2, 3, 3],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n    # SAME padding, non square window\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 2, 2, 1],\n        ksize=[1, 1, 2, 1],\n        strides=[1, 1, 1, 1],\n        padding=\"SAME\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n    # VALID padding, uneven stride\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 1, 2, 1],\n        padding=\"VALID\",\n        pool_grad_grad_func=pool_grad_grad_func)\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 1, 1],\n        padding=\"VALID\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n    # SAME padding, size 4 input\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 4, 4, 4],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n    # SAME padding, size 8 input\n    self._VerifyValues(\n        forward_op,\n        backward_op,\n        input_sizes=[1, 8, 8, 8],\n        ksize=[1, 3, 3, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\",\n        pool_grad_grad_func=pool_grad_grad_func)\n\n  def testMaxPool(self):\n    self._TestPooling(\n        nn_ops.max_pool,\n        gen_nn_ops.max_pool_grad,\n        pool_grad_grad_func=gen_nn_ops.max_pool_grad_grad)\n\n  def testAvgPool(self):\n    # Wrapper around AvgPoolGrad that ignores extra arguments needed by\n    # MaxPoolGrad.\n    def AvgPoolGrad(inputs, outputs, output_gradients, ksize, strides, padding,\n                    data_format):\n      del outputs  # Unused by average-pooling gradients.\n      return gen_nn_ops.avg_pool_grad(\n          inputs.get_shape().as_list(),\n          output_gradients,\n          ksize=ksize,\n          strides=strides,\n          padding=padding,\n          data_format=data_format)\n\n    self._TestPooling(nn_ops.avg_pool, AvgPoolGrad)\n\n  @test_util.disable_mlir_bridge(\n      \"TODO(b/266613412): investigate FPE in AvgPoolGrad for TPU\"\n  )\n  def testAvgPoolGradSamePaddingZeroStrideZeroSize(self):\n    output_gradient_vals = np.array([0.39117979], dtype=np.float32)\n    output_gradient_vals = output_gradient_vals.reshape([1, 1, 1, 1])\n    with self.session() as sess:\n      with self.test_scope():\n        output_gradients = array_ops.placeholder(\n            dtypes.float32, shape=output_gradient_vals.shape\n        )\n        t = gen_nn_ops.avg_pool_grad(\n            orig_input_shape=[1, 0, 0, 0],\n            grad=output_gradients,\n            ksize=[1, 0, 0, 0],\n            strides=[1, 0, 0, 0],\n            padding=\"SAME\",\n            data_format=\"NCHW\",\n        )\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          (\n              \"Sliding window ksize field for dimension 1 must be positive but\"\n              \" is 0\"\n          ),\n      ):\n        sess.run(t, {output_gradients: output_gradient_vals})\n\n  # The CPU implementation of AvgPoolGrad doesn't accept kernels smaller than\n  # the stride size, so we only run the following tests on MaxPoolGrad.\n\n  def testMaxPoolKernelSmallerThanStrideValid(self):\n    self._VerifyValues(\n        nn_ops.max_pool,\n        gen_nn_ops.max_pool_grad,\n        input_sizes=[1, 7, 7, 1],\n        ksize=[1, 2, 2, 1],\n        strides=[1, 3, 3, 1],\n        padding=\"VALID\")\n\n  def testMaxPoolKernelSmallerThanStrideSame(self):\n    self._VerifyValues(\n        nn_ops.max_pool,\n        gen_nn_ops.max_pool_grad,\n        input_sizes=[1, 3, 3, 1],\n        ksize=[1, 1, 1, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\")\n\n    self._VerifyValues(\n        nn_ops.max_pool,\n        gen_nn_ops.max_pool_grad,\n        input_sizes=[1, 4, 4, 1],\n        ksize=[1, 1, 1, 1],\n        strides=[1, 2, 2, 1],\n        padding=\"SAME\")\n\n\nif __name__ == \"__main__\":\n  googletest.main()\n", "/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// XLA specific pooling ops.\n\n#include <string>\n\n#include \"tensorflow/compiler/tf2xla/mlir_xla_op_kernel.h\"\n#include \"tensorflow/compiler/tf2xla/shape_util.h\"\n#include \"tensorflow/compiler/tf2xla/type_util.h\"\n#include \"tensorflow/compiler/tf2xla/xla_helpers.h\"\n#include \"tensorflow/compiler/tf2xla/xla_op_kernel.h\"\n#include \"tensorflow/compiler/tf2xla/xla_op_registry.h\"\n#include \"tensorflow/compiler/xla/client/lib/arithmetic.h\"\n#include \"tensorflow/compiler/xla/client/lib/constants.h\"\n#include \"tensorflow/compiler/xla/client/lib/pooling.h\"\n#include \"tensorflow/compiler/xla/client/value_inference.h\"\n#include \"tensorflow/compiler/xla/client/xla_builder.h\"\n#include \"tensorflow/compiler/xla/client/xla_computation.h\"\n#include \"tensorflow/compiler/xla/literal.h\"\n#include \"tensorflow/compiler/xla/util.h\"\n#include \"tensorflow/core/framework/bounds_check.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/op_requires.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/util/determinism.h\"\n#include \"tensorflow/core/util/tensor_format.h\"\n#include \"tensorflow/tsl/platform/errors.h\"\n\nnamespace tensorflow {\nnamespace {\n\ntemplate <typename T>\nstatic Status ValidateKernelSizes(const T& ksizes) {\n  for (size_t i = 0; i < ksizes.size(); ++i) {\n    if (ksizes[i] <= 0) {\n      return errors::InvalidArgument(\n          \"Sliding window ksize field for dimension \", i,\n          \" must be positive but is \", ksizes[i]);\n    }\n  }\n  return OkStatus();\n}\n\ntemplate <typename T>\nstatic Status ValidateStrides(const T& strides) {\n  for (size_t i = 0; i < strides.size(); ++i) {\n    if (strides[i] <= 0) {\n      return errors::InvalidArgument(\n          \"Sliding window stride field for dimension \", i,\n          \" must be positive but is \", strides[i]);\n    }\n  }\n  return OkStatus();\n}\n\n// Superclass of pooling ops.\nclass PoolingOp : public XlaOpKernel {\n public:\n  PoolingOp(OpKernelConstruction* ctx, int num_spatial_dims,\n            const DataType reduction_type)\n      : XlaOpKernel(ctx),\n        num_spatial_dims_(num_spatial_dims),\n        reduction_type_(reduction_type) {\n    if (ctx->num_inputs() == 1) {\n      std::vector<int32> ksize_int;\n      std::vector<int32> stride_int;\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"ksize\", &ksize_int));\n      OP_REQUIRES(ctx, ksize_int.size() == num_dims(),\n                  errors::InvalidArgument(\"Sliding window ksize field must \"\n                                          \"specify \",\n                                          num_dims(), \" dimensions\"));\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"strides\", &stride_int));\n      OP_REQUIRES(ctx, stride_int.size() == num_dims(),\n                  errors::InvalidArgument(\"Sliding window stride field must \"\n                                          \"specify \",\n                                          num_dims(), \" dimensions\"));\n      for (int i = 0; i < num_dims(); ++i) {\n        ksize_.push_back(ksize_int[i]);\n        stride_.push_back(stride_int[i]);\n      }\n    }\n    Padding padding;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padding\", &padding));\n    OP_REQUIRES(ctx, padding != EXPLICIT,\n                errors::Unimplemented(\n                    \"XLA does not support pooling ops with explicit padding.\"));\n    padding_ = (padding == VALID) ? xla::Padding::kValid : xla::Padding::kSame;\n\n    OP_REQUIRES_OK(\n        ctx, DataTypeToPrimitiveType(reduction_type_, &xla_reduction_type_));\n  }\n\n  int num_dims() const { return num_spatial_dims_ + 2; }\n\n protected:\n  StatusOr<std::vector<int64_t>> GetKernelSize(XlaOpKernelContext* ctx) {\n    std::vector<int64_t> ksize;\n    if (ctx->num_inputs() == 1) {\n      ksize = ksize_;\n    } else {\n      const TensorShape ksize_shape = ctx->InputShape(1);\n      // Validate input sizes.\n      if (!TensorShapeUtils::IsVector(ksize_shape)) {\n        return errors::InvalidArgument(\"ksize must be a vector, not shape \",\n                                       ksize_shape.DebugString());\n      }\n      if (ksize_shape.num_elements() != num_dims()) {\n        return errors::InvalidArgument(\n            \"Sliding window ksize field must \"\n            \"specify \",\n            num_dims(), \" dimensions\");\n      }\n      auto status = ctx->ConstantInputAsIntVector(1, &ksize);\n      if (!status.ok()) {\n        return status;\n      }\n    }\n    TF_RETURN_IF_ERROR(ValidateKernelSizes(ksize));\n    return ksize;\n  }\n\n  StatusOr<std::vector<int64_t>> GetStride(XlaOpKernelContext* ctx) {\n    std::vector<int64_t> stride;\n    if (ctx->num_inputs() == 1) {\n      stride = stride_;\n    } else {\n      const TensorShape stride_shape = ctx->InputShape(2);\n      // Validate input sizes.\n      if (!TensorShapeUtils::IsVector(stride_shape)) {\n        return errors::InvalidArgument(\"stride must be a vector, not shape \",\n                                       stride_shape.DebugString());\n      }\n      if (stride_shape.num_elements() != num_dims()) {\n        return errors::InvalidArgument(\n            \"Sliding window stride field must \"\n            \"specify \",\n            num_dims(), \" dimensions\");\n      }\n      auto status = ctx->ConstantInputAsIntVector(2, &stride);\n      if (!status.ok()) {\n        return status;\n      }\n    }\n    TF_RETURN_IF_ERROR(ValidateStrides(stride));\n    return stride;\n  }\n\n protected:\n  const int num_spatial_dims_;\n  std::vector<int64_t> ksize_;\n  std::vector<int64_t> stride_;\n  xla::Padding padding_;\n  TensorFormat data_format_ = FORMAT_NHWC;\n  DataType reduction_type_;\n  xla::PrimitiveType xla_reduction_type_;\n};\n\n// Converts the tensor data format to the one required by the XLA pooling\n// library.\nxla::TensorFormat XlaTensorFormat(tensorflow::TensorFormat data_format,\n                                  int num_spatial_dims) {\n  int num_dims = num_spatial_dims + 2;\n  int batch_dimension = GetTensorBatchDimIndex(num_dims, data_format);\n  int feature_dimension = GetTensorFeatureDimIndex(num_dims, data_format);\n  absl::InlinedVector<int64_t, 4> spatial_dimensions(num_spatial_dims);\n  for (int spatial_dim = 0; spatial_dim < num_spatial_dims; ++spatial_dim) {\n    spatial_dimensions[spatial_dim] =\n        GetTensorSpatialDimIndex(num_dims, data_format, spatial_dim);\n  }\n  return xla::TensorFormat(/*batch_dimension=*/batch_dimension,\n                           /*feature_dimension=*/feature_dimension,\n                           /*spatial_dimensions=*/spatial_dimensions);\n}\n\nclass MaxPoolOp : public PoolingOp {\n public:\n  MaxPoolOp(OpKernelConstruction* ctx, int num_spatial_dims)\n      : PoolingOp(ctx, /*num_spatial_dims=*/num_spatial_dims,\n                  /*reduction_type=*/ctx->input_type(0)) {\n    std::string data_format_str;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format_str));\n    OP_REQUIRES(ctx, FormatFromString(data_format_str, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n    OP_REQUIRES(ctx, data_format_ != FORMAT_NHWC_VECT_W,\n                errors::Unimplemented(\n                    \"XLA does not support the VECT_NHWC_VECT_W data format. \"\n                    \"Returning unimplemented from MaxPool to keep \"\n                    \"Tensorflow's intended optimized MaxPool here.\"));\n  }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    auto ksize_or_error = GetKernelSize(ctx);\n    OP_REQUIRES_OK(ctx, ksize_or_error.status());\n    std::vector<int64_t> ksize = ksize_or_error.value();\n\n    auto stride_or_error = GetStride(ctx);\n    OP_REQUIRES_OK(ctx, stride_or_error.status());\n    std::vector<int64_t> stride = stride_or_error.value();\n\n    xla::XlaOp input = ctx->Input(0);\n\n    StatusOr<xla::Shape> input_shape = ctx->builder()->GetShape(input);\n    OP_REQUIRES_OK(ctx, input_shape.status());\n\n    // For VECT_C max-pool ops, transpose to plain NCHW, do the max-pool, and\n    // transpose back.  This isn't necessarily the most efficient algorithm, but\n    // it's ok for starters.\n    std::optional<int64_t> vect_width;\n    if (data_format_ == FORMAT_NCHW_VECT_C) {\n      vect_width = input_shape->dimensions().back();\n      input = xla::Collapse(xla::Transpose(input, {0, 1, 4, 2, 3}), {1, 2});\n\n      input_shape = ctx->builder()->GetShape(input);\n      OP_REQUIRES_OK(ctx, input_shape.status());\n    }\n\n    OP_REQUIRES(ctx, input_shape->dimensions_size() == num_dims(),\n                errors::InvalidArgument(\"Input to \", type_string(),\n                                        \" operator must have \", num_dims(),\n                                        \" dimensions\"));\n    auto pooling = xla::MaxPool(\n        input, ksize, stride, padding_,\n        XlaTensorFormat(\n            data_format_ == FORMAT_NCHW_VECT_C ? FORMAT_NCHW : data_format_,\n            input_shape->dimensions_size() - 2));\n\n    if (data_format_ == FORMAT_NCHW_VECT_C) {\n      StatusOr<xla::Shape> result_shape = ctx->builder()->GetShape(pooling);\n      OP_REQUIRES_OK(ctx, result_shape.status());\n\n      int64 num_channels = result_shape->dimensions(1);\n      OP_REQUIRES(\n          ctx, num_channels % *vect_width == 0,\n          errors::FailedPrecondition(\"Result of NCHW_VECT_C op must have \"\n                                     \"channels multiple of \",\n                                     *vect_width, \", but was \", num_channels));\n\n      absl::InlinedVector<int64, 5> new_dims(result_shape->dimensions().begin(),\n                                             result_shape->dimensions().end());\n      new_dims[1] /= *vect_width;\n      new_dims.insert(new_dims.begin() + 2, *vect_width);\n      pooling =\n          xla::Transpose(xla::Reshape(pooling, new_dims), {0, 1, 3, 4, 2});\n    }\n\n    ctx->SetOutput(0, pooling);\n  }\n};\n\nclass MaxPool2DOp : public MaxPoolOp {\n public:\n  explicit MaxPool2DOp(OpKernelConstruction* ctx)\n      : MaxPoolOp(ctx, /*num_spatial_dims=*/2) {}\n};\nREGISTER_XLA_OP(Name(\"MaxPool\"), MaxPool2DOp);\nREGISTER_XLA_OP(Name(\"MaxPoolV2\")\n                    .CompileTimeConstantInput(\"ksize\")\n                    .CompileTimeConstantInput(\"strides\"),\n                MaxPool2DOp);\n\nclass MaxPool3DOp : public MaxPoolOp {\n public:\n  explicit MaxPool3DOp(OpKernelConstruction* ctx)\n      : MaxPoolOp(ctx, /*num_spatial_dims=*/3) {}\n};\nREGISTER_XLA_OP(Name(\"MaxPool3D\"), MaxPool3DOp);\n\nclass AvgPoolOp : public PoolingOp {\n public:\n  AvgPoolOp(OpKernelConstruction* ctx, int num_spatial_dims)\n      : PoolingOp(ctx, /*num_spatial_dims=*/num_spatial_dims,\n                  /*reduction_type=*/\n                  XlaHelpers::SumAccumulationType(ctx->input_type(0))) {\n    string data_format_str;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format_str));\n    OP_REQUIRES(ctx, FormatFromString(data_format_str, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n  }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    auto ksize_or_error = GetKernelSize(ctx);\n    OP_REQUIRES_OK(ctx, ksize_or_error.status());\n    std::vector<int64_t> ksize = ksize_or_error.value();\n\n    auto stride_or_error = GetStride(ctx);\n    OP_REQUIRES_OK(ctx, stride_or_error.status());\n    std::vector<int64_t> stride = stride_or_error.value();\n\n    const TensorShape input_shape = ctx->InputShape(0);\n    OP_REQUIRES(ctx, input_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"Input to \", type_string(),\n                                        \" operator must have \", num_dims(),\n                                        \" dimensions\"));\n\n    auto xla_data_format =\n        XlaTensorFormat(data_format_, input_shape.dims() - 2);\n    auto spatial_padding = MakeSpatialPadding(\n        input_shape.dim_sizes(), ksize, stride, padding_, xla_data_format);\n\n    // Convert the input to the reduction type.\n    auto converted_input =\n        ConvertElementType(ctx->Input(0), xla_reduction_type_);\n    auto pooling =\n        xla::AvgPool(converted_input, ksize, stride, spatial_padding,\n                     xla_data_format, padding_ == xla::Padding::kValid);\n    // Convert the pooling result back to the input type before returning it.\n    ctx->SetOutput(0, ConvertElementType(pooling, ctx->input_xla_type(0)));\n  }\n};\n\nclass AvgPool2DOp : public AvgPoolOp {\n public:\n  explicit AvgPool2DOp(OpKernelConstruction* ctx)\n      : AvgPoolOp(ctx, /*num_spatial_dims=*/2) {}\n};\nREGISTER_XLA_OP(Name(\"AvgPool\"), AvgPool2DOp);\n\nREGISTER_XLA_OP(Name(\"AvgPool3D\"), MlirXlaOpKernel);\n\n// The operation to compute MaxPool gradients.\n// It takes three inputs:\n//   - The original input tensor\n//   - The original output tensor\n//   - Backprop tensor for output\n// It produces one output: backprop tensor for input.\nclass MaxPoolGradOp : public XlaOpKernel {\n public:\n  MaxPoolGradOp(OpKernelConstruction* ctx, int num_spatial_dims)\n      : XlaOpKernel(ctx), num_spatial_dims_(num_spatial_dims) {\n    if (ctx->num_inputs() == 3) {\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"ksize\", &ksize_));\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"strides\", &stride_));\n    }\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(ctx, padding_ != EXPLICIT,\n                errors::Unimplemented(\n                    \"XLA does not support maxpoolgrad with explicit padding.\"));\n    // When determinism is enabled, the use of SelectAndScatter causes a generic\n    // error to be raised. We raise a more informative error here before\n    // SelectAndScatter is used.\n    OP_REQUIRES(\n        ctx, !tensorflow::OpDeterminismRequired(),\n        errors::Unimplemented(\"GPU MaxPool gradient ops do not yet have a \"\n                              \"deterministic XLA implementation.\"));\n  }\n\n  int num_dims() const { return num_spatial_dims_ + 2; }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    if (ctx->num_inputs() != 3) {\n      OP_REQUIRES(\n          ctx, ctx->num_inputs() == 5,\n          errors::InvalidArgument(\"Must supply ksize and stride arguments.\"));\n      const TensorShape ksize_shape = ctx->InputShape(3);\n      // Validate input sizes.\n      OP_REQUIRES(ctx, TensorShapeUtils::IsVector(ksize_shape),\n                  errors::InvalidArgument(\"ksize must be a vector, not shape \",\n                                          ksize_shape.DebugString()));\n      OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(3, &ksize_));\n\n      const TensorShape stride_shape = ctx->InputShape(4);\n      // Validate input sizes.\n      OP_REQUIRES(ctx, TensorShapeUtils::IsVector(stride_shape),\n                  errors::InvalidArgument(\"stride must be a vector, not shape \",\n                                          stride_shape.DebugString()));\n      OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(4, &stride_));\n    }\n\n    OP_REQUIRES(ctx, ksize_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n    OP_REQUIRES_OK(ctx, ValidateKernelSizes(ksize_));\n    OP_REQUIRES(ctx, stride_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window strides field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n    OP_REQUIRES_OK(ctx, ValidateStrides(stride_));\n\n    const TensorShape tensor_in_shape = ctx->InputShape(0);\n    const TensorShape tensor_out_shape = ctx->InputShape(1);\n    const TensorShape out_backprop_shape = ctx->InputShape(2);\n\n    // For maxpooling, tensor_in should have num_dims() dimensions.\n    OP_REQUIRES(ctx, tensor_in_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"tensor_in must be \", num_dims(),\n                                        \"-dimensional\"));\n    OP_REQUIRES(ctx, tensor_out_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"tensor_out must be \", num_dims(),\n                                        \"-dimensional\"));\n    // For maxpooling, out_backprop should have num_dims() dimensions.\n    OP_REQUIRES(ctx, out_backprop_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"out_backprop must be \", num_dims(),\n                                        \"-dimensional\"));\n\n    // TODO(phawkins): The XLA version doesn't need tensor_out. Investigate\n    // whether this is a good time/space tradeoff.\n    auto input = ctx->Input(0);\n    auto out_backprop = ctx->Input(2);\n    // We ensured padding_ is not EXPLICIT in the constructor.\n    xla::Padding xla_padding =\n        (padding_ == VALID) ? xla::Padding::kValid : xla::Padding::kSame;\n\n    // Create a MaxPool operation to check the expected resulting shape, and\n    // then throw away the operation because we don't actually need it here.\n    TensorShape expected_out_shape;\n    auto pooling =\n        xla::MaxPool(ctx->Input(0), ksize_, stride_, xla_padding,\n                     XlaTensorFormat(data_format_, tensor_in_shape.dims() - 2));\n    auto status_or_shape = pooling.builder()->GetShape(pooling);\n    OP_REQUIRES_OK(ctx, status_or_shape.status());\n    OP_REQUIRES_OK(ctx, XLAShapeToTensorShape(status_or_shape.value(),\n                                              &expected_out_shape));\n    OP_REQUIRES(ctx, expected_out_shape == out_backprop_shape,\n                errors::Unimplemented(\"The output dimensions do not match the \"\n                                      \"other input values.\"));\n\n    xla::PrimitiveType element_type;\n    OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(input_type(2), &element_type));\n    xla::XlaOp init_value = XlaHelpers::Zero(ctx->builder(), input_type(2));\n    auto select = CreateScalarGeComputation(element_type, ctx->builder());\n    auto scatter = CreateScalarAddComputation(element_type, ctx->builder());\n    xla::XlaOp gradients =\n        xla::SelectAndScatter(input, select, ksize_, stride_, xla_padding,\n                              out_backprop, init_value, scatter);\n\n    ctx->SetOutput(0, gradients);\n  }\n\n protected:\n  const int num_spatial_dims_;\n  std::vector<int64_t> ksize_;\n  std::vector<int64_t> stride_;\n  Padding padding_;\n  TensorFormat data_format_ = FORMAT_NHWC;\n};\n\nclass MaxPool2DGradOp : public MaxPoolGradOp {\n public:\n  explicit MaxPool2DGradOp(OpKernelConstruction* ctx)\n      : MaxPoolGradOp(ctx, /*num_spatial_dims=*/2) {\n    string data_format;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n  }\n};\nREGISTER_XLA_OP(Name(\"MaxPoolGrad\"), MaxPool2DGradOp);\nREGISTER_XLA_OP(Name(\"MaxPoolGradV2\")\n                    .CompileTimeConstantInput(\"ksize\")\n                    .CompileTimeConstantInput(\"strides\"),\n                MaxPool2DGradOp);\n\nREGISTER_XLA_OP(Name(\"MaxPool3DGrad\"), MlirXlaOpKernel);\n\n// Average-pooling gradient\nclass AvgPoolGradOp : public XlaOpKernel {\n public:\n  AvgPoolGradOp(OpKernelConstruction* ctx, int num_spatial_dims)\n      : XlaOpKernel(ctx), num_spatial_dims_(num_spatial_dims) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"ksize\", &ksize_));\n    OP_REQUIRES(ctx, ksize_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n    OP_REQUIRES_OK(ctx, ValidateKernelSizes(ksize_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"strides\", &stride_));\n    OP_REQUIRES(ctx, stride_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window strides field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n    OP_REQUIRES_OK(ctx, ValidateStrides(stride_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(ctx, padding_ != EXPLICIT,\n                errors::Unimplemented(\n                    \"XLA does not support avgpoolgrad with explicit padding.\"));\n    OP_REQUIRES(ctx, ksize_[0] == 1 && stride_[0] == 1,\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the batch dimension.\"));\n\n    string data_format;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n  }\n\n  int num_dims() const { return num_spatial_dims_ + 2; }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    TensorShape gradients_shape;\n    OP_REQUIRES_OK(\n        ctx, ctx->ConstantInputAsShape(0, &gradients_shape,\n                                       xla::ValueInferenceMode::kUpperBound));\n\n    const TensorShape out_backprop_shape = ctx->InputShape(1);\n\n    // For avgpooling, tensor_in_shape should have num_dims() dimensions.\n    OP_REQUIRES(ctx, gradients_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"orig_input_shape must be \", num_dims(),\n                                        \"-dimensional\"));\n\n    // For avgpooling, out_backprop should have num_dims() dimensions.\n    OP_REQUIRES(ctx, out_backprop_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"out_backprop must be \", num_dims(),\n                                        \"-dimensional\"));\n\n    auto out_backprop = ctx->Input(1);\n    std::vector<int64_t> stride_int64s(stride_.begin(), stride_.end());\n    xla::Padding xla_padding =\n        (padding_ == VALID) ? xla::Padding::kValid : xla::Padding::kSame;\n    xla::PrimitiveType xla_reduction_type;\n    auto reduction_type = XlaHelpers::SumAccumulationType(ctx->input_type(1));\n    OP_REQUIRES_OK(\n        ctx, DataTypeToPrimitiveType(reduction_type, &xla_reduction_type));\n    auto converted_out_backprop =\n        xla::ConvertElementType(out_backprop, xla_reduction_type);\n    auto xla_data_format =\n        XlaTensorFormat(data_format_, gradients_shape.dims() - 2);\n    auto padding_values =\n        MakeSpatialPadding(gradients_shape.dim_sizes(), ksize_, stride_int64s,\n                           xla_padding, xla_data_format);\n    auto in_backprop =\n        xla::AvgPoolGrad(converted_out_backprop, gradients_shape.dim_sizes(),\n                         ksize_, stride_int64s, padding_values, xla_data_format,\n                         /*counts_include_padding=*/padding_ == VALID);\n    // Convert the pooling result back to the input type before returning it.\n    xla::PrimitiveType xla_out_backprop_type;\n    OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(ctx->input_type(1),\n                                                &xla_out_backprop_type));\n    ctx->SetOutput(0,\n                   xla::ConvertElementType(in_backprop, xla_out_backprop_type));\n  }\n\n protected:\n  const int num_spatial_dims_;\n  std::vector<int64_t> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;\n  TensorFormat data_format_ = FORMAT_NHWC;\n};\n\nclass AvgPool2DGradOp : public AvgPoolGradOp {\n public:\n  explicit AvgPool2DGradOp(OpKernelConstruction* ctx)\n      : AvgPoolGradOp(ctx, /*num_spatial_dims=*/2) {}\n};\nREGISTER_XLA_OP(\n    Name(\"AvgPoolGrad\").CompileTimeConstantInput(\"orig_input_shape\"),\n    AvgPool2DGradOp);\n\nclass AvgPool3DGradOp : public AvgPoolGradOp {\n public:\n  explicit AvgPool3DGradOp(OpKernelConstruction* ctx)\n      : AvgPoolGradOp(ctx, /*num_spatial_dims=*/3) {}\n};\nREGISTER_XLA_OP(\n    Name(\"AvgPool3DGrad\").CompileTimeConstantInput(\"orig_input_shape\"),\n    AvgPool3DGradOp);\n\nclass MaxPoolGradGradOp : public XlaOpKernel {\n public:\n  MaxPoolGradGradOp(OpKernelConstruction* ctx, int num_spatial_dims)\n      : XlaOpKernel(ctx), num_spatial_dims_(num_spatial_dims) {\n    if (ctx->num_inputs() == 3) {\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"ksize\", &ksize_));\n      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"strides\", &stride_));\n    }\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(\n        ctx, padding_ != EXPLICIT,\n        errors::Unimplemented(\n            \"XLA does not support maxpoolgradgrad with explicit padding.\"));\n  }\n\n  int num_dims() const { return num_spatial_dims_ + 2; }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    if (ctx->num_inputs() != 3) {\n      OP_REQUIRES(\n          ctx, ctx->num_inputs() == 5,\n          errors::InvalidArgument(\"Must supply ksize and stride arguments.\"));\n      const TensorShape ksize_shape = ctx->InputShape(3);\n      // Validate input sizes.\n      OP_REQUIRES(ctx, TensorShapeUtils::IsVector(ksize_shape),\n                  errors::InvalidArgument(\"ksize must be a vector, not shape \",\n                                          ksize_shape.DebugString()));\n      OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(3, &ksize_));\n\n      const TensorShape stride_shape = ctx->InputShape(4);\n      // Validate input sizes.\n      OP_REQUIRES(ctx, TensorShapeUtils::IsVector(stride_shape),\n                  errors::InvalidArgument(\"stride must be a vector, not shape \",\n                                          stride_shape.DebugString()));\n      OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(4, &stride_));\n    }\n\n    OP_REQUIRES(ctx, ksize_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n    OP_REQUIRES_OK(ctx, ValidateKernelSizes(ksize_));\n    OP_REQUIRES(ctx, stride_.size() == num_dims(),\n                errors::InvalidArgument(\"Sliding window strides field must \"\n                                        \"specify \",\n                                        num_dims(), \" dimensions\"));\n    OP_REQUIRES_OK(ctx, ValidateStrides(stride_));\n\n    const TensorShape tensor_in_shape = ctx->InputShape(0);\n    const TensorShape tensor_out_shape = ctx->InputShape(1);\n    const TensorShape out_backprop_shape = ctx->InputShape(2);\n\n    // For maxpooling, tensor_in should have num_dims() dimensions.\n    OP_REQUIRES(ctx, tensor_in_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"tensor_in must be \", num_dims(),\n                                        \"-dimensional\"));\n    OP_REQUIRES(ctx, tensor_out_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"tensor_out must be \", num_dims(),\n                                        \"-dimensional\"));\n    // For maxpooling, out_backprop should have num_dims() dimensions.\n    OP_REQUIRES(ctx, out_backprop_shape.dims() == num_dims(),\n                errors::InvalidArgument(\"out_backprop must be \", num_dims(),\n                                        \"-dimensional\"));\n\n    // What we want to compute:\n    // Given y = MaxPool(x), and xs_grad = MaxPoolGrad(x, y, ys_grad)\n    // MaxPoolGradGrad computes {ys_grad}_grad given x, y, and {xs_grad}_grad.\n    //\n    // In the regular TF op, this amounts to selecting for each window the\n    // incoming backprop value from xs_grad_grad that corresponds to the maximal\n    // value in the corresponding window of x.\n    //\n    // TODO(b/73062247): What we really want is a ReduceWindow with different\n    // arrays for index selection vs return value selection--a select-to-gather.\n    //\n    // Here, we implement a bitwise hack: we use the hi 16 bits of input for\n    // separate max pooling alongside each of the hi and lo 16 bits of\n    // out_backprop packed into 16 lo bits, which we then glue back together at\n    // the end to get a full 32 bits of gradient.\n    //\n    // This could select the wrong backprop value for two x values that are\n    // equally maximal up to the first 16 bits, in which case we are taking the\n    // latter.\n    //\n    // Note that in principle we could use 32 separate maxpools to recover each\n    // of 32 bits of the gradient while preserving 31 bits of input for the max\n    // pooling criteria; here, we just truncate to the first 16 bits of input.\n\n    auto input = ctx->Input(0);\n    auto out_backprop = ctx->Input(2);\n\n    auto b = ctx->builder();\n\n    auto sixteen = xla::ConstantR0<uint32>(b, 16);\n    // in (f32) -> round to 7 mantissa bits (bf16)-> 16-high-bit u32.\n    //\n    // NOTE: Use a ReducePrecision operation instead of a cast to BF16 and back\n    // to F32 since the XLA compiler may ignore narrowing casts to floating\n    // point types if the debug option xla_allow_excess_precision is set.\n    auto in_hi = xla::BitcastConvertType(\n        xla::ReducePrecision(input, /*exponent_bits=*/8, /*mantissa_bits=*/7),\n        xla::U32);\n    auto bp_int = xla::BitcastConvertType(out_backprop, xla::U32);\n    auto bp_hi = xla::ShiftRightLogical(bp_int, sixteen);\n    auto bp_lo =\n        xla::ShiftRightLogical(xla::ShiftLeft(bp_int, sixteen), sixteen);\n    auto in_hi_bp_hi = xla::Add(in_hi, bp_hi);  // Want an unsigned add.\n    auto in_hi_bp_lo = xla::Add(in_hi, bp_lo);  // Want an unsigned add.\n\n    auto init_value = xla::MinValue(b, xla::F32);\n    // We will reduce by taking the maximal value up to 16 bits (ignoring the lo\n    // 16 bits of packed-in hi/lo backprop value).\n    auto rb = b->CreateSubBuilder(\"GreaterOrEqOf_ByFirst16Bits\");\n    {\n      // F32 parameters to satisfy lowering type restriction for reduce opcode.\n      const xla::Shape scalar = xla::ShapeUtil::MakeShape(xla::F32, {});\n      auto lhs = xla::Parameter(rb.get(), 0, scalar, \"lhs\");\n      auto rhs = xla::Parameter(rb.get(), 1, scalar, \"rhs\");\n      auto sixteen = xla::ConstantR0<int32>(rb.get(), 16);\n      auto lhs_criteria =\n          xla::ShiftLeft(xla::ShiftRightLogical(\n                             xla::BitcastConvertType(lhs, xla::S32), sixteen),\n                         sixteen);\n      auto rhs_criteria =\n          xla::ShiftLeft(xla::ShiftRightLogical(\n                             xla::BitcastConvertType(rhs, xla::S32), sixteen),\n                         sixteen);\n      // Must use a F32 comparison, because S32 would not work for negatives.\n      xla::Select(xla::Ge(xla::BitcastConvertType(lhs_criteria, xla::F32),\n                          xla::BitcastConvertType(rhs_criteria, xla::F32)),\n                  lhs, rhs);\n    }\n    auto reduce = rb->BuildAndNoteError();\n    xla::Padding xla_padding =\n        (padding_ == VALID) ? xla::Padding::kValid : xla::Padding::kSame;\n    auto pooled_hi =\n        xla::ReduceWindow(xla::BitcastConvertType(in_hi_bp_hi, xla::F32),\n                          init_value, reduce, ksize_, stride_, xla_padding);\n    auto pooled_lo =\n        xla::ReduceWindow(xla::BitcastConvertType(in_hi_bp_lo, xla::F32),\n                          init_value, reduce, ksize_, stride_, xla_padding);\n    auto grads_hi =\n        xla::ShiftLeft(xla::BitcastConvertType(pooled_hi, xla::U32), sixteen);\n    auto grads_lo = xla::ShiftRightLogical(\n        xla::ShiftLeft(xla::BitcastConvertType(pooled_lo, xla::U32), sixteen),\n        sixteen);\n    auto grads = xla::Add(grads_hi, grads_lo);  // Want an unsigned add.\n\n    xla::PrimitiveType element_type;\n    OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(input_type(2), &element_type));\n    ctx->SetOutput(0, xla::BitcastConvertType(grads, element_type));\n  }\n\n protected:\n  const int num_spatial_dims_;\n  std::vector<int64_t> ksize_;\n  std::vector<int64_t> stride_;\n  Padding padding_;\n  TensorFormat data_format_ = FORMAT_NHWC;\n};\n\nclass MaxPool2DGradGradOp : public MaxPoolGradGradOp {\n public:\n  explicit MaxPool2DGradGradOp(OpKernelConstruction* ctx)\n      : MaxPoolGradGradOp(ctx, /*num_spatial_dims=*/2) {\n    string data_format;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n  }\n};\nREGISTER_XLA_OP(Name(\"MaxPoolGradGrad\").TypeConstraint(\"T\", DT_FLOAT),\n                MaxPool2DGradGradOp);\nREGISTER_XLA_OP(Name(\"MaxPoolGradGradV2\")\n                    .TypeConstraint(\"T\", DT_FLOAT)\n                    .CompileTimeConstantInput(\"ksize\")\n                    .CompileTimeConstantInput(\"strides\"),\n                MaxPool2DGradGradOp);\n\nclass MaxPool3DGradGradOp : public MaxPoolGradGradOp {\n public:\n  explicit MaxPool3DGradGradOp(OpKernelConstruction* ctx)\n      : MaxPoolGradGradOp(ctx, /*num_spatial_dims=*/3) {\n    string data_format;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n  }\n};\nREGISTER_XLA_OP(Name(\"MaxPool3DGradGrad\").TypeConstraint(\"T\", DT_FLOAT),\n                MaxPool3DGradGradOp);\n\n}  // anonymous namespace\n}  // namespace tensorflow\n", "/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/compiler/xla/client/padding.h\"\n\n#include <algorithm>\n\n#include \"tensorflow/compiler/xla/util.h\"\n#include \"tensorflow/tsl/lib/math/math_util.h\"\n#include \"tensorflow/tsl/platform/logging.h\"\n\nnamespace xla {\n\nStatus ValidatePaddingValues(absl::Span<const int64_t> input_dimensions,\n                             absl::Span<const int64_t> window_dimensions,\n                             absl::Span<const int64_t> window_strides) {\n  bool ok = input_dimensions.size() == window_dimensions.size() &&\n            input_dimensions.size() == window_strides.size();\n  if (!ok) {\n    return InvalidArgument(\n        \"Want input dimensions size %u = window dimensions size %u = window \"\n        \"strides size %u\",\n        input_dimensions.size(), window_dimensions.size(),\n        window_strides.size());\n  }\n  for (size_t i = 0; i < input_dimensions.size(); ++i) {\n    if (window_dimensions[i] <= 0) {\n      return InvalidArgument(\"Window dimension %u has non-positive size %d\", i,\n                             window_dimensions[i]);\n    }\n    if (window_strides[i] <= 0) {\n      return InvalidArgument(\"Window dimension %u has non-positive stride %d\",\n                             i, window_strides[i]);\n    }\n  }\n  return OkStatus();\n}\n\nstd::vector<std::pair<int64_t, int64_t>> MakePadding(\n    absl::Span<const int64_t> input_dimensions,\n    absl::Span<const int64_t> window_dimensions,\n    absl::Span<const int64_t> window_strides, Padding padding) {\n  TF_CHECK_OK(ValidatePaddingValues(input_dimensions, window_dimensions,\n                                    window_strides));\n  std::vector<std::pair<int64_t, int64_t>> low_high_padding;\n  switch (padding) {\n    case Padding::kValid:\n      low_high_padding.resize(window_dimensions.size(), {0, 0});\n      return low_high_padding;\n\n    case Padding::kSame:\n      for (size_t i = 0; i < input_dimensions.size(); ++i) {\n        int64_t input_dimension = input_dimensions[i];\n        int64_t window_dimension = window_dimensions[i];\n        int64_t window_stride = window_strides[i];\n        // We follow the same convention as in Tensorflow, such that\n        // output dimension := ceil(input_dimension / window_stride).\n        // See tensorflow/tensorflow/python/ops/nn.py\n        // for the reference. See also tensorflow/core/kernels/ops_util.cc\n        // for the part where we avoid negative padding using max(0, x).\n        //\n        //\n        // For an odd sized window dimension 2N+1 with stride 1, the middle\n        // element is always inside the base area, so we can see it as N + 1 +\n        // N elements. In the example below, we have a kernel of size\n        // 2*3+1=7 so that the center element is 4 with 123 to the\n        // left and 567 to the right.\n        //\n        //  base area:           ------------------------\n        //  kernel at left:   1234567\n        //  kernel at right:                         1234567\n        //\n        // We can see visually here that we need to pad the base area\n        // by 3 on each side:\n        //\n        //  padded base area: 000------------------------000\n        //\n        // For an even number 2N, there are two options:\n        //\n        // *** Option A\n        //\n        // We view 2N as (N - 1) + 1 + N, so for N=3 we have 12 to the\n        // left, 3 is the center and 456 is to the right, like this:\n        //\n        //  base area:           ------------------------\n        //  kernel at left:    123456\n        //  kernel at right:                          123456\n        //  padded base area:  00------------------------000\n        //\n        // Note how we pad by one more to the right than to the left.\n        //\n        // *** Option B\n        //\n        // We view 2N as N + 1 + (N - 1), so for N=3 we have 123 to\n        // the left, 4 is the center and 56 is to the right, like\n        // this:\n        //\n        //  base area:           ------------------------\n        //  kernel at left:   123456\n        //  kernel at right:                         123456\n        //  padded base area: 000------------------------00\n        //\n        // The choice here is arbitrary. We choose option A as this is\n        // what DistBelief and Tensorflow do.\n        //\n        // When the stride is greater than 1, the output size is smaller than\n        // the input base size. The base area is padded such that the last\n        // window fully fits in the padded base area, and the padding amount is\n        // evenly divided between the left and the right (or 1 more on the right\n        // if odd size padding is required). The example below shows the\n        // required padding when the base size is 10, the kernel size is 5, and\n        // the stride is 3. In this example, the output size is 4.\n        //\n        // base area:           ----------\n        // 1'st kernel:       12345\n        // 2'nd kernel:          12345\n        // 3'rd kernel:             12345\n        // 4'th kernel:                12345\n        // padded base area:  00----------00\n        int64_t output_dimension =\n            tsl::MathUtil::CeilOfRatio(input_dimension, window_stride);\n        int64_t padding_size =\n            std::max<int64_t>((output_dimension - 1) * window_stride +\n                                  window_dimension - input_dimension,\n                              0);\n        low_high_padding.emplace_back(\n            tsl::MathUtil::FloorOfRatio(padding_size, int64_t{2}),\n            tsl::MathUtil::CeilOfRatio(padding_size, int64_t{2}));\n      }\n      break;\n  }\n\n  return low_high_padding;\n}\n\n}  // namespace xla\n"], "filenames": ["tensorflow/compiler/tests/pooling_ops_test.py", "tensorflow/compiler/tf2xla/kernels/pooling_ops.cc", "tensorflow/compiler/xla/client/padding.cc"], "buggy_code_start_loc": [20, 35, 36], "buggy_code_end_loc": [562, 585, 36], "fixing_code_start_loc": [21, 36, 37], "fixing_code_end_loc": [593, 622, 47], "type": "CWE-697", "message": "TensorFlow is an open source platform for machine learning. Prior to versions 2.12.0 and 2.11.1, if the stride and window size are not positive for `tf.raw_ops.AvgPoolGrad`, it can give a floating point exception. A fix is included in TensorFlow version 2.12.0 and version 2.11.1.", "other": {"cve": {"id": "CVE-2023-25669", "sourceIdentifier": "security-advisories@github.com", "published": "2023-03-25T00:15:07.653", "lastModified": "2023-03-30T17:44:45.267", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. Prior to versions 2.12.0 and 2.11.1, if the stride and window size are not positive for `tf.raw_ops.AvgPoolGrad`, it can give a floating point exception. A fix is included in TensorFlow version 2.12.0 and version 2.11.1."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-697"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.12.0", "matchCriteriaId": "FAC3DE54-93B4-4D6C-9648-B9D416B9770F"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/1295ae4dbb52fe06b19733b0257e2340d7b63b8d", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rcf8-g8jv-vg6p", "source": "security-advisories@github.com", "tags": ["Patch", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/1295ae4dbb52fe06b19733b0257e2340d7b63b8d"}}
{"buggy_code": ["// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_AUTHTYPES_H\n#define CEPH_AUTHTYPES_H\n\n#include \"Crypto.h\"\n#include \"common/entity_name.h\"\n\nclass Cond;\n\nstruct EntityAuth {\n  uint64_t auid;\n  CryptoKey key;\n  map<string, bufferlist> caps;\n\n  EntityAuth() : auid(CEPH_AUTH_UID_DEFAULT) {}\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 2;\n    ::encode(struct_v, bl);\n    ::encode(auid, bl);\n    ::encode(key, bl);\n    ::encode(caps, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    if (struct_v >= 2)\n      ::decode(auid, bl);\n    else auid = CEPH_AUTH_UID_DEFAULT;\n    ::decode(key, bl);\n    ::decode(caps, bl);\n  }\n};\nWRITE_CLASS_ENCODER(EntityAuth)\n\nstatic inline ostream& operator<<(ostream& out, const EntityAuth& a) {\n  return out << \"auth(auid = \" << a.auid << \" key=\" << a.key << \" with \" << a.caps.size() << \" caps)\";\n}\n\nstruct AuthCapsInfo {\n  bool allow_all;\n  bufferlist caps;\n\n  AuthCapsInfo() : allow_all(false) {}\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    __u8 a = (__u8)allow_all;\n    ::encode(a, bl);\n    ::encode(caps, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    __u8 a;\n    ::decode(a, bl);\n    allow_all = (bool)a;\n    ::decode(caps, bl);\n  }\n};\nWRITE_CLASS_ENCODER(AuthCapsInfo)\n\n/*\n * The ticket (if properly validated) authorizes the principal use\n * services as described by 'caps' during the specified validity\n * period.\n */\nstruct AuthTicket {\n  EntityName name;\n  uint64_t global_id; /* global instance id */\n  uint64_t auid;\n  utime_t created, renew_after, expires;\n  AuthCapsInfo caps;\n  __u32 flags;\n\n  AuthTicket() : global_id(0), auid(CEPH_AUTH_UID_DEFAULT), flags(0){}\n\n  void init_timestamps(utime_t now, double ttl) {\n    created = now;\n    expires = now;\n    expires += ttl;\n    renew_after = now;\n    renew_after += ttl / 2.0;\n  }\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 2;\n    ::encode(struct_v, bl);\n    ::encode(name, bl);\n    ::encode(global_id, bl);\n    ::encode(auid, bl);\n    ::encode(created, bl);\n    ::encode(expires, bl);\n    ::encode(caps, bl);\n    ::encode(flags, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(name, bl);\n    ::decode(global_id, bl);\n    if (struct_v >= 2)\n      ::decode(auid, bl);\n    else auid = CEPH_AUTH_UID_DEFAULT;\n    ::decode(created, bl);\n    ::decode(expires, bl);\n    ::decode(caps, bl);\n    ::decode(flags, bl);\n  }\n};\nWRITE_CLASS_ENCODER(AuthTicket)\n\n\n/*\n * abstract authorizer class\n */\nstruct AuthAuthorizer {\n  __u32 protocol;\n  bufferlist bl;\n  CryptoKey session_key;\n\n  explicit AuthAuthorizer(__u32 p) : protocol(p) {}\n  virtual ~AuthAuthorizer() {}\n  virtual bool verify_reply(bufferlist::iterator& reply) = 0;\n};\n\n\n/*\n * Key management\n */ \n#define KEY_ROTATE_NUM 3   /* prev, current, next */\n\nstruct ExpiringCryptoKey {\n  CryptoKey key;\n  utime_t expiration;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(key, bl);\n    ::encode(expiration, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(key, bl);\n    ::decode(expiration, bl);\n  }\n};\nWRITE_CLASS_ENCODER(ExpiringCryptoKey)\n\nstatic inline ostream& operator<<(ostream& out, const ExpiringCryptoKey& c)\n{\n  return out << c.key << \" expires \" << c.expiration;\n}\n\nstruct RotatingSecrets {\n  map<uint64_t, ExpiringCryptoKey> secrets;\n  version_t max_ver;\n  \n  RotatingSecrets() : max_ver(0) {}\n  \n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(secrets, bl);\n    ::encode(max_ver, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(secrets, bl);\n    ::decode(max_ver, bl);\n  }\n  \n  uint64_t add(ExpiringCryptoKey& key) {\n    secrets[++max_ver] = key;\n    while (secrets.size() > KEY_ROTATE_NUM)\n      secrets.erase(secrets.begin());\n    return max_ver;\n  }\n  \n  bool need_new_secrets() const {\n    return secrets.size() < KEY_ROTATE_NUM;\n  }\n  bool need_new_secrets(utime_t now) const {\n    return secrets.size() < KEY_ROTATE_NUM || current().expiration <= now;\n  }\n\n  ExpiringCryptoKey& previous() {\n    return secrets.begin()->second;\n  }\n  ExpiringCryptoKey& current() {\n    map<uint64_t, ExpiringCryptoKey>::iterator p = secrets.begin();\n    ++p;\n    return p->second;\n  }\n  const ExpiringCryptoKey& current() const {\n    map<uint64_t, ExpiringCryptoKey>::const_iterator p = secrets.begin();\n    ++p;\n    return p->second;\n  }\n  ExpiringCryptoKey& next() {\n    return secrets.rbegin()->second;\n  }\n  bool empty() {\n    return secrets.empty();\n  }\n\n  void dump();\n};\nWRITE_CLASS_ENCODER(RotatingSecrets)\n\n\n\nclass KeyStore {\npublic:\n  virtual ~KeyStore() {}\n  virtual bool get_secret(const EntityName& name, CryptoKey& secret) const = 0;\n  virtual bool get_service_secret(uint32_t service_id, uint64_t secret_id,\n\t\t\t\t  CryptoKey& secret) const = 0;\n};\n\nstatic inline bool auth_principal_needs_rotating_keys(EntityName& name)\n{\n  uint32_t ty(name.get_type());\n  return ((ty == CEPH_ENTITY_TYPE_OSD)\n      || (ty == CEPH_ENTITY_TYPE_MDS)\n      || (ty == CEPH_ENTITY_TYPE_MGR));\n}\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_AUTHAUTHORIZEHANDLER_H\n#define CEPH_AUTHAUTHORIZEHANDLER_H\n\n#include \"Auth.h\"\n#include \"AuthMethodList.h\"\n#include \"include/types.h\"\n#include \"common/Mutex.h\"\n// Different classes of session crypto handling\n\n#define SESSION_CRYPTO_NONE 0\n#define SESSION_SYMMETRIC_AUTHENTICATE 1\n#define SESSION_SYMMETRIC_ENCRYPT 2\n\nclass CephContext;\nclass KeyRing;\nclass RotatingKeyRing;\n\nstruct AuthAuthorizeHandler {\n  virtual ~AuthAuthorizeHandler() {}\n  virtual bool verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t\t bufferlist& authorizer_data, bufferlist& authorizer_reply,\n                                 EntityName& entity_name, uint64_t& global_id,\n\t\t\t\t AuthCapsInfo& caps_info, CryptoKey& session_key, uint64_t *auid = NULL) = 0;\n  virtual int authorizer_session_crypto() = 0;\n};\n\nclass AuthAuthorizeHandlerRegistry {\n  Mutex m_lock;\n  map<int,AuthAuthorizeHandler*> m_authorizers;\n  AuthMethodList supported;\n\npublic:\n  AuthAuthorizeHandlerRegistry(CephContext *cct_, std::string methods)\n    : m_lock(\"AuthAuthorizeHandlerRegistry::m_lock\"), supported(cct_, methods)\n  {}\n  ~AuthAuthorizeHandlerRegistry();\n  \n  AuthAuthorizeHandler *get_handler(int protocol);\n};\n\n#endif\n", "#include \"CephxProtocol.h\"\n#include \"CephxAuthorizeHandler.h\"\n#include \"common/dout.h\"\n\n#define dout_subsys ceph_subsys_auth\n\n\n\nbool CephxAuthorizeHandler::verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t\t\t      bufferlist& authorizer_data, bufferlist& authorizer_reply,\n                                              EntityName& entity_name, uint64_t& global_id, AuthCapsInfo& caps_info, CryptoKey& session_key,  uint64_t *auid)\n{\n  bufferlist::iterator iter = authorizer_data.begin();\n\n  if (!authorizer_data.length()) {\n    ldout(cct, 1) << \"verify authorizer, authorizer_data.length()=0\" << dendl;\n    return false;\n  }\n\n  CephXServiceTicketInfo auth_ticket_info;\n\n  bool isvalid = cephx_verify_authorizer(cct, keys, iter, auth_ticket_info, authorizer_reply);\n\n  if (isvalid) {\n    caps_info = auth_ticket_info.ticket.caps;\n    entity_name = auth_ticket_info.ticket.name;\n    global_id = auth_ticket_info.ticket.global_id;\n    session_key = auth_ticket_info.session_key;\n    if (auid) *auid = auth_ticket_info.ticket.auid;\n  }\n\n  return isvalid;\n}\n\n// Return type of crypto used for this session's data;  for cephx, symmetric authentication\n\nint CephxAuthorizeHandler::authorizer_session_crypto() \n{\n  return SESSION_SYMMETRIC_AUTHENTICATE;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_CEPHXAUTHORIZEHANDLER_H\n#define CEPH_CEPHXAUTHORIZEHANDLER_H\n\n#include \"auth/AuthAuthorizeHandler.h\"\n\nclass CephContext;\n\nstruct CephxAuthorizeHandler : public AuthAuthorizeHandler {\n  bool verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t bufferlist& authorizer_data, bufferlist& authorizer_reply,\n                         EntityName& entity_name, uint64_t& global_id,\n\t\t\t AuthCapsInfo& caps_info, CryptoKey& session_key, uint64_t *auid = NULL) override;\n  int authorizer_session_crypto() override;\n};\n\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2009-2011 New Dream Network\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include \"CephxProtocol.h\"\n#include \"common/Clock.h\"\n#include \"common/config.h\"\n#include \"common/debug.h\"\n#include \"include/buffer.h\"\n\n#define dout_subsys ceph_subsys_auth\n#undef dout_prefix\n#define dout_prefix *_dout << \"cephx: \"\n\n\n\nvoid cephx_calc_client_server_challenge(CephContext *cct, CryptoKey& secret, uint64_t server_challenge, \n\t\t  uint64_t client_challenge, uint64_t *key, std::string &error)\n{\n  CephXChallengeBlob b;\n  b.server_challenge = server_challenge;\n  b.client_challenge = client_challenge;\n\n  bufferlist enc;\n  if (encode_encrypt(cct, b, secret, enc, error))\n    return;\n\n  uint64_t k = 0;\n  const uint64_t *p = (const uint64_t *)enc.c_str();\n  for (int pos = 0; pos + sizeof(k) <= enc.length(); pos+=sizeof(k), p++)\n    k ^= mswab(*p);\n  *key = k;\n}\n\n\n/*\n * Authentication\n */\n\nbool cephx_build_service_ticket_blob(CephContext *cct, CephXSessionAuthInfo& info,\n\t\t\t\t     CephXTicketBlob& blob)\n{\n  CephXServiceTicketInfo ticket_info;\n  ticket_info.session_key = info.session_key;\n  ticket_info.ticket = info.ticket;\n  ticket_info.ticket.caps = info.ticket.caps;\n\n  ldout(cct, 10) << \"build_service_ticket service \" << ceph_entity_type_name(info.service_id)\n\t   << \" secret_id \" << info.secret_id\n\t   << \" ticket_info.ticket.name=\" << ticket_info.ticket.name.to_str() << dendl;\n  blob.secret_id = info.secret_id;\n  std::string error;\n  if (!info.service_secret.get_secret().length())\n    error = \"invalid key\";  // Bad key?\n  else\n    encode_encrypt_enc_bl(cct, ticket_info, info.service_secret, blob.blob, error);\n  if (!error.empty()) {\n    ldout(cct, -1) << \"cephx_build_service_ticket_blob failed with error \"\n\t  << error << dendl;\n    return false;\n  }\n  return true;\n}\n\n/*\n * AUTH SERVER: authenticate\n *\n * Authenticate principal, respond with AuthServiceTicketInfo\n *\n * {session key, validity}^principal_secret\n * {principal_ticket, session key}^service_secret  ... \"enc_ticket\"\n */\nbool cephx_build_service_ticket_reply(CephContext *cct,\n                     CryptoKey& principal_secret,\n                     vector<CephXSessionAuthInfo> ticket_info_vec,\n                     bool should_encrypt_ticket,\n                     CryptoKey& ticket_enc_key,\n                     bufferlist& reply)\n{\n  __u8 service_ticket_reply_v = 1;\n  ::encode(service_ticket_reply_v, reply);\n\n  uint32_t num = ticket_info_vec.size();\n  ::encode(num, reply);\n  ldout(cct, 10) << \"build_service_ticket_reply encoding \" << num\n\t   << \" tickets with secret \" << principal_secret << dendl;\n\n  for (vector<CephXSessionAuthInfo>::iterator ticket_iter = ticket_info_vec.begin(); \n       ticket_iter != ticket_info_vec.end();\n       ++ticket_iter) {\n    CephXSessionAuthInfo& info = *ticket_iter;\n    ::encode(info.service_id, reply);\n\n    __u8 service_ticket_v = 1;\n    ::encode(service_ticket_v, reply);\n\n    CephXServiceTicket msg_a;\n    msg_a.session_key = info.session_key;\n    msg_a.validity = info.validity;\n    std::string error;\n    if (encode_encrypt(cct, msg_a, principal_secret, reply, error)) {\n      ldout(cct, -1) << \"error encoding encrypted: \" << error << dendl;\n      return false;\n    }\n\n    bufferlist service_ticket_bl;\n    CephXTicketBlob blob;\n    if (!cephx_build_service_ticket_blob(cct, info, blob)) {\n      return false;\n    }\n    ::encode(blob, service_ticket_bl);\n\n    ldout(cct, 30) << \"service_ticket_blob is \";\n    service_ticket_bl.hexdump(*_dout);\n    *_dout << dendl;\n\n    ::encode((__u8)should_encrypt_ticket, reply);\n    if (should_encrypt_ticket) {\n      if (encode_encrypt(cct, service_ticket_bl, ticket_enc_key, reply, error)) {\n\tldout(cct, -1) << \"error encoding encrypted ticket: \" << error << dendl;\n        return false;\n      }\n    } else {\n      ::encode(service_ticket_bl, reply);\n    }\n  }\n  return true;\n}\n\n/*\n * PRINCIPAL: verify our attempt to authenticate succeeded.  fill out\n * this ServiceTicket with the result.\n */\nbool CephXTicketHandler::verify_service_ticket_reply(CryptoKey& secret,\n\t\t\t\t\t\t     bufferlist::iterator& indata)\n{\n  __u8 service_ticket_v;\n  ::decode(service_ticket_v, indata);\n\n  CephXServiceTicket msg_a;\n  std::string error;\n  if (decode_decrypt(cct, msg_a, secret, indata, error)) {\n    ldout(cct, 0) << \"verify_service_ticket_reply: failed decode_decrypt, error is: \" << error << dendl;\n    return false;\n  }\n  \n  __u8 ticket_enc;\n  ::decode(ticket_enc, indata);\n\n  bufferlist service_ticket_bl;\n  if (ticket_enc) {\n    ldout(cct, 10) << \" got encrypted ticket\" << dendl;\n    std::string error;\n    if (decode_decrypt(cct, service_ticket_bl, session_key, indata, error)) {\n      ldout(cct, 10) << \"verify_service_ticket_reply: decode_decrypt failed \"\n\t    << \"with \" << error << dendl;\n      return false;\n    }\n  } else {\n    ::decode(service_ticket_bl, indata);\n  }\n  bufferlist::iterator iter = service_ticket_bl.begin();\n  ::decode(ticket, iter);\n  ldout(cct, 10) << \" ticket.secret_id=\" <<  ticket.secret_id << dendl;\n\n  ldout(cct, 10) << \"verify_service_ticket_reply service \" << ceph_entity_type_name(service_id)\n\t   << \" secret_id \" << ticket.secret_id\n\t   << \" session_key \" << msg_a.session_key\n           << \" validity=\" << msg_a.validity << dendl;\n  session_key = msg_a.session_key;\n  if (!msg_a.validity.is_zero()) {\n    expires = ceph_clock_now();\n    expires += msg_a.validity;\n    renew_after = expires;\n    renew_after -= ((double)msg_a.validity.sec() / 4);\n    ldout(cct, 10) << \"ticket expires=\" << expires << \" renew_after=\" << renew_after << dendl;\n  }\n  \n  have_key_flag = true;\n  return true;\n}\n\nbool CephXTicketHandler::have_key()\n{\n  if (have_key_flag) {\n    have_key_flag = ceph_clock_now() < expires;\n  }\n\n  return have_key_flag;\n}\n\nbool CephXTicketHandler::need_key() const\n{\n  if (have_key_flag) {\n    return (!expires.is_zero()) && (ceph_clock_now() >= renew_after);\n  }\n\n  return true;\n}\n\nbool CephXTicketManager::have_key(uint32_t service_id)\n{\n  map<uint32_t, CephXTicketHandler>::iterator iter = tickets_map.find(service_id);\n  if (iter == tickets_map.end())\n    return false;\n  return iter->second.have_key();\n}\n\nbool CephXTicketManager::need_key(uint32_t service_id) const\n{\n  map<uint32_t, CephXTicketHandler>::const_iterator iter = tickets_map.find(service_id);\n  if (iter == tickets_map.end())\n    return true;\n  return iter->second.need_key();\n}\n\nvoid CephXTicketManager::set_have_need_key(uint32_t service_id, uint32_t& have, uint32_t& need)\n{\n  map<uint32_t, CephXTicketHandler>::iterator iter = tickets_map.find(service_id);\n  if (iter == tickets_map.end()) {\n    have &= ~service_id;\n    need |= service_id;\n    ldout(cct, 10) << \"set_have_need_key no handler for service \"\n\t\t   << ceph_entity_type_name(service_id) << dendl;\n    return;\n  }\n\n  //ldout(cct, 10) << \"set_have_need_key service \" << ceph_entity_type_name(service_id)\n  //<< \" (\" << service_id << \")\"\n  //<< \" need=\" << iter->second.need_key() << \" have=\" << iter->second.have_key() << dendl;\n  if (iter->second.need_key())\n    need |= service_id;\n  else\n    need &= ~service_id;\n\n  if (iter->second.have_key())\n    have |= service_id;\n  else\n    have &= ~service_id;\n}\n\nvoid CephXTicketManager::invalidate_ticket(uint32_t service_id)\n{\n  map<uint32_t, CephXTicketHandler>::iterator iter = tickets_map.find(service_id);\n  if (iter != tickets_map.end())\n    iter->second.invalidate_ticket();\n}\n\n/*\n * PRINCIPAL: verify our attempt to authenticate succeeded.  fill out\n * this ServiceTicket with the result.\n */\nbool CephXTicketManager::verify_service_ticket_reply(CryptoKey& secret,\n\t\t\t\t\t\t     bufferlist::iterator& indata)\n{\n  __u8 service_ticket_reply_v;\n  ::decode(service_ticket_reply_v, indata);\n\n  uint32_t num;\n  ::decode(num, indata);\n  ldout(cct, 10) << \"verify_service_ticket_reply got \" << num << \" keys\" << dendl;\n\n  for (int i=0; i<(int)num; i++) {\n    uint32_t type;\n    ::decode(type, indata);\n    ldout(cct, 10) << \"got key for service_id \" << ceph_entity_type_name(type) << dendl;\n    CephXTicketHandler& handler = get_handler(type);\n    if (!handler.verify_service_ticket_reply(secret, indata)) {\n      return false;\n    }\n    handler.service_id = type;\n  }\n\n  if (!indata.end())\n    return false;\n\n  return true;\n}\n\n/*\n * PRINCIPAL: build authorizer to access the service.\n *\n * ticket, {timestamp}^session_key\n */\nCephXAuthorizer *CephXTicketHandler::build_authorizer(uint64_t global_id) const\n{\n  CephXAuthorizer *a = new CephXAuthorizer(cct);\n  a->session_key = session_key;\n  a->nonce = ((uint64_t)rand() << 32) + rand();\n\n  __u8 authorizer_v = 1;\n  ::encode(authorizer_v, a->bl);\n  ::encode(global_id, a->bl);\n  ::encode(service_id, a->bl);\n\n  ::encode(ticket, a->bl);\n\n  CephXAuthorize msg;\n  msg.nonce = a->nonce;\n\n  std::string error;\n  if (encode_encrypt(cct, msg, session_key, a->bl, error)) {\n    ldout(cct, 0) << \"failed to encrypt authorizer: \" << error << dendl;\n    delete a;\n    return 0;\n  }\n  return a;\n}\n\n/*\n * PRINCIPAL: build authorizer to access the service.\n *\n * ticket, {timestamp}^session_key\n */\nCephXAuthorizer *CephXTicketManager::build_authorizer(uint32_t service_id) const\n{\n  map<uint32_t, CephXTicketHandler>::const_iterator iter = tickets_map.find(service_id);\n  if (iter == tickets_map.end()) {\n    ldout(cct, 0) << \"no TicketHandler for service \"\n\t\t  << ceph_entity_type_name(service_id) << dendl;\n    return NULL;\n  }\n\n  const CephXTicketHandler& handler = iter->second;\n  return handler.build_authorizer(global_id);\n}\n\nvoid CephXTicketManager::validate_tickets(uint32_t mask, uint32_t& have, uint32_t& need)\n{\n  uint32_t i;\n  need = 0;\n  for (i = 1; i<=mask; i<<=1) {\n    if (mask & i) {\n      set_have_need_key(i, have, need);\n    }\n  }\n  ldout(cct, 10) << \"validate_tickets want \" << mask << \" have \" << have\n\t\t << \" need \" << need << dendl;\n}\n\nbool cephx_decode_ticket(CephContext *cct, KeyStore *keys, uint32_t service_id,\n\t      CephXTicketBlob& ticket_blob, CephXServiceTicketInfo& ticket_info)\n{\n  uint64_t secret_id = ticket_blob.secret_id;\n  CryptoKey service_secret;\n\n  if (!ticket_blob.blob.length()) {\n    return false;\n  }\n\n  if (secret_id == (uint64_t)-1) {\n    if (!keys->get_secret(cct->_conf->name, service_secret)) {\n      ldout(cct, 0) << \"ceph_decode_ticket could not get general service secret for service_id=\"\n\t      << ceph_entity_type_name(service_id) << \" secret_id=\" << secret_id << dendl;\n      return false;\n    }\n  } else {\n    if (!keys->get_service_secret(service_id, secret_id, service_secret)) {\n      ldout(cct, 0) << \"ceph_decode_ticket could not get service secret for service_id=\" \n\t      << ceph_entity_type_name(service_id) << \" secret_id=\" << secret_id << dendl;\n      return false;\n    }\n  }\n\n  std::string error;\n  decode_decrypt_enc_bl(cct, ticket_info, service_secret, ticket_blob.blob, error);\n  if (!error.empty()) {\n    ldout(cct, 0) << \"ceph_decode_ticket could not decrypt ticket info. error:\" \n\t<< error << dendl;\n    return false;\n  }\n\n  return true;\n}\n\n/*\n * SERVICE: verify authorizer and generate reply authorizer\n *\n * {timestamp + 1}^session_key\n */\nbool cephx_verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t     bufferlist::iterator& indata,\n\t\t\t     CephXServiceTicketInfo& ticket_info, bufferlist& reply_bl)\n{\n  __u8 authorizer_v;\n  uint32_t service_id;\n  uint64_t global_id;\n  CryptoKey service_secret;\n  // ticket blob\n  CephXTicketBlob ticket;\n\n\n  try {\n    ::decode(authorizer_v, indata);\n    ::decode(global_id, indata);\n    ::decode(service_id, indata);\n    ::decode(ticket, indata);\n  } catch (buffer::end_of_buffer &e) {\n    // Unable to decode!\n    return false;\n  }\n  ldout(cct, 10) << \"verify_authorizer decrypted service \"\n\t   << ceph_entity_type_name(service_id)\n\t   << \" secret_id=\" << ticket.secret_id << dendl;\n\n  if (ticket.secret_id == (uint64_t)-1) {\n    EntityName name;\n    name.set_type(service_id);\n    if (!keys->get_secret(name, service_secret)) {\n      ldout(cct, 0) << \"verify_authorizer could not get general service secret for service \"\n\t      << ceph_entity_type_name(service_id) << \" secret_id=\" << ticket.secret_id << dendl;\n      return false;\n    }\n  } else {\n    if (!keys->get_service_secret(service_id, ticket.secret_id, service_secret)) {\n      ldout(cct, 0) << \"verify_authorizer could not get service secret for service \"\n\t      << ceph_entity_type_name(service_id) << \" secret_id=\" << ticket.secret_id << dendl;\n      if (cct->_conf->auth_debug && ticket.secret_id == 0)\n\tassert(0 == \"got secret_id=0\");\n      return false;\n    }\n  }\n  std::string error;\n  if (!service_secret.get_secret().length())\n    error = \"invalid key\";  // Bad key?\n  else\n    decode_decrypt_enc_bl(cct, ticket_info, service_secret, ticket.blob, error);\n  if (!error.empty()) {\n    ldout(cct, 0) << \"verify_authorizer could not decrypt ticket info: error: \"\n      << error << dendl;\n    return false;\n  }\n\n  if (ticket_info.ticket.global_id != global_id) {\n    ldout(cct, 0) << \"verify_authorizer global_id mismatch: declared id=\" << global_id\n\t    << \" ticket_id=\" << ticket_info.ticket.global_id << dendl;\n    return false;\n  }\n\n  ldout(cct, 10) << \"verify_authorizer global_id=\" << global_id << dendl;\n\n  // CephXAuthorize\n  CephXAuthorize auth_msg;\n  if (decode_decrypt(cct, auth_msg, ticket_info.session_key, indata, error)) {\n    ldout(cct, 0) << \"verify_authorizercould not decrypt authorize request with error: \"\n      << error << dendl;\n    return false;\n  }\n\n  /*\n   * Reply authorizer:\n   *  {timestamp + 1}^session_key\n   */\n  CephXAuthorizeReply reply;\n  // reply.trans_id = auth_msg.trans_id;\n  reply.nonce_plus_one = auth_msg.nonce + 1;\n  if (encode_encrypt(cct, reply, ticket_info.session_key, reply_bl, error)) {\n    ldout(cct, 10) << \"verify_authorizer: encode_encrypt error: \" << error << dendl;\n    return false;\n  }\n\n  ldout(cct, 10) << \"verify_authorizer ok nonce \" << hex << auth_msg.nonce << dec\n\t   << \" reply_bl.length()=\" << reply_bl.length() <<  dendl;\n  return true;\n}\n\nbool CephXAuthorizer::verify_reply(bufferlist::iterator& indata)\n{\n  CephXAuthorizeReply reply;\n\n  std::string error;\n  if (decode_decrypt(cct, reply, session_key, indata, error)) {\n      ldout(cct, 0) << \"verify_reply couldn't decrypt with error: \" << error << dendl;\n      return false;\n  }\n\n  uint64_t expect = nonce + 1;\n  if (expect != reply.nonce_plus_one) {\n    ldout(cct, 0) << \"verify_authorizer_reply bad nonce got \" << reply.nonce_plus_one << \" expected \" << expect\n\t    << \" sent \" << nonce << dendl;\n    return false;\n  }\n  return true;\n}\n\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_CEPHXPROTOCOL_H\n#define CEPH_CEPHXPROTOCOL_H\n\n/*\n  Ceph X protocol\n\n  First, the principal has to authenticate with the authenticator. A\n  shared-secret mechanism is being used, and the negotitaion goes like this:\n\n  A = Authenticator\n  P = Principle\n  S = Service\n\n  1. Obtaining principal/auth session key\n\n  (Authenticate Request)\n  p->a : principal, principal_addr.  authenticate me!\n\n ...authenticator does lookup in database...\n\n  a->p : A= {principal/auth session key, validity}^principal_secret (*)\n         B= {principal ticket, validity, principal/auth session key}^authsecret\n\n  \n  [principal/auth session key, validity] = service ticket\n  [principal ticket, validity, principal/auth session key] = service ticket info\n\n  (*) annotation: ^ signifies 'encrypted by'\n\n  At this point, if is genuine, the principal should have the principal/auth\n  session key at hand. The next step would be to request an authorization to\n  use some other service:\n\n  2. Obtaining principal/service session key\n\n  p->a : B, {principal_addr, timestamp}^principal/auth session key.  authorize\n         me!\n  a->p : E= {service ticket}^svcsecret\n         F= {principal/service session key, validity}^principal/auth session key\n\n  principal_addr, timestamp = authenticator\n\n  service ticket = principal name, client network address, validity, principal/service session key\n\n  Note that steps 1 and 2 are pretty much the same thing; contacting the\n  authenticator and requesting for a key.\n\n  Following this the principal should have a principal/service session key that\n  could be used later on for creating a session:\n\n  3. Opening a session to a service\n\n  p->s : E + {principal_addr, timestamp}^principal/service session key\n  s->p : {timestamp+1}^principal/service/session key\n\n  timestamp+1 = reply authenticator\n\n  Now, the principal is fully authenticated with the service. So, logically we\n  have 2 main actions here. The first one would be to obtain a session key to\n  the service (steps 1 and 2), and the second one would be to authenticate with\n  the service, using that ticket.\n*/\n\n/* authenticate requests */\n#define CEPHX_GET_AUTH_SESSION_KEY      0x0100\n#define CEPHX_GET_PRINCIPAL_SESSION_KEY 0x0200\n#define CEPHX_GET_ROTATING_KEY          0x0400\n\n#define CEPHX_REQUEST_TYPE_MASK            0x0F00\n#define CEPHX_CRYPT_ERR\t\t\t1\n\n#include \"auth/Auth.h\"\n#include <errno.h>\n#include <sstream>\n\nclass CephContext;\n\n/*\n * Authentication\n */\n\n// initial server -> client challenge\nstruct CephXServerChallenge {\n  uint64_t server_challenge;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(server_challenge, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(server_challenge, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXServerChallenge)\n\n\n// request/reply headers, for subsequent exchanges.\n\nstruct CephXRequestHeader {\n  __u16 request_type;\n\n  void encode(bufferlist& bl) const {\n    ::encode(request_type, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    ::decode(request_type, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXRequestHeader)\n\nstruct CephXResponseHeader {\n  uint16_t request_type;\n  int32_t status;\n\n  void encode(bufferlist& bl) const {\n    ::encode(request_type, bl);\n    ::encode(status, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    ::decode(request_type, bl);\n    ::decode(status, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXResponseHeader)\n\nstruct CephXTicketBlob {\n  uint64_t secret_id;\n  bufferlist blob;\n\n  CephXTicketBlob() : secret_id(0) {}\n\n  void encode(bufferlist& bl) const {\n     __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(secret_id, bl);\n    ::encode(blob, bl);\n  }\n\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(secret_id, bl);\n    ::decode(blob, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXTicketBlob)\n\n// client -> server response to challenge\nstruct CephXAuthenticate {\n  uint64_t client_challenge;\n  uint64_t key;\n  CephXTicketBlob old_ticket;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(client_challenge, bl);\n    ::encode(key, bl);\n    ::encode(old_ticket, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(client_challenge, bl);\n    ::decode(key, bl);\n    ::decode(old_ticket, bl);\n }\n};\nWRITE_CLASS_ENCODER(CephXAuthenticate)\n\nstruct CephXChallengeBlob {\n  uint64_t server_challenge, client_challenge;\n  \n  void encode(bufferlist& bl) const {\n    ::encode(server_challenge, bl);\n    ::encode(client_challenge, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    ::decode(server_challenge, bl);\n    ::decode(client_challenge, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXChallengeBlob)\n\nvoid cephx_calc_client_server_challenge(CephContext *cct, \n\t\t\t\t\tCryptoKey& secret, uint64_t server_challenge, uint64_t client_challenge,\n\t\t\t\t\tuint64_t *key, std::string &error);\n\n\n/*\n * getting service tickets\n */\nstruct CephXSessionAuthInfo {\n  uint32_t service_id;\n  uint64_t secret_id;\n  AuthTicket ticket;\n  CryptoKey session_key;\n  CryptoKey service_secret;\n  utime_t validity;\n};\n\n\nextern bool cephx_build_service_ticket_blob(CephContext *cct,\n\t\t\t\t\t    CephXSessionAuthInfo& ticket_info, CephXTicketBlob& blob);\n\nextern void cephx_build_service_ticket_request(CephContext *cct, \n\t\t\t\t\t       uint32_t keys,\n\t\t\t\t\t       bufferlist& request);\n\nextern bool cephx_build_service_ticket_reply(CephContext *cct,\n\t\t\t\t\t     CryptoKey& principal_secret,\n\t\t\t\t\t     vector<CephXSessionAuthInfo> ticket_info,\n                                             bool should_encrypt_ticket,\n                                             CryptoKey& ticket_enc_key,\n\t\t\t\t\t     bufferlist& reply);\n\nstruct CephXServiceTicketRequest {\n  uint32_t keys;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(keys, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(keys, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXServiceTicketRequest)\n\n\n/*\n * Authorize\n */\n\nstruct CephXAuthorizeReply {\n  uint64_t nonce_plus_one;\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(nonce_plus_one, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(nonce_plus_one, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXAuthorizeReply)\n\n\nstruct CephXAuthorizer : public AuthAuthorizer {\nprivate:\n  CephContext *cct;\npublic:\n  uint64_t nonce;\n\n  explicit CephXAuthorizer(CephContext *cct_)\n    : AuthAuthorizer(CEPH_AUTH_CEPHX), cct(cct_), nonce(0) {}\n\n  bool build_authorizer();\n  bool verify_reply(bufferlist::iterator& reply) override;\n};\n\n\n\n/*\n * TicketHandler\n */\nstruct CephXTicketHandler {\n  uint32_t service_id;\n  CryptoKey session_key;\n  CephXTicketBlob ticket;        // opaque to us\n  utime_t renew_after, expires;\n  bool have_key_flag;\n\n  CephXTicketHandler(CephContext *cct_, uint32_t service_id_)\n    : service_id(service_id_), have_key_flag(false), cct(cct_) { }\n\n  // to build our ServiceTicket\n  bool verify_service_ticket_reply(CryptoKey& principal_secret,\n\t\t\t\t bufferlist::iterator& indata);\n  // to access the service\n  CephXAuthorizer *build_authorizer(uint64_t global_id) const;\n\n  bool have_key();\n  bool need_key() const;\n\n  void invalidate_ticket() {\n    have_key_flag = 0;\n  }\nprivate:\n  CephContext *cct;\n};\n\nstruct CephXTicketManager {\n  typedef map<uint32_t, CephXTicketHandler> tickets_map_t;\n  tickets_map_t tickets_map;\n  uint64_t global_id;\n\n  explicit CephXTicketManager(CephContext *cct_) : global_id(0), cct(cct_) {}\n\n  bool verify_service_ticket_reply(CryptoKey& principal_secret,\n\t\t\t\t bufferlist::iterator& indata);\n\n  CephXTicketHandler& get_handler(uint32_t type) {\n    tickets_map_t::iterator i = tickets_map.find(type);\n    if (i != tickets_map.end())\n      return i->second;\n    CephXTicketHandler newTicketHandler(cct, type);\n    std::pair < tickets_map_t::iterator, bool > res =\n\ttickets_map.insert(std::make_pair(type, newTicketHandler));\n    assert(res.second);\n    return res.first->second;\n  }\n  CephXAuthorizer *build_authorizer(uint32_t service_id) const;\n  bool have_key(uint32_t service_id);\n  bool need_key(uint32_t service_id) const;\n  void set_have_need_key(uint32_t service_id, uint32_t& have, uint32_t& need);\n  void validate_tickets(uint32_t mask, uint32_t& have, uint32_t& need);\n  void invalidate_ticket(uint32_t service_id);\n\nprivate:\n  CephContext *cct;\n};\n\n\n/* A */\nstruct CephXServiceTicket {\n  CryptoKey session_key;\n  utime_t validity;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(session_key, bl);\n    ::encode(validity, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(session_key, bl);\n    ::decode(validity, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXServiceTicket)\n\n/* B */\nstruct CephXServiceTicketInfo {\n  AuthTicket ticket;\n  CryptoKey session_key;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(ticket, bl);\n    ::encode(session_key, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(ticket, bl);\n    ::decode(session_key, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXServiceTicketInfo)\n\nstruct CephXAuthorize {\n  uint64_t nonce;\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(nonce, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(nonce, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXAuthorize)\n\n/*\n * Decode an extract ticket\n */\nbool cephx_decode_ticket(CephContext *cct, KeyStore *keys,\n\t\t\t uint32_t service_id, CephXTicketBlob& ticket_blob,\n\t\t\t CephXServiceTicketInfo& ticket_info);\n\n/*\n * Verify authorizer and generate reply authorizer\n */\nextern bool cephx_verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t\t    bufferlist::iterator& indata,\n\t\t\t\t    CephXServiceTicketInfo& ticket_info, bufferlist& reply_bl);\n\n\n\n\n\n\n/*\n * encode+encrypt macros\n */\nstatic constexpr uint64_t AUTH_ENC_MAGIC = 0xff009cad8826aa55ull;\n\ntemplate <typename T>\nvoid decode_decrypt_enc_bl(CephContext *cct, T& t, CryptoKey key, bufferlist& bl_enc, \n\t\t\t   std::string &error)\n{\n  uint64_t magic;\n  bufferlist bl;\n\n  if (key.decrypt(cct, bl_enc, bl, &error) < 0)\n    return;\n\n  bufferlist::iterator iter2 = bl.begin();\n  __u8 struct_v;\n  ::decode(struct_v, iter2);\n  ::decode(magic, iter2);\n  if (magic != AUTH_ENC_MAGIC) {\n    ostringstream oss;\n    oss << \"bad magic in decode_decrypt, \" << magic << \" != \" << AUTH_ENC_MAGIC;\n    error = oss.str();\n    return;\n  }\n\n  ::decode(t, iter2);\n}\n\ntemplate <typename T>\nvoid encode_encrypt_enc_bl(CephContext *cct, const T& t, const CryptoKey& key,\n\t\t\t   bufferlist& out, std::string &error)\n{\n  bufferlist bl;\n  __u8 struct_v = 1;\n  ::encode(struct_v, bl);\n  uint64_t magic = AUTH_ENC_MAGIC;\n  ::encode(magic, bl);\n  ::encode(t, bl);\n\n  key.encrypt(cct, bl, out, &error);\n}\n\ntemplate <typename T>\nint decode_decrypt(CephContext *cct, T& t, const CryptoKey& key,\n\t\t    bufferlist::iterator& iter, std::string &error)\n{\n  bufferlist bl_enc;\n  try {\n    ::decode(bl_enc, iter);\n    decode_decrypt_enc_bl(cct, t, key, bl_enc, error);\n  }\n  catch (buffer::error &e) {\n    error = \"error decoding block for decryption\";\n  }\n  if (!error.empty())\n    return CEPHX_CRYPT_ERR;\n  return 0;\n}\n\ntemplate <typename T>\nint encode_encrypt(CephContext *cct, const T& t, const CryptoKey& key,\n\t\t    bufferlist& out, std::string &error)\n{\n  bufferlist bl_enc;\n  encode_encrypt_enc_bl(cct, t, key, bl_enc, error);\n  if (!error.empty()){\n    return CEPHX_CRYPT_ERR;\n  }\n  ::encode(bl_enc, out);\n  return 0;\n}\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n\n#include \"CephxServiceHandler.h\"\n#include \"CephxProtocol.h\"\n#include \"CephxKeyServer.h\"\n#include <errno.h>\n#include <sstream>\n\n#include \"common/config.h\"\n#include \"common/debug.h\"\n\n#define dout_subsys ceph_subsys_auth\n#undef dout_prefix\n#define dout_prefix *_dout << \"cephx server \" << entity_name << \": \"\n\nint CephxServiceHandler::start_session(EntityName& name, bufferlist::iterator& indata, bufferlist& result_bl, AuthCapsInfo& caps)\n{\n  entity_name = name;\n\n  get_random_bytes((char *)&server_challenge, sizeof(server_challenge));\n  if (!server_challenge)\n    server_challenge = 1;  // always non-zero.\n  ldout(cct, 10) << \"start_session server_challenge \" << hex << server_challenge << dec << dendl;\n\n  CephXServerChallenge ch;\n  ch.server_challenge = server_challenge;\n  ::encode(ch, result_bl);\n  return CEPH_AUTH_CEPHX;\n}\n\nint CephxServiceHandler::handle_request(bufferlist::iterator& indata, bufferlist& result_bl, uint64_t& global_id, AuthCapsInfo& caps, uint64_t *auid)\n{\n  int ret = 0;\n\n  struct CephXRequestHeader cephx_header;\n  ::decode(cephx_header, indata);\n\n\n  switch (cephx_header.request_type) {\n  case CEPHX_GET_AUTH_SESSION_KEY:\n    {\n      ldout(cct, 10) << \"handle_request get_auth_session_key for \" << entity_name << dendl;\n\n      CephXAuthenticate req;\n      ::decode(req, indata);\n\n      CryptoKey secret;\n      if (!key_server->get_secret(entity_name, secret)) {\n        ldout(cct, 0) << \"couldn't find entity name: \" << entity_name << dendl;\n\tret = -EPERM;\n\tbreak;\n      }\n\n      if (!server_challenge) {\n\tret = -EPERM;\n\tbreak;\n      }      \n\n      uint64_t expected_key;\n      std::string error;\n      cephx_calc_client_server_challenge(cct, secret, server_challenge,\n\t\t\t\t\t req.client_challenge, &expected_key, error);\n      if (!error.empty()) {\n\tldout(cct, 0) << \" cephx_calc_client_server_challenge error: \" << error << dendl;\n\tret = -EPERM;\n\tbreak;\n      }\n\n      ldout(cct, 20) << \" checking key: req.key=\" << hex << req.key\n\t       << \" expected_key=\" << expected_key << dec << dendl;\n      if (req.key != expected_key) {\n        ldout(cct, 0) << \" unexpected key: req.key=\" << hex << req.key\n\t\t<< \" expected_key=\" << expected_key << dec << dendl;\n        ret = -EPERM;\n\tbreak;\n      }\n\n      CryptoKey session_key;\n      CephXSessionAuthInfo info;\n      bool should_enc_ticket = false;\n\n      EntityAuth eauth;\n      if (! key_server->get_auth(entity_name, eauth)) {\n\tret = -EPERM;\n\tbreak;\n      }\n      CephXServiceTicketInfo old_ticket_info;\n\n      if (cephx_decode_ticket(cct, key_server, CEPH_ENTITY_TYPE_AUTH,\n\t\t\t      req.old_ticket, old_ticket_info)) {\n        global_id = old_ticket_info.ticket.global_id;\n        ldout(cct, 10) << \"decoded old_ticket with global_id=\" << global_id << dendl;\n        should_enc_ticket = true;\n      }\n\n      info.ticket.init_timestamps(ceph_clock_now(), cct->_conf->auth_mon_ticket_ttl);\n      info.ticket.name = entity_name;\n      info.ticket.global_id = global_id;\n      info.ticket.auid = eauth.auid;\n      info.validity += cct->_conf->auth_mon_ticket_ttl;\n\n      if (auid) *auid = eauth.auid;\n\n      key_server->generate_secret(session_key);\n\n      info.session_key = session_key;\n      info.service_id = CEPH_ENTITY_TYPE_AUTH;\n      if (!key_server->get_service_secret(CEPH_ENTITY_TYPE_AUTH, info.service_secret, info.secret_id)) {\n        ldout(cct, 0) << \" could not get service secret for auth subsystem\" << dendl;\n        ret = -EIO;\n        break;\n      }\n\n      vector<CephXSessionAuthInfo> info_vec;\n      info_vec.push_back(info);\n\n      build_cephx_response_header(cephx_header.request_type, 0, result_bl);\n      if (!cephx_build_service_ticket_reply(cct, eauth.key, info_vec, should_enc_ticket,\n\t\t\t\t\t    old_ticket_info.session_key, result_bl)) {\n\tret = -EIO;\n      }\n\n      if (!key_server->get_service_caps(entity_name, CEPH_ENTITY_TYPE_MON, caps)) {\n        ldout(cct, 0) << \" could not get mon caps for \" << entity_name << dendl;\n        ret = -EACCES;\n      } else {\n        char *caps_str = caps.caps.c_str();\n        if (!caps_str || !caps_str[0]) {\n          ldout(cct,0) << \"mon caps null for \" << entity_name << dendl;\n          ret = -EACCES;\n        }\n      }\n    }\n    break;\n\n  case CEPHX_GET_PRINCIPAL_SESSION_KEY:\n    {\n      ldout(cct, 10) << \"handle_request get_principal_session_key\" << dendl;\n\n      bufferlist tmp_bl;\n      CephXServiceTicketInfo auth_ticket_info;\n      if (!cephx_verify_authorizer(cct, key_server, indata, auth_ticket_info, tmp_bl)) {\n        ret = -EPERM;\n\tbreak;\n      }\n\n      CephXServiceTicketRequest ticket_req;\n      ::decode(ticket_req, indata);\n      ldout(cct, 10) << \" ticket_req.keys = \" << ticket_req.keys << dendl;\n\n      ret = 0;\n      vector<CephXSessionAuthInfo> info_vec;\n      int found_services = 0;\n      int service_err = 0;\n      for (uint32_t service_id = 1; service_id <= ticket_req.keys;\n\t   service_id <<= 1) {\n        if (ticket_req.keys & service_id) {\n\t  ldout(cct, 10) << \" adding key for service \"\n\t\t\t << ceph_entity_type_name(service_id) << dendl;\n          CephXSessionAuthInfo info;\n          int r = key_server->build_session_auth_info(service_id,\n\t\t\t\t\t\t      auth_ticket_info, info);\n\t  // tolerate missing MGR rotating key for the purposes of upgrades.\n          if (r < 0) {\n\t    ldout(cct, 10) << \"   missing key for service \"\n\t\t\t   << ceph_entity_type_name(service_id) << dendl;\n\t    service_err = r;\n\t    continue;\n\t  }\n          info.validity += cct->_conf->auth_service_ticket_ttl;\n          info_vec.push_back(info);\n\t  ++found_services;\n        }\n      }\n      if (!found_services && service_err) {\n\tldout(cct, 10) << __func__ << \" did not find any service keys\" << dendl;\n\tret = service_err;\n      }\n      CryptoKey no_key;\n      build_cephx_response_header(cephx_header.request_type, ret, result_bl);\n      cephx_build_service_ticket_reply(cct, auth_ticket_info.session_key, info_vec, false, no_key, result_bl);\n    }\n    break;\n\n  case CEPHX_GET_ROTATING_KEY:\n    {\n      ldout(cct, 10) << \"handle_request getting rotating secret for \" << entity_name << dendl;\n      build_cephx_response_header(cephx_header.request_type, 0, result_bl);\n      if (!key_server->get_rotating_encrypted(entity_name, result_bl)) {\n        ret = -EPERM;\n        break;\n      }\n    }\n    break;\n\n  default:\n    ldout(cct, 10) << \"handle_request unknown op \" << cephx_header.request_type << dendl;\n    return -EINVAL;\n  }\n  return ret;\n}\n\nvoid CephxServiceHandler::build_cephx_response_header(int request_type, int status, bufferlist& bl)\n{\n  struct CephXResponseHeader header;\n  header.request_type = request_type;\n  header.status = status;\n  ::encode(header, bl);\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2009-2011 New Dream Network\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include \"AuthNoneAuthorizeHandler.h\"\n#include \"common/debug.h\"\n\n#define dout_subsys ceph_subsys_auth\n\nbool AuthNoneAuthorizeHandler::verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t\t\t\t bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t\t\t\t EntityName& entity_name, uint64_t& global_id, AuthCapsInfo& caps_info, CryptoKey& session_key,\nuint64_t *auid)\n{\n  bufferlist::iterator iter = authorizer_data.begin();\n\n  try {\n    __u8 struct_v = 1;\n    ::decode(struct_v, iter);\n    ::decode(entity_name, iter);\n    ::decode(global_id, iter);\n  } catch (const buffer::error &err) {\n    ldout(cct, 0) << \"AuthNoneAuthorizeHandle::verify_authorizer() failed to decode\" << dendl;\n    return false;\n  }\n\n  caps_info.allow_all = true;\n\n  return true;\n}\n\n// Return type of crypto used for this session's data;  for none, no crypt used\n\nint AuthNoneAuthorizeHandler::authorizer_session_crypto() \n{\n  return SESSION_CRYPTO_NONE;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_AUTHNONEAUTHORIZEHANDLER_H\n#define CEPH_AUTHNONEAUTHORIZEHANDLER_H\n\n#include \"auth/AuthAuthorizeHandler.h\"\n\nclass CephContext;\n\nstruct AuthNoneAuthorizeHandler : public AuthAuthorizeHandler {\n  bool verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t bufferlist& authorizer_data, bufferlist& authorizer_reply,\n                         EntityName& entity_name, uint64_t& global_id,\n\t\t\t AuthCapsInfo& caps_info, CryptoKey& session_key, uint64_t *auid=NULL) override;\n  int authorizer_session_crypto() override;\n};\n\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_AUTHNONEPROTOCOL_H\n#define CEPH_AUTHNONEPROTOCOL_H\n\n#include \"auth/Auth.h\"\n\nstruct AuthNoneAuthorizer : public AuthAuthorizer {\n  AuthNoneAuthorizer() : AuthAuthorizer(CEPH_AUTH_NONE) { }\n  bool build_authorizer(const EntityName &ename, uint64_t global_id) {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(ename, bl);\n    ::encode(global_id, bl);\n    return 0;\n  }\n  bool verify_reply(bufferlist::iterator& reply) override { return true; }\n};\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2009-2011 New Dream Network\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include \"AuthUnknownAuthorizeHandler.h\"\n\nbool AuthUnknownAuthorizeHandler::verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t\t\t\t bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t\t\t\t EntityName& entity_name, uint64_t& global_id, AuthCapsInfo& caps_info, CryptoKey& session_key,\nuint64_t *auid)\n{\n  // For unknown authorizers, there's nothing to verify.  They're \"OK\" by definition.  PLR\n\n  return true;\n}\n\n// Return type of crypto used for this session's data;  for unknown, no crypt used\n\nint AuthUnknownAuthorizeHandler::authorizer_session_crypto() \n{\n  return SESSION_CRYPTO_NONE;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_AUTHUNKNOWNAUTHORIZEHANDLER_H\n#define CEPH_AUTHUNKNOWNAUTHORIZEHANDLER_H\n\n#include \"auth/AuthAuthorizeHandler.h\"\n\nclass CephContext;\n\nstruct AuthUnknownAuthorizeHandler : public AuthAuthorizeHandler {\n  bool verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t bufferlist& authorizer_data, bufferlist& authorizer_reply,\n                         EntityName& entity_name, uint64_t& global_id,\n\t\t\t AuthCapsInfo& caps_info, CryptoKey& session_key, uint64_t *auid=NULL) override;\n  int authorizer_session_crypto() override;\n};\n\n\n\n#endif\n", "#ifndef CEPH_MSGR_H\n#define CEPH_MSGR_H\n\n#ifndef __KERNEL__\n#include <sys/socket.h> // for struct sockaddr_storage\n#endif\n\n#include \"include/int_types.h\"\n\n/*\n * Data types for message passing layer used by Ceph.\n */\n\n#define CEPH_MON_PORT    6789  /* default monitor port */\n\n/*\n * client-side processes will try to bind to ports in this\n * range, simply for the benefit of tools like nmap or wireshark\n * that would like to identify the protocol.\n */\n#define CEPH_PORT_FIRST  6789\n\n/*\n * tcp connection banner.  include a protocol version. and adjust\n * whenever the wire protocol changes.  try to keep this string length\n * constant.\n */\n#define CEPH_BANNER \"ceph v027\"\n\n/*\n * Rollover-safe type and comparator for 32-bit sequence numbers.\n * Comparator returns -1, 0, or 1.\n */\ntypedef __u32 ceph_seq_t;\n\nstatic inline __s32 ceph_seq_cmp(__u32 a, __u32 b)\n{\n       return (__s32)a - (__s32)b;\n}\n\n\n/*\n * entity_name -- logical name for a process participating in the\n * network, e.g. 'mds0' or 'osd3'.\n */\nstruct ceph_entity_name {\n\t__u8 type;      /* CEPH_ENTITY_TYPE_* */\n\t__le64 num;\n} __attribute__ ((packed));\n\n#define CEPH_ENTITY_TYPE_MON    0x01\n#define CEPH_ENTITY_TYPE_MDS    0x02\n#define CEPH_ENTITY_TYPE_OSD    0x04\n#define CEPH_ENTITY_TYPE_CLIENT 0x08\n#define CEPH_ENTITY_TYPE_MGR    0x10\n#define CEPH_ENTITY_TYPE_AUTH   0x20\n\n#define CEPH_ENTITY_TYPE_ANY    0xFF\n\nextern const char *ceph_entity_type_name(int type);\n\n/*\n * entity_addr -- network address\n */\nstruct ceph_entity_addr {\n\t__le32 type;\n\t__le32 nonce;  /* unique id for process (e.g. pid) */\n\tstruct sockaddr_storage in_addr;\n} __attribute__ ((packed));\n\nstruct ceph_entity_inst {\n\tstruct ceph_entity_name name;\n\tstruct ceph_entity_addr addr;\n} __attribute__ ((packed));\n\n\n/* used by message exchange protocol */\n#define CEPH_MSGR_TAG_READY         1  /* server->client: ready for messages */\n#define CEPH_MSGR_TAG_RESETSESSION  2  /* server->client: reset, try again */\n#define CEPH_MSGR_TAG_WAIT          3  /* server->client: wait for racing\n\t\t\t\t\t  incoming connection */\n#define CEPH_MSGR_TAG_RETRY_SESSION 4  /* server->client + cseq: try again\n\t\t\t\t\t  with higher cseq */\n#define CEPH_MSGR_TAG_RETRY_GLOBAL  5  /* server->client + gseq: try again\n\t\t\t\t\t  with higher gseq */\n#define CEPH_MSGR_TAG_CLOSE         6  /* closing pipe */\n#define CEPH_MSGR_TAG_MSG           7  /* message */\n#define CEPH_MSGR_TAG_ACK           8  /* message ack */\n#define CEPH_MSGR_TAG_KEEPALIVE     9  /* just a keepalive byte! */\n#define CEPH_MSGR_TAG_BADPROTOVER  10  /* bad protocol version */\n#define CEPH_MSGR_TAG_BADAUTHORIZER 11 /* bad authorizer */\n#define CEPH_MSGR_TAG_FEATURES      12 /* insufficient features */\n#define CEPH_MSGR_TAG_SEQ           13 /* 64-bit int follows with seen seq number */\n#define CEPH_MSGR_TAG_KEEPALIVE2     14\n#define CEPH_MSGR_TAG_KEEPALIVE2_ACK 15  /* keepalive reply */\n\n\n/*\n * connection negotiation\n */\nstruct ceph_msg_connect {\n\t__le64 features;     /* supported feature bits */\n\t__le32 host_type;    /* CEPH_ENTITY_TYPE_* */\n\t__le32 global_seq;   /* count connections initiated by this host */\n\t__le32 connect_seq;  /* count connections initiated in this session */\n\t__le32 protocol_version;\n\t__le32 authorizer_protocol;\n\t__le32 authorizer_len;\n\t__u8  flags;         /* CEPH_MSG_CONNECT_* */\n} __attribute__ ((packed));\n\nstruct ceph_msg_connect_reply {\n\t__u8 tag;\n\t__le64 features;     /* feature bits for this session */\n\t__le32 global_seq;\n\t__le32 connect_seq;\n\t__le32 protocol_version;\n\t__le32 authorizer_len;\n\t__u8 flags;\n} __attribute__ ((packed));\n\n#define CEPH_MSG_CONNECT_LOSSY  1  /* messages i send may be safely dropped */\n\n\n/*\n * message header\n */\nstruct ceph_msg_header_old {\n\t__le64 seq;       /* message seq# for this session */\n\t__le64 tid;       /* transaction id */\n\t__le16 type;      /* message type */\n\t__le16 priority;  /* priority.  higher value == higher priority */\n\t__le16 version;   /* version of message encoding */\n\n\t__le32 front_len; /* bytes in main payload */\n\t__le32 middle_len;/* bytes in middle payload */\n\t__le32 data_len;  /* bytes of data payload */\n\t__le16 data_off;  /* sender: include full offset;\n\t\t\t     receiver: mask against ~PAGE_MASK */\n\n\tstruct ceph_entity_inst src, orig_src;\n\t__le32 reserved;\n\t__le32 crc;       /* header crc32c */\n} __attribute__ ((packed));\n\nstruct ceph_msg_header {\n\t__le64 seq;       /* message seq# for this session */\n\t__le64 tid;       /* transaction id */\n\t__le16 type;      /* message type */\n\t__le16 priority;  /* priority.  higher value == higher priority */\n\t__le16 version;   /* version of message encoding */\n\n\t__le32 front_len; /* bytes in main payload */\n\t__le32 middle_len;/* bytes in middle payload */\n\t__le32 data_len;  /* bytes of data payload */\n\t__le16 data_off;  /* sender: include full offset;\n\t\t\t     receiver: mask against ~PAGE_MASK */\n\n\tstruct ceph_entity_name src;\n\n\t/* oldest code we think can decode this.  unknown if zero. */\n\t__le16 compat_version;\n\t__le16 reserved;\n\t__le32 crc;       /* header crc32c */\n} __attribute__ ((packed));\n\n#define CEPH_MSG_PRIO_LOW     64\n#define CEPH_MSG_PRIO_DEFAULT 127\n#define CEPH_MSG_PRIO_HIGH    196\n#define CEPH_MSG_PRIO_HIGHEST 255\n\n/*\n * follows data payload\n * ceph_msg_footer_old does not support digital signatures on messages PLR\n */\n\nstruct ceph_msg_footer_old {\n\t__le32 front_crc, middle_crc, data_crc;\n\t__u8 flags;\n} __attribute__ ((packed));\n\nstruct ceph_msg_footer {\n\t__le32 front_crc, middle_crc, data_crc;\n\t// sig holds the 64 bits of the digital signature for the message PLR\n\t__le64  sig;\n\t__u8 flags;\n} __attribute__ ((packed));\n\n#define CEPH_MSG_FOOTER_COMPLETE  (1<<0)   /* msg wasn't aborted */\n#define CEPH_MSG_FOOTER_NOCRC     (1<<1)   /* no data crc */\n#define CEPH_MSG_FOOTER_SIGNED\t  (1<<2)   /* msg was signed */\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include <unistd.h>\n\n#include \"include/compat.h\"\n#include \"include/types.h\"\n#include \"include/str_list.h\"\n\n#include \"common/Clock.h\"\n#include \"common/HeartbeatMap.h\"\n#include \"common/Timer.h\"\n#include \"common/backport14.h\"\n#include \"common/ceph_argparse.h\"\n#include \"common/config.h\"\n#include \"common/entity_name.h\"\n#include \"common/errno.h\"\n#include \"common/perf_counters.h\"\n#include \"common/signal.h\"\n#include \"common/version.h\"\n\n#include \"global/signal_handler.h\"\n\n#include \"msg/Messenger.h\"\n#include \"mon/MonClient.h\"\n\n#include \"osdc/Objecter.h\"\n\n#include \"MDSMap.h\"\n\n#include \"MDSDaemon.h\"\n#include \"Server.h\"\n#include \"Locker.h\"\n\n#include \"SnapServer.h\"\n#include \"SnapClient.h\"\n\n#include \"events/ESession.h\"\n#include \"events/ESubtreeMap.h\"\n\n#include \"messages/MMDSMap.h\"\n\n#include \"messages/MGenericMessage.h\"\n\n#include \"messages/MMonCommand.h\"\n#include \"messages/MCommand.h\"\n#include \"messages/MCommandReply.h\"\n\n#include \"auth/AuthAuthorizeHandler.h\"\n#include \"auth/RotatingKeyRing.h\"\n#include \"auth/KeyRing.h\"\n\n#include \"perfglue/cpu_profiler.h\"\n#include \"perfglue/heap_profiler.h\"\n\n#define dout_context g_ceph_context\n#define dout_subsys ceph_subsys_mds\n#undef dout_prefix\n#define dout_prefix *_dout << \"mds.\" << name << ' '\n\n// cons/des\nMDSDaemon::MDSDaemon(boost::string_view n, Messenger *m, MonClient *mc) :\n  Dispatcher(m->cct),\n  mds_lock(\"MDSDaemon::mds_lock\"),\n  stopping(false),\n  timer(m->cct, mds_lock),\n  beacon(m->cct, mc, n),\n  authorize_handler_cluster_registry(new AuthAuthorizeHandlerRegistry(m->cct,\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_supported.empty() ?\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_cluster_required :\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_supported)),\n  authorize_handler_service_registry(new AuthAuthorizeHandlerRegistry(m->cct,\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_supported.empty() ?\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_service_required :\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_supported)),\n  name(n),\n  messenger(m),\n  monc(mc),\n  mgrc(m->cct, m),\n  log_client(m->cct, messenger, &mc->monmap, LogClient::NO_FLAGS),\n  mds_rank(NULL),\n  asok_hook(NULL),\n  starttime(mono_clock::now())\n{\n  orig_argc = 0;\n  orig_argv = NULL;\n\n  clog = log_client.create_channel();\n\n  monc->set_messenger(messenger);\n\n  mdsmap = new MDSMap;\n}\n\nMDSDaemon::~MDSDaemon() {\n  Mutex::Locker lock(mds_lock);\n\n  delete mds_rank;\n  mds_rank = NULL;\n  delete mdsmap;\n  mdsmap = NULL;\n\n  delete authorize_handler_service_registry;\n  delete authorize_handler_cluster_registry;\n}\n\nclass MDSSocketHook : public AdminSocketHook {\n  MDSDaemon *mds;\npublic:\n  explicit MDSSocketHook(MDSDaemon *m) : mds(m) {}\n  bool call(std::string command, cmdmap_t& cmdmap, std::string format,\n\t    bufferlist& out) override {\n    stringstream ss;\n    bool r = mds->asok_command(command, cmdmap, format, ss);\n    out.append(ss);\n    return r;\n  }\n};\n\nbool MDSDaemon::asok_command(string command, cmdmap_t& cmdmap, string format,\n\t\t    ostream& ss)\n{\n  dout(1) << \"asok_command: \" << command << \" (starting...)\" << dendl;\n\n  Formatter *f = Formatter::create(format, \"json-pretty\", \"json-pretty\");\n  bool handled = false;\n  if (command == \"status\") {\n    dump_status(f);\n    handled = true;\n  } else {\n    if (mds_rank == NULL) {\n      dout(1) << \"Can't run that command on an inactive MDS!\" << dendl;\n      f->dump_string(\"error\", \"mds_not_active\");\n    } else {\n      handled = mds_rank->handle_asok_command(command, cmdmap, f, ss);\n    }\n  }\n  f->flush(ss);\n  delete f;\n\n  dout(1) << \"asok_command: \" << command << \" (complete)\" << dendl;\n\n  return handled;\n}\n\nvoid MDSDaemon::dump_status(Formatter *f)\n{\n  f->open_object_section(\"status\");\n  f->dump_stream(\"cluster_fsid\") << monc->get_fsid();\n  if (mds_rank) {\n    f->dump_int(\"whoami\", mds_rank->get_nodeid());\n  } else {\n    f->dump_int(\"whoami\", MDS_RANK_NONE);\n  }\n\n  f->dump_int(\"id\", monc->get_global_id());\n  f->dump_string(\"want_state\", ceph_mds_state_name(beacon.get_want_state()));\n  f->dump_string(\"state\", ceph_mds_state_name(mdsmap->get_state_gid(mds_gid_t(\n\t    monc->get_global_id()))));\n  if (mds_rank) {\n    Mutex::Locker l(mds_lock);\n    mds_rank->dump_status(f);\n  }\n\n  f->dump_unsigned(\"mdsmap_epoch\", mdsmap->get_epoch());\n  if (mds_rank) {\n    f->dump_unsigned(\"osdmap_epoch\", mds_rank->get_osd_epoch());\n    f->dump_unsigned(\"osdmap_epoch_barrier\", mds_rank->get_osd_epoch_barrier());\n  } else {\n    f->dump_unsigned(\"osdmap_epoch\", 0);\n    f->dump_unsigned(\"osdmap_epoch_barrier\", 0);\n  }\n\n  f->dump_float(\"uptime\", get_uptime().count());\n\n  f->close_section(); // status\n}\n\nvoid MDSDaemon::set_up_admin_socket()\n{\n  int r;\n  AdminSocket *admin_socket = g_ceph_context->get_admin_socket();\n  assert(asok_hook == nullptr);\n  asok_hook = new MDSSocketHook(this);\n  r = admin_socket->register_command(\"status\", \"status\", asok_hook,\n\t\t\t\t     \"high-level status of MDS\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_ops_in_flight\",\n\t\t\t\t     \"dump_ops_in_flight\", asok_hook,\n\t\t\t\t     \"show the ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"ops\",\n\t\t\t\t     \"ops\", asok_hook,\n\t\t\t\t     \"show the ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_blocked_ops\", \"dump_blocked_ops\",\n      asok_hook,\n      \"show the blocked ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_historic_ops\", \"dump_historic_ops\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show slowest recent ops\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_historic_ops_by_duration\", \"dump_historic_ops_by_duration\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show slowest recent ops, sorted by op duration\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"scrub_path\",\n\t\t\t\t     \"scrub_path name=path,type=CephString \"\n\t\t\t\t     \"name=scrubops,type=CephChoices,\"\n\t\t\t\t     \"strings=force|recursive|repair,n=N,req=false\",\n                                     asok_hook,\n                                     \"scrub an inode and output results\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"tag path\",\n                                     \"tag path name=path,type=CephString\"\n                                     \" name=tag,type=CephString\",\n                                     asok_hook,\n                                     \"Apply scrub tag recursively\");\n   assert(r == 0);\n  r = admin_socket->register_command(\"flush_path\",\n                                     \"flush_path name=path,type=CephString\",\n                                     asok_hook,\n                                     \"flush an inode (and its dirfrags)\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"export dir\",\n                                     \"export dir \"\n                                     \"name=path,type=CephString \"\n                                     \"name=rank,type=CephInt\",\n                                     asok_hook,\n                                     \"migrate a subtree to named MDS\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump cache\",\n                                     \"dump cache name=path,type=CephString,req=false\",\n                                     asok_hook,\n                                     \"dump metadata cache (optionally to a file)\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"cache status\",\n                                     \"cache status\",\n                                     asok_hook,\n                                     \"show cache status\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump tree\",\n\t\t\t\t     \"dump tree \"\n\t\t\t\t     \"name=root,type=CephString,req=true \"\n\t\t\t\t     \"name=depth,type=CephInt,req=false \",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"dump metadata cache for subtree\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"session evict\",\n\t\t\t\t     \"session evict name=client_id,type=CephString\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Evict a CephFS client\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"osdmap barrier\",\n\t\t\t\t     \"osdmap barrier name=target_epoch,type=CephInt\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Wait until the MDS has this OSD map epoch\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"session ls\",\n\t\t\t\t     \"session ls\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Enumerate connected CephFS clients\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"flush journal\",\n\t\t\t\t     \"flush journal\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Flush the journal to the backing store\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"force_readonly\",\n\t\t\t\t     \"force_readonly\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Force MDS to read-only mode\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"get subtrees\",\n\t\t\t\t     \"get subtrees\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Return the subtree map\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dirfrag split\",\n\t\t\t\t     \"dirfrag split \"\n                                     \"name=path,type=CephString,req=true \"\n                                     \"name=frag,type=CephString,req=true \"\n                                     \"name=bits,type=CephInt,req=true \",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Fragment directory by path\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dirfrag merge\",\n\t\t\t\t     \"dirfrag merge \"\n                                     \"name=path,type=CephString,req=true \"\n                                     \"name=frag,type=CephString,req=true\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"De-fragment directory by path\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dirfrag ls\",\n\t\t\t\t     \"dirfrag ls \"\n                                     \"name=path,type=CephString,req=true\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"List fragments in directory\");\n  assert(r == 0);\n}\n\nvoid MDSDaemon::clean_up_admin_socket()\n{\n  AdminSocket *admin_socket = g_ceph_context->get_admin_socket();\n  admin_socket->unregister_command(\"status\");\n  admin_socket->unregister_command(\"dump_ops_in_flight\");\n  admin_socket->unregister_command(\"ops\");\n  admin_socket->unregister_command(\"dump_blocked_ops\");\n  admin_socket->unregister_command(\"dump_historic_ops\");\n  admin_socket->unregister_command(\"dump_historic_ops_by_duration\");\n  admin_socket->unregister_command(\"scrub_path\");\n  admin_socket->unregister_command(\"tag path\");\n  admin_socket->unregister_command(\"flush_path\");\n  admin_socket->unregister_command(\"export dir\");\n  admin_socket->unregister_command(\"dump cache\");\n  admin_socket->unregister_command(\"cache status\");\n  admin_socket->unregister_command(\"dump tree\");\n  admin_socket->unregister_command(\"session evict\");\n  admin_socket->unregister_command(\"osdmap barrier\");\n  admin_socket->unregister_command(\"session ls\");\n  admin_socket->unregister_command(\"flush journal\");\n  admin_socket->unregister_command(\"force_readonly\");\n  admin_socket->unregister_command(\"get subtrees\");\n  admin_socket->unregister_command(\"dirfrag split\");\n  admin_socket->unregister_command(\"dirfrag merge\");\n  admin_socket->unregister_command(\"dirfrag ls\");\n  delete asok_hook;\n  asok_hook = NULL;\n}\n\nconst char** MDSDaemon::get_tracked_conf_keys() const\n{\n  static const char* KEYS[] = {\n    \"mds_op_complaint_time\", \"mds_op_log_threshold\",\n    \"mds_op_history_size\", \"mds_op_history_duration\",\n    \"mds_enable_op_tracker\",\n    \"mds_log_pause\",\n    // clog & admin clog\n    \"clog_to_monitors\",\n    \"clog_to_syslog\",\n    \"clog_to_syslog_facility\",\n    \"clog_to_syslog_level\",\n    // PurgeQueue\n    \"mds_max_purge_ops\",\n    \"mds_max_purge_ops_per_pg\",\n    \"mds_max_purge_files\",\n    \"clog_to_graylog\",\n    \"clog_to_graylog_host\",\n    \"clog_to_graylog_port\",\n    \"host\",\n    \"fsid\",\n    NULL\n  };\n  return KEYS;\n}\n\nvoid MDSDaemon::handle_conf_change(const struct md_config_t *conf,\n\t\t\t     const std::set <std::string> &changed)\n{\n  // We may be called within mds_lock (via `tell`) or outwith the\n  // lock (via admin socket `config set`), so handle either case.\n  const bool initially_locked = mds_lock.is_locked_by_me();\n  if (!initially_locked) {\n    mds_lock.Lock();\n  }\n\n  if (changed.count(\"mds_op_complaint_time\") ||\n      changed.count(\"mds_op_log_threshold\")) {\n    if (mds_rank) {\n      mds_rank->op_tracker.set_complaint_and_threshold(conf->mds_op_complaint_time,\n                                             conf->mds_op_log_threshold);\n    }\n  }\n  if (changed.count(\"mds_op_history_size\") ||\n      changed.count(\"mds_op_history_duration\")) {\n    if (mds_rank) {\n      mds_rank->op_tracker.set_history_size_and_duration(conf->mds_op_history_size,\n                                               conf->mds_op_history_duration);\n    }\n  }\n  if (changed.count(\"mds_enable_op_tracker\")) {\n    if (mds_rank) {\n      mds_rank->op_tracker.set_tracking(conf->mds_enable_op_tracker);\n    }\n  }\n  if (changed.count(\"clog_to_monitors\") ||\n      changed.count(\"clog_to_syslog\") ||\n      changed.count(\"clog_to_syslog_level\") ||\n      changed.count(\"clog_to_syslog_facility\") ||\n      changed.count(\"clog_to_graylog\") ||\n      changed.count(\"clog_to_graylog_host\") ||\n      changed.count(\"clog_to_graylog_port\") ||\n      changed.count(\"host\") ||\n      changed.count(\"fsid\")) {\n    if (mds_rank) {\n      mds_rank->update_log_config();\n    }\n  }\n\n  if (!g_conf->mds_log_pause && changed.count(\"mds_log_pause\")) {\n    if (mds_rank) {\n      mds_rank->mdlog->kick_submitter();\n    }\n  }\n\n  if (mds_rank) {\n    mds_rank->handle_conf_change(conf, changed);\n  }\n\n  if (!initially_locked) {\n    mds_lock.Unlock();\n  }\n}\n\n\nint MDSDaemon::init()\n{\n  dout(10) << sizeof(MDSCacheObject) << \"\\tMDSCacheObject\" << dendl;\n  dout(10) << sizeof(CInode) << \"\\tCInode\" << dendl;\n  dout(10) << sizeof(elist<void*>::item) << \"\\t elist<>::item   *7=\" << 7*sizeof(elist<void*>::item) << dendl;\n  dout(10) << sizeof(CInode::mempool_inode) << \"\\t inode  \" << dendl;\n  dout(10) << sizeof(CInode::mempool_old_inode) << \"\\t old_inode \" << dendl;\n  dout(10) << sizeof(nest_info_t) << \"\\t  nest_info_t \" << dendl;\n  dout(10) << sizeof(frag_info_t) << \"\\t  frag_info_t \" << dendl;\n  dout(10) << sizeof(SimpleLock) << \"\\t SimpleLock   *5=\" << 5*sizeof(SimpleLock) << dendl;\n  dout(10) << sizeof(ScatterLock) << \"\\t ScatterLock  *3=\" << 3*sizeof(ScatterLock) << dendl;\n  dout(10) << sizeof(CDentry) << \"\\tCDentry\" << dendl;\n  dout(10) << sizeof(elist<void*>::item) << \"\\t elist<>::item\" << dendl;\n  dout(10) << sizeof(SimpleLock) << \"\\t SimpleLock\" << dendl;\n  dout(10) << sizeof(CDir) << \"\\tCDir \" << dendl;\n  dout(10) << sizeof(elist<void*>::item) << \"\\t elist<>::item   *2=\" << 2*sizeof(elist<void*>::item) << dendl;\n  dout(10) << sizeof(fnode_t) << \"\\t fnode_t \" << dendl;\n  dout(10) << sizeof(nest_info_t) << \"\\t  nest_info_t *2\" << dendl;\n  dout(10) << sizeof(frag_info_t) << \"\\t  frag_info_t *2\" << dendl;\n  dout(10) << sizeof(Capability) << \"\\tCapability \" << dendl;\n  dout(10) << sizeof(xlist<void*>::item) << \"\\t xlist<>::item   *2=\" << 2*sizeof(xlist<void*>::item) << dendl;\n\n  messenger->add_dispatcher_tail(&beacon);\n  messenger->add_dispatcher_tail(this);\n\n  // get monmap\n  monc->set_messenger(messenger);\n\n  monc->set_want_keys(CEPH_ENTITY_TYPE_MON | CEPH_ENTITY_TYPE_OSD |\n                      CEPH_ENTITY_TYPE_MDS | CEPH_ENTITY_TYPE_MGR);\n  int r = 0;\n  r = monc->init();\n  if (r < 0) {\n    derr << \"ERROR: failed to get monmap: \" << cpp_strerror(-r) << dendl;\n    mds_lock.Lock();\n    suicide();\n    mds_lock.Unlock();\n    return r;\n  }\n\n  // tell monc about log_client so it will know about mon session resets\n  monc->set_log_client(&log_client);\n\n  r = monc->authenticate();\n  if (r < 0) {\n    derr << \"ERROR: failed to authenticate: \" << cpp_strerror(-r) << dendl;\n    mds_lock.Lock();\n    suicide();\n    mds_lock.Unlock();\n    return r;\n  }\n\n  int rotating_auth_attempts = 0;\n  while (monc->wait_auth_rotating(30.0) < 0) {\n    if (++rotating_auth_attempts <= g_conf->max_rotating_auth_attempts) {\n      derr << \"unable to obtain rotating service keys; retrying\" << dendl;\n      continue;\n    }\n    derr << \"ERROR: failed to refresh rotating keys, \"\n         << \"maximum retry time reached.\" << dendl;\n    mds_lock.Lock();\n    suicide();\n    mds_lock.Unlock();\n    return -ETIMEDOUT;\n  }\n\n  mgrc.init();\n  messenger->add_dispatcher_head(&mgrc);\n\n  mds_lock.Lock();\n  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE) {\n    dout(4) << __func__ << \": terminated already, dropping out\" << dendl;\n    mds_lock.Unlock();\n    return 0;\n  }\n\n  monc->sub_want(\"mdsmap\", 0, 0);\n  monc->sub_want(\"mgrmap\", 0, 0);\n  monc->renew_subs();\n\n  mds_lock.Unlock();\n\n  // Set up admin socket before taking mds_lock, so that ordering\n  // is consistent (later we take mds_lock within asok callbacks)\n  set_up_admin_socket();\n  g_conf->add_observer(this);\n  mds_lock.Lock();\n  if (beacon.get_want_state() == MDSMap::STATE_DNE) {\n    suicide();  // we could do something more graceful here\n    dout(4) << __func__ << \": terminated already, dropping out\" << dendl;\n    mds_lock.Unlock();\n    return 0; \n  }\n\n  timer.init();\n\n  beacon.init(mdsmap);\n  messenger->set_myname(entity_name_t::MDS(MDS_RANK_NONE));\n\n  // schedule tick\n  reset_tick();\n  mds_lock.Unlock();\n\n  return 0;\n}\n\nvoid MDSDaemon::reset_tick()\n{\n  // cancel old\n  if (tick_event) timer.cancel_event(tick_event);\n\n  // schedule\n  tick_event = timer.add_event_after(\n    g_conf->mds_tick_interval,\n    new FunctionContext([this](int) {\n\tassert(mds_lock.is_locked_by_me());\n\ttick();\n      }));\n}\n\nvoid MDSDaemon::tick()\n{\n  // reschedule\n  reset_tick();\n\n  // Call through to subsystems' tick functions\n  if (mds_rank) {\n    mds_rank->tick();\n  }\n}\n\nvoid MDSDaemon::send_command_reply(MCommand *m, MDSRank *mds_rank,\n\t\t\t\t   int r, bufferlist outbl,\n\t\t\t\t   boost::string_view outs)\n{\n  Session *session = static_cast<Session *>(m->get_connection()->get_priv());\n  assert(session != NULL);\n  // If someone is using a closed session for sending commands (e.g.\n  // the ceph CLI) then we should feel free to clean up this connection\n  // as soon as we've sent them a response.\n  const bool live_session =\n    session->get_state_seq() > 0 &&\n    mds_rank &&\n    mds_rank->sessionmap.get_session(session->info.inst.name);\n\n  if (!live_session) {\n    // This session only existed to issue commands, so terminate it\n    // as soon as we can.\n    assert(session->is_closed());\n    session->connection->mark_disposable();\n  }\n  session->put();\n\n  MCommandReply *reply = new MCommandReply(r, outs);\n  reply->set_tid(m->get_tid());\n  reply->set_data(outbl);\n  m->get_connection()->send_message(reply);\n}\n\n/* This function DOES put the passed message before returning*/\nvoid MDSDaemon::handle_command(MCommand *m)\n{\n  Session *session = static_cast<Session *>(m->get_connection()->get_priv());\n  assert(session != NULL);\n\n  int r = 0;\n  cmdmap_t cmdmap;\n  std::stringstream ss;\n  std::string outs;\n  bufferlist outbl;\n  Context *run_after = NULL;\n  bool need_reply = true;\n\n  if (!session->auth_caps.allow_all()) {\n    dout(1) << __func__\n      << \": received command from client without `tell` capability: \"\n      << m->get_connection()->peer_addr << dendl;\n\n    ss << \"permission denied\";\n    r = -EPERM;\n  } else if (m->cmd.empty()) {\n    r = -EINVAL;\n    ss << \"no command given\";\n    outs = ss.str();\n  } else if (!cmdmap_from_json(m->cmd, &cmdmap, ss)) {\n    r = -EINVAL;\n    outs = ss.str();\n  } else {\n    r = _handle_command(cmdmap, m, &outbl, &outs, &run_after, &need_reply);\n  }\n  session->put();\n\n  if (need_reply) {\n    send_command_reply(m, mds_rank, r, outbl, outs);\n  }\n\n  if (run_after) {\n    run_after->complete(0);\n  }\n\n  m->put();\n}\n\n\nstruct MDSCommand {\n  string cmdstring;\n  string helpstring;\n  string module;\n  string perm;\n  string availability;\n} mds_commands[] = {\n\n#define COMMAND(parsesig, helptext, module, perm, availability) \\\n  {parsesig, helptext, module, perm, availability},\n\nCOMMAND(\"injectargs \" \\\n\t\"name=injected_args,type=CephString,n=N\",\n\t\"inject configuration arguments into running MDS\",\n\t\"mds\", \"*\", \"cli,rest\")\nCOMMAND(\"config set \" \\\n\t\"name=key,type=CephString name=value,type=CephString\",\n\t\"Set a configuration option at runtime (not persistent)\",\n\t\"mds\", \"*\", \"cli,rest\")\nCOMMAND(\"exit\",\n\t\"Terminate this MDS\",\n\t\"mds\", \"*\", \"cli,rest\")\nCOMMAND(\"respawn\",\n\t\"Restart this MDS\",\n\t\"mds\", \"*\", \"cli,rest\")\nCOMMAND(\"session kill \" \\\n        \"name=session_id,type=CephInt\",\n\t\"End a client session\",\n\t\"mds\", \"*\", \"cli,rest\")\nCOMMAND(\"cpu_profiler \" \\\n\t\"name=arg,type=CephChoices,strings=status|flush\",\n\t\"run cpu profiling on daemon\", \"mds\", \"rw\", \"cli,rest\")\nCOMMAND(\"session ls \" \\\n\t\"name=filters,type=CephString,n=N,req=false\",\n\t\"List client sessions\", \"mds\", \"r\", \"cli,rest\")\nCOMMAND(\"client ls \" \\\n\t\"name=filters,type=CephString,n=N,req=false\",\n\t\"List client sessions\", \"mds\", \"r\", \"cli,rest\")\nCOMMAND(\"session evict \" \\\n\t\"name=filters,type=CephString,n=N,req=false\",\n\t\"Evict client session(s)\", \"mds\", \"rw\", \"cli,rest\")\nCOMMAND(\"client evict \" \\\n\t\"name=filters,type=CephString,n=N,req=false\",\n\t\"Evict client session(s)\", \"mds\", \"rw\", \"cli,rest\")\nCOMMAND(\"damage ls\",\n\t\"List detected metadata damage\", \"mds\", \"r\", \"cli,rest\")\nCOMMAND(\"damage rm name=damage_id,type=CephInt\",\n\t\"Remove a damage table entry\", \"mds\", \"rw\", \"cli,rest\")\nCOMMAND(\"version\", \"report version of MDS\", \"mds\", \"r\", \"cli,rest\")\nCOMMAND(\"heap \" \\\n\t\"name=heapcmd,type=CephChoices,strings=dump|start_profiler|stop_profiler|release|stats\", \\\n\t\"show heap usage info (available only if compiled with tcmalloc)\", \\\n\t\"mds\", \"*\", \"cli,rest\")\n};\n\n\nint MDSDaemon::_handle_command(\n    const cmdmap_t &cmdmap,\n    MCommand *m,\n    bufferlist *outbl,\n    std::string *outs,\n    Context **run_later,\n    bool *need_reply)\n{\n  assert(outbl != NULL);\n  assert(outs != NULL);\n\n  class SuicideLater : public Context\n  {\n    MDSDaemon *mds;\n\n    public:\n    explicit SuicideLater(MDSDaemon *mds_) : mds(mds_) {}\n    void finish(int r) override {\n      // Wait a little to improve chances of caller getting\n      // our response before seeing us disappear from mdsmap\n      sleep(1);\n\n      mds->suicide();\n    }\n  };\n\n\n  class RespawnLater : public Context\n  {\n    MDSDaemon *mds;\n\n    public:\n\n    explicit RespawnLater(MDSDaemon *mds_) : mds(mds_) {}\n    void finish(int r) override {\n      // Wait a little to improve chances of caller getting\n      // our response before seeing us disappear from mdsmap\n      sleep(1);\n\n      mds->respawn();\n    }\n  };\n\n  std::stringstream ds;\n  std::stringstream ss;\n  std::string prefix;\n  std::string format;\n  std::unique_ptr<Formatter> f(Formatter::create(format));\n  cmd_getval(cct, cmdmap, \"prefix\", prefix);\n\n  int r = 0;\n\n  if (prefix == \"get_command_descriptions\") {\n    int cmdnum = 0;\n    std::unique_ptr<JSONFormatter> f(ceph::make_unique<JSONFormatter>());\n    f->open_object_section(\"command_descriptions\");\n    for (MDSCommand *cp = mds_commands;\n\t cp < &mds_commands[ARRAY_SIZE(mds_commands)]; cp++) {\n\n      ostringstream secname;\n      secname << \"cmd\" << setfill('0') << std::setw(3) << cmdnum;\n      dump_cmddesc_to_json(f.get(), secname.str(), cp->cmdstring, cp->helpstring,\n\t\t\t   cp->module, cp->perm, cp->availability, 0);\n      cmdnum++;\n    }\n    f->close_section();\t// command_descriptions\n\n    f->flush(ds);\n    goto out; \n  }\n\n  cmd_getval(cct, cmdmap, \"format\", format);\n  if (prefix == \"version\") {\n    if (f) {\n      f->open_object_section(\"version\");\n      f->dump_string(\"version\", pretty_version_to_str());\n      f->close_section();\n      f->flush(ds);\n    } else {\n      ds << pretty_version_to_str();\n    }\n  } else if (prefix == \"injectargs\") {\n    vector<string> argsvec;\n    cmd_getval(cct, cmdmap, \"injected_args\", argsvec);\n\n    if (argsvec.empty()) {\n      r = -EINVAL;\n      ss << \"ignoring empty injectargs\";\n      goto out;\n    }\n    string args = argsvec.front();\n    for (vector<string>::iterator a = ++argsvec.begin(); a != argsvec.end(); ++a)\n      args += \" \" + *a;\n    r = cct->_conf->injectargs(args, &ss);\n  } else if (prefix == \"config set\") {\n    std::string key;\n    cmd_getval(cct, cmdmap, \"key\", key);\n    std::string val;\n    cmd_getval(cct, cmdmap, \"value\", val);\n    r = cct->_conf->set_val(key, val, true, &ss);\n    if (r == 0) {\n      cct->_conf->apply_changes(nullptr);\n    }\n  } else if (prefix == \"exit\") {\n    // We will send response before executing\n    ss << \"Exiting...\";\n    *run_later = new SuicideLater(this);\n  } else if (prefix == \"respawn\") {\n    // We will send response before executing\n    ss << \"Respawning...\";\n    *run_later = new RespawnLater(this);\n  } else if (prefix == \"session kill\") {\n    if (mds_rank == NULL) {\n      r = -EINVAL;\n      ss << \"MDS not active\";\n      goto out;\n    }\n    // FIXME harmonize `session kill` with admin socket session evict\n    int64_t session_id = 0;\n    bool got = cmd_getval(cct, cmdmap, \"session_id\", session_id);\n    assert(got);\n    bool killed = mds_rank->evict_client(session_id, false,\n                                         g_conf->mds_session_blacklist_on_evict,\n                                         ss);\n    if (!killed)\n      r = -ENOENT;\n  } else if (prefix == \"heap\") {\n    if (!ceph_using_tcmalloc()) {\n      r = -EOPNOTSUPP;\n      ss << \"could not issue heap profiler command -- not using tcmalloc!\";\n    } else {\n      string heapcmd;\n      cmd_getval(cct, cmdmap, \"heapcmd\", heapcmd);\n      vector<string> heapcmd_vec;\n      get_str_vec(heapcmd, heapcmd_vec);\n      ceph_heap_profiler_handle_command(heapcmd_vec, ds);\n    }\n  } else if (prefix == \"cpu_profiler\") {\n    string arg;\n    cmd_getval(cct, cmdmap, \"arg\", arg);\n    vector<string> argvec;\n    get_str_vec(arg, argvec);\n    cpu_profiler_handle_command(argvec, ds);\n  } else {\n    // Give MDSRank a shot at the command\n    if (!mds_rank) {\n      ss << \"MDS not active\";\n      r = -EINVAL;\n    }\n    else {\n      bool handled = mds_rank->handle_command(cmdmap, m, &r, &ds, &ss,\n\t\t\t\t\t      need_reply);\n      if (!handled) {\n        // MDSDaemon doesn't know this command\n        ss << \"unrecognized command! \" << prefix;\n        r = -EINVAL;\n      }\n    }\n  }\n\nout:\n  *outs = ss.str();\n  outbl->append(ds);\n  return r;\n}\n\n/* This function deletes the passed message before returning. */\n\nvoid MDSDaemon::handle_mds_map(MMDSMap *m)\n{\n  version_t epoch = m->get_epoch();\n  dout(5) << \"handle_mds_map epoch \" << epoch << \" from \" << m->get_source() << dendl;\n\n  // is it new?\n  if (epoch <= mdsmap->get_epoch()) {\n    dout(5) << \" old map epoch \" << epoch << \" <= \" << mdsmap->get_epoch()\n\t    << \", discarding\" << dendl;\n    m->put();\n    return;\n  }\n\n  entity_addr_t addr;\n\n  // keep old map, for a moment\n  MDSMap *oldmap = mdsmap;\n\n  // decode and process\n  mdsmap = new MDSMap;\n  mdsmap->decode(m->get_encoded());\n  const MDSMap::DaemonState new_state = mdsmap->get_state_gid(mds_gid_t(monc->get_global_id()));\n  const int incarnation = mdsmap->get_inc_gid(mds_gid_t(monc->get_global_id()));\n\n  monc->sub_got(\"mdsmap\", mdsmap->get_epoch());\n\n  // Calculate my effective rank (either my owned rank or my\n  // standby_for_rank if in standby replay)\n  mds_rank_t whoami = mdsmap->get_rank_gid(mds_gid_t(monc->get_global_id()));\n\n  // verify compatset\n  CompatSet mdsmap_compat(get_mdsmap_compat_set_all());\n  dout(10) << \"     my compat \" << mdsmap_compat << dendl;\n  dout(10) << \" mdsmap compat \" << mdsmap->compat << dendl;\n  if (!mdsmap_compat.writeable(mdsmap->compat)) {\n    dout(0) << \"handle_mds_map mdsmap compatset \" << mdsmap->compat\n\t    << \" not writeable with daemon features \" << mdsmap_compat\n\t    << \", killing myself\" << dendl;\n    suicide();\n    goto out;\n  }\n\n  // mark down any failed peers\n  for (map<mds_gid_t,MDSMap::mds_info_t>::const_iterator p = oldmap->get_mds_info().begin();\n       p != oldmap->get_mds_info().end();\n       ++p) {\n    if (mdsmap->get_mds_info().count(p->first) == 0) {\n      dout(10) << \" peer mds gid \" << p->first << \" removed from map\" << dendl;\n      messenger->mark_down(p->second.addr);\n    }\n  }\n\n  if (whoami == MDS_RANK_NONE && \n      new_state == MDSMap::STATE_STANDBY_REPLAY) {\n    whoami = mdsmap->get_mds_info_gid(mds_gid_t(monc->get_global_id())).standby_for_rank;\n  }\n\n  // see who i am\n  addr = messenger->get_myaddr();\n  dout(10) << \"map says I am \" << addr << \" mds.\" << whoami << \".\" << incarnation\n\t   << \" state \" << ceph_mds_state_name(new_state) << dendl;\n\n  if (whoami == MDS_RANK_NONE) {\n    if (mds_rank != NULL) {\n      const auto myid = monc->get_global_id();\n      // We have entered a rank-holding state, we shouldn't be back\n      // here!\n      if (g_conf->mds_enforce_unique_name) {\n        if (mds_gid_t existing = mdsmap->find_mds_gid_by_name(name)) {\n          const MDSMap::mds_info_t& i = mdsmap->get_info_gid(existing);\n          if (i.global_id > myid) {\n            dout(1) << \"map replaced me with another mds.\" << whoami\n                    << \" with gid (\" << i.global_id << \") larger than myself (\"\n                    << myid << \"); quitting!\" << dendl;\n            // Call suicide() rather than respawn() because if someone else\n            // has taken our ID, we don't want to keep restarting and\n            // fighting them for the ID.\n            suicide();\n            m->put();\n            return;\n          }\n        }\n      }\n\n      dout(1) << \"map removed me (mds.\" << whoami << \" gid:\"\n              << myid << \") from cluster due to lost contact; respawning\" << dendl;\n      respawn();\n    }\n    // MDSRank not active: process the map here to see if we have\n    // been assigned a rank.\n    dout(10) <<  __func__ << \": handling map in rankless mode\" << dendl;\n    _handle_mds_map(oldmap);\n  } else {\n\n    // Did we already hold a different rank?  MDSMonitor shouldn't try\n    // to change that out from under me!\n    if (mds_rank && whoami != mds_rank->get_nodeid()) {\n      derr << \"Invalid rank transition \" << mds_rank->get_nodeid() << \"->\"\n           << whoami << dendl;\n      respawn();\n    }\n\n    // Did I previously not hold a rank?  Initialize!\n    if (mds_rank == NULL) {\n      mds_rank = new MDSRankDispatcher(whoami, mds_lock, clog,\n          timer, beacon, mdsmap, messenger, monc,\n          new FunctionContext([this](int r){respawn();}),\n          new FunctionContext([this](int r){suicide();}));\n      dout(10) <<  __func__ << \": initializing MDS rank \"\n               << mds_rank->get_nodeid() << dendl;\n      mds_rank->init();\n    }\n\n    // MDSRank is active: let him process the map, we have no say.\n    dout(10) <<  __func__ << \": handling map as rank \"\n             << mds_rank->get_nodeid() << dendl;\n    mds_rank->handle_mds_map(m, oldmap);\n  }\n\nout:\n  beacon.notify_mdsmap(mdsmap);\n  m->put();\n  delete oldmap;\n}\n\nvoid MDSDaemon::_handle_mds_map(MDSMap *oldmap)\n{\n  MDSMap::DaemonState new_state = mdsmap->get_state_gid(mds_gid_t(monc->get_global_id()));\n\n  // Normal rankless case, we're marked as standby\n  if (new_state == MDSMap::STATE_STANDBY) {\n    beacon.set_want_state(mdsmap, new_state);\n    dout(1) << \"handle_mds_map standby\" << dendl;\n\n    return;\n  }\n\n  // Case where we thought we were standby, but MDSMap disagrees\n  if (beacon.get_want_state() == MDSMap::STATE_STANDBY) {\n    dout(10) << \"dropped out of mdsmap, try to re-add myself\" << dendl;\n    new_state = MDSMap::STATE_BOOT;\n    beacon.set_want_state(mdsmap, new_state);\n    return;\n  }\n\n  // Case where we have sent a boot beacon that isn't reflected yet\n  if (beacon.get_want_state() == MDSMap::STATE_BOOT) {\n    dout(10) << \"not in map yet\" << dendl;\n  }\n}\n\nvoid MDSDaemon::handle_signal(int signum)\n{\n  assert(signum == SIGINT || signum == SIGTERM);\n  derr << \"*** got signal \" << sig_str(signum) << \" ***\" << dendl;\n  {\n    Mutex::Locker l(mds_lock);\n    if (stopping) {\n      return;\n    }\n    suicide();\n  }\n}\n\nvoid MDSDaemon::suicide()\n{\n  assert(mds_lock.is_locked());\n  \n  // make sure we don't suicide twice\n  assert(stopping == false);\n  stopping = true;\n\n  dout(1) << \"suicide.  wanted state \"\n          << ceph_mds_state_name(beacon.get_want_state()) << dendl;\n\n  if (tick_event) {\n    timer.cancel_event(tick_event);\n    tick_event = 0;\n  }\n\n  //because add_observer is called after set_up_admin_socket\n  //so we can use asok_hook to avoid assert in the remove_observer\n  if (asok_hook != NULL)\n    g_conf->remove_observer(this);\n\n  clean_up_admin_socket();\n\n  // Inform MDS we are going away, then shut down beacon\n  beacon.set_want_state(mdsmap, MDSMap::STATE_DNE);\n  if (!mdsmap->is_dne_gid(mds_gid_t(monc->get_global_id()))) {\n    // Notify the MDSMonitor that we're dying, so that it doesn't have to\n    // wait for us to go laggy.  Only do this if we're actually in the\n    // MDSMap, because otherwise the MDSMonitor will drop our message.\n    beacon.send_and_wait(1);\n  }\n  beacon.shutdown();\n\n  mgrc.shutdown();\n\n  if (mds_rank) {\n    mds_rank->shutdown();\n  } else {\n    timer.shutdown();\n\n    monc->shutdown();\n    messenger->shutdown();\n  }\n}\n\nvoid MDSDaemon::respawn()\n{\n  dout(1) << \"respawn\" << dendl;\n\n  char *new_argv[orig_argc+1];\n  dout(1) << \" e: '\" << orig_argv[0] << \"'\" << dendl;\n  for (int i=0; i<orig_argc; i++) {\n    new_argv[i] = (char *)orig_argv[i];\n    dout(1) << \" \" << i << \": '\" << orig_argv[i] << \"'\" << dendl;\n  }\n  new_argv[orig_argc] = NULL;\n\n  /* Determine the path to our executable, test if Linux /proc/self/exe exists.\n   * This allows us to exec the same executable even if it has since been\n   * unlinked.\n   */\n  char exe_path[PATH_MAX] = \"\";\n  if (readlink(PROCPREFIX \"/proc/self/exe\", exe_path, PATH_MAX-1) == -1) {\n    /* Print CWD for the user's interest */\n    char buf[PATH_MAX];\n    char *cwd = getcwd(buf, sizeof(buf));\n    assert(cwd);\n    dout(1) << \" cwd \" << cwd << dendl;\n\n    /* Fall back to a best-effort: just running in our CWD */\n    strncpy(exe_path, orig_argv[0], PATH_MAX-1);\n  } else {\n    dout(1) << \"respawning with exe \" << exe_path << dendl;\n    strcpy(exe_path, PROCPREFIX \"/proc/self/exe\");\n  }\n\n  dout(1) << \" exe_path \" << exe_path << dendl;\n\n  unblock_all_signals(NULL);\n  execv(exe_path, new_argv);\n\n  dout(0) << \"respawn execv \" << orig_argv[0]\n\t  << \" failed with \" << cpp_strerror(errno) << dendl;\n\n  // We have to assert out here, because suicide() returns, and callers\n  // to respawn expect it never to return.\n  ceph_abort();\n}\n\n\n\nbool MDSDaemon::ms_dispatch(Message *m)\n{\n  Mutex::Locker l(mds_lock);\n  if (stopping) {\n    return false;\n  }\n\n  // Drop out early if shutting down\n  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE) {\n    dout(10) << \" stopping, discarding \" << *m << dendl;\n    m->put();\n    return true;\n  }\n\n  // First see if it's a daemon message\n  const bool handled_core = handle_core_message(m);\n  if (handled_core) {\n    return true;\n  }\n\n  // Not core, try it as a rank message\n  if (mds_rank) {\n    return mds_rank->ms_dispatch(m);\n  } else {\n    return false;\n  }\n}\n\nbool MDSDaemon::ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new)\n{\n  dout(10) << \"MDSDaemon::ms_get_authorizer type=\"\n           << ceph_entity_type_name(dest_type) << dendl;\n\n  /* monitor authorization is being handled on different layer */\n  if (dest_type == CEPH_ENTITY_TYPE_MON)\n    return true;\n\n  if (force_new) {\n    if (monc->wait_auth_rotating(10) < 0)\n      return false;\n  }\n\n  *authorizer = monc->build_authorizer(dest_type);\n  return *authorizer != NULL;\n}\n\n\n/*\n * high priority messages we always process\n */\nbool MDSDaemon::handle_core_message(Message *m)\n{\n  switch (m->get_type()) {\n  case CEPH_MSG_MON_MAP:\n    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON);\n    m->put();\n    break;\n\n    // MDS\n  case CEPH_MSG_MDS_MAP:\n    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON | CEPH_ENTITY_TYPE_MDS);\n    handle_mds_map(static_cast<MMDSMap*>(m));\n    break;\n\n    // OSD\n  case MSG_COMMAND:\n    handle_command(static_cast<MCommand*>(m));\n    break;\n  case CEPH_MSG_OSD_MAP:\n    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON | CEPH_ENTITY_TYPE_OSD);\n\n    if (mds_rank) {\n      mds_rank->handle_osd_map();\n    }\n    m->put();\n    break;\n\n  case MSG_MON_COMMAND:\n    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON);\n    clog->warn() << \"dropping `mds tell` command from legacy monitor\";\n    m->put();\n    break;\n\n  default:\n    return false;\n  }\n  return true;\n}\n\nvoid MDSDaemon::ms_handle_connect(Connection *con)\n{\n}\n\nbool MDSDaemon::ms_handle_reset(Connection *con)\n{\n  if (con->get_peer_type() != CEPH_ENTITY_TYPE_CLIENT)\n    return false;\n\n  Mutex::Locker l(mds_lock);\n  if (stopping) {\n    return false;\n  }\n  dout(5) << \"ms_handle_reset on \" << con->get_peer_addr() << dendl;\n  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE)\n    return false;\n\n  Session *session = static_cast<Session *>(con->get_priv());\n  if (session) {\n    if (session->is_closed()) {\n      dout(3) << \"ms_handle_reset closing connection for session \" << session->info.inst << dendl;\n      con->mark_down();\n      con->set_priv(NULL);\n    }\n    session->put();\n  } else {\n    con->mark_down();\n  }\n  return false;\n}\n\n\nvoid MDSDaemon::ms_handle_remote_reset(Connection *con)\n{\n  if (con->get_peer_type() != CEPH_ENTITY_TYPE_CLIENT)\n    return;\n\n  Mutex::Locker l(mds_lock);\n  if (stopping) {\n    return;\n  }\n\n  dout(5) << \"ms_handle_remote_reset on \" << con->get_peer_addr() << dendl;\n  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE)\n    return;\n\n  Session *session = static_cast<Session *>(con->get_priv());\n  if (session) {\n    if (session->is_closed()) {\n      dout(3) << \"ms_handle_remote_reset closing connection for session \" << session->info.inst << dendl;\n      con->mark_down();\n      con->set_priv(NULL);\n    }\n    session->put();\n  }\n}\n\nbool MDSDaemon::ms_handle_refused(Connection *con)\n{\n  // do nothing for now\n  return false;\n}\n\nbool MDSDaemon::ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t       int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t       bool& is_valid, CryptoKey& session_key)\n{\n  Mutex::Locker l(mds_lock);\n  if (stopping) {\n    return false;\n  }\n  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE)\n    return false;\n\n  AuthAuthorizeHandler *authorize_handler = 0;\n  switch (peer_type) {\n  case CEPH_ENTITY_TYPE_MDS:\n    authorize_handler = authorize_handler_cluster_registry->get_handler(protocol);\n    break;\n  default:\n    authorize_handler = authorize_handler_service_registry->get_handler(protocol);\n  }\n  if (!authorize_handler) {\n    dout(0) << \"No AuthAuthorizeHandler found for protocol \" << protocol << dendl;\n    is_valid = false;\n    return true;\n  }\n\n  AuthCapsInfo caps_info;\n  EntityName name;\n  uint64_t global_id;\n\n  RotatingKeyRing *keys = monc->rotating_secrets.get();\n  if (keys) {\n    is_valid = authorize_handler->verify_authorizer(\n      cct, keys,\n      authorizer_data, authorizer_reply, name, global_id, caps_info,\n      session_key);\n  } else {\n    dout(10) << __func__ << \" no rotating_keys (yet), denied\" << dendl;\n    is_valid = false;\n  }\n\n  if (is_valid) {\n    entity_name_t n(con->get_peer_type(), global_id);\n\n    // We allow connections and assign Session instances to connections\n    // even if we have not been assigned a rank, because clients with\n    // \"allow *\" are allowed to connect and do 'tell' operations before\n    // we have a rank.\n    Session *s = NULL;\n    if (mds_rank) {\n      // If we do hold a rank, see if this is an existing client establishing\n      // a new connection, rather than a new client\n      s = mds_rank->sessionmap.get_session(n);\n    }\n\n    // Wire up a Session* to this connection\n    // It doesn't go into a SessionMap instance until it sends an explicit\n    // request to open a session (initial state of Session is `closed`)\n    if (!s) {\n      s = new Session;\n      s->info.auth_name = name;\n      s->info.inst.addr = con->get_peer_addr();\n      s->info.inst.name = n;\n      dout(10) << \" new session \" << s << \" for \" << s->info.inst << \" con \" << con << dendl;\n      con->set_priv(s);\n      s->connection = con;\n    } else {\n      dout(10) << \" existing session \" << s << \" for \" << s->info.inst << \" existing con \" << s->connection\n\t       << \", new/authorizing con \" << con << dendl;\n      con->set_priv(s->get());\n\n\n\n      // Wait until we fully accept the connection before setting\n      // s->connection.  In particular, if there are multiple incoming\n      // connection attempts, they will all get their authorizer\n      // validated, but some of them may \"lose the race\" and get\n      // dropped.  We only want to consider the winner(s).  See\n      // ms_handle_accept().  This is important for Sessions we replay\n      // from the journal on recovery that don't have established\n      // messenger state; we want the con from only the winning\n      // connect attempt(s).  (Normal reconnects that don't follow MDS\n      // recovery are reconnected to the existing con by the\n      // messenger.)\n    }\n\n    if (caps_info.allow_all) {\n      // Flag for auth providers that don't provide cap strings\n      s->auth_caps.set_allow_all();\n    } else {\n      bufferlist::iterator p = caps_info.caps.begin();\n      string auth_cap_str;\n      try {\n        ::decode(auth_cap_str, p);\n\n        dout(10) << __func__ << \": parsing auth_cap_str='\" << auth_cap_str << \"'\" << dendl;\n        std::ostringstream errstr;\n        if (!s->auth_caps.parse(g_ceph_context, auth_cap_str, &errstr)) {\n          dout(1) << __func__ << \": auth cap parse error: \" << errstr.str()\n\t\t  << \" parsing '\" << auth_cap_str << \"'\" << dendl;\n\t  clog->warn() << name << \" mds cap '\" << auth_cap_str\n\t\t       << \"' does not parse: \" << errstr.str();\n          is_valid = false;\n        }\n      } catch (buffer::error& e) {\n        // Assume legacy auth, defaults to:\n        //  * permit all filesystem ops\n        //  * permit no `tell` ops\n        dout(1) << __func__ << \": cannot decode auth caps bl of length \" << caps_info.caps.length() << dendl;\n        is_valid = false;\n      }\n    }\n  }\n\n  return true;  // we made a decision (see is_valid)\n}\n\n\nvoid MDSDaemon::ms_handle_accept(Connection *con)\n{\n  Mutex::Locker l(mds_lock);\n  if (stopping) {\n    return;\n  }\n\n  Session *s = static_cast<Session *>(con->get_priv());\n  dout(10) << \"ms_handle_accept \" << con->get_peer_addr() << \" con \" << con << \" session \" << s << dendl;\n  if (s) {\n    if (s->connection != con) {\n      dout(10) << \" session connection \" << s->connection << \" -> \" << con << dendl;\n      s->connection = con;\n\n      // send out any queued messages\n      while (!s->preopen_out_queue.empty()) {\n\tcon->send_message(s->preopen_out_queue.front());\n\ts->preopen_out_queue.pop_front();\n      }\n    }\n    s->put();\n  }\n}\n\nbool MDSDaemon::is_clean_shutdown()\n{\n  if (mds_rank) {\n    return mds_rank->is_stopped();\n  } else {\n    return true;\n  }\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_MDS_H\n#define CEPH_MDS_H\n\n#include <boost/utility/string_view.hpp>\n\n#include \"common/LogClient.h\"\n#include \"common/Mutex.h\"\n#include \"common/Timer.h\"\n#include \"include/Context.h\"\n#include \"include/types.h\"\n#include \"mgr/MgrClient.h\"\n#include \"msg/Dispatcher.h\"\n\n#include \"Beacon.h\"\n#include \"MDSMap.h\"\n#include \"MDSRank.h\"\n\n#define CEPH_MDS_PROTOCOL    30 /* cluster internal */\n\nclass AuthAuthorizeHandlerRegistry;\nclass Message;\nclass Messenger;\nclass MonClient;\n\nclass MDSDaemon : public Dispatcher, public md_config_obs_t {\n public:\n  /* Global MDS lock: every time someone takes this, they must\n   * also check the `stopping` flag.  If stopping is true, you\n   * must either do nothing and immediately drop the lock, or\n   * never drop the lock again (i.e. call respawn()) */\n  Mutex        mds_lock;\n  bool         stopping;\n\n  SafeTimer    timer;\n\n\n  mono_time get_starttime() const {\n    return starttime;\n  }\n  chrono::duration<double> get_uptime() const {\n    mono_time now = mono_clock::now();\n    return chrono::duration<double>(now-starttime);\n  }\n\n protected:\n  Beacon  beacon;\n\n  AuthAuthorizeHandlerRegistry *authorize_handler_cluster_registry;\n  AuthAuthorizeHandlerRegistry *authorize_handler_service_registry;\n\n  std::string name;\n\n  Messenger    *messenger;\n  MonClient    *monc;\n  MgrClient     mgrc;\n  MDSMap       *mdsmap;\n  LogClient    log_client;\n  LogChannelRef clog;\n\n  MDSRankDispatcher *mds_rank;\n\n public:\n  MDSDaemon(boost::string_view n, Messenger *m, MonClient *mc);\n  ~MDSDaemon() override;\n  int orig_argc;\n  const char **orig_argv;\n\n  // handle a signal (e.g., SIGTERM)\n  void handle_signal(int signum);\n\n  int init();\n\n  /**\n   * Hint at whether we were shutdown gracefully (i.e. we were only\n   * in standby, or our rank was stopped).  Should be removed once\n   * we handle shutdown properly (e.g. clear out all message queues)\n   * such that deleting xlists doesn't assert.\n   */\n  bool is_clean_shutdown();\n\n  // config observer bits\n  const char** get_tracked_conf_keys() const override;\n  void handle_conf_change(const struct md_config_t *conf,\n\t\t\t\t  const std::set <std::string> &changed) override;\n protected:\n  // tick and other timer fun\n  Context *tick_event = nullptr;\n  void     reset_tick();\n\n  void wait_for_omap_osds();\n\n private:\n  bool ms_dispatch(Message *m) override;\n  bool ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new) override;\n  bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t       int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t       bool& isvalid, CryptoKey& session_key) override;\n  void ms_handle_accept(Connection *con) override;\n  void ms_handle_connect(Connection *con) override;\n  bool ms_handle_reset(Connection *con) override;\n  void ms_handle_remote_reset(Connection *con) override;\n  bool ms_handle_refused(Connection *con) override;\n\n protected:\n  // admin socket handling\n  friend class MDSSocketHook;\n  class MDSSocketHook *asok_hook;\n  void set_up_admin_socket();\n  void clean_up_admin_socket();\n  void check_ops_in_flight(); // send off any slow ops to monitor\n  bool asok_command(string command, cmdmap_t& cmdmap, string format,\n\t\t    ostream& ss);\n\n  void dump_status(Formatter *f);\n\n  /**\n   * Terminate this daemon process.\n   *\n   * This function will return, but once it does so the calling thread\n   * must do no more work as all subsystems will have been shut down.\n   */\n  void suicide();\n\n  /**\n   * Start a new daemon process with the same command line parameters that\n   * this process was run with, then terminate this process\n   */\n  void respawn();\n\n  void tick();\n  \n  // messages\n  bool _dispatch(Message *m, bool new_msg);\n\nprotected:\n  bool handle_core_message(Message *m);\n  \n  // special message types\n  friend class C_MDS_Send_Command_Reply;\n  static void send_command_reply(MCommand *m, MDSRank* mds_rank, int r,\n\t\t\t\t bufferlist outbl, boost::string_view outs);\n  int _handle_command(\n      const cmdmap_t &cmdmap,\n      MCommand *m,\n      bufferlist *outbl,\n      std::string *outs,\n      Context **run_later,\n      bool *need_reply);\n  void handle_command(class MCommand *m);\n  void handle_mds_map(class MMDSMap *m);\n  void _handle_mds_map(MDSMap *oldmap);\n\nprivate:\n    mono_time starttime = mono_clock::zero();\n};\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2016 John Spray <john.spray@redhat.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n */\n\n#include \"DaemonServer.h\"\n#include \"mgr/Mgr.h\"\n\n#include \"include/stringify.h\"\n#include \"include/str_list.h\"\n#include \"auth/RotatingKeyRing.h\"\n#include \"json_spirit/json_spirit_writer.h\"\n\n#include \"mgr/mgr_commands.h\"\n#include \"mgr/OSDHealthMetricCollector.h\"\n#include \"mon/MonCommand.h\"\n\n#include \"messages/MMgrOpen.h\"\n#include \"messages/MMgrConfigure.h\"\n#include \"messages/MMonMgrReport.h\"\n#include \"messages/MCommand.h\"\n#include \"messages/MCommandReply.h\"\n#include \"messages/MPGStats.h\"\n#include \"messages/MOSDScrub.h\"\n#include \"messages/MOSDForceRecovery.h\"\n#include \"common/errno.h\"\n\n#define dout_context g_ceph_context\n#define dout_subsys ceph_subsys_mgr\n#undef dout_prefix\n#define dout_prefix *_dout << \"mgr.server \" << __func__ << \" \"\n\n\n\nDaemonServer::DaemonServer(MonClient *monc_,\n                           Finisher &finisher_,\n\t\t\t   DaemonStateIndex &daemon_state_,\n\t\t\t   ClusterState &cluster_state_,\n\t\t\t   PyModuleRegistry &py_modules_,\n\t\t\t   LogChannelRef clog_,\n\t\t\t   LogChannelRef audit_clog_)\n    : Dispatcher(g_ceph_context),\n      client_byte_throttler(new Throttle(g_ceph_context, \"mgr_client_bytes\",\n\t\t\t\t\t g_conf->get_val<uint64_t>(\"mgr_client_bytes\"))),\n      client_msg_throttler(new Throttle(g_ceph_context, \"mgr_client_messages\",\n\t\t\t\t\tg_conf->get_val<uint64_t>(\"mgr_client_messages\"))),\n      osd_byte_throttler(new Throttle(g_ceph_context, \"mgr_osd_bytes\",\n\t\t\t\t      g_conf->get_val<uint64_t>(\"mgr_osd_bytes\"))),\n      osd_msg_throttler(new Throttle(g_ceph_context, \"mgr_osd_messsages\",\n\t\t\t\t     g_conf->get_val<uint64_t>(\"mgr_osd_messages\"))),\n      mds_byte_throttler(new Throttle(g_ceph_context, \"mgr_mds_bytes\",\n\t\t\t\t      g_conf->get_val<uint64_t>(\"mgr_mds_bytes\"))),\n      mds_msg_throttler(new Throttle(g_ceph_context, \"mgr_mds_messsages\",\n\t\t\t\t     g_conf->get_val<uint64_t>(\"mgr_mds_messages\"))),\n      mon_byte_throttler(new Throttle(g_ceph_context, \"mgr_mon_bytes\",\n\t\t\t\t      g_conf->get_val<uint64_t>(\"mgr_mon_bytes\"))),\n      mon_msg_throttler(new Throttle(g_ceph_context, \"mgr_mon_messsages\",\n\t\t\t\t     g_conf->get_val<uint64_t>(\"mgr_mon_messages\"))),\n      msgr(nullptr),\n      monc(monc_),\n      finisher(finisher_),\n      daemon_state(daemon_state_),\n      cluster_state(cluster_state_),\n      py_modules(py_modules_),\n      clog(clog_),\n      audit_clog(audit_clog_),\n      auth_cluster_registry(g_ceph_context,\n                    g_conf->auth_supported.empty() ?\n                      g_conf->auth_cluster_required :\n                      g_conf->auth_supported),\n      auth_service_registry(g_ceph_context,\n                   g_conf->auth_supported.empty() ?\n                      g_conf->auth_service_required :\n                      g_conf->auth_supported),\n      lock(\"DaemonServer\"),\n      pgmap_ready(false)\n{\n  g_conf->add_observer(this);\n}\n\nDaemonServer::~DaemonServer() {\n  delete msgr;\n  g_conf->remove_observer(this);\n}\n\nint DaemonServer::init(uint64_t gid, entity_addr_t client_addr)\n{\n  // Initialize Messenger\n  std::string public_msgr_type = g_conf->ms_public_type.empty() ?\n    g_conf->get_val<std::string>(\"ms_type\") : g_conf->ms_public_type;\n  msgr = Messenger::create(g_ceph_context, public_msgr_type,\n\t\t\t   entity_name_t::MGR(gid),\n\t\t\t   \"mgr\",\n\t\t\t   getpid(), 0);\n  msgr->set_default_policy(Messenger::Policy::stateless_server(0));\n\n  // throttle clients\n  msgr->set_policy_throttlers(entity_name_t::TYPE_CLIENT,\n\t\t\t      client_byte_throttler.get(),\n\t\t\t      client_msg_throttler.get());\n\n  // servers\n  msgr->set_policy_throttlers(entity_name_t::TYPE_OSD,\n\t\t\t      osd_byte_throttler.get(),\n\t\t\t      osd_msg_throttler.get());\n  msgr->set_policy_throttlers(entity_name_t::TYPE_MDS,\n\t\t\t      mds_byte_throttler.get(),\n\t\t\t      mds_msg_throttler.get());\n  msgr->set_policy_throttlers(entity_name_t::TYPE_MON,\n\t\t\t      mon_byte_throttler.get(),\n\t\t\t      mon_msg_throttler.get());\n\n  int r = msgr->bind(g_conf->public_addr);\n  if (r < 0) {\n    derr << \"unable to bind mgr to \" << g_conf->public_addr << dendl;\n    return r;\n  }\n\n  msgr->set_myname(entity_name_t::MGR(gid));\n  msgr->set_addr_unknowns(client_addr);\n\n  msgr->start();\n  msgr->add_dispatcher_tail(this);\n\n  started_at = ceph_clock_now();\n\n  return 0;\n}\n\nentity_addr_t DaemonServer::get_myaddr() const\n{\n  return msgr->get_myaddr();\n}\n\n\nbool DaemonServer::ms_verify_authorizer(Connection *con,\n    int peer_type,\n    int protocol,\n    ceph::bufferlist& authorizer_data,\n    ceph::bufferlist& authorizer_reply,\n    bool& is_valid,\n    CryptoKey& session_key)\n{\n  AuthAuthorizeHandler *handler = nullptr;\n  if (peer_type == CEPH_ENTITY_TYPE_OSD ||\n      peer_type == CEPH_ENTITY_TYPE_MON ||\n      peer_type == CEPH_ENTITY_TYPE_MDS ||\n      peer_type == CEPH_ENTITY_TYPE_MGR) {\n    handler = auth_cluster_registry.get_handler(protocol);\n  } else {\n    handler = auth_service_registry.get_handler(protocol);\n  }\n  if (!handler) {\n    dout(0) << \"No AuthAuthorizeHandler found for protocol \" << protocol << dendl;\n    is_valid = false;\n    return true;\n  }\n\n  MgrSessionRef s(new MgrSession(cct));\n  s->inst.addr = con->get_peer_addr();\n  AuthCapsInfo caps_info;\n\n  RotatingKeyRing *keys = monc->rotating_secrets.get();\n  if (keys) {\n    is_valid = handler->verify_authorizer(\n      cct, keys,\n      authorizer_data,\n      authorizer_reply, s->entity_name,\n      s->global_id, caps_info,\n      session_key);\n  } else {\n    dout(10) << __func__ << \" no rotating_keys (yet), denied\" << dendl;\n    is_valid = false;\n  }\n\n  if (is_valid) {\n    if (caps_info.allow_all) {\n      dout(10) << \" session \" << s << \" \" << s->entity_name\n\t       << \" allow_all\" << dendl;\n      s->caps.set_allow_all();\n    }\n    if (caps_info.caps.length() > 0) {\n      bufferlist::iterator p = caps_info.caps.begin();\n      string str;\n      try {\n\t::decode(str, p);\n      }\n      catch (buffer::error& e) {\n      }\n      bool success = s->caps.parse(str);\n      if (success) {\n\tdout(10) << \" session \" << s << \" \" << s->entity_name\n\t\t << \" has caps \" << s->caps << \" '\" << str << \"'\" << dendl;\n      } else {\n\tdout(10) << \" session \" << s << \" \" << s->entity_name\n\t\t << \" failed to parse caps '\" << str << \"'\" << dendl;\n\tis_valid = false;\n      }\n    }\n    con->set_priv(s->get());\n\n    if (peer_type == CEPH_ENTITY_TYPE_OSD) {\n      Mutex::Locker l(lock);\n      s->osd_id = atoi(s->entity_name.get_id().c_str());\n      dout(10) << \"registering osd.\" << s->osd_id << \" session \"\n\t       << s << \" con \" << con << dendl;\n      osd_cons[s->osd_id].insert(con);\n    }\n  }\n\n  return true;\n}\n\n\nbool DaemonServer::ms_get_authorizer(int dest_type,\n    AuthAuthorizer **authorizer, bool force_new)\n{\n  dout(10) << \"type=\" << ceph_entity_type_name(dest_type) << dendl;\n\n  if (dest_type == CEPH_ENTITY_TYPE_MON) {\n    return true;\n  }\n\n  if (force_new) {\n    if (monc->wait_auth_rotating(10) < 0)\n      return false;\n  }\n\n  *authorizer = monc->build_authorizer(dest_type);\n  dout(20) << \"got authorizer \" << *authorizer << dendl;\n  return *authorizer != NULL;\n}\n\nbool DaemonServer::ms_handle_reset(Connection *con)\n{\n  if (con->get_peer_type() == CEPH_ENTITY_TYPE_OSD) {\n    MgrSessionRef session(static_cast<MgrSession*>(con->get_priv()));\n    if (!session) {\n      return false;\n    }\n    session->put(); // SessionRef takes a ref\n    Mutex::Locker l(lock);\n    dout(10) << \"unregistering osd.\" << session->osd_id\n\t     << \"  session \" << session << \" con \" << con << dendl;\n    osd_cons[session->osd_id].erase(con);\n\n    auto iter = daemon_connections.find(con);\n    if (iter != daemon_connections.end()) {\n      daemon_connections.erase(iter);\n    }\n  }\n  return false;\n}\n\nbool DaemonServer::ms_handle_refused(Connection *con)\n{\n  // do nothing for now\n  return false;\n}\n\nbool DaemonServer::ms_dispatch(Message *m)\n{\n  // Note that we do *not* take ::lock here, in order to avoid\n  // serializing all message handling.  It's up to each handler\n  // to take whatever locks it needs.\n  switch (m->get_type()) {\n    case MSG_PGSTATS:\n      cluster_state.ingest_pgstats(static_cast<MPGStats*>(m));\n      maybe_ready(m->get_source().num());\n      m->put();\n      return true;\n    case MSG_MGR_REPORT:\n      return handle_report(static_cast<MMgrReport*>(m));\n    case MSG_MGR_OPEN:\n      return handle_open(static_cast<MMgrOpen*>(m));\n    case MSG_COMMAND:\n      return handle_command(static_cast<MCommand*>(m));\n    default:\n      dout(1) << \"Unhandled message type \" << m->get_type() << dendl;\n      return false;\n  };\n}\n\nvoid DaemonServer::maybe_ready(int32_t osd_id)\n{\n  if (pgmap_ready.load()) {\n    // Fast path: we don't need to take lock because pgmap_ready\n    // is already set\n  } else {\n    Mutex::Locker l(lock);\n\n    if (reported_osds.find(osd_id) == reported_osds.end()) {\n      dout(4) << \"initial report from osd \" << osd_id << dendl;\n      reported_osds.insert(osd_id);\n      std::set<int32_t> up_osds;\n\n      cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n          osdmap.get_up_osds(up_osds);\n      });\n\n      std::set<int32_t> unreported_osds;\n      std::set_difference(up_osds.begin(), up_osds.end(),\n                          reported_osds.begin(), reported_osds.end(),\n                          std::inserter(unreported_osds, unreported_osds.begin()));\n\n      if (unreported_osds.size() == 0) {\n        dout(4) << \"all osds have reported, sending PG state to mon\" << dendl;\n        pgmap_ready = true;\n        reported_osds.clear();\n        // Avoid waiting for next tick\n        send_report();\n      } else {\n        dout(4) << \"still waiting for \" << unreported_osds.size() << \" osds\"\n                   \" to report in before PGMap is ready\" << dendl;\n      }\n    }\n  }\n}\n\nvoid DaemonServer::shutdown()\n{\n  dout(10) << \"begin\" << dendl;\n  msgr->shutdown();\n  msgr->wait();\n  dout(10) << \"done\" << dendl;\n}\n\n\n\nbool DaemonServer::handle_open(MMgrOpen *m)\n{\n  Mutex::Locker l(lock);\n\n  DaemonKey key;\n  if (!m->service_name.empty()) {\n    key.first = m->service_name;\n  } else {\n    key.first = ceph_entity_type_name(m->get_connection()->get_peer_type());\n  }\n  key.second = m->daemon_name;\n\n  dout(4) << \"from \" << m->get_connection() << \"  \" << key << dendl;\n\n  _send_configure(m->get_connection());\n\n  DaemonStatePtr daemon;\n  if (daemon_state.exists(key)) {\n    daemon = daemon_state.get(key);\n  }\n  if (daemon) {\n    dout(20) << \"updating existing DaemonState for \" << m->daemon_name << dendl;\n    Mutex::Locker l(daemon->lock);\n    daemon->perf_counters.clear();\n  }\n\n  if (m->service_daemon) {\n    if (!daemon) {\n      dout(4) << \"constructing new DaemonState for \" << key << dendl;\n      daemon = std::make_shared<DaemonState>(daemon_state.types);\n      daemon->key = key;\n      if (m->daemon_metadata.count(\"hostname\")) {\n        daemon->hostname = m->daemon_metadata[\"hostname\"];\n      }\n      daemon_state.insert(daemon);\n    }\n    Mutex::Locker l(daemon->lock);\n    daemon->service_daemon = true;\n    daemon->metadata = m->daemon_metadata;\n    daemon->service_status = m->daemon_status;\n\n    utime_t now = ceph_clock_now();\n    auto d = pending_service_map.get_daemon(m->service_name,\n\t\t\t\t\t    m->daemon_name);\n    if (d->gid != (uint64_t)m->get_source().num()) {\n      dout(10) << \"registering \" << key << \" in pending_service_map\" << dendl;\n      d->gid = m->get_source().num();\n      d->addr = m->get_source_addr();\n      d->start_epoch = pending_service_map.epoch;\n      d->start_stamp = now;\n      d->metadata = m->daemon_metadata;\n      pending_service_map_dirty = pending_service_map.epoch;\n    }\n  }\n\n  if (m->get_connection()->get_peer_type() != entity_name_t::TYPE_CLIENT &&\n      m->service_name.empty())\n  {\n    // Store in set of the daemon/service connections, i.e. those\n    // connections that require an update in the event of stats\n    // configuration changes.\n    daemon_connections.insert(m->get_connection());\n  }\n\n  m->put();\n  return true;\n}\n\nbool DaemonServer::handle_report(MMgrReport *m)\n{\n  DaemonKey key;\n  if (!m->service_name.empty()) {\n    key.first = m->service_name;\n  } else {\n    key.first = ceph_entity_type_name(m->get_connection()->get_peer_type());\n  }\n  key.second = m->daemon_name;\n\n  dout(4) << \"from \" << m->get_connection() << \" \" << key << dendl;\n\n  if (m->get_connection()->get_peer_type() == entity_name_t::TYPE_CLIENT &&\n      m->service_name.empty()) {\n    // Clients should not be sending us stats unless they are declaring\n    // themselves to be a daemon for some service.\n    dout(4) << \"rejecting report from non-daemon client \" << m->daemon_name\n\t    << dendl;\n    m->get_connection()->mark_down();\n    m->put();\n    return true;\n  }\n\n  // Look up the DaemonState\n  DaemonStatePtr daemon;\n  if (daemon_state.exists(key)) {\n    dout(20) << \"updating existing DaemonState for \" << key << dendl;\n    daemon = daemon_state.get(key);\n  } else {\n    // we don't know the hostname at this stage, reject MMgrReport here.\n    dout(5) << \"rejecting report from \" << key << \", since we do not have its metadata now.\"\n\t    << dendl;\n\n    // issue metadata request in background\n    if (!daemon_state.is_updating(key) && \n\t(key.first == \"osd\" || key.first == \"mds\")) {\n\n      std::ostringstream oss;\n      auto c = new MetadataUpdate(daemon_state, key);\n      if (key.first == \"osd\") {\n        oss << \"{\\\"prefix\\\": \\\"osd metadata\\\", \\\"id\\\": \"\n            << key.second<< \"}\";\n\n      } else if (key.first == \"mds\") {\n        c->set_default(\"addr\", stringify(m->get_source_addr()));\n        oss << \"{\\\"prefix\\\": \\\"mds metadata\\\", \\\"who\\\": \\\"\"\n            << key.second << \"\\\"}\";\n \n      } else {\n\tceph_abort();\n      }\n\n      monc->start_mon_command({oss.str()}, {}, &c->outbl, &c->outs, c);\n    }\n    \n    {\n      Mutex::Locker l(lock);\n      // kill session\n      MgrSessionRef session(static_cast<MgrSession*>(m->get_connection()->get_priv()));\n      if (!session) {\n\treturn false;\n      }\n      m->get_connection()->mark_down();\n      session->put();\n\n      dout(10) << \"unregistering osd.\" << session->osd_id\n\t       << \"  session \" << session << \" con \" << m->get_connection() << dendl;\n      \n      if (osd_cons.find(session->osd_id) != osd_cons.end()) {\n\t   osd_cons[session->osd_id].erase(m->get_connection());\n      } \n\n      auto iter = daemon_connections.find(m->get_connection());\n      if (iter != daemon_connections.end()) {\n\tdaemon_connections.erase(iter);\n      }\n    }\n\n    return false;\n  }\n\n  // Update the DaemonState\n  assert(daemon != nullptr);\n  {\n    Mutex::Locker l(daemon->lock);\n    auto &daemon_counters = daemon->perf_counters;\n    daemon_counters.update(m);\n\n    if (daemon->service_daemon) {\n      utime_t now = ceph_clock_now();\n      if (m->daemon_status) {\n        daemon->service_status = *m->daemon_status;\n        daemon->service_status_stamp = now;\n      }\n      daemon->last_service_beacon = now;\n    } else if (m->daemon_status) {\n      derr << \"got status from non-daemon \" << key << dendl;\n    }\n    if (m->get_connection()->peer_is_osd()) {\n      // only OSD sends health_checks to me now\n      daemon->osd_health_metrics = std::move(m->osd_health_metrics);\n    }\n  }\n\n  // if there are any schema updates, notify the python modules\n  if (!m->declare_types.empty() || !m->undeclare_types.empty()) {\n    ostringstream oss;\n    oss << key.first << '.' << key.second;\n    py_modules.notify_all(\"perf_schema_update\", oss.str());\n  }\n\n  m->put();\n  return true;\n}\n\n\nvoid DaemonServer::_generate_command_map(\n  map<string,cmd_vartype>& cmdmap,\n  map<string,string> &param_str_map)\n{\n  for (map<string,cmd_vartype>::const_iterator p = cmdmap.begin();\n       p != cmdmap.end(); ++p) {\n    if (p->first == \"prefix\")\n      continue;\n    if (p->first == \"caps\") {\n      vector<string> cv;\n      if (cmd_getval(g_ceph_context, cmdmap, \"caps\", cv) &&\n\t  cv.size() % 2 == 0) {\n\tfor (unsigned i = 0; i < cv.size(); i += 2) {\n\t  string k = string(\"caps_\") + cv[i];\n\t  param_str_map[k] = cv[i + 1];\n\t}\n\tcontinue;\n      }\n    }\n    param_str_map[p->first] = cmd_vartype_stringify(p->second);\n  }\n}\n\nconst MonCommand *DaemonServer::_get_mgrcommand(\n  const string &cmd_prefix,\n  const std::vector<MonCommand> &cmds)\n{\n  const MonCommand *this_cmd = nullptr;\n  for (const auto &cmd : cmds) {\n    if (cmd.cmdstring.compare(0, cmd_prefix.size(), cmd_prefix) == 0) {\n      this_cmd = &cmd;\n      break;\n    }\n  }\n  return this_cmd;\n}\n\nbool DaemonServer::_allowed_command(\n  MgrSession *s,\n  const string &module,\n  const string &prefix,\n  const map<string,cmd_vartype>& cmdmap,\n  const map<string,string>& param_str_map,\n  const MonCommand *this_cmd) {\n\n  if (s->entity_name.is_mon()) {\n    // mon is all-powerful.  even when it is forwarding commands on behalf of\n    // old clients; we expect the mon is validating commands before proxying!\n    return true;\n  }\n\n  bool cmd_r = this_cmd->requires_perm('r');\n  bool cmd_w = this_cmd->requires_perm('w');\n  bool cmd_x = this_cmd->requires_perm('x');\n\n  bool capable = s->caps.is_capable(\n    g_ceph_context,\n    CEPH_ENTITY_TYPE_MGR,\n    s->entity_name,\n    module, prefix, param_str_map,\n    cmd_r, cmd_w, cmd_x);\n\n  dout(10) << \" \" << s->entity_name << \" \"\n\t   << (capable ? \"\" : \"not \") << \"capable\" << dendl;\n  return capable;\n}\n\nbool DaemonServer::handle_command(MCommand *m)\n{\n  Mutex::Locker l(lock);\n  int r = 0;\n  std::stringstream ss;\n  std::string prefix;\n\n  assert(lock.is_locked_by_me());\n\n  /**\n   * The working data for processing an MCommand.  This lives in\n   * a class to enable passing it into other threads for processing\n   * outside of the thread/locks that called handle_command.\n   */\n  class CommandContext\n  {\n    public:\n    MCommand *m;\n    bufferlist odata;\n    cmdmap_t cmdmap;\n\n    CommandContext(MCommand *m_)\n      : m(m_)\n    {\n    }\n\n    ~CommandContext()\n    {\n      m->put();\n    }\n\n    void reply(int r, const std::stringstream &ss)\n    {\n      reply(r, ss.str());\n    }\n\n    void reply(int r, const std::string &rs)\n    {\n      // Let the connection drop as soon as we've sent our response\n      ConnectionRef con = m->get_connection();\n      if (con) {\n        con->mark_disposable();\n      }\n\n      dout(1) << \"handle_command \" << cpp_strerror(r) << \" \" << rs << dendl;\n      if (con) {\n        MCommandReply *reply = new MCommandReply(r, rs);\n        reply->set_tid(m->get_tid());\n        reply->set_data(odata);\n        con->send_message(reply);\n      }\n    }\n  };\n\n  /**\n   * A context for receiving a bufferlist/error string from a background\n   * function and then calling back to a CommandContext when it's done\n   */\n  class ReplyOnFinish : public Context {\n    std::shared_ptr<CommandContext> cmdctx;\n\n  public:\n    bufferlist from_mon;\n    string outs;\n\n    ReplyOnFinish(std::shared_ptr<CommandContext> cmdctx_)\n      : cmdctx(cmdctx_)\n    {}\n    void finish(int r) override {\n      cmdctx->odata.claim_append(from_mon);\n      cmdctx->reply(r, outs);\n    }\n  };\n\n  std::shared_ptr<CommandContext> cmdctx = std::make_shared<CommandContext>(m);\n\n  MgrSessionRef session(static_cast<MgrSession*>(m->get_connection()->get_priv()));\n  if (!session) {\n    return true;\n  }\n  session->put(); // SessionRef takes a ref\n  if (session->inst.name == entity_name_t())\n    session->inst.name = m->get_source();\n\n  std::string format;\n  boost::scoped_ptr<Formatter> f;\n  map<string,string> param_str_map;\n\n  if (!cmdmap_from_json(m->cmd, &(cmdctx->cmdmap), ss)) {\n    cmdctx->reply(-EINVAL, ss);\n    return true;\n  }\n\n  {\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"format\", format, string(\"plain\"));\n    f.reset(Formatter::create(format));\n  }\n\n  cmd_getval(cct, cmdctx->cmdmap, \"prefix\", prefix);\n\n  dout(4) << \"decoded \" << cmdctx->cmdmap.size() << dendl;\n  dout(4) << \"prefix=\" << prefix << dendl;\n\n  if (prefix == \"get_command_descriptions\") {\n    dout(10) << \"reading commands from python modules\" << dendl;\n    const auto py_commands = py_modules.get_commands();\n\n    int cmdnum = 0;\n    JSONFormatter f;\n    f.open_object_section(\"command_descriptions\");\n\n    auto dump_cmd = [&cmdnum, &f](const MonCommand &mc){\n      ostringstream secname;\n      secname << \"cmd\" << setfill('0') << std::setw(3) << cmdnum;\n      dump_cmddesc_to_json(&f, secname.str(), mc.cmdstring, mc.helpstring,\n                           mc.module, mc.req_perms, mc.availability, 0);\n      cmdnum++;\n    };\n\n    for (const auto &pyc : py_commands) {\n      dump_cmd(pyc);\n    }\n\n    for (const auto &mgr_cmd : mgr_commands) {\n      dump_cmd(mgr_cmd);\n    }\n\n    f.close_section();\t// command_descriptions\n    f.flush(cmdctx->odata);\n    cmdctx->reply(0, ss);\n    return true;\n  }\n\n  // lookup command\n  const MonCommand *mgr_cmd = _get_mgrcommand(prefix, mgr_commands);\n  _generate_command_map(cmdctx->cmdmap, param_str_map);\n  if (!mgr_cmd) {\n    MonCommand py_command = {\"\", \"\", \"py\", \"rw\", \"cli\"};\n    if (!_allowed_command(session.get(), py_command.module, prefix, cmdctx->cmdmap,\n                          param_str_map, &py_command)) {\n      dout(1) << \" access denied\" << dendl;\n      ss << \"access denied; does your client key have mgr caps?\"\n\t\" See http://docs.ceph.com/docs/master/mgr/administrator/#client-authentication\";\n      cmdctx->reply(-EACCES, ss);\n      return true;\n    }\n  } else {\n    // validate user's permissions for requested command\n    if (!_allowed_command(session.get(), mgr_cmd->module, prefix, cmdctx->cmdmap,\n                          param_str_map, mgr_cmd)) {\n      dout(1) << \" access denied\" << dendl;\n      audit_clog->info() << \"from='\" << session->inst << \"' \"\n                         << \"entity='\" << session->entity_name << \"' \"\n                         << \"cmd=\" << m->cmd << \":  access denied\";\n      ss << \"access denied' does your client key have mgr caps?\"\n\t\" See http://docs.ceph.com/docs/master/mgr/administrator/#client-authentication\";\n      cmdctx->reply(-EACCES, ss);\n      return true;\n    }\n  }\n\n  audit_clog->debug()\n    << \"from='\" << session->inst << \"' \"\n    << \"entity='\" << session->entity_name << \"' \"\n    << \"cmd=\" << m->cmd << \": dispatch\";\n\n  // ----------------\n  // service map commands\n  if (prefix == \"service dump\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    cluster_state.with_servicemap([&](const ServiceMap &service_map) {\n\tf->dump_object(\"service_map\", service_map);\n      });\n    f->flush(cmdctx->odata);\n    cmdctx->reply(0, ss);\n    return true;\n  }\n  if (prefix == \"service status\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    // only include state from services that are in the persisted service map\n    f->open_object_section(\"service_status\");\n    ServiceMap s;\n    cluster_state.with_servicemap([&](const ServiceMap& service_map) {\n\ts = service_map;\n      });\n    for (auto& p : s.services) {\n      f->open_object_section(p.first.c_str());\n      for (auto& q : p.second.daemons) {\n\tf->open_object_section(q.first.c_str());\n\tDaemonKey key(p.first, q.first);\n\tassert(daemon_state.exists(key));\n\tauto daemon = daemon_state.get(key);\n\tMutex::Locker l(daemon->lock);\n\tf->dump_stream(\"status_stamp\") << daemon->service_status_stamp;\n\tf->dump_stream(\"last_beacon\") << daemon->last_service_beacon;\n\tf->open_object_section(\"status\");\n\tfor (auto& r : daemon->service_status) {\n\t  f->dump_string(r.first.c_str(), r.second);\n\t}\n\tf->close_section();\n\tf->close_section();\n      }\n      f->close_section();\n    }\n    f->close_section();\n    f->flush(cmdctx->odata);\n    cmdctx->reply(0, ss);\n    return true;\n  }\n\n  if (prefix == \"config set\") {\n    std::string key;\n    std::string val;\n    cmd_getval(cct, cmdctx->cmdmap, \"key\", key);\n    cmd_getval(cct, cmdctx->cmdmap, \"value\", val);\n    r = cct->_conf->set_val(key, val, true, &ss);\n    if (r == 0) {\n      cct->_conf->apply_changes(nullptr);\n    }\n    cmdctx->reply(0, ss);\n    return true;\n  }\n\n  // -----------\n  // PG commands\n\n  if (prefix == \"pg scrub\" ||\n      prefix == \"pg repair\" ||\n      prefix == \"pg deep-scrub\") {\n    string scrubop = prefix.substr(3, string::npos);\n    pg_t pgid;\n    string pgidstr;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"pgid\", pgidstr);\n    if (!pgid.parse(pgidstr.c_str())) {\n      ss << \"invalid pgid '\" << pgidstr << \"'\";\n      cmdctx->reply(-EINVAL, ss);\n      return true;\n    }\n    bool pg_exists = false;\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\tpg_exists = osdmap.pg_exists(pgid);\n      });\n    if (!pg_exists) {\n      ss << \"pg \" << pgid << \" dne\";\n      cmdctx->reply(-ENOENT, ss);\n      return true;\n    }\n    int acting_primary = -1;\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\tacting_primary = osdmap.get_pg_acting_primary(pgid);\n      });\n    if (acting_primary == -1) {\n      ss << \"pg \" << pgid << \" has no primary osd\";\n      cmdctx->reply(-EAGAIN, ss);\n      return true;\n    }\n    auto p = osd_cons.find(acting_primary);\n    if (p == osd_cons.end()) {\n      ss << \"pg \" << pgid << \" primary osd.\" << acting_primary\n\t << \" is not currently connected\";\n      cmdctx->reply(-EAGAIN, ss);\n    }\n    vector<pg_t> pgs = { pgid };\n    for (auto& con : p->second) {\n      con->send_message(new MOSDScrub(monc->get_fsid(),\n\t\t\t\t      pgs,\n\t\t\t\t      scrubop == \"repair\",\n\t\t\t\t      scrubop == \"deep-scrub\"));\n    }\n    ss << \"instructing pg \" << pgid << \" on osd.\" << acting_primary\n       << \" to \" << scrubop;\n    cmdctx->reply(0, ss);\n    return true;\n  } else if (prefix == \"osd scrub\" ||\n\t      prefix == \"osd deep-scrub\" ||\n\t      prefix == \"osd repair\") {\n    string whostr;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"who\", whostr);\n    vector<string> pvec;\n    get_str_vec(prefix, pvec);\n\n    set<int> osds;\n    if (whostr == \"*\" || whostr == \"all\" || whostr == \"any\") {\n      cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t  for (int i = 0; i < osdmap.get_max_osd(); i++)\n\t    if (osdmap.is_up(i)) {\n\t      osds.insert(i);\n\t    }\n\t});\n    } else {\n      long osd = parse_osd_id(whostr.c_str(), &ss);\n      if (osd < 0) {\n\tss << \"invalid osd '\" << whostr << \"'\";\n\tcmdctx->reply(-EINVAL, ss);\n\treturn true;\n      }\n      cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t  if (osdmap.is_up(osd)) {\n\t    osds.insert(osd);\n\t  }\n\t});\n      if (osds.empty()) {\n\tss << \"osd.\" << osd << \" is not up\";\n\tcmdctx->reply(-EAGAIN, ss);\n\treturn true;\n      }\n    }\n    set<int> sent_osds, failed_osds;\n    for (auto osd : osds) {\n      auto p = osd_cons.find(osd);\n      if (p == osd_cons.end()) {\n\tfailed_osds.insert(osd);\n      } else {\n\tsent_osds.insert(osd);\n\tfor (auto& con : p->second) {\n\t  con->send_message(new MOSDScrub(monc->get_fsid(),\n\t\t\t\t\t  pvec.back() == \"repair\",\n\t\t\t\t\t  pvec.back() == \"deep-scrub\"));\n\t}\n      }\n    }\n    if (failed_osds.size() == osds.size()) {\n      ss << \"failed to instruct osd(s) \" << osds << \" to \" << pvec.back()\n\t << \" (not connected)\";\n      r = -EAGAIN;\n    } else {\n      ss << \"instructed osd(s) \" << sent_osds << \" to \" << pvec.back();\n      if (!failed_osds.empty()) {\n\tss << \"; osd(s) \" << failed_osds << \" were not connected\";\n      }\n      r = 0;\n    }\n    cmdctx->reply(0, ss);\n    return true;\n  } else if (prefix == \"osd reweight-by-pg\" ||\n\t     prefix == \"osd reweight-by-utilization\" ||\n\t     prefix == \"osd test-reweight-by-pg\" ||\n\t     prefix == \"osd test-reweight-by-utilization\") {\n    bool by_pg =\n      prefix == \"osd reweight-by-pg\" || prefix == \"osd test-reweight-by-pg\";\n    bool dry_run =\n      prefix == \"osd test-reweight-by-pg\" ||\n      prefix == \"osd test-reweight-by-utilization\";\n    int64_t oload;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"oload\", oload, int64_t(120));\n    set<int64_t> pools;\n    vector<string> poolnames;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"pools\", poolnames);\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\tfor (const auto& poolname : poolnames) {\n\t  int64_t pool = osdmap.lookup_pg_pool_name(poolname);\n\t  if (pool < 0) {\n\t    ss << \"pool '\" << poolname << \"' does not exist\";\n\t    r = -ENOENT;\n\t  }\n\t  pools.insert(pool);\n\t}\n      });\n    if (r) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n    double max_change = g_conf->mon_reweight_max_change;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"max_change\", max_change);\n    if (max_change <= 0.0) {\n      ss << \"max_change \" << max_change << \" must be positive\";\n      cmdctx->reply(-EINVAL, ss);\n      return true;\n    }\n    int64_t max_osds = g_conf->mon_reweight_max_osds;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"max_osds\", max_osds);\n    if (max_osds <= 0) {\n      ss << \"max_osds \" << max_osds << \" must be positive\";\n      cmdctx->reply(-EINVAL, ss);\n      return true;\n    }\n    string no_increasing;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"no_increasing\", no_increasing);\n    string out_str;\n    mempool::osdmap::map<int32_t, uint32_t> new_weights;\n    r = cluster_state.with_pgmap([&](const PGMap& pgmap) {\n\treturn cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t    return reweight::by_utilization(osdmap, pgmap,\n\t\t\t\t\t    oload,\n\t\t\t\t\t    max_change,\n\t\t\t\t\t    max_osds,\n\t\t\t\t\t    by_pg,\n\t\t\t\t\t    pools.empty() ? NULL : &pools,\n\t\t\t\t\t    no_increasing == \"--no-increasing\",\n\t\t\t\t\t    &new_weights,\n\t\t\t\t\t    &ss, &out_str, f.get());\n\t  });\n      });\n    if (r >= 0) {\n      dout(10) << \"reweight::by_utilization: finished with \" << out_str << dendl;\n    }\n    if (f) {\n      f->flush(cmdctx->odata);\n    } else {\n      cmdctx->odata.append(out_str);\n    }\n    if (r < 0) {\n      ss << \"FAILED reweight-by-pg\";\n      cmdctx->reply(r, ss);\n      return true;\n    } else if (r == 0 || dry_run) {\n      ss << \"no change\";\n      cmdctx->reply(r, ss);\n      return true;\n    } else {\n      json_spirit::Object json_object;\n      for (const auto& osd_weight : new_weights) {\n\tjson_spirit::Config::add(json_object,\n\t\t\t\t std::to_string(osd_weight.first),\n\t\t\t\t std::to_string(osd_weight.second));\n      }\n      string s = json_spirit::write(json_object);\n      std::replace(begin(s), end(s), '\\\"', '\\'');\n      const string cmd =\n\t\"{\"\n\t\"\\\"prefix\\\": \\\"osd reweightn\\\", \"\n\t\"\\\"weights\\\": \\\"\" + s + \"\\\"\"\n\t\"}\";\n      auto on_finish = new ReplyOnFinish(cmdctx);\n      monc->start_mon_command({cmd}, {},\n\t\t\t      &on_finish->from_mon, &on_finish->outs, on_finish);\n      return true;\n    }\n  } else if (prefix == \"osd df\") {\n    string method;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"output_method\", method);\n    r = cluster_state.with_pgservice([&](const PGMapStatService& pgservice) {\n\treturn cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t    print_osd_utilization(osdmap, &pgservice, ss,\n\t\t\t\t  f.get(), method == \"tree\");\n\t\t\t\t  \n\t    cmdctx->odata.append(ss);\n\t    return 0;\n\t  });\n      });\n    cmdctx->reply(r, \"\");\n    return true;\n  } else if (prefix == \"osd safe-to-destroy\") {\n    vector<string> ids;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"ids\", ids);\n    set<int> osds;\n    int r;\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\tr = osdmap.parse_osd_id_list(ids, &osds, &ss);\n      });\n    if (!r && osds.empty()) {\n      ss << \"must specify one or more OSDs\";\n      r = -EINVAL;\n    }\n    if (r < 0) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n    set<int> active_osds, missing_stats, stored_pgs;\n    int affected_pgs = 0;\n    cluster_state.with_pgmap([&](const PGMap& pg_map) {\n\tif (pg_map.num_pg_unknown > 0) {\n\t  ss << pg_map.num_pg_unknown << \" pgs have unknown state; cannot draw\"\n\t     << \" any conclusions\";\n\t  r = -EAGAIN;\n\t  return;\n\t}\n\tint num_active_clean = 0;\n\tfor (auto& p : pg_map.num_pg_by_state) {\n\t  unsigned want = PG_STATE_ACTIVE|PG_STATE_CLEAN;\n\t  if ((p.first & want) == want) {\n\t    num_active_clean += p.second;\n\t  }\n\t}\n\tcluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t    for (auto osd : osds) {\n\t      if (!osdmap.exists(osd)) {\n\t\tcontinue;  // clearly safe to destroy\n\t      }\n\t      auto q = pg_map.num_pg_by_osd.find(osd);\n\t      if (q != pg_map.num_pg_by_osd.end()) {\n\t\tif (q->second.acting > 0 || q->second.up > 0) {\n\t\t  active_osds.insert(osd);\n\t\t  affected_pgs += q->second.acting + q->second.up;\n\t\t  continue;\n\t\t}\n\t      }\n\t      if (num_active_clean < pg_map.num_pg) {\n\t\t// all pgs aren't active+clean; we need to be careful.\n\t\tauto p = pg_map.osd_stat.find(osd);\n\t\tif (p == pg_map.osd_stat.end()) {\n\t\t  missing_stats.insert(osd);\n\t\t}\n\t\tif (p->second.num_pgs > 0) {\n\t\t  stored_pgs.insert(osd);\n\t\t}\n\t      }\n\t    }\n\t  });\n      });\n    if (!r && !active_osds.empty()) {\n      ss << \"OSD(s) \" << active_osds << \" have \" << affected_pgs\n\t << \" pgs currently mapped to them\";\n      r = -EBUSY;\n    } else if (!missing_stats.empty()) {\n      ss << \"OSD(s) \" << missing_stats << \" have no reported stats, and not all\"\n\t << \" PGs are active+clean; we cannot draw any conclusions\";\n      r = -EAGAIN;\n    } else if (!stored_pgs.empty()) {\n      ss << \"OSD(s) \" << stored_pgs << \" last reported they still store some PG\"\n\t << \" data, and not all PGs are active+clean; we cannot be sure they\"\n\t << \" aren't still needed.\";\n      r = -EBUSY;\n    }\n    if (r) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n    ss << \"OSD(s) \" << osds << \" are safe to destroy without reducing data\"\n       << \" durability.\";\n    cmdctx->reply(0, ss);\n    return true;\n  } else if (prefix == \"osd ok-to-stop\") {\n    vector<string> ids;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"ids\", ids);\n    set<int> osds;\n    int r;\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\tr = osdmap.parse_osd_id_list(ids, &osds, &ss);\n      });\n    if (!r && osds.empty()) {\n      ss << \"must specify one or more OSDs\";\n      r = -EINVAL;\n    }\n    if (r < 0) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n    map<pg_t,int> pg_delta;  // pgid -> net acting set size change\n    int dangerous_pgs = 0;\n    cluster_state.with_pgmap([&](const PGMap& pg_map) {\n\treturn cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t    if (pg_map.num_pg_unknown > 0) {\n\t      ss << pg_map.num_pg_unknown << \" pgs have unknown state; \"\n\t\t << \"cannot draw any conclusions\";\n\t      r = -EAGAIN;\n\t      return;\n\t    }\n\t    for (auto osd : osds) {\n\t      auto p = pg_map.pg_by_osd.find(osd);\n\t      if (p != pg_map.pg_by_osd.end()) {\n\t\tfor (auto& pgid : p->second) {\n\t\t  --pg_delta[pgid];\n\t\t}\n\t      }\n\t    }\n\t    for (auto& p : pg_delta) {\n\t      auto q = pg_map.pg_stat.find(p.first);\n\t      if (q == pg_map.pg_stat.end()) {\n\t\tss << \"missing information about \" << p.first << \"; cannot draw\"\n\t\t   << \" any conclusions\";\n\t\tr = -EAGAIN;\n\t\treturn;\n\t      }\n\t      if (!(q->second.state & PG_STATE_ACTIVE) ||\n\t\t  (q->second.state & PG_STATE_DEGRADED)) {\n\t\t// we don't currently have a good way to tell *how* degraded\n\t\t// a degraded PG is, so we have to assume we cannot remove\n\t\t// any more replicas/shards.\n\t\t++dangerous_pgs;\n\t\tcontinue;\n\t      }\n\t      const pg_pool_t *pi = osdmap.get_pg_pool(p.first.pool());\n\t      if (!pi) {\n\t\t++dangerous_pgs; // pool is creating or deleting\n\t      } else {\n\t\tif (q->second.acting.size() + p.second < pi->min_size) {\n\t\t  ++dangerous_pgs;\n\t\t}\n\t      }\n\t    }\n\t  });\n      });\n    if (r) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n    if (dangerous_pgs) {\n      ss << dangerous_pgs << \" PGs are already degraded or might become \"\n\t << \"unavailable\";\n      cmdctx->reply(-EBUSY, ss);\n      return true;\n    }\n    ss << \"OSD(s) \" << osds << \" are ok to stop without reducing\"\n       << \" availability, provided there are no other concurrent failures\"\n       << \" or interventions. \" << pg_delta.size() << \" PGs are likely to be\"\n       << \" degraded (but remain available) as a result.\";\n    cmdctx->reply(0, ss);\n    return true;\n  } else if (prefix == \"pg force-recovery\" ||\n  \t       prefix == \"pg force-backfill\" ||\n  \t       prefix == \"pg cancel-force-recovery\" ||\n  \t       prefix == \"pg cancel-force-backfill\") {\n    string forceop = prefix.substr(3, string::npos);\n    list<pg_t> parsed_pgs;\n    map<int, list<pg_t> > osdpgs;\n\n    // figure out actual op just once\n    int actual_op = 0;\n    if (forceop == \"force-recovery\") {\n      actual_op = OFR_RECOVERY;\n    } else if (forceop == \"force-backfill\") {\n      actual_op = OFR_BACKFILL;\n    } else if (forceop == \"cancel-force-backfill\") {\n      actual_op = OFR_BACKFILL | OFR_CANCEL;\n    } else if (forceop == \"cancel-force-recovery\") {\n      actual_op = OFR_RECOVERY | OFR_CANCEL;\n    }\n\n    // covnert pg names to pgs, discard any invalid ones while at it\n    {\n      // we don't want to keep pgidstr and pgidstr_nodup forever\n      vector<string> pgidstr;\n      // get pgids to process and prune duplicates\n      cmd_getval(g_ceph_context, cmdctx->cmdmap, \"pgid\", pgidstr);\n      set<string> pgidstr_nodup(pgidstr.begin(), pgidstr.end());\n      if (pgidstr.size() != pgidstr_nodup.size()) {\n\t// move elements only when there were duplicates, as this\n\t// reorders them\n\tpgidstr.resize(pgidstr_nodup.size());\n\tauto it = pgidstr_nodup.begin();\n\tfor (size_t i = 0 ; i < pgidstr_nodup.size(); i++) {\n\t  pgidstr[i] = std::move(*it++);\n\t}\n      }\n\n      cluster_state.with_pgmap([&](const PGMap& pg_map) {\n\tfor (auto& pstr : pgidstr) {\n\t  pg_t parsed_pg;\n\t  if (!parsed_pg.parse(pstr.c_str())) {\n\t    ss << \"invalid pgid '\" << pstr << \"'; \";\n\t    r = -EINVAL;\n\t  } else {\n\t    auto workit = pg_map.pg_stat.find(parsed_pg);\n\t    if (workit == pg_map.pg_stat.end()) {\n\t      ss << \"pg \" << pstr << \" does not exist; \";\n\t      r = -ENOENT;\n\t    } else {\n\t      pg_stat_t workpg = workit->second;\n\n\t      // discard pgs for which user requests are pointless\n\t      switch (actual_op)\n\t      {\n\t\tcase OFR_RECOVERY:\n\t\t  if ((workpg.state & (PG_STATE_DEGRADED | PG_STATE_RECOVERY_WAIT | PG_STATE_RECOVERING)) == 0) {\n\t\t    // don't return error, user script may be racing with cluster. not fatal.\n\t\t    ss << \"pg \" << pstr << \" doesn't require recovery; \";\n\t\t    continue;\n\t\t  } else  if (workpg.state & PG_STATE_FORCED_RECOVERY) {\n\t\t    ss << \"pg \" << pstr << \" recovery already forced; \";\n\t\t    // return error, as it may be a bug in user script\n\t\t    r = -EINVAL;\n\t\t    continue;\n\t\t  }\n\t\t  break;\n\t\tcase OFR_BACKFILL:\n\t\t  if ((workpg.state & (PG_STATE_DEGRADED | PG_STATE_BACKFILL_WAIT | PG_STATE_BACKFILLING)) == 0) {\n\t\t    ss << \"pg \" << pstr << \" doesn't require backfilling; \";\n\t\t    continue;\n\t\t  } else  if (workpg.state & PG_STATE_FORCED_BACKFILL) {\n\t\t    ss << \"pg \" << pstr << \" backfill already forced; \";\n\t\t    r = -EINVAL;\n\t\t    continue;\n\t\t  }\n\t\t  break;\n\t\tcase OFR_BACKFILL | OFR_CANCEL:\n\t\t  if ((workpg.state & PG_STATE_FORCED_BACKFILL) == 0) {\n\t\t    ss << \"pg \" << pstr << \" backfill not forced; \";\n\t\t    continue;\n\t\t  }\n\t\t  break;\n\t\tcase OFR_RECOVERY | OFR_CANCEL:\n\t\t  if ((workpg.state & PG_STATE_FORCED_RECOVERY) == 0) {\n\t\t    ss << \"pg \" << pstr << \" recovery not forced; \";\n\t\t    continue;\n\t\t  }\n\t\t  break;\n\t\tdefault:\n\t\t  assert(0 == \"actual_op value is not supported\");\n\t      }\n\n\t      parsed_pgs.push_back(std::move(parsed_pg));\n\t    }\n\t  }\n\t}\n\n\t// group pgs to process by osd\n\tfor (auto& pgid : parsed_pgs) {\n\t  auto workit = pg_map.pg_stat.find(pgid);\n\t  if (workit != pg_map.pg_stat.end()) {\n\t    pg_stat_t workpg = workit->second;\n\t    set<int32_t> osds(workpg.up.begin(), workpg.up.end());\n\t    osds.insert(workpg.acting.begin(), workpg.acting.end());\n\t    for (auto i : osds) {\n\t      osdpgs[i].push_back(pgid);\n\t    }\n\t  }\n\t}\n\n      });\n    }\n\n    // respond with error only when no pgs are correct\n    // yes, in case of mixed errors, only the last one will be emitted,\n    // but the message presented will be fine\n    if (parsed_pgs.size() != 0) {\n      // clear error to not confuse users/scripts\n      r = 0;\n    }\n\n    // optimize the command -> messages conversion, use only one message per distinct OSD\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n      for (auto& i : osdpgs) {\n\tif (osdmap.is_up(i.first)) {\n\t  vector<pg_t> pgvec(make_move_iterator(i.second.begin()), make_move_iterator(i.second.end()));\n\t  auto p = osd_cons.find(i.first);\n\t  if (p == osd_cons.end()) {\n\t    ss << \"osd.\" << i.first << \" is not currently connected\";\n\t    r = -EAGAIN;\n\t    continue;\n\t  }\n\t  for (auto& con : p->second) {\n\t    con->send_message(new MOSDForceRecovery(monc->get_fsid(), pgvec, actual_op));\n\t  }\n\t  ss << \"instructing pg(s) \" << i.second << \" on osd.\" << i.first << \" to \" << forceop << \"; \";\n\t}\n      }\n    });\n    ss << std::endl;\n    cmdctx->reply(r, ss);\n    return true;\n  } else {\n    r = cluster_state.with_pgmap([&](const PGMap& pg_map) {\n\treturn cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t    return process_pg_map_command(prefix, cmdctx->cmdmap, pg_map, osdmap,\n\t\t\t\t\t  f.get(), &ss, &cmdctx->odata);\n\t  });\n      });\n\n    if (r != -EOPNOTSUPP) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n  }\n\n  // None of the special native commands, \n  ActivePyModule *handler = nullptr;\n  auto py_commands = py_modules.get_py_commands();\n  for (const auto &pyc : py_commands) {\n    auto pyc_prefix = cmddesc_get_prefix(pyc.cmdstring);\n    dout(1) << \"pyc_prefix: '\" << pyc_prefix << \"'\" << dendl;\n    if (pyc_prefix == prefix) {\n      handler = pyc.handler;\n      break;\n    }\n  }\n\n  if (handler == nullptr) {\n    ss << \"No handler found for '\" << prefix << \"'\";\n    dout(4) << \"No handler found for '\" << prefix << \"'\" << dendl;\n    cmdctx->reply(-EINVAL, ss);\n    return true;\n  } else {\n    // Okay, now we have a handler to call, but we must not call it\n    // in this thread, because the python handlers can do anything,\n    // including blocking, and including calling back into mgr.\n    dout(4) << \"passing through \" << cmdctx->cmdmap.size() << dendl;\n    finisher.queue(new FunctionContext([cmdctx, handler](int r_) {\n      std::stringstream ds;\n      std::stringstream ss;\n      int r = handler->handle_command(cmdctx->cmdmap, &ds, &ss);\n      cmdctx->odata.append(ds);\n      cmdctx->reply(r, ss);\n    }));\n    return true;\n  }\n}\n\nvoid DaemonServer::_prune_pending_service_map()\n{\n  utime_t cutoff = ceph_clock_now();\n  cutoff -= g_conf->get_val<double>(\"mgr_service_beacon_grace\");\n  auto p = pending_service_map.services.begin();\n  while (p != pending_service_map.services.end()) {\n    auto q = p->second.daemons.begin();\n    while (q != p->second.daemons.end()) {\n      DaemonKey key(p->first, q->first);\n      if (!daemon_state.exists(key)) {\n\tderr << \"missing key \" << key << dendl;\n\t++q;\n\tcontinue;\n      }\n      auto daemon = daemon_state.get(key);\n      Mutex::Locker l(daemon->lock);\n      if (daemon->last_service_beacon == utime_t()) {\n\t// we must have just restarted; assume they are alive now.\n\tdaemon->last_service_beacon = ceph_clock_now();\n\t++q;\n\tcontinue;\n      }\n      if (daemon->last_service_beacon < cutoff) {\n\tdout(10) << \"pruning stale \" << p->first << \".\" << q->first\n\t\t << \" last_beacon \" << daemon->last_service_beacon << dendl;\n\tq = p->second.daemons.erase(q);\n\tpending_service_map_dirty = pending_service_map.epoch;\n      } else {\n\t++q;\n      }\n    }\n    if (p->second.daemons.empty()) {\n      p = pending_service_map.services.erase(p);\n      pending_service_map_dirty = pending_service_map.epoch;\n    } else {\n      ++p;\n    }\n  }\n}\n\nvoid DaemonServer::send_report()\n{\n  if (!pgmap_ready) {\n    if (ceph_clock_now() - started_at > g_conf->get_val<int64_t>(\"mgr_stats_period\") * 4.0) {\n      pgmap_ready = true;\n      reported_osds.clear();\n      dout(1) << \"Giving up on OSDs that haven't reported yet, sending \"\n              << \"potentially incomplete PG state to mon\" << dendl;\n    } else {\n      dout(1) << \"Not sending PG status to monitor yet, waiting for OSDs\"\n              << dendl;\n      return;\n    }\n  }\n\n  auto m = new MMonMgrReport();\n  py_modules.get_health_checks(&m->health_checks);\n\n  cluster_state.with_pgmap([&](const PGMap& pg_map) {\n      cluster_state.update_delta_stats();\n\n      if (pending_service_map.epoch) {\n\t_prune_pending_service_map();\n\tif (pending_service_map_dirty >= pending_service_map.epoch) {\n\t  pending_service_map.modified = ceph_clock_now();\n\t  ::encode(pending_service_map, m->service_map_bl, CEPH_FEATURES_ALL);\n\t  dout(10) << \"sending service_map e\" << pending_service_map.epoch\n\t\t   << dendl;\n\t  pending_service_map.epoch++;\n\t}\n      }\n\n      cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t  // FIXME: no easy way to get mon features here.  this will do for\n\t  // now, though, as long as we don't make a backward-incompat change.\n\t  pg_map.encode_digest(osdmap, m->get_data(), CEPH_FEATURES_ALL);\n\t  dout(10) << pg_map << dendl;\n\n\t  pg_map.get_health_checks(g_ceph_context, osdmap,\n\t\t\t\t   &m->health_checks);\n\n\t  dout(10) << m->health_checks.checks.size() << \" health checks\"\n\t\t   << dendl;\n\t  dout(20) << \"health checks:\\n\";\n\t  JSONFormatter jf(true);\n\t  jf.dump_object(\"health_checks\", m->health_checks);\n\t  jf.flush(*_dout);\n\t  *_dout << dendl;\n\t});\n    });\n\n  auto osds = daemon_state.get_by_service(\"osd\");\n  map<osd_metric, unique_ptr<OSDHealthMetricCollector>> accumulated;\n  for (const auto& osd : osds) {\n    Mutex::Locker l(osd.second->lock);\n    for (const auto& metric : osd.second->osd_health_metrics) {\n      auto acc = accumulated.find(metric.get_type());\n      if (acc == accumulated.end()) {\n\tauto collector = OSDHealthMetricCollector::create(metric.get_type());\n\tif (!collector) {\n\t  derr << __func__ << \" \" << osd.first << \".\" << osd.second\n\t       << \" sent me an unknown health metric: \"\n\t       << static_cast<uint8_t>(metric.get_type()) << dendl;\n\t  continue;\n\t}\n\ttie(acc, std::ignore) = accumulated.emplace(metric.get_type(),\n\t\t\t\t\t\t    std::move(collector));\n      }\n      acc->second->update(osd.first, metric);\n    }\n  }\n  for (const auto& acc : accumulated) {\n    acc.second->summarize(m->health_checks);\n  }\n  // TODO? We currently do not notify the PyModules\n  // TODO: respect needs_send, so we send the report only if we are asked to do\n  //       so, or the state is updated.\n  monc->send_mon_message(m);\n}\n\nvoid DaemonServer::got_service_map()\n{\n  Mutex::Locker l(lock);\n\n  cluster_state.with_servicemap([&](const ServiceMap& service_map) {\n      if (pending_service_map.epoch == 0) {\n\t// we just started up\n\tdout(10) << \"got initial map e\" << service_map.epoch << dendl;\n\tpending_service_map = service_map;\n      } else {\n\t// we we already active and therefore must have persisted it,\n\t// which means ours is the same or newer.\n\tdout(10) << \"got updated map e\" << service_map.epoch << dendl;\n      }\n      pending_service_map.epoch = service_map.epoch + 1;\n    });\n\n  // cull missing daemons, populate new ones\n  for (auto& p : pending_service_map.services) {\n    std::set<std::string> names;\n    for (auto& q : p.second.daemons) {\n      names.insert(q.first);\n      DaemonKey key(p.first, q.first);\n      if (!daemon_state.exists(key)) {\n\tauto daemon = std::make_shared<DaemonState>(daemon_state.types);\n\tdaemon->key = key;\n\tdaemon->metadata = q.second.metadata;\n        if (q.second.metadata.count(\"hostname\")) {\n          daemon->hostname = q.second.metadata[\"hostname\"];\n        }\n\tdaemon->service_daemon = true;\n\tdaemon_state.insert(daemon);\n\tdout(10) << \"added missing \" << key << dendl;\n      }\n    }\n    daemon_state.cull(p.first, names);\n  }\n}\n\n\nconst char** DaemonServer::get_tracked_conf_keys() const\n{\n  static const char *KEYS[] = {\n    \"mgr_stats_threshold\",\n    \"mgr_stats_period\",\n    nullptr\n  };\n\n  return KEYS;\n}\n\nvoid DaemonServer::handle_conf_change(const struct md_config_t *conf,\n                                              const std::set <std::string> &changed)\n{\n  dout(4) << \"ohai\" << dendl;\n  // We may be called within lock (via MCommand `config set`) or outwith the\n  // lock (via admin socket `config set`), so handle either case.\n  const bool initially_locked = lock.is_locked_by_me();\n  if (!initially_locked) {\n    lock.Lock();\n  }\n\n  if (changed.count(\"mgr_stats_threshold\") || changed.count(\"mgr_stats_period\")) {\n    dout(4) << \"Updating stats threshold/period on \"\n            << daemon_connections.size() << \" clients\" << dendl;\n    // Send a fresh MMgrConfigure to all clients, so that they can follow\n    // the new policy for transmitting stats\n    for (auto &c : daemon_connections) {\n      _send_configure(c);\n    }\n  }\n}\n\nvoid DaemonServer::_send_configure(ConnectionRef c)\n{\n  assert(lock.is_locked_by_me());\n\n  auto configure = new MMgrConfigure();\n  configure->stats_period = g_conf->get_val<int64_t>(\"mgr_stats_period\");\n  configure->stats_threshold = g_conf->get_val<int64_t>(\"mgr_stats_threshold\");\n  c->send_message(configure);\n}\n\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2016 John Spray <john.spray@redhat.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n */\n\n#ifndef DAEMON_SERVER_H_\n#define DAEMON_SERVER_H_\n\n#include \"PyModuleRegistry.h\"\n\n#include <set>\n#include <string>\n\n#include \"common/Mutex.h\"\n#include \"common/LogClient.h\"\n\n#include <msg/Messenger.h>\n#include <mon/MonClient.h>\n\n#include \"auth/AuthAuthorizeHandler.h\"\n\n#include \"ServiceMap.h\"\n#include \"MgrSession.h\"\n#include \"DaemonState.h\"\n\nclass MMgrReport;\nclass MMgrOpen;\nclass MMonMgrReport;\nclass MCommand;\nstruct MonCommand;\n\n\n/**\n * Server used in ceph-mgr to communicate with Ceph daemons like\n * MDSs and OSDs.\n */\nclass DaemonServer : public Dispatcher, public md_config_obs_t\n{\nprotected:\n  boost::scoped_ptr<Throttle> client_byte_throttler;\n  boost::scoped_ptr<Throttle> client_msg_throttler;\n  boost::scoped_ptr<Throttle> osd_byte_throttler;\n  boost::scoped_ptr<Throttle> osd_msg_throttler;\n  boost::scoped_ptr<Throttle> mds_byte_throttler;\n  boost::scoped_ptr<Throttle> mds_msg_throttler;\n  boost::scoped_ptr<Throttle> mon_byte_throttler;\n  boost::scoped_ptr<Throttle> mon_msg_throttler;\n\n  Messenger *msgr;\n  MonClient *monc;\n  Finisher  &finisher;\n  DaemonStateIndex &daemon_state;\n  ClusterState &cluster_state;\n  PyModuleRegistry &py_modules;\n  LogChannelRef clog, audit_clog;\n\n  // Authentication methods for cluster peers\n  AuthAuthorizeHandlerRegistry auth_cluster_registry;\n  // Authentication methods for clients\n  AuthAuthorizeHandlerRegistry auth_service_registry;\n\n  // Connections for daemons, and clients with service names set\n  // (i.e. those MgrClients that are allowed to send MMgrReports)\n  std::set<ConnectionRef> daemon_connections;\n\n  /// connections for osds\n  ceph::unordered_map<int,set<ConnectionRef>> osd_cons;\n\n  ServiceMap pending_service_map;  // uncommitted\n\n  epoch_t pending_service_map_dirty = 0;\n\n  Mutex lock;\n\n  static void _generate_command_map(map<string,cmd_vartype>& cmdmap,\n                                    map<string,string> &param_str_map);\n  static const MonCommand *_get_mgrcommand(const string &cmd_prefix,\n                                           const std::vector<MonCommand> &commands);\n  bool _allowed_command(\n    MgrSession *s, const string &module, const string &prefix,\n    const map<string,cmd_vartype>& cmdmap,\n    const map<string,string>& param_str_map,\n    const MonCommand *this_cmd);\n\nprivate:\n  friend class ReplyOnFinish;\n  bool _reply(MCommand* m,\n\t      int ret, const std::string& s, const bufferlist& payload);\n\n  void _prune_pending_service_map();\n\n  utime_t started_at;\n  std::atomic<bool> pgmap_ready;\n  std::set<int32_t> reported_osds;\n  void maybe_ready(int32_t osd_id);\n\npublic:\n  int init(uint64_t gid, entity_addr_t client_addr);\n  void shutdown();\n\n  entity_addr_t get_myaddr() const;\n\n  DaemonServer(MonClient *monc_,\n               Finisher &finisher_,\n\t       DaemonStateIndex &daemon_state_,\n\t       ClusterState &cluster_state_,\n\t       PyModuleRegistry &py_modules_,\n\t       LogChannelRef cl,\n\t       LogChannelRef auditcl);\n  ~DaemonServer() override;\n\n  bool ms_dispatch(Message *m) override;\n  bool ms_handle_reset(Connection *con) override;\n  void ms_handle_remote_reset(Connection *con) override {}\n  bool ms_handle_refused(Connection *con) override;\n  bool ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer,\n                         bool force_new) override;\n  bool ms_verify_authorizer(Connection *con,\n      int peer_type,\n      int protocol,\n      ceph::bufferlist& authorizer,\n      ceph::bufferlist& authorizer_reply,\n      bool& isvalid,\n      CryptoKey& session_key) override;\n\n  bool handle_open(MMgrOpen *m);\n  bool handle_report(MMgrReport *m);\n  bool handle_command(MCommand *m);\n  void send_report();\n  void got_service_map();\n\n  void _send_configure(ConnectionRef c);\n\n  virtual const char** get_tracked_conf_keys() const override;\n  virtual void handle_conf_change(const struct md_config_t *conf,\n                          const std::set <std::string> &changed) override;\n};\n\n#endif\n\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n\n#include <sstream>\n#include <stdlib.h>\n#include <signal.h>\n#include <limits.h>\n#include <cstring>\n#include <boost/scope_exit.hpp>\n#include <boost/algorithm/string/predicate.hpp>\n\n#include \"Monitor.h\"\n#include \"common/version.h\"\n\n#include \"osd/OSDMap.h\"\n\n#include \"MonitorDBStore.h\"\n\n#include \"messages/PaxosServiceMessage.h\"\n#include \"messages/MMonMap.h\"\n#include \"messages/MMonGetMap.h\"\n#include \"messages/MMonGetVersion.h\"\n#include \"messages/MMonGetVersionReply.h\"\n#include \"messages/MGenericMessage.h\"\n#include \"messages/MMonCommand.h\"\n#include \"messages/MMonCommandAck.h\"\n#include \"messages/MMonHealth.h\"\n#include \"messages/MMonMetadata.h\"\n#include \"messages/MMonSync.h\"\n#include \"messages/MMonScrub.h\"\n#include \"messages/MMonProbe.h\"\n#include \"messages/MMonJoin.h\"\n#include \"messages/MMonPaxos.h\"\n#include \"messages/MRoute.h\"\n#include \"messages/MForward.h\"\n#include \"messages/MStatfs.h\"\n\n#include \"messages/MMonSubscribe.h\"\n#include \"messages/MMonSubscribeAck.h\"\n\n#include \"messages/MAuthReply.h\"\n\n#include \"messages/MTimeCheck.h\"\n#include \"messages/MPing.h\"\n\n#include \"common/strtol.h\"\n#include \"common/ceph_argparse.h\"\n#include \"common/Timer.h\"\n#include \"common/Clock.h\"\n#include \"common/errno.h\"\n#include \"common/perf_counters.h\"\n#include \"common/admin_socket.h\"\n#include \"global/signal_handler.h\"\n#include \"common/Formatter.h\"\n#include \"include/stringify.h\"\n#include \"include/color.h\"\n#include \"include/ceph_fs.h\"\n#include \"include/str_list.h\"\n\n#include \"OSDMonitor.h\"\n#include \"MDSMonitor.h\"\n#include \"MonmapMonitor.h\"\n#include \"PGMonitor.h\"\n#include \"LogMonitor.h\"\n#include \"AuthMonitor.h\"\n#include \"MgrMonitor.h\"\n#include \"MgrStatMonitor.h\"\n#include \"mon/QuorumService.h\"\n#include \"mon/OldHealthMonitor.h\"\n#include \"mon/HealthMonitor.h\"\n#include \"mon/ConfigKeyService.h\"\n#include \"common/config.h\"\n#include \"common/cmdparse.h\"\n#include \"include/assert.h\"\n#include \"include/compat.h\"\n#include \"perfglue/heap_profiler.h\"\n\n#include \"auth/none/AuthNoneClientHandler.h\"\n\n#define dout_subsys ceph_subsys_mon\n#undef dout_prefix\n#define dout_prefix _prefix(_dout, this)\nstatic ostream& _prefix(std::ostream *_dout, const Monitor *mon) {\n  return *_dout << \"mon.\" << mon->name << \"@\" << mon->rank\n\t\t<< \"(\" << mon->get_state_name() << \") e\" << mon->monmap->get_epoch() << \" \";\n}\n\nconst string Monitor::MONITOR_NAME = \"monitor\";\nconst string Monitor::MONITOR_STORE_PREFIX = \"monitor_store\";\n\n\n#undef FLAG\n#undef COMMAND\n#undef COMMAND_WITH_FLAG\n#define FLAG(f) (MonCommand::FLAG_##f)\n#define COMMAND(parsesig, helptext, modulename, req_perms, avail)\t\\\n  {parsesig, helptext, modulename, req_perms, avail, FLAG(NONE)},\n#define COMMAND_WITH_FLAG(parsesig, helptext, modulename, req_perms, avail, flags) \\\n  {parsesig, helptext, modulename, req_perms, avail, flags},\nMonCommand mon_commands[] = {\n#include <mon/MonCommands.h>\n};\nMonCommand pgmonitor_commands[] = {\n#include <mon/PGMonitorCommands.h>\n};\n#undef COMMAND\n#undef COMMAND_WITH_FLAG\n\n\nvoid C_MonContext::finish(int r) {\n  if (mon->is_shutdown())\n    return;\n  FunctionContext::finish(r);\n}\n\nMonitor::Monitor(CephContext* cct_, string nm, MonitorDBStore *s,\n\t\t Messenger *m, Messenger *mgr_m, MonMap *map) :\n  Dispatcher(cct_),\n  name(nm),\n  rank(-1), \n  messenger(m),\n  con_self(m ? m->get_loopback_connection() : NULL),\n  lock(\"Monitor::lock\"),\n  timer(cct_, lock),\n  finisher(cct_, \"mon_finisher\", \"fin\"),\n  cpu_tp(cct, \"Monitor::cpu_tp\", \"cpu_tp\", g_conf->mon_cpu_threads),\n  has_ever_joined(false),\n  logger(NULL), cluster_logger(NULL), cluster_logger_registered(false),\n  monmap(map),\n  log_client(cct_, messenger, monmap, LogClient::FLAG_MON),\n  key_server(cct, &keyring),\n  auth_cluster_required(cct,\n\t\t\tcct->_conf->auth_supported.empty() ?\n\t\t\tcct->_conf->auth_cluster_required : cct->_conf->auth_supported),\n  auth_service_required(cct,\n\t\t\tcct->_conf->auth_supported.empty() ?\n\t\t\tcct->_conf->auth_service_required : cct->_conf->auth_supported ),\n  mgr_messenger(mgr_m),\n  mgr_client(cct_, mgr_m),\n  pgservice(nullptr),\n  store(s),\n  \n  state(STATE_PROBING),\n  \n  elector(this),\n  required_features(0),\n  leader(0),\n  quorum_con_features(0),\n  // scrub\n  scrub_version(0),\n  scrub_event(NULL),\n  scrub_timeout_event(NULL),\n\n  // sync state\n  sync_provider_count(0),\n  sync_cookie(0),\n  sync_full(false),\n  sync_start_version(0),\n  sync_timeout_event(NULL),\n  sync_last_committed_floor(0),\n\n  timecheck_round(0),\n  timecheck_acks(0),\n  timecheck_rounds_since_clean(0),\n  timecheck_event(NULL),\n\n  paxos_service(PAXOS_NUM),\n  admin_hook(NULL),\n  routed_request_tid(0),\n  op_tracker(cct, true, 1)\n{\n  clog = log_client.create_channel(CLOG_CHANNEL_CLUSTER);\n  audit_clog = log_client.create_channel(CLOG_CHANNEL_AUDIT);\n\n  update_log_clients();\n\n  paxos = new Paxos(this, \"paxos\");\n\n  paxos_service[PAXOS_MDSMAP] = new MDSMonitor(this, paxos, \"mdsmap\");\n  paxos_service[PAXOS_MONMAP] = new MonmapMonitor(this, paxos, \"monmap\");\n  paxos_service[PAXOS_OSDMAP] = new OSDMonitor(cct, this, paxos, \"osdmap\");\n  paxos_service[PAXOS_PGMAP] = new PGMonitor(this, paxos, \"pgmap\");\n  paxos_service[PAXOS_LOG] = new LogMonitor(this, paxos, \"logm\");\n  paxos_service[PAXOS_AUTH] = new AuthMonitor(this, paxos, \"auth\");\n  paxos_service[PAXOS_MGR] = new MgrMonitor(this, paxos, \"mgr\");\n  paxos_service[PAXOS_MGRSTAT] = new MgrStatMonitor(this, paxos, \"mgrstat\");\n  paxos_service[PAXOS_HEALTH] = new HealthMonitor(this, paxos, \"health\");\n\n  health_monitor = new OldHealthMonitor(this);\n  config_key_service = new ConfigKeyService(this, paxos);\n\n  mon_caps = new MonCap();\n  bool r = mon_caps->parse(\"allow *\", NULL);\n  assert(r);\n\n  exited_quorum = ceph_clock_now();\n\n  // prepare local commands\n  local_mon_commands.resize(ARRAY_SIZE(mon_commands));\n  for (unsigned i = 0; i < ARRAY_SIZE(mon_commands); ++i) {\n    local_mon_commands[i] = mon_commands[i];\n  }\n  MonCommand::encode_vector(local_mon_commands, local_mon_commands_bl);\n\n  local_upgrading_mon_commands = local_mon_commands;\n  for (unsigned i = 0; i < ARRAY_SIZE(pgmonitor_commands); ++i) {\n    local_upgrading_mon_commands.push_back(pgmonitor_commands[i]);\n  }\n  MonCommand::encode_vector(local_upgrading_mon_commands,\n\t\t\t    local_upgrading_mon_commands_bl);\n\n  // assume our commands until we have an election.  this only means\n  // we won't reply with EINVAL before the election; any command that\n  // actually matters will wait until we have quorum etc and then\n  // retry (and revalidate).\n  leader_mon_commands = local_mon_commands;\n\n  // note: OSDMonitor may update this based on the luminous flag.\n  pgservice = mgrstatmon()->get_pg_stat_service();\n}\n\nMonitor::~Monitor()\n{\n  for (vector<PaxosService*>::iterator p = paxos_service.begin(); p != paxos_service.end(); ++p)\n    delete *p;\n  delete health_monitor;\n  delete config_key_service;\n  delete paxos;\n  assert(session_map.sessions.empty());\n  delete mon_caps;\n}\n\n\nclass AdminHook : public AdminSocketHook {\n  Monitor *mon;\npublic:\n  explicit AdminHook(Monitor *m) : mon(m) {}\n  bool call(std::string command, cmdmap_t& cmdmap, std::string format,\n\t    bufferlist& out) override {\n    stringstream ss;\n    mon->do_admin_command(command, cmdmap, format, ss);\n    out.append(ss);\n    return true;\n  }\n};\n\nvoid Monitor::do_admin_command(string command, cmdmap_t& cmdmap, string format,\n\t\t\t       ostream& ss)\n{\n  Mutex::Locker l(lock);\n\n  boost::scoped_ptr<Formatter> f(Formatter::create(format));\n\n  string args;\n  for (cmdmap_t::iterator p = cmdmap.begin();\n       p != cmdmap.end(); ++p) {\n    if (p->first == \"prefix\")\n      continue;\n    if (!args.empty())\n      args += \", \";\n    args += cmd_vartype_stringify(p->second);\n  }\n  args = \"[\" + args + \"]\";\n\n  bool read_only = (command == \"mon_status\" ||\n                    command == \"mon metadata\" ||\n                    command == \"quorum_status\" ||\n                    command == \"ops\" ||\n                    command == \"sessions\");\n\n  (read_only ? audit_clog->debug() : audit_clog->info())\n    << \"from='admin socket' entity='admin socket' \"\n    << \"cmd='\" << command << \"' args=\" << args << \": dispatch\";\n\n  if (command == \"mon_status\") {\n    get_mon_status(f.get(), ss);\n    if (f)\n      f->flush(ss);\n  } else if (command == \"quorum_status\") {\n    _quorum_status(f.get(), ss);\n  } else if (command == \"sync_force\") {\n    string validate;\n    if ((!cmd_getval(g_ceph_context, cmdmap, \"validate\", validate)) ||\n\t(validate != \"--yes-i-really-mean-it\")) {\n      ss << \"are you SURE? this will mean the monitor store will be erased \"\n            \"the next time the monitor is restarted.  pass \"\n            \"'--yes-i-really-mean-it' if you really do.\";\n      goto abort;\n    }\n    sync_force(f.get(), ss);\n  } else if (command.compare(0, 23, \"add_bootstrap_peer_hint\") == 0) {\n    if (!_add_bootstrap_peer_hint(command, cmdmap, ss))\n      goto abort;\n  } else if (command == \"quorum enter\") {\n    elector.start_participating();\n    start_election();\n    ss << \"started responding to quorum, initiated new election\";\n  } else if (command == \"quorum exit\") {\n    start_election();\n    elector.stop_participating();\n    ss << \"stopped responding to quorum, initiated new election\";\n  } else if (command == \"ops\") {\n    (void)op_tracker.dump_ops_in_flight(f.get());\n    if (f) {\n      f->flush(ss);\n    }\n  } else if (command == \"sessions\") {\n\n    if (f) {\n      f->open_array_section(\"sessions\");\n      for (auto p : session_map.sessions) {\n        f->dump_stream(\"session\") << *p;\n      }\n      f->close_section();\n      f->flush(ss);\n    }\n\n  } else {\n    assert(0 == \"bad AdminSocket command binding\");\n  }\n  (read_only ? audit_clog->debug() : audit_clog->info())\n    << \"from='admin socket' \"\n    << \"entity='admin socket' \"\n    << \"cmd=\" << command << \" \"\n    << \"args=\" << args << \": finished\";\n  return;\n\nabort:\n  (read_only ? audit_clog->debug() : audit_clog->info())\n    << \"from='admin socket' \"\n    << \"entity='admin socket' \"\n    << \"cmd=\" << command << \" \"\n    << \"args=\" << args << \": aborted\";\n}\n\nvoid Monitor::handle_signal(int signum)\n{\n  assert(signum == SIGINT || signum == SIGTERM);\n  derr << \"*** Got Signal \" << sig_str(signum) << \" ***\" << dendl;\n  shutdown();\n}\n\nCompatSet Monitor::get_initial_supported_features()\n{\n  CompatSet::FeatureSet ceph_mon_feature_compat;\n  CompatSet::FeatureSet ceph_mon_feature_ro_compat;\n  CompatSet::FeatureSet ceph_mon_feature_incompat;\n  ceph_mon_feature_incompat.insert(CEPH_MON_FEATURE_INCOMPAT_BASE);\n  ceph_mon_feature_incompat.insert(CEPH_MON_FEATURE_INCOMPAT_SINGLE_PAXOS);\n  return CompatSet(ceph_mon_feature_compat, ceph_mon_feature_ro_compat,\n\t\t   ceph_mon_feature_incompat);\n}\n\nCompatSet Monitor::get_supported_features()\n{\n  CompatSet compat = get_initial_supported_features();\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_OSD_ERASURE_CODES);\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_OSDMAP_ENC);\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V2);\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V3);\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_KRAKEN);\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_LUMINOUS);\n  return compat;\n}\n\nCompatSet Monitor::get_legacy_features()\n{\n  CompatSet::FeatureSet ceph_mon_feature_compat;\n  CompatSet::FeatureSet ceph_mon_feature_ro_compat;\n  CompatSet::FeatureSet ceph_mon_feature_incompat;\n  ceph_mon_feature_incompat.insert(CEPH_MON_FEATURE_INCOMPAT_BASE);\n  return CompatSet(ceph_mon_feature_compat, ceph_mon_feature_ro_compat,\n\t\t   ceph_mon_feature_incompat);\n}\n\nint Monitor::check_features(MonitorDBStore *store)\n{\n  CompatSet required = get_supported_features();\n  CompatSet ondisk;\n\n  read_features_off_disk(store, &ondisk);\n\n  if (!required.writeable(ondisk)) {\n    CompatSet diff = required.unsupported(ondisk);\n    generic_derr << \"ERROR: on disk data includes unsupported features: \" << diff << dendl;\n    return -EPERM;\n  }\n\n  return 0;\n}\n\nvoid Monitor::read_features_off_disk(MonitorDBStore *store, CompatSet *features)\n{\n  bufferlist featuresbl;\n  store->get(MONITOR_NAME, COMPAT_SET_LOC, featuresbl);\n  if (featuresbl.length() == 0) {\n    generic_dout(0) << \"WARNING: mon fs missing feature list.\\n\"\n            << \"Assuming it is old-style and introducing one.\" << dendl;\n    //we only want the baseline ~v.18 features assumed to be on disk.\n    //If new features are introduced this code needs to disappear or\n    //be made smarter.\n    *features = get_legacy_features();\n\n    features->encode(featuresbl);\n    auto t(std::make_shared<MonitorDBStore::Transaction>());\n    t->put(MONITOR_NAME, COMPAT_SET_LOC, featuresbl);\n    store->apply_transaction(t);\n  } else {\n    bufferlist::iterator it = featuresbl.begin();\n    features->decode(it);\n  }\n}\n\nvoid Monitor::read_features()\n{\n  read_features_off_disk(store, &features);\n  dout(10) << \"features \" << features << dendl;\n\n  calc_quorum_requirements();\n  dout(10) << \"required_features \" << required_features << dendl;\n}\n\nvoid Monitor::write_features(MonitorDBStore::TransactionRef t)\n{\n  bufferlist bl;\n  features.encode(bl);\n  t->put(MONITOR_NAME, COMPAT_SET_LOC, bl);\n}\n\nconst char** Monitor::get_tracked_conf_keys() const\n{\n  static const char* KEYS[] = {\n    \"crushtool\", // helpful for testing\n    \"mon_election_timeout\",\n    \"mon_lease\",\n    \"mon_lease_renew_interval_factor\",\n    \"mon_lease_ack_timeout_factor\",\n    \"mon_accept_timeout_factor\",\n    // clog & admin clog\n    \"clog_to_monitors\",\n    \"clog_to_syslog\",\n    \"clog_to_syslog_facility\",\n    \"clog_to_syslog_level\",\n    \"clog_to_graylog\",\n    \"clog_to_graylog_host\",\n    \"clog_to_graylog_port\",\n    \"host\",\n    \"fsid\",\n    // periodic health to clog\n    \"mon_health_to_clog\",\n    \"mon_health_to_clog_interval\",\n    \"mon_health_to_clog_tick_interval\",\n    // scrub interval\n    \"mon_scrub_interval\",\n    NULL\n  };\n  return KEYS;\n}\n\nvoid Monitor::handle_conf_change(const struct md_config_t *conf,\n                                 const std::set<std::string> &changed)\n{\n  sanitize_options();\n\n  dout(10) << __func__ << \" \" << changed << dendl;\n\n  if (changed.count(\"clog_to_monitors\") ||\n      changed.count(\"clog_to_syslog\") ||\n      changed.count(\"clog_to_syslog_level\") ||\n      changed.count(\"clog_to_syslog_facility\") ||\n      changed.count(\"clog_to_graylog\") ||\n      changed.count(\"clog_to_graylog_host\") ||\n      changed.count(\"clog_to_graylog_port\") ||\n      changed.count(\"host\") ||\n      changed.count(\"fsid\")) {\n    update_log_clients();\n  }\n\n  if (changed.count(\"mon_health_to_clog\") ||\n      changed.count(\"mon_health_to_clog_interval\") ||\n      changed.count(\"mon_health_to_clog_tick_interval\")) {\n    health_to_clog_update_conf(changed);\n  }\n\n  if (changed.count(\"mon_scrub_interval\")) {\n    scrub_update_interval(conf->mon_scrub_interval);\n  }\n}\n\nvoid Monitor::update_log_clients()\n{\n  map<string,string> log_to_monitors;\n  map<string,string> log_to_syslog;\n  map<string,string> log_channel;\n  map<string,string> log_prio;\n  map<string,string> log_to_graylog;\n  map<string,string> log_to_graylog_host;\n  map<string,string> log_to_graylog_port;\n  uuid_d fsid;\n  string host;\n\n  if (parse_log_client_options(g_ceph_context, log_to_monitors, log_to_syslog,\n\t\t\t       log_channel, log_prio, log_to_graylog,\n\t\t\t       log_to_graylog_host, log_to_graylog_port,\n\t\t\t       fsid, host))\n    return;\n\n  clog->update_config(log_to_monitors, log_to_syslog,\n\t\t      log_channel, log_prio, log_to_graylog,\n\t\t      log_to_graylog_host, log_to_graylog_port,\n\t\t      fsid, host);\n\n  audit_clog->update_config(log_to_monitors, log_to_syslog,\n\t\t\t    log_channel, log_prio, log_to_graylog,\n\t\t\t    log_to_graylog_host, log_to_graylog_port,\n\t\t\t    fsid, host);\n}\n\nint Monitor::sanitize_options()\n{\n  int r = 0;\n\n  // mon_lease must be greater than mon_lease_renewal; otherwise we\n  // may incur in leases expiring before they are renewed.\n  if (g_conf->mon_lease_renew_interval_factor >= 1.0) {\n    clog->error() << \"mon_lease_renew_interval_factor (\"\n\t\t  << g_conf->mon_lease_renew_interval_factor\n\t\t  << \") must be less than 1.0\";\n    r = -EINVAL;\n  }\n\n  // mon_lease_ack_timeout must be greater than mon_lease to make sure we've\n  // got time to renew the lease and get an ack for it. Having both options\n  // with the same value, for a given small vale, could mean timing out if\n  // the monitors happened to be overloaded -- or even under normal load for\n  // a small enough value.\n  if (g_conf->mon_lease_ack_timeout_factor <= 1.0) {\n    clog->error() << \"mon_lease_ack_timeout_factor (\"\n\t\t  << g_conf->mon_lease_ack_timeout_factor\n\t\t  << \") must be greater than 1.0\";\n    r = -EINVAL;\n  }\n\n  return r;\n}\n\nint Monitor::preinit()\n{\n  lock.Lock();\n\n  dout(1) << \"preinit fsid \" << monmap->fsid << dendl;\n\n  int r = sanitize_options();\n  if (r < 0) {\n    derr << \"option sanitization failed!\" << dendl;\n    lock.Unlock();\n    return r;\n  }\n\n  assert(!logger);\n  {\n    PerfCountersBuilder pcb(g_ceph_context, \"mon\", l_mon_first, l_mon_last);\n    pcb.add_u64(l_mon_num_sessions, \"num_sessions\", \"Open sessions\", \"sess\",\n        PerfCountersBuilder::PRIO_USEFUL);\n    pcb.add_u64_counter(l_mon_session_add, \"session_add\", \"Created sessions\",\n        \"sadd\", PerfCountersBuilder::PRIO_INTERESTING);\n    pcb.add_u64_counter(l_mon_session_rm, \"session_rm\", \"Removed sessions\",\n        \"srm\", PerfCountersBuilder::PRIO_INTERESTING);\n    pcb.add_u64_counter(l_mon_session_trim, \"session_trim\", \"Trimmed sessions\",\n        \"strm\", PerfCountersBuilder::PRIO_USEFUL);\n    pcb.add_u64_counter(l_mon_num_elections, \"num_elections\", \"Elections participated in\",\n        \"ecnt\", PerfCountersBuilder::PRIO_USEFUL);\n    pcb.add_u64_counter(l_mon_election_call, \"election_call\", \"Elections started\",\n        \"estt\", PerfCountersBuilder::PRIO_INTERESTING);\n    pcb.add_u64_counter(l_mon_election_win, \"election_win\", \"Elections won\",\n        \"ewon\", PerfCountersBuilder::PRIO_INTERESTING);\n    pcb.add_u64_counter(l_mon_election_lose, \"election_lose\", \"Elections lost\",\n        \"elst\", PerfCountersBuilder::PRIO_INTERESTING);\n    logger = pcb.create_perf_counters();\n    cct->get_perfcounters_collection()->add(logger);\n  }\n\n  assert(!cluster_logger);\n  {\n    PerfCountersBuilder pcb(g_ceph_context, \"cluster\", l_cluster_first, l_cluster_last);\n    pcb.add_u64(l_cluster_num_mon, \"num_mon\", \"Monitors\");\n    pcb.add_u64(l_cluster_num_mon_quorum, \"num_mon_quorum\", \"Monitors in quorum\");\n    pcb.add_u64(l_cluster_num_osd, \"num_osd\", \"OSDs\");\n    pcb.add_u64(l_cluster_num_osd_up, \"num_osd_up\", \"OSDs that are up\");\n    pcb.add_u64(l_cluster_num_osd_in, \"num_osd_in\", \"OSD in state \\\"in\\\" (they are in cluster)\");\n    pcb.add_u64(l_cluster_osd_epoch, \"osd_epoch\", \"Current epoch of OSD map\");\n    pcb.add_u64(l_cluster_osd_bytes, \"osd_bytes\", \"Total capacity of cluster\");\n    pcb.add_u64(l_cluster_osd_bytes_used, \"osd_bytes_used\", \"Used space\");\n    pcb.add_u64(l_cluster_osd_bytes_avail, \"osd_bytes_avail\", \"Available space\");\n    pcb.add_u64(l_cluster_num_pool, \"num_pool\", \"Pools\");\n    pcb.add_u64(l_cluster_num_pg, \"num_pg\", \"Placement groups\");\n    pcb.add_u64(l_cluster_num_pg_active_clean, \"num_pg_active_clean\", \"Placement groups in active+clean state\");\n    pcb.add_u64(l_cluster_num_pg_active, \"num_pg_active\", \"Placement groups in active state\");\n    pcb.add_u64(l_cluster_num_pg_peering, \"num_pg_peering\", \"Placement groups in peering state\");\n    pcb.add_u64(l_cluster_num_object, \"num_object\", \"Objects\");\n    pcb.add_u64(l_cluster_num_object_degraded, \"num_object_degraded\", \"Degraded (missing replicas) objects\");\n    pcb.add_u64(l_cluster_num_object_misplaced, \"num_object_misplaced\", \"Misplaced (wrong location in the cluster) objects\");\n    pcb.add_u64(l_cluster_num_object_unfound, \"num_object_unfound\", \"Unfound objects\");\n    pcb.add_u64(l_cluster_num_bytes, \"num_bytes\", \"Size of all objects\");\n    pcb.add_u64(l_cluster_num_mds_up, \"num_mds_up\", \"MDSs that are up\");\n    pcb.add_u64(l_cluster_num_mds_in, \"num_mds_in\", \"MDS in state \\\"in\\\" (they are in cluster)\");\n    pcb.add_u64(l_cluster_num_mds_failed, \"num_mds_failed\", \"Failed MDS\");\n    pcb.add_u64(l_cluster_mds_epoch, \"mds_epoch\", \"Current epoch of MDS map\");\n    cluster_logger = pcb.create_perf_counters();\n  }\n\n  paxos->init_logger();\n\n  // verify cluster_uuid\n  {\n    int r = check_fsid();\n    if (r == -ENOENT)\n      r = write_fsid();\n    if (r < 0) {\n      lock.Unlock();\n      return r;\n    }\n  }\n\n  // open compatset\n  read_features();\n\n  // have we ever joined a quorum?\n  has_ever_joined = (store->get(MONITOR_NAME, \"joined\") != 0);\n  dout(10) << \"has_ever_joined = \" << (int)has_ever_joined << dendl;\n\n  if (!has_ever_joined) {\n    // impose initial quorum restrictions?\n    list<string> initial_members;\n    get_str_list(g_conf->mon_initial_members, initial_members);\n\n    if (!initial_members.empty()) {\n      dout(1) << \" initial_members \" << initial_members << \", filtering seed monmap\" << dendl;\n\n      monmap->set_initial_members(g_ceph_context, initial_members, name, messenger->get_myaddr(),\n\t\t\t\t  &extra_probe_peers);\n\n      dout(10) << \" monmap is \" << *monmap << dendl;\n      dout(10) << \" extra probe peers \" << extra_probe_peers << dendl;\n    }\n  } else if (!monmap->contains(name)) {\n    derr << \"not in monmap and have been in a quorum before; \"\n         << \"must have been removed\" << dendl;\n    if (g_conf->mon_force_quorum_join) {\n      dout(0) << \"we should have died but \"\n              << \"'mon_force_quorum_join' is set -- allowing boot\" << dendl;\n    } else {\n      derr << \"commit suicide!\" << dendl;\n      lock.Unlock();\n      return -ENOENT;\n    }\n  }\n\n  {\n    // We have a potentially inconsistent store state in hands. Get rid of it\n    // and start fresh.\n    bool clear_store = false;\n    if (store->exists(\"mon_sync\", \"in_sync\")) {\n      dout(1) << __func__ << \" clean up potentially inconsistent store state\"\n\t      << dendl;\n      clear_store = true;\n    }\n\n    if (store->get(\"mon_sync\", \"force_sync\") > 0) {\n      dout(1) << __func__ << \" force sync by clearing store state\" << dendl;\n      clear_store = true;\n    }\n\n    if (clear_store) {\n      set<string> sync_prefixes = get_sync_targets_names();\n      store->clear(sync_prefixes);\n    }\n  }\n\n  sync_last_committed_floor = store->get(\"mon_sync\", \"last_committed_floor\");\n  dout(10) << \"sync_last_committed_floor \" << sync_last_committed_floor << dendl;\n\n  init_paxos();\n  health_monitor->init();\n\n  if (is_keyring_required()) {\n    // we need to bootstrap authentication keys so we can form an\n    // initial quorum.\n    if (authmon()->get_last_committed() == 0) {\n      dout(10) << \"loading initial keyring to bootstrap authentication for mkfs\" << dendl;\n      bufferlist bl;\n      int err = store->get(\"mkfs\", \"keyring\", bl);\n      if (err == 0 && bl.length() > 0) {\n        // Attempt to decode and extract keyring only if it is found.\n        KeyRing keyring;\n        bufferlist::iterator p = bl.begin();\n        ::decode(keyring, p);\n        extract_save_mon_key(keyring);\n      }\n    }\n\n    string keyring_loc = g_conf->mon_data + \"/keyring\";\n\n    r = keyring.load(cct, keyring_loc);\n    if (r < 0) {\n      EntityName mon_name;\n      mon_name.set_type(CEPH_ENTITY_TYPE_MON);\n      EntityAuth mon_key;\n      if (key_server.get_auth(mon_name, mon_key)) {\n\tdout(1) << \"copying mon. key from old db to external keyring\" << dendl;\n\tkeyring.add(mon_name, mon_key);\n\tbufferlist bl;\n\tkeyring.encode_plaintext(bl);\n\twrite_default_keyring(bl);\n      } else {\n\tderr << \"unable to load initial keyring \" << g_conf->keyring << dendl;\n\tlock.Unlock();\n\treturn r;\n      }\n    }\n  }\n\n  admin_hook = new AdminHook(this);\n  AdminSocket* admin_socket = cct->get_admin_socket();\n\n  // unlock while registering to avoid mon_lock -> admin socket lock dependency.\n  lock.Unlock();\n  r = admin_socket->register_command(\"mon_status\", \"mon_status\", admin_hook,\n\t\t\t\t     \"show current monitor status\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"quorum_status\", \"quorum_status\",\n\t\t\t\t     admin_hook, \"show current quorum status\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"sync_force\",\n\t\t\t\t     \"sync_force name=validate,\"\n\t\t\t\t     \"type=CephChoices,\"\n\t\t\t             \"strings=--yes-i-really-mean-it\",\n\t\t\t\t     admin_hook,\n\t\t\t\t     \"force sync of and clear monitor store\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"add_bootstrap_peer_hint\",\n\t\t\t\t     \"add_bootstrap_peer_hint name=addr,\"\n\t\t\t\t     \"type=CephIPAddr\",\n\t\t\t\t     admin_hook,\n\t\t\t\t     \"add peer address as potential bootstrap\"\n\t\t\t\t     \" peer for cluster bringup\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"quorum enter\", \"quorum enter\",\n                                     admin_hook,\n                                     \"force monitor back into quorum\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"quorum exit\", \"quorum exit\",\n                                     admin_hook,\n                                     \"force monitor out of the quorum\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"ops\",\n                                     \"ops\",\n                                     admin_hook,\n                                     \"show the ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"sessions\",\n                                     \"sessions\",\n                                     admin_hook,\n                                     \"list existing sessions\");\n  assert(r == 0);\n\n  lock.Lock();\n\n  // add ourselves as a conf observer\n  g_conf->add_observer(this);\n\n  lock.Unlock();\n  return 0;\n}\n\nint Monitor::init()\n{\n  dout(2) << \"init\" << dendl;\n  Mutex::Locker l(lock);\n\n  finisher.start();\n\n  // start ticker\n  timer.init();\n  new_tick();\n\n  cpu_tp.start();\n\n  // i'm ready!\n  messenger->add_dispatcher_tail(this);\n\n  mgr_client.init();\n  mgr_messenger->add_dispatcher_tail(&mgr_client);\n  mgr_messenger->add_dispatcher_tail(this);  // for auth ms_* calls\n\n  bootstrap();\n  // add features of myself into feature_map\n  session_map.feature_map.add_mon(con_self->get_features());\n  return 0;\n}\n\nvoid Monitor::init_paxos()\n{\n  dout(10) << __func__ << dendl;\n  paxos->init();\n\n  // init services\n  for (int i = 0; i < PAXOS_NUM; ++i) {\n    paxos_service[i]->init();\n  }\n\n  refresh_from_paxos(NULL);\n}\n\nvoid Monitor::refresh_from_paxos(bool *need_bootstrap)\n{\n  dout(10) << __func__ << dendl;\n\n  bufferlist bl;\n  int r = store->get(MONITOR_NAME, \"cluster_fingerprint\", bl);\n  if (r >= 0) {\n    try {\n      bufferlist::iterator p = bl.begin();\n      ::decode(fingerprint, p);\n    }\n    catch (buffer::error& e) {\n      dout(10) << __func__ << \" failed to decode cluster_fingerprint\" << dendl;\n    }\n  } else {\n    dout(10) << __func__ << \" no cluster_fingerprint\" << dendl;\n  }\n\n  for (int i = 0; i < PAXOS_NUM; ++i) {\n    paxos_service[i]->refresh(need_bootstrap);\n  }\n  for (int i = 0; i < PAXOS_NUM; ++i) {\n    paxos_service[i]->post_refresh();\n  }\n  load_metadata();\n}\n\nvoid Monitor::register_cluster_logger()\n{\n  if (!cluster_logger_registered) {\n    dout(10) << \"register_cluster_logger\" << dendl;\n    cluster_logger_registered = true;\n    cct->get_perfcounters_collection()->add(cluster_logger);\n  } else {\n    dout(10) << \"register_cluster_logger - already registered\" << dendl;\n  }\n}\n\nvoid Monitor::unregister_cluster_logger()\n{\n  if (cluster_logger_registered) {\n    dout(10) << \"unregister_cluster_logger\" << dendl;\n    cluster_logger_registered = false;\n    cct->get_perfcounters_collection()->remove(cluster_logger);\n  } else {\n    dout(10) << \"unregister_cluster_logger - not registered\" << dendl;\n  }\n}\n\nvoid Monitor::update_logger()\n{\n  cluster_logger->set(l_cluster_num_mon, monmap->size());\n  cluster_logger->set(l_cluster_num_mon_quorum, quorum.size());\n}\n\nvoid Monitor::shutdown()\n{\n  dout(1) << \"shutdown\" << dendl;\n\n  lock.Lock();\n\n  wait_for_paxos_write();\n\n  state = STATE_SHUTDOWN;\n\n  g_conf->remove_observer(this);\n\n  if (admin_hook) {\n    AdminSocket* admin_socket = cct->get_admin_socket();\n    admin_socket->unregister_command(\"mon_status\");\n    admin_socket->unregister_command(\"quorum_status\");\n    admin_socket->unregister_command(\"sync_force\");\n    admin_socket->unregister_command(\"add_bootstrap_peer_hint\");\n    admin_socket->unregister_command(\"quorum enter\");\n    admin_socket->unregister_command(\"quorum exit\");\n    admin_socket->unregister_command(\"ops\");\n    admin_socket->unregister_command(\"sessions\");\n    delete admin_hook;\n    admin_hook = NULL;\n  }\n\n  elector.shutdown();\n\n  mgr_client.shutdown();\n\n  lock.Unlock();\n  finisher.wait_for_empty();\n  finisher.stop();\n  lock.Lock();\n\n  // clean up\n  paxos->shutdown();\n  for (vector<PaxosService*>::iterator p = paxos_service.begin(); p != paxos_service.end(); ++p)\n    (*p)->shutdown();\n  health_monitor->shutdown();\n\n  finish_contexts(g_ceph_context, waitfor_quorum, -ECANCELED);\n  finish_contexts(g_ceph_context, maybe_wait_for_quorum, -ECANCELED);\n\n  timer.shutdown();\n\n  cpu_tp.stop();\n\n  remove_all_sessions();\n\n  if (logger) {\n    cct->get_perfcounters_collection()->remove(logger);\n    delete logger;\n    logger = NULL;\n  }\n  if (cluster_logger) {\n    if (cluster_logger_registered)\n      cct->get_perfcounters_collection()->remove(cluster_logger);\n    delete cluster_logger;\n    cluster_logger = NULL;\n  }\n\n  log_client.shutdown();\n\n  // unlock before msgr shutdown...\n  lock.Unlock();\n\n  messenger->shutdown();  // last thing!  ceph_mon.cc will delete mon.\n  mgr_messenger->shutdown();\n}\n\nvoid Monitor::wait_for_paxos_write()\n{\n  if (paxos->is_writing() || paxos->is_writing_previous()) {\n    dout(10) << __func__ << \" flushing pending write\" << dendl;\n    lock.Unlock();\n    store->flush();\n    lock.Lock();\n    dout(10) << __func__ << \" flushed pending write\" << dendl;\n  }\n}\n\nvoid Monitor::bootstrap()\n{\n  dout(10) << \"bootstrap\" << dendl;\n  wait_for_paxos_write();\n\n  sync_reset_requester();\n  unregister_cluster_logger();\n  cancel_probe_timeout();\n\n  // note my rank\n  int newrank = monmap->get_rank(messenger->get_myaddr());\n  if (newrank < 0 && rank >= 0) {\n    // was i ever part of the quorum?\n    if (has_ever_joined) {\n      dout(0) << \" removed from monmap, suicide.\" << dendl;\n      exit(0);\n    }\n  }\n  if (newrank != rank) {\n    dout(0) << \" my rank is now \" << newrank << \" (was \" << rank << \")\" << dendl;\n    messenger->set_myname(entity_name_t::MON(newrank));\n    rank = newrank;\n\n    // reset all connections, or else our peers will think we are someone else.\n    messenger->mark_down_all();\n  }\n\n  // reset\n  state = STATE_PROBING;\n\n  _reset();\n\n  // sync store\n  if (g_conf->mon_compact_on_bootstrap) {\n    dout(10) << \"bootstrap -- triggering compaction\" << dendl;\n    store->compact();\n    dout(10) << \"bootstrap -- finished compaction\" << dendl;\n  }\n\n  // singleton monitor?\n  if (monmap->size() == 1 && rank == 0) {\n    win_standalone_election();\n    return;\n  }\n\n  reset_probe_timeout();\n\n  // i'm outside the quorum\n  if (monmap->contains(name))\n    outside_quorum.insert(name);\n\n  // probe monitors\n  dout(10) << \"probing other monitors\" << dendl;\n  for (unsigned i = 0; i < monmap->size(); i++) {\n    if ((int)i != rank)\n      messenger->send_message(new MMonProbe(monmap->fsid, MMonProbe::OP_PROBE, name, has_ever_joined),\n\t\t\t      monmap->get_inst(i));\n  }\n  for (set<entity_addr_t>::iterator p = extra_probe_peers.begin();\n       p != extra_probe_peers.end();\n       ++p) {\n    if (*p != messenger->get_myaddr()) {\n      entity_inst_t i;\n      i.name = entity_name_t::MON(-1);\n      i.addr = *p;\n      messenger->send_message(new MMonProbe(monmap->fsid, MMonProbe::OP_PROBE, name, has_ever_joined), i);\n    }\n  }\n}\n\nbool Monitor::_add_bootstrap_peer_hint(string cmd, cmdmap_t& cmdmap, ostream& ss)\n{\n  string addrstr;\n  if (!cmd_getval(g_ceph_context, cmdmap, \"addr\", addrstr)) {\n    ss << \"unable to parse address string value '\"\n         << cmd_vartype_stringify(cmdmap[\"addr\"]) << \"'\";\n    return false;\n  }\n  dout(10) << \"_add_bootstrap_peer_hint '\" << cmd << \"' '\"\n           << addrstr << \"'\" << dendl;\n\n  entity_addr_t addr;\n  const char *end = 0;\n  if (!addr.parse(addrstr.c_str(), &end)) {\n    ss << \"failed to parse addr '\" << addrstr << \"'; syntax is 'add_bootstrap_peer_hint ip[:port]'\";\n    return false;\n  }\n\n  if (is_leader() || is_peon()) {\n    ss << \"mon already active; ignoring bootstrap hint\";\n    return true;\n  }\n\n  if (addr.get_port() == 0)\n    addr.set_port(CEPH_MON_PORT);\n\n  extra_probe_peers.insert(addr);\n  ss << \"adding peer \" << addr << \" to list: \" << extra_probe_peers;\n  return true;\n}\n\n// called by bootstrap(), or on leader|peon -> electing\nvoid Monitor::_reset()\n{\n  dout(10) << __func__ << dendl;\n\n  cancel_probe_timeout();\n  timecheck_finish();\n  health_events_cleanup();\n  health_check_log_times.clear();\n  scrub_event_cancel();\n\n  leader_since = utime_t();\n  if (!quorum.empty()) {\n    exited_quorum = ceph_clock_now();\n  }\n  quorum.clear();\n  outside_quorum.clear();\n  quorum_feature_map.clear();\n\n  scrub_reset();\n\n  paxos->restart();\n\n  for (vector<PaxosService*>::iterator p = paxos_service.begin(); p != paxos_service.end(); ++p)\n    (*p)->restart();\n  health_monitor->finish();\n}\n\n\n// -----------------------------------------------------------\n// sync\n\nset<string> Monitor::get_sync_targets_names()\n{\n  set<string> targets;\n  targets.insert(paxos->get_name());\n  for (int i = 0; i < PAXOS_NUM; ++i)\n    paxos_service[i]->get_store_prefixes(targets);\n  ConfigKeyService *config_key_service_ptr = dynamic_cast<ConfigKeyService*>(config_key_service);\n  assert(config_key_service_ptr);\n  config_key_service_ptr->get_store_prefixes(targets);\n  return targets;\n}\n\n\nvoid Monitor::sync_timeout()\n{\n  dout(10) << __func__ << dendl;\n  assert(state == STATE_SYNCHRONIZING);\n  bootstrap();\n}\n\nvoid Monitor::sync_obtain_latest_monmap(bufferlist &bl)\n{\n  dout(1) << __func__ << dendl;\n\n  MonMap latest_monmap;\n\n  // Grab latest monmap from MonmapMonitor\n  bufferlist monmon_bl;\n  int err = monmon()->get_monmap(monmon_bl);\n  if (err < 0) {\n    if (err != -ENOENT) {\n      derr << __func__\n           << \" something wrong happened while reading the store: \"\n           << cpp_strerror(err) << dendl;\n      assert(0 == \"error reading the store\");\n    }\n  } else {\n    latest_monmap.decode(monmon_bl);\n  }\n\n  // Grab last backed up monmap (if any) and compare epochs\n  if (store->exists(\"mon_sync\", \"latest_monmap\")) {\n    bufferlist backup_bl;\n    int err = store->get(\"mon_sync\", \"latest_monmap\", backup_bl);\n    if (err < 0) {\n      derr << __func__\n           << \" something wrong happened while reading the store: \"\n           << cpp_strerror(err) << dendl;\n      assert(0 == \"error reading the store\");\n    }\n    assert(backup_bl.length() > 0);\n\n    MonMap backup_monmap;\n    backup_monmap.decode(backup_bl);\n\n    if (backup_monmap.epoch > latest_monmap.epoch)\n      latest_monmap = backup_monmap;\n  }\n\n  // Check if our current monmap's epoch is greater than the one we've\n  // got so far.\n  if (monmap->epoch > latest_monmap.epoch)\n    latest_monmap = *monmap;\n\n  dout(1) << __func__ << \" obtained monmap e\" << latest_monmap.epoch << dendl;\n\n  latest_monmap.encode(bl, CEPH_FEATURES_ALL);\n}\n\nvoid Monitor::sync_reset_requester()\n{\n  dout(10) << __func__ << dendl;\n\n  if (sync_timeout_event) {\n    timer.cancel_event(sync_timeout_event);\n    sync_timeout_event = NULL;\n  }\n\n  sync_provider = entity_inst_t();\n  sync_cookie = 0;\n  sync_full = false;\n  sync_start_version = 0;\n}\n\nvoid Monitor::sync_reset_provider()\n{\n  dout(10) << __func__ << dendl;\n  sync_providers.clear();\n}\n\nvoid Monitor::sync_start(entity_inst_t &other, bool full)\n{\n  dout(10) << __func__ << \" \" << other << (full ? \" full\" : \" recent\") << dendl;\n\n  assert(state == STATE_PROBING ||\n\t state == STATE_SYNCHRONIZING);\n  state = STATE_SYNCHRONIZING;\n\n  // make sure are not a provider for anyone!\n  sync_reset_provider();\n\n  sync_full = full;\n\n  if (sync_full) {\n    // stash key state, and mark that we are syncing\n    auto t(std::make_shared<MonitorDBStore::Transaction>());\n    sync_stash_critical_state(t);\n    t->put(\"mon_sync\", \"in_sync\", 1);\n\n    sync_last_committed_floor = MAX(sync_last_committed_floor, paxos->get_version());\n    dout(10) << __func__ << \" marking sync in progress, storing sync_last_committed_floor \"\n\t     << sync_last_committed_floor << dendl;\n    t->put(\"mon_sync\", \"last_committed_floor\", sync_last_committed_floor);\n\n    store->apply_transaction(t);\n\n    assert(g_conf->mon_sync_requester_kill_at != 1);\n\n    // clear the underlying store\n    set<string> targets = get_sync_targets_names();\n    dout(10) << __func__ << \" clearing prefixes \" << targets << dendl;\n    store->clear(targets);\n\n    // make sure paxos knows it has been reset.  this prevents a\n    // bootstrap and then different probe reply order from possibly\n    // deciding a partial or no sync is needed.\n    paxos->init();\n\n    assert(g_conf->mon_sync_requester_kill_at != 2);\n  }\n\n  // assume 'other' as the leader. We will update the leader once we receive\n  // a reply to the sync start.\n  sync_provider = other;\n\n  sync_reset_timeout();\n\n  MMonSync *m = new MMonSync(sync_full ? MMonSync::OP_GET_COOKIE_FULL : MMonSync::OP_GET_COOKIE_RECENT);\n  if (!sync_full)\n    m->last_committed = paxos->get_version();\n  messenger->send_message(m, sync_provider);\n}\n\nvoid Monitor::sync_stash_critical_state(MonitorDBStore::TransactionRef t)\n{\n  dout(10) << __func__ << dendl;\n  bufferlist backup_monmap;\n  sync_obtain_latest_monmap(backup_monmap);\n  assert(backup_monmap.length() > 0);\n  t->put(\"mon_sync\", \"latest_monmap\", backup_monmap);\n}\n\nvoid Monitor::sync_reset_timeout()\n{\n  dout(10) << __func__ << dendl;\n  if (sync_timeout_event)\n    timer.cancel_event(sync_timeout_event);\n  sync_timeout_event = timer.add_event_after(\n    g_conf->mon_sync_timeout,\n    new C_MonContext(this, [this](int) {\n\tsync_timeout();\n      }));\n}\n\nvoid Monitor::sync_finish(version_t last_committed)\n{\n  dout(10) << __func__ << \" lc \" << last_committed << \" from \" << sync_provider << dendl;\n\n  assert(g_conf->mon_sync_requester_kill_at != 7);\n\n  if (sync_full) {\n    // finalize the paxos commits\n    auto tx(std::make_shared<MonitorDBStore::Transaction>());\n    paxos->read_and_prepare_transactions(tx, sync_start_version,\n\t\t\t\t\t last_committed);\n    tx->put(paxos->get_name(), \"last_committed\", last_committed);\n\n    dout(30) << __func__ << \" final tx dump:\\n\";\n    JSONFormatter f(true);\n    tx->dump(&f);\n    f.flush(*_dout);\n    *_dout << dendl;\n\n    store->apply_transaction(tx);\n  }\n\n  assert(g_conf->mon_sync_requester_kill_at != 8);\n\n  auto t(std::make_shared<MonitorDBStore::Transaction>());\n  t->erase(\"mon_sync\", \"in_sync\");\n  t->erase(\"mon_sync\", \"force_sync\");\n  t->erase(\"mon_sync\", \"last_committed_floor\");\n  store->apply_transaction(t);\n\n  assert(g_conf->mon_sync_requester_kill_at != 9);\n\n  init_paxos();\n\n  assert(g_conf->mon_sync_requester_kill_at != 10);\n\n  bootstrap();\n}\n\nvoid Monitor::handle_sync(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n  switch (m->op) {\n\n    // provider ---------\n\n  case MMonSync::OP_GET_COOKIE_FULL:\n  case MMonSync::OP_GET_COOKIE_RECENT:\n    handle_sync_get_cookie(op);\n    break;\n  case MMonSync::OP_GET_CHUNK:\n    handle_sync_get_chunk(op);\n    break;\n\n    // client -----------\n\n  case MMonSync::OP_COOKIE:\n    handle_sync_cookie(op);\n    break;\n\n  case MMonSync::OP_CHUNK:\n  case MMonSync::OP_LAST_CHUNK:\n    handle_sync_chunk(op);\n    break;\n  case MMonSync::OP_NO_COOKIE:\n    handle_sync_no_cookie(op);\n    break;\n\n  default:\n    dout(0) << __func__ << \" unknown op \" << m->op << dendl;\n    assert(0 == \"unknown op\");\n  }\n}\n\n// leader\n\nvoid Monitor::_sync_reply_no_cookie(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  MMonSync *reply = new MMonSync(MMonSync::OP_NO_COOKIE, m->cookie);\n  m->get_connection()->send_message(reply);\n}\n\nvoid Monitor::handle_sync_get_cookie(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  if (is_synchronizing()) {\n    _sync_reply_no_cookie(op);\n    return;\n  }\n\n  assert(g_conf->mon_sync_provider_kill_at != 1);\n\n  // make sure they can understand us.\n  if ((required_features ^ m->get_connection()->get_features()) &\n      required_features) {\n    dout(5) << \" ignoring peer mon.\" << m->get_source().num()\n\t    << \" has features \" << std::hex\n\t    << m->get_connection()->get_features()\n\t    << \" but we require \" << required_features << std::dec << dendl;\n    return;\n  }\n\n  // make up a unique cookie.  include election epoch (which persists\n  // across restarts for the whole cluster) and a counter for this\n  // process instance.  there is no need to be unique *across*\n  // monitors, though.\n  uint64_t cookie = ((unsigned long long)elector.get_epoch() << 24) + ++sync_provider_count;\n  assert(sync_providers.count(cookie) == 0);\n\n  dout(10) << __func__ << \" cookie \" << cookie << \" for \" << m->get_source_inst() << dendl;\n\n  SyncProvider& sp = sync_providers[cookie];\n  sp.cookie = cookie;\n  sp.entity = m->get_source_inst();\n  sp.reset_timeout(g_ceph_context, g_conf->mon_sync_timeout * 2);\n\n  set<string> sync_targets;\n  if (m->op == MMonSync::OP_GET_COOKIE_FULL) {\n    // full scan\n    sync_targets = get_sync_targets_names();\n    sp.last_committed = paxos->get_version();\n    sp.synchronizer = store->get_synchronizer(sp.last_key, sync_targets);\n    sp.full = true;\n    dout(10) << __func__ << \" will sync prefixes \" << sync_targets << dendl;\n  } else {\n    // just catch up paxos\n    sp.last_committed = m->last_committed;\n  }\n  dout(10) << __func__ << \" will sync from version \" << sp.last_committed << dendl;\n\n  MMonSync *reply = new MMonSync(MMonSync::OP_COOKIE, sp.cookie);\n  reply->last_committed = sp.last_committed;\n  m->get_connection()->send_message(reply);\n}\n\nvoid Monitor::handle_sync_get_chunk(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n\n  if (sync_providers.count(m->cookie) == 0) {\n    dout(10) << __func__ << \" no cookie \" << m->cookie << dendl;\n    _sync_reply_no_cookie(op);\n    return;\n  }\n\n  assert(g_conf->mon_sync_provider_kill_at != 2);\n\n  SyncProvider& sp = sync_providers[m->cookie];\n  sp.reset_timeout(g_ceph_context, g_conf->mon_sync_timeout * 2);\n\n  if (sp.last_committed < paxos->get_first_committed() &&\n      paxos->get_first_committed() > 1) {\n    dout(10) << __func__ << \" sync requester fell behind paxos, their lc \" << sp.last_committed\n\t     << \" < our fc \" << paxos->get_first_committed() << dendl;\n    sync_providers.erase(m->cookie);\n    _sync_reply_no_cookie(op);\n    return;\n  }\n\n  MMonSync *reply = new MMonSync(MMonSync::OP_CHUNK, sp.cookie);\n  auto tx(std::make_shared<MonitorDBStore::Transaction>());\n\n  int left = g_conf->mon_sync_max_payload_size;\n  while (sp.last_committed < paxos->get_version() && left > 0) {\n    bufferlist bl;\n    sp.last_committed++;\n\n    int err = store->get(paxos->get_name(), sp.last_committed, bl);\n    assert(err == 0);\n\n    tx->put(paxos->get_name(), sp.last_committed, bl);\n    left -= bl.length();\n    dout(20) << __func__ << \" including paxos state \" << sp.last_committed\n\t     << dendl;\n  }\n  reply->last_committed = sp.last_committed;\n\n  if (sp.full && left > 0) {\n    sp.synchronizer->get_chunk_tx(tx, left);\n    sp.last_key = sp.synchronizer->get_last_key();\n    reply->last_key = sp.last_key;\n  }\n\n  if ((sp.full && sp.synchronizer->has_next_chunk()) ||\n      sp.last_committed < paxos->get_version()) {\n    dout(10) << __func__ << \" chunk, through version \" << sp.last_committed\n\t     << \" key \" << sp.last_key << dendl;\n  } else {\n    dout(10) << __func__ << \" last chunk, through version \" << sp.last_committed\n\t     << \" key \" << sp.last_key << dendl;\n    reply->op = MMonSync::OP_LAST_CHUNK;\n\n    assert(g_conf->mon_sync_provider_kill_at != 3);\n\n    // clean up our local state\n    sync_providers.erase(sp.cookie);\n  }\n\n  ::encode(*tx, reply->chunk_bl);\n\n  m->get_connection()->send_message(reply);\n}\n\n// requester\n\nvoid Monitor::handle_sync_cookie(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n  if (sync_cookie) {\n    dout(10) << __func__ << \" already have a cookie, ignoring\" << dendl;\n    return;\n  }\n  if (m->get_source_inst() != sync_provider) {\n    dout(10) << __func__ << \" source does not match, discarding\" << dendl;\n    return;\n  }\n  sync_cookie = m->cookie;\n  sync_start_version = m->last_committed;\n\n  sync_reset_timeout();\n  sync_get_next_chunk();\n\n  assert(g_conf->mon_sync_requester_kill_at != 3);\n}\n\nvoid Monitor::sync_get_next_chunk()\n{\n  dout(20) << __func__ << \" cookie \" << sync_cookie << \" provider \" << sync_provider << dendl;\n  if (g_conf->mon_inject_sync_get_chunk_delay > 0) {\n    dout(20) << __func__ << \" injecting delay of \" << g_conf->mon_inject_sync_get_chunk_delay << dendl;\n    usleep((long long)(g_conf->mon_inject_sync_get_chunk_delay * 1000000.0));\n  }\n  MMonSync *r = new MMonSync(MMonSync::OP_GET_CHUNK, sync_cookie);\n  messenger->send_message(r, sync_provider);\n\n  assert(g_conf->mon_sync_requester_kill_at != 4);\n}\n\nvoid Monitor::handle_sync_chunk(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n\n  if (m->cookie != sync_cookie) {\n    dout(10) << __func__ << \" cookie does not match, discarding\" << dendl;\n    return;\n  }\n  if (m->get_source_inst() != sync_provider) {\n    dout(10) << __func__ << \" source does not match, discarding\" << dendl;\n    return;\n  }\n\n  assert(state == STATE_SYNCHRONIZING);\n  assert(g_conf->mon_sync_requester_kill_at != 5);\n\n  auto tx(std::make_shared<MonitorDBStore::Transaction>());\n  tx->append_from_encoded(m->chunk_bl);\n\n  dout(30) << __func__ << \" tx dump:\\n\";\n  JSONFormatter f(true);\n  tx->dump(&f);\n  f.flush(*_dout);\n  *_dout << dendl;\n\n  store->apply_transaction(tx);\n\n  assert(g_conf->mon_sync_requester_kill_at != 6);\n\n  if (!sync_full) {\n    dout(10) << __func__ << \" applying recent paxos transactions as we go\" << dendl;\n    auto tx(std::make_shared<MonitorDBStore::Transaction>());\n    paxos->read_and_prepare_transactions(tx, paxos->get_version() + 1,\n\t\t\t\t\t m->last_committed);\n    tx->put(paxos->get_name(), \"last_committed\", m->last_committed);\n\n    dout(30) << __func__ << \" tx dump:\\n\";\n    JSONFormatter f(true);\n    tx->dump(&f);\n    f.flush(*_dout);\n    *_dout << dendl;\n\n    store->apply_transaction(tx);\n    paxos->init();  // to refresh what we just wrote\n  }\n\n  if (m->op == MMonSync::OP_CHUNK) {\n    sync_reset_timeout();\n    sync_get_next_chunk();\n  } else if (m->op == MMonSync::OP_LAST_CHUNK) {\n    sync_finish(m->last_committed);\n  }\n}\n\nvoid Monitor::handle_sync_no_cookie(MonOpRequestRef op)\n{\n  dout(10) << __func__ << dendl;\n  bootstrap();\n}\n\nvoid Monitor::sync_trim_providers()\n{\n  dout(20) << __func__ << dendl;\n\n  utime_t now = ceph_clock_now();\n  map<uint64_t,SyncProvider>::iterator p = sync_providers.begin();\n  while (p != sync_providers.end()) {\n    if (now > p->second.timeout) {\n      dout(10) << __func__ << \" expiring cookie \" << p->second.cookie << \" for \" << p->second.entity << dendl;\n      sync_providers.erase(p++);\n    } else {\n      ++p;\n    }\n  }\n}\n\n// ---------------------------------------------------\n// probe\n\nvoid Monitor::cancel_probe_timeout()\n{\n  if (probe_timeout_event) {\n    dout(10) << \"cancel_probe_timeout \" << probe_timeout_event << dendl;\n    timer.cancel_event(probe_timeout_event);\n    probe_timeout_event = NULL;\n  } else {\n    dout(10) << \"cancel_probe_timeout (none scheduled)\" << dendl;\n  }\n}\n\nvoid Monitor::reset_probe_timeout()\n{\n  cancel_probe_timeout();\n  probe_timeout_event = new C_MonContext(this, [this](int r) {\n      probe_timeout(r);\n    });\n  double t = g_conf->mon_probe_timeout;\n  if (timer.add_event_after(t, probe_timeout_event)) {\n    dout(10) << \"reset_probe_timeout \" << probe_timeout_event\n\t     << \" after \" << t << \" seconds\" << dendl;\n  } else {\n    probe_timeout_event = nullptr;\n  }\n}\n\nvoid Monitor::probe_timeout(int r)\n{\n  dout(4) << \"probe_timeout \" << probe_timeout_event << dendl;\n  assert(is_probing() || is_synchronizing());\n  assert(probe_timeout_event);\n  probe_timeout_event = NULL;\n  bootstrap();\n}\n\nvoid Monitor::handle_probe(MonOpRequestRef op)\n{\n  MMonProbe *m = static_cast<MMonProbe*>(op->get_req());\n  dout(10) << \"handle_probe \" << *m << dendl;\n\n  if (m->fsid != monmap->fsid) {\n    dout(0) << \"handle_probe ignoring fsid \" << m->fsid << \" != \" << monmap->fsid << dendl;\n    return;\n  }\n\n  switch (m->op) {\n  case MMonProbe::OP_PROBE:\n    handle_probe_probe(op);\n    break;\n\n  case MMonProbe::OP_REPLY:\n    handle_probe_reply(op);\n    break;\n\n  case MMonProbe::OP_MISSING_FEATURES:\n    derr << __func__ << \" missing features, have \" << CEPH_FEATURES_ALL\n\t << \", required \" << m->required_features\n\t << \", missing \" << (m->required_features & ~CEPH_FEATURES_ALL)\n\t << dendl;\n    break;\n  }\n}\n\nvoid Monitor::handle_probe_probe(MonOpRequestRef op)\n{\n  MMonProbe *m = static_cast<MMonProbe*>(op->get_req());\n\n  dout(10) << \"handle_probe_probe \" << m->get_source_inst() << *m\n\t   << \" features \" << m->get_connection()->get_features() << dendl;\n  uint64_t missing = required_features & ~m->get_connection()->get_features();\n  if (missing) {\n    dout(1) << \" peer \" << m->get_source_addr() << \" missing features \"\n\t    << missing << dendl;\n    if (m->get_connection()->has_feature(CEPH_FEATURE_OSD_PRIMARY_AFFINITY)) {\n      MMonProbe *r = new MMonProbe(monmap->fsid, MMonProbe::OP_MISSING_FEATURES,\n\t\t\t\t   name, has_ever_joined);\n      m->required_features = required_features;\n      m->get_connection()->send_message(r);\n    }\n    goto out;\n  }\n\n  if (!is_probing() && !is_synchronizing()) {\n    // If the probing mon is way ahead of us, we need to re-bootstrap.\n    // Normally we capture this case when we initially bootstrap, but\n    // it is possible we pass those checks (we overlap with\n    // quorum-to-be) but fail to join a quorum before it moves past\n    // us.  We need to be kicked back to bootstrap so we can\n    // synchonize, not keep calling elections.\n    if (paxos->get_version() + 1 < m->paxos_first_version) {\n      dout(1) << \" peer \" << m->get_source_addr() << \" has first_committed \"\n\t      << \"ahead of us, re-bootstrapping\" << dendl;\n      bootstrap();\n      goto out;\n\n    }\n  }\n  \n  MMonProbe *r;\n  r = new MMonProbe(monmap->fsid, MMonProbe::OP_REPLY, name, has_ever_joined);\n  r->name = name;\n  r->quorum = quorum;\n  monmap->encode(r->monmap_bl, m->get_connection()->get_features());\n  r->paxos_first_version = paxos->get_first_committed();\n  r->paxos_last_version = paxos->get_version();\n  m->get_connection()->send_message(r);\n\n  // did we discover a peer here?\n  if (!monmap->contains(m->get_source_addr())) {\n    dout(1) << \" adding peer \" << m->get_source_addr()\n\t    << \" to list of hints\" << dendl;\n    extra_probe_peers.insert(m->get_source_addr());\n  }\n\n out:\n  return;\n}\n\nvoid Monitor::handle_probe_reply(MonOpRequestRef op)\n{\n  MMonProbe *m = static_cast<MMonProbe*>(op->get_req());\n  dout(10) << \"handle_probe_reply \" << m->get_source_inst() << *m << dendl;\n  dout(10) << \" monmap is \" << *monmap << dendl;\n\n  // discover name and addrs during probing or electing states.\n  if (!is_probing() && !is_electing()) {\n    return;\n  }\n\n  // newer map, or they've joined a quorum and we haven't?\n  bufferlist mybl;\n  monmap->encode(mybl, m->get_connection()->get_features());\n  // make sure it's actually different; the checks below err toward\n  // taking the other guy's map, which could cause us to loop.\n  if (!mybl.contents_equal(m->monmap_bl)) {\n    MonMap *newmap = new MonMap;\n    newmap->decode(m->monmap_bl);\n    if (m->has_ever_joined && (newmap->get_epoch() > monmap->get_epoch() ||\n\t\t\t       !has_ever_joined)) {\n      dout(10) << \" got newer/committed monmap epoch \" << newmap->get_epoch()\n\t       << \", mine was \" << monmap->get_epoch() << dendl;\n      delete newmap;\n      monmap->decode(m->monmap_bl);\n\n      bootstrap();\n      return;\n    }\n    delete newmap;\n  }\n\n  // rename peer?\n  string peer_name = monmap->get_name(m->get_source_addr());\n  if (monmap->get_epoch() == 0 && peer_name.compare(0, 7, \"noname-\") == 0) {\n    dout(10) << \" renaming peer \" << m->get_source_addr() << \" \"\n\t     << peer_name << \" -> \" << m->name << \" in my monmap\"\n\t     << dendl;\n    monmap->rename(peer_name, m->name);\n\n    if (is_electing()) {\n      bootstrap();\n      return;\n    }\n  } else {\n    dout(10) << \" peer name is \" << peer_name << dendl;\n  }\n\n  // new initial peer?\n  if (monmap->get_epoch() == 0 &&\n      monmap->contains(m->name) &&\n      monmap->get_addr(m->name).is_blank_ip()) {\n    dout(1) << \" learned initial mon \" << m->name << \" addr \" << m->get_source_addr() << dendl;\n    monmap->set_addr(m->name, m->get_source_addr());\n\n    bootstrap();\n    return;\n  }\n\n  // end discover phase\n  if (!is_probing()) {\n    return;\n  }\n\n  assert(paxos != NULL);\n\n  if (is_synchronizing()) {\n    dout(10) << \" currently syncing\" << dendl;\n    return;\n  }\n\n  entity_inst_t other = m->get_source_inst();\n\n  if (m->paxos_last_version < sync_last_committed_floor) {\n    dout(10) << \" peer paxos versions [\" << m->paxos_first_version\n\t     << \",\" << m->paxos_last_version << \"] < my sync_last_committed_floor \"\n\t     << sync_last_committed_floor << \", ignoring\"\n\t     << dendl;\n  } else {\n    if (paxos->get_version() < m->paxos_first_version &&\n\tm->paxos_first_version > 1) {  // no need to sync if we're 0 and they start at 1.\n      dout(10) << \" peer paxos first versions [\" << m->paxos_first_version\n\t       << \",\" << m->paxos_last_version << \"]\"\n\t       << \" vs my version \" << paxos->get_version()\n\t       << \" (too far ahead)\"\n\t       << dendl;\n      cancel_probe_timeout();\n      sync_start(other, true);\n      return;\n    }\n    if (paxos->get_version() + g_conf->paxos_max_join_drift < m->paxos_last_version) {\n      dout(10) << \" peer paxos last version \" << m->paxos_last_version\n\t       << \" vs my version \" << paxos->get_version()\n\t       << \" (too far ahead)\"\n\t       << dendl;\n      cancel_probe_timeout();\n      sync_start(other, false);\n      return;\n    }\n  }\n\n  // is there an existing quorum?\n  if (m->quorum.size()) {\n    dout(10) << \" existing quorum \" << m->quorum << dendl;\n\n    dout(10) << \" peer paxos version \" << m->paxos_last_version\n             << \" vs my version \" << paxos->get_version()\n             << \" (ok)\"\n             << dendl;\n\n    if (monmap->contains(name) &&\n        !monmap->get_addr(name).is_blank_ip()) {\n      // i'm part of the cluster; just initiate a new election\n      start_election();\n    } else {\n      dout(10) << \" ready to join, but i'm not in the monmap or my addr is blank, trying to join\" << dendl;\n      messenger->send_message(new MMonJoin(monmap->fsid, name, messenger->get_myaddr()),\n                              monmap->get_inst(*m->quorum.begin()));\n    }\n  } else {\n    if (monmap->contains(m->name)) {\n      dout(10) << \" mon.\" << m->name << \" is outside the quorum\" << dendl;\n      outside_quorum.insert(m->name);\n    } else {\n      dout(10) << \" mostly ignoring mon.\" << m->name << \", not part of monmap\" << dendl;\n      return;\n    }\n\n    unsigned need = monmap->size() / 2 + 1;\n    dout(10) << \" outside_quorum now \" << outside_quorum << \", need \" << need << dendl;\n    if (outside_quorum.size() >= need) {\n      if (outside_quorum.count(name)) {\n        dout(10) << \" that's enough to form a new quorum, calling election\" << dendl;\n        start_election();\n      } else {\n        dout(10) << \" that's enough to form a new quorum, but it does not include me; waiting\" << dendl;\n      }\n    } else {\n      dout(10) << \" that's not yet enough for a new quorum, waiting\" << dendl;\n    }\n  }\n}\n\nvoid Monitor::join_election()\n{\n  dout(10) << __func__ << dendl;\n  wait_for_paxos_write();\n  _reset();\n  state = STATE_ELECTING;\n\n  logger->inc(l_mon_num_elections);\n}\n\nvoid Monitor::start_election()\n{\n  dout(10) << \"start_election\" << dendl;\n  wait_for_paxos_write();\n  _reset();\n  state = STATE_ELECTING;\n\n  logger->inc(l_mon_num_elections);\n  logger->inc(l_mon_election_call);\n\n  clog->info() << \"mon.\" << name << \" calling monitor election\";\n  elector.call_election();\n}\n\nvoid Monitor::win_standalone_election()\n{\n  dout(1) << \"win_standalone_election\" << dendl;\n\n  // bump election epoch, in case the previous epoch included other\n  // monitors; we need to be able to make the distinction.\n  elector.init();\n  elector.advance_epoch();\n\n  rank = monmap->get_rank(name);\n  assert(rank == 0);\n  set<int> q;\n  q.insert(rank);\n\n  map<int,Metadata> metadata;\n  collect_metadata(&metadata[0]);\n\n  win_election(elector.get_epoch(), q,\n               CEPH_FEATURES_ALL,\n               ceph::features::mon::get_supported(),\n\t       metadata);\n}\n\nconst utime_t& Monitor::get_leader_since() const\n{\n  assert(state == STATE_LEADER);\n  return leader_since;\n}\n\nepoch_t Monitor::get_epoch()\n{\n  return elector.get_epoch();\n}\n\nvoid Monitor::_finish_svc_election()\n{\n  assert(state == STATE_LEADER || state == STATE_PEON);\n\n  for (auto p : paxos_service) {\n    // we already called election_finished() on monmon(); avoid callig twice\n    if (state == STATE_LEADER && p == monmon())\n      continue;\n    p->election_finished();\n  }\n}\n\nvoid Monitor::win_election(epoch_t epoch, set<int>& active, uint64_t features,\n                           const mon_feature_t& mon_features,\n\t\t\t   const map<int,Metadata>& metadata)\n{\n  dout(10) << __func__ << \" epoch \" << epoch << \" quorum \" << active\n\t   << \" features \" << features\n           << \" mon_features \" << mon_features\n           << dendl;\n  assert(is_electing());\n  state = STATE_LEADER;\n  leader_since = ceph_clock_now();\n  leader = rank;\n  quorum = active;\n  quorum_con_features = features;\n  quorum_mon_features = mon_features;\n  pending_metadata = metadata;\n  outside_quorum.clear();\n\n  clog->info() << \"mon.\" << name << \" is new leader, mons \" << get_quorum_names()\n      << \" in quorum (ranks \" << quorum << \")\";\n\n  set_leader_commands(get_local_commands(mon_features));\n\n  paxos->leader_init();\n  // NOTE: tell monmap monitor first.  This is important for the\n  // bootstrap case to ensure that the very first paxos proposal\n  // codifies the monmap.  Otherwise any manner of chaos can ensue\n  // when monitors are call elections or participating in a paxos\n  // round without agreeing on who the participants are.\n  monmon()->election_finished();\n  _finish_svc_election();\n  health_monitor->start(epoch);\n\n  logger->inc(l_mon_election_win);\n\n  // inject new metadata in first transaction.\n  {\n    // include previous metadata for missing mons (that aren't part of\n    // the current quorum).\n    map<int,Metadata> m = metadata;\n    for (unsigned rank = 0; rank < monmap->size(); ++rank) {\n      if (m.count(rank) == 0 &&\n\t  mon_metadata.count(rank)) {\n\tm[rank] = mon_metadata[rank];\n      }\n    }\n\n    // FIXME: This is a bit sloppy because we aren't guaranteed to submit\n    // a new transaction immediately after the election finishes.  We should\n    // do that anyway for other reasons, though.\n    MonitorDBStore::TransactionRef t = paxos->get_pending_transaction();\n    bufferlist bl;\n    ::encode(m, bl);\n    t->put(MONITOR_STORE_PREFIX, \"last_metadata\", bl);\n  }\n\n  finish_election();\n  if (monmap->size() > 1 &&\n      monmap->get_epoch() > 0) {\n    timecheck_start();\n    health_tick_start();\n\n    // Freshen the health status before doing health_to_clog in case\n    // our just-completed election changed the health\n    healthmon()->wait_for_active_ctx(new FunctionContext([this](int r){\n      dout(20) << \"healthmon now active\" << dendl;\n      healthmon()->tick();\n      if (healthmon()->is_proposing()) {\n        dout(20) << __func__ << \" healthmon proposing, waiting\" << dendl;\n        healthmon()->wait_for_finished_proposal(nullptr, new C_MonContext(this,\n              [this](int r){\n                assert(lock.is_locked_by_me());\n                do_health_to_clog_interval();\n              }));\n\n      } else {\n        do_health_to_clog_interval();\n      }\n    }));\n\n    scrub_event_start();\n  }\n}\n\nvoid Monitor::lose_election(epoch_t epoch, set<int> &q, int l,\n                            uint64_t features,\n                            const mon_feature_t& mon_features)\n{\n  state = STATE_PEON;\n  leader_since = utime_t();\n  leader = l;\n  quorum = q;\n  outside_quorum.clear();\n  quorum_con_features = features;\n  quorum_mon_features = mon_features;\n  dout(10) << \"lose_election, epoch \" << epoch << \" leader is mon\" << leader\n\t   << \" quorum is \" << quorum << \" features are \" << quorum_con_features\n           << \" mon_features are \" << quorum_mon_features\n           << dendl;\n\n  paxos->peon_init();\n  _finish_svc_election();\n  health_monitor->start(epoch);\n\n  logger->inc(l_mon_election_lose);\n\n  finish_election();\n\n  if ((quorum_con_features & CEPH_FEATURE_MON_METADATA) &&\n      !HAVE_FEATURE(quorum_con_features, SERVER_LUMINOUS)) {\n    // for pre-luminous mons only\n    Metadata sys_info;\n    collect_metadata(&sys_info);\n    messenger->send_message(new MMonMetadata(sys_info),\n\t\t\t    monmap->get_inst(get_leader()));\n  }\n}\n\nvoid Monitor::collect_metadata(Metadata *m)\n{\n  collect_sys_info(m, g_ceph_context);\n  (*m)[\"addr\"] = stringify(messenger->get_myaddr());\n}\n\nvoid Monitor::finish_election()\n{\n  apply_quorum_to_compatset_features();\n  apply_monmap_to_compatset_features();\n  timecheck_finish();\n  exited_quorum = utime_t();\n  finish_contexts(g_ceph_context, waitfor_quorum);\n  finish_contexts(g_ceph_context, maybe_wait_for_quorum);\n  resend_routed_requests();\n  update_logger();\n  register_cluster_logger();\n\n  // am i named properly?\n  string cur_name = monmap->get_name(messenger->get_myaddr());\n  if (cur_name != name) {\n    dout(10) << \" renaming myself from \" << cur_name << \" -> \" << name << dendl;\n    messenger->send_message(new MMonJoin(monmap->fsid, name, messenger->get_myaddr()),\n\t\t\t    monmap->get_inst(*quorum.begin()));\n  }\n}\n\nvoid Monitor::_apply_compatset_features(CompatSet &new_features)\n{\n  if (new_features.compare(features) != 0) {\n    CompatSet diff = features.unsupported(new_features);\n    dout(1) << __func__ << \" enabling new quorum features: \" << diff << dendl;\n    features = new_features;\n\n    auto t = std::make_shared<MonitorDBStore::Transaction>();\n    write_features(t);\n    store->apply_transaction(t);\n\n    calc_quorum_requirements();\n  }\n}\n\nvoid Monitor::apply_quorum_to_compatset_features()\n{\n  CompatSet new_features(features);\n  if (quorum_con_features & CEPH_FEATURE_OSD_ERASURE_CODES) {\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_OSD_ERASURE_CODES);\n  }\n  if (quorum_con_features & CEPH_FEATURE_OSDMAP_ENC) {\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_OSDMAP_ENC);\n  }\n  if (quorum_con_features & CEPH_FEATURE_ERASURE_CODE_PLUGINS_V2) {\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V2);\n  }\n  if (quorum_con_features & CEPH_FEATURE_ERASURE_CODE_PLUGINS_V3) {\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V3);\n  }\n  dout(5) << __func__ << dendl;\n  _apply_compatset_features(new_features);\n}\n\nvoid Monitor::apply_monmap_to_compatset_features()\n{\n  CompatSet new_features(features);\n  mon_feature_t monmap_features = monmap->get_required_features();\n\n  /* persistent monmap features may go into the compatset.\n   * optional monmap features may not - why?\n   *   because optional monmap features may be set/unset by the admin,\n   *   and possibly by other means that haven't yet been thought out,\n   *   so we can't make the monitor enforce them on start - because they\n   *   may go away.\n   *   this, of course, does not invalidate setting a compatset feature\n   *   for an optional feature - as long as you make sure to clean it up\n   *   once you unset it.\n   */\n  if (monmap_features.contains_all(ceph::features::mon::FEATURE_KRAKEN)) {\n    assert(ceph::features::mon::get_persistent().contains_all(\n           ceph::features::mon::FEATURE_KRAKEN));\n    // this feature should only ever be set if the quorum supports it.\n    assert(HAVE_FEATURE(quorum_con_features, SERVER_KRAKEN));\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_KRAKEN);\n  }\n  if (monmap_features.contains_all(ceph::features::mon::FEATURE_LUMINOUS)) {\n    assert(ceph::features::mon::get_persistent().contains_all(\n           ceph::features::mon::FEATURE_LUMINOUS));\n    // this feature should only ever be set if the quorum supports it.\n    assert(HAVE_FEATURE(quorum_con_features, SERVER_LUMINOUS));\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_LUMINOUS);\n  }\n\n  dout(5) << __func__ << dendl;\n  _apply_compatset_features(new_features);\n}\n\nvoid Monitor::calc_quorum_requirements()\n{\n  required_features = 0;\n\n  // compatset\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_OSD_ERASURE_CODES)) {\n    required_features |= CEPH_FEATURE_OSD_ERASURE_CODES;\n  }\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_OSDMAP_ENC)) {\n    required_features |= CEPH_FEATURE_OSDMAP_ENC;\n  }\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V2)) {\n    required_features |= CEPH_FEATURE_ERASURE_CODE_PLUGINS_V2;\n  }\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V3)) {\n    required_features |= CEPH_FEATURE_ERASURE_CODE_PLUGINS_V3;\n  }\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_KRAKEN)) {\n    required_features |= CEPH_FEATUREMASK_SERVER_KRAKEN;\n  }\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_LUMINOUS)) {\n    required_features |= CEPH_FEATUREMASK_SERVER_LUMINOUS;\n  }\n\n  // monmap\n  if (monmap->get_required_features().contains_all(\n\tceph::features::mon::FEATURE_KRAKEN)) {\n    required_features |= CEPH_FEATUREMASK_SERVER_KRAKEN;\n  }\n  if (monmap->get_required_features().contains_all(\n\tceph::features::mon::FEATURE_LUMINOUS)) {\n    required_features |= CEPH_FEATUREMASK_SERVER_LUMINOUS;\n  }\n  dout(10) << __func__ << \" required_features \" << required_features << dendl;\n}\n\nvoid Monitor::get_combined_feature_map(FeatureMap *fm)\n{\n  *fm += session_map.feature_map;\n  for (auto id : quorum) {\n    if (id != rank) {\n      *fm += quorum_feature_map[id];\n    }\n  }\n}\n\nvoid Monitor::sync_force(Formatter *f, ostream& ss)\n{\n  bool free_formatter = false;\n\n  if (!f) {\n    // louzy/lazy hack: default to json if no formatter has been defined\n    f = new JSONFormatter();\n    free_formatter = true;\n  }\n\n  auto tx(std::make_shared<MonitorDBStore::Transaction>());\n  sync_stash_critical_state(tx);\n  tx->put(\"mon_sync\", \"force_sync\", 1);\n  store->apply_transaction(tx);\n\n  f->open_object_section(\"sync_force\");\n  f->dump_int(\"ret\", 0);\n  f->dump_stream(\"msg\") << \"forcing store sync the next time the monitor starts\";\n  f->close_section(); // sync_force\n  f->flush(ss);\n  if (free_formatter)\n    delete f;\n}\n\nvoid Monitor::_quorum_status(Formatter *f, ostream& ss)\n{\n  bool free_formatter = false;\n\n  if (!f) {\n    // louzy/lazy hack: default to json if no formatter has been defined\n    f = new JSONFormatter();\n    free_formatter = true;\n  }\n  f->open_object_section(\"quorum_status\");\n  f->dump_int(\"election_epoch\", get_epoch());\n\n  f->open_array_section(\"quorum\");\n  for (set<int>::iterator p = quorum.begin(); p != quorum.end(); ++p)\n    f->dump_int(\"mon\", *p);\n  f->close_section(); // quorum\n\n  list<string> quorum_names = get_quorum_names();\n  f->open_array_section(\"quorum_names\");\n  for (list<string>::iterator p = quorum_names.begin(); p != quorum_names.end(); ++p)\n    f->dump_string(\"mon\", *p);\n  f->close_section(); // quorum_names\n\n  f->dump_string(\"quorum_leader_name\", quorum.empty() ? string() : monmap->get_name(*quorum.begin()));\n\n  f->open_object_section(\"monmap\");\n  monmap->dump(f);\n  f->close_section(); // monmap\n\n  f->close_section(); // quorum_status\n  f->flush(ss);\n  if (free_formatter)\n    delete f;\n}\n\nvoid Monitor::get_mon_status(Formatter *f, ostream& ss)\n{\n  bool free_formatter = false;\n\n  if (!f) {\n    // louzy/lazy hack: default to json if no formatter has been defined\n    f = new JSONFormatter();\n    free_formatter = true;\n  }\n\n  f->open_object_section(\"mon_status\");\n  f->dump_string(\"name\", name);\n  f->dump_int(\"rank\", rank);\n  f->dump_string(\"state\", get_state_name());\n  f->dump_int(\"election_epoch\", get_epoch());\n\n  f->open_array_section(\"quorum\");\n  for (set<int>::iterator p = quorum.begin(); p != quorum.end(); ++p) {\n    f->dump_int(\"mon\", *p);\n  }\n\n  f->close_section(); // quorum\n\n  f->open_object_section(\"features\");\n  f->dump_stream(\"required_con\") << required_features;\n  mon_feature_t req_mon_features = get_required_mon_features();\n  req_mon_features.dump(f, \"required_mon\");\n  f->dump_stream(\"quorum_con\") << quorum_con_features;\n  quorum_mon_features.dump(f, \"quorum_mon\");\n  f->close_section(); // features\n\n  f->open_array_section(\"outside_quorum\");\n  for (set<string>::iterator p = outside_quorum.begin(); p != outside_quorum.end(); ++p)\n    f->dump_string(\"mon\", *p);\n  f->close_section(); // outside_quorum\n\n  f->open_array_section(\"extra_probe_peers\");\n  for (set<entity_addr_t>::iterator p = extra_probe_peers.begin();\n       p != extra_probe_peers.end();\n       ++p)\n    f->dump_stream(\"peer\") << *p;\n  f->close_section(); // extra_probe_peers\n\n  f->open_array_section(\"sync_provider\");\n  for (map<uint64_t,SyncProvider>::const_iterator p = sync_providers.begin();\n       p != sync_providers.end();\n       ++p) {\n    f->dump_unsigned(\"cookie\", p->second.cookie);\n    f->dump_stream(\"entity\") << p->second.entity;\n    f->dump_stream(\"timeout\") << p->second.timeout;\n    f->dump_unsigned(\"last_committed\", p->second.last_committed);\n    f->dump_stream(\"last_key\") << p->second.last_key;\n  }\n  f->close_section();\n\n  if (is_synchronizing()) {\n    f->open_object_section(\"sync\");\n    f->dump_stream(\"sync_provider\") << sync_provider;\n    f->dump_unsigned(\"sync_cookie\", sync_cookie);\n    f->dump_unsigned(\"sync_start_version\", sync_start_version);\n    f->close_section();\n  }\n\n  if (g_conf->mon_sync_provider_kill_at > 0)\n    f->dump_int(\"provider_kill_at\", g_conf->mon_sync_provider_kill_at);\n  if (g_conf->mon_sync_requester_kill_at > 0)\n    f->dump_int(\"requester_kill_at\", g_conf->mon_sync_requester_kill_at);\n\n  f->open_object_section(\"monmap\");\n  monmap->dump(f);\n  f->close_section();\n\n  f->dump_object(\"feature_map\", session_map.feature_map);\n  f->close_section(); // mon_status\n\n  if (free_formatter) {\n    // flush formatter to ss and delete it iff we created the formatter\n    f->flush(ss);\n    delete f;\n  }\n}\n\n\n// health status to clog\n\nvoid Monitor::health_tick_start()\n{\n  if (!cct->_conf->mon_health_to_clog ||\n      cct->_conf->mon_health_to_clog_tick_interval <= 0)\n    return;\n\n  dout(15) << __func__ << dendl;\n\n  health_tick_stop();\n  health_tick_event = timer.add_event_after(\n    cct->_conf->mon_health_to_clog_tick_interval,\n    new C_MonContext(this, [this](int r) {\n\tif (r < 0)\n\t  return;\n\thealth_tick_start();\n      }));\n}\n\nvoid Monitor::health_tick_stop()\n{\n  dout(15) << __func__ << dendl;\n\n  if (health_tick_event) {\n    timer.cancel_event(health_tick_event);\n    health_tick_event = NULL;\n  }\n}\n\nutime_t Monitor::health_interval_calc_next_update()\n{\n  utime_t now = ceph_clock_now();\n\n  time_t secs = now.sec();\n  int remainder = secs % cct->_conf->mon_health_to_clog_interval;\n  int adjustment = cct->_conf->mon_health_to_clog_interval - remainder;\n  utime_t next = utime_t(secs + adjustment, 0);\n\n  dout(20) << __func__\n    << \" now: \" << now << \",\"\n    << \" next: \" << next << \",\"\n    << \" interval: \" << cct->_conf->mon_health_to_clog_interval\n    << dendl;\n\n  return next;\n}\n\nvoid Monitor::health_interval_start()\n{\n  dout(15) << __func__ << dendl;\n\n  if (!cct->_conf->mon_health_to_clog ||\n      cct->_conf->mon_health_to_clog_interval <= 0) {\n    return;\n  }\n\n  health_interval_stop();\n  utime_t next = health_interval_calc_next_update();\n  health_interval_event = new C_MonContext(this, [this](int r) {\n      if (r < 0)\n        return;\n      do_health_to_clog_interval();\n    });\n  if (!timer.add_event_at(next, health_interval_event)) {\n    health_interval_event = nullptr;\n  }\n}\n\nvoid Monitor::health_interval_stop()\n{\n  dout(15) << __func__ << dendl;\n  if (health_interval_event) {\n    timer.cancel_event(health_interval_event);\n  }\n  health_interval_event = NULL;\n}\n\nvoid Monitor::health_events_cleanup()\n{\n  health_tick_stop();\n  health_interval_stop();\n  health_status_cache.reset();\n}\n\nvoid Monitor::health_to_clog_update_conf(const std::set<std::string> &changed)\n{\n  dout(20) << __func__ << dendl;\n\n  if (changed.count(\"mon_health_to_clog\")) {\n    if (!cct->_conf->mon_health_to_clog) {\n      health_events_cleanup();\n    } else {\n      if (!health_tick_event) {\n        health_tick_start();\n      }\n      if (!health_interval_event) {\n        health_interval_start();\n      }\n    }\n  }\n\n  if (changed.count(\"mon_health_to_clog_interval\")) {\n    if (cct->_conf->mon_health_to_clog_interval <= 0) {\n      health_interval_stop();\n    } else {\n      health_interval_start();\n    }\n  }\n\n  if (changed.count(\"mon_health_to_clog_tick_interval\")) {\n    if (cct->_conf->mon_health_to_clog_tick_interval <= 0) {\n      health_tick_stop();\n    } else {\n      health_tick_start();\n    }\n  }\n}\n\nvoid Monitor::do_health_to_clog_interval()\n{\n  // outputting to clog may have been disabled in the conf\n  // since we were scheduled.\n  if (!cct->_conf->mon_health_to_clog ||\n      cct->_conf->mon_health_to_clog_interval <= 0)\n    return;\n\n  dout(10) << __func__ << dendl;\n\n  // do we have a cached value for next_clog_update?  if not,\n  // do we know when the last update was?\n\n  do_health_to_clog(true);\n  health_interval_start();\n}\n\nvoid Monitor::do_health_to_clog(bool force)\n{\n  // outputting to clog may have been disabled in the conf\n  // since we were scheduled.\n  if (!cct->_conf->mon_health_to_clog ||\n      cct->_conf->mon_health_to_clog_interval <= 0)\n    return;\n\n  dout(10) << __func__ << (force ? \" (force)\" : \"\") << dendl;\n\n  if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n    string summary;\n    health_status_t level = get_health_status(false, nullptr, &summary);\n    if (!force &&\n\tsummary == health_status_cache.summary &&\n\tlevel == health_status_cache.overall)\n      return;\n    clog->health(level) << \"overall \" << summary;\n    health_status_cache.summary = summary;\n    health_status_cache.overall = level;\n  } else {\n    // for jewel only\n    list<string> status;\n    health_status_t overall = get_health(status, NULL, NULL);\n    dout(25) << __func__\n\t     << (force ? \" (force)\" : \"\")\n\t     << dendl;\n\n    string summary = joinify(status.begin(), status.end(), string(\"; \"));\n\n    if (!force &&\n\toverall == health_status_cache.overall &&\n\t!health_status_cache.summary.empty() &&\n\thealth_status_cache.summary == summary) {\n      // we got a dup!\n      return;\n    }\n\n    clog->info() << summary;\n\n    health_status_cache.overall = overall;\n    health_status_cache.summary = summary;\n  }\n}\n\nhealth_status_t Monitor::get_health_status(\n  bool want_detail,\n  Formatter *f,\n  std::string *plain,\n  const char *sep1,\n  const char *sep2)\n{\n  health_status_t r = HEALTH_OK;\n  bool compat = g_conf->mon_health_preluminous_compat;\n  bool compat_warn = g_conf->get_val<bool>(\"mon_health_preluminous_compat_warning\");\n  if (f) {\n    f->open_object_section(\"health\");\n    f->open_object_section(\"checks\");\n  }\n\n  string summary;\n  string *psummary = f ? nullptr : &summary;\n  for (auto& svc : paxos_service) {\n    r = std::min(r, svc->get_health_checks().dump_summary(\n\t\t   f, psummary, sep2, want_detail));\n  }\n\n  if (f) {\n    f->close_section();\n    f->dump_stream(\"status\") << r;\n  } else {\n    // one-liner: HEALTH_FOO[ thing1[; thing2 ...]]\n    *plain = stringify(r);\n    if (summary.size()) {\n      *plain += sep1;\n      *plain += summary;\n    }\n    *plain += \"\\n\";\n  }\n\n  const std::string old_fields_message = \"'ceph health' JSON format has \"\n    \"changed in luminous. If you see this your monitoring system is \"\n    \"scraping the wrong fields. Disable this with 'mon health preluminous \"\n    \"compat warning = false'\";\n\n  if (f && (compat || compat_warn)) {\n    health_status_t cr = compat_warn ? min(HEALTH_WARN, r) : r;\n    f->open_array_section(\"summary\");\n    if (compat_warn) {\n      f->open_object_section(\"item\");\n      f->dump_stream(\"severity\") << HEALTH_WARN;\n      f->dump_string(\"summary\", old_fields_message);\n      f->close_section();\n    }\n    if (compat) {\n      for (auto& svc : paxos_service) {\n        svc->get_health_checks().dump_summary_compat(f);\n      }\n    }\n    f->close_section();\n    f->dump_stream(\"overall_status\") << cr;\n  }\n\n  if (want_detail) {\n    if (f && (compat || compat_warn)) {\n      f->open_array_section(\"detail\");\n      if (compat_warn) {\n\tf->dump_string(\"item\", old_fields_message);\n      }\n    }\n\n    for (auto& svc : paxos_service) {\n      svc->get_health_checks().dump_detail(f, plain, compat);\n    }\n\n    if (f && (compat || compat_warn)) {\n      f->close_section();\n    }\n  }\n  if (f) {\n    f->close_section();\n  }\n  return r;\n}\n\nvoid Monitor::log_health(\n  const health_check_map_t& updated,\n  const health_check_map_t& previous,\n  MonitorDBStore::TransactionRef t)\n{\n  if (!g_conf->mon_health_to_clog) {\n    return;\n  }\n\n  const utime_t now = ceph_clock_now();\n\n  // FIXME: log atomically as part of @t instead of using clog.\n  dout(10) << __func__ << \" updated \" << updated.checks.size()\n\t   << \" previous \" << previous.checks.size()\n\t   << dendl;\n  const auto min_log_period = g_conf->get_val<int64_t>(\n      \"mon_health_log_update_period\");\n  for (auto& p : updated.checks) {\n    auto q = previous.checks.find(p.first);\n    bool logged = false;\n    if (q == previous.checks.end()) {\n      // new\n      ostringstream ss;\n      ss << \"Health check failed: \" << p.second.summary << \" (\"\n         << p.first << \")\";\n      clog->health(p.second.severity) << ss.str();\n\n      logged = true;\n    } else {\n      if (p.second.summary != q->second.summary ||\n\t  p.second.severity != q->second.severity) {\n\n        auto status_iter = health_check_log_times.find(p.first);\n        if (status_iter != health_check_log_times.end()) {\n          if (p.second.severity == q->second.severity &&\n              now - status_iter->second.updated_at < min_log_period) {\n            // We already logged this recently and the severity is unchanged,\n            // so skip emitting an update of the summary string.\n            // We'll get an update out of tick() later if the check\n            // is still failing.\n            continue;\n          }\n        }\n\n        // summary or severity changed (ignore detail changes at this level)\n        ostringstream ss;\n        ss << \"Health check update: \" << p.second.summary << \" (\" << p.first << \")\";\n        clog->health(p.second.severity) << ss.str();\n\n        logged = true;\n      }\n    }\n    // Record the time at which we last logged, so that we can check this\n    // when considering whether/when to print update messages.\n    if (logged) {\n      auto iter = health_check_log_times.find(p.first);\n      if (iter == health_check_log_times.end()) {\n        health_check_log_times.emplace(p.first, HealthCheckLogStatus(\n          p.second.severity, p.second.summary, now));\n      } else {\n        iter->second = HealthCheckLogStatus(\n          p.second.severity, p.second.summary, now);\n      }\n    }\n  }\n  for (auto& p : previous.checks) {\n    if (!updated.checks.count(p.first)) {\n      // cleared\n      ostringstream ss;\n      if (p.first == \"DEGRADED_OBJECTS\") {\n        clog->info() << \"All degraded objects recovered\";\n      } else if (p.first == \"OSD_FLAGS\") {\n        clog->info() << \"OSD flags cleared\";\n      } else {\n        clog->info() << \"Health check cleared: \" << p.first << \" (was: \"\n                     << p.second.summary << \")\";\n      }\n\n      if (health_check_log_times.count(p.first)) {\n        health_check_log_times.erase(p.first);\n      }\n    }\n  }\n\n  if (previous.checks.size() && updated.checks.size() == 0) {\n    // We might be going into a fully healthy state, check\n    // other subsystems\n    bool any_checks = false;\n    for (auto& svc : paxos_service) {\n      if (&(svc->get_health_checks()) == &(previous)) {\n        // Ignore the ones we're clearing right now\n        continue;\n      }\n\n      if (svc->get_health_checks().checks.size() > 0) {\n        any_checks = true;\n        break;\n      }\n    }\n    if (!any_checks) {\n      clog->info() << \"Cluster is now healthy\";\n    }\n  }\n}\n\nhealth_status_t Monitor::get_health(list<string>& status,\n                                    bufferlist *detailbl,\n                                    Formatter *f)\n{\n  list<pair<health_status_t,string> > summary;\n  list<pair<health_status_t,string> > detail;\n\n  if (f)\n    f->open_object_section(\"health\");\n\n  for (vector<PaxosService*>::iterator p = paxos_service.begin();\n       p != paxos_service.end();\n       ++p) {\n    PaxosService *s = *p;\n    s->get_health(summary, detailbl ? &detail : NULL, cct);\n  }\n\n  health_monitor->get_health(summary, (detailbl ? &detail : NULL));\n\n  health_status_t overall = HEALTH_OK;\n  if (!timecheck_skews.empty()) {\n    list<string> warns;\n    for (map<entity_inst_t,double>::iterator i = timecheck_skews.begin();\n         i != timecheck_skews.end(); ++i) {\n      entity_inst_t inst = i->first;\n      double skew = i->second;\n      double latency = timecheck_latencies[inst];\n      string name = monmap->get_name(inst.addr);\n      ostringstream tcss;\n      health_status_t tcstatus = timecheck_status(tcss, skew, latency);\n      if (tcstatus != HEALTH_OK) {\n        if (overall > tcstatus)\n          overall = tcstatus;\n        warns.push_back(name);\n        ostringstream tmp_ss;\n        tmp_ss << \"mon.\" << name\n               << \" addr \" << inst.addr << \" \" << tcss.str()\n\t       << \" (latency \" << latency << \"s)\";\n        detail.push_back(make_pair(tcstatus, tmp_ss.str()));\n      }\n    }\n    if (!warns.empty()) {\n      ostringstream ss;\n      ss << \"clock skew detected on\";\n      while (!warns.empty()) {\n        ss << \" mon.\" << warns.front();\n        warns.pop_front();\n        if (!warns.empty())\n          ss << \",\";\n      }\n      status.push_back(ss.str());\n      summary.push_back(make_pair(HEALTH_WARN, \"Monitor clock skew detected \"));\n    }\n  }\n\n  if (f)\n    f->open_array_section(\"summary\");\n  if (!summary.empty()) {\n    while (!summary.empty()) {\n      if (overall > summary.front().first)\n\toverall = summary.front().first;\n      status.push_back(summary.front().second);\n      if (f) {\n        f->open_object_section(\"item\");\n        f->dump_stream(\"severity\") <<  summary.front().first;\n        f->dump_string(\"summary\", summary.front().second);\n        f->close_section();\n      }\n      summary.pop_front();\n    }\n  }\n  if (f)\n    f->close_section();\n\n  stringstream fss;\n  fss << overall;\n  status.push_front(fss.str());\n  if (f)\n    f->dump_stream(\"overall_status\") << overall;\n\n  if (f)\n    f->open_array_section(\"detail\");\n  while (!detail.empty()) {\n    if (f)\n      f->dump_string(\"item\", detail.front().second);\n    else if (detailbl != NULL) {\n      detailbl->append(detail.front().second);\n      detailbl->append('\\n');\n    }\n    detail.pop_front();\n  }\n  if (f)\n    f->close_section();\n\n  if (f)\n    f->close_section();\n\n  return overall;\n}\n\nvoid Monitor::get_cluster_status(stringstream &ss, Formatter *f)\n{\n  if (f)\n    f->open_object_section(\"status\");\n\n  if (f) {\n    f->dump_stream(\"fsid\") << monmap->get_fsid();\n    if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n      get_health_status(false, f, nullptr);\n    } else {\n      list<string> health_str;\n      get_health(health_str, nullptr, f);\n    }\n    f->dump_unsigned(\"election_epoch\", get_epoch());\n    {\n      f->open_array_section(\"quorum\");\n      for (set<int>::iterator p = quorum.begin(); p != quorum.end(); ++p)\n\tf->dump_int(\"rank\", *p);\n      f->close_section();\n      f->open_array_section(\"quorum_names\");\n      for (set<int>::iterator p = quorum.begin(); p != quorum.end(); ++p)\n\tf->dump_string(\"id\", monmap->get_name(*p));\n      f->close_section();\n    }\n    f->open_object_section(\"monmap\");\n    monmap->dump(f);\n    f->close_section();\n    f->open_object_section(\"osdmap\");\n    osdmon()->osdmap.print_summary(f, cout, string(12, ' '));\n    f->close_section();\n    f->open_object_section(\"pgmap\");\n    pgservice->print_summary(f, NULL);\n    f->close_section();\n    f->open_object_section(\"fsmap\");\n    mdsmon()->get_fsmap().print_summary(f, NULL);\n    f->close_section();\n    f->open_object_section(\"mgrmap\");\n    mgrmon()->get_map().print_summary(f, nullptr);\n    f->close_section();\n\n    f->dump_object(\"servicemap\", mgrstatmon()->get_service_map());\n    f->close_section();\n  } else {\n    ss << \"  cluster:\\n\";\n    ss << \"    id:     \" << monmap->get_fsid() << \"\\n\";\n\n    string health;\n    if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n      get_health_status(false, nullptr, &health,\n\t\t\t\"\\n            \", \"\\n            \");\n    } else {\n      list<string> ls;\n      get_health(ls, NULL, f);\n      health = joinify(ls.begin(), ls.end(),\n\t\t       string(\"\\n            \"));\n    }\n    ss << \"    health: \" << health << \"\\n\";\n\n    ss << \"\\n \\n  services:\\n\";\n    {\n      size_t maxlen = 3;\n      auto& service_map = mgrstatmon()->get_service_map();\n      for (auto& p : service_map.services) {\n\tmaxlen = std::max(maxlen, p.first.size());\n      }\n      string spacing(maxlen - 3, ' ');\n      const auto quorum_names = get_quorum_names();\n      const auto mon_count = monmap->mon_info.size();\n      ss << \"    mon: \" << spacing << mon_count << \" daemons, quorum \"\n\t << quorum_names;\n      if (quorum_names.size() != mon_count) {\n\tstd::list<std::string> out_of_q;\n\tfor (size_t i = 0; i < monmap->ranks.size(); ++i) {\n\t  if (quorum.count(i) == 0) {\n\t    out_of_q.push_back(monmap->ranks[i]);\n\t  }\n\t}\n\tss << \", out of quorum: \" << joinify(out_of_q.begin(),\n\t\t\t\t\t     out_of_q.end(), std::string(\", \"));\n      }\n      ss << \"\\n\";\n      if (mgrmon()->in_use()) {\n\tss << \"    mgr: \" << spacing;\n\tmgrmon()->get_map().print_summary(nullptr, &ss);\n\tss << \"\\n\";\n      }\n      if (mdsmon()->get_fsmap().filesystem_count() > 0) {\n\tss << \"    mds: \" << spacing << mdsmon()->get_fsmap() << \"\\n\";\n      }\n      ss << \"    osd: \" << spacing;\n      osdmon()->osdmap.print_summary(NULL, ss, string(maxlen + 6, ' '));\n      ss << \"\\n\";\n      for (auto& p : service_map.services) {\n\tss << \"    \" << p.first << \": \" << string(maxlen - p.first.size(), ' ')\n\t   << p.second.get_summary() << \"\\n\";\n      }\n    }\n\n    ss << \"\\n \\n  data:\\n\";\n    pgservice->print_summary(NULL, &ss);\n    ss << \"\\n \";\n  }\n}\n\nvoid Monitor::_generate_command_map(map<string,cmd_vartype>& cmdmap,\n                                    map<string,string> &param_str_map)\n{\n  for (map<string,cmd_vartype>::const_iterator p = cmdmap.begin();\n       p != cmdmap.end(); ++p) {\n    if (p->first == \"prefix\")\n      continue;\n    if (p->first == \"caps\") {\n      vector<string> cv;\n      if (cmd_getval(g_ceph_context, cmdmap, \"caps\", cv) &&\n\t  cv.size() % 2 == 0) {\n\tfor (unsigned i = 0; i < cv.size(); i += 2) {\n\t  string k = string(\"caps_\") + cv[i];\n\t  param_str_map[k] = cv[i + 1];\n\t}\n\tcontinue;\n      }\n    }\n    param_str_map[p->first] = cmd_vartype_stringify(p->second);\n  }\n}\n\nconst MonCommand *Monitor::_get_moncommand(\n  const string &cmd_prefix,\n  const vector<MonCommand>& cmds)\n{\n  for (auto& c : cmds) {\n    if (c.cmdstring.compare(0, cmd_prefix.size(), cmd_prefix) == 0) {\n      return &c;\n    }\n  }\n  return nullptr;\n}\n\nbool Monitor::_allowed_command(MonSession *s, string &module, string &prefix,\n                               const map<string,cmd_vartype>& cmdmap,\n                               const map<string,string>& param_str_map,\n                               const MonCommand *this_cmd) {\n\n  bool cmd_r = this_cmd->requires_perm('r');\n  bool cmd_w = this_cmd->requires_perm('w');\n  bool cmd_x = this_cmd->requires_perm('x');\n\n  bool capable = s->caps.is_capable(\n    g_ceph_context,\n    CEPH_ENTITY_TYPE_MON,\n    s->entity_name,\n    module, prefix, param_str_map,\n    cmd_r, cmd_w, cmd_x);\n\n  dout(10) << __func__ << \" \" << (capable ? \"\" : \"not \") << \"capable\" << dendl;\n  return capable;\n}\n\nvoid Monitor::format_command_descriptions(const std::vector<MonCommand> &commands,\n\t\t\t\t\t  Formatter *f,\n\t\t\t\t\t  bufferlist *rdata,\n\t\t\t\t\t  bool hide_mgr_flag)\n{\n  int cmdnum = 0;\n  f->open_object_section(\"command_descriptions\");\n  for (const auto &cmd : commands) {\n    unsigned flags = cmd.flags;\n    if (hide_mgr_flag) {\n      flags &= ~MonCommand::FLAG_MGR;\n    }\n    ostringstream secname;\n    secname << \"cmd\" << setfill('0') << std::setw(3) << cmdnum;\n    dump_cmddesc_to_json(f, secname.str(),\n\t\t\t cmd.cmdstring, cmd.helpstring, cmd.module,\n\t\t\t cmd.req_perms, cmd.availability, flags);\n    cmdnum++;\n  }\n  f->close_section();\t// command_descriptions\n\n  f->flush(*rdata);\n}\n\nbool Monitor::is_keyring_required()\n{\n  string auth_cluster_required = g_conf->auth_supported.empty() ?\n    g_conf->auth_cluster_required : g_conf->auth_supported;\n  string auth_service_required = g_conf->auth_supported.empty() ?\n    g_conf->auth_service_required : g_conf->auth_supported;\n\n  return auth_service_required == \"cephx\" ||\n    auth_cluster_required == \"cephx\";\n}\n\nstruct C_MgrProxyCommand : public Context {\n  Monitor *mon;\n  MonOpRequestRef op;\n  uint64_t size;\n  bufferlist outbl;\n  string outs;\n  C_MgrProxyCommand(Monitor *mon, MonOpRequestRef op, uint64_t s)\n    : mon(mon), op(op), size(s) { }\n  void finish(int r) {\n    Mutex::Locker l(mon->lock);\n    mon->mgr_proxy_bytes -= size;\n    mon->reply_command(op, r, outs, outbl, 0);\n  }\n};\n\nvoid Monitor::handle_command(MonOpRequestRef op)\n{\n  assert(op->is_type_command());\n  MMonCommand *m = static_cast<MMonCommand*>(op->get_req());\n  if (m->fsid != monmap->fsid) {\n    dout(0) << \"handle_command on fsid \" << m->fsid << \" != \" << monmap->fsid << dendl;\n    reply_command(op, -EPERM, \"wrong fsid\", 0);\n    return;\n  }\n\n  MonSession *session = static_cast<MonSession *>(\n    m->get_connection()->get_priv());\n  if (!session) {\n    dout(5) << __func__ << \" dropping stray message \" << *m << dendl;\n    return;\n  }\n  BOOST_SCOPE_EXIT_ALL(=) {\n    session->put();\n  };\n\n  if (m->cmd.empty()) {\n    string rs = \"No command supplied\";\n    reply_command(op, -EINVAL, rs, 0);\n    return;\n  }\n\n  string prefix;\n  vector<string> fullcmd;\n  map<string, cmd_vartype> cmdmap;\n  stringstream ss, ds;\n  bufferlist rdata;\n  string rs;\n  int r = -EINVAL;\n  rs = \"unrecognized command\";\n\n  if (!cmdmap_from_json(m->cmd, &cmdmap, ss)) {\n    // ss has reason for failure\n    r = -EINVAL;\n    rs = ss.str();\n    if (!m->get_source().is_mon())  // don't reply to mon->mon commands\n      reply_command(op, r, rs, 0);\n    return;\n  }\n\n  // check return value. If no prefix parameter provided,\n  // return value will be false, then return error info.\n  if (!cmd_getval(g_ceph_context, cmdmap, \"prefix\", prefix)) {\n    reply_command(op, -EINVAL, \"command prefix not found\", 0);\n    return;\n  }\n\n  // check prefix is empty\n  if (prefix.empty()) {\n    reply_command(op, -EINVAL, \"command prefix must not be empty\", 0);\n    return;\n  }\n\n  if (prefix == \"get_command_descriptions\") {\n    bufferlist rdata;\n    Formatter *f = Formatter::create(\"json\");\n    // hide mgr commands until luminous upgrade is complete\n    bool hide_mgr_flag =\n      osdmon()->osdmap.require_osd_release < CEPH_RELEASE_LUMINOUS;\n\n    std::vector<MonCommand> commands;\n\n    // only include mgr commands once all mons are upgrade (and we've dropped\n    // the hard-coded PGMonitor commands)\n    if (quorum_mon_features.contains_all(ceph::features::mon::FEATURE_LUMINOUS)) {\n      commands = static_cast<MgrMonitor*>(\n        paxos_service[PAXOS_MGR])->get_command_descs();\n    }\n\n    for (auto& c : leader_mon_commands) {\n      commands.push_back(c);\n    }\n\n    format_command_descriptions(commands, f, &rdata, hide_mgr_flag);\n    delete f;\n    reply_command(op, 0, \"\", rdata, 0);\n    return;\n  }\n\n  string module;\n  string err;\n\n  dout(0) << \"handle_command \" << *m << dendl;\n\n  string format;\n  cmd_getval(g_ceph_context, cmdmap, \"format\", format, string(\"plain\"));\n  boost::scoped_ptr<Formatter> f(Formatter::create(format));\n\n  get_str_vec(prefix, fullcmd);\n\n  // make sure fullcmd is not empty.\n  // invalid prefix will cause empty vector fullcmd.\n  // such as, prefix=\";,,;\"\n  if (fullcmd.empty()) {\n    reply_command(op, -EINVAL, \"command requires a prefix to be valid\", 0);\n    return;\n  }\n\n  module = fullcmd[0];\n\n  // validate command is in leader map\n\n  const MonCommand *leader_cmd;\n  const auto& mgr_cmds = mgrmon()->get_command_descs();\n  const MonCommand *mgr_cmd = nullptr;\n  if (!mgr_cmds.empty()) {\n    mgr_cmd = _get_moncommand(prefix, mgr_cmds);\n  }\n  leader_cmd = _get_moncommand(prefix, leader_mon_commands);\n  if (!leader_cmd) {\n    leader_cmd = mgr_cmd;\n    if (!leader_cmd) {\n      reply_command(op, -EINVAL, \"command not known\", 0);\n      return;\n    }\n  }\n  // validate command is in our map & matches, or forward if it is allowed\n  const MonCommand *mon_cmd = _get_moncommand(\n    prefix,\n    get_local_commands(quorum_mon_features));\n  if (!mon_cmd) {\n    mon_cmd = mgr_cmd;\n  }\n  if (!is_leader()) {\n    if (!mon_cmd) {\n      if (leader_cmd->is_noforward()) {\n\treply_command(op, -EINVAL,\n\t\t      \"command not locally supported and not allowed to forward\",\n\t\t      0);\n\treturn;\n      }\n      dout(10) << \"Command not locally supported, forwarding request \"\n\t       << m << dendl;\n      forward_request_leader(op);\n      return;\n    } else if (!mon_cmd->is_compat(leader_cmd)) {\n      if (mon_cmd->is_noforward()) {\n\treply_command(op, -EINVAL,\n\t\t      \"command not compatible with leader and not allowed to forward\",\n\t\t      0);\n\treturn;\n      }\n      dout(10) << \"Command not compatible with leader, forwarding request \"\n\t       << m << dendl;\n      forward_request_leader(op);\n      return;\n    }\n  }\n\n  if (mon_cmd->is_obsolete() ||\n      (cct->_conf->mon_debug_deprecated_as_obsolete\n       && mon_cmd->is_deprecated())) {\n    reply_command(op, -ENOTSUP,\n                  \"command is obsolete; please check usage and/or man page\",\n                  0);\n    return;\n  }\n\n  if (session->proxy_con && mon_cmd->is_noforward()) {\n    dout(10) << \"Got forward for noforward command \" << m << dendl;\n    reply_command(op, -EINVAL, \"forward for noforward command\", rdata, 0);\n    return;\n  }\n\n  /* what we perceive as being the service the command falls under */\n  string service(mon_cmd->module);\n\n  dout(25) << __func__ << \" prefix='\" << prefix\n           << \"' module='\" << module\n           << \"' service='\" << service << \"'\" << dendl;\n\n  bool cmd_is_rw =\n    (mon_cmd->requires_perm('w') || mon_cmd->requires_perm('x'));\n\n  // validate user's permissions for requested command\n  map<string,string> param_str_map;\n  _generate_command_map(cmdmap, param_str_map);\n  if (!_allowed_command(session, service, prefix, cmdmap,\n                        param_str_map, mon_cmd)) {\n    dout(1) << __func__ << \" access denied\" << dendl;\n    (cmd_is_rw ? audit_clog->info() : audit_clog->debug())\n      << \"from='\" << session->inst << \"' \"\n      << \"entity='\" << session->entity_name << \"' \"\n      << \"cmd=\" << m->cmd << \":  access denied\";\n    reply_command(op, -EACCES, \"access denied\", 0);\n    return;\n  }\n\n  (cmd_is_rw ? audit_clog->info() : audit_clog->debug())\n    << \"from='\" << session->inst << \"' \"\n    << \"entity='\" << session->entity_name << \"' \"\n    << \"cmd=\" << m->cmd << \": dispatch\";\n\n  if (mon_cmd->is_mgr() &&\n      osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n    const auto& hdr = m->get_header();\n    uint64_t size = hdr.front_len + hdr.middle_len + hdr.data_len;\n    uint64_t max = g_conf->get_val<uint64_t>(\"mon_client_bytes\")\n                 * g_conf->get_val<double>(\"mon_mgr_proxy_client_bytes_ratio\");\n    if (mgr_proxy_bytes + size > max) {\n      dout(10) << __func__ << \" current mgr proxy bytes \" << mgr_proxy_bytes\n\t       << \" + \" << size << \" > max \" << max << dendl;\n      reply_command(op, -EAGAIN, \"hit limit on proxied mgr commands\", rdata, 0);\n      return;\n    }\n    mgr_proxy_bytes += size;\n    dout(10) << __func__ << \" proxying mgr command (+\" << size\n\t     << \" -> \" << mgr_proxy_bytes << \")\" << dendl;\n    C_MgrProxyCommand *fin = new C_MgrProxyCommand(this, op, size);\n    mgr_client.start_command(m->cmd,\n\t\t\t     m->get_data(),\n\t\t\t     &fin->outbl,\n\t\t\t     &fin->outs,\n\t\t\t     new C_OnFinisher(fin, &finisher));\n    return;\n  }\n\n  if ((module == \"mds\" || module == \"fs\")  &&\n      prefix != \"fs authorize\") {\n    mdsmon()->dispatch(op);\n    return;\n  }\n  if ((module == \"osd\" || prefix == \"pg map\") &&\n      prefix != \"osd last-stat-seq\") {\n    osdmon()->dispatch(op);\n    return;\n  }\n\n  if (module == \"pg\") {\n    pgmon()->dispatch(op);\n    return;\n  }\n  if (module == \"mon\" &&\n      /* Let the Monitor class handle the following commands:\n       *  'mon compact'\n       *  'mon scrub'\n       *  'mon sync force'\n       */\n      prefix != \"mon compact\" &&\n      prefix != \"mon scrub\" &&\n      prefix != \"mon sync force\" &&\n      prefix != \"mon metadata\" &&\n      prefix != \"mon versions\" &&\n      prefix != \"mon count-metadata\") {\n    monmon()->dispatch(op);\n    return;\n  }\n  if (module == \"auth\" || prefix == \"fs authorize\") {\n    authmon()->dispatch(op);\n    return;\n  }\n  if (module == \"log\") {\n    logmon()->dispatch(op);\n    return;\n  }\n\n  if (module == \"config-key\") {\n    config_key_service->dispatch(op);\n    return;\n  }\n\n  if (module == \"mgr\") {\n    mgrmon()->dispatch(op);\n    return;\n  }\n\n  if (prefix == \"fsid\") {\n    if (f) {\n      f->open_object_section(\"fsid\");\n      f->dump_stream(\"fsid\") << monmap->fsid;\n      f->close_section();\n      f->flush(rdata);\n    } else {\n      ds << monmap->fsid;\n      rdata.append(ds);\n    }\n    reply_command(op, 0, \"\", rdata, 0);\n    return;\n  }\n\n  if (prefix == \"scrub\" || prefix == \"mon scrub\") {\n    wait_for_paxos_write();\n    if (is_leader()) {\n      int r = scrub_start();\n      reply_command(op, r, \"\", rdata, 0);\n    } else if (is_peon()) {\n      forward_request_leader(op);\n    } else {\n      reply_command(op, -EAGAIN, \"no quorum\", rdata, 0);\n    }\n    return;\n  }\n\n  if (prefix == \"compact\" || prefix == \"mon compact\") {\n    dout(1) << \"triggering manual compaction\" << dendl;\n    utime_t start = ceph_clock_now();\n    store->compact();\n    utime_t end = ceph_clock_now();\n    end -= start;\n    dout(1) << \"finished manual compaction in \" << end << \" seconds\" << dendl;\n    ostringstream oss;\n    oss << \"compacted \" << g_conf->get_val<std::string>(\"mon_keyvaluedb\") << \" in \" << end << \" seconds\";\n    rs = oss.str();\n    r = 0;\n  }\n  else if (prefix == \"injectargs\") {\n    vector<string> injected_args;\n    cmd_getval(g_ceph_context, cmdmap, \"injected_args\", injected_args);\n    if (!injected_args.empty()) {\n      dout(0) << \"parsing injected options '\" << injected_args << \"'\" << dendl;\n      ostringstream oss;\n      r = g_conf->injectargs(str_join(injected_args, \" \"), &oss);\n      ss << \"injectargs:\"  << oss.str();\n      rs = ss.str();\n      goto out;\n    } else {\n      rs = \"must supply options to be parsed in a single string\";\n      r = -EINVAL;\n    }\n  } else if (prefix == \"time-sync-status\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    f->open_object_section(\"time_sync\");\n    if (!timecheck_skews.empty()) {\n      f->open_object_section(\"time_skew_status\");\n      for (auto& i : timecheck_skews) {\n\tentity_inst_t inst = i.first;\n\tdouble skew = i.second;\n\tdouble latency = timecheck_latencies[inst];\n\tstring name = monmap->get_name(inst.addr);\n\tostringstream tcss;\n\thealth_status_t tcstatus = timecheck_status(tcss, skew, latency);\n\tf->open_object_section(name.c_str());\n\tf->dump_float(\"skew\", skew);\n\tf->dump_float(\"latency\", latency);\n\tf->dump_stream(\"health\") << tcstatus;\n\tif (tcstatus != HEALTH_OK) {\n\t  f->dump_stream(\"details\") << tcss.str();\n\t}\n\tf->close_section();\n      }\n      f->close_section();\n    }\n    f->open_object_section(\"timechecks\");\n    f->dump_unsigned(\"epoch\", get_epoch());\n    f->dump_int(\"round\", timecheck_round);\n    f->dump_stream(\"round_status\") << ((timecheck_round%2) ?\n\t\t\t\t       \"on-going\" : \"finished\");\n    f->close_section();\n    f->close_section();\n    f->flush(rdata);\n    r = 0;\n    rs = \"\";\n  } else if (prefix == \"config set\") {\n    std::string key;\n    cmd_getval(cct, cmdmap, \"key\", key);\n    std::string val;\n    cmd_getval(cct, cmdmap, \"value\", val);\n    r = g_conf->set_val(key, val, true, &ss);\n    if (r == 0) {\n      g_conf->apply_changes(nullptr);\n    }\n    rs = ss.str();\n    goto out;\n  } else if (prefix == \"status\" ||\n\t     prefix == \"health\" ||\n\t     prefix == \"df\") {\n    string detail;\n    cmd_getval(g_ceph_context, cmdmap, \"detail\", detail);\n\n    if (prefix == \"status\") {\n      // get_cluster_status handles f == NULL\n      get_cluster_status(ds, f.get());\n\n      if (f) {\n        f->flush(ds);\n        ds << '\\n';\n      }\n      rdata.append(ds);\n    } else if (prefix == \"health\") {\n      if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n\tstring plain;\n\tget_health_status(detail == \"detail\", f.get(), f ? nullptr : &plain);\n\tif (f) {\n\t  f->flush(rdata);\n\t} else {\n\t  rdata.append(plain);\n\t}\n      } else {\n\tlist<string> health_str;\n\tget_health(health_str, detail == \"detail\" ? &rdata : NULL, f.get());\n\tif (f) {\n\t  f->flush(ds);\n\t  ds << '\\n';\n\t} else {\n\t  assert(!health_str.empty());\n\t  ds << health_str.front();\n\t  health_str.pop_front();\n\t  if (!health_str.empty()) {\n\t    ds << ' ';\n\t    ds << joinify(health_str.begin(), health_str.end(), string(\"; \"));\n\t  }\n\t}\n\tbufferlist comb;\n\tcomb.append(ds);\n\tif (detail == \"detail\")\n\t  comb.append(rdata);\n\trdata = comb;\n      }\n    } else if (prefix == \"df\") {\n      bool verbose = (detail == \"detail\");\n      if (f)\n        f->open_object_section(\"stats\");\n\n      pgservice->dump_fs_stats(&ds, f.get(), verbose);\n      if (!f)\n        ds << '\\n';\n      pgservice->dump_pool_stats(osdmon()->osdmap, &ds, f.get(), verbose);\n\n      if (f) {\n        f->close_section();\n        f->flush(ds);\n        ds << '\\n';\n      }\n    } else {\n      assert(0 == \"We should never get here!\");\n      return;\n    }\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"report\") {\n\n    // this must be formatted, in its current form\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    f->open_object_section(\"report\");\n    f->dump_stream(\"cluster_fingerprint\") << fingerprint;\n    f->dump_string(\"version\", ceph_version_to_str());\n    f->dump_string(\"commit\", git_version_to_str());\n    f->dump_stream(\"timestamp\") << ceph_clock_now();\n\n    vector<string> tagsvec;\n    cmd_getval(g_ceph_context, cmdmap, \"tags\", tagsvec);\n    string tagstr = str_join(tagsvec, \" \");\n    if (!tagstr.empty())\n      tagstr = tagstr.substr(0, tagstr.find_last_of(' '));\n    f->dump_string(\"tag\", tagstr);\n\n    if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n      get_health_status(true, f.get(), nullptr);\n    } else {\n      list<string> health_str;\n      get_health(health_str, nullptr, f.get());\n    }\n\n    monmon()->dump_info(f.get());\n    osdmon()->dump_info(f.get());\n    mdsmon()->dump_info(f.get());\n    authmon()->dump_info(f.get());\n    pgservice->dump_info(f.get());\n\n    paxos->dump_info(f.get());\n\n    f->close_section();\n    f->flush(rdata);\n\n    ostringstream ss2;\n    ss2 << \"report \" << rdata.crc32c(CEPH_MON_PORT);\n    rs = ss2.str();\n    r = 0;\n  } else if (prefix == \"osd last-stat-seq\") {\n    int64_t osd;\n    cmd_getval(g_ceph_context, cmdmap, \"id\", osd);\n    uint64_t seq = mgrstatmon()->get_last_osd_stat_seq(osd);\n    if (f) {\n      f->dump_unsigned(\"seq\", seq);\n      f->flush(ds);\n    } else {\n      ds << seq;\n      rdata.append(ds);\n    }\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"node ls\") {\n    string node_type(\"all\");\n    cmd_getval(g_ceph_context, cmdmap, \"type\", node_type);\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    if (node_type == \"all\") {\n      f->open_object_section(\"nodes\");\n      print_nodes(f.get(), ds);\n      osdmon()->print_nodes(f.get());\n      mdsmon()->print_nodes(f.get());\n      f->close_section();\n    } else if (node_type == \"mon\") {\n      print_nodes(f.get(), ds);\n    } else if (node_type == \"osd\") {\n      osdmon()->print_nodes(f.get());\n    } else if (node_type == \"mds\") {\n      mdsmon()->print_nodes(f.get());\n    }\n    f->flush(ds);\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"features\") {\n    if (!is_leader() && !is_peon()) {\n      dout(10) << \" waiting for quorum\" << dendl;\n      waitfor_quorum.push_back(new C_RetryMessage(this, op));\n      return;\n    }\n    if (!is_leader()) {\n      forward_request_leader(op);\n      return;\n    }\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    FeatureMap fm;\n    get_combined_feature_map(&fm);\n    f->dump_object(\"features\", fm);\n    f->flush(rdata);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"mon metadata\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n\n    string name;\n    bool all = !cmd_getval(g_ceph_context, cmdmap, \"id\", name);\n    if (!all) {\n      // Dump a single mon's metadata\n      int mon = monmap->get_rank(name);\n      if (mon < 0) {\n        rs = \"requested mon not found\";\n        r = -ENOENT;\n        goto out;\n      }\n      f->open_object_section(\"mon_metadata\");\n      r = get_mon_metadata(mon, f.get(), ds);\n      f->close_section();\n    } else {\n      // Dump all mons' metadata\n      r = 0;\n      f->open_array_section(\"mon_metadata\");\n      for (unsigned int rank = 0; rank < monmap->size(); ++rank) {\n        std::ostringstream get_err;\n        f->open_object_section(\"mon\");\n        f->dump_string(\"name\", monmap->get_name(rank));\n        r = get_mon_metadata(rank, f.get(), get_err);\n        f->close_section();\n        if (r == -ENOENT || r == -EINVAL) {\n          dout(1) << get_err.str() << dendl;\n          // Drop error, list what metadata we do have\n          r = 0;\n        } else if (r != 0) {\n          derr << \"Unexpected error from get_mon_metadata: \"\n               << cpp_strerror(r) << dendl;\n          ds << get_err.str();\n          break;\n        }\n      }\n      f->close_section();\n    }\n\n    f->flush(ds);\n    rdata.append(ds);\n    rs = \"\";\n  } else if (prefix == \"mon versions\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    count_metadata(\"ceph_version\", f.get());\n    f->flush(ds);\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"mon count-metadata\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    string field;\n    cmd_getval(g_ceph_context, cmdmap, \"property\", field);\n    count_metadata(field, f.get());\n    f->flush(ds);\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"quorum_status\") {\n    // make sure our map is readable and up to date\n    if (!is_leader() && !is_peon()) {\n      dout(10) << \" waiting for quorum\" << dendl;\n      waitfor_quorum.push_back(new C_RetryMessage(this, op));\n      return;\n    }\n    _quorum_status(f.get(), ds);\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"mon_status\") {\n    get_mon_status(f.get(), ds);\n    if (f)\n      f->flush(ds);\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"sync force\" ||\n             prefix == \"mon sync force\") {\n    string validate1, validate2;\n    cmd_getval(g_ceph_context, cmdmap, \"validate1\", validate1);\n    cmd_getval(g_ceph_context, cmdmap, \"validate2\", validate2);\n    if (validate1 != \"--yes-i-really-mean-it\" ||\n\tvalidate2 != \"--i-know-what-i-am-doing\") {\n      r = -EINVAL;\n      rs = \"are you SURE? this will mean the monitor store will be \"\n\t   \"erased.  pass '--yes-i-really-mean-it \"\n\t   \"--i-know-what-i-am-doing' if you really do.\";\n      goto out;\n    }\n    sync_force(f.get(), ds);\n    rs = ds.str();\n    r = 0;\n  } else if (prefix == \"heap\") {\n    if (!ceph_using_tcmalloc())\n      rs = \"tcmalloc not enabled, can't use heap profiler commands\\n\";\n    else {\n      string heapcmd;\n      cmd_getval(g_ceph_context, cmdmap, \"heapcmd\", heapcmd);\n      // XXX 1-element vector, change at callee or make vector here?\n      vector<string> heapcmd_vec;\n      get_str_vec(heapcmd, heapcmd_vec);\n      ceph_heap_profiler_handle_command(heapcmd_vec, ds);\n      rdata.append(ds);\n      rs = \"\";\n      r = 0;\n    }\n  } else if (prefix == \"quorum\") {\n    string quorumcmd;\n    cmd_getval(g_ceph_context, cmdmap, \"quorumcmd\", quorumcmd);\n    if (quorumcmd == \"exit\") {\n      start_election();\n      elector.stop_participating();\n      rs = \"stopped responding to quorum, initiated new election\";\n      r = 0;\n    } else if (quorumcmd == \"enter\") {\n      elector.start_participating();\n      start_election();\n      rs = \"started responding to quorum, initiated new election\";\n      r = 0;\n    } else {\n      rs = \"needs a valid 'quorum' command\";\n      r = -EINVAL;\n    }\n  } else if (prefix == \"version\") {\n    if (f) {\n      f->open_object_section(\"version\");\n      f->dump_string(\"version\", pretty_version_to_str());\n      f->close_section();\n      f->flush(ds);\n    } else {\n      ds << pretty_version_to_str();\n    }\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"versions\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    map<string,int> overall;\n    f->open_object_section(\"version\");\n    map<string,int> mon, mgr, osd, mds;\n\n    count_metadata(\"ceph_version\", &mon);\n    f->open_object_section(\"mon\");\n    for (auto& p : mon) {\n      f->dump_int(p.first.c_str(), p.second);\n      overall[p.first] += p.second;\n    }\n    f->close_section();\n\n    mgrmon()->count_metadata(\"ceph_version\", &mgr);\n    f->open_object_section(\"mgr\");\n    for (auto& p : mgr) {\n      f->dump_int(p.first.c_str(), p.second);\n      overall[p.first] += p.second;\n    }\n    f->close_section();\n\n    osdmon()->count_metadata(\"ceph_version\", &osd);\n    f->open_object_section(\"osd\");\n    for (auto& p : osd) {\n      f->dump_int(p.first.c_str(), p.second);\n      overall[p.first] += p.second;\n    }\n    f->close_section();\n\n    mdsmon()->count_metadata(\"ceph_version\", &mds);\n    f->open_object_section(\"mds\");\n    for (auto& p : mds) {\n      f->dump_int(p.first.c_str(), p.second);\n      overall[p.first] += p.second;\n    }\n    f->close_section();\n\n    for (auto& p : mgrstatmon()->get_service_map().services) {\n      f->open_object_section(p.first.c_str());\n      map<string,int> m;\n      p.second.count_metadata(\"ceph_version\", &m);\n      for (auto& q : m) {\n\tf->dump_int(q.first.c_str(), q.second);\n\toverall[q.first] += q.second;\n      }\n      f->close_section();\n    }\n\n    f->open_object_section(\"overall\");\n    for (auto& p : overall) {\n      f->dump_int(p.first.c_str(), p.second);\n    }\n    f->close_section();\n    f->close_section();\n    f->flush(rdata);\n    rs = \"\";\n    r = 0;\n  }\n\n out:\n  if (!m->get_source().is_mon())  // don't reply to mon->mon commands\n    reply_command(op, r, rs, rdata, 0);\n}\n\nvoid Monitor::reply_command(MonOpRequestRef op, int rc, const string &rs, version_t version)\n{\n  bufferlist rdata;\n  reply_command(op, rc, rs, rdata, version);\n}\n\nvoid Monitor::reply_command(MonOpRequestRef op, int rc, const string &rs,\n                            bufferlist& rdata, version_t version)\n{\n  MMonCommand *m = static_cast<MMonCommand*>(op->get_req());\n  assert(m->get_type() == MSG_MON_COMMAND);\n  MMonCommandAck *reply = new MMonCommandAck(m->cmd, rc, rs, version);\n  reply->set_tid(m->get_tid());\n  reply->set_data(rdata);\n  send_reply(op, reply);\n}\n\n\n// ------------------------\n// request/reply routing\n//\n// a client/mds/osd will connect to a random monitor.  we need to forward any\n// messages requiring state updates to the leader, and then route any replies\n// back via the correct monitor and back to them.  (the monitor will not\n// initiate any connections.)\n\nvoid Monitor::forward_request_leader(MonOpRequestRef op)\n{\n  op->mark_event(__func__);\n\n  int mon = get_leader();\n  MonSession *session = op->get_session();\n  PaxosServiceMessage *req = op->get_req<PaxosServiceMessage>();\n  \n  if (req->get_source().is_mon() && req->get_source_addr() != messenger->get_myaddr()) {\n    dout(10) << \"forward_request won't forward (non-local) mon request \" << *req << dendl;\n  } else if (session->proxy_con) {\n    dout(10) << \"forward_request won't double fwd request \" << *req << dendl;\n  } else if (!session->closed) {\n    RoutedRequest *rr = new RoutedRequest;\n    rr->tid = ++routed_request_tid;\n    rr->client_inst = req->get_source_inst();\n    rr->con = req->get_connection();\n    rr->con_features = rr->con->get_features();\n    encode_message(req, CEPH_FEATURES_ALL, rr->request_bl);   // for my use only; use all features\n    rr->session = static_cast<MonSession *>(session->get());\n    rr->op = op;\n    routed_requests[rr->tid] = rr;\n    session->routed_request_tids.insert(rr->tid);\n    \n    dout(10) << \"forward_request \" << rr->tid << \" request \" << *req\n\t     << \" features \" << rr->con_features << dendl;\n\n    MForward *forward = new MForward(rr->tid,\n                                     req,\n\t\t\t\t     rr->con_features,\n\t\t\t\t     rr->session->caps);\n    forward->set_priority(req->get_priority());\n    if (session->auth_handler) {\n      forward->entity_name = session->entity_name;\n    } else if (req->get_source().is_mon()) {\n      forward->entity_name.set_type(CEPH_ENTITY_TYPE_MON);\n    }\n    messenger->send_message(forward, monmap->get_inst(mon));\n    op->mark_forwarded();\n    assert(op->get_req()->get_type() != 0);\n  } else {\n    dout(10) << \"forward_request no session for request \" << *req << dendl;\n  }\n}\n\n// fake connection attached to forwarded messages\nstruct AnonConnection : public Connection {\n  explicit AnonConnection(CephContext *cct) : Connection(cct, NULL) {}\n\n  int send_message(Message *m) override {\n    assert(!\"send_message on anonymous connection\");\n  }\n  void send_keepalive() override {\n    assert(!\"send_keepalive on anonymous connection\");\n  }\n  void mark_down() override {\n    // silently ignore\n  }\n  void mark_disposable() override {\n    // silengtly ignore\n  }\n  bool is_connected() override { return false; }\n};\n\n//extract the original message and put it into the regular dispatch function\nvoid Monitor::handle_forward(MonOpRequestRef op)\n{\n  MForward *m = static_cast<MForward*>(op->get_req());\n  dout(10) << \"received forwarded message from \" << m->client\n\t   << \" via \" << m->get_source_inst() << dendl;\n  MonSession *session = op->get_session();\n  assert(session);\n\n  if (!session->is_capable(\"mon\", MON_CAP_X)) {\n    dout(0) << \"forward from entity with insufficient caps! \" \n\t    << session->caps << dendl;\n  } else {\n    // see PaxosService::dispatch(); we rely on this being anon\n    // (c->msgr == NULL)\n    PaxosServiceMessage *req = m->claim_message();\n    assert(req != NULL);\n\n    ConnectionRef c(new AnonConnection(cct));\n    MonSession *s = new MonSession(req->get_source_inst(),\n\t\t\t\t   static_cast<Connection*>(c.get()));\n    c->set_priv(s->get());\n    c->set_peer_addr(m->client.addr);\n    c->set_peer_type(m->client.name.type());\n    c->set_features(m->con_features);\n\n    s->caps = m->client_caps;\n    dout(10) << \" caps are \" << s->caps << dendl;\n    s->entity_name = m->entity_name;\n    dout(10) << \" entity name '\" << s->entity_name << \"' type \"\n             << s->entity_name.get_type() << dendl;\n    s->proxy_con = m->get_connection();\n    s->proxy_tid = m->tid;\n\n    req->set_connection(c);\n\n    // not super accurate, but better than nothing.\n    req->set_recv_stamp(m->get_recv_stamp());\n\n    /*\n     * note which election epoch this is; we will drop the message if\n     * there is a future election since our peers will resend routed\n     * requests in that case.\n     */\n    req->rx_election_epoch = get_epoch();\n\n    /* Because this is a special fake connection, we need to break\n       the ref loop between Connection and MonSession differently\n       than we normally do. Here, the Message refers to the Connection\n       which refers to the Session, and nobody else refers to the Connection\n       or the Session. And due to the special nature of this message,\n       nobody refers to the Connection via the Session. So, clear out that\n       half of the ref loop.*/\n    s->con.reset(NULL);\n\n    dout(10) << \" mesg \" << req << \" from \" << m->get_source_addr() << dendl;\n\n    _ms_dispatch(req);\n    s->put();\n  }\n}\n\nvoid Monitor::try_send_message(Message *m, const entity_inst_t& to)\n{\n  dout(10) << \"try_send_message \" << *m << \" to \" << to << dendl;\n\n  bufferlist bl;\n  encode_message(m, quorum_con_features, bl);\n\n  messenger->send_message(m, to);\n\n  for (int i=0; i<(int)monmap->size(); i++) {\n    if (i != rank)\n      messenger->send_message(new MRoute(bl, to), monmap->get_inst(i));\n  }\n}\n\nvoid Monitor::send_reply(MonOpRequestRef op, Message *reply)\n{\n  op->mark_event(__func__);\n\n  MonSession *session = op->get_session();\n  assert(session);\n  Message *req = op->get_req();\n  ConnectionRef con = op->get_connection();\n\n  reply->set_cct(g_ceph_context);\n  dout(2) << __func__ << \" \" << op << \" \" << reply << \" \" << *reply << dendl;\n\n  if (!con) {\n    dout(2) << \"send_reply no connection, dropping reply \" << *reply\n\t    << \" to \" << req << \" \" << *req << dendl;\n    reply->put();\n    op->mark_event(\"reply: no connection\");\n    return;\n  }\n\n  if (!session->con && !session->proxy_con) {\n    dout(2) << \"send_reply no connection, dropping reply \" << *reply\n\t    << \" to \" << req << \" \" << *req << dendl;\n    reply->put();\n    op->mark_event(\"reply: no connection\");\n    return;\n  }\n\n  if (session->proxy_con) {\n    dout(15) << \"send_reply routing reply to \" << con->get_peer_addr()\n\t     << \" via \" << session->proxy_con->get_peer_addr()\n\t     << \" for request \" << *req << dendl;\n    session->proxy_con->send_message(new MRoute(session->proxy_tid, reply));\n    op->mark_event(\"reply: send routed request\");\n  } else {\n    session->con->send_message(reply);\n    op->mark_event(\"reply: send\");\n  }\n}\n\nvoid Monitor::no_reply(MonOpRequestRef op)\n{\n  MonSession *session = op->get_session();\n  Message *req = op->get_req();\n\n  if (session->proxy_con) {\n    dout(10) << \"no_reply to \" << req->get_source_inst()\n\t     << \" via \" << session->proxy_con->get_peer_addr()\n\t     << \" for request \" << *req << dendl;\n    session->proxy_con->send_message(new MRoute(session->proxy_tid, NULL));\n    op->mark_event(\"no_reply: send routed request\");\n  } else {\n    dout(10) << \"no_reply to \" << req->get_source_inst()\n             << \" \" << *req << dendl;\n    op->mark_event(\"no_reply\");\n  }\n}\n\nvoid Monitor::handle_route(MonOpRequestRef op)\n{\n  MRoute *m = static_cast<MRoute*>(op->get_req());\n  MonSession *session = op->get_session();\n  //check privileges\n  if (!session->is_capable(\"mon\", MON_CAP_X)) {\n    dout(0) << \"MRoute received from entity without appropriate perms! \"\n\t    << dendl;\n    return;\n  }\n  if (m->msg)\n    dout(10) << \"handle_route \" << *m->msg << \" to \" << m->dest << dendl;\n  else\n    dout(10) << \"handle_route null to \" << m->dest << dendl;\n  \n  // look it up\n  if (m->session_mon_tid) {\n    if (routed_requests.count(m->session_mon_tid)) {\n      RoutedRequest *rr = routed_requests[m->session_mon_tid];\n\n      // reset payload, in case encoding is dependent on target features\n      if (m->msg) {\n\tm->msg->clear_payload();\n\trr->con->send_message(m->msg);\n\tm->msg = NULL;\n      }\n      if (m->send_osdmap_first) {\n\tdout(10) << \" sending osdmaps from \" << m->send_osdmap_first << dendl;\n\tosdmon()->send_incremental(m->send_osdmap_first, rr->session,\n\t\t\t\t   true, MonOpRequestRef());\n      }\n      assert(rr->tid == m->session_mon_tid && rr->session->routed_request_tids.count(m->session_mon_tid));\n      routed_requests.erase(m->session_mon_tid);\n      rr->session->routed_request_tids.erase(m->session_mon_tid);\n      delete rr;\n    } else {\n      dout(10) << \" don't have routed request tid \" << m->session_mon_tid << dendl;\n    }\n  } else {\n    dout(10) << \" not a routed request, trying to send anyway\" << dendl;\n    if (m->msg) {\n      messenger->send_message(m->msg, m->dest);\n      m->msg = NULL;\n    }\n  }\n}\n\nvoid Monitor::resend_routed_requests()\n{\n  dout(10) << \"resend_routed_requests\" << dendl;\n  int mon = get_leader();\n  list<Context*> retry;\n  for (map<uint64_t, RoutedRequest*>::iterator p = routed_requests.begin();\n       p != routed_requests.end();\n       ++p) {\n    RoutedRequest *rr = p->second;\n\n    if (mon == rank) {\n      dout(10) << \" requeue for self tid \" << rr->tid << dendl;\n      rr->op->mark_event(\"retry routed request\");\n      retry.push_back(new C_RetryMessage(this, rr->op));\n      if (rr->session) {\n        assert(rr->session->routed_request_tids.count(p->first));\n        rr->session->routed_request_tids.erase(p->first);\n      }\n      delete rr;\n    } else {\n      bufferlist::iterator q = rr->request_bl.begin();\n      PaxosServiceMessage *req = (PaxosServiceMessage *)decode_message(cct, 0, q);\n      rr->op->mark_event(\"resend forwarded message to leader\");\n      dout(10) << \" resend to mon.\" << mon << \" tid \" << rr->tid << \" \" << *req << dendl;\n      MForward *forward = new MForward(rr->tid, req, rr->con_features,\n\t\t\t\t       rr->session->caps);\n      req->put();  // forward takes its own ref; drop ours.\n      forward->client = rr->client_inst;\n      forward->set_priority(req->get_priority());\n      messenger->send_message(forward, monmap->get_inst(mon));\n    }\n  }\n  if (mon == rank) {\n    routed_requests.clear();\n    finish_contexts(g_ceph_context, retry);\n  }\n}\n\nvoid Monitor::remove_session(MonSession *s)\n{\n  dout(10) << \"remove_session \" << s << \" \" << s->inst\n\t   << \" features 0x\" << std::hex << s->con_features << std::dec << dendl;\n  assert(s->con);\n  assert(!s->closed);\n  for (set<uint64_t>::iterator p = s->routed_request_tids.begin();\n       p != s->routed_request_tids.end();\n       ++p) {\n    assert(routed_requests.count(*p));\n    RoutedRequest *rr = routed_requests[*p];\n    dout(10) << \" dropping routed request \" << rr->tid << dendl;\n    delete rr;\n    routed_requests.erase(*p);\n  }\n  s->routed_request_tids.clear();\n  s->con->set_priv(NULL);\n  session_map.remove_session(s);\n  logger->set(l_mon_num_sessions, session_map.get_size());\n  logger->inc(l_mon_session_rm);\n}\n\nvoid Monitor::remove_all_sessions()\n{\n  Mutex::Locker l(session_map_lock);\n  while (!session_map.sessions.empty()) {\n    MonSession *s = session_map.sessions.front();\n    remove_session(s);\n    if (logger)\n      logger->inc(l_mon_session_rm);\n  }\n  if (logger)\n    logger->set(l_mon_num_sessions, session_map.get_size());\n}\n\nvoid Monitor::send_command(const entity_inst_t& inst,\n\t\t\t   const vector<string>& com)\n{\n  dout(10) << \"send_command \" << inst << \"\" << com << dendl;\n  MMonCommand *c = new MMonCommand(monmap->fsid);\n  c->cmd = com;\n  try_send_message(c, inst);\n}\n\nvoid Monitor::waitlist_or_zap_client(MonOpRequestRef op)\n{\n  /**\n   * Wait list the new session until we're in the quorum, assuming it's\n   * sufficiently new.\n   * tick() will periodically send them back through so we can send\n   * the client elsewhere if we don't think we're getting back in.\n   *\n   * But we whitelist a few sorts of messages:\n   * 1) Monitors can talk to us at any time, of course.\n   * 2) auth messages. It's unlikely to go through much faster, but\n   * it's possible we've just lost our quorum status and we want to take...\n   * 3) command messages. We want to accept these under all possible\n   * circumstances.\n   */\n  Message *m = op->get_req();\n  MonSession *s = op->get_session();\n  ConnectionRef con = op->get_connection();\n  utime_t too_old = ceph_clock_now();\n  too_old -= g_ceph_context->_conf->mon_lease;\n  if (m->get_recv_stamp() > too_old &&\n      con->is_connected()) {\n    dout(5) << \"waitlisting message \" << *m << dendl;\n    maybe_wait_for_quorum.push_back(new C_RetryMessage(this, op));\n    op->mark_wait_for_quorum();\n  } else {\n    dout(5) << \"discarding message \" << *m << \" and sending client elsewhere\" << dendl;\n    con->mark_down();\n    // proxied sessions aren't registered and don't have a con; don't remove\n    // those.\n    if (!s->proxy_con) {\n      Mutex::Locker l(session_map_lock);\n      remove_session(s);\n    }\n    op->mark_zap();\n  }\n}\n\nvoid Monitor::_ms_dispatch(Message *m)\n{\n  if (is_shutdown()) {\n    m->put();\n    return;\n  }\n\n  MonOpRequestRef op = op_tracker.create_request<MonOpRequest>(m);\n  bool src_is_mon = op->is_src_mon();\n  op->mark_event(\"mon:_ms_dispatch\");\n  MonSession *s = op->get_session();\n  if (s && s->closed) {\n    return;\n  }\n\n  if (src_is_mon && s) {\n    ConnectionRef con = m->get_connection();\n    if (con->get_messenger() && con->get_features() != s->con_features) {\n      // only update features if this is a non-anonymous connection\n      dout(10) << __func__ << \" feature change for \" << m->get_source_inst()\n               << \" (was \" << s->con_features\n               << \", now \" << con->get_features() << \")\" << dendl;\n      // connection features changed - recreate session.\n      if (s->con && s->con != con) {\n        dout(10) << __func__ << \" connection for \" << m->get_source_inst()\n                 << \" changed from session; mark down and replace\" << dendl;\n        s->con->mark_down();\n      }\n      if (s->item.is_on_list()) {\n        // forwarded messages' sessions are not in the sessions map and\n        // exist only while the op is being handled.\n        remove_session(s);\n      }\n      s->put();\n      s = nullptr;\n    }\n  }\n\n  if (!s) {\n    // if the sender is not a monitor, make sure their first message for a\n    // session is an MAuth.  If it is not, assume it's a stray message,\n    // and considering that we are creating a new session it is safe to\n    // assume that the sender hasn't authenticated yet, so we have no way\n    // of assessing whether we should handle it or not.\n    if (!src_is_mon && (m->get_type() != CEPH_MSG_AUTH &&\n\t\t\tm->get_type() != CEPH_MSG_MON_GET_MAP &&\n\t\t\tm->get_type() != CEPH_MSG_PING)) {\n      dout(1) << __func__ << \" dropping stray message \" << *m\n\t      << \" from \" << m->get_source_inst() << dendl;\n      return;\n    }\n\n    ConnectionRef con = m->get_connection();\n    {\n      Mutex::Locker l(session_map_lock);\n      s = session_map.new_session(m->get_source_inst(), con.get());\n    }\n    assert(s);\n    con->set_priv(s->get());\n    dout(10) << __func__ << \" new session \" << s << \" \" << *s\n\t     << \" features 0x\" << std::hex\n\t     << s->con_features << std::dec << dendl;\n    op->set_session(s);\n\n    logger->set(l_mon_num_sessions, session_map.get_size());\n    logger->inc(l_mon_session_add);\n\n    if (src_is_mon) {\n      // give it monitor caps; the peer type has been authenticated\n      dout(5) << __func__ << \" setting monitor caps on this connection\" << dendl;\n      if (!s->caps.is_allow_all()) // but no need to repeatedly copy\n        s->caps = *mon_caps;\n    }\n    s->put();\n  } else {\n    dout(20) << __func__ << \" existing session \" << s << \" for \" << s->inst\n\t     << dendl;\n  }\n\n  assert(s);\n\n  s->session_timeout = ceph_clock_now();\n  s->session_timeout += g_conf->mon_session_timeout;\n\n  if (s->auth_handler) {\n    s->entity_name = s->auth_handler->get_entity_name();\n  }\n  dout(20) << \" caps \" << s->caps.get_str() << dendl;\n\n  if ((is_synchronizing() ||\n       (s->global_id == 0 && !exited_quorum.is_zero())) &&\n      !src_is_mon &&\n      m->get_type() != CEPH_MSG_PING) {\n    waitlist_or_zap_client(op);\n  } else {\n    dispatch_op(op);\n  }\n  return;\n}\n\nvoid Monitor::dispatch_op(MonOpRequestRef op)\n{\n  op->mark_event(\"mon:dispatch_op\");\n  MonSession *s = op->get_session();\n  assert(s);\n  if (s->closed) {\n    dout(10) << \" session closed, dropping \" << op->get_req() << dendl;\n    return;\n  }\n\n  /* we will consider the default type as being 'monitor' until proven wrong */\n  op->set_type_monitor();\n  /* deal with all messages that do not necessarily need caps */\n  bool dealt_with = true;\n  switch (op->get_req()->get_type()) {\n    // auth\n    case MSG_MON_GLOBAL_ID:\n    case CEPH_MSG_AUTH:\n      op->set_type_service();\n      /* no need to check caps here */\n      paxos_service[PAXOS_AUTH]->dispatch(op);\n      break;\n\n    case CEPH_MSG_PING:\n      handle_ping(op);\n      break;\n\n    /* MMonGetMap may be used by clients to obtain a monmap *before*\n     * authenticating with the monitor.  We need to handle these without\n     * checking caps because, even on a cluster without cephx, we only set\n     * session caps *after* the auth handshake.  A good example of this\n     * is when a client calls MonClient::get_monmap_privately(), which does\n     * not authenticate when obtaining a monmap.\n     */\n    case CEPH_MSG_MON_GET_MAP:\n      handle_mon_get_map(op);\n      break;\n\n    case CEPH_MSG_MON_METADATA:\n      return handle_mon_metadata(op);\n\n    default:\n      dealt_with = false;\n      break;\n  }\n  if (dealt_with)\n    return;\n\n  /* well, maybe the op belongs to a service... */\n  op->set_type_service();\n  /* deal with all messages which caps should be checked somewhere else */\n  dealt_with = true;\n  switch (op->get_req()->get_type()) {\n\n    // OSDs\n    case CEPH_MSG_MON_GET_OSDMAP:\n    case CEPH_MSG_POOLOP:\n    case MSG_OSD_BEACON:\n    case MSG_OSD_MARK_ME_DOWN:\n    case MSG_OSD_FULL:\n    case MSG_OSD_FAILURE:\n    case MSG_OSD_BOOT:\n    case MSG_OSD_ALIVE:\n    case MSG_OSD_PGTEMP:\n    case MSG_OSD_PG_CREATED:\n    case MSG_REMOVE_SNAPS:\n      paxos_service[PAXOS_OSDMAP]->dispatch(op);\n      break;\n\n    // MDSs\n    case MSG_MDS_BEACON:\n    case MSG_MDS_OFFLOAD_TARGETS:\n      paxos_service[PAXOS_MDSMAP]->dispatch(op);\n      break;\n\n    // Mgrs\n    case MSG_MGR_BEACON:\n      paxos_service[PAXOS_MGR]->dispatch(op);\n      break;\n\n    // MgrStat\n    case CEPH_MSG_STATFS:\n      // this is an ugly hack, sorry!  force the version to 1 so that we do\n      // not run afoul of the is_readable() paxos check.  the client is going\n      // by the pgmonitor version and the MgrStatMonitor version will lag behind\n      // that until we complete the upgrade.  The paxos ordering crap really\n      // doesn't matter for statfs results, so just kludge around it here.\n      if (osdmon()->osdmap.require_osd_release < CEPH_RELEASE_LUMINOUS) {\n\t((MStatfs*)op->get_req())->version = 1;\n      }\n    case MSG_MON_MGR_REPORT:\n    case MSG_GETPOOLSTATS:\n      paxos_service[PAXOS_MGRSTAT]->dispatch(op);\n      break;\n\n    // pg\n    case MSG_PGSTATS:\n      paxos_service[PAXOS_PGMAP]->dispatch(op);\n      break;\n\n    // log\n    case MSG_LOG:\n      paxos_service[PAXOS_LOG]->dispatch(op);\n      break;\n\n    // handle_command() does its own caps checking\n    case MSG_MON_COMMAND:\n      op->set_type_command();\n      handle_command(op);\n      break;\n\n    default:\n      dealt_with = false;\n      break;\n  }\n  if (dealt_with)\n    return;\n\n  /* nop, looks like it's not a service message; revert back to monitor */\n  op->set_type_monitor();\n\n  /* messages we, the Monitor class, need to deal with\n   * but may be sent by clients. */\n\n  if (!op->get_session()->is_capable(\"mon\", MON_CAP_R)) {\n    dout(5) << __func__ << \" \" << op->get_req()->get_source_inst()\n            << \" not enough caps for \" << *(op->get_req()) << \" -- dropping\"\n            << dendl;\n    goto drop;\n  }\n\n  dealt_with = true;\n  switch (op->get_req()->get_type()) {\n\n    // misc\n    case CEPH_MSG_MON_GET_VERSION:\n      handle_get_version(op);\n      break;\n\n    case CEPH_MSG_MON_SUBSCRIBE:\n      /* FIXME: check what's being subscribed, filter accordingly */\n      handle_subscribe(op);\n      break;\n\n    default:\n      dealt_with = false;\n      break;\n  }\n  if (dealt_with)\n    return;\n\n  if (!op->is_src_mon()) {\n    dout(1) << __func__ << \" unexpected monitor message from\"\n            << \" non-monitor entity \" << op->get_req()->get_source_inst()\n            << \" \" << *(op->get_req()) << \" -- dropping\" << dendl;\n    goto drop;\n  }\n\n  /* messages that should only be sent by another monitor */\n  dealt_with = true;\n  switch (op->get_req()->get_type()) {\n\n    case MSG_ROUTE:\n      handle_route(op);\n      break;\n\n    case MSG_MON_PROBE:\n      handle_probe(op);\n      break;\n\n    // Sync (i.e., the new slurp, but on steroids)\n    case MSG_MON_SYNC:\n      handle_sync(op);\n      break;\n    case MSG_MON_SCRUB:\n      handle_scrub(op);\n      break;\n\n    /* log acks are sent from a monitor we sent the MLog to, and are\n       never sent by clients to us. */\n    case MSG_LOGACK:\n      log_client.handle_log_ack((MLogAck*)op->get_req());\n      break;\n\n    // monmap\n    case MSG_MON_JOIN:\n      op->set_type_service();\n      paxos_service[PAXOS_MONMAP]->dispatch(op);\n      break;\n\n    // paxos\n    case MSG_MON_PAXOS:\n      {\n        op->set_type_paxos();\n        MMonPaxos *pm = static_cast<MMonPaxos*>(op->get_req());\n        if (!op->get_session()->is_capable(\"mon\", MON_CAP_X)) {\n          //can't send these!\n          break;\n        }\n\n        if (state == STATE_SYNCHRONIZING) {\n          // we are synchronizing. These messages would do us no\n          // good, thus just drop them and ignore them.\n          dout(10) << __func__ << \" ignore paxos msg from \"\n            << pm->get_source_inst() << dendl;\n          break;\n        }\n\n        // sanitize\n        if (pm->epoch > get_epoch()) {\n          bootstrap();\n          break;\n        }\n        if (pm->epoch != get_epoch()) {\n          break;\n        }\n\n        paxos->dispatch(op);\n      }\n      break;\n\n    // elector messages\n    case MSG_MON_ELECTION:\n      op->set_type_election();\n      //check privileges here for simplicity\n      if (!op->get_session()->is_capable(\"mon\", MON_CAP_X)) {\n        dout(0) << \"MMonElection received from entity without enough caps!\"\n          << op->get_session()->caps << dendl;\n        break;\n      }\n      if (!is_probing() && !is_synchronizing()) {\n        elector.dispatch(op);\n      }\n      break;\n\n    case MSG_FORWARD:\n      handle_forward(op);\n      break;\n\n    case MSG_TIMECHECK:\n      handle_timecheck(op);\n      break;\n\n    case MSG_MON_HEALTH:\n      health_monitor->dispatch(op);\n      break;\n\n    case MSG_MON_HEALTH_CHECKS:\n      op->set_type_service();\n      paxos_service[PAXOS_HEALTH]->dispatch(op);\n      break;\n\n    default:\n      dealt_with = false;\n      break;\n  }\n  if (!dealt_with) {\n    dout(1) << \"dropping unexpected \" << *(op->get_req()) << dendl;\n    goto drop;\n  }\n  return;\n\ndrop:\n  return;\n}\n\nvoid Monitor::handle_ping(MonOpRequestRef op)\n{\n  MPing *m = static_cast<MPing*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n  MPing *reply = new MPing;\n  entity_inst_t inst = m->get_source_inst();\n  bufferlist payload;\n  boost::scoped_ptr<Formatter> f(new JSONFormatter(true));\n  f->open_object_section(\"pong\");\n\n  if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n    get_health_status(false, f.get(), nullptr);\n  } else {\n    list<string> health_str;\n    get_health(health_str, nullptr, f.get());\n  }\n\n  {\n    stringstream ss;\n    get_mon_status(f.get(), ss);\n  }\n\n  f->close_section();\n  stringstream ss;\n  f->flush(ss);\n  ::encode(ss.str(), payload);\n  reply->set_payload(payload);\n  dout(10) << __func__ << \" reply payload len \" << reply->get_payload().length() << dendl;\n  messenger->send_message(reply, inst);\n}\n\nvoid Monitor::timecheck_start()\n{\n  dout(10) << __func__ << dendl;\n  timecheck_cleanup();\n  timecheck_start_round();\n}\n\nvoid Monitor::timecheck_finish()\n{\n  dout(10) << __func__ << dendl;\n  timecheck_cleanup();\n}\n\nvoid Monitor::timecheck_start_round()\n{\n  dout(10) << __func__ << \" curr \" << timecheck_round << dendl;\n  assert(is_leader());\n\n  if (monmap->size() == 1) {\n    assert(0 == \"We are alone; this shouldn't have been scheduled!\");\n    return;\n  }\n\n  if (timecheck_round % 2) {\n    dout(10) << __func__ << \" there's a timecheck going on\" << dendl;\n    utime_t curr_time = ceph_clock_now();\n    double max = g_conf->mon_timecheck_interval*3;\n    if (curr_time - timecheck_round_start < max) {\n      dout(10) << __func__ << \" keep current round going\" << dendl;\n      goto out;\n    } else {\n      dout(10) << __func__\n               << \" finish current timecheck and start new\" << dendl;\n      timecheck_cancel_round();\n    }\n  }\n\n  assert(timecheck_round % 2 == 0);\n  timecheck_acks = 0;\n  timecheck_round ++;\n  timecheck_round_start = ceph_clock_now();\n  dout(10) << __func__ << \" new \" << timecheck_round << dendl;\n\n  timecheck();\nout:\n  dout(10) << __func__ << \" setting up next event\" << dendl;\n  timecheck_reset_event();\n}\n\nvoid Monitor::timecheck_finish_round(bool success)\n{\n  dout(10) << __func__ << \" curr \" << timecheck_round << dendl;\n  assert(timecheck_round % 2);\n  timecheck_round ++;\n  timecheck_round_start = utime_t();\n\n  if (success) {\n    assert(timecheck_waiting.empty());\n    assert(timecheck_acks == quorum.size());\n    timecheck_report();\n    timecheck_check_skews();\n    return;\n  }\n\n  dout(10) << __func__ << \" \" << timecheck_waiting.size()\n           << \" peers still waiting:\";\n  for (map<entity_inst_t,utime_t>::iterator p = timecheck_waiting.begin();\n      p != timecheck_waiting.end(); ++p) {\n    *_dout << \" \" << p->first.name;\n  }\n  *_dout << dendl;\n  timecheck_waiting.clear();\n\n  dout(10) << __func__ << \" finished to \" << timecheck_round << dendl;\n}\n\nvoid Monitor::timecheck_cancel_round()\n{\n  timecheck_finish_round(false);\n}\n\nvoid Monitor::timecheck_cleanup()\n{\n  timecheck_round = 0;\n  timecheck_acks = 0;\n  timecheck_round_start = utime_t();\n\n  if (timecheck_event) {\n    timer.cancel_event(timecheck_event);\n    timecheck_event = NULL;\n  }\n  timecheck_waiting.clear();\n  timecheck_skews.clear();\n  timecheck_latencies.clear();\n\n  timecheck_rounds_since_clean = 0;\n}\n\nvoid Monitor::timecheck_reset_event()\n{\n  if (timecheck_event) {\n    timer.cancel_event(timecheck_event);\n    timecheck_event = NULL;\n  }\n\n  double delay =\n    cct->_conf->mon_timecheck_skew_interval * timecheck_rounds_since_clean;\n\n  if (delay <= 0 || delay > cct->_conf->mon_timecheck_interval) {\n    delay = cct->_conf->mon_timecheck_interval;\n  }\n\n  dout(10) << __func__ << \" delay \" << delay\n           << \" rounds_since_clean \" << timecheck_rounds_since_clean\n           << dendl;\n\n  timecheck_event = timer.add_event_after(\n    delay,\n    new C_MonContext(this, [this](int) {\n\ttimecheck_start_round();\n      }));\n}\n\nvoid Monitor::timecheck_check_skews()\n{\n  dout(10) << __func__ << dendl;\n  assert(is_leader());\n  assert((timecheck_round % 2) == 0);\n  if (monmap->size() == 1) {\n    assert(0 == \"We are alone; we shouldn't have gotten here!\");\n    return;\n  }\n  assert(timecheck_latencies.size() == timecheck_skews.size());\n\n  bool found_skew = false;\n  for (map<entity_inst_t, double>::iterator p = timecheck_skews.begin();\n       p != timecheck_skews.end(); ++p) {\n\n    double abs_skew;\n    if (timecheck_has_skew(p->second, &abs_skew)) {\n      dout(10) << __func__\n               << \" \" << p->first << \" skew \" << abs_skew << dendl;\n      found_skew = true;\n    }\n  }\n\n  if (found_skew) {\n    ++timecheck_rounds_since_clean;\n    timecheck_reset_event();\n  } else if (timecheck_rounds_since_clean > 0) {\n    dout(1) << __func__\n      << \" no clock skews found after \" << timecheck_rounds_since_clean\n      << \" rounds\" << dendl;\n    // make sure the skews are really gone and not just a transient success\n    // this will run just once if not in the presence of skews again.\n    timecheck_rounds_since_clean = 1;\n    timecheck_reset_event();\n    timecheck_rounds_since_clean = 0;\n  }\n\n}\n\nvoid Monitor::timecheck_report()\n{\n  dout(10) << __func__ << dendl;\n  assert(is_leader());\n  assert((timecheck_round % 2) == 0);\n  if (monmap->size() == 1) {\n    assert(0 == \"We are alone; we shouldn't have gotten here!\");\n    return;\n  }\n\n  assert(timecheck_latencies.size() == timecheck_skews.size());\n  bool do_output = true; // only output report once\n  for (set<int>::iterator q = quorum.begin(); q != quorum.end(); ++q) {\n    if (monmap->get_name(*q) == name)\n      continue;\n\n    MTimeCheck *m = new MTimeCheck(MTimeCheck::OP_REPORT);\n    m->epoch = get_epoch();\n    m->round = timecheck_round;\n\n    for (map<entity_inst_t, double>::iterator it = timecheck_skews.begin();\n         it != timecheck_skews.end(); ++it) {\n      double skew = it->second;\n      double latency = timecheck_latencies[it->first];\n\n      m->skews[it->first] = skew;\n      m->latencies[it->first] = latency;\n\n      if (do_output) {\n        dout(25) << __func__ << \" \" << it->first\n                 << \" latency \" << latency\n                 << \" skew \" << skew << dendl;\n      }\n    }\n    do_output = false;\n    entity_inst_t inst = monmap->get_inst(*q);\n    dout(10) << __func__ << \" send report to \" << inst << dendl;\n    messenger->send_message(m, inst);\n  }\n}\n\nvoid Monitor::timecheck()\n{\n  dout(10) << __func__ << dendl;\n  assert(is_leader());\n  if (monmap->size() == 1) {\n    assert(0 == \"We are alone; we shouldn't have gotten here!\");\n    return;\n  }\n  assert(timecheck_round % 2 != 0);\n\n  timecheck_acks = 1; // we ack ourselves\n\n  dout(10) << __func__ << \" start timecheck epoch \" << get_epoch()\n           << \" round \" << timecheck_round << dendl;\n\n  // we are at the eye of the storm; the point of reference\n  timecheck_skews[messenger->get_myinst()] = 0.0;\n  timecheck_latencies[messenger->get_myinst()] = 0.0;\n\n  for (set<int>::iterator it = quorum.begin(); it != quorum.end(); ++it) {\n    if (monmap->get_name(*it) == name)\n      continue;\n\n    entity_inst_t inst = monmap->get_inst(*it);\n    utime_t curr_time = ceph_clock_now();\n    timecheck_waiting[inst] = curr_time;\n    MTimeCheck *m = new MTimeCheck(MTimeCheck::OP_PING);\n    m->epoch = get_epoch();\n    m->round = timecheck_round;\n    dout(10) << __func__ << \" send \" << *m << \" to \" << inst << dendl;\n    messenger->send_message(m, inst);\n  }\n}\n\nhealth_status_t Monitor::timecheck_status(ostringstream &ss,\n                                          const double skew_bound,\n                                          const double latency)\n{\n  health_status_t status = HEALTH_OK;\n  assert(latency >= 0);\n\n  double abs_skew;\n  if (timecheck_has_skew(skew_bound, &abs_skew)) {\n    status = HEALTH_WARN;\n    ss << \"clock skew \" << abs_skew << \"s\"\n       << \" > max \" << g_conf->mon_clock_drift_allowed << \"s\";\n  }\n\n  return status;\n}\n\nvoid Monitor::handle_timecheck_leader(MonOpRequestRef op)\n{\n  MTimeCheck *m = static_cast<MTimeCheck*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n  /* handles PONG's */\n  assert(m->op == MTimeCheck::OP_PONG);\n\n  entity_inst_t other = m->get_source_inst();\n  if (m->epoch < get_epoch()) {\n    dout(1) << __func__ << \" got old timecheck epoch \" << m->epoch\n            << \" from \" << other\n            << \" curr \" << get_epoch()\n            << \" -- severely lagged? discard\" << dendl;\n    return;\n  }\n  assert(m->epoch == get_epoch());\n\n  if (m->round < timecheck_round) {\n    dout(1) << __func__ << \" got old round \" << m->round\n            << \" from \" << other\n            << \" curr \" << timecheck_round << \" -- discard\" << dendl;\n    return;\n  }\n\n  utime_t curr_time = ceph_clock_now();\n\n  assert(timecheck_waiting.count(other) > 0);\n  utime_t timecheck_sent = timecheck_waiting[other];\n  timecheck_waiting.erase(other);\n  if (curr_time < timecheck_sent) {\n    // our clock was readjusted -- drop everything until it all makes sense.\n    dout(1) << __func__ << \" our clock was readjusted --\"\n            << \" bump round and drop current check\"\n            << dendl;\n    timecheck_cancel_round();\n    return;\n  }\n\n  /* update peer latencies */\n  double latency = (double)(curr_time - timecheck_sent);\n\n  if (timecheck_latencies.count(other) == 0)\n    timecheck_latencies[other] = latency;\n  else {\n    double avg_latency = ((timecheck_latencies[other]*0.8)+(latency*0.2));\n    timecheck_latencies[other] = avg_latency;\n  }\n\n  /*\n   * update skews\n   *\n   * some nasty thing goes on if we were to do 'a - b' between two utime_t,\n   * and 'a' happens to be lower than 'b'; so we use double instead.\n   *\n   * latency is always expected to be >= 0.\n   *\n   * delta, the difference between theirs timestamp and ours, may either be\n   * lower or higher than 0; will hardly ever be 0.\n   *\n   * The absolute skew is the absolute delta minus the latency, which is\n   * taken as a whole instead of an rtt given that there is some queueing\n   * and dispatch times involved and it's hard to assess how long exactly\n   * it took for the message to travel to the other side and be handled. So\n   * we call it a bounded skew, the worst case scenario.\n   *\n   * Now, to math!\n   *\n   * Given that the latency is always positive, we can establish that the\n   * bounded skew will be:\n   *\n   *  1. positive if the absolute delta is higher than the latency and\n   *     delta is positive\n   *  2. negative if the absolute delta is higher than the latency and\n   *     delta is negative.\n   *  3. zero if the absolute delta is lower than the latency.\n   *\n   * On 3. we make a judgement call and treat the skew as non-existent.\n   * This is because that, if the absolute delta is lower than the\n   * latency, then the apparently existing skew is nothing more than a\n   * side-effect of the high latency at work.\n   *\n   * This may not be entirely true though, as a severely skewed clock\n   * may be masked by an even higher latency, but with high latencies\n   * we probably have worse issues to deal with than just skewed clocks.\n   */\n  assert(latency >= 0);\n\n  double delta = ((double) m->timestamp) - ((double) curr_time);\n  double abs_delta = (delta > 0 ? delta : -delta);\n  double skew_bound = abs_delta - latency;\n  if (skew_bound < 0)\n    skew_bound = 0;\n  else if (delta < 0)\n    skew_bound = -skew_bound;\n\n  ostringstream ss;\n  health_status_t status = timecheck_status(ss, skew_bound, latency);\n  if (status != HEALTH_OK) {\n    clog->health(status) << other << \" \" << ss.str();\n  }\n\n  dout(10) << __func__ << \" from \" << other << \" ts \" << m->timestamp\n\t   << \" delta \" << delta << \" skew_bound \" << skew_bound\n\t   << \" latency \" << latency << dendl;\n\n  timecheck_skews[other] = skew_bound;\n\n  timecheck_acks++;\n  if (timecheck_acks == quorum.size()) {\n    dout(10) << __func__ << \" got pongs from everybody (\"\n             << timecheck_acks << \" total)\" << dendl;\n    assert(timecheck_skews.size() == timecheck_acks);\n    assert(timecheck_waiting.empty());\n    // everyone has acked, so bump the round to finish it.\n    timecheck_finish_round();\n  }\n}\n\nvoid Monitor::handle_timecheck_peon(MonOpRequestRef op)\n{\n  MTimeCheck *m = static_cast<MTimeCheck*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n\n  assert(is_peon());\n  assert(m->op == MTimeCheck::OP_PING || m->op == MTimeCheck::OP_REPORT);\n\n  if (m->epoch != get_epoch()) {\n    dout(1) << __func__ << \" got wrong epoch \"\n            << \"(ours \" << get_epoch()\n            << \" theirs: \" << m->epoch << \") -- discarding\" << dendl;\n    return;\n  }\n\n  if (m->round < timecheck_round) {\n    dout(1) << __func__ << \" got old round \" << m->round\n            << \" current \" << timecheck_round\n            << \" (epoch \" << get_epoch() << \") -- discarding\" << dendl;\n    return;\n  }\n\n  timecheck_round = m->round;\n\n  if (m->op == MTimeCheck::OP_REPORT) {\n    assert((timecheck_round % 2) == 0);\n    timecheck_latencies.swap(m->latencies);\n    timecheck_skews.swap(m->skews);\n    return;\n  }\n\n  assert((timecheck_round % 2) != 0);\n  MTimeCheck *reply = new MTimeCheck(MTimeCheck::OP_PONG);\n  utime_t curr_time = ceph_clock_now();\n  reply->timestamp = curr_time;\n  reply->epoch = m->epoch;\n  reply->round = m->round;\n  dout(10) << __func__ << \" send \" << *m\n           << \" to \" << m->get_source_inst() << dendl;\n  m->get_connection()->send_message(reply);\n}\n\nvoid Monitor::handle_timecheck(MonOpRequestRef op)\n{\n  MTimeCheck *m = static_cast<MTimeCheck*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n\n  if (is_leader()) {\n    if (m->op != MTimeCheck::OP_PONG) {\n      dout(1) << __func__ << \" drop unexpected msg (not pong)\" << dendl;\n    } else {\n      handle_timecheck_leader(op);\n    }\n  } else if (is_peon()) {\n    if (m->op != MTimeCheck::OP_PING && m->op != MTimeCheck::OP_REPORT) {\n      dout(1) << __func__ << \" drop unexpected msg (not ping or report)\" << dendl;\n    } else {\n      handle_timecheck_peon(op);\n    }\n  } else {\n    dout(1) << __func__ << \" drop unexpected msg\" << dendl;\n  }\n}\n\nvoid Monitor::handle_subscribe(MonOpRequestRef op)\n{\n  MMonSubscribe *m = static_cast<MMonSubscribe*>(op->get_req());\n  dout(10) << \"handle_subscribe \" << *m << dendl;\n  \n  bool reply = false;\n\n  MonSession *s = op->get_session();\n  assert(s);\n\n  for (map<string,ceph_mon_subscribe_item>::iterator p = m->what.begin();\n       p != m->what.end();\n       ++p) {\n    // if there are any non-onetime subscriptions, we need to reply to start the resubscribe timer\n    if ((p->second.flags & CEPH_SUBSCRIBE_ONETIME) == 0)\n      reply = true;\n\n    // remove conflicting subscribes\n    if (logmon()->sub_name_to_id(p->first) >= 0) {\n      for (map<string, Subscription*>::iterator it = s->sub_map.begin();\n\t   it != s->sub_map.end(); ) {\n\tif (it->first != p->first && logmon()->sub_name_to_id(it->first) >= 0) {\n\t  Mutex::Locker l(session_map_lock);\n\t  session_map.remove_sub((it++)->second);\n\t} else {\n\t  ++it;\n\t}\n      }\n    }\n\n    {\n      Mutex::Locker l(session_map_lock);\n      session_map.add_update_sub(s, p->first, p->second.start,\n\t\t\t\t p->second.flags & CEPH_SUBSCRIBE_ONETIME,\n\t\t\t\t m->get_connection()->has_feature(CEPH_FEATURE_INCSUBOSDMAP));\n    }\n\n    if (p->first.compare(0, 6, \"mdsmap\") == 0 || p->first.compare(0, 5, \"fsmap\") == 0) {\n      dout(10) << __func__ << \": MDS sub '\" << p->first << \"'\" << dendl;\n      if ((int)s->is_capable(\"mds\", MON_CAP_R)) {\n        Subscription *sub = s->sub_map[p->first];\n        assert(sub != nullptr);\n        mdsmon()->check_sub(sub);\n      }\n    } else if (p->first == \"osdmap\") {\n      if ((int)s->is_capable(\"osd\", MON_CAP_R)) {\n\tif (s->osd_epoch > p->second.start) {\n\t  // client needs earlier osdmaps on purpose, so reset the sent epoch\n\t  s->osd_epoch = 0;\n\t}\n        osdmon()->check_osdmap_sub(s->sub_map[\"osdmap\"]);\n      }\n    } else if (p->first == \"osd_pg_creates\") {\n      if ((int)s->is_capable(\"osd\", MON_CAP_W)) {\n\tif (monmap->get_required_features().contains_all(\n\t      ceph::features::mon::FEATURE_LUMINOUS)) {\n\t  osdmon()->check_pg_creates_sub(s->sub_map[\"osd_pg_creates\"]);\n\t} else {\n\t  pgmon()->check_sub(s->sub_map[\"osd_pg_creates\"]);\n\t}\n      }\n    } else if (p->first == \"monmap\") {\n      monmon()->check_sub(s->sub_map[p->first]);\n    } else if (logmon()->sub_name_to_id(p->first) >= 0) {\n      logmon()->check_sub(s->sub_map[p->first]);\n    } else if (p->first == \"mgrmap\" || p->first == \"mgrdigest\") {\n      mgrmon()->check_sub(s->sub_map[p->first]);\n    } else if (p->first == \"servicemap\") {\n      mgrstatmon()->check_sub(s->sub_map[p->first]);\n    }\n  }\n\n  if (reply) {\n    // we only need to reply if the client is old enough to think it\n    // has to send renewals.\n    ConnectionRef con = m->get_connection();\n    if (!con->has_feature(CEPH_FEATURE_MON_STATEFUL_SUB))\n      m->get_connection()->send_message(new MMonSubscribeAck(\n\tmonmap->get_fsid(), (int)g_conf->mon_subscribe_interval));\n  }\n\n}\n\nvoid Monitor::handle_get_version(MonOpRequestRef op)\n{\n  MMonGetVersion *m = static_cast<MMonGetVersion*>(op->get_req());\n  dout(10) << \"handle_get_version \" << *m << dendl;\n  PaxosService *svc = NULL;\n\n  MonSession *s = op->get_session();\n  assert(s);\n\n  if (!is_leader() && !is_peon()) {\n    dout(10) << \" waiting for quorum\" << dendl;\n    waitfor_quorum.push_back(new C_RetryMessage(this, op));\n    goto out;\n  }\n\n  if (m->what == \"mdsmap\") {\n    svc = mdsmon();\n  } else if (m->what == \"fsmap\") {\n    svc = mdsmon();\n  } else if (m->what == \"osdmap\") {\n    svc = osdmon();\n  } else if (m->what == \"monmap\") {\n    svc = monmon();\n  } else {\n    derr << \"invalid map type \" << m->what << dendl;\n  }\n\n  if (svc) {\n    if (!svc->is_readable()) {\n      svc->wait_for_readable(op, new C_RetryMessage(this, op));\n      goto out;\n    }\n\n    MMonGetVersionReply *reply = new MMonGetVersionReply();\n    reply->handle = m->handle;\n    reply->version = svc->get_last_committed();\n    reply->oldest_version = svc->get_first_committed();\n    reply->set_tid(m->get_tid());\n\n    m->get_connection()->send_message(reply);\n  }\n out:\n  return;\n}\n\nbool Monitor::ms_handle_reset(Connection *con)\n{\n  dout(10) << \"ms_handle_reset \" << con << \" \" << con->get_peer_addr() << dendl;\n\n  // ignore lossless monitor sessions\n  if (con->get_peer_type() == CEPH_ENTITY_TYPE_MON)\n    return false;\n\n  MonSession *s = static_cast<MonSession *>(con->get_priv());\n  if (!s)\n    return false;\n\n  // break any con <-> session ref cycle\n  s->con->set_priv(NULL);\n\n  if (is_shutdown())\n    return false;\n\n  Mutex::Locker l(lock);\n\n  dout(10) << \"reset/close on session \" << s->inst << dendl;\n  if (!s->closed) {\n    Mutex::Locker l(session_map_lock);\n    remove_session(s);\n  }\n  s->put();\n  return true;\n}\n\nbool Monitor::ms_handle_refused(Connection *con)\n{\n  // just log for now...\n  dout(10) << \"ms_handle_refused \" << con << \" \" << con->get_peer_addr() << dendl;\n  return false;\n}\n\n// -----\n\nvoid Monitor::send_latest_monmap(Connection *con)\n{\n  bufferlist bl;\n  monmap->encode(bl, con->get_features());\n  con->send_message(new MMonMap(bl));\n}\n\nvoid Monitor::handle_mon_get_map(MonOpRequestRef op)\n{\n  MMonGetMap *m = static_cast<MMonGetMap*>(op->get_req());\n  dout(10) << \"handle_mon_get_map\" << dendl;\n  send_latest_monmap(m->get_connection().get());\n}\n\nvoid Monitor::handle_mon_metadata(MonOpRequestRef op)\n{\n  MMonMetadata *m = static_cast<MMonMetadata*>(op->get_req());\n  if (is_leader()) {\n    dout(10) << __func__ << dendl;\n    update_mon_metadata(m->get_source().num(), std::move(m->data));\n  }\n}\n\nvoid Monitor::update_mon_metadata(int from, Metadata&& m)\n{\n  // NOTE: this is now for legacy (kraken or jewel) mons only.\n  pending_metadata[from] = std::move(m);\n\n  MonitorDBStore::TransactionRef t = paxos->get_pending_transaction();\n  bufferlist bl;\n  ::encode(pending_metadata, bl);\n  t->put(MONITOR_STORE_PREFIX, \"last_metadata\", bl);\n  paxos->trigger_propose();\n}\n\nint Monitor::load_metadata()\n{\n  bufferlist bl;\n  int r = store->get(MONITOR_STORE_PREFIX, \"last_metadata\", bl);\n  if (r)\n    return r;\n  bufferlist::iterator it = bl.begin();\n  ::decode(mon_metadata, it);\n\n  pending_metadata = mon_metadata;\n  return 0;\n}\n\nint Monitor::get_mon_metadata(int mon, Formatter *f, ostream& err)\n{\n  assert(f);\n  if (!mon_metadata.count(mon)) {\n    err << \"mon.\" << mon << \" not found\";\n    return -EINVAL;\n  }\n  const Metadata& m = mon_metadata[mon];\n  for (Metadata::const_iterator p = m.begin(); p != m.end(); ++p) {\n    f->dump_string(p->first.c_str(), p->second);\n  }\n  return 0;\n}\n\nvoid Monitor::count_metadata(const string& field, map<string,int> *out)\n{\n  for (auto& p : mon_metadata) {\n    auto q = p.second.find(field);\n    if (q == p.second.end()) {\n      (*out)[\"unknown\"]++;\n    } else {\n      (*out)[q->second]++;\n    }\n  }\n}\n\nvoid Monitor::count_metadata(const string& field, Formatter *f)\n{\n  map<string,int> by_val;\n  count_metadata(field, &by_val);\n  f->open_object_section(field.c_str());\n  for (auto& p : by_val) {\n    f->dump_int(p.first.c_str(), p.second);\n  }\n  f->close_section();\n}\n\nint Monitor::print_nodes(Formatter *f, ostream& err)\n{\n  map<string, list<int> > mons;\t// hostname => mon\n  for (map<int, Metadata>::iterator it = mon_metadata.begin();\n       it != mon_metadata.end(); ++it) {\n    const Metadata& m = it->second;\n    Metadata::const_iterator hostname = m.find(\"hostname\");\n    if (hostname == m.end()) {\n      // not likely though\n      continue;\n    }\n    mons[hostname->second].push_back(it->first);\n  }\n\n  dump_services(f, mons, \"mon\");\n  return 0;\n}\n\n// ----------------------------------------------\n// scrub\n\nint Monitor::scrub_start()\n{\n  dout(10) << __func__ << dendl;\n  assert(is_leader());\n\n  if (!scrub_result.empty()) {\n    clog->info() << \"scrub already in progress\";\n    return -EBUSY;\n  }\n\n  scrub_event_cancel();\n  scrub_result.clear();\n  scrub_state.reset(new ScrubState);\n\n  scrub();\n  return 0;\n}\n\nint Monitor::scrub()\n{\n  assert(is_leader());\n  assert(scrub_state);\n\n  scrub_cancel_timeout();\n  wait_for_paxos_write();\n  scrub_version = paxos->get_version();\n\n\n  // scrub all keys if we're the only monitor in the quorum\n  int32_t num_keys =\n    (quorum.size() == 1 ? -1 : cct->_conf->mon_scrub_max_keys);\n\n  for (set<int>::iterator p = quorum.begin();\n       p != quorum.end();\n       ++p) {\n    if (*p == rank)\n      continue;\n    MMonScrub *r = new MMonScrub(MMonScrub::OP_SCRUB, scrub_version,\n                                 num_keys);\n    r->key = scrub_state->last_key;\n    messenger->send_message(r, monmap->get_inst(*p));\n  }\n\n  // scrub my keys\n  bool r = _scrub(&scrub_result[rank],\n                  &scrub_state->last_key,\n                  &num_keys);\n\n  scrub_state->finished = !r;\n\n  // only after we got our scrub results do we really care whether the\n  // other monitors are late on their results.  Also, this way we avoid\n  // triggering the timeout if we end up getting stuck in _scrub() for\n  // longer than the duration of the timeout.\n  scrub_reset_timeout();\n\n  if (quorum.size() == 1) {\n    assert(scrub_state->finished == true);\n    scrub_finish();\n  }\n  return 0;\n}\n\nvoid Monitor::handle_scrub(MonOpRequestRef op)\n{\n  MMonScrub *m = static_cast<MMonScrub*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n  switch (m->op) {\n  case MMonScrub::OP_SCRUB:\n    {\n      if (!is_peon())\n\tbreak;\n\n      wait_for_paxos_write();\n\n      if (m->version != paxos->get_version())\n\tbreak;\n\n      MMonScrub *reply = new MMonScrub(MMonScrub::OP_RESULT,\n                                       m->version,\n                                       m->num_keys);\n\n      reply->key = m->key;\n      _scrub(&reply->result, &reply->key, &reply->num_keys);\n      m->get_connection()->send_message(reply);\n    }\n    break;\n\n  case MMonScrub::OP_RESULT:\n    {\n      if (!is_leader())\n\tbreak;\n      if (m->version != scrub_version)\n\tbreak;\n      // reset the timeout each time we get a result\n      scrub_reset_timeout();\n\n      int from = m->get_source().num();\n      assert(scrub_result.count(from) == 0);\n      scrub_result[from] = m->result;\n\n      if (scrub_result.size() == quorum.size()) {\n        scrub_check_results();\n        scrub_result.clear();\n        if (scrub_state->finished)\n          scrub_finish();\n        else\n          scrub();\n      }\n    }\n    break;\n  }\n}\n\nbool Monitor::_scrub(ScrubResult *r,\n                     pair<string,string> *start,\n                     int *num_keys)\n{\n  assert(r != NULL);\n  assert(start != NULL);\n  assert(num_keys != NULL);\n\n  set<string> prefixes = get_sync_targets_names();\n  prefixes.erase(\"paxos\");  // exclude paxos, as this one may have extra states for proposals, etc.\n\n  dout(10) << __func__ << \" start (\" << *start << \")\"\n           << \" num_keys \" << *num_keys << dendl;\n\n  MonitorDBStore::Synchronizer it = store->get_synchronizer(*start, prefixes);\n\n  int scrubbed_keys = 0;\n  pair<string,string> last_key;\n\n  while (it->has_next_chunk()) {\n\n    if (*num_keys > 0 && scrubbed_keys == *num_keys)\n      break;\n\n    pair<string,string> k = it->get_next_key();\n    if (prefixes.count(k.first) == 0)\n      continue;\n\n    if (cct->_conf->mon_scrub_inject_missing_keys > 0.0 &&\n        (rand() % 10000 < cct->_conf->mon_scrub_inject_missing_keys*10000.0)) {\n      dout(10) << __func__ << \" inject missing key, skipping (\" << k << \")\"\n               << dendl;\n      continue;\n    }\n\n    bufferlist bl;\n    int err = store->get(k.first, k.second, bl);\n    assert(err == 0);\n    \n    uint32_t key_crc = bl.crc32c(0);\n    dout(30) << __func__ << \" \" << k << \" bl \" << bl.length() << \" bytes\"\n                                     << \" crc \" << key_crc << dendl;\n    r->prefix_keys[k.first]++;\n    if (r->prefix_crc.count(k.first) == 0) {\n      r->prefix_crc[k.first] = 0;\n    }\n    r->prefix_crc[k.first] = bl.crc32c(r->prefix_crc[k.first]);\n\n    if (cct->_conf->mon_scrub_inject_crc_mismatch > 0.0 &&\n        (rand() % 10000 < cct->_conf->mon_scrub_inject_crc_mismatch*10000.0)) {\n      dout(10) << __func__ << \" inject failure at (\" << k << \")\" << dendl;\n      r->prefix_crc[k.first] += 1;\n    }\n\n    ++scrubbed_keys;\n    last_key = k;\n  }\n\n  dout(20) << __func__ << \" last_key (\" << last_key << \")\"\n                       << \" scrubbed_keys \" << scrubbed_keys\n                       << \" has_next \" << it->has_next_chunk() << dendl;\n\n  *start = last_key;\n  *num_keys = scrubbed_keys;\n\n  return it->has_next_chunk();\n}\n\nvoid Monitor::scrub_check_results()\n{\n  dout(10) << __func__ << dendl;\n\n  // compare\n  int errors = 0;\n  ScrubResult& mine = scrub_result[rank];\n  for (map<int,ScrubResult>::iterator p = scrub_result.begin();\n       p != scrub_result.end();\n       ++p) {\n    if (p->first == rank)\n      continue;\n    if (p->second != mine) {\n      ++errors;\n      clog->error() << \"scrub mismatch\";\n      clog->error() << \" mon.\" << rank << \" \" << mine;\n      clog->error() << \" mon.\" << p->first << \" \" << p->second;\n    }\n  }\n  if (!errors)\n    clog->debug() << \"scrub ok on \" << quorum << \": \" << mine;\n}\n\ninline void Monitor::scrub_timeout()\n{\n  dout(1) << __func__ << \" restarting scrub\" << dendl;\n  scrub_reset();\n  scrub_start();\n}\n\nvoid Monitor::scrub_finish()\n{\n  dout(10) << __func__ << dendl;\n  scrub_reset();\n  scrub_event_start();\n}\n\nvoid Monitor::scrub_reset()\n{\n  dout(10) << __func__ << dendl;\n  scrub_cancel_timeout();\n  scrub_version = 0;\n  scrub_result.clear();\n  scrub_state.reset();\n}\n\ninline void Monitor::scrub_update_interval(int secs)\n{\n  // we don't care about changes if we are not the leader.\n  // changes will be visible if we become the leader.\n  if (!is_leader())\n    return;\n\n  dout(1) << __func__ << \" new interval = \" << secs << dendl;\n\n  // if scrub already in progress, all changes will already be visible during\n  // the next round.  Nothing to do.\n  if (scrub_state != NULL)\n    return;\n\n  scrub_event_cancel();\n  scrub_event_start();\n}\n\nvoid Monitor::scrub_event_start()\n{\n  dout(10) << __func__ << dendl;\n\n  if (scrub_event)\n    scrub_event_cancel();\n\n  if (cct->_conf->mon_scrub_interval <= 0) {\n    dout(1) << __func__ << \" scrub event is disabled\"\n            << \" (mon_scrub_interval = \" << cct->_conf->mon_scrub_interval\n            << \")\" << dendl;\n    return;\n  }\n\n  scrub_event = timer.add_event_after(\n    cct->_conf->mon_scrub_interval,\n    new C_MonContext(this, [this](int) {\n      scrub_start();\n      }));\n}\n\nvoid Monitor::scrub_event_cancel()\n{\n  dout(10) << __func__ << dendl;\n  if (scrub_event) {\n    timer.cancel_event(scrub_event);\n    scrub_event = NULL;\n  }\n}\n\ninline void Monitor::scrub_cancel_timeout()\n{\n  if (scrub_timeout_event) {\n    timer.cancel_event(scrub_timeout_event);\n    scrub_timeout_event = NULL;\n  }\n}\n\nvoid Monitor::scrub_reset_timeout()\n{\n  dout(15) << __func__ << \" reset timeout event\" << dendl;\n  scrub_cancel_timeout();\n  scrub_timeout_event = timer.add_event_after(\n    g_conf->mon_scrub_timeout,\n    new C_MonContext(this, [this](int) {\n      scrub_timeout();\n    }));\n}\n\n/************ TICK ***************/\nvoid Monitor::new_tick()\n{\n  timer.add_event_after(g_conf->mon_tick_interval, new C_MonContext(this, [this](int) {\n\ttick();\n      }));\n}\n\nvoid Monitor::tick()\n{\n  // ok go.\n  dout(11) << \"tick\" << dendl;\n  const utime_t now = ceph_clock_now();\n  \n  // Check if we need to emit any delayed health check updated messages\n  if (is_leader()) {\n    const auto min_period = g_conf->get_val<int64_t>(\n                              \"mon_health_log_update_period\");\n    for (auto& svc : paxos_service) {\n      auto health = svc->get_health_checks();\n\n      for (const auto &i : health.checks) {\n        const std::string &code = i.first;\n        const std::string &summary = i.second.summary;\n        const health_status_t severity = i.second.severity;\n\n        auto status_iter = health_check_log_times.find(code);\n        if (status_iter == health_check_log_times.end()) {\n          continue;\n        }\n\n        auto &log_status = status_iter->second;\n        bool const changed = log_status.last_message != summary\n                             || log_status.severity != severity;\n\n        if (changed && now - log_status.updated_at > min_period) {\n          log_status.last_message = summary;\n          log_status.updated_at = now;\n          log_status.severity = severity;\n\n          ostringstream ss;\n          ss << \"Health check update: \" << summary << \" (\" << code << \")\";\n          clog->health(severity) << ss.str();\n        }\n      }\n    }\n  }\n\n\n  for (vector<PaxosService*>::iterator p = paxos_service.begin(); p != paxos_service.end(); ++p) {\n    (*p)->tick();\n    (*p)->maybe_trim();\n  }\n  \n  // trim sessions\n  {\n    Mutex::Locker l(session_map_lock);\n    auto p = session_map.sessions.begin();\n\n    bool out_for_too_long = (!exited_quorum.is_zero() &&\n\t\t\t     now > (exited_quorum + 2*g_conf->mon_lease));\n\n    while (!p.end()) {\n      MonSession *s = *p;\n      ++p;\n    \n      // don't trim monitors\n      if (s->inst.name.is_mon())\n\tcontinue;\n\n      if (s->session_timeout < now && s->con) {\n\t// check keepalive, too\n\ts->session_timeout = s->con->get_last_keepalive();\n\ts->session_timeout += g_conf->mon_session_timeout;\n      }\n      if (s->session_timeout < now) {\n\tdout(10) << \" trimming session \" << s->con << \" \" << s->inst\n\t\t << \" (timeout \" << s->session_timeout\n\t\t << \" < now \" << now << \")\" << dendl;\n      } else if (out_for_too_long) {\n\t// boot the client Session because we've taken too long getting back in\n\tdout(10) << \" trimming session \" << s->con << \" \" << s->inst\n\t\t << \" because we've been out of quorum too long\" << dendl;\n      } else {\n\tcontinue;\n      }\n\n      s->con->mark_down();\n      remove_session(s);\n      logger->inc(l_mon_session_trim);\n    }\n  }\n  sync_trim_providers();\n\n  if (!maybe_wait_for_quorum.empty()) {\n    finish_contexts(g_ceph_context, maybe_wait_for_quorum);\n  }\n\n  if (is_leader() && paxos->is_active() && fingerprint.is_zero()) {\n    // this is only necessary on upgraded clusters.\n    MonitorDBStore::TransactionRef t = paxos->get_pending_transaction();\n    prepare_new_fingerprint(t);\n    paxos->trigger_propose();\n  }\n\n  new_tick();\n}\n\nvoid Monitor::prepare_new_fingerprint(MonitorDBStore::TransactionRef t)\n{\n  uuid_d nf;\n  nf.generate_random();\n  dout(10) << __func__ << \" proposing cluster_fingerprint \" << nf << dendl;\n\n  bufferlist bl;\n  ::encode(nf, bl);\n  t->put(MONITOR_NAME, \"cluster_fingerprint\", bl);\n}\n\nint Monitor::check_fsid()\n{\n  bufferlist ebl;\n  int r = store->get(MONITOR_NAME, \"cluster_uuid\", ebl);\n  if (r == -ENOENT)\n    return r;\n  assert(r == 0);\n\n  string es(ebl.c_str(), ebl.length());\n\n  // only keep the first line\n  size_t pos = es.find_first_of('\\n');\n  if (pos != string::npos)\n    es.resize(pos);\n\n  dout(10) << \"check_fsid cluster_uuid contains '\" << es << \"'\" << dendl;\n  uuid_d ondisk;\n  if (!ondisk.parse(es.c_str())) {\n    derr << \"error: unable to parse uuid\" << dendl;\n    return -EINVAL;\n  }\n\n  if (monmap->get_fsid() != ondisk) {\n    derr << \"error: cluster_uuid file exists with value \" << ondisk\n\t << \", != our uuid \" << monmap->get_fsid() << dendl;\n    return -EEXIST;\n  }\n\n  return 0;\n}\n\nint Monitor::write_fsid()\n{\n  auto t(std::make_shared<MonitorDBStore::Transaction>());\n  write_fsid(t);\n  int r = store->apply_transaction(t);\n  return r;\n}\n\nint Monitor::write_fsid(MonitorDBStore::TransactionRef t)\n{\n  ostringstream ss;\n  ss << monmap->get_fsid() << \"\\n\";\n  string us = ss.str();\n\n  bufferlist b;\n  b.append(us);\n\n  t->put(MONITOR_NAME, \"cluster_uuid\", b);\n  return 0;\n}\n\n/*\n * this is the closest thing to a traditional 'mkfs' for ceph.\n * initialize the monitor state machines to their initial values.\n */\nint Monitor::mkfs(bufferlist& osdmapbl)\n{\n  auto t(std::make_shared<MonitorDBStore::Transaction>());\n\n  // verify cluster fsid\n  int r = check_fsid();\n  if (r < 0 && r != -ENOENT)\n    return r;\n\n  bufferlist magicbl;\n  magicbl.append(CEPH_MON_ONDISK_MAGIC);\n  magicbl.append(\"\\n\");\n  t->put(MONITOR_NAME, \"magic\", magicbl);\n\n\n  features = get_initial_supported_features();\n  write_features(t);\n\n  // save monmap, osdmap, keyring.\n  bufferlist monmapbl;\n  monmap->encode(monmapbl, CEPH_FEATURES_ALL);\n  monmap->set_epoch(0);     // must be 0 to avoid confusing first MonmapMonitor::update_from_paxos()\n  t->put(\"mkfs\", \"monmap\", monmapbl);\n\n  if (osdmapbl.length()) {\n    // make sure it's a valid osdmap\n    try {\n      OSDMap om;\n      om.decode(osdmapbl);\n    }\n    catch (buffer::error& e) {\n      derr << \"error decoding provided osdmap: \" << e.what() << dendl;\n      return -EINVAL;\n    }\n    t->put(\"mkfs\", \"osdmap\", osdmapbl);\n  }\n\n  if (is_keyring_required()) {\n    KeyRing keyring;\n    string keyring_filename;\n\n    r = ceph_resolve_file_search(g_conf->keyring, keyring_filename);\n    if (r) {\n      derr << \"unable to find a keyring file on \" << g_conf->keyring\n\t   << \": \" << cpp_strerror(r) << dendl;\n      if (g_conf->key != \"\") {\n\tstring keyring_plaintext = \"[mon.]\\n\\tkey = \" + g_conf->key +\n\t  \"\\n\\tcaps mon = \\\"allow *\\\"\\n\";\n\tbufferlist bl;\n\tbl.append(keyring_plaintext);\n\ttry {\n\t  bufferlist::iterator i = bl.begin();\n\t  keyring.decode_plaintext(i);\n\t}\n\tcatch (const buffer::error& e) {\n\t  derr << \"error decoding keyring \" << keyring_plaintext\n\t       << \": \" << e.what() << dendl;\n\t  return -EINVAL;\n\t}\n      } else {\n\treturn -ENOENT;\n      }\n    } else {\n      r = keyring.load(g_ceph_context, keyring_filename);\n      if (r < 0) {\n\tderr << \"unable to load initial keyring \" << g_conf->keyring << dendl;\n\treturn r;\n      }\n    }\n\n    // put mon. key in external keyring; seed with everything else.\n    extract_save_mon_key(keyring);\n\n    bufferlist keyringbl;\n    keyring.encode_plaintext(keyringbl);\n    t->put(\"mkfs\", \"keyring\", keyringbl);\n  }\n  write_fsid(t);\n  store->apply_transaction(t);\n\n  return 0;\n}\n\nint Monitor::write_default_keyring(bufferlist& bl)\n{\n  ostringstream os;\n  os << g_conf->mon_data << \"/keyring\";\n\n  int err = 0;\n  int fd = ::open(os.str().c_str(), O_WRONLY|O_CREAT, 0600);\n  if (fd < 0) {\n    err = -errno;\n    dout(0) << __func__ << \" failed to open \" << os.str() \n\t    << \": \" << cpp_strerror(err) << dendl;\n    return err;\n  }\n\n  err = bl.write_fd(fd);\n  if (!err)\n    ::fsync(fd);\n  VOID_TEMP_FAILURE_RETRY(::close(fd));\n\n  return err;\n}\n\nvoid Monitor::extract_save_mon_key(KeyRing& keyring)\n{\n  EntityName mon_name;\n  mon_name.set_type(CEPH_ENTITY_TYPE_MON);\n  EntityAuth mon_key;\n  if (keyring.get_auth(mon_name, mon_key)) {\n    dout(10) << \"extract_save_mon_key moving mon. key to separate keyring\" << dendl;\n    KeyRing pkey;\n    pkey.add(mon_name, mon_key);\n    bufferlist bl;\n    pkey.encode_plaintext(bl);\n    write_default_keyring(bl);\n    keyring.remove(mon_name);\n  }\n}\n\nbool Monitor::ms_get_authorizer(int service_id, AuthAuthorizer **authorizer,\n\t\t\t\tbool force_new)\n{\n  dout(10) << \"ms_get_authorizer for \" << ceph_entity_type_name(service_id)\n\t   << dendl;\n\n  if (is_shutdown())\n    return false;\n\n  // we only connect to other monitors and mgr; every else connects to us.\n  if (service_id != CEPH_ENTITY_TYPE_MON &&\n      service_id != CEPH_ENTITY_TYPE_MGR)\n    return false;\n\n  if (!auth_cluster_required.is_supported_auth(CEPH_AUTH_CEPHX)) {\n    // auth_none\n    dout(20) << __func__ << \" building auth_none authorizer\" << dendl;\n    AuthNoneClientHandler handler(g_ceph_context, nullptr);\n    handler.set_global_id(0);\n    *authorizer = handler.build_authorizer(service_id);\n    return true;\n  }\n\n  CephXServiceTicketInfo auth_ticket_info;\n  CephXSessionAuthInfo info;\n  int ret;\n\n  EntityName name;\n  name.set_type(CEPH_ENTITY_TYPE_MON);\n  auth_ticket_info.ticket.name = name;\n  auth_ticket_info.ticket.global_id = 0;\n\n  if (service_id == CEPH_ENTITY_TYPE_MON) {\n    // mon to mon authentication uses the private monitor shared key and not the\n    // rotating key\n    CryptoKey secret;\n    if (!keyring.get_secret(name, secret) &&\n\t!key_server.get_secret(name, secret)) {\n      dout(0) << \" couldn't get secret for mon service from keyring or keyserver\"\n\t      << dendl;\n      stringstream ss, ds;\n      int err = key_server.list_secrets(ds);\n      if (err < 0)\n\tss << \"no installed auth entries!\";\n      else\n\tss << \"installed auth entries:\";\n      dout(0) << ss.str() << \"\\n\" << ds.str() << dendl;\n      return false;\n    }\n\n    ret = key_server.build_session_auth_info(service_id, auth_ticket_info, info,\n\t\t\t\t\t     secret, (uint64_t)-1);\n    if (ret < 0) {\n      dout(0) << __func__ << \" failed to build mon session_auth_info \"\n\t      << cpp_strerror(ret) << dendl;\n      return false;\n    }\n  } else if (service_id == CEPH_ENTITY_TYPE_MGR) {\n    // mgr\n    ret = key_server.build_session_auth_info(service_id, auth_ticket_info, info);\n    if (ret < 0) {\n      derr << __func__ << \" failed to build mgr service session_auth_info \"\n\t   << cpp_strerror(ret) << dendl;\n      return false;\n    }\n  } else {\n    ceph_abort();  // see check at top of fn\n  }\n\n  CephXTicketBlob blob;\n  if (!cephx_build_service_ticket_blob(cct, info, blob)) {\n    dout(0) << \"ms_get_authorizer failed to build service ticket\" << dendl;\n    return false;\n  }\n  bufferlist ticket_data;\n  ::encode(blob, ticket_data);\n\n  bufferlist::iterator iter = ticket_data.begin();\n  CephXTicketHandler handler(g_ceph_context, service_id);\n  ::decode(handler.ticket, iter);\n\n  handler.session_key = info.session_key;\n\n  *authorizer = handler.build_authorizer(0);\n  \n  return true;\n}\n\nbool Monitor::ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t\t   int protocol, bufferlist& authorizer_data,\n\t\t\t\t   bufferlist& authorizer_reply,\n\t\t\t\t   bool& isvalid, CryptoKey& session_key)\n{\n  dout(10) << \"ms_verify_authorizer \" << con->get_peer_addr()\n\t   << \" \" << ceph_entity_type_name(peer_type)\n\t   << \" protocol \" << protocol << dendl;\n\n  if (is_shutdown())\n    return false;\n\n  if (peer_type == CEPH_ENTITY_TYPE_MON &&\n      auth_cluster_required.is_supported_auth(CEPH_AUTH_CEPHX)) {\n    // monitor, and cephx is enabled\n    isvalid = false;\n    if (protocol == CEPH_AUTH_CEPHX) {\n      bufferlist::iterator iter = authorizer_data.begin();\n      CephXServiceTicketInfo auth_ticket_info;\n      \n      if (authorizer_data.length()) {\n\tbool ret = cephx_verify_authorizer(g_ceph_context, &keyring, iter,\n\t\t\t\t\t  auth_ticket_info, authorizer_reply);\n\tif (ret) {\n\t  session_key = auth_ticket_info.session_key;\n\t  isvalid = true;\n\t} else {\n\t  dout(0) << \"ms_verify_authorizer bad authorizer from mon \" << con->get_peer_addr() << dendl;\n        }\n      }\n    } else {\n      dout(0) << \"ms_verify_authorizer cephx enabled, but no authorizer (required for mon)\" << dendl;\n    }\n  } else {\n    // who cares.\n    isvalid = true;\n  }\n  return true;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n/* \n * This is the top level monitor. It runs on each machine in the Monitor   \n * Cluster. The election of a leader for the paxos algorithm only happens \n * once per machine via the elector. There is a separate paxos instance (state) \n * kept for each of the system components: Object Store Device (OSD) Monitor, \n * Placement Group (PG) Monitor, Metadata Server (MDS) Monitor, and Client Monitor.\n */\n\n#ifndef CEPH_MONITOR_H\n#define CEPH_MONITOR_H\n\n#include <errno.h>\n#include <cmath>\n\n#include \"include/types.h\"\n#include \"include/health.h\"\n#include \"msg/Messenger.h\"\n\n#include \"common/Timer.h\"\n\n#include \"health_check.h\"\n#include \"MonMap.h\"\n#include \"Elector.h\"\n#include \"Paxos.h\"\n#include \"Session.h\"\n#include \"PGStatService.h\"\n#include \"MonCommand.h\"\n\n#include \"common/LogClient.h\"\n#include \"auth/cephx/CephxKeyServer.h\"\n#include \"auth/AuthMethodList.h\"\n#include \"auth/KeyRing.h\"\n#include \"messages/MMonCommand.h\"\n#include \"mon/MonitorDBStore.h\"\n#include \"include/memory.h\"\n#include \"mgr/MgrClient.h\"\n\n#include \"mon/MonOpRequest.h\"\n#include \"common/WorkQueue.h\"\n\n\n#define CEPH_MON_PROTOCOL     13 /* cluster internal */\n\n\nenum {\n  l_cluster_first = 555000,\n  l_cluster_num_mon,\n  l_cluster_num_mon_quorum,\n  l_cluster_num_osd,\n  l_cluster_num_osd_up,\n  l_cluster_num_osd_in,\n  l_cluster_osd_epoch,\n  l_cluster_osd_bytes,\n  l_cluster_osd_bytes_used,\n  l_cluster_osd_bytes_avail,\n  l_cluster_num_pool,\n  l_cluster_num_pg,\n  l_cluster_num_pg_active_clean,\n  l_cluster_num_pg_active,\n  l_cluster_num_pg_peering,\n  l_cluster_num_object,\n  l_cluster_num_object_degraded,\n  l_cluster_num_object_misplaced,\n  l_cluster_num_object_unfound,\n  l_cluster_num_bytes,\n  l_cluster_num_mds_up,\n  l_cluster_num_mds_in,\n  l_cluster_num_mds_failed,\n  l_cluster_mds_epoch,\n  l_cluster_last,\n};\n\nenum {\n  l_mon_first = 456000,\n  l_mon_num_sessions,\n  l_mon_session_add,\n  l_mon_session_rm,\n  l_mon_session_trim,\n  l_mon_num_elections,\n  l_mon_election_call,\n  l_mon_election_win,\n  l_mon_election_lose,\n  l_mon_last,\n};\n\nclass QuorumService;\nclass PaxosService;\n\nclass PerfCounters;\nclass AdminSocketHook;\n\nclass MMonGetMap;\nclass MMonGetVersion;\nclass MMonMetadata;\nclass MMonSync;\nclass MMonScrub;\nclass MMonProbe;\nstruct MMonSubscribe;\nstruct MRoute;\nstruct MForward;\nstruct MTimeCheck;\nstruct MMonHealth;\n\n#define COMPAT_SET_LOC \"feature_set\"\n\nclass C_MonContext final : public FunctionContext {\n  const Monitor *mon;\npublic:\n  explicit C_MonContext(Monitor *m, boost::function<void(int)>&& callback)\n    : FunctionContext(std::move(callback)), mon(m) {}\n  void finish(int r) override;\n};\n\nclass Monitor : public Dispatcher,\n                public md_config_obs_t {\npublic:\n  // me\n  string name;\n  int rank;\n  Messenger *messenger;\n  ConnectionRef con_self;\n  Mutex lock;\n  SafeTimer timer;\n  Finisher finisher;\n  ThreadPool cpu_tp;  ///< threadpool for CPU intensive work\n  \n  /// true if we have ever joined a quorum.  if false, we are either a\n  /// new cluster, a newly joining monitor, or a just-upgraded\n  /// monitor.\n  bool has_ever_joined;\n\n  PerfCounters *logger, *cluster_logger;\n  bool cluster_logger_registered;\n\n  void register_cluster_logger();\n  void unregister_cluster_logger();\n\n  MonMap *monmap;\n  uuid_d fingerprint;\n\n  set<entity_addr_t> extra_probe_peers;\n\n  LogClient log_client;\n  LogChannelRef clog;\n  LogChannelRef audit_clog;\n  KeyRing keyring;\n  KeyServer key_server;\n\n  AuthMethodList auth_cluster_required;\n  AuthMethodList auth_service_required;\n\n  CompatSet features;\n\n  vector<MonCommand> leader_mon_commands; // quorum leader's commands\n  vector<MonCommand> local_mon_commands;  // commands i support\n  bufferlist local_mon_commands_bl;       // encoded version of above\n\n  // for upgrading mon cluster that still uses PGMonitor\n  vector<MonCommand> local_upgrading_mon_commands;  // mixed mon cluster commands\n  bufferlist local_upgrading_mon_commands_bl;       // encoded version of above\n\n  Messenger *mgr_messenger;\n  MgrClient mgr_client;\n  uint64_t mgr_proxy_bytes = 0;  // in-flight proxied mgr command message bytes\n\n  const MonPGStatService *pgservice;\n\nprivate:\n  void new_tick();\n\n  // -- local storage --\npublic:\n  MonitorDBStore *store;\n  static const string MONITOR_NAME;\n  static const string MONITOR_STORE_PREFIX;\n\n  // -- monitor state --\nprivate:\n  enum {\n    STATE_PROBING = 1,\n    STATE_SYNCHRONIZING,\n    STATE_ELECTING,\n    STATE_LEADER,\n    STATE_PEON,\n    STATE_SHUTDOWN\n  };\n  int state;\n\npublic:\n  static const char *get_state_name(int s) {\n    switch (s) {\n    case STATE_PROBING: return \"probing\";\n    case STATE_SYNCHRONIZING: return \"synchronizing\";\n    case STATE_ELECTING: return \"electing\";\n    case STATE_LEADER: return \"leader\";\n    case STATE_PEON: return \"peon\";\n    case STATE_SHUTDOWN: return \"shutdown\";\n    default: return \"???\";\n    }\n  }\n  const char *get_state_name() const {\n    return get_state_name(state);\n  }\n\n  bool is_shutdown() const { return state == STATE_SHUTDOWN; }\n  bool is_probing() const { return state == STATE_PROBING; }\n  bool is_synchronizing() const { return state == STATE_SYNCHRONIZING; }\n  bool is_electing() const { return state == STATE_ELECTING; }\n  bool is_leader() const { return state == STATE_LEADER; }\n  bool is_peon() const { return state == STATE_PEON; }\n\n  const utime_t &get_leader_since() const;\n\n  void prepare_new_fingerprint(MonitorDBStore::TransactionRef t);\n\n  // -- elector --\nprivate:\n  Paxos *paxos;\n  Elector elector;\n  friend class Elector;\n\n  /// features we require of peers (based on on-disk compatset)\n  uint64_t required_features;\n  \n  int leader;            // current leader (to best of knowledge)\n  set<int> quorum;       // current active set of monitors (if !starting)\n  utime_t leader_since;  // when this monitor became the leader, if it is the leader\n  utime_t exited_quorum; // time detected as not in quorum; 0 if in\n\n  // map of counts of connected clients, by type and features, for\n  // each quorum mon\n  map<int,FeatureMap> quorum_feature_map;\n\n  /**\n   * Intersection of quorum member's connection feature bits.\n   */\n  uint64_t quorum_con_features;\n  /**\n   * Intersection of quorum members mon-specific feature bits\n   */\n  mon_feature_t quorum_mon_features;\n\n  set<string> outside_quorum;\n\n  /**\n   * @defgroup Monitor_h_scrub\n   * @{\n   */\n  version_t scrub_version;            ///< paxos version we are scrubbing\n  map<int,ScrubResult> scrub_result;  ///< results so far\n\n  /**\n   * trigger a cross-mon scrub\n   *\n   * Verify all mons are storing identical content\n   */\n  int scrub_start();\n  int scrub();\n  void handle_scrub(MonOpRequestRef op);\n  bool _scrub(ScrubResult *r,\n              pair<string,string> *start,\n              int *num_keys);\n  void scrub_check_results();\n  void scrub_timeout();\n  void scrub_finish();\n  void scrub_reset();\n  void scrub_update_interval(int secs);\n\n  Context *scrub_event;       ///< periodic event to trigger scrub (leader)\n  Context *scrub_timeout_event;  ///< scrub round timeout (leader)\n  void scrub_event_start();\n  void scrub_event_cancel();\n  void scrub_reset_timeout();\n  void scrub_cancel_timeout();\n\n  struct ScrubState {\n    pair<string,string> last_key; ///< last scrubbed key\n    bool finished;\n\n    ScrubState() : finished(false) { }\n    virtual ~ScrubState() { }\n  };\n  ceph::shared_ptr<ScrubState> scrub_state; ///< keeps track of current scrub\n\n  /**\n   * @defgroup Monitor_h_sync Synchronization\n   * @{\n   */\n  /**\n   * @} // provider state\n   */\n  struct SyncProvider {\n    entity_inst_t entity;  ///< who\n    uint64_t cookie;       ///< unique cookie for this sync attempt\n    utime_t timeout;       ///< when we give up and expire this attempt\n    version_t last_committed; ///< last paxos version on peer\n    pair<string,string> last_key; ///< last key sent to (or on) peer\n    bool full;             ///< full scan?\n    MonitorDBStore::Synchronizer synchronizer;   ///< iterator\n\n    SyncProvider() : cookie(0), last_committed(0), full(false) {}\n\n    void reset_timeout(CephContext *cct, int grace) {\n      timeout = ceph_clock_now();\n      timeout += grace;\n    }\n  };\n\n  map<uint64_t, SyncProvider> sync_providers;  ///< cookie -> SyncProvider for those syncing from us\n  uint64_t sync_provider_count;   ///< counter for issued cookies to keep them unique\n\n  /**\n   * @} // requester state\n   */\n  entity_inst_t sync_provider;   ///< who we are syncing from\n  uint64_t sync_cookie;          ///< 0 if we are starting, non-zero otherwise\n  bool sync_full;                ///< true if we are a full sync, false for recent catch-up\n  version_t sync_start_version;  ///< last_committed at sync start\n  Context *sync_timeout_event;   ///< timeout event\n\n  /**\n   * floor for sync source\n   *\n   * When we sync we forget about our old last_committed value which\n   * can be dangerous.  For example, if we have a cluster of:\n   *\n   *   mon.a: lc 100\n   *   mon.b: lc 80\n   *   mon.c: lc 100 (us)\n   *\n   * If something forces us to sync (say, corruption, or manual\n   * intervention, or bug), we forget last_committed, and might abort.\n   * If mon.a happens to be down when we come back, we will see:\n   *\n   *   mon.b: lc 80\n   *   mon.c: lc 0 (us)\n   *\n   * and sync from mon.b, at which point a+b will both have lc 80 and\n   * come online with a majority holding out of date commits.\n   *\n   * Avoid this by preserving our old last_committed value prior to\n   * sync and never going backwards.\n   */\n  version_t sync_last_committed_floor;\n\n  /**\n   * Obtain the synchronization target prefixes in set form.\n   *\n   * We consider a target prefix all those that are relevant when\n   * synchronizing two stores. That is, all those that hold paxos service's\n   * versions, as well as paxos versions, or any control keys such as the\n   * first or last committed version.\n   *\n   * Given the current design, this function should return the name of all and\n   * any available paxos service, plus the paxos name.\n   *\n   * @returns a set of strings referring to the prefixes being synchronized\n   */\n  set<string> get_sync_targets_names();\n\n  /**\n   * Reset the monitor's sync-related data structures for syncing *from* a peer\n   */\n  void sync_reset_requester();\n\n  /**\n   * Reset sync state related to allowing others to sync from us\n   */\n  void sync_reset_provider();\n\n  /**\n   * Caled when a sync attempt times out (requester-side)\n   */\n  void sync_timeout();\n\n  /**\n   * Get the latest monmap for backup purposes during sync\n   */\n  void sync_obtain_latest_monmap(bufferlist &bl);\n\n  /**\n   * Start sync process\n   *\n   * Start pulling committed state from another monitor.\n   *\n   * @param entity where to pull committed state from\n   * @param full whether to do a full sync or just catch up on recent paxos\n   */\n  void sync_start(entity_inst_t &entity, bool full);\n\npublic:\n  /**\n   * force a sync on next mon restart\n   */\n  void sync_force(Formatter *f, ostream& ss);\n\nprivate:\n  /**\n   * store critical state for safekeeping during sync\n   *\n   * We store a few things on the side that we don't want to get clobbered by sync.  This\n   * includes the latest monmap and a lower bound on last_committed.\n   */\n  void sync_stash_critical_state(MonitorDBStore::TransactionRef tx);\n\n  /**\n   * reset the sync timeout\n   *\n   * This is used on the client to restart if things aren't progressing\n   */\n  void sync_reset_timeout();\n\n  /**\n   * trim stale sync provider state\n   *\n   * If someone is syncing from us and hasn't talked to us recently, expire their state.\n   */\n  void sync_trim_providers();\n\n  /**\n   * Complete a sync\n   *\n   * Finish up a sync after we've gotten all of the chunks.\n   *\n   * @param last_committed final last_committed value from provider\n   */\n  void sync_finish(version_t last_committed);\n\n  /**\n   * request the next chunk from the provider\n   */\n  void sync_get_next_chunk();\n\n  /**\n   * handle sync message\n   *\n   * @param m Sync message with operation type MMonSync::OP_START_CHUNKS\n   */\n  void handle_sync(MonOpRequestRef op);\n\n  void _sync_reply_no_cookie(MonOpRequestRef op);\n\n  void handle_sync_get_cookie(MonOpRequestRef op);\n  void handle_sync_get_chunk(MonOpRequestRef op);\n  void handle_sync_finish(MonOpRequestRef op);\n\n  void handle_sync_cookie(MonOpRequestRef op);\n  void handle_sync_forward(MonOpRequestRef op);\n  void handle_sync_chunk(MonOpRequestRef op);\n  void handle_sync_no_cookie(MonOpRequestRef op);\n\n  /**\n   * @} // Synchronization\n   */\n\n  list<Context*> waitfor_quorum;\n  list<Context*> maybe_wait_for_quorum;\n\n  /**\n   * @defgroup Monitor_h_TimeCheck Monitor Clock Drift Early Warning System\n   * @{\n   *\n   * We use time checks to keep track of any clock drifting going on in the\n   * cluster. This is accomplished by periodically ping each monitor in the\n   * quorum and register its response time on a map, assessing how much its\n   * clock has drifted. We also take this opportunity to assess the latency\n   * on response.\n   *\n   * This mechanism works as follows:\n   *\n   *  - Leader sends out a 'PING' message to each other monitor in the quorum.\n   *    The message is timestamped with the leader's current time. The leader's\n   *    current time is recorded in a map, associated with each peon's\n   *    instance.\n   *  - The peon replies to the leader with a timestamped 'PONG' message.\n   *  - The leader calculates a delta between the peon's timestamp and its\n   *    current time and stashes it.\n   *  - The leader also calculates the time it took to receive the 'PONG'\n   *    since the 'PING' was sent, and stashes an approximate latency estimate.\n   *  - Once all the quorum members have pong'ed, the leader will share the\n   *    clock skew and latency maps with all the monitors in the quorum.\n   */\n  map<entity_inst_t, utime_t> timecheck_waiting;\n  map<entity_inst_t, double> timecheck_skews;\n  map<entity_inst_t, double> timecheck_latencies;\n  // odd value means we are mid-round; even value means the round has\n  // finished.\n  version_t timecheck_round;\n  unsigned int timecheck_acks;\n  utime_t timecheck_round_start;\n  friend class HealthMonitor;\n  /* When we hit a skew we will start a new round based off of\n   * 'mon_timecheck_skew_interval'. Each new round will be backed off\n   * until we hit 'mon_timecheck_interval' -- which is the typical\n   * interval when not in the presence of a skew.\n   *\n   * This variable tracks the number of rounds with skews since last clean\n   * so that we can report to the user and properly adjust the backoff.\n   */\n  uint64_t timecheck_rounds_since_clean;\n  /**\n   * Time Check event.\n   */\n  Context *timecheck_event;\n\n  void timecheck_start();\n  void timecheck_finish();\n  void timecheck_start_round();\n  void timecheck_finish_round(bool success = true);\n  void timecheck_cancel_round();\n  void timecheck_cleanup();\n  void timecheck_reset_event();\n  void timecheck_check_skews();\n  void timecheck_report();\n  void timecheck();\n  health_status_t timecheck_status(ostringstream &ss,\n                                   const double skew_bound,\n                                   const double latency);\n  void handle_timecheck_leader(MonOpRequestRef op);\n  void handle_timecheck_peon(MonOpRequestRef op);\n  void handle_timecheck(MonOpRequestRef op);\n\n  /**\n   * Returns 'true' if this is considered to be a skew; 'false' otherwise.\n   */\n  bool timecheck_has_skew(const double skew_bound, double *abs) const {\n    double abs_skew = std::fabs(skew_bound);\n    if (abs)\n      *abs = abs_skew;\n    return (abs_skew > g_conf->mon_clock_drift_allowed);\n  }\n\n  /**\n   * @}\n   */\n  /**\n   * Handle ping messages from others.\n   */\n  void handle_ping(MonOpRequestRef op);\n\n  Context *probe_timeout_event = nullptr;  // for probing\n\n  void reset_probe_timeout();\n  void cancel_probe_timeout();\n  void probe_timeout(int r);\n\n  void _apply_compatset_features(CompatSet &new_features);\n\npublic:\n  epoch_t get_epoch();\n  int get_leader() const { return leader; }\n  string get_leader_name() {\n    return quorum.empty() ? string() : monmap->get_name(*quorum.begin());\n  }\n  const set<int>& get_quorum() const { return quorum; }\n  list<string> get_quorum_names() {\n    list<string> q;\n    for (set<int>::iterator p = quorum.begin(); p != quorum.end(); ++p)\n      q.push_back(monmap->get_name(*p));\n    return q;\n  }\n  uint64_t get_quorum_con_features() const {\n    return quorum_con_features;\n  }\n  mon_feature_t get_quorum_mon_features() const {\n    return quorum_mon_features;\n  }\n  uint64_t get_required_features() const {\n    return required_features;\n  }\n  mon_feature_t get_required_mon_features() const {\n    return monmap->get_required_features();\n  }\n  void apply_quorum_to_compatset_features();\n  void apply_monmap_to_compatset_features();\n  void calc_quorum_requirements();\n\n  void get_combined_feature_map(FeatureMap *fm);\n\nprivate:\n  void _reset();   ///< called from bootstrap, start_, or join_election\n  void wait_for_paxos_write();\n  void _finish_svc_election(); ///< called by {win,lose}_election\npublic:\n  void bootstrap();\n  void join_election();\n  void start_election();\n  void win_standalone_election();\n  // end election (called by Elector)\n  void win_election(epoch_t epoch, set<int>& q,\n\t\t    uint64_t features,\n                    const mon_feature_t& mon_features,\n\t\t    const map<int,Metadata>& metadata);\n  void lose_election(epoch_t epoch, set<int>& q, int l,\n\t\t     uint64_t features,\n                     const mon_feature_t& mon_features);\n  // end election (called by Elector)\n  void finish_election();\n\n  void update_logger();\n\n  /**\n   * Vector holding the Services serviced by this Monitor.\n   */\n  vector<PaxosService*> paxos_service;\n\n  class PGMonitor *pgmon() {\n    return (class PGMonitor *)paxos_service[PAXOS_PGMAP];\n  }\n\n  class MDSMonitor *mdsmon() {\n    return (class MDSMonitor *)paxos_service[PAXOS_MDSMAP];\n  }\n\n  class MonmapMonitor *monmon() {\n    return (class MonmapMonitor *)paxos_service[PAXOS_MONMAP];\n  }\n\n  class OSDMonitor *osdmon() {\n    return (class OSDMonitor *)paxos_service[PAXOS_OSDMAP];\n  }\n\n  class AuthMonitor *authmon() {\n    return (class AuthMonitor *)paxos_service[PAXOS_AUTH];\n  }\n\n  class LogMonitor *logmon() {\n    return (class LogMonitor*) paxos_service[PAXOS_LOG];\n  }\n\n  class MgrMonitor *mgrmon() {\n    return (class MgrMonitor*) paxos_service[PAXOS_MGR];\n  }\n\n  class MgrStatMonitor *mgrstatmon() {\n    return (class MgrStatMonitor*) paxos_service[PAXOS_MGRSTAT];\n  }\n\n  class HealthMonitor *healthmon() {\n    return (class HealthMonitor*) paxos_service[PAXOS_HEALTH];\n  }\n\n  friend class Paxos;\n  friend class OSDMonitor;\n  friend class MDSMonitor;\n  friend class MonmapMonitor;\n  friend class PGMonitor;\n  friend class LogMonitor;\n  friend class ConfigKeyService;\n\n  QuorumService *health_monitor;\n  QuorumService *config_key_service;\n\n  // -- sessions --\n  MonSessionMap session_map;\n  Mutex session_map_lock{\"Monitor::session_map_lock\"};\n  AdminSocketHook *admin_hook;\n\n  template<typename Func, typename...Args>\n  void with_session_map(Func&& func) {\n    Mutex::Locker l(session_map_lock);\n    std::forward<Func>(func)(session_map);\n  }\n  void send_latest_monmap(Connection *con);\n\n  // messages\n  void handle_get_version(MonOpRequestRef op);\n  void handle_subscribe(MonOpRequestRef op);\n  void handle_mon_get_map(MonOpRequestRef op);\n\n  static void _generate_command_map(map<string,cmd_vartype>& cmdmap,\n                                    map<string,string> &param_str_map);\n  static const MonCommand *_get_moncommand(\n    const string &cmd_prefix,\n    const vector<MonCommand>& cmds);\n  bool _allowed_command(MonSession *s, string &module, string &prefix,\n                        const map<string,cmd_vartype>& cmdmap,\n                        const map<string,string>& param_str_map,\n                        const MonCommand *this_cmd);\n  void get_mon_status(Formatter *f, ostream& ss);\n  void _quorum_status(Formatter *f, ostream& ss);\n  bool _add_bootstrap_peer_hint(string cmd, cmdmap_t& cmdmap, ostream& ss);\n  void handle_command(MonOpRequestRef op);\n  void handle_route(MonOpRequestRef op);\n\n  void handle_mon_metadata(MonOpRequestRef op);\n  int get_mon_metadata(int mon, Formatter *f, ostream& err);\n  int print_nodes(Formatter *f, ostream& err);\n\n  // Accumulate metadata across calls to update_mon_metadata\n  map<int, Metadata> mon_metadata;\n  map<int, Metadata> pending_metadata;\n\n  /**\n   *\n   */\n  struct health_cache_t {\n    health_status_t overall;\n    string summary;\n\n    void reset() {\n      // health_status_t doesn't really have a NONE value and we're not\n      // okay with setting something else (say, HEALTH_ERR).  so just\n      // leave it be.\n      summary.clear();\n    }\n  } health_status_cache;\n\n  Context *health_tick_event = nullptr;\n  Context *health_interval_event = nullptr;\n\n  void health_tick_start();\n  void health_tick_stop();\n  utime_t health_interval_calc_next_update();\n  void health_interval_start();\n  void health_interval_stop();\n  void health_events_cleanup();\n\n  void health_to_clog_update_conf(const std::set<std::string> &changed);\n\n  void do_health_to_clog_interval();\n  void do_health_to_clog(bool force = false);\n\n  /**\n   * Generate health report\n   *\n   * @param status one-line status summary\n   * @param detailbl optional bufferlist* to fill with a detailed report\n   * @returns health status\n   */\n  health_status_t get_health(list<string>& status, bufferlist *detailbl,\n                             Formatter *f);\n\n  health_status_t get_health_status(\n    bool want_detail,\n    Formatter *f,\n    std::string *plain,\n    const char *sep1 = \" \",\n    const char *sep2 = \"; \");\n  void log_health(\n    const health_check_map_t& updated,\n    const health_check_map_t& previous,\n    MonitorDBStore::TransactionRef t);\n\nprotected:\n\n  class HealthCheckLogStatus {\n    public:\n    health_status_t severity;\n    std::string last_message;\n    utime_t updated_at = 0;\n    HealthCheckLogStatus(health_status_t severity_,\n                         const std::string &last_message_,\n                         utime_t updated_at_)\n      : severity(severity_),\n        last_message(last_message_),\n        updated_at(updated_at_)\n    {}\n  };\n  std::map<std::string, HealthCheckLogStatus> health_check_log_times;\n\npublic:\n\n  void get_cluster_status(stringstream &ss, Formatter *f);\n\n  void reply_command(MonOpRequestRef op, int rc, const string &rs, version_t version);\n  void reply_command(MonOpRequestRef op, int rc, const string &rs, bufferlist& rdata, version_t version);\n\n\n  void handle_probe(MonOpRequestRef op);\n  /**\n   * Handle a Probe Operation, replying with our name, quorum and known versions.\n   *\n   * We use the MMonProbe message class for anything and everything related with\n   * Monitor probing. One of the operations relates directly with the probing\n   * itself, in which we receive a probe request and to which we reply with\n   * our name, our quorum and the known versions for each Paxos service. Thus the\n   * redundant function name. This reply will obviously be sent to the one\n   * probing/requesting these infos.\n   *\n   * @todo Add @pre and @post\n   *\n   * @param m A Probe message, with an operation of type Probe.\n   */\n  void handle_probe_probe(MonOpRequestRef op);\n  void handle_probe_reply(MonOpRequestRef op);\n\n  // request routing\n  struct RoutedRequest {\n    uint64_t tid;\n    bufferlist request_bl;\n    MonSession *session;\n    ConnectionRef con;\n    uint64_t con_features;\n    entity_inst_t client_inst;\n    MonOpRequestRef op;\n\n    RoutedRequest() : tid(0), session(NULL), con_features(0) {}\n    ~RoutedRequest() {\n      if (session)\n\tsession->put();\n    }\n  };\n  uint64_t routed_request_tid;\n  map<uint64_t, RoutedRequest*> routed_requests;\n  \n  void forward_request_leader(MonOpRequestRef op);\n  void handle_forward(MonOpRequestRef op);\n  void try_send_message(Message *m, const entity_inst_t& to);\n  void send_reply(MonOpRequestRef op, Message *reply);\n  void no_reply(MonOpRequestRef op);\n  void resend_routed_requests();\n  void remove_session(MonSession *s);\n  void remove_all_sessions();\n  void waitlist_or_zap_client(MonOpRequestRef op);\n\n  void send_command(const entity_inst_t& inst,\n\t\t    const vector<string>& com);\n\npublic:\n  struct C_Command : public C_MonOp {\n    Monitor *mon;\n    int rc;\n    string rs;\n    bufferlist rdata;\n    version_t version;\n    C_Command(Monitor *_mm, MonOpRequestRef _op, int r, string s, version_t v) :\n      C_MonOp(_op), mon(_mm), rc(r), rs(s), version(v){}\n    C_Command(Monitor *_mm, MonOpRequestRef _op, int r, string s, bufferlist rd, version_t v) :\n      C_MonOp(_op), mon(_mm), rc(r), rs(s), rdata(rd), version(v){}\n\n    void _finish(int r) override {\n      MMonCommand *m = static_cast<MMonCommand*>(op->get_req());\n      if (r >= 0) {\n        ostringstream ss;\n        if (!op->get_req()->get_connection()) {\n          ss << \"connection dropped for command \";\n        } else {\n          MonSession *s = op->get_session();\n\n          // if client drops we may not have a session to draw information from.\n          if (s) {\n            ss << \"from='\" << s->inst << \"' \"\n              << \"entity='\" << s->entity_name << \"' \";\n          } else {\n            ss << \"session dropped for command \";\n          }\n        }\n        ss << \"cmd='\" << m->cmd << \"': finished\";\n\n        mon->audit_clog->info() << ss.str();\n\tmon->reply_command(op, rc, rs, rdata, version);\n      }\n      else if (r == -ECANCELED)\n        return;\n      else if (r == -EAGAIN)\n\tmon->dispatch_op(op);\n      else\n\tassert(0 == \"bad C_Command return value\");\n    }\n  };\n\n private:\n  class C_RetryMessage : public C_MonOp {\n    Monitor *mon;\n  public:\n    C_RetryMessage(Monitor *m, MonOpRequestRef op) :\n      C_MonOp(op), mon(m) { }\n\n    void _finish(int r) override {\n      if (r == -EAGAIN || r >= 0)\n        mon->dispatch_op(op);\n      else if (r == -ECANCELED)\n        return;\n      else\n\tassert(0 == \"bad C_RetryMessage return value\");\n    }\n  };\n\n  //ms_dispatch handles a lot of logic and we want to reuse it\n  //on forwarded messages, so we create a non-locking version for this class\n  void _ms_dispatch(Message *m);\n  bool ms_dispatch(Message *m) override {\n    lock.Lock();\n    _ms_dispatch(m);\n    lock.Unlock();\n    return true;\n  }\n  void dispatch_op(MonOpRequestRef op);\n  //mon_caps is used for un-connected messages from monitors\n  MonCap * mon_caps;\n  bool ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new) override;\n  bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t    int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t    bool& isvalid, CryptoKey& session_key) override;\n  bool ms_handle_reset(Connection *con) override;\n  void ms_handle_remote_reset(Connection *con) override {}\n  bool ms_handle_refused(Connection *con) override;\n\n  int write_default_keyring(bufferlist& bl);\n  void extract_save_mon_key(KeyRing& keyring);\n\n  void collect_metadata(Metadata *m);\n  void update_mon_metadata(int from, Metadata&& m);\n  int load_metadata();\n  void count_metadata(const string& field, Formatter *f);\n  void count_metadata(const string& field, map<string,int> *out);\n\n  // features\n  static CompatSet get_initial_supported_features();\n  static CompatSet get_supported_features();\n  static CompatSet get_legacy_features();\n  /// read the ondisk features into the CompatSet pointed to by read_features\n  static void read_features_off_disk(MonitorDBStore *store, CompatSet *read_features);\n  void read_features();\n  void write_features(MonitorDBStore::TransactionRef t);\n\n  OpTracker op_tracker;\n\n public:\n  Monitor(CephContext *cct_, string nm, MonitorDBStore *s,\n\t  Messenger *m, Messenger *mgr_m, MonMap *map);\n  ~Monitor() override;\n\n  static int check_features(MonitorDBStore *store);\n\n  // config observer\n  const char** get_tracked_conf_keys() const override;\n  void handle_conf_change(const struct md_config_t *conf,\n                          const std::set<std::string> &changed) override;\n\n  void update_log_clients();\n  int sanitize_options();\n  int preinit();\n  int init();\n  void init_paxos();\n  void refresh_from_paxos(bool *need_bootstrap);\n  void shutdown();\n  void tick();\n\n  void handle_signal(int sig);\n\n  int mkfs(bufferlist& osdmapbl);\n\n  /**\n   * check cluster_fsid file\n   *\n   * @return EEXIST if file exists and doesn't match, 0 on match, or negative error code\n   */\n  int check_fsid();\n\n  /**\n   * write cluster_fsid file\n   *\n   * @return 0 on success, or negative error code\n   */\n  int write_fsid();\n  int write_fsid(MonitorDBStore::TransactionRef t);\n\n  void do_admin_command(std::string command, cmdmap_t& cmdmap,\n\t\t\tstd::string format, ostream& ss);\n\nprivate:\n  // don't allow copying\n  Monitor(const Monitor& rhs);\n  Monitor& operator=(const Monitor &rhs);\n\npublic:\n  static void format_command_descriptions(const std::vector<MonCommand> &commands,\n\t\t\t\t\t  Formatter *f,\n\t\t\t\t\t  bufferlist *rdata,\n\t\t\t\t\t  bool hide_mgr_flag=false);\n\n  const std::vector<MonCommand> &get_local_commands(mon_feature_t f) {\n    if (f.contains_all(ceph::features::mon::FEATURE_LUMINOUS))\n      return local_mon_commands;\n    else\n      return local_upgrading_mon_commands;\n  }\n  const bufferlist& get_local_commands_bl(mon_feature_t f) {\n    if (f.contains_all(ceph::features::mon::FEATURE_LUMINOUS))\n      return local_mon_commands_bl;\n    else\n      return local_upgrading_mon_commands_bl;\n  }\n  void set_leader_commands(const std::vector<MonCommand>& cmds) {\n    leader_mon_commands = cmds;\n  }\n\n  static bool is_keyring_required();\n};\n\n#define CEPH_MON_FEATURE_INCOMPAT_BASE CompatSet::Feature (1, \"initial feature set (~v.18)\")\n#define CEPH_MON_FEATURE_INCOMPAT_GV CompatSet::Feature (2, \"global version sequencing (v0.52)\")\n#define CEPH_MON_FEATURE_INCOMPAT_SINGLE_PAXOS CompatSet::Feature (3, \"single paxos with k/v store (v0.\\?)\")\n#define CEPH_MON_FEATURE_INCOMPAT_OSD_ERASURE_CODES CompatSet::Feature(4, \"support erasure code pools\")\n#define CEPH_MON_FEATURE_INCOMPAT_OSDMAP_ENC CompatSet::Feature(5, \"new-style osdmap encoding\")\n#define CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V2 CompatSet::Feature(6, \"support isa/lrc erasure code\")\n#define CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V3 CompatSet::Feature(7, \"support shec erasure code\")\n#define CEPH_MON_FEATURE_INCOMPAT_KRAKEN CompatSet::Feature(8, \"support monmap features\")\n#define CEPH_MON_FEATURE_INCOMPAT_LUMINOUS CompatSet::Feature(9, \"luminous ondisk layout\")\n// make sure you add your feature to Monitor::get_supported_features\n\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n\n#ifndef CEPH_DISPATCHER_H\n#define CEPH_DISPATCHER_H\n\n#include \"include/assert.h\"\n#include \"include/buffer_fwd.h\"\n#include \"include/assert.h\"\n\nclass Messenger;\nclass Message;\nclass Connection;\nclass AuthAuthorizer;\nclass CryptoKey;\nclass CephContext;\n\nclass Dispatcher {\npublic:\n  explicit Dispatcher(CephContext *cct_)\n    : cct(cct_)\n  {\n  }\n  virtual ~Dispatcher() { }\n\n  /**\n   * The Messenger calls this function to query if you are capable\n   * of \"fast dispatch\"ing a message. Indicating that you can fast\n   * dispatch it requires that you:\n   * 1) Handle the Message quickly and without taking long-term contended\n   * locks. (This function is likely to be called in-line with message\n   * receipt.)\n   * 2) Be able to accept the Message even if you have not yet received\n   * an ms_handle_accept() notification for the Connection it is associated\n   * with, and even if you *have* called mark_down() or received an\n   * ms_handle_reset() (or similar) call on the Connection. You will\n   * not receive more than one dead \"message\" (and should generally be\n   * prepared for that circumstance anyway, since the normal dispatch can begin,\n   * then trigger Connection failure before it's percolated through your system).\n   * We provide ms_handle_fast_[connect|accept] calls if you need them, under\n   * similar speed and state constraints as fast_dispatch itself.\n   * 3) Be able to make a determination on fast_dispatch without relying\n   * on particular system state -- the ms_can_fast_dispatch() call might\n   * be called multiple times on a single message; the state might change between\n   * calling ms_can_fast_dispatch and ms_fast_dispatch; etc.\n   *\n   * @param m The message we want to fast dispatch.\n   * @returns True if the message can be fast dispatched; false otherwise.\n   */\n  virtual bool ms_can_fast_dispatch(const Message *m) const { return false;}\n  /**\n   * This function determines if a dispatcher is included in the\n   * list of fast-dispatch capable Dispatchers.\n   * @returns True if the Dispatcher can handle any messages via\n   * fast dispatch; false otherwise.\n   */\n  virtual bool ms_can_fast_dispatch_any() const { return false; }\n  /**\n   * Perform a \"fast dispatch\" on a given message. See\n   * ms_can_fast_dispatch() for the requirements.\n   *\n   * @param m The Message to fast dispatch.\n   */\n  virtual void ms_fast_dispatch(Message *m) { ceph_abort(); }\n  /**\n   * Let the Dispatcher preview a Message before it is dispatched. This\n   * function is called on *every* Message, prior to the fast/regular dispatch\n   * decision point, but it is only used on fast-dispatch capable systems. An\n   * implementation of ms_fast_preprocess must be essentially lock-free in the\n   * same way as the ms_fast_dispatch function is (in particular, ms_fast_preprocess\n   * may be called while the Messenger holds internal locks that prevent progress from\n   * other threads, so any locks it takes must be at the very bottom of the hierarchy).\n   * Messages are delivered in receipt order within a single Connection, but there are\n   * no guarantees across Connections. This makes it useful for some limited\n   * coordination between Messages which can be fast_dispatch'ed and those which must\n   * go through normal dispatch.\n   *\n   * @param m A message which has been received\n   */\n  virtual void ms_fast_preprocess(Message *m) {}\n  /**\n   * The Messenger calls this function to deliver a single message.\n   *\n   * @param m The message being delivered. You (the Dispatcher)\n   * are given a single reference count on it.\n   */\n  virtual bool ms_dispatch(Message *m) = 0;\n\n  /**\n   * This function will be called whenever a Connection is newly-created\n   * or reconnects in the Messenger.\n   *\n   * @param con The new Connection which has been established. You are not\n   * granted a reference to it -- take one if you need one!\n   */\n  virtual void ms_handle_connect(Connection *con) {}\n\n  /**\n   * This function will be called synchronously whenever a Connection is\n   * newly-created or reconnects in the Messenger, if you support fast\n   * dispatch. It is guaranteed to be called before any messages are\n   * dispatched.\n   *\n   * @param con The new Connection which has been established. You are not\n   * granted a reference to it -- take one if you need one!\n   */\n  virtual void ms_handle_fast_connect(Connection *con) {}\n\n  /**\n   * Callback indicating we have accepted an incoming connection.\n   *\n   * @param con The (new or existing) Connection associated with the session\n   */\n  virtual void ms_handle_accept(Connection *con) {}\n\n  /**\n   * Callback indicating we have accepted an incoming connection, if you\n   * support fast dispatch. It is guaranteed to be called before any messages\n   * are dispatched.\n   *\n   * @param con The (new or existing) Connection associated with the session\n   */\n  virtual void ms_handle_fast_accept(Connection *con) {}\n\n  /*\n   * this indicates that the ordered+reliable delivery semantics have \n   * been violated.  Messages may have been lost due to a fault\n   * in the network connection.\n   * Only called on lossy Connections.\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  virtual bool ms_handle_reset(Connection *con) = 0;\n\n  /**\n   * This indicates that the ordered+reliable delivery semantics\n   * have been violated because the remote somehow reset.\n   * It implies that incoming messages were dropped, and\n   * probably some of our previous outgoing messages were too.\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  virtual void ms_handle_remote_reset(Connection *con) = 0;\n  \n  /**\n   * This indicates that the connection is both broken and further\n   * connection attempts are failing because other side refuses\n   * it.\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  virtual bool ms_handle_refused(Connection *con) = 0;\n\n  /**\n   * @defgroup Authentication\n   * @{\n   */\n  /**\n   * Retrieve the AuthAuthorizer for the given peer type. It might not\n   * provide one if it knows there is no AuthAuthorizer for that type.\n   *\n   * @param dest_type The peer type we want the authorizer for.\n   * @param a Double pointer to an AuthAuthorizer. The Dispatcher will fill\n   * in *a with the correct AuthAuthorizer, if it can. Make sure that you have\n   * set *a to NULL before calling in.\n   * @param force_new Force the Dispatcher to wait for a new set of keys before\n   * returning the authorizer.\n   *\n   * @return True if this function call properly filled in *a, false otherwise.\n   */\n  virtual bool ms_get_authorizer(int dest_type, AuthAuthorizer **a, bool force_new) { return false; }\n  /**\n   * Verify the authorizer for a new incoming Connection.\n   *\n   * @param con The new incoming Connection\n   * @param peer_type The type of the endpoint which initiated this Connection\n   * @param protocol The ID of the protocol in use (at time of writing, cephx or none)\n   * @param authorizer The authorization string supplied by the remote\n   * @param authorizer_reply Output param: The string we should send back to\n   * the remote to authorize ourselves. Only filled in if isvalid\n   * @param isvalid Output param: True if authorizer is valid, false otherwise\n   *\n   * @return True if we were able to prove or disprove correctness of\n   * authorizer, false otherwise.\n   */\n  virtual bool ms_verify_authorizer(Connection *con,\n\t\t\t\t    int peer_type,\n\t\t\t\t    int protocol,\n\t\t\t\t    ceph::bufferlist& authorizer,\n\t\t\t\t    ceph::bufferlist& authorizer_reply,\n\t\t\t\t    bool& isvalid,\n\t\t\t\t    CryptoKey& session_key) { return false; }\n  /**\n   * @} //Authentication\n   */\nprotected:\n  CephContext *cct;\nprivate:\n  explicit Dispatcher(const Dispatcher &rhs);\n  Dispatcher& operator=(const Dispatcher &rhs);\n};\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n\n\n#ifndef CEPH_MESSENGER_H\n#define CEPH_MESSENGER_H\n\n#include <map>\nusing namespace std;\n\n#include \"Message.h\"\n#include \"Dispatcher.h\"\n#include \"common/Mutex.h\"\n#include \"common/Cond.h\"\n#include \"include/Context.h\"\n#include \"include/types.h\"\n#include \"include/ceph_features.h\"\n#include \"auth/Crypto.h\"\n\n#include <errno.h>\n#include <sstream>\n#include <signal.h>\n\n#define SOCKET_PRIORITY_MIN_DELAY 6\n\nclass Timer;\n\n\nclass Messenger {\nprivate:\n  list<Dispatcher*> dispatchers;\n  list <Dispatcher*> fast_dispatchers;\n  ZTracer::Endpoint trace_endpoint;\n\n  void set_endpoint_addr(const entity_addr_t& a,\n                         const entity_name_t &name);\n\nprotected:\n  /// the \"name\" of the local daemon. eg client.99\n  entity_inst_t my_inst;\n  int default_send_priority;\n  /// set to true once the Messenger has started, and set to false on shutdown\n  bool started;\n  uint32_t magic;\n  int socket_priority;\n\npublic:\n  /**\n   * Various Messenger conditional config/type flags to allow\n   * different \"transport\" Messengers to tune themselves\n   */\n  static const int HAS_HEAVY_TRAFFIC    = 0x0001;\n  static const int HAS_MANY_CONNECTIONS = 0x0002;\n  static const int HEARTBEAT            = 0x0004;\n\n  /**\n   *  The CephContext this Messenger uses. Many other components initialize themselves\n   *  from this value.\n   */\n  CephContext *cct;\n  int crcflags;\n\n  /**\n   * A Policy describes the rules of a Connection. Is there a limit on how\n   * much data this Connection can have locally? When the underlying connection\n   * experiences an error, does the Connection disappear? Can this Messenger\n   * re-establish the underlying connection?\n   */\n  struct Policy {\n    /// If true, the Connection is tossed out on errors.\n    bool lossy;\n    /// If true, the underlying connection can't be re-established from this end.\n    bool server;\n    /// If true, we will standby when idle\n    bool standby;\n    /// If true, we will try to detect session resets\n    bool resetcheck;\n    /**\n     *  The throttler is used to limit how much data is held by Messages from\n     *  the associated Connection(s). When reading in a new Message, the Messenger\n     *  will call throttler->throttle() for the size of the new Message.\n     */\n    Throttle *throttler_bytes;\n    Throttle *throttler_messages;\n\n    /// Specify features supported locally by the endpoint.\n    uint64_t features_supported;\n    /// Specify features any remotes must have to talk to this endpoint.\n    uint64_t features_required;\n\n    Policy()\n      : lossy(false), server(false), standby(false), resetcheck(true),\n\tthrottler_bytes(NULL),\n\tthrottler_messages(NULL),\n\tfeatures_supported(CEPH_FEATURES_SUPPORTED_DEFAULT),\n\tfeatures_required(0) {}\n  private:\n    Policy(bool l, bool s, bool st, bool r, uint64_t req)\n      : lossy(l), server(s), standby(st), resetcheck(r),\n\tthrottler_bytes(NULL),\n\tthrottler_messages(NULL),\n\tfeatures_supported(CEPH_FEATURES_SUPPORTED_DEFAULT),\n\tfeatures_required(req) {}\n\n  public:\n    static Policy stateful_server(uint64_t req) {\n      return Policy(false, true, true, true, req);\n    }\n    static Policy stateless_server(uint64_t req) {\n      return Policy(true, true, false, false, req);\n    }\n    static Policy lossless_peer(uint64_t req) {\n      return Policy(false, false, true, false, req);\n    }\n    static Policy lossless_peer_reuse(uint64_t req) {\n      return Policy(false, false, true, true, req);\n    }\n    static Policy lossy_client(uint64_t req) {\n      return Policy(true, false, false, false, req);\n    }\n    static Policy lossless_client(uint64_t req) {\n      return Policy(false, false, false, true, req);\n    }\n  };\n\n  /**\n   * Messenger constructor. Call this from your implementation.\n   * Messenger users should construct full implementations directly,\n   * or use the create() function.\n   */\n  Messenger(CephContext *cct_, entity_name_t w)\n    : trace_endpoint(\"0.0.0.0\", 0, \"Messenger\"),\n      my_inst(),\n      default_send_priority(CEPH_MSG_PRIO_DEFAULT), started(false),\n      magic(0),\n      socket_priority(-1),\n      cct(cct_),\n      crcflags(get_default_crc_flags(cct->_conf))\n  {\n    my_inst.name = w;\n  }\n  virtual ~Messenger() {}\n\n  /**\n   * create a new messenger\n   *\n   * Create a new messenger instance, with whatever implementation is\n   * available or specified via the configuration in cct.\n   *\n   * @param cct context\n   * @param type name of messenger type\n   * @param name entity name to register\n   * @param lname logical name of the messenger in this process (e.g., \"client\")\n   * @param nonce nonce value to uniquely identify this instance on the current host\n   * @param features bits for the local connection\n   * @param cflags general set of flags to configure transport resources\n   */\n  static Messenger *create(CephContext *cct,\n                           const string &type,\n                           entity_name_t name,\n\t\t\t   string lname,\n                           uint64_t nonce,\n\t\t\t   uint64_t cflags);\n\n  /**\n   * create a new messenger\n   *\n   * Create a new messenger instance.\n   * Same as the above, but a slightly simpler interface for clients:\n   * - Generate a random nonce\n   * - use the default feature bits\n   * - get the messenger type from cct\n   * - use the client entity_type\n   *\n   * @param cct context\n   * @param lname logical name of the messenger in this process (e.g., \"client\")\n   */\n  static Messenger *create_client_messenger(CephContext *cct, string lname);\n\n  /**\n   * @defgroup Accessors\n   * @{\n   */\n  /**\n   * Retrieve the Messenger's instance.\n   *\n   * @return A const reference to the instance this Messenger\n   * currently believes to be its own.\n   */\n  const entity_inst_t& get_myinst() { return my_inst; }\n  /**\n   * set messenger's instance\n   */\n  void set_myinst(entity_inst_t i) { my_inst = i; }\n\n  uint32_t get_magic() { return magic; }\n  void set_magic(int _magic) { magic = _magic; }\n\n  /**\n   * Retrieve the Messenger's address.\n   *\n   * @return A const reference to the address this Messenger\n   * currently believes to be its own.\n   */\n  const entity_addr_t& get_myaddr() { return my_inst.addr; }\nprotected:\n  /**\n   * set messenger's address\n   */\n  virtual void set_myaddr(const entity_addr_t& a) {\n    my_inst.addr = a;\n    set_endpoint_addr(a, my_inst.name);\n  }\npublic:\n  /**\n   * @return the zipkin trace endpoint\n   */\n  const ZTracer::Endpoint* get_trace_endpoint() const {\n    return &trace_endpoint;\n  }\n\n  /**\n   * Retrieve the Messenger's name.\n   *\n   * @return A const reference to the name this Messenger\n   * currently believes to be its own.\n   */\n  const entity_name_t& get_myname() { return my_inst.name; }\n  /**\n   * Set the name of the local entity. The name is reported to others and\n   * can be changed while the system is running, but doing so at incorrect\n   * times may have bad results.\n   *\n   * @param m The name to set.\n   */\n  void set_myname(const entity_name_t& m) { my_inst.name = m; }\n  /**\n   * Set the unknown address components for this Messenger.\n   * This is useful if the Messenger doesn't know its full address just by\n   * binding, but another Messenger on the same interface has already learned\n   * its full address. This function does not fill in known address elements,\n   * cause a rebind, or do anything of that sort.\n   *\n   * @param addr The address to use as a template.\n   */\n  virtual void set_addr_unknowns(const entity_addr_t &addr) = 0;\n  /**\n   * Set the address for this Messenger. This is useful if the Messenger\n   * binds to a specific address but advertises a different address on the\n   * the network.\n   *\n   * @param addr The address to use.\n   */\n  virtual void set_addr(const entity_addr_t &addr) = 0;\n  /// Get the default send priority.\n  int get_default_send_priority() { return default_send_priority; }\n  /**\n   * Get the number of Messages which the Messenger has received\n   * but not yet dispatched.\n   */\n  virtual int get_dispatch_queue_len() = 0;\n\n  /**\n   * Get age of oldest undelivered message\n   * (0 if the queue is empty)\n   */\n  virtual double get_dispatch_queue_max_age(utime_t now) = 0;\n  /**\n   * Get the default crc flags for this messenger.\n   * but not yet dispatched.\n   */\n  static int get_default_crc_flags(md_config_t *);\n\n  /**\n   * @} // Accessors\n   */\n\n  /**\n   * @defgroup Configuration\n   * @{\n   */\n  /**\n   * Set the cluster protocol in use by this daemon.\n   * This is an init-time function and cannot be called after calling\n   * start() or bind().\n   *\n   * @param p The cluster protocol to use. Defined externally.\n   */\n  virtual void set_cluster_protocol(int p) = 0;\n  /**\n   * Set a policy which is applied to all peers who do not have a type-specific\n   * Policy.\n   * This is an init-time function and cannot be called after calling\n   * start() or bind().\n   *\n   * @param p The Policy to apply.\n   */\n  virtual void set_default_policy(Policy p) = 0;\n  /**\n   * Set a policy which is applied to all peers of the given type.\n   * This is an init-time function and cannot be called after calling\n   * start() or bind().\n   *\n   * @param type The peer type this policy applies to.\n   * @param p The policy to apply.\n   */\n  virtual void set_policy(int type, Policy p) = 0;\n  /**\n   * Set the Policy associated with a type of peer.\n   *\n   * This can be called either on initial setup, or after connections\n   * are already established.  However, the policies for existing\n   * connections will not be affected; the new policy will only apply\n   * to future connections.\n   *\n   * @param t The peer type to get the default policy for.\n   * @return A const Policy reference.\n   */\n  virtual Policy get_policy(int t) = 0;\n  /**\n   * Get the default Policy\n   *\n   * @return A const Policy reference.\n   */\n  virtual Policy get_default_policy() = 0;\n  /**\n   * Set Throttlers applied to all Messages from the given type of peer\n   *\n   * This is an init-time function and cannot be called after calling\n   * start() or bind().\n   *\n   * @param type The peer type the Throttlers will apply to.\n   * @param bytes The Throttle for the number of bytes carried by the message\n   * @param msgs The Throttle for the number of messages for this @p type\n   * @note The Messenger does not take ownership of the Throttle pointers, but\n   * you must not destroy them before you destroy the Messenger.\n   */\n  virtual void set_policy_throttlers(int type, Throttle *bytes, Throttle *msgs=NULL) = 0;\n  /**\n   * Set the default send priority\n   *\n   * This is an init-time function and must be called *before* calling\n   * start().\n   *\n   * @param p The cluster protocol to use. Defined externally.\n   */\n  void set_default_send_priority(int p) {\n    assert(!started);\n    default_send_priority = p;\n  }\n  /**\n   * Set the priority(SO_PRIORITY) for all packets to be sent on this socket.\n   *\n   * Linux uses this value to order the networking queues: packets with a higher\n   * priority may be processed first depending on the selected device queueing\n   * discipline.\n   *\n   * @param prio The priority. Setting a priority outside the range 0 to 6\n   * requires the CAP_NET_ADMIN capability.\n   */\n  void set_socket_priority(int prio) {\n    socket_priority = prio;\n  }\n  /**\n   * Get the socket priority\n   *\n   * @return the socket priority\n   */\n  int get_socket_priority() {\n    return socket_priority;\n  }\n  /**\n   * Add a new Dispatcher to the front of the list. If you add\n   * a Dispatcher which is already included, it will get a duplicate\n   * entry. This will reduce efficiency but not break anything.\n   *\n   * @param d The Dispatcher to insert into the list.\n   */\n  void add_dispatcher_head(Dispatcher *d) { \n    bool first = dispatchers.empty();\n    dispatchers.push_front(d);\n    if (d->ms_can_fast_dispatch_any())\n      fast_dispatchers.push_front(d);\n    if (first)\n      ready();\n  }\n  /**\n   * Add a new Dispatcher to the end of the list. If you add\n   * a Dispatcher which is already included, it will get a duplicate\n   * entry. This will reduce efficiency but not break anything.\n   *\n   * @param d The Dispatcher to insert into the list.\n   */\n  void add_dispatcher_tail(Dispatcher *d) { \n    bool first = dispatchers.empty();\n    dispatchers.push_back(d);\n    if (d->ms_can_fast_dispatch_any())\n      fast_dispatchers.push_back(d);\n    if (first)\n      ready();\n  }\n  /**\n   * Bind the Messenger to a specific address. If bind_addr\n   * is not completely filled in the system will use the\n   * valid portions and cycle through the unset ones (eg, the port)\n   * in an unspecified order.\n   *\n   * @param bind_addr The address to bind to.\n   * @return 0 on success, or -1 on error, or -errno if\n   * we can be more specific about the failure.\n   */\n  virtual int bind(const entity_addr_t& bind_addr) = 0;\n  /**\n   * This function performs a full restart of the Messenger component,\n   * whatever that means.  Other entities who connect to this\n   * Messenger post-rebind() should perceive it as a new entity which\n   * they have not previously contacted, and it MUST bind to a\n   * different address than it did previously.\n   *\n   * @param avoid_ports Additional port to avoid binding to.\n   */\n  virtual int rebind(const set<int>& avoid_ports) { return -EOPNOTSUPP; }\n  /**\n   * Bind the 'client' Messenger to a specific address.Messenger will bind\n   * the address before connect to others when option ms_bind_before_connect\n   * is true.\n   * @param bind_addr The address to bind to.\n   * @return 0 on success, or -1 on error, or -errno if\n   */\n  virtual int client_bind(const entity_addr_t& bind_addr) = 0;\n  /**\n   * @} // Configuration\n   */\n\n  /**\n   * @defgroup Startup/Shutdown\n   * @{\n   */\n  /**\n   * Perform any resource allocation, thread startup, etc\n   * that is required before attempting to connect to other\n   * Messengers or transmit messages.\n   * Once this function completes, started shall be set to true.\n   *\n   * @return 0 on success; -errno on failure.\n   */\n  virtual int start() { started = true; return 0; }\n\n  // shutdown\n  /**\n   * Block until the Messenger has finished shutting down (according\n   * to the shutdown() function).\n   * It is valid to call this after calling shutdown(), but it must\n   * be called before deleting the Messenger.\n   */\n  virtual void wait() = 0;\n  /**\n   * Initiate a shutdown of the Messenger.\n   *\n   * @return 0 on success, -errno otherwise.\n   */\n  virtual int shutdown() { started = false; return 0; }\n  /**\n   * @} // Startup/Shutdown\n   */\n\n  /**\n   * @defgroup Messaging\n   * @{\n   */\n  /**\n   * Queue the given Message for the given entity.\n   * Success in this function does not guarantee Message delivery, only\n   * success in queueing the Message. Other guarantees may be provided based\n   * on the Connection policy associated with the dest.\n   *\n   * @param m The Message to send. The Messenger consumes a single reference\n   * when you pass it in.\n   * @param dest The entity to send the Message to.\n   *\n   * DEPRECATED: please do not use this interface for any new code;\n   * use the Connection* variant.\n   *\n   * @return 0 on success, or -errno on failure.\n   */\n  virtual int send_message(Message *m, const entity_inst_t& dest) = 0;\n\n  /**\n   * @} // Messaging\n   */\n  /**\n   * @defgroup Connection Management\n   * @{\n   */\n  /**\n   * Get the Connection object associated with a given entity. If a\n   * Connection does not exist, create one and establish a logical connection.\n   * The caller owns a reference when this returns. Call ->put() when you're\n   * done!\n   *\n   * @param dest The entity to get a connection for.\n   */\n  virtual ConnectionRef get_connection(const entity_inst_t& dest) = 0;\n  /**\n   * Get the Connection object associated with ourselves.\n   */\n  virtual ConnectionRef get_loopback_connection() = 0;\n  /**\n   * Mark down a Connection to a remote.\n   *\n   * This will cause us to discard our outgoing queue for them, and if\n   * reset detection is enabled in the policy and the endpoint tries\n   * to reconnect they will discard their queue when we inform them of\n   * the session reset.\n   *\n   * If there is no Connection to the given dest, it is a no-op.\n   *\n   * This generates a RESET notification to the Dispatcher.\n   *\n   * DEPRECATED: please do not use this interface for any new code;\n   * use the Connection* variant.\n   *\n   * @param a The address to mark down.\n   */\n  virtual void mark_down(const entity_addr_t& a) = 0;\n  /**\n   * Mark all the existing Connections down. This is equivalent\n   * to iterating over all Connections and calling mark_down()\n   * on each.\n   *\n   * This will generate a RESET event for each closed connections.\n   */\n  virtual void mark_down_all() = 0;\n  /**\n   * @} // Connection Management\n   */\nprotected:\n  /**\n   * @defgroup Subclass Interfacing\n   * @{\n   */\n  /**\n   * A courtesy function for Messenger implementations which\n   * will be called when we receive our first Dispatcher.\n   */\n  virtual void ready() { }\n  /**\n   * @} // Subclass Interfacing\n   */\npublic:\n#ifdef CEPH_USE_SIGPIPE_BLOCKER\n  /**\n   * We need to disable SIGPIPE on all platforms, and if they\n   * don't give us a better mechanism (read: are on Solaris) that\n   * means blocking the signal whenever we do a send or sendmsg...\n   * That means any implementations must invoke MSGR_SIGPIPE_STOPPER in-scope\n   * whenever doing so. On most systems that's blank, but on systems where\n   * it's needed we construct an RAII object to plug and un-plug the SIGPIPE.\n   * See http://www.microhowto.info/howto/ignore_sigpipe_without_affecting_other_threads_in_a_process.html\n   */\n  struct sigpipe_stopper {\n    bool blocked;\n    sigset_t existing_mask;\n    sigset_t pipe_mask;\n    sigpipe_stopper() {\n      sigemptyset(&pipe_mask);\n      sigaddset(&pipe_mask, SIGPIPE);\n      sigset_t signals;\n      sigemptyset(&signals);\n      sigpending(&signals);\n      if (sigismember(&signals, SIGPIPE)) {\n\tblocked = false;\n      } else {\n\tblocked = true;\n\tint r = pthread_sigmask(SIG_BLOCK, &pipe_mask, &existing_mask);\n\tassert(r == 0);\n      }\n    }\n    ~sigpipe_stopper() {\n      if (blocked) {\n\tstruct timespec nowait{0};\n\tint r = sigtimedwait(&pipe_mask, 0, &nowait);\n\tassert(r == EAGAIN || r == 0);\n\tr = pthread_sigmask(SIG_SETMASK, &existing_mask, 0);\n\tassert(r == 0);\n      }\n    }\n  };\n#  define MSGR_SIGPIPE_STOPPER Messenger::sigpipe_stopper stopper();\n#else\n#  define MSGR_SIGPIPE_STOPPER\n#endif\n  /**\n   * @defgroup Dispatcher Interfacing\n   * @{\n   */\n  /**\n   * Determine whether a message can be fast-dispatched. We will\n   * query each Dispatcher in sequence to determine if they are\n   * capable of handling a particular message via \"fast dispatch\".\n   *\n   * @param m The Message we are testing.\n   */\n  bool ms_can_fast_dispatch(const Message *m) {\n    for (list<Dispatcher*>::iterator p = fast_dispatchers.begin();\n\t p != fast_dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_can_fast_dispatch(m))\n\treturn true;\n    }\n    return false;\n  }\n\n  /**\n   * Deliver a single Message via \"fast dispatch\".\n   *\n   * @param m The Message we are fast dispatching. We take ownership\n   * of one reference to it.\n   * If none of our Dispatchers can handle it, ceph_abort().\n   */\n  void ms_fast_dispatch(Message *m) {\n    m->set_dispatch_stamp(ceph_clock_now());\n    for (list<Dispatcher*>::iterator p = fast_dispatchers.begin();\n\t p != fast_dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_can_fast_dispatch(m)) {\n\t(*p)->ms_fast_dispatch(m);\n\treturn;\n      }\n    }\n    ceph_abort();\n  }\n  /**\n   *\n   */\n  void ms_fast_preprocess(Message *m) {\n    for (list<Dispatcher*>::iterator p = fast_dispatchers.begin();\n\t p != fast_dispatchers.end();\n\t ++p) {\n      (*p)->ms_fast_preprocess(m);\n    }\n  }\n  /**\n   *  Deliver a single Message. Send it to each Dispatcher\n   *  in sequence until one of them handles it.\n   *  If none of our Dispatchers can handle it, assert(0).\n   *\n   *  @param m The Message to deliver. We take ownership of\n   *  one reference to it.\n   */\n  void ms_deliver_dispatch(Message *m) {\n    m->set_dispatch_stamp(ceph_clock_now());\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_dispatch(m))\n\treturn;\n    }\n    lsubdout(cct, ms, 0) << \"ms_deliver_dispatch: unhandled message \" << m << \" \" << *m << \" from \"\n\t\t\t << m->get_source_inst() << dendl;\n    assert(!cct->_conf->ms_die_on_unhandled_msg);\n    m->put();\n  }\n  /**\n   * Notify each Dispatcher of a new Connection. Call\n   * this function whenever a new Connection is initiated or\n   * reconnects.\n   *\n   * @param con Pointer to the new Connection.\n   */\n  void ms_deliver_handle_connect(Connection *con) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p)\n      (*p)->ms_handle_connect(con);\n  }\n\n  /**\n   * Notify each fast Dispatcher of a new Connection. Call\n   * this function whenever a new Connection is initiated or\n   * reconnects.\n   *\n   * @param con Pointer to the new Connection.\n   */\n  void ms_deliver_handle_fast_connect(Connection *con) {\n    for (list<Dispatcher*>::iterator p = fast_dispatchers.begin();\n         p != fast_dispatchers.end();\n         ++p)\n      (*p)->ms_handle_fast_connect(con);\n  }\n\n  /**\n   * Notify each Dispatcher of a new incomming Connection. Call\n   * this function whenever a new Connection is accepted.\n   *\n   * @param con Pointer to the new Connection.\n   */\n  void ms_deliver_handle_accept(Connection *con) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p)\n      (*p)->ms_handle_accept(con);\n  }\n\n  /**\n   * Notify each fast Dispatcher of a new incoming Connection. Call\n   * this function whenever a new Connection is accepted.\n   *\n   * @param con Pointer to the new Connection.\n   */\n  void ms_deliver_handle_fast_accept(Connection *con) {\n    for (list<Dispatcher*>::iterator p = fast_dispatchers.begin();\n         p != fast_dispatchers.end();\n         ++p)\n      (*p)->ms_handle_fast_accept(con);\n  }\n\n  /**\n   * Notify each Dispatcher of a Connection which may have lost\n   * Messages. Call this function whenever you detect that a lossy Connection\n   * has been disconnected.\n   *\n   * @param con Pointer to the broken Connection.\n   */\n  void ms_deliver_handle_reset(Connection *con) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_handle_reset(con))\n\treturn;\n    }\n  }\n  /**\n   * Notify each Dispatcher of a Connection which has been \"forgotten\" about\n   * by the remote end, implying that messages have probably been lost.\n   * Call this function whenever you detect a reset.\n   *\n   * @param con Pointer to the broken Connection.\n   */\n  void ms_deliver_handle_remote_reset(Connection *con) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p)\n      (*p)->ms_handle_remote_reset(con);\n  }\n\n  /**\n   * Notify each Dispatcher of a Connection for which reconnection\n   * attempts are being refused. Call this function whenever you\n   * detect that a lossy Connection has been disconnected and it's\n   * impossible to reconnect.\n   *\n   * @param con Pointer to the broken Connection.\n   */\n  void ms_deliver_handle_refused(Connection *con) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n         p != dispatchers.end();\n         ++p) {\n      if ((*p)->ms_handle_refused(con))\n        return;\n    }\n  }\n\n  /**\n   * Get the AuthAuthorizer for a new outgoing Connection.\n   *\n   * @param peer_type The peer type for the new Connection\n   * @param force_new True if we want to wait for new keys, false otherwise.\n   * @return A pointer to the AuthAuthorizer, if we have one; NULL otherwise\n   */\n  AuthAuthorizer *ms_deliver_get_authorizer(int peer_type, bool force_new) {\n    AuthAuthorizer *a = 0;\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_get_authorizer(peer_type, &a, force_new))\n\treturn a;\n    }\n    return NULL;\n  }\n  /**\n   * Verify that the authorizer on a new incoming Connection is correct.\n   *\n   * @param con The new incoming Connection\n   * @param peer_type The type of the endpoint on the new Connection\n   * @param protocol The ID of the protocol in use (at time of writing, cephx or none)\n   * @param authorizer The authorization string supplied by the remote\n   * @param authorizer_reply Output param: The string we should send back to\n   * the remote to authorize ourselves. Only filled in if isvalid\n   * @param isvalid Output param: True if authorizer is valid, false otherwise\n   *\n   * @return True if we were able to prove or disprove correctness of\n   * authorizer, false otherwise.\n   */\n  bool ms_deliver_verify_authorizer(Connection *con, int peer_type,\n\t\t\t\t    int protocol, bufferlist& authorizer, bufferlist& authorizer_reply,\n\t\t\t\t    bool& isvalid, CryptoKey& session_key) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_verify_authorizer(con, peer_type, protocol, authorizer, authorizer_reply, isvalid, session_key))\n\treturn true;\n    }\n    return false;\n  }\n\n  /**\n   * @} // Dispatcher Interfacing\n   */\n};\n\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2014 UnitedStack <haomai@unitedstack.com>\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include <unistd.h>\n\n#include \"include/Context.h\"\n#include \"common/errno.h\"\n#include \"AsyncMessenger.h\"\n#include \"AsyncConnection.h\"\n\n#include \"messages/MOSDOp.h\"\n#include \"messages/MOSDOpReply.h\"\n#include \"common/EventTrace.h\"\n\n// Constant to limit starting sequence number to 2^31.  Nothing special about it, just a big number.  PLR\n#define SEQ_MASK  0x7fffffff \n\n#define dout_subsys ceph_subsys_ms\n#undef dout_prefix\n#define dout_prefix _conn_prefix(_dout)\nostream& AsyncConnection::_conn_prefix(std::ostream *_dout) {\n  return *_dout << \"-- \" << async_msgr->get_myinst().addr << \" >> \" << peer_addr << \" conn(\" << this\n                << \" :\" << port\n                << \" s=\" << get_state_name(state)\n                << \" pgs=\" << peer_global_seq\n                << \" cs=\" << connect_seq\n                << \" l=\" << policy.lossy\n                << \").\";\n}\n\n// Notes:\n// 1. Don't dispatch any event when closed! It may cause AsyncConnection alive even if AsyncMessenger dead\n\nconst int AsyncConnection::TCP_PREFETCH_MIN_SIZE = 512;\nconst int ASYNC_COALESCE_THRESHOLD = 256;\n\nclass C_time_wakeup : public EventCallback {\n  AsyncConnectionRef conn;\n\n public:\n  explicit C_time_wakeup(AsyncConnectionRef c): conn(c) {}\n  void do_request(int fd_or_id) override {\n    conn->wakeup_from(fd_or_id);\n  }\n};\n\nclass C_handle_read : public EventCallback {\n  AsyncConnectionRef conn;\n\n public:\n  explicit C_handle_read(AsyncConnectionRef c): conn(c) {}\n  void do_request(int fd_or_id) override {\n    conn->process();\n  }\n};\n\nclass C_handle_write : public EventCallback {\n  AsyncConnectionRef conn;\n\n public:\n  explicit C_handle_write(AsyncConnectionRef c): conn(c) {}\n  void do_request(int fd) override {\n    conn->handle_write();\n  }\n};\n\nclass C_clean_handler : public EventCallback {\n  AsyncConnectionRef conn;\n public:\n  explicit C_clean_handler(AsyncConnectionRef c): conn(c) {}\n  void do_request(int id) override {\n    conn->cleanup();\n    delete this;\n  }\n};\n\nclass C_tick_wakeup : public EventCallback {\n  AsyncConnectionRef conn;\n\n public:\n  explicit C_tick_wakeup(AsyncConnectionRef c): conn(c) {}\n  void do_request(int fd_or_id) override {\n    conn->tick(fd_or_id);\n  }\n};\n\nstatic void alloc_aligned_buffer(bufferlist& data, unsigned len, unsigned off)\n{\n  // create a buffer to read into that matches the data alignment\n  unsigned left = len;\n  if (off & ~CEPH_PAGE_MASK) {\n    // head\n    unsigned head = 0;\n    head = MIN(CEPH_PAGE_SIZE - (off & ~CEPH_PAGE_MASK), left);\n    data.push_back(buffer::create(head));\n    left -= head;\n  }\n  unsigned middle = left & CEPH_PAGE_MASK;\n  if (middle > 0) {\n    data.push_back(buffer::create_page_aligned(middle));\n    left -= middle;\n  }\n  if (left) {\n    data.push_back(buffer::create(left));\n  }\n}\n\nAsyncConnection::AsyncConnection(CephContext *cct, AsyncMessenger *m, DispatchQueue *q,\n                                 Worker *w)\n  : Connection(cct, m), delay_state(NULL), async_msgr(m), conn_id(q->get_id()),\n    logger(w->get_perf_counter()), global_seq(0), connect_seq(0), peer_global_seq(0),\n    state(STATE_NONE), state_after_send(STATE_NONE), port(-1),\n    dispatch_queue(q), can_write(WriteStatus::NOWRITE),\n    keepalive(false), recv_buf(NULL),\n    recv_max_prefetch(MAX(msgr->cct->_conf->ms_tcp_prefetch_max_size, TCP_PREFETCH_MIN_SIZE)),\n    recv_start(0), recv_end(0),\n    last_active(ceph::coarse_mono_clock::now()),\n    inactive_timeout_us(cct->_conf->ms_tcp_read_timeout*1000*1000),\n    got_bad_auth(false), authorizer(NULL), replacing(false),\n    is_reset_from_peer(false), once_ready(false), state_buffer(NULL), state_offset(0),\n    worker(w), center(&w->center)\n{\n  read_handler = new C_handle_read(this);\n  write_handler = new C_handle_write(this);\n  wakeup_handler = new C_time_wakeup(this);\n  tick_handler = new C_tick_wakeup(this);\n  memset(msgvec, 0, sizeof(msgvec));\n  // double recv_max_prefetch see \"read_until\"\n  recv_buf = new char[2*recv_max_prefetch];\n  state_buffer = new char[4096];\n  logger->inc(l_msgr_created_connections);\n}\n\nAsyncConnection::~AsyncConnection()\n{\n  assert(out_q.empty());\n  assert(sent.empty());\n  delete authorizer;\n  if (recv_buf)\n    delete[] recv_buf;\n  if (state_buffer)\n    delete[] state_buffer;\n  assert(!delay_state);\n}\n\nvoid AsyncConnection::maybe_start_delay_thread()\n{\n  if (!delay_state) {\n    auto pos = async_msgr->cct->_conf->get_val<std::string>(\"ms_inject_delay_type\").find(ceph_entity_type_name(peer_type));\n    if (pos != string::npos) {\n      ldout(msgr->cct, 1) << __func__ << \" setting up a delay queue\" << dendl;\n      delay_state = new DelayedDelivery(async_msgr, center, dispatch_queue, conn_id);\n    }\n  }\n}\n\n/* return -1 means `fd` occurs error or closed, it should be closed\n * return 0 means EAGAIN or EINTR */\nssize_t AsyncConnection::read_bulk(char *buf, unsigned len)\n{\n  ssize_t nread;\n again:\n  nread = cs.read(buf, len);\n  if (nread < 0) {\n    if (nread == -EAGAIN) {\n      nread = 0;\n    } else if (nread == -EINTR) {\n      goto again;\n    } else {\n      ldout(async_msgr->cct, 1) << __func__ << \" reading from fd=\" << cs.fd()\n                          << \" : \"<< strerror(nread) << dendl;\n      return -1;\n    }\n  } else if (nread == 0) {\n    ldout(async_msgr->cct, 1) << __func__ << \" peer close file descriptor \"\n                              << cs.fd() << dendl;\n    return -1;\n  }\n  return nread;\n}\n\n// return the remaining bytes, it may larger than the length of ptr\n// else return < 0 means error\nssize_t AsyncConnection::_try_send(bool more)\n{\n  if (async_msgr->cct->_conf->ms_inject_socket_failures && cs) {\n    if (rand() % async_msgr->cct->_conf->ms_inject_socket_failures == 0) {\n      ldout(async_msgr->cct, 0) << __func__ << \" injecting socket failure\" << dendl;\n      cs.shutdown();\n    }\n  }\n\n  assert(center->in_thread());\n  ssize_t r = cs.send(outcoming_bl, more);\n  if (r < 0) {\n    ldout(async_msgr->cct, 1) << __func__ << \" send error: \" << cpp_strerror(r) << dendl;\n    return r;\n  }\n\n  ldout(async_msgr->cct, 10) << __func__ << \" sent bytes \" << r\n                             << \" remaining bytes \" << outcoming_bl.length() << dendl;\n\n  if (!open_write && is_queued()) {\n    center->create_file_event(cs.fd(), EVENT_WRITABLE, write_handler);\n    open_write = true;\n  }\n\n  if (open_write && !is_queued()) {\n    center->delete_file_event(cs.fd(), EVENT_WRITABLE);\n    open_write = false;\n    if (state_after_send != STATE_NONE)\n      center->dispatch_event_external(read_handler);\n  }\n\n  return outcoming_bl.length();\n}\n\n// Because this func will be called multi times to populate\n// the needed buffer, so the passed in bufferptr must be the same.\n// Normally, only \"read_message\" will pass existing bufferptr in\n//\n// And it will uses readahead method to reduce small read overhead,\n// \"recv_buf\" is used to store read buffer\n//\n// return the remaining bytes, 0 means this buffer is finished\n// else return < 0 means error\nssize_t AsyncConnection::read_until(unsigned len, char *p)\n{\n  ldout(async_msgr->cct, 25) << __func__ << \" len is \" << len << \" state_offset is \"\n                             << state_offset << dendl;\n\n  if (async_msgr->cct->_conf->ms_inject_socket_failures && cs) {\n    if (rand() % async_msgr->cct->_conf->ms_inject_socket_failures == 0) {\n      ldout(async_msgr->cct, 0) << __func__ << \" injecting socket failure\" << dendl;\n      cs.shutdown();\n    }\n  }\n\n  ssize_t r = 0;\n  uint64_t left = len - state_offset;\n  if (recv_end > recv_start) {\n    uint64_t to_read = MIN(recv_end - recv_start, left);\n    memcpy(p, recv_buf+recv_start, to_read);\n    recv_start += to_read;\n    left -= to_read;\n    ldout(async_msgr->cct, 25) << __func__ << \" got \" << to_read << \" in buffer \"\n                               << \" left is \" << left << \" buffer still has \"\n                               << recv_end - recv_start << dendl;\n    if (left == 0) {\n      return 0;\n    }\n    state_offset += to_read;\n  }\n\n  recv_end = recv_start = 0;\n  /* nothing left in the prefetch buffer */\n  if (len > recv_max_prefetch) {\n    /* this was a large read, we don't prefetch for these */\n    do {\n      r = read_bulk(p+state_offset, left);\n      ldout(async_msgr->cct, 25) << __func__ << \" read_bulk left is \" << left << \" got \" << r << dendl;\n      if (r < 0) {\n        ldout(async_msgr->cct, 1) << __func__ << \" read failed\" << dendl;\n        return -1;\n      } else if (r == static_cast<int>(left)) {\n        state_offset = 0;\n        return 0;\n      }\n      state_offset += r;\n      left -= r;\n    } while (r > 0);\n  } else {\n    do {\n      r = read_bulk(recv_buf+recv_end, recv_max_prefetch);\n      ldout(async_msgr->cct, 25) << __func__ << \" read_bulk recv_end is \" << recv_end\n                                 << \" left is \" << left << \" got \" << r << dendl;\n      if (r < 0) {\n        ldout(async_msgr->cct, 1) << __func__ << \" read failed\" << dendl;\n        return -1;\n      }\n      recv_end += r;\n      if (r >= static_cast<int>(left)) {\n        recv_start = len - state_offset;\n        memcpy(p+state_offset, recv_buf, recv_start);\n        state_offset = 0;\n        return 0;\n      }\n      left -= r;\n    } while (r > 0);\n    memcpy(p+state_offset, recv_buf, recv_end-recv_start);\n    state_offset += (recv_end - recv_start);\n    recv_end = recv_start = 0;\n  }\n  ldout(async_msgr->cct, 25) << __func__ << \" need len \" << len << \" remaining \"\n                             << len - state_offset << \" bytes\" << dendl;\n  return len - state_offset;\n}\n\nvoid AsyncConnection::inject_delay() {\n  if (async_msgr->cct->_conf->ms_inject_internal_delays) {\n    ldout(async_msgr->cct, 10) << __func__ << \" sleep for \" << \n      async_msgr->cct->_conf->ms_inject_internal_delays << dendl;\n    utime_t t;\n    t.set_from_double(async_msgr->cct->_conf->ms_inject_internal_delays);\n    t.sleep();\n  }\n}\n\nvoid AsyncConnection::process()\n{\n  ssize_t r = 0;\n  int prev_state = state;\n#if defined(WITH_LTTNG) && defined(WITH_EVENTTRACE)\n  utime_t ltt_recv_stamp = ceph_clock_now();\n#endif\n  bool need_dispatch_writer = false;\n  std::lock_guard<std::mutex> l(lock);\n  last_active = ceph::coarse_mono_clock::now();\n  auto recv_start_time = ceph::mono_clock::now();\n  do {\n    ldout(async_msgr->cct, 20) << __func__ << \" prev state is \" << get_state_name(prev_state) << dendl;\n    prev_state = state;\n    switch (state) {\n      case STATE_OPEN:\n        {\n          char tag = -1;\n          r = read_until(sizeof(tag), &tag);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read tag failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          if (tag == CEPH_MSGR_TAG_KEEPALIVE) {\n            ldout(async_msgr->cct, 20) << __func__ << \" got KEEPALIVE\" << dendl;\n\t    set_last_keepalive(ceph_clock_now());\n          } else if (tag == CEPH_MSGR_TAG_KEEPALIVE2) {\n            state = STATE_OPEN_KEEPALIVE2;\n          } else if (tag == CEPH_MSGR_TAG_KEEPALIVE2_ACK) {\n            state = STATE_OPEN_KEEPALIVE2_ACK;\n          } else if (tag == CEPH_MSGR_TAG_ACK) {\n            state = STATE_OPEN_TAG_ACK;\n          } else if (tag == CEPH_MSGR_TAG_MSG) {\n            state = STATE_OPEN_MESSAGE_HEADER;\n          } else if (tag == CEPH_MSGR_TAG_CLOSE) {\n            state = STATE_OPEN_TAG_CLOSE;\n          } else {\n            ldout(async_msgr->cct, 0) << __func__ << \" bad tag \" << (int)tag << dendl;\n            goto fail;\n          }\n\n          break;\n        }\n\n      case STATE_OPEN_KEEPALIVE2:\n        {\n          ceph_timespec *t;\n          r = read_until(sizeof(*t), state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read keeplive timespec failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          ldout(async_msgr->cct, 30) << __func__ << \" got KEEPALIVE2 tag ...\" << dendl;\n          t = (ceph_timespec*)state_buffer;\n          utime_t kp_t = utime_t(*t);\n          write_lock.lock();\n          _append_keepalive_or_ack(true, &kp_t);\n\t  write_lock.unlock();\n          ldout(async_msgr->cct, 20) << __func__ << \" got KEEPALIVE2 \" << kp_t << dendl;\n\t  set_last_keepalive(ceph_clock_now());\n          need_dispatch_writer = true;\n          state = STATE_OPEN;\n          break;\n        }\n\n      case STATE_OPEN_KEEPALIVE2_ACK:\n        {\n          ceph_timespec *t;\n          r = read_until(sizeof(*t), state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read keeplive timespec failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          t = (ceph_timespec*)state_buffer;\n          set_last_keepalive_ack(utime_t(*t));\n          ldout(async_msgr->cct, 20) << __func__ << \" got KEEPALIVE_ACK\" << dendl;\n          state = STATE_OPEN;\n          break;\n        }\n\n      case STATE_OPEN_TAG_ACK:\n        {\n          ceph_le64 *seq;\n          r = read_until(sizeof(*seq), state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read ack seq failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          seq = (ceph_le64*)state_buffer;\n          ldout(async_msgr->cct, 20) << __func__ << \" got ACK\" << dendl;\n          handle_ack(*seq);\n          state = STATE_OPEN;\n          break;\n        }\n\n      case STATE_OPEN_MESSAGE_HEADER:\n        {\n#if defined(WITH_LTTNG) && defined(WITH_EVENTTRACE)\n          ltt_recv_stamp = ceph_clock_now();\n#endif\n          recv_stamp = ceph_clock_now();\n          ldout(async_msgr->cct, 20) << __func__ << \" begin MSG\" << dendl;\n          ceph_msg_header header;\n          ceph_msg_header_old oldheader;\n          __u32 header_crc = 0;\n          unsigned len;\n          if (has_feature(CEPH_FEATURE_NOSRCADDR))\n            len = sizeof(header);\n          else\n            len = sizeof(oldheader);\n\n          r = read_until(len, state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read message header failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          ldout(async_msgr->cct, 20) << __func__ << \" got MSG header\" << dendl;\n\n          if (has_feature(CEPH_FEATURE_NOSRCADDR)) {\n            header = *((ceph_msg_header*)state_buffer);\n            if (msgr->crcflags & MSG_CRC_HEADER)\n              header_crc = ceph_crc32c(0, (unsigned char *)&header,\n                                       sizeof(header) - sizeof(header.crc));\n          } else {\n            oldheader = *((ceph_msg_header_old*)state_buffer);\n            // this is fugly\n            memcpy(&header, &oldheader, sizeof(header));\n            header.src = oldheader.src.name;\n            header.reserved = oldheader.reserved;\n            if (msgr->crcflags & MSG_CRC_HEADER) {\n              header.crc = oldheader.crc;\n              header_crc = ceph_crc32c(0, (unsigned char *)&oldheader, sizeof(oldheader) - sizeof(oldheader.crc));\n            }\n          }\n\n          ldout(async_msgr->cct, 20) << __func__ << \" got envelope type=\" << header.type\n                              << \" src \" << entity_name_t(header.src)\n                              << \" front=\" << header.front_len\n                              << \" data=\" << header.data_len\n                              << \" off \" << header.data_off << dendl;\n\n          // verify header crc\n          if (msgr->crcflags & MSG_CRC_HEADER && header_crc != header.crc) {\n            ldout(async_msgr->cct,0) << __func__ << \" got bad header crc \"\n                                     << header_crc << \" != \" << header.crc << dendl;\n            goto fail;\n          }\n\n          // Reset state\n          data_buf.clear();\n          front.clear();\n          middle.clear();\n          data.clear();\n          current_header = header;\n          state = STATE_OPEN_MESSAGE_THROTTLE_MESSAGE;\n          break;\n        }\n\n      case STATE_OPEN_MESSAGE_THROTTLE_MESSAGE:\n        {\n          if (policy.throttler_messages) {\n            ldout(async_msgr->cct, 10) << __func__ << \" wants \" << 1 << \" message from policy throttler \"\n                                       << policy.throttler_messages->get_current() << \"/\"\n                                       << policy.throttler_messages->get_max() << dendl;\n            if (!policy.throttler_messages->get_or_fail()) {\n              ldout(async_msgr->cct, 10) << __func__ << \" wants 1 message from policy throttle \"\n\t\t\t\t\t << policy.throttler_messages->get_current() << \"/\"\n\t\t\t\t\t << policy.throttler_messages->get_max() << \" failed, just wait.\" << dendl;\n              // following thread pool deal with th full message queue isn't a\n              // short time, so we can wait a ms.\n              if (register_time_events.empty())\n                register_time_events.insert(center->create_time_event(1000, wakeup_handler));\n              break;\n            }\n          }\n\n          state = STATE_OPEN_MESSAGE_THROTTLE_BYTES;\n          break;\n        }\n\n      case STATE_OPEN_MESSAGE_THROTTLE_BYTES:\n        {\n          cur_msg_size = current_header.front_len + current_header.middle_len + current_header.data_len;\n          if (cur_msg_size) {\n            if (policy.throttler_bytes) {\n              ldout(async_msgr->cct, 10) << __func__ << \" wants \" << cur_msg_size << \" bytes from policy throttler \"\n                                         << policy.throttler_bytes->get_current() << \"/\"\n                                         << policy.throttler_bytes->get_max() << dendl;\n              if (!policy.throttler_bytes->get_or_fail(cur_msg_size)) {\n                ldout(async_msgr->cct, 10) << __func__ << \" wants \" << cur_msg_size << \" bytes from policy throttler \"\n                                           << policy.throttler_bytes->get_current() << \"/\"\n                                           << policy.throttler_bytes->get_max() << \" failed, just wait.\" << dendl;\n                // following thread pool deal with th full message queue isn't a\n                // short time, so we can wait a ms.\n                if (register_time_events.empty())\n                  register_time_events.insert(center->create_time_event(1000, wakeup_handler));\n                break;\n              }\n            }\n          }\n\n          state = STATE_OPEN_MESSAGE_THROTTLE_DISPATCH_QUEUE;\n          break;\n        }\n\n      case STATE_OPEN_MESSAGE_THROTTLE_DISPATCH_QUEUE:\n        {\n          if (cur_msg_size) {\n            if (!dispatch_queue->dispatch_throttler.get_or_fail(cur_msg_size)) {\n              ldout(async_msgr->cct, 10) << __func__ << \" wants \" << cur_msg_size << \" bytes from dispatch throttle \"\n                                         << dispatch_queue->dispatch_throttler.get_current() << \"/\"\n                                         << dispatch_queue->dispatch_throttler.get_max() << \" failed, just wait.\" << dendl;\n              // following thread pool deal with th full message queue isn't a\n              // short time, so we can wait a ms.\n              if (register_time_events.empty())\n                register_time_events.insert(center->create_time_event(1000, wakeup_handler));\n              break;\n            }\n          }\n\n          throttle_stamp = ceph_clock_now();\n          state = STATE_OPEN_MESSAGE_READ_FRONT;\n          break;\n        }\n\n      case STATE_OPEN_MESSAGE_READ_FRONT:\n        {\n          // read front\n          unsigned front_len = current_header.front_len;\n          if (front_len) {\n            if (!front.length())\n              front.push_back(buffer::create(front_len));\n\n            r = read_until(front_len, front.c_str());\n            if (r < 0) {\n              ldout(async_msgr->cct, 1) << __func__ << \" read message front failed\" << dendl;\n              goto fail;\n            } else if (r > 0) {\n              break;\n            }\n\n            ldout(async_msgr->cct, 20) << __func__ << \" got front \" << front.length() << dendl;\n          }\n          state = STATE_OPEN_MESSAGE_READ_MIDDLE;\n        }\n\n      case STATE_OPEN_MESSAGE_READ_MIDDLE:\n        {\n          // read middle\n          unsigned middle_len = current_header.middle_len;\n          if (middle_len) {\n            if (!middle.length())\n              middle.push_back(buffer::create(middle_len));\n\n            r = read_until(middle_len, middle.c_str());\n            if (r < 0) {\n              ldout(async_msgr->cct, 1) << __func__ << \" read message middle failed\" << dendl;\n              goto fail;\n            } else if (r > 0) {\n              break;\n            }\n            ldout(async_msgr->cct, 20) << __func__ << \" got middle \" << middle.length() << dendl;\n          }\n\n          state = STATE_OPEN_MESSAGE_READ_DATA_PREPARE;\n        }\n\n      case STATE_OPEN_MESSAGE_READ_DATA_PREPARE:\n        {\n          // read data\n          unsigned data_len = le32_to_cpu(current_header.data_len);\n          unsigned data_off = le32_to_cpu(current_header.data_off);\n          if (data_len) {\n            // get a buffer\n            map<ceph_tid_t,pair<bufferlist,int> >::iterator p = rx_buffers.find(current_header.tid);\n            if (p != rx_buffers.end()) {\n              ldout(async_msgr->cct,10) << __func__ << \" seleting rx buffer v \" << p->second.second\n                                  << \" at offset \" << data_off\n                                  << \" len \" << p->second.first.length() << dendl;\n              data_buf = p->second.first;\n              // make sure it's big enough\n              if (data_buf.length() < data_len)\n                data_buf.push_back(buffer::create(data_len - data_buf.length()));\n              data_blp = data_buf.begin();\n            } else {\n              ldout(async_msgr->cct,20) << __func__ << \" allocating new rx buffer at offset \" << data_off << dendl;\n              alloc_aligned_buffer(data_buf, data_len, data_off);\n              data_blp = data_buf.begin();\n            }\n          }\n\n          msg_left = data_len;\n          state = STATE_OPEN_MESSAGE_READ_DATA;\n        }\n\n      case STATE_OPEN_MESSAGE_READ_DATA:\n        {\n          while (msg_left > 0) {\n            bufferptr bp = data_blp.get_current_ptr();\n            unsigned read = MIN(bp.length(), msg_left);\n            r = read_until(read, bp.c_str());\n            if (r < 0) {\n              ldout(async_msgr->cct, 1) << __func__ << \" read data error \" << dendl;\n              goto fail;\n            } else if (r > 0) {\n              break;\n            }\n\n            data_blp.advance(read);\n            data.append(bp, 0, read);\n            msg_left -= read;\n          }\n\n          if (msg_left > 0)\n            break;\n\n          state = STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH;\n        }\n\n      case STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH:\n        {\n          ceph_msg_footer footer;\n          ceph_msg_footer_old old_footer;\n          unsigned len;\n          // footer\n          if (has_feature(CEPH_FEATURE_MSG_AUTH))\n            len = sizeof(footer);\n          else\n            len = sizeof(old_footer);\n\n          r = read_until(len, state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read footer data error \" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          if (has_feature(CEPH_FEATURE_MSG_AUTH)) {\n            footer = *((ceph_msg_footer*)state_buffer);\n          } else {\n            old_footer = *((ceph_msg_footer_old*)state_buffer);\n            footer.front_crc = old_footer.front_crc;\n            footer.middle_crc = old_footer.middle_crc;\n            footer.data_crc = old_footer.data_crc;\n            footer.sig = 0;\n            footer.flags = old_footer.flags;\n          }\n          int aborted = (footer.flags & CEPH_MSG_FOOTER_COMPLETE) == 0;\n          ldout(async_msgr->cct, 10) << __func__ << \" aborted = \" << aborted << dendl;\n          if (aborted) {\n            ldout(async_msgr->cct, 0) << __func__ << \" got \" << front.length() << \" + \" << middle.length() << \" + \" << data.length()\n                                << \" byte message.. ABORTED\" << dendl;\n            goto fail;\n          }\n\n          ldout(async_msgr->cct, 20) << __func__ << \" got \" << front.length() << \" + \" << middle.length()\n                              << \" + \" << data.length() << \" byte message\" << dendl;\n          Message *message = decode_message(async_msgr->cct, async_msgr->crcflags, current_header, footer,\n                                            front, middle, data, this);\n          if (!message) {\n            ldout(async_msgr->cct, 1) << __func__ << \" decode message failed \" << dendl;\n            goto fail;\n          }\n\n          //\n          //  Check the signature if one should be present.  A zero return indicates success. PLR\n          //\n\n          if (session_security.get() == NULL) {\n            ldout(async_msgr->cct, 10) << __func__ << \" no session security set\" << dendl;\n          } else {\n            if (session_security->check_message_signature(message)) {\n              ldout(async_msgr->cct, 0) << __func__ << \" Signature check failed\" << dendl;\n              message->put();\n              goto fail;\n            }\n          }\n          message->set_byte_throttler(policy.throttler_bytes);\n          message->set_message_throttler(policy.throttler_messages);\n\n          // store reservation size in message, so we don't get confused\n          // by messages entering the dispatch queue through other paths.\n          message->set_dispatch_throttle_size(cur_msg_size);\n\n          message->set_recv_stamp(recv_stamp);\n          message->set_throttle_stamp(throttle_stamp);\n          message->set_recv_complete_stamp(ceph_clock_now());\n\n          // check received seq#.  if it is old, drop the message.  \n          // note that incoming messages may skip ahead.  this is convenient for the client\n          // side queueing because messages can't be renumbered, but the (kernel) client will\n          // occasionally pull a message out of the sent queue to send elsewhere.  in that case\n          // it doesn't matter if we \"got\" it or not.\n          uint64_t cur_seq = in_seq;\n          if (message->get_seq() <= cur_seq) {\n            ldout(async_msgr->cct,0) << __func__ << \" got old message \"\n                    << message->get_seq() << \" <= \" << cur_seq << \" \" << message << \" \" << *message\n                    << \", discarding\" << dendl;\n            message->put();\n            if (has_feature(CEPH_FEATURE_RECONNECT_SEQ) && async_msgr->cct->_conf->ms_die_on_old_message)\n              assert(0 == \"old msgs despite reconnect_seq feature\");\n            break;\n          }\n          if (message->get_seq() > cur_seq + 1) {\n            ldout(async_msgr->cct, 0) << __func__ << \" missed message?  skipped from seq \"\n                                      << cur_seq << \" to \" << message->get_seq() << dendl;\n            if (async_msgr->cct->_conf->ms_die_on_skipped_message)\n              assert(0 == \"skipped incoming seq\");\n          }\n\n          message->set_connection(this);\n\n#if defined(WITH_LTTNG) && defined(WITH_EVENTTRACE)\n          if (message->get_type() == CEPH_MSG_OSD_OP || message->get_type() == CEPH_MSG_OSD_OPREPLY) {\n            utime_t ltt_processed_stamp = ceph_clock_now();\n            double usecs_elapsed = (ltt_processed_stamp.to_nsec()-ltt_recv_stamp.to_nsec())/1000;\n            ostringstream buf;\n            if (message->get_type() == CEPH_MSG_OSD_OP)\n              OID_ELAPSED_WITH_MSG(message, usecs_elapsed, \"TIME_TO_DECODE_OSD_OP\", false);\n            else\n              OID_ELAPSED_WITH_MSG(message, usecs_elapsed, \"TIME_TO_DECODE_OSD_OPREPLY\", false);\n          }\n#endif\n\n          // note last received message.\n          in_seq = message->get_seq();\n\t  ldout(async_msgr->cct, 5) << \" rx \" << message->get_source() << \" seq \"\n                                    << message->get_seq() << \" \" << message\n\t\t\t\t    << \" \" << *message << dendl;\n\n          if (!policy.lossy) {\n            ack_left++;\n            need_dispatch_writer = true;\n          }\n          state = STATE_OPEN;\n\n          logger->inc(l_msgr_recv_messages);\n          logger->inc(l_msgr_recv_bytes, cur_msg_size + sizeof(ceph_msg_header) + sizeof(ceph_msg_footer));\n\n          async_msgr->ms_fast_preprocess(message);\n          auto fast_dispatch_time = ceph::mono_clock::now();\n          logger->tinc(l_msgr_running_recv_time, fast_dispatch_time - recv_start_time);\n          if (delay_state) {\n            utime_t release = message->get_recv_stamp();\n            double delay_period = 0;\n            if (rand() % 10000 < async_msgr->cct->_conf->ms_inject_delay_probability * 10000.0) {\n              delay_period = async_msgr->cct->_conf->ms_inject_delay_max * (double)(rand() % 10000) / 10000.0;\n              release += delay_period;\n              ldout(async_msgr->cct, 1) << \"queue_received will delay until \" << release << \" on \"\n                                        << message << \" \" << *message << dendl;\n            }\n            delay_state->queue(delay_period, release, message);\n          } else if (async_msgr->ms_can_fast_dispatch(message)) {\n            lock.unlock();\n            dispatch_queue->fast_dispatch(message);\n            recv_start_time = ceph::mono_clock::now();\n            logger->tinc(l_msgr_running_fast_dispatch_time,\n                         recv_start_time - fast_dispatch_time);\n            lock.lock();\n          } else {\n            dispatch_queue->enqueue(message, message->get_priority(), conn_id);\n          }\n\n          break;\n        }\n\n      case STATE_OPEN_TAG_CLOSE:\n        {\n          ldout(async_msgr->cct, 20) << __func__ << \" got CLOSE\" << dendl;\n          _stop();\n          return ;\n        }\n\n      case STATE_STANDBY:\n        {\n          ldout(async_msgr->cct, 20) << __func__ << \" enter STANDY\" << dendl;\n\n          break;\n        }\n\n      case STATE_NONE:\n        {\n          ldout(async_msgr->cct, 20) << __func__ << \" enter none state\" << dendl;\n          break;\n        }\n\n      case STATE_CLOSED:\n        {\n          ldout(async_msgr->cct, 20) << __func__ << \" socket closed\" << dendl;\n          break;\n        }\n\n      case STATE_WAIT:\n        {\n          ldout(async_msgr->cct, 1) << __func__ << \" enter wait state, failing\" << dendl;\n          goto fail;\n        }\n\n      default:\n        {\n          if (_process_connection() < 0)\n            goto fail;\n          break;\n        }\n    }\n  } while (prev_state != state);\n\n  if (need_dispatch_writer && is_connected())\n    center->dispatch_event_external(write_handler);\n\n  logger->tinc(l_msgr_running_recv_time, ceph::mono_clock::now() - recv_start_time);\n  return;\n\n fail:\n  fault();\n}\n\nssize_t AsyncConnection::_process_connection()\n{\n  ssize_t r = 0;\n\n  switch(state) {\n    case STATE_WAIT_SEND:\n      {\n        std::lock_guard<std::mutex> l(write_lock);\n        if (!outcoming_bl.length()) {\n          assert(state_after_send);\n          state = state_after_send;\n          state_after_send = STATE_NONE;\n        }\n        break;\n      }\n\n    case STATE_CONNECTING:\n      {\n        assert(!policy.server);\n\n        // reset connect state variables\n        got_bad_auth = false;\n        delete authorizer;\n        authorizer = NULL;\n        authorizer_buf.clear();\n        memset(&connect_msg, 0, sizeof(connect_msg));\n        memset(&connect_reply, 0, sizeof(connect_reply));\n\n        global_seq = async_msgr->get_global_seq();\n        // close old socket.  this is safe because we stopped the reader thread above.\n        if (cs) {\n          center->delete_file_event(cs.fd(), EVENT_READABLE|EVENT_WRITABLE);\n          cs.close();\n        }\n\n        SocketOptions opts;\n        opts.priority = async_msgr->get_socket_priority();\n        opts.connect_bind_addr = msgr->get_myaddr();\n        r = worker->connect(get_peer_addr(), opts, &cs);\n        if (r < 0)\n          goto fail;\n\n        center->create_file_event(cs.fd(), EVENT_READABLE, read_handler);\n        state = STATE_CONNECTING_RE;\n        break;\n      }\n\n    case STATE_CONNECTING_RE:\n      {\n        r = cs.is_connected();\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" reconnect failed \" << dendl;\n          if (r == -ECONNREFUSED) {\n            ldout(async_msgr->cct, 2) << __func__ << \" connection refused!\" << dendl;\n            dispatch_queue->queue_refused(this);\n          }\n          goto fail;\n        } else if (r == 0) {\n          ldout(async_msgr->cct, 10) << __func__ << \" nonblock connect inprogress\" << dendl;\n          if (async_msgr->get_stack()->nonblock_connect_need_writable_event())\n            center->create_file_event(cs.fd(), EVENT_WRITABLE, read_handler);\n          break;\n        }\n\n        center->delete_file_event(cs.fd(), EVENT_WRITABLE);\n        ldout(async_msgr->cct, 10) << __func__ << \" connect successfully, ready to send banner\" << dendl;\n\n        bufferlist bl;\n        bl.append(CEPH_BANNER, strlen(CEPH_BANNER));\n        r = try_send(bl);\n        if (r == 0) {\n          state = STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY;\n          ldout(async_msgr->cct, 10) << __func__ << \" connect write banner done: \"\n                                     << get_peer_addr() << dendl;\n        } else if (r > 0) {\n          state = STATE_WAIT_SEND;\n          state_after_send = STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY;\n          ldout(async_msgr->cct, 10) << __func__ << \" connect wait for write banner: \"\n                               << get_peer_addr() << dendl;\n        } else {\n          goto fail;\n        }\n\n        break;\n      }\n\n    case STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY:\n      {\n        entity_addr_t paddr, peer_addr_for_me;\n        bufferlist myaddrbl;\n        unsigned banner_len = strlen(CEPH_BANNER);\n        unsigned need_len = banner_len + sizeof(ceph_entity_addr)*2;\n        r = read_until(need_len, state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read banner and identify addresses failed\" << dendl;\n          goto fail;\n        } else if (r > 0) {\n          break;\n        }\n\n        if (memcmp(state_buffer, CEPH_BANNER, banner_len)) {\n          ldout(async_msgr->cct, 0) << __func__ << \" connect protocol error (bad banner) on peer \"\n                                    << get_peer_addr() << dendl;\n          goto fail;\n        }\n\n        bufferlist bl;\n        bl.append(state_buffer+banner_len, sizeof(ceph_entity_addr)*2);\n        bufferlist::iterator p = bl.begin();\n        try {\n          ::decode(paddr, p);\n          ::decode(peer_addr_for_me, p);\n        } catch (const buffer::error& e) {\n          lderr(async_msgr->cct) << __func__ <<  \" decode peer addr failed \" << dendl;\n          goto fail;\n        }\n        ldout(async_msgr->cct, 20) << __func__ <<  \" connect read peer addr \"\n                             << paddr << \" on socket \" << cs.fd() << dendl;\n        if (peer_addr != paddr) {\n          if (paddr.is_blank_ip() && peer_addr.get_port() == paddr.get_port() &&\n              peer_addr.get_nonce() == paddr.get_nonce()) {\n            ldout(async_msgr->cct, 0) << __func__ <<  \" connect claims to be \" << paddr\n                                << \" not \" << peer_addr\n                                << \" - presumably this is the same node!\" << dendl;\n          } else {\n            ldout(async_msgr->cct, 10) << __func__ << \" connect claims to be \"\n\t\t\t\t       << paddr << \" not \" << peer_addr << dendl;\n\t    goto fail;\n          }\n        }\n\n        ldout(async_msgr->cct, 20) << __func__ << \" connect peer addr for me is \" << peer_addr_for_me << dendl;\n        lock.unlock();\n        async_msgr->learned_addr(peer_addr_for_me);\n        if (async_msgr->cct->_conf->ms_inject_internal_delays\n            && async_msgr->cct->_conf->ms_inject_socket_failures) {\n          if (rand() % async_msgr->cct->_conf->ms_inject_socket_failures == 0) {\n            ldout(msgr->cct, 10) << __func__ << \" sleep for \"\n                                 << async_msgr->cct->_conf->ms_inject_internal_delays << dendl;\n            utime_t t;\n            t.set_from_double(async_msgr->cct->_conf->ms_inject_internal_delays);\n            t.sleep();\n          }\n        }\n\n        lock.lock();\n        if (state != STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY) {\n          ldout(async_msgr->cct, 1) << __func__ << \" state changed while learned_addr, mark_down or \"\n                                    << \" replacing must be happened just now\" << dendl;\n          return 0;\n        }\n\n        ::encode(async_msgr->get_myaddr(), myaddrbl, 0); // legacy\n        r = try_send(myaddrbl);\n        if (r == 0) {\n          state = STATE_CONNECTING_SEND_CONNECT_MSG;\n          ldout(async_msgr->cct, 10) << __func__ << \" connect sent my addr \"\n              << async_msgr->get_myaddr() << dendl;\n        } else if (r > 0) {\n          state = STATE_WAIT_SEND;\n          state_after_send = STATE_CONNECTING_SEND_CONNECT_MSG;\n          ldout(async_msgr->cct, 10) << __func__ << \" connect send my addr done: \"\n              << async_msgr->get_myaddr() << dendl;\n        } else {\n          ldout(async_msgr->cct, 2) << __func__ << \" connect couldn't write my addr, \"\n              << cpp_strerror(r) << dendl;\n          goto fail;\n        }\n\n        break;\n      }\n\n    case STATE_CONNECTING_SEND_CONNECT_MSG:\n      {\n        if (!got_bad_auth) {\n          delete authorizer;\n          authorizer = async_msgr->get_authorizer(peer_type, false);\n        }\n        bufferlist bl;\n\n        connect_msg.features = policy.features_supported;\n        connect_msg.host_type = async_msgr->get_myinst().name.type();\n        connect_msg.global_seq = global_seq;\n        connect_msg.connect_seq = connect_seq;\n        connect_msg.protocol_version = async_msgr->get_proto_version(peer_type, true);\n        connect_msg.authorizer_protocol = authorizer ? authorizer->protocol : 0;\n        connect_msg.authorizer_len = authorizer ? authorizer->bl.length() : 0;\n        if (authorizer)\n          ldout(async_msgr->cct, 10) << __func__ <<  \" connect_msg.authorizer_len=\"\n                                     << connect_msg.authorizer_len << \" protocol=\"\n                                     << connect_msg.authorizer_protocol << dendl;\n        connect_msg.flags = 0;\n        if (policy.lossy)\n          connect_msg.flags |= CEPH_MSG_CONNECT_LOSSY;  // this is fyi, actually, server decides!\n        bl.append((char*)&connect_msg, sizeof(connect_msg));\n        if (authorizer) {\n          bl.append(authorizer->bl.c_str(), authorizer->bl.length());\n        }\n        ldout(async_msgr->cct, 10) << __func__ << \" connect sending gseq=\" << global_seq << \" cseq=\"\n            << connect_seq << \" proto=\" << connect_msg.protocol_version << dendl;\n\n        r = try_send(bl);\n        if (r == 0) {\n          state = STATE_CONNECTING_WAIT_CONNECT_REPLY;\n          ldout(async_msgr->cct,20) << __func__ << \" connect wrote (self +) cseq, waiting for reply\" << dendl;\n        } else if (r > 0) {\n          state = STATE_WAIT_SEND;\n          state_after_send = STATE_CONNECTING_WAIT_CONNECT_REPLY;\n          ldout(async_msgr->cct, 10) << __func__ << \" continue send reply \" << dendl;\n        } else {\n          ldout(async_msgr->cct, 2) << __func__ << \" connect couldn't send reply \"\n              << cpp_strerror(r) << dendl;\n          goto fail;\n        }\n\n        break;\n      }\n\n    case STATE_CONNECTING_WAIT_CONNECT_REPLY:\n      {\n        r = read_until(sizeof(connect_reply), state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read connect reply failed\" << dendl;\n          goto fail;\n        } else if (r > 0) {\n          break;\n        }\n\n        connect_reply = *((ceph_msg_connect_reply*)state_buffer);\n\n        ldout(async_msgr->cct, 20) << __func__ << \" connect got reply tag \" << (int)connect_reply.tag\n                             << \" connect_seq \" << connect_reply.connect_seq << \" global_seq \"\n                             << connect_reply.global_seq << \" proto \" << connect_reply.protocol_version\n                             << \" flags \" << (int)connect_reply.flags << \" features \"\n                             << connect_reply.features << dendl;\n        state = STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH;\n\n        break;\n      }\n\n    case STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH:\n      {\n        bufferlist authorizer_reply;\n        if (connect_reply.authorizer_len) {\n          ldout(async_msgr->cct, 10) << __func__ << \" reply.authorizer_len=\" << connect_reply.authorizer_len << dendl;\n          assert(connect_reply.authorizer_len < 4096);\n          r = read_until(connect_reply.authorizer_len, state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read connect reply authorizer failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          authorizer_reply.append(state_buffer, connect_reply.authorizer_len);\n          bufferlist::iterator iter = authorizer_reply.begin();\n          if (authorizer && !authorizer->verify_reply(iter)) {\n            ldout(async_msgr->cct, 0) << __func__ << \" failed verifying authorize reply\" << dendl;\n            goto fail;\n          }\n        }\n        r = handle_connect_reply(connect_msg, connect_reply);\n        if (r < 0)\n          goto fail;\n\n        // state must be changed!\n        assert(state != STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH);\n        break;\n      }\n\n    case STATE_CONNECTING_WAIT_ACK_SEQ:\n      {\n        uint64_t newly_acked_seq = 0;\n\n        r = read_until(sizeof(newly_acked_seq), state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read connect ack seq failed\" << dendl;\n          goto fail;\n        } else if (r > 0) {\n          break;\n        }\n\n        newly_acked_seq = *((uint64_t*)state_buffer);\n        ldout(async_msgr->cct, 2) << __func__ << \" got newly_acked_seq \" << newly_acked_seq\n                            << \" vs out_seq \" << out_seq << dendl;\n        discard_requeued_up_to(newly_acked_seq);\n        //while (newly_acked_seq > out_seq.read()) {\n        //  Message *m = _get_next_outgoing(NULL);\n        //  assert(m);\n        //  ldout(async_msgr->cct, 2) << __func__ << \" discarding previously sent \" << m->get_seq()\n        //                      << \" \" << *m << dendl;\n        //  assert(m->get_seq() <= newly_acked_seq);\n        //  m->put();\n        //  out_seq.inc();\n        //}\n\n        bufferlist bl;\n        uint64_t s = in_seq;\n        bl.append((char*)&s, sizeof(s));\n        r = try_send(bl);\n        if (r == 0) {\n          state = STATE_CONNECTING_READY;\n          ldout(async_msgr->cct, 10) << __func__ << \" send in_seq done \" << dendl;\n        } else if (r > 0) {\n          state_after_send = STATE_CONNECTING_READY;\n          state = STATE_WAIT_SEND;\n          ldout(async_msgr->cct, 10) << __func__ << \" continue send in_seq \" << dendl;\n        } else {\n          goto fail;\n        }\n        break;\n      }\n\n    case STATE_CONNECTING_READY:\n      {\n        // hooray!\n        peer_global_seq = connect_reply.global_seq;\n        policy.lossy = connect_reply.flags & CEPH_MSG_CONNECT_LOSSY;\n        state = STATE_OPEN;\n        once_ready = true;\n        connect_seq += 1;\n        assert(connect_seq == connect_reply.connect_seq);\n        backoff = utime_t();\n        set_features((uint64_t)connect_reply.features & (uint64_t)connect_msg.features);\n        ldout(async_msgr->cct, 10) << __func__ << \" connect success \" << connect_seq\n                                   << \", lossy = \" << policy.lossy << \", features \"\n                                   << get_features() << dendl;\n\n        // If we have an authorizer, get a new AuthSessionHandler to deal with ongoing security of the\n        // connection.  PLR\n        if (authorizer != NULL) {\n          session_security.reset(\n              get_auth_session_handler(async_msgr->cct,\n                                       authorizer->protocol,\n                                       authorizer->session_key,\n                                       get_features()));\n        } else {\n          // We have no authorizer, so we shouldn't be applying security to messages in this AsyncConnection.  PLR\n          session_security.reset();\n        }\n\n        if (delay_state)\n          assert(delay_state->ready());\n        dispatch_queue->queue_connect(this);\n        async_msgr->ms_deliver_handle_fast_connect(this);\n\n        // make sure no pending tick timer\n        if (last_tick_id)\n          center->delete_time_event(last_tick_id);\n        last_tick_id = center->create_time_event(inactive_timeout_us, tick_handler);\n\n        // message may in queue between last _try_send and connection ready\n        // write event may already notify and we need to force scheduler again\n        write_lock.lock();\n        can_write = WriteStatus::CANWRITE;\n        if (is_queued())\n          center->dispatch_event_external(write_handler);\n        write_lock.unlock();\n        maybe_start_delay_thread();\n        break;\n      }\n\n    case STATE_ACCEPTING:\n      {\n        bufferlist bl;\n        center->create_file_event(cs.fd(), EVENT_READABLE, read_handler);\n\n        bl.append(CEPH_BANNER, strlen(CEPH_BANNER));\n\n        ::encode(async_msgr->get_myaddr(), bl, 0); // legacy\n        port = async_msgr->get_myaddr().get_port();\n        ::encode(socket_addr, bl, 0); // legacy\n        ldout(async_msgr->cct, 1) << __func__ << \" sd=\" << cs.fd() << \" \" << socket_addr << dendl;\n\n        r = try_send(bl);\n        if (r == 0) {\n          state = STATE_ACCEPTING_WAIT_BANNER_ADDR;\n          ldout(async_msgr->cct, 10) << __func__ << \" write banner and addr done: \"\n            << get_peer_addr() << dendl;\n        } else if (r > 0) {\n          state = STATE_WAIT_SEND;\n          state_after_send = STATE_ACCEPTING_WAIT_BANNER_ADDR;\n          ldout(async_msgr->cct, 10) << __func__ << \" wait for write banner and addr: \"\n                              << get_peer_addr() << dendl;\n        } else {\n          goto fail;\n        }\n\n        break;\n      }\n    case STATE_ACCEPTING_WAIT_BANNER_ADDR:\n      {\n        bufferlist addr_bl;\n        entity_addr_t peer_addr;\n\n        r = read_until(strlen(CEPH_BANNER) + sizeof(ceph_entity_addr), state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read peer banner and addr failed\" << dendl;\n          goto fail;\n        } else if (r > 0) {\n          break;\n        }\n\n        if (memcmp(state_buffer, CEPH_BANNER, strlen(CEPH_BANNER))) {\n          ldout(async_msgr->cct, 1) << __func__ << \" accept peer sent bad banner '\" << state_buffer\n                                    << \"' (should be '\" << CEPH_BANNER << \"')\" << dendl;\n          goto fail;\n        }\n\n        addr_bl.append(state_buffer+strlen(CEPH_BANNER), sizeof(ceph_entity_addr));\n        {\n          bufferlist::iterator ti = addr_bl.begin();\n          ::decode(peer_addr, ti);\n        }\n\n        ldout(async_msgr->cct, 10) << __func__ << \" accept peer addr is \" << peer_addr << dendl;\n        if (peer_addr.is_blank_ip()) {\n          // peer apparently doesn't know what ip they have; figure it out for them.\n          int port = peer_addr.get_port();\n          peer_addr.u = socket_addr.u;\n          peer_addr.set_port(port);\n          ldout(async_msgr->cct, 0) << __func__ << \" accept peer addr is really \" << peer_addr\n                             << \" (socket is \" << socket_addr << \")\" << dendl;\n        }\n        set_peer_addr(peer_addr);  // so that connection_state gets set up\n        state = STATE_ACCEPTING_WAIT_CONNECT_MSG;\n        break;\n      }\n\n    case STATE_ACCEPTING_WAIT_CONNECT_MSG:\n      {\n        r = read_until(sizeof(connect_msg), state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read connect msg failed\" << dendl;\n          goto fail;\n        } else if (r > 0) {\n          break;\n        }\n\n        connect_msg = *((ceph_msg_connect*)state_buffer);\n        state = STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH;\n        break;\n      }\n\n    case STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH:\n      {\n        bufferlist authorizer_reply;\n\n        if (connect_msg.authorizer_len) {\n          if (!authorizer_buf.length())\n            authorizer_buf.push_back(buffer::create(connect_msg.authorizer_len));\n\n          r = read_until(connect_msg.authorizer_len, authorizer_buf.c_str());\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read connect authorizer failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n        }\n\n        ldout(async_msgr->cct, 20) << __func__ << \" accept got peer connect_seq \"\n                             << connect_msg.connect_seq << \" global_seq \"\n                             << connect_msg.global_seq << dendl;\n        set_peer_type(connect_msg.host_type);\n        policy = async_msgr->get_policy(connect_msg.host_type);\n        ldout(async_msgr->cct, 10) << __func__ << \" accept of host_type \" << connect_msg.host_type\n                                   << \", policy.lossy=\" << policy.lossy << \" policy.server=\"\n                                   << policy.server << \" policy.standby=\" << policy.standby\n                                   << \" policy.resetcheck=\" << policy.resetcheck << dendl;\n\n        r = handle_connect_msg(connect_msg, authorizer_buf, authorizer_reply);\n        if (r < 0)\n          goto fail;\n\n        // state is changed by \"handle_connect_msg\"\n        assert(state != STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH);\n        break;\n      }\n\n    case STATE_ACCEPTING_WAIT_SEQ:\n      {\n        uint64_t newly_acked_seq;\n        r = read_until(sizeof(newly_acked_seq), state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read ack seq failed\" << dendl;\n          goto fail_registered;\n        } else if (r > 0) {\n          break;\n        }\n\n        newly_acked_seq = *((uint64_t*)state_buffer);\n        ldout(async_msgr->cct, 2) << __func__ << \" accept get newly_acked_seq \" << newly_acked_seq << dendl;\n        discard_requeued_up_to(newly_acked_seq);\n        state = STATE_ACCEPTING_READY;\n        break;\n      }\n\n    case STATE_ACCEPTING_READY:\n      {\n        ldout(async_msgr->cct, 20) << __func__ << \" accept done\" << dendl;\n        state = STATE_OPEN;\n        memset(&connect_msg, 0, sizeof(connect_msg));\n\n        if (delay_state)\n          assert(delay_state->ready());\n        // make sure no pending tick timer\n        if (last_tick_id)\n          center->delete_time_event(last_tick_id);\n        last_tick_id = center->create_time_event(inactive_timeout_us, tick_handler);\n\n        write_lock.lock();\n        can_write = WriteStatus::CANWRITE;\n        if (is_queued())\n          center->dispatch_event_external(write_handler);\n        write_lock.unlock();\n        maybe_start_delay_thread();\n        break;\n      }\n\n    default:\n      {\n        lderr(async_msgr->cct) << __func__ << \" bad state: \" << state << dendl;\n        ceph_abort();\n      }\n  }\n\n  return 0;\n\nfail_registered:\n  ldout(async_msgr->cct, 10) << \"accept fault after register\" << dendl;\n  inject_delay();\n\nfail:\n  return -1;\n}\n\nint AsyncConnection::handle_connect_reply(ceph_msg_connect &connect, ceph_msg_connect_reply &reply)\n{\n  uint64_t feat_missing;\n  if (reply.tag == CEPH_MSGR_TAG_FEATURES) {\n    ldout(async_msgr->cct, 0) << __func__ << \" connect protocol feature mismatch, my \"\n                        << std::hex << connect.features << \" < peer \"\n                        << reply.features << \" missing \"\n                        << (reply.features & ~policy.features_supported)\n                        << std::dec << dendl;\n    goto fail;\n  }\n\n  if (reply.tag == CEPH_MSGR_TAG_BADPROTOVER) {\n    ldout(async_msgr->cct, 0) << __func__ << \" connect protocol version mismatch, my \"\n                        << connect.protocol_version << \" != \" << reply.protocol_version\n                        << dendl;\n    goto fail;\n  }\n\n  if (reply.tag == CEPH_MSGR_TAG_BADAUTHORIZER) {\n    ldout(async_msgr->cct,0) << __func__ << \" connect got BADAUTHORIZER\" << dendl;\n    if (got_bad_auth)\n      goto fail;\n    got_bad_auth = true;\n    delete authorizer;\n    authorizer = async_msgr->get_authorizer(peer_type, true);  // try harder\n    state = STATE_CONNECTING_SEND_CONNECT_MSG;\n  }\n  if (reply.tag == CEPH_MSGR_TAG_RESETSESSION) {\n    ldout(async_msgr->cct, 0) << __func__ << \" connect got RESETSESSION\" << dendl;\n    was_session_reset();\n    // see was_session_reset\n    outcoming_bl.clear();\n    state = STATE_CONNECTING_SEND_CONNECT_MSG;\n  }\n  if (reply.tag == CEPH_MSGR_TAG_RETRY_GLOBAL) {\n    global_seq = async_msgr->get_global_seq(reply.global_seq);\n    ldout(async_msgr->cct, 5) << __func__ << \" connect got RETRY_GLOBAL \"\n                              << reply.global_seq << \" chose new \"\n                              << global_seq << dendl;\n    state = STATE_CONNECTING_SEND_CONNECT_MSG;\n  }\n  if (reply.tag == CEPH_MSGR_TAG_RETRY_SESSION) {\n    assert(reply.connect_seq > connect_seq);\n    ldout(async_msgr->cct, 5) << __func__ << \" connect got RETRY_SESSION \"\n                              << connect_seq << \" -> \"\n                              << reply.connect_seq << dendl;\n    connect_seq = reply.connect_seq;\n    state = STATE_CONNECTING_SEND_CONNECT_MSG;\n  }\n  if (reply.tag == CEPH_MSGR_TAG_WAIT) {\n    ldout(async_msgr->cct, 1) << __func__ << \" connect got WAIT (connection race)\" << dendl;\n    state = STATE_WAIT;\n  }\n\n  feat_missing = policy.features_required & ~(uint64_t)connect_reply.features;\n  if (feat_missing) {\n    ldout(async_msgr->cct, 1) << __func__ << \" missing required features \" << std::hex\n                              << feat_missing << std::dec << dendl;\n    goto fail;\n  }\n\n  if (reply.tag == CEPH_MSGR_TAG_SEQ) {\n    ldout(async_msgr->cct, 10) << __func__ << \" got CEPH_MSGR_TAG_SEQ, reading acked_seq and writing in_seq\" << dendl;\n    state = STATE_CONNECTING_WAIT_ACK_SEQ;\n  }\n  if (reply.tag == CEPH_MSGR_TAG_READY) {\n    ldout(async_msgr->cct, 10) << __func__ << \" got CEPH_MSGR_TAG_READY \" << dendl;\n    state = STATE_CONNECTING_READY;\n  }\n\n  return 0;\n\n fail:\n  return -1;\n}\n\nssize_t AsyncConnection::handle_connect_msg(ceph_msg_connect &connect, bufferlist &authorizer_bl,\n                                            bufferlist &authorizer_reply)\n{\n  ssize_t r = 0;\n  ceph_msg_connect_reply reply;\n  bufferlist reply_bl;\n\n  memset(&reply, 0, sizeof(reply));\n  reply.protocol_version = async_msgr->get_proto_version(peer_type, false);\n\n  // mismatch?\n  ldout(async_msgr->cct, 10) << __func__ << \" accept my proto \" << reply.protocol_version\n                      << \", their proto \" << connect.protocol_version << dendl;\n  if (connect.protocol_version != reply.protocol_version) {\n    return _reply_accept(CEPH_MSGR_TAG_BADPROTOVER, connect, reply, authorizer_reply);\n  }\n  // require signatures for cephx?\n  if (connect.authorizer_protocol == CEPH_AUTH_CEPHX) {\n    if (peer_type == CEPH_ENTITY_TYPE_OSD ||\n        peer_type == CEPH_ENTITY_TYPE_MDS ||\n\tpeer_type == CEPH_ENTITY_TYPE_MGR) {\n      if (async_msgr->cct->_conf->cephx_require_signatures ||\n          async_msgr->cct->_conf->cephx_cluster_require_signatures) {\n        ldout(async_msgr->cct, 10) << __func__ << \" using cephx, requiring MSG_AUTH feature bit for cluster\" << dendl;\n        policy.features_required |= CEPH_FEATURE_MSG_AUTH;\n      }\n      if (async_msgr->cct->_conf->cephx_require_version >= 2 ||\n\t  async_msgr->cct->_conf->cephx_cluster_require_version >= 2) {\n        ldout(async_msgr->cct, 10) << __func__ << \" using cephx, requiring cephx v2 feature bit for cluster\" << dendl;\n        policy.features_required |= CEPH_FEATUREMASK_CEPHX_V2;\n      }\n    } else {\n      if (async_msgr->cct->_conf->cephx_require_signatures ||\n          async_msgr->cct->_conf->cephx_service_require_signatures) {\n        ldout(async_msgr->cct, 10) << __func__ << \" using cephx, requiring MSG_AUTH feature bit for service\" << dendl;\n        policy.features_required |= CEPH_FEATURE_MSG_AUTH;\n      }\n      if (async_msgr->cct->_conf->cephx_require_version >= 2 ||\n\t  async_msgr->cct->_conf->cephx_service_require_version >= 2) {\n        ldout(async_msgr->cct, 10) << __func__ << \" using cephx, requiring cephx v2 feature bit for service\" << dendl;\n        policy.features_required |= CEPH_FEATUREMASK_CEPHX_V2;\n      }\n    }\n  }\n\n  uint64_t feat_missing = policy.features_required & ~(uint64_t)connect.features;\n  if (feat_missing) {\n    ldout(async_msgr->cct, 1) << __func__ << \" peer missing required features \"\n                        << std::hex << feat_missing << std::dec << dendl;\n    return _reply_accept(CEPH_MSGR_TAG_FEATURES, connect, reply, authorizer_reply);\n  }\n\n  lock.unlock();\n\n  bool authorizer_valid;\n  if (!async_msgr->verify_authorizer(this, peer_type, connect.authorizer_protocol, authorizer_bl,\n                               authorizer_reply, authorizer_valid, session_key) || !authorizer_valid) {\n    lock.lock();\n    ldout(async_msgr->cct,0) << __func__ << \": got bad authorizer\" << dendl;\n    session_security.reset();\n    return _reply_accept(CEPH_MSGR_TAG_BADAUTHORIZER, connect, reply, authorizer_reply);\n  }\n\n  // We've verified the authorizer for this AsyncConnection, so set up the session security structure.  PLR\n  ldout(async_msgr->cct, 10) << __func__ << \" accept setting up session_security.\" << dendl;\n\n  // existing?\n  AsyncConnectionRef existing = async_msgr->lookup_conn(peer_addr);\n\n  inject_delay();\n\n  lock.lock();\n  if (state != STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH) {\n    ldout(async_msgr->cct, 1) << __func__ << \" state changed while accept, it must be mark_down\" << dendl;\n    assert(state == STATE_CLOSED);\n    goto fail;\n  }\n\n  if (existing == this)\n    existing = NULL;\n  if (existing) {\n    // There is no possible that existing connection will acquire this\n    // connection's lock\n    existing->lock.lock();  // skip lockdep check (we are locking a second AsyncConnection here)\n\n    if (existing->state == STATE_CLOSED) {\n      ldout(async_msgr->cct, 1) << __func__ << \" existing already closed.\" << dendl;\n      existing->lock.unlock();\n      existing = NULL;\n      goto open;\n    }\n\n    if (existing->replacing) {\n      ldout(async_msgr->cct, 1) << __func__ << \" existing racing replace happened while replacing.\"\n                                << \" existing_state=\" << get_state_name(existing->state) << dendl;\n      reply.global_seq = existing->peer_global_seq;\n      r = _reply_accept(CEPH_MSGR_TAG_RETRY_GLOBAL, connect, reply, authorizer_reply);\n      existing->lock.unlock();\n      if (r < 0)\n        goto fail;\n      return 0;\n    }\n\n    if (connect.global_seq < existing->peer_global_seq) {\n      ldout(async_msgr->cct, 10) << __func__ << \" accept existing \" << existing\n                           << \".gseq \" << existing->peer_global_seq << \" > \"\n                           << connect.global_seq << \", RETRY_GLOBAL\" << dendl;\n      reply.global_seq = existing->peer_global_seq;  // so we can send it below..\n      existing->lock.unlock();\n      return _reply_accept(CEPH_MSGR_TAG_RETRY_GLOBAL, connect, reply, authorizer_reply);\n    } else {\n      ldout(async_msgr->cct, 10) << __func__ << \" accept existing \" << existing\n                           << \".gseq \" << existing->peer_global_seq\n                           << \" <= \" << connect.global_seq << \", looks ok\" << dendl;\n    }\n\n    if (existing->policy.lossy) {\n      ldout(async_msgr->cct, 0) << __func__ << \" accept replacing existing (lossy) channel (new one lossy=\"\n                          << policy.lossy << \")\" << dendl;\n      existing->was_session_reset();\n      goto replace;\n    }\n\n    ldout(async_msgr->cct, 0) << __func__ << \" accept connect_seq \" << connect.connect_seq\n                              << \" vs existing csq=\" << existing->connect_seq << \" existing_state=\"\n                              << get_state_name(existing->state) << dendl;\n\n    if (connect.connect_seq == 0 && existing->connect_seq > 0) {\n      ldout(async_msgr->cct,0) << __func__ << \" accept peer reset, then tried to connect to us, replacing\" << dendl;\n      // this is a hard reset from peer\n      is_reset_from_peer = true;\n      if (policy.resetcheck)\n        existing->was_session_reset(); // this resets out_queue, msg_ and connect_seq #'s\n      goto replace;\n    }\n\n    if (connect.connect_seq < existing->connect_seq) {\n      // old attempt, or we sent READY but they didn't get it.\n      ldout(async_msgr->cct, 10) << __func__ << \" accept existing \" << existing << \".cseq \"\n                           << existing->connect_seq << \" > \" << connect.connect_seq\n                           << \", RETRY_SESSION\" << dendl;\n      reply.connect_seq = existing->connect_seq + 1;\n      existing->lock.unlock();\n      return _reply_accept(CEPH_MSGR_TAG_RETRY_SESSION, connect, reply, authorizer_reply);\n    }\n\n    if (connect.connect_seq == existing->connect_seq) {\n      // if the existing connection successfully opened, and/or\n      // subsequently went to standby, then the peer should bump\n      // their connect_seq and retry: this is not a connection race\n      // we need to resolve here.\n      if (existing->state == STATE_OPEN ||\n          existing->state == STATE_STANDBY) {\n        ldout(async_msgr->cct, 10) << __func__ << \" accept connection race, existing \" << existing\n                             << \".cseq \" << existing->connect_seq << \" == \"\n                             << connect.connect_seq << \", OPEN|STANDBY, RETRY_SESSION\" << dendl;\n        reply.connect_seq = existing->connect_seq + 1;\n        existing->lock.unlock();\n        return _reply_accept(CEPH_MSGR_TAG_RETRY_SESSION, connect, reply, authorizer_reply);\n      }\n\n      // connection race?\n      if (peer_addr < async_msgr->get_myaddr() || existing->policy.server) {\n        // incoming wins\n        ldout(async_msgr->cct, 10) << __func__ << \" accept connection race, existing \" << existing\n                             << \".cseq \" << existing->connect_seq << \" == \" << connect.connect_seq\n                             << \", or we are server, replacing my attempt\" << dendl;\n        goto replace;\n      } else {\n        // our existing outgoing wins\n        ldout(async_msgr->cct,10) << __func__ << \" accept connection race, existing \"\n                            << existing << \".cseq \" << existing->connect_seq\n                            << \" == \" << connect.connect_seq << \", sending WAIT\" << dendl;\n        assert(peer_addr > async_msgr->get_myaddr());\n        existing->lock.unlock();\n        return _reply_accept(CEPH_MSGR_TAG_WAIT, connect, reply, authorizer_reply);\n      }\n    }\n\n    assert(connect.connect_seq > existing->connect_seq);\n    assert(connect.global_seq >= existing->peer_global_seq);\n    if (policy.resetcheck &&   // RESETSESSION only used by servers; peers do not reset each other\n        existing->connect_seq == 0) {\n      ldout(async_msgr->cct, 0) << __func__ << \" accept we reset (peer sent cseq \"\n                          << connect.connect_seq << \", \" << existing << \".cseq = \"\n                          << existing->connect_seq << \"), sending RESETSESSION\" << dendl;\n      existing->lock.unlock();\n      return _reply_accept(CEPH_MSGR_TAG_RESETSESSION, connect, reply, authorizer_reply);\n    }\n\n    // reconnect\n    ldout(async_msgr->cct, 10) << __func__ << \" accept peer sent cseq \" << connect.connect_seq\n                         << \" > \" << existing->connect_seq << dendl;\n    goto replace;\n  } // existing\n  else if (!replacing && connect.connect_seq > 0) {\n    // we reset, and they are opening a new session\n    ldout(async_msgr->cct, 0) << __func__ << \" accept we reset (peer sent cseq \"\n                        << connect.connect_seq << \"), sending RESETSESSION\" << dendl;\n    return _reply_accept(CEPH_MSGR_TAG_RESETSESSION, connect, reply, authorizer_reply);\n  } else {\n    // new session\n    ldout(async_msgr->cct, 10) << __func__ << \" accept new session\" << dendl;\n    existing = NULL;\n    goto open;\n  }\n  ceph_abort();\n\n replace:\n  ldout(async_msgr->cct, 10) << __func__ << \" accept replacing \" << existing << dendl;\n\n  inject_delay();\n  if (existing->policy.lossy) {\n    // disconnect from the Connection\n    ldout(async_msgr->cct, 1) << __func__ << \" replacing on lossy channel, failing existing\" << dendl;\n    existing->_stop();\n    existing->dispatch_queue->queue_reset(existing.get());\n  } else {\n    assert(can_write == WriteStatus::NOWRITE);\n    existing->write_lock.lock();\n\n    // reset the in_seq if this is a hard reset from peer,\n    // otherwise we respect our original connection's value\n    if (is_reset_from_peer) {\n      existing->is_reset_from_peer = true;\n    }\n\n    center->delete_file_event(cs.fd(), EVENT_READABLE|EVENT_WRITABLE);\n\n    if (existing->delay_state) {\n      existing->delay_state->flush();\n      assert(!delay_state);\n    }\n    existing->reset_recv_state();\n\n    auto temp_cs = std::move(cs);\n    EventCenter *new_center = center;\n    Worker *new_worker = worker;\n    // avoid _stop shutdown replacing socket\n    // queue a reset on the new connection, which we're dumping for the old\n    _stop();\n\n    dispatch_queue->queue_reset(this);\n    ldout(async_msgr->cct, 1) << __func__ << \" stop myself to swap existing\" << dendl;\n    existing->can_write = WriteStatus::REPLACING;\n    existing->replacing = true;\n    existing->state_offset = 0;\n    // avoid previous thread modify event\n    existing->state = STATE_NONE;\n    // Discard existing prefetch buffer in `recv_buf`\n    existing->recv_start = existing->recv_end = 0;\n    // there shouldn't exist any buffer\n    assert(recv_start == recv_end);\n\n    auto deactivate_existing = std::bind(\n        [existing, new_worker, new_center, connect, reply, authorizer_reply](ConnectedSocket &cs) mutable {\n      // we need to delete time event in original thread\n      {\n        std::lock_guard<std::mutex> l(existing->lock);\n        existing->write_lock.lock();\n        existing->requeue_sent();\n        existing->outcoming_bl.clear();\n        existing->open_write = false;\n        existing->write_lock.unlock();\n        if (existing->state == STATE_NONE) {\n          existing->shutdown_socket();\n          existing->cs = std::move(cs);\n          existing->worker->references--;\n          new_worker->references++;\n          existing->logger = new_worker->get_perf_counter();\n          existing->worker = new_worker;\n          existing->center = new_center;\n          if (existing->delay_state)\n            existing->delay_state->set_center(new_center);\n        } else if (existing->state == STATE_CLOSED) {\n          auto back_to_close = std::bind(\n            [](ConnectedSocket &cs) mutable { cs.close(); }, std::move(cs));\n          new_center->submit_to(\n              new_center->get_id(), std::move(back_to_close), true);\n          return ;\n        } else {\n          ceph_abort();\n        }\n      }\n\n      // Before changing existing->center, it may already exists some events in existing->center's queue.\n      // Then if we mark down `existing`, it will execute in another thread and clean up connection.\n      // Previous event will result in segment fault\n      auto transfer_existing = [existing, connect, reply, authorizer_reply]() mutable {\n        std::lock_guard<std::mutex> l(existing->lock);\n        if (existing->state == STATE_CLOSED)\n          return ;\n        assert(existing->state == STATE_NONE);\n  \n        existing->state = STATE_ACCEPTING_WAIT_CONNECT_MSG;\n        existing->center->create_file_event(existing->cs.fd(), EVENT_READABLE, existing->read_handler);\n        reply.global_seq = existing->peer_global_seq;\n        if (existing->_reply_accept(CEPH_MSGR_TAG_RETRY_GLOBAL, connect, reply, authorizer_reply) < 0) {\n          // handle error\n          existing->fault();\n        }\n      };\n      if (existing->center->in_thread())\n        transfer_existing();\n      else\n        existing->center->submit_to(\n            existing->center->get_id(), std::move(transfer_existing), true);\n    }, std::move(temp_cs));\n\n    existing->center->submit_to(\n        existing->center->get_id(), std::move(deactivate_existing), true);\n    existing->write_lock.unlock();\n    existing->lock.unlock();\n    return 0;\n  }\n  existing->lock.unlock();\n\n open:\n  connect_seq = connect.connect_seq + 1;\n  peer_global_seq = connect.global_seq;\n  ldout(async_msgr->cct, 10) << __func__ << \" accept success, connect_seq = \"\n                             << connect_seq << \" in_seq=\" << in_seq << \", sending READY\" << dendl;\n\n  int next_state;\n\n  // if it is a hard reset from peer, we don't need a round-trip to negotiate in/out sequence\n  if ((connect.features & CEPH_FEATURE_RECONNECT_SEQ) && !is_reset_from_peer) {\n    reply.tag = CEPH_MSGR_TAG_SEQ;\n    next_state = STATE_ACCEPTING_WAIT_SEQ;\n  } else {\n    reply.tag = CEPH_MSGR_TAG_READY;\n    next_state = STATE_ACCEPTING_READY;\n    discard_requeued_up_to(0);\n    is_reset_from_peer = false;\n    in_seq = 0;\n  }\n\n  // send READY reply\n  reply.features = policy.features_supported;\n  reply.global_seq = async_msgr->get_global_seq();\n  reply.connect_seq = connect_seq;\n  reply.flags = 0;\n  reply.authorizer_len = authorizer_reply.length();\n  if (policy.lossy)\n    reply.flags = reply.flags | CEPH_MSG_CONNECT_LOSSY;\n\n  set_features((uint64_t)reply.features & (uint64_t)connect.features);\n  ldout(async_msgr->cct, 10) << __func__ << \" accept features \" << get_features() << dendl;\n\n  session_security.reset(\n      get_auth_session_handler(async_msgr->cct, connect.authorizer_protocol,\n                               session_key, get_features()));\n\n  reply_bl.append((char*)&reply, sizeof(reply));\n\n  if (reply.authorizer_len)\n    reply_bl.append(authorizer_reply.c_str(), authorizer_reply.length());\n\n  if (reply.tag == CEPH_MSGR_TAG_SEQ) {\n    uint64_t s = in_seq;\n    reply_bl.append((char*)&s, sizeof(s));\n  }\n\n  lock.unlock();\n  // Because \"replacing\" will prevent other connections preempt this addr,\n  // it's safe that here we don't acquire Connection's lock\n  r = async_msgr->accept_conn(this);\n\n  inject_delay();\n  \n  lock.lock();\n  replacing = false;\n  if (r < 0) {\n    ldout(async_msgr->cct, 1) << __func__ << \" existing race replacing process for addr=\" << peer_addr\n                              << \" just fail later one(this)\" << dendl;\n    goto fail_registered;\n  }\n  if (state != STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH) {\n    ldout(async_msgr->cct, 1) << __func__ << \" state changed while accept_conn, it must be mark_down\" << dendl;\n    assert(state == STATE_CLOSED || state == STATE_NONE);\n    goto fail_registered;\n  }\n\n  r = try_send(reply_bl);\n  if (r < 0)\n    goto fail_registered;\n\n  // notify\n  dispatch_queue->queue_accept(this);\n  async_msgr->ms_deliver_handle_fast_accept(this);\n  once_ready = true;\n\n  if (r == 0) {\n    state = next_state;\n    ldout(async_msgr->cct, 2) << __func__ << \" accept write reply msg done\" << dendl;\n  } else {\n    state = STATE_WAIT_SEND;\n    state_after_send = next_state;\n  }\n\n  return 0;\n\n fail_registered:\n  ldout(async_msgr->cct, 10) << __func__ << \" accept fault after register\" << dendl;\n  inject_delay();\n\n fail:\n  ldout(async_msgr->cct, 10) << __func__ << \" failed to accept.\" << dendl;\n  return -1;\n}\n\nvoid AsyncConnection::_connect()\n{\n  ldout(async_msgr->cct, 10) << __func__ << \" csq=\" << connect_seq << dendl;\n\n  state = STATE_CONNECTING;\n  // rescheduler connection in order to avoid lock dep\n  // may called by external thread(send_message)\n  center->dispatch_event_external(read_handler);\n}\n\nvoid AsyncConnection::accept(ConnectedSocket socket, entity_addr_t &addr)\n{\n  ldout(async_msgr->cct, 10) << __func__ << \" sd=\" << socket.fd() << dendl;\n  assert(socket.fd() >= 0);\n\n  std::lock_guard<std::mutex> l(lock);\n  cs = std::move(socket);\n  socket_addr = addr;\n  state = STATE_ACCEPTING;\n  // rescheduler connection in order to avoid lock dep\n  center->dispatch_event_external(read_handler);\n}\n\nint AsyncConnection::send_message(Message *m)\n{\n  FUNCTRACE();\n  lgeneric_subdout(async_msgr->cct, ms,\n\t\t   1) << \"-- \" << async_msgr->get_myaddr() << \" --> \"\n\t\t      << get_peer_addr() << \" -- \"\n\t\t      << *m << \" -- \" << m << \" con \"\n\t\t      << m->get_connection().get()\n\t\t      << dendl;\n\n  // optimistic think it's ok to encode(actually may broken now)\n  if (!m->get_priority())\n    m->set_priority(async_msgr->get_default_send_priority());\n\n  m->get_header().src = async_msgr->get_myname();\n  m->set_connection(this);\n\n  if (m->get_type() == CEPH_MSG_OSD_OP)\n    OID_EVENT_TRACE_WITH_MSG(m, \"SEND_MSG_OSD_OP_BEGIN\", true);\n  else if (m->get_type() == CEPH_MSG_OSD_OPREPLY)\n    OID_EVENT_TRACE_WITH_MSG(m, \"SEND_MSG_OSD_OPREPLY_BEGIN\", true);\n\n  if (async_msgr->get_myaddr() == get_peer_addr()) { //loopback connection\n    ldout(async_msgr->cct, 20) << __func__ << \" \" << *m << \" local\" << dendl;\n    std::lock_guard<std::mutex> l(write_lock);\n    if (can_write != WriteStatus::CLOSED) {\n      dispatch_queue->local_delivery(m, m->get_priority());\n    } else {\n      ldout(async_msgr->cct, 10) << __func__ << \" loopback connection closed.\"\n                                 << \" Drop message \" << m << dendl;\n      m->put();\n    }\n    return 0;\n  }\n\n  last_active = ceph::coarse_mono_clock::now();\n  // we don't want to consider local message here, it's too lightweight which\n  // may disturb users\n  logger->inc(l_msgr_send_messages);\n\n  bufferlist bl;\n  uint64_t f = get_features();\n\n  // TODO: Currently not all messages supports reencode like MOSDMap, so here\n  // only let fast dispatch support messages prepare message\n  bool can_fast_prepare = async_msgr->ms_can_fast_dispatch(m);\n  if (can_fast_prepare)\n    prepare_send_message(f, m, bl);\n\n  std::lock_guard<std::mutex> l(write_lock);\n  // \"features\" changes will change the payload encoding\n  if (can_fast_prepare && (can_write == WriteStatus::NOWRITE || get_features() != f)) {\n    // ensure the correctness of message encoding\n    bl.clear();\n    m->get_payload().clear();\n    ldout(async_msgr->cct, 5) << __func__ << \" clear encoded buffer previous \"\n                              << f << \" != \" << get_features() << dendl;\n  }\n  if (can_write == WriteStatus::CLOSED) {\n    ldout(async_msgr->cct, 10) << __func__ << \" connection closed.\"\n                               << \" Drop message \" << m << dendl;\n    m->put();\n  } else {\n    m->trace.event(\"async enqueueing message\");\n    out_q[m->get_priority()].emplace_back(std::move(bl), m);\n    ldout(async_msgr->cct, 15) << __func__ << \" inline write is denied, reschedule m=\" << m << dendl;\n    if (can_write != WriteStatus::REPLACING)\n      center->dispatch_event_external(write_handler);\n  }\n  return 0;\n}\n\nvoid AsyncConnection::requeue_sent()\n{\n  if (sent.empty())\n    return;\n\n  list<pair<bufferlist, Message*> >& rq = out_q[CEPH_MSG_PRIO_HIGHEST];\n  while (!sent.empty()) {\n    Message* m = sent.back();\n    sent.pop_back();\n    ldout(async_msgr->cct, 10) << __func__ << \" \" << *m << \" for resend \"\n                               << \" (\" << m->get_seq() << \")\" << dendl;\n    rq.push_front(make_pair(bufferlist(), m));\n    out_seq--;\n  }\n}\n\nvoid AsyncConnection::discard_requeued_up_to(uint64_t seq)\n{\n  ldout(async_msgr->cct, 10) << __func__ << \" \" << seq << dendl;\n  std::lock_guard<std::mutex> l(write_lock);\n  if (out_q.count(CEPH_MSG_PRIO_HIGHEST) == 0)\n    return;\n  list<pair<bufferlist, Message*> >& rq = out_q[CEPH_MSG_PRIO_HIGHEST];\n  while (!rq.empty()) {\n    pair<bufferlist, Message*> p = rq.front();\n    if (p.second->get_seq() == 0 || p.second->get_seq() > seq)\n      break;\n    ldout(async_msgr->cct, 10) << __func__ << \" \" << *(p.second) << \" for resend seq \" << p.second->get_seq()\n                         << \" <= \" << seq << \", discarding\" << dendl;\n    p.second->put();\n    rq.pop_front();\n    out_seq++;\n  }\n  if (rq.empty())\n    out_q.erase(CEPH_MSG_PRIO_HIGHEST);\n}\n\n/*\n * Tears down the AsyncConnection's message queues, and removes them from the DispatchQueue\n * Must hold write_lock prior to calling.\n */\nvoid AsyncConnection::discard_out_queue()\n{\n  ldout(async_msgr->cct, 10) << __func__ << \" started\" << dendl;\n\n  for (list<Message*>::iterator p = sent.begin(); p != sent.end(); ++p) {\n    ldout(async_msgr->cct, 20) << __func__ << \" discard \" << *p << dendl;\n    (*p)->put();\n  }\n  sent.clear();\n  for (map<int, list<pair<bufferlist, Message*> > >::iterator p = out_q.begin(); p != out_q.end(); ++p)\n    for (list<pair<bufferlist, Message*> >::iterator r = p->second.begin(); r != p->second.end(); ++r) {\n      ldout(async_msgr->cct, 20) << __func__ << \" discard \" << r->second << dendl;\n      r->second->put();\n    }\n  out_q.clear();\n}\n\nint AsyncConnection::randomize_out_seq()\n{\n  if (get_features() & CEPH_FEATURE_MSG_AUTH) {\n    // Set out_seq to a random value, so CRC won't be predictable.   Don't bother checking seq_error\n    // here.  We'll check it on the call.  PLR\n    uint64_t rand_seq;\n    int seq_error = get_random_bytes((char *)&rand_seq, sizeof(rand_seq));\n    rand_seq &= SEQ_MASK;\n    lsubdout(async_msgr->cct, ms, 10) << __func__ << \" randomize_out_seq \" << rand_seq << dendl;\n    out_seq = rand_seq;\n    return seq_error;\n  } else {\n    // previously, seq #'s always started at 0.\n    out_seq = 0;\n    return 0;\n  }\n}\n\nvoid AsyncConnection::fault()\n{\n  if (state == STATE_CLOSED || state == STATE_NONE) {\n    ldout(async_msgr->cct, 10) << __func__ << \" connection is already closed\" << dendl;\n    return ;\n  }\n\n  if (policy.lossy && !(state >= STATE_CONNECTING && state < STATE_CONNECTING_READY)) {\n    ldout(async_msgr->cct, 1) << __func__ << \" on lossy channel, failing\" << dendl;\n    _stop();\n    dispatch_queue->queue_reset(this);\n    return ;\n  }\n\n  write_lock.lock();\n  can_write = WriteStatus::NOWRITE;\n  shutdown_socket();\n  open_write = false;\n\n  // queue delayed items immediately\n  if (delay_state)\n    delay_state->flush();\n  // requeue sent items\n  requeue_sent();\n  recv_start = recv_end = 0;\n  state_offset = 0;\n  replacing = false;\n  is_reset_from_peer = false;\n  outcoming_bl.clear();\n  if (!once_ready && !is_queued() &&\n      state >=STATE_ACCEPTING && state <= STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH) {\n    ldout(async_msgr->cct, 10) << __func__ << \" with nothing to send and in the half \"\n                              << \" accept state just closed\" << dendl;\n    write_lock.unlock();\n    _stop();\n    dispatch_queue->queue_reset(this);\n    return ;\n  }\n  reset_recv_state();\n  if (policy.standby && !is_queued() && state != STATE_WAIT) {\n    ldout(async_msgr->cct, 10) << __func__ << \" with nothing to send, going to standby\" << dendl;\n    state = STATE_STANDBY;\n    write_lock.unlock();\n    return;\n  }\n\n  write_lock.unlock();\n  if (!(state >= STATE_CONNECTING && state < STATE_CONNECTING_READY) &&\n      state != STATE_WAIT) { // STATE_WAIT is coming from STATE_CONNECTING_*\n    // policy maybe empty when state is in accept\n    if (policy.server) {\n      ldout(async_msgr->cct, 0) << __func__ << \" server, going to standby\" << dendl;\n      state = STATE_STANDBY;\n    } else {\n      ldout(async_msgr->cct, 0) << __func__ << \" initiating reconnect\" << dendl;\n      connect_seq++;\n      state = STATE_CONNECTING;\n    }\n    backoff = utime_t();\n    center->dispatch_event_external(read_handler);\n  } else {\n    if (state == STATE_WAIT) {\n      backoff.set_from_double(async_msgr->cct->_conf->ms_max_backoff);\n    } else if (backoff == utime_t()) {\n      backoff.set_from_double(async_msgr->cct->_conf->ms_initial_backoff);\n    } else {\n      backoff += backoff;\n      if (backoff > async_msgr->cct->_conf->ms_max_backoff)\n        backoff.set_from_double(async_msgr->cct->_conf->ms_max_backoff);\n    }\n\n    state = STATE_CONNECTING;\n    ldout(async_msgr->cct, 10) << __func__ << \" waiting \" << backoff << dendl;\n    // woke up again;\n    register_time_events.insert(center->create_time_event(\n            backoff.to_nsec()/1000, wakeup_handler));\n  }\n}\n\nvoid AsyncConnection::was_session_reset()\n{\n  ldout(async_msgr->cct,10) << __func__ << \" started\" << dendl;\n  std::lock_guard<std::mutex> l(write_lock);\n  if (delay_state)\n    delay_state->discard();\n  dispatch_queue->discard_queue(conn_id);\n  discard_out_queue();\n  // note: we need to clear outcoming_bl here, but was_session_reset may be\n  // called by other thread, so let caller clear this itself!\n  // outcoming_bl.clear();\n\n  dispatch_queue->queue_remote_reset(this);\n\n  if (randomize_out_seq()) {\n    ldout(async_msgr->cct, 15) << __func__ << \" could not get random bytes to set seq number for session reset; set seq number to \" << out_seq << dendl;\n  }\n\n  in_seq = 0;\n  connect_seq = 0;\n  // it's safe to directly set 0, double locked\n  ack_left = 0;\n  once_ready = false;\n  can_write = WriteStatus::NOWRITE;\n}\n\nvoid AsyncConnection::_stop()\n{\n  if (state == STATE_CLOSED)\n    return ;\n\n  if (delay_state)\n    delay_state->flush();\n\n  ldout(async_msgr->cct, 2) << __func__ << dendl;\n  std::lock_guard<std::mutex> l(write_lock);\n\n  reset_recv_state();\n  dispatch_queue->discard_queue(conn_id);\n  discard_out_queue();\n  async_msgr->unregister_conn(this);\n  worker->release_worker();\n\n  state = STATE_CLOSED;\n  open_write = false;\n  can_write = WriteStatus::CLOSED;\n  state_offset = 0;\n  // Make sure in-queue events will been processed\n  center->dispatch_event_external(EventCallbackRef(new C_clean_handler(this)));\n}\n\nvoid AsyncConnection::prepare_send_message(uint64_t features, Message *m, bufferlist &bl)\n{\n  ldout(async_msgr->cct, 20) << __func__ << \" m\" << \" \" << *m << dendl;\n\n  // associate message with Connection (for benefit of encode_payload)\n  if (m->empty_payload())\n    ldout(async_msgr->cct, 20) << __func__ << \" encoding features \"\n                               << features << \" \" << m << \" \" << *m << dendl;\n  else\n    ldout(async_msgr->cct, 20) << __func__ << \" half-reencoding features \"\n                               << features << \" \" << m << \" \" << *m << dendl;\n\n  // encode and copy out of *m\n  m->encode(features, msgr->crcflags);\n\n  bl.append(m->get_payload());\n  bl.append(m->get_middle());\n  bl.append(m->get_data());\n}\n\nssize_t AsyncConnection::write_message(Message *m, bufferlist& bl, bool more)\n{\n  FUNCTRACE();\n  assert(center->in_thread());\n  m->set_seq(++out_seq);\n\n  if (msgr->crcflags & MSG_CRC_HEADER)\n    m->calc_header_crc();\n\n  ceph_msg_header& header = m->get_header();\n  ceph_msg_footer& footer = m->get_footer();\n\n  // TODO: let sign_message could be reentry?\n  // Now that we have all the crcs calculated, handle the\n  // digital signature for the message, if the AsyncConnection has session\n  // security set up.  Some session security options do not\n  // actually calculate and check the signature, but they should\n  // handle the calls to sign_message and check_signature.  PLR\n  if (session_security.get() == NULL) {\n    ldout(async_msgr->cct, 20) << __func__ << \" no session security\" << dendl;\n  } else {\n    if (session_security->sign_message(m)) {\n      ldout(async_msgr->cct, 20) << __func__ << \" failed to sign m=\"\n                                 << m << \"): sig = \" << footer.sig << dendl;\n    } else {\n      ldout(async_msgr->cct, 20) << __func__ << \" signed m=\" << m\n                                 << \"): sig = \" << footer.sig << dendl;\n    }\n  }\n  \n  unsigned original_bl_len = outcoming_bl.length();\n\n  outcoming_bl.append(CEPH_MSGR_TAG_MSG);\n\n  if (has_feature(CEPH_FEATURE_NOSRCADDR)) {\n    outcoming_bl.append((char*)&header, sizeof(header));\n  } else {\n    ceph_msg_header_old oldheader;\n    memcpy(&oldheader, &header, sizeof(header));\n    oldheader.src.name = header.src;\n    oldheader.src.addr = get_peer_addr();\n    oldheader.orig_src = oldheader.src;\n    oldheader.reserved = header.reserved;\n    oldheader.crc = ceph_crc32c(0, (unsigned char*)&oldheader,\n                                sizeof(oldheader) - sizeof(oldheader.crc));\n    outcoming_bl.append((char*)&oldheader, sizeof(oldheader));\n  }\n\n  ldout(async_msgr->cct, 20) << __func__ << \" sending message type=\" << header.type\n                             << \" src \" << entity_name_t(header.src)\n                             << \" front=\" << header.front_len\n                             << \" data=\" << header.data_len\n                             << \" off \" << header.data_off << dendl;\n\n  if ((bl.length() <= ASYNC_COALESCE_THRESHOLD) && (bl.buffers().size() > 1)) {\n    for (const auto &pb : bl.buffers()) {\n      outcoming_bl.append((char*)pb.c_str(), pb.length());\n    }\n  } else {\n    outcoming_bl.claim_append(bl);  \n  }\n\n  // send footer; if receiver doesn't support signatures, use the old footer format\n  ceph_msg_footer_old old_footer;\n  if (has_feature(CEPH_FEATURE_MSG_AUTH)) {\n    outcoming_bl.append((char*)&footer, sizeof(footer));\n  } else {\n    if (msgr->crcflags & MSG_CRC_HEADER) {\n      old_footer.front_crc = footer.front_crc;\n      old_footer.middle_crc = footer.middle_crc;\n      old_footer.data_crc = footer.data_crc;\n    } else {\n       old_footer.front_crc = old_footer.middle_crc = 0;\n    }\n    old_footer.data_crc = msgr->crcflags & MSG_CRC_DATA ? footer.data_crc : 0;\n    old_footer.flags = footer.flags;\n    outcoming_bl.append((char*)&old_footer, sizeof(old_footer));\n  }\n\n  m->trace.event(\"async writing message\");\n  ldout(async_msgr->cct, 20) << __func__ << \" sending \" << m->get_seq()\n                             << \" \" << m << dendl;\n  ssize_t total_send_size = outcoming_bl.length();\n  ssize_t rc = _try_send(more);\n  if (rc < 0) {\n    ldout(async_msgr->cct, 1) << __func__ << \" error sending \" << m << \", \"\n                              << cpp_strerror(rc) << dendl;\n  } else if (rc == 0) {\n    logger->inc(l_msgr_send_bytes, total_send_size - original_bl_len);\n    ldout(async_msgr->cct, 10) << __func__ << \" sending \" << m << \" done.\" << dendl;\n  } else {\n    logger->inc(l_msgr_send_bytes, total_send_size - outcoming_bl.length());\n    ldout(async_msgr->cct, 10) << __func__ << \" sending \" << m << \" continuely.\" << dendl;\n  }\n  if (m->get_type() == CEPH_MSG_OSD_OP)\n    OID_EVENT_TRACE_WITH_MSG(m, \"SEND_MSG_OSD_OP_END\", false);\n  else if (m->get_type() == CEPH_MSG_OSD_OPREPLY)\n    OID_EVENT_TRACE_WITH_MSG(m, \"SEND_MSG_OSD_OPREPLY_END\", false);\n  m->put();\n\n  return rc;\n}\n\nvoid AsyncConnection::reset_recv_state()\n{\n  // clean up state internal variables and states\n  if (state >= STATE_CONNECTING_SEND_CONNECT_MSG &&\n      state <= STATE_CONNECTING_READY) {\n    delete authorizer;\n    authorizer = NULL;\n    got_bad_auth = false;\n  }\n\n  if (state > STATE_OPEN_MESSAGE_THROTTLE_MESSAGE &&\n      state <= STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH\n      && policy.throttler_messages) {\n    ldout(async_msgr->cct, 10) << __func__ << \" releasing \" << 1\n                               << \" message to policy throttler \"\n                               << policy.throttler_messages->get_current() << \"/\"\n                               << policy.throttler_messages->get_max() << dendl;\n    policy.throttler_messages->put();\n  }\n  if (state > STATE_OPEN_MESSAGE_THROTTLE_BYTES &&\n      state <= STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH) {\n    if (policy.throttler_bytes) {\n      ldout(async_msgr->cct, 10) << __func__ << \" releasing \" << cur_msg_size\n                                 << \" bytes to policy throttler \"\n                                 << policy.throttler_bytes->get_current() << \"/\"\n                                 << policy.throttler_bytes->get_max() << dendl;\n      policy.throttler_bytes->put(cur_msg_size);\n    }\n  }\n  if (state > STATE_OPEN_MESSAGE_THROTTLE_DISPATCH_QUEUE &&\n      state <= STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH) {\n    ldout(async_msgr->cct, 10) << __func__ << \" releasing \" << cur_msg_size\n                               << \" bytes to dispatch_queue throttler \"\n                               << dispatch_queue->dispatch_throttler.get_current() << \"/\"\n                               << dispatch_queue->dispatch_throttler.get_max() << dendl;\n    dispatch_queue->dispatch_throttle_release(cur_msg_size);\n  }\n}\n\nvoid AsyncConnection::handle_ack(uint64_t seq)\n{\n  ldout(async_msgr->cct, 15) << __func__ << \" got ack seq \" << seq << dendl;\n  // trim sent list\n  std::lock_guard<std::mutex> l(write_lock);\n  while (!sent.empty() && sent.front()->get_seq() <= seq) {\n    Message* m = sent.front();\n    sent.pop_front();\n    ldout(async_msgr->cct, 10) << __func__ << \" got ack seq \"\n                               << seq << \" >= \" << m->get_seq() << \" on \"\n                               << m << \" \" << *m << dendl;\n    m->put();\n  }\n}\n\nvoid AsyncConnection::DelayedDelivery::do_request(int id)\n{\n  Message *m = nullptr;\n  {\n    std::lock_guard<std::mutex> l(delay_lock);\n    register_time_events.erase(id);\n    if (stop_dispatch)\n      return ;\n    if (delay_queue.empty())\n      return ;\n    utime_t release = delay_queue.front().first;\n    m = delay_queue.front().second;\n    string delay_msg_type = msgr->cct->_conf->ms_inject_delay_msg_type;\n    utime_t now = ceph_clock_now();\n    if ((release > now &&\n        (delay_msg_type.empty() || m->get_type_name() == delay_msg_type))) {\n      utime_t t = release - now;\n      t.sleep();\n    }\n    delay_queue.pop_front();\n  }\n  if (msgr->ms_can_fast_dispatch(m)) {\n    dispatch_queue->fast_dispatch(m);\n  } else {\n    dispatch_queue->enqueue(m, m->get_priority(), conn_id);\n  }\n}\n\nvoid AsyncConnection::DelayedDelivery::flush() {\n  stop_dispatch = true;\n  center->submit_to(\n      center->get_id(), [this] () mutable {\n    std::lock_guard<std::mutex> l(delay_lock);\n    while (!delay_queue.empty()) {\n      Message *m = delay_queue.front().second;\n      if (msgr->ms_can_fast_dispatch(m)) {\n        dispatch_queue->fast_dispatch(m);\n      } else {\n        dispatch_queue->enqueue(m, m->get_priority(), conn_id);\n      }\n      delay_queue.pop_front();\n    }\n    for (auto i : register_time_events)\n      center->delete_time_event(i);\n    register_time_events.clear();\n    stop_dispatch = false;\n  }, true);\n}\n\nvoid AsyncConnection::send_keepalive()\n{\n  ldout(async_msgr->cct, 10) << __func__ << dendl;\n  std::lock_guard<std::mutex> l(write_lock);\n  if (can_write != WriteStatus::CLOSED) {\n    keepalive = true;\n    center->dispatch_event_external(write_handler);\n  }\n}\n\nvoid AsyncConnection::mark_down()\n{\n  ldout(async_msgr->cct, 1) << __func__ << dendl;\n  std::lock_guard<std::mutex> l(lock);\n  _stop();\n}\n\nvoid AsyncConnection::_append_keepalive_or_ack(bool ack, utime_t *tp)\n{\n  ldout(async_msgr->cct, 10) << __func__ << dendl;\n  if (ack) {\n    assert(tp);\n    struct ceph_timespec ts;\n    tp->encode_timeval(&ts);\n    outcoming_bl.append(CEPH_MSGR_TAG_KEEPALIVE2_ACK);\n    outcoming_bl.append((char*)&ts, sizeof(ts));\n  } else if (has_feature(CEPH_FEATURE_MSGR_KEEPALIVE2)) {\n    struct ceph_timespec ts;\n    utime_t t = ceph_clock_now();\n    t.encode_timeval(&ts);\n    outcoming_bl.append(CEPH_MSGR_TAG_KEEPALIVE2);\n    outcoming_bl.append((char*)&ts, sizeof(ts));\n  } else {\n    outcoming_bl.append(CEPH_MSGR_TAG_KEEPALIVE);\n  }\n}\n\nvoid AsyncConnection::handle_write()\n{\n  ldout(async_msgr->cct, 10) << __func__ << dendl;\n  ssize_t r = 0;\n\n  write_lock.lock();\n  if (can_write == WriteStatus::CANWRITE) {\n    if (keepalive) {\n      _append_keepalive_or_ack();\n      keepalive = false;\n    }\n\n    auto start = ceph::mono_clock::now();\n    bool more;\n    do {\n      bufferlist data;\n      Message *m = _get_next_outgoing(&data);\n      if (!m)\n        break;\n\n      if (!policy.lossy) {\n        // put on sent list\n        sent.push_back(m);\n        m->get();\n      }\n      more = _has_next_outgoing();\n      write_lock.unlock();\n\n      // send_message or requeue messages may not encode message\n      if (!data.length())\n        prepare_send_message(get_features(), m, data);\n\n      r = write_message(m, data, more);\n      if (r < 0) {\n        ldout(async_msgr->cct, 1) << __func__ << \" send msg failed\" << dendl;\n        goto fail;\n      }\n      write_lock.lock();\n      if (r > 0)\n        break;\n    } while (can_write == WriteStatus::CANWRITE);\n    write_lock.unlock();\n\n    uint64_t left = ack_left;\n    if (left) {\n      ceph_le64 s;\n      s = in_seq;\n      outcoming_bl.append(CEPH_MSGR_TAG_ACK);\n      outcoming_bl.append((char*)&s, sizeof(s));\n      ldout(async_msgr->cct, 10) << __func__ << \" try send msg ack, acked \" << left << \" messages\" << dendl;\n      ack_left -= left;\n      left = ack_left;\n      r = _try_send(left);\n    } else if (is_queued()) {\n      r = _try_send();\n    }\n\n    logger->tinc(l_msgr_running_send_time, ceph::mono_clock::now() - start);\n    if (r < 0) {\n      ldout(async_msgr->cct, 1) << __func__ << \" send msg failed\" << dendl;\n      goto fail;\n    }\n  } else {\n    write_lock.unlock();\n    lock.lock();\n    write_lock.lock();\n    if (state == STATE_STANDBY && !policy.server && is_queued()) {\n      ldout(async_msgr->cct, 10) << __func__ << \" policy.server is false\" << dendl;\n      _connect();\n    } else if (cs && state != STATE_NONE && state != STATE_CONNECTING && state != STATE_CONNECTING_RE && state != STATE_CLOSED) {\n      r = _try_send();\n      if (r < 0) {\n        ldout(async_msgr->cct, 1) << __func__ << \" send outcoming bl failed\" << dendl;\n        write_lock.unlock();\n        fault();\n        lock.unlock();\n        return ;\n      }\n    }\n    write_lock.unlock();\n    lock.unlock();\n  }\n\n  return ;\n\n fail:\n  lock.lock();\n  fault();\n  lock.unlock();\n}\n\nvoid AsyncConnection::wakeup_from(uint64_t id)\n{\n  lock.lock();\n  register_time_events.erase(id);\n  lock.unlock();\n  process();\n}\n\nvoid AsyncConnection::tick(uint64_t id)\n{\n  auto now = ceph::coarse_mono_clock::now();\n  ldout(async_msgr->cct, 20) << __func__ << \" last_id=\" << last_tick_id\n                             << \" last_active\" << last_active << dendl;\n  std::lock_guard<std::mutex> l(lock);\n  last_tick_id = 0;\n  auto idle_period = std::chrono::duration_cast<std::chrono::microseconds>(now - last_active).count();\n  if (inactive_timeout_us < (uint64_t)idle_period) {\n    ldout(async_msgr->cct, 1) << __func__ << \" idle(\" << idle_period << \") more than \"\n                              << inactive_timeout_us\n                              << \" us, mark self fault.\" << dendl;\n    fault();\n  } else if (is_connected()) {\n    last_tick_id = center->create_time_event(inactive_timeout_us, tick_handler);\n  }\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2014 UnitedStack <haomai@unitedstack.com>\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#ifndef CEPH_MSG_ASYNCCONNECTION_H\n#define CEPH_MSG_ASYNCCONNECTION_H\n\n#include <atomic>\n#include <pthread.h>\n#include <climits>\n#include <list>\n#include <mutex>\n#include <map>\nusing namespace std;\n\n#include \"auth/AuthSessionHandler.h\"\n#include \"common/ceph_time.h\"\n#include \"common/perf_counters.h\"\n#include \"include/buffer.h\"\n#include \"msg/Connection.h\"\n#include \"msg/Messenger.h\"\n\n#include \"Event.h\"\n#include \"Stack.h\"\n\nclass AsyncMessenger;\nclass Worker;\n\nstatic const int ASYNC_IOV_MAX = (IOV_MAX >= 1024 ? IOV_MAX / 4 : IOV_MAX);\n\n/*\n * AsyncConnection maintains a logic session between two endpoints. In other\n * word, a pair of addresses can find the only AsyncConnection. AsyncConnection\n * will handle with network fault or read/write transactions. If one file\n * descriptor broken, AsyncConnection will maintain the message queue and\n * sequence, try to reconnect peer endpoint.\n */\nclass AsyncConnection : public Connection {\n\n  ssize_t read_bulk(char *buf, unsigned len);\n  ssize_t do_sendmsg(struct msghdr &msg, unsigned len, bool more);\n  ssize_t try_send(bufferlist &bl, bool more=false) {\n    std::lock_guard<std::mutex> l(write_lock);\n    outcoming_bl.claim_append(bl);\n    return _try_send(more);\n  }\n  ssize_t _try_send(bool more=false);\n  ssize_t _send(Message *m);\n  void prepare_send_message(uint64_t features, Message *m, bufferlist &bl);\n  ssize_t read_until(unsigned needed, char *p);\n  ssize_t _process_connection();\n  void _connect();\n  void _stop();\n  int handle_connect_reply(ceph_msg_connect &connect, ceph_msg_connect_reply &r);\n  ssize_t handle_connect_msg(ceph_msg_connect &m, bufferlist &aubl, bufferlist &bl);\n  void was_session_reset();\n  void fault();\n  void discard_out_queue();\n  void discard_requeued_up_to(uint64_t seq);\n  void requeue_sent();\n  int randomize_out_seq();\n  void handle_ack(uint64_t seq);\n  void _append_keepalive_or_ack(bool ack=false, utime_t *t=NULL);\n  ssize_t write_message(Message *m, bufferlist& bl, bool more);\n  void inject_delay();\n  ssize_t _reply_accept(char tag, ceph_msg_connect &connect, ceph_msg_connect_reply &reply,\n                    bufferlist &authorizer_reply) {\n    bufferlist reply_bl;\n    reply.tag = tag;\n    reply.features = ((uint64_t)connect.features & policy.features_supported) | policy.features_required;\n    reply.authorizer_len = authorizer_reply.length();\n    reply_bl.append((char*)&reply, sizeof(reply));\n    if (reply.authorizer_len) {\n      reply_bl.append(authorizer_reply.c_str(), authorizer_reply.length());\n    }\n    ssize_t r = try_send(reply_bl);\n    if (r < 0) {\n      inject_delay();\n      return -1;\n    }\n\n    state = STATE_ACCEPTING_WAIT_CONNECT_MSG;\n    return 0;\n  }\n  bool is_queued() const {\n    return !out_q.empty() || outcoming_bl.length();\n  }\n  void shutdown_socket() {\n    for (auto &&t : register_time_events)\n      center->delete_time_event(t);\n    register_time_events.clear();\n    if (last_tick_id) {\n      center->delete_time_event(last_tick_id);\n      last_tick_id = 0;\n    }\n    if (cs) {\n      center->delete_file_event(cs.fd(), EVENT_READABLE|EVENT_WRITABLE);\n      cs.shutdown();\n      cs.close();\n    }\n  }\n  Message *_get_next_outgoing(bufferlist *bl) {\n    Message *m = 0;\n    while (!m && !out_q.empty()) {\n      map<int, list<pair<bufferlist, Message*> > >::reverse_iterator it = out_q.rbegin();\n      if (!it->second.empty()) {\n        list<pair<bufferlist, Message*> >::iterator p = it->second.begin();\n        m = p->second;\n        if (bl)\n          bl->swap(p->first);\n        it->second.erase(p);\n      }\n      if (it->second.empty())\n        out_q.erase(it->first);\n    }\n    return m;\n  }\n  bool _has_next_outgoing() const {\n    return !out_q.empty();\n  }\n  void reset_recv_state();\n\n   /**\n   * The DelayedDelivery is for injecting delays into Message delivery off\n   * the socket. It is only enabled if delays are requested, and if they\n   * are then it pulls Messages off the DelayQueue and puts them into the\n   * AsyncMessenger event queue.\n   */\n  class DelayedDelivery : public EventCallback {\n    std::set<uint64_t> register_time_events; // need to delete it if stop\n    std::deque<std::pair<utime_t, Message*> > delay_queue;\n    std::mutex delay_lock;\n    AsyncMessenger *msgr;\n    EventCenter *center;\n    DispatchQueue *dispatch_queue;\n    uint64_t conn_id;\n    std::atomic_bool stop_dispatch;\n\n   public:\n    explicit DelayedDelivery(AsyncMessenger *omsgr, EventCenter *c,\n                             DispatchQueue *q, uint64_t cid)\n      : msgr(omsgr), center(c), dispatch_queue(q), conn_id(cid),\n        stop_dispatch(false) { }\n    ~DelayedDelivery() override {\n      assert(register_time_events.empty());\n      assert(delay_queue.empty());\n    }\n    void set_center(EventCenter *c) { center = c; }\n    void do_request(int id) override;\n    void queue(double delay_period, utime_t release, Message *m) {\n      std::lock_guard<std::mutex> l(delay_lock);\n      delay_queue.push_back(std::make_pair(release, m));\n      register_time_events.insert(center->create_time_event(delay_period*1000000, this));\n    }\n    void discard() {\n      stop_dispatch = true;\n      center->submit_to(center->get_id(), [this] () mutable {\n        std::lock_guard<std::mutex> l(delay_lock);\n        while (!delay_queue.empty()) {\n          Message *m = delay_queue.front().second;\n          dispatch_queue->dispatch_throttle_release(m->get_dispatch_throttle_size());\n          m->put();\n          delay_queue.pop_front();\n        }\n        for (auto i : register_time_events)\n          center->delete_time_event(i);\n        register_time_events.clear();\n        stop_dispatch = false;\n      }, true);\n    }\n    bool ready() const { return !stop_dispatch && delay_queue.empty() && register_time_events.empty(); }\n    void flush();\n  } *delay_state;\n\n public:\n  AsyncConnection(CephContext *cct, AsyncMessenger *m, DispatchQueue *q, Worker *w);\n  ~AsyncConnection() override;\n  void maybe_start_delay_thread();\n\n  ostream& _conn_prefix(std::ostream *_dout);\n\n  bool is_connected() override {\n    return can_write.load() == WriteStatus::CANWRITE;\n  }\n\n  // Only call when AsyncConnection first construct\n  void connect(const entity_addr_t& addr, int type) {\n    set_peer_type(type);\n    set_peer_addr(addr);\n    policy = msgr->get_policy(type);\n    _connect();\n  }\n  // Only call when AsyncConnection first construct\n  void accept(ConnectedSocket socket, entity_addr_t &addr);\n  int send_message(Message *m) override;\n\n  void send_keepalive() override;\n  void mark_down() override;\n  void mark_disposable() override {\n    std::lock_guard<std::mutex> l(lock);\n    policy.lossy = true;\n  }\n  \n private:\n  enum {\n    STATE_NONE,\n    STATE_OPEN,\n    STATE_OPEN_KEEPALIVE2,\n    STATE_OPEN_KEEPALIVE2_ACK,\n    STATE_OPEN_TAG_ACK,\n    STATE_OPEN_MESSAGE_HEADER,\n    STATE_OPEN_MESSAGE_THROTTLE_MESSAGE,\n    STATE_OPEN_MESSAGE_THROTTLE_BYTES,\n    STATE_OPEN_MESSAGE_THROTTLE_DISPATCH_QUEUE,\n    STATE_OPEN_MESSAGE_READ_FRONT,\n    STATE_OPEN_MESSAGE_READ_MIDDLE,\n    STATE_OPEN_MESSAGE_READ_DATA_PREPARE,\n    STATE_OPEN_MESSAGE_READ_DATA,\n    STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH,\n    STATE_OPEN_TAG_CLOSE,\n    STATE_WAIT_SEND,\n    STATE_CONNECTING,\n    STATE_CONNECTING_RE,\n    STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY,\n    STATE_CONNECTING_SEND_CONNECT_MSG,\n    STATE_CONNECTING_WAIT_CONNECT_REPLY,\n    STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH,\n    STATE_CONNECTING_WAIT_ACK_SEQ,\n    STATE_CONNECTING_READY,\n    STATE_ACCEPTING,\n    STATE_ACCEPTING_WAIT_BANNER_ADDR,\n    STATE_ACCEPTING_WAIT_CONNECT_MSG,\n    STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH,\n    STATE_ACCEPTING_WAIT_SEQ,\n    STATE_ACCEPTING_READY,\n    STATE_STANDBY,\n    STATE_CLOSED,\n    STATE_WAIT,       // just wait for racing connection\n  };\n\n  static const int TCP_PREFETCH_MIN_SIZE;\n  static const char *get_state_name(int state) {\n      const char* const statenames[] = {\"STATE_NONE\",\n                                        \"STATE_OPEN\",\n                                        \"STATE_OPEN_KEEPALIVE2\",\n                                        \"STATE_OPEN_KEEPALIVE2_ACK\",\n                                        \"STATE_OPEN_TAG_ACK\",\n                                        \"STATE_OPEN_MESSAGE_HEADER\",\n                                        \"STATE_OPEN_MESSAGE_THROTTLE_MESSAGE\",\n                                        \"STATE_OPEN_MESSAGE_THROTTLE_BYTES\",\n                                        \"STATE_OPEN_MESSAGE_THROTTLE_DISPATCH_QUEUE\",\n                                        \"STATE_OPEN_MESSAGE_READ_FRONT\",\n                                        \"STATE_OPEN_MESSAGE_READ_MIDDLE\",\n                                        \"STATE_OPEN_MESSAGE_READ_DATA_PREPARE\",\n                                        \"STATE_OPEN_MESSAGE_READ_DATA\",\n                                        \"STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH\",\n                                        \"STATE_OPEN_TAG_CLOSE\",\n                                        \"STATE_WAIT_SEND\",\n                                        \"STATE_CONNECTING\",\n                                        \"STATE_CONNECTING_RE\",\n                                        \"STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY\",\n                                        \"STATE_CONNECTING_SEND_CONNECT_MSG\",\n                                        \"STATE_CONNECTING_WAIT_CONNECT_REPLY\",\n                                        \"STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH\",\n                                        \"STATE_CONNECTING_WAIT_ACK_SEQ\",\n                                        \"STATE_CONNECTING_READY\",\n                                        \"STATE_ACCEPTING\",\n                                        \"STATE_ACCEPTING_WAIT_BANNER_ADDR\",\n                                        \"STATE_ACCEPTING_WAIT_CONNECT_MSG\",\n                                        \"STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH\",\n                                        \"STATE_ACCEPTING_WAIT_SEQ\",\n                                        \"STATE_ACCEPTING_READY\",\n                                        \"STATE_STANDBY\",\n                                        \"STATE_CLOSED\",\n                                        \"STATE_WAIT\"};\n      return statenames[state];\n  }\n\n  AsyncMessenger *async_msgr;\n  uint64_t conn_id;\n  PerfCounters *logger;\n  int global_seq;\n  __u32 connect_seq, peer_global_seq;\n  std::atomic<uint64_t> out_seq{0};\n  std::atomic<uint64_t> ack_left{0}, in_seq{0};\n  int state;\n  int state_after_send;\n  ConnectedSocket cs;\n  int port;\n  Messenger::Policy policy;\n\n  DispatchQueue *dispatch_queue;\n\n  // lockfree, only used in own thread\n  bufferlist outcoming_bl;\n  bool open_write = false;\n\n  std::mutex write_lock;\n  enum class WriteStatus {\n    NOWRITE,\n    REPLACING,\n    CANWRITE,\n    CLOSED\n  };\n  std::atomic<WriteStatus> can_write;\n  list<Message*> sent; // the first bufferlist need to inject seq\n  map<int, list<pair<bufferlist, Message*> > > out_q;  // priority queue for outbound msgs\n  bool keepalive;\n\n  std::mutex lock;\n  utime_t backoff;         // backoff time\n  EventCallbackRef read_handler;\n  EventCallbackRef write_handler;\n  EventCallbackRef wakeup_handler;\n  EventCallbackRef tick_handler;\n  struct iovec msgvec[ASYNC_IOV_MAX];\n  char *recv_buf;\n  uint32_t recv_max_prefetch;\n  uint32_t recv_start;\n  uint32_t recv_end;\n  set<uint64_t> register_time_events; // need to delete it if stop\n  ceph::coarse_mono_clock::time_point last_active;\n  uint64_t last_tick_id = 0;\n  const uint64_t inactive_timeout_us;\n\n  // Tis section are temp variables used by state transition\n\n  // Open state\n  utime_t recv_stamp;\n  utime_t throttle_stamp;\n  unsigned msg_left;\n  uint64_t cur_msg_size;\n  ceph_msg_header current_header;\n  bufferlist data_buf;\n  bufferlist::iterator data_blp;\n  bufferlist front, middle, data;\n  ceph_msg_connect connect_msg;\n  // Connecting state\n  bool got_bad_auth;\n  AuthAuthorizer *authorizer;\n  bufferlist authorizer_buf;\n  ceph_msg_connect_reply connect_reply;\n  // Accepting state\n  entity_addr_t socket_addr;\n  CryptoKey session_key;\n  bool replacing;    // when replacing process happened, we will reply connect\n                     // side with RETRY tag and accept side will clear replaced\n                     // connection. So when connect side reissue connect_msg,\n                     // there won't exists conflicting connection so we use\n                     // \"replacing\" to skip RESETSESSION to avoid detect wrong\n                     // presentation\n  bool is_reset_from_peer;\n  bool once_ready;\n\n  // used only for local state, it will be overwrite when state transition\n  char *state_buffer;\n  // used only by \"read_until\"\n  uint64_t state_offset;\n  Worker *worker;\n  EventCenter *center;\n  ceph::shared_ptr<AuthSessionHandler> session_security;\n\n public:\n  // used by eventcallback\n  void handle_write();\n  void process();\n  void wakeup_from(uint64_t id);\n  void tick(uint64_t id);\n  void local_deliver();\n  void stop(bool queue_reset) {\n    lock.lock();\n    bool need_queue_reset = (state != STATE_CLOSED) && queue_reset;\n    _stop();\n    lock.unlock();\n    if (need_queue_reset)\n      dispatch_queue->queue_reset(this);\n  }\n  void cleanup() {\n    shutdown_socket();\n    delete read_handler;\n    delete write_handler;\n    delete wakeup_handler;\n    delete tick_handler;\n    if (delay_state) {\n      delete delay_state;\n      delay_state = NULL;\n    }\n  }\n  PerfCounters *get_perf_counter() {\n    return logger;\n  }\n}; /* AsyncConnection */\n\ntypedef boost::intrusive_ptr<AsyncConnection> AsyncConnectionRef;\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2014 UnitedStack <haomai@unitedstack.com>\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#ifndef CEPH_ASYNCMESSENGER_H\n#define CEPH_ASYNCMESSENGER_H\n\n#include \"include/types.h\"\n#include \"include/xlist.h\"\n\n#include <map>\nusing namespace std;\n#include \"include/unordered_map.h\"\n#include \"include/unordered_set.h\"\n\n#include \"common/Mutex.h\"\n#include \"common/Cond.h\"\n#include \"common/Thread.h\"\n\n#include \"include/Spinlock.h\"\n\n#include \"msg/SimplePolicyMessenger.h\"\n#include \"msg/DispatchQueue.h\"\n#include \"include/assert.h\"\n#include \"AsyncConnection.h\"\n#include \"Event.h\"\n\n\nclass AsyncMessenger;\n\n/**\n * If the Messenger binds to a specific address, the Processor runs\n * and listens for incoming connections.\n */\nclass Processor {\n  AsyncMessenger *msgr;\n  NetHandler net;\n  Worker *worker;\n  ServerSocket listen_socket;\n  EventCallbackRef listen_handler;\n\n  class C_processor_accept;\n\n public:\n  Processor(AsyncMessenger *r, Worker *w, CephContext *c);\n  ~Processor() { delete listen_handler; };\n\n  void stop();\n  int bind(const entity_addr_t &bind_addr,\n\t   const set<int>& avoid_ports,\n\t   entity_addr_t* bound_addr);\n  void start();\n  void accept();\n};\n\n/*\n * AsyncMessenger is represented for maintaining a set of asynchronous connections,\n * it may own a bind address and the accepted connections will be managed by\n * AsyncMessenger.\n *\n */\n\nclass AsyncMessenger : public SimplePolicyMessenger {\n  // First we have the public Messenger interface implementation...\npublic:\n  /**\n   * Initialize the AsyncMessenger!\n   *\n   * @param cct The CephContext to use\n   * @param name The name to assign ourselves\n   * _nonce A unique ID to use for this AsyncMessenger. It should not\n   * be a value that will be repeated if the daemon restarts.\n   */\n  AsyncMessenger(CephContext *cct, entity_name_t name, const std::string &type,\n                 string mname, uint64_t _nonce);\n\n  /**\n   * Destroy the AsyncMessenger. Pretty simple since all the work is done\n   * elsewhere.\n   */\n  ~AsyncMessenger() override;\n\n  /** @defgroup Accessors\n   * @{\n   */\n  void set_addr_unknowns(const entity_addr_t &addr) override;\n  void set_addr(const entity_addr_t &addr) override;\n\n  int get_dispatch_queue_len() override {\n    return dispatch_queue.get_queue_len();\n  }\n\n  double get_dispatch_queue_max_age(utime_t now) override {\n    return dispatch_queue.get_max_age(now);\n  }\n  /** @} Accessors */\n\n  /**\n   * @defgroup Configuration functions\n   * @{\n   */\n  void set_cluster_protocol(int p) override {\n    assert(!started && !did_bind);\n    cluster_protocol = p;\n  }\n\n  int bind(const entity_addr_t& bind_addr) override;\n  int rebind(const set<int>& avoid_ports) override;\n  int client_bind(const entity_addr_t& bind_addr) override;\n\n  /** @} Configuration functions */\n\n  /**\n   * @defgroup Startup/Shutdown\n   * @{\n   */\n  int start() override;\n  void wait() override;\n  int shutdown() override;\n\n  /** @} // Startup/Shutdown */\n\n  /**\n   * @defgroup Messaging\n   * @{\n   */\n  int send_message(Message *m, const entity_inst_t& dest) override {\n    Mutex::Locker l(lock);\n\n    return _send_message(m, dest);\n  }\n\n  /** @} // Messaging */\n\n  /**\n   * @defgroup Connection Management\n   * @{\n   */\n  ConnectionRef get_connection(const entity_inst_t& dest) override;\n  ConnectionRef get_loopback_connection() override;\n  void mark_down(const entity_addr_t& addr) override;\n  void mark_down_all() override {\n    shutdown_connections(true);\n  }\n  /** @} // Connection Management */\n\n  /**\n   * @defgroup Inner classes\n   * @{\n   */\n\n  /**\n   * @} // Inner classes\n   */\n\nprotected:\n  /**\n   * @defgroup Messenger Interfaces\n   * @{\n   */\n  /**\n   * Start up the DispatchQueue thread once we have somebody to dispatch to.\n   */\n  void ready() override;\n  /** @} // Messenger Interfaces */\n\nprivate:\n\n  /**\n   * @defgroup Utility functions\n   * @{\n   */\n\n  /**\n   * Create a connection associated with the given entity (of the given type).\n   * Initiate the connection. (This function returning does not guarantee\n   * connection success.)\n   *\n   * @param addr The address of the entity to connect to.\n   * @param type The peer type of the entity at the address.\n   *\n   * @return a pointer to the newly-created connection. Caller does not own a\n   * reference; take one if you need it.\n   */\n  AsyncConnectionRef create_connect(const entity_addr_t& addr, int type);\n\n  /**\n   * Queue up a Message for delivery to the entity specified\n   * by addr and dest_type.\n   * submit_message() is responsible for creating\n   * new AsyncConnection (and closing old ones) as necessary.\n   *\n   * @param m The Message to queue up. This function eats a reference.\n   * @param con The existing Connection to use, or NULL if you don't know of one.\n   * @param dest_addr The address to send the Message to.\n   * @param dest_type The peer type of the address we're sending to\n   * just drop silently under failure.\n   */\n  void submit_message(Message *m, AsyncConnectionRef con,\n                      const entity_addr_t& dest_addr, int dest_type);\n\n  int _send_message(Message *m, const entity_inst_t& dest);\n  void _finish_bind(const entity_addr_t& bind_addr,\n\t\t    const entity_addr_t& listen_addr);\n\n private:\n  static const uint64_t ReapDeadConnectionThreshold = 5;\n\n  NetworkStack *stack;\n  std::vector<Processor*> processors;\n  friend class Processor;\n  DispatchQueue dispatch_queue;\n\n  // the worker run messenger's cron jobs\n  Worker *local_worker;\n\n  std::string ms_type;\n\n  /// overall lock used for AsyncMessenger data structures\n  Mutex lock;\n  // AsyncMessenger stuff\n  /// approximately unique ID set by the Constructor for use in entity_addr_t\n  uint64_t nonce;\n\n  /// true, specifying we haven't learned our addr; set false when we find it.\n  // maybe this should be protected by the lock?\n  bool need_addr;\n\n  /**\n   * set to bind address if bind was called before NetworkStack was ready to\n   * bind\n   */\n  entity_addr_t pending_bind_addr;\n\n  /**\n   * false; set to true if a pending bind exists\n   */\n  bool pending_bind = false;\n\n  /**\n   *  The following aren't lock-protected since you shouldn't be able to race\n   *  the only writers.\n   */\n\n  /**\n   *  false; set to true if the AsyncMessenger bound to a specific address;\n   *  and set false again by Accepter::stop().\n   */\n  bool did_bind;\n  /// counter for the global seq our connection protocol uses\n  __u32 global_seq;\n  /// lock to protect the global_seq\n  ceph_spinlock_t global_seq_lock;\n\n  /**\n   * hash map of addresses to Asyncconnection\n   *\n   * NOTE: a Asyncconnection* with state CLOSED may still be in the map but is considered\n   * invalid and can be replaced by anyone holding the msgr lock\n   */\n  ceph::unordered_map<entity_addr_t, AsyncConnectionRef> conns;\n\n  /**\n   * list of connection are in teh process of accepting\n   *\n   * These are not yet in the conns map.\n   */\n  set<AsyncConnectionRef> accepting_conns;\n\n  /**\n   * list of connection are closed which need to be clean up\n   *\n   * Because AsyncMessenger and AsyncConnection follow a lock rule that\n   * we can lock AsyncMesenger::lock firstly then lock AsyncConnection::lock\n   * but can't reversed. This rule is aimed to avoid dead lock.\n   * So if AsyncConnection want to unregister itself from AsyncMessenger,\n   * we pick up this idea that just queue itself to this set and do lazy\n   * deleted for AsyncConnection. \"_lookup_conn\" must ensure not return a\n   * AsyncConnection in this set.\n   */\n  Mutex deleted_lock;\n  set<AsyncConnectionRef> deleted_conns;\n\n  EventCallbackRef reap_handler;\n\n  /// internal cluster protocol version, if any, for talking to entities of the same type.\n  int cluster_protocol;\n\n  Cond  stop_cond;\n  bool stopped;\n\n  AsyncConnectionRef _lookup_conn(const entity_addr_t& k) {\n    assert(lock.is_locked());\n    ceph::unordered_map<entity_addr_t, AsyncConnectionRef>::iterator p = conns.find(k);\n    if (p == conns.end())\n      return NULL;\n\n    // lazy delete, see \"deleted_conns\"\n    Mutex::Locker l(deleted_lock);\n    if (deleted_conns.erase(p->second)) {\n      p->second->get_perf_counter()->dec(l_msgr_active_connections);\n      conns.erase(p);\n      return NULL;\n    }\n\n    return p->second;\n  }\n\n  void _init_local_connection() {\n    assert(lock.is_locked());\n    local_connection->peer_addr = my_inst.addr;\n    local_connection->peer_type = my_inst.name.type();\n    local_connection->set_features(CEPH_FEATURES_ALL);\n    ms_deliver_handle_fast_connect(local_connection.get());\n  }\n\n  void shutdown_connections(bool queue_reset);\n\npublic:\n\n  /// con used for sending messages to ourselves\n  ConnectionRef local_connection;\n\n  /**\n   * @defgroup AsyncMessenger internals\n   * @{\n   */\n  /**\n   * This wraps _lookup_conn.\n   */\n  AsyncConnectionRef lookup_conn(const entity_addr_t& k) {\n    Mutex::Locker l(lock);\n    return _lookup_conn(k);\n  }\n\n  int accept_conn(AsyncConnectionRef conn) {\n    Mutex::Locker l(lock);\n    auto it = conns.find(conn->peer_addr);\n    if (it != conns.end()) {\n      AsyncConnectionRef existing = it->second;\n\n      // lazy delete, see \"deleted_conns\"\n      // If conn already in, we will return 0\n      Mutex::Locker l(deleted_lock);\n      if (deleted_conns.erase(existing)) {\n        existing->get_perf_counter()->dec(l_msgr_active_connections);\n        conns.erase(it);\n      } else if (conn != existing) {\n        return -1;\n      }\n    }\n    conns[conn->peer_addr] = conn;\n    conn->get_perf_counter()->inc(l_msgr_active_connections);\n    accepting_conns.erase(conn);\n    return 0;\n  }\n\n  void learned_addr(const entity_addr_t &peer_addr_for_me);\n  void add_accept(Worker *w, ConnectedSocket cli_socket, entity_addr_t &addr);\n  NetworkStack *get_stack() {\n    return stack;\n  }\n\n  /**\n   * This wraps ms_deliver_get_authorizer. We use it for AsyncConnection.\n   */\n  AuthAuthorizer *get_authorizer(int peer_type, bool force_new) {\n    return ms_deliver_get_authorizer(peer_type, force_new);\n  }\n\n  /**\n   * This wraps ms_deliver_verify_authorizer; we use it for AsyncConnection.\n   */\n  bool verify_authorizer(Connection *con, int peer_type, int protocol, bufferlist& auth, bufferlist& auth_reply,\n                         bool& isvalid, CryptoKey& session_key) {\n    return ms_deliver_verify_authorizer(con, peer_type, protocol, auth,\n                                        auth_reply, isvalid, session_key);\n  }\n  /**\n   * Increment the global sequence for this AsyncMessenger and return it.\n   * This is for the connect protocol, although it doesn't hurt if somebody\n   * else calls it.\n   *\n   * @return a global sequence ID that nobody else has seen.\n   */\n  __u32 get_global_seq(__u32 old=0) {\n    ceph_spin_lock(&global_seq_lock);\n    if (old > global_seq)\n      global_seq = old;\n    __u32 ret = ++global_seq;\n    ceph_spin_unlock(&global_seq_lock);\n    return ret;\n  }\n  /**\n   * Get the protocol version we support for the given peer type: either\n   * a peer protocol (if it matches our own), the protocol version for the\n   * peer (if we're connecting), or our protocol version (if we're accepting).\n   */\n  int get_proto_version(int peer_type, bool connect) const;\n\n  /**\n   * Fill in the address and peer type for the local connection, which\n   * is used for delivering messages back to ourself.\n   */\n  void init_local_connection() {\n    Mutex::Locker l(lock);\n    _init_local_connection();\n  }\n\n  /**\n   * Unregister connection from `conns`\n   *\n   * See \"deleted_conns\"\n   */\n  void unregister_conn(AsyncConnectionRef conn) {\n    Mutex::Locker l(deleted_lock);\n    deleted_conns.insert(conn);\n\n    if (deleted_conns.size() >= ReapDeadConnectionThreshold) {\n      local_worker->center.dispatch_event_external(reap_handler);\n    }\n  }\n\n  /**\n   * Reap dead connection from `deleted_conns`\n   *\n   * @return the number of dead connections\n   *\n   * See \"deleted_conns\"\n   */\n  int reap_dead();\n\n  /**\n   * @} // AsyncMessenger Internals\n   */\n} ;\n\n#endif /* CEPH_ASYNCMESSENGER_H */\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#include <sys/types.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <netinet/ip.h>\n#include <netinet/tcp.h>\n#include <sys/uio.h>\n#include <limits.h>\n#include <poll.h>\n\n#include \"msg/Message.h\"\n#include \"Pipe.h\"\n#include \"SimpleMessenger.h\"\n\n#include \"common/debug.h\"\n#include \"common/errno.h\"\n#include \"common/valgrind.h\"\n\n// Below included to get encode_encrypt(); That probably should be in Crypto.h, instead\n\n#include \"auth/Crypto.h\"\n#include \"auth/cephx/CephxProtocol.h\"\n#include \"auth/AuthSessionHandler.h\"\n\n#include \"include/sock_compat.h\"\n\n// Constant to limit starting sequence number to 2^31.  Nothing special about it, just a big number.  PLR\n#define SEQ_MASK  0x7fffffff \n#define dout_subsys ceph_subsys_ms\n\n#undef dout_prefix\n#define dout_prefix *_dout << *this\nostream& Pipe::_pipe_prefix(std::ostream &out) const {\n  return out << \"-- \" << msgr->get_myinst().addr << \" >> \" << peer_addr << \" pipe(\" << this\n\t     << \" sd=\" << sd << \" :\" << port\n             << \" s=\" << state\n             << \" pgs=\" << peer_global_seq\n             << \" cs=\" << connect_seq\n             << \" l=\" << policy.lossy\n             << \" c=\" << connection_state\n             << \").\";\n}\n\nostream& operator<<(ostream &out, const Pipe &pipe) {\n  return pipe._pipe_prefix(out);\n}\n\n/**\n * The DelayedDelivery is for injecting delays into Message delivery off\n * the socket. It is only enabled if delays are requested, and if they\n * are then it pulls Messages off the DelayQueue and puts them into the\n * in_q (SimpleMessenger::dispatch_queue).\n * Please note that this probably has issues with Pipe shutdown and\n * replacement semantics. I've tried, but no guarantees.\n */\nclass Pipe::DelayedDelivery: public Thread {\n  Pipe *pipe;\n  std::deque< pair<utime_t,Message*> > delay_queue;\n  Mutex delay_lock;\n  Cond delay_cond;\n  int flush_count;\n  bool active_flush;\n  bool stop_delayed_delivery;\n  bool delay_dispatching; // we are in fast dispatch now\n  bool stop_fast_dispatching_flag; // we need to stop fast dispatching\n\npublic:\n  explicit DelayedDelivery(Pipe *p)\n    : pipe(p),\n      delay_lock(\"Pipe::DelayedDelivery::delay_lock\"), flush_count(0),\n      active_flush(false),\n      stop_delayed_delivery(false),\n      delay_dispatching(false),\n      stop_fast_dispatching_flag(false) { }\n  ~DelayedDelivery() override {\n    discard();\n  }\n  void *entry() override;\n  void queue(utime_t release, Message *m) {\n    Mutex::Locker l(delay_lock);\n    delay_queue.push_back(make_pair(release, m));\n    delay_cond.Signal();\n  }\n  void discard();\n  void flush();\n  bool is_flushing() {\n    Mutex::Locker l(delay_lock);\n    return flush_count > 0 || active_flush;\n  }\n  void wait_for_flush() {\n    Mutex::Locker l(delay_lock);\n    while (flush_count > 0 || active_flush)\n      delay_cond.Wait(delay_lock);\n  }\n  void stop() {\n    delay_lock.Lock();\n    stop_delayed_delivery = true;\n    delay_cond.Signal();\n    delay_lock.Unlock();\n  }\n  void steal_for_pipe(Pipe *new_owner) {\n    Mutex::Locker l(delay_lock);\n    pipe = new_owner;\n  }\n  /**\n   * We need to stop fast dispatching before we need to stop putting\n   * normal messages into the DispatchQueue.\n   */\n  void stop_fast_dispatching();\n};\n\n/**************************************\n * Pipe\n */\n\nPipe::Pipe(SimpleMessenger *r, int st, PipeConnection *con)\n  : RefCountedObject(r->cct),\n    reader_thread(this),\n    writer_thread(this),\n    delay_thread(NULL),\n    msgr(r),\n    conn_id(r->dispatch_queue.get_id()),\n    recv_ofs(0),\n    recv_len(0),\n    sd(-1), port(0),\n    peer_type(-1),\n    pipe_lock(\"SimpleMessenger::Pipe::pipe_lock\"),\n    state(st),\n    connection_state(NULL),\n    reader_running(false), reader_needs_join(false),\n    reader_dispatching(false), notify_on_dispatch_done(false),\n    writer_running(false),\n    in_q(&(r->dispatch_queue)),\n    send_keepalive(false),\n    send_keepalive_ack(false),\n    connect_seq(0), peer_global_seq(0),\n    out_seq(0), in_seq(0), in_seq_acked(0) {\n  ANNOTATE_BENIGN_RACE_SIZED(&sd, sizeof(sd), \"Pipe socket\");\n  ANNOTATE_BENIGN_RACE_SIZED(&state, sizeof(state), \"Pipe state\");\n  ANNOTATE_BENIGN_RACE_SIZED(&recv_len, sizeof(recv_len), \"Pipe recv_len\");\n  ANNOTATE_BENIGN_RACE_SIZED(&recv_ofs, sizeof(recv_ofs), \"Pipe recv_ofs\");\n  if (con) {\n    connection_state = con;\n    connection_state->reset_pipe(this);\n  } else {\n    connection_state = new PipeConnection(msgr->cct, msgr);\n    connection_state->pipe = get();\n  }\n\n  if (randomize_out_seq()) {\n    lsubdout(msgr->cct,ms,15) << \"Pipe(): Could not get random bytes to set seq number for session reset; set seq number to \" << out_seq << dendl;\n  }\n    \n\n  msgr->timeout = msgr->cct->_conf->ms_tcp_read_timeout * 1000; //convert to ms\n  if (msgr->timeout == 0)\n    msgr->timeout = -1;\n\n  recv_max_prefetch = msgr->cct->_conf->ms_tcp_prefetch_max_size;\n  recv_buf = new char[recv_max_prefetch];\n}\n\nPipe::~Pipe()\n{\n  assert(out_q.empty());\n  assert(sent.empty());\n  delete delay_thread;\n  delete[] recv_buf;\n}\n\nvoid Pipe::handle_ack(uint64_t seq)\n{\n  lsubdout(msgr->cct, ms, 15) << \"reader got ack seq \" << seq << dendl;\n  // trim sent list\n  while (!sent.empty() &&\n\t sent.front()->get_seq() <= seq) {\n    Message *m = sent.front();\n    sent.pop_front();\n    lsubdout(msgr->cct, ms, 10) << \"reader got ack seq \"\n\t\t\t\t<< seq << \" >= \" << m->get_seq() << \" on \" << m << \" \" << *m << dendl;\n    m->put();\n  }\n}\n\nvoid Pipe::start_reader()\n{\n  assert(pipe_lock.is_locked());\n  assert(!reader_running);\n  if (reader_needs_join) {\n    reader_thread.join();\n    reader_needs_join = false;\n  }\n  reader_running = true;\n  reader_thread.create(\"ms_pipe_read\", msgr->cct->_conf->ms_rwthread_stack_bytes);\n}\n\nvoid Pipe::maybe_start_delay_thread()\n{\n  if (!delay_thread) {\n    auto pos = msgr->cct->_conf->get_val<std::string>(\"ms_inject_delay_type\").find(ceph_entity_type_name(connection_state->peer_type));\n    if (pos != string::npos) {\n      lsubdout(msgr->cct, ms, 1) << \"setting up a delay queue on Pipe \" << this << dendl;\n      delay_thread = new DelayedDelivery(this);\n      delay_thread->create(\"ms_pipe_delay\");\n    }\n  }\n}\n\nvoid Pipe::start_writer()\n{\n  assert(pipe_lock.is_locked());\n  assert(!writer_running);\n  writer_running = true;\n  writer_thread.create(\"ms_pipe_write\", msgr->cct->_conf->ms_rwthread_stack_bytes);\n}\n\nvoid Pipe::join_reader()\n{\n  if (!reader_running)\n    return;\n  cond.Signal();\n  pipe_lock.Unlock();\n  reader_thread.join();\n  pipe_lock.Lock();\n  reader_needs_join = false;\n}\n\nvoid Pipe::DelayedDelivery::discard()\n{\n  lgeneric_subdout(pipe->msgr->cct, ms, 20) << *pipe << \"DelayedDelivery::discard\" << dendl;\n  Mutex::Locker l(delay_lock);\n  while (!delay_queue.empty()) {\n    Message *m = delay_queue.front().second;\n    pipe->in_q->dispatch_throttle_release(m->get_dispatch_throttle_size());\n    m->put();\n    delay_queue.pop_front();\n  }\n}\n\nvoid Pipe::DelayedDelivery::flush()\n{\n  lgeneric_subdout(pipe->msgr->cct, ms, 20) << *pipe << \"DelayedDelivery::flush\" << dendl;\n  Mutex::Locker l(delay_lock);\n  flush_count = delay_queue.size();\n  delay_cond.Signal();\n}\n\nvoid *Pipe::DelayedDelivery::entry()\n{\n  Mutex::Locker locker(delay_lock);\n  lgeneric_subdout(pipe->msgr->cct, ms, 20) << *pipe << \"DelayedDelivery::entry start\" << dendl;\n\n  while (!stop_delayed_delivery) {\n    if (delay_queue.empty()) {\n      lgeneric_subdout(pipe->msgr->cct, ms, 30) << *pipe << \"DelayedDelivery::entry sleeping on delay_cond because delay queue is empty\" << dendl;\n      delay_cond.Wait(delay_lock);\n      continue;\n    }\n    utime_t release = delay_queue.front().first;\n    Message *m = delay_queue.front().second;\n    string delay_msg_type = pipe->msgr->cct->_conf->ms_inject_delay_msg_type;\n    if (!flush_count &&\n        (release > ceph_clock_now() &&\n         (delay_msg_type.empty() || m->get_type_name() == delay_msg_type))) {\n      lgeneric_subdout(pipe->msgr->cct, ms, 10) << *pipe << \"DelayedDelivery::entry sleeping on delay_cond until \" << release << dendl;\n      delay_cond.WaitUntil(delay_lock, release);\n      continue;\n    }\n    lgeneric_subdout(pipe->msgr->cct, ms, 10) << *pipe << \"DelayedDelivery::entry dequeuing message \" << m << \" for delivery, past \" << release << dendl;\n    delay_queue.pop_front();\n    if (flush_count > 0) {\n      --flush_count;\n      active_flush = true;\n    }\n    if (pipe->in_q->can_fast_dispatch(m)) {\n      if (!stop_fast_dispatching_flag) {\n        delay_dispatching = true;\n        delay_lock.Unlock();\n        pipe->in_q->fast_dispatch(m);\n        delay_lock.Lock();\n        delay_dispatching = false;\n        if (stop_fast_dispatching_flag) {\n          // we need to let the stopping thread proceed\n          delay_cond.Signal();\n          delay_lock.Unlock();\n          delay_lock.Lock();\n        }\n      }\n    } else {\n      pipe->in_q->enqueue(m, m->get_priority(), pipe->conn_id);\n    }\n    active_flush = false;\n  }\n  lgeneric_subdout(pipe->msgr->cct, ms, 20) << *pipe << \"DelayedDelivery::entry stop\" << dendl;\n  return NULL;\n}\n\nvoid Pipe::DelayedDelivery::stop_fast_dispatching() {\n  Mutex::Locker l(delay_lock);\n  stop_fast_dispatching_flag = true;\n  while (delay_dispatching)\n    delay_cond.Wait(delay_lock);\n}\n\n\nint Pipe::accept()\n{\n  ldout(msgr->cct,10) << \"accept\" << dendl;\n  assert(pipe_lock.is_locked());\n  assert(state == STATE_ACCEPTING);\n\n  pipe_lock.Unlock();\n\n  // vars\n  bufferlist addrs;\n  entity_addr_t socket_addr;\n  socklen_t len;\n  int r;\n  char banner[strlen(CEPH_BANNER)+1];\n  bufferlist addrbl;\n  ceph_msg_connect connect;\n  ceph_msg_connect_reply reply;\n  Pipe *existing = 0;\n  bufferptr bp;\n  bufferlist authorizer, authorizer_reply;\n  bool authorizer_valid;\n  uint64_t feat_missing;\n  bool replaced = false;\n  // this variable denotes if the connection attempt from peer is a hard \n  // reset or not, it is true if there is an existing connection and the\n  // connection sequence from peer is equal to zero\n  bool is_reset_from_peer = false;\n  CryptoKey session_key;\n  int removed; // single-use down below\n\n  // this should roughly mirror pseudocode at\n  //  http://ceph.com/wiki/Messaging_protocol\n  int reply_tag = 0;\n  uint64_t existing_seq = -1;\n\n  // used for reading in the remote acked seq on connect\n  uint64_t newly_acked_seq = 0;\n\n  recv_reset();\n\n  set_socket_options();\n\n  // announce myself.\n  r = tcp_write(CEPH_BANNER, strlen(CEPH_BANNER));\n  if (r < 0) {\n    ldout(msgr->cct,10) << \"accept couldn't write banner\" << dendl;\n    goto fail_unlocked;\n  }\n\n  // and my addr\n  ::encode(msgr->my_inst.addr, addrs, 0);  // legacy\n\n  port = msgr->my_inst.addr.get_port();\n\n  // and peer's socket addr (they might not know their ip)\n  sockaddr_storage ss;\n  len = sizeof(ss);\n  r = ::getpeername(sd, (sockaddr*)&ss, &len);\n  if (r < 0) {\n    ldout(msgr->cct,0) << \"accept failed to getpeername \" << cpp_strerror(errno) << dendl;\n    goto fail_unlocked;\n  }\n  socket_addr.set_sockaddr((sockaddr*)&ss);\n  ::encode(socket_addr, addrs, 0);  // legacy\n\n  r = tcp_write(addrs.c_str(), addrs.length());\n  if (r < 0) {\n    ldout(msgr->cct,10) << \"accept couldn't write my+peer addr\" << dendl;\n    goto fail_unlocked;\n  }\n\n  ldout(msgr->cct,1) << \"accept sd=\" << sd << \" \" << socket_addr << dendl;\n  \n  // identify peer\n  if (tcp_read(banner, strlen(CEPH_BANNER)) < 0) {\n    ldout(msgr->cct,10) << \"accept couldn't read banner\" << dendl;\n    goto fail_unlocked;\n  }\n  if (memcmp(banner, CEPH_BANNER, strlen(CEPH_BANNER))) {\n    banner[strlen(CEPH_BANNER)] = 0;\n    ldout(msgr->cct,1) << \"accept peer sent bad banner '\" << banner << \"' (should be '\" << CEPH_BANNER << \"')\" << dendl;\n    goto fail_unlocked;\n  }\n  {\n    bufferptr tp(sizeof(ceph_entity_addr));\n    addrbl.push_back(std::move(tp));\n  }\n  if (tcp_read(addrbl.c_str(), addrbl.length()) < 0) {\n    ldout(msgr->cct,10) << \"accept couldn't read peer_addr\" << dendl;\n    goto fail_unlocked;\n  }\n  {\n    bufferlist::iterator ti = addrbl.begin();\n    ::decode(peer_addr, ti);\n  }\n\n  ldout(msgr->cct,10) << \"accept peer addr is \" << peer_addr << dendl;\n  if (peer_addr.is_blank_ip()) {\n    // peer apparently doesn't know what ip they have; figure it out for them.\n    int port = peer_addr.get_port();\n    peer_addr.u = socket_addr.u;\n    peer_addr.set_port(port);\n    ldout(msgr->cct,0) << \"accept peer addr is really \" << peer_addr\n\t    << \" (socket is \" << socket_addr << \")\" << dendl;\n  }\n  set_peer_addr(peer_addr);  // so that connection_state gets set up\n  \n  while (1) {\n    if (tcp_read((char*)&connect, sizeof(connect)) < 0) {\n      ldout(msgr->cct,10) << \"accept couldn't read connect\" << dendl;\n      goto fail_unlocked;\n    }\n\n    authorizer.clear();\n    if (connect.authorizer_len) {\n      bp = buffer::create(connect.authorizer_len);\n      if (tcp_read(bp.c_str(), connect.authorizer_len) < 0) {\n        ldout(msgr->cct,10) << \"accept couldn't read connect authorizer\" << dendl;\n        goto fail_unlocked;\n      }\n      authorizer.push_back(std::move(bp));\n      authorizer_reply.clear();\n    }\n\n    ldout(msgr->cct,20) << \"accept got peer connect_seq \" << connect.connect_seq\n\t     << \" global_seq \" << connect.global_seq\n\t     << dendl;\n    \n    msgr->lock.Lock();   // FIXME\n    pipe_lock.Lock();\n    if (msgr->dispatch_queue.stop)\n      goto shutting_down;\n    if (state != STATE_ACCEPTING) {\n      goto shutting_down;\n    }\n\n    // note peer's type, flags\n    set_peer_type(connect.host_type);\n    policy = msgr->get_policy(connect.host_type);\n    ldout(msgr->cct,10) << \"accept of host_type \" << connect.host_type\n\t\t\t<< \", policy.lossy=\" << policy.lossy\n\t\t\t<< \" policy.server=\" << policy.server\n\t\t\t<< \" policy.standby=\" << policy.standby\n\t\t\t<< \" policy.resetcheck=\" << policy.resetcheck\n\t\t\t<< dendl;\n\n    memset(&reply, 0, sizeof(reply));\n    reply.protocol_version = msgr->get_proto_version(peer_type, false);\n    msgr->lock.Unlock();\n\n    // mismatch?\n    ldout(msgr->cct,10) << \"accept my proto \" << reply.protocol_version\n\t     << \", their proto \" << connect.protocol_version << dendl;\n    if (connect.protocol_version != reply.protocol_version) {\n      reply.tag = CEPH_MSGR_TAG_BADPROTOVER;\n      goto reply;\n    }\n\n    // require signatures for cephx?\n    if (connect.authorizer_protocol == CEPH_AUTH_CEPHX) {\n      if (peer_type == CEPH_ENTITY_TYPE_OSD ||\n\t  peer_type == CEPH_ENTITY_TYPE_MDS ||\n\t  peer_type == CEPH_ENTITY_TYPE_MGR) {\n\tif (msgr->cct->_conf->cephx_require_signatures ||\n\t    msgr->cct->_conf->cephx_cluster_require_signatures) {\n\t  ldout(msgr->cct,10) << \"using cephx, requiring MSG_AUTH feature bit for cluster\" << dendl;\n\t  policy.features_required |= CEPH_FEATURE_MSG_AUTH;\n\t}\n\tif (msgr->cct->_conf->cephx_require_version >= 2 ||\n\t    msgr->cct->_conf->cephx_cluster_require_version >= 2) {\n\t  ldout(msgr->cct,10) << \"using cephx, requiring cephx v2 feature bit for cluster\" << dendl;\n\t  policy.features_required |= CEPH_FEATUREMASK_CEPHX_V2;\n\t}\n      } else {\n\tif (msgr->cct->_conf->cephx_require_signatures ||\n\t    msgr->cct->_conf->cephx_service_require_signatures) {\n\t  ldout(msgr->cct,10) << \"using cephx, requiring MSG_AUTH feature bit for service\" << dendl;\n\t  policy.features_required |= CEPH_FEATURE_MSG_AUTH;\n\t}\n\tif (msgr->cct->_conf->cephx_require_version >= 2 ||\n\t    msgr->cct->_conf->cephx_service_require_version >= 2) {\n\t  ldout(msgr->cct,10) << \"using cephx, requiring cephx v2 feature bit for cluster\" << dendl;\n\t  policy.features_required |= CEPH_FEATUREMASK_CEPHX_V2;\n\t}\n      }\n    }\n\n    feat_missing = policy.features_required & ~(uint64_t)connect.features;\n    if (feat_missing) {\n      ldout(msgr->cct,1) << \"peer missing required features \" << std::hex << feat_missing << std::dec << dendl;\n      reply.tag = CEPH_MSGR_TAG_FEATURES;\n      goto reply;\n    }\n    \n    // Check the authorizer.  If not good, bail out.\n\n    pipe_lock.Unlock();\n\n    if (!msgr->verify_authorizer(connection_state.get(), peer_type, connect.authorizer_protocol, authorizer,\n\t\t\t\t authorizer_reply, authorizer_valid, session_key) ||\n\t!authorizer_valid) {\n      ldout(msgr->cct,0) << \"accept: got bad authorizer\" << dendl;\n      pipe_lock.Lock();\n      if (state != STATE_ACCEPTING)\n\tgoto shutting_down_msgr_unlocked;\n      reply.tag = CEPH_MSGR_TAG_BADAUTHORIZER;\n      session_security.reset();\n      goto reply;\n    } \n\n    // We've verified the authorizer for this pipe, so set up the session security structure.  PLR\n\n    ldout(msgr->cct,10) << \"accept:  setting up session_security.\" << dendl;\n\n  retry_existing_lookup:\n    msgr->lock.Lock();\n    pipe_lock.Lock();\n    if (msgr->dispatch_queue.stop)\n      goto shutting_down;\n    if (state != STATE_ACCEPTING)\n      goto shutting_down;\n    \n    // existing?\n    existing = msgr->_lookup_pipe(peer_addr);\n    if (existing) {\n      existing->pipe_lock.Lock(true);  // skip lockdep check (we are locking a second Pipe here)\n      if (existing->reader_dispatching) {\n\t/** we need to wait, or we can deadlock if downstream\n\t *  fast_dispatchers are (naughtily!) waiting on resources\n\t *  held by somebody trying to make use of the SimpleMessenger lock.\n\t *  So drop locks, wait, and retry. It just looks like a slow network\n\t *  to everybody else.\n\t *\n\t *  We take a ref to existing here since it might get reaped before we\n\t *  wake up (see bug #15870).  We can be confident that it lived until\n\t *  locked it since we held the msgr lock from _lookup_pipe through to\n\t *  locking existing->lock and checking reader_dispatching.\n\t */\n\texisting->get();\n\tpipe_lock.Unlock();\n\tmsgr->lock.Unlock();\n\texisting->notify_on_dispatch_done = true;\n\twhile (existing->reader_dispatching)\n\t  existing->cond.Wait(existing->pipe_lock);\n\texisting->pipe_lock.Unlock();\n\texisting->put();\n\texisting = nullptr;\n\tgoto retry_existing_lookup;\n      }\n\n      if (connect.global_seq < existing->peer_global_seq) {\n\tldout(msgr->cct,10) << \"accept existing \" << existing << \".gseq \" << existing->peer_global_seq\n\t\t << \" > \" << connect.global_seq << \", RETRY_GLOBAL\" << dendl;\n\treply.tag = CEPH_MSGR_TAG_RETRY_GLOBAL;\n\treply.global_seq = existing->peer_global_seq;  // so we can send it below..\n\texisting->pipe_lock.Unlock();\n\tmsgr->lock.Unlock();\n\tgoto reply;\n      } else {\n\tldout(msgr->cct,10) << \"accept existing \" << existing << \".gseq \" << existing->peer_global_seq\n\t\t << \" <= \" << connect.global_seq << \", looks ok\" << dendl;\n      }\n      \n      if (existing->policy.lossy) {\n\tldout(msgr->cct,0) << \"accept replacing existing (lossy) channel (new one lossy=\"\n\t        << policy.lossy << \")\" << dendl;\n\texisting->was_session_reset();\n\tgoto replace;\n      }\n\n      ldout(msgr->cct,0) << \"accept connect_seq \" << connect.connect_seq\n\t\t\t << \" vs existing \" << existing->connect_seq\n\t\t\t << \" state \" << existing->get_state_name() << dendl;\n\n      if (connect.connect_seq == 0 && existing->connect_seq > 0) {\n\tldout(msgr->cct,0) << \"accept peer reset, then tried to connect to us, replacing\" << dendl;\n        // this is a hard reset from peer\n        is_reset_from_peer = true;\n\tif (policy.resetcheck)\n\t  existing->was_session_reset(); // this resets out_queue, msg_ and connect_seq #'s\n\tgoto replace;\n      }\n\n      if (connect.connect_seq < existing->connect_seq) {\n\t// old attempt, or we sent READY but they didn't get it.\n\tldout(msgr->cct,10) << \"accept existing \" << existing << \".cseq \" << existing->connect_seq\n\t\t\t    << \" > \" << connect.connect_seq << \", RETRY_SESSION\" << dendl;\n\tgoto retry_session;\n      }\n\n      if (connect.connect_seq == existing->connect_seq) {\n\t// if the existing connection successfully opened, and/or\n\t// subsequently went to standby, then the peer should bump\n\t// their connect_seq and retry: this is not a connection race\n\t// we need to resolve here.\n\tif (existing->state == STATE_OPEN ||\n\t    existing->state == STATE_STANDBY) {\n\t  ldout(msgr->cct,10) << \"accept connection race, existing \" << existing\n\t\t\t      << \".cseq \" << existing->connect_seq\n\t\t\t      << \" == \" << connect.connect_seq\n\t\t\t      << \", OPEN|STANDBY, RETRY_SESSION\" << dendl;\n\t  goto retry_session;\n\t}\n\n\t// connection race?\n\tif (peer_addr < msgr->my_inst.addr ||\n\t    existing->policy.server) {\n\t  // incoming wins\n\t  ldout(msgr->cct,10) << \"accept connection race, existing \" << existing << \".cseq \" << existing->connect_seq\n\t\t   << \" == \" << connect.connect_seq << \", or we are server, replacing my attempt\" << dendl;\n\t  if (!(existing->state == STATE_CONNECTING ||\n\t\texisting->state == STATE_WAIT))\n\t    lderr(msgr->cct) << \"accept race bad state, would replace, existing=\"\n\t\t\t     << existing->get_state_name()\n\t\t\t     << \" \" << existing << \".cseq=\" << existing->connect_seq\n\t\t\t     << \" == \" << connect.connect_seq\n\t\t\t     << dendl;\n\t  assert(existing->state == STATE_CONNECTING ||\n\t\t existing->state == STATE_WAIT);\n\t  goto replace;\n\t} else {\n\t  // our existing outgoing wins\n\t  ldout(msgr->cct,10) << \"accept connection race, existing \" << existing << \".cseq \" << existing->connect_seq\n\t\t   << \" == \" << connect.connect_seq << \", sending WAIT\" << dendl;\n\t  assert(peer_addr > msgr->my_inst.addr);\n\t  if (!(existing->state == STATE_CONNECTING))\n\t    lderr(msgr->cct) << \"accept race bad state, would send wait, existing=\"\n\t\t\t     << existing->get_state_name()\n\t\t\t     << \" \" << existing << \".cseq=\" << existing->connect_seq\n\t\t\t     << \" == \" << connect.connect_seq\n\t\t\t     << dendl;\n\t  assert(existing->state == STATE_CONNECTING);\n\t  // make sure our outgoing connection will follow through\n\t  existing->_send_keepalive();\n\t  reply.tag = CEPH_MSGR_TAG_WAIT;\n\t  existing->pipe_lock.Unlock();\n\t  msgr->lock.Unlock();\n\t  goto reply;\n\t}\n      }\n\n      assert(connect.connect_seq > existing->connect_seq);\n      assert(connect.global_seq >= existing->peer_global_seq);\n      if (policy.resetcheck &&   // RESETSESSION only used by servers; peers do not reset each other\n\t  existing->connect_seq == 0) {\n\tldout(msgr->cct,0) << \"accept we reset (peer sent cseq \" << connect.connect_seq \n\t\t << \", \" << existing << \".cseq = \" << existing->connect_seq\n\t\t << \"), sending RESETSESSION\" << dendl;\n\treply.tag = CEPH_MSGR_TAG_RESETSESSION;\n\tmsgr->lock.Unlock();\n\texisting->pipe_lock.Unlock();\n\tgoto reply;\n      }\n\n      // reconnect\n      ldout(msgr->cct,10) << \"accept peer sent cseq \" << connect.connect_seq\n\t       << \" > \" << existing->connect_seq << dendl;\n      goto replace;\n    } // existing\n    else if (connect.connect_seq > 0) {\n      // we reset, and they are opening a new session\n      ldout(msgr->cct,0) << \"accept we reset (peer sent cseq \" << connect.connect_seq << \"), sending RESETSESSION\" << dendl;\n      msgr->lock.Unlock();\n      reply.tag = CEPH_MSGR_TAG_RESETSESSION;\n      goto reply;\n    } else {\n      // new session\n      ldout(msgr->cct,10) << \"accept new session\" << dendl;\n      existing = NULL;\n      goto open;\n    }\n    ceph_abort();\n\n  retry_session:\n    assert(existing->pipe_lock.is_locked());\n    assert(pipe_lock.is_locked());\n    reply.tag = CEPH_MSGR_TAG_RETRY_SESSION;\n    reply.connect_seq = existing->connect_seq + 1;\n    existing->pipe_lock.Unlock();\n    msgr->lock.Unlock();\n    goto reply;    \n\n  reply:\n    assert(pipe_lock.is_locked());\n    reply.features = ((uint64_t)connect.features & policy.features_supported) | policy.features_required;\n    reply.authorizer_len = authorizer_reply.length();\n    pipe_lock.Unlock();\n    r = tcp_write((char*)&reply, sizeof(reply));\n    if (r < 0)\n      goto fail_unlocked;\n    if (reply.authorizer_len) {\n      r = tcp_write(authorizer_reply.c_str(), authorizer_reply.length());\n      if (r < 0)\n\tgoto fail_unlocked;\n    }\n  }\n  \n replace:\n  assert(existing->pipe_lock.is_locked());\n  assert(pipe_lock.is_locked());\n  // if it is a hard reset from peer, we don't need a round-trip to negotiate in/out sequence\n  if ((connect.features & CEPH_FEATURE_RECONNECT_SEQ) && !is_reset_from_peer) {\n    reply_tag = CEPH_MSGR_TAG_SEQ;\n    existing_seq = existing->in_seq;\n  }\n  ldout(msgr->cct,10) << \"accept replacing \" << existing << dendl;\n  existing->stop();\n  existing->unregister_pipe();\n  replaced = true;\n\n  if (existing->policy.lossy) {\n    // disconnect from the Connection\n    assert(existing->connection_state);\n    if (existing->connection_state->clear_pipe(existing))\n      msgr->dispatch_queue.queue_reset(existing->connection_state.get());\n  } else {\n    // queue a reset on the new connection, which we're dumping for the old\n    msgr->dispatch_queue.queue_reset(connection_state.get());\n\n    // drop my Connection, and take a ref to the existing one. do not\n    // clear existing->connection_state, since read_message and\n    // write_message both dereference it without pipe_lock.\n    connection_state = existing->connection_state;\n\n    // make existing Connection reference us\n    connection_state->reset_pipe(this);\n\n    if (existing->delay_thread) {\n      existing->delay_thread->steal_for_pipe(this);\n      delay_thread = existing->delay_thread;\n      existing->delay_thread = NULL;\n      delay_thread->flush();\n    }\n\n    // steal incoming queue\n    uint64_t replaced_conn_id = conn_id;\n    conn_id = existing->conn_id;\n    existing->conn_id = replaced_conn_id;\n\n    // reset the in_seq if this is a hard reset from peer,\n    // otherwise we respect our original connection's value\n    in_seq = is_reset_from_peer ? 0 : existing->in_seq;\n    in_seq_acked = in_seq;\n\n    // steal outgoing queue and out_seq\n    existing->requeue_sent();\n    out_seq = existing->out_seq;\n    ldout(msgr->cct,10) << \"accept re-queuing on out_seq \" << out_seq << \" in_seq \" << in_seq << dendl;\n    for (map<int, list<Message*> >::iterator p = existing->out_q.begin();\n         p != existing->out_q.end();\n         ++p)\n      out_q[p->first].splice(out_q[p->first].begin(), p->second);\n  }\n  existing->stop_and_wait();\n  existing->pipe_lock.Unlock();\n\n open:\n  // open\n  assert(pipe_lock.is_locked());\n  connect_seq = connect.connect_seq + 1;\n  peer_global_seq = connect.global_seq;\n  assert(state == STATE_ACCEPTING);\n  state = STATE_OPEN;\n  ldout(msgr->cct,10) << \"accept success, connect_seq = \" << connect_seq << \", sending READY\" << dendl;\n\n  // send READY reply\n  reply.tag = (reply_tag ? reply_tag : CEPH_MSGR_TAG_READY);\n  reply.features = policy.features_supported;\n  reply.global_seq = msgr->get_global_seq();\n  reply.connect_seq = connect_seq;\n  reply.flags = 0;\n  reply.authorizer_len = authorizer_reply.length();\n  if (policy.lossy)\n    reply.flags = reply.flags | CEPH_MSG_CONNECT_LOSSY;\n\n  connection_state->set_features((uint64_t)reply.features & (uint64_t)connect.features);\n  ldout(msgr->cct,10) << \"accept features \" << connection_state->get_features() << dendl;\n\n  session_security.reset(\n      get_auth_session_handler(msgr->cct,\n\t\t\t       connect.authorizer_protocol,\n\t\t\t       session_key,\n\t\t\t       connection_state->get_features()));\n\n  // notify\n  msgr->dispatch_queue.queue_accept(connection_state.get());\n  msgr->ms_deliver_handle_fast_accept(connection_state.get());\n\n  // ok!\n  if (msgr->dispatch_queue.stop)\n    goto shutting_down;\n  removed = msgr->accepting_pipes.erase(this);\n  assert(removed == 1);\n  register_pipe();\n  msgr->lock.Unlock();\n  pipe_lock.Unlock();\n\n  r = tcp_write((char*)&reply, sizeof(reply));\n  if (r < 0) {\n    goto fail_registered;\n  }\n\n  if (reply.authorizer_len) {\n    r = tcp_write(authorizer_reply.c_str(), authorizer_reply.length());\n    if (r < 0) {\n      goto fail_registered;\n    }\n  }\n\n  if (reply_tag == CEPH_MSGR_TAG_SEQ) {\n    if (tcp_write((char*)&existing_seq, sizeof(existing_seq)) < 0) {\n      ldout(msgr->cct,2) << \"accept write error on in_seq\" << dendl;\n      goto fail_registered;\n    }\n    if (tcp_read((char*)&newly_acked_seq, sizeof(newly_acked_seq)) < 0) {\n      ldout(msgr->cct,2) << \"accept read error on newly_acked_seq\" << dendl;\n      goto fail_registered;\n    }\n  }\n\n  pipe_lock.Lock();\n  discard_requeued_up_to(newly_acked_seq);\n  if (state != STATE_CLOSED) {\n    ldout(msgr->cct,10) << \"accept starting writer, state \" << get_state_name() << dendl;\n    start_writer();\n  }\n  ldout(msgr->cct,20) << \"accept done\" << dendl;\n\n  maybe_start_delay_thread();\n\n  return 0;   // success.\n\n fail_registered:\n  ldout(msgr->cct, 10) << \"accept fault after register\" << dendl;\n\n  if (msgr->cct->_conf->ms_inject_internal_delays) {\n    ldout(msgr->cct, 10) << \" sleep for \" << msgr->cct->_conf->ms_inject_internal_delays << dendl;\n    utime_t t;\n    t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n    t.sleep();\n  }\n\n fail_unlocked:\n  pipe_lock.Lock();\n  if (state != STATE_CLOSED) {\n    bool queued = is_queued();\n    ldout(msgr->cct, 10) << \"  queued = \" << (int)queued << dendl;\n    if (queued) {\n      state = policy.server ? STATE_STANDBY : STATE_CONNECTING;\n    } else if (replaced) {\n      state = STATE_STANDBY;\n    } else {\n      state = STATE_CLOSED;\n      state_closed = true;\n    }\n    fault();\n    if (queued || replaced)\n      start_writer();\n  }\n  return -1;\n\n shutting_down:\n  msgr->lock.Unlock();\n shutting_down_msgr_unlocked:\n  assert(pipe_lock.is_locked());\n\n  if (msgr->cct->_conf->ms_inject_internal_delays) {\n    ldout(msgr->cct, 10) << \" sleep for \" << msgr->cct->_conf->ms_inject_internal_delays << dendl;\n    utime_t t;\n    t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n    t.sleep();\n  }\n\n  state = STATE_CLOSED;\n  state_closed = true;\n  fault();\n  return -1;\n}\n\nvoid Pipe::set_socket_options()\n{\n  // disable Nagle algorithm?\n  if (msgr->cct->_conf->ms_tcp_nodelay) {\n    int flag = 1;\n    int r = ::setsockopt(sd, IPPROTO_TCP, TCP_NODELAY, (char*)&flag, sizeof(flag));\n    if (r < 0) {\n      r = -errno;\n      ldout(msgr->cct,0) << \"couldn't set TCP_NODELAY: \"\n                         << cpp_strerror(r) << dendl;\n    }\n  }\n  if (msgr->cct->_conf->ms_tcp_rcvbuf) {\n    int size = msgr->cct->_conf->ms_tcp_rcvbuf;\n    int r = ::setsockopt(sd, SOL_SOCKET, SO_RCVBUF, (void*)&size, sizeof(size));\n    if (r < 0)  {\n      r = -errno;\n      ldout(msgr->cct,0) << \"couldn't set SO_RCVBUF to \" << size\n                         << \": \" << cpp_strerror(r) << dendl;\n    }\n  }\n\n  // block ESIGPIPE\n#ifdef CEPH_USE_SO_NOSIGPIPE\n  int val = 1;\n  int r = ::setsockopt(sd, SOL_SOCKET, SO_NOSIGPIPE, (void*)&val, sizeof(val));\n  if (r) {\n    r = -errno;\n    ldout(msgr->cct,0) << \"couldn't set SO_NOSIGPIPE: \"\n                       << cpp_strerror(r) << dendl;\n  }\n#endif\n\n#ifdef SO_PRIORITY\n  int prio = msgr->get_socket_priority();\n  if (prio >= 0) {\n    int r = -1;\n#ifdef IPTOS_CLASS_CS6\n    int iptos = IPTOS_CLASS_CS6;\n    int addr_family = 0;\n    if (!peer_addr.is_blank_ip()) {\n      addr_family = peer_addr.get_family();\n    } else {\n      addr_family = msgr->get_myaddr().get_family();\n    }\n    switch (addr_family) {\n    case AF_INET:\n      r = ::setsockopt(sd, IPPROTO_IP, IP_TOS, &iptos, sizeof(iptos));\n      break;\n    case AF_INET6:\n      r = ::setsockopt(sd, IPPROTO_IPV6, IPV6_TCLASS, &iptos, sizeof(iptos));\n      break;\n    default:\n      lderr(msgr->cct) << \"couldn't set ToS of unknown family (\"\n\t\t       << addr_family << \")\"\n\t\t       << \" to \" << iptos << dendl;\n      return;\n    }\n    if (r < 0) {\n      r = -errno;\n      ldout(msgr->cct,0) << \"couldn't set TOS to \" << iptos\n\t\t\t << \": \" << cpp_strerror(r) << dendl;\n    }\n#endif\n    // setsockopt(IPTOS_CLASS_CS6) sets the priority of the socket as 0.\n    // See http://goo.gl/QWhvsD and http://goo.gl/laTbjT\n    // We need to call setsockopt(SO_PRIORITY) after it.\n    r = ::setsockopt(sd, SOL_SOCKET, SO_PRIORITY, &prio, sizeof(prio));\n    if (r < 0) {\n      r = -errno;\n      ldout(msgr->cct,0) << \"couldn't set SO_PRIORITY to \" << prio\n                         << \": \" << cpp_strerror(r) << dendl;\n    }\n  }\n#endif\n}\n\nint Pipe::connect()\n{\n  bool got_bad_auth = false;\n\n  ldout(msgr->cct,10) << \"connect \" << connect_seq << dendl;\n  assert(pipe_lock.is_locked());\n\n  __u32 cseq = connect_seq;\n  __u32 gseq = msgr->get_global_seq();\n\n  // stop reader thread\n  join_reader();\n\n  pipe_lock.Unlock();\n  \n  char tag = -1;\n  int rc = -1;\n  struct msghdr msg;\n  struct iovec msgvec[2];\n  int msglen;\n  char banner[strlen(CEPH_BANNER) + 1];  // extra byte makes coverity happy\n  entity_addr_t paddr;\n  entity_addr_t peer_addr_for_me, socket_addr;\n  AuthAuthorizer *authorizer = NULL;\n  bufferlist addrbl, myaddrbl;\n  const md_config_t *conf = msgr->cct->_conf;\n\n  // close old socket.  this is safe because we stopped the reader thread above.\n  if (sd >= 0)\n    ::close(sd);\n\n  // create socket?\n  sd = ::socket(peer_addr.get_family(), SOCK_STREAM, 0);\n  if (sd < 0) {\n    rc = -errno;\n    lderr(msgr->cct) << \"connect couldn't create socket \" << cpp_strerror(rc) << dendl;\n    goto fail;\n  }\n\n  recv_reset();\n\n  set_socket_options();\n\n  {\n    entity_addr_t addr2bind = msgr->get_myaddr();\n    if (msgr->cct->_conf->ms_bind_before_connect && (!addr2bind.is_blank_ip())) {\n      addr2bind.set_port(0);\n      int r = ::bind(sd , addr2bind.get_sockaddr(), addr2bind.get_sockaddr_len());\n      if (r < 0) {\n        ldout(msgr->cct,2) << \"client bind error \" << \", \" << cpp_strerror(errno) << dendl;\n        goto fail;\n      }\n    }\n  }\n\n  // connect!\n  ldout(msgr->cct,10) << \"connecting to \" << peer_addr << dendl;\n  rc = ::connect(sd, peer_addr.get_sockaddr(), peer_addr.get_sockaddr_len());\n  if (rc < 0) {\n    int stored_errno = errno;\n    ldout(msgr->cct,2) << \"connect error \" << peer_addr\n\t     << \", \" << cpp_strerror(stored_errno) << dendl;\n    if (stored_errno == ECONNREFUSED) {\n      ldout(msgr->cct, 2) << \"connection refused!\" << dendl;\n      msgr->dispatch_queue.queue_refused(connection_state.get());\n    }\n    goto fail;\n  }\n\n  // verify banner\n  // FIXME: this should be non-blocking, or in some other way verify the banner as we get it.\n  rc = tcp_read((char*)&banner, strlen(CEPH_BANNER));\n  if (rc < 0) {\n    ldout(msgr->cct,2) << \"connect couldn't read banner, \" << cpp_strerror(rc) << dendl;\n    goto fail;\n  }\n  if (memcmp(banner, CEPH_BANNER, strlen(CEPH_BANNER))) {\n    ldout(msgr->cct,0) << \"connect protocol error (bad banner) on peer \" << peer_addr << dendl;\n    goto fail;\n  }\n\n  memset(&msg, 0, sizeof(msg));\n  msgvec[0].iov_base = banner;\n  msgvec[0].iov_len = strlen(CEPH_BANNER);\n  msg.msg_iov = msgvec;\n  msg.msg_iovlen = 1;\n  msglen = msgvec[0].iov_len;\n  rc = do_sendmsg(&msg, msglen);\n  if (rc < 0) {\n    ldout(msgr->cct,2) << \"connect couldn't write my banner, \" << cpp_strerror(rc) << dendl;\n    goto fail;\n  }\n\n  // identify peer\n  {\n#if defined(__linux__) || defined(DARWIN) || defined(__FreeBSD__)\n    bufferptr p(sizeof(ceph_entity_addr) * 2);\n#else\n    int wirelen = sizeof(__u32) * 2 + sizeof(ceph_sockaddr_storage);\n    bufferptr p(wirelen * 2);\n#endif\n    addrbl.push_back(std::move(p));\n  }\n  rc = tcp_read(addrbl.c_str(), addrbl.length());\n  if (rc < 0) {\n    ldout(msgr->cct,2) << \"connect couldn't read peer addrs, \" << cpp_strerror(rc) << dendl;\n    goto fail;\n  }\n  try {\n    bufferlist::iterator p = addrbl.begin();\n    ::decode(paddr, p);\n    ::decode(peer_addr_for_me, p);\n  }\n  catch (buffer::error& e) {\n    ldout(msgr->cct,2) << \"connect couldn't decode peer addrs: \" << e.what()\n\t\t       << dendl;\n    goto fail;\n  }\n  port = peer_addr_for_me.get_port();\n\n  ldout(msgr->cct,20) << \"connect read peer addr \" << paddr << \" on socket \" << sd << dendl;\n  if (peer_addr != paddr) {\n    if (paddr.is_blank_ip() &&\n\tpeer_addr.get_port() == paddr.get_port() &&\n\tpeer_addr.get_nonce() == paddr.get_nonce()) {\n      ldout(msgr->cct,0) << \"connect claims to be \" \n\t      << paddr << \" not \" << peer_addr << \" - presumably this is the same node!\" << dendl;\n    } else {\n      ldout(msgr->cct,10) << \"connect claims to be \"\n\t\t\t  << paddr << \" not \" << peer_addr << dendl;\n      goto fail;\n    }\n  }\n\n  ldout(msgr->cct,20) << \"connect peer addr for me is \" << peer_addr_for_me << dendl;\n\n  msgr->learned_addr(peer_addr_for_me);\n\n  ::encode(msgr->my_inst.addr, myaddrbl, 0);  // legacy\n\n  memset(&msg, 0, sizeof(msg));\n  msgvec[0].iov_base = myaddrbl.c_str();\n  msgvec[0].iov_len = myaddrbl.length();\n  msg.msg_iov = msgvec;\n  msg.msg_iovlen = 1;\n  msglen = msgvec[0].iov_len;\n  rc = do_sendmsg(&msg, msglen);\n  if (rc < 0) {\n    ldout(msgr->cct,2) << \"connect couldn't write my addr, \" << cpp_strerror(rc) << dendl;\n    goto fail;\n  }\n  ldout(msgr->cct,10) << \"connect sent my addr \" << msgr->my_inst.addr << dendl;\n\n\n  while (1) {\n    delete authorizer;\n    authorizer = msgr->get_authorizer(peer_type, false);\n    bufferlist authorizer_reply;\n\n    ceph_msg_connect connect;\n    connect.features = policy.features_supported;\n    connect.host_type = msgr->get_myinst().name.type();\n    connect.global_seq = gseq;\n    connect.connect_seq = cseq;\n    connect.protocol_version = msgr->get_proto_version(peer_type, true);\n    connect.authorizer_protocol = authorizer ? authorizer->protocol : 0;\n    connect.authorizer_len = authorizer ? authorizer->bl.length() : 0;\n    if (authorizer) \n      ldout(msgr->cct,10) << \"connect.authorizer_len=\" << connect.authorizer_len\n\t       << \" protocol=\" << connect.authorizer_protocol << dendl;\n    connect.flags = 0;\n    if (policy.lossy)\n      connect.flags |= CEPH_MSG_CONNECT_LOSSY;  // this is fyi, actually, server decides!\n    memset(&msg, 0, sizeof(msg));\n    msgvec[0].iov_base = (char*)&connect;\n    msgvec[0].iov_len = sizeof(connect);\n    msg.msg_iov = msgvec;\n    msg.msg_iovlen = 1;\n    msglen = msgvec[0].iov_len;\n    if (authorizer) {\n      msgvec[1].iov_base = authorizer->bl.c_str();\n      msgvec[1].iov_len = authorizer->bl.length();\n      msg.msg_iovlen++;\n      msglen += msgvec[1].iov_len;\n    }\n\n    ldout(msgr->cct,10) << \"connect sending gseq=\" << gseq << \" cseq=\" << cseq\n\t     << \" proto=\" << connect.protocol_version << dendl;\n    rc = do_sendmsg(&msg, msglen);\n    if (rc < 0) {\n      ldout(msgr->cct,2) << \"connect couldn't write gseq, cseq, \" << cpp_strerror(rc) << dendl;\n      goto fail;\n    }\n\n    ldout(msgr->cct,20) << \"connect wrote (self +) cseq, waiting for reply\" << dendl;\n    ceph_msg_connect_reply reply;\n    rc = tcp_read((char*)&reply, sizeof(reply));\n    if (rc < 0) {\n      ldout(msgr->cct,2) << \"connect read reply \" << cpp_strerror(rc) << dendl;\n      goto fail;\n    }\n\n    ldout(msgr->cct,20) << \"connect got reply tag \" << (int)reply.tag\n\t\t\t<< \" connect_seq \" << reply.connect_seq\n\t\t\t<< \" global_seq \" << reply.global_seq\n\t\t\t<< \" proto \" << reply.protocol_version\n\t\t\t<< \" flags \" << (int)reply.flags\n\t\t\t<< \" features \" << reply.features\n\t\t\t<< dendl;\n\n    authorizer_reply.clear();\n\n    if (reply.authorizer_len) {\n      ldout(msgr->cct,10) << \"reply.authorizer_len=\" << reply.authorizer_len << dendl;\n      bufferptr bp = buffer::create(reply.authorizer_len);\n      rc = tcp_read(bp.c_str(), reply.authorizer_len);\n      if (rc < 0) {\n        ldout(msgr->cct,10) << \"connect couldn't read connect authorizer_reply\" << cpp_strerror(rc) << dendl;\n\tgoto fail;\n      }\n      authorizer_reply.push_back(bp);\n    }\n\n    if (authorizer) {\n      bufferlist::iterator iter = authorizer_reply.begin();\n      if (!authorizer->verify_reply(iter)) {\n        ldout(msgr->cct,0) << \"failed verifying authorize reply\" << dendl;\n\tgoto fail;\n      }\n    }\n\n    if (conf->ms_inject_internal_delays) {\n      ldout(msgr->cct, 10) << \" sleep for \" << msgr->cct->_conf->ms_inject_internal_delays << dendl;\n      utime_t t;\n      t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n      t.sleep();\n    }\n\n    pipe_lock.Lock();\n    if (state != STATE_CONNECTING) {\n      ldout(msgr->cct,0) << \"connect got RESETSESSION but no longer connecting\" << dendl;\n      goto stop_locked;\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_FEATURES) {\n      ldout(msgr->cct,0) << \"connect protocol feature mismatch, my \" << std::hex\n\t      << connect.features << \" < peer \" << reply.features\n\t      << \" missing \" << (reply.features & ~policy.features_supported)\n\t      << std::dec << dendl;\n      goto fail_locked;\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_BADPROTOVER) {\n      ldout(msgr->cct,0) << \"connect protocol version mismatch, my \" << connect.protocol_version\n\t      << \" != \" << reply.protocol_version << dendl;\n      goto fail_locked;\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_BADAUTHORIZER) {\n      ldout(msgr->cct,0) << \"connect got BADAUTHORIZER\" << dendl;\n      if (got_bad_auth)\n        goto stop_locked;\n      got_bad_auth = true;\n      pipe_lock.Unlock();\n      delete authorizer;\n      authorizer = msgr->get_authorizer(peer_type, true);  // try harder\n      continue;\n    }\n    if (reply.tag == CEPH_MSGR_TAG_RESETSESSION) {\n      ldout(msgr->cct,0) << \"connect got RESETSESSION\" << dendl;\n      was_session_reset();\n      cseq = 0;\n      pipe_lock.Unlock();\n      continue;\n    }\n    if (reply.tag == CEPH_MSGR_TAG_RETRY_GLOBAL) {\n      gseq = msgr->get_global_seq(reply.global_seq);\n      ldout(msgr->cct,10) << \"connect got RETRY_GLOBAL \" << reply.global_seq\n\t       << \" chose new \" << gseq << dendl;\n      pipe_lock.Unlock();\n      continue;\n    }\n    if (reply.tag == CEPH_MSGR_TAG_RETRY_SESSION) {\n      assert(reply.connect_seq > connect_seq);\n      ldout(msgr->cct,10) << \"connect got RETRY_SESSION \" << connect_seq\n\t       << \" -> \" << reply.connect_seq << dendl;\n      cseq = connect_seq = reply.connect_seq;\n      pipe_lock.Unlock();\n      continue;\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_WAIT) {\n      ldout(msgr->cct,3) << \"connect got WAIT (connection race)\" << dendl;\n      state = STATE_WAIT;\n      goto stop_locked;\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_READY ||\n        reply.tag == CEPH_MSGR_TAG_SEQ) {\n      uint64_t feat_missing = policy.features_required & ~(uint64_t)reply.features;\n      if (feat_missing) {\n\tldout(msgr->cct,1) << \"missing required features \" << std::hex << feat_missing << std::dec << dendl;\n\tgoto fail_locked;\n      }\n\n      if (reply.tag == CEPH_MSGR_TAG_SEQ) {\n        ldout(msgr->cct,10) << \"got CEPH_MSGR_TAG_SEQ, reading acked_seq and writing in_seq\" << dendl;\n        uint64_t newly_acked_seq = 0;\n        rc = tcp_read((char*)&newly_acked_seq, sizeof(newly_acked_seq));\n        if (rc < 0) {\n          ldout(msgr->cct,2) << \"connect read error on newly_acked_seq\" << cpp_strerror(rc) << dendl;\n          goto fail_locked;\n        }\n\tldout(msgr->cct,2) << \" got newly_acked_seq \" << newly_acked_seq\n\t\t\t   << \" vs out_seq \" << out_seq << dendl;\n\twhile (newly_acked_seq > out_seq) {\n\t  Message *m = _get_next_outgoing();\n\t  assert(m);\n\t  ldout(msgr->cct,2) << \" discarding previously sent \" << m->get_seq()\n\t\t\t     << \" \" << *m << dendl;\n\t  assert(m->get_seq() <= newly_acked_seq);\n\t  m->put();\n\t  ++out_seq;\n\t}\n        if (tcp_write((char*)&in_seq, sizeof(in_seq)) < 0) {\n          ldout(msgr->cct,2) << \"connect write error on in_seq\" << dendl;\n          goto fail_locked;\n        }\n      }\n\n      // hooray!\n      peer_global_seq = reply.global_seq;\n      policy.lossy = reply.flags & CEPH_MSG_CONNECT_LOSSY;\n      state = STATE_OPEN;\n      connect_seq = cseq + 1;\n      assert(connect_seq == reply.connect_seq);\n      backoff = utime_t();\n      connection_state->set_features((uint64_t)reply.features & (uint64_t)connect.features);\n      ldout(msgr->cct,10) << \"connect success \" << connect_seq << \", lossy = \" << policy.lossy\n\t       << \", features \" << connection_state->get_features() << dendl;\n      \n\n      // If we have an authorizer, get a new AuthSessionHandler to deal with ongoing security of the\n      // connection.  PLR\n\n      if (authorizer != NULL) {\n\tsession_security.reset(\n            get_auth_session_handler(msgr->cct,\n\t\t\t\t     authorizer->protocol,\n\t\t\t\t     authorizer->session_key,\n\t\t\t\t     connection_state->get_features()));\n      }  else {\n        // We have no authorizer, so we shouldn't be applying security to messages in this pipe.  PLR\n\tsession_security.reset();\n      }\n\n      msgr->dispatch_queue.queue_connect(connection_state.get());\n      msgr->ms_deliver_handle_fast_connect(connection_state.get());\n      \n      if (!reader_running) {\n\tldout(msgr->cct,20) << \"connect starting reader\" << dendl;\n\tstart_reader();\n      }\n      maybe_start_delay_thread();\n      delete authorizer;\n      return 0;\n    }\n    \n    // protocol error\n    ldout(msgr->cct,0) << \"connect got bad tag \" << (int)tag << dendl;\n    goto fail_locked;\n  }\n\n fail:\n  if (conf->ms_inject_internal_delays) {\n    ldout(msgr->cct, 10) << \" sleep for \" << msgr->cct->_conf->ms_inject_internal_delays << dendl;\n    utime_t t;\n    t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n    t.sleep();\n  }\n\n  pipe_lock.Lock();\n fail_locked:\n  if (state == STATE_CONNECTING)\n    fault();\n  else\n    ldout(msgr->cct,3) << \"connect fault, but state = \" << get_state_name()\n\t\t       << \" != connecting, stopping\" << dendl;\n\n stop_locked:\n  delete authorizer;\n  return rc;\n}\n\nvoid Pipe::register_pipe()\n{\n  ldout(msgr->cct,10) << \"register_pipe\" << dendl;\n  assert(msgr->lock.is_locked());\n  Pipe *existing = msgr->_lookup_pipe(peer_addr);\n  assert(existing == NULL);\n  msgr->rank_pipe[peer_addr] = this;\n}\n\nvoid Pipe::unregister_pipe()\n{\n  assert(msgr->lock.is_locked());\n  ceph::unordered_map<entity_addr_t,Pipe*>::iterator p = msgr->rank_pipe.find(peer_addr);\n  if (p != msgr->rank_pipe.end() && p->second == this) {\n    ldout(msgr->cct,10) << \"unregister_pipe\" << dendl;\n    msgr->rank_pipe.erase(p);\n  } else {\n    ldout(msgr->cct,10) << \"unregister_pipe - not registered\" << dendl;\n    msgr->accepting_pipes.erase(this);  // somewhat overkill, but safe.\n  }\n}\n\nvoid Pipe::join()\n{\n  ldout(msgr->cct, 20) << \"join\" << dendl;\n  if (writer_thread.is_started())\n    writer_thread.join();\n  if (reader_thread.is_started())\n    reader_thread.join();\n  if (delay_thread) {\n    ldout(msgr->cct, 20) << \"joining delay_thread\" << dendl;\n    delay_thread->stop();\n    delay_thread->join();\n  }\n}\n\nvoid Pipe::requeue_sent()\n{\n  if (sent.empty())\n    return;\n\n  list<Message*>& rq = out_q[CEPH_MSG_PRIO_HIGHEST];\n  while (!sent.empty()) {\n    Message *m = sent.back();\n    sent.pop_back();\n    ldout(msgr->cct,10) << \"requeue_sent \" << *m << \" for resend seq \" << out_seq\n\t\t\t<< \" (\" << m->get_seq() << \")\" << dendl;\n    rq.push_front(m);\n    out_seq--;\n  }\n}\n\nvoid Pipe::discard_requeued_up_to(uint64_t seq)\n{\n  ldout(msgr->cct, 10) << \"discard_requeued_up_to \" << seq << dendl;\n  if (out_q.count(CEPH_MSG_PRIO_HIGHEST) == 0)\n    return;\n  list<Message*>& rq = out_q[CEPH_MSG_PRIO_HIGHEST];\n  while (!rq.empty()) {\n    Message *m = rq.front();\n    if (m->get_seq() == 0 || m->get_seq() > seq)\n      break;\n    ldout(msgr->cct,10) << \"discard_requeued_up_to \" << *m << \" for resend seq \" << out_seq\n\t\t\t<< \" <= \" << seq << \", discarding\" << dendl;\n    m->put();\n    rq.pop_front();\n    out_seq++;\n  }\n  if (rq.empty())\n    out_q.erase(CEPH_MSG_PRIO_HIGHEST);\n}\n\n/*\n * Tears down the Pipe's message queues, and removes them from the DispatchQueue\n * Must hold pipe_lock prior to calling.\n */\nvoid Pipe::discard_out_queue()\n{\n  ldout(msgr->cct,10) << \"discard_queue\" << dendl;\n\n  for (list<Message*>::iterator p = sent.begin(); p != sent.end(); ++p) {\n    ldout(msgr->cct,20) << \"  discard \" << *p << dendl;\n    (*p)->put();\n  }\n  sent.clear();\n  for (map<int,list<Message*> >::iterator p = out_q.begin(); p != out_q.end(); ++p)\n    for (list<Message*>::iterator r = p->second.begin(); r != p->second.end(); ++r) {\n      ldout(msgr->cct,20) << \"  discard \" << *r << dendl;\n      (*r)->put();\n    }\n  out_q.clear();\n}\n\nvoid Pipe::fault(bool onread)\n{\n  const md_config_t *conf = msgr->cct->_conf;\n  assert(pipe_lock.is_locked());\n  cond.Signal();\n\n  if (onread && state == STATE_CONNECTING) {\n    ldout(msgr->cct,10) << \"fault already connecting, reader shutting down\" << dendl;\n    return;\n  }\n  \n  ldout(msgr->cct,2) << \"fault \" << cpp_strerror(errno) << dendl;\n\n  if (state == STATE_CLOSED ||\n      state == STATE_CLOSING) {\n    ldout(msgr->cct,10) << \"fault already closed|closing\" << dendl;\n    if (connection_state->clear_pipe(this))\n      msgr->dispatch_queue.queue_reset(connection_state.get());\n    return;\n  }\n\n  shutdown_socket();\n\n  // lossy channel?\n  if (policy.lossy && state != STATE_CONNECTING) {\n    ldout(msgr->cct,10) << \"fault on lossy channel, failing\" << dendl;\n\n    // disconnect from Connection, and mark it failed.  future messages\n    // will be dropped.\n    assert(connection_state);\n    stop();\n    bool cleared = connection_state->clear_pipe(this);\n\n    // crib locks, blech.  note that Pipe is now STATE_CLOSED and the\n    // rank_pipe entry is ignored by others.\n    pipe_lock.Unlock();\n\n    if (conf->ms_inject_internal_delays) {\n      ldout(msgr->cct, 10) << \" sleep for \" << msgr->cct->_conf->ms_inject_internal_delays << dendl;\n      utime_t t;\n      t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n      t.sleep();\n    }\n\n    msgr->lock.Lock();\n    pipe_lock.Lock();\n    unregister_pipe();\n    msgr->lock.Unlock();\n\n    if (delay_thread)\n      delay_thread->discard();\n    in_q->discard_queue(conn_id);\n    discard_out_queue();\n    if (cleared)\n      msgr->dispatch_queue.queue_reset(connection_state.get());\n    return;\n  }\n\n  // queue delayed items immediately\n  if (delay_thread)\n    delay_thread->flush();\n\n  // requeue sent items\n  requeue_sent();\n\n  if (policy.standby && !is_queued()) {\n    ldout(msgr->cct,0) << \"fault with nothing to send, going to standby\" << dendl;\n    state = STATE_STANDBY;\n    return;\n  }\n\n  if (state != STATE_CONNECTING) {\n    if (policy.server) {\n      ldout(msgr->cct,0) << \"fault, server, going to standby\" << dendl;\n      state = STATE_STANDBY;\n    } else {\n      ldout(msgr->cct,0) << \"fault, initiating reconnect\" << dendl;\n      connect_seq++;\n      state = STATE_CONNECTING;\n    }\n    backoff = utime_t();\n  } else if (backoff == utime_t()) {\n    ldout(msgr->cct,0) << \"fault\" << dendl;\n    backoff.set_from_double(conf->ms_initial_backoff);\n  } else {\n    ldout(msgr->cct,10) << \"fault waiting \" << backoff << dendl;\n    cond.WaitInterval(pipe_lock, backoff);\n    backoff += backoff;\n    if (backoff > conf->ms_max_backoff)\n      backoff.set_from_double(conf->ms_max_backoff);\n    ldout(msgr->cct,10) << \"fault done waiting or woke up\" << dendl;\n  }\n}\n\nint Pipe::randomize_out_seq()\n{\n  if (connection_state->get_features() & CEPH_FEATURE_MSG_AUTH) {\n    // Set out_seq to a random value, so CRC won't be predictable.   Don't bother checking seq_error\n    // here.  We'll check it on the call.  PLR\n    int seq_error = get_random_bytes((char *)&out_seq, sizeof(out_seq));\n    out_seq &= SEQ_MASK;\n    lsubdout(msgr->cct, ms, 10) << \"randomize_out_seq \" << out_seq << dendl;\n    return seq_error;\n  } else {\n    // previously, seq #'s always started at 0.\n    out_seq = 0;\n    return 0;\n  }\n}\n\nvoid Pipe::was_session_reset()\n{\n  assert(pipe_lock.is_locked());\n\n  ldout(msgr->cct,10) << \"was_session_reset\" << dendl;\n  in_q->discard_queue(conn_id);\n  if (delay_thread)\n    delay_thread->discard();\n  discard_out_queue();\n\n  msgr->dispatch_queue.queue_remote_reset(connection_state.get());\n\n  if (randomize_out_seq()) {\n    lsubdout(msgr->cct,ms,15) << \"was_session_reset(): Could not get random bytes to set seq number for session reset; set seq number to \" << out_seq << dendl;\n  }\n\n  in_seq = 0;\n  connect_seq = 0;\n}\n\nvoid Pipe::stop()\n{\n  ldout(msgr->cct,10) << \"stop\" << dendl;\n  assert(pipe_lock.is_locked());\n  state = STATE_CLOSED;\n  state_closed = true;\n  cond.Signal();\n  shutdown_socket();\n}\n\nvoid Pipe::stop_and_wait()\n{\n  assert(pipe_lock.is_locked_by_me());\n  if (state != STATE_CLOSED)\n    stop();\n\n  if (msgr->cct->_conf->ms_inject_internal_delays) {\n    ldout(msgr->cct, 10) << __func__ << \" sleep for \"\n\t\t\t << msgr->cct->_conf->ms_inject_internal_delays\n\t\t\t << dendl;\n    utime_t t;\n    t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n    t.sleep();\n  }\n  \n  if (delay_thread) {\n    pipe_lock.Unlock();\n    delay_thread->stop_fast_dispatching();\n    pipe_lock.Lock();\n  }\n  while (reader_running &&\n\t reader_dispatching)\n    cond.Wait(pipe_lock);\n}\n\n/* read msgs from socket.\n * also, server.\n */\nvoid Pipe::reader()\n{\n  pipe_lock.Lock();\n\n  if (state == STATE_ACCEPTING) {\n    accept();\n    assert(pipe_lock.is_locked());\n  }\n\n  // loop.\n  while (state != STATE_CLOSED &&\n\t state != STATE_CONNECTING) {\n    assert(pipe_lock.is_locked());\n\n    // sleep if (re)connecting\n    if (state == STATE_STANDBY) {\n      ldout(msgr->cct,20) << \"reader sleeping during reconnect|standby\" << dendl;\n      cond.Wait(pipe_lock);\n      continue;\n    }\n\n    // get a reference to the AuthSessionHandler while we have the pipe_lock\n    ceph::shared_ptr<AuthSessionHandler> auth_handler = session_security;\n\n    pipe_lock.Unlock();\n\n    char tag = -1;\n    ldout(msgr->cct,20) << \"reader reading tag...\" << dendl;\n    if (tcp_read((char*)&tag, 1) < 0) {\n      pipe_lock.Lock();\n      ldout(msgr->cct,2) << \"reader couldn't read tag, \" << cpp_strerror(errno) << dendl;\n      fault(true);\n      continue;\n    }\n\n    if (tag == CEPH_MSGR_TAG_KEEPALIVE) {\n      ldout(msgr->cct,2) << \"reader got KEEPALIVE\" << dendl;\n      pipe_lock.Lock();\n      connection_state->set_last_keepalive(ceph_clock_now());\n      continue;\n    }\n    if (tag == CEPH_MSGR_TAG_KEEPALIVE2) {\n      ldout(msgr->cct,30) << \"reader got KEEPALIVE2 tag ...\" << dendl;\n      ceph_timespec t;\n      int rc = tcp_read((char*)&t, sizeof(t));\n      pipe_lock.Lock();\n      if (rc < 0) {\n\tldout(msgr->cct,2) << \"reader couldn't read KEEPALIVE2 stamp \"\n\t\t\t   << cpp_strerror(errno) << dendl;\n\tfault(true);\n      } else {\n\tsend_keepalive_ack = true;\n\tkeepalive_ack_stamp = utime_t(t);\n\tldout(msgr->cct,2) << \"reader got KEEPALIVE2 \" << keepalive_ack_stamp\n\t\t\t   << dendl;\n\tconnection_state->set_last_keepalive(ceph_clock_now());\n\tcond.Signal();\n      }\n      continue;\n    }\n    if (tag == CEPH_MSGR_TAG_KEEPALIVE2_ACK) {\n      ldout(msgr->cct,2) << \"reader got KEEPALIVE_ACK\" << dendl;\n      struct ceph_timespec t;\n      int rc = tcp_read((char*)&t, sizeof(t));\n      pipe_lock.Lock();\n      if (rc < 0) {\n\tldout(msgr->cct,2) << \"reader couldn't read KEEPALIVE2 stamp \" << cpp_strerror(errno) << dendl;\n\tfault(true);\n      } else {\n\tconnection_state->set_last_keepalive_ack(utime_t(t));\n      }\n      continue;\n    }\n\n    // open ...\n    if (tag == CEPH_MSGR_TAG_ACK) {\n      ldout(msgr->cct,20) << \"reader got ACK\" << dendl;\n      ceph_le64 seq;\n      int rc = tcp_read((char*)&seq, sizeof(seq));\n      pipe_lock.Lock();\n      if (rc < 0) {\n\tldout(msgr->cct,2) << \"reader couldn't read ack seq, \" << cpp_strerror(errno) << dendl;\n\tfault(true);\n      } else if (state != STATE_CLOSED) {\n        handle_ack(seq);\n      }\n      continue;\n    }\n\n    else if (tag == CEPH_MSGR_TAG_MSG) {\n      ldout(msgr->cct,20) << \"reader got MSG\" << dendl;\n      Message *m = 0;\n      int r = read_message(&m, auth_handler.get());\n\n      pipe_lock.Lock();\n      \n      if (!m) {\n\tif (r < 0)\n\t  fault(true);\n\tcontinue;\n      }\n\n      m->trace.event(\"pipe read message\");\n\n      if (state == STATE_CLOSED ||\n\t  state == STATE_CONNECTING) {\n\tin_q->dispatch_throttle_release(m->get_dispatch_throttle_size());\n\tm->put();\n\tcontinue;\n      }\n\n      // check received seq#.  if it is old, drop the message.  \n      // note that incoming messages may skip ahead.  this is convenient for the client\n      // side queueing because messages can't be renumbered, but the (kernel) client will\n      // occasionally pull a message out of the sent queue to send elsewhere.  in that case\n      // it doesn't matter if we \"got\" it or not.\n      if (m->get_seq() <= in_seq) {\n\tldout(msgr->cct,0) << \"reader got old message \"\n\t\t<< m->get_seq() << \" <= \" << in_seq << \" \" << m << \" \" << *m\n\t\t<< \", discarding\" << dendl;\n\tin_q->dispatch_throttle_release(m->get_dispatch_throttle_size());\n\tm->put();\n\tif (connection_state->has_feature(CEPH_FEATURE_RECONNECT_SEQ) &&\n\t    msgr->cct->_conf->ms_die_on_old_message)\n\t  assert(0 == \"old msgs despite reconnect_seq feature\");\n\tcontinue;\n      }\n      if (m->get_seq() > in_seq + 1) {\n\tldout(msgr->cct,0) << \"reader missed message?  skipped from seq \"\n\t\t\t   << in_seq << \" to \" << m->get_seq() << dendl;\n\tif (msgr->cct->_conf->ms_die_on_skipped_message)\n\t  assert(0 == \"skipped incoming seq\");\n      }\n\n      m->set_connection(connection_state.get());\n\n      // note last received message.\n      in_seq = m->get_seq();\n\n      cond.Signal();  // wake up writer, to ack this\n      \n      ldout(msgr->cct,10) << \"reader got message \"\n\t       << m->get_seq() << \" \" << m << \" \" << *m\n\t       << dendl;\n      in_q->fast_preprocess(m);\n\n      if (delay_thread) {\n        utime_t release;\n        if (rand() % 10000 < msgr->cct->_conf->ms_inject_delay_probability * 10000.0) {\n          release = m->get_recv_stamp();\n          release += msgr->cct->_conf->ms_inject_delay_max * (double)(rand() % 10000) / 10000.0;\n          lsubdout(msgr->cct, ms, 1) << \"queue_received will delay until \" << release << \" on \" << m << \" \" << *m << dendl;\n        }\n        delay_thread->queue(release, m);\n      } else {\n        if (in_q->can_fast_dispatch(m)) {\n\t  reader_dispatching = true;\n          pipe_lock.Unlock();\n          in_q->fast_dispatch(m);\n          pipe_lock.Lock();\n\t  reader_dispatching = false;\n\t  if (state == STATE_CLOSED ||\n\t      notify_on_dispatch_done) { // there might be somebody waiting\n\t    notify_on_dispatch_done = false;\n\t    cond.Signal();\n\t  }\n        } else {\n          in_q->enqueue(m, m->get_priority(), conn_id);\n        }\n      }\n    }\n    \n    else if (tag == CEPH_MSGR_TAG_CLOSE) {\n      ldout(msgr->cct,20) << \"reader got CLOSE\" << dendl;\n      pipe_lock.Lock();\n      if (state == STATE_CLOSING) {\n\tstate = STATE_CLOSED;\n\tstate_closed = true;\n      } else {\n\tstate = STATE_CLOSING;\n      }\n      cond.Signal();\n      break;\n    }\n    else {\n      ldout(msgr->cct,0) << \"reader bad tag \" << (int)tag << dendl;\n      pipe_lock.Lock();\n      fault(true);\n    }\n  }\n\n \n  // reap?\n  reader_running = false;\n  reader_needs_join = true;\n  unlock_maybe_reap();\n  ldout(msgr->cct,10) << \"reader done\" << dendl;\n}\n\n/* write msgs to socket.\n * also, client.\n */\nvoid Pipe::writer()\n{\n  pipe_lock.Lock();\n  while (state != STATE_CLOSED) {// && state != STATE_WAIT) {\n    ldout(msgr->cct,10) << \"writer: state = \" << get_state_name()\n\t\t\t<< \" policy.server=\" << policy.server << dendl;\n\n    // standby?\n    if (is_queued() && state == STATE_STANDBY && !policy.server)\n      state = STATE_CONNECTING;\n\n    // connect?\n    if (state == STATE_CONNECTING) {\n      assert(!policy.server);\n      connect();\n      continue;\n    }\n    \n    if (state == STATE_CLOSING) {\n      // write close tag\n      ldout(msgr->cct,20) << \"writer writing CLOSE tag\" << dendl;\n      char tag = CEPH_MSGR_TAG_CLOSE;\n      state = STATE_CLOSED;\n      state_closed = true;\n      pipe_lock.Unlock();\n      if (sd >= 0) {\n\t// we can ignore return value, actually; we don't care if this succeeds.\n\tint r = ::write(sd, &tag, 1);\n\t(void)r;\n      }\n      pipe_lock.Lock();\n      continue;\n    }\n\n    if (state != STATE_CONNECTING && state != STATE_WAIT && state != STATE_STANDBY &&\n\t(is_queued() || in_seq > in_seq_acked)) {\n\n      // keepalive?\n      if (send_keepalive) {\n\tint rc;\n\tif (connection_state->has_feature(CEPH_FEATURE_MSGR_KEEPALIVE2)) {\n\t  pipe_lock.Unlock();\n\t  rc = write_keepalive2(CEPH_MSGR_TAG_KEEPALIVE2,\n\t\t\t\tceph_clock_now());\n\t} else {\n\t  pipe_lock.Unlock();\n\t  rc = write_keepalive();\n\t}\n\tpipe_lock.Lock();\n\tif (rc < 0) {\n\t  ldout(msgr->cct,2) << \"writer couldn't write keepalive[2], \"\n\t\t\t     << cpp_strerror(errno) << dendl;\n\t  fault();\n \t  continue;\n\t}\n\tsend_keepalive = false;\n      }\n      if (send_keepalive_ack) {\n\tutime_t t = keepalive_ack_stamp;\n\tpipe_lock.Unlock();\n\tint rc = write_keepalive2(CEPH_MSGR_TAG_KEEPALIVE2_ACK, t);\n\tpipe_lock.Lock();\n\tif (rc < 0) {\n\t  ldout(msgr->cct,2) << \"writer couldn't write keepalive_ack, \" << cpp_strerror(errno) << dendl;\n\t  fault();\n\t  continue;\n\t}\n\tsend_keepalive_ack = false;\n      }\n\n      // send ack?\n      if (in_seq > in_seq_acked) {\n\tuint64_t send_seq = in_seq;\n\tpipe_lock.Unlock();\n\tint rc = write_ack(send_seq);\n\tpipe_lock.Lock();\n\tif (rc < 0) {\n\t  ldout(msgr->cct,2) << \"writer couldn't write ack, \" << cpp_strerror(errno) << dendl;\n\t  fault();\n \t  continue;\n\t}\n\tin_seq_acked = send_seq;\n      }\n\n      // grab outgoing message\n      Message *m = _get_next_outgoing();\n      if (m) {\n\tm->set_seq(++out_seq);\n\tif (!policy.lossy) {\n\t  // put on sent list\n\t  sent.push_back(m); \n\t  m->get();\n\t}\n\n\t// associate message with Connection (for benefit of encode_payload)\n\tm->set_connection(connection_state.get());\n\n\tuint64_t features = connection_state->get_features();\n\n\tif (m->empty_payload())\n\t  ldout(msgr->cct,20) << \"writer encoding \" << m->get_seq() << \" features \" << features\n\t\t\t      << \" \" << m << \" \" << *m << dendl;\n\telse\n\t  ldout(msgr->cct,20) << \"writer half-reencoding \" << m->get_seq() << \" features \" << features\n\t\t\t      << \" \" << m << \" \" << *m << dendl;\n\n\t// encode and copy out of *m\n\tm->encode(features, msgr->crcflags);\n\n\t// prepare everything\n\tconst ceph_msg_header& header = m->get_header();\n\tconst ceph_msg_footer& footer = m->get_footer();\n\n\t// Now that we have all the crcs calculated, handle the\n\t// digital signature for the message, if the pipe has session\n\t// security set up.  Some session security options do not\n\t// actually calculate and check the signature, but they should\n\t// handle the calls to sign_message and check_signature.  PLR\n\tif (session_security.get() == NULL) {\n\t  ldout(msgr->cct, 20) << \"writer no session security\" << dendl;\n\t} else {\n\t  if (session_security->sign_message(m)) {\n\t    ldout(msgr->cct, 20) << \"writer failed to sign seq # \" << header.seq\n\t\t\t\t << \"): sig = \" << footer.sig << dendl;\n\t  } else {\n\t    ldout(msgr->cct, 20) << \"writer signed seq # \" << header.seq\n\t\t\t\t << \"): sig = \" << footer.sig << dendl;\n\t  }\n\t}\n\n\tbufferlist blist = m->get_payload();\n\tblist.append(m->get_middle());\n\tblist.append(m->get_data());\n\n        pipe_lock.Unlock();\n\n        m->trace.event(\"pipe writing message\");\n\n        ldout(msgr->cct,20) << \"writer sending \" << m->get_seq() << \" \" << m << dendl;\n\tint rc = write_message(header, footer, blist);\n\n\tpipe_lock.Lock();\n\tif (rc < 0) {\n          ldout(msgr->cct,1) << \"writer error sending \" << m << \", \"\n\t\t  << cpp_strerror(errno) << dendl;\n\t  fault();\n        }\n\tm->put();\n      }\n      continue;\n    }\n    \n    // wait\n    ldout(msgr->cct,20) << \"writer sleeping\" << dendl;\n    cond.Wait(pipe_lock);\n  }\n  \n  ldout(msgr->cct,20) << \"writer finishing\" << dendl;\n\n  // reap?\n  writer_running = false;\n  unlock_maybe_reap();\n  ldout(msgr->cct,10) << \"writer done\" << dendl;\n}\n\nvoid Pipe::unlock_maybe_reap()\n{\n  if (!reader_running && !writer_running) {\n    shutdown_socket();\n    pipe_lock.Unlock();\n    if (delay_thread && delay_thread->is_flushing()) {\n      delay_thread->wait_for_flush();\n    }\n    msgr->queue_reap(this);\n  } else {\n    pipe_lock.Unlock();\n  }\n}\n\nstatic void alloc_aligned_buffer(bufferlist& data, unsigned len, unsigned off)\n{\n  // create a buffer to read into that matches the data alignment\n  unsigned left = len;\n  if (off & ~CEPH_PAGE_MASK) {\n    // head\n    unsigned head = 0;\n    head = MIN(CEPH_PAGE_SIZE - (off & ~CEPH_PAGE_MASK), left);\n    data.push_back(buffer::create(head));\n    left -= head;\n  }\n  unsigned middle = left & CEPH_PAGE_MASK;\n  if (middle > 0) {\n    data.push_back(buffer::create_page_aligned(middle));\n    left -= middle;\n  }\n  if (left) {\n    data.push_back(buffer::create(left));\n  }\n}\n\nint Pipe::read_message(Message **pm, AuthSessionHandler* auth_handler)\n{\n  int ret = -1;\n  // envelope\n  //ldout(msgr->cct,10) << \"receiver.read_message from sd \" << sd  << dendl;\n  \n  ceph_msg_header header; \n  ceph_msg_footer footer;\n  __u32 header_crc = 0;\n\n  if (connection_state->has_feature(CEPH_FEATURE_NOSRCADDR)) {\n    if (tcp_read((char*)&header, sizeof(header)) < 0)\n      return -1;\n    if (msgr->crcflags & MSG_CRC_HEADER) {\n      header_crc = ceph_crc32c(0, (unsigned char *)&header, sizeof(header) - sizeof(header.crc));\n    }\n  } else {\n    ceph_msg_header_old oldheader;\n    if (tcp_read((char*)&oldheader, sizeof(oldheader)) < 0)\n      return -1;\n    // this is fugly\n    memcpy(&header, &oldheader, sizeof(header));\n    header.src = oldheader.src.name;\n    header.reserved = oldheader.reserved;\n    if (msgr->crcflags & MSG_CRC_HEADER) {\n      header.crc = oldheader.crc;\n      header_crc = ceph_crc32c(0, (unsigned char *)&oldheader, sizeof(oldheader) - sizeof(oldheader.crc));\n    }\n  }\n\n  ldout(msgr->cct,20) << \"reader got envelope type=\" << header.type\n           << \" src \" << entity_name_t(header.src)\n           << \" front=\" << header.front_len\n\t   << \" data=\" << header.data_len\n\t   << \" off \" << header.data_off\n           << dendl;\n\n  // verify header crc\n  if ((msgr->crcflags & MSG_CRC_HEADER) && header_crc != header.crc) {\n    ldout(msgr->cct,0) << \"reader got bad header crc \" << header_crc << \" != \" << header.crc << dendl;\n    return -1;\n  }\n\n  bufferlist front, middle, data;\n  int front_len, middle_len;\n  unsigned data_len, data_off;\n  int aborted;\n  Message *message;\n  utime_t recv_stamp = ceph_clock_now();\n\n  if (policy.throttler_messages) {\n    ldout(msgr->cct,10) << \"reader wants \" << 1 << \" message from policy throttler \"\n\t\t\t<< policy.throttler_messages->get_current() << \"/\"\n\t\t\t<< policy.throttler_messages->get_max() << dendl;\n    policy.throttler_messages->get();\n  }\n\n  uint64_t message_size = header.front_len + header.middle_len + header.data_len;\n  if (message_size) {\n    if (policy.throttler_bytes) {\n      ldout(msgr->cct,10) << \"reader wants \" << message_size << \" bytes from policy throttler \"\n\t       << policy.throttler_bytes->get_current() << \"/\"\n\t       << policy.throttler_bytes->get_max() << dendl;\n      policy.throttler_bytes->get(message_size);\n    }\n\n    // throttle total bytes waiting for dispatch.  do this _after_ the\n    // policy throttle, as this one does not deadlock (unless dispatch\n    // blocks indefinitely, which it shouldn't).  in contrast, the\n    // policy throttle carries for the lifetime of the message.\n    ldout(msgr->cct,10) << \"reader wants \" << message_size << \" from dispatch throttler \"\n\t     << in_q->dispatch_throttler.get_current() << \"/\"\n\t     << in_q->dispatch_throttler.get_max() << dendl;\n    in_q->dispatch_throttler.get(message_size);\n  }\n\n  utime_t throttle_stamp = ceph_clock_now();\n\n  // read front\n  front_len = header.front_len;\n  if (front_len) {\n    bufferptr bp = buffer::create(front_len);\n    if (tcp_read(bp.c_str(), front_len) < 0)\n      goto out_dethrottle;\n    front.push_back(std::move(bp));\n    ldout(msgr->cct,20) << \"reader got front \" << front.length() << dendl;\n  }\n\n  // read middle\n  middle_len = header.middle_len;\n  if (middle_len) {\n    bufferptr bp = buffer::create(middle_len);\n    if (tcp_read(bp.c_str(), middle_len) < 0)\n      goto out_dethrottle;\n    middle.push_back(std::move(bp));\n    ldout(msgr->cct,20) << \"reader got middle \" << middle.length() << dendl;\n  }\n\n\n  // read data\n  data_len = le32_to_cpu(header.data_len);\n  data_off = le32_to_cpu(header.data_off);\n  if (data_len) {\n    unsigned offset = 0;\n    unsigned left = data_len;\n\n    bufferlist newbuf, rxbuf;\n    bufferlist::iterator blp;\n    int rxbuf_version = 0;\n\t\n    while (left > 0) {\n      // wait for data\n      if (tcp_read_wait() < 0)\n\tgoto out_dethrottle;\n\n      // get a buffer\n      connection_state->lock.Lock();\n      map<ceph_tid_t,pair<bufferlist,int> >::iterator p = connection_state->rx_buffers.find(header.tid);\n      if (p != connection_state->rx_buffers.end()) {\n\tif (rxbuf.length() == 0 || p->second.second != rxbuf_version) {\n\t  ldout(msgr->cct,10) << \"reader seleting rx buffer v \" << p->second.second\n\t\t   << \" at offset \" << offset\n\t\t   << \" len \" << p->second.first.length() << dendl;\n\t  rxbuf = p->second.first;\n\t  rxbuf_version = p->second.second;\n\t  // make sure it's big enough\n\t  if (rxbuf.length() < data_len)\n\t    rxbuf.push_back(buffer::create(data_len - rxbuf.length()));\n\t  blp = p->second.first.begin();\n\t  blp.advance(offset);\n\t}\n      } else {\n\tif (!newbuf.length()) {\n\t  ldout(msgr->cct,20) << \"reader allocating new rx buffer at offset \" << offset << dendl;\n\t  alloc_aligned_buffer(newbuf, data_len, data_off);\n\t  blp = newbuf.begin();\n\t  blp.advance(offset);\n\t}\n      }\n      bufferptr bp = blp.get_current_ptr();\n      int read = MIN(bp.length(), left);\n      ldout(msgr->cct,20) << \"reader reading nonblocking into \" << (void*)bp.c_str() << \" len \" << bp.length() << dendl;\n      ssize_t got = tcp_read_nonblocking(bp.c_str(), read);\n      ldout(msgr->cct,30) << \"reader read \" << got << \" of \" << read << dendl;\n      connection_state->lock.Unlock();\n      if (got < 0)\n\tgoto out_dethrottle;\n      if (got > 0) {\n\tblp.advance(got);\n\tdata.append(bp, 0, got);\n\toffset += got;\n\tleft -= got;\n      } // else we got a signal or something; just loop.\n    }\n  }\n\n  // footer\n  if (connection_state->has_feature(CEPH_FEATURE_MSG_AUTH)) {\n    if (tcp_read((char*)&footer, sizeof(footer)) < 0)\n      goto out_dethrottle;\n  } else {\n    ceph_msg_footer_old old_footer;\n    if (tcp_read((char*)&old_footer, sizeof(old_footer)) < 0)\n      goto out_dethrottle;\n    footer.front_crc = old_footer.front_crc;\n    footer.middle_crc = old_footer.middle_crc;\n    footer.data_crc = old_footer.data_crc;\n    footer.sig = 0;\n    footer.flags = old_footer.flags;\n  }\n  \n  aborted = (footer.flags & CEPH_MSG_FOOTER_COMPLETE) == 0;\n  ldout(msgr->cct,10) << \"aborted = \" << aborted << dendl;\n  if (aborted) {\n    ldout(msgr->cct,0) << \"reader got \" << front.length() << \" + \" << middle.length() << \" + \" << data.length()\n\t    << \" byte message.. ABORTED\" << dendl;\n    ret = 0;\n    goto out_dethrottle;\n  }\n\n  ldout(msgr->cct,20) << \"reader got \" << front.length() << \" + \" << middle.length() << \" + \" << data.length()\n\t   << \" byte message\" << dendl;\n  message = decode_message(msgr->cct, msgr->crcflags, header, footer,\n                           front, middle, data, connection_state.get());\n  if (!message) {\n    ret = -EINVAL;\n    goto out_dethrottle;\n  }\n\n  //\n  //  Check the signature if one should be present.  A zero return indicates success. PLR\n  //\n\n  if (auth_handler == NULL) {\n    ldout(msgr->cct, 10) << \"No session security set\" << dendl;\n  } else {\n    if (auth_handler->check_message_signature(message)) {\n      ldout(msgr->cct, 0) << \"Signature check failed\" << dendl;\n      message->put();\n      ret = -EINVAL;\n      goto out_dethrottle;\n    } \n  }\n\n  message->set_byte_throttler(policy.throttler_bytes);\n  message->set_message_throttler(policy.throttler_messages);\n\n  // store reservation size in message, so we don't get confused\n  // by messages entering the dispatch queue through other paths.\n  message->set_dispatch_throttle_size(message_size);\n\n  message->set_recv_stamp(recv_stamp);\n  message->set_throttle_stamp(throttle_stamp);\n  message->set_recv_complete_stamp(ceph_clock_now());\n\n  *pm = message;\n  return 0;\n\n out_dethrottle:\n  // release bytes reserved from the throttlers on failure\n  if (policy.throttler_messages) {\n    ldout(msgr->cct,10) << \"reader releasing \" << 1 << \" message to policy throttler \"\n\t\t\t<< policy.throttler_messages->get_current() << \"/\"\n\t\t\t<< policy.throttler_messages->get_max() << dendl;\n    policy.throttler_messages->put();\n  }\n  if (message_size) {\n    if (policy.throttler_bytes) {\n      ldout(msgr->cct,10) << \"reader releasing \" << message_size << \" bytes to policy throttler \"\n\t\t\t  << policy.throttler_bytes->get_current() << \"/\"\n\t\t\t  << policy.throttler_bytes->get_max() << dendl;\n      policy.throttler_bytes->put(message_size);\n    }\n\n    in_q->dispatch_throttle_release(message_size);\n  }\n  return ret;\n}\n\nint Pipe::do_sendmsg(struct msghdr *msg, unsigned len, bool more)\n{\n  MSGR_SIGPIPE_STOPPER;\n  while (len > 0) {\n    int r;\n    r = ::sendmsg(sd, msg, MSG_NOSIGNAL | (more ? MSG_MORE : 0));\n    if (r == 0) \n      ldout(msgr->cct,10) << \"do_sendmsg hmm do_sendmsg got r==0!\" << dendl;\n    if (r < 0) {\n      r = -errno; \n      ldout(msgr->cct,1) << \"do_sendmsg error \" << cpp_strerror(r) << dendl;\n      return r;\n    }\n    if (state == STATE_CLOSED) {\n      ldout(msgr->cct,10) << \"do_sendmsg oh look, state == CLOSED, giving up\" << dendl;\n      return -EINTR; // close enough\n    }\n\n    len -= r;\n    if (len == 0) break;\n    \n    // hrmph.  trim r bytes off the front of our message.\n    ldout(msgr->cct,20) << \"do_sendmsg short write did \" << r << \", still have \" << len << dendl;\n    while (r > 0) {\n      if (msg->msg_iov[0].iov_len <= (size_t)r) {\n\t// lose this whole item\n\t//ldout(msgr->cct,30) << \"skipping \" << msg->msg_iov[0].iov_len << \", \" << (msg->msg_iovlen-1) << \" v, \" << r << \" left\" << dendl;\n\tr -= msg->msg_iov[0].iov_len;\n\tmsg->msg_iov++;\n\tmsg->msg_iovlen--;\n      } else {\n\t// partial!\n\t//ldout(msgr->cct,30) << \"adjusting \" << msg->msg_iov[0].iov_len << \", \" << msg->msg_iovlen << \" v, \" << r << \" left\" << dendl;\n\tmsg->msg_iov[0].iov_base = (char *)msg->msg_iov[0].iov_base + r;\n\tmsg->msg_iov[0].iov_len -= r;\n\tbreak;\n      }\n    }\n  }\n  return 0;\n}\n\n\nint Pipe::write_ack(uint64_t seq)\n{\n  ldout(msgr->cct,10) << \"write_ack \" << seq << dendl;\n\n  char c = CEPH_MSGR_TAG_ACK;\n  ceph_le64 s;\n  s = seq;\n\n  struct msghdr msg;\n  memset(&msg, 0, sizeof(msg));\n  struct iovec msgvec[2];\n  msgvec[0].iov_base = &c;\n  msgvec[0].iov_len = 1;\n  msgvec[1].iov_base = &s;\n  msgvec[1].iov_len = sizeof(s);\n  msg.msg_iov = msgvec;\n  msg.msg_iovlen = 2;\n  \n  if (do_sendmsg(&msg, 1 + sizeof(s), true) < 0)\n    return -1;\t\n  return 0;\n}\n\nint Pipe::write_keepalive()\n{\n  ldout(msgr->cct,10) << \"write_keepalive\" << dendl;\n\n  char c = CEPH_MSGR_TAG_KEEPALIVE;\n\n  struct msghdr msg;\n  memset(&msg, 0, sizeof(msg));\n  struct iovec msgvec[2];\n  msgvec[0].iov_base = &c;\n  msgvec[0].iov_len = 1;\n  msg.msg_iov = msgvec;\n  msg.msg_iovlen = 1;\n  \n  if (do_sendmsg(&msg, 1) < 0)\n    return -1;\t\n  return 0;\n}\n\nint Pipe::write_keepalive2(char tag, const utime_t& t)\n{\n  ldout(msgr->cct,10) << \"write_keepalive2 \" << (int)tag << \" \" << t << dendl;\n  struct ceph_timespec ts;\n  t.encode_timeval(&ts);\n  struct msghdr msg;\n  memset(&msg, 0, sizeof(msg));\n  struct iovec msgvec[2];\n  msgvec[0].iov_base = &tag;\n  msgvec[0].iov_len = 1;\n  msgvec[1].iov_base = &ts;\n  msgvec[1].iov_len = sizeof(ts);\n  msg.msg_iov = msgvec;\n  msg.msg_iovlen = 2;\n\n  if (do_sendmsg(&msg, 1 + sizeof(ts)) < 0)\n    return -1;\n  return 0;\n}\n\n\nint Pipe::write_message(const ceph_msg_header& header, const ceph_msg_footer& footer, bufferlist& blist)\n{\n  int ret;\n\n  // set up msghdr and iovecs\n  struct msghdr msg;\n  memset(&msg, 0, sizeof(msg));\n  msg.msg_iov = msgvec;\n  int msglen = 0;\n  \n  // send tag\n  char tag = CEPH_MSGR_TAG_MSG;\n  msgvec[msg.msg_iovlen].iov_base = &tag;\n  msgvec[msg.msg_iovlen].iov_len = 1;\n  msglen++;\n  msg.msg_iovlen++;\n\n  // send envelope\n  ceph_msg_header_old oldheader;\n  if (connection_state->has_feature(CEPH_FEATURE_NOSRCADDR)) {\n    msgvec[msg.msg_iovlen].iov_base = (char*)&header;\n    msgvec[msg.msg_iovlen].iov_len = sizeof(header);\n    msglen += sizeof(header);\n    msg.msg_iovlen++;\n  } else {\n    memcpy(&oldheader, &header, sizeof(header));\n    oldheader.src.name = header.src;\n    oldheader.src.addr = connection_state->get_peer_addr();\n    oldheader.orig_src = oldheader.src;\n    oldheader.reserved = header.reserved;\n    if (msgr->crcflags & MSG_CRC_HEADER) {\n\toldheader.crc = ceph_crc32c(0, (unsigned char*)&oldheader,\n\t\t\t\t    sizeof(oldheader) - sizeof(oldheader.crc));\n    } else {\n\toldheader.crc = 0;\n    }\n    msgvec[msg.msg_iovlen].iov_base = (char*)&oldheader;\n    msgvec[msg.msg_iovlen].iov_len = sizeof(oldheader);\n    msglen += sizeof(oldheader);\n    msg.msg_iovlen++;\n  }\n\n  // payload (front+data)\n  list<bufferptr>::const_iterator pb = blist.buffers().begin();\n  unsigned b_off = 0;  // carry-over buffer offset, if any\n  unsigned bl_pos = 0; // blist pos\n  unsigned left = blist.length();\n\n  while (left > 0) {\n    unsigned donow = MIN(left, pb->length()-b_off);\n    if (donow == 0) {\n      ldout(msgr->cct,0) << \"donow = \" << donow << \" left \" << left << \" pb->length \" << pb->length()\n                         << \" b_off \" << b_off << dendl;\n    }\n    assert(donow > 0);\n    ldout(msgr->cct,30) << \" bl_pos \" << bl_pos << \" b_off \" << b_off\n\t     << \" leftinchunk \" << left\n\t     << \" buffer len \" << pb->length()\n\t     << \" writing \" << donow \n\t     << dendl;\n    \n    if (msg.msg_iovlen >= SM_IOV_MAX-2) {\n      if (do_sendmsg(&msg, msglen, true))\n\tgoto fail;\n      \n      // and restart the iov\n      msg.msg_iov = msgvec;\n      msg.msg_iovlen = 0;\n      msglen = 0;\n    }\n    \n    msgvec[msg.msg_iovlen].iov_base = (void*)(pb->c_str()+b_off);\n    msgvec[msg.msg_iovlen].iov_len = donow;\n    msglen += donow;\n    msg.msg_iovlen++;\n    \n    assert(left >= donow);\n    left -= donow;\n    b_off += donow;\n    bl_pos += donow;\n    if (left == 0)\n      break;\n    while (b_off == pb->length()) {\n      ++pb;\n      b_off = 0;\n    }\n  }\n  assert(left == 0);\n\n  // send footer; if receiver doesn't support signatures, use the old footer format\n\n  ceph_msg_footer_old old_footer;\n  if (connection_state->has_feature(CEPH_FEATURE_MSG_AUTH)) {\n    msgvec[msg.msg_iovlen].iov_base = (void*)&footer;\n    msgvec[msg.msg_iovlen].iov_len = sizeof(footer);\n    msglen += sizeof(footer);\n    msg.msg_iovlen++;\n  } else {\n    if (msgr->crcflags & MSG_CRC_HEADER) {\n      old_footer.front_crc = footer.front_crc;\n      old_footer.middle_crc = footer.middle_crc;\n    } else {\n\told_footer.front_crc = old_footer.middle_crc = 0;\n    }\n    old_footer.data_crc = msgr->crcflags & MSG_CRC_DATA ? footer.data_crc : 0;\n    old_footer.flags = footer.flags;   \n    msgvec[msg.msg_iovlen].iov_base = (char*)&old_footer;\n    msgvec[msg.msg_iovlen].iov_len = sizeof(old_footer);\n    msglen += sizeof(old_footer);\n    msg.msg_iovlen++;\n  }\n\n  // send\n  if (do_sendmsg(&msg, msglen))\n    goto fail;\n\n  ret = 0;\n\n out:\n  return ret;\n\n fail:\n  ret = -1;\n  goto out;\n}\n\n\nint Pipe::tcp_read(char *buf, unsigned len)\n{\n  if (sd < 0)\n    return -EINVAL;\n\n  while (len > 0) {\n\n    if (msgr->cct->_conf->ms_inject_socket_failures && sd >= 0) {\n      if (rand() % msgr->cct->_conf->ms_inject_socket_failures == 0) {\n\tldout(msgr->cct, 0) << \"injecting socket failure\" << dendl;\n\t::shutdown(sd, SHUT_RDWR);\n      }\n    }\n\n    if (tcp_read_wait() < 0)\n      return -1;\n\n    ssize_t got = tcp_read_nonblocking(buf, len);\n\n    if (got < 0)\n      return -1;\n\n    len -= got;\n    buf += got;\n    //lgeneric_dout(cct, DBL) << \"tcp_read got \" << got << \", \" << len << \" left\" << dendl;\n  }\n  return 0;\n}\n\nint Pipe::tcp_read_wait()\n{\n  if (sd < 0)\n    return -EINVAL;\n  struct pollfd pfd;\n  short evmask;\n  pfd.fd = sd;\n  pfd.events = POLLIN;\n#if defined(__linux__)\n  pfd.events |= POLLRDHUP;\n#endif\n\n  if (has_pending_data())\n    return 0;\n\n  int r = poll(&pfd, 1, msgr->timeout);\n  if (r < 0)\n    return -errno;\n  if (r == 0)\n    return -EAGAIN;\n\n  evmask = POLLERR | POLLHUP | POLLNVAL;\n#if defined(__linux__)\n  evmask |= POLLRDHUP;\n#endif\n  if (pfd.revents & evmask)\n    return -1;\n\n  if (!(pfd.revents & POLLIN))\n    return -1;\n\n  return 0;\n}\n\nssize_t Pipe::do_recv(char *buf, size_t len, int flags)\n{\nagain:\n  ssize_t got = ::recv( sd, buf, len, flags );\n  if (got < 0) {\n    if (errno == EINTR) {\n      goto again;\n    }\n    ldout(msgr->cct, 10) << __func__ << \" socket \" << sd << \" returned \"\n\t\t     << got << \" \" << cpp_strerror(errno) << dendl;\n    return -1;\n  }\n  if (got == 0) {\n    return -1;\n  }\n  return got;\n}\n\nssize_t Pipe::buffered_recv(char *buf, size_t len, int flags)\n{\n  size_t left = len;\n  ssize_t total_recv = 0;\n  if (recv_len > recv_ofs) {\n    int to_read = MIN(recv_len - recv_ofs, left);\n    memcpy(buf, &recv_buf[recv_ofs], to_read);\n    recv_ofs += to_read;\n    left -= to_read;\n    if (left == 0) {\n      return to_read;\n    }\n    buf += to_read;\n    total_recv += to_read;\n  }\n\n  /* nothing left in the prefetch buffer */\n\n  if (left > recv_max_prefetch) {\n    /* this was a large read, we don't prefetch for these */\n    ssize_t ret = do_recv(buf, left, flags );\n    if (ret < 0) {\n      if (total_recv > 0)\n        return total_recv;\n      return ret;\n    }\n    total_recv += ret;\n    return total_recv;\n  }\n\n\n  ssize_t got = do_recv(recv_buf, recv_max_prefetch, flags);\n  if (got < 0) {\n    if (total_recv > 0)\n      return total_recv;\n\n    return got;\n  }\n\n  recv_len = (size_t)got;\n  got = MIN(left, (size_t)got);\n  memcpy(buf, recv_buf, got);\n  recv_ofs = got;\n  total_recv += got;\n  return total_recv;\n}\n\nssize_t Pipe::tcp_read_nonblocking(char *buf, unsigned len)\n{\n  ssize_t got = buffered_recv(buf, len, MSG_DONTWAIT );\n  if (got < 0) {\n    ldout(msgr->cct, 10) << __func__ << \" socket \" << sd << \" returned \"\n\t\t         << got << \" \" << cpp_strerror(errno) << dendl;\n    return -1;\n  }\n  if (got == 0) {\n    /* poll() said there was data, but we didn't read any - peer\n     * sent a FIN.  Maybe POLLRDHUP signals this, but this is\n     * standard socket behavior as documented by Stevens.\n     */\n    return -1;\n  }\n  return got;\n}\n\nint Pipe::tcp_write(const char *buf, unsigned len)\n{\n  if (sd < 0)\n    return -1;\n  struct pollfd pfd;\n  pfd.fd = sd;\n  pfd.events = POLLOUT | POLLHUP | POLLNVAL | POLLERR;\n#if defined(__linux__)\n  pfd.events |= POLLRDHUP;\n#endif\n\n  if (msgr->cct->_conf->ms_inject_socket_failures && sd >= 0) {\n    if (rand() % msgr->cct->_conf->ms_inject_socket_failures == 0) {\n      ldout(msgr->cct, 0) << \"injecting socket failure\" << dendl;\n      ::shutdown(sd, SHUT_RDWR);\n    }\n  }\n\n  if (poll(&pfd, 1, -1) < 0)\n    return -1;\n\n  if (!(pfd.revents & POLLOUT))\n    return -1;\n\n  //lgeneric_dout(cct, DBL) << \"tcp_write writing \" << len << dendl;\n  assert(len > 0);\n  while (len > 0) {\n    MSGR_SIGPIPE_STOPPER;\n    int did = ::send( sd, buf, len, MSG_NOSIGNAL );\n    if (did < 0) {\n      //lgeneric_dout(cct, 1) << \"tcp_write error did = \" << did << \" \" << cpp_strerror(errno) << dendl;\n      //lgeneric_derr(cct, 1) << \"tcp_write error did = \" << did << \" \" << cpp_strerror(errno) << dendl;\n      return did;\n    }\n    len -= did;\n    buf += did;\n    //lgeneric_dout(cct, DBL) << \"tcp_write did \" << did << \", \" << len << \" left\" << dendl;\n  }\n  return 0;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#include <errno.h>\n#include <iostream>\n#include <fstream>\n\n\n#include \"SimpleMessenger.h\"\n\n#include \"common/config.h\"\n#include \"common/Timer.h\"\n#include \"common/errno.h\"\n#include \"common/valgrind.h\"\n#include \"auth/Crypto.h\"\n#include \"include/Spinlock.h\"\n\n#define dout_subsys ceph_subsys_ms\n#undef dout_prefix\n#define dout_prefix _prefix(_dout, this)\nstatic ostream& _prefix(std::ostream *_dout, SimpleMessenger *msgr) {\n  return *_dout << \"-- \" << msgr->get_myaddr() << \" \";\n}\n\n\n/*******************\n * SimpleMessenger\n */\n\nSimpleMessenger::SimpleMessenger(CephContext *cct, entity_name_t name,\n\t\t\t\t string mname, uint64_t _nonce)\n  : SimplePolicyMessenger(cct, name,mname, _nonce),\n    accepter(this, _nonce),\n    dispatch_queue(cct, this, mname),\n    reaper_thread(this),\n    nonce(_nonce),\n    lock(\"SimpleMessenger::lock\"), need_addr(true), did_bind(false),\n    global_seq(0),\n    cluster_protocol(0),\n    reaper_started(false), reaper_stop(false),\n    timeout(0),\n    local_connection(new PipeConnection(cct, this))\n{\n  ANNOTATE_BENIGN_RACE_SIZED(&timeout, sizeof(timeout),\n                             \"SimpleMessenger read timeout\");\n  ceph_spin_init(&global_seq_lock);\n  init_local_connection();\n}\n\n/**\n * Destroy the SimpleMessenger. Pretty simple since all the work is done\n * elsewhere.\n */\nSimpleMessenger::~SimpleMessenger()\n{\n  assert(!did_bind); // either we didn't bind or we shut down the Accepter\n  assert(rank_pipe.empty()); // we don't have any running Pipes.\n  assert(!reaper_started); // the reaper thread is stopped\n  ceph_spin_destroy(&global_seq_lock);\n}\n\nvoid SimpleMessenger::ready()\n{\n  ldout(cct,10) << \"ready \" << get_myaddr() << dendl;\n  dispatch_queue.start();\n\n  lock.Lock();\n  if (did_bind)\n    accepter.start();\n  lock.Unlock();\n}\n\n\nint SimpleMessenger::shutdown()\n{\n  ldout(cct,10) << \"shutdown \" << get_myaddr() << dendl;\n  mark_down_all();\n\n  // break ref cycles on the loopback connection\n  local_connection->set_priv(NULL);\n\n  lock.Lock();\n  stop_cond.Signal();\n  stopped = true;\n  lock.Unlock();\n\n  return 0;\n}\n\nint SimpleMessenger::_send_message(Message *m, const entity_inst_t& dest)\n{\n  // set envelope\n  m->get_header().src = get_myname();\n  m->set_cct(cct);\n\n  if (!m->get_priority()) m->set_priority(get_default_send_priority());\n \n  ldout(cct,1) <<\"--> \" << dest.name << \" \"\n          << dest.addr << \" -- \" << *m\n    \t  << \" -- ?+\" << m->get_data().length()\n\t  << \" \" << m \n\t  << dendl;\n\n  if (dest.addr == entity_addr_t()) {\n    ldout(cct,0) << \"send_message message \" << *m\n                 << \" with empty dest \" << dest.addr << dendl;\n    m->put();\n    return -EINVAL;\n  }\n\n  lock.Lock();\n  Pipe *pipe = _lookup_pipe(dest.addr);\n  submit_message(m, (pipe ? pipe->connection_state.get() : NULL),\n                 dest.addr, dest.name.type(), true);\n  lock.Unlock();\n  return 0;\n}\n\nint SimpleMessenger::_send_message(Message *m, Connection *con)\n{\n  //set envelope\n  m->get_header().src = get_myname();\n\n  if (!m->get_priority()) m->set_priority(get_default_send_priority());\n\n  ldout(cct,1) << \"--> \" << con->get_peer_addr()\n      << \" -- \" << *m\n      << \" -- ?+\" << m->get_data().length()\n      << \" \" << m << \" con \" << con\n      << dendl;\n\n  submit_message(m, static_cast<PipeConnection*>(con),\n\t\t con->get_peer_addr(), con->get_peer_type(), false);\n  return 0;\n}\n\n/**\n * If my_inst.addr doesn't have an IP set, this function\n * will fill it in from the passed addr. Otherwise it does nothing and returns.\n */\nvoid SimpleMessenger::set_addr_unknowns(const entity_addr_t &addr)\n{\n  if (my_inst.addr.is_blank_ip()) {\n    int port = my_inst.addr.get_port();\n    my_inst.addr.u = addr.u;\n    my_inst.addr.set_port(port);\n    init_local_connection();\n  }\n}\n\nvoid SimpleMessenger::set_addr(const entity_addr_t &addr)\n{\n  entity_addr_t t = addr;\n  t.set_nonce(nonce);\n  set_myaddr(t);\n  init_local_connection();\n}\n\nint SimpleMessenger::get_proto_version(int peer_type, bool connect)\n{\n  int my_type = my_inst.name.type();\n\n  // set reply protocol version\n  if (peer_type == my_type) {\n    // internal\n    return cluster_protocol;\n  } else {\n    // public\n    if (connect) {\n      switch (peer_type) {\n      case CEPH_ENTITY_TYPE_OSD: return CEPH_OSDC_PROTOCOL;\n      case CEPH_ENTITY_TYPE_MDS: return CEPH_MDSC_PROTOCOL;\n      case CEPH_ENTITY_TYPE_MON: return CEPH_MONC_PROTOCOL;\n      }\n    } else {\n      switch (my_type) {\n      case CEPH_ENTITY_TYPE_OSD: return CEPH_OSDC_PROTOCOL;\n      case CEPH_ENTITY_TYPE_MDS: return CEPH_MDSC_PROTOCOL;\n      case CEPH_ENTITY_TYPE_MON: return CEPH_MONC_PROTOCOL;\n      }\n    }\n  }\n  return 0;\n}\n\n\n\n\n\n\n\n/********************************************\n * SimpleMessenger\n */\n#undef dout_prefix\n#define dout_prefix _prefix(_dout, this)\n\nvoid SimpleMessenger::reaper_entry()\n{\n  ldout(cct,10) << \"reaper_entry start\" << dendl;\n  lock.Lock();\n  while (!reaper_stop) {\n    reaper();  // may drop and retake the lock\n    if (reaper_stop)\n      break;\n    reaper_cond.Wait(lock);\n  }\n  lock.Unlock();\n  ldout(cct,10) << \"reaper_entry done\" << dendl;\n}\n\n/*\n * note: assumes lock is held\n */\nvoid SimpleMessenger::reaper()\n{\n  ldout(cct,10) << \"reaper\" << dendl;\n  assert(lock.is_locked());\n\n  while (!pipe_reap_queue.empty()) {\n    Pipe *p = pipe_reap_queue.front();\n    pipe_reap_queue.pop_front();\n    ldout(cct,10) << \"reaper reaping pipe \" << p << \" \" <<\n      p->get_peer_addr() << dendl;\n    p->pipe_lock.Lock();\n    p->discard_out_queue();\n    if (p->connection_state) {\n      // mark_down, mark_down_all, or fault() should have done this,\n      // or accept() may have switch the Connection to a different\n      // Pipe... but make sure!\n      bool cleared = p->connection_state->clear_pipe(p);\n      assert(!cleared);\n    }\n    p->pipe_lock.Unlock();\n    p->unregister_pipe();\n    assert(pipes.count(p));\n    pipes.erase(p);\n\n    // drop msgr lock while joining thread; the delay through could be\n    // trying to fast dispatch, preventing it from joining without\n    // blocking and deadlocking.\n    lock.Unlock();\n    p->join();\n    lock.Lock();\n\n    if (p->sd >= 0)\n      ::close(p->sd);\n    ldout(cct,10) << \"reaper reaped pipe \" << p << \" \" << p->get_peer_addr() << dendl;\n    p->put();\n    ldout(cct,10) << \"reaper deleted pipe \" << p << dendl;\n  }\n  ldout(cct,10) << \"reaper done\" << dendl;\n}\n\nvoid SimpleMessenger::queue_reap(Pipe *pipe)\n{\n  ldout(cct,10) << \"queue_reap \" << pipe << dendl;\n  lock.Lock();\n  pipe_reap_queue.push_back(pipe);\n  reaper_cond.Signal();\n  lock.Unlock();\n}\n\nbool SimpleMessenger::is_connected(Connection *con)\n{\n  bool r = false;\n  if (con) {\n    Pipe *p = static_cast<Pipe *>(static_cast<PipeConnection*>(con)->get_pipe());\n    if (p) {\n      assert(p->msgr == this);\n      r = p->is_connected();\n      p->put();\n    }\n  }\n  return r;\n}\n\nint SimpleMessenger::bind(const entity_addr_t &bind_addr)\n{\n  lock.Lock();\n  if (started) {\n    ldout(cct,10) << \"rank.bind already started\" << dendl;\n    lock.Unlock();\n    return -1;\n  }\n  ldout(cct,10) << \"rank.bind \" << bind_addr << dendl;\n  lock.Unlock();\n\n  // bind to a socket\n  set<int> avoid_ports;\n  int r = accepter.bind(bind_addr, avoid_ports);\n  if (r >= 0)\n    did_bind = true;\n  return r;\n}\n\nint SimpleMessenger::rebind(const set<int>& avoid_ports)\n{\n  ldout(cct,1) << \"rebind avoid \" << avoid_ports << dendl;\n  assert(did_bind);\n  accepter.stop();\n  mark_down_all();\n  return accepter.rebind(avoid_ports);\n}\n\n\nint SimpleMessenger::client_bind(const entity_addr_t &bind_addr)\n{\n  if (!cct->_conf->ms_bind_before_connect)\n    return 0;\n  Mutex::Locker l(lock);\n  if (did_bind) {\n    assert(my_inst.addr == bind_addr);\n    return 0;\n  }\n  if (started) {\n    ldout(cct,10) << \"rank.bind already started\" << dendl;\n    return -1;\n  }\n  ldout(cct,10) << \"rank.bind \" << bind_addr << dendl;\n\n  set_myaddr(bind_addr);\n  return 0;\n}\n\n\nint SimpleMessenger::start()\n{\n  lock.Lock();\n  ldout(cct,1) << \"messenger.start\" << dendl;\n\n  // register at least one entity, first!\n  assert(my_inst.name.type() >= 0);\n\n  assert(!started);\n  started = true;\n  stopped = false;\n\n  if (!did_bind) {\n    my_inst.addr.nonce = nonce;\n    init_local_connection();\n  }\n\n  lock.Unlock();\n\n  reaper_started = true;\n  reaper_thread.create(\"ms_reaper\");\n  return 0;\n}\n\nPipe *SimpleMessenger::add_accept_pipe(int sd)\n{\n  lock.Lock();\n  Pipe *p = new Pipe(this, Pipe::STATE_ACCEPTING, NULL);\n  p->sd = sd;\n  p->pipe_lock.Lock();\n  p->start_reader();\n  p->pipe_lock.Unlock();\n  pipes.insert(p);\n  accepting_pipes.insert(p);\n  lock.Unlock();\n  return p;\n}\n\n/* connect_rank\n * NOTE: assumes messenger.lock held.\n */\nPipe *SimpleMessenger::connect_rank(const entity_addr_t& addr,\n\t\t\t\t    int type,\n\t\t\t\t    PipeConnection *con,\n\t\t\t\t    Message *first)\n{\n  assert(lock.is_locked());\n  assert(addr != my_inst.addr);\n  \n  ldout(cct,10) << \"connect_rank to \" << addr << \", creating pipe and registering\" << dendl;\n  \n  // create pipe\n  Pipe *pipe = new Pipe(this, Pipe::STATE_CONNECTING,\n\t\t\tstatic_cast<PipeConnection*>(con));\n  pipe->pipe_lock.Lock();\n  pipe->set_peer_type(type);\n  pipe->set_peer_addr(addr);\n  pipe->policy = get_policy(type);\n  pipe->start_writer();\n  if (first)\n    pipe->_send(first);\n  pipe->pipe_lock.Unlock();\n  pipe->register_pipe();\n  pipes.insert(pipe);\n\n  return pipe;\n}\n\n\n\n\n\n\nAuthAuthorizer *SimpleMessenger::get_authorizer(int peer_type, bool force_new)\n{\n  return ms_deliver_get_authorizer(peer_type, force_new);\n}\n\nbool SimpleMessenger::verify_authorizer(Connection *con, int peer_type,\n\t\t\t\t\tint protocol, bufferlist& authorizer, bufferlist& authorizer_reply,\n\t\t\t\t\tbool& isvalid,CryptoKey& session_key)\n{\n  return ms_deliver_verify_authorizer(con, peer_type, protocol, authorizer, authorizer_reply, isvalid,session_key);\n}\n\nConnectionRef SimpleMessenger::get_connection(const entity_inst_t& dest)\n{\n  Mutex::Locker l(lock);\n  if (my_inst.addr == dest.addr) {\n    // local\n    return local_connection;\n  }\n\n  // remote\n  while (true) {\n    Pipe *pipe = _lookup_pipe(dest.addr);\n    if (pipe) {\n      ldout(cct, 10) << \"get_connection \" << dest << \" existing \" << pipe << dendl;\n    } else {\n      pipe = connect_rank(dest.addr, dest.name.type(), NULL, NULL);\n      ldout(cct, 10) << \"get_connection \" << dest << \" new \" << pipe << dendl;\n    }\n    Mutex::Locker l(pipe->pipe_lock);\n    if (pipe->connection_state)\n      return pipe->connection_state;\n    // we failed too quickly!  retry.  FIXME.\n  }\n}\n\nConnectionRef SimpleMessenger::get_loopback_connection()\n{\n  return local_connection;\n}\n\nvoid SimpleMessenger::submit_message(Message *m, PipeConnection *con,\n\t\t\t\t     const entity_addr_t& dest_addr, int dest_type,\n\t\t\t\t     bool already_locked)\n{\n  m->trace.event(\"simple submitting message\");\n  if (cct->_conf->ms_dump_on_send) {\n    m->encode(-1, true);\n    ldout(cct, 0) << \"submit_message \" << *m << \"\\n\";\n    m->get_payload().hexdump(*_dout);\n    if (m->get_data().length() > 0) {\n      *_dout << \" data:\\n\";\n      m->get_data().hexdump(*_dout);\n    }\n    *_dout << dendl;\n    m->clear_payload();\n  }\n\n  // existing connection?\n  if (con) {\n    Pipe *pipe = NULL;\n    bool ok = static_cast<PipeConnection*>(con)->try_get_pipe(&pipe);\n    if (!ok) {\n      ldout(cct,0) << \"submit_message \" << *m << \" remote, \" << dest_addr\n\t\t   << \", failed lossy con, dropping message \" << m << dendl;\n      m->put();\n      return;\n    }\n    while (pipe && ok) {\n      // we loop in case of a racing reconnect, either from us or them\n      pipe->pipe_lock.Lock(); // can't use a Locker because of the Pipe ref\n      if (pipe->state != Pipe::STATE_CLOSED) {\n\tldout(cct,20) << \"submit_message \" << *m << \" remote, \" << dest_addr << \", have pipe.\" << dendl;\n\tpipe->_send(m);\n\tpipe->pipe_lock.Unlock();\n\tpipe->put();\n\treturn;\n      }\n      Pipe *current_pipe;\n      ok = con->try_get_pipe(&current_pipe);\n      pipe->pipe_lock.Unlock();\n      if (current_pipe == pipe) {\n\tldout(cct,20) << \"submit_message \" << *m << \" remote, \" << dest_addr\n\t\t      << \", had pipe \" << pipe << \", but it closed.\" << dendl;\n\tpipe->put();\n\tcurrent_pipe->put();\n\tm->put();\n\treturn;\n      } else {\n\tpipe->put();\n\tpipe = current_pipe;\n      }\n    }\n  }\n\n  // local?\n  if (my_inst.addr == dest_addr) {\n    // local\n    ldout(cct,20) << \"submit_message \" << *m << \" local\" << dendl;\n    m->set_connection(local_connection.get());\n    dispatch_queue.local_delivery(m, m->get_priority());\n    return;\n  }\n\n  // remote, no existing pipe.\n  const Policy& policy = get_policy(dest_type);\n  if (policy.server) {\n    ldout(cct,20) << \"submit_message \" << *m << \" remote, \" << dest_addr << \", lossy server for target type \"\n\t\t  << ceph_entity_type_name(dest_type) << \", no session, dropping.\" << dendl;\n    m->put();\n  } else {\n    ldout(cct,20) << \"submit_message \" << *m << \" remote, \" << dest_addr << \", new pipe.\" << dendl;\n    if (!already_locked) {\n      /** We couldn't handle the Message without reference to global data, so\n       *  grab the lock and do it again. If we got here, we know it's a non-lossy\n       *  Connection, so we can use our existing pointer without doing another lookup. */\n      Mutex::Locker l(lock);\n      submit_message(m, con, dest_addr, dest_type, true);\n    } else {\n      connect_rank(dest_addr, dest_type, static_cast<PipeConnection*>(con), m);\n    }\n  }\n}\n\nint SimpleMessenger::send_keepalive(Connection *con)\n{\n  int ret = 0;\n  Pipe *pipe = static_cast<Pipe *>(\n    static_cast<PipeConnection*>(con)->get_pipe());\n  if (pipe) {\n    ldout(cct,20) << \"send_keepalive con \" << con << \", have pipe.\" << dendl;\n    assert(pipe->msgr == this);\n    pipe->pipe_lock.Lock();\n    pipe->_send_keepalive();\n    pipe->pipe_lock.Unlock();\n    pipe->put();\n  } else {\n    ldout(cct,0) << \"send_keepalive con \" << con << \", no pipe.\" << dendl;\n    ret = -EPIPE;\n  }\n  return ret;\n}\n\n\n\nvoid SimpleMessenger::wait()\n{\n  lock.Lock();\n  if (!started) {\n    lock.Unlock();\n    return;\n  }\n  if (!stopped)\n    stop_cond.Wait(lock);\n\n  lock.Unlock();\n\n  // done!  clean up.\n  if (did_bind) {\n    ldout(cct,20) << \"wait: stopping accepter thread\" << dendl;\n    accepter.stop();\n    did_bind = false;\n    ldout(cct,20) << \"wait: stopped accepter thread\" << dendl;\n  }\n\n  dispatch_queue.shutdown();\n  if (dispatch_queue.is_started()) {\n    ldout(cct,10) << \"wait: waiting for dispatch queue\" << dendl;\n    dispatch_queue.wait();\n    dispatch_queue.discard_local();\n    ldout(cct,10) << \"wait: dispatch queue is stopped\" << dendl;\n  }\n\n  if (reaper_started) {\n    ldout(cct,20) << \"wait: stopping reaper thread\" << dendl;\n    lock.Lock();\n    reaper_cond.Signal();\n    reaper_stop = true;\n    lock.Unlock();\n    reaper_thread.join();\n    reaper_started = false;\n    ldout(cct,20) << \"wait: stopped reaper thread\" << dendl;\n  }\n\n  // close+reap all pipes\n  lock.Lock();\n  {\n    ldout(cct,10) << \"wait: closing pipes\" << dendl;\n\n    while (!rank_pipe.empty()) {\n      Pipe *p = rank_pipe.begin()->second;\n      p->unregister_pipe();\n      p->pipe_lock.Lock();\n      p->stop_and_wait();\n      // don't generate an event here; we're shutting down anyway.\n      PipeConnectionRef con = p->connection_state;\n      if (con)\n\tcon->clear_pipe(p);\n      p->pipe_lock.Unlock();\n    }\n\n    reaper();\n    ldout(cct,10) << \"wait: waiting for pipes \" << pipes << \" to close\" << dendl;\n    while (!pipes.empty()) {\n      reaper_cond.Wait(lock);\n      reaper();\n    }\n  }\n  lock.Unlock();\n\n  ldout(cct,10) << \"wait: done.\" << dendl;\n  ldout(cct,1) << \"shutdown complete.\" << dendl;\n  started = false;\n}\n\n\nvoid SimpleMessenger::mark_down_all()\n{\n  ldout(cct,1) << \"mark_down_all\" << dendl;\n  lock.Lock();\n  for (set<Pipe*>::iterator q = accepting_pipes.begin(); q != accepting_pipes.end(); ++q) {\n    Pipe *p = *q;\n    ldout(cct,5) << \"mark_down_all accepting_pipe \" << p << dendl;\n    p->pipe_lock.Lock();\n    p->stop();\n    PipeConnectionRef con = p->connection_state;\n    if (con && con->clear_pipe(p))\n      dispatch_queue.queue_reset(con.get());\n    p->pipe_lock.Unlock();\n  }\n  accepting_pipes.clear();\n\n  while (!rank_pipe.empty()) {\n    ceph::unordered_map<entity_addr_t,Pipe*>::iterator it = rank_pipe.begin();\n    Pipe *p = it->second;\n    ldout(cct,5) << \"mark_down_all \" << it->first << \" \" << p << dendl;\n    rank_pipe.erase(it);\n    p->unregister_pipe();\n    p->pipe_lock.Lock();\n    p->stop();\n    PipeConnectionRef con = p->connection_state;\n    if (con && con->clear_pipe(p))\n      dispatch_queue.queue_reset(con.get());\n    p->pipe_lock.Unlock();\n  }\n  lock.Unlock();\n}\n\nvoid SimpleMessenger::mark_down(const entity_addr_t& addr)\n{\n  lock.Lock();\n  Pipe *p = _lookup_pipe(addr);\n  if (p) {\n    ldout(cct,1) << \"mark_down \" << addr << \" -- \" << p << dendl;\n    p->unregister_pipe();\n    p->pipe_lock.Lock();\n    p->stop();\n    if (p->connection_state) {\n      // generate a reset event for the caller in this case, even\n      // though they asked for it, since this is the addr-based (and\n      // not Connection* based) interface\n      PipeConnectionRef con = p->connection_state;\n      if (con && con->clear_pipe(p))\n\tdispatch_queue.queue_reset(con.get());\n    }\n    p->pipe_lock.Unlock();\n  } else {\n    ldout(cct,1) << \"mark_down \" << addr << \" -- pipe dne\" << dendl;\n  }\n  lock.Unlock();\n}\n\nvoid SimpleMessenger::mark_down(Connection *con)\n{\n  if (con == NULL)\n    return;\n  lock.Lock();\n  Pipe *p = static_cast<Pipe *>(static_cast<PipeConnection*>(con)->get_pipe());\n  if (p) {\n    ldout(cct,1) << \"mark_down \" << con << \" -- \" << p << dendl;\n    assert(p->msgr == this);\n    p->unregister_pipe();\n    p->pipe_lock.Lock();\n    p->stop();\n    if (p->connection_state) {\n      // do not generate a reset event for the caller in this case,\n      // since they asked for it.\n      p->connection_state->clear_pipe(p);\n    }\n    p->pipe_lock.Unlock();\n    p->put();\n  } else {\n    ldout(cct,1) << \"mark_down \" << con << \" -- pipe dne\" << dendl;\n  }\n  lock.Unlock();\n}\n\nvoid SimpleMessenger::mark_disposable(Connection *con)\n{\n  lock.Lock();\n  Pipe *p = static_cast<Pipe *>(static_cast<PipeConnection*>(con)->get_pipe());\n  if (p) {\n    ldout(cct,1) << \"mark_disposable \" << con << \" -- \" << p << dendl;\n    assert(p->msgr == this);\n    p->pipe_lock.Lock();\n    p->policy.lossy = true;\n    p->pipe_lock.Unlock();\n    p->put();\n  } else {\n    ldout(cct,1) << \"mark_disposable \" << con << \" -- pipe dne\" << dendl;\n  }\n  lock.Unlock();\n}\n\nvoid SimpleMessenger::learned_addr(const entity_addr_t &peer_addr_for_me)\n{\n  // be careful here: multiple threads may block here, and readers of\n  // my_inst.addr do NOT hold any lock.\n\n  // this always goes from true -> false under the protection of the\n  // mutex.  if it is already false, we need not retake the mutex at\n  // all.\n  if (!need_addr)\n    return;\n\n  lock.Lock();\n  if (need_addr) {\n    entity_addr_t t = peer_addr_for_me;\n    t.set_port(my_inst.addr.get_port());\n    t.set_nonce(my_inst.addr.get_nonce());\n    ANNOTATE_BENIGN_RACE_SIZED(&my_inst.addr, sizeof(my_inst.addr),\n                               \"SimpleMessenger learned addr\");\n    my_inst.addr = t;\n    ldout(cct,1) << \"learned my addr \" << my_inst.addr << dendl;\n    need_addr = false;\n    init_local_connection();\n  }\n  lock.Unlock();\n}\n\nvoid SimpleMessenger::init_local_connection()\n{\n  local_connection->peer_addr = my_inst.addr;\n  local_connection->peer_type = my_inst.name.type();\n  local_connection->set_features(CEPH_FEATURES_ALL);\n  ms_deliver_handle_fast_connect(local_connection.get());\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_SIMPLEMESSENGER_H\n#define CEPH_SIMPLEMESSENGER_H\n\n#include \"include/types.h\"\n#include \"include/xlist.h\"\n\n#include <list>\n#include <map>\nusing namespace std;\n#include \"include/unordered_map.h\"\n#include \"include/unordered_set.h\"\n\n#include \"common/Mutex.h\"\n#include \"include/Spinlock.h\"\n#include \"common/Cond.h\"\n#include \"common/Thread.h\"\n#include \"common/Throttle.h\"\n\n#include \"msg/SimplePolicyMessenger.h\"\n#include \"msg/Message.h\"\n#include \"include/assert.h\"\n\n#include \"msg/DispatchQueue.h\"\n#include \"Pipe.h\"\n#include \"Accepter.h\"\n\n/*\n * This class handles transmission and reception of messages. Generally\n * speaking, there are several major components:\n *\n * - Connection\n *    Each logical session is associated with a Connection.\n * - Pipe\n *    Each network connection is handled through a pipe, which handles\n *    the input and output of each message.  There is normally a 1:1\n *    relationship between Pipe and Connection, but logical sessions may\n *    get handed off between Pipes when sockets reconnect or during\n *    connection races.\n * - IncomingQueue\n *    Incoming messages are associated with an IncomingQueue, and there\n *    is one such queue associated with each Pipe.\n * - DispatchQueue\n *    IncomingQueues get queued in the DIspatchQueue, which is responsible\n *    for doing a round-robin sweep and processing them via a worker thread.\n * - SimpleMessenger\n *    It's the exterior class passed to the external message handler and\n *    most of the API details.\n *\n * Lock ordering:\n *\n *   SimpleMessenger::lock\n *       Pipe::pipe_lock\n *           DispatchQueue::lock\n *               IncomingQueue::lock\n */\n\nclass SimpleMessenger : public SimplePolicyMessenger {\n  // First we have the public Messenger interface implementation...\npublic:\n  /**\n   * Initialize the SimpleMessenger!\n   *\n   * @param cct The CephContext to use\n   * @param name The name to assign ourselves\n   * _nonce A unique ID to use for this SimpleMessenger. It should not\n   * be a value that will be repeated if the daemon restarts.\n   * features The local features bits for the local_connection\n   */\n  SimpleMessenger(CephContext *cct, entity_name_t name,\n\t\t  string mname, uint64_t _nonce);\n\n  /**\n   * Destroy the SimpleMessenger. Pretty simple since all the work is done\n   * elsewhere.\n   */\n  ~SimpleMessenger() override;\n\n  /** @defgroup Accessors\n   * @{\n   */\n  void set_addr_unknowns(const entity_addr_t& addr) override;\n  void set_addr(const entity_addr_t &addr) override;\n\n  int get_dispatch_queue_len() override {\n    return dispatch_queue.get_queue_len();\n  }\n\n  double get_dispatch_queue_max_age(utime_t now) override {\n    return dispatch_queue.get_max_age(now);\n  }\n  /** @} Accessors */\n\n  /**\n   * @defgroup Configuration functions\n   * @{\n   */\n  void set_cluster_protocol(int p) override {\n    assert(!started && !did_bind);\n    cluster_protocol = p;\n  }\n\n  int bind(const entity_addr_t& bind_addr) override;\n  int rebind(const set<int>& avoid_ports) override;\n  int client_bind(const entity_addr_t& bind_addr) override;\n\n  /** @} Configuration functions */\n\n  /**\n   * @defgroup Startup/Shutdown\n   * @{\n   */\n  int start() override;\n  void wait() override;\n  int shutdown() override;\n\n  /** @} // Startup/Shutdown */\n\n  /**\n   * @defgroup Messaging\n   * @{\n   */\n  int send_message(Message *m, const entity_inst_t& dest) override {\n    return _send_message(m, dest);\n  }\n\n  int send_message(Message *m, Connection *con) {\n    return _send_message(m, con);\n  }\n\n  /** @} // Messaging */\n\n  /**\n   * @defgroup Connection Management\n   * @{\n   */\n  ConnectionRef get_connection(const entity_inst_t& dest) override;\n  ConnectionRef get_loopback_connection() override;\n  int send_keepalive(Connection *con);\n  void mark_down(const entity_addr_t& addr) override;\n  void mark_down(Connection *con);\n  void mark_disposable(Connection *con);\n  void mark_down_all() override;\n  /** @} // Connection Management */\nprotected:\n  /**\n   * @defgroup Messenger Interfaces\n   * @{\n   */\n  /**\n   * Start up the DispatchQueue thread once we have somebody to dispatch to.\n   */\n  void ready() override;\n  /** @} // Messenger Interfaces */\nprivate:\n  /**\n   * @defgroup Inner classes\n   * @{\n   */\n\npublic:\n  Accepter accepter;\n  DispatchQueue dispatch_queue;\n\n  friend class Accepter;\n\n  /**\n   * Register a new pipe for accept\n   *\n   * @param sd socket\n   */\n  Pipe *add_accept_pipe(int sd);\n\nprivate:\n\n  /**\n   * A thread used to tear down Pipes when they're complete.\n   */\n  class ReaperThread : public Thread {\n    SimpleMessenger *msgr;\n  public:\n    explicit ReaperThread(SimpleMessenger *m) : msgr(m) {}\n    void *entry() override {\n      msgr->reaper_entry();\n      return 0;\n    }\n  } reaper_thread;\n\n  /**\n   * @} // Inner classes\n   */\n\n  /**\n   * @defgroup Utility functions\n   * @{\n   */\n\n  /**\n   * Create a Pipe associated with the given entity (of the given type).\n   * Initiate the connection. (This function returning does not guarantee\n   * connection success.)\n   *\n   * @param addr The address of the entity to connect to.\n   * @param type The peer type of the entity at the address.\n   * @param con An existing Connection to associate with the new Pipe. If\n   * NULL, it creates a new Connection.\n   * @param first an initial message to queue on the new pipe\n   *\n   * @return a pointer to the newly-created Pipe. Caller does not own a\n   * reference; take one if you need it.\n   */\n  Pipe *connect_rank(const entity_addr_t& addr, int type, PipeConnection *con,\n\t\t     Message *first);\n  /**\n   * Send a message, lazily or not.\n   * This just glues send_message together and passes\n   * the input on to submit_message.\n   */\n  int _send_message(Message *m, const entity_inst_t& dest);\n  /**\n   * Same as above, but for the Connection-based variants.\n   */\n  int _send_message(Message *m, Connection *con);\n  /**\n   * Queue up a Message for delivery to the entity specified\n   * by addr and dest_type.\n   * submit_message() is responsible for creating\n   * new Pipes (and closing old ones) as necessary.\n   *\n   * @param m The Message to queue up. This function eats a reference.\n   * @param con The existing Connection to use, or NULL if you don't know of one.\n   * @param addr The address to send the Message to.\n   * @param dest_type The peer type of the address we're sending to\n   * just drop silently under failure.\n   * @param already_locked If false, submit_message() will acquire the\n   * SimpleMessenger lock before accessing shared data structures; otherwise\n   * it will assume the lock is held. NOTE: if you are making a request\n   * without locking, you MUST have filled in the con with a valid pointer.\n   */\n  void submit_message(Message *m, PipeConnection *con,\n\t\t      const entity_addr_t& addr, int dest_type,\n\t\t      bool already_locked);\n  /**\n   * Look through the pipes in the pipe_reap_queue and tear them down.\n   */\n  void reaper();\n  /**\n   * @} // Utility functions\n   */\n\n  // SimpleMessenger stuff\n  /// approximately unique ID set by the Constructor for use in entity_addr_t\n  uint64_t nonce;\n  /// overall lock used for SimpleMessenger data structures\n  Mutex lock;\n  /// true, specifying we haven't learned our addr; set false when we find it.\n  // maybe this should be protected by the lock?\n  bool need_addr;\n\npublic:\n  bool get_need_addr() const { return need_addr; }\n\nprivate:\n  /**\n   *  false; set to true if the SimpleMessenger bound to a specific address;\n   *  and set false again by Accepter::stop(). This isn't lock-protected\n   *  since you shouldn't be able to race the only writers.\n   */\n  bool did_bind;\n  /// counter for the global seq our connection protocol uses\n  __u32 global_seq;\n  /// lock to protect the global_seq\n  ceph_spinlock_t global_seq_lock;\n\n  /**\n   * hash map of addresses to Pipes\n   *\n   * NOTE: a Pipe* with state CLOSED may still be in the map but is considered\n   * invalid and can be replaced by anyone holding the msgr lock\n   */\n  ceph::unordered_map<entity_addr_t, Pipe*> rank_pipe;\n  /**\n   * list of pipes are in teh process of accepting\n   *\n   * These are not yet in the rank_pipe map.\n   */\n  set<Pipe*> accepting_pipes;\n  /// a set of all the Pipes we have which are somehow active\n  set<Pipe*>      pipes;\n  /// a list of Pipes we want to tear down\n  list<Pipe*>     pipe_reap_queue;\n\n  /// internal cluster protocol version, if any, for talking to entities of the same type.\n  int cluster_protocol;\n\n  Cond  stop_cond;\n  bool stopped = true;\n\n  bool reaper_started, reaper_stop;\n  Cond reaper_cond;\n\n  /// This Cond is slept on by wait() and signaled by dispatch_entry()\n  Cond  wait_cond;\n\n  friend class Pipe;\n\n  Pipe *_lookup_pipe(const entity_addr_t& k) {\n    ceph::unordered_map<entity_addr_t, Pipe*>::iterator p = rank_pipe.find(k);\n    if (p == rank_pipe.end())\n      return NULL;\n    // see lock cribbing in Pipe::fault()\n    if (p->second->state_closed)\n      return NULL;\n    return p->second;\n  }\n\npublic:\n\n  int timeout;\n\n  /// con used for sending messages to ourselves\n  ConnectionRef local_connection;\n\n  /**\n   * @defgroup SimpleMessenger internals\n   * @{\n   */\n\n  /**\n   * This wraps ms_deliver_get_authorizer. We use it for Pipe.\n   */\n  AuthAuthorizer *get_authorizer(int peer_type, bool force_new);\n  /**\n   * This wraps ms_deliver_verify_authorizer; we use it for Pipe.\n   */\n  bool verify_authorizer(Connection *con, int peer_type, int protocol, bufferlist& auth, bufferlist& auth_reply,\n                         bool& isvalid,CryptoKey& session_key);\n  /**\n   * Increment the global sequence for this SimpleMessenger and return it.\n   * This is for the connect protocol, although it doesn't hurt if somebody\n   * else calls it.\n   *\n   * @return a global sequence ID that nobody else has seen.\n   */\n  __u32 get_global_seq(__u32 old=0) {\n    ceph_spin_lock(&global_seq_lock);\n    if (old > global_seq)\n      global_seq = old;\n    __u32 ret = ++global_seq;\n    ceph_spin_unlock(&global_seq_lock);\n    return ret;\n  }\n  /**\n   * Get the protocol version we support for the given peer type: either\n   * a peer protocol (if it matches our own), the protocol version for the\n   * peer (if we're connecting), or our protocol version (if we're accepting).\n   */\n  int get_proto_version(int peer_type, bool connect);\n\n  /**\n   * Fill in the features, address and peer type for the local connection, which\n   * is used for delivering messages back to ourself.\n   */\n  void init_local_connection();\n  /**\n   * Tell the SimpleMessenger its full IP address.\n   *\n   * This is used by Pipes when connecting to other endpoints, and\n   * probably shouldn't be called by anybody else.\n   */\n  void learned_addr(const entity_addr_t& peer_addr_for_me);\n\n  /**\n   * This function is used by the reaper thread. As long as nobody\n   * has set reaper_stop, it calls the reaper function, then\n   * waits to be signaled when it needs to reap again (or when it needs\n   * to stop).\n   */\n  void reaper_entry();\n  /**\n   * Add a pipe to the pipe_reap_queue, to be torn down on\n   * the next call to reaper().\n   * It should really only be the Pipe calling this, in our current\n   * implementation.\n   *\n   * @param pipe A Pipe which has stopped its threads and is\n   * ready to be torn down.\n   */\n  void queue_reap(Pipe *pipe);\n\n  /**\n   * Used to get whether this connection ready to send\n   */\n  bool is_connected(Connection *con);\n  /**\n   * @} // SimpleMessenger Internals\n   */\n} ;\n\n#endif /* CEPH_SIMPLEMESSENGER_H */\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n * Copyright (C) 2017 OVH\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n#include \"acconfig.h\"\n\n#include <fstream>\n#include <iostream>\n#include <errno.h>\n#include <sys/stat.h>\n#include <signal.h>\n#include <ctype.h>\n#include <boost/scoped_ptr.hpp>\n\n#ifdef HAVE_SYS_PARAM_H\n#include <sys/param.h>\n#endif\n\n#ifdef HAVE_SYS_MOUNT_H\n#include <sys/mount.h>\n#endif\n\n#include \"osd/PG.h\"\n\n#include \"include/types.h\"\n#include \"include/compat.h\"\n\n#include \"OSD.h\"\n#include \"OSDMap.h\"\n#include \"Watch.h\"\n#include \"osdc/Objecter.h\"\n\n#include \"common/errno.h\"\n#include \"common/ceph_argparse.h\"\n#include \"common/ceph_time.h\"\n#include \"common/version.h\"\n#include \"common/io_priority.h\"\n#include \"common/pick_address.h\"\n\n#include \"os/ObjectStore.h\"\n#ifdef HAVE_LIBFUSE\n#include \"os/FuseStore.h\"\n#endif\n\n#include \"PrimaryLogPG.h\"\n\n\n#include \"msg/Messenger.h\"\n#include \"msg/Message.h\"\n\n#include \"mon/MonClient.h\"\n\n#include \"messages/MLog.h\"\n\n#include \"messages/MGenericMessage.h\"\n#include \"messages/MOSDPing.h\"\n#include \"messages/MOSDFailure.h\"\n#include \"messages/MOSDMarkMeDown.h\"\n#include \"messages/MOSDFull.h\"\n#include \"messages/MOSDOp.h\"\n#include \"messages/MOSDOpReply.h\"\n#include \"messages/MOSDBackoff.h\"\n#include \"messages/MOSDBeacon.h\"\n#include \"messages/MOSDRepOp.h\"\n#include \"messages/MOSDRepOpReply.h\"\n#include \"messages/MOSDBoot.h\"\n#include \"messages/MOSDPGTemp.h\"\n\n#include \"messages/MOSDMap.h\"\n#include \"messages/MMonGetOSDMap.h\"\n#include \"messages/MOSDPGNotify.h\"\n#include \"messages/MOSDPGQuery.h\"\n#include \"messages/MOSDPGLog.h\"\n#include \"messages/MOSDPGRemove.h\"\n#include \"messages/MOSDPGInfo.h\"\n#include \"messages/MOSDPGCreate.h\"\n#include \"messages/MOSDPGTrim.h\"\n#include \"messages/MOSDPGScan.h\"\n#include \"messages/MOSDPGBackfill.h\"\n#include \"messages/MBackfillReserve.h\"\n#include \"messages/MRecoveryReserve.h\"\n#include \"messages/MOSDForceRecovery.h\"\n#include \"messages/MOSDECSubOpWrite.h\"\n#include \"messages/MOSDECSubOpWriteReply.h\"\n#include \"messages/MOSDECSubOpRead.h\"\n#include \"messages/MOSDECSubOpReadReply.h\"\n#include \"messages/MOSDPGCreated.h\"\n#include \"messages/MOSDPGUpdateLogMissing.h\"\n#include \"messages/MOSDPGUpdateLogMissingReply.h\"\n\n#include \"messages/MOSDAlive.h\"\n\n#include \"messages/MOSDScrub.h\"\n#include \"messages/MOSDScrubReserve.h\"\n#include \"messages/MOSDRepScrub.h\"\n\n#include \"messages/MMonCommand.h\"\n#include \"messages/MCommand.h\"\n#include \"messages/MCommandReply.h\"\n\n#include \"messages/MPGStats.h\"\n#include \"messages/MPGStatsAck.h\"\n\n#include \"messages/MWatchNotify.h\"\n#include \"messages/MOSDPGPush.h\"\n#include \"messages/MOSDPGPushReply.h\"\n#include \"messages/MOSDPGPull.h\"\n\n#include \"common/perf_counters.h\"\n#include \"common/Timer.h\"\n#include \"common/LogClient.h\"\n#include \"common/AsyncReserver.h\"\n#include \"common/HeartbeatMap.h\"\n#include \"common/admin_socket.h\"\n#include \"common/ceph_context.h\"\n\n#include \"global/signal_handler.h\"\n#include \"global/pidfile.h\"\n\n#include \"include/color.h\"\n#include \"perfglue/cpu_profiler.h\"\n#include \"perfglue/heap_profiler.h\"\n\n#include \"osd/OpRequest.h\"\n\n#include \"auth/AuthAuthorizeHandler.h\"\n#include \"auth/RotatingKeyRing.h\"\n#include \"common/errno.h\"\n\n#include \"objclass/objclass.h\"\n\n#include \"common/cmdparse.h\"\n#include \"include/str_list.h\"\n#include \"include/util.h\"\n\n#include \"include/assert.h\"\n#include \"common/config.h\"\n#include \"common/EventTrace.h\"\n\n#ifdef WITH_LTTNG\n#define TRACEPOINT_DEFINE\n#define TRACEPOINT_PROBE_DYNAMIC_LINKAGE\n#include \"tracing/osd.h\"\n#undef TRACEPOINT_PROBE_DYNAMIC_LINKAGE\n#undef TRACEPOINT_DEFINE\n#else\n#define tracepoint(...)\n#endif\n\n#define dout_context cct\n#define dout_subsys ceph_subsys_osd\n#undef dout_prefix\n#define dout_prefix _prefix(_dout, whoami, get_osdmap_epoch())\n\n\nconst double OSD::OSD_TICK_INTERVAL = 1.0;\n\nstatic ostream& _prefix(std::ostream* _dout, int whoami, epoch_t epoch) {\n  return *_dout << \"osd.\" << whoami << \" \" << epoch << \" \";\n}\n\n//Initial features in new superblock.\n//Features here are also automatically upgraded\nCompatSet OSD::get_osd_initial_compat_set() {\n  CompatSet::FeatureSet ceph_osd_feature_compat;\n  CompatSet::FeatureSet ceph_osd_feature_ro_compat;\n  CompatSet::FeatureSet ceph_osd_feature_incompat;\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_BASE);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_PGINFO);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_OLOC);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_LEC);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_CATEGORIES);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_HOBJECTPOOL);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_BIGINFO);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_LEVELDBINFO);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_LEVELDBLOG);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_SNAPMAPPER);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_HINTS);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_PGMETA);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_MISSING);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_FASTINFO);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_RECOVERY_DELETES);\n  return CompatSet(ceph_osd_feature_compat, ceph_osd_feature_ro_compat,\n\t\t   ceph_osd_feature_incompat);\n}\n\n//Features are added here that this OSD supports.\nCompatSet OSD::get_osd_compat_set() {\n  CompatSet compat =  get_osd_initial_compat_set();\n  //Any features here can be set in code, but not in initial superblock\n  compat.incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_SHARDS);\n  return compat;\n}\n\nOSDService::OSDService(OSD *osd) :\n  osd(osd),\n  cct(osd->cct),\n  meta_osr(new ObjectStore::Sequencer(\"meta\")),\n  whoami(osd->whoami), store(osd->store),\n  log_client(osd->log_client), clog(osd->clog),\n  pg_recovery_stats(osd->pg_recovery_stats),\n  cluster_messenger(osd->cluster_messenger),\n  client_messenger(osd->client_messenger),\n  logger(osd->logger),\n  recoverystate_perf(osd->recoverystate_perf),\n  monc(osd->monc),\n  peering_wq(osd->peering_wq),\n  recovery_gen_wq(\"recovery_gen_wq\", cct->_conf->osd_recovery_thread_timeout,\n\t\t  &osd->disk_tp),\n  class_handler(osd->class_handler),\n  pg_epoch_lock(\"OSDService::pg_epoch_lock\"),\n  publish_lock(\"OSDService::publish_lock\"),\n  pre_publish_lock(\"OSDService::pre_publish_lock\"),\n  max_oldest_map(0),\n  peer_map_epoch_lock(\"OSDService::peer_map_epoch_lock\"),\n  sched_scrub_lock(\"OSDService::sched_scrub_lock\"), scrubs_pending(0),\n  scrubs_active(0),\n  agent_lock(\"OSDService::agent_lock\"),\n  agent_valid_iterator(false),\n  agent_ops(0),\n  flush_mode_high_count(0),\n  agent_active(true),\n  agent_thread(this),\n  agent_stop_flag(false),\n  agent_timer_lock(\"OSDService::agent_timer_lock\"),\n  agent_timer(osd->client_messenger->cct, agent_timer_lock),\n  last_recalibrate(ceph_clock_now()),\n  promote_max_objects(0),\n  promote_max_bytes(0),\n  objecter(new Objecter(osd->client_messenger->cct, osd->objecter_messenger, osd->monc, NULL, 0, 0)),\n  objecter_finisher(osd->client_messenger->cct),\n  watch_lock(\"OSDService::watch_lock\"),\n  watch_timer(osd->client_messenger->cct, watch_lock),\n  next_notif_id(0),\n  recovery_request_lock(\"OSDService::recovery_request_lock\"),\n  recovery_request_timer(cct, recovery_request_lock, false),\n  recovery_sleep_lock(\"OSDService::recovery_sleep_lock\"),\n  recovery_sleep_timer(cct, recovery_sleep_lock, false),\n  reserver_finisher(cct),\n  local_reserver(cct, &reserver_finisher, cct->_conf->osd_max_backfills,\n\t\t cct->_conf->osd_min_recovery_priority),\n  remote_reserver(cct, &reserver_finisher, cct->_conf->osd_max_backfills,\n\t\t  cct->_conf->osd_min_recovery_priority),\n  pg_temp_lock(\"OSDService::pg_temp_lock\"),\n  snap_sleep_lock(\"OSDService::snap_sleep_lock\"),\n  snap_sleep_timer(\n    osd->client_messenger->cct, snap_sleep_lock, false /* relax locking */),\n  scrub_sleep_lock(\"OSDService::scrub_sleep_lock\"),\n  scrub_sleep_timer(\n    osd->client_messenger->cct, scrub_sleep_lock, false /* relax locking */),\n  snap_reserver(cct, &reserver_finisher,\n\t\tcct->_conf->osd_max_trimming_pgs),\n  recovery_lock(\"OSDService::recovery_lock\"),\n  recovery_ops_active(0),\n  recovery_ops_reserved(0),\n  recovery_paused(false),\n  map_cache_lock(\"OSDService::map_cache_lock\"),\n  map_cache(cct, cct->_conf->osd_map_cache_size),\n  map_bl_cache(cct->_conf->osd_map_cache_size),\n  map_bl_inc_cache(cct->_conf->osd_map_cache_size),\n  in_progress_split_lock(\"OSDService::in_progress_split_lock\"),\n  stat_lock(\"OSDService::stat_lock\"),\n  full_status_lock(\"OSDService::full_status_lock\"),\n  cur_state(NONE),\n  cur_ratio(0),\n  epoch_lock(\"OSDService::epoch_lock\"),\n  boot_epoch(0), up_epoch(0), bind_epoch(0),\n  is_stopping_lock(\"OSDService::is_stopping_lock\")\n#ifdef PG_DEBUG_REFS\n  , pgid_lock(\"OSDService::pgid_lock\")\n#endif\n{\n  objecter->init();\n}\n\nOSDService::~OSDService()\n{\n  delete objecter;\n}\n\n\n\n#ifdef PG_DEBUG_REFS\nvoid OSDService::add_pgid(spg_t pgid, PG *pg){\n  Mutex::Locker l(pgid_lock);\n  if (!pgid_tracker.count(pgid)) {\n    live_pgs[pgid] = pg;\n  }\n  pgid_tracker[pgid]++;\n}\nvoid OSDService::remove_pgid(spg_t pgid, PG *pg)\n{\n  Mutex::Locker l(pgid_lock);\n  assert(pgid_tracker.count(pgid));\n  assert(pgid_tracker[pgid] > 0);\n  pgid_tracker[pgid]--;\n  if (pgid_tracker[pgid] == 0) {\n    pgid_tracker.erase(pgid);\n    live_pgs.erase(pgid);\n  }\n}\nvoid OSDService::dump_live_pgids()\n{\n  Mutex::Locker l(pgid_lock);\n  derr << \"live pgids:\" << dendl;\n  for (map<spg_t, int>::const_iterator i = pgid_tracker.cbegin();\n       i != pgid_tracker.cend();\n       ++i) {\n    derr << \"\\t\" << *i << dendl;\n    live_pgs[i->first]->dump_live_ids();\n  }\n}\n#endif\n\n\nvoid OSDService::_start_split(spg_t parent, const set<spg_t> &children)\n{\n  for (set<spg_t>::const_iterator i = children.begin();\n       i != children.end();\n       ++i) {\n    dout(10) << __func__ << \": Starting split on pg \" << *i\n\t     << \", parent=\" << parent << dendl;\n    assert(!pending_splits.count(*i));\n    assert(!in_progress_splits.count(*i));\n    pending_splits.insert(make_pair(*i, parent));\n\n    assert(!rev_pending_splits[parent].count(*i));\n    rev_pending_splits[parent].insert(*i);\n  }\n}\n\nvoid OSDService::mark_split_in_progress(spg_t parent, const set<spg_t> &children)\n{\n  Mutex::Locker l(in_progress_split_lock);\n  map<spg_t, set<spg_t> >::iterator piter = rev_pending_splits.find(parent);\n  assert(piter != rev_pending_splits.end());\n  for (set<spg_t>::const_iterator i = children.begin();\n       i != children.end();\n       ++i) {\n    assert(piter->second.count(*i));\n    assert(pending_splits.count(*i));\n    assert(!in_progress_splits.count(*i));\n    assert(pending_splits[*i] == parent);\n\n    pending_splits.erase(*i);\n    piter->second.erase(*i);\n    in_progress_splits.insert(*i);\n  }\n  if (piter->second.empty())\n    rev_pending_splits.erase(piter);\n}\n\nvoid OSDService::cancel_pending_splits_for_parent(spg_t parent)\n{\n  Mutex::Locker l(in_progress_split_lock);\n  _cancel_pending_splits_for_parent(parent);\n}\n\nvoid OSDService::_cancel_pending_splits_for_parent(spg_t parent)\n{\n  map<spg_t, set<spg_t> >::iterator piter = rev_pending_splits.find(parent);\n  if (piter == rev_pending_splits.end())\n    return;\n\n  for (set<spg_t>::iterator i = piter->second.begin();\n       i != piter->second.end();\n       ++i) {\n    assert(pending_splits.count(*i));\n    assert(!in_progress_splits.count(*i));\n    pending_splits.erase(*i);\n    dout(10) << __func__ << \": Completing split on pg \" << *i\n\t     << \" for parent: \" << parent << dendl;\n    _cancel_pending_splits_for_parent(*i);\n  }\n  rev_pending_splits.erase(piter);\n}\n\nvoid OSDService::_maybe_split_pgid(OSDMapRef old_map,\n\t\t\t\t  OSDMapRef new_map,\n\t\t\t\t  spg_t pgid)\n{\n  assert(old_map->have_pg_pool(pgid.pool()));\n  int old_pgnum = old_map->get_pg_num(pgid.pool());\n  if (pgid.ps() < static_cast<unsigned>(old_pgnum)) {\n    set<spg_t> children;\n    if (pgid.is_split(old_pgnum,\n\t\t  new_map->get_pg_num(pgid.pool()), &children)) { \n      _start_split(pgid, children); }\n  } else {\n    assert(pgid.ps() < static_cast<unsigned>(new_map->get_pg_num(pgid.pool())));\n  }\n}\n\nvoid OSDService::init_splits_between(spg_t pgid,\n\t\t\t\t     OSDMapRef frommap,\n\t\t\t\t     OSDMapRef tomap)\n{\n  // First, check whether we can avoid this potentially expensive check\n  if (tomap->have_pg_pool(pgid.pool()) &&\n      pgid.is_split(\n\tfrommap->get_pg_num(pgid.pool()),\n\ttomap->get_pg_num(pgid.pool()),\n\tNULL)) {\n    // Ok, a split happened, so we need to walk the osdmaps\n    set<spg_t> new_pgs; // pgs to scan on each map\n    new_pgs.insert(pgid);\n    OSDMapRef curmap(get_map(frommap->get_epoch()));\n    for (epoch_t e = frommap->get_epoch() + 1;\n\t e <= tomap->get_epoch();\n\t ++e) {\n      OSDMapRef nextmap(try_get_map(e));\n      if (!nextmap)\n\tcontinue;\n      set<spg_t> even_newer_pgs; // pgs added in this loop\n      for (set<spg_t>::iterator i = new_pgs.begin(); i != new_pgs.end(); ++i) {\n\tset<spg_t> split_pgs;\n\tif (i->is_split(curmap->get_pg_num(i->pool()),\n\t\t\tnextmap->get_pg_num(i->pool()),\n\t\t\t&split_pgs)) {\n\t  start_split(*i, split_pgs);\n\t  even_newer_pgs.insert(split_pgs.begin(), split_pgs.end());\n\t}\n      }\n      new_pgs.insert(even_newer_pgs.begin(), even_newer_pgs.end());\n      curmap = nextmap;\n    }\n    assert(curmap == tomap); // we must have had both frommap and tomap\n  }\n}\n\nvoid OSDService::expand_pg_num(OSDMapRef old_map,\n\t\t\t       OSDMapRef new_map)\n{\n  Mutex::Locker l(in_progress_split_lock);\n  for (set<spg_t>::iterator i = in_progress_splits.begin();\n       i != in_progress_splits.end();\n    ) {\n    if (!new_map->have_pg_pool(i->pool())) {\n      in_progress_splits.erase(i++);\n    } else {\n      _maybe_split_pgid(old_map, new_map, *i);\n      ++i;\n    }\n  }\n  for (map<spg_t, spg_t>::iterator i = pending_splits.begin();\n       i != pending_splits.end();\n    ) {\n    if (!new_map->have_pg_pool(i->first.pool())) {\n      rev_pending_splits.erase(i->second);\n      pending_splits.erase(i++);\n    } else {\n      _maybe_split_pgid(old_map, new_map, i->first);\n      ++i;\n    }\n  }\n}\n\nbool OSDService::splitting(spg_t pgid)\n{\n  Mutex::Locker l(in_progress_split_lock);\n  return in_progress_splits.count(pgid) ||\n    pending_splits.count(pgid);\n}\n\nvoid OSDService::complete_split(const set<spg_t> &pgs)\n{\n  Mutex::Locker l(in_progress_split_lock);\n  for (set<spg_t>::const_iterator i = pgs.begin();\n       i != pgs.end();\n       ++i) {\n    dout(10) << __func__ << \": Completing split on pg \" << *i << dendl;\n    assert(!pending_splits.count(*i));\n    assert(in_progress_splits.count(*i));\n    in_progress_splits.erase(*i);\n  }\n}\n\nvoid OSDService::need_heartbeat_peer_update()\n{\n  osd->need_heartbeat_peer_update();\n}\n\nvoid OSDService::pg_stat_queue_enqueue(PG *pg)\n{\n  osd->pg_stat_queue_enqueue(pg);\n}\n\nvoid OSDService::pg_stat_queue_dequeue(PG *pg)\n{\n  osd->pg_stat_queue_dequeue(pg);\n}\n\nvoid OSDService::start_shutdown()\n{\n  {\n    Mutex::Locker l(agent_timer_lock);\n    agent_timer.shutdown();\n  }\n\n  {\n    Mutex::Locker l(recovery_sleep_lock);\n    recovery_sleep_timer.shutdown();\n  }\n}\n\nvoid OSDService::shutdown_reserver()\n{\n  reserver_finisher.wait_for_empty();\n  reserver_finisher.stop();\n}\n\nvoid OSDService::shutdown()\n{\n  {\n    Mutex::Locker l(watch_lock);\n    watch_timer.shutdown();\n  }\n\n  objecter->shutdown();\n  objecter_finisher.wait_for_empty();\n  objecter_finisher.stop();\n\n  {\n    Mutex::Locker l(recovery_request_lock);\n    recovery_request_timer.shutdown();\n  }\n\n  {\n    Mutex::Locker l(snap_sleep_lock);\n    snap_sleep_timer.shutdown();\n  }\n\n  {\n    Mutex::Locker l(scrub_sleep_lock);\n    scrub_sleep_timer.shutdown();\n  }\n\n  osdmap = OSDMapRef();\n  next_osdmap = OSDMapRef();\n}\n\nvoid OSDService::init()\n{\n  reserver_finisher.start();\n  objecter_finisher.start();\n  objecter->set_client_incarnation(0);\n\n  // deprioritize objecter in daemonperf output\n  objecter->get_logger()->set_prio_adjust(-3);\n\n  watch_timer.init();\n  agent_timer.init();\n  snap_sleep_timer.init();\n  scrub_sleep_timer.init();\n\n  agent_thread.create(\"osd_srv_agent\");\n\n  if (cct->_conf->osd_recovery_delay_start)\n    defer_recovery(cct->_conf->osd_recovery_delay_start);\n}\n\nvoid OSDService::final_init()\n{\n  objecter->start(osdmap.get());\n}\n\nvoid OSDService::activate_map()\n{\n  // wake/unwake the tiering agent\n  agent_lock.Lock();\n  agent_active =\n    !osdmap->test_flag(CEPH_OSDMAP_NOTIERAGENT) &&\n    osd->is_active();\n  agent_cond.Signal();\n  agent_lock.Unlock();\n}\n\nvoid OSDService::request_osdmap_update(epoch_t e)\n{\n  osd->osdmap_subscribe(e, false);\n}\n\nclass AgentTimeoutCB : public Context {\n  PGRef pg;\npublic:\n  explicit AgentTimeoutCB(PGRef _pg) : pg(_pg) {}\n  void finish(int) override {\n    pg->agent_choose_mode_restart();\n  }\n};\n\nvoid OSDService::agent_entry()\n{\n  dout(10) << __func__ << \" start\" << dendl;\n  agent_lock.Lock();\n\n  while (!agent_stop_flag) {\n    if (agent_queue.empty()) {\n      dout(20) << __func__ << \" empty queue\" << dendl;\n      agent_cond.Wait(agent_lock);\n      continue;\n    }\n    uint64_t level = agent_queue.rbegin()->first;\n    set<PGRef>& top = agent_queue.rbegin()->second;\n    dout(10) << __func__\n\t     << \" tiers \" << agent_queue.size()\n\t     << \", top is \" << level\n\t     << \" with pgs \" << top.size()\n\t     << \", ops \" << agent_ops << \"/\"\n\t     << cct->_conf->osd_agent_max_ops\n\t     << (agent_active ? \" active\" : \" NOT ACTIVE\")\n\t     << dendl;\n    dout(20) << __func__ << \" oids \" << agent_oids << dendl;\n    int max = cct->_conf->osd_agent_max_ops - agent_ops;\n    int agent_flush_quota = max;\n    if (!flush_mode_high_count)\n      agent_flush_quota = cct->_conf->osd_agent_max_low_ops - agent_ops;\n    if (agent_flush_quota <= 0 || top.empty() || !agent_active) {\n      agent_cond.Wait(agent_lock);\n      continue;\n    }\n\n    if (!agent_valid_iterator || agent_queue_pos == top.end()) {\n      agent_queue_pos = top.begin();\n      agent_valid_iterator = true;\n    }\n    PGRef pg = *agent_queue_pos;\n    dout(10) << \"high_count \" << flush_mode_high_count\n\t     << \" agent_ops \" << agent_ops\n\t     << \" flush_quota \" << agent_flush_quota << dendl;\n    agent_lock.Unlock();\n    if (!pg->agent_work(max, agent_flush_quota)) {\n      dout(10) << __func__ << \" \" << pg->get_pgid()\n\t<< \" no agent_work, delay for \" << cct->_conf->osd_agent_delay_time\n\t<< \" seconds\" << dendl;\n\n      osd->logger->inc(l_osd_tier_delay);\n      // Queue a timer to call agent_choose_mode for this pg in 5 seconds\n      agent_timer_lock.Lock();\n      Context *cb = new AgentTimeoutCB(pg);\n      agent_timer.add_event_after(cct->_conf->osd_agent_delay_time, cb);\n      agent_timer_lock.Unlock();\n    }\n    agent_lock.Lock();\n  }\n  agent_lock.Unlock();\n  dout(10) << __func__ << \" finish\" << dendl;\n}\n\nvoid OSDService::agent_stop()\n{\n  {\n    Mutex::Locker l(agent_lock);\n\n    // By this time all ops should be cancelled\n    assert(agent_ops == 0);\n    // By this time all PGs are shutdown and dequeued\n    if (!agent_queue.empty()) {\n      set<PGRef>& top = agent_queue.rbegin()->second;\n      derr << \"agent queue not empty, for example \" << (*top.begin())->info.pgid << dendl;\n      assert(0 == \"agent queue not empty\");\n    }\n\n    agent_stop_flag = true;\n    agent_cond.Signal();\n  }\n  agent_thread.join();\n}\n\n// -------------------------------------\n\nvoid OSDService::promote_throttle_recalibrate()\n{\n  utime_t now = ceph_clock_now();\n  double dur = now - last_recalibrate;\n  last_recalibrate = now;\n  unsigned prob = promote_probability_millis;\n\n  uint64_t target_obj_sec = cct->_conf->osd_tier_promote_max_objects_sec;\n  uint64_t target_bytes_sec = cct->_conf->osd_tier_promote_max_bytes_sec;\n\n  unsigned min_prob = 1;\n\n  uint64_t attempts, obj, bytes;\n  promote_counter.sample_and_attenuate(&attempts, &obj, &bytes);\n  dout(10) << __func__ << \" \" << attempts << \" attempts, promoted \"\n\t   << obj << \" objects and \" << pretty_si_t(bytes) << \" bytes; target \"\n\t   << target_obj_sec << \" obj/sec or \"\n\t   << pretty_si_t(target_bytes_sec) << \" bytes/sec\"\n\t   << dendl;\n\n  // calculate what the probability *should* be, given the targets\n  unsigned new_prob;\n  if (attempts && dur > 0) {\n    uint64_t avg_size = 1;\n    if (obj)\n      avg_size = MAX(bytes / obj, 1);\n    unsigned po = (double)target_obj_sec * dur * 1000.0 / (double)attempts;\n    unsigned pb = (double)target_bytes_sec / (double)avg_size * dur * 1000.0\n      / (double)attempts;\n    dout(20) << __func__ << \"  po \" << po << \" pb \" << pb << \" avg_size \"\n\t     << avg_size << dendl;\n    if (target_obj_sec && target_bytes_sec)\n      new_prob = MIN(po, pb);\n    else if (target_obj_sec)\n      new_prob = po;\n    else if (target_bytes_sec)\n      new_prob = pb;\n    else\n      new_prob = 1000;\n  } else {\n    new_prob = 1000;\n  }\n  dout(20) << __func__ << \"  new_prob \" << new_prob << dendl;\n\n  // correct for persistent skew between target rate and actual rate, adjust\n  double ratio = 1.0;\n  unsigned actual = 0;\n  if (attempts && obj) {\n    actual = obj * 1000 / attempts;\n    ratio = (double)actual / (double)prob;\n    new_prob = (double)new_prob / ratio;\n  }\n  new_prob = MAX(new_prob, min_prob);\n  new_prob = MIN(new_prob, 1000);\n\n  // adjust\n  prob = (prob + new_prob) / 2;\n  prob = MAX(prob, min_prob);\n  prob = MIN(prob, 1000);\n  dout(10) << __func__ << \"  actual \" << actual\n\t   << \", actual/prob ratio \" << ratio\n\t   << \", adjusted new_prob \" << new_prob\n\t   << \", prob \" << promote_probability_millis << \" -> \" << prob\n\t   << dendl;\n  promote_probability_millis = prob;\n\n  // set hard limits for this interval to mitigate stampedes\n  promote_max_objects = target_obj_sec * OSD::OSD_TICK_INTERVAL * 2;\n  promote_max_bytes = target_bytes_sec * OSD::OSD_TICK_INTERVAL * 2;\n}\n\n// -------------------------------------\n\nfloat OSDService::get_failsafe_full_ratio()\n{\n  float full_ratio = cct->_conf->osd_failsafe_full_ratio;\n  if (full_ratio > 1.0) full_ratio /= 100.0;\n  return full_ratio;\n}\n\nvoid OSDService::check_full_status(float ratio)\n{\n  Mutex::Locker l(full_status_lock);\n\n  cur_ratio = ratio;\n\n  // The OSDMap ratios take precendence.  So if the failsafe is .95 and\n  // the admin sets the cluster full to .96, the failsafe moves up to .96\n  // too.  (Not that having failsafe == full is ideal, but it's better than\n  // dropping writes before the clusters appears full.)\n  OSDMapRef osdmap = get_osdmap();\n  if (!osdmap || osdmap->get_epoch() == 0) {\n    cur_state = NONE;\n    return;\n  }\n  float nearfull_ratio = osdmap->get_nearfull_ratio();\n  float backfillfull_ratio = std::max(osdmap->get_backfillfull_ratio(), nearfull_ratio);\n  float full_ratio = std::max(osdmap->get_full_ratio(), backfillfull_ratio);\n  float failsafe_ratio = std::max(get_failsafe_full_ratio(), full_ratio);\n\n  if (osdmap->require_osd_release < CEPH_RELEASE_LUMINOUS) {\n    // use the failsafe for nearfull and full; the mon isn't using the\n    // flags anyway because we're mid-upgrade.\n    full_ratio = failsafe_ratio;\n    backfillfull_ratio = failsafe_ratio;\n    nearfull_ratio = failsafe_ratio;\n  } else if (full_ratio <= 0 ||\n\t     backfillfull_ratio <= 0 ||\n\t     nearfull_ratio <= 0) {\n    derr << __func__ << \" full_ratio, backfillfull_ratio or nearfull_ratio is <= 0\" << dendl;\n    // use failsafe flag.  ick.  the monitor did something wrong or the user\n    // did something stupid.\n    full_ratio = failsafe_ratio;\n    backfillfull_ratio = failsafe_ratio;\n    nearfull_ratio = failsafe_ratio;\n  }\n\n  string inject;\n  s_names new_state;\n  if (injectfull_state > NONE && injectfull) {\n    new_state = injectfull_state;\n    inject = \"(Injected)\";\n  } else if (ratio > failsafe_ratio) {\n    new_state = FAILSAFE;\n  } else if (ratio > full_ratio) {\n    new_state = FULL;\n  } else if (ratio > backfillfull_ratio) {\n    new_state = BACKFILLFULL;\n  } else if (ratio > nearfull_ratio) {\n    new_state = NEARFULL;\n  } else {\n    new_state = NONE;\n  }\n  dout(20) << __func__ << \" cur ratio \" << ratio\n\t   << \". nearfull_ratio \" << nearfull_ratio\n\t   << \". backfillfull_ratio \" << backfillfull_ratio\n\t   << \", full_ratio \" << full_ratio\n\t   << \", failsafe_ratio \" << failsafe_ratio\n\t   << \", new state \" << get_full_state_name(new_state)\n\t   << \" \" << inject\n\t   << dendl;\n\n  // warn\n  if (cur_state != new_state) {\n    dout(10) << __func__ << \" \" << get_full_state_name(cur_state)\n\t     << \" -> \" << get_full_state_name(new_state) << dendl;\n    if (new_state == FAILSAFE) {\n      clog->error() << \"full status failsafe engaged, dropping updates, now \"\n\t\t    << (int)roundf(ratio * 100) << \"% full\";\n    } else if (cur_state == FAILSAFE) {\n      clog->error() << \"full status failsafe disengaged, no longer dropping \"\n\t\t     << \"updates, now \" << (int)roundf(ratio * 100) << \"% full\";\n    }\n    cur_state = new_state;\n  }\n}\n\nbool OSDService::need_fullness_update()\n{\n  OSDMapRef osdmap = get_osdmap();\n  s_names cur = NONE;\n  if (osdmap->exists(whoami)) {\n    if (osdmap->get_state(whoami) & CEPH_OSD_FULL) {\n      cur = FULL;\n    } else if (osdmap->get_state(whoami) & CEPH_OSD_BACKFILLFULL) {\n      cur = BACKFILLFULL;\n    } else if (osdmap->get_state(whoami) & CEPH_OSD_NEARFULL) {\n      cur = NEARFULL;\n    }\n  }\n  s_names want = NONE;\n  if (is_full())\n    want = FULL;\n  else if (is_backfillfull())\n    want = BACKFILLFULL;\n  else if (is_nearfull())\n    want = NEARFULL;\n  return want != cur;\n}\n\nbool OSDService::_check_full(s_names type, ostream &ss) const\n{\n  Mutex::Locker l(full_status_lock);\n\n  if (injectfull && injectfull_state >= type) {\n    // injectfull is either a count of the number of times to return failsafe full\n    // or if -1 then always return full\n    if (injectfull > 0)\n      --injectfull;\n    ss << \"Injected \" << get_full_state_name(type) << \" OSD (\"\n       << (injectfull < 0 ? \"set\" : std::to_string(injectfull)) << \")\";\n    return true;\n  }\n\n  ss << \"current usage is \" << cur_ratio;\n  return cur_state >= type;\n}\n\nbool OSDService::check_failsafe_full(ostream &ss) const\n{\n  return _check_full(FAILSAFE, ss);\n}\n\nbool OSDService::check_full(ostream &ss) const\n{\n  return _check_full(FULL, ss);\n}\n\nbool OSDService::check_backfill_full(ostream &ss) const\n{\n  return _check_full(BACKFILLFULL, ss);\n}\n\nbool OSDService::check_nearfull(ostream &ss) const\n{\n  return _check_full(NEARFULL, ss);\n}\n\nbool OSDService::is_failsafe_full() const\n{\n  Mutex::Locker l(full_status_lock);\n  return cur_state == FAILSAFE;\n}\n\nbool OSDService::is_full() const\n{\n  Mutex::Locker l(full_status_lock);\n  return cur_state >= FULL;\n}\n\nbool OSDService::is_backfillfull() const\n{\n  Mutex::Locker l(full_status_lock);\n  return cur_state >= BACKFILLFULL;\n}\n\nbool OSDService::is_nearfull() const\n{\n  Mutex::Locker l(full_status_lock);\n  return cur_state >= NEARFULL;\n}\n\nvoid OSDService::set_injectfull(s_names type, int64_t count)\n{\n  Mutex::Locker l(full_status_lock);\n  injectfull_state = type;\n  injectfull = count;\n}\n\nosd_stat_t OSDService::set_osd_stat(const struct store_statfs_t &stbuf,\n                                    vector<int>& hb_peers,\n\t\t\t\t    int num_pgs)\n{\n  uint64_t bytes = stbuf.total;\n  uint64_t used = bytes - stbuf.available;\n  uint64_t avail = stbuf.available;\n\n  osd->logger->set(l_osd_stat_bytes, bytes);\n  osd->logger->set(l_osd_stat_bytes_used, used);\n  osd->logger->set(l_osd_stat_bytes_avail, avail);\n\n  {\n    Mutex::Locker l(stat_lock);\n    osd_stat.hb_peers.swap(hb_peers);\n    osd->op_tracker.get_age_ms_histogram(&osd_stat.op_queue_age_hist);\n    osd_stat.kb = bytes >> 10;\n    osd_stat.kb_used = used >> 10;\n    osd_stat.kb_avail = avail >> 10;\n    osd_stat.num_pgs = num_pgs;\n    return osd_stat;\n  }\n}\n\nvoid OSDService::update_osd_stat(vector<int>& hb_peers)\n{\n  // load osd stats first\n  struct store_statfs_t stbuf;\n  int r = osd->store->statfs(&stbuf);\n  if (r < 0) {\n    derr << \"statfs() failed: \" << cpp_strerror(r) << dendl;\n    return;\n  }\n\n  auto new_stat = set_osd_stat(stbuf, hb_peers, osd->get_num_pgs());\n  dout(20) << \"update_osd_stat \" << new_stat << dendl;\n  assert(new_stat.kb);\n  float ratio = ((float)new_stat.kb_used) / ((float)new_stat.kb);\n  check_full_status(ratio);\n}\n\nbool OSDService::check_osdmap_full(const set<pg_shard_t> &missing_on)\n{\n  OSDMapRef osdmap = get_osdmap();\n  for (auto shard : missing_on) {\n    if (osdmap->get_state(shard.osd) & CEPH_OSD_FULL)\n      return true;\n  }\n  return false;\n}\n\nvoid OSDService::send_message_osd_cluster(int peer, Message *m, epoch_t from_epoch)\n{\n  OSDMapRef next_map = get_nextmap_reserved();\n  // service map is always newer/newest\n  assert(from_epoch <= next_map->get_epoch());\n\n  if (next_map->is_down(peer) ||\n      next_map->get_info(peer).up_from > from_epoch) {\n    m->put();\n    release_map(next_map);\n    return;\n  }\n  const entity_inst_t& peer_inst = next_map->get_cluster_inst(peer);\n  ConnectionRef peer_con = osd->cluster_messenger->get_connection(peer_inst);\n  share_map_peer(peer, peer_con.get(), next_map);\n  peer_con->send_message(m);\n  release_map(next_map);\n}\n\nConnectionRef OSDService::get_con_osd_cluster(int peer, epoch_t from_epoch)\n{\n  OSDMapRef next_map = get_nextmap_reserved();\n  // service map is always newer/newest\n  assert(from_epoch <= next_map->get_epoch());\n\n  if (next_map->is_down(peer) ||\n      next_map->get_info(peer).up_from > from_epoch) {\n    release_map(next_map);\n    return NULL;\n  }\n  ConnectionRef con = osd->cluster_messenger->get_connection(next_map->get_cluster_inst(peer));\n  release_map(next_map);\n  return con;\n}\n\npair<ConnectionRef,ConnectionRef> OSDService::get_con_osd_hb(int peer, epoch_t from_epoch)\n{\n  OSDMapRef next_map = get_nextmap_reserved();\n  // service map is always newer/newest\n  assert(from_epoch <= next_map->get_epoch());\n\n  pair<ConnectionRef,ConnectionRef> ret;\n  if (next_map->is_down(peer) ||\n      next_map->get_info(peer).up_from > from_epoch) {\n    release_map(next_map);\n    return ret;\n  }\n  ret.first = osd->hb_back_client_messenger->get_connection(next_map->get_hb_back_inst(peer));\n  if (next_map->get_hb_front_addr(peer) != entity_addr_t())\n    ret.second = osd->hb_front_client_messenger->get_connection(next_map->get_hb_front_inst(peer));\n  release_map(next_map);\n  return ret;\n}\n\n\nvoid OSDService::queue_want_pg_temp(pg_t pgid,\n\t\t\t\t    const vector<int>& want,\n\t\t\t\t    bool forced)\n{\n  Mutex::Locker l(pg_temp_lock);\n  auto p = pg_temp_pending.find(pgid);\n  if (p == pg_temp_pending.end() ||\n      p->second.acting != want ||\n      forced) {\n    pg_temp_wanted[pgid] = pg_temp_t{want, forced};\n  }\n}\n\nvoid OSDService::remove_want_pg_temp(pg_t pgid)\n{\n  Mutex::Locker l(pg_temp_lock);\n  pg_temp_wanted.erase(pgid);\n  pg_temp_pending.erase(pgid);\n}\n\nvoid OSDService::_sent_pg_temp()\n{\n  pg_temp_pending.insert(make_move_iterator(begin(pg_temp_wanted)),\n\t\t\t make_move_iterator(end(pg_temp_wanted)));\n  pg_temp_wanted.clear();\n}\n\nvoid OSDService::requeue_pg_temp()\n{\n  Mutex::Locker l(pg_temp_lock);\n  // wanted overrides pending.  note that remove_want_pg_temp\n  // clears the item out of both.\n  unsigned old_wanted = pg_temp_wanted.size();\n  unsigned old_pending = pg_temp_pending.size();\n  _sent_pg_temp();\n  pg_temp_wanted.swap(pg_temp_pending);\n  dout(10) << __func__ << \" \" << old_wanted << \" + \" << old_pending << \" -> \"\n\t   << pg_temp_wanted.size() << dendl;\n}\n\nstd::ostream& operator<<(std::ostream& out,\n\t\t\t const OSDService::pg_temp_t& pg_temp)\n{\n  out << pg_temp.acting;\n  if (pg_temp.forced) {\n    out << \" (forced)\";\n  }\n  return out;\n}\n\nvoid OSDService::send_pg_temp()\n{\n  Mutex::Locker l(pg_temp_lock);\n  if (pg_temp_wanted.empty())\n    return;\n  dout(10) << \"send_pg_temp \" << pg_temp_wanted << dendl;\n  MOSDPGTemp *ms[2] = {nullptr, nullptr};\n  for (auto& pg_temp : pg_temp_wanted) {\n    auto& m = ms[pg_temp.second.forced];\n    if (!m) {\n      m = new MOSDPGTemp(osdmap->get_epoch());\n      m->forced = pg_temp.second.forced;\n    }\n    m->pg_temp.emplace(pg_temp.first,\n\t\t       pg_temp.second.acting);\n  }\n  for (auto m : ms) {\n    if (m) {\n      monc->send_mon_message(m);\n    }\n  }\n  _sent_pg_temp();\n}\n\nvoid OSDService::send_pg_created(pg_t pgid)\n{\n  dout(20) << __func__ << dendl;\n  if (osdmap->require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n    monc->send_mon_message(new MOSDPGCreated(pgid));\n  }\n}\n\n// --------------------------------------\n// dispatch\n\nepoch_t OSDService::get_peer_epoch(int peer)\n{\n  Mutex::Locker l(peer_map_epoch_lock);\n  map<int,epoch_t>::iterator p = peer_map_epoch.find(peer);\n  if (p == peer_map_epoch.end())\n    return 0;\n  return p->second;\n}\n\nepoch_t OSDService::note_peer_epoch(int peer, epoch_t e)\n{\n  Mutex::Locker l(peer_map_epoch_lock);\n  map<int,epoch_t>::iterator p = peer_map_epoch.find(peer);\n  if (p != peer_map_epoch.end()) {\n    if (p->second < e) {\n      dout(10) << \"note_peer_epoch osd.\" << peer << \" has \" << e << dendl;\n      p->second = e;\n    } else {\n      dout(30) << \"note_peer_epoch osd.\" << peer << \" has \" << p->second << \" >= \" << e << dendl;\n    }\n    return p->second;\n  } else {\n    dout(10) << \"note_peer_epoch osd.\" << peer << \" now has \" << e << dendl;\n    peer_map_epoch[peer] = e;\n    return e;\n  }\n}\n\nvoid OSDService::forget_peer_epoch(int peer, epoch_t as_of)\n{\n  Mutex::Locker l(peer_map_epoch_lock);\n  map<int,epoch_t>::iterator p = peer_map_epoch.find(peer);\n  if (p != peer_map_epoch.end()) {\n    if (p->second <= as_of) {\n      dout(10) << \"forget_peer_epoch osd.\" << peer << \" as_of \" << as_of\n\t       << \" had \" << p->second << dendl;\n      peer_map_epoch.erase(p);\n    } else {\n      dout(10) << \"forget_peer_epoch osd.\" << peer << \" as_of \" << as_of\n\t       << \" has \" << p->second << \" - not forgetting\" << dendl;\n    }\n  }\n}\n\nbool OSDService::should_share_map(entity_name_t name, Connection *con,\n                                  epoch_t epoch, const OSDMapRef& osdmap,\n                                  const epoch_t *sent_epoch_p)\n{\n  dout(20) << \"should_share_map \"\n           << name << \" \" << con->get_peer_addr()\n           << \" \" << epoch << dendl;\n\n  // does client have old map?\n  if (name.is_client()) {\n    bool message_sendmap = epoch < osdmap->get_epoch();\n    if (message_sendmap && sent_epoch_p) {\n      dout(20) << \"client session last_sent_epoch: \"\n               << *sent_epoch_p\n               << \" versus osdmap epoch \" << osdmap->get_epoch() << dendl;\n      if (*sent_epoch_p < osdmap->get_epoch()) {\n        return true;\n      } // else we don't need to send it out again\n    }\n  }\n\n  if (con->get_messenger() == osd->cluster_messenger &&\n      con != osd->cluster_messenger->get_loopback_connection() &&\n      osdmap->is_up(name.num()) &&\n      (osdmap->get_cluster_addr(name.num()) == con->get_peer_addr() ||\n       osdmap->get_hb_back_addr(name.num()) == con->get_peer_addr())) {\n    // remember\n    epoch_t has = MAX(get_peer_epoch(name.num()), epoch);\n\n    // share?\n    if (has < osdmap->get_epoch()) {\n      dout(10) << name << \" \" << con->get_peer_addr()\n               << \" has old map \" << epoch << \" < \"\n               << osdmap->get_epoch() << dendl;\n      return true;\n    }\n  }\n\n  return false;\n}\n\nvoid OSDService::share_map(\n    entity_name_t name,\n    Connection *con,\n    epoch_t epoch,\n    OSDMapRef& osdmap,\n    epoch_t *sent_epoch_p)\n{\n  dout(20) << \"share_map \"\n\t   << name << \" \" << con->get_peer_addr()\n\t   << \" \" << epoch << dendl;\n\n  if (!osd->is_active()) {\n    /*It is safe not to proceed as OSD is not in healthy state*/\n    return;\n  }\n\n  bool want_shared = should_share_map(name, con, epoch,\n                                      osdmap, sent_epoch_p);\n\n  if (want_shared){\n    if (name.is_client()) {\n      dout(10) << name << \" has old map \" << epoch\n          << \" < \" << osdmap->get_epoch() << dendl;\n      // we know the Session is valid or we wouldn't be sending\n      if (sent_epoch_p) {\n\t*sent_epoch_p = osdmap->get_epoch();\n      }\n      send_incremental_map(epoch, con, osdmap);\n    } else if (con->get_messenger() == osd->cluster_messenger &&\n        osdmap->is_up(name.num()) &&\n        (osdmap->get_cluster_addr(name.num()) == con->get_peer_addr() ||\n            osdmap->get_hb_back_addr(name.num()) == con->get_peer_addr())) {\n      dout(10) << name << \" \" << con->get_peer_addr()\n\t               << \" has old map \" << epoch << \" < \"\n\t               << osdmap->get_epoch() << dendl;\n      note_peer_epoch(name.num(), osdmap->get_epoch());\n      send_incremental_map(epoch, con, osdmap);\n    }\n  }\n}\n\nvoid OSDService::share_map_peer(int peer, Connection *con, OSDMapRef map)\n{\n  if (!map)\n    map = get_osdmap();\n\n  // send map?\n  epoch_t pe = get_peer_epoch(peer);\n  if (pe) {\n    if (pe < map->get_epoch()) {\n      send_incremental_map(pe, con, map);\n      note_peer_epoch(peer, map->get_epoch());\n    } else\n      dout(20) << \"share_map_peer \" << con << \" already has epoch \" << pe << dendl;\n  } else {\n    dout(20) << \"share_map_peer \" << con << \" don't know epoch, doing nothing\" << dendl;\n    // no idea about peer's epoch.\n    // ??? send recent ???\n    // do nothing.\n  }\n}\n\nbool OSDService::can_inc_scrubs_pending()\n{\n  bool can_inc = false;\n  Mutex::Locker l(sched_scrub_lock);\n\n  if (scrubs_pending + scrubs_active < cct->_conf->osd_max_scrubs) {\n    dout(20) << __func__ << \" \" << scrubs_pending << \" -> \" << (scrubs_pending+1)\n\t     << \" (max \" << cct->_conf->osd_max_scrubs << \", active \" << scrubs_active\n\t     << \")\" << dendl;\n    can_inc = true;\n  } else {\n    dout(20) << __func__ << \" \" << scrubs_pending << \" + \" << scrubs_active\n\t     << \" active >= max \" << cct->_conf->osd_max_scrubs << dendl;\n  }\n\n  return can_inc;\n}\n\nbool OSDService::inc_scrubs_pending()\n{\n  bool result = false;\n\n  sched_scrub_lock.Lock();\n  if (scrubs_pending + scrubs_active < cct->_conf->osd_max_scrubs) {\n    dout(20) << \"inc_scrubs_pending \" << scrubs_pending << \" -> \" << (scrubs_pending+1)\n\t     << \" (max \" << cct->_conf->osd_max_scrubs << \", active \" << scrubs_active << \")\" << dendl;\n    result = true;\n    ++scrubs_pending;\n  } else {\n    dout(20) << \"inc_scrubs_pending \" << scrubs_pending << \" + \" << scrubs_active << \" active >= max \" << cct->_conf->osd_max_scrubs << dendl;\n  }\n  sched_scrub_lock.Unlock();\n\n  return result;\n}\n\nvoid OSDService::dec_scrubs_pending()\n{\n  sched_scrub_lock.Lock();\n  dout(20) << \"dec_scrubs_pending \" << scrubs_pending << \" -> \" << (scrubs_pending-1)\n\t   << \" (max \" << cct->_conf->osd_max_scrubs << \", active \" << scrubs_active << \")\" << dendl;\n  --scrubs_pending;\n  assert(scrubs_pending >= 0);\n  sched_scrub_lock.Unlock();\n}\n\nvoid OSDService::inc_scrubs_active(bool reserved)\n{\n  sched_scrub_lock.Lock();\n  ++(scrubs_active);\n  if (reserved) {\n    --(scrubs_pending);\n    dout(20) << \"inc_scrubs_active \" << (scrubs_active-1) << \" -> \" << scrubs_active\n\t     << \" (max \" << cct->_conf->osd_max_scrubs\n\t     << \", pending \" << (scrubs_pending+1) << \" -> \" << scrubs_pending << \")\" << dendl;\n    assert(scrubs_pending >= 0);\n  } else {\n    dout(20) << \"inc_scrubs_active \" << (scrubs_active-1) << \" -> \" << scrubs_active\n\t     << \" (max \" << cct->_conf->osd_max_scrubs\n\t     << \", pending \" << scrubs_pending << \")\" << dendl;\n  }\n  sched_scrub_lock.Unlock();\n}\n\nvoid OSDService::dec_scrubs_active()\n{\n  sched_scrub_lock.Lock();\n  dout(20) << \"dec_scrubs_active \" << scrubs_active << \" -> \" << (scrubs_active-1)\n\t   << \" (max \" << cct->_conf->osd_max_scrubs << \", pending \" << scrubs_pending << \")\" << dendl;\n  --scrubs_active;\n  assert(scrubs_active >= 0);\n  sched_scrub_lock.Unlock();\n}\n\nvoid OSDService::retrieve_epochs(epoch_t *_boot_epoch, epoch_t *_up_epoch,\n                                 epoch_t *_bind_epoch) const\n{\n  Mutex::Locker l(epoch_lock);\n  if (_boot_epoch)\n    *_boot_epoch = boot_epoch;\n  if (_up_epoch)\n    *_up_epoch = up_epoch;\n  if (_bind_epoch)\n    *_bind_epoch = bind_epoch;\n}\n\nvoid OSDService::set_epochs(const epoch_t *_boot_epoch, const epoch_t *_up_epoch,\n                            const epoch_t *_bind_epoch)\n{\n  Mutex::Locker l(epoch_lock);\n  if (_boot_epoch) {\n    assert(*_boot_epoch == 0 || *_boot_epoch >= boot_epoch);\n    boot_epoch = *_boot_epoch;\n  }\n  if (_up_epoch) {\n    assert(*_up_epoch == 0 || *_up_epoch >= up_epoch);\n    up_epoch = *_up_epoch;\n  }\n  if (_bind_epoch) {\n    assert(*_bind_epoch == 0 || *_bind_epoch >= bind_epoch);\n    bind_epoch = *_bind_epoch;\n  }\n}\n\nbool OSDService::prepare_to_stop()\n{\n  Mutex::Locker l(is_stopping_lock);\n  if (get_state() != NOT_STOPPING)\n    return false;\n\n  OSDMapRef osdmap = get_osdmap();\n  if (osdmap && osdmap->is_up(whoami)) {\n    dout(0) << __func__ << \" telling mon we are shutting down\" << dendl;\n    set_state(PREPARING_TO_STOP);\n    monc->send_mon_message(new MOSDMarkMeDown(monc->get_fsid(),\n\t\t\t\t\t      osdmap->get_inst(whoami),\n\t\t\t\t\t      osdmap->get_epoch(),\n\t\t\t\t\t      true  // request ack\n\t\t\t\t\t      ));\n    utime_t now = ceph_clock_now();\n    utime_t timeout;\n    timeout.set_from_double(now + cct->_conf->osd_mon_shutdown_timeout);\n    while ((ceph_clock_now() < timeout) &&\n       (get_state() != STOPPING)) {\n      is_stopping_cond.WaitUntil(is_stopping_lock, timeout);\n    }\n  }\n  dout(0) << __func__ << \" starting shutdown\" << dendl;\n  set_state(STOPPING);\n  return true;\n}\n\nvoid OSDService::got_stop_ack()\n{\n  Mutex::Locker l(is_stopping_lock);\n  if (get_state() == PREPARING_TO_STOP) {\n    dout(0) << __func__ << \" starting shutdown\" << dendl;\n    set_state(STOPPING);\n    is_stopping_cond.Signal();\n  } else {\n    dout(10) << __func__ << \" ignoring msg\" << dendl;\n  }\n}\n\nMOSDMap *OSDService::build_incremental_map_msg(epoch_t since, epoch_t to,\n                                               OSDSuperblock& sblock)\n{\n  MOSDMap *m = new MOSDMap(monc->get_fsid());\n  m->oldest_map = max_oldest_map;\n  m->newest_map = sblock.newest_map;\n\n  for (epoch_t e = to; e > since; e--) {\n    bufferlist bl;\n    if (e > m->oldest_map && get_inc_map_bl(e, bl)) {\n      m->incremental_maps[e].claim(bl);\n    } else if (get_map_bl(e, bl)) {\n      m->maps[e].claim(bl);\n      break;\n    } else {\n      derr << \"since \" << since << \" to \" << to\n\t   << \" oldest \" << m->oldest_map << \" newest \" << m->newest_map\n\t   << dendl;\n      m->put();\n      m = NULL;\n      break;\n    }\n  }\n  return m;\n}\n\nvoid OSDService::send_map(MOSDMap *m, Connection *con)\n{\n  con->send_message(m);\n}\n\nvoid OSDService::send_incremental_map(epoch_t since, Connection *con,\n                                      OSDMapRef& osdmap)\n{\n  epoch_t to = osdmap->get_epoch();\n  dout(10) << \"send_incremental_map \" << since << \" -> \" << to\n           << \" to \" << con << \" \" << con->get_peer_addr() << dendl;\n\n  MOSDMap *m = NULL;\n  while (!m) {\n    OSDSuperblock sblock(get_superblock());\n    if (since < sblock.oldest_map) {\n      // just send latest full map\n      MOSDMap *m = new MOSDMap(monc->get_fsid());\n      m->oldest_map = max_oldest_map;\n      m->newest_map = sblock.newest_map;\n      get_map_bl(to, m->maps[to]);\n      send_map(m, con);\n      return;\n    }\n\n    if (to > since && (int64_t)(to - since) > cct->_conf->osd_map_share_max_epochs) {\n      dout(10) << \"  \" << (to - since) << \" > max \" << cct->_conf->osd_map_share_max_epochs\n\t       << \", only sending most recent\" << dendl;\n      since = to - cct->_conf->osd_map_share_max_epochs;\n    }\n\n    if (to - since > (epoch_t)cct->_conf->osd_map_message_max)\n      to = since + cct->_conf->osd_map_message_max;\n    m = build_incremental_map_msg(since, to, sblock);\n  }\n  send_map(m, con);\n}\n\nbool OSDService::_get_map_bl(epoch_t e, bufferlist& bl)\n{\n  bool found = map_bl_cache.lookup(e, &bl);\n  if (found) {\n    if (logger)\n      logger->inc(l_osd_map_bl_cache_hit);\n    return true;\n  }\n  if (logger)\n    logger->inc(l_osd_map_bl_cache_miss);\n  found = store->read(coll_t::meta(),\n\t\t      OSD::get_osdmap_pobject_name(e), 0, 0, bl,\n\t\t      CEPH_OSD_OP_FLAG_FADVISE_WILLNEED) >= 0;\n  if (found) {\n    _add_map_bl(e, bl);\n  }\n  return found;\n}\n\nbool OSDService::get_inc_map_bl(epoch_t e, bufferlist& bl)\n{\n  Mutex::Locker l(map_cache_lock);\n  bool found = map_bl_inc_cache.lookup(e, &bl);\n  if (found) {\n    if (logger)\n      logger->inc(l_osd_map_bl_cache_hit);\n    return true;\n  }\n  if (logger)\n    logger->inc(l_osd_map_bl_cache_miss);\n  found = store->read(coll_t::meta(),\n\t\t      OSD::get_inc_osdmap_pobject_name(e), 0, 0, bl,\n\t\t      CEPH_OSD_OP_FLAG_FADVISE_WILLNEED) >= 0;\n  if (found) {\n    _add_map_inc_bl(e, bl);\n  }\n  return found;\n}\n\nvoid OSDService::_add_map_bl(epoch_t e, bufferlist& bl)\n{\n  dout(10) << \"add_map_bl \" << e << \" \" << bl.length() << \" bytes\" << dendl;\n  // cache a contiguous buffer\n  if (bl.get_num_buffers() > 1) {\n    bl.rebuild();\n  }\n  bl.try_assign_to_mempool(mempool::mempool_osd_mapbl);\n  map_bl_cache.add(e, bl);\n}\n\nvoid OSDService::_add_map_inc_bl(epoch_t e, bufferlist& bl)\n{\n  dout(10) << \"add_map_inc_bl \" << e << \" \" << bl.length() << \" bytes\" << dendl;\n  // cache a contiguous buffer\n  if (bl.get_num_buffers() > 1) {\n    bl.rebuild();\n  }\n  bl.try_assign_to_mempool(mempool::mempool_osd_mapbl);\n  map_bl_inc_cache.add(e, bl);\n}\n\nvoid OSDService::pin_map_inc_bl(epoch_t e, bufferlist &bl)\n{\n  Mutex::Locker l(map_cache_lock);\n  // cache a contiguous buffer\n  if (bl.get_num_buffers() > 1) {\n    bl.rebuild();\n  }\n  map_bl_inc_cache.pin(e, bl);\n}\n\nvoid OSDService::pin_map_bl(epoch_t e, bufferlist &bl)\n{\n  Mutex::Locker l(map_cache_lock);\n  // cache a contiguous buffer\n  if (bl.get_num_buffers() > 1) {\n    bl.rebuild();\n  }\n  map_bl_cache.pin(e, bl);\n}\n\nvoid OSDService::clear_map_bl_cache_pins(epoch_t e)\n{\n  Mutex::Locker l(map_cache_lock);\n  map_bl_inc_cache.clear_pinned(e);\n  map_bl_cache.clear_pinned(e);\n}\n\nOSDMapRef OSDService::_add_map(OSDMap *o)\n{\n  epoch_t e = o->get_epoch();\n\n  if (cct->_conf->osd_map_dedup) {\n    // Dedup against an existing map at a nearby epoch\n    OSDMapRef for_dedup = map_cache.lower_bound(e);\n    if (for_dedup) {\n      OSDMap::dedup(for_dedup.get(), o);\n    }\n  }\n  bool existed;\n  OSDMapRef l = map_cache.add(e, o, &existed);\n  if (existed) {\n    delete o;\n  }\n  return l;\n}\n\nOSDMapRef OSDService::try_get_map(epoch_t epoch)\n{\n  Mutex::Locker l(map_cache_lock);\n  OSDMapRef retval = map_cache.lookup(epoch);\n  if (retval) {\n    dout(30) << \"get_map \" << epoch << \" -cached\" << dendl;\n    if (logger) {\n      logger->inc(l_osd_map_cache_hit);\n    }\n    return retval;\n  }\n  if (logger) {\n    logger->inc(l_osd_map_cache_miss);\n    epoch_t lb = map_cache.cached_key_lower_bound();\n    if (epoch < lb) {\n      dout(30) << \"get_map \" << epoch << \" - miss, below lower bound\" << dendl;\n      logger->inc(l_osd_map_cache_miss_low);\n      logger->inc(l_osd_map_cache_miss_low_avg, lb - epoch);\n    }\n  }\n\n  OSDMap *map = new OSDMap;\n  if (epoch > 0) {\n    dout(20) << \"get_map \" << epoch << \" - loading and decoding \" << map << dendl;\n    bufferlist bl;\n    if (!_get_map_bl(epoch, bl) || bl.length() == 0) {\n      derr << \"failed to load OSD map for epoch \" << epoch << \", got \" << bl.length() << \" bytes\" << dendl;\n      delete map;\n      return OSDMapRef();\n    }\n    map->decode(bl);\n  } else {\n    dout(20) << \"get_map \" << epoch << \" - return initial \" << map << dendl;\n  }\n  return _add_map(map);\n}\n\n// ops\n\n\nvoid OSDService::reply_op_error(OpRequestRef op, int err)\n{\n  reply_op_error(op, err, eversion_t(), 0);\n}\n\nvoid OSDService::reply_op_error(OpRequestRef op, int err, eversion_t v,\n                                version_t uv)\n{\n  const MOSDOp *m = static_cast<const MOSDOp*>(op->get_req());\n  assert(m->get_type() == CEPH_MSG_OSD_OP);\n  int flags;\n  flags = m->get_flags() & (CEPH_OSD_FLAG_ACK|CEPH_OSD_FLAG_ONDISK);\n\n  MOSDOpReply *reply = new MOSDOpReply(m, err, osdmap->get_epoch(), flags,\n\t\t\t\t       true);\n  reply->set_reply_versions(v, uv);\n  m->get_connection()->send_message(reply);\n}\n\nvoid OSDService::handle_misdirected_op(PG *pg, OpRequestRef op)\n{\n  if (!cct->_conf->osd_debug_misdirected_ops) {\n    return;\n  }\n\n  const MOSDOp *m = static_cast<const MOSDOp*>(op->get_req());\n  assert(m->get_type() == CEPH_MSG_OSD_OP);\n\n  assert(m->get_map_epoch() >= pg->info.history.same_primary_since);\n\n  if (pg->is_ec_pg()) {\n    /**\n       * OSD recomputes op target based on current OSDMap. With an EC pg, we\n       * can get this result:\n       * 1) client at map 512 sends an op to osd 3, pg_t 3.9 based on mapping\n       *    [CRUSH_ITEM_NONE, 2, 3]/3\n       * 2) OSD 3 at map 513 remaps op to osd 3, spg_t 3.9s0 based on mapping\n       *    [3, 2, 3]/3\n       * 3) PG 3.9s0 dequeues the op at epoch 512 and notices that it isn't primary\n       *    -- misdirected op\n       * 4) client resends and this time PG 3.9s0 having caught up to 513 gets\n       *    it and fulfils it\n       *\n       * We can't compute the op target based on the sending map epoch due to\n       * splitting.  The simplest thing is to detect such cases here and drop\n       * them without an error (the client will resend anyway).\n       */\n    assert(m->get_map_epoch() <= superblock.newest_map);\n    OSDMapRef opmap = try_get_map(m->get_map_epoch());\n    if (!opmap) {\n      dout(7) << __func__ << \": \" << *pg << \" no longer have map for \"\n\t      << m->get_map_epoch() << \", dropping\" << dendl;\n      return;\n    }\n    pg_t _pgid = m->get_raw_pg();\n    spg_t pgid;\n    if ((m->get_flags() & CEPH_OSD_FLAG_PGOP) == 0)\n      _pgid = opmap->raw_pg_to_pg(_pgid);\n    if (opmap->get_primary_shard(_pgid, &pgid) &&\n\tpgid.shard != pg->info.pgid.shard) {\n      dout(7) << __func__ << \": \" << *pg << \" primary changed since \"\n\t      << m->get_map_epoch() << \", dropping\" << dendl;\n      return;\n    }\n  }\n\n  dout(7) << *pg << \" misdirected op in \" << m->get_map_epoch() << dendl;\n  clog->warn() << m->get_source_inst() << \" misdirected \" << m->get_reqid()\n\t       << \" pg \" << m->get_raw_pg()\n\t       << \" to osd.\" << whoami\n\t       << \" not \" << pg->acting\n\t       << \" in e\" << m->get_map_epoch() << \"/\" << osdmap->get_epoch();\n}\n\nvoid OSDService::enqueue_back(spg_t pgid, PGQueueable qi)\n{\n  osd->op_shardedwq.queue(make_pair(pgid, qi));\n}\n\nvoid OSDService::enqueue_front(spg_t pgid, PGQueueable qi)\n{\n  osd->op_shardedwq.queue_front(make_pair(pgid, qi));\n}\n\nvoid OSDService::queue_for_peering(PG *pg)\n{\n  peering_wq.queue(pg);\n}\n\nvoid OSDService::queue_for_snap_trim(PG *pg)\n{\n  dout(10) << \"queueing \" << *pg << \" for snaptrim\" << dendl;\n  osd->op_shardedwq.queue(\n    make_pair(\n      pg->info.pgid,\n      PGQueueable(\n\tPGSnapTrim(pg->get_osdmap()->get_epoch()),\n\tcct->_conf->osd_snap_trim_cost,\n\tcct->_conf->osd_snap_trim_priority,\n\tceph_clock_now(),\n\tentity_inst_t(),\n\tpg->get_osdmap()->get_epoch())));\n}\n\n\n// ====================================================================\n// OSD\n\n#undef dout_prefix\n#define dout_prefix *_dout\n\n// Commands shared between OSD's console and admin console:\nnamespace ceph { \nnamespace osd_cmds { \n\nint heap(CephContext& cct, cmdmap_t& cmdmap, Formatter& f, std::ostream& os);\n \n}} // namespace ceph::osd_cmds\n\nint OSD::mkfs(CephContext *cct, ObjectStore *store, const string &dev,\n\t      uuid_d fsid, int whoami)\n{\n  int ret;\n\n  ceph::shared_ptr<ObjectStore::Sequencer> osr(\n    new ObjectStore::Sequencer(\"mkfs\"));\n  OSDSuperblock sb;\n  bufferlist sbbl;\n  C_SaferCond waiter;\n\n  // if we are fed a uuid for this osd, use it.\n  store->set_fsid(cct->_conf->osd_uuid);\n\n  ret = store->mkfs();\n  if (ret) {\n    derr << \"OSD::mkfs: ObjectStore::mkfs failed with error \"\n         << cpp_strerror(ret) << dendl;\n    goto free_store;\n  }\n\n  store->set_cache_shards(1);  // doesn't matter for mkfs!\n\n  ret = store->mount();\n  if (ret) {\n    derr << \"OSD::mkfs: couldn't mount ObjectStore: error \"\n         << cpp_strerror(ret) << dendl;\n    goto free_store;\n  }\n\n  ret = store->read(coll_t::meta(), OSD_SUPERBLOCK_GOBJECT, 0, 0, sbbl);\n  if (ret >= 0) {\n    /* if we already have superblock, check content of superblock */\n    dout(0) << \" have superblock\" << dendl;\n    bufferlist::iterator p;\n    p = sbbl.begin();\n    ::decode(sb, p);\n    if (whoami != sb.whoami) {\n      derr << \"provided osd id \" << whoami << \" != superblock's \" << sb.whoami\n\t   << dendl;\n      ret = -EINVAL;\n      goto umount_store;\n    }\n    if (fsid != sb.cluster_fsid) {\n      derr << \"provided cluster fsid \" << fsid\n\t   << \" != superblock's \" << sb.cluster_fsid << dendl;\n      ret = -EINVAL;\n      goto umount_store;\n    }\n  } else {\n    // create superblock\n    sb.cluster_fsid = fsid;\n    sb.osd_fsid = store->get_fsid();\n    sb.whoami = whoami;\n    sb.compat_features = get_osd_initial_compat_set();\n\n    bufferlist bl;\n    ::encode(sb, bl);\n\n    ObjectStore::Transaction t;\n    t.create_collection(coll_t::meta(), 0);\n    t.write(coll_t::meta(), OSD_SUPERBLOCK_GOBJECT, 0, bl.length(), bl);\n    ret = store->apply_transaction(osr.get(), std::move(t));\n    if (ret) {\n      derr << \"OSD::mkfs: error while writing OSD_SUPERBLOCK_GOBJECT: \"\n\t   << \"apply_transaction returned \" << cpp_strerror(ret) << dendl;\n      goto umount_store;\n    }\n  }\n\n  if (!osr->flush_commit(&waiter)) {\n    waiter.wait();\n  }\n\n  ret = write_meta(cct, store, sb.cluster_fsid, sb.osd_fsid, whoami);\n  if (ret) {\n    derr << \"OSD::mkfs: failed to write fsid file: error \"\n         << cpp_strerror(ret) << dendl;\n    goto umount_store;\n  }\n\numount_store:\n  store->umount();\nfree_store:\n  delete store;\n  return ret;\n}\n\nint OSD::write_meta(CephContext *cct, ObjectStore *store, uuid_d& cluster_fsid, uuid_d& osd_fsid, int whoami)\n{\n  char val[80];\n  int r;\n\n  snprintf(val, sizeof(val), \"%s\", CEPH_OSD_ONDISK_MAGIC);\n  r = store->write_meta(\"magic\", val);\n  if (r < 0)\n    return r;\n\n  snprintf(val, sizeof(val), \"%d\", whoami);\n  r = store->write_meta(\"whoami\", val);\n  if (r < 0)\n    return r;\n\n  cluster_fsid.print(val);\n  r = store->write_meta(\"ceph_fsid\", val);\n  if (r < 0)\n    return r;\n\n  string key = cct->_conf->get_val<string>(\"key\");\n  if (key.size()) {\n    r = store->write_meta(\"osd_key\", key);\n    if (r < 0)\n      return r;\n  } else {\n    string keyfile = cct->_conf->get_val<string>(\"keyfile\");\n    if (!keyfile.empty()) {\n      bufferlist keybl;\n      string err;\n      if (keyfile == \"-\") {\n\tstatic_assert(1024 * 1024 >\n\t\t      (sizeof(CryptoKey) - sizeof(bufferptr) +\n\t\t       sizeof(__u16) + 16 /* AES_KEY_LEN */ + 3 - 1) / 3. * 4.,\n\t\t      \"1MB should be enough for a base64 encoded CryptoKey\");\n\tr = keybl.read_fd(STDIN_FILENO, 1024 * 1024);\n      } else {\n\tr = keybl.read_file(keyfile.c_str(), &err);\n      }\n      if (r < 0) {\n\tderr << __func__ << \" failed to read keyfile \" << keyfile << \": \"\n\t     << err << \": \" << cpp_strerror(r) << dendl;\n\treturn r;\n      }\n      r = store->write_meta(\"osd_key\", keybl.to_str());\n      if (r < 0)\n\treturn r;\n    }\n  }\n\n  r = store->write_meta(\"ready\", \"ready\");\n  if (r < 0)\n    return r;\n\n  return 0;\n}\n\nint OSD::peek_meta(ObjectStore *store, std::string& magic,\n\t\t   uuid_d& cluster_fsid, uuid_d& osd_fsid, int& whoami)\n{\n  string val;\n\n  int r = store->read_meta(\"magic\", &val);\n  if (r < 0)\n    return r;\n  magic = val;\n\n  r = store->read_meta(\"whoami\", &val);\n  if (r < 0)\n    return r;\n  whoami = atoi(val.c_str());\n\n  r = store->read_meta(\"ceph_fsid\", &val);\n  if (r < 0)\n    return r;\n  r = cluster_fsid.parse(val.c_str());\n  if (!r)\n    return -EINVAL;\n\n  r = store->read_meta(\"fsid\", &val);\n  if (r < 0) {\n    osd_fsid = uuid_d();\n  } else {\n    r = osd_fsid.parse(val.c_str());\n    if (!r)\n      return -EINVAL;\n  }\n\n  return 0;\n}\n\n\n#undef dout_prefix\n#define dout_prefix _prefix(_dout, whoami, get_osdmap_epoch())\n\n// cons/des\n\nOSD::OSD(CephContext *cct_, ObjectStore *store_,\n\t int id,\n\t Messenger *internal_messenger,\n\t Messenger *external_messenger,\n\t Messenger *hb_client_front,\n\t Messenger *hb_client_back,\n\t Messenger *hb_front_serverm,\n\t Messenger *hb_back_serverm,\n\t Messenger *osdc_messenger,\n\t MonClient *mc,\n\t const std::string &dev, const std::string &jdev) :\n  Dispatcher(cct_),\n  osd_lock(\"OSD::osd_lock\"),\n  tick_timer(cct, osd_lock),\n  tick_timer_lock(\"OSD::tick_timer_lock\"),\n  tick_timer_without_osd_lock(cct, tick_timer_lock),\n  authorize_handler_cluster_registry(new AuthAuthorizeHandlerRegistry(cct,\n\t\t\t\t\t\t\t\t      cct->_conf->auth_supported.empty() ?\n\t\t\t\t\t\t\t\t      cct->_conf->auth_cluster_required :\n\t\t\t\t\t\t\t\t      cct->_conf->auth_supported)),\n  authorize_handler_service_registry(new AuthAuthorizeHandlerRegistry(cct,\n\t\t\t\t\t\t\t\t      cct->_conf->auth_supported.empty() ?\n\t\t\t\t\t\t\t\t      cct->_conf->auth_service_required :\n\t\t\t\t\t\t\t\t      cct->_conf->auth_supported)),\n  cluster_messenger(internal_messenger),\n  client_messenger(external_messenger),\n  objecter_messenger(osdc_messenger),\n  monc(mc),\n  mgrc(cct_, client_messenger),\n  logger(NULL),\n  recoverystate_perf(NULL),\n  store(store_),\n  log_client(cct, client_messenger, &mc->monmap, LogClient::NO_FLAGS),\n  clog(log_client.create_channel()),\n  whoami(id),\n  dev_path(dev), journal_path(jdev),\n  store_is_rotational(store->is_rotational()),\n  trace_endpoint(\"0.0.0.0\", 0, \"osd\"),\n  asok_hook(NULL),\n  osd_compat(get_osd_compat_set()),\n  peering_tp(cct, \"OSD::peering_tp\", \"tp_peering\",\n\t     cct->_conf->osd_peering_wq_threads,\n\t     \"osd_peering_tp_threads\"),\n  osd_op_tp(cct, \"OSD::osd_op_tp\", \"tp_osd_tp\",\n\t    get_num_op_threads()),\n  disk_tp(cct, \"OSD::disk_tp\", \"tp_osd_disk\", cct->_conf->osd_disk_threads, \"osd_disk_threads\"),\n  command_tp(cct, \"OSD::command_tp\", \"tp_osd_cmd\",  1),\n  session_waiting_lock(\"OSD::session_waiting_lock\"),\n  osdmap_subscribe_lock(\"OSD::osdmap_subscribe_lock\"),\n  heartbeat_lock(\"OSD::heartbeat_lock\"),\n  heartbeat_stop(false),\n  heartbeat_need_update(true),\n  hb_front_client_messenger(hb_client_front),\n  hb_back_client_messenger(hb_client_back),\n  hb_front_server_messenger(hb_front_serverm),\n  hb_back_server_messenger(hb_back_serverm),\n  daily_loadavg(0.0),\n  heartbeat_thread(this),\n  heartbeat_dispatcher(this),\n  op_tracker(cct, cct->_conf->osd_enable_op_tracker,\n                  cct->_conf->osd_num_op_tracker_shard),\n  test_ops_hook(NULL),\n  op_queue(get_io_queue()),\n  op_prio_cutoff(get_io_prio_cut()),\n  op_shardedwq(\n    get_num_op_shards(),\n    this,\n    cct->_conf->osd_op_thread_timeout,\n    cct->_conf->osd_op_thread_suicide_timeout,\n    &osd_op_tp),\n  peering_wq(\n    this,\n    cct->_conf->osd_op_thread_timeout,\n    cct->_conf->osd_op_thread_suicide_timeout,\n    &peering_tp),\n  map_lock(\"OSD::map_lock\"),\n  pg_map_lock(\"OSD::pg_map_lock\"),\n  last_pg_create_epoch(0),\n  mon_report_lock(\"OSD::mon_report_lock\"),\n  stats_ack_timeout(cct->_conf->osd_mon_ack_timeout),\n  up_thru_wanted(0),\n  requested_full_first(0),\n  requested_full_last(0),\n  pg_stat_queue_lock(\"OSD::pg_stat_queue_lock\"),\n  osd_stat_updated(false),\n  pg_stat_tid(0), pg_stat_tid_flushed(0),\n  command_wq(\n    this,\n    cct->_conf->osd_command_thread_timeout,\n    cct->_conf->osd_command_thread_suicide_timeout,\n    &command_tp),\n  remove_wq(\n    cct,\n    store,\n    cct->_conf->osd_remove_thread_timeout,\n    cct->_conf->osd_remove_thread_suicide_timeout,\n    &disk_tp),\n  service(this)\n{\n  monc->set_messenger(client_messenger);\n  op_tracker.set_complaint_and_threshold(cct->_conf->osd_op_complaint_time,\n                                         cct->_conf->osd_op_log_threshold);\n  op_tracker.set_history_size_and_duration(cct->_conf->osd_op_history_size,\n                                           cct->_conf->osd_op_history_duration);\n  op_tracker.set_history_slow_op_size_and_threshold(cct->_conf->osd_op_history_slow_op_size,\n                                                    cct->_conf->osd_op_history_slow_op_threshold);\n#ifdef WITH_BLKIN\n  std::stringstream ss;\n  ss << \"osd.\" << whoami;\n  trace_endpoint.copy_name(ss.str());\n#endif\n}\n\nOSD::~OSD()\n{\n  delete authorize_handler_cluster_registry;\n  delete authorize_handler_service_registry;\n  delete class_handler;\n  cct->get_perfcounters_collection()->remove(recoverystate_perf);\n  cct->get_perfcounters_collection()->remove(logger);\n  delete recoverystate_perf;\n  delete logger;\n  delete store;\n}\n\nvoid cls_initialize(ClassHandler *ch);\n\nvoid OSD::handle_signal(int signum)\n{\n  assert(signum == SIGINT || signum == SIGTERM);\n  derr << \"*** Got signal \" << sig_str(signum) << \" ***\" << dendl;\n  shutdown();\n}\n\nint OSD::pre_init()\n{\n  Mutex::Locker lock(osd_lock);\n  if (is_stopping())\n    return 0;\n\n  if (store->test_mount_in_use()) {\n    derr << \"OSD::pre_init: object store '\" << dev_path << \"' is \"\n         << \"currently in use. (Is ceph-osd already running?)\" << dendl;\n    return -EBUSY;\n  }\n\n  cct->_conf->add_observer(this);\n  return 0;\n}\n\n// asok\n\nclass OSDSocketHook : public AdminSocketHook {\n  OSD *osd;\npublic:\n  explicit OSDSocketHook(OSD *o) : osd(o) {}\n  bool call(std::string admin_command, cmdmap_t& cmdmap, std::string format,\n\t    bufferlist& out) override {\n    stringstream ss;\n    bool r = osd->asok_command(admin_command, cmdmap, format, ss);\n    out.append(ss);\n    return r;\n  }\n};\n\nbool OSD::asok_command(string admin_command, cmdmap_t& cmdmap, string format,\n\t\t       ostream& ss)\n{\n  Formatter *f = Formatter::create(format, \"json-pretty\", \"json-pretty\");\n  if (admin_command == \"status\") {\n    f->open_object_section(\"status\");\n    f->dump_stream(\"cluster_fsid\") << superblock.cluster_fsid;\n    f->dump_stream(\"osd_fsid\") << superblock.osd_fsid;\n    f->dump_unsigned(\"whoami\", superblock.whoami);\n    f->dump_string(\"state\", get_state_name(get_state()));\n    f->dump_unsigned(\"oldest_map\", superblock.oldest_map);\n    f->dump_unsigned(\"newest_map\", superblock.newest_map);\n    {\n      RWLock::RLocker l(pg_map_lock);\n      f->dump_unsigned(\"num_pgs\", pg_map.size());\n    }\n    f->close_section();\n  } else if (admin_command == \"flush_journal\") {\n    store->flush_journal();\n  } else if (admin_command == \"dump_ops_in_flight\" ||\n             admin_command == \"ops\" ||\n             admin_command == \"dump_blocked_ops\" ||\n             admin_command == \"dump_historic_ops\" ||\n             admin_command == \"dump_historic_ops_by_duration\" ||\n             admin_command == \"dump_historic_slow_ops\") {\n\n    const string error_str = \"op_tracker tracking is not enabled now, so no ops are tracked currently, \\\neven those get stuck. Please enable \\\"osd_enable_op_tracker\\\", and the tracker \\\nwill start to track new ops received afterwards.\";\n\n    set<string> filters;\n    vector<string> filter_str;\n    if (cmd_getval(cct, cmdmap, \"filterstr\", filter_str)) {\n        copy(filter_str.begin(), filter_str.end(),\n           inserter(filters, filters.end()));\n    }\n\n    if (admin_command == \"dump_ops_in_flight\" ||\n        admin_command == \"ops\") {\n      if (!op_tracker.dump_ops_in_flight(f, false, filters)) {\n        ss << error_str;\n      }\n    }\n    if (admin_command == \"dump_blocked_ops\") {\n      if (!op_tracker.dump_ops_in_flight(f, true, filters)) {\n        ss << error_str;\n      }\n    }\n    if (admin_command == \"dump_historic_ops\") {\n      if (!op_tracker.dump_historic_ops(f, false, filters)) {\n        ss << error_str;\n      }\n    }\n    if (admin_command == \"dump_historic_ops_by_duration\") {\n      if (!op_tracker.dump_historic_ops(f, true, filters)) {\n        ss << error_str;\n      }\n    }\n    if (admin_command == \"dump_historic_slow_ops\") {\n      if (!op_tracker.dump_historic_slow_ops(f, filters)) {\n        ss << error_str;\n      }\n    }\n  } else if (admin_command == \"dump_op_pq_state\") {\n    f->open_object_section(\"pq\");\n    op_shardedwq.dump(f);\n    f->close_section();\n  } else if (admin_command == \"dump_blacklist\") {\n    list<pair<entity_addr_t,utime_t> > bl;\n    OSDMapRef curmap = service.get_osdmap();\n\n    f->open_array_section(\"blacklist\");\n    curmap->get_blacklist(&bl);\n    for (list<pair<entity_addr_t,utime_t> >::iterator it = bl.begin();\n\tit != bl.end(); ++it) {\n      f->open_object_section(\"entry\");\n      f->open_object_section(\"entity_addr_t\");\n      it->first.dump(f);\n      f->close_section(); //entity_addr_t\n      it->second.localtime(f->dump_stream(\"expire_time\"));\n      f->close_section(); //entry\n    }\n    f->close_section(); //blacklist\n  } else if (admin_command == \"dump_watchers\") {\n    list<obj_watch_item_t> watchers;\n    // scan pg's\n    {\n      Mutex::Locker l(osd_lock);\n      RWLock::RLocker l2(pg_map_lock);\n      for (ceph::unordered_map<spg_t,PG*>::iterator it = pg_map.begin();\n          it != pg_map.end();\n          ++it) {\n\n        list<obj_watch_item_t> pg_watchers;\n        PG *pg = it->second;\n        pg->lock();\n        pg->get_watchers(pg_watchers);\n        pg->unlock();\n        watchers.splice(watchers.end(), pg_watchers);\n      }\n    }\n\n    f->open_array_section(\"watchers\");\n    for (list<obj_watch_item_t>::iterator it = watchers.begin();\n\tit != watchers.end(); ++it) {\n\n      f->open_object_section(\"watch\");\n\n      f->dump_string(\"namespace\", it->obj.nspace);\n      f->dump_string(\"object\", it->obj.oid.name);\n\n      f->open_object_section(\"entity_name\");\n      it->wi.name.dump(f);\n      f->close_section(); //entity_name_t\n\n      f->dump_unsigned(\"cookie\", it->wi.cookie);\n      f->dump_unsigned(\"timeout\", it->wi.timeout_seconds);\n\n      f->open_object_section(\"entity_addr_t\");\n      it->wi.addr.dump(f);\n      f->close_section(); //entity_addr_t\n\n      f->close_section(); //watch\n    }\n\n    f->close_section(); //watchers\n  } else if (admin_command == \"dump_reservations\") {\n    f->open_object_section(\"reservations\");\n    f->open_object_section(\"local_reservations\");\n    service.local_reserver.dump(f);\n    f->close_section();\n    f->open_object_section(\"remote_reservations\");\n    service.remote_reserver.dump(f);\n    f->close_section();\n    f->close_section();\n  } else if (admin_command == \"get_latest_osdmap\") {\n    get_latest_osdmap();\n  } else if (admin_command == \"heap\") {\n    auto result = ceph::osd_cmds::heap(*cct, cmdmap, *f, ss);\n\n    // Note: Failed heap profile commands won't necessarily trigger an error:\n    f->open_object_section(\"result\");\n    f->dump_string(\"error\", cpp_strerror(result));\n    f->dump_bool(\"success\", result >= 0);\n    f->close_section();\n  } else if (admin_command == \"set_heap_property\") {\n    string property;\n    int64_t value = 0;\n    string error;\n    bool success = false;\n    if (!cmd_getval(cct, cmdmap, \"property\", property)) {\n      error = \"unable to get property\";\n      success = false;\n    } else if (!cmd_getval(cct, cmdmap, \"value\", value)) {\n      error = \"unable to get value\";\n      success = false;\n    } else if (value < 0) {\n      error = \"negative value not allowed\";\n      success = false;\n    } else if (!ceph_heap_set_numeric_property(property.c_str(), (size_t)value)) {\n      error = \"invalid property\";\n      success = false;\n    } else {\n      success = true;\n    }\n    f->open_object_section(\"result\");\n    f->dump_string(\"error\", error);\n    f->dump_bool(\"success\", success);\n    f->close_section();\n  } else if (admin_command == \"get_heap_property\") {\n    string property;\n    size_t value = 0;\n    string error;\n    bool success = false;\n    if (!cmd_getval(cct, cmdmap, \"property\", property)) {\n      error = \"unable to get property\";\n      success = false;\n    } else if (!ceph_heap_get_numeric_property(property.c_str(), &value)) {\n      error = \"invalid property\";\n      success = false;\n    } else {\n      success = true;\n    }\n    f->open_object_section(\"result\");\n    f->dump_string(\"error\", error);\n    f->dump_bool(\"success\", success);\n    f->dump_int(\"value\", value);\n    f->close_section();\n  } else if (admin_command == \"dump_objectstore_kv_stats\") {\n    store->get_db_statistics(f);\n  } else if (admin_command == \"dump_scrubs\") {\n    service.dumps_scrub(f);\n  } else if (admin_command == \"calc_objectstore_db_histogram\") {\n    store->generate_db_histogram(f);\n  } else if (admin_command == \"flush_store_cache\") {\n    store->flush_cache();\n  } else if (admin_command == \"dump_pgstate_history\") {\n    f->open_object_section(\"pgstate_history\");\n    RWLock::RLocker l2(pg_map_lock);\n    for (ceph::unordered_map<spg_t,PG*>::iterator it = pg_map.begin();\n        it != pg_map.end();\n        ++it) {\n\n      PG *pg = it->second;\n      f->dump_stream(\"pg\") << pg->get_pgid();\n      pg->lock();\n      pg->pgstate_history.dump(f);\n      pg->unlock();\n    }\n    f->close_section();\n  } else if (admin_command == \"compact\") {\n    dout(1) << \"triggering manual compaction\" << dendl;\n    auto start = ceph::coarse_mono_clock::now();\n    store->compact();\n    auto end = ceph::coarse_mono_clock::now();\n    auto time_span = chrono::duration_cast<chrono::duration<double>>(end - start);\n    dout(1) << \"finished manual compaction in \" \n            << time_span.count()\n            << \" seconds\" << dendl;\n    f->open_object_section(\"compact_result\");\n    f->dump_float(\"elapsed_time\", time_span.count());\n    f->close_section();\n  } else {\n    assert(0 == \"broken asok registration\");\n  }\n  f->flush(ss);\n  delete f;\n  return true;\n}\n\nclass TestOpsSocketHook : public AdminSocketHook {\n  OSDService *service;\n  ObjectStore *store;\npublic:\n  TestOpsSocketHook(OSDService *s, ObjectStore *st) : service(s), store(st) {}\n  bool call(std::string command, cmdmap_t& cmdmap, std::string format,\n\t    bufferlist& out) override {\n    stringstream ss;\n    test_ops(service, store, command, cmdmap, ss);\n    out.append(ss);\n    return true;\n  }\n  void test_ops(OSDService *service, ObjectStore *store,\n\t\tconst std::string &command, cmdmap_t& cmdmap, ostream &ss);\n\n};\n\nclass OSD::C_Tick : public Context {\n  OSD *osd;\n  public:\n  explicit C_Tick(OSD *o) : osd(o) {}\n  void finish(int r) override {\n    osd->tick();\n  }\n};\n\nclass OSD::C_Tick_WithoutOSDLock : public Context {\n  OSD *osd;\n  public:\n  explicit C_Tick_WithoutOSDLock(OSD *o) : osd(o) {}\n  void finish(int r) override {\n    osd->tick_without_osd_lock();\n  }\n};\n\nint OSD::enable_disable_fuse(bool stop)\n{\n#ifdef HAVE_LIBFUSE\n  int r;\n  string mntpath = cct->_conf->osd_data + \"/fuse\";\n  if (fuse_store && (stop || !cct->_conf->osd_objectstore_fuse)) {\n    dout(1) << __func__ << \" disabling\" << dendl;\n    fuse_store->stop();\n    delete fuse_store;\n    fuse_store = NULL;\n    r = ::rmdir(mntpath.c_str());\n    if (r < 0) {\n      r = -errno;\n      derr << __func__ << \" failed to rmdir \" << mntpath << \": \"\n           << cpp_strerror(r) << dendl;\n      return r;\n    }\n    return 0;\n  }\n  if (!fuse_store && cct->_conf->osd_objectstore_fuse) {\n    dout(1) << __func__ << \" enabling\" << dendl;\n    r = ::mkdir(mntpath.c_str(), 0700);\n    if (r < 0)\n      r = -errno;\n    if (r < 0 && r != -EEXIST) {\n      derr << __func__ << \" unable to create \" << mntpath << \": \"\n\t   << cpp_strerror(r) << dendl;\n      return r;\n    }\n    fuse_store = new FuseStore(store, mntpath);\n    r = fuse_store->start();\n    if (r < 0) {\n      derr << __func__ << \" unable to start fuse: \" << cpp_strerror(r) << dendl;\n      delete fuse_store;\n      fuse_store = NULL;\n      return r;\n    }\n  }\n#endif  // HAVE_LIBFUSE\n  return 0;\n}\n\nint OSD::get_num_op_shards()\n{\n  if (cct->_conf->osd_op_num_shards)\n    return cct->_conf->osd_op_num_shards;\n  if (store_is_rotational)\n    return cct->_conf->osd_op_num_shards_hdd;\n  else\n    return cct->_conf->osd_op_num_shards_ssd;\n}\n\nint OSD::get_num_op_threads()\n{\n  if (cct->_conf->osd_op_num_threads_per_shard)\n    return get_num_op_shards() * cct->_conf->osd_op_num_threads_per_shard;\n  if (store_is_rotational)\n    return get_num_op_shards() * cct->_conf->osd_op_num_threads_per_shard_hdd;\n  else\n    return get_num_op_shards() * cct->_conf->osd_op_num_threads_per_shard_ssd;\n}\n\nfloat OSD::get_osd_recovery_sleep()\n{\n  if (cct->_conf->osd_recovery_sleep)\n    return cct->_conf->osd_recovery_sleep;\n  if (!store_is_rotational && !journal_is_rotational)\n    return cct->_conf->osd_recovery_sleep_ssd;\n  else if (store_is_rotational && !journal_is_rotational)\n    return cct->_conf->get_val<double>(\"osd_recovery_sleep_hybrid\");\n  else\n    return cct->_conf->osd_recovery_sleep_hdd;\n}\n\nint OSD::init()\n{\n  CompatSet initial, diff;\n  Mutex::Locker lock(osd_lock);\n  if (is_stopping())\n    return 0;\n\n  tick_timer.init();\n  tick_timer_without_osd_lock.init();\n  service.recovery_request_timer.init();\n  service.recovery_sleep_timer.init();\n\n  // mount.\n  dout(2) << \"init \" << dev_path\n\t  << \" (looks like \" << (store_is_rotational ? \"hdd\" : \"ssd\") << \")\"\n\t  << dendl;\n  dout(2) << \"journal \" << journal_path << dendl;\n  assert(store);  // call pre_init() first!\n\n  store->set_cache_shards(get_num_op_shards());\n\n  int r = store->mount();\n  if (r < 0) {\n    derr << \"OSD:init: unable to mount object store\" << dendl;\n    return r;\n  }\n  journal_is_rotational = store->is_journal_rotational();\n  dout(2) << \"journal looks like \" << (journal_is_rotational ? \"hdd\" : \"ssd\")\n          << dendl;\n\n  enable_disable_fuse(false);\n\n  dout(2) << \"boot\" << dendl;\n\n  // initialize the daily loadavg with current 15min loadavg\n  double loadavgs[3];\n  if (getloadavg(loadavgs, 3) == 3) {\n    daily_loadavg = loadavgs[2];\n  } else {\n    derr << \"OSD::init() : couldn't read loadavgs\\n\" << dendl;\n    daily_loadavg = 1.0;\n  }\n\n  int rotating_auth_attempts = 0;\n\n  // sanity check long object name handling\n  {\n    hobject_t l;\n    l.oid.name = string(cct->_conf->osd_max_object_name_len, 'n');\n    l.set_key(string(cct->_conf->osd_max_object_name_len, 'k'));\n    l.nspace = string(cct->_conf->osd_max_object_namespace_len, 's');\n    r = store->validate_hobject_key(l);\n    if (r < 0) {\n      derr << \"backend (\" << store->get_type() << \") is unable to support max \"\n\t   << \"object name[space] len\" << dendl;\n      derr << \"   osd max object name len = \"\n\t   << cct->_conf->osd_max_object_name_len << dendl;\n      derr << \"   osd max object namespace len = \"\n\t   << cct->_conf->osd_max_object_namespace_len << dendl;\n      derr << cpp_strerror(r) << dendl;\n      if (cct->_conf->osd_check_max_object_name_len_on_startup) {\n\tgoto out;\n      }\n      derr << \"osd_check_max_object_name_len_on_startup = false, starting anyway\"\n\t   << dendl;\n    } else {\n      dout(20) << \"configured osd_max_object_name[space]_len looks ok\" << dendl;\n    }\n  }\n\n  // read superblock\n  r = read_superblock();\n  if (r < 0) {\n    derr << \"OSD::init() : unable to read osd superblock\" << dendl;\n    r = -EINVAL;\n    goto out;\n  }\n\n  if (osd_compat.compare(superblock.compat_features) < 0) {\n    derr << \"The disk uses features unsupported by the executable.\" << dendl;\n    derr << \" ondisk features \" << superblock.compat_features << dendl;\n    derr << \" daemon features \" << osd_compat << dendl;\n\n    if (osd_compat.writeable(superblock.compat_features)) {\n      CompatSet diff = osd_compat.unsupported(superblock.compat_features);\n      derr << \"it is still writeable, though. Missing features: \" << diff << dendl;\n      r = -EOPNOTSUPP;\n      goto out;\n    }\n    else {\n      CompatSet diff = osd_compat.unsupported(superblock.compat_features);\n      derr << \"Cannot write to disk! Missing features: \" << diff << dendl;\n      r = -EOPNOTSUPP;\n      goto out;\n    }\n  }\n\n  assert_warn(whoami == superblock.whoami);\n  if (whoami != superblock.whoami) {\n    derr << \"OSD::init: superblock says osd\"\n\t << superblock.whoami << \" but I am osd.\" << whoami << dendl;\n    r = -EINVAL;\n    goto out;\n  }\n\n  initial = get_osd_initial_compat_set();\n  diff = superblock.compat_features.unsupported(initial);\n  if (superblock.compat_features.merge(initial)) {\n    // We need to persist the new compat_set before we\n    // do anything else\n    dout(5) << \"Upgrading superblock adding: \" << diff << dendl;\n    ObjectStore::Transaction t;\n    write_superblock(t);\n    r = store->apply_transaction(service.meta_osr.get(), std::move(t));\n    if (r < 0)\n      goto out;\n  }\n\n  // make sure snap mapper object exists\n  if (!store->exists(coll_t::meta(), OSD::make_snapmapper_oid())) {\n    dout(10) << \"init creating/touching snapmapper object\" << dendl;\n    ObjectStore::Transaction t;\n    t.touch(coll_t::meta(), OSD::make_snapmapper_oid());\n    r = store->apply_transaction(service.meta_osr.get(), std::move(t));\n    if (r < 0)\n      goto out;\n  }\n\n  class_handler = new ClassHandler(cct);\n  cls_initialize(class_handler);\n\n  if (cct->_conf->osd_open_classes_on_start) {\n    int r = class_handler->open_all_classes();\n    if (r)\n      dout(1) << \"warning: got an error loading one or more classes: \" << cpp_strerror(r) << dendl;\n  }\n\n  // load up \"current\" osdmap\n  assert_warn(!osdmap);\n  if (osdmap) {\n    derr << \"OSD::init: unable to read current osdmap\" << dendl;\n    r = -EINVAL;\n    goto out;\n  }\n  osdmap = get_map(superblock.current_epoch);\n  check_osdmap_features(store);\n\n  create_recoverystate_perf();\n\n  {\n    epoch_t bind_epoch = osdmap->get_epoch();\n    service.set_epochs(NULL, NULL, &bind_epoch);\n  }\n\n  clear_temp_objects();\n\n  // initialize osdmap references in sharded wq\n  op_shardedwq.prune_pg_waiters(osdmap, whoami);\n\n  // load up pgs (as they previously existed)\n  load_pgs();\n\n  dout(2) << \"superblock: I am osd.\" << superblock.whoami << dendl;\n  dout(0) << \"using \" << op_queue << \" op queue with priority op cut off at \" <<\n    op_prio_cutoff << \".\" << dendl;\n\n  create_logger();\n\n  // i'm ready!\n  client_messenger->add_dispatcher_head(this);\n  cluster_messenger->add_dispatcher_head(this);\n\n  hb_front_client_messenger->add_dispatcher_head(&heartbeat_dispatcher);\n  hb_back_client_messenger->add_dispatcher_head(&heartbeat_dispatcher);\n  hb_front_server_messenger->add_dispatcher_head(&heartbeat_dispatcher);\n  hb_back_server_messenger->add_dispatcher_head(&heartbeat_dispatcher);\n\n  objecter_messenger->add_dispatcher_head(service.objecter);\n\n  monc->set_want_keys(CEPH_ENTITY_TYPE_MON | CEPH_ENTITY_TYPE_OSD\n                      | CEPH_ENTITY_TYPE_MGR);\n  r = monc->init();\n  if (r < 0)\n    goto out;\n\n  /**\n   * FIXME: this is a placeholder implementation that unconditionally\n   * sends every is_primary PG's stats every time we're called, unlike\n   * the existing mon PGStats mechanism that uses pg_stat_queue and acks.\n   * This has equivalent cost to the existing worst case where all\n   * PGs are busy and their stats are always enqueued for sending.\n   */\n  mgrc.set_pgstats_cb([this](){\n      RWLock::RLocker l(map_lock);\n      \n      utime_t had_for = ceph_clock_now() - had_map_since;\n      osd_stat_t cur_stat = service.get_osd_stat();\n      cur_stat.os_perf_stat = store->get_cur_stats();\n\n      MPGStats *m = new MPGStats(monc->get_fsid(), osdmap->get_epoch(), had_for);\n      m->osd_stat = cur_stat;\n\n      Mutex::Locker lec{min_last_epoch_clean_lock};\n      min_last_epoch_clean = osdmap->get_epoch();\n      min_last_epoch_clean_pgs.clear();\n      RWLock::RLocker lpg(pg_map_lock);\n      for (const auto &i : pg_map) {\n        PG *pg = i.second;\n        if (!pg->is_primary()) {\n          continue;\n        }\n\n        pg->pg_stats_publish_lock.Lock();\n        if (pg->pg_stats_publish_valid) {\n          m->pg_stat[pg->info.pgid.pgid] = pg->pg_stats_publish;\n\t  const auto lec = pg->pg_stats_publish.get_effective_last_epoch_clean();\n\t  min_last_epoch_clean = min(min_last_epoch_clean, lec);\n\t  min_last_epoch_clean_pgs.push_back(pg->info.pgid.pgid);\n        }\n        pg->pg_stats_publish_lock.Unlock();\n      }\n\n      return m;\n  });\n\n  mgrc.init();\n  client_messenger->add_dispatcher_head(&mgrc);\n\n  // tell monc about log_client so it will know about mon session resets\n  monc->set_log_client(&log_client);\n  update_log_config();\n\n  peering_tp.start();\n  \n  service.init();\n  service.publish_map(osdmap);\n  service.publish_superblock(superblock);\n  service.max_oldest_map = superblock.oldest_map;\n\n  osd_op_tp.start();\n  disk_tp.start();\n  command_tp.start();\n\n  set_disk_tp_priority();\n\n  // start the heartbeat\n  heartbeat_thread.create(\"osd_srv_heartbt\");\n\n  // tick\n  tick_timer.add_event_after(cct->_conf->osd_heartbeat_interval, new C_Tick(this));\n  {\n    Mutex::Locker l(tick_timer_lock);\n    tick_timer_without_osd_lock.add_event_after(cct->_conf->osd_heartbeat_interval, new C_Tick_WithoutOSDLock(this));\n  }\n\n  osd_lock.Unlock();\n\n  r = monc->authenticate();\n  if (r < 0) {\n    derr << __func__ << \" authentication failed: \" << cpp_strerror(r)\n         << dendl;\n    osd_lock.Lock(); // locker is going to unlock this on function exit\n    if (is_stopping())\n      r = 0;\n    goto monout;\n  }\n\n  while (monc->wait_auth_rotating(30.0) < 0) {\n    derr << \"unable to obtain rotating service keys; retrying\" << dendl;\n    ++rotating_auth_attempts;\n    if (rotating_auth_attempts > g_conf->max_rotating_auth_attempts) {\n        derr << __func__ << \" wait_auth_rotating timed out\" << dendl;\n        osd_lock.Lock(); // make locker happy\n        if (!is_stopping()) {\n            r = -ETIMEDOUT;\n        }\n        goto monout;\n    }\n  }\n\n  r = update_crush_device_class();\n  if (r < 0) {\n    derr << __func__ << \" unable to update_crush_device_class: \"\n\t << cpp_strerror(r) << dendl;\n    osd_lock.Lock();\n    goto monout;\n  }\n\n  r = update_crush_location();\n  if (r < 0) {\n    derr << __func__ << \" unable to update_crush_location: \"\n         << cpp_strerror(r) << dendl;\n    osd_lock.Lock();\n    goto monout;\n  }\n\n  osd_lock.Lock();\n  if (is_stopping())\n    return 0;\n\n  // start objecter *after* we have authenticated, so that we don't ignore\n  // the OSDMaps it requests.\n  service.final_init();\n\n  check_config();\n\n  dout(10) << \"ensuring pgs have consumed prior maps\" << dendl;\n  consume_map();\n  peering_wq.drain();\n\n  dout(0) << \"done with init, starting boot process\" << dendl;\n\n  // subscribe to any pg creations\n  monc->sub_want(\"osd_pg_creates\", last_pg_create_epoch, 0);\n\n  // MgrClient needs this (it doesn't have MonClient reference itself)\n  monc->sub_want(\"mgrmap\", 0, 0);\n\n  // we don't need to ask for an osdmap here; objecter will\n  //monc->sub_want(\"osdmap\", osdmap->get_epoch(), CEPH_SUBSCRIBE_ONETIME);\n\n  monc->renew_subs();\n\n  start_boot();\n\n  return 0;\nmonout:\n  exit(1);\n\nout:\n  enable_disable_fuse(true);\n  store->umount();\n  delete store;\n  store = NULL;\n  return r;\n}\n\nvoid OSD::final_init()\n{\n  AdminSocket *admin_socket = cct->get_admin_socket();\n  asok_hook = new OSDSocketHook(this);\n  int r = admin_socket->register_command(\"status\", \"status\", asok_hook,\n\t\t\t\t\t \"high-level status of OSD\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"flush_journal\", \"flush_journal\",\n                                     asok_hook,\n                                     \"flush the journal to permanent store\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_ops_in_flight\",\n\t\t\t\t     \"dump_ops_in_flight \" \\\n\t\t\t\t     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show the ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"ops\",\n\t\t\t\t     \"ops \" \\\n\t\t\t\t     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show the ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_blocked_ops\",\n\t\t\t\t     \"dump_blocked_ops \" \\\n\t\t\t\t     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show the blocked ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_historic_ops\",\n                                     \"dump_historic_ops \" \\\n                                     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show recent ops\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_historic_slow_ops\",\n                                     \"dump_historic_slow_ops \" \\\n                                     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show slowest recent ops\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_historic_ops_by_duration\",\n                                     \"dump_historic_ops_by_duration \" \\\n                                     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show slowest recent ops, sorted by duration\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_op_pq_state\", \"dump_op_pq_state\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"dump op priority queue state\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_blacklist\", \"dump_blacklist\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"dump blacklisted clients and times\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_watchers\", \"dump_watchers\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show clients which have active watches,\"\n\t\t\t\t     \" and on which objects\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_reservations\", \"dump_reservations\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show recovery reservations\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"get_latest_osdmap\", \"get_latest_osdmap\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"force osd to update the latest map from \"\n\t\t\t\t     \"the mon\");\n  assert(r == 0);\n\n  r = admin_socket->register_command( \"heap\",\n                                      \"heap \" \\\n                                      \"name=heapcmd,type=CephString\",\n                                      asok_hook,\n                                      \"show heap usage info (available only if \"\n                                      \"compiled with tcmalloc)\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"set_heap_property\",\n\t\t\t\t     \"set_heap_property \" \\\n\t\t\t\t     \"name=property,type=CephString \" \\\n\t\t\t\t     \"name=value,type=CephInt\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"update malloc extension heap property\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"get_heap_property\",\n\t\t\t\t     \"get_heap_property \" \\\n\t\t\t\t     \"name=property,type=CephString\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"get malloc extension heap property\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"dump_objectstore_kv_stats\",\n\t\t\t\t     \"dump_objectstore_kv_stats\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"print statistics of kvdb which used by bluestore\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"dump_scrubs\",\n\t\t\t\t     \"dump_scrubs\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"print scheduled scrubs\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"calc_objectstore_db_histogram\",\n                                     \"calc_objectstore_db_histogram\",\n                                     asok_hook,\n                                     \"Generate key value histogram of kvdb(rocksdb) which used by bluestore\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"flush_store_cache\",\n                                     \"flush_store_cache\",\n                                     asok_hook,\n                                     \"Flush bluestore internal cache\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_pgstate_history\", \"dump_pgstate_history\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show recent state history\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"compact\", \"compact\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Commpact object store's omap.\"\n                                     \" WARNING: Compaction probably slows your requests\");\n  assert(r == 0);\n\n  test_ops_hook = new TestOpsSocketHook(&(this->service), this->store);\n  // Note: pools are CephString instead of CephPoolname because\n  // these commands traditionally support both pool names and numbers\n  r = admin_socket->register_command(\n   \"setomapval\",\n   \"setomapval \" \\\n   \"name=pool,type=CephString \" \\\n   \"name=objname,type=CephObjectname \" \\\n   \"name=key,type=CephString \"\\\n   \"name=val,type=CephString\",\n   test_ops_hook,\n   \"set omap key\");\n  assert(r == 0);\n  r = admin_socket->register_command(\n    \"rmomapkey\",\n    \"rmomapkey \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname \" \\\n    \"name=key,type=CephString\",\n    test_ops_hook,\n    \"remove omap key\");\n  assert(r == 0);\n  r = admin_socket->register_command(\n    \"setomapheader\",\n    \"setomapheader \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname \" \\\n    \"name=header,type=CephString\",\n    test_ops_hook,\n    \"set omap header\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\n    \"getomap\",\n    \"getomap \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname\",\n    test_ops_hook,\n    \"output entire object map\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\n    \"truncobj\",\n    \"truncobj \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname \" \\\n    \"name=len,type=CephInt\",\n    test_ops_hook,\n    \"truncate object to length\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\n    \"injectdataerr\",\n    \"injectdataerr \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname \" \\\n    \"name=shardid,type=CephInt,req=false,range=0|255\",\n    test_ops_hook,\n    \"inject data error to an object\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\n    \"injectmdataerr\",\n    \"injectmdataerr \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname \" \\\n    \"name=shardid,type=CephInt,req=false,range=0|255\",\n    test_ops_hook,\n    \"inject metadata error to an object\");\n  assert(r == 0);\n  r = admin_socket->register_command(\n    \"set_recovery_delay\",\n    \"set_recovery_delay \" \\\n    \"name=utime,type=CephInt,req=false\",\n    test_ops_hook,\n     \"Delay osd recovery by specified seconds\");\n  assert(r == 0);\n  r = admin_socket->register_command(\n   \"trigger_scrub\",\n   \"trigger_scrub \" \\\n   \"name=pgid,type=CephString \",\n   test_ops_hook,\n   \"Trigger a scheduled scrub \");\n  assert(r == 0);\n  r = admin_socket->register_command(\n   \"injectfull\",\n   \"injectfull \" \\\n   \"name=type,type=CephString,req=false \" \\\n   \"name=count,type=CephInt,req=false \",\n   test_ops_hook,\n   \"Inject a full disk (optional count times)\");\n  assert(r == 0);\n}\n\nvoid OSD::create_logger()\n{\n  dout(10) << \"create_logger\" << dendl;\n\n  PerfCountersBuilder osd_plb(cct, \"osd\", l_osd_first, l_osd_last);\n\n  // Latency axis configuration for op histograms, values are in nanoseconds\n  PerfHistogramCommon::axis_config_d op_hist_x_axis_config{\n    \"Latency (usec)\",\n    PerfHistogramCommon::SCALE_LOG2, ///< Latency in logarithmic scale\n    0,                               ///< Start at 0\n    100000,                          ///< Quantization unit is 100usec\n    32,                              ///< Enough to cover much longer than slow requests\n  };\n\n  // Op size axis configuration for op histograms, values are in bytes\n  PerfHistogramCommon::axis_config_d op_hist_y_axis_config{\n    \"Request size (bytes)\",\n    PerfHistogramCommon::SCALE_LOG2, ///< Request size in logarithmic scale\n    0,                               ///< Start at 0\n    512,                             ///< Quantization unit is 512 bytes\n    32,                              ///< Enough to cover requests larger than GB\n  };\n\n\n  // All the basic OSD operation stats are to be considered useful\n  osd_plb.set_prio_default(PerfCountersBuilder::PRIO_USEFUL);\n\n  osd_plb.add_u64(\n    l_osd_op_wip, \"op_wip\",\n    \"Replication operations currently being processed (primary)\");\n  osd_plb.add_u64_counter(\n    l_osd_op, \"op\",\n    \"Client operations\",\n    \"ops\", PerfCountersBuilder::PRIO_CRITICAL);\n  osd_plb.add_u64_counter(\n    l_osd_op_inb,   \"op_in_bytes\",\n    \"Client operations total write size\",\n    \"wr\", PerfCountersBuilder::PRIO_INTERESTING);\n  osd_plb.add_u64_counter(\n    l_osd_op_outb,  \"op_out_bytes\",\n    \"Client operations total read size\",\n    \"rd\", PerfCountersBuilder::PRIO_INTERESTING);\n  osd_plb.add_time_avg(\n    l_osd_op_lat,   \"op_latency\",\n    \"Latency of client operations (including queue time)\",\n    \"l\", 9);\n  osd_plb.add_time_avg(\n    l_osd_op_process_lat, \"op_process_latency\",\n    \"Latency of client operations (excluding queue time)\");\n  osd_plb.add_time_avg(\n    l_osd_op_prepare_lat, \"op_prepare_latency\",\n    \"Latency of client operations (excluding queue time and wait for finished)\");\n\n  osd_plb.add_u64_counter(\n    l_osd_op_r, \"op_r\", \"Client read operations\");\n  osd_plb.add_u64_counter(\n    l_osd_op_r_outb, \"op_r_out_bytes\", \"Client data read\");\n  osd_plb.add_time_avg(\n    l_osd_op_r_lat, \"op_r_latency\",\n    \"Latency of read operation (including queue time)\");\n  osd_plb.add_u64_counter_histogram(\n    l_osd_op_r_lat_outb_hist, \"op_r_latency_out_bytes_histogram\",\n    op_hist_x_axis_config, op_hist_y_axis_config,\n    \"Histogram of operation latency (including queue time) + data read\");\n  osd_plb.add_time_avg(\n    l_osd_op_r_process_lat, \"op_r_process_latency\",\n    \"Latency of read operation (excluding queue time)\");\n  osd_plb.add_time_avg(\n    l_osd_op_r_prepare_lat, \"op_r_prepare_latency\",\n    \"Latency of read operations (excluding queue time and wait for finished)\");\n  osd_plb.add_u64_counter(\n    l_osd_op_w, \"op_w\", \"Client write operations\");\n  osd_plb.add_u64_counter(\n    l_osd_op_w_inb, \"op_w_in_bytes\", \"Client data written\");\n  osd_plb.add_time_avg(\n    l_osd_op_w_lat,  \"op_w_latency\",\n    \"Latency of write operation (including queue time)\");\n  osd_plb.add_u64_counter_histogram(\n    l_osd_op_w_lat_inb_hist, \"op_w_latency_in_bytes_histogram\",\n    op_hist_x_axis_config, op_hist_y_axis_config,\n    \"Histogram of operation latency (including queue time) + data written\");\n  osd_plb.add_time_avg(\n    l_osd_op_w_process_lat, \"op_w_process_latency\",\n    \"Latency of write operation (excluding queue time)\");\n  osd_plb.add_time_avg(\n    l_osd_op_w_prepare_lat, \"op_w_prepare_latency\",\n    \"Latency of write operations (excluding queue time and wait for finished)\");\n  osd_plb.add_u64_counter(\n    l_osd_op_rw, \"op_rw\",\n    \"Client read-modify-write operations\");\n  osd_plb.add_u64_counter(\n    l_osd_op_rw_inb, \"op_rw_in_bytes\",\n    \"Client read-modify-write operations write in\");\n  osd_plb.add_u64_counter(\n    l_osd_op_rw_outb,\"op_rw_out_bytes\",\n    \"Client read-modify-write operations read out \");\n  osd_plb.add_time_avg(\n    l_osd_op_rw_lat, \"op_rw_latency\",\n    \"Latency of read-modify-write operation (including queue time)\");\n  osd_plb.add_u64_counter_histogram(\n    l_osd_op_rw_lat_inb_hist, \"op_rw_latency_in_bytes_histogram\",\n    op_hist_x_axis_config, op_hist_y_axis_config,\n    \"Histogram of rw operation latency (including queue time) + data written\");\n  osd_plb.add_u64_counter_histogram(\n    l_osd_op_rw_lat_outb_hist, \"op_rw_latency_out_bytes_histogram\",\n    op_hist_x_axis_config, op_hist_y_axis_config,\n    \"Histogram of rw operation latency (including queue time) + data read\");\n  osd_plb.add_time_avg(\n    l_osd_op_rw_process_lat, \"op_rw_process_latency\",\n    \"Latency of read-modify-write operation (excluding queue time)\");\n  osd_plb.add_time_avg(\n    l_osd_op_rw_prepare_lat, \"op_rw_prepare_latency\",\n    \"Latency of read-modify-write operations (excluding queue time and wait for finished)\");\n\n  // Now we move on to some more obscure stats, revert to assuming things\n  // are low priority unless otherwise specified.\n  osd_plb.set_prio_default(PerfCountersBuilder::PRIO_DEBUGONLY);\n\n  osd_plb.add_time_avg(l_osd_op_before_queue_op_lat, \"op_before_queue_op_lat\",\n    \"Latency of IO before calling queue(before really queue into ShardedOpWq)\"); // client io before queue op_wq latency\n  osd_plb.add_time_avg(l_osd_op_before_dequeue_op_lat, \"op_before_dequeue_op_lat\",\n    \"Latency of IO before calling dequeue_op(already dequeued and get PG lock)\"); // client io before dequeue_op latency\n\n  osd_plb.add_u64_counter(\n    l_osd_sop, \"subop\", \"Suboperations\");\n  osd_plb.add_u64_counter(\n    l_osd_sop_inb, \"subop_in_bytes\", \"Suboperations total size\");\n  osd_plb.add_time_avg(l_osd_sop_lat, \"subop_latency\", \"Suboperations latency\");\n\n  osd_plb.add_u64_counter(l_osd_sop_w, \"subop_w\", \"Replicated writes\");\n  osd_plb.add_u64_counter(\n    l_osd_sop_w_inb, \"subop_w_in_bytes\", \"Replicated written data size\");\n  osd_plb.add_time_avg(\n    l_osd_sop_w_lat, \"subop_w_latency\", \"Replicated writes latency\");\n  osd_plb.add_u64_counter(\n    l_osd_sop_pull, \"subop_pull\", \"Suboperations pull requests\");\n  osd_plb.add_time_avg(\n    l_osd_sop_pull_lat, \"subop_pull_latency\", \"Suboperations pull latency\");\n  osd_plb.add_u64_counter(\n    l_osd_sop_push, \"subop_push\", \"Suboperations push messages\");\n  osd_plb.add_u64_counter(\n    l_osd_sop_push_inb, \"subop_push_in_bytes\", \"Suboperations pushed size\");\n  osd_plb.add_time_avg(\n    l_osd_sop_push_lat, \"subop_push_latency\", \"Suboperations push latency\");\n\n  osd_plb.add_u64_counter(l_osd_pull, \"pull\", \"Pull requests sent\");\n  osd_plb.add_u64_counter(l_osd_push, \"push\", \"Push messages sent\");\n  osd_plb.add_u64_counter(l_osd_push_outb, \"push_out_bytes\", \"Pushed size\");\n\n  osd_plb.add_u64_counter(\n    l_osd_rop, \"recovery_ops\",\n    \"Started recovery operations\",\n    \"rop\", PerfCountersBuilder::PRIO_INTERESTING);\n\n  osd_plb.add_u64(l_osd_loadavg, \"loadavg\", \"CPU load\");\n  osd_plb.add_u64(l_osd_buf, \"buffer_bytes\", \"Total allocated buffer size\");\n  osd_plb.add_u64(l_osd_history_alloc_bytes, \"history_alloc_Mbytes\");\n  osd_plb.add_u64(l_osd_history_alloc_num, \"history_alloc_num\");\n  osd_plb.add_u64(\n    l_osd_cached_crc, \"cached_crc\", \"Total number getting crc from crc_cache\");\n  osd_plb.add_u64(\n    l_osd_cached_crc_adjusted, \"cached_crc_adjusted\",\n    \"Total number getting crc from crc_cache with adjusting\");\n  osd_plb.add_u64(l_osd_missed_crc, \"missed_crc\", \n    \"Total number of crc cache misses\");\n\n  osd_plb.add_u64(l_osd_pg, \"numpg\", \"Placement groups\",\n\t\t  \"pgs\", PerfCountersBuilder::PRIO_USEFUL);\n  osd_plb.add_u64(\n    l_osd_pg_primary, \"numpg_primary\",\n    \"Placement groups for which this osd is primary\");\n  osd_plb.add_u64(\n    l_osd_pg_replica, \"numpg_replica\",\n    \"Placement groups for which this osd is replica\");\n  osd_plb.add_u64(\n    l_osd_pg_stray, \"numpg_stray\",\n    \"Placement groups ready to be deleted from this osd\");\n  osd_plb.add_u64(\n    l_osd_pg_removing, \"numpg_removing\",\n    \"Placement groups queued for local deletion\", \"pgsr\",\n    PerfCountersBuilder::PRIO_USEFUL);\n  osd_plb.add_u64(\n    l_osd_hb_to, \"heartbeat_to_peers\", \"Heartbeat (ping) peers we send to\");\n  osd_plb.add_u64_counter(l_osd_map, \"map_messages\", \"OSD map messages\");\n  osd_plb.add_u64_counter(l_osd_mape, \"map_message_epochs\", \"OSD map epochs\");\n  osd_plb.add_u64_counter(\n    l_osd_mape_dup, \"map_message_epoch_dups\", \"OSD map duplicates\");\n  osd_plb.add_u64_counter(\n    l_osd_waiting_for_map, \"messages_delayed_for_map\",\n    \"Operations waiting for OSD map\");\n\n  osd_plb.add_u64_counter(\n    l_osd_map_cache_hit, \"osd_map_cache_hit\", \"osdmap cache hit\");\n  osd_plb.add_u64_counter(\n    l_osd_map_cache_miss, \"osd_map_cache_miss\", \"osdmap cache miss\");\n  osd_plb.add_u64_counter(\n    l_osd_map_cache_miss_low, \"osd_map_cache_miss_low\",\n    \"osdmap cache miss below cache lower bound\");\n  osd_plb.add_u64_avg(\n    l_osd_map_cache_miss_low_avg, \"osd_map_cache_miss_low_avg\",\n    \"osdmap cache miss, avg distance below cache lower bound\");\n  osd_plb.add_u64_counter(\n    l_osd_map_bl_cache_hit, \"osd_map_bl_cache_hit\",\n    \"OSDMap buffer cache hits\");\n  osd_plb.add_u64_counter(\n    l_osd_map_bl_cache_miss, \"osd_map_bl_cache_miss\",\n    \"OSDMap buffer cache misses\");\n\n  osd_plb.add_u64(\n    l_osd_stat_bytes, \"stat_bytes\", \"OSD size\", \"size\",\n    PerfCountersBuilder::PRIO_USEFUL);\n  osd_plb.add_u64(\n    l_osd_stat_bytes_used, \"stat_bytes_used\", \"Used space\", \"used\",\n    PerfCountersBuilder::PRIO_USEFUL);\n  osd_plb.add_u64(l_osd_stat_bytes_avail, \"stat_bytes_avail\", \"Available space\");\n\n  osd_plb.add_u64_counter(\n    l_osd_copyfrom, \"copyfrom\", \"Rados \\\"copy-from\\\" operations\");\n\n  osd_plb.add_u64_counter(l_osd_tier_promote, \"tier_promote\", \"Tier promotions\");\n  osd_plb.add_u64_counter(l_osd_tier_flush, \"tier_flush\", \"Tier flushes\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_flush_fail, \"tier_flush_fail\", \"Failed tier flushes\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_try_flush, \"tier_try_flush\", \"Tier flush attempts\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_try_flush_fail, \"tier_try_flush_fail\",\n    \"Failed tier flush attempts\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_evict, \"tier_evict\", \"Tier evictions\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_whiteout, \"tier_whiteout\", \"Tier whiteouts\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_dirty, \"tier_dirty\", \"Dirty tier flag set\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_clean, \"tier_clean\", \"Dirty tier flag cleaned\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_delay, \"tier_delay\", \"Tier delays (agent waiting)\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_proxy_read, \"tier_proxy_read\", \"Tier proxy reads\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_proxy_write, \"tier_proxy_write\", \"Tier proxy writes\");\n\n  osd_plb.add_u64_counter(\n    l_osd_agent_wake, \"agent_wake\", \"Tiering agent wake up\");\n  osd_plb.add_u64_counter(\n    l_osd_agent_skip, \"agent_skip\", \"Objects skipped by agent\");\n  osd_plb.add_u64_counter(\n    l_osd_agent_flush, \"agent_flush\", \"Tiering agent flushes\");\n  osd_plb.add_u64_counter(\n    l_osd_agent_evict, \"agent_evict\", \"Tiering agent evictions\");\n\n  osd_plb.add_u64_counter(\n    l_osd_object_ctx_cache_hit, \"object_ctx_cache_hit\", \"Object context cache hits\");\n  osd_plb.add_u64_counter(\n    l_osd_object_ctx_cache_total, \"object_ctx_cache_total\", \"Object context cache lookups\");\n\n  osd_plb.add_u64_counter(l_osd_op_cache_hit, \"op_cache_hit\");\n  osd_plb.add_time_avg(\n    l_osd_tier_flush_lat, \"osd_tier_flush_lat\", \"Object flush latency\");\n  osd_plb.add_time_avg(\n    l_osd_tier_promote_lat, \"osd_tier_promote_lat\", \"Object promote latency\");\n  osd_plb.add_time_avg(\n    l_osd_tier_r_lat, \"osd_tier_r_lat\", \"Object proxy read latency\");\n\n  osd_plb.add_u64_counter(\n    l_osd_pg_info, \"osd_pg_info\", \"PG updated its info (using any method)\");\n  osd_plb.add_u64_counter(\n    l_osd_pg_fastinfo, \"osd_pg_fastinfo\",\n    \"PG updated its info using fastinfo attr\");\n  osd_plb.add_u64_counter(\n    l_osd_pg_biginfo, \"osd_pg_biginfo\", \"PG updated its biginfo attr\");\n\n  logger = osd_plb.create_perf_counters();\n  cct->get_perfcounters_collection()->add(logger);\n}\n\nvoid OSD::create_recoverystate_perf()\n{\n  dout(10) << \"create_recoverystate_perf\" << dendl;\n\n  PerfCountersBuilder rs_perf(cct, \"recoverystate_perf\", rs_first, rs_last);\n\n  rs_perf.add_time_avg(rs_initial_latency, \"initial_latency\", \"Initial recovery state latency\");\n  rs_perf.add_time_avg(rs_started_latency, \"started_latency\", \"Started recovery state latency\");\n  rs_perf.add_time_avg(rs_reset_latency, \"reset_latency\", \"Reset recovery state latency\");\n  rs_perf.add_time_avg(rs_start_latency, \"start_latency\", \"Start recovery state latency\");\n  rs_perf.add_time_avg(rs_primary_latency, \"primary_latency\", \"Primary recovery state latency\");\n  rs_perf.add_time_avg(rs_peering_latency, \"peering_latency\", \"Peering recovery state latency\");\n  rs_perf.add_time_avg(rs_backfilling_latency, \"backfilling_latency\", \"Backfilling recovery state latency\");\n  rs_perf.add_time_avg(rs_waitremotebackfillreserved_latency, \"waitremotebackfillreserved_latency\", \"Wait remote backfill reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_waitlocalbackfillreserved_latency, \"waitlocalbackfillreserved_latency\", \"Wait local backfill reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_notbackfilling_latency, \"notbackfilling_latency\", \"Notbackfilling recovery state latency\");\n  rs_perf.add_time_avg(rs_repnotrecovering_latency, \"repnotrecovering_latency\", \"Repnotrecovering recovery state latency\");\n  rs_perf.add_time_avg(rs_repwaitrecoveryreserved_latency, \"repwaitrecoveryreserved_latency\", \"Rep wait recovery reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_repwaitbackfillreserved_latency, \"repwaitbackfillreserved_latency\", \"Rep wait backfill reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_reprecovering_latency, \"reprecovering_latency\", \"RepRecovering recovery state latency\");\n  rs_perf.add_time_avg(rs_activating_latency, \"activating_latency\", \"Activating recovery state latency\");\n  rs_perf.add_time_avg(rs_waitlocalrecoveryreserved_latency, \"waitlocalrecoveryreserved_latency\", \"Wait local recovery reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_waitremoterecoveryreserved_latency, \"waitremoterecoveryreserved_latency\", \"Wait remote recovery reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_recovering_latency, \"recovering_latency\", \"Recovering recovery state latency\");\n  rs_perf.add_time_avg(rs_recovered_latency, \"recovered_latency\", \"Recovered recovery state latency\");\n  rs_perf.add_time_avg(rs_clean_latency, \"clean_latency\", \"Clean recovery state latency\");\n  rs_perf.add_time_avg(rs_active_latency, \"active_latency\", \"Active recovery state latency\");\n  rs_perf.add_time_avg(rs_replicaactive_latency, \"replicaactive_latency\", \"Replicaactive recovery state latency\");\n  rs_perf.add_time_avg(rs_stray_latency, \"stray_latency\", \"Stray recovery state latency\");\n  rs_perf.add_time_avg(rs_getinfo_latency, \"getinfo_latency\", \"Getinfo recovery state latency\");\n  rs_perf.add_time_avg(rs_getlog_latency, \"getlog_latency\", \"Getlog recovery state latency\");\n  rs_perf.add_time_avg(rs_waitactingchange_latency, \"waitactingchange_latency\", \"Waitactingchange recovery state latency\");\n  rs_perf.add_time_avg(rs_incomplete_latency, \"incomplete_latency\", \"Incomplete recovery state latency\");\n  rs_perf.add_time_avg(rs_down_latency, \"down_latency\", \"Down recovery state latency\");\n  rs_perf.add_time_avg(rs_getmissing_latency, \"getmissing_latency\", \"Getmissing recovery state latency\");\n  rs_perf.add_time_avg(rs_waitupthru_latency, \"waitupthru_latency\", \"Waitupthru recovery state latency\");\n  rs_perf.add_time_avg(rs_notrecovering_latency, \"notrecovering_latency\", \"Notrecovering recovery state latency\");\n\n  recoverystate_perf = rs_perf.create_perf_counters();\n  cct->get_perfcounters_collection()->add(recoverystate_perf);\n}\n\nint OSD::shutdown()\n{\n  if (!service.prepare_to_stop())\n    return 0; // already shutting down\n  osd_lock.Lock();\n  if (is_stopping()) {\n    osd_lock.Unlock();\n    return 0;\n  }\n  derr << \"shutdown\" << dendl;\n\n  set_state(STATE_STOPPING);\n\n  // Debugging\n  if (cct->_conf->get_val<bool>(\"osd_debug_shutdown\")) {\n    cct->_conf->set_val(\"debug_osd\", \"100\");\n    cct->_conf->set_val(\"debug_journal\", \"100\");\n    cct->_conf->set_val(\"debug_filestore\", \"100\");\n    cct->_conf->set_val(\"debug_bluestore\", \"100\");\n    cct->_conf->set_val(\"debug_ms\", \"100\");\n    cct->_conf->apply_changes(NULL);\n  }\n\n  // stop MgrClient earlier as it's more like an internal consumer of OSD\n  mgrc.shutdown();\n\n  service.start_shutdown();\n\n  // stop sending work to pgs.  this just prevents any new work in _process\n  // from racing with on_shutdown and potentially entering the pg after.\n  op_shardedwq.drain();\n\n  // Shutdown PGs\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t, PG*>::iterator p = pg_map.begin();\n        p != pg_map.end();\n        ++p) {\n      dout(20) << \" kicking pg \" << p->first << dendl;\n      p->second->lock();\n      p->second->on_shutdown();\n      p->second->unlock();\n      p->second->osr->flush();\n    }\n  }\n  clear_pg_stat_queue();\n\n  // drain op queue again (in case PGs requeued something)\n  op_shardedwq.drain();\n  {\n    finished.clear(); // zap waiters (bleh, this is messy)\n  }\n\n  op_shardedwq.clear_pg_slots();\n\n  // unregister commands\n  cct->get_admin_socket()->unregister_command(\"status\");\n  cct->get_admin_socket()->unregister_command(\"flush_journal\");\n  cct->get_admin_socket()->unregister_command(\"dump_ops_in_flight\");\n  cct->get_admin_socket()->unregister_command(\"ops\");\n  cct->get_admin_socket()->unregister_command(\"dump_blocked_ops\");\n  cct->get_admin_socket()->unregister_command(\"dump_historic_ops\");\n  cct->get_admin_socket()->unregister_command(\"dump_historic_ops_by_duration\");\n  cct->get_admin_socket()->unregister_command(\"dump_historic_slow_ops\");\n  cct->get_admin_socket()->unregister_command(\"dump_op_pq_state\");\n  cct->get_admin_socket()->unregister_command(\"dump_blacklist\");\n  cct->get_admin_socket()->unregister_command(\"dump_watchers\");\n  cct->get_admin_socket()->unregister_command(\"dump_reservations\");\n  cct->get_admin_socket()->unregister_command(\"get_latest_osdmap\");\n  cct->get_admin_socket()->unregister_command(\"heap\");\n  cct->get_admin_socket()->unregister_command(\"set_heap_property\");\n  cct->get_admin_socket()->unregister_command(\"get_heap_property\");\n  cct->get_admin_socket()->unregister_command(\"dump_objectstore_kv_stats\");\n  cct->get_admin_socket()->unregister_command(\"dump_scrubs\");\n  cct->get_admin_socket()->unregister_command(\"calc_objectstore_db_histogram\");\n  cct->get_admin_socket()->unregister_command(\"flush_store_cache\");\n  cct->get_admin_socket()->unregister_command(\"dump_pgstate_history\");\n  cct->get_admin_socket()->unregister_command(\"compact\");\n  delete asok_hook;\n  asok_hook = NULL;\n\n  cct->get_admin_socket()->unregister_command(\"setomapval\");\n  cct->get_admin_socket()->unregister_command(\"rmomapkey\");\n  cct->get_admin_socket()->unregister_command(\"setomapheader\");\n  cct->get_admin_socket()->unregister_command(\"getomap\");\n  cct->get_admin_socket()->unregister_command(\"truncobj\");\n  cct->get_admin_socket()->unregister_command(\"injectdataerr\");\n  cct->get_admin_socket()->unregister_command(\"injectmdataerr\");\n  cct->get_admin_socket()->unregister_command(\"set_recovery_delay\");\n  cct->get_admin_socket()->unregister_command(\"trigger_scrub\");\n  cct->get_admin_socket()->unregister_command(\"injectfull\");\n  delete test_ops_hook;\n  test_ops_hook = NULL;\n\n  osd_lock.Unlock();\n\n  heartbeat_lock.Lock();\n  heartbeat_stop = true;\n  heartbeat_cond.Signal();\n  heartbeat_lock.Unlock();\n  heartbeat_thread.join();\n\n  peering_tp.drain();\n  peering_wq.clear();\n  peering_tp.stop();\n  dout(10) << \"osd tp stopped\" << dendl;\n\n  osd_op_tp.drain();\n  osd_op_tp.stop();\n  dout(10) << \"op sharded tp stopped\" << dendl;\n\n  command_tp.drain();\n  command_tp.stop();\n  dout(10) << \"command tp stopped\" << dendl;\n\n  disk_tp.drain();\n  disk_tp.stop();\n  dout(10) << \"disk tp paused (new)\" << dendl;\n\n  dout(10) << \"stopping agent\" << dendl;\n  service.agent_stop();\n\n  osd_lock.Lock();\n\n  reset_heartbeat_peers();\n\n  tick_timer.shutdown();\n\n  {\n    Mutex::Locker l(tick_timer_lock);\n    tick_timer_without_osd_lock.shutdown();\n  }\n\n  // note unmount epoch\n  dout(10) << \"noting clean unmount in epoch \" << osdmap->get_epoch() << dendl;\n  superblock.mounted = service.get_boot_epoch();\n  superblock.clean_thru = osdmap->get_epoch();\n  ObjectStore::Transaction t;\n  write_superblock(t);\n  int r = store->apply_transaction(service.meta_osr.get(), std::move(t));\n  if (r) {\n    derr << \"OSD::shutdown: error writing superblock: \"\n\t << cpp_strerror(r) << dendl;\n  }\n\n\n  {\n    Mutex::Locker l(pg_stat_queue_lock);\n    assert(pg_stat_queue.empty());\n  }\n\n  service.shutdown_reserver();\n\n  // Remove PGs\n#ifdef PG_DEBUG_REFS\n  service.dump_live_pgids();\n#endif\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t, PG*>::iterator p = pg_map.begin();\n        p != pg_map.end();\n        ++p) {\n      dout(20) << \" kicking pg \" << p->first << dendl;\n      p->second->lock();\n      if (p->second->ref != 1) {\n        derr << \"pgid \" << p->first << \" has ref count of \"\n            << p->second->ref << dendl;\n#ifdef PG_DEBUG_REFS\n\tp->second->dump_live_ids();\n#endif\n\tif (cct->_conf->osd_shutdown_pgref_assert) {\n\t  ceph_abort();\n\t}\n      }\n      p->second->unlock();\n      p->second->put(\"PGMap\");\n    }\n    pg_map.clear();\n  }\n#ifdef PG_DEBUG_REFS\n  service.dump_live_pgids();\n#endif\n  cct->_conf->remove_observer(this);\n\n  dout(10) << \"syncing store\" << dendl;\n  enable_disable_fuse(true);\n\n  if (cct->_conf->osd_journal_flush_on_shutdown) {\n    dout(10) << \"flushing journal\" << dendl;\n    store->flush_journal();\n  }\n\n  store->umount();\n  delete store;\n  store = 0;\n  dout(10) << \"Store synced\" << dendl;\n\n  monc->shutdown();\n  osd_lock.Unlock();\n\n  osdmap = OSDMapRef();\n  service.shutdown();\n  op_tracker.on_shutdown();\n\n  class_handler->shutdown();\n  client_messenger->shutdown();\n  cluster_messenger->shutdown();\n  hb_front_client_messenger->shutdown();\n  hb_back_client_messenger->shutdown();\n  objecter_messenger->shutdown();\n  hb_front_server_messenger->shutdown();\n  hb_back_server_messenger->shutdown();\n\n  peering_wq.clear();\n\n  return r;\n}\n\nint OSD::mon_cmd_maybe_osd_create(string &cmd)\n{\n  bool created = false;\n  while (true) {\n    dout(10) << __func__ << \" cmd: \" << cmd << dendl;\n    vector<string> vcmd{cmd};\n    bufferlist inbl;\n    C_SaferCond w;\n    string outs;\n    monc->start_mon_command(vcmd, inbl, NULL, &outs, &w);\n    int r = w.wait();\n    if (r < 0) {\n      if (r == -ENOENT && !created) {\n\tstring newcmd = \"{\\\"prefix\\\": \\\"osd create\\\", \\\"id\\\": \" + stringify(whoami)\n\t  + \", \\\"uuid\\\": \\\"\" + stringify(superblock.osd_fsid) + \"\\\"}\";\n\tvector<string> vnewcmd{newcmd};\n\tbufferlist inbl;\n\tC_SaferCond w;\n\tstring outs;\n\tmonc->start_mon_command(vnewcmd, inbl, NULL, &outs, &w);\n\tint r = w.wait();\n\tif (r < 0) {\n\t  derr << __func__ << \" fail: osd does not exist and created failed: \"\n\t       << cpp_strerror(r) << dendl;\n\t  return r;\n\t}\n\tcreated = true;\n\tcontinue;\n      }\n      derr << __func__ << \" fail: '\" << outs << \"': \" << cpp_strerror(r) << dendl;\n      return r;\n    }\n    break;\n  }\n\n  return 0;\n}\n\nint OSD::update_crush_location()\n{\n  if (!cct->_conf->osd_crush_update_on_start) {\n    dout(10) << __func__ << \" osd_crush_update_on_start = false\" << dendl;\n    return 0;\n  }\n\n  char weight[32];\n  if (cct->_conf->osd_crush_initial_weight >= 0) {\n    snprintf(weight, sizeof(weight), \"%.4lf\", cct->_conf->osd_crush_initial_weight);\n  } else {\n    struct store_statfs_t st;\n    int r = store->statfs(&st);\n    if (r < 0) {\n      derr << \"statfs: \" << cpp_strerror(r) << dendl;\n      return r;\n    }\n    snprintf(weight, sizeof(weight), \"%.4lf\",\n\t     MAX((double).00001,\n\t\t (double)(st.total) /\n\t\t (double)(1ull << 40 /* TB */)));\n  }\n\n  std::multimap<string,string> loc = cct->crush_location.get_location();\n  dout(10) << __func__ << \" crush location is \" << loc << dendl;\n\n  string cmd =\n    string(\"{\\\"prefix\\\": \\\"osd crush create-or-move\\\", \") +\n    string(\"\\\"id\\\": \") + stringify(whoami) + string(\", \") +\n    string(\"\\\"weight\\\":\") + weight + string(\", \") +\n    string(\"\\\"args\\\": [\");\n  for (multimap<string,string>::iterator p = loc.begin(); p != loc.end(); ++p) {\n    if (p != loc.begin())\n      cmd += \", \";\n    cmd += \"\\\"\" + p->first + \"=\" + p->second + \"\\\"\";\n  }\n  cmd += \"]}\";\n\n  return mon_cmd_maybe_osd_create(cmd);\n}\n\nint OSD::update_crush_device_class()\n{\n  if (!cct->_conf->osd_class_update_on_start) {\n    dout(10) << __func__ << \" osd_class_update_on_start = false\" << dendl;\n    return 0;\n  }\n\n  string device_class;\n  int r = store->read_meta(\"crush_device_class\", &device_class);\n  if (r < 0 || device_class.empty()) {\n    device_class = store->get_default_device_class();\n  }\n\n  if (device_class.empty()) {\n    dout(20) << __func__ << \" no device class stored locally\" << dendl;\n    return 0;\n  }\n\n  string cmd =\n    string(\"{\\\"prefix\\\": \\\"osd crush set-device-class\\\", \") +\n    string(\"\\\"class\\\": \\\"\") + device_class + string(\"\\\", \") +\n    string(\"\\\"ids\\\": [\\\"\") + stringify(whoami) + string(\"\\\"]}\");\n\n  r = mon_cmd_maybe_osd_create(cmd);\n  // the above cmd can fail for various reasons, e.g.:\n  //   (1) we are connecting to a pre-luminous monitor\n  //   (2) user manually specify a class other than\n  //       'ceph-disk prepare --crush-device-class'\n  // simply skip result-checking for now\n  return 0;\n}\n\nvoid OSD::write_superblock(ObjectStore::Transaction& t)\n{\n  dout(10) << \"write_superblock \" << superblock << dendl;\n\n  //hack: at minimum it's using the baseline feature set\n  if (!superblock.compat_features.incompat.contains(CEPH_OSD_FEATURE_INCOMPAT_BASE))\n    superblock.compat_features.incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_BASE);\n\n  bufferlist bl;\n  ::encode(superblock, bl);\n  t.write(coll_t::meta(), OSD_SUPERBLOCK_GOBJECT, 0, bl.length(), bl);\n}\n\nint OSD::read_superblock()\n{\n  bufferlist bl;\n  int r = store->read(coll_t::meta(), OSD_SUPERBLOCK_GOBJECT, 0, 0, bl);\n  if (r < 0)\n    return r;\n\n  bufferlist::iterator p = bl.begin();\n  ::decode(superblock, p);\n\n  dout(10) << \"read_superblock \" << superblock << dendl;\n\n  return 0;\n}\n\nvoid OSD::clear_temp_objects()\n{\n  dout(10) << __func__ << dendl;\n  vector<coll_t> ls;\n  store->list_collections(ls);\n  for (vector<coll_t>::iterator p = ls.begin(); p != ls.end(); ++p) {\n    spg_t pgid;\n    if (!p->is_pg(&pgid))\n      continue;\n\n    // list temp objects\n    dout(20) << \" clearing temps in \" << *p << \" pgid \" << pgid << dendl;\n\n    vector<ghobject_t> temps;\n    ghobject_t next;\n    while (1) {\n      vector<ghobject_t> objects;\n      store->collection_list(*p, next, ghobject_t::get_max(),\n\t\t\t     store->get_ideal_list_max(),\n\t\t\t     &objects, &next);\n      if (objects.empty())\n\tbreak;\n      vector<ghobject_t>::iterator q;\n      for (q = objects.begin(); q != objects.end(); ++q) {\n\t// Hammer set pool for temps to -1, so check for clean-up\n\tif (q->hobj.is_temp() || (q->hobj.pool == -1)) {\n\t  temps.push_back(*q);\n\t} else {\n\t  break;\n\t}\n      }\n      // If we saw a non-temp object and hit the break above we can\n      // break out of the while loop too.\n      if (q != objects.end())\n\tbreak;\n    }\n    if (!temps.empty()) {\n      ObjectStore::Transaction t;\n      int removed = 0;\n      for (vector<ghobject_t>::iterator q = temps.begin(); q != temps.end(); ++q) {\n\tdout(20) << \"  removing \" << *p << \" object \" << *q << dendl;\n\tt.remove(*p, *q);\n        if (++removed > cct->_conf->osd_target_transaction_size) {\n          store->apply_transaction(service.meta_osr.get(), std::move(t));\n          t = ObjectStore::Transaction();\n          removed = 0;\n        }\n      }\n      if (removed) {\n        store->apply_transaction(service.meta_osr.get(), std::move(t));\n      }\n    }\n  }\n}\n\nvoid OSD::recursive_remove_collection(CephContext* cct,\n\t\t\t\t      ObjectStore *store, spg_t pgid,\n\t\t\t\t      coll_t tmp)\n{\n  OSDriver driver(\n    store,\n    coll_t(),\n    make_snapmapper_oid());\n\n  ceph::shared_ptr<ObjectStore::Sequencer> osr (std::make_shared<\n                                      ObjectStore::Sequencer>(\"rm\"));\n  ObjectStore::Transaction t;\n  SnapMapper mapper(cct, &driver, 0, 0, 0, pgid.shard);\n\n  vector<ghobject_t> objects;\n  store->collection_list(tmp, ghobject_t(), ghobject_t::get_max(),\n\t\t\t INT_MAX, &objects, 0);\n  generic_dout(10) << __func__ << \" \" << objects << dendl;\n  // delete them.\n  int removed = 0;\n  for (vector<ghobject_t>::iterator p = objects.begin();\n       p != objects.end();\n       ++p, removed++) {\n    OSDriver::OSTransaction _t(driver.get_transaction(&t));\n    int r = mapper.remove_oid(p->hobj, &_t);\n    if (r != 0 && r != -ENOENT)\n      ceph_abort();\n    t.remove(tmp, *p);\n    if (removed > cct->_conf->osd_target_transaction_size) {\n      int r = store->apply_transaction(osr.get(), std::move(t));\n      assert(r == 0);\n      t = ObjectStore::Transaction();\n      removed = 0;\n    }\n  }\n  t.remove_collection(tmp);\n  int r = store->apply_transaction(osr.get(), std::move(t));\n  assert(r == 0);\n\n  C_SaferCond waiter;\n  if (!osr->flush_commit(&waiter)) {\n    waiter.wait();\n  }\n}\n\n\n// ======================================================\n// PG's\n\nPGPool OSD::_get_pool(int id, OSDMapRef createmap)\n{\n  if (!createmap->have_pg_pool(id)) {\n    dout(5) << __func__ << \": the OSDmap does not contain a PG pool with id = \"\n\t    << id << dendl;\n    ceph_abort();\n  }\n\n  PGPool p = PGPool(cct, createmap, id);\n\n  dout(10) << \"_get_pool \" << p.id << dendl;\n  return p;\n}\n\nPG *OSD::_open_lock_pg(\n  OSDMapRef createmap,\n  spg_t pgid, bool no_lockdep_check)\n{\n  assert(osd_lock.is_locked());\n\n  PG* pg = _make_pg(createmap, pgid);\n  {\n    RWLock::WLocker l(pg_map_lock);\n    pg->lock(no_lockdep_check);\n    pg_map[pgid] = pg;\n    pg->get(\"PGMap\");  // because it's in pg_map\n    service.pg_add_epoch(pg->info.pgid, createmap->get_epoch());\n  }\n  return pg;\n}\n\nPG* OSD::_make_pg(\n  OSDMapRef createmap,\n  spg_t pgid)\n{\n  dout(10) << \"_open_lock_pg \" << pgid << dendl;\n  PGPool pool = _get_pool(pgid.pool(), createmap);\n\n  // create\n  PG *pg;\n  if (createmap->get_pg_type(pgid.pgid) == pg_pool_t::TYPE_REPLICATED ||\n      createmap->get_pg_type(pgid.pgid) == pg_pool_t::TYPE_ERASURE)\n    pg = new PrimaryLogPG(&service, createmap, pool, pgid);\n  else\n    ceph_abort();\n\n  return pg;\n}\n\n\nvoid OSD::add_newly_split_pg(PG *pg, PG::RecoveryCtx *rctx)\n{\n  epoch_t e(service.get_osdmap()->get_epoch());\n  pg->get(\"PGMap\");  // For pg_map\n  pg_map[pg->info.pgid] = pg;\n  service.pg_add_epoch(pg->info.pgid, pg->get_osdmap()->get_epoch());\n\n  dout(10) << \"Adding newly split pg \" << *pg << dendl;\n  pg->handle_loaded(rctx);\n  pg->write_if_dirty(*(rctx->transaction));\n  pg->queue_null(e, e);\n  map<spg_t, list<PG::CephPeeringEvtRef> >::iterator to_wake =\n    peering_wait_for_split.find(pg->info.pgid);\n  if (to_wake != peering_wait_for_split.end()) {\n    for (list<PG::CephPeeringEvtRef>::iterator i =\n\t   to_wake->second.begin();\n\t i != to_wake->second.end();\n\t ++i) {\n      pg->queue_peering_event(*i);\n    }\n    peering_wait_for_split.erase(to_wake);\n  }\n  if (!service.get_osdmap()->have_pg_pool(pg->info.pgid.pool()))\n    _remove_pg(pg);\n}\n\nOSD::res_result OSD::_try_resurrect_pg(\n  OSDMapRef curmap, spg_t pgid, spg_t *resurrected, PGRef *old_pg_state)\n{\n  assert(resurrected);\n  assert(old_pg_state);\n  // find nearest ancestor\n  DeletingStateRef df;\n  spg_t cur(pgid);\n  while (true) {\n    df = service.deleting_pgs.lookup(cur);\n    if (df)\n      break;\n    if (!cur.ps())\n      break;\n    cur = cur.get_parent();\n  }\n  if (!df)\n    return RES_NONE; // good to go\n\n  df->old_pg_state->lock();\n  OSDMapRef create_map = df->old_pg_state->get_osdmap();\n  df->old_pg_state->unlock();\n\n  set<spg_t> children;\n  if (cur == pgid) {\n    if (df->try_stop_deletion()) {\n      dout(10) << __func__ << \": halted deletion on pg \" << pgid << dendl;\n      *resurrected = cur;\n      *old_pg_state = df->old_pg_state;\n      service.deleting_pgs.remove(pgid); // PG is no longer being removed!\n      return RES_SELF;\n    } else {\n      // raced, ensure we don't see DeletingStateRef when we try to\n      // delete this pg\n      service.deleting_pgs.remove(pgid);\n      return RES_NONE;\n    }\n  } else if (cur.is_split(create_map->get_pg_num(cur.pool()),\n\t\t\t  curmap->get_pg_num(cur.pool()),\n\t\t\t  &children) &&\n\t     children.count(pgid)) {\n    if (df->try_stop_deletion()) {\n      dout(10) << __func__ << \": halted deletion on ancestor pg \" << pgid\n\t       << dendl;\n      *resurrected = cur;\n      *old_pg_state = df->old_pg_state;\n      service.deleting_pgs.remove(cur); // PG is no longer being removed!\n      return RES_PARENT;\n    } else {\n      /* this is not a problem, failing to cancel proves that all objects\n       * have been removed, so no hobject_t overlap is possible\n       */\n      return RES_NONE;\n    }\n  }\n  return RES_NONE;\n}\n\nPG *OSD::_create_lock_pg(\n  OSDMapRef createmap,\n  spg_t pgid,\n  bool hold_map_lock,\n  bool backfill,\n  int role,\n  vector<int>& up, int up_primary,\n  vector<int>& acting, int acting_primary,\n  pg_history_t history,\n  const PastIntervals& pi,\n  ObjectStore::Transaction& t)\n{\n  assert(osd_lock.is_locked());\n  dout(20) << \"_create_lock_pg pgid \" << pgid << dendl;\n\n  PG *pg = _open_lock_pg(createmap, pgid, true);\n\n  service.init_splits_between(pgid, pg->get_osdmap(), service.get_osdmap());\n\n  pg->init(\n    role,\n    up,\n    up_primary,\n    acting,\n    acting_primary,\n    history,\n    pi,\n    backfill,\n    &t);\n\n  dout(7) << \"_create_lock_pg \" << *pg << dendl;\n  return pg;\n}\n\nPG *OSD::_lookup_lock_pg(spg_t pgid)\n{\n  RWLock::RLocker l(pg_map_lock);\n\n  auto pg_map_entry = pg_map.find(pgid);\n  if (pg_map_entry == pg_map.end())\n    return nullptr;\n  PG *pg = pg_map_entry->second;\n  pg->lock();\n  return pg;\n}\n\nPG *OSD::lookup_lock_pg(spg_t pgid)\n{\n  return _lookup_lock_pg(pgid);\n}\n\nPG *OSD::_lookup_lock_pg_with_map_lock_held(spg_t pgid)\n{\n  assert(pg_map.count(pgid));\n  PG *pg = pg_map[pgid];\n  pg->lock();\n  return pg;\n}\n\nvoid OSD::load_pgs()\n{\n  assert(osd_lock.is_locked());\n  dout(0) << \"load_pgs\" << dendl;\n  {\n    RWLock::RLocker l(pg_map_lock);\n    assert(pg_map.empty());\n  }\n\n  vector<coll_t> ls;\n  int r = store->list_collections(ls);\n  if (r < 0) {\n    derr << \"failed to list pgs: \" << cpp_strerror(-r) << dendl;\n  }\n\n  bool has_upgraded = false;\n\n  for (vector<coll_t>::iterator it = ls.begin();\n       it != ls.end();\n       ++it) {\n    spg_t pgid;\n    if (it->is_temp(&pgid) ||\n       (it->is_pg(&pgid) && PG::_has_removal_flag(store, pgid))) {\n      dout(10) << \"load_pgs \" << *it << \" clearing temp\" << dendl;\n      recursive_remove_collection(cct, store, pgid, *it);\n      continue;\n    }\n\n    if (!it->is_pg(&pgid)) {\n      dout(10) << \"load_pgs ignoring unrecognized \" << *it << dendl;\n      continue;\n    }\n\n    if (pgid.preferred() >= 0) {\n      dout(10) << __func__ << \": skipping localized PG \" << pgid << dendl;\n      // FIXME: delete it too, eventually\n      continue;\n    }\n\n    dout(10) << \"pgid \" << pgid << \" coll \" << coll_t(pgid) << dendl;\n    bufferlist bl;\n    epoch_t map_epoch = 0;\n    int r = PG::peek_map_epoch(store, pgid, &map_epoch, &bl);\n    if (r < 0) {\n      derr << __func__ << \" unable to peek at \" << pgid << \" metadata, skipping\"\n\t   << dendl;\n      continue;\n    }\n\n    PG *pg = NULL;\n    if (map_epoch > 0) {\n      OSDMapRef pgosdmap = service.try_get_map(map_epoch);\n      if (!pgosdmap) {\n\tif (!osdmap->have_pg_pool(pgid.pool())) {\n\t  derr << __func__ << \": could not find map for epoch \" << map_epoch\n\t       << \" on pg \" << pgid << \", but the pool is not present in the \"\n\t       << \"current map, so this is probably a result of bug 10617.  \"\n\t       << \"Skipping the pg for now, you can use ceph-objectstore-tool \"\n\t       << \"to clean it up later.\" << dendl;\n\t  continue;\n\t} else {\n\t  derr << __func__ << \": have pgid \" << pgid << \" at epoch \"\n\t       << map_epoch << \", but missing map.  Crashing.\"\n\t       << dendl;\n\t  assert(0 == \"Missing map in load_pgs\");\n\t}\n      }\n      pg = _open_lock_pg(pgosdmap, pgid);\n    } else {\n      pg = _open_lock_pg(osdmap, pgid);\n    }\n    // there can be no waiters here, so we don't call wake_pg_waiters\n\n    pg->ch = store->open_collection(pg->coll);\n\n    // read pg state, log\n    pg->read_state(store, bl);\n\n    if (pg->must_upgrade()) {\n      if (!pg->can_upgrade()) {\n\tderr << \"PG needs upgrade, but on-disk data is too old; upgrade to\"\n\t     << \" an older version first.\" << dendl;\n\tassert(0 == \"PG too old to upgrade\");\n      }\n      if (!has_upgraded) {\n\tderr << \"PGs are upgrading\" << dendl;\n\thas_upgraded = true;\n      }\n      dout(10) << \"PG \" << pg->info.pgid\n\t       << \" must upgrade...\" << dendl;\n      pg->upgrade(store);\n    }\n\n    if (pg->dne())  {\n      dout(10) << \"load_pgs \" << *it << \" deleting dne\" << dendl;\n      pg->ch = nullptr;\n      service.pg_remove_epoch(pg->pg_id);\n      pg->unlock();\n      {\n\t// Delete pg\n\tRWLock::WLocker l(pg_map_lock);\n\tauto p = pg_map.find(pg->get_pgid());\n\tassert(p != pg_map.end() && p->second == pg);\n\tdout(20) << __func__ << \" removed pg \" << pg << \" from pg_map\" << dendl;\n\tpg_map.erase(p);\n\tpg->put(\"PGMap\");\n      }\n      recursive_remove_collection(cct, store, pgid, *it);\n      continue;\n    }\n\n    service.init_splits_between(pg->info.pgid, pg->get_osdmap(), osdmap);\n\n    // generate state for PG's current mapping\n    int primary, up_primary;\n    vector<int> acting, up;\n    pg->get_osdmap()->pg_to_up_acting_osds(\n      pgid.pgid, &up, &up_primary, &acting, &primary);\n    pg->init_primary_up_acting(\n      up,\n      acting,\n      up_primary,\n      primary);\n    int role = OSDMap::calc_pg_role(whoami, pg->acting);\n    if (pg->pool.info.is_replicated() || role == pg->pg_whoami.shard)\n      pg->set_role(role);\n    else\n      pg->set_role(-1);\n\n    pg->reg_next_scrub();\n\n    PG::RecoveryCtx rctx(0, 0, 0, 0, 0, 0);\n    pg->handle_loaded(&rctx);\n\n    dout(10) << \"load_pgs loaded \" << *pg << \" \" << pg->pg_log.get_log() << dendl;\n    if (pg->pg_log.is_dirty()) {\n      ObjectStore::Transaction t;\n      pg->write_if_dirty(t);\n      store->apply_transaction(pg->osr.get(), std::move(t));\n    }\n    pg->unlock();\n  }\n  {\n    RWLock::RLocker l(pg_map_lock);\n    dout(0) << \"load_pgs opened \" << pg_map.size() << \" pgs\" << dendl;\n  }\n\n  // clean up old infos object?\n  if (has_upgraded && store->exists(coll_t::meta(), OSD::make_infos_oid())) {\n    dout(1) << __func__ << \" removing legacy infos object\" << dendl;\n    ObjectStore::Transaction t;\n    t.remove(coll_t::meta(), OSD::make_infos_oid());\n    int r = store->apply_transaction(service.meta_osr.get(), std::move(t));\n    if (r != 0) {\n      derr << __func__ << \": apply_transaction returned \"\n\t   << cpp_strerror(r) << dendl;\n      ceph_abort();\n    }\n  }\n\n  build_past_intervals_parallel();\n}\n\n\n/*\n * build past_intervals efficiently on old, degraded, and buried\n * clusters.  this is important for efficiently catching up osds that\n * are way behind on maps to the current cluster state.\n *\n * this is a parallel version of PG::generate_past_intervals().\n * follow the same logic, but do all pgs at the same time so that we\n * can make a single pass across the osdmap history.\n */\nvoid OSD::build_past_intervals_parallel()\n{\n  struct pistate {\n    epoch_t start, end;\n    vector<int> old_acting, old_up;\n    epoch_t same_interval_since;\n    int primary;\n    int up_primary;\n  };\n  map<PG*,pistate> pis;\n\n  // calculate junction of map range\n  epoch_t end_epoch = superblock.oldest_map;\n  epoch_t cur_epoch = superblock.newest_map;\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t, PG*>::iterator i = pg_map.begin();\n        i != pg_map.end();\n        ++i) {\n      PG *pg = i->second;\n\n      // Ignore PGs only partially created (DNE)\n      if (pg->info.dne()) {\n\tcontinue;\n      }\n\n      auto rpib = pg->get_required_past_interval_bounds(\n\tpg->info,\n\tsuperblock.oldest_map);\n      if (rpib.first >= rpib.second && pg->past_intervals.empty()) {\n        if (pg->info.history.same_interval_since == 0) {\n          pg->info.history.same_interval_since = rpib.second;\n\t}\n\tcontinue;\n      } else {\n\tauto apib = pg->past_intervals.get_bounds();\n\tif (apib.second >= rpib.second &&\n\t    apib.first <= rpib.first) {\n\t  if (pg->info.history.same_interval_since == 0) {\n\t    pg->info.history.same_interval_since = rpib.second;\n\t  }\n\t  continue;\n\t}\n      }\n\n      dout(10) << pg->info.pgid << \" needs \" << rpib.first << \"-\"\n\t       << rpib.second << dendl;\n      pistate& p = pis[pg];\n      p.start = rpib.first;\n      p.end = rpib.second;\n      p.same_interval_since = 0;\n\n      if (rpib.first < cur_epoch)\n        cur_epoch = rpib.first;\n      if (rpib.second > end_epoch)\n        end_epoch = rpib.second;\n    }\n  }\n  if (pis.empty()) {\n    dout(10) << __func__ << \" nothing to build\" << dendl;\n    return;\n  }\n\n  dout(1) << __func__ << \" over \" << cur_epoch << \"-\" << end_epoch << dendl;\n  assert(cur_epoch <= end_epoch);\n\n  OSDMapRef cur_map, last_map;\n  for ( ; cur_epoch <= end_epoch; cur_epoch++) {\n    dout(10) << __func__ << \" epoch \" << cur_epoch << dendl;\n    last_map = cur_map;\n    cur_map = get_map(cur_epoch);\n\n    for (map<PG*,pistate>::iterator i = pis.begin(); i != pis.end(); ++i) {\n      PG *pg = i->first;\n      pistate& p = i->second;\n\n      if (cur_epoch < p.start || cur_epoch > p.end)\n\tcontinue;\n\n      vector<int> acting, up;\n      int up_primary;\n      int primary;\n      pg_t pgid = pg->info.pgid.pgid;\n      if (p.same_interval_since && last_map->get_pools().count(pgid.pool()))\n\tpgid = pgid.get_ancestor(last_map->get_pg_num(pgid.pool()));\n      cur_map->pg_to_up_acting_osds(\n\tpgid, &up, &up_primary, &acting, &primary);\n\n      if (p.same_interval_since == 0) {\n\tdout(10) << __func__ << \" epoch \" << cur_epoch << \" pg \" << pg->info.pgid\n\t\t << \" first map, acting \" << acting\n\t\t << \" up \" << up << \", same_interval_since = \" << cur_epoch << dendl;\n\tp.same_interval_since = cur_epoch;\n\tp.old_up = up;\n\tp.old_acting = acting;\n\tp.primary = primary;\n\tp.up_primary = up_primary;\n\tcontinue;\n      }\n      assert(last_map);\n\n      boost::scoped_ptr<IsPGRecoverablePredicate> recoverable(\n        pg->get_is_recoverable_predicate());\n      std::stringstream debug;\n      bool new_interval = PastIntervals::check_new_interval(\n\tp.primary,\n\tprimary,\n\tp.old_acting, acting,\n\tp.up_primary,\n\tup_primary,\n\tp.old_up, up,\n\tp.same_interval_since,\n\tpg->info.history.last_epoch_clean,\n\tcur_map, last_map,\n\tpgid,\n        recoverable.get(),\n\t&pg->past_intervals,\n\t&debug);\n      if (new_interval) {\n\tdout(10) << __func__ << \" epoch \" << cur_epoch << \" pg \" << pg->info.pgid\n\t\t << \" \" << debug.str() << dendl;\n\tp.old_up = up;\n\tp.old_acting = acting;\n\tp.primary = primary;\n\tp.up_primary = up_primary;\n\tp.same_interval_since = cur_epoch;\n      }\n    }\n  }\n\n  // Now that past_intervals have been recomputed let's fix the same_interval_since\n  // if it was cleared by import.\n  for (map<PG*,pistate>::iterator i = pis.begin(); i != pis.end(); ++i) {\n    PG *pg = i->first;\n    pistate& p = i->second;\n\n    if (pg->info.history.same_interval_since == 0) {\n      assert(p.same_interval_since);\n      dout(10) << __func__ << \" fix same_interval_since \" << p.same_interval_since << \" pg \" << *pg << dendl;\n      dout(10) << __func__ << \" past_intervals \" << pg->past_intervals << dendl;\n      // Fix it\n      pg->info.history.same_interval_since = p.same_interval_since;\n    }\n  }\n\n  // write info only at the end.  this is necessary because we check\n  // whether the past_intervals go far enough back or forward in time,\n  // but we don't check for holes.  we could avoid it by discarding\n  // the previous past_intervals and rebuilding from scratch, or we\n  // can just do this and commit all our work at the end.\n  ObjectStore::Transaction t;\n  int num = 0;\n  for (map<PG*,pistate>::iterator i = pis.begin(); i != pis.end(); ++i) {\n    PG *pg = i->first;\n    pg->lock();\n    pg->dirty_big_info = true;\n    pg->dirty_info = true;\n    pg->write_if_dirty(t);\n    pg->unlock();\n\n    // don't let the transaction get too big\n    if (++num >= cct->_conf->osd_target_transaction_size) {\n      store->apply_transaction(service.meta_osr.get(), std::move(t));\n      t = ObjectStore::Transaction();\n      num = 0;\n    }\n  }\n  if (!t.empty())\n    store->apply_transaction(service.meta_osr.get(), std::move(t));\n}\n\n/*\n * look up a pg.  if we have it, great.  if not, consider creating it IF the pg mapping\n * hasn't changed since the given epoch and we are the primary.\n */\nint OSD::handle_pg_peering_evt(\n  spg_t pgid,\n  const pg_history_t& orig_history,\n  const PastIntervals& pi,\n  epoch_t epoch,\n  PG::CephPeeringEvtRef evt)\n{\n  if (service.splitting(pgid)) {\n    peering_wait_for_split[pgid].push_back(evt);\n    return -EEXIST;\n  }\n\n  PG *pg = _lookup_lock_pg(pgid);\n  if (!pg) {\n    // same primary?\n    if (!osdmap->have_pg_pool(pgid.pool()))\n      return -EINVAL;\n    int up_primary, acting_primary;\n    vector<int> up, acting;\n    osdmap->pg_to_up_acting_osds(\n      pgid.pgid, &up, &up_primary, &acting, &acting_primary);\n\n    pg_history_t history = orig_history;\n    bool valid_history = project_pg_history(\n      pgid, history, epoch, up, up_primary, acting, acting_primary);\n\n    if (!valid_history || epoch < history.same_interval_since) {\n      dout(10) << __func__ << pgid << \" acting changed in \"\n\t       << history.same_interval_since << \" (msg from \" << epoch << \")\"\n\t       << dendl;\n      return -EINVAL;\n    }\n\n    if (service.splitting(pgid)) {\n      ceph_abort();\n    }\n\n    const bool is_mon_create =\n      evt->get_event().dynamic_type() == PG::NullEvt::static_type();\n    if (maybe_wait_for_max_pg(pgid, is_mon_create)) {\n      return -EAGAIN;\n    }\n    // do we need to resurrect a deleting pg?\n    spg_t resurrected;\n    PGRef old_pg_state;\n    res_result result = _try_resurrect_pg(\n      service.get_osdmap(),\n      pgid,\n      &resurrected,\n      &old_pg_state);\n\n    PG::RecoveryCtx rctx = create_context();\n    switch (result) {\n    case RES_NONE: {\n      const pg_pool_t* pp = osdmap->get_pg_pool(pgid.pool());\n      if (pp->has_flag(pg_pool_t::FLAG_EC_OVERWRITES) &&\n\t  store->get_type() != \"bluestore\") {\n\tclog->warn() << \"pg \" << pgid\n\t\t     << \" is at risk of silent data corruption: \"\n\t\t     << \"the pool allows ec overwrites but is not stored in \"\n\t\t     << \"bluestore, so deep scrubbing will not detect bitrot\";\n      }\n      PG::_create(*rctx.transaction, pgid, pgid.get_split_bits(pp->get_pg_num()));\n      PG::_init(*rctx.transaction, pgid, pp);\n\n      int role = osdmap->calc_pg_role(whoami, acting, acting.size());\n      if (!pp->is_replicated() && role != pgid.shard)\n\trole = -1;\n\n      pg = _create_lock_pg(\n\tget_map(epoch),\n\tpgid, false, false,\n\trole,\n\tup, up_primary,\n\tacting, acting_primary,\n\thistory, pi,\n\t*rctx.transaction);\n      pg->handle_create(&rctx);\n      pg->write_if_dirty(*rctx.transaction);\n      dispatch_context(rctx, pg, osdmap);\n\n      dout(10) << *pg << \" is new\" << dendl;\n\n      pg->queue_peering_event(evt);\n      wake_pg_waiters(pg);\n      pg->unlock();\n      return 0;\n    }\n    case RES_SELF: {\n      old_pg_state->lock();\n      OSDMapRef old_osd_map = old_pg_state->get_osdmap();\n      int old_role = old_pg_state->role;\n      vector<int> old_up = old_pg_state->up;\n      int old_up_primary = old_pg_state->up_primary.osd;\n      vector<int> old_acting = old_pg_state->acting;\n      int old_primary = old_pg_state->primary.osd;\n      pg_history_t old_history = old_pg_state->info.history;\n      PastIntervals old_past_intervals = old_pg_state->past_intervals;\n      old_pg_state->unlock();\n      pg = _create_lock_pg(\n\told_osd_map,\n\tresurrected,\n\tfalse,\n\ttrue,\n\told_role,\n\told_up,\n\told_up_primary,\n\told_acting,\n\told_primary,\n\told_history,\n\told_past_intervals,\n\t*rctx.transaction);\n      pg->handle_create(&rctx);\n      pg->write_if_dirty(*rctx.transaction);\n      dispatch_context(rctx, pg, osdmap);\n\n      dout(10) << *pg << \" is new (resurrected)\" << dendl;\n\n      pg->queue_peering_event(evt);\n      wake_pg_waiters(pg);\n      pg->unlock();\n      return 0;\n    }\n    case RES_PARENT: {\n      assert(old_pg_state);\n      old_pg_state->lock();\n      OSDMapRef old_osd_map = old_pg_state->get_osdmap();\n      int old_role = old_pg_state->role;\n      vector<int> old_up = old_pg_state->up;\n      int old_up_primary = old_pg_state->up_primary.osd;\n      vector<int> old_acting = old_pg_state->acting;\n      int old_primary = old_pg_state->primary.osd;\n      pg_history_t old_history = old_pg_state->info.history;\n      PastIntervals old_past_intervals = old_pg_state->past_intervals;\n      old_pg_state->unlock();\n      PG *parent = _create_lock_pg(\n\told_osd_map,\n\tresurrected,\n\tfalse,\n\ttrue,\n\told_role,\n\told_up,\n\told_up_primary,\n\told_acting,\n\told_primary,\n\told_history,\n\told_past_intervals,\n\t*rctx.transaction\n\t);\n      parent->handle_create(&rctx);\n      parent->write_if_dirty(*rctx.transaction);\n      dispatch_context(rctx, parent, osdmap);\n\n      dout(10) << *parent << \" is new\" << dendl;\n\n      assert(service.splitting(pgid));\n      peering_wait_for_split[pgid].push_back(evt);\n\n      //parent->queue_peering_event(evt);\n      parent->queue_null(osdmap->get_epoch(), osdmap->get_epoch());\n      wake_pg_waiters(parent);\n      parent->unlock();\n      return 0;\n    }\n    default:\n      assert(0);\n      return 0;\n    }\n  } else {\n    // already had it.  did the mapping change?\n    if (epoch < pg->info.history.same_interval_since) {\n      dout(10) << *pg << __func__ << \" acting changed in \"\n\t       << pg->info.history.same_interval_since\n\t       << \" (msg from \" << epoch << \")\" << dendl;\n    } else {\n      pg->queue_peering_event(evt);\n    }\n    pg->unlock();\n    return -EEXIST;\n  }\n}\n\nbool OSD::maybe_wait_for_max_pg(spg_t pgid, bool is_mon_create)\n{\n  const auto max_pgs_per_osd =\n    (cct->_conf->get_val<uint64_t>(\"mon_max_pg_per_osd\") *\n     cct->_conf->get_val<double>(\"osd_max_pg_per_osd_hard_ratio\"));\n\n  RWLock::RLocker pg_map_locker{pg_map_lock};\n  if (pg_map.size() < max_pgs_per_osd) {\n    return false;\n  }\n  lock_guard<mutex> pending_creates_locker{pending_creates_lock};\n  if (is_mon_create) {\n    pending_creates_from_mon++;\n  } else {\n    bool is_primary = osdmap->get_pg_acting_rank(pgid.pgid, whoami) == 0;\n    pending_creates_from_osd.emplace(pgid.pgid, is_primary);\n  }\n  dout(5) << __func__ << \" withhold creation of pg \" << pgid\n\t  << \": \" << pg_map.size() << \" >= \"<< max_pgs_per_osd << dendl;\n  return true;\n}\n\n// to re-trigger a peering, we have to twiddle the pg mapping a little bit,\n// see PG::should_restart_peering(). OSDMap::pg_to_up_acting_osds() will turn\n// to up set if pg_temp is empty. so an empty pg_temp won't work.\nstatic vector<int32_t> twiddle(const vector<int>& acting) {\n  if (acting.size() > 1) {\n    return {acting[0]};\n  } else {\n    vector<int32_t> twiddled(acting.begin(), acting.end());\n    twiddled.push_back(-1);\n    return twiddled;\n  }\n}\n\nvoid OSD::resume_creating_pg()\n{\n  bool do_sub_pg_creates = false;\n  bool have_pending_creates = false;\n  {\n    const auto max_pgs_per_osd =\n      (cct->_conf->get_val<uint64_t>(\"mon_max_pg_per_osd\") *\n       cct->_conf->get_val<double>(\"osd_max_pg_per_osd_hard_ratio\"));\n    RWLock::RLocker l(pg_map_lock);\n    if (max_pgs_per_osd <= pg_map.size()) {\n      // this could happen if admin decreases this setting before a PG is removed\n      return;\n    }\n    unsigned spare_pgs = max_pgs_per_osd - pg_map.size();\n    lock_guard<mutex> pending_creates_locker{pending_creates_lock};\n    if (pending_creates_from_mon > 0) {\n      do_sub_pg_creates = true;\n      if (pending_creates_from_mon >= spare_pgs) {\n\tspare_pgs = pending_creates_from_mon = 0;\n      } else {\n\tspare_pgs -= pending_creates_from_mon;\n\tpending_creates_from_mon = 0;\n      }\n    }\n    auto pg = pending_creates_from_osd.cbegin();\n    while (spare_pgs > 0 && pg != pending_creates_from_osd.cend()) {\n      dout(20) << __func__ << \" pg \" << pg->first << dendl;\n      vector<int> acting;\n      osdmap->pg_to_up_acting_osds(pg->first, nullptr, nullptr, &acting, nullptr);\n      service.queue_want_pg_temp(pg->first, twiddle(acting), true);\n      pg = pending_creates_from_osd.erase(pg);\n      do_sub_pg_creates = true;\n      spare_pgs--;\n    }\n    have_pending_creates = (pending_creates_from_mon > 0 ||\n\t\t\t    !pending_creates_from_osd.empty());\n  }\n\n  bool do_renew_subs = false;\n  if (do_sub_pg_creates) {\n    if (monc->sub_want(\"osd_pg_creates\", last_pg_create_epoch, 0)) {\n      dout(4) << __func__ << \": resolicit pg creates from mon since \"\n\t      << last_pg_create_epoch << dendl;\n      do_renew_subs = true;\n    }\n  }\n  version_t start = osdmap->get_epoch() + 1;\n  if (have_pending_creates) {\n    // don't miss any new osdmap deleting PGs\n    if (monc->sub_want(\"osdmap\", start, 0)) {\n      dout(4) << __func__ << \": resolicit osdmap from mon since \"\n\t      << start << dendl;\n      do_renew_subs = true;\n    }\n  } else if (do_sub_pg_creates) {\n    // no need to subscribe the osdmap continuously anymore\n    // once the pgtemp and/or mon_subscribe(pg_creates) is sent\n    if (monc->sub_want_increment(\"osdmap\", start, CEPH_SUBSCRIBE_ONETIME)) {\n      dout(4) << __func__ << \": re-subscribe osdmap(onetime) since\"\n\t      << start << dendl;\n      do_renew_subs = true;\n    }\n  }\n\n  if (do_renew_subs) {\n    monc->renew_subs();\n  }\n\n  service.send_pg_temp();\n}\n\nvoid OSD::build_initial_pg_history(\n  spg_t pgid,\n  epoch_t created,\n  utime_t created_stamp,\n  pg_history_t *h,\n  PastIntervals *pi)\n{\n  dout(10) << __func__ << \" \" << pgid << \" created \" << created << dendl;\n  h->epoch_created = created;\n  h->epoch_pool_created = created;\n  h->same_interval_since = created;\n  h->same_up_since = created;\n  h->same_primary_since = created;\n  h->last_scrub_stamp = created_stamp;\n  h->last_deep_scrub_stamp = created_stamp;\n  h->last_clean_scrub_stamp = created_stamp;\n\n  OSDMapRef lastmap = service.get_map(created);\n  int up_primary, acting_primary;\n  vector<int> up, acting;\n  lastmap->pg_to_up_acting_osds(\n    pgid.pgid, &up, &up_primary, &acting, &acting_primary);\n\n  ostringstream debug;\n  for (epoch_t e = created + 1; e <= osdmap->get_epoch(); ++e) {\n    OSDMapRef osdmap = service.get_map(e);\n    int new_up_primary, new_acting_primary;\n    vector<int> new_up, new_acting;\n    osdmap->pg_to_up_acting_osds(\n      pgid.pgid, &new_up, &new_up_primary, &new_acting, &new_acting_primary);\n\n    // this is a bit imprecise, but sufficient?\n    struct min_size_predicate_t : public IsPGRecoverablePredicate {\n      const pg_pool_t *pi;\n      bool operator()(const set<pg_shard_t> &have) const {\n\treturn have.size() >= pi->min_size;\n      }\n      min_size_predicate_t(const pg_pool_t *i) : pi(i) {}\n    } min_size_predicate(osdmap->get_pg_pool(pgid.pgid.pool()));\n\n    bool new_interval = PastIntervals::check_new_interval(\n      acting_primary,\n      new_acting_primary,\n      acting, new_acting,\n      up_primary,\n      new_up_primary,\n      up, new_up,\n      h->same_interval_since,\n      h->last_epoch_clean,\n      osdmap,\n      lastmap,\n      pgid.pgid,\n      &min_size_predicate,\n      pi,\n      &debug);\n    if (new_interval) {\n      h->same_interval_since = e;\n      if (up != new_up) {\n        h->same_up_since = e;\n      }\n      if (acting_primary != new_acting_primary) {\n        h->same_primary_since = e;\n      }\n      if (pgid.pgid.is_split(lastmap->get_pg_num(pgid.pgid.pool()),\n                             osdmap->get_pg_num(pgid.pgid.pool()),\n                             nullptr)) {\n        h->last_epoch_split = e;\n      }\n      up = new_up;\n      acting = new_acting;\n      up_primary = new_up_primary;\n      acting_primary = new_acting_primary;\n    }\n    lastmap = osdmap;\n  }\n  dout(20) << __func__ << \" \" << debug.str() << dendl;\n  dout(10) << __func__ << \" \" << *h << \" \" << *pi\n\t   << \" [\" << (pi->empty() ? pair<epoch_t,epoch_t>(0,0) :\n\t\t       pi->get_bounds()) << \")\"\n\t   << dendl;\n}\n\n/**\n * Fill in the passed history so you know same_interval_since, same_up_since,\n * and same_primary_since.\n */\nbool OSD::project_pg_history(spg_t pgid, pg_history_t& h, epoch_t from,\n\t\t\t     const vector<int>& currentup,\n\t\t\t     int currentupprimary,\n\t\t\t     const vector<int>& currentacting,\n\t\t\t     int currentactingprimary)\n{\n  dout(15) << \"project_pg_history \" << pgid\n           << \" from \" << from << \" to \" << osdmap->get_epoch()\n           << \", start \" << h\n           << dendl;\n\n  epoch_t e;\n  for (e = osdmap->get_epoch();\n       e > from;\n       e--) {\n    // verify during intermediate epoch (e-1)\n    OSDMapRef oldmap = service.try_get_map(e-1);\n    if (!oldmap) {\n      dout(15) << __func__ << \": found map gap, returning false\" << dendl;\n      return false;\n    }\n    assert(oldmap->have_pg_pool(pgid.pool()));\n\n    int upprimary, actingprimary;\n    vector<int> up, acting;\n    oldmap->pg_to_up_acting_osds(\n      pgid.pgid,\n      &up,\n      &upprimary,\n      &acting,\n      &actingprimary);\n\n    // acting set change?\n    if ((actingprimary != currentactingprimary ||\n\t upprimary != currentupprimary ||\n\t acting != currentacting ||\n\t up != currentup) && e > h.same_interval_since) {\n      dout(15) << \"project_pg_history \" << pgid << \" acting|up changed in \" << e\n\t       << \" from \" << acting << \"/\" << up\n\t       << \" \" << actingprimary << \"/\" << upprimary\n\t       << \" -> \" << currentacting << \"/\" << currentup\n\t       << \" \" << currentactingprimary << \"/\" << currentupprimary\n\t       << dendl;\n      h.same_interval_since = e;\n    }\n    // split?\n    if (pgid.is_split(oldmap->get_pg_num(pgid.pool()),\n\t\t      osdmap->get_pg_num(pgid.pool()),\n\t\t      0) && e > h.same_interval_since) {\n      h.same_interval_since = e;\n    }\n    // up set change?\n    if ((up != currentup || upprimary != currentupprimary)\n\t&& e > h.same_up_since) {\n      dout(15) << \"project_pg_history \" << pgid << \" up changed in \" << e\n\t       << \" from \" << up << \" \" << upprimary\n\t       << \" -> \" << currentup << \" \" << currentupprimary << dendl;\n      h.same_up_since = e;\n    }\n\n    // primary change?\n    if (OSDMap::primary_changed(\n\t  actingprimary,\n\t  acting,\n\t  currentactingprimary,\n\t  currentacting) &&\n        e > h.same_primary_since) {\n      dout(15) << \"project_pg_history \" << pgid << \" primary changed in \" << e << dendl;\n      h.same_primary_since = e;\n    }\n\n    if (h.same_interval_since >= e && h.same_up_since >= e && h.same_primary_since >= e)\n      break;\n  }\n\n  // base case: these floors should be the pg creation epoch if we didn't\n  // find any changes.\n  if (e == h.epoch_created) {\n    if (!h.same_interval_since)\n      h.same_interval_since = e;\n    if (!h.same_up_since)\n      h.same_up_since = e;\n    if (!h.same_primary_since)\n      h.same_primary_since = e;\n  }\n\n  dout(15) << \"project_pg_history end \" << h << dendl;\n  return true;\n}\n\n\n\nvoid OSD::_add_heartbeat_peer(int p)\n{\n  if (p == whoami)\n    return;\n  HeartbeatInfo *hi;\n\n  map<int,HeartbeatInfo>::iterator i = heartbeat_peers.find(p);\n  if (i == heartbeat_peers.end()) {\n    pair<ConnectionRef,ConnectionRef> cons = service.get_con_osd_hb(p, osdmap->get_epoch());\n    if (!cons.first)\n      return;\n    hi = &heartbeat_peers[p];\n    hi->peer = p;\n    HeartbeatSession *s = new HeartbeatSession(p);\n    hi->con_back = cons.first.get();\n    hi->con_back->set_priv(s->get());\n    if (cons.second) {\n      hi->con_front = cons.second.get();\n      hi->con_front->set_priv(s->get());\n      dout(10) << \"_add_heartbeat_peer: new peer osd.\" << p\n\t       << \" \" << hi->con_back->get_peer_addr()\n\t       << \" \" << hi->con_front->get_peer_addr()\n\t       << dendl;\n    } else {\n      hi->con_front.reset(NULL);\n      dout(10) << \"_add_heartbeat_peer: new peer osd.\" << p\n\t       << \" \" << hi->con_back->get_peer_addr()\n\t       << dendl;\n    }\n    s->put();\n  } else {\n    hi = &i->second;\n  }\n  hi->epoch = osdmap->get_epoch();\n}\n\nvoid OSD::_remove_heartbeat_peer(int n)\n{\n  map<int,HeartbeatInfo>::iterator q = heartbeat_peers.find(n);\n  assert(q != heartbeat_peers.end());\n  dout(20) << \" removing heartbeat peer osd.\" << n\n\t   << \" \" << q->second.con_back->get_peer_addr()\n\t   << \" \" << (q->second.con_front ? q->second.con_front->get_peer_addr() : entity_addr_t())\n\t   << dendl;\n  q->second.con_back->mark_down();\n  if (q->second.con_front) {\n    q->second.con_front->mark_down();\n  }\n  heartbeat_peers.erase(q);\n}\n\nvoid OSD::need_heartbeat_peer_update()\n{\n  if (is_stopping())\n    return;\n  dout(20) << \"need_heartbeat_peer_update\" << dendl;\n  heartbeat_set_peers_need_update();\n}\n\nvoid OSD::maybe_update_heartbeat_peers()\n{\n  assert(osd_lock.is_locked());\n\n  if (is_waiting_for_healthy()) {\n    utime_t now = ceph_clock_now();\n    if (last_heartbeat_resample == utime_t()) {\n      last_heartbeat_resample = now;\n      heartbeat_set_peers_need_update();\n    } else if (!heartbeat_peers_need_update()) {\n      utime_t dur = now - last_heartbeat_resample;\n      if (dur > cct->_conf->osd_heartbeat_grace) {\n\tdout(10) << \"maybe_update_heartbeat_peers forcing update after \" << dur << \" seconds\" << dendl;\n\theartbeat_set_peers_need_update();\n\tlast_heartbeat_resample = now;\n\treset_heartbeat_peers();   // we want *new* peers!\n      }\n    }\n  }\n\n  if (!heartbeat_peers_need_update())\n    return;\n  heartbeat_clear_peers_need_update();\n\n  Mutex::Locker l(heartbeat_lock);\n\n  dout(10) << \"maybe_update_heartbeat_peers updating\" << dendl;\n\n\n  // build heartbeat from set\n  if (is_active()) {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t, PG*>::iterator i = pg_map.begin();\n\t i != pg_map.end();\n\t ++i) {\n      PG *pg = i->second;\n      pg->heartbeat_peer_lock.Lock();\n      dout(20) << i->first << \" heartbeat_peers \" << pg->heartbeat_peers << dendl;\n      for (set<int>::iterator p = pg->heartbeat_peers.begin();\n\t   p != pg->heartbeat_peers.end();\n\t   ++p)\n\tif (osdmap->is_up(*p))\n\t  _add_heartbeat_peer(*p);\n      for (set<int>::iterator p = pg->probe_targets.begin();\n\t   p != pg->probe_targets.end();\n\t   ++p)\n\tif (osdmap->is_up(*p))\n\t  _add_heartbeat_peer(*p);\n      pg->heartbeat_peer_lock.Unlock();\n    }\n  }\n\n  // include next and previous up osds to ensure we have a fully-connected set\n  set<int> want, extras;\n  int next = osdmap->get_next_up_osd_after(whoami);\n  if (next >= 0)\n    want.insert(next);\n  int prev = osdmap->get_previous_up_osd_before(whoami);\n  if (prev >= 0 && prev != next)\n    want.insert(prev);\n\n  for (set<int>::iterator p = want.begin(); p != want.end(); ++p) {\n    dout(10) << \" adding neighbor peer osd.\" << *p << dendl;\n    extras.insert(*p);\n    _add_heartbeat_peer(*p);\n  }\n\n  // remove down peers; enumerate extras\n  map<int,HeartbeatInfo>::iterator p = heartbeat_peers.begin();\n  while (p != heartbeat_peers.end()) {\n    if (!osdmap->is_up(p->first)) {\n      int o = p->first;\n      ++p;\n      _remove_heartbeat_peer(o);\n      continue;\n    }\n    if (p->second.epoch < osdmap->get_epoch()) {\n      extras.insert(p->first);\n    }\n    ++p;\n  }\n\n  // too few?\n  int start = osdmap->get_next_up_osd_after(whoami);\n  for (int n = start; n >= 0; ) {\n    if ((int)heartbeat_peers.size() >= cct->_conf->osd_heartbeat_min_peers)\n      break;\n    if (!extras.count(n) && !want.count(n) && n != whoami) {\n      dout(10) << \" adding random peer osd.\" << n << dendl;\n      extras.insert(n);\n      _add_heartbeat_peer(n);\n    }\n    n = osdmap->get_next_up_osd_after(n);\n    if (n == start)\n      break;  // came full circle; stop\n  }\n\n  // too many?\n  for (set<int>::iterator p = extras.begin();\n       (int)heartbeat_peers.size() > cct->_conf->osd_heartbeat_min_peers && p != extras.end();\n       ++p) {\n    if (want.count(*p))\n      continue;\n    _remove_heartbeat_peer(*p);\n  }\n\n  dout(10) << \"maybe_update_heartbeat_peers \" << heartbeat_peers.size() << \" peers, extras \" << extras << dendl;\n}\n\nvoid OSD::reset_heartbeat_peers()\n{\n  assert(osd_lock.is_locked());\n  dout(10) << \"reset_heartbeat_peers\" << dendl;\n  Mutex::Locker l(heartbeat_lock);\n  while (!heartbeat_peers.empty()) {\n    HeartbeatInfo& hi = heartbeat_peers.begin()->second;\n    hi.con_back->mark_down();\n    if (hi.con_front) {\n      hi.con_front->mark_down();\n    }\n    heartbeat_peers.erase(heartbeat_peers.begin());\n  }\n  failure_queue.clear();\n}\n\nvoid OSD::handle_osd_ping(MOSDPing *m)\n{\n  if (superblock.cluster_fsid != m->fsid) {\n    dout(20) << \"handle_osd_ping from \" << m->get_source_inst()\n\t     << \" bad fsid \" << m->fsid << \" != \" << superblock.cluster_fsid << dendl;\n    m->put();\n    return;\n  }\n\n  int from = m->get_source().num();\n\n  heartbeat_lock.Lock();\n  if (is_stopping()) {\n    heartbeat_lock.Unlock();\n    m->put();\n    return;\n  }\n\n  OSDMapRef curmap = service.get_osdmap();\n  if (!curmap) {\n    heartbeat_lock.Unlock();\n    m->put();\n    return;\n  }\n\n  switch (m->op) {\n\n  case MOSDPing::PING:\n    {\n      if (cct->_conf->osd_debug_drop_ping_probability > 0) {\n\tauto heartbeat_drop = debug_heartbeat_drops_remaining.find(from);\n\tif (heartbeat_drop != debug_heartbeat_drops_remaining.end()) {\n\t  if (heartbeat_drop->second == 0) {\n\t    debug_heartbeat_drops_remaining.erase(heartbeat_drop);\n\t  } else {\n\t    --heartbeat_drop->second;\n\t    dout(5) << \"Dropping heartbeat from \" << from\n\t\t    << \", \" << heartbeat_drop->second\n\t\t    << \" remaining to drop\" << dendl;\n\t    break;\n\t  }\n\t} else if (cct->_conf->osd_debug_drop_ping_probability >\n\t           ((((double)(rand()%100))/100.0))) {\n\t  heartbeat_drop =\n\t    debug_heartbeat_drops_remaining.insert(std::make_pair(from,\n\t                     cct->_conf->osd_debug_drop_ping_duration)).first;\n\t  dout(5) << \"Dropping heartbeat from \" << from\n\t\t  << \", \" << heartbeat_drop->second\n\t\t  << \" remaining to drop\" << dendl;\n\t  break;\n\t}\n      }\n\n      if (!cct->get_heartbeat_map()->is_healthy()) {\n\tdout(10) << \"internal heartbeat not healthy, dropping ping request\" << dendl;\n\tbreak;\n      }\n\n      Message *r = new MOSDPing(monc->get_fsid(),\n\t\t\t\tcurmap->get_epoch(),\n\t\t\t\tMOSDPing::PING_REPLY, m->stamp,\n\t\t\t\tcct->_conf->osd_heartbeat_min_size);\n      m->get_connection()->send_message(r);\n\n      if (curmap->is_up(from)) {\n\tservice.note_peer_epoch(from, m->map_epoch);\n\tif (is_active()) {\n\t  ConnectionRef con = service.get_con_osd_cluster(from, curmap->get_epoch());\n\t  if (con) {\n\t    service.share_map_peer(from, con.get());\n\t  }\n\t}\n      } else if (!curmap->exists(from) ||\n\t\t curmap->get_down_at(from) > m->map_epoch) {\n\t// tell them they have died\n\tMessage *r = new MOSDPing(monc->get_fsid(),\n\t\t\t\t  curmap->get_epoch(),\n\t\t\t\t  MOSDPing::YOU_DIED,\n\t\t\t\t  m->stamp,\n\t\t\t\t  cct->_conf->osd_heartbeat_min_size);\n\tm->get_connection()->send_message(r);\n      }\n    }\n    break;\n\n  case MOSDPing::PING_REPLY:\n    {\n      map<int,HeartbeatInfo>::iterator i = heartbeat_peers.find(from);\n      if (i != heartbeat_peers.end()) {\n\tif (m->get_connection() == i->second.con_back) {\n\t  dout(25) << \"handle_osd_ping got reply from osd.\" << from\n\t\t   << \" first_tx \" << i->second.first_tx\n\t\t   << \" last_tx \" << i->second.last_tx\n\t\t   << \" last_rx_back \" << i->second.last_rx_back << \" -> \" << m->stamp\n\t\t   << \" last_rx_front \" << i->second.last_rx_front\n\t\t   << dendl;\n\t  i->second.last_rx_back = m->stamp;\n\t  // if there is no front con, set both stamps.\n\t  if (i->second.con_front == NULL)\n\t    i->second.last_rx_front = m->stamp;\n\t} else if (m->get_connection() == i->second.con_front) {\n\t  dout(25) << \"handle_osd_ping got reply from osd.\" << from\n\t\t   << \" first_tx \" << i->second.first_tx\n\t\t   << \" last_tx \" << i->second.last_tx\n\t\t   << \" last_rx_back \" << i->second.last_rx_back\n\t\t   << \" last_rx_front \" << i->second.last_rx_front << \" -> \" << m->stamp\n\t\t   << dendl;\n\t  i->second.last_rx_front = m->stamp;\n\t}\n\n        utime_t cutoff = ceph_clock_now();\n        cutoff -= cct->_conf->osd_heartbeat_grace;\n        if (i->second.is_healthy(cutoff)) {\n          // Cancel false reports\n\t  auto failure_queue_entry = failure_queue.find(from);\n\t  if (failure_queue_entry != failure_queue.end()) {\n            dout(10) << \"handle_osd_ping canceling queued \"\n                     << \"failure report for osd.\" << from << dendl;\n            failure_queue.erase(failure_queue_entry);\n          }\n\n\t  auto failure_pending_entry = failure_pending.find(from);\n\t  if (failure_pending_entry != failure_pending.end()) {\n            dout(10) << \"handle_osd_ping canceling in-flight \"\n                     << \"failure report for osd.\" << from << dendl;\n            send_still_alive(curmap->get_epoch(),\n\t\t\t     failure_pending_entry->second.second);\n            failure_pending.erase(failure_pending_entry);\n          }\n        }\n      }\n\n      if (m->map_epoch &&\n\t  curmap->is_up(from)) {\n\tservice.note_peer_epoch(from, m->map_epoch);\n\tif (is_active()) {\n\t  ConnectionRef con = service.get_con_osd_cluster(from, curmap->get_epoch());\n\t  if (con) {\n\t    service.share_map_peer(from, con.get());\n\t  }\n\t}\n      }\n    }\n    break;\n\n  case MOSDPing::YOU_DIED:\n    dout(10) << \"handle_osd_ping \" << m->get_source_inst()\n\t     << \" says i am down in \" << m->map_epoch << dendl;\n    osdmap_subscribe(curmap->get_epoch()+1, false);\n    break;\n  }\n\n  heartbeat_lock.Unlock();\n  m->put();\n}\n\nvoid OSD::heartbeat_entry()\n{\n  Mutex::Locker l(heartbeat_lock);\n  if (is_stopping())\n    return;\n  while (!heartbeat_stop) {\n    heartbeat();\n\n    double wait = .5 + ((float)(rand() % 10)/10.0) * (float)cct->_conf->osd_heartbeat_interval;\n    utime_t w;\n    w.set_from_double(wait);\n    dout(30) << \"heartbeat_entry sleeping for \" << wait << dendl;\n    heartbeat_cond.WaitInterval(heartbeat_lock, w);\n    if (is_stopping())\n      return;\n    dout(30) << \"heartbeat_entry woke up\" << dendl;\n  }\n}\n\nvoid OSD::heartbeat_check()\n{\n  assert(heartbeat_lock.is_locked());\n  utime_t now = ceph_clock_now();\n\n  // check for heartbeat replies (move me elsewhere?)\n  utime_t cutoff = now;\n  cutoff -= cct->_conf->osd_heartbeat_grace;\n  for (map<int,HeartbeatInfo>::iterator p = heartbeat_peers.begin();\n       p != heartbeat_peers.end();\n       ++p) {\n\n    if (p->second.first_tx == utime_t()) {\n      dout(25) << \"heartbeat_check we haven't sent ping to osd.\" << p->first\n               << \"yet, skipping\" << dendl;\n      continue;\n    }\n\n    dout(25) << \"heartbeat_check osd.\" << p->first\n\t     << \" first_tx \" << p->second.first_tx\n\t     << \" last_tx \" << p->second.last_tx\n\t     << \" last_rx_back \" << p->second.last_rx_back\n\t     << \" last_rx_front \" << p->second.last_rx_front\n\t     << dendl;\n    if (p->second.is_unhealthy(cutoff)) {\n      if (p->second.last_rx_back == utime_t() ||\n\t  p->second.last_rx_front == utime_t()) {\n\tderr << \"heartbeat_check: no reply from \" << p->second.con_front->get_peer_addr().get_sockaddr()\n\t     << \" osd.\" << p->first << \" ever on either front or back, first ping sent \"\n\t     << p->second.first_tx << \" (cutoff \" << cutoff << \")\" << dendl;\n\t// fail\n\tfailure_queue[p->first] = p->second.last_tx;\n      } else {\n\tderr << \"heartbeat_check: no reply from \" << p->second.con_front->get_peer_addr().get_sockaddr()\n\t     << \" osd.\" << p->first << \" since back \" << p->second.last_rx_back\n\t     << \" front \" << p->second.last_rx_front\n\t     << \" (cutoff \" << cutoff << \")\" << dendl;\n\t// fail\n\tfailure_queue[p->first] = MIN(p->second.last_rx_back, p->second.last_rx_front);\n      }\n    }\n  }\n}\n\nvoid OSD::heartbeat()\n{\n  dout(30) << \"heartbeat\" << dendl;\n\n  // get CPU load avg\n  double loadavgs[1];\n  int n_samples = 86400 / cct->_conf->osd_heartbeat_interval;\n  if (getloadavg(loadavgs, 1) == 1) {\n    logger->set(l_osd_loadavg, 100 * loadavgs[0]);\n    daily_loadavg = (daily_loadavg * (n_samples - 1) + loadavgs[0]) / n_samples;\n    dout(30) << \"heartbeat: daily_loadavg \" << daily_loadavg << dendl;\n  }\n\n  dout(30) << \"heartbeat checking stats\" << dendl;\n\n  // refresh stats?\n  vector<int> hb_peers;\n  for (map<int,HeartbeatInfo>::iterator p = heartbeat_peers.begin();\n       p != heartbeat_peers.end();\n       ++p)\n    hb_peers.push_back(p->first);\n  service.update_osd_stat(hb_peers);\n\n  dout(5) << \"heartbeat: \" << service.get_osd_stat() << dendl;\n\n  utime_t now = ceph_clock_now();\n\n  // send heartbeats\n  for (map<int,HeartbeatInfo>::iterator i = heartbeat_peers.begin();\n       i != heartbeat_peers.end();\n       ++i) {\n    int peer = i->first;\n    i->second.last_tx = now;\n    if (i->second.first_tx == utime_t())\n      i->second.first_tx = now;\n    dout(30) << \"heartbeat sending ping to osd.\" << peer << dendl;\n    i->second.con_back->send_message(new MOSDPing(monc->get_fsid(),\n\t\t\t\t\t  service.get_osdmap()->get_epoch(),\n\t\t\t\t\t  MOSDPing::PING, now,\n\t\t\t\t\t  cct->_conf->osd_heartbeat_min_size));\n\n    if (i->second.con_front)\n      i->second.con_front->send_message(new MOSDPing(monc->get_fsid(),\n\t\t\t\t\t     service.get_osdmap()->get_epoch(),\n\t\t\t\t\t     MOSDPing::PING, now,\n\t\t\t\t\t  cct->_conf->osd_heartbeat_min_size));\n  }\n\n  logger->set(l_osd_hb_to, heartbeat_peers.size());\n\n  // hmm.. am i all alone?\n  dout(30) << \"heartbeat lonely?\" << dendl;\n  if (heartbeat_peers.empty()) {\n    if (now - last_mon_heartbeat > cct->_conf->osd_mon_heartbeat_interval && is_active()) {\n      last_mon_heartbeat = now;\n      dout(10) << \"i have no heartbeat peers; checking mon for new map\" << dendl;\n      osdmap_subscribe(osdmap->get_epoch() + 1, false);\n    }\n  }\n\n  dout(30) << \"heartbeat done\" << dendl;\n}\n\nbool OSD::heartbeat_reset(Connection *con)\n{\n  HeartbeatSession *s = static_cast<HeartbeatSession*>(con->get_priv());\n  if (s) {\n    heartbeat_lock.Lock();\n    if (is_stopping()) {\n      heartbeat_lock.Unlock();\n      s->put();\n      return true;\n    }\n    map<int,HeartbeatInfo>::iterator p = heartbeat_peers.find(s->peer);\n    if (p != heartbeat_peers.end() &&\n\t(p->second.con_back == con ||\n\t p->second.con_front == con)) {\n      dout(10) << \"heartbeat_reset failed hb con \" << con << \" for osd.\" << p->second.peer\n\t       << \", reopening\" << dendl;\n      if (con != p->second.con_back) {\n\tp->second.con_back->mark_down();\n      }\n      p->second.con_back.reset(NULL);\n      if (p->second.con_front && con != p->second.con_front) {\n\tp->second.con_front->mark_down();\n      }\n      p->second.con_front.reset(NULL);\n      pair<ConnectionRef,ConnectionRef> newcon = service.get_con_osd_hb(p->second.peer, p->second.epoch);\n      if (newcon.first) {\n\tp->second.con_back = newcon.first.get();\n\tp->second.con_back->set_priv(s->get());\n\tif (newcon.second) {\n\t  p->second.con_front = newcon.second.get();\n\t  p->second.con_front->set_priv(s->get());\n\t}\n      } else {\n\tdout(10) << \"heartbeat_reset failed hb con \" << con << \" for osd.\" << p->second.peer\n\t\t << \", raced with osdmap update, closing out peer\" << dendl;\n\theartbeat_peers.erase(p);\n      }\n    } else {\n      dout(10) << \"heartbeat_reset closing (old) failed hb con \" << con << dendl;\n    }\n    heartbeat_lock.Unlock();\n    s->put();\n  }\n  return true;\n}\n\n\n\n// =========================================\n\nvoid OSD::tick()\n{\n  assert(osd_lock.is_locked());\n  dout(10) << \"tick\" << dendl;\n\n  if (is_active() || is_waiting_for_healthy()) {\n    maybe_update_heartbeat_peers();\n  }\n\n  if (is_waiting_for_healthy()) {\n    start_boot();\n  } else if (is_preboot() &&\n\t     waiting_for_luminous_mons &&\n\t     monc->monmap.get_required_features().contains_all(\n\t       ceph::features::mon::FEATURE_LUMINOUS)) {\n    // mon upgrade finished!\n    start_boot();\n  }\n\n  do_waiters();\n\n  tick_timer.add_event_after(OSD_TICK_INTERVAL, new C_Tick(this));\n}\n\nvoid OSD::tick_without_osd_lock()\n{\n  assert(tick_timer_lock.is_locked());\n  dout(10) << \"tick_without_osd_lock\" << dendl;\n\n  logger->set(l_osd_buf, buffer::get_total_alloc());\n  logger->set(l_osd_history_alloc_bytes, SHIFT_ROUND_UP(buffer::get_history_alloc_bytes(), 20));\n  logger->set(l_osd_history_alloc_num, buffer::get_history_alloc_num());\n  logger->set(l_osd_cached_crc, buffer::get_cached_crc());\n  logger->set(l_osd_cached_crc_adjusted, buffer::get_cached_crc_adjusted());\n  logger->set(l_osd_missed_crc, buffer::get_missed_crc());\n  logger->set(l_osd_pg_removing, remove_wq.get_remove_queue_len());\n\n  // osd_lock is not being held, which means the OSD state\n  // might change when doing the monitor report\n  if (is_active() || is_waiting_for_healthy()) {\n    heartbeat_lock.Lock();\n    heartbeat_check();\n    heartbeat_lock.Unlock();\n\n    map_lock.get_read();\n    Mutex::Locker l(mon_report_lock);\n\n    // mon report?\n    bool reset = false;\n    bool report = false;\n    utime_t now = ceph_clock_now();\n    pg_stat_queue_lock.Lock();\n    double backoff = stats_ack_timeout / cct->_conf->osd_mon_ack_timeout;\n    double adjusted_min = cct->_conf->osd_mon_report_interval_min * backoff;\n    // note: we shouldn't adjust max because it must remain < the\n    // mon's mon_osd_report_timeout (which defaults to 1.5x our\n    // value).\n    double max = cct->_conf->osd_mon_report_interval_max;\n    if (!outstanding_pg_stats.empty() &&\n\t(now - stats_ack_timeout) > last_pg_stats_ack) {\n      dout(1) << __func__ << \" mon hasn't acked PGStats in \"\n\t      << now - last_pg_stats_ack\n\t      << \" seconds, reconnecting elsewhere\" << dendl;\n      reset = true;\n      last_pg_stats_ack = now;  // reset clock\n      last_pg_stats_sent = utime_t();\n      stats_ack_timeout =\n\tMAX(cct->_conf->osd_mon_ack_timeout,\n\t    stats_ack_timeout * cct->_conf->osd_stats_ack_timeout_factor);\n      outstanding_pg_stats.clear();\n    }\n    if (now - last_pg_stats_sent > max) {\n      osd_stat_updated = true;\n      report = true;\n    } else if (service.need_fullness_update()) {\n      report = true;\n    } else if ((int)outstanding_pg_stats.size() >=\n\t       cct->_conf->osd_mon_report_max_in_flight) {\n      dout(20) << __func__ << \" have max \" << outstanding_pg_stats\n\t       << \" stats updates in flight\" << dendl;\n    } else {\n      if (now - last_mon_report > adjusted_min) {\n\tdout(20) << __func__ << \" stats backoff \" << backoff\n\t\t << \" adjusted_min \" << adjusted_min << \" - sending report\"\n\t\t << dendl;\n        osd_stat_updated = true;\n\treport = true;\n      }\n    }\n    pg_stat_queue_lock.Unlock();\n\n    if (reset) {\n      monc->reopen_session();\n    } else if (report) {\n      last_mon_report = now;\n\n      // do any pending reports\n      send_full_update();\n      send_failures();\n      if (osdmap->require_osd_release < CEPH_RELEASE_LUMINOUS) {\n\tsend_pg_stats(now);\n      }\n    }\n    map_lock.put_read();\n  }\n\n  if (is_active()) {\n    if (!scrub_random_backoff()) {\n      sched_scrub();\n    }\n    service.promote_throttle_recalibrate();\n    resume_creating_pg();\n    bool need_send_beacon = false;\n    const auto now = ceph::coarse_mono_clock::now();\n    {\n      // borrow lec lock to pretect last_sent_beacon from changing\n      Mutex::Locker l{min_last_epoch_clean_lock};\n      const auto elapsed = now - last_sent_beacon;\n      if (chrono::duration_cast<chrono::seconds>(elapsed).count() >\n        cct->_conf->osd_beacon_report_interval) {\n        need_send_beacon = true;\n      }\n    }\n    if (need_send_beacon) {\n      send_beacon(now);\n    }\n  }\n\n  mgrc.update_osd_health(get_health_metrics());\n  service.kick_recovery_queue();\n  tick_timer_without_osd_lock.add_event_after(OSD_TICK_INTERVAL, new C_Tick_WithoutOSDLock(this));\n}\n\nvoid OSD::check_ops_in_flight()\n{\n  vector<string> warnings;\n  if (op_tracker.check_ops_in_flight(warnings)) {\n    for (vector<string>::iterator i = warnings.begin();\n        i != warnings.end();\n        ++i) {\n      clog->warn() << *i;\n    }\n  }\n}\n\n// Usage:\n//   setomapval <pool-id> [namespace/]<obj-name> <key> <val>\n//   rmomapkey <pool-id> [namespace/]<obj-name> <key>\n//   setomapheader <pool-id> [namespace/]<obj-name> <header>\n//   getomap <pool> [namespace/]<obj-name>\n//   truncobj <pool-id> [namespace/]<obj-name> <newlen>\n//   injectmdataerr [namespace/]<obj-name> [shardid]\n//   injectdataerr [namespace/]<obj-name> [shardid]\n//\n//   set_recovery_delay [utime]\nvoid TestOpsSocketHook::test_ops(OSDService *service, ObjectStore *store,\n     const std::string &command, cmdmap_t& cmdmap, ostream &ss)\n{\n  //Test support\n  //Support changing the omap on a single osd by using the Admin Socket to\n  //directly request the osd make a change.\n  if (command == \"setomapval\" || command == \"rmomapkey\" ||\n      command == \"setomapheader\" || command == \"getomap\" ||\n      command == \"truncobj\" || command == \"injectmdataerr\" ||\n      command == \"injectdataerr\"\n    ) {\n    pg_t rawpg;\n    int64_t pool;\n    OSDMapRef curmap = service->get_osdmap();\n    int r = -1;\n\n    string poolstr;\n\n    cmd_getval(service->cct, cmdmap, \"pool\", poolstr);\n    pool = curmap->lookup_pg_pool_name(poolstr);\n    //If we can't find it by name then maybe id specified\n    if (pool < 0 && isdigit(poolstr[0]))\n      pool = atoll(poolstr.c_str());\n    if (pool < 0) {\n      ss << \"Invalid pool '\" << poolstr << \"''\";\n      return;\n    }\n\n    string objname, nspace;\n    cmd_getval(service->cct, cmdmap, \"objname\", objname);\n    std::size_t found = objname.find_first_of('/');\n    if (found != string::npos) {\n      nspace = objname.substr(0, found);\n      objname = objname.substr(found+1);\n    }\n    object_locator_t oloc(pool, nspace);\n    r = curmap->object_locator_to_pg(object_t(objname), oloc,  rawpg);\n\n    if (r < 0) {\n      ss << \"Invalid namespace/objname\";\n      return;\n    }\n\n    int64_t shardid;\n    cmd_getval(service->cct, cmdmap, \"shardid\", shardid, int64_t(shard_id_t::NO_SHARD));\n    hobject_t obj(object_t(objname), string(\"\"), CEPH_NOSNAP, rawpg.ps(), pool, nspace);\n    ghobject_t gobj(obj, ghobject_t::NO_GEN, shard_id_t(uint8_t(shardid)));\n    spg_t pgid(curmap->raw_pg_to_pg(rawpg), shard_id_t(shardid));\n    if (curmap->pg_is_ec(rawpg)) {\n        if ((command != \"injectdataerr\") && (command != \"injectmdataerr\")) {\n            ss << \"Must not call on ec pool, except injectdataerr or injectmdataerr\";\n            return;\n        }\n    }\n\n    ObjectStore::Transaction t;\n\n    if (command == \"setomapval\") {\n      map<string, bufferlist> newattrs;\n      bufferlist val;\n      string key, valstr;\n      cmd_getval(service->cct, cmdmap, \"key\", key);\n      cmd_getval(service->cct, cmdmap, \"val\", valstr);\n\n      val.append(valstr);\n      newattrs[key] = val;\n      t.omap_setkeys(coll_t(pgid), ghobject_t(obj), newattrs);\n      r = store->apply_transaction(service->meta_osr.get(), std::move(t));\n      if (r < 0)\n        ss << \"error=\" << r;\n      else\n        ss << \"ok\";\n    } else if (command == \"rmomapkey\") {\n      string key;\n      set<string> keys;\n      cmd_getval(service->cct, cmdmap, \"key\", key);\n\n      keys.insert(key);\n      t.omap_rmkeys(coll_t(pgid), ghobject_t(obj), keys);\n      r = store->apply_transaction(service->meta_osr.get(), std::move(t));\n      if (r < 0)\n        ss << \"error=\" << r;\n      else\n        ss << \"ok\";\n    } else if (command == \"setomapheader\") {\n      bufferlist newheader;\n      string headerstr;\n\n      cmd_getval(service->cct, cmdmap, \"header\", headerstr);\n      newheader.append(headerstr);\n      t.omap_setheader(coll_t(pgid), ghobject_t(obj), newheader);\n      r = store->apply_transaction(service->meta_osr.get(), std::move(t));\n      if (r < 0)\n        ss << \"error=\" << r;\n      else\n        ss << \"ok\";\n    } else if (command == \"getomap\") {\n      //Debug: Output entire omap\n      bufferlist hdrbl;\n      map<string, bufferlist> keyvals;\n      r = store->omap_get(coll_t(pgid), ghobject_t(obj), &hdrbl, &keyvals);\n      if (r >= 0) {\n          ss << \"header=\" << string(hdrbl.c_str(), hdrbl.length());\n          for (map<string, bufferlist>::iterator it = keyvals.begin();\n              it != keyvals.end(); ++it)\n            ss << \" key=\" << (*it).first << \" val=\"\n               << string((*it).second.c_str(), (*it).second.length());\n      } else {\n          ss << \"error=\" << r;\n      }\n    } else if (command == \"truncobj\") {\n      int64_t trunclen;\n      cmd_getval(service->cct, cmdmap, \"len\", trunclen);\n      t.truncate(coll_t(pgid), ghobject_t(obj), trunclen);\n      r = store->apply_transaction(service->meta_osr.get(), std::move(t));\n      if (r < 0)\n\tss << \"error=\" << r;\n      else\n\tss << \"ok\";\n    } else if (command == \"injectdataerr\") {\n      store->inject_data_error(gobj);\n      ss << \"ok\";\n    } else if (command == \"injectmdataerr\") {\n      store->inject_mdata_error(gobj);\n      ss << \"ok\";\n    }\n    return;\n  }\n  if (command == \"set_recovery_delay\") {\n    int64_t delay;\n    cmd_getval(service->cct, cmdmap, \"utime\", delay, (int64_t)0);\n    ostringstream oss;\n    oss << delay;\n    int r = service->cct->_conf->set_val(\"osd_recovery_delay_start\",\n\t\t\t\t\t oss.str().c_str());\n    if (r != 0) {\n      ss << \"set_recovery_delay: error setting \"\n\t << \"osd_recovery_delay_start to '\" << delay << \"': error \"\n\t << r;\n      return;\n    }\n    service->cct->_conf->apply_changes(NULL);\n    ss << \"set_recovery_delay: set osd_recovery_delay_start \"\n       << \"to \" << service->cct->_conf->osd_recovery_delay_start;\n    return;\n  }\n  if (command ==  \"trigger_scrub\") {\n    spg_t pgid;\n    OSDMapRef curmap = service->get_osdmap();\n\n    string pgidstr;\n\n    cmd_getval(service->cct, cmdmap, \"pgid\", pgidstr);\n    if (!pgid.parse(pgidstr.c_str())) {\n      ss << \"Invalid pgid specified\";\n      return;\n    }\n\n    PG *pg = service->osd->_lookup_lock_pg(pgid);\n    if (pg == nullptr) {\n      ss << \"Can't find pg \" << pgid;\n      return;\n    }\n\n    if (pg->is_primary()) {\n      pg->unreg_next_scrub();\n      const pg_pool_t *p = curmap->get_pg_pool(pgid.pool());\n      double pool_scrub_max_interval = 0;\n      p->opts.get(pool_opts_t::SCRUB_MAX_INTERVAL, &pool_scrub_max_interval);\n      double scrub_max_interval = pool_scrub_max_interval > 0 ?\n        pool_scrub_max_interval : g_conf->osd_scrub_max_interval;\n      // Instead of marking must_scrub force a schedule scrub\n      utime_t stamp = ceph_clock_now();\n      stamp -= scrub_max_interval;\n      stamp -=  100.0;  // push back last scrub more for good measure\n      pg->info.history.last_scrub_stamp = stamp;\n      pg->reg_next_scrub();\n      ss << \"ok\";\n    } else {\n      ss << \"Not primary\";\n    }\n    pg->unlock();\n    return;\n  }\n  if (command == \"injectfull\") {\n    int64_t count;\n    string type;\n    OSDService::s_names state;\n    cmd_getval(service->cct, cmdmap, \"type\", type, string(\"full\"));\n    cmd_getval(service->cct, cmdmap, \"count\", count, (int64_t)-1);\n    if (type == \"none\" || count == 0) {\n      type = \"none\";\n      count = 0;\n    }\n    state = service->get_full_state(type);\n    if (state == OSDService::s_names::INVALID) {\n      ss << \"Invalid type use (none, nearfull, backfillfull, full, failsafe)\";\n      return;\n    }\n    service->set_injectfull(state, count);\n    return;\n  }\n  ss << \"Internal error - command=\" << command;\n}\n\n// =========================================\nbool remove_dir(\n  CephContext *cct,\n  ObjectStore *store, SnapMapper *mapper,\n  OSDriver *osdriver,\n  ObjectStore::Sequencer *osr,\n  coll_t coll, DeletingStateRef dstate,\n  bool *finished,\n  ThreadPool::TPHandle &handle)\n{\n  vector<ghobject_t> olist;\n  int64_t num = 0;\n  ObjectStore::Transaction t;\n  ghobject_t next;\n  handle.reset_tp_timeout();\n  store->collection_list(\n    coll,\n    next,\n    ghobject_t::get_max(),\n    store->get_ideal_list_max(),\n    &olist,\n    &next);\n  generic_dout(10) << __func__ << \" \" << olist << dendl;\n  // default cont to true, this is safe because caller(OSD::RemoveWQ::_process()) \n  // will recheck the answer before it really goes on.\n  bool cont = true;\n  for (vector<ghobject_t>::iterator i = olist.begin();\n       i != olist.end();\n       ++i) {\n    if (i->is_pgmeta())\n      continue;\n    OSDriver::OSTransaction _t(osdriver->get_transaction(&t));\n    int r = mapper->remove_oid(i->hobj, &_t);\n    if (r != 0 && r != -ENOENT) {\n      ceph_abort();\n    }\n    t.remove(coll, *i);\n    if (++num >= cct->_conf->osd_target_transaction_size) {\n      C_SaferCond waiter;\n      store->queue_transaction(osr, std::move(t), &waiter);\n      cont = dstate->pause_clearing();\n      handle.suspend_tp_timeout();\n      waiter.wait();\n      handle.reset_tp_timeout();\n      if (cont)\n        cont = dstate->resume_clearing();\n      if (!cont)\n\treturn false;\n      t = ObjectStore::Transaction();\n      num = 0;\n    }\n  }\n  if (num) {\n    C_SaferCond waiter;\n    store->queue_transaction(osr, std::move(t), &waiter);\n    cont = dstate->pause_clearing();\n    handle.suspend_tp_timeout();\n    waiter.wait();\n    handle.reset_tp_timeout();\n    if (cont)\n      cont = dstate->resume_clearing();\n  }\n  // whether there are more objects to remove in the collection\n  *finished = next.is_max();\n  return cont;\n}\n\nvoid OSD::RemoveWQ::_process(\n  pair<PGRef, DeletingStateRef> item,\n  ThreadPool::TPHandle &handle)\n{\n  FUNCTRACE();\n  PGRef pg(item.first);\n  SnapMapper &mapper = pg->snap_mapper;\n  OSDriver &driver = pg->osdriver;\n  coll_t coll = coll_t(pg->info.pgid);\n  pg->osr->flush();\n  bool finished = false;\n\n  if (!item.second->start_or_resume_clearing())\n    return;\n\n  bool cont = remove_dir(\n    pg->cct, store, &mapper, &driver, pg->osr.get(), coll, item.second,\n    &finished, handle);\n  if (!cont)\n    return;\n  if (!finished) {\n    if (item.second->pause_clearing())\n      queue_front(item);\n    return;\n  }\n\n  if (!item.second->start_deleting())\n    return;\n\n  ObjectStore::Transaction t;\n  PGLog::clear_info_log(pg->info.pgid, &t);\n\n  if (cct->_conf->osd_inject_failure_on_pg_removal) {\n    generic_derr << \"osd_inject_failure_on_pg_removal\" << dendl;\n    _exit(1);\n  }\n  t.remove_collection(coll);\n\n  // We need the sequencer to stick around until the op is complete\n  store->queue_transaction(\n    pg->osr.get(),\n    std::move(t),\n    0, // onapplied\n    0, // oncommit\n    0, // onreadable sync\n    new ContainerContext<PGRef>(pg),\n    TrackedOpRef());\n\n  item.second->finish_deleting();\n}\n// =========================================\n\nvoid OSD::ms_handle_connect(Connection *con)\n{\n  dout(10) << __func__ << \" con \" << con << dendl;\n  if (con->get_peer_type() == CEPH_ENTITY_TYPE_MON) {\n    Mutex::Locker l(osd_lock);\n    if (is_stopping())\n      return;\n    dout(10) << __func__ << \" on mon\" << dendl;\n\n    if (is_preboot()) {\n      start_boot();\n    } else if (is_booting()) {\n      _send_boot();       // resend boot message\n    } else {\n      map_lock.get_read();\n      Mutex::Locker l2(mon_report_lock);\n\n      utime_t now = ceph_clock_now();\n      last_mon_report = now;\n\n      // resend everything, it's a new session\n      send_full_update();\n      send_alive();\n      service.requeue_pg_temp();\n      service.send_pg_temp();\n      requeue_failures();\n      send_failures();\n      if (osdmap->require_osd_release < CEPH_RELEASE_LUMINOUS) {\n\tsend_pg_stats(now);\n      }\n\n      map_lock.put_read();\n      if (is_active()) {\n\tsend_beacon(ceph::coarse_mono_clock::now());\n      }\n    }\n\n    // full map requests may happen while active or pre-boot\n    if (requested_full_first) {\n      rerequest_full_maps();\n    }\n  }\n}\n\nvoid OSD::ms_handle_fast_connect(Connection *con)\n{\n  if (con->get_peer_type() != CEPH_ENTITY_TYPE_MON &&\n      con->get_peer_type() != CEPH_ENTITY_TYPE_MGR) {\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (!s) {\n      s = new Session(cct);\n      con->set_priv(s->get());\n      s->con = con;\n      dout(10) << \" new session (outgoing) \" << s << \" con=\" << s->con\n          << \" addr=\" << s->con->get_peer_addr() << dendl;\n      // we don't connect to clients\n      assert(con->get_peer_type() == CEPH_ENTITY_TYPE_OSD);\n      s->entity_name.set_type(CEPH_ENTITY_TYPE_OSD);\n    }\n    s->put();\n  }\n}\n\nvoid OSD::ms_handle_fast_accept(Connection *con)\n{\n  if (con->get_peer_type() != CEPH_ENTITY_TYPE_MON &&\n      con->get_peer_type() != CEPH_ENTITY_TYPE_MGR) {\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (!s) {\n      s = new Session(cct);\n      con->set_priv(s->get());\n      s->con = con;\n      dout(10) << \"new session (incoming)\" << s << \" con=\" << con\n          << \" addr=\" << con->get_peer_addr()\n          << \" must have raced with connect\" << dendl;\n      assert(con->get_peer_type() == CEPH_ENTITY_TYPE_OSD);\n      s->entity_name.set_type(CEPH_ENTITY_TYPE_OSD);\n    }\n    s->put();\n  }\n}\n\nbool OSD::ms_handle_reset(Connection *con)\n{\n  Session *session = static_cast<Session*>(con->get_priv());\n  dout(2) << \"ms_handle_reset con \" << con << \" session \" << session << dendl;\n  if (!session)\n    return false;\n  session->wstate.reset(con);\n  session->con.reset(NULL);  // break con <-> session ref cycle\n  // note that we break session->con *before* the session_handle_reset\n  // cleanup below.  this avoids a race between us and\n  // PG::add_backoff, Session::check_backoff, etc.\n  session_handle_reset(session);\n  session->put();\n  return true;\n}\n\nbool OSD::ms_handle_refused(Connection *con)\n{\n  if (!cct->_conf->osd_fast_fail_on_connection_refused)\n    return false;\n\n  Session *session = static_cast<Session*>(con->get_priv());\n  dout(2) << \"ms_handle_refused con \" << con << \" session \" << session << dendl;\n  if (!session)\n    return false;\n  int type = con->get_peer_type();\n  // handle only OSD failures here\n  if (monc && (type == CEPH_ENTITY_TYPE_OSD)) {\n    OSDMapRef osdmap = get_osdmap();\n    if (osdmap) {\n      int id = osdmap->identify_osd_on_all_channels(con->get_peer_addr());\n      if (id >= 0 && osdmap->is_up(id)) {\n\t// I'm cheating mon heartbeat grace logic, because we know it's not going\n\t// to respawn alone. +1 so we won't hit any boundary case.\n\tmonc->send_mon_message(new MOSDFailure(monc->get_fsid(),\n\t\t\t\t\t\t  osdmap->get_inst(id),\n\t\t\t\t\t\t  cct->_conf->osd_heartbeat_grace + 1,\n\t\t\t\t\t\t  osdmap->get_epoch(),\n\t\t\t\t\t\t  MOSDFailure::FLAG_IMMEDIATE | MOSDFailure::FLAG_FAILED\n\t\t\t\t\t\t  ));\n      }\n    }\n  }\n  session->put();\n  return true;\n}\n\nstruct C_OSD_GetVersion : public Context {\n  OSD *osd;\n  uint64_t oldest, newest;\n  explicit C_OSD_GetVersion(OSD *o) : osd(o), oldest(0), newest(0) {}\n  void finish(int r) override {\n    if (r >= 0)\n      osd->_got_mon_epochs(oldest, newest);\n  }\n};\n\nvoid OSD::start_boot()\n{\n  if (!_is_healthy()) {\n    // if we are not healthy, do not mark ourselves up (yet)\n    dout(1) << \"not healthy; waiting to boot\" << dendl;\n    if (!is_waiting_for_healthy())\n      start_waiting_for_healthy();\n    // send pings sooner rather than later\n    heartbeat_kick();\n    return;\n  }\n  dout(1) << __func__ << dendl;\n  set_state(STATE_PREBOOT);\n  waiting_for_luminous_mons = false;\n  dout(10) << \"start_boot - have maps \" << superblock.oldest_map\n\t   << \"..\" << superblock.newest_map << dendl;\n  C_OSD_GetVersion *c = new C_OSD_GetVersion(this);\n  monc->get_version(\"osdmap\", &c->newest, &c->oldest, c);\n}\n\nvoid OSD::_got_mon_epochs(epoch_t oldest, epoch_t newest)\n{\n  Mutex::Locker l(osd_lock);\n  if (is_preboot()) {\n    _preboot(oldest, newest);\n  }\n}\n\nvoid OSD::_preboot(epoch_t oldest, epoch_t newest)\n{\n  assert(is_preboot());\n  dout(10) << __func__ << \" _preboot mon has osdmaps \"\n\t   << oldest << \"..\" << newest << dendl;\n\n  // ensure our local fullness awareness is accurate\n  heartbeat();\n\n  // if our map within recent history, try to add ourselves to the osdmap.\n  if (osdmap->get_epoch() == 0) {\n    derr << \"waiting for initial osdmap\" << dendl;\n  } else if (osdmap->is_destroyed(whoami)) {\n    derr << \"osdmap says I am destroyed\" << dendl;\n    // provide a small margin so we don't livelock seeing if we\n    // un-destroyed ourselves.\n    if (osdmap->get_epoch() > newest - 1) {\n      exit(0);\n    }\n  } else if (osdmap->test_flag(CEPH_OSDMAP_NOUP) || osdmap->is_noup(whoami)) {\n    derr << \"osdmap NOUP flag is set, waiting for it to clear\" << dendl;\n  } else if (!osdmap->test_flag(CEPH_OSDMAP_SORTBITWISE)) {\n    derr << \"osdmap SORTBITWISE OSDMap flag is NOT set; please set it\"\n\t << dendl;\n  } else if (osdmap->require_osd_release < CEPH_RELEASE_JEWEL) {\n    derr << \"osdmap REQUIRE_JEWEL OSDMap flag is NOT set; please set it\"\n\t << dendl;\n  } else if (!monc->monmap.get_required_features().contains_all(\n\t       ceph::features::mon::FEATURE_LUMINOUS)) {\n    derr << \"monmap REQUIRE_LUMINOUS is NOT set; must upgrade all monitors to \"\n\t << \"Luminous or later before Luminous OSDs will boot\" << dendl;\n    waiting_for_luminous_mons = true;\n  } else if (service.need_fullness_update()) {\n    derr << \"osdmap fullness state needs update\" << dendl;\n    send_full_update();\n  } else if (osdmap->get_epoch() >= oldest - 1 &&\n\t     osdmap->get_epoch() + cct->_conf->osd_map_message_max > newest) {\n    _send_boot();\n    return;\n  }\n\n  // get all the latest maps\n  if (osdmap->get_epoch() + 1 >= oldest)\n    osdmap_subscribe(osdmap->get_epoch() + 1, false);\n  else\n    osdmap_subscribe(oldest - 1, true);\n}\n\nvoid OSD::send_full_update()\n{\n  if (!service.need_fullness_update())\n    return;\n  unsigned state = 0;\n  if (service.is_full()) {\n    state = CEPH_OSD_FULL;\n  } else if (service.is_backfillfull()) {\n    state = CEPH_OSD_BACKFILLFULL;\n  } else if (service.is_nearfull()) {\n    state = CEPH_OSD_NEARFULL;\n  }\n  set<string> s;\n  OSDMap::calc_state_set(state, s);\n  dout(10) << __func__ << \" want state \" << s << dendl;\n  monc->send_mon_message(new MOSDFull(osdmap->get_epoch(), state));\n}\n\nvoid OSD::start_waiting_for_healthy()\n{\n  dout(1) << \"start_waiting_for_healthy\" << dendl;\n  set_state(STATE_WAITING_FOR_HEALTHY);\n  last_heartbeat_resample = utime_t();\n\n  // subscribe to osdmap updates, in case our peers really are known to be dead\n  osdmap_subscribe(osdmap->get_epoch() + 1, false);\n}\n\nbool OSD::_is_healthy()\n{\n  if (!cct->get_heartbeat_map()->is_healthy()) {\n    dout(1) << \"is_healthy false -- internal heartbeat failed\" << dendl;\n    return false;\n  }\n\n  if (is_waiting_for_healthy()) {\n    Mutex::Locker l(heartbeat_lock);\n    utime_t cutoff = ceph_clock_now();\n    cutoff -= cct->_conf->osd_heartbeat_grace;\n    int num = 0, up = 0;\n    for (map<int,HeartbeatInfo>::iterator p = heartbeat_peers.begin();\n\t p != heartbeat_peers.end();\n\t ++p) {\n      if (p->second.is_healthy(cutoff))\n\t++up;\n      ++num;\n    }\n    if ((float)up < (float)num * cct->_conf->osd_heartbeat_min_healthy_ratio) {\n      dout(1) << \"is_healthy false -- only \" << up << \"/\" << num << \" up peers (less than \"\n\t      << int(cct->_conf->osd_heartbeat_min_healthy_ratio * 100.0) << \"%)\" << dendl;\n      return false;\n    }\n  }\n\n  return true;\n}\n\nvoid OSD::_send_boot()\n{\n  dout(10) << \"_send_boot\" << dendl;\n  entity_addr_t cluster_addr = cluster_messenger->get_myaddr();\n  Connection *local_connection = cluster_messenger->get_loopback_connection().get();\n  if (cluster_addr.is_blank_ip()) {\n    int port = cluster_addr.get_port();\n    cluster_addr = client_messenger->get_myaddr();\n    cluster_addr.set_port(port);\n    cluster_messenger->set_addr_unknowns(cluster_addr);\n    dout(10) << \" assuming cluster_addr ip matches client_addr\" << dendl;\n  } else {\n    Session *s = static_cast<Session*>(local_connection->get_priv());\n    if (s)\n      s->put();\n    else\n      cluster_messenger->ms_deliver_handle_fast_connect(local_connection);\n  }\n\n  entity_addr_t hb_back_addr = hb_back_server_messenger->get_myaddr();\n  local_connection = hb_back_server_messenger->get_loopback_connection().get();\n  if (hb_back_addr.is_blank_ip()) {\n    int port = hb_back_addr.get_port();\n    hb_back_addr = cluster_addr;\n    hb_back_addr.set_port(port);\n    hb_back_server_messenger->set_addr_unknowns(hb_back_addr);\n    dout(10) << \" assuming hb_back_addr ip matches cluster_addr\" << dendl;\n  } else {\n    Session *s = static_cast<Session*>(local_connection->get_priv());\n    if (s)\n      s->put();\n    else\n      hb_back_server_messenger->ms_deliver_handle_fast_connect(local_connection);\n  }\n\n  entity_addr_t hb_front_addr = hb_front_server_messenger->get_myaddr();\n  local_connection = hb_front_server_messenger->get_loopback_connection().get();\n  if (hb_front_addr.is_blank_ip()) {\n    int port = hb_front_addr.get_port();\n    hb_front_addr = client_messenger->get_myaddr();\n    hb_front_addr.set_port(port);\n    hb_front_server_messenger->set_addr_unknowns(hb_front_addr);\n    dout(10) << \" assuming hb_front_addr ip matches client_addr\" << dendl;\n  } else {\n    Session *s = static_cast<Session*>(local_connection->get_priv());\n    if (s)\n      s->put();\n    else\n      hb_front_server_messenger->ms_deliver_handle_fast_connect(local_connection);\n  }\n\n  MOSDBoot *mboot = new MOSDBoot(superblock, get_osdmap_epoch(), service.get_boot_epoch(),\n                                 hb_back_addr, hb_front_addr, cluster_addr,\n\t\t\t\t CEPH_FEATURES_ALL);\n  dout(10) << \" client_addr \" << client_messenger->get_myaddr()\n\t   << \", cluster_addr \" << cluster_addr\n\t   << \", hb_back_addr \" << hb_back_addr\n\t   << \", hb_front_addr \" << hb_front_addr\n\t   << dendl;\n  _collect_metadata(&mboot->metadata);\n  monc->send_mon_message(mboot);\n  set_state(STATE_BOOTING);\n}\n\nvoid OSD::_collect_metadata(map<string,string> *pm)\n{\n  // config info\n  (*pm)[\"osd_data\"] = dev_path;\n  if (store->get_type() == \"filestore\") {\n    // not applicable for bluestore\n    (*pm)[\"osd_journal\"] = journal_path;\n  }\n  (*pm)[\"front_addr\"] = stringify(client_messenger->get_myaddr());\n  (*pm)[\"back_addr\"] = stringify(cluster_messenger->get_myaddr());\n  (*pm)[\"hb_front_addr\"] = stringify(hb_front_server_messenger->get_myaddr());\n  (*pm)[\"hb_back_addr\"] = stringify(hb_back_server_messenger->get_myaddr());\n\n  // backend\n  (*pm)[\"osd_objectstore\"] = store->get_type();\n  (*pm)[\"rotational\"] = store_is_rotational ? \"1\" : \"0\";\n  (*pm)[\"journal_rotational\"] = journal_is_rotational ? \"1\" : \"0\";\n  (*pm)[\"default_device_class\"] = store->get_default_device_class();\n  store->collect_metadata(pm);\n\n  collect_sys_info(pm, cct);\n\n  std::string front_iface, back_iface;\n  /*\n  pick_iface(cct,\n      CEPH_PICK_ADDRESS_PUBLIC | CEPH_PICK_ADDRESS_CLUSTER,\n      &front_iface, &back_iface);\n      */\n  (*pm)[\"front_iface\"] = pick_iface(cct,\n      client_messenger->get_myaddr().get_sockaddr_storage());\n  (*pm)[\"back_iface\"] = pick_iface(cct,\n      cluster_messenger->get_myaddr().get_sockaddr_storage());\n\n  dout(10) << __func__ << \" \" << *pm << dendl;\n}\n\nvoid OSD::queue_want_up_thru(epoch_t want)\n{\n  map_lock.get_read();\n  epoch_t cur = osdmap->get_up_thru(whoami);\n  Mutex::Locker l(mon_report_lock);\n  if (want > up_thru_wanted) {\n    dout(10) << \"queue_want_up_thru now \" << want << \" (was \" << up_thru_wanted << \")\"\n\t     << \", currently \" << cur\n\t     << dendl;\n    up_thru_wanted = want;\n    send_alive();\n  } else {\n    dout(10) << \"queue_want_up_thru want \" << want << \" <= queued \" << up_thru_wanted\n\t     << \", currently \" << cur\n\t     << dendl;\n  }\n  map_lock.put_read();\n}\n\nvoid OSD::send_alive()\n{\n  assert(mon_report_lock.is_locked());\n  if (!osdmap->exists(whoami))\n    return;\n  epoch_t up_thru = osdmap->get_up_thru(whoami);\n  dout(10) << \"send_alive up_thru currently \" << up_thru << \" want \" << up_thru_wanted << dendl;\n  if (up_thru_wanted > up_thru) {\n    dout(10) << \"send_alive want \" << up_thru_wanted << dendl;\n    monc->send_mon_message(new MOSDAlive(osdmap->get_epoch(), up_thru_wanted));\n  }\n}\n\nvoid OSD::request_full_map(epoch_t first, epoch_t last)\n{\n  dout(10) << __func__ << \" \" << first << \"..\" << last\n\t   << \", previously requested \"\n\t   << requested_full_first << \"..\" << requested_full_last << dendl;\n  assert(osd_lock.is_locked());\n  assert(first > 0 && last > 0);\n  assert(first <= last);\n  assert(first >= requested_full_first);  // we shouldn't ever ask for older maps\n  if (requested_full_first == 0) {\n    // first request\n    requested_full_first = first;\n    requested_full_last = last;\n  } else if (last <= requested_full_last) {\n    // dup\n    return;\n  } else {\n    // additional request\n    first = requested_full_last + 1;\n    requested_full_last = last;\n  }\n  MMonGetOSDMap *req = new MMonGetOSDMap;\n  req->request_full(first, last);\n  monc->send_mon_message(req);\n}\n\nvoid OSD::got_full_map(epoch_t e)\n{\n  assert(requested_full_first <= requested_full_last);\n  assert(osd_lock.is_locked());\n  if (requested_full_first == 0) {\n    dout(20) << __func__ << \" \" << e << \", nothing requested\" << dendl;\n    return;\n  }\n  if (e < requested_full_first) {\n    dout(10) << __func__ << \" \" << e << \", requested \" << requested_full_first\n\t     << \"..\" << requested_full_last\n\t     << \", ignoring\" << dendl;\n    return;\n  }\n  if (e >= requested_full_last) {\n    dout(10) << __func__ << \" \" << e << \", requested \" << requested_full_first\n\t     << \"..\" << requested_full_last << \", resetting\" << dendl;\n    requested_full_first = requested_full_last = 0;\n    return;\n  }\n  \n  requested_full_first = e + 1;\n\n  dout(10) << __func__ << \" \" << e << \", requested \" << requested_full_first\n           << \"..\" << requested_full_last\n           << \", still need more\" << dendl;\n}\n\nvoid OSD::requeue_failures()\n{\n  Mutex::Locker l(heartbeat_lock);\n  unsigned old_queue = failure_queue.size();\n  unsigned old_pending = failure_pending.size();\n  for (map<int,pair<utime_t,entity_inst_t> >::iterator p =\n\t failure_pending.begin();\n       p != failure_pending.end(); ) {\n    failure_queue[p->first] = p->second.first;\n    failure_pending.erase(p++);\n  }\n  dout(10) << __func__ << \" \" << old_queue << \" + \" << old_pending << \" -> \"\n\t   << failure_queue.size() << dendl;\n}\n\nvoid OSD::send_failures()\n{\n  assert(map_lock.is_locked());\n  assert(mon_report_lock.is_locked());\n  Mutex::Locker l(heartbeat_lock);\n  utime_t now = ceph_clock_now();\n  while (!failure_queue.empty()) {\n    int osd = failure_queue.begin()->first;\n    if (!failure_pending.count(osd)) {\n      entity_inst_t i = osdmap->get_inst(osd);\n      int failed_for = (int)(double)(now - failure_queue.begin()->second);\n      monc->send_mon_message(new MOSDFailure(monc->get_fsid(), i, failed_for,\n\t\t\t\t\t     osdmap->get_epoch()));\n      failure_pending[osd] = make_pair(failure_queue.begin()->second, i);\n    }\n    failure_queue.erase(osd);\n  }\n}\n\nvoid OSD::send_still_alive(epoch_t epoch, const entity_inst_t &i)\n{\n  MOSDFailure *m = new MOSDFailure(monc->get_fsid(), i, 0, epoch, MOSDFailure::FLAG_ALIVE);\n  monc->send_mon_message(m);\n}\n\nvoid OSD::send_pg_stats(const utime_t &now)\n{\n  assert(map_lock.is_locked());\n  assert(osdmap->require_osd_release < CEPH_RELEASE_LUMINOUS);\n  dout(20) << \"send_pg_stats\" << dendl;\n\n  osd_stat_t cur_stat = service.get_osd_stat();\n\n  cur_stat.os_perf_stat = store->get_cur_stats();\n\n  pg_stat_queue_lock.Lock();\n\n  if (osd_stat_updated || !pg_stat_queue.empty()) {\n    last_pg_stats_sent = now;\n    osd_stat_updated = false;\n\n    dout(10) << \"send_pg_stats - \" << pg_stat_queue.size() << \" pgs updated\" << dendl;\n\n    utime_t had_for(now);\n    had_for -= had_map_since;\n\n    MPGStats *m = new MPGStats(monc->get_fsid(), osdmap->get_epoch(), had_for);\n\n    uint64_t tid = ++pg_stat_tid;\n    m->set_tid(tid);\n    m->osd_stat = cur_stat;\n\n    xlist<PG*>::iterator p = pg_stat_queue.begin();\n    while (!p.end()) {\n      PG *pg = *p;\n      ++p;\n      if (!pg->is_primary()) {  // we hold map_lock; role is stable.\n\tpg->stat_queue_item.remove_myself();\n\tpg->put(\"pg_stat_queue\");\n\tcontinue;\n      }\n      pg->pg_stats_publish_lock.Lock();\n      if (pg->pg_stats_publish_valid) {\n\tm->pg_stat[pg->info.pgid.pgid] = pg->pg_stats_publish;\n\tdout(25) << \" sending \" << pg->info.pgid << \" \" << pg->pg_stats_publish.reported_epoch << \":\"\n\t\t << pg->pg_stats_publish.reported_seq << dendl;\n      } else {\n\tdout(25) << \" NOT sending \" << pg->info.pgid << \" \" << pg->pg_stats_publish.reported_epoch << \":\"\n\t\t << pg->pg_stats_publish.reported_seq << \", not valid\" << dendl;\n      }\n      pg->pg_stats_publish_lock.Unlock();\n    }\n\n    if (last_pg_stats_ack == utime_t() || !outstanding_pg_stats.empty()) {\n      last_pg_stats_ack = ceph_clock_now();\n    }\n    outstanding_pg_stats.insert(tid);\n    dout(20) << __func__ << \"  updates pending: \" << outstanding_pg_stats << dendl;\n\n    monc->send_mon_message(m);\n  }\n\n  pg_stat_queue_lock.Unlock();\n}\n\nvoid OSD::handle_pg_stats_ack(MPGStatsAck *ack)\n{\n  dout(10) << \"handle_pg_stats_ack \" << dendl;\n\n  if (!require_mon_peer(ack)) {\n    ack->put();\n    return;\n  }\n\n  // NOTE: we may get replies from a previous mon even while\n  // outstanding_pg_stats is empty if reconnecting races with replies\n  // in flight.\n\n  pg_stat_queue_lock.Lock();\n\n  last_pg_stats_ack = ceph_clock_now();\n\n  // decay timeout slowly (analogous to TCP)\n  stats_ack_timeout =\n    MAX(cct->_conf->osd_mon_ack_timeout,\n\tstats_ack_timeout * cct->_conf->osd_stats_ack_timeout_decay);\n  dout(20) << __func__ << \"  timeout now \" << stats_ack_timeout << dendl;\n\n  if (ack->get_tid() > pg_stat_tid_flushed) {\n    pg_stat_tid_flushed = ack->get_tid();\n    pg_stat_queue_cond.Signal();\n  }\n\n  xlist<PG*>::iterator p = pg_stat_queue.begin();\n  while (!p.end()) {\n    PG *pg = *p;\n    PGRef _pg(pg);\n    ++p;\n\n    auto acked = ack->pg_stat.find(pg->info.pgid.pgid);\n    if (acked != ack->pg_stat.end()) {\n      pg->pg_stats_publish_lock.Lock();\n      if (acked->second.first == pg->pg_stats_publish.reported_seq &&\n\t  acked->second.second == pg->pg_stats_publish.reported_epoch) {\n\tdout(25) << \" ack on \" << pg->info.pgid << \" \" << pg->pg_stats_publish.reported_epoch\n\t\t << \":\" << pg->pg_stats_publish.reported_seq << dendl;\n\tpg->stat_queue_item.remove_myself();\n\tpg->put(\"pg_stat_queue\");\n      } else {\n\tdout(25) << \" still pending \" << pg->info.pgid << \" \" << pg->pg_stats_publish.reported_epoch\n\t\t << \":\" << pg->pg_stats_publish.reported_seq << \" > acked \"\n\t\t << acked->second << dendl;\n      }\n      pg->pg_stats_publish_lock.Unlock();\n    } else {\n      dout(30) << \" still pending \" << pg->info.pgid << \" \" << pg->pg_stats_publish.reported_epoch\n\t       << \":\" << pg->pg_stats_publish.reported_seq << dendl;\n    }\n  }\n\n  outstanding_pg_stats.erase(ack->get_tid());\n  dout(20) << __func__ << \"  still pending: \" << outstanding_pg_stats << dendl;\n\n  pg_stat_queue_lock.Unlock();\n\n  ack->put();\n}\n\nvoid OSD::flush_pg_stats()\n{\n  dout(10) << \"flush_pg_stats\" << dendl;\n  osd_lock.Unlock();\n  utime_t now = ceph_clock_now();\n  map_lock.get_read();\n  mon_report_lock.Lock();\n  send_pg_stats(now);\n  mon_report_lock.Unlock();\n  map_lock.put_read();\n\n\n  pg_stat_queue_lock.Lock();\n  uint64_t tid = pg_stat_tid;\n  dout(10) << \"flush_pg_stats waiting for stats tid \" << tid << \" to flush\" << dendl;\n  while (tid > pg_stat_tid_flushed)\n    pg_stat_queue_cond.Wait(pg_stat_queue_lock);\n  dout(10) << \"flush_pg_stats finished waiting for stats tid \" << tid << \" to flush\" << dendl;\n  pg_stat_queue_lock.Unlock();\n\n  osd_lock.Lock();\n}\n\nvoid OSD::send_beacon(const ceph::coarse_mono_clock::time_point& now)\n{\n  const auto& monmap = monc->monmap;\n  // send beacon to mon even if we are just connected, and the monmap is not\n  // initialized yet by then.\n  if (monmap.epoch > 0 &&\n      monmap.get_required_features().contains_all(\n        ceph::features::mon::FEATURE_LUMINOUS)) {\n    dout(20) << __func__ << \" sending\" << dendl;\n    MOSDBeacon* beacon = nullptr;\n    {\n      Mutex::Locker l{min_last_epoch_clean_lock};\n      beacon = new MOSDBeacon(osdmap->get_epoch(), min_last_epoch_clean);\n      std::swap(beacon->pgs, min_last_epoch_clean_pgs);\n      last_sent_beacon = now;\n    }\n    monc->send_mon_message(beacon);\n  } else {\n    dout(20) << __func__ << \" not sending\" << dendl;\n  }\n}\n\nvoid OSD::handle_command(MMonCommand *m)\n{\n  if (!require_mon_peer(m)) {\n    m->put();\n    return;\n  }\n\n  Command *c = new Command(m->cmd, m->get_tid(), m->get_data(), NULL);\n  command_wq.queue(c);\n  m->put();\n}\n\nvoid OSD::handle_command(MCommand *m)\n{\n  ConnectionRef con = m->get_connection();\n  Session *session = static_cast<Session *>(con->get_priv());\n  if (!session) {\n    con->send_message(new MCommandReply(m, -EPERM));\n    m->put();\n    return;\n  }\n\n  OSDCap& caps = session->caps;\n  session->put();\n\n  if (!caps.allow_all() || m->get_source().is_mon()) {\n    con->send_message(new MCommandReply(m, -EPERM));\n    m->put();\n    return;\n  }\n\n  Command *c = new Command(m->cmd, m->get_tid(), m->get_data(), con.get());\n  command_wq.queue(c);\n\n  m->put();\n}\n\nstruct OSDCommand {\n  string cmdstring;\n  string helpstring;\n  string module;\n  string perm;\n  string availability;\n} osd_commands[] = {\n\n#define COMMAND(parsesig, helptext, module, perm, availability) \\\n  {parsesig, helptext, module, perm, availability},\n\n// yes, these are really pg commands, but there's a limit to how\n// much work it's worth.  The OSD returns all of them.  Make this\n// form (pg <pgid> <cmd>) valid only for the cli.\n// Rest uses \"tell <pgid> <cmd>\"\n\nCOMMAND(\"pg \" \\\n\t\"name=pgid,type=CephPgid \" \\\n\t\"name=cmd,type=CephChoices,strings=query\", \\\n\t\"show details of a specific pg\", \"osd\", \"r\", \"cli\")\nCOMMAND(\"pg \" \\\n\t\"name=pgid,type=CephPgid \" \\\n\t\"name=cmd,type=CephChoices,strings=mark_unfound_lost \" \\\n\t\"name=mulcmd,type=CephChoices,strings=revert|delete\", \\\n\t\"mark all unfound objects in this pg as lost, either removing or reverting to a prior version if one is available\",\n\t\"osd\", \"rw\", \"cli\")\nCOMMAND(\"pg \" \\\n\t\"name=pgid,type=CephPgid \" \\\n\t\"name=cmd,type=CephChoices,strings=list_missing \" \\\n\t\"name=offset,type=CephString,req=false\",\n\t\"list missing objects on this pg, perhaps starting at an offset given in JSON\",\n\t\"osd\", \"r\", \"cli\")\n\n// new form: tell <pgid> <cmd> for both cli and rest\n\nCOMMAND(\"query\",\n\t\"show details of a specific pg\", \"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"mark_unfound_lost \" \\\n\t\"name=mulcmd,type=CephChoices,strings=revert|delete\", \\\n\t\"mark all unfound objects in this pg as lost, either removing or reverting to a prior version if one is available\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"list_missing \" \\\n\t\"name=offset,type=CephString,req=false\",\n\t\"list missing objects on this pg, perhaps starting at an offset given in JSON\",\n\t\"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"perf histogram dump \"\n        \"name=logger,type=CephString,req=false \"\n        \"name=counter,type=CephString,req=false\",\n\t\"Get histogram data\",\n\t\"osd\", \"r\", \"cli,rest\")\n\n// tell <osd.n> commands.  Validation of osd.n must be special-cased in client\nCOMMAND(\"version\", \"report version of OSD\", \"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"get_command_descriptions\", \"list commands descriptions\", \"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"injectargs \" \\\n\t\"name=injected_args,type=CephString,n=N\",\n\t\"inject configuration arguments into running OSD\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"config set \" \\\n\t\"name=key,type=CephString name=value,type=CephString\",\n\t\"Set a configuration option at runtime (not persistent)\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"cluster_log \" \\\n\t\"name=level,type=CephChoices,strings=error,warning,info,debug \" \\\n\t\"name=message,type=CephString,n=N\",\n\t\"log a message to the cluster log\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"bench \" \\\n\t\"name=count,type=CephInt,req=false \" \\\n\t\"name=size,type=CephInt,req=false \" \\\n\t\"name=object_size,type=CephInt,req=false \" \\\n\t\"name=object_num,type=CephInt,req=false \", \\\n\t\"OSD benchmark: write <count> <size>-byte objects, \" \\\n\t\"(default 1G size 4MB). Results in log.\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"flush_pg_stats\", \"flush pg stats\", \"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"heap \" \\\n\t\"name=heapcmd,type=CephChoices,strings=dump|start_profiler|stop_profiler|release|stats\", \\\n\t\"show heap usage info (available only if compiled with tcmalloc)\", \\\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"debug dump_missing \" \\\n\t\"name=filename,type=CephFilepath\",\n\t\"dump missing objects to a named file\", \"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"debug kick_recovery_wq \" \\\n\t\"name=delay,type=CephInt,range=0\",\n\t\"set osd_recovery_delay_start to <val>\", \"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"cpu_profiler \" \\\n\t\"name=arg,type=CephChoices,strings=status|flush\",\n\t\"run cpu profiling on daemon\", \"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"dump_pg_recovery_stats\", \"dump pg recovery statistics\",\n\t\"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"reset_pg_recovery_stats\", \"reset pg recovery statistics\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"compact\",\n        \"compact object store's omap. \"\n        \"WARNING: Compaction probably slows your requests\",\n        \"osd\", \"rw\", \"cli,rest\")\n};\n\nvoid OSD::do_command(Connection *con, ceph_tid_t tid, vector<string>& cmd, bufferlist& data)\n{\n  int r = 0;\n  stringstream ss, ds;\n  string rs;\n  bufferlist odata;\n\n  dout(20) << \"do_command tid \" << tid << \" \" << cmd << dendl;\n\n  map<string, cmd_vartype> cmdmap;\n  string prefix;\n  string format;\n  string pgidstr;\n  boost::scoped_ptr<Formatter> f;\n\n  if (cmd.empty()) {\n    ss << \"no command given\";\n    goto out;\n  }\n\n  if (!cmdmap_from_json(cmd, &cmdmap, ss)) {\n    r = -EINVAL;\n    goto out;\n  }\n\n  cmd_getval(cct, cmdmap, \"prefix\", prefix);\n\n  if (prefix == \"get_command_descriptions\") {\n    int cmdnum = 0;\n    JSONFormatter *f = new JSONFormatter();\n    f->open_object_section(\"command_descriptions\");\n    for (OSDCommand *cp = osd_commands;\n\t cp < &osd_commands[ARRAY_SIZE(osd_commands)]; cp++) {\n\n      ostringstream secname;\n      secname << \"cmd\" << setfill('0') << std::setw(3) << cmdnum;\n      dump_cmddesc_to_json(f, secname.str(), cp->cmdstring, cp->helpstring,\n\t\t\t   cp->module, cp->perm, cp->availability, 0);\n      cmdnum++;\n    }\n    f->close_section();\t// command_descriptions\n\n    f->flush(ds);\n    delete f;\n    goto out;\n  }\n\n  cmd_getval(cct, cmdmap, \"format\", format);\n  f.reset(Formatter::create(format));\n\n  if (prefix == \"version\") {\n    if (f) {\n      f->open_object_section(\"version\");\n      f->dump_string(\"version\", pretty_version_to_str());\n      f->close_section();\n      f->flush(ds);\n    } else {\n      ds << pretty_version_to_str();\n    }\n    goto out;\n  }\n  else if (prefix == \"injectargs\") {\n    vector<string> argsvec;\n    cmd_getval(cct, cmdmap, \"injected_args\", argsvec);\n\n    if (argsvec.empty()) {\n      r = -EINVAL;\n      ss << \"ignoring empty injectargs\";\n      goto out;\n    }\n    string args = argsvec.front();\n    for (vector<string>::iterator a = ++argsvec.begin(); a != argsvec.end(); ++a)\n      args += \" \" + *a;\n    osd_lock.Unlock();\n    r = cct->_conf->injectargs(args, &ss);\n    osd_lock.Lock();\n  }\n  else if (prefix == \"config set\") {\n    std::string key;\n    std::string val;\n    cmd_getval(cct, cmdmap, \"key\", key);\n    cmd_getval(cct, cmdmap, \"value\", val);\n    osd_lock.Unlock();\n    r = cct->_conf->set_val(key, val, true, &ss);\n    if (r == 0) {\n      cct->_conf->apply_changes(nullptr);\n    }\n    osd_lock.Lock();\n  }\n  else if (prefix == \"cluster_log\") {\n    vector<string> msg;\n    cmd_getval(cct, cmdmap, \"message\", msg);\n    if (msg.empty()) {\n      r = -EINVAL;\n      ss << \"ignoring empty log message\";\n      goto out;\n    }\n    string message = msg.front();\n    for (vector<string>::iterator a = ++msg.begin(); a != msg.end(); ++a)\n      message += \" \" + *a;\n    string lvl;\n    cmd_getval(cct, cmdmap, \"level\", lvl);\n    clog_type level = string_to_clog_type(lvl);\n    if (level < 0) {\n      r = -EINVAL;\n      ss << \"unknown level '\" << lvl << \"'\";\n      goto out;\n    }\n    clog->do_log(level, message);\n  }\n\n  // either 'pg <pgid> <command>' or\n  // 'tell <pgid>' (which comes in without any of that prefix)?\n\n  else if (prefix == \"pg\" ||\n\t    prefix == \"query\" ||\n\t    prefix == \"mark_unfound_lost\" ||\n\t    prefix == \"list_missing\"\n\t   ) {\n    pg_t pgid;\n\n    if (!cmd_getval(cct, cmdmap, \"pgid\", pgidstr)) {\n      ss << \"no pgid specified\";\n      r = -EINVAL;\n    } else if (!pgid.parse(pgidstr.c_str())) {\n      ss << \"couldn't parse pgid '\" << pgidstr << \"'\";\n      r = -EINVAL;\n    } else {\n      spg_t pcand;\n      PG *pg = nullptr;\n      if (osdmap->get_primary_shard(pgid, &pcand) &&\n\t  (pg = _lookup_lock_pg(pcand))) {\n\tif (pg->is_primary()) {\n\t  // simulate pg <pgid> cmd= for pg->do-command\n\t  if (prefix != \"pg\")\n\t    cmd_putval(cct, cmdmap, \"cmd\", prefix);\n\t  r = pg->do_command(cmdmap, ss, data, odata, con, tid);\n\t  if (r == -EAGAIN) {\n\t    pg->unlock();\n\t    // don't reply, pg will do so async\n\t    return;\n\t  }\n\t} else {\n\t  ss << \"not primary for pgid \" << pgid;\n\n\t  // send them the latest diff to ensure they realize the mapping\n\t  // has changed.\n\t  service.send_incremental_map(osdmap->get_epoch() - 1, con, osdmap);\n\n\t  // do not reply; they will get newer maps and realize they\n\t  // need to resend.\n\t  pg->unlock();\n\t  return;\n\t}\n\tpg->unlock();\n      } else {\n\tss << \"i don't have pgid \" << pgid;\n\tr = -ENOENT;\n      }\n    }\n  }\n\n  else if (prefix == \"bench\") {\n    int64_t count;\n    int64_t bsize;\n    int64_t osize, onum;\n    // default count 1G, size 4MB\n    cmd_getval(cct, cmdmap, \"count\", count, (int64_t)1 << 30);\n    cmd_getval(cct, cmdmap, \"size\", bsize, (int64_t)4 << 20);\n    cmd_getval(cct, cmdmap, \"object_size\", osize, (int64_t)0);\n    cmd_getval(cct, cmdmap, \"object_num\", onum, (int64_t)0);\n\n    ceph::shared_ptr<ObjectStore::Sequencer> osr (std::make_shared<\n                                        ObjectStore::Sequencer>(\"bench\"));\n\n    uint32_t duration = cct->_conf->osd_bench_duration;\n\n    if (bsize > (int64_t) cct->_conf->osd_bench_max_block_size) {\n      // let us limit the block size because the next checks rely on it\n      // having a sane value.  If we allow any block size to be set things\n      // can still go sideways.\n      ss << \"block 'size' values are capped at \"\n         << prettybyte_t(cct->_conf->osd_bench_max_block_size) << \". If you wish to use\"\n         << \" a higher value, please adjust 'osd_bench_max_block_size'\";\n      r = -EINVAL;\n      goto out;\n    } else if (bsize < (int64_t) (1 << 20)) {\n      // entering the realm of small block sizes.\n      // limit the count to a sane value, assuming a configurable amount of\n      // IOPS and duration, so that the OSD doesn't get hung up on this,\n      // preventing timeouts from going off\n      int64_t max_count =\n        bsize * duration * cct->_conf->osd_bench_small_size_max_iops;\n      if (count > max_count) {\n        ss << \"'count' values greater than \" << max_count\n           << \" for a block size of \" << prettybyte_t(bsize) << \", assuming \"\n           << cct->_conf->osd_bench_small_size_max_iops << \" IOPS,\"\n           << \" for \" << duration << \" seconds,\"\n           << \" can cause ill effects on osd. \"\n           << \" Please adjust 'osd_bench_small_size_max_iops' with a higher\"\n           << \" value if you wish to use a higher 'count'.\";\n        r = -EINVAL;\n        goto out;\n      }\n    } else {\n      // 1MB block sizes are big enough so that we get more stuff done.\n      // However, to avoid the osd from getting hung on this and having\n      // timers being triggered, we are going to limit the count assuming\n      // a configurable throughput and duration.\n      // NOTE: max_count is the total amount of bytes that we believe we\n      //       will be able to write during 'duration' for the given\n      //       throughput.  The block size hardly impacts this unless it's\n      //       way too big.  Given we already check how big the block size\n      //       is, it's safe to assume everything will check out.\n      int64_t max_count =\n        cct->_conf->osd_bench_large_size_max_throughput * duration;\n      if (count > max_count) {\n        ss << \"'count' values greater than \" << max_count\n           << \" for a block size of \" << prettybyte_t(bsize) << \", assuming \"\n           << prettybyte_t(cct->_conf->osd_bench_large_size_max_throughput) << \"/s,\"\n           << \" for \" << duration << \" seconds,\"\n           << \" can cause ill effects on osd. \"\n           << \" Please adjust 'osd_bench_large_size_max_throughput'\"\n           << \" with a higher value if you wish to use a higher 'count'.\";\n        r = -EINVAL;\n        goto out;\n      }\n    }\n\n    if (osize && bsize > osize)\n      bsize = osize;\n\n    dout(1) << \" bench count \" << count\n            << \" bsize \" << prettybyte_t(bsize) << dendl;\n\n    ObjectStore::Transaction cleanupt;\n\n    if (osize && onum) {\n      bufferlist bl;\n      bufferptr bp(osize);\n      bp.zero();\n      bl.push_back(std::move(bp));\n      bl.rebuild_page_aligned();\n      for (int i=0; i<onum; ++i) {\n\tchar nm[30];\n\tsnprintf(nm, sizeof(nm), \"disk_bw_test_%d\", i);\n\tobject_t oid(nm);\n\thobject_t soid(sobject_t(oid, 0));\n\tObjectStore::Transaction t;\n\tt.write(coll_t(), ghobject_t(soid), 0, osize, bl);\n\tstore->queue_transaction(osr.get(), std::move(t), NULL);\n\tcleanupt.remove(coll_t(), ghobject_t(soid));\n      }\n    }\n\n    bufferlist bl;\n    bufferptr bp(bsize);\n    bp.zero();\n    bl.push_back(std::move(bp));\n    bl.rebuild_page_aligned();\n\n    {\n      C_SaferCond waiter;\n      if (!osr->flush_commit(&waiter)) {\n\twaiter.wait();\n      }\n    }\n\n    utime_t start = ceph_clock_now();\n    for (int64_t pos = 0; pos < count; pos += bsize) {\n      char nm[30];\n      unsigned offset = 0;\n      if (onum && osize) {\n\tsnprintf(nm, sizeof(nm), \"disk_bw_test_%d\", (int)(rand() % onum));\n\toffset = rand() % (osize / bsize) * bsize;\n      } else {\n\tsnprintf(nm, sizeof(nm), \"disk_bw_test_%lld\", (long long)pos);\n      }\n      object_t oid(nm);\n      hobject_t soid(sobject_t(oid, 0));\n      ObjectStore::Transaction t;\n      t.write(coll_t::meta(), ghobject_t(soid), offset, bsize, bl);\n      store->queue_transaction(osr.get(), std::move(t), NULL);\n      if (!onum || !osize)\n\tcleanupt.remove(coll_t::meta(), ghobject_t(soid));\n    }\n\n    {\n      C_SaferCond waiter;\n      if (!osr->flush_commit(&waiter)) {\n\twaiter.wait();\n      }\n    }\n    utime_t end = ceph_clock_now();\n\n    // clean up\n    store->queue_transaction(osr.get(), std::move(cleanupt), NULL);\n    {\n      C_SaferCond waiter;\n      if (!osr->flush_commit(&waiter)) {\n\twaiter.wait();\n      }\n    }\n\n    uint64_t rate = (double)count / (end - start);\n    if (f) {\n      f->open_object_section(\"osd_bench_results\");\n      f->dump_int(\"bytes_written\", count);\n      f->dump_int(\"blocksize\", bsize);\n      f->dump_unsigned(\"bytes_per_sec\", rate);\n      f->close_section();\n      f->flush(ss);\n    } else {\n      ss << \"bench: wrote \" << prettybyte_t(count)\n\t << \" in blocks of \" << prettybyte_t(bsize) << \" in \"\n\t << (end-start) << \" sec at \" << prettybyte_t(rate) << \"/sec\";\n    }\n  }\n\n  else if (prefix == \"flush_pg_stats\") {\n    if (osdmap->require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n      mgrc.send_pgstats();\n      ds << service.get_osd_stat_seq() << \"\\n\";\n    } else {\n      flush_pg_stats();\n    }\n  }\n\n  else if (prefix == \"heap\") {\n    r = ceph::osd_cmds::heap(*cct, cmdmap, *f, ds);\n  }\n\n  else if (prefix == \"debug dump_missing\") {\n    string file_name;\n    cmd_getval(cct, cmdmap, \"filename\", file_name);\n    std::ofstream fout(file_name.c_str());\n    if (!fout.is_open()) {\n\tss << \"failed to open file '\" << file_name << \"'\";\n\tr = -EINVAL;\n\tgoto out;\n    }\n\n    fout << \"*** osd \" << whoami << \": dump_missing ***\" << std::endl;\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t, PG*>::const_iterator pg_map_e = pg_map.begin();\n\t pg_map_e != pg_map.end(); ++pg_map_e) {\n      PG *pg = pg_map_e->second;\n      pg->lock();\n\n      fout << *pg << std::endl;\n      std::map<hobject_t, pg_missing_item>::const_iterator mend =\n\tpg->pg_log.get_missing().get_items().end();\n      std::map<hobject_t, pg_missing_item>::const_iterator mi =\n\tpg->pg_log.get_missing().get_items().begin();\n      for (; mi != mend; ++mi) {\n\tfout << mi->first << \" -> \" << mi->second << std::endl;\n\tif (!pg->missing_loc.needs_recovery(mi->first))\n\t  continue;\n\tif (pg->missing_loc.is_unfound(mi->first))\n\t  fout << \" unfound \";\n\tconst set<pg_shard_t> &mls(pg->missing_loc.get_locations(mi->first));\n\tif (mls.empty())\n\t  continue;\n\tfout << \"missing_loc: \" << mls << std::endl;\n      }\n      pg->unlock();\n      fout << std::endl;\n    }\n\n    fout.close();\n  }\n  else if (prefix == \"debug kick_recovery_wq\") {\n    int64_t delay;\n    cmd_getval(cct, cmdmap, \"delay\", delay);\n    ostringstream oss;\n    oss << delay;\n    r = cct->_conf->set_val(\"osd_recovery_delay_start\", oss.str().c_str());\n    if (r != 0) {\n      ss << \"kick_recovery_wq: error setting \"\n\t << \"osd_recovery_delay_start to '\" << delay << \"': error \"\n\t << r;\n      goto out;\n    }\n    cct->_conf->apply_changes(NULL);\n    ss << \"kicking recovery queue. set osd_recovery_delay_start \"\n       << \"to \" << cct->_conf->osd_recovery_delay_start;\n  }\n\n  else if (prefix == \"cpu_profiler\") {\n    string arg;\n    cmd_getval(cct, cmdmap, \"arg\", arg);\n    vector<string> argvec;\n    get_str_vec(arg, argvec);\n    cpu_profiler_handle_command(argvec, ds);\n  }\n\n  else if (prefix == \"dump_pg_recovery_stats\") {\n    stringstream s;\n    if (f) {\n      pg_recovery_stats.dump_formatted(f.get());\n      f->flush(ds);\n    } else {\n      pg_recovery_stats.dump(s);\n      ds << \"dump pg recovery stats: \" << s.str();\n    }\n  }\n\n  else if (prefix == \"reset_pg_recovery_stats\") {\n    ss << \"reset pg recovery stats\";\n    pg_recovery_stats.reset();\n  }\n\n  else if (prefix == \"perf histogram dump\") {\n    std::string logger;\n    std::string counter;\n    cmd_getval(cct, cmdmap, \"logger\", logger);\n    cmd_getval(cct, cmdmap, \"counter\", counter);\n    if (f) {\n      cct->get_perfcounters_collection()->dump_formatted_histograms(\n          f.get(), false, logger, counter);\n      f->flush(ds);\n    }\n  }\n\n  else if (prefix == \"compact\") {\n    dout(1) << \"triggering manual compaction\" << dendl;\n    auto start = ceph::coarse_mono_clock::now();\n    store->compact();\n    auto end = ceph::coarse_mono_clock::now();\n    auto time_span = chrono::duration_cast<chrono::duration<double>>(end - start);\n    dout(1) << \"finished manual compaction in \"\n            << time_span.count()\n            << \" seconds\" << dendl;\n    ss << \"compacted omap in \" << time_span.count() << \" seconds\";\n  }\n\n  else {\n    ss << \"unrecognized command! \" << cmd;\n    r = -EINVAL;\n  }\n\n out:\n  rs = ss.str();\n  odata.append(ds);\n  dout(0) << \"do_command r=\" << r << \" \" << rs << dendl;\n  clog->info() << rs;\n  if (con) {\n    MCommandReply *reply = new MCommandReply(r, rs);\n    reply->set_tid(tid);\n    reply->set_data(odata);\n    con->send_message(reply);\n  }\n}\n\nbool OSD::heartbeat_dispatch(Message *m)\n{\n  dout(30) << \"heartbeat_dispatch \" << m << dendl;\n  switch (m->get_type()) {\n\n  case CEPH_MSG_PING:\n    dout(10) << \"ping from \" << m->get_source_inst() << dendl;\n    m->put();\n    break;\n\n  case MSG_OSD_PING:\n    handle_osd_ping(static_cast<MOSDPing*>(m));\n    break;\n\n  default:\n    dout(0) << \"dropping unexpected message \" << *m << \" from \" << m->get_source_inst() << dendl;\n    m->put();\n  }\n\n  return true;\n}\n\nbool OSD::ms_dispatch(Message *m)\n{\n  dout(20) << \"OSD::ms_dispatch: \" << *m << dendl;\n  if (m->get_type() == MSG_OSD_MARK_ME_DOWN) {\n    service.got_stop_ack();\n    m->put();\n    return true;\n  }\n\n  // lock!\n\n  osd_lock.Lock();\n  if (is_stopping()) {\n    osd_lock.Unlock();\n    m->put();\n    return true;\n  }\n\n  do_waiters();\n  _dispatch(m);\n\n  osd_lock.Unlock();\n\n  return true;\n}\n\nvoid OSD::maybe_share_map(\n  Session *session,\n  OpRequestRef op,\n  OSDMapRef osdmap)\n{\n  if (!op->check_send_map) {\n    return;\n  }\n  epoch_t last_sent_epoch = 0;\n\n  session->sent_epoch_lock.lock();\n  last_sent_epoch = session->last_sent_epoch;\n  session->sent_epoch_lock.unlock();\n\n  const Message *m = op->get_req();\n  service.share_map(\n    m->get_source(),\n    m->get_connection().get(),\n    op->sent_epoch,\n    osdmap,\n    session ? &last_sent_epoch : NULL);\n\n  session->sent_epoch_lock.lock();\n  if (session->last_sent_epoch < last_sent_epoch) {\n    session->last_sent_epoch = last_sent_epoch;\n  }\n  session->sent_epoch_lock.unlock();\n\n  op->check_send_map = false;\n}\n\nvoid OSD::dispatch_session_waiting(Session *session, OSDMapRef osdmap)\n{\n  assert(session->session_dispatch_lock.is_locked());\n\n  auto i = session->waiting_on_map.begin();\n  while (i != session->waiting_on_map.end()) {\n    OpRequestRef op = &(*i);\n    assert(ms_can_fast_dispatch(op->get_req()));\n    const MOSDFastDispatchOp *m = static_cast<const MOSDFastDispatchOp*>(\n      op->get_req());\n    if (m->get_min_epoch() > osdmap->get_epoch()) {\n      break;\n    }\n    session->waiting_on_map.erase(i++);\n    op->put();\n\n    spg_t pgid;\n    if (m->get_type() == CEPH_MSG_OSD_OP) {\n      pg_t actual_pgid = osdmap->raw_pg_to_pg(\n\tstatic_cast<const MOSDOp*>(m)->get_pg());\n      if (!osdmap->get_primary_shard(actual_pgid, &pgid)) {\n\tcontinue;\n      }\n    } else {\n      pgid = m->get_spg();\n    }\n    enqueue_op(pgid, op, m->get_map_epoch());\n  }\n\n  if (session->waiting_on_map.empty()) {\n    clear_session_waiting_on_map(session);\n  } else {\n    register_session_waiting_on_map(session);\n  }\n}\n\nvoid OSD::ms_fast_dispatch(Message *m)\n{\n  FUNCTRACE();\n  if (service.is_stopping()) {\n    m->put();\n    return;\n  }\n  OpRequestRef op = op_tracker.create_request<OpRequest, Message*>(m);\n  {\n#ifdef WITH_LTTNG\n    osd_reqid_t reqid = op->get_reqid();\n#endif\n    tracepoint(osd, ms_fast_dispatch, reqid.name._type,\n        reqid.name._num, reqid.tid, reqid.inc);\n  }\n\n  if (m->trace)\n    op->osd_trace.init(\"osd op\", &trace_endpoint, &m->trace);\n\n  // note sender epoch, min req'd epoch\n  op->sent_epoch = static_cast<MOSDFastDispatchOp*>(m)->get_map_epoch();\n  op->min_epoch = static_cast<MOSDFastDispatchOp*>(m)->get_min_epoch();\n  assert(op->min_epoch <= op->sent_epoch); // sanity check!\n\n  service.maybe_inject_dispatch_delay();\n\n  if (m->get_connection()->has_features(CEPH_FEATUREMASK_RESEND_ON_SPLIT) ||\n      m->get_type() != CEPH_MSG_OSD_OP) {\n    // queue it directly\n    enqueue_op(\n      static_cast<MOSDFastDispatchOp*>(m)->get_spg(),\n      op,\n      static_cast<MOSDFastDispatchOp*>(m)->get_map_epoch());\n  } else {\n    // legacy client, and this is an MOSDOp (the *only* fast dispatch\n    // message that didn't have an explicit spg_t); we need to map\n    // them to an spg_t while preserving delivery order.\n    Session *session = static_cast<Session*>(m->get_connection()->get_priv());\n    if (session) {\n      {\n\tMutex::Locker l(session->session_dispatch_lock);\n\top->get();\n\tsession->waiting_on_map.push_back(*op);\n\tOSDMapRef nextmap = service.get_nextmap_reserved();\n\tdispatch_session_waiting(session, nextmap);\n\tservice.release_map(nextmap);\n      }\n      session->put();\n    }\n  }\n  OID_EVENT_TRACE_WITH_MSG(m, \"MS_FAST_DISPATCH_END\", false); \n}\n\nvoid OSD::ms_fast_preprocess(Message *m)\n{\n  if (m->get_connection()->get_peer_type() == CEPH_ENTITY_TYPE_OSD) {\n    if (m->get_type() == CEPH_MSG_OSD_MAP) {\n      MOSDMap *mm = static_cast<MOSDMap*>(m);\n      Session *s = static_cast<Session*>(m->get_connection()->get_priv());\n      if (s) {\n\ts->received_map_lock.lock();\n\ts->received_map_epoch = mm->get_last();\n\ts->received_map_lock.unlock();\n\ts->put();\n      }\n    }\n  }\n}\n\nbool OSD::ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new)\n{\n  dout(10) << \"OSD::ms_get_authorizer type=\" << ceph_entity_type_name(dest_type) << dendl;\n\n  if (is_stopping()) {\n    dout(10) << __func__ << \" bailing, we are shutting down\" << dendl;\n    return false;\n  }\n\n  if (dest_type == CEPH_ENTITY_TYPE_MON)\n    return true;\n\n  if (force_new) {\n    /* the MonClient checks keys every tick(), so we should just wait for that cycle\n       to get through */\n    if (monc->wait_auth_rotating(10) < 0) {\n      derr << \"OSD::ms_get_authorizer wait_auth_rotating failed\" << dendl;\n      return false;\n    }\n  }\n\n  *authorizer = monc->build_authorizer(dest_type);\n  return *authorizer != NULL;\n}\n\n\nbool OSD::ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t       int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t       bool& isvalid, CryptoKey& session_key)\n{\n  AuthAuthorizeHandler *authorize_handler = 0;\n  switch (peer_type) {\n  case CEPH_ENTITY_TYPE_MDS:\n    /*\n     * note: mds is technically a client from our perspective, but\n     * this makes the 'cluster' consistent w/ monitor's usage.\n     */\n  case CEPH_ENTITY_TYPE_OSD:\n  case CEPH_ENTITY_TYPE_MGR:\n    authorize_handler = authorize_handler_cluster_registry->get_handler(protocol);\n    break;\n  default:\n    authorize_handler = authorize_handler_service_registry->get_handler(protocol);\n  }\n  if (!authorize_handler) {\n    dout(0) << \"No AuthAuthorizeHandler found for protocol \" << protocol << dendl;\n    isvalid = false;\n    return true;\n  }\n\n  AuthCapsInfo caps_info;\n  EntityName name;\n  uint64_t global_id;\n  uint64_t auid = CEPH_AUTH_UID_DEFAULT;\n\n  RotatingKeyRing *keys = monc->rotating_secrets.get();\n  if (keys) {\n    isvalid = authorize_handler->verify_authorizer(\n      cct, keys,\n      authorizer_data, authorizer_reply, name, global_id, caps_info, session_key,\n      &auid);\n  } else {\n    dout(10) << __func__ << \" no rotating_keys (yet), denied\" << dendl;\n    isvalid = false;\n  }\n\n  if (isvalid) {\n    Session *s = static_cast<Session *>(con->get_priv());\n    if (!s) {\n      s = new Session(cct);\n      con->set_priv(s->get());\n      s->con = con;\n      dout(10) << \" new session \" << s << \" con=\" << s->con << \" addr=\" << s->con->get_peer_addr() << dendl;\n    }\n\n    s->entity_name = name;\n    if (caps_info.allow_all)\n      s->caps.set_allow_all();\n    s->auid = auid;\n\n    if (caps_info.caps.length() > 0) {\n      bufferlist::iterator p = caps_info.caps.begin();\n      string str;\n      try {\n\t::decode(str, p);\n      }\n      catch (buffer::error& e) {\n      }\n      bool success = s->caps.parse(str);\n      if (success)\n\tdout(10) << \" session \" << s << \" \" << s->entity_name << \" has caps \" << s->caps << \" '\" << str << \"'\" << dendl;\n      else\n\tdout(10) << \" session \" << s << \" \" << s->entity_name << \" failed to parse caps '\" << str << \"'\" << dendl;\n    }\n\n    s->put();\n  }\n  return true;\n}\n\nvoid OSD::do_waiters()\n{\n  assert(osd_lock.is_locked());\n\n  dout(10) << \"do_waiters -- start\" << dendl;\n  while (!finished.empty()) {\n    OpRequestRef next = finished.front();\n    finished.pop_front();\n    dispatch_op(next);\n  }\n  dout(10) << \"do_waiters -- finish\" << dendl;\n}\n\nvoid OSD::dispatch_op(OpRequestRef op)\n{\n  switch (op->get_req()->get_type()) {\n\n  case MSG_OSD_PG_CREATE:\n    handle_pg_create(op);\n    break;\n  case MSG_OSD_PG_NOTIFY:\n    handle_pg_notify(op);\n    break;\n  case MSG_OSD_PG_QUERY:\n    handle_pg_query(op);\n    break;\n  case MSG_OSD_PG_LOG:\n    handle_pg_log(op);\n    break;\n  case MSG_OSD_PG_REMOVE:\n    handle_pg_remove(op);\n    break;\n  case MSG_OSD_PG_INFO:\n    handle_pg_info(op);\n    break;\n  case MSG_OSD_PG_TRIM:\n    handle_pg_trim(op);\n    break;\n  case MSG_OSD_BACKFILL_RESERVE:\n    handle_pg_backfill_reserve(op);\n    break;\n  case MSG_OSD_RECOVERY_RESERVE:\n    handle_pg_recovery_reserve(op);\n    break;\n  }\n}\n\nvoid OSD::_dispatch(Message *m)\n{\n  assert(osd_lock.is_locked());\n  dout(20) << \"_dispatch \" << m << \" \" << *m << dendl;\n\n  switch (m->get_type()) {\n\n    // -- don't need lock --\n  case CEPH_MSG_PING:\n    dout(10) << \"ping from \" << m->get_source() << dendl;\n    m->put();\n    break;\n\n    // -- don't need OSDMap --\n\n    // map and replication\n  case CEPH_MSG_OSD_MAP:\n    handle_osd_map(static_cast<MOSDMap*>(m));\n    break;\n\n    // osd\n  case MSG_PGSTATSACK:\n    handle_pg_stats_ack(static_cast<MPGStatsAck*>(m));\n    break;\n\n  case MSG_MON_COMMAND:\n    handle_command(static_cast<MMonCommand*>(m));\n    break;\n  case MSG_COMMAND:\n    handle_command(static_cast<MCommand*>(m));\n    break;\n\n  case MSG_OSD_SCRUB:\n    handle_scrub(static_cast<MOSDScrub*>(m));\n    break;\n\n  case MSG_OSD_FORCE_RECOVERY:\n    handle_force_recovery(m);\n    break;\n\n    // -- need OSDMap --\n\n  case MSG_OSD_PG_CREATE:\n  case MSG_OSD_PG_NOTIFY:\n  case MSG_OSD_PG_QUERY:\n  case MSG_OSD_PG_LOG:\n  case MSG_OSD_PG_REMOVE:\n  case MSG_OSD_PG_INFO:\n  case MSG_OSD_PG_TRIM:\n  case MSG_OSD_BACKFILL_RESERVE:\n  case MSG_OSD_RECOVERY_RESERVE:\n    {\n      OpRequestRef op = op_tracker.create_request<OpRequest, Message*>(m);\n      if (m->trace)\n        op->osd_trace.init(\"osd op\", &trace_endpoint, &m->trace);\n      // no map?  starting up?\n      if (!osdmap) {\n        dout(7) << \"no OSDMap, not booted\" << dendl;\n\tlogger->inc(l_osd_waiting_for_map);\n        waiting_for_osdmap.push_back(op);\n\top->mark_delayed(\"no osdmap\");\n        break;\n      }\n\n      // need OSDMap\n      dispatch_op(op);\n    }\n  }\n}\n\nvoid OSD::handle_pg_scrub(MOSDScrub *m, PG *pg)\n{\n  pg->lock();\n  if (pg->is_primary()) {\n    pg->unreg_next_scrub();\n    pg->scrubber.must_scrub = true;\n    pg->scrubber.must_deep_scrub = m->deep || m->repair;\n    pg->scrubber.must_repair = m->repair;\n    pg->reg_next_scrub();\n    dout(10) << \"marking \" << *pg << \" for scrub\" << dendl;\n  }\n  pg->unlock();\n}\n\nvoid OSD::handle_scrub(MOSDScrub *m)\n{\n  dout(10) << \"handle_scrub \" << *m << dendl;\n  if (!require_mon_or_mgr_peer(m)) {\n    m->put();\n    return;\n  }\n  if (m->fsid != monc->get_fsid()) {\n    dout(0) << \"handle_scrub fsid \" << m->fsid << \" != \" << monc->get_fsid() << dendl;\n    m->put();\n    return;\n  }\n\n  RWLock::RLocker l(pg_map_lock);\n  if (m->scrub_pgs.empty()) {\n    for (ceph::unordered_map<spg_t, PG*>::iterator p = pg_map.begin();\n\t p != pg_map.end();\n\t ++p)\n      handle_pg_scrub(m, p->second);\n  } else {\n    for (vector<pg_t>::iterator p = m->scrub_pgs.begin();\n\t p != m->scrub_pgs.end();\n\t ++p) {\n      spg_t pcand;\n      if (osdmap->get_primary_shard(*p, &pcand)) {\n\tauto pg_map_entry = pg_map.find(pcand);\n\tif (pg_map_entry != pg_map.end()) {\n\t  handle_pg_scrub(m, pg_map_entry->second);\n\t}\n      }\n    }\n  }\n\n  m->put();\n}\n\nbool OSD::scrub_random_backoff()\n{\n  bool coin_flip = (rand() / (double)RAND_MAX >=\n\t\t    cct->_conf->osd_scrub_backoff_ratio);\n  if (!coin_flip) {\n    dout(20) << \"scrub_random_backoff lost coin flip, randomly backing off\" << dendl;\n    return true;\n  }\n  return false;\n}\n\nOSDService::ScrubJob::ScrubJob(CephContext* cct,\n\t\t\t       const spg_t& pg, const utime_t& timestamp,\n\t\t\t       double pool_scrub_min_interval,\n\t\t\t       double pool_scrub_max_interval, bool must)\n  : cct(cct),\n    pgid(pg),\n    sched_time(timestamp),\n    deadline(timestamp)\n{\n  // if not explicitly requested, postpone the scrub with a random delay\n  if (!must) {\n    double scrub_min_interval = pool_scrub_min_interval > 0 ?\n      pool_scrub_min_interval : cct->_conf->osd_scrub_min_interval;\n    double scrub_max_interval = pool_scrub_max_interval > 0 ?\n      pool_scrub_max_interval : cct->_conf->osd_scrub_max_interval;\n\n    sched_time += scrub_min_interval;\n    double r = rand() / (double)RAND_MAX;\n    sched_time +=\n      scrub_min_interval * cct->_conf->osd_scrub_interval_randomize_ratio * r;\n    deadline += scrub_max_interval;\n  }\n}\n\nbool OSDService::ScrubJob::ScrubJob::operator<(const OSDService::ScrubJob& rhs) const {\n  if (sched_time < rhs.sched_time)\n    return true;\n  if (sched_time > rhs.sched_time)\n    return false;\n  return pgid < rhs.pgid;\n}\n\nbool OSD::scrub_time_permit(utime_t now)\n{\n  struct tm bdt;\n  time_t tt = now.sec();\n  localtime_r(&tt, &bdt);\n\n  bool day_permit = false;\n  if (cct->_conf->osd_scrub_begin_week_day < cct->_conf->osd_scrub_end_week_day) {\n    if (bdt.tm_wday >= cct->_conf->osd_scrub_begin_week_day && bdt.tm_wday < cct->_conf->osd_scrub_end_week_day) {\n      day_permit = true;\n    }\n  } else {\n    if (bdt.tm_wday >= cct->_conf->osd_scrub_begin_week_day || bdt.tm_wday < cct->_conf->osd_scrub_end_week_day) {\n      day_permit = true;\n    }\n  }\n\n  if (!day_permit) {\n    dout(20) << __func__ << \" should run between week day \" << cct->_conf->osd_scrub_begin_week_day\n            << \" - \" << cct->_conf->osd_scrub_end_week_day\n            << \" now \" << bdt.tm_wday << \" = no\" << dendl;\n    return false;\n  }\n\n  bool time_permit = false;\n  if (cct->_conf->osd_scrub_begin_hour < cct->_conf->osd_scrub_end_hour) {\n    if (bdt.tm_hour >= cct->_conf->osd_scrub_begin_hour && bdt.tm_hour < cct->_conf->osd_scrub_end_hour) {\n      time_permit = true;\n    }\n  } else {\n    if (bdt.tm_hour >= cct->_conf->osd_scrub_begin_hour || bdt.tm_hour < cct->_conf->osd_scrub_end_hour) {\n      time_permit = true;\n    }\n  }\n  if (!time_permit) {\n    dout(20) << __func__ << \" should run between \" << cct->_conf->osd_scrub_begin_hour\n            << \" - \" << cct->_conf->osd_scrub_end_hour\n            << \" now \" << bdt.tm_hour << \" = no\" << dendl;\n  } else {\n    dout(20) << __func__ << \" should run between \" << cct->_conf->osd_scrub_begin_hour\n            << \" - \" << cct->_conf->osd_scrub_end_hour\n            << \" now \" << bdt.tm_hour << \" = yes\" << dendl;\n  }\n  return time_permit;\n}\n\nbool OSD::scrub_load_below_threshold()\n{\n  double loadavgs[3];\n  if (getloadavg(loadavgs, 3) != 3) {\n    dout(10) << __func__ << \" couldn't read loadavgs\\n\" << dendl;\n    return false;\n  }\n\n  // allow scrub if below configured threshold\n  if (loadavgs[0] < cct->_conf->osd_scrub_load_threshold) {\n    dout(20) << __func__ << \" loadavg \" << loadavgs[0]\n\t     << \" < max \" << cct->_conf->osd_scrub_load_threshold\n\t     << \" = yes\" << dendl;\n    return true;\n  }\n\n  // allow scrub if below daily avg and currently decreasing\n  if (loadavgs[0] < daily_loadavg && loadavgs[0] < loadavgs[2]) {\n    dout(20) << __func__ << \" loadavg \" << loadavgs[0]\n\t     << \" < daily_loadavg \" << daily_loadavg\n\t     << \" and < 15m avg \" << loadavgs[2]\n\t     << \" = yes\" << dendl;\n    return true;\n  }\n\n  dout(20) << __func__ << \" loadavg \" << loadavgs[0]\n\t   << \" >= max \" << cct->_conf->osd_scrub_load_threshold\n\t   << \" and ( >= daily_loadavg \" << daily_loadavg\n\t   << \" or >= 15m avg \" << loadavgs[2]\n\t   << \") = no\" << dendl;\n  return false;\n}\n\nvoid OSD::sched_scrub()\n{\n  // if not permitted, fail fast\n  if (!service.can_inc_scrubs_pending()) {\n    return;\n  }\n  if (!cct->_conf->osd_scrub_during_recovery && service.is_recovery_active()) {\n    dout(20) << __func__ << \" not scheduling scrubs due to active recovery\" << dendl;\n    return;\n  }\n\n\n  utime_t now = ceph_clock_now();\n  bool time_permit = scrub_time_permit(now);\n  bool load_is_low = scrub_load_below_threshold();\n  dout(20) << \"sched_scrub load_is_low=\" << (int)load_is_low << dendl;\n\n  OSDService::ScrubJob scrub;\n  if (service.first_scrub_stamp(&scrub)) {\n    do {\n      dout(30) << \"sched_scrub examine \" << scrub.pgid << \" at \" << scrub.sched_time << dendl;\n\n      if (scrub.sched_time > now) {\n\t// save ourselves some effort\n\tdout(10) << \"sched_scrub \" << scrub.pgid << \" scheduled at \" << scrub.sched_time\n\t\t << \" > \" << now << dendl;\n\tbreak;\n      }\n\n      if ((scrub.deadline >= now) && !(time_permit && load_is_low)) {\n        dout(10) << __func__ << \" not scheduling scrub for \" << scrub.pgid << \" due to \"\n                 << (!time_permit ? \"time not permit\" : \"high load\") << dendl;\n        continue;\n      }\n\n      PG *pg = _lookup_lock_pg(scrub.pgid);\n      if (!pg)\n\tcontinue;\n      if (pg->get_pgbackend()->scrub_supported() && pg->is_active()) {\n\tdout(10) << \"sched_scrub scrubbing \" << scrub.pgid << \" at \" << scrub.sched_time\n\t\t << (pg->scrubber.must_scrub ? \", explicitly requested\" :\n\t\t     (load_is_low ? \", load_is_low\" : \" deadline < now\"))\n\t\t << dendl;\n\tif (pg->sched_scrub()) {\n\t  pg->unlock();\n\t  break;\n\t}\n      }\n      pg->unlock();\n    } while (service.next_scrub_stamp(scrub, &scrub));\n  }\n  dout(20) << \"sched_scrub done\" << dendl;\n}\n\n\n\nvector<OSDHealthMetric> OSD::get_health_metrics()\n{\n  vector<OSDHealthMetric> metrics;\n  lock_guard<mutex> pending_creates_locker{pending_creates_lock};\n  auto n_primaries = pending_creates_from_mon;\n  for (const auto& create : pending_creates_from_osd) {\n    if (create.second) {\n      n_primaries++;\n    }\n  }\n  metrics.emplace_back(osd_metric::PENDING_CREATING_PGS, n_primaries);\n  return metrics;\n}\n\n// =====================================================\n// MAP\n\nvoid OSD::wait_for_new_map(OpRequestRef op)\n{\n  // ask?\n  if (waiting_for_osdmap.empty()) {\n    osdmap_subscribe(osdmap->get_epoch() + 1, false);\n  }\n\n  logger->inc(l_osd_waiting_for_map);\n  waiting_for_osdmap.push_back(op);\n  op->mark_delayed(\"wait for new map\");\n}\n\n\n/** update_map\n * assimilate new OSDMap(s).  scan pgs, etc.\n */\n\nvoid OSD::note_down_osd(int peer)\n{\n  assert(osd_lock.is_locked());\n  cluster_messenger->mark_down(osdmap->get_cluster_addr(peer));\n\n  heartbeat_lock.Lock();\n  failure_queue.erase(peer);\n  failure_pending.erase(peer);\n  map<int,HeartbeatInfo>::iterator p = heartbeat_peers.find(peer);\n  if (p != heartbeat_peers.end()) {\n    p->second.con_back->mark_down();\n    if (p->second.con_front) {\n      p->second.con_front->mark_down();\n    }\n    heartbeat_peers.erase(p);\n  }\n  heartbeat_lock.Unlock();\n}\n\nvoid OSD::note_up_osd(int peer)\n{\n  service.forget_peer_epoch(peer, osdmap->get_epoch() - 1);\n  heartbeat_set_peers_need_update();\n}\n\nstruct C_OnMapCommit : public Context {\n  OSD *osd;\n  epoch_t first, last;\n  MOSDMap *msg;\n  C_OnMapCommit(OSD *o, epoch_t f, epoch_t l, MOSDMap *m)\n    : osd(o), first(f), last(l), msg(m) {}\n  void finish(int r) override {\n    osd->_committed_osd_maps(first, last, msg);\n    msg->put();\n  }\n};\n\nstruct C_OnMapApply : public Context {\n  OSDService *service;\n  list<OSDMapRef> pinned_maps;\n  epoch_t e;\n  C_OnMapApply(OSDService *service,\n\t       const list<OSDMapRef> &pinned_maps,\n\t       epoch_t e)\n    : service(service), pinned_maps(pinned_maps), e(e) {}\n  void finish(int r) override {\n    service->clear_map_bl_cache_pins(e);\n  }\n};\n\nvoid OSD::osdmap_subscribe(version_t epoch, bool force_request)\n{\n  Mutex::Locker l(osdmap_subscribe_lock);\n  if (latest_subscribed_epoch >= epoch && !force_request)\n    return;\n\n  latest_subscribed_epoch = MAX(epoch, latest_subscribed_epoch);\n\n  if (monc->sub_want_increment(\"osdmap\", epoch, CEPH_SUBSCRIBE_ONETIME) ||\n      force_request) {\n    monc->renew_subs();\n  }\n}\n\nvoid OSD::trim_maps(epoch_t oldest, int nreceived, bool skip_maps)\n{\n  epoch_t min = std::min(oldest, service.map_cache.cached_key_lower_bound());\n  if (min <= superblock.oldest_map)\n    return;\n\n  int num = 0;\n  ObjectStore::Transaction t;\n  for (epoch_t e = superblock.oldest_map; e < min; ++e) {\n    dout(20) << \" removing old osdmap epoch \" << e << dendl;\n    t.remove(coll_t::meta(), get_osdmap_pobject_name(e));\n    t.remove(coll_t::meta(), get_inc_osdmap_pobject_name(e));\n    superblock.oldest_map = e + 1;\n    num++;\n    if (num >= cct->_conf->osd_target_transaction_size && num >= nreceived) {\n      service.publish_superblock(superblock);\n      write_superblock(t);\n      int tr = store->queue_transaction(service.meta_osr.get(), std::move(t), nullptr);\n      assert(tr == 0);\n      num = 0;\n      if (!skip_maps) {\n\t// skip_maps leaves us with a range of old maps if we fail to remove all\n\t// of them before moving superblock.oldest_map forward to the first map\n\t// in the incoming MOSDMap msg. so we should continue removing them in\n\t// this case, even we could do huge series of delete transactions all at\n\t// once.\n\tbreak;\n      }\n    }\n  }\n  if (num > 0) {\n    service.publish_superblock(superblock);\n    write_superblock(t);\n    int tr = store->queue_transaction(service.meta_osr.get(), std::move(t), nullptr);\n    assert(tr == 0);\n  }\n  // we should not remove the cached maps\n  assert(min <= service.map_cache.cached_key_lower_bound());\n}\n\nvoid OSD::handle_osd_map(MOSDMap *m)\n{\n  assert(osd_lock.is_locked());\n  // Keep a ref in the list until we get the newly received map written\n  // onto disk. This is important because as long as the refs are alive,\n  // the OSDMaps will be pinned in the cache and we won't try to read it\n  // off of disk. Otherwise these maps will probably not stay in the cache,\n  // and reading those OSDMaps before they are actually written can result\n  // in a crash. \n  list<OSDMapRef> pinned_maps;\n  if (m->fsid != monc->get_fsid()) {\n    dout(0) << \"handle_osd_map fsid \" << m->fsid << \" != \"\n\t    << monc->get_fsid() << dendl;\n    m->put();\n    return;\n  }\n  if (is_initializing()) {\n    dout(0) << \"ignoring osdmap until we have initialized\" << dendl;\n    m->put();\n    return;\n  }\n\n  Session *session = static_cast<Session *>(m->get_connection()->get_priv());\n  if (session && !(session->entity_name.is_mon() ||\n\t\t   session->entity_name.is_osd())) {\n    //not enough perms!\n    dout(10) << \"got osd map from Session \" << session\n             << \" which we can't take maps from (not a mon or osd)\" << dendl;\n    m->put();\n    session->put();\n    return;\n  }\n  if (session)\n    session->put();\n\n  // share with the objecter\n  if (!is_preboot())\n    service.objecter->handle_osd_map(m);\n\n  epoch_t first = m->get_first();\n  epoch_t last = m->get_last();\n  dout(3) << \"handle_osd_map epochs [\" << first << \",\" << last << \"], i have \"\n\t  << superblock.newest_map\n\t  << \", src has [\" << m->oldest_map << \",\" << m->newest_map << \"]\"\n\t  << dendl;\n\n  logger->inc(l_osd_map);\n  logger->inc(l_osd_mape, last - first + 1);\n  if (first <= superblock.newest_map)\n    logger->inc(l_osd_mape_dup, superblock.newest_map - first + 1);\n  if (service.max_oldest_map < m->oldest_map) {\n    service.max_oldest_map = m->oldest_map;\n    assert(service.max_oldest_map >= superblock.oldest_map);\n  }\n\n  // make sure there is something new, here, before we bother flushing\n  // the queues and such\n  if (last <= superblock.newest_map) {\n    dout(10) << \" no new maps here, dropping\" << dendl;\n    m->put();\n    return;\n  }\n\n  // missing some?\n  bool skip_maps = false;\n  if (first > superblock.newest_map + 1) {\n    dout(10) << \"handle_osd_map message skips epochs \"\n\t     << superblock.newest_map + 1 << \"..\" << (first-1) << dendl;\n    if (m->oldest_map <= superblock.newest_map + 1) {\n      osdmap_subscribe(superblock.newest_map + 1, false);\n      m->put();\n      return;\n    }\n    // always try to get the full range of maps--as many as we can.  this\n    //  1- is good to have\n    //  2- is at present the only way to ensure that we get a *full* map as\n    //     the first map!\n    if (m->oldest_map < first) {\n      osdmap_subscribe(m->oldest_map - 1, true);\n      m->put();\n      return;\n    }\n    skip_maps = true;\n  }\n\n  ObjectStore::Transaction t;\n  uint64_t txn_size = 0;\n\n  // store new maps: queue for disk and put in the osdmap cache\n  epoch_t start = MAX(superblock.newest_map + 1, first);\n  for (epoch_t e = start; e <= last; e++) {\n    if (txn_size >= t.get_num_bytes()) {\n      derr << __func__ << \" transaction size overflowed\" << dendl;\n      assert(txn_size < t.get_num_bytes());\n    }\n    txn_size = t.get_num_bytes();\n    map<epoch_t,bufferlist>::iterator p;\n    p = m->maps.find(e);\n    if (p != m->maps.end()) {\n      dout(10) << \"handle_osd_map  got full map for epoch \" << e << dendl;\n      OSDMap *o = new OSDMap;\n      bufferlist& bl = p->second;\n\n      o->decode(bl);\n\n      ghobject_t fulloid = get_osdmap_pobject_name(e);\n      t.write(coll_t::meta(), fulloid, 0, bl.length(), bl);\n      pin_map_bl(e, bl);\n      pinned_maps.push_back(add_map(o));\n\n      got_full_map(e);\n      continue;\n    }\n\n    p = m->incremental_maps.find(e);\n    if (p != m->incremental_maps.end()) {\n      dout(10) << \"handle_osd_map  got inc map for epoch \" << e << dendl;\n      bufferlist& bl = p->second;\n      ghobject_t oid = get_inc_osdmap_pobject_name(e);\n      t.write(coll_t::meta(), oid, 0, bl.length(), bl);\n      pin_map_inc_bl(e, bl);\n\n      OSDMap *o = new OSDMap;\n      if (e > 1) {\n\tbufferlist obl;\n        bool got = get_map_bl(e - 1, obl);\n        assert(got);\n\to->decode(obl);\n      }\n\n      OSDMap::Incremental inc;\n      bufferlist::iterator p = bl.begin();\n      inc.decode(p);\n      if (o->apply_incremental(inc) < 0) {\n\tderr << \"ERROR: bad fsid?  i have \" << osdmap->get_fsid() << \" and inc has \" << inc.fsid << dendl;\n\tassert(0 == \"bad fsid\");\n      }\n\n      bufferlist fbl;\n      o->encode(fbl, inc.encode_features | CEPH_FEATURE_RESERVED);\n\n      bool injected_failure = false;\n      if (cct->_conf->osd_inject_bad_map_crc_probability > 0 &&\n\t  (rand() % 10000) < cct->_conf->osd_inject_bad_map_crc_probability*10000.0) {\n\tderr << __func__ << \" injecting map crc failure\" << dendl;\n\tinjected_failure = true;\n      }\n\n      if ((inc.have_crc && o->get_crc() != inc.full_crc) || injected_failure) {\n\tdout(2) << \"got incremental \" << e\n\t\t<< \" but failed to encode full with correct crc; requesting\"\n\t\t<< dendl;\n\tclog->warn() << \"failed to encode map e\" << e << \" with expected crc\";\n\tdout(20) << \"my encoded map was:\\n\";\n\tfbl.hexdump(*_dout);\n\t*_dout << dendl;\n\tdelete o;\n\trequest_full_map(e, last);\n\tlast = e - 1;\n\tbreak;\n      }\n      got_full_map(e);\n\n      ghobject_t fulloid = get_osdmap_pobject_name(e);\n      t.write(coll_t::meta(), fulloid, 0, fbl.length(), fbl);\n      pin_map_bl(e, fbl);\n      pinned_maps.push_back(add_map(o));\n      continue;\n    }\n\n    assert(0 == \"MOSDMap lied about what maps it had?\");\n  }\n\n  // even if this map isn't from a mon, we may have satisfied our subscription\n  monc->sub_got(\"osdmap\", last);\n\n  if (!m->maps.empty() && requested_full_first) {\n    dout(10) << __func__ << \" still missing full maps \" << requested_full_first\n\t     << \"..\" << requested_full_last << dendl;\n    rerequest_full_maps();\n  }\n\n  if (superblock.oldest_map) {\n    // make sure we at least keep pace with incoming maps\n    trim_maps(m->oldest_map, last - first + 1, skip_maps);\n  }\n\n  if (!superblock.oldest_map || skip_maps)\n    superblock.oldest_map = first;\n  superblock.newest_map = last;\n  superblock.current_epoch = last;\n\n  // note in the superblock that we were clean thru the prior epoch\n  epoch_t boot_epoch = service.get_boot_epoch();\n  if (boot_epoch && boot_epoch >= superblock.mounted) {\n    superblock.mounted = boot_epoch;\n    superblock.clean_thru = last;\n  }\n\n  // superblock and commit\n  write_superblock(t);\n  store->queue_transaction(\n    service.meta_osr.get(),\n    std::move(t),\n    new C_OnMapApply(&service, pinned_maps, last),\n    new C_OnMapCommit(this, start, last, m), 0);\n  service.publish_superblock(superblock);\n}\n\nvoid OSD::_committed_osd_maps(epoch_t first, epoch_t last, MOSDMap *m)\n{\n  dout(10) << __func__ << \" \" << first << \"..\" << last << dendl;\n  if (is_stopping()) {\n    dout(10) << __func__ << \" bailing, we are shutting down\" << dendl;\n    return;\n  }\n  Mutex::Locker l(osd_lock);\n  if (is_stopping()) {\n    dout(10) << __func__ << \" bailing, we are shutting down\" << dendl;\n    return;\n  }\n  map_lock.get_write();\n\n  bool do_shutdown = false;\n  bool do_restart = false;\n  bool network_error = false;\n\n  // advance through the new maps\n  for (epoch_t cur = first; cur <= last; cur++) {\n    dout(10) << \" advance to epoch \" << cur\n\t     << \" (<= last \" << last\n\t     << \" <= newest_map \" << superblock.newest_map\n\t     << \")\" << dendl;\n\n    OSDMapRef newmap = get_map(cur);\n    assert(newmap);  // we just cached it above!\n\n    // start blacklisting messages sent to peers that go down.\n    service.pre_publish_map(newmap);\n\n    // kill connections to newly down osds\n    bool waited_for_reservations = false;\n    set<int> old;\n    osdmap->get_all_osds(old);\n    for (set<int>::iterator p = old.begin(); p != old.end(); ++p) {\n      if (*p != whoami &&\n\t  osdmap->is_up(*p) && // in old map\n\t  newmap->is_down(*p)) {    // but not the new one\n        if (!waited_for_reservations) {\n          service.await_reserved_maps();\n          waited_for_reservations = true;\n        }\n\tnote_down_osd(*p);\n      } else if (*p != whoami &&\n                osdmap->is_down(*p) &&\n                newmap->is_up(*p)) {\n        note_up_osd(*p);\n      }\n    }\n\n    if ((osdmap->test_flag(CEPH_OSDMAP_NOUP) !=\n        newmap->test_flag(CEPH_OSDMAP_NOUP)) ||\n        (osdmap->is_noup(whoami) != newmap->is_noup(whoami))) {\n      dout(10) << __func__ << \" NOUP flag changed in \" << newmap->get_epoch()\n\t       << dendl;\n      if (is_booting()) {\n\t// this captures the case where we sent the boot message while\n\t// NOUP was being set on the mon and our boot request was\n\t// dropped, and then later it is cleared.  it imperfectly\n\t// handles the case where our original boot message was not\n\t// dropped and we restart even though we might have booted, but\n\t// that is harmless (boot will just take slightly longer).\n\tdo_restart = true;\n      }\n    }\n    if (osdmap->require_osd_release < CEPH_RELEASE_LUMINOUS &&\n\tnewmap->require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n      dout(10) << __func__ << \" require_osd_release reached luminous in \"\n\t       << newmap->get_epoch() << dendl;\n      clear_pg_stat_queue();\n      clear_outstanding_pg_stats();\n    }\n\n    osdmap = newmap;\n    epoch_t up_epoch;\n    epoch_t boot_epoch;\n    service.retrieve_epochs(&boot_epoch, &up_epoch, NULL);\n    if (!up_epoch &&\n\tosdmap->is_up(whoami) &&\n\tosdmap->get_inst(whoami) == client_messenger->get_myinst()) {\n      up_epoch = osdmap->get_epoch();\n      dout(10) << \"up_epoch is \" << up_epoch << dendl;\n      if (!boot_epoch) {\n\tboot_epoch = osdmap->get_epoch();\n\tdout(10) << \"boot_epoch is \" << boot_epoch << dendl;\n      }\n      service.set_epochs(&boot_epoch, &up_epoch, NULL);\n    }\n  }\n\n  had_map_since = ceph_clock_now();\n\n  epoch_t _bind_epoch = service.get_bind_epoch();\n  if (osdmap->is_up(whoami) &&\n      osdmap->get_addr(whoami) == client_messenger->get_myaddr() &&\n      _bind_epoch < osdmap->get_up_from(whoami)) {\n\n    if (is_booting()) {\n      dout(1) << \"state: booting -> active\" << dendl;\n      set_state(STATE_ACTIVE);\n\n      // set incarnation so that osd_reqid_t's we generate for our\n      // objecter requests are unique across restarts.\n      service.objecter->set_client_incarnation(osdmap->get_epoch());\n    }\n  }\n\n  if (osdmap->get_epoch() > 0 &&\n      is_active()) {\n    if (!osdmap->exists(whoami)) {\n      dout(0) << \"map says i do not exist.  shutting down.\" << dendl;\n      do_shutdown = true;   // don't call shutdown() while we have\n\t\t\t    // everything paused\n    } else if (!osdmap->is_up(whoami) ||\n\t       !osdmap->get_addr(whoami).probably_equals(\n\t\t client_messenger->get_myaddr()) ||\n\t       !osdmap->get_cluster_addr(whoami).probably_equals(\n\t\t cluster_messenger->get_myaddr()) ||\n\t       !osdmap->get_hb_back_addr(whoami).probably_equals(\n\t\t hb_back_server_messenger->get_myaddr()) ||\n\t       (osdmap->get_hb_front_addr(whoami) != entity_addr_t() &&\n                !osdmap->get_hb_front_addr(whoami).probably_equals(\n\t\t  hb_front_server_messenger->get_myaddr()))) {\n      if (!osdmap->is_up(whoami)) {\n\tif (service.is_preparing_to_stop() || service.is_stopping()) {\n\t  service.got_stop_ack();\n\t} else {\n          clog->warn() << \"Monitor daemon marked osd.\" << whoami << \" down, \"\n                          \"but it is still running\";\n          clog->debug() << \"map e\" << osdmap->get_epoch()\n                        << \" wrongly marked me down at e\"\n                        << osdmap->get_down_at(whoami);\n\t}\n      } else if (!osdmap->get_addr(whoami).probably_equals(\n\t\t   client_messenger->get_myaddr())) {\n\tclog->error() << \"map e\" << osdmap->get_epoch()\n\t\t      << \" had wrong client addr (\" << osdmap->get_addr(whoami)\n\t\t      << \" != my \" << client_messenger->get_myaddr() << \")\";\n      } else if (!osdmap->get_cluster_addr(whoami).probably_equals(\n\t\t   cluster_messenger->get_myaddr())) {\n\tclog->error() << \"map e\" << osdmap->get_epoch()\n\t\t      << \" had wrong cluster addr (\"\n\t\t      << osdmap->get_cluster_addr(whoami)\n\t\t      << \" != my \" << cluster_messenger->get_myaddr() << \")\";\n      } else if (!osdmap->get_hb_back_addr(whoami).probably_equals(\n\t\t   hb_back_server_messenger->get_myaddr())) {\n\tclog->error() << \"map e\" << osdmap->get_epoch()\n\t\t      << \" had wrong heartbeat back addr (\"\n\t\t      << osdmap->get_hb_back_addr(whoami)\n\t\t      << \" != my \" << hb_back_server_messenger->get_myaddr()\n\t\t      << \")\";\n      } else if (osdmap->get_hb_front_addr(whoami) != entity_addr_t() &&\n\t\t !osdmap->get_hb_front_addr(whoami).probably_equals(\n\t\t   hb_front_server_messenger->get_myaddr())) {\n\tclog->error() << \"map e\" << osdmap->get_epoch()\n\t\t      << \" had wrong heartbeat front addr (\"\n\t\t      << osdmap->get_hb_front_addr(whoami)\n\t\t      << \" != my \" << hb_front_server_messenger->get_myaddr()\n\t\t      << \")\";\n      }\n\n      if (!service.is_stopping()) {\n        epoch_t up_epoch = 0;\n        epoch_t bind_epoch = osdmap->get_epoch();\n        service.set_epochs(NULL,&up_epoch, &bind_epoch);\n\tdo_restart = true;\n\n\t//add markdown log\n\tutime_t now = ceph_clock_now();\n\tutime_t grace = utime_t(cct->_conf->osd_max_markdown_period, 0);\n\tosd_markdown_log.push_back(now);\n\t//clear all out-of-date log\n\twhile (!osd_markdown_log.empty() &&\n\t       osd_markdown_log.front() + grace < now)\n\t  osd_markdown_log.pop_front();\n\tif ((int)osd_markdown_log.size() > cct->_conf->osd_max_markdown_count) {\n\t  dout(0) << __func__ << \" marked down \"\n\t\t  << osd_markdown_log.size()\n\t\t  << \" > osd_max_markdown_count \"\n\t\t  << cct->_conf->osd_max_markdown_count\n\t\t  << \" in last \" << grace << \" seconds, shutting down\"\n\t\t  << dendl;\n\t  do_restart = false;\n\t  do_shutdown = true;\n\t}\n\n\tstart_waiting_for_healthy();\n\n\tset<int> avoid_ports;\n#if defined(__FreeBSD__)\n        // prevent FreeBSD from grabbing the client_messenger port during\n        // rebinding. In which case a cluster_meesneger will connect also \n\t// to the same port\n\tavoid_ports.insert(client_messenger->get_myaddr().get_port());\n#endif\n\tavoid_ports.insert(cluster_messenger->get_myaddr().get_port());\n\tavoid_ports.insert(hb_back_server_messenger->get_myaddr().get_port());\n\tavoid_ports.insert(hb_front_server_messenger->get_myaddr().get_port());\n\n\tint r = cluster_messenger->rebind(avoid_ports);\n\tif (r != 0) {\n\t  do_shutdown = true;  // FIXME: do_restart?\n          network_error = true;\n          dout(0) << __func__ << \" marked down:\"\n                  << \" rebind cluster_messenger failed\" << dendl;\n        }\n\n\tr = hb_back_server_messenger->rebind(avoid_ports);\n\tif (r != 0) {\n\t  do_shutdown = true;  // FIXME: do_restart?\n          network_error = true;\n          dout(0) << __func__ << \" marked down:\"\n                  << \" rebind hb_back_server_messenger failed\" << dendl;\n        }\n\n\tr = hb_front_server_messenger->rebind(avoid_ports);\n\tif (r != 0) {\n\t  do_shutdown = true;  // FIXME: do_restart?\n          network_error = true;\n          dout(0) << __func__ << \" marked down:\" \n                  << \" rebind hb_front_server_messenger failed\" << dendl;\n        }\n\n\thb_front_client_messenger->mark_down_all();\n\thb_back_client_messenger->mark_down_all();\n\n\treset_heartbeat_peers();\n      }\n    }\n  }\n\n  map_lock.put_write();\n\n  check_osdmap_features(store);\n\n  // yay!\n  consume_map();\n\n  if (is_active() || is_waiting_for_healthy())\n    maybe_update_heartbeat_peers();\n\n  if (!is_active()) {\n    dout(10) << \" not yet active; waiting for peering wq to drain\" << dendl;\n    peering_wq.drain();\n  } else {\n    activate_map();\n  }\n\n  if (do_shutdown) {\n    if (network_error) {\n      Mutex::Locker l(heartbeat_lock);\n      map<int,pair<utime_t,entity_inst_t>>::iterator it =\n\tfailure_pending.begin();\n      while (it != failure_pending.end()) {\n        dout(10) << \"handle_osd_ping canceling in-flight failure report for osd.\"\n\t\t << it->first << dendl;\n        send_still_alive(osdmap->get_epoch(), it->second.second);\n        failure_pending.erase(it++);\n      }\n    }\n    // trigger shutdown in a different thread\n    dout(0) << __func__ << \" shutdown OSD via async signal\" << dendl;\n    queue_async_signal(SIGINT);\n  }\n  else if (m->newest_map && m->newest_map > last) {\n    dout(10) << \" msg say newest map is \" << m->newest_map\n\t     << \", requesting more\" << dendl;\n    osdmap_subscribe(osdmap->get_epoch()+1, false);\n  }\n  else if (is_preboot()) {\n    if (m->get_source().is_mon())\n      _preboot(m->oldest_map, m->newest_map);\n    else\n      start_boot();\n  }\n  else if (do_restart)\n    start_boot();\n\n}\n\nvoid OSD::check_osdmap_features(ObjectStore *fs)\n{\n  // adjust required feature bits?\n\n  // we have to be a bit careful here, because we are accessing the\n  // Policy structures without taking any lock.  in particular, only\n  // modify integer values that can safely be read by a racing CPU.\n  // since we are only accessing existing Policy structures a their\n  // current memory location, and setting or clearing bits in integer\n  // fields, and we are the only writer, this is not a problem.\n\n  {\n    Messenger::Policy p = client_messenger->get_default_policy();\n    uint64_t mask;\n    uint64_t features = osdmap->get_features(entity_name_t::TYPE_CLIENT, &mask);\n    if ((p.features_required & mask) != features) {\n      dout(0) << \"crush map has features \" << features\n\t      << \", adjusting msgr requires for clients\" << dendl;\n      p.features_required = (p.features_required & ~mask) | features;\n      client_messenger->set_default_policy(p);\n    }\n  }\n  {\n    Messenger::Policy p = client_messenger->get_policy(entity_name_t::TYPE_MON);\n    uint64_t mask;\n    uint64_t features = osdmap->get_features(entity_name_t::TYPE_MON, &mask);\n    if ((p.features_required & mask) != features) {\n      dout(0) << \"crush map has features \" << features\n\t      << \" was \" << p.features_required\n\t      << \", adjusting msgr requires for mons\" << dendl;\n      p.features_required = (p.features_required & ~mask) | features;\n      client_messenger->set_policy(entity_name_t::TYPE_MON, p);\n    }\n  }\n  {\n    Messenger::Policy p = cluster_messenger->get_policy(entity_name_t::TYPE_OSD);\n    uint64_t mask;\n    uint64_t features = osdmap->get_features(entity_name_t::TYPE_OSD, &mask);\n\n    if ((p.features_required & mask) != features) {\n      dout(0) << \"crush map has features \" << features\n\t      << \", adjusting msgr requires for osds\" << dendl;\n      p.features_required = (p.features_required & ~mask) | features;\n      cluster_messenger->set_policy(entity_name_t::TYPE_OSD, p);\n    }\n\n    if ((features & CEPH_FEATURE_OSD_ERASURE_CODES) &&\n\t!superblock.compat_features.incompat.contains(CEPH_OSD_FEATURE_INCOMPAT_SHARDS)) {\n      dout(0) << __func__ << \" enabling on-disk ERASURE CODES compat feature\" << dendl;\n      superblock.compat_features.incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_SHARDS);\n      ObjectStore::Transaction t;\n      write_superblock(t);\n      int err = store->queue_transaction(service.meta_osr.get(), std::move(t), NULL);\n      assert(err == 0);\n    }\n  }\n}\n\nbool OSD::advance_pg(\n  epoch_t osd_epoch, PG *pg,\n  ThreadPool::TPHandle &handle,\n  PG::RecoveryCtx *rctx,\n  set<PGRef> *new_pgs)\n{\n  assert(pg->is_locked());\n  epoch_t next_epoch = pg->get_osdmap()->get_epoch() + 1;\n  OSDMapRef lastmap = pg->get_osdmap();\n\n  if (lastmap->get_epoch() == osd_epoch)\n    return true;\n  assert(lastmap->get_epoch() < osd_epoch);\n\n  epoch_t min_epoch = service.get_min_pg_epoch();\n  epoch_t max;\n  if (min_epoch) {\n    max = min_epoch + cct->_conf->osd_map_max_advance;\n  } else {\n    max = next_epoch + cct->_conf->osd_map_max_advance;\n  }\n\n  for (;\n       next_epoch <= osd_epoch && next_epoch <= max;\n       ++next_epoch) {\n    OSDMapRef nextmap = service.try_get_map(next_epoch);\n    if (!nextmap) {\n      dout(20) << __func__ << \" missing map \" << next_epoch << dendl;\n      // make sure max is bumped up so that we can get past any\n      // gap in maps\n      max = MAX(max, next_epoch + cct->_conf->osd_map_max_advance);\n      continue;\n    }\n\n    vector<int> newup, newacting;\n    int up_primary, acting_primary;\n    nextmap->pg_to_up_acting_osds(\n      pg->info.pgid.pgid,\n      &newup, &up_primary,\n      &newacting, &acting_primary);\n    pg->handle_advance_map(\n      nextmap, lastmap, newup, up_primary,\n      newacting, acting_primary, rctx);\n\n    // Check for split!\n    set<spg_t> children;\n    spg_t parent(pg->info.pgid);\n    if (parent.is_split(\n\tlastmap->get_pg_num(pg->pool.id),\n\tnextmap->get_pg_num(pg->pool.id),\n\t&children)) {\n      service.mark_split_in_progress(pg->info.pgid, children);\n      split_pgs(\n\tpg, children, new_pgs, lastmap, nextmap,\n\trctx);\n    }\n\n    lastmap = nextmap;\n    handle.reset_tp_timeout();\n  }\n  service.pg_update_epoch(pg->info.pgid, lastmap->get_epoch());\n  pg->handle_activate_map(rctx);\n  if (next_epoch <= osd_epoch) {\n    dout(10) << __func__ << \" advanced to max \" << max\n\t     << \" past min epoch \" << min_epoch\n\t     << \" ... will requeue \" << *pg << dendl;\n    return false;\n  }\n  return true;\n}\n\nvoid OSD::consume_map()\n{\n  assert(osd_lock.is_locked());\n  dout(7) << \"consume_map version \" << osdmap->get_epoch() << dendl;\n\n  /** make sure the cluster is speaking in SORTBITWISE, because we don't\n   *  speak the older sorting version any more. Be careful not to force\n   *  a shutdown if we are merely processing old maps, though.\n   */\n  if (!osdmap->test_flag(CEPH_OSDMAP_SORTBITWISE) && is_active()) {\n    derr << __func__ << \" SORTBITWISE flag is not set\" << dendl;\n    ceph_abort();\n  }\n\n  int num_pg_primary = 0, num_pg_replica = 0, num_pg_stray = 0;\n  list<PGRef> to_remove;\n\n  // scan pg's\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t,PG*>::iterator it = pg_map.begin();\n        it != pg_map.end();\n        ++it) {\n      PG *pg = it->second;\n      pg->lock();\n      if (pg->is_primary())\n        num_pg_primary++;\n      else if (pg->is_replica())\n        num_pg_replica++;\n      else\n        num_pg_stray++;\n\n      if (!osdmap->have_pg_pool(pg->info.pgid.pool())) {\n        //pool is deleted!\n        to_remove.push_back(PGRef(pg));\n      } else {\n        service.init_splits_between(it->first, service.get_osdmap(), osdmap);\n      }\n\n      pg->unlock();\n    }\n\n    lock_guard<mutex> pending_creates_locker{pending_creates_lock};\n    for (auto pg = pending_creates_from_osd.cbegin();\n\t pg != pending_creates_from_osd.cend();) {\n      if (osdmap->get_pg_acting_rank(pg->first, whoami) < 0) {\n\tpg = pending_creates_from_osd.erase(pg);\n      } else {\n\t++pg;\n      }\n    }\n  }\n\n  for (list<PGRef>::iterator i = to_remove.begin();\n       i != to_remove.end();\n       to_remove.erase(i++)) {\n    RWLock::WLocker locker(pg_map_lock);\n    (*i)->lock();\n    _remove_pg(&**i);\n    (*i)->unlock();\n  }\n\n  service.expand_pg_num(service.get_osdmap(), osdmap);\n\n  service.pre_publish_map(osdmap);\n  service.await_reserved_maps();\n  service.publish_map(osdmap);\n\n  service.maybe_inject_dispatch_delay();\n\n  dispatch_sessions_waiting_on_map();\n\n  service.maybe_inject_dispatch_delay();\n\n  // remove any PGs which we no longer host from the session waiting_for_pg lists\n  dout(20) << __func__ << \" checking waiting_for_pg\" << dendl;\n  op_shardedwq.prune_pg_waiters(osdmap, whoami);\n\n  service.maybe_inject_dispatch_delay();\n\n  // scan pg's\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t,PG*>::iterator it = pg_map.begin();\n        it != pg_map.end();\n        ++it) {\n      PG *pg = it->second;\n      pg->lock();\n      pg->queue_null(osdmap->get_epoch(), osdmap->get_epoch());\n      pg->unlock();\n    }\n\n    logger->set(l_osd_pg, pg_map.size());\n  }\n  logger->set(l_osd_pg_primary, num_pg_primary);\n  logger->set(l_osd_pg_replica, num_pg_replica);\n  logger->set(l_osd_pg_stray, num_pg_stray);\n  logger->set(l_osd_pg_removing, remove_wq.get_remove_queue_len());\n}\n\nvoid OSD::activate_map()\n{\n  assert(osd_lock.is_locked());\n\n  dout(7) << \"activate_map version \" << osdmap->get_epoch() << dendl;\n\n  if (osdmap->test_flag(CEPH_OSDMAP_FULL)) {\n    dout(10) << \" osdmap flagged full, doing onetime osdmap subscribe\" << dendl;\n    osdmap_subscribe(osdmap->get_epoch() + 1, false);\n  }\n\n  // norecover?\n  if (osdmap->test_flag(CEPH_OSDMAP_NORECOVER)) {\n    if (!service.recovery_is_paused()) {\n      dout(1) << \"pausing recovery (NORECOVER flag set)\" << dendl;\n      service.pause_recovery();\n    }\n  } else {\n    if (service.recovery_is_paused()) {\n      dout(1) << \"unpausing recovery (NORECOVER flag unset)\" << dendl;\n      service.unpause_recovery();\n    }\n  }\n\n  service.activate_map();\n\n  // process waiters\n  take_waiters(waiting_for_osdmap);\n}\n\nbool OSD::require_mon_peer(const Message *m)\n{\n  if (!m->get_connection()->peer_is_mon()) {\n    dout(0) << \"require_mon_peer received from non-mon \"\n\t    << m->get_connection()->get_peer_addr()\n\t    << \" \" << *m << dendl;\n    return false;\n  }\n  return true;\n}\n\nbool OSD::require_mon_or_mgr_peer(const Message *m)\n{\n  if (!m->get_connection()->peer_is_mon() &&\n      !m->get_connection()->peer_is_mgr()) {\n    dout(0) << \"require_mon_or_mgr_peer received from non-mon, non-mgr \"\n\t    << m->get_connection()->get_peer_addr()\n\t    << \" \" << *m << dendl;\n    return false;\n  }\n  return true;\n}\n\nbool OSD::require_osd_peer(const Message *m)\n{\n  if (!m->get_connection()->peer_is_osd()) {\n    dout(0) << \"require_osd_peer received from non-osd \"\n\t    << m->get_connection()->get_peer_addr()\n\t    << \" \" << *m << dendl;\n    return false;\n  }\n  return true;\n}\n\nbool OSD::require_self_aliveness(const Message *m, epoch_t epoch)\n{\n  epoch_t up_epoch = service.get_up_epoch();\n  if (epoch < up_epoch) {\n    dout(7) << \"from pre-up epoch \" << epoch << \" < \" << up_epoch << dendl;\n    return false;\n  }\n\n  if (!is_active()) {\n    dout(7) << \"still in boot state, dropping message \" << *m << dendl;\n    return false;\n  }\n\n  return true;\n}\n\nbool OSD::require_same_peer_instance(const Message *m, OSDMapRef& map,\n\t\t\t\t     bool is_fast_dispatch)\n{\n  int from = m->get_source().num();\n\n  if (map->is_down(from) ||\n      (map->get_cluster_addr(from) != m->get_source_inst().addr)) {\n    dout(5) << \"from dead osd.\" << from << \", marking down, \"\n\t    << \" msg was \" << m->get_source_inst().addr\n\t    << \" expected \" << (map->is_up(from) ?\n\t\t\t\tmap->get_cluster_addr(from) : entity_addr_t())\n\t    << dendl;\n    ConnectionRef con = m->get_connection();\n    con->mark_down();\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (s) {\n      if (!is_fast_dispatch)\n\ts->session_dispatch_lock.Lock();\n      clear_session_waiting_on_map(s);\n      con->set_priv(NULL);   // break ref <-> session cycle, if any\n      if (!is_fast_dispatch)\n\ts->session_dispatch_lock.Unlock();\n      s->put();\n    }\n    return false;\n  }\n  return true;\n}\n\n\n/*\n * require that we have same (or newer) map, and that\n * the source is the pg primary.\n */\nbool OSD::require_same_or_newer_map(OpRequestRef& op, epoch_t epoch,\n\t\t\t\t    bool is_fast_dispatch)\n{\n  const Message *m = op->get_req();\n  dout(15) << \"require_same_or_newer_map \" << epoch\n\t   << \" (i am \" << osdmap->get_epoch() << \") \" << m << dendl;\n\n  assert(osd_lock.is_locked());\n\n  // do they have a newer map?\n  if (epoch > osdmap->get_epoch()) {\n    dout(7) << \"waiting for newer map epoch \" << epoch\n\t    << \" > my \" << osdmap->get_epoch() << \" with \" << m << dendl;\n    wait_for_new_map(op);\n    return false;\n  }\n\n  if (!require_self_aliveness(op->get_req(), epoch)) {\n    return false;\n  }\n\n  // ok, our map is same or newer.. do they still exist?\n  if (m->get_connection()->get_messenger() == cluster_messenger &&\n      !require_same_peer_instance(op->get_req(), osdmap, is_fast_dispatch)) {\n    return false;\n  }\n\n  return true;\n}\n\n\n\n\n\n// ----------------------------------------\n// pg creation\n\nvoid OSD::split_pgs(\n  PG *parent,\n  const set<spg_t> &childpgids, set<PGRef> *out_pgs,\n  OSDMapRef curmap,\n  OSDMapRef nextmap,\n  PG::RecoveryCtx *rctx)\n{\n  unsigned pg_num = nextmap->get_pg_num(\n    parent->pool.id);\n  parent->update_snap_mapper_bits(\n    parent->info.pgid.get_split_bits(pg_num)\n    );\n\n  vector<object_stat_sum_t> updated_stats(childpgids.size() + 1);\n  parent->info.stats.stats.sum.split(updated_stats);\n\n  vector<object_stat_sum_t>::iterator stat_iter = updated_stats.begin();\n  for (set<spg_t>::const_iterator i = childpgids.begin();\n       i != childpgids.end();\n       ++i, ++stat_iter) {\n    assert(stat_iter != updated_stats.end());\n    dout(10) << \"Splitting \" << *parent << \" into \" << *i << dendl;\n    assert(service.splitting(*i));\n    PG* child = _make_pg(nextmap, *i);\n    child->lock(true);\n    out_pgs->insert(child);\n    rctx->created_pgs.insert(child);\n\n    unsigned split_bits = i->get_split_bits(pg_num);\n    dout(10) << \"pg_num is \" << pg_num << dendl;\n    dout(10) << \"m_seed \" << i->ps() << dendl;\n    dout(10) << \"split_bits is \" << split_bits << dendl;\n\n    parent->split_colls(\n      *i,\n      split_bits,\n      i->ps(),\n      &child->pool.info,\n      rctx->transaction);\n    parent->split_into(\n      i->pgid,\n      child,\n      split_bits);\n    child->info.stats.stats.sum = *stat_iter;\n\n    child->write_if_dirty(*(rctx->transaction));\n    child->unlock();\n  }\n  assert(stat_iter != updated_stats.end());\n  parent->info.stats.stats.sum = *stat_iter;\n  parent->write_if_dirty(*(rctx->transaction));\n}\n\n/*\n * holding osd_lock\n */\nvoid OSD::handle_pg_create(OpRequestRef op)\n{\n  const MOSDPGCreate *m = static_cast<const MOSDPGCreate*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_CREATE);\n\n  dout(10) << \"handle_pg_create \" << *m << dendl;\n\n  if (!require_mon_peer(op->get_req())) {\n    return;\n  }\n\n  if (!require_same_or_newer_map(op, m->epoch, false))\n    return;\n\n  op->mark_started();\n\n  map<pg_t,utime_t>::const_iterator ci = m->ctimes.begin();\n  for (map<pg_t,pg_create_t>::const_iterator p = m->mkpg.begin();\n       p != m->mkpg.end();\n       ++p, ++ci) {\n    assert(ci != m->ctimes.end() && ci->first == p->first);\n    epoch_t created = p->second.created;\n    if (p->second.split_bits) // Skip split pgs\n      continue;\n    pg_t on = p->first;\n\n    if (on.preferred() >= 0) {\n      dout(20) << \"ignoring localized pg \" << on << dendl;\n      continue;\n    }\n\n    if (!osdmap->have_pg_pool(on.pool())) {\n      dout(20) << \"ignoring pg on deleted pool \" << on << dendl;\n      continue;\n    }\n\n    dout(20) << \"mkpg \" << on << \" e\" << created << \"@\" << ci->second << dendl;\n\n    // is it still ours?\n    vector<int> up, acting;\n    int up_primary = -1;\n    int acting_primary = -1;\n    osdmap->pg_to_up_acting_osds(on, &up, &up_primary, &acting, &acting_primary);\n    int role = osdmap->calc_pg_role(whoami, acting, acting.size());\n\n    if (acting_primary != whoami) {\n      dout(10) << \"mkpg \" << on << \"  not acting_primary (\" << acting_primary\n\t       << \"), my role=\" << role << \", skipping\" << dendl;\n      continue;\n    }\n\n    spg_t pgid;\n    bool mapped = osdmap->get_primary_shard(on, &pgid);\n    assert(mapped);\n\n    PastIntervals pi(\n      osdmap->get_pools().at(pgid.pool()).ec_pool(),\n      *osdmap);\n    pg_history_t history;\n    build_initial_pg_history(pgid, created, ci->second, &history, &pi);\n\n    // The mon won't resend unless the primary changed, so\n    // we ignore same_interval_since.  We'll pass this history\n    // to handle_pg_peering_evt with the current epoch as the\n    // event -- the project_pg_history check in\n    // handle_pg_peering_evt will be a noop.\n    if (history.same_primary_since > m->epoch) {\n      dout(10) << __func__ << \": got obsolete pg create on pgid \"\n\t       << pgid << \" from epoch \" << m->epoch\n\t       << \", primary changed in \" << history.same_primary_since\n\t       << dendl;\n      continue;\n    }\n    if (handle_pg_peering_evt(\n          pgid,\n          history,\n          pi,\n          osdmap->get_epoch(),\n          PG::CephPeeringEvtRef(\n\t    new PG::CephPeeringEvt(\n\t      osdmap->get_epoch(),\n\t      osdmap->get_epoch(),\n\t      PG::NullEvt()))\n          ) == -EEXIST) {\n      service.send_pg_created(pgid.pgid);\n    }\n  }\n\n  {\n    lock_guard<mutex> pending_creates_locker{pending_creates_lock};\n    if (pending_creates_from_mon == 0) {\n      last_pg_create_epoch = m->epoch;\n    }\n  }\n  maybe_update_heartbeat_peers();\n}\n\n\n// ----------------------------------------\n// peering and recovery\n\nPG::RecoveryCtx OSD::create_context()\n{\n  ObjectStore::Transaction *t = new ObjectStore::Transaction;\n  C_Contexts *on_applied = new C_Contexts(cct);\n  C_Contexts *on_safe = new C_Contexts(cct);\n  map<int, map<spg_t,pg_query_t> > *query_map =\n    new map<int, map<spg_t, pg_query_t> >;\n  map<int,vector<pair<pg_notify_t, PastIntervals> > > *notify_list =\n    new map<int, vector<pair<pg_notify_t, PastIntervals> > >;\n  map<int,vector<pair<pg_notify_t, PastIntervals> > > *info_map =\n    new map<int,vector<pair<pg_notify_t, PastIntervals> > >;\n  PG::RecoveryCtx rctx(query_map, info_map, notify_list,\n\t\t       on_applied, on_safe, t);\n  return rctx;\n}\n\nstruct C_OpenPGs : public Context {\n  set<PGRef> pgs;\n  ObjectStore *store;\n  OSD *osd;\n  C_OpenPGs(set<PGRef>& p, ObjectStore *s, OSD* o) : store(s), osd(o) {\n    pgs.swap(p);\n  }\n  void finish(int r) override {\n    RWLock::RLocker l(osd->pg_map_lock);\n    for (auto p : pgs) {\n      if (osd->pg_map.count(p->info.pgid)) {\n        p->ch = store->open_collection(p->coll);\n        assert(p->ch);\n      }\n    }\n  }\n};\n\nvoid OSD::dispatch_context_transaction(PG::RecoveryCtx &ctx, PG *pg,\n                                       ThreadPool::TPHandle *handle)\n{\n  if (!ctx.transaction->empty()) {\n    if (!ctx.created_pgs.empty()) {\n      ctx.on_applied->add(new C_OpenPGs(ctx.created_pgs, store, this));\n    }\n    int tr = store->queue_transaction(\n      pg->osr.get(),\n      std::move(*ctx.transaction), ctx.on_applied, ctx.on_safe, NULL,\n      TrackedOpRef(), handle);\n    delete (ctx.transaction);\n    assert(tr == 0);\n    ctx.transaction = new ObjectStore::Transaction;\n    ctx.on_applied = new C_Contexts(cct);\n    ctx.on_safe = new C_Contexts(cct);\n  }\n}\n\nvoid OSD::dispatch_context(PG::RecoveryCtx &ctx, PG *pg, OSDMapRef curmap,\n                           ThreadPool::TPHandle *handle)\n{\n  if (service.get_osdmap()->is_up(whoami) &&\n      is_active()) {\n    do_notifies(*ctx.notify_list, curmap);\n    do_queries(*ctx.query_map, curmap);\n    do_infos(*ctx.info_map, curmap);\n  }\n  delete ctx.notify_list;\n  delete ctx.query_map;\n  delete ctx.info_map;\n  if ((ctx.on_applied->empty() &&\n       ctx.on_safe->empty() &&\n       ctx.transaction->empty() &&\n       ctx.created_pgs.empty()) || !pg) {\n    delete ctx.transaction;\n    delete ctx.on_applied;\n    delete ctx.on_safe;\n    assert(ctx.created_pgs.empty());\n  } else {\n    if (!ctx.created_pgs.empty()) {\n      ctx.on_applied->add(new C_OpenPGs(ctx.created_pgs, store, this));\n    }\n    int tr = store->queue_transaction(\n      pg->osr.get(),\n      std::move(*ctx.transaction), ctx.on_applied, ctx.on_safe, NULL, TrackedOpRef(),\n      handle);\n    delete (ctx.transaction);\n    assert(tr == 0);\n  }\n}\n\n/** do_notifies\n * Send an MOSDPGNotify to a primary, with a list of PGs that I have\n * content for, and they are primary for.\n */\n\nvoid OSD::do_notifies(\n  map<int,vector<pair<pg_notify_t,PastIntervals> > >& notify_list,\n  OSDMapRef curmap)\n{\n  for (map<int,\n\t   vector<pair<pg_notify_t,PastIntervals> > >::iterator it =\n\t notify_list.begin();\n       it != notify_list.end();\n       ++it) {\n    if (!curmap->is_up(it->first)) {\n      dout(20) << __func__ << \" skipping down osd.\" << it->first << dendl;\n      continue;\n    }\n    ConnectionRef con = service.get_con_osd_cluster(\n      it->first, curmap->get_epoch());\n    if (!con) {\n      dout(20) << __func__ << \" skipping osd.\" << it->first\n\t       << \" (NULL con)\" << dendl;\n      continue;\n    }\n    service.share_map_peer(it->first, con.get(), curmap);\n    dout(7) << __func__ << \" osd.\" << it->first\n\t    << \" on \" << it->second.size() << \" PGs\" << dendl;\n    MOSDPGNotify *m = new MOSDPGNotify(curmap->get_epoch(),\n\t\t\t\t       it->second);\n    con->send_message(m);\n  }\n}\n\n\n/** do_queries\n * send out pending queries for info | summaries\n */\nvoid OSD::do_queries(map<int, map<spg_t,pg_query_t> >& query_map,\n\t\t     OSDMapRef curmap)\n{\n  for (map<int, map<spg_t,pg_query_t> >::iterator pit = query_map.begin();\n       pit != query_map.end();\n       ++pit) {\n    if (!curmap->is_up(pit->first)) {\n      dout(20) << __func__ << \" skipping down osd.\" << pit->first << dendl;\n      continue;\n    }\n    int who = pit->first;\n    ConnectionRef con = service.get_con_osd_cluster(who, curmap->get_epoch());\n    if (!con) {\n      dout(20) << __func__ << \" skipping osd.\" << who\n\t       << \" (NULL con)\" << dendl;\n      continue;\n    }\n    service.share_map_peer(who, con.get(), curmap);\n    dout(7) << __func__ << \" querying osd.\" << who\n\t    << \" on \" << pit->second.size() << \" PGs\" << dendl;\n    MOSDPGQuery *m = new MOSDPGQuery(curmap->get_epoch(), pit->second);\n    con->send_message(m);\n  }\n}\n\n\nvoid OSD::do_infos(map<int,\n\t\t       vector<pair<pg_notify_t, PastIntervals> > >& info_map,\n\t\t   OSDMapRef curmap)\n{\n  for (map<int,\n\t   vector<pair<pg_notify_t, PastIntervals> > >::iterator p =\n\t info_map.begin();\n       p != info_map.end();\n       ++p) {\n    if (!curmap->is_up(p->first)) {\n      dout(20) << __func__ << \" skipping down osd.\" << p->first << dendl;\n      continue;\n    }\n    for (vector<pair<pg_notify_t,PastIntervals> >::iterator i = p->second.begin();\n\t i != p->second.end();\n\t ++i) {\n      dout(20) << __func__ << \" sending info \" << i->first.info\n\t       << \" to shard \" << p->first << dendl;\n    }\n    ConnectionRef con = service.get_con_osd_cluster(\n      p->first, curmap->get_epoch());\n    if (!con) {\n      dout(20) << __func__ << \" skipping osd.\" << p->first\n\t       << \" (NULL con)\" << dendl;\n      continue;\n    }\n    service.share_map_peer(p->first, con.get(), curmap);\n    MOSDPGInfo *m = new MOSDPGInfo(curmap->get_epoch());\n    m->pg_list = p->second;\n    con->send_message(m);\n  }\n  info_map.clear();\n}\n\n\n/** PGNotify\n * from non-primary to primary\n * includes pg_info_t.\n * NOTE: called with opqueue active.\n */\nvoid OSD::handle_pg_notify(OpRequestRef op)\n{\n  const MOSDPGNotify *m = static_cast<const MOSDPGNotify*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_NOTIFY);\n\n  dout(7) << \"handle_pg_notify from \" << m->get_source() << dendl;\n  int from = m->get_source().num();\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  if (!require_same_or_newer_map(op, m->get_epoch(), false))\n    return;\n\n  op->mark_started();\n\n  for (auto it = m->get_pg_list().begin();\n       it != m->get_pg_list().end();\n       ++it) {\n    if (it->first.info.pgid.preferred() >= 0) {\n      dout(20) << \"ignoring localized pg \" << it->first.info.pgid << dendl;\n      continue;\n    }\n\n    handle_pg_peering_evt(\n      spg_t(it->first.info.pgid.pgid, it->first.to),\n      it->first.info.history, it->second,\n      it->first.query_epoch,\n      PG::CephPeeringEvtRef(\n\tnew PG::CephPeeringEvt(\n\t  it->first.epoch_sent, it->first.query_epoch,\n\t  PG::MNotifyRec(pg_shard_t(from, it->first.from), it->first,\n          op->get_req()->get_connection()->get_features())))\n      );\n  }\n}\n\nvoid OSD::handle_pg_log(OpRequestRef op)\n{\n  MOSDPGLog *m = static_cast<MOSDPGLog*>(op->get_nonconst_req());\n  assert(m->get_type() == MSG_OSD_PG_LOG);\n  dout(7) << \"handle_pg_log \" << *m << \" from \" << m->get_source() << dendl;\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  int from = m->get_source().num();\n  if (!require_same_or_newer_map(op, m->get_epoch(), false))\n    return;\n\n  if (m->info.pgid.preferred() >= 0) {\n    dout(10) << \"ignoring localized pg \" << m->info.pgid << dendl;\n    return;\n  }\n\n  op->mark_started();\n  handle_pg_peering_evt(\n    spg_t(m->info.pgid.pgid, m->to),\n    m->info.history, m->past_intervals, m->get_epoch(),\n    PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->get_epoch(), m->get_query_epoch(),\n\tPG::MLogRec(pg_shard_t(from, m->from), m)))\n    );\n}\n\nvoid OSD::handle_pg_info(OpRequestRef op)\n{\n  const MOSDPGInfo *m = static_cast<const MOSDPGInfo *>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_INFO);\n  dout(7) << \"handle_pg_info \" << *m << \" from \" << m->get_source() << dendl;\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  int from = m->get_source().num();\n  if (!require_same_or_newer_map(op, m->get_epoch(), false))\n    return;\n\n  op->mark_started();\n\n  for (auto p = m->pg_list.begin();\n       p != m->pg_list.end();\n       ++p) {\n    if (p->first.info.pgid.preferred() >= 0) {\n      dout(10) << \"ignoring localized pg \" << p->first.info.pgid << dendl;\n      continue;\n    }\n\n    handle_pg_peering_evt(\n      spg_t(p->first.info.pgid.pgid, p->first.to),\n      p->first.info.history, p->second, p->first.epoch_sent,\n      PG::CephPeeringEvtRef(\n\tnew PG::CephPeeringEvt(\n\t  p->first.epoch_sent, p->first.query_epoch,\n\t  PG::MInfoRec(\n\t    pg_shard_t(\n\t      from, p->first.from), p->first.info, p->first.epoch_sent)))\n      );\n  }\n}\n\nvoid OSD::handle_pg_trim(OpRequestRef op)\n{\n  const MOSDPGTrim *m = static_cast<const MOSDPGTrim*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_TRIM);\n\n  dout(7) << \"handle_pg_trim \" << *m << \" from \" << m->get_source() << dendl;\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  int from = m->get_source().num();\n  if (!require_same_or_newer_map(op, m->epoch, false))\n    return;\n\n  if (m->pgid.preferred() >= 0) {\n    dout(10) << \"ignoring localized pg \" << m->pgid << dendl;\n    return;\n  }\n\n  op->mark_started();\n\n  PG *pg = _lookup_lock_pg(m->pgid);\n  if(!pg) {\n    dout(10) << \" don't have pg \" << m->pgid << dendl;\n    return;\n  }\n\n  if (m->epoch < pg->info.history.same_interval_since) {\n    dout(10) << *pg << \" got old trim to \" << m->trim_to << \", ignoring\" << dendl;\n    pg->unlock();\n    return;\n  }\n\n  if (pg->is_primary()) {\n    // peer is informing us of their last_complete_ondisk\n    dout(10) << *pg << \" replica osd.\" << from << \" lcod \" << m->trim_to << dendl;\n    pg->peer_last_complete_ondisk[pg_shard_t(from, m->pgid.shard)] =\n      m->trim_to;\n    // trim log when the pg is recovered\n    pg->calc_min_last_complete_ondisk();\n  } else {\n    // primary is instructing us to trim\n    ObjectStore::Transaction t;\n    pg->pg_log.trim(m->trim_to, pg->info);\n    pg->dirty_info = true;\n    pg->write_if_dirty(t);\n    int tr = store->queue_transaction(pg->osr.get(), std::move(t), NULL);\n    assert(tr == 0);\n  }\n  pg->unlock();\n}\n\nvoid OSD::handle_pg_backfill_reserve(OpRequestRef op)\n{\n  const MBackfillReserve *m = static_cast<const MBackfillReserve*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_BACKFILL_RESERVE);\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n  if (!require_same_or_newer_map(op, m->query_epoch, false))\n    return;\n\n  PG::CephPeeringEvtRef evt;\n  if (m->type == MBackfillReserve::REQUEST) {\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RequestBackfillPrio(m->priority)));\n  } else if (m->type == MBackfillReserve::GRANT) {\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RemoteBackfillReserved()));\n  } else if (m->type == MBackfillReserve::REJECT) {\n    // NOTE: this is replica -> primary \"i reject your request\"\n    //      and also primary -> replica \"cancel my previously-granted request\"\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RemoteReservationRejected()));\n  } else {\n    ceph_abort();\n  }\n\n  if (service.splitting(m->pgid)) {\n    peering_wait_for_split[m->pgid].push_back(evt);\n    return;\n  }\n\n  PG *pg = _lookup_lock_pg(m->pgid);\n  if (!pg) {\n    dout(10) << \" don't have pg \" << m->pgid << dendl;\n    return;\n  }\n\n  pg->queue_peering_event(evt);\n  pg->unlock();\n}\n\nvoid OSD::handle_pg_recovery_reserve(OpRequestRef op)\n{\n  const MRecoveryReserve *m = static_cast<const MRecoveryReserve*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_RECOVERY_RESERVE);\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n  if (!require_same_or_newer_map(op, m->query_epoch, false))\n    return;\n\n  PG::CephPeeringEvtRef evt;\n  if (m->type == MRecoveryReserve::REQUEST) {\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RequestRecovery()));\n  } else if (m->type == MRecoveryReserve::GRANT) {\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RemoteRecoveryReserved()));\n  } else if (m->type == MRecoveryReserve::RELEASE) {\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RecoveryDone()));\n  } else {\n    ceph_abort();\n  }\n\n  if (service.splitting(m->pgid)) {\n    peering_wait_for_split[m->pgid].push_back(evt);\n    return;\n  }\n\n  PG *pg = _lookup_lock_pg(m->pgid);\n  if (!pg) {\n    dout(10) << \" don't have pg \" << m->pgid << dendl;\n    return;\n  }\n\n  pg->queue_peering_event(evt);\n  pg->unlock();\n}\n\nvoid OSD::handle_force_recovery(Message *m)\n{\n  MOSDForceRecovery *msg = static_cast<MOSDForceRecovery*>(m);\n  assert(msg->get_type() == MSG_OSD_FORCE_RECOVERY);\n\n  vector<PGRef> local_pgs;\n  local_pgs.reserve(msg->forced_pgs.size());\n\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (auto& i : msg->forced_pgs) {\n      spg_t locpg;\n      if (osdmap->get_primary_shard(i, &locpg)) {\n\tauto pg_map_entry = pg_map.find(locpg);\n\tif (pg_map_entry != pg_map.end()) {\n\t  local_pgs.push_back(pg_map_entry->second);\n\t}\n      }\n    }\n  }\n\n  if (local_pgs.size()) {\n    service.adjust_pg_priorities(local_pgs, msg->options);\n  }\n\n  msg->put();\n}\n\n/** PGQuery\n * from primary to replica | stray\n * NOTE: called with opqueue active.\n */\nvoid OSD::handle_pg_query(OpRequestRef op)\n{\n  assert(osd_lock.is_locked());\n\n  const MOSDPGQuery *m = static_cast<const MOSDPGQuery*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_QUERY);\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  dout(7) << \"handle_pg_query from \" << m->get_source() << \" epoch \" << m->get_epoch() << dendl;\n  int from = m->get_source().num();\n\n  if (!require_same_or_newer_map(op, m->get_epoch(), false))\n    return;\n\n  op->mark_started();\n\n  map< int, vector<pair<pg_notify_t, PastIntervals> > > notify_list;\n\n  for (auto it = m->pg_list.begin();\n       it != m->pg_list.end();\n       ++it) {\n    spg_t pgid = it->first;\n\n    if (pgid.preferred() >= 0) {\n      dout(10) << \"ignoring localized pg \" << pgid << dendl;\n      continue;\n    }\n\n    if (service.splitting(pgid)) {\n      peering_wait_for_split[pgid].push_back(\n\tPG::CephPeeringEvtRef(\n\t  new PG::CephPeeringEvt(\n\t    it->second.epoch_sent, it->second.epoch_sent,\n\t    PG::MQuery(pg_shard_t(from, it->second.from),\n\t\t       it->second, it->second.epoch_sent))));\n      continue;\n    }\n\n    {\n      RWLock::RLocker l(pg_map_lock);\n      if (pg_map.count(pgid)) {\n        PG *pg = 0;\n        pg = _lookup_lock_pg_with_map_lock_held(pgid);\n        pg->queue_query(\n            it->second.epoch_sent, it->second.epoch_sent,\n            pg_shard_t(from, it->second.from), it->second);\n        pg->unlock();\n        continue;\n      }\n    }\n\n    if (!osdmap->have_pg_pool(pgid.pool()))\n      continue;\n\n    // get active crush mapping\n    int up_primary, acting_primary;\n    vector<int> up, acting;\n    osdmap->pg_to_up_acting_osds(\n      pgid.pgid, &up, &up_primary, &acting, &acting_primary);\n\n    // same primary?\n    pg_history_t history = it->second.history;\n    bool valid_history = project_pg_history(\n      pgid, history, it->second.epoch_sent,\n      up, up_primary, acting, acting_primary);\n\n    if (!valid_history ||\n        it->second.epoch_sent < history.same_interval_since) {\n      dout(10) << \" pg \" << pgid << \" dne, and pg has changed in \"\n\t       << history.same_interval_since\n\t       << \" (msg from \" << it->second.epoch_sent << \")\" << dendl;\n      continue;\n    }\n\n    dout(10) << \" pg \" << pgid << \" dne\" << dendl;\n    pg_info_t empty(spg_t(pgid.pgid, it->second.to));\n    /* This is racy, but that should be ok: if we complete the deletion\n     * before the pg is recreated, we'll just start it off backfilling\n     * instead of just empty */\n    if (service.deleting_pgs.lookup(pgid))\n      empty.set_last_backfill(hobject_t());\n    if (it->second.type == pg_query_t::LOG ||\n\tit->second.type == pg_query_t::FULLLOG) {\n      ConnectionRef con = service.get_con_osd_cluster(from, osdmap->get_epoch());\n      if (con) {\n\tMOSDPGLog *mlog = new MOSDPGLog(\n\t  it->second.from, it->second.to,\n\t  osdmap->get_epoch(), empty,\n\t  it->second.epoch_sent);\n\tservice.share_map_peer(from, con.get(), osdmap);\n\tcon->send_message(mlog);\n      }\n    } else {\n      notify_list[from].push_back(\n\tmake_pair(\n\t  pg_notify_t(\n\t    it->second.from, it->second.to,\n\t    it->second.epoch_sent,\n\t    osdmap->get_epoch(),\n\t    empty),\n\t  PastIntervals(\n\t    osdmap->get_pools().at(pgid.pool()).ec_pool(),\n\t    *osdmap)));\n    }\n  }\n  do_notifies(notify_list, osdmap);\n}\n\n\nvoid OSD::handle_pg_remove(OpRequestRef op)\n{\n  const MOSDPGRemove *m = static_cast<const MOSDPGRemove *>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_REMOVE);\n  assert(osd_lock.is_locked());\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  dout(7) << \"handle_pg_remove from \" << m->get_source() << \" on \"\n\t  << m->pg_list.size() << \" pgs\" << dendl;\n\n  if (!require_same_or_newer_map(op, m->get_epoch(), false))\n    return;\n\n  op->mark_started();\n\n  for (auto it = m->pg_list.begin();\n       it != m->pg_list.end();\n       ++it) {\n    spg_t pgid = *it;\n    if (pgid.preferred() >= 0) {\n      dout(10) << \"ignoring localized pg \" << pgid << dendl;\n      continue;\n    }\n\n    RWLock::WLocker l(pg_map_lock);\n    if (pg_map.count(pgid) == 0) {\n      dout(10) << \" don't have pg \" << pgid << dendl;\n      continue;\n    }\n    dout(5) << \"queue_pg_for_deletion: \" << pgid << dendl;\n    PG *pg = _lookup_lock_pg_with_map_lock_held(pgid);\n    pg_history_t history = pg->info.history;\n    int up_primary, acting_primary;\n    vector<int> up, acting;\n    osdmap->pg_to_up_acting_osds(\n      pgid.pgid, &up, &up_primary, &acting, &acting_primary);\n    bool valid_history = project_pg_history(\n      pg->info.pgid, history, pg->get_osdmap()->get_epoch(),\n      up, up_primary, acting, acting_primary);\n    if (valid_history &&\n        history.same_interval_since <= m->get_epoch()) {\n      assert(pg->get_primary().osd == m->get_source().num());\n      PGRef _pg(pg);\n      _remove_pg(pg);\n      pg->unlock();\n    } else {\n      dout(10) << *pg << \" ignoring remove request, pg changed in epoch \"\n\t       << history.same_interval_since\n\t       << \" > \" << m->get_epoch() << dendl;\n      pg->unlock();\n    }\n  }\n}\n\nvoid OSD::_remove_pg(PG *pg)\n{\n  ObjectStore::Transaction rmt ;\n\n  // on_removal, which calls remove_watchers_and_notifies, and the erasure from\n  // the pg_map must be done together without unlocking the pg lock,\n  // to avoid racing with watcher cleanup in ms_handle_reset\n  // and handle_notify_timeout\n  pg->on_removal(&rmt);\n\n  service.cancel_pending_splits_for_parent(pg->info.pgid);\n  int tr = store->queue_transaction(\n    pg->osr.get(), std::move(rmt), NULL, \n    new ContainerContext<\n      SequencerRef>(pg->osr));\n  assert(tr == 0);\n\n  DeletingStateRef deleting = service.deleting_pgs.lookup_or_create(\n    pg->info.pgid,\n    make_pair(\n      pg->info.pgid,\n      PGRef(pg))\n    );\n  remove_wq.queue(make_pair(PGRef(pg), deleting));\n\n  service.pg_remove_epoch(pg->info.pgid);\n\n  // dereference from op_wq\n  op_shardedwq.clear_pg_pointer(pg->info.pgid);\n\n  // remove from map\n  pg_map.erase(pg->info.pgid);\n  pg->put(\"PGMap\"); // since we've taken it out of map\n}\n\n// =========================================================\n// RECOVERY\n\nvoid OSDService::_maybe_queue_recovery() {\n  assert(recovery_lock.is_locked_by_me());\n  uint64_t available_pushes;\n  while (!awaiting_throttle.empty() &&\n\t _recover_now(&available_pushes)) {\n    uint64_t to_start = MIN(\n      available_pushes,\n      cct->_conf->osd_recovery_max_single_start);\n    _queue_for_recovery(awaiting_throttle.front(), to_start);\n    awaiting_throttle.pop_front();\n    recovery_ops_reserved += to_start;\n  }\n}\n\nbool OSDService::_recover_now(uint64_t *available_pushes)\n{\n  if (available_pushes)\n      *available_pushes = 0;\n\n  if (ceph_clock_now() < defer_recovery_until) {\n    dout(15) << __func__ << \" defer until \" << defer_recovery_until << dendl;\n    return false;\n  }\n\n  if (recovery_paused) {\n    dout(15) << __func__ << \" paused\" << dendl;\n    return false;\n  }\n\n  uint64_t max = cct->_conf->osd_recovery_max_active;\n  if (max <= recovery_ops_active + recovery_ops_reserved) {\n    dout(15) << __func__ << \" active \" << recovery_ops_active\n\t     << \" + reserved \" << recovery_ops_reserved\n\t     << \" >= max \" << max << dendl;\n    return false;\n  }\n\n  if (available_pushes)\n    *available_pushes = max - recovery_ops_active - recovery_ops_reserved;\n\n  return true;\n}\n\n\nvoid OSDService::adjust_pg_priorities(const vector<PGRef>& pgs, int newflags)\n{\n  if (!pgs.size() || !(newflags & (OFR_BACKFILL | OFR_RECOVERY)))\n    return;\n  int newstate = 0;\n\n  if (newflags & OFR_BACKFILL) {\n    newstate = PG_STATE_FORCED_BACKFILL;\n  } else if (newflags & OFR_RECOVERY) {\n    newstate = PG_STATE_FORCED_RECOVERY;\n  }\n\n  // debug output here may get large, don't generate it if debug level is below\n  // 10 and use abbreviated pg ids otherwise\n  if ((cct)->_conf->subsys.should_gather(ceph_subsys_osd, 10)) {\n    stringstream ss;\n\n    for (auto& i : pgs) {\n      ss << i->get_pgid() << \" \";\n    }\n\n    dout(10) << __func__ << \" working on \" << ss.str() << dendl;\n  }\n\n  if (newflags & OFR_CANCEL) {\n    for (auto& i : pgs) {\n      i->lock();\n      i->_change_recovery_force_mode(newstate, true);\n      i->unlock();\n    }\n  } else {\n    for (auto& i : pgs) {\n      // make sure the PG is in correct state before forcing backfill or recovery, or\n      // else we'll make PG keeping FORCE_* flag forever, requiring osds restart\n      // or forcing somehow recovery/backfill.\n      i->lock();\n      int pgstate = i->get_state();\n      if ( ((newstate == PG_STATE_FORCED_RECOVERY) && (pgstate & (PG_STATE_DEGRADED | PG_STATE_RECOVERY_WAIT | PG_STATE_RECOVERING))) ||\n\t    ((newstate == PG_STATE_FORCED_BACKFILL) && (pgstate & (PG_STATE_DEGRADED | PG_STATE_BACKFILL_WAIT | PG_STATE_BACKFILLING))) )\n        i->_change_recovery_force_mode(newstate, false);\n      i->unlock();\n    }\n  }\n}\n\nvoid OSD::do_recovery(\n  PG *pg, epoch_t queued, uint64_t reserved_pushes,\n  ThreadPool::TPHandle &handle)\n{\n  uint64_t started = 0;\n\n  /*\n   * When the value of osd_recovery_sleep is set greater than zero, recovery\n   * ops are scheduled after osd_recovery_sleep amount of time from the previous\n   * recovery event's schedule time. This is done by adding a\n   * recovery_requeue_callback event, which re-queues the recovery op using\n   * queue_recovery_after_sleep.\n   */\n  float recovery_sleep = get_osd_recovery_sleep();\n  {\n    Mutex::Locker l(service.recovery_sleep_lock);\n    if (recovery_sleep > 0 && service.recovery_needs_sleep) {\n      PGRef pgref(pg);\n      auto recovery_requeue_callback = new FunctionContext([this, pgref, queued, reserved_pushes](int r) {\n        dout(20) << \"do_recovery wake up at \"\n                 << ceph_clock_now()\n\t         << \", re-queuing recovery\" << dendl;\n\tMutex::Locker l(service.recovery_sleep_lock);\n        service.recovery_needs_sleep = false;\n        service.queue_recovery_after_sleep(pgref.get(), queued, reserved_pushes);\n      });\n\n      // This is true for the first recovery op and when the previous recovery op\n      // has been scheduled in the past. The next recovery op is scheduled after\n      // completing the sleep from now.\n      if (service.recovery_schedule_time < ceph_clock_now()) {\n        service.recovery_schedule_time = ceph_clock_now();\n      }\n      service.recovery_schedule_time += recovery_sleep;\n      service.recovery_sleep_timer.add_event_at(service.recovery_schedule_time,\n\t                                        recovery_requeue_callback);\n      dout(20) << \"Recovery event scheduled at \"\n               << service.recovery_schedule_time << dendl;\n      return;\n    }\n  }\n\n  {\n    {\n      Mutex::Locker l(service.recovery_sleep_lock);\n      service.recovery_needs_sleep = true;\n    }\n\n    if (pg->pg_has_reset_since(queued)) {\n      goto out;\n    }\n\n    assert(!pg->deleting);\n    assert(pg->is_peered() && pg->is_primary());\n\n    assert(pg->recovery_queued);\n    pg->recovery_queued = false;\n\n    dout(10) << \"do_recovery starting \" << reserved_pushes << \" \" << *pg << dendl;\n#ifdef DEBUG_RECOVERY_OIDS\n    dout(20) << \"  active was \" << service.recovery_oids[pg->info.pgid] << dendl;\n#endif\n\n    bool more = pg->start_recovery_ops(reserved_pushes, handle, &started);\n    dout(10) << \"do_recovery started \" << started << \"/\" << reserved_pushes \n\t     << \" on \" << *pg << dendl;\n\n    // If no recovery op is started, don't bother to manipulate the RecoveryCtx\n    if (!started && (more || !pg->have_unfound())) {\n      goto out;\n    }\n\n    PG::RecoveryCtx rctx = create_context();\n    rctx.handle = &handle;\n\n    /*\n     * if we couldn't start any recovery ops and things are still\n     * unfound, see if we can discover more missing object locations.\n     * It may be that our initial locations were bad and we errored\n     * out while trying to pull.\n     */\n    if (!more && pg->have_unfound()) {\n      pg->discover_all_missing(*rctx.query_map);\n      if (rctx.query_map->empty()) {\n\tstring action;\n        if (pg->state_test(PG_STATE_BACKFILLING)) {\n\t  auto evt = PG::CephPeeringEvtRef(new PG::CephPeeringEvt(\n\t    queued,\n\t    queued,\n\t    PG::DeferBackfill(cct->_conf->osd_recovery_retry_interval)));\n\t  pg->queue_peering_event(evt);\n\t  action = \"in backfill\";\n        } else if (pg->state_test(PG_STATE_RECOVERING)) {\n\t  auto evt = PG::CephPeeringEvtRef(new PG::CephPeeringEvt(\n\t    queued,\n\t    queued,\n\t    PG::DeferRecovery(cct->_conf->osd_recovery_retry_interval)));\n\t  pg->queue_peering_event(evt);\n\t  action = \"in recovery\";\n\t} else {\n\t  action = \"already out of recovery/backfill\";\n\t}\n\tdout(10) << __func__ << \": no luck, giving up on this pg for now (\" << action << \")\" << dendl;\n      } else {\n\tdout(10) << __func__ << \": no luck, giving up on this pg for now (queue_recovery)\" << dendl;\n\tpg->queue_recovery();\n      }\n    }\n\n    pg->write_if_dirty(*rctx.transaction);\n    OSDMapRef curmap = pg->get_osdmap();\n    dispatch_context(rctx, pg, curmap);\n  }\n\n out:\n  assert(started <= reserved_pushes);\n  service.release_reserved_pushes(reserved_pushes);\n}\n\nvoid OSDService::start_recovery_op(PG *pg, const hobject_t& soid)\n{\n  Mutex::Locker l(recovery_lock);\n  dout(10) << \"start_recovery_op \" << *pg << \" \" << soid\n\t   << \" (\" << recovery_ops_active << \"/\"\n\t   << cct->_conf->osd_recovery_max_active << \" rops)\"\n\t   << dendl;\n  recovery_ops_active++;\n\n#ifdef DEBUG_RECOVERY_OIDS\n  dout(20) << \"  active was \" << recovery_oids[pg->info.pgid] << dendl;\n  assert(recovery_oids[pg->info.pgid].count(soid) == 0);\n  recovery_oids[pg->info.pgid].insert(soid);\n#endif\n}\n\nvoid OSDService::finish_recovery_op(PG *pg, const hobject_t& soid, bool dequeue)\n{\n  Mutex::Locker l(recovery_lock);\n  dout(10) << \"finish_recovery_op \" << *pg << \" \" << soid\n\t   << \" dequeue=\" << dequeue\n\t   << \" (\" << recovery_ops_active << \"/\" << cct->_conf->osd_recovery_max_active << \" rops)\"\n\t   << dendl;\n\n  // adjust count\n  assert(recovery_ops_active > 0);\n  recovery_ops_active--;\n\n#ifdef DEBUG_RECOVERY_OIDS\n  dout(20) << \"  active oids was \" << recovery_oids[pg->info.pgid] << dendl;\n  assert(recovery_oids[pg->info.pgid].count(soid));\n  recovery_oids[pg->info.pgid].erase(soid);\n#endif\n\n  _maybe_queue_recovery();\n}\n\nbool OSDService::is_recovery_active()\n{\n  return local_reserver.has_reservation() || remote_reserver.has_reservation();\n}\n\n// =========================================================\n// OPS\n\nbool OSD::op_is_discardable(const MOSDOp *op)\n{\n  // drop client request if they are not connected and can't get the\n  // reply anyway.\n  if (!op->get_connection()->is_connected()) {\n    return true;\n  }\n  return false;\n}\n\nvoid OSD::enqueue_op(spg_t pg, OpRequestRef& op, epoch_t epoch)\n{\n  utime_t latency = ceph_clock_now() - op->get_req()->get_recv_stamp();\n  dout(15) << \"enqueue_op \" << op << \" prio \" << op->get_req()->get_priority()\n\t   << \" cost \" << op->get_req()->get_cost()\n\t   << \" latency \" << latency\n\t   << \" epoch \" << epoch\n\t   << \" \" << *(op->get_req()) << dendl;\n  op->osd_trace.event(\"enqueue op\");\n  op->osd_trace.keyval(\"priority\", op->get_req()->get_priority());\n  op->osd_trace.keyval(\"cost\", op->get_req()->get_cost());\n  op->mark_queued_for_pg();\n  logger->tinc(l_osd_op_before_queue_op_lat, latency);\n  op_shardedwq.queue(make_pair(pg, PGQueueable(op, epoch)));\n}\n\n\n\n/*\n * NOTE: dequeue called in worker thread, with pg lock\n */\nvoid OSD::dequeue_op(\n  PGRef pg, OpRequestRef op,\n  ThreadPool::TPHandle &handle)\n{\n  FUNCTRACE();\n  OID_EVENT_TRACE_WITH_MSG(op->get_req(), \"DEQUEUE_OP_BEGIN\", false);\n\n  utime_t now = ceph_clock_now();\n  op->set_dequeued_time(now);\n  utime_t latency = now - op->get_req()->get_recv_stamp();\n  dout(10) << \"dequeue_op \" << op << \" prio \" << op->get_req()->get_priority()\n\t   << \" cost \" << op->get_req()->get_cost()\n\t   << \" latency \" << latency\n\t   << \" \" << *(op->get_req())\n\t   << \" pg \" << *pg << dendl;\n\n  logger->tinc(l_osd_op_before_dequeue_op_lat, latency);\n\n  Session *session = static_cast<Session *>(\n    op->get_req()->get_connection()->get_priv());\n  if (session) {\n    maybe_share_map(session, op, pg->get_osdmap());\n    session->put();\n  }\n\n  if (pg->deleting)\n    return;\n\n  op->mark_reached_pg();\n  op->osd_trace.event(\"dequeue_op\");\n\n  pg->do_request(op, handle);\n\n  // finish\n  dout(10) << \"dequeue_op \" << op << \" finish\" << dendl;\n  OID_EVENT_TRACE_WITH_MSG(op->get_req(), \"DEQUEUE_OP_END\", false);\n}\n\n\nstruct C_CompleteSplits : public Context {\n  OSD *osd;\n  set<PGRef> pgs;\n  C_CompleteSplits(OSD *osd, const set<PGRef> &in)\n    : osd(osd), pgs(in) {}\n  void finish(int r) override {\n    Mutex::Locker l(osd->osd_lock);\n    if (osd->is_stopping())\n      return;\n    PG::RecoveryCtx rctx = osd->create_context();\n    for (set<PGRef>::iterator i = pgs.begin();\n\t i != pgs.end();\n\t ++i) {\n      osd->pg_map_lock.get_write();\n      (*i)->lock();\n      PG *pg = i->get();\n      osd->add_newly_split_pg(pg, &rctx);\n      if (!((*i)->deleting)) {\n        set<spg_t> to_complete;\n        to_complete.insert((*i)->info.pgid);\n        osd->service.complete_split(to_complete);\n      }\n      osd->pg_map_lock.put_write();\n      osd->dispatch_context_transaction(rctx, pg);\n      osd->wake_pg_waiters(*i);\n      (*i)->unlock();\n    }\n\n    osd->dispatch_context(rctx, 0, osd->service.get_osdmap());\n  }\n};\n\nvoid OSD::process_peering_events(\n  const list<PG*> &pgs,\n  ThreadPool::TPHandle &handle\n  )\n{\n  bool need_up_thru = false;\n  epoch_t same_interval_since = 0;\n  OSDMapRef curmap;\n  PG::RecoveryCtx rctx = create_context();\n  rctx.handle = &handle;\n  for (list<PG*>::const_iterator i = pgs.begin();\n       i != pgs.end();\n       ++i) {\n    set<PGRef> split_pgs;\n    PG *pg = *i;\n    pg->lock_suspend_timeout(handle);\n    curmap = service.get_osdmap();\n    if (pg->deleting) {\n      pg->unlock();\n      continue;\n    }\n    if (!advance_pg(curmap->get_epoch(), pg, handle, &rctx, &split_pgs)) {\n      // we need to requeue the PG explicitly since we didn't actually\n      // handle an event\n      peering_wq.queue(pg);\n    } else {\n      assert(!pg->peering_queue.empty());\n      PG::CephPeeringEvtRef evt = pg->peering_queue.front();\n      pg->peering_queue.pop_front();\n      pg->handle_peering_event(evt, &rctx);\n    }\n    need_up_thru = pg->need_up_thru || need_up_thru;\n    same_interval_since = MAX(pg->info.history.same_interval_since,\n\t\t\t      same_interval_since);\n    pg->write_if_dirty(*rctx.transaction);\n    if (!split_pgs.empty()) {\n      rctx.on_applied->add(new C_CompleteSplits(this, split_pgs));\n      split_pgs.clear();\n    }\n    dispatch_context_transaction(rctx, pg, &handle);\n    pg->unlock();\n  }\n  if (need_up_thru)\n    queue_want_up_thru(same_interval_since);\n  dispatch_context(rctx, 0, curmap, &handle);\n\n  service.send_pg_temp();\n}\n\n// --------------------------------\n\nconst char** OSD::get_tracked_conf_keys() const\n{\n  static const char* KEYS[] = {\n    \"osd_max_backfills\",\n    \"osd_min_recovery_priority\",\n    \"osd_max_trimming_pgs\",\n    \"osd_op_complaint_time\",\n    \"osd_op_log_threshold\",\n    \"osd_op_history_size\",\n    \"osd_op_history_duration\",\n    \"osd_op_history_slow_op_size\",\n    \"osd_op_history_slow_op_threshold\",\n    \"osd_enable_op_tracker\",\n    \"osd_map_cache_size\",\n    \"osd_map_max_advance\",\n    \"osd_pg_epoch_persisted_max_stale\",\n    \"osd_disk_thread_ioprio_class\",\n    \"osd_disk_thread_ioprio_priority\",\n    // clog & admin clog\n    \"clog_to_monitors\",\n    \"clog_to_syslog\",\n    \"clog_to_syslog_facility\",\n    \"clog_to_syslog_level\",\n    \"osd_objectstore_fuse\",\n    \"clog_to_graylog\",\n    \"clog_to_graylog_host\",\n    \"clog_to_graylog_port\",\n    \"host\",\n    \"fsid\",\n    \"osd_recovery_delay_start\",\n    \"osd_client_message_size_cap\",\n    \"osd_client_message_cap\",\n    \"osd_heartbeat_min_size\",\n    \"osd_heartbeat_interval\",\n    NULL\n  };\n  return KEYS;\n}\n\nvoid OSD::handle_conf_change(const struct md_config_t *conf,\n\t\t\t     const std::set <std::string> &changed)\n{\n  if (changed.count(\"osd_max_backfills\")) {\n    service.local_reserver.set_max(cct->_conf->osd_max_backfills);\n    service.remote_reserver.set_max(cct->_conf->osd_max_backfills);\n  }\n  if (changed.count(\"osd_min_recovery_priority\")) {\n    service.local_reserver.set_min_priority(cct->_conf->osd_min_recovery_priority);\n    service.remote_reserver.set_min_priority(cct->_conf->osd_min_recovery_priority);\n  }\n  if (changed.count(\"osd_max_trimming_pgs\")) {\n    service.snap_reserver.set_max(cct->_conf->osd_max_trimming_pgs);\n  }\n  if (changed.count(\"osd_op_complaint_time\") ||\n      changed.count(\"osd_op_log_threshold\")) {\n    op_tracker.set_complaint_and_threshold(cct->_conf->osd_op_complaint_time,\n                                           cct->_conf->osd_op_log_threshold);\n  }\n  if (changed.count(\"osd_op_history_size\") ||\n      changed.count(\"osd_op_history_duration\")) {\n    op_tracker.set_history_size_and_duration(cct->_conf->osd_op_history_size,\n                                             cct->_conf->osd_op_history_duration);\n  }\n  if (changed.count(\"osd_op_history_slow_op_size\") ||\n      changed.count(\"osd_op_history_slow_op_threshold\")) {\n    op_tracker.set_history_slow_op_size_and_threshold(cct->_conf->osd_op_history_slow_op_size,\n                                                      cct->_conf->osd_op_history_slow_op_threshold);\n  }\n  if (changed.count(\"osd_enable_op_tracker\")) {\n      op_tracker.set_tracking(cct->_conf->osd_enable_op_tracker);\n  }\n  if (changed.count(\"osd_disk_thread_ioprio_class\") ||\n      changed.count(\"osd_disk_thread_ioprio_priority\")) {\n    set_disk_tp_priority();\n  }\n  if (changed.count(\"osd_map_cache_size\")) {\n    service.map_cache.set_size(cct->_conf->osd_map_cache_size);\n    service.map_bl_cache.set_size(cct->_conf->osd_map_cache_size);\n    service.map_bl_inc_cache.set_size(cct->_conf->osd_map_cache_size);\n  }\n  if (changed.count(\"clog_to_monitors\") ||\n      changed.count(\"clog_to_syslog\") ||\n      changed.count(\"clog_to_syslog_level\") ||\n      changed.count(\"clog_to_syslog_facility\") ||\n      changed.count(\"clog_to_graylog\") ||\n      changed.count(\"clog_to_graylog_host\") ||\n      changed.count(\"clog_to_graylog_port\") ||\n      changed.count(\"host\") ||\n      changed.count(\"fsid\")) {\n    update_log_config();\n  }\n\n#ifdef HAVE_LIBFUSE\n  if (changed.count(\"osd_objectstore_fuse\")) {\n    if (store) {\n      enable_disable_fuse(false);\n    }\n  }\n#endif\n\n  if (changed.count(\"osd_recovery_delay_start\")) {\n    service.defer_recovery(cct->_conf->osd_recovery_delay_start);\n    service.kick_recovery_queue();\n  }\n\n  if (changed.count(\"osd_client_message_cap\")) {\n    uint64_t newval = cct->_conf->osd_client_message_cap;\n    Messenger::Policy pol = client_messenger->get_policy(entity_name_t::TYPE_CLIENT);\n    if (pol.throttler_messages && newval > 0) {\n      pol.throttler_messages->reset_max(newval);\n    }\n  }\n  if (changed.count(\"osd_client_message_size_cap\")) {\n    uint64_t newval = cct->_conf->osd_client_message_size_cap;\n    Messenger::Policy pol = client_messenger->get_policy(entity_name_t::TYPE_CLIENT);\n    if (pol.throttler_bytes && newval > 0) {\n      pol.throttler_bytes->reset_max(newval);\n    }\n  }\n\n  check_config();\n}\n\nvoid OSD::update_log_config()\n{\n  map<string,string> log_to_monitors;\n  map<string,string> log_to_syslog;\n  map<string,string> log_channel;\n  map<string,string> log_prio;\n  map<string,string> log_to_graylog;\n  map<string,string> log_to_graylog_host;\n  map<string,string> log_to_graylog_port;\n  uuid_d fsid;\n  string host;\n\n  if (parse_log_client_options(cct, log_to_monitors, log_to_syslog,\n\t\t\t       log_channel, log_prio, log_to_graylog,\n\t\t\t       log_to_graylog_host, log_to_graylog_port,\n\t\t\t       fsid, host) == 0)\n    clog->update_config(log_to_monitors, log_to_syslog,\n\t\t\tlog_channel, log_prio, log_to_graylog,\n\t\t\tlog_to_graylog_host, log_to_graylog_port,\n\t\t\tfsid, host);\n  derr << \"log_to_monitors \" << log_to_monitors << dendl;\n}\n\nvoid OSD::check_config()\n{\n  // some sanity checks\n  if (cct->_conf->osd_map_cache_size <= cct->_conf->osd_map_max_advance + 2) {\n    clog->warn() << \"osd_map_cache_size (\" << cct->_conf->osd_map_cache_size << \")\"\n\t\t<< \" is not > osd_map_max_advance (\"\n\t\t<< cct->_conf->osd_map_max_advance << \")\";\n  }\n  if (cct->_conf->osd_map_cache_size <= (int)cct->_conf->osd_pg_epoch_persisted_max_stale + 2) {\n    clog->warn() << \"osd_map_cache_size (\" << cct->_conf->osd_map_cache_size << \")\"\n\t\t << \" is not > osd_pg_epoch_persisted_max_stale (\"\n\t\t << cct->_conf->osd_pg_epoch_persisted_max_stale << \")\";\n  }\n}\n\nvoid OSD::set_disk_tp_priority()\n{\n  dout(10) << __func__\n\t   << \" class \" << cct->_conf->osd_disk_thread_ioprio_class\n\t   << \" priority \" << cct->_conf->osd_disk_thread_ioprio_priority\n\t   << dendl;\n  if (cct->_conf->osd_disk_thread_ioprio_class.empty() ||\n      cct->_conf->osd_disk_thread_ioprio_priority < 0)\n    return;\n  int cls =\n    ceph_ioprio_string_to_class(cct->_conf->osd_disk_thread_ioprio_class);\n  if (cls < 0)\n    derr << __func__ << cpp_strerror(cls) << \": \"\n\t << \"osd_disk_thread_ioprio_class is \" << cct->_conf->osd_disk_thread_ioprio_class\n\t << \" but only the following values are allowed: idle, be or rt\" << dendl;\n  else\n    disk_tp.set_ioprio(cls, cct->_conf->osd_disk_thread_ioprio_priority);\n}\n\n// --------------------------------\n\nvoid OSD::get_latest_osdmap()\n{\n  dout(10) << __func__ << \" -- start\" << dendl;\n\n  C_SaferCond cond;\n  service.objecter->wait_for_latest_osdmap(&cond);\n  cond.wait();\n\n  dout(10) << __func__ << \" -- finish\" << dendl;\n}\n\n// --------------------------------\n\nint OSD::init_op_flags(OpRequestRef& op)\n{\n  const MOSDOp *m = static_cast<const MOSDOp*>(op->get_req());\n  vector<OSDOp>::const_iterator iter;\n\n  // client flags have no bearing on whether an op is a read, write, etc.\n  op->rmw_flags = 0;\n\n  if (m->has_flag(CEPH_OSD_FLAG_RWORDERED)) {\n    op->set_force_rwordered();\n  }\n\n  // set bits based on op codes, called methods.\n  for (iter = m->ops.begin(); iter != m->ops.end(); ++iter) {\n    if ((iter->op.op == CEPH_OSD_OP_WATCH &&\n\t iter->op.watch.op == CEPH_OSD_WATCH_OP_PING)) {\n      /* This a bit odd.  PING isn't actually a write.  It can't\n       * result in an update to the object_info.  PINGs also aren'ty\n       * resent, so there's no reason to write out a log entry\n       *\n       * However, we pipeline them behind writes, so let's force\n       * the write_ordered flag.\n       */\n      op->set_force_rwordered();\n    } else {\n      if (ceph_osd_op_mode_modify(iter->op.op))\n\top->set_write();\n    }\n    if (ceph_osd_op_mode_read(iter->op.op))\n      op->set_read();\n\n    // set READ flag if there are src_oids\n    if (iter->soid.oid.name.length())\n      op->set_read();\n\n    // set PGOP flag if there are PG ops\n    if (ceph_osd_op_type_pg(iter->op.op))\n      op->set_pg_op();\n\n    if (ceph_osd_op_mode_cache(iter->op.op))\n      op->set_cache();\n\n    // check for ec base pool\n    int64_t poolid = m->get_pg().pool();\n    const pg_pool_t *pool = osdmap->get_pg_pool(poolid);\n    if (pool && pool->is_tier()) {\n      const pg_pool_t *base_pool = osdmap->get_pg_pool(pool->tier_of);\n      if (base_pool && base_pool->require_rollback()) {\n        if ((iter->op.op != CEPH_OSD_OP_READ) &&\n            (iter->op.op != CEPH_OSD_OP_CHECKSUM) &&\n            (iter->op.op != CEPH_OSD_OP_CMPEXT) &&\n            (iter->op.op != CEPH_OSD_OP_STAT) &&\n            (iter->op.op != CEPH_OSD_OP_ISDIRTY) &&\n            (iter->op.op != CEPH_OSD_OP_UNDIRTY) &&\n            (iter->op.op != CEPH_OSD_OP_GETXATTR) &&\n            (iter->op.op != CEPH_OSD_OP_GETXATTRS) &&\n            (iter->op.op != CEPH_OSD_OP_CMPXATTR) &&\n            (iter->op.op != CEPH_OSD_OP_ASSERT_VER) &&\n            (iter->op.op != CEPH_OSD_OP_LIST_WATCHERS) &&\n            (iter->op.op != CEPH_OSD_OP_LIST_SNAPS) &&\n            (iter->op.op != CEPH_OSD_OP_SETALLOCHINT) &&\n            (iter->op.op != CEPH_OSD_OP_WRITEFULL) &&\n            (iter->op.op != CEPH_OSD_OP_ROLLBACK) &&\n            (iter->op.op != CEPH_OSD_OP_CREATE) &&\n            (iter->op.op != CEPH_OSD_OP_DELETE) &&\n            (iter->op.op != CEPH_OSD_OP_SETXATTR) &&\n            (iter->op.op != CEPH_OSD_OP_RMXATTR) &&\n            (iter->op.op != CEPH_OSD_OP_STARTSYNC) &&\n            (iter->op.op != CEPH_OSD_OP_COPY_GET) &&\n            (iter->op.op != CEPH_OSD_OP_COPY_FROM)) {\n          op->set_promote();\n        }\n      }\n    }\n\n    switch (iter->op.op) {\n    case CEPH_OSD_OP_CALL:\n      {\n\tbufferlist::iterator bp = const_cast<bufferlist&>(iter->indata).begin();\n\tint is_write, is_read;\n\tstring cname, mname;\n\tbp.copy(iter->op.cls.class_len, cname);\n\tbp.copy(iter->op.cls.method_len, mname);\n\n\tClassHandler::ClassData *cls;\n\tint r = class_handler->open_class(cname, &cls);\n\tif (r) {\n\t  derr << \"class \" << cname << \" open got \" << cpp_strerror(r) << dendl;\n\t  if (r == -ENOENT)\n\t    r = -EOPNOTSUPP;\n\t  else if (r != -EPERM) // propagate permission errors\n\t    r = -EIO;\n\t  return r;\n\t}\n\tint flags = cls->get_method_flags(mname.c_str());\n\tif (flags < 0) {\n\t  if (flags == -ENOENT)\n\t    r = -EOPNOTSUPP;\n\t  else\n\t    r = flags;\n\t  return r;\n\t}\n\tis_read = flags & CLS_METHOD_RD;\n\tis_write = flags & CLS_METHOD_WR;\n        bool is_promote = flags & CLS_METHOD_PROMOTE;\n\n\tdout(10) << \"class \" << cname << \" method \" << mname << \" \"\n\t\t << \"flags=\" << (is_read ? \"r\" : \"\")\n                             << (is_write ? \"w\" : \"\")\n                             << (is_promote ? \"p\" : \"\")\n                 << dendl;\n\tif (is_read)\n\t  op->set_class_read();\n\tif (is_write)\n\t  op->set_class_write();\n        if (is_promote)\n          op->set_promote();\n        op->add_class(cname, is_read, is_write, cls->whitelisted);\n\tbreak;\n      }\n\n    case CEPH_OSD_OP_WATCH:\n      // force the read bit for watch since it is depends on previous\n      // watch state (and may return early if the watch exists) or, in\n      // the case of ping, is simply a read op.\n      op->set_read();\n      // fall through\n    case CEPH_OSD_OP_NOTIFY:\n    case CEPH_OSD_OP_NOTIFY_ACK:\n      {\n        op->set_promote();\n        break;\n      }\n\n    case CEPH_OSD_OP_DELETE:\n      // if we get a delete with FAILOK we can skip handle cache. without\n      // FAILOK we still need to promote (or do something smarter) to\n      // determine whether to return ENOENT or 0.\n      if (iter == m->ops.begin() &&\n\t  iter->op.flags == CEPH_OSD_OP_FLAG_FAILOK) {\n\top->set_skip_handle_cache();\n      }\n      // skip promotion when proxying a delete op\n      if (m->ops.size() == 1) {\n\top->set_skip_promote();\n      }\n      break;\n\n    case CEPH_OSD_OP_CACHE_TRY_FLUSH:\n    case CEPH_OSD_OP_CACHE_FLUSH:\n    case CEPH_OSD_OP_CACHE_EVICT:\n      // If try_flush/flush/evict is the only op, can skip handle cache.\n      if (m->ops.size() == 1) {\n\top->set_skip_handle_cache();\n      }\n      break;\n\n    case CEPH_OSD_OP_READ:\n    case CEPH_OSD_OP_SYNC_READ:\n    case CEPH_OSD_OP_SPARSE_READ:\n    case CEPH_OSD_OP_CHECKSUM:\n    case CEPH_OSD_OP_WRITEFULL:\n      if (m->ops.size() == 1 &&\n          (iter->op.flags & CEPH_OSD_OP_FLAG_FADVISE_NOCACHE ||\n           iter->op.flags & CEPH_OSD_OP_FLAG_FADVISE_DONTNEED)) {\n        op->set_skip_promote();\n      }\n      break;\n\n    // force promotion when pin an object in cache tier\n    case CEPH_OSD_OP_CACHE_PIN:\n      op->set_promote();\n      break;\n\n    default:\n      break;\n    }\n  }\n\n  if (op->rmw_flags == 0)\n    return -EINVAL;\n\n  return 0;\n}\n\nvoid OSD::PeeringWQ::_dequeue(list<PG*> *out) {\n  for (list<PG*>::iterator i = peering_queue.begin();\n      i != peering_queue.end() &&\n      out->size() < osd->cct->_conf->osd_peering_wq_batch_size;\n      ) {\n        if (in_use.count(*i)) {\n          ++i;\n        } else {\n          out->push_back(*i);\n          peering_queue.erase(i++);\n        }\n  }\n  in_use.insert(out->begin(), out->end());\n}\n\n\n// =============================================================\n\n#undef dout_context\n#define dout_context osd->cct\n#undef dout_prefix\n#define dout_prefix *_dout << \"osd.\" << osd->whoami << \" op_wq \"\n\nvoid OSD::ShardedOpWQ::wake_pg_waiters(spg_t pgid)\n{\n  uint32_t shard_index = pgid.hash_to_shard(shard_list.size());\n  auto sdata = shard_list[shard_index];\n  bool queued = false;\n  {\n    Mutex::Locker l(sdata->sdata_op_ordering_lock);\n    auto p = sdata->pg_slots.find(pgid);\n    if (p != sdata->pg_slots.end()) {\n      dout(20) << __func__ << \" \" << pgid\n\t       << \" to_process \" << p->second.to_process\n\t       << \" waiting_for_pg=\" << (int)p->second.waiting_for_pg << dendl;\n      for (auto i = p->second.to_process.rbegin();\n\t   i != p->second.to_process.rend();\n\t   ++i) {\n\tsdata->_enqueue_front(make_pair(pgid, *i), osd->op_prio_cutoff);\n      }\n      p->second.to_process.clear();\n      p->second.waiting_for_pg = false;\n      ++p->second.requeue_seq;\n      queued = true;\n    }\n  }\n  if (queued) {\n    sdata->sdata_lock.Lock();\n    sdata->sdata_cond.SignalOne();\n    sdata->sdata_lock.Unlock();\n  }\n}\n\nvoid OSD::ShardedOpWQ::prune_pg_waiters(OSDMapRef osdmap, int whoami)\n{\n  unsigned pushes_to_free = 0;\n  for (auto sdata : shard_list) {\n    Mutex::Locker l(sdata->sdata_op_ordering_lock);\n    sdata->waiting_for_pg_osdmap = osdmap;\n    auto p = sdata->pg_slots.begin();\n    while (p != sdata->pg_slots.end()) {\n      ShardData::pg_slot& slot = p->second;\n      if (!slot.to_process.empty() && slot.num_running == 0) {\n\tif (osdmap->is_up_acting_osd_shard(p->first, whoami)) {\n\t  dout(20) << __func__ << \"  \" << p->first << \" maps to us, keeping\"\n\t\t   << dendl;\n\t  ++p;\n\t  continue;\n\t}\n\twhile (!slot.to_process.empty() &&\n\t       slot.to_process.front().get_map_epoch() <= osdmap->get_epoch()) {\n\t  auto& qi = slot.to_process.front();\n\t  dout(20) << __func__ << \"  \" << p->first\n\t\t   << \" item \" << qi\n\t\t   << \" epoch \" << qi.get_map_epoch()\n\t\t   << \" <= \" << osdmap->get_epoch()\n\t\t   << \", stale, dropping\" << dendl;\n\t  pushes_to_free += qi.get_reserved_pushes();\n\t  slot.to_process.pop_front();\n\t}\n      }\n      if (slot.to_process.empty() &&\n\t  slot.num_running == 0 &&\n\t  !slot.pg) {\n\tdout(20) << __func__ << \"  \" << p->first << \" empty, pruning\" << dendl;\n\tp = sdata->pg_slots.erase(p);\n      } else {\n\t++p;\n      }\n    }\n  }\n  if (pushes_to_free > 0) {\n    osd->service.release_reserved_pushes(pushes_to_free);\n  }\n}\n\nvoid OSD::ShardedOpWQ::clear_pg_pointer(spg_t pgid)\n{\n  uint32_t shard_index = pgid.hash_to_shard(shard_list.size());\n  auto sdata = shard_list[shard_index];\n  Mutex::Locker l(sdata->sdata_op_ordering_lock);\n  auto p = sdata->pg_slots.find(pgid);\n  if (p != sdata->pg_slots.end()) {\n    auto& slot = p->second;\n    dout(20) << __func__ << \" \" << pgid << \" pg \" << slot.pg << dendl;\n    assert(!slot.pg || slot.pg->deleting);\n    slot.pg = nullptr;\n  }\n}\n\nvoid OSD::ShardedOpWQ::clear_pg_slots()\n{\n  for (auto sdata : shard_list) {\n    Mutex::Locker l(sdata->sdata_op_ordering_lock);\n    sdata->pg_slots.clear();\n    sdata->waiting_for_pg_osdmap.reset();\n    // don't bother with reserved pushes; we are shutting down\n  }\n}\n\n#undef dout_prefix\n#define dout_prefix *_dout << \"osd.\" << osd->whoami << \" op_wq(\" << shard_index << \") \"\n\nvoid OSD::ShardedOpWQ::_process(uint32_t thread_index, heartbeat_handle_d *hb)\n{\n  uint32_t shard_index = thread_index % num_shards;\n  ShardData *sdata = shard_list[shard_index];\n  assert(NULL != sdata);\n\n  // peek at spg_t\n  sdata->sdata_op_ordering_lock.Lock();\n  if (sdata->pqueue->empty()) {\n    dout(20) << __func__ << \" empty q, waiting\" << dendl;\n    // optimistically sleep a moment; maybe another work item will come along.\n    osd->cct->get_heartbeat_map()->reset_timeout(hb,\n      osd->cct->_conf->threadpool_default_timeout, 0);\n    sdata->sdata_lock.Lock();\n    sdata->sdata_op_ordering_lock.Unlock();\n    sdata->sdata_cond.WaitInterval(sdata->sdata_lock,\n      utime_t(osd->cct->_conf->threadpool_empty_queue_max_wait, 0));\n    sdata->sdata_lock.Unlock();\n    sdata->sdata_op_ordering_lock.Lock();\n    if (sdata->pqueue->empty()) {\n      sdata->sdata_op_ordering_lock.Unlock();\n      return;\n    }\n  }\n  pair<spg_t, PGQueueable> item = sdata->pqueue->dequeue();\n  if (osd->is_stopping()) {\n    sdata->sdata_op_ordering_lock.Unlock();\n    return;    // OSD shutdown, discard.\n  }\n  PGRef pg;\n  uint64_t requeue_seq;\n  {\n    auto& slot = sdata->pg_slots[item.first];\n    dout(30) << __func__ << \" \" << item.first\n\t     << \" to_process \" << slot.to_process\n\t     << \" waiting_for_pg=\" << (int)slot.waiting_for_pg << dendl;\n    slot.to_process.push_back(item.second);\n    // note the requeue seq now...\n    requeue_seq = slot.requeue_seq;\n    if (slot.waiting_for_pg) {\n      // save ourselves a bit of effort\n      dout(20) << __func__ << \" \" << item.first << \" item \" << item.second\n\t       << \" queued, waiting_for_pg\" << dendl;\n      sdata->sdata_op_ordering_lock.Unlock();\n      return;\n    }\n    pg = slot.pg;\n    dout(20) << __func__ << \" \" << item.first << \" item \" << item.second\n\t     << \" queued\" << dendl;\n    ++slot.num_running;\n  }\n  sdata->sdata_op_ordering_lock.Unlock();\n\n  osd->service.maybe_inject_dispatch_delay();\n\n  // [lookup +] lock pg (if we have it)\n  if (!pg) {\n    pg = osd->_lookup_lock_pg(item.first);\n  } else {\n    pg->lock();\n  }\n\n  osd->service.maybe_inject_dispatch_delay();\n\n  boost::optional<PGQueueable> qi;\n\n  // we don't use a Mutex::Locker here because of the\n  // osd->service.release_reserved_pushes() call below\n  sdata->sdata_op_ordering_lock.Lock();\n\n  auto q = sdata->pg_slots.find(item.first);\n  assert(q != sdata->pg_slots.end());\n  auto& slot = q->second;\n  --slot.num_running;\n\n  if (slot.to_process.empty()) {\n    // raced with wake_pg_waiters or prune_pg_waiters\n    dout(20) << __func__ << \" \" << item.first << \" nothing queued\" << dendl;\n    if (pg) {\n      pg->unlock();\n    }\n    sdata->sdata_op_ordering_lock.Unlock();\n    return;\n  }\n  if (requeue_seq != slot.requeue_seq) {\n    dout(20) << __func__ << \" \" << item.first\n\t     << \" requeue_seq \" << slot.requeue_seq << \" > our \"\n\t     << requeue_seq << \", we raced with wake_pg_waiters\"\n\t     << dendl;\n    if (pg) {\n      pg->unlock();\n    }\n    sdata->sdata_op_ordering_lock.Unlock();\n    return;\n  }\n  if (pg && !slot.pg && !pg->deleting) {\n    dout(20) << __func__ << \" \" << item.first << \" set pg to \" << pg << dendl;\n    slot.pg = pg;\n  }\n  dout(30) << __func__ << \" \" << item.first << \" to_process \" << slot.to_process\n\t   << \" waiting_for_pg=\" << (int)slot.waiting_for_pg << dendl;\n\n  // make sure we're not already waiting for this pg\n  if (slot.waiting_for_pg) {\n    dout(20) << __func__ << \" \" << item.first << \" item \" << item.second\n\t     << \" slot is waiting_for_pg\" << dendl;\n    if (pg) {\n      pg->unlock();\n    }\n    sdata->sdata_op_ordering_lock.Unlock();\n    return;\n  }\n\n  // take next item\n  qi = slot.to_process.front();\n  slot.to_process.pop_front();\n  dout(20) << __func__ << \" \" << item.first << \" item \" << *qi\n\t   << \" pg \" << pg << dendl;\n\n  if (!pg) {\n    // should this pg shard exist on this osd in this (or a later) epoch?\n    OSDMapRef osdmap = sdata->waiting_for_pg_osdmap;\n    if (osdmap->is_up_acting_osd_shard(item.first, osd->whoami)) {\n      dout(20) << __func__ << \" \" << item.first\n\t       << \" no pg, should exist, will wait\" << \" on \" << *qi << dendl;\n      slot.to_process.push_front(*qi);\n      slot.waiting_for_pg = true;\n    } else if (qi->get_map_epoch() > osdmap->get_epoch()) {\n      dout(20) << __func__ << \" \" << item.first << \" no pg, item epoch is \"\n\t       << qi->get_map_epoch() << \" > \" << osdmap->get_epoch()\n\t       << \", will wait on \" << *qi << dendl;\n      slot.to_process.push_front(*qi);\n      slot.waiting_for_pg = true;\n    } else {\n      dout(20) << __func__ << \" \" << item.first << \" no pg, shouldn't exist,\"\n\t       << \" dropping \" << *qi << dendl;\n      // share map with client?\n      if (boost::optional<OpRequestRef> _op = qi->maybe_get_op()) {\n\tSession *session = static_cast<Session *>(\n\t  (*_op)->get_req()->get_connection()->get_priv());\n\tif (session) {\n\t  osd->maybe_share_map(session, *_op, sdata->waiting_for_pg_osdmap);\n\t  session->put();\n\t}\n      }\n      unsigned pushes_to_free = qi->get_reserved_pushes();\n      if (pushes_to_free > 0) {\n\tsdata->sdata_op_ordering_lock.Unlock();\n\tosd->service.release_reserved_pushes(pushes_to_free);\n\treturn;\n      }\n    }\n    sdata->sdata_op_ordering_lock.Unlock();\n    return;\n  }\n  sdata->sdata_op_ordering_lock.Unlock();\n\n\n  // osd_opwq_process marks the point at which an operation has been dequeued\n  // and will begin to be handled by a worker thread.\n  {\n#ifdef WITH_LTTNG\n    osd_reqid_t reqid;\n    if (boost::optional<OpRequestRef> _op = qi->maybe_get_op()) {\n      reqid = (*_op)->get_reqid();\n    }\n#endif\n    tracepoint(osd, opwq_process_start, reqid.name._type,\n        reqid.name._num, reqid.tid, reqid.inc);\n  }\n\n  lgeneric_subdout(osd->cct, osd, 30) << \"dequeue status: \";\n  Formatter *f = Formatter::create(\"json\");\n  f->open_object_section(\"q\");\n  dump(f);\n  f->close_section();\n  f->flush(*_dout);\n  delete f;\n  *_dout << dendl;\n\n  ThreadPool::TPHandle tp_handle(osd->cct, hb, timeout_interval,\n\t\t\t\t suicide_interval);\n  qi->run(osd, pg, tp_handle);\n\n  {\n#ifdef WITH_LTTNG\n    osd_reqid_t reqid;\n    if (boost::optional<OpRequestRef> _op = qi->maybe_get_op()) {\n      reqid = (*_op)->get_reqid();\n    }\n#endif\n    tracepoint(osd, opwq_process_finish, reqid.name._type,\n        reqid.name._num, reqid.tid, reqid.inc);\n  }\n\n  pg->unlock();\n}\n\nvoid OSD::ShardedOpWQ::_enqueue(pair<spg_t, PGQueueable> item) {\n  uint32_t shard_index =\n    item.first.hash_to_shard(shard_list.size());\n\n  ShardData* sdata = shard_list[shard_index];\n  assert (NULL != sdata);\n  unsigned priority = item.second.get_priority();\n  unsigned cost = item.second.get_cost();\n  sdata->sdata_op_ordering_lock.Lock();\n\n  dout(20) << __func__ << \" \" << item.first << \" \" << item.second << dendl;\n  if (priority >= osd->op_prio_cutoff)\n    sdata->pqueue->enqueue_strict(\n      item.second.get_owner(), priority, item);\n  else\n    sdata->pqueue->enqueue(\n      item.second.get_owner(),\n      priority, cost, item);\n  sdata->sdata_op_ordering_lock.Unlock();\n\n  sdata->sdata_lock.Lock();\n  sdata->sdata_cond.SignalOne();\n  sdata->sdata_lock.Unlock();\n\n}\n\nvoid OSD::ShardedOpWQ::_enqueue_front(pair<spg_t, PGQueueable> item)\n{\n  uint32_t shard_index = item.first.hash_to_shard(shard_list.size());\n  ShardData* sdata = shard_list[shard_index];\n  assert (NULL != sdata);\n  sdata->sdata_op_ordering_lock.Lock();\n  auto p = sdata->pg_slots.find(item.first);\n  if (p != sdata->pg_slots.end() && !p->second.to_process.empty()) {\n    // we may be racing with _process, which has dequeued a new item\n    // from pqueue, put it on to_process, and is now busy taking the\n    // pg lock.  ensure this old requeued item is ordered before any\n    // such newer item in to_process.\n    p->second.to_process.push_front(item.second);\n    item.second = p->second.to_process.back();\n    p->second.to_process.pop_back();\n    dout(20) << __func__ << \" \" << item.first\n\t     << \" \" << p->second.to_process.front()\n\t     << \" shuffled w/ \" << item.second << dendl;\n  } else {\n    dout(20) << __func__ << \" \" << item.first << \" \" << item.second << dendl;\n  }\n  sdata->_enqueue_front(item, osd->op_prio_cutoff);\n  sdata->sdata_op_ordering_lock.Unlock();\n  sdata->sdata_lock.Lock();\n  sdata->sdata_cond.SignalOne();\n  sdata->sdata_lock.Unlock();\n}\n\nnamespace ceph { \nnamespace osd_cmds { \n\nint heap(CephContext& cct, cmdmap_t& cmdmap, Formatter& f, std::ostream& os)\n{\n  if (!ceph_using_tcmalloc()) {\n        os << \"could not issue heap profiler command -- not using tcmalloc!\";\n        return -EOPNOTSUPP;\n  }\n  \n  string cmd;\n  if (!cmd_getval(&cct, cmdmap, \"heapcmd\", cmd)) {\n        os << \"unable to get value for command \\\"\" << cmd << \"\\\"\";\n       return -EINVAL;\n   }\n  \n  std::vector<std::string> cmd_vec;\n  get_str_vec(cmd, cmd_vec);\n  \n  ceph_heap_profiler_handle_command(cmd_vec, os);\n  \n  return 0;\n}\n \n}} // namespace ceph::osd_cmds\n\n\nstd::ostream& operator<<(std::ostream& out, const OSD::io_queue& q) {\n  switch(q) {\n  case OSD::io_queue::prioritized:\n    out << \"prioritized\";\n    break;\n  case OSD::io_queue::weightedpriority:\n    out << \"weightedpriority\";\n    break;\n  case OSD::io_queue::mclock_opclass:\n    out << \"mclock_opclass\";\n    break;\n  case OSD::io_queue::mclock_client:\n    out << \"mclock_client\";\n    break;\n  }\n  return out;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_OSD_H\n#define CEPH_OSD_H\n\n#include \"PG.h\"\n\n#include \"msg/Dispatcher.h\"\n\n#include \"common/Mutex.h\"\n#include \"common/RWLock.h\"\n#include \"common/Timer.h\"\n#include \"common/WorkQueue.h\"\n#include \"common/AsyncReserver.h\"\n#include \"common/ceph_context.h\"\n#include \"common/zipkin_trace.h\"\n\n#include \"mgr/MgrClient.h\"\n\n#include \"os/ObjectStore.h\"\n#include \"OSDCap.h\" \n \n#include \"auth/KeyRing.h\"\n#include \"osd/ClassHandler.h\"\n\n#include \"include/CompatSet.h\"\n\n#include \"OpRequest.h\"\n#include \"Session.h\"\n\n#include \"osd/PGQueueable.h\"\n\n#include <atomic>\n#include <map>\n#include <memory>\n#include \"include/memory.h\"\nusing namespace std;\n\n#include \"include/unordered_map.h\"\n\n#include \"common/shared_cache.hpp\"\n#include \"common/simple_cache.hpp\"\n#include \"common/sharedptr_registry.hpp\"\n#include \"common/WeightedPriorityQueue.h\"\n#include \"common/PrioritizedQueue.h\"\n#include \"osd/mClockOpClassQueue.h\"\n#include \"osd/mClockClientQueue.h\"\n#include \"messages/MOSDOp.h\"\n#include \"include/Spinlock.h\"\n#include \"common/EventTrace.h\"\n\n#define CEPH_OSD_PROTOCOL    10 /* cluster internal */\n\n\nenum {\n  l_osd_first = 10000,\n  l_osd_op_wip,\n  l_osd_op,\n  l_osd_op_inb,\n  l_osd_op_outb,\n  l_osd_op_lat,\n  l_osd_op_process_lat,\n  l_osd_op_prepare_lat,\n  l_osd_op_r,\n  l_osd_op_r_outb,\n  l_osd_op_r_lat,\n  l_osd_op_r_lat_outb_hist,\n  l_osd_op_r_process_lat,\n  l_osd_op_r_prepare_lat,\n  l_osd_op_w,\n  l_osd_op_w_inb,\n  l_osd_op_w_lat,\n  l_osd_op_w_lat_inb_hist,\n  l_osd_op_w_process_lat,\n  l_osd_op_w_prepare_lat,\n  l_osd_op_rw,\n  l_osd_op_rw_inb,\n  l_osd_op_rw_outb,\n  l_osd_op_rw_lat,\n  l_osd_op_rw_lat_inb_hist,\n  l_osd_op_rw_lat_outb_hist,\n  l_osd_op_rw_process_lat,\n  l_osd_op_rw_prepare_lat,\n\n  l_osd_op_before_queue_op_lat,\n  l_osd_op_before_dequeue_op_lat,\n\n  l_osd_sop,\n  l_osd_sop_inb,\n  l_osd_sop_lat,\n  l_osd_sop_w,\n  l_osd_sop_w_inb,\n  l_osd_sop_w_lat,\n  l_osd_sop_pull,\n  l_osd_sop_pull_lat,\n  l_osd_sop_push,\n  l_osd_sop_push_inb,\n  l_osd_sop_push_lat,\n\n  l_osd_pull,\n  l_osd_push,\n  l_osd_push_outb,\n\n  l_osd_rop,\n\n  l_osd_loadavg,\n  l_osd_buf,\n  l_osd_history_alloc_bytes,\n  l_osd_history_alloc_num,\n  l_osd_cached_crc,\n  l_osd_cached_crc_adjusted,\n  l_osd_missed_crc,\n\n  l_osd_pg,\n  l_osd_pg_primary,\n  l_osd_pg_replica,\n  l_osd_pg_stray,\n  l_osd_pg_removing,\n  l_osd_hb_to,\n  l_osd_map,\n  l_osd_mape,\n  l_osd_mape_dup,\n\n  l_osd_waiting_for_map,\n\n  l_osd_map_cache_hit,\n  l_osd_map_cache_miss,\n  l_osd_map_cache_miss_low,\n  l_osd_map_cache_miss_low_avg,\n  l_osd_map_bl_cache_hit,\n  l_osd_map_bl_cache_miss,\n\n  l_osd_stat_bytes,\n  l_osd_stat_bytes_used,\n  l_osd_stat_bytes_avail,\n\n  l_osd_copyfrom,\n\n  l_osd_tier_promote,\n  l_osd_tier_flush,\n  l_osd_tier_flush_fail,\n  l_osd_tier_try_flush,\n  l_osd_tier_try_flush_fail,\n  l_osd_tier_evict,\n  l_osd_tier_whiteout,\n  l_osd_tier_dirty,\n  l_osd_tier_clean,\n  l_osd_tier_delay,\n  l_osd_tier_proxy_read,\n  l_osd_tier_proxy_write,\n\n  l_osd_agent_wake,\n  l_osd_agent_skip,\n  l_osd_agent_flush,\n  l_osd_agent_evict,\n\n  l_osd_object_ctx_cache_hit,\n  l_osd_object_ctx_cache_total,\n\n  l_osd_op_cache_hit,\n  l_osd_tier_flush_lat,\n  l_osd_tier_promote_lat,\n  l_osd_tier_r_lat,\n\n  l_osd_pg_info,\n  l_osd_pg_fastinfo,\n  l_osd_pg_biginfo,\n\n  l_osd_last,\n};\n\n// RecoveryState perf counters\nenum {\n  rs_first = 20000,\n  rs_initial_latency,\n  rs_started_latency,\n  rs_reset_latency,\n  rs_start_latency,\n  rs_primary_latency,\n  rs_peering_latency,\n  rs_backfilling_latency,\n  rs_waitremotebackfillreserved_latency,\n  rs_waitlocalbackfillreserved_latency,\n  rs_notbackfilling_latency,\n  rs_repnotrecovering_latency,\n  rs_repwaitrecoveryreserved_latency,\n  rs_repwaitbackfillreserved_latency,\n  rs_reprecovering_latency,\n  rs_activating_latency,\n  rs_waitlocalrecoveryreserved_latency,\n  rs_waitremoterecoveryreserved_latency,\n  rs_recovering_latency,\n  rs_recovered_latency,\n  rs_clean_latency,\n  rs_active_latency,\n  rs_replicaactive_latency,\n  rs_stray_latency,\n  rs_getinfo_latency,\n  rs_getlog_latency,\n  rs_waitactingchange_latency,\n  rs_incomplete_latency,\n  rs_down_latency,\n  rs_getmissing_latency,\n  rs_waitupthru_latency,\n  rs_notrecovering_latency,\n  rs_last,\n};\n\nclass Messenger;\nclass Message;\nclass MonClient;\nclass PerfCounters;\nclass ObjectStore;\nclass FuseStore;\nclass OSDMap;\nclass MLog;\nclass Objecter;\n\nclass Watch;\nclass PrimaryLogPG;\n\nclass AuthAuthorizeHandlerRegistry;\n\nclass TestOpsSocketHook;\nstruct C_CompleteSplits;\nstruct C_OpenPGs;\nclass LogChannel;\nclass CephContext;\ntypedef ceph::shared_ptr<ObjectStore::Sequencer> SequencerRef;\nclass MOSDOp;\n\nclass DeletingState {\n  Mutex lock;\n  Cond cond;\n  enum {\n    QUEUED,\n    CLEARING_DIR,\n    CLEARING_WAITING,\n    DELETING_DIR,\n    DELETED_DIR,\n    CANCELED,\n  } status;\n  bool stop_deleting;\npublic:\n  const spg_t pgid;\n  const PGRef old_pg_state;\n  explicit DeletingState(const pair<spg_t, PGRef> &in) :\n    lock(\"DeletingState::lock\"), status(QUEUED), stop_deleting(false),\n    pgid(in.first), old_pg_state(in.second) {\n    }\n\n  /// transition status to CLEARING_WAITING\n  bool pause_clearing() {\n    Mutex::Locker l(lock);\n    assert(status == CLEARING_DIR);\n    if (stop_deleting) {\n      status = CANCELED;\n      cond.Signal();\n      return false;\n    }\n    status = CLEARING_WAITING;\n    return true;\n  } ///< @return false if we should cancel deletion\n\n  /// start or resume the clearing - transition the status to CLEARING_DIR\n  bool start_or_resume_clearing() {\n    Mutex::Locker l(lock);\n    assert(\n      status == QUEUED ||\n      status == DELETED_DIR ||\n      status == CLEARING_WAITING);\n    if (stop_deleting) {\n      status = CANCELED;\n      cond.Signal();\n      return false;\n    }\n    status = CLEARING_DIR;\n    return true;\n  } ///< @return false if we should cancel the deletion\n\n  /// transition status to CLEARING_DIR\n  bool resume_clearing() {\n    Mutex::Locker l(lock);\n    assert(status == CLEARING_WAITING);\n    if (stop_deleting) {\n      status = CANCELED;\n      cond.Signal();\n      return false;\n    }\n    status = CLEARING_DIR;\n    return true;\n  } ///< @return false if we should cancel deletion\n\n  /// transition status to deleting\n  bool start_deleting() {\n    Mutex::Locker l(lock);\n    assert(status == CLEARING_DIR);\n    if (stop_deleting) {\n      status = CANCELED;\n      cond.Signal();\n      return false;\n    }\n    status = DELETING_DIR;\n    return true;\n  } ///< @return false if we should cancel deletion\n\n  /// signal collection removal queued\n  void finish_deleting() {\n    Mutex::Locker l(lock);\n    assert(status == DELETING_DIR);\n    status = DELETED_DIR;\n    cond.Signal();\n  }\n\n  /// try to halt the deletion\n  bool try_stop_deletion() {\n    Mutex::Locker l(lock);\n    stop_deleting = true;\n    /**\n     * If we are in DELETING_DIR or CLEARING_DIR, there are in progress\n     * operations we have to wait for before continuing on.  States\n     * CLEARING_WAITING and QUEUED indicate that the remover will check\n     * stop_deleting before queueing any further operations.  CANCELED\n     * indicates that the remover has already halted.  DELETED_DIR\n     * indicates that the deletion has been fully queued.\n     */\n    while (status == DELETING_DIR || status == CLEARING_DIR)\n      cond.Wait(lock);\n    return status != DELETED_DIR;\n  } ///< @return true if we don't need to recreate the collection\n};\ntypedef ceph::shared_ptr<DeletingState> DeletingStateRef;\n\nclass OSD;\n\nclass OSDService {\npublic:\n  OSD *osd;\n  CephContext *cct;\n  SharedPtrRegistry<spg_t, ObjectStore::Sequencer> osr_registry;\n  ceph::shared_ptr<ObjectStore::Sequencer> meta_osr;\n  SharedPtrRegistry<spg_t, DeletingState> deleting_pgs;\n  const int whoami;\n  ObjectStore *&store;\n  LogClient &log_client;\n  LogChannelRef clog;\n  PGRecoveryStats &pg_recovery_stats;\nprivate:\n  Messenger *&cluster_messenger;\n  Messenger *&client_messenger;\npublic:\n  PerfCounters *&logger;\n  PerfCounters *&recoverystate_perf;\n  MonClient   *&monc;\n  ThreadPool::BatchWorkQueue<PG> &peering_wq;\n  GenContextWQ recovery_gen_wq;\n  ClassHandler  *&class_handler;\n\n  void enqueue_back(spg_t pgid, PGQueueable qi);\n  void enqueue_front(spg_t pgid, PGQueueable qi);\n\n  void maybe_inject_dispatch_delay() {\n    if (g_conf->osd_debug_inject_dispatch_delay_probability > 0) {\n      if (rand() % 10000 <\n\t  g_conf->osd_debug_inject_dispatch_delay_probability * 10000) {\n\tutime_t t;\n\tt.set_from_double(g_conf->osd_debug_inject_dispatch_delay_duration);\n\tt.sleep();\n      }\n    }\n  }\n\nprivate:\n  // -- map epoch lower bound --\n  Mutex pg_epoch_lock;\n  multiset<epoch_t> pg_epochs;\n  map<spg_t,epoch_t> pg_epoch;\n\npublic:\n  void pg_add_epoch(spg_t pgid, epoch_t epoch) {\n    Mutex::Locker l(pg_epoch_lock);\n    map<spg_t,epoch_t>::iterator t = pg_epoch.find(pgid);\n    assert(t == pg_epoch.end());\n    pg_epoch[pgid] = epoch;\n    pg_epochs.insert(epoch);\n  }\n  void pg_update_epoch(spg_t pgid, epoch_t epoch) {\n    Mutex::Locker l(pg_epoch_lock);\n    map<spg_t,epoch_t>::iterator t = pg_epoch.find(pgid);\n    assert(t != pg_epoch.end());\n    pg_epochs.erase(pg_epochs.find(t->second));\n    t->second = epoch;\n    pg_epochs.insert(epoch);\n  }\n  void pg_remove_epoch(spg_t pgid) {\n    Mutex::Locker l(pg_epoch_lock);\n    map<spg_t,epoch_t>::iterator t = pg_epoch.find(pgid);\n    if (t != pg_epoch.end()) {\n      pg_epochs.erase(pg_epochs.find(t->second));\n      pg_epoch.erase(t);\n    }\n  }\n  epoch_t get_min_pg_epoch() {\n    Mutex::Locker l(pg_epoch_lock);\n    if (pg_epochs.empty())\n      return 0;\n    else\n      return *pg_epochs.begin();\n  }\n\nprivate:\n  // -- superblock --\n  Mutex publish_lock, pre_publish_lock; // pre-publish orders before publish\n  OSDSuperblock superblock;\n\npublic:\n  OSDSuperblock get_superblock() {\n    Mutex::Locker l(publish_lock);\n    return superblock;\n  }\n  void publish_superblock(const OSDSuperblock &block) {\n    Mutex::Locker l(publish_lock);\n    superblock = block;\n  }\n\n  int get_nodeid() const { return whoami; }\n\n  std::atomic<epoch_t> max_oldest_map;\nprivate:\n  OSDMapRef osdmap;\n\npublic:\n  OSDMapRef get_osdmap() {\n    Mutex::Locker l(publish_lock);\n    return osdmap;\n  }\n  epoch_t get_osdmap_epoch() {\n    Mutex::Locker l(publish_lock);\n    return osdmap ? osdmap->get_epoch() : 0;\n  }\n  void publish_map(OSDMapRef map) {\n    Mutex::Locker l(publish_lock);\n    osdmap = map;\n  }\n\n  /*\n   * osdmap - current published map\n   * next_osdmap - pre_published map that is about to be published.\n   *\n   * We use the next_osdmap to send messages and initiate connections,\n   * but only if the target is the same instance as the one in the map\n   * epoch the current user is working from (i.e., the result is\n   * equivalent to what is in next_osdmap).\n   *\n   * This allows the helpers to start ignoring osds that are about to\n   * go down, and let OSD::handle_osd_map()/note_down_osd() mark them\n   * down, without worrying about reopening connections from threads\n   * working from old maps.\n   */\nprivate:\n  OSDMapRef next_osdmap;\n  Cond pre_publish_cond;\n\npublic:\n  void pre_publish_map(OSDMapRef map) {\n    Mutex::Locker l(pre_publish_lock);\n    next_osdmap = std::move(map);\n  }\n\n  void activate_map();\n  /// map epochs reserved below\n  map<epoch_t, unsigned> map_reservations;\n\n  /// gets ref to next_osdmap and registers the epoch as reserved\n  OSDMapRef get_nextmap_reserved() {\n    Mutex::Locker l(pre_publish_lock);\n    if (!next_osdmap)\n      return OSDMapRef();\n    epoch_t e = next_osdmap->get_epoch();\n    map<epoch_t, unsigned>::iterator i =\n      map_reservations.insert(make_pair(e, 0)).first;\n    i->second++;\n    return next_osdmap;\n  }\n  /// releases reservation on map\n  void release_map(OSDMapRef osdmap) {\n    Mutex::Locker l(pre_publish_lock);\n    map<epoch_t, unsigned>::iterator i =\n      map_reservations.find(osdmap->get_epoch());\n    assert(i != map_reservations.end());\n    assert(i->second > 0);\n    if (--(i->second) == 0) {\n      map_reservations.erase(i);\n    }\n    pre_publish_cond.Signal();\n  }\n  /// blocks until there are no reserved maps prior to next_osdmap\n  void await_reserved_maps() {\n    Mutex::Locker l(pre_publish_lock);\n    assert(next_osdmap);\n    while (true) {\n      map<epoch_t, unsigned>::const_iterator i = map_reservations.cbegin();\n      if (i == map_reservations.cend() || i->first >= next_osdmap->get_epoch()) {\n\tbreak;\n      } else {\n\tpre_publish_cond.Wait(pre_publish_lock);\n      }\n    }\n  }\n\nprivate:\n  Mutex peer_map_epoch_lock;\n  map<int, epoch_t> peer_map_epoch;\npublic:\n  epoch_t get_peer_epoch(int p);\n  epoch_t note_peer_epoch(int p, epoch_t e);\n  void forget_peer_epoch(int p, epoch_t e);\n\n  void send_map(class MOSDMap *m, Connection *con);\n  void send_incremental_map(epoch_t since, Connection *con, OSDMapRef& osdmap);\n  MOSDMap *build_incremental_map_msg(epoch_t from, epoch_t to,\n                                       OSDSuperblock& superblock);\n  bool should_share_map(entity_name_t name, Connection *con, epoch_t epoch,\n                        const OSDMapRef& osdmap, const epoch_t *sent_epoch_p);\n  void share_map(entity_name_t name, Connection *con, epoch_t epoch,\n                 OSDMapRef& osdmap, epoch_t *sent_epoch_p);\n  void share_map_peer(int peer, Connection *con,\n                      OSDMapRef map = OSDMapRef());\n\n  ConnectionRef get_con_osd_cluster(int peer, epoch_t from_epoch);\n  pair<ConnectionRef,ConnectionRef> get_con_osd_hb(int peer, epoch_t from_epoch);  // (back, front)\n  void send_message_osd_cluster(int peer, Message *m, epoch_t from_epoch);\n  void send_message_osd_cluster(Message *m, Connection *con) {\n    con->send_message(m);\n  }\n  void send_message_osd_cluster(Message *m, const ConnectionRef& con) {\n    con->send_message(m);\n  }\n  void send_message_osd_client(Message *m, Connection *con) {\n    con->send_message(m);\n  }\n  void send_message_osd_client(Message *m, const ConnectionRef& con) {\n    con->send_message(m);\n  }\n  entity_name_t get_cluster_msgr_name() {\n    return cluster_messenger->get_myname();\n  }\n\nprivate:\n  // -- scrub scheduling --\n  Mutex sched_scrub_lock;\n  int scrubs_pending;\n  int scrubs_active;\n\npublic:\n  struct ScrubJob {\n    CephContext* cct;\n    /// pg to be scrubbed\n    spg_t pgid;\n    /// a time scheduled for scrub. but the scrub could be delayed if system\n    /// load is too high or it fails to fall in the scrub hours\n    utime_t sched_time;\n    /// the hard upper bound of scrub time\n    utime_t deadline;\n    ScrubJob() : cct(nullptr) {}\n    explicit ScrubJob(CephContext* cct, const spg_t& pg,\n\t\t      const utime_t& timestamp,\n\t\t      double pool_scrub_min_interval = 0,\n\t\t      double pool_scrub_max_interval = 0, bool must = true);\n    /// order the jobs by sched_time\n    bool operator<(const ScrubJob& rhs) const;\n  };\n  set<ScrubJob> sched_scrub_pg;\n\n  /// @returns the scrub_reg_stamp used for unregister the scrub job\n  utime_t reg_pg_scrub(spg_t pgid, utime_t t, double pool_scrub_min_interval,\n\t\t       double pool_scrub_max_interval, bool must) {\n    ScrubJob scrub(cct, pgid, t, pool_scrub_min_interval, pool_scrub_max_interval,\n\t\t   must);\n    Mutex::Locker l(sched_scrub_lock);\n    sched_scrub_pg.insert(scrub);\n    return scrub.sched_time;\n  }\n  void unreg_pg_scrub(spg_t pgid, utime_t t) {\n    Mutex::Locker l(sched_scrub_lock);\n    size_t removed = sched_scrub_pg.erase(ScrubJob(cct, pgid, t));\n    assert(removed);\n  }\n  bool first_scrub_stamp(ScrubJob *out) {\n    Mutex::Locker l(sched_scrub_lock);\n    if (sched_scrub_pg.empty())\n      return false;\n    set<ScrubJob>::iterator iter = sched_scrub_pg.begin();\n    *out = *iter;\n    return true;\n  }\n  bool next_scrub_stamp(const ScrubJob& next,\n\t\t\tScrubJob *out) {\n    Mutex::Locker l(sched_scrub_lock);\n    if (sched_scrub_pg.empty())\n      return false;\n    set<ScrubJob>::const_iterator iter = sched_scrub_pg.lower_bound(next);\n    if (iter == sched_scrub_pg.cend())\n      return false;\n    ++iter;\n    if (iter == sched_scrub_pg.cend())\n      return false;\n    *out = *iter;\n    return true;\n  }\n\n  void dumps_scrub(Formatter *f) {\n    assert(f != nullptr);\n    Mutex::Locker l(sched_scrub_lock);\n\n    f->open_array_section(\"scrubs\");\n    for (const auto &i: sched_scrub_pg) {\n      f->open_object_section(\"scrub\");\n      f->dump_stream(\"pgid\") << i.pgid;\n      f->dump_stream(\"sched_time\") << i.sched_time;\n      f->dump_stream(\"deadline\") << i.deadline;\n      f->dump_bool(\"forced\", i.sched_time == i.deadline);\n      f->close_section();\n    }\n    f->close_section();\n  }\n\n  bool can_inc_scrubs_pending();\n  bool inc_scrubs_pending();\n  void inc_scrubs_active(bool reserved);\n  void dec_scrubs_pending();\n  void dec_scrubs_active();\n\n  void reply_op_error(OpRequestRef op, int err);\n  void reply_op_error(OpRequestRef op, int err, eversion_t v, version_t uv);\n  void handle_misdirected_op(PG *pg, OpRequestRef op);\n\n\nprivate:\n  // -- agent shared state --\n  Mutex agent_lock;\n  Cond agent_cond;\n  map<uint64_t, set<PGRef> > agent_queue;\n  set<PGRef>::iterator agent_queue_pos;\n  bool agent_valid_iterator;\n  int agent_ops;\n  int flush_mode_high_count; //once have one pg with FLUSH_MODE_HIGH then flush objects with high speed\n  set<hobject_t> agent_oids;\n  bool agent_active;\n  struct AgentThread : public Thread {\n    OSDService *osd;\n    explicit AgentThread(OSDService *o) : osd(o) {}\n    void *entry() override {\n      osd->agent_entry();\n      return NULL;\n    }\n  } agent_thread;\n  bool agent_stop_flag;\n  Mutex agent_timer_lock;\n  SafeTimer agent_timer;\n\npublic:\n  void agent_entry();\n  void agent_stop();\n\n  void _enqueue(PG *pg, uint64_t priority) {\n    if (!agent_queue.empty() &&\n\tagent_queue.rbegin()->first < priority)\n      agent_valid_iterator = false;  // inserting higher-priority queue\n    set<PGRef>& nq = agent_queue[priority];\n    if (nq.empty())\n      agent_cond.Signal();\n    nq.insert(pg);\n  }\n\n  void _dequeue(PG *pg, uint64_t old_priority) {\n    set<PGRef>& oq = agent_queue[old_priority];\n    set<PGRef>::iterator p = oq.find(pg);\n    assert(p != oq.end());\n    if (p == agent_queue_pos)\n      ++agent_queue_pos;\n    oq.erase(p);\n    if (oq.empty()) {\n      if (agent_queue.rbegin()->first == old_priority)\n\tagent_valid_iterator = false;\n      agent_queue.erase(old_priority);\n    }\n  }\n\n  /// enable agent for a pg\n  void agent_enable_pg(PG *pg, uint64_t priority) {\n    Mutex::Locker l(agent_lock);\n    _enqueue(pg, priority);\n  }\n\n  /// adjust priority for an enagled pg\n  void agent_adjust_pg(PG *pg, uint64_t old_priority, uint64_t new_priority) {\n    Mutex::Locker l(agent_lock);\n    assert(new_priority != old_priority);\n    _enqueue(pg, new_priority);\n    _dequeue(pg, old_priority);\n  }\n\n  /// disable agent for a pg\n  void agent_disable_pg(PG *pg, uint64_t old_priority) {\n    Mutex::Locker l(agent_lock);\n    _dequeue(pg, old_priority);\n  }\n\n  /// note start of an async (evict) op\n  void agent_start_evict_op() {\n    Mutex::Locker l(agent_lock);\n    ++agent_ops;\n  }\n\n  /// note finish or cancellation of an async (evict) op\n  void agent_finish_evict_op() {\n    Mutex::Locker l(agent_lock);\n    assert(agent_ops > 0);\n    --agent_ops;\n    agent_cond.Signal();\n  }\n\n  /// note start of an async (flush) op\n  void agent_start_op(const hobject_t& oid) {\n    Mutex::Locker l(agent_lock);\n    ++agent_ops;\n    assert(agent_oids.count(oid) == 0);\n    agent_oids.insert(oid);\n  }\n\n  /// note finish or cancellation of an async (flush) op\n  void agent_finish_op(const hobject_t& oid) {\n    Mutex::Locker l(agent_lock);\n    assert(agent_ops > 0);\n    --agent_ops;\n    assert(agent_oids.count(oid) == 1);\n    agent_oids.erase(oid);\n    agent_cond.Signal();\n  }\n\n  /// check if we are operating on an object\n  bool agent_is_active_oid(const hobject_t& oid) {\n    Mutex::Locker l(agent_lock);\n    return agent_oids.count(oid);\n  }\n\n  /// get count of active agent ops\n  int agent_get_num_ops() {\n    Mutex::Locker l(agent_lock);\n    return agent_ops;\n  }\n\n  void agent_inc_high_count() {\n    Mutex::Locker l(agent_lock);\n    flush_mode_high_count ++;\n  }\n\n  void agent_dec_high_count() {\n    Mutex::Locker l(agent_lock);\n    flush_mode_high_count --;\n  }\n\nprivate:\n  /// throttle promotion attempts\n  std::atomic_uint promote_probability_millis{1000}; ///< probability thousands. one word.\n  PromoteCounter promote_counter;\n  utime_t last_recalibrate;\n  unsigned long promote_max_objects, promote_max_bytes;\n\npublic:\n  bool promote_throttle() {\n    // NOTE: lockless!  we rely on the probability being a single word.\n    promote_counter.attempt();\n    if ((unsigned)rand() % 1000 > promote_probability_millis)\n      return true;  // yes throttle (no promote)\n    if (promote_max_objects &&\n\tpromote_counter.objects > promote_max_objects)\n      return true;  // yes throttle\n    if (promote_max_bytes &&\n\tpromote_counter.bytes > promote_max_bytes)\n      return true;  // yes throttle\n    return false;   //  no throttle (promote)\n  }\n  void promote_finish(uint64_t bytes) {\n    promote_counter.finish(bytes);\n  }\n  void promote_throttle_recalibrate();\n\n  // -- Objecter, for tiering reads/writes from/to other OSDs --\n  Objecter *objecter;\n  Finisher objecter_finisher;\n\n  // -- Watch --\n  Mutex watch_lock;\n  SafeTimer watch_timer;\n  uint64_t next_notif_id;\n  uint64_t get_next_id(epoch_t cur_epoch) {\n    Mutex::Locker l(watch_lock);\n    return (((uint64_t)cur_epoch) << 32) | ((uint64_t)(next_notif_id++));\n  }\n\n  // -- Recovery/Backfill Request Scheduling --\n  Mutex recovery_request_lock;\n  SafeTimer recovery_request_timer;\n\n  // For async recovery sleep\n  bool recovery_needs_sleep = true;\n  utime_t recovery_schedule_time = utime_t();\n\n  Mutex recovery_sleep_lock;\n  SafeTimer recovery_sleep_timer;\n\n  // -- tids --\n  // for ops i issue\n  std::atomic_uint last_tid{0};\n  ceph_tid_t get_tid() {\n    return (ceph_tid_t)last_tid++;\n  }\n\n  // -- backfill_reservation --\n  Finisher reserver_finisher;\n  AsyncReserver<spg_t> local_reserver;\n  AsyncReserver<spg_t> remote_reserver;\n\n  // -- pg_temp --\nprivate:\n  Mutex pg_temp_lock;\n  struct pg_temp_t {\n    pg_temp_t()\n    {}\n    pg_temp_t(vector<int> v, bool f)\n      : acting{v}, forced{f}\n    {}\n    vector<int> acting;\n    bool forced = false;\n  };\n  map<pg_t, pg_temp_t> pg_temp_wanted;\n  map<pg_t, pg_temp_t> pg_temp_pending;\n  void _sent_pg_temp();\n  friend std::ostream& operator<<(std::ostream&, const pg_temp_t&);\npublic:\n  void queue_want_pg_temp(pg_t pgid, const vector<int>& want,\n\t\t\t  bool forced = false);\n  void remove_want_pg_temp(pg_t pgid);\n  void requeue_pg_temp();\n  void send_pg_temp();\n\n  void send_pg_created(pg_t pgid);\n\n  void queue_for_peering(PG *pg);\n\n  Mutex snap_sleep_lock;\n  SafeTimer snap_sleep_timer;\n\n  Mutex scrub_sleep_lock;\n  SafeTimer scrub_sleep_timer;\n\n  AsyncReserver<spg_t> snap_reserver;\n  void queue_for_snap_trim(PG *pg);\n\n  void queue_for_scrub(PG *pg, bool with_high_priority) {\n    unsigned scrub_queue_priority = pg->scrubber.priority;\n    if (with_high_priority && scrub_queue_priority < cct->_conf->osd_client_op_priority) {\n      scrub_queue_priority = cct->_conf->osd_client_op_priority;\n    }\n    enqueue_back(\n      pg->info.pgid,\n      PGQueueable(\n\tPGScrub(pg->get_osdmap()->get_epoch()),\n\tcct->_conf->osd_scrub_cost,\n\tscrub_queue_priority,\n\tceph_clock_now(),\n\tentity_inst_t(),\n\tpg->get_osdmap()->get_epoch()));\n  }\n\nprivate:\n  // -- pg recovery and associated throttling --\n  Mutex recovery_lock;\n  list<pair<epoch_t, PGRef> > awaiting_throttle;\n\n  utime_t defer_recovery_until;\n  uint64_t recovery_ops_active;\n  uint64_t recovery_ops_reserved;\n  bool recovery_paused;\n#ifdef DEBUG_RECOVERY_OIDS\n  map<spg_t, set<hobject_t> > recovery_oids;\n#endif\n  bool _recover_now(uint64_t *available_pushes);\n  void _maybe_queue_recovery();\n  void _queue_for_recovery(\n    pair<epoch_t, PGRef> p, uint64_t reserved_pushes) {\n    assert(recovery_lock.is_locked_by_me());\n    enqueue_back(\n      p.second->info.pgid,\n      PGQueueable(\n\tPGRecovery(p.first, reserved_pushes),\n\tcct->_conf->osd_recovery_cost,\n\tcct->_conf->osd_recovery_priority,\n\tceph_clock_now(),\n\tentity_inst_t(),\n\tp.first));\n  }\npublic:\n  void start_recovery_op(PG *pg, const hobject_t& soid);\n  void finish_recovery_op(PG *pg, const hobject_t& soid, bool dequeue);\n  bool is_recovery_active();\n  void release_reserved_pushes(uint64_t pushes) {\n    Mutex::Locker l(recovery_lock);\n    assert(recovery_ops_reserved >= pushes);\n    recovery_ops_reserved -= pushes;\n    _maybe_queue_recovery();\n  }\n  void defer_recovery(float defer_for) {\n    defer_recovery_until = ceph_clock_now();\n    defer_recovery_until += defer_for;\n  }\n  void pause_recovery() {\n    Mutex::Locker l(recovery_lock);\n    recovery_paused = true;\n  }\n  bool recovery_is_paused() {\n    Mutex::Locker l(recovery_lock);\n    return recovery_paused;\n  }\n  void unpause_recovery() {\n    Mutex::Locker l(recovery_lock);\n    recovery_paused = false;\n    _maybe_queue_recovery();\n  }\n  void kick_recovery_queue() {\n    Mutex::Locker l(recovery_lock);\n    _maybe_queue_recovery();\n  }\n  void clear_queued_recovery(PG *pg) {\n    Mutex::Locker l(recovery_lock);\n    for (list<pair<epoch_t, PGRef> >::iterator i = awaiting_throttle.begin();\n\t i != awaiting_throttle.end();\n      ) {\n      if (i->second.get() == pg) {\n\tawaiting_throttle.erase(i);\n\treturn;\n      } else {\n\t++i;\n      }\n    }\n  }\n  // delayed pg activation\n  void queue_for_recovery(PG *pg) {\n    Mutex::Locker l(recovery_lock);\n\n    if (pg->get_state() & (PG_STATE_FORCED_RECOVERY | PG_STATE_FORCED_BACKFILL)) {\n      awaiting_throttle.push_front(make_pair(pg->get_osdmap()->get_epoch(), pg));\n    } else {\n      awaiting_throttle.push_back(make_pair(pg->get_osdmap()->get_epoch(), pg));\n    }\n    _maybe_queue_recovery();\n  }\n  void queue_recovery_after_sleep(PG *pg, epoch_t queued, uint64_t reserved_pushes) {\n    Mutex::Locker l(recovery_lock);\n    _queue_for_recovery(make_pair(queued, pg), reserved_pushes);\n  }\n\n  void adjust_pg_priorities(const vector<PGRef>& pgs, int newflags);\n\n  // osd map cache (past osd maps)\n  Mutex map_cache_lock;\n  SharedLRU<epoch_t, const OSDMap> map_cache;\n  SimpleLRU<epoch_t, bufferlist> map_bl_cache;\n  SimpleLRU<epoch_t, bufferlist> map_bl_inc_cache;\n\n  OSDMapRef try_get_map(epoch_t e);\n  OSDMapRef get_map(epoch_t e) {\n    OSDMapRef ret(try_get_map(e));\n    assert(ret);\n    return ret;\n  }\n  OSDMapRef add_map(OSDMap *o) {\n    Mutex::Locker l(map_cache_lock);\n    return _add_map(o);\n  }\n  OSDMapRef _add_map(OSDMap *o);\n\n  void add_map_bl(epoch_t e, bufferlist& bl) {\n    Mutex::Locker l(map_cache_lock);\n    return _add_map_bl(e, bl);\n  }\n  void pin_map_bl(epoch_t e, bufferlist &bl);\n  void _add_map_bl(epoch_t e, bufferlist& bl);\n  bool get_map_bl(epoch_t e, bufferlist& bl) {\n    Mutex::Locker l(map_cache_lock);\n    return _get_map_bl(e, bl);\n  }\n  bool _get_map_bl(epoch_t e, bufferlist& bl);\n\n  void add_map_inc_bl(epoch_t e, bufferlist& bl) {\n    Mutex::Locker l(map_cache_lock);\n    return _add_map_inc_bl(e, bl);\n  }\n  void pin_map_inc_bl(epoch_t e, bufferlist &bl);\n  void _add_map_inc_bl(epoch_t e, bufferlist& bl);\n  bool get_inc_map_bl(epoch_t e, bufferlist& bl);\n\n  void clear_map_bl_cache_pins(epoch_t e);\n\n  void need_heartbeat_peer_update();\n\n  void pg_stat_queue_enqueue(PG *pg);\n  void pg_stat_queue_dequeue(PG *pg);\n\n  void init();\n  void final_init();  \n  void start_shutdown();\n  void shutdown_reserver();\n  void shutdown();\n\nprivate:\n  // split\n  Mutex in_progress_split_lock;\n  map<spg_t, spg_t> pending_splits; // child -> parent\n  map<spg_t, set<spg_t> > rev_pending_splits; // parent -> [children]\n  set<spg_t> in_progress_splits;       // child\n\npublic:\n  void _start_split(spg_t parent, const set<spg_t> &children);\n  void start_split(spg_t parent, const set<spg_t> &children) {\n    Mutex::Locker l(in_progress_split_lock);\n    return _start_split(parent, children);\n  }\n  void mark_split_in_progress(spg_t parent, const set<spg_t> &pgs);\n  void complete_split(const set<spg_t> &pgs);\n  void cancel_pending_splits_for_parent(spg_t parent);\n  void _cancel_pending_splits_for_parent(spg_t parent);\n  bool splitting(spg_t pgid);\n  void expand_pg_num(OSDMapRef old_map,\n\t\t     OSDMapRef new_map);\n  void _maybe_split_pgid(OSDMapRef old_map,\n\t\t\t OSDMapRef new_map,\n\t\t\t spg_t pgid);\n  void init_splits_between(spg_t pgid, OSDMapRef frommap, OSDMapRef tomap);\n\n  // -- stats --\n  Mutex stat_lock;\n  osd_stat_t osd_stat;\n  uint32_t seq = 0;\n\n  void update_osd_stat(vector<int>& hb_peers);\n  osd_stat_t set_osd_stat(const struct store_statfs_t &stbuf,\n                          vector<int>& hb_peers,\n\t\t\t  int num_pgs);\n  osd_stat_t get_osd_stat() {\n    Mutex::Locker l(stat_lock);\n    ++seq;\n    osd_stat.up_from = up_epoch;\n    osd_stat.seq = ((uint64_t)osd_stat.up_from << 32) + seq;\n    return osd_stat;\n  }\n  uint64_t get_osd_stat_seq() {\n    Mutex::Locker l(stat_lock);\n    return osd_stat.seq;\n  }\n\n  // -- OSD Full Status --\nprivate:\n  friend TestOpsSocketHook;\n  mutable Mutex full_status_lock;\n  enum s_names { INVALID = -1, NONE, NEARFULL, BACKFILLFULL, FULL, FAILSAFE } cur_state;  // ascending\n  const char *get_full_state_name(s_names s) const {\n    switch (s) {\n    case NONE: return \"none\";\n    case NEARFULL: return \"nearfull\";\n    case BACKFILLFULL: return \"backfillfull\";\n    case FULL: return \"full\";\n    case FAILSAFE: return \"failsafe\";\n    default: return \"???\";\n    }\n  }\n  s_names get_full_state(string type) const {\n    if (type == \"none\")\n      return NONE;\n    else if (type == \"failsafe\")\n      return FAILSAFE;\n    else if (type == \"full\")\n      return FULL;\n    else if (type == \"backfillfull\")\n      return BACKFILLFULL;\n    else if (type == \"nearfull\")\n      return NEARFULL;\n    else\n      return INVALID;\n  }\n  double cur_ratio;  ///< current utilization\n  mutable int64_t injectfull = 0;\n  s_names injectfull_state = NONE;\n  float get_failsafe_full_ratio();\n  void check_full_status(float ratio);\n  bool _check_full(s_names type, ostream &ss) const;\npublic:\n  bool check_failsafe_full(ostream &ss) const;\n  bool check_full(ostream &ss) const;\n  bool check_backfill_full(ostream &ss) const;\n  bool check_nearfull(ostream &ss) const;\n  bool is_failsafe_full() const;\n  bool is_full() const;\n  bool is_backfillfull() const;\n  bool is_nearfull() const;\n  bool need_fullness_update();  ///< osdmap state needs update\n  void set_injectfull(s_names type, int64_t count);\n  bool check_osdmap_full(const set<pg_shard_t> &missing_on);\n\n\n  // -- epochs --\nprivate:\n  mutable Mutex epoch_lock; // protects access to boot_epoch, up_epoch, bind_epoch\n  epoch_t boot_epoch;  // _first_ epoch we were marked up (after this process started)\n  epoch_t up_epoch;    // _most_recent_ epoch we were marked up\n  epoch_t bind_epoch;  // epoch we last did a bind to new ip:ports\npublic:\n  /**\n   * Retrieve the boot_, up_, and bind_ epochs the OSD has set. The params\n   * can be NULL if you don't care about them.\n   */\n  void retrieve_epochs(epoch_t *_boot_epoch, epoch_t *_up_epoch,\n                       epoch_t *_bind_epoch) const;\n  /**\n   * Set the boot, up, and bind epochs. Any NULL params will not be set.\n   */\n  void set_epochs(const epoch_t *_boot_epoch, const epoch_t *_up_epoch,\n                  const epoch_t *_bind_epoch);\n  epoch_t get_boot_epoch() const {\n    epoch_t ret;\n    retrieve_epochs(&ret, NULL, NULL);\n    return ret;\n  }\n  epoch_t get_up_epoch() const {\n    epoch_t ret;\n    retrieve_epochs(NULL, &ret, NULL);\n    return ret;\n  }\n  epoch_t get_bind_epoch() const {\n    epoch_t ret;\n    retrieve_epochs(NULL, NULL, &ret);\n    return ret;\n  }\n\n  void request_osdmap_update(epoch_t e);\n\n  // -- stopping --\n  Mutex is_stopping_lock;\n  Cond is_stopping_cond;\n  enum {\n    NOT_STOPPING,\n    PREPARING_TO_STOP,\n    STOPPING };\n  std::atomic_int state{NOT_STOPPING};\n  int get_state() {\n    return state;\n  }\n  void set_state(int s) {\n    state = s;\n  }\n  bool is_stopping() const {\n    return state == STOPPING;\n  }\n  bool is_preparing_to_stop() const {\n    return state == PREPARING_TO_STOP;\n  }\n  bool prepare_to_stop();\n  void got_stop_ack();\n\n\n#ifdef PG_DEBUG_REFS\n  Mutex pgid_lock;\n  map<spg_t, int> pgid_tracker;\n  map<spg_t, PG*> live_pgs;\n  void add_pgid(spg_t pgid, PG *pg);\n  void remove_pgid(spg_t pgid, PG *pg);\n  void dump_live_pgids();\n#endif\n\n  explicit OSDService(OSD *osd);\n  ~OSDService();\n};\n\nclass OSD : public Dispatcher,\n\t    public md_config_obs_t {\n  /** OSD **/\n  Mutex osd_lock;\t\t\t// global lock\n  SafeTimer tick_timer;    // safe timer (osd_lock)\n\n  // Tick timer for those stuff that do not need osd_lock\n  Mutex tick_timer_lock;\n  SafeTimer tick_timer_without_osd_lock;\npublic:\n  // config observer bits\n  const char** get_tracked_conf_keys() const override;\n  void handle_conf_change(const struct md_config_t *conf,\n                          const std::set <std::string> &changed) override;\n  void update_log_config();\n  void check_config();\n\nprotected:\n\n  static const double OSD_TICK_INTERVAL; // tick interval for tick_timer and tick_timer_without_osd_lock\n\n  AuthAuthorizeHandlerRegistry *authorize_handler_cluster_registry;\n  AuthAuthorizeHandlerRegistry *authorize_handler_service_registry;\n\n  Messenger   *cluster_messenger;\n  Messenger   *client_messenger;\n  Messenger   *objecter_messenger;\n  MonClient   *monc; // check the \"monc helpers\" list before accessing directly\n  MgrClient   mgrc;\n  PerfCounters      *logger;\n  PerfCounters      *recoverystate_perf;\n  ObjectStore *store;\n#ifdef HAVE_LIBFUSE\n  FuseStore *fuse_store = nullptr;\n#endif\n  LogClient log_client;\n  LogChannelRef clog;\n\n  int whoami;\n  std::string dev_path, journal_path;\n\n  bool store_is_rotational = true;\n  bool journal_is_rotational = true;\n\n  ZTracer::Endpoint trace_endpoint;\n  void create_logger();\n  void create_recoverystate_perf();\n  void tick();\n  void tick_without_osd_lock();\n  void _dispatch(Message *m);\n  void dispatch_op(OpRequestRef op);\n\n  void check_osdmap_features(ObjectStore *store);\n\n  // asok\n  friend class OSDSocketHook;\n  class OSDSocketHook *asok_hook;\n  bool asok_command(string admin_command, cmdmap_t& cmdmap, string format, ostream& ss);\n\npublic:\n  ClassHandler  *class_handler = nullptr;\n  int get_nodeid() { return whoami; }\n  \n  static ghobject_t get_osdmap_pobject_name(epoch_t epoch) {\n    char foo[20];\n    snprintf(foo, sizeof(foo), \"osdmap.%d\", epoch);\n    return ghobject_t(hobject_t(sobject_t(object_t(foo), 0)));\n  }\n  static ghobject_t get_inc_osdmap_pobject_name(epoch_t epoch) {\n    char foo[22];\n    snprintf(foo, sizeof(foo), \"inc_osdmap.%d\", epoch);\n    return ghobject_t(hobject_t(sobject_t(object_t(foo), 0)));\n  }\n\n  static ghobject_t make_snapmapper_oid() {\n    return ghobject_t(hobject_t(\n      sobject_t(\n\tobject_t(\"snapmapper\"),\n\t0)));\n  }\n\n  static ghobject_t make_pg_log_oid(spg_t pg) {\n    stringstream ss;\n    ss << \"pglog_\" << pg;\n    string s;\n    getline(ss, s);\n    return ghobject_t(hobject_t(sobject_t(object_t(s.c_str()), 0)));\n  }\n  \n  static ghobject_t make_pg_biginfo_oid(spg_t pg) {\n    stringstream ss;\n    ss << \"pginfo_\" << pg;\n    string s;\n    getline(ss, s);\n    return ghobject_t(hobject_t(sobject_t(object_t(s.c_str()), 0)));\n  }\n  static ghobject_t make_infos_oid() {\n    hobject_t oid(sobject_t(\"infos\", CEPH_NOSNAP));\n    return ghobject_t(oid);\n  }\n  static void recursive_remove_collection(CephContext* cct,\n\t\t\t\t\t  ObjectStore *store,\n\t\t\t\t\t  spg_t pgid,\n\t\t\t\t\t  coll_t tmp);\n\n  /**\n   * get_osd_initial_compat_set()\n   *\n   * Get the initial feature set for this OSD.  Features\n   * here are automatically upgraded.\n   *\n   * Return value: Initial osd CompatSet\n   */\n  static CompatSet get_osd_initial_compat_set();\n\n  /**\n   * get_osd_compat_set()\n   *\n   * Get all features supported by this OSD\n   *\n   * Return value: CompatSet of all supported features\n   */\n  static CompatSet get_osd_compat_set();\n  \n\nprivate:\n  class C_Tick;\n  class C_Tick_WithoutOSDLock;\n\n  // -- superblock --\n  OSDSuperblock superblock;\n\n  void write_superblock();\n  void write_superblock(ObjectStore::Transaction& t);\n  int read_superblock();\n\n  void clear_temp_objects();\n\n  CompatSet osd_compat;\n\n  // -- state --\npublic:\n  typedef enum {\n    STATE_INITIALIZING = 1,\n    STATE_PREBOOT,\n    STATE_BOOTING,\n    STATE_ACTIVE,\n    STATE_STOPPING,\n    STATE_WAITING_FOR_HEALTHY\n  } osd_state_t;\n\n  static const char *get_state_name(int s) {\n    switch (s) {\n    case STATE_INITIALIZING: return \"initializing\";\n    case STATE_PREBOOT: return \"preboot\";\n    case STATE_BOOTING: return \"booting\";\n    case STATE_ACTIVE: return \"active\";\n    case STATE_STOPPING: return \"stopping\";\n    case STATE_WAITING_FOR_HEALTHY: return \"waiting_for_healthy\";\n    default: return \"???\";\n    }\n  }\n\nprivate:\n  std::atomic_int state{STATE_INITIALIZING};\n  bool waiting_for_luminous_mons = false;\n\npublic:\n  int get_state() const {\n    return state;\n  }\n  void set_state(int s) {\n    state = s;\n  }\n  bool is_initializing() const {\n    return state == STATE_INITIALIZING;\n  }\n  bool is_preboot() const {\n    return state == STATE_PREBOOT;\n  }\n  bool is_booting() const {\n    return state == STATE_BOOTING;\n  }\n  bool is_active() const {\n    return state == STATE_ACTIVE;\n  }\n  bool is_stopping() const {\n    return state == STATE_STOPPING;\n  }\n  bool is_waiting_for_healthy() const {\n    return state == STATE_WAITING_FOR_HEALTHY;\n  }\n\nprivate:\n\n  ThreadPool peering_tp;\n  ShardedThreadPool osd_op_tp;\n  ThreadPool disk_tp;\n  ThreadPool command_tp;\n\n  void set_disk_tp_priority();\n  void get_latest_osdmap();\n\n  // -- sessions --\nprivate:\n  void dispatch_session_waiting(Session *session, OSDMapRef osdmap);\n  void maybe_share_map(Session *session, OpRequestRef op, OSDMapRef osdmap);\n\n  Mutex session_waiting_lock;\n  set<Session*> session_waiting_for_map;\n\n  /// Caller assumes refs for included Sessions\n  void get_sessions_waiting_for_map(set<Session*> *out) {\n    Mutex::Locker l(session_waiting_lock);\n    out->swap(session_waiting_for_map);\n  }\n  void register_session_waiting_on_map(Session *session) {\n    Mutex::Locker l(session_waiting_lock);\n    if (session_waiting_for_map.insert(session).second) {\n      session->get();\n    }\n  }\n  void clear_session_waiting_on_map(Session *session) {\n    Mutex::Locker l(session_waiting_lock);\n    set<Session*>::iterator i = session_waiting_for_map.find(session);\n    if (i != session_waiting_for_map.end()) {\n      (*i)->put();\n      session_waiting_for_map.erase(i);\n    }\n  }\n  void dispatch_sessions_waiting_on_map() {\n    set<Session*> sessions_to_check;\n    get_sessions_waiting_for_map(&sessions_to_check);\n    for (set<Session*>::iterator i = sessions_to_check.begin();\n\t i != sessions_to_check.end();\n\t sessions_to_check.erase(i++)) {\n      (*i)->session_dispatch_lock.Lock();\n      dispatch_session_waiting(*i, osdmap);\n      (*i)->session_dispatch_lock.Unlock();\n      (*i)->put();\n    }\n  }\n  void session_handle_reset(Session *session) {\n    Mutex::Locker l(session->session_dispatch_lock);\n    clear_session_waiting_on_map(session);\n\n    session->clear_backoffs();\n\n    /* Messages have connection refs, we need to clear the\n     * connection->session->message->connection\n     * cycles which result.\n     * Bug #12338\n     */\n    session->waiting_on_map.clear_and_dispose(TrackedOp::Putter());\n  }\n\nprivate:\n  /**\n   * @defgroup monc helpers\n   * @{\n   * Right now we only have the one\n   */\n\n  /**\n   * Ask the Monitors for a sequence of OSDMaps.\n   *\n   * @param epoch The epoch to start with when replying\n   * @param force_request True if this request forces a new subscription to\n   * the monitors; false if an outstanding request that encompasses it is\n   * sufficient.\n   */\n  void osdmap_subscribe(version_t epoch, bool force_request);\n  /** @} monc helpers */\n\n  Mutex osdmap_subscribe_lock;\n  epoch_t latest_subscribed_epoch{0};\n\n  // -- heartbeat --\n  /// information about a heartbeat peer\n  struct HeartbeatInfo {\n    int peer;           ///< peer\n    ConnectionRef con_front;   ///< peer connection (front)\n    ConnectionRef con_back;    ///< peer connection (back)\n    utime_t first_tx;   ///< time we sent our first ping request\n    utime_t last_tx;    ///< last time we sent a ping request\n    utime_t last_rx_front;  ///< last time we got a ping reply on the front side\n    utime_t last_rx_back;   ///< last time we got a ping reply on the back side\n    epoch_t epoch;      ///< most recent epoch we wanted this peer\n\n    bool is_unhealthy(utime_t cutoff) const {\n      return\n\t! ((last_rx_front > cutoff ||\n\t    (last_rx_front == utime_t() && (last_tx == utime_t() ||\n\t\t\t\t\t    first_tx > cutoff))) &&\n\t   (last_rx_back > cutoff ||\n\t    (last_rx_back == utime_t() && (last_tx == utime_t() ||\n\t\t\t\t\t   first_tx > cutoff))));\n    }\n    bool is_healthy(utime_t cutoff) const {\n      return last_rx_front > cutoff && last_rx_back > cutoff;\n    }\n\n  };\n  /// state attached to outgoing heartbeat connections\n  struct HeartbeatSession : public RefCountedObject {\n    int peer;\n    explicit HeartbeatSession(int p) : peer(p) {}\n  };\n  Mutex heartbeat_lock;\n  map<int, int> debug_heartbeat_drops_remaining;\n  Cond heartbeat_cond;\n  bool heartbeat_stop;\n  std::atomic_bool heartbeat_need_update;   \n  map<int,HeartbeatInfo> heartbeat_peers;  ///< map of osd id to HeartbeatInfo\n  utime_t last_mon_heartbeat;\n  Messenger *hb_front_client_messenger;\n  Messenger *hb_back_client_messenger;\n  Messenger *hb_front_server_messenger;\n  Messenger *hb_back_server_messenger;\n  utime_t last_heartbeat_resample;   ///< last time we chose random peers in waiting-for-healthy state\n  double daily_loadavg;\n  \n  void _add_heartbeat_peer(int p);\n  void _remove_heartbeat_peer(int p);\n  bool heartbeat_reset(Connection *con);\n  void maybe_update_heartbeat_peers();\n  void reset_heartbeat_peers();\n  bool heartbeat_peers_need_update() {\n    return heartbeat_need_update.load();\n  }\n  void heartbeat_set_peers_need_update() {\n    heartbeat_need_update.store(true);\n  }\n  void heartbeat_clear_peers_need_update() {\n    heartbeat_need_update.store(false);\n  }\n  void heartbeat();\n  void heartbeat_check();\n  void heartbeat_entry();\n  void need_heartbeat_peer_update();\n\n  void heartbeat_kick() {\n    Mutex::Locker l(heartbeat_lock);\n    heartbeat_cond.Signal();\n  }\n\n  struct T_Heartbeat : public Thread {\n    OSD *osd;\n    explicit T_Heartbeat(OSD *o) : osd(o) {}\n    void *entry() override {\n      osd->heartbeat_entry();\n      return 0;\n    }\n  } heartbeat_thread;\n\npublic:\n  bool heartbeat_dispatch(Message *m);\n\n  struct HeartbeatDispatcher : public Dispatcher {\n    OSD *osd;\n    explicit HeartbeatDispatcher(OSD *o) : Dispatcher(o->cct), osd(o) {}\n\n    bool ms_can_fast_dispatch_any() const override { return true; }\n    bool ms_can_fast_dispatch(const Message *m) const override {\n      switch (m->get_type()) {\n\tcase CEPH_MSG_PING:\n\tcase MSG_OSD_PING:\n          return true;\n\tdefault:\n          return false;\n\t}\n    }\n    void ms_fast_dispatch(Message *m) override {\n      osd->heartbeat_dispatch(m);\n    }\n    bool ms_dispatch(Message *m) override {\n      return osd->heartbeat_dispatch(m);\n    }\n    bool ms_handle_reset(Connection *con) override {\n      return osd->heartbeat_reset(con);\n    }\n    void ms_handle_remote_reset(Connection *con) override {}\n    bool ms_handle_refused(Connection *con) override {\n      return osd->ms_handle_refused(con);\n    }\n    bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t      int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t      bool& isvalid, CryptoKey& session_key) override {\n      isvalid = true;\n      return true;\n    }\n  } heartbeat_dispatcher;\n\nprivate:\n  // -- waiters --\n  list<OpRequestRef> finished;\n  \n  void take_waiters(list<OpRequestRef>& ls) {\n    assert(osd_lock.is_locked());\n    finished.splice(finished.end(), ls);\n  }\n  void do_waiters();\n  \n  // -- op tracking --\n  OpTracker op_tracker;\n  void check_ops_in_flight();\n  void test_ops(std::string command, std::string args, ostream& ss);\n  friend class TestOpsSocketHook;\n  TestOpsSocketHook *test_ops_hook;\n  friend struct C_CompleteSplits;\n  friend struct C_OpenPGs;\n\n  // -- op queue --\n  enum class io_queue {\n    prioritized,\n    weightedpriority,\n    mclock_opclass,\n    mclock_client,\n  };\n  friend std::ostream& operator<<(std::ostream& out, const OSD::io_queue& q);\n\n  const io_queue op_queue;\n  const unsigned int op_prio_cutoff;\n\n  /*\n   * The ordered op delivery chain is:\n   *\n   *   fast dispatch -> pqueue back\n   *                    pqueue front <-> to_process back\n   *                                     to_process front  -> RunVis(item)\n   *                                                      <- queue_front()\n   *\n   * The pqueue is per-shard, and to_process is per pg_slot.  Items can be\n   * pushed back up into to_process and/or pqueue while order is preserved.\n   *\n   * Multiple worker threads can operate on each shard.\n   *\n   * Under normal circumstances, num_running == to_proces.size().  There are\n   * two times when that is not true: (1) when waiting_for_pg == true and\n   * to_process is accumulating requests that are waiting for the pg to be\n   * instantiated; in that case they will all get requeued together by\n   * wake_pg_waiters, and (2) when wake_pg_waiters just ran, waiting_for_pg\n   * and already requeued the items.\n   */\n  friend class PGQueueable;\n\n  class ShardedOpWQ\n    : public ShardedThreadPool::ShardedWQ<pair<spg_t,PGQueueable>>\n  {\n    struct ShardData {\n      Mutex sdata_lock;\n      Cond sdata_cond;\n\n      Mutex sdata_op_ordering_lock;   ///< protects all members below\n\n      OSDMapRef waiting_for_pg_osdmap;\n      struct pg_slot {\n\tPGRef pg;                     ///< cached pg reference [optional]\n\tlist<PGQueueable> to_process; ///< order items for this slot\n\tint num_running = 0;          ///< _process threads doing pg lookup/lock\n\n\t/// true if pg does/did not exist. if so all new items go directly to\n\t/// to_process.  cleared by prune_pg_waiters.\n\tbool waiting_for_pg = false;\n\n\t/// incremented by wake_pg_waiters; indicates racing _process threads\n\t/// should bail out (their op has been requeued)\n\tuint64_t requeue_seq = 0;\n      };\n\n      /// map of slots for each spg_t.  maintains ordering of items dequeued\n      /// from pqueue while _process thread drops shard lock to acquire the\n      /// pg lock.  slots are removed only by prune_pg_waiters.\n      unordered_map<spg_t,pg_slot> pg_slots;\n\n      /// priority queue\n      std::unique_ptr<OpQueue< pair<spg_t, PGQueueable>, entity_inst_t>> pqueue;\n\n      void _enqueue_front(pair<spg_t, PGQueueable> item, unsigned cutoff) {\n\tunsigned priority = item.second.get_priority();\n\tunsigned cost = item.second.get_cost();\n\tif (priority >= cutoff)\n\t  pqueue->enqueue_strict_front(\n\t    item.second.get_owner(),\n\t    priority, item);\n\telse\n\t  pqueue->enqueue_front(\n\t    item.second.get_owner(),\n\t    priority, cost, item);\n      }\n\n      ShardData(\n\tstring lock_name, string ordering_lock,\n\tuint64_t max_tok_per_prio, uint64_t min_cost, CephContext *cct,\n\tio_queue opqueue)\n\t: sdata_lock(lock_name.c_str(), false, true, false, cct),\n\t  sdata_op_ordering_lock(ordering_lock.c_str(), false, true,\n\t\t\t\t false, cct) {\n\tif (opqueue == io_queue::weightedpriority) {\n\t  pqueue = std::unique_ptr\n\t    <WeightedPriorityQueue<pair<spg_t,PGQueueable>,entity_inst_t>>(\n\t      new WeightedPriorityQueue<pair<spg_t,PGQueueable>,entity_inst_t>(\n\t\tmax_tok_per_prio, min_cost));\n\t} else if (opqueue == io_queue::prioritized) {\n\t  pqueue = std::unique_ptr\n\t    <PrioritizedQueue<pair<spg_t,PGQueueable>,entity_inst_t>>(\n\t      new PrioritizedQueue<pair<spg_t,PGQueueable>,entity_inst_t>(\n\t\tmax_tok_per_prio, min_cost));\n\t} else if (opqueue == io_queue::mclock_opclass) {\n\t  pqueue = std::unique_ptr\n\t    <ceph::mClockOpClassQueue>(new ceph::mClockOpClassQueue(cct));\n\t} else if (opqueue == io_queue::mclock_client) {\n\t  pqueue = std::unique_ptr\n\t    <ceph::mClockClientQueue>(new ceph::mClockClientQueue(cct));\n\t}\n      }\n    }; // struct ShardData\n\n    vector<ShardData*> shard_list;\n    OSD *osd;\n    uint32_t num_shards;\n\n  public:\n    ShardedOpWQ(uint32_t pnum_shards,\n\t\tOSD *o,\n\t\ttime_t ti,\n\t\ttime_t si,\n\t\tShardedThreadPool* tp)\n      : ShardedThreadPool::ShardedWQ<pair<spg_t,PGQueueable>>(ti, si, tp),\n        osd(o),\n        num_shards(pnum_shards) {\n      for (uint32_t i = 0; i < num_shards; i++) {\n\tchar lock_name[32] = {0};\n\tsnprintf(lock_name, sizeof(lock_name), \"%s.%d\", \"OSD:ShardedOpWQ:\", i);\n\tchar order_lock[32] = {0};\n\tsnprintf(order_lock, sizeof(order_lock), \"%s.%d\",\n\t\t \"OSD:ShardedOpWQ:order:\", i);\n\tShardData* one_shard = new ShardData(\n\t  lock_name, order_lock,\n\t  osd->cct->_conf->osd_op_pq_max_tokens_per_priority, \n\t  osd->cct->_conf->osd_op_pq_min_cost, osd->cct, osd->op_queue);\n\tshard_list.push_back(one_shard);\n      }\n    }\n    ~ShardedOpWQ() override {\n      while (!shard_list.empty()) {\n\tdelete shard_list.back();\n\tshard_list.pop_back();\n      }\n    }\n\n    /// wake any pg waiters after a PG is created/instantiated\n    void wake_pg_waiters(spg_t pgid);\n\n    /// prune ops (and possiblye pg_slots) for pgs that shouldn't be here\n    void prune_pg_waiters(OSDMapRef osdmap, int whoami);\n\n    /// clear cached PGRef on pg deletion\n    void clear_pg_pointer(spg_t pgid);\n\n    /// clear pg_slots on shutdown\n    void clear_pg_slots();\n\n    /// try to do some work\n    void _process(uint32_t thread_index, heartbeat_handle_d *hb) override;\n\n    /// enqueue a new item\n    void _enqueue(pair <spg_t, PGQueueable> item) override;\n\n    /// requeue an old item (at the front of the line)\n    void _enqueue_front(pair <spg_t, PGQueueable> item) override;\n      \n    void return_waiting_threads() override {\n      for(uint32_t i = 0; i < num_shards; i++) {\n\tShardData* sdata = shard_list[i];\n\tassert (NULL != sdata); \n\tsdata->sdata_lock.Lock();\n\tsdata->sdata_cond.Signal();\n\tsdata->sdata_lock.Unlock();\n      }\n    }\n\n    void dump(Formatter *f) {\n      for(uint32_t i = 0; i < num_shards; i++) {\n\tShardData* sdata = shard_list[i];\n\tchar lock_name[32] = {0};\n\tsnprintf(lock_name, sizeof(lock_name), \"%s%d\", \"OSD:ShardedOpWQ:\", i);\n\tassert (NULL != sdata);\n\tsdata->sdata_op_ordering_lock.Lock();\n\tf->open_object_section(lock_name);\n\tsdata->pqueue->dump(f);\n\tf->close_section();\n\tsdata->sdata_op_ordering_lock.Unlock();\n      }\n    }\n\n    /// Must be called on ops queued back to front\n    struct Pred {\n      spg_t pgid;\n      list<OpRequestRef> *out_ops;\n      uint64_t reserved_pushes_to_free;\n      Pred(spg_t pg, list<OpRequestRef> *out_ops = 0)\n\t: pgid(pg), out_ops(out_ops), reserved_pushes_to_free(0) {}\n      void accumulate(const PGQueueable &op) {\n\treserved_pushes_to_free += op.get_reserved_pushes();\n\tif (out_ops) {\n\t  boost::optional<OpRequestRef> mop = op.maybe_get_op();\n\t  if (mop)\n\t    out_ops->push_front(*mop);\n\t}\n      }\n      bool operator()(const pair<spg_t, PGQueueable> &op) {\n\tif (op.first == pgid) {\n\t  accumulate(op.second);\n\t  return true;\n\t} else {\n\t  return false;\n\t}\n      }\n      uint64_t get_reserved_pushes_to_free() const {\n\treturn reserved_pushes_to_free;\n      }\n    };\n\n    bool is_shard_empty(uint32_t thread_index) override {\n      uint32_t shard_index = thread_index % num_shards; \n      ShardData* sdata = shard_list[shard_index];\n      assert(NULL != sdata);\n      Mutex::Locker l(sdata->sdata_op_ordering_lock);\n      return sdata->pqueue->empty();\n    }\n  } op_shardedwq;\n\n\n  void enqueue_op(spg_t pg, OpRequestRef& op, epoch_t epoch);\n  void dequeue_op(\n    PGRef pg, OpRequestRef op,\n    ThreadPool::TPHandle &handle);\n\n  // -- peering queue --\n  struct PeeringWQ : public ThreadPool::BatchWorkQueue<PG> {\n    list<PG*> peering_queue;\n    OSD *osd;\n    set<PG*> in_use;\n    PeeringWQ(OSD *o, time_t ti, time_t si, ThreadPool *tp)\n      : ThreadPool::BatchWorkQueue<PG>(\n\t\"OSD::PeeringWQ\", ti, si, tp), osd(o) {}\n\n    void _dequeue(PG *pg) override {\n      for (list<PG*>::iterator i = peering_queue.begin();\n\t   i != peering_queue.end();\n\t   ) {\n\tif (*i == pg) {\n\t  peering_queue.erase(i++);\n\t  pg->put(\"PeeringWQ\");\n\t} else {\n\t  ++i;\n\t}\n      }\n    }\n    bool _enqueue(PG *pg) override {\n      pg->get(\"PeeringWQ\");\n      peering_queue.push_back(pg);\n      return true;\n    }\n    bool _empty() override {\n      return peering_queue.empty();\n    }\n    void _dequeue(list<PG*> *out) override;\n    void _process(\n      const list<PG *> &pgs,\n      ThreadPool::TPHandle &handle) override {\n      assert(!pgs.empty());\n      osd->process_peering_events(pgs, handle);\n      for (list<PG *>::const_iterator i = pgs.begin();\n\t   i != pgs.end();\n\t   ++i) {\n\t(*i)->put(\"PeeringWQ\");\n      }\n    }\n    void _process_finish(const list<PG *> &pgs) override {\n      for (list<PG*>::const_iterator i = pgs.begin();\n\t   i != pgs.end();\n\t   ++i) {\n\tin_use.erase(*i);\n      }\n    }\n    void _clear() override {\n      assert(peering_queue.empty());\n    }\n  } peering_wq;\n\n  void process_peering_events(\n    const list<PG*> &pg,\n    ThreadPool::TPHandle &handle);\n\n  friend class PG;\n  friend class PrimaryLogPG;\n\n\n protected:\n\n  // -- osd map --\n  OSDMapRef       osdmap;\n  OSDMapRef get_osdmap() {\n    return osdmap;\n  }\n  epoch_t get_osdmap_epoch() const {\n    return osdmap ? osdmap->get_epoch() : 0;\n  }\n\n  utime_t         had_map_since;\n  RWLock          map_lock;\n  list<OpRequestRef>  waiting_for_osdmap;\n  deque<utime_t> osd_markdown_log;\n\n  friend struct send_map_on_destruct;\n\n  void wait_for_new_map(OpRequestRef op);\n  void handle_osd_map(class MOSDMap *m);\n  void _committed_osd_maps(epoch_t first, epoch_t last, class MOSDMap *m);\n  void trim_maps(epoch_t oldest, int nreceived, bool skip_maps);\n  void note_down_osd(int osd);\n  void note_up_osd(int osd);\n  friend class C_OnMapCommit;\n\n  bool advance_pg(\n    epoch_t advance_to, PG *pg,\n    ThreadPool::TPHandle &handle,\n    PG::RecoveryCtx *rctx,\n    set<PGRef> *split_pgs\n  );\n  void consume_map();\n  void activate_map();\n\n  // osd map cache (past osd maps)\n  OSDMapRef get_map(epoch_t e) {\n    return service.get_map(e);\n  }\n  OSDMapRef add_map(OSDMap *o) {\n    return service.add_map(o);\n  }\n  void add_map_bl(epoch_t e, bufferlist& bl) {\n    return service.add_map_bl(e, bl);\n  }\n  void pin_map_bl(epoch_t e, bufferlist &bl) {\n    return service.pin_map_bl(e, bl);\n  }\n  bool get_map_bl(epoch_t e, bufferlist& bl) {\n    return service.get_map_bl(e, bl);\n  }\n  void add_map_inc_bl(epoch_t e, bufferlist& bl) {\n    return service.add_map_inc_bl(e, bl);\n  }\n  void pin_map_inc_bl(epoch_t e, bufferlist &bl) {\n    return service.pin_map_inc_bl(e, bl);\n  }\n\nprotected:\n  // -- placement groups --\n  RWLock pg_map_lock; // this lock orders *above* individual PG _locks\n  ceph::unordered_map<spg_t, PG*> pg_map; // protected by pg_map lock\n\n  std::mutex pending_creates_lock;\n  using create_from_osd_t = std::pair<pg_t, bool /* is primary*/>;\n  std::set<create_from_osd_t> pending_creates_from_osd;\n  unsigned pending_creates_from_mon = 0;\n\n  map<spg_t, list<PG::CephPeeringEvtRef> > peering_wait_for_split;\n  PGRecoveryStats pg_recovery_stats;\n\n  PGPool _get_pool(int id, OSDMapRef createmap);\n\n  PG   *_lookup_lock_pg_with_map_lock_held(spg_t pgid);\n  PG   *_lookup_lock_pg(spg_t pgid);\n\npublic:\n  PG   *lookup_lock_pg(spg_t pgid);\n\n  int get_num_pgs() {\n    RWLock::RLocker l(pg_map_lock);\n    return pg_map.size();\n  }\n\nprotected:\n  PG   *_open_lock_pg(OSDMapRef createmap,\n\t\t      spg_t pg, bool no_lockdep_check=false);\n  enum res_result {\n    RES_PARENT,    // resurrected a parent\n    RES_SELF,      // resurrected self\n    RES_NONE       // nothing relevant deleting\n  };\n  res_result _try_resurrect_pg(\n    OSDMapRef curmap, spg_t pgid, spg_t *resurrected, PGRef *old_pg_state);\n\n  PG   *_create_lock_pg(\n    OSDMapRef createmap,\n    spg_t pgid,\n    bool hold_map_lock,\n    bool backfill,\n    int role,\n    vector<int>& up, int up_primary,\n    vector<int>& acting, int acting_primary,\n    pg_history_t history,\n    const PastIntervals& pi,\n    ObjectStore::Transaction& t);\n\n  PG* _make_pg(OSDMapRef createmap, spg_t pgid);\n  void add_newly_split_pg(PG *pg,\n\t\t\t  PG::RecoveryCtx *rctx);\n\n  int handle_pg_peering_evt(\n    spg_t pgid,\n    const pg_history_t& orig_history,\n    const PastIntervals& pi,\n    epoch_t epoch,\n    PG::CephPeeringEvtRef evt);\n  bool maybe_wait_for_max_pg(spg_t pgid, bool is_mon_create);\n  void resume_creating_pg();\n\n  void load_pgs();\n  void build_past_intervals_parallel();\n\n  /// build initial pg history and intervals on create\n  void build_initial_pg_history(\n    spg_t pgid,\n    epoch_t created,\n    utime_t created_stamp,\n    pg_history_t *h,\n    PastIntervals *pi);\n\n  /// project pg history from from to now\n  bool project_pg_history(\n    spg_t pgid, pg_history_t& h, epoch_t from,\n    const vector<int>& lastup,\n    int lastupprimary,\n    const vector<int>& lastacting,\n    int lastactingprimary\n    ); ///< @return false if there was a map gap between from and now\n\n  // this must be called with pg->lock held on any pg addition to pg_map\n  void wake_pg_waiters(PGRef pg) {\n    assert(pg->is_locked());\n    op_shardedwq.wake_pg_waiters(pg->info.pgid);\n  }\n  epoch_t last_pg_create_epoch;\n\n  void handle_pg_create(OpRequestRef op);\n\n  void split_pgs(\n    PG *parent,\n    const set<spg_t> &childpgids, set<PGRef> *out_pgs,\n    OSDMapRef curmap,\n    OSDMapRef nextmap,\n    PG::RecoveryCtx *rctx);\n\n  // == monitor interaction ==\n  Mutex mon_report_lock;\n  utime_t last_mon_report;\n  utime_t last_pg_stats_sent;\n\n  /* if our monitor dies, we want to notice it and reconnect.\n   *  So we keep track of when it last acked our stat updates,\n   *  and if too much time passes (and we've been sending\n   *  more updates) then we can call it dead and reconnect\n   *  elsewhere.\n   */\n  utime_t last_pg_stats_ack;\n  float stats_ack_timeout;\n  set<uint64_t> outstanding_pg_stats; // how many stat updates haven't been acked yet\n\n  // -- boot --\n  void start_boot();\n  void _got_mon_epochs(epoch_t oldest, epoch_t newest);\n  void _preboot(epoch_t oldest, epoch_t newest);\n  void _send_boot();\n  void _collect_metadata(map<string,string> *pmeta);\n\n  void start_waiting_for_healthy();\n  bool _is_healthy();\n\n  void send_full_update();\n  \n  friend struct C_OSD_GetVersion;\n\n  // -- alive --\n  epoch_t up_thru_wanted;\n\n  void queue_want_up_thru(epoch_t want);\n  void send_alive();\n\n  // -- full map requests --\n  epoch_t requested_full_first, requested_full_last;\n\n  void request_full_map(epoch_t first, epoch_t last);\n  void rerequest_full_maps() {\n    epoch_t first = requested_full_first;\n    epoch_t last = requested_full_last;\n    requested_full_first = 0;\n    requested_full_last = 0;\n    request_full_map(first, last);\n  }\n  void got_full_map(epoch_t e);\n\n  // -- failures --\n  map<int,utime_t> failure_queue;\n  map<int,pair<utime_t,entity_inst_t> > failure_pending;\n\n  void requeue_failures();\n  void send_failures();\n  void send_still_alive(epoch_t epoch, const entity_inst_t &i);\n\n  // -- pg stats --\n  Mutex pg_stat_queue_lock;\n  Cond pg_stat_queue_cond;\n  xlist<PG*> pg_stat_queue;\n  bool osd_stat_updated;\n  uint64_t pg_stat_tid, pg_stat_tid_flushed;\n\n  void send_pg_stats(const utime_t &now);\n  void handle_pg_stats_ack(class MPGStatsAck *ack);\n  void flush_pg_stats();\n\n  ceph::coarse_mono_clock::time_point last_sent_beacon;\n  Mutex min_last_epoch_clean_lock{\"OSD::min_last_epoch_clean_lock\"};\n  epoch_t min_last_epoch_clean = 0;\n  // which pgs were scanned for min_lec\n  std::vector<pg_t> min_last_epoch_clean_pgs;\n  void send_beacon(const ceph::coarse_mono_clock::time_point& now);\n\n  void pg_stat_queue_enqueue(PG *pg) {\n    pg_stat_queue_lock.Lock();\n    if (pg->is_primary() && !pg->stat_queue_item.is_on_list()) {\n      pg->get(\"pg_stat_queue\");\n      pg_stat_queue.push_back(&pg->stat_queue_item);\n    }\n    osd_stat_updated = true;\n    pg_stat_queue_lock.Unlock();\n  }\n  void pg_stat_queue_dequeue(PG *pg) {\n    pg_stat_queue_lock.Lock();\n    if (pg->stat_queue_item.remove_myself())\n      pg->put(\"pg_stat_queue\");\n    pg_stat_queue_lock.Unlock();\n  }\n  void clear_pg_stat_queue() {\n    pg_stat_queue_lock.Lock();\n    while (!pg_stat_queue.empty()) {\n      PG *pg = pg_stat_queue.front();\n      pg_stat_queue.pop_front();\n      pg->put(\"pg_stat_queue\");\n    }\n    pg_stat_queue_lock.Unlock();\n  }\n  void clear_outstanding_pg_stats(){\n    Mutex::Locker l(pg_stat_queue_lock);\n    outstanding_pg_stats.clear();\n  }\n\n  ceph_tid_t get_tid() {\n    return service.get_tid();\n  }\n\n  // -- generic pg peering --\n  PG::RecoveryCtx create_context();\n  void dispatch_context(PG::RecoveryCtx &ctx, PG *pg, OSDMapRef curmap,\n                        ThreadPool::TPHandle *handle = NULL);\n  void dispatch_context_transaction(PG::RecoveryCtx &ctx, PG *pg,\n                                    ThreadPool::TPHandle *handle = NULL);\n  void do_notifies(map<int,\n\t\t       vector<pair<pg_notify_t, PastIntervals> > >&\n\t\t       notify_list,\n\t\t   OSDMapRef map);\n  void do_queries(map<int, map<spg_t,pg_query_t> >& query_map,\n\t\t  OSDMapRef map);\n  void do_infos(map<int,\n\t\t    vector<pair<pg_notify_t, PastIntervals> > >& info_map,\n\t\tOSDMapRef map);\n\n  bool require_mon_peer(const Message *m);\n  bool require_mon_or_mgr_peer(const Message *m);\n  bool require_osd_peer(const Message *m);\n  /***\n   * Verifies that we were alive in the given epoch, and that\n   * still are.\n   */\n  bool require_self_aliveness(const Message *m, epoch_t alive_since);\n  /**\n   * Verifies that the OSD who sent the given op has the same\n   * address as in the given map.\n   * @pre op was sent by an OSD using the cluster messenger\n   */\n  bool require_same_peer_instance(const Message *m, OSDMapRef& map,\n\t\t\t\t  bool is_fast_dispatch);\n\n  bool require_same_or_newer_map(OpRequestRef& op, epoch_t e,\n\t\t\t\t bool is_fast_dispatch);\n\n  void handle_pg_query(OpRequestRef op);\n  void handle_pg_notify(OpRequestRef op);\n  void handle_pg_log(OpRequestRef op);\n  void handle_pg_info(OpRequestRef op);\n  void handle_pg_trim(OpRequestRef op);\n\n  void handle_pg_backfill_reserve(OpRequestRef op);\n  void handle_pg_recovery_reserve(OpRequestRef op);\n\n  void handle_force_recovery(Message *m);\n\n  void handle_pg_remove(OpRequestRef op);\n  void _remove_pg(PG *pg);\n\n  // -- commands --\n  struct Command {\n    vector<string> cmd;\n    ceph_tid_t tid;\n    bufferlist indata;\n    ConnectionRef con;\n\n    Command(vector<string>& c, ceph_tid_t t, bufferlist& bl, Connection *co)\n      : cmd(c), tid(t), indata(bl), con(co) {}\n  };\n  list<Command*> command_queue;\n  struct CommandWQ : public ThreadPool::WorkQueue<Command> {\n    OSD *osd;\n    CommandWQ(OSD *o, time_t ti, time_t si, ThreadPool *tp)\n      : ThreadPool::WorkQueue<Command>(\"OSD::CommandWQ\", ti, si, tp), osd(o) {}\n\n    bool _empty() override {\n      return osd->command_queue.empty();\n    }\n    bool _enqueue(Command *c) override {\n      osd->command_queue.push_back(c);\n      return true;\n    }\n    void _dequeue(Command *pg) override {\n      ceph_abort();\n    }\n    Command *_dequeue() override {\n      if (osd->command_queue.empty())\n\treturn NULL;\n      Command *c = osd->command_queue.front();\n      osd->command_queue.pop_front();\n      return c;\n    }\n    void _process(Command *c, ThreadPool::TPHandle &) override {\n      osd->osd_lock.Lock();\n      if (osd->is_stopping()) {\n\tosd->osd_lock.Unlock();\n\tdelete c;\n\treturn;\n      }\n      osd->do_command(c->con.get(), c->tid, c->cmd, c->indata);\n      osd->osd_lock.Unlock();\n      delete c;\n    }\n    void _clear() override {\n      while (!osd->command_queue.empty()) {\n\tCommand *c = osd->command_queue.front();\n\tosd->command_queue.pop_front();\n\tdelete c;\n      }\n    }\n  } command_wq;\n\n  void handle_command(class MMonCommand *m);\n  void handle_command(class MCommand *m);\n  void do_command(Connection *con, ceph_tid_t tid, vector<string>& cmd, bufferlist& data);\n\n  // -- pg recovery --\n  void do_recovery(PG *pg, epoch_t epoch_queued, uint64_t pushes_reserved,\n\t\t   ThreadPool::TPHandle &handle);\n\n\n  // -- scrubbing --\n  void sched_scrub();\n  bool scrub_random_backoff();\n  bool scrub_load_below_threshold();\n  bool scrub_time_permit(utime_t now);\n\n  // -- removing --\n  struct RemoveWQ :\n    public ThreadPool::WorkQueueVal<pair<PGRef, DeletingStateRef> > {\n    CephContext* cct;\n    ObjectStore *&store;\n    list<pair<PGRef, DeletingStateRef> > remove_queue;\n    RemoveWQ(CephContext* cct, ObjectStore *&o, time_t ti, time_t si,\n\t     ThreadPool *tp)\n      : ThreadPool::WorkQueueVal<pair<PGRef, DeletingStateRef> >(\n\t\"OSD::RemoveWQ\", ti, si, tp), cct(cct), store(o) {}\n\n    bool _empty() override {\n      return remove_queue.empty();\n    }\n    void _enqueue(pair<PGRef, DeletingStateRef> item) override {\n      remove_queue.push_back(item);\n    }\n    void _enqueue_front(pair<PGRef, DeletingStateRef> item) override {\n      remove_queue.push_front(item);\n    }\n    bool _dequeue(pair<PGRef, DeletingStateRef> item) {\n      ceph_abort();\n    }\n    pair<PGRef, DeletingStateRef> _dequeue() override {\n      assert(!remove_queue.empty());\n      pair<PGRef, DeletingStateRef> item = remove_queue.front();\n      remove_queue.pop_front();\n      return item;\n    }\n    void _process(pair<PGRef, DeletingStateRef>,\n\t\t  ThreadPool::TPHandle &) override;\n    void _clear() override {\n      remove_queue.clear();\n    }\n    int get_remove_queue_len() {\n      lock();\n      int r = remove_queue.size();\n      unlock();\n      return r;\n    }\n  } remove_wq;\n\n  // -- status reporting --\n  MPGStats *collect_pg_stats();\n  std::vector<OSDHealthMetric> get_health_metrics();\n\nprivate:\n  bool ms_can_fast_dispatch_any() const override { return true; }\n  bool ms_can_fast_dispatch(const Message *m) const override {\n    switch (m->get_type()) {\n    case CEPH_MSG_OSD_OP:\n    case CEPH_MSG_OSD_BACKOFF:\n    case MSG_OSD_SUBOP:\n    case MSG_OSD_REPOP:\n    case MSG_OSD_SUBOPREPLY:\n    case MSG_OSD_REPOPREPLY:\n    case MSG_OSD_PG_PUSH:\n    case MSG_OSD_PG_PULL:\n    case MSG_OSD_PG_PUSH_REPLY:\n    case MSG_OSD_PG_SCAN:\n    case MSG_OSD_PG_BACKFILL:\n    case MSG_OSD_PG_BACKFILL_REMOVE:\n    case MSG_OSD_EC_WRITE:\n    case MSG_OSD_EC_WRITE_REPLY:\n    case MSG_OSD_EC_READ:\n    case MSG_OSD_EC_READ_REPLY:\n    case MSG_OSD_SCRUB_RESERVE:\n    case MSG_OSD_REP_SCRUB:\n    case MSG_OSD_REP_SCRUBMAP:\n    case MSG_OSD_PG_UPDATE_LOG_MISSING:\n    case MSG_OSD_PG_UPDATE_LOG_MISSING_REPLY:\n    case MSG_OSD_PG_RECOVERY_DELETE:\n    case MSG_OSD_PG_RECOVERY_DELETE_REPLY:\n      return true;\n    default:\n      return false;\n    }\n  }\n  void ms_fast_dispatch(Message *m) override;\n  void ms_fast_preprocess(Message *m) override;\n  bool ms_dispatch(Message *m) override;\n  bool ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new) override;\n  bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t    int protocol, bufferlist& authorizer, bufferlist& authorizer_reply,\n\t\t\t    bool& isvalid, CryptoKey& session_key) override;\n  void ms_handle_connect(Connection *con) override;\n  void ms_handle_fast_connect(Connection *con) override;\n  void ms_handle_fast_accept(Connection *con) override;\n  bool ms_handle_reset(Connection *con) override;\n  void ms_handle_remote_reset(Connection *con) override {}\n  bool ms_handle_refused(Connection *con) override;\n\n  io_queue get_io_queue() const {\n    if (cct->_conf->osd_op_queue == \"debug_random\") {\n      static io_queue index_lookup[] = { io_queue::prioritized,\n\t\t\t\t\t io_queue::weightedpriority,\n\t\t\t\t\t io_queue::mclock_opclass,\n\t\t\t\t\t io_queue::mclock_client };\n      srand(time(NULL));\n      unsigned which = rand() % (sizeof(index_lookup) / sizeof(index_lookup[0]));\n      return index_lookup[which];\n    } else if (cct->_conf->osd_op_queue == \"prioritized\") {\n      return io_queue::prioritized;\n    } else if (cct->_conf->osd_op_queue == \"mclock_opclass\") {\n      return io_queue::mclock_opclass;\n    } else if (cct->_conf->osd_op_queue == \"mclock_client\") {\n      return io_queue::mclock_client;\n    } else {\n      // default / catch-all is 'wpq'\n      return io_queue::weightedpriority;\n    }\n  }\n\n  unsigned int get_io_prio_cut() const {\n    if (cct->_conf->osd_op_queue_cut_off == \"debug_random\") {\n      srand(time(NULL));\n      return (rand() % 2 < 1) ? CEPH_MSG_PRIO_HIGH : CEPH_MSG_PRIO_LOW;\n    } else if (cct->_conf->osd_op_queue_cut_off == \"high\") {\n      return CEPH_MSG_PRIO_HIGH;\n    } else {\n      // default / catch-all is 'low'\n      return CEPH_MSG_PRIO_LOW;\n    }\n  }\n\n public:\n  /* internal and external can point to the same messenger, they will still\n   * be cleaned up properly*/\n  OSD(CephContext *cct_,\n      ObjectStore *store_,\n      int id,\n      Messenger *internal,\n      Messenger *external,\n      Messenger *hb_front_client,\n      Messenger *hb_back_client,\n      Messenger *hb_front_server,\n      Messenger *hb_back_server,\n      Messenger *osdc_messenger,\n      MonClient *mc, const std::string &dev, const std::string &jdev);\n  ~OSD() override;\n\n  // static bits\n  static int mkfs(CephContext *cct, ObjectStore *store,\n\t\t  const string& dev,\n\t\t  uuid_d fsid, int whoami);\n  /* remove any non-user xattrs from a map of them */\n  void filter_xattrs(map<string, bufferptr>& attrs) {\n    for (map<string, bufferptr>::iterator iter = attrs.begin();\n\t iter != attrs.end();\n\t ) {\n      if (('_' != iter->first.at(0)) || (iter->first.size() == 1))\n\tattrs.erase(iter++);\n      else ++iter;\n    }\n  }\n\nprivate:\n  int mon_cmd_maybe_osd_create(string &cmd);\n  int update_crush_device_class();\n  int update_crush_location();\n\n  static int write_meta(CephContext *cct,\n\t\t\tObjectStore *store,\n\t\t\tuuid_d& cluster_fsid, uuid_d& osd_fsid, int whoami);\n\n  void handle_pg_scrub(struct MOSDScrub *m, PG* pg);\n  void handle_scrub(struct MOSDScrub *m);\n  void handle_osd_ping(class MOSDPing *m);\n\n  int init_op_flags(OpRequestRef& op);\n\n  int get_num_op_shards();\n  int get_num_op_threads();\n\n  float get_osd_recovery_sleep();\n\npublic:\n  static int peek_meta(ObjectStore *store, string& magic,\n\t\t       uuid_d& cluster_fsid, uuid_d& osd_fsid, int& whoami);\n  \n\n  // startup/shutdown\n  int pre_init();\n  int init();\n  void final_init();\n\n  int enable_disable_fuse(bool stop);\n\n  void suicide(int exitcode);\n  int shutdown();\n\n  void handle_signal(int signum);\n\n  /// check if we can throw out op from a disconnected client\n  static bool op_is_discardable(const MOSDOp *m);\n\npublic:\n  OSDService service;\n  friend class OSDService;\n};\n\n\nstd::ostream& operator<<(std::ostream& out, const OSD::io_queue& q);\n\n\n//compatibility of the executable\nextern const CompatSet::Feature ceph_osd_feature_compat[];\nextern const CompatSet::Feature ceph_osd_feature_ro_compat[];\nextern const CompatSet::Feature ceph_osd_feature_incompat[];\n\n#endif // CEPH_OSD_H\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2013 CohortFS, LLC\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#ifndef SIMPLEDISPATCHER_H_\n#define SIMPLEDISPATCHER_H_\n\n#include \"msg/Dispatcher.h\"\n#include \"msg/Messenger.h\"\n\nclass SimpleDispatcher: public Dispatcher {\nprivate:\n  bool active;\n  Messenger *messenger;\n  uint64_t dcount;\npublic:\n  explicit SimpleDispatcher(Messenger *msgr);\n  ~SimpleDispatcher() override;\n\n  uint64_t get_dcount() { return dcount; }\n\n  void set_active() {\n    active = true;\n  };\n\n  // how i receive messages\n  bool ms_dispatch(Message *m) override;\n\n  /**\n   * This function will be called whenever a new Connection is made to the\n   * Messenger.\n   *\n   * @param con The new Connection which has been established. You are not\n   * granted a reference to it -- take one if you need one!\n   */\n  void ms_handle_connect(Connection *con) override { };\n\n  /**\n   * Callback indicating we have accepted an incoming connection.\n   *\n   * @param con The (new or existing) Connection associated with the session\n   */\n  void ms_handle_accept(Connection *con) override { };\n\n  /*\n   * this indicates that the ordered+reliable delivery semantics have\n   * been violated.  Messages may have been lost due to a fault\n   * in the network connection.\n   * Only called on lossy Connections or those you've\n   * designated mark_down_on_empty().\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  bool ms_handle_reset(Connection *con) override;\n\n  /**\n   * This indicates that the ordered+reliable delivery semantics\n   * have been violated because the remote somehow reset.\n   * It implies that incoming messages were dropped, and\n   * probably some of our previous outgoing messages were too.\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  void ms_handle_remote_reset(Connection *con) override;\n  \n  bool ms_handle_refused(Connection *con) override { return false; }\n\n  /**\n   * @defgroup Authentication\n   * @{\n   */\n  /**\n   * Retrieve the AuthAuthorizer for the given peer type. It might not\n   * provide one if it knows there is no AuthAuthorizer for that type.\n   *\n   * @param dest_type The peer type we want the authorizer for.\n   * @param a Double pointer to an AuthAuthorizer. The Dispatcher will fill\n   * in *a with the correct AuthAuthorizer, if it can. Make sure that you have\n   * set *a to NULL before calling in.\n   * @param force_new Force the Dispatcher to wait for a new set of keys before\n   * returning the authorizer.\n   *\n   * @return True if this function call properly filled in *a, false otherwise.\n   */\n  bool ms_get_authorizer(int dest_type, AuthAuthorizer **a,\n\t\t\t\t bool force_new) override { return false; };\n\n  /**\n   * Verify the authorizer for a new incoming Connection.\n   *\n   * @param con The new incoming Connection\n   * @param peer_type The type of the endpoint which initiated this Connection\n   * @param protocol The ID of the protocol in use (at time of writing, cephx\n   *  or none)\n   * @param authorizer The authorization string supplied by the remote\n   * @param authorizer_reply Output param: The string we should send back to\n   * the remote to authorize ourselves. Only filled in if isvalid\n   * @param isvalid Output param: True if authorizer is valid, false otherwise\n   *\n   * @return True if we were able to prove or disprove correctness of\n   * authorizer, false otherwise.\n   */\n  bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t\t    int protocol, bufferlist& authorizer,\n\t\t\t\t    bufferlist& authorizer_reply,\n\t\t\t\t    bool& isvalid, CryptoKey& session_key) override {\n    /* always succeed */\n    isvalid = true;\n    return true;\n  };\n\n};\n\n#endif /* SIMPLEDISPATCHER_H_ */\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2013 CohortFS, LLC\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#ifndef XIODISPATCHER_H_\n#define XIODISPATCHER_H_\n\n#include \"msg/Dispatcher.h\"\n#include \"msg/Messenger.h\"\n\nclass XioDispatcher: public Dispatcher {\nprivate:\n  bool active;\n  Messenger *messenger;\n  uint64_t dcount;\npublic:\n  explicit XioDispatcher(Messenger *msgr);\n  virtual ~XioDispatcher();\n\n  uint64_t get_dcount() { return dcount; }\n\n  void set_active() {\n    active = true;\n  };\n\n  // how i receive messages\n  virtual bool ms_dispatch(Message *m);\n\n  /**\n   * This function will be called whenever a new Connection is made to the\n   * Messenger.\n   *\n   * @param con The new Connection which has been established. You are not\n   * granted a reference to it -- take one if you need one!\n   */\n  virtual void ms_handle_connect(Connection *con) { };\n\n  /**\n   * Callback indicating we have accepted an incoming connection.\n   *\n   * @param con The (new or existing) Connection associated with the session\n   */\n  virtual void ms_handle_accept(Connection *con) { };\n\n  /*\n   * this indicates that the ordered+reliable delivery semantics have\n   * been violated.  Messages may have been lost due to a fault\n   * in the network connection.\n   * Only called on lossy Connections or those you've\n   * designated mark_down_on_empty().\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  virtual bool ms_handle_reset(Connection *con);\n\n  /**\n   * This indicates that the ordered+reliable delivery semantics\n   * have been violated because the remote somehow reset.\n   * It implies that incoming messages were dropped, and\n   * probably some of our previous outgoing messages were too.\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  virtual void ms_handle_remote_reset(Connection *con);\n  \n  virtual bool ms_handle_refused(Connection *con) { return false; }\n\n  /**\n   * @defgroup test_xio_dispatcher_h_auth Authentication\n   * @{\n   */\n  /**\n   * Retrieve the AuthAuthorizer for the given peer type. It might not\n   * provide one if it knows there is no AuthAuthorizer for that type.\n   *\n   * @param dest_type The peer type we want the authorizer for.\n   * @param a Double pointer to an AuthAuthorizer. The Dispatcher will fill\n   * in *a with the correct AuthAuthorizer, if it can. Make sure that you have\n   * set *a to NULL before calling in.\n   * @param force_new Force the Dispatcher to wait for a new set of keys before\n   * returning the authorizer.\n   *\n   * @return True if this function call properly filled in *a, false otherwise.\n   */\n  virtual bool ms_get_authorizer(int dest_type, AuthAuthorizer **a,\n\t\t\t\t bool force_new) { return false; };\n\n  /**\n   * Verify the authorizer for a new incoming Connection.\n   *\n   * @param con The new incoming Connection\n   * @param peer_type The type of the endpoint which initiated this Connection\n   * @param protocol The ID of the protocol in use (at time of writing, cephx\n   *  or none)\n   * @param authorizer The authorization string supplied by the remote\n   * @param authorizer_reply Output param: The string we should send back to\n   * the remote to authorize ourselves. Only filled in if isvalid\n   * @param isvalid Output param: True if authorizer is valid, false otherwise\n   *\n   * @return True if we were able to prove or disprove correctness of\n   * authorizer, false otherwise.\n   */\n  virtual bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t\t    int protocol, bufferlist& authorizer,\n\t\t\t\t    bufferlist& authorizer_reply,\n\t\t\t\t    bool& isvalid, CryptoKey& session_key) {\n    /* always succeed */\n    isvalid = true;\n    return true;\n  };\n\n};\n\n#endif /* XIODISPATCHER_H_ */\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2015 Haomai Wang\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include <stdlib.h>\n#include <stdint.h>\n#include <string>\n#include <unistd.h>\n#include <iostream>\n\nusing namespace std;\n\n#include \"common/ceph_argparse.h\"\n#include \"common/debug.h\"\n#include \"common/Cycles.h\"\n#include \"global/global_init.h\"\n#include \"msg/Messenger.h\"\n#include \"messages/MOSDOp.h\"\n\n#include <atomic>\n\nclass MessengerClient {\n  class ClientThread;\n  class ClientDispatcher : public Dispatcher {\n    uint64_t think_time;\n    ClientThread *thread;\n\n   public:\n    ClientDispatcher(uint64_t delay, ClientThread *t): Dispatcher(g_ceph_context), think_time(delay), thread(t) {}\n    bool ms_can_fast_dispatch_any() const override { return true; }\n    bool ms_can_fast_dispatch(const Message *m) const override {\n      switch (m->get_type()) {\n      case CEPH_MSG_OSD_OPREPLY:\n        return true;\n      default:\n        return false;\n      }\n    }\n\n    void ms_handle_fast_connect(Connection *con) override {}\n    void ms_handle_fast_accept(Connection *con) override {}\n    bool ms_dispatch(Message *m) override { return true; }\n    void ms_fast_dispatch(Message *m) override;\n    bool ms_handle_reset(Connection *con) override { return true; }\n    void ms_handle_remote_reset(Connection *con) override {}\n    bool ms_handle_refused(Connection *con) override { return false; }\n    bool ms_verify_authorizer(Connection *con, int peer_type, int protocol,\n                              bufferlist& authorizer, bufferlist& authorizer_reply,\n                              bool& isvalid, CryptoKey& session_key) override {\n      isvalid = true;\n      return true;\n    }\n  };\n\n  class ClientThread : public Thread {\n    Messenger *msgr;\n    int concurrent;\n    ConnectionRef conn;\n    std::atomic<unsigned> client_inc = { 0 };\n    object_t oid;\n    object_locator_t oloc;\n    pg_t pgid;\n    int msg_len;\n    bufferlist data;\n    int ops;\n    ClientDispatcher dispatcher;\n\n   public:\n    Mutex lock;\n    Cond cond;\n    uint64_t inflight;\n\n    ClientThread(Messenger *m, int c, ConnectionRef con, int len, int ops, int think_time_us):\n        msgr(m), concurrent(c), conn(con), oid(\"object-name\"), oloc(1, 1), msg_len(len), ops(ops),\n        dispatcher(think_time_us, this), lock(\"MessengerBenchmark::ClientThread::lock\"), inflight(0) {\n      m->add_dispatcher_head(&dispatcher);\n      bufferptr ptr(msg_len);\n      memset(ptr.c_str(), 0, msg_len);\n      data.append(ptr);\n    }\n    void *entry() override {\n      lock.Lock();\n      for (int i = 0; i < ops; ++i) {\n        if (inflight > uint64_t(concurrent)) {\n          cond.Wait(lock);\n        }\n\thobject_t hobj(oid, oloc.key, CEPH_NOSNAP, pgid.ps(), pgid.pool(),\n\t\t       oloc.nspace);\n\tspg_t spgid(pgid);\n        MOSDOp *m = new MOSDOp(client_inc, 0, hobj, spgid, 0, 0, 0);\n        m->write(0, msg_len, data);\n        inflight++;\n        conn->send_message(m);\n        //cerr << __func__ << \" send m=\" << m << std::endl;\n      }\n      lock.Unlock();\n      msgr->shutdown();\n      return 0;\n    }\n  };\n\n  string type;\n  string serveraddr;\n  int think_time_us;\n  vector<Messenger*> msgrs;\n  vector<ClientThread*> clients;\n\n public:\n  MessengerClient(string t, string addr, int delay):\n      type(t), serveraddr(addr), think_time_us(delay) {\n  }\n  ~MessengerClient() {\n    for (uint64_t i = 0; i < clients.size(); ++i)\n      delete clients[i];\n    for (uint64_t i = 0; i < msgrs.size(); ++i) {\n      msgrs[i]->shutdown();\n      msgrs[i]->wait();\n    }\n  }\n  void ready(int c, int jobs, int ops, int msg_len) {\n    entity_addr_t addr;\n    addr.parse(serveraddr.c_str());\n    addr.set_nonce(0);\n    for (int i = 0; i < jobs; ++i) {\n      Messenger *msgr = Messenger::create(g_ceph_context, type, entity_name_t::CLIENT(0), \"client\", getpid()+i, 0);\n      msgr->set_default_policy(Messenger::Policy::lossless_client(0));\n      entity_inst_t inst(entity_name_t::OSD(0), addr);\n      ConnectionRef conn = msgr->get_connection(inst);\n      ClientThread *t = new ClientThread(msgr, c, conn, msg_len, ops, think_time_us);\n      msgrs.push_back(msgr);\n      clients.push_back(t);\n      msgr->start();\n    }\n    usleep(1000*1000);\n  }\n  void start() {\n    for (uint64_t i = 0; i < clients.size(); ++i)\n      clients[i]->create(\"client\");\n    for (uint64_t i = 0; i < msgrs.size(); ++i)\n      msgrs[i]->wait();\n  }\n};\n\nvoid MessengerClient::ClientDispatcher::ms_fast_dispatch(Message *m) {\n  usleep(think_time);\n  m->put();\n  Mutex::Locker l(thread->lock);\n  thread->inflight--;\n  thread->cond.Signal();\n}\n\n\nvoid usage(const string &name) {\n  cerr << \"Usage: \" << name << \" [server ip:port] [numjobs] [concurrency] [ios] [thinktime us] [msg length]\" << std::endl;\n  cerr << \"       [server ip:port]: connect to the ip:port pair\" << std::endl;\n  cerr << \"       [numjobs]: how much client threads spawned and do benchmark\" << std::endl;\n  cerr << \"       [concurrency]: the max inflight messages(like iodepth in fio)\" << std::endl;\n  cerr << \"       [ios]: how much messages sent for each client\" << std::endl;\n  cerr << \"       [thinktime]: sleep time when do fast dispatching(match client logic)\" << std::endl;\n  cerr << \"       [msg length]: message data bytes\" << std::endl;\n}\n\nint main(int argc, char **argv)\n{\n  vector<const char*> args;\n  argv_to_vec(argc, (const char **)argv, args);\n\n  auto cct = global_init(NULL, args, CEPH_ENTITY_TYPE_CLIENT,\n\t\t\t CODE_ENVIRONMENT_UTILITY, 0);\n  common_init_finish(g_ceph_context);\n  g_ceph_context->_conf->apply_changes(NULL);\n\n  if (args.size() < 6) {\n    usage(argv[0]);\n    return 1;\n  }\n\n  int numjobs = atoi(args[1]);\n  int concurrent = atoi(args[2]);\n  int ios = atoi(args[3]);\n  int think_time = atoi(args[4]);\n  int len = atoi(args[5]);\n\n  std::string public_msgr_type = g_ceph_context->_conf->ms_public_type.empty() ? g_ceph_context->_conf->get_val<std::string>(\"ms_type\") : g_ceph_context->_conf->ms_public_type;\n\n  cerr << \" using ms-public-type \" << public_msgr_type << std::endl;\n  cerr << \"       server ip:port \" << args[0] << std::endl;\n  cerr << \"       numjobs \" << numjobs << std::endl;\n  cerr << \"       concurrency \" << concurrent << std::endl;\n  cerr << \"       ios \" << ios << std::endl;\n  cerr << \"       thinktime(us) \" << think_time << std::endl;\n  cerr << \"       message data bytes \" << len << std::endl;\n\n  MessengerClient client(public_msgr_type, args[0], think_time);\n\n  client.ready(concurrent, numjobs, ios, len);\n  Cycles::init();\n  uint64_t start = Cycles::rdtsc();\n  client.start();\n  uint64_t stop = Cycles::rdtsc();\n  cerr << \" Total op \" << ios << \" run time \" << Cycles::to_microseconds(stop - start) << \"us.\" << std::endl;\n\n  return 0;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2015 Haomai Wang\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include <stdlib.h>\n#include <stdint.h>\n#include <string>\n#include <unistd.h>\n#include <iostream>\n\nusing namespace std;\n\n#include \"common/ceph_argparse.h\"\n#include \"common/debug.h\"\n#include \"global/global_init.h\"\n#include \"msg/Messenger.h\"\n#include \"messages/MOSDOp.h\"\n#include \"messages/MOSDOpReply.h\"\n\nclass ServerDispatcher : public Dispatcher {\n  uint64_t think_time;\n  ThreadPool op_tp;\n  class OpWQ : public ThreadPool::WorkQueue<Message> {\n    list<Message*> messages;\n\n   public:\n    OpWQ(time_t timeout, time_t suicide_timeout, ThreadPool *tp)\n      : ThreadPool::WorkQueue<Message>(\"ServerDispatcher::OpWQ\", timeout, suicide_timeout, tp) {}\n\n    bool _enqueue(Message *m) override {\n      messages.push_back(m);\n      return true;\n    }\n    void _dequeue(Message *m) override {\n      ceph_abort();\n    }\n    bool _empty() override {\n      return messages.empty();\n    }\n    Message *_dequeue() override {\n      if (messages.empty())\n\treturn NULL;\n      Message *m = messages.front();\n      messages.pop_front();\n      return m;\n    }\n    void _process(Message *m, ThreadPool::TPHandle &handle) override {\n      MOSDOp *osd_op = static_cast<MOSDOp*>(m);\n      MOSDOpReply *reply = new MOSDOpReply(osd_op, 0, 0, 0, false);\n      m->get_connection()->send_message(reply);\n      m->put();\n    }\n    void _process_finish(Message *m) override { }\n    void _clear() override {\n      assert(messages.empty());\n    }\n  } op_wq;\n\n public:\n  ServerDispatcher(int threads, uint64_t delay): Dispatcher(g_ceph_context), think_time(delay),\n    op_tp(g_ceph_context, \"ServerDispatcher::op_tp\", \"tp_serv_disp\", threads, \"serverdispatcher_op_threads\"),\n    op_wq(30, 30, &op_tp) {\n    op_tp.start();\n  }\n  ~ServerDispatcher() override {\n    op_tp.stop();\n  }\n  bool ms_can_fast_dispatch_any() const override { return true; }\n  bool ms_can_fast_dispatch(const Message *m) const override {\n    switch (m->get_type()) {\n    case CEPH_MSG_OSD_OP:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  void ms_handle_fast_connect(Connection *con) override {}\n  void ms_handle_fast_accept(Connection *con) override {}\n  bool ms_dispatch(Message *m) override { return true; }\n  bool ms_handle_reset(Connection *con) override { return true; }\n  void ms_handle_remote_reset(Connection *con) override {}\n  bool ms_handle_refused(Connection *con) override { return false; }\n  void ms_fast_dispatch(Message *m) override {\n    usleep(think_time);\n    //cerr << __func__ << \" reply message=\" << m << std::endl;\n    op_wq.queue(m);\n  }\n  bool ms_verify_authorizer(Connection *con, int peer_type, int protocol,\n                            bufferlist& authorizer, bufferlist& authorizer_reply,\n                            bool& isvalid, CryptoKey& session_key) override {\n    isvalid = true;\n    return true;\n  }\n};\n\nclass MessengerServer {\n  Messenger *msgr;\n  string type;\n  string bindaddr;\n  ServerDispatcher dispatcher;\n\n public:\n  MessengerServer(string t, string addr, int threads, int delay):\n      msgr(NULL), type(t), bindaddr(addr), dispatcher(threads, delay) {\n    msgr = Messenger::create(g_ceph_context, type, entity_name_t::OSD(0), \"server\", 0, 0);\n    msgr->set_default_policy(Messenger::Policy::stateless_server(0));\n  }\n  ~MessengerServer() {\n    msgr->shutdown();\n    msgr->wait();\n  }\n  void start() {\n    entity_addr_t addr;\n    addr.parse(bindaddr.c_str());\n    msgr->bind(addr);\n    msgr->add_dispatcher_head(&dispatcher);\n    msgr->start();\n    msgr->wait();\n  }\n};\n\nvoid usage(const string &name) {\n  cerr << \"Usage: \" << name << \" [bind ip:port] [server worker threads] [thinktime us]\" << std::endl;\n  cerr << \"       [bind ip:port]: The ip:port pair to bind, client need to specify this pair to connect\" << std::endl;\n  cerr << \"       [server worker threads]: threads will process incoming messages and reply(matching pg threads)\" << std::endl;\n  cerr << \"       [thinktime]: sleep time when do dispatching(match fast dispatch logic in OSD.cc)\" << std::endl;\n}\n\nint main(int argc, char **argv)\n{\n  vector<const char*> args;\n  argv_to_vec(argc, (const char **)argv, args);\n\n  auto cct = global_init(NULL, args, CEPH_ENTITY_TYPE_CLIENT,\n\t\t\t CODE_ENVIRONMENT_UTILITY, 0);\n  common_init_finish(g_ceph_context);\n  g_ceph_context->_conf->apply_changes(NULL);\n\n  if (args.size() < 3) {\n    usage(argv[0]);\n    return 1;\n  }\n\n  int worker_threads = atoi(args[1]);\n  int think_time = atoi(args[2]);\n  std::string public_msgr_type = g_ceph_context->_conf->ms_public_type.empty() ? g_ceph_context->_conf->get_val<std::string>(\"ms_type\") : g_ceph_context->_conf->ms_public_type;\n\n  cerr << \" This tool won't handle connection error alike things, \" << std::endl;\n  cerr << \"please ensure the proper network environment to test.\" << std::endl;\n  cerr << \" Or ctrl+c when meeting error and restart tests\" << std::endl;\n  cerr << \" using ms-public-type \" << public_msgr_type << std::endl;\n  cerr << \"       bind ip:port \" << args[0] << std::endl;\n  cerr << \"       worker threads \" << worker_threads << std::endl;\n  cerr << \"       thinktime(us) \" << think_time << std::endl;\n\n  MessengerServer server(public_msgr_type, args[0], worker_threads, think_time);\n  server.start();\n\n  return 0;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2014 UnitedStack <haomai@unitedstack.com>\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include <atomic>\n#include <iostream>\n#include <unistd.h>\n#include <stdlib.h>\n#include <time.h>\n#include \"common/Mutex.h\"\n#include \"common/Cond.h\"\n#include \"common/ceph_argparse.h\"\n#include \"global/global_init.h\"\n#include \"msg/Dispatcher.h\"\n#include \"msg/msg_types.h\"\n#include \"msg/Message.h\"\n#include \"msg/Messenger.h\"\n#include \"msg/Connection.h\"\n#include \"messages/MPing.h\"\n#include \"messages/MCommand.h\"\n\n#include <boost/random/mersenne_twister.hpp>\n#include <boost/random/uniform_int.hpp>\n#include <boost/random/binomial_distribution.hpp>\n#include <gtest/gtest.h>\n\ntypedef boost::mt11213b gen_type;\n\n#include \"common/dout.h\"\n#include \"include/assert.h\"\n\n#define dout_subsys ceph_subsys_ms\n#undef dout_prefix\n#define dout_prefix *_dout << \" ceph_test_msgr \"\n\n\n#if GTEST_HAS_PARAM_TEST\n\n#define CHECK_AND_WAIT_TRUE(expr) do {  \\\n  int n = 1000;                         \\\n  while (--n) {                         \\\n    if (expr)                           \\\n      break;                            \\\n    usleep(1000);                       \\\n  }                                     \\\n} while(0);\n\nclass MessengerTest : public ::testing::TestWithParam<const char*> {\n public:\n  Messenger *server_msgr;\n  Messenger *client_msgr;\n\n  MessengerTest(): server_msgr(NULL), client_msgr(NULL) {}\n  void SetUp() override {\n    lderr(g_ceph_context) << __func__ << \" start set up \" << GetParam() << dendl;\n    server_msgr = Messenger::create(g_ceph_context, string(GetParam()), entity_name_t::OSD(0), \"server\", getpid(), 0);\n    client_msgr = Messenger::create(g_ceph_context, string(GetParam()), entity_name_t::CLIENT(-1), \"client\", getpid(), 0);\n    server_msgr->set_default_policy(Messenger::Policy::stateless_server(0));\n    client_msgr->set_default_policy(Messenger::Policy::lossy_client(0));\n  }\n  void TearDown() override {\n    ASSERT_EQ(server_msgr->get_dispatch_queue_len(), 0);\n    ASSERT_EQ(client_msgr->get_dispatch_queue_len(), 0);\n    delete server_msgr;\n    delete client_msgr;\n  }\n\n};\n\n\nclass FakeDispatcher : public Dispatcher {\n public:\n  struct Session : public RefCountedObject {\n    atomic<uint64_t> count;\n    ConnectionRef con;\n\n    explicit Session(ConnectionRef c): RefCountedObject(g_ceph_context), count(0), con(c) {\n    }\n    uint64_t get_count() { return count; }\n  };\n\n  Mutex lock;\n  Cond cond;\n  bool is_server;\n  bool got_new;\n  bool got_remote_reset;\n  bool got_connect;\n  bool loopback;\n\n  explicit FakeDispatcher(bool s): Dispatcher(g_ceph_context), lock(\"FakeDispatcher::lock\"),\n                          is_server(s), got_new(false), got_remote_reset(false),\n                          got_connect(false), loopback(false) {}\n  bool ms_can_fast_dispatch_any() const override { return true; }\n  bool ms_can_fast_dispatch(const Message *m) const override {\n    switch (m->get_type()) {\n    case CEPH_MSG_PING:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  void ms_handle_fast_connect(Connection *con) override {\n    lock.Lock();\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (!s) {\n      s = new Session(con);\n      con->set_priv(s->get());\n      lderr(g_ceph_context) << __func__ << \" con: \" << con << \" count: \" << s->count << dendl;\n    }\n    s->put();\n    got_connect = true;\n    cond.Signal();\n    lock.Unlock();\n  }\n  void ms_handle_fast_accept(Connection *con) override {\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (!s) {\n      s = new Session(con);\n      con->set_priv(s->get());\n    }\n    s->put();\n  }\n  bool ms_dispatch(Message *m) override {\n    Session *s = static_cast<Session*>(m->get_connection()->get_priv());\n    if (!s) {\n      s = new Session(m->get_connection());\n      m->get_connection()->set_priv(s->get());\n    }\n    s->put();\n    s->count++;\n    lderr(g_ceph_context) << __func__ << \" conn: \" << m->get_connection() << \" session \" << s << \" count: \" << s->count << dendl;\n    if (is_server) {\n      reply_message(m);\n    }\n    Mutex::Locker l(lock);\n    got_new = true;\n    cond.Signal();\n    m->put();\n    return true;\n  }\n  bool ms_handle_reset(Connection *con) override {\n    Mutex::Locker l(lock);\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (s) {\n      s->con.reset(NULL);  // break con <-> session ref cycle\n      con->set_priv(NULL);   // break ref <-> session cycle, if any\n      s->put();\n    }\n    return true;\n  }\n  void ms_handle_remote_reset(Connection *con) override {\n    Mutex::Locker l(lock);\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (s) {\n      s->con.reset(NULL);  // break con <-> session ref cycle\n      con->set_priv(NULL);   // break ref <-> session cycle, if any\n      s->put();\n    }\n    got_remote_reset = true;\n    cond.Signal();\n  }\n  bool ms_handle_refused(Connection *con) override {\n    return false;\n  }\n  void ms_fast_dispatch(Message *m) override {\n    Session *s = static_cast<Session*>(m->get_connection()->get_priv());\n    if (!s) {\n      s = new Session(m->get_connection());\n      m->get_connection()->set_priv(s->get());\n    }\n    s->put();\n    s->count++;\n    lderr(g_ceph_context) << __func__ << \" conn: \" << m->get_connection() << \" session \" << s << \" count: \" << s->count << dendl;\n    if (is_server) {\n      if (loopback)\n        assert(m->get_source().is_osd());\n      else\n        reply_message(m);\n    } else if (loopback) {\n      assert(m->get_source().is_client());\n    }\n    m->put();\n    Mutex::Locker l(lock);\n    got_new = true;\n    cond.Signal();\n  }\n\n  bool ms_verify_authorizer(Connection *con, int peer_type, int protocol,\n                            bufferlist& authorizer, bufferlist& authorizer_reply,\n                            bool& isvalid, CryptoKey& session_key) override {\n    isvalid = true;\n    return true;\n  }\n\n  void reply_message(Message *m) {\n    MPing *rm = new MPing();\n    m->get_connection()->send_message(rm);\n  }\n};\n\ntypedef FakeDispatcher::Session Session;\n\nTEST_P(MessengerTest, SimpleTest) {\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. simple round trip\n  MPing *m = new MPing();\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(conn->is_connected());\n  ASSERT_TRUE((static_cast<Session*>(conn->get_priv()))->get_count() == 1);\n  ASSERT_TRUE(conn->peer_is_osd());\n\n  // 2. test rebind port\n  set<int> avoid_ports;\n  for (int i = 0; i < 10 ; i++)\n    avoid_ports.insert(server_msgr->get_myaddr().get_port() + i);\n  server_msgr->rebind(avoid_ports);\n  ASSERT_TRUE(avoid_ports.count(server_msgr->get_myaddr().get_port()) == 0);\n\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n\n  // 3. test markdown connection\n  conn->mark_down();\n  ASSERT_FALSE(conn->is_connected());\n\n  // 4. test failed connection\n  server_msgr->shutdown();\n  server_msgr->wait();\n\n  m = new MPing();\n  conn->send_message(m);\n  CHECK_AND_WAIT_TRUE(!conn->is_connected());\n  ASSERT_FALSE(conn->is_connected());\n\n  // 5. loopback connection\n  srv_dispatcher.loopback = true;\n  conn = client_msgr->get_loopback_connection();\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  srv_dispatcher.loopback = false;\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  client_msgr->shutdown();\n  client_msgr->wait();\n  server_msgr->shutdown();\n  server_msgr->wait();\n}\n\nTEST_P(MessengerTest, NameAddrTest) {\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  MPing *m = new MPing();\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  ASSERT_TRUE(conn->get_peer_addr() == server_msgr->get_myaddr());\n  ConnectionRef server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  // Make should server_conn is the one we already accepted from client,\n  // so it means client_msgr has the same addr when server connection has\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, FeatureTest) {\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  uint64_t all_feature_supported, feature_required, feature_supported = 0;\n  for (int i = 0; i < 10; i++)\n    feature_supported |= 1ULL << i;\n  feature_required = feature_supported | 1ULL << 13;\n  all_feature_supported = feature_required | 1ULL << 14;\n\n  Messenger::Policy p = server_msgr->get_policy(entity_name_t::TYPE_CLIENT);\n  p.features_required = feature_required;\n  server_msgr->set_policy(entity_name_t::TYPE_CLIENT, p);\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n\n  // 1. Suppose if only support less than required\n  p = client_msgr->get_policy(entity_name_t::TYPE_OSD);\n  p.features_supported = feature_supported;\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  MPing *m = new MPing();\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  conn->send_message(m);\n  CHECK_AND_WAIT_TRUE(!conn->is_connected());\n  // should failed build a connection\n  ASSERT_FALSE(conn->is_connected());\n\n  client_msgr->shutdown();\n  client_msgr->wait();\n\n  // 2. supported met required\n  p = client_msgr->get_policy(entity_name_t::TYPE_OSD);\n  p.features_supported = all_feature_supported;\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n  client_msgr->start();\n\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, TimeoutTest) {\n  g_ceph_context->_conf->set_val(\"ms_tcp_read_timeout\", \"1\");\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. build the connection\n  MPing *m = new MPing();\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(conn->is_connected());\n  ASSERT_TRUE((static_cast<Session*>(conn->get_priv()))->get_count() == 1);\n  ASSERT_TRUE(conn->peer_is_osd());\n\n  // 2. wait for idle\n  usleep(2500*1000);\n  ASSERT_FALSE(conn->is_connected());\n\n  server_msgr->shutdown();\n  server_msgr->wait();\n\n  client_msgr->shutdown();\n  client_msgr->wait();\n  g_ceph_context->_conf->set_val(\"ms_tcp_read_timeout\", \"900\");\n}\n\nTEST_P(MessengerTest, StatefulTest) {\n  Message *m;\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  Messenger::Policy p = Messenger::Policy::stateful_server(0);\n  server_msgr->set_policy(entity_name_t::TYPE_CLIENT, p);\n  p = Messenger::Policy::lossless_client(0);\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. test for server standby\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  conn->mark_down();\n  ASSERT_FALSE(conn->is_connected());\n  ConnectionRef server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  // don't lose state\n  ASSERT_TRUE(static_cast<Session*>(server_conn->get_priv())->get_count() == 1);\n\n  srv_dispatcher.got_new = false;\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  {\n    Mutex::Locker l(srv_dispatcher.lock);\n    while (!srv_dispatcher.got_remote_reset)\n      srv_dispatcher.cond.Wait(srv_dispatcher.lock);\n  }\n\n  // 2. test for client reconnect\n  ASSERT_FALSE(cli_dispatcher.got_remote_reset);\n  cli_dispatcher.got_connect = false;\n  cli_dispatcher.got_new = false;\n  cli_dispatcher.got_remote_reset = false;\n  server_conn->mark_down();\n  ASSERT_FALSE(server_conn->is_connected());\n  // ensure client detect server socket closed\n  {\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_remote_reset)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_remote_reset = false;\n  }\n  {\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_connect)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_connect = false;\n  }\n  CHECK_AND_WAIT_TRUE(conn->is_connected());\n  ASSERT_TRUE(conn->is_connected());\n\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    ASSERT_TRUE(conn->is_connected());\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  // resetcheck happen\n  ASSERT_EQ(1U, static_cast<Session*>(conn->get_priv())->get_count());\n  server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  ASSERT_EQ(1U, static_cast<Session*>(server_conn->get_priv())->get_count());\n  cli_dispatcher.got_remote_reset = false;\n\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, StatelessTest) {\n  Message *m;\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  Messenger::Policy p = Messenger::Policy::stateless_server(0);\n  server_msgr->set_policy(entity_name_t::TYPE_CLIENT, p);\n  p = Messenger::Policy::lossy_client(0);\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. test for server lose state\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  conn->mark_down();\n  ASSERT_FALSE(conn->is_connected());\n\n  srv_dispatcher.got_new = false;\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  ConnectionRef server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  // server lose state\n  {\n    Mutex::Locker l(srv_dispatcher.lock);\n    while (!srv_dispatcher.got_new)\n      srv_dispatcher.cond.Wait(srv_dispatcher.lock);\n  }\n  ASSERT_EQ(1U, static_cast<Session*>(server_conn->get_priv())->get_count());\n\n  // 2. test for client lossy\n  server_conn->mark_down();\n  ASSERT_FALSE(server_conn->is_connected());\n  conn->send_keepalive();\n  CHECK_AND_WAIT_TRUE(!conn->is_connected());\n  ASSERT_FALSE(conn->is_connected());\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, ClientStandbyTest) {\n  Message *m;\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  Messenger::Policy p = Messenger::Policy::stateful_server(0);\n  server_msgr->set_policy(entity_name_t::TYPE_CLIENT, p);\n  p = Messenger::Policy::lossless_peer(0);\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. test for client standby, resetcheck\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  ConnectionRef server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  ASSERT_FALSE(cli_dispatcher.got_remote_reset);\n  cli_dispatcher.got_connect = false;\n  server_conn->mark_down();\n  ASSERT_FALSE(server_conn->is_connected());\n  // client should be standby\n  usleep(300*1000);\n  // client should be standby, so we use original connection\n  {\n    // Try send message to verify got remote reset callback\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    {\n      Mutex::Locker l(cli_dispatcher.lock);\n      while (!cli_dispatcher.got_remote_reset)\n        cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n      cli_dispatcher.got_remote_reset = false;\n      while (!cli_dispatcher.got_connect)\n        cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n      cli_dispatcher.got_connect = false;\n    }\n    CHECK_AND_WAIT_TRUE(conn->is_connected());\n    ASSERT_TRUE(conn->is_connected());\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  ASSERT_TRUE(static_cast<Session*>(server_conn->get_priv())->get_count() == 1);\n\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, AuthTest) {\n  g_ceph_context->_conf->set_val(\"auth_cluster_required\", \"cephx\");\n  g_ceph_context->_conf->set_val(\"auth_service_required\", \"cephx\");\n  g_ceph_context->_conf->set_val(\"auth_client_required\", \"cephx\");\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. simple auth round trip\n  MPing *m = new MPing();\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(conn->is_connected());\n  ASSERT_TRUE((static_cast<Session*>(conn->get_priv()))->get_count() == 1);\n\n  // 2. mix auth\n  g_ceph_context->_conf->set_val(\"auth_cluster_required\", \"none\");\n  g_ceph_context->_conf->set_val(\"auth_service_required\", \"none\");\n  g_ceph_context->_conf->set_val(\"auth_client_required\", \"none\");\n  conn->mark_down();\n  ASSERT_FALSE(conn->is_connected());\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    MPing *m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(conn->is_connected());\n  ASSERT_TRUE((static_cast<Session*>(conn->get_priv()))->get_count() == 1);\n\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, MessageTest) {\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  Messenger::Policy p = Messenger::Policy::stateful_server(0);\n  server_msgr->set_policy(entity_name_t::TYPE_CLIENT, p);\n  p = Messenger::Policy::lossless_peer(0);\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n\n  // 1. A very large \"front\"(as well as \"payload\")\n  // Because a external message need to invade Messenger::decode_message,\n  // here we only use existing message class(MCommand)\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    uuid_d uuid;\n    uuid.generate_random();\n    vector<string> cmds;\n    string s(\"abcdefghijklmnopqrstuvwxyz\");\n    for (int i = 0; i < 1024*30; i++)\n      cmds.push_back(s);\n    MCommand *m = new MCommand(uuid);\n    m->cmd = cmds;\n    conn->send_message(m);\n    utime_t t;\n    t += 1000*1000*500;\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.WaitInterval(cli_dispatcher.lock, t);\n    ASSERT_TRUE(cli_dispatcher.got_new);\n    cli_dispatcher.got_new = false;\n  }\n\n  // 2. A very large \"data\"\n  {\n    bufferlist bl;\n    string s(\"abcdefghijklmnopqrstuvwxyz\");\n    for (int i = 0; i < 1024*30; i++)\n      bl.append(s);\n    MPing *m = new MPing();\n    m->set_data(bl);\n    conn->send_message(m);\n    utime_t t;\n    t += 1000*1000*500;\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.WaitInterval(cli_dispatcher.lock, t);\n    ASSERT_TRUE(cli_dispatcher.got_new);\n    cli_dispatcher.got_new = false;\n  }\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\n\nclass SyntheticWorkload;\n\nstruct Payload {\n  enum Who : uint8_t {\n    PING = 0,\n    PONG = 1,\n  };\n  uint8_t who;\n  uint64_t seq;\n  bufferlist data;\n\n  Payload(Who who, uint64_t seq, const bufferlist& data)\n    : who(who), seq(seq), data(data)\n  {}\n  Payload() = default;\n  DENC(Payload, v, p) {\n    DENC_START(1, 1, p);\n    denc(v.who, p);\n    denc(v.seq, p);\n    denc(v.data, p);\n    DENC_FINISH(p);\n  }\n};\nWRITE_CLASS_DENC(Payload)\n\nostream& operator<<(ostream& out, const Payload &pl)\n{\n  return out << \"reply=\" << pl.who << \" i = \" << pl.seq;\n}\n\nclass SyntheticDispatcher : public Dispatcher {\n public:\n  Mutex lock;\n  Cond cond;\n  bool is_server;\n  bool got_new;\n  bool got_remote_reset;\n  bool got_connect;\n  map<ConnectionRef, list<uint64_t> > conn_sent;\n  map<uint64_t, bufferlist> sent;\n  atomic<uint64_t> index;\n  SyntheticWorkload *workload;\n\n  SyntheticDispatcher(bool s, SyntheticWorkload *wl):\n      Dispatcher(g_ceph_context), lock(\"SyntheticDispatcher::lock\"), is_server(s), got_new(false),\n      got_remote_reset(false), got_connect(false), index(0), workload(wl) {}\n  bool ms_can_fast_dispatch_any() const override { return true; }\n  bool ms_can_fast_dispatch(const Message *m) const override {\n    switch (m->get_type()) {\n    case CEPH_MSG_PING:\n    case MSG_COMMAND:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  void ms_handle_fast_connect(Connection *con) override {\n    Mutex::Locker l(lock);\n    list<uint64_t> c = conn_sent[con];\n    for (list<uint64_t>::iterator it = c.begin();\n         it != c.end(); ++it)\n      sent.erase(*it);\n    conn_sent.erase(con);\n    got_connect = true;\n    cond.Signal();\n  }\n  void ms_handle_fast_accept(Connection *con) override {\n    Mutex::Locker l(lock);\n    list<uint64_t> c = conn_sent[con];\n    for (list<uint64_t>::iterator it = c.begin();\n         it != c.end(); ++it)\n      sent.erase(*it);\n    conn_sent.erase(con);\n    cond.Signal();\n  }\n  bool ms_dispatch(Message *m) override {\n    ceph_abort();\n  }\n  bool ms_handle_reset(Connection *con) override;\n  void ms_handle_remote_reset(Connection *con) override {\n    Mutex::Locker l(lock);\n    list<uint64_t> c = conn_sent[con];\n    for (list<uint64_t>::iterator it = c.begin();\n         it != c.end(); ++it)\n      sent.erase(*it);\n    conn_sent.erase(con);\n    got_remote_reset = true;\n  }\n  bool ms_handle_refused(Connection *con) override {\n    return false;\n  }\n  void ms_fast_dispatch(Message *m) override {\n    // MSG_COMMAND is used to disorganize regular message flow\n    if (m->get_type() == MSG_COMMAND) {\n      m->put();\n      return ;\n    }\n\n    Payload pl;\n    auto p = m->get_data().begin();\n    ::decode(pl, p);\n    if (pl.who == Payload::PING) {\n      lderr(g_ceph_context) << __func__ << \" conn=\" << m->get_connection() << pl << dendl;\n      reply_message(m, pl);\n      m->put();\n      Mutex::Locker l(lock);\n      got_new = true;\n      cond.Signal();\n    } else {\n      Mutex::Locker l(lock);\n      if (sent.count(pl.seq)) {\n\tlderr(g_ceph_context) << __func__ << \" conn=\" << m->get_connection() << pl << dendl;\n\tASSERT_EQ(conn_sent[m->get_connection()].front(), pl.seq);\n\tASSERT_TRUE(pl.data.contents_equal(sent[pl.seq]));\n\tconn_sent[m->get_connection()].pop_front();\n\tsent.erase(pl.seq);\n      }\n      m->put();\n      got_new = true;\n      cond.Signal();\n    }\n  }\n\n  bool ms_verify_authorizer(Connection *con, int peer_type, int protocol,\n                            bufferlist& authorizer, bufferlist& authorizer_reply,\n                            bool& isvalid, CryptoKey& session_key) override {\n    isvalid = true;\n    return true;\n  }\n\n  void reply_message(const Message *m, Payload& pl) {\n    pl.who = Payload::PONG;\n    bufferlist bl;\n    ::encode(pl, bl);\n    MPing *rm = new MPing();\n    rm->set_data(bl);\n    m->get_connection()->send_message(rm);\n    lderr(g_ceph_context) << __func__ << \" conn=\" << m->get_connection() << \" reply m=\" << m << \" i=\" << pl.seq << dendl;\n  }\n\n  void send_message_wrap(ConnectionRef con, const bufferlist& data) {\n    Message *m = new MPing();\n    Payload pl{Payload::PING, index++, data};\n    bufferlist bl;\n    ::encode(pl, bl);\n    m->set_data(bl);\n    if (!con->get_messenger()->get_default_policy().lossy) {\n      Mutex::Locker l(lock);\n      sent[pl.seq] = pl.data;\n      conn_sent[con].push_back(pl.seq);\n    }\n    lderr(g_ceph_context) << __func__ << \" conn=\" << con.get() << \" send m=\" << m << \" i=\" << pl.seq << dendl;\n    ASSERT_EQ(0, con->send_message(m));\n  }\n\n  uint64_t get_pending() {\n    Mutex::Locker l(lock);\n    return sent.size();\n  }\n\n  void clear_pending(ConnectionRef con) {\n    Mutex::Locker l(lock);\n\n    for (list<uint64_t>::iterator it = conn_sent[con].begin();\n         it != conn_sent[con].end(); ++it)\n      sent.erase(*it);\n    conn_sent.erase(con);\n  }\n\n  void print() {\n    for (auto && p : conn_sent) {\n      if (!p.second.empty()) {\n        lderr(g_ceph_context) << __func__ << \" \" << p.first << \" wait \" << p.second.size() << dendl;\n      }\n    }\n  }\n};\n\n\nclass SyntheticWorkload {\n  Mutex lock;\n  Cond cond;\n  set<Messenger*> available_servers;\n  set<Messenger*> available_clients;\n  map<ConnectionRef, pair<Messenger*, Messenger*> > available_connections;\n  SyntheticDispatcher dispatcher;\n  gen_type rng;\n  vector<bufferlist> rand_data;\n\n public:\n  static const unsigned max_in_flight = 64;\n  static const unsigned max_connections = 128;\n  static const unsigned max_message_len = 1024 * 1024 * 4;\n\n  SyntheticWorkload(int servers, int clients, string type, int random_num,\n                    Messenger::Policy srv_policy, Messenger::Policy cli_policy):\n      lock(\"SyntheticWorkload::lock\"), dispatcher(false, this), rng(time(NULL)) {\n    Messenger *msgr;\n    int base_port = 16800;\n    entity_addr_t bind_addr;\n    char addr[64];\n    for (int i = 0; i < servers; ++i) {\n      msgr = Messenger::create(g_ceph_context, type, entity_name_t::OSD(0),\n                               \"server\", getpid()+i, 0);\n      snprintf(addr, sizeof(addr), \"127.0.0.1:%d\", base_port+i);\n      bind_addr.parse(addr);\n      msgr->bind(bind_addr);\n      msgr->add_dispatcher_head(&dispatcher);\n\n      assert(msgr);\n      msgr->set_default_policy(srv_policy);\n      available_servers.insert(msgr);\n      msgr->start();\n    }\n\n    for (int i = 0; i < clients; ++i) {\n      msgr = Messenger::create(g_ceph_context, type, entity_name_t::CLIENT(-1),\n                               \"client\", getpid()+i+servers, 0);\n      if (cli_policy.standby) {\n        snprintf(addr, sizeof(addr), \"127.0.0.1:%d\", base_port+i+servers);\n        bind_addr.parse(addr);\n        msgr->bind(bind_addr);\n      }\n      msgr->add_dispatcher_head(&dispatcher);\n\n      assert(msgr);\n      msgr->set_default_policy(cli_policy);\n      available_clients.insert(msgr);\n      msgr->start();\n    }\n\n    for (int i = 0; i < random_num; i++) {\n      bufferlist bl;\n      boost::uniform_int<> u(32, max_message_len);\n      uint64_t value_len = u(rng);\n      bufferptr bp(value_len);\n      bp.zero();\n      for (uint64_t j = 0; j < value_len-sizeof(i); ) {\n        memcpy(bp.c_str()+j, &i, sizeof(i));\n        j += 4096;\n      }\n\n      bl.append(bp);\n      rand_data.push_back(bl);\n    }\n  }\n\n  ConnectionRef _get_random_connection() {\n    while (dispatcher.get_pending() > max_in_flight) {\n      lock.Unlock();\n      usleep(500);\n      lock.Lock();\n    }\n    assert(lock.is_locked());\n    boost::uniform_int<> choose(0, available_connections.size() - 1);\n    int index = choose(rng);\n    map<ConnectionRef, pair<Messenger*, Messenger*> >::iterator i = available_connections.begin();\n    for (; index > 0; --index, ++i) ;\n    return i->first;\n  }\n\n  bool can_create_connection() {\n    return available_connections.size() < max_connections;\n  }\n\n  void generate_connection() {\n    Mutex::Locker l(lock);\n    if (!can_create_connection())\n      return ;\n\n    Messenger *server, *client;\n    {\n      boost::uniform_int<> choose(0, available_servers.size() - 1);\n      int index = choose(rng);\n      set<Messenger*>::iterator i = available_servers.begin();\n      for (; index > 0; --index, ++i) ;\n      server = *i;\n    }\n    {\n      boost::uniform_int<> choose(0, available_clients.size() - 1);\n      int index = choose(rng);\n      set<Messenger*>::iterator i = available_clients.begin();\n      for (; index > 0; --index, ++i) ;\n      client = *i;\n    }\n\n    pair<Messenger*, Messenger*> p;\n    {\n      boost::uniform_int<> choose(0, available_servers.size() - 1);\n      if (server->get_default_policy().server) {\n        p = make_pair(client, server);\n      } else {\n        ConnectionRef conn = client->get_connection(server->get_myinst());\n        if (available_connections.count(conn) || choose(rng) % 2)\n          p = make_pair(client, server);\n        else\n          p = make_pair(server, client);\n      }\n    }\n    ConnectionRef conn = p.first->get_connection(p.second->get_myinst());\n    available_connections[conn] = p;\n  }\n\n  void send_message() {\n    Mutex::Locker l(lock);\n    ConnectionRef conn = _get_random_connection();\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val >= 95) {\n      uuid_d uuid;\n      uuid.generate_random();\n      MCommand *m = new MCommand(uuid);\n      vector<string> cmds;\n      cmds.push_back(\"command\");\n      m->cmd = cmds;\n      m->set_priority(200);\n      conn->send_message(m);\n    } else {\n      boost::uniform_int<> u(0, rand_data.size()-1);\n      dispatcher.send_message_wrap(conn, rand_data[u(rng)]);\n    }\n  }\n\n  void drop_connection() {\n    Mutex::Locker l(lock);\n    if (available_connections.size() < 10)\n      return;\n    ConnectionRef conn = _get_random_connection();\n    dispatcher.clear_pending(conn);\n    conn->mark_down();\n    pair<Messenger*, Messenger*> &p = available_connections[conn];\n    // it's a lossless policy, so we need to mark down each side\n    if (!p.first->get_default_policy().server && !p.second->get_default_policy().server) {\n      ASSERT_EQ(conn->get_messenger(), p.first);\n      ConnectionRef peer = p.second->get_connection(p.first->get_myinst());\n      peer->mark_down();\n      dispatcher.clear_pending(peer);\n      available_connections.erase(peer);\n    }\n    ASSERT_EQ(available_connections.erase(conn), 1U);\n  }\n\n  void print_internal_state(bool detail=false) {\n    Mutex::Locker l(lock);\n    lderr(g_ceph_context) << \"available_connections: \" << available_connections.size()\n         << \" inflight messages: \" << dispatcher.get_pending() << dendl;\n    if (detail && !available_connections.empty()) {\n      dispatcher.print();\n    }\n  }\n\n  void wait_for_done() {\n    int64_t tick_us = 1000 * 100; // 100ms\n    int64_t timeout_us = 5 * 60 * 1000 * 1000; // 5 mins\n    int i = 0;\n    while (dispatcher.get_pending()) {\n      usleep(tick_us);\n      timeout_us -= tick_us;\n      if (i++ % 50 == 0)\n        print_internal_state(true);\n      if (timeout_us < 0)\n        assert(0 == \" loop time exceed 5 mins, it looks we stuck into some problems!\");\n    }\n    for (set<Messenger*>::iterator it = available_servers.begin();\n         it != available_servers.end(); ++it) {\n      (*it)->shutdown();\n      (*it)->wait();\n      ASSERT_EQ((*it)->get_dispatch_queue_len(), 0);\n      delete (*it);\n    }\n    available_servers.clear();\n\n    for (set<Messenger*>::iterator it = available_clients.begin();\n         it != available_clients.end(); ++it) {\n      (*it)->shutdown();\n      (*it)->wait();\n      ASSERT_EQ((*it)->get_dispatch_queue_len(), 0);\n      delete (*it);\n    }\n    available_clients.clear();\n  }\n\n  void handle_reset(Connection *con) {\n    Mutex::Locker l(lock);\n    available_connections.erase(con);\n    dispatcher.clear_pending(con);\n  }\n};\n\nbool SyntheticDispatcher::ms_handle_reset(Connection *con) {\n  workload->handle_reset(con);\n  return true;\n}\n\nTEST_P(MessengerTest, SyntheticStressTest) {\n  SyntheticWorkload test_msg(8, 32, GetParam(), 100,\n                             Messenger::Policy::stateful_server(0),\n                             Messenger::Policy::lossless_client(0));\n  for (int i = 0; i < 100; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 5000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 90) {\n      test_msg.generate_connection();\n    } else if (val > 80) {\n      test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 1000 + 500);\n    }\n  }\n  test_msg.wait_for_done();\n}\n\nTEST_P(MessengerTest, SyntheticStressTest1) {\n  SyntheticWorkload test_msg(16, 32, GetParam(), 100,\n                             Messenger::Policy::lossless_peer_reuse(0),\n                             Messenger::Policy::lossless_peer_reuse(0));\n  for (int i = 0; i < 10; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 10000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 80) {\n      test_msg.generate_connection();\n    } else if (val > 60) {\n      test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 1000 + 500);\n    }\n  }\n  test_msg.wait_for_done();\n}\n\n\nTEST_P(MessengerTest, SyntheticInjectTest) {\n  uint64_t dispatch_throttle_bytes = g_ceph_context->_conf->ms_dispatch_throttle_bytes;\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"30\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0.1\");\n  g_ceph_context->_conf->set_val(\"ms_dispatch_throttle_bytes\", \"16777216\");\n  SyntheticWorkload test_msg(8, 32, GetParam(), 100,\n                             Messenger::Policy::stateful_server(0),\n                             Messenger::Policy::lossless_client(0));\n  for (int i = 0; i < 100; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 1000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 90) {\n      test_msg.generate_connection();\n    } else if (val > 80) {\n      test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 500 + 100);\n    }\n  }\n  test_msg.wait_for_done();\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0\");\n  g_ceph_context->_conf->set_val(\n      \"ms_dispatch_throttle_bytes\", std::to_string(dispatch_throttle_bytes));\n}\n\nTEST_P(MessengerTest, SyntheticInjectTest2) {\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"30\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0.1\");\n  SyntheticWorkload test_msg(8, 16, GetParam(), 100,\n                             Messenger::Policy::lossless_peer_reuse(0),\n                             Messenger::Policy::lossless_peer_reuse(0));\n  for (int i = 0; i < 100; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 1000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 90) {\n      test_msg.generate_connection();\n    } else if (val > 80) {\n      test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 500 + 100);\n    }\n  }\n  test_msg.wait_for_done();\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0\");\n}\n\nTEST_P(MessengerTest, SyntheticInjectTest3) {\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"600\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0.1\");\n  SyntheticWorkload test_msg(8, 16, GetParam(), 100,\n                             Messenger::Policy::stateless_server(0),\n                             Messenger::Policy::lossy_client(0));\n  for (int i = 0; i < 100; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 1000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 90) {\n      test_msg.generate_connection();\n    } else if (val > 80) {\n      test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 500 + 100);\n    }\n  }\n  test_msg.wait_for_done();\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0\");\n}\n\n\nTEST_P(MessengerTest, SyntheticInjectTest4) {\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"30\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0.1\");\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_probability\", \"1\");\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_type\", \"client osd\", false);\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_max\", \"5\");\n  SyntheticWorkload test_msg(16, 32, GetParam(), 100,\n                             Messenger::Policy::lossless_peer(0),\n                             Messenger::Policy::lossless_peer(0));\n  for (int i = 0; i < 100; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 1000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 95) {\n      test_msg.generate_connection();\n    } else if (val > 80) {\n      // test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 500 + 100);\n    }\n  }\n  test_msg.wait_for_done();\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_probability\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_type\", \"\", false);\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_max\", \"0\");\n}\n\n\nclass MarkdownDispatcher : public Dispatcher {\n  Mutex lock;\n  set<ConnectionRef> conns;\n  bool last_mark;\n public:\n  std::atomic<uint64_t> count = { 0 };\n  explicit MarkdownDispatcher(bool s): Dispatcher(g_ceph_context), lock(\"MarkdownDispatcher::lock\"),\n                              last_mark(false) {}\n  bool ms_can_fast_dispatch_any() const override { return false; }\n  bool ms_can_fast_dispatch(const Message *m) const override {\n    switch (m->get_type()) {\n    case CEPH_MSG_PING:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  void ms_handle_fast_connect(Connection *con) override {\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n    Mutex::Locker l(lock);\n    conns.insert(con);\n  }\n  void ms_handle_fast_accept(Connection *con) override {\n    Mutex::Locker l(lock);\n    conns.insert(con);\n  }\n  bool ms_dispatch(Message *m) override {\n    lderr(g_ceph_context) << __func__ << \" conn: \" << m->get_connection() << dendl;\n    Mutex::Locker l(lock);\n    count++;\n    conns.insert(m->get_connection());\n    if (conns.size() < 2 && !last_mark) {\n      m->put();\n      return true;\n    }\n\n    last_mark = true;\n    usleep(rand() % 500);\n    for (set<ConnectionRef>::iterator it = conns.begin(); it != conns.end(); ++it) {\n      if ((*it) != m->get_connection().get()) {\n        (*it)->mark_down();\n        conns.erase(it);\n        break;\n      }\n    }\n    if (conns.empty())\n      last_mark = false;\n    m->put();\n    return true;\n  }\n  bool ms_handle_reset(Connection *con) override {\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n    Mutex::Locker l(lock);\n    conns.erase(con);\n    usleep(rand() % 500);\n    return true;\n  }\n  void ms_handle_remote_reset(Connection *con) override {\n    Mutex::Locker l(lock);\n    conns.erase(con);\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n  }\n  bool ms_handle_refused(Connection *con) override {\n    return false;\n  }\n  void ms_fast_dispatch(Message *m) override {\n    ceph_abort();\n  }\n  bool ms_verify_authorizer(Connection *con, int peer_type, int protocol,\n                            bufferlist& authorizer, bufferlist& authorizer_reply,\n                            bool& isvalid, CryptoKey& session_key) override {\n    isvalid = true;\n    return true;\n  }\n};\n\n\n// Markdown with external lock\nTEST_P(MessengerTest, MarkdownTest) {\n  Messenger *server_msgr2 = Messenger::create(g_ceph_context, string(GetParam()), entity_name_t::OSD(0), \"server\", getpid(), 0);\n  MarkdownDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1:16800\");\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n  bind_addr.parse(\"127.0.0.1:16801\");\n  server_msgr2->bind(bind_addr);\n  server_msgr2->add_dispatcher_head(&srv_dispatcher);\n  server_msgr2->start();\n\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  int i = 1000;\n  uint64_t last = 0;\n  bool equal = false;\n  uint64_t equal_count = 0;\n  while (i--) {\n    ConnectionRef conn1 = client_msgr->get_connection(server_msgr->get_myinst());\n    ConnectionRef conn2 = client_msgr->get_connection(server_msgr2->get_myinst());\n    MPing *m = new MPing();\n    ASSERT_EQ(conn1->send_message(m), 0);\n    m = new MPing();\n    ASSERT_EQ(conn2->send_message(m), 0);\n    CHECK_AND_WAIT_TRUE(srv_dispatcher.count > last + 1);\n    if (srv_dispatcher.count == last) {\n      lderr(g_ceph_context) << __func__ << \" last is \" << last << dendl;\n      equal = true;\n      equal_count++;\n    } else {\n      equal = false;\n      equal_count = 0;\n    }\n    last = srv_dispatcher.count;\n    if (equal_count)\n      usleep(1000*500);\n    ASSERT_FALSE(equal && equal_count > 3);\n  }\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr2->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n  server_msgr2->wait();\n  delete server_msgr2;\n}\n\nINSTANTIATE_TEST_CASE_P(\n  Messenger,\n  MessengerTest,\n  ::testing::Values(\n    \"async+posix\",\n    \"simple\"\n  )\n);\n\n#else\n\n// Google Test may not support value-parameterized tests with some\n// compilers. If we use conditional compilation to compile out all\n// code referring to the gtest_main library, MSVC linker will not link\n// that library at all and consequently complain about missing entry\n// point defined in that library (fatal error LNK1561: entry point\n// must be defined). This dummy test keeps gtest_main linked in.\nTEST(DummyTest, ValueParameterizedTestsAreNotSupportedOnThisPlatform) {}\n\n#endif\n\n\nint main(int argc, char **argv) {\n  vector<const char*> args;\n  argv_to_vec(argc, (const char **)argv, args);\n  env_to_vec(args);\n\n  auto cct = global_init(NULL, args, CEPH_ENTITY_TYPE_CLIENT, CODE_ENVIRONMENT_UTILITY, 0);\n  g_ceph_context->_conf->set_val(\"auth_cluster_required\", \"none\");\n  g_ceph_context->_conf->set_val(\"auth_service_required\", \"none\");\n  g_ceph_context->_conf->set_val(\"auth_client_required\", \"none\");\n  g_ceph_context->_conf->set_val(\"enable_experimental_unrecoverable_data_corrupting_features\", \"ms-type-async\");\n  g_ceph_context->_conf->set_val(\"ms_die_on_bad_msg\", \"true\");\n  g_ceph_context->_conf->set_val(\"ms_die_on_old_message\", \"true\");\n  g_ceph_context->_conf->set_val(\"ms_max_backoff\", \"1\");\n  common_init_finish(g_ceph_context);\n\n  ::testing::InitGoogleTest(&argc, argv);\n  return RUN_ALL_TESTS();\n}\n\n/*\n * Local Variables:\n * compile-command: \"cd ../.. ; make -j4 ceph_test_msgr && valgrind --tool=memcheck ./ceph_test_msgr\"\n * End:\n */\n"], "fixing_code": ["// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_AUTHTYPES_H\n#define CEPH_AUTHTYPES_H\n\n#include \"Crypto.h\"\n#include \"common/entity_name.h\"\n\nclass Cond;\n\nstruct EntityAuth {\n  uint64_t auid;\n  CryptoKey key;\n  map<string, bufferlist> caps;\n\n  EntityAuth() : auid(CEPH_AUTH_UID_DEFAULT) {}\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 2;\n    ::encode(struct_v, bl);\n    ::encode(auid, bl);\n    ::encode(key, bl);\n    ::encode(caps, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    if (struct_v >= 2)\n      ::decode(auid, bl);\n    else auid = CEPH_AUTH_UID_DEFAULT;\n    ::decode(key, bl);\n    ::decode(caps, bl);\n  }\n};\nWRITE_CLASS_ENCODER(EntityAuth)\n\nstatic inline ostream& operator<<(ostream& out, const EntityAuth& a) {\n  return out << \"auth(auid = \" << a.auid << \" key=\" << a.key << \" with \" << a.caps.size() << \" caps)\";\n}\n\nstruct AuthCapsInfo {\n  bool allow_all;\n  bufferlist caps;\n\n  AuthCapsInfo() : allow_all(false) {}\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    __u8 a = (__u8)allow_all;\n    ::encode(a, bl);\n    ::encode(caps, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    __u8 a;\n    ::decode(a, bl);\n    allow_all = (bool)a;\n    ::decode(caps, bl);\n  }\n};\nWRITE_CLASS_ENCODER(AuthCapsInfo)\n\n/*\n * The ticket (if properly validated) authorizes the principal use\n * services as described by 'caps' during the specified validity\n * period.\n */\nstruct AuthTicket {\n  EntityName name;\n  uint64_t global_id; /* global instance id */\n  uint64_t auid;\n  utime_t created, renew_after, expires;\n  AuthCapsInfo caps;\n  __u32 flags;\n\n  AuthTicket() : global_id(0), auid(CEPH_AUTH_UID_DEFAULT), flags(0){}\n\n  void init_timestamps(utime_t now, double ttl) {\n    created = now;\n    expires = now;\n    expires += ttl;\n    renew_after = now;\n    renew_after += ttl / 2.0;\n  }\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 2;\n    ::encode(struct_v, bl);\n    ::encode(name, bl);\n    ::encode(global_id, bl);\n    ::encode(auid, bl);\n    ::encode(created, bl);\n    ::encode(expires, bl);\n    ::encode(caps, bl);\n    ::encode(flags, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(name, bl);\n    ::decode(global_id, bl);\n    if (struct_v >= 2)\n      ::decode(auid, bl);\n    else auid = CEPH_AUTH_UID_DEFAULT;\n    ::decode(created, bl);\n    ::decode(expires, bl);\n    ::decode(caps, bl);\n    ::decode(flags, bl);\n  }\n};\nWRITE_CLASS_ENCODER(AuthTicket)\n\n\n/*\n * abstract authorizer class\n */\nstruct AuthAuthorizer {\n  __u32 protocol;\n  bufferlist bl;\n  CryptoKey session_key;\n\n  explicit AuthAuthorizer(__u32 p) : protocol(p) {}\n  virtual ~AuthAuthorizer() {}\n  virtual bool verify_reply(bufferlist::iterator& reply) = 0;\n  virtual bool add_challenge(CephContext *cct, bufferlist& challenge) = 0;\n};\n\nstruct AuthAuthorizerChallenge {\n  virtual ~AuthAuthorizerChallenge() {}\n};\n\n\n/*\n * Key management\n */ \n#define KEY_ROTATE_NUM 3   /* prev, current, next */\n\nstruct ExpiringCryptoKey {\n  CryptoKey key;\n  utime_t expiration;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(key, bl);\n    ::encode(expiration, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(key, bl);\n    ::decode(expiration, bl);\n  }\n};\nWRITE_CLASS_ENCODER(ExpiringCryptoKey)\n\nstatic inline ostream& operator<<(ostream& out, const ExpiringCryptoKey& c)\n{\n  return out << c.key << \" expires \" << c.expiration;\n}\n\nstruct RotatingSecrets {\n  map<uint64_t, ExpiringCryptoKey> secrets;\n  version_t max_ver;\n  \n  RotatingSecrets() : max_ver(0) {}\n  \n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(secrets, bl);\n    ::encode(max_ver, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(secrets, bl);\n    ::decode(max_ver, bl);\n  }\n  \n  uint64_t add(ExpiringCryptoKey& key) {\n    secrets[++max_ver] = key;\n    while (secrets.size() > KEY_ROTATE_NUM)\n      secrets.erase(secrets.begin());\n    return max_ver;\n  }\n  \n  bool need_new_secrets() const {\n    return secrets.size() < KEY_ROTATE_NUM;\n  }\n  bool need_new_secrets(utime_t now) const {\n    return secrets.size() < KEY_ROTATE_NUM || current().expiration <= now;\n  }\n\n  ExpiringCryptoKey& previous() {\n    return secrets.begin()->second;\n  }\n  ExpiringCryptoKey& current() {\n    map<uint64_t, ExpiringCryptoKey>::iterator p = secrets.begin();\n    ++p;\n    return p->second;\n  }\n  const ExpiringCryptoKey& current() const {\n    map<uint64_t, ExpiringCryptoKey>::const_iterator p = secrets.begin();\n    ++p;\n    return p->second;\n  }\n  ExpiringCryptoKey& next() {\n    return secrets.rbegin()->second;\n  }\n  bool empty() {\n    return secrets.empty();\n  }\n\n  void dump();\n};\nWRITE_CLASS_ENCODER(RotatingSecrets)\n\n\n\nclass KeyStore {\npublic:\n  virtual ~KeyStore() {}\n  virtual bool get_secret(const EntityName& name, CryptoKey& secret) const = 0;\n  virtual bool get_service_secret(uint32_t service_id, uint64_t secret_id,\n\t\t\t\t  CryptoKey& secret) const = 0;\n};\n\nstatic inline bool auth_principal_needs_rotating_keys(EntityName& name)\n{\n  uint32_t ty(name.get_type());\n  return ((ty == CEPH_ENTITY_TYPE_OSD)\n      || (ty == CEPH_ENTITY_TYPE_MDS)\n      || (ty == CEPH_ENTITY_TYPE_MGR));\n}\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_AUTHAUTHORIZEHANDLER_H\n#define CEPH_AUTHAUTHORIZEHANDLER_H\n\n#include \"Auth.h\"\n#include \"AuthMethodList.h\"\n#include \"include/types.h\"\n#include \"common/Mutex.h\"\n// Different classes of session crypto handling\n\n#define SESSION_CRYPTO_NONE 0\n#define SESSION_SYMMETRIC_AUTHENTICATE 1\n#define SESSION_SYMMETRIC_ENCRYPT 2\n\nclass CephContext;\nclass KeyRing;\nclass RotatingKeyRing;\n\nstruct AuthAuthorizeHandler {\n  virtual ~AuthAuthorizeHandler() {}\n  virtual bool verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t\t bufferlist& authorizer_data, bufferlist& authorizer_reply,\n                                 EntityName& entity_name, uint64_t& global_id,\n\t\t\t\t AuthCapsInfo& caps_info, CryptoKey& session_key,\n\t\t\t\t uint64_t *auid,\n\t\t\t\t std::unique_ptr<AuthAuthorizerChallenge> *challenge) = 0;\n  virtual int authorizer_session_crypto() = 0;\n};\n\nclass AuthAuthorizeHandlerRegistry {\n  Mutex m_lock;\n  map<int,AuthAuthorizeHandler*> m_authorizers;\n  AuthMethodList supported;\n\npublic:\n  AuthAuthorizeHandlerRegistry(CephContext *cct_, std::string methods)\n    : m_lock(\"AuthAuthorizeHandlerRegistry::m_lock\"), supported(cct_, methods)\n  {}\n  ~AuthAuthorizeHandlerRegistry();\n  \n  AuthAuthorizeHandler *get_handler(int protocol);\n};\n\n#endif\n", "#include \"CephxProtocol.h\"\n#include \"CephxAuthorizeHandler.h\"\n#include \"common/dout.h\"\n\n#define dout_subsys ceph_subsys_auth\n\n\n\nbool CephxAuthorizeHandler::verify_authorizer(\n  CephContext *cct, KeyStore *keys,\n  bufferlist& authorizer_data, bufferlist& authorizer_reply,\n  EntityName& entity_name, uint64_t& global_id, AuthCapsInfo& caps_info,\n  CryptoKey& session_key, uint64_t *auid,\n  std::unique_ptr<AuthAuthorizerChallenge> *challenge)\n{\n  bufferlist::iterator iter = authorizer_data.begin();\n\n  if (!authorizer_data.length()) {\n    ldout(cct, 1) << \"verify authorizer, authorizer_data.length()=0\" << dendl;\n    return false;\n  }\n\n  CephXServiceTicketInfo auth_ticket_info;\n\n  bool isvalid = cephx_verify_authorizer(cct, keys, iter, auth_ticket_info, challenge,\n\t\t\t\t\t authorizer_reply);\n\n  if (isvalid) {\n    caps_info = auth_ticket_info.ticket.caps;\n    entity_name = auth_ticket_info.ticket.name;\n    global_id = auth_ticket_info.ticket.global_id;\n    session_key = auth_ticket_info.session_key;\n    if (auid) *auid = auth_ticket_info.ticket.auid;\n  }\n\n  return isvalid;\n}\n\n// Return type of crypto used for this session's data;  for cephx, symmetric authentication\n\nint CephxAuthorizeHandler::authorizer_session_crypto() \n{\n  return SESSION_SYMMETRIC_AUTHENTICATE;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_CEPHXAUTHORIZEHANDLER_H\n#define CEPH_CEPHXAUTHORIZEHANDLER_H\n\n#include \"auth/AuthAuthorizeHandler.h\"\n\nclass CephContext;\n\nstruct CephxAuthorizeHandler : public AuthAuthorizeHandler {\n  bool verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t bufferlist& authorizer_data, bufferlist& authorizer_reply,\n                         EntityName& entity_name, uint64_t& global_id,\n\t\t\t AuthCapsInfo& caps_info, CryptoKey& session_key, uint64_t *auid,\n\t\t\t std::unique_ptr<AuthAuthorizerChallenge> *challenge) override;\n  int authorizer_session_crypto() override;\n};\n\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2009-2011 New Dream Network\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include \"CephxProtocol.h\"\n#include \"common/Clock.h\"\n#include \"common/config.h\"\n#include \"common/debug.h\"\n#include \"include/buffer.h\"\n\n#define dout_subsys ceph_subsys_auth\n#undef dout_prefix\n#define dout_prefix *_dout << \"cephx: \"\n\n\n\nvoid cephx_calc_client_server_challenge(CephContext *cct, CryptoKey& secret, uint64_t server_challenge, \n\t\t  uint64_t client_challenge, uint64_t *key, std::string &error)\n{\n  CephXChallengeBlob b;\n  b.server_challenge = server_challenge;\n  b.client_challenge = client_challenge;\n\n  bufferlist enc;\n  if (encode_encrypt(cct, b, secret, enc, error))\n    return;\n\n  uint64_t k = 0;\n  const uint64_t *p = (const uint64_t *)enc.c_str();\n  for (int pos = 0; pos + sizeof(k) <= enc.length(); pos+=sizeof(k), p++)\n    k ^= mswab(*p);\n  *key = k;\n}\n\n\n/*\n * Authentication\n */\n\nbool cephx_build_service_ticket_blob(CephContext *cct, CephXSessionAuthInfo& info,\n\t\t\t\t     CephXTicketBlob& blob)\n{\n  CephXServiceTicketInfo ticket_info;\n  ticket_info.session_key = info.session_key;\n  ticket_info.ticket = info.ticket;\n  ticket_info.ticket.caps = info.ticket.caps;\n\n  ldout(cct, 10) << \"build_service_ticket service \" << ceph_entity_type_name(info.service_id)\n\t   << \" secret_id \" << info.secret_id\n\t   << \" ticket_info.ticket.name=\" << ticket_info.ticket.name.to_str() << dendl;\n  blob.secret_id = info.secret_id;\n  std::string error;\n  if (!info.service_secret.get_secret().length())\n    error = \"invalid key\";  // Bad key?\n  else\n    encode_encrypt_enc_bl(cct, ticket_info, info.service_secret, blob.blob, error);\n  if (!error.empty()) {\n    ldout(cct, -1) << \"cephx_build_service_ticket_blob failed with error \"\n\t  << error << dendl;\n    return false;\n  }\n  return true;\n}\n\n/*\n * AUTH SERVER: authenticate\n *\n * Authenticate principal, respond with AuthServiceTicketInfo\n *\n * {session key, validity}^principal_secret\n * {principal_ticket, session key}^service_secret  ... \"enc_ticket\"\n */\nbool cephx_build_service_ticket_reply(CephContext *cct,\n                     CryptoKey& principal_secret,\n                     vector<CephXSessionAuthInfo> ticket_info_vec,\n                     bool should_encrypt_ticket,\n                     CryptoKey& ticket_enc_key,\n                     bufferlist& reply)\n{\n  __u8 service_ticket_reply_v = 1;\n  ::encode(service_ticket_reply_v, reply);\n\n  uint32_t num = ticket_info_vec.size();\n  ::encode(num, reply);\n  ldout(cct, 10) << \"build_service_ticket_reply encoding \" << num\n\t   << \" tickets with secret \" << principal_secret << dendl;\n\n  for (vector<CephXSessionAuthInfo>::iterator ticket_iter = ticket_info_vec.begin(); \n       ticket_iter != ticket_info_vec.end();\n       ++ticket_iter) {\n    CephXSessionAuthInfo& info = *ticket_iter;\n    ::encode(info.service_id, reply);\n\n    __u8 service_ticket_v = 1;\n    ::encode(service_ticket_v, reply);\n\n    CephXServiceTicket msg_a;\n    msg_a.session_key = info.session_key;\n    msg_a.validity = info.validity;\n    std::string error;\n    if (encode_encrypt(cct, msg_a, principal_secret, reply, error)) {\n      ldout(cct, -1) << \"error encoding encrypted: \" << error << dendl;\n      return false;\n    }\n\n    bufferlist service_ticket_bl;\n    CephXTicketBlob blob;\n    if (!cephx_build_service_ticket_blob(cct, info, blob)) {\n      return false;\n    }\n    ::encode(blob, service_ticket_bl);\n\n    ldout(cct, 30) << \"service_ticket_blob is \";\n    service_ticket_bl.hexdump(*_dout);\n    *_dout << dendl;\n\n    ::encode((__u8)should_encrypt_ticket, reply);\n    if (should_encrypt_ticket) {\n      if (encode_encrypt(cct, service_ticket_bl, ticket_enc_key, reply, error)) {\n\tldout(cct, -1) << \"error encoding encrypted ticket: \" << error << dendl;\n        return false;\n      }\n    } else {\n      ::encode(service_ticket_bl, reply);\n    }\n  }\n  return true;\n}\n\n/*\n * PRINCIPAL: verify our attempt to authenticate succeeded.  fill out\n * this ServiceTicket with the result.\n */\nbool CephXTicketHandler::verify_service_ticket_reply(CryptoKey& secret,\n\t\t\t\t\t\t     bufferlist::iterator& indata)\n{\n  __u8 service_ticket_v;\n  ::decode(service_ticket_v, indata);\n\n  CephXServiceTicket msg_a;\n  std::string error;\n  if (decode_decrypt(cct, msg_a, secret, indata, error)) {\n    ldout(cct, 0) << \"verify_service_ticket_reply: failed decode_decrypt, error is: \" << error << dendl;\n    return false;\n  }\n  \n  __u8 ticket_enc;\n  ::decode(ticket_enc, indata);\n\n  bufferlist service_ticket_bl;\n  if (ticket_enc) {\n    ldout(cct, 10) << \" got encrypted ticket\" << dendl;\n    std::string error;\n    if (decode_decrypt(cct, service_ticket_bl, session_key, indata, error)) {\n      ldout(cct, 10) << \"verify_service_ticket_reply: decode_decrypt failed \"\n\t    << \"with \" << error << dendl;\n      return false;\n    }\n  } else {\n    ::decode(service_ticket_bl, indata);\n  }\n  bufferlist::iterator iter = service_ticket_bl.begin();\n  ::decode(ticket, iter);\n  ldout(cct, 10) << \" ticket.secret_id=\" <<  ticket.secret_id << dendl;\n\n  ldout(cct, 10) << \"verify_service_ticket_reply service \" << ceph_entity_type_name(service_id)\n\t   << \" secret_id \" << ticket.secret_id\n\t   << \" session_key \" << msg_a.session_key\n           << \" validity=\" << msg_a.validity << dendl;\n  session_key = msg_a.session_key;\n  if (!msg_a.validity.is_zero()) {\n    expires = ceph_clock_now();\n    expires += msg_a.validity;\n    renew_after = expires;\n    renew_after -= ((double)msg_a.validity.sec() / 4);\n    ldout(cct, 10) << \"ticket expires=\" << expires << \" renew_after=\" << renew_after << dendl;\n  }\n  \n  have_key_flag = true;\n  return true;\n}\n\nbool CephXTicketHandler::have_key()\n{\n  if (have_key_flag) {\n    have_key_flag = ceph_clock_now() < expires;\n  }\n\n  return have_key_flag;\n}\n\nbool CephXTicketHandler::need_key() const\n{\n  if (have_key_flag) {\n    return (!expires.is_zero()) && (ceph_clock_now() >= renew_after);\n  }\n\n  return true;\n}\n\nbool CephXTicketManager::have_key(uint32_t service_id)\n{\n  map<uint32_t, CephXTicketHandler>::iterator iter = tickets_map.find(service_id);\n  if (iter == tickets_map.end())\n    return false;\n  return iter->second.have_key();\n}\n\nbool CephXTicketManager::need_key(uint32_t service_id) const\n{\n  map<uint32_t, CephXTicketHandler>::const_iterator iter = tickets_map.find(service_id);\n  if (iter == tickets_map.end())\n    return true;\n  return iter->second.need_key();\n}\n\nvoid CephXTicketManager::set_have_need_key(uint32_t service_id, uint32_t& have, uint32_t& need)\n{\n  map<uint32_t, CephXTicketHandler>::iterator iter = tickets_map.find(service_id);\n  if (iter == tickets_map.end()) {\n    have &= ~service_id;\n    need |= service_id;\n    ldout(cct, 10) << \"set_have_need_key no handler for service \"\n\t\t   << ceph_entity_type_name(service_id) << dendl;\n    return;\n  }\n\n  //ldout(cct, 10) << \"set_have_need_key service \" << ceph_entity_type_name(service_id)\n  //<< \" (\" << service_id << \")\"\n  //<< \" need=\" << iter->second.need_key() << \" have=\" << iter->second.have_key() << dendl;\n  if (iter->second.need_key())\n    need |= service_id;\n  else\n    need &= ~service_id;\n\n  if (iter->second.have_key())\n    have |= service_id;\n  else\n    have &= ~service_id;\n}\n\nvoid CephXTicketManager::invalidate_ticket(uint32_t service_id)\n{\n  map<uint32_t, CephXTicketHandler>::iterator iter = tickets_map.find(service_id);\n  if (iter != tickets_map.end())\n    iter->second.invalidate_ticket();\n}\n\n/*\n * PRINCIPAL: verify our attempt to authenticate succeeded.  fill out\n * this ServiceTicket with the result.\n */\nbool CephXTicketManager::verify_service_ticket_reply(CryptoKey& secret,\n\t\t\t\t\t\t     bufferlist::iterator& indata)\n{\n  __u8 service_ticket_reply_v;\n  ::decode(service_ticket_reply_v, indata);\n\n  uint32_t num;\n  ::decode(num, indata);\n  ldout(cct, 10) << \"verify_service_ticket_reply got \" << num << \" keys\" << dendl;\n\n  for (int i=0; i<(int)num; i++) {\n    uint32_t type;\n    ::decode(type, indata);\n    ldout(cct, 10) << \"got key for service_id \" << ceph_entity_type_name(type) << dendl;\n    CephXTicketHandler& handler = get_handler(type);\n    if (!handler.verify_service_ticket_reply(secret, indata)) {\n      return false;\n    }\n    handler.service_id = type;\n  }\n\n  if (!indata.end())\n    return false;\n\n  return true;\n}\n\n/*\n * PRINCIPAL: build authorizer to access the service.\n *\n * ticket, {timestamp}^session_key\n */\nCephXAuthorizer *CephXTicketHandler::build_authorizer(uint64_t global_id) const\n{\n  CephXAuthorizer *a = new CephXAuthorizer(cct);\n  a->session_key = session_key;\n  a->nonce = ((uint64_t)rand() << 32) + rand();\n\n  __u8 authorizer_v = 1;\n  ::encode(authorizer_v, a->bl);\n  ::encode(global_id, a->bl);\n  ::encode(service_id, a->bl);\n\n  ::encode(ticket, a->bl);\n  a->base_bl = a->bl;\n\n  CephXAuthorize msg;\n  msg.nonce = a->nonce;\n\n  std::string error;\n  if (encode_encrypt(cct, msg, session_key, a->bl, error)) {\n    ldout(cct, 0) << \"failed to encrypt authorizer: \" << error << dendl;\n    delete a;\n    return 0;\n  }\n  return a;\n}\n\n/*\n * PRINCIPAL: build authorizer to access the service.\n *\n * ticket, {timestamp}^session_key\n */\nCephXAuthorizer *CephXTicketManager::build_authorizer(uint32_t service_id) const\n{\n  map<uint32_t, CephXTicketHandler>::const_iterator iter = tickets_map.find(service_id);\n  if (iter == tickets_map.end()) {\n    ldout(cct, 0) << \"no TicketHandler for service \"\n\t\t  << ceph_entity_type_name(service_id) << dendl;\n    return NULL;\n  }\n\n  const CephXTicketHandler& handler = iter->second;\n  return handler.build_authorizer(global_id);\n}\n\nvoid CephXTicketManager::validate_tickets(uint32_t mask, uint32_t& have, uint32_t& need)\n{\n  uint32_t i;\n  need = 0;\n  for (i = 1; i<=mask; i<<=1) {\n    if (mask & i) {\n      set_have_need_key(i, have, need);\n    }\n  }\n  ldout(cct, 10) << \"validate_tickets want \" << mask << \" have \" << have\n\t\t << \" need \" << need << dendl;\n}\n\nbool cephx_decode_ticket(CephContext *cct, KeyStore *keys, uint32_t service_id,\n\t      CephXTicketBlob& ticket_blob, CephXServiceTicketInfo& ticket_info)\n{\n  uint64_t secret_id = ticket_blob.secret_id;\n  CryptoKey service_secret;\n\n  if (!ticket_blob.blob.length()) {\n    return false;\n  }\n\n  if (secret_id == (uint64_t)-1) {\n    if (!keys->get_secret(cct->_conf->name, service_secret)) {\n      ldout(cct, 0) << \"ceph_decode_ticket could not get general service secret for service_id=\"\n\t      << ceph_entity_type_name(service_id) << \" secret_id=\" << secret_id << dendl;\n      return false;\n    }\n  } else {\n    if (!keys->get_service_secret(service_id, secret_id, service_secret)) {\n      ldout(cct, 0) << \"ceph_decode_ticket could not get service secret for service_id=\" \n\t      << ceph_entity_type_name(service_id) << \" secret_id=\" << secret_id << dendl;\n      return false;\n    }\n  }\n\n  std::string error;\n  decode_decrypt_enc_bl(cct, ticket_info, service_secret, ticket_blob.blob, error);\n  if (!error.empty()) {\n    ldout(cct, 0) << \"ceph_decode_ticket could not decrypt ticket info. error:\" \n\t<< error << dendl;\n    return false;\n  }\n\n  return true;\n}\n\n/*\n * SERVICE: verify authorizer and generate reply authorizer\n *\n * {timestamp + 1}^session_key\n */\nbool cephx_verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t     bufferlist::iterator& indata,\n\t\t\t     CephXServiceTicketInfo& ticket_info,\n\t\t\t     std::unique_ptr<AuthAuthorizerChallenge> *challenge,\n\t\t\t     bufferlist& reply_bl)\n{\n  __u8 authorizer_v;\n  uint32_t service_id;\n  uint64_t global_id;\n  CryptoKey service_secret;\n  // ticket blob\n  CephXTicketBlob ticket;\n\n\n  try {\n    ::decode(authorizer_v, indata);\n    ::decode(global_id, indata);\n    ::decode(service_id, indata);\n    ::decode(ticket, indata);\n  } catch (buffer::end_of_buffer &e) {\n    // Unable to decode!\n    return false;\n  }\n  ldout(cct, 10) << \"verify_authorizer decrypted service \"\n\t   << ceph_entity_type_name(service_id)\n\t   << \" secret_id=\" << ticket.secret_id << dendl;\n\n  if (ticket.secret_id == (uint64_t)-1) {\n    EntityName name;\n    name.set_type(service_id);\n    if (!keys->get_secret(name, service_secret)) {\n      ldout(cct, 0) << \"verify_authorizer could not get general service secret for service \"\n\t      << ceph_entity_type_name(service_id) << \" secret_id=\" << ticket.secret_id << dendl;\n      return false;\n    }\n  } else {\n    if (!keys->get_service_secret(service_id, ticket.secret_id, service_secret)) {\n      ldout(cct, 0) << \"verify_authorizer could not get service secret for service \"\n\t      << ceph_entity_type_name(service_id) << \" secret_id=\" << ticket.secret_id << dendl;\n      if (cct->_conf->auth_debug && ticket.secret_id == 0)\n\tassert(0 == \"got secret_id=0\");\n      return false;\n    }\n  }\n  std::string error;\n  if (!service_secret.get_secret().length())\n    error = \"invalid key\";  // Bad key?\n  else\n    decode_decrypt_enc_bl(cct, ticket_info, service_secret, ticket.blob, error);\n  if (!error.empty()) {\n    ldout(cct, 0) << \"verify_authorizer could not decrypt ticket info: error: \"\n      << error << dendl;\n    return false;\n  }\n\n  if (ticket_info.ticket.global_id != global_id) {\n    ldout(cct, 0) << \"verify_authorizer global_id mismatch: declared id=\" << global_id\n\t    << \" ticket_id=\" << ticket_info.ticket.global_id << dendl;\n    return false;\n  }\n\n  ldout(cct, 10) << \"verify_authorizer global_id=\" << global_id << dendl;\n\n  // CephXAuthorize\n  CephXAuthorize auth_msg;\n  if (decode_decrypt(cct, auth_msg, ticket_info.session_key, indata, error)) {\n    ldout(cct, 0) << \"verify_authorizercould not decrypt authorize request with error: \"\n      << error << dendl;\n    return false;\n  }\n\n  if (challenge) {\n    auto *c = static_cast<CephXAuthorizeChallenge*>(challenge->get());\n    if (!auth_msg.have_challenge || !c) {\n      c = new CephXAuthorizeChallenge;\n      challenge->reset(c);\n      get_random_bytes((char*)&c->server_challenge, sizeof(c->server_challenge));\n      ldout(cct,10) << __func__ << \" adding server_challenge \" << c->server_challenge\n\t\t    << dendl;\n\n      encode_encrypt_enc_bl(cct, *c, ticket_info.session_key, reply_bl, error);\n      if (!error.empty()) {\n\tldout(cct, 10) << \"verify_authorizer: encode_encrypt error: \" << error << dendl;\n\treturn false;\n      }\n      return false;\n    }\n    ldout(cct, 10) << __func__ << \" got server_challenge+1 \"\n\t\t   << auth_msg.server_challenge_plus_one\n\t\t   << \" expecting \" << c->server_challenge + 1 << dendl;\n    if (c->server_challenge + 1 != auth_msg.server_challenge_plus_one) {\n      return false;\n    }\n  }\n\n  /*\n   * Reply authorizer:\n   *  {timestamp + 1}^session_key\n   */\n  CephXAuthorizeReply reply;\n  // reply.trans_id = auth_msg.trans_id;\n  reply.nonce_plus_one = auth_msg.nonce + 1;\n  if (encode_encrypt(cct, reply, ticket_info.session_key, reply_bl, error)) {\n    ldout(cct, 10) << \"verify_authorizer: encode_encrypt error: \" << error << dendl;\n    return false;\n  }\n\n  ldout(cct, 10) << \"verify_authorizer ok nonce \" << hex << auth_msg.nonce << dec\n\t   << \" reply_bl.length()=\" << reply_bl.length() <<  dendl;\n  return true;\n}\n\nbool CephXAuthorizer::verify_reply(bufferlist::iterator& indata)\n{\n  CephXAuthorizeReply reply;\n\n  std::string error;\n  if (decode_decrypt(cct, reply, session_key, indata, error)) {\n      ldout(cct, 0) << \"verify_reply couldn't decrypt with error: \" << error << dendl;\n      return false;\n  }\n\n  uint64_t expect = nonce + 1;\n  if (expect != reply.nonce_plus_one) {\n    ldout(cct, 0) << \"verify_authorizer_reply bad nonce got \" << reply.nonce_plus_one << \" expected \" << expect\n\t    << \" sent \" << nonce << dendl;\n    return false;\n  }\n  return true;\n}\n\nbool CephXAuthorizer::add_challenge(CephContext *cct, bufferlist& challenge)\n{\n  bl = base_bl;\n\n  CephXAuthorize msg;\n  msg.nonce = nonce;\n\n  auto p = challenge.begin();\n  if (!p.end()) {\n    std::string error;\n    CephXAuthorizeChallenge ch;\n    decode_decrypt_enc_bl(cct, ch, session_key, challenge, error);\n    if (!error.empty()) {\n      ldout(cct, 0) << \"failed to decrypt challenge (\" << challenge.length() << \" bytes): \"\n\t\t    << error << dendl;\n      return false;\n    }\n    msg.have_challenge = true;\n    msg.server_challenge_plus_one = ch.server_challenge + 1;\n  }\n\n  std::string error;\n  if (encode_encrypt(cct, msg, session_key, bl, error)) {\n    ldout(cct, 0) << __func__ << \" failed to encrypt authorizer: \" << error << dendl;\n    return false;\n  }\n  return true;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_CEPHXPROTOCOL_H\n#define CEPH_CEPHXPROTOCOL_H\n\n/*\n  Ceph X protocol\n\n  First, the principal has to authenticate with the authenticator. A\n  shared-secret mechanism is being used, and the negotitaion goes like this:\n\n  A = Authenticator\n  P = Principle\n  S = Service\n\n  1. Obtaining principal/auth session key\n\n  (Authenticate Request)\n  p->a : principal, principal_addr.  authenticate me!\n\n ...authenticator does lookup in database...\n\n  a->p : A= {principal/auth session key, validity}^principal_secret (*)\n         B= {principal ticket, validity, principal/auth session key}^authsecret\n\n  \n  [principal/auth session key, validity] = service ticket\n  [principal ticket, validity, principal/auth session key] = service ticket info\n\n  (*) annotation: ^ signifies 'encrypted by'\n\n  At this point, if is genuine, the principal should have the principal/auth\n  session key at hand. The next step would be to request an authorization to\n  use some other service:\n\n  2. Obtaining principal/service session key\n\n  p->a : B, {principal_addr, timestamp}^principal/auth session key.  authorize\n         me!\n  a->p : E= {service ticket}^svcsecret\n         F= {principal/service session key, validity}^principal/auth session key\n\n  principal_addr, timestamp = authenticator\n\n  service ticket = principal name, client network address, validity, principal/service session key\n\n  Note that steps 1 and 2 are pretty much the same thing; contacting the\n  authenticator and requesting for a key.\n\n  Following this the principal should have a principal/service session key that\n  could be used later on for creating a session:\n\n  3. Opening a session to a service\n\n  p->s : E + {principal_addr, timestamp}^principal/service session key\n  s->p : {timestamp+1}^principal/service/session key\n\n  timestamp+1 = reply authenticator\n\n  Now, the principal is fully authenticated with the service. So, logically we\n  have 2 main actions here. The first one would be to obtain a session key to\n  the service (steps 1 and 2), and the second one would be to authenticate with\n  the service, using that ticket.\n*/\n\n/* authenticate requests */\n#define CEPHX_GET_AUTH_SESSION_KEY      0x0100\n#define CEPHX_GET_PRINCIPAL_SESSION_KEY 0x0200\n#define CEPHX_GET_ROTATING_KEY          0x0400\n\n#define CEPHX_REQUEST_TYPE_MASK            0x0F00\n#define CEPHX_CRYPT_ERR\t\t\t1\n\n#include \"auth/Auth.h\"\n#include <errno.h>\n#include <sstream>\n\nclass CephContext;\n\n/*\n * Authentication\n */\n\n// initial server -> client challenge\nstruct CephXServerChallenge {\n  uint64_t server_challenge;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(server_challenge, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(server_challenge, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXServerChallenge)\n\n\n// request/reply headers, for subsequent exchanges.\n\nstruct CephXRequestHeader {\n  __u16 request_type;\n\n  void encode(bufferlist& bl) const {\n    ::encode(request_type, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    ::decode(request_type, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXRequestHeader)\n\nstruct CephXResponseHeader {\n  uint16_t request_type;\n  int32_t status;\n\n  void encode(bufferlist& bl) const {\n    ::encode(request_type, bl);\n    ::encode(status, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    ::decode(request_type, bl);\n    ::decode(status, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXResponseHeader)\n\nstruct CephXTicketBlob {\n  uint64_t secret_id;\n  bufferlist blob;\n\n  CephXTicketBlob() : secret_id(0) {}\n\n  void encode(bufferlist& bl) const {\n     __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(secret_id, bl);\n    ::encode(blob, bl);\n  }\n\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(secret_id, bl);\n    ::decode(blob, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXTicketBlob)\n\n// client -> server response to challenge\nstruct CephXAuthenticate {\n  uint64_t client_challenge;\n  uint64_t key;\n  CephXTicketBlob old_ticket;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(client_challenge, bl);\n    ::encode(key, bl);\n    ::encode(old_ticket, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(client_challenge, bl);\n    ::decode(key, bl);\n    ::decode(old_ticket, bl);\n }\n};\nWRITE_CLASS_ENCODER(CephXAuthenticate)\n\nstruct CephXChallengeBlob {\n  uint64_t server_challenge, client_challenge;\n  \n  void encode(bufferlist& bl) const {\n    ::encode(server_challenge, bl);\n    ::encode(client_challenge, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    ::decode(server_challenge, bl);\n    ::decode(client_challenge, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXChallengeBlob)\n\nvoid cephx_calc_client_server_challenge(CephContext *cct, \n\t\t\t\t\tCryptoKey& secret, uint64_t server_challenge, uint64_t client_challenge,\n\t\t\t\t\tuint64_t *key, std::string &error);\n\n\n/*\n * getting service tickets\n */\nstruct CephXSessionAuthInfo {\n  uint32_t service_id;\n  uint64_t secret_id;\n  AuthTicket ticket;\n  CryptoKey session_key;\n  CryptoKey service_secret;\n  utime_t validity;\n};\n\n\nextern bool cephx_build_service_ticket_blob(CephContext *cct,\n\t\t\t\t\t    CephXSessionAuthInfo& ticket_info, CephXTicketBlob& blob);\n\nextern void cephx_build_service_ticket_request(CephContext *cct, \n\t\t\t\t\t       uint32_t keys,\n\t\t\t\t\t       bufferlist& request);\n\nextern bool cephx_build_service_ticket_reply(CephContext *cct,\n\t\t\t\t\t     CryptoKey& principal_secret,\n\t\t\t\t\t     vector<CephXSessionAuthInfo> ticket_info,\n                                             bool should_encrypt_ticket,\n                                             CryptoKey& ticket_enc_key,\n\t\t\t\t\t     bufferlist& reply);\n\nstruct CephXServiceTicketRequest {\n  uint32_t keys;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(keys, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(keys, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXServiceTicketRequest)\n\n\n/*\n * Authorize\n */\n\nstruct CephXAuthorizeReply {\n  uint64_t nonce_plus_one;\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(nonce_plus_one, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(nonce_plus_one, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXAuthorizeReply)\n\n\nstruct CephXAuthorizer : public AuthAuthorizer {\nprivate:\n  CephContext *cct;\npublic:\n  uint64_t nonce;\n  bufferlist base_bl;\n\n  explicit CephXAuthorizer(CephContext *cct_)\n    : AuthAuthorizer(CEPH_AUTH_CEPHX), cct(cct_), nonce(0) {}\n\n  bool build_authorizer();\n  bool verify_reply(bufferlist::iterator& reply) override;\n  bool add_challenge(CephContext *cct, bufferlist& challenge) override;\n};\n\n\n\n/*\n * TicketHandler\n */\nstruct CephXTicketHandler {\n  uint32_t service_id;\n  CryptoKey session_key;\n  CephXTicketBlob ticket;        // opaque to us\n  utime_t renew_after, expires;\n  bool have_key_flag;\n\n  CephXTicketHandler(CephContext *cct_, uint32_t service_id_)\n    : service_id(service_id_), have_key_flag(false), cct(cct_) { }\n\n  // to build our ServiceTicket\n  bool verify_service_ticket_reply(CryptoKey& principal_secret,\n\t\t\t\t bufferlist::iterator& indata);\n  // to access the service\n  CephXAuthorizer *build_authorizer(uint64_t global_id) const;\n\n  bool have_key();\n  bool need_key() const;\n\n  void invalidate_ticket() {\n    have_key_flag = 0;\n  }\nprivate:\n  CephContext *cct;\n};\n\nstruct CephXTicketManager {\n  typedef map<uint32_t, CephXTicketHandler> tickets_map_t;\n  tickets_map_t tickets_map;\n  uint64_t global_id;\n\n  explicit CephXTicketManager(CephContext *cct_) : global_id(0), cct(cct_) {}\n\n  bool verify_service_ticket_reply(CryptoKey& principal_secret,\n\t\t\t\t bufferlist::iterator& indata);\n\n  CephXTicketHandler& get_handler(uint32_t type) {\n    tickets_map_t::iterator i = tickets_map.find(type);\n    if (i != tickets_map.end())\n      return i->second;\n    CephXTicketHandler newTicketHandler(cct, type);\n    std::pair < tickets_map_t::iterator, bool > res =\n\ttickets_map.insert(std::make_pair(type, newTicketHandler));\n    assert(res.second);\n    return res.first->second;\n  }\n  CephXAuthorizer *build_authorizer(uint32_t service_id) const;\n  bool have_key(uint32_t service_id);\n  bool need_key(uint32_t service_id) const;\n  void set_have_need_key(uint32_t service_id, uint32_t& have, uint32_t& need);\n  void validate_tickets(uint32_t mask, uint32_t& have, uint32_t& need);\n  void invalidate_ticket(uint32_t service_id);\n\nprivate:\n  CephContext *cct;\n};\n\n\n/* A */\nstruct CephXServiceTicket {\n  CryptoKey session_key;\n  utime_t validity;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(session_key, bl);\n    ::encode(validity, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(session_key, bl);\n    ::decode(validity, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXServiceTicket)\n\n/* B */\nstruct CephXServiceTicketInfo {\n  AuthTicket ticket;\n  CryptoKey session_key;\n\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(ticket, bl);\n    ::encode(session_key, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(ticket, bl);\n    ::decode(session_key, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXServiceTicketInfo)\n\nstruct CephXAuthorizeChallenge : public AuthAuthorizerChallenge {\n  uint64_t server_challenge;\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(server_challenge, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(server_challenge, bl);\n  }\n};\nWRITE_CLASS_ENCODER(CephXAuthorizeChallenge)\n\nstruct CephXAuthorize {\n  uint64_t nonce;\n  bool have_challenge = false;\n  uint64_t server_challenge_plus_one = 0;\n  void encode(bufferlist& bl) const {\n    __u8 struct_v = 2;\n    ::encode(struct_v, bl);\n    ::encode(nonce, bl);\n    ::encode(have_challenge, bl);\n    ::encode(server_challenge_plus_one, bl);\n  }\n  void decode(bufferlist::iterator& bl) {\n    __u8 struct_v;\n    ::decode(struct_v, bl);\n    ::decode(nonce, bl);\n    if (struct_v >= 2) {\n      ::decode(have_challenge, bl);\n      ::decode(server_challenge_plus_one, bl);\n    }\n\n  }\n};\nWRITE_CLASS_ENCODER(CephXAuthorize)\n\n/*\n * Decode an extract ticket\n */\nbool cephx_decode_ticket(CephContext *cct, KeyStore *keys,\n\t\t\t uint32_t service_id, CephXTicketBlob& ticket_blob,\n\t\t\t CephXServiceTicketInfo& ticket_info);\n\n/*\n * Verify authorizer and generate reply authorizer\n */\nextern bool cephx_verify_authorizer(\n  CephContext *cct, KeyStore *keys,\n  bufferlist::iterator& indata,\n  CephXServiceTicketInfo& ticket_info,\n  std::unique_ptr<AuthAuthorizerChallenge> *challenge,\n  bufferlist& reply_bl);\n\n\n\n\n\n\n/*\n * encode+encrypt macros\n */\nstatic constexpr uint64_t AUTH_ENC_MAGIC = 0xff009cad8826aa55ull;\n\ntemplate <typename T>\nvoid decode_decrypt_enc_bl(CephContext *cct, T& t, CryptoKey key, bufferlist& bl_enc, \n\t\t\t   std::string &error)\n{\n  uint64_t magic;\n  bufferlist bl;\n\n  if (key.decrypt(cct, bl_enc, bl, &error) < 0)\n    return;\n\n  bufferlist::iterator iter2 = bl.begin();\n  __u8 struct_v;\n  ::decode(struct_v, iter2);\n  ::decode(magic, iter2);\n  if (magic != AUTH_ENC_MAGIC) {\n    ostringstream oss;\n    oss << \"bad magic in decode_decrypt, \" << magic << \" != \" << AUTH_ENC_MAGIC;\n    error = oss.str();\n    return;\n  }\n\n  ::decode(t, iter2);\n}\n\ntemplate <typename T>\nvoid encode_encrypt_enc_bl(CephContext *cct, const T& t, const CryptoKey& key,\n\t\t\t   bufferlist& out, std::string &error)\n{\n  bufferlist bl;\n  __u8 struct_v = 1;\n  ::encode(struct_v, bl);\n  uint64_t magic = AUTH_ENC_MAGIC;\n  ::encode(magic, bl);\n  ::encode(t, bl);\n\n  key.encrypt(cct, bl, out, &error);\n}\n\ntemplate <typename T>\nint decode_decrypt(CephContext *cct, T& t, const CryptoKey& key,\n\t\t    bufferlist::iterator& iter, std::string &error)\n{\n  bufferlist bl_enc;\n  try {\n    ::decode(bl_enc, iter);\n    decode_decrypt_enc_bl(cct, t, key, bl_enc, error);\n  }\n  catch (buffer::error &e) {\n    error = \"error decoding block for decryption\";\n  }\n  if (!error.empty())\n    return CEPHX_CRYPT_ERR;\n  return 0;\n}\n\ntemplate <typename T>\nint encode_encrypt(CephContext *cct, const T& t, const CryptoKey& key,\n\t\t    bufferlist& out, std::string &error)\n{\n  bufferlist bl_enc;\n  encode_encrypt_enc_bl(cct, t, key, bl_enc, error);\n  if (!error.empty()){\n    return CEPHX_CRYPT_ERR;\n  }\n  ::encode(bl_enc, out);\n  return 0;\n}\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n\n#include \"CephxServiceHandler.h\"\n#include \"CephxProtocol.h\"\n#include \"CephxKeyServer.h\"\n#include <errno.h>\n#include <sstream>\n\n#include \"common/config.h\"\n#include \"common/debug.h\"\n\n#define dout_subsys ceph_subsys_auth\n#undef dout_prefix\n#define dout_prefix *_dout << \"cephx server \" << entity_name << \": \"\n\nint CephxServiceHandler::start_session(EntityName& name, bufferlist::iterator& indata, bufferlist& result_bl, AuthCapsInfo& caps)\n{\n  entity_name = name;\n\n  get_random_bytes((char *)&server_challenge, sizeof(server_challenge));\n  if (!server_challenge)\n    server_challenge = 1;  // always non-zero.\n  ldout(cct, 10) << \"start_session server_challenge \" << hex << server_challenge << dec << dendl;\n\n  CephXServerChallenge ch;\n  ch.server_challenge = server_challenge;\n  ::encode(ch, result_bl);\n  return CEPH_AUTH_CEPHX;\n}\n\nint CephxServiceHandler::handle_request(bufferlist::iterator& indata, bufferlist& result_bl, uint64_t& global_id, AuthCapsInfo& caps, uint64_t *auid)\n{\n  int ret = 0;\n\n  struct CephXRequestHeader cephx_header;\n  ::decode(cephx_header, indata);\n\n\n  switch (cephx_header.request_type) {\n  case CEPHX_GET_AUTH_SESSION_KEY:\n    {\n      ldout(cct, 10) << \"handle_request get_auth_session_key for \" << entity_name << dendl;\n\n      CephXAuthenticate req;\n      ::decode(req, indata);\n\n      CryptoKey secret;\n      if (!key_server->get_secret(entity_name, secret)) {\n        ldout(cct, 0) << \"couldn't find entity name: \" << entity_name << dendl;\n\tret = -EPERM;\n\tbreak;\n      }\n\n      if (!server_challenge) {\n\tret = -EPERM;\n\tbreak;\n      }      \n\n      uint64_t expected_key;\n      std::string error;\n      cephx_calc_client_server_challenge(cct, secret, server_challenge,\n\t\t\t\t\t req.client_challenge, &expected_key, error);\n      if (!error.empty()) {\n\tldout(cct, 0) << \" cephx_calc_client_server_challenge error: \" << error << dendl;\n\tret = -EPERM;\n\tbreak;\n      }\n\n      ldout(cct, 20) << \" checking key: req.key=\" << hex << req.key\n\t       << \" expected_key=\" << expected_key << dec << dendl;\n      if (req.key != expected_key) {\n        ldout(cct, 0) << \" unexpected key: req.key=\" << hex << req.key\n\t\t<< \" expected_key=\" << expected_key << dec << dendl;\n        ret = -EPERM;\n\tbreak;\n      }\n\n      CryptoKey session_key;\n      CephXSessionAuthInfo info;\n      bool should_enc_ticket = false;\n\n      EntityAuth eauth;\n      if (! key_server->get_auth(entity_name, eauth)) {\n\tret = -EPERM;\n\tbreak;\n      }\n      CephXServiceTicketInfo old_ticket_info;\n\n      if (cephx_decode_ticket(cct, key_server, CEPH_ENTITY_TYPE_AUTH,\n\t\t\t      req.old_ticket, old_ticket_info)) {\n        global_id = old_ticket_info.ticket.global_id;\n        ldout(cct, 10) << \"decoded old_ticket with global_id=\" << global_id << dendl;\n        should_enc_ticket = true;\n      }\n\n      info.ticket.init_timestamps(ceph_clock_now(), cct->_conf->auth_mon_ticket_ttl);\n      info.ticket.name = entity_name;\n      info.ticket.global_id = global_id;\n      info.ticket.auid = eauth.auid;\n      info.validity += cct->_conf->auth_mon_ticket_ttl;\n\n      if (auid) *auid = eauth.auid;\n\n      key_server->generate_secret(session_key);\n\n      info.session_key = session_key;\n      info.service_id = CEPH_ENTITY_TYPE_AUTH;\n      if (!key_server->get_service_secret(CEPH_ENTITY_TYPE_AUTH, info.service_secret, info.secret_id)) {\n        ldout(cct, 0) << \" could not get service secret for auth subsystem\" << dendl;\n        ret = -EIO;\n        break;\n      }\n\n      vector<CephXSessionAuthInfo> info_vec;\n      info_vec.push_back(info);\n\n      build_cephx_response_header(cephx_header.request_type, 0, result_bl);\n      if (!cephx_build_service_ticket_reply(cct, eauth.key, info_vec, should_enc_ticket,\n\t\t\t\t\t    old_ticket_info.session_key, result_bl)) {\n\tret = -EIO;\n      }\n\n      if (!key_server->get_service_caps(entity_name, CEPH_ENTITY_TYPE_MON, caps)) {\n        ldout(cct, 0) << \" could not get mon caps for \" << entity_name << dendl;\n        ret = -EACCES;\n      } else {\n        char *caps_str = caps.caps.c_str();\n        if (!caps_str || !caps_str[0]) {\n          ldout(cct,0) << \"mon caps null for \" << entity_name << dendl;\n          ret = -EACCES;\n        }\n      }\n    }\n    break;\n\n  case CEPHX_GET_PRINCIPAL_SESSION_KEY:\n    {\n      ldout(cct, 10) << \"handle_request get_principal_session_key\" << dendl;\n\n      bufferlist tmp_bl;\n      CephXServiceTicketInfo auth_ticket_info;\n      // note: no challenge here.\n      if (!cephx_verify_authorizer(cct, key_server, indata, auth_ticket_info, nullptr,\n\t\t\t\t   tmp_bl)) {\n        ret = -EPERM;\n\tbreak;\n      }\n\n      CephXServiceTicketRequest ticket_req;\n      ::decode(ticket_req, indata);\n      ldout(cct, 10) << \" ticket_req.keys = \" << ticket_req.keys << dendl;\n\n      ret = 0;\n      vector<CephXSessionAuthInfo> info_vec;\n      int found_services = 0;\n      int service_err = 0;\n      for (uint32_t service_id = 1; service_id <= ticket_req.keys;\n\t   service_id <<= 1) {\n        if (ticket_req.keys & service_id) {\n\t  ldout(cct, 10) << \" adding key for service \"\n\t\t\t << ceph_entity_type_name(service_id) << dendl;\n          CephXSessionAuthInfo info;\n          int r = key_server->build_session_auth_info(service_id,\n\t\t\t\t\t\t      auth_ticket_info, info);\n\t  // tolerate missing MGR rotating key for the purposes of upgrades.\n          if (r < 0) {\n\t    ldout(cct, 10) << \"   missing key for service \"\n\t\t\t   << ceph_entity_type_name(service_id) << dendl;\n\t    service_err = r;\n\t    continue;\n\t  }\n          info.validity += cct->_conf->auth_service_ticket_ttl;\n          info_vec.push_back(info);\n\t  ++found_services;\n        }\n      }\n      if (!found_services && service_err) {\n\tldout(cct, 10) << __func__ << \" did not find any service keys\" << dendl;\n\tret = service_err;\n      }\n      CryptoKey no_key;\n      build_cephx_response_header(cephx_header.request_type, ret, result_bl);\n      cephx_build_service_ticket_reply(cct, auth_ticket_info.session_key, info_vec, false, no_key, result_bl);\n    }\n    break;\n\n  case CEPHX_GET_ROTATING_KEY:\n    {\n      ldout(cct, 10) << \"handle_request getting rotating secret for \" << entity_name << dendl;\n      build_cephx_response_header(cephx_header.request_type, 0, result_bl);\n      if (!key_server->get_rotating_encrypted(entity_name, result_bl)) {\n        ret = -EPERM;\n        break;\n      }\n    }\n    break;\n\n  default:\n    ldout(cct, 10) << \"handle_request unknown op \" << cephx_header.request_type << dendl;\n    return -EINVAL;\n  }\n  return ret;\n}\n\nvoid CephxServiceHandler::build_cephx_response_header(int request_type, int status, bufferlist& bl)\n{\n  struct CephXResponseHeader header;\n  header.request_type = request_type;\n  header.status = status;\n  ::encode(header, bl);\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2009-2011 New Dream Network\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include \"AuthNoneAuthorizeHandler.h\"\n#include \"common/debug.h\"\n\n#define dout_subsys ceph_subsys_auth\n\nbool AuthNoneAuthorizeHandler::verify_authorizer(\n  CephContext *cct, KeyStore *keys,\n  bufferlist& authorizer_data, bufferlist& authorizer_reply,\n  EntityName& entity_name, uint64_t& global_id, AuthCapsInfo& caps_info,\n  CryptoKey& session_key,\n  uint64_t *auid,\n  std::unique_ptr<AuthAuthorizerChallenge> *challenge)\n{\n  bufferlist::iterator iter = authorizer_data.begin();\n\n  try {\n    __u8 struct_v = 1;\n    ::decode(struct_v, iter);\n    ::decode(entity_name, iter);\n    ::decode(global_id, iter);\n  } catch (const buffer::error &err) {\n    ldout(cct, 0) << \"AuthNoneAuthorizeHandle::verify_authorizer() failed to decode\" << dendl;\n    return false;\n  }\n\n  caps_info.allow_all = true;\n\n  return true;\n}\n\n// Return type of crypto used for this session's data;  for none, no crypt used\n\nint AuthNoneAuthorizeHandler::authorizer_session_crypto() \n{\n  return SESSION_CRYPTO_NONE;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_AUTHNONEAUTHORIZEHANDLER_H\n#define CEPH_AUTHNONEAUTHORIZEHANDLER_H\n\n#include \"auth/AuthAuthorizeHandler.h\"\n\nclass CephContext;\n\nstruct AuthNoneAuthorizeHandler : public AuthAuthorizeHandler {\n  bool verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t bufferlist& authorizer_data, bufferlist& authorizer_reply,\n                         EntityName& entity_name, uint64_t& global_id,\n\t\t\t AuthCapsInfo& caps_info, CryptoKey& session_key, uint64_t *auid,\n\t\t\t std::unique_ptr<AuthAuthorizerChallenge> *challenge) override;\n  int authorizer_session_crypto() override;\n};\n\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_AUTHNONEPROTOCOL_H\n#define CEPH_AUTHNONEPROTOCOL_H\n\n#include \"auth/Auth.h\"\n\nclass CephContext;\n\nstruct AuthNoneAuthorizer : public AuthAuthorizer {\n  AuthNoneAuthorizer() : AuthAuthorizer(CEPH_AUTH_NONE) { }\n  bool build_authorizer(const EntityName &ename, uint64_t global_id) {\n    __u8 struct_v = 1;\n    ::encode(struct_v, bl);\n    ::encode(ename, bl);\n    ::encode(global_id, bl);\n    return 0;\n  }\n  bool verify_reply(bufferlist::iterator& reply) override { return true; }\n  bool add_challenge(CephContext *cct, bufferlist& ch) override { return true; }\n};\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2009-2011 New Dream Network\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include \"AuthUnknownAuthorizeHandler.h\"\n\nbool AuthUnknownAuthorizeHandler::verify_authorizer(\n  CephContext *cct, KeyStore *keys,\n  bufferlist& authorizer_data, bufferlist& authorizer_reply,\n  EntityName& entity_name, uint64_t& global_id, AuthCapsInfo& caps_info,\n  CryptoKey& session_key,\n  uint64_t *auid,\n  std::unique_ptr<AuthAuthorizerChallenge> *challenge)\n{\n  // For unknown authorizers, there's nothing to verify.  They're \"OK\" by definition.  PLR\n\n  return true;\n}\n\n// Return type of crypto used for this session's data;  for unknown, no crypt used\n\nint AuthUnknownAuthorizeHandler::authorizer_session_crypto() \n{\n  return SESSION_CRYPTO_NONE;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2009 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_AUTHUNKNOWNAUTHORIZEHANDLER_H\n#define CEPH_AUTHUNKNOWNAUTHORIZEHANDLER_H\n\n#include \"auth/AuthAuthorizeHandler.h\"\n\nclass CephContext;\n\nstruct AuthUnknownAuthorizeHandler : public AuthAuthorizeHandler {\n  bool verify_authorizer(CephContext *cct, KeyStore *keys,\n\t\t\t bufferlist& authorizer_data, bufferlist& authorizer_reply,\n                         EntityName& entity_name, uint64_t& global_id,\n\t\t\t AuthCapsInfo& caps_info, CryptoKey& session_key, uint64_t *auid,\n\t\t\t std::unique_ptr<AuthAuthorizerChallenge> *challenge) override;\n  int authorizer_session_crypto() override;\n};\n\n\n\n#endif\n", "#ifndef CEPH_MSGR_H\n#define CEPH_MSGR_H\n\n#ifndef __KERNEL__\n#include <sys/socket.h> // for struct sockaddr_storage\n#endif\n\n#include \"include/int_types.h\"\n\n/*\n * Data types for message passing layer used by Ceph.\n */\n\n#define CEPH_MON_PORT    6789  /* default monitor port */\n\n/*\n * client-side processes will try to bind to ports in this\n * range, simply for the benefit of tools like nmap or wireshark\n * that would like to identify the protocol.\n */\n#define CEPH_PORT_FIRST  6789\n\n/*\n * tcp connection banner.  include a protocol version. and adjust\n * whenever the wire protocol changes.  try to keep this string length\n * constant.\n */\n#define CEPH_BANNER \"ceph v027\"\n\n/*\n * Rollover-safe type and comparator for 32-bit sequence numbers.\n * Comparator returns -1, 0, or 1.\n */\ntypedef __u32 ceph_seq_t;\n\nstatic inline __s32 ceph_seq_cmp(__u32 a, __u32 b)\n{\n       return (__s32)a - (__s32)b;\n}\n\n\n/*\n * entity_name -- logical name for a process participating in the\n * network, e.g. 'mds0' or 'osd3'.\n */\nstruct ceph_entity_name {\n\t__u8 type;      /* CEPH_ENTITY_TYPE_* */\n\t__le64 num;\n} __attribute__ ((packed));\n\n#define CEPH_ENTITY_TYPE_MON    0x01\n#define CEPH_ENTITY_TYPE_MDS    0x02\n#define CEPH_ENTITY_TYPE_OSD    0x04\n#define CEPH_ENTITY_TYPE_CLIENT 0x08\n#define CEPH_ENTITY_TYPE_MGR    0x10\n#define CEPH_ENTITY_TYPE_AUTH   0x20\n\n#define CEPH_ENTITY_TYPE_ANY    0xFF\n\nextern const char *ceph_entity_type_name(int type);\n\n/*\n * entity_addr -- network address\n */\nstruct ceph_entity_addr {\n\t__le32 type;\n\t__le32 nonce;  /* unique id for process (e.g. pid) */\n\tstruct sockaddr_storage in_addr;\n} __attribute__ ((packed));\n\nstruct ceph_entity_inst {\n\tstruct ceph_entity_name name;\n\tstruct ceph_entity_addr addr;\n} __attribute__ ((packed));\n\n\n/* used by message exchange protocol */\n#define CEPH_MSGR_TAG_READY         1  /* server->client: ready for messages */\n#define CEPH_MSGR_TAG_RESETSESSION  2  /* server->client: reset, try again */\n#define CEPH_MSGR_TAG_WAIT          3  /* server->client: wait for racing\n\t\t\t\t\t  incoming connection */\n#define CEPH_MSGR_TAG_RETRY_SESSION 4  /* server->client + cseq: try again\n\t\t\t\t\t  with higher cseq */\n#define CEPH_MSGR_TAG_RETRY_GLOBAL  5  /* server->client + gseq: try again\n\t\t\t\t\t  with higher gseq */\n#define CEPH_MSGR_TAG_CLOSE         6  /* closing pipe */\n#define CEPH_MSGR_TAG_MSG           7  /* message */\n#define CEPH_MSGR_TAG_ACK           8  /* message ack */\n#define CEPH_MSGR_TAG_KEEPALIVE     9  /* just a keepalive byte! */\n#define CEPH_MSGR_TAG_BADPROTOVER  10  /* bad protocol version */\n#define CEPH_MSGR_TAG_BADAUTHORIZER 11 /* bad authorizer */\n#define CEPH_MSGR_TAG_FEATURES      12 /* insufficient features */\n#define CEPH_MSGR_TAG_SEQ           13 /* 64-bit int follows with seen seq number */\n#define CEPH_MSGR_TAG_KEEPALIVE2     14\n#define CEPH_MSGR_TAG_KEEPALIVE2_ACK 15  /* keepalive reply */\n#define CEPH_MSGR_TAG_CHALLENGE_AUTHORIZER 16  /* ceph v2 doing server challenge */\n\n/*\n * connection negotiation\n */\nstruct ceph_msg_connect {\n\t__le64 features;     /* supported feature bits */\n\t__le32 host_type;    /* CEPH_ENTITY_TYPE_* */\n\t__le32 global_seq;   /* count connections initiated by this host */\n\t__le32 connect_seq;  /* count connections initiated in this session */\n\t__le32 protocol_version;\n\t__le32 authorizer_protocol;\n\t__le32 authorizer_len;\n\t__u8  flags;         /* CEPH_MSG_CONNECT_* */\n} __attribute__ ((packed));\n\nstruct ceph_msg_connect_reply {\n\t__u8 tag;\n\t__le64 features;     /* feature bits for this session */\n\t__le32 global_seq;\n\t__le32 connect_seq;\n\t__le32 protocol_version;\n\t__le32 authorizer_len;\n\t__u8 flags;\n} __attribute__ ((packed));\n\n#define CEPH_MSG_CONNECT_LOSSY  1  /* messages i send may be safely dropped */\n\n\n/*\n * message header\n */\nstruct ceph_msg_header_old {\n\t__le64 seq;       /* message seq# for this session */\n\t__le64 tid;       /* transaction id */\n\t__le16 type;      /* message type */\n\t__le16 priority;  /* priority.  higher value == higher priority */\n\t__le16 version;   /* version of message encoding */\n\n\t__le32 front_len; /* bytes in main payload */\n\t__le32 middle_len;/* bytes in middle payload */\n\t__le32 data_len;  /* bytes of data payload */\n\t__le16 data_off;  /* sender: include full offset;\n\t\t\t     receiver: mask against ~PAGE_MASK */\n\n\tstruct ceph_entity_inst src, orig_src;\n\t__le32 reserved;\n\t__le32 crc;       /* header crc32c */\n} __attribute__ ((packed));\n\nstruct ceph_msg_header {\n\t__le64 seq;       /* message seq# for this session */\n\t__le64 tid;       /* transaction id */\n\t__le16 type;      /* message type */\n\t__le16 priority;  /* priority.  higher value == higher priority */\n\t__le16 version;   /* version of message encoding */\n\n\t__le32 front_len; /* bytes in main payload */\n\t__le32 middle_len;/* bytes in middle payload */\n\t__le32 data_len;  /* bytes of data payload */\n\t__le16 data_off;  /* sender: include full offset;\n\t\t\t     receiver: mask against ~PAGE_MASK */\n\n\tstruct ceph_entity_name src;\n\n\t/* oldest code we think can decode this.  unknown if zero. */\n\t__le16 compat_version;\n\t__le16 reserved;\n\t__le32 crc;       /* header crc32c */\n} __attribute__ ((packed));\n\n#define CEPH_MSG_PRIO_LOW     64\n#define CEPH_MSG_PRIO_DEFAULT 127\n#define CEPH_MSG_PRIO_HIGH    196\n#define CEPH_MSG_PRIO_HIGHEST 255\n\n/*\n * follows data payload\n * ceph_msg_footer_old does not support digital signatures on messages PLR\n */\n\nstruct ceph_msg_footer_old {\n\t__le32 front_crc, middle_crc, data_crc;\n\t__u8 flags;\n} __attribute__ ((packed));\n\nstruct ceph_msg_footer {\n\t__le32 front_crc, middle_crc, data_crc;\n\t// sig holds the 64 bits of the digital signature for the message PLR\n\t__le64  sig;\n\t__u8 flags;\n} __attribute__ ((packed));\n\n#define CEPH_MSG_FOOTER_COMPLETE  (1<<0)   /* msg wasn't aborted */\n#define CEPH_MSG_FOOTER_NOCRC     (1<<1)   /* no data crc */\n#define CEPH_MSG_FOOTER_SIGNED\t  (1<<2)   /* msg was signed */\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include <unistd.h>\n\n#include \"include/compat.h\"\n#include \"include/types.h\"\n#include \"include/str_list.h\"\n\n#include \"common/Clock.h\"\n#include \"common/HeartbeatMap.h\"\n#include \"common/Timer.h\"\n#include \"common/backport14.h\"\n#include \"common/ceph_argparse.h\"\n#include \"common/config.h\"\n#include \"common/entity_name.h\"\n#include \"common/errno.h\"\n#include \"common/perf_counters.h\"\n#include \"common/signal.h\"\n#include \"common/version.h\"\n\n#include \"global/signal_handler.h\"\n\n#include \"msg/Messenger.h\"\n#include \"mon/MonClient.h\"\n\n#include \"osdc/Objecter.h\"\n\n#include \"MDSMap.h\"\n\n#include \"MDSDaemon.h\"\n#include \"Server.h\"\n#include \"Locker.h\"\n\n#include \"SnapServer.h\"\n#include \"SnapClient.h\"\n\n#include \"events/ESession.h\"\n#include \"events/ESubtreeMap.h\"\n\n#include \"messages/MMDSMap.h\"\n\n#include \"messages/MGenericMessage.h\"\n\n#include \"messages/MMonCommand.h\"\n#include \"messages/MCommand.h\"\n#include \"messages/MCommandReply.h\"\n\n#include \"auth/AuthAuthorizeHandler.h\"\n#include \"auth/RotatingKeyRing.h\"\n#include \"auth/KeyRing.h\"\n\n#include \"perfglue/cpu_profiler.h\"\n#include \"perfglue/heap_profiler.h\"\n\n#define dout_context g_ceph_context\n#define dout_subsys ceph_subsys_mds\n#undef dout_prefix\n#define dout_prefix *_dout << \"mds.\" << name << ' '\n\n// cons/des\nMDSDaemon::MDSDaemon(boost::string_view n, Messenger *m, MonClient *mc) :\n  Dispatcher(m->cct),\n  mds_lock(\"MDSDaemon::mds_lock\"),\n  stopping(false),\n  timer(m->cct, mds_lock),\n  beacon(m->cct, mc, n),\n  authorize_handler_cluster_registry(new AuthAuthorizeHandlerRegistry(m->cct,\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_supported.empty() ?\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_cluster_required :\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_supported)),\n  authorize_handler_service_registry(new AuthAuthorizeHandlerRegistry(m->cct,\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_supported.empty() ?\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_service_required :\n\t\t\t\t\t\t\t\t      m->cct->_conf->auth_supported)),\n  name(n),\n  messenger(m),\n  monc(mc),\n  mgrc(m->cct, m),\n  log_client(m->cct, messenger, &mc->monmap, LogClient::NO_FLAGS),\n  mds_rank(NULL),\n  asok_hook(NULL),\n  starttime(mono_clock::now())\n{\n  orig_argc = 0;\n  orig_argv = NULL;\n\n  clog = log_client.create_channel();\n\n  monc->set_messenger(messenger);\n\n  mdsmap = new MDSMap;\n}\n\nMDSDaemon::~MDSDaemon() {\n  Mutex::Locker lock(mds_lock);\n\n  delete mds_rank;\n  mds_rank = NULL;\n  delete mdsmap;\n  mdsmap = NULL;\n\n  delete authorize_handler_service_registry;\n  delete authorize_handler_cluster_registry;\n}\n\nclass MDSSocketHook : public AdminSocketHook {\n  MDSDaemon *mds;\npublic:\n  explicit MDSSocketHook(MDSDaemon *m) : mds(m) {}\n  bool call(std::string command, cmdmap_t& cmdmap, std::string format,\n\t    bufferlist& out) override {\n    stringstream ss;\n    bool r = mds->asok_command(command, cmdmap, format, ss);\n    out.append(ss);\n    return r;\n  }\n};\n\nbool MDSDaemon::asok_command(string command, cmdmap_t& cmdmap, string format,\n\t\t    ostream& ss)\n{\n  dout(1) << \"asok_command: \" << command << \" (starting...)\" << dendl;\n\n  Formatter *f = Formatter::create(format, \"json-pretty\", \"json-pretty\");\n  bool handled = false;\n  if (command == \"status\") {\n    dump_status(f);\n    handled = true;\n  } else {\n    if (mds_rank == NULL) {\n      dout(1) << \"Can't run that command on an inactive MDS!\" << dendl;\n      f->dump_string(\"error\", \"mds_not_active\");\n    } else {\n      handled = mds_rank->handle_asok_command(command, cmdmap, f, ss);\n    }\n  }\n  f->flush(ss);\n  delete f;\n\n  dout(1) << \"asok_command: \" << command << \" (complete)\" << dendl;\n\n  return handled;\n}\n\nvoid MDSDaemon::dump_status(Formatter *f)\n{\n  f->open_object_section(\"status\");\n  f->dump_stream(\"cluster_fsid\") << monc->get_fsid();\n  if (mds_rank) {\n    f->dump_int(\"whoami\", mds_rank->get_nodeid());\n  } else {\n    f->dump_int(\"whoami\", MDS_RANK_NONE);\n  }\n\n  f->dump_int(\"id\", monc->get_global_id());\n  f->dump_string(\"want_state\", ceph_mds_state_name(beacon.get_want_state()));\n  f->dump_string(\"state\", ceph_mds_state_name(mdsmap->get_state_gid(mds_gid_t(\n\t    monc->get_global_id()))));\n  if (mds_rank) {\n    Mutex::Locker l(mds_lock);\n    mds_rank->dump_status(f);\n  }\n\n  f->dump_unsigned(\"mdsmap_epoch\", mdsmap->get_epoch());\n  if (mds_rank) {\n    f->dump_unsigned(\"osdmap_epoch\", mds_rank->get_osd_epoch());\n    f->dump_unsigned(\"osdmap_epoch_barrier\", mds_rank->get_osd_epoch_barrier());\n  } else {\n    f->dump_unsigned(\"osdmap_epoch\", 0);\n    f->dump_unsigned(\"osdmap_epoch_barrier\", 0);\n  }\n\n  f->dump_float(\"uptime\", get_uptime().count());\n\n  f->close_section(); // status\n}\n\nvoid MDSDaemon::set_up_admin_socket()\n{\n  int r;\n  AdminSocket *admin_socket = g_ceph_context->get_admin_socket();\n  assert(asok_hook == nullptr);\n  asok_hook = new MDSSocketHook(this);\n  r = admin_socket->register_command(\"status\", \"status\", asok_hook,\n\t\t\t\t     \"high-level status of MDS\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_ops_in_flight\",\n\t\t\t\t     \"dump_ops_in_flight\", asok_hook,\n\t\t\t\t     \"show the ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"ops\",\n\t\t\t\t     \"ops\", asok_hook,\n\t\t\t\t     \"show the ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_blocked_ops\", \"dump_blocked_ops\",\n      asok_hook,\n      \"show the blocked ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_historic_ops\", \"dump_historic_ops\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show slowest recent ops\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_historic_ops_by_duration\", \"dump_historic_ops_by_duration\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show slowest recent ops, sorted by op duration\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"scrub_path\",\n\t\t\t\t     \"scrub_path name=path,type=CephString \"\n\t\t\t\t     \"name=scrubops,type=CephChoices,\"\n\t\t\t\t     \"strings=force|recursive|repair,n=N,req=false\",\n                                     asok_hook,\n                                     \"scrub an inode and output results\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"tag path\",\n                                     \"tag path name=path,type=CephString\"\n                                     \" name=tag,type=CephString\",\n                                     asok_hook,\n                                     \"Apply scrub tag recursively\");\n   assert(r == 0);\n  r = admin_socket->register_command(\"flush_path\",\n                                     \"flush_path name=path,type=CephString\",\n                                     asok_hook,\n                                     \"flush an inode (and its dirfrags)\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"export dir\",\n                                     \"export dir \"\n                                     \"name=path,type=CephString \"\n                                     \"name=rank,type=CephInt\",\n                                     asok_hook,\n                                     \"migrate a subtree to named MDS\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump cache\",\n                                     \"dump cache name=path,type=CephString,req=false\",\n                                     asok_hook,\n                                     \"dump metadata cache (optionally to a file)\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"cache status\",\n                                     \"cache status\",\n                                     asok_hook,\n                                     \"show cache status\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump tree\",\n\t\t\t\t     \"dump tree \"\n\t\t\t\t     \"name=root,type=CephString,req=true \"\n\t\t\t\t     \"name=depth,type=CephInt,req=false \",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"dump metadata cache for subtree\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"session evict\",\n\t\t\t\t     \"session evict name=client_id,type=CephString\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Evict a CephFS client\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"osdmap barrier\",\n\t\t\t\t     \"osdmap barrier name=target_epoch,type=CephInt\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Wait until the MDS has this OSD map epoch\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"session ls\",\n\t\t\t\t     \"session ls\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Enumerate connected CephFS clients\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"flush journal\",\n\t\t\t\t     \"flush journal\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Flush the journal to the backing store\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"force_readonly\",\n\t\t\t\t     \"force_readonly\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Force MDS to read-only mode\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"get subtrees\",\n\t\t\t\t     \"get subtrees\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Return the subtree map\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dirfrag split\",\n\t\t\t\t     \"dirfrag split \"\n                                     \"name=path,type=CephString,req=true \"\n                                     \"name=frag,type=CephString,req=true \"\n                                     \"name=bits,type=CephInt,req=true \",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Fragment directory by path\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dirfrag merge\",\n\t\t\t\t     \"dirfrag merge \"\n                                     \"name=path,type=CephString,req=true \"\n                                     \"name=frag,type=CephString,req=true\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"De-fragment directory by path\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dirfrag ls\",\n\t\t\t\t     \"dirfrag ls \"\n                                     \"name=path,type=CephString,req=true\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"List fragments in directory\");\n  assert(r == 0);\n}\n\nvoid MDSDaemon::clean_up_admin_socket()\n{\n  AdminSocket *admin_socket = g_ceph_context->get_admin_socket();\n  admin_socket->unregister_command(\"status\");\n  admin_socket->unregister_command(\"dump_ops_in_flight\");\n  admin_socket->unregister_command(\"ops\");\n  admin_socket->unregister_command(\"dump_blocked_ops\");\n  admin_socket->unregister_command(\"dump_historic_ops\");\n  admin_socket->unregister_command(\"dump_historic_ops_by_duration\");\n  admin_socket->unregister_command(\"scrub_path\");\n  admin_socket->unregister_command(\"tag path\");\n  admin_socket->unregister_command(\"flush_path\");\n  admin_socket->unregister_command(\"export dir\");\n  admin_socket->unregister_command(\"dump cache\");\n  admin_socket->unregister_command(\"cache status\");\n  admin_socket->unregister_command(\"dump tree\");\n  admin_socket->unregister_command(\"session evict\");\n  admin_socket->unregister_command(\"osdmap barrier\");\n  admin_socket->unregister_command(\"session ls\");\n  admin_socket->unregister_command(\"flush journal\");\n  admin_socket->unregister_command(\"force_readonly\");\n  admin_socket->unregister_command(\"get subtrees\");\n  admin_socket->unregister_command(\"dirfrag split\");\n  admin_socket->unregister_command(\"dirfrag merge\");\n  admin_socket->unregister_command(\"dirfrag ls\");\n  delete asok_hook;\n  asok_hook = NULL;\n}\n\nconst char** MDSDaemon::get_tracked_conf_keys() const\n{\n  static const char* KEYS[] = {\n    \"mds_op_complaint_time\", \"mds_op_log_threshold\",\n    \"mds_op_history_size\", \"mds_op_history_duration\",\n    \"mds_enable_op_tracker\",\n    \"mds_log_pause\",\n    // clog & admin clog\n    \"clog_to_monitors\",\n    \"clog_to_syslog\",\n    \"clog_to_syslog_facility\",\n    \"clog_to_syslog_level\",\n    // PurgeQueue\n    \"mds_max_purge_ops\",\n    \"mds_max_purge_ops_per_pg\",\n    \"mds_max_purge_files\",\n    \"clog_to_graylog\",\n    \"clog_to_graylog_host\",\n    \"clog_to_graylog_port\",\n    \"host\",\n    \"fsid\",\n    NULL\n  };\n  return KEYS;\n}\n\nvoid MDSDaemon::handle_conf_change(const struct md_config_t *conf,\n\t\t\t     const std::set <std::string> &changed)\n{\n  // We may be called within mds_lock (via `tell`) or outwith the\n  // lock (via admin socket `config set`), so handle either case.\n  const bool initially_locked = mds_lock.is_locked_by_me();\n  if (!initially_locked) {\n    mds_lock.Lock();\n  }\n\n  if (changed.count(\"mds_op_complaint_time\") ||\n      changed.count(\"mds_op_log_threshold\")) {\n    if (mds_rank) {\n      mds_rank->op_tracker.set_complaint_and_threshold(conf->mds_op_complaint_time,\n                                             conf->mds_op_log_threshold);\n    }\n  }\n  if (changed.count(\"mds_op_history_size\") ||\n      changed.count(\"mds_op_history_duration\")) {\n    if (mds_rank) {\n      mds_rank->op_tracker.set_history_size_and_duration(conf->mds_op_history_size,\n                                               conf->mds_op_history_duration);\n    }\n  }\n  if (changed.count(\"mds_enable_op_tracker\")) {\n    if (mds_rank) {\n      mds_rank->op_tracker.set_tracking(conf->mds_enable_op_tracker);\n    }\n  }\n  if (changed.count(\"clog_to_monitors\") ||\n      changed.count(\"clog_to_syslog\") ||\n      changed.count(\"clog_to_syslog_level\") ||\n      changed.count(\"clog_to_syslog_facility\") ||\n      changed.count(\"clog_to_graylog\") ||\n      changed.count(\"clog_to_graylog_host\") ||\n      changed.count(\"clog_to_graylog_port\") ||\n      changed.count(\"host\") ||\n      changed.count(\"fsid\")) {\n    if (mds_rank) {\n      mds_rank->update_log_config();\n    }\n  }\n\n  if (!g_conf->mds_log_pause && changed.count(\"mds_log_pause\")) {\n    if (mds_rank) {\n      mds_rank->mdlog->kick_submitter();\n    }\n  }\n\n  if (mds_rank) {\n    mds_rank->handle_conf_change(conf, changed);\n  }\n\n  if (!initially_locked) {\n    mds_lock.Unlock();\n  }\n}\n\n\nint MDSDaemon::init()\n{\n  dout(10) << sizeof(MDSCacheObject) << \"\\tMDSCacheObject\" << dendl;\n  dout(10) << sizeof(CInode) << \"\\tCInode\" << dendl;\n  dout(10) << sizeof(elist<void*>::item) << \"\\t elist<>::item   *7=\" << 7*sizeof(elist<void*>::item) << dendl;\n  dout(10) << sizeof(CInode::mempool_inode) << \"\\t inode  \" << dendl;\n  dout(10) << sizeof(CInode::mempool_old_inode) << \"\\t old_inode \" << dendl;\n  dout(10) << sizeof(nest_info_t) << \"\\t  nest_info_t \" << dendl;\n  dout(10) << sizeof(frag_info_t) << \"\\t  frag_info_t \" << dendl;\n  dout(10) << sizeof(SimpleLock) << \"\\t SimpleLock   *5=\" << 5*sizeof(SimpleLock) << dendl;\n  dout(10) << sizeof(ScatterLock) << \"\\t ScatterLock  *3=\" << 3*sizeof(ScatterLock) << dendl;\n  dout(10) << sizeof(CDentry) << \"\\tCDentry\" << dendl;\n  dout(10) << sizeof(elist<void*>::item) << \"\\t elist<>::item\" << dendl;\n  dout(10) << sizeof(SimpleLock) << \"\\t SimpleLock\" << dendl;\n  dout(10) << sizeof(CDir) << \"\\tCDir \" << dendl;\n  dout(10) << sizeof(elist<void*>::item) << \"\\t elist<>::item   *2=\" << 2*sizeof(elist<void*>::item) << dendl;\n  dout(10) << sizeof(fnode_t) << \"\\t fnode_t \" << dendl;\n  dout(10) << sizeof(nest_info_t) << \"\\t  nest_info_t *2\" << dendl;\n  dout(10) << sizeof(frag_info_t) << \"\\t  frag_info_t *2\" << dendl;\n  dout(10) << sizeof(Capability) << \"\\tCapability \" << dendl;\n  dout(10) << sizeof(xlist<void*>::item) << \"\\t xlist<>::item   *2=\" << 2*sizeof(xlist<void*>::item) << dendl;\n\n  messenger->add_dispatcher_tail(&beacon);\n  messenger->add_dispatcher_tail(this);\n\n  // get monmap\n  monc->set_messenger(messenger);\n\n  monc->set_want_keys(CEPH_ENTITY_TYPE_MON | CEPH_ENTITY_TYPE_OSD |\n                      CEPH_ENTITY_TYPE_MDS | CEPH_ENTITY_TYPE_MGR);\n  int r = 0;\n  r = monc->init();\n  if (r < 0) {\n    derr << \"ERROR: failed to get monmap: \" << cpp_strerror(-r) << dendl;\n    mds_lock.Lock();\n    suicide();\n    mds_lock.Unlock();\n    return r;\n  }\n\n  // tell monc about log_client so it will know about mon session resets\n  monc->set_log_client(&log_client);\n\n  r = monc->authenticate();\n  if (r < 0) {\n    derr << \"ERROR: failed to authenticate: \" << cpp_strerror(-r) << dendl;\n    mds_lock.Lock();\n    suicide();\n    mds_lock.Unlock();\n    return r;\n  }\n\n  int rotating_auth_attempts = 0;\n  while (monc->wait_auth_rotating(30.0) < 0) {\n    if (++rotating_auth_attempts <= g_conf->max_rotating_auth_attempts) {\n      derr << \"unable to obtain rotating service keys; retrying\" << dendl;\n      continue;\n    }\n    derr << \"ERROR: failed to refresh rotating keys, \"\n         << \"maximum retry time reached.\" << dendl;\n    mds_lock.Lock();\n    suicide();\n    mds_lock.Unlock();\n    return -ETIMEDOUT;\n  }\n\n  mgrc.init();\n  messenger->add_dispatcher_head(&mgrc);\n\n  mds_lock.Lock();\n  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE) {\n    dout(4) << __func__ << \": terminated already, dropping out\" << dendl;\n    mds_lock.Unlock();\n    return 0;\n  }\n\n  monc->sub_want(\"mdsmap\", 0, 0);\n  monc->sub_want(\"mgrmap\", 0, 0);\n  monc->renew_subs();\n\n  mds_lock.Unlock();\n\n  // Set up admin socket before taking mds_lock, so that ordering\n  // is consistent (later we take mds_lock within asok callbacks)\n  set_up_admin_socket();\n  g_conf->add_observer(this);\n  mds_lock.Lock();\n  if (beacon.get_want_state() == MDSMap::STATE_DNE) {\n    suicide();  // we could do something more graceful here\n    dout(4) << __func__ << \": terminated already, dropping out\" << dendl;\n    mds_lock.Unlock();\n    return 0; \n  }\n\n  timer.init();\n\n  beacon.init(mdsmap);\n  messenger->set_myname(entity_name_t::MDS(MDS_RANK_NONE));\n\n  // schedule tick\n  reset_tick();\n  mds_lock.Unlock();\n\n  return 0;\n}\n\nvoid MDSDaemon::reset_tick()\n{\n  // cancel old\n  if (tick_event) timer.cancel_event(tick_event);\n\n  // schedule\n  tick_event = timer.add_event_after(\n    g_conf->mds_tick_interval,\n    new FunctionContext([this](int) {\n\tassert(mds_lock.is_locked_by_me());\n\ttick();\n      }));\n}\n\nvoid MDSDaemon::tick()\n{\n  // reschedule\n  reset_tick();\n\n  // Call through to subsystems' tick functions\n  if (mds_rank) {\n    mds_rank->tick();\n  }\n}\n\nvoid MDSDaemon::send_command_reply(MCommand *m, MDSRank *mds_rank,\n\t\t\t\t   int r, bufferlist outbl,\n\t\t\t\t   boost::string_view outs)\n{\n  Session *session = static_cast<Session *>(m->get_connection()->get_priv());\n  assert(session != NULL);\n  // If someone is using a closed session for sending commands (e.g.\n  // the ceph CLI) then we should feel free to clean up this connection\n  // as soon as we've sent them a response.\n  const bool live_session =\n    session->get_state_seq() > 0 &&\n    mds_rank &&\n    mds_rank->sessionmap.get_session(session->info.inst.name);\n\n  if (!live_session) {\n    // This session only existed to issue commands, so terminate it\n    // as soon as we can.\n    assert(session->is_closed());\n    session->connection->mark_disposable();\n  }\n  session->put();\n\n  MCommandReply *reply = new MCommandReply(r, outs);\n  reply->set_tid(m->get_tid());\n  reply->set_data(outbl);\n  m->get_connection()->send_message(reply);\n}\n\n/* This function DOES put the passed message before returning*/\nvoid MDSDaemon::handle_command(MCommand *m)\n{\n  Session *session = static_cast<Session *>(m->get_connection()->get_priv());\n  assert(session != NULL);\n\n  int r = 0;\n  cmdmap_t cmdmap;\n  std::stringstream ss;\n  std::string outs;\n  bufferlist outbl;\n  Context *run_after = NULL;\n  bool need_reply = true;\n\n  if (!session->auth_caps.allow_all()) {\n    dout(1) << __func__\n      << \": received command from client without `tell` capability: \"\n      << m->get_connection()->peer_addr << dendl;\n\n    ss << \"permission denied\";\n    r = -EPERM;\n  } else if (m->cmd.empty()) {\n    r = -EINVAL;\n    ss << \"no command given\";\n    outs = ss.str();\n  } else if (!cmdmap_from_json(m->cmd, &cmdmap, ss)) {\n    r = -EINVAL;\n    outs = ss.str();\n  } else {\n    r = _handle_command(cmdmap, m, &outbl, &outs, &run_after, &need_reply);\n  }\n  session->put();\n\n  if (need_reply) {\n    send_command_reply(m, mds_rank, r, outbl, outs);\n  }\n\n  if (run_after) {\n    run_after->complete(0);\n  }\n\n  m->put();\n}\n\n\nstruct MDSCommand {\n  string cmdstring;\n  string helpstring;\n  string module;\n  string perm;\n  string availability;\n} mds_commands[] = {\n\n#define COMMAND(parsesig, helptext, module, perm, availability) \\\n  {parsesig, helptext, module, perm, availability},\n\nCOMMAND(\"injectargs \" \\\n\t\"name=injected_args,type=CephString,n=N\",\n\t\"inject configuration arguments into running MDS\",\n\t\"mds\", \"*\", \"cli,rest\")\nCOMMAND(\"config set \" \\\n\t\"name=key,type=CephString name=value,type=CephString\",\n\t\"Set a configuration option at runtime (not persistent)\",\n\t\"mds\", \"*\", \"cli,rest\")\nCOMMAND(\"exit\",\n\t\"Terminate this MDS\",\n\t\"mds\", \"*\", \"cli,rest\")\nCOMMAND(\"respawn\",\n\t\"Restart this MDS\",\n\t\"mds\", \"*\", \"cli,rest\")\nCOMMAND(\"session kill \" \\\n        \"name=session_id,type=CephInt\",\n\t\"End a client session\",\n\t\"mds\", \"*\", \"cli,rest\")\nCOMMAND(\"cpu_profiler \" \\\n\t\"name=arg,type=CephChoices,strings=status|flush\",\n\t\"run cpu profiling on daemon\", \"mds\", \"rw\", \"cli,rest\")\nCOMMAND(\"session ls \" \\\n\t\"name=filters,type=CephString,n=N,req=false\",\n\t\"List client sessions\", \"mds\", \"r\", \"cli,rest\")\nCOMMAND(\"client ls \" \\\n\t\"name=filters,type=CephString,n=N,req=false\",\n\t\"List client sessions\", \"mds\", \"r\", \"cli,rest\")\nCOMMAND(\"session evict \" \\\n\t\"name=filters,type=CephString,n=N,req=false\",\n\t\"Evict client session(s)\", \"mds\", \"rw\", \"cli,rest\")\nCOMMAND(\"client evict \" \\\n\t\"name=filters,type=CephString,n=N,req=false\",\n\t\"Evict client session(s)\", \"mds\", \"rw\", \"cli,rest\")\nCOMMAND(\"damage ls\",\n\t\"List detected metadata damage\", \"mds\", \"r\", \"cli,rest\")\nCOMMAND(\"damage rm name=damage_id,type=CephInt\",\n\t\"Remove a damage table entry\", \"mds\", \"rw\", \"cli,rest\")\nCOMMAND(\"version\", \"report version of MDS\", \"mds\", \"r\", \"cli,rest\")\nCOMMAND(\"heap \" \\\n\t\"name=heapcmd,type=CephChoices,strings=dump|start_profiler|stop_profiler|release|stats\", \\\n\t\"show heap usage info (available only if compiled with tcmalloc)\", \\\n\t\"mds\", \"*\", \"cli,rest\")\n};\n\n\nint MDSDaemon::_handle_command(\n    const cmdmap_t &cmdmap,\n    MCommand *m,\n    bufferlist *outbl,\n    std::string *outs,\n    Context **run_later,\n    bool *need_reply)\n{\n  assert(outbl != NULL);\n  assert(outs != NULL);\n\n  class SuicideLater : public Context\n  {\n    MDSDaemon *mds;\n\n    public:\n    explicit SuicideLater(MDSDaemon *mds_) : mds(mds_) {}\n    void finish(int r) override {\n      // Wait a little to improve chances of caller getting\n      // our response before seeing us disappear from mdsmap\n      sleep(1);\n\n      mds->suicide();\n    }\n  };\n\n\n  class RespawnLater : public Context\n  {\n    MDSDaemon *mds;\n\n    public:\n\n    explicit RespawnLater(MDSDaemon *mds_) : mds(mds_) {}\n    void finish(int r) override {\n      // Wait a little to improve chances of caller getting\n      // our response before seeing us disappear from mdsmap\n      sleep(1);\n\n      mds->respawn();\n    }\n  };\n\n  std::stringstream ds;\n  std::stringstream ss;\n  std::string prefix;\n  std::string format;\n  std::unique_ptr<Formatter> f(Formatter::create(format));\n  cmd_getval(cct, cmdmap, \"prefix\", prefix);\n\n  int r = 0;\n\n  if (prefix == \"get_command_descriptions\") {\n    int cmdnum = 0;\n    std::unique_ptr<JSONFormatter> f(ceph::make_unique<JSONFormatter>());\n    f->open_object_section(\"command_descriptions\");\n    for (MDSCommand *cp = mds_commands;\n\t cp < &mds_commands[ARRAY_SIZE(mds_commands)]; cp++) {\n\n      ostringstream secname;\n      secname << \"cmd\" << setfill('0') << std::setw(3) << cmdnum;\n      dump_cmddesc_to_json(f.get(), secname.str(), cp->cmdstring, cp->helpstring,\n\t\t\t   cp->module, cp->perm, cp->availability, 0);\n      cmdnum++;\n    }\n    f->close_section();\t// command_descriptions\n\n    f->flush(ds);\n    goto out; \n  }\n\n  cmd_getval(cct, cmdmap, \"format\", format);\n  if (prefix == \"version\") {\n    if (f) {\n      f->open_object_section(\"version\");\n      f->dump_string(\"version\", pretty_version_to_str());\n      f->close_section();\n      f->flush(ds);\n    } else {\n      ds << pretty_version_to_str();\n    }\n  } else if (prefix == \"injectargs\") {\n    vector<string> argsvec;\n    cmd_getval(cct, cmdmap, \"injected_args\", argsvec);\n\n    if (argsvec.empty()) {\n      r = -EINVAL;\n      ss << \"ignoring empty injectargs\";\n      goto out;\n    }\n    string args = argsvec.front();\n    for (vector<string>::iterator a = ++argsvec.begin(); a != argsvec.end(); ++a)\n      args += \" \" + *a;\n    r = cct->_conf->injectargs(args, &ss);\n  } else if (prefix == \"config set\") {\n    std::string key;\n    cmd_getval(cct, cmdmap, \"key\", key);\n    std::string val;\n    cmd_getval(cct, cmdmap, \"value\", val);\n    r = cct->_conf->set_val(key, val, true, &ss);\n    if (r == 0) {\n      cct->_conf->apply_changes(nullptr);\n    }\n  } else if (prefix == \"exit\") {\n    // We will send response before executing\n    ss << \"Exiting...\";\n    *run_later = new SuicideLater(this);\n  } else if (prefix == \"respawn\") {\n    // We will send response before executing\n    ss << \"Respawning...\";\n    *run_later = new RespawnLater(this);\n  } else if (prefix == \"session kill\") {\n    if (mds_rank == NULL) {\n      r = -EINVAL;\n      ss << \"MDS not active\";\n      goto out;\n    }\n    // FIXME harmonize `session kill` with admin socket session evict\n    int64_t session_id = 0;\n    bool got = cmd_getval(cct, cmdmap, \"session_id\", session_id);\n    assert(got);\n    bool killed = mds_rank->evict_client(session_id, false,\n                                         g_conf->mds_session_blacklist_on_evict,\n                                         ss);\n    if (!killed)\n      r = -ENOENT;\n  } else if (prefix == \"heap\") {\n    if (!ceph_using_tcmalloc()) {\n      r = -EOPNOTSUPP;\n      ss << \"could not issue heap profiler command -- not using tcmalloc!\";\n    } else {\n      string heapcmd;\n      cmd_getval(cct, cmdmap, \"heapcmd\", heapcmd);\n      vector<string> heapcmd_vec;\n      get_str_vec(heapcmd, heapcmd_vec);\n      ceph_heap_profiler_handle_command(heapcmd_vec, ds);\n    }\n  } else if (prefix == \"cpu_profiler\") {\n    string arg;\n    cmd_getval(cct, cmdmap, \"arg\", arg);\n    vector<string> argvec;\n    get_str_vec(arg, argvec);\n    cpu_profiler_handle_command(argvec, ds);\n  } else {\n    // Give MDSRank a shot at the command\n    if (!mds_rank) {\n      ss << \"MDS not active\";\n      r = -EINVAL;\n    }\n    else {\n      bool handled = mds_rank->handle_command(cmdmap, m, &r, &ds, &ss,\n\t\t\t\t\t      need_reply);\n      if (!handled) {\n        // MDSDaemon doesn't know this command\n        ss << \"unrecognized command! \" << prefix;\n        r = -EINVAL;\n      }\n    }\n  }\n\nout:\n  *outs = ss.str();\n  outbl->append(ds);\n  return r;\n}\n\n/* This function deletes the passed message before returning. */\n\nvoid MDSDaemon::handle_mds_map(MMDSMap *m)\n{\n  version_t epoch = m->get_epoch();\n  dout(5) << \"handle_mds_map epoch \" << epoch << \" from \" << m->get_source() << dendl;\n\n  // is it new?\n  if (epoch <= mdsmap->get_epoch()) {\n    dout(5) << \" old map epoch \" << epoch << \" <= \" << mdsmap->get_epoch()\n\t    << \", discarding\" << dendl;\n    m->put();\n    return;\n  }\n\n  entity_addr_t addr;\n\n  // keep old map, for a moment\n  MDSMap *oldmap = mdsmap;\n\n  // decode and process\n  mdsmap = new MDSMap;\n  mdsmap->decode(m->get_encoded());\n  const MDSMap::DaemonState new_state = mdsmap->get_state_gid(mds_gid_t(monc->get_global_id()));\n  const int incarnation = mdsmap->get_inc_gid(mds_gid_t(monc->get_global_id()));\n\n  monc->sub_got(\"mdsmap\", mdsmap->get_epoch());\n\n  // Calculate my effective rank (either my owned rank or my\n  // standby_for_rank if in standby replay)\n  mds_rank_t whoami = mdsmap->get_rank_gid(mds_gid_t(monc->get_global_id()));\n\n  // verify compatset\n  CompatSet mdsmap_compat(get_mdsmap_compat_set_all());\n  dout(10) << \"     my compat \" << mdsmap_compat << dendl;\n  dout(10) << \" mdsmap compat \" << mdsmap->compat << dendl;\n  if (!mdsmap_compat.writeable(mdsmap->compat)) {\n    dout(0) << \"handle_mds_map mdsmap compatset \" << mdsmap->compat\n\t    << \" not writeable with daemon features \" << mdsmap_compat\n\t    << \", killing myself\" << dendl;\n    suicide();\n    goto out;\n  }\n\n  // mark down any failed peers\n  for (map<mds_gid_t,MDSMap::mds_info_t>::const_iterator p = oldmap->get_mds_info().begin();\n       p != oldmap->get_mds_info().end();\n       ++p) {\n    if (mdsmap->get_mds_info().count(p->first) == 0) {\n      dout(10) << \" peer mds gid \" << p->first << \" removed from map\" << dendl;\n      messenger->mark_down(p->second.addr);\n    }\n  }\n\n  if (whoami == MDS_RANK_NONE && \n      new_state == MDSMap::STATE_STANDBY_REPLAY) {\n    whoami = mdsmap->get_mds_info_gid(mds_gid_t(monc->get_global_id())).standby_for_rank;\n  }\n\n  // see who i am\n  addr = messenger->get_myaddr();\n  dout(10) << \"map says I am \" << addr << \" mds.\" << whoami << \".\" << incarnation\n\t   << \" state \" << ceph_mds_state_name(new_state) << dendl;\n\n  if (whoami == MDS_RANK_NONE) {\n    if (mds_rank != NULL) {\n      const auto myid = monc->get_global_id();\n      // We have entered a rank-holding state, we shouldn't be back\n      // here!\n      if (g_conf->mds_enforce_unique_name) {\n        if (mds_gid_t existing = mdsmap->find_mds_gid_by_name(name)) {\n          const MDSMap::mds_info_t& i = mdsmap->get_info_gid(existing);\n          if (i.global_id > myid) {\n            dout(1) << \"map replaced me with another mds.\" << whoami\n                    << \" with gid (\" << i.global_id << \") larger than myself (\"\n                    << myid << \"); quitting!\" << dendl;\n            // Call suicide() rather than respawn() because if someone else\n            // has taken our ID, we don't want to keep restarting and\n            // fighting them for the ID.\n            suicide();\n            m->put();\n            return;\n          }\n        }\n      }\n\n      dout(1) << \"map removed me (mds.\" << whoami << \" gid:\"\n              << myid << \") from cluster due to lost contact; respawning\" << dendl;\n      respawn();\n    }\n    // MDSRank not active: process the map here to see if we have\n    // been assigned a rank.\n    dout(10) <<  __func__ << \": handling map in rankless mode\" << dendl;\n    _handle_mds_map(oldmap);\n  } else {\n\n    // Did we already hold a different rank?  MDSMonitor shouldn't try\n    // to change that out from under me!\n    if (mds_rank && whoami != mds_rank->get_nodeid()) {\n      derr << \"Invalid rank transition \" << mds_rank->get_nodeid() << \"->\"\n           << whoami << dendl;\n      respawn();\n    }\n\n    // Did I previously not hold a rank?  Initialize!\n    if (mds_rank == NULL) {\n      mds_rank = new MDSRankDispatcher(whoami, mds_lock, clog,\n          timer, beacon, mdsmap, messenger, monc,\n          new FunctionContext([this](int r){respawn();}),\n          new FunctionContext([this](int r){suicide();}));\n      dout(10) <<  __func__ << \": initializing MDS rank \"\n               << mds_rank->get_nodeid() << dendl;\n      mds_rank->init();\n    }\n\n    // MDSRank is active: let him process the map, we have no say.\n    dout(10) <<  __func__ << \": handling map as rank \"\n             << mds_rank->get_nodeid() << dendl;\n    mds_rank->handle_mds_map(m, oldmap);\n  }\n\nout:\n  beacon.notify_mdsmap(mdsmap);\n  m->put();\n  delete oldmap;\n}\n\nvoid MDSDaemon::_handle_mds_map(MDSMap *oldmap)\n{\n  MDSMap::DaemonState new_state = mdsmap->get_state_gid(mds_gid_t(monc->get_global_id()));\n\n  // Normal rankless case, we're marked as standby\n  if (new_state == MDSMap::STATE_STANDBY) {\n    beacon.set_want_state(mdsmap, new_state);\n    dout(1) << \"handle_mds_map standby\" << dendl;\n\n    return;\n  }\n\n  // Case where we thought we were standby, but MDSMap disagrees\n  if (beacon.get_want_state() == MDSMap::STATE_STANDBY) {\n    dout(10) << \"dropped out of mdsmap, try to re-add myself\" << dendl;\n    new_state = MDSMap::STATE_BOOT;\n    beacon.set_want_state(mdsmap, new_state);\n    return;\n  }\n\n  // Case where we have sent a boot beacon that isn't reflected yet\n  if (beacon.get_want_state() == MDSMap::STATE_BOOT) {\n    dout(10) << \"not in map yet\" << dendl;\n  }\n}\n\nvoid MDSDaemon::handle_signal(int signum)\n{\n  assert(signum == SIGINT || signum == SIGTERM);\n  derr << \"*** got signal \" << sig_str(signum) << \" ***\" << dendl;\n  {\n    Mutex::Locker l(mds_lock);\n    if (stopping) {\n      return;\n    }\n    suicide();\n  }\n}\n\nvoid MDSDaemon::suicide()\n{\n  assert(mds_lock.is_locked());\n  \n  // make sure we don't suicide twice\n  assert(stopping == false);\n  stopping = true;\n\n  dout(1) << \"suicide.  wanted state \"\n          << ceph_mds_state_name(beacon.get_want_state()) << dendl;\n\n  if (tick_event) {\n    timer.cancel_event(tick_event);\n    tick_event = 0;\n  }\n\n  //because add_observer is called after set_up_admin_socket\n  //so we can use asok_hook to avoid assert in the remove_observer\n  if (asok_hook != NULL)\n    g_conf->remove_observer(this);\n\n  clean_up_admin_socket();\n\n  // Inform MDS we are going away, then shut down beacon\n  beacon.set_want_state(mdsmap, MDSMap::STATE_DNE);\n  if (!mdsmap->is_dne_gid(mds_gid_t(monc->get_global_id()))) {\n    // Notify the MDSMonitor that we're dying, so that it doesn't have to\n    // wait for us to go laggy.  Only do this if we're actually in the\n    // MDSMap, because otherwise the MDSMonitor will drop our message.\n    beacon.send_and_wait(1);\n  }\n  beacon.shutdown();\n\n  mgrc.shutdown();\n\n  if (mds_rank) {\n    mds_rank->shutdown();\n  } else {\n    timer.shutdown();\n\n    monc->shutdown();\n    messenger->shutdown();\n  }\n}\n\nvoid MDSDaemon::respawn()\n{\n  dout(1) << \"respawn\" << dendl;\n\n  char *new_argv[orig_argc+1];\n  dout(1) << \" e: '\" << orig_argv[0] << \"'\" << dendl;\n  for (int i=0; i<orig_argc; i++) {\n    new_argv[i] = (char *)orig_argv[i];\n    dout(1) << \" \" << i << \": '\" << orig_argv[i] << \"'\" << dendl;\n  }\n  new_argv[orig_argc] = NULL;\n\n  /* Determine the path to our executable, test if Linux /proc/self/exe exists.\n   * This allows us to exec the same executable even if it has since been\n   * unlinked.\n   */\n  char exe_path[PATH_MAX] = \"\";\n  if (readlink(PROCPREFIX \"/proc/self/exe\", exe_path, PATH_MAX-1) == -1) {\n    /* Print CWD for the user's interest */\n    char buf[PATH_MAX];\n    char *cwd = getcwd(buf, sizeof(buf));\n    assert(cwd);\n    dout(1) << \" cwd \" << cwd << dendl;\n\n    /* Fall back to a best-effort: just running in our CWD */\n    strncpy(exe_path, orig_argv[0], PATH_MAX-1);\n  } else {\n    dout(1) << \"respawning with exe \" << exe_path << dendl;\n    strcpy(exe_path, PROCPREFIX \"/proc/self/exe\");\n  }\n\n  dout(1) << \" exe_path \" << exe_path << dendl;\n\n  unblock_all_signals(NULL);\n  execv(exe_path, new_argv);\n\n  dout(0) << \"respawn execv \" << orig_argv[0]\n\t  << \" failed with \" << cpp_strerror(errno) << dendl;\n\n  // We have to assert out here, because suicide() returns, and callers\n  // to respawn expect it never to return.\n  ceph_abort();\n}\n\n\n\nbool MDSDaemon::ms_dispatch(Message *m)\n{\n  Mutex::Locker l(mds_lock);\n  if (stopping) {\n    return false;\n  }\n\n  // Drop out early if shutting down\n  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE) {\n    dout(10) << \" stopping, discarding \" << *m << dendl;\n    m->put();\n    return true;\n  }\n\n  // First see if it's a daemon message\n  const bool handled_core = handle_core_message(m);\n  if (handled_core) {\n    return true;\n  }\n\n  // Not core, try it as a rank message\n  if (mds_rank) {\n    return mds_rank->ms_dispatch(m);\n  } else {\n    return false;\n  }\n}\n\nbool MDSDaemon::ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new)\n{\n  dout(10) << \"MDSDaemon::ms_get_authorizer type=\"\n           << ceph_entity_type_name(dest_type) << dendl;\n\n  /* monitor authorization is being handled on different layer */\n  if (dest_type == CEPH_ENTITY_TYPE_MON)\n    return true;\n\n  if (force_new) {\n    if (monc->wait_auth_rotating(10) < 0)\n      return false;\n  }\n\n  *authorizer = monc->build_authorizer(dest_type);\n  return *authorizer != NULL;\n}\n\n\n/*\n * high priority messages we always process\n */\nbool MDSDaemon::handle_core_message(Message *m)\n{\n  switch (m->get_type()) {\n  case CEPH_MSG_MON_MAP:\n    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON);\n    m->put();\n    break;\n\n    // MDS\n  case CEPH_MSG_MDS_MAP:\n    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON | CEPH_ENTITY_TYPE_MDS);\n    handle_mds_map(static_cast<MMDSMap*>(m));\n    break;\n\n    // OSD\n  case MSG_COMMAND:\n    handle_command(static_cast<MCommand*>(m));\n    break;\n  case CEPH_MSG_OSD_MAP:\n    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON | CEPH_ENTITY_TYPE_OSD);\n\n    if (mds_rank) {\n      mds_rank->handle_osd_map();\n    }\n    m->put();\n    break;\n\n  case MSG_MON_COMMAND:\n    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON);\n    clog->warn() << \"dropping `mds tell` command from legacy monitor\";\n    m->put();\n    break;\n\n  default:\n    return false;\n  }\n  return true;\n}\n\nvoid MDSDaemon::ms_handle_connect(Connection *con)\n{\n}\n\nbool MDSDaemon::ms_handle_reset(Connection *con)\n{\n  if (con->get_peer_type() != CEPH_ENTITY_TYPE_CLIENT)\n    return false;\n\n  Mutex::Locker l(mds_lock);\n  if (stopping) {\n    return false;\n  }\n  dout(5) << \"ms_handle_reset on \" << con->get_peer_addr() << dendl;\n  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE)\n    return false;\n\n  Session *session = static_cast<Session *>(con->get_priv());\n  if (session) {\n    if (session->is_closed()) {\n      dout(3) << \"ms_handle_reset closing connection for session \" << session->info.inst << dendl;\n      con->mark_down();\n      con->set_priv(NULL);\n    }\n    session->put();\n  } else {\n    con->mark_down();\n  }\n  return false;\n}\n\n\nvoid MDSDaemon::ms_handle_remote_reset(Connection *con)\n{\n  if (con->get_peer_type() != CEPH_ENTITY_TYPE_CLIENT)\n    return;\n\n  Mutex::Locker l(mds_lock);\n  if (stopping) {\n    return;\n  }\n\n  dout(5) << \"ms_handle_remote_reset on \" << con->get_peer_addr() << dendl;\n  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE)\n    return;\n\n  Session *session = static_cast<Session *>(con->get_priv());\n  if (session) {\n    if (session->is_closed()) {\n      dout(3) << \"ms_handle_remote_reset closing connection for session \" << session->info.inst << dendl;\n      con->mark_down();\n      con->set_priv(NULL);\n    }\n    session->put();\n  }\n}\n\nbool MDSDaemon::ms_handle_refused(Connection *con)\n{\n  // do nothing for now\n  return false;\n}\n\nbool MDSDaemon::ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t       int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t\t     bool& is_valid, CryptoKey& session_key,\n\t\t\t\t     std::unique_ptr<AuthAuthorizerChallenge> *challenge)\n{\n  Mutex::Locker l(mds_lock);\n  if (stopping) {\n    return false;\n  }\n  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE)\n    return false;\n\n  AuthAuthorizeHandler *authorize_handler = 0;\n  switch (peer_type) {\n  case CEPH_ENTITY_TYPE_MDS:\n    authorize_handler = authorize_handler_cluster_registry->get_handler(protocol);\n    break;\n  default:\n    authorize_handler = authorize_handler_service_registry->get_handler(protocol);\n  }\n  if (!authorize_handler) {\n    dout(0) << \"No AuthAuthorizeHandler found for protocol \" << protocol << dendl;\n    is_valid = false;\n    return true;\n  }\n\n  AuthCapsInfo caps_info;\n  EntityName name;\n  uint64_t global_id;\n\n  RotatingKeyRing *keys = monc->rotating_secrets.get();\n  if (keys) {\n    is_valid = authorize_handler->verify_authorizer(\n      cct, keys,\n      authorizer_data, authorizer_reply, name, global_id, caps_info,\n      session_key, nullptr, challenge);\n  } else {\n    dout(10) << __func__ << \" no rotating_keys (yet), denied\" << dendl;\n    is_valid = false;\n  }\n\n  if (is_valid) {\n    entity_name_t n(con->get_peer_type(), global_id);\n\n    // We allow connections and assign Session instances to connections\n    // even if we have not been assigned a rank, because clients with\n    // \"allow *\" are allowed to connect and do 'tell' operations before\n    // we have a rank.\n    Session *s = NULL;\n    if (mds_rank) {\n      // If we do hold a rank, see if this is an existing client establishing\n      // a new connection, rather than a new client\n      s = mds_rank->sessionmap.get_session(n);\n    }\n\n    // Wire up a Session* to this connection\n    // It doesn't go into a SessionMap instance until it sends an explicit\n    // request to open a session (initial state of Session is `closed`)\n    if (!s) {\n      s = new Session;\n      s->info.auth_name = name;\n      s->info.inst.addr = con->get_peer_addr();\n      s->info.inst.name = n;\n      dout(10) << \" new session \" << s << \" for \" << s->info.inst << \" con \" << con << dendl;\n      con->set_priv(s);\n      s->connection = con;\n    } else {\n      dout(10) << \" existing session \" << s << \" for \" << s->info.inst << \" existing con \" << s->connection\n\t       << \", new/authorizing con \" << con << dendl;\n      con->set_priv(s->get());\n\n\n\n      // Wait until we fully accept the connection before setting\n      // s->connection.  In particular, if there are multiple incoming\n      // connection attempts, they will all get their authorizer\n      // validated, but some of them may \"lose the race\" and get\n      // dropped.  We only want to consider the winner(s).  See\n      // ms_handle_accept().  This is important for Sessions we replay\n      // from the journal on recovery that don't have established\n      // messenger state; we want the con from only the winning\n      // connect attempt(s).  (Normal reconnects that don't follow MDS\n      // recovery are reconnected to the existing con by the\n      // messenger.)\n    }\n\n    if (caps_info.allow_all) {\n      // Flag for auth providers that don't provide cap strings\n      s->auth_caps.set_allow_all();\n    } else {\n      bufferlist::iterator p = caps_info.caps.begin();\n      string auth_cap_str;\n      try {\n        ::decode(auth_cap_str, p);\n\n        dout(10) << __func__ << \": parsing auth_cap_str='\" << auth_cap_str << \"'\" << dendl;\n        std::ostringstream errstr;\n        if (!s->auth_caps.parse(g_ceph_context, auth_cap_str, &errstr)) {\n          dout(1) << __func__ << \": auth cap parse error: \" << errstr.str()\n\t\t  << \" parsing '\" << auth_cap_str << \"'\" << dendl;\n\t  clog->warn() << name << \" mds cap '\" << auth_cap_str\n\t\t       << \"' does not parse: \" << errstr.str();\n          is_valid = false;\n        }\n      } catch (buffer::error& e) {\n        // Assume legacy auth, defaults to:\n        //  * permit all filesystem ops\n        //  * permit no `tell` ops\n        dout(1) << __func__ << \": cannot decode auth caps bl of length \" << caps_info.caps.length() << dendl;\n        is_valid = false;\n      }\n    }\n  }\n\n  return true;  // we made a decision (see is_valid)\n}\n\n\nvoid MDSDaemon::ms_handle_accept(Connection *con)\n{\n  Mutex::Locker l(mds_lock);\n  if (stopping) {\n    return;\n  }\n\n  Session *s = static_cast<Session *>(con->get_priv());\n  dout(10) << \"ms_handle_accept \" << con->get_peer_addr() << \" con \" << con << \" session \" << s << dendl;\n  if (s) {\n    if (s->connection != con) {\n      dout(10) << \" session connection \" << s->connection << \" -> \" << con << dendl;\n      s->connection = con;\n\n      // send out any queued messages\n      while (!s->preopen_out_queue.empty()) {\n\tcon->send_message(s->preopen_out_queue.front());\n\ts->preopen_out_queue.pop_front();\n      }\n    }\n    s->put();\n  }\n}\n\nbool MDSDaemon::is_clean_shutdown()\n{\n  if (mds_rank) {\n    return mds_rank->is_stopped();\n  } else {\n    return true;\n  }\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_MDS_H\n#define CEPH_MDS_H\n\n#include <boost/utility/string_view.hpp>\n\n#include \"common/LogClient.h\"\n#include \"common/Mutex.h\"\n#include \"common/Timer.h\"\n#include \"include/Context.h\"\n#include \"include/types.h\"\n#include \"mgr/MgrClient.h\"\n#include \"msg/Dispatcher.h\"\n\n#include \"Beacon.h\"\n#include \"MDSMap.h\"\n#include \"MDSRank.h\"\n\n#define CEPH_MDS_PROTOCOL    30 /* cluster internal */\n\nclass AuthAuthorizeHandlerRegistry;\nclass Message;\nclass Messenger;\nclass MonClient;\n\nclass MDSDaemon : public Dispatcher, public md_config_obs_t {\n public:\n  /* Global MDS lock: every time someone takes this, they must\n   * also check the `stopping` flag.  If stopping is true, you\n   * must either do nothing and immediately drop the lock, or\n   * never drop the lock again (i.e. call respawn()) */\n  Mutex        mds_lock;\n  bool         stopping;\n\n  SafeTimer    timer;\n\n\n  mono_time get_starttime() const {\n    return starttime;\n  }\n  chrono::duration<double> get_uptime() const {\n    mono_time now = mono_clock::now();\n    return chrono::duration<double>(now-starttime);\n  }\n\n protected:\n  Beacon  beacon;\n\n  AuthAuthorizeHandlerRegistry *authorize_handler_cluster_registry;\n  AuthAuthorizeHandlerRegistry *authorize_handler_service_registry;\n\n  std::string name;\n\n  Messenger    *messenger;\n  MonClient    *monc;\n  MgrClient     mgrc;\n  MDSMap       *mdsmap;\n  LogClient    log_client;\n  LogChannelRef clog;\n\n  MDSRankDispatcher *mds_rank;\n\n public:\n  MDSDaemon(boost::string_view n, Messenger *m, MonClient *mc);\n  ~MDSDaemon() override;\n  int orig_argc;\n  const char **orig_argv;\n\n  // handle a signal (e.g., SIGTERM)\n  void handle_signal(int signum);\n\n  int init();\n\n  /**\n   * Hint at whether we were shutdown gracefully (i.e. we were only\n   * in standby, or our rank was stopped).  Should be removed once\n   * we handle shutdown properly (e.g. clear out all message queues)\n   * such that deleting xlists doesn't assert.\n   */\n  bool is_clean_shutdown();\n\n  // config observer bits\n  const char** get_tracked_conf_keys() const override;\n  void handle_conf_change(const struct md_config_t *conf,\n\t\t\t\t  const std::set <std::string> &changed) override;\n protected:\n  // tick and other timer fun\n  Context *tick_event = nullptr;\n  void     reset_tick();\n\n  void wait_for_omap_osds();\n\n private:\n  bool ms_dispatch(Message *m) override;\n  bool ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new) override;\n  bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t       int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t    bool& isvalid, CryptoKey& session_key,\n\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) override;\n  void ms_handle_accept(Connection *con) override;\n  void ms_handle_connect(Connection *con) override;\n  bool ms_handle_reset(Connection *con) override;\n  void ms_handle_remote_reset(Connection *con) override;\n  bool ms_handle_refused(Connection *con) override;\n\n protected:\n  // admin socket handling\n  friend class MDSSocketHook;\n  class MDSSocketHook *asok_hook;\n  void set_up_admin_socket();\n  void clean_up_admin_socket();\n  void check_ops_in_flight(); // send off any slow ops to monitor\n  bool asok_command(string command, cmdmap_t& cmdmap, string format,\n\t\t    ostream& ss);\n\n  void dump_status(Formatter *f);\n\n  /**\n   * Terminate this daemon process.\n   *\n   * This function will return, but once it does so the calling thread\n   * must do no more work as all subsystems will have been shut down.\n   */\n  void suicide();\n\n  /**\n   * Start a new daemon process with the same command line parameters that\n   * this process was run with, then terminate this process\n   */\n  void respawn();\n\n  void tick();\n  \n  // messages\n  bool _dispatch(Message *m, bool new_msg);\n\nprotected:\n  bool handle_core_message(Message *m);\n  \n  // special message types\n  friend class C_MDS_Send_Command_Reply;\n  static void send_command_reply(MCommand *m, MDSRank* mds_rank, int r,\n\t\t\t\t bufferlist outbl, boost::string_view outs);\n  int _handle_command(\n      const cmdmap_t &cmdmap,\n      MCommand *m,\n      bufferlist *outbl,\n      std::string *outs,\n      Context **run_later,\n      bool *need_reply);\n  void handle_command(class MCommand *m);\n  void handle_mds_map(class MMDSMap *m);\n  void _handle_mds_map(MDSMap *oldmap);\n\nprivate:\n    mono_time starttime = mono_clock::zero();\n};\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2016 John Spray <john.spray@redhat.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n */\n\n#include \"DaemonServer.h\"\n#include \"mgr/Mgr.h\"\n\n#include \"include/stringify.h\"\n#include \"include/str_list.h\"\n#include \"auth/RotatingKeyRing.h\"\n#include \"json_spirit/json_spirit_writer.h\"\n\n#include \"mgr/mgr_commands.h\"\n#include \"mgr/OSDHealthMetricCollector.h\"\n#include \"mon/MonCommand.h\"\n\n#include \"messages/MMgrOpen.h\"\n#include \"messages/MMgrConfigure.h\"\n#include \"messages/MMonMgrReport.h\"\n#include \"messages/MCommand.h\"\n#include \"messages/MCommandReply.h\"\n#include \"messages/MPGStats.h\"\n#include \"messages/MOSDScrub.h\"\n#include \"messages/MOSDForceRecovery.h\"\n#include \"common/errno.h\"\n\n#define dout_context g_ceph_context\n#define dout_subsys ceph_subsys_mgr\n#undef dout_prefix\n#define dout_prefix *_dout << \"mgr.server \" << __func__ << \" \"\n\n\n\nDaemonServer::DaemonServer(MonClient *monc_,\n                           Finisher &finisher_,\n\t\t\t   DaemonStateIndex &daemon_state_,\n\t\t\t   ClusterState &cluster_state_,\n\t\t\t   PyModuleRegistry &py_modules_,\n\t\t\t   LogChannelRef clog_,\n\t\t\t   LogChannelRef audit_clog_)\n    : Dispatcher(g_ceph_context),\n      client_byte_throttler(new Throttle(g_ceph_context, \"mgr_client_bytes\",\n\t\t\t\t\t g_conf->get_val<uint64_t>(\"mgr_client_bytes\"))),\n      client_msg_throttler(new Throttle(g_ceph_context, \"mgr_client_messages\",\n\t\t\t\t\tg_conf->get_val<uint64_t>(\"mgr_client_messages\"))),\n      osd_byte_throttler(new Throttle(g_ceph_context, \"mgr_osd_bytes\",\n\t\t\t\t      g_conf->get_val<uint64_t>(\"mgr_osd_bytes\"))),\n      osd_msg_throttler(new Throttle(g_ceph_context, \"mgr_osd_messsages\",\n\t\t\t\t     g_conf->get_val<uint64_t>(\"mgr_osd_messages\"))),\n      mds_byte_throttler(new Throttle(g_ceph_context, \"mgr_mds_bytes\",\n\t\t\t\t      g_conf->get_val<uint64_t>(\"mgr_mds_bytes\"))),\n      mds_msg_throttler(new Throttle(g_ceph_context, \"mgr_mds_messsages\",\n\t\t\t\t     g_conf->get_val<uint64_t>(\"mgr_mds_messages\"))),\n      mon_byte_throttler(new Throttle(g_ceph_context, \"mgr_mon_bytes\",\n\t\t\t\t      g_conf->get_val<uint64_t>(\"mgr_mon_bytes\"))),\n      mon_msg_throttler(new Throttle(g_ceph_context, \"mgr_mon_messsages\",\n\t\t\t\t     g_conf->get_val<uint64_t>(\"mgr_mon_messages\"))),\n      msgr(nullptr),\n      monc(monc_),\n      finisher(finisher_),\n      daemon_state(daemon_state_),\n      cluster_state(cluster_state_),\n      py_modules(py_modules_),\n      clog(clog_),\n      audit_clog(audit_clog_),\n      auth_cluster_registry(g_ceph_context,\n                    g_conf->auth_supported.empty() ?\n                      g_conf->auth_cluster_required :\n                      g_conf->auth_supported),\n      auth_service_registry(g_ceph_context,\n                   g_conf->auth_supported.empty() ?\n                      g_conf->auth_service_required :\n                      g_conf->auth_supported),\n      lock(\"DaemonServer\"),\n      pgmap_ready(false)\n{\n  g_conf->add_observer(this);\n}\n\nDaemonServer::~DaemonServer() {\n  delete msgr;\n  g_conf->remove_observer(this);\n}\n\nint DaemonServer::init(uint64_t gid, entity_addr_t client_addr)\n{\n  // Initialize Messenger\n  std::string public_msgr_type = g_conf->ms_public_type.empty() ?\n    g_conf->get_val<std::string>(\"ms_type\") : g_conf->ms_public_type;\n  msgr = Messenger::create(g_ceph_context, public_msgr_type,\n\t\t\t   entity_name_t::MGR(gid),\n\t\t\t   \"mgr\",\n\t\t\t   getpid(), 0);\n  msgr->set_default_policy(Messenger::Policy::stateless_server(0));\n\n  // throttle clients\n  msgr->set_policy_throttlers(entity_name_t::TYPE_CLIENT,\n\t\t\t      client_byte_throttler.get(),\n\t\t\t      client_msg_throttler.get());\n\n  // servers\n  msgr->set_policy_throttlers(entity_name_t::TYPE_OSD,\n\t\t\t      osd_byte_throttler.get(),\n\t\t\t      osd_msg_throttler.get());\n  msgr->set_policy_throttlers(entity_name_t::TYPE_MDS,\n\t\t\t      mds_byte_throttler.get(),\n\t\t\t      mds_msg_throttler.get());\n  msgr->set_policy_throttlers(entity_name_t::TYPE_MON,\n\t\t\t      mon_byte_throttler.get(),\n\t\t\t      mon_msg_throttler.get());\n\n  int r = msgr->bind(g_conf->public_addr);\n  if (r < 0) {\n    derr << \"unable to bind mgr to \" << g_conf->public_addr << dendl;\n    return r;\n  }\n\n  msgr->set_myname(entity_name_t::MGR(gid));\n  msgr->set_addr_unknowns(client_addr);\n\n  msgr->start();\n  msgr->add_dispatcher_tail(this);\n\n  started_at = ceph_clock_now();\n\n  return 0;\n}\n\nentity_addr_t DaemonServer::get_myaddr() const\n{\n  return msgr->get_myaddr();\n}\n\n\nbool DaemonServer::ms_verify_authorizer(\n  Connection *con,\n  int peer_type,\n  int protocol,\n  ceph::bufferlist& authorizer_data,\n  ceph::bufferlist& authorizer_reply,\n  bool& is_valid,\n  CryptoKey& session_key,\n  std::unique_ptr<AuthAuthorizerChallenge> *challenge)\n{\n  AuthAuthorizeHandler *handler = nullptr;\n  if (peer_type == CEPH_ENTITY_TYPE_OSD ||\n      peer_type == CEPH_ENTITY_TYPE_MON ||\n      peer_type == CEPH_ENTITY_TYPE_MDS ||\n      peer_type == CEPH_ENTITY_TYPE_MGR) {\n    handler = auth_cluster_registry.get_handler(protocol);\n  } else {\n    handler = auth_service_registry.get_handler(protocol);\n  }\n  if (!handler) {\n    dout(0) << \"No AuthAuthorizeHandler found for protocol \" << protocol << dendl;\n    is_valid = false;\n    return true;\n  }\n\n  MgrSessionRef s(new MgrSession(cct));\n  s->inst.addr = con->get_peer_addr();\n  AuthCapsInfo caps_info;\n\n  RotatingKeyRing *keys = monc->rotating_secrets.get();\n  if (keys) {\n    is_valid = handler->verify_authorizer(\n      cct, keys,\n      authorizer_data,\n      authorizer_reply, s->entity_name,\n      s->global_id, caps_info,\n      session_key,\n      nullptr,\n      challenge);\n  } else {\n    dout(10) << __func__ << \" no rotating_keys (yet), denied\" << dendl;\n    is_valid = false;\n  }\n\n  if (is_valid) {\n    if (caps_info.allow_all) {\n      dout(10) << \" session \" << s << \" \" << s->entity_name\n\t       << \" allow_all\" << dendl;\n      s->caps.set_allow_all();\n    }\n    if (caps_info.caps.length() > 0) {\n      bufferlist::iterator p = caps_info.caps.begin();\n      string str;\n      try {\n\t::decode(str, p);\n      }\n      catch (buffer::error& e) {\n      }\n      bool success = s->caps.parse(str);\n      if (success) {\n\tdout(10) << \" session \" << s << \" \" << s->entity_name\n\t\t << \" has caps \" << s->caps << \" '\" << str << \"'\" << dendl;\n      } else {\n\tdout(10) << \" session \" << s << \" \" << s->entity_name\n\t\t << \" failed to parse caps '\" << str << \"'\" << dendl;\n\tis_valid = false;\n      }\n    }\n    con->set_priv(s->get());\n\n    if (peer_type == CEPH_ENTITY_TYPE_OSD) {\n      Mutex::Locker l(lock);\n      s->osd_id = atoi(s->entity_name.get_id().c_str());\n      dout(10) << \"registering osd.\" << s->osd_id << \" session \"\n\t       << s << \" con \" << con << dendl;\n      osd_cons[s->osd_id].insert(con);\n    }\n  }\n\n  return true;\n}\n\n\nbool DaemonServer::ms_get_authorizer(int dest_type,\n    AuthAuthorizer **authorizer, bool force_new)\n{\n  dout(10) << \"type=\" << ceph_entity_type_name(dest_type) << dendl;\n\n  if (dest_type == CEPH_ENTITY_TYPE_MON) {\n    return true;\n  }\n\n  if (force_new) {\n    if (monc->wait_auth_rotating(10) < 0)\n      return false;\n  }\n\n  *authorizer = monc->build_authorizer(dest_type);\n  dout(20) << \"got authorizer \" << *authorizer << dendl;\n  return *authorizer != NULL;\n}\n\nbool DaemonServer::ms_handle_reset(Connection *con)\n{\n  if (con->get_peer_type() == CEPH_ENTITY_TYPE_OSD) {\n    MgrSessionRef session(static_cast<MgrSession*>(con->get_priv()));\n    if (!session) {\n      return false;\n    }\n    session->put(); // SessionRef takes a ref\n    Mutex::Locker l(lock);\n    dout(10) << \"unregistering osd.\" << session->osd_id\n\t     << \"  session \" << session << \" con \" << con << dendl;\n    osd_cons[session->osd_id].erase(con);\n\n    auto iter = daemon_connections.find(con);\n    if (iter != daemon_connections.end()) {\n      daemon_connections.erase(iter);\n    }\n  }\n  return false;\n}\n\nbool DaemonServer::ms_handle_refused(Connection *con)\n{\n  // do nothing for now\n  return false;\n}\n\nbool DaemonServer::ms_dispatch(Message *m)\n{\n  // Note that we do *not* take ::lock here, in order to avoid\n  // serializing all message handling.  It's up to each handler\n  // to take whatever locks it needs.\n  switch (m->get_type()) {\n    case MSG_PGSTATS:\n      cluster_state.ingest_pgstats(static_cast<MPGStats*>(m));\n      maybe_ready(m->get_source().num());\n      m->put();\n      return true;\n    case MSG_MGR_REPORT:\n      return handle_report(static_cast<MMgrReport*>(m));\n    case MSG_MGR_OPEN:\n      return handle_open(static_cast<MMgrOpen*>(m));\n    case MSG_COMMAND:\n      return handle_command(static_cast<MCommand*>(m));\n    default:\n      dout(1) << \"Unhandled message type \" << m->get_type() << dendl;\n      return false;\n  };\n}\n\nvoid DaemonServer::maybe_ready(int32_t osd_id)\n{\n  if (pgmap_ready.load()) {\n    // Fast path: we don't need to take lock because pgmap_ready\n    // is already set\n  } else {\n    Mutex::Locker l(lock);\n\n    if (reported_osds.find(osd_id) == reported_osds.end()) {\n      dout(4) << \"initial report from osd \" << osd_id << dendl;\n      reported_osds.insert(osd_id);\n      std::set<int32_t> up_osds;\n\n      cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n          osdmap.get_up_osds(up_osds);\n      });\n\n      std::set<int32_t> unreported_osds;\n      std::set_difference(up_osds.begin(), up_osds.end(),\n                          reported_osds.begin(), reported_osds.end(),\n                          std::inserter(unreported_osds, unreported_osds.begin()));\n\n      if (unreported_osds.size() == 0) {\n        dout(4) << \"all osds have reported, sending PG state to mon\" << dendl;\n        pgmap_ready = true;\n        reported_osds.clear();\n        // Avoid waiting for next tick\n        send_report();\n      } else {\n        dout(4) << \"still waiting for \" << unreported_osds.size() << \" osds\"\n                   \" to report in before PGMap is ready\" << dendl;\n      }\n    }\n  }\n}\n\nvoid DaemonServer::shutdown()\n{\n  dout(10) << \"begin\" << dendl;\n  msgr->shutdown();\n  msgr->wait();\n  dout(10) << \"done\" << dendl;\n}\n\n\n\nbool DaemonServer::handle_open(MMgrOpen *m)\n{\n  Mutex::Locker l(lock);\n\n  DaemonKey key;\n  if (!m->service_name.empty()) {\n    key.first = m->service_name;\n  } else {\n    key.first = ceph_entity_type_name(m->get_connection()->get_peer_type());\n  }\n  key.second = m->daemon_name;\n\n  dout(4) << \"from \" << m->get_connection() << \"  \" << key << dendl;\n\n  _send_configure(m->get_connection());\n\n  DaemonStatePtr daemon;\n  if (daemon_state.exists(key)) {\n    daemon = daemon_state.get(key);\n  }\n  if (daemon) {\n    dout(20) << \"updating existing DaemonState for \" << m->daemon_name << dendl;\n    Mutex::Locker l(daemon->lock);\n    daemon->perf_counters.clear();\n  }\n\n  if (m->service_daemon) {\n    if (!daemon) {\n      dout(4) << \"constructing new DaemonState for \" << key << dendl;\n      daemon = std::make_shared<DaemonState>(daemon_state.types);\n      daemon->key = key;\n      if (m->daemon_metadata.count(\"hostname\")) {\n        daemon->hostname = m->daemon_metadata[\"hostname\"];\n      }\n      daemon_state.insert(daemon);\n    }\n    Mutex::Locker l(daemon->lock);\n    daemon->service_daemon = true;\n    daemon->metadata = m->daemon_metadata;\n    daemon->service_status = m->daemon_status;\n\n    utime_t now = ceph_clock_now();\n    auto d = pending_service_map.get_daemon(m->service_name,\n\t\t\t\t\t    m->daemon_name);\n    if (d->gid != (uint64_t)m->get_source().num()) {\n      dout(10) << \"registering \" << key << \" in pending_service_map\" << dendl;\n      d->gid = m->get_source().num();\n      d->addr = m->get_source_addr();\n      d->start_epoch = pending_service_map.epoch;\n      d->start_stamp = now;\n      d->metadata = m->daemon_metadata;\n      pending_service_map_dirty = pending_service_map.epoch;\n    }\n  }\n\n  if (m->get_connection()->get_peer_type() != entity_name_t::TYPE_CLIENT &&\n      m->service_name.empty())\n  {\n    // Store in set of the daemon/service connections, i.e. those\n    // connections that require an update in the event of stats\n    // configuration changes.\n    daemon_connections.insert(m->get_connection());\n  }\n\n  m->put();\n  return true;\n}\n\nbool DaemonServer::handle_report(MMgrReport *m)\n{\n  DaemonKey key;\n  if (!m->service_name.empty()) {\n    key.first = m->service_name;\n  } else {\n    key.first = ceph_entity_type_name(m->get_connection()->get_peer_type());\n  }\n  key.second = m->daemon_name;\n\n  dout(4) << \"from \" << m->get_connection() << \" \" << key << dendl;\n\n  if (m->get_connection()->get_peer_type() == entity_name_t::TYPE_CLIENT &&\n      m->service_name.empty()) {\n    // Clients should not be sending us stats unless they are declaring\n    // themselves to be a daemon for some service.\n    dout(4) << \"rejecting report from non-daemon client \" << m->daemon_name\n\t    << dendl;\n    m->get_connection()->mark_down();\n    m->put();\n    return true;\n  }\n\n  // Look up the DaemonState\n  DaemonStatePtr daemon;\n  if (daemon_state.exists(key)) {\n    dout(20) << \"updating existing DaemonState for \" << key << dendl;\n    daemon = daemon_state.get(key);\n  } else {\n    // we don't know the hostname at this stage, reject MMgrReport here.\n    dout(5) << \"rejecting report from \" << key << \", since we do not have its metadata now.\"\n\t    << dendl;\n\n    // issue metadata request in background\n    if (!daemon_state.is_updating(key) && \n\t(key.first == \"osd\" || key.first == \"mds\")) {\n\n      std::ostringstream oss;\n      auto c = new MetadataUpdate(daemon_state, key);\n      if (key.first == \"osd\") {\n        oss << \"{\\\"prefix\\\": \\\"osd metadata\\\", \\\"id\\\": \"\n            << key.second<< \"}\";\n\n      } else if (key.first == \"mds\") {\n        c->set_default(\"addr\", stringify(m->get_source_addr()));\n        oss << \"{\\\"prefix\\\": \\\"mds metadata\\\", \\\"who\\\": \\\"\"\n            << key.second << \"\\\"}\";\n \n      } else {\n\tceph_abort();\n      }\n\n      monc->start_mon_command({oss.str()}, {}, &c->outbl, &c->outs, c);\n    }\n    \n    {\n      Mutex::Locker l(lock);\n      // kill session\n      MgrSessionRef session(static_cast<MgrSession*>(m->get_connection()->get_priv()));\n      if (!session) {\n\treturn false;\n      }\n      m->get_connection()->mark_down();\n      session->put();\n\n      dout(10) << \"unregistering osd.\" << session->osd_id\n\t       << \"  session \" << session << \" con \" << m->get_connection() << dendl;\n      \n      if (osd_cons.find(session->osd_id) != osd_cons.end()) {\n\t   osd_cons[session->osd_id].erase(m->get_connection());\n      } \n\n      auto iter = daemon_connections.find(m->get_connection());\n      if (iter != daemon_connections.end()) {\n\tdaemon_connections.erase(iter);\n      }\n    }\n\n    return false;\n  }\n\n  // Update the DaemonState\n  assert(daemon != nullptr);\n  {\n    Mutex::Locker l(daemon->lock);\n    auto &daemon_counters = daemon->perf_counters;\n    daemon_counters.update(m);\n\n    if (daemon->service_daemon) {\n      utime_t now = ceph_clock_now();\n      if (m->daemon_status) {\n        daemon->service_status = *m->daemon_status;\n        daemon->service_status_stamp = now;\n      }\n      daemon->last_service_beacon = now;\n    } else if (m->daemon_status) {\n      derr << \"got status from non-daemon \" << key << dendl;\n    }\n    if (m->get_connection()->peer_is_osd()) {\n      // only OSD sends health_checks to me now\n      daemon->osd_health_metrics = std::move(m->osd_health_metrics);\n    }\n  }\n\n  // if there are any schema updates, notify the python modules\n  if (!m->declare_types.empty() || !m->undeclare_types.empty()) {\n    ostringstream oss;\n    oss << key.first << '.' << key.second;\n    py_modules.notify_all(\"perf_schema_update\", oss.str());\n  }\n\n  m->put();\n  return true;\n}\n\n\nvoid DaemonServer::_generate_command_map(\n  map<string,cmd_vartype>& cmdmap,\n  map<string,string> &param_str_map)\n{\n  for (map<string,cmd_vartype>::const_iterator p = cmdmap.begin();\n       p != cmdmap.end(); ++p) {\n    if (p->first == \"prefix\")\n      continue;\n    if (p->first == \"caps\") {\n      vector<string> cv;\n      if (cmd_getval(g_ceph_context, cmdmap, \"caps\", cv) &&\n\t  cv.size() % 2 == 0) {\n\tfor (unsigned i = 0; i < cv.size(); i += 2) {\n\t  string k = string(\"caps_\") + cv[i];\n\t  param_str_map[k] = cv[i + 1];\n\t}\n\tcontinue;\n      }\n    }\n    param_str_map[p->first] = cmd_vartype_stringify(p->second);\n  }\n}\n\nconst MonCommand *DaemonServer::_get_mgrcommand(\n  const string &cmd_prefix,\n  const std::vector<MonCommand> &cmds)\n{\n  const MonCommand *this_cmd = nullptr;\n  for (const auto &cmd : cmds) {\n    if (cmd.cmdstring.compare(0, cmd_prefix.size(), cmd_prefix) == 0) {\n      this_cmd = &cmd;\n      break;\n    }\n  }\n  return this_cmd;\n}\n\nbool DaemonServer::_allowed_command(\n  MgrSession *s,\n  const string &module,\n  const string &prefix,\n  const map<string,cmd_vartype>& cmdmap,\n  const map<string,string>& param_str_map,\n  const MonCommand *this_cmd) {\n\n  if (s->entity_name.is_mon()) {\n    // mon is all-powerful.  even when it is forwarding commands on behalf of\n    // old clients; we expect the mon is validating commands before proxying!\n    return true;\n  }\n\n  bool cmd_r = this_cmd->requires_perm('r');\n  bool cmd_w = this_cmd->requires_perm('w');\n  bool cmd_x = this_cmd->requires_perm('x');\n\n  bool capable = s->caps.is_capable(\n    g_ceph_context,\n    CEPH_ENTITY_TYPE_MGR,\n    s->entity_name,\n    module, prefix, param_str_map,\n    cmd_r, cmd_w, cmd_x);\n\n  dout(10) << \" \" << s->entity_name << \" \"\n\t   << (capable ? \"\" : \"not \") << \"capable\" << dendl;\n  return capable;\n}\n\nbool DaemonServer::handle_command(MCommand *m)\n{\n  Mutex::Locker l(lock);\n  int r = 0;\n  std::stringstream ss;\n  std::string prefix;\n\n  assert(lock.is_locked_by_me());\n\n  /**\n   * The working data for processing an MCommand.  This lives in\n   * a class to enable passing it into other threads for processing\n   * outside of the thread/locks that called handle_command.\n   */\n  class CommandContext\n  {\n    public:\n    MCommand *m;\n    bufferlist odata;\n    cmdmap_t cmdmap;\n\n    CommandContext(MCommand *m_)\n      : m(m_)\n    {\n    }\n\n    ~CommandContext()\n    {\n      m->put();\n    }\n\n    void reply(int r, const std::stringstream &ss)\n    {\n      reply(r, ss.str());\n    }\n\n    void reply(int r, const std::string &rs)\n    {\n      // Let the connection drop as soon as we've sent our response\n      ConnectionRef con = m->get_connection();\n      if (con) {\n        con->mark_disposable();\n      }\n\n      dout(1) << \"handle_command \" << cpp_strerror(r) << \" \" << rs << dendl;\n      if (con) {\n        MCommandReply *reply = new MCommandReply(r, rs);\n        reply->set_tid(m->get_tid());\n        reply->set_data(odata);\n        con->send_message(reply);\n      }\n    }\n  };\n\n  /**\n   * A context for receiving a bufferlist/error string from a background\n   * function and then calling back to a CommandContext when it's done\n   */\n  class ReplyOnFinish : public Context {\n    std::shared_ptr<CommandContext> cmdctx;\n\n  public:\n    bufferlist from_mon;\n    string outs;\n\n    ReplyOnFinish(std::shared_ptr<CommandContext> cmdctx_)\n      : cmdctx(cmdctx_)\n    {}\n    void finish(int r) override {\n      cmdctx->odata.claim_append(from_mon);\n      cmdctx->reply(r, outs);\n    }\n  };\n\n  std::shared_ptr<CommandContext> cmdctx = std::make_shared<CommandContext>(m);\n\n  MgrSessionRef session(static_cast<MgrSession*>(m->get_connection()->get_priv()));\n  if (!session) {\n    return true;\n  }\n  session->put(); // SessionRef takes a ref\n  if (session->inst.name == entity_name_t())\n    session->inst.name = m->get_source();\n\n  std::string format;\n  boost::scoped_ptr<Formatter> f;\n  map<string,string> param_str_map;\n\n  if (!cmdmap_from_json(m->cmd, &(cmdctx->cmdmap), ss)) {\n    cmdctx->reply(-EINVAL, ss);\n    return true;\n  }\n\n  {\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"format\", format, string(\"plain\"));\n    f.reset(Formatter::create(format));\n  }\n\n  cmd_getval(cct, cmdctx->cmdmap, \"prefix\", prefix);\n\n  dout(4) << \"decoded \" << cmdctx->cmdmap.size() << dendl;\n  dout(4) << \"prefix=\" << prefix << dendl;\n\n  if (prefix == \"get_command_descriptions\") {\n    dout(10) << \"reading commands from python modules\" << dendl;\n    const auto py_commands = py_modules.get_commands();\n\n    int cmdnum = 0;\n    JSONFormatter f;\n    f.open_object_section(\"command_descriptions\");\n\n    auto dump_cmd = [&cmdnum, &f](const MonCommand &mc){\n      ostringstream secname;\n      secname << \"cmd\" << setfill('0') << std::setw(3) << cmdnum;\n      dump_cmddesc_to_json(&f, secname.str(), mc.cmdstring, mc.helpstring,\n                           mc.module, mc.req_perms, mc.availability, 0);\n      cmdnum++;\n    };\n\n    for (const auto &pyc : py_commands) {\n      dump_cmd(pyc);\n    }\n\n    for (const auto &mgr_cmd : mgr_commands) {\n      dump_cmd(mgr_cmd);\n    }\n\n    f.close_section();\t// command_descriptions\n    f.flush(cmdctx->odata);\n    cmdctx->reply(0, ss);\n    return true;\n  }\n\n  // lookup command\n  const MonCommand *mgr_cmd = _get_mgrcommand(prefix, mgr_commands);\n  _generate_command_map(cmdctx->cmdmap, param_str_map);\n  if (!mgr_cmd) {\n    MonCommand py_command = {\"\", \"\", \"py\", \"rw\", \"cli\"};\n    if (!_allowed_command(session.get(), py_command.module, prefix, cmdctx->cmdmap,\n                          param_str_map, &py_command)) {\n      dout(1) << \" access denied\" << dendl;\n      ss << \"access denied; does your client key have mgr caps?\"\n\t\" See http://docs.ceph.com/docs/master/mgr/administrator/#client-authentication\";\n      cmdctx->reply(-EACCES, ss);\n      return true;\n    }\n  } else {\n    // validate user's permissions for requested command\n    if (!_allowed_command(session.get(), mgr_cmd->module, prefix, cmdctx->cmdmap,\n                          param_str_map, mgr_cmd)) {\n      dout(1) << \" access denied\" << dendl;\n      audit_clog->info() << \"from='\" << session->inst << \"' \"\n                         << \"entity='\" << session->entity_name << \"' \"\n                         << \"cmd=\" << m->cmd << \":  access denied\";\n      ss << \"access denied' does your client key have mgr caps?\"\n\t\" See http://docs.ceph.com/docs/master/mgr/administrator/#client-authentication\";\n      cmdctx->reply(-EACCES, ss);\n      return true;\n    }\n  }\n\n  audit_clog->debug()\n    << \"from='\" << session->inst << \"' \"\n    << \"entity='\" << session->entity_name << \"' \"\n    << \"cmd=\" << m->cmd << \": dispatch\";\n\n  // ----------------\n  // service map commands\n  if (prefix == \"service dump\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    cluster_state.with_servicemap([&](const ServiceMap &service_map) {\n\tf->dump_object(\"service_map\", service_map);\n      });\n    f->flush(cmdctx->odata);\n    cmdctx->reply(0, ss);\n    return true;\n  }\n  if (prefix == \"service status\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    // only include state from services that are in the persisted service map\n    f->open_object_section(\"service_status\");\n    ServiceMap s;\n    cluster_state.with_servicemap([&](const ServiceMap& service_map) {\n\ts = service_map;\n      });\n    for (auto& p : s.services) {\n      f->open_object_section(p.first.c_str());\n      for (auto& q : p.second.daemons) {\n\tf->open_object_section(q.first.c_str());\n\tDaemonKey key(p.first, q.first);\n\tassert(daemon_state.exists(key));\n\tauto daemon = daemon_state.get(key);\n\tMutex::Locker l(daemon->lock);\n\tf->dump_stream(\"status_stamp\") << daemon->service_status_stamp;\n\tf->dump_stream(\"last_beacon\") << daemon->last_service_beacon;\n\tf->open_object_section(\"status\");\n\tfor (auto& r : daemon->service_status) {\n\t  f->dump_string(r.first.c_str(), r.second);\n\t}\n\tf->close_section();\n\tf->close_section();\n      }\n      f->close_section();\n    }\n    f->close_section();\n    f->flush(cmdctx->odata);\n    cmdctx->reply(0, ss);\n    return true;\n  }\n\n  if (prefix == \"config set\") {\n    std::string key;\n    std::string val;\n    cmd_getval(cct, cmdctx->cmdmap, \"key\", key);\n    cmd_getval(cct, cmdctx->cmdmap, \"value\", val);\n    r = cct->_conf->set_val(key, val, true, &ss);\n    if (r == 0) {\n      cct->_conf->apply_changes(nullptr);\n    }\n    cmdctx->reply(0, ss);\n    return true;\n  }\n\n  // -----------\n  // PG commands\n\n  if (prefix == \"pg scrub\" ||\n      prefix == \"pg repair\" ||\n      prefix == \"pg deep-scrub\") {\n    string scrubop = prefix.substr(3, string::npos);\n    pg_t pgid;\n    string pgidstr;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"pgid\", pgidstr);\n    if (!pgid.parse(pgidstr.c_str())) {\n      ss << \"invalid pgid '\" << pgidstr << \"'\";\n      cmdctx->reply(-EINVAL, ss);\n      return true;\n    }\n    bool pg_exists = false;\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\tpg_exists = osdmap.pg_exists(pgid);\n      });\n    if (!pg_exists) {\n      ss << \"pg \" << pgid << \" dne\";\n      cmdctx->reply(-ENOENT, ss);\n      return true;\n    }\n    int acting_primary = -1;\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\tacting_primary = osdmap.get_pg_acting_primary(pgid);\n      });\n    if (acting_primary == -1) {\n      ss << \"pg \" << pgid << \" has no primary osd\";\n      cmdctx->reply(-EAGAIN, ss);\n      return true;\n    }\n    auto p = osd_cons.find(acting_primary);\n    if (p == osd_cons.end()) {\n      ss << \"pg \" << pgid << \" primary osd.\" << acting_primary\n\t << \" is not currently connected\";\n      cmdctx->reply(-EAGAIN, ss);\n    }\n    vector<pg_t> pgs = { pgid };\n    for (auto& con : p->second) {\n      con->send_message(new MOSDScrub(monc->get_fsid(),\n\t\t\t\t      pgs,\n\t\t\t\t      scrubop == \"repair\",\n\t\t\t\t      scrubop == \"deep-scrub\"));\n    }\n    ss << \"instructing pg \" << pgid << \" on osd.\" << acting_primary\n       << \" to \" << scrubop;\n    cmdctx->reply(0, ss);\n    return true;\n  } else if (prefix == \"osd scrub\" ||\n\t      prefix == \"osd deep-scrub\" ||\n\t      prefix == \"osd repair\") {\n    string whostr;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"who\", whostr);\n    vector<string> pvec;\n    get_str_vec(prefix, pvec);\n\n    set<int> osds;\n    if (whostr == \"*\" || whostr == \"all\" || whostr == \"any\") {\n      cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t  for (int i = 0; i < osdmap.get_max_osd(); i++)\n\t    if (osdmap.is_up(i)) {\n\t      osds.insert(i);\n\t    }\n\t});\n    } else {\n      long osd = parse_osd_id(whostr.c_str(), &ss);\n      if (osd < 0) {\n\tss << \"invalid osd '\" << whostr << \"'\";\n\tcmdctx->reply(-EINVAL, ss);\n\treturn true;\n      }\n      cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t  if (osdmap.is_up(osd)) {\n\t    osds.insert(osd);\n\t  }\n\t});\n      if (osds.empty()) {\n\tss << \"osd.\" << osd << \" is not up\";\n\tcmdctx->reply(-EAGAIN, ss);\n\treturn true;\n      }\n    }\n    set<int> sent_osds, failed_osds;\n    for (auto osd : osds) {\n      auto p = osd_cons.find(osd);\n      if (p == osd_cons.end()) {\n\tfailed_osds.insert(osd);\n      } else {\n\tsent_osds.insert(osd);\n\tfor (auto& con : p->second) {\n\t  con->send_message(new MOSDScrub(monc->get_fsid(),\n\t\t\t\t\t  pvec.back() == \"repair\",\n\t\t\t\t\t  pvec.back() == \"deep-scrub\"));\n\t}\n      }\n    }\n    if (failed_osds.size() == osds.size()) {\n      ss << \"failed to instruct osd(s) \" << osds << \" to \" << pvec.back()\n\t << \" (not connected)\";\n      r = -EAGAIN;\n    } else {\n      ss << \"instructed osd(s) \" << sent_osds << \" to \" << pvec.back();\n      if (!failed_osds.empty()) {\n\tss << \"; osd(s) \" << failed_osds << \" were not connected\";\n      }\n      r = 0;\n    }\n    cmdctx->reply(0, ss);\n    return true;\n  } else if (prefix == \"osd reweight-by-pg\" ||\n\t     prefix == \"osd reweight-by-utilization\" ||\n\t     prefix == \"osd test-reweight-by-pg\" ||\n\t     prefix == \"osd test-reweight-by-utilization\") {\n    bool by_pg =\n      prefix == \"osd reweight-by-pg\" || prefix == \"osd test-reweight-by-pg\";\n    bool dry_run =\n      prefix == \"osd test-reweight-by-pg\" ||\n      prefix == \"osd test-reweight-by-utilization\";\n    int64_t oload;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"oload\", oload, int64_t(120));\n    set<int64_t> pools;\n    vector<string> poolnames;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"pools\", poolnames);\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\tfor (const auto& poolname : poolnames) {\n\t  int64_t pool = osdmap.lookup_pg_pool_name(poolname);\n\t  if (pool < 0) {\n\t    ss << \"pool '\" << poolname << \"' does not exist\";\n\t    r = -ENOENT;\n\t  }\n\t  pools.insert(pool);\n\t}\n      });\n    if (r) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n    double max_change = g_conf->mon_reweight_max_change;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"max_change\", max_change);\n    if (max_change <= 0.0) {\n      ss << \"max_change \" << max_change << \" must be positive\";\n      cmdctx->reply(-EINVAL, ss);\n      return true;\n    }\n    int64_t max_osds = g_conf->mon_reweight_max_osds;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"max_osds\", max_osds);\n    if (max_osds <= 0) {\n      ss << \"max_osds \" << max_osds << \" must be positive\";\n      cmdctx->reply(-EINVAL, ss);\n      return true;\n    }\n    string no_increasing;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"no_increasing\", no_increasing);\n    string out_str;\n    mempool::osdmap::map<int32_t, uint32_t> new_weights;\n    r = cluster_state.with_pgmap([&](const PGMap& pgmap) {\n\treturn cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t    return reweight::by_utilization(osdmap, pgmap,\n\t\t\t\t\t    oload,\n\t\t\t\t\t    max_change,\n\t\t\t\t\t    max_osds,\n\t\t\t\t\t    by_pg,\n\t\t\t\t\t    pools.empty() ? NULL : &pools,\n\t\t\t\t\t    no_increasing == \"--no-increasing\",\n\t\t\t\t\t    &new_weights,\n\t\t\t\t\t    &ss, &out_str, f.get());\n\t  });\n      });\n    if (r >= 0) {\n      dout(10) << \"reweight::by_utilization: finished with \" << out_str << dendl;\n    }\n    if (f) {\n      f->flush(cmdctx->odata);\n    } else {\n      cmdctx->odata.append(out_str);\n    }\n    if (r < 0) {\n      ss << \"FAILED reweight-by-pg\";\n      cmdctx->reply(r, ss);\n      return true;\n    } else if (r == 0 || dry_run) {\n      ss << \"no change\";\n      cmdctx->reply(r, ss);\n      return true;\n    } else {\n      json_spirit::Object json_object;\n      for (const auto& osd_weight : new_weights) {\n\tjson_spirit::Config::add(json_object,\n\t\t\t\t std::to_string(osd_weight.first),\n\t\t\t\t std::to_string(osd_weight.second));\n      }\n      string s = json_spirit::write(json_object);\n      std::replace(begin(s), end(s), '\\\"', '\\'');\n      const string cmd =\n\t\"{\"\n\t\"\\\"prefix\\\": \\\"osd reweightn\\\", \"\n\t\"\\\"weights\\\": \\\"\" + s + \"\\\"\"\n\t\"}\";\n      auto on_finish = new ReplyOnFinish(cmdctx);\n      monc->start_mon_command({cmd}, {},\n\t\t\t      &on_finish->from_mon, &on_finish->outs, on_finish);\n      return true;\n    }\n  } else if (prefix == \"osd df\") {\n    string method;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"output_method\", method);\n    r = cluster_state.with_pgservice([&](const PGMapStatService& pgservice) {\n\treturn cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t    print_osd_utilization(osdmap, &pgservice, ss,\n\t\t\t\t  f.get(), method == \"tree\");\n\t\t\t\t  \n\t    cmdctx->odata.append(ss);\n\t    return 0;\n\t  });\n      });\n    cmdctx->reply(r, \"\");\n    return true;\n  } else if (prefix == \"osd safe-to-destroy\") {\n    vector<string> ids;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"ids\", ids);\n    set<int> osds;\n    int r;\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\tr = osdmap.parse_osd_id_list(ids, &osds, &ss);\n      });\n    if (!r && osds.empty()) {\n      ss << \"must specify one or more OSDs\";\n      r = -EINVAL;\n    }\n    if (r < 0) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n    set<int> active_osds, missing_stats, stored_pgs;\n    int affected_pgs = 0;\n    cluster_state.with_pgmap([&](const PGMap& pg_map) {\n\tif (pg_map.num_pg_unknown > 0) {\n\t  ss << pg_map.num_pg_unknown << \" pgs have unknown state; cannot draw\"\n\t     << \" any conclusions\";\n\t  r = -EAGAIN;\n\t  return;\n\t}\n\tint num_active_clean = 0;\n\tfor (auto& p : pg_map.num_pg_by_state) {\n\t  unsigned want = PG_STATE_ACTIVE|PG_STATE_CLEAN;\n\t  if ((p.first & want) == want) {\n\t    num_active_clean += p.second;\n\t  }\n\t}\n\tcluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t    for (auto osd : osds) {\n\t      if (!osdmap.exists(osd)) {\n\t\tcontinue;  // clearly safe to destroy\n\t      }\n\t      auto q = pg_map.num_pg_by_osd.find(osd);\n\t      if (q != pg_map.num_pg_by_osd.end()) {\n\t\tif (q->second.acting > 0 || q->second.up > 0) {\n\t\t  active_osds.insert(osd);\n\t\t  affected_pgs += q->second.acting + q->second.up;\n\t\t  continue;\n\t\t}\n\t      }\n\t      if (num_active_clean < pg_map.num_pg) {\n\t\t// all pgs aren't active+clean; we need to be careful.\n\t\tauto p = pg_map.osd_stat.find(osd);\n\t\tif (p == pg_map.osd_stat.end()) {\n\t\t  missing_stats.insert(osd);\n\t\t}\n\t\tif (p->second.num_pgs > 0) {\n\t\t  stored_pgs.insert(osd);\n\t\t}\n\t      }\n\t    }\n\t  });\n      });\n    if (!r && !active_osds.empty()) {\n      ss << \"OSD(s) \" << active_osds << \" have \" << affected_pgs\n\t << \" pgs currently mapped to them\";\n      r = -EBUSY;\n    } else if (!missing_stats.empty()) {\n      ss << \"OSD(s) \" << missing_stats << \" have no reported stats, and not all\"\n\t << \" PGs are active+clean; we cannot draw any conclusions\";\n      r = -EAGAIN;\n    } else if (!stored_pgs.empty()) {\n      ss << \"OSD(s) \" << stored_pgs << \" last reported they still store some PG\"\n\t << \" data, and not all PGs are active+clean; we cannot be sure they\"\n\t << \" aren't still needed.\";\n      r = -EBUSY;\n    }\n    if (r) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n    ss << \"OSD(s) \" << osds << \" are safe to destroy without reducing data\"\n       << \" durability.\";\n    cmdctx->reply(0, ss);\n    return true;\n  } else if (prefix == \"osd ok-to-stop\") {\n    vector<string> ids;\n    cmd_getval(g_ceph_context, cmdctx->cmdmap, \"ids\", ids);\n    set<int> osds;\n    int r;\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\tr = osdmap.parse_osd_id_list(ids, &osds, &ss);\n      });\n    if (!r && osds.empty()) {\n      ss << \"must specify one or more OSDs\";\n      r = -EINVAL;\n    }\n    if (r < 0) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n    map<pg_t,int> pg_delta;  // pgid -> net acting set size change\n    int dangerous_pgs = 0;\n    cluster_state.with_pgmap([&](const PGMap& pg_map) {\n\treturn cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t    if (pg_map.num_pg_unknown > 0) {\n\t      ss << pg_map.num_pg_unknown << \" pgs have unknown state; \"\n\t\t << \"cannot draw any conclusions\";\n\t      r = -EAGAIN;\n\t      return;\n\t    }\n\t    for (auto osd : osds) {\n\t      auto p = pg_map.pg_by_osd.find(osd);\n\t      if (p != pg_map.pg_by_osd.end()) {\n\t\tfor (auto& pgid : p->second) {\n\t\t  --pg_delta[pgid];\n\t\t}\n\t      }\n\t    }\n\t    for (auto& p : pg_delta) {\n\t      auto q = pg_map.pg_stat.find(p.first);\n\t      if (q == pg_map.pg_stat.end()) {\n\t\tss << \"missing information about \" << p.first << \"; cannot draw\"\n\t\t   << \" any conclusions\";\n\t\tr = -EAGAIN;\n\t\treturn;\n\t      }\n\t      if (!(q->second.state & PG_STATE_ACTIVE) ||\n\t\t  (q->second.state & PG_STATE_DEGRADED)) {\n\t\t// we don't currently have a good way to tell *how* degraded\n\t\t// a degraded PG is, so we have to assume we cannot remove\n\t\t// any more replicas/shards.\n\t\t++dangerous_pgs;\n\t\tcontinue;\n\t      }\n\t      const pg_pool_t *pi = osdmap.get_pg_pool(p.first.pool());\n\t      if (!pi) {\n\t\t++dangerous_pgs; // pool is creating or deleting\n\t      } else {\n\t\tif (q->second.acting.size() + p.second < pi->min_size) {\n\t\t  ++dangerous_pgs;\n\t\t}\n\t      }\n\t    }\n\t  });\n      });\n    if (r) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n    if (dangerous_pgs) {\n      ss << dangerous_pgs << \" PGs are already degraded or might become \"\n\t << \"unavailable\";\n      cmdctx->reply(-EBUSY, ss);\n      return true;\n    }\n    ss << \"OSD(s) \" << osds << \" are ok to stop without reducing\"\n       << \" availability, provided there are no other concurrent failures\"\n       << \" or interventions. \" << pg_delta.size() << \" PGs are likely to be\"\n       << \" degraded (but remain available) as a result.\";\n    cmdctx->reply(0, ss);\n    return true;\n  } else if (prefix == \"pg force-recovery\" ||\n  \t       prefix == \"pg force-backfill\" ||\n  \t       prefix == \"pg cancel-force-recovery\" ||\n  \t       prefix == \"pg cancel-force-backfill\") {\n    string forceop = prefix.substr(3, string::npos);\n    list<pg_t> parsed_pgs;\n    map<int, list<pg_t> > osdpgs;\n\n    // figure out actual op just once\n    int actual_op = 0;\n    if (forceop == \"force-recovery\") {\n      actual_op = OFR_RECOVERY;\n    } else if (forceop == \"force-backfill\") {\n      actual_op = OFR_BACKFILL;\n    } else if (forceop == \"cancel-force-backfill\") {\n      actual_op = OFR_BACKFILL | OFR_CANCEL;\n    } else if (forceop == \"cancel-force-recovery\") {\n      actual_op = OFR_RECOVERY | OFR_CANCEL;\n    }\n\n    // covnert pg names to pgs, discard any invalid ones while at it\n    {\n      // we don't want to keep pgidstr and pgidstr_nodup forever\n      vector<string> pgidstr;\n      // get pgids to process and prune duplicates\n      cmd_getval(g_ceph_context, cmdctx->cmdmap, \"pgid\", pgidstr);\n      set<string> pgidstr_nodup(pgidstr.begin(), pgidstr.end());\n      if (pgidstr.size() != pgidstr_nodup.size()) {\n\t// move elements only when there were duplicates, as this\n\t// reorders them\n\tpgidstr.resize(pgidstr_nodup.size());\n\tauto it = pgidstr_nodup.begin();\n\tfor (size_t i = 0 ; i < pgidstr_nodup.size(); i++) {\n\t  pgidstr[i] = std::move(*it++);\n\t}\n      }\n\n      cluster_state.with_pgmap([&](const PGMap& pg_map) {\n\tfor (auto& pstr : pgidstr) {\n\t  pg_t parsed_pg;\n\t  if (!parsed_pg.parse(pstr.c_str())) {\n\t    ss << \"invalid pgid '\" << pstr << \"'; \";\n\t    r = -EINVAL;\n\t  } else {\n\t    auto workit = pg_map.pg_stat.find(parsed_pg);\n\t    if (workit == pg_map.pg_stat.end()) {\n\t      ss << \"pg \" << pstr << \" does not exist; \";\n\t      r = -ENOENT;\n\t    } else {\n\t      pg_stat_t workpg = workit->second;\n\n\t      // discard pgs for which user requests are pointless\n\t      switch (actual_op)\n\t      {\n\t\tcase OFR_RECOVERY:\n\t\t  if ((workpg.state & (PG_STATE_DEGRADED | PG_STATE_RECOVERY_WAIT | PG_STATE_RECOVERING)) == 0) {\n\t\t    // don't return error, user script may be racing with cluster. not fatal.\n\t\t    ss << \"pg \" << pstr << \" doesn't require recovery; \";\n\t\t    continue;\n\t\t  } else  if (workpg.state & PG_STATE_FORCED_RECOVERY) {\n\t\t    ss << \"pg \" << pstr << \" recovery already forced; \";\n\t\t    // return error, as it may be a bug in user script\n\t\t    r = -EINVAL;\n\t\t    continue;\n\t\t  }\n\t\t  break;\n\t\tcase OFR_BACKFILL:\n\t\t  if ((workpg.state & (PG_STATE_DEGRADED | PG_STATE_BACKFILL_WAIT | PG_STATE_BACKFILLING)) == 0) {\n\t\t    ss << \"pg \" << pstr << \" doesn't require backfilling; \";\n\t\t    continue;\n\t\t  } else  if (workpg.state & PG_STATE_FORCED_BACKFILL) {\n\t\t    ss << \"pg \" << pstr << \" backfill already forced; \";\n\t\t    r = -EINVAL;\n\t\t    continue;\n\t\t  }\n\t\t  break;\n\t\tcase OFR_BACKFILL | OFR_CANCEL:\n\t\t  if ((workpg.state & PG_STATE_FORCED_BACKFILL) == 0) {\n\t\t    ss << \"pg \" << pstr << \" backfill not forced; \";\n\t\t    continue;\n\t\t  }\n\t\t  break;\n\t\tcase OFR_RECOVERY | OFR_CANCEL:\n\t\t  if ((workpg.state & PG_STATE_FORCED_RECOVERY) == 0) {\n\t\t    ss << \"pg \" << pstr << \" recovery not forced; \";\n\t\t    continue;\n\t\t  }\n\t\t  break;\n\t\tdefault:\n\t\t  assert(0 == \"actual_op value is not supported\");\n\t      }\n\n\t      parsed_pgs.push_back(std::move(parsed_pg));\n\t    }\n\t  }\n\t}\n\n\t// group pgs to process by osd\n\tfor (auto& pgid : parsed_pgs) {\n\t  auto workit = pg_map.pg_stat.find(pgid);\n\t  if (workit != pg_map.pg_stat.end()) {\n\t    pg_stat_t workpg = workit->second;\n\t    set<int32_t> osds(workpg.up.begin(), workpg.up.end());\n\t    osds.insert(workpg.acting.begin(), workpg.acting.end());\n\t    for (auto i : osds) {\n\t      osdpgs[i].push_back(pgid);\n\t    }\n\t  }\n\t}\n\n      });\n    }\n\n    // respond with error only when no pgs are correct\n    // yes, in case of mixed errors, only the last one will be emitted,\n    // but the message presented will be fine\n    if (parsed_pgs.size() != 0) {\n      // clear error to not confuse users/scripts\n      r = 0;\n    }\n\n    // optimize the command -> messages conversion, use only one message per distinct OSD\n    cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n      for (auto& i : osdpgs) {\n\tif (osdmap.is_up(i.first)) {\n\t  vector<pg_t> pgvec(make_move_iterator(i.second.begin()), make_move_iterator(i.second.end()));\n\t  auto p = osd_cons.find(i.first);\n\t  if (p == osd_cons.end()) {\n\t    ss << \"osd.\" << i.first << \" is not currently connected\";\n\t    r = -EAGAIN;\n\t    continue;\n\t  }\n\t  for (auto& con : p->second) {\n\t    con->send_message(new MOSDForceRecovery(monc->get_fsid(), pgvec, actual_op));\n\t  }\n\t  ss << \"instructing pg(s) \" << i.second << \" on osd.\" << i.first << \" to \" << forceop << \"; \";\n\t}\n      }\n    });\n    ss << std::endl;\n    cmdctx->reply(r, ss);\n    return true;\n  } else {\n    r = cluster_state.with_pgmap([&](const PGMap& pg_map) {\n\treturn cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t    return process_pg_map_command(prefix, cmdctx->cmdmap, pg_map, osdmap,\n\t\t\t\t\t  f.get(), &ss, &cmdctx->odata);\n\t  });\n      });\n\n    if (r != -EOPNOTSUPP) {\n      cmdctx->reply(r, ss);\n      return true;\n    }\n  }\n\n  // None of the special native commands, \n  ActivePyModule *handler = nullptr;\n  auto py_commands = py_modules.get_py_commands();\n  for (const auto &pyc : py_commands) {\n    auto pyc_prefix = cmddesc_get_prefix(pyc.cmdstring);\n    dout(1) << \"pyc_prefix: '\" << pyc_prefix << \"'\" << dendl;\n    if (pyc_prefix == prefix) {\n      handler = pyc.handler;\n      break;\n    }\n  }\n\n  if (handler == nullptr) {\n    ss << \"No handler found for '\" << prefix << \"'\";\n    dout(4) << \"No handler found for '\" << prefix << \"'\" << dendl;\n    cmdctx->reply(-EINVAL, ss);\n    return true;\n  } else {\n    // Okay, now we have a handler to call, but we must not call it\n    // in this thread, because the python handlers can do anything,\n    // including blocking, and including calling back into mgr.\n    dout(4) << \"passing through \" << cmdctx->cmdmap.size() << dendl;\n    finisher.queue(new FunctionContext([cmdctx, handler](int r_) {\n      std::stringstream ds;\n      std::stringstream ss;\n      int r = handler->handle_command(cmdctx->cmdmap, &ds, &ss);\n      cmdctx->odata.append(ds);\n      cmdctx->reply(r, ss);\n    }));\n    return true;\n  }\n}\n\nvoid DaemonServer::_prune_pending_service_map()\n{\n  utime_t cutoff = ceph_clock_now();\n  cutoff -= g_conf->get_val<double>(\"mgr_service_beacon_grace\");\n  auto p = pending_service_map.services.begin();\n  while (p != pending_service_map.services.end()) {\n    auto q = p->second.daemons.begin();\n    while (q != p->second.daemons.end()) {\n      DaemonKey key(p->first, q->first);\n      if (!daemon_state.exists(key)) {\n\tderr << \"missing key \" << key << dendl;\n\t++q;\n\tcontinue;\n      }\n      auto daemon = daemon_state.get(key);\n      Mutex::Locker l(daemon->lock);\n      if (daemon->last_service_beacon == utime_t()) {\n\t// we must have just restarted; assume they are alive now.\n\tdaemon->last_service_beacon = ceph_clock_now();\n\t++q;\n\tcontinue;\n      }\n      if (daemon->last_service_beacon < cutoff) {\n\tdout(10) << \"pruning stale \" << p->first << \".\" << q->first\n\t\t << \" last_beacon \" << daemon->last_service_beacon << dendl;\n\tq = p->second.daemons.erase(q);\n\tpending_service_map_dirty = pending_service_map.epoch;\n      } else {\n\t++q;\n      }\n    }\n    if (p->second.daemons.empty()) {\n      p = pending_service_map.services.erase(p);\n      pending_service_map_dirty = pending_service_map.epoch;\n    } else {\n      ++p;\n    }\n  }\n}\n\nvoid DaemonServer::send_report()\n{\n  if (!pgmap_ready) {\n    if (ceph_clock_now() - started_at > g_conf->get_val<int64_t>(\"mgr_stats_period\") * 4.0) {\n      pgmap_ready = true;\n      reported_osds.clear();\n      dout(1) << \"Giving up on OSDs that haven't reported yet, sending \"\n              << \"potentially incomplete PG state to mon\" << dendl;\n    } else {\n      dout(1) << \"Not sending PG status to monitor yet, waiting for OSDs\"\n              << dendl;\n      return;\n    }\n  }\n\n  auto m = new MMonMgrReport();\n  py_modules.get_health_checks(&m->health_checks);\n\n  cluster_state.with_pgmap([&](const PGMap& pg_map) {\n      cluster_state.update_delta_stats();\n\n      if (pending_service_map.epoch) {\n\t_prune_pending_service_map();\n\tif (pending_service_map_dirty >= pending_service_map.epoch) {\n\t  pending_service_map.modified = ceph_clock_now();\n\t  ::encode(pending_service_map, m->service_map_bl, CEPH_FEATURES_ALL);\n\t  dout(10) << \"sending service_map e\" << pending_service_map.epoch\n\t\t   << dendl;\n\t  pending_service_map.epoch++;\n\t}\n      }\n\n      cluster_state.with_osdmap([&](const OSDMap& osdmap) {\n\t  // FIXME: no easy way to get mon features here.  this will do for\n\t  // now, though, as long as we don't make a backward-incompat change.\n\t  pg_map.encode_digest(osdmap, m->get_data(), CEPH_FEATURES_ALL);\n\t  dout(10) << pg_map << dendl;\n\n\t  pg_map.get_health_checks(g_ceph_context, osdmap,\n\t\t\t\t   &m->health_checks);\n\n\t  dout(10) << m->health_checks.checks.size() << \" health checks\"\n\t\t   << dendl;\n\t  dout(20) << \"health checks:\\n\";\n\t  JSONFormatter jf(true);\n\t  jf.dump_object(\"health_checks\", m->health_checks);\n\t  jf.flush(*_dout);\n\t  *_dout << dendl;\n\t});\n    });\n\n  auto osds = daemon_state.get_by_service(\"osd\");\n  map<osd_metric, unique_ptr<OSDHealthMetricCollector>> accumulated;\n  for (const auto& osd : osds) {\n    Mutex::Locker l(osd.second->lock);\n    for (const auto& metric : osd.second->osd_health_metrics) {\n      auto acc = accumulated.find(metric.get_type());\n      if (acc == accumulated.end()) {\n\tauto collector = OSDHealthMetricCollector::create(metric.get_type());\n\tif (!collector) {\n\t  derr << __func__ << \" \" << osd.first << \".\" << osd.second\n\t       << \" sent me an unknown health metric: \"\n\t       << static_cast<uint8_t>(metric.get_type()) << dendl;\n\t  continue;\n\t}\n\ttie(acc, std::ignore) = accumulated.emplace(metric.get_type(),\n\t\t\t\t\t\t    std::move(collector));\n      }\n      acc->second->update(osd.first, metric);\n    }\n  }\n  for (const auto& acc : accumulated) {\n    acc.second->summarize(m->health_checks);\n  }\n  // TODO? We currently do not notify the PyModules\n  // TODO: respect needs_send, so we send the report only if we are asked to do\n  //       so, or the state is updated.\n  monc->send_mon_message(m);\n}\n\nvoid DaemonServer::got_service_map()\n{\n  Mutex::Locker l(lock);\n\n  cluster_state.with_servicemap([&](const ServiceMap& service_map) {\n      if (pending_service_map.epoch == 0) {\n\t// we just started up\n\tdout(10) << \"got initial map e\" << service_map.epoch << dendl;\n\tpending_service_map = service_map;\n      } else {\n\t// we we already active and therefore must have persisted it,\n\t// which means ours is the same or newer.\n\tdout(10) << \"got updated map e\" << service_map.epoch << dendl;\n      }\n      pending_service_map.epoch = service_map.epoch + 1;\n    });\n\n  // cull missing daemons, populate new ones\n  for (auto& p : pending_service_map.services) {\n    std::set<std::string> names;\n    for (auto& q : p.second.daemons) {\n      names.insert(q.first);\n      DaemonKey key(p.first, q.first);\n      if (!daemon_state.exists(key)) {\n\tauto daemon = std::make_shared<DaemonState>(daemon_state.types);\n\tdaemon->key = key;\n\tdaemon->metadata = q.second.metadata;\n        if (q.second.metadata.count(\"hostname\")) {\n          daemon->hostname = q.second.metadata[\"hostname\"];\n        }\n\tdaemon->service_daemon = true;\n\tdaemon_state.insert(daemon);\n\tdout(10) << \"added missing \" << key << dendl;\n      }\n    }\n    daemon_state.cull(p.first, names);\n  }\n}\n\n\nconst char** DaemonServer::get_tracked_conf_keys() const\n{\n  static const char *KEYS[] = {\n    \"mgr_stats_threshold\",\n    \"mgr_stats_period\",\n    nullptr\n  };\n\n  return KEYS;\n}\n\nvoid DaemonServer::handle_conf_change(const struct md_config_t *conf,\n                                              const std::set <std::string> &changed)\n{\n  dout(4) << \"ohai\" << dendl;\n  // We may be called within lock (via MCommand `config set`) or outwith the\n  // lock (via admin socket `config set`), so handle either case.\n  const bool initially_locked = lock.is_locked_by_me();\n  if (!initially_locked) {\n    lock.Lock();\n  }\n\n  if (changed.count(\"mgr_stats_threshold\") || changed.count(\"mgr_stats_period\")) {\n    dout(4) << \"Updating stats threshold/period on \"\n            << daemon_connections.size() << \" clients\" << dendl;\n    // Send a fresh MMgrConfigure to all clients, so that they can follow\n    // the new policy for transmitting stats\n    for (auto &c : daemon_connections) {\n      _send_configure(c);\n    }\n  }\n}\n\nvoid DaemonServer::_send_configure(ConnectionRef c)\n{\n  assert(lock.is_locked_by_me());\n\n  auto configure = new MMgrConfigure();\n  configure->stats_period = g_conf->get_val<int64_t>(\"mgr_stats_period\");\n  configure->stats_threshold = g_conf->get_val<int64_t>(\"mgr_stats_threshold\");\n  c->send_message(configure);\n}\n\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2016 John Spray <john.spray@redhat.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n */\n\n#ifndef DAEMON_SERVER_H_\n#define DAEMON_SERVER_H_\n\n#include \"PyModuleRegistry.h\"\n\n#include <set>\n#include <string>\n\n#include \"common/Mutex.h\"\n#include \"common/LogClient.h\"\n\n#include <msg/Messenger.h>\n#include <mon/MonClient.h>\n\n#include \"auth/AuthAuthorizeHandler.h\"\n\n#include \"ServiceMap.h\"\n#include \"MgrSession.h\"\n#include \"DaemonState.h\"\n\nclass MMgrReport;\nclass MMgrOpen;\nclass MMonMgrReport;\nclass MCommand;\nstruct MonCommand;\n\n\n/**\n * Server used in ceph-mgr to communicate with Ceph daemons like\n * MDSs and OSDs.\n */\nclass DaemonServer : public Dispatcher, public md_config_obs_t\n{\nprotected:\n  boost::scoped_ptr<Throttle> client_byte_throttler;\n  boost::scoped_ptr<Throttle> client_msg_throttler;\n  boost::scoped_ptr<Throttle> osd_byte_throttler;\n  boost::scoped_ptr<Throttle> osd_msg_throttler;\n  boost::scoped_ptr<Throttle> mds_byte_throttler;\n  boost::scoped_ptr<Throttle> mds_msg_throttler;\n  boost::scoped_ptr<Throttle> mon_byte_throttler;\n  boost::scoped_ptr<Throttle> mon_msg_throttler;\n\n  Messenger *msgr;\n  MonClient *monc;\n  Finisher  &finisher;\n  DaemonStateIndex &daemon_state;\n  ClusterState &cluster_state;\n  PyModuleRegistry &py_modules;\n  LogChannelRef clog, audit_clog;\n\n  // Authentication methods for cluster peers\n  AuthAuthorizeHandlerRegistry auth_cluster_registry;\n  // Authentication methods for clients\n  AuthAuthorizeHandlerRegistry auth_service_registry;\n\n  // Connections for daemons, and clients with service names set\n  // (i.e. those MgrClients that are allowed to send MMgrReports)\n  std::set<ConnectionRef> daemon_connections;\n\n  /// connections for osds\n  ceph::unordered_map<int,set<ConnectionRef>> osd_cons;\n\n  ServiceMap pending_service_map;  // uncommitted\n\n  epoch_t pending_service_map_dirty = 0;\n\n  Mutex lock;\n\n  static void _generate_command_map(map<string,cmd_vartype>& cmdmap,\n                                    map<string,string> &param_str_map);\n  static const MonCommand *_get_mgrcommand(const string &cmd_prefix,\n                                           const std::vector<MonCommand> &commands);\n  bool _allowed_command(\n    MgrSession *s, const string &module, const string &prefix,\n    const map<string,cmd_vartype>& cmdmap,\n    const map<string,string>& param_str_map,\n    const MonCommand *this_cmd);\n\nprivate:\n  friend class ReplyOnFinish;\n  bool _reply(MCommand* m,\n\t      int ret, const std::string& s, const bufferlist& payload);\n\n  void _prune_pending_service_map();\n\n  utime_t started_at;\n  std::atomic<bool> pgmap_ready;\n  std::set<int32_t> reported_osds;\n  void maybe_ready(int32_t osd_id);\n\npublic:\n  int init(uint64_t gid, entity_addr_t client_addr);\n  void shutdown();\n\n  entity_addr_t get_myaddr() const;\n\n  DaemonServer(MonClient *monc_,\n               Finisher &finisher_,\n\t       DaemonStateIndex &daemon_state_,\n\t       ClusterState &cluster_state_,\n\t       PyModuleRegistry &py_modules_,\n\t       LogChannelRef cl,\n\t       LogChannelRef auditcl);\n  ~DaemonServer() override;\n\n  bool ms_dispatch(Message *m) override;\n  bool ms_handle_reset(Connection *con) override;\n  void ms_handle_remote_reset(Connection *con) override {}\n  bool ms_handle_refused(Connection *con) override;\n  bool ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer,\n                         bool force_new) override;\n  bool ms_verify_authorizer(\n    Connection *con,\n    int peer_type,\n    int protocol,\n    ceph::bufferlist& authorizer,\n    ceph::bufferlist& authorizer_reply,\n    bool& isvalid,\n    CryptoKey& session_key,\n    std::unique_ptr<AuthAuthorizerChallenge> *challenge) override;\n\n  bool handle_open(MMgrOpen *m);\n  bool handle_report(MMgrReport *m);\n  bool handle_command(MCommand *m);\n  void send_report();\n  void got_service_map();\n\n  void _send_configure(ConnectionRef c);\n\n  virtual const char** get_tracked_conf_keys() const override;\n  virtual void handle_conf_change(const struct md_config_t *conf,\n                          const std::set <std::string> &changed) override;\n};\n\n#endif\n\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n\n#include <sstream>\n#include <stdlib.h>\n#include <signal.h>\n#include <limits.h>\n#include <cstring>\n#include <boost/scope_exit.hpp>\n#include <boost/algorithm/string/predicate.hpp>\n\n#include \"Monitor.h\"\n#include \"common/version.h\"\n\n#include \"osd/OSDMap.h\"\n\n#include \"MonitorDBStore.h\"\n\n#include \"messages/PaxosServiceMessage.h\"\n#include \"messages/MMonMap.h\"\n#include \"messages/MMonGetMap.h\"\n#include \"messages/MMonGetVersion.h\"\n#include \"messages/MMonGetVersionReply.h\"\n#include \"messages/MGenericMessage.h\"\n#include \"messages/MMonCommand.h\"\n#include \"messages/MMonCommandAck.h\"\n#include \"messages/MMonHealth.h\"\n#include \"messages/MMonMetadata.h\"\n#include \"messages/MMonSync.h\"\n#include \"messages/MMonScrub.h\"\n#include \"messages/MMonProbe.h\"\n#include \"messages/MMonJoin.h\"\n#include \"messages/MMonPaxos.h\"\n#include \"messages/MRoute.h\"\n#include \"messages/MForward.h\"\n#include \"messages/MStatfs.h\"\n\n#include \"messages/MMonSubscribe.h\"\n#include \"messages/MMonSubscribeAck.h\"\n\n#include \"messages/MAuthReply.h\"\n\n#include \"messages/MTimeCheck.h\"\n#include \"messages/MPing.h\"\n\n#include \"common/strtol.h\"\n#include \"common/ceph_argparse.h\"\n#include \"common/Timer.h\"\n#include \"common/Clock.h\"\n#include \"common/errno.h\"\n#include \"common/perf_counters.h\"\n#include \"common/admin_socket.h\"\n#include \"global/signal_handler.h\"\n#include \"common/Formatter.h\"\n#include \"include/stringify.h\"\n#include \"include/color.h\"\n#include \"include/ceph_fs.h\"\n#include \"include/str_list.h\"\n\n#include \"OSDMonitor.h\"\n#include \"MDSMonitor.h\"\n#include \"MonmapMonitor.h\"\n#include \"PGMonitor.h\"\n#include \"LogMonitor.h\"\n#include \"AuthMonitor.h\"\n#include \"MgrMonitor.h\"\n#include \"MgrStatMonitor.h\"\n#include \"mon/QuorumService.h\"\n#include \"mon/OldHealthMonitor.h\"\n#include \"mon/HealthMonitor.h\"\n#include \"mon/ConfigKeyService.h\"\n#include \"common/config.h\"\n#include \"common/cmdparse.h\"\n#include \"include/assert.h\"\n#include \"include/compat.h\"\n#include \"perfglue/heap_profiler.h\"\n\n#include \"auth/none/AuthNoneClientHandler.h\"\n\n#define dout_subsys ceph_subsys_mon\n#undef dout_prefix\n#define dout_prefix _prefix(_dout, this)\nstatic ostream& _prefix(std::ostream *_dout, const Monitor *mon) {\n  return *_dout << \"mon.\" << mon->name << \"@\" << mon->rank\n\t\t<< \"(\" << mon->get_state_name() << \") e\" << mon->monmap->get_epoch() << \" \";\n}\n\nconst string Monitor::MONITOR_NAME = \"monitor\";\nconst string Monitor::MONITOR_STORE_PREFIX = \"monitor_store\";\n\n\n#undef FLAG\n#undef COMMAND\n#undef COMMAND_WITH_FLAG\n#define FLAG(f) (MonCommand::FLAG_##f)\n#define COMMAND(parsesig, helptext, modulename, req_perms, avail)\t\\\n  {parsesig, helptext, modulename, req_perms, avail, FLAG(NONE)},\n#define COMMAND_WITH_FLAG(parsesig, helptext, modulename, req_perms, avail, flags) \\\n  {parsesig, helptext, modulename, req_perms, avail, flags},\nMonCommand mon_commands[] = {\n#include <mon/MonCommands.h>\n};\nMonCommand pgmonitor_commands[] = {\n#include <mon/PGMonitorCommands.h>\n};\n#undef COMMAND\n#undef COMMAND_WITH_FLAG\n\n\nvoid C_MonContext::finish(int r) {\n  if (mon->is_shutdown())\n    return;\n  FunctionContext::finish(r);\n}\n\nMonitor::Monitor(CephContext* cct_, string nm, MonitorDBStore *s,\n\t\t Messenger *m, Messenger *mgr_m, MonMap *map) :\n  Dispatcher(cct_),\n  name(nm),\n  rank(-1), \n  messenger(m),\n  con_self(m ? m->get_loopback_connection() : NULL),\n  lock(\"Monitor::lock\"),\n  timer(cct_, lock),\n  finisher(cct_, \"mon_finisher\", \"fin\"),\n  cpu_tp(cct, \"Monitor::cpu_tp\", \"cpu_tp\", g_conf->mon_cpu_threads),\n  has_ever_joined(false),\n  logger(NULL), cluster_logger(NULL), cluster_logger_registered(false),\n  monmap(map),\n  log_client(cct_, messenger, monmap, LogClient::FLAG_MON),\n  key_server(cct, &keyring),\n  auth_cluster_required(cct,\n\t\t\tcct->_conf->auth_supported.empty() ?\n\t\t\tcct->_conf->auth_cluster_required : cct->_conf->auth_supported),\n  auth_service_required(cct,\n\t\t\tcct->_conf->auth_supported.empty() ?\n\t\t\tcct->_conf->auth_service_required : cct->_conf->auth_supported ),\n  mgr_messenger(mgr_m),\n  mgr_client(cct_, mgr_m),\n  pgservice(nullptr),\n  store(s),\n  \n  state(STATE_PROBING),\n  \n  elector(this),\n  required_features(0),\n  leader(0),\n  quorum_con_features(0),\n  // scrub\n  scrub_version(0),\n  scrub_event(NULL),\n  scrub_timeout_event(NULL),\n\n  // sync state\n  sync_provider_count(0),\n  sync_cookie(0),\n  sync_full(false),\n  sync_start_version(0),\n  sync_timeout_event(NULL),\n  sync_last_committed_floor(0),\n\n  timecheck_round(0),\n  timecheck_acks(0),\n  timecheck_rounds_since_clean(0),\n  timecheck_event(NULL),\n\n  paxos_service(PAXOS_NUM),\n  admin_hook(NULL),\n  routed_request_tid(0),\n  op_tracker(cct, true, 1)\n{\n  clog = log_client.create_channel(CLOG_CHANNEL_CLUSTER);\n  audit_clog = log_client.create_channel(CLOG_CHANNEL_AUDIT);\n\n  update_log_clients();\n\n  paxos = new Paxos(this, \"paxos\");\n\n  paxos_service[PAXOS_MDSMAP] = new MDSMonitor(this, paxos, \"mdsmap\");\n  paxos_service[PAXOS_MONMAP] = new MonmapMonitor(this, paxos, \"monmap\");\n  paxos_service[PAXOS_OSDMAP] = new OSDMonitor(cct, this, paxos, \"osdmap\");\n  paxos_service[PAXOS_PGMAP] = new PGMonitor(this, paxos, \"pgmap\");\n  paxos_service[PAXOS_LOG] = new LogMonitor(this, paxos, \"logm\");\n  paxos_service[PAXOS_AUTH] = new AuthMonitor(this, paxos, \"auth\");\n  paxos_service[PAXOS_MGR] = new MgrMonitor(this, paxos, \"mgr\");\n  paxos_service[PAXOS_MGRSTAT] = new MgrStatMonitor(this, paxos, \"mgrstat\");\n  paxos_service[PAXOS_HEALTH] = new HealthMonitor(this, paxos, \"health\");\n\n  health_monitor = new OldHealthMonitor(this);\n  config_key_service = new ConfigKeyService(this, paxos);\n\n  mon_caps = new MonCap();\n  bool r = mon_caps->parse(\"allow *\", NULL);\n  assert(r);\n\n  exited_quorum = ceph_clock_now();\n\n  // prepare local commands\n  local_mon_commands.resize(ARRAY_SIZE(mon_commands));\n  for (unsigned i = 0; i < ARRAY_SIZE(mon_commands); ++i) {\n    local_mon_commands[i] = mon_commands[i];\n  }\n  MonCommand::encode_vector(local_mon_commands, local_mon_commands_bl);\n\n  local_upgrading_mon_commands = local_mon_commands;\n  for (unsigned i = 0; i < ARRAY_SIZE(pgmonitor_commands); ++i) {\n    local_upgrading_mon_commands.push_back(pgmonitor_commands[i]);\n  }\n  MonCommand::encode_vector(local_upgrading_mon_commands,\n\t\t\t    local_upgrading_mon_commands_bl);\n\n  // assume our commands until we have an election.  this only means\n  // we won't reply with EINVAL before the election; any command that\n  // actually matters will wait until we have quorum etc and then\n  // retry (and revalidate).\n  leader_mon_commands = local_mon_commands;\n\n  // note: OSDMonitor may update this based on the luminous flag.\n  pgservice = mgrstatmon()->get_pg_stat_service();\n}\n\nMonitor::~Monitor()\n{\n  for (vector<PaxosService*>::iterator p = paxos_service.begin(); p != paxos_service.end(); ++p)\n    delete *p;\n  delete health_monitor;\n  delete config_key_service;\n  delete paxos;\n  assert(session_map.sessions.empty());\n  delete mon_caps;\n}\n\n\nclass AdminHook : public AdminSocketHook {\n  Monitor *mon;\npublic:\n  explicit AdminHook(Monitor *m) : mon(m) {}\n  bool call(std::string command, cmdmap_t& cmdmap, std::string format,\n\t    bufferlist& out) override {\n    stringstream ss;\n    mon->do_admin_command(command, cmdmap, format, ss);\n    out.append(ss);\n    return true;\n  }\n};\n\nvoid Monitor::do_admin_command(string command, cmdmap_t& cmdmap, string format,\n\t\t\t       ostream& ss)\n{\n  Mutex::Locker l(lock);\n\n  boost::scoped_ptr<Formatter> f(Formatter::create(format));\n\n  string args;\n  for (cmdmap_t::iterator p = cmdmap.begin();\n       p != cmdmap.end(); ++p) {\n    if (p->first == \"prefix\")\n      continue;\n    if (!args.empty())\n      args += \", \";\n    args += cmd_vartype_stringify(p->second);\n  }\n  args = \"[\" + args + \"]\";\n\n  bool read_only = (command == \"mon_status\" ||\n                    command == \"mon metadata\" ||\n                    command == \"quorum_status\" ||\n                    command == \"ops\" ||\n                    command == \"sessions\");\n\n  (read_only ? audit_clog->debug() : audit_clog->info())\n    << \"from='admin socket' entity='admin socket' \"\n    << \"cmd='\" << command << \"' args=\" << args << \": dispatch\";\n\n  if (command == \"mon_status\") {\n    get_mon_status(f.get(), ss);\n    if (f)\n      f->flush(ss);\n  } else if (command == \"quorum_status\") {\n    _quorum_status(f.get(), ss);\n  } else if (command == \"sync_force\") {\n    string validate;\n    if ((!cmd_getval(g_ceph_context, cmdmap, \"validate\", validate)) ||\n\t(validate != \"--yes-i-really-mean-it\")) {\n      ss << \"are you SURE? this will mean the monitor store will be erased \"\n            \"the next time the monitor is restarted.  pass \"\n            \"'--yes-i-really-mean-it' if you really do.\";\n      goto abort;\n    }\n    sync_force(f.get(), ss);\n  } else if (command.compare(0, 23, \"add_bootstrap_peer_hint\") == 0) {\n    if (!_add_bootstrap_peer_hint(command, cmdmap, ss))\n      goto abort;\n  } else if (command == \"quorum enter\") {\n    elector.start_participating();\n    start_election();\n    ss << \"started responding to quorum, initiated new election\";\n  } else if (command == \"quorum exit\") {\n    start_election();\n    elector.stop_participating();\n    ss << \"stopped responding to quorum, initiated new election\";\n  } else if (command == \"ops\") {\n    (void)op_tracker.dump_ops_in_flight(f.get());\n    if (f) {\n      f->flush(ss);\n    }\n  } else if (command == \"sessions\") {\n\n    if (f) {\n      f->open_array_section(\"sessions\");\n      for (auto p : session_map.sessions) {\n        f->dump_stream(\"session\") << *p;\n      }\n      f->close_section();\n      f->flush(ss);\n    }\n\n  } else {\n    assert(0 == \"bad AdminSocket command binding\");\n  }\n  (read_only ? audit_clog->debug() : audit_clog->info())\n    << \"from='admin socket' \"\n    << \"entity='admin socket' \"\n    << \"cmd=\" << command << \" \"\n    << \"args=\" << args << \": finished\";\n  return;\n\nabort:\n  (read_only ? audit_clog->debug() : audit_clog->info())\n    << \"from='admin socket' \"\n    << \"entity='admin socket' \"\n    << \"cmd=\" << command << \" \"\n    << \"args=\" << args << \": aborted\";\n}\n\nvoid Monitor::handle_signal(int signum)\n{\n  assert(signum == SIGINT || signum == SIGTERM);\n  derr << \"*** Got Signal \" << sig_str(signum) << \" ***\" << dendl;\n  shutdown();\n}\n\nCompatSet Monitor::get_initial_supported_features()\n{\n  CompatSet::FeatureSet ceph_mon_feature_compat;\n  CompatSet::FeatureSet ceph_mon_feature_ro_compat;\n  CompatSet::FeatureSet ceph_mon_feature_incompat;\n  ceph_mon_feature_incompat.insert(CEPH_MON_FEATURE_INCOMPAT_BASE);\n  ceph_mon_feature_incompat.insert(CEPH_MON_FEATURE_INCOMPAT_SINGLE_PAXOS);\n  return CompatSet(ceph_mon_feature_compat, ceph_mon_feature_ro_compat,\n\t\t   ceph_mon_feature_incompat);\n}\n\nCompatSet Monitor::get_supported_features()\n{\n  CompatSet compat = get_initial_supported_features();\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_OSD_ERASURE_CODES);\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_OSDMAP_ENC);\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V2);\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V3);\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_KRAKEN);\n  compat.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_LUMINOUS);\n  return compat;\n}\n\nCompatSet Monitor::get_legacy_features()\n{\n  CompatSet::FeatureSet ceph_mon_feature_compat;\n  CompatSet::FeatureSet ceph_mon_feature_ro_compat;\n  CompatSet::FeatureSet ceph_mon_feature_incompat;\n  ceph_mon_feature_incompat.insert(CEPH_MON_FEATURE_INCOMPAT_BASE);\n  return CompatSet(ceph_mon_feature_compat, ceph_mon_feature_ro_compat,\n\t\t   ceph_mon_feature_incompat);\n}\n\nint Monitor::check_features(MonitorDBStore *store)\n{\n  CompatSet required = get_supported_features();\n  CompatSet ondisk;\n\n  read_features_off_disk(store, &ondisk);\n\n  if (!required.writeable(ondisk)) {\n    CompatSet diff = required.unsupported(ondisk);\n    generic_derr << \"ERROR: on disk data includes unsupported features: \" << diff << dendl;\n    return -EPERM;\n  }\n\n  return 0;\n}\n\nvoid Monitor::read_features_off_disk(MonitorDBStore *store, CompatSet *features)\n{\n  bufferlist featuresbl;\n  store->get(MONITOR_NAME, COMPAT_SET_LOC, featuresbl);\n  if (featuresbl.length() == 0) {\n    generic_dout(0) << \"WARNING: mon fs missing feature list.\\n\"\n            << \"Assuming it is old-style and introducing one.\" << dendl;\n    //we only want the baseline ~v.18 features assumed to be on disk.\n    //If new features are introduced this code needs to disappear or\n    //be made smarter.\n    *features = get_legacy_features();\n\n    features->encode(featuresbl);\n    auto t(std::make_shared<MonitorDBStore::Transaction>());\n    t->put(MONITOR_NAME, COMPAT_SET_LOC, featuresbl);\n    store->apply_transaction(t);\n  } else {\n    bufferlist::iterator it = featuresbl.begin();\n    features->decode(it);\n  }\n}\n\nvoid Monitor::read_features()\n{\n  read_features_off_disk(store, &features);\n  dout(10) << \"features \" << features << dendl;\n\n  calc_quorum_requirements();\n  dout(10) << \"required_features \" << required_features << dendl;\n}\n\nvoid Monitor::write_features(MonitorDBStore::TransactionRef t)\n{\n  bufferlist bl;\n  features.encode(bl);\n  t->put(MONITOR_NAME, COMPAT_SET_LOC, bl);\n}\n\nconst char** Monitor::get_tracked_conf_keys() const\n{\n  static const char* KEYS[] = {\n    \"crushtool\", // helpful for testing\n    \"mon_election_timeout\",\n    \"mon_lease\",\n    \"mon_lease_renew_interval_factor\",\n    \"mon_lease_ack_timeout_factor\",\n    \"mon_accept_timeout_factor\",\n    // clog & admin clog\n    \"clog_to_monitors\",\n    \"clog_to_syslog\",\n    \"clog_to_syslog_facility\",\n    \"clog_to_syslog_level\",\n    \"clog_to_graylog\",\n    \"clog_to_graylog_host\",\n    \"clog_to_graylog_port\",\n    \"host\",\n    \"fsid\",\n    // periodic health to clog\n    \"mon_health_to_clog\",\n    \"mon_health_to_clog_interval\",\n    \"mon_health_to_clog_tick_interval\",\n    // scrub interval\n    \"mon_scrub_interval\",\n    NULL\n  };\n  return KEYS;\n}\n\nvoid Monitor::handle_conf_change(const struct md_config_t *conf,\n                                 const std::set<std::string> &changed)\n{\n  sanitize_options();\n\n  dout(10) << __func__ << \" \" << changed << dendl;\n\n  if (changed.count(\"clog_to_monitors\") ||\n      changed.count(\"clog_to_syslog\") ||\n      changed.count(\"clog_to_syslog_level\") ||\n      changed.count(\"clog_to_syslog_facility\") ||\n      changed.count(\"clog_to_graylog\") ||\n      changed.count(\"clog_to_graylog_host\") ||\n      changed.count(\"clog_to_graylog_port\") ||\n      changed.count(\"host\") ||\n      changed.count(\"fsid\")) {\n    update_log_clients();\n  }\n\n  if (changed.count(\"mon_health_to_clog\") ||\n      changed.count(\"mon_health_to_clog_interval\") ||\n      changed.count(\"mon_health_to_clog_tick_interval\")) {\n    health_to_clog_update_conf(changed);\n  }\n\n  if (changed.count(\"mon_scrub_interval\")) {\n    scrub_update_interval(conf->mon_scrub_interval);\n  }\n}\n\nvoid Monitor::update_log_clients()\n{\n  map<string,string> log_to_monitors;\n  map<string,string> log_to_syslog;\n  map<string,string> log_channel;\n  map<string,string> log_prio;\n  map<string,string> log_to_graylog;\n  map<string,string> log_to_graylog_host;\n  map<string,string> log_to_graylog_port;\n  uuid_d fsid;\n  string host;\n\n  if (parse_log_client_options(g_ceph_context, log_to_monitors, log_to_syslog,\n\t\t\t       log_channel, log_prio, log_to_graylog,\n\t\t\t       log_to_graylog_host, log_to_graylog_port,\n\t\t\t       fsid, host))\n    return;\n\n  clog->update_config(log_to_monitors, log_to_syslog,\n\t\t      log_channel, log_prio, log_to_graylog,\n\t\t      log_to_graylog_host, log_to_graylog_port,\n\t\t      fsid, host);\n\n  audit_clog->update_config(log_to_monitors, log_to_syslog,\n\t\t\t    log_channel, log_prio, log_to_graylog,\n\t\t\t    log_to_graylog_host, log_to_graylog_port,\n\t\t\t    fsid, host);\n}\n\nint Monitor::sanitize_options()\n{\n  int r = 0;\n\n  // mon_lease must be greater than mon_lease_renewal; otherwise we\n  // may incur in leases expiring before they are renewed.\n  if (g_conf->mon_lease_renew_interval_factor >= 1.0) {\n    clog->error() << \"mon_lease_renew_interval_factor (\"\n\t\t  << g_conf->mon_lease_renew_interval_factor\n\t\t  << \") must be less than 1.0\";\n    r = -EINVAL;\n  }\n\n  // mon_lease_ack_timeout must be greater than mon_lease to make sure we've\n  // got time to renew the lease and get an ack for it. Having both options\n  // with the same value, for a given small vale, could mean timing out if\n  // the monitors happened to be overloaded -- or even under normal load for\n  // a small enough value.\n  if (g_conf->mon_lease_ack_timeout_factor <= 1.0) {\n    clog->error() << \"mon_lease_ack_timeout_factor (\"\n\t\t  << g_conf->mon_lease_ack_timeout_factor\n\t\t  << \") must be greater than 1.0\";\n    r = -EINVAL;\n  }\n\n  return r;\n}\n\nint Monitor::preinit()\n{\n  lock.Lock();\n\n  dout(1) << \"preinit fsid \" << monmap->fsid << dendl;\n\n  int r = sanitize_options();\n  if (r < 0) {\n    derr << \"option sanitization failed!\" << dendl;\n    lock.Unlock();\n    return r;\n  }\n\n  assert(!logger);\n  {\n    PerfCountersBuilder pcb(g_ceph_context, \"mon\", l_mon_first, l_mon_last);\n    pcb.add_u64(l_mon_num_sessions, \"num_sessions\", \"Open sessions\", \"sess\",\n        PerfCountersBuilder::PRIO_USEFUL);\n    pcb.add_u64_counter(l_mon_session_add, \"session_add\", \"Created sessions\",\n        \"sadd\", PerfCountersBuilder::PRIO_INTERESTING);\n    pcb.add_u64_counter(l_mon_session_rm, \"session_rm\", \"Removed sessions\",\n        \"srm\", PerfCountersBuilder::PRIO_INTERESTING);\n    pcb.add_u64_counter(l_mon_session_trim, \"session_trim\", \"Trimmed sessions\",\n        \"strm\", PerfCountersBuilder::PRIO_USEFUL);\n    pcb.add_u64_counter(l_mon_num_elections, \"num_elections\", \"Elections participated in\",\n        \"ecnt\", PerfCountersBuilder::PRIO_USEFUL);\n    pcb.add_u64_counter(l_mon_election_call, \"election_call\", \"Elections started\",\n        \"estt\", PerfCountersBuilder::PRIO_INTERESTING);\n    pcb.add_u64_counter(l_mon_election_win, \"election_win\", \"Elections won\",\n        \"ewon\", PerfCountersBuilder::PRIO_INTERESTING);\n    pcb.add_u64_counter(l_mon_election_lose, \"election_lose\", \"Elections lost\",\n        \"elst\", PerfCountersBuilder::PRIO_INTERESTING);\n    logger = pcb.create_perf_counters();\n    cct->get_perfcounters_collection()->add(logger);\n  }\n\n  assert(!cluster_logger);\n  {\n    PerfCountersBuilder pcb(g_ceph_context, \"cluster\", l_cluster_first, l_cluster_last);\n    pcb.add_u64(l_cluster_num_mon, \"num_mon\", \"Monitors\");\n    pcb.add_u64(l_cluster_num_mon_quorum, \"num_mon_quorum\", \"Monitors in quorum\");\n    pcb.add_u64(l_cluster_num_osd, \"num_osd\", \"OSDs\");\n    pcb.add_u64(l_cluster_num_osd_up, \"num_osd_up\", \"OSDs that are up\");\n    pcb.add_u64(l_cluster_num_osd_in, \"num_osd_in\", \"OSD in state \\\"in\\\" (they are in cluster)\");\n    pcb.add_u64(l_cluster_osd_epoch, \"osd_epoch\", \"Current epoch of OSD map\");\n    pcb.add_u64(l_cluster_osd_bytes, \"osd_bytes\", \"Total capacity of cluster\");\n    pcb.add_u64(l_cluster_osd_bytes_used, \"osd_bytes_used\", \"Used space\");\n    pcb.add_u64(l_cluster_osd_bytes_avail, \"osd_bytes_avail\", \"Available space\");\n    pcb.add_u64(l_cluster_num_pool, \"num_pool\", \"Pools\");\n    pcb.add_u64(l_cluster_num_pg, \"num_pg\", \"Placement groups\");\n    pcb.add_u64(l_cluster_num_pg_active_clean, \"num_pg_active_clean\", \"Placement groups in active+clean state\");\n    pcb.add_u64(l_cluster_num_pg_active, \"num_pg_active\", \"Placement groups in active state\");\n    pcb.add_u64(l_cluster_num_pg_peering, \"num_pg_peering\", \"Placement groups in peering state\");\n    pcb.add_u64(l_cluster_num_object, \"num_object\", \"Objects\");\n    pcb.add_u64(l_cluster_num_object_degraded, \"num_object_degraded\", \"Degraded (missing replicas) objects\");\n    pcb.add_u64(l_cluster_num_object_misplaced, \"num_object_misplaced\", \"Misplaced (wrong location in the cluster) objects\");\n    pcb.add_u64(l_cluster_num_object_unfound, \"num_object_unfound\", \"Unfound objects\");\n    pcb.add_u64(l_cluster_num_bytes, \"num_bytes\", \"Size of all objects\");\n    pcb.add_u64(l_cluster_num_mds_up, \"num_mds_up\", \"MDSs that are up\");\n    pcb.add_u64(l_cluster_num_mds_in, \"num_mds_in\", \"MDS in state \\\"in\\\" (they are in cluster)\");\n    pcb.add_u64(l_cluster_num_mds_failed, \"num_mds_failed\", \"Failed MDS\");\n    pcb.add_u64(l_cluster_mds_epoch, \"mds_epoch\", \"Current epoch of MDS map\");\n    cluster_logger = pcb.create_perf_counters();\n  }\n\n  paxos->init_logger();\n\n  // verify cluster_uuid\n  {\n    int r = check_fsid();\n    if (r == -ENOENT)\n      r = write_fsid();\n    if (r < 0) {\n      lock.Unlock();\n      return r;\n    }\n  }\n\n  // open compatset\n  read_features();\n\n  // have we ever joined a quorum?\n  has_ever_joined = (store->get(MONITOR_NAME, \"joined\") != 0);\n  dout(10) << \"has_ever_joined = \" << (int)has_ever_joined << dendl;\n\n  if (!has_ever_joined) {\n    // impose initial quorum restrictions?\n    list<string> initial_members;\n    get_str_list(g_conf->mon_initial_members, initial_members);\n\n    if (!initial_members.empty()) {\n      dout(1) << \" initial_members \" << initial_members << \", filtering seed monmap\" << dendl;\n\n      monmap->set_initial_members(g_ceph_context, initial_members, name, messenger->get_myaddr(),\n\t\t\t\t  &extra_probe_peers);\n\n      dout(10) << \" monmap is \" << *monmap << dendl;\n      dout(10) << \" extra probe peers \" << extra_probe_peers << dendl;\n    }\n  } else if (!monmap->contains(name)) {\n    derr << \"not in monmap and have been in a quorum before; \"\n         << \"must have been removed\" << dendl;\n    if (g_conf->mon_force_quorum_join) {\n      dout(0) << \"we should have died but \"\n              << \"'mon_force_quorum_join' is set -- allowing boot\" << dendl;\n    } else {\n      derr << \"commit suicide!\" << dendl;\n      lock.Unlock();\n      return -ENOENT;\n    }\n  }\n\n  {\n    // We have a potentially inconsistent store state in hands. Get rid of it\n    // and start fresh.\n    bool clear_store = false;\n    if (store->exists(\"mon_sync\", \"in_sync\")) {\n      dout(1) << __func__ << \" clean up potentially inconsistent store state\"\n\t      << dendl;\n      clear_store = true;\n    }\n\n    if (store->get(\"mon_sync\", \"force_sync\") > 0) {\n      dout(1) << __func__ << \" force sync by clearing store state\" << dendl;\n      clear_store = true;\n    }\n\n    if (clear_store) {\n      set<string> sync_prefixes = get_sync_targets_names();\n      store->clear(sync_prefixes);\n    }\n  }\n\n  sync_last_committed_floor = store->get(\"mon_sync\", \"last_committed_floor\");\n  dout(10) << \"sync_last_committed_floor \" << sync_last_committed_floor << dendl;\n\n  init_paxos();\n  health_monitor->init();\n\n  if (is_keyring_required()) {\n    // we need to bootstrap authentication keys so we can form an\n    // initial quorum.\n    if (authmon()->get_last_committed() == 0) {\n      dout(10) << \"loading initial keyring to bootstrap authentication for mkfs\" << dendl;\n      bufferlist bl;\n      int err = store->get(\"mkfs\", \"keyring\", bl);\n      if (err == 0 && bl.length() > 0) {\n        // Attempt to decode and extract keyring only if it is found.\n        KeyRing keyring;\n        bufferlist::iterator p = bl.begin();\n        ::decode(keyring, p);\n        extract_save_mon_key(keyring);\n      }\n    }\n\n    string keyring_loc = g_conf->mon_data + \"/keyring\";\n\n    r = keyring.load(cct, keyring_loc);\n    if (r < 0) {\n      EntityName mon_name;\n      mon_name.set_type(CEPH_ENTITY_TYPE_MON);\n      EntityAuth mon_key;\n      if (key_server.get_auth(mon_name, mon_key)) {\n\tdout(1) << \"copying mon. key from old db to external keyring\" << dendl;\n\tkeyring.add(mon_name, mon_key);\n\tbufferlist bl;\n\tkeyring.encode_plaintext(bl);\n\twrite_default_keyring(bl);\n      } else {\n\tderr << \"unable to load initial keyring \" << g_conf->keyring << dendl;\n\tlock.Unlock();\n\treturn r;\n      }\n    }\n  }\n\n  admin_hook = new AdminHook(this);\n  AdminSocket* admin_socket = cct->get_admin_socket();\n\n  // unlock while registering to avoid mon_lock -> admin socket lock dependency.\n  lock.Unlock();\n  r = admin_socket->register_command(\"mon_status\", \"mon_status\", admin_hook,\n\t\t\t\t     \"show current monitor status\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"quorum_status\", \"quorum_status\",\n\t\t\t\t     admin_hook, \"show current quorum status\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"sync_force\",\n\t\t\t\t     \"sync_force name=validate,\"\n\t\t\t\t     \"type=CephChoices,\"\n\t\t\t             \"strings=--yes-i-really-mean-it\",\n\t\t\t\t     admin_hook,\n\t\t\t\t     \"force sync of and clear monitor store\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"add_bootstrap_peer_hint\",\n\t\t\t\t     \"add_bootstrap_peer_hint name=addr,\"\n\t\t\t\t     \"type=CephIPAddr\",\n\t\t\t\t     admin_hook,\n\t\t\t\t     \"add peer address as potential bootstrap\"\n\t\t\t\t     \" peer for cluster bringup\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"quorum enter\", \"quorum enter\",\n                                     admin_hook,\n                                     \"force monitor back into quorum\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"quorum exit\", \"quorum exit\",\n                                     admin_hook,\n                                     \"force monitor out of the quorum\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"ops\",\n                                     \"ops\",\n                                     admin_hook,\n                                     \"show the ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"sessions\",\n                                     \"sessions\",\n                                     admin_hook,\n                                     \"list existing sessions\");\n  assert(r == 0);\n\n  lock.Lock();\n\n  // add ourselves as a conf observer\n  g_conf->add_observer(this);\n\n  lock.Unlock();\n  return 0;\n}\n\nint Monitor::init()\n{\n  dout(2) << \"init\" << dendl;\n  Mutex::Locker l(lock);\n\n  finisher.start();\n\n  // start ticker\n  timer.init();\n  new_tick();\n\n  cpu_tp.start();\n\n  // i'm ready!\n  messenger->add_dispatcher_tail(this);\n\n  mgr_client.init();\n  mgr_messenger->add_dispatcher_tail(&mgr_client);\n  mgr_messenger->add_dispatcher_tail(this);  // for auth ms_* calls\n\n  bootstrap();\n  // add features of myself into feature_map\n  session_map.feature_map.add_mon(con_self->get_features());\n  return 0;\n}\n\nvoid Monitor::init_paxos()\n{\n  dout(10) << __func__ << dendl;\n  paxos->init();\n\n  // init services\n  for (int i = 0; i < PAXOS_NUM; ++i) {\n    paxos_service[i]->init();\n  }\n\n  refresh_from_paxos(NULL);\n}\n\nvoid Monitor::refresh_from_paxos(bool *need_bootstrap)\n{\n  dout(10) << __func__ << dendl;\n\n  bufferlist bl;\n  int r = store->get(MONITOR_NAME, \"cluster_fingerprint\", bl);\n  if (r >= 0) {\n    try {\n      bufferlist::iterator p = bl.begin();\n      ::decode(fingerprint, p);\n    }\n    catch (buffer::error& e) {\n      dout(10) << __func__ << \" failed to decode cluster_fingerprint\" << dendl;\n    }\n  } else {\n    dout(10) << __func__ << \" no cluster_fingerprint\" << dendl;\n  }\n\n  for (int i = 0; i < PAXOS_NUM; ++i) {\n    paxos_service[i]->refresh(need_bootstrap);\n  }\n  for (int i = 0; i < PAXOS_NUM; ++i) {\n    paxos_service[i]->post_refresh();\n  }\n  load_metadata();\n}\n\nvoid Monitor::register_cluster_logger()\n{\n  if (!cluster_logger_registered) {\n    dout(10) << \"register_cluster_logger\" << dendl;\n    cluster_logger_registered = true;\n    cct->get_perfcounters_collection()->add(cluster_logger);\n  } else {\n    dout(10) << \"register_cluster_logger - already registered\" << dendl;\n  }\n}\n\nvoid Monitor::unregister_cluster_logger()\n{\n  if (cluster_logger_registered) {\n    dout(10) << \"unregister_cluster_logger\" << dendl;\n    cluster_logger_registered = false;\n    cct->get_perfcounters_collection()->remove(cluster_logger);\n  } else {\n    dout(10) << \"unregister_cluster_logger - not registered\" << dendl;\n  }\n}\n\nvoid Monitor::update_logger()\n{\n  cluster_logger->set(l_cluster_num_mon, monmap->size());\n  cluster_logger->set(l_cluster_num_mon_quorum, quorum.size());\n}\n\nvoid Monitor::shutdown()\n{\n  dout(1) << \"shutdown\" << dendl;\n\n  lock.Lock();\n\n  wait_for_paxos_write();\n\n  state = STATE_SHUTDOWN;\n\n  g_conf->remove_observer(this);\n\n  if (admin_hook) {\n    AdminSocket* admin_socket = cct->get_admin_socket();\n    admin_socket->unregister_command(\"mon_status\");\n    admin_socket->unregister_command(\"quorum_status\");\n    admin_socket->unregister_command(\"sync_force\");\n    admin_socket->unregister_command(\"add_bootstrap_peer_hint\");\n    admin_socket->unregister_command(\"quorum enter\");\n    admin_socket->unregister_command(\"quorum exit\");\n    admin_socket->unregister_command(\"ops\");\n    admin_socket->unregister_command(\"sessions\");\n    delete admin_hook;\n    admin_hook = NULL;\n  }\n\n  elector.shutdown();\n\n  mgr_client.shutdown();\n\n  lock.Unlock();\n  finisher.wait_for_empty();\n  finisher.stop();\n  lock.Lock();\n\n  // clean up\n  paxos->shutdown();\n  for (vector<PaxosService*>::iterator p = paxos_service.begin(); p != paxos_service.end(); ++p)\n    (*p)->shutdown();\n  health_monitor->shutdown();\n\n  finish_contexts(g_ceph_context, waitfor_quorum, -ECANCELED);\n  finish_contexts(g_ceph_context, maybe_wait_for_quorum, -ECANCELED);\n\n  timer.shutdown();\n\n  cpu_tp.stop();\n\n  remove_all_sessions();\n\n  if (logger) {\n    cct->get_perfcounters_collection()->remove(logger);\n    delete logger;\n    logger = NULL;\n  }\n  if (cluster_logger) {\n    if (cluster_logger_registered)\n      cct->get_perfcounters_collection()->remove(cluster_logger);\n    delete cluster_logger;\n    cluster_logger = NULL;\n  }\n\n  log_client.shutdown();\n\n  // unlock before msgr shutdown...\n  lock.Unlock();\n\n  messenger->shutdown();  // last thing!  ceph_mon.cc will delete mon.\n  mgr_messenger->shutdown();\n}\n\nvoid Monitor::wait_for_paxos_write()\n{\n  if (paxos->is_writing() || paxos->is_writing_previous()) {\n    dout(10) << __func__ << \" flushing pending write\" << dendl;\n    lock.Unlock();\n    store->flush();\n    lock.Lock();\n    dout(10) << __func__ << \" flushed pending write\" << dendl;\n  }\n}\n\nvoid Monitor::bootstrap()\n{\n  dout(10) << \"bootstrap\" << dendl;\n  wait_for_paxos_write();\n\n  sync_reset_requester();\n  unregister_cluster_logger();\n  cancel_probe_timeout();\n\n  // note my rank\n  int newrank = monmap->get_rank(messenger->get_myaddr());\n  if (newrank < 0 && rank >= 0) {\n    // was i ever part of the quorum?\n    if (has_ever_joined) {\n      dout(0) << \" removed from monmap, suicide.\" << dendl;\n      exit(0);\n    }\n  }\n  if (newrank != rank) {\n    dout(0) << \" my rank is now \" << newrank << \" (was \" << rank << \")\" << dendl;\n    messenger->set_myname(entity_name_t::MON(newrank));\n    rank = newrank;\n\n    // reset all connections, or else our peers will think we are someone else.\n    messenger->mark_down_all();\n  }\n\n  // reset\n  state = STATE_PROBING;\n\n  _reset();\n\n  // sync store\n  if (g_conf->mon_compact_on_bootstrap) {\n    dout(10) << \"bootstrap -- triggering compaction\" << dendl;\n    store->compact();\n    dout(10) << \"bootstrap -- finished compaction\" << dendl;\n  }\n\n  // singleton monitor?\n  if (monmap->size() == 1 && rank == 0) {\n    win_standalone_election();\n    return;\n  }\n\n  reset_probe_timeout();\n\n  // i'm outside the quorum\n  if (monmap->contains(name))\n    outside_quorum.insert(name);\n\n  // probe monitors\n  dout(10) << \"probing other monitors\" << dendl;\n  for (unsigned i = 0; i < monmap->size(); i++) {\n    if ((int)i != rank)\n      messenger->send_message(new MMonProbe(monmap->fsid, MMonProbe::OP_PROBE, name, has_ever_joined),\n\t\t\t      monmap->get_inst(i));\n  }\n  for (set<entity_addr_t>::iterator p = extra_probe_peers.begin();\n       p != extra_probe_peers.end();\n       ++p) {\n    if (*p != messenger->get_myaddr()) {\n      entity_inst_t i;\n      i.name = entity_name_t::MON(-1);\n      i.addr = *p;\n      messenger->send_message(new MMonProbe(monmap->fsid, MMonProbe::OP_PROBE, name, has_ever_joined), i);\n    }\n  }\n}\n\nbool Monitor::_add_bootstrap_peer_hint(string cmd, cmdmap_t& cmdmap, ostream& ss)\n{\n  string addrstr;\n  if (!cmd_getval(g_ceph_context, cmdmap, \"addr\", addrstr)) {\n    ss << \"unable to parse address string value '\"\n         << cmd_vartype_stringify(cmdmap[\"addr\"]) << \"'\";\n    return false;\n  }\n  dout(10) << \"_add_bootstrap_peer_hint '\" << cmd << \"' '\"\n           << addrstr << \"'\" << dendl;\n\n  entity_addr_t addr;\n  const char *end = 0;\n  if (!addr.parse(addrstr.c_str(), &end)) {\n    ss << \"failed to parse addr '\" << addrstr << \"'; syntax is 'add_bootstrap_peer_hint ip[:port]'\";\n    return false;\n  }\n\n  if (is_leader() || is_peon()) {\n    ss << \"mon already active; ignoring bootstrap hint\";\n    return true;\n  }\n\n  if (addr.get_port() == 0)\n    addr.set_port(CEPH_MON_PORT);\n\n  extra_probe_peers.insert(addr);\n  ss << \"adding peer \" << addr << \" to list: \" << extra_probe_peers;\n  return true;\n}\n\n// called by bootstrap(), or on leader|peon -> electing\nvoid Monitor::_reset()\n{\n  dout(10) << __func__ << dendl;\n\n  cancel_probe_timeout();\n  timecheck_finish();\n  health_events_cleanup();\n  health_check_log_times.clear();\n  scrub_event_cancel();\n\n  leader_since = utime_t();\n  if (!quorum.empty()) {\n    exited_quorum = ceph_clock_now();\n  }\n  quorum.clear();\n  outside_quorum.clear();\n  quorum_feature_map.clear();\n\n  scrub_reset();\n\n  paxos->restart();\n\n  for (vector<PaxosService*>::iterator p = paxos_service.begin(); p != paxos_service.end(); ++p)\n    (*p)->restart();\n  health_monitor->finish();\n}\n\n\n// -----------------------------------------------------------\n// sync\n\nset<string> Monitor::get_sync_targets_names()\n{\n  set<string> targets;\n  targets.insert(paxos->get_name());\n  for (int i = 0; i < PAXOS_NUM; ++i)\n    paxos_service[i]->get_store_prefixes(targets);\n  ConfigKeyService *config_key_service_ptr = dynamic_cast<ConfigKeyService*>(config_key_service);\n  assert(config_key_service_ptr);\n  config_key_service_ptr->get_store_prefixes(targets);\n  return targets;\n}\n\n\nvoid Monitor::sync_timeout()\n{\n  dout(10) << __func__ << dendl;\n  assert(state == STATE_SYNCHRONIZING);\n  bootstrap();\n}\n\nvoid Monitor::sync_obtain_latest_monmap(bufferlist &bl)\n{\n  dout(1) << __func__ << dendl;\n\n  MonMap latest_monmap;\n\n  // Grab latest monmap from MonmapMonitor\n  bufferlist monmon_bl;\n  int err = monmon()->get_monmap(monmon_bl);\n  if (err < 0) {\n    if (err != -ENOENT) {\n      derr << __func__\n           << \" something wrong happened while reading the store: \"\n           << cpp_strerror(err) << dendl;\n      assert(0 == \"error reading the store\");\n    }\n  } else {\n    latest_monmap.decode(monmon_bl);\n  }\n\n  // Grab last backed up monmap (if any) and compare epochs\n  if (store->exists(\"mon_sync\", \"latest_monmap\")) {\n    bufferlist backup_bl;\n    int err = store->get(\"mon_sync\", \"latest_monmap\", backup_bl);\n    if (err < 0) {\n      derr << __func__\n           << \" something wrong happened while reading the store: \"\n           << cpp_strerror(err) << dendl;\n      assert(0 == \"error reading the store\");\n    }\n    assert(backup_bl.length() > 0);\n\n    MonMap backup_monmap;\n    backup_monmap.decode(backup_bl);\n\n    if (backup_monmap.epoch > latest_monmap.epoch)\n      latest_monmap = backup_monmap;\n  }\n\n  // Check if our current monmap's epoch is greater than the one we've\n  // got so far.\n  if (monmap->epoch > latest_monmap.epoch)\n    latest_monmap = *monmap;\n\n  dout(1) << __func__ << \" obtained monmap e\" << latest_monmap.epoch << dendl;\n\n  latest_monmap.encode(bl, CEPH_FEATURES_ALL);\n}\n\nvoid Monitor::sync_reset_requester()\n{\n  dout(10) << __func__ << dendl;\n\n  if (sync_timeout_event) {\n    timer.cancel_event(sync_timeout_event);\n    sync_timeout_event = NULL;\n  }\n\n  sync_provider = entity_inst_t();\n  sync_cookie = 0;\n  sync_full = false;\n  sync_start_version = 0;\n}\n\nvoid Monitor::sync_reset_provider()\n{\n  dout(10) << __func__ << dendl;\n  sync_providers.clear();\n}\n\nvoid Monitor::sync_start(entity_inst_t &other, bool full)\n{\n  dout(10) << __func__ << \" \" << other << (full ? \" full\" : \" recent\") << dendl;\n\n  assert(state == STATE_PROBING ||\n\t state == STATE_SYNCHRONIZING);\n  state = STATE_SYNCHRONIZING;\n\n  // make sure are not a provider for anyone!\n  sync_reset_provider();\n\n  sync_full = full;\n\n  if (sync_full) {\n    // stash key state, and mark that we are syncing\n    auto t(std::make_shared<MonitorDBStore::Transaction>());\n    sync_stash_critical_state(t);\n    t->put(\"mon_sync\", \"in_sync\", 1);\n\n    sync_last_committed_floor = MAX(sync_last_committed_floor, paxos->get_version());\n    dout(10) << __func__ << \" marking sync in progress, storing sync_last_committed_floor \"\n\t     << sync_last_committed_floor << dendl;\n    t->put(\"mon_sync\", \"last_committed_floor\", sync_last_committed_floor);\n\n    store->apply_transaction(t);\n\n    assert(g_conf->mon_sync_requester_kill_at != 1);\n\n    // clear the underlying store\n    set<string> targets = get_sync_targets_names();\n    dout(10) << __func__ << \" clearing prefixes \" << targets << dendl;\n    store->clear(targets);\n\n    // make sure paxos knows it has been reset.  this prevents a\n    // bootstrap and then different probe reply order from possibly\n    // deciding a partial or no sync is needed.\n    paxos->init();\n\n    assert(g_conf->mon_sync_requester_kill_at != 2);\n  }\n\n  // assume 'other' as the leader. We will update the leader once we receive\n  // a reply to the sync start.\n  sync_provider = other;\n\n  sync_reset_timeout();\n\n  MMonSync *m = new MMonSync(sync_full ? MMonSync::OP_GET_COOKIE_FULL : MMonSync::OP_GET_COOKIE_RECENT);\n  if (!sync_full)\n    m->last_committed = paxos->get_version();\n  messenger->send_message(m, sync_provider);\n}\n\nvoid Monitor::sync_stash_critical_state(MonitorDBStore::TransactionRef t)\n{\n  dout(10) << __func__ << dendl;\n  bufferlist backup_monmap;\n  sync_obtain_latest_monmap(backup_monmap);\n  assert(backup_monmap.length() > 0);\n  t->put(\"mon_sync\", \"latest_monmap\", backup_monmap);\n}\n\nvoid Monitor::sync_reset_timeout()\n{\n  dout(10) << __func__ << dendl;\n  if (sync_timeout_event)\n    timer.cancel_event(sync_timeout_event);\n  sync_timeout_event = timer.add_event_after(\n    g_conf->mon_sync_timeout,\n    new C_MonContext(this, [this](int) {\n\tsync_timeout();\n      }));\n}\n\nvoid Monitor::sync_finish(version_t last_committed)\n{\n  dout(10) << __func__ << \" lc \" << last_committed << \" from \" << sync_provider << dendl;\n\n  assert(g_conf->mon_sync_requester_kill_at != 7);\n\n  if (sync_full) {\n    // finalize the paxos commits\n    auto tx(std::make_shared<MonitorDBStore::Transaction>());\n    paxos->read_and_prepare_transactions(tx, sync_start_version,\n\t\t\t\t\t last_committed);\n    tx->put(paxos->get_name(), \"last_committed\", last_committed);\n\n    dout(30) << __func__ << \" final tx dump:\\n\";\n    JSONFormatter f(true);\n    tx->dump(&f);\n    f.flush(*_dout);\n    *_dout << dendl;\n\n    store->apply_transaction(tx);\n  }\n\n  assert(g_conf->mon_sync_requester_kill_at != 8);\n\n  auto t(std::make_shared<MonitorDBStore::Transaction>());\n  t->erase(\"mon_sync\", \"in_sync\");\n  t->erase(\"mon_sync\", \"force_sync\");\n  t->erase(\"mon_sync\", \"last_committed_floor\");\n  store->apply_transaction(t);\n\n  assert(g_conf->mon_sync_requester_kill_at != 9);\n\n  init_paxos();\n\n  assert(g_conf->mon_sync_requester_kill_at != 10);\n\n  bootstrap();\n}\n\nvoid Monitor::handle_sync(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n  switch (m->op) {\n\n    // provider ---------\n\n  case MMonSync::OP_GET_COOKIE_FULL:\n  case MMonSync::OP_GET_COOKIE_RECENT:\n    handle_sync_get_cookie(op);\n    break;\n  case MMonSync::OP_GET_CHUNK:\n    handle_sync_get_chunk(op);\n    break;\n\n    // client -----------\n\n  case MMonSync::OP_COOKIE:\n    handle_sync_cookie(op);\n    break;\n\n  case MMonSync::OP_CHUNK:\n  case MMonSync::OP_LAST_CHUNK:\n    handle_sync_chunk(op);\n    break;\n  case MMonSync::OP_NO_COOKIE:\n    handle_sync_no_cookie(op);\n    break;\n\n  default:\n    dout(0) << __func__ << \" unknown op \" << m->op << dendl;\n    assert(0 == \"unknown op\");\n  }\n}\n\n// leader\n\nvoid Monitor::_sync_reply_no_cookie(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  MMonSync *reply = new MMonSync(MMonSync::OP_NO_COOKIE, m->cookie);\n  m->get_connection()->send_message(reply);\n}\n\nvoid Monitor::handle_sync_get_cookie(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  if (is_synchronizing()) {\n    _sync_reply_no_cookie(op);\n    return;\n  }\n\n  assert(g_conf->mon_sync_provider_kill_at != 1);\n\n  // make sure they can understand us.\n  if ((required_features ^ m->get_connection()->get_features()) &\n      required_features) {\n    dout(5) << \" ignoring peer mon.\" << m->get_source().num()\n\t    << \" has features \" << std::hex\n\t    << m->get_connection()->get_features()\n\t    << \" but we require \" << required_features << std::dec << dendl;\n    return;\n  }\n\n  // make up a unique cookie.  include election epoch (which persists\n  // across restarts for the whole cluster) and a counter for this\n  // process instance.  there is no need to be unique *across*\n  // monitors, though.\n  uint64_t cookie = ((unsigned long long)elector.get_epoch() << 24) + ++sync_provider_count;\n  assert(sync_providers.count(cookie) == 0);\n\n  dout(10) << __func__ << \" cookie \" << cookie << \" for \" << m->get_source_inst() << dendl;\n\n  SyncProvider& sp = sync_providers[cookie];\n  sp.cookie = cookie;\n  sp.entity = m->get_source_inst();\n  sp.reset_timeout(g_ceph_context, g_conf->mon_sync_timeout * 2);\n\n  set<string> sync_targets;\n  if (m->op == MMonSync::OP_GET_COOKIE_FULL) {\n    // full scan\n    sync_targets = get_sync_targets_names();\n    sp.last_committed = paxos->get_version();\n    sp.synchronizer = store->get_synchronizer(sp.last_key, sync_targets);\n    sp.full = true;\n    dout(10) << __func__ << \" will sync prefixes \" << sync_targets << dendl;\n  } else {\n    // just catch up paxos\n    sp.last_committed = m->last_committed;\n  }\n  dout(10) << __func__ << \" will sync from version \" << sp.last_committed << dendl;\n\n  MMonSync *reply = new MMonSync(MMonSync::OP_COOKIE, sp.cookie);\n  reply->last_committed = sp.last_committed;\n  m->get_connection()->send_message(reply);\n}\n\nvoid Monitor::handle_sync_get_chunk(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n\n  if (sync_providers.count(m->cookie) == 0) {\n    dout(10) << __func__ << \" no cookie \" << m->cookie << dendl;\n    _sync_reply_no_cookie(op);\n    return;\n  }\n\n  assert(g_conf->mon_sync_provider_kill_at != 2);\n\n  SyncProvider& sp = sync_providers[m->cookie];\n  sp.reset_timeout(g_ceph_context, g_conf->mon_sync_timeout * 2);\n\n  if (sp.last_committed < paxos->get_first_committed() &&\n      paxos->get_first_committed() > 1) {\n    dout(10) << __func__ << \" sync requester fell behind paxos, their lc \" << sp.last_committed\n\t     << \" < our fc \" << paxos->get_first_committed() << dendl;\n    sync_providers.erase(m->cookie);\n    _sync_reply_no_cookie(op);\n    return;\n  }\n\n  MMonSync *reply = new MMonSync(MMonSync::OP_CHUNK, sp.cookie);\n  auto tx(std::make_shared<MonitorDBStore::Transaction>());\n\n  int left = g_conf->mon_sync_max_payload_size;\n  while (sp.last_committed < paxos->get_version() && left > 0) {\n    bufferlist bl;\n    sp.last_committed++;\n\n    int err = store->get(paxos->get_name(), sp.last_committed, bl);\n    assert(err == 0);\n\n    tx->put(paxos->get_name(), sp.last_committed, bl);\n    left -= bl.length();\n    dout(20) << __func__ << \" including paxos state \" << sp.last_committed\n\t     << dendl;\n  }\n  reply->last_committed = sp.last_committed;\n\n  if (sp.full && left > 0) {\n    sp.synchronizer->get_chunk_tx(tx, left);\n    sp.last_key = sp.synchronizer->get_last_key();\n    reply->last_key = sp.last_key;\n  }\n\n  if ((sp.full && sp.synchronizer->has_next_chunk()) ||\n      sp.last_committed < paxos->get_version()) {\n    dout(10) << __func__ << \" chunk, through version \" << sp.last_committed\n\t     << \" key \" << sp.last_key << dendl;\n  } else {\n    dout(10) << __func__ << \" last chunk, through version \" << sp.last_committed\n\t     << \" key \" << sp.last_key << dendl;\n    reply->op = MMonSync::OP_LAST_CHUNK;\n\n    assert(g_conf->mon_sync_provider_kill_at != 3);\n\n    // clean up our local state\n    sync_providers.erase(sp.cookie);\n  }\n\n  ::encode(*tx, reply->chunk_bl);\n\n  m->get_connection()->send_message(reply);\n}\n\n// requester\n\nvoid Monitor::handle_sync_cookie(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n  if (sync_cookie) {\n    dout(10) << __func__ << \" already have a cookie, ignoring\" << dendl;\n    return;\n  }\n  if (m->get_source_inst() != sync_provider) {\n    dout(10) << __func__ << \" source does not match, discarding\" << dendl;\n    return;\n  }\n  sync_cookie = m->cookie;\n  sync_start_version = m->last_committed;\n\n  sync_reset_timeout();\n  sync_get_next_chunk();\n\n  assert(g_conf->mon_sync_requester_kill_at != 3);\n}\n\nvoid Monitor::sync_get_next_chunk()\n{\n  dout(20) << __func__ << \" cookie \" << sync_cookie << \" provider \" << sync_provider << dendl;\n  if (g_conf->mon_inject_sync_get_chunk_delay > 0) {\n    dout(20) << __func__ << \" injecting delay of \" << g_conf->mon_inject_sync_get_chunk_delay << dendl;\n    usleep((long long)(g_conf->mon_inject_sync_get_chunk_delay * 1000000.0));\n  }\n  MMonSync *r = new MMonSync(MMonSync::OP_GET_CHUNK, sync_cookie);\n  messenger->send_message(r, sync_provider);\n\n  assert(g_conf->mon_sync_requester_kill_at != 4);\n}\n\nvoid Monitor::handle_sync_chunk(MonOpRequestRef op)\n{\n  MMonSync *m = static_cast<MMonSync*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n\n  if (m->cookie != sync_cookie) {\n    dout(10) << __func__ << \" cookie does not match, discarding\" << dendl;\n    return;\n  }\n  if (m->get_source_inst() != sync_provider) {\n    dout(10) << __func__ << \" source does not match, discarding\" << dendl;\n    return;\n  }\n\n  assert(state == STATE_SYNCHRONIZING);\n  assert(g_conf->mon_sync_requester_kill_at != 5);\n\n  auto tx(std::make_shared<MonitorDBStore::Transaction>());\n  tx->append_from_encoded(m->chunk_bl);\n\n  dout(30) << __func__ << \" tx dump:\\n\";\n  JSONFormatter f(true);\n  tx->dump(&f);\n  f.flush(*_dout);\n  *_dout << dendl;\n\n  store->apply_transaction(tx);\n\n  assert(g_conf->mon_sync_requester_kill_at != 6);\n\n  if (!sync_full) {\n    dout(10) << __func__ << \" applying recent paxos transactions as we go\" << dendl;\n    auto tx(std::make_shared<MonitorDBStore::Transaction>());\n    paxos->read_and_prepare_transactions(tx, paxos->get_version() + 1,\n\t\t\t\t\t m->last_committed);\n    tx->put(paxos->get_name(), \"last_committed\", m->last_committed);\n\n    dout(30) << __func__ << \" tx dump:\\n\";\n    JSONFormatter f(true);\n    tx->dump(&f);\n    f.flush(*_dout);\n    *_dout << dendl;\n\n    store->apply_transaction(tx);\n    paxos->init();  // to refresh what we just wrote\n  }\n\n  if (m->op == MMonSync::OP_CHUNK) {\n    sync_reset_timeout();\n    sync_get_next_chunk();\n  } else if (m->op == MMonSync::OP_LAST_CHUNK) {\n    sync_finish(m->last_committed);\n  }\n}\n\nvoid Monitor::handle_sync_no_cookie(MonOpRequestRef op)\n{\n  dout(10) << __func__ << dendl;\n  bootstrap();\n}\n\nvoid Monitor::sync_trim_providers()\n{\n  dout(20) << __func__ << dendl;\n\n  utime_t now = ceph_clock_now();\n  map<uint64_t,SyncProvider>::iterator p = sync_providers.begin();\n  while (p != sync_providers.end()) {\n    if (now > p->second.timeout) {\n      dout(10) << __func__ << \" expiring cookie \" << p->second.cookie << \" for \" << p->second.entity << dendl;\n      sync_providers.erase(p++);\n    } else {\n      ++p;\n    }\n  }\n}\n\n// ---------------------------------------------------\n// probe\n\nvoid Monitor::cancel_probe_timeout()\n{\n  if (probe_timeout_event) {\n    dout(10) << \"cancel_probe_timeout \" << probe_timeout_event << dendl;\n    timer.cancel_event(probe_timeout_event);\n    probe_timeout_event = NULL;\n  } else {\n    dout(10) << \"cancel_probe_timeout (none scheduled)\" << dendl;\n  }\n}\n\nvoid Monitor::reset_probe_timeout()\n{\n  cancel_probe_timeout();\n  probe_timeout_event = new C_MonContext(this, [this](int r) {\n      probe_timeout(r);\n    });\n  double t = g_conf->mon_probe_timeout;\n  if (timer.add_event_after(t, probe_timeout_event)) {\n    dout(10) << \"reset_probe_timeout \" << probe_timeout_event\n\t     << \" after \" << t << \" seconds\" << dendl;\n  } else {\n    probe_timeout_event = nullptr;\n  }\n}\n\nvoid Monitor::probe_timeout(int r)\n{\n  dout(4) << \"probe_timeout \" << probe_timeout_event << dendl;\n  assert(is_probing() || is_synchronizing());\n  assert(probe_timeout_event);\n  probe_timeout_event = NULL;\n  bootstrap();\n}\n\nvoid Monitor::handle_probe(MonOpRequestRef op)\n{\n  MMonProbe *m = static_cast<MMonProbe*>(op->get_req());\n  dout(10) << \"handle_probe \" << *m << dendl;\n\n  if (m->fsid != monmap->fsid) {\n    dout(0) << \"handle_probe ignoring fsid \" << m->fsid << \" != \" << monmap->fsid << dendl;\n    return;\n  }\n\n  switch (m->op) {\n  case MMonProbe::OP_PROBE:\n    handle_probe_probe(op);\n    break;\n\n  case MMonProbe::OP_REPLY:\n    handle_probe_reply(op);\n    break;\n\n  case MMonProbe::OP_MISSING_FEATURES:\n    derr << __func__ << \" missing features, have \" << CEPH_FEATURES_ALL\n\t << \", required \" << m->required_features\n\t << \", missing \" << (m->required_features & ~CEPH_FEATURES_ALL)\n\t << dendl;\n    break;\n  }\n}\n\nvoid Monitor::handle_probe_probe(MonOpRequestRef op)\n{\n  MMonProbe *m = static_cast<MMonProbe*>(op->get_req());\n\n  dout(10) << \"handle_probe_probe \" << m->get_source_inst() << *m\n\t   << \" features \" << m->get_connection()->get_features() << dendl;\n  uint64_t missing = required_features & ~m->get_connection()->get_features();\n  if (missing) {\n    dout(1) << \" peer \" << m->get_source_addr() << \" missing features \"\n\t    << missing << dendl;\n    if (m->get_connection()->has_feature(CEPH_FEATURE_OSD_PRIMARY_AFFINITY)) {\n      MMonProbe *r = new MMonProbe(monmap->fsid, MMonProbe::OP_MISSING_FEATURES,\n\t\t\t\t   name, has_ever_joined);\n      m->required_features = required_features;\n      m->get_connection()->send_message(r);\n    }\n    goto out;\n  }\n\n  if (!is_probing() && !is_synchronizing()) {\n    // If the probing mon is way ahead of us, we need to re-bootstrap.\n    // Normally we capture this case when we initially bootstrap, but\n    // it is possible we pass those checks (we overlap with\n    // quorum-to-be) but fail to join a quorum before it moves past\n    // us.  We need to be kicked back to bootstrap so we can\n    // synchonize, not keep calling elections.\n    if (paxos->get_version() + 1 < m->paxos_first_version) {\n      dout(1) << \" peer \" << m->get_source_addr() << \" has first_committed \"\n\t      << \"ahead of us, re-bootstrapping\" << dendl;\n      bootstrap();\n      goto out;\n\n    }\n  }\n  \n  MMonProbe *r;\n  r = new MMonProbe(monmap->fsid, MMonProbe::OP_REPLY, name, has_ever_joined);\n  r->name = name;\n  r->quorum = quorum;\n  monmap->encode(r->monmap_bl, m->get_connection()->get_features());\n  r->paxos_first_version = paxos->get_first_committed();\n  r->paxos_last_version = paxos->get_version();\n  m->get_connection()->send_message(r);\n\n  // did we discover a peer here?\n  if (!monmap->contains(m->get_source_addr())) {\n    dout(1) << \" adding peer \" << m->get_source_addr()\n\t    << \" to list of hints\" << dendl;\n    extra_probe_peers.insert(m->get_source_addr());\n  }\n\n out:\n  return;\n}\n\nvoid Monitor::handle_probe_reply(MonOpRequestRef op)\n{\n  MMonProbe *m = static_cast<MMonProbe*>(op->get_req());\n  dout(10) << \"handle_probe_reply \" << m->get_source_inst() << *m << dendl;\n  dout(10) << \" monmap is \" << *monmap << dendl;\n\n  // discover name and addrs during probing or electing states.\n  if (!is_probing() && !is_electing()) {\n    return;\n  }\n\n  // newer map, or they've joined a quorum and we haven't?\n  bufferlist mybl;\n  monmap->encode(mybl, m->get_connection()->get_features());\n  // make sure it's actually different; the checks below err toward\n  // taking the other guy's map, which could cause us to loop.\n  if (!mybl.contents_equal(m->monmap_bl)) {\n    MonMap *newmap = new MonMap;\n    newmap->decode(m->monmap_bl);\n    if (m->has_ever_joined && (newmap->get_epoch() > monmap->get_epoch() ||\n\t\t\t       !has_ever_joined)) {\n      dout(10) << \" got newer/committed monmap epoch \" << newmap->get_epoch()\n\t       << \", mine was \" << monmap->get_epoch() << dendl;\n      delete newmap;\n      monmap->decode(m->monmap_bl);\n\n      bootstrap();\n      return;\n    }\n    delete newmap;\n  }\n\n  // rename peer?\n  string peer_name = monmap->get_name(m->get_source_addr());\n  if (monmap->get_epoch() == 0 && peer_name.compare(0, 7, \"noname-\") == 0) {\n    dout(10) << \" renaming peer \" << m->get_source_addr() << \" \"\n\t     << peer_name << \" -> \" << m->name << \" in my monmap\"\n\t     << dendl;\n    monmap->rename(peer_name, m->name);\n\n    if (is_electing()) {\n      bootstrap();\n      return;\n    }\n  } else {\n    dout(10) << \" peer name is \" << peer_name << dendl;\n  }\n\n  // new initial peer?\n  if (monmap->get_epoch() == 0 &&\n      monmap->contains(m->name) &&\n      monmap->get_addr(m->name).is_blank_ip()) {\n    dout(1) << \" learned initial mon \" << m->name << \" addr \" << m->get_source_addr() << dendl;\n    monmap->set_addr(m->name, m->get_source_addr());\n\n    bootstrap();\n    return;\n  }\n\n  // end discover phase\n  if (!is_probing()) {\n    return;\n  }\n\n  assert(paxos != NULL);\n\n  if (is_synchronizing()) {\n    dout(10) << \" currently syncing\" << dendl;\n    return;\n  }\n\n  entity_inst_t other = m->get_source_inst();\n\n  if (m->paxos_last_version < sync_last_committed_floor) {\n    dout(10) << \" peer paxos versions [\" << m->paxos_first_version\n\t     << \",\" << m->paxos_last_version << \"] < my sync_last_committed_floor \"\n\t     << sync_last_committed_floor << \", ignoring\"\n\t     << dendl;\n  } else {\n    if (paxos->get_version() < m->paxos_first_version &&\n\tm->paxos_first_version > 1) {  // no need to sync if we're 0 and they start at 1.\n      dout(10) << \" peer paxos first versions [\" << m->paxos_first_version\n\t       << \",\" << m->paxos_last_version << \"]\"\n\t       << \" vs my version \" << paxos->get_version()\n\t       << \" (too far ahead)\"\n\t       << dendl;\n      cancel_probe_timeout();\n      sync_start(other, true);\n      return;\n    }\n    if (paxos->get_version() + g_conf->paxos_max_join_drift < m->paxos_last_version) {\n      dout(10) << \" peer paxos last version \" << m->paxos_last_version\n\t       << \" vs my version \" << paxos->get_version()\n\t       << \" (too far ahead)\"\n\t       << dendl;\n      cancel_probe_timeout();\n      sync_start(other, false);\n      return;\n    }\n  }\n\n  // is there an existing quorum?\n  if (m->quorum.size()) {\n    dout(10) << \" existing quorum \" << m->quorum << dendl;\n\n    dout(10) << \" peer paxos version \" << m->paxos_last_version\n             << \" vs my version \" << paxos->get_version()\n             << \" (ok)\"\n             << dendl;\n\n    if (monmap->contains(name) &&\n        !monmap->get_addr(name).is_blank_ip()) {\n      // i'm part of the cluster; just initiate a new election\n      start_election();\n    } else {\n      dout(10) << \" ready to join, but i'm not in the monmap or my addr is blank, trying to join\" << dendl;\n      messenger->send_message(new MMonJoin(monmap->fsid, name, messenger->get_myaddr()),\n                              monmap->get_inst(*m->quorum.begin()));\n    }\n  } else {\n    if (monmap->contains(m->name)) {\n      dout(10) << \" mon.\" << m->name << \" is outside the quorum\" << dendl;\n      outside_quorum.insert(m->name);\n    } else {\n      dout(10) << \" mostly ignoring mon.\" << m->name << \", not part of monmap\" << dendl;\n      return;\n    }\n\n    unsigned need = monmap->size() / 2 + 1;\n    dout(10) << \" outside_quorum now \" << outside_quorum << \", need \" << need << dendl;\n    if (outside_quorum.size() >= need) {\n      if (outside_quorum.count(name)) {\n        dout(10) << \" that's enough to form a new quorum, calling election\" << dendl;\n        start_election();\n      } else {\n        dout(10) << \" that's enough to form a new quorum, but it does not include me; waiting\" << dendl;\n      }\n    } else {\n      dout(10) << \" that's not yet enough for a new quorum, waiting\" << dendl;\n    }\n  }\n}\n\nvoid Monitor::join_election()\n{\n  dout(10) << __func__ << dendl;\n  wait_for_paxos_write();\n  _reset();\n  state = STATE_ELECTING;\n\n  logger->inc(l_mon_num_elections);\n}\n\nvoid Monitor::start_election()\n{\n  dout(10) << \"start_election\" << dendl;\n  wait_for_paxos_write();\n  _reset();\n  state = STATE_ELECTING;\n\n  logger->inc(l_mon_num_elections);\n  logger->inc(l_mon_election_call);\n\n  clog->info() << \"mon.\" << name << \" calling monitor election\";\n  elector.call_election();\n}\n\nvoid Monitor::win_standalone_election()\n{\n  dout(1) << \"win_standalone_election\" << dendl;\n\n  // bump election epoch, in case the previous epoch included other\n  // monitors; we need to be able to make the distinction.\n  elector.init();\n  elector.advance_epoch();\n\n  rank = monmap->get_rank(name);\n  assert(rank == 0);\n  set<int> q;\n  q.insert(rank);\n\n  map<int,Metadata> metadata;\n  collect_metadata(&metadata[0]);\n\n  win_election(elector.get_epoch(), q,\n               CEPH_FEATURES_ALL,\n               ceph::features::mon::get_supported(),\n\t       metadata);\n}\n\nconst utime_t& Monitor::get_leader_since() const\n{\n  assert(state == STATE_LEADER);\n  return leader_since;\n}\n\nepoch_t Monitor::get_epoch()\n{\n  return elector.get_epoch();\n}\n\nvoid Monitor::_finish_svc_election()\n{\n  assert(state == STATE_LEADER || state == STATE_PEON);\n\n  for (auto p : paxos_service) {\n    // we already called election_finished() on monmon(); avoid callig twice\n    if (state == STATE_LEADER && p == monmon())\n      continue;\n    p->election_finished();\n  }\n}\n\nvoid Monitor::win_election(epoch_t epoch, set<int>& active, uint64_t features,\n                           const mon_feature_t& mon_features,\n\t\t\t   const map<int,Metadata>& metadata)\n{\n  dout(10) << __func__ << \" epoch \" << epoch << \" quorum \" << active\n\t   << \" features \" << features\n           << \" mon_features \" << mon_features\n           << dendl;\n  assert(is_electing());\n  state = STATE_LEADER;\n  leader_since = ceph_clock_now();\n  leader = rank;\n  quorum = active;\n  quorum_con_features = features;\n  quorum_mon_features = mon_features;\n  pending_metadata = metadata;\n  outside_quorum.clear();\n\n  clog->info() << \"mon.\" << name << \" is new leader, mons \" << get_quorum_names()\n      << \" in quorum (ranks \" << quorum << \")\";\n\n  set_leader_commands(get_local_commands(mon_features));\n\n  paxos->leader_init();\n  // NOTE: tell monmap monitor first.  This is important for the\n  // bootstrap case to ensure that the very first paxos proposal\n  // codifies the monmap.  Otherwise any manner of chaos can ensue\n  // when monitors are call elections or participating in a paxos\n  // round without agreeing on who the participants are.\n  monmon()->election_finished();\n  _finish_svc_election();\n  health_monitor->start(epoch);\n\n  logger->inc(l_mon_election_win);\n\n  // inject new metadata in first transaction.\n  {\n    // include previous metadata for missing mons (that aren't part of\n    // the current quorum).\n    map<int,Metadata> m = metadata;\n    for (unsigned rank = 0; rank < monmap->size(); ++rank) {\n      if (m.count(rank) == 0 &&\n\t  mon_metadata.count(rank)) {\n\tm[rank] = mon_metadata[rank];\n      }\n    }\n\n    // FIXME: This is a bit sloppy because we aren't guaranteed to submit\n    // a new transaction immediately after the election finishes.  We should\n    // do that anyway for other reasons, though.\n    MonitorDBStore::TransactionRef t = paxos->get_pending_transaction();\n    bufferlist bl;\n    ::encode(m, bl);\n    t->put(MONITOR_STORE_PREFIX, \"last_metadata\", bl);\n  }\n\n  finish_election();\n  if (monmap->size() > 1 &&\n      monmap->get_epoch() > 0) {\n    timecheck_start();\n    health_tick_start();\n\n    // Freshen the health status before doing health_to_clog in case\n    // our just-completed election changed the health\n    healthmon()->wait_for_active_ctx(new FunctionContext([this](int r){\n      dout(20) << \"healthmon now active\" << dendl;\n      healthmon()->tick();\n      if (healthmon()->is_proposing()) {\n        dout(20) << __func__ << \" healthmon proposing, waiting\" << dendl;\n        healthmon()->wait_for_finished_proposal(nullptr, new C_MonContext(this,\n              [this](int r){\n                assert(lock.is_locked_by_me());\n                do_health_to_clog_interval();\n              }));\n\n      } else {\n        do_health_to_clog_interval();\n      }\n    }));\n\n    scrub_event_start();\n  }\n}\n\nvoid Monitor::lose_election(epoch_t epoch, set<int> &q, int l,\n                            uint64_t features,\n                            const mon_feature_t& mon_features)\n{\n  state = STATE_PEON;\n  leader_since = utime_t();\n  leader = l;\n  quorum = q;\n  outside_quorum.clear();\n  quorum_con_features = features;\n  quorum_mon_features = mon_features;\n  dout(10) << \"lose_election, epoch \" << epoch << \" leader is mon\" << leader\n\t   << \" quorum is \" << quorum << \" features are \" << quorum_con_features\n           << \" mon_features are \" << quorum_mon_features\n           << dendl;\n\n  paxos->peon_init();\n  _finish_svc_election();\n  health_monitor->start(epoch);\n\n  logger->inc(l_mon_election_lose);\n\n  finish_election();\n\n  if ((quorum_con_features & CEPH_FEATURE_MON_METADATA) &&\n      !HAVE_FEATURE(quorum_con_features, SERVER_LUMINOUS)) {\n    // for pre-luminous mons only\n    Metadata sys_info;\n    collect_metadata(&sys_info);\n    messenger->send_message(new MMonMetadata(sys_info),\n\t\t\t    monmap->get_inst(get_leader()));\n  }\n}\n\nvoid Monitor::collect_metadata(Metadata *m)\n{\n  collect_sys_info(m, g_ceph_context);\n  (*m)[\"addr\"] = stringify(messenger->get_myaddr());\n}\n\nvoid Monitor::finish_election()\n{\n  apply_quorum_to_compatset_features();\n  apply_monmap_to_compatset_features();\n  timecheck_finish();\n  exited_quorum = utime_t();\n  finish_contexts(g_ceph_context, waitfor_quorum);\n  finish_contexts(g_ceph_context, maybe_wait_for_quorum);\n  resend_routed_requests();\n  update_logger();\n  register_cluster_logger();\n\n  // am i named properly?\n  string cur_name = monmap->get_name(messenger->get_myaddr());\n  if (cur_name != name) {\n    dout(10) << \" renaming myself from \" << cur_name << \" -> \" << name << dendl;\n    messenger->send_message(new MMonJoin(monmap->fsid, name, messenger->get_myaddr()),\n\t\t\t    monmap->get_inst(*quorum.begin()));\n  }\n}\n\nvoid Monitor::_apply_compatset_features(CompatSet &new_features)\n{\n  if (new_features.compare(features) != 0) {\n    CompatSet diff = features.unsupported(new_features);\n    dout(1) << __func__ << \" enabling new quorum features: \" << diff << dendl;\n    features = new_features;\n\n    auto t = std::make_shared<MonitorDBStore::Transaction>();\n    write_features(t);\n    store->apply_transaction(t);\n\n    calc_quorum_requirements();\n  }\n}\n\nvoid Monitor::apply_quorum_to_compatset_features()\n{\n  CompatSet new_features(features);\n  if (quorum_con_features & CEPH_FEATURE_OSD_ERASURE_CODES) {\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_OSD_ERASURE_CODES);\n  }\n  if (quorum_con_features & CEPH_FEATURE_OSDMAP_ENC) {\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_OSDMAP_ENC);\n  }\n  if (quorum_con_features & CEPH_FEATURE_ERASURE_CODE_PLUGINS_V2) {\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V2);\n  }\n  if (quorum_con_features & CEPH_FEATURE_ERASURE_CODE_PLUGINS_V3) {\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V3);\n  }\n  dout(5) << __func__ << dendl;\n  _apply_compatset_features(new_features);\n}\n\nvoid Monitor::apply_monmap_to_compatset_features()\n{\n  CompatSet new_features(features);\n  mon_feature_t monmap_features = monmap->get_required_features();\n\n  /* persistent monmap features may go into the compatset.\n   * optional monmap features may not - why?\n   *   because optional monmap features may be set/unset by the admin,\n   *   and possibly by other means that haven't yet been thought out,\n   *   so we can't make the monitor enforce them on start - because they\n   *   may go away.\n   *   this, of course, does not invalidate setting a compatset feature\n   *   for an optional feature - as long as you make sure to clean it up\n   *   once you unset it.\n   */\n  if (monmap_features.contains_all(ceph::features::mon::FEATURE_KRAKEN)) {\n    assert(ceph::features::mon::get_persistent().contains_all(\n           ceph::features::mon::FEATURE_KRAKEN));\n    // this feature should only ever be set if the quorum supports it.\n    assert(HAVE_FEATURE(quorum_con_features, SERVER_KRAKEN));\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_KRAKEN);\n  }\n  if (monmap_features.contains_all(ceph::features::mon::FEATURE_LUMINOUS)) {\n    assert(ceph::features::mon::get_persistent().contains_all(\n           ceph::features::mon::FEATURE_LUMINOUS));\n    // this feature should only ever be set if the quorum supports it.\n    assert(HAVE_FEATURE(quorum_con_features, SERVER_LUMINOUS));\n    new_features.incompat.insert(CEPH_MON_FEATURE_INCOMPAT_LUMINOUS);\n  }\n\n  dout(5) << __func__ << dendl;\n  _apply_compatset_features(new_features);\n}\n\nvoid Monitor::calc_quorum_requirements()\n{\n  required_features = 0;\n\n  // compatset\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_OSD_ERASURE_CODES)) {\n    required_features |= CEPH_FEATURE_OSD_ERASURE_CODES;\n  }\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_OSDMAP_ENC)) {\n    required_features |= CEPH_FEATURE_OSDMAP_ENC;\n  }\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V2)) {\n    required_features |= CEPH_FEATURE_ERASURE_CODE_PLUGINS_V2;\n  }\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V3)) {\n    required_features |= CEPH_FEATURE_ERASURE_CODE_PLUGINS_V3;\n  }\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_KRAKEN)) {\n    required_features |= CEPH_FEATUREMASK_SERVER_KRAKEN;\n  }\n  if (features.incompat.contains(CEPH_MON_FEATURE_INCOMPAT_LUMINOUS)) {\n    required_features |= CEPH_FEATUREMASK_SERVER_LUMINOUS;\n  }\n\n  // monmap\n  if (monmap->get_required_features().contains_all(\n\tceph::features::mon::FEATURE_KRAKEN)) {\n    required_features |= CEPH_FEATUREMASK_SERVER_KRAKEN;\n  }\n  if (monmap->get_required_features().contains_all(\n\tceph::features::mon::FEATURE_LUMINOUS)) {\n    required_features |= CEPH_FEATUREMASK_SERVER_LUMINOUS;\n  }\n  dout(10) << __func__ << \" required_features \" << required_features << dendl;\n}\n\nvoid Monitor::get_combined_feature_map(FeatureMap *fm)\n{\n  *fm += session_map.feature_map;\n  for (auto id : quorum) {\n    if (id != rank) {\n      *fm += quorum_feature_map[id];\n    }\n  }\n}\n\nvoid Monitor::sync_force(Formatter *f, ostream& ss)\n{\n  bool free_formatter = false;\n\n  if (!f) {\n    // louzy/lazy hack: default to json if no formatter has been defined\n    f = new JSONFormatter();\n    free_formatter = true;\n  }\n\n  auto tx(std::make_shared<MonitorDBStore::Transaction>());\n  sync_stash_critical_state(tx);\n  tx->put(\"mon_sync\", \"force_sync\", 1);\n  store->apply_transaction(tx);\n\n  f->open_object_section(\"sync_force\");\n  f->dump_int(\"ret\", 0);\n  f->dump_stream(\"msg\") << \"forcing store sync the next time the monitor starts\";\n  f->close_section(); // sync_force\n  f->flush(ss);\n  if (free_formatter)\n    delete f;\n}\n\nvoid Monitor::_quorum_status(Formatter *f, ostream& ss)\n{\n  bool free_formatter = false;\n\n  if (!f) {\n    // louzy/lazy hack: default to json if no formatter has been defined\n    f = new JSONFormatter();\n    free_formatter = true;\n  }\n  f->open_object_section(\"quorum_status\");\n  f->dump_int(\"election_epoch\", get_epoch());\n\n  f->open_array_section(\"quorum\");\n  for (set<int>::iterator p = quorum.begin(); p != quorum.end(); ++p)\n    f->dump_int(\"mon\", *p);\n  f->close_section(); // quorum\n\n  list<string> quorum_names = get_quorum_names();\n  f->open_array_section(\"quorum_names\");\n  for (list<string>::iterator p = quorum_names.begin(); p != quorum_names.end(); ++p)\n    f->dump_string(\"mon\", *p);\n  f->close_section(); // quorum_names\n\n  f->dump_string(\"quorum_leader_name\", quorum.empty() ? string() : monmap->get_name(*quorum.begin()));\n\n  f->open_object_section(\"monmap\");\n  monmap->dump(f);\n  f->close_section(); // monmap\n\n  f->close_section(); // quorum_status\n  f->flush(ss);\n  if (free_formatter)\n    delete f;\n}\n\nvoid Monitor::get_mon_status(Formatter *f, ostream& ss)\n{\n  bool free_formatter = false;\n\n  if (!f) {\n    // louzy/lazy hack: default to json if no formatter has been defined\n    f = new JSONFormatter();\n    free_formatter = true;\n  }\n\n  f->open_object_section(\"mon_status\");\n  f->dump_string(\"name\", name);\n  f->dump_int(\"rank\", rank);\n  f->dump_string(\"state\", get_state_name());\n  f->dump_int(\"election_epoch\", get_epoch());\n\n  f->open_array_section(\"quorum\");\n  for (set<int>::iterator p = quorum.begin(); p != quorum.end(); ++p) {\n    f->dump_int(\"mon\", *p);\n  }\n\n  f->close_section(); // quorum\n\n  f->open_object_section(\"features\");\n  f->dump_stream(\"required_con\") << required_features;\n  mon_feature_t req_mon_features = get_required_mon_features();\n  req_mon_features.dump(f, \"required_mon\");\n  f->dump_stream(\"quorum_con\") << quorum_con_features;\n  quorum_mon_features.dump(f, \"quorum_mon\");\n  f->close_section(); // features\n\n  f->open_array_section(\"outside_quorum\");\n  for (set<string>::iterator p = outside_quorum.begin(); p != outside_quorum.end(); ++p)\n    f->dump_string(\"mon\", *p);\n  f->close_section(); // outside_quorum\n\n  f->open_array_section(\"extra_probe_peers\");\n  for (set<entity_addr_t>::iterator p = extra_probe_peers.begin();\n       p != extra_probe_peers.end();\n       ++p)\n    f->dump_stream(\"peer\") << *p;\n  f->close_section(); // extra_probe_peers\n\n  f->open_array_section(\"sync_provider\");\n  for (map<uint64_t,SyncProvider>::const_iterator p = sync_providers.begin();\n       p != sync_providers.end();\n       ++p) {\n    f->dump_unsigned(\"cookie\", p->second.cookie);\n    f->dump_stream(\"entity\") << p->second.entity;\n    f->dump_stream(\"timeout\") << p->second.timeout;\n    f->dump_unsigned(\"last_committed\", p->second.last_committed);\n    f->dump_stream(\"last_key\") << p->second.last_key;\n  }\n  f->close_section();\n\n  if (is_synchronizing()) {\n    f->open_object_section(\"sync\");\n    f->dump_stream(\"sync_provider\") << sync_provider;\n    f->dump_unsigned(\"sync_cookie\", sync_cookie);\n    f->dump_unsigned(\"sync_start_version\", sync_start_version);\n    f->close_section();\n  }\n\n  if (g_conf->mon_sync_provider_kill_at > 0)\n    f->dump_int(\"provider_kill_at\", g_conf->mon_sync_provider_kill_at);\n  if (g_conf->mon_sync_requester_kill_at > 0)\n    f->dump_int(\"requester_kill_at\", g_conf->mon_sync_requester_kill_at);\n\n  f->open_object_section(\"monmap\");\n  monmap->dump(f);\n  f->close_section();\n\n  f->dump_object(\"feature_map\", session_map.feature_map);\n  f->close_section(); // mon_status\n\n  if (free_formatter) {\n    // flush formatter to ss and delete it iff we created the formatter\n    f->flush(ss);\n    delete f;\n  }\n}\n\n\n// health status to clog\n\nvoid Monitor::health_tick_start()\n{\n  if (!cct->_conf->mon_health_to_clog ||\n      cct->_conf->mon_health_to_clog_tick_interval <= 0)\n    return;\n\n  dout(15) << __func__ << dendl;\n\n  health_tick_stop();\n  health_tick_event = timer.add_event_after(\n    cct->_conf->mon_health_to_clog_tick_interval,\n    new C_MonContext(this, [this](int r) {\n\tif (r < 0)\n\t  return;\n\thealth_tick_start();\n      }));\n}\n\nvoid Monitor::health_tick_stop()\n{\n  dout(15) << __func__ << dendl;\n\n  if (health_tick_event) {\n    timer.cancel_event(health_tick_event);\n    health_tick_event = NULL;\n  }\n}\n\nutime_t Monitor::health_interval_calc_next_update()\n{\n  utime_t now = ceph_clock_now();\n\n  time_t secs = now.sec();\n  int remainder = secs % cct->_conf->mon_health_to_clog_interval;\n  int adjustment = cct->_conf->mon_health_to_clog_interval - remainder;\n  utime_t next = utime_t(secs + adjustment, 0);\n\n  dout(20) << __func__\n    << \" now: \" << now << \",\"\n    << \" next: \" << next << \",\"\n    << \" interval: \" << cct->_conf->mon_health_to_clog_interval\n    << dendl;\n\n  return next;\n}\n\nvoid Monitor::health_interval_start()\n{\n  dout(15) << __func__ << dendl;\n\n  if (!cct->_conf->mon_health_to_clog ||\n      cct->_conf->mon_health_to_clog_interval <= 0) {\n    return;\n  }\n\n  health_interval_stop();\n  utime_t next = health_interval_calc_next_update();\n  health_interval_event = new C_MonContext(this, [this](int r) {\n      if (r < 0)\n        return;\n      do_health_to_clog_interval();\n    });\n  if (!timer.add_event_at(next, health_interval_event)) {\n    health_interval_event = nullptr;\n  }\n}\n\nvoid Monitor::health_interval_stop()\n{\n  dout(15) << __func__ << dendl;\n  if (health_interval_event) {\n    timer.cancel_event(health_interval_event);\n  }\n  health_interval_event = NULL;\n}\n\nvoid Monitor::health_events_cleanup()\n{\n  health_tick_stop();\n  health_interval_stop();\n  health_status_cache.reset();\n}\n\nvoid Monitor::health_to_clog_update_conf(const std::set<std::string> &changed)\n{\n  dout(20) << __func__ << dendl;\n\n  if (changed.count(\"mon_health_to_clog\")) {\n    if (!cct->_conf->mon_health_to_clog) {\n      health_events_cleanup();\n    } else {\n      if (!health_tick_event) {\n        health_tick_start();\n      }\n      if (!health_interval_event) {\n        health_interval_start();\n      }\n    }\n  }\n\n  if (changed.count(\"mon_health_to_clog_interval\")) {\n    if (cct->_conf->mon_health_to_clog_interval <= 0) {\n      health_interval_stop();\n    } else {\n      health_interval_start();\n    }\n  }\n\n  if (changed.count(\"mon_health_to_clog_tick_interval\")) {\n    if (cct->_conf->mon_health_to_clog_tick_interval <= 0) {\n      health_tick_stop();\n    } else {\n      health_tick_start();\n    }\n  }\n}\n\nvoid Monitor::do_health_to_clog_interval()\n{\n  // outputting to clog may have been disabled in the conf\n  // since we were scheduled.\n  if (!cct->_conf->mon_health_to_clog ||\n      cct->_conf->mon_health_to_clog_interval <= 0)\n    return;\n\n  dout(10) << __func__ << dendl;\n\n  // do we have a cached value for next_clog_update?  if not,\n  // do we know when the last update was?\n\n  do_health_to_clog(true);\n  health_interval_start();\n}\n\nvoid Monitor::do_health_to_clog(bool force)\n{\n  // outputting to clog may have been disabled in the conf\n  // since we were scheduled.\n  if (!cct->_conf->mon_health_to_clog ||\n      cct->_conf->mon_health_to_clog_interval <= 0)\n    return;\n\n  dout(10) << __func__ << (force ? \" (force)\" : \"\") << dendl;\n\n  if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n    string summary;\n    health_status_t level = get_health_status(false, nullptr, &summary);\n    if (!force &&\n\tsummary == health_status_cache.summary &&\n\tlevel == health_status_cache.overall)\n      return;\n    clog->health(level) << \"overall \" << summary;\n    health_status_cache.summary = summary;\n    health_status_cache.overall = level;\n  } else {\n    // for jewel only\n    list<string> status;\n    health_status_t overall = get_health(status, NULL, NULL);\n    dout(25) << __func__\n\t     << (force ? \" (force)\" : \"\")\n\t     << dendl;\n\n    string summary = joinify(status.begin(), status.end(), string(\"; \"));\n\n    if (!force &&\n\toverall == health_status_cache.overall &&\n\t!health_status_cache.summary.empty() &&\n\thealth_status_cache.summary == summary) {\n      // we got a dup!\n      return;\n    }\n\n    clog->info() << summary;\n\n    health_status_cache.overall = overall;\n    health_status_cache.summary = summary;\n  }\n}\n\nhealth_status_t Monitor::get_health_status(\n  bool want_detail,\n  Formatter *f,\n  std::string *plain,\n  const char *sep1,\n  const char *sep2)\n{\n  health_status_t r = HEALTH_OK;\n  bool compat = g_conf->mon_health_preluminous_compat;\n  bool compat_warn = g_conf->get_val<bool>(\"mon_health_preluminous_compat_warning\");\n  if (f) {\n    f->open_object_section(\"health\");\n    f->open_object_section(\"checks\");\n  }\n\n  string summary;\n  string *psummary = f ? nullptr : &summary;\n  for (auto& svc : paxos_service) {\n    r = std::min(r, svc->get_health_checks().dump_summary(\n\t\t   f, psummary, sep2, want_detail));\n  }\n\n  if (f) {\n    f->close_section();\n    f->dump_stream(\"status\") << r;\n  } else {\n    // one-liner: HEALTH_FOO[ thing1[; thing2 ...]]\n    *plain = stringify(r);\n    if (summary.size()) {\n      *plain += sep1;\n      *plain += summary;\n    }\n    *plain += \"\\n\";\n  }\n\n  const std::string old_fields_message = \"'ceph health' JSON format has \"\n    \"changed in luminous. If you see this your monitoring system is \"\n    \"scraping the wrong fields. Disable this with 'mon health preluminous \"\n    \"compat warning = false'\";\n\n  if (f && (compat || compat_warn)) {\n    health_status_t cr = compat_warn ? min(HEALTH_WARN, r) : r;\n    f->open_array_section(\"summary\");\n    if (compat_warn) {\n      f->open_object_section(\"item\");\n      f->dump_stream(\"severity\") << HEALTH_WARN;\n      f->dump_string(\"summary\", old_fields_message);\n      f->close_section();\n    }\n    if (compat) {\n      for (auto& svc : paxos_service) {\n        svc->get_health_checks().dump_summary_compat(f);\n      }\n    }\n    f->close_section();\n    f->dump_stream(\"overall_status\") << cr;\n  }\n\n  if (want_detail) {\n    if (f && (compat || compat_warn)) {\n      f->open_array_section(\"detail\");\n      if (compat_warn) {\n\tf->dump_string(\"item\", old_fields_message);\n      }\n    }\n\n    for (auto& svc : paxos_service) {\n      svc->get_health_checks().dump_detail(f, plain, compat);\n    }\n\n    if (f && (compat || compat_warn)) {\n      f->close_section();\n    }\n  }\n  if (f) {\n    f->close_section();\n  }\n  return r;\n}\n\nvoid Monitor::log_health(\n  const health_check_map_t& updated,\n  const health_check_map_t& previous,\n  MonitorDBStore::TransactionRef t)\n{\n  if (!g_conf->mon_health_to_clog) {\n    return;\n  }\n\n  const utime_t now = ceph_clock_now();\n\n  // FIXME: log atomically as part of @t instead of using clog.\n  dout(10) << __func__ << \" updated \" << updated.checks.size()\n\t   << \" previous \" << previous.checks.size()\n\t   << dendl;\n  const auto min_log_period = g_conf->get_val<int64_t>(\n      \"mon_health_log_update_period\");\n  for (auto& p : updated.checks) {\n    auto q = previous.checks.find(p.first);\n    bool logged = false;\n    if (q == previous.checks.end()) {\n      // new\n      ostringstream ss;\n      ss << \"Health check failed: \" << p.second.summary << \" (\"\n         << p.first << \")\";\n      clog->health(p.second.severity) << ss.str();\n\n      logged = true;\n    } else {\n      if (p.second.summary != q->second.summary ||\n\t  p.second.severity != q->second.severity) {\n\n        auto status_iter = health_check_log_times.find(p.first);\n        if (status_iter != health_check_log_times.end()) {\n          if (p.second.severity == q->second.severity &&\n              now - status_iter->second.updated_at < min_log_period) {\n            // We already logged this recently and the severity is unchanged,\n            // so skip emitting an update of the summary string.\n            // We'll get an update out of tick() later if the check\n            // is still failing.\n            continue;\n          }\n        }\n\n        // summary or severity changed (ignore detail changes at this level)\n        ostringstream ss;\n        ss << \"Health check update: \" << p.second.summary << \" (\" << p.first << \")\";\n        clog->health(p.second.severity) << ss.str();\n\n        logged = true;\n      }\n    }\n    // Record the time at which we last logged, so that we can check this\n    // when considering whether/when to print update messages.\n    if (logged) {\n      auto iter = health_check_log_times.find(p.first);\n      if (iter == health_check_log_times.end()) {\n        health_check_log_times.emplace(p.first, HealthCheckLogStatus(\n          p.second.severity, p.second.summary, now));\n      } else {\n        iter->second = HealthCheckLogStatus(\n          p.second.severity, p.second.summary, now);\n      }\n    }\n  }\n  for (auto& p : previous.checks) {\n    if (!updated.checks.count(p.first)) {\n      // cleared\n      ostringstream ss;\n      if (p.first == \"DEGRADED_OBJECTS\") {\n        clog->info() << \"All degraded objects recovered\";\n      } else if (p.first == \"OSD_FLAGS\") {\n        clog->info() << \"OSD flags cleared\";\n      } else {\n        clog->info() << \"Health check cleared: \" << p.first << \" (was: \"\n                     << p.second.summary << \")\";\n      }\n\n      if (health_check_log_times.count(p.first)) {\n        health_check_log_times.erase(p.first);\n      }\n    }\n  }\n\n  if (previous.checks.size() && updated.checks.size() == 0) {\n    // We might be going into a fully healthy state, check\n    // other subsystems\n    bool any_checks = false;\n    for (auto& svc : paxos_service) {\n      if (&(svc->get_health_checks()) == &(previous)) {\n        // Ignore the ones we're clearing right now\n        continue;\n      }\n\n      if (svc->get_health_checks().checks.size() > 0) {\n        any_checks = true;\n        break;\n      }\n    }\n    if (!any_checks) {\n      clog->info() << \"Cluster is now healthy\";\n    }\n  }\n}\n\nhealth_status_t Monitor::get_health(list<string>& status,\n                                    bufferlist *detailbl,\n                                    Formatter *f)\n{\n  list<pair<health_status_t,string> > summary;\n  list<pair<health_status_t,string> > detail;\n\n  if (f)\n    f->open_object_section(\"health\");\n\n  for (vector<PaxosService*>::iterator p = paxos_service.begin();\n       p != paxos_service.end();\n       ++p) {\n    PaxosService *s = *p;\n    s->get_health(summary, detailbl ? &detail : NULL, cct);\n  }\n\n  health_monitor->get_health(summary, (detailbl ? &detail : NULL));\n\n  health_status_t overall = HEALTH_OK;\n  if (!timecheck_skews.empty()) {\n    list<string> warns;\n    for (map<entity_inst_t,double>::iterator i = timecheck_skews.begin();\n         i != timecheck_skews.end(); ++i) {\n      entity_inst_t inst = i->first;\n      double skew = i->second;\n      double latency = timecheck_latencies[inst];\n      string name = monmap->get_name(inst.addr);\n      ostringstream tcss;\n      health_status_t tcstatus = timecheck_status(tcss, skew, latency);\n      if (tcstatus != HEALTH_OK) {\n        if (overall > tcstatus)\n          overall = tcstatus;\n        warns.push_back(name);\n        ostringstream tmp_ss;\n        tmp_ss << \"mon.\" << name\n               << \" addr \" << inst.addr << \" \" << tcss.str()\n\t       << \" (latency \" << latency << \"s)\";\n        detail.push_back(make_pair(tcstatus, tmp_ss.str()));\n      }\n    }\n    if (!warns.empty()) {\n      ostringstream ss;\n      ss << \"clock skew detected on\";\n      while (!warns.empty()) {\n        ss << \" mon.\" << warns.front();\n        warns.pop_front();\n        if (!warns.empty())\n          ss << \",\";\n      }\n      status.push_back(ss.str());\n      summary.push_back(make_pair(HEALTH_WARN, \"Monitor clock skew detected \"));\n    }\n  }\n\n  if (f)\n    f->open_array_section(\"summary\");\n  if (!summary.empty()) {\n    while (!summary.empty()) {\n      if (overall > summary.front().first)\n\toverall = summary.front().first;\n      status.push_back(summary.front().second);\n      if (f) {\n        f->open_object_section(\"item\");\n        f->dump_stream(\"severity\") <<  summary.front().first;\n        f->dump_string(\"summary\", summary.front().second);\n        f->close_section();\n      }\n      summary.pop_front();\n    }\n  }\n  if (f)\n    f->close_section();\n\n  stringstream fss;\n  fss << overall;\n  status.push_front(fss.str());\n  if (f)\n    f->dump_stream(\"overall_status\") << overall;\n\n  if (f)\n    f->open_array_section(\"detail\");\n  while (!detail.empty()) {\n    if (f)\n      f->dump_string(\"item\", detail.front().second);\n    else if (detailbl != NULL) {\n      detailbl->append(detail.front().second);\n      detailbl->append('\\n');\n    }\n    detail.pop_front();\n  }\n  if (f)\n    f->close_section();\n\n  if (f)\n    f->close_section();\n\n  return overall;\n}\n\nvoid Monitor::get_cluster_status(stringstream &ss, Formatter *f)\n{\n  if (f)\n    f->open_object_section(\"status\");\n\n  if (f) {\n    f->dump_stream(\"fsid\") << monmap->get_fsid();\n    if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n      get_health_status(false, f, nullptr);\n    } else {\n      list<string> health_str;\n      get_health(health_str, nullptr, f);\n    }\n    f->dump_unsigned(\"election_epoch\", get_epoch());\n    {\n      f->open_array_section(\"quorum\");\n      for (set<int>::iterator p = quorum.begin(); p != quorum.end(); ++p)\n\tf->dump_int(\"rank\", *p);\n      f->close_section();\n      f->open_array_section(\"quorum_names\");\n      for (set<int>::iterator p = quorum.begin(); p != quorum.end(); ++p)\n\tf->dump_string(\"id\", monmap->get_name(*p));\n      f->close_section();\n    }\n    f->open_object_section(\"monmap\");\n    monmap->dump(f);\n    f->close_section();\n    f->open_object_section(\"osdmap\");\n    osdmon()->osdmap.print_summary(f, cout, string(12, ' '));\n    f->close_section();\n    f->open_object_section(\"pgmap\");\n    pgservice->print_summary(f, NULL);\n    f->close_section();\n    f->open_object_section(\"fsmap\");\n    mdsmon()->get_fsmap().print_summary(f, NULL);\n    f->close_section();\n    f->open_object_section(\"mgrmap\");\n    mgrmon()->get_map().print_summary(f, nullptr);\n    f->close_section();\n\n    f->dump_object(\"servicemap\", mgrstatmon()->get_service_map());\n    f->close_section();\n  } else {\n    ss << \"  cluster:\\n\";\n    ss << \"    id:     \" << monmap->get_fsid() << \"\\n\";\n\n    string health;\n    if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n      get_health_status(false, nullptr, &health,\n\t\t\t\"\\n            \", \"\\n            \");\n    } else {\n      list<string> ls;\n      get_health(ls, NULL, f);\n      health = joinify(ls.begin(), ls.end(),\n\t\t       string(\"\\n            \"));\n    }\n    ss << \"    health: \" << health << \"\\n\";\n\n    ss << \"\\n \\n  services:\\n\";\n    {\n      size_t maxlen = 3;\n      auto& service_map = mgrstatmon()->get_service_map();\n      for (auto& p : service_map.services) {\n\tmaxlen = std::max(maxlen, p.first.size());\n      }\n      string spacing(maxlen - 3, ' ');\n      const auto quorum_names = get_quorum_names();\n      const auto mon_count = monmap->mon_info.size();\n      ss << \"    mon: \" << spacing << mon_count << \" daemons, quorum \"\n\t << quorum_names;\n      if (quorum_names.size() != mon_count) {\n\tstd::list<std::string> out_of_q;\n\tfor (size_t i = 0; i < monmap->ranks.size(); ++i) {\n\t  if (quorum.count(i) == 0) {\n\t    out_of_q.push_back(monmap->ranks[i]);\n\t  }\n\t}\n\tss << \", out of quorum: \" << joinify(out_of_q.begin(),\n\t\t\t\t\t     out_of_q.end(), std::string(\", \"));\n      }\n      ss << \"\\n\";\n      if (mgrmon()->in_use()) {\n\tss << \"    mgr: \" << spacing;\n\tmgrmon()->get_map().print_summary(nullptr, &ss);\n\tss << \"\\n\";\n      }\n      if (mdsmon()->get_fsmap().filesystem_count() > 0) {\n\tss << \"    mds: \" << spacing << mdsmon()->get_fsmap() << \"\\n\";\n      }\n      ss << \"    osd: \" << spacing;\n      osdmon()->osdmap.print_summary(NULL, ss, string(maxlen + 6, ' '));\n      ss << \"\\n\";\n      for (auto& p : service_map.services) {\n\tss << \"    \" << p.first << \": \" << string(maxlen - p.first.size(), ' ')\n\t   << p.second.get_summary() << \"\\n\";\n      }\n    }\n\n    ss << \"\\n \\n  data:\\n\";\n    pgservice->print_summary(NULL, &ss);\n    ss << \"\\n \";\n  }\n}\n\nvoid Monitor::_generate_command_map(map<string,cmd_vartype>& cmdmap,\n                                    map<string,string> &param_str_map)\n{\n  for (map<string,cmd_vartype>::const_iterator p = cmdmap.begin();\n       p != cmdmap.end(); ++p) {\n    if (p->first == \"prefix\")\n      continue;\n    if (p->first == \"caps\") {\n      vector<string> cv;\n      if (cmd_getval(g_ceph_context, cmdmap, \"caps\", cv) &&\n\t  cv.size() % 2 == 0) {\n\tfor (unsigned i = 0; i < cv.size(); i += 2) {\n\t  string k = string(\"caps_\") + cv[i];\n\t  param_str_map[k] = cv[i + 1];\n\t}\n\tcontinue;\n      }\n    }\n    param_str_map[p->first] = cmd_vartype_stringify(p->second);\n  }\n}\n\nconst MonCommand *Monitor::_get_moncommand(\n  const string &cmd_prefix,\n  const vector<MonCommand>& cmds)\n{\n  for (auto& c : cmds) {\n    if (c.cmdstring.compare(0, cmd_prefix.size(), cmd_prefix) == 0) {\n      return &c;\n    }\n  }\n  return nullptr;\n}\n\nbool Monitor::_allowed_command(MonSession *s, string &module, string &prefix,\n                               const map<string,cmd_vartype>& cmdmap,\n                               const map<string,string>& param_str_map,\n                               const MonCommand *this_cmd) {\n\n  bool cmd_r = this_cmd->requires_perm('r');\n  bool cmd_w = this_cmd->requires_perm('w');\n  bool cmd_x = this_cmd->requires_perm('x');\n\n  bool capable = s->caps.is_capable(\n    g_ceph_context,\n    CEPH_ENTITY_TYPE_MON,\n    s->entity_name,\n    module, prefix, param_str_map,\n    cmd_r, cmd_w, cmd_x);\n\n  dout(10) << __func__ << \" \" << (capable ? \"\" : \"not \") << \"capable\" << dendl;\n  return capable;\n}\n\nvoid Monitor::format_command_descriptions(const std::vector<MonCommand> &commands,\n\t\t\t\t\t  Formatter *f,\n\t\t\t\t\t  bufferlist *rdata,\n\t\t\t\t\t  bool hide_mgr_flag)\n{\n  int cmdnum = 0;\n  f->open_object_section(\"command_descriptions\");\n  for (const auto &cmd : commands) {\n    unsigned flags = cmd.flags;\n    if (hide_mgr_flag) {\n      flags &= ~MonCommand::FLAG_MGR;\n    }\n    ostringstream secname;\n    secname << \"cmd\" << setfill('0') << std::setw(3) << cmdnum;\n    dump_cmddesc_to_json(f, secname.str(),\n\t\t\t cmd.cmdstring, cmd.helpstring, cmd.module,\n\t\t\t cmd.req_perms, cmd.availability, flags);\n    cmdnum++;\n  }\n  f->close_section();\t// command_descriptions\n\n  f->flush(*rdata);\n}\n\nbool Monitor::is_keyring_required()\n{\n  string auth_cluster_required = g_conf->auth_supported.empty() ?\n    g_conf->auth_cluster_required : g_conf->auth_supported;\n  string auth_service_required = g_conf->auth_supported.empty() ?\n    g_conf->auth_service_required : g_conf->auth_supported;\n\n  return auth_service_required == \"cephx\" ||\n    auth_cluster_required == \"cephx\";\n}\n\nstruct C_MgrProxyCommand : public Context {\n  Monitor *mon;\n  MonOpRequestRef op;\n  uint64_t size;\n  bufferlist outbl;\n  string outs;\n  C_MgrProxyCommand(Monitor *mon, MonOpRequestRef op, uint64_t s)\n    : mon(mon), op(op), size(s) { }\n  void finish(int r) {\n    Mutex::Locker l(mon->lock);\n    mon->mgr_proxy_bytes -= size;\n    mon->reply_command(op, r, outs, outbl, 0);\n  }\n};\n\nvoid Monitor::handle_command(MonOpRequestRef op)\n{\n  assert(op->is_type_command());\n  MMonCommand *m = static_cast<MMonCommand*>(op->get_req());\n  if (m->fsid != monmap->fsid) {\n    dout(0) << \"handle_command on fsid \" << m->fsid << \" != \" << monmap->fsid << dendl;\n    reply_command(op, -EPERM, \"wrong fsid\", 0);\n    return;\n  }\n\n  MonSession *session = static_cast<MonSession *>(\n    m->get_connection()->get_priv());\n  if (!session) {\n    dout(5) << __func__ << \" dropping stray message \" << *m << dendl;\n    return;\n  }\n  BOOST_SCOPE_EXIT_ALL(=) {\n    session->put();\n  };\n\n  if (m->cmd.empty()) {\n    string rs = \"No command supplied\";\n    reply_command(op, -EINVAL, rs, 0);\n    return;\n  }\n\n  string prefix;\n  vector<string> fullcmd;\n  map<string, cmd_vartype> cmdmap;\n  stringstream ss, ds;\n  bufferlist rdata;\n  string rs;\n  int r = -EINVAL;\n  rs = \"unrecognized command\";\n\n  if (!cmdmap_from_json(m->cmd, &cmdmap, ss)) {\n    // ss has reason for failure\n    r = -EINVAL;\n    rs = ss.str();\n    if (!m->get_source().is_mon())  // don't reply to mon->mon commands\n      reply_command(op, r, rs, 0);\n    return;\n  }\n\n  // check return value. If no prefix parameter provided,\n  // return value will be false, then return error info.\n  if (!cmd_getval(g_ceph_context, cmdmap, \"prefix\", prefix)) {\n    reply_command(op, -EINVAL, \"command prefix not found\", 0);\n    return;\n  }\n\n  // check prefix is empty\n  if (prefix.empty()) {\n    reply_command(op, -EINVAL, \"command prefix must not be empty\", 0);\n    return;\n  }\n\n  if (prefix == \"get_command_descriptions\") {\n    bufferlist rdata;\n    Formatter *f = Formatter::create(\"json\");\n    // hide mgr commands until luminous upgrade is complete\n    bool hide_mgr_flag =\n      osdmon()->osdmap.require_osd_release < CEPH_RELEASE_LUMINOUS;\n\n    std::vector<MonCommand> commands;\n\n    // only include mgr commands once all mons are upgrade (and we've dropped\n    // the hard-coded PGMonitor commands)\n    if (quorum_mon_features.contains_all(ceph::features::mon::FEATURE_LUMINOUS)) {\n      commands = static_cast<MgrMonitor*>(\n        paxos_service[PAXOS_MGR])->get_command_descs();\n    }\n\n    for (auto& c : leader_mon_commands) {\n      commands.push_back(c);\n    }\n\n    format_command_descriptions(commands, f, &rdata, hide_mgr_flag);\n    delete f;\n    reply_command(op, 0, \"\", rdata, 0);\n    return;\n  }\n\n  string module;\n  string err;\n\n  dout(0) << \"handle_command \" << *m << dendl;\n\n  string format;\n  cmd_getval(g_ceph_context, cmdmap, \"format\", format, string(\"plain\"));\n  boost::scoped_ptr<Formatter> f(Formatter::create(format));\n\n  get_str_vec(prefix, fullcmd);\n\n  // make sure fullcmd is not empty.\n  // invalid prefix will cause empty vector fullcmd.\n  // such as, prefix=\";,,;\"\n  if (fullcmd.empty()) {\n    reply_command(op, -EINVAL, \"command requires a prefix to be valid\", 0);\n    return;\n  }\n\n  module = fullcmd[0];\n\n  // validate command is in leader map\n\n  const MonCommand *leader_cmd;\n  const auto& mgr_cmds = mgrmon()->get_command_descs();\n  const MonCommand *mgr_cmd = nullptr;\n  if (!mgr_cmds.empty()) {\n    mgr_cmd = _get_moncommand(prefix, mgr_cmds);\n  }\n  leader_cmd = _get_moncommand(prefix, leader_mon_commands);\n  if (!leader_cmd) {\n    leader_cmd = mgr_cmd;\n    if (!leader_cmd) {\n      reply_command(op, -EINVAL, \"command not known\", 0);\n      return;\n    }\n  }\n  // validate command is in our map & matches, or forward if it is allowed\n  const MonCommand *mon_cmd = _get_moncommand(\n    prefix,\n    get_local_commands(quorum_mon_features));\n  if (!mon_cmd) {\n    mon_cmd = mgr_cmd;\n  }\n  if (!is_leader()) {\n    if (!mon_cmd) {\n      if (leader_cmd->is_noforward()) {\n\treply_command(op, -EINVAL,\n\t\t      \"command not locally supported and not allowed to forward\",\n\t\t      0);\n\treturn;\n      }\n      dout(10) << \"Command not locally supported, forwarding request \"\n\t       << m << dendl;\n      forward_request_leader(op);\n      return;\n    } else if (!mon_cmd->is_compat(leader_cmd)) {\n      if (mon_cmd->is_noforward()) {\n\treply_command(op, -EINVAL,\n\t\t      \"command not compatible with leader and not allowed to forward\",\n\t\t      0);\n\treturn;\n      }\n      dout(10) << \"Command not compatible with leader, forwarding request \"\n\t       << m << dendl;\n      forward_request_leader(op);\n      return;\n    }\n  }\n\n  if (mon_cmd->is_obsolete() ||\n      (cct->_conf->mon_debug_deprecated_as_obsolete\n       && mon_cmd->is_deprecated())) {\n    reply_command(op, -ENOTSUP,\n                  \"command is obsolete; please check usage and/or man page\",\n                  0);\n    return;\n  }\n\n  if (session->proxy_con && mon_cmd->is_noforward()) {\n    dout(10) << \"Got forward for noforward command \" << m << dendl;\n    reply_command(op, -EINVAL, \"forward for noforward command\", rdata, 0);\n    return;\n  }\n\n  /* what we perceive as being the service the command falls under */\n  string service(mon_cmd->module);\n\n  dout(25) << __func__ << \" prefix='\" << prefix\n           << \"' module='\" << module\n           << \"' service='\" << service << \"'\" << dendl;\n\n  bool cmd_is_rw =\n    (mon_cmd->requires_perm('w') || mon_cmd->requires_perm('x'));\n\n  // validate user's permissions for requested command\n  map<string,string> param_str_map;\n  _generate_command_map(cmdmap, param_str_map);\n  if (!_allowed_command(session, service, prefix, cmdmap,\n                        param_str_map, mon_cmd)) {\n    dout(1) << __func__ << \" access denied\" << dendl;\n    (cmd_is_rw ? audit_clog->info() : audit_clog->debug())\n      << \"from='\" << session->inst << \"' \"\n      << \"entity='\" << session->entity_name << \"' \"\n      << \"cmd=\" << m->cmd << \":  access denied\";\n    reply_command(op, -EACCES, \"access denied\", 0);\n    return;\n  }\n\n  (cmd_is_rw ? audit_clog->info() : audit_clog->debug())\n    << \"from='\" << session->inst << \"' \"\n    << \"entity='\" << session->entity_name << \"' \"\n    << \"cmd=\" << m->cmd << \": dispatch\";\n\n  if (mon_cmd->is_mgr() &&\n      osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n    const auto& hdr = m->get_header();\n    uint64_t size = hdr.front_len + hdr.middle_len + hdr.data_len;\n    uint64_t max = g_conf->get_val<uint64_t>(\"mon_client_bytes\")\n                 * g_conf->get_val<double>(\"mon_mgr_proxy_client_bytes_ratio\");\n    if (mgr_proxy_bytes + size > max) {\n      dout(10) << __func__ << \" current mgr proxy bytes \" << mgr_proxy_bytes\n\t       << \" + \" << size << \" > max \" << max << dendl;\n      reply_command(op, -EAGAIN, \"hit limit on proxied mgr commands\", rdata, 0);\n      return;\n    }\n    mgr_proxy_bytes += size;\n    dout(10) << __func__ << \" proxying mgr command (+\" << size\n\t     << \" -> \" << mgr_proxy_bytes << \")\" << dendl;\n    C_MgrProxyCommand *fin = new C_MgrProxyCommand(this, op, size);\n    mgr_client.start_command(m->cmd,\n\t\t\t     m->get_data(),\n\t\t\t     &fin->outbl,\n\t\t\t     &fin->outs,\n\t\t\t     new C_OnFinisher(fin, &finisher));\n    return;\n  }\n\n  if ((module == \"mds\" || module == \"fs\")  &&\n      prefix != \"fs authorize\") {\n    mdsmon()->dispatch(op);\n    return;\n  }\n  if ((module == \"osd\" || prefix == \"pg map\") &&\n      prefix != \"osd last-stat-seq\") {\n    osdmon()->dispatch(op);\n    return;\n  }\n\n  if (module == \"pg\") {\n    pgmon()->dispatch(op);\n    return;\n  }\n  if (module == \"mon\" &&\n      /* Let the Monitor class handle the following commands:\n       *  'mon compact'\n       *  'mon scrub'\n       *  'mon sync force'\n       */\n      prefix != \"mon compact\" &&\n      prefix != \"mon scrub\" &&\n      prefix != \"mon sync force\" &&\n      prefix != \"mon metadata\" &&\n      prefix != \"mon versions\" &&\n      prefix != \"mon count-metadata\") {\n    monmon()->dispatch(op);\n    return;\n  }\n  if (module == \"auth\" || prefix == \"fs authorize\") {\n    authmon()->dispatch(op);\n    return;\n  }\n  if (module == \"log\") {\n    logmon()->dispatch(op);\n    return;\n  }\n\n  if (module == \"config-key\") {\n    config_key_service->dispatch(op);\n    return;\n  }\n\n  if (module == \"mgr\") {\n    mgrmon()->dispatch(op);\n    return;\n  }\n\n  if (prefix == \"fsid\") {\n    if (f) {\n      f->open_object_section(\"fsid\");\n      f->dump_stream(\"fsid\") << monmap->fsid;\n      f->close_section();\n      f->flush(rdata);\n    } else {\n      ds << monmap->fsid;\n      rdata.append(ds);\n    }\n    reply_command(op, 0, \"\", rdata, 0);\n    return;\n  }\n\n  if (prefix == \"scrub\" || prefix == \"mon scrub\") {\n    wait_for_paxos_write();\n    if (is_leader()) {\n      int r = scrub_start();\n      reply_command(op, r, \"\", rdata, 0);\n    } else if (is_peon()) {\n      forward_request_leader(op);\n    } else {\n      reply_command(op, -EAGAIN, \"no quorum\", rdata, 0);\n    }\n    return;\n  }\n\n  if (prefix == \"compact\" || prefix == \"mon compact\") {\n    dout(1) << \"triggering manual compaction\" << dendl;\n    utime_t start = ceph_clock_now();\n    store->compact();\n    utime_t end = ceph_clock_now();\n    end -= start;\n    dout(1) << \"finished manual compaction in \" << end << \" seconds\" << dendl;\n    ostringstream oss;\n    oss << \"compacted \" << g_conf->get_val<std::string>(\"mon_keyvaluedb\") << \" in \" << end << \" seconds\";\n    rs = oss.str();\n    r = 0;\n  }\n  else if (prefix == \"injectargs\") {\n    vector<string> injected_args;\n    cmd_getval(g_ceph_context, cmdmap, \"injected_args\", injected_args);\n    if (!injected_args.empty()) {\n      dout(0) << \"parsing injected options '\" << injected_args << \"'\" << dendl;\n      ostringstream oss;\n      r = g_conf->injectargs(str_join(injected_args, \" \"), &oss);\n      ss << \"injectargs:\"  << oss.str();\n      rs = ss.str();\n      goto out;\n    } else {\n      rs = \"must supply options to be parsed in a single string\";\n      r = -EINVAL;\n    }\n  } else if (prefix == \"time-sync-status\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    f->open_object_section(\"time_sync\");\n    if (!timecheck_skews.empty()) {\n      f->open_object_section(\"time_skew_status\");\n      for (auto& i : timecheck_skews) {\n\tentity_inst_t inst = i.first;\n\tdouble skew = i.second;\n\tdouble latency = timecheck_latencies[inst];\n\tstring name = monmap->get_name(inst.addr);\n\tostringstream tcss;\n\thealth_status_t tcstatus = timecheck_status(tcss, skew, latency);\n\tf->open_object_section(name.c_str());\n\tf->dump_float(\"skew\", skew);\n\tf->dump_float(\"latency\", latency);\n\tf->dump_stream(\"health\") << tcstatus;\n\tif (tcstatus != HEALTH_OK) {\n\t  f->dump_stream(\"details\") << tcss.str();\n\t}\n\tf->close_section();\n      }\n      f->close_section();\n    }\n    f->open_object_section(\"timechecks\");\n    f->dump_unsigned(\"epoch\", get_epoch());\n    f->dump_int(\"round\", timecheck_round);\n    f->dump_stream(\"round_status\") << ((timecheck_round%2) ?\n\t\t\t\t       \"on-going\" : \"finished\");\n    f->close_section();\n    f->close_section();\n    f->flush(rdata);\n    r = 0;\n    rs = \"\";\n  } else if (prefix == \"config set\") {\n    std::string key;\n    cmd_getval(cct, cmdmap, \"key\", key);\n    std::string val;\n    cmd_getval(cct, cmdmap, \"value\", val);\n    r = g_conf->set_val(key, val, true, &ss);\n    if (r == 0) {\n      g_conf->apply_changes(nullptr);\n    }\n    rs = ss.str();\n    goto out;\n  } else if (prefix == \"status\" ||\n\t     prefix == \"health\" ||\n\t     prefix == \"df\") {\n    string detail;\n    cmd_getval(g_ceph_context, cmdmap, \"detail\", detail);\n\n    if (prefix == \"status\") {\n      // get_cluster_status handles f == NULL\n      get_cluster_status(ds, f.get());\n\n      if (f) {\n        f->flush(ds);\n        ds << '\\n';\n      }\n      rdata.append(ds);\n    } else if (prefix == \"health\") {\n      if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n\tstring plain;\n\tget_health_status(detail == \"detail\", f.get(), f ? nullptr : &plain);\n\tif (f) {\n\t  f->flush(rdata);\n\t} else {\n\t  rdata.append(plain);\n\t}\n      } else {\n\tlist<string> health_str;\n\tget_health(health_str, detail == \"detail\" ? &rdata : NULL, f.get());\n\tif (f) {\n\t  f->flush(ds);\n\t  ds << '\\n';\n\t} else {\n\t  assert(!health_str.empty());\n\t  ds << health_str.front();\n\t  health_str.pop_front();\n\t  if (!health_str.empty()) {\n\t    ds << ' ';\n\t    ds << joinify(health_str.begin(), health_str.end(), string(\"; \"));\n\t  }\n\t}\n\tbufferlist comb;\n\tcomb.append(ds);\n\tif (detail == \"detail\")\n\t  comb.append(rdata);\n\trdata = comb;\n      }\n    } else if (prefix == \"df\") {\n      bool verbose = (detail == \"detail\");\n      if (f)\n        f->open_object_section(\"stats\");\n\n      pgservice->dump_fs_stats(&ds, f.get(), verbose);\n      if (!f)\n        ds << '\\n';\n      pgservice->dump_pool_stats(osdmon()->osdmap, &ds, f.get(), verbose);\n\n      if (f) {\n        f->close_section();\n        f->flush(ds);\n        ds << '\\n';\n      }\n    } else {\n      assert(0 == \"We should never get here!\");\n      return;\n    }\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"report\") {\n\n    // this must be formatted, in its current form\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    f->open_object_section(\"report\");\n    f->dump_stream(\"cluster_fingerprint\") << fingerprint;\n    f->dump_string(\"version\", ceph_version_to_str());\n    f->dump_string(\"commit\", git_version_to_str());\n    f->dump_stream(\"timestamp\") << ceph_clock_now();\n\n    vector<string> tagsvec;\n    cmd_getval(g_ceph_context, cmdmap, \"tags\", tagsvec);\n    string tagstr = str_join(tagsvec, \" \");\n    if (!tagstr.empty())\n      tagstr = tagstr.substr(0, tagstr.find_last_of(' '));\n    f->dump_string(\"tag\", tagstr);\n\n    if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n      get_health_status(true, f.get(), nullptr);\n    } else {\n      list<string> health_str;\n      get_health(health_str, nullptr, f.get());\n    }\n\n    monmon()->dump_info(f.get());\n    osdmon()->dump_info(f.get());\n    mdsmon()->dump_info(f.get());\n    authmon()->dump_info(f.get());\n    pgservice->dump_info(f.get());\n\n    paxos->dump_info(f.get());\n\n    f->close_section();\n    f->flush(rdata);\n\n    ostringstream ss2;\n    ss2 << \"report \" << rdata.crc32c(CEPH_MON_PORT);\n    rs = ss2.str();\n    r = 0;\n  } else if (prefix == \"osd last-stat-seq\") {\n    int64_t osd;\n    cmd_getval(g_ceph_context, cmdmap, \"id\", osd);\n    uint64_t seq = mgrstatmon()->get_last_osd_stat_seq(osd);\n    if (f) {\n      f->dump_unsigned(\"seq\", seq);\n      f->flush(ds);\n    } else {\n      ds << seq;\n      rdata.append(ds);\n    }\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"node ls\") {\n    string node_type(\"all\");\n    cmd_getval(g_ceph_context, cmdmap, \"type\", node_type);\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    if (node_type == \"all\") {\n      f->open_object_section(\"nodes\");\n      print_nodes(f.get(), ds);\n      osdmon()->print_nodes(f.get());\n      mdsmon()->print_nodes(f.get());\n      f->close_section();\n    } else if (node_type == \"mon\") {\n      print_nodes(f.get(), ds);\n    } else if (node_type == \"osd\") {\n      osdmon()->print_nodes(f.get());\n    } else if (node_type == \"mds\") {\n      mdsmon()->print_nodes(f.get());\n    }\n    f->flush(ds);\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"features\") {\n    if (!is_leader() && !is_peon()) {\n      dout(10) << \" waiting for quorum\" << dendl;\n      waitfor_quorum.push_back(new C_RetryMessage(this, op));\n      return;\n    }\n    if (!is_leader()) {\n      forward_request_leader(op);\n      return;\n    }\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    FeatureMap fm;\n    get_combined_feature_map(&fm);\n    f->dump_object(\"features\", fm);\n    f->flush(rdata);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"mon metadata\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n\n    string name;\n    bool all = !cmd_getval(g_ceph_context, cmdmap, \"id\", name);\n    if (!all) {\n      // Dump a single mon's metadata\n      int mon = monmap->get_rank(name);\n      if (mon < 0) {\n        rs = \"requested mon not found\";\n        r = -ENOENT;\n        goto out;\n      }\n      f->open_object_section(\"mon_metadata\");\n      r = get_mon_metadata(mon, f.get(), ds);\n      f->close_section();\n    } else {\n      // Dump all mons' metadata\n      r = 0;\n      f->open_array_section(\"mon_metadata\");\n      for (unsigned int rank = 0; rank < monmap->size(); ++rank) {\n        std::ostringstream get_err;\n        f->open_object_section(\"mon\");\n        f->dump_string(\"name\", monmap->get_name(rank));\n        r = get_mon_metadata(rank, f.get(), get_err);\n        f->close_section();\n        if (r == -ENOENT || r == -EINVAL) {\n          dout(1) << get_err.str() << dendl;\n          // Drop error, list what metadata we do have\n          r = 0;\n        } else if (r != 0) {\n          derr << \"Unexpected error from get_mon_metadata: \"\n               << cpp_strerror(r) << dendl;\n          ds << get_err.str();\n          break;\n        }\n      }\n      f->close_section();\n    }\n\n    f->flush(ds);\n    rdata.append(ds);\n    rs = \"\";\n  } else if (prefix == \"mon versions\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    count_metadata(\"ceph_version\", f.get());\n    f->flush(ds);\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"mon count-metadata\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    string field;\n    cmd_getval(g_ceph_context, cmdmap, \"property\", field);\n    count_metadata(field, f.get());\n    f->flush(ds);\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"quorum_status\") {\n    // make sure our map is readable and up to date\n    if (!is_leader() && !is_peon()) {\n      dout(10) << \" waiting for quorum\" << dendl;\n      waitfor_quorum.push_back(new C_RetryMessage(this, op));\n      return;\n    }\n    _quorum_status(f.get(), ds);\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"mon_status\") {\n    get_mon_status(f.get(), ds);\n    if (f)\n      f->flush(ds);\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"sync force\" ||\n             prefix == \"mon sync force\") {\n    string validate1, validate2;\n    cmd_getval(g_ceph_context, cmdmap, \"validate1\", validate1);\n    cmd_getval(g_ceph_context, cmdmap, \"validate2\", validate2);\n    if (validate1 != \"--yes-i-really-mean-it\" ||\n\tvalidate2 != \"--i-know-what-i-am-doing\") {\n      r = -EINVAL;\n      rs = \"are you SURE? this will mean the monitor store will be \"\n\t   \"erased.  pass '--yes-i-really-mean-it \"\n\t   \"--i-know-what-i-am-doing' if you really do.\";\n      goto out;\n    }\n    sync_force(f.get(), ds);\n    rs = ds.str();\n    r = 0;\n  } else if (prefix == \"heap\") {\n    if (!ceph_using_tcmalloc())\n      rs = \"tcmalloc not enabled, can't use heap profiler commands\\n\";\n    else {\n      string heapcmd;\n      cmd_getval(g_ceph_context, cmdmap, \"heapcmd\", heapcmd);\n      // XXX 1-element vector, change at callee or make vector here?\n      vector<string> heapcmd_vec;\n      get_str_vec(heapcmd, heapcmd_vec);\n      ceph_heap_profiler_handle_command(heapcmd_vec, ds);\n      rdata.append(ds);\n      rs = \"\";\n      r = 0;\n    }\n  } else if (prefix == \"quorum\") {\n    string quorumcmd;\n    cmd_getval(g_ceph_context, cmdmap, \"quorumcmd\", quorumcmd);\n    if (quorumcmd == \"exit\") {\n      start_election();\n      elector.stop_participating();\n      rs = \"stopped responding to quorum, initiated new election\";\n      r = 0;\n    } else if (quorumcmd == \"enter\") {\n      elector.start_participating();\n      start_election();\n      rs = \"started responding to quorum, initiated new election\";\n      r = 0;\n    } else {\n      rs = \"needs a valid 'quorum' command\";\n      r = -EINVAL;\n    }\n  } else if (prefix == \"version\") {\n    if (f) {\n      f->open_object_section(\"version\");\n      f->dump_string(\"version\", pretty_version_to_str());\n      f->close_section();\n      f->flush(ds);\n    } else {\n      ds << pretty_version_to_str();\n    }\n    rdata.append(ds);\n    rs = \"\";\n    r = 0;\n  } else if (prefix == \"versions\") {\n    if (!f)\n      f.reset(Formatter::create(\"json-pretty\"));\n    map<string,int> overall;\n    f->open_object_section(\"version\");\n    map<string,int> mon, mgr, osd, mds;\n\n    count_metadata(\"ceph_version\", &mon);\n    f->open_object_section(\"mon\");\n    for (auto& p : mon) {\n      f->dump_int(p.first.c_str(), p.second);\n      overall[p.first] += p.second;\n    }\n    f->close_section();\n\n    mgrmon()->count_metadata(\"ceph_version\", &mgr);\n    f->open_object_section(\"mgr\");\n    for (auto& p : mgr) {\n      f->dump_int(p.first.c_str(), p.second);\n      overall[p.first] += p.second;\n    }\n    f->close_section();\n\n    osdmon()->count_metadata(\"ceph_version\", &osd);\n    f->open_object_section(\"osd\");\n    for (auto& p : osd) {\n      f->dump_int(p.first.c_str(), p.second);\n      overall[p.first] += p.second;\n    }\n    f->close_section();\n\n    mdsmon()->count_metadata(\"ceph_version\", &mds);\n    f->open_object_section(\"mds\");\n    for (auto& p : mds) {\n      f->dump_int(p.first.c_str(), p.second);\n      overall[p.first] += p.second;\n    }\n    f->close_section();\n\n    for (auto& p : mgrstatmon()->get_service_map().services) {\n      f->open_object_section(p.first.c_str());\n      map<string,int> m;\n      p.second.count_metadata(\"ceph_version\", &m);\n      for (auto& q : m) {\n\tf->dump_int(q.first.c_str(), q.second);\n\toverall[q.first] += q.second;\n      }\n      f->close_section();\n    }\n\n    f->open_object_section(\"overall\");\n    for (auto& p : overall) {\n      f->dump_int(p.first.c_str(), p.second);\n    }\n    f->close_section();\n    f->close_section();\n    f->flush(rdata);\n    rs = \"\";\n    r = 0;\n  }\n\n out:\n  if (!m->get_source().is_mon())  // don't reply to mon->mon commands\n    reply_command(op, r, rs, rdata, 0);\n}\n\nvoid Monitor::reply_command(MonOpRequestRef op, int rc, const string &rs, version_t version)\n{\n  bufferlist rdata;\n  reply_command(op, rc, rs, rdata, version);\n}\n\nvoid Monitor::reply_command(MonOpRequestRef op, int rc, const string &rs,\n                            bufferlist& rdata, version_t version)\n{\n  MMonCommand *m = static_cast<MMonCommand*>(op->get_req());\n  assert(m->get_type() == MSG_MON_COMMAND);\n  MMonCommandAck *reply = new MMonCommandAck(m->cmd, rc, rs, version);\n  reply->set_tid(m->get_tid());\n  reply->set_data(rdata);\n  send_reply(op, reply);\n}\n\n\n// ------------------------\n// request/reply routing\n//\n// a client/mds/osd will connect to a random monitor.  we need to forward any\n// messages requiring state updates to the leader, and then route any replies\n// back via the correct monitor and back to them.  (the monitor will not\n// initiate any connections.)\n\nvoid Monitor::forward_request_leader(MonOpRequestRef op)\n{\n  op->mark_event(__func__);\n\n  int mon = get_leader();\n  MonSession *session = op->get_session();\n  PaxosServiceMessage *req = op->get_req<PaxosServiceMessage>();\n  \n  if (req->get_source().is_mon() && req->get_source_addr() != messenger->get_myaddr()) {\n    dout(10) << \"forward_request won't forward (non-local) mon request \" << *req << dendl;\n  } else if (session->proxy_con) {\n    dout(10) << \"forward_request won't double fwd request \" << *req << dendl;\n  } else if (!session->closed) {\n    RoutedRequest *rr = new RoutedRequest;\n    rr->tid = ++routed_request_tid;\n    rr->client_inst = req->get_source_inst();\n    rr->con = req->get_connection();\n    rr->con_features = rr->con->get_features();\n    encode_message(req, CEPH_FEATURES_ALL, rr->request_bl);   // for my use only; use all features\n    rr->session = static_cast<MonSession *>(session->get());\n    rr->op = op;\n    routed_requests[rr->tid] = rr;\n    session->routed_request_tids.insert(rr->tid);\n    \n    dout(10) << \"forward_request \" << rr->tid << \" request \" << *req\n\t     << \" features \" << rr->con_features << dendl;\n\n    MForward *forward = new MForward(rr->tid,\n                                     req,\n\t\t\t\t     rr->con_features,\n\t\t\t\t     rr->session->caps);\n    forward->set_priority(req->get_priority());\n    if (session->auth_handler) {\n      forward->entity_name = session->entity_name;\n    } else if (req->get_source().is_mon()) {\n      forward->entity_name.set_type(CEPH_ENTITY_TYPE_MON);\n    }\n    messenger->send_message(forward, monmap->get_inst(mon));\n    op->mark_forwarded();\n    assert(op->get_req()->get_type() != 0);\n  } else {\n    dout(10) << \"forward_request no session for request \" << *req << dendl;\n  }\n}\n\n// fake connection attached to forwarded messages\nstruct AnonConnection : public Connection {\n  explicit AnonConnection(CephContext *cct) : Connection(cct, NULL) {}\n\n  int send_message(Message *m) override {\n    assert(!\"send_message on anonymous connection\");\n  }\n  void send_keepalive() override {\n    assert(!\"send_keepalive on anonymous connection\");\n  }\n  void mark_down() override {\n    // silently ignore\n  }\n  void mark_disposable() override {\n    // silengtly ignore\n  }\n  bool is_connected() override { return false; }\n};\n\n//extract the original message and put it into the regular dispatch function\nvoid Monitor::handle_forward(MonOpRequestRef op)\n{\n  MForward *m = static_cast<MForward*>(op->get_req());\n  dout(10) << \"received forwarded message from \" << m->client\n\t   << \" via \" << m->get_source_inst() << dendl;\n  MonSession *session = op->get_session();\n  assert(session);\n\n  if (!session->is_capable(\"mon\", MON_CAP_X)) {\n    dout(0) << \"forward from entity with insufficient caps! \" \n\t    << session->caps << dendl;\n  } else {\n    // see PaxosService::dispatch(); we rely on this being anon\n    // (c->msgr == NULL)\n    PaxosServiceMessage *req = m->claim_message();\n    assert(req != NULL);\n\n    ConnectionRef c(new AnonConnection(cct));\n    MonSession *s = new MonSession(req->get_source_inst(),\n\t\t\t\t   static_cast<Connection*>(c.get()));\n    c->set_priv(s->get());\n    c->set_peer_addr(m->client.addr);\n    c->set_peer_type(m->client.name.type());\n    c->set_features(m->con_features);\n\n    s->caps = m->client_caps;\n    dout(10) << \" caps are \" << s->caps << dendl;\n    s->entity_name = m->entity_name;\n    dout(10) << \" entity name '\" << s->entity_name << \"' type \"\n             << s->entity_name.get_type() << dendl;\n    s->proxy_con = m->get_connection();\n    s->proxy_tid = m->tid;\n\n    req->set_connection(c);\n\n    // not super accurate, but better than nothing.\n    req->set_recv_stamp(m->get_recv_stamp());\n\n    /*\n     * note which election epoch this is; we will drop the message if\n     * there is a future election since our peers will resend routed\n     * requests in that case.\n     */\n    req->rx_election_epoch = get_epoch();\n\n    /* Because this is a special fake connection, we need to break\n       the ref loop between Connection and MonSession differently\n       than we normally do. Here, the Message refers to the Connection\n       which refers to the Session, and nobody else refers to the Connection\n       or the Session. And due to the special nature of this message,\n       nobody refers to the Connection via the Session. So, clear out that\n       half of the ref loop.*/\n    s->con.reset(NULL);\n\n    dout(10) << \" mesg \" << req << \" from \" << m->get_source_addr() << dendl;\n\n    _ms_dispatch(req);\n    s->put();\n  }\n}\n\nvoid Monitor::try_send_message(Message *m, const entity_inst_t& to)\n{\n  dout(10) << \"try_send_message \" << *m << \" to \" << to << dendl;\n\n  bufferlist bl;\n  encode_message(m, quorum_con_features, bl);\n\n  messenger->send_message(m, to);\n\n  for (int i=0; i<(int)monmap->size(); i++) {\n    if (i != rank)\n      messenger->send_message(new MRoute(bl, to), monmap->get_inst(i));\n  }\n}\n\nvoid Monitor::send_reply(MonOpRequestRef op, Message *reply)\n{\n  op->mark_event(__func__);\n\n  MonSession *session = op->get_session();\n  assert(session);\n  Message *req = op->get_req();\n  ConnectionRef con = op->get_connection();\n\n  reply->set_cct(g_ceph_context);\n  dout(2) << __func__ << \" \" << op << \" \" << reply << \" \" << *reply << dendl;\n\n  if (!con) {\n    dout(2) << \"send_reply no connection, dropping reply \" << *reply\n\t    << \" to \" << req << \" \" << *req << dendl;\n    reply->put();\n    op->mark_event(\"reply: no connection\");\n    return;\n  }\n\n  if (!session->con && !session->proxy_con) {\n    dout(2) << \"send_reply no connection, dropping reply \" << *reply\n\t    << \" to \" << req << \" \" << *req << dendl;\n    reply->put();\n    op->mark_event(\"reply: no connection\");\n    return;\n  }\n\n  if (session->proxy_con) {\n    dout(15) << \"send_reply routing reply to \" << con->get_peer_addr()\n\t     << \" via \" << session->proxy_con->get_peer_addr()\n\t     << \" for request \" << *req << dendl;\n    session->proxy_con->send_message(new MRoute(session->proxy_tid, reply));\n    op->mark_event(\"reply: send routed request\");\n  } else {\n    session->con->send_message(reply);\n    op->mark_event(\"reply: send\");\n  }\n}\n\nvoid Monitor::no_reply(MonOpRequestRef op)\n{\n  MonSession *session = op->get_session();\n  Message *req = op->get_req();\n\n  if (session->proxy_con) {\n    dout(10) << \"no_reply to \" << req->get_source_inst()\n\t     << \" via \" << session->proxy_con->get_peer_addr()\n\t     << \" for request \" << *req << dendl;\n    session->proxy_con->send_message(new MRoute(session->proxy_tid, NULL));\n    op->mark_event(\"no_reply: send routed request\");\n  } else {\n    dout(10) << \"no_reply to \" << req->get_source_inst()\n             << \" \" << *req << dendl;\n    op->mark_event(\"no_reply\");\n  }\n}\n\nvoid Monitor::handle_route(MonOpRequestRef op)\n{\n  MRoute *m = static_cast<MRoute*>(op->get_req());\n  MonSession *session = op->get_session();\n  //check privileges\n  if (!session->is_capable(\"mon\", MON_CAP_X)) {\n    dout(0) << \"MRoute received from entity without appropriate perms! \"\n\t    << dendl;\n    return;\n  }\n  if (m->msg)\n    dout(10) << \"handle_route \" << *m->msg << \" to \" << m->dest << dendl;\n  else\n    dout(10) << \"handle_route null to \" << m->dest << dendl;\n  \n  // look it up\n  if (m->session_mon_tid) {\n    if (routed_requests.count(m->session_mon_tid)) {\n      RoutedRequest *rr = routed_requests[m->session_mon_tid];\n\n      // reset payload, in case encoding is dependent on target features\n      if (m->msg) {\n\tm->msg->clear_payload();\n\trr->con->send_message(m->msg);\n\tm->msg = NULL;\n      }\n      if (m->send_osdmap_first) {\n\tdout(10) << \" sending osdmaps from \" << m->send_osdmap_first << dendl;\n\tosdmon()->send_incremental(m->send_osdmap_first, rr->session,\n\t\t\t\t   true, MonOpRequestRef());\n      }\n      assert(rr->tid == m->session_mon_tid && rr->session->routed_request_tids.count(m->session_mon_tid));\n      routed_requests.erase(m->session_mon_tid);\n      rr->session->routed_request_tids.erase(m->session_mon_tid);\n      delete rr;\n    } else {\n      dout(10) << \" don't have routed request tid \" << m->session_mon_tid << dendl;\n    }\n  } else {\n    dout(10) << \" not a routed request, trying to send anyway\" << dendl;\n    if (m->msg) {\n      messenger->send_message(m->msg, m->dest);\n      m->msg = NULL;\n    }\n  }\n}\n\nvoid Monitor::resend_routed_requests()\n{\n  dout(10) << \"resend_routed_requests\" << dendl;\n  int mon = get_leader();\n  list<Context*> retry;\n  for (map<uint64_t, RoutedRequest*>::iterator p = routed_requests.begin();\n       p != routed_requests.end();\n       ++p) {\n    RoutedRequest *rr = p->second;\n\n    if (mon == rank) {\n      dout(10) << \" requeue for self tid \" << rr->tid << dendl;\n      rr->op->mark_event(\"retry routed request\");\n      retry.push_back(new C_RetryMessage(this, rr->op));\n      if (rr->session) {\n        assert(rr->session->routed_request_tids.count(p->first));\n        rr->session->routed_request_tids.erase(p->first);\n      }\n      delete rr;\n    } else {\n      bufferlist::iterator q = rr->request_bl.begin();\n      PaxosServiceMessage *req = (PaxosServiceMessage *)decode_message(cct, 0, q);\n      rr->op->mark_event(\"resend forwarded message to leader\");\n      dout(10) << \" resend to mon.\" << mon << \" tid \" << rr->tid << \" \" << *req << dendl;\n      MForward *forward = new MForward(rr->tid, req, rr->con_features,\n\t\t\t\t       rr->session->caps);\n      req->put();  // forward takes its own ref; drop ours.\n      forward->client = rr->client_inst;\n      forward->set_priority(req->get_priority());\n      messenger->send_message(forward, monmap->get_inst(mon));\n    }\n  }\n  if (mon == rank) {\n    routed_requests.clear();\n    finish_contexts(g_ceph_context, retry);\n  }\n}\n\nvoid Monitor::remove_session(MonSession *s)\n{\n  dout(10) << \"remove_session \" << s << \" \" << s->inst\n\t   << \" features 0x\" << std::hex << s->con_features << std::dec << dendl;\n  assert(s->con);\n  assert(!s->closed);\n  for (set<uint64_t>::iterator p = s->routed_request_tids.begin();\n       p != s->routed_request_tids.end();\n       ++p) {\n    assert(routed_requests.count(*p));\n    RoutedRequest *rr = routed_requests[*p];\n    dout(10) << \" dropping routed request \" << rr->tid << dendl;\n    delete rr;\n    routed_requests.erase(*p);\n  }\n  s->routed_request_tids.clear();\n  s->con->set_priv(NULL);\n  session_map.remove_session(s);\n  logger->set(l_mon_num_sessions, session_map.get_size());\n  logger->inc(l_mon_session_rm);\n}\n\nvoid Monitor::remove_all_sessions()\n{\n  Mutex::Locker l(session_map_lock);\n  while (!session_map.sessions.empty()) {\n    MonSession *s = session_map.sessions.front();\n    remove_session(s);\n    if (logger)\n      logger->inc(l_mon_session_rm);\n  }\n  if (logger)\n    logger->set(l_mon_num_sessions, session_map.get_size());\n}\n\nvoid Monitor::send_command(const entity_inst_t& inst,\n\t\t\t   const vector<string>& com)\n{\n  dout(10) << \"send_command \" << inst << \"\" << com << dendl;\n  MMonCommand *c = new MMonCommand(monmap->fsid);\n  c->cmd = com;\n  try_send_message(c, inst);\n}\n\nvoid Monitor::waitlist_or_zap_client(MonOpRequestRef op)\n{\n  /**\n   * Wait list the new session until we're in the quorum, assuming it's\n   * sufficiently new.\n   * tick() will periodically send them back through so we can send\n   * the client elsewhere if we don't think we're getting back in.\n   *\n   * But we whitelist a few sorts of messages:\n   * 1) Monitors can talk to us at any time, of course.\n   * 2) auth messages. It's unlikely to go through much faster, but\n   * it's possible we've just lost our quorum status and we want to take...\n   * 3) command messages. We want to accept these under all possible\n   * circumstances.\n   */\n  Message *m = op->get_req();\n  MonSession *s = op->get_session();\n  ConnectionRef con = op->get_connection();\n  utime_t too_old = ceph_clock_now();\n  too_old -= g_ceph_context->_conf->mon_lease;\n  if (m->get_recv_stamp() > too_old &&\n      con->is_connected()) {\n    dout(5) << \"waitlisting message \" << *m << dendl;\n    maybe_wait_for_quorum.push_back(new C_RetryMessage(this, op));\n    op->mark_wait_for_quorum();\n  } else {\n    dout(5) << \"discarding message \" << *m << \" and sending client elsewhere\" << dendl;\n    con->mark_down();\n    // proxied sessions aren't registered and don't have a con; don't remove\n    // those.\n    if (!s->proxy_con) {\n      Mutex::Locker l(session_map_lock);\n      remove_session(s);\n    }\n    op->mark_zap();\n  }\n}\n\nvoid Monitor::_ms_dispatch(Message *m)\n{\n  if (is_shutdown()) {\n    m->put();\n    return;\n  }\n\n  MonOpRequestRef op = op_tracker.create_request<MonOpRequest>(m);\n  bool src_is_mon = op->is_src_mon();\n  op->mark_event(\"mon:_ms_dispatch\");\n  MonSession *s = op->get_session();\n  if (s && s->closed) {\n    return;\n  }\n\n  if (src_is_mon && s) {\n    ConnectionRef con = m->get_connection();\n    if (con->get_messenger() && con->get_features() != s->con_features) {\n      // only update features if this is a non-anonymous connection\n      dout(10) << __func__ << \" feature change for \" << m->get_source_inst()\n               << \" (was \" << s->con_features\n               << \", now \" << con->get_features() << \")\" << dendl;\n      // connection features changed - recreate session.\n      if (s->con && s->con != con) {\n        dout(10) << __func__ << \" connection for \" << m->get_source_inst()\n                 << \" changed from session; mark down and replace\" << dendl;\n        s->con->mark_down();\n      }\n      if (s->item.is_on_list()) {\n        // forwarded messages' sessions are not in the sessions map and\n        // exist only while the op is being handled.\n        remove_session(s);\n      }\n      s->put();\n      s = nullptr;\n    }\n  }\n\n  if (!s) {\n    // if the sender is not a monitor, make sure their first message for a\n    // session is an MAuth.  If it is not, assume it's a stray message,\n    // and considering that we are creating a new session it is safe to\n    // assume that the sender hasn't authenticated yet, so we have no way\n    // of assessing whether we should handle it or not.\n    if (!src_is_mon && (m->get_type() != CEPH_MSG_AUTH &&\n\t\t\tm->get_type() != CEPH_MSG_MON_GET_MAP &&\n\t\t\tm->get_type() != CEPH_MSG_PING)) {\n      dout(1) << __func__ << \" dropping stray message \" << *m\n\t      << \" from \" << m->get_source_inst() << dendl;\n      return;\n    }\n\n    ConnectionRef con = m->get_connection();\n    {\n      Mutex::Locker l(session_map_lock);\n      s = session_map.new_session(m->get_source_inst(), con.get());\n    }\n    assert(s);\n    con->set_priv(s->get());\n    dout(10) << __func__ << \" new session \" << s << \" \" << *s\n\t     << \" features 0x\" << std::hex\n\t     << s->con_features << std::dec << dendl;\n    op->set_session(s);\n\n    logger->set(l_mon_num_sessions, session_map.get_size());\n    logger->inc(l_mon_session_add);\n\n    if (src_is_mon) {\n      // give it monitor caps; the peer type has been authenticated\n      dout(5) << __func__ << \" setting monitor caps on this connection\" << dendl;\n      if (!s->caps.is_allow_all()) // but no need to repeatedly copy\n        s->caps = *mon_caps;\n    }\n    s->put();\n  } else {\n    dout(20) << __func__ << \" existing session \" << s << \" for \" << s->inst\n\t     << dendl;\n  }\n\n  assert(s);\n\n  s->session_timeout = ceph_clock_now();\n  s->session_timeout += g_conf->mon_session_timeout;\n\n  if (s->auth_handler) {\n    s->entity_name = s->auth_handler->get_entity_name();\n  }\n  dout(20) << \" caps \" << s->caps.get_str() << dendl;\n\n  if ((is_synchronizing() ||\n       (s->global_id == 0 && !exited_quorum.is_zero())) &&\n      !src_is_mon &&\n      m->get_type() != CEPH_MSG_PING) {\n    waitlist_or_zap_client(op);\n  } else {\n    dispatch_op(op);\n  }\n  return;\n}\n\nvoid Monitor::dispatch_op(MonOpRequestRef op)\n{\n  op->mark_event(\"mon:dispatch_op\");\n  MonSession *s = op->get_session();\n  assert(s);\n  if (s->closed) {\n    dout(10) << \" session closed, dropping \" << op->get_req() << dendl;\n    return;\n  }\n\n  /* we will consider the default type as being 'monitor' until proven wrong */\n  op->set_type_monitor();\n  /* deal with all messages that do not necessarily need caps */\n  bool dealt_with = true;\n  switch (op->get_req()->get_type()) {\n    // auth\n    case MSG_MON_GLOBAL_ID:\n    case CEPH_MSG_AUTH:\n      op->set_type_service();\n      /* no need to check caps here */\n      paxos_service[PAXOS_AUTH]->dispatch(op);\n      break;\n\n    case CEPH_MSG_PING:\n      handle_ping(op);\n      break;\n\n    /* MMonGetMap may be used by clients to obtain a monmap *before*\n     * authenticating with the monitor.  We need to handle these without\n     * checking caps because, even on a cluster without cephx, we only set\n     * session caps *after* the auth handshake.  A good example of this\n     * is when a client calls MonClient::get_monmap_privately(), which does\n     * not authenticate when obtaining a monmap.\n     */\n    case CEPH_MSG_MON_GET_MAP:\n      handle_mon_get_map(op);\n      break;\n\n    case CEPH_MSG_MON_METADATA:\n      return handle_mon_metadata(op);\n\n    default:\n      dealt_with = false;\n      break;\n  }\n  if (dealt_with)\n    return;\n\n  /* well, maybe the op belongs to a service... */\n  op->set_type_service();\n  /* deal with all messages which caps should be checked somewhere else */\n  dealt_with = true;\n  switch (op->get_req()->get_type()) {\n\n    // OSDs\n    case CEPH_MSG_MON_GET_OSDMAP:\n    case CEPH_MSG_POOLOP:\n    case MSG_OSD_BEACON:\n    case MSG_OSD_MARK_ME_DOWN:\n    case MSG_OSD_FULL:\n    case MSG_OSD_FAILURE:\n    case MSG_OSD_BOOT:\n    case MSG_OSD_ALIVE:\n    case MSG_OSD_PGTEMP:\n    case MSG_OSD_PG_CREATED:\n    case MSG_REMOVE_SNAPS:\n      paxos_service[PAXOS_OSDMAP]->dispatch(op);\n      break;\n\n    // MDSs\n    case MSG_MDS_BEACON:\n    case MSG_MDS_OFFLOAD_TARGETS:\n      paxos_service[PAXOS_MDSMAP]->dispatch(op);\n      break;\n\n    // Mgrs\n    case MSG_MGR_BEACON:\n      paxos_service[PAXOS_MGR]->dispatch(op);\n      break;\n\n    // MgrStat\n    case CEPH_MSG_STATFS:\n      // this is an ugly hack, sorry!  force the version to 1 so that we do\n      // not run afoul of the is_readable() paxos check.  the client is going\n      // by the pgmonitor version and the MgrStatMonitor version will lag behind\n      // that until we complete the upgrade.  The paxos ordering crap really\n      // doesn't matter for statfs results, so just kludge around it here.\n      if (osdmon()->osdmap.require_osd_release < CEPH_RELEASE_LUMINOUS) {\n\t((MStatfs*)op->get_req())->version = 1;\n      }\n    case MSG_MON_MGR_REPORT:\n    case MSG_GETPOOLSTATS:\n      paxos_service[PAXOS_MGRSTAT]->dispatch(op);\n      break;\n\n    // pg\n    case MSG_PGSTATS:\n      paxos_service[PAXOS_PGMAP]->dispatch(op);\n      break;\n\n    // log\n    case MSG_LOG:\n      paxos_service[PAXOS_LOG]->dispatch(op);\n      break;\n\n    // handle_command() does its own caps checking\n    case MSG_MON_COMMAND:\n      op->set_type_command();\n      handle_command(op);\n      break;\n\n    default:\n      dealt_with = false;\n      break;\n  }\n  if (dealt_with)\n    return;\n\n  /* nop, looks like it's not a service message; revert back to monitor */\n  op->set_type_monitor();\n\n  /* messages we, the Monitor class, need to deal with\n   * but may be sent by clients. */\n\n  if (!op->get_session()->is_capable(\"mon\", MON_CAP_R)) {\n    dout(5) << __func__ << \" \" << op->get_req()->get_source_inst()\n            << \" not enough caps for \" << *(op->get_req()) << \" -- dropping\"\n            << dendl;\n    goto drop;\n  }\n\n  dealt_with = true;\n  switch (op->get_req()->get_type()) {\n\n    // misc\n    case CEPH_MSG_MON_GET_VERSION:\n      handle_get_version(op);\n      break;\n\n    case CEPH_MSG_MON_SUBSCRIBE:\n      /* FIXME: check what's being subscribed, filter accordingly */\n      handle_subscribe(op);\n      break;\n\n    default:\n      dealt_with = false;\n      break;\n  }\n  if (dealt_with)\n    return;\n\n  if (!op->is_src_mon()) {\n    dout(1) << __func__ << \" unexpected monitor message from\"\n            << \" non-monitor entity \" << op->get_req()->get_source_inst()\n            << \" \" << *(op->get_req()) << \" -- dropping\" << dendl;\n    goto drop;\n  }\n\n  /* messages that should only be sent by another monitor */\n  dealt_with = true;\n  switch (op->get_req()->get_type()) {\n\n    case MSG_ROUTE:\n      handle_route(op);\n      break;\n\n    case MSG_MON_PROBE:\n      handle_probe(op);\n      break;\n\n    // Sync (i.e., the new slurp, but on steroids)\n    case MSG_MON_SYNC:\n      handle_sync(op);\n      break;\n    case MSG_MON_SCRUB:\n      handle_scrub(op);\n      break;\n\n    /* log acks are sent from a monitor we sent the MLog to, and are\n       never sent by clients to us. */\n    case MSG_LOGACK:\n      log_client.handle_log_ack((MLogAck*)op->get_req());\n      break;\n\n    // monmap\n    case MSG_MON_JOIN:\n      op->set_type_service();\n      paxos_service[PAXOS_MONMAP]->dispatch(op);\n      break;\n\n    // paxos\n    case MSG_MON_PAXOS:\n      {\n        op->set_type_paxos();\n        MMonPaxos *pm = static_cast<MMonPaxos*>(op->get_req());\n        if (!op->get_session()->is_capable(\"mon\", MON_CAP_X)) {\n          //can't send these!\n          break;\n        }\n\n        if (state == STATE_SYNCHRONIZING) {\n          // we are synchronizing. These messages would do us no\n          // good, thus just drop them and ignore them.\n          dout(10) << __func__ << \" ignore paxos msg from \"\n            << pm->get_source_inst() << dendl;\n          break;\n        }\n\n        // sanitize\n        if (pm->epoch > get_epoch()) {\n          bootstrap();\n          break;\n        }\n        if (pm->epoch != get_epoch()) {\n          break;\n        }\n\n        paxos->dispatch(op);\n      }\n      break;\n\n    // elector messages\n    case MSG_MON_ELECTION:\n      op->set_type_election();\n      //check privileges here for simplicity\n      if (!op->get_session()->is_capable(\"mon\", MON_CAP_X)) {\n        dout(0) << \"MMonElection received from entity without enough caps!\"\n          << op->get_session()->caps << dendl;\n        break;\n      }\n      if (!is_probing() && !is_synchronizing()) {\n        elector.dispatch(op);\n      }\n      break;\n\n    case MSG_FORWARD:\n      handle_forward(op);\n      break;\n\n    case MSG_TIMECHECK:\n      handle_timecheck(op);\n      break;\n\n    case MSG_MON_HEALTH:\n      health_monitor->dispatch(op);\n      break;\n\n    case MSG_MON_HEALTH_CHECKS:\n      op->set_type_service();\n      paxos_service[PAXOS_HEALTH]->dispatch(op);\n      break;\n\n    default:\n      dealt_with = false;\n      break;\n  }\n  if (!dealt_with) {\n    dout(1) << \"dropping unexpected \" << *(op->get_req()) << dendl;\n    goto drop;\n  }\n  return;\n\ndrop:\n  return;\n}\n\nvoid Monitor::handle_ping(MonOpRequestRef op)\n{\n  MPing *m = static_cast<MPing*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n  MPing *reply = new MPing;\n  entity_inst_t inst = m->get_source_inst();\n  bufferlist payload;\n  boost::scoped_ptr<Formatter> f(new JSONFormatter(true));\n  f->open_object_section(\"pong\");\n\n  if (osdmon()->osdmap.require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n    get_health_status(false, f.get(), nullptr);\n  } else {\n    list<string> health_str;\n    get_health(health_str, nullptr, f.get());\n  }\n\n  {\n    stringstream ss;\n    get_mon_status(f.get(), ss);\n  }\n\n  f->close_section();\n  stringstream ss;\n  f->flush(ss);\n  ::encode(ss.str(), payload);\n  reply->set_payload(payload);\n  dout(10) << __func__ << \" reply payload len \" << reply->get_payload().length() << dendl;\n  messenger->send_message(reply, inst);\n}\n\nvoid Monitor::timecheck_start()\n{\n  dout(10) << __func__ << dendl;\n  timecheck_cleanup();\n  timecheck_start_round();\n}\n\nvoid Monitor::timecheck_finish()\n{\n  dout(10) << __func__ << dendl;\n  timecheck_cleanup();\n}\n\nvoid Monitor::timecheck_start_round()\n{\n  dout(10) << __func__ << \" curr \" << timecheck_round << dendl;\n  assert(is_leader());\n\n  if (monmap->size() == 1) {\n    assert(0 == \"We are alone; this shouldn't have been scheduled!\");\n    return;\n  }\n\n  if (timecheck_round % 2) {\n    dout(10) << __func__ << \" there's a timecheck going on\" << dendl;\n    utime_t curr_time = ceph_clock_now();\n    double max = g_conf->mon_timecheck_interval*3;\n    if (curr_time - timecheck_round_start < max) {\n      dout(10) << __func__ << \" keep current round going\" << dendl;\n      goto out;\n    } else {\n      dout(10) << __func__\n               << \" finish current timecheck and start new\" << dendl;\n      timecheck_cancel_round();\n    }\n  }\n\n  assert(timecheck_round % 2 == 0);\n  timecheck_acks = 0;\n  timecheck_round ++;\n  timecheck_round_start = ceph_clock_now();\n  dout(10) << __func__ << \" new \" << timecheck_round << dendl;\n\n  timecheck();\nout:\n  dout(10) << __func__ << \" setting up next event\" << dendl;\n  timecheck_reset_event();\n}\n\nvoid Monitor::timecheck_finish_round(bool success)\n{\n  dout(10) << __func__ << \" curr \" << timecheck_round << dendl;\n  assert(timecheck_round % 2);\n  timecheck_round ++;\n  timecheck_round_start = utime_t();\n\n  if (success) {\n    assert(timecheck_waiting.empty());\n    assert(timecheck_acks == quorum.size());\n    timecheck_report();\n    timecheck_check_skews();\n    return;\n  }\n\n  dout(10) << __func__ << \" \" << timecheck_waiting.size()\n           << \" peers still waiting:\";\n  for (map<entity_inst_t,utime_t>::iterator p = timecheck_waiting.begin();\n      p != timecheck_waiting.end(); ++p) {\n    *_dout << \" \" << p->first.name;\n  }\n  *_dout << dendl;\n  timecheck_waiting.clear();\n\n  dout(10) << __func__ << \" finished to \" << timecheck_round << dendl;\n}\n\nvoid Monitor::timecheck_cancel_round()\n{\n  timecheck_finish_round(false);\n}\n\nvoid Monitor::timecheck_cleanup()\n{\n  timecheck_round = 0;\n  timecheck_acks = 0;\n  timecheck_round_start = utime_t();\n\n  if (timecheck_event) {\n    timer.cancel_event(timecheck_event);\n    timecheck_event = NULL;\n  }\n  timecheck_waiting.clear();\n  timecheck_skews.clear();\n  timecheck_latencies.clear();\n\n  timecheck_rounds_since_clean = 0;\n}\n\nvoid Monitor::timecheck_reset_event()\n{\n  if (timecheck_event) {\n    timer.cancel_event(timecheck_event);\n    timecheck_event = NULL;\n  }\n\n  double delay =\n    cct->_conf->mon_timecheck_skew_interval * timecheck_rounds_since_clean;\n\n  if (delay <= 0 || delay > cct->_conf->mon_timecheck_interval) {\n    delay = cct->_conf->mon_timecheck_interval;\n  }\n\n  dout(10) << __func__ << \" delay \" << delay\n           << \" rounds_since_clean \" << timecheck_rounds_since_clean\n           << dendl;\n\n  timecheck_event = timer.add_event_after(\n    delay,\n    new C_MonContext(this, [this](int) {\n\ttimecheck_start_round();\n      }));\n}\n\nvoid Monitor::timecheck_check_skews()\n{\n  dout(10) << __func__ << dendl;\n  assert(is_leader());\n  assert((timecheck_round % 2) == 0);\n  if (monmap->size() == 1) {\n    assert(0 == \"We are alone; we shouldn't have gotten here!\");\n    return;\n  }\n  assert(timecheck_latencies.size() == timecheck_skews.size());\n\n  bool found_skew = false;\n  for (map<entity_inst_t, double>::iterator p = timecheck_skews.begin();\n       p != timecheck_skews.end(); ++p) {\n\n    double abs_skew;\n    if (timecheck_has_skew(p->second, &abs_skew)) {\n      dout(10) << __func__\n               << \" \" << p->first << \" skew \" << abs_skew << dendl;\n      found_skew = true;\n    }\n  }\n\n  if (found_skew) {\n    ++timecheck_rounds_since_clean;\n    timecheck_reset_event();\n  } else if (timecheck_rounds_since_clean > 0) {\n    dout(1) << __func__\n      << \" no clock skews found after \" << timecheck_rounds_since_clean\n      << \" rounds\" << dendl;\n    // make sure the skews are really gone and not just a transient success\n    // this will run just once if not in the presence of skews again.\n    timecheck_rounds_since_clean = 1;\n    timecheck_reset_event();\n    timecheck_rounds_since_clean = 0;\n  }\n\n}\n\nvoid Monitor::timecheck_report()\n{\n  dout(10) << __func__ << dendl;\n  assert(is_leader());\n  assert((timecheck_round % 2) == 0);\n  if (monmap->size() == 1) {\n    assert(0 == \"We are alone; we shouldn't have gotten here!\");\n    return;\n  }\n\n  assert(timecheck_latencies.size() == timecheck_skews.size());\n  bool do_output = true; // only output report once\n  for (set<int>::iterator q = quorum.begin(); q != quorum.end(); ++q) {\n    if (monmap->get_name(*q) == name)\n      continue;\n\n    MTimeCheck *m = new MTimeCheck(MTimeCheck::OP_REPORT);\n    m->epoch = get_epoch();\n    m->round = timecheck_round;\n\n    for (map<entity_inst_t, double>::iterator it = timecheck_skews.begin();\n         it != timecheck_skews.end(); ++it) {\n      double skew = it->second;\n      double latency = timecheck_latencies[it->first];\n\n      m->skews[it->first] = skew;\n      m->latencies[it->first] = latency;\n\n      if (do_output) {\n        dout(25) << __func__ << \" \" << it->first\n                 << \" latency \" << latency\n                 << \" skew \" << skew << dendl;\n      }\n    }\n    do_output = false;\n    entity_inst_t inst = monmap->get_inst(*q);\n    dout(10) << __func__ << \" send report to \" << inst << dendl;\n    messenger->send_message(m, inst);\n  }\n}\n\nvoid Monitor::timecheck()\n{\n  dout(10) << __func__ << dendl;\n  assert(is_leader());\n  if (monmap->size() == 1) {\n    assert(0 == \"We are alone; we shouldn't have gotten here!\");\n    return;\n  }\n  assert(timecheck_round % 2 != 0);\n\n  timecheck_acks = 1; // we ack ourselves\n\n  dout(10) << __func__ << \" start timecheck epoch \" << get_epoch()\n           << \" round \" << timecheck_round << dendl;\n\n  // we are at the eye of the storm; the point of reference\n  timecheck_skews[messenger->get_myinst()] = 0.0;\n  timecheck_latencies[messenger->get_myinst()] = 0.0;\n\n  for (set<int>::iterator it = quorum.begin(); it != quorum.end(); ++it) {\n    if (monmap->get_name(*it) == name)\n      continue;\n\n    entity_inst_t inst = monmap->get_inst(*it);\n    utime_t curr_time = ceph_clock_now();\n    timecheck_waiting[inst] = curr_time;\n    MTimeCheck *m = new MTimeCheck(MTimeCheck::OP_PING);\n    m->epoch = get_epoch();\n    m->round = timecheck_round;\n    dout(10) << __func__ << \" send \" << *m << \" to \" << inst << dendl;\n    messenger->send_message(m, inst);\n  }\n}\n\nhealth_status_t Monitor::timecheck_status(ostringstream &ss,\n                                          const double skew_bound,\n                                          const double latency)\n{\n  health_status_t status = HEALTH_OK;\n  assert(latency >= 0);\n\n  double abs_skew;\n  if (timecheck_has_skew(skew_bound, &abs_skew)) {\n    status = HEALTH_WARN;\n    ss << \"clock skew \" << abs_skew << \"s\"\n       << \" > max \" << g_conf->mon_clock_drift_allowed << \"s\";\n  }\n\n  return status;\n}\n\nvoid Monitor::handle_timecheck_leader(MonOpRequestRef op)\n{\n  MTimeCheck *m = static_cast<MTimeCheck*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n  /* handles PONG's */\n  assert(m->op == MTimeCheck::OP_PONG);\n\n  entity_inst_t other = m->get_source_inst();\n  if (m->epoch < get_epoch()) {\n    dout(1) << __func__ << \" got old timecheck epoch \" << m->epoch\n            << \" from \" << other\n            << \" curr \" << get_epoch()\n            << \" -- severely lagged? discard\" << dendl;\n    return;\n  }\n  assert(m->epoch == get_epoch());\n\n  if (m->round < timecheck_round) {\n    dout(1) << __func__ << \" got old round \" << m->round\n            << \" from \" << other\n            << \" curr \" << timecheck_round << \" -- discard\" << dendl;\n    return;\n  }\n\n  utime_t curr_time = ceph_clock_now();\n\n  assert(timecheck_waiting.count(other) > 0);\n  utime_t timecheck_sent = timecheck_waiting[other];\n  timecheck_waiting.erase(other);\n  if (curr_time < timecheck_sent) {\n    // our clock was readjusted -- drop everything until it all makes sense.\n    dout(1) << __func__ << \" our clock was readjusted --\"\n            << \" bump round and drop current check\"\n            << dendl;\n    timecheck_cancel_round();\n    return;\n  }\n\n  /* update peer latencies */\n  double latency = (double)(curr_time - timecheck_sent);\n\n  if (timecheck_latencies.count(other) == 0)\n    timecheck_latencies[other] = latency;\n  else {\n    double avg_latency = ((timecheck_latencies[other]*0.8)+(latency*0.2));\n    timecheck_latencies[other] = avg_latency;\n  }\n\n  /*\n   * update skews\n   *\n   * some nasty thing goes on if we were to do 'a - b' between two utime_t,\n   * and 'a' happens to be lower than 'b'; so we use double instead.\n   *\n   * latency is always expected to be >= 0.\n   *\n   * delta, the difference between theirs timestamp and ours, may either be\n   * lower or higher than 0; will hardly ever be 0.\n   *\n   * The absolute skew is the absolute delta minus the latency, which is\n   * taken as a whole instead of an rtt given that there is some queueing\n   * and dispatch times involved and it's hard to assess how long exactly\n   * it took for the message to travel to the other side and be handled. So\n   * we call it a bounded skew, the worst case scenario.\n   *\n   * Now, to math!\n   *\n   * Given that the latency is always positive, we can establish that the\n   * bounded skew will be:\n   *\n   *  1. positive if the absolute delta is higher than the latency and\n   *     delta is positive\n   *  2. negative if the absolute delta is higher than the latency and\n   *     delta is negative.\n   *  3. zero if the absolute delta is lower than the latency.\n   *\n   * On 3. we make a judgement call and treat the skew as non-existent.\n   * This is because that, if the absolute delta is lower than the\n   * latency, then the apparently existing skew is nothing more than a\n   * side-effect of the high latency at work.\n   *\n   * This may not be entirely true though, as a severely skewed clock\n   * may be masked by an even higher latency, but with high latencies\n   * we probably have worse issues to deal with than just skewed clocks.\n   */\n  assert(latency >= 0);\n\n  double delta = ((double) m->timestamp) - ((double) curr_time);\n  double abs_delta = (delta > 0 ? delta : -delta);\n  double skew_bound = abs_delta - latency;\n  if (skew_bound < 0)\n    skew_bound = 0;\n  else if (delta < 0)\n    skew_bound = -skew_bound;\n\n  ostringstream ss;\n  health_status_t status = timecheck_status(ss, skew_bound, latency);\n  if (status != HEALTH_OK) {\n    clog->health(status) << other << \" \" << ss.str();\n  }\n\n  dout(10) << __func__ << \" from \" << other << \" ts \" << m->timestamp\n\t   << \" delta \" << delta << \" skew_bound \" << skew_bound\n\t   << \" latency \" << latency << dendl;\n\n  timecheck_skews[other] = skew_bound;\n\n  timecheck_acks++;\n  if (timecheck_acks == quorum.size()) {\n    dout(10) << __func__ << \" got pongs from everybody (\"\n             << timecheck_acks << \" total)\" << dendl;\n    assert(timecheck_skews.size() == timecheck_acks);\n    assert(timecheck_waiting.empty());\n    // everyone has acked, so bump the round to finish it.\n    timecheck_finish_round();\n  }\n}\n\nvoid Monitor::handle_timecheck_peon(MonOpRequestRef op)\n{\n  MTimeCheck *m = static_cast<MTimeCheck*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n\n  assert(is_peon());\n  assert(m->op == MTimeCheck::OP_PING || m->op == MTimeCheck::OP_REPORT);\n\n  if (m->epoch != get_epoch()) {\n    dout(1) << __func__ << \" got wrong epoch \"\n            << \"(ours \" << get_epoch()\n            << \" theirs: \" << m->epoch << \") -- discarding\" << dendl;\n    return;\n  }\n\n  if (m->round < timecheck_round) {\n    dout(1) << __func__ << \" got old round \" << m->round\n            << \" current \" << timecheck_round\n            << \" (epoch \" << get_epoch() << \") -- discarding\" << dendl;\n    return;\n  }\n\n  timecheck_round = m->round;\n\n  if (m->op == MTimeCheck::OP_REPORT) {\n    assert((timecheck_round % 2) == 0);\n    timecheck_latencies.swap(m->latencies);\n    timecheck_skews.swap(m->skews);\n    return;\n  }\n\n  assert((timecheck_round % 2) != 0);\n  MTimeCheck *reply = new MTimeCheck(MTimeCheck::OP_PONG);\n  utime_t curr_time = ceph_clock_now();\n  reply->timestamp = curr_time;\n  reply->epoch = m->epoch;\n  reply->round = m->round;\n  dout(10) << __func__ << \" send \" << *m\n           << \" to \" << m->get_source_inst() << dendl;\n  m->get_connection()->send_message(reply);\n}\n\nvoid Monitor::handle_timecheck(MonOpRequestRef op)\n{\n  MTimeCheck *m = static_cast<MTimeCheck*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n\n  if (is_leader()) {\n    if (m->op != MTimeCheck::OP_PONG) {\n      dout(1) << __func__ << \" drop unexpected msg (not pong)\" << dendl;\n    } else {\n      handle_timecheck_leader(op);\n    }\n  } else if (is_peon()) {\n    if (m->op != MTimeCheck::OP_PING && m->op != MTimeCheck::OP_REPORT) {\n      dout(1) << __func__ << \" drop unexpected msg (not ping or report)\" << dendl;\n    } else {\n      handle_timecheck_peon(op);\n    }\n  } else {\n    dout(1) << __func__ << \" drop unexpected msg\" << dendl;\n  }\n}\n\nvoid Monitor::handle_subscribe(MonOpRequestRef op)\n{\n  MMonSubscribe *m = static_cast<MMonSubscribe*>(op->get_req());\n  dout(10) << \"handle_subscribe \" << *m << dendl;\n  \n  bool reply = false;\n\n  MonSession *s = op->get_session();\n  assert(s);\n\n  for (map<string,ceph_mon_subscribe_item>::iterator p = m->what.begin();\n       p != m->what.end();\n       ++p) {\n    // if there are any non-onetime subscriptions, we need to reply to start the resubscribe timer\n    if ((p->second.flags & CEPH_SUBSCRIBE_ONETIME) == 0)\n      reply = true;\n\n    // remove conflicting subscribes\n    if (logmon()->sub_name_to_id(p->first) >= 0) {\n      for (map<string, Subscription*>::iterator it = s->sub_map.begin();\n\t   it != s->sub_map.end(); ) {\n\tif (it->first != p->first && logmon()->sub_name_to_id(it->first) >= 0) {\n\t  Mutex::Locker l(session_map_lock);\n\t  session_map.remove_sub((it++)->second);\n\t} else {\n\t  ++it;\n\t}\n      }\n    }\n\n    {\n      Mutex::Locker l(session_map_lock);\n      session_map.add_update_sub(s, p->first, p->second.start,\n\t\t\t\t p->second.flags & CEPH_SUBSCRIBE_ONETIME,\n\t\t\t\t m->get_connection()->has_feature(CEPH_FEATURE_INCSUBOSDMAP));\n    }\n\n    if (p->first.compare(0, 6, \"mdsmap\") == 0 || p->first.compare(0, 5, \"fsmap\") == 0) {\n      dout(10) << __func__ << \": MDS sub '\" << p->first << \"'\" << dendl;\n      if ((int)s->is_capable(\"mds\", MON_CAP_R)) {\n        Subscription *sub = s->sub_map[p->first];\n        assert(sub != nullptr);\n        mdsmon()->check_sub(sub);\n      }\n    } else if (p->first == \"osdmap\") {\n      if ((int)s->is_capable(\"osd\", MON_CAP_R)) {\n\tif (s->osd_epoch > p->second.start) {\n\t  // client needs earlier osdmaps on purpose, so reset the sent epoch\n\t  s->osd_epoch = 0;\n\t}\n        osdmon()->check_osdmap_sub(s->sub_map[\"osdmap\"]);\n      }\n    } else if (p->first == \"osd_pg_creates\") {\n      if ((int)s->is_capable(\"osd\", MON_CAP_W)) {\n\tif (monmap->get_required_features().contains_all(\n\t      ceph::features::mon::FEATURE_LUMINOUS)) {\n\t  osdmon()->check_pg_creates_sub(s->sub_map[\"osd_pg_creates\"]);\n\t} else {\n\t  pgmon()->check_sub(s->sub_map[\"osd_pg_creates\"]);\n\t}\n      }\n    } else if (p->first == \"monmap\") {\n      monmon()->check_sub(s->sub_map[p->first]);\n    } else if (logmon()->sub_name_to_id(p->first) >= 0) {\n      logmon()->check_sub(s->sub_map[p->first]);\n    } else if (p->first == \"mgrmap\" || p->first == \"mgrdigest\") {\n      mgrmon()->check_sub(s->sub_map[p->first]);\n    } else if (p->first == \"servicemap\") {\n      mgrstatmon()->check_sub(s->sub_map[p->first]);\n    }\n  }\n\n  if (reply) {\n    // we only need to reply if the client is old enough to think it\n    // has to send renewals.\n    ConnectionRef con = m->get_connection();\n    if (!con->has_feature(CEPH_FEATURE_MON_STATEFUL_SUB))\n      m->get_connection()->send_message(new MMonSubscribeAck(\n\tmonmap->get_fsid(), (int)g_conf->mon_subscribe_interval));\n  }\n\n}\n\nvoid Monitor::handle_get_version(MonOpRequestRef op)\n{\n  MMonGetVersion *m = static_cast<MMonGetVersion*>(op->get_req());\n  dout(10) << \"handle_get_version \" << *m << dendl;\n  PaxosService *svc = NULL;\n\n  MonSession *s = op->get_session();\n  assert(s);\n\n  if (!is_leader() && !is_peon()) {\n    dout(10) << \" waiting for quorum\" << dendl;\n    waitfor_quorum.push_back(new C_RetryMessage(this, op));\n    goto out;\n  }\n\n  if (m->what == \"mdsmap\") {\n    svc = mdsmon();\n  } else if (m->what == \"fsmap\") {\n    svc = mdsmon();\n  } else if (m->what == \"osdmap\") {\n    svc = osdmon();\n  } else if (m->what == \"monmap\") {\n    svc = monmon();\n  } else {\n    derr << \"invalid map type \" << m->what << dendl;\n  }\n\n  if (svc) {\n    if (!svc->is_readable()) {\n      svc->wait_for_readable(op, new C_RetryMessage(this, op));\n      goto out;\n    }\n\n    MMonGetVersionReply *reply = new MMonGetVersionReply();\n    reply->handle = m->handle;\n    reply->version = svc->get_last_committed();\n    reply->oldest_version = svc->get_first_committed();\n    reply->set_tid(m->get_tid());\n\n    m->get_connection()->send_message(reply);\n  }\n out:\n  return;\n}\n\nbool Monitor::ms_handle_reset(Connection *con)\n{\n  dout(10) << \"ms_handle_reset \" << con << \" \" << con->get_peer_addr() << dendl;\n\n  // ignore lossless monitor sessions\n  if (con->get_peer_type() == CEPH_ENTITY_TYPE_MON)\n    return false;\n\n  MonSession *s = static_cast<MonSession *>(con->get_priv());\n  if (!s)\n    return false;\n\n  // break any con <-> session ref cycle\n  s->con->set_priv(NULL);\n\n  if (is_shutdown())\n    return false;\n\n  Mutex::Locker l(lock);\n\n  dout(10) << \"reset/close on session \" << s->inst << dendl;\n  if (!s->closed) {\n    Mutex::Locker l(session_map_lock);\n    remove_session(s);\n  }\n  s->put();\n  return true;\n}\n\nbool Monitor::ms_handle_refused(Connection *con)\n{\n  // just log for now...\n  dout(10) << \"ms_handle_refused \" << con << \" \" << con->get_peer_addr() << dendl;\n  return false;\n}\n\n// -----\n\nvoid Monitor::send_latest_monmap(Connection *con)\n{\n  bufferlist bl;\n  monmap->encode(bl, con->get_features());\n  con->send_message(new MMonMap(bl));\n}\n\nvoid Monitor::handle_mon_get_map(MonOpRequestRef op)\n{\n  MMonGetMap *m = static_cast<MMonGetMap*>(op->get_req());\n  dout(10) << \"handle_mon_get_map\" << dendl;\n  send_latest_monmap(m->get_connection().get());\n}\n\nvoid Monitor::handle_mon_metadata(MonOpRequestRef op)\n{\n  MMonMetadata *m = static_cast<MMonMetadata*>(op->get_req());\n  if (is_leader()) {\n    dout(10) << __func__ << dendl;\n    update_mon_metadata(m->get_source().num(), std::move(m->data));\n  }\n}\n\nvoid Monitor::update_mon_metadata(int from, Metadata&& m)\n{\n  // NOTE: this is now for legacy (kraken or jewel) mons only.\n  pending_metadata[from] = std::move(m);\n\n  MonitorDBStore::TransactionRef t = paxos->get_pending_transaction();\n  bufferlist bl;\n  ::encode(pending_metadata, bl);\n  t->put(MONITOR_STORE_PREFIX, \"last_metadata\", bl);\n  paxos->trigger_propose();\n}\n\nint Monitor::load_metadata()\n{\n  bufferlist bl;\n  int r = store->get(MONITOR_STORE_PREFIX, \"last_metadata\", bl);\n  if (r)\n    return r;\n  bufferlist::iterator it = bl.begin();\n  ::decode(mon_metadata, it);\n\n  pending_metadata = mon_metadata;\n  return 0;\n}\n\nint Monitor::get_mon_metadata(int mon, Formatter *f, ostream& err)\n{\n  assert(f);\n  if (!mon_metadata.count(mon)) {\n    err << \"mon.\" << mon << \" not found\";\n    return -EINVAL;\n  }\n  const Metadata& m = mon_metadata[mon];\n  for (Metadata::const_iterator p = m.begin(); p != m.end(); ++p) {\n    f->dump_string(p->first.c_str(), p->second);\n  }\n  return 0;\n}\n\nvoid Monitor::count_metadata(const string& field, map<string,int> *out)\n{\n  for (auto& p : mon_metadata) {\n    auto q = p.second.find(field);\n    if (q == p.second.end()) {\n      (*out)[\"unknown\"]++;\n    } else {\n      (*out)[q->second]++;\n    }\n  }\n}\n\nvoid Monitor::count_metadata(const string& field, Formatter *f)\n{\n  map<string,int> by_val;\n  count_metadata(field, &by_val);\n  f->open_object_section(field.c_str());\n  for (auto& p : by_val) {\n    f->dump_int(p.first.c_str(), p.second);\n  }\n  f->close_section();\n}\n\nint Monitor::print_nodes(Formatter *f, ostream& err)\n{\n  map<string, list<int> > mons;\t// hostname => mon\n  for (map<int, Metadata>::iterator it = mon_metadata.begin();\n       it != mon_metadata.end(); ++it) {\n    const Metadata& m = it->second;\n    Metadata::const_iterator hostname = m.find(\"hostname\");\n    if (hostname == m.end()) {\n      // not likely though\n      continue;\n    }\n    mons[hostname->second].push_back(it->first);\n  }\n\n  dump_services(f, mons, \"mon\");\n  return 0;\n}\n\n// ----------------------------------------------\n// scrub\n\nint Monitor::scrub_start()\n{\n  dout(10) << __func__ << dendl;\n  assert(is_leader());\n\n  if (!scrub_result.empty()) {\n    clog->info() << \"scrub already in progress\";\n    return -EBUSY;\n  }\n\n  scrub_event_cancel();\n  scrub_result.clear();\n  scrub_state.reset(new ScrubState);\n\n  scrub();\n  return 0;\n}\n\nint Monitor::scrub()\n{\n  assert(is_leader());\n  assert(scrub_state);\n\n  scrub_cancel_timeout();\n  wait_for_paxos_write();\n  scrub_version = paxos->get_version();\n\n\n  // scrub all keys if we're the only monitor in the quorum\n  int32_t num_keys =\n    (quorum.size() == 1 ? -1 : cct->_conf->mon_scrub_max_keys);\n\n  for (set<int>::iterator p = quorum.begin();\n       p != quorum.end();\n       ++p) {\n    if (*p == rank)\n      continue;\n    MMonScrub *r = new MMonScrub(MMonScrub::OP_SCRUB, scrub_version,\n                                 num_keys);\n    r->key = scrub_state->last_key;\n    messenger->send_message(r, monmap->get_inst(*p));\n  }\n\n  // scrub my keys\n  bool r = _scrub(&scrub_result[rank],\n                  &scrub_state->last_key,\n                  &num_keys);\n\n  scrub_state->finished = !r;\n\n  // only after we got our scrub results do we really care whether the\n  // other monitors are late on their results.  Also, this way we avoid\n  // triggering the timeout if we end up getting stuck in _scrub() for\n  // longer than the duration of the timeout.\n  scrub_reset_timeout();\n\n  if (quorum.size() == 1) {\n    assert(scrub_state->finished == true);\n    scrub_finish();\n  }\n  return 0;\n}\n\nvoid Monitor::handle_scrub(MonOpRequestRef op)\n{\n  MMonScrub *m = static_cast<MMonScrub*>(op->get_req());\n  dout(10) << __func__ << \" \" << *m << dendl;\n  switch (m->op) {\n  case MMonScrub::OP_SCRUB:\n    {\n      if (!is_peon())\n\tbreak;\n\n      wait_for_paxos_write();\n\n      if (m->version != paxos->get_version())\n\tbreak;\n\n      MMonScrub *reply = new MMonScrub(MMonScrub::OP_RESULT,\n                                       m->version,\n                                       m->num_keys);\n\n      reply->key = m->key;\n      _scrub(&reply->result, &reply->key, &reply->num_keys);\n      m->get_connection()->send_message(reply);\n    }\n    break;\n\n  case MMonScrub::OP_RESULT:\n    {\n      if (!is_leader())\n\tbreak;\n      if (m->version != scrub_version)\n\tbreak;\n      // reset the timeout each time we get a result\n      scrub_reset_timeout();\n\n      int from = m->get_source().num();\n      assert(scrub_result.count(from) == 0);\n      scrub_result[from] = m->result;\n\n      if (scrub_result.size() == quorum.size()) {\n        scrub_check_results();\n        scrub_result.clear();\n        if (scrub_state->finished)\n          scrub_finish();\n        else\n          scrub();\n      }\n    }\n    break;\n  }\n}\n\nbool Monitor::_scrub(ScrubResult *r,\n                     pair<string,string> *start,\n                     int *num_keys)\n{\n  assert(r != NULL);\n  assert(start != NULL);\n  assert(num_keys != NULL);\n\n  set<string> prefixes = get_sync_targets_names();\n  prefixes.erase(\"paxos\");  // exclude paxos, as this one may have extra states for proposals, etc.\n\n  dout(10) << __func__ << \" start (\" << *start << \")\"\n           << \" num_keys \" << *num_keys << dendl;\n\n  MonitorDBStore::Synchronizer it = store->get_synchronizer(*start, prefixes);\n\n  int scrubbed_keys = 0;\n  pair<string,string> last_key;\n\n  while (it->has_next_chunk()) {\n\n    if (*num_keys > 0 && scrubbed_keys == *num_keys)\n      break;\n\n    pair<string,string> k = it->get_next_key();\n    if (prefixes.count(k.first) == 0)\n      continue;\n\n    if (cct->_conf->mon_scrub_inject_missing_keys > 0.0 &&\n        (rand() % 10000 < cct->_conf->mon_scrub_inject_missing_keys*10000.0)) {\n      dout(10) << __func__ << \" inject missing key, skipping (\" << k << \")\"\n               << dendl;\n      continue;\n    }\n\n    bufferlist bl;\n    int err = store->get(k.first, k.second, bl);\n    assert(err == 0);\n    \n    uint32_t key_crc = bl.crc32c(0);\n    dout(30) << __func__ << \" \" << k << \" bl \" << bl.length() << \" bytes\"\n                                     << \" crc \" << key_crc << dendl;\n    r->prefix_keys[k.first]++;\n    if (r->prefix_crc.count(k.first) == 0) {\n      r->prefix_crc[k.first] = 0;\n    }\n    r->prefix_crc[k.first] = bl.crc32c(r->prefix_crc[k.first]);\n\n    if (cct->_conf->mon_scrub_inject_crc_mismatch > 0.0 &&\n        (rand() % 10000 < cct->_conf->mon_scrub_inject_crc_mismatch*10000.0)) {\n      dout(10) << __func__ << \" inject failure at (\" << k << \")\" << dendl;\n      r->prefix_crc[k.first] += 1;\n    }\n\n    ++scrubbed_keys;\n    last_key = k;\n  }\n\n  dout(20) << __func__ << \" last_key (\" << last_key << \")\"\n                       << \" scrubbed_keys \" << scrubbed_keys\n                       << \" has_next \" << it->has_next_chunk() << dendl;\n\n  *start = last_key;\n  *num_keys = scrubbed_keys;\n\n  return it->has_next_chunk();\n}\n\nvoid Monitor::scrub_check_results()\n{\n  dout(10) << __func__ << dendl;\n\n  // compare\n  int errors = 0;\n  ScrubResult& mine = scrub_result[rank];\n  for (map<int,ScrubResult>::iterator p = scrub_result.begin();\n       p != scrub_result.end();\n       ++p) {\n    if (p->first == rank)\n      continue;\n    if (p->second != mine) {\n      ++errors;\n      clog->error() << \"scrub mismatch\";\n      clog->error() << \" mon.\" << rank << \" \" << mine;\n      clog->error() << \" mon.\" << p->first << \" \" << p->second;\n    }\n  }\n  if (!errors)\n    clog->debug() << \"scrub ok on \" << quorum << \": \" << mine;\n}\n\ninline void Monitor::scrub_timeout()\n{\n  dout(1) << __func__ << \" restarting scrub\" << dendl;\n  scrub_reset();\n  scrub_start();\n}\n\nvoid Monitor::scrub_finish()\n{\n  dout(10) << __func__ << dendl;\n  scrub_reset();\n  scrub_event_start();\n}\n\nvoid Monitor::scrub_reset()\n{\n  dout(10) << __func__ << dendl;\n  scrub_cancel_timeout();\n  scrub_version = 0;\n  scrub_result.clear();\n  scrub_state.reset();\n}\n\ninline void Monitor::scrub_update_interval(int secs)\n{\n  // we don't care about changes if we are not the leader.\n  // changes will be visible if we become the leader.\n  if (!is_leader())\n    return;\n\n  dout(1) << __func__ << \" new interval = \" << secs << dendl;\n\n  // if scrub already in progress, all changes will already be visible during\n  // the next round.  Nothing to do.\n  if (scrub_state != NULL)\n    return;\n\n  scrub_event_cancel();\n  scrub_event_start();\n}\n\nvoid Monitor::scrub_event_start()\n{\n  dout(10) << __func__ << dendl;\n\n  if (scrub_event)\n    scrub_event_cancel();\n\n  if (cct->_conf->mon_scrub_interval <= 0) {\n    dout(1) << __func__ << \" scrub event is disabled\"\n            << \" (mon_scrub_interval = \" << cct->_conf->mon_scrub_interval\n            << \")\" << dendl;\n    return;\n  }\n\n  scrub_event = timer.add_event_after(\n    cct->_conf->mon_scrub_interval,\n    new C_MonContext(this, [this](int) {\n      scrub_start();\n      }));\n}\n\nvoid Monitor::scrub_event_cancel()\n{\n  dout(10) << __func__ << dendl;\n  if (scrub_event) {\n    timer.cancel_event(scrub_event);\n    scrub_event = NULL;\n  }\n}\n\ninline void Monitor::scrub_cancel_timeout()\n{\n  if (scrub_timeout_event) {\n    timer.cancel_event(scrub_timeout_event);\n    scrub_timeout_event = NULL;\n  }\n}\n\nvoid Monitor::scrub_reset_timeout()\n{\n  dout(15) << __func__ << \" reset timeout event\" << dendl;\n  scrub_cancel_timeout();\n  scrub_timeout_event = timer.add_event_after(\n    g_conf->mon_scrub_timeout,\n    new C_MonContext(this, [this](int) {\n      scrub_timeout();\n    }));\n}\n\n/************ TICK ***************/\nvoid Monitor::new_tick()\n{\n  timer.add_event_after(g_conf->mon_tick_interval, new C_MonContext(this, [this](int) {\n\ttick();\n      }));\n}\n\nvoid Monitor::tick()\n{\n  // ok go.\n  dout(11) << \"tick\" << dendl;\n  const utime_t now = ceph_clock_now();\n  \n  // Check if we need to emit any delayed health check updated messages\n  if (is_leader()) {\n    const auto min_period = g_conf->get_val<int64_t>(\n                              \"mon_health_log_update_period\");\n    for (auto& svc : paxos_service) {\n      auto health = svc->get_health_checks();\n\n      for (const auto &i : health.checks) {\n        const std::string &code = i.first;\n        const std::string &summary = i.second.summary;\n        const health_status_t severity = i.second.severity;\n\n        auto status_iter = health_check_log_times.find(code);\n        if (status_iter == health_check_log_times.end()) {\n          continue;\n        }\n\n        auto &log_status = status_iter->second;\n        bool const changed = log_status.last_message != summary\n                             || log_status.severity != severity;\n\n        if (changed && now - log_status.updated_at > min_period) {\n          log_status.last_message = summary;\n          log_status.updated_at = now;\n          log_status.severity = severity;\n\n          ostringstream ss;\n          ss << \"Health check update: \" << summary << \" (\" << code << \")\";\n          clog->health(severity) << ss.str();\n        }\n      }\n    }\n  }\n\n\n  for (vector<PaxosService*>::iterator p = paxos_service.begin(); p != paxos_service.end(); ++p) {\n    (*p)->tick();\n    (*p)->maybe_trim();\n  }\n  \n  // trim sessions\n  {\n    Mutex::Locker l(session_map_lock);\n    auto p = session_map.sessions.begin();\n\n    bool out_for_too_long = (!exited_quorum.is_zero() &&\n\t\t\t     now > (exited_quorum + 2*g_conf->mon_lease));\n\n    while (!p.end()) {\n      MonSession *s = *p;\n      ++p;\n    \n      // don't trim monitors\n      if (s->inst.name.is_mon())\n\tcontinue;\n\n      if (s->session_timeout < now && s->con) {\n\t// check keepalive, too\n\ts->session_timeout = s->con->get_last_keepalive();\n\ts->session_timeout += g_conf->mon_session_timeout;\n      }\n      if (s->session_timeout < now) {\n\tdout(10) << \" trimming session \" << s->con << \" \" << s->inst\n\t\t << \" (timeout \" << s->session_timeout\n\t\t << \" < now \" << now << \")\" << dendl;\n      } else if (out_for_too_long) {\n\t// boot the client Session because we've taken too long getting back in\n\tdout(10) << \" trimming session \" << s->con << \" \" << s->inst\n\t\t << \" because we've been out of quorum too long\" << dendl;\n      } else {\n\tcontinue;\n      }\n\n      s->con->mark_down();\n      remove_session(s);\n      logger->inc(l_mon_session_trim);\n    }\n  }\n  sync_trim_providers();\n\n  if (!maybe_wait_for_quorum.empty()) {\n    finish_contexts(g_ceph_context, maybe_wait_for_quorum);\n  }\n\n  if (is_leader() && paxos->is_active() && fingerprint.is_zero()) {\n    // this is only necessary on upgraded clusters.\n    MonitorDBStore::TransactionRef t = paxos->get_pending_transaction();\n    prepare_new_fingerprint(t);\n    paxos->trigger_propose();\n  }\n\n  new_tick();\n}\n\nvoid Monitor::prepare_new_fingerprint(MonitorDBStore::TransactionRef t)\n{\n  uuid_d nf;\n  nf.generate_random();\n  dout(10) << __func__ << \" proposing cluster_fingerprint \" << nf << dendl;\n\n  bufferlist bl;\n  ::encode(nf, bl);\n  t->put(MONITOR_NAME, \"cluster_fingerprint\", bl);\n}\n\nint Monitor::check_fsid()\n{\n  bufferlist ebl;\n  int r = store->get(MONITOR_NAME, \"cluster_uuid\", ebl);\n  if (r == -ENOENT)\n    return r;\n  assert(r == 0);\n\n  string es(ebl.c_str(), ebl.length());\n\n  // only keep the first line\n  size_t pos = es.find_first_of('\\n');\n  if (pos != string::npos)\n    es.resize(pos);\n\n  dout(10) << \"check_fsid cluster_uuid contains '\" << es << \"'\" << dendl;\n  uuid_d ondisk;\n  if (!ondisk.parse(es.c_str())) {\n    derr << \"error: unable to parse uuid\" << dendl;\n    return -EINVAL;\n  }\n\n  if (monmap->get_fsid() != ondisk) {\n    derr << \"error: cluster_uuid file exists with value \" << ondisk\n\t << \", != our uuid \" << monmap->get_fsid() << dendl;\n    return -EEXIST;\n  }\n\n  return 0;\n}\n\nint Monitor::write_fsid()\n{\n  auto t(std::make_shared<MonitorDBStore::Transaction>());\n  write_fsid(t);\n  int r = store->apply_transaction(t);\n  return r;\n}\n\nint Monitor::write_fsid(MonitorDBStore::TransactionRef t)\n{\n  ostringstream ss;\n  ss << monmap->get_fsid() << \"\\n\";\n  string us = ss.str();\n\n  bufferlist b;\n  b.append(us);\n\n  t->put(MONITOR_NAME, \"cluster_uuid\", b);\n  return 0;\n}\n\n/*\n * this is the closest thing to a traditional 'mkfs' for ceph.\n * initialize the monitor state machines to their initial values.\n */\nint Monitor::mkfs(bufferlist& osdmapbl)\n{\n  auto t(std::make_shared<MonitorDBStore::Transaction>());\n\n  // verify cluster fsid\n  int r = check_fsid();\n  if (r < 0 && r != -ENOENT)\n    return r;\n\n  bufferlist magicbl;\n  magicbl.append(CEPH_MON_ONDISK_MAGIC);\n  magicbl.append(\"\\n\");\n  t->put(MONITOR_NAME, \"magic\", magicbl);\n\n\n  features = get_initial_supported_features();\n  write_features(t);\n\n  // save monmap, osdmap, keyring.\n  bufferlist monmapbl;\n  monmap->encode(monmapbl, CEPH_FEATURES_ALL);\n  monmap->set_epoch(0);     // must be 0 to avoid confusing first MonmapMonitor::update_from_paxos()\n  t->put(\"mkfs\", \"monmap\", monmapbl);\n\n  if (osdmapbl.length()) {\n    // make sure it's a valid osdmap\n    try {\n      OSDMap om;\n      om.decode(osdmapbl);\n    }\n    catch (buffer::error& e) {\n      derr << \"error decoding provided osdmap: \" << e.what() << dendl;\n      return -EINVAL;\n    }\n    t->put(\"mkfs\", \"osdmap\", osdmapbl);\n  }\n\n  if (is_keyring_required()) {\n    KeyRing keyring;\n    string keyring_filename;\n\n    r = ceph_resolve_file_search(g_conf->keyring, keyring_filename);\n    if (r) {\n      derr << \"unable to find a keyring file on \" << g_conf->keyring\n\t   << \": \" << cpp_strerror(r) << dendl;\n      if (g_conf->key != \"\") {\n\tstring keyring_plaintext = \"[mon.]\\n\\tkey = \" + g_conf->key +\n\t  \"\\n\\tcaps mon = \\\"allow *\\\"\\n\";\n\tbufferlist bl;\n\tbl.append(keyring_plaintext);\n\ttry {\n\t  bufferlist::iterator i = bl.begin();\n\t  keyring.decode_plaintext(i);\n\t}\n\tcatch (const buffer::error& e) {\n\t  derr << \"error decoding keyring \" << keyring_plaintext\n\t       << \": \" << e.what() << dendl;\n\t  return -EINVAL;\n\t}\n      } else {\n\treturn -ENOENT;\n      }\n    } else {\n      r = keyring.load(g_ceph_context, keyring_filename);\n      if (r < 0) {\n\tderr << \"unable to load initial keyring \" << g_conf->keyring << dendl;\n\treturn r;\n      }\n    }\n\n    // put mon. key in external keyring; seed with everything else.\n    extract_save_mon_key(keyring);\n\n    bufferlist keyringbl;\n    keyring.encode_plaintext(keyringbl);\n    t->put(\"mkfs\", \"keyring\", keyringbl);\n  }\n  write_fsid(t);\n  store->apply_transaction(t);\n\n  return 0;\n}\n\nint Monitor::write_default_keyring(bufferlist& bl)\n{\n  ostringstream os;\n  os << g_conf->mon_data << \"/keyring\";\n\n  int err = 0;\n  int fd = ::open(os.str().c_str(), O_WRONLY|O_CREAT, 0600);\n  if (fd < 0) {\n    err = -errno;\n    dout(0) << __func__ << \" failed to open \" << os.str() \n\t    << \": \" << cpp_strerror(err) << dendl;\n    return err;\n  }\n\n  err = bl.write_fd(fd);\n  if (!err)\n    ::fsync(fd);\n  VOID_TEMP_FAILURE_RETRY(::close(fd));\n\n  return err;\n}\n\nvoid Monitor::extract_save_mon_key(KeyRing& keyring)\n{\n  EntityName mon_name;\n  mon_name.set_type(CEPH_ENTITY_TYPE_MON);\n  EntityAuth mon_key;\n  if (keyring.get_auth(mon_name, mon_key)) {\n    dout(10) << \"extract_save_mon_key moving mon. key to separate keyring\" << dendl;\n    KeyRing pkey;\n    pkey.add(mon_name, mon_key);\n    bufferlist bl;\n    pkey.encode_plaintext(bl);\n    write_default_keyring(bl);\n    keyring.remove(mon_name);\n  }\n}\n\nbool Monitor::ms_get_authorizer(int service_id, AuthAuthorizer **authorizer,\n\t\t\t\tbool force_new)\n{\n  dout(10) << \"ms_get_authorizer for \" << ceph_entity_type_name(service_id)\n\t   << dendl;\n\n  if (is_shutdown())\n    return false;\n\n  // we only connect to other monitors and mgr; every else connects to us.\n  if (service_id != CEPH_ENTITY_TYPE_MON &&\n      service_id != CEPH_ENTITY_TYPE_MGR)\n    return false;\n\n  if (!auth_cluster_required.is_supported_auth(CEPH_AUTH_CEPHX)) {\n    // auth_none\n    dout(20) << __func__ << \" building auth_none authorizer\" << dendl;\n    AuthNoneClientHandler handler(g_ceph_context, nullptr);\n    handler.set_global_id(0);\n    *authorizer = handler.build_authorizer(service_id);\n    return true;\n  }\n\n  CephXServiceTicketInfo auth_ticket_info;\n  CephXSessionAuthInfo info;\n  int ret;\n\n  EntityName name;\n  name.set_type(CEPH_ENTITY_TYPE_MON);\n  auth_ticket_info.ticket.name = name;\n  auth_ticket_info.ticket.global_id = 0;\n\n  if (service_id == CEPH_ENTITY_TYPE_MON) {\n    // mon to mon authentication uses the private monitor shared key and not the\n    // rotating key\n    CryptoKey secret;\n    if (!keyring.get_secret(name, secret) &&\n\t!key_server.get_secret(name, secret)) {\n      dout(0) << \" couldn't get secret for mon service from keyring or keyserver\"\n\t      << dendl;\n      stringstream ss, ds;\n      int err = key_server.list_secrets(ds);\n      if (err < 0)\n\tss << \"no installed auth entries!\";\n      else\n\tss << \"installed auth entries:\";\n      dout(0) << ss.str() << \"\\n\" << ds.str() << dendl;\n      return false;\n    }\n\n    ret = key_server.build_session_auth_info(service_id, auth_ticket_info, info,\n\t\t\t\t\t     secret, (uint64_t)-1);\n    if (ret < 0) {\n      dout(0) << __func__ << \" failed to build mon session_auth_info \"\n\t      << cpp_strerror(ret) << dendl;\n      return false;\n    }\n  } else if (service_id == CEPH_ENTITY_TYPE_MGR) {\n    // mgr\n    ret = key_server.build_session_auth_info(service_id, auth_ticket_info, info);\n    if (ret < 0) {\n      derr << __func__ << \" failed to build mgr service session_auth_info \"\n\t   << cpp_strerror(ret) << dendl;\n      return false;\n    }\n  } else {\n    ceph_abort();  // see check at top of fn\n  }\n\n  CephXTicketBlob blob;\n  if (!cephx_build_service_ticket_blob(cct, info, blob)) {\n    dout(0) << \"ms_get_authorizer failed to build service ticket\" << dendl;\n    return false;\n  }\n  bufferlist ticket_data;\n  ::encode(blob, ticket_data);\n\n  bufferlist::iterator iter = ticket_data.begin();\n  CephXTicketHandler handler(g_ceph_context, service_id);\n  ::decode(handler.ticket, iter);\n\n  handler.session_key = info.session_key;\n\n  *authorizer = handler.build_authorizer(0);\n  \n  return true;\n}\n\nbool Monitor::ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t\t   int protocol, bufferlist& authorizer_data,\n\t\t\t\t   bufferlist& authorizer_reply,\n\t\t\t\t   bool& isvalid, CryptoKey& session_key,\n\t\t\t\t   std::unique_ptr<AuthAuthorizerChallenge> *challenge)\n{\n  dout(10) << \"ms_verify_authorizer \" << con->get_peer_addr()\n\t   << \" \" << ceph_entity_type_name(peer_type)\n\t   << \" protocol \" << protocol << dendl;\n\n  if (is_shutdown())\n    return false;\n\n  if (peer_type == CEPH_ENTITY_TYPE_MON &&\n      auth_cluster_required.is_supported_auth(CEPH_AUTH_CEPHX)) {\n    // monitor, and cephx is enabled\n    isvalid = false;\n    if (protocol == CEPH_AUTH_CEPHX) {\n      bufferlist::iterator iter = authorizer_data.begin();\n      CephXServiceTicketInfo auth_ticket_info;\n      \n      if (authorizer_data.length()) {\n\tbool ret = cephx_verify_authorizer(g_ceph_context, &keyring, iter,\n\t\t\t\t\t   auth_ticket_info, challenge, authorizer_reply);\n\tif (ret) {\n\t  session_key = auth_ticket_info.session_key;\n\t  isvalid = true;\n\t} else {\n\t  dout(0) << \"ms_verify_authorizer bad authorizer from mon \" << con->get_peer_addr() << dendl;\n        }\n      }\n    } else {\n      dout(0) << \"ms_verify_authorizer cephx enabled, but no authorizer (required for mon)\" << dendl;\n    }\n  } else {\n    // who cares.\n    isvalid = true;\n  }\n  return true;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n/* \n * This is the top level monitor. It runs on each machine in the Monitor   \n * Cluster. The election of a leader for the paxos algorithm only happens \n * once per machine via the elector. There is a separate paxos instance (state) \n * kept for each of the system components: Object Store Device (OSD) Monitor, \n * Placement Group (PG) Monitor, Metadata Server (MDS) Monitor, and Client Monitor.\n */\n\n#ifndef CEPH_MONITOR_H\n#define CEPH_MONITOR_H\n\n#include <errno.h>\n#include <cmath>\n\n#include \"include/types.h\"\n#include \"include/health.h\"\n#include \"msg/Messenger.h\"\n\n#include \"common/Timer.h\"\n\n#include \"health_check.h\"\n#include \"MonMap.h\"\n#include \"Elector.h\"\n#include \"Paxos.h\"\n#include \"Session.h\"\n#include \"PGStatService.h\"\n#include \"MonCommand.h\"\n\n#include \"common/LogClient.h\"\n#include \"auth/cephx/CephxKeyServer.h\"\n#include \"auth/AuthMethodList.h\"\n#include \"auth/KeyRing.h\"\n#include \"messages/MMonCommand.h\"\n#include \"mon/MonitorDBStore.h\"\n#include \"include/memory.h\"\n#include \"mgr/MgrClient.h\"\n\n#include \"mon/MonOpRequest.h\"\n#include \"common/WorkQueue.h\"\n\n\n#define CEPH_MON_PROTOCOL     13 /* cluster internal */\n\n\nenum {\n  l_cluster_first = 555000,\n  l_cluster_num_mon,\n  l_cluster_num_mon_quorum,\n  l_cluster_num_osd,\n  l_cluster_num_osd_up,\n  l_cluster_num_osd_in,\n  l_cluster_osd_epoch,\n  l_cluster_osd_bytes,\n  l_cluster_osd_bytes_used,\n  l_cluster_osd_bytes_avail,\n  l_cluster_num_pool,\n  l_cluster_num_pg,\n  l_cluster_num_pg_active_clean,\n  l_cluster_num_pg_active,\n  l_cluster_num_pg_peering,\n  l_cluster_num_object,\n  l_cluster_num_object_degraded,\n  l_cluster_num_object_misplaced,\n  l_cluster_num_object_unfound,\n  l_cluster_num_bytes,\n  l_cluster_num_mds_up,\n  l_cluster_num_mds_in,\n  l_cluster_num_mds_failed,\n  l_cluster_mds_epoch,\n  l_cluster_last,\n};\n\nenum {\n  l_mon_first = 456000,\n  l_mon_num_sessions,\n  l_mon_session_add,\n  l_mon_session_rm,\n  l_mon_session_trim,\n  l_mon_num_elections,\n  l_mon_election_call,\n  l_mon_election_win,\n  l_mon_election_lose,\n  l_mon_last,\n};\n\nclass QuorumService;\nclass PaxosService;\n\nclass PerfCounters;\nclass AdminSocketHook;\n\nclass MMonGetMap;\nclass MMonGetVersion;\nclass MMonMetadata;\nclass MMonSync;\nclass MMonScrub;\nclass MMonProbe;\nstruct MMonSubscribe;\nstruct MRoute;\nstruct MForward;\nstruct MTimeCheck;\nstruct MMonHealth;\n\n#define COMPAT_SET_LOC \"feature_set\"\n\nclass C_MonContext final : public FunctionContext {\n  const Monitor *mon;\npublic:\n  explicit C_MonContext(Monitor *m, boost::function<void(int)>&& callback)\n    : FunctionContext(std::move(callback)), mon(m) {}\n  void finish(int r) override;\n};\n\nclass Monitor : public Dispatcher,\n                public md_config_obs_t {\npublic:\n  // me\n  string name;\n  int rank;\n  Messenger *messenger;\n  ConnectionRef con_self;\n  Mutex lock;\n  SafeTimer timer;\n  Finisher finisher;\n  ThreadPool cpu_tp;  ///< threadpool for CPU intensive work\n  \n  /// true if we have ever joined a quorum.  if false, we are either a\n  /// new cluster, a newly joining monitor, or a just-upgraded\n  /// monitor.\n  bool has_ever_joined;\n\n  PerfCounters *logger, *cluster_logger;\n  bool cluster_logger_registered;\n\n  void register_cluster_logger();\n  void unregister_cluster_logger();\n\n  MonMap *monmap;\n  uuid_d fingerprint;\n\n  set<entity_addr_t> extra_probe_peers;\n\n  LogClient log_client;\n  LogChannelRef clog;\n  LogChannelRef audit_clog;\n  KeyRing keyring;\n  KeyServer key_server;\n\n  AuthMethodList auth_cluster_required;\n  AuthMethodList auth_service_required;\n\n  CompatSet features;\n\n  vector<MonCommand> leader_mon_commands; // quorum leader's commands\n  vector<MonCommand> local_mon_commands;  // commands i support\n  bufferlist local_mon_commands_bl;       // encoded version of above\n\n  // for upgrading mon cluster that still uses PGMonitor\n  vector<MonCommand> local_upgrading_mon_commands;  // mixed mon cluster commands\n  bufferlist local_upgrading_mon_commands_bl;       // encoded version of above\n\n  Messenger *mgr_messenger;\n  MgrClient mgr_client;\n  uint64_t mgr_proxy_bytes = 0;  // in-flight proxied mgr command message bytes\n\n  const MonPGStatService *pgservice;\n\nprivate:\n  void new_tick();\n\n  // -- local storage --\npublic:\n  MonitorDBStore *store;\n  static const string MONITOR_NAME;\n  static const string MONITOR_STORE_PREFIX;\n\n  // -- monitor state --\nprivate:\n  enum {\n    STATE_PROBING = 1,\n    STATE_SYNCHRONIZING,\n    STATE_ELECTING,\n    STATE_LEADER,\n    STATE_PEON,\n    STATE_SHUTDOWN\n  };\n  int state;\n\npublic:\n  static const char *get_state_name(int s) {\n    switch (s) {\n    case STATE_PROBING: return \"probing\";\n    case STATE_SYNCHRONIZING: return \"synchronizing\";\n    case STATE_ELECTING: return \"electing\";\n    case STATE_LEADER: return \"leader\";\n    case STATE_PEON: return \"peon\";\n    case STATE_SHUTDOWN: return \"shutdown\";\n    default: return \"???\";\n    }\n  }\n  const char *get_state_name() const {\n    return get_state_name(state);\n  }\n\n  bool is_shutdown() const { return state == STATE_SHUTDOWN; }\n  bool is_probing() const { return state == STATE_PROBING; }\n  bool is_synchronizing() const { return state == STATE_SYNCHRONIZING; }\n  bool is_electing() const { return state == STATE_ELECTING; }\n  bool is_leader() const { return state == STATE_LEADER; }\n  bool is_peon() const { return state == STATE_PEON; }\n\n  const utime_t &get_leader_since() const;\n\n  void prepare_new_fingerprint(MonitorDBStore::TransactionRef t);\n\n  // -- elector --\nprivate:\n  Paxos *paxos;\n  Elector elector;\n  friend class Elector;\n\n  /// features we require of peers (based on on-disk compatset)\n  uint64_t required_features;\n  \n  int leader;            // current leader (to best of knowledge)\n  set<int> quorum;       // current active set of monitors (if !starting)\n  utime_t leader_since;  // when this monitor became the leader, if it is the leader\n  utime_t exited_quorum; // time detected as not in quorum; 0 if in\n\n  // map of counts of connected clients, by type and features, for\n  // each quorum mon\n  map<int,FeatureMap> quorum_feature_map;\n\n  /**\n   * Intersection of quorum member's connection feature bits.\n   */\n  uint64_t quorum_con_features;\n  /**\n   * Intersection of quorum members mon-specific feature bits\n   */\n  mon_feature_t quorum_mon_features;\n\n  set<string> outside_quorum;\n\n  /**\n   * @defgroup Monitor_h_scrub\n   * @{\n   */\n  version_t scrub_version;            ///< paxos version we are scrubbing\n  map<int,ScrubResult> scrub_result;  ///< results so far\n\n  /**\n   * trigger a cross-mon scrub\n   *\n   * Verify all mons are storing identical content\n   */\n  int scrub_start();\n  int scrub();\n  void handle_scrub(MonOpRequestRef op);\n  bool _scrub(ScrubResult *r,\n              pair<string,string> *start,\n              int *num_keys);\n  void scrub_check_results();\n  void scrub_timeout();\n  void scrub_finish();\n  void scrub_reset();\n  void scrub_update_interval(int secs);\n\n  Context *scrub_event;       ///< periodic event to trigger scrub (leader)\n  Context *scrub_timeout_event;  ///< scrub round timeout (leader)\n  void scrub_event_start();\n  void scrub_event_cancel();\n  void scrub_reset_timeout();\n  void scrub_cancel_timeout();\n\n  struct ScrubState {\n    pair<string,string> last_key; ///< last scrubbed key\n    bool finished;\n\n    ScrubState() : finished(false) { }\n    virtual ~ScrubState() { }\n  };\n  ceph::shared_ptr<ScrubState> scrub_state; ///< keeps track of current scrub\n\n  /**\n   * @defgroup Monitor_h_sync Synchronization\n   * @{\n   */\n  /**\n   * @} // provider state\n   */\n  struct SyncProvider {\n    entity_inst_t entity;  ///< who\n    uint64_t cookie;       ///< unique cookie for this sync attempt\n    utime_t timeout;       ///< when we give up and expire this attempt\n    version_t last_committed; ///< last paxos version on peer\n    pair<string,string> last_key; ///< last key sent to (or on) peer\n    bool full;             ///< full scan?\n    MonitorDBStore::Synchronizer synchronizer;   ///< iterator\n\n    SyncProvider() : cookie(0), last_committed(0), full(false) {}\n\n    void reset_timeout(CephContext *cct, int grace) {\n      timeout = ceph_clock_now();\n      timeout += grace;\n    }\n  };\n\n  map<uint64_t, SyncProvider> sync_providers;  ///< cookie -> SyncProvider for those syncing from us\n  uint64_t sync_provider_count;   ///< counter for issued cookies to keep them unique\n\n  /**\n   * @} // requester state\n   */\n  entity_inst_t sync_provider;   ///< who we are syncing from\n  uint64_t sync_cookie;          ///< 0 if we are starting, non-zero otherwise\n  bool sync_full;                ///< true if we are a full sync, false for recent catch-up\n  version_t sync_start_version;  ///< last_committed at sync start\n  Context *sync_timeout_event;   ///< timeout event\n\n  /**\n   * floor for sync source\n   *\n   * When we sync we forget about our old last_committed value which\n   * can be dangerous.  For example, if we have a cluster of:\n   *\n   *   mon.a: lc 100\n   *   mon.b: lc 80\n   *   mon.c: lc 100 (us)\n   *\n   * If something forces us to sync (say, corruption, or manual\n   * intervention, or bug), we forget last_committed, and might abort.\n   * If mon.a happens to be down when we come back, we will see:\n   *\n   *   mon.b: lc 80\n   *   mon.c: lc 0 (us)\n   *\n   * and sync from mon.b, at which point a+b will both have lc 80 and\n   * come online with a majority holding out of date commits.\n   *\n   * Avoid this by preserving our old last_committed value prior to\n   * sync and never going backwards.\n   */\n  version_t sync_last_committed_floor;\n\n  /**\n   * Obtain the synchronization target prefixes in set form.\n   *\n   * We consider a target prefix all those that are relevant when\n   * synchronizing two stores. That is, all those that hold paxos service's\n   * versions, as well as paxos versions, or any control keys such as the\n   * first or last committed version.\n   *\n   * Given the current design, this function should return the name of all and\n   * any available paxos service, plus the paxos name.\n   *\n   * @returns a set of strings referring to the prefixes being synchronized\n   */\n  set<string> get_sync_targets_names();\n\n  /**\n   * Reset the monitor's sync-related data structures for syncing *from* a peer\n   */\n  void sync_reset_requester();\n\n  /**\n   * Reset sync state related to allowing others to sync from us\n   */\n  void sync_reset_provider();\n\n  /**\n   * Caled when a sync attempt times out (requester-side)\n   */\n  void sync_timeout();\n\n  /**\n   * Get the latest monmap for backup purposes during sync\n   */\n  void sync_obtain_latest_monmap(bufferlist &bl);\n\n  /**\n   * Start sync process\n   *\n   * Start pulling committed state from another monitor.\n   *\n   * @param entity where to pull committed state from\n   * @param full whether to do a full sync or just catch up on recent paxos\n   */\n  void sync_start(entity_inst_t &entity, bool full);\n\npublic:\n  /**\n   * force a sync on next mon restart\n   */\n  void sync_force(Formatter *f, ostream& ss);\n\nprivate:\n  /**\n   * store critical state for safekeeping during sync\n   *\n   * We store a few things on the side that we don't want to get clobbered by sync.  This\n   * includes the latest monmap and a lower bound on last_committed.\n   */\n  void sync_stash_critical_state(MonitorDBStore::TransactionRef tx);\n\n  /**\n   * reset the sync timeout\n   *\n   * This is used on the client to restart if things aren't progressing\n   */\n  void sync_reset_timeout();\n\n  /**\n   * trim stale sync provider state\n   *\n   * If someone is syncing from us and hasn't talked to us recently, expire their state.\n   */\n  void sync_trim_providers();\n\n  /**\n   * Complete a sync\n   *\n   * Finish up a sync after we've gotten all of the chunks.\n   *\n   * @param last_committed final last_committed value from provider\n   */\n  void sync_finish(version_t last_committed);\n\n  /**\n   * request the next chunk from the provider\n   */\n  void sync_get_next_chunk();\n\n  /**\n   * handle sync message\n   *\n   * @param m Sync message with operation type MMonSync::OP_START_CHUNKS\n   */\n  void handle_sync(MonOpRequestRef op);\n\n  void _sync_reply_no_cookie(MonOpRequestRef op);\n\n  void handle_sync_get_cookie(MonOpRequestRef op);\n  void handle_sync_get_chunk(MonOpRequestRef op);\n  void handle_sync_finish(MonOpRequestRef op);\n\n  void handle_sync_cookie(MonOpRequestRef op);\n  void handle_sync_forward(MonOpRequestRef op);\n  void handle_sync_chunk(MonOpRequestRef op);\n  void handle_sync_no_cookie(MonOpRequestRef op);\n\n  /**\n   * @} // Synchronization\n   */\n\n  list<Context*> waitfor_quorum;\n  list<Context*> maybe_wait_for_quorum;\n\n  /**\n   * @defgroup Monitor_h_TimeCheck Monitor Clock Drift Early Warning System\n   * @{\n   *\n   * We use time checks to keep track of any clock drifting going on in the\n   * cluster. This is accomplished by periodically ping each monitor in the\n   * quorum and register its response time on a map, assessing how much its\n   * clock has drifted. We also take this opportunity to assess the latency\n   * on response.\n   *\n   * This mechanism works as follows:\n   *\n   *  - Leader sends out a 'PING' message to each other monitor in the quorum.\n   *    The message is timestamped with the leader's current time. The leader's\n   *    current time is recorded in a map, associated with each peon's\n   *    instance.\n   *  - The peon replies to the leader with a timestamped 'PONG' message.\n   *  - The leader calculates a delta between the peon's timestamp and its\n   *    current time and stashes it.\n   *  - The leader also calculates the time it took to receive the 'PONG'\n   *    since the 'PING' was sent, and stashes an approximate latency estimate.\n   *  - Once all the quorum members have pong'ed, the leader will share the\n   *    clock skew and latency maps with all the monitors in the quorum.\n   */\n  map<entity_inst_t, utime_t> timecheck_waiting;\n  map<entity_inst_t, double> timecheck_skews;\n  map<entity_inst_t, double> timecheck_latencies;\n  // odd value means we are mid-round; even value means the round has\n  // finished.\n  version_t timecheck_round;\n  unsigned int timecheck_acks;\n  utime_t timecheck_round_start;\n  friend class HealthMonitor;\n  /* When we hit a skew we will start a new round based off of\n   * 'mon_timecheck_skew_interval'. Each new round will be backed off\n   * until we hit 'mon_timecheck_interval' -- which is the typical\n   * interval when not in the presence of a skew.\n   *\n   * This variable tracks the number of rounds with skews since last clean\n   * so that we can report to the user and properly adjust the backoff.\n   */\n  uint64_t timecheck_rounds_since_clean;\n  /**\n   * Time Check event.\n   */\n  Context *timecheck_event;\n\n  void timecheck_start();\n  void timecheck_finish();\n  void timecheck_start_round();\n  void timecheck_finish_round(bool success = true);\n  void timecheck_cancel_round();\n  void timecheck_cleanup();\n  void timecheck_reset_event();\n  void timecheck_check_skews();\n  void timecheck_report();\n  void timecheck();\n  health_status_t timecheck_status(ostringstream &ss,\n                                   const double skew_bound,\n                                   const double latency);\n  void handle_timecheck_leader(MonOpRequestRef op);\n  void handle_timecheck_peon(MonOpRequestRef op);\n  void handle_timecheck(MonOpRequestRef op);\n\n  /**\n   * Returns 'true' if this is considered to be a skew; 'false' otherwise.\n   */\n  bool timecheck_has_skew(const double skew_bound, double *abs) const {\n    double abs_skew = std::fabs(skew_bound);\n    if (abs)\n      *abs = abs_skew;\n    return (abs_skew > g_conf->mon_clock_drift_allowed);\n  }\n\n  /**\n   * @}\n   */\n  /**\n   * Handle ping messages from others.\n   */\n  void handle_ping(MonOpRequestRef op);\n\n  Context *probe_timeout_event = nullptr;  // for probing\n\n  void reset_probe_timeout();\n  void cancel_probe_timeout();\n  void probe_timeout(int r);\n\n  void _apply_compatset_features(CompatSet &new_features);\n\npublic:\n  epoch_t get_epoch();\n  int get_leader() const { return leader; }\n  string get_leader_name() {\n    return quorum.empty() ? string() : monmap->get_name(*quorum.begin());\n  }\n  const set<int>& get_quorum() const { return quorum; }\n  list<string> get_quorum_names() {\n    list<string> q;\n    for (set<int>::iterator p = quorum.begin(); p != quorum.end(); ++p)\n      q.push_back(monmap->get_name(*p));\n    return q;\n  }\n  uint64_t get_quorum_con_features() const {\n    return quorum_con_features;\n  }\n  mon_feature_t get_quorum_mon_features() const {\n    return quorum_mon_features;\n  }\n  uint64_t get_required_features() const {\n    return required_features;\n  }\n  mon_feature_t get_required_mon_features() const {\n    return monmap->get_required_features();\n  }\n  void apply_quorum_to_compatset_features();\n  void apply_monmap_to_compatset_features();\n  void calc_quorum_requirements();\n\n  void get_combined_feature_map(FeatureMap *fm);\n\nprivate:\n  void _reset();   ///< called from bootstrap, start_, or join_election\n  void wait_for_paxos_write();\n  void _finish_svc_election(); ///< called by {win,lose}_election\npublic:\n  void bootstrap();\n  void join_election();\n  void start_election();\n  void win_standalone_election();\n  // end election (called by Elector)\n  void win_election(epoch_t epoch, set<int>& q,\n\t\t    uint64_t features,\n                    const mon_feature_t& mon_features,\n\t\t    const map<int,Metadata>& metadata);\n  void lose_election(epoch_t epoch, set<int>& q, int l,\n\t\t     uint64_t features,\n                     const mon_feature_t& mon_features);\n  // end election (called by Elector)\n  void finish_election();\n\n  void update_logger();\n\n  /**\n   * Vector holding the Services serviced by this Monitor.\n   */\n  vector<PaxosService*> paxos_service;\n\n  class PGMonitor *pgmon() {\n    return (class PGMonitor *)paxos_service[PAXOS_PGMAP];\n  }\n\n  class MDSMonitor *mdsmon() {\n    return (class MDSMonitor *)paxos_service[PAXOS_MDSMAP];\n  }\n\n  class MonmapMonitor *monmon() {\n    return (class MonmapMonitor *)paxos_service[PAXOS_MONMAP];\n  }\n\n  class OSDMonitor *osdmon() {\n    return (class OSDMonitor *)paxos_service[PAXOS_OSDMAP];\n  }\n\n  class AuthMonitor *authmon() {\n    return (class AuthMonitor *)paxos_service[PAXOS_AUTH];\n  }\n\n  class LogMonitor *logmon() {\n    return (class LogMonitor*) paxos_service[PAXOS_LOG];\n  }\n\n  class MgrMonitor *mgrmon() {\n    return (class MgrMonitor*) paxos_service[PAXOS_MGR];\n  }\n\n  class MgrStatMonitor *mgrstatmon() {\n    return (class MgrStatMonitor*) paxos_service[PAXOS_MGRSTAT];\n  }\n\n  class HealthMonitor *healthmon() {\n    return (class HealthMonitor*) paxos_service[PAXOS_HEALTH];\n  }\n\n  friend class Paxos;\n  friend class OSDMonitor;\n  friend class MDSMonitor;\n  friend class MonmapMonitor;\n  friend class PGMonitor;\n  friend class LogMonitor;\n  friend class ConfigKeyService;\n\n  QuorumService *health_monitor;\n  QuorumService *config_key_service;\n\n  // -- sessions --\n  MonSessionMap session_map;\n  Mutex session_map_lock{\"Monitor::session_map_lock\"};\n  AdminSocketHook *admin_hook;\n\n  template<typename Func, typename...Args>\n  void with_session_map(Func&& func) {\n    Mutex::Locker l(session_map_lock);\n    std::forward<Func>(func)(session_map);\n  }\n  void send_latest_monmap(Connection *con);\n\n  // messages\n  void handle_get_version(MonOpRequestRef op);\n  void handle_subscribe(MonOpRequestRef op);\n  void handle_mon_get_map(MonOpRequestRef op);\n\n  static void _generate_command_map(map<string,cmd_vartype>& cmdmap,\n                                    map<string,string> &param_str_map);\n  static const MonCommand *_get_moncommand(\n    const string &cmd_prefix,\n    const vector<MonCommand>& cmds);\n  bool _allowed_command(MonSession *s, string &module, string &prefix,\n                        const map<string,cmd_vartype>& cmdmap,\n                        const map<string,string>& param_str_map,\n                        const MonCommand *this_cmd);\n  void get_mon_status(Formatter *f, ostream& ss);\n  void _quorum_status(Formatter *f, ostream& ss);\n  bool _add_bootstrap_peer_hint(string cmd, cmdmap_t& cmdmap, ostream& ss);\n  void handle_command(MonOpRequestRef op);\n  void handle_route(MonOpRequestRef op);\n\n  void handle_mon_metadata(MonOpRequestRef op);\n  int get_mon_metadata(int mon, Formatter *f, ostream& err);\n  int print_nodes(Formatter *f, ostream& err);\n\n  // Accumulate metadata across calls to update_mon_metadata\n  map<int, Metadata> mon_metadata;\n  map<int, Metadata> pending_metadata;\n\n  /**\n   *\n   */\n  struct health_cache_t {\n    health_status_t overall;\n    string summary;\n\n    void reset() {\n      // health_status_t doesn't really have a NONE value and we're not\n      // okay with setting something else (say, HEALTH_ERR).  so just\n      // leave it be.\n      summary.clear();\n    }\n  } health_status_cache;\n\n  Context *health_tick_event = nullptr;\n  Context *health_interval_event = nullptr;\n\n  void health_tick_start();\n  void health_tick_stop();\n  utime_t health_interval_calc_next_update();\n  void health_interval_start();\n  void health_interval_stop();\n  void health_events_cleanup();\n\n  void health_to_clog_update_conf(const std::set<std::string> &changed);\n\n  void do_health_to_clog_interval();\n  void do_health_to_clog(bool force = false);\n\n  /**\n   * Generate health report\n   *\n   * @param status one-line status summary\n   * @param detailbl optional bufferlist* to fill with a detailed report\n   * @returns health status\n   */\n  health_status_t get_health(list<string>& status, bufferlist *detailbl,\n                             Formatter *f);\n\n  health_status_t get_health_status(\n    bool want_detail,\n    Formatter *f,\n    std::string *plain,\n    const char *sep1 = \" \",\n    const char *sep2 = \"; \");\n  void log_health(\n    const health_check_map_t& updated,\n    const health_check_map_t& previous,\n    MonitorDBStore::TransactionRef t);\n\nprotected:\n\n  class HealthCheckLogStatus {\n    public:\n    health_status_t severity;\n    std::string last_message;\n    utime_t updated_at = 0;\n    HealthCheckLogStatus(health_status_t severity_,\n                         const std::string &last_message_,\n                         utime_t updated_at_)\n      : severity(severity_),\n        last_message(last_message_),\n        updated_at(updated_at_)\n    {}\n  };\n  std::map<std::string, HealthCheckLogStatus> health_check_log_times;\n\npublic:\n\n  void get_cluster_status(stringstream &ss, Formatter *f);\n\n  void reply_command(MonOpRequestRef op, int rc, const string &rs, version_t version);\n  void reply_command(MonOpRequestRef op, int rc, const string &rs, bufferlist& rdata, version_t version);\n\n\n  void handle_probe(MonOpRequestRef op);\n  /**\n   * Handle a Probe Operation, replying with our name, quorum and known versions.\n   *\n   * We use the MMonProbe message class for anything and everything related with\n   * Monitor probing. One of the operations relates directly with the probing\n   * itself, in which we receive a probe request and to which we reply with\n   * our name, our quorum and the known versions for each Paxos service. Thus the\n   * redundant function name. This reply will obviously be sent to the one\n   * probing/requesting these infos.\n   *\n   * @todo Add @pre and @post\n   *\n   * @param m A Probe message, with an operation of type Probe.\n   */\n  void handle_probe_probe(MonOpRequestRef op);\n  void handle_probe_reply(MonOpRequestRef op);\n\n  // request routing\n  struct RoutedRequest {\n    uint64_t tid;\n    bufferlist request_bl;\n    MonSession *session;\n    ConnectionRef con;\n    uint64_t con_features;\n    entity_inst_t client_inst;\n    MonOpRequestRef op;\n\n    RoutedRequest() : tid(0), session(NULL), con_features(0) {}\n    ~RoutedRequest() {\n      if (session)\n\tsession->put();\n    }\n  };\n  uint64_t routed_request_tid;\n  map<uint64_t, RoutedRequest*> routed_requests;\n  \n  void forward_request_leader(MonOpRequestRef op);\n  void handle_forward(MonOpRequestRef op);\n  void try_send_message(Message *m, const entity_inst_t& to);\n  void send_reply(MonOpRequestRef op, Message *reply);\n  void no_reply(MonOpRequestRef op);\n  void resend_routed_requests();\n  void remove_session(MonSession *s);\n  void remove_all_sessions();\n  void waitlist_or_zap_client(MonOpRequestRef op);\n\n  void send_command(const entity_inst_t& inst,\n\t\t    const vector<string>& com);\n\npublic:\n  struct C_Command : public C_MonOp {\n    Monitor *mon;\n    int rc;\n    string rs;\n    bufferlist rdata;\n    version_t version;\n    C_Command(Monitor *_mm, MonOpRequestRef _op, int r, string s, version_t v) :\n      C_MonOp(_op), mon(_mm), rc(r), rs(s), version(v){}\n    C_Command(Monitor *_mm, MonOpRequestRef _op, int r, string s, bufferlist rd, version_t v) :\n      C_MonOp(_op), mon(_mm), rc(r), rs(s), rdata(rd), version(v){}\n\n    void _finish(int r) override {\n      MMonCommand *m = static_cast<MMonCommand*>(op->get_req());\n      if (r >= 0) {\n        ostringstream ss;\n        if (!op->get_req()->get_connection()) {\n          ss << \"connection dropped for command \";\n        } else {\n          MonSession *s = op->get_session();\n\n          // if client drops we may not have a session to draw information from.\n          if (s) {\n            ss << \"from='\" << s->inst << \"' \"\n              << \"entity='\" << s->entity_name << \"' \";\n          } else {\n            ss << \"session dropped for command \";\n          }\n        }\n        ss << \"cmd='\" << m->cmd << \"': finished\";\n\n        mon->audit_clog->info() << ss.str();\n\tmon->reply_command(op, rc, rs, rdata, version);\n      }\n      else if (r == -ECANCELED)\n        return;\n      else if (r == -EAGAIN)\n\tmon->dispatch_op(op);\n      else\n\tassert(0 == \"bad C_Command return value\");\n    }\n  };\n\n private:\n  class C_RetryMessage : public C_MonOp {\n    Monitor *mon;\n  public:\n    C_RetryMessage(Monitor *m, MonOpRequestRef op) :\n      C_MonOp(op), mon(m) { }\n\n    void _finish(int r) override {\n      if (r == -EAGAIN || r >= 0)\n        mon->dispatch_op(op);\n      else if (r == -ECANCELED)\n        return;\n      else\n\tassert(0 == \"bad C_RetryMessage return value\");\n    }\n  };\n\n  //ms_dispatch handles a lot of logic and we want to reuse it\n  //on forwarded messages, so we create a non-locking version for this class\n  void _ms_dispatch(Message *m);\n  bool ms_dispatch(Message *m) override {\n    lock.Lock();\n    _ms_dispatch(m);\n    lock.Unlock();\n    return true;\n  }\n  void dispatch_op(MonOpRequestRef op);\n  //mon_caps is used for un-connected messages from monitors\n  MonCap * mon_caps;\n  bool ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new) override;\n  bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t    int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t    bool& isvalid, CryptoKey& session_key,\n\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) override;\n  bool ms_handle_reset(Connection *con) override;\n  void ms_handle_remote_reset(Connection *con) override {}\n  bool ms_handle_refused(Connection *con) override;\n\n  int write_default_keyring(bufferlist& bl);\n  void extract_save_mon_key(KeyRing& keyring);\n\n  void collect_metadata(Metadata *m);\n  void update_mon_metadata(int from, Metadata&& m);\n  int load_metadata();\n  void count_metadata(const string& field, Formatter *f);\n  void count_metadata(const string& field, map<string,int> *out);\n\n  // features\n  static CompatSet get_initial_supported_features();\n  static CompatSet get_supported_features();\n  static CompatSet get_legacy_features();\n  /// read the ondisk features into the CompatSet pointed to by read_features\n  static void read_features_off_disk(MonitorDBStore *store, CompatSet *read_features);\n  void read_features();\n  void write_features(MonitorDBStore::TransactionRef t);\n\n  OpTracker op_tracker;\n\n public:\n  Monitor(CephContext *cct_, string nm, MonitorDBStore *s,\n\t  Messenger *m, Messenger *mgr_m, MonMap *map);\n  ~Monitor() override;\n\n  static int check_features(MonitorDBStore *store);\n\n  // config observer\n  const char** get_tracked_conf_keys() const override;\n  void handle_conf_change(const struct md_config_t *conf,\n                          const std::set<std::string> &changed) override;\n\n  void update_log_clients();\n  int sanitize_options();\n  int preinit();\n  int init();\n  void init_paxos();\n  void refresh_from_paxos(bool *need_bootstrap);\n  void shutdown();\n  void tick();\n\n  void handle_signal(int sig);\n\n  int mkfs(bufferlist& osdmapbl);\n\n  /**\n   * check cluster_fsid file\n   *\n   * @return EEXIST if file exists and doesn't match, 0 on match, or negative error code\n   */\n  int check_fsid();\n\n  /**\n   * write cluster_fsid file\n   *\n   * @return 0 on success, or negative error code\n   */\n  int write_fsid();\n  int write_fsid(MonitorDBStore::TransactionRef t);\n\n  void do_admin_command(std::string command, cmdmap_t& cmdmap,\n\t\t\tstd::string format, ostream& ss);\n\nprivate:\n  // don't allow copying\n  Monitor(const Monitor& rhs);\n  Monitor& operator=(const Monitor &rhs);\n\npublic:\n  static void format_command_descriptions(const std::vector<MonCommand> &commands,\n\t\t\t\t\t  Formatter *f,\n\t\t\t\t\t  bufferlist *rdata,\n\t\t\t\t\t  bool hide_mgr_flag=false);\n\n  const std::vector<MonCommand> &get_local_commands(mon_feature_t f) {\n    if (f.contains_all(ceph::features::mon::FEATURE_LUMINOUS))\n      return local_mon_commands;\n    else\n      return local_upgrading_mon_commands;\n  }\n  const bufferlist& get_local_commands_bl(mon_feature_t f) {\n    if (f.contains_all(ceph::features::mon::FEATURE_LUMINOUS))\n      return local_mon_commands_bl;\n    else\n      return local_upgrading_mon_commands_bl;\n  }\n  void set_leader_commands(const std::vector<MonCommand>& cmds) {\n    leader_mon_commands = cmds;\n  }\n\n  static bool is_keyring_required();\n};\n\n#define CEPH_MON_FEATURE_INCOMPAT_BASE CompatSet::Feature (1, \"initial feature set (~v.18)\")\n#define CEPH_MON_FEATURE_INCOMPAT_GV CompatSet::Feature (2, \"global version sequencing (v0.52)\")\n#define CEPH_MON_FEATURE_INCOMPAT_SINGLE_PAXOS CompatSet::Feature (3, \"single paxos with k/v store (v0.\\?)\")\n#define CEPH_MON_FEATURE_INCOMPAT_OSD_ERASURE_CODES CompatSet::Feature(4, \"support erasure code pools\")\n#define CEPH_MON_FEATURE_INCOMPAT_OSDMAP_ENC CompatSet::Feature(5, \"new-style osdmap encoding\")\n#define CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V2 CompatSet::Feature(6, \"support isa/lrc erasure code\")\n#define CEPH_MON_FEATURE_INCOMPAT_ERASURE_CODE_PLUGINS_V3 CompatSet::Feature(7, \"support shec erasure code\")\n#define CEPH_MON_FEATURE_INCOMPAT_KRAKEN CompatSet::Feature(8, \"support monmap features\")\n#define CEPH_MON_FEATURE_INCOMPAT_LUMINOUS CompatSet::Feature(9, \"luminous ondisk layout\")\n// make sure you add your feature to Monitor::get_supported_features\n\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n\n#ifndef CEPH_DISPATCHER_H\n#define CEPH_DISPATCHER_H\n\n#include \"include/assert.h\"\n#include <memory>\n#include \"include/buffer_fwd.h\"\n#include \"include/assert.h\"\n\nclass Messenger;\nclass Message;\nclass Connection;\nclass AuthAuthorizer;\nclass CryptoKey;\nclass CephContext;\nclass AuthAuthorizerChallenge;\n\nclass Dispatcher {\npublic:\n  explicit Dispatcher(CephContext *cct_)\n    : cct(cct_)\n  {\n  }\n  virtual ~Dispatcher() { }\n\n  /**\n   * The Messenger calls this function to query if you are capable\n   * of \"fast dispatch\"ing a message. Indicating that you can fast\n   * dispatch it requires that you:\n   * 1) Handle the Message quickly and without taking long-term contended\n   * locks. (This function is likely to be called in-line with message\n   * receipt.)\n   * 2) Be able to accept the Message even if you have not yet received\n   * an ms_handle_accept() notification for the Connection it is associated\n   * with, and even if you *have* called mark_down() or received an\n   * ms_handle_reset() (or similar) call on the Connection. You will\n   * not receive more than one dead \"message\" (and should generally be\n   * prepared for that circumstance anyway, since the normal dispatch can begin,\n   * then trigger Connection failure before it's percolated through your system).\n   * We provide ms_handle_fast_[connect|accept] calls if you need them, under\n   * similar speed and state constraints as fast_dispatch itself.\n   * 3) Be able to make a determination on fast_dispatch without relying\n   * on particular system state -- the ms_can_fast_dispatch() call might\n   * be called multiple times on a single message; the state might change between\n   * calling ms_can_fast_dispatch and ms_fast_dispatch; etc.\n   *\n   * @param m The message we want to fast dispatch.\n   * @returns True if the message can be fast dispatched; false otherwise.\n   */\n  virtual bool ms_can_fast_dispatch(const Message *m) const { return false;}\n  /**\n   * This function determines if a dispatcher is included in the\n   * list of fast-dispatch capable Dispatchers.\n   * @returns True if the Dispatcher can handle any messages via\n   * fast dispatch; false otherwise.\n   */\n  virtual bool ms_can_fast_dispatch_any() const { return false; }\n  /**\n   * Perform a \"fast dispatch\" on a given message. See\n   * ms_can_fast_dispatch() for the requirements.\n   *\n   * @param m The Message to fast dispatch.\n   */\n  virtual void ms_fast_dispatch(Message *m) { ceph_abort(); }\n  /**\n   * Let the Dispatcher preview a Message before it is dispatched. This\n   * function is called on *every* Message, prior to the fast/regular dispatch\n   * decision point, but it is only used on fast-dispatch capable systems. An\n   * implementation of ms_fast_preprocess must be essentially lock-free in the\n   * same way as the ms_fast_dispatch function is (in particular, ms_fast_preprocess\n   * may be called while the Messenger holds internal locks that prevent progress from\n   * other threads, so any locks it takes must be at the very bottom of the hierarchy).\n   * Messages are delivered in receipt order within a single Connection, but there are\n   * no guarantees across Connections. This makes it useful for some limited\n   * coordination between Messages which can be fast_dispatch'ed and those which must\n   * go through normal dispatch.\n   *\n   * @param m A message which has been received\n   */\n  virtual void ms_fast_preprocess(Message *m) {}\n  /**\n   * The Messenger calls this function to deliver a single message.\n   *\n   * @param m The message being delivered. You (the Dispatcher)\n   * are given a single reference count on it.\n   */\n  virtual bool ms_dispatch(Message *m) = 0;\n\n  /**\n   * This function will be called whenever a Connection is newly-created\n   * or reconnects in the Messenger.\n   *\n   * @param con The new Connection which has been established. You are not\n   * granted a reference to it -- take one if you need one!\n   */\n  virtual void ms_handle_connect(Connection *con) {}\n\n  /**\n   * This function will be called synchronously whenever a Connection is\n   * newly-created or reconnects in the Messenger, if you support fast\n   * dispatch. It is guaranteed to be called before any messages are\n   * dispatched.\n   *\n   * @param con The new Connection which has been established. You are not\n   * granted a reference to it -- take one if you need one!\n   */\n  virtual void ms_handle_fast_connect(Connection *con) {}\n\n  /**\n   * Callback indicating we have accepted an incoming connection.\n   *\n   * @param con The (new or existing) Connection associated with the session\n   */\n  virtual void ms_handle_accept(Connection *con) {}\n\n  /**\n   * Callback indicating we have accepted an incoming connection, if you\n   * support fast dispatch. It is guaranteed to be called before any messages\n   * are dispatched.\n   *\n   * @param con The (new or existing) Connection associated with the session\n   */\n  virtual void ms_handle_fast_accept(Connection *con) {}\n\n  /*\n   * this indicates that the ordered+reliable delivery semantics have \n   * been violated.  Messages may have been lost due to a fault\n   * in the network connection.\n   * Only called on lossy Connections.\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  virtual bool ms_handle_reset(Connection *con) = 0;\n\n  /**\n   * This indicates that the ordered+reliable delivery semantics\n   * have been violated because the remote somehow reset.\n   * It implies that incoming messages were dropped, and\n   * probably some of our previous outgoing messages were too.\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  virtual void ms_handle_remote_reset(Connection *con) = 0;\n  \n  /**\n   * This indicates that the connection is both broken and further\n   * connection attempts are failing because other side refuses\n   * it.\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  virtual bool ms_handle_refused(Connection *con) = 0;\n\n  /**\n   * @defgroup Authentication\n   * @{\n   */\n  /**\n   * Retrieve the AuthAuthorizer for the given peer type. It might not\n   * provide one if it knows there is no AuthAuthorizer for that type.\n   *\n   * @param dest_type The peer type we want the authorizer for.\n   * @param a Double pointer to an AuthAuthorizer. The Dispatcher will fill\n   * in *a with the correct AuthAuthorizer, if it can. Make sure that you have\n   * set *a to NULL before calling in.\n   * @param force_new Force the Dispatcher to wait for a new set of keys before\n   * returning the authorizer.\n   *\n   * @return True if this function call properly filled in *a, false otherwise.\n   */\n  virtual bool ms_get_authorizer(int dest_type, AuthAuthorizer **a, bool force_new) { return false; }\n  /**\n   * Verify the authorizer for a new incoming Connection.\n   *\n   * @param con The new incoming Connection\n   * @param peer_type The type of the endpoint which initiated this Connection\n   * @param protocol The ID of the protocol in use (at time of writing, cephx or none)\n   * @param authorizer The authorization string supplied by the remote\n   * @param authorizer_reply Output param: The string we should send back to\n   * the remote to authorize ourselves. Only filled in if isvalid\n   * @param isvalid Output param: True if authorizer is valid, false otherwise\n   *\n   * @return True if we were able to prove or disprove correctness of\n   * authorizer, false otherwise.\n   */\n  virtual bool ms_verify_authorizer(Connection *con,\n\t\t\t\t    int peer_type,\n\t\t\t\t    int protocol,\n\t\t\t\t    ceph::bufferlist& authorizer,\n\t\t\t\t    ceph::bufferlist& authorizer_reply,\n\t\t\t\t    bool& isvalid,\n\t\t\t\t    CryptoKey& session_key,\n\t\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) {\n    return false;\n  }\n  /**\n   * @} //Authentication\n   */\nprotected:\n  CephContext *cct;\nprivate:\n  explicit Dispatcher(const Dispatcher &rhs);\n  Dispatcher& operator=(const Dispatcher &rhs);\n};\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n\n\n#ifndef CEPH_MESSENGER_H\n#define CEPH_MESSENGER_H\n\n#include <map>\nusing namespace std;\n\n#include \"Message.h\"\n#include \"Dispatcher.h\"\n#include \"common/Mutex.h\"\n#include \"common/Cond.h\"\n#include \"include/Context.h\"\n#include \"include/types.h\"\n#include \"include/ceph_features.h\"\n#include \"auth/Crypto.h\"\n\n#include <errno.h>\n#include <sstream>\n#include <signal.h>\n\n#define SOCKET_PRIORITY_MIN_DELAY 6\n\nclass Timer;\n\n\nclass Messenger {\nprivate:\n  list<Dispatcher*> dispatchers;\n  list <Dispatcher*> fast_dispatchers;\n  ZTracer::Endpoint trace_endpoint;\n\n  void set_endpoint_addr(const entity_addr_t& a,\n                         const entity_name_t &name);\n\nprotected:\n  /// the \"name\" of the local daemon. eg client.99\n  entity_inst_t my_inst;\n  int default_send_priority;\n  /// set to true once the Messenger has started, and set to false on shutdown\n  bool started;\n  uint32_t magic;\n  int socket_priority;\n\npublic:\n  /**\n   * Various Messenger conditional config/type flags to allow\n   * different \"transport\" Messengers to tune themselves\n   */\n  static const int HAS_HEAVY_TRAFFIC    = 0x0001;\n  static const int HAS_MANY_CONNECTIONS = 0x0002;\n  static const int HEARTBEAT            = 0x0004;\n\n  /**\n   *  The CephContext this Messenger uses. Many other components initialize themselves\n   *  from this value.\n   */\n  CephContext *cct;\n  int crcflags;\n\n  /**\n   * A Policy describes the rules of a Connection. Is there a limit on how\n   * much data this Connection can have locally? When the underlying connection\n   * experiences an error, does the Connection disappear? Can this Messenger\n   * re-establish the underlying connection?\n   */\n  struct Policy {\n    /// If true, the Connection is tossed out on errors.\n    bool lossy;\n    /// If true, the underlying connection can't be re-established from this end.\n    bool server;\n    /// If true, we will standby when idle\n    bool standby;\n    /// If true, we will try to detect session resets\n    bool resetcheck;\n    /**\n     *  The throttler is used to limit how much data is held by Messages from\n     *  the associated Connection(s). When reading in a new Message, the Messenger\n     *  will call throttler->throttle() for the size of the new Message.\n     */\n    Throttle *throttler_bytes;\n    Throttle *throttler_messages;\n\n    /// Specify features supported locally by the endpoint.\n    uint64_t features_supported;\n    /// Specify features any remotes must have to talk to this endpoint.\n    uint64_t features_required;\n\n    Policy()\n      : lossy(false), server(false), standby(false), resetcheck(true),\n\tthrottler_bytes(NULL),\n\tthrottler_messages(NULL),\n\tfeatures_supported(CEPH_FEATURES_SUPPORTED_DEFAULT),\n\tfeatures_required(0) {}\n  private:\n    Policy(bool l, bool s, bool st, bool r, uint64_t req)\n      : lossy(l), server(s), standby(st), resetcheck(r),\n\tthrottler_bytes(NULL),\n\tthrottler_messages(NULL),\n\tfeatures_supported(CEPH_FEATURES_SUPPORTED_DEFAULT),\n\tfeatures_required(req) {}\n\n  public:\n    static Policy stateful_server(uint64_t req) {\n      return Policy(false, true, true, true, req);\n    }\n    static Policy stateless_server(uint64_t req) {\n      return Policy(true, true, false, false, req);\n    }\n    static Policy lossless_peer(uint64_t req) {\n      return Policy(false, false, true, false, req);\n    }\n    static Policy lossless_peer_reuse(uint64_t req) {\n      return Policy(false, false, true, true, req);\n    }\n    static Policy lossy_client(uint64_t req) {\n      return Policy(true, false, false, false, req);\n    }\n    static Policy lossless_client(uint64_t req) {\n      return Policy(false, false, false, true, req);\n    }\n  };\n\n  /**\n   * Messenger constructor. Call this from your implementation.\n   * Messenger users should construct full implementations directly,\n   * or use the create() function.\n   */\n  Messenger(CephContext *cct_, entity_name_t w)\n    : trace_endpoint(\"0.0.0.0\", 0, \"Messenger\"),\n      my_inst(),\n      default_send_priority(CEPH_MSG_PRIO_DEFAULT), started(false),\n      magic(0),\n      socket_priority(-1),\n      cct(cct_),\n      crcflags(get_default_crc_flags(cct->_conf))\n  {\n    my_inst.name = w;\n  }\n  virtual ~Messenger() {}\n\n  /**\n   * create a new messenger\n   *\n   * Create a new messenger instance, with whatever implementation is\n   * available or specified via the configuration in cct.\n   *\n   * @param cct context\n   * @param type name of messenger type\n   * @param name entity name to register\n   * @param lname logical name of the messenger in this process (e.g., \"client\")\n   * @param nonce nonce value to uniquely identify this instance on the current host\n   * @param features bits for the local connection\n   * @param cflags general set of flags to configure transport resources\n   */\n  static Messenger *create(CephContext *cct,\n                           const string &type,\n                           entity_name_t name,\n\t\t\t   string lname,\n                           uint64_t nonce,\n\t\t\t   uint64_t cflags);\n\n  /**\n   * create a new messenger\n   *\n   * Create a new messenger instance.\n   * Same as the above, but a slightly simpler interface for clients:\n   * - Generate a random nonce\n   * - use the default feature bits\n   * - get the messenger type from cct\n   * - use the client entity_type\n   *\n   * @param cct context\n   * @param lname logical name of the messenger in this process (e.g., \"client\")\n   */\n  static Messenger *create_client_messenger(CephContext *cct, string lname);\n\n  /**\n   * @defgroup Accessors\n   * @{\n   */\n  /**\n   * Retrieve the Messenger's instance.\n   *\n   * @return A const reference to the instance this Messenger\n   * currently believes to be its own.\n   */\n  const entity_inst_t& get_myinst() { return my_inst; }\n  /**\n   * set messenger's instance\n   */\n  void set_myinst(entity_inst_t i) { my_inst = i; }\n\n  uint32_t get_magic() { return magic; }\n  void set_magic(int _magic) { magic = _magic; }\n\n  /**\n   * Retrieve the Messenger's address.\n   *\n   * @return A const reference to the address this Messenger\n   * currently believes to be its own.\n   */\n  const entity_addr_t& get_myaddr() { return my_inst.addr; }\nprotected:\n  /**\n   * set messenger's address\n   */\n  virtual void set_myaddr(const entity_addr_t& a) {\n    my_inst.addr = a;\n    set_endpoint_addr(a, my_inst.name);\n  }\npublic:\n  /**\n   * @return the zipkin trace endpoint\n   */\n  const ZTracer::Endpoint* get_trace_endpoint() const {\n    return &trace_endpoint;\n  }\n\n  /**\n   * Retrieve the Messenger's name.\n   *\n   * @return A const reference to the name this Messenger\n   * currently believes to be its own.\n   */\n  const entity_name_t& get_myname() { return my_inst.name; }\n  /**\n   * Set the name of the local entity. The name is reported to others and\n   * can be changed while the system is running, but doing so at incorrect\n   * times may have bad results.\n   *\n   * @param m The name to set.\n   */\n  void set_myname(const entity_name_t& m) { my_inst.name = m; }\n  /**\n   * Set the unknown address components for this Messenger.\n   * This is useful if the Messenger doesn't know its full address just by\n   * binding, but another Messenger on the same interface has already learned\n   * its full address. This function does not fill in known address elements,\n   * cause a rebind, or do anything of that sort.\n   *\n   * @param addr The address to use as a template.\n   */\n  virtual void set_addr_unknowns(const entity_addr_t &addr) = 0;\n  /**\n   * Set the address for this Messenger. This is useful if the Messenger\n   * binds to a specific address but advertises a different address on the\n   * the network.\n   *\n   * @param addr The address to use.\n   */\n  virtual void set_addr(const entity_addr_t &addr) = 0;\n  /// Get the default send priority.\n  int get_default_send_priority() { return default_send_priority; }\n  /**\n   * Get the number of Messages which the Messenger has received\n   * but not yet dispatched.\n   */\n  virtual int get_dispatch_queue_len() = 0;\n\n  /**\n   * Get age of oldest undelivered message\n   * (0 if the queue is empty)\n   */\n  virtual double get_dispatch_queue_max_age(utime_t now) = 0;\n  /**\n   * Get the default crc flags for this messenger.\n   * but not yet dispatched.\n   */\n  static int get_default_crc_flags(md_config_t *);\n\n  /**\n   * @} // Accessors\n   */\n\n  /**\n   * @defgroup Configuration\n   * @{\n   */\n  /**\n   * Set the cluster protocol in use by this daemon.\n   * This is an init-time function and cannot be called after calling\n   * start() or bind().\n   *\n   * @param p The cluster protocol to use. Defined externally.\n   */\n  virtual void set_cluster_protocol(int p) = 0;\n  /**\n   * Set a policy which is applied to all peers who do not have a type-specific\n   * Policy.\n   * This is an init-time function and cannot be called after calling\n   * start() or bind().\n   *\n   * @param p The Policy to apply.\n   */\n  virtual void set_default_policy(Policy p) = 0;\n  /**\n   * Set a policy which is applied to all peers of the given type.\n   * This is an init-time function and cannot be called after calling\n   * start() or bind().\n   *\n   * @param type The peer type this policy applies to.\n   * @param p The policy to apply.\n   */\n  virtual void set_policy(int type, Policy p) = 0;\n  /**\n   * Set the Policy associated with a type of peer.\n   *\n   * This can be called either on initial setup, or after connections\n   * are already established.  However, the policies for existing\n   * connections will not be affected; the new policy will only apply\n   * to future connections.\n   *\n   * @param t The peer type to get the default policy for.\n   * @return A const Policy reference.\n   */\n  virtual Policy get_policy(int t) = 0;\n  /**\n   * Get the default Policy\n   *\n   * @return A const Policy reference.\n   */\n  virtual Policy get_default_policy() = 0;\n  /**\n   * Set Throttlers applied to all Messages from the given type of peer\n   *\n   * This is an init-time function and cannot be called after calling\n   * start() or bind().\n   *\n   * @param type The peer type the Throttlers will apply to.\n   * @param bytes The Throttle for the number of bytes carried by the message\n   * @param msgs The Throttle for the number of messages for this @p type\n   * @note The Messenger does not take ownership of the Throttle pointers, but\n   * you must not destroy them before you destroy the Messenger.\n   */\n  virtual void set_policy_throttlers(int type, Throttle *bytes, Throttle *msgs=NULL) = 0;\n  /**\n   * Set the default send priority\n   *\n   * This is an init-time function and must be called *before* calling\n   * start().\n   *\n   * @param p The cluster protocol to use. Defined externally.\n   */\n  void set_default_send_priority(int p) {\n    assert(!started);\n    default_send_priority = p;\n  }\n  /**\n   * Set the priority(SO_PRIORITY) for all packets to be sent on this socket.\n   *\n   * Linux uses this value to order the networking queues: packets with a higher\n   * priority may be processed first depending on the selected device queueing\n   * discipline.\n   *\n   * @param prio The priority. Setting a priority outside the range 0 to 6\n   * requires the CAP_NET_ADMIN capability.\n   */\n  void set_socket_priority(int prio) {\n    socket_priority = prio;\n  }\n  /**\n   * Get the socket priority\n   *\n   * @return the socket priority\n   */\n  int get_socket_priority() {\n    return socket_priority;\n  }\n  /**\n   * Add a new Dispatcher to the front of the list. If you add\n   * a Dispatcher which is already included, it will get a duplicate\n   * entry. This will reduce efficiency but not break anything.\n   *\n   * @param d The Dispatcher to insert into the list.\n   */\n  void add_dispatcher_head(Dispatcher *d) { \n    bool first = dispatchers.empty();\n    dispatchers.push_front(d);\n    if (d->ms_can_fast_dispatch_any())\n      fast_dispatchers.push_front(d);\n    if (first)\n      ready();\n  }\n  /**\n   * Add a new Dispatcher to the end of the list. If you add\n   * a Dispatcher which is already included, it will get a duplicate\n   * entry. This will reduce efficiency but not break anything.\n   *\n   * @param d The Dispatcher to insert into the list.\n   */\n  void add_dispatcher_tail(Dispatcher *d) { \n    bool first = dispatchers.empty();\n    dispatchers.push_back(d);\n    if (d->ms_can_fast_dispatch_any())\n      fast_dispatchers.push_back(d);\n    if (first)\n      ready();\n  }\n  /**\n   * Bind the Messenger to a specific address. If bind_addr\n   * is not completely filled in the system will use the\n   * valid portions and cycle through the unset ones (eg, the port)\n   * in an unspecified order.\n   *\n   * @param bind_addr The address to bind to.\n   * @return 0 on success, or -1 on error, or -errno if\n   * we can be more specific about the failure.\n   */\n  virtual int bind(const entity_addr_t& bind_addr) = 0;\n  /**\n   * This function performs a full restart of the Messenger component,\n   * whatever that means.  Other entities who connect to this\n   * Messenger post-rebind() should perceive it as a new entity which\n   * they have not previously contacted, and it MUST bind to a\n   * different address than it did previously.\n   *\n   * @param avoid_ports Additional port to avoid binding to.\n   */\n  virtual int rebind(const set<int>& avoid_ports) { return -EOPNOTSUPP; }\n  /**\n   * Bind the 'client' Messenger to a specific address.Messenger will bind\n   * the address before connect to others when option ms_bind_before_connect\n   * is true.\n   * @param bind_addr The address to bind to.\n   * @return 0 on success, or -1 on error, or -errno if\n   */\n  virtual int client_bind(const entity_addr_t& bind_addr) = 0;\n  /**\n   * @} // Configuration\n   */\n\n  /**\n   * @defgroup Startup/Shutdown\n   * @{\n   */\n  /**\n   * Perform any resource allocation, thread startup, etc\n   * that is required before attempting to connect to other\n   * Messengers or transmit messages.\n   * Once this function completes, started shall be set to true.\n   *\n   * @return 0 on success; -errno on failure.\n   */\n  virtual int start() { started = true; return 0; }\n\n  // shutdown\n  /**\n   * Block until the Messenger has finished shutting down (according\n   * to the shutdown() function).\n   * It is valid to call this after calling shutdown(), but it must\n   * be called before deleting the Messenger.\n   */\n  virtual void wait() = 0;\n  /**\n   * Initiate a shutdown of the Messenger.\n   *\n   * @return 0 on success, -errno otherwise.\n   */\n  virtual int shutdown() { started = false; return 0; }\n  /**\n   * @} // Startup/Shutdown\n   */\n\n  /**\n   * @defgroup Messaging\n   * @{\n   */\n  /**\n   * Queue the given Message for the given entity.\n   * Success in this function does not guarantee Message delivery, only\n   * success in queueing the Message. Other guarantees may be provided based\n   * on the Connection policy associated with the dest.\n   *\n   * @param m The Message to send. The Messenger consumes a single reference\n   * when you pass it in.\n   * @param dest The entity to send the Message to.\n   *\n   * DEPRECATED: please do not use this interface for any new code;\n   * use the Connection* variant.\n   *\n   * @return 0 on success, or -errno on failure.\n   */\n  virtual int send_message(Message *m, const entity_inst_t& dest) = 0;\n\n  /**\n   * @} // Messaging\n   */\n  /**\n   * @defgroup Connection Management\n   * @{\n   */\n  /**\n   * Get the Connection object associated with a given entity. If a\n   * Connection does not exist, create one and establish a logical connection.\n   * The caller owns a reference when this returns. Call ->put() when you're\n   * done!\n   *\n   * @param dest The entity to get a connection for.\n   */\n  virtual ConnectionRef get_connection(const entity_inst_t& dest) = 0;\n  /**\n   * Get the Connection object associated with ourselves.\n   */\n  virtual ConnectionRef get_loopback_connection() = 0;\n  /**\n   * Mark down a Connection to a remote.\n   *\n   * This will cause us to discard our outgoing queue for them, and if\n   * reset detection is enabled in the policy and the endpoint tries\n   * to reconnect they will discard their queue when we inform them of\n   * the session reset.\n   *\n   * If there is no Connection to the given dest, it is a no-op.\n   *\n   * This generates a RESET notification to the Dispatcher.\n   *\n   * DEPRECATED: please do not use this interface for any new code;\n   * use the Connection* variant.\n   *\n   * @param a The address to mark down.\n   */\n  virtual void mark_down(const entity_addr_t& a) = 0;\n  /**\n   * Mark all the existing Connections down. This is equivalent\n   * to iterating over all Connections and calling mark_down()\n   * on each.\n   *\n   * This will generate a RESET event for each closed connections.\n   */\n  virtual void mark_down_all() = 0;\n  /**\n   * @} // Connection Management\n   */\nprotected:\n  /**\n   * @defgroup Subclass Interfacing\n   * @{\n   */\n  /**\n   * A courtesy function for Messenger implementations which\n   * will be called when we receive our first Dispatcher.\n   */\n  virtual void ready() { }\n  /**\n   * @} // Subclass Interfacing\n   */\npublic:\n#ifdef CEPH_USE_SIGPIPE_BLOCKER\n  /**\n   * We need to disable SIGPIPE on all platforms, and if they\n   * don't give us a better mechanism (read: are on Solaris) that\n   * means blocking the signal whenever we do a send or sendmsg...\n   * That means any implementations must invoke MSGR_SIGPIPE_STOPPER in-scope\n   * whenever doing so. On most systems that's blank, but on systems where\n   * it's needed we construct an RAII object to plug and un-plug the SIGPIPE.\n   * See http://www.microhowto.info/howto/ignore_sigpipe_without_affecting_other_threads_in_a_process.html\n   */\n  struct sigpipe_stopper {\n    bool blocked;\n    sigset_t existing_mask;\n    sigset_t pipe_mask;\n    sigpipe_stopper() {\n      sigemptyset(&pipe_mask);\n      sigaddset(&pipe_mask, SIGPIPE);\n      sigset_t signals;\n      sigemptyset(&signals);\n      sigpending(&signals);\n      if (sigismember(&signals, SIGPIPE)) {\n\tblocked = false;\n      } else {\n\tblocked = true;\n\tint r = pthread_sigmask(SIG_BLOCK, &pipe_mask, &existing_mask);\n\tassert(r == 0);\n      }\n    }\n    ~sigpipe_stopper() {\n      if (blocked) {\n\tstruct timespec nowait{0};\n\tint r = sigtimedwait(&pipe_mask, 0, &nowait);\n\tassert(r == EAGAIN || r == 0);\n\tr = pthread_sigmask(SIG_SETMASK, &existing_mask, 0);\n\tassert(r == 0);\n      }\n    }\n  };\n#  define MSGR_SIGPIPE_STOPPER Messenger::sigpipe_stopper stopper();\n#else\n#  define MSGR_SIGPIPE_STOPPER\n#endif\n  /**\n   * @defgroup Dispatcher Interfacing\n   * @{\n   */\n  /**\n   * Determine whether a message can be fast-dispatched. We will\n   * query each Dispatcher in sequence to determine if they are\n   * capable of handling a particular message via \"fast dispatch\".\n   *\n   * @param m The Message we are testing.\n   */\n  bool ms_can_fast_dispatch(const Message *m) {\n    for (list<Dispatcher*>::iterator p = fast_dispatchers.begin();\n\t p != fast_dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_can_fast_dispatch(m))\n\treturn true;\n    }\n    return false;\n  }\n\n  /**\n   * Deliver a single Message via \"fast dispatch\".\n   *\n   * @param m The Message we are fast dispatching. We take ownership\n   * of one reference to it.\n   * If none of our Dispatchers can handle it, ceph_abort().\n   */\n  void ms_fast_dispatch(Message *m) {\n    m->set_dispatch_stamp(ceph_clock_now());\n    for (list<Dispatcher*>::iterator p = fast_dispatchers.begin();\n\t p != fast_dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_can_fast_dispatch(m)) {\n\t(*p)->ms_fast_dispatch(m);\n\treturn;\n      }\n    }\n    ceph_abort();\n  }\n  /**\n   *\n   */\n  void ms_fast_preprocess(Message *m) {\n    for (list<Dispatcher*>::iterator p = fast_dispatchers.begin();\n\t p != fast_dispatchers.end();\n\t ++p) {\n      (*p)->ms_fast_preprocess(m);\n    }\n  }\n  /**\n   *  Deliver a single Message. Send it to each Dispatcher\n   *  in sequence until one of them handles it.\n   *  If none of our Dispatchers can handle it, assert(0).\n   *\n   *  @param m The Message to deliver. We take ownership of\n   *  one reference to it.\n   */\n  void ms_deliver_dispatch(Message *m) {\n    m->set_dispatch_stamp(ceph_clock_now());\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_dispatch(m))\n\treturn;\n    }\n    lsubdout(cct, ms, 0) << \"ms_deliver_dispatch: unhandled message \" << m << \" \" << *m << \" from \"\n\t\t\t << m->get_source_inst() << dendl;\n    assert(!cct->_conf->ms_die_on_unhandled_msg);\n    m->put();\n  }\n  /**\n   * Notify each Dispatcher of a new Connection. Call\n   * this function whenever a new Connection is initiated or\n   * reconnects.\n   *\n   * @param con Pointer to the new Connection.\n   */\n  void ms_deliver_handle_connect(Connection *con) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p)\n      (*p)->ms_handle_connect(con);\n  }\n\n  /**\n   * Notify each fast Dispatcher of a new Connection. Call\n   * this function whenever a new Connection is initiated or\n   * reconnects.\n   *\n   * @param con Pointer to the new Connection.\n   */\n  void ms_deliver_handle_fast_connect(Connection *con) {\n    for (list<Dispatcher*>::iterator p = fast_dispatchers.begin();\n         p != fast_dispatchers.end();\n         ++p)\n      (*p)->ms_handle_fast_connect(con);\n  }\n\n  /**\n   * Notify each Dispatcher of a new incomming Connection. Call\n   * this function whenever a new Connection is accepted.\n   *\n   * @param con Pointer to the new Connection.\n   */\n  void ms_deliver_handle_accept(Connection *con) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p)\n      (*p)->ms_handle_accept(con);\n  }\n\n  /**\n   * Notify each fast Dispatcher of a new incoming Connection. Call\n   * this function whenever a new Connection is accepted.\n   *\n   * @param con Pointer to the new Connection.\n   */\n  void ms_deliver_handle_fast_accept(Connection *con) {\n    for (list<Dispatcher*>::iterator p = fast_dispatchers.begin();\n         p != fast_dispatchers.end();\n         ++p)\n      (*p)->ms_handle_fast_accept(con);\n  }\n\n  /**\n   * Notify each Dispatcher of a Connection which may have lost\n   * Messages. Call this function whenever you detect that a lossy Connection\n   * has been disconnected.\n   *\n   * @param con Pointer to the broken Connection.\n   */\n  void ms_deliver_handle_reset(Connection *con) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_handle_reset(con))\n\treturn;\n    }\n  }\n  /**\n   * Notify each Dispatcher of a Connection which has been \"forgotten\" about\n   * by the remote end, implying that messages have probably been lost.\n   * Call this function whenever you detect a reset.\n   *\n   * @param con Pointer to the broken Connection.\n   */\n  void ms_deliver_handle_remote_reset(Connection *con) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p)\n      (*p)->ms_handle_remote_reset(con);\n  }\n\n  /**\n   * Notify each Dispatcher of a Connection for which reconnection\n   * attempts are being refused. Call this function whenever you\n   * detect that a lossy Connection has been disconnected and it's\n   * impossible to reconnect.\n   *\n   * @param con Pointer to the broken Connection.\n   */\n  void ms_deliver_handle_refused(Connection *con) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n         p != dispatchers.end();\n         ++p) {\n      if ((*p)->ms_handle_refused(con))\n        return;\n    }\n  }\n\n  /**\n   * Get the AuthAuthorizer for a new outgoing Connection.\n   *\n   * @param peer_type The peer type for the new Connection\n   * @param force_new True if we want to wait for new keys, false otherwise.\n   * @return A pointer to the AuthAuthorizer, if we have one; NULL otherwise\n   */\n  AuthAuthorizer *ms_deliver_get_authorizer(int peer_type, bool force_new) {\n    AuthAuthorizer *a = 0;\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_get_authorizer(peer_type, &a, force_new))\n\treturn a;\n    }\n    return NULL;\n  }\n  /**\n   * Verify that the authorizer on a new incoming Connection is correct.\n   *\n   * @param con The new incoming Connection\n   * @param peer_type The type of the endpoint on the new Connection\n   * @param protocol The ID of the protocol in use (at time of writing, cephx or none)\n   * @param authorizer The authorization string supplied by the remote\n   * @param authorizer_reply Output param: The string we should send back to\n   * the remote to authorize ourselves. Only filled in if isvalid\n   * @param isvalid Output param: True if authorizer is valid, false otherwise\n   *\n   * @return True if we were able to prove or disprove correctness of\n   * authorizer, false otherwise.\n   */\n  bool ms_deliver_verify_authorizer(Connection *con, int peer_type,\n\t\t\t\t    int protocol, bufferlist& authorizer, bufferlist& authorizer_reply,\n\t\t\t\t    bool& isvalid, CryptoKey& session_key,\n\t\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) {\n    for (list<Dispatcher*>::iterator p = dispatchers.begin();\n\t p != dispatchers.end();\n\t ++p) {\n      if ((*p)->ms_verify_authorizer(con, peer_type, protocol, authorizer, authorizer_reply,\n\t\t\t\t     isvalid, session_key, challenge))\n\treturn true;\n    }\n    return false;\n  }\n\n  /**\n   * @} // Dispatcher Interfacing\n   */\n};\n\n\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2014 UnitedStack <haomai@unitedstack.com>\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include <unistd.h>\n\n#include \"include/Context.h\"\n#include \"common/errno.h\"\n#include \"AsyncMessenger.h\"\n#include \"AsyncConnection.h\"\n\n#include \"messages/MOSDOp.h\"\n#include \"messages/MOSDOpReply.h\"\n#include \"common/EventTrace.h\"\n\n// Constant to limit starting sequence number to 2^31.  Nothing special about it, just a big number.  PLR\n#define SEQ_MASK  0x7fffffff \n\n#define dout_subsys ceph_subsys_ms\n#undef dout_prefix\n#define dout_prefix _conn_prefix(_dout)\nostream& AsyncConnection::_conn_prefix(std::ostream *_dout) {\n  return *_dout << \"-- \" << async_msgr->get_myinst().addr << \" >> \" << peer_addr << \" conn(\" << this\n                << \" :\" << port\n                << \" s=\" << get_state_name(state)\n                << \" pgs=\" << peer_global_seq\n                << \" cs=\" << connect_seq\n                << \" l=\" << policy.lossy\n                << \").\";\n}\n\n// Notes:\n// 1. Don't dispatch any event when closed! It may cause AsyncConnection alive even if AsyncMessenger dead\n\nconst int AsyncConnection::TCP_PREFETCH_MIN_SIZE = 512;\nconst int ASYNC_COALESCE_THRESHOLD = 256;\n\nclass C_time_wakeup : public EventCallback {\n  AsyncConnectionRef conn;\n\n public:\n  explicit C_time_wakeup(AsyncConnectionRef c): conn(c) {}\n  void do_request(int fd_or_id) override {\n    conn->wakeup_from(fd_or_id);\n  }\n};\n\nclass C_handle_read : public EventCallback {\n  AsyncConnectionRef conn;\n\n public:\n  explicit C_handle_read(AsyncConnectionRef c): conn(c) {}\n  void do_request(int fd_or_id) override {\n    conn->process();\n  }\n};\n\nclass C_handle_write : public EventCallback {\n  AsyncConnectionRef conn;\n\n public:\n  explicit C_handle_write(AsyncConnectionRef c): conn(c) {}\n  void do_request(int fd) override {\n    conn->handle_write();\n  }\n};\n\nclass C_clean_handler : public EventCallback {\n  AsyncConnectionRef conn;\n public:\n  explicit C_clean_handler(AsyncConnectionRef c): conn(c) {}\n  void do_request(int id) override {\n    conn->cleanup();\n    delete this;\n  }\n};\n\nclass C_tick_wakeup : public EventCallback {\n  AsyncConnectionRef conn;\n\n public:\n  explicit C_tick_wakeup(AsyncConnectionRef c): conn(c) {}\n  void do_request(int fd_or_id) override {\n    conn->tick(fd_or_id);\n  }\n};\n\nstatic void alloc_aligned_buffer(bufferlist& data, unsigned len, unsigned off)\n{\n  // create a buffer to read into that matches the data alignment\n  unsigned left = len;\n  if (off & ~CEPH_PAGE_MASK) {\n    // head\n    unsigned head = 0;\n    head = MIN(CEPH_PAGE_SIZE - (off & ~CEPH_PAGE_MASK), left);\n    data.push_back(buffer::create(head));\n    left -= head;\n  }\n  unsigned middle = left & CEPH_PAGE_MASK;\n  if (middle > 0) {\n    data.push_back(buffer::create_page_aligned(middle));\n    left -= middle;\n  }\n  if (left) {\n    data.push_back(buffer::create(left));\n  }\n}\n\nAsyncConnection::AsyncConnection(CephContext *cct, AsyncMessenger *m, DispatchQueue *q,\n                                 Worker *w)\n  : Connection(cct, m), delay_state(NULL), async_msgr(m), conn_id(q->get_id()),\n    logger(w->get_perf_counter()), global_seq(0), connect_seq(0), peer_global_seq(0),\n    state(STATE_NONE), state_after_send(STATE_NONE), port(-1),\n    dispatch_queue(q), can_write(WriteStatus::NOWRITE),\n    keepalive(false), recv_buf(NULL),\n    recv_max_prefetch(MAX(msgr->cct->_conf->ms_tcp_prefetch_max_size, TCP_PREFETCH_MIN_SIZE)),\n    recv_start(0), recv_end(0),\n    last_active(ceph::coarse_mono_clock::now()),\n    inactive_timeout_us(cct->_conf->ms_tcp_read_timeout*1000*1000),\n    got_bad_auth(false), authorizer(NULL), replacing(false),\n    is_reset_from_peer(false), once_ready(false), state_buffer(NULL), state_offset(0),\n    worker(w), center(&w->center)\n{\n  read_handler = new C_handle_read(this);\n  write_handler = new C_handle_write(this);\n  wakeup_handler = new C_time_wakeup(this);\n  tick_handler = new C_tick_wakeup(this);\n  memset(msgvec, 0, sizeof(msgvec));\n  // double recv_max_prefetch see \"read_until\"\n  recv_buf = new char[2*recv_max_prefetch];\n  state_buffer = new char[4096];\n  logger->inc(l_msgr_created_connections);\n}\n\nAsyncConnection::~AsyncConnection()\n{\n  assert(out_q.empty());\n  assert(sent.empty());\n  delete authorizer;\n  if (recv_buf)\n    delete[] recv_buf;\n  if (state_buffer)\n    delete[] state_buffer;\n  assert(!delay_state);\n}\n\nvoid AsyncConnection::maybe_start_delay_thread()\n{\n  if (!delay_state) {\n    auto pos = async_msgr->cct->_conf->get_val<std::string>(\"ms_inject_delay_type\").find(ceph_entity_type_name(peer_type));\n    if (pos != string::npos) {\n      ldout(msgr->cct, 1) << __func__ << \" setting up a delay queue\" << dendl;\n      delay_state = new DelayedDelivery(async_msgr, center, dispatch_queue, conn_id);\n    }\n  }\n}\n\n/* return -1 means `fd` occurs error or closed, it should be closed\n * return 0 means EAGAIN or EINTR */\nssize_t AsyncConnection::read_bulk(char *buf, unsigned len)\n{\n  ssize_t nread;\n again:\n  nread = cs.read(buf, len);\n  if (nread < 0) {\n    if (nread == -EAGAIN) {\n      nread = 0;\n    } else if (nread == -EINTR) {\n      goto again;\n    } else {\n      ldout(async_msgr->cct, 1) << __func__ << \" reading from fd=\" << cs.fd()\n                          << \" : \"<< strerror(nread) << dendl;\n      return -1;\n    }\n  } else if (nread == 0) {\n    ldout(async_msgr->cct, 1) << __func__ << \" peer close file descriptor \"\n                              << cs.fd() << dendl;\n    return -1;\n  }\n  return nread;\n}\n\n// return the remaining bytes, it may larger than the length of ptr\n// else return < 0 means error\nssize_t AsyncConnection::_try_send(bool more)\n{\n  if (async_msgr->cct->_conf->ms_inject_socket_failures && cs) {\n    if (rand() % async_msgr->cct->_conf->ms_inject_socket_failures == 0) {\n      ldout(async_msgr->cct, 0) << __func__ << \" injecting socket failure\" << dendl;\n      cs.shutdown();\n    }\n  }\n\n  assert(center->in_thread());\n  ssize_t r = cs.send(outcoming_bl, more);\n  if (r < 0) {\n    ldout(async_msgr->cct, 1) << __func__ << \" send error: \" << cpp_strerror(r) << dendl;\n    return r;\n  }\n\n  ldout(async_msgr->cct, 10) << __func__ << \" sent bytes \" << r\n                             << \" remaining bytes \" << outcoming_bl.length() << dendl;\n\n  if (!open_write && is_queued()) {\n    center->create_file_event(cs.fd(), EVENT_WRITABLE, write_handler);\n    open_write = true;\n  }\n\n  if (open_write && !is_queued()) {\n    center->delete_file_event(cs.fd(), EVENT_WRITABLE);\n    open_write = false;\n    if (state_after_send != STATE_NONE)\n      center->dispatch_event_external(read_handler);\n  }\n\n  return outcoming_bl.length();\n}\n\n// Because this func will be called multi times to populate\n// the needed buffer, so the passed in bufferptr must be the same.\n// Normally, only \"read_message\" will pass existing bufferptr in\n//\n// And it will uses readahead method to reduce small read overhead,\n// \"recv_buf\" is used to store read buffer\n//\n// return the remaining bytes, 0 means this buffer is finished\n// else return < 0 means error\nssize_t AsyncConnection::read_until(unsigned len, char *p)\n{\n  ldout(async_msgr->cct, 25) << __func__ << \" len is \" << len << \" state_offset is \"\n                             << state_offset << dendl;\n\n  if (async_msgr->cct->_conf->ms_inject_socket_failures && cs) {\n    if (rand() % async_msgr->cct->_conf->ms_inject_socket_failures == 0) {\n      ldout(async_msgr->cct, 0) << __func__ << \" injecting socket failure\" << dendl;\n      cs.shutdown();\n    }\n  }\n\n  ssize_t r = 0;\n  uint64_t left = len - state_offset;\n  if (recv_end > recv_start) {\n    uint64_t to_read = MIN(recv_end - recv_start, left);\n    memcpy(p, recv_buf+recv_start, to_read);\n    recv_start += to_read;\n    left -= to_read;\n    ldout(async_msgr->cct, 25) << __func__ << \" got \" << to_read << \" in buffer \"\n                               << \" left is \" << left << \" buffer still has \"\n                               << recv_end - recv_start << dendl;\n    if (left == 0) {\n      return 0;\n    }\n    state_offset += to_read;\n  }\n\n  recv_end = recv_start = 0;\n  /* nothing left in the prefetch buffer */\n  if (len > recv_max_prefetch) {\n    /* this was a large read, we don't prefetch for these */\n    do {\n      r = read_bulk(p+state_offset, left);\n      ldout(async_msgr->cct, 25) << __func__ << \" read_bulk left is \" << left << \" got \" << r << dendl;\n      if (r < 0) {\n        ldout(async_msgr->cct, 1) << __func__ << \" read failed\" << dendl;\n        return -1;\n      } else if (r == static_cast<int>(left)) {\n        state_offset = 0;\n        return 0;\n      }\n      state_offset += r;\n      left -= r;\n    } while (r > 0);\n  } else {\n    do {\n      r = read_bulk(recv_buf+recv_end, recv_max_prefetch);\n      ldout(async_msgr->cct, 25) << __func__ << \" read_bulk recv_end is \" << recv_end\n                                 << \" left is \" << left << \" got \" << r << dendl;\n      if (r < 0) {\n        ldout(async_msgr->cct, 1) << __func__ << \" read failed\" << dendl;\n        return -1;\n      }\n      recv_end += r;\n      if (r >= static_cast<int>(left)) {\n        recv_start = len - state_offset;\n        memcpy(p+state_offset, recv_buf, recv_start);\n        state_offset = 0;\n        return 0;\n      }\n      left -= r;\n    } while (r > 0);\n    memcpy(p+state_offset, recv_buf, recv_end-recv_start);\n    state_offset += (recv_end - recv_start);\n    recv_end = recv_start = 0;\n  }\n  ldout(async_msgr->cct, 25) << __func__ << \" need len \" << len << \" remaining \"\n                             << len - state_offset << \" bytes\" << dendl;\n  return len - state_offset;\n}\n\nvoid AsyncConnection::inject_delay() {\n  if (async_msgr->cct->_conf->ms_inject_internal_delays) {\n    ldout(async_msgr->cct, 10) << __func__ << \" sleep for \" << \n      async_msgr->cct->_conf->ms_inject_internal_delays << dendl;\n    utime_t t;\n    t.set_from_double(async_msgr->cct->_conf->ms_inject_internal_delays);\n    t.sleep();\n  }\n}\n\nvoid AsyncConnection::process()\n{\n  ssize_t r = 0;\n  int prev_state = state;\n#if defined(WITH_LTTNG) && defined(WITH_EVENTTRACE)\n  utime_t ltt_recv_stamp = ceph_clock_now();\n#endif\n  bool need_dispatch_writer = false;\n  std::lock_guard<std::mutex> l(lock);\n  last_active = ceph::coarse_mono_clock::now();\n  auto recv_start_time = ceph::mono_clock::now();\n  do {\n    ldout(async_msgr->cct, 20) << __func__ << \" prev state is \" << get_state_name(prev_state) << dendl;\n    prev_state = state;\n    switch (state) {\n      case STATE_OPEN:\n        {\n          char tag = -1;\n          r = read_until(sizeof(tag), &tag);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read tag failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          if (tag == CEPH_MSGR_TAG_KEEPALIVE) {\n            ldout(async_msgr->cct, 20) << __func__ << \" got KEEPALIVE\" << dendl;\n\t    set_last_keepalive(ceph_clock_now());\n          } else if (tag == CEPH_MSGR_TAG_KEEPALIVE2) {\n            state = STATE_OPEN_KEEPALIVE2;\n          } else if (tag == CEPH_MSGR_TAG_KEEPALIVE2_ACK) {\n            state = STATE_OPEN_KEEPALIVE2_ACK;\n          } else if (tag == CEPH_MSGR_TAG_ACK) {\n            state = STATE_OPEN_TAG_ACK;\n          } else if (tag == CEPH_MSGR_TAG_MSG) {\n            state = STATE_OPEN_MESSAGE_HEADER;\n          } else if (tag == CEPH_MSGR_TAG_CLOSE) {\n            state = STATE_OPEN_TAG_CLOSE;\n          } else {\n            ldout(async_msgr->cct, 0) << __func__ << \" bad tag \" << (int)tag << dendl;\n            goto fail;\n          }\n\n          break;\n        }\n\n      case STATE_OPEN_KEEPALIVE2:\n        {\n          ceph_timespec *t;\n          r = read_until(sizeof(*t), state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read keeplive timespec failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          ldout(async_msgr->cct, 30) << __func__ << \" got KEEPALIVE2 tag ...\" << dendl;\n          t = (ceph_timespec*)state_buffer;\n          utime_t kp_t = utime_t(*t);\n          write_lock.lock();\n          _append_keepalive_or_ack(true, &kp_t);\n\t  write_lock.unlock();\n          ldout(async_msgr->cct, 20) << __func__ << \" got KEEPALIVE2 \" << kp_t << dendl;\n\t  set_last_keepalive(ceph_clock_now());\n          need_dispatch_writer = true;\n          state = STATE_OPEN;\n          break;\n        }\n\n      case STATE_OPEN_KEEPALIVE2_ACK:\n        {\n          ceph_timespec *t;\n          r = read_until(sizeof(*t), state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read keeplive timespec failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          t = (ceph_timespec*)state_buffer;\n          set_last_keepalive_ack(utime_t(*t));\n          ldout(async_msgr->cct, 20) << __func__ << \" got KEEPALIVE_ACK\" << dendl;\n          state = STATE_OPEN;\n          break;\n        }\n\n      case STATE_OPEN_TAG_ACK:\n        {\n          ceph_le64 *seq;\n          r = read_until(sizeof(*seq), state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read ack seq failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          seq = (ceph_le64*)state_buffer;\n          ldout(async_msgr->cct, 20) << __func__ << \" got ACK\" << dendl;\n          handle_ack(*seq);\n          state = STATE_OPEN;\n          break;\n        }\n\n      case STATE_OPEN_MESSAGE_HEADER:\n        {\n#if defined(WITH_LTTNG) && defined(WITH_EVENTTRACE)\n          ltt_recv_stamp = ceph_clock_now();\n#endif\n          recv_stamp = ceph_clock_now();\n          ldout(async_msgr->cct, 20) << __func__ << \" begin MSG\" << dendl;\n          ceph_msg_header header;\n          ceph_msg_header_old oldheader;\n          __u32 header_crc = 0;\n          unsigned len;\n          if (has_feature(CEPH_FEATURE_NOSRCADDR))\n            len = sizeof(header);\n          else\n            len = sizeof(oldheader);\n\n          r = read_until(len, state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read message header failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          ldout(async_msgr->cct, 20) << __func__ << \" got MSG header\" << dendl;\n\n          if (has_feature(CEPH_FEATURE_NOSRCADDR)) {\n            header = *((ceph_msg_header*)state_buffer);\n            if (msgr->crcflags & MSG_CRC_HEADER)\n              header_crc = ceph_crc32c(0, (unsigned char *)&header,\n                                       sizeof(header) - sizeof(header.crc));\n          } else {\n            oldheader = *((ceph_msg_header_old*)state_buffer);\n            // this is fugly\n            memcpy(&header, &oldheader, sizeof(header));\n            header.src = oldheader.src.name;\n            header.reserved = oldheader.reserved;\n            if (msgr->crcflags & MSG_CRC_HEADER) {\n              header.crc = oldheader.crc;\n              header_crc = ceph_crc32c(0, (unsigned char *)&oldheader, sizeof(oldheader) - sizeof(oldheader.crc));\n            }\n          }\n\n          ldout(async_msgr->cct, 20) << __func__ << \" got envelope type=\" << header.type\n                              << \" src \" << entity_name_t(header.src)\n                              << \" front=\" << header.front_len\n                              << \" data=\" << header.data_len\n                              << \" off \" << header.data_off << dendl;\n\n          // verify header crc\n          if (msgr->crcflags & MSG_CRC_HEADER && header_crc != header.crc) {\n            ldout(async_msgr->cct,0) << __func__ << \" got bad header crc \"\n                                     << header_crc << \" != \" << header.crc << dendl;\n            goto fail;\n          }\n\n          // Reset state\n          data_buf.clear();\n          front.clear();\n          middle.clear();\n          data.clear();\n          current_header = header;\n          state = STATE_OPEN_MESSAGE_THROTTLE_MESSAGE;\n          break;\n        }\n\n      case STATE_OPEN_MESSAGE_THROTTLE_MESSAGE:\n        {\n          if (policy.throttler_messages) {\n            ldout(async_msgr->cct, 10) << __func__ << \" wants \" << 1 << \" message from policy throttler \"\n                                       << policy.throttler_messages->get_current() << \"/\"\n                                       << policy.throttler_messages->get_max() << dendl;\n            if (!policy.throttler_messages->get_or_fail()) {\n              ldout(async_msgr->cct, 10) << __func__ << \" wants 1 message from policy throttle \"\n\t\t\t\t\t << policy.throttler_messages->get_current() << \"/\"\n\t\t\t\t\t << policy.throttler_messages->get_max() << \" failed, just wait.\" << dendl;\n              // following thread pool deal with th full message queue isn't a\n              // short time, so we can wait a ms.\n              if (register_time_events.empty())\n                register_time_events.insert(center->create_time_event(1000, wakeup_handler));\n              break;\n            }\n          }\n\n          state = STATE_OPEN_MESSAGE_THROTTLE_BYTES;\n          break;\n        }\n\n      case STATE_OPEN_MESSAGE_THROTTLE_BYTES:\n        {\n          cur_msg_size = current_header.front_len + current_header.middle_len + current_header.data_len;\n          if (cur_msg_size) {\n            if (policy.throttler_bytes) {\n              ldout(async_msgr->cct, 10) << __func__ << \" wants \" << cur_msg_size << \" bytes from policy throttler \"\n                                         << policy.throttler_bytes->get_current() << \"/\"\n                                         << policy.throttler_bytes->get_max() << dendl;\n              if (!policy.throttler_bytes->get_or_fail(cur_msg_size)) {\n                ldout(async_msgr->cct, 10) << __func__ << \" wants \" << cur_msg_size << \" bytes from policy throttler \"\n                                           << policy.throttler_bytes->get_current() << \"/\"\n                                           << policy.throttler_bytes->get_max() << \" failed, just wait.\" << dendl;\n                // following thread pool deal with th full message queue isn't a\n                // short time, so we can wait a ms.\n                if (register_time_events.empty())\n                  register_time_events.insert(center->create_time_event(1000, wakeup_handler));\n                break;\n              }\n            }\n          }\n\n          state = STATE_OPEN_MESSAGE_THROTTLE_DISPATCH_QUEUE;\n          break;\n        }\n\n      case STATE_OPEN_MESSAGE_THROTTLE_DISPATCH_QUEUE:\n        {\n          if (cur_msg_size) {\n            if (!dispatch_queue->dispatch_throttler.get_or_fail(cur_msg_size)) {\n              ldout(async_msgr->cct, 10) << __func__ << \" wants \" << cur_msg_size << \" bytes from dispatch throttle \"\n                                         << dispatch_queue->dispatch_throttler.get_current() << \"/\"\n                                         << dispatch_queue->dispatch_throttler.get_max() << \" failed, just wait.\" << dendl;\n              // following thread pool deal with th full message queue isn't a\n              // short time, so we can wait a ms.\n              if (register_time_events.empty())\n                register_time_events.insert(center->create_time_event(1000, wakeup_handler));\n              break;\n            }\n          }\n\n          throttle_stamp = ceph_clock_now();\n          state = STATE_OPEN_MESSAGE_READ_FRONT;\n          break;\n        }\n\n      case STATE_OPEN_MESSAGE_READ_FRONT:\n        {\n          // read front\n          unsigned front_len = current_header.front_len;\n          if (front_len) {\n            if (!front.length())\n              front.push_back(buffer::create(front_len));\n\n            r = read_until(front_len, front.c_str());\n            if (r < 0) {\n              ldout(async_msgr->cct, 1) << __func__ << \" read message front failed\" << dendl;\n              goto fail;\n            } else if (r > 0) {\n              break;\n            }\n\n            ldout(async_msgr->cct, 20) << __func__ << \" got front \" << front.length() << dendl;\n          }\n          state = STATE_OPEN_MESSAGE_READ_MIDDLE;\n        }\n\n      case STATE_OPEN_MESSAGE_READ_MIDDLE:\n        {\n          // read middle\n          unsigned middle_len = current_header.middle_len;\n          if (middle_len) {\n            if (!middle.length())\n              middle.push_back(buffer::create(middle_len));\n\n            r = read_until(middle_len, middle.c_str());\n            if (r < 0) {\n              ldout(async_msgr->cct, 1) << __func__ << \" read message middle failed\" << dendl;\n              goto fail;\n            } else if (r > 0) {\n              break;\n            }\n            ldout(async_msgr->cct, 20) << __func__ << \" got middle \" << middle.length() << dendl;\n          }\n\n          state = STATE_OPEN_MESSAGE_READ_DATA_PREPARE;\n        }\n\n      case STATE_OPEN_MESSAGE_READ_DATA_PREPARE:\n        {\n          // read data\n          unsigned data_len = le32_to_cpu(current_header.data_len);\n          unsigned data_off = le32_to_cpu(current_header.data_off);\n          if (data_len) {\n            // get a buffer\n            map<ceph_tid_t,pair<bufferlist,int> >::iterator p = rx_buffers.find(current_header.tid);\n            if (p != rx_buffers.end()) {\n              ldout(async_msgr->cct,10) << __func__ << \" seleting rx buffer v \" << p->second.second\n                                  << \" at offset \" << data_off\n                                  << \" len \" << p->second.first.length() << dendl;\n              data_buf = p->second.first;\n              // make sure it's big enough\n              if (data_buf.length() < data_len)\n                data_buf.push_back(buffer::create(data_len - data_buf.length()));\n              data_blp = data_buf.begin();\n            } else {\n              ldout(async_msgr->cct,20) << __func__ << \" allocating new rx buffer at offset \" << data_off << dendl;\n              alloc_aligned_buffer(data_buf, data_len, data_off);\n              data_blp = data_buf.begin();\n            }\n          }\n\n          msg_left = data_len;\n          state = STATE_OPEN_MESSAGE_READ_DATA;\n        }\n\n      case STATE_OPEN_MESSAGE_READ_DATA:\n        {\n          while (msg_left > 0) {\n            bufferptr bp = data_blp.get_current_ptr();\n            unsigned read = MIN(bp.length(), msg_left);\n            r = read_until(read, bp.c_str());\n            if (r < 0) {\n              ldout(async_msgr->cct, 1) << __func__ << \" read data error \" << dendl;\n              goto fail;\n            } else if (r > 0) {\n              break;\n            }\n\n            data_blp.advance(read);\n            data.append(bp, 0, read);\n            msg_left -= read;\n          }\n\n          if (msg_left > 0)\n            break;\n\n          state = STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH;\n        }\n\n      case STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH:\n        {\n          ceph_msg_footer footer;\n          ceph_msg_footer_old old_footer;\n          unsigned len;\n          // footer\n          if (has_feature(CEPH_FEATURE_MSG_AUTH))\n            len = sizeof(footer);\n          else\n            len = sizeof(old_footer);\n\n          r = read_until(len, state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read footer data error \" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          if (has_feature(CEPH_FEATURE_MSG_AUTH)) {\n            footer = *((ceph_msg_footer*)state_buffer);\n          } else {\n            old_footer = *((ceph_msg_footer_old*)state_buffer);\n            footer.front_crc = old_footer.front_crc;\n            footer.middle_crc = old_footer.middle_crc;\n            footer.data_crc = old_footer.data_crc;\n            footer.sig = 0;\n            footer.flags = old_footer.flags;\n          }\n          int aborted = (footer.flags & CEPH_MSG_FOOTER_COMPLETE) == 0;\n          ldout(async_msgr->cct, 10) << __func__ << \" aborted = \" << aborted << dendl;\n          if (aborted) {\n            ldout(async_msgr->cct, 0) << __func__ << \" got \" << front.length() << \" + \" << middle.length() << \" + \" << data.length()\n                                << \" byte message.. ABORTED\" << dendl;\n            goto fail;\n          }\n\n          ldout(async_msgr->cct, 20) << __func__ << \" got \" << front.length() << \" + \" << middle.length()\n                              << \" + \" << data.length() << \" byte message\" << dendl;\n          Message *message = decode_message(async_msgr->cct, async_msgr->crcflags, current_header, footer,\n                                            front, middle, data, this);\n          if (!message) {\n            ldout(async_msgr->cct, 1) << __func__ << \" decode message failed \" << dendl;\n            goto fail;\n          }\n\n          //\n          //  Check the signature if one should be present.  A zero return indicates success. PLR\n          //\n\n          if (session_security.get() == NULL) {\n            ldout(async_msgr->cct, 10) << __func__ << \" no session security set\" << dendl;\n          } else {\n            if (session_security->check_message_signature(message)) {\n              ldout(async_msgr->cct, 0) << __func__ << \" Signature check failed\" << dendl;\n              message->put();\n              goto fail;\n            }\n          }\n          message->set_byte_throttler(policy.throttler_bytes);\n          message->set_message_throttler(policy.throttler_messages);\n\n          // store reservation size in message, so we don't get confused\n          // by messages entering the dispatch queue through other paths.\n          message->set_dispatch_throttle_size(cur_msg_size);\n\n          message->set_recv_stamp(recv_stamp);\n          message->set_throttle_stamp(throttle_stamp);\n          message->set_recv_complete_stamp(ceph_clock_now());\n\n          // check received seq#.  if it is old, drop the message.  \n          // note that incoming messages may skip ahead.  this is convenient for the client\n          // side queueing because messages can't be renumbered, but the (kernel) client will\n          // occasionally pull a message out of the sent queue to send elsewhere.  in that case\n          // it doesn't matter if we \"got\" it or not.\n          uint64_t cur_seq = in_seq;\n          if (message->get_seq() <= cur_seq) {\n            ldout(async_msgr->cct,0) << __func__ << \" got old message \"\n                    << message->get_seq() << \" <= \" << cur_seq << \" \" << message << \" \" << *message\n                    << \", discarding\" << dendl;\n            message->put();\n            if (has_feature(CEPH_FEATURE_RECONNECT_SEQ) && async_msgr->cct->_conf->ms_die_on_old_message)\n              assert(0 == \"old msgs despite reconnect_seq feature\");\n            break;\n          }\n          if (message->get_seq() > cur_seq + 1) {\n            ldout(async_msgr->cct, 0) << __func__ << \" missed message?  skipped from seq \"\n                                      << cur_seq << \" to \" << message->get_seq() << dendl;\n            if (async_msgr->cct->_conf->ms_die_on_skipped_message)\n              assert(0 == \"skipped incoming seq\");\n          }\n\n          message->set_connection(this);\n\n#if defined(WITH_LTTNG) && defined(WITH_EVENTTRACE)\n          if (message->get_type() == CEPH_MSG_OSD_OP || message->get_type() == CEPH_MSG_OSD_OPREPLY) {\n            utime_t ltt_processed_stamp = ceph_clock_now();\n            double usecs_elapsed = (ltt_processed_stamp.to_nsec()-ltt_recv_stamp.to_nsec())/1000;\n            ostringstream buf;\n            if (message->get_type() == CEPH_MSG_OSD_OP)\n              OID_ELAPSED_WITH_MSG(message, usecs_elapsed, \"TIME_TO_DECODE_OSD_OP\", false);\n            else\n              OID_ELAPSED_WITH_MSG(message, usecs_elapsed, \"TIME_TO_DECODE_OSD_OPREPLY\", false);\n          }\n#endif\n\n          // note last received message.\n          in_seq = message->get_seq();\n\t  ldout(async_msgr->cct, 5) << \" rx \" << message->get_source() << \" seq \"\n                                    << message->get_seq() << \" \" << message\n\t\t\t\t    << \" \" << *message << dendl;\n\n          if (!policy.lossy) {\n            ack_left++;\n            need_dispatch_writer = true;\n          }\n          state = STATE_OPEN;\n\n          logger->inc(l_msgr_recv_messages);\n          logger->inc(l_msgr_recv_bytes, cur_msg_size + sizeof(ceph_msg_header) + sizeof(ceph_msg_footer));\n\n          async_msgr->ms_fast_preprocess(message);\n          auto fast_dispatch_time = ceph::mono_clock::now();\n          logger->tinc(l_msgr_running_recv_time, fast_dispatch_time - recv_start_time);\n          if (delay_state) {\n            utime_t release = message->get_recv_stamp();\n            double delay_period = 0;\n            if (rand() % 10000 < async_msgr->cct->_conf->ms_inject_delay_probability * 10000.0) {\n              delay_period = async_msgr->cct->_conf->ms_inject_delay_max * (double)(rand() % 10000) / 10000.0;\n              release += delay_period;\n              ldout(async_msgr->cct, 1) << \"queue_received will delay until \" << release << \" on \"\n                                        << message << \" \" << *message << dendl;\n            }\n            delay_state->queue(delay_period, release, message);\n          } else if (async_msgr->ms_can_fast_dispatch(message)) {\n            lock.unlock();\n            dispatch_queue->fast_dispatch(message);\n            recv_start_time = ceph::mono_clock::now();\n            logger->tinc(l_msgr_running_fast_dispatch_time,\n                         recv_start_time - fast_dispatch_time);\n            lock.lock();\n          } else {\n            dispatch_queue->enqueue(message, message->get_priority(), conn_id);\n          }\n\n          break;\n        }\n\n      case STATE_OPEN_TAG_CLOSE:\n        {\n          ldout(async_msgr->cct, 20) << __func__ << \" got CLOSE\" << dendl;\n          _stop();\n          return ;\n        }\n\n      case STATE_STANDBY:\n        {\n          ldout(async_msgr->cct, 20) << __func__ << \" enter STANDY\" << dendl;\n\n          break;\n        }\n\n      case STATE_NONE:\n        {\n          ldout(async_msgr->cct, 20) << __func__ << \" enter none state\" << dendl;\n          break;\n        }\n\n      case STATE_CLOSED:\n        {\n          ldout(async_msgr->cct, 20) << __func__ << \" socket closed\" << dendl;\n          break;\n        }\n\n      case STATE_WAIT:\n        {\n          ldout(async_msgr->cct, 1) << __func__ << \" enter wait state, failing\" << dendl;\n          goto fail;\n        }\n\n      default:\n        {\n          if (_process_connection() < 0)\n            goto fail;\n          break;\n        }\n    }\n  } while (prev_state != state);\n\n  if (need_dispatch_writer && is_connected())\n    center->dispatch_event_external(write_handler);\n\n  logger->tinc(l_msgr_running_recv_time, ceph::mono_clock::now() - recv_start_time);\n  return;\n\n fail:\n  fault();\n}\n\nssize_t AsyncConnection::_process_connection()\n{\n  ssize_t r = 0;\n\n  switch(state) {\n    case STATE_WAIT_SEND:\n      {\n        std::lock_guard<std::mutex> l(write_lock);\n        if (!outcoming_bl.length()) {\n          assert(state_after_send);\n          state = state_after_send;\n          state_after_send = STATE_NONE;\n        }\n        break;\n      }\n\n    case STATE_CONNECTING:\n      {\n        assert(!policy.server);\n\n        // reset connect state variables\n        got_bad_auth = false;\n        delete authorizer;\n        authorizer = NULL;\n        authorizer_buf.clear();\n        memset(&connect_msg, 0, sizeof(connect_msg));\n        memset(&connect_reply, 0, sizeof(connect_reply));\n\n        global_seq = async_msgr->get_global_seq();\n        // close old socket.  this is safe because we stopped the reader thread above.\n        if (cs) {\n          center->delete_file_event(cs.fd(), EVENT_READABLE|EVENT_WRITABLE);\n          cs.close();\n        }\n\n        SocketOptions opts;\n        opts.priority = async_msgr->get_socket_priority();\n        opts.connect_bind_addr = msgr->get_myaddr();\n        r = worker->connect(get_peer_addr(), opts, &cs);\n        if (r < 0)\n          goto fail;\n\n        center->create_file_event(cs.fd(), EVENT_READABLE, read_handler);\n        state = STATE_CONNECTING_RE;\n        break;\n      }\n\n    case STATE_CONNECTING_RE:\n      {\n        r = cs.is_connected();\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" reconnect failed \" << dendl;\n          if (r == -ECONNREFUSED) {\n            ldout(async_msgr->cct, 2) << __func__ << \" connection refused!\" << dendl;\n            dispatch_queue->queue_refused(this);\n          }\n          goto fail;\n        } else if (r == 0) {\n          ldout(async_msgr->cct, 10) << __func__ << \" nonblock connect inprogress\" << dendl;\n          if (async_msgr->get_stack()->nonblock_connect_need_writable_event())\n            center->create_file_event(cs.fd(), EVENT_WRITABLE, read_handler);\n          break;\n        }\n\n        center->delete_file_event(cs.fd(), EVENT_WRITABLE);\n        ldout(async_msgr->cct, 10) << __func__ << \" connect successfully, ready to send banner\" << dendl;\n\n        bufferlist bl;\n        bl.append(CEPH_BANNER, strlen(CEPH_BANNER));\n        r = try_send(bl);\n        if (r == 0) {\n          state = STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY;\n          ldout(async_msgr->cct, 10) << __func__ << \" connect write banner done: \"\n                                     << get_peer_addr() << dendl;\n        } else if (r > 0) {\n          state = STATE_WAIT_SEND;\n          state_after_send = STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY;\n          ldout(async_msgr->cct, 10) << __func__ << \" connect wait for write banner: \"\n                               << get_peer_addr() << dendl;\n        } else {\n          goto fail;\n        }\n\n        break;\n      }\n\n    case STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY:\n      {\n        entity_addr_t paddr, peer_addr_for_me;\n        bufferlist myaddrbl;\n        unsigned banner_len = strlen(CEPH_BANNER);\n        unsigned need_len = banner_len + sizeof(ceph_entity_addr)*2;\n        r = read_until(need_len, state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read banner and identify addresses failed\" << dendl;\n          goto fail;\n        } else if (r > 0) {\n          break;\n        }\n\n        if (memcmp(state_buffer, CEPH_BANNER, banner_len)) {\n          ldout(async_msgr->cct, 0) << __func__ << \" connect protocol error (bad banner) on peer \"\n                                    << get_peer_addr() << dendl;\n          goto fail;\n        }\n\n        bufferlist bl;\n        bl.append(state_buffer+banner_len, sizeof(ceph_entity_addr)*2);\n        bufferlist::iterator p = bl.begin();\n        try {\n          ::decode(paddr, p);\n          ::decode(peer_addr_for_me, p);\n        } catch (const buffer::error& e) {\n          lderr(async_msgr->cct) << __func__ <<  \" decode peer addr failed \" << dendl;\n          goto fail;\n        }\n        ldout(async_msgr->cct, 20) << __func__ <<  \" connect read peer addr \"\n                             << paddr << \" on socket \" << cs.fd() << dendl;\n        if (peer_addr != paddr) {\n          if (paddr.is_blank_ip() && peer_addr.get_port() == paddr.get_port() &&\n              peer_addr.get_nonce() == paddr.get_nonce()) {\n            ldout(async_msgr->cct, 0) << __func__ <<  \" connect claims to be \" << paddr\n                                << \" not \" << peer_addr\n                                << \" - presumably this is the same node!\" << dendl;\n          } else {\n            ldout(async_msgr->cct, 10) << __func__ << \" connect claims to be \"\n\t\t\t\t       << paddr << \" not \" << peer_addr << dendl;\n\t    goto fail;\n          }\n        }\n\n        ldout(async_msgr->cct, 20) << __func__ << \" connect peer addr for me is \" << peer_addr_for_me << dendl;\n        lock.unlock();\n        async_msgr->learned_addr(peer_addr_for_me);\n        if (async_msgr->cct->_conf->ms_inject_internal_delays\n            && async_msgr->cct->_conf->ms_inject_socket_failures) {\n          if (rand() % async_msgr->cct->_conf->ms_inject_socket_failures == 0) {\n            ldout(msgr->cct, 10) << __func__ << \" sleep for \"\n                                 << async_msgr->cct->_conf->ms_inject_internal_delays << dendl;\n            utime_t t;\n            t.set_from_double(async_msgr->cct->_conf->ms_inject_internal_delays);\n            t.sleep();\n          }\n        }\n\n        lock.lock();\n        if (state != STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY) {\n          ldout(async_msgr->cct, 1) << __func__ << \" state changed while learned_addr, mark_down or \"\n                                    << \" replacing must be happened just now\" << dendl;\n          return 0;\n        }\n\n        ::encode(async_msgr->get_myaddr(), myaddrbl, 0); // legacy\n        r = try_send(myaddrbl);\n        if (r == 0) {\n          state = STATE_CONNECTING_SEND_CONNECT_MSG;\n          ldout(async_msgr->cct, 10) << __func__ << \" connect sent my addr \"\n              << async_msgr->get_myaddr() << dendl;\n        } else if (r > 0) {\n          state = STATE_WAIT_SEND;\n          state_after_send = STATE_CONNECTING_SEND_CONNECT_MSG;\n          ldout(async_msgr->cct, 10) << __func__ << \" connect send my addr done: \"\n              << async_msgr->get_myaddr() << dendl;\n        } else {\n          ldout(async_msgr->cct, 2) << __func__ << \" connect couldn't write my addr, \"\n              << cpp_strerror(r) << dendl;\n          goto fail;\n        }\n\n        break;\n      }\n\n    case STATE_CONNECTING_SEND_CONNECT_MSG:\n      {\n        if (!authorizer) {\n          authorizer = async_msgr->get_authorizer(peer_type, false);\n        }\n        bufferlist bl;\n\n        connect_msg.features = policy.features_supported;\n        connect_msg.host_type = async_msgr->get_myinst().name.type();\n        connect_msg.global_seq = global_seq;\n        connect_msg.connect_seq = connect_seq;\n        connect_msg.protocol_version = async_msgr->get_proto_version(peer_type, true);\n        connect_msg.authorizer_protocol = authorizer ? authorizer->protocol : 0;\n        connect_msg.authorizer_len = authorizer ? authorizer->bl.length() : 0;\n        if (authorizer)\n          ldout(async_msgr->cct, 10) << __func__ <<  \" connect_msg.authorizer_len=\"\n                                     << connect_msg.authorizer_len << \" protocol=\"\n                                     << connect_msg.authorizer_protocol << dendl;\n        connect_msg.flags = 0;\n        if (policy.lossy)\n          connect_msg.flags |= CEPH_MSG_CONNECT_LOSSY;  // this is fyi, actually, server decides!\n        bl.append((char*)&connect_msg, sizeof(connect_msg));\n        if (authorizer) {\n          bl.append(authorizer->bl.c_str(), authorizer->bl.length());\n        }\n        ldout(async_msgr->cct, 10) << __func__ << \" connect sending gseq=\" << global_seq << \" cseq=\"\n            << connect_seq << \" proto=\" << connect_msg.protocol_version << dendl;\n\n        r = try_send(bl);\n        if (r == 0) {\n          state = STATE_CONNECTING_WAIT_CONNECT_REPLY;\n          ldout(async_msgr->cct,20) << __func__ << \" connect wrote (self +) cseq, waiting for reply\" << dendl;\n        } else if (r > 0) {\n          state = STATE_WAIT_SEND;\n          state_after_send = STATE_CONNECTING_WAIT_CONNECT_REPLY;\n          ldout(async_msgr->cct, 10) << __func__ << \" continue send reply \" << dendl;\n        } else {\n          ldout(async_msgr->cct, 2) << __func__ << \" connect couldn't send reply \"\n              << cpp_strerror(r) << dendl;\n          goto fail;\n        }\n\n        break;\n      }\n\n    case STATE_CONNECTING_WAIT_CONNECT_REPLY:\n      {\n        r = read_until(sizeof(connect_reply), state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read connect reply failed\" << dendl;\n          goto fail;\n        } else if (r > 0) {\n          break;\n        }\n\n        connect_reply = *((ceph_msg_connect_reply*)state_buffer);\n\n        ldout(async_msgr->cct, 20) << __func__ << \" connect got reply tag \" << (int)connect_reply.tag\n                             << \" connect_seq \" << connect_reply.connect_seq << \" global_seq \"\n                             << connect_reply.global_seq << \" proto \" << connect_reply.protocol_version\n                             << \" flags \" << (int)connect_reply.flags << \" features \"\n                             << connect_reply.features << dendl;\n        state = STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH;\n\n        break;\n      }\n\n    case STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH:\n      {\n        bufferlist authorizer_reply;\n        if (connect_reply.authorizer_len) {\n          ldout(async_msgr->cct, 10) << __func__ << \" reply.authorizer_len=\" << connect_reply.authorizer_len << dendl;\n          assert(connect_reply.authorizer_len < 4096);\n          r = read_until(connect_reply.authorizer_len, state_buffer);\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read connect reply authorizer failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n\n          authorizer_reply.append(state_buffer, connect_reply.authorizer_len);\n\n\t  if (connect_reply.tag == CEPH_MSGR_TAG_CHALLENGE_AUTHORIZER) {\n\t    ldout(async_msgr->cct,10) << __func__ << \" connect got auth challenge\" << dendl;\n\t    authorizer->add_challenge(async_msgr->cct, authorizer_reply);\n\t    state = STATE_CONNECTING_SEND_CONNECT_MSG;\n\t    break;\n\t  }\n\n          auto iter = authorizer_reply.begin();\n          if (authorizer && !authorizer->verify_reply(iter)) {\n            ldout(async_msgr->cct, 0) << __func__ << \" failed verifying authorize reply\" << dendl;\n            goto fail;\n          }\n        }\n        r = handle_connect_reply(connect_msg, connect_reply);\n        if (r < 0)\n          goto fail;\n\n        // state must be changed!\n        assert(state != STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH);\n        break;\n      }\n\n    case STATE_CONNECTING_WAIT_ACK_SEQ:\n      {\n        uint64_t newly_acked_seq = 0;\n\n        r = read_until(sizeof(newly_acked_seq), state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read connect ack seq failed\" << dendl;\n          goto fail;\n        } else if (r > 0) {\n          break;\n        }\n\n        newly_acked_seq = *((uint64_t*)state_buffer);\n        ldout(async_msgr->cct, 2) << __func__ << \" got newly_acked_seq \" << newly_acked_seq\n                            << \" vs out_seq \" << out_seq << dendl;\n        discard_requeued_up_to(newly_acked_seq);\n        //while (newly_acked_seq > out_seq.read()) {\n        //  Message *m = _get_next_outgoing(NULL);\n        //  assert(m);\n        //  ldout(async_msgr->cct, 2) << __func__ << \" discarding previously sent \" << m->get_seq()\n        //                      << \" \" << *m << dendl;\n        //  assert(m->get_seq() <= newly_acked_seq);\n        //  m->put();\n        //  out_seq.inc();\n        //}\n\n        bufferlist bl;\n        uint64_t s = in_seq;\n        bl.append((char*)&s, sizeof(s));\n        r = try_send(bl);\n        if (r == 0) {\n          state = STATE_CONNECTING_READY;\n          ldout(async_msgr->cct, 10) << __func__ << \" send in_seq done \" << dendl;\n        } else if (r > 0) {\n          state_after_send = STATE_CONNECTING_READY;\n          state = STATE_WAIT_SEND;\n          ldout(async_msgr->cct, 10) << __func__ << \" continue send in_seq \" << dendl;\n        } else {\n          goto fail;\n        }\n        break;\n      }\n\n    case STATE_CONNECTING_READY:\n      {\n        // hooray!\n        peer_global_seq = connect_reply.global_seq;\n        policy.lossy = connect_reply.flags & CEPH_MSG_CONNECT_LOSSY;\n        state = STATE_OPEN;\n        once_ready = true;\n        connect_seq += 1;\n        assert(connect_seq == connect_reply.connect_seq);\n        backoff = utime_t();\n        set_features((uint64_t)connect_reply.features & (uint64_t)connect_msg.features);\n        ldout(async_msgr->cct, 10) << __func__ << \" connect success \" << connect_seq\n                                   << \", lossy = \" << policy.lossy << \", features \"\n                                   << get_features() << dendl;\n\n        // If we have an authorizer, get a new AuthSessionHandler to deal with ongoing security of the\n        // connection.  PLR\n        if (authorizer != NULL) {\n          session_security.reset(\n              get_auth_session_handler(async_msgr->cct,\n                                       authorizer->protocol,\n                                       authorizer->session_key,\n                                       get_features()));\n        } else {\n          // We have no authorizer, so we shouldn't be applying security to messages in this AsyncConnection.  PLR\n          session_security.reset();\n        }\n\n        if (delay_state)\n          assert(delay_state->ready());\n        dispatch_queue->queue_connect(this);\n        async_msgr->ms_deliver_handle_fast_connect(this);\n\n        // make sure no pending tick timer\n        if (last_tick_id)\n          center->delete_time_event(last_tick_id);\n        last_tick_id = center->create_time_event(inactive_timeout_us, tick_handler);\n\n        // message may in queue between last _try_send and connection ready\n        // write event may already notify and we need to force scheduler again\n        write_lock.lock();\n        can_write = WriteStatus::CANWRITE;\n        if (is_queued())\n          center->dispatch_event_external(write_handler);\n        write_lock.unlock();\n        maybe_start_delay_thread();\n        break;\n      }\n\n    case STATE_ACCEPTING:\n      {\n        bufferlist bl;\n        center->create_file_event(cs.fd(), EVENT_READABLE, read_handler);\n\n        bl.append(CEPH_BANNER, strlen(CEPH_BANNER));\n\n        ::encode(async_msgr->get_myaddr(), bl, 0); // legacy\n        port = async_msgr->get_myaddr().get_port();\n        ::encode(socket_addr, bl, 0); // legacy\n        ldout(async_msgr->cct, 1) << __func__ << \" sd=\" << cs.fd() << \" \" << socket_addr << dendl;\n\n        r = try_send(bl);\n        if (r == 0) {\n          state = STATE_ACCEPTING_WAIT_BANNER_ADDR;\n          ldout(async_msgr->cct, 10) << __func__ << \" write banner and addr done: \"\n            << get_peer_addr() << dendl;\n        } else if (r > 0) {\n          state = STATE_WAIT_SEND;\n          state_after_send = STATE_ACCEPTING_WAIT_BANNER_ADDR;\n          ldout(async_msgr->cct, 10) << __func__ << \" wait for write banner and addr: \"\n                              << get_peer_addr() << dendl;\n        } else {\n          goto fail;\n        }\n\n        break;\n      }\n    case STATE_ACCEPTING_WAIT_BANNER_ADDR:\n      {\n        bufferlist addr_bl;\n        entity_addr_t peer_addr;\n\n        r = read_until(strlen(CEPH_BANNER) + sizeof(ceph_entity_addr), state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read peer banner and addr failed\" << dendl;\n          goto fail;\n        } else if (r > 0) {\n          break;\n        }\n\n        if (memcmp(state_buffer, CEPH_BANNER, strlen(CEPH_BANNER))) {\n          ldout(async_msgr->cct, 1) << __func__ << \" accept peer sent bad banner '\" << state_buffer\n                                    << \"' (should be '\" << CEPH_BANNER << \"')\" << dendl;\n          goto fail;\n        }\n\n        addr_bl.append(state_buffer+strlen(CEPH_BANNER), sizeof(ceph_entity_addr));\n        {\n          bufferlist::iterator ti = addr_bl.begin();\n          ::decode(peer_addr, ti);\n        }\n\n        ldout(async_msgr->cct, 10) << __func__ << \" accept peer addr is \" << peer_addr << dendl;\n        if (peer_addr.is_blank_ip()) {\n          // peer apparently doesn't know what ip they have; figure it out for them.\n          int port = peer_addr.get_port();\n          peer_addr.u = socket_addr.u;\n          peer_addr.set_port(port);\n          ldout(async_msgr->cct, 0) << __func__ << \" accept peer addr is really \" << peer_addr\n                             << \" (socket is \" << socket_addr << \")\" << dendl;\n        }\n        set_peer_addr(peer_addr);  // so that connection_state gets set up\n        state = STATE_ACCEPTING_WAIT_CONNECT_MSG;\n        break;\n      }\n\n    case STATE_ACCEPTING_WAIT_CONNECT_MSG:\n      {\n        r = read_until(sizeof(connect_msg), state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read connect msg failed\" << dendl;\n          goto fail;\n        } else if (r > 0) {\n          break;\n        }\n\n        connect_msg = *((ceph_msg_connect*)state_buffer);\n        state = STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH;\n        break;\n      }\n\n    case STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH:\n      {\n        bufferlist authorizer_reply;\n\n        if (connect_msg.authorizer_len) {\n          if (!authorizer_buf.length())\n            authorizer_buf.push_back(buffer::create(connect_msg.authorizer_len));\n\n          r = read_until(connect_msg.authorizer_len, authorizer_buf.c_str());\n          if (r < 0) {\n            ldout(async_msgr->cct, 1) << __func__ << \" read connect authorizer failed\" << dendl;\n            goto fail;\n          } else if (r > 0) {\n            break;\n          }\n        }\n\n        ldout(async_msgr->cct, 20) << __func__ << \" accept got peer connect_seq \"\n                             << connect_msg.connect_seq << \" global_seq \"\n                             << connect_msg.global_seq << dendl;\n        set_peer_type(connect_msg.host_type);\n        policy = async_msgr->get_policy(connect_msg.host_type);\n        ldout(async_msgr->cct, 10) << __func__ << \" accept of host_type \" << connect_msg.host_type\n                                   << \", policy.lossy=\" << policy.lossy << \" policy.server=\"\n                                   << policy.server << \" policy.standby=\" << policy.standby\n                                   << \" policy.resetcheck=\" << policy.resetcheck << dendl;\n\n        r = handle_connect_msg(connect_msg, authorizer_buf, authorizer_reply);\n        if (r < 0)\n          goto fail;\n\n        // state is changed by \"handle_connect_msg\"\n        assert(state != STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH);\n        break;\n      }\n\n    case STATE_ACCEPTING_WAIT_SEQ:\n      {\n        uint64_t newly_acked_seq;\n        r = read_until(sizeof(newly_acked_seq), state_buffer);\n        if (r < 0) {\n          ldout(async_msgr->cct, 1) << __func__ << \" read ack seq failed\" << dendl;\n          goto fail_registered;\n        } else if (r > 0) {\n          break;\n        }\n\n        newly_acked_seq = *((uint64_t*)state_buffer);\n        ldout(async_msgr->cct, 2) << __func__ << \" accept get newly_acked_seq \" << newly_acked_seq << dendl;\n        discard_requeued_up_to(newly_acked_seq);\n        state = STATE_ACCEPTING_READY;\n        break;\n      }\n\n    case STATE_ACCEPTING_READY:\n      {\n        ldout(async_msgr->cct, 20) << __func__ << \" accept done\" << dendl;\n        state = STATE_OPEN;\n        memset(&connect_msg, 0, sizeof(connect_msg));\n\n        if (delay_state)\n          assert(delay_state->ready());\n        // make sure no pending tick timer\n        if (last_tick_id)\n          center->delete_time_event(last_tick_id);\n        last_tick_id = center->create_time_event(inactive_timeout_us, tick_handler);\n\n        write_lock.lock();\n        can_write = WriteStatus::CANWRITE;\n        if (is_queued())\n          center->dispatch_event_external(write_handler);\n        write_lock.unlock();\n        maybe_start_delay_thread();\n        break;\n      }\n\n    default:\n      {\n        lderr(async_msgr->cct) << __func__ << \" bad state: \" << state << dendl;\n        ceph_abort();\n      }\n  }\n\n  return 0;\n\nfail_registered:\n  ldout(async_msgr->cct, 10) << \"accept fault after register\" << dendl;\n  inject_delay();\n\nfail:\n  return -1;\n}\n\nint AsyncConnection::handle_connect_reply(ceph_msg_connect &connect, ceph_msg_connect_reply &reply)\n{\n  uint64_t feat_missing;\n  if (reply.tag == CEPH_MSGR_TAG_FEATURES) {\n    ldout(async_msgr->cct, 0) << __func__ << \" connect protocol feature mismatch, my \"\n                        << std::hex << connect.features << \" < peer \"\n                        << reply.features << \" missing \"\n                        << (reply.features & ~policy.features_supported)\n                        << std::dec << dendl;\n    goto fail;\n  }\n\n  if (reply.tag == CEPH_MSGR_TAG_BADPROTOVER) {\n    ldout(async_msgr->cct, 0) << __func__ << \" connect protocol version mismatch, my \"\n                        << connect.protocol_version << \" != \" << reply.protocol_version\n                        << dendl;\n    goto fail;\n  }\n\n  if (reply.tag == CEPH_MSGR_TAG_BADAUTHORIZER) {\n    ldout(async_msgr->cct,0) << __func__ << \" connect got BADAUTHORIZER\" << dendl;\n    if (got_bad_auth)\n      goto fail;\n    got_bad_auth = true;\n    delete authorizer;\n    authorizer = async_msgr->get_authorizer(peer_type, true);  // try harder\n    state = STATE_CONNECTING_SEND_CONNECT_MSG;\n  }\n  if (reply.tag == CEPH_MSGR_TAG_RESETSESSION) {\n    ldout(async_msgr->cct, 0) << __func__ << \" connect got RESETSESSION\" << dendl;\n    was_session_reset();\n    // see was_session_reset\n    outcoming_bl.clear();\n    state = STATE_CONNECTING_SEND_CONNECT_MSG;\n  }\n  if (reply.tag == CEPH_MSGR_TAG_RETRY_GLOBAL) {\n    global_seq = async_msgr->get_global_seq(reply.global_seq);\n    ldout(async_msgr->cct, 5) << __func__ << \" connect got RETRY_GLOBAL \"\n                              << reply.global_seq << \" chose new \"\n                              << global_seq << dendl;\n    state = STATE_CONNECTING_SEND_CONNECT_MSG;\n  }\n  if (reply.tag == CEPH_MSGR_TAG_RETRY_SESSION) {\n    assert(reply.connect_seq > connect_seq);\n    ldout(async_msgr->cct, 5) << __func__ << \" connect got RETRY_SESSION \"\n                              << connect_seq << \" -> \"\n                              << reply.connect_seq << dendl;\n    connect_seq = reply.connect_seq;\n    state = STATE_CONNECTING_SEND_CONNECT_MSG;\n  }\n  if (reply.tag == CEPH_MSGR_TAG_WAIT) {\n    ldout(async_msgr->cct, 1) << __func__ << \" connect got WAIT (connection race)\" << dendl;\n    state = STATE_WAIT;\n  }\n\n  feat_missing = policy.features_required & ~(uint64_t)connect_reply.features;\n  if (feat_missing) {\n    ldout(async_msgr->cct, 1) << __func__ << \" missing required features \" << std::hex\n                              << feat_missing << std::dec << dendl;\n    goto fail;\n  }\n\n  if (reply.tag == CEPH_MSGR_TAG_SEQ) {\n    ldout(async_msgr->cct, 10) << __func__ << \" got CEPH_MSGR_TAG_SEQ, reading acked_seq and writing in_seq\" << dendl;\n    state = STATE_CONNECTING_WAIT_ACK_SEQ;\n  }\n  if (reply.tag == CEPH_MSGR_TAG_READY) {\n    ldout(async_msgr->cct, 10) << __func__ << \" got CEPH_MSGR_TAG_READY \" << dendl;\n    state = STATE_CONNECTING_READY;\n  }\n\n  return 0;\n\n fail:\n  return -1;\n}\n\nssize_t AsyncConnection::handle_connect_msg(ceph_msg_connect &connect, bufferlist &authorizer_bl,\n                                            bufferlist &authorizer_reply)\n{\n  ssize_t r = 0;\n  ceph_msg_connect_reply reply;\n  bufferlist reply_bl;\n\n  memset(&reply, 0, sizeof(reply));\n  reply.protocol_version = async_msgr->get_proto_version(peer_type, false);\n\n  // mismatch?\n  ldout(async_msgr->cct, 10) << __func__ << \" accept my proto \" << reply.protocol_version\n                      << \", their proto \" << connect.protocol_version << dendl;\n  if (connect.protocol_version != reply.protocol_version) {\n    return _reply_accept(CEPH_MSGR_TAG_BADPROTOVER, connect, reply, authorizer_reply);\n  }\n  // require signatures for cephx?\n  if (connect.authorizer_protocol == CEPH_AUTH_CEPHX) {\n    if (peer_type == CEPH_ENTITY_TYPE_OSD ||\n        peer_type == CEPH_ENTITY_TYPE_MDS ||\n\tpeer_type == CEPH_ENTITY_TYPE_MGR) {\n      if (async_msgr->cct->_conf->cephx_require_signatures ||\n          async_msgr->cct->_conf->cephx_cluster_require_signatures) {\n        ldout(async_msgr->cct, 10) << __func__ << \" using cephx, requiring MSG_AUTH feature bit for cluster\" << dendl;\n        policy.features_required |= CEPH_FEATURE_MSG_AUTH;\n      }\n      if (async_msgr->cct->_conf->cephx_require_version >= 2 ||\n\t  async_msgr->cct->_conf->cephx_cluster_require_version >= 2) {\n        ldout(async_msgr->cct, 10) << __func__ << \" using cephx, requiring cephx v2 feature bit for cluster\" << dendl;\n        policy.features_required |= CEPH_FEATUREMASK_CEPHX_V2;\n      }\n    } else {\n      if (async_msgr->cct->_conf->cephx_require_signatures ||\n          async_msgr->cct->_conf->cephx_service_require_signatures) {\n        ldout(async_msgr->cct, 10) << __func__ << \" using cephx, requiring MSG_AUTH feature bit for service\" << dendl;\n        policy.features_required |= CEPH_FEATURE_MSG_AUTH;\n      }\n      if (async_msgr->cct->_conf->cephx_require_version >= 2 ||\n\t  async_msgr->cct->_conf->cephx_service_require_version >= 2) {\n        ldout(async_msgr->cct, 10) << __func__ << \" using cephx, requiring cephx v2 feature bit for service\" << dendl;\n        policy.features_required |= CEPH_FEATUREMASK_CEPHX_V2;\n      }\n    }\n  }\n\n  uint64_t feat_missing = policy.features_required & ~(uint64_t)connect.features;\n  if (feat_missing) {\n    ldout(async_msgr->cct, 1) << __func__ << \" peer missing required features \"\n                        << std::hex << feat_missing << std::dec << dendl;\n    return _reply_accept(CEPH_MSGR_TAG_FEATURES, connect, reply, authorizer_reply);\n  }\n\n  lock.unlock();\n\n  bool authorizer_valid;\n  bool need_challenge = HAVE_FEATURE(connect.features, CEPHX_V2);\n  bool had_challenge = (bool)authorizer_challenge;\n  if (!async_msgr->verify_authorizer(\n\tthis, peer_type, connect.authorizer_protocol, authorizer_bl,\n\tauthorizer_reply, authorizer_valid, session_key,\n\tneed_challenge ? &authorizer_challenge : nullptr) ||\n      !authorizer_valid) {\n    lock.lock();\n    char tag;\n    if (need_challenge && !had_challenge && authorizer_challenge) {\n      ldout(async_msgr->cct,0) << __func__ << \": challenging authorizer\"\n\t\t\t       << dendl;\n      assert(authorizer_reply.length());\n      tag = CEPH_MSGR_TAG_CHALLENGE_AUTHORIZER;\n    } else {\n      ldout(async_msgr->cct,0) << __func__ << \": got bad authorizer\" << dendl;\n      tag = CEPH_MSGR_TAG_BADAUTHORIZER;\n    }\n    session_security.reset();\n    return _reply_accept(tag, connect, reply, authorizer_reply);\n  }\n\n  // We've verified the authorizer for this AsyncConnection, so set up the session security structure.  PLR\n  ldout(async_msgr->cct, 10) << __func__ << \" accept setting up session_security.\" << dendl;\n\n  // existing?\n  AsyncConnectionRef existing = async_msgr->lookup_conn(peer_addr);\n\n  inject_delay();\n\n  lock.lock();\n  if (state != STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH) {\n    ldout(async_msgr->cct, 1) << __func__ << \" state changed while accept, it must be mark_down\" << dendl;\n    assert(state == STATE_CLOSED);\n    goto fail;\n  }\n\n  if (existing == this)\n    existing = NULL;\n  if (existing) {\n    // There is no possible that existing connection will acquire this\n    // connection's lock\n    existing->lock.lock();  // skip lockdep check (we are locking a second AsyncConnection here)\n\n    if (existing->state == STATE_CLOSED) {\n      ldout(async_msgr->cct, 1) << __func__ << \" existing already closed.\" << dendl;\n      existing->lock.unlock();\n      existing = NULL;\n      goto open;\n    }\n\n    if (existing->replacing) {\n      ldout(async_msgr->cct, 1) << __func__ << \" existing racing replace happened while replacing.\"\n                                << \" existing_state=\" << get_state_name(existing->state) << dendl;\n      reply.global_seq = existing->peer_global_seq;\n      r = _reply_accept(CEPH_MSGR_TAG_RETRY_GLOBAL, connect, reply, authorizer_reply);\n      existing->lock.unlock();\n      if (r < 0)\n        goto fail;\n      return 0;\n    }\n\n    if (connect.global_seq < existing->peer_global_seq) {\n      ldout(async_msgr->cct, 10) << __func__ << \" accept existing \" << existing\n                           << \".gseq \" << existing->peer_global_seq << \" > \"\n                           << connect.global_seq << \", RETRY_GLOBAL\" << dendl;\n      reply.global_seq = existing->peer_global_seq;  // so we can send it below..\n      existing->lock.unlock();\n      return _reply_accept(CEPH_MSGR_TAG_RETRY_GLOBAL, connect, reply, authorizer_reply);\n    } else {\n      ldout(async_msgr->cct, 10) << __func__ << \" accept existing \" << existing\n                           << \".gseq \" << existing->peer_global_seq\n                           << \" <= \" << connect.global_seq << \", looks ok\" << dendl;\n    }\n\n    if (existing->policy.lossy) {\n      ldout(async_msgr->cct, 0) << __func__ << \" accept replacing existing (lossy) channel (new one lossy=\"\n                          << policy.lossy << \")\" << dendl;\n      existing->was_session_reset();\n      goto replace;\n    }\n\n    ldout(async_msgr->cct, 0) << __func__ << \" accept connect_seq \" << connect.connect_seq\n                              << \" vs existing csq=\" << existing->connect_seq << \" existing_state=\"\n                              << get_state_name(existing->state) << dendl;\n\n    if (connect.connect_seq == 0 && existing->connect_seq > 0) {\n      ldout(async_msgr->cct,0) << __func__ << \" accept peer reset, then tried to connect to us, replacing\" << dendl;\n      // this is a hard reset from peer\n      is_reset_from_peer = true;\n      if (policy.resetcheck)\n        existing->was_session_reset(); // this resets out_queue, msg_ and connect_seq #'s\n      goto replace;\n    }\n\n    if (connect.connect_seq < existing->connect_seq) {\n      // old attempt, or we sent READY but they didn't get it.\n      ldout(async_msgr->cct, 10) << __func__ << \" accept existing \" << existing << \".cseq \"\n                           << existing->connect_seq << \" > \" << connect.connect_seq\n                           << \", RETRY_SESSION\" << dendl;\n      reply.connect_seq = existing->connect_seq + 1;\n      existing->lock.unlock();\n      return _reply_accept(CEPH_MSGR_TAG_RETRY_SESSION, connect, reply, authorizer_reply);\n    }\n\n    if (connect.connect_seq == existing->connect_seq) {\n      // if the existing connection successfully opened, and/or\n      // subsequently went to standby, then the peer should bump\n      // their connect_seq and retry: this is not a connection race\n      // we need to resolve here.\n      if (existing->state == STATE_OPEN ||\n          existing->state == STATE_STANDBY) {\n        ldout(async_msgr->cct, 10) << __func__ << \" accept connection race, existing \" << existing\n                             << \".cseq \" << existing->connect_seq << \" == \"\n                             << connect.connect_seq << \", OPEN|STANDBY, RETRY_SESSION\" << dendl;\n        reply.connect_seq = existing->connect_seq + 1;\n        existing->lock.unlock();\n        return _reply_accept(CEPH_MSGR_TAG_RETRY_SESSION, connect, reply, authorizer_reply);\n      }\n\n      // connection race?\n      if (peer_addr < async_msgr->get_myaddr() || existing->policy.server) {\n        // incoming wins\n        ldout(async_msgr->cct, 10) << __func__ << \" accept connection race, existing \" << existing\n                             << \".cseq \" << existing->connect_seq << \" == \" << connect.connect_seq\n                             << \", or we are server, replacing my attempt\" << dendl;\n        goto replace;\n      } else {\n        // our existing outgoing wins\n        ldout(async_msgr->cct,10) << __func__ << \" accept connection race, existing \"\n                            << existing << \".cseq \" << existing->connect_seq\n                            << \" == \" << connect.connect_seq << \", sending WAIT\" << dendl;\n        assert(peer_addr > async_msgr->get_myaddr());\n        existing->lock.unlock();\n        return _reply_accept(CEPH_MSGR_TAG_WAIT, connect, reply, authorizer_reply);\n      }\n    }\n\n    assert(connect.connect_seq > existing->connect_seq);\n    assert(connect.global_seq >= existing->peer_global_seq);\n    if (policy.resetcheck &&   // RESETSESSION only used by servers; peers do not reset each other\n        existing->connect_seq == 0) {\n      ldout(async_msgr->cct, 0) << __func__ << \" accept we reset (peer sent cseq \"\n                          << connect.connect_seq << \", \" << existing << \".cseq = \"\n                          << existing->connect_seq << \"), sending RESETSESSION\" << dendl;\n      existing->lock.unlock();\n      return _reply_accept(CEPH_MSGR_TAG_RESETSESSION, connect, reply, authorizer_reply);\n    }\n\n    // reconnect\n    ldout(async_msgr->cct, 10) << __func__ << \" accept peer sent cseq \" << connect.connect_seq\n                         << \" > \" << existing->connect_seq << dendl;\n    goto replace;\n  } // existing\n  else if (!replacing && connect.connect_seq > 0) {\n    // we reset, and they are opening a new session\n    ldout(async_msgr->cct, 0) << __func__ << \" accept we reset (peer sent cseq \"\n                        << connect.connect_seq << \"), sending RESETSESSION\" << dendl;\n    return _reply_accept(CEPH_MSGR_TAG_RESETSESSION, connect, reply, authorizer_reply);\n  } else {\n    // new session\n    ldout(async_msgr->cct, 10) << __func__ << \" accept new session\" << dendl;\n    existing = NULL;\n    goto open;\n  }\n  ceph_abort();\n\n replace:\n  ldout(async_msgr->cct, 10) << __func__ << \" accept replacing \" << existing << dendl;\n\n  inject_delay();\n  if (existing->policy.lossy) {\n    // disconnect from the Connection\n    ldout(async_msgr->cct, 1) << __func__ << \" replacing on lossy channel, failing existing\" << dendl;\n    existing->_stop();\n    existing->dispatch_queue->queue_reset(existing.get());\n  } else {\n    assert(can_write == WriteStatus::NOWRITE);\n    existing->write_lock.lock();\n\n    // reset the in_seq if this is a hard reset from peer,\n    // otherwise we respect our original connection's value\n    if (is_reset_from_peer) {\n      existing->is_reset_from_peer = true;\n    }\n\n    center->delete_file_event(cs.fd(), EVENT_READABLE|EVENT_WRITABLE);\n\n    if (existing->delay_state) {\n      existing->delay_state->flush();\n      assert(!delay_state);\n    }\n    existing->reset_recv_state();\n\n    auto temp_cs = std::move(cs);\n    EventCenter *new_center = center;\n    Worker *new_worker = worker;\n    // avoid _stop shutdown replacing socket\n    // queue a reset on the new connection, which we're dumping for the old\n    _stop();\n\n    dispatch_queue->queue_reset(this);\n    ldout(async_msgr->cct, 1) << __func__ << \" stop myself to swap existing\" << dendl;\n    existing->can_write = WriteStatus::REPLACING;\n    existing->replacing = true;\n    existing->state_offset = 0;\n    // avoid previous thread modify event\n    existing->state = STATE_NONE;\n    // Discard existing prefetch buffer in `recv_buf`\n    existing->recv_start = existing->recv_end = 0;\n    // there shouldn't exist any buffer\n    assert(recv_start == recv_end);\n\n    existing->authorizer_challenge.reset();\n\n    auto deactivate_existing = std::bind(\n        [existing, new_worker, new_center, connect, reply, authorizer_reply](ConnectedSocket &cs) mutable {\n      // we need to delete time event in original thread\n      {\n        std::lock_guard<std::mutex> l(existing->lock);\n        existing->write_lock.lock();\n        existing->requeue_sent();\n        existing->outcoming_bl.clear();\n        existing->open_write = false;\n        existing->write_lock.unlock();\n        if (existing->state == STATE_NONE) {\n          existing->shutdown_socket();\n          existing->cs = std::move(cs);\n          existing->worker->references--;\n          new_worker->references++;\n          existing->logger = new_worker->get_perf_counter();\n          existing->worker = new_worker;\n          existing->center = new_center;\n          if (existing->delay_state)\n            existing->delay_state->set_center(new_center);\n        } else if (existing->state == STATE_CLOSED) {\n          auto back_to_close = std::bind(\n            [](ConnectedSocket &cs) mutable { cs.close(); }, std::move(cs));\n          new_center->submit_to(\n              new_center->get_id(), std::move(back_to_close), true);\n          return ;\n        } else {\n          ceph_abort();\n        }\n      }\n\n      // Before changing existing->center, it may already exists some events in existing->center's queue.\n      // Then if we mark down `existing`, it will execute in another thread and clean up connection.\n      // Previous event will result in segment fault\n      auto transfer_existing = [existing, connect, reply, authorizer_reply]() mutable {\n        std::lock_guard<std::mutex> l(existing->lock);\n        if (existing->state == STATE_CLOSED)\n          return ;\n        assert(existing->state == STATE_NONE);\n  \n        existing->state = STATE_ACCEPTING_WAIT_CONNECT_MSG;\n        existing->center->create_file_event(existing->cs.fd(), EVENT_READABLE, existing->read_handler);\n        reply.global_seq = existing->peer_global_seq;\n        if (existing->_reply_accept(CEPH_MSGR_TAG_RETRY_GLOBAL, connect, reply, authorizer_reply) < 0) {\n          // handle error\n          existing->fault();\n        }\n      };\n      if (existing->center->in_thread())\n        transfer_existing();\n      else\n        existing->center->submit_to(\n            existing->center->get_id(), std::move(transfer_existing), true);\n    }, std::move(temp_cs));\n\n    existing->center->submit_to(\n        existing->center->get_id(), std::move(deactivate_existing), true);\n    existing->write_lock.unlock();\n    existing->lock.unlock();\n    return 0;\n  }\n  existing->lock.unlock();\n\n open:\n  connect_seq = connect.connect_seq + 1;\n  peer_global_seq = connect.global_seq;\n  ldout(async_msgr->cct, 10) << __func__ << \" accept success, connect_seq = \"\n                             << connect_seq << \" in_seq=\" << in_seq << \", sending READY\" << dendl;\n\n  int next_state;\n\n  // if it is a hard reset from peer, we don't need a round-trip to negotiate in/out sequence\n  if ((connect.features & CEPH_FEATURE_RECONNECT_SEQ) && !is_reset_from_peer) {\n    reply.tag = CEPH_MSGR_TAG_SEQ;\n    next_state = STATE_ACCEPTING_WAIT_SEQ;\n  } else {\n    reply.tag = CEPH_MSGR_TAG_READY;\n    next_state = STATE_ACCEPTING_READY;\n    discard_requeued_up_to(0);\n    is_reset_from_peer = false;\n    in_seq = 0;\n  }\n\n  // send READY reply\n  reply.features = policy.features_supported;\n  reply.global_seq = async_msgr->get_global_seq();\n  reply.connect_seq = connect_seq;\n  reply.flags = 0;\n  reply.authorizer_len = authorizer_reply.length();\n  if (policy.lossy)\n    reply.flags = reply.flags | CEPH_MSG_CONNECT_LOSSY;\n\n  set_features((uint64_t)reply.features & (uint64_t)connect.features);\n  ldout(async_msgr->cct, 10) << __func__ << \" accept features \" << get_features() << dendl;\n\n  session_security.reset(\n      get_auth_session_handler(async_msgr->cct, connect.authorizer_protocol,\n                               session_key, get_features()));\n\n  reply_bl.append((char*)&reply, sizeof(reply));\n\n  if (reply.authorizer_len)\n    reply_bl.append(authorizer_reply.c_str(), authorizer_reply.length());\n\n  if (reply.tag == CEPH_MSGR_TAG_SEQ) {\n    uint64_t s = in_seq;\n    reply_bl.append((char*)&s, sizeof(s));\n  }\n\n  lock.unlock();\n  // Because \"replacing\" will prevent other connections preempt this addr,\n  // it's safe that here we don't acquire Connection's lock\n  r = async_msgr->accept_conn(this);\n\n  inject_delay();\n  \n  lock.lock();\n  replacing = false;\n  if (r < 0) {\n    ldout(async_msgr->cct, 1) << __func__ << \" existing race replacing process for addr=\" << peer_addr\n                              << \" just fail later one(this)\" << dendl;\n    goto fail_registered;\n  }\n  if (state != STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH) {\n    ldout(async_msgr->cct, 1) << __func__ << \" state changed while accept_conn, it must be mark_down\" << dendl;\n    assert(state == STATE_CLOSED || state == STATE_NONE);\n    goto fail_registered;\n  }\n\n  r = try_send(reply_bl);\n  if (r < 0)\n    goto fail_registered;\n\n  // notify\n  dispatch_queue->queue_accept(this);\n  async_msgr->ms_deliver_handle_fast_accept(this);\n  once_ready = true;\n\n  if (r == 0) {\n    state = next_state;\n    ldout(async_msgr->cct, 2) << __func__ << \" accept write reply msg done\" << dendl;\n  } else {\n    state = STATE_WAIT_SEND;\n    state_after_send = next_state;\n  }\n\n  return 0;\n\n fail_registered:\n  ldout(async_msgr->cct, 10) << __func__ << \" accept fault after register\" << dendl;\n  inject_delay();\n\n fail:\n  ldout(async_msgr->cct, 10) << __func__ << \" failed to accept.\" << dendl;\n  return -1;\n}\n\nvoid AsyncConnection::_connect()\n{\n  ldout(async_msgr->cct, 10) << __func__ << \" csq=\" << connect_seq << dendl;\n\n  state = STATE_CONNECTING;\n  // rescheduler connection in order to avoid lock dep\n  // may called by external thread(send_message)\n  center->dispatch_event_external(read_handler);\n}\n\nvoid AsyncConnection::accept(ConnectedSocket socket, entity_addr_t &addr)\n{\n  ldout(async_msgr->cct, 10) << __func__ << \" sd=\" << socket.fd() << dendl;\n  assert(socket.fd() >= 0);\n\n  std::lock_guard<std::mutex> l(lock);\n  cs = std::move(socket);\n  socket_addr = addr;\n  state = STATE_ACCEPTING;\n  // rescheduler connection in order to avoid lock dep\n  center->dispatch_event_external(read_handler);\n}\n\nint AsyncConnection::send_message(Message *m)\n{\n  FUNCTRACE();\n  lgeneric_subdout(async_msgr->cct, ms,\n\t\t   1) << \"-- \" << async_msgr->get_myaddr() << \" --> \"\n\t\t      << get_peer_addr() << \" -- \"\n\t\t      << *m << \" -- \" << m << \" con \"\n\t\t      << m->get_connection().get()\n\t\t      << dendl;\n\n  // optimistic think it's ok to encode(actually may broken now)\n  if (!m->get_priority())\n    m->set_priority(async_msgr->get_default_send_priority());\n\n  m->get_header().src = async_msgr->get_myname();\n  m->set_connection(this);\n\n  if (m->get_type() == CEPH_MSG_OSD_OP)\n    OID_EVENT_TRACE_WITH_MSG(m, \"SEND_MSG_OSD_OP_BEGIN\", true);\n  else if (m->get_type() == CEPH_MSG_OSD_OPREPLY)\n    OID_EVENT_TRACE_WITH_MSG(m, \"SEND_MSG_OSD_OPREPLY_BEGIN\", true);\n\n  if (async_msgr->get_myaddr() == get_peer_addr()) { //loopback connection\n    ldout(async_msgr->cct, 20) << __func__ << \" \" << *m << \" local\" << dendl;\n    std::lock_guard<std::mutex> l(write_lock);\n    if (can_write != WriteStatus::CLOSED) {\n      dispatch_queue->local_delivery(m, m->get_priority());\n    } else {\n      ldout(async_msgr->cct, 10) << __func__ << \" loopback connection closed.\"\n                                 << \" Drop message \" << m << dendl;\n      m->put();\n    }\n    return 0;\n  }\n\n  last_active = ceph::coarse_mono_clock::now();\n  // we don't want to consider local message here, it's too lightweight which\n  // may disturb users\n  logger->inc(l_msgr_send_messages);\n\n  bufferlist bl;\n  uint64_t f = get_features();\n\n  // TODO: Currently not all messages supports reencode like MOSDMap, so here\n  // only let fast dispatch support messages prepare message\n  bool can_fast_prepare = async_msgr->ms_can_fast_dispatch(m);\n  if (can_fast_prepare)\n    prepare_send_message(f, m, bl);\n\n  std::lock_guard<std::mutex> l(write_lock);\n  // \"features\" changes will change the payload encoding\n  if (can_fast_prepare && (can_write == WriteStatus::NOWRITE || get_features() != f)) {\n    // ensure the correctness of message encoding\n    bl.clear();\n    m->get_payload().clear();\n    ldout(async_msgr->cct, 5) << __func__ << \" clear encoded buffer previous \"\n                              << f << \" != \" << get_features() << dendl;\n  }\n  if (can_write == WriteStatus::CLOSED) {\n    ldout(async_msgr->cct, 10) << __func__ << \" connection closed.\"\n                               << \" Drop message \" << m << dendl;\n    m->put();\n  } else {\n    m->trace.event(\"async enqueueing message\");\n    out_q[m->get_priority()].emplace_back(std::move(bl), m);\n    ldout(async_msgr->cct, 15) << __func__ << \" inline write is denied, reschedule m=\" << m << dendl;\n    if (can_write != WriteStatus::REPLACING)\n      center->dispatch_event_external(write_handler);\n  }\n  return 0;\n}\n\nvoid AsyncConnection::requeue_sent()\n{\n  if (sent.empty())\n    return;\n\n  list<pair<bufferlist, Message*> >& rq = out_q[CEPH_MSG_PRIO_HIGHEST];\n  while (!sent.empty()) {\n    Message* m = sent.back();\n    sent.pop_back();\n    ldout(async_msgr->cct, 10) << __func__ << \" \" << *m << \" for resend \"\n                               << \" (\" << m->get_seq() << \")\" << dendl;\n    rq.push_front(make_pair(bufferlist(), m));\n    out_seq--;\n  }\n}\n\nvoid AsyncConnection::discard_requeued_up_to(uint64_t seq)\n{\n  ldout(async_msgr->cct, 10) << __func__ << \" \" << seq << dendl;\n  std::lock_guard<std::mutex> l(write_lock);\n  if (out_q.count(CEPH_MSG_PRIO_HIGHEST) == 0)\n    return;\n  list<pair<bufferlist, Message*> >& rq = out_q[CEPH_MSG_PRIO_HIGHEST];\n  while (!rq.empty()) {\n    pair<bufferlist, Message*> p = rq.front();\n    if (p.second->get_seq() == 0 || p.second->get_seq() > seq)\n      break;\n    ldout(async_msgr->cct, 10) << __func__ << \" \" << *(p.second) << \" for resend seq \" << p.second->get_seq()\n                         << \" <= \" << seq << \", discarding\" << dendl;\n    p.second->put();\n    rq.pop_front();\n    out_seq++;\n  }\n  if (rq.empty())\n    out_q.erase(CEPH_MSG_PRIO_HIGHEST);\n}\n\n/*\n * Tears down the AsyncConnection's message queues, and removes them from the DispatchQueue\n * Must hold write_lock prior to calling.\n */\nvoid AsyncConnection::discard_out_queue()\n{\n  ldout(async_msgr->cct, 10) << __func__ << \" started\" << dendl;\n\n  for (list<Message*>::iterator p = sent.begin(); p != sent.end(); ++p) {\n    ldout(async_msgr->cct, 20) << __func__ << \" discard \" << *p << dendl;\n    (*p)->put();\n  }\n  sent.clear();\n  for (map<int, list<pair<bufferlist, Message*> > >::iterator p = out_q.begin(); p != out_q.end(); ++p)\n    for (list<pair<bufferlist, Message*> >::iterator r = p->second.begin(); r != p->second.end(); ++r) {\n      ldout(async_msgr->cct, 20) << __func__ << \" discard \" << r->second << dendl;\n      r->second->put();\n    }\n  out_q.clear();\n}\n\nint AsyncConnection::randomize_out_seq()\n{\n  if (get_features() & CEPH_FEATURE_MSG_AUTH) {\n    // Set out_seq to a random value, so CRC won't be predictable.   Don't bother checking seq_error\n    // here.  We'll check it on the call.  PLR\n    uint64_t rand_seq;\n    int seq_error = get_random_bytes((char *)&rand_seq, sizeof(rand_seq));\n    rand_seq &= SEQ_MASK;\n    lsubdout(async_msgr->cct, ms, 10) << __func__ << \" randomize_out_seq \" << rand_seq << dendl;\n    out_seq = rand_seq;\n    return seq_error;\n  } else {\n    // previously, seq #'s always started at 0.\n    out_seq = 0;\n    return 0;\n  }\n}\n\nvoid AsyncConnection::fault()\n{\n  if (state == STATE_CLOSED || state == STATE_NONE) {\n    ldout(async_msgr->cct, 10) << __func__ << \" connection is already closed\" << dendl;\n    return ;\n  }\n\n  if (policy.lossy && !(state >= STATE_CONNECTING && state < STATE_CONNECTING_READY)) {\n    ldout(async_msgr->cct, 1) << __func__ << \" on lossy channel, failing\" << dendl;\n    _stop();\n    dispatch_queue->queue_reset(this);\n    return ;\n  }\n\n  write_lock.lock();\n  can_write = WriteStatus::NOWRITE;\n  shutdown_socket();\n  open_write = false;\n\n  // queue delayed items immediately\n  if (delay_state)\n    delay_state->flush();\n  // requeue sent items\n  requeue_sent();\n  recv_start = recv_end = 0;\n  state_offset = 0;\n  replacing = false;\n  is_reset_from_peer = false;\n  outcoming_bl.clear();\n  if (!once_ready && !is_queued() &&\n      state >=STATE_ACCEPTING && state <= STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH) {\n    ldout(async_msgr->cct, 10) << __func__ << \" with nothing to send and in the half \"\n                              << \" accept state just closed\" << dendl;\n    write_lock.unlock();\n    _stop();\n    dispatch_queue->queue_reset(this);\n    return ;\n  }\n  reset_recv_state();\n  if (policy.standby && !is_queued() && state != STATE_WAIT) {\n    ldout(async_msgr->cct, 10) << __func__ << \" with nothing to send, going to standby\" << dendl;\n    state = STATE_STANDBY;\n    write_lock.unlock();\n    return;\n  }\n\n  write_lock.unlock();\n  if (!(state >= STATE_CONNECTING && state < STATE_CONNECTING_READY) &&\n      state != STATE_WAIT) { // STATE_WAIT is coming from STATE_CONNECTING_*\n    // policy maybe empty when state is in accept\n    if (policy.server) {\n      ldout(async_msgr->cct, 0) << __func__ << \" server, going to standby\" << dendl;\n      state = STATE_STANDBY;\n    } else {\n      ldout(async_msgr->cct, 0) << __func__ << \" initiating reconnect\" << dendl;\n      connect_seq++;\n      state = STATE_CONNECTING;\n    }\n    backoff = utime_t();\n    center->dispatch_event_external(read_handler);\n  } else {\n    if (state == STATE_WAIT) {\n      backoff.set_from_double(async_msgr->cct->_conf->ms_max_backoff);\n    } else if (backoff == utime_t()) {\n      backoff.set_from_double(async_msgr->cct->_conf->ms_initial_backoff);\n    } else {\n      backoff += backoff;\n      if (backoff > async_msgr->cct->_conf->ms_max_backoff)\n        backoff.set_from_double(async_msgr->cct->_conf->ms_max_backoff);\n    }\n\n    state = STATE_CONNECTING;\n    ldout(async_msgr->cct, 10) << __func__ << \" waiting \" << backoff << dendl;\n    // woke up again;\n    register_time_events.insert(center->create_time_event(\n            backoff.to_nsec()/1000, wakeup_handler));\n  }\n}\n\nvoid AsyncConnection::was_session_reset()\n{\n  ldout(async_msgr->cct,10) << __func__ << \" started\" << dendl;\n  std::lock_guard<std::mutex> l(write_lock);\n  if (delay_state)\n    delay_state->discard();\n  dispatch_queue->discard_queue(conn_id);\n  discard_out_queue();\n  // note: we need to clear outcoming_bl here, but was_session_reset may be\n  // called by other thread, so let caller clear this itself!\n  // outcoming_bl.clear();\n\n  dispatch_queue->queue_remote_reset(this);\n\n  if (randomize_out_seq()) {\n    ldout(async_msgr->cct, 15) << __func__ << \" could not get random bytes to set seq number for session reset; set seq number to \" << out_seq << dendl;\n  }\n\n  in_seq = 0;\n  connect_seq = 0;\n  // it's safe to directly set 0, double locked\n  ack_left = 0;\n  once_ready = false;\n  can_write = WriteStatus::NOWRITE;\n}\n\nvoid AsyncConnection::_stop()\n{\n  if (state == STATE_CLOSED)\n    return ;\n\n  if (delay_state)\n    delay_state->flush();\n\n  ldout(async_msgr->cct, 2) << __func__ << dendl;\n  std::lock_guard<std::mutex> l(write_lock);\n\n  reset_recv_state();\n  dispatch_queue->discard_queue(conn_id);\n  discard_out_queue();\n  async_msgr->unregister_conn(this);\n  worker->release_worker();\n\n  state = STATE_CLOSED;\n  open_write = false;\n  can_write = WriteStatus::CLOSED;\n  state_offset = 0;\n  // Make sure in-queue events will been processed\n  center->dispatch_event_external(EventCallbackRef(new C_clean_handler(this)));\n}\n\nvoid AsyncConnection::prepare_send_message(uint64_t features, Message *m, bufferlist &bl)\n{\n  ldout(async_msgr->cct, 20) << __func__ << \" m\" << \" \" << *m << dendl;\n\n  // associate message with Connection (for benefit of encode_payload)\n  if (m->empty_payload())\n    ldout(async_msgr->cct, 20) << __func__ << \" encoding features \"\n                               << features << \" \" << m << \" \" << *m << dendl;\n  else\n    ldout(async_msgr->cct, 20) << __func__ << \" half-reencoding features \"\n                               << features << \" \" << m << \" \" << *m << dendl;\n\n  // encode and copy out of *m\n  m->encode(features, msgr->crcflags);\n\n  bl.append(m->get_payload());\n  bl.append(m->get_middle());\n  bl.append(m->get_data());\n}\n\nssize_t AsyncConnection::write_message(Message *m, bufferlist& bl, bool more)\n{\n  FUNCTRACE();\n  assert(center->in_thread());\n  m->set_seq(++out_seq);\n\n  if (msgr->crcflags & MSG_CRC_HEADER)\n    m->calc_header_crc();\n\n  ceph_msg_header& header = m->get_header();\n  ceph_msg_footer& footer = m->get_footer();\n\n  // TODO: let sign_message could be reentry?\n  // Now that we have all the crcs calculated, handle the\n  // digital signature for the message, if the AsyncConnection has session\n  // security set up.  Some session security options do not\n  // actually calculate and check the signature, but they should\n  // handle the calls to sign_message and check_signature.  PLR\n  if (session_security.get() == NULL) {\n    ldout(async_msgr->cct, 20) << __func__ << \" no session security\" << dendl;\n  } else {\n    if (session_security->sign_message(m)) {\n      ldout(async_msgr->cct, 20) << __func__ << \" failed to sign m=\"\n                                 << m << \"): sig = \" << footer.sig << dendl;\n    } else {\n      ldout(async_msgr->cct, 20) << __func__ << \" signed m=\" << m\n                                 << \"): sig = \" << footer.sig << dendl;\n    }\n  }\n  \n  unsigned original_bl_len = outcoming_bl.length();\n\n  outcoming_bl.append(CEPH_MSGR_TAG_MSG);\n\n  if (has_feature(CEPH_FEATURE_NOSRCADDR)) {\n    outcoming_bl.append((char*)&header, sizeof(header));\n  } else {\n    ceph_msg_header_old oldheader;\n    memcpy(&oldheader, &header, sizeof(header));\n    oldheader.src.name = header.src;\n    oldheader.src.addr = get_peer_addr();\n    oldheader.orig_src = oldheader.src;\n    oldheader.reserved = header.reserved;\n    oldheader.crc = ceph_crc32c(0, (unsigned char*)&oldheader,\n                                sizeof(oldheader) - sizeof(oldheader.crc));\n    outcoming_bl.append((char*)&oldheader, sizeof(oldheader));\n  }\n\n  ldout(async_msgr->cct, 20) << __func__ << \" sending message type=\" << header.type\n                             << \" src \" << entity_name_t(header.src)\n                             << \" front=\" << header.front_len\n                             << \" data=\" << header.data_len\n                             << \" off \" << header.data_off << dendl;\n\n  if ((bl.length() <= ASYNC_COALESCE_THRESHOLD) && (bl.buffers().size() > 1)) {\n    for (const auto &pb : bl.buffers()) {\n      outcoming_bl.append((char*)pb.c_str(), pb.length());\n    }\n  } else {\n    outcoming_bl.claim_append(bl);  \n  }\n\n  // send footer; if receiver doesn't support signatures, use the old footer format\n  ceph_msg_footer_old old_footer;\n  if (has_feature(CEPH_FEATURE_MSG_AUTH)) {\n    outcoming_bl.append((char*)&footer, sizeof(footer));\n  } else {\n    if (msgr->crcflags & MSG_CRC_HEADER) {\n      old_footer.front_crc = footer.front_crc;\n      old_footer.middle_crc = footer.middle_crc;\n      old_footer.data_crc = footer.data_crc;\n    } else {\n       old_footer.front_crc = old_footer.middle_crc = 0;\n    }\n    old_footer.data_crc = msgr->crcflags & MSG_CRC_DATA ? footer.data_crc : 0;\n    old_footer.flags = footer.flags;\n    outcoming_bl.append((char*)&old_footer, sizeof(old_footer));\n  }\n\n  m->trace.event(\"async writing message\");\n  ldout(async_msgr->cct, 20) << __func__ << \" sending \" << m->get_seq()\n                             << \" \" << m << dendl;\n  ssize_t total_send_size = outcoming_bl.length();\n  ssize_t rc = _try_send(more);\n  if (rc < 0) {\n    ldout(async_msgr->cct, 1) << __func__ << \" error sending \" << m << \", \"\n                              << cpp_strerror(rc) << dendl;\n  } else if (rc == 0) {\n    logger->inc(l_msgr_send_bytes, total_send_size - original_bl_len);\n    ldout(async_msgr->cct, 10) << __func__ << \" sending \" << m << \" done.\" << dendl;\n  } else {\n    logger->inc(l_msgr_send_bytes, total_send_size - outcoming_bl.length());\n    ldout(async_msgr->cct, 10) << __func__ << \" sending \" << m << \" continuely.\" << dendl;\n  }\n  if (m->get_type() == CEPH_MSG_OSD_OP)\n    OID_EVENT_TRACE_WITH_MSG(m, \"SEND_MSG_OSD_OP_END\", false);\n  else if (m->get_type() == CEPH_MSG_OSD_OPREPLY)\n    OID_EVENT_TRACE_WITH_MSG(m, \"SEND_MSG_OSD_OPREPLY_END\", false);\n  m->put();\n\n  return rc;\n}\n\nvoid AsyncConnection::reset_recv_state()\n{\n  // clean up state internal variables and states\n  if (state >= STATE_CONNECTING_SEND_CONNECT_MSG &&\n      state <= STATE_CONNECTING_READY) {\n    delete authorizer;\n    authorizer = NULL;\n    got_bad_auth = false;\n  }\n\n  if (state > STATE_OPEN_MESSAGE_THROTTLE_MESSAGE &&\n      state <= STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH\n      && policy.throttler_messages) {\n    ldout(async_msgr->cct, 10) << __func__ << \" releasing \" << 1\n                               << \" message to policy throttler \"\n                               << policy.throttler_messages->get_current() << \"/\"\n                               << policy.throttler_messages->get_max() << dendl;\n    policy.throttler_messages->put();\n  }\n  if (state > STATE_OPEN_MESSAGE_THROTTLE_BYTES &&\n      state <= STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH) {\n    if (policy.throttler_bytes) {\n      ldout(async_msgr->cct, 10) << __func__ << \" releasing \" << cur_msg_size\n                                 << \" bytes to policy throttler \"\n                                 << policy.throttler_bytes->get_current() << \"/\"\n                                 << policy.throttler_bytes->get_max() << dendl;\n      policy.throttler_bytes->put(cur_msg_size);\n    }\n  }\n  if (state > STATE_OPEN_MESSAGE_THROTTLE_DISPATCH_QUEUE &&\n      state <= STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH) {\n    ldout(async_msgr->cct, 10) << __func__ << \" releasing \" << cur_msg_size\n                               << \" bytes to dispatch_queue throttler \"\n                               << dispatch_queue->dispatch_throttler.get_current() << \"/\"\n                               << dispatch_queue->dispatch_throttler.get_max() << dendl;\n    dispatch_queue->dispatch_throttle_release(cur_msg_size);\n  }\n}\n\nvoid AsyncConnection::handle_ack(uint64_t seq)\n{\n  ldout(async_msgr->cct, 15) << __func__ << \" got ack seq \" << seq << dendl;\n  // trim sent list\n  std::lock_guard<std::mutex> l(write_lock);\n  while (!sent.empty() && sent.front()->get_seq() <= seq) {\n    Message* m = sent.front();\n    sent.pop_front();\n    ldout(async_msgr->cct, 10) << __func__ << \" got ack seq \"\n                               << seq << \" >= \" << m->get_seq() << \" on \"\n                               << m << \" \" << *m << dendl;\n    m->put();\n  }\n}\n\nvoid AsyncConnection::DelayedDelivery::do_request(int id)\n{\n  Message *m = nullptr;\n  {\n    std::lock_guard<std::mutex> l(delay_lock);\n    register_time_events.erase(id);\n    if (stop_dispatch)\n      return ;\n    if (delay_queue.empty())\n      return ;\n    utime_t release = delay_queue.front().first;\n    m = delay_queue.front().second;\n    string delay_msg_type = msgr->cct->_conf->ms_inject_delay_msg_type;\n    utime_t now = ceph_clock_now();\n    if ((release > now &&\n        (delay_msg_type.empty() || m->get_type_name() == delay_msg_type))) {\n      utime_t t = release - now;\n      t.sleep();\n    }\n    delay_queue.pop_front();\n  }\n  if (msgr->ms_can_fast_dispatch(m)) {\n    dispatch_queue->fast_dispatch(m);\n  } else {\n    dispatch_queue->enqueue(m, m->get_priority(), conn_id);\n  }\n}\n\nvoid AsyncConnection::DelayedDelivery::flush() {\n  stop_dispatch = true;\n  center->submit_to(\n      center->get_id(), [this] () mutable {\n    std::lock_guard<std::mutex> l(delay_lock);\n    while (!delay_queue.empty()) {\n      Message *m = delay_queue.front().second;\n      if (msgr->ms_can_fast_dispatch(m)) {\n        dispatch_queue->fast_dispatch(m);\n      } else {\n        dispatch_queue->enqueue(m, m->get_priority(), conn_id);\n      }\n      delay_queue.pop_front();\n    }\n    for (auto i : register_time_events)\n      center->delete_time_event(i);\n    register_time_events.clear();\n    stop_dispatch = false;\n  }, true);\n}\n\nvoid AsyncConnection::send_keepalive()\n{\n  ldout(async_msgr->cct, 10) << __func__ << dendl;\n  std::lock_guard<std::mutex> l(write_lock);\n  if (can_write != WriteStatus::CLOSED) {\n    keepalive = true;\n    center->dispatch_event_external(write_handler);\n  }\n}\n\nvoid AsyncConnection::mark_down()\n{\n  ldout(async_msgr->cct, 1) << __func__ << dendl;\n  std::lock_guard<std::mutex> l(lock);\n  _stop();\n}\n\nvoid AsyncConnection::_append_keepalive_or_ack(bool ack, utime_t *tp)\n{\n  ldout(async_msgr->cct, 10) << __func__ << dendl;\n  if (ack) {\n    assert(tp);\n    struct ceph_timespec ts;\n    tp->encode_timeval(&ts);\n    outcoming_bl.append(CEPH_MSGR_TAG_KEEPALIVE2_ACK);\n    outcoming_bl.append((char*)&ts, sizeof(ts));\n  } else if (has_feature(CEPH_FEATURE_MSGR_KEEPALIVE2)) {\n    struct ceph_timespec ts;\n    utime_t t = ceph_clock_now();\n    t.encode_timeval(&ts);\n    outcoming_bl.append(CEPH_MSGR_TAG_KEEPALIVE2);\n    outcoming_bl.append((char*)&ts, sizeof(ts));\n  } else {\n    outcoming_bl.append(CEPH_MSGR_TAG_KEEPALIVE);\n  }\n}\n\nvoid AsyncConnection::handle_write()\n{\n  ldout(async_msgr->cct, 10) << __func__ << dendl;\n  ssize_t r = 0;\n\n  write_lock.lock();\n  if (can_write == WriteStatus::CANWRITE) {\n    if (keepalive) {\n      _append_keepalive_or_ack();\n      keepalive = false;\n    }\n\n    auto start = ceph::mono_clock::now();\n    bool more;\n    do {\n      bufferlist data;\n      Message *m = _get_next_outgoing(&data);\n      if (!m)\n        break;\n\n      if (!policy.lossy) {\n        // put on sent list\n        sent.push_back(m);\n        m->get();\n      }\n      more = _has_next_outgoing();\n      write_lock.unlock();\n\n      // send_message or requeue messages may not encode message\n      if (!data.length())\n        prepare_send_message(get_features(), m, data);\n\n      r = write_message(m, data, more);\n      if (r < 0) {\n        ldout(async_msgr->cct, 1) << __func__ << \" send msg failed\" << dendl;\n        goto fail;\n      }\n      write_lock.lock();\n      if (r > 0)\n        break;\n    } while (can_write == WriteStatus::CANWRITE);\n    write_lock.unlock();\n\n    uint64_t left = ack_left;\n    if (left) {\n      ceph_le64 s;\n      s = in_seq;\n      outcoming_bl.append(CEPH_MSGR_TAG_ACK);\n      outcoming_bl.append((char*)&s, sizeof(s));\n      ldout(async_msgr->cct, 10) << __func__ << \" try send msg ack, acked \" << left << \" messages\" << dendl;\n      ack_left -= left;\n      left = ack_left;\n      r = _try_send(left);\n    } else if (is_queued()) {\n      r = _try_send();\n    }\n\n    logger->tinc(l_msgr_running_send_time, ceph::mono_clock::now() - start);\n    if (r < 0) {\n      ldout(async_msgr->cct, 1) << __func__ << \" send msg failed\" << dendl;\n      goto fail;\n    }\n  } else {\n    write_lock.unlock();\n    lock.lock();\n    write_lock.lock();\n    if (state == STATE_STANDBY && !policy.server && is_queued()) {\n      ldout(async_msgr->cct, 10) << __func__ << \" policy.server is false\" << dendl;\n      _connect();\n    } else if (cs && state != STATE_NONE && state != STATE_CONNECTING && state != STATE_CONNECTING_RE && state != STATE_CLOSED) {\n      r = _try_send();\n      if (r < 0) {\n        ldout(async_msgr->cct, 1) << __func__ << \" send outcoming bl failed\" << dendl;\n        write_lock.unlock();\n        fault();\n        lock.unlock();\n        return ;\n      }\n    }\n    write_lock.unlock();\n    lock.unlock();\n  }\n\n  return ;\n\n fail:\n  lock.lock();\n  fault();\n  lock.unlock();\n}\n\nvoid AsyncConnection::wakeup_from(uint64_t id)\n{\n  lock.lock();\n  register_time_events.erase(id);\n  lock.unlock();\n  process();\n}\n\nvoid AsyncConnection::tick(uint64_t id)\n{\n  auto now = ceph::coarse_mono_clock::now();\n  ldout(async_msgr->cct, 20) << __func__ << \" last_id=\" << last_tick_id\n                             << \" last_active\" << last_active << dendl;\n  std::lock_guard<std::mutex> l(lock);\n  last_tick_id = 0;\n  auto idle_period = std::chrono::duration_cast<std::chrono::microseconds>(now - last_active).count();\n  if (inactive_timeout_us < (uint64_t)idle_period) {\n    ldout(async_msgr->cct, 1) << __func__ << \" idle(\" << idle_period << \") more than \"\n                              << inactive_timeout_us\n                              << \" us, mark self fault.\" << dendl;\n    fault();\n  } else if (is_connected()) {\n    last_tick_id = center->create_time_event(inactive_timeout_us, tick_handler);\n  }\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2014 UnitedStack <haomai@unitedstack.com>\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#ifndef CEPH_MSG_ASYNCCONNECTION_H\n#define CEPH_MSG_ASYNCCONNECTION_H\n\n#include <atomic>\n#include <pthread.h>\n#include <climits>\n#include <list>\n#include <mutex>\n#include <map>\nusing namespace std;\n\n#include \"auth/AuthSessionHandler.h\"\n#include \"common/ceph_time.h\"\n#include \"common/perf_counters.h\"\n#include \"include/buffer.h\"\n#include \"msg/Connection.h\"\n#include \"msg/Messenger.h\"\n\n#include \"Event.h\"\n#include \"Stack.h\"\n\nclass AsyncMessenger;\nclass Worker;\n\nstatic const int ASYNC_IOV_MAX = (IOV_MAX >= 1024 ? IOV_MAX / 4 : IOV_MAX);\n\n/*\n * AsyncConnection maintains a logic session between two endpoints. In other\n * word, a pair of addresses can find the only AsyncConnection. AsyncConnection\n * will handle with network fault or read/write transactions. If one file\n * descriptor broken, AsyncConnection will maintain the message queue and\n * sequence, try to reconnect peer endpoint.\n */\nclass AsyncConnection : public Connection {\n\n  ssize_t read_bulk(char *buf, unsigned len);\n  ssize_t do_sendmsg(struct msghdr &msg, unsigned len, bool more);\n  ssize_t try_send(bufferlist &bl, bool more=false) {\n    std::lock_guard<std::mutex> l(write_lock);\n    outcoming_bl.claim_append(bl);\n    return _try_send(more);\n  }\n  ssize_t _try_send(bool more=false);\n  ssize_t _send(Message *m);\n  void prepare_send_message(uint64_t features, Message *m, bufferlist &bl);\n  ssize_t read_until(unsigned needed, char *p);\n  ssize_t _process_connection();\n  void _connect();\n  void _stop();\n  int handle_connect_reply(ceph_msg_connect &connect, ceph_msg_connect_reply &r);\n  ssize_t handle_connect_msg(ceph_msg_connect &m, bufferlist &aubl, bufferlist &bl);\n  void was_session_reset();\n  void fault();\n  void discard_out_queue();\n  void discard_requeued_up_to(uint64_t seq);\n  void requeue_sent();\n  int randomize_out_seq();\n  void handle_ack(uint64_t seq);\n  void _append_keepalive_or_ack(bool ack=false, utime_t *t=NULL);\n  ssize_t write_message(Message *m, bufferlist& bl, bool more);\n  void inject_delay();\n  ssize_t _reply_accept(char tag, ceph_msg_connect &connect, ceph_msg_connect_reply &reply,\n                    bufferlist &authorizer_reply) {\n    bufferlist reply_bl;\n    reply.tag = tag;\n    reply.features = ((uint64_t)connect.features & policy.features_supported) | policy.features_required;\n    reply.authorizer_len = authorizer_reply.length();\n    reply_bl.append((char*)&reply, sizeof(reply));\n    if (reply.authorizer_len) {\n      reply_bl.append(authorizer_reply.c_str(), authorizer_reply.length());\n    }\n    ssize_t r = try_send(reply_bl);\n    if (r < 0) {\n      inject_delay();\n      return -1;\n    }\n\n    state = STATE_ACCEPTING_WAIT_CONNECT_MSG;\n    return 0;\n  }\n  bool is_queued() const {\n    return !out_q.empty() || outcoming_bl.length();\n  }\n  void shutdown_socket() {\n    for (auto &&t : register_time_events)\n      center->delete_time_event(t);\n    register_time_events.clear();\n    if (last_tick_id) {\n      center->delete_time_event(last_tick_id);\n      last_tick_id = 0;\n    }\n    if (cs) {\n      center->delete_file_event(cs.fd(), EVENT_READABLE|EVENT_WRITABLE);\n      cs.shutdown();\n      cs.close();\n    }\n  }\n  Message *_get_next_outgoing(bufferlist *bl) {\n    Message *m = 0;\n    while (!m && !out_q.empty()) {\n      map<int, list<pair<bufferlist, Message*> > >::reverse_iterator it = out_q.rbegin();\n      if (!it->second.empty()) {\n        list<pair<bufferlist, Message*> >::iterator p = it->second.begin();\n        m = p->second;\n        if (bl)\n          bl->swap(p->first);\n        it->second.erase(p);\n      }\n      if (it->second.empty())\n        out_q.erase(it->first);\n    }\n    return m;\n  }\n  bool _has_next_outgoing() const {\n    return !out_q.empty();\n  }\n  void reset_recv_state();\n\n   /**\n   * The DelayedDelivery is for injecting delays into Message delivery off\n   * the socket. It is only enabled if delays are requested, and if they\n   * are then it pulls Messages off the DelayQueue and puts them into the\n   * AsyncMessenger event queue.\n   */\n  class DelayedDelivery : public EventCallback {\n    std::set<uint64_t> register_time_events; // need to delete it if stop\n    std::deque<std::pair<utime_t, Message*> > delay_queue;\n    std::mutex delay_lock;\n    AsyncMessenger *msgr;\n    EventCenter *center;\n    DispatchQueue *dispatch_queue;\n    uint64_t conn_id;\n    std::atomic_bool stop_dispatch;\n\n   public:\n    explicit DelayedDelivery(AsyncMessenger *omsgr, EventCenter *c,\n                             DispatchQueue *q, uint64_t cid)\n      : msgr(omsgr), center(c), dispatch_queue(q), conn_id(cid),\n        stop_dispatch(false) { }\n    ~DelayedDelivery() override {\n      assert(register_time_events.empty());\n      assert(delay_queue.empty());\n    }\n    void set_center(EventCenter *c) { center = c; }\n    void do_request(int id) override;\n    void queue(double delay_period, utime_t release, Message *m) {\n      std::lock_guard<std::mutex> l(delay_lock);\n      delay_queue.push_back(std::make_pair(release, m));\n      register_time_events.insert(center->create_time_event(delay_period*1000000, this));\n    }\n    void discard() {\n      stop_dispatch = true;\n      center->submit_to(center->get_id(), [this] () mutable {\n        std::lock_guard<std::mutex> l(delay_lock);\n        while (!delay_queue.empty()) {\n          Message *m = delay_queue.front().second;\n          dispatch_queue->dispatch_throttle_release(m->get_dispatch_throttle_size());\n          m->put();\n          delay_queue.pop_front();\n        }\n        for (auto i : register_time_events)\n          center->delete_time_event(i);\n        register_time_events.clear();\n        stop_dispatch = false;\n      }, true);\n    }\n    bool ready() const { return !stop_dispatch && delay_queue.empty() && register_time_events.empty(); }\n    void flush();\n  } *delay_state;\n\n public:\n  AsyncConnection(CephContext *cct, AsyncMessenger *m, DispatchQueue *q, Worker *w);\n  ~AsyncConnection() override;\n  void maybe_start_delay_thread();\n\n  ostream& _conn_prefix(std::ostream *_dout);\n\n  bool is_connected() override {\n    return can_write.load() == WriteStatus::CANWRITE;\n  }\n\n  // Only call when AsyncConnection first construct\n  void connect(const entity_addr_t& addr, int type) {\n    set_peer_type(type);\n    set_peer_addr(addr);\n    policy = msgr->get_policy(type);\n    _connect();\n  }\n  // Only call when AsyncConnection first construct\n  void accept(ConnectedSocket socket, entity_addr_t &addr);\n  int send_message(Message *m) override;\n\n  void send_keepalive() override;\n  void mark_down() override;\n  void mark_disposable() override {\n    std::lock_guard<std::mutex> l(lock);\n    policy.lossy = true;\n  }\n  \n private:\n  enum {\n    STATE_NONE,\n    STATE_OPEN,\n    STATE_OPEN_KEEPALIVE2,\n    STATE_OPEN_KEEPALIVE2_ACK,\n    STATE_OPEN_TAG_ACK,\n    STATE_OPEN_MESSAGE_HEADER,\n    STATE_OPEN_MESSAGE_THROTTLE_MESSAGE,\n    STATE_OPEN_MESSAGE_THROTTLE_BYTES,\n    STATE_OPEN_MESSAGE_THROTTLE_DISPATCH_QUEUE,\n    STATE_OPEN_MESSAGE_READ_FRONT,\n    STATE_OPEN_MESSAGE_READ_MIDDLE,\n    STATE_OPEN_MESSAGE_READ_DATA_PREPARE,\n    STATE_OPEN_MESSAGE_READ_DATA,\n    STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH,\n    STATE_OPEN_TAG_CLOSE,\n    STATE_WAIT_SEND,\n    STATE_CONNECTING,\n    STATE_CONNECTING_RE,\n    STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY,\n    STATE_CONNECTING_SEND_CONNECT_MSG,\n    STATE_CONNECTING_WAIT_CONNECT_REPLY,\n    STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH,\n    STATE_CONNECTING_WAIT_ACK_SEQ,\n    STATE_CONNECTING_READY,\n    STATE_ACCEPTING,\n    STATE_ACCEPTING_WAIT_BANNER_ADDR,\n    STATE_ACCEPTING_WAIT_CONNECT_MSG,\n    STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH,\n    STATE_ACCEPTING_WAIT_SEQ,\n    STATE_ACCEPTING_READY,\n    STATE_STANDBY,\n    STATE_CLOSED,\n    STATE_WAIT,       // just wait for racing connection\n  };\n\n  static const int TCP_PREFETCH_MIN_SIZE;\n  static const char *get_state_name(int state) {\n      const char* const statenames[] = {\"STATE_NONE\",\n                                        \"STATE_OPEN\",\n                                        \"STATE_OPEN_KEEPALIVE2\",\n                                        \"STATE_OPEN_KEEPALIVE2_ACK\",\n                                        \"STATE_OPEN_TAG_ACK\",\n                                        \"STATE_OPEN_MESSAGE_HEADER\",\n                                        \"STATE_OPEN_MESSAGE_THROTTLE_MESSAGE\",\n                                        \"STATE_OPEN_MESSAGE_THROTTLE_BYTES\",\n                                        \"STATE_OPEN_MESSAGE_THROTTLE_DISPATCH_QUEUE\",\n                                        \"STATE_OPEN_MESSAGE_READ_FRONT\",\n                                        \"STATE_OPEN_MESSAGE_READ_MIDDLE\",\n                                        \"STATE_OPEN_MESSAGE_READ_DATA_PREPARE\",\n                                        \"STATE_OPEN_MESSAGE_READ_DATA\",\n                                        \"STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH\",\n                                        \"STATE_OPEN_TAG_CLOSE\",\n                                        \"STATE_WAIT_SEND\",\n                                        \"STATE_CONNECTING\",\n                                        \"STATE_CONNECTING_RE\",\n                                        \"STATE_CONNECTING_WAIT_BANNER_AND_IDENTIFY\",\n                                        \"STATE_CONNECTING_SEND_CONNECT_MSG\",\n                                        \"STATE_CONNECTING_WAIT_CONNECT_REPLY\",\n                                        \"STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH\",\n                                        \"STATE_CONNECTING_WAIT_ACK_SEQ\",\n                                        \"STATE_CONNECTING_READY\",\n                                        \"STATE_ACCEPTING\",\n                                        \"STATE_ACCEPTING_WAIT_BANNER_ADDR\",\n                                        \"STATE_ACCEPTING_WAIT_CONNECT_MSG\",\n                                        \"STATE_ACCEPTING_WAIT_CONNECT_MSG_AUTH\",\n                                        \"STATE_ACCEPTING_WAIT_SEQ\",\n                                        \"STATE_ACCEPTING_READY\",\n                                        \"STATE_STANDBY\",\n                                        \"STATE_CLOSED\",\n                                        \"STATE_WAIT\"};\n      return statenames[state];\n  }\n\n  AsyncMessenger *async_msgr;\n  uint64_t conn_id;\n  PerfCounters *logger;\n  int global_seq;\n  __u32 connect_seq, peer_global_seq;\n  std::atomic<uint64_t> out_seq{0};\n  std::atomic<uint64_t> ack_left{0}, in_seq{0};\n  int state;\n  int state_after_send;\n  ConnectedSocket cs;\n  int port;\n  Messenger::Policy policy;\n\n  DispatchQueue *dispatch_queue;\n\n  // lockfree, only used in own thread\n  bufferlist outcoming_bl;\n  bool open_write = false;\n\n  std::mutex write_lock;\n  enum class WriteStatus {\n    NOWRITE,\n    REPLACING,\n    CANWRITE,\n    CLOSED\n  };\n  std::atomic<WriteStatus> can_write;\n  list<Message*> sent; // the first bufferlist need to inject seq\n  map<int, list<pair<bufferlist, Message*> > > out_q;  // priority queue for outbound msgs\n  bool keepalive;\n\n  std::mutex lock;\n  utime_t backoff;         // backoff time\n  EventCallbackRef read_handler;\n  EventCallbackRef write_handler;\n  EventCallbackRef wakeup_handler;\n  EventCallbackRef tick_handler;\n  struct iovec msgvec[ASYNC_IOV_MAX];\n  char *recv_buf;\n  uint32_t recv_max_prefetch;\n  uint32_t recv_start;\n  uint32_t recv_end;\n  set<uint64_t> register_time_events; // need to delete it if stop\n  ceph::coarse_mono_clock::time_point last_active;\n  uint64_t last_tick_id = 0;\n  const uint64_t inactive_timeout_us;\n\n  // Tis section are temp variables used by state transition\n\n  // Open state\n  utime_t recv_stamp;\n  utime_t throttle_stamp;\n  unsigned msg_left;\n  uint64_t cur_msg_size;\n  ceph_msg_header current_header;\n  bufferlist data_buf;\n  bufferlist::iterator data_blp;\n  bufferlist front, middle, data;\n  ceph_msg_connect connect_msg;\n  // Connecting state\n  bool got_bad_auth;\n  AuthAuthorizer *authorizer;\n  bufferlist authorizer_buf;\n  ceph_msg_connect_reply connect_reply;\n  // Accepting state\n  entity_addr_t socket_addr;\n  CryptoKey session_key;\n  bool replacing;    // when replacing process happened, we will reply connect\n                     // side with RETRY tag and accept side will clear replaced\n                     // connection. So when connect side reissue connect_msg,\n                     // there won't exists conflicting connection so we use\n                     // \"replacing\" to skip RESETSESSION to avoid detect wrong\n                     // presentation\n  bool is_reset_from_peer;\n  bool once_ready;\n\n  // used only for local state, it will be overwrite when state transition\n  char *state_buffer;\n  // used only by \"read_until\"\n  uint64_t state_offset;\n  Worker *worker;\n  EventCenter *center;\n  ceph::shared_ptr<AuthSessionHandler> session_security;\n  std::unique_ptr<AuthAuthorizerChallenge> authorizer_challenge; // accept side\n\n public:\n  // used by eventcallback\n  void handle_write();\n  void process();\n  void wakeup_from(uint64_t id);\n  void tick(uint64_t id);\n  void local_deliver();\n  void stop(bool queue_reset) {\n    lock.lock();\n    bool need_queue_reset = (state != STATE_CLOSED) && queue_reset;\n    _stop();\n    lock.unlock();\n    if (need_queue_reset)\n      dispatch_queue->queue_reset(this);\n  }\n  void cleanup() {\n    shutdown_socket();\n    delete read_handler;\n    delete write_handler;\n    delete wakeup_handler;\n    delete tick_handler;\n    if (delay_state) {\n      delete delay_state;\n      delay_state = NULL;\n    }\n  }\n  PerfCounters *get_perf_counter() {\n    return logger;\n  }\n}; /* AsyncConnection */\n\ntypedef boost::intrusive_ptr<AsyncConnection> AsyncConnectionRef;\n\n#endif\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2014 UnitedStack <haomai@unitedstack.com>\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#ifndef CEPH_ASYNCMESSENGER_H\n#define CEPH_ASYNCMESSENGER_H\n\n#include \"include/types.h\"\n#include \"include/xlist.h\"\n\n#include <map>\nusing namespace std;\n#include \"include/unordered_map.h\"\n#include \"include/unordered_set.h\"\n\n#include \"common/Mutex.h\"\n#include \"common/Cond.h\"\n#include \"common/Thread.h\"\n\n#include \"include/Spinlock.h\"\n\n#include \"msg/SimplePolicyMessenger.h\"\n#include \"msg/DispatchQueue.h\"\n#include \"include/assert.h\"\n#include \"AsyncConnection.h\"\n#include \"Event.h\"\n\n\nclass AsyncMessenger;\n\n/**\n * If the Messenger binds to a specific address, the Processor runs\n * and listens for incoming connections.\n */\nclass Processor {\n  AsyncMessenger *msgr;\n  NetHandler net;\n  Worker *worker;\n  ServerSocket listen_socket;\n  EventCallbackRef listen_handler;\n\n  class C_processor_accept;\n\n public:\n  Processor(AsyncMessenger *r, Worker *w, CephContext *c);\n  ~Processor() { delete listen_handler; };\n\n  void stop();\n  int bind(const entity_addr_t &bind_addr,\n\t   const set<int>& avoid_ports,\n\t   entity_addr_t* bound_addr);\n  void start();\n  void accept();\n};\n\n/*\n * AsyncMessenger is represented for maintaining a set of asynchronous connections,\n * it may own a bind address and the accepted connections will be managed by\n * AsyncMessenger.\n *\n */\n\nclass AsyncMessenger : public SimplePolicyMessenger {\n  // First we have the public Messenger interface implementation...\npublic:\n  /**\n   * Initialize the AsyncMessenger!\n   *\n   * @param cct The CephContext to use\n   * @param name The name to assign ourselves\n   * _nonce A unique ID to use for this AsyncMessenger. It should not\n   * be a value that will be repeated if the daemon restarts.\n   */\n  AsyncMessenger(CephContext *cct, entity_name_t name, const std::string &type,\n                 string mname, uint64_t _nonce);\n\n  /**\n   * Destroy the AsyncMessenger. Pretty simple since all the work is done\n   * elsewhere.\n   */\n  ~AsyncMessenger() override;\n\n  /** @defgroup Accessors\n   * @{\n   */\n  void set_addr_unknowns(const entity_addr_t &addr) override;\n  void set_addr(const entity_addr_t &addr) override;\n\n  int get_dispatch_queue_len() override {\n    return dispatch_queue.get_queue_len();\n  }\n\n  double get_dispatch_queue_max_age(utime_t now) override {\n    return dispatch_queue.get_max_age(now);\n  }\n  /** @} Accessors */\n\n  /**\n   * @defgroup Configuration functions\n   * @{\n   */\n  void set_cluster_protocol(int p) override {\n    assert(!started && !did_bind);\n    cluster_protocol = p;\n  }\n\n  int bind(const entity_addr_t& bind_addr) override;\n  int rebind(const set<int>& avoid_ports) override;\n  int client_bind(const entity_addr_t& bind_addr) override;\n\n  /** @} Configuration functions */\n\n  /**\n   * @defgroup Startup/Shutdown\n   * @{\n   */\n  int start() override;\n  void wait() override;\n  int shutdown() override;\n\n  /** @} // Startup/Shutdown */\n\n  /**\n   * @defgroup Messaging\n   * @{\n   */\n  int send_message(Message *m, const entity_inst_t& dest) override {\n    Mutex::Locker l(lock);\n\n    return _send_message(m, dest);\n  }\n\n  /** @} // Messaging */\n\n  /**\n   * @defgroup Connection Management\n   * @{\n   */\n  ConnectionRef get_connection(const entity_inst_t& dest) override;\n  ConnectionRef get_loopback_connection() override;\n  void mark_down(const entity_addr_t& addr) override;\n  void mark_down_all() override {\n    shutdown_connections(true);\n  }\n  /** @} // Connection Management */\n\n  /**\n   * @defgroup Inner classes\n   * @{\n   */\n\n  /**\n   * @} // Inner classes\n   */\n\nprotected:\n  /**\n   * @defgroup Messenger Interfaces\n   * @{\n   */\n  /**\n   * Start up the DispatchQueue thread once we have somebody to dispatch to.\n   */\n  void ready() override;\n  /** @} // Messenger Interfaces */\n\nprivate:\n\n  /**\n   * @defgroup Utility functions\n   * @{\n   */\n\n  /**\n   * Create a connection associated with the given entity (of the given type).\n   * Initiate the connection. (This function returning does not guarantee\n   * connection success.)\n   *\n   * @param addr The address of the entity to connect to.\n   * @param type The peer type of the entity at the address.\n   *\n   * @return a pointer to the newly-created connection. Caller does not own a\n   * reference; take one if you need it.\n   */\n  AsyncConnectionRef create_connect(const entity_addr_t& addr, int type);\n\n  /**\n   * Queue up a Message for delivery to the entity specified\n   * by addr and dest_type.\n   * submit_message() is responsible for creating\n   * new AsyncConnection (and closing old ones) as necessary.\n   *\n   * @param m The Message to queue up. This function eats a reference.\n   * @param con The existing Connection to use, or NULL if you don't know of one.\n   * @param dest_addr The address to send the Message to.\n   * @param dest_type The peer type of the address we're sending to\n   * just drop silently under failure.\n   */\n  void submit_message(Message *m, AsyncConnectionRef con,\n                      const entity_addr_t& dest_addr, int dest_type);\n\n  int _send_message(Message *m, const entity_inst_t& dest);\n  void _finish_bind(const entity_addr_t& bind_addr,\n\t\t    const entity_addr_t& listen_addr);\n\n private:\n  static const uint64_t ReapDeadConnectionThreshold = 5;\n\n  NetworkStack *stack;\n  std::vector<Processor*> processors;\n  friend class Processor;\n  DispatchQueue dispatch_queue;\n\n  // the worker run messenger's cron jobs\n  Worker *local_worker;\n\n  std::string ms_type;\n\n  /// overall lock used for AsyncMessenger data structures\n  Mutex lock;\n  // AsyncMessenger stuff\n  /// approximately unique ID set by the Constructor for use in entity_addr_t\n  uint64_t nonce;\n\n  /// true, specifying we haven't learned our addr; set false when we find it.\n  // maybe this should be protected by the lock?\n  bool need_addr;\n\n  /**\n   * set to bind address if bind was called before NetworkStack was ready to\n   * bind\n   */\n  entity_addr_t pending_bind_addr;\n\n  /**\n   * false; set to true if a pending bind exists\n   */\n  bool pending_bind = false;\n\n  /**\n   *  The following aren't lock-protected since you shouldn't be able to race\n   *  the only writers.\n   */\n\n  /**\n   *  false; set to true if the AsyncMessenger bound to a specific address;\n   *  and set false again by Accepter::stop().\n   */\n  bool did_bind;\n  /// counter for the global seq our connection protocol uses\n  __u32 global_seq;\n  /// lock to protect the global_seq\n  ceph_spinlock_t global_seq_lock;\n\n  /**\n   * hash map of addresses to Asyncconnection\n   *\n   * NOTE: a Asyncconnection* with state CLOSED may still be in the map but is considered\n   * invalid and can be replaced by anyone holding the msgr lock\n   */\n  ceph::unordered_map<entity_addr_t, AsyncConnectionRef> conns;\n\n  /**\n   * list of connection are in teh process of accepting\n   *\n   * These are not yet in the conns map.\n   */\n  set<AsyncConnectionRef> accepting_conns;\n\n  /**\n   * list of connection are closed which need to be clean up\n   *\n   * Because AsyncMessenger and AsyncConnection follow a lock rule that\n   * we can lock AsyncMesenger::lock firstly then lock AsyncConnection::lock\n   * but can't reversed. This rule is aimed to avoid dead lock.\n   * So if AsyncConnection want to unregister itself from AsyncMessenger,\n   * we pick up this idea that just queue itself to this set and do lazy\n   * deleted for AsyncConnection. \"_lookup_conn\" must ensure not return a\n   * AsyncConnection in this set.\n   */\n  Mutex deleted_lock;\n  set<AsyncConnectionRef> deleted_conns;\n\n  EventCallbackRef reap_handler;\n\n  /// internal cluster protocol version, if any, for talking to entities of the same type.\n  int cluster_protocol;\n\n  Cond  stop_cond;\n  bool stopped;\n\n  AsyncConnectionRef _lookup_conn(const entity_addr_t& k) {\n    assert(lock.is_locked());\n    ceph::unordered_map<entity_addr_t, AsyncConnectionRef>::iterator p = conns.find(k);\n    if (p == conns.end())\n      return NULL;\n\n    // lazy delete, see \"deleted_conns\"\n    Mutex::Locker l(deleted_lock);\n    if (deleted_conns.erase(p->second)) {\n      p->second->get_perf_counter()->dec(l_msgr_active_connections);\n      conns.erase(p);\n      return NULL;\n    }\n\n    return p->second;\n  }\n\n  void _init_local_connection() {\n    assert(lock.is_locked());\n    local_connection->peer_addr = my_inst.addr;\n    local_connection->peer_type = my_inst.name.type();\n    local_connection->set_features(CEPH_FEATURES_ALL);\n    ms_deliver_handle_fast_connect(local_connection.get());\n  }\n\n  void shutdown_connections(bool queue_reset);\n\npublic:\n\n  /// con used for sending messages to ourselves\n  ConnectionRef local_connection;\n\n  /**\n   * @defgroup AsyncMessenger internals\n   * @{\n   */\n  /**\n   * This wraps _lookup_conn.\n   */\n  AsyncConnectionRef lookup_conn(const entity_addr_t& k) {\n    Mutex::Locker l(lock);\n    return _lookup_conn(k);\n  }\n\n  int accept_conn(AsyncConnectionRef conn) {\n    Mutex::Locker l(lock);\n    auto it = conns.find(conn->peer_addr);\n    if (it != conns.end()) {\n      AsyncConnectionRef existing = it->second;\n\n      // lazy delete, see \"deleted_conns\"\n      // If conn already in, we will return 0\n      Mutex::Locker l(deleted_lock);\n      if (deleted_conns.erase(existing)) {\n        existing->get_perf_counter()->dec(l_msgr_active_connections);\n        conns.erase(it);\n      } else if (conn != existing) {\n        return -1;\n      }\n    }\n    conns[conn->peer_addr] = conn;\n    conn->get_perf_counter()->inc(l_msgr_active_connections);\n    accepting_conns.erase(conn);\n    return 0;\n  }\n\n  void learned_addr(const entity_addr_t &peer_addr_for_me);\n  void add_accept(Worker *w, ConnectedSocket cli_socket, entity_addr_t &addr);\n  NetworkStack *get_stack() {\n    return stack;\n  }\n\n  /**\n   * This wraps ms_deliver_get_authorizer. We use it for AsyncConnection.\n   */\n  AuthAuthorizer *get_authorizer(int peer_type, bool force_new) {\n    return ms_deliver_get_authorizer(peer_type, force_new);\n  }\n\n  /**\n   * This wraps ms_deliver_verify_authorizer; we use it for AsyncConnection.\n   */\n  bool verify_authorizer(Connection *con, int peer_type, int protocol, bufferlist& auth, bufferlist& auth_reply,\n                         bool& isvalid, CryptoKey& session_key,\n\t\t\t std::unique_ptr<AuthAuthorizerChallenge> *challenge) {\n    return ms_deliver_verify_authorizer(con, peer_type, protocol, auth,\n                                        auth_reply, isvalid, session_key, challenge);\n  }\n  /**\n   * Increment the global sequence for this AsyncMessenger and return it.\n   * This is for the connect protocol, although it doesn't hurt if somebody\n   * else calls it.\n   *\n   * @return a global sequence ID that nobody else has seen.\n   */\n  __u32 get_global_seq(__u32 old=0) {\n    ceph_spin_lock(&global_seq_lock);\n    if (old > global_seq)\n      global_seq = old;\n    __u32 ret = ++global_seq;\n    ceph_spin_unlock(&global_seq_lock);\n    return ret;\n  }\n  /**\n   * Get the protocol version we support for the given peer type: either\n   * a peer protocol (if it matches our own), the protocol version for the\n   * peer (if we're connecting), or our protocol version (if we're accepting).\n   */\n  int get_proto_version(int peer_type, bool connect) const;\n\n  /**\n   * Fill in the address and peer type for the local connection, which\n   * is used for delivering messages back to ourself.\n   */\n  void init_local_connection() {\n    Mutex::Locker l(lock);\n    _init_local_connection();\n  }\n\n  /**\n   * Unregister connection from `conns`\n   *\n   * See \"deleted_conns\"\n   */\n  void unregister_conn(AsyncConnectionRef conn) {\n    Mutex::Locker l(deleted_lock);\n    deleted_conns.insert(conn);\n\n    if (deleted_conns.size() >= ReapDeadConnectionThreshold) {\n      local_worker->center.dispatch_event_external(reap_handler);\n    }\n  }\n\n  /**\n   * Reap dead connection from `deleted_conns`\n   *\n   * @return the number of dead connections\n   *\n   * See \"deleted_conns\"\n   */\n  int reap_dead();\n\n  /**\n   * @} // AsyncMessenger Internals\n   */\n} ;\n\n#endif /* CEPH_ASYNCMESSENGER_H */\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#include <sys/types.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <netinet/ip.h>\n#include <netinet/tcp.h>\n#include <sys/uio.h>\n#include <limits.h>\n#include <poll.h>\n\n#include \"msg/Message.h\"\n#include \"Pipe.h\"\n#include \"SimpleMessenger.h\"\n\n#include \"common/debug.h\"\n#include \"common/errno.h\"\n#include \"common/valgrind.h\"\n\n// Below included to get encode_encrypt(); That probably should be in Crypto.h, instead\n\n#include \"auth/Crypto.h\"\n#include \"auth/cephx/CephxProtocol.h\"\n#include \"auth/AuthSessionHandler.h\"\n\n#include \"include/sock_compat.h\"\n\n// Constant to limit starting sequence number to 2^31.  Nothing special about it, just a big number.  PLR\n#define SEQ_MASK  0x7fffffff \n#define dout_subsys ceph_subsys_ms\n\n#undef dout_prefix\n#define dout_prefix *_dout << *this\nostream& Pipe::_pipe_prefix(std::ostream &out) const {\n  return out << \"-- \" << msgr->get_myinst().addr << \" >> \" << peer_addr << \" pipe(\" << this\n\t     << \" sd=\" << sd << \" :\" << port\n             << \" s=\" << state\n             << \" pgs=\" << peer_global_seq\n             << \" cs=\" << connect_seq\n             << \" l=\" << policy.lossy\n             << \" c=\" << connection_state\n             << \").\";\n}\n\nostream& operator<<(ostream &out, const Pipe &pipe) {\n  return pipe._pipe_prefix(out);\n}\n\n/**\n * The DelayedDelivery is for injecting delays into Message delivery off\n * the socket. It is only enabled if delays are requested, and if they\n * are then it pulls Messages off the DelayQueue and puts them into the\n * in_q (SimpleMessenger::dispatch_queue).\n * Please note that this probably has issues with Pipe shutdown and\n * replacement semantics. I've tried, but no guarantees.\n */\nclass Pipe::DelayedDelivery: public Thread {\n  Pipe *pipe;\n  std::deque< pair<utime_t,Message*> > delay_queue;\n  Mutex delay_lock;\n  Cond delay_cond;\n  int flush_count;\n  bool active_flush;\n  bool stop_delayed_delivery;\n  bool delay_dispatching; // we are in fast dispatch now\n  bool stop_fast_dispatching_flag; // we need to stop fast dispatching\n\npublic:\n  explicit DelayedDelivery(Pipe *p)\n    : pipe(p),\n      delay_lock(\"Pipe::DelayedDelivery::delay_lock\"), flush_count(0),\n      active_flush(false),\n      stop_delayed_delivery(false),\n      delay_dispatching(false),\n      stop_fast_dispatching_flag(false) { }\n  ~DelayedDelivery() override {\n    discard();\n  }\n  void *entry() override;\n  void queue(utime_t release, Message *m) {\n    Mutex::Locker l(delay_lock);\n    delay_queue.push_back(make_pair(release, m));\n    delay_cond.Signal();\n  }\n  void discard();\n  void flush();\n  bool is_flushing() {\n    Mutex::Locker l(delay_lock);\n    return flush_count > 0 || active_flush;\n  }\n  void wait_for_flush() {\n    Mutex::Locker l(delay_lock);\n    while (flush_count > 0 || active_flush)\n      delay_cond.Wait(delay_lock);\n  }\n  void stop() {\n    delay_lock.Lock();\n    stop_delayed_delivery = true;\n    delay_cond.Signal();\n    delay_lock.Unlock();\n  }\n  void steal_for_pipe(Pipe *new_owner) {\n    Mutex::Locker l(delay_lock);\n    pipe = new_owner;\n  }\n  /**\n   * We need to stop fast dispatching before we need to stop putting\n   * normal messages into the DispatchQueue.\n   */\n  void stop_fast_dispatching();\n};\n\n/**************************************\n * Pipe\n */\n\nPipe::Pipe(SimpleMessenger *r, int st, PipeConnection *con)\n  : RefCountedObject(r->cct),\n    reader_thread(this),\n    writer_thread(this),\n    delay_thread(NULL),\n    msgr(r),\n    conn_id(r->dispatch_queue.get_id()),\n    recv_ofs(0),\n    recv_len(0),\n    sd(-1), port(0),\n    peer_type(-1),\n    pipe_lock(\"SimpleMessenger::Pipe::pipe_lock\"),\n    state(st),\n    connection_state(NULL),\n    reader_running(false), reader_needs_join(false),\n    reader_dispatching(false), notify_on_dispatch_done(false),\n    writer_running(false),\n    in_q(&(r->dispatch_queue)),\n    send_keepalive(false),\n    send_keepalive_ack(false),\n    connect_seq(0), peer_global_seq(0),\n    out_seq(0), in_seq(0), in_seq_acked(0) {\n  ANNOTATE_BENIGN_RACE_SIZED(&sd, sizeof(sd), \"Pipe socket\");\n  ANNOTATE_BENIGN_RACE_SIZED(&state, sizeof(state), \"Pipe state\");\n  ANNOTATE_BENIGN_RACE_SIZED(&recv_len, sizeof(recv_len), \"Pipe recv_len\");\n  ANNOTATE_BENIGN_RACE_SIZED(&recv_ofs, sizeof(recv_ofs), \"Pipe recv_ofs\");\n  if (con) {\n    connection_state = con;\n    connection_state->reset_pipe(this);\n  } else {\n    connection_state = new PipeConnection(msgr->cct, msgr);\n    connection_state->pipe = get();\n  }\n\n  if (randomize_out_seq()) {\n    lsubdout(msgr->cct,ms,15) << \"Pipe(): Could not get random bytes to set seq number for session reset; set seq number to \" << out_seq << dendl;\n  }\n    \n\n  msgr->timeout = msgr->cct->_conf->ms_tcp_read_timeout * 1000; //convert to ms\n  if (msgr->timeout == 0)\n    msgr->timeout = -1;\n\n  recv_max_prefetch = msgr->cct->_conf->ms_tcp_prefetch_max_size;\n  recv_buf = new char[recv_max_prefetch];\n}\n\nPipe::~Pipe()\n{\n  assert(out_q.empty());\n  assert(sent.empty());\n  delete delay_thread;\n  delete[] recv_buf;\n}\n\nvoid Pipe::handle_ack(uint64_t seq)\n{\n  lsubdout(msgr->cct, ms, 15) << \"reader got ack seq \" << seq << dendl;\n  // trim sent list\n  while (!sent.empty() &&\n\t sent.front()->get_seq() <= seq) {\n    Message *m = sent.front();\n    sent.pop_front();\n    lsubdout(msgr->cct, ms, 10) << \"reader got ack seq \"\n\t\t\t\t<< seq << \" >= \" << m->get_seq() << \" on \" << m << \" \" << *m << dendl;\n    m->put();\n  }\n}\n\nvoid Pipe::start_reader()\n{\n  assert(pipe_lock.is_locked());\n  assert(!reader_running);\n  if (reader_needs_join) {\n    reader_thread.join();\n    reader_needs_join = false;\n  }\n  reader_running = true;\n  reader_thread.create(\"ms_pipe_read\", msgr->cct->_conf->ms_rwthread_stack_bytes);\n}\n\nvoid Pipe::maybe_start_delay_thread()\n{\n  if (!delay_thread) {\n    auto pos = msgr->cct->_conf->get_val<std::string>(\"ms_inject_delay_type\").find(ceph_entity_type_name(connection_state->peer_type));\n    if (pos != string::npos) {\n      lsubdout(msgr->cct, ms, 1) << \"setting up a delay queue on Pipe \" << this << dendl;\n      delay_thread = new DelayedDelivery(this);\n      delay_thread->create(\"ms_pipe_delay\");\n    }\n  }\n}\n\nvoid Pipe::start_writer()\n{\n  assert(pipe_lock.is_locked());\n  assert(!writer_running);\n  writer_running = true;\n  writer_thread.create(\"ms_pipe_write\", msgr->cct->_conf->ms_rwthread_stack_bytes);\n}\n\nvoid Pipe::join_reader()\n{\n  if (!reader_running)\n    return;\n  cond.Signal();\n  pipe_lock.Unlock();\n  reader_thread.join();\n  pipe_lock.Lock();\n  reader_needs_join = false;\n}\n\nvoid Pipe::DelayedDelivery::discard()\n{\n  lgeneric_subdout(pipe->msgr->cct, ms, 20) << *pipe << \"DelayedDelivery::discard\" << dendl;\n  Mutex::Locker l(delay_lock);\n  while (!delay_queue.empty()) {\n    Message *m = delay_queue.front().second;\n    pipe->in_q->dispatch_throttle_release(m->get_dispatch_throttle_size());\n    m->put();\n    delay_queue.pop_front();\n  }\n}\n\nvoid Pipe::DelayedDelivery::flush()\n{\n  lgeneric_subdout(pipe->msgr->cct, ms, 20) << *pipe << \"DelayedDelivery::flush\" << dendl;\n  Mutex::Locker l(delay_lock);\n  flush_count = delay_queue.size();\n  delay_cond.Signal();\n}\n\nvoid *Pipe::DelayedDelivery::entry()\n{\n  Mutex::Locker locker(delay_lock);\n  lgeneric_subdout(pipe->msgr->cct, ms, 20) << *pipe << \"DelayedDelivery::entry start\" << dendl;\n\n  while (!stop_delayed_delivery) {\n    if (delay_queue.empty()) {\n      lgeneric_subdout(pipe->msgr->cct, ms, 30) << *pipe << \"DelayedDelivery::entry sleeping on delay_cond because delay queue is empty\" << dendl;\n      delay_cond.Wait(delay_lock);\n      continue;\n    }\n    utime_t release = delay_queue.front().first;\n    Message *m = delay_queue.front().second;\n    string delay_msg_type = pipe->msgr->cct->_conf->ms_inject_delay_msg_type;\n    if (!flush_count &&\n        (release > ceph_clock_now() &&\n         (delay_msg_type.empty() || m->get_type_name() == delay_msg_type))) {\n      lgeneric_subdout(pipe->msgr->cct, ms, 10) << *pipe << \"DelayedDelivery::entry sleeping on delay_cond until \" << release << dendl;\n      delay_cond.WaitUntil(delay_lock, release);\n      continue;\n    }\n    lgeneric_subdout(pipe->msgr->cct, ms, 10) << *pipe << \"DelayedDelivery::entry dequeuing message \" << m << \" for delivery, past \" << release << dendl;\n    delay_queue.pop_front();\n    if (flush_count > 0) {\n      --flush_count;\n      active_flush = true;\n    }\n    if (pipe->in_q->can_fast_dispatch(m)) {\n      if (!stop_fast_dispatching_flag) {\n        delay_dispatching = true;\n        delay_lock.Unlock();\n        pipe->in_q->fast_dispatch(m);\n        delay_lock.Lock();\n        delay_dispatching = false;\n        if (stop_fast_dispatching_flag) {\n          // we need to let the stopping thread proceed\n          delay_cond.Signal();\n          delay_lock.Unlock();\n          delay_lock.Lock();\n        }\n      }\n    } else {\n      pipe->in_q->enqueue(m, m->get_priority(), pipe->conn_id);\n    }\n    active_flush = false;\n  }\n  lgeneric_subdout(pipe->msgr->cct, ms, 20) << *pipe << \"DelayedDelivery::entry stop\" << dendl;\n  return NULL;\n}\n\nvoid Pipe::DelayedDelivery::stop_fast_dispatching() {\n  Mutex::Locker l(delay_lock);\n  stop_fast_dispatching_flag = true;\n  while (delay_dispatching)\n    delay_cond.Wait(delay_lock);\n}\n\n\nint Pipe::accept()\n{\n  ldout(msgr->cct,10) << \"accept\" << dendl;\n  assert(pipe_lock.is_locked());\n  assert(state == STATE_ACCEPTING);\n\n  pipe_lock.Unlock();\n\n  // vars\n  bufferlist addrs;\n  entity_addr_t socket_addr;\n  socklen_t len;\n  int r;\n  char banner[strlen(CEPH_BANNER)+1];\n  bufferlist addrbl;\n  ceph_msg_connect connect;\n  ceph_msg_connect_reply reply;\n  Pipe *existing = 0;\n  bufferptr bp;\n  bufferlist authorizer, authorizer_reply;\n  bool authorizer_valid;\n  uint64_t feat_missing;\n  bool replaced = false;\n  // this variable denotes if the connection attempt from peer is a hard \n  // reset or not, it is true if there is an existing connection and the\n  // connection sequence from peer is equal to zero\n  bool is_reset_from_peer = false;\n  CryptoKey session_key;\n  int removed; // single-use down below\n\n  // this should roughly mirror pseudocode at\n  //  http://ceph.com/wiki/Messaging_protocol\n  int reply_tag = 0;\n  uint64_t existing_seq = -1;\n\n  // used for reading in the remote acked seq on connect\n  uint64_t newly_acked_seq = 0;\n\n  bool need_challenge = false;\n  bool had_challenge = false;\n  std::unique_ptr<AuthAuthorizerChallenge> authorizer_challenge;\n\n  recv_reset();\n\n  set_socket_options();\n\n  // announce myself.\n  r = tcp_write(CEPH_BANNER, strlen(CEPH_BANNER));\n  if (r < 0) {\n    ldout(msgr->cct,10) << \"accept couldn't write banner\" << dendl;\n    goto fail_unlocked;\n  }\n\n  // and my addr\n  ::encode(msgr->my_inst.addr, addrs, 0);  // legacy\n\n  port = msgr->my_inst.addr.get_port();\n\n  // and peer's socket addr (they might not know their ip)\n  sockaddr_storage ss;\n  len = sizeof(ss);\n  r = ::getpeername(sd, (sockaddr*)&ss, &len);\n  if (r < 0) {\n    ldout(msgr->cct,0) << \"accept failed to getpeername \" << cpp_strerror(errno) << dendl;\n    goto fail_unlocked;\n  }\n  socket_addr.set_sockaddr((sockaddr*)&ss);\n  ::encode(socket_addr, addrs, 0);  // legacy\n\n  r = tcp_write(addrs.c_str(), addrs.length());\n  if (r < 0) {\n    ldout(msgr->cct,10) << \"accept couldn't write my+peer addr\" << dendl;\n    goto fail_unlocked;\n  }\n\n  ldout(msgr->cct,1) << \"accept sd=\" << sd << \" \" << socket_addr << dendl;\n  \n  // identify peer\n  if (tcp_read(banner, strlen(CEPH_BANNER)) < 0) {\n    ldout(msgr->cct,10) << \"accept couldn't read banner\" << dendl;\n    goto fail_unlocked;\n  }\n  if (memcmp(banner, CEPH_BANNER, strlen(CEPH_BANNER))) {\n    banner[strlen(CEPH_BANNER)] = 0;\n    ldout(msgr->cct,1) << \"accept peer sent bad banner '\" << banner << \"' (should be '\" << CEPH_BANNER << \"')\" << dendl;\n    goto fail_unlocked;\n  }\n  {\n    bufferptr tp(sizeof(ceph_entity_addr));\n    addrbl.push_back(std::move(tp));\n  }\n  if (tcp_read(addrbl.c_str(), addrbl.length()) < 0) {\n    ldout(msgr->cct,10) << \"accept couldn't read peer_addr\" << dendl;\n    goto fail_unlocked;\n  }\n  {\n    bufferlist::iterator ti = addrbl.begin();\n    ::decode(peer_addr, ti);\n  }\n\n  ldout(msgr->cct,10) << \"accept peer addr is \" << peer_addr << dendl;\n  if (peer_addr.is_blank_ip()) {\n    // peer apparently doesn't know what ip they have; figure it out for them.\n    int port = peer_addr.get_port();\n    peer_addr.u = socket_addr.u;\n    peer_addr.set_port(port);\n    ldout(msgr->cct,0) << \"accept peer addr is really \" << peer_addr\n\t    << \" (socket is \" << socket_addr << \")\" << dendl;\n  }\n  set_peer_addr(peer_addr);  // so that connection_state gets set up\n  \n  while (1) {\n    if (tcp_read((char*)&connect, sizeof(connect)) < 0) {\n      ldout(msgr->cct,10) << \"accept couldn't read connect\" << dendl;\n      goto fail_unlocked;\n    }\n\n    authorizer.clear();\n    if (connect.authorizer_len) {\n      bp = buffer::create(connect.authorizer_len);\n      if (tcp_read(bp.c_str(), connect.authorizer_len) < 0) {\n        ldout(msgr->cct,10) << \"accept couldn't read connect authorizer\" << dendl;\n        goto fail_unlocked;\n      }\n      authorizer.push_back(std::move(bp));\n      authorizer_reply.clear();\n    }\n\n    ldout(msgr->cct,20) << \"accept got peer connect_seq \" << connect.connect_seq\n\t     << \" global_seq \" << connect.global_seq\n\t     << dendl;\n    \n    msgr->lock.Lock();   // FIXME\n    pipe_lock.Lock();\n    if (msgr->dispatch_queue.stop)\n      goto shutting_down;\n    if (state != STATE_ACCEPTING) {\n      goto shutting_down;\n    }\n\n    // note peer's type, flags\n    set_peer_type(connect.host_type);\n    policy = msgr->get_policy(connect.host_type);\n    ldout(msgr->cct,10) << \"accept of host_type \" << connect.host_type\n\t\t\t<< \", policy.lossy=\" << policy.lossy\n\t\t\t<< \" policy.server=\" << policy.server\n\t\t\t<< \" policy.standby=\" << policy.standby\n\t\t\t<< \" policy.resetcheck=\" << policy.resetcheck\n\t\t\t<< dendl;\n\n    memset(&reply, 0, sizeof(reply));\n    reply.protocol_version = msgr->get_proto_version(peer_type, false);\n    msgr->lock.Unlock();\n\n    // mismatch?\n    ldout(msgr->cct,10) << \"accept my proto \" << reply.protocol_version\n\t     << \", their proto \" << connect.protocol_version << dendl;\n    if (connect.protocol_version != reply.protocol_version) {\n      reply.tag = CEPH_MSGR_TAG_BADPROTOVER;\n      goto reply;\n    }\n\n    // require signatures for cephx?\n    if (connect.authorizer_protocol == CEPH_AUTH_CEPHX) {\n      if (peer_type == CEPH_ENTITY_TYPE_OSD ||\n\t  peer_type == CEPH_ENTITY_TYPE_MDS ||\n\t  peer_type == CEPH_ENTITY_TYPE_MGR) {\n\tif (msgr->cct->_conf->cephx_require_signatures ||\n\t    msgr->cct->_conf->cephx_cluster_require_signatures) {\n\t  ldout(msgr->cct,10) << \"using cephx, requiring MSG_AUTH feature bit for cluster\" << dendl;\n\t  policy.features_required |= CEPH_FEATURE_MSG_AUTH;\n\t}\n\tif (msgr->cct->_conf->cephx_require_version >= 2 ||\n\t    msgr->cct->_conf->cephx_cluster_require_version >= 2) {\n\t  ldout(msgr->cct,10) << \"using cephx, requiring cephx v2 feature bit for cluster\" << dendl;\n\t  policy.features_required |= CEPH_FEATUREMASK_CEPHX_V2;\n\t}\n      } else {\n\tif (msgr->cct->_conf->cephx_require_signatures ||\n\t    msgr->cct->_conf->cephx_service_require_signatures) {\n\t  ldout(msgr->cct,10) << \"using cephx, requiring MSG_AUTH feature bit for service\" << dendl;\n\t  policy.features_required |= CEPH_FEATURE_MSG_AUTH;\n\t}\n\tif (msgr->cct->_conf->cephx_require_version >= 2 ||\n\t    msgr->cct->_conf->cephx_service_require_version >= 2) {\n\t  ldout(msgr->cct,10) << \"using cephx, requiring cephx v2 feature bit for cluster\" << dendl;\n\t  policy.features_required |= CEPH_FEATUREMASK_CEPHX_V2;\n\t}\n      }\n    }\n\n    feat_missing = policy.features_required & ~(uint64_t)connect.features;\n    if (feat_missing) {\n      ldout(msgr->cct,1) << \"peer missing required features \" << std::hex << feat_missing << std::dec << dendl;\n      reply.tag = CEPH_MSGR_TAG_FEATURES;\n      goto reply;\n    }\n    \n    // Check the authorizer.  If not good, bail out.\n\n    pipe_lock.Unlock();\n\n    need_challenge = HAVE_FEATURE(connect.features, CEPHX_V2);\n    had_challenge = (bool)authorizer_challenge;\n    authorizer_reply.clear();\n    if (!msgr->verify_authorizer(\n\t  connection_state.get(), peer_type, connect.authorizer_protocol, authorizer,\n\t  authorizer_reply, authorizer_valid, session_key,\n\t  need_challenge ? &authorizer_challenge : nullptr) ||\n\t!authorizer_valid) {\n      pipe_lock.Lock();\n      if (state != STATE_ACCEPTING)\n\tgoto shutting_down_msgr_unlocked;\n      if (!had_challenge && need_challenge && authorizer_challenge) {\n\tldout(msgr->cct,0) << \"accept: challenging authorizer \"\n\t\t\t   << authorizer_reply.length()\n\t\t\t   << \" bytes\" << dendl;\n\tassert(authorizer_reply.length());\n\treply.tag = CEPH_MSGR_TAG_CHALLENGE_AUTHORIZER;\n      } else {\n\tldout(msgr->cct,0) << \"accept: got bad authorizer\" << dendl;\n\treply.tag = CEPH_MSGR_TAG_BADAUTHORIZER;\n      }\n      session_security.reset();\n      goto reply;\n    } \n\n    // We've verified the authorizer for this pipe, so set up the session security structure.  PLR\n\n    ldout(msgr->cct,10) << \"accept:  setting up session_security.\" << dendl;\n\n  retry_existing_lookup:\n    msgr->lock.Lock();\n    pipe_lock.Lock();\n    if (msgr->dispatch_queue.stop)\n      goto shutting_down;\n    if (state != STATE_ACCEPTING)\n      goto shutting_down;\n    \n    // existing?\n    existing = msgr->_lookup_pipe(peer_addr);\n    if (existing) {\n      existing->pipe_lock.Lock(true);  // skip lockdep check (we are locking a second Pipe here)\n      if (existing->reader_dispatching) {\n\t/** we need to wait, or we can deadlock if downstream\n\t *  fast_dispatchers are (naughtily!) waiting on resources\n\t *  held by somebody trying to make use of the SimpleMessenger lock.\n\t *  So drop locks, wait, and retry. It just looks like a slow network\n\t *  to everybody else.\n\t *\n\t *  We take a ref to existing here since it might get reaped before we\n\t *  wake up (see bug #15870).  We can be confident that it lived until\n\t *  locked it since we held the msgr lock from _lookup_pipe through to\n\t *  locking existing->lock and checking reader_dispatching.\n\t */\n\texisting->get();\n\tpipe_lock.Unlock();\n\tmsgr->lock.Unlock();\n\texisting->notify_on_dispatch_done = true;\n\twhile (existing->reader_dispatching)\n\t  existing->cond.Wait(existing->pipe_lock);\n\texisting->pipe_lock.Unlock();\n\texisting->put();\n\texisting = nullptr;\n\tgoto retry_existing_lookup;\n      }\n\n      if (connect.global_seq < existing->peer_global_seq) {\n\tldout(msgr->cct,10) << \"accept existing \" << existing << \".gseq \" << existing->peer_global_seq\n\t\t << \" > \" << connect.global_seq << \", RETRY_GLOBAL\" << dendl;\n\treply.tag = CEPH_MSGR_TAG_RETRY_GLOBAL;\n\treply.global_seq = existing->peer_global_seq;  // so we can send it below..\n\texisting->pipe_lock.Unlock();\n\tmsgr->lock.Unlock();\n\tgoto reply;\n      } else {\n\tldout(msgr->cct,10) << \"accept existing \" << existing << \".gseq \" << existing->peer_global_seq\n\t\t << \" <= \" << connect.global_seq << \", looks ok\" << dendl;\n      }\n      \n      if (existing->policy.lossy) {\n\tldout(msgr->cct,0) << \"accept replacing existing (lossy) channel (new one lossy=\"\n\t        << policy.lossy << \")\" << dendl;\n\texisting->was_session_reset();\n\tgoto replace;\n      }\n\n      ldout(msgr->cct,0) << \"accept connect_seq \" << connect.connect_seq\n\t\t\t << \" vs existing \" << existing->connect_seq\n\t\t\t << \" state \" << existing->get_state_name() << dendl;\n\n      if (connect.connect_seq == 0 && existing->connect_seq > 0) {\n\tldout(msgr->cct,0) << \"accept peer reset, then tried to connect to us, replacing\" << dendl;\n        // this is a hard reset from peer\n        is_reset_from_peer = true;\n\tif (policy.resetcheck)\n\t  existing->was_session_reset(); // this resets out_queue, msg_ and connect_seq #'s\n\tgoto replace;\n      }\n\n      if (connect.connect_seq < existing->connect_seq) {\n\t// old attempt, or we sent READY but they didn't get it.\n\tldout(msgr->cct,10) << \"accept existing \" << existing << \".cseq \" << existing->connect_seq\n\t\t\t    << \" > \" << connect.connect_seq << \", RETRY_SESSION\" << dendl;\n\tgoto retry_session;\n      }\n\n      if (connect.connect_seq == existing->connect_seq) {\n\t// if the existing connection successfully opened, and/or\n\t// subsequently went to standby, then the peer should bump\n\t// their connect_seq and retry: this is not a connection race\n\t// we need to resolve here.\n\tif (existing->state == STATE_OPEN ||\n\t    existing->state == STATE_STANDBY) {\n\t  ldout(msgr->cct,10) << \"accept connection race, existing \" << existing\n\t\t\t      << \".cseq \" << existing->connect_seq\n\t\t\t      << \" == \" << connect.connect_seq\n\t\t\t      << \", OPEN|STANDBY, RETRY_SESSION\" << dendl;\n\t  goto retry_session;\n\t}\n\n\t// connection race?\n\tif (peer_addr < msgr->my_inst.addr ||\n\t    existing->policy.server) {\n\t  // incoming wins\n\t  ldout(msgr->cct,10) << \"accept connection race, existing \" << existing << \".cseq \" << existing->connect_seq\n\t\t   << \" == \" << connect.connect_seq << \", or we are server, replacing my attempt\" << dendl;\n\t  if (!(existing->state == STATE_CONNECTING ||\n\t\texisting->state == STATE_WAIT))\n\t    lderr(msgr->cct) << \"accept race bad state, would replace, existing=\"\n\t\t\t     << existing->get_state_name()\n\t\t\t     << \" \" << existing << \".cseq=\" << existing->connect_seq\n\t\t\t     << \" == \" << connect.connect_seq\n\t\t\t     << dendl;\n\t  assert(existing->state == STATE_CONNECTING ||\n\t\t existing->state == STATE_WAIT);\n\t  goto replace;\n\t} else {\n\t  // our existing outgoing wins\n\t  ldout(msgr->cct,10) << \"accept connection race, existing \" << existing << \".cseq \" << existing->connect_seq\n\t\t   << \" == \" << connect.connect_seq << \", sending WAIT\" << dendl;\n\t  assert(peer_addr > msgr->my_inst.addr);\n\t  if (!(existing->state == STATE_CONNECTING))\n\t    lderr(msgr->cct) << \"accept race bad state, would send wait, existing=\"\n\t\t\t     << existing->get_state_name()\n\t\t\t     << \" \" << existing << \".cseq=\" << existing->connect_seq\n\t\t\t     << \" == \" << connect.connect_seq\n\t\t\t     << dendl;\n\t  assert(existing->state == STATE_CONNECTING);\n\t  // make sure our outgoing connection will follow through\n\t  existing->_send_keepalive();\n\t  reply.tag = CEPH_MSGR_TAG_WAIT;\n\t  existing->pipe_lock.Unlock();\n\t  msgr->lock.Unlock();\n\t  goto reply;\n\t}\n      }\n\n      assert(connect.connect_seq > existing->connect_seq);\n      assert(connect.global_seq >= existing->peer_global_seq);\n      if (policy.resetcheck &&   // RESETSESSION only used by servers; peers do not reset each other\n\t  existing->connect_seq == 0) {\n\tldout(msgr->cct,0) << \"accept we reset (peer sent cseq \" << connect.connect_seq \n\t\t << \", \" << existing << \".cseq = \" << existing->connect_seq\n\t\t << \"), sending RESETSESSION\" << dendl;\n\treply.tag = CEPH_MSGR_TAG_RESETSESSION;\n\tmsgr->lock.Unlock();\n\texisting->pipe_lock.Unlock();\n\tgoto reply;\n      }\n\n      // reconnect\n      ldout(msgr->cct,10) << \"accept peer sent cseq \" << connect.connect_seq\n\t       << \" > \" << existing->connect_seq << dendl;\n      goto replace;\n    } // existing\n    else if (connect.connect_seq > 0) {\n      // we reset, and they are opening a new session\n      ldout(msgr->cct,0) << \"accept we reset (peer sent cseq \" << connect.connect_seq << \"), sending RESETSESSION\" << dendl;\n      msgr->lock.Unlock();\n      reply.tag = CEPH_MSGR_TAG_RESETSESSION;\n      goto reply;\n    } else {\n      // new session\n      ldout(msgr->cct,10) << \"accept new session\" << dendl;\n      existing = NULL;\n      goto open;\n    }\n    ceph_abort();\n\n  retry_session:\n    assert(existing->pipe_lock.is_locked());\n    assert(pipe_lock.is_locked());\n    reply.tag = CEPH_MSGR_TAG_RETRY_SESSION;\n    reply.connect_seq = existing->connect_seq + 1;\n    existing->pipe_lock.Unlock();\n    msgr->lock.Unlock();\n    goto reply;    \n\n  reply:\n    assert(pipe_lock.is_locked());\n    reply.features = ((uint64_t)connect.features & policy.features_supported) | policy.features_required;\n    reply.authorizer_len = authorizer_reply.length();\n    pipe_lock.Unlock();\n    r = tcp_write((char*)&reply, sizeof(reply));\n    if (r < 0)\n      goto fail_unlocked;\n    if (reply.authorizer_len) {\n      r = tcp_write(authorizer_reply.c_str(), authorizer_reply.length());\n      if (r < 0)\n\tgoto fail_unlocked;\n    }\n  }\n  \n replace:\n  assert(existing->pipe_lock.is_locked());\n  assert(pipe_lock.is_locked());\n  // if it is a hard reset from peer, we don't need a round-trip to negotiate in/out sequence\n  if ((connect.features & CEPH_FEATURE_RECONNECT_SEQ) && !is_reset_from_peer) {\n    reply_tag = CEPH_MSGR_TAG_SEQ;\n    existing_seq = existing->in_seq;\n  }\n  ldout(msgr->cct,10) << \"accept replacing \" << existing << dendl;\n  existing->stop();\n  existing->unregister_pipe();\n  replaced = true;\n\n  if (existing->policy.lossy) {\n    // disconnect from the Connection\n    assert(existing->connection_state);\n    if (existing->connection_state->clear_pipe(existing))\n      msgr->dispatch_queue.queue_reset(existing->connection_state.get());\n  } else {\n    // queue a reset on the new connection, which we're dumping for the old\n    msgr->dispatch_queue.queue_reset(connection_state.get());\n\n    // drop my Connection, and take a ref to the existing one. do not\n    // clear existing->connection_state, since read_message and\n    // write_message both dereference it without pipe_lock.\n    connection_state = existing->connection_state;\n\n    // make existing Connection reference us\n    connection_state->reset_pipe(this);\n\n    if (existing->delay_thread) {\n      existing->delay_thread->steal_for_pipe(this);\n      delay_thread = existing->delay_thread;\n      existing->delay_thread = NULL;\n      delay_thread->flush();\n    }\n\n    // steal incoming queue\n    uint64_t replaced_conn_id = conn_id;\n    conn_id = existing->conn_id;\n    existing->conn_id = replaced_conn_id;\n\n    // reset the in_seq if this is a hard reset from peer,\n    // otherwise we respect our original connection's value\n    in_seq = is_reset_from_peer ? 0 : existing->in_seq;\n    in_seq_acked = in_seq;\n\n    // steal outgoing queue and out_seq\n    existing->requeue_sent();\n    out_seq = existing->out_seq;\n    ldout(msgr->cct,10) << \"accept re-queuing on out_seq \" << out_seq << \" in_seq \" << in_seq << dendl;\n    for (map<int, list<Message*> >::iterator p = existing->out_q.begin();\n         p != existing->out_q.end();\n         ++p)\n      out_q[p->first].splice(out_q[p->first].begin(), p->second);\n  }\n  existing->stop_and_wait();\n  existing->pipe_lock.Unlock();\n\n open:\n  // open\n  assert(pipe_lock.is_locked());\n  connect_seq = connect.connect_seq + 1;\n  peer_global_seq = connect.global_seq;\n  assert(state == STATE_ACCEPTING);\n  state = STATE_OPEN;\n  ldout(msgr->cct,10) << \"accept success, connect_seq = \" << connect_seq << \", sending READY\" << dendl;\n\n  // send READY reply\n  reply.tag = (reply_tag ? reply_tag : CEPH_MSGR_TAG_READY);\n  reply.features = policy.features_supported;\n  reply.global_seq = msgr->get_global_seq();\n  reply.connect_seq = connect_seq;\n  reply.flags = 0;\n  reply.authorizer_len = authorizer_reply.length();\n  if (policy.lossy)\n    reply.flags = reply.flags | CEPH_MSG_CONNECT_LOSSY;\n\n  connection_state->set_features((uint64_t)reply.features & (uint64_t)connect.features);\n  ldout(msgr->cct,10) << \"accept features \" << connection_state->get_features() << dendl;\n\n  session_security.reset(\n      get_auth_session_handler(msgr->cct,\n\t\t\t       connect.authorizer_protocol,\n\t\t\t       session_key,\n\t\t\t       connection_state->get_features()));\n\n  // notify\n  msgr->dispatch_queue.queue_accept(connection_state.get());\n  msgr->ms_deliver_handle_fast_accept(connection_state.get());\n\n  // ok!\n  if (msgr->dispatch_queue.stop)\n    goto shutting_down;\n  removed = msgr->accepting_pipes.erase(this);\n  assert(removed == 1);\n  register_pipe();\n  msgr->lock.Unlock();\n  pipe_lock.Unlock();\n\n  r = tcp_write((char*)&reply, sizeof(reply));\n  if (r < 0) {\n    goto fail_registered;\n  }\n\n  if (reply.authorizer_len) {\n    r = tcp_write(authorizer_reply.c_str(), authorizer_reply.length());\n    if (r < 0) {\n      goto fail_registered;\n    }\n  }\n\n  if (reply_tag == CEPH_MSGR_TAG_SEQ) {\n    if (tcp_write((char*)&existing_seq, sizeof(existing_seq)) < 0) {\n      ldout(msgr->cct,2) << \"accept write error on in_seq\" << dendl;\n      goto fail_registered;\n    }\n    if (tcp_read((char*)&newly_acked_seq, sizeof(newly_acked_seq)) < 0) {\n      ldout(msgr->cct,2) << \"accept read error on newly_acked_seq\" << dendl;\n      goto fail_registered;\n    }\n  }\n\n  pipe_lock.Lock();\n  discard_requeued_up_to(newly_acked_seq);\n  if (state != STATE_CLOSED) {\n    ldout(msgr->cct,10) << \"accept starting writer, state \" << get_state_name() << dendl;\n    start_writer();\n  }\n  ldout(msgr->cct,20) << \"accept done\" << dendl;\n\n  maybe_start_delay_thread();\n\n  return 0;   // success.\n\n fail_registered:\n  ldout(msgr->cct, 10) << \"accept fault after register\" << dendl;\n\n  if (msgr->cct->_conf->ms_inject_internal_delays) {\n    ldout(msgr->cct, 10) << \" sleep for \" << msgr->cct->_conf->ms_inject_internal_delays << dendl;\n    utime_t t;\n    t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n    t.sleep();\n  }\n\n fail_unlocked:\n  pipe_lock.Lock();\n  if (state != STATE_CLOSED) {\n    bool queued = is_queued();\n    ldout(msgr->cct, 10) << \"  queued = \" << (int)queued << dendl;\n    if (queued) {\n      state = policy.server ? STATE_STANDBY : STATE_CONNECTING;\n    } else if (replaced) {\n      state = STATE_STANDBY;\n    } else {\n      state = STATE_CLOSED;\n      state_closed = true;\n    }\n    fault();\n    if (queued || replaced)\n      start_writer();\n  }\n  return -1;\n\n shutting_down:\n  msgr->lock.Unlock();\n shutting_down_msgr_unlocked:\n  assert(pipe_lock.is_locked());\n\n  if (msgr->cct->_conf->ms_inject_internal_delays) {\n    ldout(msgr->cct, 10) << \" sleep for \" << msgr->cct->_conf->ms_inject_internal_delays << dendl;\n    utime_t t;\n    t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n    t.sleep();\n  }\n\n  state = STATE_CLOSED;\n  state_closed = true;\n  fault();\n  return -1;\n}\n\nvoid Pipe::set_socket_options()\n{\n  // disable Nagle algorithm?\n  if (msgr->cct->_conf->ms_tcp_nodelay) {\n    int flag = 1;\n    int r = ::setsockopt(sd, IPPROTO_TCP, TCP_NODELAY, (char*)&flag, sizeof(flag));\n    if (r < 0) {\n      r = -errno;\n      ldout(msgr->cct,0) << \"couldn't set TCP_NODELAY: \"\n                         << cpp_strerror(r) << dendl;\n    }\n  }\n  if (msgr->cct->_conf->ms_tcp_rcvbuf) {\n    int size = msgr->cct->_conf->ms_tcp_rcvbuf;\n    int r = ::setsockopt(sd, SOL_SOCKET, SO_RCVBUF, (void*)&size, sizeof(size));\n    if (r < 0)  {\n      r = -errno;\n      ldout(msgr->cct,0) << \"couldn't set SO_RCVBUF to \" << size\n                         << \": \" << cpp_strerror(r) << dendl;\n    }\n  }\n\n  // block ESIGPIPE\n#ifdef CEPH_USE_SO_NOSIGPIPE\n  int val = 1;\n  int r = ::setsockopt(sd, SOL_SOCKET, SO_NOSIGPIPE, (void*)&val, sizeof(val));\n  if (r) {\n    r = -errno;\n    ldout(msgr->cct,0) << \"couldn't set SO_NOSIGPIPE: \"\n                       << cpp_strerror(r) << dendl;\n  }\n#endif\n\n#ifdef SO_PRIORITY\n  int prio = msgr->get_socket_priority();\n  if (prio >= 0) {\n    int r = -1;\n#ifdef IPTOS_CLASS_CS6\n    int iptos = IPTOS_CLASS_CS6;\n    int addr_family = 0;\n    if (!peer_addr.is_blank_ip()) {\n      addr_family = peer_addr.get_family();\n    } else {\n      addr_family = msgr->get_myaddr().get_family();\n    }\n    switch (addr_family) {\n    case AF_INET:\n      r = ::setsockopt(sd, IPPROTO_IP, IP_TOS, &iptos, sizeof(iptos));\n      break;\n    case AF_INET6:\n      r = ::setsockopt(sd, IPPROTO_IPV6, IPV6_TCLASS, &iptos, sizeof(iptos));\n      break;\n    default:\n      lderr(msgr->cct) << \"couldn't set ToS of unknown family (\"\n\t\t       << addr_family << \")\"\n\t\t       << \" to \" << iptos << dendl;\n      return;\n    }\n    if (r < 0) {\n      r = -errno;\n      ldout(msgr->cct,0) << \"couldn't set TOS to \" << iptos\n\t\t\t << \": \" << cpp_strerror(r) << dendl;\n    }\n#endif\n    // setsockopt(IPTOS_CLASS_CS6) sets the priority of the socket as 0.\n    // See http://goo.gl/QWhvsD and http://goo.gl/laTbjT\n    // We need to call setsockopt(SO_PRIORITY) after it.\n    r = ::setsockopt(sd, SOL_SOCKET, SO_PRIORITY, &prio, sizeof(prio));\n    if (r < 0) {\n      r = -errno;\n      ldout(msgr->cct,0) << \"couldn't set SO_PRIORITY to \" << prio\n                         << \": \" << cpp_strerror(r) << dendl;\n    }\n  }\n#endif\n}\n\nint Pipe::connect()\n{\n  bool got_bad_auth = false;\n\n  ldout(msgr->cct,10) << \"connect \" << connect_seq << dendl;\n  assert(pipe_lock.is_locked());\n\n  __u32 cseq = connect_seq;\n  __u32 gseq = msgr->get_global_seq();\n\n  // stop reader thread\n  join_reader();\n\n  pipe_lock.Unlock();\n  \n  char tag = -1;\n  int rc = -1;\n  struct msghdr msg;\n  struct iovec msgvec[2];\n  int msglen;\n  char banner[strlen(CEPH_BANNER) + 1];  // extra byte makes coverity happy\n  entity_addr_t paddr;\n  entity_addr_t peer_addr_for_me, socket_addr;\n  AuthAuthorizer *authorizer = NULL;\n  bufferlist addrbl, myaddrbl;\n  const md_config_t *conf = msgr->cct->_conf;\n\n  // close old socket.  this is safe because we stopped the reader thread above.\n  if (sd >= 0)\n    ::close(sd);\n\n  // create socket?\n  sd = ::socket(peer_addr.get_family(), SOCK_STREAM, 0);\n  if (sd < 0) {\n    rc = -errno;\n    lderr(msgr->cct) << \"connect couldn't create socket \" << cpp_strerror(rc) << dendl;\n    goto fail;\n  }\n\n  recv_reset();\n\n  set_socket_options();\n\n  {\n    entity_addr_t addr2bind = msgr->get_myaddr();\n    if (msgr->cct->_conf->ms_bind_before_connect && (!addr2bind.is_blank_ip())) {\n      addr2bind.set_port(0);\n      int r = ::bind(sd , addr2bind.get_sockaddr(), addr2bind.get_sockaddr_len());\n      if (r < 0) {\n        ldout(msgr->cct,2) << \"client bind error \" << \", \" << cpp_strerror(errno) << dendl;\n        goto fail;\n      }\n    }\n  }\n\n  // connect!\n  ldout(msgr->cct,10) << \"connecting to \" << peer_addr << dendl;\n  rc = ::connect(sd, peer_addr.get_sockaddr(), peer_addr.get_sockaddr_len());\n  if (rc < 0) {\n    int stored_errno = errno;\n    ldout(msgr->cct,2) << \"connect error \" << peer_addr\n\t     << \", \" << cpp_strerror(stored_errno) << dendl;\n    if (stored_errno == ECONNREFUSED) {\n      ldout(msgr->cct, 2) << \"connection refused!\" << dendl;\n      msgr->dispatch_queue.queue_refused(connection_state.get());\n    }\n    goto fail;\n  }\n\n  // verify banner\n  // FIXME: this should be non-blocking, or in some other way verify the banner as we get it.\n  rc = tcp_read((char*)&banner, strlen(CEPH_BANNER));\n  if (rc < 0) {\n    ldout(msgr->cct,2) << \"connect couldn't read banner, \" << cpp_strerror(rc) << dendl;\n    goto fail;\n  }\n  if (memcmp(banner, CEPH_BANNER, strlen(CEPH_BANNER))) {\n    ldout(msgr->cct,0) << \"connect protocol error (bad banner) on peer \" << peer_addr << dendl;\n    goto fail;\n  }\n\n  memset(&msg, 0, sizeof(msg));\n  msgvec[0].iov_base = banner;\n  msgvec[0].iov_len = strlen(CEPH_BANNER);\n  msg.msg_iov = msgvec;\n  msg.msg_iovlen = 1;\n  msglen = msgvec[0].iov_len;\n  rc = do_sendmsg(&msg, msglen);\n  if (rc < 0) {\n    ldout(msgr->cct,2) << \"connect couldn't write my banner, \" << cpp_strerror(rc) << dendl;\n    goto fail;\n  }\n\n  // identify peer\n  {\n#if defined(__linux__) || defined(DARWIN) || defined(__FreeBSD__)\n    bufferptr p(sizeof(ceph_entity_addr) * 2);\n#else\n    int wirelen = sizeof(__u32) * 2 + sizeof(ceph_sockaddr_storage);\n    bufferptr p(wirelen * 2);\n#endif\n    addrbl.push_back(std::move(p));\n  }\n  rc = tcp_read(addrbl.c_str(), addrbl.length());\n  if (rc < 0) {\n    ldout(msgr->cct,2) << \"connect couldn't read peer addrs, \" << cpp_strerror(rc) << dendl;\n    goto fail;\n  }\n  try {\n    bufferlist::iterator p = addrbl.begin();\n    ::decode(paddr, p);\n    ::decode(peer_addr_for_me, p);\n  }\n  catch (buffer::error& e) {\n    ldout(msgr->cct,2) << \"connect couldn't decode peer addrs: \" << e.what()\n\t\t       << dendl;\n    goto fail;\n  }\n  port = peer_addr_for_me.get_port();\n\n  ldout(msgr->cct,20) << \"connect read peer addr \" << paddr << \" on socket \" << sd << dendl;\n  if (peer_addr != paddr) {\n    if (paddr.is_blank_ip() &&\n\tpeer_addr.get_port() == paddr.get_port() &&\n\tpeer_addr.get_nonce() == paddr.get_nonce()) {\n      ldout(msgr->cct,0) << \"connect claims to be \" \n\t      << paddr << \" not \" << peer_addr << \" - presumably this is the same node!\" << dendl;\n    } else {\n      ldout(msgr->cct,10) << \"connect claims to be \"\n\t\t\t  << paddr << \" not \" << peer_addr << dendl;\n      goto fail;\n    }\n  }\n\n  ldout(msgr->cct,20) << \"connect peer addr for me is \" << peer_addr_for_me << dendl;\n\n  msgr->learned_addr(peer_addr_for_me);\n\n  ::encode(msgr->my_inst.addr, myaddrbl, 0);  // legacy\n\n  memset(&msg, 0, sizeof(msg));\n  msgvec[0].iov_base = myaddrbl.c_str();\n  msgvec[0].iov_len = myaddrbl.length();\n  msg.msg_iov = msgvec;\n  msg.msg_iovlen = 1;\n  msglen = msgvec[0].iov_len;\n  rc = do_sendmsg(&msg, msglen);\n  if (rc < 0) {\n    ldout(msgr->cct,2) << \"connect couldn't write my addr, \" << cpp_strerror(rc) << dendl;\n    goto fail;\n  }\n  ldout(msgr->cct,10) << \"connect sent my addr \" << msgr->my_inst.addr << dendl;\n\n\n  while (1) {\n    if (!authorizer) {\n      authorizer = msgr->get_authorizer(peer_type, false);\n    }\n    bufferlist authorizer_reply;\n\n    ceph_msg_connect connect;\n    connect.features = policy.features_supported;\n    connect.host_type = msgr->get_myinst().name.type();\n    connect.global_seq = gseq;\n    connect.connect_seq = cseq;\n    connect.protocol_version = msgr->get_proto_version(peer_type, true);\n    connect.authorizer_protocol = authorizer ? authorizer->protocol : 0;\n    connect.authorizer_len = authorizer ? authorizer->bl.length() : 0;\n    if (authorizer) \n      ldout(msgr->cct,10) << \"connect.authorizer_len=\" << connect.authorizer_len\n\t       << \" protocol=\" << connect.authorizer_protocol << dendl;\n    connect.flags = 0;\n    if (policy.lossy)\n      connect.flags |= CEPH_MSG_CONNECT_LOSSY;  // this is fyi, actually, server decides!\n    memset(&msg, 0, sizeof(msg));\n    msgvec[0].iov_base = (char*)&connect;\n    msgvec[0].iov_len = sizeof(connect);\n    msg.msg_iov = msgvec;\n    msg.msg_iovlen = 1;\n    msglen = msgvec[0].iov_len;\n    if (authorizer) {\n      msgvec[1].iov_base = authorizer->bl.c_str();\n      msgvec[1].iov_len = authorizer->bl.length();\n      msg.msg_iovlen++;\n      msglen += msgvec[1].iov_len;\n    }\n\n    ldout(msgr->cct,10) << \"connect sending gseq=\" << gseq << \" cseq=\" << cseq\n\t     << \" proto=\" << connect.protocol_version << dendl;\n    rc = do_sendmsg(&msg, msglen);\n    if (rc < 0) {\n      ldout(msgr->cct,2) << \"connect couldn't write gseq, cseq, \" << cpp_strerror(rc) << dendl;\n      goto fail;\n    }\n\n    ldout(msgr->cct,20) << \"connect wrote (self +) cseq, waiting for reply\" << dendl;\n    ceph_msg_connect_reply reply;\n    rc = tcp_read((char*)&reply, sizeof(reply));\n    if (rc < 0) {\n      ldout(msgr->cct,2) << \"connect read reply \" << cpp_strerror(rc) << dendl;\n      goto fail;\n    }\n\n    ldout(msgr->cct,20) << \"connect got reply tag \" << (int)reply.tag\n\t\t\t<< \" connect_seq \" << reply.connect_seq\n\t\t\t<< \" global_seq \" << reply.global_seq\n\t\t\t<< \" proto \" << reply.protocol_version\n\t\t\t<< \" flags \" << (int)reply.flags\n\t\t\t<< \" features \" << reply.features\n\t\t\t<< dendl;\n\n    authorizer_reply.clear();\n\n    if (reply.authorizer_len) {\n      ldout(msgr->cct,10) << \"reply.authorizer_len=\" << reply.authorizer_len << dendl;\n      bufferptr bp = buffer::create(reply.authorizer_len);\n      rc = tcp_read(bp.c_str(), reply.authorizer_len);\n      if (rc < 0) {\n        ldout(msgr->cct,10) << \"connect couldn't read connect authorizer_reply\" << cpp_strerror(rc) << dendl;\n\tgoto fail;\n      }\n      authorizer_reply.push_back(bp);\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_CHALLENGE_AUTHORIZER) {\n      authorizer->add_challenge(msgr->cct, authorizer_reply);\n      ldout(msgr->cct,10) << \" got authorizer challenge, \" << authorizer_reply.length()\n\t\t\t  << \" bytes\" << dendl;\n      continue;\n    }\n\n    if (authorizer) {\n      bufferlist::iterator iter = authorizer_reply.begin();\n      if (!authorizer->verify_reply(iter)) {\n        ldout(msgr->cct,0) << \"failed verifying authorize reply\" << dendl;\n\tgoto fail;\n      }\n    }\n\n    if (conf->ms_inject_internal_delays) {\n      ldout(msgr->cct, 10) << \" sleep for \" << msgr->cct->_conf->ms_inject_internal_delays << dendl;\n      utime_t t;\n      t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n      t.sleep();\n    }\n\n    pipe_lock.Lock();\n    if (state != STATE_CONNECTING) {\n      ldout(msgr->cct,0) << \"connect got RESETSESSION but no longer connecting\" << dendl;\n      goto stop_locked;\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_FEATURES) {\n      ldout(msgr->cct,0) << \"connect protocol feature mismatch, my \" << std::hex\n\t      << connect.features << \" < peer \" << reply.features\n\t      << \" missing \" << (reply.features & ~policy.features_supported)\n\t      << std::dec << dendl;\n      goto fail_locked;\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_BADPROTOVER) {\n      ldout(msgr->cct,0) << \"connect protocol version mismatch, my \" << connect.protocol_version\n\t      << \" != \" << reply.protocol_version << dendl;\n      goto fail_locked;\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_BADAUTHORIZER) {\n      ldout(msgr->cct,0) << \"connect got BADAUTHORIZER\" << dendl;\n      if (got_bad_auth)\n        goto stop_locked;\n      got_bad_auth = true;\n      pipe_lock.Unlock();\n      delete authorizer;\n      authorizer = msgr->get_authorizer(peer_type, true);  // try harder\n      continue;\n    }\n    if (reply.tag == CEPH_MSGR_TAG_RESETSESSION) {\n      ldout(msgr->cct,0) << \"connect got RESETSESSION\" << dendl;\n      was_session_reset();\n      cseq = 0;\n      pipe_lock.Unlock();\n      continue;\n    }\n    if (reply.tag == CEPH_MSGR_TAG_RETRY_GLOBAL) {\n      gseq = msgr->get_global_seq(reply.global_seq);\n      ldout(msgr->cct,10) << \"connect got RETRY_GLOBAL \" << reply.global_seq\n\t       << \" chose new \" << gseq << dendl;\n      pipe_lock.Unlock();\n      continue;\n    }\n    if (reply.tag == CEPH_MSGR_TAG_RETRY_SESSION) {\n      assert(reply.connect_seq > connect_seq);\n      ldout(msgr->cct,10) << \"connect got RETRY_SESSION \" << connect_seq\n\t       << \" -> \" << reply.connect_seq << dendl;\n      cseq = connect_seq = reply.connect_seq;\n      pipe_lock.Unlock();\n      continue;\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_WAIT) {\n      ldout(msgr->cct,3) << \"connect got WAIT (connection race)\" << dendl;\n      state = STATE_WAIT;\n      goto stop_locked;\n    }\n\n    if (reply.tag == CEPH_MSGR_TAG_READY ||\n        reply.tag == CEPH_MSGR_TAG_SEQ) {\n      uint64_t feat_missing = policy.features_required & ~(uint64_t)reply.features;\n      if (feat_missing) {\n\tldout(msgr->cct,1) << \"missing required features \" << std::hex << feat_missing << std::dec << dendl;\n\tgoto fail_locked;\n      }\n\n      if (reply.tag == CEPH_MSGR_TAG_SEQ) {\n        ldout(msgr->cct,10) << \"got CEPH_MSGR_TAG_SEQ, reading acked_seq and writing in_seq\" << dendl;\n        uint64_t newly_acked_seq = 0;\n        rc = tcp_read((char*)&newly_acked_seq, sizeof(newly_acked_seq));\n        if (rc < 0) {\n          ldout(msgr->cct,2) << \"connect read error on newly_acked_seq\" << cpp_strerror(rc) << dendl;\n          goto fail_locked;\n        }\n\tldout(msgr->cct,2) << \" got newly_acked_seq \" << newly_acked_seq\n\t\t\t   << \" vs out_seq \" << out_seq << dendl;\n\twhile (newly_acked_seq > out_seq) {\n\t  Message *m = _get_next_outgoing();\n\t  assert(m);\n\t  ldout(msgr->cct,2) << \" discarding previously sent \" << m->get_seq()\n\t\t\t     << \" \" << *m << dendl;\n\t  assert(m->get_seq() <= newly_acked_seq);\n\t  m->put();\n\t  ++out_seq;\n\t}\n        if (tcp_write((char*)&in_seq, sizeof(in_seq)) < 0) {\n          ldout(msgr->cct,2) << \"connect write error on in_seq\" << dendl;\n          goto fail_locked;\n        }\n      }\n\n      // hooray!\n      peer_global_seq = reply.global_seq;\n      policy.lossy = reply.flags & CEPH_MSG_CONNECT_LOSSY;\n      state = STATE_OPEN;\n      connect_seq = cseq + 1;\n      assert(connect_seq == reply.connect_seq);\n      backoff = utime_t();\n      connection_state->set_features((uint64_t)reply.features & (uint64_t)connect.features);\n      ldout(msgr->cct,10) << \"connect success \" << connect_seq << \", lossy = \" << policy.lossy\n\t       << \", features \" << connection_state->get_features() << dendl;\n      \n\n      // If we have an authorizer, get a new AuthSessionHandler to deal with ongoing security of the\n      // connection.  PLR\n\n      if (authorizer != NULL) {\n\tsession_security.reset(\n            get_auth_session_handler(msgr->cct,\n\t\t\t\t     authorizer->protocol,\n\t\t\t\t     authorizer->session_key,\n\t\t\t\t     connection_state->get_features()));\n      }  else {\n        // We have no authorizer, so we shouldn't be applying security to messages in this pipe.  PLR\n\tsession_security.reset();\n      }\n\n      msgr->dispatch_queue.queue_connect(connection_state.get());\n      msgr->ms_deliver_handle_fast_connect(connection_state.get());\n      \n      if (!reader_running) {\n\tldout(msgr->cct,20) << \"connect starting reader\" << dendl;\n\tstart_reader();\n      }\n      maybe_start_delay_thread();\n      delete authorizer;\n      return 0;\n    }\n    \n    // protocol error\n    ldout(msgr->cct,0) << \"connect got bad tag \" << (int)tag << dendl;\n    goto fail_locked;\n  }\n\n fail:\n  if (conf->ms_inject_internal_delays) {\n    ldout(msgr->cct, 10) << \" sleep for \" << msgr->cct->_conf->ms_inject_internal_delays << dendl;\n    utime_t t;\n    t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n    t.sleep();\n  }\n\n  pipe_lock.Lock();\n fail_locked:\n  if (state == STATE_CONNECTING)\n    fault();\n  else\n    ldout(msgr->cct,3) << \"connect fault, but state = \" << get_state_name()\n\t\t       << \" != connecting, stopping\" << dendl;\n\n stop_locked:\n  delete authorizer;\n  return rc;\n}\n\nvoid Pipe::register_pipe()\n{\n  ldout(msgr->cct,10) << \"register_pipe\" << dendl;\n  assert(msgr->lock.is_locked());\n  Pipe *existing = msgr->_lookup_pipe(peer_addr);\n  assert(existing == NULL);\n  msgr->rank_pipe[peer_addr] = this;\n}\n\nvoid Pipe::unregister_pipe()\n{\n  assert(msgr->lock.is_locked());\n  ceph::unordered_map<entity_addr_t,Pipe*>::iterator p = msgr->rank_pipe.find(peer_addr);\n  if (p != msgr->rank_pipe.end() && p->second == this) {\n    ldout(msgr->cct,10) << \"unregister_pipe\" << dendl;\n    msgr->rank_pipe.erase(p);\n  } else {\n    ldout(msgr->cct,10) << \"unregister_pipe - not registered\" << dendl;\n    msgr->accepting_pipes.erase(this);  // somewhat overkill, but safe.\n  }\n}\n\nvoid Pipe::join()\n{\n  ldout(msgr->cct, 20) << \"join\" << dendl;\n  if (writer_thread.is_started())\n    writer_thread.join();\n  if (reader_thread.is_started())\n    reader_thread.join();\n  if (delay_thread) {\n    ldout(msgr->cct, 20) << \"joining delay_thread\" << dendl;\n    delay_thread->stop();\n    delay_thread->join();\n  }\n}\n\nvoid Pipe::requeue_sent()\n{\n  if (sent.empty())\n    return;\n\n  list<Message*>& rq = out_q[CEPH_MSG_PRIO_HIGHEST];\n  while (!sent.empty()) {\n    Message *m = sent.back();\n    sent.pop_back();\n    ldout(msgr->cct,10) << \"requeue_sent \" << *m << \" for resend seq \" << out_seq\n\t\t\t<< \" (\" << m->get_seq() << \")\" << dendl;\n    rq.push_front(m);\n    out_seq--;\n  }\n}\n\nvoid Pipe::discard_requeued_up_to(uint64_t seq)\n{\n  ldout(msgr->cct, 10) << \"discard_requeued_up_to \" << seq << dendl;\n  if (out_q.count(CEPH_MSG_PRIO_HIGHEST) == 0)\n    return;\n  list<Message*>& rq = out_q[CEPH_MSG_PRIO_HIGHEST];\n  while (!rq.empty()) {\n    Message *m = rq.front();\n    if (m->get_seq() == 0 || m->get_seq() > seq)\n      break;\n    ldout(msgr->cct,10) << \"discard_requeued_up_to \" << *m << \" for resend seq \" << out_seq\n\t\t\t<< \" <= \" << seq << \", discarding\" << dendl;\n    m->put();\n    rq.pop_front();\n    out_seq++;\n  }\n  if (rq.empty())\n    out_q.erase(CEPH_MSG_PRIO_HIGHEST);\n}\n\n/*\n * Tears down the Pipe's message queues, and removes them from the DispatchQueue\n * Must hold pipe_lock prior to calling.\n */\nvoid Pipe::discard_out_queue()\n{\n  ldout(msgr->cct,10) << \"discard_queue\" << dendl;\n\n  for (list<Message*>::iterator p = sent.begin(); p != sent.end(); ++p) {\n    ldout(msgr->cct,20) << \"  discard \" << *p << dendl;\n    (*p)->put();\n  }\n  sent.clear();\n  for (map<int,list<Message*> >::iterator p = out_q.begin(); p != out_q.end(); ++p)\n    for (list<Message*>::iterator r = p->second.begin(); r != p->second.end(); ++r) {\n      ldout(msgr->cct,20) << \"  discard \" << *r << dendl;\n      (*r)->put();\n    }\n  out_q.clear();\n}\n\nvoid Pipe::fault(bool onread)\n{\n  const md_config_t *conf = msgr->cct->_conf;\n  assert(pipe_lock.is_locked());\n  cond.Signal();\n\n  if (onread && state == STATE_CONNECTING) {\n    ldout(msgr->cct,10) << \"fault already connecting, reader shutting down\" << dendl;\n    return;\n  }\n  \n  ldout(msgr->cct,2) << \"fault \" << cpp_strerror(errno) << dendl;\n\n  if (state == STATE_CLOSED ||\n      state == STATE_CLOSING) {\n    ldout(msgr->cct,10) << \"fault already closed|closing\" << dendl;\n    if (connection_state->clear_pipe(this))\n      msgr->dispatch_queue.queue_reset(connection_state.get());\n    return;\n  }\n\n  shutdown_socket();\n\n  // lossy channel?\n  if (policy.lossy && state != STATE_CONNECTING) {\n    ldout(msgr->cct,10) << \"fault on lossy channel, failing\" << dendl;\n\n    // disconnect from Connection, and mark it failed.  future messages\n    // will be dropped.\n    assert(connection_state);\n    stop();\n    bool cleared = connection_state->clear_pipe(this);\n\n    // crib locks, blech.  note that Pipe is now STATE_CLOSED and the\n    // rank_pipe entry is ignored by others.\n    pipe_lock.Unlock();\n\n    if (conf->ms_inject_internal_delays) {\n      ldout(msgr->cct, 10) << \" sleep for \" << msgr->cct->_conf->ms_inject_internal_delays << dendl;\n      utime_t t;\n      t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n      t.sleep();\n    }\n\n    msgr->lock.Lock();\n    pipe_lock.Lock();\n    unregister_pipe();\n    msgr->lock.Unlock();\n\n    if (delay_thread)\n      delay_thread->discard();\n    in_q->discard_queue(conn_id);\n    discard_out_queue();\n    if (cleared)\n      msgr->dispatch_queue.queue_reset(connection_state.get());\n    return;\n  }\n\n  // queue delayed items immediately\n  if (delay_thread)\n    delay_thread->flush();\n\n  // requeue sent items\n  requeue_sent();\n\n  if (policy.standby && !is_queued()) {\n    ldout(msgr->cct,0) << \"fault with nothing to send, going to standby\" << dendl;\n    state = STATE_STANDBY;\n    return;\n  }\n\n  if (state != STATE_CONNECTING) {\n    if (policy.server) {\n      ldout(msgr->cct,0) << \"fault, server, going to standby\" << dendl;\n      state = STATE_STANDBY;\n    } else {\n      ldout(msgr->cct,0) << \"fault, initiating reconnect\" << dendl;\n      connect_seq++;\n      state = STATE_CONNECTING;\n    }\n    backoff = utime_t();\n  } else if (backoff == utime_t()) {\n    ldout(msgr->cct,0) << \"fault\" << dendl;\n    backoff.set_from_double(conf->ms_initial_backoff);\n  } else {\n    ldout(msgr->cct,10) << \"fault waiting \" << backoff << dendl;\n    cond.WaitInterval(pipe_lock, backoff);\n    backoff += backoff;\n    if (backoff > conf->ms_max_backoff)\n      backoff.set_from_double(conf->ms_max_backoff);\n    ldout(msgr->cct,10) << \"fault done waiting or woke up\" << dendl;\n  }\n}\n\nint Pipe::randomize_out_seq()\n{\n  if (connection_state->get_features() & CEPH_FEATURE_MSG_AUTH) {\n    // Set out_seq to a random value, so CRC won't be predictable.   Don't bother checking seq_error\n    // here.  We'll check it on the call.  PLR\n    int seq_error = get_random_bytes((char *)&out_seq, sizeof(out_seq));\n    out_seq &= SEQ_MASK;\n    lsubdout(msgr->cct, ms, 10) << \"randomize_out_seq \" << out_seq << dendl;\n    return seq_error;\n  } else {\n    // previously, seq #'s always started at 0.\n    out_seq = 0;\n    return 0;\n  }\n}\n\nvoid Pipe::was_session_reset()\n{\n  assert(pipe_lock.is_locked());\n\n  ldout(msgr->cct,10) << \"was_session_reset\" << dendl;\n  in_q->discard_queue(conn_id);\n  if (delay_thread)\n    delay_thread->discard();\n  discard_out_queue();\n\n  msgr->dispatch_queue.queue_remote_reset(connection_state.get());\n\n  if (randomize_out_seq()) {\n    lsubdout(msgr->cct,ms,15) << \"was_session_reset(): Could not get random bytes to set seq number for session reset; set seq number to \" << out_seq << dendl;\n  }\n\n  in_seq = 0;\n  connect_seq = 0;\n}\n\nvoid Pipe::stop()\n{\n  ldout(msgr->cct,10) << \"stop\" << dendl;\n  assert(pipe_lock.is_locked());\n  state = STATE_CLOSED;\n  state_closed = true;\n  cond.Signal();\n  shutdown_socket();\n}\n\nvoid Pipe::stop_and_wait()\n{\n  assert(pipe_lock.is_locked_by_me());\n  if (state != STATE_CLOSED)\n    stop();\n\n  if (msgr->cct->_conf->ms_inject_internal_delays) {\n    ldout(msgr->cct, 10) << __func__ << \" sleep for \"\n\t\t\t << msgr->cct->_conf->ms_inject_internal_delays\n\t\t\t << dendl;\n    utime_t t;\n    t.set_from_double(msgr->cct->_conf->ms_inject_internal_delays);\n    t.sleep();\n  }\n  \n  if (delay_thread) {\n    pipe_lock.Unlock();\n    delay_thread->stop_fast_dispatching();\n    pipe_lock.Lock();\n  }\n  while (reader_running &&\n\t reader_dispatching)\n    cond.Wait(pipe_lock);\n}\n\n/* read msgs from socket.\n * also, server.\n */\nvoid Pipe::reader()\n{\n  pipe_lock.Lock();\n\n  if (state == STATE_ACCEPTING) {\n    accept();\n    assert(pipe_lock.is_locked());\n  }\n\n  // loop.\n  while (state != STATE_CLOSED &&\n\t state != STATE_CONNECTING) {\n    assert(pipe_lock.is_locked());\n\n    // sleep if (re)connecting\n    if (state == STATE_STANDBY) {\n      ldout(msgr->cct,20) << \"reader sleeping during reconnect|standby\" << dendl;\n      cond.Wait(pipe_lock);\n      continue;\n    }\n\n    // get a reference to the AuthSessionHandler while we have the pipe_lock\n    ceph::shared_ptr<AuthSessionHandler> auth_handler = session_security;\n\n    pipe_lock.Unlock();\n\n    char tag = -1;\n    ldout(msgr->cct,20) << \"reader reading tag...\" << dendl;\n    if (tcp_read((char*)&tag, 1) < 0) {\n      pipe_lock.Lock();\n      ldout(msgr->cct,2) << \"reader couldn't read tag, \" << cpp_strerror(errno) << dendl;\n      fault(true);\n      continue;\n    }\n\n    if (tag == CEPH_MSGR_TAG_KEEPALIVE) {\n      ldout(msgr->cct,2) << \"reader got KEEPALIVE\" << dendl;\n      pipe_lock.Lock();\n      connection_state->set_last_keepalive(ceph_clock_now());\n      continue;\n    }\n    if (tag == CEPH_MSGR_TAG_KEEPALIVE2) {\n      ldout(msgr->cct,30) << \"reader got KEEPALIVE2 tag ...\" << dendl;\n      ceph_timespec t;\n      int rc = tcp_read((char*)&t, sizeof(t));\n      pipe_lock.Lock();\n      if (rc < 0) {\n\tldout(msgr->cct,2) << \"reader couldn't read KEEPALIVE2 stamp \"\n\t\t\t   << cpp_strerror(errno) << dendl;\n\tfault(true);\n      } else {\n\tsend_keepalive_ack = true;\n\tkeepalive_ack_stamp = utime_t(t);\n\tldout(msgr->cct,2) << \"reader got KEEPALIVE2 \" << keepalive_ack_stamp\n\t\t\t   << dendl;\n\tconnection_state->set_last_keepalive(ceph_clock_now());\n\tcond.Signal();\n      }\n      continue;\n    }\n    if (tag == CEPH_MSGR_TAG_KEEPALIVE2_ACK) {\n      ldout(msgr->cct,2) << \"reader got KEEPALIVE_ACK\" << dendl;\n      struct ceph_timespec t;\n      int rc = tcp_read((char*)&t, sizeof(t));\n      pipe_lock.Lock();\n      if (rc < 0) {\n\tldout(msgr->cct,2) << \"reader couldn't read KEEPALIVE2 stamp \" << cpp_strerror(errno) << dendl;\n\tfault(true);\n      } else {\n\tconnection_state->set_last_keepalive_ack(utime_t(t));\n      }\n      continue;\n    }\n\n    // open ...\n    if (tag == CEPH_MSGR_TAG_ACK) {\n      ldout(msgr->cct,20) << \"reader got ACK\" << dendl;\n      ceph_le64 seq;\n      int rc = tcp_read((char*)&seq, sizeof(seq));\n      pipe_lock.Lock();\n      if (rc < 0) {\n\tldout(msgr->cct,2) << \"reader couldn't read ack seq, \" << cpp_strerror(errno) << dendl;\n\tfault(true);\n      } else if (state != STATE_CLOSED) {\n        handle_ack(seq);\n      }\n      continue;\n    }\n\n    else if (tag == CEPH_MSGR_TAG_MSG) {\n      ldout(msgr->cct,20) << \"reader got MSG\" << dendl;\n      Message *m = 0;\n      int r = read_message(&m, auth_handler.get());\n\n      pipe_lock.Lock();\n      \n      if (!m) {\n\tif (r < 0)\n\t  fault(true);\n\tcontinue;\n      }\n\n      m->trace.event(\"pipe read message\");\n\n      if (state == STATE_CLOSED ||\n\t  state == STATE_CONNECTING) {\n\tin_q->dispatch_throttle_release(m->get_dispatch_throttle_size());\n\tm->put();\n\tcontinue;\n      }\n\n      // check received seq#.  if it is old, drop the message.  \n      // note that incoming messages may skip ahead.  this is convenient for the client\n      // side queueing because messages can't be renumbered, but the (kernel) client will\n      // occasionally pull a message out of the sent queue to send elsewhere.  in that case\n      // it doesn't matter if we \"got\" it or not.\n      if (m->get_seq() <= in_seq) {\n\tldout(msgr->cct,0) << \"reader got old message \"\n\t\t<< m->get_seq() << \" <= \" << in_seq << \" \" << m << \" \" << *m\n\t\t<< \", discarding\" << dendl;\n\tin_q->dispatch_throttle_release(m->get_dispatch_throttle_size());\n\tm->put();\n\tif (connection_state->has_feature(CEPH_FEATURE_RECONNECT_SEQ) &&\n\t    msgr->cct->_conf->ms_die_on_old_message)\n\t  assert(0 == \"old msgs despite reconnect_seq feature\");\n\tcontinue;\n      }\n      if (m->get_seq() > in_seq + 1) {\n\tldout(msgr->cct,0) << \"reader missed message?  skipped from seq \"\n\t\t\t   << in_seq << \" to \" << m->get_seq() << dendl;\n\tif (msgr->cct->_conf->ms_die_on_skipped_message)\n\t  assert(0 == \"skipped incoming seq\");\n      }\n\n      m->set_connection(connection_state.get());\n\n      // note last received message.\n      in_seq = m->get_seq();\n\n      cond.Signal();  // wake up writer, to ack this\n      \n      ldout(msgr->cct,10) << \"reader got message \"\n\t       << m->get_seq() << \" \" << m << \" \" << *m\n\t       << dendl;\n      in_q->fast_preprocess(m);\n\n      if (delay_thread) {\n        utime_t release;\n        if (rand() % 10000 < msgr->cct->_conf->ms_inject_delay_probability * 10000.0) {\n          release = m->get_recv_stamp();\n          release += msgr->cct->_conf->ms_inject_delay_max * (double)(rand() % 10000) / 10000.0;\n          lsubdout(msgr->cct, ms, 1) << \"queue_received will delay until \" << release << \" on \" << m << \" \" << *m << dendl;\n        }\n        delay_thread->queue(release, m);\n      } else {\n        if (in_q->can_fast_dispatch(m)) {\n\t  reader_dispatching = true;\n          pipe_lock.Unlock();\n          in_q->fast_dispatch(m);\n          pipe_lock.Lock();\n\t  reader_dispatching = false;\n\t  if (state == STATE_CLOSED ||\n\t      notify_on_dispatch_done) { // there might be somebody waiting\n\t    notify_on_dispatch_done = false;\n\t    cond.Signal();\n\t  }\n        } else {\n          in_q->enqueue(m, m->get_priority(), conn_id);\n        }\n      }\n    }\n    \n    else if (tag == CEPH_MSGR_TAG_CLOSE) {\n      ldout(msgr->cct,20) << \"reader got CLOSE\" << dendl;\n      pipe_lock.Lock();\n      if (state == STATE_CLOSING) {\n\tstate = STATE_CLOSED;\n\tstate_closed = true;\n      } else {\n\tstate = STATE_CLOSING;\n      }\n      cond.Signal();\n      break;\n    }\n    else {\n      ldout(msgr->cct,0) << \"reader bad tag \" << (int)tag << dendl;\n      pipe_lock.Lock();\n      fault(true);\n    }\n  }\n\n \n  // reap?\n  reader_running = false;\n  reader_needs_join = true;\n  unlock_maybe_reap();\n  ldout(msgr->cct,10) << \"reader done\" << dendl;\n}\n\n/* write msgs to socket.\n * also, client.\n */\nvoid Pipe::writer()\n{\n  pipe_lock.Lock();\n  while (state != STATE_CLOSED) {// && state != STATE_WAIT) {\n    ldout(msgr->cct,10) << \"writer: state = \" << get_state_name()\n\t\t\t<< \" policy.server=\" << policy.server << dendl;\n\n    // standby?\n    if (is_queued() && state == STATE_STANDBY && !policy.server)\n      state = STATE_CONNECTING;\n\n    // connect?\n    if (state == STATE_CONNECTING) {\n      assert(!policy.server);\n      connect();\n      continue;\n    }\n    \n    if (state == STATE_CLOSING) {\n      // write close tag\n      ldout(msgr->cct,20) << \"writer writing CLOSE tag\" << dendl;\n      char tag = CEPH_MSGR_TAG_CLOSE;\n      state = STATE_CLOSED;\n      state_closed = true;\n      pipe_lock.Unlock();\n      if (sd >= 0) {\n\t// we can ignore return value, actually; we don't care if this succeeds.\n\tint r = ::write(sd, &tag, 1);\n\t(void)r;\n      }\n      pipe_lock.Lock();\n      continue;\n    }\n\n    if (state != STATE_CONNECTING && state != STATE_WAIT && state != STATE_STANDBY &&\n\t(is_queued() || in_seq > in_seq_acked)) {\n\n      // keepalive?\n      if (send_keepalive) {\n\tint rc;\n\tif (connection_state->has_feature(CEPH_FEATURE_MSGR_KEEPALIVE2)) {\n\t  pipe_lock.Unlock();\n\t  rc = write_keepalive2(CEPH_MSGR_TAG_KEEPALIVE2,\n\t\t\t\tceph_clock_now());\n\t} else {\n\t  pipe_lock.Unlock();\n\t  rc = write_keepalive();\n\t}\n\tpipe_lock.Lock();\n\tif (rc < 0) {\n\t  ldout(msgr->cct,2) << \"writer couldn't write keepalive[2], \"\n\t\t\t     << cpp_strerror(errno) << dendl;\n\t  fault();\n \t  continue;\n\t}\n\tsend_keepalive = false;\n      }\n      if (send_keepalive_ack) {\n\tutime_t t = keepalive_ack_stamp;\n\tpipe_lock.Unlock();\n\tint rc = write_keepalive2(CEPH_MSGR_TAG_KEEPALIVE2_ACK, t);\n\tpipe_lock.Lock();\n\tif (rc < 0) {\n\t  ldout(msgr->cct,2) << \"writer couldn't write keepalive_ack, \" << cpp_strerror(errno) << dendl;\n\t  fault();\n\t  continue;\n\t}\n\tsend_keepalive_ack = false;\n      }\n\n      // send ack?\n      if (in_seq > in_seq_acked) {\n\tuint64_t send_seq = in_seq;\n\tpipe_lock.Unlock();\n\tint rc = write_ack(send_seq);\n\tpipe_lock.Lock();\n\tif (rc < 0) {\n\t  ldout(msgr->cct,2) << \"writer couldn't write ack, \" << cpp_strerror(errno) << dendl;\n\t  fault();\n \t  continue;\n\t}\n\tin_seq_acked = send_seq;\n      }\n\n      // grab outgoing message\n      Message *m = _get_next_outgoing();\n      if (m) {\n\tm->set_seq(++out_seq);\n\tif (!policy.lossy) {\n\t  // put on sent list\n\t  sent.push_back(m); \n\t  m->get();\n\t}\n\n\t// associate message with Connection (for benefit of encode_payload)\n\tm->set_connection(connection_state.get());\n\n\tuint64_t features = connection_state->get_features();\n\n\tif (m->empty_payload())\n\t  ldout(msgr->cct,20) << \"writer encoding \" << m->get_seq() << \" features \" << features\n\t\t\t      << \" \" << m << \" \" << *m << dendl;\n\telse\n\t  ldout(msgr->cct,20) << \"writer half-reencoding \" << m->get_seq() << \" features \" << features\n\t\t\t      << \" \" << m << \" \" << *m << dendl;\n\n\t// encode and copy out of *m\n\tm->encode(features, msgr->crcflags);\n\n\t// prepare everything\n\tconst ceph_msg_header& header = m->get_header();\n\tconst ceph_msg_footer& footer = m->get_footer();\n\n\t// Now that we have all the crcs calculated, handle the\n\t// digital signature for the message, if the pipe has session\n\t// security set up.  Some session security options do not\n\t// actually calculate and check the signature, but they should\n\t// handle the calls to sign_message and check_signature.  PLR\n\tif (session_security.get() == NULL) {\n\t  ldout(msgr->cct, 20) << \"writer no session security\" << dendl;\n\t} else {\n\t  if (session_security->sign_message(m)) {\n\t    ldout(msgr->cct, 20) << \"writer failed to sign seq # \" << header.seq\n\t\t\t\t << \"): sig = \" << footer.sig << dendl;\n\t  } else {\n\t    ldout(msgr->cct, 20) << \"writer signed seq # \" << header.seq\n\t\t\t\t << \"): sig = \" << footer.sig << dendl;\n\t  }\n\t}\n\n\tbufferlist blist = m->get_payload();\n\tblist.append(m->get_middle());\n\tblist.append(m->get_data());\n\n        pipe_lock.Unlock();\n\n        m->trace.event(\"pipe writing message\");\n\n        ldout(msgr->cct,20) << \"writer sending \" << m->get_seq() << \" \" << m << dendl;\n\tint rc = write_message(header, footer, blist);\n\n\tpipe_lock.Lock();\n\tif (rc < 0) {\n          ldout(msgr->cct,1) << \"writer error sending \" << m << \", \"\n\t\t  << cpp_strerror(errno) << dendl;\n\t  fault();\n        }\n\tm->put();\n      }\n      continue;\n    }\n    \n    // wait\n    ldout(msgr->cct,20) << \"writer sleeping\" << dendl;\n    cond.Wait(pipe_lock);\n  }\n  \n  ldout(msgr->cct,20) << \"writer finishing\" << dendl;\n\n  // reap?\n  writer_running = false;\n  unlock_maybe_reap();\n  ldout(msgr->cct,10) << \"writer done\" << dendl;\n}\n\nvoid Pipe::unlock_maybe_reap()\n{\n  if (!reader_running && !writer_running) {\n    shutdown_socket();\n    pipe_lock.Unlock();\n    if (delay_thread && delay_thread->is_flushing()) {\n      delay_thread->wait_for_flush();\n    }\n    msgr->queue_reap(this);\n  } else {\n    pipe_lock.Unlock();\n  }\n}\n\nstatic void alloc_aligned_buffer(bufferlist& data, unsigned len, unsigned off)\n{\n  // create a buffer to read into that matches the data alignment\n  unsigned left = len;\n  if (off & ~CEPH_PAGE_MASK) {\n    // head\n    unsigned head = 0;\n    head = MIN(CEPH_PAGE_SIZE - (off & ~CEPH_PAGE_MASK), left);\n    data.push_back(buffer::create(head));\n    left -= head;\n  }\n  unsigned middle = left & CEPH_PAGE_MASK;\n  if (middle > 0) {\n    data.push_back(buffer::create_page_aligned(middle));\n    left -= middle;\n  }\n  if (left) {\n    data.push_back(buffer::create(left));\n  }\n}\n\nint Pipe::read_message(Message **pm, AuthSessionHandler* auth_handler)\n{\n  int ret = -1;\n  // envelope\n  //ldout(msgr->cct,10) << \"receiver.read_message from sd \" << sd  << dendl;\n  \n  ceph_msg_header header; \n  ceph_msg_footer footer;\n  __u32 header_crc = 0;\n\n  if (connection_state->has_feature(CEPH_FEATURE_NOSRCADDR)) {\n    if (tcp_read((char*)&header, sizeof(header)) < 0)\n      return -1;\n    if (msgr->crcflags & MSG_CRC_HEADER) {\n      header_crc = ceph_crc32c(0, (unsigned char *)&header, sizeof(header) - sizeof(header.crc));\n    }\n  } else {\n    ceph_msg_header_old oldheader;\n    if (tcp_read((char*)&oldheader, sizeof(oldheader)) < 0)\n      return -1;\n    // this is fugly\n    memcpy(&header, &oldheader, sizeof(header));\n    header.src = oldheader.src.name;\n    header.reserved = oldheader.reserved;\n    if (msgr->crcflags & MSG_CRC_HEADER) {\n      header.crc = oldheader.crc;\n      header_crc = ceph_crc32c(0, (unsigned char *)&oldheader, sizeof(oldheader) - sizeof(oldheader.crc));\n    }\n  }\n\n  ldout(msgr->cct,20) << \"reader got envelope type=\" << header.type\n           << \" src \" << entity_name_t(header.src)\n           << \" front=\" << header.front_len\n\t   << \" data=\" << header.data_len\n\t   << \" off \" << header.data_off\n           << dendl;\n\n  // verify header crc\n  if ((msgr->crcflags & MSG_CRC_HEADER) && header_crc != header.crc) {\n    ldout(msgr->cct,0) << \"reader got bad header crc \" << header_crc << \" != \" << header.crc << dendl;\n    return -1;\n  }\n\n  bufferlist front, middle, data;\n  int front_len, middle_len;\n  unsigned data_len, data_off;\n  int aborted;\n  Message *message;\n  utime_t recv_stamp = ceph_clock_now();\n\n  if (policy.throttler_messages) {\n    ldout(msgr->cct,10) << \"reader wants \" << 1 << \" message from policy throttler \"\n\t\t\t<< policy.throttler_messages->get_current() << \"/\"\n\t\t\t<< policy.throttler_messages->get_max() << dendl;\n    policy.throttler_messages->get();\n  }\n\n  uint64_t message_size = header.front_len + header.middle_len + header.data_len;\n  if (message_size) {\n    if (policy.throttler_bytes) {\n      ldout(msgr->cct,10) << \"reader wants \" << message_size << \" bytes from policy throttler \"\n\t       << policy.throttler_bytes->get_current() << \"/\"\n\t       << policy.throttler_bytes->get_max() << dendl;\n      policy.throttler_bytes->get(message_size);\n    }\n\n    // throttle total bytes waiting for dispatch.  do this _after_ the\n    // policy throttle, as this one does not deadlock (unless dispatch\n    // blocks indefinitely, which it shouldn't).  in contrast, the\n    // policy throttle carries for the lifetime of the message.\n    ldout(msgr->cct,10) << \"reader wants \" << message_size << \" from dispatch throttler \"\n\t     << in_q->dispatch_throttler.get_current() << \"/\"\n\t     << in_q->dispatch_throttler.get_max() << dendl;\n    in_q->dispatch_throttler.get(message_size);\n  }\n\n  utime_t throttle_stamp = ceph_clock_now();\n\n  // read front\n  front_len = header.front_len;\n  if (front_len) {\n    bufferptr bp = buffer::create(front_len);\n    if (tcp_read(bp.c_str(), front_len) < 0)\n      goto out_dethrottle;\n    front.push_back(std::move(bp));\n    ldout(msgr->cct,20) << \"reader got front \" << front.length() << dendl;\n  }\n\n  // read middle\n  middle_len = header.middle_len;\n  if (middle_len) {\n    bufferptr bp = buffer::create(middle_len);\n    if (tcp_read(bp.c_str(), middle_len) < 0)\n      goto out_dethrottle;\n    middle.push_back(std::move(bp));\n    ldout(msgr->cct,20) << \"reader got middle \" << middle.length() << dendl;\n  }\n\n\n  // read data\n  data_len = le32_to_cpu(header.data_len);\n  data_off = le32_to_cpu(header.data_off);\n  if (data_len) {\n    unsigned offset = 0;\n    unsigned left = data_len;\n\n    bufferlist newbuf, rxbuf;\n    bufferlist::iterator blp;\n    int rxbuf_version = 0;\n\t\n    while (left > 0) {\n      // wait for data\n      if (tcp_read_wait() < 0)\n\tgoto out_dethrottle;\n\n      // get a buffer\n      connection_state->lock.Lock();\n      map<ceph_tid_t,pair<bufferlist,int> >::iterator p = connection_state->rx_buffers.find(header.tid);\n      if (p != connection_state->rx_buffers.end()) {\n\tif (rxbuf.length() == 0 || p->second.second != rxbuf_version) {\n\t  ldout(msgr->cct,10) << \"reader seleting rx buffer v \" << p->second.second\n\t\t   << \" at offset \" << offset\n\t\t   << \" len \" << p->second.first.length() << dendl;\n\t  rxbuf = p->second.first;\n\t  rxbuf_version = p->second.second;\n\t  // make sure it's big enough\n\t  if (rxbuf.length() < data_len)\n\t    rxbuf.push_back(buffer::create(data_len - rxbuf.length()));\n\t  blp = p->second.first.begin();\n\t  blp.advance(offset);\n\t}\n      } else {\n\tif (!newbuf.length()) {\n\t  ldout(msgr->cct,20) << \"reader allocating new rx buffer at offset \" << offset << dendl;\n\t  alloc_aligned_buffer(newbuf, data_len, data_off);\n\t  blp = newbuf.begin();\n\t  blp.advance(offset);\n\t}\n      }\n      bufferptr bp = blp.get_current_ptr();\n      int read = MIN(bp.length(), left);\n      ldout(msgr->cct,20) << \"reader reading nonblocking into \" << (void*)bp.c_str() << \" len \" << bp.length() << dendl;\n      ssize_t got = tcp_read_nonblocking(bp.c_str(), read);\n      ldout(msgr->cct,30) << \"reader read \" << got << \" of \" << read << dendl;\n      connection_state->lock.Unlock();\n      if (got < 0)\n\tgoto out_dethrottle;\n      if (got > 0) {\n\tblp.advance(got);\n\tdata.append(bp, 0, got);\n\toffset += got;\n\tleft -= got;\n      } // else we got a signal or something; just loop.\n    }\n  }\n\n  // footer\n  if (connection_state->has_feature(CEPH_FEATURE_MSG_AUTH)) {\n    if (tcp_read((char*)&footer, sizeof(footer)) < 0)\n      goto out_dethrottle;\n  } else {\n    ceph_msg_footer_old old_footer;\n    if (tcp_read((char*)&old_footer, sizeof(old_footer)) < 0)\n      goto out_dethrottle;\n    footer.front_crc = old_footer.front_crc;\n    footer.middle_crc = old_footer.middle_crc;\n    footer.data_crc = old_footer.data_crc;\n    footer.sig = 0;\n    footer.flags = old_footer.flags;\n  }\n  \n  aborted = (footer.flags & CEPH_MSG_FOOTER_COMPLETE) == 0;\n  ldout(msgr->cct,10) << \"aborted = \" << aborted << dendl;\n  if (aborted) {\n    ldout(msgr->cct,0) << \"reader got \" << front.length() << \" + \" << middle.length() << \" + \" << data.length()\n\t    << \" byte message.. ABORTED\" << dendl;\n    ret = 0;\n    goto out_dethrottle;\n  }\n\n  ldout(msgr->cct,20) << \"reader got \" << front.length() << \" + \" << middle.length() << \" + \" << data.length()\n\t   << \" byte message\" << dendl;\n  message = decode_message(msgr->cct, msgr->crcflags, header, footer,\n                           front, middle, data, connection_state.get());\n  if (!message) {\n    ret = -EINVAL;\n    goto out_dethrottle;\n  }\n\n  //\n  //  Check the signature if one should be present.  A zero return indicates success. PLR\n  //\n\n  if (auth_handler == NULL) {\n    ldout(msgr->cct, 10) << \"No session security set\" << dendl;\n  } else {\n    if (auth_handler->check_message_signature(message)) {\n      ldout(msgr->cct, 0) << \"Signature check failed\" << dendl;\n      message->put();\n      ret = -EINVAL;\n      goto out_dethrottle;\n    } \n  }\n\n  message->set_byte_throttler(policy.throttler_bytes);\n  message->set_message_throttler(policy.throttler_messages);\n\n  // store reservation size in message, so we don't get confused\n  // by messages entering the dispatch queue through other paths.\n  message->set_dispatch_throttle_size(message_size);\n\n  message->set_recv_stamp(recv_stamp);\n  message->set_throttle_stamp(throttle_stamp);\n  message->set_recv_complete_stamp(ceph_clock_now());\n\n  *pm = message;\n  return 0;\n\n out_dethrottle:\n  // release bytes reserved from the throttlers on failure\n  if (policy.throttler_messages) {\n    ldout(msgr->cct,10) << \"reader releasing \" << 1 << \" message to policy throttler \"\n\t\t\t<< policy.throttler_messages->get_current() << \"/\"\n\t\t\t<< policy.throttler_messages->get_max() << dendl;\n    policy.throttler_messages->put();\n  }\n  if (message_size) {\n    if (policy.throttler_bytes) {\n      ldout(msgr->cct,10) << \"reader releasing \" << message_size << \" bytes to policy throttler \"\n\t\t\t  << policy.throttler_bytes->get_current() << \"/\"\n\t\t\t  << policy.throttler_bytes->get_max() << dendl;\n      policy.throttler_bytes->put(message_size);\n    }\n\n    in_q->dispatch_throttle_release(message_size);\n  }\n  return ret;\n}\n\nint Pipe::do_sendmsg(struct msghdr *msg, unsigned len, bool more)\n{\n  MSGR_SIGPIPE_STOPPER;\n  while (len > 0) {\n    int r;\n    r = ::sendmsg(sd, msg, MSG_NOSIGNAL | (more ? MSG_MORE : 0));\n    if (r == 0) \n      ldout(msgr->cct,10) << \"do_sendmsg hmm do_sendmsg got r==0!\" << dendl;\n    if (r < 0) {\n      r = -errno; \n      ldout(msgr->cct,1) << \"do_sendmsg error \" << cpp_strerror(r) << dendl;\n      return r;\n    }\n    if (state == STATE_CLOSED) {\n      ldout(msgr->cct,10) << \"do_sendmsg oh look, state == CLOSED, giving up\" << dendl;\n      return -EINTR; // close enough\n    }\n\n    len -= r;\n    if (len == 0) break;\n    \n    // hrmph.  trim r bytes off the front of our message.\n    ldout(msgr->cct,20) << \"do_sendmsg short write did \" << r << \", still have \" << len << dendl;\n    while (r > 0) {\n      if (msg->msg_iov[0].iov_len <= (size_t)r) {\n\t// lose this whole item\n\t//ldout(msgr->cct,30) << \"skipping \" << msg->msg_iov[0].iov_len << \", \" << (msg->msg_iovlen-1) << \" v, \" << r << \" left\" << dendl;\n\tr -= msg->msg_iov[0].iov_len;\n\tmsg->msg_iov++;\n\tmsg->msg_iovlen--;\n      } else {\n\t// partial!\n\t//ldout(msgr->cct,30) << \"adjusting \" << msg->msg_iov[0].iov_len << \", \" << msg->msg_iovlen << \" v, \" << r << \" left\" << dendl;\n\tmsg->msg_iov[0].iov_base = (char *)msg->msg_iov[0].iov_base + r;\n\tmsg->msg_iov[0].iov_len -= r;\n\tbreak;\n      }\n    }\n  }\n  return 0;\n}\n\n\nint Pipe::write_ack(uint64_t seq)\n{\n  ldout(msgr->cct,10) << \"write_ack \" << seq << dendl;\n\n  char c = CEPH_MSGR_TAG_ACK;\n  ceph_le64 s;\n  s = seq;\n\n  struct msghdr msg;\n  memset(&msg, 0, sizeof(msg));\n  struct iovec msgvec[2];\n  msgvec[0].iov_base = &c;\n  msgvec[0].iov_len = 1;\n  msgvec[1].iov_base = &s;\n  msgvec[1].iov_len = sizeof(s);\n  msg.msg_iov = msgvec;\n  msg.msg_iovlen = 2;\n  \n  if (do_sendmsg(&msg, 1 + sizeof(s), true) < 0)\n    return -1;\t\n  return 0;\n}\n\nint Pipe::write_keepalive()\n{\n  ldout(msgr->cct,10) << \"write_keepalive\" << dendl;\n\n  char c = CEPH_MSGR_TAG_KEEPALIVE;\n\n  struct msghdr msg;\n  memset(&msg, 0, sizeof(msg));\n  struct iovec msgvec[2];\n  msgvec[0].iov_base = &c;\n  msgvec[0].iov_len = 1;\n  msg.msg_iov = msgvec;\n  msg.msg_iovlen = 1;\n  \n  if (do_sendmsg(&msg, 1) < 0)\n    return -1;\t\n  return 0;\n}\n\nint Pipe::write_keepalive2(char tag, const utime_t& t)\n{\n  ldout(msgr->cct,10) << \"write_keepalive2 \" << (int)tag << \" \" << t << dendl;\n  struct ceph_timespec ts;\n  t.encode_timeval(&ts);\n  struct msghdr msg;\n  memset(&msg, 0, sizeof(msg));\n  struct iovec msgvec[2];\n  msgvec[0].iov_base = &tag;\n  msgvec[0].iov_len = 1;\n  msgvec[1].iov_base = &ts;\n  msgvec[1].iov_len = sizeof(ts);\n  msg.msg_iov = msgvec;\n  msg.msg_iovlen = 2;\n\n  if (do_sendmsg(&msg, 1 + sizeof(ts)) < 0)\n    return -1;\n  return 0;\n}\n\n\nint Pipe::write_message(const ceph_msg_header& header, const ceph_msg_footer& footer, bufferlist& blist)\n{\n  int ret;\n\n  // set up msghdr and iovecs\n  struct msghdr msg;\n  memset(&msg, 0, sizeof(msg));\n  msg.msg_iov = msgvec;\n  int msglen = 0;\n  \n  // send tag\n  char tag = CEPH_MSGR_TAG_MSG;\n  msgvec[msg.msg_iovlen].iov_base = &tag;\n  msgvec[msg.msg_iovlen].iov_len = 1;\n  msglen++;\n  msg.msg_iovlen++;\n\n  // send envelope\n  ceph_msg_header_old oldheader;\n  if (connection_state->has_feature(CEPH_FEATURE_NOSRCADDR)) {\n    msgvec[msg.msg_iovlen].iov_base = (char*)&header;\n    msgvec[msg.msg_iovlen].iov_len = sizeof(header);\n    msglen += sizeof(header);\n    msg.msg_iovlen++;\n  } else {\n    memcpy(&oldheader, &header, sizeof(header));\n    oldheader.src.name = header.src;\n    oldheader.src.addr = connection_state->get_peer_addr();\n    oldheader.orig_src = oldheader.src;\n    oldheader.reserved = header.reserved;\n    if (msgr->crcflags & MSG_CRC_HEADER) {\n\toldheader.crc = ceph_crc32c(0, (unsigned char*)&oldheader,\n\t\t\t\t    sizeof(oldheader) - sizeof(oldheader.crc));\n    } else {\n\toldheader.crc = 0;\n    }\n    msgvec[msg.msg_iovlen].iov_base = (char*)&oldheader;\n    msgvec[msg.msg_iovlen].iov_len = sizeof(oldheader);\n    msglen += sizeof(oldheader);\n    msg.msg_iovlen++;\n  }\n\n  // payload (front+data)\n  list<bufferptr>::const_iterator pb = blist.buffers().begin();\n  unsigned b_off = 0;  // carry-over buffer offset, if any\n  unsigned bl_pos = 0; // blist pos\n  unsigned left = blist.length();\n\n  while (left > 0) {\n    unsigned donow = MIN(left, pb->length()-b_off);\n    if (donow == 0) {\n      ldout(msgr->cct,0) << \"donow = \" << donow << \" left \" << left << \" pb->length \" << pb->length()\n                         << \" b_off \" << b_off << dendl;\n    }\n    assert(donow > 0);\n    ldout(msgr->cct,30) << \" bl_pos \" << bl_pos << \" b_off \" << b_off\n\t     << \" leftinchunk \" << left\n\t     << \" buffer len \" << pb->length()\n\t     << \" writing \" << donow \n\t     << dendl;\n    \n    if (msg.msg_iovlen >= SM_IOV_MAX-2) {\n      if (do_sendmsg(&msg, msglen, true))\n\tgoto fail;\n      \n      // and restart the iov\n      msg.msg_iov = msgvec;\n      msg.msg_iovlen = 0;\n      msglen = 0;\n    }\n    \n    msgvec[msg.msg_iovlen].iov_base = (void*)(pb->c_str()+b_off);\n    msgvec[msg.msg_iovlen].iov_len = donow;\n    msglen += donow;\n    msg.msg_iovlen++;\n    \n    assert(left >= donow);\n    left -= donow;\n    b_off += donow;\n    bl_pos += donow;\n    if (left == 0)\n      break;\n    while (b_off == pb->length()) {\n      ++pb;\n      b_off = 0;\n    }\n  }\n  assert(left == 0);\n\n  // send footer; if receiver doesn't support signatures, use the old footer format\n\n  ceph_msg_footer_old old_footer;\n  if (connection_state->has_feature(CEPH_FEATURE_MSG_AUTH)) {\n    msgvec[msg.msg_iovlen].iov_base = (void*)&footer;\n    msgvec[msg.msg_iovlen].iov_len = sizeof(footer);\n    msglen += sizeof(footer);\n    msg.msg_iovlen++;\n  } else {\n    if (msgr->crcflags & MSG_CRC_HEADER) {\n      old_footer.front_crc = footer.front_crc;\n      old_footer.middle_crc = footer.middle_crc;\n    } else {\n\told_footer.front_crc = old_footer.middle_crc = 0;\n    }\n    old_footer.data_crc = msgr->crcflags & MSG_CRC_DATA ? footer.data_crc : 0;\n    old_footer.flags = footer.flags;   \n    msgvec[msg.msg_iovlen].iov_base = (char*)&old_footer;\n    msgvec[msg.msg_iovlen].iov_len = sizeof(old_footer);\n    msglen += sizeof(old_footer);\n    msg.msg_iovlen++;\n  }\n\n  // send\n  if (do_sendmsg(&msg, msglen))\n    goto fail;\n\n  ret = 0;\n\n out:\n  return ret;\n\n fail:\n  ret = -1;\n  goto out;\n}\n\n\nint Pipe::tcp_read(char *buf, unsigned len)\n{\n  if (sd < 0)\n    return -EINVAL;\n\n  while (len > 0) {\n\n    if (msgr->cct->_conf->ms_inject_socket_failures && sd >= 0) {\n      if (rand() % msgr->cct->_conf->ms_inject_socket_failures == 0) {\n\tldout(msgr->cct, 0) << \"injecting socket failure\" << dendl;\n\t::shutdown(sd, SHUT_RDWR);\n      }\n    }\n\n    if (tcp_read_wait() < 0)\n      return -1;\n\n    ssize_t got = tcp_read_nonblocking(buf, len);\n\n    if (got < 0)\n      return -1;\n\n    len -= got;\n    buf += got;\n    //lgeneric_dout(cct, DBL) << \"tcp_read got \" << got << \", \" << len << \" left\" << dendl;\n  }\n  return 0;\n}\n\nint Pipe::tcp_read_wait()\n{\n  if (sd < 0)\n    return -EINVAL;\n  struct pollfd pfd;\n  short evmask;\n  pfd.fd = sd;\n  pfd.events = POLLIN;\n#if defined(__linux__)\n  pfd.events |= POLLRDHUP;\n#endif\n\n  if (has_pending_data())\n    return 0;\n\n  int r = poll(&pfd, 1, msgr->timeout);\n  if (r < 0)\n    return -errno;\n  if (r == 0)\n    return -EAGAIN;\n\n  evmask = POLLERR | POLLHUP | POLLNVAL;\n#if defined(__linux__)\n  evmask |= POLLRDHUP;\n#endif\n  if (pfd.revents & evmask)\n    return -1;\n\n  if (!(pfd.revents & POLLIN))\n    return -1;\n\n  return 0;\n}\n\nssize_t Pipe::do_recv(char *buf, size_t len, int flags)\n{\nagain:\n  ssize_t got = ::recv( sd, buf, len, flags );\n  if (got < 0) {\n    if (errno == EINTR) {\n      goto again;\n    }\n    ldout(msgr->cct, 10) << __func__ << \" socket \" << sd << \" returned \"\n\t\t     << got << \" \" << cpp_strerror(errno) << dendl;\n    return -1;\n  }\n  if (got == 0) {\n    return -1;\n  }\n  return got;\n}\n\nssize_t Pipe::buffered_recv(char *buf, size_t len, int flags)\n{\n  size_t left = len;\n  ssize_t total_recv = 0;\n  if (recv_len > recv_ofs) {\n    int to_read = MIN(recv_len - recv_ofs, left);\n    memcpy(buf, &recv_buf[recv_ofs], to_read);\n    recv_ofs += to_read;\n    left -= to_read;\n    if (left == 0) {\n      return to_read;\n    }\n    buf += to_read;\n    total_recv += to_read;\n  }\n\n  /* nothing left in the prefetch buffer */\n\n  if (left > recv_max_prefetch) {\n    /* this was a large read, we don't prefetch for these */\n    ssize_t ret = do_recv(buf, left, flags );\n    if (ret < 0) {\n      if (total_recv > 0)\n        return total_recv;\n      return ret;\n    }\n    total_recv += ret;\n    return total_recv;\n  }\n\n\n  ssize_t got = do_recv(recv_buf, recv_max_prefetch, flags);\n  if (got < 0) {\n    if (total_recv > 0)\n      return total_recv;\n\n    return got;\n  }\n\n  recv_len = (size_t)got;\n  got = MIN(left, (size_t)got);\n  memcpy(buf, recv_buf, got);\n  recv_ofs = got;\n  total_recv += got;\n  return total_recv;\n}\n\nssize_t Pipe::tcp_read_nonblocking(char *buf, unsigned len)\n{\n  ssize_t got = buffered_recv(buf, len, MSG_DONTWAIT );\n  if (got < 0) {\n    ldout(msgr->cct, 10) << __func__ << \" socket \" << sd << \" returned \"\n\t\t         << got << \" \" << cpp_strerror(errno) << dendl;\n    return -1;\n  }\n  if (got == 0) {\n    /* poll() said there was data, but we didn't read any - peer\n     * sent a FIN.  Maybe POLLRDHUP signals this, but this is\n     * standard socket behavior as documented by Stevens.\n     */\n    return -1;\n  }\n  return got;\n}\n\nint Pipe::tcp_write(const char *buf, unsigned len)\n{\n  if (sd < 0)\n    return -1;\n  struct pollfd pfd;\n  pfd.fd = sd;\n  pfd.events = POLLOUT | POLLHUP | POLLNVAL | POLLERR;\n#if defined(__linux__)\n  pfd.events |= POLLRDHUP;\n#endif\n\n  if (msgr->cct->_conf->ms_inject_socket_failures && sd >= 0) {\n    if (rand() % msgr->cct->_conf->ms_inject_socket_failures == 0) {\n      ldout(msgr->cct, 0) << \"injecting socket failure\" << dendl;\n      ::shutdown(sd, SHUT_RDWR);\n    }\n  }\n\n  if (poll(&pfd, 1, -1) < 0)\n    return -1;\n\n  if (!(pfd.revents & POLLOUT))\n    return -1;\n\n  //lgeneric_dout(cct, DBL) << \"tcp_write writing \" << len << dendl;\n  assert(len > 0);\n  while (len > 0) {\n    MSGR_SIGPIPE_STOPPER;\n    int did = ::send( sd, buf, len, MSG_NOSIGNAL );\n    if (did < 0) {\n      //lgeneric_dout(cct, 1) << \"tcp_write error did = \" << did << \" \" << cpp_strerror(errno) << dendl;\n      //lgeneric_derr(cct, 1) << \"tcp_write error did = \" << did << \" \" << cpp_strerror(errno) << dendl;\n      return did;\n    }\n    len -= did;\n    buf += did;\n    //lgeneric_dout(cct, DBL) << \"tcp_write did \" << did << \", \" << len << \" left\" << dendl;\n  }\n  return 0;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#include <errno.h>\n#include <iostream>\n#include <fstream>\n\n\n#include \"SimpleMessenger.h\"\n\n#include \"common/config.h\"\n#include \"common/Timer.h\"\n#include \"common/errno.h\"\n#include \"common/valgrind.h\"\n#include \"auth/Crypto.h\"\n#include \"include/Spinlock.h\"\n\n#define dout_subsys ceph_subsys_ms\n#undef dout_prefix\n#define dout_prefix _prefix(_dout, this)\nstatic ostream& _prefix(std::ostream *_dout, SimpleMessenger *msgr) {\n  return *_dout << \"-- \" << msgr->get_myaddr() << \" \";\n}\n\n\n/*******************\n * SimpleMessenger\n */\n\nSimpleMessenger::SimpleMessenger(CephContext *cct, entity_name_t name,\n\t\t\t\t string mname, uint64_t _nonce)\n  : SimplePolicyMessenger(cct, name,mname, _nonce),\n    accepter(this, _nonce),\n    dispatch_queue(cct, this, mname),\n    reaper_thread(this),\n    nonce(_nonce),\n    lock(\"SimpleMessenger::lock\"), need_addr(true), did_bind(false),\n    global_seq(0),\n    cluster_protocol(0),\n    reaper_started(false), reaper_stop(false),\n    timeout(0),\n    local_connection(new PipeConnection(cct, this))\n{\n  ANNOTATE_BENIGN_RACE_SIZED(&timeout, sizeof(timeout),\n                             \"SimpleMessenger read timeout\");\n  ceph_spin_init(&global_seq_lock);\n  init_local_connection();\n}\n\n/**\n * Destroy the SimpleMessenger. Pretty simple since all the work is done\n * elsewhere.\n */\nSimpleMessenger::~SimpleMessenger()\n{\n  assert(!did_bind); // either we didn't bind or we shut down the Accepter\n  assert(rank_pipe.empty()); // we don't have any running Pipes.\n  assert(!reaper_started); // the reaper thread is stopped\n  ceph_spin_destroy(&global_seq_lock);\n}\n\nvoid SimpleMessenger::ready()\n{\n  ldout(cct,10) << \"ready \" << get_myaddr() << dendl;\n  dispatch_queue.start();\n\n  lock.Lock();\n  if (did_bind)\n    accepter.start();\n  lock.Unlock();\n}\n\n\nint SimpleMessenger::shutdown()\n{\n  ldout(cct,10) << \"shutdown \" << get_myaddr() << dendl;\n  mark_down_all();\n\n  // break ref cycles on the loopback connection\n  local_connection->set_priv(NULL);\n\n  lock.Lock();\n  stop_cond.Signal();\n  stopped = true;\n  lock.Unlock();\n\n  return 0;\n}\n\nint SimpleMessenger::_send_message(Message *m, const entity_inst_t& dest)\n{\n  // set envelope\n  m->get_header().src = get_myname();\n  m->set_cct(cct);\n\n  if (!m->get_priority()) m->set_priority(get_default_send_priority());\n \n  ldout(cct,1) <<\"--> \" << dest.name << \" \"\n          << dest.addr << \" -- \" << *m\n    \t  << \" -- ?+\" << m->get_data().length()\n\t  << \" \" << m \n\t  << dendl;\n\n  if (dest.addr == entity_addr_t()) {\n    ldout(cct,0) << \"send_message message \" << *m\n                 << \" with empty dest \" << dest.addr << dendl;\n    m->put();\n    return -EINVAL;\n  }\n\n  lock.Lock();\n  Pipe *pipe = _lookup_pipe(dest.addr);\n  submit_message(m, (pipe ? pipe->connection_state.get() : NULL),\n                 dest.addr, dest.name.type(), true);\n  lock.Unlock();\n  return 0;\n}\n\nint SimpleMessenger::_send_message(Message *m, Connection *con)\n{\n  //set envelope\n  m->get_header().src = get_myname();\n\n  if (!m->get_priority()) m->set_priority(get_default_send_priority());\n\n  ldout(cct,1) << \"--> \" << con->get_peer_addr()\n      << \" -- \" << *m\n      << \" -- ?+\" << m->get_data().length()\n      << \" \" << m << \" con \" << con\n      << dendl;\n\n  submit_message(m, static_cast<PipeConnection*>(con),\n\t\t con->get_peer_addr(), con->get_peer_type(), false);\n  return 0;\n}\n\n/**\n * If my_inst.addr doesn't have an IP set, this function\n * will fill it in from the passed addr. Otherwise it does nothing and returns.\n */\nvoid SimpleMessenger::set_addr_unknowns(const entity_addr_t &addr)\n{\n  if (my_inst.addr.is_blank_ip()) {\n    int port = my_inst.addr.get_port();\n    my_inst.addr.u = addr.u;\n    my_inst.addr.set_port(port);\n    init_local_connection();\n  }\n}\n\nvoid SimpleMessenger::set_addr(const entity_addr_t &addr)\n{\n  entity_addr_t t = addr;\n  t.set_nonce(nonce);\n  set_myaddr(t);\n  init_local_connection();\n}\n\nint SimpleMessenger::get_proto_version(int peer_type, bool connect)\n{\n  int my_type = my_inst.name.type();\n\n  // set reply protocol version\n  if (peer_type == my_type) {\n    // internal\n    return cluster_protocol;\n  } else {\n    // public\n    if (connect) {\n      switch (peer_type) {\n      case CEPH_ENTITY_TYPE_OSD: return CEPH_OSDC_PROTOCOL;\n      case CEPH_ENTITY_TYPE_MDS: return CEPH_MDSC_PROTOCOL;\n      case CEPH_ENTITY_TYPE_MON: return CEPH_MONC_PROTOCOL;\n      }\n    } else {\n      switch (my_type) {\n      case CEPH_ENTITY_TYPE_OSD: return CEPH_OSDC_PROTOCOL;\n      case CEPH_ENTITY_TYPE_MDS: return CEPH_MDSC_PROTOCOL;\n      case CEPH_ENTITY_TYPE_MON: return CEPH_MONC_PROTOCOL;\n      }\n    }\n  }\n  return 0;\n}\n\n\n\n\n\n\n\n/********************************************\n * SimpleMessenger\n */\n#undef dout_prefix\n#define dout_prefix _prefix(_dout, this)\n\nvoid SimpleMessenger::reaper_entry()\n{\n  ldout(cct,10) << \"reaper_entry start\" << dendl;\n  lock.Lock();\n  while (!reaper_stop) {\n    reaper();  // may drop and retake the lock\n    if (reaper_stop)\n      break;\n    reaper_cond.Wait(lock);\n  }\n  lock.Unlock();\n  ldout(cct,10) << \"reaper_entry done\" << dendl;\n}\n\n/*\n * note: assumes lock is held\n */\nvoid SimpleMessenger::reaper()\n{\n  ldout(cct,10) << \"reaper\" << dendl;\n  assert(lock.is_locked());\n\n  while (!pipe_reap_queue.empty()) {\n    Pipe *p = pipe_reap_queue.front();\n    pipe_reap_queue.pop_front();\n    ldout(cct,10) << \"reaper reaping pipe \" << p << \" \" <<\n      p->get_peer_addr() << dendl;\n    p->pipe_lock.Lock();\n    p->discard_out_queue();\n    if (p->connection_state) {\n      // mark_down, mark_down_all, or fault() should have done this,\n      // or accept() may have switch the Connection to a different\n      // Pipe... but make sure!\n      bool cleared = p->connection_state->clear_pipe(p);\n      assert(!cleared);\n    }\n    p->pipe_lock.Unlock();\n    p->unregister_pipe();\n    assert(pipes.count(p));\n    pipes.erase(p);\n\n    // drop msgr lock while joining thread; the delay through could be\n    // trying to fast dispatch, preventing it from joining without\n    // blocking and deadlocking.\n    lock.Unlock();\n    p->join();\n    lock.Lock();\n\n    if (p->sd >= 0)\n      ::close(p->sd);\n    ldout(cct,10) << \"reaper reaped pipe \" << p << \" \" << p->get_peer_addr() << dendl;\n    p->put();\n    ldout(cct,10) << \"reaper deleted pipe \" << p << dendl;\n  }\n  ldout(cct,10) << \"reaper done\" << dendl;\n}\n\nvoid SimpleMessenger::queue_reap(Pipe *pipe)\n{\n  ldout(cct,10) << \"queue_reap \" << pipe << dendl;\n  lock.Lock();\n  pipe_reap_queue.push_back(pipe);\n  reaper_cond.Signal();\n  lock.Unlock();\n}\n\nbool SimpleMessenger::is_connected(Connection *con)\n{\n  bool r = false;\n  if (con) {\n    Pipe *p = static_cast<Pipe *>(static_cast<PipeConnection*>(con)->get_pipe());\n    if (p) {\n      assert(p->msgr == this);\n      r = p->is_connected();\n      p->put();\n    }\n  }\n  return r;\n}\n\nint SimpleMessenger::bind(const entity_addr_t &bind_addr)\n{\n  lock.Lock();\n  if (started) {\n    ldout(cct,10) << \"rank.bind already started\" << dendl;\n    lock.Unlock();\n    return -1;\n  }\n  ldout(cct,10) << \"rank.bind \" << bind_addr << dendl;\n  lock.Unlock();\n\n  // bind to a socket\n  set<int> avoid_ports;\n  int r = accepter.bind(bind_addr, avoid_ports);\n  if (r >= 0)\n    did_bind = true;\n  return r;\n}\n\nint SimpleMessenger::rebind(const set<int>& avoid_ports)\n{\n  ldout(cct,1) << \"rebind avoid \" << avoid_ports << dendl;\n  assert(did_bind);\n  accepter.stop();\n  mark_down_all();\n  return accepter.rebind(avoid_ports);\n}\n\n\nint SimpleMessenger::client_bind(const entity_addr_t &bind_addr)\n{\n  if (!cct->_conf->ms_bind_before_connect)\n    return 0;\n  Mutex::Locker l(lock);\n  if (did_bind) {\n    assert(my_inst.addr == bind_addr);\n    return 0;\n  }\n  if (started) {\n    ldout(cct,10) << \"rank.bind already started\" << dendl;\n    return -1;\n  }\n  ldout(cct,10) << \"rank.bind \" << bind_addr << dendl;\n\n  set_myaddr(bind_addr);\n  return 0;\n}\n\n\nint SimpleMessenger::start()\n{\n  lock.Lock();\n  ldout(cct,1) << \"messenger.start\" << dendl;\n\n  // register at least one entity, first!\n  assert(my_inst.name.type() >= 0);\n\n  assert(!started);\n  started = true;\n  stopped = false;\n\n  if (!did_bind) {\n    my_inst.addr.nonce = nonce;\n    init_local_connection();\n  }\n\n  lock.Unlock();\n\n  reaper_started = true;\n  reaper_thread.create(\"ms_reaper\");\n  return 0;\n}\n\nPipe *SimpleMessenger::add_accept_pipe(int sd)\n{\n  lock.Lock();\n  Pipe *p = new Pipe(this, Pipe::STATE_ACCEPTING, NULL);\n  p->sd = sd;\n  p->pipe_lock.Lock();\n  p->start_reader();\n  p->pipe_lock.Unlock();\n  pipes.insert(p);\n  accepting_pipes.insert(p);\n  lock.Unlock();\n  return p;\n}\n\n/* connect_rank\n * NOTE: assumes messenger.lock held.\n */\nPipe *SimpleMessenger::connect_rank(const entity_addr_t& addr,\n\t\t\t\t    int type,\n\t\t\t\t    PipeConnection *con,\n\t\t\t\t    Message *first)\n{\n  assert(lock.is_locked());\n  assert(addr != my_inst.addr);\n  \n  ldout(cct,10) << \"connect_rank to \" << addr << \", creating pipe and registering\" << dendl;\n  \n  // create pipe\n  Pipe *pipe = new Pipe(this, Pipe::STATE_CONNECTING,\n\t\t\tstatic_cast<PipeConnection*>(con));\n  pipe->pipe_lock.Lock();\n  pipe->set_peer_type(type);\n  pipe->set_peer_addr(addr);\n  pipe->policy = get_policy(type);\n  pipe->start_writer();\n  if (first)\n    pipe->_send(first);\n  pipe->pipe_lock.Unlock();\n  pipe->register_pipe();\n  pipes.insert(pipe);\n\n  return pipe;\n}\n\n\n\n\n\n\nAuthAuthorizer *SimpleMessenger::get_authorizer(int peer_type, bool force_new)\n{\n  return ms_deliver_get_authorizer(peer_type, force_new);\n}\n\nbool SimpleMessenger::verify_authorizer(Connection *con, int peer_type,\n\t\t\t\t\tint protocol, bufferlist& authorizer, bufferlist& authorizer_reply,\n\t\t\t\t\tbool& isvalid,CryptoKey& session_key,\n\t\t\t\t\tstd::unique_ptr<AuthAuthorizerChallenge> *challenge)\n{\n  return ms_deliver_verify_authorizer(con, peer_type, protocol, authorizer, authorizer_reply,\n\t\t\t\t      isvalid, session_key,\n\t\t\t\t      challenge);\n}\n\nConnectionRef SimpleMessenger::get_connection(const entity_inst_t& dest)\n{\n  Mutex::Locker l(lock);\n  if (my_inst.addr == dest.addr) {\n    // local\n    return local_connection;\n  }\n\n  // remote\n  while (true) {\n    Pipe *pipe = _lookup_pipe(dest.addr);\n    if (pipe) {\n      ldout(cct, 10) << \"get_connection \" << dest << \" existing \" << pipe << dendl;\n    } else {\n      pipe = connect_rank(dest.addr, dest.name.type(), NULL, NULL);\n      ldout(cct, 10) << \"get_connection \" << dest << \" new \" << pipe << dendl;\n    }\n    Mutex::Locker l(pipe->pipe_lock);\n    if (pipe->connection_state)\n      return pipe->connection_state;\n    // we failed too quickly!  retry.  FIXME.\n  }\n}\n\nConnectionRef SimpleMessenger::get_loopback_connection()\n{\n  return local_connection;\n}\n\nvoid SimpleMessenger::submit_message(Message *m, PipeConnection *con,\n\t\t\t\t     const entity_addr_t& dest_addr, int dest_type,\n\t\t\t\t     bool already_locked)\n{\n  m->trace.event(\"simple submitting message\");\n  if (cct->_conf->ms_dump_on_send) {\n    m->encode(-1, true);\n    ldout(cct, 0) << \"submit_message \" << *m << \"\\n\";\n    m->get_payload().hexdump(*_dout);\n    if (m->get_data().length() > 0) {\n      *_dout << \" data:\\n\";\n      m->get_data().hexdump(*_dout);\n    }\n    *_dout << dendl;\n    m->clear_payload();\n  }\n\n  // existing connection?\n  if (con) {\n    Pipe *pipe = NULL;\n    bool ok = static_cast<PipeConnection*>(con)->try_get_pipe(&pipe);\n    if (!ok) {\n      ldout(cct,0) << \"submit_message \" << *m << \" remote, \" << dest_addr\n\t\t   << \", failed lossy con, dropping message \" << m << dendl;\n      m->put();\n      return;\n    }\n    while (pipe && ok) {\n      // we loop in case of a racing reconnect, either from us or them\n      pipe->pipe_lock.Lock(); // can't use a Locker because of the Pipe ref\n      if (pipe->state != Pipe::STATE_CLOSED) {\n\tldout(cct,20) << \"submit_message \" << *m << \" remote, \" << dest_addr << \", have pipe.\" << dendl;\n\tpipe->_send(m);\n\tpipe->pipe_lock.Unlock();\n\tpipe->put();\n\treturn;\n      }\n      Pipe *current_pipe;\n      ok = con->try_get_pipe(&current_pipe);\n      pipe->pipe_lock.Unlock();\n      if (current_pipe == pipe) {\n\tldout(cct,20) << \"submit_message \" << *m << \" remote, \" << dest_addr\n\t\t      << \", had pipe \" << pipe << \", but it closed.\" << dendl;\n\tpipe->put();\n\tcurrent_pipe->put();\n\tm->put();\n\treturn;\n      } else {\n\tpipe->put();\n\tpipe = current_pipe;\n      }\n    }\n  }\n\n  // local?\n  if (my_inst.addr == dest_addr) {\n    // local\n    ldout(cct,20) << \"submit_message \" << *m << \" local\" << dendl;\n    m->set_connection(local_connection.get());\n    dispatch_queue.local_delivery(m, m->get_priority());\n    return;\n  }\n\n  // remote, no existing pipe.\n  const Policy& policy = get_policy(dest_type);\n  if (policy.server) {\n    ldout(cct,20) << \"submit_message \" << *m << \" remote, \" << dest_addr << \", lossy server for target type \"\n\t\t  << ceph_entity_type_name(dest_type) << \", no session, dropping.\" << dendl;\n    m->put();\n  } else {\n    ldout(cct,20) << \"submit_message \" << *m << \" remote, \" << dest_addr << \", new pipe.\" << dendl;\n    if (!already_locked) {\n      /** We couldn't handle the Message without reference to global data, so\n       *  grab the lock and do it again. If we got here, we know it's a non-lossy\n       *  Connection, so we can use our existing pointer without doing another lookup. */\n      Mutex::Locker l(lock);\n      submit_message(m, con, dest_addr, dest_type, true);\n    } else {\n      connect_rank(dest_addr, dest_type, static_cast<PipeConnection*>(con), m);\n    }\n  }\n}\n\nint SimpleMessenger::send_keepalive(Connection *con)\n{\n  int ret = 0;\n  Pipe *pipe = static_cast<Pipe *>(\n    static_cast<PipeConnection*>(con)->get_pipe());\n  if (pipe) {\n    ldout(cct,20) << \"send_keepalive con \" << con << \", have pipe.\" << dendl;\n    assert(pipe->msgr == this);\n    pipe->pipe_lock.Lock();\n    pipe->_send_keepalive();\n    pipe->pipe_lock.Unlock();\n    pipe->put();\n  } else {\n    ldout(cct,0) << \"send_keepalive con \" << con << \", no pipe.\" << dendl;\n    ret = -EPIPE;\n  }\n  return ret;\n}\n\n\n\nvoid SimpleMessenger::wait()\n{\n  lock.Lock();\n  if (!started) {\n    lock.Unlock();\n    return;\n  }\n  if (!stopped)\n    stop_cond.Wait(lock);\n\n  lock.Unlock();\n\n  // done!  clean up.\n  if (did_bind) {\n    ldout(cct,20) << \"wait: stopping accepter thread\" << dendl;\n    accepter.stop();\n    did_bind = false;\n    ldout(cct,20) << \"wait: stopped accepter thread\" << dendl;\n  }\n\n  dispatch_queue.shutdown();\n  if (dispatch_queue.is_started()) {\n    ldout(cct,10) << \"wait: waiting for dispatch queue\" << dendl;\n    dispatch_queue.wait();\n    dispatch_queue.discard_local();\n    ldout(cct,10) << \"wait: dispatch queue is stopped\" << dendl;\n  }\n\n  if (reaper_started) {\n    ldout(cct,20) << \"wait: stopping reaper thread\" << dendl;\n    lock.Lock();\n    reaper_cond.Signal();\n    reaper_stop = true;\n    lock.Unlock();\n    reaper_thread.join();\n    reaper_started = false;\n    ldout(cct,20) << \"wait: stopped reaper thread\" << dendl;\n  }\n\n  // close+reap all pipes\n  lock.Lock();\n  {\n    ldout(cct,10) << \"wait: closing pipes\" << dendl;\n\n    while (!rank_pipe.empty()) {\n      Pipe *p = rank_pipe.begin()->second;\n      p->unregister_pipe();\n      p->pipe_lock.Lock();\n      p->stop_and_wait();\n      // don't generate an event here; we're shutting down anyway.\n      PipeConnectionRef con = p->connection_state;\n      if (con)\n\tcon->clear_pipe(p);\n      p->pipe_lock.Unlock();\n    }\n\n    reaper();\n    ldout(cct,10) << \"wait: waiting for pipes \" << pipes << \" to close\" << dendl;\n    while (!pipes.empty()) {\n      reaper_cond.Wait(lock);\n      reaper();\n    }\n  }\n  lock.Unlock();\n\n  ldout(cct,10) << \"wait: done.\" << dendl;\n  ldout(cct,1) << \"shutdown complete.\" << dendl;\n  started = false;\n}\n\n\nvoid SimpleMessenger::mark_down_all()\n{\n  ldout(cct,1) << \"mark_down_all\" << dendl;\n  lock.Lock();\n  for (set<Pipe*>::iterator q = accepting_pipes.begin(); q != accepting_pipes.end(); ++q) {\n    Pipe *p = *q;\n    ldout(cct,5) << \"mark_down_all accepting_pipe \" << p << dendl;\n    p->pipe_lock.Lock();\n    p->stop();\n    PipeConnectionRef con = p->connection_state;\n    if (con && con->clear_pipe(p))\n      dispatch_queue.queue_reset(con.get());\n    p->pipe_lock.Unlock();\n  }\n  accepting_pipes.clear();\n\n  while (!rank_pipe.empty()) {\n    ceph::unordered_map<entity_addr_t,Pipe*>::iterator it = rank_pipe.begin();\n    Pipe *p = it->second;\n    ldout(cct,5) << \"mark_down_all \" << it->first << \" \" << p << dendl;\n    rank_pipe.erase(it);\n    p->unregister_pipe();\n    p->pipe_lock.Lock();\n    p->stop();\n    PipeConnectionRef con = p->connection_state;\n    if (con && con->clear_pipe(p))\n      dispatch_queue.queue_reset(con.get());\n    p->pipe_lock.Unlock();\n  }\n  lock.Unlock();\n}\n\nvoid SimpleMessenger::mark_down(const entity_addr_t& addr)\n{\n  lock.Lock();\n  Pipe *p = _lookup_pipe(addr);\n  if (p) {\n    ldout(cct,1) << \"mark_down \" << addr << \" -- \" << p << dendl;\n    p->unregister_pipe();\n    p->pipe_lock.Lock();\n    p->stop();\n    if (p->connection_state) {\n      // generate a reset event for the caller in this case, even\n      // though they asked for it, since this is the addr-based (and\n      // not Connection* based) interface\n      PipeConnectionRef con = p->connection_state;\n      if (con && con->clear_pipe(p))\n\tdispatch_queue.queue_reset(con.get());\n    }\n    p->pipe_lock.Unlock();\n  } else {\n    ldout(cct,1) << \"mark_down \" << addr << \" -- pipe dne\" << dendl;\n  }\n  lock.Unlock();\n}\n\nvoid SimpleMessenger::mark_down(Connection *con)\n{\n  if (con == NULL)\n    return;\n  lock.Lock();\n  Pipe *p = static_cast<Pipe *>(static_cast<PipeConnection*>(con)->get_pipe());\n  if (p) {\n    ldout(cct,1) << \"mark_down \" << con << \" -- \" << p << dendl;\n    assert(p->msgr == this);\n    p->unregister_pipe();\n    p->pipe_lock.Lock();\n    p->stop();\n    if (p->connection_state) {\n      // do not generate a reset event for the caller in this case,\n      // since they asked for it.\n      p->connection_state->clear_pipe(p);\n    }\n    p->pipe_lock.Unlock();\n    p->put();\n  } else {\n    ldout(cct,1) << \"mark_down \" << con << \" -- pipe dne\" << dendl;\n  }\n  lock.Unlock();\n}\n\nvoid SimpleMessenger::mark_disposable(Connection *con)\n{\n  lock.Lock();\n  Pipe *p = static_cast<Pipe *>(static_cast<PipeConnection*>(con)->get_pipe());\n  if (p) {\n    ldout(cct,1) << \"mark_disposable \" << con << \" -- \" << p << dendl;\n    assert(p->msgr == this);\n    p->pipe_lock.Lock();\n    p->policy.lossy = true;\n    p->pipe_lock.Unlock();\n    p->put();\n  } else {\n    ldout(cct,1) << \"mark_disposable \" << con << \" -- pipe dne\" << dendl;\n  }\n  lock.Unlock();\n}\n\nvoid SimpleMessenger::learned_addr(const entity_addr_t &peer_addr_for_me)\n{\n  // be careful here: multiple threads may block here, and readers of\n  // my_inst.addr do NOT hold any lock.\n\n  // this always goes from true -> false under the protection of the\n  // mutex.  if it is already false, we need not retake the mutex at\n  // all.\n  if (!need_addr)\n    return;\n\n  lock.Lock();\n  if (need_addr) {\n    entity_addr_t t = peer_addr_for_me;\n    t.set_port(my_inst.addr.get_port());\n    t.set_nonce(my_inst.addr.get_nonce());\n    ANNOTATE_BENIGN_RACE_SIZED(&my_inst.addr, sizeof(my_inst.addr),\n                               \"SimpleMessenger learned addr\");\n    my_inst.addr = t;\n    ldout(cct,1) << \"learned my addr \" << my_inst.addr << dendl;\n    need_addr = false;\n    init_local_connection();\n  }\n  lock.Unlock();\n}\n\nvoid SimpleMessenger::init_local_connection()\n{\n  local_connection->peer_addr = my_inst.addr;\n  local_connection->peer_type = my_inst.name.type();\n  local_connection->set_features(CEPH_FEATURES_ALL);\n  ms_deliver_handle_fast_connect(local_connection.get());\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_SIMPLEMESSENGER_H\n#define CEPH_SIMPLEMESSENGER_H\n\n#include \"include/types.h\"\n#include \"include/xlist.h\"\n\n#include <list>\n#include <map>\nusing namespace std;\n#include \"include/unordered_map.h\"\n#include \"include/unordered_set.h\"\n\n#include \"common/Mutex.h\"\n#include \"include/Spinlock.h\"\n#include \"common/Cond.h\"\n#include \"common/Thread.h\"\n#include \"common/Throttle.h\"\n\n#include \"msg/SimplePolicyMessenger.h\"\n#include \"msg/Message.h\"\n#include \"include/assert.h\"\n\n#include \"msg/DispatchQueue.h\"\n#include \"Pipe.h\"\n#include \"Accepter.h\"\n\n/*\n * This class handles transmission and reception of messages. Generally\n * speaking, there are several major components:\n *\n * - Connection\n *    Each logical session is associated with a Connection.\n * - Pipe\n *    Each network connection is handled through a pipe, which handles\n *    the input and output of each message.  There is normally a 1:1\n *    relationship between Pipe and Connection, but logical sessions may\n *    get handed off between Pipes when sockets reconnect or during\n *    connection races.\n * - IncomingQueue\n *    Incoming messages are associated with an IncomingQueue, and there\n *    is one such queue associated with each Pipe.\n * - DispatchQueue\n *    IncomingQueues get queued in the DIspatchQueue, which is responsible\n *    for doing a round-robin sweep and processing them via a worker thread.\n * - SimpleMessenger\n *    It's the exterior class passed to the external message handler and\n *    most of the API details.\n *\n * Lock ordering:\n *\n *   SimpleMessenger::lock\n *       Pipe::pipe_lock\n *           DispatchQueue::lock\n *               IncomingQueue::lock\n */\n\nclass SimpleMessenger : public SimplePolicyMessenger {\n  // First we have the public Messenger interface implementation...\npublic:\n  /**\n   * Initialize the SimpleMessenger!\n   *\n   * @param cct The CephContext to use\n   * @param name The name to assign ourselves\n   * _nonce A unique ID to use for this SimpleMessenger. It should not\n   * be a value that will be repeated if the daemon restarts.\n   * features The local features bits for the local_connection\n   */\n  SimpleMessenger(CephContext *cct, entity_name_t name,\n\t\t  string mname, uint64_t _nonce);\n\n  /**\n   * Destroy the SimpleMessenger. Pretty simple since all the work is done\n   * elsewhere.\n   */\n  ~SimpleMessenger() override;\n\n  /** @defgroup Accessors\n   * @{\n   */\n  void set_addr_unknowns(const entity_addr_t& addr) override;\n  void set_addr(const entity_addr_t &addr) override;\n\n  int get_dispatch_queue_len() override {\n    return dispatch_queue.get_queue_len();\n  }\n\n  double get_dispatch_queue_max_age(utime_t now) override {\n    return dispatch_queue.get_max_age(now);\n  }\n  /** @} Accessors */\n\n  /**\n   * @defgroup Configuration functions\n   * @{\n   */\n  void set_cluster_protocol(int p) override {\n    assert(!started && !did_bind);\n    cluster_protocol = p;\n  }\n\n  int bind(const entity_addr_t& bind_addr) override;\n  int rebind(const set<int>& avoid_ports) override;\n  int client_bind(const entity_addr_t& bind_addr) override;\n\n  /** @} Configuration functions */\n\n  /**\n   * @defgroup Startup/Shutdown\n   * @{\n   */\n  int start() override;\n  void wait() override;\n  int shutdown() override;\n\n  /** @} // Startup/Shutdown */\n\n  /**\n   * @defgroup Messaging\n   * @{\n   */\n  int send_message(Message *m, const entity_inst_t& dest) override {\n    return _send_message(m, dest);\n  }\n\n  int send_message(Message *m, Connection *con) {\n    return _send_message(m, con);\n  }\n\n  /** @} // Messaging */\n\n  /**\n   * @defgroup Connection Management\n   * @{\n   */\n  ConnectionRef get_connection(const entity_inst_t& dest) override;\n  ConnectionRef get_loopback_connection() override;\n  int send_keepalive(Connection *con);\n  void mark_down(const entity_addr_t& addr) override;\n  void mark_down(Connection *con);\n  void mark_disposable(Connection *con);\n  void mark_down_all() override;\n  /** @} // Connection Management */\nprotected:\n  /**\n   * @defgroup Messenger Interfaces\n   * @{\n   */\n  /**\n   * Start up the DispatchQueue thread once we have somebody to dispatch to.\n   */\n  void ready() override;\n  /** @} // Messenger Interfaces */\nprivate:\n  /**\n   * @defgroup Inner classes\n   * @{\n   */\n\npublic:\n  Accepter accepter;\n  DispatchQueue dispatch_queue;\n\n  friend class Accepter;\n\n  /**\n   * Register a new pipe for accept\n   *\n   * @param sd socket\n   */\n  Pipe *add_accept_pipe(int sd);\n\nprivate:\n\n  /**\n   * A thread used to tear down Pipes when they're complete.\n   */\n  class ReaperThread : public Thread {\n    SimpleMessenger *msgr;\n  public:\n    explicit ReaperThread(SimpleMessenger *m) : msgr(m) {}\n    void *entry() override {\n      msgr->reaper_entry();\n      return 0;\n    }\n  } reaper_thread;\n\n  /**\n   * @} // Inner classes\n   */\n\n  /**\n   * @defgroup Utility functions\n   * @{\n   */\n\n  /**\n   * Create a Pipe associated with the given entity (of the given type).\n   * Initiate the connection. (This function returning does not guarantee\n   * connection success.)\n   *\n   * @param addr The address of the entity to connect to.\n   * @param type The peer type of the entity at the address.\n   * @param con An existing Connection to associate with the new Pipe. If\n   * NULL, it creates a new Connection.\n   * @param first an initial message to queue on the new pipe\n   *\n   * @return a pointer to the newly-created Pipe. Caller does not own a\n   * reference; take one if you need it.\n   */\n  Pipe *connect_rank(const entity_addr_t& addr, int type, PipeConnection *con,\n\t\t     Message *first);\n  /**\n   * Send a message, lazily or not.\n   * This just glues send_message together and passes\n   * the input on to submit_message.\n   */\n  int _send_message(Message *m, const entity_inst_t& dest);\n  /**\n   * Same as above, but for the Connection-based variants.\n   */\n  int _send_message(Message *m, Connection *con);\n  /**\n   * Queue up a Message for delivery to the entity specified\n   * by addr and dest_type.\n   * submit_message() is responsible for creating\n   * new Pipes (and closing old ones) as necessary.\n   *\n   * @param m The Message to queue up. This function eats a reference.\n   * @param con The existing Connection to use, or NULL if you don't know of one.\n   * @param addr The address to send the Message to.\n   * @param dest_type The peer type of the address we're sending to\n   * just drop silently under failure.\n   * @param already_locked If false, submit_message() will acquire the\n   * SimpleMessenger lock before accessing shared data structures; otherwise\n   * it will assume the lock is held. NOTE: if you are making a request\n   * without locking, you MUST have filled in the con with a valid pointer.\n   */\n  void submit_message(Message *m, PipeConnection *con,\n\t\t      const entity_addr_t& addr, int dest_type,\n\t\t      bool already_locked);\n  /**\n   * Look through the pipes in the pipe_reap_queue and tear them down.\n   */\n  void reaper();\n  /**\n   * @} // Utility functions\n   */\n\n  // SimpleMessenger stuff\n  /// approximately unique ID set by the Constructor for use in entity_addr_t\n  uint64_t nonce;\n  /// overall lock used for SimpleMessenger data structures\n  Mutex lock;\n  /// true, specifying we haven't learned our addr; set false when we find it.\n  // maybe this should be protected by the lock?\n  bool need_addr;\n\npublic:\n  bool get_need_addr() const { return need_addr; }\n\nprivate:\n  /**\n   *  false; set to true if the SimpleMessenger bound to a specific address;\n   *  and set false again by Accepter::stop(). This isn't lock-protected\n   *  since you shouldn't be able to race the only writers.\n   */\n  bool did_bind;\n  /// counter for the global seq our connection protocol uses\n  __u32 global_seq;\n  /// lock to protect the global_seq\n  ceph_spinlock_t global_seq_lock;\n\n  /**\n   * hash map of addresses to Pipes\n   *\n   * NOTE: a Pipe* with state CLOSED may still be in the map but is considered\n   * invalid and can be replaced by anyone holding the msgr lock\n   */\n  ceph::unordered_map<entity_addr_t, Pipe*> rank_pipe;\n  /**\n   * list of pipes are in teh process of accepting\n   *\n   * These are not yet in the rank_pipe map.\n   */\n  set<Pipe*> accepting_pipes;\n  /// a set of all the Pipes we have which are somehow active\n  set<Pipe*>      pipes;\n  /// a list of Pipes we want to tear down\n  list<Pipe*>     pipe_reap_queue;\n\n  /// internal cluster protocol version, if any, for talking to entities of the same type.\n  int cluster_protocol;\n\n  Cond  stop_cond;\n  bool stopped = true;\n\n  bool reaper_started, reaper_stop;\n  Cond reaper_cond;\n\n  /// This Cond is slept on by wait() and signaled by dispatch_entry()\n  Cond  wait_cond;\n\n  friend class Pipe;\n\n  Pipe *_lookup_pipe(const entity_addr_t& k) {\n    ceph::unordered_map<entity_addr_t, Pipe*>::iterator p = rank_pipe.find(k);\n    if (p == rank_pipe.end())\n      return NULL;\n    // see lock cribbing in Pipe::fault()\n    if (p->second->state_closed)\n      return NULL;\n    return p->second;\n  }\n\npublic:\n\n  int timeout;\n\n  /// con used for sending messages to ourselves\n  ConnectionRef local_connection;\n\n  /**\n   * @defgroup SimpleMessenger internals\n   * @{\n   */\n\n  /**\n   * This wraps ms_deliver_get_authorizer. We use it for Pipe.\n   */\n  AuthAuthorizer *get_authorizer(int peer_type, bool force_new);\n  /**\n   * This wraps ms_deliver_verify_authorizer; we use it for Pipe.\n   */\n  bool verify_authorizer(Connection *con, int peer_type, int protocol, bufferlist& auth,\n\t\t\t bufferlist& auth_reply,\n                         bool& isvalid,CryptoKey& session_key,\n\t\t\t std::unique_ptr<AuthAuthorizerChallenge> *challenge);\n  /**\n   * Increment the global sequence for this SimpleMessenger and return it.\n   * This is for the connect protocol, although it doesn't hurt if somebody\n   * else calls it.\n   *\n   * @return a global sequence ID that nobody else has seen.\n   */\n  __u32 get_global_seq(__u32 old=0) {\n    ceph_spin_lock(&global_seq_lock);\n    if (old > global_seq)\n      global_seq = old;\n    __u32 ret = ++global_seq;\n    ceph_spin_unlock(&global_seq_lock);\n    return ret;\n  }\n  /**\n   * Get the protocol version we support for the given peer type: either\n   * a peer protocol (if it matches our own), the protocol version for the\n   * peer (if we're connecting), or our protocol version (if we're accepting).\n   */\n  int get_proto_version(int peer_type, bool connect);\n\n  /**\n   * Fill in the features, address and peer type for the local connection, which\n   * is used for delivering messages back to ourself.\n   */\n  void init_local_connection();\n  /**\n   * Tell the SimpleMessenger its full IP address.\n   *\n   * This is used by Pipes when connecting to other endpoints, and\n   * probably shouldn't be called by anybody else.\n   */\n  void learned_addr(const entity_addr_t& peer_addr_for_me);\n\n  /**\n   * This function is used by the reaper thread. As long as nobody\n   * has set reaper_stop, it calls the reaper function, then\n   * waits to be signaled when it needs to reap again (or when it needs\n   * to stop).\n   */\n  void reaper_entry();\n  /**\n   * Add a pipe to the pipe_reap_queue, to be torn down on\n   * the next call to reaper().\n   * It should really only be the Pipe calling this, in our current\n   * implementation.\n   *\n   * @param pipe A Pipe which has stopped its threads and is\n   * ready to be torn down.\n   */\n  void queue_reap(Pipe *pipe);\n\n  /**\n   * Used to get whether this connection ready to send\n   */\n  bool is_connected(Connection *con);\n  /**\n   * @} // SimpleMessenger Internals\n   */\n} ;\n\n#endif /* CEPH_SIMPLEMESSENGER_H */\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n * Copyright (C) 2017 OVH\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n#include \"acconfig.h\"\n\n#include <fstream>\n#include <iostream>\n#include <errno.h>\n#include <sys/stat.h>\n#include <signal.h>\n#include <ctype.h>\n#include <boost/scoped_ptr.hpp>\n\n#ifdef HAVE_SYS_PARAM_H\n#include <sys/param.h>\n#endif\n\n#ifdef HAVE_SYS_MOUNT_H\n#include <sys/mount.h>\n#endif\n\n#include \"osd/PG.h\"\n\n#include \"include/types.h\"\n#include \"include/compat.h\"\n\n#include \"OSD.h\"\n#include \"OSDMap.h\"\n#include \"Watch.h\"\n#include \"osdc/Objecter.h\"\n\n#include \"common/errno.h\"\n#include \"common/ceph_argparse.h\"\n#include \"common/ceph_time.h\"\n#include \"common/version.h\"\n#include \"common/io_priority.h\"\n#include \"common/pick_address.h\"\n\n#include \"os/ObjectStore.h\"\n#ifdef HAVE_LIBFUSE\n#include \"os/FuseStore.h\"\n#endif\n\n#include \"PrimaryLogPG.h\"\n\n\n#include \"msg/Messenger.h\"\n#include \"msg/Message.h\"\n\n#include \"mon/MonClient.h\"\n\n#include \"messages/MLog.h\"\n\n#include \"messages/MGenericMessage.h\"\n#include \"messages/MOSDPing.h\"\n#include \"messages/MOSDFailure.h\"\n#include \"messages/MOSDMarkMeDown.h\"\n#include \"messages/MOSDFull.h\"\n#include \"messages/MOSDOp.h\"\n#include \"messages/MOSDOpReply.h\"\n#include \"messages/MOSDBackoff.h\"\n#include \"messages/MOSDBeacon.h\"\n#include \"messages/MOSDRepOp.h\"\n#include \"messages/MOSDRepOpReply.h\"\n#include \"messages/MOSDBoot.h\"\n#include \"messages/MOSDPGTemp.h\"\n\n#include \"messages/MOSDMap.h\"\n#include \"messages/MMonGetOSDMap.h\"\n#include \"messages/MOSDPGNotify.h\"\n#include \"messages/MOSDPGQuery.h\"\n#include \"messages/MOSDPGLog.h\"\n#include \"messages/MOSDPGRemove.h\"\n#include \"messages/MOSDPGInfo.h\"\n#include \"messages/MOSDPGCreate.h\"\n#include \"messages/MOSDPGTrim.h\"\n#include \"messages/MOSDPGScan.h\"\n#include \"messages/MOSDPGBackfill.h\"\n#include \"messages/MBackfillReserve.h\"\n#include \"messages/MRecoveryReserve.h\"\n#include \"messages/MOSDForceRecovery.h\"\n#include \"messages/MOSDECSubOpWrite.h\"\n#include \"messages/MOSDECSubOpWriteReply.h\"\n#include \"messages/MOSDECSubOpRead.h\"\n#include \"messages/MOSDECSubOpReadReply.h\"\n#include \"messages/MOSDPGCreated.h\"\n#include \"messages/MOSDPGUpdateLogMissing.h\"\n#include \"messages/MOSDPGUpdateLogMissingReply.h\"\n\n#include \"messages/MOSDAlive.h\"\n\n#include \"messages/MOSDScrub.h\"\n#include \"messages/MOSDScrubReserve.h\"\n#include \"messages/MOSDRepScrub.h\"\n\n#include \"messages/MMonCommand.h\"\n#include \"messages/MCommand.h\"\n#include \"messages/MCommandReply.h\"\n\n#include \"messages/MPGStats.h\"\n#include \"messages/MPGStatsAck.h\"\n\n#include \"messages/MWatchNotify.h\"\n#include \"messages/MOSDPGPush.h\"\n#include \"messages/MOSDPGPushReply.h\"\n#include \"messages/MOSDPGPull.h\"\n\n#include \"common/perf_counters.h\"\n#include \"common/Timer.h\"\n#include \"common/LogClient.h\"\n#include \"common/AsyncReserver.h\"\n#include \"common/HeartbeatMap.h\"\n#include \"common/admin_socket.h\"\n#include \"common/ceph_context.h\"\n\n#include \"global/signal_handler.h\"\n#include \"global/pidfile.h\"\n\n#include \"include/color.h\"\n#include \"perfglue/cpu_profiler.h\"\n#include \"perfglue/heap_profiler.h\"\n\n#include \"osd/OpRequest.h\"\n\n#include \"auth/AuthAuthorizeHandler.h\"\n#include \"auth/RotatingKeyRing.h\"\n#include \"common/errno.h\"\n\n#include \"objclass/objclass.h\"\n\n#include \"common/cmdparse.h\"\n#include \"include/str_list.h\"\n#include \"include/util.h\"\n\n#include \"include/assert.h\"\n#include \"common/config.h\"\n#include \"common/EventTrace.h\"\n\n#ifdef WITH_LTTNG\n#define TRACEPOINT_DEFINE\n#define TRACEPOINT_PROBE_DYNAMIC_LINKAGE\n#include \"tracing/osd.h\"\n#undef TRACEPOINT_PROBE_DYNAMIC_LINKAGE\n#undef TRACEPOINT_DEFINE\n#else\n#define tracepoint(...)\n#endif\n\n#define dout_context cct\n#define dout_subsys ceph_subsys_osd\n#undef dout_prefix\n#define dout_prefix _prefix(_dout, whoami, get_osdmap_epoch())\n\n\nconst double OSD::OSD_TICK_INTERVAL = 1.0;\n\nstatic ostream& _prefix(std::ostream* _dout, int whoami, epoch_t epoch) {\n  return *_dout << \"osd.\" << whoami << \" \" << epoch << \" \";\n}\n\n//Initial features in new superblock.\n//Features here are also automatically upgraded\nCompatSet OSD::get_osd_initial_compat_set() {\n  CompatSet::FeatureSet ceph_osd_feature_compat;\n  CompatSet::FeatureSet ceph_osd_feature_ro_compat;\n  CompatSet::FeatureSet ceph_osd_feature_incompat;\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_BASE);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_PGINFO);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_OLOC);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_LEC);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_CATEGORIES);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_HOBJECTPOOL);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_BIGINFO);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_LEVELDBINFO);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_LEVELDBLOG);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_SNAPMAPPER);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_HINTS);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_PGMETA);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_MISSING);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_FASTINFO);\n  ceph_osd_feature_incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_RECOVERY_DELETES);\n  return CompatSet(ceph_osd_feature_compat, ceph_osd_feature_ro_compat,\n\t\t   ceph_osd_feature_incompat);\n}\n\n//Features are added here that this OSD supports.\nCompatSet OSD::get_osd_compat_set() {\n  CompatSet compat =  get_osd_initial_compat_set();\n  //Any features here can be set in code, but not in initial superblock\n  compat.incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_SHARDS);\n  return compat;\n}\n\nOSDService::OSDService(OSD *osd) :\n  osd(osd),\n  cct(osd->cct),\n  meta_osr(new ObjectStore::Sequencer(\"meta\")),\n  whoami(osd->whoami), store(osd->store),\n  log_client(osd->log_client), clog(osd->clog),\n  pg_recovery_stats(osd->pg_recovery_stats),\n  cluster_messenger(osd->cluster_messenger),\n  client_messenger(osd->client_messenger),\n  logger(osd->logger),\n  recoverystate_perf(osd->recoverystate_perf),\n  monc(osd->monc),\n  peering_wq(osd->peering_wq),\n  recovery_gen_wq(\"recovery_gen_wq\", cct->_conf->osd_recovery_thread_timeout,\n\t\t  &osd->disk_tp),\n  class_handler(osd->class_handler),\n  pg_epoch_lock(\"OSDService::pg_epoch_lock\"),\n  publish_lock(\"OSDService::publish_lock\"),\n  pre_publish_lock(\"OSDService::pre_publish_lock\"),\n  max_oldest_map(0),\n  peer_map_epoch_lock(\"OSDService::peer_map_epoch_lock\"),\n  sched_scrub_lock(\"OSDService::sched_scrub_lock\"), scrubs_pending(0),\n  scrubs_active(0),\n  agent_lock(\"OSDService::agent_lock\"),\n  agent_valid_iterator(false),\n  agent_ops(0),\n  flush_mode_high_count(0),\n  agent_active(true),\n  agent_thread(this),\n  agent_stop_flag(false),\n  agent_timer_lock(\"OSDService::agent_timer_lock\"),\n  agent_timer(osd->client_messenger->cct, agent_timer_lock),\n  last_recalibrate(ceph_clock_now()),\n  promote_max_objects(0),\n  promote_max_bytes(0),\n  objecter(new Objecter(osd->client_messenger->cct, osd->objecter_messenger, osd->monc, NULL, 0, 0)),\n  objecter_finisher(osd->client_messenger->cct),\n  watch_lock(\"OSDService::watch_lock\"),\n  watch_timer(osd->client_messenger->cct, watch_lock),\n  next_notif_id(0),\n  recovery_request_lock(\"OSDService::recovery_request_lock\"),\n  recovery_request_timer(cct, recovery_request_lock, false),\n  recovery_sleep_lock(\"OSDService::recovery_sleep_lock\"),\n  recovery_sleep_timer(cct, recovery_sleep_lock, false),\n  reserver_finisher(cct),\n  local_reserver(cct, &reserver_finisher, cct->_conf->osd_max_backfills,\n\t\t cct->_conf->osd_min_recovery_priority),\n  remote_reserver(cct, &reserver_finisher, cct->_conf->osd_max_backfills,\n\t\t  cct->_conf->osd_min_recovery_priority),\n  pg_temp_lock(\"OSDService::pg_temp_lock\"),\n  snap_sleep_lock(\"OSDService::snap_sleep_lock\"),\n  snap_sleep_timer(\n    osd->client_messenger->cct, snap_sleep_lock, false /* relax locking */),\n  scrub_sleep_lock(\"OSDService::scrub_sleep_lock\"),\n  scrub_sleep_timer(\n    osd->client_messenger->cct, scrub_sleep_lock, false /* relax locking */),\n  snap_reserver(cct, &reserver_finisher,\n\t\tcct->_conf->osd_max_trimming_pgs),\n  recovery_lock(\"OSDService::recovery_lock\"),\n  recovery_ops_active(0),\n  recovery_ops_reserved(0),\n  recovery_paused(false),\n  map_cache_lock(\"OSDService::map_cache_lock\"),\n  map_cache(cct, cct->_conf->osd_map_cache_size),\n  map_bl_cache(cct->_conf->osd_map_cache_size),\n  map_bl_inc_cache(cct->_conf->osd_map_cache_size),\n  in_progress_split_lock(\"OSDService::in_progress_split_lock\"),\n  stat_lock(\"OSDService::stat_lock\"),\n  full_status_lock(\"OSDService::full_status_lock\"),\n  cur_state(NONE),\n  cur_ratio(0),\n  epoch_lock(\"OSDService::epoch_lock\"),\n  boot_epoch(0), up_epoch(0), bind_epoch(0),\n  is_stopping_lock(\"OSDService::is_stopping_lock\")\n#ifdef PG_DEBUG_REFS\n  , pgid_lock(\"OSDService::pgid_lock\")\n#endif\n{\n  objecter->init();\n}\n\nOSDService::~OSDService()\n{\n  delete objecter;\n}\n\n\n\n#ifdef PG_DEBUG_REFS\nvoid OSDService::add_pgid(spg_t pgid, PG *pg){\n  Mutex::Locker l(pgid_lock);\n  if (!pgid_tracker.count(pgid)) {\n    live_pgs[pgid] = pg;\n  }\n  pgid_tracker[pgid]++;\n}\nvoid OSDService::remove_pgid(spg_t pgid, PG *pg)\n{\n  Mutex::Locker l(pgid_lock);\n  assert(pgid_tracker.count(pgid));\n  assert(pgid_tracker[pgid] > 0);\n  pgid_tracker[pgid]--;\n  if (pgid_tracker[pgid] == 0) {\n    pgid_tracker.erase(pgid);\n    live_pgs.erase(pgid);\n  }\n}\nvoid OSDService::dump_live_pgids()\n{\n  Mutex::Locker l(pgid_lock);\n  derr << \"live pgids:\" << dendl;\n  for (map<spg_t, int>::const_iterator i = pgid_tracker.cbegin();\n       i != pgid_tracker.cend();\n       ++i) {\n    derr << \"\\t\" << *i << dendl;\n    live_pgs[i->first]->dump_live_ids();\n  }\n}\n#endif\n\n\nvoid OSDService::_start_split(spg_t parent, const set<spg_t> &children)\n{\n  for (set<spg_t>::const_iterator i = children.begin();\n       i != children.end();\n       ++i) {\n    dout(10) << __func__ << \": Starting split on pg \" << *i\n\t     << \", parent=\" << parent << dendl;\n    assert(!pending_splits.count(*i));\n    assert(!in_progress_splits.count(*i));\n    pending_splits.insert(make_pair(*i, parent));\n\n    assert(!rev_pending_splits[parent].count(*i));\n    rev_pending_splits[parent].insert(*i);\n  }\n}\n\nvoid OSDService::mark_split_in_progress(spg_t parent, const set<spg_t> &children)\n{\n  Mutex::Locker l(in_progress_split_lock);\n  map<spg_t, set<spg_t> >::iterator piter = rev_pending_splits.find(parent);\n  assert(piter != rev_pending_splits.end());\n  for (set<spg_t>::const_iterator i = children.begin();\n       i != children.end();\n       ++i) {\n    assert(piter->second.count(*i));\n    assert(pending_splits.count(*i));\n    assert(!in_progress_splits.count(*i));\n    assert(pending_splits[*i] == parent);\n\n    pending_splits.erase(*i);\n    piter->second.erase(*i);\n    in_progress_splits.insert(*i);\n  }\n  if (piter->second.empty())\n    rev_pending_splits.erase(piter);\n}\n\nvoid OSDService::cancel_pending_splits_for_parent(spg_t parent)\n{\n  Mutex::Locker l(in_progress_split_lock);\n  _cancel_pending_splits_for_parent(parent);\n}\n\nvoid OSDService::_cancel_pending_splits_for_parent(spg_t parent)\n{\n  map<spg_t, set<spg_t> >::iterator piter = rev_pending_splits.find(parent);\n  if (piter == rev_pending_splits.end())\n    return;\n\n  for (set<spg_t>::iterator i = piter->second.begin();\n       i != piter->second.end();\n       ++i) {\n    assert(pending_splits.count(*i));\n    assert(!in_progress_splits.count(*i));\n    pending_splits.erase(*i);\n    dout(10) << __func__ << \": Completing split on pg \" << *i\n\t     << \" for parent: \" << parent << dendl;\n    _cancel_pending_splits_for_parent(*i);\n  }\n  rev_pending_splits.erase(piter);\n}\n\nvoid OSDService::_maybe_split_pgid(OSDMapRef old_map,\n\t\t\t\t  OSDMapRef new_map,\n\t\t\t\t  spg_t pgid)\n{\n  assert(old_map->have_pg_pool(pgid.pool()));\n  int old_pgnum = old_map->get_pg_num(pgid.pool());\n  if (pgid.ps() < static_cast<unsigned>(old_pgnum)) {\n    set<spg_t> children;\n    if (pgid.is_split(old_pgnum,\n\t\t  new_map->get_pg_num(pgid.pool()), &children)) { \n      _start_split(pgid, children); }\n  } else {\n    assert(pgid.ps() < static_cast<unsigned>(new_map->get_pg_num(pgid.pool())));\n  }\n}\n\nvoid OSDService::init_splits_between(spg_t pgid,\n\t\t\t\t     OSDMapRef frommap,\n\t\t\t\t     OSDMapRef tomap)\n{\n  // First, check whether we can avoid this potentially expensive check\n  if (tomap->have_pg_pool(pgid.pool()) &&\n      pgid.is_split(\n\tfrommap->get_pg_num(pgid.pool()),\n\ttomap->get_pg_num(pgid.pool()),\n\tNULL)) {\n    // Ok, a split happened, so we need to walk the osdmaps\n    set<spg_t> new_pgs; // pgs to scan on each map\n    new_pgs.insert(pgid);\n    OSDMapRef curmap(get_map(frommap->get_epoch()));\n    for (epoch_t e = frommap->get_epoch() + 1;\n\t e <= tomap->get_epoch();\n\t ++e) {\n      OSDMapRef nextmap(try_get_map(e));\n      if (!nextmap)\n\tcontinue;\n      set<spg_t> even_newer_pgs; // pgs added in this loop\n      for (set<spg_t>::iterator i = new_pgs.begin(); i != new_pgs.end(); ++i) {\n\tset<spg_t> split_pgs;\n\tif (i->is_split(curmap->get_pg_num(i->pool()),\n\t\t\tnextmap->get_pg_num(i->pool()),\n\t\t\t&split_pgs)) {\n\t  start_split(*i, split_pgs);\n\t  even_newer_pgs.insert(split_pgs.begin(), split_pgs.end());\n\t}\n      }\n      new_pgs.insert(even_newer_pgs.begin(), even_newer_pgs.end());\n      curmap = nextmap;\n    }\n    assert(curmap == tomap); // we must have had both frommap and tomap\n  }\n}\n\nvoid OSDService::expand_pg_num(OSDMapRef old_map,\n\t\t\t       OSDMapRef new_map)\n{\n  Mutex::Locker l(in_progress_split_lock);\n  for (set<spg_t>::iterator i = in_progress_splits.begin();\n       i != in_progress_splits.end();\n    ) {\n    if (!new_map->have_pg_pool(i->pool())) {\n      in_progress_splits.erase(i++);\n    } else {\n      _maybe_split_pgid(old_map, new_map, *i);\n      ++i;\n    }\n  }\n  for (map<spg_t, spg_t>::iterator i = pending_splits.begin();\n       i != pending_splits.end();\n    ) {\n    if (!new_map->have_pg_pool(i->first.pool())) {\n      rev_pending_splits.erase(i->second);\n      pending_splits.erase(i++);\n    } else {\n      _maybe_split_pgid(old_map, new_map, i->first);\n      ++i;\n    }\n  }\n}\n\nbool OSDService::splitting(spg_t pgid)\n{\n  Mutex::Locker l(in_progress_split_lock);\n  return in_progress_splits.count(pgid) ||\n    pending_splits.count(pgid);\n}\n\nvoid OSDService::complete_split(const set<spg_t> &pgs)\n{\n  Mutex::Locker l(in_progress_split_lock);\n  for (set<spg_t>::const_iterator i = pgs.begin();\n       i != pgs.end();\n       ++i) {\n    dout(10) << __func__ << \": Completing split on pg \" << *i << dendl;\n    assert(!pending_splits.count(*i));\n    assert(in_progress_splits.count(*i));\n    in_progress_splits.erase(*i);\n  }\n}\n\nvoid OSDService::need_heartbeat_peer_update()\n{\n  osd->need_heartbeat_peer_update();\n}\n\nvoid OSDService::pg_stat_queue_enqueue(PG *pg)\n{\n  osd->pg_stat_queue_enqueue(pg);\n}\n\nvoid OSDService::pg_stat_queue_dequeue(PG *pg)\n{\n  osd->pg_stat_queue_dequeue(pg);\n}\n\nvoid OSDService::start_shutdown()\n{\n  {\n    Mutex::Locker l(agent_timer_lock);\n    agent_timer.shutdown();\n  }\n\n  {\n    Mutex::Locker l(recovery_sleep_lock);\n    recovery_sleep_timer.shutdown();\n  }\n}\n\nvoid OSDService::shutdown_reserver()\n{\n  reserver_finisher.wait_for_empty();\n  reserver_finisher.stop();\n}\n\nvoid OSDService::shutdown()\n{\n  {\n    Mutex::Locker l(watch_lock);\n    watch_timer.shutdown();\n  }\n\n  objecter->shutdown();\n  objecter_finisher.wait_for_empty();\n  objecter_finisher.stop();\n\n  {\n    Mutex::Locker l(recovery_request_lock);\n    recovery_request_timer.shutdown();\n  }\n\n  {\n    Mutex::Locker l(snap_sleep_lock);\n    snap_sleep_timer.shutdown();\n  }\n\n  {\n    Mutex::Locker l(scrub_sleep_lock);\n    scrub_sleep_timer.shutdown();\n  }\n\n  osdmap = OSDMapRef();\n  next_osdmap = OSDMapRef();\n}\n\nvoid OSDService::init()\n{\n  reserver_finisher.start();\n  objecter_finisher.start();\n  objecter->set_client_incarnation(0);\n\n  // deprioritize objecter in daemonperf output\n  objecter->get_logger()->set_prio_adjust(-3);\n\n  watch_timer.init();\n  agent_timer.init();\n  snap_sleep_timer.init();\n  scrub_sleep_timer.init();\n\n  agent_thread.create(\"osd_srv_agent\");\n\n  if (cct->_conf->osd_recovery_delay_start)\n    defer_recovery(cct->_conf->osd_recovery_delay_start);\n}\n\nvoid OSDService::final_init()\n{\n  objecter->start(osdmap.get());\n}\n\nvoid OSDService::activate_map()\n{\n  // wake/unwake the tiering agent\n  agent_lock.Lock();\n  agent_active =\n    !osdmap->test_flag(CEPH_OSDMAP_NOTIERAGENT) &&\n    osd->is_active();\n  agent_cond.Signal();\n  agent_lock.Unlock();\n}\n\nvoid OSDService::request_osdmap_update(epoch_t e)\n{\n  osd->osdmap_subscribe(e, false);\n}\n\nclass AgentTimeoutCB : public Context {\n  PGRef pg;\npublic:\n  explicit AgentTimeoutCB(PGRef _pg) : pg(_pg) {}\n  void finish(int) override {\n    pg->agent_choose_mode_restart();\n  }\n};\n\nvoid OSDService::agent_entry()\n{\n  dout(10) << __func__ << \" start\" << dendl;\n  agent_lock.Lock();\n\n  while (!agent_stop_flag) {\n    if (agent_queue.empty()) {\n      dout(20) << __func__ << \" empty queue\" << dendl;\n      agent_cond.Wait(agent_lock);\n      continue;\n    }\n    uint64_t level = agent_queue.rbegin()->first;\n    set<PGRef>& top = agent_queue.rbegin()->second;\n    dout(10) << __func__\n\t     << \" tiers \" << agent_queue.size()\n\t     << \", top is \" << level\n\t     << \" with pgs \" << top.size()\n\t     << \", ops \" << agent_ops << \"/\"\n\t     << cct->_conf->osd_agent_max_ops\n\t     << (agent_active ? \" active\" : \" NOT ACTIVE\")\n\t     << dendl;\n    dout(20) << __func__ << \" oids \" << agent_oids << dendl;\n    int max = cct->_conf->osd_agent_max_ops - agent_ops;\n    int agent_flush_quota = max;\n    if (!flush_mode_high_count)\n      agent_flush_quota = cct->_conf->osd_agent_max_low_ops - agent_ops;\n    if (agent_flush_quota <= 0 || top.empty() || !agent_active) {\n      agent_cond.Wait(agent_lock);\n      continue;\n    }\n\n    if (!agent_valid_iterator || agent_queue_pos == top.end()) {\n      agent_queue_pos = top.begin();\n      agent_valid_iterator = true;\n    }\n    PGRef pg = *agent_queue_pos;\n    dout(10) << \"high_count \" << flush_mode_high_count\n\t     << \" agent_ops \" << agent_ops\n\t     << \" flush_quota \" << agent_flush_quota << dendl;\n    agent_lock.Unlock();\n    if (!pg->agent_work(max, agent_flush_quota)) {\n      dout(10) << __func__ << \" \" << pg->get_pgid()\n\t<< \" no agent_work, delay for \" << cct->_conf->osd_agent_delay_time\n\t<< \" seconds\" << dendl;\n\n      osd->logger->inc(l_osd_tier_delay);\n      // Queue a timer to call agent_choose_mode for this pg in 5 seconds\n      agent_timer_lock.Lock();\n      Context *cb = new AgentTimeoutCB(pg);\n      agent_timer.add_event_after(cct->_conf->osd_agent_delay_time, cb);\n      agent_timer_lock.Unlock();\n    }\n    agent_lock.Lock();\n  }\n  agent_lock.Unlock();\n  dout(10) << __func__ << \" finish\" << dendl;\n}\n\nvoid OSDService::agent_stop()\n{\n  {\n    Mutex::Locker l(agent_lock);\n\n    // By this time all ops should be cancelled\n    assert(agent_ops == 0);\n    // By this time all PGs are shutdown and dequeued\n    if (!agent_queue.empty()) {\n      set<PGRef>& top = agent_queue.rbegin()->second;\n      derr << \"agent queue not empty, for example \" << (*top.begin())->info.pgid << dendl;\n      assert(0 == \"agent queue not empty\");\n    }\n\n    agent_stop_flag = true;\n    agent_cond.Signal();\n  }\n  agent_thread.join();\n}\n\n// -------------------------------------\n\nvoid OSDService::promote_throttle_recalibrate()\n{\n  utime_t now = ceph_clock_now();\n  double dur = now - last_recalibrate;\n  last_recalibrate = now;\n  unsigned prob = promote_probability_millis;\n\n  uint64_t target_obj_sec = cct->_conf->osd_tier_promote_max_objects_sec;\n  uint64_t target_bytes_sec = cct->_conf->osd_tier_promote_max_bytes_sec;\n\n  unsigned min_prob = 1;\n\n  uint64_t attempts, obj, bytes;\n  promote_counter.sample_and_attenuate(&attempts, &obj, &bytes);\n  dout(10) << __func__ << \" \" << attempts << \" attempts, promoted \"\n\t   << obj << \" objects and \" << pretty_si_t(bytes) << \" bytes; target \"\n\t   << target_obj_sec << \" obj/sec or \"\n\t   << pretty_si_t(target_bytes_sec) << \" bytes/sec\"\n\t   << dendl;\n\n  // calculate what the probability *should* be, given the targets\n  unsigned new_prob;\n  if (attempts && dur > 0) {\n    uint64_t avg_size = 1;\n    if (obj)\n      avg_size = MAX(bytes / obj, 1);\n    unsigned po = (double)target_obj_sec * dur * 1000.0 / (double)attempts;\n    unsigned pb = (double)target_bytes_sec / (double)avg_size * dur * 1000.0\n      / (double)attempts;\n    dout(20) << __func__ << \"  po \" << po << \" pb \" << pb << \" avg_size \"\n\t     << avg_size << dendl;\n    if (target_obj_sec && target_bytes_sec)\n      new_prob = MIN(po, pb);\n    else if (target_obj_sec)\n      new_prob = po;\n    else if (target_bytes_sec)\n      new_prob = pb;\n    else\n      new_prob = 1000;\n  } else {\n    new_prob = 1000;\n  }\n  dout(20) << __func__ << \"  new_prob \" << new_prob << dendl;\n\n  // correct for persistent skew between target rate and actual rate, adjust\n  double ratio = 1.0;\n  unsigned actual = 0;\n  if (attempts && obj) {\n    actual = obj * 1000 / attempts;\n    ratio = (double)actual / (double)prob;\n    new_prob = (double)new_prob / ratio;\n  }\n  new_prob = MAX(new_prob, min_prob);\n  new_prob = MIN(new_prob, 1000);\n\n  // adjust\n  prob = (prob + new_prob) / 2;\n  prob = MAX(prob, min_prob);\n  prob = MIN(prob, 1000);\n  dout(10) << __func__ << \"  actual \" << actual\n\t   << \", actual/prob ratio \" << ratio\n\t   << \", adjusted new_prob \" << new_prob\n\t   << \", prob \" << promote_probability_millis << \" -> \" << prob\n\t   << dendl;\n  promote_probability_millis = prob;\n\n  // set hard limits for this interval to mitigate stampedes\n  promote_max_objects = target_obj_sec * OSD::OSD_TICK_INTERVAL * 2;\n  promote_max_bytes = target_bytes_sec * OSD::OSD_TICK_INTERVAL * 2;\n}\n\n// -------------------------------------\n\nfloat OSDService::get_failsafe_full_ratio()\n{\n  float full_ratio = cct->_conf->osd_failsafe_full_ratio;\n  if (full_ratio > 1.0) full_ratio /= 100.0;\n  return full_ratio;\n}\n\nvoid OSDService::check_full_status(float ratio)\n{\n  Mutex::Locker l(full_status_lock);\n\n  cur_ratio = ratio;\n\n  // The OSDMap ratios take precendence.  So if the failsafe is .95 and\n  // the admin sets the cluster full to .96, the failsafe moves up to .96\n  // too.  (Not that having failsafe == full is ideal, but it's better than\n  // dropping writes before the clusters appears full.)\n  OSDMapRef osdmap = get_osdmap();\n  if (!osdmap || osdmap->get_epoch() == 0) {\n    cur_state = NONE;\n    return;\n  }\n  float nearfull_ratio = osdmap->get_nearfull_ratio();\n  float backfillfull_ratio = std::max(osdmap->get_backfillfull_ratio(), nearfull_ratio);\n  float full_ratio = std::max(osdmap->get_full_ratio(), backfillfull_ratio);\n  float failsafe_ratio = std::max(get_failsafe_full_ratio(), full_ratio);\n\n  if (osdmap->require_osd_release < CEPH_RELEASE_LUMINOUS) {\n    // use the failsafe for nearfull and full; the mon isn't using the\n    // flags anyway because we're mid-upgrade.\n    full_ratio = failsafe_ratio;\n    backfillfull_ratio = failsafe_ratio;\n    nearfull_ratio = failsafe_ratio;\n  } else if (full_ratio <= 0 ||\n\t     backfillfull_ratio <= 0 ||\n\t     nearfull_ratio <= 0) {\n    derr << __func__ << \" full_ratio, backfillfull_ratio or nearfull_ratio is <= 0\" << dendl;\n    // use failsafe flag.  ick.  the monitor did something wrong or the user\n    // did something stupid.\n    full_ratio = failsafe_ratio;\n    backfillfull_ratio = failsafe_ratio;\n    nearfull_ratio = failsafe_ratio;\n  }\n\n  string inject;\n  s_names new_state;\n  if (injectfull_state > NONE && injectfull) {\n    new_state = injectfull_state;\n    inject = \"(Injected)\";\n  } else if (ratio > failsafe_ratio) {\n    new_state = FAILSAFE;\n  } else if (ratio > full_ratio) {\n    new_state = FULL;\n  } else if (ratio > backfillfull_ratio) {\n    new_state = BACKFILLFULL;\n  } else if (ratio > nearfull_ratio) {\n    new_state = NEARFULL;\n  } else {\n    new_state = NONE;\n  }\n  dout(20) << __func__ << \" cur ratio \" << ratio\n\t   << \". nearfull_ratio \" << nearfull_ratio\n\t   << \". backfillfull_ratio \" << backfillfull_ratio\n\t   << \", full_ratio \" << full_ratio\n\t   << \", failsafe_ratio \" << failsafe_ratio\n\t   << \", new state \" << get_full_state_name(new_state)\n\t   << \" \" << inject\n\t   << dendl;\n\n  // warn\n  if (cur_state != new_state) {\n    dout(10) << __func__ << \" \" << get_full_state_name(cur_state)\n\t     << \" -> \" << get_full_state_name(new_state) << dendl;\n    if (new_state == FAILSAFE) {\n      clog->error() << \"full status failsafe engaged, dropping updates, now \"\n\t\t    << (int)roundf(ratio * 100) << \"% full\";\n    } else if (cur_state == FAILSAFE) {\n      clog->error() << \"full status failsafe disengaged, no longer dropping \"\n\t\t     << \"updates, now \" << (int)roundf(ratio * 100) << \"% full\";\n    }\n    cur_state = new_state;\n  }\n}\n\nbool OSDService::need_fullness_update()\n{\n  OSDMapRef osdmap = get_osdmap();\n  s_names cur = NONE;\n  if (osdmap->exists(whoami)) {\n    if (osdmap->get_state(whoami) & CEPH_OSD_FULL) {\n      cur = FULL;\n    } else if (osdmap->get_state(whoami) & CEPH_OSD_BACKFILLFULL) {\n      cur = BACKFILLFULL;\n    } else if (osdmap->get_state(whoami) & CEPH_OSD_NEARFULL) {\n      cur = NEARFULL;\n    }\n  }\n  s_names want = NONE;\n  if (is_full())\n    want = FULL;\n  else if (is_backfillfull())\n    want = BACKFILLFULL;\n  else if (is_nearfull())\n    want = NEARFULL;\n  return want != cur;\n}\n\nbool OSDService::_check_full(s_names type, ostream &ss) const\n{\n  Mutex::Locker l(full_status_lock);\n\n  if (injectfull && injectfull_state >= type) {\n    // injectfull is either a count of the number of times to return failsafe full\n    // or if -1 then always return full\n    if (injectfull > 0)\n      --injectfull;\n    ss << \"Injected \" << get_full_state_name(type) << \" OSD (\"\n       << (injectfull < 0 ? \"set\" : std::to_string(injectfull)) << \")\";\n    return true;\n  }\n\n  ss << \"current usage is \" << cur_ratio;\n  return cur_state >= type;\n}\n\nbool OSDService::check_failsafe_full(ostream &ss) const\n{\n  return _check_full(FAILSAFE, ss);\n}\n\nbool OSDService::check_full(ostream &ss) const\n{\n  return _check_full(FULL, ss);\n}\n\nbool OSDService::check_backfill_full(ostream &ss) const\n{\n  return _check_full(BACKFILLFULL, ss);\n}\n\nbool OSDService::check_nearfull(ostream &ss) const\n{\n  return _check_full(NEARFULL, ss);\n}\n\nbool OSDService::is_failsafe_full() const\n{\n  Mutex::Locker l(full_status_lock);\n  return cur_state == FAILSAFE;\n}\n\nbool OSDService::is_full() const\n{\n  Mutex::Locker l(full_status_lock);\n  return cur_state >= FULL;\n}\n\nbool OSDService::is_backfillfull() const\n{\n  Mutex::Locker l(full_status_lock);\n  return cur_state >= BACKFILLFULL;\n}\n\nbool OSDService::is_nearfull() const\n{\n  Mutex::Locker l(full_status_lock);\n  return cur_state >= NEARFULL;\n}\n\nvoid OSDService::set_injectfull(s_names type, int64_t count)\n{\n  Mutex::Locker l(full_status_lock);\n  injectfull_state = type;\n  injectfull = count;\n}\n\nosd_stat_t OSDService::set_osd_stat(const struct store_statfs_t &stbuf,\n                                    vector<int>& hb_peers,\n\t\t\t\t    int num_pgs)\n{\n  uint64_t bytes = stbuf.total;\n  uint64_t used = bytes - stbuf.available;\n  uint64_t avail = stbuf.available;\n\n  osd->logger->set(l_osd_stat_bytes, bytes);\n  osd->logger->set(l_osd_stat_bytes_used, used);\n  osd->logger->set(l_osd_stat_bytes_avail, avail);\n\n  {\n    Mutex::Locker l(stat_lock);\n    osd_stat.hb_peers.swap(hb_peers);\n    osd->op_tracker.get_age_ms_histogram(&osd_stat.op_queue_age_hist);\n    osd_stat.kb = bytes >> 10;\n    osd_stat.kb_used = used >> 10;\n    osd_stat.kb_avail = avail >> 10;\n    osd_stat.num_pgs = num_pgs;\n    return osd_stat;\n  }\n}\n\nvoid OSDService::update_osd_stat(vector<int>& hb_peers)\n{\n  // load osd stats first\n  struct store_statfs_t stbuf;\n  int r = osd->store->statfs(&stbuf);\n  if (r < 0) {\n    derr << \"statfs() failed: \" << cpp_strerror(r) << dendl;\n    return;\n  }\n\n  auto new_stat = set_osd_stat(stbuf, hb_peers, osd->get_num_pgs());\n  dout(20) << \"update_osd_stat \" << new_stat << dendl;\n  assert(new_stat.kb);\n  float ratio = ((float)new_stat.kb_used) / ((float)new_stat.kb);\n  check_full_status(ratio);\n}\n\nbool OSDService::check_osdmap_full(const set<pg_shard_t> &missing_on)\n{\n  OSDMapRef osdmap = get_osdmap();\n  for (auto shard : missing_on) {\n    if (osdmap->get_state(shard.osd) & CEPH_OSD_FULL)\n      return true;\n  }\n  return false;\n}\n\nvoid OSDService::send_message_osd_cluster(int peer, Message *m, epoch_t from_epoch)\n{\n  OSDMapRef next_map = get_nextmap_reserved();\n  // service map is always newer/newest\n  assert(from_epoch <= next_map->get_epoch());\n\n  if (next_map->is_down(peer) ||\n      next_map->get_info(peer).up_from > from_epoch) {\n    m->put();\n    release_map(next_map);\n    return;\n  }\n  const entity_inst_t& peer_inst = next_map->get_cluster_inst(peer);\n  ConnectionRef peer_con = osd->cluster_messenger->get_connection(peer_inst);\n  share_map_peer(peer, peer_con.get(), next_map);\n  peer_con->send_message(m);\n  release_map(next_map);\n}\n\nConnectionRef OSDService::get_con_osd_cluster(int peer, epoch_t from_epoch)\n{\n  OSDMapRef next_map = get_nextmap_reserved();\n  // service map is always newer/newest\n  assert(from_epoch <= next_map->get_epoch());\n\n  if (next_map->is_down(peer) ||\n      next_map->get_info(peer).up_from > from_epoch) {\n    release_map(next_map);\n    return NULL;\n  }\n  ConnectionRef con = osd->cluster_messenger->get_connection(next_map->get_cluster_inst(peer));\n  release_map(next_map);\n  return con;\n}\n\npair<ConnectionRef,ConnectionRef> OSDService::get_con_osd_hb(int peer, epoch_t from_epoch)\n{\n  OSDMapRef next_map = get_nextmap_reserved();\n  // service map is always newer/newest\n  assert(from_epoch <= next_map->get_epoch());\n\n  pair<ConnectionRef,ConnectionRef> ret;\n  if (next_map->is_down(peer) ||\n      next_map->get_info(peer).up_from > from_epoch) {\n    release_map(next_map);\n    return ret;\n  }\n  ret.first = osd->hb_back_client_messenger->get_connection(next_map->get_hb_back_inst(peer));\n  if (next_map->get_hb_front_addr(peer) != entity_addr_t())\n    ret.second = osd->hb_front_client_messenger->get_connection(next_map->get_hb_front_inst(peer));\n  release_map(next_map);\n  return ret;\n}\n\n\nvoid OSDService::queue_want_pg_temp(pg_t pgid,\n\t\t\t\t    const vector<int>& want,\n\t\t\t\t    bool forced)\n{\n  Mutex::Locker l(pg_temp_lock);\n  auto p = pg_temp_pending.find(pgid);\n  if (p == pg_temp_pending.end() ||\n      p->second.acting != want ||\n      forced) {\n    pg_temp_wanted[pgid] = pg_temp_t{want, forced};\n  }\n}\n\nvoid OSDService::remove_want_pg_temp(pg_t pgid)\n{\n  Mutex::Locker l(pg_temp_lock);\n  pg_temp_wanted.erase(pgid);\n  pg_temp_pending.erase(pgid);\n}\n\nvoid OSDService::_sent_pg_temp()\n{\n  pg_temp_pending.insert(make_move_iterator(begin(pg_temp_wanted)),\n\t\t\t make_move_iterator(end(pg_temp_wanted)));\n  pg_temp_wanted.clear();\n}\n\nvoid OSDService::requeue_pg_temp()\n{\n  Mutex::Locker l(pg_temp_lock);\n  // wanted overrides pending.  note that remove_want_pg_temp\n  // clears the item out of both.\n  unsigned old_wanted = pg_temp_wanted.size();\n  unsigned old_pending = pg_temp_pending.size();\n  _sent_pg_temp();\n  pg_temp_wanted.swap(pg_temp_pending);\n  dout(10) << __func__ << \" \" << old_wanted << \" + \" << old_pending << \" -> \"\n\t   << pg_temp_wanted.size() << dendl;\n}\n\nstd::ostream& operator<<(std::ostream& out,\n\t\t\t const OSDService::pg_temp_t& pg_temp)\n{\n  out << pg_temp.acting;\n  if (pg_temp.forced) {\n    out << \" (forced)\";\n  }\n  return out;\n}\n\nvoid OSDService::send_pg_temp()\n{\n  Mutex::Locker l(pg_temp_lock);\n  if (pg_temp_wanted.empty())\n    return;\n  dout(10) << \"send_pg_temp \" << pg_temp_wanted << dendl;\n  MOSDPGTemp *ms[2] = {nullptr, nullptr};\n  for (auto& pg_temp : pg_temp_wanted) {\n    auto& m = ms[pg_temp.second.forced];\n    if (!m) {\n      m = new MOSDPGTemp(osdmap->get_epoch());\n      m->forced = pg_temp.second.forced;\n    }\n    m->pg_temp.emplace(pg_temp.first,\n\t\t       pg_temp.second.acting);\n  }\n  for (auto m : ms) {\n    if (m) {\n      monc->send_mon_message(m);\n    }\n  }\n  _sent_pg_temp();\n}\n\nvoid OSDService::send_pg_created(pg_t pgid)\n{\n  dout(20) << __func__ << dendl;\n  if (osdmap->require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n    monc->send_mon_message(new MOSDPGCreated(pgid));\n  }\n}\n\n// --------------------------------------\n// dispatch\n\nepoch_t OSDService::get_peer_epoch(int peer)\n{\n  Mutex::Locker l(peer_map_epoch_lock);\n  map<int,epoch_t>::iterator p = peer_map_epoch.find(peer);\n  if (p == peer_map_epoch.end())\n    return 0;\n  return p->second;\n}\n\nepoch_t OSDService::note_peer_epoch(int peer, epoch_t e)\n{\n  Mutex::Locker l(peer_map_epoch_lock);\n  map<int,epoch_t>::iterator p = peer_map_epoch.find(peer);\n  if (p != peer_map_epoch.end()) {\n    if (p->second < e) {\n      dout(10) << \"note_peer_epoch osd.\" << peer << \" has \" << e << dendl;\n      p->second = e;\n    } else {\n      dout(30) << \"note_peer_epoch osd.\" << peer << \" has \" << p->second << \" >= \" << e << dendl;\n    }\n    return p->second;\n  } else {\n    dout(10) << \"note_peer_epoch osd.\" << peer << \" now has \" << e << dendl;\n    peer_map_epoch[peer] = e;\n    return e;\n  }\n}\n\nvoid OSDService::forget_peer_epoch(int peer, epoch_t as_of)\n{\n  Mutex::Locker l(peer_map_epoch_lock);\n  map<int,epoch_t>::iterator p = peer_map_epoch.find(peer);\n  if (p != peer_map_epoch.end()) {\n    if (p->second <= as_of) {\n      dout(10) << \"forget_peer_epoch osd.\" << peer << \" as_of \" << as_of\n\t       << \" had \" << p->second << dendl;\n      peer_map_epoch.erase(p);\n    } else {\n      dout(10) << \"forget_peer_epoch osd.\" << peer << \" as_of \" << as_of\n\t       << \" has \" << p->second << \" - not forgetting\" << dendl;\n    }\n  }\n}\n\nbool OSDService::should_share_map(entity_name_t name, Connection *con,\n                                  epoch_t epoch, const OSDMapRef& osdmap,\n                                  const epoch_t *sent_epoch_p)\n{\n  dout(20) << \"should_share_map \"\n           << name << \" \" << con->get_peer_addr()\n           << \" \" << epoch << dendl;\n\n  // does client have old map?\n  if (name.is_client()) {\n    bool message_sendmap = epoch < osdmap->get_epoch();\n    if (message_sendmap && sent_epoch_p) {\n      dout(20) << \"client session last_sent_epoch: \"\n               << *sent_epoch_p\n               << \" versus osdmap epoch \" << osdmap->get_epoch() << dendl;\n      if (*sent_epoch_p < osdmap->get_epoch()) {\n        return true;\n      } // else we don't need to send it out again\n    }\n  }\n\n  if (con->get_messenger() == osd->cluster_messenger &&\n      con != osd->cluster_messenger->get_loopback_connection() &&\n      osdmap->is_up(name.num()) &&\n      (osdmap->get_cluster_addr(name.num()) == con->get_peer_addr() ||\n       osdmap->get_hb_back_addr(name.num()) == con->get_peer_addr())) {\n    // remember\n    epoch_t has = MAX(get_peer_epoch(name.num()), epoch);\n\n    // share?\n    if (has < osdmap->get_epoch()) {\n      dout(10) << name << \" \" << con->get_peer_addr()\n               << \" has old map \" << epoch << \" < \"\n               << osdmap->get_epoch() << dendl;\n      return true;\n    }\n  }\n\n  return false;\n}\n\nvoid OSDService::share_map(\n    entity_name_t name,\n    Connection *con,\n    epoch_t epoch,\n    OSDMapRef& osdmap,\n    epoch_t *sent_epoch_p)\n{\n  dout(20) << \"share_map \"\n\t   << name << \" \" << con->get_peer_addr()\n\t   << \" \" << epoch << dendl;\n\n  if (!osd->is_active()) {\n    /*It is safe not to proceed as OSD is not in healthy state*/\n    return;\n  }\n\n  bool want_shared = should_share_map(name, con, epoch,\n                                      osdmap, sent_epoch_p);\n\n  if (want_shared){\n    if (name.is_client()) {\n      dout(10) << name << \" has old map \" << epoch\n          << \" < \" << osdmap->get_epoch() << dendl;\n      // we know the Session is valid or we wouldn't be sending\n      if (sent_epoch_p) {\n\t*sent_epoch_p = osdmap->get_epoch();\n      }\n      send_incremental_map(epoch, con, osdmap);\n    } else if (con->get_messenger() == osd->cluster_messenger &&\n        osdmap->is_up(name.num()) &&\n        (osdmap->get_cluster_addr(name.num()) == con->get_peer_addr() ||\n            osdmap->get_hb_back_addr(name.num()) == con->get_peer_addr())) {\n      dout(10) << name << \" \" << con->get_peer_addr()\n\t               << \" has old map \" << epoch << \" < \"\n\t               << osdmap->get_epoch() << dendl;\n      note_peer_epoch(name.num(), osdmap->get_epoch());\n      send_incremental_map(epoch, con, osdmap);\n    }\n  }\n}\n\nvoid OSDService::share_map_peer(int peer, Connection *con, OSDMapRef map)\n{\n  if (!map)\n    map = get_osdmap();\n\n  // send map?\n  epoch_t pe = get_peer_epoch(peer);\n  if (pe) {\n    if (pe < map->get_epoch()) {\n      send_incremental_map(pe, con, map);\n      note_peer_epoch(peer, map->get_epoch());\n    } else\n      dout(20) << \"share_map_peer \" << con << \" already has epoch \" << pe << dendl;\n  } else {\n    dout(20) << \"share_map_peer \" << con << \" don't know epoch, doing nothing\" << dendl;\n    // no idea about peer's epoch.\n    // ??? send recent ???\n    // do nothing.\n  }\n}\n\nbool OSDService::can_inc_scrubs_pending()\n{\n  bool can_inc = false;\n  Mutex::Locker l(sched_scrub_lock);\n\n  if (scrubs_pending + scrubs_active < cct->_conf->osd_max_scrubs) {\n    dout(20) << __func__ << \" \" << scrubs_pending << \" -> \" << (scrubs_pending+1)\n\t     << \" (max \" << cct->_conf->osd_max_scrubs << \", active \" << scrubs_active\n\t     << \")\" << dendl;\n    can_inc = true;\n  } else {\n    dout(20) << __func__ << \" \" << scrubs_pending << \" + \" << scrubs_active\n\t     << \" active >= max \" << cct->_conf->osd_max_scrubs << dendl;\n  }\n\n  return can_inc;\n}\n\nbool OSDService::inc_scrubs_pending()\n{\n  bool result = false;\n\n  sched_scrub_lock.Lock();\n  if (scrubs_pending + scrubs_active < cct->_conf->osd_max_scrubs) {\n    dout(20) << \"inc_scrubs_pending \" << scrubs_pending << \" -> \" << (scrubs_pending+1)\n\t     << \" (max \" << cct->_conf->osd_max_scrubs << \", active \" << scrubs_active << \")\" << dendl;\n    result = true;\n    ++scrubs_pending;\n  } else {\n    dout(20) << \"inc_scrubs_pending \" << scrubs_pending << \" + \" << scrubs_active << \" active >= max \" << cct->_conf->osd_max_scrubs << dendl;\n  }\n  sched_scrub_lock.Unlock();\n\n  return result;\n}\n\nvoid OSDService::dec_scrubs_pending()\n{\n  sched_scrub_lock.Lock();\n  dout(20) << \"dec_scrubs_pending \" << scrubs_pending << \" -> \" << (scrubs_pending-1)\n\t   << \" (max \" << cct->_conf->osd_max_scrubs << \", active \" << scrubs_active << \")\" << dendl;\n  --scrubs_pending;\n  assert(scrubs_pending >= 0);\n  sched_scrub_lock.Unlock();\n}\n\nvoid OSDService::inc_scrubs_active(bool reserved)\n{\n  sched_scrub_lock.Lock();\n  ++(scrubs_active);\n  if (reserved) {\n    --(scrubs_pending);\n    dout(20) << \"inc_scrubs_active \" << (scrubs_active-1) << \" -> \" << scrubs_active\n\t     << \" (max \" << cct->_conf->osd_max_scrubs\n\t     << \", pending \" << (scrubs_pending+1) << \" -> \" << scrubs_pending << \")\" << dendl;\n    assert(scrubs_pending >= 0);\n  } else {\n    dout(20) << \"inc_scrubs_active \" << (scrubs_active-1) << \" -> \" << scrubs_active\n\t     << \" (max \" << cct->_conf->osd_max_scrubs\n\t     << \", pending \" << scrubs_pending << \")\" << dendl;\n  }\n  sched_scrub_lock.Unlock();\n}\n\nvoid OSDService::dec_scrubs_active()\n{\n  sched_scrub_lock.Lock();\n  dout(20) << \"dec_scrubs_active \" << scrubs_active << \" -> \" << (scrubs_active-1)\n\t   << \" (max \" << cct->_conf->osd_max_scrubs << \", pending \" << scrubs_pending << \")\" << dendl;\n  --scrubs_active;\n  assert(scrubs_active >= 0);\n  sched_scrub_lock.Unlock();\n}\n\nvoid OSDService::retrieve_epochs(epoch_t *_boot_epoch, epoch_t *_up_epoch,\n                                 epoch_t *_bind_epoch) const\n{\n  Mutex::Locker l(epoch_lock);\n  if (_boot_epoch)\n    *_boot_epoch = boot_epoch;\n  if (_up_epoch)\n    *_up_epoch = up_epoch;\n  if (_bind_epoch)\n    *_bind_epoch = bind_epoch;\n}\n\nvoid OSDService::set_epochs(const epoch_t *_boot_epoch, const epoch_t *_up_epoch,\n                            const epoch_t *_bind_epoch)\n{\n  Mutex::Locker l(epoch_lock);\n  if (_boot_epoch) {\n    assert(*_boot_epoch == 0 || *_boot_epoch >= boot_epoch);\n    boot_epoch = *_boot_epoch;\n  }\n  if (_up_epoch) {\n    assert(*_up_epoch == 0 || *_up_epoch >= up_epoch);\n    up_epoch = *_up_epoch;\n  }\n  if (_bind_epoch) {\n    assert(*_bind_epoch == 0 || *_bind_epoch >= bind_epoch);\n    bind_epoch = *_bind_epoch;\n  }\n}\n\nbool OSDService::prepare_to_stop()\n{\n  Mutex::Locker l(is_stopping_lock);\n  if (get_state() != NOT_STOPPING)\n    return false;\n\n  OSDMapRef osdmap = get_osdmap();\n  if (osdmap && osdmap->is_up(whoami)) {\n    dout(0) << __func__ << \" telling mon we are shutting down\" << dendl;\n    set_state(PREPARING_TO_STOP);\n    monc->send_mon_message(new MOSDMarkMeDown(monc->get_fsid(),\n\t\t\t\t\t      osdmap->get_inst(whoami),\n\t\t\t\t\t      osdmap->get_epoch(),\n\t\t\t\t\t      true  // request ack\n\t\t\t\t\t      ));\n    utime_t now = ceph_clock_now();\n    utime_t timeout;\n    timeout.set_from_double(now + cct->_conf->osd_mon_shutdown_timeout);\n    while ((ceph_clock_now() < timeout) &&\n       (get_state() != STOPPING)) {\n      is_stopping_cond.WaitUntil(is_stopping_lock, timeout);\n    }\n  }\n  dout(0) << __func__ << \" starting shutdown\" << dendl;\n  set_state(STOPPING);\n  return true;\n}\n\nvoid OSDService::got_stop_ack()\n{\n  Mutex::Locker l(is_stopping_lock);\n  if (get_state() == PREPARING_TO_STOP) {\n    dout(0) << __func__ << \" starting shutdown\" << dendl;\n    set_state(STOPPING);\n    is_stopping_cond.Signal();\n  } else {\n    dout(10) << __func__ << \" ignoring msg\" << dendl;\n  }\n}\n\nMOSDMap *OSDService::build_incremental_map_msg(epoch_t since, epoch_t to,\n                                               OSDSuperblock& sblock)\n{\n  MOSDMap *m = new MOSDMap(monc->get_fsid());\n  m->oldest_map = max_oldest_map;\n  m->newest_map = sblock.newest_map;\n\n  for (epoch_t e = to; e > since; e--) {\n    bufferlist bl;\n    if (e > m->oldest_map && get_inc_map_bl(e, bl)) {\n      m->incremental_maps[e].claim(bl);\n    } else if (get_map_bl(e, bl)) {\n      m->maps[e].claim(bl);\n      break;\n    } else {\n      derr << \"since \" << since << \" to \" << to\n\t   << \" oldest \" << m->oldest_map << \" newest \" << m->newest_map\n\t   << dendl;\n      m->put();\n      m = NULL;\n      break;\n    }\n  }\n  return m;\n}\n\nvoid OSDService::send_map(MOSDMap *m, Connection *con)\n{\n  con->send_message(m);\n}\n\nvoid OSDService::send_incremental_map(epoch_t since, Connection *con,\n                                      OSDMapRef& osdmap)\n{\n  epoch_t to = osdmap->get_epoch();\n  dout(10) << \"send_incremental_map \" << since << \" -> \" << to\n           << \" to \" << con << \" \" << con->get_peer_addr() << dendl;\n\n  MOSDMap *m = NULL;\n  while (!m) {\n    OSDSuperblock sblock(get_superblock());\n    if (since < sblock.oldest_map) {\n      // just send latest full map\n      MOSDMap *m = new MOSDMap(monc->get_fsid());\n      m->oldest_map = max_oldest_map;\n      m->newest_map = sblock.newest_map;\n      get_map_bl(to, m->maps[to]);\n      send_map(m, con);\n      return;\n    }\n\n    if (to > since && (int64_t)(to - since) > cct->_conf->osd_map_share_max_epochs) {\n      dout(10) << \"  \" << (to - since) << \" > max \" << cct->_conf->osd_map_share_max_epochs\n\t       << \", only sending most recent\" << dendl;\n      since = to - cct->_conf->osd_map_share_max_epochs;\n    }\n\n    if (to - since > (epoch_t)cct->_conf->osd_map_message_max)\n      to = since + cct->_conf->osd_map_message_max;\n    m = build_incremental_map_msg(since, to, sblock);\n  }\n  send_map(m, con);\n}\n\nbool OSDService::_get_map_bl(epoch_t e, bufferlist& bl)\n{\n  bool found = map_bl_cache.lookup(e, &bl);\n  if (found) {\n    if (logger)\n      logger->inc(l_osd_map_bl_cache_hit);\n    return true;\n  }\n  if (logger)\n    logger->inc(l_osd_map_bl_cache_miss);\n  found = store->read(coll_t::meta(),\n\t\t      OSD::get_osdmap_pobject_name(e), 0, 0, bl,\n\t\t      CEPH_OSD_OP_FLAG_FADVISE_WILLNEED) >= 0;\n  if (found) {\n    _add_map_bl(e, bl);\n  }\n  return found;\n}\n\nbool OSDService::get_inc_map_bl(epoch_t e, bufferlist& bl)\n{\n  Mutex::Locker l(map_cache_lock);\n  bool found = map_bl_inc_cache.lookup(e, &bl);\n  if (found) {\n    if (logger)\n      logger->inc(l_osd_map_bl_cache_hit);\n    return true;\n  }\n  if (logger)\n    logger->inc(l_osd_map_bl_cache_miss);\n  found = store->read(coll_t::meta(),\n\t\t      OSD::get_inc_osdmap_pobject_name(e), 0, 0, bl,\n\t\t      CEPH_OSD_OP_FLAG_FADVISE_WILLNEED) >= 0;\n  if (found) {\n    _add_map_inc_bl(e, bl);\n  }\n  return found;\n}\n\nvoid OSDService::_add_map_bl(epoch_t e, bufferlist& bl)\n{\n  dout(10) << \"add_map_bl \" << e << \" \" << bl.length() << \" bytes\" << dendl;\n  // cache a contiguous buffer\n  if (bl.get_num_buffers() > 1) {\n    bl.rebuild();\n  }\n  bl.try_assign_to_mempool(mempool::mempool_osd_mapbl);\n  map_bl_cache.add(e, bl);\n}\n\nvoid OSDService::_add_map_inc_bl(epoch_t e, bufferlist& bl)\n{\n  dout(10) << \"add_map_inc_bl \" << e << \" \" << bl.length() << \" bytes\" << dendl;\n  // cache a contiguous buffer\n  if (bl.get_num_buffers() > 1) {\n    bl.rebuild();\n  }\n  bl.try_assign_to_mempool(mempool::mempool_osd_mapbl);\n  map_bl_inc_cache.add(e, bl);\n}\n\nvoid OSDService::pin_map_inc_bl(epoch_t e, bufferlist &bl)\n{\n  Mutex::Locker l(map_cache_lock);\n  // cache a contiguous buffer\n  if (bl.get_num_buffers() > 1) {\n    bl.rebuild();\n  }\n  map_bl_inc_cache.pin(e, bl);\n}\n\nvoid OSDService::pin_map_bl(epoch_t e, bufferlist &bl)\n{\n  Mutex::Locker l(map_cache_lock);\n  // cache a contiguous buffer\n  if (bl.get_num_buffers() > 1) {\n    bl.rebuild();\n  }\n  map_bl_cache.pin(e, bl);\n}\n\nvoid OSDService::clear_map_bl_cache_pins(epoch_t e)\n{\n  Mutex::Locker l(map_cache_lock);\n  map_bl_inc_cache.clear_pinned(e);\n  map_bl_cache.clear_pinned(e);\n}\n\nOSDMapRef OSDService::_add_map(OSDMap *o)\n{\n  epoch_t e = o->get_epoch();\n\n  if (cct->_conf->osd_map_dedup) {\n    // Dedup against an existing map at a nearby epoch\n    OSDMapRef for_dedup = map_cache.lower_bound(e);\n    if (for_dedup) {\n      OSDMap::dedup(for_dedup.get(), o);\n    }\n  }\n  bool existed;\n  OSDMapRef l = map_cache.add(e, o, &existed);\n  if (existed) {\n    delete o;\n  }\n  return l;\n}\n\nOSDMapRef OSDService::try_get_map(epoch_t epoch)\n{\n  Mutex::Locker l(map_cache_lock);\n  OSDMapRef retval = map_cache.lookup(epoch);\n  if (retval) {\n    dout(30) << \"get_map \" << epoch << \" -cached\" << dendl;\n    if (logger) {\n      logger->inc(l_osd_map_cache_hit);\n    }\n    return retval;\n  }\n  if (logger) {\n    logger->inc(l_osd_map_cache_miss);\n    epoch_t lb = map_cache.cached_key_lower_bound();\n    if (epoch < lb) {\n      dout(30) << \"get_map \" << epoch << \" - miss, below lower bound\" << dendl;\n      logger->inc(l_osd_map_cache_miss_low);\n      logger->inc(l_osd_map_cache_miss_low_avg, lb - epoch);\n    }\n  }\n\n  OSDMap *map = new OSDMap;\n  if (epoch > 0) {\n    dout(20) << \"get_map \" << epoch << \" - loading and decoding \" << map << dendl;\n    bufferlist bl;\n    if (!_get_map_bl(epoch, bl) || bl.length() == 0) {\n      derr << \"failed to load OSD map for epoch \" << epoch << \", got \" << bl.length() << \" bytes\" << dendl;\n      delete map;\n      return OSDMapRef();\n    }\n    map->decode(bl);\n  } else {\n    dout(20) << \"get_map \" << epoch << \" - return initial \" << map << dendl;\n  }\n  return _add_map(map);\n}\n\n// ops\n\n\nvoid OSDService::reply_op_error(OpRequestRef op, int err)\n{\n  reply_op_error(op, err, eversion_t(), 0);\n}\n\nvoid OSDService::reply_op_error(OpRequestRef op, int err, eversion_t v,\n                                version_t uv)\n{\n  const MOSDOp *m = static_cast<const MOSDOp*>(op->get_req());\n  assert(m->get_type() == CEPH_MSG_OSD_OP);\n  int flags;\n  flags = m->get_flags() & (CEPH_OSD_FLAG_ACK|CEPH_OSD_FLAG_ONDISK);\n\n  MOSDOpReply *reply = new MOSDOpReply(m, err, osdmap->get_epoch(), flags,\n\t\t\t\t       true);\n  reply->set_reply_versions(v, uv);\n  m->get_connection()->send_message(reply);\n}\n\nvoid OSDService::handle_misdirected_op(PG *pg, OpRequestRef op)\n{\n  if (!cct->_conf->osd_debug_misdirected_ops) {\n    return;\n  }\n\n  const MOSDOp *m = static_cast<const MOSDOp*>(op->get_req());\n  assert(m->get_type() == CEPH_MSG_OSD_OP);\n\n  assert(m->get_map_epoch() >= pg->info.history.same_primary_since);\n\n  if (pg->is_ec_pg()) {\n    /**\n       * OSD recomputes op target based on current OSDMap. With an EC pg, we\n       * can get this result:\n       * 1) client at map 512 sends an op to osd 3, pg_t 3.9 based on mapping\n       *    [CRUSH_ITEM_NONE, 2, 3]/3\n       * 2) OSD 3 at map 513 remaps op to osd 3, spg_t 3.9s0 based on mapping\n       *    [3, 2, 3]/3\n       * 3) PG 3.9s0 dequeues the op at epoch 512 and notices that it isn't primary\n       *    -- misdirected op\n       * 4) client resends and this time PG 3.9s0 having caught up to 513 gets\n       *    it and fulfils it\n       *\n       * We can't compute the op target based on the sending map epoch due to\n       * splitting.  The simplest thing is to detect such cases here and drop\n       * them without an error (the client will resend anyway).\n       */\n    assert(m->get_map_epoch() <= superblock.newest_map);\n    OSDMapRef opmap = try_get_map(m->get_map_epoch());\n    if (!opmap) {\n      dout(7) << __func__ << \": \" << *pg << \" no longer have map for \"\n\t      << m->get_map_epoch() << \", dropping\" << dendl;\n      return;\n    }\n    pg_t _pgid = m->get_raw_pg();\n    spg_t pgid;\n    if ((m->get_flags() & CEPH_OSD_FLAG_PGOP) == 0)\n      _pgid = opmap->raw_pg_to_pg(_pgid);\n    if (opmap->get_primary_shard(_pgid, &pgid) &&\n\tpgid.shard != pg->info.pgid.shard) {\n      dout(7) << __func__ << \": \" << *pg << \" primary changed since \"\n\t      << m->get_map_epoch() << \", dropping\" << dendl;\n      return;\n    }\n  }\n\n  dout(7) << *pg << \" misdirected op in \" << m->get_map_epoch() << dendl;\n  clog->warn() << m->get_source_inst() << \" misdirected \" << m->get_reqid()\n\t       << \" pg \" << m->get_raw_pg()\n\t       << \" to osd.\" << whoami\n\t       << \" not \" << pg->acting\n\t       << \" in e\" << m->get_map_epoch() << \"/\" << osdmap->get_epoch();\n}\n\nvoid OSDService::enqueue_back(spg_t pgid, PGQueueable qi)\n{\n  osd->op_shardedwq.queue(make_pair(pgid, qi));\n}\n\nvoid OSDService::enqueue_front(spg_t pgid, PGQueueable qi)\n{\n  osd->op_shardedwq.queue_front(make_pair(pgid, qi));\n}\n\nvoid OSDService::queue_for_peering(PG *pg)\n{\n  peering_wq.queue(pg);\n}\n\nvoid OSDService::queue_for_snap_trim(PG *pg)\n{\n  dout(10) << \"queueing \" << *pg << \" for snaptrim\" << dendl;\n  osd->op_shardedwq.queue(\n    make_pair(\n      pg->info.pgid,\n      PGQueueable(\n\tPGSnapTrim(pg->get_osdmap()->get_epoch()),\n\tcct->_conf->osd_snap_trim_cost,\n\tcct->_conf->osd_snap_trim_priority,\n\tceph_clock_now(),\n\tentity_inst_t(),\n\tpg->get_osdmap()->get_epoch())));\n}\n\n\n// ====================================================================\n// OSD\n\n#undef dout_prefix\n#define dout_prefix *_dout\n\n// Commands shared between OSD's console and admin console:\nnamespace ceph { \nnamespace osd_cmds { \n\nint heap(CephContext& cct, cmdmap_t& cmdmap, Formatter& f, std::ostream& os);\n \n}} // namespace ceph::osd_cmds\n\nint OSD::mkfs(CephContext *cct, ObjectStore *store, const string &dev,\n\t      uuid_d fsid, int whoami)\n{\n  int ret;\n\n  ceph::shared_ptr<ObjectStore::Sequencer> osr(\n    new ObjectStore::Sequencer(\"mkfs\"));\n  OSDSuperblock sb;\n  bufferlist sbbl;\n  C_SaferCond waiter;\n\n  // if we are fed a uuid for this osd, use it.\n  store->set_fsid(cct->_conf->osd_uuid);\n\n  ret = store->mkfs();\n  if (ret) {\n    derr << \"OSD::mkfs: ObjectStore::mkfs failed with error \"\n         << cpp_strerror(ret) << dendl;\n    goto free_store;\n  }\n\n  store->set_cache_shards(1);  // doesn't matter for mkfs!\n\n  ret = store->mount();\n  if (ret) {\n    derr << \"OSD::mkfs: couldn't mount ObjectStore: error \"\n         << cpp_strerror(ret) << dendl;\n    goto free_store;\n  }\n\n  ret = store->read(coll_t::meta(), OSD_SUPERBLOCK_GOBJECT, 0, 0, sbbl);\n  if (ret >= 0) {\n    /* if we already have superblock, check content of superblock */\n    dout(0) << \" have superblock\" << dendl;\n    bufferlist::iterator p;\n    p = sbbl.begin();\n    ::decode(sb, p);\n    if (whoami != sb.whoami) {\n      derr << \"provided osd id \" << whoami << \" != superblock's \" << sb.whoami\n\t   << dendl;\n      ret = -EINVAL;\n      goto umount_store;\n    }\n    if (fsid != sb.cluster_fsid) {\n      derr << \"provided cluster fsid \" << fsid\n\t   << \" != superblock's \" << sb.cluster_fsid << dendl;\n      ret = -EINVAL;\n      goto umount_store;\n    }\n  } else {\n    // create superblock\n    sb.cluster_fsid = fsid;\n    sb.osd_fsid = store->get_fsid();\n    sb.whoami = whoami;\n    sb.compat_features = get_osd_initial_compat_set();\n\n    bufferlist bl;\n    ::encode(sb, bl);\n\n    ObjectStore::Transaction t;\n    t.create_collection(coll_t::meta(), 0);\n    t.write(coll_t::meta(), OSD_SUPERBLOCK_GOBJECT, 0, bl.length(), bl);\n    ret = store->apply_transaction(osr.get(), std::move(t));\n    if (ret) {\n      derr << \"OSD::mkfs: error while writing OSD_SUPERBLOCK_GOBJECT: \"\n\t   << \"apply_transaction returned \" << cpp_strerror(ret) << dendl;\n      goto umount_store;\n    }\n  }\n\n  if (!osr->flush_commit(&waiter)) {\n    waiter.wait();\n  }\n\n  ret = write_meta(cct, store, sb.cluster_fsid, sb.osd_fsid, whoami);\n  if (ret) {\n    derr << \"OSD::mkfs: failed to write fsid file: error \"\n         << cpp_strerror(ret) << dendl;\n    goto umount_store;\n  }\n\numount_store:\n  store->umount();\nfree_store:\n  delete store;\n  return ret;\n}\n\nint OSD::write_meta(CephContext *cct, ObjectStore *store, uuid_d& cluster_fsid, uuid_d& osd_fsid, int whoami)\n{\n  char val[80];\n  int r;\n\n  snprintf(val, sizeof(val), \"%s\", CEPH_OSD_ONDISK_MAGIC);\n  r = store->write_meta(\"magic\", val);\n  if (r < 0)\n    return r;\n\n  snprintf(val, sizeof(val), \"%d\", whoami);\n  r = store->write_meta(\"whoami\", val);\n  if (r < 0)\n    return r;\n\n  cluster_fsid.print(val);\n  r = store->write_meta(\"ceph_fsid\", val);\n  if (r < 0)\n    return r;\n\n  string key = cct->_conf->get_val<string>(\"key\");\n  if (key.size()) {\n    r = store->write_meta(\"osd_key\", key);\n    if (r < 0)\n      return r;\n  } else {\n    string keyfile = cct->_conf->get_val<string>(\"keyfile\");\n    if (!keyfile.empty()) {\n      bufferlist keybl;\n      string err;\n      if (keyfile == \"-\") {\n\tstatic_assert(1024 * 1024 >\n\t\t      (sizeof(CryptoKey) - sizeof(bufferptr) +\n\t\t       sizeof(__u16) + 16 /* AES_KEY_LEN */ + 3 - 1) / 3. * 4.,\n\t\t      \"1MB should be enough for a base64 encoded CryptoKey\");\n\tr = keybl.read_fd(STDIN_FILENO, 1024 * 1024);\n      } else {\n\tr = keybl.read_file(keyfile.c_str(), &err);\n      }\n      if (r < 0) {\n\tderr << __func__ << \" failed to read keyfile \" << keyfile << \": \"\n\t     << err << \": \" << cpp_strerror(r) << dendl;\n\treturn r;\n      }\n      r = store->write_meta(\"osd_key\", keybl.to_str());\n      if (r < 0)\n\treturn r;\n    }\n  }\n\n  r = store->write_meta(\"ready\", \"ready\");\n  if (r < 0)\n    return r;\n\n  return 0;\n}\n\nint OSD::peek_meta(ObjectStore *store, std::string& magic,\n\t\t   uuid_d& cluster_fsid, uuid_d& osd_fsid, int& whoami)\n{\n  string val;\n\n  int r = store->read_meta(\"magic\", &val);\n  if (r < 0)\n    return r;\n  magic = val;\n\n  r = store->read_meta(\"whoami\", &val);\n  if (r < 0)\n    return r;\n  whoami = atoi(val.c_str());\n\n  r = store->read_meta(\"ceph_fsid\", &val);\n  if (r < 0)\n    return r;\n  r = cluster_fsid.parse(val.c_str());\n  if (!r)\n    return -EINVAL;\n\n  r = store->read_meta(\"fsid\", &val);\n  if (r < 0) {\n    osd_fsid = uuid_d();\n  } else {\n    r = osd_fsid.parse(val.c_str());\n    if (!r)\n      return -EINVAL;\n  }\n\n  return 0;\n}\n\n\n#undef dout_prefix\n#define dout_prefix _prefix(_dout, whoami, get_osdmap_epoch())\n\n// cons/des\n\nOSD::OSD(CephContext *cct_, ObjectStore *store_,\n\t int id,\n\t Messenger *internal_messenger,\n\t Messenger *external_messenger,\n\t Messenger *hb_client_front,\n\t Messenger *hb_client_back,\n\t Messenger *hb_front_serverm,\n\t Messenger *hb_back_serverm,\n\t Messenger *osdc_messenger,\n\t MonClient *mc,\n\t const std::string &dev, const std::string &jdev) :\n  Dispatcher(cct_),\n  osd_lock(\"OSD::osd_lock\"),\n  tick_timer(cct, osd_lock),\n  tick_timer_lock(\"OSD::tick_timer_lock\"),\n  tick_timer_without_osd_lock(cct, tick_timer_lock),\n  authorize_handler_cluster_registry(new AuthAuthorizeHandlerRegistry(cct,\n\t\t\t\t\t\t\t\t      cct->_conf->auth_supported.empty() ?\n\t\t\t\t\t\t\t\t      cct->_conf->auth_cluster_required :\n\t\t\t\t\t\t\t\t      cct->_conf->auth_supported)),\n  authorize_handler_service_registry(new AuthAuthorizeHandlerRegistry(cct,\n\t\t\t\t\t\t\t\t      cct->_conf->auth_supported.empty() ?\n\t\t\t\t\t\t\t\t      cct->_conf->auth_service_required :\n\t\t\t\t\t\t\t\t      cct->_conf->auth_supported)),\n  cluster_messenger(internal_messenger),\n  client_messenger(external_messenger),\n  objecter_messenger(osdc_messenger),\n  monc(mc),\n  mgrc(cct_, client_messenger),\n  logger(NULL),\n  recoverystate_perf(NULL),\n  store(store_),\n  log_client(cct, client_messenger, &mc->monmap, LogClient::NO_FLAGS),\n  clog(log_client.create_channel()),\n  whoami(id),\n  dev_path(dev), journal_path(jdev),\n  store_is_rotational(store->is_rotational()),\n  trace_endpoint(\"0.0.0.0\", 0, \"osd\"),\n  asok_hook(NULL),\n  osd_compat(get_osd_compat_set()),\n  peering_tp(cct, \"OSD::peering_tp\", \"tp_peering\",\n\t     cct->_conf->osd_peering_wq_threads,\n\t     \"osd_peering_tp_threads\"),\n  osd_op_tp(cct, \"OSD::osd_op_tp\", \"tp_osd_tp\",\n\t    get_num_op_threads()),\n  disk_tp(cct, \"OSD::disk_tp\", \"tp_osd_disk\", cct->_conf->osd_disk_threads, \"osd_disk_threads\"),\n  command_tp(cct, \"OSD::command_tp\", \"tp_osd_cmd\",  1),\n  session_waiting_lock(\"OSD::session_waiting_lock\"),\n  osdmap_subscribe_lock(\"OSD::osdmap_subscribe_lock\"),\n  heartbeat_lock(\"OSD::heartbeat_lock\"),\n  heartbeat_stop(false),\n  heartbeat_need_update(true),\n  hb_front_client_messenger(hb_client_front),\n  hb_back_client_messenger(hb_client_back),\n  hb_front_server_messenger(hb_front_serverm),\n  hb_back_server_messenger(hb_back_serverm),\n  daily_loadavg(0.0),\n  heartbeat_thread(this),\n  heartbeat_dispatcher(this),\n  op_tracker(cct, cct->_conf->osd_enable_op_tracker,\n                  cct->_conf->osd_num_op_tracker_shard),\n  test_ops_hook(NULL),\n  op_queue(get_io_queue()),\n  op_prio_cutoff(get_io_prio_cut()),\n  op_shardedwq(\n    get_num_op_shards(),\n    this,\n    cct->_conf->osd_op_thread_timeout,\n    cct->_conf->osd_op_thread_suicide_timeout,\n    &osd_op_tp),\n  peering_wq(\n    this,\n    cct->_conf->osd_op_thread_timeout,\n    cct->_conf->osd_op_thread_suicide_timeout,\n    &peering_tp),\n  map_lock(\"OSD::map_lock\"),\n  pg_map_lock(\"OSD::pg_map_lock\"),\n  last_pg_create_epoch(0),\n  mon_report_lock(\"OSD::mon_report_lock\"),\n  stats_ack_timeout(cct->_conf->osd_mon_ack_timeout),\n  up_thru_wanted(0),\n  requested_full_first(0),\n  requested_full_last(0),\n  pg_stat_queue_lock(\"OSD::pg_stat_queue_lock\"),\n  osd_stat_updated(false),\n  pg_stat_tid(0), pg_stat_tid_flushed(0),\n  command_wq(\n    this,\n    cct->_conf->osd_command_thread_timeout,\n    cct->_conf->osd_command_thread_suicide_timeout,\n    &command_tp),\n  remove_wq(\n    cct,\n    store,\n    cct->_conf->osd_remove_thread_timeout,\n    cct->_conf->osd_remove_thread_suicide_timeout,\n    &disk_tp),\n  service(this)\n{\n  monc->set_messenger(client_messenger);\n  op_tracker.set_complaint_and_threshold(cct->_conf->osd_op_complaint_time,\n                                         cct->_conf->osd_op_log_threshold);\n  op_tracker.set_history_size_and_duration(cct->_conf->osd_op_history_size,\n                                           cct->_conf->osd_op_history_duration);\n  op_tracker.set_history_slow_op_size_and_threshold(cct->_conf->osd_op_history_slow_op_size,\n                                                    cct->_conf->osd_op_history_slow_op_threshold);\n#ifdef WITH_BLKIN\n  std::stringstream ss;\n  ss << \"osd.\" << whoami;\n  trace_endpoint.copy_name(ss.str());\n#endif\n}\n\nOSD::~OSD()\n{\n  delete authorize_handler_cluster_registry;\n  delete authorize_handler_service_registry;\n  delete class_handler;\n  cct->get_perfcounters_collection()->remove(recoverystate_perf);\n  cct->get_perfcounters_collection()->remove(logger);\n  delete recoverystate_perf;\n  delete logger;\n  delete store;\n}\n\nvoid cls_initialize(ClassHandler *ch);\n\nvoid OSD::handle_signal(int signum)\n{\n  assert(signum == SIGINT || signum == SIGTERM);\n  derr << \"*** Got signal \" << sig_str(signum) << \" ***\" << dendl;\n  shutdown();\n}\n\nint OSD::pre_init()\n{\n  Mutex::Locker lock(osd_lock);\n  if (is_stopping())\n    return 0;\n\n  if (store->test_mount_in_use()) {\n    derr << \"OSD::pre_init: object store '\" << dev_path << \"' is \"\n         << \"currently in use. (Is ceph-osd already running?)\" << dendl;\n    return -EBUSY;\n  }\n\n  cct->_conf->add_observer(this);\n  return 0;\n}\n\n// asok\n\nclass OSDSocketHook : public AdminSocketHook {\n  OSD *osd;\npublic:\n  explicit OSDSocketHook(OSD *o) : osd(o) {}\n  bool call(std::string admin_command, cmdmap_t& cmdmap, std::string format,\n\t    bufferlist& out) override {\n    stringstream ss;\n    bool r = osd->asok_command(admin_command, cmdmap, format, ss);\n    out.append(ss);\n    return r;\n  }\n};\n\nbool OSD::asok_command(string admin_command, cmdmap_t& cmdmap, string format,\n\t\t       ostream& ss)\n{\n  Formatter *f = Formatter::create(format, \"json-pretty\", \"json-pretty\");\n  if (admin_command == \"status\") {\n    f->open_object_section(\"status\");\n    f->dump_stream(\"cluster_fsid\") << superblock.cluster_fsid;\n    f->dump_stream(\"osd_fsid\") << superblock.osd_fsid;\n    f->dump_unsigned(\"whoami\", superblock.whoami);\n    f->dump_string(\"state\", get_state_name(get_state()));\n    f->dump_unsigned(\"oldest_map\", superblock.oldest_map);\n    f->dump_unsigned(\"newest_map\", superblock.newest_map);\n    {\n      RWLock::RLocker l(pg_map_lock);\n      f->dump_unsigned(\"num_pgs\", pg_map.size());\n    }\n    f->close_section();\n  } else if (admin_command == \"flush_journal\") {\n    store->flush_journal();\n  } else if (admin_command == \"dump_ops_in_flight\" ||\n             admin_command == \"ops\" ||\n             admin_command == \"dump_blocked_ops\" ||\n             admin_command == \"dump_historic_ops\" ||\n             admin_command == \"dump_historic_ops_by_duration\" ||\n             admin_command == \"dump_historic_slow_ops\") {\n\n    const string error_str = \"op_tracker tracking is not enabled now, so no ops are tracked currently, \\\neven those get stuck. Please enable \\\"osd_enable_op_tracker\\\", and the tracker \\\nwill start to track new ops received afterwards.\";\n\n    set<string> filters;\n    vector<string> filter_str;\n    if (cmd_getval(cct, cmdmap, \"filterstr\", filter_str)) {\n        copy(filter_str.begin(), filter_str.end(),\n           inserter(filters, filters.end()));\n    }\n\n    if (admin_command == \"dump_ops_in_flight\" ||\n        admin_command == \"ops\") {\n      if (!op_tracker.dump_ops_in_flight(f, false, filters)) {\n        ss << error_str;\n      }\n    }\n    if (admin_command == \"dump_blocked_ops\") {\n      if (!op_tracker.dump_ops_in_flight(f, true, filters)) {\n        ss << error_str;\n      }\n    }\n    if (admin_command == \"dump_historic_ops\") {\n      if (!op_tracker.dump_historic_ops(f, false, filters)) {\n        ss << error_str;\n      }\n    }\n    if (admin_command == \"dump_historic_ops_by_duration\") {\n      if (!op_tracker.dump_historic_ops(f, true, filters)) {\n        ss << error_str;\n      }\n    }\n    if (admin_command == \"dump_historic_slow_ops\") {\n      if (!op_tracker.dump_historic_slow_ops(f, filters)) {\n        ss << error_str;\n      }\n    }\n  } else if (admin_command == \"dump_op_pq_state\") {\n    f->open_object_section(\"pq\");\n    op_shardedwq.dump(f);\n    f->close_section();\n  } else if (admin_command == \"dump_blacklist\") {\n    list<pair<entity_addr_t,utime_t> > bl;\n    OSDMapRef curmap = service.get_osdmap();\n\n    f->open_array_section(\"blacklist\");\n    curmap->get_blacklist(&bl);\n    for (list<pair<entity_addr_t,utime_t> >::iterator it = bl.begin();\n\tit != bl.end(); ++it) {\n      f->open_object_section(\"entry\");\n      f->open_object_section(\"entity_addr_t\");\n      it->first.dump(f);\n      f->close_section(); //entity_addr_t\n      it->second.localtime(f->dump_stream(\"expire_time\"));\n      f->close_section(); //entry\n    }\n    f->close_section(); //blacklist\n  } else if (admin_command == \"dump_watchers\") {\n    list<obj_watch_item_t> watchers;\n    // scan pg's\n    {\n      Mutex::Locker l(osd_lock);\n      RWLock::RLocker l2(pg_map_lock);\n      for (ceph::unordered_map<spg_t,PG*>::iterator it = pg_map.begin();\n          it != pg_map.end();\n          ++it) {\n\n        list<obj_watch_item_t> pg_watchers;\n        PG *pg = it->second;\n        pg->lock();\n        pg->get_watchers(pg_watchers);\n        pg->unlock();\n        watchers.splice(watchers.end(), pg_watchers);\n      }\n    }\n\n    f->open_array_section(\"watchers\");\n    for (list<obj_watch_item_t>::iterator it = watchers.begin();\n\tit != watchers.end(); ++it) {\n\n      f->open_object_section(\"watch\");\n\n      f->dump_string(\"namespace\", it->obj.nspace);\n      f->dump_string(\"object\", it->obj.oid.name);\n\n      f->open_object_section(\"entity_name\");\n      it->wi.name.dump(f);\n      f->close_section(); //entity_name_t\n\n      f->dump_unsigned(\"cookie\", it->wi.cookie);\n      f->dump_unsigned(\"timeout\", it->wi.timeout_seconds);\n\n      f->open_object_section(\"entity_addr_t\");\n      it->wi.addr.dump(f);\n      f->close_section(); //entity_addr_t\n\n      f->close_section(); //watch\n    }\n\n    f->close_section(); //watchers\n  } else if (admin_command == \"dump_reservations\") {\n    f->open_object_section(\"reservations\");\n    f->open_object_section(\"local_reservations\");\n    service.local_reserver.dump(f);\n    f->close_section();\n    f->open_object_section(\"remote_reservations\");\n    service.remote_reserver.dump(f);\n    f->close_section();\n    f->close_section();\n  } else if (admin_command == \"get_latest_osdmap\") {\n    get_latest_osdmap();\n  } else if (admin_command == \"heap\") {\n    auto result = ceph::osd_cmds::heap(*cct, cmdmap, *f, ss);\n\n    // Note: Failed heap profile commands won't necessarily trigger an error:\n    f->open_object_section(\"result\");\n    f->dump_string(\"error\", cpp_strerror(result));\n    f->dump_bool(\"success\", result >= 0);\n    f->close_section();\n  } else if (admin_command == \"set_heap_property\") {\n    string property;\n    int64_t value = 0;\n    string error;\n    bool success = false;\n    if (!cmd_getval(cct, cmdmap, \"property\", property)) {\n      error = \"unable to get property\";\n      success = false;\n    } else if (!cmd_getval(cct, cmdmap, \"value\", value)) {\n      error = \"unable to get value\";\n      success = false;\n    } else if (value < 0) {\n      error = \"negative value not allowed\";\n      success = false;\n    } else if (!ceph_heap_set_numeric_property(property.c_str(), (size_t)value)) {\n      error = \"invalid property\";\n      success = false;\n    } else {\n      success = true;\n    }\n    f->open_object_section(\"result\");\n    f->dump_string(\"error\", error);\n    f->dump_bool(\"success\", success);\n    f->close_section();\n  } else if (admin_command == \"get_heap_property\") {\n    string property;\n    size_t value = 0;\n    string error;\n    bool success = false;\n    if (!cmd_getval(cct, cmdmap, \"property\", property)) {\n      error = \"unable to get property\";\n      success = false;\n    } else if (!ceph_heap_get_numeric_property(property.c_str(), &value)) {\n      error = \"invalid property\";\n      success = false;\n    } else {\n      success = true;\n    }\n    f->open_object_section(\"result\");\n    f->dump_string(\"error\", error);\n    f->dump_bool(\"success\", success);\n    f->dump_int(\"value\", value);\n    f->close_section();\n  } else if (admin_command == \"dump_objectstore_kv_stats\") {\n    store->get_db_statistics(f);\n  } else if (admin_command == \"dump_scrubs\") {\n    service.dumps_scrub(f);\n  } else if (admin_command == \"calc_objectstore_db_histogram\") {\n    store->generate_db_histogram(f);\n  } else if (admin_command == \"flush_store_cache\") {\n    store->flush_cache();\n  } else if (admin_command == \"dump_pgstate_history\") {\n    f->open_object_section(\"pgstate_history\");\n    RWLock::RLocker l2(pg_map_lock);\n    for (ceph::unordered_map<spg_t,PG*>::iterator it = pg_map.begin();\n        it != pg_map.end();\n        ++it) {\n\n      PG *pg = it->second;\n      f->dump_stream(\"pg\") << pg->get_pgid();\n      pg->lock();\n      pg->pgstate_history.dump(f);\n      pg->unlock();\n    }\n    f->close_section();\n  } else if (admin_command == \"compact\") {\n    dout(1) << \"triggering manual compaction\" << dendl;\n    auto start = ceph::coarse_mono_clock::now();\n    store->compact();\n    auto end = ceph::coarse_mono_clock::now();\n    auto time_span = chrono::duration_cast<chrono::duration<double>>(end - start);\n    dout(1) << \"finished manual compaction in \" \n            << time_span.count()\n            << \" seconds\" << dendl;\n    f->open_object_section(\"compact_result\");\n    f->dump_float(\"elapsed_time\", time_span.count());\n    f->close_section();\n  } else {\n    assert(0 == \"broken asok registration\");\n  }\n  f->flush(ss);\n  delete f;\n  return true;\n}\n\nclass TestOpsSocketHook : public AdminSocketHook {\n  OSDService *service;\n  ObjectStore *store;\npublic:\n  TestOpsSocketHook(OSDService *s, ObjectStore *st) : service(s), store(st) {}\n  bool call(std::string command, cmdmap_t& cmdmap, std::string format,\n\t    bufferlist& out) override {\n    stringstream ss;\n    test_ops(service, store, command, cmdmap, ss);\n    out.append(ss);\n    return true;\n  }\n  void test_ops(OSDService *service, ObjectStore *store,\n\t\tconst std::string &command, cmdmap_t& cmdmap, ostream &ss);\n\n};\n\nclass OSD::C_Tick : public Context {\n  OSD *osd;\n  public:\n  explicit C_Tick(OSD *o) : osd(o) {}\n  void finish(int r) override {\n    osd->tick();\n  }\n};\n\nclass OSD::C_Tick_WithoutOSDLock : public Context {\n  OSD *osd;\n  public:\n  explicit C_Tick_WithoutOSDLock(OSD *o) : osd(o) {}\n  void finish(int r) override {\n    osd->tick_without_osd_lock();\n  }\n};\n\nint OSD::enable_disable_fuse(bool stop)\n{\n#ifdef HAVE_LIBFUSE\n  int r;\n  string mntpath = cct->_conf->osd_data + \"/fuse\";\n  if (fuse_store && (stop || !cct->_conf->osd_objectstore_fuse)) {\n    dout(1) << __func__ << \" disabling\" << dendl;\n    fuse_store->stop();\n    delete fuse_store;\n    fuse_store = NULL;\n    r = ::rmdir(mntpath.c_str());\n    if (r < 0) {\n      r = -errno;\n      derr << __func__ << \" failed to rmdir \" << mntpath << \": \"\n           << cpp_strerror(r) << dendl;\n      return r;\n    }\n    return 0;\n  }\n  if (!fuse_store && cct->_conf->osd_objectstore_fuse) {\n    dout(1) << __func__ << \" enabling\" << dendl;\n    r = ::mkdir(mntpath.c_str(), 0700);\n    if (r < 0)\n      r = -errno;\n    if (r < 0 && r != -EEXIST) {\n      derr << __func__ << \" unable to create \" << mntpath << \": \"\n\t   << cpp_strerror(r) << dendl;\n      return r;\n    }\n    fuse_store = new FuseStore(store, mntpath);\n    r = fuse_store->start();\n    if (r < 0) {\n      derr << __func__ << \" unable to start fuse: \" << cpp_strerror(r) << dendl;\n      delete fuse_store;\n      fuse_store = NULL;\n      return r;\n    }\n  }\n#endif  // HAVE_LIBFUSE\n  return 0;\n}\n\nint OSD::get_num_op_shards()\n{\n  if (cct->_conf->osd_op_num_shards)\n    return cct->_conf->osd_op_num_shards;\n  if (store_is_rotational)\n    return cct->_conf->osd_op_num_shards_hdd;\n  else\n    return cct->_conf->osd_op_num_shards_ssd;\n}\n\nint OSD::get_num_op_threads()\n{\n  if (cct->_conf->osd_op_num_threads_per_shard)\n    return get_num_op_shards() * cct->_conf->osd_op_num_threads_per_shard;\n  if (store_is_rotational)\n    return get_num_op_shards() * cct->_conf->osd_op_num_threads_per_shard_hdd;\n  else\n    return get_num_op_shards() * cct->_conf->osd_op_num_threads_per_shard_ssd;\n}\n\nfloat OSD::get_osd_recovery_sleep()\n{\n  if (cct->_conf->osd_recovery_sleep)\n    return cct->_conf->osd_recovery_sleep;\n  if (!store_is_rotational && !journal_is_rotational)\n    return cct->_conf->osd_recovery_sleep_ssd;\n  else if (store_is_rotational && !journal_is_rotational)\n    return cct->_conf->get_val<double>(\"osd_recovery_sleep_hybrid\");\n  else\n    return cct->_conf->osd_recovery_sleep_hdd;\n}\n\nint OSD::init()\n{\n  CompatSet initial, diff;\n  Mutex::Locker lock(osd_lock);\n  if (is_stopping())\n    return 0;\n\n  tick_timer.init();\n  tick_timer_without_osd_lock.init();\n  service.recovery_request_timer.init();\n  service.recovery_sleep_timer.init();\n\n  // mount.\n  dout(2) << \"init \" << dev_path\n\t  << \" (looks like \" << (store_is_rotational ? \"hdd\" : \"ssd\") << \")\"\n\t  << dendl;\n  dout(2) << \"journal \" << journal_path << dendl;\n  assert(store);  // call pre_init() first!\n\n  store->set_cache_shards(get_num_op_shards());\n\n  int r = store->mount();\n  if (r < 0) {\n    derr << \"OSD:init: unable to mount object store\" << dendl;\n    return r;\n  }\n  journal_is_rotational = store->is_journal_rotational();\n  dout(2) << \"journal looks like \" << (journal_is_rotational ? \"hdd\" : \"ssd\")\n          << dendl;\n\n  enable_disable_fuse(false);\n\n  dout(2) << \"boot\" << dendl;\n\n  // initialize the daily loadavg with current 15min loadavg\n  double loadavgs[3];\n  if (getloadavg(loadavgs, 3) == 3) {\n    daily_loadavg = loadavgs[2];\n  } else {\n    derr << \"OSD::init() : couldn't read loadavgs\\n\" << dendl;\n    daily_loadavg = 1.0;\n  }\n\n  int rotating_auth_attempts = 0;\n\n  // sanity check long object name handling\n  {\n    hobject_t l;\n    l.oid.name = string(cct->_conf->osd_max_object_name_len, 'n');\n    l.set_key(string(cct->_conf->osd_max_object_name_len, 'k'));\n    l.nspace = string(cct->_conf->osd_max_object_namespace_len, 's');\n    r = store->validate_hobject_key(l);\n    if (r < 0) {\n      derr << \"backend (\" << store->get_type() << \") is unable to support max \"\n\t   << \"object name[space] len\" << dendl;\n      derr << \"   osd max object name len = \"\n\t   << cct->_conf->osd_max_object_name_len << dendl;\n      derr << \"   osd max object namespace len = \"\n\t   << cct->_conf->osd_max_object_namespace_len << dendl;\n      derr << cpp_strerror(r) << dendl;\n      if (cct->_conf->osd_check_max_object_name_len_on_startup) {\n\tgoto out;\n      }\n      derr << \"osd_check_max_object_name_len_on_startup = false, starting anyway\"\n\t   << dendl;\n    } else {\n      dout(20) << \"configured osd_max_object_name[space]_len looks ok\" << dendl;\n    }\n  }\n\n  // read superblock\n  r = read_superblock();\n  if (r < 0) {\n    derr << \"OSD::init() : unable to read osd superblock\" << dendl;\n    r = -EINVAL;\n    goto out;\n  }\n\n  if (osd_compat.compare(superblock.compat_features) < 0) {\n    derr << \"The disk uses features unsupported by the executable.\" << dendl;\n    derr << \" ondisk features \" << superblock.compat_features << dendl;\n    derr << \" daemon features \" << osd_compat << dendl;\n\n    if (osd_compat.writeable(superblock.compat_features)) {\n      CompatSet diff = osd_compat.unsupported(superblock.compat_features);\n      derr << \"it is still writeable, though. Missing features: \" << diff << dendl;\n      r = -EOPNOTSUPP;\n      goto out;\n    }\n    else {\n      CompatSet diff = osd_compat.unsupported(superblock.compat_features);\n      derr << \"Cannot write to disk! Missing features: \" << diff << dendl;\n      r = -EOPNOTSUPP;\n      goto out;\n    }\n  }\n\n  assert_warn(whoami == superblock.whoami);\n  if (whoami != superblock.whoami) {\n    derr << \"OSD::init: superblock says osd\"\n\t << superblock.whoami << \" but I am osd.\" << whoami << dendl;\n    r = -EINVAL;\n    goto out;\n  }\n\n  initial = get_osd_initial_compat_set();\n  diff = superblock.compat_features.unsupported(initial);\n  if (superblock.compat_features.merge(initial)) {\n    // We need to persist the new compat_set before we\n    // do anything else\n    dout(5) << \"Upgrading superblock adding: \" << diff << dendl;\n    ObjectStore::Transaction t;\n    write_superblock(t);\n    r = store->apply_transaction(service.meta_osr.get(), std::move(t));\n    if (r < 0)\n      goto out;\n  }\n\n  // make sure snap mapper object exists\n  if (!store->exists(coll_t::meta(), OSD::make_snapmapper_oid())) {\n    dout(10) << \"init creating/touching snapmapper object\" << dendl;\n    ObjectStore::Transaction t;\n    t.touch(coll_t::meta(), OSD::make_snapmapper_oid());\n    r = store->apply_transaction(service.meta_osr.get(), std::move(t));\n    if (r < 0)\n      goto out;\n  }\n\n  class_handler = new ClassHandler(cct);\n  cls_initialize(class_handler);\n\n  if (cct->_conf->osd_open_classes_on_start) {\n    int r = class_handler->open_all_classes();\n    if (r)\n      dout(1) << \"warning: got an error loading one or more classes: \" << cpp_strerror(r) << dendl;\n  }\n\n  // load up \"current\" osdmap\n  assert_warn(!osdmap);\n  if (osdmap) {\n    derr << \"OSD::init: unable to read current osdmap\" << dendl;\n    r = -EINVAL;\n    goto out;\n  }\n  osdmap = get_map(superblock.current_epoch);\n  check_osdmap_features(store);\n\n  create_recoverystate_perf();\n\n  {\n    epoch_t bind_epoch = osdmap->get_epoch();\n    service.set_epochs(NULL, NULL, &bind_epoch);\n  }\n\n  clear_temp_objects();\n\n  // initialize osdmap references in sharded wq\n  op_shardedwq.prune_pg_waiters(osdmap, whoami);\n\n  // load up pgs (as they previously existed)\n  load_pgs();\n\n  dout(2) << \"superblock: I am osd.\" << superblock.whoami << dendl;\n  dout(0) << \"using \" << op_queue << \" op queue with priority op cut off at \" <<\n    op_prio_cutoff << \".\" << dendl;\n\n  create_logger();\n\n  // i'm ready!\n  client_messenger->add_dispatcher_head(this);\n  cluster_messenger->add_dispatcher_head(this);\n\n  hb_front_client_messenger->add_dispatcher_head(&heartbeat_dispatcher);\n  hb_back_client_messenger->add_dispatcher_head(&heartbeat_dispatcher);\n  hb_front_server_messenger->add_dispatcher_head(&heartbeat_dispatcher);\n  hb_back_server_messenger->add_dispatcher_head(&heartbeat_dispatcher);\n\n  objecter_messenger->add_dispatcher_head(service.objecter);\n\n  monc->set_want_keys(CEPH_ENTITY_TYPE_MON | CEPH_ENTITY_TYPE_OSD\n                      | CEPH_ENTITY_TYPE_MGR);\n  r = monc->init();\n  if (r < 0)\n    goto out;\n\n  /**\n   * FIXME: this is a placeholder implementation that unconditionally\n   * sends every is_primary PG's stats every time we're called, unlike\n   * the existing mon PGStats mechanism that uses pg_stat_queue and acks.\n   * This has equivalent cost to the existing worst case where all\n   * PGs are busy and their stats are always enqueued for sending.\n   */\n  mgrc.set_pgstats_cb([this](){\n      RWLock::RLocker l(map_lock);\n      \n      utime_t had_for = ceph_clock_now() - had_map_since;\n      osd_stat_t cur_stat = service.get_osd_stat();\n      cur_stat.os_perf_stat = store->get_cur_stats();\n\n      MPGStats *m = new MPGStats(monc->get_fsid(), osdmap->get_epoch(), had_for);\n      m->osd_stat = cur_stat;\n\n      Mutex::Locker lec{min_last_epoch_clean_lock};\n      min_last_epoch_clean = osdmap->get_epoch();\n      min_last_epoch_clean_pgs.clear();\n      RWLock::RLocker lpg(pg_map_lock);\n      for (const auto &i : pg_map) {\n        PG *pg = i.second;\n        if (!pg->is_primary()) {\n          continue;\n        }\n\n        pg->pg_stats_publish_lock.Lock();\n        if (pg->pg_stats_publish_valid) {\n          m->pg_stat[pg->info.pgid.pgid] = pg->pg_stats_publish;\n\t  const auto lec = pg->pg_stats_publish.get_effective_last_epoch_clean();\n\t  min_last_epoch_clean = min(min_last_epoch_clean, lec);\n\t  min_last_epoch_clean_pgs.push_back(pg->info.pgid.pgid);\n        }\n        pg->pg_stats_publish_lock.Unlock();\n      }\n\n      return m;\n  });\n\n  mgrc.init();\n  client_messenger->add_dispatcher_head(&mgrc);\n\n  // tell monc about log_client so it will know about mon session resets\n  monc->set_log_client(&log_client);\n  update_log_config();\n\n  peering_tp.start();\n  \n  service.init();\n  service.publish_map(osdmap);\n  service.publish_superblock(superblock);\n  service.max_oldest_map = superblock.oldest_map;\n\n  osd_op_tp.start();\n  disk_tp.start();\n  command_tp.start();\n\n  set_disk_tp_priority();\n\n  // start the heartbeat\n  heartbeat_thread.create(\"osd_srv_heartbt\");\n\n  // tick\n  tick_timer.add_event_after(cct->_conf->osd_heartbeat_interval, new C_Tick(this));\n  {\n    Mutex::Locker l(tick_timer_lock);\n    tick_timer_without_osd_lock.add_event_after(cct->_conf->osd_heartbeat_interval, new C_Tick_WithoutOSDLock(this));\n  }\n\n  osd_lock.Unlock();\n\n  r = monc->authenticate();\n  if (r < 0) {\n    derr << __func__ << \" authentication failed: \" << cpp_strerror(r)\n         << dendl;\n    osd_lock.Lock(); // locker is going to unlock this on function exit\n    if (is_stopping())\n      r = 0;\n    goto monout;\n  }\n\n  while (monc->wait_auth_rotating(30.0) < 0) {\n    derr << \"unable to obtain rotating service keys; retrying\" << dendl;\n    ++rotating_auth_attempts;\n    if (rotating_auth_attempts > g_conf->max_rotating_auth_attempts) {\n        derr << __func__ << \" wait_auth_rotating timed out\" << dendl;\n        osd_lock.Lock(); // make locker happy\n        if (!is_stopping()) {\n            r = -ETIMEDOUT;\n        }\n        goto monout;\n    }\n  }\n\n  r = update_crush_device_class();\n  if (r < 0) {\n    derr << __func__ << \" unable to update_crush_device_class: \"\n\t << cpp_strerror(r) << dendl;\n    osd_lock.Lock();\n    goto monout;\n  }\n\n  r = update_crush_location();\n  if (r < 0) {\n    derr << __func__ << \" unable to update_crush_location: \"\n         << cpp_strerror(r) << dendl;\n    osd_lock.Lock();\n    goto monout;\n  }\n\n  osd_lock.Lock();\n  if (is_stopping())\n    return 0;\n\n  // start objecter *after* we have authenticated, so that we don't ignore\n  // the OSDMaps it requests.\n  service.final_init();\n\n  check_config();\n\n  dout(10) << \"ensuring pgs have consumed prior maps\" << dendl;\n  consume_map();\n  peering_wq.drain();\n\n  dout(0) << \"done with init, starting boot process\" << dendl;\n\n  // subscribe to any pg creations\n  monc->sub_want(\"osd_pg_creates\", last_pg_create_epoch, 0);\n\n  // MgrClient needs this (it doesn't have MonClient reference itself)\n  monc->sub_want(\"mgrmap\", 0, 0);\n\n  // we don't need to ask for an osdmap here; objecter will\n  //monc->sub_want(\"osdmap\", osdmap->get_epoch(), CEPH_SUBSCRIBE_ONETIME);\n\n  monc->renew_subs();\n\n  start_boot();\n\n  return 0;\nmonout:\n  exit(1);\n\nout:\n  enable_disable_fuse(true);\n  store->umount();\n  delete store;\n  store = NULL;\n  return r;\n}\n\nvoid OSD::final_init()\n{\n  AdminSocket *admin_socket = cct->get_admin_socket();\n  asok_hook = new OSDSocketHook(this);\n  int r = admin_socket->register_command(\"status\", \"status\", asok_hook,\n\t\t\t\t\t \"high-level status of OSD\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"flush_journal\", \"flush_journal\",\n                                     asok_hook,\n                                     \"flush the journal to permanent store\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_ops_in_flight\",\n\t\t\t\t     \"dump_ops_in_flight \" \\\n\t\t\t\t     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show the ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"ops\",\n\t\t\t\t     \"ops \" \\\n\t\t\t\t     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show the ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_blocked_ops\",\n\t\t\t\t     \"dump_blocked_ops \" \\\n\t\t\t\t     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show the blocked ops currently in flight\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_historic_ops\",\n                                     \"dump_historic_ops \" \\\n                                     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show recent ops\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_historic_slow_ops\",\n                                     \"dump_historic_slow_ops \" \\\n                                     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show slowest recent ops\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_historic_ops_by_duration\",\n                                     \"dump_historic_ops_by_duration \" \\\n                                     \"name=filterstr,type=CephString,n=N,req=false\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show slowest recent ops, sorted by duration\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_op_pq_state\", \"dump_op_pq_state\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"dump op priority queue state\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_blacklist\", \"dump_blacklist\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"dump blacklisted clients and times\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_watchers\", \"dump_watchers\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show clients which have active watches,\"\n\t\t\t\t     \" and on which objects\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_reservations\", \"dump_reservations\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show recovery reservations\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"get_latest_osdmap\", \"get_latest_osdmap\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"force osd to update the latest map from \"\n\t\t\t\t     \"the mon\");\n  assert(r == 0);\n\n  r = admin_socket->register_command( \"heap\",\n                                      \"heap \" \\\n                                      \"name=heapcmd,type=CephString\",\n                                      asok_hook,\n                                      \"show heap usage info (available only if \"\n                                      \"compiled with tcmalloc)\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"set_heap_property\",\n\t\t\t\t     \"set_heap_property \" \\\n\t\t\t\t     \"name=property,type=CephString \" \\\n\t\t\t\t     \"name=value,type=CephInt\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"update malloc extension heap property\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"get_heap_property\",\n\t\t\t\t     \"get_heap_property \" \\\n\t\t\t\t     \"name=property,type=CephString\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"get malloc extension heap property\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"dump_objectstore_kv_stats\",\n\t\t\t\t     \"dump_objectstore_kv_stats\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"print statistics of kvdb which used by bluestore\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"dump_scrubs\",\n\t\t\t\t     \"dump_scrubs\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"print scheduled scrubs\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"calc_objectstore_db_histogram\",\n                                     \"calc_objectstore_db_histogram\",\n                                     asok_hook,\n                                     \"Generate key value histogram of kvdb(rocksdb) which used by bluestore\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"flush_store_cache\",\n                                     \"flush_store_cache\",\n                                     asok_hook,\n                                     \"Flush bluestore internal cache\");\n  assert(r == 0);\n  r = admin_socket->register_command(\"dump_pgstate_history\", \"dump_pgstate_history\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"show recent state history\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\"compact\", \"compact\",\n\t\t\t\t     asok_hook,\n\t\t\t\t     \"Commpact object store's omap.\"\n                                     \" WARNING: Compaction probably slows your requests\");\n  assert(r == 0);\n\n  test_ops_hook = new TestOpsSocketHook(&(this->service), this->store);\n  // Note: pools are CephString instead of CephPoolname because\n  // these commands traditionally support both pool names and numbers\n  r = admin_socket->register_command(\n   \"setomapval\",\n   \"setomapval \" \\\n   \"name=pool,type=CephString \" \\\n   \"name=objname,type=CephObjectname \" \\\n   \"name=key,type=CephString \"\\\n   \"name=val,type=CephString\",\n   test_ops_hook,\n   \"set omap key\");\n  assert(r == 0);\n  r = admin_socket->register_command(\n    \"rmomapkey\",\n    \"rmomapkey \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname \" \\\n    \"name=key,type=CephString\",\n    test_ops_hook,\n    \"remove omap key\");\n  assert(r == 0);\n  r = admin_socket->register_command(\n    \"setomapheader\",\n    \"setomapheader \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname \" \\\n    \"name=header,type=CephString\",\n    test_ops_hook,\n    \"set omap header\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\n    \"getomap\",\n    \"getomap \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname\",\n    test_ops_hook,\n    \"output entire object map\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\n    \"truncobj\",\n    \"truncobj \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname \" \\\n    \"name=len,type=CephInt\",\n    test_ops_hook,\n    \"truncate object to length\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\n    \"injectdataerr\",\n    \"injectdataerr \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname \" \\\n    \"name=shardid,type=CephInt,req=false,range=0|255\",\n    test_ops_hook,\n    \"inject data error to an object\");\n  assert(r == 0);\n\n  r = admin_socket->register_command(\n    \"injectmdataerr\",\n    \"injectmdataerr \" \\\n    \"name=pool,type=CephString \" \\\n    \"name=objname,type=CephObjectname \" \\\n    \"name=shardid,type=CephInt,req=false,range=0|255\",\n    test_ops_hook,\n    \"inject metadata error to an object\");\n  assert(r == 0);\n  r = admin_socket->register_command(\n    \"set_recovery_delay\",\n    \"set_recovery_delay \" \\\n    \"name=utime,type=CephInt,req=false\",\n    test_ops_hook,\n     \"Delay osd recovery by specified seconds\");\n  assert(r == 0);\n  r = admin_socket->register_command(\n   \"trigger_scrub\",\n   \"trigger_scrub \" \\\n   \"name=pgid,type=CephString \",\n   test_ops_hook,\n   \"Trigger a scheduled scrub \");\n  assert(r == 0);\n  r = admin_socket->register_command(\n   \"injectfull\",\n   \"injectfull \" \\\n   \"name=type,type=CephString,req=false \" \\\n   \"name=count,type=CephInt,req=false \",\n   test_ops_hook,\n   \"Inject a full disk (optional count times)\");\n  assert(r == 0);\n}\n\nvoid OSD::create_logger()\n{\n  dout(10) << \"create_logger\" << dendl;\n\n  PerfCountersBuilder osd_plb(cct, \"osd\", l_osd_first, l_osd_last);\n\n  // Latency axis configuration for op histograms, values are in nanoseconds\n  PerfHistogramCommon::axis_config_d op_hist_x_axis_config{\n    \"Latency (usec)\",\n    PerfHistogramCommon::SCALE_LOG2, ///< Latency in logarithmic scale\n    0,                               ///< Start at 0\n    100000,                          ///< Quantization unit is 100usec\n    32,                              ///< Enough to cover much longer than slow requests\n  };\n\n  // Op size axis configuration for op histograms, values are in bytes\n  PerfHistogramCommon::axis_config_d op_hist_y_axis_config{\n    \"Request size (bytes)\",\n    PerfHistogramCommon::SCALE_LOG2, ///< Request size in logarithmic scale\n    0,                               ///< Start at 0\n    512,                             ///< Quantization unit is 512 bytes\n    32,                              ///< Enough to cover requests larger than GB\n  };\n\n\n  // All the basic OSD operation stats are to be considered useful\n  osd_plb.set_prio_default(PerfCountersBuilder::PRIO_USEFUL);\n\n  osd_plb.add_u64(\n    l_osd_op_wip, \"op_wip\",\n    \"Replication operations currently being processed (primary)\");\n  osd_plb.add_u64_counter(\n    l_osd_op, \"op\",\n    \"Client operations\",\n    \"ops\", PerfCountersBuilder::PRIO_CRITICAL);\n  osd_plb.add_u64_counter(\n    l_osd_op_inb,   \"op_in_bytes\",\n    \"Client operations total write size\",\n    \"wr\", PerfCountersBuilder::PRIO_INTERESTING);\n  osd_plb.add_u64_counter(\n    l_osd_op_outb,  \"op_out_bytes\",\n    \"Client operations total read size\",\n    \"rd\", PerfCountersBuilder::PRIO_INTERESTING);\n  osd_plb.add_time_avg(\n    l_osd_op_lat,   \"op_latency\",\n    \"Latency of client operations (including queue time)\",\n    \"l\", 9);\n  osd_plb.add_time_avg(\n    l_osd_op_process_lat, \"op_process_latency\",\n    \"Latency of client operations (excluding queue time)\");\n  osd_plb.add_time_avg(\n    l_osd_op_prepare_lat, \"op_prepare_latency\",\n    \"Latency of client operations (excluding queue time and wait for finished)\");\n\n  osd_plb.add_u64_counter(\n    l_osd_op_r, \"op_r\", \"Client read operations\");\n  osd_plb.add_u64_counter(\n    l_osd_op_r_outb, \"op_r_out_bytes\", \"Client data read\");\n  osd_plb.add_time_avg(\n    l_osd_op_r_lat, \"op_r_latency\",\n    \"Latency of read operation (including queue time)\");\n  osd_plb.add_u64_counter_histogram(\n    l_osd_op_r_lat_outb_hist, \"op_r_latency_out_bytes_histogram\",\n    op_hist_x_axis_config, op_hist_y_axis_config,\n    \"Histogram of operation latency (including queue time) + data read\");\n  osd_plb.add_time_avg(\n    l_osd_op_r_process_lat, \"op_r_process_latency\",\n    \"Latency of read operation (excluding queue time)\");\n  osd_plb.add_time_avg(\n    l_osd_op_r_prepare_lat, \"op_r_prepare_latency\",\n    \"Latency of read operations (excluding queue time and wait for finished)\");\n  osd_plb.add_u64_counter(\n    l_osd_op_w, \"op_w\", \"Client write operations\");\n  osd_plb.add_u64_counter(\n    l_osd_op_w_inb, \"op_w_in_bytes\", \"Client data written\");\n  osd_plb.add_time_avg(\n    l_osd_op_w_lat,  \"op_w_latency\",\n    \"Latency of write operation (including queue time)\");\n  osd_plb.add_u64_counter_histogram(\n    l_osd_op_w_lat_inb_hist, \"op_w_latency_in_bytes_histogram\",\n    op_hist_x_axis_config, op_hist_y_axis_config,\n    \"Histogram of operation latency (including queue time) + data written\");\n  osd_plb.add_time_avg(\n    l_osd_op_w_process_lat, \"op_w_process_latency\",\n    \"Latency of write operation (excluding queue time)\");\n  osd_plb.add_time_avg(\n    l_osd_op_w_prepare_lat, \"op_w_prepare_latency\",\n    \"Latency of write operations (excluding queue time and wait for finished)\");\n  osd_plb.add_u64_counter(\n    l_osd_op_rw, \"op_rw\",\n    \"Client read-modify-write operations\");\n  osd_plb.add_u64_counter(\n    l_osd_op_rw_inb, \"op_rw_in_bytes\",\n    \"Client read-modify-write operations write in\");\n  osd_plb.add_u64_counter(\n    l_osd_op_rw_outb,\"op_rw_out_bytes\",\n    \"Client read-modify-write operations read out \");\n  osd_plb.add_time_avg(\n    l_osd_op_rw_lat, \"op_rw_latency\",\n    \"Latency of read-modify-write operation (including queue time)\");\n  osd_plb.add_u64_counter_histogram(\n    l_osd_op_rw_lat_inb_hist, \"op_rw_latency_in_bytes_histogram\",\n    op_hist_x_axis_config, op_hist_y_axis_config,\n    \"Histogram of rw operation latency (including queue time) + data written\");\n  osd_plb.add_u64_counter_histogram(\n    l_osd_op_rw_lat_outb_hist, \"op_rw_latency_out_bytes_histogram\",\n    op_hist_x_axis_config, op_hist_y_axis_config,\n    \"Histogram of rw operation latency (including queue time) + data read\");\n  osd_plb.add_time_avg(\n    l_osd_op_rw_process_lat, \"op_rw_process_latency\",\n    \"Latency of read-modify-write operation (excluding queue time)\");\n  osd_plb.add_time_avg(\n    l_osd_op_rw_prepare_lat, \"op_rw_prepare_latency\",\n    \"Latency of read-modify-write operations (excluding queue time and wait for finished)\");\n\n  // Now we move on to some more obscure stats, revert to assuming things\n  // are low priority unless otherwise specified.\n  osd_plb.set_prio_default(PerfCountersBuilder::PRIO_DEBUGONLY);\n\n  osd_plb.add_time_avg(l_osd_op_before_queue_op_lat, \"op_before_queue_op_lat\",\n    \"Latency of IO before calling queue(before really queue into ShardedOpWq)\"); // client io before queue op_wq latency\n  osd_plb.add_time_avg(l_osd_op_before_dequeue_op_lat, \"op_before_dequeue_op_lat\",\n    \"Latency of IO before calling dequeue_op(already dequeued and get PG lock)\"); // client io before dequeue_op latency\n\n  osd_plb.add_u64_counter(\n    l_osd_sop, \"subop\", \"Suboperations\");\n  osd_plb.add_u64_counter(\n    l_osd_sop_inb, \"subop_in_bytes\", \"Suboperations total size\");\n  osd_plb.add_time_avg(l_osd_sop_lat, \"subop_latency\", \"Suboperations latency\");\n\n  osd_plb.add_u64_counter(l_osd_sop_w, \"subop_w\", \"Replicated writes\");\n  osd_plb.add_u64_counter(\n    l_osd_sop_w_inb, \"subop_w_in_bytes\", \"Replicated written data size\");\n  osd_plb.add_time_avg(\n    l_osd_sop_w_lat, \"subop_w_latency\", \"Replicated writes latency\");\n  osd_plb.add_u64_counter(\n    l_osd_sop_pull, \"subop_pull\", \"Suboperations pull requests\");\n  osd_plb.add_time_avg(\n    l_osd_sop_pull_lat, \"subop_pull_latency\", \"Suboperations pull latency\");\n  osd_plb.add_u64_counter(\n    l_osd_sop_push, \"subop_push\", \"Suboperations push messages\");\n  osd_plb.add_u64_counter(\n    l_osd_sop_push_inb, \"subop_push_in_bytes\", \"Suboperations pushed size\");\n  osd_plb.add_time_avg(\n    l_osd_sop_push_lat, \"subop_push_latency\", \"Suboperations push latency\");\n\n  osd_plb.add_u64_counter(l_osd_pull, \"pull\", \"Pull requests sent\");\n  osd_plb.add_u64_counter(l_osd_push, \"push\", \"Push messages sent\");\n  osd_plb.add_u64_counter(l_osd_push_outb, \"push_out_bytes\", \"Pushed size\");\n\n  osd_plb.add_u64_counter(\n    l_osd_rop, \"recovery_ops\",\n    \"Started recovery operations\",\n    \"rop\", PerfCountersBuilder::PRIO_INTERESTING);\n\n  osd_plb.add_u64(l_osd_loadavg, \"loadavg\", \"CPU load\");\n  osd_plb.add_u64(l_osd_buf, \"buffer_bytes\", \"Total allocated buffer size\");\n  osd_plb.add_u64(l_osd_history_alloc_bytes, \"history_alloc_Mbytes\");\n  osd_plb.add_u64(l_osd_history_alloc_num, \"history_alloc_num\");\n  osd_plb.add_u64(\n    l_osd_cached_crc, \"cached_crc\", \"Total number getting crc from crc_cache\");\n  osd_plb.add_u64(\n    l_osd_cached_crc_adjusted, \"cached_crc_adjusted\",\n    \"Total number getting crc from crc_cache with adjusting\");\n  osd_plb.add_u64(l_osd_missed_crc, \"missed_crc\", \n    \"Total number of crc cache misses\");\n\n  osd_plb.add_u64(l_osd_pg, \"numpg\", \"Placement groups\",\n\t\t  \"pgs\", PerfCountersBuilder::PRIO_USEFUL);\n  osd_plb.add_u64(\n    l_osd_pg_primary, \"numpg_primary\",\n    \"Placement groups for which this osd is primary\");\n  osd_plb.add_u64(\n    l_osd_pg_replica, \"numpg_replica\",\n    \"Placement groups for which this osd is replica\");\n  osd_plb.add_u64(\n    l_osd_pg_stray, \"numpg_stray\",\n    \"Placement groups ready to be deleted from this osd\");\n  osd_plb.add_u64(\n    l_osd_pg_removing, \"numpg_removing\",\n    \"Placement groups queued for local deletion\", \"pgsr\",\n    PerfCountersBuilder::PRIO_USEFUL);\n  osd_plb.add_u64(\n    l_osd_hb_to, \"heartbeat_to_peers\", \"Heartbeat (ping) peers we send to\");\n  osd_plb.add_u64_counter(l_osd_map, \"map_messages\", \"OSD map messages\");\n  osd_plb.add_u64_counter(l_osd_mape, \"map_message_epochs\", \"OSD map epochs\");\n  osd_plb.add_u64_counter(\n    l_osd_mape_dup, \"map_message_epoch_dups\", \"OSD map duplicates\");\n  osd_plb.add_u64_counter(\n    l_osd_waiting_for_map, \"messages_delayed_for_map\",\n    \"Operations waiting for OSD map\");\n\n  osd_plb.add_u64_counter(\n    l_osd_map_cache_hit, \"osd_map_cache_hit\", \"osdmap cache hit\");\n  osd_plb.add_u64_counter(\n    l_osd_map_cache_miss, \"osd_map_cache_miss\", \"osdmap cache miss\");\n  osd_plb.add_u64_counter(\n    l_osd_map_cache_miss_low, \"osd_map_cache_miss_low\",\n    \"osdmap cache miss below cache lower bound\");\n  osd_plb.add_u64_avg(\n    l_osd_map_cache_miss_low_avg, \"osd_map_cache_miss_low_avg\",\n    \"osdmap cache miss, avg distance below cache lower bound\");\n  osd_plb.add_u64_counter(\n    l_osd_map_bl_cache_hit, \"osd_map_bl_cache_hit\",\n    \"OSDMap buffer cache hits\");\n  osd_plb.add_u64_counter(\n    l_osd_map_bl_cache_miss, \"osd_map_bl_cache_miss\",\n    \"OSDMap buffer cache misses\");\n\n  osd_plb.add_u64(\n    l_osd_stat_bytes, \"stat_bytes\", \"OSD size\", \"size\",\n    PerfCountersBuilder::PRIO_USEFUL);\n  osd_plb.add_u64(\n    l_osd_stat_bytes_used, \"stat_bytes_used\", \"Used space\", \"used\",\n    PerfCountersBuilder::PRIO_USEFUL);\n  osd_plb.add_u64(l_osd_stat_bytes_avail, \"stat_bytes_avail\", \"Available space\");\n\n  osd_plb.add_u64_counter(\n    l_osd_copyfrom, \"copyfrom\", \"Rados \\\"copy-from\\\" operations\");\n\n  osd_plb.add_u64_counter(l_osd_tier_promote, \"tier_promote\", \"Tier promotions\");\n  osd_plb.add_u64_counter(l_osd_tier_flush, \"tier_flush\", \"Tier flushes\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_flush_fail, \"tier_flush_fail\", \"Failed tier flushes\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_try_flush, \"tier_try_flush\", \"Tier flush attempts\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_try_flush_fail, \"tier_try_flush_fail\",\n    \"Failed tier flush attempts\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_evict, \"tier_evict\", \"Tier evictions\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_whiteout, \"tier_whiteout\", \"Tier whiteouts\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_dirty, \"tier_dirty\", \"Dirty tier flag set\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_clean, \"tier_clean\", \"Dirty tier flag cleaned\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_delay, \"tier_delay\", \"Tier delays (agent waiting)\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_proxy_read, \"tier_proxy_read\", \"Tier proxy reads\");\n  osd_plb.add_u64_counter(\n    l_osd_tier_proxy_write, \"tier_proxy_write\", \"Tier proxy writes\");\n\n  osd_plb.add_u64_counter(\n    l_osd_agent_wake, \"agent_wake\", \"Tiering agent wake up\");\n  osd_plb.add_u64_counter(\n    l_osd_agent_skip, \"agent_skip\", \"Objects skipped by agent\");\n  osd_plb.add_u64_counter(\n    l_osd_agent_flush, \"agent_flush\", \"Tiering agent flushes\");\n  osd_plb.add_u64_counter(\n    l_osd_agent_evict, \"agent_evict\", \"Tiering agent evictions\");\n\n  osd_plb.add_u64_counter(\n    l_osd_object_ctx_cache_hit, \"object_ctx_cache_hit\", \"Object context cache hits\");\n  osd_plb.add_u64_counter(\n    l_osd_object_ctx_cache_total, \"object_ctx_cache_total\", \"Object context cache lookups\");\n\n  osd_plb.add_u64_counter(l_osd_op_cache_hit, \"op_cache_hit\");\n  osd_plb.add_time_avg(\n    l_osd_tier_flush_lat, \"osd_tier_flush_lat\", \"Object flush latency\");\n  osd_plb.add_time_avg(\n    l_osd_tier_promote_lat, \"osd_tier_promote_lat\", \"Object promote latency\");\n  osd_plb.add_time_avg(\n    l_osd_tier_r_lat, \"osd_tier_r_lat\", \"Object proxy read latency\");\n\n  osd_plb.add_u64_counter(\n    l_osd_pg_info, \"osd_pg_info\", \"PG updated its info (using any method)\");\n  osd_plb.add_u64_counter(\n    l_osd_pg_fastinfo, \"osd_pg_fastinfo\",\n    \"PG updated its info using fastinfo attr\");\n  osd_plb.add_u64_counter(\n    l_osd_pg_biginfo, \"osd_pg_biginfo\", \"PG updated its biginfo attr\");\n\n  logger = osd_plb.create_perf_counters();\n  cct->get_perfcounters_collection()->add(logger);\n}\n\nvoid OSD::create_recoverystate_perf()\n{\n  dout(10) << \"create_recoverystate_perf\" << dendl;\n\n  PerfCountersBuilder rs_perf(cct, \"recoverystate_perf\", rs_first, rs_last);\n\n  rs_perf.add_time_avg(rs_initial_latency, \"initial_latency\", \"Initial recovery state latency\");\n  rs_perf.add_time_avg(rs_started_latency, \"started_latency\", \"Started recovery state latency\");\n  rs_perf.add_time_avg(rs_reset_latency, \"reset_latency\", \"Reset recovery state latency\");\n  rs_perf.add_time_avg(rs_start_latency, \"start_latency\", \"Start recovery state latency\");\n  rs_perf.add_time_avg(rs_primary_latency, \"primary_latency\", \"Primary recovery state latency\");\n  rs_perf.add_time_avg(rs_peering_latency, \"peering_latency\", \"Peering recovery state latency\");\n  rs_perf.add_time_avg(rs_backfilling_latency, \"backfilling_latency\", \"Backfilling recovery state latency\");\n  rs_perf.add_time_avg(rs_waitremotebackfillreserved_latency, \"waitremotebackfillreserved_latency\", \"Wait remote backfill reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_waitlocalbackfillreserved_latency, \"waitlocalbackfillreserved_latency\", \"Wait local backfill reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_notbackfilling_latency, \"notbackfilling_latency\", \"Notbackfilling recovery state latency\");\n  rs_perf.add_time_avg(rs_repnotrecovering_latency, \"repnotrecovering_latency\", \"Repnotrecovering recovery state latency\");\n  rs_perf.add_time_avg(rs_repwaitrecoveryreserved_latency, \"repwaitrecoveryreserved_latency\", \"Rep wait recovery reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_repwaitbackfillreserved_latency, \"repwaitbackfillreserved_latency\", \"Rep wait backfill reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_reprecovering_latency, \"reprecovering_latency\", \"RepRecovering recovery state latency\");\n  rs_perf.add_time_avg(rs_activating_latency, \"activating_latency\", \"Activating recovery state latency\");\n  rs_perf.add_time_avg(rs_waitlocalrecoveryreserved_latency, \"waitlocalrecoveryreserved_latency\", \"Wait local recovery reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_waitremoterecoveryreserved_latency, \"waitremoterecoveryreserved_latency\", \"Wait remote recovery reserved recovery state latency\");\n  rs_perf.add_time_avg(rs_recovering_latency, \"recovering_latency\", \"Recovering recovery state latency\");\n  rs_perf.add_time_avg(rs_recovered_latency, \"recovered_latency\", \"Recovered recovery state latency\");\n  rs_perf.add_time_avg(rs_clean_latency, \"clean_latency\", \"Clean recovery state latency\");\n  rs_perf.add_time_avg(rs_active_latency, \"active_latency\", \"Active recovery state latency\");\n  rs_perf.add_time_avg(rs_replicaactive_latency, \"replicaactive_latency\", \"Replicaactive recovery state latency\");\n  rs_perf.add_time_avg(rs_stray_latency, \"stray_latency\", \"Stray recovery state latency\");\n  rs_perf.add_time_avg(rs_getinfo_latency, \"getinfo_latency\", \"Getinfo recovery state latency\");\n  rs_perf.add_time_avg(rs_getlog_latency, \"getlog_latency\", \"Getlog recovery state latency\");\n  rs_perf.add_time_avg(rs_waitactingchange_latency, \"waitactingchange_latency\", \"Waitactingchange recovery state latency\");\n  rs_perf.add_time_avg(rs_incomplete_latency, \"incomplete_latency\", \"Incomplete recovery state latency\");\n  rs_perf.add_time_avg(rs_down_latency, \"down_latency\", \"Down recovery state latency\");\n  rs_perf.add_time_avg(rs_getmissing_latency, \"getmissing_latency\", \"Getmissing recovery state latency\");\n  rs_perf.add_time_avg(rs_waitupthru_latency, \"waitupthru_latency\", \"Waitupthru recovery state latency\");\n  rs_perf.add_time_avg(rs_notrecovering_latency, \"notrecovering_latency\", \"Notrecovering recovery state latency\");\n\n  recoverystate_perf = rs_perf.create_perf_counters();\n  cct->get_perfcounters_collection()->add(recoverystate_perf);\n}\n\nint OSD::shutdown()\n{\n  if (!service.prepare_to_stop())\n    return 0; // already shutting down\n  osd_lock.Lock();\n  if (is_stopping()) {\n    osd_lock.Unlock();\n    return 0;\n  }\n  derr << \"shutdown\" << dendl;\n\n  set_state(STATE_STOPPING);\n\n  // Debugging\n  if (cct->_conf->get_val<bool>(\"osd_debug_shutdown\")) {\n    cct->_conf->set_val(\"debug_osd\", \"100\");\n    cct->_conf->set_val(\"debug_journal\", \"100\");\n    cct->_conf->set_val(\"debug_filestore\", \"100\");\n    cct->_conf->set_val(\"debug_bluestore\", \"100\");\n    cct->_conf->set_val(\"debug_ms\", \"100\");\n    cct->_conf->apply_changes(NULL);\n  }\n\n  // stop MgrClient earlier as it's more like an internal consumer of OSD\n  mgrc.shutdown();\n\n  service.start_shutdown();\n\n  // stop sending work to pgs.  this just prevents any new work in _process\n  // from racing with on_shutdown and potentially entering the pg after.\n  op_shardedwq.drain();\n\n  // Shutdown PGs\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t, PG*>::iterator p = pg_map.begin();\n        p != pg_map.end();\n        ++p) {\n      dout(20) << \" kicking pg \" << p->first << dendl;\n      p->second->lock();\n      p->second->on_shutdown();\n      p->second->unlock();\n      p->second->osr->flush();\n    }\n  }\n  clear_pg_stat_queue();\n\n  // drain op queue again (in case PGs requeued something)\n  op_shardedwq.drain();\n  {\n    finished.clear(); // zap waiters (bleh, this is messy)\n  }\n\n  op_shardedwq.clear_pg_slots();\n\n  // unregister commands\n  cct->get_admin_socket()->unregister_command(\"status\");\n  cct->get_admin_socket()->unregister_command(\"flush_journal\");\n  cct->get_admin_socket()->unregister_command(\"dump_ops_in_flight\");\n  cct->get_admin_socket()->unregister_command(\"ops\");\n  cct->get_admin_socket()->unregister_command(\"dump_blocked_ops\");\n  cct->get_admin_socket()->unregister_command(\"dump_historic_ops\");\n  cct->get_admin_socket()->unregister_command(\"dump_historic_ops_by_duration\");\n  cct->get_admin_socket()->unregister_command(\"dump_historic_slow_ops\");\n  cct->get_admin_socket()->unregister_command(\"dump_op_pq_state\");\n  cct->get_admin_socket()->unregister_command(\"dump_blacklist\");\n  cct->get_admin_socket()->unregister_command(\"dump_watchers\");\n  cct->get_admin_socket()->unregister_command(\"dump_reservations\");\n  cct->get_admin_socket()->unregister_command(\"get_latest_osdmap\");\n  cct->get_admin_socket()->unregister_command(\"heap\");\n  cct->get_admin_socket()->unregister_command(\"set_heap_property\");\n  cct->get_admin_socket()->unregister_command(\"get_heap_property\");\n  cct->get_admin_socket()->unregister_command(\"dump_objectstore_kv_stats\");\n  cct->get_admin_socket()->unregister_command(\"dump_scrubs\");\n  cct->get_admin_socket()->unregister_command(\"calc_objectstore_db_histogram\");\n  cct->get_admin_socket()->unregister_command(\"flush_store_cache\");\n  cct->get_admin_socket()->unregister_command(\"dump_pgstate_history\");\n  cct->get_admin_socket()->unregister_command(\"compact\");\n  delete asok_hook;\n  asok_hook = NULL;\n\n  cct->get_admin_socket()->unregister_command(\"setomapval\");\n  cct->get_admin_socket()->unregister_command(\"rmomapkey\");\n  cct->get_admin_socket()->unregister_command(\"setomapheader\");\n  cct->get_admin_socket()->unregister_command(\"getomap\");\n  cct->get_admin_socket()->unregister_command(\"truncobj\");\n  cct->get_admin_socket()->unregister_command(\"injectdataerr\");\n  cct->get_admin_socket()->unregister_command(\"injectmdataerr\");\n  cct->get_admin_socket()->unregister_command(\"set_recovery_delay\");\n  cct->get_admin_socket()->unregister_command(\"trigger_scrub\");\n  cct->get_admin_socket()->unregister_command(\"injectfull\");\n  delete test_ops_hook;\n  test_ops_hook = NULL;\n\n  osd_lock.Unlock();\n\n  heartbeat_lock.Lock();\n  heartbeat_stop = true;\n  heartbeat_cond.Signal();\n  heartbeat_lock.Unlock();\n  heartbeat_thread.join();\n\n  peering_tp.drain();\n  peering_wq.clear();\n  peering_tp.stop();\n  dout(10) << \"osd tp stopped\" << dendl;\n\n  osd_op_tp.drain();\n  osd_op_tp.stop();\n  dout(10) << \"op sharded tp stopped\" << dendl;\n\n  command_tp.drain();\n  command_tp.stop();\n  dout(10) << \"command tp stopped\" << dendl;\n\n  disk_tp.drain();\n  disk_tp.stop();\n  dout(10) << \"disk tp paused (new)\" << dendl;\n\n  dout(10) << \"stopping agent\" << dendl;\n  service.agent_stop();\n\n  osd_lock.Lock();\n\n  reset_heartbeat_peers();\n\n  tick_timer.shutdown();\n\n  {\n    Mutex::Locker l(tick_timer_lock);\n    tick_timer_without_osd_lock.shutdown();\n  }\n\n  // note unmount epoch\n  dout(10) << \"noting clean unmount in epoch \" << osdmap->get_epoch() << dendl;\n  superblock.mounted = service.get_boot_epoch();\n  superblock.clean_thru = osdmap->get_epoch();\n  ObjectStore::Transaction t;\n  write_superblock(t);\n  int r = store->apply_transaction(service.meta_osr.get(), std::move(t));\n  if (r) {\n    derr << \"OSD::shutdown: error writing superblock: \"\n\t << cpp_strerror(r) << dendl;\n  }\n\n\n  {\n    Mutex::Locker l(pg_stat_queue_lock);\n    assert(pg_stat_queue.empty());\n  }\n\n  service.shutdown_reserver();\n\n  // Remove PGs\n#ifdef PG_DEBUG_REFS\n  service.dump_live_pgids();\n#endif\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t, PG*>::iterator p = pg_map.begin();\n        p != pg_map.end();\n        ++p) {\n      dout(20) << \" kicking pg \" << p->first << dendl;\n      p->second->lock();\n      if (p->second->ref != 1) {\n        derr << \"pgid \" << p->first << \" has ref count of \"\n            << p->second->ref << dendl;\n#ifdef PG_DEBUG_REFS\n\tp->second->dump_live_ids();\n#endif\n\tif (cct->_conf->osd_shutdown_pgref_assert) {\n\t  ceph_abort();\n\t}\n      }\n      p->second->unlock();\n      p->second->put(\"PGMap\");\n    }\n    pg_map.clear();\n  }\n#ifdef PG_DEBUG_REFS\n  service.dump_live_pgids();\n#endif\n  cct->_conf->remove_observer(this);\n\n  dout(10) << \"syncing store\" << dendl;\n  enable_disable_fuse(true);\n\n  if (cct->_conf->osd_journal_flush_on_shutdown) {\n    dout(10) << \"flushing journal\" << dendl;\n    store->flush_journal();\n  }\n\n  store->umount();\n  delete store;\n  store = 0;\n  dout(10) << \"Store synced\" << dendl;\n\n  monc->shutdown();\n  osd_lock.Unlock();\n\n  osdmap = OSDMapRef();\n  service.shutdown();\n  op_tracker.on_shutdown();\n\n  class_handler->shutdown();\n  client_messenger->shutdown();\n  cluster_messenger->shutdown();\n  hb_front_client_messenger->shutdown();\n  hb_back_client_messenger->shutdown();\n  objecter_messenger->shutdown();\n  hb_front_server_messenger->shutdown();\n  hb_back_server_messenger->shutdown();\n\n  peering_wq.clear();\n\n  return r;\n}\n\nint OSD::mon_cmd_maybe_osd_create(string &cmd)\n{\n  bool created = false;\n  while (true) {\n    dout(10) << __func__ << \" cmd: \" << cmd << dendl;\n    vector<string> vcmd{cmd};\n    bufferlist inbl;\n    C_SaferCond w;\n    string outs;\n    monc->start_mon_command(vcmd, inbl, NULL, &outs, &w);\n    int r = w.wait();\n    if (r < 0) {\n      if (r == -ENOENT && !created) {\n\tstring newcmd = \"{\\\"prefix\\\": \\\"osd create\\\", \\\"id\\\": \" + stringify(whoami)\n\t  + \", \\\"uuid\\\": \\\"\" + stringify(superblock.osd_fsid) + \"\\\"}\";\n\tvector<string> vnewcmd{newcmd};\n\tbufferlist inbl;\n\tC_SaferCond w;\n\tstring outs;\n\tmonc->start_mon_command(vnewcmd, inbl, NULL, &outs, &w);\n\tint r = w.wait();\n\tif (r < 0) {\n\t  derr << __func__ << \" fail: osd does not exist and created failed: \"\n\t       << cpp_strerror(r) << dendl;\n\t  return r;\n\t}\n\tcreated = true;\n\tcontinue;\n      }\n      derr << __func__ << \" fail: '\" << outs << \"': \" << cpp_strerror(r) << dendl;\n      return r;\n    }\n    break;\n  }\n\n  return 0;\n}\n\nint OSD::update_crush_location()\n{\n  if (!cct->_conf->osd_crush_update_on_start) {\n    dout(10) << __func__ << \" osd_crush_update_on_start = false\" << dendl;\n    return 0;\n  }\n\n  char weight[32];\n  if (cct->_conf->osd_crush_initial_weight >= 0) {\n    snprintf(weight, sizeof(weight), \"%.4lf\", cct->_conf->osd_crush_initial_weight);\n  } else {\n    struct store_statfs_t st;\n    int r = store->statfs(&st);\n    if (r < 0) {\n      derr << \"statfs: \" << cpp_strerror(r) << dendl;\n      return r;\n    }\n    snprintf(weight, sizeof(weight), \"%.4lf\",\n\t     MAX((double).00001,\n\t\t (double)(st.total) /\n\t\t (double)(1ull << 40 /* TB */)));\n  }\n\n  std::multimap<string,string> loc = cct->crush_location.get_location();\n  dout(10) << __func__ << \" crush location is \" << loc << dendl;\n\n  string cmd =\n    string(\"{\\\"prefix\\\": \\\"osd crush create-or-move\\\", \") +\n    string(\"\\\"id\\\": \") + stringify(whoami) + string(\", \") +\n    string(\"\\\"weight\\\":\") + weight + string(\", \") +\n    string(\"\\\"args\\\": [\");\n  for (multimap<string,string>::iterator p = loc.begin(); p != loc.end(); ++p) {\n    if (p != loc.begin())\n      cmd += \", \";\n    cmd += \"\\\"\" + p->first + \"=\" + p->second + \"\\\"\";\n  }\n  cmd += \"]}\";\n\n  return mon_cmd_maybe_osd_create(cmd);\n}\n\nint OSD::update_crush_device_class()\n{\n  if (!cct->_conf->osd_class_update_on_start) {\n    dout(10) << __func__ << \" osd_class_update_on_start = false\" << dendl;\n    return 0;\n  }\n\n  string device_class;\n  int r = store->read_meta(\"crush_device_class\", &device_class);\n  if (r < 0 || device_class.empty()) {\n    device_class = store->get_default_device_class();\n  }\n\n  if (device_class.empty()) {\n    dout(20) << __func__ << \" no device class stored locally\" << dendl;\n    return 0;\n  }\n\n  string cmd =\n    string(\"{\\\"prefix\\\": \\\"osd crush set-device-class\\\", \") +\n    string(\"\\\"class\\\": \\\"\") + device_class + string(\"\\\", \") +\n    string(\"\\\"ids\\\": [\\\"\") + stringify(whoami) + string(\"\\\"]}\");\n\n  r = mon_cmd_maybe_osd_create(cmd);\n  // the above cmd can fail for various reasons, e.g.:\n  //   (1) we are connecting to a pre-luminous monitor\n  //   (2) user manually specify a class other than\n  //       'ceph-disk prepare --crush-device-class'\n  // simply skip result-checking for now\n  return 0;\n}\n\nvoid OSD::write_superblock(ObjectStore::Transaction& t)\n{\n  dout(10) << \"write_superblock \" << superblock << dendl;\n\n  //hack: at minimum it's using the baseline feature set\n  if (!superblock.compat_features.incompat.contains(CEPH_OSD_FEATURE_INCOMPAT_BASE))\n    superblock.compat_features.incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_BASE);\n\n  bufferlist bl;\n  ::encode(superblock, bl);\n  t.write(coll_t::meta(), OSD_SUPERBLOCK_GOBJECT, 0, bl.length(), bl);\n}\n\nint OSD::read_superblock()\n{\n  bufferlist bl;\n  int r = store->read(coll_t::meta(), OSD_SUPERBLOCK_GOBJECT, 0, 0, bl);\n  if (r < 0)\n    return r;\n\n  bufferlist::iterator p = bl.begin();\n  ::decode(superblock, p);\n\n  dout(10) << \"read_superblock \" << superblock << dendl;\n\n  return 0;\n}\n\nvoid OSD::clear_temp_objects()\n{\n  dout(10) << __func__ << dendl;\n  vector<coll_t> ls;\n  store->list_collections(ls);\n  for (vector<coll_t>::iterator p = ls.begin(); p != ls.end(); ++p) {\n    spg_t pgid;\n    if (!p->is_pg(&pgid))\n      continue;\n\n    // list temp objects\n    dout(20) << \" clearing temps in \" << *p << \" pgid \" << pgid << dendl;\n\n    vector<ghobject_t> temps;\n    ghobject_t next;\n    while (1) {\n      vector<ghobject_t> objects;\n      store->collection_list(*p, next, ghobject_t::get_max(),\n\t\t\t     store->get_ideal_list_max(),\n\t\t\t     &objects, &next);\n      if (objects.empty())\n\tbreak;\n      vector<ghobject_t>::iterator q;\n      for (q = objects.begin(); q != objects.end(); ++q) {\n\t// Hammer set pool for temps to -1, so check for clean-up\n\tif (q->hobj.is_temp() || (q->hobj.pool == -1)) {\n\t  temps.push_back(*q);\n\t} else {\n\t  break;\n\t}\n      }\n      // If we saw a non-temp object and hit the break above we can\n      // break out of the while loop too.\n      if (q != objects.end())\n\tbreak;\n    }\n    if (!temps.empty()) {\n      ObjectStore::Transaction t;\n      int removed = 0;\n      for (vector<ghobject_t>::iterator q = temps.begin(); q != temps.end(); ++q) {\n\tdout(20) << \"  removing \" << *p << \" object \" << *q << dendl;\n\tt.remove(*p, *q);\n        if (++removed > cct->_conf->osd_target_transaction_size) {\n          store->apply_transaction(service.meta_osr.get(), std::move(t));\n          t = ObjectStore::Transaction();\n          removed = 0;\n        }\n      }\n      if (removed) {\n        store->apply_transaction(service.meta_osr.get(), std::move(t));\n      }\n    }\n  }\n}\n\nvoid OSD::recursive_remove_collection(CephContext* cct,\n\t\t\t\t      ObjectStore *store, spg_t pgid,\n\t\t\t\t      coll_t tmp)\n{\n  OSDriver driver(\n    store,\n    coll_t(),\n    make_snapmapper_oid());\n\n  ceph::shared_ptr<ObjectStore::Sequencer> osr (std::make_shared<\n                                      ObjectStore::Sequencer>(\"rm\"));\n  ObjectStore::Transaction t;\n  SnapMapper mapper(cct, &driver, 0, 0, 0, pgid.shard);\n\n  vector<ghobject_t> objects;\n  store->collection_list(tmp, ghobject_t(), ghobject_t::get_max(),\n\t\t\t INT_MAX, &objects, 0);\n  generic_dout(10) << __func__ << \" \" << objects << dendl;\n  // delete them.\n  int removed = 0;\n  for (vector<ghobject_t>::iterator p = objects.begin();\n       p != objects.end();\n       ++p, removed++) {\n    OSDriver::OSTransaction _t(driver.get_transaction(&t));\n    int r = mapper.remove_oid(p->hobj, &_t);\n    if (r != 0 && r != -ENOENT)\n      ceph_abort();\n    t.remove(tmp, *p);\n    if (removed > cct->_conf->osd_target_transaction_size) {\n      int r = store->apply_transaction(osr.get(), std::move(t));\n      assert(r == 0);\n      t = ObjectStore::Transaction();\n      removed = 0;\n    }\n  }\n  t.remove_collection(tmp);\n  int r = store->apply_transaction(osr.get(), std::move(t));\n  assert(r == 0);\n\n  C_SaferCond waiter;\n  if (!osr->flush_commit(&waiter)) {\n    waiter.wait();\n  }\n}\n\n\n// ======================================================\n// PG's\n\nPGPool OSD::_get_pool(int id, OSDMapRef createmap)\n{\n  if (!createmap->have_pg_pool(id)) {\n    dout(5) << __func__ << \": the OSDmap does not contain a PG pool with id = \"\n\t    << id << dendl;\n    ceph_abort();\n  }\n\n  PGPool p = PGPool(cct, createmap, id);\n\n  dout(10) << \"_get_pool \" << p.id << dendl;\n  return p;\n}\n\nPG *OSD::_open_lock_pg(\n  OSDMapRef createmap,\n  spg_t pgid, bool no_lockdep_check)\n{\n  assert(osd_lock.is_locked());\n\n  PG* pg = _make_pg(createmap, pgid);\n  {\n    RWLock::WLocker l(pg_map_lock);\n    pg->lock(no_lockdep_check);\n    pg_map[pgid] = pg;\n    pg->get(\"PGMap\");  // because it's in pg_map\n    service.pg_add_epoch(pg->info.pgid, createmap->get_epoch());\n  }\n  return pg;\n}\n\nPG* OSD::_make_pg(\n  OSDMapRef createmap,\n  spg_t pgid)\n{\n  dout(10) << \"_open_lock_pg \" << pgid << dendl;\n  PGPool pool = _get_pool(pgid.pool(), createmap);\n\n  // create\n  PG *pg;\n  if (createmap->get_pg_type(pgid.pgid) == pg_pool_t::TYPE_REPLICATED ||\n      createmap->get_pg_type(pgid.pgid) == pg_pool_t::TYPE_ERASURE)\n    pg = new PrimaryLogPG(&service, createmap, pool, pgid);\n  else\n    ceph_abort();\n\n  return pg;\n}\n\n\nvoid OSD::add_newly_split_pg(PG *pg, PG::RecoveryCtx *rctx)\n{\n  epoch_t e(service.get_osdmap()->get_epoch());\n  pg->get(\"PGMap\");  // For pg_map\n  pg_map[pg->info.pgid] = pg;\n  service.pg_add_epoch(pg->info.pgid, pg->get_osdmap()->get_epoch());\n\n  dout(10) << \"Adding newly split pg \" << *pg << dendl;\n  pg->handle_loaded(rctx);\n  pg->write_if_dirty(*(rctx->transaction));\n  pg->queue_null(e, e);\n  map<spg_t, list<PG::CephPeeringEvtRef> >::iterator to_wake =\n    peering_wait_for_split.find(pg->info.pgid);\n  if (to_wake != peering_wait_for_split.end()) {\n    for (list<PG::CephPeeringEvtRef>::iterator i =\n\t   to_wake->second.begin();\n\t i != to_wake->second.end();\n\t ++i) {\n      pg->queue_peering_event(*i);\n    }\n    peering_wait_for_split.erase(to_wake);\n  }\n  if (!service.get_osdmap()->have_pg_pool(pg->info.pgid.pool()))\n    _remove_pg(pg);\n}\n\nOSD::res_result OSD::_try_resurrect_pg(\n  OSDMapRef curmap, spg_t pgid, spg_t *resurrected, PGRef *old_pg_state)\n{\n  assert(resurrected);\n  assert(old_pg_state);\n  // find nearest ancestor\n  DeletingStateRef df;\n  spg_t cur(pgid);\n  while (true) {\n    df = service.deleting_pgs.lookup(cur);\n    if (df)\n      break;\n    if (!cur.ps())\n      break;\n    cur = cur.get_parent();\n  }\n  if (!df)\n    return RES_NONE; // good to go\n\n  df->old_pg_state->lock();\n  OSDMapRef create_map = df->old_pg_state->get_osdmap();\n  df->old_pg_state->unlock();\n\n  set<spg_t> children;\n  if (cur == pgid) {\n    if (df->try_stop_deletion()) {\n      dout(10) << __func__ << \": halted deletion on pg \" << pgid << dendl;\n      *resurrected = cur;\n      *old_pg_state = df->old_pg_state;\n      service.deleting_pgs.remove(pgid); // PG is no longer being removed!\n      return RES_SELF;\n    } else {\n      // raced, ensure we don't see DeletingStateRef when we try to\n      // delete this pg\n      service.deleting_pgs.remove(pgid);\n      return RES_NONE;\n    }\n  } else if (cur.is_split(create_map->get_pg_num(cur.pool()),\n\t\t\t  curmap->get_pg_num(cur.pool()),\n\t\t\t  &children) &&\n\t     children.count(pgid)) {\n    if (df->try_stop_deletion()) {\n      dout(10) << __func__ << \": halted deletion on ancestor pg \" << pgid\n\t       << dendl;\n      *resurrected = cur;\n      *old_pg_state = df->old_pg_state;\n      service.deleting_pgs.remove(cur); // PG is no longer being removed!\n      return RES_PARENT;\n    } else {\n      /* this is not a problem, failing to cancel proves that all objects\n       * have been removed, so no hobject_t overlap is possible\n       */\n      return RES_NONE;\n    }\n  }\n  return RES_NONE;\n}\n\nPG *OSD::_create_lock_pg(\n  OSDMapRef createmap,\n  spg_t pgid,\n  bool hold_map_lock,\n  bool backfill,\n  int role,\n  vector<int>& up, int up_primary,\n  vector<int>& acting, int acting_primary,\n  pg_history_t history,\n  const PastIntervals& pi,\n  ObjectStore::Transaction& t)\n{\n  assert(osd_lock.is_locked());\n  dout(20) << \"_create_lock_pg pgid \" << pgid << dendl;\n\n  PG *pg = _open_lock_pg(createmap, pgid, true);\n\n  service.init_splits_between(pgid, pg->get_osdmap(), service.get_osdmap());\n\n  pg->init(\n    role,\n    up,\n    up_primary,\n    acting,\n    acting_primary,\n    history,\n    pi,\n    backfill,\n    &t);\n\n  dout(7) << \"_create_lock_pg \" << *pg << dendl;\n  return pg;\n}\n\nPG *OSD::_lookup_lock_pg(spg_t pgid)\n{\n  RWLock::RLocker l(pg_map_lock);\n\n  auto pg_map_entry = pg_map.find(pgid);\n  if (pg_map_entry == pg_map.end())\n    return nullptr;\n  PG *pg = pg_map_entry->second;\n  pg->lock();\n  return pg;\n}\n\nPG *OSD::lookup_lock_pg(spg_t pgid)\n{\n  return _lookup_lock_pg(pgid);\n}\n\nPG *OSD::_lookup_lock_pg_with_map_lock_held(spg_t pgid)\n{\n  assert(pg_map.count(pgid));\n  PG *pg = pg_map[pgid];\n  pg->lock();\n  return pg;\n}\n\nvoid OSD::load_pgs()\n{\n  assert(osd_lock.is_locked());\n  dout(0) << \"load_pgs\" << dendl;\n  {\n    RWLock::RLocker l(pg_map_lock);\n    assert(pg_map.empty());\n  }\n\n  vector<coll_t> ls;\n  int r = store->list_collections(ls);\n  if (r < 0) {\n    derr << \"failed to list pgs: \" << cpp_strerror(-r) << dendl;\n  }\n\n  bool has_upgraded = false;\n\n  for (vector<coll_t>::iterator it = ls.begin();\n       it != ls.end();\n       ++it) {\n    spg_t pgid;\n    if (it->is_temp(&pgid) ||\n       (it->is_pg(&pgid) && PG::_has_removal_flag(store, pgid))) {\n      dout(10) << \"load_pgs \" << *it << \" clearing temp\" << dendl;\n      recursive_remove_collection(cct, store, pgid, *it);\n      continue;\n    }\n\n    if (!it->is_pg(&pgid)) {\n      dout(10) << \"load_pgs ignoring unrecognized \" << *it << dendl;\n      continue;\n    }\n\n    if (pgid.preferred() >= 0) {\n      dout(10) << __func__ << \": skipping localized PG \" << pgid << dendl;\n      // FIXME: delete it too, eventually\n      continue;\n    }\n\n    dout(10) << \"pgid \" << pgid << \" coll \" << coll_t(pgid) << dendl;\n    bufferlist bl;\n    epoch_t map_epoch = 0;\n    int r = PG::peek_map_epoch(store, pgid, &map_epoch, &bl);\n    if (r < 0) {\n      derr << __func__ << \" unable to peek at \" << pgid << \" metadata, skipping\"\n\t   << dendl;\n      continue;\n    }\n\n    PG *pg = NULL;\n    if (map_epoch > 0) {\n      OSDMapRef pgosdmap = service.try_get_map(map_epoch);\n      if (!pgosdmap) {\n\tif (!osdmap->have_pg_pool(pgid.pool())) {\n\t  derr << __func__ << \": could not find map for epoch \" << map_epoch\n\t       << \" on pg \" << pgid << \", but the pool is not present in the \"\n\t       << \"current map, so this is probably a result of bug 10617.  \"\n\t       << \"Skipping the pg for now, you can use ceph-objectstore-tool \"\n\t       << \"to clean it up later.\" << dendl;\n\t  continue;\n\t} else {\n\t  derr << __func__ << \": have pgid \" << pgid << \" at epoch \"\n\t       << map_epoch << \", but missing map.  Crashing.\"\n\t       << dendl;\n\t  assert(0 == \"Missing map in load_pgs\");\n\t}\n      }\n      pg = _open_lock_pg(pgosdmap, pgid);\n    } else {\n      pg = _open_lock_pg(osdmap, pgid);\n    }\n    // there can be no waiters here, so we don't call wake_pg_waiters\n\n    pg->ch = store->open_collection(pg->coll);\n\n    // read pg state, log\n    pg->read_state(store, bl);\n\n    if (pg->must_upgrade()) {\n      if (!pg->can_upgrade()) {\n\tderr << \"PG needs upgrade, but on-disk data is too old; upgrade to\"\n\t     << \" an older version first.\" << dendl;\n\tassert(0 == \"PG too old to upgrade\");\n      }\n      if (!has_upgraded) {\n\tderr << \"PGs are upgrading\" << dendl;\n\thas_upgraded = true;\n      }\n      dout(10) << \"PG \" << pg->info.pgid\n\t       << \" must upgrade...\" << dendl;\n      pg->upgrade(store);\n    }\n\n    if (pg->dne())  {\n      dout(10) << \"load_pgs \" << *it << \" deleting dne\" << dendl;\n      pg->ch = nullptr;\n      service.pg_remove_epoch(pg->pg_id);\n      pg->unlock();\n      {\n\t// Delete pg\n\tRWLock::WLocker l(pg_map_lock);\n\tauto p = pg_map.find(pg->get_pgid());\n\tassert(p != pg_map.end() && p->second == pg);\n\tdout(20) << __func__ << \" removed pg \" << pg << \" from pg_map\" << dendl;\n\tpg_map.erase(p);\n\tpg->put(\"PGMap\");\n      }\n      recursive_remove_collection(cct, store, pgid, *it);\n      continue;\n    }\n\n    service.init_splits_between(pg->info.pgid, pg->get_osdmap(), osdmap);\n\n    // generate state for PG's current mapping\n    int primary, up_primary;\n    vector<int> acting, up;\n    pg->get_osdmap()->pg_to_up_acting_osds(\n      pgid.pgid, &up, &up_primary, &acting, &primary);\n    pg->init_primary_up_acting(\n      up,\n      acting,\n      up_primary,\n      primary);\n    int role = OSDMap::calc_pg_role(whoami, pg->acting);\n    if (pg->pool.info.is_replicated() || role == pg->pg_whoami.shard)\n      pg->set_role(role);\n    else\n      pg->set_role(-1);\n\n    pg->reg_next_scrub();\n\n    PG::RecoveryCtx rctx(0, 0, 0, 0, 0, 0);\n    pg->handle_loaded(&rctx);\n\n    dout(10) << \"load_pgs loaded \" << *pg << \" \" << pg->pg_log.get_log() << dendl;\n    if (pg->pg_log.is_dirty()) {\n      ObjectStore::Transaction t;\n      pg->write_if_dirty(t);\n      store->apply_transaction(pg->osr.get(), std::move(t));\n    }\n    pg->unlock();\n  }\n  {\n    RWLock::RLocker l(pg_map_lock);\n    dout(0) << \"load_pgs opened \" << pg_map.size() << \" pgs\" << dendl;\n  }\n\n  // clean up old infos object?\n  if (has_upgraded && store->exists(coll_t::meta(), OSD::make_infos_oid())) {\n    dout(1) << __func__ << \" removing legacy infos object\" << dendl;\n    ObjectStore::Transaction t;\n    t.remove(coll_t::meta(), OSD::make_infos_oid());\n    int r = store->apply_transaction(service.meta_osr.get(), std::move(t));\n    if (r != 0) {\n      derr << __func__ << \": apply_transaction returned \"\n\t   << cpp_strerror(r) << dendl;\n      ceph_abort();\n    }\n  }\n\n  build_past_intervals_parallel();\n}\n\n\n/*\n * build past_intervals efficiently on old, degraded, and buried\n * clusters.  this is important for efficiently catching up osds that\n * are way behind on maps to the current cluster state.\n *\n * this is a parallel version of PG::generate_past_intervals().\n * follow the same logic, but do all pgs at the same time so that we\n * can make a single pass across the osdmap history.\n */\nvoid OSD::build_past_intervals_parallel()\n{\n  struct pistate {\n    epoch_t start, end;\n    vector<int> old_acting, old_up;\n    epoch_t same_interval_since;\n    int primary;\n    int up_primary;\n  };\n  map<PG*,pistate> pis;\n\n  // calculate junction of map range\n  epoch_t end_epoch = superblock.oldest_map;\n  epoch_t cur_epoch = superblock.newest_map;\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t, PG*>::iterator i = pg_map.begin();\n        i != pg_map.end();\n        ++i) {\n      PG *pg = i->second;\n\n      // Ignore PGs only partially created (DNE)\n      if (pg->info.dne()) {\n\tcontinue;\n      }\n\n      auto rpib = pg->get_required_past_interval_bounds(\n\tpg->info,\n\tsuperblock.oldest_map);\n      if (rpib.first >= rpib.second && pg->past_intervals.empty()) {\n        if (pg->info.history.same_interval_since == 0) {\n          pg->info.history.same_interval_since = rpib.second;\n\t}\n\tcontinue;\n      } else {\n\tauto apib = pg->past_intervals.get_bounds();\n\tif (apib.second >= rpib.second &&\n\t    apib.first <= rpib.first) {\n\t  if (pg->info.history.same_interval_since == 0) {\n\t    pg->info.history.same_interval_since = rpib.second;\n\t  }\n\t  continue;\n\t}\n      }\n\n      dout(10) << pg->info.pgid << \" needs \" << rpib.first << \"-\"\n\t       << rpib.second << dendl;\n      pistate& p = pis[pg];\n      p.start = rpib.first;\n      p.end = rpib.second;\n      p.same_interval_since = 0;\n\n      if (rpib.first < cur_epoch)\n        cur_epoch = rpib.first;\n      if (rpib.second > end_epoch)\n        end_epoch = rpib.second;\n    }\n  }\n  if (pis.empty()) {\n    dout(10) << __func__ << \" nothing to build\" << dendl;\n    return;\n  }\n\n  dout(1) << __func__ << \" over \" << cur_epoch << \"-\" << end_epoch << dendl;\n  assert(cur_epoch <= end_epoch);\n\n  OSDMapRef cur_map, last_map;\n  for ( ; cur_epoch <= end_epoch; cur_epoch++) {\n    dout(10) << __func__ << \" epoch \" << cur_epoch << dendl;\n    last_map = cur_map;\n    cur_map = get_map(cur_epoch);\n\n    for (map<PG*,pistate>::iterator i = pis.begin(); i != pis.end(); ++i) {\n      PG *pg = i->first;\n      pistate& p = i->second;\n\n      if (cur_epoch < p.start || cur_epoch > p.end)\n\tcontinue;\n\n      vector<int> acting, up;\n      int up_primary;\n      int primary;\n      pg_t pgid = pg->info.pgid.pgid;\n      if (p.same_interval_since && last_map->get_pools().count(pgid.pool()))\n\tpgid = pgid.get_ancestor(last_map->get_pg_num(pgid.pool()));\n      cur_map->pg_to_up_acting_osds(\n\tpgid, &up, &up_primary, &acting, &primary);\n\n      if (p.same_interval_since == 0) {\n\tdout(10) << __func__ << \" epoch \" << cur_epoch << \" pg \" << pg->info.pgid\n\t\t << \" first map, acting \" << acting\n\t\t << \" up \" << up << \", same_interval_since = \" << cur_epoch << dendl;\n\tp.same_interval_since = cur_epoch;\n\tp.old_up = up;\n\tp.old_acting = acting;\n\tp.primary = primary;\n\tp.up_primary = up_primary;\n\tcontinue;\n      }\n      assert(last_map);\n\n      boost::scoped_ptr<IsPGRecoverablePredicate> recoverable(\n        pg->get_is_recoverable_predicate());\n      std::stringstream debug;\n      bool new_interval = PastIntervals::check_new_interval(\n\tp.primary,\n\tprimary,\n\tp.old_acting, acting,\n\tp.up_primary,\n\tup_primary,\n\tp.old_up, up,\n\tp.same_interval_since,\n\tpg->info.history.last_epoch_clean,\n\tcur_map, last_map,\n\tpgid,\n        recoverable.get(),\n\t&pg->past_intervals,\n\t&debug);\n      if (new_interval) {\n\tdout(10) << __func__ << \" epoch \" << cur_epoch << \" pg \" << pg->info.pgid\n\t\t << \" \" << debug.str() << dendl;\n\tp.old_up = up;\n\tp.old_acting = acting;\n\tp.primary = primary;\n\tp.up_primary = up_primary;\n\tp.same_interval_since = cur_epoch;\n      }\n    }\n  }\n\n  // Now that past_intervals have been recomputed let's fix the same_interval_since\n  // if it was cleared by import.\n  for (map<PG*,pistate>::iterator i = pis.begin(); i != pis.end(); ++i) {\n    PG *pg = i->first;\n    pistate& p = i->second;\n\n    if (pg->info.history.same_interval_since == 0) {\n      assert(p.same_interval_since);\n      dout(10) << __func__ << \" fix same_interval_since \" << p.same_interval_since << \" pg \" << *pg << dendl;\n      dout(10) << __func__ << \" past_intervals \" << pg->past_intervals << dendl;\n      // Fix it\n      pg->info.history.same_interval_since = p.same_interval_since;\n    }\n  }\n\n  // write info only at the end.  this is necessary because we check\n  // whether the past_intervals go far enough back or forward in time,\n  // but we don't check for holes.  we could avoid it by discarding\n  // the previous past_intervals and rebuilding from scratch, or we\n  // can just do this and commit all our work at the end.\n  ObjectStore::Transaction t;\n  int num = 0;\n  for (map<PG*,pistate>::iterator i = pis.begin(); i != pis.end(); ++i) {\n    PG *pg = i->first;\n    pg->lock();\n    pg->dirty_big_info = true;\n    pg->dirty_info = true;\n    pg->write_if_dirty(t);\n    pg->unlock();\n\n    // don't let the transaction get too big\n    if (++num >= cct->_conf->osd_target_transaction_size) {\n      store->apply_transaction(service.meta_osr.get(), std::move(t));\n      t = ObjectStore::Transaction();\n      num = 0;\n    }\n  }\n  if (!t.empty())\n    store->apply_transaction(service.meta_osr.get(), std::move(t));\n}\n\n/*\n * look up a pg.  if we have it, great.  if not, consider creating it IF the pg mapping\n * hasn't changed since the given epoch and we are the primary.\n */\nint OSD::handle_pg_peering_evt(\n  spg_t pgid,\n  const pg_history_t& orig_history,\n  const PastIntervals& pi,\n  epoch_t epoch,\n  PG::CephPeeringEvtRef evt)\n{\n  if (service.splitting(pgid)) {\n    peering_wait_for_split[pgid].push_back(evt);\n    return -EEXIST;\n  }\n\n  PG *pg = _lookup_lock_pg(pgid);\n  if (!pg) {\n    // same primary?\n    if (!osdmap->have_pg_pool(pgid.pool()))\n      return -EINVAL;\n    int up_primary, acting_primary;\n    vector<int> up, acting;\n    osdmap->pg_to_up_acting_osds(\n      pgid.pgid, &up, &up_primary, &acting, &acting_primary);\n\n    pg_history_t history = orig_history;\n    bool valid_history = project_pg_history(\n      pgid, history, epoch, up, up_primary, acting, acting_primary);\n\n    if (!valid_history || epoch < history.same_interval_since) {\n      dout(10) << __func__ << pgid << \" acting changed in \"\n\t       << history.same_interval_since << \" (msg from \" << epoch << \")\"\n\t       << dendl;\n      return -EINVAL;\n    }\n\n    if (service.splitting(pgid)) {\n      ceph_abort();\n    }\n\n    const bool is_mon_create =\n      evt->get_event().dynamic_type() == PG::NullEvt::static_type();\n    if (maybe_wait_for_max_pg(pgid, is_mon_create)) {\n      return -EAGAIN;\n    }\n    // do we need to resurrect a deleting pg?\n    spg_t resurrected;\n    PGRef old_pg_state;\n    res_result result = _try_resurrect_pg(\n      service.get_osdmap(),\n      pgid,\n      &resurrected,\n      &old_pg_state);\n\n    PG::RecoveryCtx rctx = create_context();\n    switch (result) {\n    case RES_NONE: {\n      const pg_pool_t* pp = osdmap->get_pg_pool(pgid.pool());\n      if (pp->has_flag(pg_pool_t::FLAG_EC_OVERWRITES) &&\n\t  store->get_type() != \"bluestore\") {\n\tclog->warn() << \"pg \" << pgid\n\t\t     << \" is at risk of silent data corruption: \"\n\t\t     << \"the pool allows ec overwrites but is not stored in \"\n\t\t     << \"bluestore, so deep scrubbing will not detect bitrot\";\n      }\n      PG::_create(*rctx.transaction, pgid, pgid.get_split_bits(pp->get_pg_num()));\n      PG::_init(*rctx.transaction, pgid, pp);\n\n      int role = osdmap->calc_pg_role(whoami, acting, acting.size());\n      if (!pp->is_replicated() && role != pgid.shard)\n\trole = -1;\n\n      pg = _create_lock_pg(\n\tget_map(epoch),\n\tpgid, false, false,\n\trole,\n\tup, up_primary,\n\tacting, acting_primary,\n\thistory, pi,\n\t*rctx.transaction);\n      pg->handle_create(&rctx);\n      pg->write_if_dirty(*rctx.transaction);\n      dispatch_context(rctx, pg, osdmap);\n\n      dout(10) << *pg << \" is new\" << dendl;\n\n      pg->queue_peering_event(evt);\n      wake_pg_waiters(pg);\n      pg->unlock();\n      return 0;\n    }\n    case RES_SELF: {\n      old_pg_state->lock();\n      OSDMapRef old_osd_map = old_pg_state->get_osdmap();\n      int old_role = old_pg_state->role;\n      vector<int> old_up = old_pg_state->up;\n      int old_up_primary = old_pg_state->up_primary.osd;\n      vector<int> old_acting = old_pg_state->acting;\n      int old_primary = old_pg_state->primary.osd;\n      pg_history_t old_history = old_pg_state->info.history;\n      PastIntervals old_past_intervals = old_pg_state->past_intervals;\n      old_pg_state->unlock();\n      pg = _create_lock_pg(\n\told_osd_map,\n\tresurrected,\n\tfalse,\n\ttrue,\n\told_role,\n\told_up,\n\told_up_primary,\n\told_acting,\n\told_primary,\n\told_history,\n\told_past_intervals,\n\t*rctx.transaction);\n      pg->handle_create(&rctx);\n      pg->write_if_dirty(*rctx.transaction);\n      dispatch_context(rctx, pg, osdmap);\n\n      dout(10) << *pg << \" is new (resurrected)\" << dendl;\n\n      pg->queue_peering_event(evt);\n      wake_pg_waiters(pg);\n      pg->unlock();\n      return 0;\n    }\n    case RES_PARENT: {\n      assert(old_pg_state);\n      old_pg_state->lock();\n      OSDMapRef old_osd_map = old_pg_state->get_osdmap();\n      int old_role = old_pg_state->role;\n      vector<int> old_up = old_pg_state->up;\n      int old_up_primary = old_pg_state->up_primary.osd;\n      vector<int> old_acting = old_pg_state->acting;\n      int old_primary = old_pg_state->primary.osd;\n      pg_history_t old_history = old_pg_state->info.history;\n      PastIntervals old_past_intervals = old_pg_state->past_intervals;\n      old_pg_state->unlock();\n      PG *parent = _create_lock_pg(\n\told_osd_map,\n\tresurrected,\n\tfalse,\n\ttrue,\n\told_role,\n\told_up,\n\told_up_primary,\n\told_acting,\n\told_primary,\n\told_history,\n\told_past_intervals,\n\t*rctx.transaction\n\t);\n      parent->handle_create(&rctx);\n      parent->write_if_dirty(*rctx.transaction);\n      dispatch_context(rctx, parent, osdmap);\n\n      dout(10) << *parent << \" is new\" << dendl;\n\n      assert(service.splitting(pgid));\n      peering_wait_for_split[pgid].push_back(evt);\n\n      //parent->queue_peering_event(evt);\n      parent->queue_null(osdmap->get_epoch(), osdmap->get_epoch());\n      wake_pg_waiters(parent);\n      parent->unlock();\n      return 0;\n    }\n    default:\n      assert(0);\n      return 0;\n    }\n  } else {\n    // already had it.  did the mapping change?\n    if (epoch < pg->info.history.same_interval_since) {\n      dout(10) << *pg << __func__ << \" acting changed in \"\n\t       << pg->info.history.same_interval_since\n\t       << \" (msg from \" << epoch << \")\" << dendl;\n    } else {\n      pg->queue_peering_event(evt);\n    }\n    pg->unlock();\n    return -EEXIST;\n  }\n}\n\nbool OSD::maybe_wait_for_max_pg(spg_t pgid, bool is_mon_create)\n{\n  const auto max_pgs_per_osd =\n    (cct->_conf->get_val<uint64_t>(\"mon_max_pg_per_osd\") *\n     cct->_conf->get_val<double>(\"osd_max_pg_per_osd_hard_ratio\"));\n\n  RWLock::RLocker pg_map_locker{pg_map_lock};\n  if (pg_map.size() < max_pgs_per_osd) {\n    return false;\n  }\n  lock_guard<mutex> pending_creates_locker{pending_creates_lock};\n  if (is_mon_create) {\n    pending_creates_from_mon++;\n  } else {\n    bool is_primary = osdmap->get_pg_acting_rank(pgid.pgid, whoami) == 0;\n    pending_creates_from_osd.emplace(pgid.pgid, is_primary);\n  }\n  dout(5) << __func__ << \" withhold creation of pg \" << pgid\n\t  << \": \" << pg_map.size() << \" >= \"<< max_pgs_per_osd << dendl;\n  return true;\n}\n\n// to re-trigger a peering, we have to twiddle the pg mapping a little bit,\n// see PG::should_restart_peering(). OSDMap::pg_to_up_acting_osds() will turn\n// to up set if pg_temp is empty. so an empty pg_temp won't work.\nstatic vector<int32_t> twiddle(const vector<int>& acting) {\n  if (acting.size() > 1) {\n    return {acting[0]};\n  } else {\n    vector<int32_t> twiddled(acting.begin(), acting.end());\n    twiddled.push_back(-1);\n    return twiddled;\n  }\n}\n\nvoid OSD::resume_creating_pg()\n{\n  bool do_sub_pg_creates = false;\n  bool have_pending_creates = false;\n  {\n    const auto max_pgs_per_osd =\n      (cct->_conf->get_val<uint64_t>(\"mon_max_pg_per_osd\") *\n       cct->_conf->get_val<double>(\"osd_max_pg_per_osd_hard_ratio\"));\n    RWLock::RLocker l(pg_map_lock);\n    if (max_pgs_per_osd <= pg_map.size()) {\n      // this could happen if admin decreases this setting before a PG is removed\n      return;\n    }\n    unsigned spare_pgs = max_pgs_per_osd - pg_map.size();\n    lock_guard<mutex> pending_creates_locker{pending_creates_lock};\n    if (pending_creates_from_mon > 0) {\n      do_sub_pg_creates = true;\n      if (pending_creates_from_mon >= spare_pgs) {\n\tspare_pgs = pending_creates_from_mon = 0;\n      } else {\n\tspare_pgs -= pending_creates_from_mon;\n\tpending_creates_from_mon = 0;\n      }\n    }\n    auto pg = pending_creates_from_osd.cbegin();\n    while (spare_pgs > 0 && pg != pending_creates_from_osd.cend()) {\n      dout(20) << __func__ << \" pg \" << pg->first << dendl;\n      vector<int> acting;\n      osdmap->pg_to_up_acting_osds(pg->first, nullptr, nullptr, &acting, nullptr);\n      service.queue_want_pg_temp(pg->first, twiddle(acting), true);\n      pg = pending_creates_from_osd.erase(pg);\n      do_sub_pg_creates = true;\n      spare_pgs--;\n    }\n    have_pending_creates = (pending_creates_from_mon > 0 ||\n\t\t\t    !pending_creates_from_osd.empty());\n  }\n\n  bool do_renew_subs = false;\n  if (do_sub_pg_creates) {\n    if (monc->sub_want(\"osd_pg_creates\", last_pg_create_epoch, 0)) {\n      dout(4) << __func__ << \": resolicit pg creates from mon since \"\n\t      << last_pg_create_epoch << dendl;\n      do_renew_subs = true;\n    }\n  }\n  version_t start = osdmap->get_epoch() + 1;\n  if (have_pending_creates) {\n    // don't miss any new osdmap deleting PGs\n    if (monc->sub_want(\"osdmap\", start, 0)) {\n      dout(4) << __func__ << \": resolicit osdmap from mon since \"\n\t      << start << dendl;\n      do_renew_subs = true;\n    }\n  } else if (do_sub_pg_creates) {\n    // no need to subscribe the osdmap continuously anymore\n    // once the pgtemp and/or mon_subscribe(pg_creates) is sent\n    if (monc->sub_want_increment(\"osdmap\", start, CEPH_SUBSCRIBE_ONETIME)) {\n      dout(4) << __func__ << \": re-subscribe osdmap(onetime) since\"\n\t      << start << dendl;\n      do_renew_subs = true;\n    }\n  }\n\n  if (do_renew_subs) {\n    monc->renew_subs();\n  }\n\n  service.send_pg_temp();\n}\n\nvoid OSD::build_initial_pg_history(\n  spg_t pgid,\n  epoch_t created,\n  utime_t created_stamp,\n  pg_history_t *h,\n  PastIntervals *pi)\n{\n  dout(10) << __func__ << \" \" << pgid << \" created \" << created << dendl;\n  h->epoch_created = created;\n  h->epoch_pool_created = created;\n  h->same_interval_since = created;\n  h->same_up_since = created;\n  h->same_primary_since = created;\n  h->last_scrub_stamp = created_stamp;\n  h->last_deep_scrub_stamp = created_stamp;\n  h->last_clean_scrub_stamp = created_stamp;\n\n  OSDMapRef lastmap = service.get_map(created);\n  int up_primary, acting_primary;\n  vector<int> up, acting;\n  lastmap->pg_to_up_acting_osds(\n    pgid.pgid, &up, &up_primary, &acting, &acting_primary);\n\n  ostringstream debug;\n  for (epoch_t e = created + 1; e <= osdmap->get_epoch(); ++e) {\n    OSDMapRef osdmap = service.get_map(e);\n    int new_up_primary, new_acting_primary;\n    vector<int> new_up, new_acting;\n    osdmap->pg_to_up_acting_osds(\n      pgid.pgid, &new_up, &new_up_primary, &new_acting, &new_acting_primary);\n\n    // this is a bit imprecise, but sufficient?\n    struct min_size_predicate_t : public IsPGRecoverablePredicate {\n      const pg_pool_t *pi;\n      bool operator()(const set<pg_shard_t> &have) const {\n\treturn have.size() >= pi->min_size;\n      }\n      min_size_predicate_t(const pg_pool_t *i) : pi(i) {}\n    } min_size_predicate(osdmap->get_pg_pool(pgid.pgid.pool()));\n\n    bool new_interval = PastIntervals::check_new_interval(\n      acting_primary,\n      new_acting_primary,\n      acting, new_acting,\n      up_primary,\n      new_up_primary,\n      up, new_up,\n      h->same_interval_since,\n      h->last_epoch_clean,\n      osdmap,\n      lastmap,\n      pgid.pgid,\n      &min_size_predicate,\n      pi,\n      &debug);\n    if (new_interval) {\n      h->same_interval_since = e;\n      if (up != new_up) {\n        h->same_up_since = e;\n      }\n      if (acting_primary != new_acting_primary) {\n        h->same_primary_since = e;\n      }\n      if (pgid.pgid.is_split(lastmap->get_pg_num(pgid.pgid.pool()),\n                             osdmap->get_pg_num(pgid.pgid.pool()),\n                             nullptr)) {\n        h->last_epoch_split = e;\n      }\n      up = new_up;\n      acting = new_acting;\n      up_primary = new_up_primary;\n      acting_primary = new_acting_primary;\n    }\n    lastmap = osdmap;\n  }\n  dout(20) << __func__ << \" \" << debug.str() << dendl;\n  dout(10) << __func__ << \" \" << *h << \" \" << *pi\n\t   << \" [\" << (pi->empty() ? pair<epoch_t,epoch_t>(0,0) :\n\t\t       pi->get_bounds()) << \")\"\n\t   << dendl;\n}\n\n/**\n * Fill in the passed history so you know same_interval_since, same_up_since,\n * and same_primary_since.\n */\nbool OSD::project_pg_history(spg_t pgid, pg_history_t& h, epoch_t from,\n\t\t\t     const vector<int>& currentup,\n\t\t\t     int currentupprimary,\n\t\t\t     const vector<int>& currentacting,\n\t\t\t     int currentactingprimary)\n{\n  dout(15) << \"project_pg_history \" << pgid\n           << \" from \" << from << \" to \" << osdmap->get_epoch()\n           << \", start \" << h\n           << dendl;\n\n  epoch_t e;\n  for (e = osdmap->get_epoch();\n       e > from;\n       e--) {\n    // verify during intermediate epoch (e-1)\n    OSDMapRef oldmap = service.try_get_map(e-1);\n    if (!oldmap) {\n      dout(15) << __func__ << \": found map gap, returning false\" << dendl;\n      return false;\n    }\n    assert(oldmap->have_pg_pool(pgid.pool()));\n\n    int upprimary, actingprimary;\n    vector<int> up, acting;\n    oldmap->pg_to_up_acting_osds(\n      pgid.pgid,\n      &up,\n      &upprimary,\n      &acting,\n      &actingprimary);\n\n    // acting set change?\n    if ((actingprimary != currentactingprimary ||\n\t upprimary != currentupprimary ||\n\t acting != currentacting ||\n\t up != currentup) && e > h.same_interval_since) {\n      dout(15) << \"project_pg_history \" << pgid << \" acting|up changed in \" << e\n\t       << \" from \" << acting << \"/\" << up\n\t       << \" \" << actingprimary << \"/\" << upprimary\n\t       << \" -> \" << currentacting << \"/\" << currentup\n\t       << \" \" << currentactingprimary << \"/\" << currentupprimary\n\t       << dendl;\n      h.same_interval_since = e;\n    }\n    // split?\n    if (pgid.is_split(oldmap->get_pg_num(pgid.pool()),\n\t\t      osdmap->get_pg_num(pgid.pool()),\n\t\t      0) && e > h.same_interval_since) {\n      h.same_interval_since = e;\n    }\n    // up set change?\n    if ((up != currentup || upprimary != currentupprimary)\n\t&& e > h.same_up_since) {\n      dout(15) << \"project_pg_history \" << pgid << \" up changed in \" << e\n\t       << \" from \" << up << \" \" << upprimary\n\t       << \" -> \" << currentup << \" \" << currentupprimary << dendl;\n      h.same_up_since = e;\n    }\n\n    // primary change?\n    if (OSDMap::primary_changed(\n\t  actingprimary,\n\t  acting,\n\t  currentactingprimary,\n\t  currentacting) &&\n        e > h.same_primary_since) {\n      dout(15) << \"project_pg_history \" << pgid << \" primary changed in \" << e << dendl;\n      h.same_primary_since = e;\n    }\n\n    if (h.same_interval_since >= e && h.same_up_since >= e && h.same_primary_since >= e)\n      break;\n  }\n\n  // base case: these floors should be the pg creation epoch if we didn't\n  // find any changes.\n  if (e == h.epoch_created) {\n    if (!h.same_interval_since)\n      h.same_interval_since = e;\n    if (!h.same_up_since)\n      h.same_up_since = e;\n    if (!h.same_primary_since)\n      h.same_primary_since = e;\n  }\n\n  dout(15) << \"project_pg_history end \" << h << dendl;\n  return true;\n}\n\n\n\nvoid OSD::_add_heartbeat_peer(int p)\n{\n  if (p == whoami)\n    return;\n  HeartbeatInfo *hi;\n\n  map<int,HeartbeatInfo>::iterator i = heartbeat_peers.find(p);\n  if (i == heartbeat_peers.end()) {\n    pair<ConnectionRef,ConnectionRef> cons = service.get_con_osd_hb(p, osdmap->get_epoch());\n    if (!cons.first)\n      return;\n    hi = &heartbeat_peers[p];\n    hi->peer = p;\n    HeartbeatSession *s = new HeartbeatSession(p);\n    hi->con_back = cons.first.get();\n    hi->con_back->set_priv(s->get());\n    if (cons.second) {\n      hi->con_front = cons.second.get();\n      hi->con_front->set_priv(s->get());\n      dout(10) << \"_add_heartbeat_peer: new peer osd.\" << p\n\t       << \" \" << hi->con_back->get_peer_addr()\n\t       << \" \" << hi->con_front->get_peer_addr()\n\t       << dendl;\n    } else {\n      hi->con_front.reset(NULL);\n      dout(10) << \"_add_heartbeat_peer: new peer osd.\" << p\n\t       << \" \" << hi->con_back->get_peer_addr()\n\t       << dendl;\n    }\n    s->put();\n  } else {\n    hi = &i->second;\n  }\n  hi->epoch = osdmap->get_epoch();\n}\n\nvoid OSD::_remove_heartbeat_peer(int n)\n{\n  map<int,HeartbeatInfo>::iterator q = heartbeat_peers.find(n);\n  assert(q != heartbeat_peers.end());\n  dout(20) << \" removing heartbeat peer osd.\" << n\n\t   << \" \" << q->second.con_back->get_peer_addr()\n\t   << \" \" << (q->second.con_front ? q->second.con_front->get_peer_addr() : entity_addr_t())\n\t   << dendl;\n  q->second.con_back->mark_down();\n  if (q->second.con_front) {\n    q->second.con_front->mark_down();\n  }\n  heartbeat_peers.erase(q);\n}\n\nvoid OSD::need_heartbeat_peer_update()\n{\n  if (is_stopping())\n    return;\n  dout(20) << \"need_heartbeat_peer_update\" << dendl;\n  heartbeat_set_peers_need_update();\n}\n\nvoid OSD::maybe_update_heartbeat_peers()\n{\n  assert(osd_lock.is_locked());\n\n  if (is_waiting_for_healthy()) {\n    utime_t now = ceph_clock_now();\n    if (last_heartbeat_resample == utime_t()) {\n      last_heartbeat_resample = now;\n      heartbeat_set_peers_need_update();\n    } else if (!heartbeat_peers_need_update()) {\n      utime_t dur = now - last_heartbeat_resample;\n      if (dur > cct->_conf->osd_heartbeat_grace) {\n\tdout(10) << \"maybe_update_heartbeat_peers forcing update after \" << dur << \" seconds\" << dendl;\n\theartbeat_set_peers_need_update();\n\tlast_heartbeat_resample = now;\n\treset_heartbeat_peers();   // we want *new* peers!\n      }\n    }\n  }\n\n  if (!heartbeat_peers_need_update())\n    return;\n  heartbeat_clear_peers_need_update();\n\n  Mutex::Locker l(heartbeat_lock);\n\n  dout(10) << \"maybe_update_heartbeat_peers updating\" << dendl;\n\n\n  // build heartbeat from set\n  if (is_active()) {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t, PG*>::iterator i = pg_map.begin();\n\t i != pg_map.end();\n\t ++i) {\n      PG *pg = i->second;\n      pg->heartbeat_peer_lock.Lock();\n      dout(20) << i->first << \" heartbeat_peers \" << pg->heartbeat_peers << dendl;\n      for (set<int>::iterator p = pg->heartbeat_peers.begin();\n\t   p != pg->heartbeat_peers.end();\n\t   ++p)\n\tif (osdmap->is_up(*p))\n\t  _add_heartbeat_peer(*p);\n      for (set<int>::iterator p = pg->probe_targets.begin();\n\t   p != pg->probe_targets.end();\n\t   ++p)\n\tif (osdmap->is_up(*p))\n\t  _add_heartbeat_peer(*p);\n      pg->heartbeat_peer_lock.Unlock();\n    }\n  }\n\n  // include next and previous up osds to ensure we have a fully-connected set\n  set<int> want, extras;\n  int next = osdmap->get_next_up_osd_after(whoami);\n  if (next >= 0)\n    want.insert(next);\n  int prev = osdmap->get_previous_up_osd_before(whoami);\n  if (prev >= 0 && prev != next)\n    want.insert(prev);\n\n  for (set<int>::iterator p = want.begin(); p != want.end(); ++p) {\n    dout(10) << \" adding neighbor peer osd.\" << *p << dendl;\n    extras.insert(*p);\n    _add_heartbeat_peer(*p);\n  }\n\n  // remove down peers; enumerate extras\n  map<int,HeartbeatInfo>::iterator p = heartbeat_peers.begin();\n  while (p != heartbeat_peers.end()) {\n    if (!osdmap->is_up(p->first)) {\n      int o = p->first;\n      ++p;\n      _remove_heartbeat_peer(o);\n      continue;\n    }\n    if (p->second.epoch < osdmap->get_epoch()) {\n      extras.insert(p->first);\n    }\n    ++p;\n  }\n\n  // too few?\n  int start = osdmap->get_next_up_osd_after(whoami);\n  for (int n = start; n >= 0; ) {\n    if ((int)heartbeat_peers.size() >= cct->_conf->osd_heartbeat_min_peers)\n      break;\n    if (!extras.count(n) && !want.count(n) && n != whoami) {\n      dout(10) << \" adding random peer osd.\" << n << dendl;\n      extras.insert(n);\n      _add_heartbeat_peer(n);\n    }\n    n = osdmap->get_next_up_osd_after(n);\n    if (n == start)\n      break;  // came full circle; stop\n  }\n\n  // too many?\n  for (set<int>::iterator p = extras.begin();\n       (int)heartbeat_peers.size() > cct->_conf->osd_heartbeat_min_peers && p != extras.end();\n       ++p) {\n    if (want.count(*p))\n      continue;\n    _remove_heartbeat_peer(*p);\n  }\n\n  dout(10) << \"maybe_update_heartbeat_peers \" << heartbeat_peers.size() << \" peers, extras \" << extras << dendl;\n}\n\nvoid OSD::reset_heartbeat_peers()\n{\n  assert(osd_lock.is_locked());\n  dout(10) << \"reset_heartbeat_peers\" << dendl;\n  Mutex::Locker l(heartbeat_lock);\n  while (!heartbeat_peers.empty()) {\n    HeartbeatInfo& hi = heartbeat_peers.begin()->second;\n    hi.con_back->mark_down();\n    if (hi.con_front) {\n      hi.con_front->mark_down();\n    }\n    heartbeat_peers.erase(heartbeat_peers.begin());\n  }\n  failure_queue.clear();\n}\n\nvoid OSD::handle_osd_ping(MOSDPing *m)\n{\n  if (superblock.cluster_fsid != m->fsid) {\n    dout(20) << \"handle_osd_ping from \" << m->get_source_inst()\n\t     << \" bad fsid \" << m->fsid << \" != \" << superblock.cluster_fsid << dendl;\n    m->put();\n    return;\n  }\n\n  int from = m->get_source().num();\n\n  heartbeat_lock.Lock();\n  if (is_stopping()) {\n    heartbeat_lock.Unlock();\n    m->put();\n    return;\n  }\n\n  OSDMapRef curmap = service.get_osdmap();\n  if (!curmap) {\n    heartbeat_lock.Unlock();\n    m->put();\n    return;\n  }\n\n  switch (m->op) {\n\n  case MOSDPing::PING:\n    {\n      if (cct->_conf->osd_debug_drop_ping_probability > 0) {\n\tauto heartbeat_drop = debug_heartbeat_drops_remaining.find(from);\n\tif (heartbeat_drop != debug_heartbeat_drops_remaining.end()) {\n\t  if (heartbeat_drop->second == 0) {\n\t    debug_heartbeat_drops_remaining.erase(heartbeat_drop);\n\t  } else {\n\t    --heartbeat_drop->second;\n\t    dout(5) << \"Dropping heartbeat from \" << from\n\t\t    << \", \" << heartbeat_drop->second\n\t\t    << \" remaining to drop\" << dendl;\n\t    break;\n\t  }\n\t} else if (cct->_conf->osd_debug_drop_ping_probability >\n\t           ((((double)(rand()%100))/100.0))) {\n\t  heartbeat_drop =\n\t    debug_heartbeat_drops_remaining.insert(std::make_pair(from,\n\t                     cct->_conf->osd_debug_drop_ping_duration)).first;\n\t  dout(5) << \"Dropping heartbeat from \" << from\n\t\t  << \", \" << heartbeat_drop->second\n\t\t  << \" remaining to drop\" << dendl;\n\t  break;\n\t}\n      }\n\n      if (!cct->get_heartbeat_map()->is_healthy()) {\n\tdout(10) << \"internal heartbeat not healthy, dropping ping request\" << dendl;\n\tbreak;\n      }\n\n      Message *r = new MOSDPing(monc->get_fsid(),\n\t\t\t\tcurmap->get_epoch(),\n\t\t\t\tMOSDPing::PING_REPLY, m->stamp,\n\t\t\t\tcct->_conf->osd_heartbeat_min_size);\n      m->get_connection()->send_message(r);\n\n      if (curmap->is_up(from)) {\n\tservice.note_peer_epoch(from, m->map_epoch);\n\tif (is_active()) {\n\t  ConnectionRef con = service.get_con_osd_cluster(from, curmap->get_epoch());\n\t  if (con) {\n\t    service.share_map_peer(from, con.get());\n\t  }\n\t}\n      } else if (!curmap->exists(from) ||\n\t\t curmap->get_down_at(from) > m->map_epoch) {\n\t// tell them they have died\n\tMessage *r = new MOSDPing(monc->get_fsid(),\n\t\t\t\t  curmap->get_epoch(),\n\t\t\t\t  MOSDPing::YOU_DIED,\n\t\t\t\t  m->stamp,\n\t\t\t\t  cct->_conf->osd_heartbeat_min_size);\n\tm->get_connection()->send_message(r);\n      }\n    }\n    break;\n\n  case MOSDPing::PING_REPLY:\n    {\n      map<int,HeartbeatInfo>::iterator i = heartbeat_peers.find(from);\n      if (i != heartbeat_peers.end()) {\n\tif (m->get_connection() == i->second.con_back) {\n\t  dout(25) << \"handle_osd_ping got reply from osd.\" << from\n\t\t   << \" first_tx \" << i->second.first_tx\n\t\t   << \" last_tx \" << i->second.last_tx\n\t\t   << \" last_rx_back \" << i->second.last_rx_back << \" -> \" << m->stamp\n\t\t   << \" last_rx_front \" << i->second.last_rx_front\n\t\t   << dendl;\n\t  i->second.last_rx_back = m->stamp;\n\t  // if there is no front con, set both stamps.\n\t  if (i->second.con_front == NULL)\n\t    i->second.last_rx_front = m->stamp;\n\t} else if (m->get_connection() == i->second.con_front) {\n\t  dout(25) << \"handle_osd_ping got reply from osd.\" << from\n\t\t   << \" first_tx \" << i->second.first_tx\n\t\t   << \" last_tx \" << i->second.last_tx\n\t\t   << \" last_rx_back \" << i->second.last_rx_back\n\t\t   << \" last_rx_front \" << i->second.last_rx_front << \" -> \" << m->stamp\n\t\t   << dendl;\n\t  i->second.last_rx_front = m->stamp;\n\t}\n\n        utime_t cutoff = ceph_clock_now();\n        cutoff -= cct->_conf->osd_heartbeat_grace;\n        if (i->second.is_healthy(cutoff)) {\n          // Cancel false reports\n\t  auto failure_queue_entry = failure_queue.find(from);\n\t  if (failure_queue_entry != failure_queue.end()) {\n            dout(10) << \"handle_osd_ping canceling queued \"\n                     << \"failure report for osd.\" << from << dendl;\n            failure_queue.erase(failure_queue_entry);\n          }\n\n\t  auto failure_pending_entry = failure_pending.find(from);\n\t  if (failure_pending_entry != failure_pending.end()) {\n            dout(10) << \"handle_osd_ping canceling in-flight \"\n                     << \"failure report for osd.\" << from << dendl;\n            send_still_alive(curmap->get_epoch(),\n\t\t\t     failure_pending_entry->second.second);\n            failure_pending.erase(failure_pending_entry);\n          }\n        }\n      }\n\n      if (m->map_epoch &&\n\t  curmap->is_up(from)) {\n\tservice.note_peer_epoch(from, m->map_epoch);\n\tif (is_active()) {\n\t  ConnectionRef con = service.get_con_osd_cluster(from, curmap->get_epoch());\n\t  if (con) {\n\t    service.share_map_peer(from, con.get());\n\t  }\n\t}\n      }\n    }\n    break;\n\n  case MOSDPing::YOU_DIED:\n    dout(10) << \"handle_osd_ping \" << m->get_source_inst()\n\t     << \" says i am down in \" << m->map_epoch << dendl;\n    osdmap_subscribe(curmap->get_epoch()+1, false);\n    break;\n  }\n\n  heartbeat_lock.Unlock();\n  m->put();\n}\n\nvoid OSD::heartbeat_entry()\n{\n  Mutex::Locker l(heartbeat_lock);\n  if (is_stopping())\n    return;\n  while (!heartbeat_stop) {\n    heartbeat();\n\n    double wait = .5 + ((float)(rand() % 10)/10.0) * (float)cct->_conf->osd_heartbeat_interval;\n    utime_t w;\n    w.set_from_double(wait);\n    dout(30) << \"heartbeat_entry sleeping for \" << wait << dendl;\n    heartbeat_cond.WaitInterval(heartbeat_lock, w);\n    if (is_stopping())\n      return;\n    dout(30) << \"heartbeat_entry woke up\" << dendl;\n  }\n}\n\nvoid OSD::heartbeat_check()\n{\n  assert(heartbeat_lock.is_locked());\n  utime_t now = ceph_clock_now();\n\n  // check for heartbeat replies (move me elsewhere?)\n  utime_t cutoff = now;\n  cutoff -= cct->_conf->osd_heartbeat_grace;\n  for (map<int,HeartbeatInfo>::iterator p = heartbeat_peers.begin();\n       p != heartbeat_peers.end();\n       ++p) {\n\n    if (p->second.first_tx == utime_t()) {\n      dout(25) << \"heartbeat_check we haven't sent ping to osd.\" << p->first\n               << \"yet, skipping\" << dendl;\n      continue;\n    }\n\n    dout(25) << \"heartbeat_check osd.\" << p->first\n\t     << \" first_tx \" << p->second.first_tx\n\t     << \" last_tx \" << p->second.last_tx\n\t     << \" last_rx_back \" << p->second.last_rx_back\n\t     << \" last_rx_front \" << p->second.last_rx_front\n\t     << dendl;\n    if (p->second.is_unhealthy(cutoff)) {\n      if (p->second.last_rx_back == utime_t() ||\n\t  p->second.last_rx_front == utime_t()) {\n\tderr << \"heartbeat_check: no reply from \" << p->second.con_front->get_peer_addr().get_sockaddr()\n\t     << \" osd.\" << p->first << \" ever on either front or back, first ping sent \"\n\t     << p->second.first_tx << \" (cutoff \" << cutoff << \")\" << dendl;\n\t// fail\n\tfailure_queue[p->first] = p->second.last_tx;\n      } else {\n\tderr << \"heartbeat_check: no reply from \" << p->second.con_front->get_peer_addr().get_sockaddr()\n\t     << \" osd.\" << p->first << \" since back \" << p->second.last_rx_back\n\t     << \" front \" << p->second.last_rx_front\n\t     << \" (cutoff \" << cutoff << \")\" << dendl;\n\t// fail\n\tfailure_queue[p->first] = MIN(p->second.last_rx_back, p->second.last_rx_front);\n      }\n    }\n  }\n}\n\nvoid OSD::heartbeat()\n{\n  dout(30) << \"heartbeat\" << dendl;\n\n  // get CPU load avg\n  double loadavgs[1];\n  int n_samples = 86400 / cct->_conf->osd_heartbeat_interval;\n  if (getloadavg(loadavgs, 1) == 1) {\n    logger->set(l_osd_loadavg, 100 * loadavgs[0]);\n    daily_loadavg = (daily_loadavg * (n_samples - 1) + loadavgs[0]) / n_samples;\n    dout(30) << \"heartbeat: daily_loadavg \" << daily_loadavg << dendl;\n  }\n\n  dout(30) << \"heartbeat checking stats\" << dendl;\n\n  // refresh stats?\n  vector<int> hb_peers;\n  for (map<int,HeartbeatInfo>::iterator p = heartbeat_peers.begin();\n       p != heartbeat_peers.end();\n       ++p)\n    hb_peers.push_back(p->first);\n  service.update_osd_stat(hb_peers);\n\n  dout(5) << \"heartbeat: \" << service.get_osd_stat() << dendl;\n\n  utime_t now = ceph_clock_now();\n\n  // send heartbeats\n  for (map<int,HeartbeatInfo>::iterator i = heartbeat_peers.begin();\n       i != heartbeat_peers.end();\n       ++i) {\n    int peer = i->first;\n    i->second.last_tx = now;\n    if (i->second.first_tx == utime_t())\n      i->second.first_tx = now;\n    dout(30) << \"heartbeat sending ping to osd.\" << peer << dendl;\n    i->second.con_back->send_message(new MOSDPing(monc->get_fsid(),\n\t\t\t\t\t  service.get_osdmap()->get_epoch(),\n\t\t\t\t\t  MOSDPing::PING, now,\n\t\t\t\t\t  cct->_conf->osd_heartbeat_min_size));\n\n    if (i->second.con_front)\n      i->second.con_front->send_message(new MOSDPing(monc->get_fsid(),\n\t\t\t\t\t     service.get_osdmap()->get_epoch(),\n\t\t\t\t\t     MOSDPing::PING, now,\n\t\t\t\t\t  cct->_conf->osd_heartbeat_min_size));\n  }\n\n  logger->set(l_osd_hb_to, heartbeat_peers.size());\n\n  // hmm.. am i all alone?\n  dout(30) << \"heartbeat lonely?\" << dendl;\n  if (heartbeat_peers.empty()) {\n    if (now - last_mon_heartbeat > cct->_conf->osd_mon_heartbeat_interval && is_active()) {\n      last_mon_heartbeat = now;\n      dout(10) << \"i have no heartbeat peers; checking mon for new map\" << dendl;\n      osdmap_subscribe(osdmap->get_epoch() + 1, false);\n    }\n  }\n\n  dout(30) << \"heartbeat done\" << dendl;\n}\n\nbool OSD::heartbeat_reset(Connection *con)\n{\n  HeartbeatSession *s = static_cast<HeartbeatSession*>(con->get_priv());\n  if (s) {\n    heartbeat_lock.Lock();\n    if (is_stopping()) {\n      heartbeat_lock.Unlock();\n      s->put();\n      return true;\n    }\n    map<int,HeartbeatInfo>::iterator p = heartbeat_peers.find(s->peer);\n    if (p != heartbeat_peers.end() &&\n\t(p->second.con_back == con ||\n\t p->second.con_front == con)) {\n      dout(10) << \"heartbeat_reset failed hb con \" << con << \" for osd.\" << p->second.peer\n\t       << \", reopening\" << dendl;\n      if (con != p->second.con_back) {\n\tp->second.con_back->mark_down();\n      }\n      p->second.con_back.reset(NULL);\n      if (p->second.con_front && con != p->second.con_front) {\n\tp->second.con_front->mark_down();\n      }\n      p->second.con_front.reset(NULL);\n      pair<ConnectionRef,ConnectionRef> newcon = service.get_con_osd_hb(p->second.peer, p->second.epoch);\n      if (newcon.first) {\n\tp->second.con_back = newcon.first.get();\n\tp->second.con_back->set_priv(s->get());\n\tif (newcon.second) {\n\t  p->second.con_front = newcon.second.get();\n\t  p->second.con_front->set_priv(s->get());\n\t}\n      } else {\n\tdout(10) << \"heartbeat_reset failed hb con \" << con << \" for osd.\" << p->second.peer\n\t\t << \", raced with osdmap update, closing out peer\" << dendl;\n\theartbeat_peers.erase(p);\n      }\n    } else {\n      dout(10) << \"heartbeat_reset closing (old) failed hb con \" << con << dendl;\n    }\n    heartbeat_lock.Unlock();\n    s->put();\n  }\n  return true;\n}\n\n\n\n// =========================================\n\nvoid OSD::tick()\n{\n  assert(osd_lock.is_locked());\n  dout(10) << \"tick\" << dendl;\n\n  if (is_active() || is_waiting_for_healthy()) {\n    maybe_update_heartbeat_peers();\n  }\n\n  if (is_waiting_for_healthy()) {\n    start_boot();\n  } else if (is_preboot() &&\n\t     waiting_for_luminous_mons &&\n\t     monc->monmap.get_required_features().contains_all(\n\t       ceph::features::mon::FEATURE_LUMINOUS)) {\n    // mon upgrade finished!\n    start_boot();\n  }\n\n  do_waiters();\n\n  tick_timer.add_event_after(OSD_TICK_INTERVAL, new C_Tick(this));\n}\n\nvoid OSD::tick_without_osd_lock()\n{\n  assert(tick_timer_lock.is_locked());\n  dout(10) << \"tick_without_osd_lock\" << dendl;\n\n  logger->set(l_osd_buf, buffer::get_total_alloc());\n  logger->set(l_osd_history_alloc_bytes, SHIFT_ROUND_UP(buffer::get_history_alloc_bytes(), 20));\n  logger->set(l_osd_history_alloc_num, buffer::get_history_alloc_num());\n  logger->set(l_osd_cached_crc, buffer::get_cached_crc());\n  logger->set(l_osd_cached_crc_adjusted, buffer::get_cached_crc_adjusted());\n  logger->set(l_osd_missed_crc, buffer::get_missed_crc());\n  logger->set(l_osd_pg_removing, remove_wq.get_remove_queue_len());\n\n  // osd_lock is not being held, which means the OSD state\n  // might change when doing the monitor report\n  if (is_active() || is_waiting_for_healthy()) {\n    heartbeat_lock.Lock();\n    heartbeat_check();\n    heartbeat_lock.Unlock();\n\n    map_lock.get_read();\n    Mutex::Locker l(mon_report_lock);\n\n    // mon report?\n    bool reset = false;\n    bool report = false;\n    utime_t now = ceph_clock_now();\n    pg_stat_queue_lock.Lock();\n    double backoff = stats_ack_timeout / cct->_conf->osd_mon_ack_timeout;\n    double adjusted_min = cct->_conf->osd_mon_report_interval_min * backoff;\n    // note: we shouldn't adjust max because it must remain < the\n    // mon's mon_osd_report_timeout (which defaults to 1.5x our\n    // value).\n    double max = cct->_conf->osd_mon_report_interval_max;\n    if (!outstanding_pg_stats.empty() &&\n\t(now - stats_ack_timeout) > last_pg_stats_ack) {\n      dout(1) << __func__ << \" mon hasn't acked PGStats in \"\n\t      << now - last_pg_stats_ack\n\t      << \" seconds, reconnecting elsewhere\" << dendl;\n      reset = true;\n      last_pg_stats_ack = now;  // reset clock\n      last_pg_stats_sent = utime_t();\n      stats_ack_timeout =\n\tMAX(cct->_conf->osd_mon_ack_timeout,\n\t    stats_ack_timeout * cct->_conf->osd_stats_ack_timeout_factor);\n      outstanding_pg_stats.clear();\n    }\n    if (now - last_pg_stats_sent > max) {\n      osd_stat_updated = true;\n      report = true;\n    } else if (service.need_fullness_update()) {\n      report = true;\n    } else if ((int)outstanding_pg_stats.size() >=\n\t       cct->_conf->osd_mon_report_max_in_flight) {\n      dout(20) << __func__ << \" have max \" << outstanding_pg_stats\n\t       << \" stats updates in flight\" << dendl;\n    } else {\n      if (now - last_mon_report > adjusted_min) {\n\tdout(20) << __func__ << \" stats backoff \" << backoff\n\t\t << \" adjusted_min \" << adjusted_min << \" - sending report\"\n\t\t << dendl;\n        osd_stat_updated = true;\n\treport = true;\n      }\n    }\n    pg_stat_queue_lock.Unlock();\n\n    if (reset) {\n      monc->reopen_session();\n    } else if (report) {\n      last_mon_report = now;\n\n      // do any pending reports\n      send_full_update();\n      send_failures();\n      if (osdmap->require_osd_release < CEPH_RELEASE_LUMINOUS) {\n\tsend_pg_stats(now);\n      }\n    }\n    map_lock.put_read();\n  }\n\n  if (is_active()) {\n    if (!scrub_random_backoff()) {\n      sched_scrub();\n    }\n    service.promote_throttle_recalibrate();\n    resume_creating_pg();\n    bool need_send_beacon = false;\n    const auto now = ceph::coarse_mono_clock::now();\n    {\n      // borrow lec lock to pretect last_sent_beacon from changing\n      Mutex::Locker l{min_last_epoch_clean_lock};\n      const auto elapsed = now - last_sent_beacon;\n      if (chrono::duration_cast<chrono::seconds>(elapsed).count() >\n        cct->_conf->osd_beacon_report_interval) {\n        need_send_beacon = true;\n      }\n    }\n    if (need_send_beacon) {\n      send_beacon(now);\n    }\n  }\n\n  mgrc.update_osd_health(get_health_metrics());\n  service.kick_recovery_queue();\n  tick_timer_without_osd_lock.add_event_after(OSD_TICK_INTERVAL, new C_Tick_WithoutOSDLock(this));\n}\n\nvoid OSD::check_ops_in_flight()\n{\n  vector<string> warnings;\n  if (op_tracker.check_ops_in_flight(warnings)) {\n    for (vector<string>::iterator i = warnings.begin();\n        i != warnings.end();\n        ++i) {\n      clog->warn() << *i;\n    }\n  }\n}\n\n// Usage:\n//   setomapval <pool-id> [namespace/]<obj-name> <key> <val>\n//   rmomapkey <pool-id> [namespace/]<obj-name> <key>\n//   setomapheader <pool-id> [namespace/]<obj-name> <header>\n//   getomap <pool> [namespace/]<obj-name>\n//   truncobj <pool-id> [namespace/]<obj-name> <newlen>\n//   injectmdataerr [namespace/]<obj-name> [shardid]\n//   injectdataerr [namespace/]<obj-name> [shardid]\n//\n//   set_recovery_delay [utime]\nvoid TestOpsSocketHook::test_ops(OSDService *service, ObjectStore *store,\n     const std::string &command, cmdmap_t& cmdmap, ostream &ss)\n{\n  //Test support\n  //Support changing the omap on a single osd by using the Admin Socket to\n  //directly request the osd make a change.\n  if (command == \"setomapval\" || command == \"rmomapkey\" ||\n      command == \"setomapheader\" || command == \"getomap\" ||\n      command == \"truncobj\" || command == \"injectmdataerr\" ||\n      command == \"injectdataerr\"\n    ) {\n    pg_t rawpg;\n    int64_t pool;\n    OSDMapRef curmap = service->get_osdmap();\n    int r = -1;\n\n    string poolstr;\n\n    cmd_getval(service->cct, cmdmap, \"pool\", poolstr);\n    pool = curmap->lookup_pg_pool_name(poolstr);\n    //If we can't find it by name then maybe id specified\n    if (pool < 0 && isdigit(poolstr[0]))\n      pool = atoll(poolstr.c_str());\n    if (pool < 0) {\n      ss << \"Invalid pool '\" << poolstr << \"''\";\n      return;\n    }\n\n    string objname, nspace;\n    cmd_getval(service->cct, cmdmap, \"objname\", objname);\n    std::size_t found = objname.find_first_of('/');\n    if (found != string::npos) {\n      nspace = objname.substr(0, found);\n      objname = objname.substr(found+1);\n    }\n    object_locator_t oloc(pool, nspace);\n    r = curmap->object_locator_to_pg(object_t(objname), oloc,  rawpg);\n\n    if (r < 0) {\n      ss << \"Invalid namespace/objname\";\n      return;\n    }\n\n    int64_t shardid;\n    cmd_getval(service->cct, cmdmap, \"shardid\", shardid, int64_t(shard_id_t::NO_SHARD));\n    hobject_t obj(object_t(objname), string(\"\"), CEPH_NOSNAP, rawpg.ps(), pool, nspace);\n    ghobject_t gobj(obj, ghobject_t::NO_GEN, shard_id_t(uint8_t(shardid)));\n    spg_t pgid(curmap->raw_pg_to_pg(rawpg), shard_id_t(shardid));\n    if (curmap->pg_is_ec(rawpg)) {\n        if ((command != \"injectdataerr\") && (command != \"injectmdataerr\")) {\n            ss << \"Must not call on ec pool, except injectdataerr or injectmdataerr\";\n            return;\n        }\n    }\n\n    ObjectStore::Transaction t;\n\n    if (command == \"setomapval\") {\n      map<string, bufferlist> newattrs;\n      bufferlist val;\n      string key, valstr;\n      cmd_getval(service->cct, cmdmap, \"key\", key);\n      cmd_getval(service->cct, cmdmap, \"val\", valstr);\n\n      val.append(valstr);\n      newattrs[key] = val;\n      t.omap_setkeys(coll_t(pgid), ghobject_t(obj), newattrs);\n      r = store->apply_transaction(service->meta_osr.get(), std::move(t));\n      if (r < 0)\n        ss << \"error=\" << r;\n      else\n        ss << \"ok\";\n    } else if (command == \"rmomapkey\") {\n      string key;\n      set<string> keys;\n      cmd_getval(service->cct, cmdmap, \"key\", key);\n\n      keys.insert(key);\n      t.omap_rmkeys(coll_t(pgid), ghobject_t(obj), keys);\n      r = store->apply_transaction(service->meta_osr.get(), std::move(t));\n      if (r < 0)\n        ss << \"error=\" << r;\n      else\n        ss << \"ok\";\n    } else if (command == \"setomapheader\") {\n      bufferlist newheader;\n      string headerstr;\n\n      cmd_getval(service->cct, cmdmap, \"header\", headerstr);\n      newheader.append(headerstr);\n      t.omap_setheader(coll_t(pgid), ghobject_t(obj), newheader);\n      r = store->apply_transaction(service->meta_osr.get(), std::move(t));\n      if (r < 0)\n        ss << \"error=\" << r;\n      else\n        ss << \"ok\";\n    } else if (command == \"getomap\") {\n      //Debug: Output entire omap\n      bufferlist hdrbl;\n      map<string, bufferlist> keyvals;\n      r = store->omap_get(coll_t(pgid), ghobject_t(obj), &hdrbl, &keyvals);\n      if (r >= 0) {\n          ss << \"header=\" << string(hdrbl.c_str(), hdrbl.length());\n          for (map<string, bufferlist>::iterator it = keyvals.begin();\n              it != keyvals.end(); ++it)\n            ss << \" key=\" << (*it).first << \" val=\"\n               << string((*it).second.c_str(), (*it).second.length());\n      } else {\n          ss << \"error=\" << r;\n      }\n    } else if (command == \"truncobj\") {\n      int64_t trunclen;\n      cmd_getval(service->cct, cmdmap, \"len\", trunclen);\n      t.truncate(coll_t(pgid), ghobject_t(obj), trunclen);\n      r = store->apply_transaction(service->meta_osr.get(), std::move(t));\n      if (r < 0)\n\tss << \"error=\" << r;\n      else\n\tss << \"ok\";\n    } else if (command == \"injectdataerr\") {\n      store->inject_data_error(gobj);\n      ss << \"ok\";\n    } else if (command == \"injectmdataerr\") {\n      store->inject_mdata_error(gobj);\n      ss << \"ok\";\n    }\n    return;\n  }\n  if (command == \"set_recovery_delay\") {\n    int64_t delay;\n    cmd_getval(service->cct, cmdmap, \"utime\", delay, (int64_t)0);\n    ostringstream oss;\n    oss << delay;\n    int r = service->cct->_conf->set_val(\"osd_recovery_delay_start\",\n\t\t\t\t\t oss.str().c_str());\n    if (r != 0) {\n      ss << \"set_recovery_delay: error setting \"\n\t << \"osd_recovery_delay_start to '\" << delay << \"': error \"\n\t << r;\n      return;\n    }\n    service->cct->_conf->apply_changes(NULL);\n    ss << \"set_recovery_delay: set osd_recovery_delay_start \"\n       << \"to \" << service->cct->_conf->osd_recovery_delay_start;\n    return;\n  }\n  if (command ==  \"trigger_scrub\") {\n    spg_t pgid;\n    OSDMapRef curmap = service->get_osdmap();\n\n    string pgidstr;\n\n    cmd_getval(service->cct, cmdmap, \"pgid\", pgidstr);\n    if (!pgid.parse(pgidstr.c_str())) {\n      ss << \"Invalid pgid specified\";\n      return;\n    }\n\n    PG *pg = service->osd->_lookup_lock_pg(pgid);\n    if (pg == nullptr) {\n      ss << \"Can't find pg \" << pgid;\n      return;\n    }\n\n    if (pg->is_primary()) {\n      pg->unreg_next_scrub();\n      const pg_pool_t *p = curmap->get_pg_pool(pgid.pool());\n      double pool_scrub_max_interval = 0;\n      p->opts.get(pool_opts_t::SCRUB_MAX_INTERVAL, &pool_scrub_max_interval);\n      double scrub_max_interval = pool_scrub_max_interval > 0 ?\n        pool_scrub_max_interval : g_conf->osd_scrub_max_interval;\n      // Instead of marking must_scrub force a schedule scrub\n      utime_t stamp = ceph_clock_now();\n      stamp -= scrub_max_interval;\n      stamp -=  100.0;  // push back last scrub more for good measure\n      pg->info.history.last_scrub_stamp = stamp;\n      pg->reg_next_scrub();\n      ss << \"ok\";\n    } else {\n      ss << \"Not primary\";\n    }\n    pg->unlock();\n    return;\n  }\n  if (command == \"injectfull\") {\n    int64_t count;\n    string type;\n    OSDService::s_names state;\n    cmd_getval(service->cct, cmdmap, \"type\", type, string(\"full\"));\n    cmd_getval(service->cct, cmdmap, \"count\", count, (int64_t)-1);\n    if (type == \"none\" || count == 0) {\n      type = \"none\";\n      count = 0;\n    }\n    state = service->get_full_state(type);\n    if (state == OSDService::s_names::INVALID) {\n      ss << \"Invalid type use (none, nearfull, backfillfull, full, failsafe)\";\n      return;\n    }\n    service->set_injectfull(state, count);\n    return;\n  }\n  ss << \"Internal error - command=\" << command;\n}\n\n// =========================================\nbool remove_dir(\n  CephContext *cct,\n  ObjectStore *store, SnapMapper *mapper,\n  OSDriver *osdriver,\n  ObjectStore::Sequencer *osr,\n  coll_t coll, DeletingStateRef dstate,\n  bool *finished,\n  ThreadPool::TPHandle &handle)\n{\n  vector<ghobject_t> olist;\n  int64_t num = 0;\n  ObjectStore::Transaction t;\n  ghobject_t next;\n  handle.reset_tp_timeout();\n  store->collection_list(\n    coll,\n    next,\n    ghobject_t::get_max(),\n    store->get_ideal_list_max(),\n    &olist,\n    &next);\n  generic_dout(10) << __func__ << \" \" << olist << dendl;\n  // default cont to true, this is safe because caller(OSD::RemoveWQ::_process()) \n  // will recheck the answer before it really goes on.\n  bool cont = true;\n  for (vector<ghobject_t>::iterator i = olist.begin();\n       i != olist.end();\n       ++i) {\n    if (i->is_pgmeta())\n      continue;\n    OSDriver::OSTransaction _t(osdriver->get_transaction(&t));\n    int r = mapper->remove_oid(i->hobj, &_t);\n    if (r != 0 && r != -ENOENT) {\n      ceph_abort();\n    }\n    t.remove(coll, *i);\n    if (++num >= cct->_conf->osd_target_transaction_size) {\n      C_SaferCond waiter;\n      store->queue_transaction(osr, std::move(t), &waiter);\n      cont = dstate->pause_clearing();\n      handle.suspend_tp_timeout();\n      waiter.wait();\n      handle.reset_tp_timeout();\n      if (cont)\n        cont = dstate->resume_clearing();\n      if (!cont)\n\treturn false;\n      t = ObjectStore::Transaction();\n      num = 0;\n    }\n  }\n  if (num) {\n    C_SaferCond waiter;\n    store->queue_transaction(osr, std::move(t), &waiter);\n    cont = dstate->pause_clearing();\n    handle.suspend_tp_timeout();\n    waiter.wait();\n    handle.reset_tp_timeout();\n    if (cont)\n      cont = dstate->resume_clearing();\n  }\n  // whether there are more objects to remove in the collection\n  *finished = next.is_max();\n  return cont;\n}\n\nvoid OSD::RemoveWQ::_process(\n  pair<PGRef, DeletingStateRef> item,\n  ThreadPool::TPHandle &handle)\n{\n  FUNCTRACE();\n  PGRef pg(item.first);\n  SnapMapper &mapper = pg->snap_mapper;\n  OSDriver &driver = pg->osdriver;\n  coll_t coll = coll_t(pg->info.pgid);\n  pg->osr->flush();\n  bool finished = false;\n\n  if (!item.second->start_or_resume_clearing())\n    return;\n\n  bool cont = remove_dir(\n    pg->cct, store, &mapper, &driver, pg->osr.get(), coll, item.second,\n    &finished, handle);\n  if (!cont)\n    return;\n  if (!finished) {\n    if (item.second->pause_clearing())\n      queue_front(item);\n    return;\n  }\n\n  if (!item.second->start_deleting())\n    return;\n\n  ObjectStore::Transaction t;\n  PGLog::clear_info_log(pg->info.pgid, &t);\n\n  if (cct->_conf->osd_inject_failure_on_pg_removal) {\n    generic_derr << \"osd_inject_failure_on_pg_removal\" << dendl;\n    _exit(1);\n  }\n  t.remove_collection(coll);\n\n  // We need the sequencer to stick around until the op is complete\n  store->queue_transaction(\n    pg->osr.get(),\n    std::move(t),\n    0, // onapplied\n    0, // oncommit\n    0, // onreadable sync\n    new ContainerContext<PGRef>(pg),\n    TrackedOpRef());\n\n  item.second->finish_deleting();\n}\n// =========================================\n\nvoid OSD::ms_handle_connect(Connection *con)\n{\n  dout(10) << __func__ << \" con \" << con << dendl;\n  if (con->get_peer_type() == CEPH_ENTITY_TYPE_MON) {\n    Mutex::Locker l(osd_lock);\n    if (is_stopping())\n      return;\n    dout(10) << __func__ << \" on mon\" << dendl;\n\n    if (is_preboot()) {\n      start_boot();\n    } else if (is_booting()) {\n      _send_boot();       // resend boot message\n    } else {\n      map_lock.get_read();\n      Mutex::Locker l2(mon_report_lock);\n\n      utime_t now = ceph_clock_now();\n      last_mon_report = now;\n\n      // resend everything, it's a new session\n      send_full_update();\n      send_alive();\n      service.requeue_pg_temp();\n      service.send_pg_temp();\n      requeue_failures();\n      send_failures();\n      if (osdmap->require_osd_release < CEPH_RELEASE_LUMINOUS) {\n\tsend_pg_stats(now);\n      }\n\n      map_lock.put_read();\n      if (is_active()) {\n\tsend_beacon(ceph::coarse_mono_clock::now());\n      }\n    }\n\n    // full map requests may happen while active or pre-boot\n    if (requested_full_first) {\n      rerequest_full_maps();\n    }\n  }\n}\n\nvoid OSD::ms_handle_fast_connect(Connection *con)\n{\n  if (con->get_peer_type() != CEPH_ENTITY_TYPE_MON &&\n      con->get_peer_type() != CEPH_ENTITY_TYPE_MGR) {\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (!s) {\n      s = new Session(cct);\n      con->set_priv(s->get());\n      s->con = con;\n      dout(10) << \" new session (outgoing) \" << s << \" con=\" << s->con\n          << \" addr=\" << s->con->get_peer_addr() << dendl;\n      // we don't connect to clients\n      assert(con->get_peer_type() == CEPH_ENTITY_TYPE_OSD);\n      s->entity_name.set_type(CEPH_ENTITY_TYPE_OSD);\n    }\n    s->put();\n  }\n}\n\nvoid OSD::ms_handle_fast_accept(Connection *con)\n{\n  if (con->get_peer_type() != CEPH_ENTITY_TYPE_MON &&\n      con->get_peer_type() != CEPH_ENTITY_TYPE_MGR) {\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (!s) {\n      s = new Session(cct);\n      con->set_priv(s->get());\n      s->con = con;\n      dout(10) << \"new session (incoming)\" << s << \" con=\" << con\n          << \" addr=\" << con->get_peer_addr()\n          << \" must have raced with connect\" << dendl;\n      assert(con->get_peer_type() == CEPH_ENTITY_TYPE_OSD);\n      s->entity_name.set_type(CEPH_ENTITY_TYPE_OSD);\n    }\n    s->put();\n  }\n}\n\nbool OSD::ms_handle_reset(Connection *con)\n{\n  Session *session = static_cast<Session*>(con->get_priv());\n  dout(2) << \"ms_handle_reset con \" << con << \" session \" << session << dendl;\n  if (!session)\n    return false;\n  session->wstate.reset(con);\n  session->con.reset(NULL);  // break con <-> session ref cycle\n  // note that we break session->con *before* the session_handle_reset\n  // cleanup below.  this avoids a race between us and\n  // PG::add_backoff, Session::check_backoff, etc.\n  session_handle_reset(session);\n  session->put();\n  return true;\n}\n\nbool OSD::ms_handle_refused(Connection *con)\n{\n  if (!cct->_conf->osd_fast_fail_on_connection_refused)\n    return false;\n\n  Session *session = static_cast<Session*>(con->get_priv());\n  dout(2) << \"ms_handle_refused con \" << con << \" session \" << session << dendl;\n  if (!session)\n    return false;\n  int type = con->get_peer_type();\n  // handle only OSD failures here\n  if (monc && (type == CEPH_ENTITY_TYPE_OSD)) {\n    OSDMapRef osdmap = get_osdmap();\n    if (osdmap) {\n      int id = osdmap->identify_osd_on_all_channels(con->get_peer_addr());\n      if (id >= 0 && osdmap->is_up(id)) {\n\t// I'm cheating mon heartbeat grace logic, because we know it's not going\n\t// to respawn alone. +1 so we won't hit any boundary case.\n\tmonc->send_mon_message(new MOSDFailure(monc->get_fsid(),\n\t\t\t\t\t\t  osdmap->get_inst(id),\n\t\t\t\t\t\t  cct->_conf->osd_heartbeat_grace + 1,\n\t\t\t\t\t\t  osdmap->get_epoch(),\n\t\t\t\t\t\t  MOSDFailure::FLAG_IMMEDIATE | MOSDFailure::FLAG_FAILED\n\t\t\t\t\t\t  ));\n      }\n    }\n  }\n  session->put();\n  return true;\n}\n\nstruct C_OSD_GetVersion : public Context {\n  OSD *osd;\n  uint64_t oldest, newest;\n  explicit C_OSD_GetVersion(OSD *o) : osd(o), oldest(0), newest(0) {}\n  void finish(int r) override {\n    if (r >= 0)\n      osd->_got_mon_epochs(oldest, newest);\n  }\n};\n\nvoid OSD::start_boot()\n{\n  if (!_is_healthy()) {\n    // if we are not healthy, do not mark ourselves up (yet)\n    dout(1) << \"not healthy; waiting to boot\" << dendl;\n    if (!is_waiting_for_healthy())\n      start_waiting_for_healthy();\n    // send pings sooner rather than later\n    heartbeat_kick();\n    return;\n  }\n  dout(1) << __func__ << dendl;\n  set_state(STATE_PREBOOT);\n  waiting_for_luminous_mons = false;\n  dout(10) << \"start_boot - have maps \" << superblock.oldest_map\n\t   << \"..\" << superblock.newest_map << dendl;\n  C_OSD_GetVersion *c = new C_OSD_GetVersion(this);\n  monc->get_version(\"osdmap\", &c->newest, &c->oldest, c);\n}\n\nvoid OSD::_got_mon_epochs(epoch_t oldest, epoch_t newest)\n{\n  Mutex::Locker l(osd_lock);\n  if (is_preboot()) {\n    _preboot(oldest, newest);\n  }\n}\n\nvoid OSD::_preboot(epoch_t oldest, epoch_t newest)\n{\n  assert(is_preboot());\n  dout(10) << __func__ << \" _preboot mon has osdmaps \"\n\t   << oldest << \"..\" << newest << dendl;\n\n  // ensure our local fullness awareness is accurate\n  heartbeat();\n\n  // if our map within recent history, try to add ourselves to the osdmap.\n  if (osdmap->get_epoch() == 0) {\n    derr << \"waiting for initial osdmap\" << dendl;\n  } else if (osdmap->is_destroyed(whoami)) {\n    derr << \"osdmap says I am destroyed\" << dendl;\n    // provide a small margin so we don't livelock seeing if we\n    // un-destroyed ourselves.\n    if (osdmap->get_epoch() > newest - 1) {\n      exit(0);\n    }\n  } else if (osdmap->test_flag(CEPH_OSDMAP_NOUP) || osdmap->is_noup(whoami)) {\n    derr << \"osdmap NOUP flag is set, waiting for it to clear\" << dendl;\n  } else if (!osdmap->test_flag(CEPH_OSDMAP_SORTBITWISE)) {\n    derr << \"osdmap SORTBITWISE OSDMap flag is NOT set; please set it\"\n\t << dendl;\n  } else if (osdmap->require_osd_release < CEPH_RELEASE_JEWEL) {\n    derr << \"osdmap REQUIRE_JEWEL OSDMap flag is NOT set; please set it\"\n\t << dendl;\n  } else if (!monc->monmap.get_required_features().contains_all(\n\t       ceph::features::mon::FEATURE_LUMINOUS)) {\n    derr << \"monmap REQUIRE_LUMINOUS is NOT set; must upgrade all monitors to \"\n\t << \"Luminous or later before Luminous OSDs will boot\" << dendl;\n    waiting_for_luminous_mons = true;\n  } else if (service.need_fullness_update()) {\n    derr << \"osdmap fullness state needs update\" << dendl;\n    send_full_update();\n  } else if (osdmap->get_epoch() >= oldest - 1 &&\n\t     osdmap->get_epoch() + cct->_conf->osd_map_message_max > newest) {\n    _send_boot();\n    return;\n  }\n\n  // get all the latest maps\n  if (osdmap->get_epoch() + 1 >= oldest)\n    osdmap_subscribe(osdmap->get_epoch() + 1, false);\n  else\n    osdmap_subscribe(oldest - 1, true);\n}\n\nvoid OSD::send_full_update()\n{\n  if (!service.need_fullness_update())\n    return;\n  unsigned state = 0;\n  if (service.is_full()) {\n    state = CEPH_OSD_FULL;\n  } else if (service.is_backfillfull()) {\n    state = CEPH_OSD_BACKFILLFULL;\n  } else if (service.is_nearfull()) {\n    state = CEPH_OSD_NEARFULL;\n  }\n  set<string> s;\n  OSDMap::calc_state_set(state, s);\n  dout(10) << __func__ << \" want state \" << s << dendl;\n  monc->send_mon_message(new MOSDFull(osdmap->get_epoch(), state));\n}\n\nvoid OSD::start_waiting_for_healthy()\n{\n  dout(1) << \"start_waiting_for_healthy\" << dendl;\n  set_state(STATE_WAITING_FOR_HEALTHY);\n  last_heartbeat_resample = utime_t();\n\n  // subscribe to osdmap updates, in case our peers really are known to be dead\n  osdmap_subscribe(osdmap->get_epoch() + 1, false);\n}\n\nbool OSD::_is_healthy()\n{\n  if (!cct->get_heartbeat_map()->is_healthy()) {\n    dout(1) << \"is_healthy false -- internal heartbeat failed\" << dendl;\n    return false;\n  }\n\n  if (is_waiting_for_healthy()) {\n    Mutex::Locker l(heartbeat_lock);\n    utime_t cutoff = ceph_clock_now();\n    cutoff -= cct->_conf->osd_heartbeat_grace;\n    int num = 0, up = 0;\n    for (map<int,HeartbeatInfo>::iterator p = heartbeat_peers.begin();\n\t p != heartbeat_peers.end();\n\t ++p) {\n      if (p->second.is_healthy(cutoff))\n\t++up;\n      ++num;\n    }\n    if ((float)up < (float)num * cct->_conf->osd_heartbeat_min_healthy_ratio) {\n      dout(1) << \"is_healthy false -- only \" << up << \"/\" << num << \" up peers (less than \"\n\t      << int(cct->_conf->osd_heartbeat_min_healthy_ratio * 100.0) << \"%)\" << dendl;\n      return false;\n    }\n  }\n\n  return true;\n}\n\nvoid OSD::_send_boot()\n{\n  dout(10) << \"_send_boot\" << dendl;\n  entity_addr_t cluster_addr = cluster_messenger->get_myaddr();\n  Connection *local_connection = cluster_messenger->get_loopback_connection().get();\n  if (cluster_addr.is_blank_ip()) {\n    int port = cluster_addr.get_port();\n    cluster_addr = client_messenger->get_myaddr();\n    cluster_addr.set_port(port);\n    cluster_messenger->set_addr_unknowns(cluster_addr);\n    dout(10) << \" assuming cluster_addr ip matches client_addr\" << dendl;\n  } else {\n    Session *s = static_cast<Session*>(local_connection->get_priv());\n    if (s)\n      s->put();\n    else\n      cluster_messenger->ms_deliver_handle_fast_connect(local_connection);\n  }\n\n  entity_addr_t hb_back_addr = hb_back_server_messenger->get_myaddr();\n  local_connection = hb_back_server_messenger->get_loopback_connection().get();\n  if (hb_back_addr.is_blank_ip()) {\n    int port = hb_back_addr.get_port();\n    hb_back_addr = cluster_addr;\n    hb_back_addr.set_port(port);\n    hb_back_server_messenger->set_addr_unknowns(hb_back_addr);\n    dout(10) << \" assuming hb_back_addr ip matches cluster_addr\" << dendl;\n  } else {\n    Session *s = static_cast<Session*>(local_connection->get_priv());\n    if (s)\n      s->put();\n    else\n      hb_back_server_messenger->ms_deliver_handle_fast_connect(local_connection);\n  }\n\n  entity_addr_t hb_front_addr = hb_front_server_messenger->get_myaddr();\n  local_connection = hb_front_server_messenger->get_loopback_connection().get();\n  if (hb_front_addr.is_blank_ip()) {\n    int port = hb_front_addr.get_port();\n    hb_front_addr = client_messenger->get_myaddr();\n    hb_front_addr.set_port(port);\n    hb_front_server_messenger->set_addr_unknowns(hb_front_addr);\n    dout(10) << \" assuming hb_front_addr ip matches client_addr\" << dendl;\n  } else {\n    Session *s = static_cast<Session*>(local_connection->get_priv());\n    if (s)\n      s->put();\n    else\n      hb_front_server_messenger->ms_deliver_handle_fast_connect(local_connection);\n  }\n\n  MOSDBoot *mboot = new MOSDBoot(superblock, get_osdmap_epoch(), service.get_boot_epoch(),\n                                 hb_back_addr, hb_front_addr, cluster_addr,\n\t\t\t\t CEPH_FEATURES_ALL);\n  dout(10) << \" client_addr \" << client_messenger->get_myaddr()\n\t   << \", cluster_addr \" << cluster_addr\n\t   << \", hb_back_addr \" << hb_back_addr\n\t   << \", hb_front_addr \" << hb_front_addr\n\t   << dendl;\n  _collect_metadata(&mboot->metadata);\n  monc->send_mon_message(mboot);\n  set_state(STATE_BOOTING);\n}\n\nvoid OSD::_collect_metadata(map<string,string> *pm)\n{\n  // config info\n  (*pm)[\"osd_data\"] = dev_path;\n  if (store->get_type() == \"filestore\") {\n    // not applicable for bluestore\n    (*pm)[\"osd_journal\"] = journal_path;\n  }\n  (*pm)[\"front_addr\"] = stringify(client_messenger->get_myaddr());\n  (*pm)[\"back_addr\"] = stringify(cluster_messenger->get_myaddr());\n  (*pm)[\"hb_front_addr\"] = stringify(hb_front_server_messenger->get_myaddr());\n  (*pm)[\"hb_back_addr\"] = stringify(hb_back_server_messenger->get_myaddr());\n\n  // backend\n  (*pm)[\"osd_objectstore\"] = store->get_type();\n  (*pm)[\"rotational\"] = store_is_rotational ? \"1\" : \"0\";\n  (*pm)[\"journal_rotational\"] = journal_is_rotational ? \"1\" : \"0\";\n  (*pm)[\"default_device_class\"] = store->get_default_device_class();\n  store->collect_metadata(pm);\n\n  collect_sys_info(pm, cct);\n\n  std::string front_iface, back_iface;\n  /*\n  pick_iface(cct,\n      CEPH_PICK_ADDRESS_PUBLIC | CEPH_PICK_ADDRESS_CLUSTER,\n      &front_iface, &back_iface);\n      */\n  (*pm)[\"front_iface\"] = pick_iface(cct,\n      client_messenger->get_myaddr().get_sockaddr_storage());\n  (*pm)[\"back_iface\"] = pick_iface(cct,\n      cluster_messenger->get_myaddr().get_sockaddr_storage());\n\n  dout(10) << __func__ << \" \" << *pm << dendl;\n}\n\nvoid OSD::queue_want_up_thru(epoch_t want)\n{\n  map_lock.get_read();\n  epoch_t cur = osdmap->get_up_thru(whoami);\n  Mutex::Locker l(mon_report_lock);\n  if (want > up_thru_wanted) {\n    dout(10) << \"queue_want_up_thru now \" << want << \" (was \" << up_thru_wanted << \")\"\n\t     << \", currently \" << cur\n\t     << dendl;\n    up_thru_wanted = want;\n    send_alive();\n  } else {\n    dout(10) << \"queue_want_up_thru want \" << want << \" <= queued \" << up_thru_wanted\n\t     << \", currently \" << cur\n\t     << dendl;\n  }\n  map_lock.put_read();\n}\n\nvoid OSD::send_alive()\n{\n  assert(mon_report_lock.is_locked());\n  if (!osdmap->exists(whoami))\n    return;\n  epoch_t up_thru = osdmap->get_up_thru(whoami);\n  dout(10) << \"send_alive up_thru currently \" << up_thru << \" want \" << up_thru_wanted << dendl;\n  if (up_thru_wanted > up_thru) {\n    dout(10) << \"send_alive want \" << up_thru_wanted << dendl;\n    monc->send_mon_message(new MOSDAlive(osdmap->get_epoch(), up_thru_wanted));\n  }\n}\n\nvoid OSD::request_full_map(epoch_t first, epoch_t last)\n{\n  dout(10) << __func__ << \" \" << first << \"..\" << last\n\t   << \", previously requested \"\n\t   << requested_full_first << \"..\" << requested_full_last << dendl;\n  assert(osd_lock.is_locked());\n  assert(first > 0 && last > 0);\n  assert(first <= last);\n  assert(first >= requested_full_first);  // we shouldn't ever ask for older maps\n  if (requested_full_first == 0) {\n    // first request\n    requested_full_first = first;\n    requested_full_last = last;\n  } else if (last <= requested_full_last) {\n    // dup\n    return;\n  } else {\n    // additional request\n    first = requested_full_last + 1;\n    requested_full_last = last;\n  }\n  MMonGetOSDMap *req = new MMonGetOSDMap;\n  req->request_full(first, last);\n  monc->send_mon_message(req);\n}\n\nvoid OSD::got_full_map(epoch_t e)\n{\n  assert(requested_full_first <= requested_full_last);\n  assert(osd_lock.is_locked());\n  if (requested_full_first == 0) {\n    dout(20) << __func__ << \" \" << e << \", nothing requested\" << dendl;\n    return;\n  }\n  if (e < requested_full_first) {\n    dout(10) << __func__ << \" \" << e << \", requested \" << requested_full_first\n\t     << \"..\" << requested_full_last\n\t     << \", ignoring\" << dendl;\n    return;\n  }\n  if (e >= requested_full_last) {\n    dout(10) << __func__ << \" \" << e << \", requested \" << requested_full_first\n\t     << \"..\" << requested_full_last << \", resetting\" << dendl;\n    requested_full_first = requested_full_last = 0;\n    return;\n  }\n  \n  requested_full_first = e + 1;\n\n  dout(10) << __func__ << \" \" << e << \", requested \" << requested_full_first\n           << \"..\" << requested_full_last\n           << \", still need more\" << dendl;\n}\n\nvoid OSD::requeue_failures()\n{\n  Mutex::Locker l(heartbeat_lock);\n  unsigned old_queue = failure_queue.size();\n  unsigned old_pending = failure_pending.size();\n  for (map<int,pair<utime_t,entity_inst_t> >::iterator p =\n\t failure_pending.begin();\n       p != failure_pending.end(); ) {\n    failure_queue[p->first] = p->second.first;\n    failure_pending.erase(p++);\n  }\n  dout(10) << __func__ << \" \" << old_queue << \" + \" << old_pending << \" -> \"\n\t   << failure_queue.size() << dendl;\n}\n\nvoid OSD::send_failures()\n{\n  assert(map_lock.is_locked());\n  assert(mon_report_lock.is_locked());\n  Mutex::Locker l(heartbeat_lock);\n  utime_t now = ceph_clock_now();\n  while (!failure_queue.empty()) {\n    int osd = failure_queue.begin()->first;\n    if (!failure_pending.count(osd)) {\n      entity_inst_t i = osdmap->get_inst(osd);\n      int failed_for = (int)(double)(now - failure_queue.begin()->second);\n      monc->send_mon_message(new MOSDFailure(monc->get_fsid(), i, failed_for,\n\t\t\t\t\t     osdmap->get_epoch()));\n      failure_pending[osd] = make_pair(failure_queue.begin()->second, i);\n    }\n    failure_queue.erase(osd);\n  }\n}\n\nvoid OSD::send_still_alive(epoch_t epoch, const entity_inst_t &i)\n{\n  MOSDFailure *m = new MOSDFailure(monc->get_fsid(), i, 0, epoch, MOSDFailure::FLAG_ALIVE);\n  monc->send_mon_message(m);\n}\n\nvoid OSD::send_pg_stats(const utime_t &now)\n{\n  assert(map_lock.is_locked());\n  assert(osdmap->require_osd_release < CEPH_RELEASE_LUMINOUS);\n  dout(20) << \"send_pg_stats\" << dendl;\n\n  osd_stat_t cur_stat = service.get_osd_stat();\n\n  cur_stat.os_perf_stat = store->get_cur_stats();\n\n  pg_stat_queue_lock.Lock();\n\n  if (osd_stat_updated || !pg_stat_queue.empty()) {\n    last_pg_stats_sent = now;\n    osd_stat_updated = false;\n\n    dout(10) << \"send_pg_stats - \" << pg_stat_queue.size() << \" pgs updated\" << dendl;\n\n    utime_t had_for(now);\n    had_for -= had_map_since;\n\n    MPGStats *m = new MPGStats(monc->get_fsid(), osdmap->get_epoch(), had_for);\n\n    uint64_t tid = ++pg_stat_tid;\n    m->set_tid(tid);\n    m->osd_stat = cur_stat;\n\n    xlist<PG*>::iterator p = pg_stat_queue.begin();\n    while (!p.end()) {\n      PG *pg = *p;\n      ++p;\n      if (!pg->is_primary()) {  // we hold map_lock; role is stable.\n\tpg->stat_queue_item.remove_myself();\n\tpg->put(\"pg_stat_queue\");\n\tcontinue;\n      }\n      pg->pg_stats_publish_lock.Lock();\n      if (pg->pg_stats_publish_valid) {\n\tm->pg_stat[pg->info.pgid.pgid] = pg->pg_stats_publish;\n\tdout(25) << \" sending \" << pg->info.pgid << \" \" << pg->pg_stats_publish.reported_epoch << \":\"\n\t\t << pg->pg_stats_publish.reported_seq << dendl;\n      } else {\n\tdout(25) << \" NOT sending \" << pg->info.pgid << \" \" << pg->pg_stats_publish.reported_epoch << \":\"\n\t\t << pg->pg_stats_publish.reported_seq << \", not valid\" << dendl;\n      }\n      pg->pg_stats_publish_lock.Unlock();\n    }\n\n    if (last_pg_stats_ack == utime_t() || !outstanding_pg_stats.empty()) {\n      last_pg_stats_ack = ceph_clock_now();\n    }\n    outstanding_pg_stats.insert(tid);\n    dout(20) << __func__ << \"  updates pending: \" << outstanding_pg_stats << dendl;\n\n    monc->send_mon_message(m);\n  }\n\n  pg_stat_queue_lock.Unlock();\n}\n\nvoid OSD::handle_pg_stats_ack(MPGStatsAck *ack)\n{\n  dout(10) << \"handle_pg_stats_ack \" << dendl;\n\n  if (!require_mon_peer(ack)) {\n    ack->put();\n    return;\n  }\n\n  // NOTE: we may get replies from a previous mon even while\n  // outstanding_pg_stats is empty if reconnecting races with replies\n  // in flight.\n\n  pg_stat_queue_lock.Lock();\n\n  last_pg_stats_ack = ceph_clock_now();\n\n  // decay timeout slowly (analogous to TCP)\n  stats_ack_timeout =\n    MAX(cct->_conf->osd_mon_ack_timeout,\n\tstats_ack_timeout * cct->_conf->osd_stats_ack_timeout_decay);\n  dout(20) << __func__ << \"  timeout now \" << stats_ack_timeout << dendl;\n\n  if (ack->get_tid() > pg_stat_tid_flushed) {\n    pg_stat_tid_flushed = ack->get_tid();\n    pg_stat_queue_cond.Signal();\n  }\n\n  xlist<PG*>::iterator p = pg_stat_queue.begin();\n  while (!p.end()) {\n    PG *pg = *p;\n    PGRef _pg(pg);\n    ++p;\n\n    auto acked = ack->pg_stat.find(pg->info.pgid.pgid);\n    if (acked != ack->pg_stat.end()) {\n      pg->pg_stats_publish_lock.Lock();\n      if (acked->second.first == pg->pg_stats_publish.reported_seq &&\n\t  acked->second.second == pg->pg_stats_publish.reported_epoch) {\n\tdout(25) << \" ack on \" << pg->info.pgid << \" \" << pg->pg_stats_publish.reported_epoch\n\t\t << \":\" << pg->pg_stats_publish.reported_seq << dendl;\n\tpg->stat_queue_item.remove_myself();\n\tpg->put(\"pg_stat_queue\");\n      } else {\n\tdout(25) << \" still pending \" << pg->info.pgid << \" \" << pg->pg_stats_publish.reported_epoch\n\t\t << \":\" << pg->pg_stats_publish.reported_seq << \" > acked \"\n\t\t << acked->second << dendl;\n      }\n      pg->pg_stats_publish_lock.Unlock();\n    } else {\n      dout(30) << \" still pending \" << pg->info.pgid << \" \" << pg->pg_stats_publish.reported_epoch\n\t       << \":\" << pg->pg_stats_publish.reported_seq << dendl;\n    }\n  }\n\n  outstanding_pg_stats.erase(ack->get_tid());\n  dout(20) << __func__ << \"  still pending: \" << outstanding_pg_stats << dendl;\n\n  pg_stat_queue_lock.Unlock();\n\n  ack->put();\n}\n\nvoid OSD::flush_pg_stats()\n{\n  dout(10) << \"flush_pg_stats\" << dendl;\n  osd_lock.Unlock();\n  utime_t now = ceph_clock_now();\n  map_lock.get_read();\n  mon_report_lock.Lock();\n  send_pg_stats(now);\n  mon_report_lock.Unlock();\n  map_lock.put_read();\n\n\n  pg_stat_queue_lock.Lock();\n  uint64_t tid = pg_stat_tid;\n  dout(10) << \"flush_pg_stats waiting for stats tid \" << tid << \" to flush\" << dendl;\n  while (tid > pg_stat_tid_flushed)\n    pg_stat_queue_cond.Wait(pg_stat_queue_lock);\n  dout(10) << \"flush_pg_stats finished waiting for stats tid \" << tid << \" to flush\" << dendl;\n  pg_stat_queue_lock.Unlock();\n\n  osd_lock.Lock();\n}\n\nvoid OSD::send_beacon(const ceph::coarse_mono_clock::time_point& now)\n{\n  const auto& monmap = monc->monmap;\n  // send beacon to mon even if we are just connected, and the monmap is not\n  // initialized yet by then.\n  if (monmap.epoch > 0 &&\n      monmap.get_required_features().contains_all(\n        ceph::features::mon::FEATURE_LUMINOUS)) {\n    dout(20) << __func__ << \" sending\" << dendl;\n    MOSDBeacon* beacon = nullptr;\n    {\n      Mutex::Locker l{min_last_epoch_clean_lock};\n      beacon = new MOSDBeacon(osdmap->get_epoch(), min_last_epoch_clean);\n      std::swap(beacon->pgs, min_last_epoch_clean_pgs);\n      last_sent_beacon = now;\n    }\n    monc->send_mon_message(beacon);\n  } else {\n    dout(20) << __func__ << \" not sending\" << dendl;\n  }\n}\n\nvoid OSD::handle_command(MMonCommand *m)\n{\n  if (!require_mon_peer(m)) {\n    m->put();\n    return;\n  }\n\n  Command *c = new Command(m->cmd, m->get_tid(), m->get_data(), NULL);\n  command_wq.queue(c);\n  m->put();\n}\n\nvoid OSD::handle_command(MCommand *m)\n{\n  ConnectionRef con = m->get_connection();\n  Session *session = static_cast<Session *>(con->get_priv());\n  if (!session) {\n    con->send_message(new MCommandReply(m, -EPERM));\n    m->put();\n    return;\n  }\n\n  OSDCap& caps = session->caps;\n  session->put();\n\n  if (!caps.allow_all() || m->get_source().is_mon()) {\n    con->send_message(new MCommandReply(m, -EPERM));\n    m->put();\n    return;\n  }\n\n  Command *c = new Command(m->cmd, m->get_tid(), m->get_data(), con.get());\n  command_wq.queue(c);\n\n  m->put();\n}\n\nstruct OSDCommand {\n  string cmdstring;\n  string helpstring;\n  string module;\n  string perm;\n  string availability;\n} osd_commands[] = {\n\n#define COMMAND(parsesig, helptext, module, perm, availability) \\\n  {parsesig, helptext, module, perm, availability},\n\n// yes, these are really pg commands, but there's a limit to how\n// much work it's worth.  The OSD returns all of them.  Make this\n// form (pg <pgid> <cmd>) valid only for the cli.\n// Rest uses \"tell <pgid> <cmd>\"\n\nCOMMAND(\"pg \" \\\n\t\"name=pgid,type=CephPgid \" \\\n\t\"name=cmd,type=CephChoices,strings=query\", \\\n\t\"show details of a specific pg\", \"osd\", \"r\", \"cli\")\nCOMMAND(\"pg \" \\\n\t\"name=pgid,type=CephPgid \" \\\n\t\"name=cmd,type=CephChoices,strings=mark_unfound_lost \" \\\n\t\"name=mulcmd,type=CephChoices,strings=revert|delete\", \\\n\t\"mark all unfound objects in this pg as lost, either removing or reverting to a prior version if one is available\",\n\t\"osd\", \"rw\", \"cli\")\nCOMMAND(\"pg \" \\\n\t\"name=pgid,type=CephPgid \" \\\n\t\"name=cmd,type=CephChoices,strings=list_missing \" \\\n\t\"name=offset,type=CephString,req=false\",\n\t\"list missing objects on this pg, perhaps starting at an offset given in JSON\",\n\t\"osd\", \"r\", \"cli\")\n\n// new form: tell <pgid> <cmd> for both cli and rest\n\nCOMMAND(\"query\",\n\t\"show details of a specific pg\", \"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"mark_unfound_lost \" \\\n\t\"name=mulcmd,type=CephChoices,strings=revert|delete\", \\\n\t\"mark all unfound objects in this pg as lost, either removing or reverting to a prior version if one is available\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"list_missing \" \\\n\t\"name=offset,type=CephString,req=false\",\n\t\"list missing objects on this pg, perhaps starting at an offset given in JSON\",\n\t\"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"perf histogram dump \"\n        \"name=logger,type=CephString,req=false \"\n        \"name=counter,type=CephString,req=false\",\n\t\"Get histogram data\",\n\t\"osd\", \"r\", \"cli,rest\")\n\n// tell <osd.n> commands.  Validation of osd.n must be special-cased in client\nCOMMAND(\"version\", \"report version of OSD\", \"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"get_command_descriptions\", \"list commands descriptions\", \"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"injectargs \" \\\n\t\"name=injected_args,type=CephString,n=N\",\n\t\"inject configuration arguments into running OSD\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"config set \" \\\n\t\"name=key,type=CephString name=value,type=CephString\",\n\t\"Set a configuration option at runtime (not persistent)\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"cluster_log \" \\\n\t\"name=level,type=CephChoices,strings=error,warning,info,debug \" \\\n\t\"name=message,type=CephString,n=N\",\n\t\"log a message to the cluster log\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"bench \" \\\n\t\"name=count,type=CephInt,req=false \" \\\n\t\"name=size,type=CephInt,req=false \" \\\n\t\"name=object_size,type=CephInt,req=false \" \\\n\t\"name=object_num,type=CephInt,req=false \", \\\n\t\"OSD benchmark: write <count> <size>-byte objects, \" \\\n\t\"(default 1G size 4MB). Results in log.\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"flush_pg_stats\", \"flush pg stats\", \"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"heap \" \\\n\t\"name=heapcmd,type=CephChoices,strings=dump|start_profiler|stop_profiler|release|stats\", \\\n\t\"show heap usage info (available only if compiled with tcmalloc)\", \\\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"debug dump_missing \" \\\n\t\"name=filename,type=CephFilepath\",\n\t\"dump missing objects to a named file\", \"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"debug kick_recovery_wq \" \\\n\t\"name=delay,type=CephInt,range=0\",\n\t\"set osd_recovery_delay_start to <val>\", \"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"cpu_profiler \" \\\n\t\"name=arg,type=CephChoices,strings=status|flush\",\n\t\"run cpu profiling on daemon\", \"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"dump_pg_recovery_stats\", \"dump pg recovery statistics\",\n\t\"osd\", \"r\", \"cli,rest\")\nCOMMAND(\"reset_pg_recovery_stats\", \"reset pg recovery statistics\",\n\t\"osd\", \"rw\", \"cli,rest\")\nCOMMAND(\"compact\",\n        \"compact object store's omap. \"\n        \"WARNING: Compaction probably slows your requests\",\n        \"osd\", \"rw\", \"cli,rest\")\n};\n\nvoid OSD::do_command(Connection *con, ceph_tid_t tid, vector<string>& cmd, bufferlist& data)\n{\n  int r = 0;\n  stringstream ss, ds;\n  string rs;\n  bufferlist odata;\n\n  dout(20) << \"do_command tid \" << tid << \" \" << cmd << dendl;\n\n  map<string, cmd_vartype> cmdmap;\n  string prefix;\n  string format;\n  string pgidstr;\n  boost::scoped_ptr<Formatter> f;\n\n  if (cmd.empty()) {\n    ss << \"no command given\";\n    goto out;\n  }\n\n  if (!cmdmap_from_json(cmd, &cmdmap, ss)) {\n    r = -EINVAL;\n    goto out;\n  }\n\n  cmd_getval(cct, cmdmap, \"prefix\", prefix);\n\n  if (prefix == \"get_command_descriptions\") {\n    int cmdnum = 0;\n    JSONFormatter *f = new JSONFormatter();\n    f->open_object_section(\"command_descriptions\");\n    for (OSDCommand *cp = osd_commands;\n\t cp < &osd_commands[ARRAY_SIZE(osd_commands)]; cp++) {\n\n      ostringstream secname;\n      secname << \"cmd\" << setfill('0') << std::setw(3) << cmdnum;\n      dump_cmddesc_to_json(f, secname.str(), cp->cmdstring, cp->helpstring,\n\t\t\t   cp->module, cp->perm, cp->availability, 0);\n      cmdnum++;\n    }\n    f->close_section();\t// command_descriptions\n\n    f->flush(ds);\n    delete f;\n    goto out;\n  }\n\n  cmd_getval(cct, cmdmap, \"format\", format);\n  f.reset(Formatter::create(format));\n\n  if (prefix == \"version\") {\n    if (f) {\n      f->open_object_section(\"version\");\n      f->dump_string(\"version\", pretty_version_to_str());\n      f->close_section();\n      f->flush(ds);\n    } else {\n      ds << pretty_version_to_str();\n    }\n    goto out;\n  }\n  else if (prefix == \"injectargs\") {\n    vector<string> argsvec;\n    cmd_getval(cct, cmdmap, \"injected_args\", argsvec);\n\n    if (argsvec.empty()) {\n      r = -EINVAL;\n      ss << \"ignoring empty injectargs\";\n      goto out;\n    }\n    string args = argsvec.front();\n    for (vector<string>::iterator a = ++argsvec.begin(); a != argsvec.end(); ++a)\n      args += \" \" + *a;\n    osd_lock.Unlock();\n    r = cct->_conf->injectargs(args, &ss);\n    osd_lock.Lock();\n  }\n  else if (prefix == \"config set\") {\n    std::string key;\n    std::string val;\n    cmd_getval(cct, cmdmap, \"key\", key);\n    cmd_getval(cct, cmdmap, \"value\", val);\n    osd_lock.Unlock();\n    r = cct->_conf->set_val(key, val, true, &ss);\n    if (r == 0) {\n      cct->_conf->apply_changes(nullptr);\n    }\n    osd_lock.Lock();\n  }\n  else if (prefix == \"cluster_log\") {\n    vector<string> msg;\n    cmd_getval(cct, cmdmap, \"message\", msg);\n    if (msg.empty()) {\n      r = -EINVAL;\n      ss << \"ignoring empty log message\";\n      goto out;\n    }\n    string message = msg.front();\n    for (vector<string>::iterator a = ++msg.begin(); a != msg.end(); ++a)\n      message += \" \" + *a;\n    string lvl;\n    cmd_getval(cct, cmdmap, \"level\", lvl);\n    clog_type level = string_to_clog_type(lvl);\n    if (level < 0) {\n      r = -EINVAL;\n      ss << \"unknown level '\" << lvl << \"'\";\n      goto out;\n    }\n    clog->do_log(level, message);\n  }\n\n  // either 'pg <pgid> <command>' or\n  // 'tell <pgid>' (which comes in without any of that prefix)?\n\n  else if (prefix == \"pg\" ||\n\t    prefix == \"query\" ||\n\t    prefix == \"mark_unfound_lost\" ||\n\t    prefix == \"list_missing\"\n\t   ) {\n    pg_t pgid;\n\n    if (!cmd_getval(cct, cmdmap, \"pgid\", pgidstr)) {\n      ss << \"no pgid specified\";\n      r = -EINVAL;\n    } else if (!pgid.parse(pgidstr.c_str())) {\n      ss << \"couldn't parse pgid '\" << pgidstr << \"'\";\n      r = -EINVAL;\n    } else {\n      spg_t pcand;\n      PG *pg = nullptr;\n      if (osdmap->get_primary_shard(pgid, &pcand) &&\n\t  (pg = _lookup_lock_pg(pcand))) {\n\tif (pg->is_primary()) {\n\t  // simulate pg <pgid> cmd= for pg->do-command\n\t  if (prefix != \"pg\")\n\t    cmd_putval(cct, cmdmap, \"cmd\", prefix);\n\t  r = pg->do_command(cmdmap, ss, data, odata, con, tid);\n\t  if (r == -EAGAIN) {\n\t    pg->unlock();\n\t    // don't reply, pg will do so async\n\t    return;\n\t  }\n\t} else {\n\t  ss << \"not primary for pgid \" << pgid;\n\n\t  // send them the latest diff to ensure they realize the mapping\n\t  // has changed.\n\t  service.send_incremental_map(osdmap->get_epoch() - 1, con, osdmap);\n\n\t  // do not reply; they will get newer maps and realize they\n\t  // need to resend.\n\t  pg->unlock();\n\t  return;\n\t}\n\tpg->unlock();\n      } else {\n\tss << \"i don't have pgid \" << pgid;\n\tr = -ENOENT;\n      }\n    }\n  }\n\n  else if (prefix == \"bench\") {\n    int64_t count;\n    int64_t bsize;\n    int64_t osize, onum;\n    // default count 1G, size 4MB\n    cmd_getval(cct, cmdmap, \"count\", count, (int64_t)1 << 30);\n    cmd_getval(cct, cmdmap, \"size\", bsize, (int64_t)4 << 20);\n    cmd_getval(cct, cmdmap, \"object_size\", osize, (int64_t)0);\n    cmd_getval(cct, cmdmap, \"object_num\", onum, (int64_t)0);\n\n    ceph::shared_ptr<ObjectStore::Sequencer> osr (std::make_shared<\n                                        ObjectStore::Sequencer>(\"bench\"));\n\n    uint32_t duration = cct->_conf->osd_bench_duration;\n\n    if (bsize > (int64_t) cct->_conf->osd_bench_max_block_size) {\n      // let us limit the block size because the next checks rely on it\n      // having a sane value.  If we allow any block size to be set things\n      // can still go sideways.\n      ss << \"block 'size' values are capped at \"\n         << prettybyte_t(cct->_conf->osd_bench_max_block_size) << \". If you wish to use\"\n         << \" a higher value, please adjust 'osd_bench_max_block_size'\";\n      r = -EINVAL;\n      goto out;\n    } else if (bsize < (int64_t) (1 << 20)) {\n      // entering the realm of small block sizes.\n      // limit the count to a sane value, assuming a configurable amount of\n      // IOPS and duration, so that the OSD doesn't get hung up on this,\n      // preventing timeouts from going off\n      int64_t max_count =\n        bsize * duration * cct->_conf->osd_bench_small_size_max_iops;\n      if (count > max_count) {\n        ss << \"'count' values greater than \" << max_count\n           << \" for a block size of \" << prettybyte_t(bsize) << \", assuming \"\n           << cct->_conf->osd_bench_small_size_max_iops << \" IOPS,\"\n           << \" for \" << duration << \" seconds,\"\n           << \" can cause ill effects on osd. \"\n           << \" Please adjust 'osd_bench_small_size_max_iops' with a higher\"\n           << \" value if you wish to use a higher 'count'.\";\n        r = -EINVAL;\n        goto out;\n      }\n    } else {\n      // 1MB block sizes are big enough so that we get more stuff done.\n      // However, to avoid the osd from getting hung on this and having\n      // timers being triggered, we are going to limit the count assuming\n      // a configurable throughput and duration.\n      // NOTE: max_count is the total amount of bytes that we believe we\n      //       will be able to write during 'duration' for the given\n      //       throughput.  The block size hardly impacts this unless it's\n      //       way too big.  Given we already check how big the block size\n      //       is, it's safe to assume everything will check out.\n      int64_t max_count =\n        cct->_conf->osd_bench_large_size_max_throughput * duration;\n      if (count > max_count) {\n        ss << \"'count' values greater than \" << max_count\n           << \" for a block size of \" << prettybyte_t(bsize) << \", assuming \"\n           << prettybyte_t(cct->_conf->osd_bench_large_size_max_throughput) << \"/s,\"\n           << \" for \" << duration << \" seconds,\"\n           << \" can cause ill effects on osd. \"\n           << \" Please adjust 'osd_bench_large_size_max_throughput'\"\n           << \" with a higher value if you wish to use a higher 'count'.\";\n        r = -EINVAL;\n        goto out;\n      }\n    }\n\n    if (osize && bsize > osize)\n      bsize = osize;\n\n    dout(1) << \" bench count \" << count\n            << \" bsize \" << prettybyte_t(bsize) << dendl;\n\n    ObjectStore::Transaction cleanupt;\n\n    if (osize && onum) {\n      bufferlist bl;\n      bufferptr bp(osize);\n      bp.zero();\n      bl.push_back(std::move(bp));\n      bl.rebuild_page_aligned();\n      for (int i=0; i<onum; ++i) {\n\tchar nm[30];\n\tsnprintf(nm, sizeof(nm), \"disk_bw_test_%d\", i);\n\tobject_t oid(nm);\n\thobject_t soid(sobject_t(oid, 0));\n\tObjectStore::Transaction t;\n\tt.write(coll_t(), ghobject_t(soid), 0, osize, bl);\n\tstore->queue_transaction(osr.get(), std::move(t), NULL);\n\tcleanupt.remove(coll_t(), ghobject_t(soid));\n      }\n    }\n\n    bufferlist bl;\n    bufferptr bp(bsize);\n    bp.zero();\n    bl.push_back(std::move(bp));\n    bl.rebuild_page_aligned();\n\n    {\n      C_SaferCond waiter;\n      if (!osr->flush_commit(&waiter)) {\n\twaiter.wait();\n      }\n    }\n\n    utime_t start = ceph_clock_now();\n    for (int64_t pos = 0; pos < count; pos += bsize) {\n      char nm[30];\n      unsigned offset = 0;\n      if (onum && osize) {\n\tsnprintf(nm, sizeof(nm), \"disk_bw_test_%d\", (int)(rand() % onum));\n\toffset = rand() % (osize / bsize) * bsize;\n      } else {\n\tsnprintf(nm, sizeof(nm), \"disk_bw_test_%lld\", (long long)pos);\n      }\n      object_t oid(nm);\n      hobject_t soid(sobject_t(oid, 0));\n      ObjectStore::Transaction t;\n      t.write(coll_t::meta(), ghobject_t(soid), offset, bsize, bl);\n      store->queue_transaction(osr.get(), std::move(t), NULL);\n      if (!onum || !osize)\n\tcleanupt.remove(coll_t::meta(), ghobject_t(soid));\n    }\n\n    {\n      C_SaferCond waiter;\n      if (!osr->flush_commit(&waiter)) {\n\twaiter.wait();\n      }\n    }\n    utime_t end = ceph_clock_now();\n\n    // clean up\n    store->queue_transaction(osr.get(), std::move(cleanupt), NULL);\n    {\n      C_SaferCond waiter;\n      if (!osr->flush_commit(&waiter)) {\n\twaiter.wait();\n      }\n    }\n\n    uint64_t rate = (double)count / (end - start);\n    if (f) {\n      f->open_object_section(\"osd_bench_results\");\n      f->dump_int(\"bytes_written\", count);\n      f->dump_int(\"blocksize\", bsize);\n      f->dump_unsigned(\"bytes_per_sec\", rate);\n      f->close_section();\n      f->flush(ss);\n    } else {\n      ss << \"bench: wrote \" << prettybyte_t(count)\n\t << \" in blocks of \" << prettybyte_t(bsize) << \" in \"\n\t << (end-start) << \" sec at \" << prettybyte_t(rate) << \"/sec\";\n    }\n  }\n\n  else if (prefix == \"flush_pg_stats\") {\n    if (osdmap->require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n      mgrc.send_pgstats();\n      ds << service.get_osd_stat_seq() << \"\\n\";\n    } else {\n      flush_pg_stats();\n    }\n  }\n\n  else if (prefix == \"heap\") {\n    r = ceph::osd_cmds::heap(*cct, cmdmap, *f, ds);\n  }\n\n  else if (prefix == \"debug dump_missing\") {\n    string file_name;\n    cmd_getval(cct, cmdmap, \"filename\", file_name);\n    std::ofstream fout(file_name.c_str());\n    if (!fout.is_open()) {\n\tss << \"failed to open file '\" << file_name << \"'\";\n\tr = -EINVAL;\n\tgoto out;\n    }\n\n    fout << \"*** osd \" << whoami << \": dump_missing ***\" << std::endl;\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t, PG*>::const_iterator pg_map_e = pg_map.begin();\n\t pg_map_e != pg_map.end(); ++pg_map_e) {\n      PG *pg = pg_map_e->second;\n      pg->lock();\n\n      fout << *pg << std::endl;\n      std::map<hobject_t, pg_missing_item>::const_iterator mend =\n\tpg->pg_log.get_missing().get_items().end();\n      std::map<hobject_t, pg_missing_item>::const_iterator mi =\n\tpg->pg_log.get_missing().get_items().begin();\n      for (; mi != mend; ++mi) {\n\tfout << mi->first << \" -> \" << mi->second << std::endl;\n\tif (!pg->missing_loc.needs_recovery(mi->first))\n\t  continue;\n\tif (pg->missing_loc.is_unfound(mi->first))\n\t  fout << \" unfound \";\n\tconst set<pg_shard_t> &mls(pg->missing_loc.get_locations(mi->first));\n\tif (mls.empty())\n\t  continue;\n\tfout << \"missing_loc: \" << mls << std::endl;\n      }\n      pg->unlock();\n      fout << std::endl;\n    }\n\n    fout.close();\n  }\n  else if (prefix == \"debug kick_recovery_wq\") {\n    int64_t delay;\n    cmd_getval(cct, cmdmap, \"delay\", delay);\n    ostringstream oss;\n    oss << delay;\n    r = cct->_conf->set_val(\"osd_recovery_delay_start\", oss.str().c_str());\n    if (r != 0) {\n      ss << \"kick_recovery_wq: error setting \"\n\t << \"osd_recovery_delay_start to '\" << delay << \"': error \"\n\t << r;\n      goto out;\n    }\n    cct->_conf->apply_changes(NULL);\n    ss << \"kicking recovery queue. set osd_recovery_delay_start \"\n       << \"to \" << cct->_conf->osd_recovery_delay_start;\n  }\n\n  else if (prefix == \"cpu_profiler\") {\n    string arg;\n    cmd_getval(cct, cmdmap, \"arg\", arg);\n    vector<string> argvec;\n    get_str_vec(arg, argvec);\n    cpu_profiler_handle_command(argvec, ds);\n  }\n\n  else if (prefix == \"dump_pg_recovery_stats\") {\n    stringstream s;\n    if (f) {\n      pg_recovery_stats.dump_formatted(f.get());\n      f->flush(ds);\n    } else {\n      pg_recovery_stats.dump(s);\n      ds << \"dump pg recovery stats: \" << s.str();\n    }\n  }\n\n  else if (prefix == \"reset_pg_recovery_stats\") {\n    ss << \"reset pg recovery stats\";\n    pg_recovery_stats.reset();\n  }\n\n  else if (prefix == \"perf histogram dump\") {\n    std::string logger;\n    std::string counter;\n    cmd_getval(cct, cmdmap, \"logger\", logger);\n    cmd_getval(cct, cmdmap, \"counter\", counter);\n    if (f) {\n      cct->get_perfcounters_collection()->dump_formatted_histograms(\n          f.get(), false, logger, counter);\n      f->flush(ds);\n    }\n  }\n\n  else if (prefix == \"compact\") {\n    dout(1) << \"triggering manual compaction\" << dendl;\n    auto start = ceph::coarse_mono_clock::now();\n    store->compact();\n    auto end = ceph::coarse_mono_clock::now();\n    auto time_span = chrono::duration_cast<chrono::duration<double>>(end - start);\n    dout(1) << \"finished manual compaction in \"\n            << time_span.count()\n            << \" seconds\" << dendl;\n    ss << \"compacted omap in \" << time_span.count() << \" seconds\";\n  }\n\n  else {\n    ss << \"unrecognized command! \" << cmd;\n    r = -EINVAL;\n  }\n\n out:\n  rs = ss.str();\n  odata.append(ds);\n  dout(0) << \"do_command r=\" << r << \" \" << rs << dendl;\n  clog->info() << rs;\n  if (con) {\n    MCommandReply *reply = new MCommandReply(r, rs);\n    reply->set_tid(tid);\n    reply->set_data(odata);\n    con->send_message(reply);\n  }\n}\n\nbool OSD::heartbeat_dispatch(Message *m)\n{\n  dout(30) << \"heartbeat_dispatch \" << m << dendl;\n  switch (m->get_type()) {\n\n  case CEPH_MSG_PING:\n    dout(10) << \"ping from \" << m->get_source_inst() << dendl;\n    m->put();\n    break;\n\n  case MSG_OSD_PING:\n    handle_osd_ping(static_cast<MOSDPing*>(m));\n    break;\n\n  default:\n    dout(0) << \"dropping unexpected message \" << *m << \" from \" << m->get_source_inst() << dendl;\n    m->put();\n  }\n\n  return true;\n}\n\nbool OSD::ms_dispatch(Message *m)\n{\n  dout(20) << \"OSD::ms_dispatch: \" << *m << dendl;\n  if (m->get_type() == MSG_OSD_MARK_ME_DOWN) {\n    service.got_stop_ack();\n    m->put();\n    return true;\n  }\n\n  // lock!\n\n  osd_lock.Lock();\n  if (is_stopping()) {\n    osd_lock.Unlock();\n    m->put();\n    return true;\n  }\n\n  do_waiters();\n  _dispatch(m);\n\n  osd_lock.Unlock();\n\n  return true;\n}\n\nvoid OSD::maybe_share_map(\n  Session *session,\n  OpRequestRef op,\n  OSDMapRef osdmap)\n{\n  if (!op->check_send_map) {\n    return;\n  }\n  epoch_t last_sent_epoch = 0;\n\n  session->sent_epoch_lock.lock();\n  last_sent_epoch = session->last_sent_epoch;\n  session->sent_epoch_lock.unlock();\n\n  const Message *m = op->get_req();\n  service.share_map(\n    m->get_source(),\n    m->get_connection().get(),\n    op->sent_epoch,\n    osdmap,\n    session ? &last_sent_epoch : NULL);\n\n  session->sent_epoch_lock.lock();\n  if (session->last_sent_epoch < last_sent_epoch) {\n    session->last_sent_epoch = last_sent_epoch;\n  }\n  session->sent_epoch_lock.unlock();\n\n  op->check_send_map = false;\n}\n\nvoid OSD::dispatch_session_waiting(Session *session, OSDMapRef osdmap)\n{\n  assert(session->session_dispatch_lock.is_locked());\n\n  auto i = session->waiting_on_map.begin();\n  while (i != session->waiting_on_map.end()) {\n    OpRequestRef op = &(*i);\n    assert(ms_can_fast_dispatch(op->get_req()));\n    const MOSDFastDispatchOp *m = static_cast<const MOSDFastDispatchOp*>(\n      op->get_req());\n    if (m->get_min_epoch() > osdmap->get_epoch()) {\n      break;\n    }\n    session->waiting_on_map.erase(i++);\n    op->put();\n\n    spg_t pgid;\n    if (m->get_type() == CEPH_MSG_OSD_OP) {\n      pg_t actual_pgid = osdmap->raw_pg_to_pg(\n\tstatic_cast<const MOSDOp*>(m)->get_pg());\n      if (!osdmap->get_primary_shard(actual_pgid, &pgid)) {\n\tcontinue;\n      }\n    } else {\n      pgid = m->get_spg();\n    }\n    enqueue_op(pgid, op, m->get_map_epoch());\n  }\n\n  if (session->waiting_on_map.empty()) {\n    clear_session_waiting_on_map(session);\n  } else {\n    register_session_waiting_on_map(session);\n  }\n}\n\nvoid OSD::ms_fast_dispatch(Message *m)\n{\n  FUNCTRACE();\n  if (service.is_stopping()) {\n    m->put();\n    return;\n  }\n  OpRequestRef op = op_tracker.create_request<OpRequest, Message*>(m);\n  {\n#ifdef WITH_LTTNG\n    osd_reqid_t reqid = op->get_reqid();\n#endif\n    tracepoint(osd, ms_fast_dispatch, reqid.name._type,\n        reqid.name._num, reqid.tid, reqid.inc);\n  }\n\n  if (m->trace)\n    op->osd_trace.init(\"osd op\", &trace_endpoint, &m->trace);\n\n  // note sender epoch, min req'd epoch\n  op->sent_epoch = static_cast<MOSDFastDispatchOp*>(m)->get_map_epoch();\n  op->min_epoch = static_cast<MOSDFastDispatchOp*>(m)->get_min_epoch();\n  assert(op->min_epoch <= op->sent_epoch); // sanity check!\n\n  service.maybe_inject_dispatch_delay();\n\n  if (m->get_connection()->has_features(CEPH_FEATUREMASK_RESEND_ON_SPLIT) ||\n      m->get_type() != CEPH_MSG_OSD_OP) {\n    // queue it directly\n    enqueue_op(\n      static_cast<MOSDFastDispatchOp*>(m)->get_spg(),\n      op,\n      static_cast<MOSDFastDispatchOp*>(m)->get_map_epoch());\n  } else {\n    // legacy client, and this is an MOSDOp (the *only* fast dispatch\n    // message that didn't have an explicit spg_t); we need to map\n    // them to an spg_t while preserving delivery order.\n    Session *session = static_cast<Session*>(m->get_connection()->get_priv());\n    if (session) {\n      {\n\tMutex::Locker l(session->session_dispatch_lock);\n\top->get();\n\tsession->waiting_on_map.push_back(*op);\n\tOSDMapRef nextmap = service.get_nextmap_reserved();\n\tdispatch_session_waiting(session, nextmap);\n\tservice.release_map(nextmap);\n      }\n      session->put();\n    }\n  }\n  OID_EVENT_TRACE_WITH_MSG(m, \"MS_FAST_DISPATCH_END\", false); \n}\n\nvoid OSD::ms_fast_preprocess(Message *m)\n{\n  if (m->get_connection()->get_peer_type() == CEPH_ENTITY_TYPE_OSD) {\n    if (m->get_type() == CEPH_MSG_OSD_MAP) {\n      MOSDMap *mm = static_cast<MOSDMap*>(m);\n      Session *s = static_cast<Session*>(m->get_connection()->get_priv());\n      if (s) {\n\ts->received_map_lock.lock();\n\ts->received_map_epoch = mm->get_last();\n\ts->received_map_lock.unlock();\n\ts->put();\n      }\n    }\n  }\n}\n\nbool OSD::ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new)\n{\n  dout(10) << \"OSD::ms_get_authorizer type=\" << ceph_entity_type_name(dest_type) << dendl;\n\n  if (is_stopping()) {\n    dout(10) << __func__ << \" bailing, we are shutting down\" << dendl;\n    return false;\n  }\n\n  if (dest_type == CEPH_ENTITY_TYPE_MON)\n    return true;\n\n  if (force_new) {\n    /* the MonClient checks keys every tick(), so we should just wait for that cycle\n       to get through */\n    if (monc->wait_auth_rotating(10) < 0) {\n      derr << \"OSD::ms_get_authorizer wait_auth_rotating failed\" << dendl;\n      return false;\n    }\n  }\n\n  *authorizer = monc->build_authorizer(dest_type);\n  return *authorizer != NULL;\n}\n\n\nbool OSD::ms_verify_authorizer(\n  Connection *con, int peer_type,\n  int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,\n  bool& isvalid, CryptoKey& session_key,\n  std::unique_ptr<AuthAuthorizerChallenge> *challenge)\n{\n  AuthAuthorizeHandler *authorize_handler = 0;\n  switch (peer_type) {\n  case CEPH_ENTITY_TYPE_MDS:\n    /*\n     * note: mds is technically a client from our perspective, but\n     * this makes the 'cluster' consistent w/ monitor's usage.\n     */\n  case CEPH_ENTITY_TYPE_OSD:\n  case CEPH_ENTITY_TYPE_MGR:\n    authorize_handler = authorize_handler_cluster_registry->get_handler(protocol);\n    break;\n  default:\n    authorize_handler = authorize_handler_service_registry->get_handler(protocol);\n  }\n  if (!authorize_handler) {\n    dout(0) << \"No AuthAuthorizeHandler found for protocol \" << protocol << dendl;\n    isvalid = false;\n    return true;\n  }\n\n  AuthCapsInfo caps_info;\n  EntityName name;\n  uint64_t global_id;\n  uint64_t auid = CEPH_AUTH_UID_DEFAULT;\n\n  RotatingKeyRing *keys = monc->rotating_secrets.get();\n  if (keys) {\n    isvalid = authorize_handler->verify_authorizer(\n      cct, keys,\n      authorizer_data, authorizer_reply, name, global_id, caps_info, session_key,\n      &auid, challenge);\n  } else {\n    dout(10) << __func__ << \" no rotating_keys (yet), denied\" << dendl;\n    isvalid = false;\n  }\n\n  if (isvalid) {\n    Session *s = static_cast<Session *>(con->get_priv());\n    if (!s) {\n      s = new Session(cct);\n      con->set_priv(s->get());\n      s->con = con;\n      dout(10) << \" new session \" << s << \" con=\" << s->con << \" addr=\" << s->con->get_peer_addr() << dendl;\n    }\n\n    s->entity_name = name;\n    if (caps_info.allow_all)\n      s->caps.set_allow_all();\n    s->auid = auid;\n\n    if (caps_info.caps.length() > 0) {\n      bufferlist::iterator p = caps_info.caps.begin();\n      string str;\n      try {\n\t::decode(str, p);\n      }\n      catch (buffer::error& e) {\n      }\n      bool success = s->caps.parse(str);\n      if (success)\n\tdout(10) << \" session \" << s << \" \" << s->entity_name << \" has caps \" << s->caps << \" '\" << str << \"'\" << dendl;\n      else\n\tdout(10) << \" session \" << s << \" \" << s->entity_name << \" failed to parse caps '\" << str << \"'\" << dendl;\n    }\n\n    s->put();\n  }\n  return true;\n}\n\nvoid OSD::do_waiters()\n{\n  assert(osd_lock.is_locked());\n\n  dout(10) << \"do_waiters -- start\" << dendl;\n  while (!finished.empty()) {\n    OpRequestRef next = finished.front();\n    finished.pop_front();\n    dispatch_op(next);\n  }\n  dout(10) << \"do_waiters -- finish\" << dendl;\n}\n\nvoid OSD::dispatch_op(OpRequestRef op)\n{\n  switch (op->get_req()->get_type()) {\n\n  case MSG_OSD_PG_CREATE:\n    handle_pg_create(op);\n    break;\n  case MSG_OSD_PG_NOTIFY:\n    handle_pg_notify(op);\n    break;\n  case MSG_OSD_PG_QUERY:\n    handle_pg_query(op);\n    break;\n  case MSG_OSD_PG_LOG:\n    handle_pg_log(op);\n    break;\n  case MSG_OSD_PG_REMOVE:\n    handle_pg_remove(op);\n    break;\n  case MSG_OSD_PG_INFO:\n    handle_pg_info(op);\n    break;\n  case MSG_OSD_PG_TRIM:\n    handle_pg_trim(op);\n    break;\n  case MSG_OSD_BACKFILL_RESERVE:\n    handle_pg_backfill_reserve(op);\n    break;\n  case MSG_OSD_RECOVERY_RESERVE:\n    handle_pg_recovery_reserve(op);\n    break;\n  }\n}\n\nvoid OSD::_dispatch(Message *m)\n{\n  assert(osd_lock.is_locked());\n  dout(20) << \"_dispatch \" << m << \" \" << *m << dendl;\n\n  switch (m->get_type()) {\n\n    // -- don't need lock --\n  case CEPH_MSG_PING:\n    dout(10) << \"ping from \" << m->get_source() << dendl;\n    m->put();\n    break;\n\n    // -- don't need OSDMap --\n\n    // map and replication\n  case CEPH_MSG_OSD_MAP:\n    handle_osd_map(static_cast<MOSDMap*>(m));\n    break;\n\n    // osd\n  case MSG_PGSTATSACK:\n    handle_pg_stats_ack(static_cast<MPGStatsAck*>(m));\n    break;\n\n  case MSG_MON_COMMAND:\n    handle_command(static_cast<MMonCommand*>(m));\n    break;\n  case MSG_COMMAND:\n    handle_command(static_cast<MCommand*>(m));\n    break;\n\n  case MSG_OSD_SCRUB:\n    handle_scrub(static_cast<MOSDScrub*>(m));\n    break;\n\n  case MSG_OSD_FORCE_RECOVERY:\n    handle_force_recovery(m);\n    break;\n\n    // -- need OSDMap --\n\n  case MSG_OSD_PG_CREATE:\n  case MSG_OSD_PG_NOTIFY:\n  case MSG_OSD_PG_QUERY:\n  case MSG_OSD_PG_LOG:\n  case MSG_OSD_PG_REMOVE:\n  case MSG_OSD_PG_INFO:\n  case MSG_OSD_PG_TRIM:\n  case MSG_OSD_BACKFILL_RESERVE:\n  case MSG_OSD_RECOVERY_RESERVE:\n    {\n      OpRequestRef op = op_tracker.create_request<OpRequest, Message*>(m);\n      if (m->trace)\n        op->osd_trace.init(\"osd op\", &trace_endpoint, &m->trace);\n      // no map?  starting up?\n      if (!osdmap) {\n        dout(7) << \"no OSDMap, not booted\" << dendl;\n\tlogger->inc(l_osd_waiting_for_map);\n        waiting_for_osdmap.push_back(op);\n\top->mark_delayed(\"no osdmap\");\n        break;\n      }\n\n      // need OSDMap\n      dispatch_op(op);\n    }\n  }\n}\n\nvoid OSD::handle_pg_scrub(MOSDScrub *m, PG *pg)\n{\n  pg->lock();\n  if (pg->is_primary()) {\n    pg->unreg_next_scrub();\n    pg->scrubber.must_scrub = true;\n    pg->scrubber.must_deep_scrub = m->deep || m->repair;\n    pg->scrubber.must_repair = m->repair;\n    pg->reg_next_scrub();\n    dout(10) << \"marking \" << *pg << \" for scrub\" << dendl;\n  }\n  pg->unlock();\n}\n\nvoid OSD::handle_scrub(MOSDScrub *m)\n{\n  dout(10) << \"handle_scrub \" << *m << dendl;\n  if (!require_mon_or_mgr_peer(m)) {\n    m->put();\n    return;\n  }\n  if (m->fsid != monc->get_fsid()) {\n    dout(0) << \"handle_scrub fsid \" << m->fsid << \" != \" << monc->get_fsid() << dendl;\n    m->put();\n    return;\n  }\n\n  RWLock::RLocker l(pg_map_lock);\n  if (m->scrub_pgs.empty()) {\n    for (ceph::unordered_map<spg_t, PG*>::iterator p = pg_map.begin();\n\t p != pg_map.end();\n\t ++p)\n      handle_pg_scrub(m, p->second);\n  } else {\n    for (vector<pg_t>::iterator p = m->scrub_pgs.begin();\n\t p != m->scrub_pgs.end();\n\t ++p) {\n      spg_t pcand;\n      if (osdmap->get_primary_shard(*p, &pcand)) {\n\tauto pg_map_entry = pg_map.find(pcand);\n\tif (pg_map_entry != pg_map.end()) {\n\t  handle_pg_scrub(m, pg_map_entry->second);\n\t}\n      }\n    }\n  }\n\n  m->put();\n}\n\nbool OSD::scrub_random_backoff()\n{\n  bool coin_flip = (rand() / (double)RAND_MAX >=\n\t\t    cct->_conf->osd_scrub_backoff_ratio);\n  if (!coin_flip) {\n    dout(20) << \"scrub_random_backoff lost coin flip, randomly backing off\" << dendl;\n    return true;\n  }\n  return false;\n}\n\nOSDService::ScrubJob::ScrubJob(CephContext* cct,\n\t\t\t       const spg_t& pg, const utime_t& timestamp,\n\t\t\t       double pool_scrub_min_interval,\n\t\t\t       double pool_scrub_max_interval, bool must)\n  : cct(cct),\n    pgid(pg),\n    sched_time(timestamp),\n    deadline(timestamp)\n{\n  // if not explicitly requested, postpone the scrub with a random delay\n  if (!must) {\n    double scrub_min_interval = pool_scrub_min_interval > 0 ?\n      pool_scrub_min_interval : cct->_conf->osd_scrub_min_interval;\n    double scrub_max_interval = pool_scrub_max_interval > 0 ?\n      pool_scrub_max_interval : cct->_conf->osd_scrub_max_interval;\n\n    sched_time += scrub_min_interval;\n    double r = rand() / (double)RAND_MAX;\n    sched_time +=\n      scrub_min_interval * cct->_conf->osd_scrub_interval_randomize_ratio * r;\n    deadline += scrub_max_interval;\n  }\n}\n\nbool OSDService::ScrubJob::ScrubJob::operator<(const OSDService::ScrubJob& rhs) const {\n  if (sched_time < rhs.sched_time)\n    return true;\n  if (sched_time > rhs.sched_time)\n    return false;\n  return pgid < rhs.pgid;\n}\n\nbool OSD::scrub_time_permit(utime_t now)\n{\n  struct tm bdt;\n  time_t tt = now.sec();\n  localtime_r(&tt, &bdt);\n\n  bool day_permit = false;\n  if (cct->_conf->osd_scrub_begin_week_day < cct->_conf->osd_scrub_end_week_day) {\n    if (bdt.tm_wday >= cct->_conf->osd_scrub_begin_week_day && bdt.tm_wday < cct->_conf->osd_scrub_end_week_day) {\n      day_permit = true;\n    }\n  } else {\n    if (bdt.tm_wday >= cct->_conf->osd_scrub_begin_week_day || bdt.tm_wday < cct->_conf->osd_scrub_end_week_day) {\n      day_permit = true;\n    }\n  }\n\n  if (!day_permit) {\n    dout(20) << __func__ << \" should run between week day \" << cct->_conf->osd_scrub_begin_week_day\n            << \" - \" << cct->_conf->osd_scrub_end_week_day\n            << \" now \" << bdt.tm_wday << \" = no\" << dendl;\n    return false;\n  }\n\n  bool time_permit = false;\n  if (cct->_conf->osd_scrub_begin_hour < cct->_conf->osd_scrub_end_hour) {\n    if (bdt.tm_hour >= cct->_conf->osd_scrub_begin_hour && bdt.tm_hour < cct->_conf->osd_scrub_end_hour) {\n      time_permit = true;\n    }\n  } else {\n    if (bdt.tm_hour >= cct->_conf->osd_scrub_begin_hour || bdt.tm_hour < cct->_conf->osd_scrub_end_hour) {\n      time_permit = true;\n    }\n  }\n  if (!time_permit) {\n    dout(20) << __func__ << \" should run between \" << cct->_conf->osd_scrub_begin_hour\n            << \" - \" << cct->_conf->osd_scrub_end_hour\n            << \" now \" << bdt.tm_hour << \" = no\" << dendl;\n  } else {\n    dout(20) << __func__ << \" should run between \" << cct->_conf->osd_scrub_begin_hour\n            << \" - \" << cct->_conf->osd_scrub_end_hour\n            << \" now \" << bdt.tm_hour << \" = yes\" << dendl;\n  }\n  return time_permit;\n}\n\nbool OSD::scrub_load_below_threshold()\n{\n  double loadavgs[3];\n  if (getloadavg(loadavgs, 3) != 3) {\n    dout(10) << __func__ << \" couldn't read loadavgs\\n\" << dendl;\n    return false;\n  }\n\n  // allow scrub if below configured threshold\n  if (loadavgs[0] < cct->_conf->osd_scrub_load_threshold) {\n    dout(20) << __func__ << \" loadavg \" << loadavgs[0]\n\t     << \" < max \" << cct->_conf->osd_scrub_load_threshold\n\t     << \" = yes\" << dendl;\n    return true;\n  }\n\n  // allow scrub if below daily avg and currently decreasing\n  if (loadavgs[0] < daily_loadavg && loadavgs[0] < loadavgs[2]) {\n    dout(20) << __func__ << \" loadavg \" << loadavgs[0]\n\t     << \" < daily_loadavg \" << daily_loadavg\n\t     << \" and < 15m avg \" << loadavgs[2]\n\t     << \" = yes\" << dendl;\n    return true;\n  }\n\n  dout(20) << __func__ << \" loadavg \" << loadavgs[0]\n\t   << \" >= max \" << cct->_conf->osd_scrub_load_threshold\n\t   << \" and ( >= daily_loadavg \" << daily_loadavg\n\t   << \" or >= 15m avg \" << loadavgs[2]\n\t   << \") = no\" << dendl;\n  return false;\n}\n\nvoid OSD::sched_scrub()\n{\n  // if not permitted, fail fast\n  if (!service.can_inc_scrubs_pending()) {\n    return;\n  }\n  if (!cct->_conf->osd_scrub_during_recovery && service.is_recovery_active()) {\n    dout(20) << __func__ << \" not scheduling scrubs due to active recovery\" << dendl;\n    return;\n  }\n\n\n  utime_t now = ceph_clock_now();\n  bool time_permit = scrub_time_permit(now);\n  bool load_is_low = scrub_load_below_threshold();\n  dout(20) << \"sched_scrub load_is_low=\" << (int)load_is_low << dendl;\n\n  OSDService::ScrubJob scrub;\n  if (service.first_scrub_stamp(&scrub)) {\n    do {\n      dout(30) << \"sched_scrub examine \" << scrub.pgid << \" at \" << scrub.sched_time << dendl;\n\n      if (scrub.sched_time > now) {\n\t// save ourselves some effort\n\tdout(10) << \"sched_scrub \" << scrub.pgid << \" scheduled at \" << scrub.sched_time\n\t\t << \" > \" << now << dendl;\n\tbreak;\n      }\n\n      if ((scrub.deadline >= now) && !(time_permit && load_is_low)) {\n        dout(10) << __func__ << \" not scheduling scrub for \" << scrub.pgid << \" due to \"\n                 << (!time_permit ? \"time not permit\" : \"high load\") << dendl;\n        continue;\n      }\n\n      PG *pg = _lookup_lock_pg(scrub.pgid);\n      if (!pg)\n\tcontinue;\n      if (pg->get_pgbackend()->scrub_supported() && pg->is_active()) {\n\tdout(10) << \"sched_scrub scrubbing \" << scrub.pgid << \" at \" << scrub.sched_time\n\t\t << (pg->scrubber.must_scrub ? \", explicitly requested\" :\n\t\t     (load_is_low ? \", load_is_low\" : \" deadline < now\"))\n\t\t << dendl;\n\tif (pg->sched_scrub()) {\n\t  pg->unlock();\n\t  break;\n\t}\n      }\n      pg->unlock();\n    } while (service.next_scrub_stamp(scrub, &scrub));\n  }\n  dout(20) << \"sched_scrub done\" << dendl;\n}\n\n\n\nvector<OSDHealthMetric> OSD::get_health_metrics()\n{\n  vector<OSDHealthMetric> metrics;\n  lock_guard<mutex> pending_creates_locker{pending_creates_lock};\n  auto n_primaries = pending_creates_from_mon;\n  for (const auto& create : pending_creates_from_osd) {\n    if (create.second) {\n      n_primaries++;\n    }\n  }\n  metrics.emplace_back(osd_metric::PENDING_CREATING_PGS, n_primaries);\n  return metrics;\n}\n\n// =====================================================\n// MAP\n\nvoid OSD::wait_for_new_map(OpRequestRef op)\n{\n  // ask?\n  if (waiting_for_osdmap.empty()) {\n    osdmap_subscribe(osdmap->get_epoch() + 1, false);\n  }\n\n  logger->inc(l_osd_waiting_for_map);\n  waiting_for_osdmap.push_back(op);\n  op->mark_delayed(\"wait for new map\");\n}\n\n\n/** update_map\n * assimilate new OSDMap(s).  scan pgs, etc.\n */\n\nvoid OSD::note_down_osd(int peer)\n{\n  assert(osd_lock.is_locked());\n  cluster_messenger->mark_down(osdmap->get_cluster_addr(peer));\n\n  heartbeat_lock.Lock();\n  failure_queue.erase(peer);\n  failure_pending.erase(peer);\n  map<int,HeartbeatInfo>::iterator p = heartbeat_peers.find(peer);\n  if (p != heartbeat_peers.end()) {\n    p->second.con_back->mark_down();\n    if (p->second.con_front) {\n      p->second.con_front->mark_down();\n    }\n    heartbeat_peers.erase(p);\n  }\n  heartbeat_lock.Unlock();\n}\n\nvoid OSD::note_up_osd(int peer)\n{\n  service.forget_peer_epoch(peer, osdmap->get_epoch() - 1);\n  heartbeat_set_peers_need_update();\n}\n\nstruct C_OnMapCommit : public Context {\n  OSD *osd;\n  epoch_t first, last;\n  MOSDMap *msg;\n  C_OnMapCommit(OSD *o, epoch_t f, epoch_t l, MOSDMap *m)\n    : osd(o), first(f), last(l), msg(m) {}\n  void finish(int r) override {\n    osd->_committed_osd_maps(first, last, msg);\n    msg->put();\n  }\n};\n\nstruct C_OnMapApply : public Context {\n  OSDService *service;\n  list<OSDMapRef> pinned_maps;\n  epoch_t e;\n  C_OnMapApply(OSDService *service,\n\t       const list<OSDMapRef> &pinned_maps,\n\t       epoch_t e)\n    : service(service), pinned_maps(pinned_maps), e(e) {}\n  void finish(int r) override {\n    service->clear_map_bl_cache_pins(e);\n  }\n};\n\nvoid OSD::osdmap_subscribe(version_t epoch, bool force_request)\n{\n  Mutex::Locker l(osdmap_subscribe_lock);\n  if (latest_subscribed_epoch >= epoch && !force_request)\n    return;\n\n  latest_subscribed_epoch = MAX(epoch, latest_subscribed_epoch);\n\n  if (monc->sub_want_increment(\"osdmap\", epoch, CEPH_SUBSCRIBE_ONETIME) ||\n      force_request) {\n    monc->renew_subs();\n  }\n}\n\nvoid OSD::trim_maps(epoch_t oldest, int nreceived, bool skip_maps)\n{\n  epoch_t min = std::min(oldest, service.map_cache.cached_key_lower_bound());\n  if (min <= superblock.oldest_map)\n    return;\n\n  int num = 0;\n  ObjectStore::Transaction t;\n  for (epoch_t e = superblock.oldest_map; e < min; ++e) {\n    dout(20) << \" removing old osdmap epoch \" << e << dendl;\n    t.remove(coll_t::meta(), get_osdmap_pobject_name(e));\n    t.remove(coll_t::meta(), get_inc_osdmap_pobject_name(e));\n    superblock.oldest_map = e + 1;\n    num++;\n    if (num >= cct->_conf->osd_target_transaction_size && num >= nreceived) {\n      service.publish_superblock(superblock);\n      write_superblock(t);\n      int tr = store->queue_transaction(service.meta_osr.get(), std::move(t), nullptr);\n      assert(tr == 0);\n      num = 0;\n      if (!skip_maps) {\n\t// skip_maps leaves us with a range of old maps if we fail to remove all\n\t// of them before moving superblock.oldest_map forward to the first map\n\t// in the incoming MOSDMap msg. so we should continue removing them in\n\t// this case, even we could do huge series of delete transactions all at\n\t// once.\n\tbreak;\n      }\n    }\n  }\n  if (num > 0) {\n    service.publish_superblock(superblock);\n    write_superblock(t);\n    int tr = store->queue_transaction(service.meta_osr.get(), std::move(t), nullptr);\n    assert(tr == 0);\n  }\n  // we should not remove the cached maps\n  assert(min <= service.map_cache.cached_key_lower_bound());\n}\n\nvoid OSD::handle_osd_map(MOSDMap *m)\n{\n  assert(osd_lock.is_locked());\n  // Keep a ref in the list until we get the newly received map written\n  // onto disk. This is important because as long as the refs are alive,\n  // the OSDMaps will be pinned in the cache and we won't try to read it\n  // off of disk. Otherwise these maps will probably not stay in the cache,\n  // and reading those OSDMaps before they are actually written can result\n  // in a crash. \n  list<OSDMapRef> pinned_maps;\n  if (m->fsid != monc->get_fsid()) {\n    dout(0) << \"handle_osd_map fsid \" << m->fsid << \" != \"\n\t    << monc->get_fsid() << dendl;\n    m->put();\n    return;\n  }\n  if (is_initializing()) {\n    dout(0) << \"ignoring osdmap until we have initialized\" << dendl;\n    m->put();\n    return;\n  }\n\n  Session *session = static_cast<Session *>(m->get_connection()->get_priv());\n  if (session && !(session->entity_name.is_mon() ||\n\t\t   session->entity_name.is_osd())) {\n    //not enough perms!\n    dout(10) << \"got osd map from Session \" << session\n             << \" which we can't take maps from (not a mon or osd)\" << dendl;\n    m->put();\n    session->put();\n    return;\n  }\n  if (session)\n    session->put();\n\n  // share with the objecter\n  if (!is_preboot())\n    service.objecter->handle_osd_map(m);\n\n  epoch_t first = m->get_first();\n  epoch_t last = m->get_last();\n  dout(3) << \"handle_osd_map epochs [\" << first << \",\" << last << \"], i have \"\n\t  << superblock.newest_map\n\t  << \", src has [\" << m->oldest_map << \",\" << m->newest_map << \"]\"\n\t  << dendl;\n\n  logger->inc(l_osd_map);\n  logger->inc(l_osd_mape, last - first + 1);\n  if (first <= superblock.newest_map)\n    logger->inc(l_osd_mape_dup, superblock.newest_map - first + 1);\n  if (service.max_oldest_map < m->oldest_map) {\n    service.max_oldest_map = m->oldest_map;\n    assert(service.max_oldest_map >= superblock.oldest_map);\n  }\n\n  // make sure there is something new, here, before we bother flushing\n  // the queues and such\n  if (last <= superblock.newest_map) {\n    dout(10) << \" no new maps here, dropping\" << dendl;\n    m->put();\n    return;\n  }\n\n  // missing some?\n  bool skip_maps = false;\n  if (first > superblock.newest_map + 1) {\n    dout(10) << \"handle_osd_map message skips epochs \"\n\t     << superblock.newest_map + 1 << \"..\" << (first-1) << dendl;\n    if (m->oldest_map <= superblock.newest_map + 1) {\n      osdmap_subscribe(superblock.newest_map + 1, false);\n      m->put();\n      return;\n    }\n    // always try to get the full range of maps--as many as we can.  this\n    //  1- is good to have\n    //  2- is at present the only way to ensure that we get a *full* map as\n    //     the first map!\n    if (m->oldest_map < first) {\n      osdmap_subscribe(m->oldest_map - 1, true);\n      m->put();\n      return;\n    }\n    skip_maps = true;\n  }\n\n  ObjectStore::Transaction t;\n  uint64_t txn_size = 0;\n\n  // store new maps: queue for disk and put in the osdmap cache\n  epoch_t start = MAX(superblock.newest_map + 1, first);\n  for (epoch_t e = start; e <= last; e++) {\n    if (txn_size >= t.get_num_bytes()) {\n      derr << __func__ << \" transaction size overflowed\" << dendl;\n      assert(txn_size < t.get_num_bytes());\n    }\n    txn_size = t.get_num_bytes();\n    map<epoch_t,bufferlist>::iterator p;\n    p = m->maps.find(e);\n    if (p != m->maps.end()) {\n      dout(10) << \"handle_osd_map  got full map for epoch \" << e << dendl;\n      OSDMap *o = new OSDMap;\n      bufferlist& bl = p->second;\n\n      o->decode(bl);\n\n      ghobject_t fulloid = get_osdmap_pobject_name(e);\n      t.write(coll_t::meta(), fulloid, 0, bl.length(), bl);\n      pin_map_bl(e, bl);\n      pinned_maps.push_back(add_map(o));\n\n      got_full_map(e);\n      continue;\n    }\n\n    p = m->incremental_maps.find(e);\n    if (p != m->incremental_maps.end()) {\n      dout(10) << \"handle_osd_map  got inc map for epoch \" << e << dendl;\n      bufferlist& bl = p->second;\n      ghobject_t oid = get_inc_osdmap_pobject_name(e);\n      t.write(coll_t::meta(), oid, 0, bl.length(), bl);\n      pin_map_inc_bl(e, bl);\n\n      OSDMap *o = new OSDMap;\n      if (e > 1) {\n\tbufferlist obl;\n        bool got = get_map_bl(e - 1, obl);\n        assert(got);\n\to->decode(obl);\n      }\n\n      OSDMap::Incremental inc;\n      bufferlist::iterator p = bl.begin();\n      inc.decode(p);\n      if (o->apply_incremental(inc) < 0) {\n\tderr << \"ERROR: bad fsid?  i have \" << osdmap->get_fsid() << \" and inc has \" << inc.fsid << dendl;\n\tassert(0 == \"bad fsid\");\n      }\n\n      bufferlist fbl;\n      o->encode(fbl, inc.encode_features | CEPH_FEATURE_RESERVED);\n\n      bool injected_failure = false;\n      if (cct->_conf->osd_inject_bad_map_crc_probability > 0 &&\n\t  (rand() % 10000) < cct->_conf->osd_inject_bad_map_crc_probability*10000.0) {\n\tderr << __func__ << \" injecting map crc failure\" << dendl;\n\tinjected_failure = true;\n      }\n\n      if ((inc.have_crc && o->get_crc() != inc.full_crc) || injected_failure) {\n\tdout(2) << \"got incremental \" << e\n\t\t<< \" but failed to encode full with correct crc; requesting\"\n\t\t<< dendl;\n\tclog->warn() << \"failed to encode map e\" << e << \" with expected crc\";\n\tdout(20) << \"my encoded map was:\\n\";\n\tfbl.hexdump(*_dout);\n\t*_dout << dendl;\n\tdelete o;\n\trequest_full_map(e, last);\n\tlast = e - 1;\n\tbreak;\n      }\n      got_full_map(e);\n\n      ghobject_t fulloid = get_osdmap_pobject_name(e);\n      t.write(coll_t::meta(), fulloid, 0, fbl.length(), fbl);\n      pin_map_bl(e, fbl);\n      pinned_maps.push_back(add_map(o));\n      continue;\n    }\n\n    assert(0 == \"MOSDMap lied about what maps it had?\");\n  }\n\n  // even if this map isn't from a mon, we may have satisfied our subscription\n  monc->sub_got(\"osdmap\", last);\n\n  if (!m->maps.empty() && requested_full_first) {\n    dout(10) << __func__ << \" still missing full maps \" << requested_full_first\n\t     << \"..\" << requested_full_last << dendl;\n    rerequest_full_maps();\n  }\n\n  if (superblock.oldest_map) {\n    // make sure we at least keep pace with incoming maps\n    trim_maps(m->oldest_map, last - first + 1, skip_maps);\n  }\n\n  if (!superblock.oldest_map || skip_maps)\n    superblock.oldest_map = first;\n  superblock.newest_map = last;\n  superblock.current_epoch = last;\n\n  // note in the superblock that we were clean thru the prior epoch\n  epoch_t boot_epoch = service.get_boot_epoch();\n  if (boot_epoch && boot_epoch >= superblock.mounted) {\n    superblock.mounted = boot_epoch;\n    superblock.clean_thru = last;\n  }\n\n  // superblock and commit\n  write_superblock(t);\n  store->queue_transaction(\n    service.meta_osr.get(),\n    std::move(t),\n    new C_OnMapApply(&service, pinned_maps, last),\n    new C_OnMapCommit(this, start, last, m), 0);\n  service.publish_superblock(superblock);\n}\n\nvoid OSD::_committed_osd_maps(epoch_t first, epoch_t last, MOSDMap *m)\n{\n  dout(10) << __func__ << \" \" << first << \"..\" << last << dendl;\n  if (is_stopping()) {\n    dout(10) << __func__ << \" bailing, we are shutting down\" << dendl;\n    return;\n  }\n  Mutex::Locker l(osd_lock);\n  if (is_stopping()) {\n    dout(10) << __func__ << \" bailing, we are shutting down\" << dendl;\n    return;\n  }\n  map_lock.get_write();\n\n  bool do_shutdown = false;\n  bool do_restart = false;\n  bool network_error = false;\n\n  // advance through the new maps\n  for (epoch_t cur = first; cur <= last; cur++) {\n    dout(10) << \" advance to epoch \" << cur\n\t     << \" (<= last \" << last\n\t     << \" <= newest_map \" << superblock.newest_map\n\t     << \")\" << dendl;\n\n    OSDMapRef newmap = get_map(cur);\n    assert(newmap);  // we just cached it above!\n\n    // start blacklisting messages sent to peers that go down.\n    service.pre_publish_map(newmap);\n\n    // kill connections to newly down osds\n    bool waited_for_reservations = false;\n    set<int> old;\n    osdmap->get_all_osds(old);\n    for (set<int>::iterator p = old.begin(); p != old.end(); ++p) {\n      if (*p != whoami &&\n\t  osdmap->is_up(*p) && // in old map\n\t  newmap->is_down(*p)) {    // but not the new one\n        if (!waited_for_reservations) {\n          service.await_reserved_maps();\n          waited_for_reservations = true;\n        }\n\tnote_down_osd(*p);\n      } else if (*p != whoami &&\n                osdmap->is_down(*p) &&\n                newmap->is_up(*p)) {\n        note_up_osd(*p);\n      }\n    }\n\n    if ((osdmap->test_flag(CEPH_OSDMAP_NOUP) !=\n        newmap->test_flag(CEPH_OSDMAP_NOUP)) ||\n        (osdmap->is_noup(whoami) != newmap->is_noup(whoami))) {\n      dout(10) << __func__ << \" NOUP flag changed in \" << newmap->get_epoch()\n\t       << dendl;\n      if (is_booting()) {\n\t// this captures the case where we sent the boot message while\n\t// NOUP was being set on the mon and our boot request was\n\t// dropped, and then later it is cleared.  it imperfectly\n\t// handles the case where our original boot message was not\n\t// dropped and we restart even though we might have booted, but\n\t// that is harmless (boot will just take slightly longer).\n\tdo_restart = true;\n      }\n    }\n    if (osdmap->require_osd_release < CEPH_RELEASE_LUMINOUS &&\n\tnewmap->require_osd_release >= CEPH_RELEASE_LUMINOUS) {\n      dout(10) << __func__ << \" require_osd_release reached luminous in \"\n\t       << newmap->get_epoch() << dendl;\n      clear_pg_stat_queue();\n      clear_outstanding_pg_stats();\n    }\n\n    osdmap = newmap;\n    epoch_t up_epoch;\n    epoch_t boot_epoch;\n    service.retrieve_epochs(&boot_epoch, &up_epoch, NULL);\n    if (!up_epoch &&\n\tosdmap->is_up(whoami) &&\n\tosdmap->get_inst(whoami) == client_messenger->get_myinst()) {\n      up_epoch = osdmap->get_epoch();\n      dout(10) << \"up_epoch is \" << up_epoch << dendl;\n      if (!boot_epoch) {\n\tboot_epoch = osdmap->get_epoch();\n\tdout(10) << \"boot_epoch is \" << boot_epoch << dendl;\n      }\n      service.set_epochs(&boot_epoch, &up_epoch, NULL);\n    }\n  }\n\n  had_map_since = ceph_clock_now();\n\n  epoch_t _bind_epoch = service.get_bind_epoch();\n  if (osdmap->is_up(whoami) &&\n      osdmap->get_addr(whoami) == client_messenger->get_myaddr() &&\n      _bind_epoch < osdmap->get_up_from(whoami)) {\n\n    if (is_booting()) {\n      dout(1) << \"state: booting -> active\" << dendl;\n      set_state(STATE_ACTIVE);\n\n      // set incarnation so that osd_reqid_t's we generate for our\n      // objecter requests are unique across restarts.\n      service.objecter->set_client_incarnation(osdmap->get_epoch());\n    }\n  }\n\n  if (osdmap->get_epoch() > 0 &&\n      is_active()) {\n    if (!osdmap->exists(whoami)) {\n      dout(0) << \"map says i do not exist.  shutting down.\" << dendl;\n      do_shutdown = true;   // don't call shutdown() while we have\n\t\t\t    // everything paused\n    } else if (!osdmap->is_up(whoami) ||\n\t       !osdmap->get_addr(whoami).probably_equals(\n\t\t client_messenger->get_myaddr()) ||\n\t       !osdmap->get_cluster_addr(whoami).probably_equals(\n\t\t cluster_messenger->get_myaddr()) ||\n\t       !osdmap->get_hb_back_addr(whoami).probably_equals(\n\t\t hb_back_server_messenger->get_myaddr()) ||\n\t       (osdmap->get_hb_front_addr(whoami) != entity_addr_t() &&\n                !osdmap->get_hb_front_addr(whoami).probably_equals(\n\t\t  hb_front_server_messenger->get_myaddr()))) {\n      if (!osdmap->is_up(whoami)) {\n\tif (service.is_preparing_to_stop() || service.is_stopping()) {\n\t  service.got_stop_ack();\n\t} else {\n          clog->warn() << \"Monitor daemon marked osd.\" << whoami << \" down, \"\n                          \"but it is still running\";\n          clog->debug() << \"map e\" << osdmap->get_epoch()\n                        << \" wrongly marked me down at e\"\n                        << osdmap->get_down_at(whoami);\n\t}\n      } else if (!osdmap->get_addr(whoami).probably_equals(\n\t\t   client_messenger->get_myaddr())) {\n\tclog->error() << \"map e\" << osdmap->get_epoch()\n\t\t      << \" had wrong client addr (\" << osdmap->get_addr(whoami)\n\t\t      << \" != my \" << client_messenger->get_myaddr() << \")\";\n      } else if (!osdmap->get_cluster_addr(whoami).probably_equals(\n\t\t   cluster_messenger->get_myaddr())) {\n\tclog->error() << \"map e\" << osdmap->get_epoch()\n\t\t      << \" had wrong cluster addr (\"\n\t\t      << osdmap->get_cluster_addr(whoami)\n\t\t      << \" != my \" << cluster_messenger->get_myaddr() << \")\";\n      } else if (!osdmap->get_hb_back_addr(whoami).probably_equals(\n\t\t   hb_back_server_messenger->get_myaddr())) {\n\tclog->error() << \"map e\" << osdmap->get_epoch()\n\t\t      << \" had wrong heartbeat back addr (\"\n\t\t      << osdmap->get_hb_back_addr(whoami)\n\t\t      << \" != my \" << hb_back_server_messenger->get_myaddr()\n\t\t      << \")\";\n      } else if (osdmap->get_hb_front_addr(whoami) != entity_addr_t() &&\n\t\t !osdmap->get_hb_front_addr(whoami).probably_equals(\n\t\t   hb_front_server_messenger->get_myaddr())) {\n\tclog->error() << \"map e\" << osdmap->get_epoch()\n\t\t      << \" had wrong heartbeat front addr (\"\n\t\t      << osdmap->get_hb_front_addr(whoami)\n\t\t      << \" != my \" << hb_front_server_messenger->get_myaddr()\n\t\t      << \")\";\n      }\n\n      if (!service.is_stopping()) {\n        epoch_t up_epoch = 0;\n        epoch_t bind_epoch = osdmap->get_epoch();\n        service.set_epochs(NULL,&up_epoch, &bind_epoch);\n\tdo_restart = true;\n\n\t//add markdown log\n\tutime_t now = ceph_clock_now();\n\tutime_t grace = utime_t(cct->_conf->osd_max_markdown_period, 0);\n\tosd_markdown_log.push_back(now);\n\t//clear all out-of-date log\n\twhile (!osd_markdown_log.empty() &&\n\t       osd_markdown_log.front() + grace < now)\n\t  osd_markdown_log.pop_front();\n\tif ((int)osd_markdown_log.size() > cct->_conf->osd_max_markdown_count) {\n\t  dout(0) << __func__ << \" marked down \"\n\t\t  << osd_markdown_log.size()\n\t\t  << \" > osd_max_markdown_count \"\n\t\t  << cct->_conf->osd_max_markdown_count\n\t\t  << \" in last \" << grace << \" seconds, shutting down\"\n\t\t  << dendl;\n\t  do_restart = false;\n\t  do_shutdown = true;\n\t}\n\n\tstart_waiting_for_healthy();\n\n\tset<int> avoid_ports;\n#if defined(__FreeBSD__)\n        // prevent FreeBSD from grabbing the client_messenger port during\n        // rebinding. In which case a cluster_meesneger will connect also \n\t// to the same port\n\tavoid_ports.insert(client_messenger->get_myaddr().get_port());\n#endif\n\tavoid_ports.insert(cluster_messenger->get_myaddr().get_port());\n\tavoid_ports.insert(hb_back_server_messenger->get_myaddr().get_port());\n\tavoid_ports.insert(hb_front_server_messenger->get_myaddr().get_port());\n\n\tint r = cluster_messenger->rebind(avoid_ports);\n\tif (r != 0) {\n\t  do_shutdown = true;  // FIXME: do_restart?\n          network_error = true;\n          dout(0) << __func__ << \" marked down:\"\n                  << \" rebind cluster_messenger failed\" << dendl;\n        }\n\n\tr = hb_back_server_messenger->rebind(avoid_ports);\n\tif (r != 0) {\n\t  do_shutdown = true;  // FIXME: do_restart?\n          network_error = true;\n          dout(0) << __func__ << \" marked down:\"\n                  << \" rebind hb_back_server_messenger failed\" << dendl;\n        }\n\n\tr = hb_front_server_messenger->rebind(avoid_ports);\n\tif (r != 0) {\n\t  do_shutdown = true;  // FIXME: do_restart?\n          network_error = true;\n          dout(0) << __func__ << \" marked down:\" \n                  << \" rebind hb_front_server_messenger failed\" << dendl;\n        }\n\n\thb_front_client_messenger->mark_down_all();\n\thb_back_client_messenger->mark_down_all();\n\n\treset_heartbeat_peers();\n      }\n    }\n  }\n\n  map_lock.put_write();\n\n  check_osdmap_features(store);\n\n  // yay!\n  consume_map();\n\n  if (is_active() || is_waiting_for_healthy())\n    maybe_update_heartbeat_peers();\n\n  if (!is_active()) {\n    dout(10) << \" not yet active; waiting for peering wq to drain\" << dendl;\n    peering_wq.drain();\n  } else {\n    activate_map();\n  }\n\n  if (do_shutdown) {\n    if (network_error) {\n      Mutex::Locker l(heartbeat_lock);\n      map<int,pair<utime_t,entity_inst_t>>::iterator it =\n\tfailure_pending.begin();\n      while (it != failure_pending.end()) {\n        dout(10) << \"handle_osd_ping canceling in-flight failure report for osd.\"\n\t\t << it->first << dendl;\n        send_still_alive(osdmap->get_epoch(), it->second.second);\n        failure_pending.erase(it++);\n      }\n    }\n    // trigger shutdown in a different thread\n    dout(0) << __func__ << \" shutdown OSD via async signal\" << dendl;\n    queue_async_signal(SIGINT);\n  }\n  else if (m->newest_map && m->newest_map > last) {\n    dout(10) << \" msg say newest map is \" << m->newest_map\n\t     << \", requesting more\" << dendl;\n    osdmap_subscribe(osdmap->get_epoch()+1, false);\n  }\n  else if (is_preboot()) {\n    if (m->get_source().is_mon())\n      _preboot(m->oldest_map, m->newest_map);\n    else\n      start_boot();\n  }\n  else if (do_restart)\n    start_boot();\n\n}\n\nvoid OSD::check_osdmap_features(ObjectStore *fs)\n{\n  // adjust required feature bits?\n\n  // we have to be a bit careful here, because we are accessing the\n  // Policy structures without taking any lock.  in particular, only\n  // modify integer values that can safely be read by a racing CPU.\n  // since we are only accessing existing Policy structures a their\n  // current memory location, and setting or clearing bits in integer\n  // fields, and we are the only writer, this is not a problem.\n\n  {\n    Messenger::Policy p = client_messenger->get_default_policy();\n    uint64_t mask;\n    uint64_t features = osdmap->get_features(entity_name_t::TYPE_CLIENT, &mask);\n    if ((p.features_required & mask) != features) {\n      dout(0) << \"crush map has features \" << features\n\t      << \", adjusting msgr requires for clients\" << dendl;\n      p.features_required = (p.features_required & ~mask) | features;\n      client_messenger->set_default_policy(p);\n    }\n  }\n  {\n    Messenger::Policy p = client_messenger->get_policy(entity_name_t::TYPE_MON);\n    uint64_t mask;\n    uint64_t features = osdmap->get_features(entity_name_t::TYPE_MON, &mask);\n    if ((p.features_required & mask) != features) {\n      dout(0) << \"crush map has features \" << features\n\t      << \" was \" << p.features_required\n\t      << \", adjusting msgr requires for mons\" << dendl;\n      p.features_required = (p.features_required & ~mask) | features;\n      client_messenger->set_policy(entity_name_t::TYPE_MON, p);\n    }\n  }\n  {\n    Messenger::Policy p = cluster_messenger->get_policy(entity_name_t::TYPE_OSD);\n    uint64_t mask;\n    uint64_t features = osdmap->get_features(entity_name_t::TYPE_OSD, &mask);\n\n    if ((p.features_required & mask) != features) {\n      dout(0) << \"crush map has features \" << features\n\t      << \", adjusting msgr requires for osds\" << dendl;\n      p.features_required = (p.features_required & ~mask) | features;\n      cluster_messenger->set_policy(entity_name_t::TYPE_OSD, p);\n    }\n\n    if ((features & CEPH_FEATURE_OSD_ERASURE_CODES) &&\n\t!superblock.compat_features.incompat.contains(CEPH_OSD_FEATURE_INCOMPAT_SHARDS)) {\n      dout(0) << __func__ << \" enabling on-disk ERASURE CODES compat feature\" << dendl;\n      superblock.compat_features.incompat.insert(CEPH_OSD_FEATURE_INCOMPAT_SHARDS);\n      ObjectStore::Transaction t;\n      write_superblock(t);\n      int err = store->queue_transaction(service.meta_osr.get(), std::move(t), NULL);\n      assert(err == 0);\n    }\n  }\n}\n\nbool OSD::advance_pg(\n  epoch_t osd_epoch, PG *pg,\n  ThreadPool::TPHandle &handle,\n  PG::RecoveryCtx *rctx,\n  set<PGRef> *new_pgs)\n{\n  assert(pg->is_locked());\n  epoch_t next_epoch = pg->get_osdmap()->get_epoch() + 1;\n  OSDMapRef lastmap = pg->get_osdmap();\n\n  if (lastmap->get_epoch() == osd_epoch)\n    return true;\n  assert(lastmap->get_epoch() < osd_epoch);\n\n  epoch_t min_epoch = service.get_min_pg_epoch();\n  epoch_t max;\n  if (min_epoch) {\n    max = min_epoch + cct->_conf->osd_map_max_advance;\n  } else {\n    max = next_epoch + cct->_conf->osd_map_max_advance;\n  }\n\n  for (;\n       next_epoch <= osd_epoch && next_epoch <= max;\n       ++next_epoch) {\n    OSDMapRef nextmap = service.try_get_map(next_epoch);\n    if (!nextmap) {\n      dout(20) << __func__ << \" missing map \" << next_epoch << dendl;\n      // make sure max is bumped up so that we can get past any\n      // gap in maps\n      max = MAX(max, next_epoch + cct->_conf->osd_map_max_advance);\n      continue;\n    }\n\n    vector<int> newup, newacting;\n    int up_primary, acting_primary;\n    nextmap->pg_to_up_acting_osds(\n      pg->info.pgid.pgid,\n      &newup, &up_primary,\n      &newacting, &acting_primary);\n    pg->handle_advance_map(\n      nextmap, lastmap, newup, up_primary,\n      newacting, acting_primary, rctx);\n\n    // Check for split!\n    set<spg_t> children;\n    spg_t parent(pg->info.pgid);\n    if (parent.is_split(\n\tlastmap->get_pg_num(pg->pool.id),\n\tnextmap->get_pg_num(pg->pool.id),\n\t&children)) {\n      service.mark_split_in_progress(pg->info.pgid, children);\n      split_pgs(\n\tpg, children, new_pgs, lastmap, nextmap,\n\trctx);\n    }\n\n    lastmap = nextmap;\n    handle.reset_tp_timeout();\n  }\n  service.pg_update_epoch(pg->info.pgid, lastmap->get_epoch());\n  pg->handle_activate_map(rctx);\n  if (next_epoch <= osd_epoch) {\n    dout(10) << __func__ << \" advanced to max \" << max\n\t     << \" past min epoch \" << min_epoch\n\t     << \" ... will requeue \" << *pg << dendl;\n    return false;\n  }\n  return true;\n}\n\nvoid OSD::consume_map()\n{\n  assert(osd_lock.is_locked());\n  dout(7) << \"consume_map version \" << osdmap->get_epoch() << dendl;\n\n  /** make sure the cluster is speaking in SORTBITWISE, because we don't\n   *  speak the older sorting version any more. Be careful not to force\n   *  a shutdown if we are merely processing old maps, though.\n   */\n  if (!osdmap->test_flag(CEPH_OSDMAP_SORTBITWISE) && is_active()) {\n    derr << __func__ << \" SORTBITWISE flag is not set\" << dendl;\n    ceph_abort();\n  }\n\n  int num_pg_primary = 0, num_pg_replica = 0, num_pg_stray = 0;\n  list<PGRef> to_remove;\n\n  // scan pg's\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t,PG*>::iterator it = pg_map.begin();\n        it != pg_map.end();\n        ++it) {\n      PG *pg = it->second;\n      pg->lock();\n      if (pg->is_primary())\n        num_pg_primary++;\n      else if (pg->is_replica())\n        num_pg_replica++;\n      else\n        num_pg_stray++;\n\n      if (!osdmap->have_pg_pool(pg->info.pgid.pool())) {\n        //pool is deleted!\n        to_remove.push_back(PGRef(pg));\n      } else {\n        service.init_splits_between(it->first, service.get_osdmap(), osdmap);\n      }\n\n      pg->unlock();\n    }\n\n    lock_guard<mutex> pending_creates_locker{pending_creates_lock};\n    for (auto pg = pending_creates_from_osd.cbegin();\n\t pg != pending_creates_from_osd.cend();) {\n      if (osdmap->get_pg_acting_rank(pg->first, whoami) < 0) {\n\tpg = pending_creates_from_osd.erase(pg);\n      } else {\n\t++pg;\n      }\n    }\n  }\n\n  for (list<PGRef>::iterator i = to_remove.begin();\n       i != to_remove.end();\n       to_remove.erase(i++)) {\n    RWLock::WLocker locker(pg_map_lock);\n    (*i)->lock();\n    _remove_pg(&**i);\n    (*i)->unlock();\n  }\n\n  service.expand_pg_num(service.get_osdmap(), osdmap);\n\n  service.pre_publish_map(osdmap);\n  service.await_reserved_maps();\n  service.publish_map(osdmap);\n\n  service.maybe_inject_dispatch_delay();\n\n  dispatch_sessions_waiting_on_map();\n\n  service.maybe_inject_dispatch_delay();\n\n  // remove any PGs which we no longer host from the session waiting_for_pg lists\n  dout(20) << __func__ << \" checking waiting_for_pg\" << dendl;\n  op_shardedwq.prune_pg_waiters(osdmap, whoami);\n\n  service.maybe_inject_dispatch_delay();\n\n  // scan pg's\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (ceph::unordered_map<spg_t,PG*>::iterator it = pg_map.begin();\n        it != pg_map.end();\n        ++it) {\n      PG *pg = it->second;\n      pg->lock();\n      pg->queue_null(osdmap->get_epoch(), osdmap->get_epoch());\n      pg->unlock();\n    }\n\n    logger->set(l_osd_pg, pg_map.size());\n  }\n  logger->set(l_osd_pg_primary, num_pg_primary);\n  logger->set(l_osd_pg_replica, num_pg_replica);\n  logger->set(l_osd_pg_stray, num_pg_stray);\n  logger->set(l_osd_pg_removing, remove_wq.get_remove_queue_len());\n}\n\nvoid OSD::activate_map()\n{\n  assert(osd_lock.is_locked());\n\n  dout(7) << \"activate_map version \" << osdmap->get_epoch() << dendl;\n\n  if (osdmap->test_flag(CEPH_OSDMAP_FULL)) {\n    dout(10) << \" osdmap flagged full, doing onetime osdmap subscribe\" << dendl;\n    osdmap_subscribe(osdmap->get_epoch() + 1, false);\n  }\n\n  // norecover?\n  if (osdmap->test_flag(CEPH_OSDMAP_NORECOVER)) {\n    if (!service.recovery_is_paused()) {\n      dout(1) << \"pausing recovery (NORECOVER flag set)\" << dendl;\n      service.pause_recovery();\n    }\n  } else {\n    if (service.recovery_is_paused()) {\n      dout(1) << \"unpausing recovery (NORECOVER flag unset)\" << dendl;\n      service.unpause_recovery();\n    }\n  }\n\n  service.activate_map();\n\n  // process waiters\n  take_waiters(waiting_for_osdmap);\n}\n\nbool OSD::require_mon_peer(const Message *m)\n{\n  if (!m->get_connection()->peer_is_mon()) {\n    dout(0) << \"require_mon_peer received from non-mon \"\n\t    << m->get_connection()->get_peer_addr()\n\t    << \" \" << *m << dendl;\n    return false;\n  }\n  return true;\n}\n\nbool OSD::require_mon_or_mgr_peer(const Message *m)\n{\n  if (!m->get_connection()->peer_is_mon() &&\n      !m->get_connection()->peer_is_mgr()) {\n    dout(0) << \"require_mon_or_mgr_peer received from non-mon, non-mgr \"\n\t    << m->get_connection()->get_peer_addr()\n\t    << \" \" << *m << dendl;\n    return false;\n  }\n  return true;\n}\n\nbool OSD::require_osd_peer(const Message *m)\n{\n  if (!m->get_connection()->peer_is_osd()) {\n    dout(0) << \"require_osd_peer received from non-osd \"\n\t    << m->get_connection()->get_peer_addr()\n\t    << \" \" << *m << dendl;\n    return false;\n  }\n  return true;\n}\n\nbool OSD::require_self_aliveness(const Message *m, epoch_t epoch)\n{\n  epoch_t up_epoch = service.get_up_epoch();\n  if (epoch < up_epoch) {\n    dout(7) << \"from pre-up epoch \" << epoch << \" < \" << up_epoch << dendl;\n    return false;\n  }\n\n  if (!is_active()) {\n    dout(7) << \"still in boot state, dropping message \" << *m << dendl;\n    return false;\n  }\n\n  return true;\n}\n\nbool OSD::require_same_peer_instance(const Message *m, OSDMapRef& map,\n\t\t\t\t     bool is_fast_dispatch)\n{\n  int from = m->get_source().num();\n\n  if (map->is_down(from) ||\n      (map->get_cluster_addr(from) != m->get_source_inst().addr)) {\n    dout(5) << \"from dead osd.\" << from << \", marking down, \"\n\t    << \" msg was \" << m->get_source_inst().addr\n\t    << \" expected \" << (map->is_up(from) ?\n\t\t\t\tmap->get_cluster_addr(from) : entity_addr_t())\n\t    << dendl;\n    ConnectionRef con = m->get_connection();\n    con->mark_down();\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (s) {\n      if (!is_fast_dispatch)\n\ts->session_dispatch_lock.Lock();\n      clear_session_waiting_on_map(s);\n      con->set_priv(NULL);   // break ref <-> session cycle, if any\n      if (!is_fast_dispatch)\n\ts->session_dispatch_lock.Unlock();\n      s->put();\n    }\n    return false;\n  }\n  return true;\n}\n\n\n/*\n * require that we have same (or newer) map, and that\n * the source is the pg primary.\n */\nbool OSD::require_same_or_newer_map(OpRequestRef& op, epoch_t epoch,\n\t\t\t\t    bool is_fast_dispatch)\n{\n  const Message *m = op->get_req();\n  dout(15) << \"require_same_or_newer_map \" << epoch\n\t   << \" (i am \" << osdmap->get_epoch() << \") \" << m << dendl;\n\n  assert(osd_lock.is_locked());\n\n  // do they have a newer map?\n  if (epoch > osdmap->get_epoch()) {\n    dout(7) << \"waiting for newer map epoch \" << epoch\n\t    << \" > my \" << osdmap->get_epoch() << \" with \" << m << dendl;\n    wait_for_new_map(op);\n    return false;\n  }\n\n  if (!require_self_aliveness(op->get_req(), epoch)) {\n    return false;\n  }\n\n  // ok, our map is same or newer.. do they still exist?\n  if (m->get_connection()->get_messenger() == cluster_messenger &&\n      !require_same_peer_instance(op->get_req(), osdmap, is_fast_dispatch)) {\n    return false;\n  }\n\n  return true;\n}\n\n\n\n\n\n// ----------------------------------------\n// pg creation\n\nvoid OSD::split_pgs(\n  PG *parent,\n  const set<spg_t> &childpgids, set<PGRef> *out_pgs,\n  OSDMapRef curmap,\n  OSDMapRef nextmap,\n  PG::RecoveryCtx *rctx)\n{\n  unsigned pg_num = nextmap->get_pg_num(\n    parent->pool.id);\n  parent->update_snap_mapper_bits(\n    parent->info.pgid.get_split_bits(pg_num)\n    );\n\n  vector<object_stat_sum_t> updated_stats(childpgids.size() + 1);\n  parent->info.stats.stats.sum.split(updated_stats);\n\n  vector<object_stat_sum_t>::iterator stat_iter = updated_stats.begin();\n  for (set<spg_t>::const_iterator i = childpgids.begin();\n       i != childpgids.end();\n       ++i, ++stat_iter) {\n    assert(stat_iter != updated_stats.end());\n    dout(10) << \"Splitting \" << *parent << \" into \" << *i << dendl;\n    assert(service.splitting(*i));\n    PG* child = _make_pg(nextmap, *i);\n    child->lock(true);\n    out_pgs->insert(child);\n    rctx->created_pgs.insert(child);\n\n    unsigned split_bits = i->get_split_bits(pg_num);\n    dout(10) << \"pg_num is \" << pg_num << dendl;\n    dout(10) << \"m_seed \" << i->ps() << dendl;\n    dout(10) << \"split_bits is \" << split_bits << dendl;\n\n    parent->split_colls(\n      *i,\n      split_bits,\n      i->ps(),\n      &child->pool.info,\n      rctx->transaction);\n    parent->split_into(\n      i->pgid,\n      child,\n      split_bits);\n    child->info.stats.stats.sum = *stat_iter;\n\n    child->write_if_dirty(*(rctx->transaction));\n    child->unlock();\n  }\n  assert(stat_iter != updated_stats.end());\n  parent->info.stats.stats.sum = *stat_iter;\n  parent->write_if_dirty(*(rctx->transaction));\n}\n\n/*\n * holding osd_lock\n */\nvoid OSD::handle_pg_create(OpRequestRef op)\n{\n  const MOSDPGCreate *m = static_cast<const MOSDPGCreate*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_CREATE);\n\n  dout(10) << \"handle_pg_create \" << *m << dendl;\n\n  if (!require_mon_peer(op->get_req())) {\n    return;\n  }\n\n  if (!require_same_or_newer_map(op, m->epoch, false))\n    return;\n\n  op->mark_started();\n\n  map<pg_t,utime_t>::const_iterator ci = m->ctimes.begin();\n  for (map<pg_t,pg_create_t>::const_iterator p = m->mkpg.begin();\n       p != m->mkpg.end();\n       ++p, ++ci) {\n    assert(ci != m->ctimes.end() && ci->first == p->first);\n    epoch_t created = p->second.created;\n    if (p->second.split_bits) // Skip split pgs\n      continue;\n    pg_t on = p->first;\n\n    if (on.preferred() >= 0) {\n      dout(20) << \"ignoring localized pg \" << on << dendl;\n      continue;\n    }\n\n    if (!osdmap->have_pg_pool(on.pool())) {\n      dout(20) << \"ignoring pg on deleted pool \" << on << dendl;\n      continue;\n    }\n\n    dout(20) << \"mkpg \" << on << \" e\" << created << \"@\" << ci->second << dendl;\n\n    // is it still ours?\n    vector<int> up, acting;\n    int up_primary = -1;\n    int acting_primary = -1;\n    osdmap->pg_to_up_acting_osds(on, &up, &up_primary, &acting, &acting_primary);\n    int role = osdmap->calc_pg_role(whoami, acting, acting.size());\n\n    if (acting_primary != whoami) {\n      dout(10) << \"mkpg \" << on << \"  not acting_primary (\" << acting_primary\n\t       << \"), my role=\" << role << \", skipping\" << dendl;\n      continue;\n    }\n\n    spg_t pgid;\n    bool mapped = osdmap->get_primary_shard(on, &pgid);\n    assert(mapped);\n\n    PastIntervals pi(\n      osdmap->get_pools().at(pgid.pool()).ec_pool(),\n      *osdmap);\n    pg_history_t history;\n    build_initial_pg_history(pgid, created, ci->second, &history, &pi);\n\n    // The mon won't resend unless the primary changed, so\n    // we ignore same_interval_since.  We'll pass this history\n    // to handle_pg_peering_evt with the current epoch as the\n    // event -- the project_pg_history check in\n    // handle_pg_peering_evt will be a noop.\n    if (history.same_primary_since > m->epoch) {\n      dout(10) << __func__ << \": got obsolete pg create on pgid \"\n\t       << pgid << \" from epoch \" << m->epoch\n\t       << \", primary changed in \" << history.same_primary_since\n\t       << dendl;\n      continue;\n    }\n    if (handle_pg_peering_evt(\n          pgid,\n          history,\n          pi,\n          osdmap->get_epoch(),\n          PG::CephPeeringEvtRef(\n\t    new PG::CephPeeringEvt(\n\t      osdmap->get_epoch(),\n\t      osdmap->get_epoch(),\n\t      PG::NullEvt()))\n          ) == -EEXIST) {\n      service.send_pg_created(pgid.pgid);\n    }\n  }\n\n  {\n    lock_guard<mutex> pending_creates_locker{pending_creates_lock};\n    if (pending_creates_from_mon == 0) {\n      last_pg_create_epoch = m->epoch;\n    }\n  }\n  maybe_update_heartbeat_peers();\n}\n\n\n// ----------------------------------------\n// peering and recovery\n\nPG::RecoveryCtx OSD::create_context()\n{\n  ObjectStore::Transaction *t = new ObjectStore::Transaction;\n  C_Contexts *on_applied = new C_Contexts(cct);\n  C_Contexts *on_safe = new C_Contexts(cct);\n  map<int, map<spg_t,pg_query_t> > *query_map =\n    new map<int, map<spg_t, pg_query_t> >;\n  map<int,vector<pair<pg_notify_t, PastIntervals> > > *notify_list =\n    new map<int, vector<pair<pg_notify_t, PastIntervals> > >;\n  map<int,vector<pair<pg_notify_t, PastIntervals> > > *info_map =\n    new map<int,vector<pair<pg_notify_t, PastIntervals> > >;\n  PG::RecoveryCtx rctx(query_map, info_map, notify_list,\n\t\t       on_applied, on_safe, t);\n  return rctx;\n}\n\nstruct C_OpenPGs : public Context {\n  set<PGRef> pgs;\n  ObjectStore *store;\n  OSD *osd;\n  C_OpenPGs(set<PGRef>& p, ObjectStore *s, OSD* o) : store(s), osd(o) {\n    pgs.swap(p);\n  }\n  void finish(int r) override {\n    RWLock::RLocker l(osd->pg_map_lock);\n    for (auto p : pgs) {\n      if (osd->pg_map.count(p->info.pgid)) {\n        p->ch = store->open_collection(p->coll);\n        assert(p->ch);\n      }\n    }\n  }\n};\n\nvoid OSD::dispatch_context_transaction(PG::RecoveryCtx &ctx, PG *pg,\n                                       ThreadPool::TPHandle *handle)\n{\n  if (!ctx.transaction->empty()) {\n    if (!ctx.created_pgs.empty()) {\n      ctx.on_applied->add(new C_OpenPGs(ctx.created_pgs, store, this));\n    }\n    int tr = store->queue_transaction(\n      pg->osr.get(),\n      std::move(*ctx.transaction), ctx.on_applied, ctx.on_safe, NULL,\n      TrackedOpRef(), handle);\n    delete (ctx.transaction);\n    assert(tr == 0);\n    ctx.transaction = new ObjectStore::Transaction;\n    ctx.on_applied = new C_Contexts(cct);\n    ctx.on_safe = new C_Contexts(cct);\n  }\n}\n\nvoid OSD::dispatch_context(PG::RecoveryCtx &ctx, PG *pg, OSDMapRef curmap,\n                           ThreadPool::TPHandle *handle)\n{\n  if (service.get_osdmap()->is_up(whoami) &&\n      is_active()) {\n    do_notifies(*ctx.notify_list, curmap);\n    do_queries(*ctx.query_map, curmap);\n    do_infos(*ctx.info_map, curmap);\n  }\n  delete ctx.notify_list;\n  delete ctx.query_map;\n  delete ctx.info_map;\n  if ((ctx.on_applied->empty() &&\n       ctx.on_safe->empty() &&\n       ctx.transaction->empty() &&\n       ctx.created_pgs.empty()) || !pg) {\n    delete ctx.transaction;\n    delete ctx.on_applied;\n    delete ctx.on_safe;\n    assert(ctx.created_pgs.empty());\n  } else {\n    if (!ctx.created_pgs.empty()) {\n      ctx.on_applied->add(new C_OpenPGs(ctx.created_pgs, store, this));\n    }\n    int tr = store->queue_transaction(\n      pg->osr.get(),\n      std::move(*ctx.transaction), ctx.on_applied, ctx.on_safe, NULL, TrackedOpRef(),\n      handle);\n    delete (ctx.transaction);\n    assert(tr == 0);\n  }\n}\n\n/** do_notifies\n * Send an MOSDPGNotify to a primary, with a list of PGs that I have\n * content for, and they are primary for.\n */\n\nvoid OSD::do_notifies(\n  map<int,vector<pair<pg_notify_t,PastIntervals> > >& notify_list,\n  OSDMapRef curmap)\n{\n  for (map<int,\n\t   vector<pair<pg_notify_t,PastIntervals> > >::iterator it =\n\t notify_list.begin();\n       it != notify_list.end();\n       ++it) {\n    if (!curmap->is_up(it->first)) {\n      dout(20) << __func__ << \" skipping down osd.\" << it->first << dendl;\n      continue;\n    }\n    ConnectionRef con = service.get_con_osd_cluster(\n      it->first, curmap->get_epoch());\n    if (!con) {\n      dout(20) << __func__ << \" skipping osd.\" << it->first\n\t       << \" (NULL con)\" << dendl;\n      continue;\n    }\n    service.share_map_peer(it->first, con.get(), curmap);\n    dout(7) << __func__ << \" osd.\" << it->first\n\t    << \" on \" << it->second.size() << \" PGs\" << dendl;\n    MOSDPGNotify *m = new MOSDPGNotify(curmap->get_epoch(),\n\t\t\t\t       it->second);\n    con->send_message(m);\n  }\n}\n\n\n/** do_queries\n * send out pending queries for info | summaries\n */\nvoid OSD::do_queries(map<int, map<spg_t,pg_query_t> >& query_map,\n\t\t     OSDMapRef curmap)\n{\n  for (map<int, map<spg_t,pg_query_t> >::iterator pit = query_map.begin();\n       pit != query_map.end();\n       ++pit) {\n    if (!curmap->is_up(pit->first)) {\n      dout(20) << __func__ << \" skipping down osd.\" << pit->first << dendl;\n      continue;\n    }\n    int who = pit->first;\n    ConnectionRef con = service.get_con_osd_cluster(who, curmap->get_epoch());\n    if (!con) {\n      dout(20) << __func__ << \" skipping osd.\" << who\n\t       << \" (NULL con)\" << dendl;\n      continue;\n    }\n    service.share_map_peer(who, con.get(), curmap);\n    dout(7) << __func__ << \" querying osd.\" << who\n\t    << \" on \" << pit->second.size() << \" PGs\" << dendl;\n    MOSDPGQuery *m = new MOSDPGQuery(curmap->get_epoch(), pit->second);\n    con->send_message(m);\n  }\n}\n\n\nvoid OSD::do_infos(map<int,\n\t\t       vector<pair<pg_notify_t, PastIntervals> > >& info_map,\n\t\t   OSDMapRef curmap)\n{\n  for (map<int,\n\t   vector<pair<pg_notify_t, PastIntervals> > >::iterator p =\n\t info_map.begin();\n       p != info_map.end();\n       ++p) {\n    if (!curmap->is_up(p->first)) {\n      dout(20) << __func__ << \" skipping down osd.\" << p->first << dendl;\n      continue;\n    }\n    for (vector<pair<pg_notify_t,PastIntervals> >::iterator i = p->second.begin();\n\t i != p->second.end();\n\t ++i) {\n      dout(20) << __func__ << \" sending info \" << i->first.info\n\t       << \" to shard \" << p->first << dendl;\n    }\n    ConnectionRef con = service.get_con_osd_cluster(\n      p->first, curmap->get_epoch());\n    if (!con) {\n      dout(20) << __func__ << \" skipping osd.\" << p->first\n\t       << \" (NULL con)\" << dendl;\n      continue;\n    }\n    service.share_map_peer(p->first, con.get(), curmap);\n    MOSDPGInfo *m = new MOSDPGInfo(curmap->get_epoch());\n    m->pg_list = p->second;\n    con->send_message(m);\n  }\n  info_map.clear();\n}\n\n\n/** PGNotify\n * from non-primary to primary\n * includes pg_info_t.\n * NOTE: called with opqueue active.\n */\nvoid OSD::handle_pg_notify(OpRequestRef op)\n{\n  const MOSDPGNotify *m = static_cast<const MOSDPGNotify*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_NOTIFY);\n\n  dout(7) << \"handle_pg_notify from \" << m->get_source() << dendl;\n  int from = m->get_source().num();\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  if (!require_same_or_newer_map(op, m->get_epoch(), false))\n    return;\n\n  op->mark_started();\n\n  for (auto it = m->get_pg_list().begin();\n       it != m->get_pg_list().end();\n       ++it) {\n    if (it->first.info.pgid.preferred() >= 0) {\n      dout(20) << \"ignoring localized pg \" << it->first.info.pgid << dendl;\n      continue;\n    }\n\n    handle_pg_peering_evt(\n      spg_t(it->first.info.pgid.pgid, it->first.to),\n      it->first.info.history, it->second,\n      it->first.query_epoch,\n      PG::CephPeeringEvtRef(\n\tnew PG::CephPeeringEvt(\n\t  it->first.epoch_sent, it->first.query_epoch,\n\t  PG::MNotifyRec(pg_shard_t(from, it->first.from), it->first,\n          op->get_req()->get_connection()->get_features())))\n      );\n  }\n}\n\nvoid OSD::handle_pg_log(OpRequestRef op)\n{\n  MOSDPGLog *m = static_cast<MOSDPGLog*>(op->get_nonconst_req());\n  assert(m->get_type() == MSG_OSD_PG_LOG);\n  dout(7) << \"handle_pg_log \" << *m << \" from \" << m->get_source() << dendl;\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  int from = m->get_source().num();\n  if (!require_same_or_newer_map(op, m->get_epoch(), false))\n    return;\n\n  if (m->info.pgid.preferred() >= 0) {\n    dout(10) << \"ignoring localized pg \" << m->info.pgid << dendl;\n    return;\n  }\n\n  op->mark_started();\n  handle_pg_peering_evt(\n    spg_t(m->info.pgid.pgid, m->to),\n    m->info.history, m->past_intervals, m->get_epoch(),\n    PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->get_epoch(), m->get_query_epoch(),\n\tPG::MLogRec(pg_shard_t(from, m->from), m)))\n    );\n}\n\nvoid OSD::handle_pg_info(OpRequestRef op)\n{\n  const MOSDPGInfo *m = static_cast<const MOSDPGInfo *>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_INFO);\n  dout(7) << \"handle_pg_info \" << *m << \" from \" << m->get_source() << dendl;\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  int from = m->get_source().num();\n  if (!require_same_or_newer_map(op, m->get_epoch(), false))\n    return;\n\n  op->mark_started();\n\n  for (auto p = m->pg_list.begin();\n       p != m->pg_list.end();\n       ++p) {\n    if (p->first.info.pgid.preferred() >= 0) {\n      dout(10) << \"ignoring localized pg \" << p->first.info.pgid << dendl;\n      continue;\n    }\n\n    handle_pg_peering_evt(\n      spg_t(p->first.info.pgid.pgid, p->first.to),\n      p->first.info.history, p->second, p->first.epoch_sent,\n      PG::CephPeeringEvtRef(\n\tnew PG::CephPeeringEvt(\n\t  p->first.epoch_sent, p->first.query_epoch,\n\t  PG::MInfoRec(\n\t    pg_shard_t(\n\t      from, p->first.from), p->first.info, p->first.epoch_sent)))\n      );\n  }\n}\n\nvoid OSD::handle_pg_trim(OpRequestRef op)\n{\n  const MOSDPGTrim *m = static_cast<const MOSDPGTrim*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_TRIM);\n\n  dout(7) << \"handle_pg_trim \" << *m << \" from \" << m->get_source() << dendl;\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  int from = m->get_source().num();\n  if (!require_same_or_newer_map(op, m->epoch, false))\n    return;\n\n  if (m->pgid.preferred() >= 0) {\n    dout(10) << \"ignoring localized pg \" << m->pgid << dendl;\n    return;\n  }\n\n  op->mark_started();\n\n  PG *pg = _lookup_lock_pg(m->pgid);\n  if(!pg) {\n    dout(10) << \" don't have pg \" << m->pgid << dendl;\n    return;\n  }\n\n  if (m->epoch < pg->info.history.same_interval_since) {\n    dout(10) << *pg << \" got old trim to \" << m->trim_to << \", ignoring\" << dendl;\n    pg->unlock();\n    return;\n  }\n\n  if (pg->is_primary()) {\n    // peer is informing us of their last_complete_ondisk\n    dout(10) << *pg << \" replica osd.\" << from << \" lcod \" << m->trim_to << dendl;\n    pg->peer_last_complete_ondisk[pg_shard_t(from, m->pgid.shard)] =\n      m->trim_to;\n    // trim log when the pg is recovered\n    pg->calc_min_last_complete_ondisk();\n  } else {\n    // primary is instructing us to trim\n    ObjectStore::Transaction t;\n    pg->pg_log.trim(m->trim_to, pg->info);\n    pg->dirty_info = true;\n    pg->write_if_dirty(t);\n    int tr = store->queue_transaction(pg->osr.get(), std::move(t), NULL);\n    assert(tr == 0);\n  }\n  pg->unlock();\n}\n\nvoid OSD::handle_pg_backfill_reserve(OpRequestRef op)\n{\n  const MBackfillReserve *m = static_cast<const MBackfillReserve*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_BACKFILL_RESERVE);\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n  if (!require_same_or_newer_map(op, m->query_epoch, false))\n    return;\n\n  PG::CephPeeringEvtRef evt;\n  if (m->type == MBackfillReserve::REQUEST) {\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RequestBackfillPrio(m->priority)));\n  } else if (m->type == MBackfillReserve::GRANT) {\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RemoteBackfillReserved()));\n  } else if (m->type == MBackfillReserve::REJECT) {\n    // NOTE: this is replica -> primary \"i reject your request\"\n    //      and also primary -> replica \"cancel my previously-granted request\"\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RemoteReservationRejected()));\n  } else {\n    ceph_abort();\n  }\n\n  if (service.splitting(m->pgid)) {\n    peering_wait_for_split[m->pgid].push_back(evt);\n    return;\n  }\n\n  PG *pg = _lookup_lock_pg(m->pgid);\n  if (!pg) {\n    dout(10) << \" don't have pg \" << m->pgid << dendl;\n    return;\n  }\n\n  pg->queue_peering_event(evt);\n  pg->unlock();\n}\n\nvoid OSD::handle_pg_recovery_reserve(OpRequestRef op)\n{\n  const MRecoveryReserve *m = static_cast<const MRecoveryReserve*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_RECOVERY_RESERVE);\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n  if (!require_same_or_newer_map(op, m->query_epoch, false))\n    return;\n\n  PG::CephPeeringEvtRef evt;\n  if (m->type == MRecoveryReserve::REQUEST) {\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RequestRecovery()));\n  } else if (m->type == MRecoveryReserve::GRANT) {\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RemoteRecoveryReserved()));\n  } else if (m->type == MRecoveryReserve::RELEASE) {\n    evt = PG::CephPeeringEvtRef(\n      new PG::CephPeeringEvt(\n\tm->query_epoch,\n\tm->query_epoch,\n\tPG::RecoveryDone()));\n  } else {\n    ceph_abort();\n  }\n\n  if (service.splitting(m->pgid)) {\n    peering_wait_for_split[m->pgid].push_back(evt);\n    return;\n  }\n\n  PG *pg = _lookup_lock_pg(m->pgid);\n  if (!pg) {\n    dout(10) << \" don't have pg \" << m->pgid << dendl;\n    return;\n  }\n\n  pg->queue_peering_event(evt);\n  pg->unlock();\n}\n\nvoid OSD::handle_force_recovery(Message *m)\n{\n  MOSDForceRecovery *msg = static_cast<MOSDForceRecovery*>(m);\n  assert(msg->get_type() == MSG_OSD_FORCE_RECOVERY);\n\n  vector<PGRef> local_pgs;\n  local_pgs.reserve(msg->forced_pgs.size());\n\n  {\n    RWLock::RLocker l(pg_map_lock);\n    for (auto& i : msg->forced_pgs) {\n      spg_t locpg;\n      if (osdmap->get_primary_shard(i, &locpg)) {\n\tauto pg_map_entry = pg_map.find(locpg);\n\tif (pg_map_entry != pg_map.end()) {\n\t  local_pgs.push_back(pg_map_entry->second);\n\t}\n      }\n    }\n  }\n\n  if (local_pgs.size()) {\n    service.adjust_pg_priorities(local_pgs, msg->options);\n  }\n\n  msg->put();\n}\n\n/** PGQuery\n * from primary to replica | stray\n * NOTE: called with opqueue active.\n */\nvoid OSD::handle_pg_query(OpRequestRef op)\n{\n  assert(osd_lock.is_locked());\n\n  const MOSDPGQuery *m = static_cast<const MOSDPGQuery*>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_QUERY);\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  dout(7) << \"handle_pg_query from \" << m->get_source() << \" epoch \" << m->get_epoch() << dendl;\n  int from = m->get_source().num();\n\n  if (!require_same_or_newer_map(op, m->get_epoch(), false))\n    return;\n\n  op->mark_started();\n\n  map< int, vector<pair<pg_notify_t, PastIntervals> > > notify_list;\n\n  for (auto it = m->pg_list.begin();\n       it != m->pg_list.end();\n       ++it) {\n    spg_t pgid = it->first;\n\n    if (pgid.preferred() >= 0) {\n      dout(10) << \"ignoring localized pg \" << pgid << dendl;\n      continue;\n    }\n\n    if (service.splitting(pgid)) {\n      peering_wait_for_split[pgid].push_back(\n\tPG::CephPeeringEvtRef(\n\t  new PG::CephPeeringEvt(\n\t    it->second.epoch_sent, it->second.epoch_sent,\n\t    PG::MQuery(pg_shard_t(from, it->second.from),\n\t\t       it->second, it->second.epoch_sent))));\n      continue;\n    }\n\n    {\n      RWLock::RLocker l(pg_map_lock);\n      if (pg_map.count(pgid)) {\n        PG *pg = 0;\n        pg = _lookup_lock_pg_with_map_lock_held(pgid);\n        pg->queue_query(\n            it->second.epoch_sent, it->second.epoch_sent,\n            pg_shard_t(from, it->second.from), it->second);\n        pg->unlock();\n        continue;\n      }\n    }\n\n    if (!osdmap->have_pg_pool(pgid.pool()))\n      continue;\n\n    // get active crush mapping\n    int up_primary, acting_primary;\n    vector<int> up, acting;\n    osdmap->pg_to_up_acting_osds(\n      pgid.pgid, &up, &up_primary, &acting, &acting_primary);\n\n    // same primary?\n    pg_history_t history = it->second.history;\n    bool valid_history = project_pg_history(\n      pgid, history, it->second.epoch_sent,\n      up, up_primary, acting, acting_primary);\n\n    if (!valid_history ||\n        it->second.epoch_sent < history.same_interval_since) {\n      dout(10) << \" pg \" << pgid << \" dne, and pg has changed in \"\n\t       << history.same_interval_since\n\t       << \" (msg from \" << it->second.epoch_sent << \")\" << dendl;\n      continue;\n    }\n\n    dout(10) << \" pg \" << pgid << \" dne\" << dendl;\n    pg_info_t empty(spg_t(pgid.pgid, it->second.to));\n    /* This is racy, but that should be ok: if we complete the deletion\n     * before the pg is recreated, we'll just start it off backfilling\n     * instead of just empty */\n    if (service.deleting_pgs.lookup(pgid))\n      empty.set_last_backfill(hobject_t());\n    if (it->second.type == pg_query_t::LOG ||\n\tit->second.type == pg_query_t::FULLLOG) {\n      ConnectionRef con = service.get_con_osd_cluster(from, osdmap->get_epoch());\n      if (con) {\n\tMOSDPGLog *mlog = new MOSDPGLog(\n\t  it->second.from, it->second.to,\n\t  osdmap->get_epoch(), empty,\n\t  it->second.epoch_sent);\n\tservice.share_map_peer(from, con.get(), osdmap);\n\tcon->send_message(mlog);\n      }\n    } else {\n      notify_list[from].push_back(\n\tmake_pair(\n\t  pg_notify_t(\n\t    it->second.from, it->second.to,\n\t    it->second.epoch_sent,\n\t    osdmap->get_epoch(),\n\t    empty),\n\t  PastIntervals(\n\t    osdmap->get_pools().at(pgid.pool()).ec_pool(),\n\t    *osdmap)));\n    }\n  }\n  do_notifies(notify_list, osdmap);\n}\n\n\nvoid OSD::handle_pg_remove(OpRequestRef op)\n{\n  const MOSDPGRemove *m = static_cast<const MOSDPGRemove *>(op->get_req());\n  assert(m->get_type() == MSG_OSD_PG_REMOVE);\n  assert(osd_lock.is_locked());\n\n  if (!require_osd_peer(op->get_req()))\n    return;\n\n  dout(7) << \"handle_pg_remove from \" << m->get_source() << \" on \"\n\t  << m->pg_list.size() << \" pgs\" << dendl;\n\n  if (!require_same_or_newer_map(op, m->get_epoch(), false))\n    return;\n\n  op->mark_started();\n\n  for (auto it = m->pg_list.begin();\n       it != m->pg_list.end();\n       ++it) {\n    spg_t pgid = *it;\n    if (pgid.preferred() >= 0) {\n      dout(10) << \"ignoring localized pg \" << pgid << dendl;\n      continue;\n    }\n\n    RWLock::WLocker l(pg_map_lock);\n    if (pg_map.count(pgid) == 0) {\n      dout(10) << \" don't have pg \" << pgid << dendl;\n      continue;\n    }\n    dout(5) << \"queue_pg_for_deletion: \" << pgid << dendl;\n    PG *pg = _lookup_lock_pg_with_map_lock_held(pgid);\n    pg_history_t history = pg->info.history;\n    int up_primary, acting_primary;\n    vector<int> up, acting;\n    osdmap->pg_to_up_acting_osds(\n      pgid.pgid, &up, &up_primary, &acting, &acting_primary);\n    bool valid_history = project_pg_history(\n      pg->info.pgid, history, pg->get_osdmap()->get_epoch(),\n      up, up_primary, acting, acting_primary);\n    if (valid_history &&\n        history.same_interval_since <= m->get_epoch()) {\n      assert(pg->get_primary().osd == m->get_source().num());\n      PGRef _pg(pg);\n      _remove_pg(pg);\n      pg->unlock();\n    } else {\n      dout(10) << *pg << \" ignoring remove request, pg changed in epoch \"\n\t       << history.same_interval_since\n\t       << \" > \" << m->get_epoch() << dendl;\n      pg->unlock();\n    }\n  }\n}\n\nvoid OSD::_remove_pg(PG *pg)\n{\n  ObjectStore::Transaction rmt ;\n\n  // on_removal, which calls remove_watchers_and_notifies, and the erasure from\n  // the pg_map must be done together without unlocking the pg lock,\n  // to avoid racing with watcher cleanup in ms_handle_reset\n  // and handle_notify_timeout\n  pg->on_removal(&rmt);\n\n  service.cancel_pending_splits_for_parent(pg->info.pgid);\n  int tr = store->queue_transaction(\n    pg->osr.get(), std::move(rmt), NULL, \n    new ContainerContext<\n      SequencerRef>(pg->osr));\n  assert(tr == 0);\n\n  DeletingStateRef deleting = service.deleting_pgs.lookup_or_create(\n    pg->info.pgid,\n    make_pair(\n      pg->info.pgid,\n      PGRef(pg))\n    );\n  remove_wq.queue(make_pair(PGRef(pg), deleting));\n\n  service.pg_remove_epoch(pg->info.pgid);\n\n  // dereference from op_wq\n  op_shardedwq.clear_pg_pointer(pg->info.pgid);\n\n  // remove from map\n  pg_map.erase(pg->info.pgid);\n  pg->put(\"PGMap\"); // since we've taken it out of map\n}\n\n// =========================================================\n// RECOVERY\n\nvoid OSDService::_maybe_queue_recovery() {\n  assert(recovery_lock.is_locked_by_me());\n  uint64_t available_pushes;\n  while (!awaiting_throttle.empty() &&\n\t _recover_now(&available_pushes)) {\n    uint64_t to_start = MIN(\n      available_pushes,\n      cct->_conf->osd_recovery_max_single_start);\n    _queue_for_recovery(awaiting_throttle.front(), to_start);\n    awaiting_throttle.pop_front();\n    recovery_ops_reserved += to_start;\n  }\n}\n\nbool OSDService::_recover_now(uint64_t *available_pushes)\n{\n  if (available_pushes)\n      *available_pushes = 0;\n\n  if (ceph_clock_now() < defer_recovery_until) {\n    dout(15) << __func__ << \" defer until \" << defer_recovery_until << dendl;\n    return false;\n  }\n\n  if (recovery_paused) {\n    dout(15) << __func__ << \" paused\" << dendl;\n    return false;\n  }\n\n  uint64_t max = cct->_conf->osd_recovery_max_active;\n  if (max <= recovery_ops_active + recovery_ops_reserved) {\n    dout(15) << __func__ << \" active \" << recovery_ops_active\n\t     << \" + reserved \" << recovery_ops_reserved\n\t     << \" >= max \" << max << dendl;\n    return false;\n  }\n\n  if (available_pushes)\n    *available_pushes = max - recovery_ops_active - recovery_ops_reserved;\n\n  return true;\n}\n\n\nvoid OSDService::adjust_pg_priorities(const vector<PGRef>& pgs, int newflags)\n{\n  if (!pgs.size() || !(newflags & (OFR_BACKFILL | OFR_RECOVERY)))\n    return;\n  int newstate = 0;\n\n  if (newflags & OFR_BACKFILL) {\n    newstate = PG_STATE_FORCED_BACKFILL;\n  } else if (newflags & OFR_RECOVERY) {\n    newstate = PG_STATE_FORCED_RECOVERY;\n  }\n\n  // debug output here may get large, don't generate it if debug level is below\n  // 10 and use abbreviated pg ids otherwise\n  if ((cct)->_conf->subsys.should_gather(ceph_subsys_osd, 10)) {\n    stringstream ss;\n\n    for (auto& i : pgs) {\n      ss << i->get_pgid() << \" \";\n    }\n\n    dout(10) << __func__ << \" working on \" << ss.str() << dendl;\n  }\n\n  if (newflags & OFR_CANCEL) {\n    for (auto& i : pgs) {\n      i->lock();\n      i->_change_recovery_force_mode(newstate, true);\n      i->unlock();\n    }\n  } else {\n    for (auto& i : pgs) {\n      // make sure the PG is in correct state before forcing backfill or recovery, or\n      // else we'll make PG keeping FORCE_* flag forever, requiring osds restart\n      // or forcing somehow recovery/backfill.\n      i->lock();\n      int pgstate = i->get_state();\n      if ( ((newstate == PG_STATE_FORCED_RECOVERY) && (pgstate & (PG_STATE_DEGRADED | PG_STATE_RECOVERY_WAIT | PG_STATE_RECOVERING))) ||\n\t    ((newstate == PG_STATE_FORCED_BACKFILL) && (pgstate & (PG_STATE_DEGRADED | PG_STATE_BACKFILL_WAIT | PG_STATE_BACKFILLING))) )\n        i->_change_recovery_force_mode(newstate, false);\n      i->unlock();\n    }\n  }\n}\n\nvoid OSD::do_recovery(\n  PG *pg, epoch_t queued, uint64_t reserved_pushes,\n  ThreadPool::TPHandle &handle)\n{\n  uint64_t started = 0;\n\n  /*\n   * When the value of osd_recovery_sleep is set greater than zero, recovery\n   * ops are scheduled after osd_recovery_sleep amount of time from the previous\n   * recovery event's schedule time. This is done by adding a\n   * recovery_requeue_callback event, which re-queues the recovery op using\n   * queue_recovery_after_sleep.\n   */\n  float recovery_sleep = get_osd_recovery_sleep();\n  {\n    Mutex::Locker l(service.recovery_sleep_lock);\n    if (recovery_sleep > 0 && service.recovery_needs_sleep) {\n      PGRef pgref(pg);\n      auto recovery_requeue_callback = new FunctionContext([this, pgref, queued, reserved_pushes](int r) {\n        dout(20) << \"do_recovery wake up at \"\n                 << ceph_clock_now()\n\t         << \", re-queuing recovery\" << dendl;\n\tMutex::Locker l(service.recovery_sleep_lock);\n        service.recovery_needs_sleep = false;\n        service.queue_recovery_after_sleep(pgref.get(), queued, reserved_pushes);\n      });\n\n      // This is true for the first recovery op and when the previous recovery op\n      // has been scheduled in the past. The next recovery op is scheduled after\n      // completing the sleep from now.\n      if (service.recovery_schedule_time < ceph_clock_now()) {\n        service.recovery_schedule_time = ceph_clock_now();\n      }\n      service.recovery_schedule_time += recovery_sleep;\n      service.recovery_sleep_timer.add_event_at(service.recovery_schedule_time,\n\t                                        recovery_requeue_callback);\n      dout(20) << \"Recovery event scheduled at \"\n               << service.recovery_schedule_time << dendl;\n      return;\n    }\n  }\n\n  {\n    {\n      Mutex::Locker l(service.recovery_sleep_lock);\n      service.recovery_needs_sleep = true;\n    }\n\n    if (pg->pg_has_reset_since(queued)) {\n      goto out;\n    }\n\n    assert(!pg->deleting);\n    assert(pg->is_peered() && pg->is_primary());\n\n    assert(pg->recovery_queued);\n    pg->recovery_queued = false;\n\n    dout(10) << \"do_recovery starting \" << reserved_pushes << \" \" << *pg << dendl;\n#ifdef DEBUG_RECOVERY_OIDS\n    dout(20) << \"  active was \" << service.recovery_oids[pg->info.pgid] << dendl;\n#endif\n\n    bool more = pg->start_recovery_ops(reserved_pushes, handle, &started);\n    dout(10) << \"do_recovery started \" << started << \"/\" << reserved_pushes \n\t     << \" on \" << *pg << dendl;\n\n    // If no recovery op is started, don't bother to manipulate the RecoveryCtx\n    if (!started && (more || !pg->have_unfound())) {\n      goto out;\n    }\n\n    PG::RecoveryCtx rctx = create_context();\n    rctx.handle = &handle;\n\n    /*\n     * if we couldn't start any recovery ops and things are still\n     * unfound, see if we can discover more missing object locations.\n     * It may be that our initial locations were bad and we errored\n     * out while trying to pull.\n     */\n    if (!more && pg->have_unfound()) {\n      pg->discover_all_missing(*rctx.query_map);\n      if (rctx.query_map->empty()) {\n\tstring action;\n        if (pg->state_test(PG_STATE_BACKFILLING)) {\n\t  auto evt = PG::CephPeeringEvtRef(new PG::CephPeeringEvt(\n\t    queued,\n\t    queued,\n\t    PG::DeferBackfill(cct->_conf->osd_recovery_retry_interval)));\n\t  pg->queue_peering_event(evt);\n\t  action = \"in backfill\";\n        } else if (pg->state_test(PG_STATE_RECOVERING)) {\n\t  auto evt = PG::CephPeeringEvtRef(new PG::CephPeeringEvt(\n\t    queued,\n\t    queued,\n\t    PG::DeferRecovery(cct->_conf->osd_recovery_retry_interval)));\n\t  pg->queue_peering_event(evt);\n\t  action = \"in recovery\";\n\t} else {\n\t  action = \"already out of recovery/backfill\";\n\t}\n\tdout(10) << __func__ << \": no luck, giving up on this pg for now (\" << action << \")\" << dendl;\n      } else {\n\tdout(10) << __func__ << \": no luck, giving up on this pg for now (queue_recovery)\" << dendl;\n\tpg->queue_recovery();\n      }\n    }\n\n    pg->write_if_dirty(*rctx.transaction);\n    OSDMapRef curmap = pg->get_osdmap();\n    dispatch_context(rctx, pg, curmap);\n  }\n\n out:\n  assert(started <= reserved_pushes);\n  service.release_reserved_pushes(reserved_pushes);\n}\n\nvoid OSDService::start_recovery_op(PG *pg, const hobject_t& soid)\n{\n  Mutex::Locker l(recovery_lock);\n  dout(10) << \"start_recovery_op \" << *pg << \" \" << soid\n\t   << \" (\" << recovery_ops_active << \"/\"\n\t   << cct->_conf->osd_recovery_max_active << \" rops)\"\n\t   << dendl;\n  recovery_ops_active++;\n\n#ifdef DEBUG_RECOVERY_OIDS\n  dout(20) << \"  active was \" << recovery_oids[pg->info.pgid] << dendl;\n  assert(recovery_oids[pg->info.pgid].count(soid) == 0);\n  recovery_oids[pg->info.pgid].insert(soid);\n#endif\n}\n\nvoid OSDService::finish_recovery_op(PG *pg, const hobject_t& soid, bool dequeue)\n{\n  Mutex::Locker l(recovery_lock);\n  dout(10) << \"finish_recovery_op \" << *pg << \" \" << soid\n\t   << \" dequeue=\" << dequeue\n\t   << \" (\" << recovery_ops_active << \"/\" << cct->_conf->osd_recovery_max_active << \" rops)\"\n\t   << dendl;\n\n  // adjust count\n  assert(recovery_ops_active > 0);\n  recovery_ops_active--;\n\n#ifdef DEBUG_RECOVERY_OIDS\n  dout(20) << \"  active oids was \" << recovery_oids[pg->info.pgid] << dendl;\n  assert(recovery_oids[pg->info.pgid].count(soid));\n  recovery_oids[pg->info.pgid].erase(soid);\n#endif\n\n  _maybe_queue_recovery();\n}\n\nbool OSDService::is_recovery_active()\n{\n  return local_reserver.has_reservation() || remote_reserver.has_reservation();\n}\n\n// =========================================================\n// OPS\n\nbool OSD::op_is_discardable(const MOSDOp *op)\n{\n  // drop client request if they are not connected and can't get the\n  // reply anyway.\n  if (!op->get_connection()->is_connected()) {\n    return true;\n  }\n  return false;\n}\n\nvoid OSD::enqueue_op(spg_t pg, OpRequestRef& op, epoch_t epoch)\n{\n  utime_t latency = ceph_clock_now() - op->get_req()->get_recv_stamp();\n  dout(15) << \"enqueue_op \" << op << \" prio \" << op->get_req()->get_priority()\n\t   << \" cost \" << op->get_req()->get_cost()\n\t   << \" latency \" << latency\n\t   << \" epoch \" << epoch\n\t   << \" \" << *(op->get_req()) << dendl;\n  op->osd_trace.event(\"enqueue op\");\n  op->osd_trace.keyval(\"priority\", op->get_req()->get_priority());\n  op->osd_trace.keyval(\"cost\", op->get_req()->get_cost());\n  op->mark_queued_for_pg();\n  logger->tinc(l_osd_op_before_queue_op_lat, latency);\n  op_shardedwq.queue(make_pair(pg, PGQueueable(op, epoch)));\n}\n\n\n\n/*\n * NOTE: dequeue called in worker thread, with pg lock\n */\nvoid OSD::dequeue_op(\n  PGRef pg, OpRequestRef op,\n  ThreadPool::TPHandle &handle)\n{\n  FUNCTRACE();\n  OID_EVENT_TRACE_WITH_MSG(op->get_req(), \"DEQUEUE_OP_BEGIN\", false);\n\n  utime_t now = ceph_clock_now();\n  op->set_dequeued_time(now);\n  utime_t latency = now - op->get_req()->get_recv_stamp();\n  dout(10) << \"dequeue_op \" << op << \" prio \" << op->get_req()->get_priority()\n\t   << \" cost \" << op->get_req()->get_cost()\n\t   << \" latency \" << latency\n\t   << \" \" << *(op->get_req())\n\t   << \" pg \" << *pg << dendl;\n\n  logger->tinc(l_osd_op_before_dequeue_op_lat, latency);\n\n  Session *session = static_cast<Session *>(\n    op->get_req()->get_connection()->get_priv());\n  if (session) {\n    maybe_share_map(session, op, pg->get_osdmap());\n    session->put();\n  }\n\n  if (pg->deleting)\n    return;\n\n  op->mark_reached_pg();\n  op->osd_trace.event(\"dequeue_op\");\n\n  pg->do_request(op, handle);\n\n  // finish\n  dout(10) << \"dequeue_op \" << op << \" finish\" << dendl;\n  OID_EVENT_TRACE_WITH_MSG(op->get_req(), \"DEQUEUE_OP_END\", false);\n}\n\n\nstruct C_CompleteSplits : public Context {\n  OSD *osd;\n  set<PGRef> pgs;\n  C_CompleteSplits(OSD *osd, const set<PGRef> &in)\n    : osd(osd), pgs(in) {}\n  void finish(int r) override {\n    Mutex::Locker l(osd->osd_lock);\n    if (osd->is_stopping())\n      return;\n    PG::RecoveryCtx rctx = osd->create_context();\n    for (set<PGRef>::iterator i = pgs.begin();\n\t i != pgs.end();\n\t ++i) {\n      osd->pg_map_lock.get_write();\n      (*i)->lock();\n      PG *pg = i->get();\n      osd->add_newly_split_pg(pg, &rctx);\n      if (!((*i)->deleting)) {\n        set<spg_t> to_complete;\n        to_complete.insert((*i)->info.pgid);\n        osd->service.complete_split(to_complete);\n      }\n      osd->pg_map_lock.put_write();\n      osd->dispatch_context_transaction(rctx, pg);\n      osd->wake_pg_waiters(*i);\n      (*i)->unlock();\n    }\n\n    osd->dispatch_context(rctx, 0, osd->service.get_osdmap());\n  }\n};\n\nvoid OSD::process_peering_events(\n  const list<PG*> &pgs,\n  ThreadPool::TPHandle &handle\n  )\n{\n  bool need_up_thru = false;\n  epoch_t same_interval_since = 0;\n  OSDMapRef curmap;\n  PG::RecoveryCtx rctx = create_context();\n  rctx.handle = &handle;\n  for (list<PG*>::const_iterator i = pgs.begin();\n       i != pgs.end();\n       ++i) {\n    set<PGRef> split_pgs;\n    PG *pg = *i;\n    pg->lock_suspend_timeout(handle);\n    curmap = service.get_osdmap();\n    if (pg->deleting) {\n      pg->unlock();\n      continue;\n    }\n    if (!advance_pg(curmap->get_epoch(), pg, handle, &rctx, &split_pgs)) {\n      // we need to requeue the PG explicitly since we didn't actually\n      // handle an event\n      peering_wq.queue(pg);\n    } else {\n      assert(!pg->peering_queue.empty());\n      PG::CephPeeringEvtRef evt = pg->peering_queue.front();\n      pg->peering_queue.pop_front();\n      pg->handle_peering_event(evt, &rctx);\n    }\n    need_up_thru = pg->need_up_thru || need_up_thru;\n    same_interval_since = MAX(pg->info.history.same_interval_since,\n\t\t\t      same_interval_since);\n    pg->write_if_dirty(*rctx.transaction);\n    if (!split_pgs.empty()) {\n      rctx.on_applied->add(new C_CompleteSplits(this, split_pgs));\n      split_pgs.clear();\n    }\n    dispatch_context_transaction(rctx, pg, &handle);\n    pg->unlock();\n  }\n  if (need_up_thru)\n    queue_want_up_thru(same_interval_since);\n  dispatch_context(rctx, 0, curmap, &handle);\n\n  service.send_pg_temp();\n}\n\n// --------------------------------\n\nconst char** OSD::get_tracked_conf_keys() const\n{\n  static const char* KEYS[] = {\n    \"osd_max_backfills\",\n    \"osd_min_recovery_priority\",\n    \"osd_max_trimming_pgs\",\n    \"osd_op_complaint_time\",\n    \"osd_op_log_threshold\",\n    \"osd_op_history_size\",\n    \"osd_op_history_duration\",\n    \"osd_op_history_slow_op_size\",\n    \"osd_op_history_slow_op_threshold\",\n    \"osd_enable_op_tracker\",\n    \"osd_map_cache_size\",\n    \"osd_map_max_advance\",\n    \"osd_pg_epoch_persisted_max_stale\",\n    \"osd_disk_thread_ioprio_class\",\n    \"osd_disk_thread_ioprio_priority\",\n    // clog & admin clog\n    \"clog_to_monitors\",\n    \"clog_to_syslog\",\n    \"clog_to_syslog_facility\",\n    \"clog_to_syslog_level\",\n    \"osd_objectstore_fuse\",\n    \"clog_to_graylog\",\n    \"clog_to_graylog_host\",\n    \"clog_to_graylog_port\",\n    \"host\",\n    \"fsid\",\n    \"osd_recovery_delay_start\",\n    \"osd_client_message_size_cap\",\n    \"osd_client_message_cap\",\n    \"osd_heartbeat_min_size\",\n    \"osd_heartbeat_interval\",\n    NULL\n  };\n  return KEYS;\n}\n\nvoid OSD::handle_conf_change(const struct md_config_t *conf,\n\t\t\t     const std::set <std::string> &changed)\n{\n  if (changed.count(\"osd_max_backfills\")) {\n    service.local_reserver.set_max(cct->_conf->osd_max_backfills);\n    service.remote_reserver.set_max(cct->_conf->osd_max_backfills);\n  }\n  if (changed.count(\"osd_min_recovery_priority\")) {\n    service.local_reserver.set_min_priority(cct->_conf->osd_min_recovery_priority);\n    service.remote_reserver.set_min_priority(cct->_conf->osd_min_recovery_priority);\n  }\n  if (changed.count(\"osd_max_trimming_pgs\")) {\n    service.snap_reserver.set_max(cct->_conf->osd_max_trimming_pgs);\n  }\n  if (changed.count(\"osd_op_complaint_time\") ||\n      changed.count(\"osd_op_log_threshold\")) {\n    op_tracker.set_complaint_and_threshold(cct->_conf->osd_op_complaint_time,\n                                           cct->_conf->osd_op_log_threshold);\n  }\n  if (changed.count(\"osd_op_history_size\") ||\n      changed.count(\"osd_op_history_duration\")) {\n    op_tracker.set_history_size_and_duration(cct->_conf->osd_op_history_size,\n                                             cct->_conf->osd_op_history_duration);\n  }\n  if (changed.count(\"osd_op_history_slow_op_size\") ||\n      changed.count(\"osd_op_history_slow_op_threshold\")) {\n    op_tracker.set_history_slow_op_size_and_threshold(cct->_conf->osd_op_history_slow_op_size,\n                                                      cct->_conf->osd_op_history_slow_op_threshold);\n  }\n  if (changed.count(\"osd_enable_op_tracker\")) {\n      op_tracker.set_tracking(cct->_conf->osd_enable_op_tracker);\n  }\n  if (changed.count(\"osd_disk_thread_ioprio_class\") ||\n      changed.count(\"osd_disk_thread_ioprio_priority\")) {\n    set_disk_tp_priority();\n  }\n  if (changed.count(\"osd_map_cache_size\")) {\n    service.map_cache.set_size(cct->_conf->osd_map_cache_size);\n    service.map_bl_cache.set_size(cct->_conf->osd_map_cache_size);\n    service.map_bl_inc_cache.set_size(cct->_conf->osd_map_cache_size);\n  }\n  if (changed.count(\"clog_to_monitors\") ||\n      changed.count(\"clog_to_syslog\") ||\n      changed.count(\"clog_to_syslog_level\") ||\n      changed.count(\"clog_to_syslog_facility\") ||\n      changed.count(\"clog_to_graylog\") ||\n      changed.count(\"clog_to_graylog_host\") ||\n      changed.count(\"clog_to_graylog_port\") ||\n      changed.count(\"host\") ||\n      changed.count(\"fsid\")) {\n    update_log_config();\n  }\n\n#ifdef HAVE_LIBFUSE\n  if (changed.count(\"osd_objectstore_fuse\")) {\n    if (store) {\n      enable_disable_fuse(false);\n    }\n  }\n#endif\n\n  if (changed.count(\"osd_recovery_delay_start\")) {\n    service.defer_recovery(cct->_conf->osd_recovery_delay_start);\n    service.kick_recovery_queue();\n  }\n\n  if (changed.count(\"osd_client_message_cap\")) {\n    uint64_t newval = cct->_conf->osd_client_message_cap;\n    Messenger::Policy pol = client_messenger->get_policy(entity_name_t::TYPE_CLIENT);\n    if (pol.throttler_messages && newval > 0) {\n      pol.throttler_messages->reset_max(newval);\n    }\n  }\n  if (changed.count(\"osd_client_message_size_cap\")) {\n    uint64_t newval = cct->_conf->osd_client_message_size_cap;\n    Messenger::Policy pol = client_messenger->get_policy(entity_name_t::TYPE_CLIENT);\n    if (pol.throttler_bytes && newval > 0) {\n      pol.throttler_bytes->reset_max(newval);\n    }\n  }\n\n  check_config();\n}\n\nvoid OSD::update_log_config()\n{\n  map<string,string> log_to_monitors;\n  map<string,string> log_to_syslog;\n  map<string,string> log_channel;\n  map<string,string> log_prio;\n  map<string,string> log_to_graylog;\n  map<string,string> log_to_graylog_host;\n  map<string,string> log_to_graylog_port;\n  uuid_d fsid;\n  string host;\n\n  if (parse_log_client_options(cct, log_to_monitors, log_to_syslog,\n\t\t\t       log_channel, log_prio, log_to_graylog,\n\t\t\t       log_to_graylog_host, log_to_graylog_port,\n\t\t\t       fsid, host) == 0)\n    clog->update_config(log_to_monitors, log_to_syslog,\n\t\t\tlog_channel, log_prio, log_to_graylog,\n\t\t\tlog_to_graylog_host, log_to_graylog_port,\n\t\t\tfsid, host);\n  derr << \"log_to_monitors \" << log_to_monitors << dendl;\n}\n\nvoid OSD::check_config()\n{\n  // some sanity checks\n  if (cct->_conf->osd_map_cache_size <= cct->_conf->osd_map_max_advance + 2) {\n    clog->warn() << \"osd_map_cache_size (\" << cct->_conf->osd_map_cache_size << \")\"\n\t\t<< \" is not > osd_map_max_advance (\"\n\t\t<< cct->_conf->osd_map_max_advance << \")\";\n  }\n  if (cct->_conf->osd_map_cache_size <= (int)cct->_conf->osd_pg_epoch_persisted_max_stale + 2) {\n    clog->warn() << \"osd_map_cache_size (\" << cct->_conf->osd_map_cache_size << \")\"\n\t\t << \" is not > osd_pg_epoch_persisted_max_stale (\"\n\t\t << cct->_conf->osd_pg_epoch_persisted_max_stale << \")\";\n  }\n}\n\nvoid OSD::set_disk_tp_priority()\n{\n  dout(10) << __func__\n\t   << \" class \" << cct->_conf->osd_disk_thread_ioprio_class\n\t   << \" priority \" << cct->_conf->osd_disk_thread_ioprio_priority\n\t   << dendl;\n  if (cct->_conf->osd_disk_thread_ioprio_class.empty() ||\n      cct->_conf->osd_disk_thread_ioprio_priority < 0)\n    return;\n  int cls =\n    ceph_ioprio_string_to_class(cct->_conf->osd_disk_thread_ioprio_class);\n  if (cls < 0)\n    derr << __func__ << cpp_strerror(cls) << \": \"\n\t << \"osd_disk_thread_ioprio_class is \" << cct->_conf->osd_disk_thread_ioprio_class\n\t << \" but only the following values are allowed: idle, be or rt\" << dendl;\n  else\n    disk_tp.set_ioprio(cls, cct->_conf->osd_disk_thread_ioprio_priority);\n}\n\n// --------------------------------\n\nvoid OSD::get_latest_osdmap()\n{\n  dout(10) << __func__ << \" -- start\" << dendl;\n\n  C_SaferCond cond;\n  service.objecter->wait_for_latest_osdmap(&cond);\n  cond.wait();\n\n  dout(10) << __func__ << \" -- finish\" << dendl;\n}\n\n// --------------------------------\n\nint OSD::init_op_flags(OpRequestRef& op)\n{\n  const MOSDOp *m = static_cast<const MOSDOp*>(op->get_req());\n  vector<OSDOp>::const_iterator iter;\n\n  // client flags have no bearing on whether an op is a read, write, etc.\n  op->rmw_flags = 0;\n\n  if (m->has_flag(CEPH_OSD_FLAG_RWORDERED)) {\n    op->set_force_rwordered();\n  }\n\n  // set bits based on op codes, called methods.\n  for (iter = m->ops.begin(); iter != m->ops.end(); ++iter) {\n    if ((iter->op.op == CEPH_OSD_OP_WATCH &&\n\t iter->op.watch.op == CEPH_OSD_WATCH_OP_PING)) {\n      /* This a bit odd.  PING isn't actually a write.  It can't\n       * result in an update to the object_info.  PINGs also aren'ty\n       * resent, so there's no reason to write out a log entry\n       *\n       * However, we pipeline them behind writes, so let's force\n       * the write_ordered flag.\n       */\n      op->set_force_rwordered();\n    } else {\n      if (ceph_osd_op_mode_modify(iter->op.op))\n\top->set_write();\n    }\n    if (ceph_osd_op_mode_read(iter->op.op))\n      op->set_read();\n\n    // set READ flag if there are src_oids\n    if (iter->soid.oid.name.length())\n      op->set_read();\n\n    // set PGOP flag if there are PG ops\n    if (ceph_osd_op_type_pg(iter->op.op))\n      op->set_pg_op();\n\n    if (ceph_osd_op_mode_cache(iter->op.op))\n      op->set_cache();\n\n    // check for ec base pool\n    int64_t poolid = m->get_pg().pool();\n    const pg_pool_t *pool = osdmap->get_pg_pool(poolid);\n    if (pool && pool->is_tier()) {\n      const pg_pool_t *base_pool = osdmap->get_pg_pool(pool->tier_of);\n      if (base_pool && base_pool->require_rollback()) {\n        if ((iter->op.op != CEPH_OSD_OP_READ) &&\n            (iter->op.op != CEPH_OSD_OP_CHECKSUM) &&\n            (iter->op.op != CEPH_OSD_OP_CMPEXT) &&\n            (iter->op.op != CEPH_OSD_OP_STAT) &&\n            (iter->op.op != CEPH_OSD_OP_ISDIRTY) &&\n            (iter->op.op != CEPH_OSD_OP_UNDIRTY) &&\n            (iter->op.op != CEPH_OSD_OP_GETXATTR) &&\n            (iter->op.op != CEPH_OSD_OP_GETXATTRS) &&\n            (iter->op.op != CEPH_OSD_OP_CMPXATTR) &&\n            (iter->op.op != CEPH_OSD_OP_ASSERT_VER) &&\n            (iter->op.op != CEPH_OSD_OP_LIST_WATCHERS) &&\n            (iter->op.op != CEPH_OSD_OP_LIST_SNAPS) &&\n            (iter->op.op != CEPH_OSD_OP_SETALLOCHINT) &&\n            (iter->op.op != CEPH_OSD_OP_WRITEFULL) &&\n            (iter->op.op != CEPH_OSD_OP_ROLLBACK) &&\n            (iter->op.op != CEPH_OSD_OP_CREATE) &&\n            (iter->op.op != CEPH_OSD_OP_DELETE) &&\n            (iter->op.op != CEPH_OSD_OP_SETXATTR) &&\n            (iter->op.op != CEPH_OSD_OP_RMXATTR) &&\n            (iter->op.op != CEPH_OSD_OP_STARTSYNC) &&\n            (iter->op.op != CEPH_OSD_OP_COPY_GET) &&\n            (iter->op.op != CEPH_OSD_OP_COPY_FROM)) {\n          op->set_promote();\n        }\n      }\n    }\n\n    switch (iter->op.op) {\n    case CEPH_OSD_OP_CALL:\n      {\n\tbufferlist::iterator bp = const_cast<bufferlist&>(iter->indata).begin();\n\tint is_write, is_read;\n\tstring cname, mname;\n\tbp.copy(iter->op.cls.class_len, cname);\n\tbp.copy(iter->op.cls.method_len, mname);\n\n\tClassHandler::ClassData *cls;\n\tint r = class_handler->open_class(cname, &cls);\n\tif (r) {\n\t  derr << \"class \" << cname << \" open got \" << cpp_strerror(r) << dendl;\n\t  if (r == -ENOENT)\n\t    r = -EOPNOTSUPP;\n\t  else if (r != -EPERM) // propagate permission errors\n\t    r = -EIO;\n\t  return r;\n\t}\n\tint flags = cls->get_method_flags(mname.c_str());\n\tif (flags < 0) {\n\t  if (flags == -ENOENT)\n\t    r = -EOPNOTSUPP;\n\t  else\n\t    r = flags;\n\t  return r;\n\t}\n\tis_read = flags & CLS_METHOD_RD;\n\tis_write = flags & CLS_METHOD_WR;\n        bool is_promote = flags & CLS_METHOD_PROMOTE;\n\n\tdout(10) << \"class \" << cname << \" method \" << mname << \" \"\n\t\t << \"flags=\" << (is_read ? \"r\" : \"\")\n                             << (is_write ? \"w\" : \"\")\n                             << (is_promote ? \"p\" : \"\")\n                 << dendl;\n\tif (is_read)\n\t  op->set_class_read();\n\tif (is_write)\n\t  op->set_class_write();\n        if (is_promote)\n          op->set_promote();\n        op->add_class(cname, is_read, is_write, cls->whitelisted);\n\tbreak;\n      }\n\n    case CEPH_OSD_OP_WATCH:\n      // force the read bit for watch since it is depends on previous\n      // watch state (and may return early if the watch exists) or, in\n      // the case of ping, is simply a read op.\n      op->set_read();\n      // fall through\n    case CEPH_OSD_OP_NOTIFY:\n    case CEPH_OSD_OP_NOTIFY_ACK:\n      {\n        op->set_promote();\n        break;\n      }\n\n    case CEPH_OSD_OP_DELETE:\n      // if we get a delete with FAILOK we can skip handle cache. without\n      // FAILOK we still need to promote (or do something smarter) to\n      // determine whether to return ENOENT or 0.\n      if (iter == m->ops.begin() &&\n\t  iter->op.flags == CEPH_OSD_OP_FLAG_FAILOK) {\n\top->set_skip_handle_cache();\n      }\n      // skip promotion when proxying a delete op\n      if (m->ops.size() == 1) {\n\top->set_skip_promote();\n      }\n      break;\n\n    case CEPH_OSD_OP_CACHE_TRY_FLUSH:\n    case CEPH_OSD_OP_CACHE_FLUSH:\n    case CEPH_OSD_OP_CACHE_EVICT:\n      // If try_flush/flush/evict is the only op, can skip handle cache.\n      if (m->ops.size() == 1) {\n\top->set_skip_handle_cache();\n      }\n      break;\n\n    case CEPH_OSD_OP_READ:\n    case CEPH_OSD_OP_SYNC_READ:\n    case CEPH_OSD_OP_SPARSE_READ:\n    case CEPH_OSD_OP_CHECKSUM:\n    case CEPH_OSD_OP_WRITEFULL:\n      if (m->ops.size() == 1 &&\n          (iter->op.flags & CEPH_OSD_OP_FLAG_FADVISE_NOCACHE ||\n           iter->op.flags & CEPH_OSD_OP_FLAG_FADVISE_DONTNEED)) {\n        op->set_skip_promote();\n      }\n      break;\n\n    // force promotion when pin an object in cache tier\n    case CEPH_OSD_OP_CACHE_PIN:\n      op->set_promote();\n      break;\n\n    default:\n      break;\n    }\n  }\n\n  if (op->rmw_flags == 0)\n    return -EINVAL;\n\n  return 0;\n}\n\nvoid OSD::PeeringWQ::_dequeue(list<PG*> *out) {\n  for (list<PG*>::iterator i = peering_queue.begin();\n      i != peering_queue.end() &&\n      out->size() < osd->cct->_conf->osd_peering_wq_batch_size;\n      ) {\n        if (in_use.count(*i)) {\n          ++i;\n        } else {\n          out->push_back(*i);\n          peering_queue.erase(i++);\n        }\n  }\n  in_use.insert(out->begin(), out->end());\n}\n\n\n// =============================================================\n\n#undef dout_context\n#define dout_context osd->cct\n#undef dout_prefix\n#define dout_prefix *_dout << \"osd.\" << osd->whoami << \" op_wq \"\n\nvoid OSD::ShardedOpWQ::wake_pg_waiters(spg_t pgid)\n{\n  uint32_t shard_index = pgid.hash_to_shard(shard_list.size());\n  auto sdata = shard_list[shard_index];\n  bool queued = false;\n  {\n    Mutex::Locker l(sdata->sdata_op_ordering_lock);\n    auto p = sdata->pg_slots.find(pgid);\n    if (p != sdata->pg_slots.end()) {\n      dout(20) << __func__ << \" \" << pgid\n\t       << \" to_process \" << p->second.to_process\n\t       << \" waiting_for_pg=\" << (int)p->second.waiting_for_pg << dendl;\n      for (auto i = p->second.to_process.rbegin();\n\t   i != p->second.to_process.rend();\n\t   ++i) {\n\tsdata->_enqueue_front(make_pair(pgid, *i), osd->op_prio_cutoff);\n      }\n      p->second.to_process.clear();\n      p->second.waiting_for_pg = false;\n      ++p->second.requeue_seq;\n      queued = true;\n    }\n  }\n  if (queued) {\n    sdata->sdata_lock.Lock();\n    sdata->sdata_cond.SignalOne();\n    sdata->sdata_lock.Unlock();\n  }\n}\n\nvoid OSD::ShardedOpWQ::prune_pg_waiters(OSDMapRef osdmap, int whoami)\n{\n  unsigned pushes_to_free = 0;\n  for (auto sdata : shard_list) {\n    Mutex::Locker l(sdata->sdata_op_ordering_lock);\n    sdata->waiting_for_pg_osdmap = osdmap;\n    auto p = sdata->pg_slots.begin();\n    while (p != sdata->pg_slots.end()) {\n      ShardData::pg_slot& slot = p->second;\n      if (!slot.to_process.empty() && slot.num_running == 0) {\n\tif (osdmap->is_up_acting_osd_shard(p->first, whoami)) {\n\t  dout(20) << __func__ << \"  \" << p->first << \" maps to us, keeping\"\n\t\t   << dendl;\n\t  ++p;\n\t  continue;\n\t}\n\twhile (!slot.to_process.empty() &&\n\t       slot.to_process.front().get_map_epoch() <= osdmap->get_epoch()) {\n\t  auto& qi = slot.to_process.front();\n\t  dout(20) << __func__ << \"  \" << p->first\n\t\t   << \" item \" << qi\n\t\t   << \" epoch \" << qi.get_map_epoch()\n\t\t   << \" <= \" << osdmap->get_epoch()\n\t\t   << \", stale, dropping\" << dendl;\n\t  pushes_to_free += qi.get_reserved_pushes();\n\t  slot.to_process.pop_front();\n\t}\n      }\n      if (slot.to_process.empty() &&\n\t  slot.num_running == 0 &&\n\t  !slot.pg) {\n\tdout(20) << __func__ << \"  \" << p->first << \" empty, pruning\" << dendl;\n\tp = sdata->pg_slots.erase(p);\n      } else {\n\t++p;\n      }\n    }\n  }\n  if (pushes_to_free > 0) {\n    osd->service.release_reserved_pushes(pushes_to_free);\n  }\n}\n\nvoid OSD::ShardedOpWQ::clear_pg_pointer(spg_t pgid)\n{\n  uint32_t shard_index = pgid.hash_to_shard(shard_list.size());\n  auto sdata = shard_list[shard_index];\n  Mutex::Locker l(sdata->sdata_op_ordering_lock);\n  auto p = sdata->pg_slots.find(pgid);\n  if (p != sdata->pg_slots.end()) {\n    auto& slot = p->second;\n    dout(20) << __func__ << \" \" << pgid << \" pg \" << slot.pg << dendl;\n    assert(!slot.pg || slot.pg->deleting);\n    slot.pg = nullptr;\n  }\n}\n\nvoid OSD::ShardedOpWQ::clear_pg_slots()\n{\n  for (auto sdata : shard_list) {\n    Mutex::Locker l(sdata->sdata_op_ordering_lock);\n    sdata->pg_slots.clear();\n    sdata->waiting_for_pg_osdmap.reset();\n    // don't bother with reserved pushes; we are shutting down\n  }\n}\n\n#undef dout_prefix\n#define dout_prefix *_dout << \"osd.\" << osd->whoami << \" op_wq(\" << shard_index << \") \"\n\nvoid OSD::ShardedOpWQ::_process(uint32_t thread_index, heartbeat_handle_d *hb)\n{\n  uint32_t shard_index = thread_index % num_shards;\n  ShardData *sdata = shard_list[shard_index];\n  assert(NULL != sdata);\n\n  // peek at spg_t\n  sdata->sdata_op_ordering_lock.Lock();\n  if (sdata->pqueue->empty()) {\n    dout(20) << __func__ << \" empty q, waiting\" << dendl;\n    // optimistically sleep a moment; maybe another work item will come along.\n    osd->cct->get_heartbeat_map()->reset_timeout(hb,\n      osd->cct->_conf->threadpool_default_timeout, 0);\n    sdata->sdata_lock.Lock();\n    sdata->sdata_op_ordering_lock.Unlock();\n    sdata->sdata_cond.WaitInterval(sdata->sdata_lock,\n      utime_t(osd->cct->_conf->threadpool_empty_queue_max_wait, 0));\n    sdata->sdata_lock.Unlock();\n    sdata->sdata_op_ordering_lock.Lock();\n    if (sdata->pqueue->empty()) {\n      sdata->sdata_op_ordering_lock.Unlock();\n      return;\n    }\n  }\n  pair<spg_t, PGQueueable> item = sdata->pqueue->dequeue();\n  if (osd->is_stopping()) {\n    sdata->sdata_op_ordering_lock.Unlock();\n    return;    // OSD shutdown, discard.\n  }\n  PGRef pg;\n  uint64_t requeue_seq;\n  {\n    auto& slot = sdata->pg_slots[item.first];\n    dout(30) << __func__ << \" \" << item.first\n\t     << \" to_process \" << slot.to_process\n\t     << \" waiting_for_pg=\" << (int)slot.waiting_for_pg << dendl;\n    slot.to_process.push_back(item.second);\n    // note the requeue seq now...\n    requeue_seq = slot.requeue_seq;\n    if (slot.waiting_for_pg) {\n      // save ourselves a bit of effort\n      dout(20) << __func__ << \" \" << item.first << \" item \" << item.second\n\t       << \" queued, waiting_for_pg\" << dendl;\n      sdata->sdata_op_ordering_lock.Unlock();\n      return;\n    }\n    pg = slot.pg;\n    dout(20) << __func__ << \" \" << item.first << \" item \" << item.second\n\t     << \" queued\" << dendl;\n    ++slot.num_running;\n  }\n  sdata->sdata_op_ordering_lock.Unlock();\n\n  osd->service.maybe_inject_dispatch_delay();\n\n  // [lookup +] lock pg (if we have it)\n  if (!pg) {\n    pg = osd->_lookup_lock_pg(item.first);\n  } else {\n    pg->lock();\n  }\n\n  osd->service.maybe_inject_dispatch_delay();\n\n  boost::optional<PGQueueable> qi;\n\n  // we don't use a Mutex::Locker here because of the\n  // osd->service.release_reserved_pushes() call below\n  sdata->sdata_op_ordering_lock.Lock();\n\n  auto q = sdata->pg_slots.find(item.first);\n  assert(q != sdata->pg_slots.end());\n  auto& slot = q->second;\n  --slot.num_running;\n\n  if (slot.to_process.empty()) {\n    // raced with wake_pg_waiters or prune_pg_waiters\n    dout(20) << __func__ << \" \" << item.first << \" nothing queued\" << dendl;\n    if (pg) {\n      pg->unlock();\n    }\n    sdata->sdata_op_ordering_lock.Unlock();\n    return;\n  }\n  if (requeue_seq != slot.requeue_seq) {\n    dout(20) << __func__ << \" \" << item.first\n\t     << \" requeue_seq \" << slot.requeue_seq << \" > our \"\n\t     << requeue_seq << \", we raced with wake_pg_waiters\"\n\t     << dendl;\n    if (pg) {\n      pg->unlock();\n    }\n    sdata->sdata_op_ordering_lock.Unlock();\n    return;\n  }\n  if (pg && !slot.pg && !pg->deleting) {\n    dout(20) << __func__ << \" \" << item.first << \" set pg to \" << pg << dendl;\n    slot.pg = pg;\n  }\n  dout(30) << __func__ << \" \" << item.first << \" to_process \" << slot.to_process\n\t   << \" waiting_for_pg=\" << (int)slot.waiting_for_pg << dendl;\n\n  // make sure we're not already waiting for this pg\n  if (slot.waiting_for_pg) {\n    dout(20) << __func__ << \" \" << item.first << \" item \" << item.second\n\t     << \" slot is waiting_for_pg\" << dendl;\n    if (pg) {\n      pg->unlock();\n    }\n    sdata->sdata_op_ordering_lock.Unlock();\n    return;\n  }\n\n  // take next item\n  qi = slot.to_process.front();\n  slot.to_process.pop_front();\n  dout(20) << __func__ << \" \" << item.first << \" item \" << *qi\n\t   << \" pg \" << pg << dendl;\n\n  if (!pg) {\n    // should this pg shard exist on this osd in this (or a later) epoch?\n    OSDMapRef osdmap = sdata->waiting_for_pg_osdmap;\n    if (osdmap->is_up_acting_osd_shard(item.first, osd->whoami)) {\n      dout(20) << __func__ << \" \" << item.first\n\t       << \" no pg, should exist, will wait\" << \" on \" << *qi << dendl;\n      slot.to_process.push_front(*qi);\n      slot.waiting_for_pg = true;\n    } else if (qi->get_map_epoch() > osdmap->get_epoch()) {\n      dout(20) << __func__ << \" \" << item.first << \" no pg, item epoch is \"\n\t       << qi->get_map_epoch() << \" > \" << osdmap->get_epoch()\n\t       << \", will wait on \" << *qi << dendl;\n      slot.to_process.push_front(*qi);\n      slot.waiting_for_pg = true;\n    } else {\n      dout(20) << __func__ << \" \" << item.first << \" no pg, shouldn't exist,\"\n\t       << \" dropping \" << *qi << dendl;\n      // share map with client?\n      if (boost::optional<OpRequestRef> _op = qi->maybe_get_op()) {\n\tSession *session = static_cast<Session *>(\n\t  (*_op)->get_req()->get_connection()->get_priv());\n\tif (session) {\n\t  osd->maybe_share_map(session, *_op, sdata->waiting_for_pg_osdmap);\n\t  session->put();\n\t}\n      }\n      unsigned pushes_to_free = qi->get_reserved_pushes();\n      if (pushes_to_free > 0) {\n\tsdata->sdata_op_ordering_lock.Unlock();\n\tosd->service.release_reserved_pushes(pushes_to_free);\n\treturn;\n      }\n    }\n    sdata->sdata_op_ordering_lock.Unlock();\n    return;\n  }\n  sdata->sdata_op_ordering_lock.Unlock();\n\n\n  // osd_opwq_process marks the point at which an operation has been dequeued\n  // and will begin to be handled by a worker thread.\n  {\n#ifdef WITH_LTTNG\n    osd_reqid_t reqid;\n    if (boost::optional<OpRequestRef> _op = qi->maybe_get_op()) {\n      reqid = (*_op)->get_reqid();\n    }\n#endif\n    tracepoint(osd, opwq_process_start, reqid.name._type,\n        reqid.name._num, reqid.tid, reqid.inc);\n  }\n\n  lgeneric_subdout(osd->cct, osd, 30) << \"dequeue status: \";\n  Formatter *f = Formatter::create(\"json\");\n  f->open_object_section(\"q\");\n  dump(f);\n  f->close_section();\n  f->flush(*_dout);\n  delete f;\n  *_dout << dendl;\n\n  ThreadPool::TPHandle tp_handle(osd->cct, hb, timeout_interval,\n\t\t\t\t suicide_interval);\n  qi->run(osd, pg, tp_handle);\n\n  {\n#ifdef WITH_LTTNG\n    osd_reqid_t reqid;\n    if (boost::optional<OpRequestRef> _op = qi->maybe_get_op()) {\n      reqid = (*_op)->get_reqid();\n    }\n#endif\n    tracepoint(osd, opwq_process_finish, reqid.name._type,\n        reqid.name._num, reqid.tid, reqid.inc);\n  }\n\n  pg->unlock();\n}\n\nvoid OSD::ShardedOpWQ::_enqueue(pair<spg_t, PGQueueable> item) {\n  uint32_t shard_index =\n    item.first.hash_to_shard(shard_list.size());\n\n  ShardData* sdata = shard_list[shard_index];\n  assert (NULL != sdata);\n  unsigned priority = item.second.get_priority();\n  unsigned cost = item.second.get_cost();\n  sdata->sdata_op_ordering_lock.Lock();\n\n  dout(20) << __func__ << \" \" << item.first << \" \" << item.second << dendl;\n  if (priority >= osd->op_prio_cutoff)\n    sdata->pqueue->enqueue_strict(\n      item.second.get_owner(), priority, item);\n  else\n    sdata->pqueue->enqueue(\n      item.second.get_owner(),\n      priority, cost, item);\n  sdata->sdata_op_ordering_lock.Unlock();\n\n  sdata->sdata_lock.Lock();\n  sdata->sdata_cond.SignalOne();\n  sdata->sdata_lock.Unlock();\n\n}\n\nvoid OSD::ShardedOpWQ::_enqueue_front(pair<spg_t, PGQueueable> item)\n{\n  uint32_t shard_index = item.first.hash_to_shard(shard_list.size());\n  ShardData* sdata = shard_list[shard_index];\n  assert (NULL != sdata);\n  sdata->sdata_op_ordering_lock.Lock();\n  auto p = sdata->pg_slots.find(item.first);\n  if (p != sdata->pg_slots.end() && !p->second.to_process.empty()) {\n    // we may be racing with _process, which has dequeued a new item\n    // from pqueue, put it on to_process, and is now busy taking the\n    // pg lock.  ensure this old requeued item is ordered before any\n    // such newer item in to_process.\n    p->second.to_process.push_front(item.second);\n    item.second = p->second.to_process.back();\n    p->second.to_process.pop_back();\n    dout(20) << __func__ << \" \" << item.first\n\t     << \" \" << p->second.to_process.front()\n\t     << \" shuffled w/ \" << item.second << dendl;\n  } else {\n    dout(20) << __func__ << \" \" << item.first << \" \" << item.second << dendl;\n  }\n  sdata->_enqueue_front(item, osd->op_prio_cutoff);\n  sdata->sdata_op_ordering_lock.Unlock();\n  sdata->sdata_lock.Lock();\n  sdata->sdata_cond.SignalOne();\n  sdata->sdata_lock.Unlock();\n}\n\nnamespace ceph { \nnamespace osd_cmds { \n\nint heap(CephContext& cct, cmdmap_t& cmdmap, Formatter& f, std::ostream& os)\n{\n  if (!ceph_using_tcmalloc()) {\n        os << \"could not issue heap profiler command -- not using tcmalloc!\";\n        return -EOPNOTSUPP;\n  }\n  \n  string cmd;\n  if (!cmd_getval(&cct, cmdmap, \"heapcmd\", cmd)) {\n        os << \"unable to get value for command \\\"\" << cmd << \"\\\"\";\n       return -EINVAL;\n   }\n  \n  std::vector<std::string> cmd_vec;\n  get_str_vec(cmd, cmd_vec);\n  \n  ceph_heap_profiler_handle_command(cmd_vec, os);\n  \n  return 0;\n}\n \n}} // namespace ceph::osd_cmds\n\n\nstd::ostream& operator<<(std::ostream& out, const OSD::io_queue& q) {\n  switch(q) {\n  case OSD::io_queue::prioritized:\n    out << \"prioritized\";\n    break;\n  case OSD::io_queue::weightedpriority:\n    out << \"weightedpriority\";\n    break;\n  case OSD::io_queue::mclock_opclass:\n    out << \"mclock_opclass\";\n    break;\n  case OSD::io_queue::mclock_client:\n    out << \"mclock_client\";\n    break;\n  }\n  return out;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2004-2006 Sage Weil <sage@newdream.net>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software \n * Foundation.  See file COPYING.\n * \n */\n\n#ifndef CEPH_OSD_H\n#define CEPH_OSD_H\n\n#include \"PG.h\"\n\n#include \"msg/Dispatcher.h\"\n\n#include \"common/Mutex.h\"\n#include \"common/RWLock.h\"\n#include \"common/Timer.h\"\n#include \"common/WorkQueue.h\"\n#include \"common/AsyncReserver.h\"\n#include \"common/ceph_context.h\"\n#include \"common/zipkin_trace.h\"\n\n#include \"mgr/MgrClient.h\"\n\n#include \"os/ObjectStore.h\"\n#include \"OSDCap.h\" \n \n#include \"auth/KeyRing.h\"\n#include \"osd/ClassHandler.h\"\n\n#include \"include/CompatSet.h\"\n\n#include \"OpRequest.h\"\n#include \"Session.h\"\n\n#include \"osd/PGQueueable.h\"\n\n#include <atomic>\n#include <map>\n#include <memory>\n#include \"include/memory.h\"\nusing namespace std;\n\n#include \"include/unordered_map.h\"\n\n#include \"common/shared_cache.hpp\"\n#include \"common/simple_cache.hpp\"\n#include \"common/sharedptr_registry.hpp\"\n#include \"common/WeightedPriorityQueue.h\"\n#include \"common/PrioritizedQueue.h\"\n#include \"osd/mClockOpClassQueue.h\"\n#include \"osd/mClockClientQueue.h\"\n#include \"messages/MOSDOp.h\"\n#include \"include/Spinlock.h\"\n#include \"common/EventTrace.h\"\n\n#define CEPH_OSD_PROTOCOL    10 /* cluster internal */\n\n\nenum {\n  l_osd_first = 10000,\n  l_osd_op_wip,\n  l_osd_op,\n  l_osd_op_inb,\n  l_osd_op_outb,\n  l_osd_op_lat,\n  l_osd_op_process_lat,\n  l_osd_op_prepare_lat,\n  l_osd_op_r,\n  l_osd_op_r_outb,\n  l_osd_op_r_lat,\n  l_osd_op_r_lat_outb_hist,\n  l_osd_op_r_process_lat,\n  l_osd_op_r_prepare_lat,\n  l_osd_op_w,\n  l_osd_op_w_inb,\n  l_osd_op_w_lat,\n  l_osd_op_w_lat_inb_hist,\n  l_osd_op_w_process_lat,\n  l_osd_op_w_prepare_lat,\n  l_osd_op_rw,\n  l_osd_op_rw_inb,\n  l_osd_op_rw_outb,\n  l_osd_op_rw_lat,\n  l_osd_op_rw_lat_inb_hist,\n  l_osd_op_rw_lat_outb_hist,\n  l_osd_op_rw_process_lat,\n  l_osd_op_rw_prepare_lat,\n\n  l_osd_op_before_queue_op_lat,\n  l_osd_op_before_dequeue_op_lat,\n\n  l_osd_sop,\n  l_osd_sop_inb,\n  l_osd_sop_lat,\n  l_osd_sop_w,\n  l_osd_sop_w_inb,\n  l_osd_sop_w_lat,\n  l_osd_sop_pull,\n  l_osd_sop_pull_lat,\n  l_osd_sop_push,\n  l_osd_sop_push_inb,\n  l_osd_sop_push_lat,\n\n  l_osd_pull,\n  l_osd_push,\n  l_osd_push_outb,\n\n  l_osd_rop,\n\n  l_osd_loadavg,\n  l_osd_buf,\n  l_osd_history_alloc_bytes,\n  l_osd_history_alloc_num,\n  l_osd_cached_crc,\n  l_osd_cached_crc_adjusted,\n  l_osd_missed_crc,\n\n  l_osd_pg,\n  l_osd_pg_primary,\n  l_osd_pg_replica,\n  l_osd_pg_stray,\n  l_osd_pg_removing,\n  l_osd_hb_to,\n  l_osd_map,\n  l_osd_mape,\n  l_osd_mape_dup,\n\n  l_osd_waiting_for_map,\n\n  l_osd_map_cache_hit,\n  l_osd_map_cache_miss,\n  l_osd_map_cache_miss_low,\n  l_osd_map_cache_miss_low_avg,\n  l_osd_map_bl_cache_hit,\n  l_osd_map_bl_cache_miss,\n\n  l_osd_stat_bytes,\n  l_osd_stat_bytes_used,\n  l_osd_stat_bytes_avail,\n\n  l_osd_copyfrom,\n\n  l_osd_tier_promote,\n  l_osd_tier_flush,\n  l_osd_tier_flush_fail,\n  l_osd_tier_try_flush,\n  l_osd_tier_try_flush_fail,\n  l_osd_tier_evict,\n  l_osd_tier_whiteout,\n  l_osd_tier_dirty,\n  l_osd_tier_clean,\n  l_osd_tier_delay,\n  l_osd_tier_proxy_read,\n  l_osd_tier_proxy_write,\n\n  l_osd_agent_wake,\n  l_osd_agent_skip,\n  l_osd_agent_flush,\n  l_osd_agent_evict,\n\n  l_osd_object_ctx_cache_hit,\n  l_osd_object_ctx_cache_total,\n\n  l_osd_op_cache_hit,\n  l_osd_tier_flush_lat,\n  l_osd_tier_promote_lat,\n  l_osd_tier_r_lat,\n\n  l_osd_pg_info,\n  l_osd_pg_fastinfo,\n  l_osd_pg_biginfo,\n\n  l_osd_last,\n};\n\n// RecoveryState perf counters\nenum {\n  rs_first = 20000,\n  rs_initial_latency,\n  rs_started_latency,\n  rs_reset_latency,\n  rs_start_latency,\n  rs_primary_latency,\n  rs_peering_latency,\n  rs_backfilling_latency,\n  rs_waitremotebackfillreserved_latency,\n  rs_waitlocalbackfillreserved_latency,\n  rs_notbackfilling_latency,\n  rs_repnotrecovering_latency,\n  rs_repwaitrecoveryreserved_latency,\n  rs_repwaitbackfillreserved_latency,\n  rs_reprecovering_latency,\n  rs_activating_latency,\n  rs_waitlocalrecoveryreserved_latency,\n  rs_waitremoterecoveryreserved_latency,\n  rs_recovering_latency,\n  rs_recovered_latency,\n  rs_clean_latency,\n  rs_active_latency,\n  rs_replicaactive_latency,\n  rs_stray_latency,\n  rs_getinfo_latency,\n  rs_getlog_latency,\n  rs_waitactingchange_latency,\n  rs_incomplete_latency,\n  rs_down_latency,\n  rs_getmissing_latency,\n  rs_waitupthru_latency,\n  rs_notrecovering_latency,\n  rs_last,\n};\n\nclass Messenger;\nclass Message;\nclass MonClient;\nclass PerfCounters;\nclass ObjectStore;\nclass FuseStore;\nclass OSDMap;\nclass MLog;\nclass Objecter;\n\nclass Watch;\nclass PrimaryLogPG;\n\nclass AuthAuthorizeHandlerRegistry;\n\nclass TestOpsSocketHook;\nstruct C_CompleteSplits;\nstruct C_OpenPGs;\nclass LogChannel;\nclass CephContext;\ntypedef ceph::shared_ptr<ObjectStore::Sequencer> SequencerRef;\nclass MOSDOp;\n\nclass DeletingState {\n  Mutex lock;\n  Cond cond;\n  enum {\n    QUEUED,\n    CLEARING_DIR,\n    CLEARING_WAITING,\n    DELETING_DIR,\n    DELETED_DIR,\n    CANCELED,\n  } status;\n  bool stop_deleting;\npublic:\n  const spg_t pgid;\n  const PGRef old_pg_state;\n  explicit DeletingState(const pair<spg_t, PGRef> &in) :\n    lock(\"DeletingState::lock\"), status(QUEUED), stop_deleting(false),\n    pgid(in.first), old_pg_state(in.second) {\n    }\n\n  /// transition status to CLEARING_WAITING\n  bool pause_clearing() {\n    Mutex::Locker l(lock);\n    assert(status == CLEARING_DIR);\n    if (stop_deleting) {\n      status = CANCELED;\n      cond.Signal();\n      return false;\n    }\n    status = CLEARING_WAITING;\n    return true;\n  } ///< @return false if we should cancel deletion\n\n  /// start or resume the clearing - transition the status to CLEARING_DIR\n  bool start_or_resume_clearing() {\n    Mutex::Locker l(lock);\n    assert(\n      status == QUEUED ||\n      status == DELETED_DIR ||\n      status == CLEARING_WAITING);\n    if (stop_deleting) {\n      status = CANCELED;\n      cond.Signal();\n      return false;\n    }\n    status = CLEARING_DIR;\n    return true;\n  } ///< @return false if we should cancel the deletion\n\n  /// transition status to CLEARING_DIR\n  bool resume_clearing() {\n    Mutex::Locker l(lock);\n    assert(status == CLEARING_WAITING);\n    if (stop_deleting) {\n      status = CANCELED;\n      cond.Signal();\n      return false;\n    }\n    status = CLEARING_DIR;\n    return true;\n  } ///< @return false if we should cancel deletion\n\n  /// transition status to deleting\n  bool start_deleting() {\n    Mutex::Locker l(lock);\n    assert(status == CLEARING_DIR);\n    if (stop_deleting) {\n      status = CANCELED;\n      cond.Signal();\n      return false;\n    }\n    status = DELETING_DIR;\n    return true;\n  } ///< @return false if we should cancel deletion\n\n  /// signal collection removal queued\n  void finish_deleting() {\n    Mutex::Locker l(lock);\n    assert(status == DELETING_DIR);\n    status = DELETED_DIR;\n    cond.Signal();\n  }\n\n  /// try to halt the deletion\n  bool try_stop_deletion() {\n    Mutex::Locker l(lock);\n    stop_deleting = true;\n    /**\n     * If we are in DELETING_DIR or CLEARING_DIR, there are in progress\n     * operations we have to wait for before continuing on.  States\n     * CLEARING_WAITING and QUEUED indicate that the remover will check\n     * stop_deleting before queueing any further operations.  CANCELED\n     * indicates that the remover has already halted.  DELETED_DIR\n     * indicates that the deletion has been fully queued.\n     */\n    while (status == DELETING_DIR || status == CLEARING_DIR)\n      cond.Wait(lock);\n    return status != DELETED_DIR;\n  } ///< @return true if we don't need to recreate the collection\n};\ntypedef ceph::shared_ptr<DeletingState> DeletingStateRef;\n\nclass OSD;\n\nclass OSDService {\npublic:\n  OSD *osd;\n  CephContext *cct;\n  SharedPtrRegistry<spg_t, ObjectStore::Sequencer> osr_registry;\n  ceph::shared_ptr<ObjectStore::Sequencer> meta_osr;\n  SharedPtrRegistry<spg_t, DeletingState> deleting_pgs;\n  const int whoami;\n  ObjectStore *&store;\n  LogClient &log_client;\n  LogChannelRef clog;\n  PGRecoveryStats &pg_recovery_stats;\nprivate:\n  Messenger *&cluster_messenger;\n  Messenger *&client_messenger;\npublic:\n  PerfCounters *&logger;\n  PerfCounters *&recoverystate_perf;\n  MonClient   *&monc;\n  ThreadPool::BatchWorkQueue<PG> &peering_wq;\n  GenContextWQ recovery_gen_wq;\n  ClassHandler  *&class_handler;\n\n  void enqueue_back(spg_t pgid, PGQueueable qi);\n  void enqueue_front(spg_t pgid, PGQueueable qi);\n\n  void maybe_inject_dispatch_delay() {\n    if (g_conf->osd_debug_inject_dispatch_delay_probability > 0) {\n      if (rand() % 10000 <\n\t  g_conf->osd_debug_inject_dispatch_delay_probability * 10000) {\n\tutime_t t;\n\tt.set_from_double(g_conf->osd_debug_inject_dispatch_delay_duration);\n\tt.sleep();\n      }\n    }\n  }\n\nprivate:\n  // -- map epoch lower bound --\n  Mutex pg_epoch_lock;\n  multiset<epoch_t> pg_epochs;\n  map<spg_t,epoch_t> pg_epoch;\n\npublic:\n  void pg_add_epoch(spg_t pgid, epoch_t epoch) {\n    Mutex::Locker l(pg_epoch_lock);\n    map<spg_t,epoch_t>::iterator t = pg_epoch.find(pgid);\n    assert(t == pg_epoch.end());\n    pg_epoch[pgid] = epoch;\n    pg_epochs.insert(epoch);\n  }\n  void pg_update_epoch(spg_t pgid, epoch_t epoch) {\n    Mutex::Locker l(pg_epoch_lock);\n    map<spg_t,epoch_t>::iterator t = pg_epoch.find(pgid);\n    assert(t != pg_epoch.end());\n    pg_epochs.erase(pg_epochs.find(t->second));\n    t->second = epoch;\n    pg_epochs.insert(epoch);\n  }\n  void pg_remove_epoch(spg_t pgid) {\n    Mutex::Locker l(pg_epoch_lock);\n    map<spg_t,epoch_t>::iterator t = pg_epoch.find(pgid);\n    if (t != pg_epoch.end()) {\n      pg_epochs.erase(pg_epochs.find(t->second));\n      pg_epoch.erase(t);\n    }\n  }\n  epoch_t get_min_pg_epoch() {\n    Mutex::Locker l(pg_epoch_lock);\n    if (pg_epochs.empty())\n      return 0;\n    else\n      return *pg_epochs.begin();\n  }\n\nprivate:\n  // -- superblock --\n  Mutex publish_lock, pre_publish_lock; // pre-publish orders before publish\n  OSDSuperblock superblock;\n\npublic:\n  OSDSuperblock get_superblock() {\n    Mutex::Locker l(publish_lock);\n    return superblock;\n  }\n  void publish_superblock(const OSDSuperblock &block) {\n    Mutex::Locker l(publish_lock);\n    superblock = block;\n  }\n\n  int get_nodeid() const { return whoami; }\n\n  std::atomic<epoch_t> max_oldest_map;\nprivate:\n  OSDMapRef osdmap;\n\npublic:\n  OSDMapRef get_osdmap() {\n    Mutex::Locker l(publish_lock);\n    return osdmap;\n  }\n  epoch_t get_osdmap_epoch() {\n    Mutex::Locker l(publish_lock);\n    return osdmap ? osdmap->get_epoch() : 0;\n  }\n  void publish_map(OSDMapRef map) {\n    Mutex::Locker l(publish_lock);\n    osdmap = map;\n  }\n\n  /*\n   * osdmap - current published map\n   * next_osdmap - pre_published map that is about to be published.\n   *\n   * We use the next_osdmap to send messages and initiate connections,\n   * but only if the target is the same instance as the one in the map\n   * epoch the current user is working from (i.e., the result is\n   * equivalent to what is in next_osdmap).\n   *\n   * This allows the helpers to start ignoring osds that are about to\n   * go down, and let OSD::handle_osd_map()/note_down_osd() mark them\n   * down, without worrying about reopening connections from threads\n   * working from old maps.\n   */\nprivate:\n  OSDMapRef next_osdmap;\n  Cond pre_publish_cond;\n\npublic:\n  void pre_publish_map(OSDMapRef map) {\n    Mutex::Locker l(pre_publish_lock);\n    next_osdmap = std::move(map);\n  }\n\n  void activate_map();\n  /// map epochs reserved below\n  map<epoch_t, unsigned> map_reservations;\n\n  /// gets ref to next_osdmap and registers the epoch as reserved\n  OSDMapRef get_nextmap_reserved() {\n    Mutex::Locker l(pre_publish_lock);\n    if (!next_osdmap)\n      return OSDMapRef();\n    epoch_t e = next_osdmap->get_epoch();\n    map<epoch_t, unsigned>::iterator i =\n      map_reservations.insert(make_pair(e, 0)).first;\n    i->second++;\n    return next_osdmap;\n  }\n  /// releases reservation on map\n  void release_map(OSDMapRef osdmap) {\n    Mutex::Locker l(pre_publish_lock);\n    map<epoch_t, unsigned>::iterator i =\n      map_reservations.find(osdmap->get_epoch());\n    assert(i != map_reservations.end());\n    assert(i->second > 0);\n    if (--(i->second) == 0) {\n      map_reservations.erase(i);\n    }\n    pre_publish_cond.Signal();\n  }\n  /// blocks until there are no reserved maps prior to next_osdmap\n  void await_reserved_maps() {\n    Mutex::Locker l(pre_publish_lock);\n    assert(next_osdmap);\n    while (true) {\n      map<epoch_t, unsigned>::const_iterator i = map_reservations.cbegin();\n      if (i == map_reservations.cend() || i->first >= next_osdmap->get_epoch()) {\n\tbreak;\n      } else {\n\tpre_publish_cond.Wait(pre_publish_lock);\n      }\n    }\n  }\n\nprivate:\n  Mutex peer_map_epoch_lock;\n  map<int, epoch_t> peer_map_epoch;\npublic:\n  epoch_t get_peer_epoch(int p);\n  epoch_t note_peer_epoch(int p, epoch_t e);\n  void forget_peer_epoch(int p, epoch_t e);\n\n  void send_map(class MOSDMap *m, Connection *con);\n  void send_incremental_map(epoch_t since, Connection *con, OSDMapRef& osdmap);\n  MOSDMap *build_incremental_map_msg(epoch_t from, epoch_t to,\n                                       OSDSuperblock& superblock);\n  bool should_share_map(entity_name_t name, Connection *con, epoch_t epoch,\n                        const OSDMapRef& osdmap, const epoch_t *sent_epoch_p);\n  void share_map(entity_name_t name, Connection *con, epoch_t epoch,\n                 OSDMapRef& osdmap, epoch_t *sent_epoch_p);\n  void share_map_peer(int peer, Connection *con,\n                      OSDMapRef map = OSDMapRef());\n\n  ConnectionRef get_con_osd_cluster(int peer, epoch_t from_epoch);\n  pair<ConnectionRef,ConnectionRef> get_con_osd_hb(int peer, epoch_t from_epoch);  // (back, front)\n  void send_message_osd_cluster(int peer, Message *m, epoch_t from_epoch);\n  void send_message_osd_cluster(Message *m, Connection *con) {\n    con->send_message(m);\n  }\n  void send_message_osd_cluster(Message *m, const ConnectionRef& con) {\n    con->send_message(m);\n  }\n  void send_message_osd_client(Message *m, Connection *con) {\n    con->send_message(m);\n  }\n  void send_message_osd_client(Message *m, const ConnectionRef& con) {\n    con->send_message(m);\n  }\n  entity_name_t get_cluster_msgr_name() {\n    return cluster_messenger->get_myname();\n  }\n\nprivate:\n  // -- scrub scheduling --\n  Mutex sched_scrub_lock;\n  int scrubs_pending;\n  int scrubs_active;\n\npublic:\n  struct ScrubJob {\n    CephContext* cct;\n    /// pg to be scrubbed\n    spg_t pgid;\n    /// a time scheduled for scrub. but the scrub could be delayed if system\n    /// load is too high or it fails to fall in the scrub hours\n    utime_t sched_time;\n    /// the hard upper bound of scrub time\n    utime_t deadline;\n    ScrubJob() : cct(nullptr) {}\n    explicit ScrubJob(CephContext* cct, const spg_t& pg,\n\t\t      const utime_t& timestamp,\n\t\t      double pool_scrub_min_interval = 0,\n\t\t      double pool_scrub_max_interval = 0, bool must = true);\n    /// order the jobs by sched_time\n    bool operator<(const ScrubJob& rhs) const;\n  };\n  set<ScrubJob> sched_scrub_pg;\n\n  /// @returns the scrub_reg_stamp used for unregister the scrub job\n  utime_t reg_pg_scrub(spg_t pgid, utime_t t, double pool_scrub_min_interval,\n\t\t       double pool_scrub_max_interval, bool must) {\n    ScrubJob scrub(cct, pgid, t, pool_scrub_min_interval, pool_scrub_max_interval,\n\t\t   must);\n    Mutex::Locker l(sched_scrub_lock);\n    sched_scrub_pg.insert(scrub);\n    return scrub.sched_time;\n  }\n  void unreg_pg_scrub(spg_t pgid, utime_t t) {\n    Mutex::Locker l(sched_scrub_lock);\n    size_t removed = sched_scrub_pg.erase(ScrubJob(cct, pgid, t));\n    assert(removed);\n  }\n  bool first_scrub_stamp(ScrubJob *out) {\n    Mutex::Locker l(sched_scrub_lock);\n    if (sched_scrub_pg.empty())\n      return false;\n    set<ScrubJob>::iterator iter = sched_scrub_pg.begin();\n    *out = *iter;\n    return true;\n  }\n  bool next_scrub_stamp(const ScrubJob& next,\n\t\t\tScrubJob *out) {\n    Mutex::Locker l(sched_scrub_lock);\n    if (sched_scrub_pg.empty())\n      return false;\n    set<ScrubJob>::const_iterator iter = sched_scrub_pg.lower_bound(next);\n    if (iter == sched_scrub_pg.cend())\n      return false;\n    ++iter;\n    if (iter == sched_scrub_pg.cend())\n      return false;\n    *out = *iter;\n    return true;\n  }\n\n  void dumps_scrub(Formatter *f) {\n    assert(f != nullptr);\n    Mutex::Locker l(sched_scrub_lock);\n\n    f->open_array_section(\"scrubs\");\n    for (const auto &i: sched_scrub_pg) {\n      f->open_object_section(\"scrub\");\n      f->dump_stream(\"pgid\") << i.pgid;\n      f->dump_stream(\"sched_time\") << i.sched_time;\n      f->dump_stream(\"deadline\") << i.deadline;\n      f->dump_bool(\"forced\", i.sched_time == i.deadline);\n      f->close_section();\n    }\n    f->close_section();\n  }\n\n  bool can_inc_scrubs_pending();\n  bool inc_scrubs_pending();\n  void inc_scrubs_active(bool reserved);\n  void dec_scrubs_pending();\n  void dec_scrubs_active();\n\n  void reply_op_error(OpRequestRef op, int err);\n  void reply_op_error(OpRequestRef op, int err, eversion_t v, version_t uv);\n  void handle_misdirected_op(PG *pg, OpRequestRef op);\n\n\nprivate:\n  // -- agent shared state --\n  Mutex agent_lock;\n  Cond agent_cond;\n  map<uint64_t, set<PGRef> > agent_queue;\n  set<PGRef>::iterator agent_queue_pos;\n  bool agent_valid_iterator;\n  int agent_ops;\n  int flush_mode_high_count; //once have one pg with FLUSH_MODE_HIGH then flush objects with high speed\n  set<hobject_t> agent_oids;\n  bool agent_active;\n  struct AgentThread : public Thread {\n    OSDService *osd;\n    explicit AgentThread(OSDService *o) : osd(o) {}\n    void *entry() override {\n      osd->agent_entry();\n      return NULL;\n    }\n  } agent_thread;\n  bool agent_stop_flag;\n  Mutex agent_timer_lock;\n  SafeTimer agent_timer;\n\npublic:\n  void agent_entry();\n  void agent_stop();\n\n  void _enqueue(PG *pg, uint64_t priority) {\n    if (!agent_queue.empty() &&\n\tagent_queue.rbegin()->first < priority)\n      agent_valid_iterator = false;  // inserting higher-priority queue\n    set<PGRef>& nq = agent_queue[priority];\n    if (nq.empty())\n      agent_cond.Signal();\n    nq.insert(pg);\n  }\n\n  void _dequeue(PG *pg, uint64_t old_priority) {\n    set<PGRef>& oq = agent_queue[old_priority];\n    set<PGRef>::iterator p = oq.find(pg);\n    assert(p != oq.end());\n    if (p == agent_queue_pos)\n      ++agent_queue_pos;\n    oq.erase(p);\n    if (oq.empty()) {\n      if (agent_queue.rbegin()->first == old_priority)\n\tagent_valid_iterator = false;\n      agent_queue.erase(old_priority);\n    }\n  }\n\n  /// enable agent for a pg\n  void agent_enable_pg(PG *pg, uint64_t priority) {\n    Mutex::Locker l(agent_lock);\n    _enqueue(pg, priority);\n  }\n\n  /// adjust priority for an enagled pg\n  void agent_adjust_pg(PG *pg, uint64_t old_priority, uint64_t new_priority) {\n    Mutex::Locker l(agent_lock);\n    assert(new_priority != old_priority);\n    _enqueue(pg, new_priority);\n    _dequeue(pg, old_priority);\n  }\n\n  /// disable agent for a pg\n  void agent_disable_pg(PG *pg, uint64_t old_priority) {\n    Mutex::Locker l(agent_lock);\n    _dequeue(pg, old_priority);\n  }\n\n  /// note start of an async (evict) op\n  void agent_start_evict_op() {\n    Mutex::Locker l(agent_lock);\n    ++agent_ops;\n  }\n\n  /// note finish or cancellation of an async (evict) op\n  void agent_finish_evict_op() {\n    Mutex::Locker l(agent_lock);\n    assert(agent_ops > 0);\n    --agent_ops;\n    agent_cond.Signal();\n  }\n\n  /// note start of an async (flush) op\n  void agent_start_op(const hobject_t& oid) {\n    Mutex::Locker l(agent_lock);\n    ++agent_ops;\n    assert(agent_oids.count(oid) == 0);\n    agent_oids.insert(oid);\n  }\n\n  /// note finish or cancellation of an async (flush) op\n  void agent_finish_op(const hobject_t& oid) {\n    Mutex::Locker l(agent_lock);\n    assert(agent_ops > 0);\n    --agent_ops;\n    assert(agent_oids.count(oid) == 1);\n    agent_oids.erase(oid);\n    agent_cond.Signal();\n  }\n\n  /// check if we are operating on an object\n  bool agent_is_active_oid(const hobject_t& oid) {\n    Mutex::Locker l(agent_lock);\n    return agent_oids.count(oid);\n  }\n\n  /// get count of active agent ops\n  int agent_get_num_ops() {\n    Mutex::Locker l(agent_lock);\n    return agent_ops;\n  }\n\n  void agent_inc_high_count() {\n    Mutex::Locker l(agent_lock);\n    flush_mode_high_count ++;\n  }\n\n  void agent_dec_high_count() {\n    Mutex::Locker l(agent_lock);\n    flush_mode_high_count --;\n  }\n\nprivate:\n  /// throttle promotion attempts\n  std::atomic_uint promote_probability_millis{1000}; ///< probability thousands. one word.\n  PromoteCounter promote_counter;\n  utime_t last_recalibrate;\n  unsigned long promote_max_objects, promote_max_bytes;\n\npublic:\n  bool promote_throttle() {\n    // NOTE: lockless!  we rely on the probability being a single word.\n    promote_counter.attempt();\n    if ((unsigned)rand() % 1000 > promote_probability_millis)\n      return true;  // yes throttle (no promote)\n    if (promote_max_objects &&\n\tpromote_counter.objects > promote_max_objects)\n      return true;  // yes throttle\n    if (promote_max_bytes &&\n\tpromote_counter.bytes > promote_max_bytes)\n      return true;  // yes throttle\n    return false;   //  no throttle (promote)\n  }\n  void promote_finish(uint64_t bytes) {\n    promote_counter.finish(bytes);\n  }\n  void promote_throttle_recalibrate();\n\n  // -- Objecter, for tiering reads/writes from/to other OSDs --\n  Objecter *objecter;\n  Finisher objecter_finisher;\n\n  // -- Watch --\n  Mutex watch_lock;\n  SafeTimer watch_timer;\n  uint64_t next_notif_id;\n  uint64_t get_next_id(epoch_t cur_epoch) {\n    Mutex::Locker l(watch_lock);\n    return (((uint64_t)cur_epoch) << 32) | ((uint64_t)(next_notif_id++));\n  }\n\n  // -- Recovery/Backfill Request Scheduling --\n  Mutex recovery_request_lock;\n  SafeTimer recovery_request_timer;\n\n  // For async recovery sleep\n  bool recovery_needs_sleep = true;\n  utime_t recovery_schedule_time = utime_t();\n\n  Mutex recovery_sleep_lock;\n  SafeTimer recovery_sleep_timer;\n\n  // -- tids --\n  // for ops i issue\n  std::atomic_uint last_tid{0};\n  ceph_tid_t get_tid() {\n    return (ceph_tid_t)last_tid++;\n  }\n\n  // -- backfill_reservation --\n  Finisher reserver_finisher;\n  AsyncReserver<spg_t> local_reserver;\n  AsyncReserver<spg_t> remote_reserver;\n\n  // -- pg_temp --\nprivate:\n  Mutex pg_temp_lock;\n  struct pg_temp_t {\n    pg_temp_t()\n    {}\n    pg_temp_t(vector<int> v, bool f)\n      : acting{v}, forced{f}\n    {}\n    vector<int> acting;\n    bool forced = false;\n  };\n  map<pg_t, pg_temp_t> pg_temp_wanted;\n  map<pg_t, pg_temp_t> pg_temp_pending;\n  void _sent_pg_temp();\n  friend std::ostream& operator<<(std::ostream&, const pg_temp_t&);\npublic:\n  void queue_want_pg_temp(pg_t pgid, const vector<int>& want,\n\t\t\t  bool forced = false);\n  void remove_want_pg_temp(pg_t pgid);\n  void requeue_pg_temp();\n  void send_pg_temp();\n\n  void send_pg_created(pg_t pgid);\n\n  void queue_for_peering(PG *pg);\n\n  Mutex snap_sleep_lock;\n  SafeTimer snap_sleep_timer;\n\n  Mutex scrub_sleep_lock;\n  SafeTimer scrub_sleep_timer;\n\n  AsyncReserver<spg_t> snap_reserver;\n  void queue_for_snap_trim(PG *pg);\n\n  void queue_for_scrub(PG *pg, bool with_high_priority) {\n    unsigned scrub_queue_priority = pg->scrubber.priority;\n    if (with_high_priority && scrub_queue_priority < cct->_conf->osd_client_op_priority) {\n      scrub_queue_priority = cct->_conf->osd_client_op_priority;\n    }\n    enqueue_back(\n      pg->info.pgid,\n      PGQueueable(\n\tPGScrub(pg->get_osdmap()->get_epoch()),\n\tcct->_conf->osd_scrub_cost,\n\tscrub_queue_priority,\n\tceph_clock_now(),\n\tentity_inst_t(),\n\tpg->get_osdmap()->get_epoch()));\n  }\n\nprivate:\n  // -- pg recovery and associated throttling --\n  Mutex recovery_lock;\n  list<pair<epoch_t, PGRef> > awaiting_throttle;\n\n  utime_t defer_recovery_until;\n  uint64_t recovery_ops_active;\n  uint64_t recovery_ops_reserved;\n  bool recovery_paused;\n#ifdef DEBUG_RECOVERY_OIDS\n  map<spg_t, set<hobject_t> > recovery_oids;\n#endif\n  bool _recover_now(uint64_t *available_pushes);\n  void _maybe_queue_recovery();\n  void _queue_for_recovery(\n    pair<epoch_t, PGRef> p, uint64_t reserved_pushes) {\n    assert(recovery_lock.is_locked_by_me());\n    enqueue_back(\n      p.second->info.pgid,\n      PGQueueable(\n\tPGRecovery(p.first, reserved_pushes),\n\tcct->_conf->osd_recovery_cost,\n\tcct->_conf->osd_recovery_priority,\n\tceph_clock_now(),\n\tentity_inst_t(),\n\tp.first));\n  }\npublic:\n  void start_recovery_op(PG *pg, const hobject_t& soid);\n  void finish_recovery_op(PG *pg, const hobject_t& soid, bool dequeue);\n  bool is_recovery_active();\n  void release_reserved_pushes(uint64_t pushes) {\n    Mutex::Locker l(recovery_lock);\n    assert(recovery_ops_reserved >= pushes);\n    recovery_ops_reserved -= pushes;\n    _maybe_queue_recovery();\n  }\n  void defer_recovery(float defer_for) {\n    defer_recovery_until = ceph_clock_now();\n    defer_recovery_until += defer_for;\n  }\n  void pause_recovery() {\n    Mutex::Locker l(recovery_lock);\n    recovery_paused = true;\n  }\n  bool recovery_is_paused() {\n    Mutex::Locker l(recovery_lock);\n    return recovery_paused;\n  }\n  void unpause_recovery() {\n    Mutex::Locker l(recovery_lock);\n    recovery_paused = false;\n    _maybe_queue_recovery();\n  }\n  void kick_recovery_queue() {\n    Mutex::Locker l(recovery_lock);\n    _maybe_queue_recovery();\n  }\n  void clear_queued_recovery(PG *pg) {\n    Mutex::Locker l(recovery_lock);\n    for (list<pair<epoch_t, PGRef> >::iterator i = awaiting_throttle.begin();\n\t i != awaiting_throttle.end();\n      ) {\n      if (i->second.get() == pg) {\n\tawaiting_throttle.erase(i);\n\treturn;\n      } else {\n\t++i;\n      }\n    }\n  }\n  // delayed pg activation\n  void queue_for_recovery(PG *pg) {\n    Mutex::Locker l(recovery_lock);\n\n    if (pg->get_state() & (PG_STATE_FORCED_RECOVERY | PG_STATE_FORCED_BACKFILL)) {\n      awaiting_throttle.push_front(make_pair(pg->get_osdmap()->get_epoch(), pg));\n    } else {\n      awaiting_throttle.push_back(make_pair(pg->get_osdmap()->get_epoch(), pg));\n    }\n    _maybe_queue_recovery();\n  }\n  void queue_recovery_after_sleep(PG *pg, epoch_t queued, uint64_t reserved_pushes) {\n    Mutex::Locker l(recovery_lock);\n    _queue_for_recovery(make_pair(queued, pg), reserved_pushes);\n  }\n\n  void adjust_pg_priorities(const vector<PGRef>& pgs, int newflags);\n\n  // osd map cache (past osd maps)\n  Mutex map_cache_lock;\n  SharedLRU<epoch_t, const OSDMap> map_cache;\n  SimpleLRU<epoch_t, bufferlist> map_bl_cache;\n  SimpleLRU<epoch_t, bufferlist> map_bl_inc_cache;\n\n  OSDMapRef try_get_map(epoch_t e);\n  OSDMapRef get_map(epoch_t e) {\n    OSDMapRef ret(try_get_map(e));\n    assert(ret);\n    return ret;\n  }\n  OSDMapRef add_map(OSDMap *o) {\n    Mutex::Locker l(map_cache_lock);\n    return _add_map(o);\n  }\n  OSDMapRef _add_map(OSDMap *o);\n\n  void add_map_bl(epoch_t e, bufferlist& bl) {\n    Mutex::Locker l(map_cache_lock);\n    return _add_map_bl(e, bl);\n  }\n  void pin_map_bl(epoch_t e, bufferlist &bl);\n  void _add_map_bl(epoch_t e, bufferlist& bl);\n  bool get_map_bl(epoch_t e, bufferlist& bl) {\n    Mutex::Locker l(map_cache_lock);\n    return _get_map_bl(e, bl);\n  }\n  bool _get_map_bl(epoch_t e, bufferlist& bl);\n\n  void add_map_inc_bl(epoch_t e, bufferlist& bl) {\n    Mutex::Locker l(map_cache_lock);\n    return _add_map_inc_bl(e, bl);\n  }\n  void pin_map_inc_bl(epoch_t e, bufferlist &bl);\n  void _add_map_inc_bl(epoch_t e, bufferlist& bl);\n  bool get_inc_map_bl(epoch_t e, bufferlist& bl);\n\n  void clear_map_bl_cache_pins(epoch_t e);\n\n  void need_heartbeat_peer_update();\n\n  void pg_stat_queue_enqueue(PG *pg);\n  void pg_stat_queue_dequeue(PG *pg);\n\n  void init();\n  void final_init();  \n  void start_shutdown();\n  void shutdown_reserver();\n  void shutdown();\n\nprivate:\n  // split\n  Mutex in_progress_split_lock;\n  map<spg_t, spg_t> pending_splits; // child -> parent\n  map<spg_t, set<spg_t> > rev_pending_splits; // parent -> [children]\n  set<spg_t> in_progress_splits;       // child\n\npublic:\n  void _start_split(spg_t parent, const set<spg_t> &children);\n  void start_split(spg_t parent, const set<spg_t> &children) {\n    Mutex::Locker l(in_progress_split_lock);\n    return _start_split(parent, children);\n  }\n  void mark_split_in_progress(spg_t parent, const set<spg_t> &pgs);\n  void complete_split(const set<spg_t> &pgs);\n  void cancel_pending_splits_for_parent(spg_t parent);\n  void _cancel_pending_splits_for_parent(spg_t parent);\n  bool splitting(spg_t pgid);\n  void expand_pg_num(OSDMapRef old_map,\n\t\t     OSDMapRef new_map);\n  void _maybe_split_pgid(OSDMapRef old_map,\n\t\t\t OSDMapRef new_map,\n\t\t\t spg_t pgid);\n  void init_splits_between(spg_t pgid, OSDMapRef frommap, OSDMapRef tomap);\n\n  // -- stats --\n  Mutex stat_lock;\n  osd_stat_t osd_stat;\n  uint32_t seq = 0;\n\n  void update_osd_stat(vector<int>& hb_peers);\n  osd_stat_t set_osd_stat(const struct store_statfs_t &stbuf,\n                          vector<int>& hb_peers,\n\t\t\t  int num_pgs);\n  osd_stat_t get_osd_stat() {\n    Mutex::Locker l(stat_lock);\n    ++seq;\n    osd_stat.up_from = up_epoch;\n    osd_stat.seq = ((uint64_t)osd_stat.up_from << 32) + seq;\n    return osd_stat;\n  }\n  uint64_t get_osd_stat_seq() {\n    Mutex::Locker l(stat_lock);\n    return osd_stat.seq;\n  }\n\n  // -- OSD Full Status --\nprivate:\n  friend TestOpsSocketHook;\n  mutable Mutex full_status_lock;\n  enum s_names { INVALID = -1, NONE, NEARFULL, BACKFILLFULL, FULL, FAILSAFE } cur_state;  // ascending\n  const char *get_full_state_name(s_names s) const {\n    switch (s) {\n    case NONE: return \"none\";\n    case NEARFULL: return \"nearfull\";\n    case BACKFILLFULL: return \"backfillfull\";\n    case FULL: return \"full\";\n    case FAILSAFE: return \"failsafe\";\n    default: return \"???\";\n    }\n  }\n  s_names get_full_state(string type) const {\n    if (type == \"none\")\n      return NONE;\n    else if (type == \"failsafe\")\n      return FAILSAFE;\n    else if (type == \"full\")\n      return FULL;\n    else if (type == \"backfillfull\")\n      return BACKFILLFULL;\n    else if (type == \"nearfull\")\n      return NEARFULL;\n    else\n      return INVALID;\n  }\n  double cur_ratio;  ///< current utilization\n  mutable int64_t injectfull = 0;\n  s_names injectfull_state = NONE;\n  float get_failsafe_full_ratio();\n  void check_full_status(float ratio);\n  bool _check_full(s_names type, ostream &ss) const;\npublic:\n  bool check_failsafe_full(ostream &ss) const;\n  bool check_full(ostream &ss) const;\n  bool check_backfill_full(ostream &ss) const;\n  bool check_nearfull(ostream &ss) const;\n  bool is_failsafe_full() const;\n  bool is_full() const;\n  bool is_backfillfull() const;\n  bool is_nearfull() const;\n  bool need_fullness_update();  ///< osdmap state needs update\n  void set_injectfull(s_names type, int64_t count);\n  bool check_osdmap_full(const set<pg_shard_t> &missing_on);\n\n\n  // -- epochs --\nprivate:\n  mutable Mutex epoch_lock; // protects access to boot_epoch, up_epoch, bind_epoch\n  epoch_t boot_epoch;  // _first_ epoch we were marked up (after this process started)\n  epoch_t up_epoch;    // _most_recent_ epoch we were marked up\n  epoch_t bind_epoch;  // epoch we last did a bind to new ip:ports\npublic:\n  /**\n   * Retrieve the boot_, up_, and bind_ epochs the OSD has set. The params\n   * can be NULL if you don't care about them.\n   */\n  void retrieve_epochs(epoch_t *_boot_epoch, epoch_t *_up_epoch,\n                       epoch_t *_bind_epoch) const;\n  /**\n   * Set the boot, up, and bind epochs. Any NULL params will not be set.\n   */\n  void set_epochs(const epoch_t *_boot_epoch, const epoch_t *_up_epoch,\n                  const epoch_t *_bind_epoch);\n  epoch_t get_boot_epoch() const {\n    epoch_t ret;\n    retrieve_epochs(&ret, NULL, NULL);\n    return ret;\n  }\n  epoch_t get_up_epoch() const {\n    epoch_t ret;\n    retrieve_epochs(NULL, &ret, NULL);\n    return ret;\n  }\n  epoch_t get_bind_epoch() const {\n    epoch_t ret;\n    retrieve_epochs(NULL, NULL, &ret);\n    return ret;\n  }\n\n  void request_osdmap_update(epoch_t e);\n\n  // -- stopping --\n  Mutex is_stopping_lock;\n  Cond is_stopping_cond;\n  enum {\n    NOT_STOPPING,\n    PREPARING_TO_STOP,\n    STOPPING };\n  std::atomic_int state{NOT_STOPPING};\n  int get_state() {\n    return state;\n  }\n  void set_state(int s) {\n    state = s;\n  }\n  bool is_stopping() const {\n    return state == STOPPING;\n  }\n  bool is_preparing_to_stop() const {\n    return state == PREPARING_TO_STOP;\n  }\n  bool prepare_to_stop();\n  void got_stop_ack();\n\n\n#ifdef PG_DEBUG_REFS\n  Mutex pgid_lock;\n  map<spg_t, int> pgid_tracker;\n  map<spg_t, PG*> live_pgs;\n  void add_pgid(spg_t pgid, PG *pg);\n  void remove_pgid(spg_t pgid, PG *pg);\n  void dump_live_pgids();\n#endif\n\n  explicit OSDService(OSD *osd);\n  ~OSDService();\n};\n\nclass OSD : public Dispatcher,\n\t    public md_config_obs_t {\n  /** OSD **/\n  Mutex osd_lock;\t\t\t// global lock\n  SafeTimer tick_timer;    // safe timer (osd_lock)\n\n  // Tick timer for those stuff that do not need osd_lock\n  Mutex tick_timer_lock;\n  SafeTimer tick_timer_without_osd_lock;\npublic:\n  // config observer bits\n  const char** get_tracked_conf_keys() const override;\n  void handle_conf_change(const struct md_config_t *conf,\n                          const std::set <std::string> &changed) override;\n  void update_log_config();\n  void check_config();\n\nprotected:\n\n  static const double OSD_TICK_INTERVAL; // tick interval for tick_timer and tick_timer_without_osd_lock\n\n  AuthAuthorizeHandlerRegistry *authorize_handler_cluster_registry;\n  AuthAuthorizeHandlerRegistry *authorize_handler_service_registry;\n\n  Messenger   *cluster_messenger;\n  Messenger   *client_messenger;\n  Messenger   *objecter_messenger;\n  MonClient   *monc; // check the \"monc helpers\" list before accessing directly\n  MgrClient   mgrc;\n  PerfCounters      *logger;\n  PerfCounters      *recoverystate_perf;\n  ObjectStore *store;\n#ifdef HAVE_LIBFUSE\n  FuseStore *fuse_store = nullptr;\n#endif\n  LogClient log_client;\n  LogChannelRef clog;\n\n  int whoami;\n  std::string dev_path, journal_path;\n\n  bool store_is_rotational = true;\n  bool journal_is_rotational = true;\n\n  ZTracer::Endpoint trace_endpoint;\n  void create_logger();\n  void create_recoverystate_perf();\n  void tick();\n  void tick_without_osd_lock();\n  void _dispatch(Message *m);\n  void dispatch_op(OpRequestRef op);\n\n  void check_osdmap_features(ObjectStore *store);\n\n  // asok\n  friend class OSDSocketHook;\n  class OSDSocketHook *asok_hook;\n  bool asok_command(string admin_command, cmdmap_t& cmdmap, string format, ostream& ss);\n\npublic:\n  ClassHandler  *class_handler = nullptr;\n  int get_nodeid() { return whoami; }\n  \n  static ghobject_t get_osdmap_pobject_name(epoch_t epoch) {\n    char foo[20];\n    snprintf(foo, sizeof(foo), \"osdmap.%d\", epoch);\n    return ghobject_t(hobject_t(sobject_t(object_t(foo), 0)));\n  }\n  static ghobject_t get_inc_osdmap_pobject_name(epoch_t epoch) {\n    char foo[22];\n    snprintf(foo, sizeof(foo), \"inc_osdmap.%d\", epoch);\n    return ghobject_t(hobject_t(sobject_t(object_t(foo), 0)));\n  }\n\n  static ghobject_t make_snapmapper_oid() {\n    return ghobject_t(hobject_t(\n      sobject_t(\n\tobject_t(\"snapmapper\"),\n\t0)));\n  }\n\n  static ghobject_t make_pg_log_oid(spg_t pg) {\n    stringstream ss;\n    ss << \"pglog_\" << pg;\n    string s;\n    getline(ss, s);\n    return ghobject_t(hobject_t(sobject_t(object_t(s.c_str()), 0)));\n  }\n  \n  static ghobject_t make_pg_biginfo_oid(spg_t pg) {\n    stringstream ss;\n    ss << \"pginfo_\" << pg;\n    string s;\n    getline(ss, s);\n    return ghobject_t(hobject_t(sobject_t(object_t(s.c_str()), 0)));\n  }\n  static ghobject_t make_infos_oid() {\n    hobject_t oid(sobject_t(\"infos\", CEPH_NOSNAP));\n    return ghobject_t(oid);\n  }\n  static void recursive_remove_collection(CephContext* cct,\n\t\t\t\t\t  ObjectStore *store,\n\t\t\t\t\t  spg_t pgid,\n\t\t\t\t\t  coll_t tmp);\n\n  /**\n   * get_osd_initial_compat_set()\n   *\n   * Get the initial feature set for this OSD.  Features\n   * here are automatically upgraded.\n   *\n   * Return value: Initial osd CompatSet\n   */\n  static CompatSet get_osd_initial_compat_set();\n\n  /**\n   * get_osd_compat_set()\n   *\n   * Get all features supported by this OSD\n   *\n   * Return value: CompatSet of all supported features\n   */\n  static CompatSet get_osd_compat_set();\n  \n\nprivate:\n  class C_Tick;\n  class C_Tick_WithoutOSDLock;\n\n  // -- superblock --\n  OSDSuperblock superblock;\n\n  void write_superblock();\n  void write_superblock(ObjectStore::Transaction& t);\n  int read_superblock();\n\n  void clear_temp_objects();\n\n  CompatSet osd_compat;\n\n  // -- state --\npublic:\n  typedef enum {\n    STATE_INITIALIZING = 1,\n    STATE_PREBOOT,\n    STATE_BOOTING,\n    STATE_ACTIVE,\n    STATE_STOPPING,\n    STATE_WAITING_FOR_HEALTHY\n  } osd_state_t;\n\n  static const char *get_state_name(int s) {\n    switch (s) {\n    case STATE_INITIALIZING: return \"initializing\";\n    case STATE_PREBOOT: return \"preboot\";\n    case STATE_BOOTING: return \"booting\";\n    case STATE_ACTIVE: return \"active\";\n    case STATE_STOPPING: return \"stopping\";\n    case STATE_WAITING_FOR_HEALTHY: return \"waiting_for_healthy\";\n    default: return \"???\";\n    }\n  }\n\nprivate:\n  std::atomic_int state{STATE_INITIALIZING};\n  bool waiting_for_luminous_mons = false;\n\npublic:\n  int get_state() const {\n    return state;\n  }\n  void set_state(int s) {\n    state = s;\n  }\n  bool is_initializing() const {\n    return state == STATE_INITIALIZING;\n  }\n  bool is_preboot() const {\n    return state == STATE_PREBOOT;\n  }\n  bool is_booting() const {\n    return state == STATE_BOOTING;\n  }\n  bool is_active() const {\n    return state == STATE_ACTIVE;\n  }\n  bool is_stopping() const {\n    return state == STATE_STOPPING;\n  }\n  bool is_waiting_for_healthy() const {\n    return state == STATE_WAITING_FOR_HEALTHY;\n  }\n\nprivate:\n\n  ThreadPool peering_tp;\n  ShardedThreadPool osd_op_tp;\n  ThreadPool disk_tp;\n  ThreadPool command_tp;\n\n  void set_disk_tp_priority();\n  void get_latest_osdmap();\n\n  // -- sessions --\nprivate:\n  void dispatch_session_waiting(Session *session, OSDMapRef osdmap);\n  void maybe_share_map(Session *session, OpRequestRef op, OSDMapRef osdmap);\n\n  Mutex session_waiting_lock;\n  set<Session*> session_waiting_for_map;\n\n  /// Caller assumes refs for included Sessions\n  void get_sessions_waiting_for_map(set<Session*> *out) {\n    Mutex::Locker l(session_waiting_lock);\n    out->swap(session_waiting_for_map);\n  }\n  void register_session_waiting_on_map(Session *session) {\n    Mutex::Locker l(session_waiting_lock);\n    if (session_waiting_for_map.insert(session).second) {\n      session->get();\n    }\n  }\n  void clear_session_waiting_on_map(Session *session) {\n    Mutex::Locker l(session_waiting_lock);\n    set<Session*>::iterator i = session_waiting_for_map.find(session);\n    if (i != session_waiting_for_map.end()) {\n      (*i)->put();\n      session_waiting_for_map.erase(i);\n    }\n  }\n  void dispatch_sessions_waiting_on_map() {\n    set<Session*> sessions_to_check;\n    get_sessions_waiting_for_map(&sessions_to_check);\n    for (set<Session*>::iterator i = sessions_to_check.begin();\n\t i != sessions_to_check.end();\n\t sessions_to_check.erase(i++)) {\n      (*i)->session_dispatch_lock.Lock();\n      dispatch_session_waiting(*i, osdmap);\n      (*i)->session_dispatch_lock.Unlock();\n      (*i)->put();\n    }\n  }\n  void session_handle_reset(Session *session) {\n    Mutex::Locker l(session->session_dispatch_lock);\n    clear_session_waiting_on_map(session);\n\n    session->clear_backoffs();\n\n    /* Messages have connection refs, we need to clear the\n     * connection->session->message->connection\n     * cycles which result.\n     * Bug #12338\n     */\n    session->waiting_on_map.clear_and_dispose(TrackedOp::Putter());\n  }\n\nprivate:\n  /**\n   * @defgroup monc helpers\n   * @{\n   * Right now we only have the one\n   */\n\n  /**\n   * Ask the Monitors for a sequence of OSDMaps.\n   *\n   * @param epoch The epoch to start with when replying\n   * @param force_request True if this request forces a new subscription to\n   * the monitors; false if an outstanding request that encompasses it is\n   * sufficient.\n   */\n  void osdmap_subscribe(version_t epoch, bool force_request);\n  /** @} monc helpers */\n\n  Mutex osdmap_subscribe_lock;\n  epoch_t latest_subscribed_epoch{0};\n\n  // -- heartbeat --\n  /// information about a heartbeat peer\n  struct HeartbeatInfo {\n    int peer;           ///< peer\n    ConnectionRef con_front;   ///< peer connection (front)\n    ConnectionRef con_back;    ///< peer connection (back)\n    utime_t first_tx;   ///< time we sent our first ping request\n    utime_t last_tx;    ///< last time we sent a ping request\n    utime_t last_rx_front;  ///< last time we got a ping reply on the front side\n    utime_t last_rx_back;   ///< last time we got a ping reply on the back side\n    epoch_t epoch;      ///< most recent epoch we wanted this peer\n\n    bool is_unhealthy(utime_t cutoff) const {\n      return\n\t! ((last_rx_front > cutoff ||\n\t    (last_rx_front == utime_t() && (last_tx == utime_t() ||\n\t\t\t\t\t    first_tx > cutoff))) &&\n\t   (last_rx_back > cutoff ||\n\t    (last_rx_back == utime_t() && (last_tx == utime_t() ||\n\t\t\t\t\t   first_tx > cutoff))));\n    }\n    bool is_healthy(utime_t cutoff) const {\n      return last_rx_front > cutoff && last_rx_back > cutoff;\n    }\n\n  };\n  /// state attached to outgoing heartbeat connections\n  struct HeartbeatSession : public RefCountedObject {\n    int peer;\n    explicit HeartbeatSession(int p) : peer(p) {}\n  };\n  Mutex heartbeat_lock;\n  map<int, int> debug_heartbeat_drops_remaining;\n  Cond heartbeat_cond;\n  bool heartbeat_stop;\n  std::atomic_bool heartbeat_need_update;   \n  map<int,HeartbeatInfo> heartbeat_peers;  ///< map of osd id to HeartbeatInfo\n  utime_t last_mon_heartbeat;\n  Messenger *hb_front_client_messenger;\n  Messenger *hb_back_client_messenger;\n  Messenger *hb_front_server_messenger;\n  Messenger *hb_back_server_messenger;\n  utime_t last_heartbeat_resample;   ///< last time we chose random peers in waiting-for-healthy state\n  double daily_loadavg;\n  \n  void _add_heartbeat_peer(int p);\n  void _remove_heartbeat_peer(int p);\n  bool heartbeat_reset(Connection *con);\n  void maybe_update_heartbeat_peers();\n  void reset_heartbeat_peers();\n  bool heartbeat_peers_need_update() {\n    return heartbeat_need_update.load();\n  }\n  void heartbeat_set_peers_need_update() {\n    heartbeat_need_update.store(true);\n  }\n  void heartbeat_clear_peers_need_update() {\n    heartbeat_need_update.store(false);\n  }\n  void heartbeat();\n  void heartbeat_check();\n  void heartbeat_entry();\n  void need_heartbeat_peer_update();\n\n  void heartbeat_kick() {\n    Mutex::Locker l(heartbeat_lock);\n    heartbeat_cond.Signal();\n  }\n\n  struct T_Heartbeat : public Thread {\n    OSD *osd;\n    explicit T_Heartbeat(OSD *o) : osd(o) {}\n    void *entry() override {\n      osd->heartbeat_entry();\n      return 0;\n    }\n  } heartbeat_thread;\n\npublic:\n  bool heartbeat_dispatch(Message *m);\n\n  struct HeartbeatDispatcher : public Dispatcher {\n    OSD *osd;\n    explicit HeartbeatDispatcher(OSD *o) : Dispatcher(o->cct), osd(o) {}\n\n    bool ms_can_fast_dispatch_any() const override { return true; }\n    bool ms_can_fast_dispatch(const Message *m) const override {\n      switch (m->get_type()) {\n\tcase CEPH_MSG_PING:\n\tcase MSG_OSD_PING:\n          return true;\n\tdefault:\n          return false;\n\t}\n    }\n    void ms_fast_dispatch(Message *m) override {\n      osd->heartbeat_dispatch(m);\n    }\n    bool ms_dispatch(Message *m) override {\n      return osd->heartbeat_dispatch(m);\n    }\n    bool ms_handle_reset(Connection *con) override {\n      return osd->heartbeat_reset(con);\n    }\n    void ms_handle_remote_reset(Connection *con) override {}\n    bool ms_handle_refused(Connection *con) override {\n      return osd->ms_handle_refused(con);\n    }\n    bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t      int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,\n\t\t\t      bool& isvalid, CryptoKey& session_key,\n\t\t\t      std::unique_ptr<AuthAuthorizerChallenge> *challenge) override {\n      isvalid = true;\n      return true;\n    }\n  } heartbeat_dispatcher;\n\nprivate:\n  // -- waiters --\n  list<OpRequestRef> finished;\n  \n  void take_waiters(list<OpRequestRef>& ls) {\n    assert(osd_lock.is_locked());\n    finished.splice(finished.end(), ls);\n  }\n  void do_waiters();\n  \n  // -- op tracking --\n  OpTracker op_tracker;\n  void check_ops_in_flight();\n  void test_ops(std::string command, std::string args, ostream& ss);\n  friend class TestOpsSocketHook;\n  TestOpsSocketHook *test_ops_hook;\n  friend struct C_CompleteSplits;\n  friend struct C_OpenPGs;\n\n  // -- op queue --\n  enum class io_queue {\n    prioritized,\n    weightedpriority,\n    mclock_opclass,\n    mclock_client,\n  };\n  friend std::ostream& operator<<(std::ostream& out, const OSD::io_queue& q);\n\n  const io_queue op_queue;\n  const unsigned int op_prio_cutoff;\n\n  /*\n   * The ordered op delivery chain is:\n   *\n   *   fast dispatch -> pqueue back\n   *                    pqueue front <-> to_process back\n   *                                     to_process front  -> RunVis(item)\n   *                                                      <- queue_front()\n   *\n   * The pqueue is per-shard, and to_process is per pg_slot.  Items can be\n   * pushed back up into to_process and/or pqueue while order is preserved.\n   *\n   * Multiple worker threads can operate on each shard.\n   *\n   * Under normal circumstances, num_running == to_proces.size().  There are\n   * two times when that is not true: (1) when waiting_for_pg == true and\n   * to_process is accumulating requests that are waiting for the pg to be\n   * instantiated; in that case they will all get requeued together by\n   * wake_pg_waiters, and (2) when wake_pg_waiters just ran, waiting_for_pg\n   * and already requeued the items.\n   */\n  friend class PGQueueable;\n\n  class ShardedOpWQ\n    : public ShardedThreadPool::ShardedWQ<pair<spg_t,PGQueueable>>\n  {\n    struct ShardData {\n      Mutex sdata_lock;\n      Cond sdata_cond;\n\n      Mutex sdata_op_ordering_lock;   ///< protects all members below\n\n      OSDMapRef waiting_for_pg_osdmap;\n      struct pg_slot {\n\tPGRef pg;                     ///< cached pg reference [optional]\n\tlist<PGQueueable> to_process; ///< order items for this slot\n\tint num_running = 0;          ///< _process threads doing pg lookup/lock\n\n\t/// true if pg does/did not exist. if so all new items go directly to\n\t/// to_process.  cleared by prune_pg_waiters.\n\tbool waiting_for_pg = false;\n\n\t/// incremented by wake_pg_waiters; indicates racing _process threads\n\t/// should bail out (their op has been requeued)\n\tuint64_t requeue_seq = 0;\n      };\n\n      /// map of slots for each spg_t.  maintains ordering of items dequeued\n      /// from pqueue while _process thread drops shard lock to acquire the\n      /// pg lock.  slots are removed only by prune_pg_waiters.\n      unordered_map<spg_t,pg_slot> pg_slots;\n\n      /// priority queue\n      std::unique_ptr<OpQueue< pair<spg_t, PGQueueable>, entity_inst_t>> pqueue;\n\n      void _enqueue_front(pair<spg_t, PGQueueable> item, unsigned cutoff) {\n\tunsigned priority = item.second.get_priority();\n\tunsigned cost = item.second.get_cost();\n\tif (priority >= cutoff)\n\t  pqueue->enqueue_strict_front(\n\t    item.second.get_owner(),\n\t    priority, item);\n\telse\n\t  pqueue->enqueue_front(\n\t    item.second.get_owner(),\n\t    priority, cost, item);\n      }\n\n      ShardData(\n\tstring lock_name, string ordering_lock,\n\tuint64_t max_tok_per_prio, uint64_t min_cost, CephContext *cct,\n\tio_queue opqueue)\n\t: sdata_lock(lock_name.c_str(), false, true, false, cct),\n\t  sdata_op_ordering_lock(ordering_lock.c_str(), false, true,\n\t\t\t\t false, cct) {\n\tif (opqueue == io_queue::weightedpriority) {\n\t  pqueue = std::unique_ptr\n\t    <WeightedPriorityQueue<pair<spg_t,PGQueueable>,entity_inst_t>>(\n\t      new WeightedPriorityQueue<pair<spg_t,PGQueueable>,entity_inst_t>(\n\t\tmax_tok_per_prio, min_cost));\n\t} else if (opqueue == io_queue::prioritized) {\n\t  pqueue = std::unique_ptr\n\t    <PrioritizedQueue<pair<spg_t,PGQueueable>,entity_inst_t>>(\n\t      new PrioritizedQueue<pair<spg_t,PGQueueable>,entity_inst_t>(\n\t\tmax_tok_per_prio, min_cost));\n\t} else if (opqueue == io_queue::mclock_opclass) {\n\t  pqueue = std::unique_ptr\n\t    <ceph::mClockOpClassQueue>(new ceph::mClockOpClassQueue(cct));\n\t} else if (opqueue == io_queue::mclock_client) {\n\t  pqueue = std::unique_ptr\n\t    <ceph::mClockClientQueue>(new ceph::mClockClientQueue(cct));\n\t}\n      }\n    }; // struct ShardData\n\n    vector<ShardData*> shard_list;\n    OSD *osd;\n    uint32_t num_shards;\n\n  public:\n    ShardedOpWQ(uint32_t pnum_shards,\n\t\tOSD *o,\n\t\ttime_t ti,\n\t\ttime_t si,\n\t\tShardedThreadPool* tp)\n      : ShardedThreadPool::ShardedWQ<pair<spg_t,PGQueueable>>(ti, si, tp),\n        osd(o),\n        num_shards(pnum_shards) {\n      for (uint32_t i = 0; i < num_shards; i++) {\n\tchar lock_name[32] = {0};\n\tsnprintf(lock_name, sizeof(lock_name), \"%s.%d\", \"OSD:ShardedOpWQ:\", i);\n\tchar order_lock[32] = {0};\n\tsnprintf(order_lock, sizeof(order_lock), \"%s.%d\",\n\t\t \"OSD:ShardedOpWQ:order:\", i);\n\tShardData* one_shard = new ShardData(\n\t  lock_name, order_lock,\n\t  osd->cct->_conf->osd_op_pq_max_tokens_per_priority, \n\t  osd->cct->_conf->osd_op_pq_min_cost, osd->cct, osd->op_queue);\n\tshard_list.push_back(one_shard);\n      }\n    }\n    ~ShardedOpWQ() override {\n      while (!shard_list.empty()) {\n\tdelete shard_list.back();\n\tshard_list.pop_back();\n      }\n    }\n\n    /// wake any pg waiters after a PG is created/instantiated\n    void wake_pg_waiters(spg_t pgid);\n\n    /// prune ops (and possiblye pg_slots) for pgs that shouldn't be here\n    void prune_pg_waiters(OSDMapRef osdmap, int whoami);\n\n    /// clear cached PGRef on pg deletion\n    void clear_pg_pointer(spg_t pgid);\n\n    /// clear pg_slots on shutdown\n    void clear_pg_slots();\n\n    /// try to do some work\n    void _process(uint32_t thread_index, heartbeat_handle_d *hb) override;\n\n    /// enqueue a new item\n    void _enqueue(pair <spg_t, PGQueueable> item) override;\n\n    /// requeue an old item (at the front of the line)\n    void _enqueue_front(pair <spg_t, PGQueueable> item) override;\n      \n    void return_waiting_threads() override {\n      for(uint32_t i = 0; i < num_shards; i++) {\n\tShardData* sdata = shard_list[i];\n\tassert (NULL != sdata); \n\tsdata->sdata_lock.Lock();\n\tsdata->sdata_cond.Signal();\n\tsdata->sdata_lock.Unlock();\n      }\n    }\n\n    void dump(Formatter *f) {\n      for(uint32_t i = 0; i < num_shards; i++) {\n\tShardData* sdata = shard_list[i];\n\tchar lock_name[32] = {0};\n\tsnprintf(lock_name, sizeof(lock_name), \"%s%d\", \"OSD:ShardedOpWQ:\", i);\n\tassert (NULL != sdata);\n\tsdata->sdata_op_ordering_lock.Lock();\n\tf->open_object_section(lock_name);\n\tsdata->pqueue->dump(f);\n\tf->close_section();\n\tsdata->sdata_op_ordering_lock.Unlock();\n      }\n    }\n\n    /// Must be called on ops queued back to front\n    struct Pred {\n      spg_t pgid;\n      list<OpRequestRef> *out_ops;\n      uint64_t reserved_pushes_to_free;\n      Pred(spg_t pg, list<OpRequestRef> *out_ops = 0)\n\t: pgid(pg), out_ops(out_ops), reserved_pushes_to_free(0) {}\n      void accumulate(const PGQueueable &op) {\n\treserved_pushes_to_free += op.get_reserved_pushes();\n\tif (out_ops) {\n\t  boost::optional<OpRequestRef> mop = op.maybe_get_op();\n\t  if (mop)\n\t    out_ops->push_front(*mop);\n\t}\n      }\n      bool operator()(const pair<spg_t, PGQueueable> &op) {\n\tif (op.first == pgid) {\n\t  accumulate(op.second);\n\t  return true;\n\t} else {\n\t  return false;\n\t}\n      }\n      uint64_t get_reserved_pushes_to_free() const {\n\treturn reserved_pushes_to_free;\n      }\n    };\n\n    bool is_shard_empty(uint32_t thread_index) override {\n      uint32_t shard_index = thread_index % num_shards; \n      ShardData* sdata = shard_list[shard_index];\n      assert(NULL != sdata);\n      Mutex::Locker l(sdata->sdata_op_ordering_lock);\n      return sdata->pqueue->empty();\n    }\n  } op_shardedwq;\n\n\n  void enqueue_op(spg_t pg, OpRequestRef& op, epoch_t epoch);\n  void dequeue_op(\n    PGRef pg, OpRequestRef op,\n    ThreadPool::TPHandle &handle);\n\n  // -- peering queue --\n  struct PeeringWQ : public ThreadPool::BatchWorkQueue<PG> {\n    list<PG*> peering_queue;\n    OSD *osd;\n    set<PG*> in_use;\n    PeeringWQ(OSD *o, time_t ti, time_t si, ThreadPool *tp)\n      : ThreadPool::BatchWorkQueue<PG>(\n\t\"OSD::PeeringWQ\", ti, si, tp), osd(o) {}\n\n    void _dequeue(PG *pg) override {\n      for (list<PG*>::iterator i = peering_queue.begin();\n\t   i != peering_queue.end();\n\t   ) {\n\tif (*i == pg) {\n\t  peering_queue.erase(i++);\n\t  pg->put(\"PeeringWQ\");\n\t} else {\n\t  ++i;\n\t}\n      }\n    }\n    bool _enqueue(PG *pg) override {\n      pg->get(\"PeeringWQ\");\n      peering_queue.push_back(pg);\n      return true;\n    }\n    bool _empty() override {\n      return peering_queue.empty();\n    }\n    void _dequeue(list<PG*> *out) override;\n    void _process(\n      const list<PG *> &pgs,\n      ThreadPool::TPHandle &handle) override {\n      assert(!pgs.empty());\n      osd->process_peering_events(pgs, handle);\n      for (list<PG *>::const_iterator i = pgs.begin();\n\t   i != pgs.end();\n\t   ++i) {\n\t(*i)->put(\"PeeringWQ\");\n      }\n    }\n    void _process_finish(const list<PG *> &pgs) override {\n      for (list<PG*>::const_iterator i = pgs.begin();\n\t   i != pgs.end();\n\t   ++i) {\n\tin_use.erase(*i);\n      }\n    }\n    void _clear() override {\n      assert(peering_queue.empty());\n    }\n  } peering_wq;\n\n  void process_peering_events(\n    const list<PG*> &pg,\n    ThreadPool::TPHandle &handle);\n\n  friend class PG;\n  friend class PrimaryLogPG;\n\n\n protected:\n\n  // -- osd map --\n  OSDMapRef       osdmap;\n  OSDMapRef get_osdmap() {\n    return osdmap;\n  }\n  epoch_t get_osdmap_epoch() const {\n    return osdmap ? osdmap->get_epoch() : 0;\n  }\n\n  utime_t         had_map_since;\n  RWLock          map_lock;\n  list<OpRequestRef>  waiting_for_osdmap;\n  deque<utime_t> osd_markdown_log;\n\n  friend struct send_map_on_destruct;\n\n  void wait_for_new_map(OpRequestRef op);\n  void handle_osd_map(class MOSDMap *m);\n  void _committed_osd_maps(epoch_t first, epoch_t last, class MOSDMap *m);\n  void trim_maps(epoch_t oldest, int nreceived, bool skip_maps);\n  void note_down_osd(int osd);\n  void note_up_osd(int osd);\n  friend class C_OnMapCommit;\n\n  bool advance_pg(\n    epoch_t advance_to, PG *pg,\n    ThreadPool::TPHandle &handle,\n    PG::RecoveryCtx *rctx,\n    set<PGRef> *split_pgs\n  );\n  void consume_map();\n  void activate_map();\n\n  // osd map cache (past osd maps)\n  OSDMapRef get_map(epoch_t e) {\n    return service.get_map(e);\n  }\n  OSDMapRef add_map(OSDMap *o) {\n    return service.add_map(o);\n  }\n  void add_map_bl(epoch_t e, bufferlist& bl) {\n    return service.add_map_bl(e, bl);\n  }\n  void pin_map_bl(epoch_t e, bufferlist &bl) {\n    return service.pin_map_bl(e, bl);\n  }\n  bool get_map_bl(epoch_t e, bufferlist& bl) {\n    return service.get_map_bl(e, bl);\n  }\n  void add_map_inc_bl(epoch_t e, bufferlist& bl) {\n    return service.add_map_inc_bl(e, bl);\n  }\n  void pin_map_inc_bl(epoch_t e, bufferlist &bl) {\n    return service.pin_map_inc_bl(e, bl);\n  }\n\nprotected:\n  // -- placement groups --\n  RWLock pg_map_lock; // this lock orders *above* individual PG _locks\n  ceph::unordered_map<spg_t, PG*> pg_map; // protected by pg_map lock\n\n  std::mutex pending_creates_lock;\n  using create_from_osd_t = std::pair<pg_t, bool /* is primary*/>;\n  std::set<create_from_osd_t> pending_creates_from_osd;\n  unsigned pending_creates_from_mon = 0;\n\n  map<spg_t, list<PG::CephPeeringEvtRef> > peering_wait_for_split;\n  PGRecoveryStats pg_recovery_stats;\n\n  PGPool _get_pool(int id, OSDMapRef createmap);\n\n  PG   *_lookup_lock_pg_with_map_lock_held(spg_t pgid);\n  PG   *_lookup_lock_pg(spg_t pgid);\n\npublic:\n  PG   *lookup_lock_pg(spg_t pgid);\n\n  int get_num_pgs() {\n    RWLock::RLocker l(pg_map_lock);\n    return pg_map.size();\n  }\n\nprotected:\n  PG   *_open_lock_pg(OSDMapRef createmap,\n\t\t      spg_t pg, bool no_lockdep_check=false);\n  enum res_result {\n    RES_PARENT,    // resurrected a parent\n    RES_SELF,      // resurrected self\n    RES_NONE       // nothing relevant deleting\n  };\n  res_result _try_resurrect_pg(\n    OSDMapRef curmap, spg_t pgid, spg_t *resurrected, PGRef *old_pg_state);\n\n  PG   *_create_lock_pg(\n    OSDMapRef createmap,\n    spg_t pgid,\n    bool hold_map_lock,\n    bool backfill,\n    int role,\n    vector<int>& up, int up_primary,\n    vector<int>& acting, int acting_primary,\n    pg_history_t history,\n    const PastIntervals& pi,\n    ObjectStore::Transaction& t);\n\n  PG* _make_pg(OSDMapRef createmap, spg_t pgid);\n  void add_newly_split_pg(PG *pg,\n\t\t\t  PG::RecoveryCtx *rctx);\n\n  int handle_pg_peering_evt(\n    spg_t pgid,\n    const pg_history_t& orig_history,\n    const PastIntervals& pi,\n    epoch_t epoch,\n    PG::CephPeeringEvtRef evt);\n  bool maybe_wait_for_max_pg(spg_t pgid, bool is_mon_create);\n  void resume_creating_pg();\n\n  void load_pgs();\n  void build_past_intervals_parallel();\n\n  /// build initial pg history and intervals on create\n  void build_initial_pg_history(\n    spg_t pgid,\n    epoch_t created,\n    utime_t created_stamp,\n    pg_history_t *h,\n    PastIntervals *pi);\n\n  /// project pg history from from to now\n  bool project_pg_history(\n    spg_t pgid, pg_history_t& h, epoch_t from,\n    const vector<int>& lastup,\n    int lastupprimary,\n    const vector<int>& lastacting,\n    int lastactingprimary\n    ); ///< @return false if there was a map gap between from and now\n\n  // this must be called with pg->lock held on any pg addition to pg_map\n  void wake_pg_waiters(PGRef pg) {\n    assert(pg->is_locked());\n    op_shardedwq.wake_pg_waiters(pg->info.pgid);\n  }\n  epoch_t last_pg_create_epoch;\n\n  void handle_pg_create(OpRequestRef op);\n\n  void split_pgs(\n    PG *parent,\n    const set<spg_t> &childpgids, set<PGRef> *out_pgs,\n    OSDMapRef curmap,\n    OSDMapRef nextmap,\n    PG::RecoveryCtx *rctx);\n\n  // == monitor interaction ==\n  Mutex mon_report_lock;\n  utime_t last_mon_report;\n  utime_t last_pg_stats_sent;\n\n  /* if our monitor dies, we want to notice it and reconnect.\n   *  So we keep track of when it last acked our stat updates,\n   *  and if too much time passes (and we've been sending\n   *  more updates) then we can call it dead and reconnect\n   *  elsewhere.\n   */\n  utime_t last_pg_stats_ack;\n  float stats_ack_timeout;\n  set<uint64_t> outstanding_pg_stats; // how many stat updates haven't been acked yet\n\n  // -- boot --\n  void start_boot();\n  void _got_mon_epochs(epoch_t oldest, epoch_t newest);\n  void _preboot(epoch_t oldest, epoch_t newest);\n  void _send_boot();\n  void _collect_metadata(map<string,string> *pmeta);\n\n  void start_waiting_for_healthy();\n  bool _is_healthy();\n\n  void send_full_update();\n  \n  friend struct C_OSD_GetVersion;\n\n  // -- alive --\n  epoch_t up_thru_wanted;\n\n  void queue_want_up_thru(epoch_t want);\n  void send_alive();\n\n  // -- full map requests --\n  epoch_t requested_full_first, requested_full_last;\n\n  void request_full_map(epoch_t first, epoch_t last);\n  void rerequest_full_maps() {\n    epoch_t first = requested_full_first;\n    epoch_t last = requested_full_last;\n    requested_full_first = 0;\n    requested_full_last = 0;\n    request_full_map(first, last);\n  }\n  void got_full_map(epoch_t e);\n\n  // -- failures --\n  map<int,utime_t> failure_queue;\n  map<int,pair<utime_t,entity_inst_t> > failure_pending;\n\n  void requeue_failures();\n  void send_failures();\n  void send_still_alive(epoch_t epoch, const entity_inst_t &i);\n\n  // -- pg stats --\n  Mutex pg_stat_queue_lock;\n  Cond pg_stat_queue_cond;\n  xlist<PG*> pg_stat_queue;\n  bool osd_stat_updated;\n  uint64_t pg_stat_tid, pg_stat_tid_flushed;\n\n  void send_pg_stats(const utime_t &now);\n  void handle_pg_stats_ack(class MPGStatsAck *ack);\n  void flush_pg_stats();\n\n  ceph::coarse_mono_clock::time_point last_sent_beacon;\n  Mutex min_last_epoch_clean_lock{\"OSD::min_last_epoch_clean_lock\"};\n  epoch_t min_last_epoch_clean = 0;\n  // which pgs were scanned for min_lec\n  std::vector<pg_t> min_last_epoch_clean_pgs;\n  void send_beacon(const ceph::coarse_mono_clock::time_point& now);\n\n  void pg_stat_queue_enqueue(PG *pg) {\n    pg_stat_queue_lock.Lock();\n    if (pg->is_primary() && !pg->stat_queue_item.is_on_list()) {\n      pg->get(\"pg_stat_queue\");\n      pg_stat_queue.push_back(&pg->stat_queue_item);\n    }\n    osd_stat_updated = true;\n    pg_stat_queue_lock.Unlock();\n  }\n  void pg_stat_queue_dequeue(PG *pg) {\n    pg_stat_queue_lock.Lock();\n    if (pg->stat_queue_item.remove_myself())\n      pg->put(\"pg_stat_queue\");\n    pg_stat_queue_lock.Unlock();\n  }\n  void clear_pg_stat_queue() {\n    pg_stat_queue_lock.Lock();\n    while (!pg_stat_queue.empty()) {\n      PG *pg = pg_stat_queue.front();\n      pg_stat_queue.pop_front();\n      pg->put(\"pg_stat_queue\");\n    }\n    pg_stat_queue_lock.Unlock();\n  }\n  void clear_outstanding_pg_stats(){\n    Mutex::Locker l(pg_stat_queue_lock);\n    outstanding_pg_stats.clear();\n  }\n\n  ceph_tid_t get_tid() {\n    return service.get_tid();\n  }\n\n  // -- generic pg peering --\n  PG::RecoveryCtx create_context();\n  void dispatch_context(PG::RecoveryCtx &ctx, PG *pg, OSDMapRef curmap,\n                        ThreadPool::TPHandle *handle = NULL);\n  void dispatch_context_transaction(PG::RecoveryCtx &ctx, PG *pg,\n                                    ThreadPool::TPHandle *handle = NULL);\n  void do_notifies(map<int,\n\t\t       vector<pair<pg_notify_t, PastIntervals> > >&\n\t\t       notify_list,\n\t\t   OSDMapRef map);\n  void do_queries(map<int, map<spg_t,pg_query_t> >& query_map,\n\t\t  OSDMapRef map);\n  void do_infos(map<int,\n\t\t    vector<pair<pg_notify_t, PastIntervals> > >& info_map,\n\t\tOSDMapRef map);\n\n  bool require_mon_peer(const Message *m);\n  bool require_mon_or_mgr_peer(const Message *m);\n  bool require_osd_peer(const Message *m);\n  /***\n   * Verifies that we were alive in the given epoch, and that\n   * still are.\n   */\n  bool require_self_aliveness(const Message *m, epoch_t alive_since);\n  /**\n   * Verifies that the OSD who sent the given op has the same\n   * address as in the given map.\n   * @pre op was sent by an OSD using the cluster messenger\n   */\n  bool require_same_peer_instance(const Message *m, OSDMapRef& map,\n\t\t\t\t  bool is_fast_dispatch);\n\n  bool require_same_or_newer_map(OpRequestRef& op, epoch_t e,\n\t\t\t\t bool is_fast_dispatch);\n\n  void handle_pg_query(OpRequestRef op);\n  void handle_pg_notify(OpRequestRef op);\n  void handle_pg_log(OpRequestRef op);\n  void handle_pg_info(OpRequestRef op);\n  void handle_pg_trim(OpRequestRef op);\n\n  void handle_pg_backfill_reserve(OpRequestRef op);\n  void handle_pg_recovery_reserve(OpRequestRef op);\n\n  void handle_force_recovery(Message *m);\n\n  void handle_pg_remove(OpRequestRef op);\n  void _remove_pg(PG *pg);\n\n  // -- commands --\n  struct Command {\n    vector<string> cmd;\n    ceph_tid_t tid;\n    bufferlist indata;\n    ConnectionRef con;\n\n    Command(vector<string>& c, ceph_tid_t t, bufferlist& bl, Connection *co)\n      : cmd(c), tid(t), indata(bl), con(co) {}\n  };\n  list<Command*> command_queue;\n  struct CommandWQ : public ThreadPool::WorkQueue<Command> {\n    OSD *osd;\n    CommandWQ(OSD *o, time_t ti, time_t si, ThreadPool *tp)\n      : ThreadPool::WorkQueue<Command>(\"OSD::CommandWQ\", ti, si, tp), osd(o) {}\n\n    bool _empty() override {\n      return osd->command_queue.empty();\n    }\n    bool _enqueue(Command *c) override {\n      osd->command_queue.push_back(c);\n      return true;\n    }\n    void _dequeue(Command *pg) override {\n      ceph_abort();\n    }\n    Command *_dequeue() override {\n      if (osd->command_queue.empty())\n\treturn NULL;\n      Command *c = osd->command_queue.front();\n      osd->command_queue.pop_front();\n      return c;\n    }\n    void _process(Command *c, ThreadPool::TPHandle &) override {\n      osd->osd_lock.Lock();\n      if (osd->is_stopping()) {\n\tosd->osd_lock.Unlock();\n\tdelete c;\n\treturn;\n      }\n      osd->do_command(c->con.get(), c->tid, c->cmd, c->indata);\n      osd->osd_lock.Unlock();\n      delete c;\n    }\n    void _clear() override {\n      while (!osd->command_queue.empty()) {\n\tCommand *c = osd->command_queue.front();\n\tosd->command_queue.pop_front();\n\tdelete c;\n      }\n    }\n  } command_wq;\n\n  void handle_command(class MMonCommand *m);\n  void handle_command(class MCommand *m);\n  void do_command(Connection *con, ceph_tid_t tid, vector<string>& cmd, bufferlist& data);\n\n  // -- pg recovery --\n  void do_recovery(PG *pg, epoch_t epoch_queued, uint64_t pushes_reserved,\n\t\t   ThreadPool::TPHandle &handle);\n\n\n  // -- scrubbing --\n  void sched_scrub();\n  bool scrub_random_backoff();\n  bool scrub_load_below_threshold();\n  bool scrub_time_permit(utime_t now);\n\n  // -- removing --\n  struct RemoveWQ :\n    public ThreadPool::WorkQueueVal<pair<PGRef, DeletingStateRef> > {\n    CephContext* cct;\n    ObjectStore *&store;\n    list<pair<PGRef, DeletingStateRef> > remove_queue;\n    RemoveWQ(CephContext* cct, ObjectStore *&o, time_t ti, time_t si,\n\t     ThreadPool *tp)\n      : ThreadPool::WorkQueueVal<pair<PGRef, DeletingStateRef> >(\n\t\"OSD::RemoveWQ\", ti, si, tp), cct(cct), store(o) {}\n\n    bool _empty() override {\n      return remove_queue.empty();\n    }\n    void _enqueue(pair<PGRef, DeletingStateRef> item) override {\n      remove_queue.push_back(item);\n    }\n    void _enqueue_front(pair<PGRef, DeletingStateRef> item) override {\n      remove_queue.push_front(item);\n    }\n    bool _dequeue(pair<PGRef, DeletingStateRef> item) {\n      ceph_abort();\n    }\n    pair<PGRef, DeletingStateRef> _dequeue() override {\n      assert(!remove_queue.empty());\n      pair<PGRef, DeletingStateRef> item = remove_queue.front();\n      remove_queue.pop_front();\n      return item;\n    }\n    void _process(pair<PGRef, DeletingStateRef>,\n\t\t  ThreadPool::TPHandle &) override;\n    void _clear() override {\n      remove_queue.clear();\n    }\n    int get_remove_queue_len() {\n      lock();\n      int r = remove_queue.size();\n      unlock();\n      return r;\n    }\n  } remove_wq;\n\n  // -- status reporting --\n  MPGStats *collect_pg_stats();\n  std::vector<OSDHealthMetric> get_health_metrics();\n\nprivate:\n  bool ms_can_fast_dispatch_any() const override { return true; }\n  bool ms_can_fast_dispatch(const Message *m) const override {\n    switch (m->get_type()) {\n    case CEPH_MSG_OSD_OP:\n    case CEPH_MSG_OSD_BACKOFF:\n    case MSG_OSD_SUBOP:\n    case MSG_OSD_REPOP:\n    case MSG_OSD_SUBOPREPLY:\n    case MSG_OSD_REPOPREPLY:\n    case MSG_OSD_PG_PUSH:\n    case MSG_OSD_PG_PULL:\n    case MSG_OSD_PG_PUSH_REPLY:\n    case MSG_OSD_PG_SCAN:\n    case MSG_OSD_PG_BACKFILL:\n    case MSG_OSD_PG_BACKFILL_REMOVE:\n    case MSG_OSD_EC_WRITE:\n    case MSG_OSD_EC_WRITE_REPLY:\n    case MSG_OSD_EC_READ:\n    case MSG_OSD_EC_READ_REPLY:\n    case MSG_OSD_SCRUB_RESERVE:\n    case MSG_OSD_REP_SCRUB:\n    case MSG_OSD_REP_SCRUBMAP:\n    case MSG_OSD_PG_UPDATE_LOG_MISSING:\n    case MSG_OSD_PG_UPDATE_LOG_MISSING_REPLY:\n    case MSG_OSD_PG_RECOVERY_DELETE:\n    case MSG_OSD_PG_RECOVERY_DELETE_REPLY:\n      return true;\n    default:\n      return false;\n    }\n  }\n  void ms_fast_dispatch(Message *m) override;\n  void ms_fast_preprocess(Message *m) override;\n  bool ms_dispatch(Message *m) override;\n  bool ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new) override;\n  bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t    int protocol, bufferlist& authorizer, bufferlist& authorizer_reply,\n\t\t\t    bool& isvalid, CryptoKey& session_key,\n\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) override;\n  void ms_handle_connect(Connection *con) override;\n  void ms_handle_fast_connect(Connection *con) override;\n  void ms_handle_fast_accept(Connection *con) override;\n  bool ms_handle_reset(Connection *con) override;\n  void ms_handle_remote_reset(Connection *con) override {}\n  bool ms_handle_refused(Connection *con) override;\n\n  io_queue get_io_queue() const {\n    if (cct->_conf->osd_op_queue == \"debug_random\") {\n      static io_queue index_lookup[] = { io_queue::prioritized,\n\t\t\t\t\t io_queue::weightedpriority,\n\t\t\t\t\t io_queue::mclock_opclass,\n\t\t\t\t\t io_queue::mclock_client };\n      srand(time(NULL));\n      unsigned which = rand() % (sizeof(index_lookup) / sizeof(index_lookup[0]));\n      return index_lookup[which];\n    } else if (cct->_conf->osd_op_queue == \"prioritized\") {\n      return io_queue::prioritized;\n    } else if (cct->_conf->osd_op_queue == \"mclock_opclass\") {\n      return io_queue::mclock_opclass;\n    } else if (cct->_conf->osd_op_queue == \"mclock_client\") {\n      return io_queue::mclock_client;\n    } else {\n      // default / catch-all is 'wpq'\n      return io_queue::weightedpriority;\n    }\n  }\n\n  unsigned int get_io_prio_cut() const {\n    if (cct->_conf->osd_op_queue_cut_off == \"debug_random\") {\n      srand(time(NULL));\n      return (rand() % 2 < 1) ? CEPH_MSG_PRIO_HIGH : CEPH_MSG_PRIO_LOW;\n    } else if (cct->_conf->osd_op_queue_cut_off == \"high\") {\n      return CEPH_MSG_PRIO_HIGH;\n    } else {\n      // default / catch-all is 'low'\n      return CEPH_MSG_PRIO_LOW;\n    }\n  }\n\n public:\n  /* internal and external can point to the same messenger, they will still\n   * be cleaned up properly*/\n  OSD(CephContext *cct_,\n      ObjectStore *store_,\n      int id,\n      Messenger *internal,\n      Messenger *external,\n      Messenger *hb_front_client,\n      Messenger *hb_back_client,\n      Messenger *hb_front_server,\n      Messenger *hb_back_server,\n      Messenger *osdc_messenger,\n      MonClient *mc, const std::string &dev, const std::string &jdev);\n  ~OSD() override;\n\n  // static bits\n  static int mkfs(CephContext *cct, ObjectStore *store,\n\t\t  const string& dev,\n\t\t  uuid_d fsid, int whoami);\n  /* remove any non-user xattrs from a map of them */\n  void filter_xattrs(map<string, bufferptr>& attrs) {\n    for (map<string, bufferptr>::iterator iter = attrs.begin();\n\t iter != attrs.end();\n\t ) {\n      if (('_' != iter->first.at(0)) || (iter->first.size() == 1))\n\tattrs.erase(iter++);\n      else ++iter;\n    }\n  }\n\nprivate:\n  int mon_cmd_maybe_osd_create(string &cmd);\n  int update_crush_device_class();\n  int update_crush_location();\n\n  static int write_meta(CephContext *cct,\n\t\t\tObjectStore *store,\n\t\t\tuuid_d& cluster_fsid, uuid_d& osd_fsid, int whoami);\n\n  void handle_pg_scrub(struct MOSDScrub *m, PG* pg);\n  void handle_scrub(struct MOSDScrub *m);\n  void handle_osd_ping(class MOSDPing *m);\n\n  int init_op_flags(OpRequestRef& op);\n\n  int get_num_op_shards();\n  int get_num_op_threads();\n\n  float get_osd_recovery_sleep();\n\npublic:\n  static int peek_meta(ObjectStore *store, string& magic,\n\t\t       uuid_d& cluster_fsid, uuid_d& osd_fsid, int& whoami);\n  \n\n  // startup/shutdown\n  int pre_init();\n  int init();\n  void final_init();\n\n  int enable_disable_fuse(bool stop);\n\n  void suicide(int exitcode);\n  int shutdown();\n\n  void handle_signal(int signum);\n\n  /// check if we can throw out op from a disconnected client\n  static bool op_is_discardable(const MOSDOp *m);\n\npublic:\n  OSDService service;\n  friend class OSDService;\n};\n\n\nstd::ostream& operator<<(std::ostream& out, const OSD::io_queue& q);\n\n\n//compatibility of the executable\nextern const CompatSet::Feature ceph_osd_feature_compat[];\nextern const CompatSet::Feature ceph_osd_feature_ro_compat[];\nextern const CompatSet::Feature ceph_osd_feature_incompat[];\n\n#endif // CEPH_OSD_H\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2013 CohortFS, LLC\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#ifndef SIMPLEDISPATCHER_H_\n#define SIMPLEDISPATCHER_H_\n\n#include \"msg/Dispatcher.h\"\n#include \"msg/Messenger.h\"\n\nclass SimpleDispatcher: public Dispatcher {\nprivate:\n  bool active;\n  Messenger *messenger;\n  uint64_t dcount;\npublic:\n  explicit SimpleDispatcher(Messenger *msgr);\n  ~SimpleDispatcher() override;\n\n  uint64_t get_dcount() { return dcount; }\n\n  void set_active() {\n    active = true;\n  };\n\n  // how i receive messages\n  bool ms_dispatch(Message *m) override;\n\n  /**\n   * This function will be called whenever a new Connection is made to the\n   * Messenger.\n   *\n   * @param con The new Connection which has been established. You are not\n   * granted a reference to it -- take one if you need one!\n   */\n  void ms_handle_connect(Connection *con) override { };\n\n  /**\n   * Callback indicating we have accepted an incoming connection.\n   *\n   * @param con The (new or existing) Connection associated with the session\n   */\n  void ms_handle_accept(Connection *con) override { };\n\n  /*\n   * this indicates that the ordered+reliable delivery semantics have\n   * been violated.  Messages may have been lost due to a fault\n   * in the network connection.\n   * Only called on lossy Connections or those you've\n   * designated mark_down_on_empty().\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  bool ms_handle_reset(Connection *con) override;\n\n  /**\n   * This indicates that the ordered+reliable delivery semantics\n   * have been violated because the remote somehow reset.\n   * It implies that incoming messages were dropped, and\n   * probably some of our previous outgoing messages were too.\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  void ms_handle_remote_reset(Connection *con) override;\n  \n  bool ms_handle_refused(Connection *con) override { return false; }\n\n  /**\n   * @defgroup Authentication\n   * @{\n   */\n  /**\n   * Retrieve the AuthAuthorizer for the given peer type. It might not\n   * provide one if it knows there is no AuthAuthorizer for that type.\n   *\n   * @param dest_type The peer type we want the authorizer for.\n   * @param a Double pointer to an AuthAuthorizer. The Dispatcher will fill\n   * in *a with the correct AuthAuthorizer, if it can. Make sure that you have\n   * set *a to NULL before calling in.\n   * @param force_new Force the Dispatcher to wait for a new set of keys before\n   * returning the authorizer.\n   *\n   * @return True if this function call properly filled in *a, false otherwise.\n   */\n  bool ms_get_authorizer(int dest_type, AuthAuthorizer **a,\n\t\t\t\t bool force_new) override { return false; };\n\n  /**\n   * Verify the authorizer for a new incoming Connection.\n   *\n   * @param con The new incoming Connection\n   * @param peer_type The type of the endpoint which initiated this Connection\n   * @param protocol The ID of the protocol in use (at time of writing, cephx\n   *  or none)\n   * @param authorizer The authorization string supplied by the remote\n   * @param authorizer_reply Output param: The string we should send back to\n   * the remote to authorize ourselves. Only filled in if isvalid\n   * @param isvalid Output param: True if authorizer is valid, false otherwise\n   *\n   * @return True if we were able to prove or disprove correctness of\n   * authorizer, false otherwise.\n   */\n  bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t    int protocol, bufferlist& authorizer,\n\t\t\t    bufferlist& authorizer_reply,\n\t\t\t    bool& isvalid, CryptoKey& session_key,\n\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) override {\n    /* always succeed */\n    isvalid = true;\n    return true;\n  };\n\n};\n\n#endif /* SIMPLEDISPATCHER_H_ */\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*-\n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2013 CohortFS, LLC\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#ifndef XIODISPATCHER_H_\n#define XIODISPATCHER_H_\n\n#include \"msg/Dispatcher.h\"\n#include \"msg/Messenger.h\"\n\nclass XioDispatcher: public Dispatcher {\nprivate:\n  bool active;\n  Messenger *messenger;\n  uint64_t dcount;\npublic:\n  explicit XioDispatcher(Messenger *msgr);\n  virtual ~XioDispatcher();\n\n  uint64_t get_dcount() { return dcount; }\n\n  void set_active() {\n    active = true;\n  };\n\n  // how i receive messages\n  virtual bool ms_dispatch(Message *m);\n\n  /**\n   * This function will be called whenever a new Connection is made to the\n   * Messenger.\n   *\n   * @param con The new Connection which has been established. You are not\n   * granted a reference to it -- take one if you need one!\n   */\n  virtual void ms_handle_connect(Connection *con) { };\n\n  /**\n   * Callback indicating we have accepted an incoming connection.\n   *\n   * @param con The (new or existing) Connection associated with the session\n   */\n  virtual void ms_handle_accept(Connection *con) { };\n\n  /*\n   * this indicates that the ordered+reliable delivery semantics have\n   * been violated.  Messages may have been lost due to a fault\n   * in the network connection.\n   * Only called on lossy Connections or those you've\n   * designated mark_down_on_empty().\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  virtual bool ms_handle_reset(Connection *con);\n\n  /**\n   * This indicates that the ordered+reliable delivery semantics\n   * have been violated because the remote somehow reset.\n   * It implies that incoming messages were dropped, and\n   * probably some of our previous outgoing messages were too.\n   *\n   * @param con The Connection which broke. You are not granted\n   * a reference to it.\n   */\n  virtual void ms_handle_remote_reset(Connection *con);\n  \n  virtual bool ms_handle_refused(Connection *con) { return false; }\n\n  /**\n   * @defgroup test_xio_dispatcher_h_auth Authentication\n   * @{\n   */\n  /**\n   * Retrieve the AuthAuthorizer for the given peer type. It might not\n   * provide one if it knows there is no AuthAuthorizer for that type.\n   *\n   * @param dest_type The peer type we want the authorizer for.\n   * @param a Double pointer to an AuthAuthorizer. The Dispatcher will fill\n   * in *a with the correct AuthAuthorizer, if it can. Make sure that you have\n   * set *a to NULL before calling in.\n   * @param force_new Force the Dispatcher to wait for a new set of keys before\n   * returning the authorizer.\n   *\n   * @return True if this function call properly filled in *a, false otherwise.\n   */\n  virtual bool ms_get_authorizer(int dest_type, AuthAuthorizer **a,\n\t\t\t\t bool force_new) { return false; };\n\n  /**\n   * Verify the authorizer for a new incoming Connection.\n   *\n   * @param con The new incoming Connection\n   * @param peer_type The type of the endpoint which initiated this Connection\n   * @param protocol The ID of the protocol in use (at time of writing, cephx\n   *  or none)\n   * @param authorizer The authorization string supplied by the remote\n   * @param authorizer_reply Output param: The string we should send back to\n   * the remote to authorize ourselves. Only filled in if isvalid\n   * @param isvalid Output param: True if authorizer is valid, false otherwise\n   *\n   * @return True if we were able to prove or disprove correctness of\n   * authorizer, false otherwise.\n   */\n  virtual bool ms_verify_authorizer(Connection *con, int peer_type,\n\t\t\t\t    int protocol, bufferlist& authorizer,\n\t\t\t\t    bufferlist& authorizer_reply,\n\t\t\t\t    bool& isvalid, CryptoKey& session_key,\n\t\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) {\n    /* always succeed */\n    isvalid = true;\n    return true;\n  };\n\n};\n\n#endif /* XIODISPATCHER_H_ */\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2015 Haomai Wang\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include <stdlib.h>\n#include <stdint.h>\n#include <string>\n#include <unistd.h>\n#include <iostream>\n\nusing namespace std;\n\n#include \"common/ceph_argparse.h\"\n#include \"common/debug.h\"\n#include \"common/Cycles.h\"\n#include \"global/global_init.h\"\n#include \"msg/Messenger.h\"\n#include \"messages/MOSDOp.h\"\n\n#include <atomic>\n\nclass MessengerClient {\n  class ClientThread;\n  class ClientDispatcher : public Dispatcher {\n    uint64_t think_time;\n    ClientThread *thread;\n\n   public:\n    ClientDispatcher(uint64_t delay, ClientThread *t): Dispatcher(g_ceph_context), think_time(delay), thread(t) {}\n    bool ms_can_fast_dispatch_any() const override { return true; }\n    bool ms_can_fast_dispatch(const Message *m) const override {\n      switch (m->get_type()) {\n      case CEPH_MSG_OSD_OPREPLY:\n        return true;\n      default:\n        return false;\n      }\n    }\n\n    void ms_handle_fast_connect(Connection *con) override {}\n    void ms_handle_fast_accept(Connection *con) override {}\n    bool ms_dispatch(Message *m) override { return true; }\n    void ms_fast_dispatch(Message *m) override;\n    bool ms_handle_reset(Connection *con) override { return true; }\n    void ms_handle_remote_reset(Connection *con) override {}\n    bool ms_handle_refused(Connection *con) override { return false; }\n    bool ms_verify_authorizer(Connection *con, int peer_type, int protocol,\n                              bufferlist& authorizer, bufferlist& authorizer_reply,\n                              bool& isvalid, CryptoKey& session_key,\n\t\t\t      std::unique_ptr<AuthAuthorizerChallenge> *challenge) override {\n      isvalid = true;\n      return true;\n    }\n  };\n\n  class ClientThread : public Thread {\n    Messenger *msgr;\n    int concurrent;\n    ConnectionRef conn;\n    std::atomic<unsigned> client_inc = { 0 };\n    object_t oid;\n    object_locator_t oloc;\n    pg_t pgid;\n    int msg_len;\n    bufferlist data;\n    int ops;\n    ClientDispatcher dispatcher;\n\n   public:\n    Mutex lock;\n    Cond cond;\n    uint64_t inflight;\n\n    ClientThread(Messenger *m, int c, ConnectionRef con, int len, int ops, int think_time_us):\n        msgr(m), concurrent(c), conn(con), oid(\"object-name\"), oloc(1, 1), msg_len(len), ops(ops),\n        dispatcher(think_time_us, this), lock(\"MessengerBenchmark::ClientThread::lock\"), inflight(0) {\n      m->add_dispatcher_head(&dispatcher);\n      bufferptr ptr(msg_len);\n      memset(ptr.c_str(), 0, msg_len);\n      data.append(ptr);\n    }\n    void *entry() override {\n      lock.Lock();\n      for (int i = 0; i < ops; ++i) {\n        if (inflight > uint64_t(concurrent)) {\n          cond.Wait(lock);\n        }\n\thobject_t hobj(oid, oloc.key, CEPH_NOSNAP, pgid.ps(), pgid.pool(),\n\t\t       oloc.nspace);\n\tspg_t spgid(pgid);\n        MOSDOp *m = new MOSDOp(client_inc, 0, hobj, spgid, 0, 0, 0);\n        m->write(0, msg_len, data);\n        inflight++;\n        conn->send_message(m);\n        //cerr << __func__ << \" send m=\" << m << std::endl;\n      }\n      lock.Unlock();\n      msgr->shutdown();\n      return 0;\n    }\n  };\n\n  string type;\n  string serveraddr;\n  int think_time_us;\n  vector<Messenger*> msgrs;\n  vector<ClientThread*> clients;\n\n public:\n  MessengerClient(string t, string addr, int delay):\n      type(t), serveraddr(addr), think_time_us(delay) {\n  }\n  ~MessengerClient() {\n    for (uint64_t i = 0; i < clients.size(); ++i)\n      delete clients[i];\n    for (uint64_t i = 0; i < msgrs.size(); ++i) {\n      msgrs[i]->shutdown();\n      msgrs[i]->wait();\n    }\n  }\n  void ready(int c, int jobs, int ops, int msg_len) {\n    entity_addr_t addr;\n    addr.parse(serveraddr.c_str());\n    addr.set_nonce(0);\n    for (int i = 0; i < jobs; ++i) {\n      Messenger *msgr = Messenger::create(g_ceph_context, type, entity_name_t::CLIENT(0), \"client\", getpid()+i, 0);\n      msgr->set_default_policy(Messenger::Policy::lossless_client(0));\n      entity_inst_t inst(entity_name_t::OSD(0), addr);\n      ConnectionRef conn = msgr->get_connection(inst);\n      ClientThread *t = new ClientThread(msgr, c, conn, msg_len, ops, think_time_us);\n      msgrs.push_back(msgr);\n      clients.push_back(t);\n      msgr->start();\n    }\n    usleep(1000*1000);\n  }\n  void start() {\n    for (uint64_t i = 0; i < clients.size(); ++i)\n      clients[i]->create(\"client\");\n    for (uint64_t i = 0; i < msgrs.size(); ++i)\n      msgrs[i]->wait();\n  }\n};\n\nvoid MessengerClient::ClientDispatcher::ms_fast_dispatch(Message *m) {\n  usleep(think_time);\n  m->put();\n  Mutex::Locker l(thread->lock);\n  thread->inflight--;\n  thread->cond.Signal();\n}\n\n\nvoid usage(const string &name) {\n  cerr << \"Usage: \" << name << \" [server ip:port] [numjobs] [concurrency] [ios] [thinktime us] [msg length]\" << std::endl;\n  cerr << \"       [server ip:port]: connect to the ip:port pair\" << std::endl;\n  cerr << \"       [numjobs]: how much client threads spawned and do benchmark\" << std::endl;\n  cerr << \"       [concurrency]: the max inflight messages(like iodepth in fio)\" << std::endl;\n  cerr << \"       [ios]: how much messages sent for each client\" << std::endl;\n  cerr << \"       [thinktime]: sleep time when do fast dispatching(match client logic)\" << std::endl;\n  cerr << \"       [msg length]: message data bytes\" << std::endl;\n}\n\nint main(int argc, char **argv)\n{\n  vector<const char*> args;\n  argv_to_vec(argc, (const char **)argv, args);\n\n  auto cct = global_init(NULL, args, CEPH_ENTITY_TYPE_CLIENT,\n\t\t\t CODE_ENVIRONMENT_UTILITY, 0);\n  common_init_finish(g_ceph_context);\n  g_ceph_context->_conf->apply_changes(NULL);\n\n  if (args.size() < 6) {\n    usage(argv[0]);\n    return 1;\n  }\n\n  int numjobs = atoi(args[1]);\n  int concurrent = atoi(args[2]);\n  int ios = atoi(args[3]);\n  int think_time = atoi(args[4]);\n  int len = atoi(args[5]);\n\n  std::string public_msgr_type = g_ceph_context->_conf->ms_public_type.empty() ? g_ceph_context->_conf->get_val<std::string>(\"ms_type\") : g_ceph_context->_conf->ms_public_type;\n\n  cerr << \" using ms-public-type \" << public_msgr_type << std::endl;\n  cerr << \"       server ip:port \" << args[0] << std::endl;\n  cerr << \"       numjobs \" << numjobs << std::endl;\n  cerr << \"       concurrency \" << concurrent << std::endl;\n  cerr << \"       ios \" << ios << std::endl;\n  cerr << \"       thinktime(us) \" << think_time << std::endl;\n  cerr << \"       message data bytes \" << len << std::endl;\n\n  MessengerClient client(public_msgr_type, args[0], think_time);\n\n  client.ready(concurrent, numjobs, ios, len);\n  Cycles::init();\n  uint64_t start = Cycles::rdtsc();\n  client.start();\n  uint64_t stop = Cycles::rdtsc();\n  cerr << \" Total op \" << ios << \" run time \" << Cycles::to_microseconds(stop - start) << \"us.\" << std::endl;\n\n  return 0;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2015 Haomai Wang\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include <stdlib.h>\n#include <stdint.h>\n#include <string>\n#include <unistd.h>\n#include <iostream>\n\nusing namespace std;\n\n#include \"common/ceph_argparse.h\"\n#include \"common/debug.h\"\n#include \"global/global_init.h\"\n#include \"msg/Messenger.h\"\n#include \"messages/MOSDOp.h\"\n#include \"messages/MOSDOpReply.h\"\n\nclass ServerDispatcher : public Dispatcher {\n  uint64_t think_time;\n  ThreadPool op_tp;\n  class OpWQ : public ThreadPool::WorkQueue<Message> {\n    list<Message*> messages;\n\n   public:\n    OpWQ(time_t timeout, time_t suicide_timeout, ThreadPool *tp)\n      : ThreadPool::WorkQueue<Message>(\"ServerDispatcher::OpWQ\", timeout, suicide_timeout, tp) {}\n\n    bool _enqueue(Message *m) override {\n      messages.push_back(m);\n      return true;\n    }\n    void _dequeue(Message *m) override {\n      ceph_abort();\n    }\n    bool _empty() override {\n      return messages.empty();\n    }\n    Message *_dequeue() override {\n      if (messages.empty())\n\treturn NULL;\n      Message *m = messages.front();\n      messages.pop_front();\n      return m;\n    }\n    void _process(Message *m, ThreadPool::TPHandle &handle) override {\n      MOSDOp *osd_op = static_cast<MOSDOp*>(m);\n      MOSDOpReply *reply = new MOSDOpReply(osd_op, 0, 0, 0, false);\n      m->get_connection()->send_message(reply);\n      m->put();\n    }\n    void _process_finish(Message *m) override { }\n    void _clear() override {\n      assert(messages.empty());\n    }\n  } op_wq;\n\n public:\n  ServerDispatcher(int threads, uint64_t delay): Dispatcher(g_ceph_context), think_time(delay),\n    op_tp(g_ceph_context, \"ServerDispatcher::op_tp\", \"tp_serv_disp\", threads, \"serverdispatcher_op_threads\"),\n    op_wq(30, 30, &op_tp) {\n    op_tp.start();\n  }\n  ~ServerDispatcher() override {\n    op_tp.stop();\n  }\n  bool ms_can_fast_dispatch_any() const override { return true; }\n  bool ms_can_fast_dispatch(const Message *m) const override {\n    switch (m->get_type()) {\n    case CEPH_MSG_OSD_OP:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  void ms_handle_fast_connect(Connection *con) override {}\n  void ms_handle_fast_accept(Connection *con) override {}\n  bool ms_dispatch(Message *m) override { return true; }\n  bool ms_handle_reset(Connection *con) override { return true; }\n  void ms_handle_remote_reset(Connection *con) override {}\n  bool ms_handle_refused(Connection *con) override { return false; }\n  void ms_fast_dispatch(Message *m) override {\n    usleep(think_time);\n    //cerr << __func__ << \" reply message=\" << m << std::endl;\n    op_wq.queue(m);\n  }\n  bool ms_verify_authorizer(Connection *con, int peer_type, int protocol,\n                            bufferlist& authorizer, bufferlist& authorizer_reply,\n                            bool& isvalid, CryptoKey& session_key,\n\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) override {\n    isvalid = true;\n    return true;\n  }\n};\n\nclass MessengerServer {\n  Messenger *msgr;\n  string type;\n  string bindaddr;\n  ServerDispatcher dispatcher;\n\n public:\n  MessengerServer(string t, string addr, int threads, int delay):\n      msgr(NULL), type(t), bindaddr(addr), dispatcher(threads, delay) {\n    msgr = Messenger::create(g_ceph_context, type, entity_name_t::OSD(0), \"server\", 0, 0);\n    msgr->set_default_policy(Messenger::Policy::stateless_server(0));\n  }\n  ~MessengerServer() {\n    msgr->shutdown();\n    msgr->wait();\n  }\n  void start() {\n    entity_addr_t addr;\n    addr.parse(bindaddr.c_str());\n    msgr->bind(addr);\n    msgr->add_dispatcher_head(&dispatcher);\n    msgr->start();\n    msgr->wait();\n  }\n};\n\nvoid usage(const string &name) {\n  cerr << \"Usage: \" << name << \" [bind ip:port] [server worker threads] [thinktime us]\" << std::endl;\n  cerr << \"       [bind ip:port]: The ip:port pair to bind, client need to specify this pair to connect\" << std::endl;\n  cerr << \"       [server worker threads]: threads will process incoming messages and reply(matching pg threads)\" << std::endl;\n  cerr << \"       [thinktime]: sleep time when do dispatching(match fast dispatch logic in OSD.cc)\" << std::endl;\n}\n\nint main(int argc, char **argv)\n{\n  vector<const char*> args;\n  argv_to_vec(argc, (const char **)argv, args);\n\n  auto cct = global_init(NULL, args, CEPH_ENTITY_TYPE_CLIENT,\n\t\t\t CODE_ENVIRONMENT_UTILITY, 0);\n  common_init_finish(g_ceph_context);\n  g_ceph_context->_conf->apply_changes(NULL);\n\n  if (args.size() < 3) {\n    usage(argv[0]);\n    return 1;\n  }\n\n  int worker_threads = atoi(args[1]);\n  int think_time = atoi(args[2]);\n  std::string public_msgr_type = g_ceph_context->_conf->ms_public_type.empty() ? g_ceph_context->_conf->get_val<std::string>(\"ms_type\") : g_ceph_context->_conf->ms_public_type;\n\n  cerr << \" This tool won't handle connection error alike things, \" << std::endl;\n  cerr << \"please ensure the proper network environment to test.\" << std::endl;\n  cerr << \" Or ctrl+c when meeting error and restart tests\" << std::endl;\n  cerr << \" using ms-public-type \" << public_msgr_type << std::endl;\n  cerr << \"       bind ip:port \" << args[0] << std::endl;\n  cerr << \"       worker threads \" << worker_threads << std::endl;\n  cerr << \"       thinktime(us) \" << think_time << std::endl;\n\n  MessengerServer server(public_msgr_type, args[0], worker_threads, think_time);\n  server.start();\n\n  return 0;\n}\n", "// -*- mode:C++; tab-width:8; c-basic-offset:2; indent-tabs-mode:t -*- \n// vim: ts=8 sw=2 smarttab\n/*\n * Ceph - scalable distributed file system\n *\n * Copyright (C) 2014 UnitedStack <haomai@unitedstack.com>\n *\n * Author: Haomai Wang <haomaiwang@gmail.com>\n *\n * This is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License version 2.1, as published by the Free Software\n * Foundation.  See file COPYING.\n *\n */\n\n#include <atomic>\n#include <iostream>\n#include <unistd.h>\n#include <stdlib.h>\n#include <time.h>\n#include \"common/Mutex.h\"\n#include \"common/Cond.h\"\n#include \"common/ceph_argparse.h\"\n#include \"global/global_init.h\"\n#include \"msg/Dispatcher.h\"\n#include \"msg/msg_types.h\"\n#include \"msg/Message.h\"\n#include \"msg/Messenger.h\"\n#include \"msg/Connection.h\"\n#include \"messages/MPing.h\"\n#include \"messages/MCommand.h\"\n\n#include <boost/random/mersenne_twister.hpp>\n#include <boost/random/uniform_int.hpp>\n#include <boost/random/binomial_distribution.hpp>\n#include <gtest/gtest.h>\n\ntypedef boost::mt11213b gen_type;\n\n#include \"common/dout.h\"\n#include \"include/assert.h\"\n\n#define dout_subsys ceph_subsys_ms\n#undef dout_prefix\n#define dout_prefix *_dout << \" ceph_test_msgr \"\n\n\n#if GTEST_HAS_PARAM_TEST\n\n#define CHECK_AND_WAIT_TRUE(expr) do {  \\\n  int n = 1000;                         \\\n  while (--n) {                         \\\n    if (expr)                           \\\n      break;                            \\\n    usleep(1000);                       \\\n  }                                     \\\n} while(0);\n\nclass MessengerTest : public ::testing::TestWithParam<const char*> {\n public:\n  Messenger *server_msgr;\n  Messenger *client_msgr;\n\n  MessengerTest(): server_msgr(NULL), client_msgr(NULL) {}\n  void SetUp() override {\n    lderr(g_ceph_context) << __func__ << \" start set up \" << GetParam() << dendl;\n    server_msgr = Messenger::create(g_ceph_context, string(GetParam()), entity_name_t::OSD(0), \"server\", getpid(), 0);\n    client_msgr = Messenger::create(g_ceph_context, string(GetParam()), entity_name_t::CLIENT(-1), \"client\", getpid(), 0);\n    server_msgr->set_default_policy(Messenger::Policy::stateless_server(0));\n    client_msgr->set_default_policy(Messenger::Policy::lossy_client(0));\n  }\n  void TearDown() override {\n    ASSERT_EQ(server_msgr->get_dispatch_queue_len(), 0);\n    ASSERT_EQ(client_msgr->get_dispatch_queue_len(), 0);\n    delete server_msgr;\n    delete client_msgr;\n  }\n\n};\n\n\nclass FakeDispatcher : public Dispatcher {\n public:\n  struct Session : public RefCountedObject {\n    atomic<uint64_t> count;\n    ConnectionRef con;\n\n    explicit Session(ConnectionRef c): RefCountedObject(g_ceph_context), count(0), con(c) {\n    }\n    uint64_t get_count() { return count; }\n  };\n\n  Mutex lock;\n  Cond cond;\n  bool is_server;\n  bool got_new;\n  bool got_remote_reset;\n  bool got_connect;\n  bool loopback;\n\n  explicit FakeDispatcher(bool s): Dispatcher(g_ceph_context), lock(\"FakeDispatcher::lock\"),\n                          is_server(s), got_new(false), got_remote_reset(false),\n                          got_connect(false), loopback(false) {}\n  bool ms_can_fast_dispatch_any() const override { return true; }\n  bool ms_can_fast_dispatch(const Message *m) const override {\n    switch (m->get_type()) {\n    case CEPH_MSG_PING:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  void ms_handle_fast_connect(Connection *con) override {\n    lock.Lock();\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (!s) {\n      s = new Session(con);\n      con->set_priv(s->get());\n      lderr(g_ceph_context) << __func__ << \" con: \" << con << \" count: \" << s->count << dendl;\n    }\n    s->put();\n    got_connect = true;\n    cond.Signal();\n    lock.Unlock();\n  }\n  void ms_handle_fast_accept(Connection *con) override {\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (!s) {\n      s = new Session(con);\n      con->set_priv(s->get());\n    }\n    s->put();\n  }\n  bool ms_dispatch(Message *m) override {\n    Session *s = static_cast<Session*>(m->get_connection()->get_priv());\n    if (!s) {\n      s = new Session(m->get_connection());\n      m->get_connection()->set_priv(s->get());\n    }\n    s->put();\n    s->count++;\n    lderr(g_ceph_context) << __func__ << \" conn: \" << m->get_connection() << \" session \" << s << \" count: \" << s->count << dendl;\n    if (is_server) {\n      reply_message(m);\n    }\n    Mutex::Locker l(lock);\n    got_new = true;\n    cond.Signal();\n    m->put();\n    return true;\n  }\n  bool ms_handle_reset(Connection *con) override {\n    Mutex::Locker l(lock);\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (s) {\n      s->con.reset(NULL);  // break con <-> session ref cycle\n      con->set_priv(NULL);   // break ref <-> session cycle, if any\n      s->put();\n    }\n    return true;\n  }\n  void ms_handle_remote_reset(Connection *con) override {\n    Mutex::Locker l(lock);\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n    Session *s = static_cast<Session*>(con->get_priv());\n    if (s) {\n      s->con.reset(NULL);  // break con <-> session ref cycle\n      con->set_priv(NULL);   // break ref <-> session cycle, if any\n      s->put();\n    }\n    got_remote_reset = true;\n    cond.Signal();\n  }\n  bool ms_handle_refused(Connection *con) override {\n    return false;\n  }\n  void ms_fast_dispatch(Message *m) override {\n    Session *s = static_cast<Session*>(m->get_connection()->get_priv());\n    if (!s) {\n      s = new Session(m->get_connection());\n      m->get_connection()->set_priv(s->get());\n    }\n    s->put();\n    s->count++;\n    lderr(g_ceph_context) << __func__ << \" conn: \" << m->get_connection() << \" session \" << s << \" count: \" << s->count << dendl;\n    if (is_server) {\n      if (loopback)\n        assert(m->get_source().is_osd());\n      else\n        reply_message(m);\n    } else if (loopback) {\n      assert(m->get_source().is_client());\n    }\n    m->put();\n    Mutex::Locker l(lock);\n    got_new = true;\n    cond.Signal();\n  }\n\n  bool ms_verify_authorizer(Connection *con, int peer_type, int protocol,\n                            bufferlist& authorizer, bufferlist& authorizer_reply,\n                            bool& isvalid, CryptoKey& session_key,\n\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) override {\n    isvalid = true;\n    return true;\n  }\n\n  void reply_message(Message *m) {\n    MPing *rm = new MPing();\n    m->get_connection()->send_message(rm);\n  }\n};\n\ntypedef FakeDispatcher::Session Session;\n\nTEST_P(MessengerTest, SimpleTest) {\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. simple round trip\n  MPing *m = new MPing();\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(conn->is_connected());\n  ASSERT_TRUE((static_cast<Session*>(conn->get_priv()))->get_count() == 1);\n  ASSERT_TRUE(conn->peer_is_osd());\n\n  // 2. test rebind port\n  set<int> avoid_ports;\n  for (int i = 0; i < 10 ; i++)\n    avoid_ports.insert(server_msgr->get_myaddr().get_port() + i);\n  server_msgr->rebind(avoid_ports);\n  ASSERT_TRUE(avoid_ports.count(server_msgr->get_myaddr().get_port()) == 0);\n\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n\n  // 3. test markdown connection\n  conn->mark_down();\n  ASSERT_FALSE(conn->is_connected());\n\n  // 4. test failed connection\n  server_msgr->shutdown();\n  server_msgr->wait();\n\n  m = new MPing();\n  conn->send_message(m);\n  CHECK_AND_WAIT_TRUE(!conn->is_connected());\n  ASSERT_FALSE(conn->is_connected());\n\n  // 5. loopback connection\n  srv_dispatcher.loopback = true;\n  conn = client_msgr->get_loopback_connection();\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  srv_dispatcher.loopback = false;\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  client_msgr->shutdown();\n  client_msgr->wait();\n  server_msgr->shutdown();\n  server_msgr->wait();\n}\n\nTEST_P(MessengerTest, NameAddrTest) {\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  MPing *m = new MPing();\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  ASSERT_TRUE(conn->get_peer_addr() == server_msgr->get_myaddr());\n  ConnectionRef server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  // Make should server_conn is the one we already accepted from client,\n  // so it means client_msgr has the same addr when server connection has\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, FeatureTest) {\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  uint64_t all_feature_supported, feature_required, feature_supported = 0;\n  for (int i = 0; i < 10; i++)\n    feature_supported |= 1ULL << i;\n  feature_required = feature_supported | 1ULL << 13;\n  all_feature_supported = feature_required | 1ULL << 14;\n\n  Messenger::Policy p = server_msgr->get_policy(entity_name_t::TYPE_CLIENT);\n  p.features_required = feature_required;\n  server_msgr->set_policy(entity_name_t::TYPE_CLIENT, p);\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n\n  // 1. Suppose if only support less than required\n  p = client_msgr->get_policy(entity_name_t::TYPE_OSD);\n  p.features_supported = feature_supported;\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  MPing *m = new MPing();\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  conn->send_message(m);\n  CHECK_AND_WAIT_TRUE(!conn->is_connected());\n  // should failed build a connection\n  ASSERT_FALSE(conn->is_connected());\n\n  client_msgr->shutdown();\n  client_msgr->wait();\n\n  // 2. supported met required\n  p = client_msgr->get_policy(entity_name_t::TYPE_OSD);\n  p.features_supported = all_feature_supported;\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n  client_msgr->start();\n\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, TimeoutTest) {\n  g_ceph_context->_conf->set_val(\"ms_tcp_read_timeout\", \"1\");\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. build the connection\n  MPing *m = new MPing();\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(conn->is_connected());\n  ASSERT_TRUE((static_cast<Session*>(conn->get_priv()))->get_count() == 1);\n  ASSERT_TRUE(conn->peer_is_osd());\n\n  // 2. wait for idle\n  usleep(2500*1000);\n  ASSERT_FALSE(conn->is_connected());\n\n  server_msgr->shutdown();\n  server_msgr->wait();\n\n  client_msgr->shutdown();\n  client_msgr->wait();\n  g_ceph_context->_conf->set_val(\"ms_tcp_read_timeout\", \"900\");\n}\n\nTEST_P(MessengerTest, StatefulTest) {\n  Message *m;\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  Messenger::Policy p = Messenger::Policy::stateful_server(0);\n  server_msgr->set_policy(entity_name_t::TYPE_CLIENT, p);\n  p = Messenger::Policy::lossless_client(0);\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. test for server standby\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  conn->mark_down();\n  ASSERT_FALSE(conn->is_connected());\n  ConnectionRef server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  // don't lose state\n  ASSERT_TRUE(static_cast<Session*>(server_conn->get_priv())->get_count() == 1);\n\n  srv_dispatcher.got_new = false;\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  {\n    Mutex::Locker l(srv_dispatcher.lock);\n    while (!srv_dispatcher.got_remote_reset)\n      srv_dispatcher.cond.Wait(srv_dispatcher.lock);\n  }\n\n  // 2. test for client reconnect\n  ASSERT_FALSE(cli_dispatcher.got_remote_reset);\n  cli_dispatcher.got_connect = false;\n  cli_dispatcher.got_new = false;\n  cli_dispatcher.got_remote_reset = false;\n  server_conn->mark_down();\n  ASSERT_FALSE(server_conn->is_connected());\n  // ensure client detect server socket closed\n  {\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_remote_reset)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_remote_reset = false;\n  }\n  {\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_connect)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_connect = false;\n  }\n  CHECK_AND_WAIT_TRUE(conn->is_connected());\n  ASSERT_TRUE(conn->is_connected());\n\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    ASSERT_TRUE(conn->is_connected());\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  // resetcheck happen\n  ASSERT_EQ(1U, static_cast<Session*>(conn->get_priv())->get_count());\n  server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  ASSERT_EQ(1U, static_cast<Session*>(server_conn->get_priv())->get_count());\n  cli_dispatcher.got_remote_reset = false;\n\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, StatelessTest) {\n  Message *m;\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  Messenger::Policy p = Messenger::Policy::stateless_server(0);\n  server_msgr->set_policy(entity_name_t::TYPE_CLIENT, p);\n  p = Messenger::Policy::lossy_client(0);\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. test for server lose state\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  conn->mark_down();\n  ASSERT_FALSE(conn->is_connected());\n\n  srv_dispatcher.got_new = false;\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  ConnectionRef server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  // server lose state\n  {\n    Mutex::Locker l(srv_dispatcher.lock);\n    while (!srv_dispatcher.got_new)\n      srv_dispatcher.cond.Wait(srv_dispatcher.lock);\n  }\n  ASSERT_EQ(1U, static_cast<Session*>(server_conn->get_priv())->get_count());\n\n  // 2. test for client lossy\n  server_conn->mark_down();\n  ASSERT_FALSE(server_conn->is_connected());\n  conn->send_keepalive();\n  CHECK_AND_WAIT_TRUE(!conn->is_connected());\n  ASSERT_FALSE(conn->is_connected());\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, ClientStandbyTest) {\n  Message *m;\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  Messenger::Policy p = Messenger::Policy::stateful_server(0);\n  server_msgr->set_policy(entity_name_t::TYPE_CLIENT, p);\n  p = Messenger::Policy::lossless_peer(0);\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. test for client standby, resetcheck\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  ConnectionRef server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  ASSERT_FALSE(cli_dispatcher.got_remote_reset);\n  cli_dispatcher.got_connect = false;\n  server_conn->mark_down();\n  ASSERT_FALSE(server_conn->is_connected());\n  // client should be standby\n  usleep(300*1000);\n  // client should be standby, so we use original connection\n  {\n    // Try send message to verify got remote reset callback\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    {\n      Mutex::Locker l(cli_dispatcher.lock);\n      while (!cli_dispatcher.got_remote_reset)\n        cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n      cli_dispatcher.got_remote_reset = false;\n      while (!cli_dispatcher.got_connect)\n        cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n      cli_dispatcher.got_connect = false;\n    }\n    CHECK_AND_WAIT_TRUE(conn->is_connected());\n    ASSERT_TRUE(conn->is_connected());\n    m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(static_cast<Session*>(conn->get_priv())->get_count() == 1);\n  server_conn = server_msgr->get_connection(client_msgr->get_myinst());\n  ASSERT_TRUE(static_cast<Session*>(server_conn->get_priv())->get_count() == 1);\n\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, AuthTest) {\n  g_ceph_context->_conf->set_val(\"auth_cluster_required\", \"cephx\");\n  g_ceph_context->_conf->set_val(\"auth_service_required\", \"cephx\");\n  g_ceph_context->_conf->set_val(\"auth_client_required\", \"cephx\");\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  // 1. simple auth round trip\n  MPing *m = new MPing();\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(conn->is_connected());\n  ASSERT_TRUE((static_cast<Session*>(conn->get_priv()))->get_count() == 1);\n\n  // 2. mix auth\n  g_ceph_context->_conf->set_val(\"auth_cluster_required\", \"none\");\n  g_ceph_context->_conf->set_val(\"auth_service_required\", \"none\");\n  g_ceph_context->_conf->set_val(\"auth_client_required\", \"none\");\n  conn->mark_down();\n  ASSERT_FALSE(conn->is_connected());\n  conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    MPing *m = new MPing();\n    ASSERT_EQ(conn->send_message(m), 0);\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.Wait(cli_dispatcher.lock);\n    cli_dispatcher.got_new = false;\n  }\n  ASSERT_TRUE(conn->is_connected());\n  ASSERT_TRUE((static_cast<Session*>(conn->get_priv()))->get_count() == 1);\n\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\nTEST_P(MessengerTest, MessageTest) {\n  FakeDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1\");\n  Messenger::Policy p = Messenger::Policy::stateful_server(0);\n  server_msgr->set_policy(entity_name_t::TYPE_CLIENT, p);\n  p = Messenger::Policy::lossless_peer(0);\n  client_msgr->set_policy(entity_name_t::TYPE_OSD, p);\n\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n\n  // 1. A very large \"front\"(as well as \"payload\")\n  // Because a external message need to invade Messenger::decode_message,\n  // here we only use existing message class(MCommand)\n  ConnectionRef conn = client_msgr->get_connection(server_msgr->get_myinst());\n  {\n    uuid_d uuid;\n    uuid.generate_random();\n    vector<string> cmds;\n    string s(\"abcdefghijklmnopqrstuvwxyz\");\n    for (int i = 0; i < 1024*30; i++)\n      cmds.push_back(s);\n    MCommand *m = new MCommand(uuid);\n    m->cmd = cmds;\n    conn->send_message(m);\n    utime_t t;\n    t += 1000*1000*500;\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.WaitInterval(cli_dispatcher.lock, t);\n    ASSERT_TRUE(cli_dispatcher.got_new);\n    cli_dispatcher.got_new = false;\n  }\n\n  // 2. A very large \"data\"\n  {\n    bufferlist bl;\n    string s(\"abcdefghijklmnopqrstuvwxyz\");\n    for (int i = 0; i < 1024*30; i++)\n      bl.append(s);\n    MPing *m = new MPing();\n    m->set_data(bl);\n    conn->send_message(m);\n    utime_t t;\n    t += 1000*1000*500;\n    Mutex::Locker l(cli_dispatcher.lock);\n    while (!cli_dispatcher.got_new)\n      cli_dispatcher.cond.WaitInterval(cli_dispatcher.lock, t);\n    ASSERT_TRUE(cli_dispatcher.got_new);\n    cli_dispatcher.got_new = false;\n  }\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n}\n\n\nclass SyntheticWorkload;\n\nstruct Payload {\n  enum Who : uint8_t {\n    PING = 0,\n    PONG = 1,\n  };\n  uint8_t who;\n  uint64_t seq;\n  bufferlist data;\n\n  Payload(Who who, uint64_t seq, const bufferlist& data)\n    : who(who), seq(seq), data(data)\n  {}\n  Payload() = default;\n  DENC(Payload, v, p) {\n    DENC_START(1, 1, p);\n    denc(v.who, p);\n    denc(v.seq, p);\n    denc(v.data, p);\n    DENC_FINISH(p);\n  }\n};\nWRITE_CLASS_DENC(Payload)\n\nostream& operator<<(ostream& out, const Payload &pl)\n{\n  return out << \"reply=\" << pl.who << \" i = \" << pl.seq;\n}\n\nclass SyntheticDispatcher : public Dispatcher {\n public:\n  Mutex lock;\n  Cond cond;\n  bool is_server;\n  bool got_new;\n  bool got_remote_reset;\n  bool got_connect;\n  map<ConnectionRef, list<uint64_t> > conn_sent;\n  map<uint64_t, bufferlist> sent;\n  atomic<uint64_t> index;\n  SyntheticWorkload *workload;\n\n  SyntheticDispatcher(bool s, SyntheticWorkload *wl):\n      Dispatcher(g_ceph_context), lock(\"SyntheticDispatcher::lock\"), is_server(s), got_new(false),\n      got_remote_reset(false), got_connect(false), index(0), workload(wl) {}\n  bool ms_can_fast_dispatch_any() const override { return true; }\n  bool ms_can_fast_dispatch(const Message *m) const override {\n    switch (m->get_type()) {\n    case CEPH_MSG_PING:\n    case MSG_COMMAND:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  void ms_handle_fast_connect(Connection *con) override {\n    Mutex::Locker l(lock);\n    list<uint64_t> c = conn_sent[con];\n    for (list<uint64_t>::iterator it = c.begin();\n         it != c.end(); ++it)\n      sent.erase(*it);\n    conn_sent.erase(con);\n    got_connect = true;\n    cond.Signal();\n  }\n  void ms_handle_fast_accept(Connection *con) override {\n    Mutex::Locker l(lock);\n    list<uint64_t> c = conn_sent[con];\n    for (list<uint64_t>::iterator it = c.begin();\n         it != c.end(); ++it)\n      sent.erase(*it);\n    conn_sent.erase(con);\n    cond.Signal();\n  }\n  bool ms_dispatch(Message *m) override {\n    ceph_abort();\n  }\n  bool ms_handle_reset(Connection *con) override;\n  void ms_handle_remote_reset(Connection *con) override {\n    Mutex::Locker l(lock);\n    list<uint64_t> c = conn_sent[con];\n    for (list<uint64_t>::iterator it = c.begin();\n         it != c.end(); ++it)\n      sent.erase(*it);\n    conn_sent.erase(con);\n    got_remote_reset = true;\n  }\n  bool ms_handle_refused(Connection *con) override {\n    return false;\n  }\n  void ms_fast_dispatch(Message *m) override {\n    // MSG_COMMAND is used to disorganize regular message flow\n    if (m->get_type() == MSG_COMMAND) {\n      m->put();\n      return ;\n    }\n\n    Payload pl;\n    auto p = m->get_data().begin();\n    ::decode(pl, p);\n    if (pl.who == Payload::PING) {\n      lderr(g_ceph_context) << __func__ << \" conn=\" << m->get_connection() << pl << dendl;\n      reply_message(m, pl);\n      m->put();\n      Mutex::Locker l(lock);\n      got_new = true;\n      cond.Signal();\n    } else {\n      Mutex::Locker l(lock);\n      if (sent.count(pl.seq)) {\n\tlderr(g_ceph_context) << __func__ << \" conn=\" << m->get_connection() << pl << dendl;\n\tASSERT_EQ(conn_sent[m->get_connection()].front(), pl.seq);\n\tASSERT_TRUE(pl.data.contents_equal(sent[pl.seq]));\n\tconn_sent[m->get_connection()].pop_front();\n\tsent.erase(pl.seq);\n      }\n      m->put();\n      got_new = true;\n      cond.Signal();\n    }\n  }\n\n  bool ms_verify_authorizer(Connection *con, int peer_type, int protocol,\n                            bufferlist& authorizer, bufferlist& authorizer_reply,\n                            bool& isvalid, CryptoKey& session_key,\n\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) override {\n    isvalid = true;\n    return true;\n  }\n\n  void reply_message(const Message *m, Payload& pl) {\n    pl.who = Payload::PONG;\n    bufferlist bl;\n    ::encode(pl, bl);\n    MPing *rm = new MPing();\n    rm->set_data(bl);\n    m->get_connection()->send_message(rm);\n    lderr(g_ceph_context) << __func__ << \" conn=\" << m->get_connection() << \" reply m=\" << m << \" i=\" << pl.seq << dendl;\n  }\n\n  void send_message_wrap(ConnectionRef con, const bufferlist& data) {\n    Message *m = new MPing();\n    Payload pl{Payload::PING, index++, data};\n    bufferlist bl;\n    ::encode(pl, bl);\n    m->set_data(bl);\n    if (!con->get_messenger()->get_default_policy().lossy) {\n      Mutex::Locker l(lock);\n      sent[pl.seq] = pl.data;\n      conn_sent[con].push_back(pl.seq);\n    }\n    lderr(g_ceph_context) << __func__ << \" conn=\" << con.get() << \" send m=\" << m << \" i=\" << pl.seq << dendl;\n    ASSERT_EQ(0, con->send_message(m));\n  }\n\n  uint64_t get_pending() {\n    Mutex::Locker l(lock);\n    return sent.size();\n  }\n\n  void clear_pending(ConnectionRef con) {\n    Mutex::Locker l(lock);\n\n    for (list<uint64_t>::iterator it = conn_sent[con].begin();\n         it != conn_sent[con].end(); ++it)\n      sent.erase(*it);\n    conn_sent.erase(con);\n  }\n\n  void print() {\n    for (auto && p : conn_sent) {\n      if (!p.second.empty()) {\n        lderr(g_ceph_context) << __func__ << \" \" << p.first << \" wait \" << p.second.size() << dendl;\n      }\n    }\n  }\n};\n\n\nclass SyntheticWorkload {\n  Mutex lock;\n  Cond cond;\n  set<Messenger*> available_servers;\n  set<Messenger*> available_clients;\n  map<ConnectionRef, pair<Messenger*, Messenger*> > available_connections;\n  SyntheticDispatcher dispatcher;\n  gen_type rng;\n  vector<bufferlist> rand_data;\n\n public:\n  static const unsigned max_in_flight = 64;\n  static const unsigned max_connections = 128;\n  static const unsigned max_message_len = 1024 * 1024 * 4;\n\n  SyntheticWorkload(int servers, int clients, string type, int random_num,\n                    Messenger::Policy srv_policy, Messenger::Policy cli_policy):\n      lock(\"SyntheticWorkload::lock\"), dispatcher(false, this), rng(time(NULL)) {\n    Messenger *msgr;\n    int base_port = 16800;\n    entity_addr_t bind_addr;\n    char addr[64];\n    for (int i = 0; i < servers; ++i) {\n      msgr = Messenger::create(g_ceph_context, type, entity_name_t::OSD(0),\n                               \"server\", getpid()+i, 0);\n      snprintf(addr, sizeof(addr), \"127.0.0.1:%d\", base_port+i);\n      bind_addr.parse(addr);\n      msgr->bind(bind_addr);\n      msgr->add_dispatcher_head(&dispatcher);\n\n      assert(msgr);\n      msgr->set_default_policy(srv_policy);\n      available_servers.insert(msgr);\n      msgr->start();\n    }\n\n    for (int i = 0; i < clients; ++i) {\n      msgr = Messenger::create(g_ceph_context, type, entity_name_t::CLIENT(-1),\n                               \"client\", getpid()+i+servers, 0);\n      if (cli_policy.standby) {\n        snprintf(addr, sizeof(addr), \"127.0.0.1:%d\", base_port+i+servers);\n        bind_addr.parse(addr);\n        msgr->bind(bind_addr);\n      }\n      msgr->add_dispatcher_head(&dispatcher);\n\n      assert(msgr);\n      msgr->set_default_policy(cli_policy);\n      available_clients.insert(msgr);\n      msgr->start();\n    }\n\n    for (int i = 0; i < random_num; i++) {\n      bufferlist bl;\n      boost::uniform_int<> u(32, max_message_len);\n      uint64_t value_len = u(rng);\n      bufferptr bp(value_len);\n      bp.zero();\n      for (uint64_t j = 0; j < value_len-sizeof(i); ) {\n        memcpy(bp.c_str()+j, &i, sizeof(i));\n        j += 4096;\n      }\n\n      bl.append(bp);\n      rand_data.push_back(bl);\n    }\n  }\n\n  ConnectionRef _get_random_connection() {\n    while (dispatcher.get_pending() > max_in_flight) {\n      lock.Unlock();\n      usleep(500);\n      lock.Lock();\n    }\n    assert(lock.is_locked());\n    boost::uniform_int<> choose(0, available_connections.size() - 1);\n    int index = choose(rng);\n    map<ConnectionRef, pair<Messenger*, Messenger*> >::iterator i = available_connections.begin();\n    for (; index > 0; --index, ++i) ;\n    return i->first;\n  }\n\n  bool can_create_connection() {\n    return available_connections.size() < max_connections;\n  }\n\n  void generate_connection() {\n    Mutex::Locker l(lock);\n    if (!can_create_connection())\n      return ;\n\n    Messenger *server, *client;\n    {\n      boost::uniform_int<> choose(0, available_servers.size() - 1);\n      int index = choose(rng);\n      set<Messenger*>::iterator i = available_servers.begin();\n      for (; index > 0; --index, ++i) ;\n      server = *i;\n    }\n    {\n      boost::uniform_int<> choose(0, available_clients.size() - 1);\n      int index = choose(rng);\n      set<Messenger*>::iterator i = available_clients.begin();\n      for (; index > 0; --index, ++i) ;\n      client = *i;\n    }\n\n    pair<Messenger*, Messenger*> p;\n    {\n      boost::uniform_int<> choose(0, available_servers.size() - 1);\n      if (server->get_default_policy().server) {\n        p = make_pair(client, server);\n      } else {\n        ConnectionRef conn = client->get_connection(server->get_myinst());\n        if (available_connections.count(conn) || choose(rng) % 2)\n          p = make_pair(client, server);\n        else\n          p = make_pair(server, client);\n      }\n    }\n    ConnectionRef conn = p.first->get_connection(p.second->get_myinst());\n    available_connections[conn] = p;\n  }\n\n  void send_message() {\n    Mutex::Locker l(lock);\n    ConnectionRef conn = _get_random_connection();\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val >= 95) {\n      uuid_d uuid;\n      uuid.generate_random();\n      MCommand *m = new MCommand(uuid);\n      vector<string> cmds;\n      cmds.push_back(\"command\");\n      m->cmd = cmds;\n      m->set_priority(200);\n      conn->send_message(m);\n    } else {\n      boost::uniform_int<> u(0, rand_data.size()-1);\n      dispatcher.send_message_wrap(conn, rand_data[u(rng)]);\n    }\n  }\n\n  void drop_connection() {\n    Mutex::Locker l(lock);\n    if (available_connections.size() < 10)\n      return;\n    ConnectionRef conn = _get_random_connection();\n    dispatcher.clear_pending(conn);\n    conn->mark_down();\n    pair<Messenger*, Messenger*> &p = available_connections[conn];\n    // it's a lossless policy, so we need to mark down each side\n    if (!p.first->get_default_policy().server && !p.second->get_default_policy().server) {\n      ASSERT_EQ(conn->get_messenger(), p.first);\n      ConnectionRef peer = p.second->get_connection(p.first->get_myinst());\n      peer->mark_down();\n      dispatcher.clear_pending(peer);\n      available_connections.erase(peer);\n    }\n    ASSERT_EQ(available_connections.erase(conn), 1U);\n  }\n\n  void print_internal_state(bool detail=false) {\n    Mutex::Locker l(lock);\n    lderr(g_ceph_context) << \"available_connections: \" << available_connections.size()\n         << \" inflight messages: \" << dispatcher.get_pending() << dendl;\n    if (detail && !available_connections.empty()) {\n      dispatcher.print();\n    }\n  }\n\n  void wait_for_done() {\n    int64_t tick_us = 1000 * 100; // 100ms\n    int64_t timeout_us = 5 * 60 * 1000 * 1000; // 5 mins\n    int i = 0;\n    while (dispatcher.get_pending()) {\n      usleep(tick_us);\n      timeout_us -= tick_us;\n      if (i++ % 50 == 0)\n        print_internal_state(true);\n      if (timeout_us < 0)\n        assert(0 == \" loop time exceed 5 mins, it looks we stuck into some problems!\");\n    }\n    for (set<Messenger*>::iterator it = available_servers.begin();\n         it != available_servers.end(); ++it) {\n      (*it)->shutdown();\n      (*it)->wait();\n      ASSERT_EQ((*it)->get_dispatch_queue_len(), 0);\n      delete (*it);\n    }\n    available_servers.clear();\n\n    for (set<Messenger*>::iterator it = available_clients.begin();\n         it != available_clients.end(); ++it) {\n      (*it)->shutdown();\n      (*it)->wait();\n      ASSERT_EQ((*it)->get_dispatch_queue_len(), 0);\n      delete (*it);\n    }\n    available_clients.clear();\n  }\n\n  void handle_reset(Connection *con) {\n    Mutex::Locker l(lock);\n    available_connections.erase(con);\n    dispatcher.clear_pending(con);\n  }\n};\n\nbool SyntheticDispatcher::ms_handle_reset(Connection *con) {\n  workload->handle_reset(con);\n  return true;\n}\n\nTEST_P(MessengerTest, SyntheticStressTest) {\n  SyntheticWorkload test_msg(8, 32, GetParam(), 100,\n                             Messenger::Policy::stateful_server(0),\n                             Messenger::Policy::lossless_client(0));\n  for (int i = 0; i < 100; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 5000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 90) {\n      test_msg.generate_connection();\n    } else if (val > 80) {\n      test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 1000 + 500);\n    }\n  }\n  test_msg.wait_for_done();\n}\n\nTEST_P(MessengerTest, SyntheticStressTest1) {\n  SyntheticWorkload test_msg(16, 32, GetParam(), 100,\n                             Messenger::Policy::lossless_peer_reuse(0),\n                             Messenger::Policy::lossless_peer_reuse(0));\n  for (int i = 0; i < 10; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 10000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 80) {\n      test_msg.generate_connection();\n    } else if (val > 60) {\n      test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 1000 + 500);\n    }\n  }\n  test_msg.wait_for_done();\n}\n\n\nTEST_P(MessengerTest, SyntheticInjectTest) {\n  uint64_t dispatch_throttle_bytes = g_ceph_context->_conf->ms_dispatch_throttle_bytes;\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"30\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0.1\");\n  g_ceph_context->_conf->set_val(\"ms_dispatch_throttle_bytes\", \"16777216\");\n  SyntheticWorkload test_msg(8, 32, GetParam(), 100,\n                             Messenger::Policy::stateful_server(0),\n                             Messenger::Policy::lossless_client(0));\n  for (int i = 0; i < 100; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 1000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 90) {\n      test_msg.generate_connection();\n    } else if (val > 80) {\n      test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 500 + 100);\n    }\n  }\n  test_msg.wait_for_done();\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0\");\n  g_ceph_context->_conf->set_val(\n      \"ms_dispatch_throttle_bytes\", std::to_string(dispatch_throttle_bytes));\n}\n\nTEST_P(MessengerTest, SyntheticInjectTest2) {\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"30\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0.1\");\n  SyntheticWorkload test_msg(8, 16, GetParam(), 100,\n                             Messenger::Policy::lossless_peer_reuse(0),\n                             Messenger::Policy::lossless_peer_reuse(0));\n  for (int i = 0; i < 100; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 1000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 90) {\n      test_msg.generate_connection();\n    } else if (val > 80) {\n      test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 500 + 100);\n    }\n  }\n  test_msg.wait_for_done();\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0\");\n}\n\nTEST_P(MessengerTest, SyntheticInjectTest3) {\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"600\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0.1\");\n  SyntheticWorkload test_msg(8, 16, GetParam(), 100,\n                             Messenger::Policy::stateless_server(0),\n                             Messenger::Policy::lossy_client(0));\n  for (int i = 0; i < 100; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 1000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 90) {\n      test_msg.generate_connection();\n    } else if (val > 80) {\n      test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 500 + 100);\n    }\n  }\n  test_msg.wait_for_done();\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0\");\n}\n\n\nTEST_P(MessengerTest, SyntheticInjectTest4) {\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"30\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0.1\");\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_probability\", \"1\");\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_type\", \"client osd\", false);\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_max\", \"5\");\n  SyntheticWorkload test_msg(16, 32, GetParam(), 100,\n                             Messenger::Policy::lossless_peer(0),\n                             Messenger::Policy::lossless_peer(0));\n  for (int i = 0; i < 100; ++i) {\n    if (!(i % 10)) lderr(g_ceph_context) << \"seeding connection \" << i << dendl;\n    test_msg.generate_connection();\n  }\n  gen_type rng(time(NULL));\n  for (int i = 0; i < 1000; ++i) {\n    if (!(i % 10)) {\n      lderr(g_ceph_context) << \"Op \" << i << \": \" << dendl;\n      test_msg.print_internal_state();\n    }\n    boost::uniform_int<> true_false(0, 99);\n    int val = true_false(rng);\n    if (val > 95) {\n      test_msg.generate_connection();\n    } else if (val > 80) {\n      // test_msg.drop_connection();\n    } else if (val > 10) {\n      test_msg.send_message();\n    } else {\n      usleep(rand() % 500 + 100);\n    }\n  }\n  test_msg.wait_for_done();\n  g_ceph_context->_conf->set_val(\"ms_inject_socket_failures\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_internal_delays\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_probability\", \"0\");\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_type\", \"\", false);\n  g_ceph_context->_conf->set_val(\"ms_inject_delay_max\", \"0\");\n}\n\n\nclass MarkdownDispatcher : public Dispatcher {\n  Mutex lock;\n  set<ConnectionRef> conns;\n  bool last_mark;\n public:\n  std::atomic<uint64_t> count = { 0 };\n  explicit MarkdownDispatcher(bool s): Dispatcher(g_ceph_context), lock(\"MarkdownDispatcher::lock\"),\n                              last_mark(false) {}\n  bool ms_can_fast_dispatch_any() const override { return false; }\n  bool ms_can_fast_dispatch(const Message *m) const override {\n    switch (m->get_type()) {\n    case CEPH_MSG_PING:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  void ms_handle_fast_connect(Connection *con) override {\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n    Mutex::Locker l(lock);\n    conns.insert(con);\n  }\n  void ms_handle_fast_accept(Connection *con) override {\n    Mutex::Locker l(lock);\n    conns.insert(con);\n  }\n  bool ms_dispatch(Message *m) override {\n    lderr(g_ceph_context) << __func__ << \" conn: \" << m->get_connection() << dendl;\n    Mutex::Locker l(lock);\n    count++;\n    conns.insert(m->get_connection());\n    if (conns.size() < 2 && !last_mark) {\n      m->put();\n      return true;\n    }\n\n    last_mark = true;\n    usleep(rand() % 500);\n    for (set<ConnectionRef>::iterator it = conns.begin(); it != conns.end(); ++it) {\n      if ((*it) != m->get_connection().get()) {\n        (*it)->mark_down();\n        conns.erase(it);\n        break;\n      }\n    }\n    if (conns.empty())\n      last_mark = false;\n    m->put();\n    return true;\n  }\n  bool ms_handle_reset(Connection *con) override {\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n    Mutex::Locker l(lock);\n    conns.erase(con);\n    usleep(rand() % 500);\n    return true;\n  }\n  void ms_handle_remote_reset(Connection *con) override {\n    Mutex::Locker l(lock);\n    conns.erase(con);\n    lderr(g_ceph_context) << __func__ << \" \" << con << dendl;\n  }\n  bool ms_handle_refused(Connection *con) override {\n    return false;\n  }\n  void ms_fast_dispatch(Message *m) override {\n    ceph_abort();\n  }\n  bool ms_verify_authorizer(Connection *con, int peer_type, int protocol,\n                            bufferlist& authorizer, bufferlist& authorizer_reply,\n                            bool& isvalid, CryptoKey& session_key,\n\t\t\t    std::unique_ptr<AuthAuthorizerChallenge> *challenge) override {\n    isvalid = true;\n    return true;\n  }\n};\n\n\n// Markdown with external lock\nTEST_P(MessengerTest, MarkdownTest) {\n  Messenger *server_msgr2 = Messenger::create(g_ceph_context, string(GetParam()), entity_name_t::OSD(0), \"server\", getpid(), 0);\n  MarkdownDispatcher cli_dispatcher(false), srv_dispatcher(true);\n  entity_addr_t bind_addr;\n  bind_addr.parse(\"127.0.0.1:16800\");\n  server_msgr->bind(bind_addr);\n  server_msgr->add_dispatcher_head(&srv_dispatcher);\n  server_msgr->start();\n  bind_addr.parse(\"127.0.0.1:16801\");\n  server_msgr2->bind(bind_addr);\n  server_msgr2->add_dispatcher_head(&srv_dispatcher);\n  server_msgr2->start();\n\n  client_msgr->add_dispatcher_head(&cli_dispatcher);\n  client_msgr->start();\n\n  int i = 1000;\n  uint64_t last = 0;\n  bool equal = false;\n  uint64_t equal_count = 0;\n  while (i--) {\n    ConnectionRef conn1 = client_msgr->get_connection(server_msgr->get_myinst());\n    ConnectionRef conn2 = client_msgr->get_connection(server_msgr2->get_myinst());\n    MPing *m = new MPing();\n    ASSERT_EQ(conn1->send_message(m), 0);\n    m = new MPing();\n    ASSERT_EQ(conn2->send_message(m), 0);\n    CHECK_AND_WAIT_TRUE(srv_dispatcher.count > last + 1);\n    if (srv_dispatcher.count == last) {\n      lderr(g_ceph_context) << __func__ << \" last is \" << last << dendl;\n      equal = true;\n      equal_count++;\n    } else {\n      equal = false;\n      equal_count = 0;\n    }\n    last = srv_dispatcher.count;\n    if (equal_count)\n      usleep(1000*500);\n    ASSERT_FALSE(equal && equal_count > 3);\n  }\n  server_msgr->shutdown();\n  client_msgr->shutdown();\n  server_msgr2->shutdown();\n  server_msgr->wait();\n  client_msgr->wait();\n  server_msgr2->wait();\n  delete server_msgr2;\n}\n\nINSTANTIATE_TEST_CASE_P(\n  Messenger,\n  MessengerTest,\n  ::testing::Values(\n    \"async+posix\",\n    \"simple\"\n  )\n);\n\n#else\n\n// Google Test may not support value-parameterized tests with some\n// compilers. If we use conditional compilation to compile out all\n// code referring to the gtest_main library, MSVC linker will not link\n// that library at all and consequently complain about missing entry\n// point defined in that library (fatal error LNK1561: entry point\n// must be defined). This dummy test keeps gtest_main linked in.\nTEST(DummyTest, ValueParameterizedTestsAreNotSupportedOnThisPlatform) {}\n\n#endif\n\n\nint main(int argc, char **argv) {\n  vector<const char*> args;\n  argv_to_vec(argc, (const char **)argv, args);\n  env_to_vec(args);\n\n  auto cct = global_init(NULL, args, CEPH_ENTITY_TYPE_CLIENT, CODE_ENVIRONMENT_UTILITY, 0);\n  g_ceph_context->_conf->set_val(\"auth_cluster_required\", \"none\");\n  g_ceph_context->_conf->set_val(\"auth_service_required\", \"none\");\n  g_ceph_context->_conf->set_val(\"auth_client_required\", \"none\");\n  g_ceph_context->_conf->set_val(\"enable_experimental_unrecoverable_data_corrupting_features\", \"ms-type-async\");\n  g_ceph_context->_conf->set_val(\"ms_die_on_bad_msg\", \"true\");\n  g_ceph_context->_conf->set_val(\"ms_die_on_old_message\", \"true\");\n  g_ceph_context->_conf->set_val(\"ms_max_backoff\", \"1\");\n  common_init_finish(g_ceph_context);\n\n  ::testing::InitGoogleTest(&argc, argv);\n  return RUN_ALL_TESTS();\n}\n\n/*\n * Local Variables:\n * compile-command: \"cd ../.. ; make -j4 ceph_test_msgr && valgrind --tool=memcheck ./ceph_test_msgr\"\n * End:\n */\n"], "filenames": ["src/auth/Auth.h", "src/auth/AuthAuthorizeHandler.h", "src/auth/cephx/CephxAuthorizeHandler.cc", "src/auth/cephx/CephxAuthorizeHandler.h", "src/auth/cephx/CephxProtocol.cc", "src/auth/cephx/CephxProtocol.h", "src/auth/cephx/CephxServiceHandler.cc", "src/auth/none/AuthNoneAuthorizeHandler.cc", "src/auth/none/AuthNoneAuthorizeHandler.h", "src/auth/none/AuthNoneProtocol.h", "src/auth/unknown/AuthUnknownAuthorizeHandler.cc", "src/auth/unknown/AuthUnknownAuthorizeHandler.h", "src/include/msgr.h", "src/mds/MDSDaemon.cc", "src/mds/MDSDaemon.h", "src/mgr/DaemonServer.cc", "src/mgr/DaemonServer.h", "src/mon/Monitor.cc", "src/mon/Monitor.h", "src/msg/Dispatcher.h", "src/msg/Messenger.h", "src/msg/async/AsyncConnection.cc", "src/msg/async/AsyncConnection.h", "src/msg/async/AsyncMessenger.h", "src/msg/simple/Pipe.cc", "src/msg/simple/SimpleMessenger.cc", "src/msg/simple/SimpleMessenger.h", "src/osd/OSD.cc", "src/osd/OSD.h", "src/test/messenger/simple_dispatcher.h", "src/test/messenger/xio_dispatcher.h", "src/test/msgr/perf_msgr_client.cc", "src/test/msgr/perf_msgr_server.cc", "src/test/msgr/test_msgr.cc"], "buggy_code_start_loc": [138, 37, 9, 26, 306, 275, 155, 20, 26, 19, 17, 26, 96, 1265, 111, 144, 126, 5901, 909, 19, 809, 1029, 373, 387, 356, 418, 349, 7239, 1585, 116, 118, 61, 103, 206], "buggy_code_end_loc": [138, 38, 23, 27, 495, 415, 156, 24, 27, 29, 21, 27, 97, 1298, 112, 179, 133, 5921, 910, 208, 814, 1721, 373, 390, 1197, 421, 351, 7274, 2363, 119, 119, 62, 104, 1440], "fixing_code_start_loc": [139, 37, 9, 26, 307, 276, 155, 20, 26, 20, 17, 26, 96, 1265, 111, 144, 126, 5901, 909, 20, 809, 1029, 374, 387, 357, 418, 349, 7239, 1585, 116, 118, 61, 103, 206], "fixing_code_end_loc": [144, 40, 27, 28, 551, 444, 158, 27, 28, 33, 24, 28, 97, 1299, 113, 183, 135, 5922, 911, 213, 816, 1745, 375, 391, 1223, 424, 353, 7276, 2365, 120, 120, 63, 105, 1443], "type": "CWE-287", "message": "It was found that cephx authentication protocol did not verify ceph clients correctly and was vulnerable to replay attack. Any attacker having access to ceph cluster network who is able to sniff packets on network can use this vulnerability to authenticate with ceph service and perform actions allowed by ceph service. Ceph branches master, mimic, luminous and jewel are believed to be vulnerable.", "other": {"cve": {"id": "CVE-2018-1128", "sourceIdentifier": "secalert@redhat.com", "published": "2018-07-10T14:29:00.370", "lastModified": "2020-11-17T19:15:10.920", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "It was found that cephx authentication protocol did not verify ceph clients correctly and was vulnerable to replay attack. Any attacker having access to ceph cluster network who is able to sniff packets on network can use this vulnerability to authenticate with ceph service and perform actions allowed by ceph service. Ceph branches master, mimic, luminous and jewel are believed to be vulnerable."}, {"lang": "es", "value": "Se ha descubierto que el protocolo de autenticaci\u00f3n cephx no verificaba correctamente los clientes ceph y era vulnerable a ataques de reproducci\u00f3n. Cualquier atacante que tenga acceso a la red de cl\u00fasters de ceph y que pueda rastrear paquetes en la red puede emplear esta vulnerabilidad para autenticarse con el servicio ceph y realizar acciones permitidas por el servicio ceph. Se cree que las ramas de ceph master, mimic, luminous y jewel son vulnerables."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:A/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "ADJACENT_NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.6, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:A/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "ADJACENT_NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 5.4}, "baseSeverity": "MEDIUM", "exploitabilityScore": 5.5, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-287"}]}, {"source": "secalert@redhat.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-294"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:redhat:ceph_storage:3:*:*:*:*:*:*:*", "matchCriteriaId": "E9184616-421F-4EA9-AC1A-A4C95BBAAC99"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redhat:ceph_storage_mon:2:*:*:*:*:*:*:*", "matchCriteriaId": "8C2EBAD9-F0D5-4176-9C4D-001B230E699E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redhat:ceph_storage_mon:3:*:*:*:*:*:*:*", "matchCriteriaId": "CD2F9BA8-FE0A-43DE-A756-C35A24C3D96E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redhat:ceph_storage_osd:2:*:*:*:*:*:*:*", "matchCriteriaId": "AA5F5227-DBDA-4C01-BF7C-4D53F455404F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redhat:ceph_storage_osd:3:*:*:*:*:*:*:*", "matchCriteriaId": "A80BACB5-7A56-4BC6-9261-58A3860F4E8C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "142AD0DD-4CF3-4D74-9442-459CE3347E3A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_desktop:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "33C068A4-3780-4EAB-A937-6082DF847564"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_server:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "51EF4996-72F4-4FA4-814F-F5991E7A8318"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_workstation:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "825ECE2D-E232-46E0-A047-074B34DB1E97"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:redhat:ceph:*:*:*:*:*:*:*:*", "versionStartIncluding": "10.2.0", "versionEndIncluding": "13.2.1", "matchCriteriaId": "1E50612E-0E8A-4CCE-91DB-502079B9540C"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:15.0:*:*:*:*:*:*:*", "matchCriteriaId": "F1E78106-58E6-4D59-990F-75DA575BFAD9"}]}]}], "references": [{"url": "http://lists.opensuse.org/opensuse-security-announce/2019-04/msg00100.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://tracker.ceph.com/issues/24836", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Vendor Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2020/11/17/3", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2020/11/17/4", "source": "secalert@redhat.com"}, {"url": "https://access.redhat.com/errata/RHSA-2018:2177", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2179", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2261", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2274", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1575866", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/ceph/ceph/commit/5ead97120e07054d80623dada90a5cc764c28468", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2019/03/msg00017.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://www.debian.org/security/2018/dsa-4339", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/ceph/ceph/commit/5ead97120e07054d80623dada90a5cc764c28468"}}
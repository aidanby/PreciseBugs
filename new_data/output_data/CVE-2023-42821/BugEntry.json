{"buggy_code": ["package parser\n\nimport (\n\t\"bytes\"\n\t\"html\"\n\t\"regexp\"\n\t\"strconv\"\n\t\"unicode\"\n\n\t\"github.com/gomarkdown/markdown/ast\"\n)\n\n// Parsing block-level elements.\n\nconst (\n\tcharEntity = \"&(?:#x[a-f0-9]{1,8}|#[0-9]{1,8}|[a-z][a-z0-9]{1,31});\"\n\tescapable  = \"[!\\\"#$%&'()*+,./:;<=>?@[\\\\\\\\\\\\]^_`{|}~-]\"\n)\n\nconst (\n\tcaptionTable  = \"Table: \"\n\tcaptionFigure = \"Figure: \"\n\tcaptionQuote  = \"Quote: \"\n)\n\nvar (\n\treBackslashOrAmp      = regexp.MustCompile(`[\\&]`)\n\treEntityOrEscapedChar = regexp.MustCompile(`(?i)\\\\` + escapable + \"|\" + charEntity)\n\n\t// blockTags is a set of tags that are recognized as HTML block tags.\n\t// Any of these can be included in markdown text without special escaping.\n\tblockTags = map[string]struct{}{\n\t\t\"blockquote\": {},\n\t\t\"del\":        {},\n\t\t\"dd\":         {},\n\t\t\"div\":        {},\n\t\t\"dl\":         {},\n\t\t\"dt\":         {},\n\t\t\"fieldset\":   {},\n\t\t\"form\":       {},\n\t\t\"h1\":         {},\n\t\t\"h2\":         {},\n\t\t\"h3\":         {},\n\t\t\"h4\":         {},\n\t\t\"h5\":         {},\n\t\t\"h6\":         {},\n\t\t// TODO: technically block but breaks Inline HTML (Simple).text\n\t\t//\"hr\":         {},\n\t\t\"iframe\":   {},\n\t\t\"ins\":      {},\n\t\t\"li\":       {},\n\t\t\"math\":     {},\n\t\t\"noscript\": {},\n\t\t\"ol\":       {},\n\t\t\"pre\":      {},\n\t\t\"p\":        {},\n\t\t\"script\":   {},\n\t\t\"style\":    {},\n\t\t\"table\":    {},\n\t\t\"ul\":       {},\n\n\t\t// HTML5\n\t\t\"address\":    {},\n\t\t\"article\":    {},\n\t\t\"aside\":      {},\n\t\t\"canvas\":     {},\n\t\t\"details\":    {},\n\t\t\"dialog\":     {},\n\t\t\"figcaption\": {},\n\t\t\"figure\":     {},\n\t\t\"footer\":     {},\n\t\t\"header\":     {},\n\t\t\"hgroup\":     {},\n\t\t\"main\":       {},\n\t\t\"nav\":        {},\n\t\t\"output\":     {},\n\t\t\"progress\":   {},\n\t\t\"section\":    {},\n\t\t\"video\":      {},\n\t}\n)\n\n// sanitizeHeadingID returns a sanitized anchor name for the given text.\n// Taken from https://github.com/shurcooL/sanitized_anchor_name/blob/master/main.go#L14:1\nfunc sanitizeHeadingID(text string) string {\n\tvar anchorName []rune\n\tvar futureDash = false\n\tfor _, r := range text {\n\t\tswitch {\n\t\tcase unicode.IsLetter(r) || unicode.IsNumber(r):\n\t\t\tif futureDash && len(anchorName) > 0 {\n\t\t\t\tanchorName = append(anchorName, '-')\n\t\t\t}\n\t\t\tfutureDash = false\n\t\t\tanchorName = append(anchorName, unicode.ToLower(r))\n\t\tdefault:\n\t\t\tfutureDash = true\n\t\t}\n\t}\n\tif len(anchorName) == 0 {\n\t\treturn \"empty\"\n\t}\n\treturn string(anchorName)\n}\n\n// Parse Block-level data.\n// Note: this function and many that it calls assume that\n// the input buffer ends with a newline.\nfunc (p *Parser) Block(data []byte) {\n\t// this is called recursively: enforce a maximum depth\n\tif p.nesting >= p.maxNesting {\n\t\treturn\n\t}\n\tp.nesting++\n\n\t// parse out one block-level construct at a time\n\tfor len(data) > 0 {\n\t\t// attributes that can be specific before a block element:\n\t\t//\n\t\t// {#id .class1 .class2 key=\"value\"}\n\t\tif p.extensions&Attributes != 0 {\n\t\t\tdata = p.attribute(data)\n\t\t}\n\n\t\tif p.extensions&Includes != 0 {\n\t\t\tf := p.readInclude\n\t\t\tpath, address, consumed := p.isInclude(data)\n\t\t\tif consumed == 0 {\n\t\t\t\tpath, address, consumed = p.isCodeInclude(data)\n\t\t\t\tf = p.readCodeInclude\n\t\t\t}\n\t\t\tif consumed > 0 {\n\t\t\t\tincluded := f(p.includeStack.Last(), path, address)\n\n\t\t\t\t// if we find a caption below this, we need to include it in 'included', so\n\t\t\t\t// that the caption will be part of the include text. (+1 to skip newline)\n\t\t\t\tfor _, caption := range []string{captionFigure, captionTable, captionQuote} {\n\t\t\t\t\tif _, _, capcon := p.caption(data[consumed+1:], []byte(caption)); capcon > 0 {\n\t\t\t\t\t\tincluded = append(included, data[consumed+1:consumed+1+capcon]...)\n\t\t\t\t\t\tconsumed += 1 + capcon\n\t\t\t\t\t\tbreak // there can only be 1 caption.\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tp.includeStack.Push(path)\n\t\t\t\tp.Block(included)\n\t\t\t\tp.includeStack.Pop()\n\t\t\t\tdata = data[consumed:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// user supplied parser function\n\t\tif p.Opts.ParserHook != nil {\n\t\t\tnode, blockdata, consumed := p.Opts.ParserHook(data)\n\t\t\tif consumed > 0 {\n\t\t\t\tdata = data[consumed:]\n\n\t\t\t\tif node != nil {\n\t\t\t\t\tp.AddBlock(node)\n\t\t\t\t\tif blockdata != nil {\n\t\t\t\t\t\tp.Block(blockdata)\n\t\t\t\t\t\tp.Finalize(node)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// prefixed heading:\n\t\t//\n\t\t// # Heading 1\n\t\t// ## Heading 2\n\t\t// ...\n\t\t// ###### Heading 6\n\t\tif p.isPrefixHeading(data) {\n\t\t\tdata = data[p.prefixHeading(data):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// prefixed special heading:\n\t\t// (there are no levels.)\n\t\t//\n\t\t// .# Abstract\n\t\tif p.isPrefixSpecialHeading(data) {\n\t\t\tdata = data[p.prefixSpecialHeading(data):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// block of preformatted HTML:\n\t\t//\n\t\t// <div>\n\t\t//     ...\n\t\t// </div>\n\t\tif data[0] == '<' {\n\t\t\tif i := p.html(data, true); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// title block\n\t\t//\n\t\t// % stuff\n\t\t// % more stuff\n\t\t// % even more stuff\n\t\tif p.extensions&Titleblock != 0 {\n\t\t\tif data[0] == '%' {\n\t\t\t\tif i := p.titleBlock(data, true); i > 0 {\n\t\t\t\t\tdata = data[i:]\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// blank lines.  note: returns the # of bytes to skip\n\t\tif i := IsEmpty(data); i > 0 {\n\t\t\tdata = data[i:]\n\t\t\tcontinue\n\t\t}\n\n\t\t// indented code block:\n\t\t//\n\t\t//     func max(a, b int) int {\n\t\t//         if a > b {\n\t\t//             return a\n\t\t//         }\n\t\t//         return b\n\t\t//      }\n\t\tif p.codePrefix(data) > 0 {\n\t\t\tdata = data[p.code(data):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// fenced code block:\n\t\t//\n\t\t// ``` go\n\t\t// func fact(n int) int {\n\t\t//     if n <= 1 {\n\t\t//         return n\n\t\t//     }\n\t\t//     return n * fact(n-1)\n\t\t// }\n\t\t// ```\n\t\tif p.extensions&FencedCode != 0 {\n\t\t\tif i := p.fencedCodeBlock(data, true); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// horizontal rule:\n\t\t//\n\t\t// ------\n\t\t// or\n\t\t// ******\n\t\t// or\n\t\t// ______\n\t\tif isHRule(data) {\n\t\t\ti := skipUntilChar(data, 0, '\\n')\n\t\t\thr := ast.HorizontalRule{}\n\t\t\thr.Literal = bytes.Trim(data[:i], \" \\n\")\n\t\t\tp.AddBlock(&hr)\n\t\t\tdata = data[i:]\n\t\t\tcontinue\n\t\t}\n\n\t\t// block quote:\n\t\t//\n\t\t// > A big quote I found somewhere\n\t\t// > on the web\n\t\tif p.quotePrefix(data) > 0 {\n\t\t\tdata = data[p.quote(data):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// aside:\n\t\t//\n\t\t// A> The proof is too large to fit\n\t\t// A> in the margin.\n\t\tif p.extensions&Mmark != 0 {\n\t\t\tif p.asidePrefix(data) > 0 {\n\t\t\t\tdata = data[p.aside(data):]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// figure block:\n\t\t//\n\t\t// !---\n\t\t// ![Alt Text](img.jpg \"This is an image\")\n\t\t// ![Alt Text](img2.jpg \"This is a second image\")\n\t\t// !---\n\t\tif p.extensions&Mmark != 0 {\n\t\t\tif i := p.figureBlock(data, true); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif p.extensions&Tables != 0 {\n\t\t\tif i := p.table(data); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// an itemized/unordered list:\n\t\t//\n\t\t// * Item 1\n\t\t// * Item 2\n\t\t//\n\t\t// also works with + or -\n\t\tif p.uliPrefix(data) > 0 {\n\t\t\tdata = data[p.list(data, 0, 0, '.'):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// a numbered/ordered list:\n\t\t//\n\t\t// 1. Item 1\n\t\t// 2. Item 2\n\t\tif i := p.oliPrefix(data); i > 0 {\n\t\t\tstart := 0\n\t\t\tdelim := byte('.')\n\t\t\tif i > 2 {\n\t\t\t\tif p.extensions&OrderedListStart != 0 {\n\t\t\t\t\ts := string(data[:i-2])\n\t\t\t\t\tstart, _ = strconv.Atoi(s)\n\t\t\t\t\tif start == 1 {\n\t\t\t\t\t\tstart = 0\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tdelim = data[i-2]\n\t\t\t}\n\t\t\tdata = data[p.list(data, ast.ListTypeOrdered, start, delim):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// definition lists:\n\t\t//\n\t\t// Term 1\n\t\t// :   Definition a\n\t\t// :   Definition b\n\t\t//\n\t\t// Term 2\n\t\t// :   Definition c\n\t\tif p.extensions&DefinitionLists != 0 {\n\t\t\tif p.dliPrefix(data) > 0 {\n\t\t\t\tdata = data[p.list(data, ast.ListTypeDefinition, 0, '.'):]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif p.extensions&MathJax != 0 {\n\t\t\tif i := p.blockMath(data); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// document matters:\n\t\t//\n\t\t// {frontmatter}/{mainmatter}/{backmatter}\n\t\tif p.extensions&Mmark != 0 {\n\t\t\tif i := p.documentMatter(data); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// anything else must look like a normal paragraph\n\t\t// note: this finds underlined headings, too\n\t\tidx := p.paragraph(data)\n\t\tdata = data[idx:]\n\t}\n\n\tp.nesting--\n}\n\nfunc (p *Parser) AddBlock(n ast.Node) ast.Node {\n\tp.closeUnmatchedBlocks()\n\n\tif p.attr != nil {\n\t\tif c := n.AsContainer(); c != nil {\n\t\t\tc.Attribute = p.attr\n\t\t}\n\t\tif l := n.AsLeaf(); l != nil {\n\t\t\tl.Attribute = p.attr\n\t\t}\n\t\tp.attr = nil\n\t}\n\treturn p.addChild(n)\n}\n\nfunc (p *Parser) isPrefixHeading(data []byte) bool {\n\tif data[0] != '#' {\n\t\treturn false\n\t}\n\n\tif p.extensions&SpaceHeadings != 0 {\n\t\tlevel := skipCharN(data, 0, '#', 6)\n\t\tif level == len(data) || data[level] != ' ' {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc (p *Parser) prefixHeading(data []byte) int {\n\tlevel := skipCharN(data, 0, '#', 6)\n\ti := skipChar(data, level, ' ')\n\tend := skipUntilChar(data, i, '\\n')\n\tskip := end\n\tid := \"\"\n\tif p.extensions&HeadingIDs != 0 {\n\t\tj, k := 0, 0\n\t\t// find start/end of heading id\n\t\tfor j = i; j < end-1 && (data[j] != '{' || data[j+1] != '#'); j++ {\n\t\t}\n\t\tfor k = j + 1; k < end && data[k] != '}'; k++ {\n\t\t}\n\t\t// extract heading id iff found\n\t\tif j < end && k < end {\n\t\t\tid = string(data[j+2 : k])\n\t\t\tend = j\n\t\t\tskip = k + 1\n\t\t\tfor end > 0 && data[end-1] == ' ' {\n\t\t\t\tend--\n\t\t\t}\n\t\t}\n\t}\n\tfor end > 0 && data[end-1] == '#' {\n\t\tif isBackslashEscaped(data, end-1) {\n\t\t\tbreak\n\t\t}\n\t\tend--\n\t}\n\tfor end > 0 && data[end-1] == ' ' {\n\t\tend--\n\t}\n\tif end > i {\n\t\tblock := &ast.Heading{\n\t\t\tHeadingID: id,\n\t\t\tLevel:     level,\n\t\t}\n\t\tif id == \"\" && p.extensions&AutoHeadingIDs != 0 {\n\t\t\tblock.HeadingID = sanitizeHeadingID(string(data[i:end]))\n\t\t\tp.allHeadingsWithAutoID = append(p.allHeadingsWithAutoID, block)\n\t\t}\n\t\tblock.Content = data[i:end]\n\t\tp.AddBlock(block)\n\t}\n\treturn skip\n}\n\nfunc (p *Parser) isPrefixSpecialHeading(data []byte) bool {\n\tif p.extensions|Mmark == 0 {\n\t\treturn false\n\t}\n\tif len(data) < 4 {\n\t\treturn false\n\t}\n\tif data[0] != '.' {\n\t\treturn false\n\t}\n\tif data[1] != '#' {\n\t\treturn false\n\t}\n\tif data[2] == '#' { // we don't support level, so nack this.\n\t\treturn false\n\t}\n\n\tif p.extensions&SpaceHeadings != 0 {\n\t\tif data[2] != ' ' {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc (p *Parser) prefixSpecialHeading(data []byte) int {\n\ti := skipChar(data, 2, ' ') // \".#\" skipped\n\tend := skipUntilChar(data, i, '\\n')\n\tskip := end\n\tid := \"\"\n\tif p.extensions&HeadingIDs != 0 {\n\t\tj, k := 0, 0\n\t\t// find start/end of heading id\n\t\tfor j = i; j < end-1 && (data[j] != '{' || data[j+1] != '#'); j++ {\n\t\t}\n\t\tfor k = j + 1; k < end && data[k] != '}'; k++ {\n\t\t}\n\t\t// extract heading id iff found\n\t\tif j < end && k < end {\n\t\t\tid = string(data[j+2 : k])\n\t\t\tend = j\n\t\t\tskip = k + 1\n\t\t\tfor end > 0 && data[end-1] == ' ' {\n\t\t\t\tend--\n\t\t\t}\n\t\t}\n\t}\n\tfor end > 0 && data[end-1] == '#' {\n\t\tif isBackslashEscaped(data, end-1) {\n\t\t\tbreak\n\t\t}\n\t\tend--\n\t}\n\tfor end > 0 && data[end-1] == ' ' {\n\t\tend--\n\t}\n\tif end > i {\n\t\tblock := &ast.Heading{\n\t\t\tHeadingID: id,\n\t\t\tIsSpecial: true,\n\t\t\tLevel:     1, // always level 1.\n\t\t}\n\t\tif id == \"\" && p.extensions&AutoHeadingIDs != 0 {\n\t\t\tblock.HeadingID = sanitizeHeadingID(string(data[i:end]))\n\t\t\tp.allHeadingsWithAutoID = append(p.allHeadingsWithAutoID, block)\n\t\t}\n\t\tblock.Literal = data[i:end]\n\t\tblock.Content = data[i:end]\n\t\tp.AddBlock(block)\n\t}\n\treturn skip\n}\n\nfunc (p *Parser) isUnderlinedHeading(data []byte) int {\n\t// test of level 1 heading\n\tif data[0] == '=' {\n\t\ti := skipChar(data, 1, '=')\n\t\ti = skipChar(data, i, ' ')\n\t\tif i < len(data) && data[i] == '\\n' {\n\t\t\treturn 1\n\t\t}\n\t\treturn 0\n\t}\n\n\t// test of level 2 heading\n\tif data[0] == '-' {\n\t\ti := skipChar(data, 1, '-')\n\t\ti = skipChar(data, i, ' ')\n\t\tif i < len(data) && data[i] == '\\n' {\n\t\t\treturn 2\n\t\t}\n\t\treturn 0\n\t}\n\n\treturn 0\n}\n\nfunc (p *Parser) titleBlock(data []byte, doRender bool) int {\n\tif data[0] != '%' {\n\t\treturn 0\n\t}\n\tsplitData := bytes.Split(data, []byte(\"\\n\"))\n\tvar i int\n\tfor idx, b := range splitData {\n\t\tif !bytes.HasPrefix(b, []byte(\"%\")) {\n\t\t\ti = idx // - 1\n\t\t\tbreak\n\t\t}\n\t}\n\n\tdata = bytes.Join(splitData[0:i], []byte(\"\\n\"))\n\tconsumed := len(data)\n\tdata = bytes.TrimPrefix(data, []byte(\"% \"))\n\tdata = bytes.Replace(data, []byte(\"\\n% \"), []byte(\"\\n\"), -1)\n\tblock := &ast.Heading{\n\t\tLevel:        1,\n\t\tIsTitleblock: true,\n\t}\n\tblock.Content = data\n\tp.AddBlock(block)\n\n\treturn consumed\n}\n\nfunc (p *Parser) html(data []byte, doRender bool) int {\n\tvar i, j int\n\n\t// identify the opening tag\n\tif data[0] != '<' {\n\t\treturn 0\n\t}\n\tcurtag, tagfound := p.htmlFindTag(data[1:])\n\n\t// handle special cases\n\tif !tagfound {\n\t\t// check for an HTML comment\n\t\tif size := p.htmlComment(data, doRender); size > 0 {\n\t\t\treturn size\n\t\t}\n\n\t\t// check for an <hr> tag\n\t\tif size := p.htmlHr(data, doRender); size > 0 {\n\t\t\treturn size\n\t\t}\n\n\t\t// no special case recognized\n\t\treturn 0\n\t}\n\n\t// look for an unindented matching closing tag\n\t// followed by a blank line\n\tfound := false\n\t/*\n\t\tclosetag := []byte(\"\\n</\" + curtag + \">\")\n\t\tj = len(curtag) + 1\n\t\tfor !found {\n\t\t\t// scan for a closing tag at the beginning of a line\n\t\t\tif skip := bytes.Index(data[j:], closetag); skip >= 0 {\n\t\t\t\tj += skip + len(closetag)\n\t\t\t} else {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// see if it is the only thing on the line\n\t\t\tif skip := IsEmpty(data[j:]); skip > 0 {\n\t\t\t\t// see if it is followed by a blank line/eof\n\t\t\t\tj += skip\n\t\t\t\tif j >= len(data) {\n\t\t\t\t\tfound = true\n\t\t\t\t\ti = j\n\t\t\t\t} else {\n\t\t\t\t\tif skip := IsEmpty(data[j:]); skip > 0 {\n\t\t\t\t\t\tj += skip\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\ti = j\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t*/\n\n\t// if not found, try a second pass looking for indented match\n\t// but not if tag is \"ins\" or \"del\" (following original Markdown.pl)\n\tif !found && curtag != \"ins\" && curtag != \"del\" {\n\t\ti = 1\n\t\tfor i < len(data) {\n\t\t\ti++\n\t\t\tfor i < len(data) && !(data[i-1] == '<' && data[i] == '/') {\n\t\t\t\ti++\n\t\t\t}\n\n\t\t\tif i+2+len(curtag) >= len(data) {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tj = p.htmlFindEnd(curtag, data[i-1:])\n\n\t\t\tif j > 0 {\n\t\t\t\ti += j - 1\n\t\t\t\tfound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif !found {\n\t\treturn 0\n\t}\n\n\t// the end of the block has been found\n\tif doRender {\n\t\t// trim newlines\n\t\tend := backChar(data, i, '\\n')\n\t\thtmlBLock := &ast.HTMLBlock{Leaf: ast.Leaf{Content: data[:end]}}\n\t\tp.AddBlock(htmlBLock)\n\t\tfinalizeHTMLBlock(htmlBLock)\n\t}\n\n\treturn i\n}\n\nfunc finalizeHTMLBlock(block *ast.HTMLBlock) {\n\tblock.Literal = block.Content\n\tblock.Content = nil\n}\n\n// HTML comment, lax form\nfunc (p *Parser) htmlComment(data []byte, doRender bool) int {\n\ti := p.inlineHTMLComment(data)\n\t// needs to end with a blank line\n\tif j := IsEmpty(data[i:]); j > 0 {\n\t\tsize := i + j\n\t\tif doRender {\n\t\t\t// trim trailing newlines\n\t\t\tend := backChar(data, size, '\\n')\n\t\t\thtmlBLock := &ast.HTMLBlock{Leaf: ast.Leaf{Content: data[:end]}}\n\t\t\tp.AddBlock(htmlBLock)\n\t\t\tfinalizeHTMLBlock(htmlBLock)\n\t\t}\n\t\treturn size\n\t}\n\treturn 0\n}\n\n// HR, which is the only self-closing block tag considered\nfunc (p *Parser) htmlHr(data []byte, doRender bool) int {\n\tif len(data) < 4 {\n\t\treturn 0\n\t}\n\tif data[0] != '<' || (data[1] != 'h' && data[1] != 'H') || (data[2] != 'r' && data[2] != 'R') {\n\t\treturn 0\n\t}\n\tif data[3] != ' ' && data[3] != '/' && data[3] != '>' {\n\t\t// not an <hr> tag after all; at least not a valid one\n\t\treturn 0\n\t}\n\ti := 3\n\tfor i < len(data) && data[i] != '>' && data[i] != '\\n' {\n\t\ti++\n\t}\n\tif i < len(data) && data[i] == '>' {\n\t\ti++\n\t\tif j := IsEmpty(data[i:]); j > 0 {\n\t\t\tsize := i + j\n\t\t\tif doRender {\n\t\t\t\t// trim newlines\n\t\t\t\tend := backChar(data, size, '\\n')\n\t\t\t\thtmlBlock := &ast.HTMLBlock{Leaf: ast.Leaf{Content: data[:end]}}\n\t\t\t\tp.AddBlock(htmlBlock)\n\t\t\t\tfinalizeHTMLBlock(htmlBlock)\n\t\t\t}\n\t\t\treturn size\n\t\t}\n\t}\n\treturn 0\n}\n\nfunc (p *Parser) htmlFindTag(data []byte) (string, bool) {\n\ti := skipAlnum(data, 0)\n\tkey := string(data[:i])\n\tif _, ok := blockTags[key]; ok {\n\t\treturn key, true\n\t}\n\treturn \"\", false\n}\n\nfunc (p *Parser) htmlFindEnd(tag string, data []byte) int {\n\t// assume data[0] == '<' && data[1] == '/' already tested\n\tif tag == \"hr\" {\n\t\treturn 2\n\t}\n\t// check if tag is a match\n\tclosetag := []byte(\"</\" + tag + \">\")\n\tif !bytes.HasPrefix(data, closetag) {\n\t\treturn 0\n\t}\n\ti := len(closetag)\n\n\t// check that the rest of the line is blank\n\tskip := 0\n\tif skip = IsEmpty(data[i:]); skip == 0 {\n\t\treturn 0\n\t}\n\ti += skip\n\tskip = 0\n\n\tif i >= len(data) {\n\t\treturn i\n\t}\n\n\tif p.extensions&LaxHTMLBlocks != 0 {\n\t\treturn i\n\t}\n\tif skip = IsEmpty(data[i:]); skip == 0 {\n\t\t// following line must be blank\n\t\treturn 0\n\t}\n\n\treturn i + skip\n}\n\nfunc IsEmpty(data []byte) int {\n\t// it is okay to call isEmpty on an empty buffer\n\tif len(data) == 0 {\n\t\treturn 0\n\t}\n\n\tvar i int\n\tfor i = 0; i < len(data) && data[i] != '\\n'; i++ {\n\t\tif data[i] != ' ' && data[i] != '\\t' {\n\t\t\treturn 0\n\t\t}\n\t}\n\ti = skipCharN(data, i, '\\n', 1)\n\treturn i\n}\n\nfunc isHRule(data []byte) bool {\n\ti := 0\n\n\t// skip up to three spaces\n\tfor i < 3 && data[i] == ' ' {\n\t\ti++\n\t}\n\n\t// look at the hrule char\n\tif data[i] != '*' && data[i] != '-' && data[i] != '_' {\n\t\treturn false\n\t}\n\tc := data[i]\n\n\t// the whole line must be the char or whitespace\n\tn := 0\n\tfor i < len(data) && data[i] != '\\n' {\n\t\tswitch {\n\t\tcase data[i] == c:\n\t\t\tn++\n\t\tcase data[i] != ' ':\n\t\t\treturn false\n\t\t}\n\t\ti++\n\t}\n\n\treturn n >= 3\n}\n\n// isFenceLine checks if there's a fence line (e.g., ``` or ``` go) at the beginning of data,\n// and returns the end index if so, or 0 otherwise. It also returns the marker found.\n// If syntax is not nil, it gets set to the syntax specified in the fence line.\nfunc isFenceLine(data []byte, syntax *string, oldmarker string) (end int, marker string) {\n\ti, size := 0, 0\n\n\tn := len(data)\n\t// skip up to three spaces\n\tfor i < n && i < 3 && data[i] == ' ' {\n\t\ti++\n\t}\n\n\t// check for the marker characters: ~ or `\n\tif i >= n {\n\t\treturn 0, \"\"\n\t}\n\tif data[i] != '~' && data[i] != '`' {\n\t\treturn 0, \"\"\n\t}\n\n\tc := data[i]\n\n\t// the whole line must be the same char or whitespace\n\tfor i < n && data[i] == c {\n\t\tsize++\n\t\ti++\n\t}\n\n\t// the marker char must occur at least 3 times\n\tif size < 3 {\n\t\treturn 0, \"\"\n\t}\n\tmarker = string(data[i-size : i])\n\n\t// if this is the end marker, it must match the beginning marker\n\tif oldmarker != \"\" && marker != oldmarker {\n\t\treturn 0, \"\"\n\t}\n\n\t// if just read the beginning marker, read the syntax\n\tif oldmarker == \"\" {\n\t\ti = skipChar(data, i, ' ')\n\t\tif i >= n {\n\t\t\tif i == n {\n\t\t\t\treturn i, marker\n\t\t\t}\n\t\t\treturn 0, \"\"\n\t\t}\n\n\t\tsyntaxStart, syntaxLen := syntaxRange(data, &i)\n\t\tif syntaxStart == 0 && syntaxLen == 0 {\n\t\t\treturn 0, \"\"\n\t\t}\n\n\t\t// caller wants the syntax\n\t\tif syntax != nil {\n\t\t\t*syntax = string(data[syntaxStart : syntaxStart+syntaxLen])\n\t\t}\n\t}\n\n\ti = skipChar(data, i, ' ')\n\tif i >= n || data[i] != '\\n' {\n\t\tif i == n {\n\t\t\treturn i, marker\n\t\t}\n\t\treturn 0, \"\"\n\t}\n\treturn i + 1, marker // Take newline into account.\n}\n\nfunc syntaxRange(data []byte, iout *int) (int, int) {\n\tn := len(data)\n\tsyn := 0\n\ti := *iout\n\tsyntaxStart := i\n\tif data[i] == '{' {\n\t\ti++\n\t\tsyntaxStart++\n\n\t\tfor i < n && data[i] != '}' && data[i] != '\\n' {\n\t\t\tsyn++\n\t\t\ti++\n\t\t}\n\n\t\tif i >= n || data[i] != '}' {\n\t\t\treturn 0, 0\n\t\t}\n\n\t\t// strip all whitespace at the beginning and the end\n\t\t// of the {} block\n\t\tfor syn > 0 && IsSpace(data[syntaxStart]) {\n\t\t\tsyntaxStart++\n\t\t\tsyn--\n\t\t}\n\n\t\tfor syn > 0 && IsSpace(data[syntaxStart+syn-1]) {\n\t\t\tsyn--\n\t\t}\n\n\t\ti++\n\t} else {\n\t\tfor i < n && !IsSpace(data[i]) {\n\t\t\tsyn++\n\t\t\ti++\n\t\t}\n\t}\n\n\t*iout = i\n\treturn syntaxStart, syn\n}\n\n// fencedCodeBlock returns the end index if data contains a fenced code block at the beginning,\n// or 0 otherwise. It writes to out if doRender is true, otherwise it has no side effects.\n// If doRender is true, a final newline is mandatory to recognize the fenced code block.\nfunc (p *Parser) fencedCodeBlock(data []byte, doRender bool) int {\n\tvar syntax string\n\tbeg, marker := isFenceLine(data, &syntax, \"\")\n\tif beg == 0 || beg >= len(data) {\n\t\treturn 0\n\t}\n\n\tvar work bytes.Buffer\n\twork.WriteString(syntax)\n\twork.WriteByte('\\n')\n\n\tfor {\n\t\t// safe to assume beg < len(data)\n\n\t\t// check for the end of the code block\n\t\tfenceEnd, _ := isFenceLine(data[beg:], nil, marker)\n\t\tif fenceEnd != 0 {\n\t\t\tbeg += fenceEnd\n\t\t\tbreak\n\t\t}\n\n\t\t// copy the current line\n\t\tend := skipUntilChar(data, beg, '\\n') + 1\n\n\t\t// did we reach the end of the buffer without a closing marker?\n\t\tif end >= len(data) {\n\t\t\treturn 0\n\t\t}\n\n\t\t// verbatim copy to the working buffer\n\t\tif doRender {\n\t\t\twork.Write(data[beg:end])\n\t\t}\n\t\tbeg = end\n\t}\n\n\tif doRender {\n\t\tcodeBlock := &ast.CodeBlock{\n\t\t\tIsFenced: true,\n\t\t}\n\t\tcodeBlock.Content = work.Bytes() // TODO: get rid of temp buffer\n\n\t\tif p.extensions&Mmark == 0 {\n\t\t\tp.AddBlock(codeBlock)\n\t\t\tfinalizeCodeBlock(codeBlock)\n\t\t\treturn beg\n\t\t}\n\n\t\t// Check for caption and if found make it a figure.\n\t\tif captionContent, id, consumed := p.caption(data[beg:], []byte(captionFigure)); consumed > 0 {\n\t\t\tfigure := &ast.CaptionFigure{}\n\t\t\tcaption := &ast.Caption{}\n\t\t\tfigure.HeadingID = id\n\t\t\tp.Inline(caption, captionContent)\n\n\t\t\tp.AddBlock(figure)\n\t\t\tcodeBlock.AsLeaf().Attribute = figure.AsContainer().Attribute\n\t\t\tp.addChild(codeBlock)\n\t\t\tfinalizeCodeBlock(codeBlock)\n\t\t\tp.addChild(caption)\n\t\t\tp.Finalize(figure)\n\n\t\t\tbeg += consumed\n\n\t\t\treturn beg\n\t\t}\n\n\t\t// Still here, normal block\n\t\tp.AddBlock(codeBlock)\n\t\tfinalizeCodeBlock(codeBlock)\n\t}\n\n\treturn beg\n}\n\nfunc unescapeChar(str []byte) []byte {\n\tif str[0] == '\\\\' {\n\t\treturn []byte{str[1]}\n\t}\n\treturn []byte(html.UnescapeString(string(str)))\n}\n\nfunc unescapeString(str []byte) []byte {\n\tif reBackslashOrAmp.Match(str) {\n\t\treturn reEntityOrEscapedChar.ReplaceAllFunc(str, unescapeChar)\n\t}\n\treturn str\n}\n\nfunc finalizeCodeBlock(code *ast.CodeBlock) {\n\tc := code.Content\n\tif code.IsFenced {\n\t\tnewlinePos := bytes.IndexByte(c, '\\n')\n\t\tfirstLine := c[:newlinePos]\n\t\trest := c[newlinePos+1:]\n\t\tcode.Info = unescapeString(bytes.Trim(firstLine, \"\\n\"))\n\t\tcode.Literal = rest\n\t} else {\n\t\tcode.Literal = c\n\t}\n\tcode.Content = nil\n}\n\n// returns blockquote prefix length\nfunc (p *Parser) quotePrefix(data []byte) int {\n\ti := 0\n\tn := len(data)\n\tfor i < 3 && i < n && data[i] == ' ' {\n\t\ti++\n\t}\n\tif i < n && data[i] == '>' {\n\t\tif i+1 < n && data[i+1] == ' ' {\n\t\t\treturn i + 2\n\t\t}\n\t\treturn i + 1\n\t}\n\treturn 0\n}\n\n// blockquote ends with at least one blank line\n// followed by something without a blockquote prefix\nfunc (p *Parser) terminateBlockquote(data []byte, beg, end int) bool {\n\tif IsEmpty(data[beg:]) <= 0 {\n\t\treturn false\n\t}\n\tif end >= len(data) {\n\t\treturn true\n\t}\n\treturn p.quotePrefix(data[end:]) == 0 && IsEmpty(data[end:]) == 0\n}\n\n// parse a blockquote fragment\nfunc (p *Parser) quote(data []byte) int {\n\tvar raw bytes.Buffer\n\tbeg, end := 0, 0\n\tfor beg < len(data) {\n\t\tend = beg\n\t\t// Step over whole lines, collecting them. While doing that, check for\n\t\t// fenced code and if one's found, incorporate it altogether,\n\t\t// irregardless of any contents inside it\n\t\tfor end < len(data) && data[end] != '\\n' {\n\t\t\tif p.extensions&FencedCode != 0 {\n\t\t\t\tif i := p.fencedCodeBlock(data[end:], false); i > 0 {\n\t\t\t\t\t// -1 to compensate for the extra end++ after the loop:\n\t\t\t\t\tend += i - 1\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tend++\n\t\t}\n\t\tend = skipCharN(data, end, '\\n', 1)\n\t\tif pre := p.quotePrefix(data[beg:]); pre > 0 {\n\t\t\t// skip the prefix\n\t\t\tbeg += pre\n\t\t} else if p.terminateBlockquote(data, beg, end) {\n\t\t\tbreak\n\t\t}\n\t\t// this line is part of the blockquote\n\t\traw.Write(data[beg:end])\n\t\tbeg = end\n\t}\n\n\tif p.extensions&Mmark == 0 {\n\t\tblock := p.AddBlock(&ast.BlockQuote{})\n\t\tp.Block(raw.Bytes())\n\t\tp.Finalize(block)\n\t\treturn end\n\t}\n\n\tif captionContent, id, consumed := p.caption(data[end:], []byte(captionQuote)); consumed > 0 {\n\t\tfigure := &ast.CaptionFigure{}\n\t\tcaption := &ast.Caption{}\n\t\tfigure.HeadingID = id\n\t\tp.Inline(caption, captionContent)\n\n\t\tp.AddBlock(figure) // this discard any attributes\n\t\tblock := &ast.BlockQuote{}\n\t\tblock.AsContainer().Attribute = figure.AsContainer().Attribute\n\t\tp.addChild(block)\n\t\tp.Block(raw.Bytes())\n\t\tp.Finalize(block)\n\n\t\tp.addChild(caption)\n\t\tp.Finalize(figure)\n\n\t\tend += consumed\n\n\t\treturn end\n\t}\n\n\tblock := p.AddBlock(&ast.BlockQuote{})\n\tp.Block(raw.Bytes())\n\tp.Finalize(block)\n\n\treturn end\n}\n\n// returns prefix length for block code\nfunc (p *Parser) codePrefix(data []byte) int {\n\tn := len(data)\n\tif n >= 1 && data[0] == '\\t' {\n\t\treturn 1\n\t}\n\tif n >= 4 && data[3] == ' ' && data[2] == ' ' && data[1] == ' ' && data[0] == ' ' {\n\t\treturn 4\n\t}\n\treturn 0\n}\n\nfunc (p *Parser) code(data []byte) int {\n\tvar work bytes.Buffer\n\n\ti := 0\n\tfor i < len(data) {\n\t\tbeg := i\n\n\t\ti = skipUntilChar(data, i, '\\n')\n\t\ti = skipCharN(data, i, '\\n', 1)\n\n\t\tblankline := IsEmpty(data[beg:i]) > 0\n\t\tif pre := p.codePrefix(data[beg:i]); pre > 0 {\n\t\t\tbeg += pre\n\t\t} else if !blankline {\n\t\t\t// non-empty, non-prefixed line breaks the pre\n\t\t\ti = beg\n\t\t\tbreak\n\t\t}\n\n\t\t// verbatim copy to the working buffer\n\t\tif blankline {\n\t\t\twork.WriteByte('\\n')\n\t\t} else {\n\t\t\twork.Write(data[beg:i])\n\t\t}\n\t}\n\n\t// trim all the \\n off the end of work\n\tworkbytes := work.Bytes()\n\n\teol := backChar(workbytes, len(workbytes), '\\n')\n\n\tif eol != len(workbytes) {\n\t\twork.Truncate(eol)\n\t}\n\n\twork.WriteByte('\\n')\n\n\tcodeBlock := &ast.CodeBlock{\n\t\tIsFenced: false,\n\t}\n\t// TODO: get rid of temp buffer\n\tcodeBlock.Content = work.Bytes()\n\tp.AddBlock(codeBlock)\n\tfinalizeCodeBlock(codeBlock)\n\n\treturn i\n}\n\n// returns unordered list item prefix\nfunc (p *Parser) uliPrefix(data []byte) int {\n\t// start with up to 3 spaces\n\ti := skipCharN(data, 0, ' ', 3)\n\n\tif i >= len(data)-1 {\n\t\treturn 0\n\t}\n\t// need one of {'*', '+', '-'} followed by a space or a tab\n\tif (data[i] != '*' && data[i] != '+' && data[i] != '-') ||\n\t\t(data[i+1] != ' ' && data[i+1] != '\\t') {\n\t\treturn 0\n\t}\n\treturn i + 2\n}\n\n// returns ordered list item prefix\nfunc (p *Parser) oliPrefix(data []byte) int {\n\t// start with up to 3 spaces\n\ti := skipCharN(data, 0, ' ', 3)\n\n\t// count the digits\n\tstart := i\n\tfor i < len(data) && data[i] >= '0' && data[i] <= '9' {\n\t\ti++\n\t}\n\tif start == i || i >= len(data)-1 {\n\t\treturn 0\n\t}\n\n\t// we need >= 1 digits followed by a dot and a space or a tab\n\tif data[i] != '.' && data[i] != ')' || !(data[i+1] == ' ' || data[i+1] == '\\t') {\n\t\treturn 0\n\t}\n\treturn i + 2\n}\n\n// returns definition list item prefix\nfunc (p *Parser) dliPrefix(data []byte) int {\n\tif len(data) < 2 {\n\t\treturn 0\n\t}\n\t// need a ':' followed by a space or a tab\n\tif data[0] != ':' || !(data[1] == ' ' || data[1] == '\\t') {\n\t\treturn 0\n\t}\n\t// TODO: this is a no-op (data[0] is ':' so not ' ').\n\t// Maybe the intent was to eat spaces before ':' ?\n\t// either way, no change in tests\n\ti := skipChar(data, 0, ' ')\n\treturn i + 2\n}\n\n// TODO: maybe it was meant to be like below\n// either way, no change in tests\n/*\nfunc (p *Parser) dliPrefix(data []byte) int {\n\ti := skipChar(data, 0, ' ')\n\tif i+len(data) < 2 {\n\t\treturn 0\n\t}\n\t// need a ':' followed by a space or a tab\n\tif data[i] != ':' || !(data[i+1] == ' ' || data[i+1] == '\\t') {\n\t\treturn 0\n\t}\n\treturn i + 2\n}\n*/\n\n// parse ordered or unordered list block\nfunc (p *Parser) list(data []byte, flags ast.ListType, start int, delim byte) int {\n\ti := 0\n\tflags |= ast.ListItemBeginningOfList\n\tlist := &ast.List{\n\t\tListFlags: flags,\n\t\tTight:     true,\n\t\tStart:     start,\n\t\tDelimiter: delim,\n\t}\n\tblock := p.AddBlock(list)\n\n\tfor i < len(data) {\n\t\tskip := p.listItem(data[i:], &flags)\n\t\tif flags&ast.ListItemContainsBlock != 0 {\n\t\t\tlist.Tight = false\n\t\t}\n\t\ti += skip\n\t\tif skip == 0 || flags&ast.ListItemEndOfList != 0 {\n\t\t\tbreak\n\t\t}\n\t\tflags &= ^ast.ListItemBeginningOfList\n\t}\n\n\tabove := block.GetParent()\n\tfinalizeList(list)\n\tp.tip = above\n\treturn i\n}\n\n// Returns true if the list item is not the same type as its parent list\nfunc (p *Parser) listTypeChanged(data []byte, flags *ast.ListType) bool {\n\tif p.dliPrefix(data) > 0 && *flags&ast.ListTypeDefinition == 0 {\n\t\treturn true\n\t} else if p.oliPrefix(data) > 0 && *flags&ast.ListTypeOrdered == 0 {\n\t\treturn true\n\t} else if p.uliPrefix(data) > 0 && (*flags&ast.ListTypeOrdered != 0 || *flags&ast.ListTypeDefinition != 0) {\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Returns true if block ends with a blank line, descending if needed\n// into lists and sublists.\nfunc endsWithBlankLine(block ast.Node) bool {\n\t// TODO: figure this out. Always false now.\n\tfor block != nil {\n\t\t//if block.lastLineBlank {\n\t\t//return true\n\t\t//}\n\t\tswitch block.(type) {\n\t\tcase *ast.List, *ast.ListItem:\n\t\t\tblock = ast.GetLastChild(block)\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\treturn false\n}\n\nfunc finalizeList(list *ast.List) {\n\titems := list.Parent.GetChildren()\n\tlastItemIdx := len(items) - 1\n\tfor i, item := range items {\n\t\tisLastItem := i == lastItemIdx\n\t\t// check for non-final list item ending with blank line:\n\t\tif !isLastItem && endsWithBlankLine(item) {\n\t\t\tlist.Tight = false\n\t\t\tbreak\n\t\t}\n\t\t// recurse into children of list item, to see if there are spaces\n\t\t// between any of them:\n\t\tsubItems := item.GetParent().GetChildren()\n\t\tlastSubItemIdx := len(subItems) - 1\n\t\tfor j, subItem := range subItems {\n\t\t\tisLastSubItem := j == lastSubItemIdx\n\t\t\tif (!isLastItem || !isLastSubItem) && endsWithBlankLine(subItem) {\n\t\t\t\tlist.Tight = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n}\n\n// Parse a single list item.\n// Assumes initial prefix is already removed if this is a sublist.\nfunc (p *Parser) listItem(data []byte, flags *ast.ListType) int {\n\t// keep track of the indentation of the first line\n\titemIndent := 0\n\tif data[0] == '\\t' {\n\t\titemIndent += 4\n\t} else {\n\t\tfor itemIndent < 3 && data[itemIndent] == ' ' {\n\t\t\titemIndent++\n\t\t}\n\t}\n\n\tvar (\n\t\tbulletChar byte = '*'\n\t\tdelimiter  byte = '.'\n\t)\n\ti := p.uliPrefix(data)\n\tif i == 0 {\n\t\ti = p.oliPrefix(data)\n\t\tif i > 0 {\n\t\t\tdelimiter = data[i-2]\n\t\t}\n\t} else {\n\t\tbulletChar = data[i-2]\n\t}\n\tif i == 0 {\n\t\ti = p.dliPrefix(data)\n\t\t// reset definition term flag\n\t\tif i > 0 {\n\t\t\t*flags &= ^ast.ListTypeTerm\n\t\t}\n\t}\n\tif i == 0 {\n\t\t// if in definition list, set term flag and continue\n\t\tif *flags&ast.ListTypeDefinition != 0 {\n\t\t\t*flags |= ast.ListTypeTerm\n\t\t} else {\n\t\t\treturn 0\n\t\t}\n\t}\n\n\t// skip leading whitespace on first line\n\ti = skipChar(data, i, ' ')\n\n\t// find the end of the line\n\tline := i\n\tfor i > 0 && i < len(data) && data[i-1] != '\\n' {\n\t\ti++\n\t}\n\n\t// get working buffer\n\tvar raw bytes.Buffer\n\n\t// put the first line into the working buffer\n\traw.Write(data[line:i])\n\tline = i\n\n\t// process the following lines\n\tcontainsBlankLine := false\n\tsublist := 0\n\ngatherlines:\n\tfor line < len(data) {\n\t\ti++\n\n\t\t// find the end of this line\n\t\tfor i < len(data) && data[i-1] != '\\n' {\n\t\t\ti++\n\t\t}\n\n\t\t// if it is an empty line, guess that it is part of this item\n\t\t// and move on to the next line\n\t\tif IsEmpty(data[line:i]) > 0 {\n\t\t\tcontainsBlankLine = true\n\t\t\tline = i\n\t\t\tcontinue\n\t\t}\n\n\t\t// calculate the indentation\n\t\tindent := 0\n\t\tindentIndex := 0\n\t\tif data[line] == '\\t' {\n\t\t\tindentIndex++\n\t\t\tindent += 4\n\t\t} else {\n\t\t\tfor indent < 4 && line+indent < i && data[line+indent] == ' ' {\n\t\t\t\tindent++\n\t\t\t\tindentIndex++\n\t\t\t}\n\t\t}\n\n\t\tchunk := data[line+indentIndex : i]\n\n\t\t// If there is a fence line (marking starting of a code block)\n\t\t// without indent do not process it as part of the list.\n\t\tif p.extensions&FencedCode != 0 {\n\t\t\tfenceLineEnd, _ := isFenceLine(chunk, nil, \"\")\n\t\t\tif fenceLineEnd > 0 && indent == 0 {\n\t\t\t\t*flags |= ast.ListItemEndOfList\n\t\t\t\tbreak gatherlines\n\t\t\t}\n\t\t}\n\n\t\t// evaluate how this line fits in\n\t\tswitch {\n\t\t// is this a nested list item?\n\t\tcase (p.uliPrefix(chunk) > 0 && !isHRule(chunk)) || p.oliPrefix(chunk) > 0 || p.dliPrefix(chunk) > 0:\n\n\t\t\t// if indent is 4 or more spaces on unordered or ordered lists\n\t\t\t// we need to add leadingWhiteSpaces + 1 spaces in the beginning of the chunk\n\t\t\tif indentIndex >= 4 && p.dliPrefix(chunk) <= 0 {\n\t\t\t\tleadingWhiteSpaces := skipChar(chunk, 0, ' ')\n\t\t\t\tchunk = data[line+indentIndex-(leadingWhiteSpaces+1) : i]\n\t\t\t}\n\n\t\t\t// to be a nested list, it must be indented more\n\t\t\t// if not, it is either a different kind of list\n\t\t\t// or the next item in the same list\n\t\t\tif indent <= itemIndent {\n\t\t\t\tif p.listTypeChanged(chunk, flags) {\n\t\t\t\t\t*flags |= ast.ListItemEndOfList\n\t\t\t\t} else if containsBlankLine {\n\t\t\t\t\t*flags |= ast.ListItemContainsBlock\n\t\t\t\t}\n\n\t\t\t\tbreak gatherlines\n\t\t\t}\n\n\t\t\tif containsBlankLine {\n\t\t\t\t*flags |= ast.ListItemContainsBlock\n\t\t\t}\n\n\t\t\t// is this the first item in the nested list?\n\t\t\tif sublist == 0 {\n\t\t\t\tsublist = raw.Len()\n\t\t\t\t// in the case of dliPrefix we are too late and need to search back for the definition item, which\n\t\t\t\t// should be on the previous line, we then adjust sublist to start there.\n\t\t\t\tif p.dliPrefix(chunk) > 0 {\n\t\t\t\t\tsublist = backUntilChar(raw.Bytes(), raw.Len()-1, '\\n')\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// is this a nested prefix heading?\n\t\tcase p.isPrefixHeading(chunk), p.isPrefixSpecialHeading(chunk):\n\t\t\t// if the heading is not indented, it is not nested in the list\n\t\t\t// and thus ends the list\n\t\t\tif containsBlankLine && indent < 4 {\n\t\t\t\t*flags |= ast.ListItemEndOfList\n\t\t\t\tbreak gatherlines\n\t\t\t}\n\t\t\t*flags |= ast.ListItemContainsBlock\n\n\t\t// anything following an empty line is only part\n\t\t// of this item if it is indented 4 spaces\n\t\t// (regardless of the indentation of the beginning of the item)\n\t\tcase containsBlankLine && indent < 4:\n\t\t\tif *flags&ast.ListTypeDefinition != 0 && i < len(data)-1 {\n\t\t\t\t// is the next item still a part of this list?\n\t\t\t\tnext := skipUntilChar(data, i, '\\n')\n\t\t\t\tfor next < len(data)-1 && data[next] == '\\n' {\n\t\t\t\t\tnext++\n\t\t\t\t}\n\t\t\t\tif i < len(data)-1 && data[i] != ':' && next < len(data)-1 && data[next] != ':' {\n\t\t\t\t\t*flags |= ast.ListItemEndOfList\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t*flags |= ast.ListItemEndOfList\n\t\t\t}\n\t\t\tbreak gatherlines\n\n\t\t// a blank line means this should be parsed as a block\n\t\tcase containsBlankLine:\n\t\t\traw.WriteByte('\\n')\n\t\t\t*flags |= ast.ListItemContainsBlock\n\t\t}\n\n\t\t// if this line was preceded by one or more blanks,\n\t\t// re-introduce the blank into the buffer\n\t\tif containsBlankLine {\n\t\t\tcontainsBlankLine = false\n\t\t\traw.WriteByte('\\n')\n\t\t}\n\n\t\t// add the line into the working buffer without prefix\n\t\traw.Write(chunk)\n\n\t\tline = i\n\t}\n\n\trawBytes := raw.Bytes()\n\n\tlistItem := &ast.ListItem{\n\t\tListFlags:  *flags,\n\t\tTight:      false,\n\t\tBulletChar: bulletChar,\n\t\tDelimiter:  delimiter,\n\t}\n\tp.AddBlock(listItem)\n\n\t// render the contents of the list item\n\tif *flags&ast.ListItemContainsBlock != 0 && *flags&ast.ListTypeTerm == 0 {\n\t\t// intermediate render of block item, except for definition term\n\t\tif sublist > 0 {\n\t\t\tp.Block(rawBytes[:sublist])\n\t\t\tp.Block(rawBytes[sublist:])\n\t\t} else {\n\t\t\tp.Block(rawBytes)\n\t\t}\n\t} else {\n\t\t// intermediate render of inline item\n\t\tpara := &ast.Paragraph{}\n\t\tif sublist > 0 {\n\t\t\tpara.Content = rawBytes[:sublist]\n\t\t} else {\n\t\t\tpara.Content = rawBytes\n\t\t}\n\t\tp.addChild(para)\n\t\tif sublist > 0 {\n\t\t\tp.Block(rawBytes[sublist:])\n\t\t}\n\t}\n\treturn line\n}\n\n// render a single paragraph that has already been parsed out\nfunc (p *Parser) renderParagraph(data []byte) {\n\tif len(data) == 0 {\n\t\treturn\n\t}\n\n\t// trim leading spaces\n\tbeg := skipChar(data, 0, ' ')\n\n\tend := len(data)\n\t// trim trailing newline\n\tif data[len(data)-1] == '\\n' {\n\t\tend--\n\t}\n\n\t// trim trailing spaces\n\tfor end > beg && data[end-1] == ' ' {\n\t\tend--\n\t}\n\tpara := &ast.Paragraph{}\n\tpara.Content = data[beg:end]\n\tp.AddBlock(para)\n}\n\n// blockMath handle block surround with $$\nfunc (p *Parser) blockMath(data []byte) int {\n\tif len(data) <= 4 || data[0] != '$' || data[1] != '$' || data[2] == '$' {\n\t\treturn 0\n\t}\n\n\t// find next $$\n\tvar end int\n\tfor end = 2; end+1 < len(data) && (data[end] != '$' || data[end+1] != '$'); end++ {\n\t}\n\n\t// $$ not match\n\tif end+1 == len(data) {\n\t\treturn 0\n\t}\n\n\t// render the display math\n\tmathBlock := &ast.MathBlock{}\n\tmathBlock.Literal = data[2:end]\n\tp.AddBlock(mathBlock)\n\n\treturn end + 2\n}\n\nfunc (p *Parser) paragraph(data []byte) int {\n\t// prev: index of 1st char of previous line\n\t// line: index of 1st char of current line\n\t// i: index of cursor/end of current line\n\tvar prev, line, i int\n\ttabSize := tabSizeDefault\n\tif p.extensions&TabSizeEight != 0 {\n\t\ttabSize = tabSizeDouble\n\t}\n\t// keep going until we find something to mark the end of the paragraph\n\tfor i < len(data) {\n\t\t// mark the beginning of the current line\n\t\tprev = line\n\t\tcurrent := data[i:]\n\t\tline = i\n\n\t\t// did we find a reference or a footnote? If so, end a paragraph\n\t\t// preceding it and report that we have consumed up to the end of that\n\t\t// reference:\n\t\tif refEnd := isReference(p, current, tabSize); refEnd > 0 {\n\t\t\tp.renderParagraph(data[:i])\n\t\t\treturn i + refEnd\n\t\t}\n\n\t\t// did we find a blank line marking the end of the paragraph?\n\t\tif n := IsEmpty(current); n > 0 {\n\t\t\t// did this blank line followed by a definition list item?\n\t\t\tif p.extensions&DefinitionLists != 0 {\n\t\t\t\tif i < len(data)-1 && data[i+1] == ':' {\n\t\t\t\t\tlistLen := p.list(data[prev:], ast.ListTypeDefinition, 0, '.')\n\t\t\t\t\treturn prev + listLen\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tp.renderParagraph(data[:i])\n\t\t\treturn i + n\n\t\t}\n\n\t\t// an underline under some text marks a heading, so our paragraph ended on prev line\n\t\tif i > 0 {\n\t\t\tif level := p.isUnderlinedHeading(current); level > 0 {\n\t\t\t\t// render the paragraph\n\t\t\t\tp.renderParagraph(data[:prev])\n\n\t\t\t\t// ignore leading and trailing whitespace\n\t\t\t\teol := i - 1\n\t\t\t\tfor prev < eol && data[prev] == ' ' {\n\t\t\t\t\tprev++\n\t\t\t\t}\n\t\t\t\tfor eol > prev && data[eol-1] == ' ' {\n\t\t\t\t\teol--\n\t\t\t\t}\n\n\t\t\t\tblock := &ast.Heading{\n\t\t\t\t\tLevel: level,\n\t\t\t\t}\n\t\t\t\tif p.extensions&AutoHeadingIDs != 0 {\n\t\t\t\t\tblock.HeadingID = sanitizeHeadingID(string(data[prev:eol]))\n\t\t\t\t\tp.allHeadingsWithAutoID = append(p.allHeadingsWithAutoID, block)\n\t\t\t\t}\n\n\t\t\t\tblock.Content = data[prev:eol]\n\t\t\t\tp.AddBlock(block)\n\n\t\t\t\t// find the end of the underline\n\t\t\t\treturn skipUntilChar(data, i, '\\n')\n\t\t\t}\n\t\t}\n\n\t\t// if the next line starts a block of HTML, then the paragraph ends here\n\t\tif p.extensions&LaxHTMLBlocks != 0 {\n\t\t\tif data[i] == '<' && p.html(current, false) > 0 {\n\t\t\t\t// rewind to before the HTML block\n\t\t\t\tp.renderParagraph(data[:i])\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\n\t\t// if there's a prefixed heading or a horizontal rule after this, paragraph is over\n\t\tif p.isPrefixHeading(current) || p.isPrefixSpecialHeading(current) || isHRule(current) {\n\t\t\tp.renderParagraph(data[:i])\n\t\t\treturn i\n\t\t}\n\n\t\t// if there's a block quote, paragraph is over\n\t\tif p.quotePrefix(current) > 0 {\n\t\t\tp.renderParagraph(data[:i])\n\t\t\treturn i\n\t\t}\n\n\t\t// if there's a fenced code block, paragraph is over\n\t\tif p.extensions&FencedCode != 0 {\n\t\t\tif p.fencedCodeBlock(current, false) > 0 {\n\t\t\t\tp.renderParagraph(data[:i])\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\n\t\t// if there's a figure block, paragraph is over\n\t\tif p.extensions&Mmark != 0 {\n\t\t\tif p.figureBlock(current, false) > 0 {\n\t\t\t\tp.renderParagraph(data[:i])\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\n\t\t// if there's a table, paragraph is over\n\t\tif p.extensions&Tables != 0 {\n\t\t\tif j, _, _ := p.tableHeader(current, false); j > 0 {\n\t\t\t\tp.renderParagraph(data[:i])\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\n\t\t// if there's a definition list item, prev line is a definition term\n\t\tif p.extensions&DefinitionLists != 0 {\n\t\t\tif p.dliPrefix(current) != 0 {\n\t\t\t\tret := p.list(data[prev:], ast.ListTypeDefinition, 0, '.')\n\t\t\t\treturn ret + prev\n\t\t\t}\n\t\t}\n\n\t\t// if there's a list after this, paragraph is over\n\t\tif p.extensions&NoEmptyLineBeforeBlock != 0 {\n\t\t\tif p.uliPrefix(current) != 0 ||\n\t\t\t\tp.oliPrefix(current) != 0 ||\n\t\t\t\tp.quotePrefix(current) != 0 ||\n\t\t\t\tp.codePrefix(current) != 0 {\n\t\t\t\tp.renderParagraph(data[:i])\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\n\t\t// otherwise, scan to the beginning of the next line\n\t\tnl := bytes.IndexByte(data[i:], '\\n')\n\t\tif nl >= 0 {\n\t\t\ti += nl + 1\n\t\t} else {\n\t\t\ti += len(data[i:])\n\t\t}\n\t}\n\n\tp.renderParagraph(data[:i])\n\treturn i\n}\n\n// skipChar advances i as long as data[i] == c\nfunc skipChar(data []byte, i int, c byte) int {\n\tn := len(data)\n\tfor i < n && data[i] == c {\n\t\ti++\n\t}\n\treturn i\n}\n\n// like skipChar but only skips up to max characters\nfunc skipCharN(data []byte, i int, c byte, max int) int {\n\tn := len(data)\n\tfor i < n && max > 0 && data[i] == c {\n\t\ti++\n\t\tmax--\n\t}\n\treturn i\n}\n\n// skipUntilChar advances i as long as data[i] != c\nfunc skipUntilChar(data []byte, i int, c byte) int {\n\tn := len(data)\n\tfor i < n && data[i] != c {\n\t\ti++\n\t}\n\treturn i\n}\n\nfunc skipAlnum(data []byte, i int) int {\n\tn := len(data)\n\tfor i < n && IsAlnum(data[i]) {\n\t\ti++\n\t}\n\treturn i\n}\n\nfunc skipSpace(data []byte, i int) int {\n\tn := len(data)\n\tfor i < n && IsSpace(data[i]) {\n\t\ti++\n\t}\n\treturn i\n}\n\nfunc backChar(data []byte, i int, c byte) int {\n\tfor i > 0 && data[i-1] == c {\n\t\ti--\n\t}\n\treturn i\n}\n\nfunc backUntilChar(data []byte, i int, c byte) int {\n\tfor i > 0 && data[i-1] != c {\n\t\ti--\n\t}\n\treturn i\n}\n", "package parser\n\nimport (\n\t\"bytes\"\n\n\t\"github.com/gomarkdown/markdown/ast\"\n)\n\n// citation parses a citation. In its most simple form [@ref], we allow multiple\n// being separated by semicolons and a sub reference inside ala pandoc: [@ref, p. 23].\n// Each citation can have a modifier: !, ? or - wich mean:\n//\n// ! - normative\n// ? - formative\n// - - suppressed\n//\n// The suffix starts after a comma, we strip any whitespace before and after. If the output\n// allows for it, this can be rendered.\nfunc citation(p *Parser, data []byte, offset int) (int, ast.Node) {\n\t// look for the matching closing bracket\n\ti := offset + 1\n\tfor level := 1; level > 0 && i < len(data); i++ {\n\t\tswitch {\n\t\tcase data[i] == '\\n':\n\t\t\t// no newlines allowed.\n\t\t\treturn 0, nil\n\n\t\tcase data[i-1] == '\\\\':\n\t\t\tcontinue\n\n\t\tcase data[i] == '[':\n\t\t\tlevel++\n\n\t\tcase data[i] == ']':\n\t\t\tlevel--\n\t\t\tif level <= 0 {\n\t\t\t\ti-- // compensate for extra i++ in for loop\n\t\t\t}\n\t\t}\n\t}\n\n\tif i >= len(data) {\n\t\treturn 0, nil\n\t}\n\n\tnode := &ast.Citation{}\n\n\tcitations := bytes.Split(data[1:i], []byte(\";\"))\n\tfor _, citation := range citations {\n\t\tvar suffix []byte\n\t\tcitation = bytes.TrimSpace(citation)\n\t\tj := 0\n\t\tif citation[j] != '@' {\n\t\t\t// not a citation, drop out entirely.\n\t\t\treturn 0, nil\n\t\t}\n\t\tif c := bytes.Index(citation, []byte(\",\")); c > 0 {\n\t\t\tpart := citation[:c]\n\t\t\tsuff := citation[c+1:]\n\t\t\tpart = bytes.TrimSpace(part)\n\t\t\tsuff = bytes.TrimSpace(suff)\n\n\t\t\tcitation = part\n\t\t\tsuffix = suff\n\t\t}\n\n\t\tciteType := ast.CitationTypeInformative\n\t\tj = 1\n\t\tswitch citation[j] {\n\t\tcase '!':\n\t\t\tciteType = ast.CitationTypeNormative\n\t\t\tj++\n\t\tcase '?':\n\t\t\tciteType = ast.CitationTypeInformative\n\t\t\tj++\n\t\tcase '-':\n\t\t\tciteType = ast.CitationTypeSuppressed\n\t\t\tj++\n\t\t}\n\t\tnode.Destination = append(node.Destination, citation[j:])\n\t\tnode.Type = append(node.Type, citeType)\n\t\tnode.Suffix = append(node.Suffix, suffix)\n\t}\n\n\treturn i + 1, node\n}\n"], "fixing_code": ["package parser\n\nimport (\n\t\"bytes\"\n\t\"html\"\n\t\"regexp\"\n\t\"strconv\"\n\t\"unicode\"\n\n\t\"github.com/gomarkdown/markdown/ast\"\n)\n\n// Parsing block-level elements.\n\nconst (\n\tcharEntity = \"&(?:#x[a-f0-9]{1,8}|#[0-9]{1,8}|[a-z][a-z0-9]{1,31});\"\n\tescapable  = \"[!\\\"#$%&'()*+,./:;<=>?@[\\\\\\\\\\\\]^_`{|}~-]\"\n)\n\nconst (\n\tcaptionTable  = \"Table: \"\n\tcaptionFigure = \"Figure: \"\n\tcaptionQuote  = \"Quote: \"\n)\n\nvar (\n\treBackslashOrAmp      = regexp.MustCompile(`[\\&]`)\n\treEntityOrEscapedChar = regexp.MustCompile(`(?i)\\\\` + escapable + \"|\" + charEntity)\n\n\t// blockTags is a set of tags that are recognized as HTML block tags.\n\t// Any of these can be included in markdown text without special escaping.\n\tblockTags = map[string]struct{}{\n\t\t\"blockquote\": {},\n\t\t\"del\":        {},\n\t\t\"dd\":         {},\n\t\t\"div\":        {},\n\t\t\"dl\":         {},\n\t\t\"dt\":         {},\n\t\t\"fieldset\":   {},\n\t\t\"form\":       {},\n\t\t\"h1\":         {},\n\t\t\"h2\":         {},\n\t\t\"h3\":         {},\n\t\t\"h4\":         {},\n\t\t\"h5\":         {},\n\t\t\"h6\":         {},\n\t\t// TODO: technically block but breaks Inline HTML (Simple).text\n\t\t//\"hr\":         {},\n\t\t\"iframe\":   {},\n\t\t\"ins\":      {},\n\t\t\"li\":       {},\n\t\t\"math\":     {},\n\t\t\"noscript\": {},\n\t\t\"ol\":       {},\n\t\t\"pre\":      {},\n\t\t\"p\":        {},\n\t\t\"script\":   {},\n\t\t\"style\":    {},\n\t\t\"table\":    {},\n\t\t\"ul\":       {},\n\n\t\t// HTML5\n\t\t\"address\":    {},\n\t\t\"article\":    {},\n\t\t\"aside\":      {},\n\t\t\"canvas\":     {},\n\t\t\"details\":    {},\n\t\t\"dialog\":     {},\n\t\t\"figcaption\": {},\n\t\t\"figure\":     {},\n\t\t\"footer\":     {},\n\t\t\"header\":     {},\n\t\t\"hgroup\":     {},\n\t\t\"main\":       {},\n\t\t\"nav\":        {},\n\t\t\"output\":     {},\n\t\t\"progress\":   {},\n\t\t\"section\":    {},\n\t\t\"video\":      {},\n\t}\n)\n\n// sanitizeHeadingID returns a sanitized anchor name for the given text.\n// Taken from https://github.com/shurcooL/sanitized_anchor_name/blob/master/main.go#L14:1\nfunc sanitizeHeadingID(text string) string {\n\tvar anchorName []rune\n\tvar futureDash = false\n\tfor _, r := range text {\n\t\tswitch {\n\t\tcase unicode.IsLetter(r) || unicode.IsNumber(r):\n\t\t\tif futureDash && len(anchorName) > 0 {\n\t\t\t\tanchorName = append(anchorName, '-')\n\t\t\t}\n\t\t\tfutureDash = false\n\t\t\tanchorName = append(anchorName, unicode.ToLower(r))\n\t\tdefault:\n\t\t\tfutureDash = true\n\t\t}\n\t}\n\tif len(anchorName) == 0 {\n\t\treturn \"empty\"\n\t}\n\treturn string(anchorName)\n}\n\n// Parse Block-level data.\n// Note: this function and many that it calls assume that\n// the input buffer ends with a newline.\nfunc (p *Parser) Block(data []byte) {\n\t// this is called recursively: enforce a maximum depth\n\tif p.nesting >= p.maxNesting {\n\t\treturn\n\t}\n\tp.nesting++\n\n\t// parse out one block-level construct at a time\n\tfor len(data) > 0 {\n\t\t// attributes that can be specific before a block element:\n\t\t//\n\t\t// {#id .class1 .class2 key=\"value\"}\n\t\tif p.extensions&Attributes != 0 {\n\t\t\tdata = p.attribute(data)\n\t\t}\n\n\t\tif p.extensions&Includes != 0 {\n\t\t\tf := p.readInclude\n\t\t\tpath, address, consumed := p.isInclude(data)\n\t\t\tif consumed == 0 {\n\t\t\t\tpath, address, consumed = p.isCodeInclude(data)\n\t\t\t\tf = p.readCodeInclude\n\t\t\t}\n\t\t\tif consumed > 0 {\n\t\t\t\tincluded := f(p.includeStack.Last(), path, address)\n\n\t\t\t\t// if we find a caption below this, we need to include it in 'included', so\n\t\t\t\t// that the caption will be part of the include text. (+1 to skip newline)\n\t\t\t\tfor _, caption := range []string{captionFigure, captionTable, captionQuote} {\n\t\t\t\t\tif _, _, capcon := p.caption(data[consumed+1:], []byte(caption)); capcon > 0 {\n\t\t\t\t\t\tincluded = append(included, data[consumed+1:consumed+1+capcon]...)\n\t\t\t\t\t\tconsumed += 1 + capcon\n\t\t\t\t\t\tbreak // there can only be 1 caption.\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tp.includeStack.Push(path)\n\t\t\t\tp.Block(included)\n\t\t\t\tp.includeStack.Pop()\n\t\t\t\tdata = data[consumed:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// user supplied parser function\n\t\tif p.Opts.ParserHook != nil {\n\t\t\tnode, blockdata, consumed := p.Opts.ParserHook(data)\n\t\t\tif consumed > 0 {\n\t\t\t\tdata = data[consumed:]\n\n\t\t\t\tif node != nil {\n\t\t\t\t\tp.AddBlock(node)\n\t\t\t\t\tif blockdata != nil {\n\t\t\t\t\t\tp.Block(blockdata)\n\t\t\t\t\t\tp.Finalize(node)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// prefixed heading:\n\t\t//\n\t\t// # Heading 1\n\t\t// ## Heading 2\n\t\t// ...\n\t\t// ###### Heading 6\n\t\tif p.isPrefixHeading(data) {\n\t\t\tdata = data[p.prefixHeading(data):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// prefixed special heading:\n\t\t// (there are no levels.)\n\t\t//\n\t\t// .# Abstract\n\t\tif p.isPrefixSpecialHeading(data) {\n\t\t\tdata = data[p.prefixSpecialHeading(data):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// block of preformatted HTML:\n\t\t//\n\t\t// <div>\n\t\t//     ...\n\t\t// </div>\n\n\t\tif len(data) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\tif data[0] == '<' {\n\t\t\tif i := p.html(data, true); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// title block\n\t\t//\n\t\t// % stuff\n\t\t// % more stuff\n\t\t// % even more stuff\n\t\tif p.extensions&Titleblock != 0 {\n\t\t\tif data[0] == '%' {\n\t\t\t\tif i := p.titleBlock(data, true); i > 0 {\n\t\t\t\t\tdata = data[i:]\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// blank lines.  note: returns the # of bytes to skip\n\t\tif i := IsEmpty(data); i > 0 {\n\t\t\tdata = data[i:]\n\t\t\tcontinue\n\t\t}\n\n\t\t// indented code block:\n\t\t//\n\t\t//     func max(a, b int) int {\n\t\t//         if a > b {\n\t\t//             return a\n\t\t//         }\n\t\t//         return b\n\t\t//      }\n\t\tif p.codePrefix(data) > 0 {\n\t\t\tdata = data[p.code(data):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// fenced code block:\n\t\t//\n\t\t// ``` go\n\t\t// func fact(n int) int {\n\t\t//     if n <= 1 {\n\t\t//         return n\n\t\t//     }\n\t\t//     return n * fact(n-1)\n\t\t// }\n\t\t// ```\n\t\tif p.extensions&FencedCode != 0 {\n\t\t\tif i := p.fencedCodeBlock(data, true); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// horizontal rule:\n\t\t//\n\t\t// ------\n\t\t// or\n\t\t// ******\n\t\t// or\n\t\t// ______\n\t\tif isHRule(data) {\n\t\t\ti := skipUntilChar(data, 0, '\\n')\n\t\t\thr := ast.HorizontalRule{}\n\t\t\thr.Literal = bytes.Trim(data[:i], \" \\n\")\n\t\t\tp.AddBlock(&hr)\n\t\t\tdata = data[i:]\n\t\t\tcontinue\n\t\t}\n\n\t\t// block quote:\n\t\t//\n\t\t// > A big quote I found somewhere\n\t\t// > on the web\n\t\tif p.quotePrefix(data) > 0 {\n\t\t\tdata = data[p.quote(data):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// aside:\n\t\t//\n\t\t// A> The proof is too large to fit\n\t\t// A> in the margin.\n\t\tif p.extensions&Mmark != 0 {\n\t\t\tif p.asidePrefix(data) > 0 {\n\t\t\t\tdata = data[p.aside(data):]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// figure block:\n\t\t//\n\t\t// !---\n\t\t// ![Alt Text](img.jpg \"This is an image\")\n\t\t// ![Alt Text](img2.jpg \"This is a second image\")\n\t\t// !---\n\t\tif p.extensions&Mmark != 0 {\n\t\t\tif i := p.figureBlock(data, true); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif p.extensions&Tables != 0 {\n\t\t\tif i := p.table(data); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// an itemized/unordered list:\n\t\t//\n\t\t// * Item 1\n\t\t// * Item 2\n\t\t//\n\t\t// also works with + or -\n\t\tif p.uliPrefix(data) > 0 {\n\t\t\tdata = data[p.list(data, 0, 0, '.'):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// a numbered/ordered list:\n\t\t//\n\t\t// 1. Item 1\n\t\t// 2. Item 2\n\t\tif i := p.oliPrefix(data); i > 0 {\n\t\t\tstart := 0\n\t\t\tdelim := byte('.')\n\t\t\tif i > 2 {\n\t\t\t\tif p.extensions&OrderedListStart != 0 {\n\t\t\t\t\ts := string(data[:i-2])\n\t\t\t\t\tstart, _ = strconv.Atoi(s)\n\t\t\t\t\tif start == 1 {\n\t\t\t\t\t\tstart = 0\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tdelim = data[i-2]\n\t\t\t}\n\t\t\tdata = data[p.list(data, ast.ListTypeOrdered, start, delim):]\n\t\t\tcontinue\n\t\t}\n\n\t\t// definition lists:\n\t\t//\n\t\t// Term 1\n\t\t// :   Definition a\n\t\t// :   Definition b\n\t\t//\n\t\t// Term 2\n\t\t// :   Definition c\n\t\tif p.extensions&DefinitionLists != 0 {\n\t\t\tif p.dliPrefix(data) > 0 {\n\t\t\t\tdata = data[p.list(data, ast.ListTypeDefinition, 0, '.'):]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif p.extensions&MathJax != 0 {\n\t\t\tif i := p.blockMath(data); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// document matters:\n\t\t//\n\t\t// {frontmatter}/{mainmatter}/{backmatter}\n\t\tif p.extensions&Mmark != 0 {\n\t\t\tif i := p.documentMatter(data); i > 0 {\n\t\t\t\tdata = data[i:]\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// anything else must look like a normal paragraph\n\t\t// note: this finds underlined headings, too\n\t\tidx := p.paragraph(data)\n\t\tdata = data[idx:]\n\t}\n\n\tp.nesting--\n}\n\nfunc (p *Parser) AddBlock(n ast.Node) ast.Node {\n\tp.closeUnmatchedBlocks()\n\n\tif p.attr != nil {\n\t\tif c := n.AsContainer(); c != nil {\n\t\t\tc.Attribute = p.attr\n\t\t}\n\t\tif l := n.AsLeaf(); l != nil {\n\t\t\tl.Attribute = p.attr\n\t\t}\n\t\tp.attr = nil\n\t}\n\treturn p.addChild(n)\n}\n\nfunc (p *Parser) isPrefixHeading(data []byte) bool {\n\tif len(data) > 0 && data[0] != '#' {\n\t\treturn false\n\t}\n\n\tif p.extensions&SpaceHeadings != 0 {\n\t\tlevel := skipCharN(data, 0, '#', 6)\n\t\tif level == len(data) || data[level] != ' ' {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc (p *Parser) prefixHeading(data []byte) int {\n\tlevel := skipCharN(data, 0, '#', 6)\n\ti := skipChar(data, level, ' ')\n\tend := skipUntilChar(data, i, '\\n')\n\tskip := end\n\tid := \"\"\n\tif p.extensions&HeadingIDs != 0 {\n\t\tj, k := 0, 0\n\t\t// find start/end of heading id\n\t\tfor j = i; j < end-1 && (data[j] != '{' || data[j+1] != '#'); j++ {\n\t\t}\n\t\tfor k = j + 1; k < end && data[k] != '}'; k++ {\n\t\t}\n\t\t// extract heading id iff found\n\t\tif j < end && k < end {\n\t\t\tid = string(data[j+2 : k])\n\t\t\tend = j\n\t\t\tskip = k + 1\n\t\t\tfor end > 0 && data[end-1] == ' ' {\n\t\t\t\tend--\n\t\t\t}\n\t\t}\n\t}\n\tfor end > 0 && data[end-1] == '#' {\n\t\tif isBackslashEscaped(data, end-1) {\n\t\t\tbreak\n\t\t}\n\t\tend--\n\t}\n\tfor end > 0 && data[end-1] == ' ' {\n\t\tend--\n\t}\n\tif end > i {\n\t\tblock := &ast.Heading{\n\t\t\tHeadingID: id,\n\t\t\tLevel:     level,\n\t\t}\n\t\tif id == \"\" && p.extensions&AutoHeadingIDs != 0 {\n\t\t\tblock.HeadingID = sanitizeHeadingID(string(data[i:end]))\n\t\t\tp.allHeadingsWithAutoID = append(p.allHeadingsWithAutoID, block)\n\t\t}\n\t\tblock.Content = data[i:end]\n\t\tp.AddBlock(block)\n\t}\n\treturn skip\n}\n\nfunc (p *Parser) isPrefixSpecialHeading(data []byte) bool {\n\tif p.extensions|Mmark == 0 {\n\t\treturn false\n\t}\n\tif len(data) < 4 {\n\t\treturn false\n\t}\n\tif data[0] != '.' {\n\t\treturn false\n\t}\n\tif data[1] != '#' {\n\t\treturn false\n\t}\n\tif data[2] == '#' { // we don't support level, so nack this.\n\t\treturn false\n\t}\n\n\tif p.extensions&SpaceHeadings != 0 {\n\t\tif data[2] != ' ' {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc (p *Parser) prefixSpecialHeading(data []byte) int {\n\ti := skipChar(data, 2, ' ') // \".#\" skipped\n\tend := skipUntilChar(data, i, '\\n')\n\tskip := end\n\tid := \"\"\n\tif p.extensions&HeadingIDs != 0 {\n\t\tj, k := 0, 0\n\t\t// find start/end of heading id\n\t\tfor j = i; j < end-1 && (data[j] != '{' || data[j+1] != '#'); j++ {\n\t\t}\n\t\tfor k = j + 1; k < end && data[k] != '}'; k++ {\n\t\t}\n\t\t// extract heading id iff found\n\t\tif j < end && k < end {\n\t\t\tid = string(data[j+2 : k])\n\t\t\tend = j\n\t\t\tskip = k + 1\n\t\t\tfor end > 0 && data[end-1] == ' ' {\n\t\t\t\tend--\n\t\t\t}\n\t\t}\n\t}\n\tfor end > 0 && data[end-1] == '#' {\n\t\tif isBackslashEscaped(data, end-1) {\n\t\t\tbreak\n\t\t}\n\t\tend--\n\t}\n\tfor end > 0 && data[end-1] == ' ' {\n\t\tend--\n\t}\n\tif end > i {\n\t\tblock := &ast.Heading{\n\t\t\tHeadingID: id,\n\t\t\tIsSpecial: true,\n\t\t\tLevel:     1, // always level 1.\n\t\t}\n\t\tif id == \"\" && p.extensions&AutoHeadingIDs != 0 {\n\t\t\tblock.HeadingID = sanitizeHeadingID(string(data[i:end]))\n\t\t\tp.allHeadingsWithAutoID = append(p.allHeadingsWithAutoID, block)\n\t\t}\n\t\tblock.Literal = data[i:end]\n\t\tblock.Content = data[i:end]\n\t\tp.AddBlock(block)\n\t}\n\treturn skip\n}\n\nfunc (p *Parser) isUnderlinedHeading(data []byte) int {\n\t// test of level 1 heading\n\tif data[0] == '=' {\n\t\ti := skipChar(data, 1, '=')\n\t\ti = skipChar(data, i, ' ')\n\t\tif i < len(data) && data[i] == '\\n' {\n\t\t\treturn 1\n\t\t}\n\t\treturn 0\n\t}\n\n\t// test of level 2 heading\n\tif data[0] == '-' {\n\t\ti := skipChar(data, 1, '-')\n\t\ti = skipChar(data, i, ' ')\n\t\tif i < len(data) && data[i] == '\\n' {\n\t\t\treturn 2\n\t\t}\n\t\treturn 0\n\t}\n\n\treturn 0\n}\n\nfunc (p *Parser) titleBlock(data []byte, doRender bool) int {\n\tif data[0] != '%' {\n\t\treturn 0\n\t}\n\tsplitData := bytes.Split(data, []byte(\"\\n\"))\n\tvar i int\n\tfor idx, b := range splitData {\n\t\tif !bytes.HasPrefix(b, []byte(\"%\")) {\n\t\t\ti = idx // - 1\n\t\t\tbreak\n\t\t}\n\t}\n\n\tdata = bytes.Join(splitData[0:i], []byte(\"\\n\"))\n\tconsumed := len(data)\n\tdata = bytes.TrimPrefix(data, []byte(\"% \"))\n\tdata = bytes.Replace(data, []byte(\"\\n% \"), []byte(\"\\n\"), -1)\n\tblock := &ast.Heading{\n\t\tLevel:        1,\n\t\tIsTitleblock: true,\n\t}\n\tblock.Content = data\n\tp.AddBlock(block)\n\n\treturn consumed\n}\n\nfunc (p *Parser) html(data []byte, doRender bool) int {\n\tvar i, j int\n\n\t// identify the opening tag\n\tif data[0] != '<' {\n\t\treturn 0\n\t}\n\tcurtag, tagfound := p.htmlFindTag(data[1:])\n\n\t// handle special cases\n\tif !tagfound {\n\t\t// check for an HTML comment\n\t\tif size := p.htmlComment(data, doRender); size > 0 {\n\t\t\treturn size\n\t\t}\n\n\t\t// check for an <hr> tag\n\t\tif size := p.htmlHr(data, doRender); size > 0 {\n\t\t\treturn size\n\t\t}\n\n\t\t// no special case recognized\n\t\treturn 0\n\t}\n\n\t// look for an unindented matching closing tag\n\t// followed by a blank line\n\tfound := false\n\t/*\n\t\tclosetag := []byte(\"\\n</\" + curtag + \">\")\n\t\tj = len(curtag) + 1\n\t\tfor !found {\n\t\t\t// scan for a closing tag at the beginning of a line\n\t\t\tif skip := bytes.Index(data[j:], closetag); skip >= 0 {\n\t\t\t\tj += skip + len(closetag)\n\t\t\t} else {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// see if it is the only thing on the line\n\t\t\tif skip := IsEmpty(data[j:]); skip > 0 {\n\t\t\t\t// see if it is followed by a blank line/eof\n\t\t\t\tj += skip\n\t\t\t\tif j >= len(data) {\n\t\t\t\t\tfound = true\n\t\t\t\t\ti = j\n\t\t\t\t} else {\n\t\t\t\t\tif skip := IsEmpty(data[j:]); skip > 0 {\n\t\t\t\t\t\tj += skip\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\ti = j\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t*/\n\n\t// if not found, try a second pass looking for indented match\n\t// but not if tag is \"ins\" or \"del\" (following original Markdown.pl)\n\tif !found && curtag != \"ins\" && curtag != \"del\" {\n\t\ti = 1\n\t\tfor i < len(data) {\n\t\t\ti++\n\t\t\tfor i < len(data) && !(data[i-1] == '<' && data[i] == '/') {\n\t\t\t\ti++\n\t\t\t}\n\n\t\t\tif i+2+len(curtag) >= len(data) {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tj = p.htmlFindEnd(curtag, data[i-1:])\n\n\t\t\tif j > 0 {\n\t\t\t\ti += j - 1\n\t\t\t\tfound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif !found {\n\t\treturn 0\n\t}\n\n\t// the end of the block has been found\n\tif doRender {\n\t\t// trim newlines\n\t\tend := backChar(data, i, '\\n')\n\t\thtmlBLock := &ast.HTMLBlock{Leaf: ast.Leaf{Content: data[:end]}}\n\t\tp.AddBlock(htmlBLock)\n\t\tfinalizeHTMLBlock(htmlBLock)\n\t}\n\n\treturn i\n}\n\nfunc finalizeHTMLBlock(block *ast.HTMLBlock) {\n\tblock.Literal = block.Content\n\tblock.Content = nil\n}\n\n// HTML comment, lax form\nfunc (p *Parser) htmlComment(data []byte, doRender bool) int {\n\ti := p.inlineHTMLComment(data)\n\t// needs to end with a blank line\n\tif j := IsEmpty(data[i:]); j > 0 {\n\t\tsize := i + j\n\t\tif doRender {\n\t\t\t// trim trailing newlines\n\t\t\tend := backChar(data, size, '\\n')\n\t\t\thtmlBLock := &ast.HTMLBlock{Leaf: ast.Leaf{Content: data[:end]}}\n\t\t\tp.AddBlock(htmlBLock)\n\t\t\tfinalizeHTMLBlock(htmlBLock)\n\t\t}\n\t\treturn size\n\t}\n\treturn 0\n}\n\n// HR, which is the only self-closing block tag considered\nfunc (p *Parser) htmlHr(data []byte, doRender bool) int {\n\tif len(data) < 4 {\n\t\treturn 0\n\t}\n\tif data[0] != '<' || (data[1] != 'h' && data[1] != 'H') || (data[2] != 'r' && data[2] != 'R') {\n\t\treturn 0\n\t}\n\tif data[3] != ' ' && data[3] != '/' && data[3] != '>' {\n\t\t// not an <hr> tag after all; at least not a valid one\n\t\treturn 0\n\t}\n\ti := 3\n\tfor i < len(data) && data[i] != '>' && data[i] != '\\n' {\n\t\ti++\n\t}\n\tif i < len(data) && data[i] == '>' {\n\t\ti++\n\t\tif j := IsEmpty(data[i:]); j > 0 {\n\t\t\tsize := i + j\n\t\t\tif doRender {\n\t\t\t\t// trim newlines\n\t\t\t\tend := backChar(data, size, '\\n')\n\t\t\t\thtmlBlock := &ast.HTMLBlock{Leaf: ast.Leaf{Content: data[:end]}}\n\t\t\t\tp.AddBlock(htmlBlock)\n\t\t\t\tfinalizeHTMLBlock(htmlBlock)\n\t\t\t}\n\t\t\treturn size\n\t\t}\n\t}\n\treturn 0\n}\n\nfunc (p *Parser) htmlFindTag(data []byte) (string, bool) {\n\ti := skipAlnum(data, 0)\n\tkey := string(data[:i])\n\tif _, ok := blockTags[key]; ok {\n\t\treturn key, true\n\t}\n\treturn \"\", false\n}\n\nfunc (p *Parser) htmlFindEnd(tag string, data []byte) int {\n\t// assume data[0] == '<' && data[1] == '/' already tested\n\tif tag == \"hr\" {\n\t\treturn 2\n\t}\n\t// check if tag is a match\n\tclosetag := []byte(\"</\" + tag + \">\")\n\tif !bytes.HasPrefix(data, closetag) {\n\t\treturn 0\n\t}\n\ti := len(closetag)\n\n\t// check that the rest of the line is blank\n\tskip := 0\n\tif skip = IsEmpty(data[i:]); skip == 0 {\n\t\treturn 0\n\t}\n\ti += skip\n\tskip = 0\n\n\tif i >= len(data) {\n\t\treturn i\n\t}\n\n\tif p.extensions&LaxHTMLBlocks != 0 {\n\t\treturn i\n\t}\n\tif skip = IsEmpty(data[i:]); skip == 0 {\n\t\t// following line must be blank\n\t\treturn 0\n\t}\n\n\treturn i + skip\n}\n\nfunc IsEmpty(data []byte) int {\n\t// it is okay to call isEmpty on an empty buffer\n\tif len(data) == 0 {\n\t\treturn 0\n\t}\n\n\tvar i int\n\tfor i = 0; i < len(data) && data[i] != '\\n'; i++ {\n\t\tif data[i] != ' ' && data[i] != '\\t' {\n\t\t\treturn 0\n\t\t}\n\t}\n\ti = skipCharN(data, i, '\\n', 1)\n\treturn i\n}\n\nfunc isHRule(data []byte) bool {\n\ti := 0\n\n\t// skip up to three spaces\n\tfor i < 3 && data[i] == ' ' {\n\t\ti++\n\t}\n\n\t// look at the hrule char\n\tif data[i] != '*' && data[i] != '-' && data[i] != '_' {\n\t\treturn false\n\t}\n\tc := data[i]\n\n\t// the whole line must be the char or whitespace\n\tn := 0\n\tfor i < len(data) && data[i] != '\\n' {\n\t\tswitch {\n\t\tcase data[i] == c:\n\t\t\tn++\n\t\tcase data[i] != ' ':\n\t\t\treturn false\n\t\t}\n\t\ti++\n\t}\n\n\treturn n >= 3\n}\n\n// isFenceLine checks if there's a fence line (e.g., ``` or ``` go) at the beginning of data,\n// and returns the end index if so, or 0 otherwise. It also returns the marker found.\n// If syntax is not nil, it gets set to the syntax specified in the fence line.\nfunc isFenceLine(data []byte, syntax *string, oldmarker string) (end int, marker string) {\n\ti, size := 0, 0\n\n\tn := len(data)\n\t// skip up to three spaces\n\tfor i < n && i < 3 && data[i] == ' ' {\n\t\ti++\n\t}\n\n\t// check for the marker characters: ~ or `\n\tif i >= n {\n\t\treturn 0, \"\"\n\t}\n\tif data[i] != '~' && data[i] != '`' {\n\t\treturn 0, \"\"\n\t}\n\n\tc := data[i]\n\n\t// the whole line must be the same char or whitespace\n\tfor i < n && data[i] == c {\n\t\tsize++\n\t\ti++\n\t}\n\n\t// the marker char must occur at least 3 times\n\tif size < 3 {\n\t\treturn 0, \"\"\n\t}\n\tmarker = string(data[i-size : i])\n\n\t// if this is the end marker, it must match the beginning marker\n\tif oldmarker != \"\" && marker != oldmarker {\n\t\treturn 0, \"\"\n\t}\n\n\t// if just read the beginning marker, read the syntax\n\tif oldmarker == \"\" {\n\t\ti = skipChar(data, i, ' ')\n\t\tif i >= n {\n\t\t\tif i == n {\n\t\t\t\treturn i, marker\n\t\t\t}\n\t\t\treturn 0, \"\"\n\t\t}\n\n\t\tsyntaxStart, syntaxLen := syntaxRange(data, &i)\n\t\tif syntaxStart == 0 && syntaxLen == 0 {\n\t\t\treturn 0, \"\"\n\t\t}\n\n\t\t// caller wants the syntax\n\t\tif syntax != nil {\n\t\t\t*syntax = string(data[syntaxStart : syntaxStart+syntaxLen])\n\t\t}\n\t}\n\n\ti = skipChar(data, i, ' ')\n\tif i >= n || data[i] != '\\n' {\n\t\tif i == n {\n\t\t\treturn i, marker\n\t\t}\n\t\treturn 0, \"\"\n\t}\n\treturn i + 1, marker // Take newline into account.\n}\n\nfunc syntaxRange(data []byte, iout *int) (int, int) {\n\tn := len(data)\n\tsyn := 0\n\ti := *iout\n\tsyntaxStart := i\n\tif data[i] == '{' {\n\t\ti++\n\t\tsyntaxStart++\n\n\t\tfor i < n && data[i] != '}' && data[i] != '\\n' {\n\t\t\tsyn++\n\t\t\ti++\n\t\t}\n\n\t\tif i >= n || data[i] != '}' {\n\t\t\treturn 0, 0\n\t\t}\n\n\t\t// strip all whitespace at the beginning and the end\n\t\t// of the {} block\n\t\tfor syn > 0 && IsSpace(data[syntaxStart]) {\n\t\t\tsyntaxStart++\n\t\t\tsyn--\n\t\t}\n\n\t\tfor syn > 0 && IsSpace(data[syntaxStart+syn-1]) {\n\t\t\tsyn--\n\t\t}\n\n\t\ti++\n\t} else {\n\t\tfor i < n && !IsSpace(data[i]) {\n\t\t\tsyn++\n\t\t\ti++\n\t\t}\n\t}\n\n\t*iout = i\n\treturn syntaxStart, syn\n}\n\n// fencedCodeBlock returns the end index if data contains a fenced code block at the beginning,\n// or 0 otherwise. It writes to out if doRender is true, otherwise it has no side effects.\n// If doRender is true, a final newline is mandatory to recognize the fenced code block.\nfunc (p *Parser) fencedCodeBlock(data []byte, doRender bool) int {\n\tvar syntax string\n\tbeg, marker := isFenceLine(data, &syntax, \"\")\n\tif beg == 0 || beg >= len(data) {\n\t\treturn 0\n\t}\n\n\tvar work bytes.Buffer\n\twork.WriteString(syntax)\n\twork.WriteByte('\\n')\n\n\tfor {\n\t\t// safe to assume beg < len(data)\n\n\t\t// check for the end of the code block\n\t\tfenceEnd, _ := isFenceLine(data[beg:], nil, marker)\n\t\tif fenceEnd != 0 {\n\t\t\tbeg += fenceEnd\n\t\t\tbreak\n\t\t}\n\n\t\t// copy the current line\n\t\tend := skipUntilChar(data, beg, '\\n') + 1\n\n\t\t// did we reach the end of the buffer without a closing marker?\n\t\tif end >= len(data) {\n\t\t\treturn 0\n\t\t}\n\n\t\t// verbatim copy to the working buffer\n\t\tif doRender {\n\t\t\twork.Write(data[beg:end])\n\t\t}\n\t\tbeg = end\n\t}\n\n\tif doRender {\n\t\tcodeBlock := &ast.CodeBlock{\n\t\t\tIsFenced: true,\n\t\t}\n\t\tcodeBlock.Content = work.Bytes() // TODO: get rid of temp buffer\n\n\t\tif p.extensions&Mmark == 0 {\n\t\t\tp.AddBlock(codeBlock)\n\t\t\tfinalizeCodeBlock(codeBlock)\n\t\t\treturn beg\n\t\t}\n\n\t\t// Check for caption and if found make it a figure.\n\t\tif captionContent, id, consumed := p.caption(data[beg:], []byte(captionFigure)); consumed > 0 {\n\t\t\tfigure := &ast.CaptionFigure{}\n\t\t\tcaption := &ast.Caption{}\n\t\t\tfigure.HeadingID = id\n\t\t\tp.Inline(caption, captionContent)\n\n\t\t\tp.AddBlock(figure)\n\t\t\tcodeBlock.AsLeaf().Attribute = figure.AsContainer().Attribute\n\t\t\tp.addChild(codeBlock)\n\t\t\tfinalizeCodeBlock(codeBlock)\n\t\t\tp.addChild(caption)\n\t\t\tp.Finalize(figure)\n\n\t\t\tbeg += consumed\n\n\t\t\treturn beg\n\t\t}\n\n\t\t// Still here, normal block\n\t\tp.AddBlock(codeBlock)\n\t\tfinalizeCodeBlock(codeBlock)\n\t}\n\n\treturn beg\n}\n\nfunc unescapeChar(str []byte) []byte {\n\tif str[0] == '\\\\' {\n\t\treturn []byte{str[1]}\n\t}\n\treturn []byte(html.UnescapeString(string(str)))\n}\n\nfunc unescapeString(str []byte) []byte {\n\tif reBackslashOrAmp.Match(str) {\n\t\treturn reEntityOrEscapedChar.ReplaceAllFunc(str, unescapeChar)\n\t}\n\treturn str\n}\n\nfunc finalizeCodeBlock(code *ast.CodeBlock) {\n\tc := code.Content\n\tif code.IsFenced {\n\t\tnewlinePos := bytes.IndexByte(c, '\\n')\n\t\tfirstLine := c[:newlinePos]\n\t\trest := c[newlinePos+1:]\n\t\tcode.Info = unescapeString(bytes.Trim(firstLine, \"\\n\"))\n\t\tcode.Literal = rest\n\t} else {\n\t\tcode.Literal = c\n\t}\n\tcode.Content = nil\n}\n\n// returns blockquote prefix length\nfunc (p *Parser) quotePrefix(data []byte) int {\n\ti := 0\n\tn := len(data)\n\tfor i < 3 && i < n && data[i] == ' ' {\n\t\ti++\n\t}\n\tif i < n && data[i] == '>' {\n\t\tif i+1 < n && data[i+1] == ' ' {\n\t\t\treturn i + 2\n\t\t}\n\t\treturn i + 1\n\t}\n\treturn 0\n}\n\n// blockquote ends with at least one blank line\n// followed by something without a blockquote prefix\nfunc (p *Parser) terminateBlockquote(data []byte, beg, end int) bool {\n\tif IsEmpty(data[beg:]) <= 0 {\n\t\treturn false\n\t}\n\tif end >= len(data) {\n\t\treturn true\n\t}\n\treturn p.quotePrefix(data[end:]) == 0 && IsEmpty(data[end:]) == 0\n}\n\n// parse a blockquote fragment\nfunc (p *Parser) quote(data []byte) int {\n\tvar raw bytes.Buffer\n\tbeg, end := 0, 0\n\tfor beg < len(data) {\n\t\tend = beg\n\t\t// Step over whole lines, collecting them. While doing that, check for\n\t\t// fenced code and if one's found, incorporate it altogether,\n\t\t// irregardless of any contents inside it\n\t\tfor end < len(data) && data[end] != '\\n' {\n\t\t\tif p.extensions&FencedCode != 0 {\n\t\t\t\tif i := p.fencedCodeBlock(data[end:], false); i > 0 {\n\t\t\t\t\t// -1 to compensate for the extra end++ after the loop:\n\t\t\t\t\tend += i - 1\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tend++\n\t\t}\n\t\tend = skipCharN(data, end, '\\n', 1)\n\t\tif pre := p.quotePrefix(data[beg:]); pre > 0 {\n\t\t\t// skip the prefix\n\t\t\tbeg += pre\n\t\t} else if p.terminateBlockquote(data, beg, end) {\n\t\t\tbreak\n\t\t}\n\t\t// this line is part of the blockquote\n\t\traw.Write(data[beg:end])\n\t\tbeg = end\n\t}\n\n\tif p.extensions&Mmark == 0 {\n\t\tblock := p.AddBlock(&ast.BlockQuote{})\n\t\tp.Block(raw.Bytes())\n\t\tp.Finalize(block)\n\t\treturn end\n\t}\n\n\tif captionContent, id, consumed := p.caption(data[end:], []byte(captionQuote)); consumed > 0 {\n\t\tfigure := &ast.CaptionFigure{}\n\t\tcaption := &ast.Caption{}\n\t\tfigure.HeadingID = id\n\t\tp.Inline(caption, captionContent)\n\n\t\tp.AddBlock(figure) // this discard any attributes\n\t\tblock := &ast.BlockQuote{}\n\t\tblock.AsContainer().Attribute = figure.AsContainer().Attribute\n\t\tp.addChild(block)\n\t\tp.Block(raw.Bytes())\n\t\tp.Finalize(block)\n\n\t\tp.addChild(caption)\n\t\tp.Finalize(figure)\n\n\t\tend += consumed\n\n\t\treturn end\n\t}\n\n\tblock := p.AddBlock(&ast.BlockQuote{})\n\tp.Block(raw.Bytes())\n\tp.Finalize(block)\n\n\treturn end\n}\n\n// returns prefix length for block code\nfunc (p *Parser) codePrefix(data []byte) int {\n\tn := len(data)\n\tif n >= 1 && data[0] == '\\t' {\n\t\treturn 1\n\t}\n\tif n >= 4 && data[3] == ' ' && data[2] == ' ' && data[1] == ' ' && data[0] == ' ' {\n\t\treturn 4\n\t}\n\treturn 0\n}\n\nfunc (p *Parser) code(data []byte) int {\n\tvar work bytes.Buffer\n\n\ti := 0\n\tfor i < len(data) {\n\t\tbeg := i\n\n\t\ti = skipUntilChar(data, i, '\\n')\n\t\ti = skipCharN(data, i, '\\n', 1)\n\n\t\tblankline := IsEmpty(data[beg:i]) > 0\n\t\tif pre := p.codePrefix(data[beg:i]); pre > 0 {\n\t\t\tbeg += pre\n\t\t} else if !blankline {\n\t\t\t// non-empty, non-prefixed line breaks the pre\n\t\t\ti = beg\n\t\t\tbreak\n\t\t}\n\n\t\t// verbatim copy to the working buffer\n\t\tif blankline {\n\t\t\twork.WriteByte('\\n')\n\t\t} else {\n\t\t\twork.Write(data[beg:i])\n\t\t}\n\t}\n\n\t// trim all the \\n off the end of work\n\tworkbytes := work.Bytes()\n\n\teol := backChar(workbytes, len(workbytes), '\\n')\n\n\tif eol != len(workbytes) {\n\t\twork.Truncate(eol)\n\t}\n\n\twork.WriteByte('\\n')\n\n\tcodeBlock := &ast.CodeBlock{\n\t\tIsFenced: false,\n\t}\n\t// TODO: get rid of temp buffer\n\tcodeBlock.Content = work.Bytes()\n\tp.AddBlock(codeBlock)\n\tfinalizeCodeBlock(codeBlock)\n\n\treturn i\n}\n\n// returns unordered list item prefix\nfunc (p *Parser) uliPrefix(data []byte) int {\n\t// start with up to 3 spaces\n\ti := skipCharN(data, 0, ' ', 3)\n\n\tif i >= len(data)-1 {\n\t\treturn 0\n\t}\n\t// need one of {'*', '+', '-'} followed by a space or a tab\n\tif (data[i] != '*' && data[i] != '+' && data[i] != '-') ||\n\t\t(data[i+1] != ' ' && data[i+1] != '\\t') {\n\t\treturn 0\n\t}\n\treturn i + 2\n}\n\n// returns ordered list item prefix\nfunc (p *Parser) oliPrefix(data []byte) int {\n\t// start with up to 3 spaces\n\ti := skipCharN(data, 0, ' ', 3)\n\n\t// count the digits\n\tstart := i\n\tfor i < len(data) && data[i] >= '0' && data[i] <= '9' {\n\t\ti++\n\t}\n\tif start == i || i >= len(data)-1 {\n\t\treturn 0\n\t}\n\n\t// we need >= 1 digits followed by a dot and a space or a tab\n\tif data[i] != '.' && data[i] != ')' || !(data[i+1] == ' ' || data[i+1] == '\\t') {\n\t\treturn 0\n\t}\n\treturn i + 2\n}\n\n// returns definition list item prefix\nfunc (p *Parser) dliPrefix(data []byte) int {\n\tif len(data) < 2 {\n\t\treturn 0\n\t}\n\t// need a ':' followed by a space or a tab\n\tif data[0] != ':' || !(data[1] == ' ' || data[1] == '\\t') {\n\t\treturn 0\n\t}\n\t// TODO: this is a no-op (data[0] is ':' so not ' ').\n\t// Maybe the intent was to eat spaces before ':' ?\n\t// either way, no change in tests\n\ti := skipChar(data, 0, ' ')\n\treturn i + 2\n}\n\n// TODO: maybe it was meant to be like below\n// either way, no change in tests\n/*\nfunc (p *Parser) dliPrefix(data []byte) int {\n\ti := skipChar(data, 0, ' ')\n\tif i+len(data) < 2 {\n\t\treturn 0\n\t}\n\t// need a ':' followed by a space or a tab\n\tif data[i] != ':' || !(data[i+1] == ' ' || data[i+1] == '\\t') {\n\t\treturn 0\n\t}\n\treturn i + 2\n}\n*/\n\n// parse ordered or unordered list block\nfunc (p *Parser) list(data []byte, flags ast.ListType, start int, delim byte) int {\n\ti := 0\n\tflags |= ast.ListItemBeginningOfList\n\tlist := &ast.List{\n\t\tListFlags: flags,\n\t\tTight:     true,\n\t\tStart:     start,\n\t\tDelimiter: delim,\n\t}\n\tblock := p.AddBlock(list)\n\n\tfor i < len(data) {\n\t\tskip := p.listItem(data[i:], &flags)\n\t\tif flags&ast.ListItemContainsBlock != 0 {\n\t\t\tlist.Tight = false\n\t\t}\n\t\ti += skip\n\t\tif skip == 0 || flags&ast.ListItemEndOfList != 0 {\n\t\t\tbreak\n\t\t}\n\t\tflags &= ^ast.ListItemBeginningOfList\n\t}\n\n\tabove := block.GetParent()\n\tfinalizeList(list)\n\tp.tip = above\n\treturn i\n}\n\n// Returns true if the list item is not the same type as its parent list\nfunc (p *Parser) listTypeChanged(data []byte, flags *ast.ListType) bool {\n\tif p.dliPrefix(data) > 0 && *flags&ast.ListTypeDefinition == 0 {\n\t\treturn true\n\t} else if p.oliPrefix(data) > 0 && *flags&ast.ListTypeOrdered == 0 {\n\t\treturn true\n\t} else if p.uliPrefix(data) > 0 && (*flags&ast.ListTypeOrdered != 0 || *flags&ast.ListTypeDefinition != 0) {\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Returns true if block ends with a blank line, descending if needed\n// into lists and sublists.\nfunc endsWithBlankLine(block ast.Node) bool {\n\t// TODO: figure this out. Always false now.\n\tfor block != nil {\n\t\t//if block.lastLineBlank {\n\t\t//return true\n\t\t//}\n\t\tswitch block.(type) {\n\t\tcase *ast.List, *ast.ListItem:\n\t\t\tblock = ast.GetLastChild(block)\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\treturn false\n}\n\nfunc finalizeList(list *ast.List) {\n\titems := list.Parent.GetChildren()\n\tlastItemIdx := len(items) - 1\n\tfor i, item := range items {\n\t\tisLastItem := i == lastItemIdx\n\t\t// check for non-final list item ending with blank line:\n\t\tif !isLastItem && endsWithBlankLine(item) {\n\t\t\tlist.Tight = false\n\t\t\tbreak\n\t\t}\n\t\t// recurse into children of list item, to see if there are spaces\n\t\t// between any of them:\n\t\tsubItems := item.GetParent().GetChildren()\n\t\tlastSubItemIdx := len(subItems) - 1\n\t\tfor j, subItem := range subItems {\n\t\t\tisLastSubItem := j == lastSubItemIdx\n\t\t\tif (!isLastItem || !isLastSubItem) && endsWithBlankLine(subItem) {\n\t\t\t\tlist.Tight = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n}\n\n// Parse a single list item.\n// Assumes initial prefix is already removed if this is a sublist.\nfunc (p *Parser) listItem(data []byte, flags *ast.ListType) int {\n\t// keep track of the indentation of the first line\n\titemIndent := 0\n\tif data[0] == '\\t' {\n\t\titemIndent += 4\n\t} else {\n\t\tfor itemIndent < 3 && data[itemIndent] == ' ' {\n\t\t\titemIndent++\n\t\t}\n\t}\n\n\tvar (\n\t\tbulletChar byte = '*'\n\t\tdelimiter  byte = '.'\n\t)\n\ti := p.uliPrefix(data)\n\tif i == 0 {\n\t\ti = p.oliPrefix(data)\n\t\tif i > 0 {\n\t\t\tdelimiter = data[i-2]\n\t\t}\n\t} else {\n\t\tbulletChar = data[i-2]\n\t}\n\tif i == 0 {\n\t\ti = p.dliPrefix(data)\n\t\t// reset definition term flag\n\t\tif i > 0 {\n\t\t\t*flags &= ^ast.ListTypeTerm\n\t\t}\n\t}\n\tif i == 0 {\n\t\t// if in definition list, set term flag and continue\n\t\tif *flags&ast.ListTypeDefinition != 0 {\n\t\t\t*flags |= ast.ListTypeTerm\n\t\t} else {\n\t\t\treturn 0\n\t\t}\n\t}\n\n\t// skip leading whitespace on first line\n\ti = skipChar(data, i, ' ')\n\n\t// find the end of the line\n\tline := i\n\tfor i > 0 && i < len(data) && data[i-1] != '\\n' {\n\t\ti++\n\t}\n\n\t// get working buffer\n\tvar raw bytes.Buffer\n\n\t// put the first line into the working buffer\n\traw.Write(data[line:i])\n\tline = i\n\n\t// process the following lines\n\tcontainsBlankLine := false\n\tsublist := 0\n\ngatherlines:\n\tfor line < len(data) {\n\t\ti++\n\n\t\t// find the end of this line\n\t\tfor i < len(data) && data[i-1] != '\\n' {\n\t\t\ti++\n\t\t}\n\n\t\t// if it is an empty line, guess that it is part of this item\n\t\t// and move on to the next line\n\t\tif IsEmpty(data[line:i]) > 0 {\n\t\t\tcontainsBlankLine = true\n\t\t\tline = i\n\t\t\tcontinue\n\t\t}\n\n\t\t// calculate the indentation\n\t\tindent := 0\n\t\tindentIndex := 0\n\t\tif data[line] == '\\t' {\n\t\t\tindentIndex++\n\t\t\tindent += 4\n\t\t} else {\n\t\t\tfor indent < 4 && line+indent < i && data[line+indent] == ' ' {\n\t\t\t\tindent++\n\t\t\t\tindentIndex++\n\t\t\t}\n\t\t}\n\n\t\tchunk := data[line+indentIndex : i]\n\n\t\t// If there is a fence line (marking starting of a code block)\n\t\t// without indent do not process it as part of the list.\n\t\tif p.extensions&FencedCode != 0 {\n\t\t\tfenceLineEnd, _ := isFenceLine(chunk, nil, \"\")\n\t\t\tif fenceLineEnd > 0 && indent == 0 {\n\t\t\t\t*flags |= ast.ListItemEndOfList\n\t\t\t\tbreak gatherlines\n\t\t\t}\n\t\t}\n\n\t\t// evaluate how this line fits in\n\t\tswitch {\n\t\t// is this a nested list item?\n\t\tcase (p.uliPrefix(chunk) > 0 && !isHRule(chunk)) || p.oliPrefix(chunk) > 0 || p.dliPrefix(chunk) > 0:\n\n\t\t\t// if indent is 4 or more spaces on unordered or ordered lists\n\t\t\t// we need to add leadingWhiteSpaces + 1 spaces in the beginning of the chunk\n\t\t\tif indentIndex >= 4 && p.dliPrefix(chunk) <= 0 {\n\t\t\t\tleadingWhiteSpaces := skipChar(chunk, 0, ' ')\n\t\t\t\tchunk = data[line+indentIndex-(leadingWhiteSpaces+1) : i]\n\t\t\t}\n\n\t\t\t// to be a nested list, it must be indented more\n\t\t\t// if not, it is either a different kind of list\n\t\t\t// or the next item in the same list\n\t\t\tif indent <= itemIndent {\n\t\t\t\tif p.listTypeChanged(chunk, flags) {\n\t\t\t\t\t*flags |= ast.ListItemEndOfList\n\t\t\t\t} else if containsBlankLine {\n\t\t\t\t\t*flags |= ast.ListItemContainsBlock\n\t\t\t\t}\n\n\t\t\t\tbreak gatherlines\n\t\t\t}\n\n\t\t\tif containsBlankLine {\n\t\t\t\t*flags |= ast.ListItemContainsBlock\n\t\t\t}\n\n\t\t\t// is this the first item in the nested list?\n\t\t\tif sublist == 0 {\n\t\t\t\tsublist = raw.Len()\n\t\t\t\t// in the case of dliPrefix we are too late and need to search back for the definition item, which\n\t\t\t\t// should be on the previous line, we then adjust sublist to start there.\n\t\t\t\tif p.dliPrefix(chunk) > 0 {\n\t\t\t\t\tsublist = backUntilChar(raw.Bytes(), raw.Len()-1, '\\n')\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// is this a nested prefix heading?\n\t\tcase p.isPrefixHeading(chunk), p.isPrefixSpecialHeading(chunk):\n\t\t\t// if the heading is not indented, it is not nested in the list\n\t\t\t// and thus ends the list\n\t\t\tif containsBlankLine && indent < 4 {\n\t\t\t\t*flags |= ast.ListItemEndOfList\n\t\t\t\tbreak gatherlines\n\t\t\t}\n\t\t\t*flags |= ast.ListItemContainsBlock\n\n\t\t// anything following an empty line is only part\n\t\t// of this item if it is indented 4 spaces\n\t\t// (regardless of the indentation of the beginning of the item)\n\t\tcase containsBlankLine && indent < 4:\n\t\t\tif *flags&ast.ListTypeDefinition != 0 && i < len(data)-1 {\n\t\t\t\t// is the next item still a part of this list?\n\t\t\t\tnext := skipUntilChar(data, i, '\\n')\n\t\t\t\tfor next < len(data)-1 && data[next] == '\\n' {\n\t\t\t\t\tnext++\n\t\t\t\t}\n\t\t\t\tif i < len(data)-1 && data[i] != ':' && next < len(data)-1 && data[next] != ':' {\n\t\t\t\t\t*flags |= ast.ListItemEndOfList\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t*flags |= ast.ListItemEndOfList\n\t\t\t}\n\t\t\tbreak gatherlines\n\n\t\t// a blank line means this should be parsed as a block\n\t\tcase containsBlankLine:\n\t\t\traw.WriteByte('\\n')\n\t\t\t*flags |= ast.ListItemContainsBlock\n\t\t}\n\n\t\t// if this line was preceded by one or more blanks,\n\t\t// re-introduce the blank into the buffer\n\t\tif containsBlankLine {\n\t\t\tcontainsBlankLine = false\n\t\t\traw.WriteByte('\\n')\n\t\t}\n\n\t\t// add the line into the working buffer without prefix\n\t\traw.Write(chunk)\n\n\t\tline = i\n\t}\n\n\trawBytes := raw.Bytes()\n\n\tlistItem := &ast.ListItem{\n\t\tListFlags:  *flags,\n\t\tTight:      false,\n\t\tBulletChar: bulletChar,\n\t\tDelimiter:  delimiter,\n\t}\n\tp.AddBlock(listItem)\n\n\t// render the contents of the list item\n\tif *flags&ast.ListItemContainsBlock != 0 && *flags&ast.ListTypeTerm == 0 {\n\t\t// intermediate render of block item, except for definition term\n\t\tif sublist > 0 {\n\t\t\tp.Block(rawBytes[:sublist])\n\t\t\tp.Block(rawBytes[sublist:])\n\t\t} else {\n\t\t\tp.Block(rawBytes)\n\t\t}\n\t} else {\n\t\t// intermediate render of inline item\n\t\tpara := &ast.Paragraph{}\n\t\tif sublist > 0 {\n\t\t\tpara.Content = rawBytes[:sublist]\n\t\t} else {\n\t\t\tpara.Content = rawBytes\n\t\t}\n\t\tp.addChild(para)\n\t\tif sublist > 0 {\n\t\t\tp.Block(rawBytes[sublist:])\n\t\t}\n\t}\n\treturn line\n}\n\n// render a single paragraph that has already been parsed out\nfunc (p *Parser) renderParagraph(data []byte) {\n\tif len(data) == 0 {\n\t\treturn\n\t}\n\n\t// trim leading spaces\n\tbeg := skipChar(data, 0, ' ')\n\n\tend := len(data)\n\t// trim trailing newline\n\tif data[len(data)-1] == '\\n' {\n\t\tend--\n\t}\n\n\t// trim trailing spaces\n\tfor end > beg && data[end-1] == ' ' {\n\t\tend--\n\t}\n\tpara := &ast.Paragraph{}\n\tpara.Content = data[beg:end]\n\tp.AddBlock(para)\n}\n\n// blockMath handle block surround with $$\nfunc (p *Parser) blockMath(data []byte) int {\n\tif len(data) <= 4 || data[0] != '$' || data[1] != '$' || data[2] == '$' {\n\t\treturn 0\n\t}\n\n\t// find next $$\n\tvar end int\n\tfor end = 2; end+1 < len(data) && (data[end] != '$' || data[end+1] != '$'); end++ {\n\t}\n\n\t// $$ not match\n\tif end+1 == len(data) {\n\t\treturn 0\n\t}\n\n\t// render the display math\n\tmathBlock := &ast.MathBlock{}\n\tmathBlock.Literal = data[2:end]\n\tp.AddBlock(mathBlock)\n\n\treturn end + 2\n}\n\nfunc (p *Parser) paragraph(data []byte) int {\n\t// prev: index of 1st char of previous line\n\t// line: index of 1st char of current line\n\t// i: index of cursor/end of current line\n\tvar prev, line, i int\n\ttabSize := tabSizeDefault\n\tif p.extensions&TabSizeEight != 0 {\n\t\ttabSize = tabSizeDouble\n\t}\n\t// keep going until we find something to mark the end of the paragraph\n\tfor i < len(data) {\n\t\t// mark the beginning of the current line\n\t\tprev = line\n\t\tcurrent := data[i:]\n\t\tline = i\n\n\t\t// did we find a reference or a footnote? If so, end a paragraph\n\t\t// preceding it and report that we have consumed up to the end of that\n\t\t// reference:\n\t\tif refEnd := isReference(p, current, tabSize); refEnd > 0 {\n\t\t\tp.renderParagraph(data[:i])\n\t\t\treturn i + refEnd\n\t\t}\n\n\t\t// did we find a blank line marking the end of the paragraph?\n\t\tif n := IsEmpty(current); n > 0 {\n\t\t\t// did this blank line followed by a definition list item?\n\t\t\tif p.extensions&DefinitionLists != 0 {\n\t\t\t\tif i < len(data)-1 && data[i+1] == ':' {\n\t\t\t\t\tlistLen := p.list(data[prev:], ast.ListTypeDefinition, 0, '.')\n\t\t\t\t\treturn prev + listLen\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tp.renderParagraph(data[:i])\n\t\t\treturn i + n\n\t\t}\n\n\t\t// an underline under some text marks a heading, so our paragraph ended on prev line\n\t\tif i > 0 {\n\t\t\tif level := p.isUnderlinedHeading(current); level > 0 {\n\t\t\t\t// render the paragraph\n\t\t\t\tp.renderParagraph(data[:prev])\n\n\t\t\t\t// ignore leading and trailing whitespace\n\t\t\t\teol := i - 1\n\t\t\t\tfor prev < eol && data[prev] == ' ' {\n\t\t\t\t\tprev++\n\t\t\t\t}\n\t\t\t\tfor eol > prev && data[eol-1] == ' ' {\n\t\t\t\t\teol--\n\t\t\t\t}\n\n\t\t\t\tblock := &ast.Heading{\n\t\t\t\t\tLevel: level,\n\t\t\t\t}\n\t\t\t\tif p.extensions&AutoHeadingIDs != 0 {\n\t\t\t\t\tblock.HeadingID = sanitizeHeadingID(string(data[prev:eol]))\n\t\t\t\t\tp.allHeadingsWithAutoID = append(p.allHeadingsWithAutoID, block)\n\t\t\t\t}\n\n\t\t\t\tblock.Content = data[prev:eol]\n\t\t\t\tp.AddBlock(block)\n\n\t\t\t\t// find the end of the underline\n\t\t\t\treturn skipUntilChar(data, i, '\\n')\n\t\t\t}\n\t\t}\n\n\t\t// if the next line starts a block of HTML, then the paragraph ends here\n\t\tif p.extensions&LaxHTMLBlocks != 0 {\n\t\t\tif data[i] == '<' && p.html(current, false) > 0 {\n\t\t\t\t// rewind to before the HTML block\n\t\t\t\tp.renderParagraph(data[:i])\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\n\t\t// if there's a prefixed heading or a horizontal rule after this, paragraph is over\n\t\tif p.isPrefixHeading(current) || p.isPrefixSpecialHeading(current) || isHRule(current) {\n\t\t\tp.renderParagraph(data[:i])\n\t\t\treturn i\n\t\t}\n\n\t\t// if there's a block quote, paragraph is over\n\t\tif p.quotePrefix(current) > 0 {\n\t\t\tp.renderParagraph(data[:i])\n\t\t\treturn i\n\t\t}\n\n\t\t// if there's a fenced code block, paragraph is over\n\t\tif p.extensions&FencedCode != 0 {\n\t\t\tif p.fencedCodeBlock(current, false) > 0 {\n\t\t\t\tp.renderParagraph(data[:i])\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\n\t\t// if there's a figure block, paragraph is over\n\t\tif p.extensions&Mmark != 0 {\n\t\t\tif p.figureBlock(current, false) > 0 {\n\t\t\t\tp.renderParagraph(data[:i])\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\n\t\t// if there's a table, paragraph is over\n\t\tif p.extensions&Tables != 0 {\n\t\t\tif j, _, _ := p.tableHeader(current, false); j > 0 {\n\t\t\t\tp.renderParagraph(data[:i])\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\n\t\t// if there's a definition list item, prev line is a definition term\n\t\tif p.extensions&DefinitionLists != 0 {\n\t\t\tif p.dliPrefix(current) != 0 {\n\t\t\t\tret := p.list(data[prev:], ast.ListTypeDefinition, 0, '.')\n\t\t\t\treturn ret + prev\n\t\t\t}\n\t\t}\n\n\t\t// if there's a list after this, paragraph is over\n\t\tif p.extensions&NoEmptyLineBeforeBlock != 0 {\n\t\t\tif p.uliPrefix(current) != 0 ||\n\t\t\t\tp.oliPrefix(current) != 0 ||\n\t\t\t\tp.quotePrefix(current) != 0 ||\n\t\t\t\tp.codePrefix(current) != 0 {\n\t\t\t\tp.renderParagraph(data[:i])\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\n\t\t// otherwise, scan to the beginning of the next line\n\t\tnl := bytes.IndexByte(data[i:], '\\n')\n\t\tif nl >= 0 {\n\t\t\ti += nl + 1\n\t\t} else {\n\t\t\ti += len(data[i:])\n\t\t}\n\t}\n\n\tp.renderParagraph(data[:i])\n\treturn i\n}\n\n// skipChar advances i as long as data[i] == c\nfunc skipChar(data []byte, i int, c byte) int {\n\tn := len(data)\n\tfor i < n && data[i] == c {\n\t\ti++\n\t}\n\treturn i\n}\n\n// like skipChar but only skips up to max characters\nfunc skipCharN(data []byte, i int, c byte, max int) int {\n\tn := len(data)\n\tfor i < n && max > 0 && data[i] == c {\n\t\ti++\n\t\tmax--\n\t}\n\treturn i\n}\n\n// skipUntilChar advances i as long as data[i] != c\nfunc skipUntilChar(data []byte, i int, c byte) int {\n\tn := len(data)\n\tfor i < n && data[i] != c {\n\t\ti++\n\t}\n\treturn i\n}\n\nfunc skipAlnum(data []byte, i int) int {\n\tn := len(data)\n\tfor i < n && IsAlnum(data[i]) {\n\t\ti++\n\t}\n\treturn i\n}\n\nfunc skipSpace(data []byte, i int) int {\n\tn := len(data)\n\tfor i < n && IsSpace(data[i]) {\n\t\ti++\n\t}\n\treturn i\n}\n\nfunc backChar(data []byte, i int, c byte) int {\n\tfor i > 0 && data[i-1] == c {\n\t\ti--\n\t}\n\treturn i\n}\n\nfunc backUntilChar(data []byte, i int, c byte) int {\n\tfor i > 0 && data[i-1] != c {\n\t\ti--\n\t}\n\treturn i\n}\n", "package parser\n\nimport (\n\t\"bytes\"\n\n\t\"github.com/gomarkdown/markdown/ast\"\n)\n\n// citation parses a citation. In its most simple form [@ref], we allow multiple\n// being separated by semicolons and a sub reference inside ala pandoc: [@ref, p. 23].\n// Each citation can have a modifier: !, ? or - wich mean:\n//\n// ! - normative\n// ? - formative\n// - - suppressed\n//\n// The suffix starts after a comma, we strip any whitespace before and after. If the output\n// allows for it, this can be rendered.\nfunc citation(p *Parser, data []byte, offset int) (int, ast.Node) {\n\t// look for the matching closing bracket\n\ti := offset + 1\n\tfor level := 1; level > 0 && i < len(data); i++ {\n\t\tswitch {\n\t\tcase data[i] == '\\n':\n\t\t\t// no newlines allowed.\n\t\t\treturn 0, nil\n\n\t\tcase data[i-1] == '\\\\':\n\t\t\tcontinue\n\n\t\tcase data[i] == '[':\n\t\t\tlevel++\n\n\t\tcase data[i] == ']':\n\t\t\tlevel--\n\t\t\tif level <= 0 {\n\t\t\t\ti-- // compensate for extra i++ in for loop\n\t\t\t}\n\t\t}\n\t}\n\n\tif i >= len(data) {\n\t\treturn 0, nil\n\t}\n\n\tnode := &ast.Citation{}\n\n\tcitations := bytes.Split(data[1:i], []byte(\";\"))\n\tfor _, citation := range citations {\n\t\tvar suffix []byte\n\t\tcitation = bytes.TrimSpace(citation)\n\t\tj := 0\n\t\tif citation[j] != '@' {\n\t\t\t// not a citation, drop out entirely.\n\t\t\treturn 0, nil\n\t\t}\n\t\tif c := bytes.Index(citation, []byte(\",\")); c > 0 {\n\t\t\tpart := citation[:c]\n\t\t\tsuff := citation[c+1:]\n\t\t\tpart = bytes.TrimSpace(part)\n\t\t\tsuff = bytes.TrimSpace(suff)\n\n\t\t\tcitation = part\n\t\t\tsuffix = suff\n\t\t}\n\n\t\tciteType := ast.CitationTypeInformative\n\n\t\tif len(citation) < 2 {\n\t\t\tcontinue\n\t\t}\n\n\t\tj = 1\n\t\tswitch citation[j] {\n\t\tcase '!':\n\t\t\tciteType = ast.CitationTypeNormative\n\t\t\tj++\n\t\tcase '?':\n\t\t\tciteType = ast.CitationTypeInformative\n\t\t\tj++\n\t\tcase '-':\n\t\t\tciteType = ast.CitationTypeSuppressed\n\t\t\tj++\n\t\t}\n\t\tnode.Destination = append(node.Destination, citation[j:])\n\t\tnode.Type = append(node.Type, citeType)\n\t\tnode.Suffix = append(node.Suffix, suffix)\n\t}\n\n\treturn i + 1, node\n}\n"], "filenames": ["parser/block.go", "parser/citation.go"], "buggy_code_start_loc": [193, 67], "buggy_code_end_loc": [397, 67], "fixing_code_start_loc": [194, 68], "fixing_code_end_loc": [402, 73], "type": "CWE-125", "message": "The package `github.com/gomarkdown/markdown` is a Go library for parsing Markdown text and rendering as HTML. Prior to pseudoversion `0.0.0-20230922105210-14b16010c2ee`, which corresponds with commit `14b16010c2ee7ff33a940a541d993bd043a88940`, parsing malformed markdown input with parser that uses parser.Mmark extension could result in out-of-bounds read vulnerability. To exploit the vulnerability, parser needs to have `parser.Mmark` extension set. The panic occurs inside the `citation.go` file on the line 69 when the parser tries to access the element past its length. This can result in a denial of service. Commit `14b16010c2ee7ff33a940a541d993bd043a88940`/pseudoversion `0.0.0-20230922105210-14b16010c2ee` contains a patch for this issue.", "other": {"cve": {"id": "CVE-2023-42821", "sourceIdentifier": "security-advisories@github.com", "published": "2023-09-22T17:15:14.990", "lastModified": "2023-09-26T14:59:06.790", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The package `github.com/gomarkdown/markdown` is a Go library for parsing Markdown text and rendering as HTML. Prior to pseudoversion `0.0.0-20230922105210-14b16010c2ee`, which corresponds with commit `14b16010c2ee7ff33a940a541d993bd043a88940`, parsing malformed markdown input with parser that uses parser.Mmark extension could result in out-of-bounds read vulnerability. To exploit the vulnerability, parser needs to have `parser.Mmark` extension set. The panic occurs inside the `citation.go` file on the line 69 when the parser tries to access the element past its length. This can result in a denial of service. Commit `14b16010c2ee7ff33a940a541d993bd043a88940`/pseudoversion `0.0.0-20230922105210-14b16010c2ee` contains a patch for this issue."}, {"lang": "es", "value": "El paquete `github.com/gomarkdown/markdown` es una liber\u00eda Go para analizar texto Markdown y representarlo como HTML. Antes de la pseudoversi\u00f3n `0.0.0-20230922105210-14b16010c2ee`, que corresponde con el commit `14b16010c2ee7ff33a940a541d993bd043a88940`, analizando el markdown con formato incorrecto con un analizador que utiliza la extensi\u00f3n parser.Mmark podr\u00eda resultar en una vulnerabilidad de lectura fuera de los l\u00edmites. Para explotar la vulnerabilidad, el analizador debe tener configurada la extensi\u00f3n `parser.Mmark`. El p\u00e1nico ocurre dentro del archivo `citation.go` en la l\u00ednea 69 cuando el analizador intenta acceder al elemento m\u00e1s all\u00e1 de su longitud. Esto puede resultar en una denegaci\u00f3n de servicio. Commit `14b16010c2ee7ff33a940a541d993bd043a88940`/pseudoversion `0.0.0-20230922105210-14b16010c2ee` contiene un parche para este problema."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-125"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:gomarkdown:markdown:-:*:*:*:*:go:*:*", "matchCriteriaId": "0982DB0A-C064-4EEE-814A-730F890C5F6F"}]}]}], "references": [{"url": "https://github.com/gomarkdown/markdown/blob/7478c230c7cd3e7328803d89abe591d0b61c41e4/parser/citation.go#L69", "source": "security-advisories@github.com", "tags": ["Product"]}, {"url": "https://github.com/gomarkdown/markdown/commit/14b16010c2ee7ff33a940a541d993bd043a88940", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/gomarkdown/markdown/security/advisories/GHSA-m9xq-6h2j-65r2", "source": "security-advisories@github.com", "tags": ["Exploit", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/gomarkdown/markdown/commit/14b16010c2ee7ff33a940a541d993bd043a88940"}}
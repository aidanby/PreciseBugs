{"buggy_code": ["/*\n * Copyright (c) 2009-2012, Salvatore Sanfilippo <antirez at gmail dot com>\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *   * Redistributions of source code must retain the above copyright notice,\n *     this list of conditions and the following disclaimer.\n *   * Redistributions in binary form must reproduce the above copyright\n *     notice, this list of conditions and the following disclaimer in the\n *     documentation and/or other materials provided with the distribution.\n *   * Neither the name of Redis nor the names of its contributors may be used\n *     to endorse or promote products derived from this software without\n *     specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"server.h\"\n#include \"cluster.h\"\n#include \"atomicvar.h\"\n#include \"latency.h\"\n#include \"script.h\"\n#include \"functions.h\"\n\n#include <signal.h>\n#include <ctype.h>\n\n/*-----------------------------------------------------------------------------\n * C-level DB API\n *----------------------------------------------------------------------------*/\n\n/* Flags for expireIfNeeded */\n#define EXPIRE_FORCE_DELETE_EXPIRED 1\n#define EXPIRE_AVOID_DELETE_EXPIRED 2\n\nint expireIfNeeded(redisDb *db, robj *key, int flags);\nint keyIsExpired(redisDb *db, robj *key);\nstatic void dbSetValue(redisDb *db, robj *key, robj *val, int overwrite, dictEntry *de);\n\n/* Update LFU when an object is accessed.\n * Firstly, decrement the counter if the decrement time is reached.\n * Then logarithmically increment the counter, and update the access time. */\nvoid updateLFU(robj *val) {\n    unsigned long counter = LFUDecrAndReturn(val);\n    counter = LFULogIncr(counter);\n    val->lru = (LFUGetTimeInMinutes()<<8) | counter;\n}\n\n/* Lookup a key for read or write operations, or return NULL if the key is not\n * found in the specified DB. This function implements the functionality of\n * lookupKeyRead(), lookupKeyWrite() and their ...WithFlags() variants.\n *\n * Side-effects of calling this function:\n *\n * 1. A key gets expired if it reached it's TTL.\n * 2. The key's last access time is updated.\n * 3. The global keys hits/misses stats are updated (reported in INFO).\n * 4. If keyspace notifications are enabled, a \"keymiss\" notification is fired.\n *\n * Flags change the behavior of this command:\n *\n *  LOOKUP_NONE (or zero): No special flags are passed.\n *  LOOKUP_NOTOUCH: Don't alter the last access time of the key.\n *  LOOKUP_NONOTIFY: Don't trigger keyspace event on key miss.\n *  LOOKUP_NOSTATS: Don't increment key hits/misses counters.\n *  LOOKUP_WRITE: Prepare the key for writing (delete expired keys even on\n *                replicas, use separate keyspace stats and events (TODO)).\n *  LOOKUP_NOEXPIRE: Perform expiration check, but avoid deleting the key,\n *                   so that we don't have to propagate the deletion.\n *\n * Note: this function also returns NULL if the key is logically expired but\n * still existing, in case this is a replica and the LOOKUP_WRITE is not set.\n * Even if the key expiry is master-driven, we can correctly report a key is\n * expired on replicas even if the master is lagging expiring our key via DELs\n * in the replication link. */\nrobj *lookupKey(redisDb *db, robj *key, int flags) {\n    dictEntry *de = dictFind(db->dict,key->ptr);\n    robj *val = NULL;\n    if (de) {\n        val = dictGetVal(de);\n        /* Forcing deletion of expired keys on a replica makes the replica\n         * inconsistent with the master. We forbid it on readonly replicas, but\n         * we have to allow it on writable replicas to make write commands\n         * behave consistently.\n         *\n         * It's possible that the WRITE flag is set even during a readonly\n         * command, since the command may trigger events that cause modules to\n         * perform additional writes. */\n        int is_ro_replica = server.masterhost && server.repl_slave_ro;\n        int expire_flags = 0;\n        if (flags & LOOKUP_WRITE && !is_ro_replica)\n            expire_flags |= EXPIRE_FORCE_DELETE_EXPIRED;\n        if (flags & LOOKUP_NOEXPIRE)\n            expire_flags |= EXPIRE_AVOID_DELETE_EXPIRED;\n        if (expireIfNeeded(db, key, expire_flags)) {\n            /* The key is no longer valid. */\n            val = NULL;\n        }\n    }\n\n    if (val) {\n        /* Update the access time for the ageing algorithm.\n         * Don't do it if we have a saving child, as this will trigger\n         * a copy on write madness. */\n        if (server.current_client && server.current_client->flags & CLIENT_NO_TOUCH &&\n            server.current_client->cmd->proc != touchCommand)\n            flags |= LOOKUP_NOTOUCH;\n        if (!hasActiveChildProcess() && !(flags & LOOKUP_NOTOUCH)){\n            if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {\n                updateLFU(val);\n            } else {\n                val->lru = LRU_CLOCK();\n            }\n        }\n\n        if (!(flags & (LOOKUP_NOSTATS | LOOKUP_WRITE)))\n            server.stat_keyspace_hits++;\n        /* TODO: Use separate hits stats for WRITE */\n    } else {\n        if (!(flags & (LOOKUP_NONOTIFY | LOOKUP_WRITE)))\n            notifyKeyspaceEvent(NOTIFY_KEY_MISS, \"keymiss\", key, db->id);\n        if (!(flags & (LOOKUP_NOSTATS | LOOKUP_WRITE)))\n            server.stat_keyspace_misses++;\n        /* TODO: Use separate misses stats and notify event for WRITE */\n    }\n\n    return val;\n}\n\n/* Lookup a key for read operations, or return NULL if the key is not found\n * in the specified DB.\n *\n * This API should not be used when we write to the key after obtaining\n * the object linked to the key, but only for read only operations.\n *\n * This function is equivalent to lookupKey(). The point of using this function\n * rather than lookupKey() directly is to indicate that the purpose is to read\n * the key. */\nrobj *lookupKeyReadWithFlags(redisDb *db, robj *key, int flags) {\n    serverAssert(!(flags & LOOKUP_WRITE));\n    return lookupKey(db, key, flags);\n}\n\n/* Like lookupKeyReadWithFlags(), but does not use any flag, which is the\n * common case. */\nrobj *lookupKeyRead(redisDb *db, robj *key) {\n    return lookupKeyReadWithFlags(db,key,LOOKUP_NONE);\n}\n\n/* Lookup a key for write operations, and as a side effect, if needed, expires\n * the key if its TTL is reached. It's equivalent to lookupKey() with the\n * LOOKUP_WRITE flag added.\n *\n * Returns the linked value object if the key exists or NULL if the key\n * does not exist in the specified DB. */\nrobj *lookupKeyWriteWithFlags(redisDb *db, robj *key, int flags) {\n    return lookupKey(db, key, flags | LOOKUP_WRITE);\n}\n\nrobj *lookupKeyWrite(redisDb *db, robj *key) {\n    return lookupKeyWriteWithFlags(db, key, LOOKUP_NONE);\n}\n\nrobj *lookupKeyReadOrReply(client *c, robj *key, robj *reply) {\n    robj *o = lookupKeyRead(c->db, key);\n    if (!o) addReplyOrErrorObject(c, reply);\n    return o;\n}\n\nrobj *lookupKeyWriteOrReply(client *c, robj *key, robj *reply) {\n    robj *o = lookupKeyWrite(c->db, key);\n    if (!o) addReplyOrErrorObject(c, reply);\n    return o;\n}\n\n/* Add the key to the DB. It's up to the caller to increment the reference\n * counter of the value if needed.\n *\n * If the update_if_existing argument is false, the the program is aborted\n * if the key already exists, otherwise, it can fall back to dbOverwite. */\nstatic void dbAddInternal(redisDb *db, robj *key, robj *val, int update_if_existing) {\n    dictEntry *existing;\n    dictEntry *de = dictAddRaw(db->dict, key->ptr, &existing);\n    if (update_if_existing && existing) {\n        dbSetValue(db, key, val, 1, existing);\n        return;\n    }\n    serverAssertWithInfo(NULL, key, de != NULL);\n    dictSetKey(db->dict, de, sdsdup(key->ptr));\n    initObjectLRUOrLFU(val);\n    dictSetVal(db->dict, de, val);\n    signalKeyAsReady(db, key, val->type);\n    if (server.cluster_enabled) slotToKeyAddEntry(de, db);\n    notifyKeyspaceEvent(NOTIFY_NEW,\"new\",key,db->id);\n}\n\nvoid dbAdd(redisDb *db, robj *key, robj *val) {\n    dbAddInternal(db, key, val, 0);\n}\n\n/* This is a special version of dbAdd() that is used only when loading\n * keys from the RDB file: the key is passed as an SDS string that is\n * retained by the function (and not freed by the caller).\n *\n * Moreover this function will not abort if the key is already busy, to\n * give more control to the caller, nor will signal the key as ready\n * since it is not useful in this context.\n *\n * The function returns 1 if the key was added to the database, taking\n * ownership of the SDS string, otherwise 0 is returned, and is up to the\n * caller to free the SDS string. */\nint dbAddRDBLoad(redisDb *db, sds key, robj *val) {\n    dictEntry *de = dictAddRaw(db->dict, key, NULL);\n    if (de == NULL) return 0;\n    initObjectLRUOrLFU(val);\n    dictSetVal(db->dict, de, val);\n    if (server.cluster_enabled) slotToKeyAddEntry(de, db);\n    return 1;\n}\n\n/* Overwrite an existing key with a new value. Incrementing the reference\n * count of the new value is up to the caller.\n * This function does not modify the expire time of the existing key.\n *\n * The 'overwrite' flag is an indication whether this is done as part of a\n * complete replacement of their key, which can be thought as a deletion and\n * replacement (in which case we need to emit deletion signals), or just an\n * update of a value of an existing key (when false).\n *\n * The dictEntry input is optional, can be used if we already have one.\n *\n * The program is aborted if the key was not already present. */\nstatic void dbSetValue(redisDb *db, robj *key, robj *val, int overwrite, dictEntry *de) {\n    if (!de) de = dictFind(db->dict,key->ptr);\n    serverAssertWithInfo(NULL,key,de != NULL);\n    robj *old = dictGetVal(de);\n\n    val->lru = old->lru;\n\n    if (overwrite) {\n        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we\n         * need to incr to retain old */\n        incrRefCount(old);\n        /* Although the key is not really deleted from the database, we regard\n         * overwrite as two steps of unlink+add, so we still need to call the unlink\n         * callback of the module. */\n        moduleNotifyKeyUnlink(key,old,db->id,DB_FLAG_KEY_OVERWRITE);\n        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */\n        signalDeletedKeyAsReady(db,key,old->type);\n        decrRefCount(old);\n        /* Because of RM_StringDMA, old may be changed, so we need get old again */\n        old = dictGetVal(de);\n    }\n    dictSetVal(db->dict, de, val);\n\n    if (server.lazyfree_lazy_server_del) {\n        freeObjAsync(key,old,db->id);\n    } else {\n        /* This is just decrRefCount(old); */\n        db->dict->type->valDestructor(db->dict, old);\n    }\n}\n\n/* Replace an existing key with a new value, we just replace value and don't\n * emit any events */\nvoid dbReplaceValue(redisDb *db, robj *key, robj *val) {\n    dbSetValue(db, key, val, 0, NULL);\n}\n\n/* High level Set operation. This function can be used in order to set\n * a key, whatever it was existing or not, to a new object.\n *\n * 1) The ref count of the value object is incremented.\n * 2) clients WATCHing for the destination key notified.\n * 3) The expire time of the key is reset (the key is made persistent),\n *    unless 'SETKEY_KEEPTTL' is enabled in flags.\n * 4) The key lookup can take place outside this interface outcome will be\n *    delivered with 'SETKEY_ALREADY_EXIST' or 'SETKEY_DOESNT_EXIST'\n *\n * All the new keys in the database should be created via this interface.\n * The client 'c' argument may be set to NULL if the operation is performed\n * in a context where there is no clear client performing the operation. */\nvoid setKey(client *c, redisDb *db, robj *key, robj *val, int flags) {\n    int keyfound = 0;\n\n    if (flags & SETKEY_ALREADY_EXIST)\n        keyfound = 1;\n    else if (flags & SETKEY_ADD_OR_UPDATE)\n        keyfound = -1;\n    else if (!(flags & SETKEY_DOESNT_EXIST))\n        keyfound = (lookupKeyWrite(db,key) != NULL);\n\n    if (!keyfound) {\n        dbAdd(db,key,val);\n    } else if (keyfound<0) {\n        dbAddInternal(db,key,val,1);\n    } else {\n        dbSetValue(db,key,val,1,NULL);\n    }\n    incrRefCount(val);\n    if (!(flags & SETKEY_KEEPTTL)) removeExpire(db,key);\n    if (!(flags & SETKEY_NO_SIGNAL)) signalModifiedKey(c,db,key);\n}\n\n/* Return a random key, in form of a Redis object.\n * If there are no keys, NULL is returned.\n *\n * The function makes sure to return keys not already expired. */\nrobj *dbRandomKey(redisDb *db) {\n    dictEntry *de;\n    int maxtries = 100;\n    int allvolatile = dictSize(db->dict) == dictSize(db->expires);\n\n    while(1) {\n        sds key;\n        robj *keyobj;\n\n        de = dictGetFairRandomKey(db->dict);\n        if (de == NULL) return NULL;\n\n        key = dictGetKey(de);\n        keyobj = createStringObject(key,sdslen(key));\n        if (dictFind(db->expires,key)) {\n            if (allvolatile && server.masterhost && --maxtries == 0) {\n                /* If the DB is composed only of keys with an expire set,\n                 * it could happen that all the keys are already logically\n                 * expired in the slave, so the function cannot stop because\n                 * expireIfNeeded() is false, nor it can stop because\n                 * dictGetFairRandomKey() returns NULL (there are keys to return).\n                 * To prevent the infinite loop we do some tries, but if there\n                 * are the conditions for an infinite loop, eventually we\n                 * return a key name that may be already expired. */\n                return keyobj;\n            }\n            if (expireIfNeeded(db,keyobj,0)) {\n                decrRefCount(keyobj);\n                continue; /* search for another key. This expired. */\n            }\n        }\n        return keyobj;\n    }\n}\n\n/* Helper for sync and async delete. */\nint dbGenericDelete(redisDb *db, robj *key, int async, int flags) {\n    dictEntry **plink;\n    int table;\n    dictEntry *de = dictTwoPhaseUnlinkFind(db->dict,key->ptr,&plink,&table);\n    if (de) {\n        robj *val = dictGetVal(de);\n        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we\n         * need to incr to retain val */\n        incrRefCount(val);\n        /* Tells the module that the key has been unlinked from the database. */\n        moduleNotifyKeyUnlink(key,val,db->id,flags);\n        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */\n        signalDeletedKeyAsReady(db,key,val->type);\n        /* We should call decr before freeObjAsync. If not, the refcount may be\n         * greater than 1, so freeObjAsync doesn't work */\n        decrRefCount(val);\n        if (async) {\n            /* Because of dbUnshareStringValue, the val in de may change. */\n            freeObjAsync(key, dictGetVal(de), db->id);\n            dictSetVal(db->dict, de, NULL);\n        }\n        if (server.cluster_enabled) slotToKeyDelEntry(de, db);\n\n        /* Deleting an entry from the expires dict will not free the sds of\n        * the key, because it is shared with the main dictionary. */\n        if (dictSize(db->expires) > 0) dictDelete(db->expires,key->ptr);\n        dictTwoPhaseUnlinkFree(db->dict,de,plink,table);\n        return 1;\n    } else {\n        return 0;\n    }\n}\n\n/* Delete a key, value, and associated expiration entry if any, from the DB */\nint dbSyncDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, 0, DB_FLAG_KEY_DELETED);\n}\n\n/* Delete a key, value, and associated expiration entry if any, from the DB. If\n * the value consists of many allocations, it may be freed asynchronously. */\nint dbAsyncDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, 1, DB_FLAG_KEY_DELETED);\n}\n\n/* This is a wrapper whose behavior depends on the Redis lazy free\n * configuration. Deletes the key synchronously or asynchronously. */\nint dbDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, server.lazyfree_lazy_server_del, DB_FLAG_KEY_DELETED);\n}\n\n/* Prepare the string object stored at 'key' to be modified destructively\n * to implement commands like SETBIT or APPEND.\n *\n * An object is usually ready to be modified unless one of the two conditions\n * are true:\n *\n * 1) The object 'o' is shared (refcount > 1), we don't want to affect\n *    other users.\n * 2) The object encoding is not \"RAW\".\n *\n * If the object is found in one of the above conditions (or both) by the\n * function, an unshared / not-encoded copy of the string object is stored\n * at 'key' in the specified 'db'. Otherwise the object 'o' itself is\n * returned.\n *\n * USAGE:\n *\n * The object 'o' is what the caller already obtained by looking up 'key'\n * in 'db', the usage pattern looks like this:\n *\n * o = lookupKeyWrite(db,key);\n * if (checkType(c,o,OBJ_STRING)) return;\n * o = dbUnshareStringValue(db,key,o);\n *\n * At this point the caller is ready to modify the object, for example\n * using an sdscat() call to append some data, or anything else.\n */\nrobj *dbUnshareStringValue(redisDb *db, robj *key, robj *o) {\n    serverAssert(o->type == OBJ_STRING);\n    if (o->refcount != 1 || o->encoding != OBJ_ENCODING_RAW) {\n        robj *decoded = getDecodedObject(o);\n        o = createRawStringObject(decoded->ptr, sdslen(decoded->ptr));\n        decrRefCount(decoded);\n        dbReplaceValue(db,key,o);\n    }\n    return o;\n}\n\n/* Remove all keys from the database(s) structure. The dbarray argument\n * may not be the server main DBs (could be a temporary DB).\n *\n * The dbnum can be -1 if all the DBs should be emptied, or the specified\n * DB index if we want to empty only a single database.\n * The function returns the number of keys removed from the database(s). */\nlong long emptyDbStructure(redisDb *dbarray, int dbnum, int async,\n                           void(callback)(dict*))\n{\n    long long removed = 0;\n    int startdb, enddb;\n\n    if (dbnum == -1) {\n        startdb = 0;\n        enddb = server.dbnum-1;\n    } else {\n        startdb = enddb = dbnum;\n    }\n\n    for (int j = startdb; j <= enddb; j++) {\n        removed += dictSize(dbarray[j].dict);\n        if (async) {\n            emptyDbAsync(&dbarray[j]);\n        } else {\n            dictEmpty(dbarray[j].dict,callback);\n            dictEmpty(dbarray[j].expires,callback);\n        }\n        /* Because all keys of database are removed, reset average ttl. */\n        dbarray[j].avg_ttl = 0;\n        dbarray[j].expires_cursor = 0;\n    }\n\n    return removed;\n}\n\n/* Remove all data (keys and functions) from all the databases in a\n * Redis server. If callback is given the function is called from\n * time to time to signal that work is in progress.\n *\n * The dbnum can be -1 if all the DBs should be flushed, or the specified\n * DB number if we want to flush only a single Redis database number.\n *\n * Flags are be EMPTYDB_NO_FLAGS if no special flags are specified or\n * EMPTYDB_ASYNC if we want the memory to be freed in a different thread\n * and the function to return ASAP. EMPTYDB_NOFUNCTIONS can also be set\n * to specify that we do not want to delete the functions.\n *\n * On success the function returns the number of keys removed from the\n * database(s). Otherwise -1 is returned in the specific case the\n * DB number is out of range, and errno is set to EINVAL. */\nlong long emptyData(int dbnum, int flags, void(callback)(dict*)) {\n    int async = (flags & EMPTYDB_ASYNC);\n    int with_functions = !(flags & EMPTYDB_NOFUNCTIONS);\n    RedisModuleFlushInfoV1 fi = {REDISMODULE_FLUSHINFO_VERSION,!async,dbnum};\n    long long removed = 0;\n\n    if (dbnum < -1 || dbnum >= server.dbnum) {\n        errno = EINVAL;\n        return -1;\n    }\n\n    /* Fire the flushdb modules event. */\n    moduleFireServerEvent(REDISMODULE_EVENT_FLUSHDB,\n                          REDISMODULE_SUBEVENT_FLUSHDB_START,\n                          &fi);\n\n    /* Make sure the WATCHed keys are affected by the FLUSH* commands.\n     * Note that we need to call the function while the keys are still\n     * there. */\n    signalFlushedDb(dbnum, async);\n\n    /* Empty redis database structure. */\n    removed = emptyDbStructure(server.db, dbnum, async, callback);\n\n    /* Flush slots to keys map if enable cluster, we can flush entire\n     * slots to keys map whatever dbnum because only support one DB\n     * in cluster mode. */\n    if (server.cluster_enabled) slotToKeyFlush(server.db);\n\n    if (dbnum == -1) flushSlaveKeysWithExpireList();\n\n    if (with_functions) {\n        serverAssert(dbnum == -1);\n        functionsLibCtxClearCurrent(async);\n    }\n\n    /* Also fire the end event. Note that this event will fire almost\n     * immediately after the start event if the flush is asynchronous. */\n    moduleFireServerEvent(REDISMODULE_EVENT_FLUSHDB,\n                          REDISMODULE_SUBEVENT_FLUSHDB_END,\n                          &fi);\n\n    return removed;\n}\n\n/* Initialize temporary db on replica for use during diskless replication. */\nredisDb *initTempDb(void) {\n    redisDb *tempDb = zcalloc(sizeof(redisDb)*server.dbnum);\n    for (int i=0; i<server.dbnum; i++) {\n        tempDb[i].dict = dictCreate(&dbDictType);\n        tempDb[i].expires = dictCreate(&dbExpiresDictType);\n        tempDb[i].slots_to_keys = NULL;\n    }\n\n    if (server.cluster_enabled) {\n        /* Prepare temp slot to key map to be written during async diskless replication. */\n        slotToKeyInit(tempDb);\n    }\n\n    return tempDb;\n}\n\n/* Discard tempDb, this can be slow (similar to FLUSHALL), but it's always async. */\nvoid discardTempDb(redisDb *tempDb, void(callback)(dict*)) {\n    int async = 1;\n\n    /* Release temp DBs. */\n    emptyDbStructure(tempDb, -1, async, callback);\n    for (int i=0; i<server.dbnum; i++) {\n        dictRelease(tempDb[i].dict);\n        dictRelease(tempDb[i].expires);\n    }\n\n    if (server.cluster_enabled) {\n        /* Release temp slot to key map. */\n        slotToKeyDestroy(tempDb);\n    }\n\n    zfree(tempDb);\n}\n\nint selectDb(client *c, int id) {\n    if (id < 0 || id >= server.dbnum)\n        return C_ERR;\n    c->db = &server.db[id];\n    return C_OK;\n}\n\nlong long dbTotalServerKeyCount(void) {\n    long long total = 0;\n    int j;\n    for (j = 0; j < server.dbnum; j++) {\n        total += dictSize(server.db[j].dict);\n    }\n    return total;\n}\n\n/*-----------------------------------------------------------------------------\n * Hooks for key space changes.\n *\n * Every time a key in the database is modified the function\n * signalModifiedKey() is called.\n *\n * Every time a DB is flushed the function signalFlushDb() is called.\n *----------------------------------------------------------------------------*/\n\n/* Note that the 'c' argument may be NULL if the key was modified out of\n * a context of a client. */\nvoid signalModifiedKey(client *c, redisDb *db, robj *key) {\n    touchWatchedKey(db,key);\n    trackingInvalidateKey(c,key,1);\n}\n\nvoid signalFlushedDb(int dbid, int async) {\n    int startdb, enddb;\n    if (dbid == -1) {\n        startdb = 0;\n        enddb = server.dbnum-1;\n    } else {\n        startdb = enddb = dbid;\n    }\n\n    for (int j = startdb; j <= enddb; j++) {\n        scanDatabaseForDeletedKeys(&server.db[j], NULL);\n        touchAllWatchedKeysInDb(&server.db[j], NULL);\n    }\n\n    trackingInvalidateKeysOnFlush(async);\n\n    /* Changes in this method may take place in swapMainDbWithTempDb as well,\n     * where we execute similar calls, but with subtle differences as it's\n     * not simply flushing db. */\n}\n\n/*-----------------------------------------------------------------------------\n * Type agnostic commands operating on the key space\n *----------------------------------------------------------------------------*/\n\n/* Return the set of flags to use for the emptyDb() call for FLUSHALL\n * and FLUSHDB commands.\n *\n * sync: flushes the database in an sync manner.\n * async: flushes the database in an async manner.\n * no option: determine sync or async according to the value of lazyfree-lazy-user-flush.\n *\n * On success C_OK is returned and the flags are stored in *flags, otherwise\n * C_ERR is returned and the function sends an error to the client. */\nint getFlushCommandFlags(client *c, int *flags) {\n    /* Parse the optional ASYNC option. */\n    if (c->argc == 2 && !strcasecmp(c->argv[1]->ptr,\"sync\")) {\n        *flags = EMPTYDB_NO_FLAGS;\n    } else if (c->argc == 2 && !strcasecmp(c->argv[1]->ptr,\"async\")) {\n        *flags = EMPTYDB_ASYNC;\n    } else if (c->argc == 1) {\n        *flags = server.lazyfree_lazy_user_flush ? EMPTYDB_ASYNC : EMPTYDB_NO_FLAGS;\n    } else {\n        addReplyErrorObject(c,shared.syntaxerr);\n        return C_ERR;\n    }\n    return C_OK;\n}\n\n/* Flushes the whole server data set. */\nvoid flushAllDataAndResetRDB(int flags) {\n    server.dirty += emptyData(-1,flags,NULL);\n    if (server.child_type == CHILD_TYPE_RDB) killRDBChild();\n    if (server.saveparamslen > 0) {\n        rdbSaveInfo rsi, *rsiptr;\n        rsiptr = rdbPopulateSaveInfo(&rsi);\n        rdbSave(SLAVE_REQ_NONE,server.rdb_filename,rsiptr,RDBFLAGS_NONE);\n    }\n\n#if defined(USE_JEMALLOC)\n    /* jemalloc 5 doesn't release pages back to the OS when there's no traffic.\n     * for large databases, flushdb blocks for long anyway, so a bit more won't\n     * harm and this way the flush and purge will be synchronous. */\n    if (!(flags & EMPTYDB_ASYNC))\n        jemalloc_purge();\n#endif\n}\n\n/* FLUSHDB [ASYNC]\n *\n * Flushes the currently SELECTed Redis DB. */\nvoid flushdbCommand(client *c) {\n    int flags;\n\n    if (getFlushCommandFlags(c,&flags) == C_ERR) return;\n    /* flushdb should not flush the functions */\n    server.dirty += emptyData(c->db->id,flags | EMPTYDB_NOFUNCTIONS,NULL);\n\n    /* Without the forceCommandPropagation, when DB was already empty,\n     * FLUSHDB will not be replicated nor put into the AOF. */\n    forceCommandPropagation(c, PROPAGATE_REPL | PROPAGATE_AOF);\n\n    addReply(c,shared.ok);\n\n#if defined(USE_JEMALLOC)\n    /* jemalloc 5 doesn't release pages back to the OS when there's no traffic.\n     * for large databases, flushdb blocks for long anyway, so a bit more won't\n     * harm and this way the flush and purge will be synchronous. */\n    if (!(flags & EMPTYDB_ASYNC))\n        jemalloc_purge();\n#endif\n}\n\n/* FLUSHALL [ASYNC]\n *\n * Flushes the whole server data set. */\nvoid flushallCommand(client *c) {\n    int flags;\n    if (getFlushCommandFlags(c,&flags) == C_ERR) return;\n    /* flushall should not flush the functions */\n    flushAllDataAndResetRDB(flags | EMPTYDB_NOFUNCTIONS);\n\n    /* Without the forceCommandPropagation, when DBs were already empty,\n     * FLUSHALL will not be replicated nor put into the AOF. */\n    forceCommandPropagation(c, PROPAGATE_REPL | PROPAGATE_AOF);\n\n    addReply(c,shared.ok);\n}\n\n/* This command implements DEL and UNLINK. */\nvoid delGenericCommand(client *c, int lazy) {\n    int numdel = 0, j;\n\n    for (j = 1; j < c->argc; j++) {\n        expireIfNeeded(c->db,c->argv[j],0);\n        int deleted  = lazy ? dbAsyncDelete(c->db,c->argv[j]) :\n                              dbSyncDelete(c->db,c->argv[j]);\n        if (deleted) {\n            signalModifiedKey(c,c->db,c->argv[j]);\n            notifyKeyspaceEvent(NOTIFY_GENERIC,\n                \"del\",c->argv[j],c->db->id);\n            server.dirty++;\n            numdel++;\n        }\n    }\n    addReplyLongLong(c,numdel);\n}\n\nvoid delCommand(client *c) {\n    delGenericCommand(c,server.lazyfree_lazy_user_del);\n}\n\nvoid unlinkCommand(client *c) {\n    delGenericCommand(c,1);\n}\n\n/* EXISTS key1 key2 ... key_N.\n * Return value is the number of keys existing. */\nvoid existsCommand(client *c) {\n    long long count = 0;\n    int j;\n\n    for (j = 1; j < c->argc; j++) {\n        if (lookupKeyReadWithFlags(c->db,c->argv[j],LOOKUP_NOTOUCH)) count++;\n    }\n    addReplyLongLong(c,count);\n}\n\nvoid selectCommand(client *c) {\n    int id;\n\n    if (getIntFromObjectOrReply(c, c->argv[1], &id, NULL) != C_OK)\n        return;\n\n    if (server.cluster_enabled && id != 0) {\n        addReplyError(c,\"SELECT is not allowed in cluster mode\");\n        return;\n    }\n    if (selectDb(c,id) == C_ERR) {\n        addReplyError(c,\"DB index is out of range\");\n    } else {\n        addReply(c,shared.ok);\n    }\n}\n\nvoid randomkeyCommand(client *c) {\n    robj *key;\n\n    if ((key = dbRandomKey(c->db)) == NULL) {\n        addReplyNull(c);\n        return;\n    }\n\n    addReplyBulk(c,key);\n    decrRefCount(key);\n}\n\nvoid keysCommand(client *c) {\n    dictIterator *di;\n    dictEntry *de;\n    sds pattern = c->argv[1]->ptr;\n    int plen = sdslen(pattern), allkeys;\n    unsigned long numkeys = 0;\n    void *replylen = addReplyDeferredLen(c);\n\n    di = dictGetSafeIterator(c->db->dict);\n    allkeys = (pattern[0] == '*' && plen == 1);\n    robj keyobj;\n    while((de = dictNext(di)) != NULL) {\n        sds key = dictGetKey(de);\n\n        if (allkeys || stringmatchlen(pattern,plen,key,sdslen(key),0)) {\n            initStaticStringObject(keyobj, key);\n            if (!keyIsExpired(c->db, &keyobj)) {\n                addReplyBulkCBuffer(c, key, sdslen(key));\n                numkeys++;\n            }\n        }\n        if (c->flags & CLIENT_CLOSE_ASAP)\n            break;\n    }\n    dictReleaseIterator(di);\n    setDeferredArrayLen(c,replylen,numkeys);\n}\n\n/* Data used by the dict scan callback. */\ntypedef struct {\n    list *keys;   /* elements that collect from dict */\n    robj *o;      /* o must be a hash/set/zset object, NULL means current db */\n    long long type; /* the particular type when scan the db */\n    sds pattern;  /* pattern string, NULL means no pattern */\n    long sampled; /* cumulative number of keys sampled */\n} scanData;\n\n/* Helper function to compare key type in scan commands */\nint objectTypeCompare(robj *o, long long target) {\n    if (o->type != OBJ_MODULE) {\n        if (o->type != target) \n            return 0;\n        else \n            return 1;\n    }\n    /* module type compare */\n    long long mt = (long long)REDISMODULE_TYPE_SIGN(((moduleValue *)o->ptr)->type->id);\n    if (target != -mt)\n        return 0;\n    else \n        return 1;\n}\n/* This callback is used by scanGenericCommand in order to collect elements\n * returned by the dictionary iterator into a list. */\nvoid scanCallback(void *privdata, const dictEntry *de) {\n    scanData *data = (scanData *)privdata;\n    list *keys = data->keys;\n    robj *o = data->o;\n    sds val = NULL;\n    sds key = NULL;\n    data->sampled++;\n\n    /* o and typename can not have values at the same time. */\n    serverAssert(!((data->type != LLONG_MAX) && o));\n\n    /* Filter an element if it isn't the type we want. */\n    /* TODO: uncomment in redis 8.0\n    if (!o && data->type != LLONG_MAX) {\n        robj *rval = dictGetVal(de);\n        if (!objectTypeCompare(rval, data->type)) return;\n    }*/\n\n    /* Filter element if it does not match the pattern. */\n    sds keysds = dictGetKey(de);\n    if (data->pattern) {\n        if (!stringmatchlen(data->pattern, sdslen(data->pattern), keysds, sdslen(keysds), 0)) {\n            return;\n        }\n    }\n\n    if (o == NULL) {\n        key = keysds;\n    } else if (o->type == OBJ_SET) {\n        key = keysds;\n    } else if (o->type == OBJ_HASH) {\n        key = keysds;\n        val = dictGetVal(de);\n    } else if (o->type == OBJ_ZSET) {\n        char buf[MAX_LONG_DOUBLE_CHARS];\n        int len = ld2string(buf, sizeof(buf), *(double *)dictGetVal(de), LD_STR_AUTO);\n        key = sdsdup(keysds);\n        val = sdsnewlen(buf, len);\n    } else {\n        serverPanic(\"Type not handled in SCAN callback.\");\n    }\n\n    listAddNodeTail(keys, key);\n    if (val) listAddNodeTail(keys, val);\n}\n\n/* Try to parse a SCAN cursor stored at object 'o':\n * if the cursor is valid, store it as unsigned integer into *cursor and\n * returns C_OK. Otherwise return C_ERR and send an error to the\n * client. */\nint parseScanCursorOrReply(client *c, robj *o, unsigned long *cursor) {\n    char *eptr;\n\n    /* Use strtoul() because we need an *unsigned* long, so\n     * getLongLongFromObject() does not cover the whole cursor space. */\n    errno = 0;\n    *cursor = strtoul(o->ptr, &eptr, 10);\n    if (isspace(((char*)o->ptr)[0]) || eptr[0] != '\\0' || errno == ERANGE)\n    {\n        addReplyError(c, \"invalid cursor\");\n        return C_ERR;\n    }\n    return C_OK;\n}\n\nchar *obj_type_name[OBJ_TYPE_MAX] = {\n    \"string\", \n    \"list\", \n    \"set\", \n    \"zset\", \n    \"hash\", \n    NULL, /* module type is special */\n    \"stream\"\n};\n\n/* Helper function to get type from a string in scan commands */\nlong long getObjectTypeByName(char *name) {\n\n    for (long long i = 0; i < OBJ_TYPE_MAX; i++) {\n        if (obj_type_name[i] && !strcasecmp(name, obj_type_name[i])) {\n            return i;\n        }\n    }\n\n    moduleType *mt = moduleTypeLookupModuleByNameIgnoreCase(name);\n    if (mt != NULL) return -(REDISMODULE_TYPE_SIGN(mt->id));\n\n    return LLONG_MAX;\n}\n\nchar *getObjectTypeName(robj *o) {\n    if (o == NULL) {\n        return \"none\";\n    }\n\n    serverAssert(o->type >= 0 && o->type < OBJ_TYPE_MAX);\n\n    if (o->type == OBJ_MODULE) {\n        moduleValue *mv = o->ptr;\n        return mv->type->name;\n    } else {\n        return obj_type_name[o->type];\n    }\n}\n\n/* This command implements SCAN, HSCAN and SSCAN commands.\n * If object 'o' is passed, then it must be a Hash, Set or Zset object, otherwise\n * if 'o' is NULL the command will operate on the dictionary associated with\n * the current database.\n *\n * When 'o' is not NULL the function assumes that the first argument in\n * the client arguments vector is a key so it skips it before iterating\n * in order to parse options.\n *\n * In the case of a Hash object the function returns both the field and value\n * of every element on the Hash. */\nvoid scanGenericCommand(client *c, robj *o, unsigned long cursor) {\n    int i, j;\n    listNode *node;\n    long count = 10;\n    sds pat = NULL;\n    sds typename = NULL;\n    long long type = LLONG_MAX;\n    int patlen = 0, use_pattern = 0;\n    dict *ht;\n\n    /* Object must be NULL (to iterate keys names), or the type of the object\n     * must be Set, Sorted Set, or Hash. */\n    serverAssert(o == NULL || o->type == OBJ_SET || o->type == OBJ_HASH ||\n                o->type == OBJ_ZSET);\n\n    /* Set i to the first option argument. The previous one is the cursor. */\n    i = (o == NULL) ? 2 : 3; /* Skip the key argument if needed. */\n\n    /* Step 1: Parse options. */\n    while (i < c->argc) {\n        j = c->argc - i;\n        if (!strcasecmp(c->argv[i]->ptr, \"count\") && j >= 2) {\n            if (getLongFromObjectOrReply(c, c->argv[i+1], &count, NULL)\n                != C_OK)\n            {\n                return;\n            }\n\n            if (count < 1) {\n                addReplyErrorObject(c,shared.syntaxerr);\n                return;\n            }\n\n            i += 2;\n        } else if (!strcasecmp(c->argv[i]->ptr, \"match\") && j >= 2) {\n            pat = c->argv[i+1]->ptr;\n            patlen = sdslen(pat);\n\n            /* The pattern always matches if it is exactly \"*\", so it is\n             * equivalent to disabling it. */\n            use_pattern = !(patlen == 1 && pat[0] == '*');\n\n            i += 2;\n        } else if (!strcasecmp(c->argv[i]->ptr, \"type\") && o == NULL && j >= 2) {\n            /* SCAN for a particular type only applies to the db dict */\n            typename = c->argv[i+1]->ptr;\n            type = getObjectTypeByName(typename);\n            if (type == LLONG_MAX) {\n                /* TODO: uncomment in redis 8.0\n                addReplyErrorFormat(c, \"unknown type name '%s'\", typename);\n                return; */\n            }\n            i+= 2;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            return;\n        }\n    }\n\n    /* Step 2: Iterate the collection.\n     *\n     * Note that if the object is encoded with a listpack, intset, or any other\n     * representation that is not a hash table, we are sure that it is also\n     * composed of a small number of elements. So to avoid taking state we\n     * just return everything inside the object in a single call, setting the\n     * cursor to zero to signal the end of the iteration. */\n\n    /* Handle the case of a hash table. */\n    ht = NULL;\n    if (o == NULL) {\n        ht = c->db->dict;\n    } else if (o->type == OBJ_SET && o->encoding == OBJ_ENCODING_HT) {\n        ht = o->ptr;\n    } else if (o->type == OBJ_HASH && o->encoding == OBJ_ENCODING_HT) {\n        ht = o->ptr;\n    } else if (o->type == OBJ_ZSET && o->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = o->ptr;\n        ht = zs->dict;\n    }\n\n    list *keys = listCreate();\n    /* Set a free callback for the contents of the collected keys list.\n     * For the main keyspace dict, and when we scan a key that's dict encoded\n     * (we have 'ht'), we don't need to define free method because the strings\n     * in the list are just a shallow copy from the pointer in the dictEntry.\n     * When scanning a key with other encodings (e.g. listpack), we need to\n     * free the temporary strings we add to that list.\n     * The exception to the above is ZSET, where we do allocate temporary\n     * strings even when scanning a dict. */\n    if (o && (!ht || o->type == OBJ_ZSET)) {\n        listSetFreeMethod(keys, (void (*)(void*))sdsfree);\n    }\n\n    if (ht) {\n        /* We set the max number of iterations to ten times the specified\n         * COUNT, so if the hash table is in a pathological state (very\n         * sparsely populated) we avoid to block too much time at the cost\n         * of returning no or very few elements. */\n        long maxiterations = count*10;\n\n        /* We pass scanData which have three pointers to the callback:\n         * 1. data.keys: the list to which it will add new elements;\n         * 2. data.o: the object containing the dictionary so that\n         * it is possible to fetch more data in a type-dependent way;\n         * 3. data.type: the specified type scan in the db, LLONG_MAX means\n         * type matching is no needed;\n         * 4. data.pattern: the pattern string\n         * 5. data.sampled: the maxiteration limit is there in case we're\n         * working on an empty dict, one with a lot of empty buckets, and\n         * for the buckets are not empty, we need to limit the spampled number\n         * to prevent a long hang time caused by filtering too many keys*/\n        scanData data = {\n            .keys = keys,\n            .o = o,\n            .type = type,\n            .pattern = use_pattern ? pat : NULL,\n            .sampled = 0,\n        };\n        do {\n            cursor = dictScan(ht, cursor, scanCallback, &data);\n        } while (cursor && maxiterations-- && data.sampled < count);\n    } else if (o->type == OBJ_SET) {\n        char *str;\n        char buf[LONG_STR_SIZE];\n        size_t len;\n        int64_t llele;\n        setTypeIterator *si = setTypeInitIterator(o);\n        while (setTypeNext(si, &str, &len, &llele) != -1) {\n            if (str == NULL) {\n                len = ll2string(buf, sizeof(buf), llele);\n            }\n            char *key = str ? str : buf;\n            if (use_pattern && !stringmatchlen(pat, sdslen(pat), key, len, 0)) {\n                continue;\n            }\n            listAddNodeTail(keys, sdsnewlen(key, len));\n        }\n        setTypeReleaseIterator(si);\n        cursor = 0;\n    } else if ((o->type == OBJ_HASH || o->type == OBJ_ZSET) &&\n               o->encoding == OBJ_ENCODING_LISTPACK)\n    {\n        unsigned char *p = lpFirst(o->ptr);\n        unsigned char *str;\n        int64_t len;\n        unsigned char intbuf[LP_INTBUF_SIZE];\n\n        while(p) {\n            str = lpGet(p, &len, intbuf);\n            /* point to the value */\n            p = lpNext(o->ptr, p);\n            if (use_pattern && !stringmatchlen(pat, sdslen(pat), (char *)str, len, 0)) {\n                /* jump to the next key/val pair */\n                p = lpNext(o->ptr, p);\n                continue;\n            }\n            /* add key object */\n            listAddNodeTail(keys, sdsnewlen(str, len));\n            /* add value object */\n            str = lpGet(p, &len, intbuf);\n            listAddNodeTail(keys, sdsnewlen(str, len));\n            p = lpNext(o->ptr, p);\n        }\n        cursor = 0;\n    } else {\n        serverPanic(\"Not handled encoding in SCAN.\");\n    }\n\n    /* Step 3: Filter the expired keys */\n    if (o == NULL && listLength(keys)) {\n        robj kobj;\n        listIter li;\n        listNode *ln;\n        listRewind(keys, &li);\n        while ((ln = listNext(&li))) {\n            sds key = listNodeValue(ln);\n            initStaticStringObject(kobj, key);\n            /* Filter an element if it isn't the type we want. */\n            /* TODO: remove this in redis 8.0 */\n            if (typename) {\n                robj* typecheck = lookupKeyReadWithFlags(c->db, &kobj, LOOKUP_NOTOUCH|LOOKUP_NONOTIFY);\n                if (!typecheck || !objectTypeCompare(typecheck, type)) {\n                    listDelNode(keys, ln);\n                }\n                continue;\n            }\n            if (expireIfNeeded(c->db, &kobj, 0)) {\n                listDelNode(keys, ln);\n            }\n        }\n    }\n\n    /* Step 4: Reply to the client. */\n    addReplyArrayLen(c, 2);\n    addReplyBulkLongLong(c,cursor);\n\n    addReplyArrayLen(c, listLength(keys));\n    while ((node = listFirst(keys)) != NULL) {\n        sds key = listNodeValue(node);\n        addReplyBulkCBuffer(c, key, sdslen(key));\n        listDelNode(keys, node);\n    }\n\n    listRelease(keys);\n}\n\n/* The SCAN command completely relies on scanGenericCommand. */\nvoid scanCommand(client *c) {\n    unsigned long cursor;\n    if (parseScanCursorOrReply(c,c->argv[1],&cursor) == C_ERR) return;\n    scanGenericCommand(c,NULL,cursor);\n}\n\nvoid dbsizeCommand(client *c) {\n    addReplyLongLong(c,dictSize(c->db->dict));\n}\n\nvoid lastsaveCommand(client *c) {\n    addReplyLongLong(c,server.lastsave);\n}\n\nvoid typeCommand(client *c) {\n    robj *o;\n    o = lookupKeyReadWithFlags(c->db,c->argv[1],LOOKUP_NOTOUCH);\n    addReplyStatus(c, getObjectTypeName(o));\n}\n\nvoid shutdownCommand(client *c) {\n    int flags = SHUTDOWN_NOFLAGS;\n    int abort = 0;\n    for (int i = 1; i < c->argc; i++) {\n        if (!strcasecmp(c->argv[i]->ptr,\"nosave\")) {\n            flags |= SHUTDOWN_NOSAVE;\n        } else if (!strcasecmp(c->argv[i]->ptr,\"save\")) {\n            flags |= SHUTDOWN_SAVE;\n        } else if (!strcasecmp(c->argv[i]->ptr, \"now\")) {\n            flags |= SHUTDOWN_NOW;\n        } else if (!strcasecmp(c->argv[i]->ptr, \"force\")) {\n            flags |= SHUTDOWN_FORCE;\n        } else if (!strcasecmp(c->argv[i]->ptr, \"abort\")) {\n            abort = 1;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            return;\n        }\n    }\n    if ((abort && flags != SHUTDOWN_NOFLAGS) ||\n        (flags & SHUTDOWN_NOSAVE && flags & SHUTDOWN_SAVE))\n    {\n        /* Illegal combo. */\n        addReplyErrorObject(c,shared.syntaxerr);\n        return;\n    }\n\n    if (abort) {\n        if (abortShutdown() == C_OK)\n            addReply(c, shared.ok);\n        else\n            addReplyError(c, \"No shutdown in progress.\");\n        return;\n    }\n\n    if (!(flags & SHUTDOWN_NOW) && c->flags & CLIENT_DENY_BLOCKING) {\n        addReplyError(c, \"SHUTDOWN without NOW or ABORT isn't allowed for DENY BLOCKING client\");\n        return;\n    }\n\n    if (!(flags & SHUTDOWN_NOSAVE) && isInsideYieldingLongCommand()) {\n        /* Script timed out. Shutdown allowed only with the NOSAVE flag. See\n         * also processCommand where these errors are returned. */\n        if (server.busy_module_yield_flags && server.busy_module_yield_reply) {\n            addReplyErrorFormat(c, \"-BUSY %s\", server.busy_module_yield_reply);\n        } else if (server.busy_module_yield_flags) {\n            addReplyErrorObject(c, shared.slowmoduleerr);\n        } else if (scriptIsEval()) {\n            addReplyErrorObject(c, shared.slowevalerr);\n        } else {\n            addReplyErrorObject(c, shared.slowscripterr);\n        }\n        return;\n    }\n\n    blockClientShutdown(c);\n    if (prepareForShutdown(flags) == C_OK) exit(0);\n    /* If we're here, then shutdown is ongoing (the client is still blocked) or\n     * failed (the client has received an error). */\n}\n\nvoid renameGenericCommand(client *c, int nx) {\n    robj *o;\n    long long expire;\n    int samekey = 0;\n\n    /* When source and dest key is the same, no operation is performed,\n     * if the key exists, however we still return an error on unexisting key. */\n    if (sdscmp(c->argv[1]->ptr,c->argv[2]->ptr) == 0) samekey = 1;\n\n    if ((o = lookupKeyWriteOrReply(c,c->argv[1],shared.nokeyerr)) == NULL)\n        return;\n\n    if (samekey) {\n        addReply(c,nx ? shared.czero : shared.ok);\n        return;\n    }\n\n    incrRefCount(o);\n    expire = getExpire(c->db,c->argv[1]);\n    if (lookupKeyWrite(c->db,c->argv[2]) != NULL) {\n        if (nx) {\n            decrRefCount(o);\n            addReply(c,shared.czero);\n            return;\n        }\n        /* Overwrite: delete the old key before creating the new one\n         * with the same name. */\n        dbDelete(c->db,c->argv[2]);\n    }\n    dbAdd(c->db,c->argv[2],o);\n    if (expire != -1) setExpire(c,c->db,c->argv[2],expire);\n    dbDelete(c->db,c->argv[1]);\n    signalModifiedKey(c,c->db,c->argv[1]);\n    signalModifiedKey(c,c->db,c->argv[2]);\n    notifyKeyspaceEvent(NOTIFY_GENERIC,\"rename_from\",\n        c->argv[1],c->db->id);\n    notifyKeyspaceEvent(NOTIFY_GENERIC,\"rename_to\",\n        c->argv[2],c->db->id);\n    server.dirty++;\n    addReply(c,nx ? shared.cone : shared.ok);\n}\n\nvoid renameCommand(client *c) {\n    renameGenericCommand(c,0);\n}\n\nvoid renamenxCommand(client *c) {\n    renameGenericCommand(c,1);\n}\n\nvoid moveCommand(client *c) {\n    robj *o;\n    redisDb *src, *dst;\n    int srcid, dbid;\n    long long expire;\n\n    if (server.cluster_enabled) {\n        addReplyError(c,\"MOVE is not allowed in cluster mode\");\n        return;\n    }\n\n    /* Obtain source and target DB pointers */\n    src = c->db;\n    srcid = c->db->id;\n\n    if (getIntFromObjectOrReply(c, c->argv[2], &dbid, NULL) != C_OK)\n        return;\n\n    if (selectDb(c,dbid) == C_ERR) {\n        addReplyError(c,\"DB index is out of range\");\n        return;\n    }\n    dst = c->db;\n    selectDb(c,srcid); /* Back to the source DB */\n\n    /* If the user is moving using as target the same\n     * DB as the source DB it is probably an error. */\n    if (src == dst) {\n        addReplyErrorObject(c,shared.sameobjecterr);\n        return;\n    }\n\n    /* Check if the element exists and get a reference */\n    o = lookupKeyWrite(c->db,c->argv[1]);\n    if (!o) {\n        addReply(c,shared.czero);\n        return;\n    }\n    expire = getExpire(c->db,c->argv[1]);\n\n    /* Return zero if the key already exists in the target DB */\n    if (lookupKeyWrite(dst,c->argv[1]) != NULL) {\n        addReply(c,shared.czero);\n        return;\n    }\n    dbAdd(dst,c->argv[1],o);\n    if (expire != -1) setExpire(c,dst,c->argv[1],expire);\n    incrRefCount(o);\n\n    /* OK! key moved, free the entry in the source DB */\n    dbDelete(src,c->argv[1]);\n    signalModifiedKey(c,src,c->argv[1]);\n    signalModifiedKey(c,dst,c->argv[1]);\n    notifyKeyspaceEvent(NOTIFY_GENERIC,\n                \"move_from\",c->argv[1],src->id);\n    notifyKeyspaceEvent(NOTIFY_GENERIC,\n                \"move_to\",c->argv[1],dst->id);\n\n    server.dirty++;\n    addReply(c,shared.cone);\n}\n\nvoid copyCommand(client *c) {\n    robj *o;\n    redisDb *src, *dst;\n    int srcid, dbid;\n    long long expire;\n    int j, replace = 0, delete = 0;\n\n    /* Obtain source and target DB pointers \n     * Default target DB is the same as the source DB \n     * Parse the REPLACE option and targetDB option. */\n    src = c->db;\n    dst = c->db;\n    srcid = c->db->id;\n    dbid = c->db->id;\n    for (j = 3; j < c->argc; j++) {\n        int additional = c->argc - j - 1;\n        if (!strcasecmp(c->argv[j]->ptr,\"replace\")) {\n            replace = 1;\n        } else if (!strcasecmp(c->argv[j]->ptr, \"db\") && additional >= 1) {\n            if (getIntFromObjectOrReply(c, c->argv[j+1], &dbid, NULL) != C_OK)\n                return;\n\n            if (selectDb(c, dbid) == C_ERR) {\n                addReplyError(c,\"DB index is out of range\");\n                return;\n            }\n            dst = c->db;\n            selectDb(c,srcid); /* Back to the source DB */\n            j++; /* Consume additional arg. */\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            return;\n        }\n    }\n\n    if ((server.cluster_enabled == 1) && (srcid != 0 || dbid != 0)) {\n        addReplyError(c,\"Copying to another database is not allowed in cluster mode\");\n        return;\n    }\n\n    /* If the user select the same DB as\n     * the source DB and using newkey as the same key\n     * it is probably an error. */\n    robj *key = c->argv[1];\n    robj *newkey = c->argv[2];\n    if (src == dst && (sdscmp(key->ptr, newkey->ptr) == 0)) {\n        addReplyErrorObject(c,shared.sameobjecterr);\n        return;\n    }\n\n    /* Check if the element exists and get a reference */\n    o = lookupKeyRead(c->db, key);\n    if (!o) {\n        addReply(c,shared.czero);\n        return;\n    }\n    expire = getExpire(c->db,key);\n\n    /* Return zero if the key already exists in the target DB. \n     * If REPLACE option is selected, delete newkey from targetDB. */\n    if (lookupKeyWrite(dst,newkey) != NULL) {\n        if (replace) {\n            delete = 1;\n        } else {\n            addReply(c,shared.czero);\n            return;\n        }\n    }\n\n    /* Duplicate object according to object's type. */\n    robj *newobj;\n    switch(o->type) {\n        case OBJ_STRING: newobj = dupStringObject(o); break;\n        case OBJ_LIST: newobj = listTypeDup(o); break;\n        case OBJ_SET: newobj = setTypeDup(o); break;\n        case OBJ_ZSET: newobj = zsetDup(o); break;\n        case OBJ_HASH: newobj = hashTypeDup(o); break;\n        case OBJ_STREAM: newobj = streamDup(o); break;\n        case OBJ_MODULE:\n            newobj = moduleTypeDupOrReply(c, key, newkey, dst->id, o);\n            if (!newobj) return;\n            break;\n        default:\n            addReplyError(c, \"unknown type object\");\n            return;\n    }\n\n    if (delete) {\n        dbDelete(dst,newkey);\n    }\n\n    dbAdd(dst,newkey,newobj);\n    if (expire != -1) setExpire(c, dst, newkey, expire);\n\n    /* OK! key copied */\n    signalModifiedKey(c,dst,c->argv[2]);\n    notifyKeyspaceEvent(NOTIFY_GENERIC,\"copy_to\",c->argv[2],dst->id);\n\n    server.dirty++;\n    addReply(c,shared.cone);\n}\n\n/* Helper function for dbSwapDatabases(): scans the list of keys that have\n * one or more blocked clients for B[LR]POP or other blocking commands\n * and signal the keys as ready if they are of the right type. See the comment\n * where the function is used for more info. */\nvoid scanDatabaseForReadyKeys(redisDb *db) {\n    dictEntry *de;\n    dictIterator *di = dictGetSafeIterator(db->blocking_keys);\n    while((de = dictNext(di)) != NULL) {\n        robj *key = dictGetKey(de);\n        dictEntry *kde = dictFind(db->dict,key->ptr);\n        if (kde) {\n            robj *value = dictGetVal(kde);\n            signalKeyAsReady(db, key, value->type);\n        }\n    }\n    dictReleaseIterator(di);\n}\n\n/* Since we are unblocking XREADGROUP clients in the event the\n * key was deleted/overwritten we must do the same in case the\n * database was flushed/swapped. */\nvoid scanDatabaseForDeletedKeys(redisDb *emptied, redisDb *replaced_with) {\n    dictEntry *de;\n    dictIterator *di = dictGetSafeIterator(emptied->blocking_keys);\n    while((de = dictNext(di)) != NULL) {\n        robj *key = dictGetKey(de);\n        int existed = 0, exists = 0;\n        int original_type = -1, curr_type = -1;\n\n        dictEntry *kde = dictFind(emptied->dict, key->ptr);\n        if (kde) {\n            robj *value = dictGetVal(kde);\n            original_type = value->type;\n            existed = 1;\n        }\n\n        if (replaced_with) {\n            dictEntry *kde = dictFind(replaced_with->dict, key->ptr);\n            if (kde) {\n                robj *value = dictGetVal(kde);\n                curr_type = value->type;\n                exists = 1;\n            }\n        }\n        /* We want to try to unblock any client using a blocking XREADGROUP */\n        if ((existed && !exists) || original_type != curr_type)\n            signalDeletedKeyAsReady(emptied, key, original_type);\n    }\n    dictReleaseIterator(di);\n}\n\n/* Swap two databases at runtime so that all clients will magically see\n * the new database even if already connected. Note that the client\n * structure c->db points to a given DB, so we need to be smarter and\n * swap the underlying referenced structures, otherwise we would need\n * to fix all the references to the Redis DB structure.\n *\n * Returns C_ERR if at least one of the DB ids are out of range, otherwise\n * C_OK is returned. */\nint dbSwapDatabases(int id1, int id2) {\n    if (id1 < 0 || id1 >= server.dbnum ||\n        id2 < 0 || id2 >= server.dbnum) return C_ERR;\n    if (id1 == id2) return C_OK;\n    redisDb aux = server.db[id1];\n    redisDb *db1 = &server.db[id1], *db2 = &server.db[id2];\n\n    /* Swapdb should make transaction fail if there is any\n     * client watching keys */\n    touchAllWatchedKeysInDb(db1, db2);\n    touchAllWatchedKeysInDb(db2, db1);\n\n    /* Try to unblock any XREADGROUP clients if the key no longer exists. */\n    scanDatabaseForDeletedKeys(db1, db2);\n    scanDatabaseForDeletedKeys(db2, db1);\n\n    /* Swap hash tables. Note that we don't swap blocking_keys,\n     * ready_keys and watched_keys, since we want clients to\n     * remain in the same DB they were. */\n    db1->dict = db2->dict;\n    db1->expires = db2->expires;\n    db1->avg_ttl = db2->avg_ttl;\n    db1->expires_cursor = db2->expires_cursor;\n\n    db2->dict = aux.dict;\n    db2->expires = aux.expires;\n    db2->avg_ttl = aux.avg_ttl;\n    db2->expires_cursor = aux.expires_cursor;\n\n    /* Now we need to handle clients blocked on lists: as an effect\n     * of swapping the two DBs, a client that was waiting for list\n     * X in a given DB, may now actually be unblocked if X happens\n     * to exist in the new version of the DB, after the swap.\n     *\n     * However normally we only do this check for efficiency reasons\n     * in dbAdd() when a list is created. So here we need to rescan\n     * the list of clients blocked on lists and signal lists as ready\n     * if needed. */\n    scanDatabaseForReadyKeys(db1);\n    scanDatabaseForReadyKeys(db2);\n    return C_OK;\n}\n\n/* Logically, this discards (flushes) the old main database, and apply the newly loaded\n * database (temp) as the main (active) database, the actual freeing of old database\n * (which will now be placed in the temp one) is done later. */\nvoid swapMainDbWithTempDb(redisDb *tempDb) {\n    if (server.cluster_enabled) {\n        /* Swap slots_to_keys from tempdb just loaded with main db slots_to_keys. */\n        clusterSlotToKeyMapping *aux = server.db->slots_to_keys;\n        server.db->slots_to_keys = tempDb->slots_to_keys;\n        tempDb->slots_to_keys = aux;\n    }\n\n    for (int i=0; i<server.dbnum; i++) {\n        redisDb aux = server.db[i];\n        redisDb *activedb = &server.db[i], *newdb = &tempDb[i];\n\n        /* Swapping databases should make transaction fail if there is any\n         * client watching keys. */\n        touchAllWatchedKeysInDb(activedb, newdb);\n\n        /* Try to unblock any XREADGROUP clients if the key no longer exists. */\n        scanDatabaseForDeletedKeys(activedb, newdb);\n\n        /* Swap hash tables. Note that we don't swap blocking_keys,\n         * ready_keys and watched_keys, since clients \n         * remain in the same DB they were. */\n        activedb->dict = newdb->dict;\n        activedb->expires = newdb->expires;\n        activedb->avg_ttl = newdb->avg_ttl;\n        activedb->expires_cursor = newdb->expires_cursor;\n\n        newdb->dict = aux.dict;\n        newdb->expires = aux.expires;\n        newdb->avg_ttl = aux.avg_ttl;\n        newdb->expires_cursor = aux.expires_cursor;\n\n        /* Now we need to handle clients blocked on lists: as an effect\n         * of swapping the two DBs, a client that was waiting for list\n         * X in a given DB, may now actually be unblocked if X happens\n         * to exist in the new version of the DB, after the swap.\n         *\n         * However normally we only do this check for efficiency reasons\n         * in dbAdd() when a list is created. So here we need to rescan\n         * the list of clients blocked on lists and signal lists as ready\n         * if needed. */\n        scanDatabaseForReadyKeys(activedb);\n    }\n\n    trackingInvalidateKeysOnFlush(1);\n    flushSlaveKeysWithExpireList();\n}\n\n/* SWAPDB db1 db2 */\nvoid swapdbCommand(client *c) {\n    int id1, id2;\n\n    /* Not allowed in cluster mode: we have just DB 0 there. */\n    if (server.cluster_enabled) {\n        addReplyError(c,\"SWAPDB is not allowed in cluster mode\");\n        return;\n    }\n\n    /* Get the two DBs indexes. */\n    if (getIntFromObjectOrReply(c, c->argv[1], &id1,\n        \"invalid first DB index\") != C_OK)\n        return;\n\n    if (getIntFromObjectOrReply(c, c->argv[2], &id2,\n        \"invalid second DB index\") != C_OK)\n        return;\n\n    /* Swap... */\n    if (dbSwapDatabases(id1,id2) == C_ERR) {\n        addReplyError(c,\"DB index is out of range\");\n        return;\n    } else {\n        RedisModuleSwapDbInfo si = {REDISMODULE_SWAPDBINFO_VERSION,id1,id2};\n        moduleFireServerEvent(REDISMODULE_EVENT_SWAPDB,0,&si);\n        server.dirty++;\n        addReply(c,shared.ok);\n    }\n}\n\n/*-----------------------------------------------------------------------------\n * Expires API\n *----------------------------------------------------------------------------*/\n\nint removeExpire(redisDb *db, robj *key) {\n    return dictDelete(db->expires,key->ptr) == DICT_OK;\n}\n\n/* Set an expire to the specified key. If the expire is set in the context\n * of an user calling a command 'c' is the client, otherwise 'c' is set\n * to NULL. The 'when' parameter is the absolute unix time in milliseconds\n * after which the key will no longer be considered valid. */\nvoid setExpire(client *c, redisDb *db, robj *key, long long when) {\n    dictEntry *kde, *de;\n\n    /* Reuse the sds from the main dict in the expire dict */\n    kde = dictFind(db->dict,key->ptr);\n    serverAssertWithInfo(NULL,key,kde != NULL);\n    de = dictAddOrFind(db->expires,dictGetKey(kde));\n    dictSetSignedIntegerVal(de,when);\n\n    int writable_slave = server.masterhost && server.repl_slave_ro == 0;\n    if (c && writable_slave && !(c->flags & CLIENT_MASTER))\n        rememberSlaveKeyWithExpire(db,key);\n}\n\n/* Return the expire time of the specified key, or -1 if no expire\n * is associated with this key (i.e. the key is non volatile) */\nlong long getExpire(redisDb *db, robj *key) {\n    dictEntry *de;\n\n    /* No expire? return ASAP */\n    if (dictSize(db->expires) == 0 ||\n       (de = dictFind(db->expires,key->ptr)) == NULL) return -1;\n\n    return dictGetSignedIntegerVal(de);\n}\n\n/* Delete the specified expired key and propagate expire. */\nvoid deleteExpiredKeyAndPropagate(redisDb *db, robj *keyobj) {\n    mstime_t expire_latency;\n    latencyStartMonitor(expire_latency);\n    dbGenericDelete(db,keyobj,server.lazyfree_lazy_expire,DB_FLAG_KEY_EXPIRED);\n    latencyEndMonitor(expire_latency);\n    latencyAddSampleIfNeeded(\"expire-del\",expire_latency);\n    notifyKeyspaceEvent(NOTIFY_EXPIRED,\"expired\",keyobj,db->id);\n    signalModifiedKey(NULL, db, keyobj);\n    propagateDeletion(db,keyobj,server.lazyfree_lazy_expire);\n    server.stat_expiredkeys++;\n}\n\n/* Propagate expires into slaves and the AOF file.\n * When a key expires in the master, a DEL operation for this key is sent\n * to all the slaves and the AOF file if enabled.\n *\n * This way the key expiry is centralized in one place, and since both\n * AOF and the master->slave link guarantee operation ordering, everything\n * will be consistent even if we allow write operations against expiring\n * keys.\n *\n * This function may be called from:\n * 1. Within call(): Example: Lazy-expire on key access.\n *    In this case the caller doesn't have to do anything\n *    because call() handles server.also_propagate(); or\n * 2. Outside of call(): Example: Active-expire, eviction.\n *    In this the caller must remember to call\n *    postExecutionUnitOperations, preferably just after a\n *    single deletion batch, so that DELs will NOT be wrapped\n *    in MULTI/EXEC */\nvoid propagateDeletion(redisDb *db, robj *key, int lazy) {\n    robj *argv[2];\n\n    argv[0] = lazy ? shared.unlink : shared.del;\n    argv[1] = key;\n    incrRefCount(argv[0]);\n    incrRefCount(argv[1]);\n\n    /* If the master decided to expire a key we must propagate it to replicas no matter what..\n     * Even if module executed a command without asking for propagation. */\n    int prev_replication_allowed = server.replication_allowed;\n    server.replication_allowed = 1;\n    alsoPropagate(db->id,argv,2,PROPAGATE_AOF|PROPAGATE_REPL);\n    server.replication_allowed = prev_replication_allowed;\n\n    decrRefCount(argv[0]);\n    decrRefCount(argv[1]);\n}\n\n/* Check if the key is expired. */\nint keyIsExpired(redisDb *db, robj *key) {\n    /* Don't expire anything while loading. It will be done later. */\n    if (server.loading) return 0;\n\n    mstime_t when = getExpire(db,key);\n    mstime_t now;\n\n    if (when < 0) return 0; /* No expire for this key */\n\n    now = commandTimeSnapshot();\n\n    /* The key expired if the current (virtual or real) time is greater\n     * than the expire time of the key. */\n    return now > when;\n}\n\n/* This function is called when we are going to perform some operation\n * in a given key, but such key may be already logically expired even if\n * it still exists in the database. The main way this function is called\n * is via lookupKey*() family of functions.\n *\n * The behavior of the function depends on the replication role of the\n * instance, because by default replicas do not delete expired keys. They\n * wait for DELs from the master for consistency matters. However even\n * replicas will try to have a coherent return value for the function,\n * so that read commands executed in the replica side will be able to\n * behave like if the key is expired even if still present (because the\n * master has yet to propagate the DEL).\n *\n * In masters as a side effect of finding a key which is expired, such\n * key will be evicted from the database. Also this may trigger the\n * propagation of a DEL/UNLINK command in AOF / replication stream.\n *\n * On replicas, this function does not delete expired keys by default, but\n * it still returns 1 if the key is logically expired. To force deletion\n * of logically expired keys even on replicas, use the EXPIRE_FORCE_DELETE_EXPIRED\n * flag. Note though that if the current client is executing\n * replicated commands from the master, keys are never considered expired.\n *\n * On the other hand, if you just want expiration check, but need to avoid\n * the actual key deletion and propagation of the deletion, use the\n * EXPIRE_AVOID_DELETE_EXPIRED flag.\n *\n * The return value of the function is 0 if the key is still valid,\n * otherwise the function returns 1 if the key is expired. */\nint expireIfNeeded(redisDb *db, robj *key, int flags) {\n    if (server.lazy_expire_disabled) return 0;\n    if (!keyIsExpired(db,key)) return 0;\n\n    /* If we are running in the context of a replica, instead of\n     * evicting the expired key from the database, we return ASAP:\n     * the replica key expiration is controlled by the master that will\n     * send us synthesized DEL operations for expired keys. The\n     * exception is when write operations are performed on writable\n     * replicas.\n     *\n     * Still we try to return the right information to the caller,\n     * that is, 0 if we think the key should be still valid, 1 if\n     * we think the key is expired at this time.\n     *\n     * When replicating commands from the master, keys are never considered\n     * expired. */\n    if (server.masterhost != NULL) {\n        if (server.current_client && (server.current_client->flags & CLIENT_MASTER)) return 0;\n        if (!(flags & EXPIRE_FORCE_DELETE_EXPIRED)) return 1;\n    }\n\n    /* In some cases we're explicitly instructed to return an indication of a\n     * missing key without actually deleting it, even on masters. */\n    if (flags & EXPIRE_AVOID_DELETE_EXPIRED)\n        return 1;\n\n    /* If 'expire' action is paused, for whatever reason, then don't expire any key.\n     * Typically, at the end of the pause we will properly expire the key OR we\n     * will have failed over and the new primary will send us the expire. */\n    if (isPausedActionsWithUpdate(PAUSE_ACTION_EXPIRE)) return 1;\n\n    /* The key needs to be converted from static to heap before deleted */\n    int static_key = key->refcount == OBJ_STATIC_REFCOUNT;\n    if (static_key) {\n        key = createStringObject(key->ptr, sdslen(key->ptr));\n    }\n    /* Delete the key */\n    deleteExpiredKeyAndPropagate(db,key);\n    if (static_key) {\n        decrRefCount(key);\n    }\n    return 1;\n}\n\n/* -----------------------------------------------------------------------------\n * API to get key arguments from commands\n * ---------------------------------------------------------------------------*/\n\n/* Prepare the getKeysResult struct to hold numkeys, either by using the\n * pre-allocated keysbuf or by allocating a new array on the heap.\n *\n * This function must be called at least once before starting to populate\n * the result, and can be called repeatedly to enlarge the result array.\n */\nkeyReference *getKeysPrepareResult(getKeysResult *result, int numkeys) {\n    /* GETKEYS_RESULT_INIT initializes keys to NULL, point it to the pre-allocated stack\n     * buffer here. */\n    if (!result->keys) {\n        serverAssert(!result->numkeys);\n        result->keys = result->keysbuf;\n    }\n\n    /* Resize if necessary */\n    if (numkeys > result->size) {\n        if (result->keys != result->keysbuf) {\n            /* We're not using a static buffer, just (re)alloc */\n            result->keys = zrealloc(result->keys, numkeys * sizeof(keyReference));\n        } else {\n            /* We are using a static buffer, copy its contents */\n            result->keys = zmalloc(numkeys * sizeof(keyReference));\n            if (result->numkeys)\n                memcpy(result->keys, result->keysbuf, result->numkeys * sizeof(keyReference));\n        }\n        result->size = numkeys;\n    }\n\n    return result->keys;\n}\n\n/* Returns a bitmask with all the flags found in any of the key specs of the command.\n * The 'inv' argument means we'll return a mask with all flags that are missing in at least one spec. */\nint64_t getAllKeySpecsFlags(struct redisCommand *cmd, int inv) {\n    int64_t flags = 0;\n    for (int j = 0; j < cmd->key_specs_num; j++) {\n        keySpec *spec = cmd->key_specs + j;\n        flags |= inv? ~spec->flags : spec->flags;\n    }\n    return flags;\n}\n\n/* Fetch the keys based of the provided key specs. Returns the number of keys found, or -1 on error.\n * There are several flags that can be used to modify how this function finds keys in a command.\n * \n * GET_KEYSPEC_INCLUDE_NOT_KEYS: Return 'fake' keys as if they were keys.\n * GET_KEYSPEC_RETURN_PARTIAL:   Skips invalid and incomplete keyspecs but returns the keys\n *                               found in other valid keyspecs. \n */\nint getKeysUsingKeySpecs(struct redisCommand *cmd, robj **argv, int argc, int search_flags, getKeysResult *result) {\n    int j, i, last, first, step;\n    keyReference *keys;\n    serverAssert(result->numkeys == 0); /* caller should initialize or reset it */\n\n    for (j = 0; j < cmd->key_specs_num; j++) {\n        keySpec *spec = cmd->key_specs + j;\n        serverAssert(spec->begin_search_type != KSPEC_BS_INVALID);\n        /* Skip specs that represent 'fake' keys */\n        if ((spec->flags & CMD_KEY_NOT_KEY) && !(search_flags & GET_KEYSPEC_INCLUDE_NOT_KEYS)) {\n            continue;\n        }\n\n        first = 0;\n        if (spec->begin_search_type == KSPEC_BS_INDEX) {\n            first = spec->bs.index.pos;\n        } else if (spec->begin_search_type == KSPEC_BS_KEYWORD) {\n            int start_index = spec->bs.keyword.startfrom > 0 ? spec->bs.keyword.startfrom : argc+spec->bs.keyword.startfrom;\n            int end_index = spec->bs.keyword.startfrom > 0 ? argc-1: 1;\n            for (i = start_index; i != end_index; i = start_index <= end_index ? i + 1 : i - 1) {\n                if (i >= argc || i < 1)\n                    break;\n                if (!strcasecmp((char*)argv[i]->ptr,spec->bs.keyword.keyword)) {\n                    first = i+1;\n                    break;\n                }\n            }\n            /* keyword not found */\n            if (!first) {\n                continue;\n            }\n        } else {\n            /* unknown spec */\n            goto invalid_spec;\n        }\n\n        if (spec->find_keys_type == KSPEC_FK_RANGE) {\n            step = spec->fk.range.keystep;\n            if (spec->fk.range.lastkey >= 0) {\n                last = first + spec->fk.range.lastkey;\n            } else {\n                if (!spec->fk.range.limit) {\n                    last = argc + spec->fk.range.lastkey;\n                } else {\n                    serverAssert(spec->fk.range.lastkey == -1);\n                    last = first + ((argc-first)/spec->fk.range.limit + spec->fk.range.lastkey);\n                }\n            }\n        } else if (spec->find_keys_type == KSPEC_FK_KEYNUM) {\n            step = spec->fk.keynum.keystep;\n            long long numkeys;\n            if (spec->fk.keynum.keynumidx >= argc)\n                goto invalid_spec;\n\n            sds keynum_str = argv[first + spec->fk.keynum.keynumidx]->ptr;\n            if (!string2ll(keynum_str,sdslen(keynum_str),&numkeys) || numkeys < 0) {\n                /* Unable to parse the numkeys argument or it was invalid */\n                goto invalid_spec;\n            }\n\n            first += spec->fk.keynum.firstkey;\n            last = first + (int)numkeys-1;\n        } else {\n            /* unknown spec */\n            goto invalid_spec;\n        }\n\n        int count = ((last - first)+1);\n        keys = getKeysPrepareResult(result, result->numkeys + count);\n\n        /* First or last is out of bounds, which indicates a syntax error */\n        if (last >= argc || last < first || first >= argc) {\n            goto invalid_spec;\n        }\n\n        for (i = first; i <= last; i += step) {\n            if (i >= argc || i < first) {\n                /* Modules commands, and standard commands with a not fixed number\n                 * of arguments (negative arity parameter) do not have dispatch\n                 * time arity checks, so we need to handle the case where the user\n                 * passed an invalid number of arguments here. In this case we\n                 * return no keys and expect the command implementation to report\n                 * an arity or syntax error. */\n                if (cmd->flags & CMD_MODULE || cmd->arity < 0) {\n                    continue;\n                } else {\n                    serverPanic(\"Redis built-in command declared keys positions not matching the arity requirements.\");\n                }\n            }\n            keys[result->numkeys].pos = i;\n            keys[result->numkeys].flags = spec->flags;\n            result->numkeys++;\n        }\n\n        /* Handle incomplete specs (only after we added the current spec\n         * to `keys`, just in case GET_KEYSPEC_RETURN_PARTIAL was given) */\n        if (spec->flags & CMD_KEY_INCOMPLETE) {\n            goto invalid_spec;\n        }\n\n        /* Done with this spec */\n        continue;\n\ninvalid_spec:\n        if (search_flags & GET_KEYSPEC_RETURN_PARTIAL) {\n            continue;\n        } else {\n            result->numkeys = 0;\n            return -1;\n        }\n    }\n\n    return result->numkeys;\n}\n\n/* Return all the arguments that are keys in the command passed via argc / argv. \n * This function will eventually replace getKeysFromCommand.\n *\n * The command returns the positions of all the key arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n * \n * Along with the position, this command also returns the flags that are\n * associated with how Redis will access the key.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0]. */\nint getKeysFromCommandWithSpecs(struct redisCommand *cmd, robj **argv, int argc, int search_flags, getKeysResult *result) {\n    /* The command has at least one key-spec not marked as NOT_KEY */\n    int has_keyspec = (getAllKeySpecsFlags(cmd, 1) & CMD_KEY_NOT_KEY);\n    /* The command has at least one key-spec marked as VARIABLE_FLAGS */\n    int has_varflags = (getAllKeySpecsFlags(cmd, 0) & CMD_KEY_VARIABLE_FLAGS);\n\n    /* We prefer key-specs if there are any, and their flags are reliable. */\n    if (has_keyspec && !has_varflags) {\n        int ret = getKeysUsingKeySpecs(cmd,argv,argc,search_flags,result);\n        if (ret >= 0)\n            return ret;\n        /* If the specs returned with an error (probably an INVALID or INCOMPLETE spec),\n         * fallback to the callback method. */\n    }\n\n    /* Resort to getkeys callback methods. */\n    if (cmd->flags & CMD_MODULE_GETKEYS)\n        return moduleGetCommandKeysViaAPI(cmd,argv,argc,result);\n\n    /* We use native getkeys as a last resort, since not all these native getkeys provide\n     * flags properly (only the ones that correspond to INVALID, INCOMPLETE or VARIABLE_FLAGS do.*/\n    if (cmd->getkeys_proc)\n        return cmd->getkeys_proc(cmd,argv,argc,result);\n    return 0;\n}\n\n/* This function returns a sanity check if the command may have keys. */\nint doesCommandHaveKeys(struct redisCommand *cmd) {\n    return cmd->getkeys_proc ||                                 /* has getkeys_proc (non modules) */\n        (cmd->flags & CMD_MODULE_GETKEYS) ||                    /* module with GETKEYS */\n        (getAllKeySpecsFlags(cmd, 1) & CMD_KEY_NOT_KEY);        /* has at least one key-spec not marked as NOT_KEY */\n}\n\n/* A simplified channel spec table that contains all of the redis commands\n * and which channels they have and how they are accessed. */\ntypedef struct ChannelSpecs {\n    redisCommandProc *proc; /* Command procedure to match against */\n    uint64_t flags;         /* CMD_CHANNEL_* flags for this command */\n    int start;              /* The initial position of the first channel */\n    int count;              /* The number of channels, or -1 if all remaining\n                             * arguments are channels. */\n} ChannelSpecs;\n\nChannelSpecs commands_with_channels[] = {\n    {subscribeCommand, CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {ssubscribeCommand, CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {unsubscribeCommand, CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {sunsubscribeCommand, CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {psubscribeCommand, CMD_CHANNEL_PATTERN | CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {punsubscribeCommand, CMD_CHANNEL_PATTERN | CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {publishCommand, CMD_CHANNEL_PUBLISH, 1, 1},\n    {spublishCommand, CMD_CHANNEL_PUBLISH, 1, 1},\n    {NULL,0} /* Terminator. */\n};\n\n/* Returns 1 if the command may access any channels matched by the flags\n * argument. */\nint doesCommandHaveChannelsWithFlags(struct redisCommand *cmd, int flags) {\n    /* If a module declares get channels, we are just going to assume\n     * has channels. This API is allowed to return false positives. */\n    if (cmd->flags & CMD_MODULE_GETCHANNELS) {\n        return 1;\n    }\n    for (ChannelSpecs *spec = commands_with_channels; spec->proc != NULL; spec += 1) {\n        if (cmd->proc == spec->proc) {\n            return !!(spec->flags & flags);\n        }\n    }\n    return 0;\n}\n\n/* Return all the arguments that are channels in the command passed via argc / argv. \n * This function behaves similar to getKeysFromCommandWithSpecs, but with channels \n * instead of keys.\n * \n * The command returns the positions of all the channel arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n * \n * Along with the position, this command also returns the flags that are\n * associated with how Redis will access the channel.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0]. */\nint getChannelsFromCommand(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    /* If a module declares get channels, use that. */\n    if (cmd->flags & CMD_MODULE_GETCHANNELS) {\n        return moduleGetCommandChannelsViaAPI(cmd, argv, argc, result);\n    }\n    /* Otherwise check the channel spec table */\n    for (ChannelSpecs *spec = commands_with_channels; spec != NULL; spec += 1) {\n        if (cmd->proc == spec->proc) {\n            int start = spec->start;\n            int stop = (spec->count == -1) ? argc : start + spec->count;\n            if (stop > argc) stop = argc;\n            int count = 0;\n            keys = getKeysPrepareResult(result, stop - start);\n            for (int i = start; i < stop; i++ ) {\n                keys[count].pos = i;\n                keys[count++].flags = spec->flags;\n            }\n            result->numkeys = count;\n            return count;\n        }\n    }\n    return 0;\n}\n\n/* The base case is to use the keys position as given in the command table\n * (firstkey, lastkey, step).\n * This function works only on command with the legacy_range_key_spec,\n * all other commands should be handled by getkeys_proc. \n * \n * If the commands keyspec is incomplete, no keys will be returned, and the provided\n * keys function should be called instead.\n * \n * NOTE: This function does not guarantee populating the flags for \n * the keys, in order to get flags you should use getKeysUsingKeySpecs. */\nint getKeysUsingLegacyRangeSpec(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int j, i = 0, last, first, step;\n    keyReference *keys;\n    UNUSED(argv);\n\n    if (cmd->legacy_range_key_spec.begin_search_type == KSPEC_BS_INVALID) {\n        result->numkeys = 0;\n        return 0;\n    }\n\n    first = cmd->legacy_range_key_spec.bs.index.pos;\n    last = cmd->legacy_range_key_spec.fk.range.lastkey;\n    if (last >= 0)\n        last += first;\n    step = cmd->legacy_range_key_spec.fk.range.keystep;\n\n    if (last < 0) last = argc+last;\n\n    int count = ((last - first)+1);\n    keys = getKeysPrepareResult(result, count);\n\n    for (j = first; j <= last; j += step) {\n        if (j >= argc || j < first) {\n            /* Modules commands, and standard commands with a not fixed number\n             * of arguments (negative arity parameter) do not have dispatch\n             * time arity checks, so we need to handle the case where the user\n             * passed an invalid number of arguments here. In this case we\n             * return no keys and expect the command implementation to report\n             * an arity or syntax error. */\n            if (cmd->flags & CMD_MODULE || cmd->arity < 0) {\n                result->numkeys = 0;\n                return 0;\n            } else {\n                serverPanic(\"Redis built-in command declared keys positions not matching the arity requirements.\");\n            }\n        }\n        keys[i].pos = j;\n        /* Flags are omitted from legacy key specs */\n        keys[i++].flags = 0;\n    }\n    result->numkeys = i;\n    return i;\n}\n\n/* Return all the arguments that are keys in the command passed via argc / argv.\n *\n * The command returns the positions of all the key arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0].\n *\n * This function uses the command table if a command-specific helper function\n * is not required, otherwise it calls the command-specific function. */\nint getKeysFromCommand(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    if (cmd->flags & CMD_MODULE_GETKEYS) {\n        return moduleGetCommandKeysViaAPI(cmd,argv,argc,result);\n    } else if (cmd->getkeys_proc) {\n        return cmd->getkeys_proc(cmd,argv,argc,result);\n    } else {\n        return getKeysUsingLegacyRangeSpec(cmd,argv,argc,result);\n    }\n}\n\n/* Free the result of getKeysFromCommand. */\nvoid getKeysFreeResult(getKeysResult *result) {\n    if (result && result->keys != result->keysbuf)\n        zfree(result->keys);\n}\n\n/* Helper function to extract keys from following commands:\n * COMMAND [destkey] <num-keys> <key> [...] <key> [...] ... <options>\n *\n * eg:\n * ZUNION <num-keys> <key> <key> ... <key> <options>\n * ZUNIONSTORE <destkey> <num-keys> <key> <key> ... <key> <options>\n *\n * 'storeKeyOfs': destkey index, 0 means destkey not exists.\n * 'keyCountOfs': num-keys index.\n * 'firstKeyOfs': firstkey index.\n * 'keyStep': the interval of each key, usually this value is 1.\n * \n * The commands using this function have a fully defined keyspec, so returning flags isn't needed. */\nint genericGetKeys(int storeKeyOfs, int keyCountOfs, int firstKeyOfs, int keyStep,\n                    robj **argv, int argc, getKeysResult *result) {\n    int i, num;\n    keyReference *keys;\n\n    num = atoi(argv[keyCountOfs]->ptr);\n    /* Sanity check. Don't return any key if the command is going to\n     * reply with syntax error. (no input keys). */\n    if (num < 1 || num > (argc - firstKeyOfs)/keyStep) {\n        result->numkeys = 0;\n        return 0;\n    }\n\n    int numkeys = storeKeyOfs ? num + 1 : num;\n    keys = getKeysPrepareResult(result, numkeys);\n    result->numkeys = numkeys;\n\n    /* Add all key positions for argv[firstKeyOfs...n] to keys[] */\n    for (i = 0; i < num; i++) {\n        keys[i].pos = firstKeyOfs+(i*keyStep);\n        keys[i].flags = 0;\n    } \n\n    if (storeKeyOfs) {\n        keys[num].pos = storeKeyOfs;\n        keys[num].flags = 0;\n    } \n    return result->numkeys;\n}\n\nint sintercardGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint zunionInterDiffStoreGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(1, 2, 3, 1, argv, argc, result);\n}\n\nint zunionInterDiffGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint evalGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint functionGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint lmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint blmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint zmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint bzmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\n/* Helper function to extract keys from the SORT RO command.\n *\n * SORT <sort-key>\n *\n * The second argument of SORT is always a key, however an arbitrary number of\n * keys may be accessed while doing the sort (the BY and GET args), so the\n * key-spec declares incomplete keys which is why we have to provide a concrete\n * implementation to fetch the keys.\n *\n * This command declares incomplete keys, so the flags are correctly set for this function */\nint sortROGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n    UNUSED(argv);\n    UNUSED(argc);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* <sort-key> is always present. */\n    keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    return 1;\n}\n\n/* Helper function to extract keys from the SORT command.\n *\n * SORT <sort-key> ... STORE <store-key> ...\n *\n * The first argument of SORT is always a key, however a list of options\n * follow in SQL-alike style. Here we parse just the minimum in order to\n * correctly identify keys in the \"STORE\" option. \n * \n * This command declares incomplete keys, so the flags are correctly set for this function */\nint sortGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, j, num, found_store = 0;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    num = 0;\n    keys = getKeysPrepareResult(result, 2); /* Alloc 2 places for the worst case. */\n    keys[num].pos = 1; /* <sort-key> is always present. */\n    keys[num++].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n\n    /* Search for STORE option. By default we consider options to don't\n     * have arguments, so if we find an unknown option name we scan the\n     * next. However there are options with 1 or 2 arguments, so we\n     * provide a list here in order to skip the right number of args. */\n    struct {\n        char *name;\n        int skip;\n    } skiplist[] = {\n        {\"limit\", 2},\n        {\"get\", 1},\n        {\"by\", 1},\n        {NULL, 0} /* End of elements. */\n    };\n\n    for (i = 2; i < argc; i++) {\n        for (j = 0; skiplist[j].name != NULL; j++) {\n            if (!strcasecmp(argv[i]->ptr,skiplist[j].name)) {\n                i += skiplist[j].skip;\n                break;\n            } else if (!strcasecmp(argv[i]->ptr,\"store\") && i+1 < argc) {\n                /* Note: we don't increment \"num\" here and continue the loop\n                 * to be sure to process the *last* \"STORE\" option if multiple\n                 * ones are provided. This is same behavior as SORT. */\n                found_store = 1;\n                keys[num].pos = i+1; /* <store-key> */\n                keys[num].flags = CMD_KEY_OW | CMD_KEY_UPDATE;\n                break;\n            }\n        }\n    }\n    result->numkeys = num + found_store;\n    return result->numkeys;\n}\n\n/* This command declares incomplete keys, so the flags are correctly set for this function */\nint migrateGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, j, num, first;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* Assume the obvious form. */\n    first = 3;\n    num = 1;\n\n    /* But check for the extended one with the KEYS option. */\n    struct {\n        char* name;\n        int skip;\n    } skip_keywords[] = {       \n        {\"copy\", 0},\n        {\"replace\", 0},\n        {\"auth\", 1},\n        {\"auth2\", 2},\n        {NULL, 0}\n    };\n    if (argc > 6) {\n        for (i = 6; i < argc; i++) {\n            if (!strcasecmp(argv[i]->ptr, \"keys\")) {\n                if (sdslen(argv[3]->ptr) > 0) {\n                    /* This is a syntax error. So ignore the keys and leave\n                     * the syntax error to be handled by migrateCommand. */\n                    num = 0; \n                } else {\n                    first = i + 1;\n                    num = argc - first;\n                }\n                break;\n            }\n            for (j = 0; skip_keywords[j].name != NULL; j++) {\n                if (!strcasecmp(argv[i]->ptr, skip_keywords[j].name)) {\n                    i += skip_keywords[j].skip;\n                    break;\n                }\n            }\n        }\n    }\n\n    keys = getKeysPrepareResult(result, num);\n    for (i = 0; i < num; i++) {\n        keys[i].pos = first+i;\n        keys[i].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_DELETE;\n    } \n    result->numkeys = num;\n    return num;\n}\n\n/* Helper function to extract keys from following commands:\n * GEORADIUS key x y radius unit [WITHDIST] [WITHHASH] [WITHCOORD] [ASC|DESC]\n *                             [COUNT count] [STORE key|STOREDIST key]\n * GEORADIUSBYMEMBER key member radius unit ... options ...\n * \n * This command has a fully defined keyspec, so returning flags isn't needed. */\nint georadiusGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, num;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* Check for the presence of the stored key in the command */\n    int stored_key = -1;\n    for (i = 5; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        /* For the case when user specifies both \"store\" and \"storedist\" options, the\n         * second key specified would override the first key. This behavior is kept\n         * the same as in georadiusCommand method.\n         */\n        if ((!strcasecmp(arg, \"store\") || !strcasecmp(arg, \"storedist\")) && ((i+1) < argc)) {\n            stored_key = i+1;\n            i++;\n        }\n    }\n    num = 1 + (stored_key == -1 ? 0 : 1);\n\n    /* Keys in the command come from two places:\n     * argv[1] = key,\n     * argv[5...n] = stored key if present\n     */\n    keys = getKeysPrepareResult(result, num);\n\n    /* Add all key positions to keys[] */\n    keys[0].pos = 1;\n    keys[0].flags = 0;\n    if(num > 1) {\n         keys[1].pos = stored_key;\n         keys[1].flags = 0;\n    }\n    result->numkeys = num;\n    return num;\n}\n\n/* XREAD [BLOCK <milliseconds>] [COUNT <count>] [GROUP <groupname> <ttl>]\n *       STREAMS key_1 key_2 ... key_N ID_1 ID_2 ... ID_N\n *\n * This command has a fully defined keyspec, so returning flags isn't needed. */\nint xreadGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, num = 0;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* We need to parse the options of the command in order to seek the first\n     * \"STREAMS\" string which is actually the option. This is needed because\n     * \"STREAMS\" could also be the name of the consumer group and even the\n     * name of the stream key. */\n    int streams_pos = -1;\n    for (i = 1; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        if (!strcasecmp(arg, \"block\")) {\n            i++; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"count\")) {\n            i++; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"group\")) {\n            i += 2; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"noack\")) {\n            /* Nothing to do. */\n        } else if (!strcasecmp(arg, \"streams\")) {\n            streams_pos = i;\n            break;\n        } else {\n            break; /* Syntax error. */\n        }\n    }\n    if (streams_pos != -1) num = argc - streams_pos - 1;\n\n    /* Syntax error. */\n    if (streams_pos == -1 || num == 0 || num % 2 != 0) {\n        result->numkeys = 0;\n        return 0;\n    }\n    num /= 2; /* We have half the keys as there are arguments because\n                 there are also the IDs, one per key. */\n\n    keys = getKeysPrepareResult(result, num);\n    for (i = streams_pos+1; i < argc-num; i++) {\n        keys[i-streams_pos-1].pos = i;\n        keys[i-streams_pos-1].flags = 0; \n    } \n    result->numkeys = num;\n    return num;\n}\n\n/* Helper function to extract keys from the SET command, which may have\n * a read flag if the GET argument is passed in. */\nint setGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* We always know the position */\n    result->numkeys = 1;\n\n    for (int i = 3; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        if ((arg[0] == 'g' || arg[0] == 'G') &&\n            (arg[1] == 'e' || arg[1] == 'E') &&\n            (arg[2] == 't' || arg[2] == 'T') && arg[3] == '\\0')\n        {\n            keys[0].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_UPDATE;\n            return 1;\n        }\n    }\n\n    keys[0].flags = CMD_KEY_OW | CMD_KEY_UPDATE;\n    return 1;\n}\n\n/* Helper function to extract keys from the BITFIELD command, which may be\n * read-only if the BITFIELD GET subcommand is used. */\nint bitfieldGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    int readonly = 1;\n    UNUSED(cmd);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* We always know the position */\n    result->numkeys = 1;\n\n    for (int i = 2; i < argc; i++) {\n        int remargs = argc - i - 1; /* Remaining args other than current. */\n        char *arg = argv[i]->ptr;\n        if (!strcasecmp(arg, \"get\") && remargs >= 2) {\n            i += 2;\n        } else if ((!strcasecmp(arg, \"set\") || !strcasecmp(arg, \"incrby\")) && remargs >= 3) {\n            readonly = 0;\n            i += 3;\n            break;\n        } else if (!strcasecmp(arg, \"overflow\") && remargs >= 1) {\n            i += 1;\n        } else {\n            readonly = 0; /* Syntax error. safer to assume non-RO. */\n            break;\n        }\n    }\n\n    if (readonly) {\n        keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    } else {\n        keys[0].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_UPDATE;\n    }\n    return 1;\n}\n", "start_server {\n    tags {\"sort\"}\n    overrides {\n        \"list-max-ziplist-size\" 16\n        \"set-max-intset-entries\" 32\n    }\n} {\n    proc create_random_dataset {num cmd} {\n        set tosort {}\n        set result {}\n        array set seenrand {}\n        r del tosort\n        for {set i 0} {$i < $num} {incr i} {\n            # Make sure all the weights are different because\n            # Redis does not use a stable sort but Tcl does.\n            while 1 {\n                randpath {\n                    set rint [expr int(rand()*1000000)]\n                } {\n                    set rint [expr rand()]\n                }\n                if {![info exists seenrand($rint)]} break\n            }\n            set seenrand($rint) x\n            r $cmd tosort $i\n            r set weight_$i $rint\n            r hset wobj_$i weight $rint\n            lappend tosort [list $i $rint]\n        }\n        set sorted [lsort -index 1 -real $tosort]\n        for {set i 0} {$i < $num} {incr i} {\n            lappend result [lindex $sorted $i 0]\n        }\n        set _ $result\n    }\n\n    proc check_sort_store_encoding {key} {\n        set listpack_max_size [lindex [r config get list-max-ziplist-size] 1]\n\n        # When the length or size of quicklist is less than the limit,\n        # it will be converted to listpack.\n        if {[r llen $key] <= $listpack_max_size} {\n            assert_encoding listpack $key\n        } else {\n            assert_encoding quicklist $key\n        }\n    }\n\n    foreach {num cmd enc title} {\n        16 lpush listpack \"Listpack\"\n        1000 lpush quicklist \"Quicklist\"\n        10000 lpush quicklist \"Big Quicklist\"\n        16 sadd intset \"Intset\"\n        1000 sadd hashtable \"Hash table\"\n        10000 sadd hashtable \"Big Hash table\"\n    } {\n        set result [create_random_dataset $num $cmd]\n        assert_encoding $enc tosort\n\n        test \"$title: SORT BY key\" {\n            assert_equal $result [r sort tosort BY weight_*]\n        } {} {cluster:skip}\n\n        test \"$title: SORT BY key with limit\" {\n            assert_equal [lrange $result 5 9] [r sort tosort BY weight_* LIMIT 5 5]\n        } {} {cluster:skip}\n\n        test \"$title: SORT BY hash field\" {\n            assert_equal $result [r sort tosort BY wobj_*->weight]\n        } {} {cluster:skip}\n    }\n\n    set result [create_random_dataset 16 lpush]\n    test \"SORT GET #\" {\n        assert_equal [lsort -integer $result] [r sort tosort GET #]\n    } {} {cluster:skip}\n\n    test \"SORT GET <const>\" {\n        r del foo\n        set res [r sort tosort GET foo]\n        assert_equal 16 [llength $res]\n        foreach item $res { assert_equal {} $item }\n    } {} {cluster:skip}\n\n    test \"SORT GET (key and hash) with sanity check\" {\n        set l1 [r sort tosort GET # GET weight_*]\n        set l2 [r sort tosort GET # GET wobj_*->weight]\n        foreach {id1 w1} $l1 {id2 w2} $l2 {\n            assert_equal $id1 $id2\n            assert_equal $w1 [r get weight_$id1]\n            assert_equal $w2 [r get weight_$id1]\n        }\n    } {} {cluster:skip}\n\n    test \"SORT BY key STORE\" {\n        r sort tosort BY weight_* store sort-res\n        assert_equal $result [r lrange sort-res 0 -1]\n        assert_equal 16 [r llen sort-res]\n        check_sort_store_encoding sort-res\n    } {} {cluster:skip}\n\n    test \"SORT BY hash field STORE\" {\n        r sort tosort BY wobj_*->weight store sort-res\n        assert_equal $result [r lrange sort-res 0 -1]\n        assert_equal 16 [r llen sort-res]\n        check_sort_store_encoding sort-res\n    } {} {cluster:skip}\n\n    test \"SORT extracts STORE correctly\" {\n        r command getkeys sort abc store def\n    } {abc def}\n\n    test \"SORT extracts multiple STORE correctly\" {\n        r command getkeys sort abc store invalid store stillbad store def\n    } {abc def}\n\n    test \"SORT DESC\" {\n        assert_equal [lsort -decreasing -integer $result] [r sort tosort DESC]\n    }\n\n    test \"SORT ALPHA against integer encoded strings\" {\n        r del mylist\n        r lpush mylist 2\n        r lpush mylist 1\n        r lpush mylist 3\n        r lpush mylist 10\n        r sort mylist alpha\n    } {1 10 2 3}\n\n    test \"SORT sorted set\" {\n        r del zset\n        r zadd zset 1 a\n        r zadd zset 5 b\n        r zadd zset 2 c\n        r zadd zset 10 d\n        r zadd zset 3 e\n        r sort zset alpha desc\n    } {e d c b a}\n\n    test \"SORT sorted set BY nosort should retain ordering\" {\n        r del zset\n        r zadd zset 1 a\n        r zadd zset 5 b\n        r zadd zset 2 c\n        r zadd zset 10 d\n        r zadd zset 3 e\n        r multi\n        r sort zset by nosort asc\n        r sort zset by nosort desc\n        r exec\n    } {{a c e b d} {d b e c a}}\n\n    test \"SORT sorted set BY nosort + LIMIT\" {\n        r del zset\n        r zadd zset 1 a\n        r zadd zset 5 b\n        r zadd zset 2 c\n        r zadd zset 10 d\n        r zadd zset 3 e\n        assert_equal [r sort zset by nosort asc limit 0 1] {a}\n        assert_equal [r sort zset by nosort desc limit 0 1] {d}\n        assert_equal [r sort zset by nosort asc limit 0 2] {a c}\n        assert_equal [r sort zset by nosort desc limit 0 2] {d b}\n        assert_equal [r sort zset by nosort limit 5 10] {}\n        assert_equal [r sort zset by nosort limit -10 100] {a c e b d}\n    }\n\n    test \"SORT sorted set BY nosort works as expected from scripts\" {\n        r del zset\n        r zadd zset 1 a\n        r zadd zset 5 b\n        r zadd zset 2 c\n        r zadd zset 10 d\n        r zadd zset 3 e\n        r eval {\n            return {redis.call('sort',KEYS[1],'by','nosort','asc'),\n                    redis.call('sort',KEYS[1],'by','nosort','desc')}\n        } 1 zset\n    } {{a c e b d} {d b e c a}}\n\n    test \"SORT sorted set: +inf and -inf handling\" {\n        r del zset\n        r zadd zset -100 a\n        r zadd zset 200 b\n        r zadd zset -300 c\n        r zadd zset 1000000 d\n        r zadd zset +inf max\n        r zadd zset -inf min\n        r zrange zset 0 -1\n    } {min c a b d max}\n\n    test \"SORT regression for issue #19, sorting floats\" {\n        r flushdb\n        set floats {1.1 5.10 3.10 7.44 2.1 5.75 6.12 0.25 1.15}\n        foreach x $floats {\n            r lpush mylist $x\n        }\n        assert_equal [lsort -real $floats] [r sort mylist]\n    }\n\n    test \"SORT with STORE returns zero if result is empty (github issue 224)\" {\n        r flushdb\n        r sort foo{t} store bar{t}\n    } {0}\n\n    test \"SORT with STORE does not create empty lists (github issue 224)\" {\n        r flushdb\n        r lpush foo{t} bar\n        r sort foo{t} alpha limit 10 10 store zap{t}\n        r exists zap{t}\n    } {0}\n\n    test \"SORT with STORE removes key if result is empty (github issue 227)\" {\n        r flushdb\n        r lpush foo{t} bar\n        r sort emptylist{t} store foo{t}\n        r exists foo{t}\n    } {0}\n\n    test \"SORT with BY <constant> and STORE should still order output\" {\n        r del myset mylist\n        r sadd myset a b c d e f g h i l m n o p q r s t u v z aa aaa azz\n        r sort myset alpha by _ store mylist\n        r lrange mylist 0 -1\n    } {a aa aaa azz b c d e f g h i l m n o p q r s t u v z} {cluster:skip}\n\n    test \"SORT will complain with numerical sorting and bad doubles (1)\" {\n        r del myset\n        r sadd myset 1 2 3 4 not-a-double\n        set e {}\n        catch {r sort myset} e\n        set e\n    } {*ERR*double*}\n\n    test \"SORT will complain with numerical sorting and bad doubles (2)\" {\n        r del myset\n        r sadd myset 1 2 3 4\n        r mset score:1 10 score:2 20 score:3 30 score:4 not-a-double\n        set e {}\n        catch {r sort myset by score:*} e\n        set e\n    } {*ERR*double*} {cluster:skip}\n\n    test \"SORT BY sub-sorts lexicographically if score is the same\" {\n        r del myset\n        r sadd myset a b c d e f g h i l m n o p q r s t u v z aa aaa azz\n        foreach ele {a aa aaa azz b c d e f g h i l m n o p q r s t u v z} {\n            set score:$ele 100\n        }\n        r sort myset by score:*\n    } {a aa aaa azz b c d e f g h i l m n o p q r s t u v z} {cluster:skip}\n\n    test \"SORT GET with pattern ending with just -> does not get hash field\" {\n        r del mylist\n        r lpush mylist a\n        r set x:a-> 100\n        r sort mylist by num get x:*->\n    } {100} {cluster:skip}\n\n    test \"SORT by nosort retains native order for lists\" {\n        r del testa\n        r lpush testa 2 1 4 3 5\n        r sort testa by nosort\n    } {5 3 4 1 2} {cluster:skip}\n\n    test \"SORT by nosort plus store retains native order for lists\" {\n        r del testa\n        r lpush testa 2 1 4 3 5\n        r sort testa by nosort store testb\n        r lrange testb 0 -1\n    } {5 3 4 1 2} {cluster:skip}\n\n    test \"SORT by nosort with limit returns based on original list order\" {\n        r sort testa by nosort limit 0 3 store testb\n        r lrange testb 0 -1\n    } {5 3 4} {cluster:skip}\n\n    test \"SORT_RO - Successful case\" {\n        r del mylist\n        r lpush mylist a\n        r set x:a 100\n        r sort_ro mylist by nosort get x:*->\n    } {100} {cluster:skip}\n\n    test \"SORT_RO - Cannot run with STORE arg\" {\n        catch {r sort_ro foolist STORE bar} e\n        set e\n    } {ERR syntax error}\n\n    tags {\"slow\"} {\n        set num 100\n        set res [create_random_dataset $num lpush]\n\n        test \"SORT speed, $num element list BY key, 100 times\" {\n            set start [clock clicks -milliseconds]\n            for {set i 0} {$i < 100} {incr i} {\n                set sorted [r sort tosort BY weight_* LIMIT 0 10]\n            }\n            set elapsed [expr [clock clicks -milliseconds]-$start]\n            if {$::verbose} {\n                puts -nonewline \"\\n  Average time to sort: [expr double($elapsed)/100] milliseconds \"\n                flush stdout\n            }\n        } {} {cluster:skip}\n\n        test \"SORT speed, $num element list BY hash field, 100 times\" {\n            set start [clock clicks -milliseconds]\n            for {set i 0} {$i < 100} {incr i} {\n                set sorted [r sort tosort BY wobj_*->weight LIMIT 0 10]\n            }\n            set elapsed [expr [clock clicks -milliseconds]-$start]\n            if {$::verbose} {\n                puts -nonewline \"\\n  Average time to sort: [expr double($elapsed)/100] milliseconds \"\n                flush stdout\n            }\n        } {} {cluster:skip}\n\n        test \"SORT speed, $num element list directly, 100 times\" {\n            set start [clock clicks -milliseconds]\n            for {set i 0} {$i < 100} {incr i} {\n                set sorted [r sort tosort LIMIT 0 10]\n            }\n            set elapsed [expr [clock clicks -milliseconds]-$start]\n            if {$::verbose} {\n                puts -nonewline \"\\n  Average time to sort: [expr double($elapsed)/100] milliseconds \"\n                flush stdout\n            }\n        }\n\n        test \"SORT speed, $num element list BY <const>, 100 times\" {\n            set start [clock clicks -milliseconds]\n            for {set i 0} {$i < 100} {incr i} {\n                set sorted [r sort tosort BY nokey LIMIT 0 10]\n            }\n            set elapsed [expr [clock clicks -milliseconds]-$start]\n            if {$::verbose} {\n                puts -nonewline \"\\n  Average time to sort: [expr double($elapsed)/100] milliseconds \"\n                flush stdout\n            }\n        } {} {cluster:skip}\n    }\n\n    test {SETRANGE with huge offset} {\n        r lpush L 2 1 0\n        # expecting a different outcome on 32 and 64 bit systems\n        foreach value {9223372036854775807 2147483647} {\n            catch {[r sort_ro L by a limit 2 $value]} res\n            if {![string match \"2\" $res] && ![string match \"*out of range*\" $res]} {\n                assert_not_equal $res \"expecting an error or 2\"\n            }\n        }\n    }\n}\n"], "fixing_code": ["/*\n * Copyright (c) 2009-2012, Salvatore Sanfilippo <antirez at gmail dot com>\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *   * Redistributions of source code must retain the above copyright notice,\n *     this list of conditions and the following disclaimer.\n *   * Redistributions in binary form must reproduce the above copyright\n *     notice, this list of conditions and the following disclaimer in the\n *     documentation and/or other materials provided with the distribution.\n *   * Neither the name of Redis nor the names of its contributors may be used\n *     to endorse or promote products derived from this software without\n *     specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include \"server.h\"\n#include \"cluster.h\"\n#include \"atomicvar.h\"\n#include \"latency.h\"\n#include \"script.h\"\n#include \"functions.h\"\n\n#include <signal.h>\n#include <ctype.h>\n\n/*-----------------------------------------------------------------------------\n * C-level DB API\n *----------------------------------------------------------------------------*/\n\n/* Flags for expireIfNeeded */\n#define EXPIRE_FORCE_DELETE_EXPIRED 1\n#define EXPIRE_AVOID_DELETE_EXPIRED 2\n\nint expireIfNeeded(redisDb *db, robj *key, int flags);\nint keyIsExpired(redisDb *db, robj *key);\nstatic void dbSetValue(redisDb *db, robj *key, robj *val, int overwrite, dictEntry *de);\n\n/* Update LFU when an object is accessed.\n * Firstly, decrement the counter if the decrement time is reached.\n * Then logarithmically increment the counter, and update the access time. */\nvoid updateLFU(robj *val) {\n    unsigned long counter = LFUDecrAndReturn(val);\n    counter = LFULogIncr(counter);\n    val->lru = (LFUGetTimeInMinutes()<<8) | counter;\n}\n\n/* Lookup a key for read or write operations, or return NULL if the key is not\n * found in the specified DB. This function implements the functionality of\n * lookupKeyRead(), lookupKeyWrite() and their ...WithFlags() variants.\n *\n * Side-effects of calling this function:\n *\n * 1. A key gets expired if it reached it's TTL.\n * 2. The key's last access time is updated.\n * 3. The global keys hits/misses stats are updated (reported in INFO).\n * 4. If keyspace notifications are enabled, a \"keymiss\" notification is fired.\n *\n * Flags change the behavior of this command:\n *\n *  LOOKUP_NONE (or zero): No special flags are passed.\n *  LOOKUP_NOTOUCH: Don't alter the last access time of the key.\n *  LOOKUP_NONOTIFY: Don't trigger keyspace event on key miss.\n *  LOOKUP_NOSTATS: Don't increment key hits/misses counters.\n *  LOOKUP_WRITE: Prepare the key for writing (delete expired keys even on\n *                replicas, use separate keyspace stats and events (TODO)).\n *  LOOKUP_NOEXPIRE: Perform expiration check, but avoid deleting the key,\n *                   so that we don't have to propagate the deletion.\n *\n * Note: this function also returns NULL if the key is logically expired but\n * still existing, in case this is a replica and the LOOKUP_WRITE is not set.\n * Even if the key expiry is master-driven, we can correctly report a key is\n * expired on replicas even if the master is lagging expiring our key via DELs\n * in the replication link. */\nrobj *lookupKey(redisDb *db, robj *key, int flags) {\n    dictEntry *de = dictFind(db->dict,key->ptr);\n    robj *val = NULL;\n    if (de) {\n        val = dictGetVal(de);\n        /* Forcing deletion of expired keys on a replica makes the replica\n         * inconsistent with the master. We forbid it on readonly replicas, but\n         * we have to allow it on writable replicas to make write commands\n         * behave consistently.\n         *\n         * It's possible that the WRITE flag is set even during a readonly\n         * command, since the command may trigger events that cause modules to\n         * perform additional writes. */\n        int is_ro_replica = server.masterhost && server.repl_slave_ro;\n        int expire_flags = 0;\n        if (flags & LOOKUP_WRITE && !is_ro_replica)\n            expire_flags |= EXPIRE_FORCE_DELETE_EXPIRED;\n        if (flags & LOOKUP_NOEXPIRE)\n            expire_flags |= EXPIRE_AVOID_DELETE_EXPIRED;\n        if (expireIfNeeded(db, key, expire_flags)) {\n            /* The key is no longer valid. */\n            val = NULL;\n        }\n    }\n\n    if (val) {\n        /* Update the access time for the ageing algorithm.\n         * Don't do it if we have a saving child, as this will trigger\n         * a copy on write madness. */\n        if (server.current_client && server.current_client->flags & CLIENT_NO_TOUCH &&\n            server.current_client->cmd->proc != touchCommand)\n            flags |= LOOKUP_NOTOUCH;\n        if (!hasActiveChildProcess() && !(flags & LOOKUP_NOTOUCH)){\n            if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {\n                updateLFU(val);\n            } else {\n                val->lru = LRU_CLOCK();\n            }\n        }\n\n        if (!(flags & (LOOKUP_NOSTATS | LOOKUP_WRITE)))\n            server.stat_keyspace_hits++;\n        /* TODO: Use separate hits stats for WRITE */\n    } else {\n        if (!(flags & (LOOKUP_NONOTIFY | LOOKUP_WRITE)))\n            notifyKeyspaceEvent(NOTIFY_KEY_MISS, \"keymiss\", key, db->id);\n        if (!(flags & (LOOKUP_NOSTATS | LOOKUP_WRITE)))\n            server.stat_keyspace_misses++;\n        /* TODO: Use separate misses stats and notify event for WRITE */\n    }\n\n    return val;\n}\n\n/* Lookup a key for read operations, or return NULL if the key is not found\n * in the specified DB.\n *\n * This API should not be used when we write to the key after obtaining\n * the object linked to the key, but only for read only operations.\n *\n * This function is equivalent to lookupKey(). The point of using this function\n * rather than lookupKey() directly is to indicate that the purpose is to read\n * the key. */\nrobj *lookupKeyReadWithFlags(redisDb *db, robj *key, int flags) {\n    serverAssert(!(flags & LOOKUP_WRITE));\n    return lookupKey(db, key, flags);\n}\n\n/* Like lookupKeyReadWithFlags(), but does not use any flag, which is the\n * common case. */\nrobj *lookupKeyRead(redisDb *db, robj *key) {\n    return lookupKeyReadWithFlags(db,key,LOOKUP_NONE);\n}\n\n/* Lookup a key for write operations, and as a side effect, if needed, expires\n * the key if its TTL is reached. It's equivalent to lookupKey() with the\n * LOOKUP_WRITE flag added.\n *\n * Returns the linked value object if the key exists or NULL if the key\n * does not exist in the specified DB. */\nrobj *lookupKeyWriteWithFlags(redisDb *db, robj *key, int flags) {\n    return lookupKey(db, key, flags | LOOKUP_WRITE);\n}\n\nrobj *lookupKeyWrite(redisDb *db, robj *key) {\n    return lookupKeyWriteWithFlags(db, key, LOOKUP_NONE);\n}\n\nrobj *lookupKeyReadOrReply(client *c, robj *key, robj *reply) {\n    robj *o = lookupKeyRead(c->db, key);\n    if (!o) addReplyOrErrorObject(c, reply);\n    return o;\n}\n\nrobj *lookupKeyWriteOrReply(client *c, robj *key, robj *reply) {\n    robj *o = lookupKeyWrite(c->db, key);\n    if (!o) addReplyOrErrorObject(c, reply);\n    return o;\n}\n\n/* Add the key to the DB. It's up to the caller to increment the reference\n * counter of the value if needed.\n *\n * If the update_if_existing argument is false, the the program is aborted\n * if the key already exists, otherwise, it can fall back to dbOverwite. */\nstatic void dbAddInternal(redisDb *db, robj *key, robj *val, int update_if_existing) {\n    dictEntry *existing;\n    dictEntry *de = dictAddRaw(db->dict, key->ptr, &existing);\n    if (update_if_existing && existing) {\n        dbSetValue(db, key, val, 1, existing);\n        return;\n    }\n    serverAssertWithInfo(NULL, key, de != NULL);\n    dictSetKey(db->dict, de, sdsdup(key->ptr));\n    initObjectLRUOrLFU(val);\n    dictSetVal(db->dict, de, val);\n    signalKeyAsReady(db, key, val->type);\n    if (server.cluster_enabled) slotToKeyAddEntry(de, db);\n    notifyKeyspaceEvent(NOTIFY_NEW,\"new\",key,db->id);\n}\n\nvoid dbAdd(redisDb *db, robj *key, robj *val) {\n    dbAddInternal(db, key, val, 0);\n}\n\n/* This is a special version of dbAdd() that is used only when loading\n * keys from the RDB file: the key is passed as an SDS string that is\n * retained by the function (and not freed by the caller).\n *\n * Moreover this function will not abort if the key is already busy, to\n * give more control to the caller, nor will signal the key as ready\n * since it is not useful in this context.\n *\n * The function returns 1 if the key was added to the database, taking\n * ownership of the SDS string, otherwise 0 is returned, and is up to the\n * caller to free the SDS string. */\nint dbAddRDBLoad(redisDb *db, sds key, robj *val) {\n    dictEntry *de = dictAddRaw(db->dict, key, NULL);\n    if (de == NULL) return 0;\n    initObjectLRUOrLFU(val);\n    dictSetVal(db->dict, de, val);\n    if (server.cluster_enabled) slotToKeyAddEntry(de, db);\n    return 1;\n}\n\n/* Overwrite an existing key with a new value. Incrementing the reference\n * count of the new value is up to the caller.\n * This function does not modify the expire time of the existing key.\n *\n * The 'overwrite' flag is an indication whether this is done as part of a\n * complete replacement of their key, which can be thought as a deletion and\n * replacement (in which case we need to emit deletion signals), or just an\n * update of a value of an existing key (when false).\n *\n * The dictEntry input is optional, can be used if we already have one.\n *\n * The program is aborted if the key was not already present. */\nstatic void dbSetValue(redisDb *db, robj *key, robj *val, int overwrite, dictEntry *de) {\n    if (!de) de = dictFind(db->dict,key->ptr);\n    serverAssertWithInfo(NULL,key,de != NULL);\n    robj *old = dictGetVal(de);\n\n    val->lru = old->lru;\n\n    if (overwrite) {\n        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we\n         * need to incr to retain old */\n        incrRefCount(old);\n        /* Although the key is not really deleted from the database, we regard\n         * overwrite as two steps of unlink+add, so we still need to call the unlink\n         * callback of the module. */\n        moduleNotifyKeyUnlink(key,old,db->id,DB_FLAG_KEY_OVERWRITE);\n        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */\n        signalDeletedKeyAsReady(db,key,old->type);\n        decrRefCount(old);\n        /* Because of RM_StringDMA, old may be changed, so we need get old again */\n        old = dictGetVal(de);\n    }\n    dictSetVal(db->dict, de, val);\n\n    if (server.lazyfree_lazy_server_del) {\n        freeObjAsync(key,old,db->id);\n    } else {\n        /* This is just decrRefCount(old); */\n        db->dict->type->valDestructor(db->dict, old);\n    }\n}\n\n/* Replace an existing key with a new value, we just replace value and don't\n * emit any events */\nvoid dbReplaceValue(redisDb *db, robj *key, robj *val) {\n    dbSetValue(db, key, val, 0, NULL);\n}\n\n/* High level Set operation. This function can be used in order to set\n * a key, whatever it was existing or not, to a new object.\n *\n * 1) The ref count of the value object is incremented.\n * 2) clients WATCHing for the destination key notified.\n * 3) The expire time of the key is reset (the key is made persistent),\n *    unless 'SETKEY_KEEPTTL' is enabled in flags.\n * 4) The key lookup can take place outside this interface outcome will be\n *    delivered with 'SETKEY_ALREADY_EXIST' or 'SETKEY_DOESNT_EXIST'\n *\n * All the new keys in the database should be created via this interface.\n * The client 'c' argument may be set to NULL if the operation is performed\n * in a context where there is no clear client performing the operation. */\nvoid setKey(client *c, redisDb *db, robj *key, robj *val, int flags) {\n    int keyfound = 0;\n\n    if (flags & SETKEY_ALREADY_EXIST)\n        keyfound = 1;\n    else if (flags & SETKEY_ADD_OR_UPDATE)\n        keyfound = -1;\n    else if (!(flags & SETKEY_DOESNT_EXIST))\n        keyfound = (lookupKeyWrite(db,key) != NULL);\n\n    if (!keyfound) {\n        dbAdd(db,key,val);\n    } else if (keyfound<0) {\n        dbAddInternal(db,key,val,1);\n    } else {\n        dbSetValue(db,key,val,1,NULL);\n    }\n    incrRefCount(val);\n    if (!(flags & SETKEY_KEEPTTL)) removeExpire(db,key);\n    if (!(flags & SETKEY_NO_SIGNAL)) signalModifiedKey(c,db,key);\n}\n\n/* Return a random key, in form of a Redis object.\n * If there are no keys, NULL is returned.\n *\n * The function makes sure to return keys not already expired. */\nrobj *dbRandomKey(redisDb *db) {\n    dictEntry *de;\n    int maxtries = 100;\n    int allvolatile = dictSize(db->dict) == dictSize(db->expires);\n\n    while(1) {\n        sds key;\n        robj *keyobj;\n\n        de = dictGetFairRandomKey(db->dict);\n        if (de == NULL) return NULL;\n\n        key = dictGetKey(de);\n        keyobj = createStringObject(key,sdslen(key));\n        if (dictFind(db->expires,key)) {\n            if (allvolatile && server.masterhost && --maxtries == 0) {\n                /* If the DB is composed only of keys with an expire set,\n                 * it could happen that all the keys are already logically\n                 * expired in the slave, so the function cannot stop because\n                 * expireIfNeeded() is false, nor it can stop because\n                 * dictGetFairRandomKey() returns NULL (there are keys to return).\n                 * To prevent the infinite loop we do some tries, but if there\n                 * are the conditions for an infinite loop, eventually we\n                 * return a key name that may be already expired. */\n                return keyobj;\n            }\n            if (expireIfNeeded(db,keyobj,0)) {\n                decrRefCount(keyobj);\n                continue; /* search for another key. This expired. */\n            }\n        }\n        return keyobj;\n    }\n}\n\n/* Helper for sync and async delete. */\nint dbGenericDelete(redisDb *db, robj *key, int async, int flags) {\n    dictEntry **plink;\n    int table;\n    dictEntry *de = dictTwoPhaseUnlinkFind(db->dict,key->ptr,&plink,&table);\n    if (de) {\n        robj *val = dictGetVal(de);\n        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we\n         * need to incr to retain val */\n        incrRefCount(val);\n        /* Tells the module that the key has been unlinked from the database. */\n        moduleNotifyKeyUnlink(key,val,db->id,flags);\n        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */\n        signalDeletedKeyAsReady(db,key,val->type);\n        /* We should call decr before freeObjAsync. If not, the refcount may be\n         * greater than 1, so freeObjAsync doesn't work */\n        decrRefCount(val);\n        if (async) {\n            /* Because of dbUnshareStringValue, the val in de may change. */\n            freeObjAsync(key, dictGetVal(de), db->id);\n            dictSetVal(db->dict, de, NULL);\n        }\n        if (server.cluster_enabled) slotToKeyDelEntry(de, db);\n\n        /* Deleting an entry from the expires dict will not free the sds of\n        * the key, because it is shared with the main dictionary. */\n        if (dictSize(db->expires) > 0) dictDelete(db->expires,key->ptr);\n        dictTwoPhaseUnlinkFree(db->dict,de,plink,table);\n        return 1;\n    } else {\n        return 0;\n    }\n}\n\n/* Delete a key, value, and associated expiration entry if any, from the DB */\nint dbSyncDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, 0, DB_FLAG_KEY_DELETED);\n}\n\n/* Delete a key, value, and associated expiration entry if any, from the DB. If\n * the value consists of many allocations, it may be freed asynchronously. */\nint dbAsyncDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, 1, DB_FLAG_KEY_DELETED);\n}\n\n/* This is a wrapper whose behavior depends on the Redis lazy free\n * configuration. Deletes the key synchronously or asynchronously. */\nint dbDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, server.lazyfree_lazy_server_del, DB_FLAG_KEY_DELETED);\n}\n\n/* Prepare the string object stored at 'key' to be modified destructively\n * to implement commands like SETBIT or APPEND.\n *\n * An object is usually ready to be modified unless one of the two conditions\n * are true:\n *\n * 1) The object 'o' is shared (refcount > 1), we don't want to affect\n *    other users.\n * 2) The object encoding is not \"RAW\".\n *\n * If the object is found in one of the above conditions (or both) by the\n * function, an unshared / not-encoded copy of the string object is stored\n * at 'key' in the specified 'db'. Otherwise the object 'o' itself is\n * returned.\n *\n * USAGE:\n *\n * The object 'o' is what the caller already obtained by looking up 'key'\n * in 'db', the usage pattern looks like this:\n *\n * o = lookupKeyWrite(db,key);\n * if (checkType(c,o,OBJ_STRING)) return;\n * o = dbUnshareStringValue(db,key,o);\n *\n * At this point the caller is ready to modify the object, for example\n * using an sdscat() call to append some data, or anything else.\n */\nrobj *dbUnshareStringValue(redisDb *db, robj *key, robj *o) {\n    serverAssert(o->type == OBJ_STRING);\n    if (o->refcount != 1 || o->encoding != OBJ_ENCODING_RAW) {\n        robj *decoded = getDecodedObject(o);\n        o = createRawStringObject(decoded->ptr, sdslen(decoded->ptr));\n        decrRefCount(decoded);\n        dbReplaceValue(db,key,o);\n    }\n    return o;\n}\n\n/* Remove all keys from the database(s) structure. The dbarray argument\n * may not be the server main DBs (could be a temporary DB).\n *\n * The dbnum can be -1 if all the DBs should be emptied, or the specified\n * DB index if we want to empty only a single database.\n * The function returns the number of keys removed from the database(s). */\nlong long emptyDbStructure(redisDb *dbarray, int dbnum, int async,\n                           void(callback)(dict*))\n{\n    long long removed = 0;\n    int startdb, enddb;\n\n    if (dbnum == -1) {\n        startdb = 0;\n        enddb = server.dbnum-1;\n    } else {\n        startdb = enddb = dbnum;\n    }\n\n    for (int j = startdb; j <= enddb; j++) {\n        removed += dictSize(dbarray[j].dict);\n        if (async) {\n            emptyDbAsync(&dbarray[j]);\n        } else {\n            dictEmpty(dbarray[j].dict,callback);\n            dictEmpty(dbarray[j].expires,callback);\n        }\n        /* Because all keys of database are removed, reset average ttl. */\n        dbarray[j].avg_ttl = 0;\n        dbarray[j].expires_cursor = 0;\n    }\n\n    return removed;\n}\n\n/* Remove all data (keys and functions) from all the databases in a\n * Redis server. If callback is given the function is called from\n * time to time to signal that work is in progress.\n *\n * The dbnum can be -1 if all the DBs should be flushed, or the specified\n * DB number if we want to flush only a single Redis database number.\n *\n * Flags are be EMPTYDB_NO_FLAGS if no special flags are specified or\n * EMPTYDB_ASYNC if we want the memory to be freed in a different thread\n * and the function to return ASAP. EMPTYDB_NOFUNCTIONS can also be set\n * to specify that we do not want to delete the functions.\n *\n * On success the function returns the number of keys removed from the\n * database(s). Otherwise -1 is returned in the specific case the\n * DB number is out of range, and errno is set to EINVAL. */\nlong long emptyData(int dbnum, int flags, void(callback)(dict*)) {\n    int async = (flags & EMPTYDB_ASYNC);\n    int with_functions = !(flags & EMPTYDB_NOFUNCTIONS);\n    RedisModuleFlushInfoV1 fi = {REDISMODULE_FLUSHINFO_VERSION,!async,dbnum};\n    long long removed = 0;\n\n    if (dbnum < -1 || dbnum >= server.dbnum) {\n        errno = EINVAL;\n        return -1;\n    }\n\n    /* Fire the flushdb modules event. */\n    moduleFireServerEvent(REDISMODULE_EVENT_FLUSHDB,\n                          REDISMODULE_SUBEVENT_FLUSHDB_START,\n                          &fi);\n\n    /* Make sure the WATCHed keys are affected by the FLUSH* commands.\n     * Note that we need to call the function while the keys are still\n     * there. */\n    signalFlushedDb(dbnum, async);\n\n    /* Empty redis database structure. */\n    removed = emptyDbStructure(server.db, dbnum, async, callback);\n\n    /* Flush slots to keys map if enable cluster, we can flush entire\n     * slots to keys map whatever dbnum because only support one DB\n     * in cluster mode. */\n    if (server.cluster_enabled) slotToKeyFlush(server.db);\n\n    if (dbnum == -1) flushSlaveKeysWithExpireList();\n\n    if (with_functions) {\n        serverAssert(dbnum == -1);\n        functionsLibCtxClearCurrent(async);\n    }\n\n    /* Also fire the end event. Note that this event will fire almost\n     * immediately after the start event if the flush is asynchronous. */\n    moduleFireServerEvent(REDISMODULE_EVENT_FLUSHDB,\n                          REDISMODULE_SUBEVENT_FLUSHDB_END,\n                          &fi);\n\n    return removed;\n}\n\n/* Initialize temporary db on replica for use during diskless replication. */\nredisDb *initTempDb(void) {\n    redisDb *tempDb = zcalloc(sizeof(redisDb)*server.dbnum);\n    for (int i=0; i<server.dbnum; i++) {\n        tempDb[i].dict = dictCreate(&dbDictType);\n        tempDb[i].expires = dictCreate(&dbExpiresDictType);\n        tempDb[i].slots_to_keys = NULL;\n    }\n\n    if (server.cluster_enabled) {\n        /* Prepare temp slot to key map to be written during async diskless replication. */\n        slotToKeyInit(tempDb);\n    }\n\n    return tempDb;\n}\n\n/* Discard tempDb, this can be slow (similar to FLUSHALL), but it's always async. */\nvoid discardTempDb(redisDb *tempDb, void(callback)(dict*)) {\n    int async = 1;\n\n    /* Release temp DBs. */\n    emptyDbStructure(tempDb, -1, async, callback);\n    for (int i=0; i<server.dbnum; i++) {\n        dictRelease(tempDb[i].dict);\n        dictRelease(tempDb[i].expires);\n    }\n\n    if (server.cluster_enabled) {\n        /* Release temp slot to key map. */\n        slotToKeyDestroy(tempDb);\n    }\n\n    zfree(tempDb);\n}\n\nint selectDb(client *c, int id) {\n    if (id < 0 || id >= server.dbnum)\n        return C_ERR;\n    c->db = &server.db[id];\n    return C_OK;\n}\n\nlong long dbTotalServerKeyCount(void) {\n    long long total = 0;\n    int j;\n    for (j = 0; j < server.dbnum; j++) {\n        total += dictSize(server.db[j].dict);\n    }\n    return total;\n}\n\n/*-----------------------------------------------------------------------------\n * Hooks for key space changes.\n *\n * Every time a key in the database is modified the function\n * signalModifiedKey() is called.\n *\n * Every time a DB is flushed the function signalFlushDb() is called.\n *----------------------------------------------------------------------------*/\n\n/* Note that the 'c' argument may be NULL if the key was modified out of\n * a context of a client. */\nvoid signalModifiedKey(client *c, redisDb *db, robj *key) {\n    touchWatchedKey(db,key);\n    trackingInvalidateKey(c,key,1);\n}\n\nvoid signalFlushedDb(int dbid, int async) {\n    int startdb, enddb;\n    if (dbid == -1) {\n        startdb = 0;\n        enddb = server.dbnum-1;\n    } else {\n        startdb = enddb = dbid;\n    }\n\n    for (int j = startdb; j <= enddb; j++) {\n        scanDatabaseForDeletedKeys(&server.db[j], NULL);\n        touchAllWatchedKeysInDb(&server.db[j], NULL);\n    }\n\n    trackingInvalidateKeysOnFlush(async);\n\n    /* Changes in this method may take place in swapMainDbWithTempDb as well,\n     * where we execute similar calls, but with subtle differences as it's\n     * not simply flushing db. */\n}\n\n/*-----------------------------------------------------------------------------\n * Type agnostic commands operating on the key space\n *----------------------------------------------------------------------------*/\n\n/* Return the set of flags to use for the emptyDb() call for FLUSHALL\n * and FLUSHDB commands.\n *\n * sync: flushes the database in an sync manner.\n * async: flushes the database in an async manner.\n * no option: determine sync or async according to the value of lazyfree-lazy-user-flush.\n *\n * On success C_OK is returned and the flags are stored in *flags, otherwise\n * C_ERR is returned and the function sends an error to the client. */\nint getFlushCommandFlags(client *c, int *flags) {\n    /* Parse the optional ASYNC option. */\n    if (c->argc == 2 && !strcasecmp(c->argv[1]->ptr,\"sync\")) {\n        *flags = EMPTYDB_NO_FLAGS;\n    } else if (c->argc == 2 && !strcasecmp(c->argv[1]->ptr,\"async\")) {\n        *flags = EMPTYDB_ASYNC;\n    } else if (c->argc == 1) {\n        *flags = server.lazyfree_lazy_user_flush ? EMPTYDB_ASYNC : EMPTYDB_NO_FLAGS;\n    } else {\n        addReplyErrorObject(c,shared.syntaxerr);\n        return C_ERR;\n    }\n    return C_OK;\n}\n\n/* Flushes the whole server data set. */\nvoid flushAllDataAndResetRDB(int flags) {\n    server.dirty += emptyData(-1,flags,NULL);\n    if (server.child_type == CHILD_TYPE_RDB) killRDBChild();\n    if (server.saveparamslen > 0) {\n        rdbSaveInfo rsi, *rsiptr;\n        rsiptr = rdbPopulateSaveInfo(&rsi);\n        rdbSave(SLAVE_REQ_NONE,server.rdb_filename,rsiptr,RDBFLAGS_NONE);\n    }\n\n#if defined(USE_JEMALLOC)\n    /* jemalloc 5 doesn't release pages back to the OS when there's no traffic.\n     * for large databases, flushdb blocks for long anyway, so a bit more won't\n     * harm and this way the flush and purge will be synchronous. */\n    if (!(flags & EMPTYDB_ASYNC))\n        jemalloc_purge();\n#endif\n}\n\n/* FLUSHDB [ASYNC]\n *\n * Flushes the currently SELECTed Redis DB. */\nvoid flushdbCommand(client *c) {\n    int flags;\n\n    if (getFlushCommandFlags(c,&flags) == C_ERR) return;\n    /* flushdb should not flush the functions */\n    server.dirty += emptyData(c->db->id,flags | EMPTYDB_NOFUNCTIONS,NULL);\n\n    /* Without the forceCommandPropagation, when DB was already empty,\n     * FLUSHDB will not be replicated nor put into the AOF. */\n    forceCommandPropagation(c, PROPAGATE_REPL | PROPAGATE_AOF);\n\n    addReply(c,shared.ok);\n\n#if defined(USE_JEMALLOC)\n    /* jemalloc 5 doesn't release pages back to the OS when there's no traffic.\n     * for large databases, flushdb blocks for long anyway, so a bit more won't\n     * harm and this way the flush and purge will be synchronous. */\n    if (!(flags & EMPTYDB_ASYNC))\n        jemalloc_purge();\n#endif\n}\n\n/* FLUSHALL [ASYNC]\n *\n * Flushes the whole server data set. */\nvoid flushallCommand(client *c) {\n    int flags;\n    if (getFlushCommandFlags(c,&flags) == C_ERR) return;\n    /* flushall should not flush the functions */\n    flushAllDataAndResetRDB(flags | EMPTYDB_NOFUNCTIONS);\n\n    /* Without the forceCommandPropagation, when DBs were already empty,\n     * FLUSHALL will not be replicated nor put into the AOF. */\n    forceCommandPropagation(c, PROPAGATE_REPL | PROPAGATE_AOF);\n\n    addReply(c,shared.ok);\n}\n\n/* This command implements DEL and UNLINK. */\nvoid delGenericCommand(client *c, int lazy) {\n    int numdel = 0, j;\n\n    for (j = 1; j < c->argc; j++) {\n        expireIfNeeded(c->db,c->argv[j],0);\n        int deleted  = lazy ? dbAsyncDelete(c->db,c->argv[j]) :\n                              dbSyncDelete(c->db,c->argv[j]);\n        if (deleted) {\n            signalModifiedKey(c,c->db,c->argv[j]);\n            notifyKeyspaceEvent(NOTIFY_GENERIC,\n                \"del\",c->argv[j],c->db->id);\n            server.dirty++;\n            numdel++;\n        }\n    }\n    addReplyLongLong(c,numdel);\n}\n\nvoid delCommand(client *c) {\n    delGenericCommand(c,server.lazyfree_lazy_user_del);\n}\n\nvoid unlinkCommand(client *c) {\n    delGenericCommand(c,1);\n}\n\n/* EXISTS key1 key2 ... key_N.\n * Return value is the number of keys existing. */\nvoid existsCommand(client *c) {\n    long long count = 0;\n    int j;\n\n    for (j = 1; j < c->argc; j++) {\n        if (lookupKeyReadWithFlags(c->db,c->argv[j],LOOKUP_NOTOUCH)) count++;\n    }\n    addReplyLongLong(c,count);\n}\n\nvoid selectCommand(client *c) {\n    int id;\n\n    if (getIntFromObjectOrReply(c, c->argv[1], &id, NULL) != C_OK)\n        return;\n\n    if (server.cluster_enabled && id != 0) {\n        addReplyError(c,\"SELECT is not allowed in cluster mode\");\n        return;\n    }\n    if (selectDb(c,id) == C_ERR) {\n        addReplyError(c,\"DB index is out of range\");\n    } else {\n        addReply(c,shared.ok);\n    }\n}\n\nvoid randomkeyCommand(client *c) {\n    robj *key;\n\n    if ((key = dbRandomKey(c->db)) == NULL) {\n        addReplyNull(c);\n        return;\n    }\n\n    addReplyBulk(c,key);\n    decrRefCount(key);\n}\n\nvoid keysCommand(client *c) {\n    dictIterator *di;\n    dictEntry *de;\n    sds pattern = c->argv[1]->ptr;\n    int plen = sdslen(pattern), allkeys;\n    unsigned long numkeys = 0;\n    void *replylen = addReplyDeferredLen(c);\n\n    di = dictGetSafeIterator(c->db->dict);\n    allkeys = (pattern[0] == '*' && plen == 1);\n    robj keyobj;\n    while((de = dictNext(di)) != NULL) {\n        sds key = dictGetKey(de);\n\n        if (allkeys || stringmatchlen(pattern,plen,key,sdslen(key),0)) {\n            initStaticStringObject(keyobj, key);\n            if (!keyIsExpired(c->db, &keyobj)) {\n                addReplyBulkCBuffer(c, key, sdslen(key));\n                numkeys++;\n            }\n        }\n        if (c->flags & CLIENT_CLOSE_ASAP)\n            break;\n    }\n    dictReleaseIterator(di);\n    setDeferredArrayLen(c,replylen,numkeys);\n}\n\n/* Data used by the dict scan callback. */\ntypedef struct {\n    list *keys;   /* elements that collect from dict */\n    robj *o;      /* o must be a hash/set/zset object, NULL means current db */\n    long long type; /* the particular type when scan the db */\n    sds pattern;  /* pattern string, NULL means no pattern */\n    long sampled; /* cumulative number of keys sampled */\n} scanData;\n\n/* Helper function to compare key type in scan commands */\nint objectTypeCompare(robj *o, long long target) {\n    if (o->type != OBJ_MODULE) {\n        if (o->type != target) \n            return 0;\n        else \n            return 1;\n    }\n    /* module type compare */\n    long long mt = (long long)REDISMODULE_TYPE_SIGN(((moduleValue *)o->ptr)->type->id);\n    if (target != -mt)\n        return 0;\n    else \n        return 1;\n}\n/* This callback is used by scanGenericCommand in order to collect elements\n * returned by the dictionary iterator into a list. */\nvoid scanCallback(void *privdata, const dictEntry *de) {\n    scanData *data = (scanData *)privdata;\n    list *keys = data->keys;\n    robj *o = data->o;\n    sds val = NULL;\n    sds key = NULL;\n    data->sampled++;\n\n    /* o and typename can not have values at the same time. */\n    serverAssert(!((data->type != LLONG_MAX) && o));\n\n    /* Filter an element if it isn't the type we want. */\n    /* TODO: uncomment in redis 8.0\n    if (!o && data->type != LLONG_MAX) {\n        robj *rval = dictGetVal(de);\n        if (!objectTypeCompare(rval, data->type)) return;\n    }*/\n\n    /* Filter element if it does not match the pattern. */\n    sds keysds = dictGetKey(de);\n    if (data->pattern) {\n        if (!stringmatchlen(data->pattern, sdslen(data->pattern), keysds, sdslen(keysds), 0)) {\n            return;\n        }\n    }\n\n    if (o == NULL) {\n        key = keysds;\n    } else if (o->type == OBJ_SET) {\n        key = keysds;\n    } else if (o->type == OBJ_HASH) {\n        key = keysds;\n        val = dictGetVal(de);\n    } else if (o->type == OBJ_ZSET) {\n        char buf[MAX_LONG_DOUBLE_CHARS];\n        int len = ld2string(buf, sizeof(buf), *(double *)dictGetVal(de), LD_STR_AUTO);\n        key = sdsdup(keysds);\n        val = sdsnewlen(buf, len);\n    } else {\n        serverPanic(\"Type not handled in SCAN callback.\");\n    }\n\n    listAddNodeTail(keys, key);\n    if (val) listAddNodeTail(keys, val);\n}\n\n/* Try to parse a SCAN cursor stored at object 'o':\n * if the cursor is valid, store it as unsigned integer into *cursor and\n * returns C_OK. Otherwise return C_ERR and send an error to the\n * client. */\nint parseScanCursorOrReply(client *c, robj *o, unsigned long *cursor) {\n    char *eptr;\n\n    /* Use strtoul() because we need an *unsigned* long, so\n     * getLongLongFromObject() does not cover the whole cursor space. */\n    errno = 0;\n    *cursor = strtoul(o->ptr, &eptr, 10);\n    if (isspace(((char*)o->ptr)[0]) || eptr[0] != '\\0' || errno == ERANGE)\n    {\n        addReplyError(c, \"invalid cursor\");\n        return C_ERR;\n    }\n    return C_OK;\n}\n\nchar *obj_type_name[OBJ_TYPE_MAX] = {\n    \"string\", \n    \"list\", \n    \"set\", \n    \"zset\", \n    \"hash\", \n    NULL, /* module type is special */\n    \"stream\"\n};\n\n/* Helper function to get type from a string in scan commands */\nlong long getObjectTypeByName(char *name) {\n\n    for (long long i = 0; i < OBJ_TYPE_MAX; i++) {\n        if (obj_type_name[i] && !strcasecmp(name, obj_type_name[i])) {\n            return i;\n        }\n    }\n\n    moduleType *mt = moduleTypeLookupModuleByNameIgnoreCase(name);\n    if (mt != NULL) return -(REDISMODULE_TYPE_SIGN(mt->id));\n\n    return LLONG_MAX;\n}\n\nchar *getObjectTypeName(robj *o) {\n    if (o == NULL) {\n        return \"none\";\n    }\n\n    serverAssert(o->type >= 0 && o->type < OBJ_TYPE_MAX);\n\n    if (o->type == OBJ_MODULE) {\n        moduleValue *mv = o->ptr;\n        return mv->type->name;\n    } else {\n        return obj_type_name[o->type];\n    }\n}\n\n/* This command implements SCAN, HSCAN and SSCAN commands.\n * If object 'o' is passed, then it must be a Hash, Set or Zset object, otherwise\n * if 'o' is NULL the command will operate on the dictionary associated with\n * the current database.\n *\n * When 'o' is not NULL the function assumes that the first argument in\n * the client arguments vector is a key so it skips it before iterating\n * in order to parse options.\n *\n * In the case of a Hash object the function returns both the field and value\n * of every element on the Hash. */\nvoid scanGenericCommand(client *c, robj *o, unsigned long cursor) {\n    int i, j;\n    listNode *node;\n    long count = 10;\n    sds pat = NULL;\n    sds typename = NULL;\n    long long type = LLONG_MAX;\n    int patlen = 0, use_pattern = 0;\n    dict *ht;\n\n    /* Object must be NULL (to iterate keys names), or the type of the object\n     * must be Set, Sorted Set, or Hash. */\n    serverAssert(o == NULL || o->type == OBJ_SET || o->type == OBJ_HASH ||\n                o->type == OBJ_ZSET);\n\n    /* Set i to the first option argument. The previous one is the cursor. */\n    i = (o == NULL) ? 2 : 3; /* Skip the key argument if needed. */\n\n    /* Step 1: Parse options. */\n    while (i < c->argc) {\n        j = c->argc - i;\n        if (!strcasecmp(c->argv[i]->ptr, \"count\") && j >= 2) {\n            if (getLongFromObjectOrReply(c, c->argv[i+1], &count, NULL)\n                != C_OK)\n            {\n                return;\n            }\n\n            if (count < 1) {\n                addReplyErrorObject(c,shared.syntaxerr);\n                return;\n            }\n\n            i += 2;\n        } else if (!strcasecmp(c->argv[i]->ptr, \"match\") && j >= 2) {\n            pat = c->argv[i+1]->ptr;\n            patlen = sdslen(pat);\n\n            /* The pattern always matches if it is exactly \"*\", so it is\n             * equivalent to disabling it. */\n            use_pattern = !(patlen == 1 && pat[0] == '*');\n\n            i += 2;\n        } else if (!strcasecmp(c->argv[i]->ptr, \"type\") && o == NULL && j >= 2) {\n            /* SCAN for a particular type only applies to the db dict */\n            typename = c->argv[i+1]->ptr;\n            type = getObjectTypeByName(typename);\n            if (type == LLONG_MAX) {\n                /* TODO: uncomment in redis 8.0\n                addReplyErrorFormat(c, \"unknown type name '%s'\", typename);\n                return; */\n            }\n            i+= 2;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            return;\n        }\n    }\n\n    /* Step 2: Iterate the collection.\n     *\n     * Note that if the object is encoded with a listpack, intset, or any other\n     * representation that is not a hash table, we are sure that it is also\n     * composed of a small number of elements. So to avoid taking state we\n     * just return everything inside the object in a single call, setting the\n     * cursor to zero to signal the end of the iteration. */\n\n    /* Handle the case of a hash table. */\n    ht = NULL;\n    if (o == NULL) {\n        ht = c->db->dict;\n    } else if (o->type == OBJ_SET && o->encoding == OBJ_ENCODING_HT) {\n        ht = o->ptr;\n    } else if (o->type == OBJ_HASH && o->encoding == OBJ_ENCODING_HT) {\n        ht = o->ptr;\n    } else if (o->type == OBJ_ZSET && o->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = o->ptr;\n        ht = zs->dict;\n    }\n\n    list *keys = listCreate();\n    /* Set a free callback for the contents of the collected keys list.\n     * For the main keyspace dict, and when we scan a key that's dict encoded\n     * (we have 'ht'), we don't need to define free method because the strings\n     * in the list are just a shallow copy from the pointer in the dictEntry.\n     * When scanning a key with other encodings (e.g. listpack), we need to\n     * free the temporary strings we add to that list.\n     * The exception to the above is ZSET, where we do allocate temporary\n     * strings even when scanning a dict. */\n    if (o && (!ht || o->type == OBJ_ZSET)) {\n        listSetFreeMethod(keys, (void (*)(void*))sdsfree);\n    }\n\n    if (ht) {\n        /* We set the max number of iterations to ten times the specified\n         * COUNT, so if the hash table is in a pathological state (very\n         * sparsely populated) we avoid to block too much time at the cost\n         * of returning no or very few elements. */\n        long maxiterations = count*10;\n\n        /* We pass scanData which have three pointers to the callback:\n         * 1. data.keys: the list to which it will add new elements;\n         * 2. data.o: the object containing the dictionary so that\n         * it is possible to fetch more data in a type-dependent way;\n         * 3. data.type: the specified type scan in the db, LLONG_MAX means\n         * type matching is no needed;\n         * 4. data.pattern: the pattern string\n         * 5. data.sampled: the maxiteration limit is there in case we're\n         * working on an empty dict, one with a lot of empty buckets, and\n         * for the buckets are not empty, we need to limit the spampled number\n         * to prevent a long hang time caused by filtering too many keys*/\n        scanData data = {\n            .keys = keys,\n            .o = o,\n            .type = type,\n            .pattern = use_pattern ? pat : NULL,\n            .sampled = 0,\n        };\n        do {\n            cursor = dictScan(ht, cursor, scanCallback, &data);\n        } while (cursor && maxiterations-- && data.sampled < count);\n    } else if (o->type == OBJ_SET) {\n        char *str;\n        char buf[LONG_STR_SIZE];\n        size_t len;\n        int64_t llele;\n        setTypeIterator *si = setTypeInitIterator(o);\n        while (setTypeNext(si, &str, &len, &llele) != -1) {\n            if (str == NULL) {\n                len = ll2string(buf, sizeof(buf), llele);\n            }\n            char *key = str ? str : buf;\n            if (use_pattern && !stringmatchlen(pat, sdslen(pat), key, len, 0)) {\n                continue;\n            }\n            listAddNodeTail(keys, sdsnewlen(key, len));\n        }\n        setTypeReleaseIterator(si);\n        cursor = 0;\n    } else if ((o->type == OBJ_HASH || o->type == OBJ_ZSET) &&\n               o->encoding == OBJ_ENCODING_LISTPACK)\n    {\n        unsigned char *p = lpFirst(o->ptr);\n        unsigned char *str;\n        int64_t len;\n        unsigned char intbuf[LP_INTBUF_SIZE];\n\n        while(p) {\n            str = lpGet(p, &len, intbuf);\n            /* point to the value */\n            p = lpNext(o->ptr, p);\n            if (use_pattern && !stringmatchlen(pat, sdslen(pat), (char *)str, len, 0)) {\n                /* jump to the next key/val pair */\n                p = lpNext(o->ptr, p);\n                continue;\n            }\n            /* add key object */\n            listAddNodeTail(keys, sdsnewlen(str, len));\n            /* add value object */\n            str = lpGet(p, &len, intbuf);\n            listAddNodeTail(keys, sdsnewlen(str, len));\n            p = lpNext(o->ptr, p);\n        }\n        cursor = 0;\n    } else {\n        serverPanic(\"Not handled encoding in SCAN.\");\n    }\n\n    /* Step 3: Filter the expired keys */\n    if (o == NULL && listLength(keys)) {\n        robj kobj;\n        listIter li;\n        listNode *ln;\n        listRewind(keys, &li);\n        while ((ln = listNext(&li))) {\n            sds key = listNodeValue(ln);\n            initStaticStringObject(kobj, key);\n            /* Filter an element if it isn't the type we want. */\n            /* TODO: remove this in redis 8.0 */\n            if (typename) {\n                robj* typecheck = lookupKeyReadWithFlags(c->db, &kobj, LOOKUP_NOTOUCH|LOOKUP_NONOTIFY);\n                if (!typecheck || !objectTypeCompare(typecheck, type)) {\n                    listDelNode(keys, ln);\n                }\n                continue;\n            }\n            if (expireIfNeeded(c->db, &kobj, 0)) {\n                listDelNode(keys, ln);\n            }\n        }\n    }\n\n    /* Step 4: Reply to the client. */\n    addReplyArrayLen(c, 2);\n    addReplyBulkLongLong(c,cursor);\n\n    addReplyArrayLen(c, listLength(keys));\n    while ((node = listFirst(keys)) != NULL) {\n        sds key = listNodeValue(node);\n        addReplyBulkCBuffer(c, key, sdslen(key));\n        listDelNode(keys, node);\n    }\n\n    listRelease(keys);\n}\n\n/* The SCAN command completely relies on scanGenericCommand. */\nvoid scanCommand(client *c) {\n    unsigned long cursor;\n    if (parseScanCursorOrReply(c,c->argv[1],&cursor) == C_ERR) return;\n    scanGenericCommand(c,NULL,cursor);\n}\n\nvoid dbsizeCommand(client *c) {\n    addReplyLongLong(c,dictSize(c->db->dict));\n}\n\nvoid lastsaveCommand(client *c) {\n    addReplyLongLong(c,server.lastsave);\n}\n\nvoid typeCommand(client *c) {\n    robj *o;\n    o = lookupKeyReadWithFlags(c->db,c->argv[1],LOOKUP_NOTOUCH);\n    addReplyStatus(c, getObjectTypeName(o));\n}\n\nvoid shutdownCommand(client *c) {\n    int flags = SHUTDOWN_NOFLAGS;\n    int abort = 0;\n    for (int i = 1; i < c->argc; i++) {\n        if (!strcasecmp(c->argv[i]->ptr,\"nosave\")) {\n            flags |= SHUTDOWN_NOSAVE;\n        } else if (!strcasecmp(c->argv[i]->ptr,\"save\")) {\n            flags |= SHUTDOWN_SAVE;\n        } else if (!strcasecmp(c->argv[i]->ptr, \"now\")) {\n            flags |= SHUTDOWN_NOW;\n        } else if (!strcasecmp(c->argv[i]->ptr, \"force\")) {\n            flags |= SHUTDOWN_FORCE;\n        } else if (!strcasecmp(c->argv[i]->ptr, \"abort\")) {\n            abort = 1;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            return;\n        }\n    }\n    if ((abort && flags != SHUTDOWN_NOFLAGS) ||\n        (flags & SHUTDOWN_NOSAVE && flags & SHUTDOWN_SAVE))\n    {\n        /* Illegal combo. */\n        addReplyErrorObject(c,shared.syntaxerr);\n        return;\n    }\n\n    if (abort) {\n        if (abortShutdown() == C_OK)\n            addReply(c, shared.ok);\n        else\n            addReplyError(c, \"No shutdown in progress.\");\n        return;\n    }\n\n    if (!(flags & SHUTDOWN_NOW) && c->flags & CLIENT_DENY_BLOCKING) {\n        addReplyError(c, \"SHUTDOWN without NOW or ABORT isn't allowed for DENY BLOCKING client\");\n        return;\n    }\n\n    if (!(flags & SHUTDOWN_NOSAVE) && isInsideYieldingLongCommand()) {\n        /* Script timed out. Shutdown allowed only with the NOSAVE flag. See\n         * also processCommand where these errors are returned. */\n        if (server.busy_module_yield_flags && server.busy_module_yield_reply) {\n            addReplyErrorFormat(c, \"-BUSY %s\", server.busy_module_yield_reply);\n        } else if (server.busy_module_yield_flags) {\n            addReplyErrorObject(c, shared.slowmoduleerr);\n        } else if (scriptIsEval()) {\n            addReplyErrorObject(c, shared.slowevalerr);\n        } else {\n            addReplyErrorObject(c, shared.slowscripterr);\n        }\n        return;\n    }\n\n    blockClientShutdown(c);\n    if (prepareForShutdown(flags) == C_OK) exit(0);\n    /* If we're here, then shutdown is ongoing (the client is still blocked) or\n     * failed (the client has received an error). */\n}\n\nvoid renameGenericCommand(client *c, int nx) {\n    robj *o;\n    long long expire;\n    int samekey = 0;\n\n    /* When source and dest key is the same, no operation is performed,\n     * if the key exists, however we still return an error on unexisting key. */\n    if (sdscmp(c->argv[1]->ptr,c->argv[2]->ptr) == 0) samekey = 1;\n\n    if ((o = lookupKeyWriteOrReply(c,c->argv[1],shared.nokeyerr)) == NULL)\n        return;\n\n    if (samekey) {\n        addReply(c,nx ? shared.czero : shared.ok);\n        return;\n    }\n\n    incrRefCount(o);\n    expire = getExpire(c->db,c->argv[1]);\n    if (lookupKeyWrite(c->db,c->argv[2]) != NULL) {\n        if (nx) {\n            decrRefCount(o);\n            addReply(c,shared.czero);\n            return;\n        }\n        /* Overwrite: delete the old key before creating the new one\n         * with the same name. */\n        dbDelete(c->db,c->argv[2]);\n    }\n    dbAdd(c->db,c->argv[2],o);\n    if (expire != -1) setExpire(c,c->db,c->argv[2],expire);\n    dbDelete(c->db,c->argv[1]);\n    signalModifiedKey(c,c->db,c->argv[1]);\n    signalModifiedKey(c,c->db,c->argv[2]);\n    notifyKeyspaceEvent(NOTIFY_GENERIC,\"rename_from\",\n        c->argv[1],c->db->id);\n    notifyKeyspaceEvent(NOTIFY_GENERIC,\"rename_to\",\n        c->argv[2],c->db->id);\n    server.dirty++;\n    addReply(c,nx ? shared.cone : shared.ok);\n}\n\nvoid renameCommand(client *c) {\n    renameGenericCommand(c,0);\n}\n\nvoid renamenxCommand(client *c) {\n    renameGenericCommand(c,1);\n}\n\nvoid moveCommand(client *c) {\n    robj *o;\n    redisDb *src, *dst;\n    int srcid, dbid;\n    long long expire;\n\n    if (server.cluster_enabled) {\n        addReplyError(c,\"MOVE is not allowed in cluster mode\");\n        return;\n    }\n\n    /* Obtain source and target DB pointers */\n    src = c->db;\n    srcid = c->db->id;\n\n    if (getIntFromObjectOrReply(c, c->argv[2], &dbid, NULL) != C_OK)\n        return;\n\n    if (selectDb(c,dbid) == C_ERR) {\n        addReplyError(c,\"DB index is out of range\");\n        return;\n    }\n    dst = c->db;\n    selectDb(c,srcid); /* Back to the source DB */\n\n    /* If the user is moving using as target the same\n     * DB as the source DB it is probably an error. */\n    if (src == dst) {\n        addReplyErrorObject(c,shared.sameobjecterr);\n        return;\n    }\n\n    /* Check if the element exists and get a reference */\n    o = lookupKeyWrite(c->db,c->argv[1]);\n    if (!o) {\n        addReply(c,shared.czero);\n        return;\n    }\n    expire = getExpire(c->db,c->argv[1]);\n\n    /* Return zero if the key already exists in the target DB */\n    if (lookupKeyWrite(dst,c->argv[1]) != NULL) {\n        addReply(c,shared.czero);\n        return;\n    }\n    dbAdd(dst,c->argv[1],o);\n    if (expire != -1) setExpire(c,dst,c->argv[1],expire);\n    incrRefCount(o);\n\n    /* OK! key moved, free the entry in the source DB */\n    dbDelete(src,c->argv[1]);\n    signalModifiedKey(c,src,c->argv[1]);\n    signalModifiedKey(c,dst,c->argv[1]);\n    notifyKeyspaceEvent(NOTIFY_GENERIC,\n                \"move_from\",c->argv[1],src->id);\n    notifyKeyspaceEvent(NOTIFY_GENERIC,\n                \"move_to\",c->argv[1],dst->id);\n\n    server.dirty++;\n    addReply(c,shared.cone);\n}\n\nvoid copyCommand(client *c) {\n    robj *o;\n    redisDb *src, *dst;\n    int srcid, dbid;\n    long long expire;\n    int j, replace = 0, delete = 0;\n\n    /* Obtain source and target DB pointers \n     * Default target DB is the same as the source DB \n     * Parse the REPLACE option and targetDB option. */\n    src = c->db;\n    dst = c->db;\n    srcid = c->db->id;\n    dbid = c->db->id;\n    for (j = 3; j < c->argc; j++) {\n        int additional = c->argc - j - 1;\n        if (!strcasecmp(c->argv[j]->ptr,\"replace\")) {\n            replace = 1;\n        } else if (!strcasecmp(c->argv[j]->ptr, \"db\") && additional >= 1) {\n            if (getIntFromObjectOrReply(c, c->argv[j+1], &dbid, NULL) != C_OK)\n                return;\n\n            if (selectDb(c, dbid) == C_ERR) {\n                addReplyError(c,\"DB index is out of range\");\n                return;\n            }\n            dst = c->db;\n            selectDb(c,srcid); /* Back to the source DB */\n            j++; /* Consume additional arg. */\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            return;\n        }\n    }\n\n    if ((server.cluster_enabled == 1) && (srcid != 0 || dbid != 0)) {\n        addReplyError(c,\"Copying to another database is not allowed in cluster mode\");\n        return;\n    }\n\n    /* If the user select the same DB as\n     * the source DB and using newkey as the same key\n     * it is probably an error. */\n    robj *key = c->argv[1];\n    robj *newkey = c->argv[2];\n    if (src == dst && (sdscmp(key->ptr, newkey->ptr) == 0)) {\n        addReplyErrorObject(c,shared.sameobjecterr);\n        return;\n    }\n\n    /* Check if the element exists and get a reference */\n    o = lookupKeyRead(c->db, key);\n    if (!o) {\n        addReply(c,shared.czero);\n        return;\n    }\n    expire = getExpire(c->db,key);\n\n    /* Return zero if the key already exists in the target DB. \n     * If REPLACE option is selected, delete newkey from targetDB. */\n    if (lookupKeyWrite(dst,newkey) != NULL) {\n        if (replace) {\n            delete = 1;\n        } else {\n            addReply(c,shared.czero);\n            return;\n        }\n    }\n\n    /* Duplicate object according to object's type. */\n    robj *newobj;\n    switch(o->type) {\n        case OBJ_STRING: newobj = dupStringObject(o); break;\n        case OBJ_LIST: newobj = listTypeDup(o); break;\n        case OBJ_SET: newobj = setTypeDup(o); break;\n        case OBJ_ZSET: newobj = zsetDup(o); break;\n        case OBJ_HASH: newobj = hashTypeDup(o); break;\n        case OBJ_STREAM: newobj = streamDup(o); break;\n        case OBJ_MODULE:\n            newobj = moduleTypeDupOrReply(c, key, newkey, dst->id, o);\n            if (!newobj) return;\n            break;\n        default:\n            addReplyError(c, \"unknown type object\");\n            return;\n    }\n\n    if (delete) {\n        dbDelete(dst,newkey);\n    }\n\n    dbAdd(dst,newkey,newobj);\n    if (expire != -1) setExpire(c, dst, newkey, expire);\n\n    /* OK! key copied */\n    signalModifiedKey(c,dst,c->argv[2]);\n    notifyKeyspaceEvent(NOTIFY_GENERIC,\"copy_to\",c->argv[2],dst->id);\n\n    server.dirty++;\n    addReply(c,shared.cone);\n}\n\n/* Helper function for dbSwapDatabases(): scans the list of keys that have\n * one or more blocked clients for B[LR]POP or other blocking commands\n * and signal the keys as ready if they are of the right type. See the comment\n * where the function is used for more info. */\nvoid scanDatabaseForReadyKeys(redisDb *db) {\n    dictEntry *de;\n    dictIterator *di = dictGetSafeIterator(db->blocking_keys);\n    while((de = dictNext(di)) != NULL) {\n        robj *key = dictGetKey(de);\n        dictEntry *kde = dictFind(db->dict,key->ptr);\n        if (kde) {\n            robj *value = dictGetVal(kde);\n            signalKeyAsReady(db, key, value->type);\n        }\n    }\n    dictReleaseIterator(di);\n}\n\n/* Since we are unblocking XREADGROUP clients in the event the\n * key was deleted/overwritten we must do the same in case the\n * database was flushed/swapped. */\nvoid scanDatabaseForDeletedKeys(redisDb *emptied, redisDb *replaced_with) {\n    dictEntry *de;\n    dictIterator *di = dictGetSafeIterator(emptied->blocking_keys);\n    while((de = dictNext(di)) != NULL) {\n        robj *key = dictGetKey(de);\n        int existed = 0, exists = 0;\n        int original_type = -1, curr_type = -1;\n\n        dictEntry *kde = dictFind(emptied->dict, key->ptr);\n        if (kde) {\n            robj *value = dictGetVal(kde);\n            original_type = value->type;\n            existed = 1;\n        }\n\n        if (replaced_with) {\n            dictEntry *kde = dictFind(replaced_with->dict, key->ptr);\n            if (kde) {\n                robj *value = dictGetVal(kde);\n                curr_type = value->type;\n                exists = 1;\n            }\n        }\n        /* We want to try to unblock any client using a blocking XREADGROUP */\n        if ((existed && !exists) || original_type != curr_type)\n            signalDeletedKeyAsReady(emptied, key, original_type);\n    }\n    dictReleaseIterator(di);\n}\n\n/* Swap two databases at runtime so that all clients will magically see\n * the new database even if already connected. Note that the client\n * structure c->db points to a given DB, so we need to be smarter and\n * swap the underlying referenced structures, otherwise we would need\n * to fix all the references to the Redis DB structure.\n *\n * Returns C_ERR if at least one of the DB ids are out of range, otherwise\n * C_OK is returned. */\nint dbSwapDatabases(int id1, int id2) {\n    if (id1 < 0 || id1 >= server.dbnum ||\n        id2 < 0 || id2 >= server.dbnum) return C_ERR;\n    if (id1 == id2) return C_OK;\n    redisDb aux = server.db[id1];\n    redisDb *db1 = &server.db[id1], *db2 = &server.db[id2];\n\n    /* Swapdb should make transaction fail if there is any\n     * client watching keys */\n    touchAllWatchedKeysInDb(db1, db2);\n    touchAllWatchedKeysInDb(db2, db1);\n\n    /* Try to unblock any XREADGROUP clients if the key no longer exists. */\n    scanDatabaseForDeletedKeys(db1, db2);\n    scanDatabaseForDeletedKeys(db2, db1);\n\n    /* Swap hash tables. Note that we don't swap blocking_keys,\n     * ready_keys and watched_keys, since we want clients to\n     * remain in the same DB they were. */\n    db1->dict = db2->dict;\n    db1->expires = db2->expires;\n    db1->avg_ttl = db2->avg_ttl;\n    db1->expires_cursor = db2->expires_cursor;\n\n    db2->dict = aux.dict;\n    db2->expires = aux.expires;\n    db2->avg_ttl = aux.avg_ttl;\n    db2->expires_cursor = aux.expires_cursor;\n\n    /* Now we need to handle clients blocked on lists: as an effect\n     * of swapping the two DBs, a client that was waiting for list\n     * X in a given DB, may now actually be unblocked if X happens\n     * to exist in the new version of the DB, after the swap.\n     *\n     * However normally we only do this check for efficiency reasons\n     * in dbAdd() when a list is created. So here we need to rescan\n     * the list of clients blocked on lists and signal lists as ready\n     * if needed. */\n    scanDatabaseForReadyKeys(db1);\n    scanDatabaseForReadyKeys(db2);\n    return C_OK;\n}\n\n/* Logically, this discards (flushes) the old main database, and apply the newly loaded\n * database (temp) as the main (active) database, the actual freeing of old database\n * (which will now be placed in the temp one) is done later. */\nvoid swapMainDbWithTempDb(redisDb *tempDb) {\n    if (server.cluster_enabled) {\n        /* Swap slots_to_keys from tempdb just loaded with main db slots_to_keys. */\n        clusterSlotToKeyMapping *aux = server.db->slots_to_keys;\n        server.db->slots_to_keys = tempDb->slots_to_keys;\n        tempDb->slots_to_keys = aux;\n    }\n\n    for (int i=0; i<server.dbnum; i++) {\n        redisDb aux = server.db[i];\n        redisDb *activedb = &server.db[i], *newdb = &tempDb[i];\n\n        /* Swapping databases should make transaction fail if there is any\n         * client watching keys. */\n        touchAllWatchedKeysInDb(activedb, newdb);\n\n        /* Try to unblock any XREADGROUP clients if the key no longer exists. */\n        scanDatabaseForDeletedKeys(activedb, newdb);\n\n        /* Swap hash tables. Note that we don't swap blocking_keys,\n         * ready_keys and watched_keys, since clients \n         * remain in the same DB they were. */\n        activedb->dict = newdb->dict;\n        activedb->expires = newdb->expires;\n        activedb->avg_ttl = newdb->avg_ttl;\n        activedb->expires_cursor = newdb->expires_cursor;\n\n        newdb->dict = aux.dict;\n        newdb->expires = aux.expires;\n        newdb->avg_ttl = aux.avg_ttl;\n        newdb->expires_cursor = aux.expires_cursor;\n\n        /* Now we need to handle clients blocked on lists: as an effect\n         * of swapping the two DBs, a client that was waiting for list\n         * X in a given DB, may now actually be unblocked if X happens\n         * to exist in the new version of the DB, after the swap.\n         *\n         * However normally we only do this check for efficiency reasons\n         * in dbAdd() when a list is created. So here we need to rescan\n         * the list of clients blocked on lists and signal lists as ready\n         * if needed. */\n        scanDatabaseForReadyKeys(activedb);\n    }\n\n    trackingInvalidateKeysOnFlush(1);\n    flushSlaveKeysWithExpireList();\n}\n\n/* SWAPDB db1 db2 */\nvoid swapdbCommand(client *c) {\n    int id1, id2;\n\n    /* Not allowed in cluster mode: we have just DB 0 there. */\n    if (server.cluster_enabled) {\n        addReplyError(c,\"SWAPDB is not allowed in cluster mode\");\n        return;\n    }\n\n    /* Get the two DBs indexes. */\n    if (getIntFromObjectOrReply(c, c->argv[1], &id1,\n        \"invalid first DB index\") != C_OK)\n        return;\n\n    if (getIntFromObjectOrReply(c, c->argv[2], &id2,\n        \"invalid second DB index\") != C_OK)\n        return;\n\n    /* Swap... */\n    if (dbSwapDatabases(id1,id2) == C_ERR) {\n        addReplyError(c,\"DB index is out of range\");\n        return;\n    } else {\n        RedisModuleSwapDbInfo si = {REDISMODULE_SWAPDBINFO_VERSION,id1,id2};\n        moduleFireServerEvent(REDISMODULE_EVENT_SWAPDB,0,&si);\n        server.dirty++;\n        addReply(c,shared.ok);\n    }\n}\n\n/*-----------------------------------------------------------------------------\n * Expires API\n *----------------------------------------------------------------------------*/\n\nint removeExpire(redisDb *db, robj *key) {\n    return dictDelete(db->expires,key->ptr) == DICT_OK;\n}\n\n/* Set an expire to the specified key. If the expire is set in the context\n * of an user calling a command 'c' is the client, otherwise 'c' is set\n * to NULL. The 'when' parameter is the absolute unix time in milliseconds\n * after which the key will no longer be considered valid. */\nvoid setExpire(client *c, redisDb *db, robj *key, long long when) {\n    dictEntry *kde, *de;\n\n    /* Reuse the sds from the main dict in the expire dict */\n    kde = dictFind(db->dict,key->ptr);\n    serverAssertWithInfo(NULL,key,kde != NULL);\n    de = dictAddOrFind(db->expires,dictGetKey(kde));\n    dictSetSignedIntegerVal(de,when);\n\n    int writable_slave = server.masterhost && server.repl_slave_ro == 0;\n    if (c && writable_slave && !(c->flags & CLIENT_MASTER))\n        rememberSlaveKeyWithExpire(db,key);\n}\n\n/* Return the expire time of the specified key, or -1 if no expire\n * is associated with this key (i.e. the key is non volatile) */\nlong long getExpire(redisDb *db, robj *key) {\n    dictEntry *de;\n\n    /* No expire? return ASAP */\n    if (dictSize(db->expires) == 0 ||\n       (de = dictFind(db->expires,key->ptr)) == NULL) return -1;\n\n    return dictGetSignedIntegerVal(de);\n}\n\n/* Delete the specified expired key and propagate expire. */\nvoid deleteExpiredKeyAndPropagate(redisDb *db, robj *keyobj) {\n    mstime_t expire_latency;\n    latencyStartMonitor(expire_latency);\n    dbGenericDelete(db,keyobj,server.lazyfree_lazy_expire,DB_FLAG_KEY_EXPIRED);\n    latencyEndMonitor(expire_latency);\n    latencyAddSampleIfNeeded(\"expire-del\",expire_latency);\n    notifyKeyspaceEvent(NOTIFY_EXPIRED,\"expired\",keyobj,db->id);\n    signalModifiedKey(NULL, db, keyobj);\n    propagateDeletion(db,keyobj,server.lazyfree_lazy_expire);\n    server.stat_expiredkeys++;\n}\n\n/* Propagate expires into slaves and the AOF file.\n * When a key expires in the master, a DEL operation for this key is sent\n * to all the slaves and the AOF file if enabled.\n *\n * This way the key expiry is centralized in one place, and since both\n * AOF and the master->slave link guarantee operation ordering, everything\n * will be consistent even if we allow write operations against expiring\n * keys.\n *\n * This function may be called from:\n * 1. Within call(): Example: Lazy-expire on key access.\n *    In this case the caller doesn't have to do anything\n *    because call() handles server.also_propagate(); or\n * 2. Outside of call(): Example: Active-expire, eviction.\n *    In this the caller must remember to call\n *    postExecutionUnitOperations, preferably just after a\n *    single deletion batch, so that DELs will NOT be wrapped\n *    in MULTI/EXEC */\nvoid propagateDeletion(redisDb *db, robj *key, int lazy) {\n    robj *argv[2];\n\n    argv[0] = lazy ? shared.unlink : shared.del;\n    argv[1] = key;\n    incrRefCount(argv[0]);\n    incrRefCount(argv[1]);\n\n    /* If the master decided to expire a key we must propagate it to replicas no matter what..\n     * Even if module executed a command without asking for propagation. */\n    int prev_replication_allowed = server.replication_allowed;\n    server.replication_allowed = 1;\n    alsoPropagate(db->id,argv,2,PROPAGATE_AOF|PROPAGATE_REPL);\n    server.replication_allowed = prev_replication_allowed;\n\n    decrRefCount(argv[0]);\n    decrRefCount(argv[1]);\n}\n\n/* Check if the key is expired. */\nint keyIsExpired(redisDb *db, robj *key) {\n    /* Don't expire anything while loading. It will be done later. */\n    if (server.loading) return 0;\n\n    mstime_t when = getExpire(db,key);\n    mstime_t now;\n\n    if (when < 0) return 0; /* No expire for this key */\n\n    now = commandTimeSnapshot();\n\n    /* The key expired if the current (virtual or real) time is greater\n     * than the expire time of the key. */\n    return now > when;\n}\n\n/* This function is called when we are going to perform some operation\n * in a given key, but such key may be already logically expired even if\n * it still exists in the database. The main way this function is called\n * is via lookupKey*() family of functions.\n *\n * The behavior of the function depends on the replication role of the\n * instance, because by default replicas do not delete expired keys. They\n * wait for DELs from the master for consistency matters. However even\n * replicas will try to have a coherent return value for the function,\n * so that read commands executed in the replica side will be able to\n * behave like if the key is expired even if still present (because the\n * master has yet to propagate the DEL).\n *\n * In masters as a side effect of finding a key which is expired, such\n * key will be evicted from the database. Also this may trigger the\n * propagation of a DEL/UNLINK command in AOF / replication stream.\n *\n * On replicas, this function does not delete expired keys by default, but\n * it still returns 1 if the key is logically expired. To force deletion\n * of logically expired keys even on replicas, use the EXPIRE_FORCE_DELETE_EXPIRED\n * flag. Note though that if the current client is executing\n * replicated commands from the master, keys are never considered expired.\n *\n * On the other hand, if you just want expiration check, but need to avoid\n * the actual key deletion and propagation of the deletion, use the\n * EXPIRE_AVOID_DELETE_EXPIRED flag.\n *\n * The return value of the function is 0 if the key is still valid,\n * otherwise the function returns 1 if the key is expired. */\nint expireIfNeeded(redisDb *db, robj *key, int flags) {\n    if (server.lazy_expire_disabled) return 0;\n    if (!keyIsExpired(db,key)) return 0;\n\n    /* If we are running in the context of a replica, instead of\n     * evicting the expired key from the database, we return ASAP:\n     * the replica key expiration is controlled by the master that will\n     * send us synthesized DEL operations for expired keys. The\n     * exception is when write operations are performed on writable\n     * replicas.\n     *\n     * Still we try to return the right information to the caller,\n     * that is, 0 if we think the key should be still valid, 1 if\n     * we think the key is expired at this time.\n     *\n     * When replicating commands from the master, keys are never considered\n     * expired. */\n    if (server.masterhost != NULL) {\n        if (server.current_client && (server.current_client->flags & CLIENT_MASTER)) return 0;\n        if (!(flags & EXPIRE_FORCE_DELETE_EXPIRED)) return 1;\n    }\n\n    /* In some cases we're explicitly instructed to return an indication of a\n     * missing key without actually deleting it, even on masters. */\n    if (flags & EXPIRE_AVOID_DELETE_EXPIRED)\n        return 1;\n\n    /* If 'expire' action is paused, for whatever reason, then don't expire any key.\n     * Typically, at the end of the pause we will properly expire the key OR we\n     * will have failed over and the new primary will send us the expire. */\n    if (isPausedActionsWithUpdate(PAUSE_ACTION_EXPIRE)) return 1;\n\n    /* The key needs to be converted from static to heap before deleted */\n    int static_key = key->refcount == OBJ_STATIC_REFCOUNT;\n    if (static_key) {\n        key = createStringObject(key->ptr, sdslen(key->ptr));\n    }\n    /* Delete the key */\n    deleteExpiredKeyAndPropagate(db,key);\n    if (static_key) {\n        decrRefCount(key);\n    }\n    return 1;\n}\n\n/* -----------------------------------------------------------------------------\n * API to get key arguments from commands\n * ---------------------------------------------------------------------------*/\n\n/* Prepare the getKeysResult struct to hold numkeys, either by using the\n * pre-allocated keysbuf or by allocating a new array on the heap.\n *\n * This function must be called at least once before starting to populate\n * the result, and can be called repeatedly to enlarge the result array.\n */\nkeyReference *getKeysPrepareResult(getKeysResult *result, int numkeys) {\n    /* GETKEYS_RESULT_INIT initializes keys to NULL, point it to the pre-allocated stack\n     * buffer here. */\n    if (!result->keys) {\n        serverAssert(!result->numkeys);\n        result->keys = result->keysbuf;\n    }\n\n    /* Resize if necessary */\n    if (numkeys > result->size) {\n        if (result->keys != result->keysbuf) {\n            /* We're not using a static buffer, just (re)alloc */\n            result->keys = zrealloc(result->keys, numkeys * sizeof(keyReference));\n        } else {\n            /* We are using a static buffer, copy its contents */\n            result->keys = zmalloc(numkeys * sizeof(keyReference));\n            if (result->numkeys)\n                memcpy(result->keys, result->keysbuf, result->numkeys * sizeof(keyReference));\n        }\n        result->size = numkeys;\n    }\n\n    return result->keys;\n}\n\n/* Returns a bitmask with all the flags found in any of the key specs of the command.\n * The 'inv' argument means we'll return a mask with all flags that are missing in at least one spec. */\nint64_t getAllKeySpecsFlags(struct redisCommand *cmd, int inv) {\n    int64_t flags = 0;\n    for (int j = 0; j < cmd->key_specs_num; j++) {\n        keySpec *spec = cmd->key_specs + j;\n        flags |= inv? ~spec->flags : spec->flags;\n    }\n    return flags;\n}\n\n/* Fetch the keys based of the provided key specs. Returns the number of keys found, or -1 on error.\n * There are several flags that can be used to modify how this function finds keys in a command.\n * \n * GET_KEYSPEC_INCLUDE_NOT_KEYS: Return 'fake' keys as if they were keys.\n * GET_KEYSPEC_RETURN_PARTIAL:   Skips invalid and incomplete keyspecs but returns the keys\n *                               found in other valid keyspecs. \n */\nint getKeysUsingKeySpecs(struct redisCommand *cmd, robj **argv, int argc, int search_flags, getKeysResult *result) {\n    int j, i, last, first, step;\n    keyReference *keys;\n    serverAssert(result->numkeys == 0); /* caller should initialize or reset it */\n\n    for (j = 0; j < cmd->key_specs_num; j++) {\n        keySpec *spec = cmd->key_specs + j;\n        serverAssert(spec->begin_search_type != KSPEC_BS_INVALID);\n        /* Skip specs that represent 'fake' keys */\n        if ((spec->flags & CMD_KEY_NOT_KEY) && !(search_flags & GET_KEYSPEC_INCLUDE_NOT_KEYS)) {\n            continue;\n        }\n\n        first = 0;\n        if (spec->begin_search_type == KSPEC_BS_INDEX) {\n            first = spec->bs.index.pos;\n        } else if (spec->begin_search_type == KSPEC_BS_KEYWORD) {\n            int start_index = spec->bs.keyword.startfrom > 0 ? spec->bs.keyword.startfrom : argc+spec->bs.keyword.startfrom;\n            int end_index = spec->bs.keyword.startfrom > 0 ? argc-1: 1;\n            for (i = start_index; i != end_index; i = start_index <= end_index ? i + 1 : i - 1) {\n                if (i >= argc || i < 1)\n                    break;\n                if (!strcasecmp((char*)argv[i]->ptr,spec->bs.keyword.keyword)) {\n                    first = i+1;\n                    break;\n                }\n            }\n            /* keyword not found */\n            if (!first) {\n                continue;\n            }\n        } else {\n            /* unknown spec */\n            goto invalid_spec;\n        }\n\n        if (spec->find_keys_type == KSPEC_FK_RANGE) {\n            step = spec->fk.range.keystep;\n            if (spec->fk.range.lastkey >= 0) {\n                last = first + spec->fk.range.lastkey;\n            } else {\n                if (!spec->fk.range.limit) {\n                    last = argc + spec->fk.range.lastkey;\n                } else {\n                    serverAssert(spec->fk.range.lastkey == -1);\n                    last = first + ((argc-first)/spec->fk.range.limit + spec->fk.range.lastkey);\n                }\n            }\n        } else if (spec->find_keys_type == KSPEC_FK_KEYNUM) {\n            step = spec->fk.keynum.keystep;\n            long long numkeys;\n            if (spec->fk.keynum.keynumidx >= argc)\n                goto invalid_spec;\n\n            sds keynum_str = argv[first + spec->fk.keynum.keynumidx]->ptr;\n            if (!string2ll(keynum_str,sdslen(keynum_str),&numkeys) || numkeys < 0) {\n                /* Unable to parse the numkeys argument or it was invalid */\n                goto invalid_spec;\n            }\n\n            first += spec->fk.keynum.firstkey;\n            last = first + (int)numkeys-1;\n        } else {\n            /* unknown spec */\n            goto invalid_spec;\n        }\n\n        int count = ((last - first)+1);\n        keys = getKeysPrepareResult(result, result->numkeys + count);\n\n        /* First or last is out of bounds, which indicates a syntax error */\n        if (last >= argc || last < first || first >= argc) {\n            goto invalid_spec;\n        }\n\n        for (i = first; i <= last; i += step) {\n            if (i >= argc || i < first) {\n                /* Modules commands, and standard commands with a not fixed number\n                 * of arguments (negative arity parameter) do not have dispatch\n                 * time arity checks, so we need to handle the case where the user\n                 * passed an invalid number of arguments here. In this case we\n                 * return no keys and expect the command implementation to report\n                 * an arity or syntax error. */\n                if (cmd->flags & CMD_MODULE || cmd->arity < 0) {\n                    continue;\n                } else {\n                    serverPanic(\"Redis built-in command declared keys positions not matching the arity requirements.\");\n                }\n            }\n            keys[result->numkeys].pos = i;\n            keys[result->numkeys].flags = spec->flags;\n            result->numkeys++;\n        }\n\n        /* Handle incomplete specs (only after we added the current spec\n         * to `keys`, just in case GET_KEYSPEC_RETURN_PARTIAL was given) */\n        if (spec->flags & CMD_KEY_INCOMPLETE) {\n            goto invalid_spec;\n        }\n\n        /* Done with this spec */\n        continue;\n\ninvalid_spec:\n        if (search_flags & GET_KEYSPEC_RETURN_PARTIAL) {\n            continue;\n        } else {\n            result->numkeys = 0;\n            return -1;\n        }\n    }\n\n    return result->numkeys;\n}\n\n/* Return all the arguments that are keys in the command passed via argc / argv. \n * This function will eventually replace getKeysFromCommand.\n *\n * The command returns the positions of all the key arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n * \n * Along with the position, this command also returns the flags that are\n * associated with how Redis will access the key.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0]. */\nint getKeysFromCommandWithSpecs(struct redisCommand *cmd, robj **argv, int argc, int search_flags, getKeysResult *result) {\n    /* The command has at least one key-spec not marked as NOT_KEY */\n    int has_keyspec = (getAllKeySpecsFlags(cmd, 1) & CMD_KEY_NOT_KEY);\n    /* The command has at least one key-spec marked as VARIABLE_FLAGS */\n    int has_varflags = (getAllKeySpecsFlags(cmd, 0) & CMD_KEY_VARIABLE_FLAGS);\n\n    /* We prefer key-specs if there are any, and their flags are reliable. */\n    if (has_keyspec && !has_varflags) {\n        int ret = getKeysUsingKeySpecs(cmd,argv,argc,search_flags,result);\n        if (ret >= 0)\n            return ret;\n        /* If the specs returned with an error (probably an INVALID or INCOMPLETE spec),\n         * fallback to the callback method. */\n    }\n\n    /* Resort to getkeys callback methods. */\n    if (cmd->flags & CMD_MODULE_GETKEYS)\n        return moduleGetCommandKeysViaAPI(cmd,argv,argc,result);\n\n    /* We use native getkeys as a last resort, since not all these native getkeys provide\n     * flags properly (only the ones that correspond to INVALID, INCOMPLETE or VARIABLE_FLAGS do.*/\n    if (cmd->getkeys_proc)\n        return cmd->getkeys_proc(cmd,argv,argc,result);\n    return 0;\n}\n\n/* This function returns a sanity check if the command may have keys. */\nint doesCommandHaveKeys(struct redisCommand *cmd) {\n    return cmd->getkeys_proc ||                                 /* has getkeys_proc (non modules) */\n        (cmd->flags & CMD_MODULE_GETKEYS) ||                    /* module with GETKEYS */\n        (getAllKeySpecsFlags(cmd, 1) & CMD_KEY_NOT_KEY);        /* has at least one key-spec not marked as NOT_KEY */\n}\n\n/* A simplified channel spec table that contains all of the redis commands\n * and which channels they have and how they are accessed. */\ntypedef struct ChannelSpecs {\n    redisCommandProc *proc; /* Command procedure to match against */\n    uint64_t flags;         /* CMD_CHANNEL_* flags for this command */\n    int start;              /* The initial position of the first channel */\n    int count;              /* The number of channels, or -1 if all remaining\n                             * arguments are channels. */\n} ChannelSpecs;\n\nChannelSpecs commands_with_channels[] = {\n    {subscribeCommand, CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {ssubscribeCommand, CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {unsubscribeCommand, CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {sunsubscribeCommand, CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {psubscribeCommand, CMD_CHANNEL_PATTERN | CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {punsubscribeCommand, CMD_CHANNEL_PATTERN | CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {publishCommand, CMD_CHANNEL_PUBLISH, 1, 1},\n    {spublishCommand, CMD_CHANNEL_PUBLISH, 1, 1},\n    {NULL,0} /* Terminator. */\n};\n\n/* Returns 1 if the command may access any channels matched by the flags\n * argument. */\nint doesCommandHaveChannelsWithFlags(struct redisCommand *cmd, int flags) {\n    /* If a module declares get channels, we are just going to assume\n     * has channels. This API is allowed to return false positives. */\n    if (cmd->flags & CMD_MODULE_GETCHANNELS) {\n        return 1;\n    }\n    for (ChannelSpecs *spec = commands_with_channels; spec->proc != NULL; spec += 1) {\n        if (cmd->proc == spec->proc) {\n            return !!(spec->flags & flags);\n        }\n    }\n    return 0;\n}\n\n/* Return all the arguments that are channels in the command passed via argc / argv. \n * This function behaves similar to getKeysFromCommandWithSpecs, but with channels \n * instead of keys.\n * \n * The command returns the positions of all the channel arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n * \n * Along with the position, this command also returns the flags that are\n * associated with how Redis will access the channel.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0]. */\nint getChannelsFromCommand(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    /* If a module declares get channels, use that. */\n    if (cmd->flags & CMD_MODULE_GETCHANNELS) {\n        return moduleGetCommandChannelsViaAPI(cmd, argv, argc, result);\n    }\n    /* Otherwise check the channel spec table */\n    for (ChannelSpecs *spec = commands_with_channels; spec != NULL; spec += 1) {\n        if (cmd->proc == spec->proc) {\n            int start = spec->start;\n            int stop = (spec->count == -1) ? argc : start + spec->count;\n            if (stop > argc) stop = argc;\n            int count = 0;\n            keys = getKeysPrepareResult(result, stop - start);\n            for (int i = start; i < stop; i++ ) {\n                keys[count].pos = i;\n                keys[count++].flags = spec->flags;\n            }\n            result->numkeys = count;\n            return count;\n        }\n    }\n    return 0;\n}\n\n/* The base case is to use the keys position as given in the command table\n * (firstkey, lastkey, step).\n * This function works only on command with the legacy_range_key_spec,\n * all other commands should be handled by getkeys_proc. \n * \n * If the commands keyspec is incomplete, no keys will be returned, and the provided\n * keys function should be called instead.\n * \n * NOTE: This function does not guarantee populating the flags for \n * the keys, in order to get flags you should use getKeysUsingKeySpecs. */\nint getKeysUsingLegacyRangeSpec(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int j, i = 0, last, first, step;\n    keyReference *keys;\n    UNUSED(argv);\n\n    if (cmd->legacy_range_key_spec.begin_search_type == KSPEC_BS_INVALID) {\n        result->numkeys = 0;\n        return 0;\n    }\n\n    first = cmd->legacy_range_key_spec.bs.index.pos;\n    last = cmd->legacy_range_key_spec.fk.range.lastkey;\n    if (last >= 0)\n        last += first;\n    step = cmd->legacy_range_key_spec.fk.range.keystep;\n\n    if (last < 0) last = argc+last;\n\n    int count = ((last - first)+1);\n    keys = getKeysPrepareResult(result, count);\n\n    for (j = first; j <= last; j += step) {\n        if (j >= argc || j < first) {\n            /* Modules commands, and standard commands with a not fixed number\n             * of arguments (negative arity parameter) do not have dispatch\n             * time arity checks, so we need to handle the case where the user\n             * passed an invalid number of arguments here. In this case we\n             * return no keys and expect the command implementation to report\n             * an arity or syntax error. */\n            if (cmd->flags & CMD_MODULE || cmd->arity < 0) {\n                result->numkeys = 0;\n                return 0;\n            } else {\n                serverPanic(\"Redis built-in command declared keys positions not matching the arity requirements.\");\n            }\n        }\n        keys[i].pos = j;\n        /* Flags are omitted from legacy key specs */\n        keys[i++].flags = 0;\n    }\n    result->numkeys = i;\n    return i;\n}\n\n/* Return all the arguments that are keys in the command passed via argc / argv.\n *\n * The command returns the positions of all the key arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0].\n *\n * This function uses the command table if a command-specific helper function\n * is not required, otherwise it calls the command-specific function. */\nint getKeysFromCommand(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    if (cmd->flags & CMD_MODULE_GETKEYS) {\n        return moduleGetCommandKeysViaAPI(cmd,argv,argc,result);\n    } else if (cmd->getkeys_proc) {\n        return cmd->getkeys_proc(cmd,argv,argc,result);\n    } else {\n        return getKeysUsingLegacyRangeSpec(cmd,argv,argc,result);\n    }\n}\n\n/* Free the result of getKeysFromCommand. */\nvoid getKeysFreeResult(getKeysResult *result) {\n    if (result && result->keys != result->keysbuf)\n        zfree(result->keys);\n}\n\n/* Helper function to extract keys from following commands:\n * COMMAND [destkey] <num-keys> <key> [...] <key> [...] ... <options>\n *\n * eg:\n * ZUNION <num-keys> <key> <key> ... <key> <options>\n * ZUNIONSTORE <destkey> <num-keys> <key> <key> ... <key> <options>\n *\n * 'storeKeyOfs': destkey index, 0 means destkey not exists.\n * 'keyCountOfs': num-keys index.\n * 'firstKeyOfs': firstkey index.\n * 'keyStep': the interval of each key, usually this value is 1.\n * \n * The commands using this function have a fully defined keyspec, so returning flags isn't needed. */\nint genericGetKeys(int storeKeyOfs, int keyCountOfs, int firstKeyOfs, int keyStep,\n                    robj **argv, int argc, getKeysResult *result) {\n    int i, num;\n    keyReference *keys;\n\n    num = atoi(argv[keyCountOfs]->ptr);\n    /* Sanity check. Don't return any key if the command is going to\n     * reply with syntax error. (no input keys). */\n    if (num < 1 || num > (argc - firstKeyOfs)/keyStep) {\n        result->numkeys = 0;\n        return 0;\n    }\n\n    int numkeys = storeKeyOfs ? num + 1 : num;\n    keys = getKeysPrepareResult(result, numkeys);\n    result->numkeys = numkeys;\n\n    /* Add all key positions for argv[firstKeyOfs...n] to keys[] */\n    for (i = 0; i < num; i++) {\n        keys[i].pos = firstKeyOfs+(i*keyStep);\n        keys[i].flags = 0;\n    } \n\n    if (storeKeyOfs) {\n        keys[num].pos = storeKeyOfs;\n        keys[num].flags = 0;\n    } \n    return result->numkeys;\n}\n\nint sintercardGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint zunionInterDiffStoreGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(1, 2, 3, 1, argv, argc, result);\n}\n\nint zunionInterDiffGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint evalGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint functionGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint lmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint blmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint zmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint bzmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\n/* Helper function to extract keys from the SORT RO command.\n *\n * SORT <sort-key>\n *\n * The second argument of SORT is always a key, however an arbitrary number of\n * keys may be accessed while doing the sort (the BY and GET args), so the\n * key-spec declares incomplete keys which is why we have to provide a concrete\n * implementation to fetch the keys.\n *\n * This command declares incomplete keys, so the flags are correctly set for this function */\nint sortROGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n    UNUSED(argv);\n    UNUSED(argc);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* <sort-key> is always present. */\n    keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    result->numkeys = 1;\n    return result->numkeys;\n}\n\n/* Helper function to extract keys from the SORT command.\n *\n * SORT <sort-key> ... STORE <store-key> ...\n *\n * The first argument of SORT is always a key, however a list of options\n * follow in SQL-alike style. Here we parse just the minimum in order to\n * correctly identify keys in the \"STORE\" option. \n * \n * This command declares incomplete keys, so the flags are correctly set for this function */\nint sortGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, j, num, found_store = 0;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    num = 0;\n    keys = getKeysPrepareResult(result, 2); /* Alloc 2 places for the worst case. */\n    keys[num].pos = 1; /* <sort-key> is always present. */\n    keys[num++].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n\n    /* Search for STORE option. By default we consider options to don't\n     * have arguments, so if we find an unknown option name we scan the\n     * next. However there are options with 1 or 2 arguments, so we\n     * provide a list here in order to skip the right number of args. */\n    struct {\n        char *name;\n        int skip;\n    } skiplist[] = {\n        {\"limit\", 2},\n        {\"get\", 1},\n        {\"by\", 1},\n        {NULL, 0} /* End of elements. */\n    };\n\n    for (i = 2; i < argc; i++) {\n        for (j = 0; skiplist[j].name != NULL; j++) {\n            if (!strcasecmp(argv[i]->ptr,skiplist[j].name)) {\n                i += skiplist[j].skip;\n                break;\n            } else if (!strcasecmp(argv[i]->ptr,\"store\") && i+1 < argc) {\n                /* Note: we don't increment \"num\" here and continue the loop\n                 * to be sure to process the *last* \"STORE\" option if multiple\n                 * ones are provided. This is same behavior as SORT. */\n                found_store = 1;\n                keys[num].pos = i+1; /* <store-key> */\n                keys[num].flags = CMD_KEY_OW | CMD_KEY_UPDATE;\n                break;\n            }\n        }\n    }\n    result->numkeys = num + found_store;\n    return result->numkeys;\n}\n\n/* This command declares incomplete keys, so the flags are correctly set for this function */\nint migrateGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, j, num, first;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* Assume the obvious form. */\n    first = 3;\n    num = 1;\n\n    /* But check for the extended one with the KEYS option. */\n    struct {\n        char* name;\n        int skip;\n    } skip_keywords[] = {       \n        {\"copy\", 0},\n        {\"replace\", 0},\n        {\"auth\", 1},\n        {\"auth2\", 2},\n        {NULL, 0}\n    };\n    if (argc > 6) {\n        for (i = 6; i < argc; i++) {\n            if (!strcasecmp(argv[i]->ptr, \"keys\")) {\n                if (sdslen(argv[3]->ptr) > 0) {\n                    /* This is a syntax error. So ignore the keys and leave\n                     * the syntax error to be handled by migrateCommand. */\n                    num = 0; \n                } else {\n                    first = i + 1;\n                    num = argc - first;\n                }\n                break;\n            }\n            for (j = 0; skip_keywords[j].name != NULL; j++) {\n                if (!strcasecmp(argv[i]->ptr, skip_keywords[j].name)) {\n                    i += skip_keywords[j].skip;\n                    break;\n                }\n            }\n        }\n    }\n\n    keys = getKeysPrepareResult(result, num);\n    for (i = 0; i < num; i++) {\n        keys[i].pos = first+i;\n        keys[i].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_DELETE;\n    } \n    result->numkeys = num;\n    return num;\n}\n\n/* Helper function to extract keys from following commands:\n * GEORADIUS key x y radius unit [WITHDIST] [WITHHASH] [WITHCOORD] [ASC|DESC]\n *                             [COUNT count] [STORE key|STOREDIST key]\n * GEORADIUSBYMEMBER key member radius unit ... options ...\n * \n * This command has a fully defined keyspec, so returning flags isn't needed. */\nint georadiusGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, num;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* Check for the presence of the stored key in the command */\n    int stored_key = -1;\n    for (i = 5; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        /* For the case when user specifies both \"store\" and \"storedist\" options, the\n         * second key specified would override the first key. This behavior is kept\n         * the same as in georadiusCommand method.\n         */\n        if ((!strcasecmp(arg, \"store\") || !strcasecmp(arg, \"storedist\")) && ((i+1) < argc)) {\n            stored_key = i+1;\n            i++;\n        }\n    }\n    num = 1 + (stored_key == -1 ? 0 : 1);\n\n    /* Keys in the command come from two places:\n     * argv[1] = key,\n     * argv[5...n] = stored key if present\n     */\n    keys = getKeysPrepareResult(result, num);\n\n    /* Add all key positions to keys[] */\n    keys[0].pos = 1;\n    keys[0].flags = 0;\n    if(num > 1) {\n         keys[1].pos = stored_key;\n         keys[1].flags = 0;\n    }\n    result->numkeys = num;\n    return num;\n}\n\n/* XREAD [BLOCK <milliseconds>] [COUNT <count>] [GROUP <groupname> <ttl>]\n *       STREAMS key_1 key_2 ... key_N ID_1 ID_2 ... ID_N\n *\n * This command has a fully defined keyspec, so returning flags isn't needed. */\nint xreadGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, num = 0;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* We need to parse the options of the command in order to seek the first\n     * \"STREAMS\" string which is actually the option. This is needed because\n     * \"STREAMS\" could also be the name of the consumer group and even the\n     * name of the stream key. */\n    int streams_pos = -1;\n    for (i = 1; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        if (!strcasecmp(arg, \"block\")) {\n            i++; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"count\")) {\n            i++; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"group\")) {\n            i += 2; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"noack\")) {\n            /* Nothing to do. */\n        } else if (!strcasecmp(arg, \"streams\")) {\n            streams_pos = i;\n            break;\n        } else {\n            break; /* Syntax error. */\n        }\n    }\n    if (streams_pos != -1) num = argc - streams_pos - 1;\n\n    /* Syntax error. */\n    if (streams_pos == -1 || num == 0 || num % 2 != 0) {\n        result->numkeys = 0;\n        return 0;\n    }\n    num /= 2; /* We have half the keys as there are arguments because\n                 there are also the IDs, one per key. */\n\n    keys = getKeysPrepareResult(result, num);\n    for (i = streams_pos+1; i < argc-num; i++) {\n        keys[i-streams_pos-1].pos = i;\n        keys[i-streams_pos-1].flags = 0; \n    } \n    result->numkeys = num;\n    return num;\n}\n\n/* Helper function to extract keys from the SET command, which may have\n * a read flag if the GET argument is passed in. */\nint setGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* We always know the position */\n    result->numkeys = 1;\n\n    for (int i = 3; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        if ((arg[0] == 'g' || arg[0] == 'G') &&\n            (arg[1] == 'e' || arg[1] == 'E') &&\n            (arg[2] == 't' || arg[2] == 'T') && arg[3] == '\\0')\n        {\n            keys[0].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_UPDATE;\n            return 1;\n        }\n    }\n\n    keys[0].flags = CMD_KEY_OW | CMD_KEY_UPDATE;\n    return 1;\n}\n\n/* Helper function to extract keys from the BITFIELD command, which may be\n * read-only if the BITFIELD GET subcommand is used. */\nint bitfieldGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    int readonly = 1;\n    UNUSED(cmd);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* We always know the position */\n    result->numkeys = 1;\n\n    for (int i = 2; i < argc; i++) {\n        int remargs = argc - i - 1; /* Remaining args other than current. */\n        char *arg = argv[i]->ptr;\n        if (!strcasecmp(arg, \"get\") && remargs >= 2) {\n            i += 2;\n        } else if ((!strcasecmp(arg, \"set\") || !strcasecmp(arg, \"incrby\")) && remargs >= 3) {\n            readonly = 0;\n            i += 3;\n            break;\n        } else if (!strcasecmp(arg, \"overflow\") && remargs >= 1) {\n            i += 1;\n        } else {\n            readonly = 0; /* Syntax error. safer to assume non-RO. */\n            break;\n        }\n    }\n\n    if (readonly) {\n        keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    } else {\n        keys[0].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_UPDATE;\n    }\n    return 1;\n}\n", "start_server {\n    tags {\"sort\"}\n    overrides {\n        \"list-max-ziplist-size\" 16\n        \"set-max-intset-entries\" 32\n    }\n} {\n    proc create_random_dataset {num cmd} {\n        set tosort {}\n        set result {}\n        array set seenrand {}\n        r del tosort\n        for {set i 0} {$i < $num} {incr i} {\n            # Make sure all the weights are different because\n            # Redis does not use a stable sort but Tcl does.\n            while 1 {\n                randpath {\n                    set rint [expr int(rand()*1000000)]\n                } {\n                    set rint [expr rand()]\n                }\n                if {![info exists seenrand($rint)]} break\n            }\n            set seenrand($rint) x\n            r $cmd tosort $i\n            r set weight_$i $rint\n            r hset wobj_$i weight $rint\n            lappend tosort [list $i $rint]\n        }\n        set sorted [lsort -index 1 -real $tosort]\n        for {set i 0} {$i < $num} {incr i} {\n            lappend result [lindex $sorted $i 0]\n        }\n        set _ $result\n    }\n\n    proc check_sort_store_encoding {key} {\n        set listpack_max_size [lindex [r config get list-max-ziplist-size] 1]\n\n        # When the length or size of quicklist is less than the limit,\n        # it will be converted to listpack.\n        if {[r llen $key] <= $listpack_max_size} {\n            assert_encoding listpack $key\n        } else {\n            assert_encoding quicklist $key\n        }\n    }\n\n    foreach {num cmd enc title} {\n        16 lpush listpack \"Listpack\"\n        1000 lpush quicklist \"Quicklist\"\n        10000 lpush quicklist \"Big Quicklist\"\n        16 sadd intset \"Intset\"\n        1000 sadd hashtable \"Hash table\"\n        10000 sadd hashtable \"Big Hash table\"\n    } {\n        set result [create_random_dataset $num $cmd]\n        assert_encoding $enc tosort\n\n        test \"$title: SORT BY key\" {\n            assert_equal $result [r sort tosort BY weight_*]\n        } {} {cluster:skip}\n\n        test \"$title: SORT BY key with limit\" {\n            assert_equal [lrange $result 5 9] [r sort tosort BY weight_* LIMIT 5 5]\n        } {} {cluster:skip}\n\n        test \"$title: SORT BY hash field\" {\n            assert_equal $result [r sort tosort BY wobj_*->weight]\n        } {} {cluster:skip}\n    }\n\n    set result [create_random_dataset 16 lpush]\n    test \"SORT GET #\" {\n        assert_equal [lsort -integer $result] [r sort tosort GET #]\n    } {} {cluster:skip}\n\n    test \"SORT GET <const>\" {\n        r del foo\n        set res [r sort tosort GET foo]\n        assert_equal 16 [llength $res]\n        foreach item $res { assert_equal {} $item }\n    } {} {cluster:skip}\n\n    test \"SORT GET (key and hash) with sanity check\" {\n        set l1 [r sort tosort GET # GET weight_*]\n        set l2 [r sort tosort GET # GET wobj_*->weight]\n        foreach {id1 w1} $l1 {id2 w2} $l2 {\n            assert_equal $id1 $id2\n            assert_equal $w1 [r get weight_$id1]\n            assert_equal $w2 [r get weight_$id1]\n        }\n    } {} {cluster:skip}\n\n    test \"SORT BY key STORE\" {\n        r sort tosort BY weight_* store sort-res\n        assert_equal $result [r lrange sort-res 0 -1]\n        assert_equal 16 [r llen sort-res]\n        check_sort_store_encoding sort-res\n    } {} {cluster:skip}\n\n    test \"SORT BY hash field STORE\" {\n        r sort tosort BY wobj_*->weight store sort-res\n        assert_equal $result [r lrange sort-res 0 -1]\n        assert_equal 16 [r llen sort-res]\n        check_sort_store_encoding sort-res\n    } {} {cluster:skip}\n\n    test \"SORT extracts STORE correctly\" {\n        r command getkeys sort abc store def\n    } {abc def}\n    \n    test \"SORT_RO get keys\" {\n        r command getkeys sort_ro abc\n    } {abc}\n\n    test \"SORT extracts multiple STORE correctly\" {\n        r command getkeys sort abc store invalid store stillbad store def\n    } {abc def}\n\n    test \"SORT DESC\" {\n        assert_equal [lsort -decreasing -integer $result] [r sort tosort DESC]\n    }\n\n    test \"SORT ALPHA against integer encoded strings\" {\n        r del mylist\n        r lpush mylist 2\n        r lpush mylist 1\n        r lpush mylist 3\n        r lpush mylist 10\n        r sort mylist alpha\n    } {1 10 2 3}\n\n    test \"SORT sorted set\" {\n        r del zset\n        r zadd zset 1 a\n        r zadd zset 5 b\n        r zadd zset 2 c\n        r zadd zset 10 d\n        r zadd zset 3 e\n        r sort zset alpha desc\n    } {e d c b a}\n\n    test \"SORT sorted set BY nosort should retain ordering\" {\n        r del zset\n        r zadd zset 1 a\n        r zadd zset 5 b\n        r zadd zset 2 c\n        r zadd zset 10 d\n        r zadd zset 3 e\n        r multi\n        r sort zset by nosort asc\n        r sort zset by nosort desc\n        r exec\n    } {{a c e b d} {d b e c a}}\n\n    test \"SORT sorted set BY nosort + LIMIT\" {\n        r del zset\n        r zadd zset 1 a\n        r zadd zset 5 b\n        r zadd zset 2 c\n        r zadd zset 10 d\n        r zadd zset 3 e\n        assert_equal [r sort zset by nosort asc limit 0 1] {a}\n        assert_equal [r sort zset by nosort desc limit 0 1] {d}\n        assert_equal [r sort zset by nosort asc limit 0 2] {a c}\n        assert_equal [r sort zset by nosort desc limit 0 2] {d b}\n        assert_equal [r sort zset by nosort limit 5 10] {}\n        assert_equal [r sort zset by nosort limit -10 100] {a c e b d}\n    }\n\n    test \"SORT sorted set BY nosort works as expected from scripts\" {\n        r del zset\n        r zadd zset 1 a\n        r zadd zset 5 b\n        r zadd zset 2 c\n        r zadd zset 10 d\n        r zadd zset 3 e\n        r eval {\n            return {redis.call('sort',KEYS[1],'by','nosort','asc'),\n                    redis.call('sort',KEYS[1],'by','nosort','desc')}\n        } 1 zset\n    } {{a c e b d} {d b e c a}}\n\n    test \"SORT sorted set: +inf and -inf handling\" {\n        r del zset\n        r zadd zset -100 a\n        r zadd zset 200 b\n        r zadd zset -300 c\n        r zadd zset 1000000 d\n        r zadd zset +inf max\n        r zadd zset -inf min\n        r zrange zset 0 -1\n    } {min c a b d max}\n\n    test \"SORT regression for issue #19, sorting floats\" {\n        r flushdb\n        set floats {1.1 5.10 3.10 7.44 2.1 5.75 6.12 0.25 1.15}\n        foreach x $floats {\n            r lpush mylist $x\n        }\n        assert_equal [lsort -real $floats] [r sort mylist]\n    }\n\n    test \"SORT with STORE returns zero if result is empty (github issue 224)\" {\n        r flushdb\n        r sort foo{t} store bar{t}\n    } {0}\n\n    test \"SORT with STORE does not create empty lists (github issue 224)\" {\n        r flushdb\n        r lpush foo{t} bar\n        r sort foo{t} alpha limit 10 10 store zap{t}\n        r exists zap{t}\n    } {0}\n\n    test \"SORT with STORE removes key if result is empty (github issue 227)\" {\n        r flushdb\n        r lpush foo{t} bar\n        r sort emptylist{t} store foo{t}\n        r exists foo{t}\n    } {0}\n\n    test \"SORT with BY <constant> and STORE should still order output\" {\n        r del myset mylist\n        r sadd myset a b c d e f g h i l m n o p q r s t u v z aa aaa azz\n        r sort myset alpha by _ store mylist\n        r lrange mylist 0 -1\n    } {a aa aaa azz b c d e f g h i l m n o p q r s t u v z} {cluster:skip}\n\n    test \"SORT will complain with numerical sorting and bad doubles (1)\" {\n        r del myset\n        r sadd myset 1 2 3 4 not-a-double\n        set e {}\n        catch {r sort myset} e\n        set e\n    } {*ERR*double*}\n\n    test \"SORT will complain with numerical sorting and bad doubles (2)\" {\n        r del myset\n        r sadd myset 1 2 3 4\n        r mset score:1 10 score:2 20 score:3 30 score:4 not-a-double\n        set e {}\n        catch {r sort myset by score:*} e\n        set e\n    } {*ERR*double*} {cluster:skip}\n\n    test \"SORT BY sub-sorts lexicographically if score is the same\" {\n        r del myset\n        r sadd myset a b c d e f g h i l m n o p q r s t u v z aa aaa azz\n        foreach ele {a aa aaa azz b c d e f g h i l m n o p q r s t u v z} {\n            set score:$ele 100\n        }\n        r sort myset by score:*\n    } {a aa aaa azz b c d e f g h i l m n o p q r s t u v z} {cluster:skip}\n\n    test \"SORT GET with pattern ending with just -> does not get hash field\" {\n        r del mylist\n        r lpush mylist a\n        r set x:a-> 100\n        r sort mylist by num get x:*->\n    } {100} {cluster:skip}\n\n    test \"SORT by nosort retains native order for lists\" {\n        r del testa\n        r lpush testa 2 1 4 3 5\n        r sort testa by nosort\n    } {5 3 4 1 2} {cluster:skip}\n\n    test \"SORT by nosort plus store retains native order for lists\" {\n        r del testa\n        r lpush testa 2 1 4 3 5\n        r sort testa by nosort store testb\n        r lrange testb 0 -1\n    } {5 3 4 1 2} {cluster:skip}\n\n    test \"SORT by nosort with limit returns based on original list order\" {\n        r sort testa by nosort limit 0 3 store testb\n        r lrange testb 0 -1\n    } {5 3 4} {cluster:skip}\n\n    test \"SORT_RO - Successful case\" {\n        r del mylist\n        r lpush mylist a\n        r set x:a 100\n        r sort_ro mylist by nosort get x:*->\n    } {100} {cluster:skip}\n\n    test \"SORT_RO - Cannot run with STORE arg\" {\n        catch {r sort_ro foolist STORE bar} e\n        set e\n    } {ERR syntax error}\n\n    tags {\"slow\"} {\n        set num 100\n        set res [create_random_dataset $num lpush]\n\n        test \"SORT speed, $num element list BY key, 100 times\" {\n            set start [clock clicks -milliseconds]\n            for {set i 0} {$i < 100} {incr i} {\n                set sorted [r sort tosort BY weight_* LIMIT 0 10]\n            }\n            set elapsed [expr [clock clicks -milliseconds]-$start]\n            if {$::verbose} {\n                puts -nonewline \"\\n  Average time to sort: [expr double($elapsed)/100] milliseconds \"\n                flush stdout\n            }\n        } {} {cluster:skip}\n\n        test \"SORT speed, $num element list BY hash field, 100 times\" {\n            set start [clock clicks -milliseconds]\n            for {set i 0} {$i < 100} {incr i} {\n                set sorted [r sort tosort BY wobj_*->weight LIMIT 0 10]\n            }\n            set elapsed [expr [clock clicks -milliseconds]-$start]\n            if {$::verbose} {\n                puts -nonewline \"\\n  Average time to sort: [expr double($elapsed)/100] milliseconds \"\n                flush stdout\n            }\n        } {} {cluster:skip}\n\n        test \"SORT speed, $num element list directly, 100 times\" {\n            set start [clock clicks -milliseconds]\n            for {set i 0} {$i < 100} {incr i} {\n                set sorted [r sort tosort LIMIT 0 10]\n            }\n            set elapsed [expr [clock clicks -milliseconds]-$start]\n            if {$::verbose} {\n                puts -nonewline \"\\n  Average time to sort: [expr double($elapsed)/100] milliseconds \"\n                flush stdout\n            }\n        }\n\n        test \"SORT speed, $num element list BY <const>, 100 times\" {\n            set start [clock clicks -milliseconds]\n            for {set i 0} {$i < 100} {incr i} {\n                set sorted [r sort tosort BY nokey LIMIT 0 10]\n            }\n            set elapsed [expr [clock clicks -milliseconds]-$start]\n            if {$::verbose} {\n                puts -nonewline \"\\n  Average time to sort: [expr double($elapsed)/100] milliseconds \"\n                flush stdout\n            }\n        } {} {cluster:skip}\n    }\n\n    test {SETRANGE with huge offset} {\n        r lpush L 2 1 0\n        # expecting a different outcome on 32 and 64 bit systems\n        foreach value {9223372036854775807 2147483647} {\n            catch {[r sort_ro L by a limit 2 $value]} res\n            if {![string match \"2\" $res] && ![string match \"*out of range*\" $res]} {\n                assert_not_equal $res \"expecting an error or 2\"\n            }\n        }\n    }\n}\n"], "filenames": ["src/db.c", "tests/unit/sort.tcl"], "buggy_code_start_loc": [2297, 111], "buggy_code_end_loc": [2298, 111], "fixing_code_start_loc": [2297, 112], "fixing_code_end_loc": [2299, 116], "type": "CWE-269", "message": "Redis is an in-memory database that persists on disk. Redis does not correctly identify keys accessed by `SORT_RO` and as a result may grant users executing this command access to keys that are not explicitly authorized by the ACL configuration. The problem exists in Redis 7.0 or newer and has been fixed in Redis 7.0.13 and 7.2.1. Users are advised to upgrade. There are no known workarounds for this vulnerability.", "other": {"cve": {"id": "CVE-2023-41053", "sourceIdentifier": "security-advisories@github.com", "published": "2023-09-06T21:15:14.137", "lastModified": "2023-09-16T04:15:23.450", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "Redis is an in-memory database that persists on disk. Redis does not correctly identify keys accessed by `SORT_RO` and as a result may grant users executing this command access to keys that are not explicitly authorized by the ACL configuration. The problem exists in Redis 7.0 or newer and has been fixed in Redis 7.0.13 and 7.2.1. Users are advised to upgrade. There are no known workarounds for this vulnerability."}, {"lang": "es", "value": "Redis es una base de datos en memoria que persiste en el disco. Redis no identifica correctamente las claves a las que accede `SORT_RO` y, como resultado, puede otorgar a los usuarios que ejecutan este comando acceso a claves que no est\u00e1n autorizadas expl\u00edcitamente por la configuraci\u00f3n de ACL. El problema existe en Redis 7.0 o posterior y se solucion\u00f3 en Redis 7.0.13 y 7.2.1. Se recomienda a los usuarios que actualicen. No se conocen workarounds para esta vulnerabilidad."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 3.3, "baseSeverity": "LOW"}, "exploitabilityScore": 1.8, "impactScore": 1.4}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 3.3, "baseSeverity": "LOW"}, "exploitabilityScore": 1.8, "impactScore": 1.4}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-269"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:redis:redis:*:*:*:*:*:*:*:*", "versionStartIncluding": "7.0", "versionEndExcluding": "7.0.13", "matchCriteriaId": "9E282AA9-8D85-45E2-8172-8E0812158236"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redis:redis:7.2.0:-:*:*:*:*:*:*", "matchCriteriaId": "22D9F44A-6BF8-41CD-8C01-9DC43C9AB7BB"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redis:redis:7.2.0:rc1:*:*:*:*:*:*", "matchCriteriaId": "A6033CAF-9EB3-4B3A-8E9D-C75D961F15E5"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redis:redis:7.2.0:rc2:*:*:*:*:*:*", "matchCriteriaId": "49A74653-1F7E-4052-ABC6-A9C17FB7F52C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redis:redis:7.2.0:rc3:*:*:*:*:*:*", "matchCriteriaId": "4FCB1A20-8C00-4C17-8E20-2329F51C60C5"}]}]}], "references": [{"url": "https://github.com/redis/redis/commit/9e505e6cd842338424e05883521ca1fb7d0f47f6", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/redis/redis/security/advisories/GHSA-q4jr-5p56-4xwc", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/OLBPIUUD273UGRN2WAYHPVUAULY36QVL/", "source": "security-advisories@github.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/UA4MSJ623BH6HP5UHSJD2FOTN3QM5DQS/", "source": "security-advisories@github.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/YLYNYT52EHR63E7L7SHRTHEPUMAFFDLX/", "source": "security-advisories@github.com"}]}, "github_commit_url": "https://github.com/redis/redis/commit/9e505e6cd842338424e05883521ca1fb7d0f47f6"}}
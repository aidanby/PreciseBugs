{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0\n/*\n * The USB Monitor, inspired by Dave Harding's USBMon.\n *\n * This is a binary format reader.\n *\n * Copyright (C) 2006 Paolo Abeni (paolo.abeni@email.it)\n * Copyright (C) 2006,2007 Pete Zaitcev (zaitcev@redhat.com)\n */\n\n#include <linux/kernel.h>\n#include <linux/sched/signal.h>\n#include <linux/types.h>\n#include <linux/fs.h>\n#include <linux/cdev.h>\n#include <linux/export.h>\n#include <linux/usb.h>\n#include <linux/poll.h>\n#include <linux/compat.h>\n#include <linux/mm.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/time64.h>\n\n#include <linux/uaccess.h>\n\n#include \"usb_mon.h\"\n\n/*\n * Defined by USB 2.0 clause 9.3, table 9.2.\n */\n#define SETUP_LEN  8\n\n/* ioctl macros */\n#define MON_IOC_MAGIC 0x92\n\n#define MON_IOCQ_URB_LEN _IO(MON_IOC_MAGIC, 1)\n/* #2 used to be MON_IOCX_URB, removed before it got into Linus tree */\n#define MON_IOCG_STATS _IOR(MON_IOC_MAGIC, 3, struct mon_bin_stats)\n#define MON_IOCT_RING_SIZE _IO(MON_IOC_MAGIC, 4)\n#define MON_IOCQ_RING_SIZE _IO(MON_IOC_MAGIC, 5)\n#define MON_IOCX_GET   _IOW(MON_IOC_MAGIC, 6, struct mon_bin_get)\n#define MON_IOCX_MFETCH _IOWR(MON_IOC_MAGIC, 7, struct mon_bin_mfetch)\n#define MON_IOCH_MFLUSH _IO(MON_IOC_MAGIC, 8)\n/* #9 was MON_IOCT_SETAPI */\n#define MON_IOCX_GETX   _IOW(MON_IOC_MAGIC, 10, struct mon_bin_get)\n\n#ifdef CONFIG_COMPAT\n#define MON_IOCX_GET32 _IOW(MON_IOC_MAGIC, 6, struct mon_bin_get32)\n#define MON_IOCX_MFETCH32 _IOWR(MON_IOC_MAGIC, 7, struct mon_bin_mfetch32)\n#define MON_IOCX_GETX32   _IOW(MON_IOC_MAGIC, 10, struct mon_bin_get32)\n#endif\n\n/*\n * Some architectures have enormous basic pages (16KB for ia64, 64KB for ppc).\n * But it's all right. Just use a simple way to make sure the chunk is never\n * smaller than a page.\n *\n * N.B. An application does not know our chunk size.\n *\n * Woops, get_zeroed_page() returns a single page. I guess we're stuck with\n * page-sized chunks for the time being.\n */\n#define CHUNK_SIZE   PAGE_SIZE\n#define CHUNK_ALIGN(x)   (((x)+CHUNK_SIZE-1) & ~(CHUNK_SIZE-1))\n\n/*\n * The magic limit was calculated so that it allows the monitoring\n * application to pick data once in two ticks. This way, another application,\n * which presumably drives the bus, gets to hog CPU, yet we collect our data.\n * If HZ is 100, a 480 mbit/s bus drives 614 KB every jiffy. USB has an\n * enormous overhead built into the bus protocol, so we need about 1000 KB.\n *\n * This is still too much for most cases, where we just snoop a few\n * descriptor fetches for enumeration. So, the default is a \"reasonable\"\n * amount for systems with HZ=250 and incomplete bus saturation.\n *\n * XXX What about multi-megabyte URBs which take minutes to transfer?\n */\n#define BUFF_MAX  CHUNK_ALIGN(1200*1024)\n#define BUFF_DFL   CHUNK_ALIGN(300*1024)\n#define BUFF_MIN     CHUNK_ALIGN(8*1024)\n\n/*\n * The per-event API header (2 per URB).\n *\n * This structure is seen in userland as defined by the documentation.\n */\nstruct mon_bin_hdr {\n\tu64 id;\t\t\t/* URB ID - from submission to callback */\n\tunsigned char type;\t/* Same as in text API; extensible. */\n\tunsigned char xfer_type;\t/* ISO, Intr, Control, Bulk */\n\tunsigned char epnum;\t/* Endpoint number and transfer direction */\n\tunsigned char devnum;\t/* Device address */\n\tunsigned short busnum;\t/* Bus number */\n\tchar flag_setup;\n\tchar flag_data;\n\ts64 ts_sec;\t\t/* ktime_get_real_ts64 */\n\ts32 ts_usec;\t\t/* ktime_get_real_ts64 */\n\tint status;\n\tunsigned int len_urb;\t/* Length of data (submitted or actual) */\n\tunsigned int len_cap;\t/* Delivered length */\n\tunion {\n\t\tunsigned char setup[SETUP_LEN];\t/* Only for Control S-type */\n\t\tstruct iso_rec {\n\t\t\tint error_count;\n\t\t\tint numdesc;\n\t\t} iso;\n\t} s;\n\tint interval;\n\tint start_frame;\n\tunsigned int xfer_flags;\n\tunsigned int ndesc;\t/* Actual number of ISO descriptors */\n};\n\n/*\n * ISO vector, packed into the head of data stream.\n * This has to take 16 bytes to make sure that the end of buffer\n * wrap is not happening in the middle of a descriptor.\n */\nstruct mon_bin_isodesc {\n\tint          iso_status;\n\tunsigned int iso_off;\n\tunsigned int iso_len;\n\tu32 _pad;\n};\n\n/* per file statistic */\nstruct mon_bin_stats {\n\tu32 queued;\n\tu32 dropped;\n};\n\nstruct mon_bin_get {\n\tstruct mon_bin_hdr __user *hdr;\t/* Can be 48 bytes or 64. */\n\tvoid __user *data;\n\tsize_t alloc;\t\t/* Length of data (can be zero) */\n};\n\nstruct mon_bin_mfetch {\n\tu32 __user *offvec;\t/* Vector of events fetched */\n\tu32 nfetch;\t\t/* Number of events to fetch (out: fetched) */\n\tu32 nflush;\t\t/* Number of events to flush */\n};\n\n#ifdef CONFIG_COMPAT\nstruct mon_bin_get32 {\n\tu32 hdr32;\n\tu32 data32;\n\tu32 alloc32;\n};\n\nstruct mon_bin_mfetch32 {\n        u32 offvec32;\n        u32 nfetch32;\n        u32 nflush32;\n};\n#endif\n\n/* Having these two values same prevents wrapping of the mon_bin_hdr */\n#define PKT_ALIGN   64\n#define PKT_SIZE    64\n\n#define PKT_SZ_API0 48\t/* API 0 (2.6.20) size */\n#define PKT_SZ_API1 64\t/* API 1 size: extra fields */\n\n#define ISODESC_MAX   128\t/* Same number as usbfs allows, 2048 bytes. */\n\n/* max number of USB bus supported */\n#define MON_BIN_MAX_MINOR 128\n\n/*\n * The buffer: map of used pages.\n */\nstruct mon_pgmap {\n\tstruct page *pg;\n\tunsigned char *ptr;\t/* XXX just use page_to_virt everywhere? */\n};\n\n/*\n * This gets associated with an open file struct.\n */\nstruct mon_reader_bin {\n\t/* The buffer: one per open. */\n\tspinlock_t b_lock;\t\t/* Protect b_cnt, b_in */\n\tunsigned int b_size;\t\t/* Current size of the buffer - bytes */\n\tunsigned int b_cnt;\t\t/* Bytes used */\n\tunsigned int b_in, b_out;\t/* Offsets into buffer - bytes */\n\tunsigned int b_read;\t\t/* Amount of read data in curr. pkt. */\n\tstruct mon_pgmap *b_vec;\t/* The map array */\n\twait_queue_head_t b_wait;\t/* Wait for data here */\n\n\tstruct mutex fetch_lock;\t/* Protect b_read, b_out */\n\tint mmap_active;\n\n\t/* A list of these is needed for \"bus 0\". Some time later. */\n\tstruct mon_reader r;\n\n\t/* Stats */\n\tunsigned int cnt_lost;\n};\n\nstatic inline struct mon_bin_hdr *MON_OFF2HDR(const struct mon_reader_bin *rp,\n    unsigned int offset)\n{\n\treturn (struct mon_bin_hdr *)\n\t    (rp->b_vec[offset / CHUNK_SIZE].ptr + offset % CHUNK_SIZE);\n}\n\n#define MON_RING_EMPTY(rp)\t((rp)->b_cnt == 0)\n\nstatic unsigned char xfer_to_pipe[4] = {\n\tPIPE_CONTROL, PIPE_ISOCHRONOUS, PIPE_BULK, PIPE_INTERRUPT\n};\n\nstatic struct class *mon_bin_class;\nstatic dev_t mon_bin_dev0;\nstatic struct cdev mon_bin_cdev;\n\nstatic void mon_buff_area_fill(const struct mon_reader_bin *rp,\n    unsigned int offset, unsigned int size);\nstatic int mon_bin_wait_event(struct file *file, struct mon_reader_bin *rp);\nstatic int mon_alloc_buff(struct mon_pgmap *map, int npages);\nstatic void mon_free_buff(struct mon_pgmap *map, int npages);\n\n/*\n * This is a \"chunked memcpy\". It does not manipulate any counters.\n */\nstatic unsigned int mon_copy_to_buff(const struct mon_reader_bin *this,\n    unsigned int off, const unsigned char *from, unsigned int length)\n{\n\tunsigned int step_len;\n\tunsigned char *buf;\n\tunsigned int in_page;\n\n\twhile (length) {\n\t\t/*\n\t\t * Determine step_len.\n\t\t */\n\t\tstep_len = length;\n\t\tin_page = CHUNK_SIZE - (off & (CHUNK_SIZE-1));\n\t\tif (in_page < step_len)\n\t\t\tstep_len = in_page;\n\n\t\t/*\n\t\t * Copy data and advance pointers.\n\t\t */\n\t\tbuf = this->b_vec[off / CHUNK_SIZE].ptr + off % CHUNK_SIZE;\n\t\tmemcpy(buf, from, step_len);\n\t\tif ((off += step_len) >= this->b_size) off = 0;\n\t\tfrom += step_len;\n\t\tlength -= step_len;\n\t}\n\treturn off;\n}\n\n/*\n * This is a little worse than the above because it's \"chunked copy_to_user\".\n * The return value is an error code, not an offset.\n */\nstatic int copy_from_buf(const struct mon_reader_bin *this, unsigned int off,\n    char __user *to, int length)\n{\n\tunsigned int step_len;\n\tunsigned char *buf;\n\tunsigned int in_page;\n\n\twhile (length) {\n\t\t/*\n\t\t * Determine step_len.\n\t\t */\n\t\tstep_len = length;\n\t\tin_page = CHUNK_SIZE - (off & (CHUNK_SIZE-1));\n\t\tif (in_page < step_len)\n\t\t\tstep_len = in_page;\n\n\t\t/*\n\t\t * Copy data and advance pointers.\n\t\t */\n\t\tbuf = this->b_vec[off / CHUNK_SIZE].ptr + off % CHUNK_SIZE;\n\t\tif (copy_to_user(to, buf, step_len))\n\t\t\treturn -EINVAL;\n\t\tif ((off += step_len) >= this->b_size) off = 0;\n\t\tto += step_len;\n\t\tlength -= step_len;\n\t}\n\treturn 0;\n}\n\n/*\n * Allocate an (aligned) area in the buffer.\n * This is called under b_lock.\n * Returns ~0 on failure.\n */\nstatic unsigned int mon_buff_area_alloc(struct mon_reader_bin *rp,\n    unsigned int size)\n{\n\tunsigned int offset;\n\n\tsize = (size + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\tif (rp->b_cnt + size > rp->b_size)\n\t\treturn ~0;\n\toffset = rp->b_in;\n\trp->b_cnt += size;\n\tif ((rp->b_in += size) >= rp->b_size)\n\t\trp->b_in -= rp->b_size;\n\treturn offset;\n}\n\n/*\n * This is the same thing as mon_buff_area_alloc, only it does not allow\n * buffers to wrap. This is needed by applications which pass references\n * into mmap-ed buffers up their stacks (libpcap can do that).\n *\n * Currently, we always have the header stuck with the data, although\n * it is not strictly speaking necessary.\n *\n * When a buffer would wrap, we place a filler packet to mark the space.\n */\nstatic unsigned int mon_buff_area_alloc_contiguous(struct mon_reader_bin *rp,\n    unsigned int size)\n{\n\tunsigned int offset;\n\tunsigned int fill_size;\n\n\tsize = (size + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\tif (rp->b_cnt + size > rp->b_size)\n\t\treturn ~0;\n\tif (rp->b_in + size > rp->b_size) {\n\t\t/*\n\t\t * This would wrap. Find if we still have space after\n\t\t * skipping to the end of the buffer. If we do, place\n\t\t * a filler packet and allocate a new packet.\n\t\t */\n\t\tfill_size = rp->b_size - rp->b_in;\n\t\tif (rp->b_cnt + size + fill_size > rp->b_size)\n\t\t\treturn ~0;\n\t\tmon_buff_area_fill(rp, rp->b_in, fill_size);\n\n\t\toffset = 0;\n\t\trp->b_in = size;\n\t\trp->b_cnt += size + fill_size;\n\t} else if (rp->b_in + size == rp->b_size) {\n\t\toffset = rp->b_in;\n\t\trp->b_in = 0;\n\t\trp->b_cnt += size;\n\t} else {\n\t\toffset = rp->b_in;\n\t\trp->b_in += size;\n\t\trp->b_cnt += size;\n\t}\n\treturn offset;\n}\n\n/*\n * Return a few (kilo-)bytes to the head of the buffer.\n * This is used if a data fetch fails.\n */\nstatic void mon_buff_area_shrink(struct mon_reader_bin *rp, unsigned int size)\n{\n\n\t/* size &= ~(PKT_ALIGN-1);  -- we're called with aligned size */\n\trp->b_cnt -= size;\n\tif (rp->b_in < size)\n\t\trp->b_in += rp->b_size;\n\trp->b_in -= size;\n}\n\n/*\n * This has to be called under both b_lock and fetch_lock, because\n * it accesses both b_cnt and b_out.\n */\nstatic void mon_buff_area_free(struct mon_reader_bin *rp, unsigned int size)\n{\n\n\tsize = (size + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\trp->b_cnt -= size;\n\tif ((rp->b_out += size) >= rp->b_size)\n\t\trp->b_out -= rp->b_size;\n}\n\nstatic void mon_buff_area_fill(const struct mon_reader_bin *rp,\n    unsigned int offset, unsigned int size)\n{\n\tstruct mon_bin_hdr *ep;\n\n\tep = MON_OFF2HDR(rp, offset);\n\tmemset(ep, 0, PKT_SIZE);\n\tep->type = '@';\n\tep->len_cap = size - PKT_SIZE;\n}\n\nstatic inline char mon_bin_get_setup(unsigned char *setupb,\n    const struct urb *urb, char ev_type)\n{\n\n\tif (urb->setup_packet == NULL)\n\t\treturn 'Z';\n\tmemcpy(setupb, urb->setup_packet, SETUP_LEN);\n\treturn 0;\n}\n\nstatic unsigned int mon_bin_get_data(const struct mon_reader_bin *rp,\n    unsigned int offset, struct urb *urb, unsigned int length,\n    char *flag)\n{\n\tint i;\n\tstruct scatterlist *sg;\n\tunsigned int this_len;\n\n\t*flag = 0;\n\tif (urb->num_sgs == 0) {\n\t\tif (urb->transfer_buffer == NULL) {\n\t\t\t*flag = 'Z';\n\t\t\treturn length;\n\t\t}\n\t\tmon_copy_to_buff(rp, offset, urb->transfer_buffer, length);\n\t\tlength = 0;\n\n\t} else {\n\t\t/* If IOMMU coalescing occurred, we cannot trust sg_page */\n\t\tif (urb->transfer_flags & URB_DMA_SG_COMBINED) {\n\t\t\t*flag = 'D';\n\t\t\treturn length;\n\t\t}\n\n\t\t/* Copy up to the first non-addressable segment */\n\t\tfor_each_sg(urb->sg, sg, urb->num_sgs, i) {\n\t\t\tif (length == 0 || PageHighMem(sg_page(sg)))\n\t\t\t\tbreak;\n\t\t\tthis_len = min_t(unsigned int, sg->length, length);\n\t\t\toffset = mon_copy_to_buff(rp, offset, sg_virt(sg),\n\t\t\t\t\tthis_len);\n\t\t\tlength -= this_len;\n\t\t}\n\t\tif (i == 0)\n\t\t\t*flag = 'D';\n\t}\n\n\treturn length;\n}\n\n/*\n * This is the look-ahead pass in case of 'C Zi', when actual_length cannot\n * be used to determine the length of the whole contiguous buffer.\n */\nstatic unsigned int mon_bin_collate_isodesc(const struct mon_reader_bin *rp,\n    struct urb *urb, unsigned int ndesc)\n{\n\tstruct usb_iso_packet_descriptor *fp;\n\tunsigned int length;\n\n\tlength = 0;\n\tfp = urb->iso_frame_desc;\n\twhile (ndesc-- != 0) {\n\t\tif (fp->actual_length != 0) {\n\t\t\tif (fp->offset + fp->actual_length > length)\n\t\t\t\tlength = fp->offset + fp->actual_length;\n\t\t}\n\t\tfp++;\n\t}\n\treturn length;\n}\n\nstatic void mon_bin_get_isodesc(const struct mon_reader_bin *rp,\n    unsigned int offset, struct urb *urb, char ev_type, unsigned int ndesc)\n{\n\tstruct mon_bin_isodesc *dp;\n\tstruct usb_iso_packet_descriptor *fp;\n\n\tfp = urb->iso_frame_desc;\n\twhile (ndesc-- != 0) {\n\t\tdp = (struct mon_bin_isodesc *)\n\t\t    (rp->b_vec[offset / CHUNK_SIZE].ptr + offset % CHUNK_SIZE);\n\t\tdp->iso_status = fp->status;\n\t\tdp->iso_off = fp->offset;\n\t\tdp->iso_len = (ev_type == 'S') ? fp->length : fp->actual_length;\n\t\tdp->_pad = 0;\n\t\tif ((offset += sizeof(struct mon_bin_isodesc)) >= rp->b_size)\n\t\t\toffset = 0;\n\t\tfp++;\n\t}\n}\n\nstatic void mon_bin_event(struct mon_reader_bin *rp, struct urb *urb,\n    char ev_type, int status)\n{\n\tconst struct usb_endpoint_descriptor *epd = &urb->ep->desc;\n\tstruct timespec64 ts;\n\tunsigned long flags;\n\tunsigned int urb_length;\n\tunsigned int offset;\n\tunsigned int length;\n\tunsigned int delta;\n\tunsigned int ndesc, lendesc;\n\tunsigned char dir;\n\tstruct mon_bin_hdr *ep;\n\tchar data_tag = 0;\n\n\tktime_get_real_ts64(&ts);\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\n\t/*\n\t * Find the maximum allowable length, then allocate space.\n\t */\n\turb_length = (ev_type == 'S') ?\n\t    urb->transfer_buffer_length : urb->actual_length;\n\tlength = urb_length;\n\n\tif (usb_endpoint_xfer_isoc(epd)) {\n\t\tif (urb->number_of_packets < 0) {\n\t\t\tndesc = 0;\n\t\t} else if (urb->number_of_packets >= ISODESC_MAX) {\n\t\t\tndesc = ISODESC_MAX;\n\t\t} else {\n\t\t\tndesc = urb->number_of_packets;\n\t\t}\n\t\tif (ev_type == 'C' && usb_urb_dir_in(urb))\n\t\t\tlength = mon_bin_collate_isodesc(rp, urb, ndesc);\n\t} else {\n\t\tndesc = 0;\n\t}\n\tlendesc = ndesc*sizeof(struct mon_bin_isodesc);\n\n\t/* not an issue unless there's a subtle bug in a HCD somewhere */\n\tif (length >= urb->transfer_buffer_length)\n\t\tlength = urb->transfer_buffer_length;\n\n\tif (length >= rp->b_size/5)\n\t\tlength = rp->b_size/5;\n\n\tif (usb_urb_dir_in(urb)) {\n\t\tif (ev_type == 'S') {\n\t\t\tlength = 0;\n\t\t\tdata_tag = '<';\n\t\t}\n\t\t/* Cannot rely on endpoint number in case of control ep.0 */\n\t\tdir = USB_DIR_IN;\n\t} else {\n\t\tif (ev_type == 'C') {\n\t\t\tlength = 0;\n\t\t\tdata_tag = '>';\n\t\t}\n\t\tdir = 0;\n\t}\n\n\tif (rp->mmap_active) {\n\t\toffset = mon_buff_area_alloc_contiguous(rp,\n\t\t\t\t\t\t length + PKT_SIZE + lendesc);\n\t} else {\n\t\toffset = mon_buff_area_alloc(rp, length + PKT_SIZE + lendesc);\n\t}\n\tif (offset == ~0) {\n\t\trp->cnt_lost++;\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\treturn;\n\t}\n\n\tep = MON_OFF2HDR(rp, offset);\n\tif ((offset += PKT_SIZE) >= rp->b_size) offset = 0;\n\n\t/*\n\t * Fill the allocated area.\n\t */\n\tmemset(ep, 0, PKT_SIZE);\n\tep->type = ev_type;\n\tep->xfer_type = xfer_to_pipe[usb_endpoint_type(epd)];\n\tep->epnum = dir | usb_endpoint_num(epd);\n\tep->devnum = urb->dev->devnum;\n\tep->busnum = urb->dev->bus->busnum;\n\tep->id = (unsigned long) urb;\n\tep->ts_sec = ts.tv_sec;\n\tep->ts_usec = ts.tv_nsec / NSEC_PER_USEC;\n\tep->status = status;\n\tep->len_urb = urb_length;\n\tep->len_cap = length + lendesc;\n\tep->xfer_flags = urb->transfer_flags;\n\n\tif (usb_endpoint_xfer_int(epd)) {\n\t\tep->interval = urb->interval;\n\t} else if (usb_endpoint_xfer_isoc(epd)) {\n\t\tep->interval = urb->interval;\n\t\tep->start_frame = urb->start_frame;\n\t\tep->s.iso.error_count = urb->error_count;\n\t\tep->s.iso.numdesc = urb->number_of_packets;\n\t}\n\n\tif (usb_endpoint_xfer_control(epd) && ev_type == 'S') {\n\t\tep->flag_setup = mon_bin_get_setup(ep->s.setup, urb, ev_type);\n\t} else {\n\t\tep->flag_setup = '-';\n\t}\n\n\tif (ndesc != 0) {\n\t\tep->ndesc = ndesc;\n\t\tmon_bin_get_isodesc(rp, offset, urb, ev_type, ndesc);\n\t\tif ((offset += lendesc) >= rp->b_size)\n\t\t\toffset -= rp->b_size;\n\t}\n\n\tif (length != 0) {\n\t\tlength = mon_bin_get_data(rp, offset, urb, length,\n\t\t\t\t&ep->flag_data);\n\t\tif (length > 0) {\n\t\t\tdelta = (ep->len_cap + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\t\t\tep->len_cap -= length;\n\t\t\tdelta -= (ep->len_cap + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\t\t\tmon_buff_area_shrink(rp, delta);\n\t\t}\n\t} else {\n\t\tep->flag_data = data_tag;\n\t}\n\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\twake_up(&rp->b_wait);\n}\n\nstatic void mon_bin_submit(void *data, struct urb *urb)\n{\n\tstruct mon_reader_bin *rp = data;\n\tmon_bin_event(rp, urb, 'S', -EINPROGRESS);\n}\n\nstatic void mon_bin_complete(void *data, struct urb *urb, int status)\n{\n\tstruct mon_reader_bin *rp = data;\n\tmon_bin_event(rp, urb, 'C', status);\n}\n\nstatic void mon_bin_error(void *data, struct urb *urb, int error)\n{\n\tstruct mon_reader_bin *rp = data;\n\tstruct timespec64 ts;\n\tunsigned long flags;\n\tunsigned int offset;\n\tstruct mon_bin_hdr *ep;\n\n\tktime_get_real_ts64(&ts);\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\n\toffset = mon_buff_area_alloc(rp, PKT_SIZE);\n\tif (offset == ~0) {\n\t\t/* Not incrementing cnt_lost. Just because. */\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\treturn;\n\t}\n\n\tep = MON_OFF2HDR(rp, offset);\n\n\tmemset(ep, 0, PKT_SIZE);\n\tep->type = 'E';\n\tep->xfer_type = xfer_to_pipe[usb_endpoint_type(&urb->ep->desc)];\n\tep->epnum = usb_urb_dir_in(urb) ? USB_DIR_IN : 0;\n\tep->epnum |= usb_endpoint_num(&urb->ep->desc);\n\tep->devnum = urb->dev->devnum;\n\tep->busnum = urb->dev->bus->busnum;\n\tep->id = (unsigned long) urb;\n\tep->ts_sec = ts.tv_sec;\n\tep->ts_usec = ts.tv_nsec / NSEC_PER_USEC;\n\tep->status = error;\n\n\tep->flag_setup = '-';\n\tep->flag_data = 'E';\n\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\twake_up(&rp->b_wait);\n}\n\nstatic int mon_bin_open(struct inode *inode, struct file *file)\n{\n\tstruct mon_bus *mbus;\n\tstruct mon_reader_bin *rp;\n\tsize_t size;\n\tint rc;\n\n\tmutex_lock(&mon_lock);\n\tmbus = mon_bus_lookup(iminor(inode));\n\tif (mbus == NULL) {\n\t\tmutex_unlock(&mon_lock);\n\t\treturn -ENODEV;\n\t}\n\tif (mbus != &mon_bus0 && mbus->u_bus == NULL) {\n\t\tprintk(KERN_ERR TAG \": consistency error on open\\n\");\n\t\tmutex_unlock(&mon_lock);\n\t\treturn -ENODEV;\n\t}\n\n\trp = kzalloc(sizeof(struct mon_reader_bin), GFP_KERNEL);\n\tif (rp == NULL) {\n\t\trc = -ENOMEM;\n\t\tgoto err_alloc;\n\t}\n\tspin_lock_init(&rp->b_lock);\n\tinit_waitqueue_head(&rp->b_wait);\n\tmutex_init(&rp->fetch_lock);\n\trp->b_size = BUFF_DFL;\n\n\tsize = sizeof(struct mon_pgmap) * (rp->b_size/CHUNK_SIZE);\n\tif ((rp->b_vec = kzalloc(size, GFP_KERNEL)) == NULL) {\n\t\trc = -ENOMEM;\n\t\tgoto err_allocvec;\n\t}\n\n\tif ((rc = mon_alloc_buff(rp->b_vec, rp->b_size/CHUNK_SIZE)) < 0)\n\t\tgoto err_allocbuff;\n\n\trp->r.m_bus = mbus;\n\trp->r.r_data = rp;\n\trp->r.rnf_submit = mon_bin_submit;\n\trp->r.rnf_error = mon_bin_error;\n\trp->r.rnf_complete = mon_bin_complete;\n\n\tmon_reader_add(mbus, &rp->r);\n\n\tfile->private_data = rp;\n\tmutex_unlock(&mon_lock);\n\treturn 0;\n\nerr_allocbuff:\n\tkfree(rp->b_vec);\nerr_allocvec:\n\tkfree(rp);\nerr_alloc:\n\tmutex_unlock(&mon_lock);\n\treturn rc;\n}\n\n/*\n * Extract an event from buffer and copy it to user space.\n * Wait if there is no event ready.\n * Returns zero or error.\n */\nstatic int mon_bin_get_event(struct file *file, struct mon_reader_bin *rp,\n    struct mon_bin_hdr __user *hdr, unsigned int hdrbytes,\n    void __user *data, unsigned int nbytes)\n{\n\tunsigned long flags;\n\tstruct mon_bin_hdr *ep;\n\tsize_t step_len;\n\tunsigned int offset;\n\tint rc;\n\n\tmutex_lock(&rp->fetch_lock);\n\n\tif ((rc = mon_bin_wait_event(file, rp)) < 0) {\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\treturn rc;\n\t}\n\n\tep = MON_OFF2HDR(rp, rp->b_out);\n\n\tif (copy_to_user(hdr, ep, hdrbytes)) {\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\treturn -EFAULT;\n\t}\n\n\tstep_len = min(ep->len_cap, nbytes);\n\tif ((offset = rp->b_out + PKT_SIZE) >= rp->b_size) offset = 0;\n\n\tif (copy_from_buf(rp, offset, data, step_len)) {\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\treturn -EFAULT;\n\t}\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\tmon_buff_area_free(rp, PKT_SIZE + ep->len_cap);\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\trp->b_read = 0;\n\n\tmutex_unlock(&rp->fetch_lock);\n\treturn 0;\n}\n\nstatic int mon_bin_release(struct inode *inode, struct file *file)\n{\n\tstruct mon_reader_bin *rp = file->private_data;\n\tstruct mon_bus* mbus = rp->r.m_bus;\n\n\tmutex_lock(&mon_lock);\n\n\tif (mbus->nreaders <= 0) {\n\t\tprintk(KERN_ERR TAG \": consistency error on close\\n\");\n\t\tmutex_unlock(&mon_lock);\n\t\treturn 0;\n\t}\n\tmon_reader_del(mbus, &rp->r);\n\n\tmon_free_buff(rp->b_vec, rp->b_size/CHUNK_SIZE);\n\tkfree(rp->b_vec);\n\tkfree(rp);\n\n\tmutex_unlock(&mon_lock);\n\treturn 0;\n}\n\nstatic ssize_t mon_bin_read(struct file *file, char __user *buf,\n    size_t nbytes, loff_t *ppos)\n{\n\tstruct mon_reader_bin *rp = file->private_data;\n\tunsigned int hdrbytes = PKT_SZ_API0;\n\tunsigned long flags;\n\tstruct mon_bin_hdr *ep;\n\tunsigned int offset;\n\tsize_t step_len;\n\tchar *ptr;\n\tssize_t done = 0;\n\tint rc;\n\n\tmutex_lock(&rp->fetch_lock);\n\n\tif ((rc = mon_bin_wait_event(file, rp)) < 0) {\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\treturn rc;\n\t}\n\n\tep = MON_OFF2HDR(rp, rp->b_out);\n\n\tif (rp->b_read < hdrbytes) {\n\t\tstep_len = min(nbytes, (size_t)(hdrbytes - rp->b_read));\n\t\tptr = ((char *)ep) + rp->b_read;\n\t\tif (step_len && copy_to_user(buf, ptr, step_len)) {\n\t\t\tmutex_unlock(&rp->fetch_lock);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tnbytes -= step_len;\n\t\tbuf += step_len;\n\t\trp->b_read += step_len;\n\t\tdone += step_len;\n\t}\n\n\tif (rp->b_read >= hdrbytes) {\n\t\tstep_len = ep->len_cap;\n\t\tstep_len -= rp->b_read - hdrbytes;\n\t\tif (step_len > nbytes)\n\t\t\tstep_len = nbytes;\n\t\toffset = rp->b_out + PKT_SIZE;\n\t\toffset += rp->b_read - hdrbytes;\n\t\tif (offset >= rp->b_size)\n\t\t\toffset -= rp->b_size;\n\t\tif (copy_from_buf(rp, offset, buf, step_len)) {\n\t\t\tmutex_unlock(&rp->fetch_lock);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tnbytes -= step_len;\n\t\tbuf += step_len;\n\t\trp->b_read += step_len;\n\t\tdone += step_len;\n\t}\n\n\t/*\n\t * Check if whole packet was read, and if so, jump to the next one.\n\t */\n\tif (rp->b_read >= hdrbytes + ep->len_cap) {\n\t\tspin_lock_irqsave(&rp->b_lock, flags);\n\t\tmon_buff_area_free(rp, PKT_SIZE + ep->len_cap);\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\trp->b_read = 0;\n\t}\n\n\tmutex_unlock(&rp->fetch_lock);\n\treturn done;\n}\n\n/*\n * Remove at most nevents from chunked buffer.\n * Returns the number of removed events.\n */\nstatic int mon_bin_flush(struct mon_reader_bin *rp, unsigned nevents)\n{\n\tunsigned long flags;\n\tstruct mon_bin_hdr *ep;\n\tint i;\n\n\tmutex_lock(&rp->fetch_lock);\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\tfor (i = 0; i < nevents; ++i) {\n\t\tif (MON_RING_EMPTY(rp))\n\t\t\tbreak;\n\n\t\tep = MON_OFF2HDR(rp, rp->b_out);\n\t\tmon_buff_area_free(rp, PKT_SIZE + ep->len_cap);\n\t}\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\trp->b_read = 0;\n\tmutex_unlock(&rp->fetch_lock);\n\treturn i;\n}\n\n/*\n * Fetch at most max event offsets into the buffer and put them into vec.\n * The events are usually freed later with mon_bin_flush.\n * Return the effective number of events fetched.\n */\nstatic int mon_bin_fetch(struct file *file, struct mon_reader_bin *rp,\n    u32 __user *vec, unsigned int max)\n{\n\tunsigned int cur_out;\n\tunsigned int bytes, avail;\n\tunsigned int size;\n\tunsigned int nevents;\n\tstruct mon_bin_hdr *ep;\n\tunsigned long flags;\n\tint rc;\n\n\tmutex_lock(&rp->fetch_lock);\n\n\tif ((rc = mon_bin_wait_event(file, rp)) < 0) {\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\treturn rc;\n\t}\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\tavail = rp->b_cnt;\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\tcur_out = rp->b_out;\n\tnevents = 0;\n\tbytes = 0;\n\twhile (bytes < avail) {\n\t\tif (nevents >= max)\n\t\t\tbreak;\n\n\t\tep = MON_OFF2HDR(rp, cur_out);\n\t\tif (put_user(cur_out, &vec[nevents])) {\n\t\t\tmutex_unlock(&rp->fetch_lock);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tnevents++;\n\t\tsize = ep->len_cap + PKT_SIZE;\n\t\tsize = (size + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\t\tif ((cur_out += size) >= rp->b_size)\n\t\t\tcur_out -= rp->b_size;\n\t\tbytes += size;\n\t}\n\n\tmutex_unlock(&rp->fetch_lock);\n\treturn nevents;\n}\n\n/*\n * Count events. This is almost the same as the above mon_bin_fetch,\n * only we do not store offsets into user vector, and we have no limit.\n */\nstatic int mon_bin_queued(struct mon_reader_bin *rp)\n{\n\tunsigned int cur_out;\n\tunsigned int bytes, avail;\n\tunsigned int size;\n\tunsigned int nevents;\n\tstruct mon_bin_hdr *ep;\n\tunsigned long flags;\n\n\tmutex_lock(&rp->fetch_lock);\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\tavail = rp->b_cnt;\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\tcur_out = rp->b_out;\n\tnevents = 0;\n\tbytes = 0;\n\twhile (bytes < avail) {\n\t\tep = MON_OFF2HDR(rp, cur_out);\n\n\t\tnevents++;\n\t\tsize = ep->len_cap + PKT_SIZE;\n\t\tsize = (size + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\t\tif ((cur_out += size) >= rp->b_size)\n\t\t\tcur_out -= rp->b_size;\n\t\tbytes += size;\n\t}\n\n\tmutex_unlock(&rp->fetch_lock);\n\treturn nevents;\n}\n\n/*\n */\nstatic long mon_bin_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct mon_reader_bin *rp = file->private_data;\n\t// struct mon_bus* mbus = rp->r.m_bus;\n\tint ret = 0;\n\tstruct mon_bin_hdr *ep;\n\tunsigned long flags;\n\n\tswitch (cmd) {\n\n\tcase MON_IOCQ_URB_LEN:\n\t\t/*\n\t\t * N.B. This only returns the size of data, without the header.\n\t\t */\n\t\tspin_lock_irqsave(&rp->b_lock, flags);\n\t\tif (!MON_RING_EMPTY(rp)) {\n\t\t\tep = MON_OFF2HDR(rp, rp->b_out);\n\t\t\tret = ep->len_cap;\n\t\t}\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\tbreak;\n\n\tcase MON_IOCQ_RING_SIZE:\n\t\tmutex_lock(&rp->fetch_lock);\n\t\tret = rp->b_size;\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\tbreak;\n\n\tcase MON_IOCT_RING_SIZE:\n\t\t/*\n\t\t * Changing the buffer size will flush it's contents; the new\n\t\t * buffer is allocated before releasing the old one to be sure\n\t\t * the device will stay functional also in case of memory\n\t\t * pressure.\n\t\t */\n\t\t{\n\t\tint size;\n\t\tstruct mon_pgmap *vec;\n\n\t\tif (arg < BUFF_MIN || arg > BUFF_MAX)\n\t\t\treturn -EINVAL;\n\n\t\tsize = CHUNK_ALIGN(arg);\n\t\tvec = kcalloc(size / CHUNK_SIZE, sizeof(struct mon_pgmap),\n\t\t\t      GFP_KERNEL);\n\t\tif (vec == NULL) {\n\t\t\tret = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tret = mon_alloc_buff(vec, size/CHUNK_SIZE);\n\t\tif (ret < 0) {\n\t\t\tkfree(vec);\n\t\t\tbreak;\n\t\t}\n\n\t\tmutex_lock(&rp->fetch_lock);\n\t\tspin_lock_irqsave(&rp->b_lock, flags);\n\t\tif (rp->mmap_active) {\n\t\t\tmon_free_buff(vec, size/CHUNK_SIZE);\n\t\t\tkfree(vec);\n\t\t\tret = -EBUSY;\n\t\t} else {\n\t\t\tmon_free_buff(rp->b_vec, rp->b_size/CHUNK_SIZE);\n\t\t\tkfree(rp->b_vec);\n\t\t\trp->b_vec  = vec;\n\t\t\trp->b_size = size;\n\t\t\trp->b_read = rp->b_in = rp->b_out = rp->b_cnt = 0;\n\t\t\trp->cnt_lost = 0;\n\t\t}\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\t}\n\t\tbreak;\n\n\tcase MON_IOCH_MFLUSH:\n\t\tret = mon_bin_flush(rp, arg);\n\t\tbreak;\n\n\tcase MON_IOCX_GET:\n\tcase MON_IOCX_GETX:\n\t\t{\n\t\tstruct mon_bin_get getb;\n\n\t\tif (copy_from_user(&getb, (void __user *)arg,\n\t\t\t\t\t    sizeof(struct mon_bin_get)))\n\t\t\treturn -EFAULT;\n\n\t\tif (getb.alloc > 0x10000000)\t/* Want to cast to u32 */\n\t\t\treturn -EINVAL;\n\t\tret = mon_bin_get_event(file, rp, getb.hdr,\n\t\t    (cmd == MON_IOCX_GET)? PKT_SZ_API0: PKT_SZ_API1,\n\t\t    getb.data, (unsigned int)getb.alloc);\n\t\t}\n\t\tbreak;\n\n\tcase MON_IOCX_MFETCH:\n\t\t{\n\t\tstruct mon_bin_mfetch mfetch;\n\t\tstruct mon_bin_mfetch __user *uptr;\n\n\t\tuptr = (struct mon_bin_mfetch __user *)arg;\n\n\t\tif (copy_from_user(&mfetch, uptr, sizeof(mfetch)))\n\t\t\treturn -EFAULT;\n\n\t\tif (mfetch.nflush) {\n\t\t\tret = mon_bin_flush(rp, mfetch.nflush);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tif (put_user(ret, &uptr->nflush))\n\t\t\t\treturn -EFAULT;\n\t\t}\n\t\tret = mon_bin_fetch(file, rp, mfetch.offvec, mfetch.nfetch);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tif (put_user(ret, &uptr->nfetch))\n\t\t\treturn -EFAULT;\n\t\tret = 0;\n\t\t}\n\t\tbreak;\n\n\tcase MON_IOCG_STATS: {\n\t\tstruct mon_bin_stats __user *sp;\n\t\tunsigned int nevents;\n\t\tunsigned int ndropped;\n\n\t\tspin_lock_irqsave(&rp->b_lock, flags);\n\t\tndropped = rp->cnt_lost;\n\t\trp->cnt_lost = 0;\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\tnevents = mon_bin_queued(rp);\n\n\t\tsp = (struct mon_bin_stats __user *)arg;\n\t\tif (put_user(ndropped, &sp->dropped))\n\t\t\treturn -EFAULT;\n\t\tif (put_user(nevents, &sp->queued))\n\t\t\treturn -EFAULT;\n\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic long mon_bin_compat_ioctl(struct file *file,\n    unsigned int cmd, unsigned long arg)\n{\n\tstruct mon_reader_bin *rp = file->private_data;\n\tint ret;\n\n\tswitch (cmd) {\n\n\tcase MON_IOCX_GET32:\n\tcase MON_IOCX_GETX32:\n\t\t{\n\t\tstruct mon_bin_get32 getb;\n\n\t\tif (copy_from_user(&getb, (void __user *)arg,\n\t\t\t\t\t    sizeof(struct mon_bin_get32)))\n\t\t\treturn -EFAULT;\n\n\t\tret = mon_bin_get_event(file, rp, compat_ptr(getb.hdr32),\n\t\t    (cmd == MON_IOCX_GET32)? PKT_SZ_API0: PKT_SZ_API1,\n\t\t    compat_ptr(getb.data32), getb.alloc32);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\t}\n\t\treturn 0;\n\n\tcase MON_IOCX_MFETCH32:\n\t\t{\n\t\tstruct mon_bin_mfetch32 mfetch;\n\t\tstruct mon_bin_mfetch32 __user *uptr;\n\n\t\tuptr = (struct mon_bin_mfetch32 __user *) compat_ptr(arg);\n\n\t\tif (copy_from_user(&mfetch, uptr, sizeof(mfetch)))\n\t\t\treturn -EFAULT;\n\n\t\tif (mfetch.nflush32) {\n\t\t\tret = mon_bin_flush(rp, mfetch.nflush32);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tif (put_user(ret, &uptr->nflush32))\n\t\t\t\treturn -EFAULT;\n\t\t}\n\t\tret = mon_bin_fetch(file, rp, compat_ptr(mfetch.offvec32),\n\t\t    mfetch.nfetch32);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tif (put_user(ret, &uptr->nfetch32))\n\t\t\treturn -EFAULT;\n\t\t}\n\t\treturn 0;\n\n\tcase MON_IOCG_STATS:\n\t\treturn mon_bin_ioctl(file, cmd, (unsigned long) compat_ptr(arg));\n\n\tcase MON_IOCQ_URB_LEN:\n\tcase MON_IOCQ_RING_SIZE:\n\tcase MON_IOCT_RING_SIZE:\n\tcase MON_IOCH_MFLUSH:\n\t\treturn mon_bin_ioctl(file, cmd, arg);\n\n\tdefault:\n\t\t;\n\t}\n\treturn -ENOTTY;\n}\n#endif /* CONFIG_COMPAT */\n\nstatic __poll_t\nmon_bin_poll(struct file *file, struct poll_table_struct *wait)\n{\n\tstruct mon_reader_bin *rp = file->private_data;\n\t__poll_t mask = 0;\n\tunsigned long flags;\n\n\tif (file->f_mode & FMODE_READ)\n\t\tpoll_wait(file, &rp->b_wait, wait);\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\tif (!MON_RING_EMPTY(rp))\n\t\tmask |= EPOLLIN | EPOLLRDNORM;    /* readable */\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\treturn mask;\n}\n\n/*\n * open and close: just keep track of how many times the device is\n * mapped, to use the proper memory allocation function.\n */\nstatic void mon_bin_vma_open(struct vm_area_struct *vma)\n{\n\tstruct mon_reader_bin *rp = vma->vm_private_data;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\trp->mmap_active++;\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n}\n\nstatic void mon_bin_vma_close(struct vm_area_struct *vma)\n{\n\tunsigned long flags;\n\n\tstruct mon_reader_bin *rp = vma->vm_private_data;\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\trp->mmap_active--;\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n}\n\n/*\n * Map ring pages to user space.\n */\nstatic vm_fault_t mon_bin_vma_fault(struct vm_fault *vmf)\n{\n\tstruct mon_reader_bin *rp = vmf->vma->vm_private_data;\n\tunsigned long offset, chunk_idx;\n\tstruct page *pageptr;\n\n\toffset = vmf->pgoff << PAGE_SHIFT;\n\tif (offset >= rp->b_size)\n\t\treturn VM_FAULT_SIGBUS;\n\tchunk_idx = offset / CHUNK_SIZE;\n\tpageptr = rp->b_vec[chunk_idx].pg;\n\tget_page(pageptr);\n\tvmf->page = pageptr;\n\treturn 0;\n}\n\nstatic const struct vm_operations_struct mon_bin_vm_ops = {\n\t.open =     mon_bin_vma_open,\n\t.close =    mon_bin_vma_close,\n\t.fault =    mon_bin_vma_fault,\n};\n\nstatic int mon_bin_mmap(struct file *filp, struct vm_area_struct *vma)\n{\n\t/* don't do anything here: \"fault\" will set up page table entries */\n\tvma->vm_ops = &mon_bin_vm_ops;\n\tvma->vm_flags |= VM_DONTEXPAND | VM_DONTDUMP;\n\tvma->vm_private_data = filp->private_data;\n\tmon_bin_vma_open(vma);\n\treturn 0;\n}\n\nstatic const struct file_operations mon_fops_binary = {\n\t.owner =\tTHIS_MODULE,\n\t.open =\t\tmon_bin_open,\n\t.llseek =\tno_llseek,\n\t.read =\t\tmon_bin_read,\n\t/* .write =\tmon_text_write, */\n\t.poll =\t\tmon_bin_poll,\n\t.unlocked_ioctl = mon_bin_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl =\tmon_bin_compat_ioctl,\n#endif\n\t.release =\tmon_bin_release,\n\t.mmap =\t\tmon_bin_mmap,\n};\n\nstatic int mon_bin_wait_event(struct file *file, struct mon_reader_bin *rp)\n{\n\tDECLARE_WAITQUEUE(waita, current);\n\tunsigned long flags;\n\n\tadd_wait_queue(&rp->b_wait, &waita);\n\tset_current_state(TASK_INTERRUPTIBLE);\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\twhile (MON_RING_EMPTY(rp)) {\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\t\tif (file->f_flags & O_NONBLOCK) {\n\t\t\tset_current_state(TASK_RUNNING);\n\t\t\tremove_wait_queue(&rp->b_wait, &waita);\n\t\t\treturn -EWOULDBLOCK; /* Same as EAGAIN in Linux */\n\t\t}\n\t\tschedule();\n\t\tif (signal_pending(current)) {\n\t\t\tremove_wait_queue(&rp->b_wait, &waita);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\n\t\tspin_lock_irqsave(&rp->b_lock, flags);\n\t}\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\tset_current_state(TASK_RUNNING);\n\tremove_wait_queue(&rp->b_wait, &waita);\n\treturn 0;\n}\n\nstatic int mon_alloc_buff(struct mon_pgmap *map, int npages)\n{\n\tint n;\n\tunsigned long vaddr;\n\n\tfor (n = 0; n < npages; n++) {\n\t\tvaddr = get_zeroed_page(GFP_KERNEL);\n\t\tif (vaddr == 0) {\n\t\t\twhile (n-- != 0)\n\t\t\t\tfree_page((unsigned long) map[n].ptr);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tmap[n].ptr = (unsigned char *) vaddr;\n\t\tmap[n].pg = virt_to_page((void *) vaddr);\n\t}\n\treturn 0;\n}\n\nstatic void mon_free_buff(struct mon_pgmap *map, int npages)\n{\n\tint n;\n\n\tfor (n = 0; n < npages; n++)\n\t\tfree_page((unsigned long) map[n].ptr);\n}\n\nint mon_bin_add(struct mon_bus *mbus, const struct usb_bus *ubus)\n{\n\tstruct device *dev;\n\tunsigned minor = ubus? ubus->busnum: 0;\n\n\tif (minor >= MON_BIN_MAX_MINOR)\n\t\treturn 0;\n\n\tdev = device_create(mon_bin_class, ubus ? ubus->controller : NULL,\n\t\t\t    MKDEV(MAJOR(mon_bin_dev0), minor), NULL,\n\t\t\t    \"usbmon%d\", minor);\n\tif (IS_ERR(dev))\n\t\treturn 0;\n\n\tmbus->classdev = dev;\n\treturn 1;\n}\n\nvoid mon_bin_del(struct mon_bus *mbus)\n{\n\tdevice_destroy(mon_bin_class, mbus->classdev->devt);\n}\n\nint __init mon_bin_init(void)\n{\n\tint rc;\n\n\tmon_bin_class = class_create(THIS_MODULE, \"usbmon\");\n\tif (IS_ERR(mon_bin_class)) {\n\t\trc = PTR_ERR(mon_bin_class);\n\t\tgoto err_class;\n\t}\n\n\trc = alloc_chrdev_region(&mon_bin_dev0, 0, MON_BIN_MAX_MINOR, \"usbmon\");\n\tif (rc < 0)\n\t\tgoto err_dev;\n\n\tcdev_init(&mon_bin_cdev, &mon_fops_binary);\n\tmon_bin_cdev.owner = THIS_MODULE;\n\n\trc = cdev_add(&mon_bin_cdev, mon_bin_dev0, MON_BIN_MAX_MINOR);\n\tif (rc < 0)\n\t\tgoto err_add;\n\n\treturn 0;\n\nerr_add:\n\tunregister_chrdev_region(mon_bin_dev0, MON_BIN_MAX_MINOR);\nerr_dev:\n\tclass_destroy(mon_bin_class);\nerr_class:\n\treturn rc;\n}\n\nvoid mon_bin_exit(void)\n{\n\tcdev_del(&mon_bin_cdev);\n\tunregister_chrdev_region(mon_bin_dev0, MON_BIN_MAX_MINOR);\n\tclass_destroy(mon_bin_class);\n}\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0\n/*\n * The USB Monitor, inspired by Dave Harding's USBMon.\n *\n * This is a binary format reader.\n *\n * Copyright (C) 2006 Paolo Abeni (paolo.abeni@email.it)\n * Copyright (C) 2006,2007 Pete Zaitcev (zaitcev@redhat.com)\n */\n\n#include <linux/kernel.h>\n#include <linux/sched/signal.h>\n#include <linux/types.h>\n#include <linux/fs.h>\n#include <linux/cdev.h>\n#include <linux/export.h>\n#include <linux/usb.h>\n#include <linux/poll.h>\n#include <linux/compat.h>\n#include <linux/mm.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/time64.h>\n\n#include <linux/uaccess.h>\n\n#include \"usb_mon.h\"\n\n/*\n * Defined by USB 2.0 clause 9.3, table 9.2.\n */\n#define SETUP_LEN  8\n\n/* ioctl macros */\n#define MON_IOC_MAGIC 0x92\n\n#define MON_IOCQ_URB_LEN _IO(MON_IOC_MAGIC, 1)\n/* #2 used to be MON_IOCX_URB, removed before it got into Linus tree */\n#define MON_IOCG_STATS _IOR(MON_IOC_MAGIC, 3, struct mon_bin_stats)\n#define MON_IOCT_RING_SIZE _IO(MON_IOC_MAGIC, 4)\n#define MON_IOCQ_RING_SIZE _IO(MON_IOC_MAGIC, 5)\n#define MON_IOCX_GET   _IOW(MON_IOC_MAGIC, 6, struct mon_bin_get)\n#define MON_IOCX_MFETCH _IOWR(MON_IOC_MAGIC, 7, struct mon_bin_mfetch)\n#define MON_IOCH_MFLUSH _IO(MON_IOC_MAGIC, 8)\n/* #9 was MON_IOCT_SETAPI */\n#define MON_IOCX_GETX   _IOW(MON_IOC_MAGIC, 10, struct mon_bin_get)\n\n#ifdef CONFIG_COMPAT\n#define MON_IOCX_GET32 _IOW(MON_IOC_MAGIC, 6, struct mon_bin_get32)\n#define MON_IOCX_MFETCH32 _IOWR(MON_IOC_MAGIC, 7, struct mon_bin_mfetch32)\n#define MON_IOCX_GETX32   _IOW(MON_IOC_MAGIC, 10, struct mon_bin_get32)\n#endif\n\n/*\n * Some architectures have enormous basic pages (16KB for ia64, 64KB for ppc).\n * But it's all right. Just use a simple way to make sure the chunk is never\n * smaller than a page.\n *\n * N.B. An application does not know our chunk size.\n *\n * Woops, get_zeroed_page() returns a single page. I guess we're stuck with\n * page-sized chunks for the time being.\n */\n#define CHUNK_SIZE   PAGE_SIZE\n#define CHUNK_ALIGN(x)   (((x)+CHUNK_SIZE-1) & ~(CHUNK_SIZE-1))\n\n/*\n * The magic limit was calculated so that it allows the monitoring\n * application to pick data once in two ticks. This way, another application,\n * which presumably drives the bus, gets to hog CPU, yet we collect our data.\n * If HZ is 100, a 480 mbit/s bus drives 614 KB every jiffy. USB has an\n * enormous overhead built into the bus protocol, so we need about 1000 KB.\n *\n * This is still too much for most cases, where we just snoop a few\n * descriptor fetches for enumeration. So, the default is a \"reasonable\"\n * amount for systems with HZ=250 and incomplete bus saturation.\n *\n * XXX What about multi-megabyte URBs which take minutes to transfer?\n */\n#define BUFF_MAX  CHUNK_ALIGN(1200*1024)\n#define BUFF_DFL   CHUNK_ALIGN(300*1024)\n#define BUFF_MIN     CHUNK_ALIGN(8*1024)\n\n/*\n * The per-event API header (2 per URB).\n *\n * This structure is seen in userland as defined by the documentation.\n */\nstruct mon_bin_hdr {\n\tu64 id;\t\t\t/* URB ID - from submission to callback */\n\tunsigned char type;\t/* Same as in text API; extensible. */\n\tunsigned char xfer_type;\t/* ISO, Intr, Control, Bulk */\n\tunsigned char epnum;\t/* Endpoint number and transfer direction */\n\tunsigned char devnum;\t/* Device address */\n\tunsigned short busnum;\t/* Bus number */\n\tchar flag_setup;\n\tchar flag_data;\n\ts64 ts_sec;\t\t/* ktime_get_real_ts64 */\n\ts32 ts_usec;\t\t/* ktime_get_real_ts64 */\n\tint status;\n\tunsigned int len_urb;\t/* Length of data (submitted or actual) */\n\tunsigned int len_cap;\t/* Delivered length */\n\tunion {\n\t\tunsigned char setup[SETUP_LEN];\t/* Only for Control S-type */\n\t\tstruct iso_rec {\n\t\t\tint error_count;\n\t\t\tint numdesc;\n\t\t} iso;\n\t} s;\n\tint interval;\n\tint start_frame;\n\tunsigned int xfer_flags;\n\tunsigned int ndesc;\t/* Actual number of ISO descriptors */\n};\n\n/*\n * ISO vector, packed into the head of data stream.\n * This has to take 16 bytes to make sure that the end of buffer\n * wrap is not happening in the middle of a descriptor.\n */\nstruct mon_bin_isodesc {\n\tint          iso_status;\n\tunsigned int iso_off;\n\tunsigned int iso_len;\n\tu32 _pad;\n};\n\n/* per file statistic */\nstruct mon_bin_stats {\n\tu32 queued;\n\tu32 dropped;\n};\n\nstruct mon_bin_get {\n\tstruct mon_bin_hdr __user *hdr;\t/* Can be 48 bytes or 64. */\n\tvoid __user *data;\n\tsize_t alloc;\t\t/* Length of data (can be zero) */\n};\n\nstruct mon_bin_mfetch {\n\tu32 __user *offvec;\t/* Vector of events fetched */\n\tu32 nfetch;\t\t/* Number of events to fetch (out: fetched) */\n\tu32 nflush;\t\t/* Number of events to flush */\n};\n\n#ifdef CONFIG_COMPAT\nstruct mon_bin_get32 {\n\tu32 hdr32;\n\tu32 data32;\n\tu32 alloc32;\n};\n\nstruct mon_bin_mfetch32 {\n        u32 offvec32;\n        u32 nfetch32;\n        u32 nflush32;\n};\n#endif\n\n/* Having these two values same prevents wrapping of the mon_bin_hdr */\n#define PKT_ALIGN   64\n#define PKT_SIZE    64\n\n#define PKT_SZ_API0 48\t/* API 0 (2.6.20) size */\n#define PKT_SZ_API1 64\t/* API 1 size: extra fields */\n\n#define ISODESC_MAX   128\t/* Same number as usbfs allows, 2048 bytes. */\n\n/* max number of USB bus supported */\n#define MON_BIN_MAX_MINOR 128\n\n/*\n * The buffer: map of used pages.\n */\nstruct mon_pgmap {\n\tstruct page *pg;\n\tunsigned char *ptr;\t/* XXX just use page_to_virt everywhere? */\n};\n\n/*\n * This gets associated with an open file struct.\n */\nstruct mon_reader_bin {\n\t/* The buffer: one per open. */\n\tspinlock_t b_lock;\t\t/* Protect b_cnt, b_in */\n\tunsigned int b_size;\t\t/* Current size of the buffer - bytes */\n\tunsigned int b_cnt;\t\t/* Bytes used */\n\tunsigned int b_in, b_out;\t/* Offsets into buffer - bytes */\n\tunsigned int b_read;\t\t/* Amount of read data in curr. pkt. */\n\tstruct mon_pgmap *b_vec;\t/* The map array */\n\twait_queue_head_t b_wait;\t/* Wait for data here */\n\n\tstruct mutex fetch_lock;\t/* Protect b_read, b_out */\n\tint mmap_active;\n\n\t/* A list of these is needed for \"bus 0\". Some time later. */\n\tstruct mon_reader r;\n\n\t/* Stats */\n\tunsigned int cnt_lost;\n};\n\nstatic inline struct mon_bin_hdr *MON_OFF2HDR(const struct mon_reader_bin *rp,\n    unsigned int offset)\n{\n\treturn (struct mon_bin_hdr *)\n\t    (rp->b_vec[offset / CHUNK_SIZE].ptr + offset % CHUNK_SIZE);\n}\n\n#define MON_RING_EMPTY(rp)\t((rp)->b_cnt == 0)\n\nstatic unsigned char xfer_to_pipe[4] = {\n\tPIPE_CONTROL, PIPE_ISOCHRONOUS, PIPE_BULK, PIPE_INTERRUPT\n};\n\nstatic struct class *mon_bin_class;\nstatic dev_t mon_bin_dev0;\nstatic struct cdev mon_bin_cdev;\n\nstatic void mon_buff_area_fill(const struct mon_reader_bin *rp,\n    unsigned int offset, unsigned int size);\nstatic int mon_bin_wait_event(struct file *file, struct mon_reader_bin *rp);\nstatic int mon_alloc_buff(struct mon_pgmap *map, int npages);\nstatic void mon_free_buff(struct mon_pgmap *map, int npages);\n\n/*\n * This is a \"chunked memcpy\". It does not manipulate any counters.\n */\nstatic unsigned int mon_copy_to_buff(const struct mon_reader_bin *this,\n    unsigned int off, const unsigned char *from, unsigned int length)\n{\n\tunsigned int step_len;\n\tunsigned char *buf;\n\tunsigned int in_page;\n\n\twhile (length) {\n\t\t/*\n\t\t * Determine step_len.\n\t\t */\n\t\tstep_len = length;\n\t\tin_page = CHUNK_SIZE - (off & (CHUNK_SIZE-1));\n\t\tif (in_page < step_len)\n\t\t\tstep_len = in_page;\n\n\t\t/*\n\t\t * Copy data and advance pointers.\n\t\t */\n\t\tbuf = this->b_vec[off / CHUNK_SIZE].ptr + off % CHUNK_SIZE;\n\t\tmemcpy(buf, from, step_len);\n\t\tif ((off += step_len) >= this->b_size) off = 0;\n\t\tfrom += step_len;\n\t\tlength -= step_len;\n\t}\n\treturn off;\n}\n\n/*\n * This is a little worse than the above because it's \"chunked copy_to_user\".\n * The return value is an error code, not an offset.\n */\nstatic int copy_from_buf(const struct mon_reader_bin *this, unsigned int off,\n    char __user *to, int length)\n{\n\tunsigned int step_len;\n\tunsigned char *buf;\n\tunsigned int in_page;\n\n\twhile (length) {\n\t\t/*\n\t\t * Determine step_len.\n\t\t */\n\t\tstep_len = length;\n\t\tin_page = CHUNK_SIZE - (off & (CHUNK_SIZE-1));\n\t\tif (in_page < step_len)\n\t\t\tstep_len = in_page;\n\n\t\t/*\n\t\t * Copy data and advance pointers.\n\t\t */\n\t\tbuf = this->b_vec[off / CHUNK_SIZE].ptr + off % CHUNK_SIZE;\n\t\tif (copy_to_user(to, buf, step_len))\n\t\t\treturn -EINVAL;\n\t\tif ((off += step_len) >= this->b_size) off = 0;\n\t\tto += step_len;\n\t\tlength -= step_len;\n\t}\n\treturn 0;\n}\n\n/*\n * Allocate an (aligned) area in the buffer.\n * This is called under b_lock.\n * Returns ~0 on failure.\n */\nstatic unsigned int mon_buff_area_alloc(struct mon_reader_bin *rp,\n    unsigned int size)\n{\n\tunsigned int offset;\n\n\tsize = (size + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\tif (rp->b_cnt + size > rp->b_size)\n\t\treturn ~0;\n\toffset = rp->b_in;\n\trp->b_cnt += size;\n\tif ((rp->b_in += size) >= rp->b_size)\n\t\trp->b_in -= rp->b_size;\n\treturn offset;\n}\n\n/*\n * This is the same thing as mon_buff_area_alloc, only it does not allow\n * buffers to wrap. This is needed by applications which pass references\n * into mmap-ed buffers up their stacks (libpcap can do that).\n *\n * Currently, we always have the header stuck with the data, although\n * it is not strictly speaking necessary.\n *\n * When a buffer would wrap, we place a filler packet to mark the space.\n */\nstatic unsigned int mon_buff_area_alloc_contiguous(struct mon_reader_bin *rp,\n    unsigned int size)\n{\n\tunsigned int offset;\n\tunsigned int fill_size;\n\n\tsize = (size + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\tif (rp->b_cnt + size > rp->b_size)\n\t\treturn ~0;\n\tif (rp->b_in + size > rp->b_size) {\n\t\t/*\n\t\t * This would wrap. Find if we still have space after\n\t\t * skipping to the end of the buffer. If we do, place\n\t\t * a filler packet and allocate a new packet.\n\t\t */\n\t\tfill_size = rp->b_size - rp->b_in;\n\t\tif (rp->b_cnt + size + fill_size > rp->b_size)\n\t\t\treturn ~0;\n\t\tmon_buff_area_fill(rp, rp->b_in, fill_size);\n\n\t\toffset = 0;\n\t\trp->b_in = size;\n\t\trp->b_cnt += size + fill_size;\n\t} else if (rp->b_in + size == rp->b_size) {\n\t\toffset = rp->b_in;\n\t\trp->b_in = 0;\n\t\trp->b_cnt += size;\n\t} else {\n\t\toffset = rp->b_in;\n\t\trp->b_in += size;\n\t\trp->b_cnt += size;\n\t}\n\treturn offset;\n}\n\n/*\n * Return a few (kilo-)bytes to the head of the buffer.\n * This is used if a data fetch fails.\n */\nstatic void mon_buff_area_shrink(struct mon_reader_bin *rp, unsigned int size)\n{\n\n\t/* size &= ~(PKT_ALIGN-1);  -- we're called with aligned size */\n\trp->b_cnt -= size;\n\tif (rp->b_in < size)\n\t\trp->b_in += rp->b_size;\n\trp->b_in -= size;\n}\n\n/*\n * This has to be called under both b_lock and fetch_lock, because\n * it accesses both b_cnt and b_out.\n */\nstatic void mon_buff_area_free(struct mon_reader_bin *rp, unsigned int size)\n{\n\n\tsize = (size + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\trp->b_cnt -= size;\n\tif ((rp->b_out += size) >= rp->b_size)\n\t\trp->b_out -= rp->b_size;\n}\n\nstatic void mon_buff_area_fill(const struct mon_reader_bin *rp,\n    unsigned int offset, unsigned int size)\n{\n\tstruct mon_bin_hdr *ep;\n\n\tep = MON_OFF2HDR(rp, offset);\n\tmemset(ep, 0, PKT_SIZE);\n\tep->type = '@';\n\tep->len_cap = size - PKT_SIZE;\n}\n\nstatic inline char mon_bin_get_setup(unsigned char *setupb,\n    const struct urb *urb, char ev_type)\n{\n\n\tif (urb->setup_packet == NULL)\n\t\treturn 'Z';\n\tmemcpy(setupb, urb->setup_packet, SETUP_LEN);\n\treturn 0;\n}\n\nstatic unsigned int mon_bin_get_data(const struct mon_reader_bin *rp,\n    unsigned int offset, struct urb *urb, unsigned int length,\n    char *flag)\n{\n\tint i;\n\tstruct scatterlist *sg;\n\tunsigned int this_len;\n\n\t*flag = 0;\n\tif (urb->num_sgs == 0) {\n\t\tif (urb->transfer_buffer == NULL) {\n\t\t\t*flag = 'Z';\n\t\t\treturn length;\n\t\t}\n\t\tmon_copy_to_buff(rp, offset, urb->transfer_buffer, length);\n\t\tlength = 0;\n\n\t} else {\n\t\t/* If IOMMU coalescing occurred, we cannot trust sg_page */\n\t\tif (urb->transfer_flags & URB_DMA_SG_COMBINED) {\n\t\t\t*flag = 'D';\n\t\t\treturn length;\n\t\t}\n\n\t\t/* Copy up to the first non-addressable segment */\n\t\tfor_each_sg(urb->sg, sg, urb->num_sgs, i) {\n\t\t\tif (length == 0 || PageHighMem(sg_page(sg)))\n\t\t\t\tbreak;\n\t\t\tthis_len = min_t(unsigned int, sg->length, length);\n\t\t\toffset = mon_copy_to_buff(rp, offset, sg_virt(sg),\n\t\t\t\t\tthis_len);\n\t\t\tlength -= this_len;\n\t\t}\n\t\tif (i == 0)\n\t\t\t*flag = 'D';\n\t}\n\n\treturn length;\n}\n\n/*\n * This is the look-ahead pass in case of 'C Zi', when actual_length cannot\n * be used to determine the length of the whole contiguous buffer.\n */\nstatic unsigned int mon_bin_collate_isodesc(const struct mon_reader_bin *rp,\n    struct urb *urb, unsigned int ndesc)\n{\n\tstruct usb_iso_packet_descriptor *fp;\n\tunsigned int length;\n\n\tlength = 0;\n\tfp = urb->iso_frame_desc;\n\twhile (ndesc-- != 0) {\n\t\tif (fp->actual_length != 0) {\n\t\t\tif (fp->offset + fp->actual_length > length)\n\t\t\t\tlength = fp->offset + fp->actual_length;\n\t\t}\n\t\tfp++;\n\t}\n\treturn length;\n}\n\nstatic void mon_bin_get_isodesc(const struct mon_reader_bin *rp,\n    unsigned int offset, struct urb *urb, char ev_type, unsigned int ndesc)\n{\n\tstruct mon_bin_isodesc *dp;\n\tstruct usb_iso_packet_descriptor *fp;\n\n\tfp = urb->iso_frame_desc;\n\twhile (ndesc-- != 0) {\n\t\tdp = (struct mon_bin_isodesc *)\n\t\t    (rp->b_vec[offset / CHUNK_SIZE].ptr + offset % CHUNK_SIZE);\n\t\tdp->iso_status = fp->status;\n\t\tdp->iso_off = fp->offset;\n\t\tdp->iso_len = (ev_type == 'S') ? fp->length : fp->actual_length;\n\t\tdp->_pad = 0;\n\t\tif ((offset += sizeof(struct mon_bin_isodesc)) >= rp->b_size)\n\t\t\toffset = 0;\n\t\tfp++;\n\t}\n}\n\nstatic void mon_bin_event(struct mon_reader_bin *rp, struct urb *urb,\n    char ev_type, int status)\n{\n\tconst struct usb_endpoint_descriptor *epd = &urb->ep->desc;\n\tstruct timespec64 ts;\n\tunsigned long flags;\n\tunsigned int urb_length;\n\tunsigned int offset;\n\tunsigned int length;\n\tunsigned int delta;\n\tunsigned int ndesc, lendesc;\n\tunsigned char dir;\n\tstruct mon_bin_hdr *ep;\n\tchar data_tag = 0;\n\n\tktime_get_real_ts64(&ts);\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\n\t/*\n\t * Find the maximum allowable length, then allocate space.\n\t */\n\turb_length = (ev_type == 'S') ?\n\t    urb->transfer_buffer_length : urb->actual_length;\n\tlength = urb_length;\n\n\tif (usb_endpoint_xfer_isoc(epd)) {\n\t\tif (urb->number_of_packets < 0) {\n\t\t\tndesc = 0;\n\t\t} else if (urb->number_of_packets >= ISODESC_MAX) {\n\t\t\tndesc = ISODESC_MAX;\n\t\t} else {\n\t\t\tndesc = urb->number_of_packets;\n\t\t}\n\t\tif (ev_type == 'C' && usb_urb_dir_in(urb))\n\t\t\tlength = mon_bin_collate_isodesc(rp, urb, ndesc);\n\t} else {\n\t\tndesc = 0;\n\t}\n\tlendesc = ndesc*sizeof(struct mon_bin_isodesc);\n\n\t/* not an issue unless there's a subtle bug in a HCD somewhere */\n\tif (length >= urb->transfer_buffer_length)\n\t\tlength = urb->transfer_buffer_length;\n\n\tif (length >= rp->b_size/5)\n\t\tlength = rp->b_size/5;\n\n\tif (usb_urb_dir_in(urb)) {\n\t\tif (ev_type == 'S') {\n\t\t\tlength = 0;\n\t\t\tdata_tag = '<';\n\t\t}\n\t\t/* Cannot rely on endpoint number in case of control ep.0 */\n\t\tdir = USB_DIR_IN;\n\t} else {\n\t\tif (ev_type == 'C') {\n\t\t\tlength = 0;\n\t\t\tdata_tag = '>';\n\t\t}\n\t\tdir = 0;\n\t}\n\n\tif (rp->mmap_active) {\n\t\toffset = mon_buff_area_alloc_contiguous(rp,\n\t\t\t\t\t\t length + PKT_SIZE + lendesc);\n\t} else {\n\t\toffset = mon_buff_area_alloc(rp, length + PKT_SIZE + lendesc);\n\t}\n\tif (offset == ~0) {\n\t\trp->cnt_lost++;\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\treturn;\n\t}\n\n\tep = MON_OFF2HDR(rp, offset);\n\tif ((offset += PKT_SIZE) >= rp->b_size) offset = 0;\n\n\t/*\n\t * Fill the allocated area.\n\t */\n\tmemset(ep, 0, PKT_SIZE);\n\tep->type = ev_type;\n\tep->xfer_type = xfer_to_pipe[usb_endpoint_type(epd)];\n\tep->epnum = dir | usb_endpoint_num(epd);\n\tep->devnum = urb->dev->devnum;\n\tep->busnum = urb->dev->bus->busnum;\n\tep->id = (unsigned long) urb;\n\tep->ts_sec = ts.tv_sec;\n\tep->ts_usec = ts.tv_nsec / NSEC_PER_USEC;\n\tep->status = status;\n\tep->len_urb = urb_length;\n\tep->len_cap = length + lendesc;\n\tep->xfer_flags = urb->transfer_flags;\n\n\tif (usb_endpoint_xfer_int(epd)) {\n\t\tep->interval = urb->interval;\n\t} else if (usb_endpoint_xfer_isoc(epd)) {\n\t\tep->interval = urb->interval;\n\t\tep->start_frame = urb->start_frame;\n\t\tep->s.iso.error_count = urb->error_count;\n\t\tep->s.iso.numdesc = urb->number_of_packets;\n\t}\n\n\tif (usb_endpoint_xfer_control(epd) && ev_type == 'S') {\n\t\tep->flag_setup = mon_bin_get_setup(ep->s.setup, urb, ev_type);\n\t} else {\n\t\tep->flag_setup = '-';\n\t}\n\n\tif (ndesc != 0) {\n\t\tep->ndesc = ndesc;\n\t\tmon_bin_get_isodesc(rp, offset, urb, ev_type, ndesc);\n\t\tif ((offset += lendesc) >= rp->b_size)\n\t\t\toffset -= rp->b_size;\n\t}\n\n\tif (length != 0) {\n\t\tlength = mon_bin_get_data(rp, offset, urb, length,\n\t\t\t\t&ep->flag_data);\n\t\tif (length > 0) {\n\t\t\tdelta = (ep->len_cap + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\t\t\tep->len_cap -= length;\n\t\t\tdelta -= (ep->len_cap + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\t\t\tmon_buff_area_shrink(rp, delta);\n\t\t}\n\t} else {\n\t\tep->flag_data = data_tag;\n\t}\n\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\twake_up(&rp->b_wait);\n}\n\nstatic void mon_bin_submit(void *data, struct urb *urb)\n{\n\tstruct mon_reader_bin *rp = data;\n\tmon_bin_event(rp, urb, 'S', -EINPROGRESS);\n}\n\nstatic void mon_bin_complete(void *data, struct urb *urb, int status)\n{\n\tstruct mon_reader_bin *rp = data;\n\tmon_bin_event(rp, urb, 'C', status);\n}\n\nstatic void mon_bin_error(void *data, struct urb *urb, int error)\n{\n\tstruct mon_reader_bin *rp = data;\n\tstruct timespec64 ts;\n\tunsigned long flags;\n\tunsigned int offset;\n\tstruct mon_bin_hdr *ep;\n\n\tktime_get_real_ts64(&ts);\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\n\toffset = mon_buff_area_alloc(rp, PKT_SIZE);\n\tif (offset == ~0) {\n\t\t/* Not incrementing cnt_lost. Just because. */\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\treturn;\n\t}\n\n\tep = MON_OFF2HDR(rp, offset);\n\n\tmemset(ep, 0, PKT_SIZE);\n\tep->type = 'E';\n\tep->xfer_type = xfer_to_pipe[usb_endpoint_type(&urb->ep->desc)];\n\tep->epnum = usb_urb_dir_in(urb) ? USB_DIR_IN : 0;\n\tep->epnum |= usb_endpoint_num(&urb->ep->desc);\n\tep->devnum = urb->dev->devnum;\n\tep->busnum = urb->dev->bus->busnum;\n\tep->id = (unsigned long) urb;\n\tep->ts_sec = ts.tv_sec;\n\tep->ts_usec = ts.tv_nsec / NSEC_PER_USEC;\n\tep->status = error;\n\n\tep->flag_setup = '-';\n\tep->flag_data = 'E';\n\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\twake_up(&rp->b_wait);\n}\n\nstatic int mon_bin_open(struct inode *inode, struct file *file)\n{\n\tstruct mon_bus *mbus;\n\tstruct mon_reader_bin *rp;\n\tsize_t size;\n\tint rc;\n\n\tmutex_lock(&mon_lock);\n\tmbus = mon_bus_lookup(iminor(inode));\n\tif (mbus == NULL) {\n\t\tmutex_unlock(&mon_lock);\n\t\treturn -ENODEV;\n\t}\n\tif (mbus != &mon_bus0 && mbus->u_bus == NULL) {\n\t\tprintk(KERN_ERR TAG \": consistency error on open\\n\");\n\t\tmutex_unlock(&mon_lock);\n\t\treturn -ENODEV;\n\t}\n\n\trp = kzalloc(sizeof(struct mon_reader_bin), GFP_KERNEL);\n\tif (rp == NULL) {\n\t\trc = -ENOMEM;\n\t\tgoto err_alloc;\n\t}\n\tspin_lock_init(&rp->b_lock);\n\tinit_waitqueue_head(&rp->b_wait);\n\tmutex_init(&rp->fetch_lock);\n\trp->b_size = BUFF_DFL;\n\n\tsize = sizeof(struct mon_pgmap) * (rp->b_size/CHUNK_SIZE);\n\tif ((rp->b_vec = kzalloc(size, GFP_KERNEL)) == NULL) {\n\t\trc = -ENOMEM;\n\t\tgoto err_allocvec;\n\t}\n\n\tif ((rc = mon_alloc_buff(rp->b_vec, rp->b_size/CHUNK_SIZE)) < 0)\n\t\tgoto err_allocbuff;\n\n\trp->r.m_bus = mbus;\n\trp->r.r_data = rp;\n\trp->r.rnf_submit = mon_bin_submit;\n\trp->r.rnf_error = mon_bin_error;\n\trp->r.rnf_complete = mon_bin_complete;\n\n\tmon_reader_add(mbus, &rp->r);\n\n\tfile->private_data = rp;\n\tmutex_unlock(&mon_lock);\n\treturn 0;\n\nerr_allocbuff:\n\tkfree(rp->b_vec);\nerr_allocvec:\n\tkfree(rp);\nerr_alloc:\n\tmutex_unlock(&mon_lock);\n\treturn rc;\n}\n\n/*\n * Extract an event from buffer and copy it to user space.\n * Wait if there is no event ready.\n * Returns zero or error.\n */\nstatic int mon_bin_get_event(struct file *file, struct mon_reader_bin *rp,\n    struct mon_bin_hdr __user *hdr, unsigned int hdrbytes,\n    void __user *data, unsigned int nbytes)\n{\n\tunsigned long flags;\n\tstruct mon_bin_hdr *ep;\n\tsize_t step_len;\n\tunsigned int offset;\n\tint rc;\n\n\tmutex_lock(&rp->fetch_lock);\n\n\tif ((rc = mon_bin_wait_event(file, rp)) < 0) {\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\treturn rc;\n\t}\n\n\tep = MON_OFF2HDR(rp, rp->b_out);\n\n\tif (copy_to_user(hdr, ep, hdrbytes)) {\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\treturn -EFAULT;\n\t}\n\n\tstep_len = min(ep->len_cap, nbytes);\n\tif ((offset = rp->b_out + PKT_SIZE) >= rp->b_size) offset = 0;\n\n\tif (copy_from_buf(rp, offset, data, step_len)) {\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\treturn -EFAULT;\n\t}\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\tmon_buff_area_free(rp, PKT_SIZE + ep->len_cap);\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\trp->b_read = 0;\n\n\tmutex_unlock(&rp->fetch_lock);\n\treturn 0;\n}\n\nstatic int mon_bin_release(struct inode *inode, struct file *file)\n{\n\tstruct mon_reader_bin *rp = file->private_data;\n\tstruct mon_bus* mbus = rp->r.m_bus;\n\n\tmutex_lock(&mon_lock);\n\n\tif (mbus->nreaders <= 0) {\n\t\tprintk(KERN_ERR TAG \": consistency error on close\\n\");\n\t\tmutex_unlock(&mon_lock);\n\t\treturn 0;\n\t}\n\tmon_reader_del(mbus, &rp->r);\n\n\tmon_free_buff(rp->b_vec, rp->b_size/CHUNK_SIZE);\n\tkfree(rp->b_vec);\n\tkfree(rp);\n\n\tmutex_unlock(&mon_lock);\n\treturn 0;\n}\n\nstatic ssize_t mon_bin_read(struct file *file, char __user *buf,\n    size_t nbytes, loff_t *ppos)\n{\n\tstruct mon_reader_bin *rp = file->private_data;\n\tunsigned int hdrbytes = PKT_SZ_API0;\n\tunsigned long flags;\n\tstruct mon_bin_hdr *ep;\n\tunsigned int offset;\n\tsize_t step_len;\n\tchar *ptr;\n\tssize_t done = 0;\n\tint rc;\n\n\tmutex_lock(&rp->fetch_lock);\n\n\tif ((rc = mon_bin_wait_event(file, rp)) < 0) {\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\treturn rc;\n\t}\n\n\tep = MON_OFF2HDR(rp, rp->b_out);\n\n\tif (rp->b_read < hdrbytes) {\n\t\tstep_len = min(nbytes, (size_t)(hdrbytes - rp->b_read));\n\t\tptr = ((char *)ep) + rp->b_read;\n\t\tif (step_len && copy_to_user(buf, ptr, step_len)) {\n\t\t\tmutex_unlock(&rp->fetch_lock);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tnbytes -= step_len;\n\t\tbuf += step_len;\n\t\trp->b_read += step_len;\n\t\tdone += step_len;\n\t}\n\n\tif (rp->b_read >= hdrbytes) {\n\t\tstep_len = ep->len_cap;\n\t\tstep_len -= rp->b_read - hdrbytes;\n\t\tif (step_len > nbytes)\n\t\t\tstep_len = nbytes;\n\t\toffset = rp->b_out + PKT_SIZE;\n\t\toffset += rp->b_read - hdrbytes;\n\t\tif (offset >= rp->b_size)\n\t\t\toffset -= rp->b_size;\n\t\tif (copy_from_buf(rp, offset, buf, step_len)) {\n\t\t\tmutex_unlock(&rp->fetch_lock);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tnbytes -= step_len;\n\t\tbuf += step_len;\n\t\trp->b_read += step_len;\n\t\tdone += step_len;\n\t}\n\n\t/*\n\t * Check if whole packet was read, and if so, jump to the next one.\n\t */\n\tif (rp->b_read >= hdrbytes + ep->len_cap) {\n\t\tspin_lock_irqsave(&rp->b_lock, flags);\n\t\tmon_buff_area_free(rp, PKT_SIZE + ep->len_cap);\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\trp->b_read = 0;\n\t}\n\n\tmutex_unlock(&rp->fetch_lock);\n\treturn done;\n}\n\n/*\n * Remove at most nevents from chunked buffer.\n * Returns the number of removed events.\n */\nstatic int mon_bin_flush(struct mon_reader_bin *rp, unsigned nevents)\n{\n\tunsigned long flags;\n\tstruct mon_bin_hdr *ep;\n\tint i;\n\n\tmutex_lock(&rp->fetch_lock);\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\tfor (i = 0; i < nevents; ++i) {\n\t\tif (MON_RING_EMPTY(rp))\n\t\t\tbreak;\n\n\t\tep = MON_OFF2HDR(rp, rp->b_out);\n\t\tmon_buff_area_free(rp, PKT_SIZE + ep->len_cap);\n\t}\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\trp->b_read = 0;\n\tmutex_unlock(&rp->fetch_lock);\n\treturn i;\n}\n\n/*\n * Fetch at most max event offsets into the buffer and put them into vec.\n * The events are usually freed later with mon_bin_flush.\n * Return the effective number of events fetched.\n */\nstatic int mon_bin_fetch(struct file *file, struct mon_reader_bin *rp,\n    u32 __user *vec, unsigned int max)\n{\n\tunsigned int cur_out;\n\tunsigned int bytes, avail;\n\tunsigned int size;\n\tunsigned int nevents;\n\tstruct mon_bin_hdr *ep;\n\tunsigned long flags;\n\tint rc;\n\n\tmutex_lock(&rp->fetch_lock);\n\n\tif ((rc = mon_bin_wait_event(file, rp)) < 0) {\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\treturn rc;\n\t}\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\tavail = rp->b_cnt;\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\tcur_out = rp->b_out;\n\tnevents = 0;\n\tbytes = 0;\n\twhile (bytes < avail) {\n\t\tif (nevents >= max)\n\t\t\tbreak;\n\n\t\tep = MON_OFF2HDR(rp, cur_out);\n\t\tif (put_user(cur_out, &vec[nevents])) {\n\t\t\tmutex_unlock(&rp->fetch_lock);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tnevents++;\n\t\tsize = ep->len_cap + PKT_SIZE;\n\t\tsize = (size + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\t\tif ((cur_out += size) >= rp->b_size)\n\t\t\tcur_out -= rp->b_size;\n\t\tbytes += size;\n\t}\n\n\tmutex_unlock(&rp->fetch_lock);\n\treturn nevents;\n}\n\n/*\n * Count events. This is almost the same as the above mon_bin_fetch,\n * only we do not store offsets into user vector, and we have no limit.\n */\nstatic int mon_bin_queued(struct mon_reader_bin *rp)\n{\n\tunsigned int cur_out;\n\tunsigned int bytes, avail;\n\tunsigned int size;\n\tunsigned int nevents;\n\tstruct mon_bin_hdr *ep;\n\tunsigned long flags;\n\n\tmutex_lock(&rp->fetch_lock);\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\tavail = rp->b_cnt;\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\tcur_out = rp->b_out;\n\tnevents = 0;\n\tbytes = 0;\n\twhile (bytes < avail) {\n\t\tep = MON_OFF2HDR(rp, cur_out);\n\n\t\tnevents++;\n\t\tsize = ep->len_cap + PKT_SIZE;\n\t\tsize = (size + PKT_ALIGN-1) & ~(PKT_ALIGN-1);\n\t\tif ((cur_out += size) >= rp->b_size)\n\t\t\tcur_out -= rp->b_size;\n\t\tbytes += size;\n\t}\n\n\tmutex_unlock(&rp->fetch_lock);\n\treturn nevents;\n}\n\n/*\n */\nstatic long mon_bin_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct mon_reader_bin *rp = file->private_data;\n\t// struct mon_bus* mbus = rp->r.m_bus;\n\tint ret = 0;\n\tstruct mon_bin_hdr *ep;\n\tunsigned long flags;\n\n\tswitch (cmd) {\n\n\tcase MON_IOCQ_URB_LEN:\n\t\t/*\n\t\t * N.B. This only returns the size of data, without the header.\n\t\t */\n\t\tspin_lock_irqsave(&rp->b_lock, flags);\n\t\tif (!MON_RING_EMPTY(rp)) {\n\t\t\tep = MON_OFF2HDR(rp, rp->b_out);\n\t\t\tret = ep->len_cap;\n\t\t}\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\tbreak;\n\n\tcase MON_IOCQ_RING_SIZE:\n\t\tmutex_lock(&rp->fetch_lock);\n\t\tret = rp->b_size;\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\tbreak;\n\n\tcase MON_IOCT_RING_SIZE:\n\t\t/*\n\t\t * Changing the buffer size will flush it's contents; the new\n\t\t * buffer is allocated before releasing the old one to be sure\n\t\t * the device will stay functional also in case of memory\n\t\t * pressure.\n\t\t */\n\t\t{\n\t\tint size;\n\t\tstruct mon_pgmap *vec;\n\n\t\tif (arg < BUFF_MIN || arg > BUFF_MAX)\n\t\t\treturn -EINVAL;\n\n\t\tsize = CHUNK_ALIGN(arg);\n\t\tvec = kcalloc(size / CHUNK_SIZE, sizeof(struct mon_pgmap),\n\t\t\t      GFP_KERNEL);\n\t\tif (vec == NULL) {\n\t\t\tret = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tret = mon_alloc_buff(vec, size/CHUNK_SIZE);\n\t\tif (ret < 0) {\n\t\t\tkfree(vec);\n\t\t\tbreak;\n\t\t}\n\n\t\tmutex_lock(&rp->fetch_lock);\n\t\tspin_lock_irqsave(&rp->b_lock, flags);\n\t\tif (rp->mmap_active) {\n\t\t\tmon_free_buff(vec, size/CHUNK_SIZE);\n\t\t\tkfree(vec);\n\t\t\tret = -EBUSY;\n\t\t} else {\n\t\t\tmon_free_buff(rp->b_vec, rp->b_size/CHUNK_SIZE);\n\t\t\tkfree(rp->b_vec);\n\t\t\trp->b_vec  = vec;\n\t\t\trp->b_size = size;\n\t\t\trp->b_read = rp->b_in = rp->b_out = rp->b_cnt = 0;\n\t\t\trp->cnt_lost = 0;\n\t\t}\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\tmutex_unlock(&rp->fetch_lock);\n\t\t}\n\t\tbreak;\n\n\tcase MON_IOCH_MFLUSH:\n\t\tret = mon_bin_flush(rp, arg);\n\t\tbreak;\n\n\tcase MON_IOCX_GET:\n\tcase MON_IOCX_GETX:\n\t\t{\n\t\tstruct mon_bin_get getb;\n\n\t\tif (copy_from_user(&getb, (void __user *)arg,\n\t\t\t\t\t    sizeof(struct mon_bin_get)))\n\t\t\treturn -EFAULT;\n\n\t\tif (getb.alloc > 0x10000000)\t/* Want to cast to u32 */\n\t\t\treturn -EINVAL;\n\t\tret = mon_bin_get_event(file, rp, getb.hdr,\n\t\t    (cmd == MON_IOCX_GET)? PKT_SZ_API0: PKT_SZ_API1,\n\t\t    getb.data, (unsigned int)getb.alloc);\n\t\t}\n\t\tbreak;\n\n\tcase MON_IOCX_MFETCH:\n\t\t{\n\t\tstruct mon_bin_mfetch mfetch;\n\t\tstruct mon_bin_mfetch __user *uptr;\n\n\t\tuptr = (struct mon_bin_mfetch __user *)arg;\n\n\t\tif (copy_from_user(&mfetch, uptr, sizeof(mfetch)))\n\t\t\treturn -EFAULT;\n\n\t\tif (mfetch.nflush) {\n\t\t\tret = mon_bin_flush(rp, mfetch.nflush);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tif (put_user(ret, &uptr->nflush))\n\t\t\t\treturn -EFAULT;\n\t\t}\n\t\tret = mon_bin_fetch(file, rp, mfetch.offvec, mfetch.nfetch);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tif (put_user(ret, &uptr->nfetch))\n\t\t\treturn -EFAULT;\n\t\tret = 0;\n\t\t}\n\t\tbreak;\n\n\tcase MON_IOCG_STATS: {\n\t\tstruct mon_bin_stats __user *sp;\n\t\tunsigned int nevents;\n\t\tunsigned int ndropped;\n\n\t\tspin_lock_irqsave(&rp->b_lock, flags);\n\t\tndropped = rp->cnt_lost;\n\t\trp->cnt_lost = 0;\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\t\tnevents = mon_bin_queued(rp);\n\n\t\tsp = (struct mon_bin_stats __user *)arg;\n\t\tif (put_user(ndropped, &sp->dropped))\n\t\t\treturn -EFAULT;\n\t\tif (put_user(nevents, &sp->queued))\n\t\t\treturn -EFAULT;\n\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic long mon_bin_compat_ioctl(struct file *file,\n    unsigned int cmd, unsigned long arg)\n{\n\tstruct mon_reader_bin *rp = file->private_data;\n\tint ret;\n\n\tswitch (cmd) {\n\n\tcase MON_IOCX_GET32:\n\tcase MON_IOCX_GETX32:\n\t\t{\n\t\tstruct mon_bin_get32 getb;\n\n\t\tif (copy_from_user(&getb, (void __user *)arg,\n\t\t\t\t\t    sizeof(struct mon_bin_get32)))\n\t\t\treturn -EFAULT;\n\n\t\tret = mon_bin_get_event(file, rp, compat_ptr(getb.hdr32),\n\t\t    (cmd == MON_IOCX_GET32)? PKT_SZ_API0: PKT_SZ_API1,\n\t\t    compat_ptr(getb.data32), getb.alloc32);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\t}\n\t\treturn 0;\n\n\tcase MON_IOCX_MFETCH32:\n\t\t{\n\t\tstruct mon_bin_mfetch32 mfetch;\n\t\tstruct mon_bin_mfetch32 __user *uptr;\n\n\t\tuptr = (struct mon_bin_mfetch32 __user *) compat_ptr(arg);\n\n\t\tif (copy_from_user(&mfetch, uptr, sizeof(mfetch)))\n\t\t\treturn -EFAULT;\n\n\t\tif (mfetch.nflush32) {\n\t\t\tret = mon_bin_flush(rp, mfetch.nflush32);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\tif (put_user(ret, &uptr->nflush32))\n\t\t\t\treturn -EFAULT;\n\t\t}\n\t\tret = mon_bin_fetch(file, rp, compat_ptr(mfetch.offvec32),\n\t\t    mfetch.nfetch32);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tif (put_user(ret, &uptr->nfetch32))\n\t\t\treturn -EFAULT;\n\t\t}\n\t\treturn 0;\n\n\tcase MON_IOCG_STATS:\n\t\treturn mon_bin_ioctl(file, cmd, (unsigned long) compat_ptr(arg));\n\n\tcase MON_IOCQ_URB_LEN:\n\tcase MON_IOCQ_RING_SIZE:\n\tcase MON_IOCT_RING_SIZE:\n\tcase MON_IOCH_MFLUSH:\n\t\treturn mon_bin_ioctl(file, cmd, arg);\n\n\tdefault:\n\t\t;\n\t}\n\treturn -ENOTTY;\n}\n#endif /* CONFIG_COMPAT */\n\nstatic __poll_t\nmon_bin_poll(struct file *file, struct poll_table_struct *wait)\n{\n\tstruct mon_reader_bin *rp = file->private_data;\n\t__poll_t mask = 0;\n\tunsigned long flags;\n\n\tif (file->f_mode & FMODE_READ)\n\t\tpoll_wait(file, &rp->b_wait, wait);\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\tif (!MON_RING_EMPTY(rp))\n\t\tmask |= EPOLLIN | EPOLLRDNORM;    /* readable */\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\treturn mask;\n}\n\n/*\n * open and close: just keep track of how many times the device is\n * mapped, to use the proper memory allocation function.\n */\nstatic void mon_bin_vma_open(struct vm_area_struct *vma)\n{\n\tstruct mon_reader_bin *rp = vma->vm_private_data;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\trp->mmap_active++;\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n}\n\nstatic void mon_bin_vma_close(struct vm_area_struct *vma)\n{\n\tunsigned long flags;\n\n\tstruct mon_reader_bin *rp = vma->vm_private_data;\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\trp->mmap_active--;\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n}\n\n/*\n * Map ring pages to user space.\n */\nstatic vm_fault_t mon_bin_vma_fault(struct vm_fault *vmf)\n{\n\tstruct mon_reader_bin *rp = vmf->vma->vm_private_data;\n\tunsigned long offset, chunk_idx;\n\tstruct page *pageptr;\n\n\toffset = vmf->pgoff << PAGE_SHIFT;\n\tif (offset >= rp->b_size)\n\t\treturn VM_FAULT_SIGBUS;\n\tchunk_idx = offset / CHUNK_SIZE;\n\tpageptr = rp->b_vec[chunk_idx].pg;\n\tget_page(pageptr);\n\tvmf->page = pageptr;\n\treturn 0;\n}\n\nstatic const struct vm_operations_struct mon_bin_vm_ops = {\n\t.open =     mon_bin_vma_open,\n\t.close =    mon_bin_vma_close,\n\t.fault =    mon_bin_vma_fault,\n};\n\nstatic int mon_bin_mmap(struct file *filp, struct vm_area_struct *vma)\n{\n\t/* don't do anything here: \"fault\" will set up page table entries */\n\tvma->vm_ops = &mon_bin_vm_ops;\n\n\tif (vma->vm_flags & VM_WRITE)\n\t\treturn -EPERM;\n\n\tvma->vm_flags &= ~VM_MAYWRITE;\n\tvma->vm_flags |= VM_DONTEXPAND | VM_DONTDUMP;\n\tvma->vm_private_data = filp->private_data;\n\tmon_bin_vma_open(vma);\n\treturn 0;\n}\n\nstatic const struct file_operations mon_fops_binary = {\n\t.owner =\tTHIS_MODULE,\n\t.open =\t\tmon_bin_open,\n\t.llseek =\tno_llseek,\n\t.read =\t\tmon_bin_read,\n\t/* .write =\tmon_text_write, */\n\t.poll =\t\tmon_bin_poll,\n\t.unlocked_ioctl = mon_bin_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl =\tmon_bin_compat_ioctl,\n#endif\n\t.release =\tmon_bin_release,\n\t.mmap =\t\tmon_bin_mmap,\n};\n\nstatic int mon_bin_wait_event(struct file *file, struct mon_reader_bin *rp)\n{\n\tDECLARE_WAITQUEUE(waita, current);\n\tunsigned long flags;\n\n\tadd_wait_queue(&rp->b_wait, &waita);\n\tset_current_state(TASK_INTERRUPTIBLE);\n\n\tspin_lock_irqsave(&rp->b_lock, flags);\n\twhile (MON_RING_EMPTY(rp)) {\n\t\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\t\tif (file->f_flags & O_NONBLOCK) {\n\t\t\tset_current_state(TASK_RUNNING);\n\t\t\tremove_wait_queue(&rp->b_wait, &waita);\n\t\t\treturn -EWOULDBLOCK; /* Same as EAGAIN in Linux */\n\t\t}\n\t\tschedule();\n\t\tif (signal_pending(current)) {\n\t\t\tremove_wait_queue(&rp->b_wait, &waita);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\n\t\tspin_lock_irqsave(&rp->b_lock, flags);\n\t}\n\tspin_unlock_irqrestore(&rp->b_lock, flags);\n\n\tset_current_state(TASK_RUNNING);\n\tremove_wait_queue(&rp->b_wait, &waita);\n\treturn 0;\n}\n\nstatic int mon_alloc_buff(struct mon_pgmap *map, int npages)\n{\n\tint n;\n\tunsigned long vaddr;\n\n\tfor (n = 0; n < npages; n++) {\n\t\tvaddr = get_zeroed_page(GFP_KERNEL);\n\t\tif (vaddr == 0) {\n\t\t\twhile (n-- != 0)\n\t\t\t\tfree_page((unsigned long) map[n].ptr);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tmap[n].ptr = (unsigned char *) vaddr;\n\t\tmap[n].pg = virt_to_page((void *) vaddr);\n\t}\n\treturn 0;\n}\n\nstatic void mon_free_buff(struct mon_pgmap *map, int npages)\n{\n\tint n;\n\n\tfor (n = 0; n < npages; n++)\n\t\tfree_page((unsigned long) map[n].ptr);\n}\n\nint mon_bin_add(struct mon_bus *mbus, const struct usb_bus *ubus)\n{\n\tstruct device *dev;\n\tunsigned minor = ubus? ubus->busnum: 0;\n\n\tif (minor >= MON_BIN_MAX_MINOR)\n\t\treturn 0;\n\n\tdev = device_create(mon_bin_class, ubus ? ubus->controller : NULL,\n\t\t\t    MKDEV(MAJOR(mon_bin_dev0), minor), NULL,\n\t\t\t    \"usbmon%d\", minor);\n\tif (IS_ERR(dev))\n\t\treturn 0;\n\n\tmbus->classdev = dev;\n\treturn 1;\n}\n\nvoid mon_bin_del(struct mon_bus *mbus)\n{\n\tdevice_destroy(mon_bin_class, mbus->classdev->devt);\n}\n\nint __init mon_bin_init(void)\n{\n\tint rc;\n\n\tmon_bin_class = class_create(THIS_MODULE, \"usbmon\");\n\tif (IS_ERR(mon_bin_class)) {\n\t\trc = PTR_ERR(mon_bin_class);\n\t\tgoto err_class;\n\t}\n\n\trc = alloc_chrdev_region(&mon_bin_dev0, 0, MON_BIN_MAX_MINOR, \"usbmon\");\n\tif (rc < 0)\n\t\tgoto err_dev;\n\n\tcdev_init(&mon_bin_cdev, &mon_fops_binary);\n\tmon_bin_cdev.owner = THIS_MODULE;\n\n\trc = cdev_add(&mon_bin_cdev, mon_bin_dev0, MON_BIN_MAX_MINOR);\n\tif (rc < 0)\n\t\tgoto err_add;\n\n\treturn 0;\n\nerr_add:\n\tunregister_chrdev_region(mon_bin_dev0, MON_BIN_MAX_MINOR);\nerr_dev:\n\tclass_destroy(mon_bin_class);\nerr_class:\n\treturn rc;\n}\n\nvoid mon_bin_exit(void)\n{\n\tcdev_del(&mon_bin_cdev);\n\tunregister_chrdev_region(mon_bin_dev0, MON_BIN_MAX_MINOR);\n\tclass_destroy(mon_bin_class);\n}\n"], "filenames": ["drivers/usb/mon/mon_bin.c"], "buggy_code_start_loc": [1270], "buggy_code_end_loc": [1270], "fixing_code_start_loc": [1271], "fixing_code_end_loc": [1276], "type": "CWE-787", "message": "drivers/usb/mon/mon_bin.c in usbmon in the Linux kernel before 5.19.15 and 6.x before 6.0.1 allows a user-space client to corrupt the monitor's internal memory.", "other": {"cve": {"id": "CVE-2022-43750", "sourceIdentifier": "cve@mitre.org", "published": "2022-10-26T04:15:13.990", "lastModified": "2023-02-14T21:38:48.193", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "drivers/usb/mon/mon_bin.c in usbmon in the Linux kernel before 5.19.15 and 6.x before 6.0.1 allows a user-space client to corrupt the monitor's internal memory."}, {"lang": "es", "value": "El archivo drivers/usb/mon/mon_bin.c en usbmon en el kernel de Linux versiones anteriores a 5.19.15 y versiones 6.x anteriores a 6.0.1, permite que un cliente del espacio de usuario corrompa la memoria interna del monitor"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "HIGH", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 6.7, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 0.8, "impactScore": 5.9}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.21", "versionEndExcluding": "4.9.331", "matchCriteriaId": "96B230C6-4735-4F30-AD60-78D36C5A0962"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.10", "versionEndExcluding": "4.14.296", "matchCriteriaId": "1927ABC6-E0D2-478F-B103-B982A42D1158"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.15", "versionEndExcluding": "4.19.262", "matchCriteriaId": "D6B62970-1FAD-4ED6-930A-23E26A8D2E08"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.20", "versionEndExcluding": "5.4.218", "matchCriteriaId": "ED2FAD62-84D0-451F-9F4D-66173BBD59E2"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "5.5", "versionEndExcluding": "5.10.148", "matchCriteriaId": "A125CF4C-603D-4ED4-AE18-CFC7C8D5CCF1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "5.11", "versionEndExcluding": "5.15.73", "matchCriteriaId": "BD909509-E426-404A-A91F-525301A0E517"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "5.16", "versionEndExcluding": "5.19.15", "matchCriteriaId": "80E4DFA6-D363-43C6-A3B1-88F31DA1EE0C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "6.0", "versionEndExcluding": "6.0.1", "matchCriteriaId": "1E5DDBBA-1F3E-4276-B4F9-59FD799BC0F7"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:10.0:*:*:*:*:*:*:*", "matchCriteriaId": "07B237A9-69A3-4A9C-9DA0-4E06BD37AE73"}]}]}], "references": [{"url": "https://cdn.kernel.org/pub/linux/kernel/v5.x/ChangeLog-5.19.15", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "https://cdn.kernel.org/pub/linux/kernel/v6.x/ChangeLog-6.0.1", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=a659daf63d16aa883be42f3f34ff84235c302198", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/a659daf63d16aa883be42f3f34ff84235c302198", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2022/11/msg00001.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2022/12/msg00034.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/a659daf63d16aa883be42f3f34ff84235c302198"}}
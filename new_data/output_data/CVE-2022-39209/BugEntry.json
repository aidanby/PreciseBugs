{"buggy_code": ["cmake_minimum_required(VERSION 3.0)\nproject(cmark-gfm)\n\nset(PROJECT_VERSION_MAJOR 0)\nset(PROJECT_VERSION_MINOR 29)\nset(PROJECT_VERSION_PATCH 0)\nset(PROJECT_VERSION_GFM 5)\nset(PROJECT_VERSION ${PROJECT_VERSION_MAJOR}.${PROJECT_VERSION_MINOR}.${PROJECT_VERSION_PATCH}.gfm.${PROJECT_VERSION_GFM})\n\ninclude(\"FindAsan.cmake\")\ninclude(\"CheckFileOffsetBits.cmake\")\n\nif(\"${CMAKE_SOURCE_DIR}\" STREQUAL \"${CMAKE_BINARY_DIR}\")\n    message(FATAL_ERROR \"Do not build in-source.\\nPlease remove CMakeCache.txt and the CMakeFiles/ directory.\\nThen: mkdir build ; cd build ; cmake .. ; make\")\nendif()\n\noption(CMARK_TESTS \"Build cmark-gfm tests and enable testing\" ON)\noption(CMARK_STATIC \"Build static libcmark-gfm library\" ON)\noption(CMARK_SHARED \"Build shared libcmark-gfm library\" ON)\noption(CMARK_LIB_FUZZER \"Build libFuzzer fuzzing harness\" OFF)\n\nadd_subdirectory(src)\nadd_subdirectory(extensions)\nif(CMARK_TESTS AND (CMARK_SHARED OR CMARK_STATIC))\n  add_subdirectory(api_test)\nendif()\nadd_subdirectory(man)\nif(CMARK_TESTS)\n  enable_testing()\n  add_subdirectory(test testdir)\nendif()\n\nif(NOT CMAKE_BUILD_TYPE)\n  set(CMAKE_BUILD_TYPE \"Release\" CACHE STRING\n  \"Choose the type of build, options are: Debug Profile Release Asan Ubsan.\" FORCE)\nendif(NOT CMAKE_BUILD_TYPE)\n", "[0.29.0.gfm.5]\n  * Added xmpp: and mailto: support to the autolink extension\n\n[0.29.0.gfm.4]\n  * Remove `source` from list of HTML blocks\n\n[0.29.0.gfm.3]\n  * Fixed heap memory corruption vulnerabiliy via integer overflow per https://github.com/github/cmark-gfm/security/advisories/GHSA-mc3g-88wq-6f4x\n\n[0.29.0.gfm.2]\n  * Fixed issues with footnote rendering when used with the autolinker (#121),\n    and when footnotes are adjacent (#139).\n  * We now allow footnotes to be referenced from inside a footnote definition,\n    we use the footnote label for the fnref href text when rendering html, and\n    we insert multiple backrefs when a footnote has been referenced multiple\n    times (#229, #230)\n  * We added new data- attributes to footnote html rendering to make them\n    easier to style (#234)\n\n[0.29.0.gfm.1]\n\n  * Fixed denial of service bug in GFM's table extension\n    per https://github.com/github/cmark-gfm/security/advisories/GHSA-7gc6-9qr5-hc85\n\n[0.29.0]\n\n  * Update spec to 0.29.\n  * Make rendering safe by default (#239, #273).\n    Adds `CMARK_OPT_UNSAFE` and make `CMARK_OPT_SAFE` a no-op (for API\n    compatibility).  The new default behavior is to suppress raw HTML and\n    potentially dangerous links.  The `CMARK_OPT_UNSAFE` option has to be set\n    explicitly to prevent this.\n    **NOTE:** This change will require modifications in bindings for cmark\n    and in most libraries and programs that use cmark.\n    Borrows heavily from @kivikakk's patch in github/cmark-gfm#123.\n  * Add sourcepos info for inlines (Yuki Izumi).\n  * Disallow more than 32 nested balanced parens in a link (Yuki Izumi).\n  * Resolve link references before creating setext header.\n    A setext header line after a link reference should not\n    create a header, according to the spec.\n  * commonmark renderer: improve escaping.\n    URL-escape special characters when escape mode is URL, and not otherwise.\n    Entity-escape control characters (< 0x20) in non-literal escape modes.\n  * render:  only emit actual newline when escape mode is LITERAL.\n    For markdown content, e.g., in other contexts we want some\n    kind of escaping, not a literal newline.\n  * Update code span normalization to conform with spec change.\n  * Allow empty `<>` link destination in reference link.\n  * Remove leftover includes of `memory.h` (#290).\n  * A link destination can't start with `<` unless it is\n    an angle-bracket link that also ends with `>` (#289).\n    (If your URL really starts with `<`, URL-escape it.)\n  * Allow internal delimiter runs to match if both have lengths that are\n    multiples of 3.  See commonmark/commonmark#528.\n  * Include `references.h` in `parser.h` (#287).\n  * Fix `[link](<foo\\>)`.\n  * Use hand-rolled scanner for thematic break (see #284).\n    Keep track of the last position where a thematic break\n    failed to match on a line, to avoid rescanning unnecessarily.\n  * Rename `ends_with_blank_line` with `S_` prefix.\n  * Add `CMARK_NODE__LAST_LINE_CHECKED` flag (#284).\n    Use this to avoid unnecessary recursion in `ends_with_blank_line`.\n  * In `ends_with_blank_line`, call `S_set_last_line_blank`\n    to avoid unnecessary repetition (#284).  Once we settle whether a list\n    item ends in a blank line, we don't need to revisit this in considering\n    parent list items.\n  * Disallow unescaped `(` in parenthesized link title.\n  * Copy line/col info straight from opener/closer (Ashe Connor).\n    We can't rely on anything in `subj` since it's been modified while parsing\n    the subject and could represent line info from a future line.  This is\n    simple and works.\n  * `render.c`: reset `last_breakable` after cr.  Fixes jgm/pandoc#5033.\n  * Fix a typo in `houdini_href_e.c` (Felix Yan).\n  * commonmark writer: use `~~~` fences if info string contains backtick.\n    This is needed for round-trip tests.\n  * Update scanners for new info string rules.\n  * Add XSLT stylesheet to convert cmark XML back to Commonmark\n    (Nick Wellnhofer, #264).  Initial version of an XSLT stylesheet that\n    converts the XML format produced by `cmark -t xml` back to Commonmark.\n  * Check for whitespace before reference title (#263).\n  * Bump CMake to version 3 (Jonathan M\u00fcller).\n  * Build: Remove deprecated call to `add_compiler_export_flags()`\n    (Jonathan M\u00fcller).  It is deprecated in CMake 3.0, the replacement is to\n    set the `CXX_VISIBILITY_PRESET` (or in our case `C_VISIBILITY_PRESET`) and\n    `VISIBILITY_INLINES_HIDDEN` properties of the target.  We're already\n    setting them by setting the CMake variables anyway, so the call can be\n    removed.\n  * Build: only attempt to install MSVC system libraries on Windows\n    (Saleem Abdulrasool).  Newer versions of CMake attempt to query the system\n    for information about the VS 2017 installation.  Unfortunately, this query\n    fails on non-Windows systems when cross-compiling:\n    `cmake_host_system_information does not recognize <key> VS_15_DIR`.\n    CMake will not find these system libraries on non-Windows hosts anyways,\n    and we were silencing the warnings, so simply omit the installation when\n    cross-compiling to Windows.\n  * Simplify code normalization, in line with spec change.\n  * Implement code span spec changes.  These affect both parsing and writing\n    commonmark.\n  * Add link parsing corner cases to regressions (Ashe Connor).\n  * Add `xml:space=\"preserve\"` in XML output when appropriate\n    (Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy).\n    (For text, code, code_block, html_inline and html_block tags.)\n  * Removed meta from list of block tags.  Added regression test.\n    See commonmark/CommonMark#527.\n  * `entity_tests.py` - omit noisy success output.\n  * `pathological_tests.py`: make tests run faster.\n    Commented out the (already ignored) \"many references\" test, which\n    times out.  Reduced the iterations for a couple other tests.\n  * `pathological_tests.py`: added test for deeply nested lists.\n  * Optimize `S_find_first_nonspace`.  We were needlessly redoing things we'd\n    already done.  Now we skip the work if the first nonspace is greater than\n    the current offset.  This fixes pathological slowdown with deeply nested\n    lists (#255).  For N = 3000, the time goes from over 17s to about 0.7s.\n    Thanks to Martin Mitas for diagnosing the problem.\n  * Allow spaces in link destination delimited with pointy brackets.\n  * Adjust max length of decimal/numeric entities.\n    See commonmark/CommonMark#487.\n  * Fix inline raw HTML parsing.\n    This fixes a recently added failing spec test case.  Previously spaces\n    were being allowed in unquoted attribute values; no we forbid them.\n  * Don't allow list markers to be indented >= 4 spaces.\n    See commonmark/CommonMark#497.\n  * Check for empty buffer when rendering (Phil Turnbull).\n    For empty documents, `->size` is zero so\n    `renderer.buffer->ptr[renderer.buffer->size - 1]` will cause an\n    out-of-bounds read. Empty buffers always point to the global\n    `cmark_strbuf__initbuf` buffer so we read `cmark_strbuf__initbuf[-1]`.\n  * Also run API tests with `CMARK_SHARED=OFF` (Nick Wellnhofer).\n  * Rename roundtrip and entity tests (Nick Wellnhofer).\n    Rename the tests to reflect that they use the library, not the\n    executable.\n  * Generate export header for static-only build (#247, Nick Wellnhofer).\n  * Fuzz width parameter too (Phil Turnbull).  Allow the `width` parameter to\n    be generated too so we get better fuzz-coverage.\n  * Don't discard empty fuzz test-cases (Phil Turnbull).  We currently discard\n    fuzz test-cases that are empty but empty inputs are valid markdown. This\n    improves the fuzzing coverage slightly.\n  * Fixed exit code for pathological tests.\n  * Add allowed failures to `pathological_tests.py`.\n    This allows us to include tests that we don't yet know how to pass.\n  * Add timeout to `pathological_tests.py`.\n    Tests must complete in 8 seconds or are errors.\n  * Add more pathological tests (Martin Mitas).\n    These tests target the issues #214, #218, #220.\n  * Use pledge(2) on OpenBSD (Ashe Connor).\n  * Update the Racket wrapper (Eli Barzilay).\n  * Makefile: For afl target, don't build tests.\n\n[0.28.3.gfm.20]\n\n  * Add tasklist extension implementation (Watson1978, #94).\n\n[0.28.3.gfm.19]\n\n  * Prevent out-of-bound memory access in strikethrough matcher (Xavier D\u00e9coret, #124).\n  * Limit recursion in autolink extension (Xavier D\u00e9coret, #125).\n  * Add plaintext rendering for footnotes (Xavier D\u00e9coret, #126).\n\n[0.28.3.gfm.18]\n\n  * Match strikethrough more strictly (#120).\n  * Default to safe operation (#123).\n\n[0.28.3.gfm.17]\n\n  * Allow extension to provide opaque allocation function (Nicol\u00e1s Ojeda\n    B\u00e4r, #89).\n  * Upstream optimisations and fixes.\n  * Extensions can add custom XML attributes (#116).\n  * Support for GFM extensions in cmark XML to CommonMark XSLT converter\n    (Ma\u00eblle Salmon, #117).\n\n[0.28.3.gfm.16]\n\n  * Do not percent-encode tildes (~) in HTML attribute values (#110).\n  * Fix footnote references in tables (#112).\n\n[0.28.3.gfm.15]\n\n  * Escape non-strikethrough tildes (~) in commonmark output (John MacFarlane, #106).\n  * Cosmetic fix to table HTML output (John MacFarlane, #105).\n  * Use two tildes for strikethrough CommonMark output (John MacFarlane, #104).\n  * Normalised header and define names (#109).\n\n[0.28.3.gfm.14]\n\n  * Added a plaintext renderer for strikethrough nodes.\n\n[0.28.3.gfm.13]\n\n  * Footnote rendering bugfix (Michael Camilleri, #90).\n  * Debian packaging (Joachim Nilsson, #97).\n  * Add CMARK_OPT_STRIKETHROUGH_DOUBLE_TILDE for redcarpet compatibility.\n  * Add CMARK_OPT_TABLE_PREFER_STYLE_ATTRIBUTES (FUJI Goro, #86, #87).\n  * Fix pathological nested list parsing (Phil Turnbull, #95).\n  * Expose more of the extension APIs (Minghao Liu, #96).\n  * Add python example which uses extensions (Greg Stein, #102).\n  * Add CMARK_OPT_FULL_INFO_STRING (Mike Kavouras, #103).\n\n[0.28.3.gfm.12]\n\n  * Various security and bug fixes.\n\n[0.28.3]\n\n  * Include GNUInstallDirs in src/CMakeLists.txt (Nick Wellnhofer, #240).\n    This fixes build problems on some cmake versions (#241).\n\n[0.28.2]\n\n  * Fixed regression in install dest for static library (#238).\n    Due to a mistake, 0.28.1 installed libcmark.a into include/.\n\n[0.28.1]\n\n  * `--smart`: open quote can never occur right after `]` or `)` (#227).\n  * Fix quadratic behavior in `finalize` (Vicent Marti).\n  * Don't use `CMAKE_INSTALL_LIBDIR` to create `libcmark.pc` (#236).\n    This wasn't getting set in processing `libcmark.pc.in`, and we\n    were getting the wrong entry in `libcmark.pc`.\n    The new approach sets an internal `libdir` variable to\n    `lib${LIB_SUFFIX}`.  This variable is used both to set the\n    install destination and in the libcmark.pc.in template.\n  * Update README.md, replace `make astyle` with `make format`\n    (Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy).\n\n[0.28.0.gfm.11]\n\n  * Do not output empty `<tbody>` in table extension.\n\n[0.28.0.gfm.10]\n\n  * Fix denial of service parsing references.\n\n[0.28.0.gfm.9]\n\n  * Fix denial of service parsing nested links (#49).\n\n[0.28.0.gfm.8]\n\n  * Fix bug where autolink would cause `:` to be skipped in emphasis\n    processing.\n\n[0.28.0.gfm.7]\n\n  * Strikethrough characters do not disturb regular emphasis processing.\n\n[0.28.0.gfm.6]\n\n  * Fix inline sourcepos info when inlines span multiple lines, and in\n    ATX headings.\n\n[0.28.0.gfm.5]\n\n  * Latest spec.\n  * Fix a typo in the spec (John Gardner).\n  * Fix quadratic behavior in reference lookups.\n  * Add `core_extensions_ensure_registered`.\n  * Add sourcepos information for inlines.\n\n[0.28.0]\n\n  * Update spec.\n  * Use unsigned integer when shifting (Phil Turnbull).\n    Avoids a UBSAN warning which can be triggered when handling a\n    long sequence of backticks.\n  * Avoid memcpy'ing NULL pointers (Phil Turnbull).\n    Avoids a UBSAN warning when link title is empty string.\n    The length of the memcpy is zero so the NULL pointer is not\n    dereferenced but it is still undefined behaviour.\n  * DeMorgan simplification of some tests in emphasis parser.\n    This also brings the code into closer alignment with the wording\n    of the spec (see jgm/CommonMark#467).\n  * Fixed undefined shift in commonmark writer (#211).\n    Found by google/oss-fuzz:\n    <https://oss-fuzz.com/v2/testcase-detail/4686992824598528>.\n  * latex writer:  fix memory overflow (#210).\n    We got an array overflow in enumerated lists nested more than\n    10 deep with start number =/= 1.\n    This commit also ensures that we don't try to set `enum_` counters\n    that aren't defined by LaTeX (generally up to enumv).\n    Found by google/oss-fuzz:\n    <https://oss-fuzz.com/v2/testcase-detail/5546760854306816>.\n  * Check for NULL pointer in get_link_type (Phil Turnbull).\n    `echo '[](xx:)' | ./build/src/cmark -t latex` gave a\n    segfault.\n  * Move fuzzing dictionary into single file (Phil Turnbull).\n    This allows AFL and libFuzzer to use the same dictionary\n  * Reset bytes after UTF8 proc (Yuki Izumi, #206).\n  * Don't scan past an EOL (Yuki Izumi).\n    The existing negated character classes (`[^\u2026]`) are careful to\n    always include` \\x00` in the characters excluded, but these `.`\n    catch-alls can scan right past the terminating NUL placed\n    at the end of the buffer by `_scan_at`.  As such, buffer\n    overruns can occur.  Also, don't scan past a newline in HTML\n    block end scanners.\n  * Document cases where `get_` functions return `NULL` (#155).\n    E.g. `cmark_node_get_url` on a non-link or image.\n  * Properly handle backslashes in link destinations (#192).\n    Only ascii punctuation characters are escapable, per the spec.\n  * Fixed `cmark_node_get_list_start` to return 0 for bullet lists,\n    as documented (#202).\n  * Use `CMARK_NO_DELIM` for bullet lists (#201).\n  * Fixed code for freeing delimiter stack (#189).\n  * Removed abort outside of conditional (typo).\n  * Removed coercion in error message when aborting from buffer.\n  * Print message to stderr when we abort due to memory demands (#188).\n  * `libcmark.pc`: use `CMAKE_INSTALL_LIBDIR` (#185, Jens Petersen).\n    Needed for multilib distros like Fedora.\n  * Fixed buffer overflow error in `S_parser_feed` (#184).\n    The overflow could occur in the following condition:\n    the buffer ends with `\\r` and the next memory address\n    contains `\\n`.\n  * Update emphasis parsing for spec change.\n    Strong now goes inside Emph rather than the reverse,\n    when both scopes are possible.  The code is much simpler.\n    This also avoids a spec inconsistency that cmark had previously:\n    `***hi***` became Strong (Emph \"hi\")) but\n    `***hi****` became Emph (Strong \"hi\")) \"*\"\n  * Fixes for the LaTeX renderer (#182, Doeme)\n    + Don't double-output the link in latex-rendering.\n    + Prevent ligatures in dashes sensibly when rendering latex.\n      `\\-` is a hyphenation, so it doesn't get displayed at all.\n  * Added a test for NULL when freeing `subj->last_delim`.\n  * Cleaned up setting of lower bounds for openers.\n    We now use a much smaller array.\n  * Fix #178, quadratic parsing bug.  Add pathological test.\n  * Slight improvement of clarity of logic in emph matching.\n  * Fix \"multiple of 3\" determination in emph/strong parsing.\n    We need to store the length of the original delimiter run,\n    instead of using the length of the remaining delimiters\n    after some have been subtracted.  Test case:\n    `a***b* c*`.  Thanks to Raph Levin for reporting.\n  * Correctly initialize chunk in S_process_line (Nick Wellnhofer, #170).\n    The `alloc` member wasn't initialized.  This also allows to add an\n    assertion in `chunk_rtrim` which doesn't work for alloced chunks.\n  * Added 'make newbench'.\n  * `scanners.c` generated with re2c 0.16 (68K smaller!).\n  * `scanners.re` - fixed warnings; use `*` for fallback.\n  * Fixed some warnings in `scanners.re`.\n  * Update CaseFolding to latest (Kevin Wojniak, #168).\n  * Allow balanced nested parens in link destinations (Yuki Izumi, #166)\n  * Allocate enough bytes for backticks array.\n  * Inlines: Ensure that the delimiter stack is freed in subject.\n  * Fixed pathological cases with backtick code spans:\n\n    - Removed recursion in scan_to_closing_backticks\n    - Added an array of pointers to potential backtick closers\n      to subject\n    - This array is used to avoid traversing the subject again\n      when we've already seen all the potential backtick closers.\n    - Added a max bound of 1000 for backtick code span delimiters.\n    - This helps with pathological cases like:\n\n            x\n            x `\n            x ``\n            x ```\n            x ````\n            ...\n\n    - Added pathological test case.\n\n    Thanks to Martin Mit\u00e1\u0161 for identifying the problem and for\n    discussion of solutions.\n  * Remove redundant cmake_minimum_required (#163, @kainjow).\n  * Make shared and static libraries optional (Azamat H. Hackimov).\n    Now you can enable/disable compilation and installation targets for\n    shared and static libraries via `-DCMARK_SHARED=ON/OFF` and\n    `-DCMARK_STATIC=ON/OFF`.\n  * Added support for built-in `${LIB_SUFFIX}` feature (Azamat H.\n    Hackimov).  Replaced `${LIB_INSTALL_DIR}` option with built-in\n    `${LIB_SUFFIX}` for installing for 32/64-bit systems. Normally,\n    CMake will set `${LIB_SUFFIX}` automatically for required enviroment.\n    If you have any issues with it, you can override this option with\n    `-DLIB_SUFFIX=64` or `-DLIB_SUFFIX=\"\"` during configuration.\n  * Add Makefile target and harness to fuzz with libFuzzer (Phil Turnbull).\n    This can be run locally with `make libFuzzer` but the harness will be\n    integrated into oss-fuzz for large-scale fuzzing.\n  * Advertise `--validate-utf8` in usage information\n    (Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy).\n  * Makefile: use warnings with re2c.\n  * README: Add link to Python wrapper, prettify languages list\n    (Pavlo Kapyshin).\n  * README: Add link to cmark-scala (Tim Nieradzik, #196)\n\n[0.27.1.gfm.4]\n\n  * Fix regression with nested parentheses in link targets (#48).\n\n[0.27.1.gfm.3]\n\n  * Various undefined behavior issues fixed (#38, #39, #40).\n  * Tag filter is case-insensitive (#43).\n\n[0.27.1.gfm.2]\n\n  * Fix a number of bugs (reading past end of buffer, undefined behavior.\n  * Add `cmark_syntax_extension_get_private()`. (Jonathan M\u00fcller)\n\n[0.27.1.gfm.1]\n\n  * Add plaintext renderer.\n  * Remove normalize option; we now always normalize the AST.\n  * Add getters for table alignment.\n  * `make install` also installs the extensions static/shared library.\n\n[0.27.1.gfm.0]\n\n  * Add extensions: tagfilter, strikethrough, table, autolink.\n  * Add arena memory implementation.\n  * Add CMARK_OPT_GITHUB_PRE_LANG for fenced code blocks.\n  * Skip UTF-8 BOM on input.\n\n[0.27.1]\n\n  * Set policy for CMP0063 to avoid a warning (#162).\n    Put set_policy under cmake version test.\n    Otherwise we get errors in older versions of cmake.\n  * Use VERSION_GREATER to clean up cmake version test.\n  * Improve afl target.  Use afl-clang by default.  Set default for path.\n\n[0.27.0]\n\n  * Update spec to 0.27.\n  * Fix warnings building with MSVC on Windows (#165, Hugh Bellamy).\n  * Fix `CMAKE_C_VISIBILITY_PRESET` for cmake versions greater than 1.8\n    (e.g. 3.6.2) (#162, Hugh Bellamy).  This lets us build swift-cmark\n    on Windows, using clang-cl.\n  * Fix for non-matching entities (#161, Yuki Izumi).\n  * Modified `print_delimiters` (commented out) so it compiles again.\n  * `make format`: don't change order of includes.\n  * Changed logic for null/eol checks (#160).\n    + only check once for \"not at end of line\"\n    + check for null before we check for newline characters (the\n      previous patch would fail for NULL + CR)\n  * Fix by not advancing past both `\\0` and `\\n` (Yuki Izumi).\n  * Add test for NUL-LF sequence (Yuki Izumi).\n  * Fix memory leak in list parsing (Yuki Izumi).\n  * Use `cmark_mem` to free where used to alloc (Yuki Izumi).\n  * Allow a shortcut link before a `(` (jgm/CommonMark#427).\n  * Allow tabs after setext header line (jgm/commonmark.js#109).\n  * Don't let URI schemes start with spaces.\n  * Fixed h2..h6 HTML blocks (jgm/CommonMark#430).  Added regression test.\n  * Autolink scheme can contain digits (G\u00e1bor Cs\u00e1rdi).\n  * Fix nullary function declarations in cmark.h (Nick Wellnhofer).\n    Fixes strict prototypes warnings.\n  * COPYING: Update file name and remove duplicate section and\n    (Peter Eisentraut).\n  * Fix typo (Pavlo Kapyshin).\n\n[0.26.1]\n\n  * Removed unnecessary typedef that caused build failure on\n    some platforms.\n  * Use `$(MAKE)` in Makefile instead of hardcoded `make` (#146,\n    Tobias Kortkamp).\n\n[0.26.0]\n\n  * Implement spec changes for list items:\n    - Empty list items cannot interrupt paragraphs.\n    - Ordered lists cannot interrupt paragraphs unless\n      they start with 1.\n    - Removed \"two blank lines break out of a list\" feature.\n  * Fix sourcepos for blockquotes (#142).\n  * Fix sourcepos for atx headers (#141).\n  * Fix ATX headers and thematic breaks to allow tabs as well as spaces.\n  * Fix `chunk_set_cstr` with suffix of current string (#139,\n    Nick Wellnhofer).  It's possible that `cmark_chunk_set_cstr` is called\n    with a substring (suffix) of the current string. Delay freeing of the\n    chunk content to handle this case correctly.\n  * Export targets on installation (Jonathan M\u00fcller).\n    This allows using them in other cmake projects.\n  * Fix cmake warning about CMP0048 (Jonathan M\u00fcller).\n  * commonmark renderer:  Ensure we don't have a blank line\n    before a code block when it's the first thing in a list\n    item.\n  * Change parsing of strong/emph in response to spec changes.\n    `process_emphasis` now gets better results in corner cases.\n    The change is this:  when considering matches between an interior\n    delimiter run (one that can open and can close) and another delimiter\n    run, we require that the sum of the lengths of the two delimiter\n    runs mod 3 is not 0.\n  * Ported Robin Stocker's changes to link parsing in jgm/commonmark#101.\n    This uses a separate stack for brackets, instead of putting them on the\n    delimiter stack.  This avoids the need for looking through the delimiter\n    stack for the next bracket.\n  * `cmark_reference_lookup`: Return NULL if reference is null string.\n  * Fix character type detection in `commonmark.c` (Nick Wellnhofer).\n    Fixes test failures on Windows and undefined behavior.\n    - Implement `cmark_isalpha`.\n    - Check for ASCII character before implicit cast to char.\n    - Use internal ctype functions in `commonmark.c`.\n  * Better documentation of memory-freeing responsibilities.\n    in `cmark.h` and its man page (#124).\n  * Use library functions to insert nodes in emphasis/link processing.\n    Previously we did this manually, which introduces many\n    places where errors can creep in.\n  * Correctly handle list marker followed only by spaces.\n    Previously when a list marker was followed only by spaces,\n    cmark expected the following content to be indented by\n    the same number of spaces.  But in this case we should\n    treat the line just like a blank line and set list padding\n    accordingly.\n  * Fixed a number of issues relating to line wrapping.\n    - Extend `CMARK_OPT_NOBREAKS` to all renderers and add `--nobreaks`.\n    - Do not autowrap, regardless of width parameter, if\n      `CMARK_OPT_NOBREAKS` is set.\n    - Fixed `CMARK_OPT_HARDBREAKS` for LaTeX and man renderers.\n    - Ensure that no auto-wrapping occurs if\n      `CMARK_OPT_NOBREAKS` is enabled, or if output is CommonMark and\n      `CMARK_OPT_HARDBREAKS` is enabled.\n  * Set stdin to binary mode on Windows (Nick Wellnhofer, #113).\n    This fixes EOLs when reading from stdin.\n  * Add library option to render softbreaks as spaces (Pavlo\n    Kapyshin).  Note that the `NOBREAKS` option is HTML-only\n  * renderer:  `no_linebreaks` instead of `no_wrap`.\n    We generally want this option to prohibit any breaking\n    in things like headers (not just wraps, but softbreaks).\n  * Coerce `realurllen` to `int`.  This is an alternate solution for pull\n    request #132, which introduced a new warning on the comparison\n    (Benedict Cohen).\n  * Remove unused variable `link_text` (Mathiew Duponchelle).\n  * Improved safety checks in buffer (Vicent Marti).\n  * Add new interface allowing specification of custom memory allocator\n    for nodes (Vicent Marti).  Added `cmark_node_new_with_mem`,\n    `cmark_parser_new_with_mem`, `cmark_mem` to API.\n  * Reduce storage size for nodes by using bit flags instead of\n    separate booleans (Vicent Marti).\n  * config: Add `SSIZE_T` compat for Win32 (Vicent Marti).\n  * cmake: Global handler for OOM situations (Vicent Marti).\n  * Add tests for memory exhaustion (Vicent Marti).\n  * Document in man page and public header that one should use the same\n    memory allocator for every node in a tree.\n  * Fix ctypes in Python FFI calls (Nick Wellnhofer).  This didn't cause\n    problems so far because all types are 32-bit on 32-bit systems and\n    arguments are passed in registers on x86-64.  The wrong types could cause\n    crashes on other platforms, though.\n  * Remove spurious failures in roundtrip tests.  In the commonmark writer we\n    separate lists, and lists and indented code, using a dummy HTML comment.\n    So in evaluating the round-trip tests, we now strip out\n    these comments.  We also normalize HTML to avoid issues\n    having to do with line breaks.\n  * Add 2016 to copyright (Kevin Burke).\n  * Added `to_commonmark` in `test/cmark.py` (for round-trip tests).\n  * `spec_test.py` - parameterize `do_test` with converter.\n  * `spec_tests.py`: exit code is now sum of failures and errors.\n    This ensures that a failing exit code will be given when\n    there are errors, not just with failures.\n  * Fixed round trip tests.  Previously they actually ran\n    `cmark` instead of the round-trip version, since there was a bug in\n    setting the ROUNDTRIP variable (#131).\n  * Added new `roundtrip_tests.py`.  This replaces the old use of simple shell\n    scripts.  It is much faster, and more flexible.  (We will be able\n    to do custom normalization and skip certain tests.)\n  * Fix tests under MinGW (Nick Wellnhofer).\n  * Fix leak in `api_test` (Mathieu Duponchelle).\n  * Makefile: have leakcheck stop on first error instead of going through\n    all the formats and options and probably getting the same output.\n  * Add regression tests (Nick Wellnhofer).\n\n[0.25.2]\n\n  * Open files in binary mode (#113, Nick Wellnhofer).  Now that cmark\n    supports different line endings, files must be openend in binary mode\n    on Windows.\n  * Reset `partially_consumed_tab` on every new line (#114, Nick Wellnhofer).\n  * Handle buffer split across a CRLF line ending (#117).  Adds an internal\n    field to the parser struct to keep track of `last_buffer_ended_with_cr`.\n    Added test.\n\n[0.25.1]\n\n  * Release with no code changes.  cmark version was mistakenly set to\n    0.25.1 in the 0.25.0 release (#112), so this release just\n    ensures that this will cause no confusion later.\n\n[0.25.0]\n\n  * Fixed tabs in indentation (#101).  This patch fixes S_advance_offset\n    so that it doesn't gobble a tab character when advancing less than the\n    width of a tab.\n  * Added partially_consumed_tab to parser.  This keeps track of when we\n    have gotten partway through a tab when consuming initial indentation.\n  * Simplified add_line (only need parser parameter).\n  * Properly handle partially consumed tab.  E.g. in\n\n        - foo\n\n         <TAB><TAB>bar\n\n    we should consume two spaces from the second tab, including two spaces\n    in the code block.\n  * Properly handle tabs with blockquotes and fenced blocks.\n  * Fixed handling of tabs in lists.\n  * Clarified logic in S_advance_offset.\n  * Use an assertion to check for in-range html_block_type.\n    It's a programming error if the type is out of range.\n  * Refactored S_processLines to make the logic easier to\n    understand, and added documentation (Mathieu Duponchelle).\n  * Removed unnecessary check for empty string_content.\n  * Factored out contains_inlines.\n  * Moved the cmake minimum version to top line of CMakeLists.txt\n    (tinysun212).\n  * Fix ctype(3) usage on NetBSD (Kamil Rytarowski).  We need to cast value\n    passed to isspace(3) to unsigned char to explicitly prevent possibly\n    undefined behavior.\n  * Compile in plain C mode with MSVC 12.0 or newer (Nick Wellnhofer).\n    Under MSVC, we used to compile in C++ mode to get some C99 features\n    like mixing declarations and code. With newer MSVC versions, it's\n    possible to build in plain C mode.\n  * Switched from \"inline\" to \"CMARK_INLINE\" (Nick Wellnhofer).\n    Newer MSVC versions support enough of C99 to be able to compile cmark\n    in plain C mode. Only the \"inline\" keyword is still unsupported.\n    We have to use \"__inline\" instead.\n  * Added include guards to config.h\n  * config.h.in - added compatibility snprintf, vsnprintf for MSVC.\n  * Replaced sprintf with snprintf (Marco Benelli).\n  * config.h: include stdio.h for _vscprintf etc.\n  * Include starg.h when needed in config.h.\n  * Removed an unnecessary C99-ism in buffer.c.  This helps compiling on\n    systems like luarocks that don't have all the cmake configuration\n    goodness (thanks to carlmartus).\n  * Don't use variable length arrays (Nick Wellnhofer).\n    They're not supported by MSVC.\n  * Test with multiple MSVC versions under Appveyor (Nick Wellnhofer).\n  * Fix installation dir of man-pages on NetBSD (Kamil Rytarowski).\n  * Fixed typo in cmark.h comments (Chris Eidhof).\n  * Clarify in man page that cmark_node_free frees a node's children too.\n  * Fixed documentation of --width in man page.\n  * Require re2c >= 1.14.2 (#102).\n  * Generated scanners.c with more recent re2c.\n\n[0.24.1]\n\n  * Commonmark renderer:\n    + Use HTML comment, not two blank lines, to separate a list\n      item from a following code block or list.  This makes the\n      output more portable, since the \"two blank lines\" rule is\n      unique to CommonMark.  Also, it allows us to break out of\n      a sublist without breaking out of all levels of nesting.\n    + `is_autolink` - handle case where link has no children,\n      which previously caused a segfault.\n    + Use 4-space indent for bullet lists, for increased portability.\n    + Use 2-space + newline for line break for increased portability (#90).\n    + Improved punctuation escaping.  Previously all `)` and\n      `.` characters after digits were escaped; now they are\n      only escaped if they are genuinely in a position where\n      they'd cause a list item.  This is achieved by changes in\n      `render.c`: (a) `renderer->begin_content` is only set to\n      false after a string of digits at the beginning of the\n      line, and (b) we never break a line before a digit.\n      Also, `begin_content` is properly initialized to true.\n  * Handle NULL root in `consolidate_text_nodes`.\n\n[0.24.0]\n\n  * [API change] Added `cmark_node_replace(oldnode, newnode)`.\n  * Updated spec.txt to 0.24.\n  * Fixed edge case with escaped parens in link destination (#97).\n    This was also checked against the #82 case with asan.\n  * Removed unnecessary check for `fenced` in `cmark_render_html`.\n    It's sufficient to check that the info string is empty.\n    Indeed, those who use the API may well create a code block\n    with an info string without explicitly setting `fenced`.\n  * Updated format of `test/smart_punct.txt`.\n  * Updated `test/spec.txt`, `test/smart_punct.txt`, and\n    `spec_tests.py` to new format.\n  * Fixed `get_containing_block` logic in `src/commonmark.c`.\n    This did not allow for the possibility that a node might have no\n    containing block, causing the commonmark renderer to segfault if\n    passed an inline node with no block parent.\n  * Fixed string representations of `CUSTOM_BLOCK`,\n    `CUSTOM_INLINE`.  The old versions `raw_inline` and\n    `raw_block` were being used, and this led to incorrect xml output.\n  * Use default opts in python sample wrapper.\n  * Allow multiline setext header content, as per spec.\n  * Don't allow spaces in link destinations, even with pointy brackets.\n    Conforms to latest change in spec.\n  * Updated `scheme` scanner according to spec change.  We no longer use\n    a whitelist of valid schemes.\n  * Allow any kind of nodes as children of `CUSTOM_BLOCK` (#96).\n  * `cmark.h`: moved typedefs for iterator into iterator section.\n    This just moves some code around so it makes more sense\n    to read, and in the man page.\n  * Fixed `make_man_page.py` so it includes typedefs again.\n\n[0.23.0]\n\n  * [API change] Added `CUSTOM_BLOCK` and `CUSTOM_INLINE` node types.\n    They are never generated by the parser, and do not correspond\n    to CommonMark elements.  They are designed to be inserted by\n    filters that postprocess the AST.  For example, a filter might\n    convert specially marked code blocks to svg diagrams in HTML\n    and tikz diagrams in LaTeX, passing these through to the renderer\n    as a `CUSTOM_BLOCK`.  These nodes can have children, but they\n    also have literal text to be printed by the renderer \"on enter\"\n    and \"on exit.\" Added `cmark_node_get_on_enter`,\n    `cmark_node_set_on_enter`, `cmark_node_get_on_exit`,\n    `cmark_node_set_on_exit` to API.\n  * [API change] Rename `NODE_HTML` -> `NODE_HTML_BLOCK`,\n    `NODE_INLINE_HTML` -> `NODE_HTML_INLINE`.  Define aliases\n    so the old names still work, for backwards compatibility.\n  * [API change] Rename `CMARK_NODE_HEADER` -> `CMARK_NODE_HEADING`.\n    Note that for backwards compatibility, we have defined aliases:\n    `CMARK_NODE_HEADER` = `CMARK_NODE_HEADING`,\n    `cmark_node_get_header_level` = `cmark_node_get_heading_level`, and\n    `cmark_node_set_header_level` = `cmark_node_set_heading_level`.\n  * [API change] Rename `CMARK_NODE_HRULE` -> `CMARK_NODE_THEMATIC_BREAK`.\n    Defined the former as the latter for backwards compatibility.\n  * Don't allow space between link text and link label in a reference link\n    (spec change).\n  * Separate parsing and rendering opts in `cmark.h` (#88).\n    This change also changes some of these constants' numerical values,\n    but nothing should change in the API if you use the constants\n    themselves.  It should now be clear in the man page which\n    options affect parsing and which affect rendering.\n  * xml renderer - Added xmlns attribute to document node (jgm/CommonMark#87).\n  * Commonmark renderer:  ensure html blocks surrounded by blanks.\n    Otherwise we get failures of roundtrip tests.\n  * Commonmark renderer: ensure that literal characters get escaped\n    when they're at the beginning of a block, e.g.  `> \\- foo`.\n  * LaTeX renderer - better handling of internal links.\n    Now we render `[foo](#bar)` as `\\protect\\hyperlink{bar}{foo}`.\n  * Check for NULL pointer in _scan_at (#81).\n  * `Makefile.nmake`:  be more robust when cmake is missing.  Previously,\n    when cmake was missing, the build dir would be created anyway, and\n    subsequent attempts (even with cmake) would fail, because cmake would\n    not be run.  Depending on `build/CMakeFiles` is more robust -- this won't\n    be created unless cmake is run.  Partially addresses #85.\n  * Fixed DOCTYPE in xml output.\n  * commonmark.c: fix `size_t` to `int`.  This fixes an MSVC warning\n   \"conversion from 'size_t' to 'int', possible loss of data\" (Kevin Wojniak).\n  * Correct string length in `cmark_parse_document` example (Lee Jeffery).\n  * Fix non-ASCII end-of-line character check (andyuhnak).\n  * Fix \"declaration shadows a local variable\" (Kevin Wojniak).\n  * Install static library (jgm/CommonMark#381).\n  * Fix warnings about dropping const qualifier (Kevin Wojniak).\n  * Use full (unabbreviated) versions of constants (`CMARK_...`).\n  * Removed outdated targets from Makefile.\n  * Removed need for sudo in `make bench`.\n  * Improved benchmark.  Use longer test, since `time` has limited resolution.\n  * Removed `bench.h` and timing calls in `main.c`.\n  * Updated API docs; getters return empty strings if not set\n    rather than NULL, as previously documented.\n  * Added api_tests for custom nodes.\n  * Made roundtrip test part of the test suite run by cmake.\n  * Regenerate `scanners.c` using re2c 0.15.3.\n  * Adjusted scanner for link url.  This fixes a heap buffer overflow (#82).\n  * Added version number (1.0) to XML namespace.  We don't guarantee\n    stability in this until 1.0 is actually released, however.\n  * Removed obsolete `TIMER` macro.\n  * Make `LIB_INSTALL_DIR` configurable (Mathieu Bridon, #79).\n  * Removed out-of-date luajit wrapper.\n  * Use `input`, not `parser->curline` to determine last line length.\n  * Small optimizations in `_scan_at`.\n  * Replaced hard-coded 4 with `TAB_STOP`.\n  * Have `make format` reformat api tests as well.\n  * Added api tests for man, latex, commonmark, and xml renderers (#51).\n  * render.c:  added `begin_content` field.  This is like `begin_line` except\n    that it doesn't trigger production of the prefix.  So it can be set\n    after an initial prefix (say `> `) is printed by the renderer, and\n    consulted in determining whether to escape content that has a special\n    meaning at the beginning of a line.  Used in the commonmark renderer.\n  * Python 3.5 compatibility: don't require HTMLParseError (Zhiming Wang).\n    HTMLParseError was removed in Python 3.5. Since it could never be thrown\n    in Python 3.5+, we simply define a placeholder when HTMLParseError\n    cannot be imported.\n  * Set `convert_charrefs=False` in `normalize.py` (#83).  This defeats the\n    new default as of python 3.5, and allows the script to work with python\n    3.5.\n\n[0.22.0]\n\n  * Removed `pre` from blocktags scanner. `pre` is handled separately\n    in rule 1 and needn't be handled in rule 6.\n  * Added `iframe` to list of blocktags, as per spec change.\n  * Fixed bug with `HRULE` after blank line. This previously caused cmark\n    to break out of a list, thinking it had two consecutive blanks.\n  * Check for empty string before trying to look at line ending.\n  * Make sure every line fed to `S_process_line` ends with `\\n` (#72).\n    So `S_process_line` sees only unix style line endings. Ultimately we\n    probably want a better solution, allowing the line ending style of\n    the input file to be preserved. This solution forces output with newlines.\n  * Improved `cmark_strbuf_normalize_whitespace` (#73). Now all characters\n    that satisfy `cmark_isspace` are recognized as whitespace. Previously\n    `\\r` and `\\t` (and others) weren't included.\n  * Treat line ending with EOF as ending with newline (#71).\n  * Fixed `--hardbreaks` with `\\r\\n` line breaks (#68).\n  * Disallow list item starting with multiple blank lines (jgm/CommonMark#332).\n  * Allow tabs before closing `#`s in ATX header\n  * Removed `cmark_strbuf_printf` and `cmark_strbuf_vprintf`.\n    These are no longer needed, and cause complications for MSVC.\n    Also removed `HAVE_VA_COPY` and `HAVE_C99_SNPRINTF` feature tests.\n  * Added option to disable tests (Kevin Wojniak).\n  * Added `CMARK_INLINE` macro.\n  * Removed need to disable MSVC warnings 4267, 4244, 4800\n    (Kevin Wojniak).\n  * Fixed MSVC inline errors when cmark is included in sources that\n    don't have the same set of disabled warnings (Kevin Wojniak).\n  * Fix `FileNotFoundError` errors on tests when cmark is built from\n    another project via `add_subdirectory()` (Kevin Wojniak).\n  * Prefix `utf8proc` functions to avoid conflict with existing library\n    (Kevin Wojniak).\n  * Avoid name clash between Windows `.pdb` files (Nick Wellnhofer).\n  * Improved `smart_punct.txt` (see jgm/commonmark.js#61).\n  * Set `POSITION_INDEPENDENT_CODE` `ON` for static library (see #39).\n  * `make bench`: allow overriding `BENCHFILE`. Previously if you did\n    this, it would clopper `BENCHFILE` with the default bench file.\n  * `make bench`: Use -10 priority with renice.\n  * Improved `make_autolink`. Ensures that title is chunk with empty\n    string rather than NULL, as with other links.\n  * Added `clang-check` target.\n  * Travis: split `roundtrip_test` and `leakcheck` (OGINO Masanori).\n  * Use clang-format, llvm style, for formatting. Reformatted all source files.\n    Added `format` target to Makefile. Removed `astyle` target.\n    Updated `.editorconfig`.\n\n[0.21.0]\n\n  * Updated to version 0.21 of spec.\n  * Added latex renderer (#31). New exported function in API:\n    `cmark_render_latex`. New source file: `src/latex.hs`.\n  * Updates for new HTML block spec. Removed old `html_block_tag` scanner.\n    Added new `html_block_start` and `html_block_start_7`, as well\n    as `html_block_end_n` for n = 1-5. Rewrote block parser for new HTML\n    block spec.\n  * We no longer preprocess tabs to spaces before parsing.\n    Instead, we keep track of both the byte offset and\n    the (virtual) column as we parse block starts.\n    This allows us to handle tabs without converting\n    to spaces first.  Tabs are left as tabs in the output, as\n    per the revised spec.\n  * Removed utf8 validation by default.  We now replace null characters\n    in the line splitting code.\n  * Added `CMARK_OPT_VALIDATE_UTF8` option and command-line option\n    `--validate-utf8`.  This option causes cmark to check for valid\n    UTF-8, replacing invalid sequences with the replacement\n    character, U+FFFD.  Previously this was done by default in\n    connection with tab expansion, but we no longer do it by\n    default with the new tab treatment.  (Many applications will\n    know that the input is valid UTF-8, so validation will not\n    be necessary.)\n  * Added `CMARK_OPT_SAFE` option and `--safe` command-line flag.\n    + Added `CMARK_OPT_SAFE`.  This option disables rendering of raw HTML\n      and potentially dangerous links.\n    + Added `--safe` option in command-line program.\n    + Updated `cmark.3` man page.\n    + Added `scan_dangerous_url` to scanners.\n    + In HTML, suppress rendering of raw HTML and potentially dangerous\n      links if `CMARK_OPT_SAFE`.  Dangerous URLs are those that begin\n      with `javascript:`, `vbscript:`, `file:`, or `data:` (except for\n      `image/png`, `image/gif`, `image/jpeg`, or `image/webp` mime types).\n    + Added `api_test` for `OPT_CMARK_SAFE`.\n    + Rewrote `README.md` on security.\n  * Limit ordered list start to 9 digits, per spec.\n  * Added width parameter to `render_man` (API change).\n  * Extracted common renderer code from latex, man, and commonmark\n    renderers into a separate module, `renderer.[ch]` (#63).  To write a\n    renderer now, you only need to write a character escaping function\n    and a node rendering function.  You pass these to `cmark_render`\n    and it handles all the plumbing (including line wrapping) for you.\n    So far this is an internal module, but we might consider adding\n    it to the API in the future.\n  * commonmark writer:  correctly handle email autolinks.\n  * commonmark writer:  escape `!`.\n  * Fixed soft breaks in commonmark renderer.\n  * Fixed scanner for link url. re2c returns the longest match, so we\n    were getting bad results with `[link](foo\\(and\\(bar\\)\\))`\n    which it would parse as containing a bare `\\` followed by\n    an in-parens chunk ending with the final paren.\n  * Allow non-initial hyphens in html tag names. This allows for\n    custom tags, see jgm/CommonMark#239.\n  * Updated `test/smart_punct.txt`.\n  * Implemented new treatment of hyphens with `--smart`, converting\n    sequences of hyphens to sequences of em and en dashes that contain no\n    hyphens.\n  * HTML renderer:  properly split info on first space char (see\n    jgm/commonmark.js#54).\n  * Changed version variables to functions (#60, Andrius Bentkus).\n    This is easier to access using ffi, since some languages, like C#\n    like to use only function interfaces for accessing library\n    functionality.\n  * `process_emphasis`: Fixed setting lower bound to potential openers.\n    Renamed `potential_openers` -> `openers_bottom`.\n    Renamed `start_delim` -> `stack_bottom`.\n  * Added case for #59 to `pathological_test.py`.\n  * Fixed emphasis/link parsing bug (#59).\n  * Fixed off-by-one error in line splitting routine.\n    This caused certain NULLs not to be replaced.\n  * Don't rtrim in `subject_from_buffer`.  This gives bad results in\n    parsing reference links, where we might have trailing blanks\n    (`finalize` removes the bytes parsed as a reference definition;\n    before this change, some blank bytes might remain on the line).\n    + Added `column` and `first_nonspace_column` fields to `parser`.\n    + Added utility function to advance the offset, computing\n      the virtual column too.  Note that we don't need to deal with\n      UTF-8 here at all.  Only ASCII occurs in block starts.\n    + Significant performance improvement due to the fact that\n      we're not doing UTF-8 validation.\n  * Fixed entity lookup table.  The old one had many errors.\n    The new one is derived from the list in the npm entities package.\n    Since the sequences can now be longer (multi-code-point), we\n    have bumped the length limit from 4 to 8, which also affects\n    `houdini_html_u.c`.  An example of the kind of error that was fixed:\n    `&ngE;` should be rendered as \"\u2267\u0338\" (U+02267 U+00338), but it was\n    being rendered as \"\u2267\" (which is the same as `&gE;`).\n  * Replace gperf-based entity lookup with binary tree lookup.\n    The primary advantage is a big reduction in the size of\n    the compiled library and executable (> 100K).\n    There should be no measurable performance difference in\n    normal documents.  I detected only a slight performance\n    hit in a file containing 1,000,000 entities.\n    + Removed `src/html_unescape.gperf` and `src/html_unescape.h`.\n    + Added `src/entities.h` (generated by `tools/make_entities_h.py`).\n    + Added binary tree lookup functions to `houdini_html_u.c`, and\n      use the data in `src/entities.h`.\n    * Renamed `entities.h` -> `entities.inc`, and\n      `tools/make_entities_h.py` -> `tools/make_entitis_inc.py`.\n  * Fixed cases like\n    ```\n    [ref]: url\n    \"title\" ok\n    ```\n    Here we should parse the first line as a reference.\n  * `inlines.c`:  Added utility functions to skip spaces and line endings.\n  * Fixed backslashes in link destinations that are not part of escapes\n    (jgm/commonmark#45).\n  * `process_line`: Removed \"add newline if line doesn't have one.\"\n    This isn't actually needed.\n  * Small logic fixes and a simplification in `process_emphasis`.\n  * Added more pathological tests:\n    + Many link closers with no openers.\n    + Many link openers with no closers.\n    + Many emph openers with no closers.\n    + Many closers with no openers.\n    + `\"*a_ \" * 20000`.\n  * Fixed `process_emphasis` to handle new pathological cases.\n    Now we have an array of pointers (`potential_openers`),\n    keyed to the delim char.  When we've failed to match a potential opener\n    prior to point X in the delimiter stack, we reset `potential_openers`\n    for that opener type to X, and thus avoid having to look again through\n    all the openers we've already rejected.\n  * `process_inlines`:  remove closers from delim stack when possible.\n    When they have no matching openers and cannot be openers themselves,\n    we can safely remove them.  This helps with a performance case:\n    `\"a_ \" * 20000` (jgm/commonmark.js#43).\n  * Roll utf8proc_charlen into utf8proc_valid (Nick Wellnhofer).\n    Speeds up \"make bench\" by another percent.\n  * `spec_tests.py`: allow `\u2192` for tab in HTML examples.\n  * `normalize.py`:  don't collapse whitespace in pre contexts.\n  * Use utf-8 aware re2c.\n  * Makefile afl target:  removed `-m none`, added `CMARK_OPTS`.\n  * README: added `make afl` instructions.\n  * Limit generated generated `cmark.3` to 72 character line width.\n  * Travis: switched to containerized build system.\n  * Removed `debug.h`. (It uses GNU extensions, and we don't need it anyway.)\n  * Removed sundown from benchmarks, because the reading was anomalous.\n    sundown had an arbitrary 16MB limit on buffers, and the benchmark\n    input exceeded that.  So who knows what we were actually testing?\n    Added hoedown, sundown's successor, which is a better comparison.\n\n[0.20.0]\n\n  * Fixed bug in list item parsing when items indented >= 4 spaces (#52).\n  * Don't allow link labels with no non-whitespace characters\n    (jgm/CommonMark#322).\n  * Fixed multiple issues with numeric entities (#33, Nick Wellnhofer).\n  * Support CR and CRLF line endings (Ben Trask).\n  * Added test for different line endings to `api_test`.\n  * Allow NULL value in string setters (Nick Wellnhofer).  (NULL\n    produces a 0-length string value.)  Internally, URL and\n    title are now stored as `cmark_chunk` rather than `char *`.\n  * Fixed memory leak in `cmark_consolidate_text_nodes` (#32).\n  * Fixed `is_autolink` in the CommonMark renderer (#50).  Previously *any*\n    link with an absolute URL was treated as an autolink.\n  * Cope with broken `snprintf` on Windows (Nick Wellnhofer).  On Windows,\n    `snprintf` returns -1 if the output was truncated. Fall back to\n    Windows-specific `_scprintf`.\n  * Switched length parameter on `cmark_markdown_to_html`,\n    `cmark_parser_feed`, and `cmark_parse_document` from `int`\n    to `size_t` (#53, Nick Wellnhofer).\n  * Use a custom type `bufsize_t` for all string sizes and indices.\n    This allows to switch to 64-bit string buffers by changing a single\n    typedef and a macro definition (Nick Wellnhofer).\n  * Hardened the `strbuf` code, checking for integer overflows and\n    adding range checks (Nick Wellnhofer).\n  * Removed unused function `cmark_strbuf_attach` (Nick Wellnhofer).\n  * Fixed all implicit 64-bit to 32-bit conversions that\n    `-Wshorten-64-to-32` warns about (Nick Wellnhofer).\n  * Added helper function `cmark_strbuf_safe_strlen` that converts\n    from `size_t` to `bufsize_t` and throws an error in case of\n    an overflow (Nick Wellnhofer).\n  * Abort on `strbuf` out of memory errors (Nick Wellnhofer).\n    Previously such errors were not being trapped.  This involves\n    some internal changes to the `buffer` library that do not affect\n    the API.\n  * Factored out `S_find_first_nonspace` in `S_proces_line`.\n    Added fields `offset`, `first_nonspace`, `indent`, and `blank`\n    to `cmark_parser` struct.  This just removes some repetition.\n  * Added Racket Racket (5.3+) wrapper (Eli Barzilay).\n  * Removed `-pg` from Debug build flags (#47).\n  * Added Ubsan build target, to check for undefined behavior.\n  * Improved `make leakcheck`.  We now return an error status if anything\n    in the loop fails.  We now check `--smart` and `--normalize` options.\n  * Removed `wrapper3.py`, made `wrapper.py` work with python 2 and 3.\n    Also improved the wrapper to work with Windows, and to use smart\n    punctuation (as an example).\n  * In `wrapper.rb`, added argument for options.\n  * Revised luajit wrapper.\n  * Added build status badges to README.md.\n  * Added links to go, perl, ruby, R, and Haskell bindings to README.md.\n\n[0.19.0]\n\n  * Fixed `_` emphasis parsing to conform to spec (jgm/CommonMark#317).\n  * Updated `spec.txt`.\n  * Compile static library with `-DCMARK_STATIC_DEFINE` (Nick Wellnhofer).\n  * Suppress warnings about Windows runtime library files (Nick Wellnhofer).\n    Visual Studio Express editions do not include the redistributable files.\n    Set `CMAKE_INSTALL_SYSTEM_RUNTIME_LIBS_NO_WARNINGS` to suppress warnings.\n  * Added appyeyor: Windows continuous integration (`appveyor.yml`).\n  * Use `os.path.join` in `test/cmark.py` for proper cross-platform paths.\n  * Fixed `Makefile.nmake`.\n  * Improved `make afl`:  added `test/afl_dictionary`, increased timeout\n    for hangs.\n  * Improved README with a description of the library's strengths.\n  * Pass-through Unicode non-characters (Nick Wellnhofer).\n    Despite their name, Unicode non-characters are valid code points. They\n    should be passed through by a library like libcmark.\n  * Check return status of `utf8proc_iterate` (#27).\n\n[0.18.3]\n\n  * Include patch level in soname (Nick Wellnhofer). Minor version is\n    tied to spec version, so this allows breaking the ABI between spec\n    releases.\n  * Install compiler-provided system runtime libraries (Changjiang Yang).\n  * Use `strbuf_printf` instead of `snprintf`. `snprintf` is not\n    available on some platforms (Visual Studio 2013 and earlier).\n  * Fixed memory access bug: \"invalid read of size 1\" on input `[link](<>)`.\n\n[0.18.2]\n\n  * Added commonmark renderer: `cmark_render_commonmark`. In addition\n    to options, this takes a `width` parameter.  A value of 0 disables\n    wrapping; a positive value wraps the document to the specified\n    width.  Note that width is automatically set to 0 if the\n    `CMARK_OPT_HARDBREAKS` option is set.\n  * The `cmark` executable now allows `-t commonmark` for output as\n    CommonMark.  A `--width` option has been added to specify wrapping\n    width.\n  * Added `roundtrip_test` Makefile target.  This runs all the spec\n    through the commonmark renderer, and then through the commonmark\n    parser, and compares normalized HTML to the test.  All tests pass\n    with the current parser and renderer, giving us some confidence that\n    the commonmark renderer is sufficiently robust.  Eventually this\n    should be pythonized and put in the cmake test routine.\n  * Removed an unnecessary check in `blocks.c`.  By the time we check\n    for a list start, we've already checked for a horizontal rule, so\n    we don't need to repeat that check here.  Thanks to Robin Stocker for\n    pointing out a similar redundancy in commonmark.js.\n  * Fixed bug in `cmark_strbuf_unescape` (`buffer.c`).  The old function\n    gave incorrect results on input like `\\\\*`, since the next backslash\n    would be treated as escaping the `*` instead of being escaped itself.\n  * `scanners.re`:  added `_scan_scheme`, `scan_scheme`, used in the\n    commonmark renderer.\n  * Check for `CMAKE_C_COMPILER` (not `CC_COMPILER`) when setting C flags.\n  * Update code examples in documentation, adding new parser option\n    argument, and using `CMARK_OPT_DEFAULT` (Nick Wellnhofer).\n  * Added options parameter to `cmark_markdown_to_html`.\n  * Removed obsolete reference to `CMARK_NODE_LINK_LABEL`.\n  * `make leakcheck` now checks all output formats.\n  * `test/cmark.py`:  set default options for `markdown_to_html`.\n  * Warn about buggy re2c versions (Nick Wellnhofer).\n\n[0.18.1]\n\n  * Build static version of library in default build (#11).\n  * `cmark.h`:  Add missing argument to `cmark_parser_new` (#12).\n\n[0.18]\n\n  * Switch to 2-clause BSD license, with agreement of contributors.\n  * Added Profile build type, `make prof` target.\n  * Fixed autolink scanner to conform to the spec. Backslash escapes\n    not allowed in autolinks.\n  * Don't rely on strnlen being available (Nick Wellnhofer).\n  * Updated scanners for new whitespace definition.\n  * Added `CMARK_OPT_SMART` and `--smart` option, `smart.c`, `smart.h`.\n  * Added test for `--smart` option.\n  * Fixed segfault with --normalize (closes #7).\n  * Moved normalization step from XML renderer to `cmark_parser_finish`.\n  * Added options parameter to `cmark_parse_document`, `cmark_parse_file`.\n  * Fixed man renderer's escaping for unicode characters.\n  * Don't require python3 to make `cmark.3` man page.\n  * Use ASCII escapes for punctuation characters for portability.\n  * Made `options` an int rather than a long, for consistency.\n  * Packed `cmark_node` struct to fit into 128 bytes.\n    This gives a small performance boost and lowers memory usage.\n  * Repacked `delimiter` struct to avoid hole.\n  * Fixed use-after-free bug, which arose when a paragraph containing\n    only reference links and blank space was finalized (#9).\n    Avoid using `parser->current` in the loop that creates new\n    blocks, since `finalize` in `add_child` may have removed\n    the current parser (if it contains only reference definitions).\n    This isn't a great solution; in the long run we need to rewrite\n    to make the logic clearer and to make it harder to make\n    mistakes like this one.\n  * Added 'Asan' build type. `make asan` will link against ASan; the\n    resulting executable will do checks for memory access issues.\n    Thanks @JordanMilne for the suggestion.\n  * Add Makefile target to fuzz with AFL (Nick Wellnhofer)\n    The variable `$AFL_PATH` must point to the directory containing the AFL\n    binaries. It can be set as an environment variable or passed to make on\n    the command line.\n\n[0.17]\n\n  * Stripped out all JavaScript related code and documentation, moving\n    it to a separate repository (<https://github.com/jgm/commonmark.js>).\n  * Improved Makefile targets, so that `cmake` is run again only when\n    necessary (Nick Wellnhofer).\n  * Added `INSTALL_PREFIX` to the Makefile, allowing installation to a\n    location other than `/usr/local` without invoking `cmake`\n    manually (Nick Wellnhofer).\n  * `make test` now guarantees that the project will\n    be rebuilt before tests are run (Nick Wellnhofer).\n  * Prohibited overriding of some Makefile variables (Nick Wellnhofer).\n  * Provide version number and string, both as macros\n    (`CMARK_VERSION`, `CMARK_VERSION_STRING`) and as symbols\n    (`cmark_version`, `cmark_version_string`) (Nick Wellnhofer).  All of\n    these come from `cmark_version.h`, which is constructed from a\n    template `cmark_version.h.in` and data in `CMakeLists.txt`.\n  * Avoid calling `free` on null pointer.\n  * Added an accessor for an iterator's root node (`cmark_iter_get_root`).\n  * Added user data field for nodes (Nick Wellnhofer).  This is\n    intended mainly for use in bindings for dynamic languages, where\n    it could store a pointer to a target language object (#287).  But\n    it can be used for anything.\n  * Man renderer:  properly escape multiline strings.\n  * Added assertion to raise error if finalize is called on a closed block.\n  * Implemented the new spec rule for emphasis and strong emphasis with `_`.\n  * Moved the check for fence-close with the other checks for end-of-block.\n  * Fixed a bug with loose list detection with items containings\n    fenced code blocks (#285).\n  * Removed recursive algorithm in `ends_with_blank_line` (#286).\n  * Minor code reformatting: renamed parameters.\n\n[0.16]\n\n  * Added xml renderer (XML representation of the CommonMark AST,\n    which is described in `CommonMark.dtd`).\n  * Reduced size of gperf entity table (Nick Wellnhofer).\n  * Reworked iterators to allow deletion of nodes during iteration\n    (Nick Wellnhofer).\n  * Optimized `S_is_leaf`.\n  * Added `cmark_iter_reset` to iterator API.\n  * Added `cmark_consolidate_text_nodes` to API to combine adjacent\n    text nodes.\n  * Added `CMARK_OPT_NORMALIZE` to options (this combines adjacent\n    text nodes).\n  * Added `--normalize` option to command-line program.\n  * Improved regex for HTML comments in inline parsing.\n  * Python is no longer required for a basic build from the\n    repository.\n", "#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n\n#include \"cmark_ctype.h\"\n#include \"config.h\"\n#include \"node.h\"\n#include \"parser.h\"\n#include \"references.h\"\n#include \"cmark-gfm.h\"\n#include \"houdini.h\"\n#include \"utf8.h\"\n#include \"scanners.h\"\n#include \"inlines.h\"\n#include \"syntax_extension.h\"\n\nstatic const char *EMDASH = \"\\xE2\\x80\\x94\";\nstatic const char *ENDASH = \"\\xE2\\x80\\x93\";\nstatic const char *ELLIPSES = \"\\xE2\\x80\\xA6\";\nstatic const char *LEFTDOUBLEQUOTE = \"\\xE2\\x80\\x9C\";\nstatic const char *RIGHTDOUBLEQUOTE = \"\\xE2\\x80\\x9D\";\nstatic const char *LEFTSINGLEQUOTE = \"\\xE2\\x80\\x98\";\nstatic const char *RIGHTSINGLEQUOTE = \"\\xE2\\x80\\x99\";\n\n// Macros for creating various kinds of simple.\n#define make_str(subj, sc, ec, s) make_literal(subj, CMARK_NODE_TEXT, sc, ec, s)\n#define make_code(subj, sc, ec, s) make_literal(subj, CMARK_NODE_CODE, sc, ec, s)\n#define make_raw_html(subj, sc, ec, s) make_literal(subj, CMARK_NODE_HTML_INLINE, sc, ec, s)\n#define make_linebreak(mem) make_simple(mem, CMARK_NODE_LINEBREAK)\n#define make_softbreak(mem) make_simple(mem, CMARK_NODE_SOFTBREAK)\n#define make_emph(mem) make_simple(mem, CMARK_NODE_EMPH)\n#define make_strong(mem) make_simple(mem, CMARK_NODE_STRONG)\n\n#define MAXBACKTICKS 80\n\ntypedef struct bracket {\n  struct bracket *previous;\n  struct delimiter *previous_delimiter;\n  cmark_node *inl_text;\n  bufsize_t position;\n  bool image;\n  bool active;\n  bool bracket_after;\n} bracket;\n\ntypedef struct subject{\n  cmark_mem *mem;\n  cmark_chunk input;\n  int line;\n  bufsize_t pos;\n  int block_offset;\n  int column_offset;\n  cmark_map *refmap;\n  delimiter *last_delim;\n  bracket *last_bracket;\n  bufsize_t backticks[MAXBACKTICKS + 1];\n  bool scanned_for_backticks;\n} subject;\n\n// Extensions may populate this.\nstatic int8_t SKIP_CHARS[256];\n\nstatic CMARK_INLINE bool S_is_line_end_char(char c) {\n  return (c == '\\n' || c == '\\r');\n}\n\nstatic delimiter *S_insert_emph(subject *subj, delimiter *opener,\n                                delimiter *closer);\n\nstatic int parse_inline(cmark_parser *parser, subject *subj, cmark_node *parent, int options);\n\nstatic void subject_from_buf(cmark_mem *mem, int line_number, int block_offset, subject *e,\n                             cmark_chunk *buffer, cmark_map *refmap);\nstatic bufsize_t subject_find_special_char(subject *subj, int options);\n\n// Create an inline with a literal string value.\nstatic CMARK_INLINE cmark_node *make_literal(subject *subj, cmark_node_type t,\n                                             int start_column, int end_column,\n                                             cmark_chunk s) {\n  cmark_node *e = (cmark_node *)subj->mem->calloc(1, sizeof(*e));\n  cmark_strbuf_init(subj->mem, &e->content, 0);\n  e->type = (uint16_t)t;\n  e->as.literal = s;\n  e->start_line = e->end_line = subj->line;\n  // columns are 1 based.\n  e->start_column = start_column + 1 + subj->column_offset + subj->block_offset;\n  e->end_column = end_column + 1 + subj->column_offset + subj->block_offset;\n  return e;\n}\n\n// Create an inline with no value.\nstatic CMARK_INLINE cmark_node *make_simple(cmark_mem *mem, cmark_node_type t) {\n  cmark_node *e = (cmark_node *)mem->calloc(1, sizeof(*e));\n  cmark_strbuf_init(mem, &e->content, 0);\n  e->type = (uint16_t)t;\n  return e;\n}\n\n// Like make_str, but parses entities.\nstatic cmark_node *make_str_with_entities(subject *subj,\n                                          int start_column, int end_column,\n                                          cmark_chunk *content) {\n  cmark_strbuf unescaped = CMARK_BUF_INIT(subj->mem);\n\n  if (houdini_unescape_html(&unescaped, content->data, content->len)) {\n    return make_str(subj, start_column, end_column, cmark_chunk_buf_detach(&unescaped));\n  } else {\n    return make_str(subj, start_column, end_column, *content);\n  }\n}\n\n// Duplicate a chunk by creating a copy of the buffer not by reusing the\n// buffer like cmark_chunk_dup does.\nstatic cmark_chunk chunk_clone(cmark_mem *mem, cmark_chunk *src) {\n  cmark_chunk c;\n  bufsize_t len = src->len;\n\n  c.len = len;\n  c.data = (unsigned char *)mem->calloc(len + 1, 1);\n  c.alloc = 1;\n  if (len)\n    memcpy(c.data, src->data, len);\n  c.data[len] = '\\0';\n\n  return c;\n}\n\nstatic cmark_chunk cmark_clean_autolink(cmark_mem *mem, cmark_chunk *url,\n                                        int is_email) {\n  cmark_strbuf buf = CMARK_BUF_INIT(mem);\n\n  cmark_chunk_trim(url);\n\n  if (url->len == 0) {\n    cmark_chunk result = CMARK_CHUNK_EMPTY;\n    return result;\n  }\n\n  if (is_email)\n    cmark_strbuf_puts(&buf, \"mailto:\");\n\n  houdini_unescape_html_f(&buf, url->data, url->len);\n  return cmark_chunk_buf_detach(&buf);\n}\n\nstatic CMARK_INLINE cmark_node *make_autolink(subject *subj,\n                                              int start_column, int end_column,\n                                              cmark_chunk url, int is_email) {\n  cmark_node *link = make_simple(subj->mem, CMARK_NODE_LINK);\n  link->as.link.url = cmark_clean_autolink(subj->mem, &url, is_email);\n  link->as.link.title = cmark_chunk_literal(\"\");\n  link->start_line = link->end_line = subj->line;\n  link->start_column = start_column + 1;\n  link->end_column = end_column + 1;\n  cmark_node_append_child(link, make_str_with_entities(subj, start_column + 1, end_column - 1, &url));\n  return link;\n}\n\nstatic void subject_from_buf(cmark_mem *mem, int line_number, int block_offset, subject *e,\n                             cmark_chunk *chunk, cmark_map *refmap) {\n  int i;\n  e->mem = mem;\n  e->input = *chunk;\n  e->line = line_number;\n  e->pos = 0;\n  e->block_offset = block_offset;\n  e->column_offset = 0;\n  e->refmap = refmap;\n  e->last_delim = NULL;\n  e->last_bracket = NULL;\n  for (i = 0; i <= MAXBACKTICKS; i++) {\n    e->backticks[i] = 0;\n  }\n  e->scanned_for_backticks = false;\n}\n\nstatic CMARK_INLINE int isbacktick(int c) { return (c == '`'); }\n\nstatic CMARK_INLINE unsigned char peek_char_n(subject *subj, bufsize_t n) {\n  // NULL bytes should have been stripped out by now.  If they're\n  // present, it's a programming error:\n  assert(!(subj->pos + n < subj->input.len && subj->input.data[subj->pos + n] == 0));\n  return (subj->pos + n < subj->input.len) ? subj->input.data[subj->pos + n] : 0;\n}\n\nstatic CMARK_INLINE unsigned char peek_char(subject *subj) {\n  return peek_char_n(subj, 0);\n}\n\nstatic CMARK_INLINE unsigned char peek_at(subject *subj, bufsize_t pos) {\n  return subj->input.data[pos];\n}\n\n// Return true if there are more characters in the subject.\nstatic CMARK_INLINE int is_eof(subject *subj) {\n  return (subj->pos >= subj->input.len);\n}\n\n// Advance the subject.  Doesn't check for eof.\n#define advance(subj) (subj)->pos += 1\n\nstatic CMARK_INLINE bool skip_spaces(subject *subj) {\n  bool skipped = false;\n  while (peek_char(subj) == ' ' || peek_char(subj) == '\\t') {\n    advance(subj);\n    skipped = true;\n  }\n  return skipped;\n}\n\nstatic CMARK_INLINE bool skip_line_end(subject *subj) {\n  bool seen_line_end_char = false;\n  if (peek_char(subj) == '\\r') {\n    advance(subj);\n    seen_line_end_char = true;\n  }\n  if (peek_char(subj) == '\\n') {\n    advance(subj);\n    seen_line_end_char = true;\n  }\n  return seen_line_end_char || is_eof(subj);\n}\n\n// Take characters while a predicate holds, and return a string.\nstatic CMARK_INLINE cmark_chunk take_while(subject *subj, int (*f)(int)) {\n  unsigned char c;\n  bufsize_t startpos = subj->pos;\n  bufsize_t len = 0;\n\n  while ((c = peek_char(subj)) && (*f)(c)) {\n    advance(subj);\n    len++;\n  }\n\n  return cmark_chunk_dup(&subj->input, startpos, len);\n}\n\n// Return the number of newlines in a given span of text in a subject.  If\n// the number is greater than zero, also return the number of characters\n// between the last newline and the end of the span in `since_newline`.\nstatic int count_newlines(subject *subj, bufsize_t from, bufsize_t len, int *since_newline) {\n  int nls = 0;\n  int since_nl = 0;\n\n  while (len--) {\n    if (subj->input.data[from++] == '\\n') {\n      ++nls;\n      since_nl = 0;\n    } else {\n      ++since_nl;\n    }\n  }\n\n  if (!nls)\n    return 0;\n\n  *since_newline = since_nl;\n  return nls;\n}\n\n// Adjust `node`'s `end_line`, `end_column`, and `subj`'s `line` and\n// `column_offset` according to the number of newlines in a just-matched span\n// of text in `subj`.\nstatic void adjust_subj_node_newlines(subject *subj, cmark_node *node, int matchlen, int extra, int options) {\n  if (!(options & CMARK_OPT_SOURCEPOS)) {\n    return;\n  }\n\n  int since_newline;\n  int newlines = count_newlines(subj, subj->pos - matchlen - extra, matchlen, &since_newline);\n  if (newlines) {\n    subj->line += newlines;\n    node->end_line += newlines;\n    node->end_column = since_newline;\n    subj->column_offset = -subj->pos + since_newline + extra;\n  }\n}\n\n// Try to process a backtick code span that began with a\n// span of ticks of length openticklength length (already\n// parsed).  Return 0 if you don't find matching closing\n// backticks, otherwise return the position in the subject\n// after the closing backticks.\nstatic bufsize_t scan_to_closing_backticks(subject *subj,\n                                           bufsize_t openticklength) {\n\n  bool found = false;\n  if (openticklength > MAXBACKTICKS) {\n    // we limit backtick string length because of the array subj->backticks:\n    return 0;\n  }\n  if (subj->scanned_for_backticks &&\n      subj->backticks[openticklength] <= subj->pos) {\n    // return if we already know there's no closer\n    return 0;\n  }\n  while (!found) {\n    // read non backticks\n    unsigned char c;\n    while ((c = peek_char(subj)) && c != '`') {\n      advance(subj);\n    }\n    if (is_eof(subj)) {\n      break;\n    }\n    bufsize_t numticks = 0;\n    while (peek_char(subj) == '`') {\n      advance(subj);\n      numticks++;\n    }\n    // store position of ender\n    if (numticks <= MAXBACKTICKS) {\n      subj->backticks[numticks] = subj->pos - numticks;\n    }\n    if (numticks == openticklength) {\n      return (subj->pos);\n    }\n  }\n  // got through whole input without finding closer\n  subj->scanned_for_backticks = true;\n  return 0;\n}\n\n// Destructively modify string, converting newlines to\n// spaces, then removing a single leading + trailing space,\n// unless the code span consists entirely of space characters.\nstatic void S_normalize_code(cmark_strbuf *s) {\n  bufsize_t r, w;\n  bool contains_nonspace = false;\n\n  for (r = 0, w = 0; r < s->size; ++r) {\n    switch (s->ptr[r]) {\n    case '\\r':\n      if (s->ptr[r + 1] != '\\n') {\n\ts->ptr[w++] = ' ';\n      }\n      break;\n    case '\\n':\n      s->ptr[w++] = ' ';\n      break;\n    default:\n      s->ptr[w++] = s->ptr[r];\n    }\n    if (s->ptr[r] != ' ') {\n      contains_nonspace = true;\n    }\n  }\n\n  // begins and ends with space?\n  if (contains_nonspace &&\n      s->ptr[0] == ' ' && s->ptr[w - 1] == ' ') {\n    cmark_strbuf_drop(s, 1);\n    cmark_strbuf_truncate(s, w - 2);\n  } else {\n    cmark_strbuf_truncate(s, w);\n  }\n\n}\n\n\n// Parse backtick code section or raw backticks, return an inline.\n// Assumes that the subject has a backtick at the current position.\nstatic cmark_node *handle_backticks(subject *subj, int options) {\n  cmark_chunk openticks = take_while(subj, isbacktick);\n  bufsize_t startpos = subj->pos;\n  bufsize_t endpos = scan_to_closing_backticks(subj, openticks.len);\n\n  if (endpos == 0) {      // not found\n    subj->pos = startpos; // rewind\n    return make_str(subj, subj->pos, subj->pos, openticks);\n  } else {\n    cmark_strbuf buf = CMARK_BUF_INIT(subj->mem);\n\n    cmark_strbuf_set(&buf, subj->input.data + startpos,\n                     endpos - startpos - openticks.len);\n    S_normalize_code(&buf);\n\n    cmark_node *node = make_code(subj, startpos, endpos - openticks.len - 1, cmark_chunk_buf_detach(&buf));\n    adjust_subj_node_newlines(subj, node, endpos - startpos, openticks.len, options);\n    return node;\n  }\n}\n\n\n// Scan ***, **, or * and return number scanned, or 0.\n// Advances position.\nstatic int scan_delims(subject *subj, unsigned char c, bool *can_open,\n                       bool *can_close) {\n  int numdelims = 0;\n  bufsize_t before_char_pos, after_char_pos;\n  int32_t after_char = 0;\n  int32_t before_char = 0;\n  int len;\n  bool left_flanking, right_flanking;\n\n  if (subj->pos == 0) {\n    before_char = 10;\n  } else {\n    before_char_pos = subj->pos - 1;\n    // walk back to the beginning of the UTF_8 sequence:\n    while ((peek_at(subj, before_char_pos) >> 6 == 2 || SKIP_CHARS[peek_at(subj, before_char_pos)]) && before_char_pos > 0) {\n      before_char_pos -= 1;\n    }\n    len = cmark_utf8proc_iterate(subj->input.data + before_char_pos,\n                                 subj->pos - before_char_pos, &before_char);\n    if (len == -1 || (before_char < 256 && SKIP_CHARS[(unsigned char) before_char])) {\n      before_char = 10;\n    }\n  }\n\n  if (c == '\\'' || c == '\"') {\n    numdelims++;\n    advance(subj); // limit to 1 delim for quotes\n  } else {\n    while (peek_char(subj) == c) {\n      numdelims++;\n      advance(subj);\n    }\n  }\n\n  if (subj->pos == subj->input.len) {\n    after_char = 10;\n  } else {\n    after_char_pos = subj->pos;\n    while (SKIP_CHARS[peek_at(subj, after_char_pos)] && after_char_pos < subj->input.len) {\n      after_char_pos += 1;\n    }\n    len = cmark_utf8proc_iterate(subj->input.data + after_char_pos,\n                                 subj->input.len - after_char_pos, &after_char);\n    if (len == -1 || (after_char < 256 && SKIP_CHARS[(unsigned char) after_char])) {\n    after_char = 10;\n  }\n  }\n\n  left_flanking = numdelims > 0 && !cmark_utf8proc_is_space(after_char) &&\n                  (!cmark_utf8proc_is_punctuation(after_char) ||\n                   cmark_utf8proc_is_space(before_char) ||\n                   cmark_utf8proc_is_punctuation(before_char));\n  right_flanking = numdelims > 0 && !cmark_utf8proc_is_space(before_char) &&\n                   (!cmark_utf8proc_is_punctuation(before_char) ||\n                    cmark_utf8proc_is_space(after_char) ||\n                    cmark_utf8proc_is_punctuation(after_char));\n  if (c == '_') {\n    *can_open = left_flanking &&\n                (!right_flanking || cmark_utf8proc_is_punctuation(before_char));\n    *can_close = right_flanking &&\n                 (!left_flanking || cmark_utf8proc_is_punctuation(after_char));\n  } else if (c == '\\'' || c == '\"') {\n    *can_open = left_flanking && !right_flanking &&\n\t         before_char != ']' && before_char != ')';\n    *can_close = right_flanking;\n  } else {\n    *can_open = left_flanking;\n    *can_close = right_flanking;\n  }\n  return numdelims;\n}\n\n/*\nstatic void print_delimiters(subject *subj)\n{\n        delimiter *delim;\n        delim = subj->last_delim;\n        while (delim != NULL) {\n                printf(\"Item at stack pos %p: %d %d %d next(%p) prev(%p)\\n\",\n                       (void*)delim, delim->delim_char,\n                       delim->can_open, delim->can_close,\n                       (void*)delim->next, (void*)delim->previous);\n                delim = delim->previous;\n        }\n}\n*/\n\nstatic void remove_delimiter(subject *subj, delimiter *delim) {\n  if (delim == NULL)\n    return;\n  if (delim->next == NULL) {\n    // end of list:\n    assert(delim == subj->last_delim);\n    subj->last_delim = delim->previous;\n  } else {\n    delim->next->previous = delim->previous;\n  }\n  if (delim->previous != NULL) {\n    delim->previous->next = delim->next;\n  }\n  subj->mem->free(delim);\n}\n\nstatic void pop_bracket(subject *subj) {\n  bracket *b;\n  if (subj->last_bracket == NULL)\n    return;\n  b = subj->last_bracket;\n  subj->last_bracket = subj->last_bracket->previous;\n  subj->mem->free(b);\n}\n\nstatic void push_delimiter(subject *subj, unsigned char c, bool can_open,\n                           bool can_close, cmark_node *inl_text) {\n  delimiter *delim = (delimiter *)subj->mem->calloc(1, sizeof(delimiter));\n  delim->delim_char = c;\n  delim->can_open = can_open;\n  delim->can_close = can_close;\n  delim->inl_text = inl_text;\n  delim->length = inl_text->as.literal.len;\n  delim->previous = subj->last_delim;\n  delim->next = NULL;\n  if (delim->previous != NULL) {\n    delim->previous->next = delim;\n  }\n  subj->last_delim = delim;\n}\n\nstatic void push_bracket(subject *subj, bool image, cmark_node *inl_text) {\n  bracket *b = (bracket *)subj->mem->calloc(1, sizeof(bracket));\n  if (subj->last_bracket != NULL) {\n    subj->last_bracket->bracket_after = true;\n  }\n  b->image = image;\n  b->active = true;\n  b->inl_text = inl_text;\n  b->previous = subj->last_bracket;\n  b->previous_delimiter = subj->last_delim;\n  b->position = subj->pos;\n  b->bracket_after = false;\n  subj->last_bracket = b;\n}\n\n// Assumes the subject has a c at the current position.\nstatic cmark_node *handle_delim(subject *subj, unsigned char c, bool smart) {\n  bufsize_t numdelims;\n  cmark_node *inl_text;\n  bool can_open, can_close;\n  cmark_chunk contents;\n\n  numdelims = scan_delims(subj, c, &can_open, &can_close);\n\n  if (c == '\\'' && smart) {\n    contents = cmark_chunk_literal(RIGHTSINGLEQUOTE);\n  } else if (c == '\"' && smart) {\n    contents =\n        cmark_chunk_literal(can_close ? RIGHTDOUBLEQUOTE : LEFTDOUBLEQUOTE);\n  } else {\n    contents = cmark_chunk_dup(&subj->input, subj->pos - numdelims, numdelims);\n  }\n\n  inl_text = make_str(subj, subj->pos - numdelims, subj->pos - 1, contents);\n\n  if ((can_open || can_close) && (!(c == '\\'' || c == '\"') || smart)) {\n    push_delimiter(subj, c, can_open, can_close, inl_text);\n  }\n\n  return inl_text;\n}\n\n// Assumes we have a hyphen at the current position.\nstatic cmark_node *handle_hyphen(subject *subj, bool smart) {\n  int startpos = subj->pos;\n\n  advance(subj);\n\n  if (!smart || peek_char(subj) != '-') {\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"-\"));\n  }\n\n  while (smart && peek_char(subj) == '-') {\n    advance(subj);\n  }\n\n  int numhyphens = subj->pos - startpos;\n  int en_count = 0;\n  int em_count = 0;\n  int i;\n  cmark_strbuf buf = CMARK_BUF_INIT(subj->mem);\n\n  if (numhyphens % 3 == 0) { // if divisible by 3, use all em dashes\n    em_count = numhyphens / 3;\n  } else if (numhyphens % 2 == 0) { // if divisible by 2, use all en dashes\n    en_count = numhyphens / 2;\n  } else if (numhyphens % 3 == 2) { // use one en dash at end\n    en_count = 1;\n    em_count = (numhyphens - 2) / 3;\n  } else { // use two en dashes at the end\n    en_count = 2;\n    em_count = (numhyphens - 4) / 3;\n  }\n\n  for (i = em_count; i > 0; i--) {\n    cmark_strbuf_puts(&buf, EMDASH);\n  }\n\n  for (i = en_count; i > 0; i--) {\n    cmark_strbuf_puts(&buf, ENDASH);\n  }\n\n  return make_str(subj, startpos, subj->pos - 1, cmark_chunk_buf_detach(&buf));\n}\n\n// Assumes we have a period at the current position.\nstatic cmark_node *handle_period(subject *subj, bool smart) {\n  advance(subj);\n  if (smart && peek_char(subj) == '.') {\n    advance(subj);\n    if (peek_char(subj) == '.') {\n      advance(subj);\n      return make_str(subj, subj->pos - 3, subj->pos - 1, cmark_chunk_literal(ELLIPSES));\n    } else {\n      return make_str(subj, subj->pos - 2, subj->pos - 1, cmark_chunk_literal(\"..\"));\n    }\n  } else {\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\".\"));\n  }\n}\n\nstatic cmark_syntax_extension *get_extension_for_special_char(cmark_parser *parser, unsigned char c) {\n  cmark_llist *tmp_ext;\n\n  for (tmp_ext = parser->inline_syntax_extensions; tmp_ext; tmp_ext=tmp_ext->next) {\n    cmark_syntax_extension *ext = (cmark_syntax_extension *) tmp_ext->data;\n    cmark_llist *tmp_char;\n    for (tmp_char = ext->special_inline_chars; tmp_char; tmp_char=tmp_char->next) {\n      unsigned char tmp_c = (unsigned char)(size_t)tmp_char->data;\n\n      if (tmp_c == c) {\n        return ext;\n      }\n    }\n  }\n\n  return NULL;\n}\n\nstatic void process_emphasis(cmark_parser *parser, subject *subj, delimiter *stack_bottom) {\n  delimiter *closer = subj->last_delim;\n  delimiter *opener;\n  delimiter *old_closer;\n  bool opener_found;\n  delimiter *openers_bottom[3][128];\n  int i;\n\n  // initialize openers_bottom:\n  memset(&openers_bottom, 0, sizeof(openers_bottom));\n  for (i=0; i < 3; i++) {\n    openers_bottom[i]['*'] = stack_bottom;\n    openers_bottom[i]['_'] = stack_bottom;\n    openers_bottom[i]['\\''] = stack_bottom;\n    openers_bottom[i]['\"'] = stack_bottom;\n  }\n\n  // move back to first relevant delim.\n  while (closer != NULL && closer->previous != stack_bottom) {\n    closer = closer->previous;\n  }\n\n  // now move forward, looking for closers, and handling each\n  while (closer != NULL) {\n    cmark_syntax_extension *extension = get_extension_for_special_char(parser, closer->delim_char);\n    if (closer->can_close) {\n      // Now look backwards for first matching opener:\n      opener = closer->previous;\n      opener_found = false;\n      while (opener != NULL && opener != stack_bottom &&\n             opener != openers_bottom[closer->length % 3][closer->delim_char]) {\n        if (opener->can_open && opener->delim_char == closer->delim_char) {\n          // interior closer of size 2 can't match opener of size 1\n          // or of size 1 can't match 2\n          if (!(closer->can_open || opener->can_close) ||\n\t      closer->length % 3 == 0 ||\n              (opener->length + closer->length) % 3 != 0) {\n            opener_found = true;\n            break;\n          }\n        }\n        opener = opener->previous;\n      }\n      old_closer = closer;\n\n      if (extension) {\n        if (opener_found)\n          closer = extension->insert_inline_from_delim(extension, parser, subj, opener, closer);\n        else\n          closer = closer->next;\n      } else if (closer->delim_char == '*' || closer->delim_char == '_') {\n        if (opener_found) {\n          closer = S_insert_emph(subj, opener, closer);\n        } else {\n          closer = closer->next;\n        }\n      } else if (closer->delim_char == '\\'') {\n        cmark_chunk_free(subj->mem, &closer->inl_text->as.literal);\n        closer->inl_text->as.literal = cmark_chunk_literal(RIGHTSINGLEQUOTE);\n        if (opener_found) {\n          cmark_chunk_free(subj->mem, &opener->inl_text->as.literal);\n          opener->inl_text->as.literal = cmark_chunk_literal(LEFTSINGLEQUOTE);\n        }\n        closer = closer->next;\n      } else if (closer->delim_char == '\"') {\n        cmark_chunk_free(subj->mem, &closer->inl_text->as.literal);\n        closer->inl_text->as.literal = cmark_chunk_literal(RIGHTDOUBLEQUOTE);\n        if (opener_found) {\n          cmark_chunk_free(subj->mem, &opener->inl_text->as.literal);\n          opener->inl_text->as.literal = cmark_chunk_literal(LEFTDOUBLEQUOTE);\n        }\n        closer = closer->next;\n      }\n      if (!opener_found) {\n        // set lower bound for future searches for openers\n        openers_bottom[old_closer->length % 3][old_closer->delim_char] =\n\t\told_closer->previous;\n        if (!old_closer->can_open) {\n          // we can remove a closer that can't be an\n          // opener, once we've seen there's no\n          // matching opener:\n          remove_delimiter(subj, old_closer);\n        }\n      }\n    } else {\n      closer = closer->next;\n    }\n  }\n  // free all delimiters in list until stack_bottom:\n  while (subj->last_delim != NULL && subj->last_delim != stack_bottom) {\n    remove_delimiter(subj, subj->last_delim);\n  }\n}\n\nstatic delimiter *S_insert_emph(subject *subj, delimiter *opener,\n                                delimiter *closer) {\n  delimiter *delim, *tmp_delim;\n  bufsize_t use_delims;\n  cmark_node *opener_inl = opener->inl_text;\n  cmark_node *closer_inl = closer->inl_text;\n  bufsize_t opener_num_chars = opener_inl->as.literal.len;\n  bufsize_t closer_num_chars = closer_inl->as.literal.len;\n  cmark_node *tmp, *tmpnext, *emph;\n\n  // calculate the actual number of characters used from this closer\n  use_delims = (closer_num_chars >= 2 && opener_num_chars >= 2) ? 2 : 1;\n\n  // remove used characters from associated inlines.\n  opener_num_chars -= use_delims;\n  closer_num_chars -= use_delims;\n  opener_inl->as.literal.len = opener_num_chars;\n  closer_inl->as.literal.len = closer_num_chars;\n\n  // free delimiters between opener and closer\n  delim = closer->previous;\n  while (delim != NULL && delim != opener) {\n    tmp_delim = delim->previous;\n    remove_delimiter(subj, delim);\n    delim = tmp_delim;\n  }\n\n  // create new emph or strong, and splice it in to our inlines\n  // between the opener and closer\n  emph = use_delims == 1 ? make_emph(subj->mem) : make_strong(subj->mem);\n\n  tmp = opener_inl->next;\n  while (tmp && tmp != closer_inl) {\n    tmpnext = tmp->next;\n    cmark_node_append_child(emph, tmp);\n    tmp = tmpnext;\n  }\n  cmark_node_insert_after(opener_inl, emph);\n\n  emph->start_line = opener_inl->start_line;\n  emph->end_line = closer_inl->end_line;\n  emph->start_column = opener_inl->start_column;\n  emph->end_column = closer_inl->end_column;\n\n  // if opener has 0 characters, remove it and its associated inline\n  if (opener_num_chars == 0) {\n    cmark_node_free(opener_inl);\n    remove_delimiter(subj, opener);\n  }\n\n  // if closer has 0 characters, remove it and its associated inline\n  if (closer_num_chars == 0) {\n    // remove empty closer inline\n    cmark_node_free(closer_inl);\n    // remove closer from list\n    tmp_delim = closer->next;\n    remove_delimiter(subj, closer);\n    closer = tmp_delim;\n  }\n\n  return closer;\n}\n\n// Parse backslash-escape or just a backslash, returning an inline.\nstatic cmark_node *handle_backslash(cmark_parser *parser, subject *subj) {\n  advance(subj);\n  unsigned char nextchar = peek_char(subj);\n  if ((parser->backslash_ispunct ? parser->backslash_ispunct : cmark_ispunct)(nextchar)) {\n    // only ascii symbols and newline can be escaped\n    advance(subj);\n    return make_str(subj, subj->pos - 2, subj->pos - 1, cmark_chunk_dup(&subj->input, subj->pos - 1, 1));\n  } else if (!is_eof(subj) && skip_line_end(subj)) {\n    return make_linebreak(subj->mem);\n  } else {\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"\\\\\"));\n  }\n}\n\n// Parse an entity or a regular \"&\" string.\n// Assumes the subject has an '&' character at the current position.\nstatic cmark_node *handle_entity(subject *subj) {\n  cmark_strbuf ent = CMARK_BUF_INIT(subj->mem);\n  bufsize_t len;\n\n  advance(subj);\n\n  len = houdini_unescape_ent(&ent, subj->input.data + subj->pos,\n                             subj->input.len - subj->pos);\n\n  if (len == 0)\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"&\"));\n\n  subj->pos += len;\n  return make_str(subj, subj->pos - 1 - len, subj->pos - 1, cmark_chunk_buf_detach(&ent));\n}\n\n// Clean a URL: remove surrounding whitespace, and remove \\ that escape\n// punctuation.\ncmark_chunk cmark_clean_url(cmark_mem *mem, cmark_chunk *url) {\n  cmark_strbuf buf = CMARK_BUF_INIT(mem);\n\n  cmark_chunk_trim(url);\n\n  if (url->len == 0) {\n    cmark_chunk result = CMARK_CHUNK_EMPTY;\n    return result;\n  }\n\n  houdini_unescape_html_f(&buf, url->data, url->len);\n\n  cmark_strbuf_unescape(&buf);\n  return cmark_chunk_buf_detach(&buf);\n}\n\ncmark_chunk cmark_clean_title(cmark_mem *mem, cmark_chunk *title) {\n  cmark_strbuf buf = CMARK_BUF_INIT(mem);\n  unsigned char first, last;\n\n  if (title->len == 0) {\n    cmark_chunk result = CMARK_CHUNK_EMPTY;\n    return result;\n  }\n\n  first = title->data[0];\n  last = title->data[title->len - 1];\n\n  // remove surrounding quotes if any:\n  if ((first == '\\'' && last == '\\'') || (first == '(' && last == ')') ||\n      (first == '\"' && last == '\"')) {\n    houdini_unescape_html_f(&buf, title->data + 1, title->len - 2);\n  } else {\n    houdini_unescape_html_f(&buf, title->data, title->len);\n  }\n\n  cmark_strbuf_unescape(&buf);\n  return cmark_chunk_buf_detach(&buf);\n}\n\n// Parse an autolink or HTML tag.\n// Assumes the subject has a '<' character at the current position.\nstatic cmark_node *handle_pointy_brace(subject *subj, int options) {\n  bufsize_t matchlen = 0;\n  cmark_chunk contents;\n\n  advance(subj); // advance past first <\n\n  // first try to match a URL autolink\n  matchlen = scan_autolink_uri(&subj->input, subj->pos);\n  if (matchlen > 0) {\n    contents = cmark_chunk_dup(&subj->input, subj->pos, matchlen - 1);\n    subj->pos += matchlen;\n\n    return make_autolink(subj, subj->pos - 1 - matchlen, subj->pos - 1, contents, 0);\n  }\n\n  // next try to match an email autolink\n  matchlen = scan_autolink_email(&subj->input, subj->pos);\n  if (matchlen > 0) {\n    contents = cmark_chunk_dup(&subj->input, subj->pos, matchlen - 1);\n    subj->pos += matchlen;\n\n    return make_autolink(subj, subj->pos - 1 - matchlen, subj->pos - 1, contents, 1);\n  }\n\n  // finally, try to match an html tag\n  matchlen = scan_html_tag(&subj->input, subj->pos);\n  if (matchlen > 0) {\n    contents = cmark_chunk_dup(&subj->input, subj->pos - 1, matchlen + 1);\n    subj->pos += matchlen;\n    cmark_node *node = make_raw_html(subj, subj->pos - matchlen - 1, subj->pos - 1, contents);\n    adjust_subj_node_newlines(subj, node, matchlen, 1, options);\n    return node;\n  }\n\n  if (options & CMARK_OPT_LIBERAL_HTML_TAG) {\n    matchlen = scan_liberal_html_tag(&subj->input, subj->pos);\n    if (matchlen > 0) {\n      contents = cmark_chunk_dup(&subj->input, subj->pos - 1, matchlen + 1);\n      subj->pos += matchlen;\n      cmark_node *node = make_raw_html(subj, subj->pos - matchlen - 1, subj->pos - 1, contents);\n      adjust_subj_node_newlines(subj, node, matchlen, 1, options);\n      return node;\n    }\n  }\n\n  // if nothing matches, just return the opening <:\n  return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"<\"));\n}\n\n// Parse a link label.  Returns 1 if successful.\n// Note:  unescaped brackets are not allowed in labels.\n// The label begins with `[` and ends with the first `]` character\n// encountered.  Backticks in labels do not start code spans.\nstatic int link_label(subject *subj, cmark_chunk *raw_label) {\n  bufsize_t startpos = subj->pos;\n  int length = 0;\n  unsigned char c;\n\n  // advance past [\n  if (peek_char(subj) == '[') {\n    advance(subj);\n  } else {\n    return 0;\n  }\n\n  while ((c = peek_char(subj)) && c != '[' && c != ']') {\n    if (c == '\\\\') {\n      advance(subj);\n      length++;\n      if (cmark_ispunct(peek_char(subj))) {\n        advance(subj);\n        length++;\n      }\n    } else {\n      advance(subj);\n      length++;\n    }\n    if (length > MAX_LINK_LABEL_LENGTH) {\n      goto noMatch;\n    }\n  }\n\n  if (c == ']') { // match found\n    *raw_label =\n        cmark_chunk_dup(&subj->input, startpos + 1, subj->pos - (startpos + 1));\n    cmark_chunk_trim(raw_label);\n    advance(subj); // advance past ]\n    return 1;\n  }\n\nnoMatch:\n  subj->pos = startpos; // rewind\n  return 0;\n}\n\nstatic bufsize_t manual_scan_link_url_2(cmark_chunk *input, bufsize_t offset,\n                                        cmark_chunk *output) {\n  bufsize_t i = offset;\n  size_t nb_p = 0;\n\n  while (i < input->len) {\n    if (input->data[i] == '\\\\' &&\n        i + 1 < input-> len &&\n        cmark_ispunct(input->data[i+1]))\n      i += 2;\n    else if (input->data[i] == '(') {\n      ++nb_p;\n      ++i;\n      if (nb_p > 32)\n        return -1;\n    } else if (input->data[i] == ')') {\n      if (nb_p == 0)\n        break;\n      --nb_p;\n      ++i;\n    } else if (cmark_isspace(input->data[i])) {\n      if (i == offset) {\n        return -1;\n      }\n      break;\n    } else {\n      ++i;\n    }\n  }\n\n  if (i >= input->len)\n    return -1;\n\n  {\n    cmark_chunk result = {input->data + offset, i - offset, 0};\n    *output = result;\n  }\n  return i - offset;\n}\n\nstatic bufsize_t manual_scan_link_url(cmark_chunk *input, bufsize_t offset,\n                                      cmark_chunk *output) {\n  bufsize_t i = offset;\n\n  if (i < input->len && input->data[i] == '<') {\n    ++i;\n    while (i < input->len) {\n      if (input->data[i] == '>') {\n        ++i;\n        break;\n      } else if (input->data[i] == '\\\\')\n        i += 2;\n      else if (input->data[i] == '\\n' || input->data[i] == '<')\n        return -1;\n      else\n        ++i;\n    }\n  } else {\n    return manual_scan_link_url_2(input, offset, output);\n  }\n\n  if (i >= input->len)\n    return -1;\n\n  {\n    cmark_chunk result = {input->data + offset + 1, i - 2 - offset, 0};\n    *output = result;\n  }\n  return i - offset;\n}\n\n// Return a link, an image, or a literal close bracket.\nstatic cmark_node *handle_close_bracket(cmark_parser *parser, subject *subj) {\n  bufsize_t initial_pos, after_link_text_pos;\n  bufsize_t endurl, starttitle, endtitle, endall;\n  bufsize_t sps, n;\n  cmark_reference *ref = NULL;\n  cmark_chunk url_chunk, title_chunk;\n  cmark_chunk url, title;\n  bracket *opener;\n  cmark_node *inl;\n  cmark_chunk raw_label;\n  int found_label;\n  cmark_node *tmp, *tmpnext;\n  bool is_image;\n\n  advance(subj); // advance past ]\n  initial_pos = subj->pos;\n\n  // get last [ or ![\n  opener = subj->last_bracket;\n\n  if (opener == NULL) {\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"]\"));\n  }\n\n  if (!opener->active) {\n    // take delimiter off stack\n    pop_bracket(subj);\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"]\"));\n  }\n\n  // If we got here, we matched a potential link/image text.\n  // Now we check to see if it's a link/image.\n  is_image = opener->image;\n\n  after_link_text_pos = subj->pos;\n\n  // First, look for an inline link.\n  if (peek_char(subj) == '(' &&\n      ((sps = scan_spacechars(&subj->input, subj->pos + 1)) > -1) &&\n      ((n = manual_scan_link_url(&subj->input, subj->pos + 1 + sps,\n                                 &url_chunk)) > -1)) {\n\n    // try to parse an explicit link:\n    endurl = subj->pos + 1 + sps + n;\n    starttitle = endurl + scan_spacechars(&subj->input, endurl);\n\n    // ensure there are spaces btw url and title\n    endtitle = (starttitle == endurl)\n                   ? starttitle\n                   : starttitle + scan_link_title(&subj->input, starttitle);\n\n    endall = endtitle + scan_spacechars(&subj->input, endtitle);\n\n    if (peek_at(subj, endall) == ')') {\n      subj->pos = endall + 1;\n\n      title_chunk =\n          cmark_chunk_dup(&subj->input, starttitle, endtitle - starttitle);\n      url = cmark_clean_url(subj->mem, &url_chunk);\n      title = cmark_clean_title(subj->mem, &title_chunk);\n      cmark_chunk_free(subj->mem, &url_chunk);\n      cmark_chunk_free(subj->mem, &title_chunk);\n      goto match;\n\n    } else {\n      // it could still be a shortcut reference link\n      subj->pos = after_link_text_pos;\n    }\n  }\n\n  // Next, look for a following [link label] that matches in refmap.\n  // skip spaces\n  raw_label = cmark_chunk_literal(\"\");\n  found_label = link_label(subj, &raw_label);\n  if (!found_label) {\n    // If we have a shortcut reference link, back up\n    // to before the spacse we skipped.\n    subj->pos = initial_pos;\n  }\n\n  if ((!found_label || raw_label.len == 0) && !opener->bracket_after) {\n    cmark_chunk_free(subj->mem, &raw_label);\n    raw_label = cmark_chunk_dup(&subj->input, opener->position,\n                                initial_pos - opener->position - 1);\n    found_label = true;\n  }\n\n  if (found_label) {\n    ref = (cmark_reference *)cmark_map_lookup(subj->refmap, &raw_label);\n    cmark_chunk_free(subj->mem, &raw_label);\n  }\n\n  if (ref != NULL) { // found\n    url = chunk_clone(subj->mem, &ref->url);\n    title = chunk_clone(subj->mem, &ref->title);\n    goto match;\n  } else {\n    goto noMatch;\n  }\n\nnoMatch:\n  // If we fall through to here, it means we didn't match a link.\n  // What if we're a footnote link?\n  if (parser->options & CMARK_OPT_FOOTNOTES &&\n      opener->inl_text->next &&\n      opener->inl_text->next->type == CMARK_NODE_TEXT) {\n\n    cmark_chunk *literal = &opener->inl_text->next->as.literal;\n\n    // look back to the opening '[', and skip ahead to the next character\n    // if we're looking at a '[^' sequence, and there is other text or nodes\n    // after the ^, let's call it a footnote reference.\n    if ((literal->len > 0 && literal->data[0] == '^') && (literal->len > 1 || opener->inl_text->next->next)) {\n\n      // Before we got this far, the `handle_close_bracket` function may have\n      // advanced the current state beyond our footnote's actual closing\n      // bracket, ie if it went looking for a `link_label`.\n      // Let's just rewind the subject's position:\n      subj->pos = initial_pos;\n\n      cmark_node *fnref = make_simple(subj->mem, CMARK_NODE_FOOTNOTE_REFERENCE);\n\n      // the start and end of the footnote ref is the opening and closing brace\n      // i.e. the subject's current position, and the opener's start_column\n      int fnref_end_column = subj->pos + subj->column_offset + subj->block_offset;\n      int fnref_start_column = opener->inl_text->start_column;\n\n      // any given node delineates a substring of the line being processed,\n      // with the remainder of the line being pointed to thru its 'literal'\n      // struct member.\n      // here, we copy the literal's pointer, moving it past the '^' character\n      // for a length equal to the size of footnote reference text.\n      // i.e. end_col minus start_col, minus the [ and the ^ characters\n      //\n      // this copies the footnote reference string, even if between the\n      // `opener` and the subject's current position there are other nodes\n      //\n      // (first, check for underflows)\n      if ((fnref_start_column + 2) <= fnref_end_column) {\n        fnref->as.literal = cmark_chunk_dup(literal, 1, (fnref_end_column - fnref_start_column) - 2);\n      } else {\n        fnref->as.literal = cmark_chunk_dup(literal, 1, 0);\n      }\n\n      fnref->start_line = fnref->end_line = subj->line;\n      fnref->start_column = fnref_start_column;\n      fnref->end_column = fnref_end_column;\n\n      // we then replace the opener with this new fnref node, the net effect\n      // being replacing the opening '[' text node with a `^footnote-ref]` node.\n      cmark_node_insert_before(opener->inl_text, fnref);\n\n      process_emphasis(parser, subj, opener->previous_delimiter);\n      // sometimes, the footnote reference text gets parsed into multiple nodes\n      // i.e. '[^example]' parsed into '[', '^exam', 'ple]'.\n      // this happens for ex with the autolink extension. when the autolinker\n      // finds the 'w' character, it will split the text into multiple nodes\n      // in hopes of being able to match a 'www.' substring.\n      //\n      // because this function is called one character at a time via the\n      // `parse_inlines` function, and the current subj->pos is pointing at the\n      // closing ] brace, and because we copy all the text between the [ ]\n      // braces, we should be able to safely ignore and delete any nodes after\n      // the opener->inl_text->next.\n      //\n      // therefore, here we walk thru the list and free them all up\n      cmark_node *next_node;\n      cmark_node *current_node = opener->inl_text->next;\n      while(current_node) {\n        next_node = current_node->next;\n        cmark_node_free(current_node);\n        current_node = next_node;\n      }\n\n      cmark_node_free(opener->inl_text);\n\n      pop_bracket(subj);\n      return NULL;\n    }\n  }\n\n  pop_bracket(subj); // remove this opener from delimiter list\n  subj->pos = initial_pos;\n  return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"]\"));\n\nmatch:\n  inl = make_simple(subj->mem, is_image ? CMARK_NODE_IMAGE : CMARK_NODE_LINK);\n  inl->as.link.url = url;\n  inl->as.link.title = title;\n  inl->start_line = inl->end_line = subj->line;\n  inl->start_column = opener->inl_text->start_column;\n  inl->end_column = subj->pos + subj->column_offset + subj->block_offset;\n  cmark_node_insert_before(opener->inl_text, inl);\n  // Add link text:\n  tmp = opener->inl_text->next;\n  while (tmp) {\n    tmpnext = tmp->next;\n    cmark_node_append_child(inl, tmp);\n    tmp = tmpnext;\n  }\n\n  // Free the bracket [:\n  cmark_node_free(opener->inl_text);\n\n  process_emphasis(parser, subj, opener->previous_delimiter);\n  pop_bracket(subj);\n\n  // Now, if we have a link, we also want to deactivate earlier link\n  // delimiters. (This code can be removed if we decide to allow links\n  // inside links.)\n  if (!is_image) {\n    opener = subj->last_bracket;\n    while (opener != NULL) {\n      if (!opener->image) {\n        if (!opener->active) {\n          break;\n        } else {\n          opener->active = false;\n        }\n      }\n      opener = opener->previous;\n    }\n  }\n\n  return NULL;\n}\n\n// Parse a hard or soft linebreak, returning an inline.\n// Assumes the subject has a cr or newline at the current position.\nstatic cmark_node *handle_newline(subject *subj) {\n  bufsize_t nlpos = subj->pos;\n  // skip over cr, crlf, or lf:\n  if (peek_at(subj, subj->pos) == '\\r') {\n    advance(subj);\n  }\n  if (peek_at(subj, subj->pos) == '\\n') {\n    advance(subj);\n  }\n  ++subj->line;\n  subj->column_offset = -subj->pos;\n  // skip spaces at beginning of line\n  skip_spaces(subj);\n  if (nlpos > 1 && peek_at(subj, nlpos - 1) == ' ' &&\n      peek_at(subj, nlpos - 2) == ' ') {\n    return make_linebreak(subj->mem);\n  } else {\n    return make_softbreak(subj->mem);\n  }\n}\n\n// \"\\r\\n\\\\`&_*[]<!\"\nstatic int8_t SPECIAL_CHARS[256] = {\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n      1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};\n\n// \" ' . -\nstatic char SMART_PUNCT_CHARS[] = {\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n};\n\nstatic bufsize_t subject_find_special_char(subject *subj, int options) {\n  bufsize_t n = subj->pos + 1;\n\n  while (n < subj->input.len) {\n    if (SPECIAL_CHARS[subj->input.data[n]])\n      return n;\n    if (options & CMARK_OPT_SMART && SMART_PUNCT_CHARS[subj->input.data[n]])\n      return n;\n    n++;\n  }\n\n  return subj->input.len;\n}\n\nvoid cmark_inlines_add_special_character(unsigned char c, bool emphasis) {\n  SPECIAL_CHARS[c] = 1;\n  if (emphasis)\n    SKIP_CHARS[c] = 1;\n}\n\nvoid cmark_inlines_remove_special_character(unsigned char c, bool emphasis) {\n  SPECIAL_CHARS[c] = 0;\n  if (emphasis)\n    SKIP_CHARS[c] = 0;\n}\n\nstatic cmark_node *try_extensions(cmark_parser *parser,\n                                  cmark_node *parent,\n                                  unsigned char c,\n                                  subject *subj) {\n  cmark_node *res = NULL;\n  cmark_llist *tmp;\n\n  for (tmp = parser->inline_syntax_extensions; tmp; tmp = tmp->next) {\n    cmark_syntax_extension *ext = (cmark_syntax_extension *) tmp->data;\n    res = ext->match_inline(ext, parser, parent, c, subj);\n\n    if (res)\n      break;\n  }\n\n  return res;\n}\n\n// Parse an inline, advancing subject, and add it as a child of parent.\n// Return 0 if no inline can be parsed, 1 otherwise.\nstatic int parse_inline(cmark_parser *parser, subject *subj, cmark_node *parent, int options) {\n  cmark_node *new_inl = NULL;\n  cmark_chunk contents;\n  unsigned char c;\n  bufsize_t startpos, endpos;\n  c = peek_char(subj);\n  if (c == 0) {\n    return 0;\n  }\n  switch (c) {\n  case '\\r':\n  case '\\n':\n    new_inl = handle_newline(subj);\n    break;\n  case '`':\n    new_inl = handle_backticks(subj, options);\n    break;\n  case '\\\\':\n    new_inl = handle_backslash(parser, subj);\n    break;\n  case '&':\n    new_inl = handle_entity(subj);\n    break;\n  case '<':\n    new_inl = handle_pointy_brace(subj, options);\n    break;\n  case '*':\n  case '_':\n  case '\\'':\n  case '\"':\n    new_inl = handle_delim(subj, c, (options & CMARK_OPT_SMART) != 0);\n    break;\n  case '-':\n    new_inl = handle_hyphen(subj, (options & CMARK_OPT_SMART) != 0);\n    break;\n  case '.':\n    new_inl = handle_period(subj, (options & CMARK_OPT_SMART) != 0);\n    break;\n  case '[':\n    advance(subj);\n    new_inl = make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"[\"));\n    push_bracket(subj, false, new_inl);\n    break;\n  case ']':\n    new_inl = handle_close_bracket(parser, subj);\n    break;\n  case '!':\n    advance(subj);\n    if (peek_char(subj) == '[' && peek_char_n(subj, 1) != '^') {\n      advance(subj);\n      new_inl = make_str(subj, subj->pos - 2, subj->pos - 1, cmark_chunk_literal(\"![\"));\n      push_bracket(subj, true, new_inl);\n    } else {\n      new_inl = make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"!\"));\n    }\n    break;\n  default:\n    new_inl = try_extensions(parser, parent, c, subj);\n    if (new_inl != NULL)\n      break;\n\n    endpos = subject_find_special_char(subj, options);\n    contents = cmark_chunk_dup(&subj->input, subj->pos, endpos - subj->pos);\n    startpos = subj->pos;\n    subj->pos = endpos;\n\n    // if we're at a newline, strip trailing spaces.\n    if (S_is_line_end_char(peek_char(subj))) {\n      cmark_chunk_rtrim(&contents);\n    }\n\n    new_inl = make_str(subj, startpos, endpos - 1, contents);\n  }\n  if (new_inl != NULL) {\n    cmark_node_append_child(parent, new_inl);\n  }\n\n  return 1;\n}\n\n// Parse inlines from parent's string_content, adding as children of parent.\nvoid cmark_parse_inlines(cmark_parser *parser,\n                         cmark_node *parent,\n                         cmark_map *refmap,\n                         int options) {\n  subject subj;\n  cmark_chunk content = {parent->content.ptr, parent->content.size, 0};\n  subject_from_buf(parser->mem, parent->start_line, parent->start_column - 1 + parent->internal_offset, &subj, &content, refmap);\n  cmark_chunk_rtrim(&subj.input);\n\n  while (!is_eof(&subj) && parse_inline(parser, &subj, parent, options))\n    ;\n\n  process_emphasis(parser, &subj, NULL);\n  // free bracket and delim stack\n  while (subj.last_delim) {\n    remove_delimiter(&subj, subj.last_delim);\n  }\n  while (subj.last_bracket) {\n    pop_bracket(&subj);\n  }\n}\n\n// Parse zero or more space characters, including at most one newline.\nstatic void spnl(subject *subj) {\n  skip_spaces(subj);\n  if (skip_line_end(subj)) {\n    skip_spaces(subj);\n  }\n}\n\n// Parse reference.  Assumes string begins with '[' character.\n// Modify refmap if a reference is encountered.\n// Return 0 if no reference found, otherwise position of subject\n// after reference is parsed.\nbufsize_t cmark_parse_reference_inline(cmark_mem *mem, cmark_chunk *input,\n                                       cmark_map *refmap) {\n  subject subj;\n\n  cmark_chunk lab;\n  cmark_chunk url;\n  cmark_chunk title;\n\n  bufsize_t matchlen = 0;\n  bufsize_t beforetitle;\n\n  subject_from_buf(mem, -1, 0, &subj, input, NULL);\n\n  // parse label:\n  if (!link_label(&subj, &lab) || lab.len == 0)\n    return 0;\n\n  // colon:\n  if (peek_char(&subj) == ':') {\n    advance(&subj);\n  } else {\n    return 0;\n  }\n\n  // parse link url:\n  spnl(&subj);\n  if ((matchlen = manual_scan_link_url(&subj.input, subj.pos, &url)) > -1) {\n    subj.pos += matchlen;\n  } else {\n    return 0;\n  }\n\n  // parse optional link_title\n  beforetitle = subj.pos;\n  spnl(&subj);\n  matchlen = subj.pos == beforetitle ? 0 : scan_link_title(&subj.input, subj.pos);\n  if (matchlen) {\n    title = cmark_chunk_dup(&subj.input, subj.pos, matchlen);\n    subj.pos += matchlen;\n  } else {\n    subj.pos = beforetitle;\n    title = cmark_chunk_literal(\"\");\n  }\n\n  // parse final spaces and newline:\n  skip_spaces(&subj);\n  if (!skip_line_end(&subj)) {\n    if (matchlen) { // try rewinding before title\n      subj.pos = beforetitle;\n      skip_spaces(&subj);\n      if (!skip_line_end(&subj)) {\n        return 0;\n      }\n    } else {\n      return 0;\n    }\n  }\n  // insert reference into refmap\n  cmark_reference_create(refmap, &lab, &url, &title);\n  return subj.pos;\n}\n\nunsigned char cmark_inline_parser_peek_char(cmark_inline_parser *parser) {\n  return peek_char(parser);\n}\n\nunsigned char cmark_inline_parser_peek_at(cmark_inline_parser *parser, bufsize_t pos) {\n  return peek_at(parser, pos);\n}\n\nint cmark_inline_parser_is_eof(cmark_inline_parser *parser) {\n  return is_eof(parser);\n}\n\nstatic char *\nmy_strndup (const char *s, size_t n)\n{\n  char *result;\n  size_t len = strlen (s);\n\n  if (n < len)\n    len = n;\n\n  result = (char *) malloc (len + 1);\n  if (!result)\n    return 0;\n\n  result[len] = '\\0';\n  return (char *) memcpy (result, s, len);\n}\n\nchar *cmark_inline_parser_take_while(cmark_inline_parser *parser, cmark_inline_predicate pred) {\n  unsigned char c;\n  bufsize_t startpos = parser->pos;\n  bufsize_t len = 0;\n\n  while ((c = peek_char(parser)) && (*pred)(c)) {\n    advance(parser);\n    len++;\n  }\n\n  return my_strndup((const char *) parser->input.data + startpos, len);\n}\n\nvoid cmark_inline_parser_push_delimiter(cmark_inline_parser *parser,\n                                  unsigned char c,\n                                  int can_open,\n                                  int can_close,\n                                  cmark_node *inl_text) {\n  push_delimiter(parser, c, can_open != 0, can_close != 0, inl_text);\n}\n\nvoid cmark_inline_parser_remove_delimiter(cmark_inline_parser *parser, delimiter *delim) {\n  remove_delimiter(parser, delim);\n}\n\nint cmark_inline_parser_scan_delimiters(cmark_inline_parser *parser,\n                                  int max_delims,\n                                  unsigned char c,\n                                  int *left_flanking,\n                                  int *right_flanking,\n                                  int *punct_before,\n                                  int *punct_after) {\n  int numdelims = 0;\n  bufsize_t before_char_pos;\n  int32_t after_char = 0;\n  int32_t before_char = 0;\n  int len;\n  bool space_before, space_after;\n\n  if (parser->pos == 0) {\n    before_char = 10;\n  } else {\n    before_char_pos = parser->pos - 1;\n    // walk back to the beginning of the UTF_8 sequence:\n    while (peek_at(parser, before_char_pos) >> 6 == 2 && before_char_pos > 0) {\n      before_char_pos -= 1;\n    }\n    len = cmark_utf8proc_iterate(parser->input.data + before_char_pos,\n                                 parser->pos - before_char_pos, &before_char);\n    if (len == -1) {\n      before_char = 10;\n    }\n  }\n\n  while (peek_char(parser) == c && numdelims < max_delims) {\n    numdelims++;\n    advance(parser);\n  }\n\n  len = cmark_utf8proc_iterate(parser->input.data + parser->pos,\n                               parser->input.len - parser->pos, &after_char);\n  if (len == -1) {\n    after_char = 10;\n  }\n\n  *punct_before = cmark_utf8proc_is_punctuation(before_char);\n  *punct_after = cmark_utf8proc_is_punctuation(after_char);\n  space_before = cmark_utf8proc_is_space(before_char) != 0;\n  space_after = cmark_utf8proc_is_space(after_char) != 0;\n\n  *left_flanking = numdelims > 0 && !cmark_utf8proc_is_space(after_char) &&\n                  !(*punct_after && !space_before && !*punct_before);\n  *right_flanking = numdelims > 0 && !cmark_utf8proc_is_space(before_char) &&\n                  !(*punct_before && !space_after && !*punct_after);\n\n  return numdelims;\n}\n\nvoid cmark_inline_parser_advance_offset(cmark_inline_parser *parser) {\n  advance(parser);\n}\n\nint cmark_inline_parser_get_offset(cmark_inline_parser *parser) {\n  return parser->pos;\n}\n\nvoid cmark_inline_parser_set_offset(cmark_inline_parser *parser, int offset) {\n  parser->pos = offset;\n}\n\nint cmark_inline_parser_get_column(cmark_inline_parser *parser) {\n  return parser->pos + 1 + parser->column_offset + parser->block_offset;\n}\n\ncmark_chunk *cmark_inline_parser_get_chunk(cmark_inline_parser *parser) {\n  return &parser->input;\n}\n\nint cmark_inline_parser_in_bracket(cmark_inline_parser *parser, int image) {\n  for (bracket *b = parser->last_bracket; b; b = b->previous)\n    if (b->active && b->image == (image != 0))\n      return 1;\n  return 0;\n}\n\nvoid cmark_node_unput(cmark_node *node, int n) {\n\tnode = node->last_child;\n\twhile (n > 0 && node && node->type == CMARK_NODE_TEXT) {\n\t\tif (node->as.literal.len < n) {\n\t\t\tn -= node->as.literal.len;\n\t\t\tnode->as.literal.len = 0;\n\t\t} else {\n\t\t\tnode->as.literal.len -= n;\n\t\t\tn = 0;\n\t\t}\n\t\tnode = node->prev;\n\t}\n}\n\ndelimiter *cmark_inline_parser_get_last_delimiter(cmark_inline_parser *parser) {\n  return parser->last_delim;\n}\n\nint cmark_inline_parser_get_line(cmark_inline_parser *parser) {\n  return parser->line;\n}\n"], "fixing_code": ["cmake_minimum_required(VERSION 3.0)\nproject(cmark-gfm)\n\nset(PROJECT_VERSION_MAJOR 0)\nset(PROJECT_VERSION_MINOR 29)\nset(PROJECT_VERSION_PATCH 0)\nset(PROJECT_VERSION_GFM 6)\nset(PROJECT_VERSION ${PROJECT_VERSION_MAJOR}.${PROJECT_VERSION_MINOR}.${PROJECT_VERSION_PATCH}.gfm.${PROJECT_VERSION_GFM})\n\ninclude(\"FindAsan.cmake\")\ninclude(\"CheckFileOffsetBits.cmake\")\n\nif(\"${CMAKE_SOURCE_DIR}\" STREQUAL \"${CMAKE_BINARY_DIR}\")\n    message(FATAL_ERROR \"Do not build in-source.\\nPlease remove CMakeCache.txt and the CMakeFiles/ directory.\\nThen: mkdir build ; cd build ; cmake .. ; make\")\nendif()\n\noption(CMARK_TESTS \"Build cmark-gfm tests and enable testing\" ON)\noption(CMARK_STATIC \"Build static libcmark-gfm library\" ON)\noption(CMARK_SHARED \"Build shared libcmark-gfm library\" ON)\noption(CMARK_LIB_FUZZER \"Build libFuzzer fuzzing harness\" OFF)\n\nadd_subdirectory(src)\nadd_subdirectory(extensions)\nif(CMARK_TESTS AND (CMARK_SHARED OR CMARK_STATIC))\n  add_subdirectory(api_test)\nendif()\nadd_subdirectory(man)\nif(CMARK_TESTS)\n  enable_testing()\n  add_subdirectory(test testdir)\nendif()\n\nif(NOT CMAKE_BUILD_TYPE)\n  set(CMAKE_BUILD_TYPE \"Release\" CACHE STRING\n  \"Choose the type of build, options are: Debug Profile Release Asan Ubsan.\" FORCE)\nendif(NOT CMAKE_BUILD_TYPE)\n", "[0.29.0.gfm.6]\n  * Fixed polynomial time complexity DoS vulnerability in autolink extension\n  \n[0.29.0.gfm.5]\n  * Added xmpp: and mailto: support to the autolink extension\n\n[0.29.0.gfm.4]\n  * Remove `source` from list of HTML blocks\n\n[0.29.0.gfm.3]\n  * Fixed heap memory corruption vulnerabiliy via integer overflow per https://github.com/github/cmark-gfm/security/advisories/GHSA-mc3g-88wq-6f4x\n\n[0.29.0.gfm.2]\n  * Fixed issues with footnote rendering when used with the autolinker (#121),\n    and when footnotes are adjacent (#139).\n  * We now allow footnotes to be referenced from inside a footnote definition,\n    we use the footnote label for the fnref href text when rendering html, and\n    we insert multiple backrefs when a footnote has been referenced multiple\n    times (#229, #230)\n  * We added new data- attributes to footnote html rendering to make them\n    easier to style (#234)\n\n[0.29.0.gfm.1]\n\n  * Fixed denial of service bug in GFM's table extension\n    per https://github.com/github/cmark-gfm/security/advisories/GHSA-7gc6-9qr5-hc85\n\n[0.29.0]\n\n  * Update spec to 0.29.\n  * Make rendering safe by default (#239, #273).\n    Adds `CMARK_OPT_UNSAFE` and make `CMARK_OPT_SAFE` a no-op (for API\n    compatibility).  The new default behavior is to suppress raw HTML and\n    potentially dangerous links.  The `CMARK_OPT_UNSAFE` option has to be set\n    explicitly to prevent this.\n    **NOTE:** This change will require modifications in bindings for cmark\n    and in most libraries and programs that use cmark.\n    Borrows heavily from @kivikakk's patch in github/cmark-gfm#123.\n  * Add sourcepos info for inlines (Yuki Izumi).\n  * Disallow more than 32 nested balanced parens in a link (Yuki Izumi).\n  * Resolve link references before creating setext header.\n    A setext header line after a link reference should not\n    create a header, according to the spec.\n  * commonmark renderer: improve escaping.\n    URL-escape special characters when escape mode is URL, and not otherwise.\n    Entity-escape control characters (< 0x20) in non-literal escape modes.\n  * render:  only emit actual newline when escape mode is LITERAL.\n    For markdown content, e.g., in other contexts we want some\n    kind of escaping, not a literal newline.\n  * Update code span normalization to conform with spec change.\n  * Allow empty `<>` link destination in reference link.\n  * Remove leftover includes of `memory.h` (#290).\n  * A link destination can't start with `<` unless it is\n    an angle-bracket link that also ends with `>` (#289).\n    (If your URL really starts with `<`, URL-escape it.)\n  * Allow internal delimiter runs to match if both have lengths that are\n    multiples of 3.  See commonmark/commonmark#528.\n  * Include `references.h` in `parser.h` (#287).\n  * Fix `[link](<foo\\>)`.\n  * Use hand-rolled scanner for thematic break (see #284).\n    Keep track of the last position where a thematic break\n    failed to match on a line, to avoid rescanning unnecessarily.\n  * Rename `ends_with_blank_line` with `S_` prefix.\n  * Add `CMARK_NODE__LAST_LINE_CHECKED` flag (#284).\n    Use this to avoid unnecessary recursion in `ends_with_blank_line`.\n  * In `ends_with_blank_line`, call `S_set_last_line_blank`\n    to avoid unnecessary repetition (#284).  Once we settle whether a list\n    item ends in a blank line, we don't need to revisit this in considering\n    parent list items.\n  * Disallow unescaped `(` in parenthesized link title.\n  * Copy line/col info straight from opener/closer (Ashe Connor).\n    We can't rely on anything in `subj` since it's been modified while parsing\n    the subject and could represent line info from a future line.  This is\n    simple and works.\n  * `render.c`: reset `last_breakable` after cr.  Fixes jgm/pandoc#5033.\n  * Fix a typo in `houdini_href_e.c` (Felix Yan).\n  * commonmark writer: use `~~~` fences if info string contains backtick.\n    This is needed for round-trip tests.\n  * Update scanners for new info string rules.\n  * Add XSLT stylesheet to convert cmark XML back to Commonmark\n    (Nick Wellnhofer, #264).  Initial version of an XSLT stylesheet that\n    converts the XML format produced by `cmark -t xml` back to Commonmark.\n  * Check for whitespace before reference title (#263).\n  * Bump CMake to version 3 (Jonathan M\u00fcller).\n  * Build: Remove deprecated call to `add_compiler_export_flags()`\n    (Jonathan M\u00fcller).  It is deprecated in CMake 3.0, the replacement is to\n    set the `CXX_VISIBILITY_PRESET` (or in our case `C_VISIBILITY_PRESET`) and\n    `VISIBILITY_INLINES_HIDDEN` properties of the target.  We're already\n    setting them by setting the CMake variables anyway, so the call can be\n    removed.\n  * Build: only attempt to install MSVC system libraries on Windows\n    (Saleem Abdulrasool).  Newer versions of CMake attempt to query the system\n    for information about the VS 2017 installation.  Unfortunately, this query\n    fails on non-Windows systems when cross-compiling:\n    `cmake_host_system_information does not recognize <key> VS_15_DIR`.\n    CMake will not find these system libraries on non-Windows hosts anyways,\n    and we were silencing the warnings, so simply omit the installation when\n    cross-compiling to Windows.\n  * Simplify code normalization, in line with spec change.\n  * Implement code span spec changes.  These affect both parsing and writing\n    commonmark.\n  * Add link parsing corner cases to regressions (Ashe Connor).\n  * Add `xml:space=\"preserve\"` in XML output when appropriate\n    (Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy).\n    (For text, code, code_block, html_inline and html_block tags.)\n  * Removed meta from list of block tags.  Added regression test.\n    See commonmark/CommonMark#527.\n  * `entity_tests.py` - omit noisy success output.\n  * `pathological_tests.py`: make tests run faster.\n    Commented out the (already ignored) \"many references\" test, which\n    times out.  Reduced the iterations for a couple other tests.\n  * `pathological_tests.py`: added test for deeply nested lists.\n  * Optimize `S_find_first_nonspace`.  We were needlessly redoing things we'd\n    already done.  Now we skip the work if the first nonspace is greater than\n    the current offset.  This fixes pathological slowdown with deeply nested\n    lists (#255).  For N = 3000, the time goes from over 17s to about 0.7s.\n    Thanks to Martin Mitas for diagnosing the problem.\n  * Allow spaces in link destination delimited with pointy brackets.\n  * Adjust max length of decimal/numeric entities.\n    See commonmark/CommonMark#487.\n  * Fix inline raw HTML parsing.\n    This fixes a recently added failing spec test case.  Previously spaces\n    were being allowed in unquoted attribute values; no we forbid them.\n  * Don't allow list markers to be indented >= 4 spaces.\n    See commonmark/CommonMark#497.\n  * Check for empty buffer when rendering (Phil Turnbull).\n    For empty documents, `->size` is zero so\n    `renderer.buffer->ptr[renderer.buffer->size - 1]` will cause an\n    out-of-bounds read. Empty buffers always point to the global\n    `cmark_strbuf__initbuf` buffer so we read `cmark_strbuf__initbuf[-1]`.\n  * Also run API tests with `CMARK_SHARED=OFF` (Nick Wellnhofer).\n  * Rename roundtrip and entity tests (Nick Wellnhofer).\n    Rename the tests to reflect that they use the library, not the\n    executable.\n  * Generate export header for static-only build (#247, Nick Wellnhofer).\n  * Fuzz width parameter too (Phil Turnbull).  Allow the `width` parameter to\n    be generated too so we get better fuzz-coverage.\n  * Don't discard empty fuzz test-cases (Phil Turnbull).  We currently discard\n    fuzz test-cases that are empty but empty inputs are valid markdown. This\n    improves the fuzzing coverage slightly.\n  * Fixed exit code for pathological tests.\n  * Add allowed failures to `pathological_tests.py`.\n    This allows us to include tests that we don't yet know how to pass.\n  * Add timeout to `pathological_tests.py`.\n    Tests must complete in 8 seconds or are errors.\n  * Add more pathological tests (Martin Mitas).\n    These tests target the issues #214, #218, #220.\n  * Use pledge(2) on OpenBSD (Ashe Connor).\n  * Update the Racket wrapper (Eli Barzilay).\n  * Makefile: For afl target, don't build tests.\n\n[0.28.3.gfm.20]\n\n  * Add tasklist extension implementation (Watson1978, #94).\n\n[0.28.3.gfm.19]\n\n  * Prevent out-of-bound memory access in strikethrough matcher (Xavier D\u00e9coret, #124).\n  * Limit recursion in autolink extension (Xavier D\u00e9coret, #125).\n  * Add plaintext rendering for footnotes (Xavier D\u00e9coret, #126).\n\n[0.28.3.gfm.18]\n\n  * Match strikethrough more strictly (#120).\n  * Default to safe operation (#123).\n\n[0.28.3.gfm.17]\n\n  * Allow extension to provide opaque allocation function (Nicol\u00e1s Ojeda\n    B\u00e4r, #89).\n  * Upstream optimisations and fixes.\n  * Extensions can add custom XML attributes (#116).\n  * Support for GFM extensions in cmark XML to CommonMark XSLT converter\n    (Ma\u00eblle Salmon, #117).\n\n[0.28.3.gfm.16]\n\n  * Do not percent-encode tildes (~) in HTML attribute values (#110).\n  * Fix footnote references in tables (#112).\n\n[0.28.3.gfm.15]\n\n  * Escape non-strikethrough tildes (~) in commonmark output (John MacFarlane, #106).\n  * Cosmetic fix to table HTML output (John MacFarlane, #105).\n  * Use two tildes for strikethrough CommonMark output (John MacFarlane, #104).\n  * Normalised header and define names (#109).\n\n[0.28.3.gfm.14]\n\n  * Added a plaintext renderer for strikethrough nodes.\n\n[0.28.3.gfm.13]\n\n  * Footnote rendering bugfix (Michael Camilleri, #90).\n  * Debian packaging (Joachim Nilsson, #97).\n  * Add CMARK_OPT_STRIKETHROUGH_DOUBLE_TILDE for redcarpet compatibility.\n  * Add CMARK_OPT_TABLE_PREFER_STYLE_ATTRIBUTES (FUJI Goro, #86, #87).\n  * Fix pathological nested list parsing (Phil Turnbull, #95).\n  * Expose more of the extension APIs (Minghao Liu, #96).\n  * Add python example which uses extensions (Greg Stein, #102).\n  * Add CMARK_OPT_FULL_INFO_STRING (Mike Kavouras, #103).\n\n[0.28.3.gfm.12]\n\n  * Various security and bug fixes.\n\n[0.28.3]\n\n  * Include GNUInstallDirs in src/CMakeLists.txt (Nick Wellnhofer, #240).\n    This fixes build problems on some cmake versions (#241).\n\n[0.28.2]\n\n  * Fixed regression in install dest for static library (#238).\n    Due to a mistake, 0.28.1 installed libcmark.a into include/.\n\n[0.28.1]\n\n  * `--smart`: open quote can never occur right after `]` or `)` (#227).\n  * Fix quadratic behavior in `finalize` (Vicent Marti).\n  * Don't use `CMAKE_INSTALL_LIBDIR` to create `libcmark.pc` (#236).\n    This wasn't getting set in processing `libcmark.pc.in`, and we\n    were getting the wrong entry in `libcmark.pc`.\n    The new approach sets an internal `libdir` variable to\n    `lib${LIB_SUFFIX}`.  This variable is used both to set the\n    install destination and in the libcmark.pc.in template.\n  * Update README.md, replace `make astyle` with `make format`\n    (Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy).\n\n[0.28.0.gfm.11]\n\n  * Do not output empty `<tbody>` in table extension.\n\n[0.28.0.gfm.10]\n\n  * Fix denial of service parsing references.\n\n[0.28.0.gfm.9]\n\n  * Fix denial of service parsing nested links (#49).\n\n[0.28.0.gfm.8]\n\n  * Fix bug where autolink would cause `:` to be skipped in emphasis\n    processing.\n\n[0.28.0.gfm.7]\n\n  * Strikethrough characters do not disturb regular emphasis processing.\n\n[0.28.0.gfm.6]\n\n  * Fix inline sourcepos info when inlines span multiple lines, and in\n    ATX headings.\n\n[0.28.0.gfm.5]\n\n  * Latest spec.\n  * Fix a typo in the spec (John Gardner).\n  * Fix quadratic behavior in reference lookups.\n  * Add `core_extensions_ensure_registered`.\n  * Add sourcepos information for inlines.\n\n[0.28.0]\n\n  * Update spec.\n  * Use unsigned integer when shifting (Phil Turnbull).\n    Avoids a UBSAN warning which can be triggered when handling a\n    long sequence of backticks.\n  * Avoid memcpy'ing NULL pointers (Phil Turnbull).\n    Avoids a UBSAN warning when link title is empty string.\n    The length of the memcpy is zero so the NULL pointer is not\n    dereferenced but it is still undefined behaviour.\n  * DeMorgan simplification of some tests in emphasis parser.\n    This also brings the code into closer alignment with the wording\n    of the spec (see jgm/CommonMark#467).\n  * Fixed undefined shift in commonmark writer (#211).\n    Found by google/oss-fuzz:\n    <https://oss-fuzz.com/v2/testcase-detail/4686992824598528>.\n  * latex writer:  fix memory overflow (#210).\n    We got an array overflow in enumerated lists nested more than\n    10 deep with start number =/= 1.\n    This commit also ensures that we don't try to set `enum_` counters\n    that aren't defined by LaTeX (generally up to enumv).\n    Found by google/oss-fuzz:\n    <https://oss-fuzz.com/v2/testcase-detail/5546760854306816>.\n  * Check for NULL pointer in get_link_type (Phil Turnbull).\n    `echo '[](xx:)' | ./build/src/cmark -t latex` gave a\n    segfault.\n  * Move fuzzing dictionary into single file (Phil Turnbull).\n    This allows AFL and libFuzzer to use the same dictionary\n  * Reset bytes after UTF8 proc (Yuki Izumi, #206).\n  * Don't scan past an EOL (Yuki Izumi).\n    The existing negated character classes (`[^\u2026]`) are careful to\n    always include` \\x00` in the characters excluded, but these `.`\n    catch-alls can scan right past the terminating NUL placed\n    at the end of the buffer by `_scan_at`.  As such, buffer\n    overruns can occur.  Also, don't scan past a newline in HTML\n    block end scanners.\n  * Document cases where `get_` functions return `NULL` (#155).\n    E.g. `cmark_node_get_url` on a non-link or image.\n  * Properly handle backslashes in link destinations (#192).\n    Only ascii punctuation characters are escapable, per the spec.\n  * Fixed `cmark_node_get_list_start` to return 0 for bullet lists,\n    as documented (#202).\n  * Use `CMARK_NO_DELIM` for bullet lists (#201).\n  * Fixed code for freeing delimiter stack (#189).\n  * Removed abort outside of conditional (typo).\n  * Removed coercion in error message when aborting from buffer.\n  * Print message to stderr when we abort due to memory demands (#188).\n  * `libcmark.pc`: use `CMAKE_INSTALL_LIBDIR` (#185, Jens Petersen).\n    Needed for multilib distros like Fedora.\n  * Fixed buffer overflow error in `S_parser_feed` (#184).\n    The overflow could occur in the following condition:\n    the buffer ends with `\\r` and the next memory address\n    contains `\\n`.\n  * Update emphasis parsing for spec change.\n    Strong now goes inside Emph rather than the reverse,\n    when both scopes are possible.  The code is much simpler.\n    This also avoids a spec inconsistency that cmark had previously:\n    `***hi***` became Strong (Emph \"hi\")) but\n    `***hi****` became Emph (Strong \"hi\")) \"*\"\n  * Fixes for the LaTeX renderer (#182, Doeme)\n    + Don't double-output the link in latex-rendering.\n    + Prevent ligatures in dashes sensibly when rendering latex.\n      `\\-` is a hyphenation, so it doesn't get displayed at all.\n  * Added a test for NULL when freeing `subj->last_delim`.\n  * Cleaned up setting of lower bounds for openers.\n    We now use a much smaller array.\n  * Fix #178, quadratic parsing bug.  Add pathological test.\n  * Slight improvement of clarity of logic in emph matching.\n  * Fix \"multiple of 3\" determination in emph/strong parsing.\n    We need to store the length of the original delimiter run,\n    instead of using the length of the remaining delimiters\n    after some have been subtracted.  Test case:\n    `a***b* c*`.  Thanks to Raph Levin for reporting.\n  * Correctly initialize chunk in S_process_line (Nick Wellnhofer, #170).\n    The `alloc` member wasn't initialized.  This also allows to add an\n    assertion in `chunk_rtrim` which doesn't work for alloced chunks.\n  * Added 'make newbench'.\n  * `scanners.c` generated with re2c 0.16 (68K smaller!).\n  * `scanners.re` - fixed warnings; use `*` for fallback.\n  * Fixed some warnings in `scanners.re`.\n  * Update CaseFolding to latest (Kevin Wojniak, #168).\n  * Allow balanced nested parens in link destinations (Yuki Izumi, #166)\n  * Allocate enough bytes for backticks array.\n  * Inlines: Ensure that the delimiter stack is freed in subject.\n  * Fixed pathological cases with backtick code spans:\n\n    - Removed recursion in scan_to_closing_backticks\n    - Added an array of pointers to potential backtick closers\n      to subject\n    - This array is used to avoid traversing the subject again\n      when we've already seen all the potential backtick closers.\n    - Added a max bound of 1000 for backtick code span delimiters.\n    - This helps with pathological cases like:\n\n            x\n            x `\n            x ``\n            x ```\n            x ````\n            ...\n\n    - Added pathological test case.\n\n    Thanks to Martin Mit\u00e1\u0161 for identifying the problem and for\n    discussion of solutions.\n  * Remove redundant cmake_minimum_required (#163, @kainjow).\n  * Make shared and static libraries optional (Azamat H. Hackimov).\n    Now you can enable/disable compilation and installation targets for\n    shared and static libraries via `-DCMARK_SHARED=ON/OFF` and\n    `-DCMARK_STATIC=ON/OFF`.\n  * Added support for built-in `${LIB_SUFFIX}` feature (Azamat H.\n    Hackimov).  Replaced `${LIB_INSTALL_DIR}` option with built-in\n    `${LIB_SUFFIX}` for installing for 32/64-bit systems. Normally,\n    CMake will set `${LIB_SUFFIX}` automatically for required enviroment.\n    If you have any issues with it, you can override this option with\n    `-DLIB_SUFFIX=64` or `-DLIB_SUFFIX=\"\"` during configuration.\n  * Add Makefile target and harness to fuzz with libFuzzer (Phil Turnbull).\n    This can be run locally with `make libFuzzer` but the harness will be\n    integrated into oss-fuzz for large-scale fuzzing.\n  * Advertise `--validate-utf8` in usage information\n    (Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy).\n  * Makefile: use warnings with re2c.\n  * README: Add link to Python wrapper, prettify languages list\n    (Pavlo Kapyshin).\n  * README: Add link to cmark-scala (Tim Nieradzik, #196)\n\n[0.27.1.gfm.4]\n\n  * Fix regression with nested parentheses in link targets (#48).\n\n[0.27.1.gfm.3]\n\n  * Various undefined behavior issues fixed (#38, #39, #40).\n  * Tag filter is case-insensitive (#43).\n\n[0.27.1.gfm.2]\n\n  * Fix a number of bugs (reading past end of buffer, undefined behavior.\n  * Add `cmark_syntax_extension_get_private()`. (Jonathan M\u00fcller)\n\n[0.27.1.gfm.1]\n\n  * Add plaintext renderer.\n  * Remove normalize option; we now always normalize the AST.\n  * Add getters for table alignment.\n  * `make install` also installs the extensions static/shared library.\n\n[0.27.1.gfm.0]\n\n  * Add extensions: tagfilter, strikethrough, table, autolink.\n  * Add arena memory implementation.\n  * Add CMARK_OPT_GITHUB_PRE_LANG for fenced code blocks.\n  * Skip UTF-8 BOM on input.\n\n[0.27.1]\n\n  * Set policy for CMP0063 to avoid a warning (#162).\n    Put set_policy under cmake version test.\n    Otherwise we get errors in older versions of cmake.\n  * Use VERSION_GREATER to clean up cmake version test.\n  * Improve afl target.  Use afl-clang by default.  Set default for path.\n\n[0.27.0]\n\n  * Update spec to 0.27.\n  * Fix warnings building with MSVC on Windows (#165, Hugh Bellamy).\n  * Fix `CMAKE_C_VISIBILITY_PRESET` for cmake versions greater than 1.8\n    (e.g. 3.6.2) (#162, Hugh Bellamy).  This lets us build swift-cmark\n    on Windows, using clang-cl.\n  * Fix for non-matching entities (#161, Yuki Izumi).\n  * Modified `print_delimiters` (commented out) so it compiles again.\n  * `make format`: don't change order of includes.\n  * Changed logic for null/eol checks (#160).\n    + only check once for \"not at end of line\"\n    + check for null before we check for newline characters (the\n      previous patch would fail for NULL + CR)\n  * Fix by not advancing past both `\\0` and `\\n` (Yuki Izumi).\n  * Add test for NUL-LF sequence (Yuki Izumi).\n  * Fix memory leak in list parsing (Yuki Izumi).\n  * Use `cmark_mem` to free where used to alloc (Yuki Izumi).\n  * Allow a shortcut link before a `(` (jgm/CommonMark#427).\n  * Allow tabs after setext header line (jgm/commonmark.js#109).\n  * Don't let URI schemes start with spaces.\n  * Fixed h2..h6 HTML blocks (jgm/CommonMark#430).  Added regression test.\n  * Autolink scheme can contain digits (G\u00e1bor Cs\u00e1rdi).\n  * Fix nullary function declarations in cmark.h (Nick Wellnhofer).\n    Fixes strict prototypes warnings.\n  * COPYING: Update file name and remove duplicate section and\n    (Peter Eisentraut).\n  * Fix typo (Pavlo Kapyshin).\n\n[0.26.1]\n\n  * Removed unnecessary typedef that caused build failure on\n    some platforms.\n  * Use `$(MAKE)` in Makefile instead of hardcoded `make` (#146,\n    Tobias Kortkamp).\n\n[0.26.0]\n\n  * Implement spec changes for list items:\n    - Empty list items cannot interrupt paragraphs.\n    - Ordered lists cannot interrupt paragraphs unless\n      they start with 1.\n    - Removed \"two blank lines break out of a list\" feature.\n  * Fix sourcepos for blockquotes (#142).\n  * Fix sourcepos for atx headers (#141).\n  * Fix ATX headers and thematic breaks to allow tabs as well as spaces.\n  * Fix `chunk_set_cstr` with suffix of current string (#139,\n    Nick Wellnhofer).  It's possible that `cmark_chunk_set_cstr` is called\n    with a substring (suffix) of the current string. Delay freeing of the\n    chunk content to handle this case correctly.\n  * Export targets on installation (Jonathan M\u00fcller).\n    This allows using them in other cmake projects.\n  * Fix cmake warning about CMP0048 (Jonathan M\u00fcller).\n  * commonmark renderer:  Ensure we don't have a blank line\n    before a code block when it's the first thing in a list\n    item.\n  * Change parsing of strong/emph in response to spec changes.\n    `process_emphasis` now gets better results in corner cases.\n    The change is this:  when considering matches between an interior\n    delimiter run (one that can open and can close) and another delimiter\n    run, we require that the sum of the lengths of the two delimiter\n    runs mod 3 is not 0.\n  * Ported Robin Stocker's changes to link parsing in jgm/commonmark#101.\n    This uses a separate stack for brackets, instead of putting them on the\n    delimiter stack.  This avoids the need for looking through the delimiter\n    stack for the next bracket.\n  * `cmark_reference_lookup`: Return NULL if reference is null string.\n  * Fix character type detection in `commonmark.c` (Nick Wellnhofer).\n    Fixes test failures on Windows and undefined behavior.\n    - Implement `cmark_isalpha`.\n    - Check for ASCII character before implicit cast to char.\n    - Use internal ctype functions in `commonmark.c`.\n  * Better documentation of memory-freeing responsibilities.\n    in `cmark.h` and its man page (#124).\n  * Use library functions to insert nodes in emphasis/link processing.\n    Previously we did this manually, which introduces many\n    places where errors can creep in.\n  * Correctly handle list marker followed only by spaces.\n    Previously when a list marker was followed only by spaces,\n    cmark expected the following content to be indented by\n    the same number of spaces.  But in this case we should\n    treat the line just like a blank line and set list padding\n    accordingly.\n  * Fixed a number of issues relating to line wrapping.\n    - Extend `CMARK_OPT_NOBREAKS` to all renderers and add `--nobreaks`.\n    - Do not autowrap, regardless of width parameter, if\n      `CMARK_OPT_NOBREAKS` is set.\n    - Fixed `CMARK_OPT_HARDBREAKS` for LaTeX and man renderers.\n    - Ensure that no auto-wrapping occurs if\n      `CMARK_OPT_NOBREAKS` is enabled, or if output is CommonMark and\n      `CMARK_OPT_HARDBREAKS` is enabled.\n  * Set stdin to binary mode on Windows (Nick Wellnhofer, #113).\n    This fixes EOLs when reading from stdin.\n  * Add library option to render softbreaks as spaces (Pavlo\n    Kapyshin).  Note that the `NOBREAKS` option is HTML-only\n  * renderer:  `no_linebreaks` instead of `no_wrap`.\n    We generally want this option to prohibit any breaking\n    in things like headers (not just wraps, but softbreaks).\n  * Coerce `realurllen` to `int`.  This is an alternate solution for pull\n    request #132, which introduced a new warning on the comparison\n    (Benedict Cohen).\n  * Remove unused variable `link_text` (Mathiew Duponchelle).\n  * Improved safety checks in buffer (Vicent Marti).\n  * Add new interface allowing specification of custom memory allocator\n    for nodes (Vicent Marti).  Added `cmark_node_new_with_mem`,\n    `cmark_parser_new_with_mem`, `cmark_mem` to API.\n  * Reduce storage size for nodes by using bit flags instead of\n    separate booleans (Vicent Marti).\n  * config: Add `SSIZE_T` compat for Win32 (Vicent Marti).\n  * cmake: Global handler for OOM situations (Vicent Marti).\n  * Add tests for memory exhaustion (Vicent Marti).\n  * Document in man page and public header that one should use the same\n    memory allocator for every node in a tree.\n  * Fix ctypes in Python FFI calls (Nick Wellnhofer).  This didn't cause\n    problems so far because all types are 32-bit on 32-bit systems and\n    arguments are passed in registers on x86-64.  The wrong types could cause\n    crashes on other platforms, though.\n  * Remove spurious failures in roundtrip tests.  In the commonmark writer we\n    separate lists, and lists and indented code, using a dummy HTML comment.\n    So in evaluating the round-trip tests, we now strip out\n    these comments.  We also normalize HTML to avoid issues\n    having to do with line breaks.\n  * Add 2016 to copyright (Kevin Burke).\n  * Added `to_commonmark` in `test/cmark.py` (for round-trip tests).\n  * `spec_test.py` - parameterize `do_test` with converter.\n  * `spec_tests.py`: exit code is now sum of failures and errors.\n    This ensures that a failing exit code will be given when\n    there are errors, not just with failures.\n  * Fixed round trip tests.  Previously they actually ran\n    `cmark` instead of the round-trip version, since there was a bug in\n    setting the ROUNDTRIP variable (#131).\n  * Added new `roundtrip_tests.py`.  This replaces the old use of simple shell\n    scripts.  It is much faster, and more flexible.  (We will be able\n    to do custom normalization and skip certain tests.)\n  * Fix tests under MinGW (Nick Wellnhofer).\n  * Fix leak in `api_test` (Mathieu Duponchelle).\n  * Makefile: have leakcheck stop on first error instead of going through\n    all the formats and options and probably getting the same output.\n  * Add regression tests (Nick Wellnhofer).\n\n[0.25.2]\n\n  * Open files in binary mode (#113, Nick Wellnhofer).  Now that cmark\n    supports different line endings, files must be openend in binary mode\n    on Windows.\n  * Reset `partially_consumed_tab` on every new line (#114, Nick Wellnhofer).\n  * Handle buffer split across a CRLF line ending (#117).  Adds an internal\n    field to the parser struct to keep track of `last_buffer_ended_with_cr`.\n    Added test.\n\n[0.25.1]\n\n  * Release with no code changes.  cmark version was mistakenly set to\n    0.25.1 in the 0.25.0 release (#112), so this release just\n    ensures that this will cause no confusion later.\n\n[0.25.0]\n\n  * Fixed tabs in indentation (#101).  This patch fixes S_advance_offset\n    so that it doesn't gobble a tab character when advancing less than the\n    width of a tab.\n  * Added partially_consumed_tab to parser.  This keeps track of when we\n    have gotten partway through a tab when consuming initial indentation.\n  * Simplified add_line (only need parser parameter).\n  * Properly handle partially consumed tab.  E.g. in\n\n        - foo\n\n         <TAB><TAB>bar\n\n    we should consume two spaces from the second tab, including two spaces\n    in the code block.\n  * Properly handle tabs with blockquotes and fenced blocks.\n  * Fixed handling of tabs in lists.\n  * Clarified logic in S_advance_offset.\n  * Use an assertion to check for in-range html_block_type.\n    It's a programming error if the type is out of range.\n  * Refactored S_processLines to make the logic easier to\n    understand, and added documentation (Mathieu Duponchelle).\n  * Removed unnecessary check for empty string_content.\n  * Factored out contains_inlines.\n  * Moved the cmake minimum version to top line of CMakeLists.txt\n    (tinysun212).\n  * Fix ctype(3) usage on NetBSD (Kamil Rytarowski).  We need to cast value\n    passed to isspace(3) to unsigned char to explicitly prevent possibly\n    undefined behavior.\n  * Compile in plain C mode with MSVC 12.0 or newer (Nick Wellnhofer).\n    Under MSVC, we used to compile in C++ mode to get some C99 features\n    like mixing declarations and code. With newer MSVC versions, it's\n    possible to build in plain C mode.\n  * Switched from \"inline\" to \"CMARK_INLINE\" (Nick Wellnhofer).\n    Newer MSVC versions support enough of C99 to be able to compile cmark\n    in plain C mode. Only the \"inline\" keyword is still unsupported.\n    We have to use \"__inline\" instead.\n  * Added include guards to config.h\n  * config.h.in - added compatibility snprintf, vsnprintf for MSVC.\n  * Replaced sprintf with snprintf (Marco Benelli).\n  * config.h: include stdio.h for _vscprintf etc.\n  * Include starg.h when needed in config.h.\n  * Removed an unnecessary C99-ism in buffer.c.  This helps compiling on\n    systems like luarocks that don't have all the cmake configuration\n    goodness (thanks to carlmartus).\n  * Don't use variable length arrays (Nick Wellnhofer).\n    They're not supported by MSVC.\n  * Test with multiple MSVC versions under Appveyor (Nick Wellnhofer).\n  * Fix installation dir of man-pages on NetBSD (Kamil Rytarowski).\n  * Fixed typo in cmark.h comments (Chris Eidhof).\n  * Clarify in man page that cmark_node_free frees a node's children too.\n  * Fixed documentation of --width in man page.\n  * Require re2c >= 1.14.2 (#102).\n  * Generated scanners.c with more recent re2c.\n\n[0.24.1]\n\n  * Commonmark renderer:\n    + Use HTML comment, not two blank lines, to separate a list\n      item from a following code block or list.  This makes the\n      output more portable, since the \"two blank lines\" rule is\n      unique to CommonMark.  Also, it allows us to break out of\n      a sublist without breaking out of all levels of nesting.\n    + `is_autolink` - handle case where link has no children,\n      which previously caused a segfault.\n    + Use 4-space indent for bullet lists, for increased portability.\n    + Use 2-space + newline for line break for increased portability (#90).\n    + Improved punctuation escaping.  Previously all `)` and\n      `.` characters after digits were escaped; now they are\n      only escaped if they are genuinely in a position where\n      they'd cause a list item.  This is achieved by changes in\n      `render.c`: (a) `renderer->begin_content` is only set to\n      false after a string of digits at the beginning of the\n      line, and (b) we never break a line before a digit.\n      Also, `begin_content` is properly initialized to true.\n  * Handle NULL root in `consolidate_text_nodes`.\n\n[0.24.0]\n\n  * [API change] Added `cmark_node_replace(oldnode, newnode)`.\n  * Updated spec.txt to 0.24.\n  * Fixed edge case with escaped parens in link destination (#97).\n    This was also checked against the #82 case with asan.\n  * Removed unnecessary check for `fenced` in `cmark_render_html`.\n    It's sufficient to check that the info string is empty.\n    Indeed, those who use the API may well create a code block\n    with an info string without explicitly setting `fenced`.\n  * Updated format of `test/smart_punct.txt`.\n  * Updated `test/spec.txt`, `test/smart_punct.txt`, and\n    `spec_tests.py` to new format.\n  * Fixed `get_containing_block` logic in `src/commonmark.c`.\n    This did not allow for the possibility that a node might have no\n    containing block, causing the commonmark renderer to segfault if\n    passed an inline node with no block parent.\n  * Fixed string representations of `CUSTOM_BLOCK`,\n    `CUSTOM_INLINE`.  The old versions `raw_inline` and\n    `raw_block` were being used, and this led to incorrect xml output.\n  * Use default opts in python sample wrapper.\n  * Allow multiline setext header content, as per spec.\n  * Don't allow spaces in link destinations, even with pointy brackets.\n    Conforms to latest change in spec.\n  * Updated `scheme` scanner according to spec change.  We no longer use\n    a whitelist of valid schemes.\n  * Allow any kind of nodes as children of `CUSTOM_BLOCK` (#96).\n  * `cmark.h`: moved typedefs for iterator into iterator section.\n    This just moves some code around so it makes more sense\n    to read, and in the man page.\n  * Fixed `make_man_page.py` so it includes typedefs again.\n\n[0.23.0]\n\n  * [API change] Added `CUSTOM_BLOCK` and `CUSTOM_INLINE` node types.\n    They are never generated by the parser, and do not correspond\n    to CommonMark elements.  They are designed to be inserted by\n    filters that postprocess the AST.  For example, a filter might\n    convert specially marked code blocks to svg diagrams in HTML\n    and tikz diagrams in LaTeX, passing these through to the renderer\n    as a `CUSTOM_BLOCK`.  These nodes can have children, but they\n    also have literal text to be printed by the renderer \"on enter\"\n    and \"on exit.\" Added `cmark_node_get_on_enter`,\n    `cmark_node_set_on_enter`, `cmark_node_get_on_exit`,\n    `cmark_node_set_on_exit` to API.\n  * [API change] Rename `NODE_HTML` -> `NODE_HTML_BLOCK`,\n    `NODE_INLINE_HTML` -> `NODE_HTML_INLINE`.  Define aliases\n    so the old names still work, for backwards compatibility.\n  * [API change] Rename `CMARK_NODE_HEADER` -> `CMARK_NODE_HEADING`.\n    Note that for backwards compatibility, we have defined aliases:\n    `CMARK_NODE_HEADER` = `CMARK_NODE_HEADING`,\n    `cmark_node_get_header_level` = `cmark_node_get_heading_level`, and\n    `cmark_node_set_header_level` = `cmark_node_set_heading_level`.\n  * [API change] Rename `CMARK_NODE_HRULE` -> `CMARK_NODE_THEMATIC_BREAK`.\n    Defined the former as the latter for backwards compatibility.\n  * Don't allow space between link text and link label in a reference link\n    (spec change).\n  * Separate parsing and rendering opts in `cmark.h` (#88).\n    This change also changes some of these constants' numerical values,\n    but nothing should change in the API if you use the constants\n    themselves.  It should now be clear in the man page which\n    options affect parsing and which affect rendering.\n  * xml renderer - Added xmlns attribute to document node (jgm/CommonMark#87).\n  * Commonmark renderer:  ensure html blocks surrounded by blanks.\n    Otherwise we get failures of roundtrip tests.\n  * Commonmark renderer: ensure that literal characters get escaped\n    when they're at the beginning of a block, e.g.  `> \\- foo`.\n  * LaTeX renderer - better handling of internal links.\n    Now we render `[foo](#bar)` as `\\protect\\hyperlink{bar}{foo}`.\n  * Check for NULL pointer in _scan_at (#81).\n  * `Makefile.nmake`:  be more robust when cmake is missing.  Previously,\n    when cmake was missing, the build dir would be created anyway, and\n    subsequent attempts (even with cmake) would fail, because cmake would\n    not be run.  Depending on `build/CMakeFiles` is more robust -- this won't\n    be created unless cmake is run.  Partially addresses #85.\n  * Fixed DOCTYPE in xml output.\n  * commonmark.c: fix `size_t` to `int`.  This fixes an MSVC warning\n   \"conversion from 'size_t' to 'int', possible loss of data\" (Kevin Wojniak).\n  * Correct string length in `cmark_parse_document` example (Lee Jeffery).\n  * Fix non-ASCII end-of-line character check (andyuhnak).\n  * Fix \"declaration shadows a local variable\" (Kevin Wojniak).\n  * Install static library (jgm/CommonMark#381).\n  * Fix warnings about dropping const qualifier (Kevin Wojniak).\n  * Use full (unabbreviated) versions of constants (`CMARK_...`).\n  * Removed outdated targets from Makefile.\n  * Removed need for sudo in `make bench`.\n  * Improved benchmark.  Use longer test, since `time` has limited resolution.\n  * Removed `bench.h` and timing calls in `main.c`.\n  * Updated API docs; getters return empty strings if not set\n    rather than NULL, as previously documented.\n  * Added api_tests for custom nodes.\n  * Made roundtrip test part of the test suite run by cmake.\n  * Regenerate `scanners.c` using re2c 0.15.3.\n  * Adjusted scanner for link url.  This fixes a heap buffer overflow (#82).\n  * Added version number (1.0) to XML namespace.  We don't guarantee\n    stability in this until 1.0 is actually released, however.\n  * Removed obsolete `TIMER` macro.\n  * Make `LIB_INSTALL_DIR` configurable (Mathieu Bridon, #79).\n  * Removed out-of-date luajit wrapper.\n  * Use `input`, not `parser->curline` to determine last line length.\n  * Small optimizations in `_scan_at`.\n  * Replaced hard-coded 4 with `TAB_STOP`.\n  * Have `make format` reformat api tests as well.\n  * Added api tests for man, latex, commonmark, and xml renderers (#51).\n  * render.c:  added `begin_content` field.  This is like `begin_line` except\n    that it doesn't trigger production of the prefix.  So it can be set\n    after an initial prefix (say `> `) is printed by the renderer, and\n    consulted in determining whether to escape content that has a special\n    meaning at the beginning of a line.  Used in the commonmark renderer.\n  * Python 3.5 compatibility: don't require HTMLParseError (Zhiming Wang).\n    HTMLParseError was removed in Python 3.5. Since it could never be thrown\n    in Python 3.5+, we simply define a placeholder when HTMLParseError\n    cannot be imported.\n  * Set `convert_charrefs=False` in `normalize.py` (#83).  This defeats the\n    new default as of python 3.5, and allows the script to work with python\n    3.5.\n\n[0.22.0]\n\n  * Removed `pre` from blocktags scanner. `pre` is handled separately\n    in rule 1 and needn't be handled in rule 6.\n  * Added `iframe` to list of blocktags, as per spec change.\n  * Fixed bug with `HRULE` after blank line. This previously caused cmark\n    to break out of a list, thinking it had two consecutive blanks.\n  * Check for empty string before trying to look at line ending.\n  * Make sure every line fed to `S_process_line` ends with `\\n` (#72).\n    So `S_process_line` sees only unix style line endings. Ultimately we\n    probably want a better solution, allowing the line ending style of\n    the input file to be preserved. This solution forces output with newlines.\n  * Improved `cmark_strbuf_normalize_whitespace` (#73). Now all characters\n    that satisfy `cmark_isspace` are recognized as whitespace. Previously\n    `\\r` and `\\t` (and others) weren't included.\n  * Treat line ending with EOF as ending with newline (#71).\n  * Fixed `--hardbreaks` with `\\r\\n` line breaks (#68).\n  * Disallow list item starting with multiple blank lines (jgm/CommonMark#332).\n  * Allow tabs before closing `#`s in ATX header\n  * Removed `cmark_strbuf_printf` and `cmark_strbuf_vprintf`.\n    These are no longer needed, and cause complications for MSVC.\n    Also removed `HAVE_VA_COPY` and `HAVE_C99_SNPRINTF` feature tests.\n  * Added option to disable tests (Kevin Wojniak).\n  * Added `CMARK_INLINE` macro.\n  * Removed need to disable MSVC warnings 4267, 4244, 4800\n    (Kevin Wojniak).\n  * Fixed MSVC inline errors when cmark is included in sources that\n    don't have the same set of disabled warnings (Kevin Wojniak).\n  * Fix `FileNotFoundError` errors on tests when cmark is built from\n    another project via `add_subdirectory()` (Kevin Wojniak).\n  * Prefix `utf8proc` functions to avoid conflict with existing library\n    (Kevin Wojniak).\n  * Avoid name clash between Windows `.pdb` files (Nick Wellnhofer).\n  * Improved `smart_punct.txt` (see jgm/commonmark.js#61).\n  * Set `POSITION_INDEPENDENT_CODE` `ON` for static library (see #39).\n  * `make bench`: allow overriding `BENCHFILE`. Previously if you did\n    this, it would clopper `BENCHFILE` with the default bench file.\n  * `make bench`: Use -10 priority with renice.\n  * Improved `make_autolink`. Ensures that title is chunk with empty\n    string rather than NULL, as with other links.\n  * Added `clang-check` target.\n  * Travis: split `roundtrip_test` and `leakcheck` (OGINO Masanori).\n  * Use clang-format, llvm style, for formatting. Reformatted all source files.\n    Added `format` target to Makefile. Removed `astyle` target.\n    Updated `.editorconfig`.\n\n[0.21.0]\n\n  * Updated to version 0.21 of spec.\n  * Added latex renderer (#31). New exported function in API:\n    `cmark_render_latex`. New source file: `src/latex.hs`.\n  * Updates for new HTML block spec. Removed old `html_block_tag` scanner.\n    Added new `html_block_start` and `html_block_start_7`, as well\n    as `html_block_end_n` for n = 1-5. Rewrote block parser for new HTML\n    block spec.\n  * We no longer preprocess tabs to spaces before parsing.\n    Instead, we keep track of both the byte offset and\n    the (virtual) column as we parse block starts.\n    This allows us to handle tabs without converting\n    to spaces first.  Tabs are left as tabs in the output, as\n    per the revised spec.\n  * Removed utf8 validation by default.  We now replace null characters\n    in the line splitting code.\n  * Added `CMARK_OPT_VALIDATE_UTF8` option and command-line option\n    `--validate-utf8`.  This option causes cmark to check for valid\n    UTF-8, replacing invalid sequences with the replacement\n    character, U+FFFD.  Previously this was done by default in\n    connection with tab expansion, but we no longer do it by\n    default with the new tab treatment.  (Many applications will\n    know that the input is valid UTF-8, so validation will not\n    be necessary.)\n  * Added `CMARK_OPT_SAFE` option and `--safe` command-line flag.\n    + Added `CMARK_OPT_SAFE`.  This option disables rendering of raw HTML\n      and potentially dangerous links.\n    + Added `--safe` option in command-line program.\n    + Updated `cmark.3` man page.\n    + Added `scan_dangerous_url` to scanners.\n    + In HTML, suppress rendering of raw HTML and potentially dangerous\n      links if `CMARK_OPT_SAFE`.  Dangerous URLs are those that begin\n      with `javascript:`, `vbscript:`, `file:`, or `data:` (except for\n      `image/png`, `image/gif`, `image/jpeg`, or `image/webp` mime types).\n    + Added `api_test` for `OPT_CMARK_SAFE`.\n    + Rewrote `README.md` on security.\n  * Limit ordered list start to 9 digits, per spec.\n  * Added width parameter to `render_man` (API change).\n  * Extracted common renderer code from latex, man, and commonmark\n    renderers into a separate module, `renderer.[ch]` (#63).  To write a\n    renderer now, you only need to write a character escaping function\n    and a node rendering function.  You pass these to `cmark_render`\n    and it handles all the plumbing (including line wrapping) for you.\n    So far this is an internal module, but we might consider adding\n    it to the API in the future.\n  * commonmark writer:  correctly handle email autolinks.\n  * commonmark writer:  escape `!`.\n  * Fixed soft breaks in commonmark renderer.\n  * Fixed scanner for link url. re2c returns the longest match, so we\n    were getting bad results with `[link](foo\\(and\\(bar\\)\\))`\n    which it would parse as containing a bare `\\` followed by\n    an in-parens chunk ending with the final paren.\n  * Allow non-initial hyphens in html tag names. This allows for\n    custom tags, see jgm/CommonMark#239.\n  * Updated `test/smart_punct.txt`.\n  * Implemented new treatment of hyphens with `--smart`, converting\n    sequences of hyphens to sequences of em and en dashes that contain no\n    hyphens.\n  * HTML renderer:  properly split info on first space char (see\n    jgm/commonmark.js#54).\n  * Changed version variables to functions (#60, Andrius Bentkus).\n    This is easier to access using ffi, since some languages, like C#\n    like to use only function interfaces for accessing library\n    functionality.\n  * `process_emphasis`: Fixed setting lower bound to potential openers.\n    Renamed `potential_openers` -> `openers_bottom`.\n    Renamed `start_delim` -> `stack_bottom`.\n  * Added case for #59 to `pathological_test.py`.\n  * Fixed emphasis/link parsing bug (#59).\n  * Fixed off-by-one error in line splitting routine.\n    This caused certain NULLs not to be replaced.\n  * Don't rtrim in `subject_from_buffer`.  This gives bad results in\n    parsing reference links, where we might have trailing blanks\n    (`finalize` removes the bytes parsed as a reference definition;\n    before this change, some blank bytes might remain on the line).\n    + Added `column` and `first_nonspace_column` fields to `parser`.\n    + Added utility function to advance the offset, computing\n      the virtual column too.  Note that we don't need to deal with\n      UTF-8 here at all.  Only ASCII occurs in block starts.\n    + Significant performance improvement due to the fact that\n      we're not doing UTF-8 validation.\n  * Fixed entity lookup table.  The old one had many errors.\n    The new one is derived from the list in the npm entities package.\n    Since the sequences can now be longer (multi-code-point), we\n    have bumped the length limit from 4 to 8, which also affects\n    `houdini_html_u.c`.  An example of the kind of error that was fixed:\n    `&ngE;` should be rendered as \"\u2267\u0338\" (U+02267 U+00338), but it was\n    being rendered as \"\u2267\" (which is the same as `&gE;`).\n  * Replace gperf-based entity lookup with binary tree lookup.\n    The primary advantage is a big reduction in the size of\n    the compiled library and executable (> 100K).\n    There should be no measurable performance difference in\n    normal documents.  I detected only a slight performance\n    hit in a file containing 1,000,000 entities.\n    + Removed `src/html_unescape.gperf` and `src/html_unescape.h`.\n    + Added `src/entities.h` (generated by `tools/make_entities_h.py`).\n    + Added binary tree lookup functions to `houdini_html_u.c`, and\n      use the data in `src/entities.h`.\n    * Renamed `entities.h` -> `entities.inc`, and\n      `tools/make_entities_h.py` -> `tools/make_entitis_inc.py`.\n  * Fixed cases like\n    ```\n    [ref]: url\n    \"title\" ok\n    ```\n    Here we should parse the first line as a reference.\n  * `inlines.c`:  Added utility functions to skip spaces and line endings.\n  * Fixed backslashes in link destinations that are not part of escapes\n    (jgm/commonmark#45).\n  * `process_line`: Removed \"add newline if line doesn't have one.\"\n    This isn't actually needed.\n  * Small logic fixes and a simplification in `process_emphasis`.\n  * Added more pathological tests:\n    + Many link closers with no openers.\n    + Many link openers with no closers.\n    + Many emph openers with no closers.\n    + Many closers with no openers.\n    + `\"*a_ \" * 20000`.\n  * Fixed `process_emphasis` to handle new pathological cases.\n    Now we have an array of pointers (`potential_openers`),\n    keyed to the delim char.  When we've failed to match a potential opener\n    prior to point X in the delimiter stack, we reset `potential_openers`\n    for that opener type to X, and thus avoid having to look again through\n    all the openers we've already rejected.\n  * `process_inlines`:  remove closers from delim stack when possible.\n    When they have no matching openers and cannot be openers themselves,\n    we can safely remove them.  This helps with a performance case:\n    `\"a_ \" * 20000` (jgm/commonmark.js#43).\n  * Roll utf8proc_charlen into utf8proc_valid (Nick Wellnhofer).\n    Speeds up \"make bench\" by another percent.\n  * `spec_tests.py`: allow `\u2192` for tab in HTML examples.\n  * `normalize.py`:  don't collapse whitespace in pre contexts.\n  * Use utf-8 aware re2c.\n  * Makefile afl target:  removed `-m none`, added `CMARK_OPTS`.\n  * README: added `make afl` instructions.\n  * Limit generated generated `cmark.3` to 72 character line width.\n  * Travis: switched to containerized build system.\n  * Removed `debug.h`. (It uses GNU extensions, and we don't need it anyway.)\n  * Removed sundown from benchmarks, because the reading was anomalous.\n    sundown had an arbitrary 16MB limit on buffers, and the benchmark\n    input exceeded that.  So who knows what we were actually testing?\n    Added hoedown, sundown's successor, which is a better comparison.\n\n[0.20.0]\n\n  * Fixed bug in list item parsing when items indented >= 4 spaces (#52).\n  * Don't allow link labels with no non-whitespace characters\n    (jgm/CommonMark#322).\n  * Fixed multiple issues with numeric entities (#33, Nick Wellnhofer).\n  * Support CR and CRLF line endings (Ben Trask).\n  * Added test for different line endings to `api_test`.\n  * Allow NULL value in string setters (Nick Wellnhofer).  (NULL\n    produces a 0-length string value.)  Internally, URL and\n    title are now stored as `cmark_chunk` rather than `char *`.\n  * Fixed memory leak in `cmark_consolidate_text_nodes` (#32).\n  * Fixed `is_autolink` in the CommonMark renderer (#50).  Previously *any*\n    link with an absolute URL was treated as an autolink.\n  * Cope with broken `snprintf` on Windows (Nick Wellnhofer).  On Windows,\n    `snprintf` returns -1 if the output was truncated. Fall back to\n    Windows-specific `_scprintf`.\n  * Switched length parameter on `cmark_markdown_to_html`,\n    `cmark_parser_feed`, and `cmark_parse_document` from `int`\n    to `size_t` (#53, Nick Wellnhofer).\n  * Use a custom type `bufsize_t` for all string sizes and indices.\n    This allows to switch to 64-bit string buffers by changing a single\n    typedef and a macro definition (Nick Wellnhofer).\n  * Hardened the `strbuf` code, checking for integer overflows and\n    adding range checks (Nick Wellnhofer).\n  * Removed unused function `cmark_strbuf_attach` (Nick Wellnhofer).\n  * Fixed all implicit 64-bit to 32-bit conversions that\n    `-Wshorten-64-to-32` warns about (Nick Wellnhofer).\n  * Added helper function `cmark_strbuf_safe_strlen` that converts\n    from `size_t` to `bufsize_t` and throws an error in case of\n    an overflow (Nick Wellnhofer).\n  * Abort on `strbuf` out of memory errors (Nick Wellnhofer).\n    Previously such errors were not being trapped.  This involves\n    some internal changes to the `buffer` library that do not affect\n    the API.\n  * Factored out `S_find_first_nonspace` in `S_proces_line`.\n    Added fields `offset`, `first_nonspace`, `indent`, and `blank`\n    to `cmark_parser` struct.  This just removes some repetition.\n  * Added Racket Racket (5.3+) wrapper (Eli Barzilay).\n  * Removed `-pg` from Debug build flags (#47).\n  * Added Ubsan build target, to check for undefined behavior.\n  * Improved `make leakcheck`.  We now return an error status if anything\n    in the loop fails.  We now check `--smart` and `--normalize` options.\n  * Removed `wrapper3.py`, made `wrapper.py` work with python 2 and 3.\n    Also improved the wrapper to work with Windows, and to use smart\n    punctuation (as an example).\n  * In `wrapper.rb`, added argument for options.\n  * Revised luajit wrapper.\n  * Added build status badges to README.md.\n  * Added links to go, perl, ruby, R, and Haskell bindings to README.md.\n\n[0.19.0]\n\n  * Fixed `_` emphasis parsing to conform to spec (jgm/CommonMark#317).\n  * Updated `spec.txt`.\n  * Compile static library with `-DCMARK_STATIC_DEFINE` (Nick Wellnhofer).\n  * Suppress warnings about Windows runtime library files (Nick Wellnhofer).\n    Visual Studio Express editions do not include the redistributable files.\n    Set `CMAKE_INSTALL_SYSTEM_RUNTIME_LIBS_NO_WARNINGS` to suppress warnings.\n  * Added appyeyor: Windows continuous integration (`appveyor.yml`).\n  * Use `os.path.join` in `test/cmark.py` for proper cross-platform paths.\n  * Fixed `Makefile.nmake`.\n  * Improved `make afl`:  added `test/afl_dictionary`, increased timeout\n    for hangs.\n  * Improved README with a description of the library's strengths.\n  * Pass-through Unicode non-characters (Nick Wellnhofer).\n    Despite their name, Unicode non-characters are valid code points. They\n    should be passed through by a library like libcmark.\n  * Check return status of `utf8proc_iterate` (#27).\n\n[0.18.3]\n\n  * Include patch level in soname (Nick Wellnhofer). Minor version is\n    tied to spec version, so this allows breaking the ABI between spec\n    releases.\n  * Install compiler-provided system runtime libraries (Changjiang Yang).\n  * Use `strbuf_printf` instead of `snprintf`. `snprintf` is not\n    available on some platforms (Visual Studio 2013 and earlier).\n  * Fixed memory access bug: \"invalid read of size 1\" on input `[link](<>)`.\n\n[0.18.2]\n\n  * Added commonmark renderer: `cmark_render_commonmark`. In addition\n    to options, this takes a `width` parameter.  A value of 0 disables\n    wrapping; a positive value wraps the document to the specified\n    width.  Note that width is automatically set to 0 if the\n    `CMARK_OPT_HARDBREAKS` option is set.\n  * The `cmark` executable now allows `-t commonmark` for output as\n    CommonMark.  A `--width` option has been added to specify wrapping\n    width.\n  * Added `roundtrip_test` Makefile target.  This runs all the spec\n    through the commonmark renderer, and then through the commonmark\n    parser, and compares normalized HTML to the test.  All tests pass\n    with the current parser and renderer, giving us some confidence that\n    the commonmark renderer is sufficiently robust.  Eventually this\n    should be pythonized and put in the cmake test routine.\n  * Removed an unnecessary check in `blocks.c`.  By the time we check\n    for a list start, we've already checked for a horizontal rule, so\n    we don't need to repeat that check here.  Thanks to Robin Stocker for\n    pointing out a similar redundancy in commonmark.js.\n  * Fixed bug in `cmark_strbuf_unescape` (`buffer.c`).  The old function\n    gave incorrect results on input like `\\\\*`, since the next backslash\n    would be treated as escaping the `*` instead of being escaped itself.\n  * `scanners.re`:  added `_scan_scheme`, `scan_scheme`, used in the\n    commonmark renderer.\n  * Check for `CMAKE_C_COMPILER` (not `CC_COMPILER`) when setting C flags.\n  * Update code examples in documentation, adding new parser option\n    argument, and using `CMARK_OPT_DEFAULT` (Nick Wellnhofer).\n  * Added options parameter to `cmark_markdown_to_html`.\n  * Removed obsolete reference to `CMARK_NODE_LINK_LABEL`.\n  * `make leakcheck` now checks all output formats.\n  * `test/cmark.py`:  set default options for `markdown_to_html`.\n  * Warn about buggy re2c versions (Nick Wellnhofer).\n\n[0.18.1]\n\n  * Build static version of library in default build (#11).\n  * `cmark.h`:  Add missing argument to `cmark_parser_new` (#12).\n\n[0.18]\n\n  * Switch to 2-clause BSD license, with agreement of contributors.\n  * Added Profile build type, `make prof` target.\n  * Fixed autolink scanner to conform to the spec. Backslash escapes\n    not allowed in autolinks.\n  * Don't rely on strnlen being available (Nick Wellnhofer).\n  * Updated scanners for new whitespace definition.\n  * Added `CMARK_OPT_SMART` and `--smart` option, `smart.c`, `smart.h`.\n  * Added test for `--smart` option.\n  * Fixed segfault with --normalize (closes #7).\n  * Moved normalization step from XML renderer to `cmark_parser_finish`.\n  * Added options parameter to `cmark_parse_document`, `cmark_parse_file`.\n  * Fixed man renderer's escaping for unicode characters.\n  * Don't require python3 to make `cmark.3` man page.\n  * Use ASCII escapes for punctuation characters for portability.\n  * Made `options` an int rather than a long, for consistency.\n  * Packed `cmark_node` struct to fit into 128 bytes.\n    This gives a small performance boost and lowers memory usage.\n  * Repacked `delimiter` struct to avoid hole.\n  * Fixed use-after-free bug, which arose when a paragraph containing\n    only reference links and blank space was finalized (#9).\n    Avoid using `parser->current` in the loop that creates new\n    blocks, since `finalize` in `add_child` may have removed\n    the current parser (if it contains only reference definitions).\n    This isn't a great solution; in the long run we need to rewrite\n    to make the logic clearer and to make it harder to make\n    mistakes like this one.\n  * Added 'Asan' build type. `make asan` will link against ASan; the\n    resulting executable will do checks for memory access issues.\n    Thanks @JordanMilne for the suggestion.\n  * Add Makefile target to fuzz with AFL (Nick Wellnhofer)\n    The variable `$AFL_PATH` must point to the directory containing the AFL\n    binaries. It can be set as an environment variable or passed to make on\n    the command line.\n\n[0.17]\n\n  * Stripped out all JavaScript related code and documentation, moving\n    it to a separate repository (<https://github.com/jgm/commonmark.js>).\n  * Improved Makefile targets, so that `cmake` is run again only when\n    necessary (Nick Wellnhofer).\n  * Added `INSTALL_PREFIX` to the Makefile, allowing installation to a\n    location other than `/usr/local` without invoking `cmake`\n    manually (Nick Wellnhofer).\n  * `make test` now guarantees that the project will\n    be rebuilt before tests are run (Nick Wellnhofer).\n  * Prohibited overriding of some Makefile variables (Nick Wellnhofer).\n  * Provide version number and string, both as macros\n    (`CMARK_VERSION`, `CMARK_VERSION_STRING`) and as symbols\n    (`cmark_version`, `cmark_version_string`) (Nick Wellnhofer).  All of\n    these come from `cmark_version.h`, which is constructed from a\n    template `cmark_version.h.in` and data in `CMakeLists.txt`.\n  * Avoid calling `free` on null pointer.\n  * Added an accessor for an iterator's root node (`cmark_iter_get_root`).\n  * Added user data field for nodes (Nick Wellnhofer).  This is\n    intended mainly for use in bindings for dynamic languages, where\n    it could store a pointer to a target language object (#287).  But\n    it can be used for anything.\n  * Man renderer:  properly escape multiline strings.\n  * Added assertion to raise error if finalize is called on a closed block.\n  * Implemented the new spec rule for emphasis and strong emphasis with `_`.\n  * Moved the check for fence-close with the other checks for end-of-block.\n  * Fixed a bug with loose list detection with items containings\n    fenced code blocks (#285).\n  * Removed recursive algorithm in `ends_with_blank_line` (#286).\n  * Minor code reformatting: renamed parameters.\n\n[0.16]\n\n  * Added xml renderer (XML representation of the CommonMark AST,\n    which is described in `CommonMark.dtd`).\n  * Reduced size of gperf entity table (Nick Wellnhofer).\n  * Reworked iterators to allow deletion of nodes during iteration\n    (Nick Wellnhofer).\n  * Optimized `S_is_leaf`.\n  * Added `cmark_iter_reset` to iterator API.\n  * Added `cmark_consolidate_text_nodes` to API to combine adjacent\n    text nodes.\n  * Added `CMARK_OPT_NORMALIZE` to options (this combines adjacent\n    text nodes).\n  * Added `--normalize` option to command-line program.\n  * Improved regex for HTML comments in inline parsing.\n  * Python is no longer required for a basic build from the\n    repository.\n", "#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n\n#include \"cmark_ctype.h\"\n#include \"config.h\"\n#include \"node.h\"\n#include \"parser.h\"\n#include \"references.h\"\n#include \"cmark-gfm.h\"\n#include \"houdini.h\"\n#include \"utf8.h\"\n#include \"scanners.h\"\n#include \"inlines.h\"\n#include \"syntax_extension.h\"\n\nstatic const char *EMDASH = \"\\xE2\\x80\\x94\";\nstatic const char *ENDASH = \"\\xE2\\x80\\x93\";\nstatic const char *ELLIPSES = \"\\xE2\\x80\\xA6\";\nstatic const char *LEFTDOUBLEQUOTE = \"\\xE2\\x80\\x9C\";\nstatic const char *RIGHTDOUBLEQUOTE = \"\\xE2\\x80\\x9D\";\nstatic const char *LEFTSINGLEQUOTE = \"\\xE2\\x80\\x98\";\nstatic const char *RIGHTSINGLEQUOTE = \"\\xE2\\x80\\x99\";\n\n// Macros for creating various kinds of simple.\n#define make_str(subj, sc, ec, s) make_literal(subj, CMARK_NODE_TEXT, sc, ec, s)\n#define make_code(subj, sc, ec, s) make_literal(subj, CMARK_NODE_CODE, sc, ec, s)\n#define make_raw_html(subj, sc, ec, s) make_literal(subj, CMARK_NODE_HTML_INLINE, sc, ec, s)\n#define make_linebreak(mem) make_simple(mem, CMARK_NODE_LINEBREAK)\n#define make_softbreak(mem) make_simple(mem, CMARK_NODE_SOFTBREAK)\n#define make_emph(mem) make_simple(mem, CMARK_NODE_EMPH)\n#define make_strong(mem) make_simple(mem, CMARK_NODE_STRONG)\n\n#define MAXBACKTICKS 80\n\ntypedef struct bracket {\n  struct bracket *previous;\n  struct delimiter *previous_delimiter;\n  cmark_node *inl_text;\n  bufsize_t position;\n  bool image;\n  bool active;\n  bool bracket_after;\n  bool in_bracket_image0;\n  bool in_bracket_image1;\n} bracket;\n\ntypedef struct subject{\n  cmark_mem *mem;\n  cmark_chunk input;\n  int line;\n  bufsize_t pos;\n  int block_offset;\n  int column_offset;\n  cmark_map *refmap;\n  delimiter *last_delim;\n  bracket *last_bracket;\n  bufsize_t backticks[MAXBACKTICKS + 1];\n  bool scanned_for_backticks;\n} subject;\n\n// Extensions may populate this.\nstatic int8_t SKIP_CHARS[256];\n\nstatic CMARK_INLINE bool S_is_line_end_char(char c) {\n  return (c == '\\n' || c == '\\r');\n}\n\nstatic delimiter *S_insert_emph(subject *subj, delimiter *opener,\n                                delimiter *closer);\n\nstatic int parse_inline(cmark_parser *parser, subject *subj, cmark_node *parent, int options);\n\nstatic void subject_from_buf(cmark_mem *mem, int line_number, int block_offset, subject *e,\n                             cmark_chunk *buffer, cmark_map *refmap);\nstatic bufsize_t subject_find_special_char(subject *subj, int options);\n\n// Create an inline with a literal string value.\nstatic CMARK_INLINE cmark_node *make_literal(subject *subj, cmark_node_type t,\n                                             int start_column, int end_column,\n                                             cmark_chunk s) {\n  cmark_node *e = (cmark_node *)subj->mem->calloc(1, sizeof(*e));\n  cmark_strbuf_init(subj->mem, &e->content, 0);\n  e->type = (uint16_t)t;\n  e->as.literal = s;\n  e->start_line = e->end_line = subj->line;\n  // columns are 1 based.\n  e->start_column = start_column + 1 + subj->column_offset + subj->block_offset;\n  e->end_column = end_column + 1 + subj->column_offset + subj->block_offset;\n  return e;\n}\n\n// Create an inline with no value.\nstatic CMARK_INLINE cmark_node *make_simple(cmark_mem *mem, cmark_node_type t) {\n  cmark_node *e = (cmark_node *)mem->calloc(1, sizeof(*e));\n  cmark_strbuf_init(mem, &e->content, 0);\n  e->type = (uint16_t)t;\n  return e;\n}\n\n// Like make_str, but parses entities.\nstatic cmark_node *make_str_with_entities(subject *subj,\n                                          int start_column, int end_column,\n                                          cmark_chunk *content) {\n  cmark_strbuf unescaped = CMARK_BUF_INIT(subj->mem);\n\n  if (houdini_unescape_html(&unescaped, content->data, content->len)) {\n    return make_str(subj, start_column, end_column, cmark_chunk_buf_detach(&unescaped));\n  } else {\n    return make_str(subj, start_column, end_column, *content);\n  }\n}\n\n// Duplicate a chunk by creating a copy of the buffer not by reusing the\n// buffer like cmark_chunk_dup does.\nstatic cmark_chunk chunk_clone(cmark_mem *mem, cmark_chunk *src) {\n  cmark_chunk c;\n  bufsize_t len = src->len;\n\n  c.len = len;\n  c.data = (unsigned char *)mem->calloc(len + 1, 1);\n  c.alloc = 1;\n  if (len)\n    memcpy(c.data, src->data, len);\n  c.data[len] = '\\0';\n\n  return c;\n}\n\nstatic cmark_chunk cmark_clean_autolink(cmark_mem *mem, cmark_chunk *url,\n                                        int is_email) {\n  cmark_strbuf buf = CMARK_BUF_INIT(mem);\n\n  cmark_chunk_trim(url);\n\n  if (url->len == 0) {\n    cmark_chunk result = CMARK_CHUNK_EMPTY;\n    return result;\n  }\n\n  if (is_email)\n    cmark_strbuf_puts(&buf, \"mailto:\");\n\n  houdini_unescape_html_f(&buf, url->data, url->len);\n  return cmark_chunk_buf_detach(&buf);\n}\n\nstatic CMARK_INLINE cmark_node *make_autolink(subject *subj,\n                                              int start_column, int end_column,\n                                              cmark_chunk url, int is_email) {\n  cmark_node *link = make_simple(subj->mem, CMARK_NODE_LINK);\n  link->as.link.url = cmark_clean_autolink(subj->mem, &url, is_email);\n  link->as.link.title = cmark_chunk_literal(\"\");\n  link->start_line = link->end_line = subj->line;\n  link->start_column = start_column + 1;\n  link->end_column = end_column + 1;\n  cmark_node_append_child(link, make_str_with_entities(subj, start_column + 1, end_column - 1, &url));\n  return link;\n}\n\nstatic void subject_from_buf(cmark_mem *mem, int line_number, int block_offset, subject *e,\n                             cmark_chunk *chunk, cmark_map *refmap) {\n  int i;\n  e->mem = mem;\n  e->input = *chunk;\n  e->line = line_number;\n  e->pos = 0;\n  e->block_offset = block_offset;\n  e->column_offset = 0;\n  e->refmap = refmap;\n  e->last_delim = NULL;\n  e->last_bracket = NULL;\n  for (i = 0; i <= MAXBACKTICKS; i++) {\n    e->backticks[i] = 0;\n  }\n  e->scanned_for_backticks = false;\n}\n\nstatic CMARK_INLINE int isbacktick(int c) { return (c == '`'); }\n\nstatic CMARK_INLINE unsigned char peek_char_n(subject *subj, bufsize_t n) {\n  // NULL bytes should have been stripped out by now.  If they're\n  // present, it's a programming error:\n  assert(!(subj->pos + n < subj->input.len && subj->input.data[subj->pos + n] == 0));\n  return (subj->pos + n < subj->input.len) ? subj->input.data[subj->pos + n] : 0;\n}\n\nstatic CMARK_INLINE unsigned char peek_char(subject *subj) {\n  return peek_char_n(subj, 0);\n}\n\nstatic CMARK_INLINE unsigned char peek_at(subject *subj, bufsize_t pos) {\n  return subj->input.data[pos];\n}\n\n// Return true if there are more characters in the subject.\nstatic CMARK_INLINE int is_eof(subject *subj) {\n  return (subj->pos >= subj->input.len);\n}\n\n// Advance the subject.  Doesn't check for eof.\n#define advance(subj) (subj)->pos += 1\n\nstatic CMARK_INLINE bool skip_spaces(subject *subj) {\n  bool skipped = false;\n  while (peek_char(subj) == ' ' || peek_char(subj) == '\\t') {\n    advance(subj);\n    skipped = true;\n  }\n  return skipped;\n}\n\nstatic CMARK_INLINE bool skip_line_end(subject *subj) {\n  bool seen_line_end_char = false;\n  if (peek_char(subj) == '\\r') {\n    advance(subj);\n    seen_line_end_char = true;\n  }\n  if (peek_char(subj) == '\\n') {\n    advance(subj);\n    seen_line_end_char = true;\n  }\n  return seen_line_end_char || is_eof(subj);\n}\n\n// Take characters while a predicate holds, and return a string.\nstatic CMARK_INLINE cmark_chunk take_while(subject *subj, int (*f)(int)) {\n  unsigned char c;\n  bufsize_t startpos = subj->pos;\n  bufsize_t len = 0;\n\n  while ((c = peek_char(subj)) && (*f)(c)) {\n    advance(subj);\n    len++;\n  }\n\n  return cmark_chunk_dup(&subj->input, startpos, len);\n}\n\n// Return the number of newlines in a given span of text in a subject.  If\n// the number is greater than zero, also return the number of characters\n// between the last newline and the end of the span in `since_newline`.\nstatic int count_newlines(subject *subj, bufsize_t from, bufsize_t len, int *since_newline) {\n  int nls = 0;\n  int since_nl = 0;\n\n  while (len--) {\n    if (subj->input.data[from++] == '\\n') {\n      ++nls;\n      since_nl = 0;\n    } else {\n      ++since_nl;\n    }\n  }\n\n  if (!nls)\n    return 0;\n\n  *since_newline = since_nl;\n  return nls;\n}\n\n// Adjust `node`'s `end_line`, `end_column`, and `subj`'s `line` and\n// `column_offset` according to the number of newlines in a just-matched span\n// of text in `subj`.\nstatic void adjust_subj_node_newlines(subject *subj, cmark_node *node, int matchlen, int extra, int options) {\n  if (!(options & CMARK_OPT_SOURCEPOS)) {\n    return;\n  }\n\n  int since_newline;\n  int newlines = count_newlines(subj, subj->pos - matchlen - extra, matchlen, &since_newline);\n  if (newlines) {\n    subj->line += newlines;\n    node->end_line += newlines;\n    node->end_column = since_newline;\n    subj->column_offset = -subj->pos + since_newline + extra;\n  }\n}\n\n// Try to process a backtick code span that began with a\n// span of ticks of length openticklength length (already\n// parsed).  Return 0 if you don't find matching closing\n// backticks, otherwise return the position in the subject\n// after the closing backticks.\nstatic bufsize_t scan_to_closing_backticks(subject *subj,\n                                           bufsize_t openticklength) {\n\n  bool found = false;\n  if (openticklength > MAXBACKTICKS) {\n    // we limit backtick string length because of the array subj->backticks:\n    return 0;\n  }\n  if (subj->scanned_for_backticks &&\n      subj->backticks[openticklength] <= subj->pos) {\n    // return if we already know there's no closer\n    return 0;\n  }\n  while (!found) {\n    // read non backticks\n    unsigned char c;\n    while ((c = peek_char(subj)) && c != '`') {\n      advance(subj);\n    }\n    if (is_eof(subj)) {\n      break;\n    }\n    bufsize_t numticks = 0;\n    while (peek_char(subj) == '`') {\n      advance(subj);\n      numticks++;\n    }\n    // store position of ender\n    if (numticks <= MAXBACKTICKS) {\n      subj->backticks[numticks] = subj->pos - numticks;\n    }\n    if (numticks == openticklength) {\n      return (subj->pos);\n    }\n  }\n  // got through whole input without finding closer\n  subj->scanned_for_backticks = true;\n  return 0;\n}\n\n// Destructively modify string, converting newlines to\n// spaces, then removing a single leading + trailing space,\n// unless the code span consists entirely of space characters.\nstatic void S_normalize_code(cmark_strbuf *s) {\n  bufsize_t r, w;\n  bool contains_nonspace = false;\n\n  for (r = 0, w = 0; r < s->size; ++r) {\n    switch (s->ptr[r]) {\n    case '\\r':\n      if (s->ptr[r + 1] != '\\n') {\n\ts->ptr[w++] = ' ';\n      }\n      break;\n    case '\\n':\n      s->ptr[w++] = ' ';\n      break;\n    default:\n      s->ptr[w++] = s->ptr[r];\n    }\n    if (s->ptr[r] != ' ') {\n      contains_nonspace = true;\n    }\n  }\n\n  // begins and ends with space?\n  if (contains_nonspace &&\n      s->ptr[0] == ' ' && s->ptr[w - 1] == ' ') {\n    cmark_strbuf_drop(s, 1);\n    cmark_strbuf_truncate(s, w - 2);\n  } else {\n    cmark_strbuf_truncate(s, w);\n  }\n\n}\n\n\n// Parse backtick code section or raw backticks, return an inline.\n// Assumes that the subject has a backtick at the current position.\nstatic cmark_node *handle_backticks(subject *subj, int options) {\n  cmark_chunk openticks = take_while(subj, isbacktick);\n  bufsize_t startpos = subj->pos;\n  bufsize_t endpos = scan_to_closing_backticks(subj, openticks.len);\n\n  if (endpos == 0) {      // not found\n    subj->pos = startpos; // rewind\n    return make_str(subj, subj->pos, subj->pos, openticks);\n  } else {\n    cmark_strbuf buf = CMARK_BUF_INIT(subj->mem);\n\n    cmark_strbuf_set(&buf, subj->input.data + startpos,\n                     endpos - startpos - openticks.len);\n    S_normalize_code(&buf);\n\n    cmark_node *node = make_code(subj, startpos, endpos - openticks.len - 1, cmark_chunk_buf_detach(&buf));\n    adjust_subj_node_newlines(subj, node, endpos - startpos, openticks.len, options);\n    return node;\n  }\n}\n\n\n// Scan ***, **, or * and return number scanned, or 0.\n// Advances position.\nstatic int scan_delims(subject *subj, unsigned char c, bool *can_open,\n                       bool *can_close) {\n  int numdelims = 0;\n  bufsize_t before_char_pos, after_char_pos;\n  int32_t after_char = 0;\n  int32_t before_char = 0;\n  int len;\n  bool left_flanking, right_flanking;\n\n  if (subj->pos == 0) {\n    before_char = 10;\n  } else {\n    before_char_pos = subj->pos - 1;\n    // walk back to the beginning of the UTF_8 sequence:\n    while ((peek_at(subj, before_char_pos) >> 6 == 2 || SKIP_CHARS[peek_at(subj, before_char_pos)]) && before_char_pos > 0) {\n      before_char_pos -= 1;\n    }\n    len = cmark_utf8proc_iterate(subj->input.data + before_char_pos,\n                                 subj->pos - before_char_pos, &before_char);\n    if (len == -1 || (before_char < 256 && SKIP_CHARS[(unsigned char) before_char])) {\n      before_char = 10;\n    }\n  }\n\n  if (c == '\\'' || c == '\"') {\n    numdelims++;\n    advance(subj); // limit to 1 delim for quotes\n  } else {\n    while (peek_char(subj) == c) {\n      numdelims++;\n      advance(subj);\n    }\n  }\n\n  if (subj->pos == subj->input.len) {\n    after_char = 10;\n  } else {\n    after_char_pos = subj->pos;\n    while (SKIP_CHARS[peek_at(subj, after_char_pos)] && after_char_pos < subj->input.len) {\n      after_char_pos += 1;\n    }\n    len = cmark_utf8proc_iterate(subj->input.data + after_char_pos,\n                                 subj->input.len - after_char_pos, &after_char);\n    if (len == -1 || (after_char < 256 && SKIP_CHARS[(unsigned char) after_char])) {\n    after_char = 10;\n  }\n  }\n\n  left_flanking = numdelims > 0 && !cmark_utf8proc_is_space(after_char) &&\n                  (!cmark_utf8proc_is_punctuation(after_char) ||\n                   cmark_utf8proc_is_space(before_char) ||\n                   cmark_utf8proc_is_punctuation(before_char));\n  right_flanking = numdelims > 0 && !cmark_utf8proc_is_space(before_char) &&\n                   (!cmark_utf8proc_is_punctuation(before_char) ||\n                    cmark_utf8proc_is_space(after_char) ||\n                    cmark_utf8proc_is_punctuation(after_char));\n  if (c == '_') {\n    *can_open = left_flanking &&\n                (!right_flanking || cmark_utf8proc_is_punctuation(before_char));\n    *can_close = right_flanking &&\n                 (!left_flanking || cmark_utf8proc_is_punctuation(after_char));\n  } else if (c == '\\'' || c == '\"') {\n    *can_open = left_flanking && !right_flanking &&\n\t         before_char != ']' && before_char != ')';\n    *can_close = right_flanking;\n  } else {\n    *can_open = left_flanking;\n    *can_close = right_flanking;\n  }\n  return numdelims;\n}\n\n/*\nstatic void print_delimiters(subject *subj)\n{\n        delimiter *delim;\n        delim = subj->last_delim;\n        while (delim != NULL) {\n                printf(\"Item at stack pos %p: %d %d %d next(%p) prev(%p)\\n\",\n                       (void*)delim, delim->delim_char,\n                       delim->can_open, delim->can_close,\n                       (void*)delim->next, (void*)delim->previous);\n                delim = delim->previous;\n        }\n}\n*/\n\nstatic void remove_delimiter(subject *subj, delimiter *delim) {\n  if (delim == NULL)\n    return;\n  if (delim->next == NULL) {\n    // end of list:\n    assert(delim == subj->last_delim);\n    subj->last_delim = delim->previous;\n  } else {\n    delim->next->previous = delim->previous;\n  }\n  if (delim->previous != NULL) {\n    delim->previous->next = delim->next;\n  }\n  subj->mem->free(delim);\n}\n\nstatic void pop_bracket(subject *subj) {\n  bracket *b;\n  if (subj->last_bracket == NULL)\n    return;\n  b = subj->last_bracket;\n  subj->last_bracket = subj->last_bracket->previous;\n  subj->mem->free(b);\n}\n\nstatic void push_delimiter(subject *subj, unsigned char c, bool can_open,\n                           bool can_close, cmark_node *inl_text) {\n  delimiter *delim = (delimiter *)subj->mem->calloc(1, sizeof(delimiter));\n  delim->delim_char = c;\n  delim->can_open = can_open;\n  delim->can_close = can_close;\n  delim->inl_text = inl_text;\n  delim->length = inl_text->as.literal.len;\n  delim->previous = subj->last_delim;\n  delim->next = NULL;\n  if (delim->previous != NULL) {\n    delim->previous->next = delim;\n  }\n  subj->last_delim = delim;\n}\n\nstatic void push_bracket(subject *subj, bool image, cmark_node *inl_text) {\n  bracket *b = (bracket *)subj->mem->calloc(1, sizeof(bracket));\n  if (subj->last_bracket != NULL) {\n    subj->last_bracket->bracket_after = true;\n    b->in_bracket_image0 = subj->last_bracket->in_bracket_image0;\n    b->in_bracket_image1 = subj->last_bracket->in_bracket_image1;\n  }\n  b->image = image;\n  b->active = true;\n  b->inl_text = inl_text;\n  b->previous = subj->last_bracket;\n  b->previous_delimiter = subj->last_delim;\n  b->position = subj->pos;\n  b->bracket_after = false;\n  if (image) {\n    b->in_bracket_image1 = true;\n  } else {\n    b->in_bracket_image0 = true;\n  }\n  subj->last_bracket = b;\n}\n\n// Assumes the subject has a c at the current position.\nstatic cmark_node *handle_delim(subject *subj, unsigned char c, bool smart) {\n  bufsize_t numdelims;\n  cmark_node *inl_text;\n  bool can_open, can_close;\n  cmark_chunk contents;\n\n  numdelims = scan_delims(subj, c, &can_open, &can_close);\n\n  if (c == '\\'' && smart) {\n    contents = cmark_chunk_literal(RIGHTSINGLEQUOTE);\n  } else if (c == '\"' && smart) {\n    contents =\n        cmark_chunk_literal(can_close ? RIGHTDOUBLEQUOTE : LEFTDOUBLEQUOTE);\n  } else {\n    contents = cmark_chunk_dup(&subj->input, subj->pos - numdelims, numdelims);\n  }\n\n  inl_text = make_str(subj, subj->pos - numdelims, subj->pos - 1, contents);\n\n  if ((can_open || can_close) && (!(c == '\\'' || c == '\"') || smart)) {\n    push_delimiter(subj, c, can_open, can_close, inl_text);\n  }\n\n  return inl_text;\n}\n\n// Assumes we have a hyphen at the current position.\nstatic cmark_node *handle_hyphen(subject *subj, bool smart) {\n  int startpos = subj->pos;\n\n  advance(subj);\n\n  if (!smart || peek_char(subj) != '-') {\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"-\"));\n  }\n\n  while (smart && peek_char(subj) == '-') {\n    advance(subj);\n  }\n\n  int numhyphens = subj->pos - startpos;\n  int en_count = 0;\n  int em_count = 0;\n  int i;\n  cmark_strbuf buf = CMARK_BUF_INIT(subj->mem);\n\n  if (numhyphens % 3 == 0) { // if divisible by 3, use all em dashes\n    em_count = numhyphens / 3;\n  } else if (numhyphens % 2 == 0) { // if divisible by 2, use all en dashes\n    en_count = numhyphens / 2;\n  } else if (numhyphens % 3 == 2) { // use one en dash at end\n    en_count = 1;\n    em_count = (numhyphens - 2) / 3;\n  } else { // use two en dashes at the end\n    en_count = 2;\n    em_count = (numhyphens - 4) / 3;\n  }\n\n  for (i = em_count; i > 0; i--) {\n    cmark_strbuf_puts(&buf, EMDASH);\n  }\n\n  for (i = en_count; i > 0; i--) {\n    cmark_strbuf_puts(&buf, ENDASH);\n  }\n\n  return make_str(subj, startpos, subj->pos - 1, cmark_chunk_buf_detach(&buf));\n}\n\n// Assumes we have a period at the current position.\nstatic cmark_node *handle_period(subject *subj, bool smart) {\n  advance(subj);\n  if (smart && peek_char(subj) == '.') {\n    advance(subj);\n    if (peek_char(subj) == '.') {\n      advance(subj);\n      return make_str(subj, subj->pos - 3, subj->pos - 1, cmark_chunk_literal(ELLIPSES));\n    } else {\n      return make_str(subj, subj->pos - 2, subj->pos - 1, cmark_chunk_literal(\"..\"));\n    }\n  } else {\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\".\"));\n  }\n}\n\nstatic cmark_syntax_extension *get_extension_for_special_char(cmark_parser *parser, unsigned char c) {\n  cmark_llist *tmp_ext;\n\n  for (tmp_ext = parser->inline_syntax_extensions; tmp_ext; tmp_ext=tmp_ext->next) {\n    cmark_syntax_extension *ext = (cmark_syntax_extension *) tmp_ext->data;\n    cmark_llist *tmp_char;\n    for (tmp_char = ext->special_inline_chars; tmp_char; tmp_char=tmp_char->next) {\n      unsigned char tmp_c = (unsigned char)(size_t)tmp_char->data;\n\n      if (tmp_c == c) {\n        return ext;\n      }\n    }\n  }\n\n  return NULL;\n}\n\nstatic void process_emphasis(cmark_parser *parser, subject *subj, delimiter *stack_bottom) {\n  delimiter *closer = subj->last_delim;\n  delimiter *opener;\n  delimiter *old_closer;\n  bool opener_found;\n  delimiter *openers_bottom[3][128];\n  int i;\n\n  // initialize openers_bottom:\n  memset(&openers_bottom, 0, sizeof(openers_bottom));\n  for (i=0; i < 3; i++) {\n    openers_bottom[i]['*'] = stack_bottom;\n    openers_bottom[i]['_'] = stack_bottom;\n    openers_bottom[i]['\\''] = stack_bottom;\n    openers_bottom[i]['\"'] = stack_bottom;\n  }\n\n  // move back to first relevant delim.\n  while (closer != NULL && closer->previous != stack_bottom) {\n    closer = closer->previous;\n  }\n\n  // now move forward, looking for closers, and handling each\n  while (closer != NULL) {\n    cmark_syntax_extension *extension = get_extension_for_special_char(parser, closer->delim_char);\n    if (closer->can_close) {\n      // Now look backwards for first matching opener:\n      opener = closer->previous;\n      opener_found = false;\n      while (opener != NULL && opener != stack_bottom &&\n             opener != openers_bottom[closer->length % 3][closer->delim_char]) {\n        if (opener->can_open && opener->delim_char == closer->delim_char) {\n          // interior closer of size 2 can't match opener of size 1\n          // or of size 1 can't match 2\n          if (!(closer->can_open || opener->can_close) ||\n\t      closer->length % 3 == 0 ||\n              (opener->length + closer->length) % 3 != 0) {\n            opener_found = true;\n            break;\n          }\n        }\n        opener = opener->previous;\n      }\n      old_closer = closer;\n\n      if (extension) {\n        if (opener_found)\n          closer = extension->insert_inline_from_delim(extension, parser, subj, opener, closer);\n        else\n          closer = closer->next;\n      } else if (closer->delim_char == '*' || closer->delim_char == '_') {\n        if (opener_found) {\n          closer = S_insert_emph(subj, opener, closer);\n        } else {\n          closer = closer->next;\n        }\n      } else if (closer->delim_char == '\\'') {\n        cmark_chunk_free(subj->mem, &closer->inl_text->as.literal);\n        closer->inl_text->as.literal = cmark_chunk_literal(RIGHTSINGLEQUOTE);\n        if (opener_found) {\n          cmark_chunk_free(subj->mem, &opener->inl_text->as.literal);\n          opener->inl_text->as.literal = cmark_chunk_literal(LEFTSINGLEQUOTE);\n        }\n        closer = closer->next;\n      } else if (closer->delim_char == '\"') {\n        cmark_chunk_free(subj->mem, &closer->inl_text->as.literal);\n        closer->inl_text->as.literal = cmark_chunk_literal(RIGHTDOUBLEQUOTE);\n        if (opener_found) {\n          cmark_chunk_free(subj->mem, &opener->inl_text->as.literal);\n          opener->inl_text->as.literal = cmark_chunk_literal(LEFTDOUBLEQUOTE);\n        }\n        closer = closer->next;\n      }\n      if (!opener_found) {\n        // set lower bound for future searches for openers\n        openers_bottom[old_closer->length % 3][old_closer->delim_char] =\n\t\told_closer->previous;\n        if (!old_closer->can_open) {\n          // we can remove a closer that can't be an\n          // opener, once we've seen there's no\n          // matching opener:\n          remove_delimiter(subj, old_closer);\n        }\n      }\n    } else {\n      closer = closer->next;\n    }\n  }\n  // free all delimiters in list until stack_bottom:\n  while (subj->last_delim != NULL && subj->last_delim != stack_bottom) {\n    remove_delimiter(subj, subj->last_delim);\n  }\n}\n\nstatic delimiter *S_insert_emph(subject *subj, delimiter *opener,\n                                delimiter *closer) {\n  delimiter *delim, *tmp_delim;\n  bufsize_t use_delims;\n  cmark_node *opener_inl = opener->inl_text;\n  cmark_node *closer_inl = closer->inl_text;\n  bufsize_t opener_num_chars = opener_inl->as.literal.len;\n  bufsize_t closer_num_chars = closer_inl->as.literal.len;\n  cmark_node *tmp, *tmpnext, *emph;\n\n  // calculate the actual number of characters used from this closer\n  use_delims = (closer_num_chars >= 2 && opener_num_chars >= 2) ? 2 : 1;\n\n  // remove used characters from associated inlines.\n  opener_num_chars -= use_delims;\n  closer_num_chars -= use_delims;\n  opener_inl->as.literal.len = opener_num_chars;\n  closer_inl->as.literal.len = closer_num_chars;\n\n  // free delimiters between opener and closer\n  delim = closer->previous;\n  while (delim != NULL && delim != opener) {\n    tmp_delim = delim->previous;\n    remove_delimiter(subj, delim);\n    delim = tmp_delim;\n  }\n\n  // create new emph or strong, and splice it in to our inlines\n  // between the opener and closer\n  emph = use_delims == 1 ? make_emph(subj->mem) : make_strong(subj->mem);\n\n  tmp = opener_inl->next;\n  while (tmp && tmp != closer_inl) {\n    tmpnext = tmp->next;\n    cmark_node_append_child(emph, tmp);\n    tmp = tmpnext;\n  }\n  cmark_node_insert_after(opener_inl, emph);\n\n  emph->start_line = opener_inl->start_line;\n  emph->end_line = closer_inl->end_line;\n  emph->start_column = opener_inl->start_column;\n  emph->end_column = closer_inl->end_column;\n\n  // if opener has 0 characters, remove it and its associated inline\n  if (opener_num_chars == 0) {\n    cmark_node_free(opener_inl);\n    remove_delimiter(subj, opener);\n  }\n\n  // if closer has 0 characters, remove it and its associated inline\n  if (closer_num_chars == 0) {\n    // remove empty closer inline\n    cmark_node_free(closer_inl);\n    // remove closer from list\n    tmp_delim = closer->next;\n    remove_delimiter(subj, closer);\n    closer = tmp_delim;\n  }\n\n  return closer;\n}\n\n// Parse backslash-escape or just a backslash, returning an inline.\nstatic cmark_node *handle_backslash(cmark_parser *parser, subject *subj) {\n  advance(subj);\n  unsigned char nextchar = peek_char(subj);\n  if ((parser->backslash_ispunct ? parser->backslash_ispunct : cmark_ispunct)(nextchar)) {\n    // only ascii symbols and newline can be escaped\n    advance(subj);\n    return make_str(subj, subj->pos - 2, subj->pos - 1, cmark_chunk_dup(&subj->input, subj->pos - 1, 1));\n  } else if (!is_eof(subj) && skip_line_end(subj)) {\n    return make_linebreak(subj->mem);\n  } else {\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"\\\\\"));\n  }\n}\n\n// Parse an entity or a regular \"&\" string.\n// Assumes the subject has an '&' character at the current position.\nstatic cmark_node *handle_entity(subject *subj) {\n  cmark_strbuf ent = CMARK_BUF_INIT(subj->mem);\n  bufsize_t len;\n\n  advance(subj);\n\n  len = houdini_unescape_ent(&ent, subj->input.data + subj->pos,\n                             subj->input.len - subj->pos);\n\n  if (len == 0)\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"&\"));\n\n  subj->pos += len;\n  return make_str(subj, subj->pos - 1 - len, subj->pos - 1, cmark_chunk_buf_detach(&ent));\n}\n\n// Clean a URL: remove surrounding whitespace, and remove \\ that escape\n// punctuation.\ncmark_chunk cmark_clean_url(cmark_mem *mem, cmark_chunk *url) {\n  cmark_strbuf buf = CMARK_BUF_INIT(mem);\n\n  cmark_chunk_trim(url);\n\n  if (url->len == 0) {\n    cmark_chunk result = CMARK_CHUNK_EMPTY;\n    return result;\n  }\n\n  houdini_unescape_html_f(&buf, url->data, url->len);\n\n  cmark_strbuf_unescape(&buf);\n  return cmark_chunk_buf_detach(&buf);\n}\n\ncmark_chunk cmark_clean_title(cmark_mem *mem, cmark_chunk *title) {\n  cmark_strbuf buf = CMARK_BUF_INIT(mem);\n  unsigned char first, last;\n\n  if (title->len == 0) {\n    cmark_chunk result = CMARK_CHUNK_EMPTY;\n    return result;\n  }\n\n  first = title->data[0];\n  last = title->data[title->len - 1];\n\n  // remove surrounding quotes if any:\n  if ((first == '\\'' && last == '\\'') || (first == '(' && last == ')') ||\n      (first == '\"' && last == '\"')) {\n    houdini_unescape_html_f(&buf, title->data + 1, title->len - 2);\n  } else {\n    houdini_unescape_html_f(&buf, title->data, title->len);\n  }\n\n  cmark_strbuf_unescape(&buf);\n  return cmark_chunk_buf_detach(&buf);\n}\n\n// Parse an autolink or HTML tag.\n// Assumes the subject has a '<' character at the current position.\nstatic cmark_node *handle_pointy_brace(subject *subj, int options) {\n  bufsize_t matchlen = 0;\n  cmark_chunk contents;\n\n  advance(subj); // advance past first <\n\n  // first try to match a URL autolink\n  matchlen = scan_autolink_uri(&subj->input, subj->pos);\n  if (matchlen > 0) {\n    contents = cmark_chunk_dup(&subj->input, subj->pos, matchlen - 1);\n    subj->pos += matchlen;\n\n    return make_autolink(subj, subj->pos - 1 - matchlen, subj->pos - 1, contents, 0);\n  }\n\n  // next try to match an email autolink\n  matchlen = scan_autolink_email(&subj->input, subj->pos);\n  if (matchlen > 0) {\n    contents = cmark_chunk_dup(&subj->input, subj->pos, matchlen - 1);\n    subj->pos += matchlen;\n\n    return make_autolink(subj, subj->pos - 1 - matchlen, subj->pos - 1, contents, 1);\n  }\n\n  // finally, try to match an html tag\n  matchlen = scan_html_tag(&subj->input, subj->pos);\n  if (matchlen > 0) {\n    contents = cmark_chunk_dup(&subj->input, subj->pos - 1, matchlen + 1);\n    subj->pos += matchlen;\n    cmark_node *node = make_raw_html(subj, subj->pos - matchlen - 1, subj->pos - 1, contents);\n    adjust_subj_node_newlines(subj, node, matchlen, 1, options);\n    return node;\n  }\n\n  if (options & CMARK_OPT_LIBERAL_HTML_TAG) {\n    matchlen = scan_liberal_html_tag(&subj->input, subj->pos);\n    if (matchlen > 0) {\n      contents = cmark_chunk_dup(&subj->input, subj->pos - 1, matchlen + 1);\n      subj->pos += matchlen;\n      cmark_node *node = make_raw_html(subj, subj->pos - matchlen - 1, subj->pos - 1, contents);\n      adjust_subj_node_newlines(subj, node, matchlen, 1, options);\n      return node;\n    }\n  }\n\n  // if nothing matches, just return the opening <:\n  return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"<\"));\n}\n\n// Parse a link label.  Returns 1 if successful.\n// Note:  unescaped brackets are not allowed in labels.\n// The label begins with `[` and ends with the first `]` character\n// encountered.  Backticks in labels do not start code spans.\nstatic int link_label(subject *subj, cmark_chunk *raw_label) {\n  bufsize_t startpos = subj->pos;\n  int length = 0;\n  unsigned char c;\n\n  // advance past [\n  if (peek_char(subj) == '[') {\n    advance(subj);\n  } else {\n    return 0;\n  }\n\n  while ((c = peek_char(subj)) && c != '[' && c != ']') {\n    if (c == '\\\\') {\n      advance(subj);\n      length++;\n      if (cmark_ispunct(peek_char(subj))) {\n        advance(subj);\n        length++;\n      }\n    } else {\n      advance(subj);\n      length++;\n    }\n    if (length > MAX_LINK_LABEL_LENGTH) {\n      goto noMatch;\n    }\n  }\n\n  if (c == ']') { // match found\n    *raw_label =\n        cmark_chunk_dup(&subj->input, startpos + 1, subj->pos - (startpos + 1));\n    cmark_chunk_trim(raw_label);\n    advance(subj); // advance past ]\n    return 1;\n  }\n\nnoMatch:\n  subj->pos = startpos; // rewind\n  return 0;\n}\n\nstatic bufsize_t manual_scan_link_url_2(cmark_chunk *input, bufsize_t offset,\n                                        cmark_chunk *output) {\n  bufsize_t i = offset;\n  size_t nb_p = 0;\n\n  while (i < input->len) {\n    if (input->data[i] == '\\\\' &&\n        i + 1 < input-> len &&\n        cmark_ispunct(input->data[i+1]))\n      i += 2;\n    else if (input->data[i] == '(') {\n      ++nb_p;\n      ++i;\n      if (nb_p > 32)\n        return -1;\n    } else if (input->data[i] == ')') {\n      if (nb_p == 0)\n        break;\n      --nb_p;\n      ++i;\n    } else if (cmark_isspace(input->data[i])) {\n      if (i == offset) {\n        return -1;\n      }\n      break;\n    } else {\n      ++i;\n    }\n  }\n\n  if (i >= input->len)\n    return -1;\n\n  {\n    cmark_chunk result = {input->data + offset, i - offset, 0};\n    *output = result;\n  }\n  return i - offset;\n}\n\nstatic bufsize_t manual_scan_link_url(cmark_chunk *input, bufsize_t offset,\n                                      cmark_chunk *output) {\n  bufsize_t i = offset;\n\n  if (i < input->len && input->data[i] == '<') {\n    ++i;\n    while (i < input->len) {\n      if (input->data[i] == '>') {\n        ++i;\n        break;\n      } else if (input->data[i] == '\\\\')\n        i += 2;\n      else if (input->data[i] == '\\n' || input->data[i] == '<')\n        return -1;\n      else\n        ++i;\n    }\n  } else {\n    return manual_scan_link_url_2(input, offset, output);\n  }\n\n  if (i >= input->len)\n    return -1;\n\n  {\n    cmark_chunk result = {input->data + offset + 1, i - 2 - offset, 0};\n    *output = result;\n  }\n  return i - offset;\n}\n\n// Return a link, an image, or a literal close bracket.\nstatic cmark_node *handle_close_bracket(cmark_parser *parser, subject *subj) {\n  bufsize_t initial_pos, after_link_text_pos;\n  bufsize_t endurl, starttitle, endtitle, endall;\n  bufsize_t sps, n;\n  cmark_reference *ref = NULL;\n  cmark_chunk url_chunk, title_chunk;\n  cmark_chunk url, title;\n  bracket *opener;\n  cmark_node *inl;\n  cmark_chunk raw_label;\n  int found_label;\n  cmark_node *tmp, *tmpnext;\n  bool is_image;\n\n  advance(subj); // advance past ]\n  initial_pos = subj->pos;\n\n  // get last [ or ![\n  opener = subj->last_bracket;\n\n  if (opener == NULL) {\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"]\"));\n  }\n\n  if (!opener->active) {\n    // take delimiter off stack\n    pop_bracket(subj);\n    return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"]\"));\n  }\n\n  // If we got here, we matched a potential link/image text.\n  // Now we check to see if it's a link/image.\n  is_image = opener->image;\n\n  after_link_text_pos = subj->pos;\n\n  // First, look for an inline link.\n  if (peek_char(subj) == '(' &&\n      ((sps = scan_spacechars(&subj->input, subj->pos + 1)) > -1) &&\n      ((n = manual_scan_link_url(&subj->input, subj->pos + 1 + sps,\n                                 &url_chunk)) > -1)) {\n\n    // try to parse an explicit link:\n    endurl = subj->pos + 1 + sps + n;\n    starttitle = endurl + scan_spacechars(&subj->input, endurl);\n\n    // ensure there are spaces btw url and title\n    endtitle = (starttitle == endurl)\n                   ? starttitle\n                   : starttitle + scan_link_title(&subj->input, starttitle);\n\n    endall = endtitle + scan_spacechars(&subj->input, endtitle);\n\n    if (peek_at(subj, endall) == ')') {\n      subj->pos = endall + 1;\n\n      title_chunk =\n          cmark_chunk_dup(&subj->input, starttitle, endtitle - starttitle);\n      url = cmark_clean_url(subj->mem, &url_chunk);\n      title = cmark_clean_title(subj->mem, &title_chunk);\n      cmark_chunk_free(subj->mem, &url_chunk);\n      cmark_chunk_free(subj->mem, &title_chunk);\n      goto match;\n\n    } else {\n      // it could still be a shortcut reference link\n      subj->pos = after_link_text_pos;\n    }\n  }\n\n  // Next, look for a following [link label] that matches in refmap.\n  // skip spaces\n  raw_label = cmark_chunk_literal(\"\");\n  found_label = link_label(subj, &raw_label);\n  if (!found_label) {\n    // If we have a shortcut reference link, back up\n    // to before the spacse we skipped.\n    subj->pos = initial_pos;\n  }\n\n  if ((!found_label || raw_label.len == 0) && !opener->bracket_after) {\n    cmark_chunk_free(subj->mem, &raw_label);\n    raw_label = cmark_chunk_dup(&subj->input, opener->position,\n                                initial_pos - opener->position - 1);\n    found_label = true;\n  }\n\n  if (found_label) {\n    ref = (cmark_reference *)cmark_map_lookup(subj->refmap, &raw_label);\n    cmark_chunk_free(subj->mem, &raw_label);\n  }\n\n  if (ref != NULL) { // found\n    url = chunk_clone(subj->mem, &ref->url);\n    title = chunk_clone(subj->mem, &ref->title);\n    goto match;\n  } else {\n    goto noMatch;\n  }\n\nnoMatch:\n  // If we fall through to here, it means we didn't match a link.\n  // What if we're a footnote link?\n  if (parser->options & CMARK_OPT_FOOTNOTES &&\n      opener->inl_text->next &&\n      opener->inl_text->next->type == CMARK_NODE_TEXT) {\n\n    cmark_chunk *literal = &opener->inl_text->next->as.literal;\n\n    // look back to the opening '[', and skip ahead to the next character\n    // if we're looking at a '[^' sequence, and there is other text or nodes\n    // after the ^, let's call it a footnote reference.\n    if ((literal->len > 0 && literal->data[0] == '^') && (literal->len > 1 || opener->inl_text->next->next)) {\n\n      // Before we got this far, the `handle_close_bracket` function may have\n      // advanced the current state beyond our footnote's actual closing\n      // bracket, ie if it went looking for a `link_label`.\n      // Let's just rewind the subject's position:\n      subj->pos = initial_pos;\n\n      cmark_node *fnref = make_simple(subj->mem, CMARK_NODE_FOOTNOTE_REFERENCE);\n\n      // the start and end of the footnote ref is the opening and closing brace\n      // i.e. the subject's current position, and the opener's start_column\n      int fnref_end_column = subj->pos + subj->column_offset + subj->block_offset;\n      int fnref_start_column = opener->inl_text->start_column;\n\n      // any given node delineates a substring of the line being processed,\n      // with the remainder of the line being pointed to thru its 'literal'\n      // struct member.\n      // here, we copy the literal's pointer, moving it past the '^' character\n      // for a length equal to the size of footnote reference text.\n      // i.e. end_col minus start_col, minus the [ and the ^ characters\n      //\n      // this copies the footnote reference string, even if between the\n      // `opener` and the subject's current position there are other nodes\n      //\n      // (first, check for underflows)\n      if ((fnref_start_column + 2) <= fnref_end_column) {\n        fnref->as.literal = cmark_chunk_dup(literal, 1, (fnref_end_column - fnref_start_column) - 2);\n      } else {\n        fnref->as.literal = cmark_chunk_dup(literal, 1, 0);\n      }\n\n      fnref->start_line = fnref->end_line = subj->line;\n      fnref->start_column = fnref_start_column;\n      fnref->end_column = fnref_end_column;\n\n      // we then replace the opener with this new fnref node, the net effect\n      // being replacing the opening '[' text node with a `^footnote-ref]` node.\n      cmark_node_insert_before(opener->inl_text, fnref);\n\n      process_emphasis(parser, subj, opener->previous_delimiter);\n      // sometimes, the footnote reference text gets parsed into multiple nodes\n      // i.e. '[^example]' parsed into '[', '^exam', 'ple]'.\n      // this happens for ex with the autolink extension. when the autolinker\n      // finds the 'w' character, it will split the text into multiple nodes\n      // in hopes of being able to match a 'www.' substring.\n      //\n      // because this function is called one character at a time via the\n      // `parse_inlines` function, and the current subj->pos is pointing at the\n      // closing ] brace, and because we copy all the text between the [ ]\n      // braces, we should be able to safely ignore and delete any nodes after\n      // the opener->inl_text->next.\n      //\n      // therefore, here we walk thru the list and free them all up\n      cmark_node *next_node;\n      cmark_node *current_node = opener->inl_text->next;\n      while(current_node) {\n        next_node = current_node->next;\n        cmark_node_free(current_node);\n        current_node = next_node;\n      }\n\n      cmark_node_free(opener->inl_text);\n\n      pop_bracket(subj);\n      return NULL;\n    }\n  }\n\n  pop_bracket(subj); // remove this opener from delimiter list\n  subj->pos = initial_pos;\n  return make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"]\"));\n\nmatch:\n  inl = make_simple(subj->mem, is_image ? CMARK_NODE_IMAGE : CMARK_NODE_LINK);\n  inl->as.link.url = url;\n  inl->as.link.title = title;\n  inl->start_line = inl->end_line = subj->line;\n  inl->start_column = opener->inl_text->start_column;\n  inl->end_column = subj->pos + subj->column_offset + subj->block_offset;\n  cmark_node_insert_before(opener->inl_text, inl);\n  // Add link text:\n  tmp = opener->inl_text->next;\n  while (tmp) {\n    tmpnext = tmp->next;\n    cmark_node_append_child(inl, tmp);\n    tmp = tmpnext;\n  }\n\n  // Free the bracket [:\n  cmark_node_free(opener->inl_text);\n\n  process_emphasis(parser, subj, opener->previous_delimiter);\n  pop_bracket(subj);\n\n  // Now, if we have a link, we also want to deactivate earlier link\n  // delimiters. (This code can be removed if we decide to allow links\n  // inside links.)\n  if (!is_image) {\n    opener = subj->last_bracket;\n    while (opener != NULL) {\n      if (!opener->image) {\n        if (!opener->active) {\n          break;\n        } else {\n          opener->active = false;\n        }\n      }\n      opener = opener->previous;\n    }\n    bool in_bracket_image1 = false;\n    if (opener) {\n      in_bracket_image1 = opener->in_bracket_image1;\n    }\n    bracket *opener2 = subj->last_bracket;\n    while (opener2 != opener) {\n      if (opener2->image) {\n        opener2->in_bracket_image1 = in_bracket_image1;\n      }\n      opener2 = opener2->previous;\n    }\n  }\n\n  return NULL;\n}\n\n// Parse a hard or soft linebreak, returning an inline.\n// Assumes the subject has a cr or newline at the current position.\nstatic cmark_node *handle_newline(subject *subj) {\n  bufsize_t nlpos = subj->pos;\n  // skip over cr, crlf, or lf:\n  if (peek_at(subj, subj->pos) == '\\r') {\n    advance(subj);\n  }\n  if (peek_at(subj, subj->pos) == '\\n') {\n    advance(subj);\n  }\n  ++subj->line;\n  subj->column_offset = -subj->pos;\n  // skip spaces at beginning of line\n  skip_spaces(subj);\n  if (nlpos > 1 && peek_at(subj, nlpos - 1) == ' ' &&\n      peek_at(subj, nlpos - 2) == ' ') {\n    return make_linebreak(subj->mem);\n  } else {\n    return make_softbreak(subj->mem);\n  }\n}\n\n// \"\\r\\n\\\\`&_*[]<!\"\nstatic int8_t SPECIAL_CHARS[256] = {\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n      1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};\n\n// \" ' . -\nstatic char SMART_PUNCT_CHARS[] = {\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n};\n\nstatic bufsize_t subject_find_special_char(subject *subj, int options) {\n  bufsize_t n = subj->pos + 1;\n\n  while (n < subj->input.len) {\n    if (SPECIAL_CHARS[subj->input.data[n]])\n      return n;\n    if (options & CMARK_OPT_SMART && SMART_PUNCT_CHARS[subj->input.data[n]])\n      return n;\n    n++;\n  }\n\n  return subj->input.len;\n}\n\nvoid cmark_inlines_add_special_character(unsigned char c, bool emphasis) {\n  SPECIAL_CHARS[c] = 1;\n  if (emphasis)\n    SKIP_CHARS[c] = 1;\n}\n\nvoid cmark_inlines_remove_special_character(unsigned char c, bool emphasis) {\n  SPECIAL_CHARS[c] = 0;\n  if (emphasis)\n    SKIP_CHARS[c] = 0;\n}\n\nstatic cmark_node *try_extensions(cmark_parser *parser,\n                                  cmark_node *parent,\n                                  unsigned char c,\n                                  subject *subj) {\n  cmark_node *res = NULL;\n  cmark_llist *tmp;\n\n  for (tmp = parser->inline_syntax_extensions; tmp; tmp = tmp->next) {\n    cmark_syntax_extension *ext = (cmark_syntax_extension *) tmp->data;\n    res = ext->match_inline(ext, parser, parent, c, subj);\n\n    if (res)\n      break;\n  }\n\n  return res;\n}\n\n// Parse an inline, advancing subject, and add it as a child of parent.\n// Return 0 if no inline can be parsed, 1 otherwise.\nstatic int parse_inline(cmark_parser *parser, subject *subj, cmark_node *parent, int options) {\n  cmark_node *new_inl = NULL;\n  cmark_chunk contents;\n  unsigned char c;\n  bufsize_t startpos, endpos;\n  c = peek_char(subj);\n  if (c == 0) {\n    return 0;\n  }\n  switch (c) {\n  case '\\r':\n  case '\\n':\n    new_inl = handle_newline(subj);\n    break;\n  case '`':\n    new_inl = handle_backticks(subj, options);\n    break;\n  case '\\\\':\n    new_inl = handle_backslash(parser, subj);\n    break;\n  case '&':\n    new_inl = handle_entity(subj);\n    break;\n  case '<':\n    new_inl = handle_pointy_brace(subj, options);\n    break;\n  case '*':\n  case '_':\n  case '\\'':\n  case '\"':\n    new_inl = handle_delim(subj, c, (options & CMARK_OPT_SMART) != 0);\n    break;\n  case '-':\n    new_inl = handle_hyphen(subj, (options & CMARK_OPT_SMART) != 0);\n    break;\n  case '.':\n    new_inl = handle_period(subj, (options & CMARK_OPT_SMART) != 0);\n    break;\n  case '[':\n    advance(subj);\n    new_inl = make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"[\"));\n    push_bracket(subj, false, new_inl);\n    break;\n  case ']':\n    new_inl = handle_close_bracket(parser, subj);\n    break;\n  case '!':\n    advance(subj);\n    if (peek_char(subj) == '[' && peek_char_n(subj, 1) != '^') {\n      advance(subj);\n      new_inl = make_str(subj, subj->pos - 2, subj->pos - 1, cmark_chunk_literal(\"![\"));\n      push_bracket(subj, true, new_inl);\n    } else {\n      new_inl = make_str(subj, subj->pos - 1, subj->pos - 1, cmark_chunk_literal(\"!\"));\n    }\n    break;\n  default:\n    new_inl = try_extensions(parser, parent, c, subj);\n    if (new_inl != NULL)\n      break;\n\n    endpos = subject_find_special_char(subj, options);\n    contents = cmark_chunk_dup(&subj->input, subj->pos, endpos - subj->pos);\n    startpos = subj->pos;\n    subj->pos = endpos;\n\n    // if we're at a newline, strip trailing spaces.\n    if (S_is_line_end_char(peek_char(subj))) {\n      cmark_chunk_rtrim(&contents);\n    }\n\n    new_inl = make_str(subj, startpos, endpos - 1, contents);\n  }\n  if (new_inl != NULL) {\n    cmark_node_append_child(parent, new_inl);\n  }\n\n  return 1;\n}\n\n// Parse inlines from parent's string_content, adding as children of parent.\nvoid cmark_parse_inlines(cmark_parser *parser,\n                         cmark_node *parent,\n                         cmark_map *refmap,\n                         int options) {\n  subject subj;\n  cmark_chunk content = {parent->content.ptr, parent->content.size, 0};\n  subject_from_buf(parser->mem, parent->start_line, parent->start_column - 1 + parent->internal_offset, &subj, &content, refmap);\n  cmark_chunk_rtrim(&subj.input);\n\n  while (!is_eof(&subj) && parse_inline(parser, &subj, parent, options))\n    ;\n\n  process_emphasis(parser, &subj, NULL);\n  // free bracket and delim stack\n  while (subj.last_delim) {\n    remove_delimiter(&subj, subj.last_delim);\n  }\n  while (subj.last_bracket) {\n    pop_bracket(&subj);\n  }\n}\n\n// Parse zero or more space characters, including at most one newline.\nstatic void spnl(subject *subj) {\n  skip_spaces(subj);\n  if (skip_line_end(subj)) {\n    skip_spaces(subj);\n  }\n}\n\n// Parse reference.  Assumes string begins with '[' character.\n// Modify refmap if a reference is encountered.\n// Return 0 if no reference found, otherwise position of subject\n// after reference is parsed.\nbufsize_t cmark_parse_reference_inline(cmark_mem *mem, cmark_chunk *input,\n                                       cmark_map *refmap) {\n  subject subj;\n\n  cmark_chunk lab;\n  cmark_chunk url;\n  cmark_chunk title;\n\n  bufsize_t matchlen = 0;\n  bufsize_t beforetitle;\n\n  subject_from_buf(mem, -1, 0, &subj, input, NULL);\n\n  // parse label:\n  if (!link_label(&subj, &lab) || lab.len == 0)\n    return 0;\n\n  // colon:\n  if (peek_char(&subj) == ':') {\n    advance(&subj);\n  } else {\n    return 0;\n  }\n\n  // parse link url:\n  spnl(&subj);\n  if ((matchlen = manual_scan_link_url(&subj.input, subj.pos, &url)) > -1) {\n    subj.pos += matchlen;\n  } else {\n    return 0;\n  }\n\n  // parse optional link_title\n  beforetitle = subj.pos;\n  spnl(&subj);\n  matchlen = subj.pos == beforetitle ? 0 : scan_link_title(&subj.input, subj.pos);\n  if (matchlen) {\n    title = cmark_chunk_dup(&subj.input, subj.pos, matchlen);\n    subj.pos += matchlen;\n  } else {\n    subj.pos = beforetitle;\n    title = cmark_chunk_literal(\"\");\n  }\n\n  // parse final spaces and newline:\n  skip_spaces(&subj);\n  if (!skip_line_end(&subj)) {\n    if (matchlen) { // try rewinding before title\n      subj.pos = beforetitle;\n      skip_spaces(&subj);\n      if (!skip_line_end(&subj)) {\n        return 0;\n      }\n    } else {\n      return 0;\n    }\n  }\n  // insert reference into refmap\n  cmark_reference_create(refmap, &lab, &url, &title);\n  return subj.pos;\n}\n\nunsigned char cmark_inline_parser_peek_char(cmark_inline_parser *parser) {\n  return peek_char(parser);\n}\n\nunsigned char cmark_inline_parser_peek_at(cmark_inline_parser *parser, bufsize_t pos) {\n  return peek_at(parser, pos);\n}\n\nint cmark_inline_parser_is_eof(cmark_inline_parser *parser) {\n  return is_eof(parser);\n}\n\nstatic char *\nmy_strndup (const char *s, size_t n)\n{\n  char *result;\n  size_t len = strlen (s);\n\n  if (n < len)\n    len = n;\n\n  result = (char *) malloc (len + 1);\n  if (!result)\n    return 0;\n\n  result[len] = '\\0';\n  return (char *) memcpy (result, s, len);\n}\n\nchar *cmark_inline_parser_take_while(cmark_inline_parser *parser, cmark_inline_predicate pred) {\n  unsigned char c;\n  bufsize_t startpos = parser->pos;\n  bufsize_t len = 0;\n\n  while ((c = peek_char(parser)) && (*pred)(c)) {\n    advance(parser);\n    len++;\n  }\n\n  return my_strndup((const char *) parser->input.data + startpos, len);\n}\n\nvoid cmark_inline_parser_push_delimiter(cmark_inline_parser *parser,\n                                  unsigned char c,\n                                  int can_open,\n                                  int can_close,\n                                  cmark_node *inl_text) {\n  push_delimiter(parser, c, can_open != 0, can_close != 0, inl_text);\n}\n\nvoid cmark_inline_parser_remove_delimiter(cmark_inline_parser *parser, delimiter *delim) {\n  remove_delimiter(parser, delim);\n}\n\nint cmark_inline_parser_scan_delimiters(cmark_inline_parser *parser,\n                                  int max_delims,\n                                  unsigned char c,\n                                  int *left_flanking,\n                                  int *right_flanking,\n                                  int *punct_before,\n                                  int *punct_after) {\n  int numdelims = 0;\n  bufsize_t before_char_pos;\n  int32_t after_char = 0;\n  int32_t before_char = 0;\n  int len;\n  bool space_before, space_after;\n\n  if (parser->pos == 0) {\n    before_char = 10;\n  } else {\n    before_char_pos = parser->pos - 1;\n    // walk back to the beginning of the UTF_8 sequence:\n    while (peek_at(parser, before_char_pos) >> 6 == 2 && before_char_pos > 0) {\n      before_char_pos -= 1;\n    }\n    len = cmark_utf8proc_iterate(parser->input.data + before_char_pos,\n                                 parser->pos - before_char_pos, &before_char);\n    if (len == -1) {\n      before_char = 10;\n    }\n  }\n\n  while (peek_char(parser) == c && numdelims < max_delims) {\n    numdelims++;\n    advance(parser);\n  }\n\n  len = cmark_utf8proc_iterate(parser->input.data + parser->pos,\n                               parser->input.len - parser->pos, &after_char);\n  if (len == -1) {\n    after_char = 10;\n  }\n\n  *punct_before = cmark_utf8proc_is_punctuation(before_char);\n  *punct_after = cmark_utf8proc_is_punctuation(after_char);\n  space_before = cmark_utf8proc_is_space(before_char) != 0;\n  space_after = cmark_utf8proc_is_space(after_char) != 0;\n\n  *left_flanking = numdelims > 0 && !cmark_utf8proc_is_space(after_char) &&\n                  !(*punct_after && !space_before && !*punct_before);\n  *right_flanking = numdelims > 0 && !cmark_utf8proc_is_space(before_char) &&\n                  !(*punct_before && !space_after && !*punct_after);\n\n  return numdelims;\n}\n\nvoid cmark_inline_parser_advance_offset(cmark_inline_parser *parser) {\n  advance(parser);\n}\n\nint cmark_inline_parser_get_offset(cmark_inline_parser *parser) {\n  return parser->pos;\n}\n\nvoid cmark_inline_parser_set_offset(cmark_inline_parser *parser, int offset) {\n  parser->pos = offset;\n}\n\nint cmark_inline_parser_get_column(cmark_inline_parser *parser) {\n  return parser->pos + 1 + parser->column_offset + parser->block_offset;\n}\n\ncmark_chunk *cmark_inline_parser_get_chunk(cmark_inline_parser *parser) {\n  return &parser->input;\n}\n\nint cmark_inline_parser_in_bracket(cmark_inline_parser *parser, int image) {\n  bracket *b = parser->last_bracket;\n  if (!b) {\n    return 0;\n  }\n  if (image != 0) {\n    return b->in_bracket_image1;\n  } else {\n    return b->in_bracket_image0;\n  }\n}\n\nvoid cmark_node_unput(cmark_node *node, int n) {\n\tnode = node->last_child;\n\twhile (n > 0 && node && node->type == CMARK_NODE_TEXT) {\n\t\tif (node->as.literal.len < n) {\n\t\t\tn -= node->as.literal.len;\n\t\t\tnode->as.literal.len = 0;\n\t\t} else {\n\t\t\tnode->as.literal.len -= n;\n\t\t\tn = 0;\n\t\t}\n\t\tnode = node->prev;\n\t}\n}\n\ndelimiter *cmark_inline_parser_get_last_delimiter(cmark_inline_parser *parser) {\n  return parser->last_delim;\n}\n\nint cmark_inline_parser_get_line(cmark_inline_parser *parser) {\n  return parser->line;\n}\n"], "filenames": ["CMakeLists.txt", "changelog.txt", "src/inlines.c"], "buggy_code_start_loc": [7, 0, 43], "buggy_code_end_loc": [8, 0, 1669], "fixing_code_start_loc": [7, 1, 44], "fixing_code_end_loc": [8, 4, 1694], "type": "CWE-400", "message": "cmark-gfm is GitHub's fork of cmark, a CommonMark parsing and rendering library and program in C. In versions prior to 0.29.0.gfm.6 a polynomial time complexity issue in cmark-gfm's autolink extension may lead to unbounded resource exhaustion and subsequent denial of service. Users may verify the patch by running `python3 -c 'print(\"![l\"* 100000 + \"\\n\")' | ./cmark-gfm -e autolink`, which will resource exhaust on unpatched cmark-gfm but render correctly on patched cmark-gfm. This vulnerability has been patched in 0.29.0.gfm.6. Users are advised to upgrade. Users unable to upgrade should disable the use of the autolink extension.", "other": {"cve": {"id": "CVE-2022-39209", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-15T18:15:12.260", "lastModified": "2023-01-20T12:34:33.713", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "cmark-gfm is GitHub's fork of cmark, a CommonMark parsing and rendering library and program in C. In versions prior to 0.29.0.gfm.6 a polynomial time complexity issue in cmark-gfm's autolink extension may lead to unbounded resource exhaustion and subsequent denial of service. Users may verify the patch by running `python3 -c 'print(\"![l\"* 100000 + \"\\n\")' | ./cmark-gfm -e autolink`, which will resource exhaust on unpatched cmark-gfm but render correctly on patched cmark-gfm. This vulnerability has been patched in 0.29.0.gfm.6. Users are advised to upgrade. Users unable to upgrade should disable the use of the autolink extension."}, {"lang": "es", "value": "cmark-gfm es la bifurcaci\u00f3n de GitHub de cmark, una biblioteca de an\u00e1lisis y renderizaci\u00f3n de CommonMark y un programa en C. En versiones anteriores a 0.29.0.gfm.6, un problema de complejidad de tiempo polin\u00f3mico en la extensi\u00f3n de autolink de cmark-gfm puede conllevar a un agotamiento de recursos sin l\u00edmites y la consiguiente denegaci\u00f3n de servicio. Los usuarios pueden verificar el parche al ejecutar \"python3 -c \"print(\"![l \"* 100000 + \"\\n\")' | ./cmark-gfm -e autolink\", que agotar\u00e1 los recursos en cmark-gfm sin parchear, pero ser\u00e1 mostrado correctamente en cmark-gfm parcheado. Esta vulnerabilidad ha sido parcheada en versi\u00f3n 0.29.0.gfm.6. Es recomendado a usuarios actualizar. Los usuarios que no puedan actualizares deber\u00e1n deshabilitar el uso de la extensi\u00f3n autolink"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-400"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-400"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:github:cmark-gfm:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.29.0.gfm.6", "matchCriteriaId": "9BC5A247-1236-4667-BA80-41EC86DFE3B2"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:35:*:*:*:*:*:*:*", "matchCriteriaId": "80E516C0-98A4-4ADE-B69F-66A772E2BAAA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:36:*:*:*:*:*:*:*", "matchCriteriaId": "5C675112-476C-4D7C-BCB9-A2FB2D0BC9FD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:37:*:*:*:*:*:*:*", "matchCriteriaId": "E30D0E6F-4AE8-4284-8716-991DFA48CC5D"}]}]}], "references": [{"url": "https://en.wikipedia.org/wiki/Time_complexity", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/github/cmark-gfm/commit/9d57d8a23142b316282bdfc954cb0ecda40a8655", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/github/cmark-gfm/security/advisories/GHSA-cgh3-p57x-9q7q", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/JIUCZN3PEKUCT2JQYQTYOVIJG2KSD6G7/", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/JMGP65NANDVKPDMXMKYO2ZV2H2HZJY4P/", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/UEAAAI4OULDYQ2TA3HOXH54PC3DCBFZS/", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/github/cmark-gfm/commit/9d57d8a23142b316282bdfc954cb0ecda40a8655"}}
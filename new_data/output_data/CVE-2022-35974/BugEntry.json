{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// See docs in ../ops/array_ops.cc.\n\n#define EIGEN_USE_THREADS\n\n#include <math.h>\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/type_traits.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/kernels/meta_support.h\"\n#include \"tensorflow/core/kernels/quantization_utils.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\n\ntemplate <class T1, class T2>\nclass QuantizeDownAndShrinkRangeOp : public OpKernel {\n public:\n  explicit QuantizeDownAndShrinkRangeOp(OpKernelConstruction* ctx)\n      : OpKernel(ctx) {}\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const float input_min_float = ctx->input(1).flat<float>()(0);\n    const float input_max_float = ctx->input(2).flat<float>()(0);\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n    Tensor* output_min = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(2, TensorShape({}), &output_max));\n\n    // See QuantizationRangeOp as well, which has a copy of this logic.\n    auto input_array = input.flat<T1>();\n    const int32_t input_lowest_quantized =\n        static_cast<int32>(Eigen::NumTraits<T1>::lowest());\n    const int32_t input_highest_quantized =\n        static_cast<int32>(Eigen::NumTraits<T1>::highest());\n    T1 actual_min_quantized = input_highest_quantized;\n    T1 actual_max_quantized = input_lowest_quantized;\n    for (int i = 0; i < input_array.size(); ++i) {\n      const T1 value = input_array(i);\n      actual_min_quantized = std::min(actual_min_quantized, value);\n      actual_max_quantized = std::max(actual_max_quantized, value);\n    }\n    // We want to make sure that the minimum is no larger than zero, so that the\n    // convolution operation can run efficiently.\n    const float actual_min_float =\n        std::min(0.0f, QuantizedToFloat(actual_min_quantized, input_min_float,\n                                        input_max_float));\n    const float actual_max_float = QuantizedToFloat(\n        actual_max_quantized, input_min_float, input_max_float);\n\n#if 0\n    // This is the reference, non-eigen implementation:\n    auto output_array = output->flat<T2>();\n    RequantizeManyInNewRange<T1, T2>(input_array.data(), input_array.size(),\n                                     input_min_float, input_max_float,\n                                     actual_min_float, actual_max_float,\n                                     output_array.data());\n#endif\n\n    if (input_array.size() > 0) {\n      if (meta::IsSupportedAndEnabled() && std::is_same<T1, qint32>() &&\n          std::is_same<T2, quint8>()) {\n        auto input_i32_array = input.flat<qint32>();\n        meta::Requantize(ctx, input_i32_array.data(), input_i32_array.size(),\n                         input_min_float, input_max_float, actual_min_float,\n                         actual_max_float, output->flat<quint8>().data());\n      } else {\n        RequantizeManyInNewRangeUsingEigen<T1, T2>(\n            ctx->eigen_device<CPUDevice>(), input, input_min_float,\n            input_max_float, actual_min_float, actual_max_float, output);\n      }\n    }\n\n    output_min->flat<float>().setConstant(actual_min_float);\n    output_max->flat<float>().setConstant(actual_max_float);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"QuantizeDownAndShrinkRange\")\n                            .Device(DEVICE_CPU)\n                            .TypeConstraint<qint32>(\"Tinput\")\n                            .TypeConstraint<quint8>(\"out_type\"),\n                        QuantizeDownAndShrinkRangeOp<qint32, quint8>);\n\n}  // namespace tensorflow\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/allocator.h\"\n#include \"tensorflow/core/framework/fake_input.h\"\n#include \"tensorflow/core/framework/node_def_builder.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_testutil.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/kernels/ops_testutil.h\"\n#include \"tensorflow/core/kernels/ops_util.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/platform/test.h\"\n\nnamespace tensorflow {\n\nclass QuantizeDownAndShrinkRangeTest : public OpsTestBase {\n protected:\n};\n\n// Runs a manually generated array through the operator, and makes sure that the\n// results match the expected hand-calculated values.\nTEST_F(QuantizeDownAndShrinkRangeTest, HandCrafted) {\n  TF_ASSERT_OK(NodeDefBuilder(\"quantize_down_and_shrink_range_op\",\n                              \"QuantizeDownAndShrinkRange\")\n                   .Input(FakeInput(DT_QINT32))\n                   .Input(FakeInput(DT_FLOAT))\n                   .Input(FakeInput(DT_FLOAT))\n                   .Attr(\"Tinput\", DataTypeToEnum<qint32>::v())\n                   .Attr(\"out_type\", DataTypeToEnum<quint8>::v())\n                   .Finalize(node_def()));\n  TF_ASSERT_OK(InitOp());\n\n  // For this test we have an input that has the theoretical range of -256.0f to\n  // +256.0f, but the actual values present only span -1.0f to 1.0f. We expect\n  // the operator to take advantage of this, and rescale the output to fill up\n  // the available range in the lower bit depth, and update to the true min and\n  // max ranges.\n  const int value_count = 3;\n  AddInputFromArray<qint32>(TensorShape({value_count}),\n                            {-(1 << 23), 0, (1 << 23)});\n  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n  TF_ASSERT_OK(RunOpKernel());\n  Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));\n  test::FillValues<quint8>(&expected, {0, 128, 255});\n  test::ExpectTensorEqual<quint8>(expected, *GetOutput(0));\n  Tensor expected_min(allocator(), DT_FLOAT, TensorShape({}));\n  test::FillValues<float>(&expected_min, {-1.0f});\n  test::ExpectTensorEqual<float>(expected_min, *GetOutput(1));\n  Tensor expected_max(allocator(), DT_FLOAT, TensorShape({}));\n  test::FillValues<float>(&expected_max, {1.0f});\n  test::ExpectTensorEqual<float>(expected_max, *GetOutput(2));\n}\n\n}  // end namespace tensorflow\n", "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for tf.quantize ops.\"\"\"\nimport numpy as np\n\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import nn_ops\nfrom tensorflow.python.platform import googletest\n\n\nclass FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars(\n              inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars(\n              inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))\n\n\nclass FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 1\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[[0.0]], max=[1.0]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"Dimensions must be equal|incorrect size\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 1\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[1.0], max=[[1.0]]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"Dimensions must be equal|incorrect size\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n\n\nclass QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)\n    bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=[],\n              max_input=1.0,\n              min_bias=0.0,\n              max_bias=1.0,\n              out_type=dtypes.qint32))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=0.0,\n              max_input=[],\n              min_bias=0.0,\n              max_bias=1.0,\n              out_type=dtypes.qint32))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=0.0,\n              max_input=1.0,\n              min_bias=[],\n              max_bias=1.0,\n              out_type=dtypes.qint32))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=0.0,\n              max_input=1.0,\n              min_bias=0.0,\n              max_bias=[],\n              out_type=dtypes.qint32))\n\n\nclass QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.quantized_instance_norm(\n              x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.quantized_instance_norm(\n              x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))\n\n\nclass RequantizeOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=[],\n              input_max=1.0,\n              requested_output_min=0.0,\n              requested_output_max=1.0,\n              out_type=dtypes.qint8))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=0.0,\n              input_max=[],\n              requested_output_min=0.0,\n              requested_output_max=1.0,\n              out_type=dtypes.qint8))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=0.0,\n              input_max=1.0,\n              requested_output_min=[],\n              requested_output_max=1.0,\n              out_type=dtypes.qint8))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=0.0,\n              input_max=1.0,\n              requested_output_min=0.0,\n              requested_output_max=[],\n              out_type=dtypes.qint8))\n\n\nclass QuantizedAddOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    x = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.quantized_add(\n              x=x,\n              y=y,\n              min_x=[],\n              max_x=1.0,\n              min_y=0.0,\n              max_y=1.0,\n              Toutput=dtypes.qint32))\n\n\nclass QuantizedReluOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_relu(\n              features=inputs,\n              min_features=[],\n              max_features=127.0,\n              out_type=dtypes.quint8))\n\n\nclass QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_relu6(\n              features=inputs,\n              min_features=[],\n              max_features=127.0,\n              out_type=dtypes.quint8))\n\n\nif __name__ == \"__main__\":\n  googletest.main()\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// See docs in ../ops/array_ops.cc.\n\n#define EIGEN_USE_THREADS\n\n#include <math.h>\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/type_traits.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/kernels/meta_support.h\"\n#include \"tensorflow/core/kernels/quantization_utils.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\n\ntemplate <class T1, class T2>\nclass QuantizeDownAndShrinkRangeOp : public OpKernel {\n public:\n  explicit QuantizeDownAndShrinkRangeOp(OpKernelConstruction* ctx)\n      : OpKernel(ctx) {}\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const Tensor& input_min = ctx->input(1);\n    const Tensor& input_max = ctx->input(2);\n\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n                                input_min.dims()));\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n                                input_max.dims()));\n\n    const float input_min_float = input_min.scalar<float>()();\n    const float input_max_float = input_max.scalar<float>()();\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n    Tensor* output_min = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(2, TensorShape({}), &output_max));\n\n    // See QuantizationRangeOp as well, which has a copy of this logic.\n    auto input_array = input.flat<T1>();\n    const int32_t input_lowest_quantized =\n        static_cast<int32>(Eigen::NumTraits<T1>::lowest());\n    const int32_t input_highest_quantized =\n        static_cast<int32>(Eigen::NumTraits<T1>::highest());\n    T1 actual_min_quantized = input_highest_quantized;\n    T1 actual_max_quantized = input_lowest_quantized;\n    for (int i = 0; i < input_array.size(); ++i) {\n      const T1 value = input_array(i);\n      actual_min_quantized = std::min(actual_min_quantized, value);\n      actual_max_quantized = std::max(actual_max_quantized, value);\n    }\n    // We want to make sure that the minimum is no larger than zero, so that the\n    // convolution operation can run efficiently.\n    const float actual_min_float =\n        std::min(0.0f, QuantizedToFloat(actual_min_quantized, input_min_float,\n                                        input_max_float));\n    const float actual_max_float = QuantizedToFloat(\n        actual_max_quantized, input_min_float, input_max_float);\n\n#if 0\n    // This is the reference, non-eigen implementation:\n    auto output_array = output->flat<T2>();\n    RequantizeManyInNewRange<T1, T2>(input_array.data(), input_array.size(),\n                                     input_min_float, input_max_float,\n                                     actual_min_float, actual_max_float,\n                                     output_array.data());\n#endif\n\n    if (input_array.size() > 0) {\n      if (meta::IsSupportedAndEnabled() && std::is_same<T1, qint32>() &&\n          std::is_same<T2, quint8>()) {\n        auto input_i32_array = input.flat<qint32>();\n        meta::Requantize(ctx, input_i32_array.data(), input_i32_array.size(),\n                         input_min_float, input_max_float, actual_min_float,\n                         actual_max_float, output->flat<quint8>().data());\n      } else {\n        RequantizeManyInNewRangeUsingEigen<T1, T2>(\n            ctx->eigen_device<CPUDevice>(), input, input_min_float,\n            input_max_float, actual_min_float, actual_max_float, output);\n      }\n    }\n\n    output_min->flat<float>().setConstant(actual_min_float);\n    output_max->flat<float>().setConstant(actual_max_float);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"QuantizeDownAndShrinkRange\")\n                            .Device(DEVICE_CPU)\n                            .TypeConstraint<qint32>(\"Tinput\")\n                            .TypeConstraint<quint8>(\"out_type\"),\n                        QuantizeDownAndShrinkRangeOp<qint32, quint8>);\n\n}  // namespace tensorflow\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/allocator.h\"\n#include \"tensorflow/core/framework/fake_input.h\"\n#include \"tensorflow/core/framework/node_def_builder.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_testutil.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/kernels/ops_testutil.h\"\n#include \"tensorflow/core/kernels/ops_util.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/platform/test.h\"\n\nnamespace tensorflow {\n\nclass QuantizeDownAndShrinkRangeTest : public OpsTestBase {\n protected:\n};\n\n// Runs a manually generated array through the operator, and makes sure that the\n// results match the expected hand-calculated values.\nTEST_F(QuantizeDownAndShrinkRangeTest, HandCrafted) {\n  TF_ASSERT_OK(NodeDefBuilder(\"quantize_down_and_shrink_range_op\",\n                              \"QuantizeDownAndShrinkRange\")\n                   .Input(FakeInput(DT_QINT32))\n                   .Input(FakeInput(DT_FLOAT))\n                   .Input(FakeInput(DT_FLOAT))\n                   .Attr(\"Tinput\", DataTypeToEnum<qint32>::v())\n                   .Attr(\"out_type\", DataTypeToEnum<quint8>::v())\n                   .Finalize(node_def()));\n  TF_ASSERT_OK(InitOp());\n\n  // For this test we have an input that has the theoretical range of -256.0f to\n  // +256.0f, but the actual values present only span -1.0f to 1.0f. We expect\n  // the operator to take advantage of this, and rescale the output to fill up\n  // the available range in the lower bit depth, and update to the true min and\n  // max ranges.\n  const int value_count = 3;\n  AddInputFromArray<qint32>(TensorShape({value_count}),\n                            {-(1 << 23), 0, (1 << 23)});\n  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n  AddInputFromArray<float>(TensorShape({}), {256.0f});\n  TF_ASSERT_OK(RunOpKernel());\n  Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));\n  test::FillValues<quint8>(&expected, {0, 128, 255});\n  test::ExpectTensorEqual<quint8>(expected, *GetOutput(0));\n  Tensor expected_min(allocator(), DT_FLOAT, TensorShape({}));\n  test::FillValues<float>(&expected_min, {-1.0f});\n  test::ExpectTensorEqual<float>(expected_min, *GetOutput(1));\n  Tensor expected_max(allocator(), DT_FLOAT, TensorShape({}));\n  test::FillValues<float>(&expected_max, {1.0f});\n  test::ExpectTensorEqual<float>(expected_max, *GetOutput(2));\n}\n\n}  // end namespace tensorflow\n", "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for tf.quantize ops.\"\"\"\nimport numpy as np\n\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import nn_ops\nfrom tensorflow.python.platform import googletest\n\n\nclass FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars(\n              inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars(\n              inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))\n\n\nclass FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 1\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[[0.0]], max=[1.0]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"Dimensions must be equal|incorrect size\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 1\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[1.0], max=[[1.0]]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"Dimensions must be equal|incorrect size\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n\n\nclass QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)\n    bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=[],\n              max_input=1.0,\n              min_bias=0.0,\n              max_bias=1.0,\n              out_type=dtypes.qint32))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=0.0,\n              max_input=[],\n              min_bias=0.0,\n              max_bias=1.0,\n              out_type=dtypes.qint32))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=0.0,\n              max_input=1.0,\n              min_bias=[],\n              max_bias=1.0,\n              out_type=dtypes.qint32))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=0.0,\n              max_input=1.0,\n              min_bias=0.0,\n              max_bias=[],\n              out_type=dtypes.qint32))\n\n\nclass QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.quantized_instance_norm(\n              x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.quantized_instance_norm(\n              x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))\n\n\nclass RequantizeOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=[],\n              input_max=1.0,\n              requested_output_min=0.0,\n              requested_output_max=1.0,\n              out_type=dtypes.qint8))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=0.0,\n              input_max=[],\n              requested_output_min=0.0,\n              requested_output_max=1.0,\n              out_type=dtypes.qint8))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=0.0,\n              input_max=1.0,\n              requested_output_min=[],\n              requested_output_max=1.0,\n              out_type=dtypes.qint8))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=0.0,\n              input_max=1.0,\n              requested_output_min=0.0,\n              requested_output_max=[],\n              out_type=dtypes.qint8))\n\n\nclass QuantizedAddOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    x = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.quantized_add(\n              x=x,\n              y=y,\n              min_x=[],\n              max_x=1.0,\n              min_y=0.0,\n              max_y=1.0,\n              Toutput=dtypes.qint32))\n\n\nclass QuantizedReluOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_relu(\n              features=inputs,\n              min_features=[],\n              max_features=127.0,\n              out_type=dtypes.quint8))\n\n\nclass QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_relu6(\n              features=inputs,\n              min_features=[],\n              max_features=127.0,\n              out_type=dtypes.quint8))\n\n\nclass QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.quantize_down_and_shrink_range(input=inputs,\n                                                  input_min=[],\n                                                  input_max=4.0,\n                                                  out_type=dtypes.quint8))\n\n\nif __name__ == \"__main__\":\n  googletest.main()\n"], "filenames": ["tensorflow/core/kernels/quantize_down_and_shrink_range.cc", "tensorflow/core/kernels/quantize_down_and_shrink_range_op_test.cc", "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"], "buggy_code_start_loc": [43, 56, 263], "buggy_code_end_loc": [45, 58, 263], "fixing_code_start_loc": [43, 56, 264], "fixing_code_end_loc": [57, 58, 280], "type": "NVD-CWE-noinfo", "message": "TensorFlow is an open source platform for machine learning. If `QuantizeDownAndShrinkRange` is given nonscalar inputs for `input_min` or `input_max`, it results in a segfault that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 73ad1815ebcfeb7c051f9c2f7ab5024380ca8613. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.", "other": {"cve": {"id": "CVE-2022-35974", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-16T21:15:09.550", "lastModified": "2022-09-20T19:19:45.370", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. If `QuantizeDownAndShrinkRange` is given nonscalar inputs for `input_min` or `input_max`, it results in a segfault that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 73ad1815ebcfeb7c051f9c2f7ab5024380ca8613. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. Si \"QuantizeDownAndShrinkRange\" recibe entradas no escalares para \"input_min\" o \"input_max\", resulta en un segfault que puede usarse para desencadenar un ataque de denegaci\u00f3n de servicio. Hemos parcheado el problema en el commit 73ad1815ebcfeb7c051f9c2f7ab5024380ca8613 de GitHub. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.10.0. Tambi\u00e9n seleccionaremos este compromiso en TensorFlow versi\u00f3n 2.9.1, TensorFlow versi\u00f3n 2.8.1, y TensorFlow versi\u00f3n 2.7.2, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango admitido. No se presentan mitigaciones conocidas para este problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.7.0", "versionEndExcluding": "2.7.2", "matchCriteriaId": "C4DFBF2D-5283-42F6-8800-D653BFA5CE82"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.8.0", "versionEndExcluding": "2.8.1", "matchCriteriaId": "0F9D273D-02DC-441E-AA91-EAC8DEAA4B44"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.9.0", "versionEndExcluding": "2.9.1", "matchCriteriaId": "FE4F8A81-6CC2-4F7F-9602-C170FDD926E7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc0:*:*:*:*:*:*", "matchCriteriaId": "1DBFBCE2-0A01-4575-BE45-6775ABFB8B28"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc1:*:*:*:*:*:*", "matchCriteriaId": "89806CF9-E423-4CA6-A01A-8175C260CB24"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc2:*:*:*:*:*:*", "matchCriteriaId": "F2B80690-A257-4E16-BD27-9AE045BC56ED"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc3:*:*:*:*:*:*", "matchCriteriaId": "F335F9A4-5AB8-4E53-BC18-E01F7C653E5E"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/73ad1815ebcfeb7c051f9c2f7ab5024380ca8613", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vgvh-2pf4-jr2x", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/73ad1815ebcfeb7c051f9c2f7ab5024380ca8613"}}
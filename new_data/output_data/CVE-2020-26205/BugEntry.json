{"buggy_code": ["[flake8]\nmax-line-length = 120\nignore = F401,F405,E402,F403,W504,W605\nmax-complexity = 126\nexclude = venv/*,*/migrations/*,wip_plugins/*,datatableview/*, sal/settings.py\n", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n\t<key>version</key>\n\t<string>4.1.6.2167</string>\n</dict>\n</plist>\n", "import itertools\nimport json\nimport logging\nimport re\nfrom collections import defaultdict\n\nimport dateutil.parser\nimport pytz\n\nimport django.utils.timezone\nfrom django.conf import settings\nfrom django.contrib.auth.decorators import login_required\nfrom django.db.models import Q\nfrom django.http import (\n    HttpResponse, JsonResponse, Http404, HttpResponseBadRequest)\nfrom django.shortcuts import get_object_or_404\nfrom django.urls import reverse\nfrom django.views.decorators.csrf import csrf_exempt\nfrom django.views.decorators.http import require_POST\n\nimport server.utils\nimport utils.csv\nfrom sal.decorators import key_auth_required\nfrom sal.plugin import Widget, ReportPlugin, PluginManager\nfrom server.models import (Machine, Fact, HistoricalFact, MachineGroup, Message, Plugin, Report,\n                           ManagedItem, MachineDetailPlugin, ManagementSource, ManagedItemHistory)\n\n\n# The database probably isn't going to change while this is loaded.\nIS_POSTGRES = server.utils.is_postgres()\nHISTORICAL_FACTS = set(server.utils.get_django_setting('HISTORICAL_FACTS', []))\nif server.utils.get_django_setting('IGNORE_FACTS'):\n    IGNORE_PREFIXES = re.compile(\n        '|'.join(server.utils.get_django_setting('IGNORE_FACTS')))\nelse:\n    IGNORE_PREFIXES = None\n# Build a translation table for serial numbers, to remove garbage\n# VMware puts in.\nSERIAL_TRANSLATE = {ord(c): None for c in '+/'}\n\nlogger = logging.getLogger(__name__)\n\n\n@login_required\ndef tableajax(request, plugin_name, data, group_type='all', group_id=None):\n    \"\"\"Table ajax for dataTables\"\"\"\n    # Pull our variables out of the GET request\n    get_data = request.GET['args']\n    get_data = json.loads(get_data)\n    draw = get_data.get('draw', 0)\n    start = int(get_data.get('start', 0))\n    length = int(get_data.get('length', 0))\n    search_value = ''\n    if 'search' in get_data:\n        if 'value' in get_data['search']:\n            search_value = get_data['search']['value']\n\n    # default ordering\n    order_column = 2\n    order_direction = 'desc'\n    order_name = ''\n    if 'order' in get_data:\n        order_column = get_data['order'][0]['column']\n        order_direction = get_data['order'][0]['dir']\n    for column in get_data.get('columns', None):\n        if column['data'] == order_column:\n            order_name = column['name']\n            break\n\n    plugin_object = process_plugin(plugin_name, group_type, group_id)\n    queryset = plugin_object.get_queryset(\n        request, group_type=group_type, group_id=group_id)\n    machines, title = plugin_object.filter_machines(queryset, data)\n    machines = machines.values('id', 'hostname', 'console_user', 'last_checkin')\n\n    if len(order_name) != 0:\n        if order_direction == 'desc':\n            order_string = \"-%s\" % order_name\n        else:\n            order_string = \"%s\" % order_name\n\n    if len(search_value) != 0:\n        hostname_q = Q(hostname__icontains=search_value)\n        user_q = Q(console_user__icontains=search_value)\n        checkin_q = Q(last_checkin__icontains=search_value)\n        searched_machines = machines.filter(hostname_q | user_q | checkin_q).order_by(order_string)\n    else:\n        searched_machines = machines.order_by(order_string)\n\n    limited_machines = searched_machines[start:(start + length)]\n\n    return_data = {}\n    return_data['title'] = title\n    return_data['draw'] = int(draw)\n    return_data['recordsTotal'] = machines.count()\n    return_data['recordsFiltered'] = return_data['recordsTotal']\n\n    return_data['data'] = []\n    settings_time_zone = None\n    try:\n        settings_time_zone = pytz.timezone(settings.TIME_ZONE)\n    except Exception:\n        pass\n\n    for machine in limited_machines:\n        if machine['last_checkin']:\n            # formatted_date = pytz.utc.localize(machine.last_checkin)\n            if settings_time_zone:\n                formatted_date = machine['last_checkin'].astimezone(\n                    settings_time_zone).strftime(\"%Y-%m-%d %H:%M %Z\")\n            else:\n                formatted_date = machine['last_checkin'].strftime(\"%Y-%m-%d %H:%M\")\n        else:\n            formatted_date = \"\"\n        hostname_link = \"<a href=\\\"%s\\\">%s</a>\" % (\n            reverse('machine_detail', args=[machine['id']]), machine['hostname'])\n\n        list_data = [hostname_link, machine['console_user'], formatted_date]\n        return_data['data'].append(list_data)\n\n    return JsonResponse(return_data)\n\n\n@login_required\ndef plugin_load(request, plugin_name, group_type='all', group_id=None):\n    plugin_object = process_plugin(plugin_name, group_type, group_id)\n    return HttpResponse(\n        plugin_object.widget_content(request, group_type=group_type, group_id=group_id))\n\n\ndef process_plugin(plugin_name, group_type='all', group_id=None):\n    plugin = PluginManager.get_plugin_by_name(plugin_name)\n\n    # Ensure that a plugin was instantiated before proceeding.\n    if not plugin:\n        raise Http404\n\n    # Ensure the request is not for a disabled plugin.\n    if isinstance(plugin, Widget):\n        model = Plugin\n    elif isinstance(plugin, ReportPlugin):\n        model = Report\n    else:\n        model = MachineDetailPlugin\n    get_object_or_404(model, name=plugin_name)\n\n    return plugin\n\n\n@login_required\ndef export_csv(request, plugin_name, data, group_type='all', group_id=None):\n    plugin_object = process_plugin(plugin_name, group_type, group_id)\n    queryset = plugin_object.get_queryset(\n        request, group_type=group_type, group_id=group_id)\n    machines, title = plugin_object.filter_machines(queryset, data)\n\n    return utils.csv.get_csv_response(machines, utils.csv.machine_fields(), title)\n\n\n@csrf_exempt\n@key_auth_required\ndef preflight_v2(request):\n    \"\"\"Find plugins that have embedded preflight scripts.\"\"\"\n    # Load in the default plugins if needed\n    server.utils.load_default_plugins()\n    output = []\n    # Old Sal scripts just do a GET; just send everything in that case.\n    os_family = None if request.method != 'POST' else request.POST.get('os_family')\n\n    enabled_reports = Report.objects.all()\n    enabled_plugins = Plugin.objects.all()\n    enabled_detail_plugins = MachineDetailPlugin.objects.all()\n    for enabled_plugin in itertools.chain(enabled_reports, enabled_plugins, enabled_detail_plugins):\n        plugin = PluginManager.get_plugin_by_name(enabled_plugin.name)\n        if not plugin:\n            continue\n        if os_family is None or os_family in plugin.get_supported_os_families():\n            scripts = server.utils.get_plugin_scripts(plugin, hash_only=True)\n            if scripts:\n                output += scripts\n\n    return HttpResponse(json.dumps(output))\n\n\n@csrf_exempt\n@key_auth_required\ndef preflight_v2_get_script(request, plugin_name, script_name):\n    output = []\n    plugin = PluginManager.get_plugin_by_name(plugin_name)\n    if plugin:\n        content = server.utils.get_plugin_scripts(plugin, script_name=script_name)\n        if content:\n            output += content\n\n    return HttpResponse(json.dumps(output))\n\n\n@csrf_exempt\n@require_POST\n@key_auth_required\ndef report_broken_client(request):\n    data = request.POST\n\n    # Take out some of the weird junk VMware puts in. Keep an eye out in case\n    # Apple actually uses these:\n    serial = data.get('serial', '').upper().translate(SERIAL_TRANSLATE)\n    # Are we using Sal for some sort of inventory (like, I don't know, Puppet?)\n    machine = get_object_or_404(Machine, serial=serial)\n\n    machine_group_key = data.get('key')\n    machine.machine_group = get_object_or_404(MachineGroup, key=machine_group_key)\n\n    machine.last_checkin = django.utils.timezone.now()\n    machine.hostname = data.get('name', '<NO NAME>')\n    machine.sal_version = data.get('sal_version')\n\n    if server.utils.get_django_setting('DEPLOYED_ON_CHECKIN', False):\n        machine.deployed = True\n\n    if bool(data.get('broken_client', False)):\n        machine.broken_client = True\n        machine.save()\n        return HttpResponse(\"Broken Client report submmitted for %s\" % data.get('serial'))\n    return HttpResponseBadRequest()\n\n\n@csrf_exempt\n@require_POST\n@key_auth_required\ndef checkin(request):\n    if request.content_type != 'application/json':\n        return HttpResponseBadRequest('Checkin must be content-type \"application/json\"!')\n    # Ensure we have the bare minimum data before continuing.\n    try:\n        submission = json.loads(request.body.decode())\n    except json.JSONDecodeError:\n        return HttpResponseBadRequest('Checkin has invalid JSON!')\n    if not isinstance(submission, dict) or 'Machine' not in submission:\n        return HttpResponseBadRequest('Checkin JSON is missing required key \"Machine\"!')\n\n    # Process machine submission information.\n    try:\n        serial = submission['Machine']['extra_data'].get('serial')\n    except KeyError:\n        return HttpResponseBadRequest('Checkin JSON is missing required \"Machine\" key \"serial\"!')\n    if not serial:\n        return HttpResponseBadRequest('Checkin JSON is missing required \"Machine\" key \"serial\"!')\n\n    machine = process_checkin_serial(serial)\n    machine_group = get_object_or_404(MachineGroup, key=submission['Sal']['extra_data'].get('key'))\n    machine.machine_group = machine_group\n    machine.broken_client = False\n    machine.save()\n    clean_related(machine)\n\n    object_queue = {\n        'facts': [],\n        'historical_facts': [],\n        'managed_items': [],\n        'managed_item_histories': [],\n        'messages': []\n    }\n\n    # Pop off the plugin_results, because they are a list instead of\n    # a dict.\n    plugin_results = submission.pop('plugin_results', {})\n    for management_source_name, management_data in submission.items():\n        management_source, _ = ManagementSource.objects.get_or_create(\n            name=management_source_name)\n\n        object_queue = process_management_submission(\n            management_source, management_data, machine, object_queue)\n\n    object_queue = process_managed_item_histories(object_queue, machine)\n\n    create_objects(object_queue)\n\n    server.utils.process_plugin_script(plugin_results, machine)\n    server.utils.run_plugin_processing(machine, submission)\n\n    if server.utils.get_setting('send_data') in (None, True):\n        # If setting is None, it hasn't been configured yet; assume True\n        try:\n            # If the report server is down, don't halt all submissions\n            server.utils.send_report()\n        except Exception as e:\n            logger.debug(e)\n\n    msg = f\"Sal report submitted for {machine.serial}\"\n    logger.debug(msg)\n    return HttpResponse(msg)\n\n\ndef process_checkin_serial(serial):\n    # Take out some of the weird junk VMware puts in. Keep an eye out in case\n    # Apple actually uses these:\n    serial = serial.upper().translate(SERIAL_TRANSLATE)\n\n    # Are we using Sal for some sort of inventory (like, I don't know, Puppet?)\n    if server.utils.get_django_setting('ADD_NEW_MACHINES', True):\n        try:\n            machine = Machine.objects.get(serial=serial)\n        except Machine.DoesNotExist:\n            machine = Machine(serial=serial)\n            logger.debug(\"Creating new machine for checkin: '%s'\", serial)\n    else:\n        machine = get_object_or_404(Machine, serial=serial)\n    return machine\n\n\ndef clean_related(machine):\n    # Clear out existing Facts and start from scratch.\n    facts = machine.facts.all()\n    if facts.exists():\n        facts._raw_delete(facts.db)\n\n    # Clear out existing ManagedItems and start from scratch.\n    managed_items = machine.manageditem_set.all()\n    if managed_items.exists():\n        managed_items._raw_delete(managed_items.db)\n\n    # Clear out existing Messages and start from scratch.\n    messages = machine.messages.all()\n    if messages.exists():\n        messages._raw_delete(messages.db)\n\n\ndef process_management_submission(source, management_data, machine, object_queue):\n    \"\"\"Process a single management source's data\n\n    This function first optionally calls any additional processors for\n    the management source in question (Munki for example).\n\n    Then it processes Facts.\n    Then ManagedItems.\n    \"\"\"\n    # Add custom processor funcs to this dictionary.\n    # The key should be the same name used in the submission for ManagementSource.\n    # The func's signature must be\n    # f(management_data: dict, machine: Machine, object_queue: dict)\n    processing_funcs = {\n        'Machine': process_machine_submission,\n        'Sal': process_sal_submission,\n        'Munki': process_munki_extra_keys}\n\n    processing_func = processing_funcs.get(source.name)\n    if processing_func:\n        object_queue = processing_func(management_data, machine, object_queue)\n\n    object_queue = process_facts(source, management_data, machine, object_queue)\n    object_queue = process_managed_items(source, management_data, machine, object_queue)\n    object_queue = process_messages(source, management_data, machine, object_queue)\n\n    return object_queue\n\n\ndef process_machine_submission(machine_submission, machine, object_queue):\n    extra_data = machine_submission.get('extra_data', {})\n    machine.hostname = extra_data.get('hostname', '<NO NAME>')\n    # Drop the setup assistant user if encountered.\n    console_user = extra_data.get('console_user')\n    console_user = console_user if console_user != '_mbsetupuser' else None\n    machine.console_user = console_user\n    machine.os_family = extra_data.get('os_family', 'Darwin')\n    machine.operating_system = extra_data.get('operating_system')\n    machine.hd_space = extra_data.get('hd_space')\n    machine.hd_total = extra_data.get('hd_total')\n    machine.hd_percent = extra_data.get('hd_percent')\n    machine.machine_model = extra_data.get('machine_model')\n    machine.machine_model_friendly = extra_data.get('machine_model_friendly')\n    machine.cpu_type = extra_data.get('cpu_type')\n    machine.cpu_speed = extra_data.get('cpu_speed')\n    machine.memory = extra_data.get('memory')\n    machine.memory_kb = extra_data.get('memory_kb', 0)\n    machine.save()\n    return object_queue\n\n\ndef process_sal_submission(sal_submission, machine, object_queue):\n    extras = sal_submission.get('extra_data', {})\n    machine.sal_version = extras.get('sal_version')\n    machine.last_checkin = django.utils.timezone.now()\n\n    if server.utils.get_django_setting('DEPLOYED_ON_CHECKIN', True):\n        machine.deployed = True\n\n    machine.save()\n    return object_queue\n\n\ndef process_munki_extra_keys(management_data, machine, object_queue):\n    extra_data = management_data.get('extra_data', {})\n    machine.munki_version = extra_data.get('munki_version')\n    machine.manifest = extra_data.get('manifest')\n    machine.save()\n    return object_queue\n\n\ndef process_facts(management_source, management_data, machine, object_queue):\n    now = django.utils.timezone.now()\n    for fact_name, fact_data in management_data.get('facts', {}).items():\n        if IGNORE_PREFIXES and IGNORE_PREFIXES.match(fact_name):\n            continue\n\n        object_queue['facts'].append(\n            Fact(\n                machine=machine, fact_data=fact_data, fact_name=fact_name,\n                management_source=management_source))\n\n        if fact_name in HISTORICAL_FACTS:\n            object_queue['historical_facts'].append(\n                HistoricalFact(\n                    machine=machine, fact_data=fact_data, fact_name=fact_name,\n                    management_source=management_source, fact_recorded=now))\n\n    return object_queue\n\n\ndef process_managed_items(management_source, management_data, machine, object_queue):\n    now = django.utils.timezone.now()\n    for name, managed_item in management_data.get('managed_items', {}).items():\n        object_queue['managed_items'].append(\n            _process_managed_item(name, managed_item, machine, management_source, now))\n\n    return object_queue\n\n\ndef _process_managed_item(name, managed_item, machine, management_source, now):\n    submitted_date = managed_item.get('date_managed')\n    try:\n        # Make sure there isn't somerthing stupid in the date format\n        date_managed = dateutil.parser.parse(submitted_date) if submitted_date else now\n    except Exception:\n        date_managed = now\n    status = managed_item.get('status', 'UNKNOWN')\n    data = managed_item.get('data')\n    dumped_data = json.dumps(data) if data else None\n    return ManagedItem(\n        name=name, machine=machine, management_source=management_source,\n        date_managed=date_managed, status=status, data=dumped_data)\n\n\ndef process_managed_item_histories(object_queue, machine):\n    histories = machine.manageditemhistory_set.all()\n    for managed_item in object_queue['managed_items']:\n        item_histories = histories.filter(\n            name=managed_item.name, management_source=managed_item.management_source)\n        if _history_creation_needed(managed_item, item_histories.first()):\n            object_queue['managed_item_histories'].append(\n                ManagedItemHistory(\n                    name=managed_item.name,\n                    status=managed_item.status,\n                    management_source=managed_item.management_source,\n                    machine=machine,\n                    recorded=managed_item.date_managed))\n\n    return object_queue\n\n\ndef _history_creation_needed(managed_item, last_history):\n    if not last_history or last_history.status != managed_item.status:\n        return True\n    else:\n        return False\n\n\ndef process_messages(management_source, management_data, machine, object_queue):\n    now = django.utils.timezone.now()\n    for message_item in management_data.get('messages', []):\n        object_queue['messages'].append(\n            Message(\n                machine=machine,\n                management_source=management_source,\n                text=message_item.get('text'),\n                message_type=message_item.get('message_type'),\n                date=message_item.get('date', now)))\n\n    return object_queue\n\n\ndef create_objects(object_queue):\n    \"\"\"Bulk create Fact, HistoricalFact, Message, and ManagedItem objects.\"\"\"\n    models = {'facts': Fact, 'historical_facts': HistoricalFact, 'managed_items': ManagedItem,\n              'messages': Message, 'managed_item_histories': ManagedItemHistory}\n\n    for name, objects in object_queue.items():\n        _bulk_create_or_iterate_save(objects, models[name])\n\n\ndef _bulk_create_or_iterate_save(objects, model):\n    if objects and IS_POSTGRES:\n        model.objects.bulk_create(objects)\n    else:\n        for item in objects:\n            item.save()\n"], "fixing_code": ["[flake8]\nmax-line-length = 120\nignore = F401,F405,E402,F403,W504,W605,E203\nmax-complexity = 126\nexclude = venv/*,*/migrations/*,wip_plugins/*,datatableview/*, sal/settings.py\n", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n\t<key>version</key>\n\t<string>4.1.6.2169</string>\n</dict>\n</plist>\n", "import itertools\nimport json\nimport logging\nimport re\nfrom collections import defaultdict\n\nimport dateutil.parser\nimport pytz\n\nimport django.utils.timezone\nfrom django.conf import settings\nfrom django.contrib.auth.decorators import login_required\nfrom django.db.models import Q\nfrom django.http import HttpResponse, JsonResponse, Http404, HttpResponseBadRequest\nfrom django.shortcuts import get_object_or_404\nfrom django.urls import reverse\nfrom django.views.decorators.csrf import csrf_exempt\nfrom django.views.decorators.http import require_POST\nfrom django.utils.html import escape\n\nimport server.utils\nimport utils.csv\nfrom sal.decorators import key_auth_required\nfrom sal.plugin import Widget, ReportPlugin, PluginManager\nfrom server.models import (\n    Machine,\n    Fact,\n    HistoricalFact,\n    MachineGroup,\n    Message,\n    Plugin,\n    Report,\n    ManagedItem,\n    MachineDetailPlugin,\n    ManagementSource,\n    ManagedItemHistory,\n)\n\n\n# The database probably isn't going to change while this is loaded.\nIS_POSTGRES = server.utils.is_postgres()\nHISTORICAL_FACTS = set(server.utils.get_django_setting(\"HISTORICAL_FACTS\", []))\nif server.utils.get_django_setting(\"IGNORE_FACTS\"):\n    IGNORE_PREFIXES = re.compile(\n        \"|\".join(server.utils.get_django_setting(\"IGNORE_FACTS\"))\n    )\nelse:\n    IGNORE_PREFIXES = None\n# Build a translation table for serial numbers, to remove garbage\n# VMware puts in.\nSERIAL_TRANSLATE = {ord(c): None for c in \"+/\"}\n\nlogger = logging.getLogger(__name__)\n\n\n@login_required\ndef tableajax(request, plugin_name, data, group_type=\"all\", group_id=None):\n    \"\"\"Table ajax for dataTables\"\"\"\n    # Pull our variables out of the GET request\n    get_data = request.GET[\"args\"]\n    get_data = json.loads(get_data)\n    draw = get_data.get(\"draw\", 0)\n    start = int(get_data.get(\"start\", 0))\n    length = int(get_data.get(\"length\", 0))\n    search_value = \"\"\n    if \"search\" in get_data:\n        if \"value\" in get_data[\"search\"]:\n            search_value = get_data[\"search\"][\"value\"]\n\n    # default ordering\n    order_column = 2\n    order_direction = \"desc\"\n    order_name = \"\"\n    if \"order\" in get_data:\n        order_column = get_data[\"order\"][0][\"column\"]\n        order_direction = get_data[\"order\"][0][\"dir\"]\n    for column in get_data.get(\"columns\", None):\n        if column[\"data\"] == order_column:\n            order_name = column[\"name\"]\n            break\n\n    plugin_object = process_plugin(plugin_name, group_type, group_id)\n    queryset = plugin_object.get_queryset(\n        request, group_type=group_type, group_id=group_id\n    )\n    machines, title = plugin_object.filter_machines(queryset, data)\n    machines = machines.values(\"id\", \"hostname\", \"console_user\", \"last_checkin\")\n\n    if len(order_name) != 0:\n        if order_direction == \"desc\":\n            order_string = \"-%s\" % order_name\n        else:\n            order_string = \"%s\" % order_name\n\n    if len(search_value) != 0:\n        hostname_q = Q(hostname__icontains=search_value)\n        user_q = Q(console_user__icontains=search_value)\n        checkin_q = Q(last_checkin__icontains=search_value)\n        searched_machines = machines.filter(hostname_q | user_q | checkin_q).order_by(\n            order_string\n        )\n    else:\n        searched_machines = machines.order_by(order_string)\n\n    limited_machines = searched_machines[start : (start + length)]\n\n    return_data = {}\n    return_data[\"title\"] = title\n    return_data[\"draw\"] = int(draw)\n    return_data[\"recordsTotal\"] = machines.count()\n    return_data[\"recordsFiltered\"] = return_data[\"recordsTotal\"]\n\n    return_data[\"data\"] = []\n    settings_time_zone = None\n    try:\n        settings_time_zone = pytz.timezone(settings.TIME_ZONE)\n    except Exception:\n        pass\n\n    for machine in limited_machines:\n        if machine[\"last_checkin\"]:\n            # formatted_date = pytz.utc.localize(machine.last_checkin)\n            if settings_time_zone:\n                formatted_date = (\n                    machine[\"last_checkin\"]\n                    .astimezone(settings_time_zone)\n                    .strftime(\"%Y-%m-%d %H:%M %Z\")\n                )\n            else:\n                formatted_date = machine[\"last_checkin\"].strftime(\"%Y-%m-%d %H:%M\")\n        else:\n            formatted_date = \"\"\n        hostname_link = '<a href=\"%s\">%s</a>' % (\n            reverse(\"machine_detail\", args=[machine[\"id\"]]),\n            escape(machine[\"hostname\"]),\n        )\n\n        list_data = [hostname_link, escape(machine[\"console_user\"]), formatted_date]\n        return_data[\"data\"].append(list_data)\n\n    return JsonResponse(return_data)\n\n\n@login_required\ndef plugin_load(request, plugin_name, group_type=\"all\", group_id=None):\n    plugin_object = process_plugin(plugin_name, group_type, group_id)\n    return HttpResponse(\n        plugin_object.widget_content(request, group_type=group_type, group_id=group_id)\n    )\n\n\ndef process_plugin(plugin_name, group_type=\"all\", group_id=None):\n    plugin = PluginManager.get_plugin_by_name(plugin_name)\n\n    # Ensure that a plugin was instantiated before proceeding.\n    if not plugin:\n        raise Http404\n\n    # Ensure the request is not for a disabled plugin.\n    if isinstance(plugin, Widget):\n        model = Plugin\n    elif isinstance(plugin, ReportPlugin):\n        model = Report\n    else:\n        model = MachineDetailPlugin\n    get_object_or_404(model, name=plugin_name)\n\n    return plugin\n\n\n@login_required\ndef export_csv(request, plugin_name, data, group_type=\"all\", group_id=None):\n    plugin_object = process_plugin(plugin_name, group_type, group_id)\n    queryset = plugin_object.get_queryset(\n        request, group_type=group_type, group_id=group_id\n    )\n    machines, title = plugin_object.filter_machines(queryset, data)\n\n    return utils.csv.get_csv_response(machines, utils.csv.machine_fields(), title)\n\n\n@csrf_exempt\n@key_auth_required\ndef preflight_v2(request):\n    \"\"\"Find plugins that have embedded preflight scripts.\"\"\"\n    # Load in the default plugins if needed\n    server.utils.load_default_plugins()\n    output = []\n    # Old Sal scripts just do a GET; just send everything in that case.\n    os_family = None if request.method != \"POST\" else request.POST.get(\"os_family\")\n\n    enabled_reports = Report.objects.all()\n    enabled_plugins = Plugin.objects.all()\n    enabled_detail_plugins = MachineDetailPlugin.objects.all()\n    for enabled_plugin in itertools.chain(\n        enabled_reports, enabled_plugins, enabled_detail_plugins\n    ):\n        plugin = PluginManager.get_plugin_by_name(enabled_plugin.name)\n        if not plugin:\n            continue\n        if os_family is None or os_family in plugin.get_supported_os_families():\n            scripts = server.utils.get_plugin_scripts(plugin, hash_only=True)\n            if scripts:\n                output += scripts\n\n    return HttpResponse(json.dumps(output))\n\n\n@csrf_exempt\n@key_auth_required\ndef preflight_v2_get_script(request, plugin_name, script_name):\n    output = []\n    plugin = PluginManager.get_plugin_by_name(plugin_name)\n    if plugin:\n        content = server.utils.get_plugin_scripts(plugin, script_name=script_name)\n        if content:\n            output += content\n\n    return HttpResponse(json.dumps(output))\n\n\n@csrf_exempt\n@require_POST\n@key_auth_required\ndef report_broken_client(request):\n    data = request.POST\n\n    # Take out some of the weird junk VMware puts in. Keep an eye out in case\n    # Apple actually uses these:\n    serial = data.get(\"serial\", \"\").upper().translate(SERIAL_TRANSLATE)\n    # Are we using Sal for some sort of inventory (like, I don't know, Puppet?)\n    machine = get_object_or_404(Machine, serial=serial)\n\n    machine_group_key = data.get(\"key\")\n    machine.machine_group = get_object_or_404(MachineGroup, key=machine_group_key)\n\n    machine.last_checkin = django.utils.timezone.now()\n    machine.hostname = data.get(\"name\", \"<NO NAME>\")\n    machine.sal_version = data.get(\"sal_version\")\n\n    if server.utils.get_django_setting(\"DEPLOYED_ON_CHECKIN\", False):\n        machine.deployed = True\n\n    if bool(data.get(\"broken_client\", False)):\n        machine.broken_client = True\n        machine.save()\n        return HttpResponse(\n            \"Broken Client report submmitted for %s\" % data.get(\"serial\")\n        )\n    return HttpResponseBadRequest()\n\n\n@csrf_exempt\n@require_POST\n@key_auth_required\ndef checkin(request):\n    if request.content_type != \"application/json\":\n        return HttpResponseBadRequest(\n            'Checkin must be content-type \"application/json\"!'\n        )\n    # Ensure we have the bare minimum data before continuing.\n    try:\n        submission = json.loads(request.body.decode())\n    except json.JSONDecodeError:\n        return HttpResponseBadRequest(\"Checkin has invalid JSON!\")\n    if not isinstance(submission, dict) or \"Machine\" not in submission:\n        return HttpResponseBadRequest('Checkin JSON is missing required key \"Machine\"!')\n\n    # Process machine submission information.\n    try:\n        serial = submission[\"Machine\"][\"extra_data\"].get(\"serial\")\n    except KeyError:\n        return HttpResponseBadRequest(\n            'Checkin JSON is missing required \"Machine\" key \"serial\"!'\n        )\n    if not serial:\n        return HttpResponseBadRequest(\n            'Checkin JSON is missing required \"Machine\" key \"serial\"!'\n        )\n\n    machine = process_checkin_serial(serial)\n    machine_group = get_object_or_404(\n        MachineGroup, key=submission[\"Sal\"][\"extra_data\"].get(\"key\")\n    )\n    machine.machine_group = machine_group\n    machine.broken_client = False\n    machine.save()\n    clean_related(machine)\n\n    object_queue = {\n        \"facts\": [],\n        \"historical_facts\": [],\n        \"managed_items\": [],\n        \"managed_item_histories\": [],\n        \"messages\": [],\n    }\n\n    # Pop off the plugin_results, because they are a list instead of\n    # a dict.\n    plugin_results = submission.pop(\"plugin_results\", {})\n    for management_source_name, management_data in submission.items():\n        management_source, _ = ManagementSource.objects.get_or_create(\n            name=management_source_name\n        )\n\n        object_queue = process_management_submission(\n            management_source, management_data, machine, object_queue\n        )\n\n    object_queue = process_managed_item_histories(object_queue, machine)\n\n    create_objects(object_queue)\n\n    server.utils.process_plugin_script(plugin_results, machine)\n    server.utils.run_plugin_processing(machine, submission)\n\n    if server.utils.get_setting(\"send_data\") in (None, True):\n        # If setting is None, it hasn't been configured yet; assume True\n        try:\n            # If the report server is down, don't halt all submissions\n            server.utils.send_report()\n        except Exception as e:\n            logger.debug(e)\n\n    msg = f\"Sal report submitted for {machine.serial}\"\n    logger.debug(msg)\n    return HttpResponse(msg)\n\n\ndef process_checkin_serial(serial):\n    # Take out some of the weird junk VMware puts in. Keep an eye out in case\n    # Apple actually uses these:\n    serial = serial.upper().translate(SERIAL_TRANSLATE)\n\n    # Are we using Sal for some sort of inventory (like, I don't know, Puppet?)\n    if server.utils.get_django_setting(\"ADD_NEW_MACHINES\", True):\n        try:\n            machine = Machine.objects.get(serial=serial)\n        except Machine.DoesNotExist:\n            machine = Machine(serial=serial)\n            logger.debug(\"Creating new machine for checkin: '%s'\", serial)\n    else:\n        machine = get_object_or_404(Machine, serial=serial)\n    return machine\n\n\ndef clean_related(machine):\n    # Clear out existing Facts and start from scratch.\n    facts = machine.facts.all()\n    if facts.exists():\n        facts._raw_delete(facts.db)\n\n    # Clear out existing ManagedItems and start from scratch.\n    managed_items = machine.manageditem_set.all()\n    if managed_items.exists():\n        managed_items._raw_delete(managed_items.db)\n\n    # Clear out existing Messages and start from scratch.\n    messages = machine.messages.all()\n    if messages.exists():\n        messages._raw_delete(messages.db)\n\n\ndef process_management_submission(source, management_data, machine, object_queue):\n    \"\"\"Process a single management source's data\n\n    This function first optionally calls any additional processors for\n    the management source in question (Munki for example).\n\n    Then it processes Facts.\n    Then ManagedItems.\n    \"\"\"\n    # Add custom processor funcs to this dictionary.\n    # The key should be the same name used in the submission for ManagementSource.\n    # The func's signature must be\n    # f(management_data: dict, machine: Machine, object_queue: dict)\n    processing_funcs = {\n        \"Machine\": process_machine_submission,\n        \"Sal\": process_sal_submission,\n        \"Munki\": process_munki_extra_keys,\n    }\n\n    processing_func = processing_funcs.get(source.name)\n    if processing_func:\n        object_queue = processing_func(management_data, machine, object_queue)\n\n    object_queue = process_facts(source, management_data, machine, object_queue)\n    object_queue = process_managed_items(source, management_data, machine, object_queue)\n    object_queue = process_messages(source, management_data, machine, object_queue)\n\n    return object_queue\n\n\ndef process_machine_submission(machine_submission, machine, object_queue):\n    extra_data = machine_submission.get(\"extra_data\", {})\n    machine.hostname = extra_data.get(\"hostname\", \"<NO NAME>\")\n    # Drop the setup assistant user if encountered.\n    console_user = extra_data.get(\"console_user\")\n    console_user = console_user if console_user != \"_mbsetupuser\" else None\n    machine.console_user = console_user\n    machine.os_family = extra_data.get(\"os_family\", \"Darwin\")\n    machine.operating_system = extra_data.get(\"operating_system\")\n    machine.hd_space = extra_data.get(\"hd_space\")\n    machine.hd_total = extra_data.get(\"hd_total\")\n    machine.hd_percent = extra_data.get(\"hd_percent\")\n    machine.machine_model = extra_data.get(\"machine_model\")\n    machine.machine_model_friendly = extra_data.get(\"machine_model_friendly\")\n    machine.cpu_type = extra_data.get(\"cpu_type\")\n    machine.cpu_speed = extra_data.get(\"cpu_speed\")\n    machine.memory = extra_data.get(\"memory\")\n    machine.memory_kb = extra_data.get(\"memory_kb\", 0)\n    machine.save()\n    return object_queue\n\n\ndef process_sal_submission(sal_submission, machine, object_queue):\n    extras = sal_submission.get(\"extra_data\", {})\n    machine.sal_version = extras.get(\"sal_version\")\n    machine.last_checkin = django.utils.timezone.now()\n\n    if server.utils.get_django_setting(\"DEPLOYED_ON_CHECKIN\", True):\n        machine.deployed = True\n\n    machine.save()\n    return object_queue\n\n\ndef process_munki_extra_keys(management_data, machine, object_queue):\n    extra_data = management_data.get(\"extra_data\", {})\n    machine.munki_version = extra_data.get(\"munki_version\")\n    machine.manifest = extra_data.get(\"manifest\")\n    machine.save()\n    return object_queue\n\n\ndef process_facts(management_source, management_data, machine, object_queue):\n    now = django.utils.timezone.now()\n    for fact_name, fact_data in management_data.get(\"facts\", {}).items():\n        if IGNORE_PREFIXES and IGNORE_PREFIXES.match(fact_name):\n            continue\n\n        object_queue[\"facts\"].append(\n            Fact(\n                machine=machine,\n                fact_data=fact_data,\n                fact_name=fact_name,\n                management_source=management_source,\n            )\n        )\n\n        if fact_name in HISTORICAL_FACTS:\n            object_queue[\"historical_facts\"].append(\n                HistoricalFact(\n                    machine=machine,\n                    fact_data=fact_data,\n                    fact_name=fact_name,\n                    management_source=management_source,\n                    fact_recorded=now,\n                )\n            )\n\n    return object_queue\n\n\ndef process_managed_items(management_source, management_data, machine, object_queue):\n    now = django.utils.timezone.now()\n    for name, managed_item in management_data.get(\"managed_items\", {}).items():\n        object_queue[\"managed_items\"].append(\n            _process_managed_item(name, managed_item, machine, management_source, now)\n        )\n\n    return object_queue\n\n\ndef _process_managed_item(name, managed_item, machine, management_source, now):\n    submitted_date = managed_item.get(\"date_managed\")\n    try:\n        # Make sure there isn't somerthing stupid in the date format\n        date_managed = dateutil.parser.parse(submitted_date) if submitted_date else now\n    except Exception:\n        date_managed = now\n    status = managed_item.get(\"status\", \"UNKNOWN\")\n    data = managed_item.get(\"data\")\n    dumped_data = json.dumps(data) if data else None\n    return ManagedItem(\n        name=name,\n        machine=machine,\n        management_source=management_source,\n        date_managed=date_managed,\n        status=status,\n        data=dumped_data,\n    )\n\n\ndef process_managed_item_histories(object_queue, machine):\n    histories = machine.manageditemhistory_set.all()\n    for managed_item in object_queue[\"managed_items\"]:\n        item_histories = histories.filter(\n            name=managed_item.name, management_source=managed_item.management_source\n        )\n        if _history_creation_needed(managed_item, item_histories.first()):\n            object_queue[\"managed_item_histories\"].append(\n                ManagedItemHistory(\n                    name=managed_item.name,\n                    status=managed_item.status,\n                    management_source=managed_item.management_source,\n                    machine=machine,\n                    recorded=managed_item.date_managed,\n                )\n            )\n\n    return object_queue\n\n\ndef _history_creation_needed(managed_item, last_history):\n    if not last_history or last_history.status != managed_item.status:\n        return True\n    else:\n        return False\n\n\ndef process_messages(management_source, management_data, machine, object_queue):\n    now = django.utils.timezone.now()\n    for message_item in management_data.get(\"messages\", []):\n        object_queue[\"messages\"].append(\n            Message(\n                machine=machine,\n                management_source=management_source,\n                text=message_item.get(\"text\"),\n                message_type=message_item.get(\"message_type\"),\n                date=message_item.get(\"date\", now),\n            )\n        )\n\n    return object_queue\n\n\ndef create_objects(object_queue):\n    \"\"\"Bulk create Fact, HistoricalFact, Message, and ManagedItem objects.\"\"\"\n    models = {\n        \"facts\": Fact,\n        \"historical_facts\": HistoricalFact,\n        \"managed_items\": ManagedItem,\n        \"messages\": Message,\n        \"managed_item_histories\": ManagedItemHistory,\n    }\n\n    for name, objects in object_queue.items():\n        _bulk_create_or_iterate_save(objects, models[name])\n\n\ndef _bulk_create_or_iterate_save(objects, model):\n    if objects and IS_POSTGRES:\n        model.objects.bulk_create(objects)\n    else:\n        for item in objects:\n            item.save()\n"], "filenames": [".flake8", "sal/version.plist", "server/non_ui_views.py"], "buggy_code_start_loc": [3, 6, 14], "buggy_code_end_loc": [4, 7, 485], "fixing_code_start_loc": [3, 6, 14], "fixing_code_end_loc": [4, 7, 547], "type": "CWE-79", "message": "Sal is a multi-tenanted reporting dashboard for Munki with the ability to display information from Facter. In Sal through version 4.1.6 there is an XSS vulnerability on the machine_list view.", "other": {"cve": {"id": "CVE-2020-26205", "sourceIdentifier": "security-advisories@github.com", "published": "2020-10-29T20:15:19.353", "lastModified": "2020-11-03T17:45:49.700", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Sal is a multi-tenanted reporting dashboard for Munki with the ability to display information from Facter. In Sal through version 4.1.6 there is an XSS vulnerability on the machine_list view."}, {"lang": "es", "value": "Sal es un panel de multitenencia para Munki con la capacidad de mostrar informaci\u00f3n de Facter.&#xa0;En Sal versiones hasta 4.1.6, se presenta una vulnerabilidad de tipo XSS en la vista machine_list"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 5.4, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.3, "impactScore": 2.7}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "LOW", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.6, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.3, "impactScore": 4.7}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:S/C:N/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "SINGLE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 3.5}, "baseSeverity": "LOW", "exploitabilityScore": 6.8, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-79"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:sal_project:sal:*:*:*:*:*:*:*:*", "versionEndIncluding": "4.1.6", "matchCriteriaId": "516245B1-B1CD-4948-88E5-6D0A6DBFB7B4"}]}]}], "references": [{"url": "https://github.com/salopensource/sal/commit/145bb72daf8460bdedbbc9fb708d346283e7a568", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/salopensource/sal/pull/405", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/salopensource/sal/commit/145bb72daf8460bdedbbc9fb708d346283e7a568"}}
{"buggy_code": ["# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Unit tests for TensorFlow \"Eager\" Mode's Tensor class.\"\"\"\n\nimport copy\nimport re\nimport sys\n\nimport numpy as np\n\nfrom tensorflow.python import pywrap_tfe\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import core\nfrom tensorflow.python.eager import test\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import io_ops\nfrom tensorflow.python.ops import list_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.ops import variables\n\n\ndef _create_tensor(value, device=None, dtype=None):\n  context.ensure_initialized()\n  ctx = context.context()\n  if device is None:\n    device = ctx.device_name\n  if dtype is not None:\n    dtype = dtype.as_datatype_enum\n  try:\n    return ops.EagerTensor(value, device=device, dtype=dtype)\n  except core._NotOkStatusException as e:  # pylint: disable=protected-access\n    raise core._status_to_exception(e)\n\n\nclass TFETensorTest(test_util.TensorFlowTestCase):\n\n  def testScalarTensor(self):\n    t = _create_tensor(3, dtype=dtypes.int32)\n    self.assertAllEqual(t, _create_tensor(np.array(3)))\n    self.assertEqual(dtypes.int32, t.dtype)\n    self.assertEqual(0, t.shape.ndims)\n    self.assertAllEqual([], t.shape.as_list())\n    self.assertIn(\"tf.Tensor\", str(t))\n    self.assertIn(\"tf.Tensor\", repr(t))\n\n  def testBadConstructorArgs(self):\n    context.ensure_initialized()\n    ctx = context.context()\n    device = ctx.device_name\n    # Missing device.\n    with self.assertRaisesRegex(TypeError, r\".*argument 'device' \\(pos 2\\).*\"):\n      ops.EagerTensor(1)\n    # Bad dtype type.\n    with self.assertRaisesRegex(TypeError,\n                                \"Expecting a DataType value for dtype. Got\"):\n      ops.EagerTensor(1, device=device, dtype=\"1\")\n\n    # Following errors happen when trying to copy to GPU.\n    if not test_util.is_gpu_available():\n      self.skipTest(\"No GPUs found\")\n\n    with ops.device(\"/device:GPU:0\"):\n      # Bad device.\n      with self.assertRaisesRegex(TypeError, \"Error parsing device argument\"):\n        ops.EagerTensor(1.0, device=1)\n\n  def testNumpyValue(self):\n    values = np.array([3.0])\n    t = _create_tensor(values)\n    self.assertAllEqual(values, t)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testNumpyDtypeSurvivesThroughTensorConversion(self):\n    scalar_creators = [np.int32, np.int64, np.float32, np.float64]\n    conversion_functions = [ops.convert_to_tensor, constant_op.constant]\n\n    for scalar_creator in scalar_creators:\n      for conversion_function in conversion_functions:\n        np_val = scalar_creator(3)\n        tensor_val = conversion_function(np_val)\n        self.assertEqual(tensor_val.numpy().dtype, np_val.dtype)\n        self.assertEqual(tensor_val.numpy(), np_val)\n\n  def testNumpyValueWithCast(self):\n    values = np.array([3.0], dtype=np.float32)\n    t = _create_tensor(values, dtype=dtypes.float64)\n    self.assertAllEqual(values, t)\n    ctx = context.context()\n    # Bad dtype value.\n    with self.assertRaisesRegex(TypeError, \"Invalid dtype argument value\"):\n      ops.EagerTensor(values, device=ctx.device_name, dtype=12345)\n\n  def testNumpyOrderHandling(self):\n    n = np.array([[1, 2], [3, 4]], order=\"F\")\n    t = _create_tensor(n)\n    self.assertAllEqual([[1, 2], [3, 4]], t)\n\n  def testNumpyArrayDtype(self):\n    tensor = constant_op.constant([1.0, 2.0, 3.0])\n    numpy_tensor = np.asarray(tensor, dtype=np.int32)\n    self.assertAllEqual(numpy_tensor, [1, 2, 3])\n\n  def testNdimsAgreesWithNumpy(self):\n    numpy_tensor = np.asarray(1.0)\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(numpy_tensor.ndim, tensor.ndim)\n\n    numpy_tensor = np.asarray([1.0, 2.0, 3.0])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(numpy_tensor.ndim, tensor.ndim)\n\n    numpy_tensor = np.asarray([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(numpy_tensor.ndim, tensor.ndim)\n\n  def testLenAgreesWithNumpy(self):\n    numpy_tensor = np.asarray(1.0)\n    tensor = constant_op.constant(numpy_tensor)\n    with self.assertRaises(TypeError):\n      len(numpy_tensor)\n    with self.assertRaisesRegex(TypeError, r\"Scalar tensor has no `len[(][)]`\"):\n      len(tensor)\n\n    numpy_tensor = np.asarray([1.0, 2.0, 3.0])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(len(numpy_tensor), len(tensor))\n\n    numpy_tensor = np.asarray([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(len(numpy_tensor), len(tensor))\n\n  def testCopy(self):\n    t = constant_op.constant(1.0)\n    tt = copy.copy(t)\n    self.assertAllEqual(tt, 1.0)\n    del tt\n    tt = copy.deepcopy(t)\n    self.assertAllEqual(tt, 1.0)\n    del tt\n    self.assertAllEqual(t, 1.0)\n\n  def testConstantDtype(self):\n    self.assertEqual(\n        constant_op.constant(1, dtype=np.int64).dtype, dtypes.int64)\n\n  def testTensorAndNumpyMatrix(self):\n    expected = np.array([[1.0, 2.0], [3.0, 4.0]], np.float32)\n    actual = _create_tensor([[1.0, 2.0], [3.0, 4.0]])\n    self.assertAllEqual(expected, actual)\n    self.assertEqual(np.float32, actual.dtype)\n    self.assertEqual(dtypes.float32, actual.dtype)\n    self.assertAllEqual([2, 2], actual.shape.as_list())\n\n  def testNumpyArrayInterface(self):\n\n    class ArrayAsArrayInterface:\n      \"\"\"Simple class that wraps an np.array as an __array_interface__.\"\"\"\n\n      def __init__(self, array):\n        self.array = array\n\n      @property\n      def __array_interface__(self):\n        return self.array.__array_interface__\n\n    expected = np.array([[1.0, 2.0], [3.0, 4.0]], np.float32)\n    array_interface = ArrayAsArrayInterface(expected)\n    actual = _create_tensor(array_interface)\n    self.assertAllEqual(expected, actual)\n\n  def testFloatDowncast(self):\n    # Unless explicitly specified, float64->float32\n    t = _create_tensor(3.0)\n    self.assertEqual(dtypes.float32, t.dtype)\n    t = _create_tensor(3.0, dtype=dtypes.float64)\n    self.assertEqual(dtypes.float64, t.dtype)\n\n  def testBool(self):\n    self.assertFalse(bool(_create_tensor(False)))\n    self.assertFalse(bool(_create_tensor([False])))\n    self.assertFalse(bool(_create_tensor([[False]])))\n    self.assertFalse(bool(_create_tensor([0])))\n    self.assertFalse(bool(_create_tensor([0.])))\n    self.assertTrue(bool(_create_tensor([1])))\n    self.assertTrue(bool(_create_tensor([1.])))\n\n  def testIndex(self):\n    self.assertEqual([42][_create_tensor(0)], 42)\n\n    with self.assertRaises(TypeError):\n      _ = [42][_create_tensor([0])]\n\n  def testIntDowncast(self):\n    t = _create_tensor(3)\n    self.assertEqual(dtypes.int32, t.dtype)\n    t = _create_tensor(3, dtype=dtypes.int64)\n    self.assertEqual(dtypes.int64, t.dtype)\n    t = _create_tensor(2**33)\n    self.assertEqual(dtypes.int64, t.dtype)\n\n  def testTensorCreationFailure(self):\n    with self.assertRaises(ValueError):\n      # Should fail because the each row of the Python object has a different\n      # number of columns.\n      self.assertEqual(None, _create_tensor([[1], [1, 2]]))\n\n  def testMultiLineTensorStr(self):\n    t = _create_tensor(np.eye(3))\n    tensor_str = str(t)\n    self.assertIn(\"shape=%s, dtype=%s\" % (t.shape, t.dtype.name), tensor_str)\n    self.assertIn(str(t), tensor_str)\n\n  def testMultiLineTensorRepr(self):\n    t = _create_tensor(np.eye(3))\n    tensor_repr = repr(t)\n    self.assertTrue(tensor_repr.startswith(\"<\"))\n    self.assertTrue(tensor_repr.endswith(\">\"))\n    self.assertIn(\n        \"shape=%s, dtype=%s, numpy=\\n%r\" % (t.shape, t.dtype.name, t.numpy()),\n        tensor_repr)\n\n  def testTensorStrReprObeyNumpyPrintOptions(self):\n    orig_threshold = np.get_printoptions()[\"threshold\"]\n    orig_edgeitems = np.get_printoptions()[\"edgeitems\"]\n    np.set_printoptions(threshold=2, edgeitems=1)\n\n    t = _create_tensor(np.arange(10, dtype=np.int32))\n    self.assertTrue(re.match(r\".*\\[.*0.*\\.\\.\\..*9.*\\]\", str(t)))\n    self.assertTrue(re.match(r\".*\\[.*0.*\\.\\.\\..*9.*\\]\", repr(t)))\n\n    # Clean up: reset to previous printoptions.\n    np.set_printoptions(threshold=orig_threshold, edgeitems=orig_edgeitems)\n\n  def testZeroDimTensorStr(self):\n    t = _create_tensor(42)\n    self.assertIn(\"42, shape=(), dtype=int32\", str(t))\n\n  def testZeroDimTensorRepr(self):\n    t = _create_tensor(42)\n    self.assertTrue(repr(t).startswith(\"<\"))\n    self.assertTrue(repr(t).endswith(\">\"))\n    self.assertIn(\"shape=(), dtype=int32, numpy=42\", repr(t))\n\n  def testZeroSizeTensorStr(self):\n    t = _create_tensor(np.zeros(0, dtype=np.float32))\n    self.assertIn(\"[], shape=(0,), dtype=float32\", str(t))\n\n  def testZeroSizeTensorRepr(self):\n    t = _create_tensor(np.zeros(0, dtype=np.float32))\n    self.assertTrue(repr(t).startswith(\"<\"))\n    self.assertTrue(repr(t).endswith(\">\"))\n    self.assertIn(\"shape=(0,), dtype=float32, numpy=%r\" % t.numpy(), repr(t))\n\n  def testStringTensor(self):\n    t_np_orig = np.array([[b\"a\", b\"ab\"], [b\"abc\", b\"abcd\"]])\n    t = _create_tensor(t_np_orig)\n    t_np = t.numpy()\n    self.assertTrue(np.all(t_np == t_np_orig), \"%s vs %s\" % (t_np, t_np_orig))\n\n  def testIterateOverTensor(self):\n    l = [[1, 2], [3, 4]]\n    t = _create_tensor(l)\n    for list_element, tensor_element in zip(l, t):\n      self.assertAllEqual(list_element, tensor_element.numpy())\n\n  def testIterateOverScalarTensorRaises(self):\n    t = _create_tensor(1)\n    with self.assertRaisesRegex(TypeError,\n                                \"Cannot iterate over a scalar tensor\"):\n      iter(t)\n\n  @test_util.run_gpu_only\n  def testStringTensorOnGPU(self):\n    with ops.device(\"/device:GPU:0\"):\n      t = _create_tensor(\"test string\")\n      self.assertIn(\"GPU\", t.device)\n\n  def testInvalidUTF8ProducesReasonableError(self):\n    if sys.version_info[0] < 3:\n      self.skipTest(\"Test is only valid in python3.\")\n    with self.assertRaises(UnicodeDecodeError):\n      io_ops.read_file(b\"\\xff\")\n\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorPreferredDtypeIsRespected(self):\n    self.assertEqual(\n        ops.convert_to_tensor(0.5, preferred_dtype=dtypes.int32).dtype,\n        dtypes.float32)\n    self.assertEqual(\n        ops.convert_to_tensor(0.5, preferred_dtype=dtypes.float64).dtype,\n        dtypes.float64)\n\n  @test_util.run_in_graph_and_eager_modes\n  def testCompatibility(self):\n    integer_types = [\n        dtypes.int8, dtypes.int16, dtypes.int32, dtypes.int64, dtypes.uint8,\n        dtypes.uint16, dtypes.uint32, dtypes.uint64\n    ]\n\n    # Floats are not compatible with ints\n    for t in integer_types:\n      with self.assertRaises(TypeError):\n        constant_op.constant(0.5, dtype=t)\n\n    # Ints compatible with floats\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.float16)), 5.0)\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.float32)), 5.0)\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.float64)), 5.0)\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.bfloat16)), 5.0)\n\n    # Ints and floats are compatible with complex types\n    self.assertEqual(\n        constant_op.constant([[1.0]], dtype=dtypes.complex128).dtype,\n        dtypes.complex128)\n    self.assertEqual(\n        constant_op.constant([[1]], dtype=dtypes.complex128).dtype,\n        dtypes.complex128)\n\n    # Quantized types are not compatible with floats\n    quantized_types = [\n        dtypes.qint16, dtypes.qint32, dtypes.qint8, dtypes.quint16,\n        dtypes.quint8\n    ]\n\n    for t in quantized_types:\n      with self.assertRaises(TypeError):\n        constant_op.constant(0.5, dtype=t)\n\n    # TODO(b/118402529): quantized types are broken in eager.\n\n  @test_util.run_in_graph_and_eager_modes\n  def testCConvertToTensor(self):\n    with self.assertRaises(TypeError):\n      _ = constant_op.constant(0) < 0.5\n\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorAllowsOverflow(self):\n    _ = ops.convert_to_tensor(123456789, dtype=dtypes.uint8)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorNumpyZeroDim(self):\n    for np_type, dtype in [(np.int32, dtypes.int32), (np.half, dtypes.half),\n                           (np.float32, dtypes.float32)]:\n      x = ops.convert_to_tensor(\n          [np.array(65, dtype=np_type),\n           np.array(16, dtype=np_type)])\n      self.assertEqual(x.dtype, dtype)\n      self.assertAllEqual(x, [65, 16])\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorNumpyScalar(self):\n    x = ops.convert_to_tensor([\n        np.array(321, dtype=np.int64).item(),\n        np.array(16, dtype=np.int64).item()\n    ])\n    self.assertAllEqual(x, [321, 16])\n\n  def testEagerTensorError(self):\n    with self.assertRaisesRegex(TypeError,\n                                \"Cannot convert .* to EagerTensor of dtype .*\"):\n      _ = ops.convert_to_tensor(1., dtype=dtypes.int32)\n\n  def testEagerLargeConstant(self):\n    for t in [dtypes.uint64, dtypes.uint32, dtypes.int32, dtypes.int64]:\n      self.assertEqual(constant_op.constant(t.max, dtype=t).numpy(), t.max)\n      self.assertEqual(constant_op.constant(t.min, dtype=t).numpy(), t.min)\n\n  def test_numpyIsView(self):\n    with ops.device(\"CPU\"):\n      t = constant_op.constant([0.0])\n      t._numpy()[0] = 42.0\n      self.assertAllClose(t, constant_op.constant([42.0]))\n\n  def test_numpyFailsForResource(self):\n    v = variables.Variable(42)\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Cannot convert .+ resource\"):\n      v._handle._numpy()\n\n  def test_numpyFailsForVariant(self):\n    variant_t = list_ops.tensor_list_reserve(\n        element_shape=[], num_elements=1, element_dtype=dtypes.float32)\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Cannot convert .+ variant\"):\n      variant_t._numpy()\n\n  def testMemoryviewFailsForResource(self):\n    v = variables.Variable(42)\n    with self.assertRaisesRegex(BufferError, \"Cannot convert .+ resource\"):\n      np.asarray(memoryview(v._handle))\n\n  def testMemoryviewFailsForVariant(self):\n    variant_t = list_ops.tensor_list_reserve(\n        element_shape=[], num_elements=1, element_dtype=dtypes.float32)\n    with self.assertRaisesRegex(BufferError, \"Cannot convert .+ variant\"):\n      np.asarray(memoryview(variant_t))\n\n  def testMemoryviewIsReadonly(self):\n    t = constant_op.constant([0.0])\n    self.assertTrue(memoryview(t).readonly)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testMemoryviewScalar(self):\n    t = constant_op.constant(42.0)\n    self.assertAllEqual(\n        np.array(memoryview(t)), np.array(42.0, dtype=np.float32))\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testMemoryviewEmpty(self):\n    t = constant_op.constant([], dtype=np.float32)\n    self.assertAllEqual(np.array(memoryview(t)), np.array([]))\n\n  @test_util.run_gpu_only\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testMemoryviewCopyToCPU(self):\n    with ops.device(\"/device:GPU:0\"):\n      t = constant_op.constant([0.0])\n    self.assertAllEqual(\n        np.array(memoryview(t)), np.array([0.0], dtype=np.float32))\n\n  @test_util.disable_tfrt(\"b/169877776: ResourceVariable is not initialized \"\n                          \"properly in TFRT\")\n  def testResourceTensorCopy(self):\n    if not test_util.is_gpu_available():\n      self.skipTest(\"GPU only\")\n\n    with ops.device(\"GPU:0\"):\n      v = resource_variable_ops.ResourceVariable(1.)\n\n    read_handle_on_gpu = resource_variable_ops.read_variable_op(\n        v.handle, dtypes.float32)\n    handle_on_cpu = v.handle.cpu()\n    read_handle_on_cpu = resource_variable_ops.read_variable_op(\n        handle_on_cpu, dtypes.float32)\n\n    self.assertAllEqual(read_handle_on_cpu, read_handle_on_gpu)\n\n  def testEagerTensorFormat(self):\n    t = array_ops.constant(1)\n    self.assertEqual(f\"{t}\", \"1\")\n    self.assertEqual(str(t), \"tf.Tensor(1, shape=(), dtype=int32)\")\n    self.assertEqual(f\"{t!s}\", \"tf.Tensor(1, shape=(), dtype=int32)\")\n    self.assertEqual(repr(t), \"<tf.Tensor: shape=(), dtype=int32, numpy=1>\")\n    self.assertEqual(f\"{t!r}\", \"<tf.Tensor: shape=(), dtype=int32, numpy=1>\")\n\n  def testEagerTensorFormatForResource(self):\n    t = resource_variable_ops.VarHandleOp(shape=[], dtype=dtypes.float32)\n\n    # type is compiler-depdendent, as it comes from demangling.\n    handle_str = (f\"<ResourceHandle(\"\n                  f\"name=\\\"\\\", \"\n                  f\"device=\\\"{t.device}\\\", \"\n                  f\"container=\\\"localhost\\\", \"\n                  f\"type=\\\"@@tensorflow@@Var@@\\\")>\")\n\n    def make_regex(s):\n      return re.escape(s).replace(\"@@\", \".*\")\n\n    self.assertRegex(f\"{t}\", make_regex(handle_str))\n    self.assertRegex(\n        str(t),\n        make_regex(f\"tf.Tensor({handle_str}, shape=(), dtype=resource)\"))\n    self.assertRegex(\n        f\"{t!s}\",\n        make_regex(f\"tf.Tensor({handle_str}, shape=(), dtype=resource)\"))\n    self.assertRegex(\n        repr(t),\n        make_regex(\n            f\"<tf.Tensor: shape=(), dtype=resource, value={handle_str}>\"))\n    self.assertRegex(\n        f\"{t!r}\",\n        make_regex(\n            f\"<tf.Tensor: shape=(), dtype=resource, value={handle_str}>\"))\n\n  def testEagerTensorFormatForVariant(self):\n    t = list_ops.tensor_list_reserve(\n        element_shape=[1], num_elements=1, element_dtype=dtypes.float32)\n    self.assertEqual(f\"{t}\", \"<TensorList>\")\n    self.assertEqual(str(t), \"tf.Tensor(<TensorList>, shape=(), dtype=variant)\")\n    self.assertEqual(f\"{t!s}\",\n                     \"tf.Tensor(<TensorList>, shape=(), dtype=variant)\")\n    self.assertEqual(\n        repr(t), \"<tf.Tensor: shape=(), dtype=variant, value=<TensorList>>\")\n    self.assertEqual(\n        f\"{t!r}\", \"<tf.Tensor: shape=(), dtype=variant, value=<TensorList>>\")\n\n  def testNumpyTooManyDimensions(self):\n    t = constant_op.constant(1., shape=[1] * 33)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Cannot convert tensor with 33 dimensions to NumPy array. NumPy arrays \"\n        \"can have at most 32 dimensions\"):\n      t.numpy()\n\n\nclass TFETensorUtilTest(test_util.TensorFlowTestCase):\n\n  def setUp(self):\n    super(TFETensorUtilTest, self).setUp()\n    context.ensure_initialized()\n\n  def testListOfThree(self):\n    t1 = _create_tensor([[1, 2], [3, 4], [5, 6]], dtype=dtypes.int32)\n    t2 = _create_tensor([[1, 2, 5], [3, 4, 5]], dtype=dtypes.int32)\n    t3 = _create_tensor([[1], [3], [5], [6]], dtype=dtypes.int32)\n\n    r = pywrap_tfe.TFE_Py_TensorShapeSlice([t1, t2, t3], 0)\n    self.assertAllEqual(np.array([3, 2, 4]), r.numpy())\n\n    r = pywrap_tfe.TFE_Py_TensorShapeSlice([t1, t2, t3], 1)\n    self.assertAllEqual(np.array([2, 3, 1]), r.numpy())\n\n  def testEmptyTensorList(self):\n    a = pywrap_tfe.TFE_Py_TensorShapeSlice([], 0)\n    self.assertTrue(isinstance(a, ops.EagerTensor))\n    self.assertEqual(0, a.numpy().size)\n\n  def testTensorListContainsNonTensors(self):\n    t1 = _create_tensor([1, 2], dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        TypeError,\n        r\"Expected a list of EagerTensors but element 1 has type \\\"str\\\"\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1, \"abc\"], 0)\n\n    with self.assertRaisesRegex(\n        TypeError,\n        r\"Expected a list of EagerTensors but element 0 has type \\\"int\\\"\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([2, t1], 0)\n\n  def testTensorListNotList(self):\n    t1 = _create_tensor([1, 2], dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        TypeError,\n        r\"tensors argument must be a list or a tuple. Got.*EagerTensor\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice(t1, -2)\n\n  def testNegativeSliceDim(self):\n    t1 = _create_tensor([1, 2], dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        ValueError, r\"Slice dimension must be non-negative. Got -2\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1], -2)\n\n  def testUnicode(self):\n    self.assertEqual(constant_op.constant(u\"asdf\").numpy(), b\"asdf\")\n\n  def testFloatTensor(self):\n    self.assertEqual(dtypes.float64, _create_tensor(np.float64()).dtype)  # pylint: disable=no-value-for-parameter\n    self.assertEqual(dtypes.float32, _create_tensor(np.float32()).dtype)  # pylint: disable=no-value-for-parameter\n    self.assertEqual(dtypes.float16, _create_tensor(np.float16()).dtype)  # pylint: disable=no-value-for-parameter\n    self.assertEqual(dtypes.float32, _create_tensor(0.0).dtype)\n\n  def testSliceDimOutOfRange(self):\n    t1 = _create_tensor([[1, 2], [3, 4], [5, 6]], dtype=dtypes.int32)\n    t2 = _create_tensor([1, 2], dtype=dtypes.int32)\n    t3 = _create_tensor(2, dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(2\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 0 has rank 2\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1], 2)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(1\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 0 has rank 1\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t2], 1)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(1\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 1 has rank 1\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1, t2], 1)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(0\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 0 has rank 0\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t3], 0)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(0\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 2 has rank 0\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t2, t1, t3], 0)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testTensorDir(self):\n    t = array_ops.ones(1)\n    t.test_attr = \"Test\"\n\n    instance_dir = dir(t)\n    type_dir = dir(ops.EagerTensor)\n\n    # Monkey patched attributes should show up in dir(t)\n    self.assertIn(\"test_attr\", instance_dir)\n    instance_dir.remove(\"test_attr\")\n    self.assertEqual(instance_dir, type_dir)\n\n  def testNonRectangularPackAsConstant(self):\n    l = [array_ops.zeros((10, 1)).numpy(), array_ops.zeros(1).numpy()]\n\n    with self.assertRaisesRegex(ValueError, \"non-rectangular Python sequence\"):\n      constant_op.constant(l)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testFloatAndIntAreConvertibleToComplex(self):\n    a = [[1., 1], [1j, 2j]]\n    np_value = np.array(a, dtype=np.complex128)\n    tf_value = ops.convert_to_tensor(a, dtype=dtypes.complex128)\n    self.assertAllEqual(tf_value.numpy(), np_value)\n\n\nif __name__ == \"__main__\":\n  test.main()\n", "# python/lib/core package\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_python_pybind_extension\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_py_test\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_external_workspace_visible\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"get_compatible_with_portable\")\n\nvisibility = [\n    \"//engedu/ml/tf_from_scratch:__pkg__\",\n    \"//third_party/cloud_tpu/convergence_tools:__subpackages__\",\n    \"//third_party/mlperf:__subpackages__\",\n    \"//tensorflow:internal\",\n    \"//tensorflow/lite/toco/python:__pkg__\",\n    \"//tensorflow_models:__subpackages__\",\n    \"//tensorflow_model_optimization:__subpackages__\",\n    \"//third_party/py/cleverhans:__subpackages__\",\n    \"//third_party/py/launchpad:__subpackages__\",\n    \"//third_party/py/reverb:__subpackages__\",\n    \"//third_party/py/neural_structured_learning:__subpackages__\",\n    \"//third_party/py/tensorflow_examples:__subpackages__\",\n    \"//third_party/py/tf_agents:__subpackages__\",  # For benchmarks.\n    \"//third_party/py/tf_slim:__subpackages__\",\n    \"//third_party/py/tensorflow_docs:__subpackages__\",\n    \"//third_party/py/keras:__subpackages__\",\n]\n\npackage(\n    default_visibility = visibility,\n    licenses = [\"notice\"],\n)\n\ncc_library(\n    name = \"numpy_lib\",\n    srcs = [\"numpy.cc\"],\n    hdrs = [\"numpy.h\"],\n    deps = [\n        \"//third_party/py/numpy:headers\",\n        \"//third_party/python_runtime:headers\",\n    ],\n)\n\ncc_library(\n    name = \"bfloat16_lib\",\n    srcs = [\n        \"bfloat16.cc\",\n        \"float8_e4m3b11.cc\",\n    ],\n    hdrs = [\n        \"bfloat16.h\",\n        \"float8_e4m3b11.h\",\n    ],\n    deps = [\n        \":numpy_lib\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:types\",\n        \"//third_party/eigen3\",\n        \"//third_party/python_runtime:headers\",  # build_cleaner: keep; DNR: b/35864863\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_python_pybind_extension(\n    name = \"_pywrap_bfloat16\",\n    srcs = [\"bfloat16_wrapper.cc\"],\n    hdrs = [\"bfloat16.h\"],\n    deps = [\n        \"//third_party/python_runtime:headers\",\n        \"@pybind11\",\n    ],\n)\n\ncc_library(\n    name = \"ndarray_tensor_bridge\",\n    srcs = [\"ndarray_tensor_bridge.cc\"],\n    hdrs = [\"ndarray_tensor_bridge.h\"],\n    visibility = tf_external_workspace_visible(\n        visibility + [\n            \"//tensorflow:ndarray_tensor_allow_list\",\n        ],\n    ),\n    deps = [\n        \":bfloat16_lib\",\n        \":numpy_lib\",\n        \"//tensorflow/c:c_api_no_xla\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n    ],\n)\n\ncc_library(\n    name = \"py_exception_registry\",\n    srcs = [\"py_exception_registry.cc\"],\n    hdrs = [\"py_exception_registry.h\"],\n    deps = [\n        \"//tensorflow/c:tf_status_headers\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//third_party/python_runtime:headers\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"pybind11_absl\",\n    hdrs = [\"pybind11_absl.h\"],\n    features = [\"-parse_headers\"],\n    visibility = tf_external_workspace_visible(visibility),\n    deps = [\n        \"//tensorflow/core/platform:stringpiece\",\n        \"@pybind11\",\n    ],\n)\n\ncc_library(\n    name = \"pybind11_lib\",\n    hdrs = [\"pybind11_lib.h\"],\n    compatible_with = get_compatible_with_portable(),\n    features = [\"-parse_headers\"],\n    visibility = tf_external_workspace_visible(visibility),\n    deps = [\n        \"@pybind11\",\n    ],\n)\n\ncc_library(\n    name = \"pybind11_status_headers\",\n    hdrs = [\n        \"py_exception_registry.h\",\n        \"pybind11_status.h\",\n        \"//tensorflow/c:headers\",\n        \"//tensorflow/c:tf_status_internal_headers\",\n        \"//tensorflow/c/eager:headers\",\n    ],\n    features = [\n        \"-parse_headers\",\n    ],\n    visibility = tf_external_workspace_visible(visibility),\n    deps = [\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core/common_runtime:core_cpu_headers_lib\",\n        \"//third_party/python_runtime:headers\",\n        \"@pybind11\",\n    ],\n)\n\ncc_library(\n    name = \"pybind11_status\",\n    hdrs = [\n        \"py_exception_registry.h\",\n        \"pybind11_status.h\",\n    ],\n    features = [\"-parse_headers\"],\n    visibility = tf_external_workspace_visible(visibility),\n    deps = [\n        \":pybind11_status_headers\",\n        \"//tensorflow/core:lib\",\n    ],\n)\n\ncc_library(\n    name = \"pybind11_proto\",\n    hdrs = [\"pybind11_proto.h\"],\n    features = [\"-parse_headers\"],\n    visibility = tf_external_workspace_visible(visibility),\n    deps = [\n        \"@com_google_absl//absl/strings\",\n        \"@pybind11\",\n    ],\n)\n\nfilegroup(\n    name = \"py_exception_registry_hdr\",\n    srcs = [\n        \"py_exception_registry.h\",\n    ],\n    visibility = [\"//visibility:public\"],\n)\n\nfilegroup(\n    name = \"numpy_hdr\",\n    srcs = [\"numpy.h\"],\n)\n\nfilegroup(\n    name = \"safe_ptr_hdr\",\n    srcs = [\"safe_ptr.h\"],\n)\n\nfilegroup(\n    name = \"ndarray_tensor_hdr\",\n    srcs = [\"ndarray_tensor.h\"],\n)\n\nfilegroup(\n    name = \"basic_hdrs\",\n    srcs = [\n        \"bfloat16.h\",\n        \"ndarray_tensor.h\",\n        \"ndarray_tensor_bridge.h\",\n        \"numpy.h\",\n        \"py_exception_registry.h\",\n        \"pybind11_status.h\",\n        \"safe_ptr.h\",\n        \"safe_pyobject_ptr.h\",\n    ],\n)\n\ncc_library(\n    name = \"py_func_lib\",\n    srcs = [\"py_func.cc\"],\n    hdrs = [\"py_func.h\"],\n    deps = [\n        \":ndarray_tensor\",\n        \":ndarray_tensor_bridge\",\n        \":numpy_lib\",\n        \":py_util\",\n        \":safe_ptr\",\n        \"//tensorflow/c:tf_status_helper\",\n        \"//tensorflow/c/eager:c_api\",\n        \"//tensorflow/c/eager:tfe_context_internal\",\n        \"//tensorflow/c/eager:tfe_tensorhandle_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:script_ops_op_lib\",\n        \"//tensorflow/core/common_runtime/eager:context\",\n        \"//tensorflow/core/common_runtime/eager:tensor_handle\",\n        \"//tensorflow/python/eager:pywrap_tfe_lib\",\n        \"//third_party/py/numpy:headers\",\n        \"//third_party/python_runtime:headers\",\n    ],\n    alwayslink = 1,\n)\n\ntf_python_pybind_extension(\n    name = \"_pywrap_py_func\",\n    srcs = [\"py_func_wrapper.cc\"],\n    deps = [\n        \"//tensorflow/python:py_func_headers_lib\",\n        \"//third_party/python_runtime:headers\",\n        \"@pybind11\",\n    ],\n)\n\ncc_library(\n    name = \"safe_pyobject_ptr\",\n    srcs = [\"safe_pyobject_ptr.cc\"],\n    hdrs = [\"safe_pyobject_ptr.h\"],\n    deps = [\n        \"//third_party/python_runtime:headers\",\n    ],\n)\n\ncc_library(\n    name = \"safe_pyobject_ptr_required_hdrs\",\n    textual_hdrs = [\"safe_pyobject_ptr.h\"],\n)\n\ncc_library(\n    name = \"safe_ptr\",\n    srcs = [\n        \"safe_ptr.cc\",\n        \"//tensorflow/c/eager:headers\",\n    ],\n    hdrs = [\"safe_ptr.h\"],\n    deps = [\n        \":safe_pyobject_ptr\",\n        \"//tensorflow/c:c_api_no_xla\",\n        \"//third_party/python_runtime:headers\",\n    ],\n)\n\ncc_library(\n    name = \"ndarray_tensor_headers\",\n    hdrs = [\n        \"bfloat16.h\",\n        \"ndarray_tensor.h\",\n        \"ndarray_tensor_bridge.h\",\n        \"numpy.h\",\n        \"safe_ptr.h\",\n        \"safe_pyobject_ptr.h\",\n        \"//tensorflow/c:headers\",\n        \"//tensorflow/c/eager:headers\",\n    ],\n    features = [\n        \"-parse_headers\",\n    ],\n    visibility = tf_external_workspace_visible(visibility + [\n        \"//tensorflow:ndarray_tensor_allow_list\",\n    ]),\n    deps = [\n        \":numpy_lib\",\n        \"//tensorflow/c:pywrap_required_hdrs\",\n        \"//tensorflow/c:tf_status_headers\",\n        \"//tensorflow/core:framework_internal_headers_lib\",\n        \"//tensorflow/core/common_runtime:core_cpu_headers_lib\",\n        \"//third_party/py/numpy:headers\",\n        \"//third_party/python_runtime:headers\",\n    ],\n)\n\ncc_library(\n    name = \"ndarray_tensor\",\n    srcs = [\"ndarray_tensor.cc\"],\n    hdrs = [\"ndarray_tensor.h\"],\n    visibility = tf_external_workspace_visible(visibility + [\n        \"//tensorflow:ndarray_tensor_allow_list\",\n    ]),\n    deps = [\n        \":bfloat16_lib\",\n        \":ndarray_tensor_bridge\",\n        \":numpy_lib\",\n        \":safe_ptr\",\n        \"//tensorflow/c:c_api_internal\",\n        \"//tensorflow/c:tf_status_helper\",\n        \"//tensorflow/c:tf_tensor_internal\",\n        \"//tensorflow/c/eager:tfe_context_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n    ],\n)\n\ncc_library(\n    name = \"py_seq_tensor\",\n    srcs = [\"py_seq_tensor.cc\"],\n    hdrs = [\"py_seq_tensor.h\"],\n    features = [\"-parse_headers\"],\n    deps = [\n        \":ndarray_tensor\",\n        \":ndarray_tensor_bridge\",\n        \":numpy_lib\",\n        \":py_util\",\n        \":safe_ptr\",\n        \"//tensorflow/c:tensor_interface\",\n        \"//tensorflow/c:tf_tensor_internal\",\n        \"//tensorflow/c/eager:c_api_internal\",\n        \"//tensorflow/c/eager:tfe_context_internal\",\n        \"//tensorflow/c/eager:tfe_tensorhandle_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//third_party/python_runtime:headers\",  # build_cleaner: keep; DNR: b/35864863\n    ],\n)\n\ncc_library(\n    name = \"py_util\",\n    srcs = [\"py_util.cc\"],\n    hdrs = [\"py_util.h\"],\n    deps = [\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:script_ops_op_lib\",\n        \"//tensorflow/core/platform:logging\",\n        \"//third_party/python_runtime:headers\",\n    ],\n)\n\ntf_py_test(\n    name = \"bfloat16_test\",\n    size = \"small\",\n    srcs = [\"bfloat16_test.py\"],\n    python_version = \"PY3\",\n    deps = [\n        \"//tensorflow/python:pywrap_tensorflow\",\n        \"//tensorflow/python/lib/io:lib\",\n        \"//tensorflow/python/platform:client_testlib\",\n    ],\n)\n", "/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// Must be included first.\n#include \"tensorflow/python/lib/core/numpy.h\"\n\n#include <vector>\n\n#include \"tensorflow/c/c_api.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/platform/mutex.h\"\n#include \"tensorflow/python/lib/core/bfloat16.h\"\n#include \"tensorflow/python/lib/core/ndarray_tensor_bridge.h\"\n\nnamespace tensorflow {\n\n// Mutex used to serialize accesses to cached vector of pointers to python\n// arrays to be dereferenced.\nstatic mutex* DelayedDecrefLock() {\n  static mutex* decref_lock = new mutex;\n  return decref_lock;\n}\n\n// Caches pointers to numpy arrays which need to be dereferenced.\nstatic std::vector<void*>* DecrefCache() {\n  static std::vector<void*>* decref_cache = new std::vector<void*>;\n  return decref_cache;\n}\n\n// Destructor passed to TF_NewTensor when it reuses a numpy buffer. Stores a\n// pointer to the pyobj in a buffer to be dereferenced later when we're actually\n// holding the GIL.\nvoid DelayedNumpyDecref(void* data, size_t len, void* obj) {\n  mutex_lock ml(*DelayedDecrefLock());\n  DecrefCache()->push_back(obj);\n}\n\n// Actually dereferences cached numpy arrays. REQUIRES being called while\n// holding the GIL.\nvoid ClearDecrefCache() {\n  std::vector<void*> cache_copy;\n  {\n    mutex_lock ml(*DelayedDecrefLock());\n    cache_copy.swap(*DecrefCache());\n  }\n  for (void* obj : cache_copy) {\n    Py_DECREF(reinterpret_cast<PyObject*>(obj));\n  }\n}\n\n// Structure which keeps a reference to a Tensor alive while numpy has a pointer\n// to it.\nstruct TensorReleaser {\n  // Python macro to include standard members.\n  PyObject_HEAD\n\n      // Destructor responsible for releasing the memory.\n      std::function<void()>* destructor;\n};\n\nextern PyTypeObject TensorReleaserType;\n\nstatic void TensorReleaser_dealloc(PyObject* pself) {\n  TensorReleaser* self = reinterpret_cast<TensorReleaser*>(pself);\n  (*self->destructor)();\n  delete self->destructor;\n  TensorReleaserType.tp_free(pself);\n}\n\n// clang-format off\nPyTypeObject TensorReleaserType = {\n    PyVarObject_HEAD_INIT(nullptr, 0) /* head init */\n    \"tensorflow_wrapper\",             /* tp_name */\n    sizeof(TensorReleaser),           /* tp_basicsize */\n    0,                                /* tp_itemsize */\n    /* methods */\n    TensorReleaser_dealloc,      /* tp_dealloc */\n#if PY_VERSION_HEX < 0x03080000\n    nullptr,                     /* tp_print */\n#else\n    0,                           /* tp_vectorcall_offset */\n#endif\n    nullptr,                     /* tp_getattr */\n    nullptr,                     /* tp_setattr */\n    nullptr,                     /* tp_compare */\n    nullptr,                     /* tp_repr */\n    nullptr,                     /* tp_as_number */\n    nullptr,                     /* tp_as_sequence */\n    nullptr,                     /* tp_as_mapping */\n    nullptr,                     /* tp_hash */\n    nullptr,                     /* tp_call */\n    nullptr,                     /* tp_str */\n    nullptr,                     /* tp_getattro */\n    nullptr,                     /* tp_setattro */\n    nullptr,                     /* tp_as_buffer */\n    Py_TPFLAGS_DEFAULT,          /* tp_flags */\n    \"Wrapped TensorFlow Tensor\", /* tp_doc */\n    nullptr,                     /* tp_traverse */\n    nullptr,                     /* tp_clear */\n    nullptr,                     /* tp_richcompare */\n};\n// clang-format on\n\nStatus TF_DataType_to_PyArray_TYPE(TF_DataType tf_datatype,\n                                   int* out_pyarray_type) {\n  switch (tf_datatype) {\n    case TF_HALF:\n      *out_pyarray_type = NPY_FLOAT16;\n      break;\n    case TF_FLOAT:\n      *out_pyarray_type = NPY_FLOAT32;\n      break;\n    case TF_DOUBLE:\n      *out_pyarray_type = NPY_FLOAT64;\n      break;\n    case TF_INT32:\n      *out_pyarray_type = NPY_INT32;\n      break;\n    case TF_UINT32:\n      *out_pyarray_type = NPY_UINT32;\n      break;\n    case TF_UINT8:\n      *out_pyarray_type = NPY_UINT8;\n      break;\n    case TF_UINT16:\n      *out_pyarray_type = NPY_UINT16;\n      break;\n    case TF_INT8:\n      *out_pyarray_type = NPY_INT8;\n      break;\n    case TF_INT16:\n      *out_pyarray_type = NPY_INT16;\n      break;\n    case TF_INT64:\n      *out_pyarray_type = NPY_INT64;\n      break;\n    case TF_UINT64:\n      *out_pyarray_type = NPY_UINT64;\n      break;\n    case TF_BOOL:\n      *out_pyarray_type = NPY_BOOL;\n      break;\n    case TF_COMPLEX64:\n      *out_pyarray_type = NPY_COMPLEX64;\n      break;\n    case TF_COMPLEX128:\n      *out_pyarray_type = NPY_COMPLEX128;\n      break;\n    case TF_STRING:\n      *out_pyarray_type = NPY_OBJECT;\n      break;\n    case TF_RESOURCE:\n      *out_pyarray_type = NPY_VOID;\n      break;\n    // TODO(keveman): These should be changed to NPY_VOID, and the type used for\n    // the resulting numpy array should be the custom struct types that we\n    // expect for quantized types.\n    case TF_QINT8:\n      *out_pyarray_type = NPY_INT8;\n      break;\n    case TF_QUINT8:\n      *out_pyarray_type = NPY_UINT8;\n      break;\n    case TF_QINT16:\n      *out_pyarray_type = NPY_INT16;\n      break;\n    case TF_QUINT16:\n      *out_pyarray_type = NPY_UINT16;\n      break;\n    case TF_QINT32:\n      *out_pyarray_type = NPY_INT32;\n      break;\n    case TF_BFLOAT16:\n      *out_pyarray_type = Bfloat16NumpyType();\n      break;\n    default:\n      return errors::Internal(\"Tensorflow type \", tf_datatype,\n                              \" not convertible to numpy dtype.\");\n  }\n  return OkStatus();\n}\n\nStatus ArrayFromMemory(int dim_size, npy_intp* dims, void* data, DataType dtype,\n                       std::function<void()> destructor, PyObject** result) {\n  if (dtype == DT_STRING || dtype == DT_RESOURCE) {\n    return errors::FailedPrecondition(\n        \"Cannot convert string or resource Tensors.\");\n  }\n\n  int type_num = -1;\n  Status s =\n      TF_DataType_to_PyArray_TYPE(static_cast<TF_DataType>(dtype), &type_num);\n  if (!s.ok()) {\n    return s;\n  }\n\n  if (dim_size > NPY_MAXDIMS) {\n    return errors::InvalidArgument(\n        \"Cannot convert tensor with \", dim_size,\n        \" dimensions to NumPy array. NumPy arrays can have at most \",\n        NPY_MAXDIMS, \" dimensions\");\n  }\n  auto* np_array = reinterpret_cast<PyArrayObject*>(\n      PyArray_SimpleNewFromData(dim_size, dims, type_num, data));\n  PyArray_CLEARFLAGS(np_array, NPY_ARRAY_OWNDATA);\n  if (PyType_Ready(&TensorReleaserType) == -1) {\n    return errors::Unknown(\"Python type initialization failed.\");\n  }\n  auto* releaser = reinterpret_cast<TensorReleaser*>(\n      TensorReleaserType.tp_alloc(&TensorReleaserType, 0));\n  releaser->destructor = new std::function<void()>(std::move(destructor));\n  if (PyArray_SetBaseObject(np_array, reinterpret_cast<PyObject*>(releaser)) ==\n      -1) {\n    Py_DECREF(releaser);\n    return errors::Unknown(\"Python array refused to use memory.\");\n  }\n  *result = reinterpret_cast<PyObject*>(np_array);\n  return OkStatus();\n}\n\n}  // namespace tensorflow\n"], "fixing_code": ["# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Unit tests for TensorFlow \"Eager\" Mode's Tensor class.\"\"\"\n\nimport copy\nimport re\nimport sys\n\nimport numpy as np\n\nfrom tensorflow.python import pywrap_tfe\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import core\nfrom tensorflow.python.eager import test\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import io_ops\nfrom tensorflow.python.ops import list_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.ops import variables\n\n\ndef _create_tensor(value, device=None, dtype=None):\n  context.ensure_initialized()\n  ctx = context.context()\n  if device is None:\n    device = ctx.device_name\n  if dtype is not None:\n    dtype = dtype.as_datatype_enum\n  try:\n    return ops.EagerTensor(value, device=device, dtype=dtype)\n  except core._NotOkStatusException as e:  # pylint: disable=protected-access\n    raise core._status_to_exception(e)\n\n\nclass TFETensorTest(test_util.TensorFlowTestCase):\n\n  def testScalarTensor(self):\n    t = _create_tensor(3, dtype=dtypes.int32)\n    self.assertAllEqual(t, _create_tensor(np.array(3)))\n    self.assertEqual(dtypes.int32, t.dtype)\n    self.assertEqual(0, t.shape.ndims)\n    self.assertAllEqual([], t.shape.as_list())\n    self.assertIn(\"tf.Tensor\", str(t))\n    self.assertIn(\"tf.Tensor\", repr(t))\n\n  def testBadConstructorArgs(self):\n    context.ensure_initialized()\n    ctx = context.context()\n    device = ctx.device_name\n    # Missing device.\n    with self.assertRaisesRegex(TypeError, r\".*argument 'device' \\(pos 2\\).*\"):\n      ops.EagerTensor(1)\n    # Bad dtype type.\n    with self.assertRaisesRegex(TypeError,\n                                \"Expecting a DataType value for dtype. Got\"):\n      ops.EagerTensor(1, device=device, dtype=\"1\")\n\n    # Following errors happen when trying to copy to GPU.\n    if not test_util.is_gpu_available():\n      self.skipTest(\"No GPUs found\")\n\n    with ops.device(\"/device:GPU:0\"):\n      # Bad device.\n      with self.assertRaisesRegex(TypeError, \"Error parsing device argument\"):\n        ops.EagerTensor(1.0, device=1)\n\n  def testNumpyValue(self):\n    values = np.array([3.0])\n    t = _create_tensor(values)\n    self.assertAllEqual(values, t)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testNumpyDtypeSurvivesThroughTensorConversion(self):\n    scalar_creators = [np.int32, np.int64, np.float32, np.float64]\n    conversion_functions = [ops.convert_to_tensor, constant_op.constant]\n\n    for scalar_creator in scalar_creators:\n      for conversion_function in conversion_functions:\n        np_val = scalar_creator(3)\n        tensor_val = conversion_function(np_val)\n        self.assertEqual(tensor_val.numpy().dtype, np_val.dtype)\n        self.assertEqual(tensor_val.numpy(), np_val)\n\n  def testNumpyValueWithCast(self):\n    values = np.array([3.0], dtype=np.float32)\n    t = _create_tensor(values, dtype=dtypes.float64)\n    self.assertAllEqual(values, t)\n    ctx = context.context()\n    # Bad dtype value.\n    with self.assertRaisesRegex(TypeError, \"Invalid dtype argument value\"):\n      ops.EagerTensor(values, device=ctx.device_name, dtype=12345)\n\n  def testNumpyOrderHandling(self):\n    n = np.array([[1, 2], [3, 4]], order=\"F\")\n    t = _create_tensor(n)\n    self.assertAllEqual([[1, 2], [3, 4]], t)\n\n  def testNumpyArrayDtype(self):\n    tensor = constant_op.constant([1.0, 2.0, 3.0])\n    numpy_tensor = np.asarray(tensor, dtype=np.int32)\n    self.assertAllEqual(numpy_tensor, [1, 2, 3])\n\n  def testNdimsAgreesWithNumpy(self):\n    numpy_tensor = np.asarray(1.0)\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(numpy_tensor.ndim, tensor.ndim)\n\n    numpy_tensor = np.asarray([1.0, 2.0, 3.0])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(numpy_tensor.ndim, tensor.ndim)\n\n    numpy_tensor = np.asarray([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(numpy_tensor.ndim, tensor.ndim)\n\n  def testLenAgreesWithNumpy(self):\n    numpy_tensor = np.asarray(1.0)\n    tensor = constant_op.constant(numpy_tensor)\n    with self.assertRaises(TypeError):\n      len(numpy_tensor)\n    with self.assertRaisesRegex(TypeError, r\"Scalar tensor has no `len[(][)]`\"):\n      len(tensor)\n\n    numpy_tensor = np.asarray([1.0, 2.0, 3.0])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(len(numpy_tensor), len(tensor))\n\n    numpy_tensor = np.asarray([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(len(numpy_tensor), len(tensor))\n\n  def testCopy(self):\n    t = constant_op.constant(1.0)\n    tt = copy.copy(t)\n    self.assertAllEqual(tt, 1.0)\n    del tt\n    tt = copy.deepcopy(t)\n    self.assertAllEqual(tt, 1.0)\n    del tt\n    self.assertAllEqual(t, 1.0)\n\n  def testConstantDtype(self):\n    self.assertEqual(\n        constant_op.constant(1, dtype=np.int64).dtype, dtypes.int64)\n\n  def testTensorAndNumpyMatrix(self):\n    expected = np.array([[1.0, 2.0], [3.0, 4.0]], np.float32)\n    actual = _create_tensor([[1.0, 2.0], [3.0, 4.0]])\n    self.assertAllEqual(expected, actual)\n    self.assertEqual(np.float32, actual.dtype)\n    self.assertEqual(dtypes.float32, actual.dtype)\n    self.assertAllEqual([2, 2], actual.shape.as_list())\n\n  def testNumpyArrayInterface(self):\n\n    class ArrayAsArrayInterface:\n      \"\"\"Simple class that wraps an np.array as an __array_interface__.\"\"\"\n\n      def __init__(self, array):\n        self.array = array\n\n      @property\n      def __array_interface__(self):\n        return self.array.__array_interface__\n\n    expected = np.array([[1.0, 2.0], [3.0, 4.0]], np.float32)\n    array_interface = ArrayAsArrayInterface(expected)\n    actual = _create_tensor(array_interface)\n    self.assertAllEqual(expected, actual)\n\n  def testFloatDowncast(self):\n    # Unless explicitly specified, float64->float32\n    t = _create_tensor(3.0)\n    self.assertEqual(dtypes.float32, t.dtype)\n    t = _create_tensor(3.0, dtype=dtypes.float64)\n    self.assertEqual(dtypes.float64, t.dtype)\n\n  def testBool(self):\n    self.assertFalse(bool(_create_tensor(False)))\n    self.assertFalse(bool(_create_tensor([False])))\n    self.assertFalse(bool(_create_tensor([[False]])))\n    self.assertFalse(bool(_create_tensor([0])))\n    self.assertFalse(bool(_create_tensor([0.])))\n    self.assertTrue(bool(_create_tensor([1])))\n    self.assertTrue(bool(_create_tensor([1.])))\n\n  def testIndex(self):\n    self.assertEqual([42][_create_tensor(0)], 42)\n\n    with self.assertRaises(TypeError):\n      _ = [42][_create_tensor([0])]\n\n  def testIntDowncast(self):\n    t = _create_tensor(3)\n    self.assertEqual(dtypes.int32, t.dtype)\n    t = _create_tensor(3, dtype=dtypes.int64)\n    self.assertEqual(dtypes.int64, t.dtype)\n    t = _create_tensor(2**33)\n    self.assertEqual(dtypes.int64, t.dtype)\n\n  def testTensorCreationFailure(self):\n    with self.assertRaises(ValueError):\n      # Should fail because the each row of the Python object has a different\n      # number of columns.\n      self.assertEqual(None, _create_tensor([[1], [1, 2]]))\n\n  def testMultiLineTensorStr(self):\n    t = _create_tensor(np.eye(3))\n    tensor_str = str(t)\n    self.assertIn(\"shape=%s, dtype=%s\" % (t.shape, t.dtype.name), tensor_str)\n    self.assertIn(str(t), tensor_str)\n\n  def testMultiLineTensorRepr(self):\n    t = _create_tensor(np.eye(3))\n    tensor_repr = repr(t)\n    self.assertTrue(tensor_repr.startswith(\"<\"))\n    self.assertTrue(tensor_repr.endswith(\">\"))\n    self.assertIn(\n        \"shape=%s, dtype=%s, numpy=\\n%r\" % (t.shape, t.dtype.name, t.numpy()),\n        tensor_repr)\n\n  def testTensorStrReprObeyNumpyPrintOptions(self):\n    orig_threshold = np.get_printoptions()[\"threshold\"]\n    orig_edgeitems = np.get_printoptions()[\"edgeitems\"]\n    np.set_printoptions(threshold=2, edgeitems=1)\n\n    t = _create_tensor(np.arange(10, dtype=np.int32))\n    self.assertTrue(re.match(r\".*\\[.*0.*\\.\\.\\..*9.*\\]\", str(t)))\n    self.assertTrue(re.match(r\".*\\[.*0.*\\.\\.\\..*9.*\\]\", repr(t)))\n\n    # Clean up: reset to previous printoptions.\n    np.set_printoptions(threshold=orig_threshold, edgeitems=orig_edgeitems)\n\n  def testZeroDimTensorStr(self):\n    t = _create_tensor(42)\n    self.assertIn(\"42, shape=(), dtype=int32\", str(t))\n\n  def testZeroDimTensorRepr(self):\n    t = _create_tensor(42)\n    self.assertTrue(repr(t).startswith(\"<\"))\n    self.assertTrue(repr(t).endswith(\">\"))\n    self.assertIn(\"shape=(), dtype=int32, numpy=42\", repr(t))\n\n  def testZeroSizeTensorStr(self):\n    t = _create_tensor(np.zeros(0, dtype=np.float32))\n    self.assertIn(\"[], shape=(0,), dtype=float32\", str(t))\n\n  def testZeroSizeTensorRepr(self):\n    t = _create_tensor(np.zeros(0, dtype=np.float32))\n    self.assertTrue(repr(t).startswith(\"<\"))\n    self.assertTrue(repr(t).endswith(\">\"))\n    self.assertIn(\"shape=(0,), dtype=float32, numpy=%r\" % t.numpy(), repr(t))\n\n  def testStringTensor(self):\n    t_np_orig = np.array([[b\"a\", b\"ab\"], [b\"abc\", b\"abcd\"]])\n    t = _create_tensor(t_np_orig)\n    t_np = t.numpy()\n    self.assertTrue(np.all(t_np == t_np_orig), \"%s vs %s\" % (t_np, t_np_orig))\n\n  def testIterateOverTensor(self):\n    l = [[1, 2], [3, 4]]\n    t = _create_tensor(l)\n    for list_element, tensor_element in zip(l, t):\n      self.assertAllEqual(list_element, tensor_element.numpy())\n\n  def testIterateOverScalarTensorRaises(self):\n    t = _create_tensor(1)\n    with self.assertRaisesRegex(TypeError,\n                                \"Cannot iterate over a scalar tensor\"):\n      iter(t)\n\n  @test_util.run_gpu_only\n  def testStringTensorOnGPU(self):\n    with ops.device(\"/device:GPU:0\"):\n      t = _create_tensor(\"test string\")\n      self.assertIn(\"GPU\", t.device)\n\n  def testInvalidUTF8ProducesReasonableError(self):\n    if sys.version_info[0] < 3:\n      self.skipTest(\"Test is only valid in python3.\")\n    with self.assertRaises(UnicodeDecodeError):\n      io_ops.read_file(b\"\\xff\")\n\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorPreferredDtypeIsRespected(self):\n    self.assertEqual(\n        ops.convert_to_tensor(0.5, preferred_dtype=dtypes.int32).dtype,\n        dtypes.float32)\n    self.assertEqual(\n        ops.convert_to_tensor(0.5, preferred_dtype=dtypes.float64).dtype,\n        dtypes.float64)\n\n  @test_util.run_in_graph_and_eager_modes\n  def testCompatibility(self):\n    integer_types = [\n        dtypes.int8, dtypes.int16, dtypes.int32, dtypes.int64, dtypes.uint8,\n        dtypes.uint16, dtypes.uint32, dtypes.uint64\n    ]\n\n    # Floats are not compatible with ints\n    for t in integer_types:\n      with self.assertRaises(TypeError):\n        constant_op.constant(0.5, dtype=t)\n\n    # Ints compatible with floats\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.float16)), 5.0)\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.float32)), 5.0)\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.float64)), 5.0)\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.bfloat16)), 5.0)\n\n    # Ints and floats are compatible with complex types\n    self.assertEqual(\n        constant_op.constant([[1.0]], dtype=dtypes.complex128).dtype,\n        dtypes.complex128)\n    self.assertEqual(\n        constant_op.constant([[1]], dtype=dtypes.complex128).dtype,\n        dtypes.complex128)\n\n    # Quantized types are not compatible with floats\n    quantized_types = [\n        dtypes.qint16, dtypes.qint32, dtypes.qint8, dtypes.quint16,\n        dtypes.quint8\n    ]\n\n    for t in quantized_types:\n      with self.assertRaises(TypeError):\n        constant_op.constant(0.5, dtype=t)\n\n    # TODO(b/118402529): quantized types are broken in eager.\n\n  @test_util.run_in_graph_and_eager_modes\n  def testCConvertToTensor(self):\n    with self.assertRaises(TypeError):\n      _ = constant_op.constant(0) < 0.5\n\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorAllowsOverflow(self):\n    _ = ops.convert_to_tensor(123456789, dtype=dtypes.uint8)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorNumpyZeroDim(self):\n    for np_type, dtype in [(np.int32, dtypes.int32), (np.half, dtypes.half),\n                           (np.float32, dtypes.float32)]:\n      x = ops.convert_to_tensor(\n          [np.array(65, dtype=np_type),\n           np.array(16, dtype=np_type)])\n      self.assertEqual(x.dtype, dtype)\n      self.assertAllEqual(x, [65, 16])\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorNumpyScalar(self):\n    x = ops.convert_to_tensor([\n        np.array(321, dtype=np.int64).item(),\n        np.array(16, dtype=np.int64).item()\n    ])\n    self.assertAllEqual(x, [321, 16])\n\n  def testEagerTensorError(self):\n    with self.assertRaisesRegex(TypeError,\n                                \"Cannot convert .* to EagerTensor of dtype .*\"):\n      _ = ops.convert_to_tensor(1., dtype=dtypes.int32)\n\n  def testEagerLargeConstant(self):\n    for t in [dtypes.uint64, dtypes.uint32, dtypes.int32, dtypes.int64]:\n      self.assertEqual(constant_op.constant(t.max, dtype=t).numpy(), t.max)\n      self.assertEqual(constant_op.constant(t.min, dtype=t).numpy(), t.min)\n\n  def test_numpyIsView(self):\n    with ops.device(\"CPU\"):\n      t = constant_op.constant([0.0])\n      t._numpy()[0] = 42.0\n      self.assertAllClose(t, constant_op.constant([42.0]))\n\n  def test_numpyFailsForResource(self):\n    v = variables.Variable(42)\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Cannot convert .+ resource\"):\n      v._handle._numpy()\n\n  def test_numpyFailsForVariant(self):\n    variant_t = list_ops.tensor_list_reserve(\n        element_shape=[], num_elements=1, element_dtype=dtypes.float32)\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Cannot convert .+ variant\"):\n      variant_t._numpy()\n\n  def testMemoryviewFailsForResource(self):\n    v = variables.Variable(42)\n    with self.assertRaisesRegex(BufferError, \"Cannot convert .+ resource\"):\n      np.asarray(memoryview(v._handle))\n\n  def testMemoryviewFailsForVariant(self):\n    variant_t = list_ops.tensor_list_reserve(\n        element_shape=[], num_elements=1, element_dtype=dtypes.float32)\n    with self.assertRaisesRegex(BufferError, \"Cannot convert .+ variant\"):\n      np.asarray(memoryview(variant_t))\n\n  def testMemoryviewIsReadonly(self):\n    t = constant_op.constant([0.0])\n    self.assertTrue(memoryview(t).readonly)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testMemoryviewScalar(self):\n    t = constant_op.constant(42.0)\n    self.assertAllEqual(\n        np.array(memoryview(t)), np.array(42.0, dtype=np.float32))\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testMemoryviewEmpty(self):\n    t = constant_op.constant([], dtype=np.float32)\n    self.assertAllEqual(np.array(memoryview(t)), np.array([]))\n\n  @test_util.run_gpu_only\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testMemoryviewCopyToCPU(self):\n    with ops.device(\"/device:GPU:0\"):\n      t = constant_op.constant([0.0])\n    self.assertAllEqual(\n        np.array(memoryview(t)), np.array([0.0], dtype=np.float32))\n\n  @test_util.disable_tfrt(\"b/169877776: ResourceVariable is not initialized \"\n                          \"properly in TFRT\")\n  def testResourceTensorCopy(self):\n    if not test_util.is_gpu_available():\n      self.skipTest(\"GPU only\")\n\n    with ops.device(\"GPU:0\"):\n      v = resource_variable_ops.ResourceVariable(1.)\n\n    read_handle_on_gpu = resource_variable_ops.read_variable_op(\n        v.handle, dtypes.float32)\n    handle_on_cpu = v.handle.cpu()\n    read_handle_on_cpu = resource_variable_ops.read_variable_op(\n        handle_on_cpu, dtypes.float32)\n\n    self.assertAllEqual(read_handle_on_cpu, read_handle_on_gpu)\n\n  def testEagerTensorFormat(self):\n    t = array_ops.constant(1)\n    self.assertEqual(f\"{t}\", \"1\")\n    self.assertEqual(str(t), \"tf.Tensor(1, shape=(), dtype=int32)\")\n    self.assertEqual(f\"{t!s}\", \"tf.Tensor(1, shape=(), dtype=int32)\")\n    self.assertEqual(repr(t), \"<tf.Tensor: shape=(), dtype=int32, numpy=1>\")\n    self.assertEqual(f\"{t!r}\", \"<tf.Tensor: shape=(), dtype=int32, numpy=1>\")\n\n  def testEagerTensorFormatForResource(self):\n    t = resource_variable_ops.VarHandleOp(shape=[], dtype=dtypes.float32)\n\n    # type is compiler-depdendent, as it comes from demangling.\n    handle_str = (f\"<ResourceHandle(\"\n                  f\"name=\\\"\\\", \"\n                  f\"device=\\\"{t.device}\\\", \"\n                  f\"container=\\\"localhost\\\", \"\n                  f\"type=\\\"@@tensorflow@@Var@@\\\")>\")\n\n    def make_regex(s):\n      return re.escape(s).replace(\"@@\", \".*\")\n\n    self.assertRegex(f\"{t}\", make_regex(handle_str))\n    self.assertRegex(\n        str(t),\n        make_regex(f\"tf.Tensor({handle_str}, shape=(), dtype=resource)\"))\n    self.assertRegex(\n        f\"{t!s}\",\n        make_regex(f\"tf.Tensor({handle_str}, shape=(), dtype=resource)\"))\n    self.assertRegex(\n        repr(t),\n        make_regex(\n            f\"<tf.Tensor: shape=(), dtype=resource, value={handle_str}>\"))\n    self.assertRegex(\n        f\"{t!r}\",\n        make_regex(\n            f\"<tf.Tensor: shape=(), dtype=resource, value={handle_str}>\"))\n\n  def testEagerTensorFormatForVariant(self):\n    t = list_ops.tensor_list_reserve(\n        element_shape=[1], num_elements=1, element_dtype=dtypes.float32)\n    self.assertEqual(f\"{t}\", \"<TensorList>\")\n    self.assertEqual(str(t), \"tf.Tensor(<TensorList>, shape=(), dtype=variant)\")\n    self.assertEqual(f\"{t!s}\",\n                     \"tf.Tensor(<TensorList>, shape=(), dtype=variant)\")\n    self.assertEqual(\n        repr(t), \"<tf.Tensor: shape=(), dtype=variant, value=<TensorList>>\")\n    self.assertEqual(\n        f\"{t!r}\", \"<tf.Tensor: shape=(), dtype=variant, value=<TensorList>>\")\n\n  def testNumpyTooManyDimensions(self):\n    t = constant_op.constant(1., shape=[1] * 33)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Cannot convert tensor with 33 dimensions to NumPy array. NumPy arrays \"\n        \"can have at most 32 dimensions\"):\n      t.numpy()\n\n  def testNumpyDimsTooBig(self):\n    # Creating a Numpy array fails in some cases if the product of non-zero\n    # dimensions is very big, even if the shape also has a zero in it.\n    t = array_ops.ones((0, 2**31, 2**31))\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Failed to create numpy array from tensor of shape \"\n        r\"\\[0, 2147483648, 2147483648\\]. Numpy error.*array is too big\"):\n      t.numpy()\n\n\nclass TFETensorUtilTest(test_util.TensorFlowTestCase):\n\n  def setUp(self):\n    super(TFETensorUtilTest, self).setUp()\n    context.ensure_initialized()\n\n  def testListOfThree(self):\n    t1 = _create_tensor([[1, 2], [3, 4], [5, 6]], dtype=dtypes.int32)\n    t2 = _create_tensor([[1, 2, 5], [3, 4, 5]], dtype=dtypes.int32)\n    t3 = _create_tensor([[1], [3], [5], [6]], dtype=dtypes.int32)\n\n    r = pywrap_tfe.TFE_Py_TensorShapeSlice([t1, t2, t3], 0)\n    self.assertAllEqual(np.array([3, 2, 4]), r.numpy())\n\n    r = pywrap_tfe.TFE_Py_TensorShapeSlice([t1, t2, t3], 1)\n    self.assertAllEqual(np.array([2, 3, 1]), r.numpy())\n\n  def testEmptyTensorList(self):\n    a = pywrap_tfe.TFE_Py_TensorShapeSlice([], 0)\n    self.assertTrue(isinstance(a, ops.EagerTensor))\n    self.assertEqual(0, a.numpy().size)\n\n  def testTensorListContainsNonTensors(self):\n    t1 = _create_tensor([1, 2], dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        TypeError,\n        r\"Expected a list of EagerTensors but element 1 has type \\\"str\\\"\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1, \"abc\"], 0)\n\n    with self.assertRaisesRegex(\n        TypeError,\n        r\"Expected a list of EagerTensors but element 0 has type \\\"int\\\"\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([2, t1], 0)\n\n  def testTensorListNotList(self):\n    t1 = _create_tensor([1, 2], dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        TypeError,\n        r\"tensors argument must be a list or a tuple. Got.*EagerTensor\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice(t1, -2)\n\n  def testNegativeSliceDim(self):\n    t1 = _create_tensor([1, 2], dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        ValueError, r\"Slice dimension must be non-negative. Got -2\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1], -2)\n\n  def testUnicode(self):\n    self.assertEqual(constant_op.constant(u\"asdf\").numpy(), b\"asdf\")\n\n  def testFloatTensor(self):\n    self.assertEqual(dtypes.float64, _create_tensor(np.float64()).dtype)  # pylint: disable=no-value-for-parameter\n    self.assertEqual(dtypes.float32, _create_tensor(np.float32()).dtype)  # pylint: disable=no-value-for-parameter\n    self.assertEqual(dtypes.float16, _create_tensor(np.float16()).dtype)  # pylint: disable=no-value-for-parameter\n    self.assertEqual(dtypes.float32, _create_tensor(0.0).dtype)\n\n  def testSliceDimOutOfRange(self):\n    t1 = _create_tensor([[1, 2], [3, 4], [5, 6]], dtype=dtypes.int32)\n    t2 = _create_tensor([1, 2], dtype=dtypes.int32)\n    t3 = _create_tensor(2, dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(2\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 0 has rank 2\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1], 2)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(1\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 0 has rank 1\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t2], 1)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(1\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 1 has rank 1\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1, t2], 1)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(0\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 0 has rank 0\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t3], 0)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(0\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 2 has rank 0\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t2, t1, t3], 0)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testTensorDir(self):\n    t = array_ops.ones(1)\n    t.test_attr = \"Test\"\n\n    instance_dir = dir(t)\n    type_dir = dir(ops.EagerTensor)\n\n    # Monkey patched attributes should show up in dir(t)\n    self.assertIn(\"test_attr\", instance_dir)\n    instance_dir.remove(\"test_attr\")\n    self.assertEqual(instance_dir, type_dir)\n\n  def testNonRectangularPackAsConstant(self):\n    l = [array_ops.zeros((10, 1)).numpy(), array_ops.zeros(1).numpy()]\n\n    with self.assertRaisesRegex(ValueError, \"non-rectangular Python sequence\"):\n      constant_op.constant(l)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testFloatAndIntAreConvertibleToComplex(self):\n    a = [[1., 1], [1j, 2j]]\n    np_value = np.array(a, dtype=np.complex128)\n    tf_value = ops.convert_to_tensor(a, dtype=dtypes.complex128)\n    self.assertAllEqual(tf_value.numpy(), np_value)\n\n\nif __name__ == \"__main__\":\n  test.main()\n", "# python/lib/core package\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_python_pybind_extension\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_py_test\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_external_workspace_visible\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"get_compatible_with_portable\")\n\nvisibility = [\n    \"//engedu/ml/tf_from_scratch:__pkg__\",\n    \"//third_party/cloud_tpu/convergence_tools:__subpackages__\",\n    \"//third_party/mlperf:__subpackages__\",\n    \"//tensorflow:internal\",\n    \"//tensorflow/lite/toco/python:__pkg__\",\n    \"//tensorflow_models:__subpackages__\",\n    \"//tensorflow_model_optimization:__subpackages__\",\n    \"//third_party/py/cleverhans:__subpackages__\",\n    \"//third_party/py/launchpad:__subpackages__\",\n    \"//third_party/py/reverb:__subpackages__\",\n    \"//third_party/py/neural_structured_learning:__subpackages__\",\n    \"//third_party/py/tensorflow_examples:__subpackages__\",\n    \"//third_party/py/tf_agents:__subpackages__\",  # For benchmarks.\n    \"//third_party/py/tf_slim:__subpackages__\",\n    \"//third_party/py/tensorflow_docs:__subpackages__\",\n    \"//third_party/py/keras:__subpackages__\",\n]\n\npackage(\n    default_visibility = visibility,\n    licenses = [\"notice\"],\n)\n\ncc_library(\n    name = \"numpy_lib\",\n    srcs = [\"numpy.cc\"],\n    hdrs = [\"numpy.h\"],\n    deps = [\n        \"//third_party/py/numpy:headers\",\n        \"//third_party/python_runtime:headers\",\n    ],\n)\n\ncc_library(\n    name = \"bfloat16_lib\",\n    srcs = [\n        \"bfloat16.cc\",\n        \"float8_e4m3b11.cc\",\n    ],\n    hdrs = [\n        \"bfloat16.h\",\n        \"float8_e4m3b11.h\",\n    ],\n    deps = [\n        \":numpy_lib\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:types\",\n        \"//third_party/eigen3\",\n        \"//third_party/python_runtime:headers\",  # build_cleaner: keep; DNR: b/35864863\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_python_pybind_extension(\n    name = \"_pywrap_bfloat16\",\n    srcs = [\"bfloat16_wrapper.cc\"],\n    hdrs = [\"bfloat16.h\"],\n    deps = [\n        \"//third_party/python_runtime:headers\",\n        \"@pybind11\",\n    ],\n)\n\ncc_library(\n    name = \"ndarray_tensor_bridge\",\n    srcs = [\"ndarray_tensor_bridge.cc\"],\n    hdrs = [\"ndarray_tensor_bridge.h\"],\n    visibility = tf_external_workspace_visible(\n        visibility + [\n            \"//tensorflow:ndarray_tensor_allow_list\",\n        ],\n    ),\n    deps = [\n        \":bfloat16_lib\",\n        \":numpy_lib\",\n        \":py_util\",\n        \"//tensorflow/c:c_api_no_xla\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n    ],\n)\n\ncc_library(\n    name = \"py_exception_registry\",\n    srcs = [\"py_exception_registry.cc\"],\n    hdrs = [\"py_exception_registry.h\"],\n    deps = [\n        \"//tensorflow/c:tf_status_headers\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//third_party/python_runtime:headers\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"pybind11_absl\",\n    hdrs = [\"pybind11_absl.h\"],\n    features = [\"-parse_headers\"],\n    visibility = tf_external_workspace_visible(visibility),\n    deps = [\n        \"//tensorflow/core/platform:stringpiece\",\n        \"@pybind11\",\n    ],\n)\n\ncc_library(\n    name = \"pybind11_lib\",\n    hdrs = [\"pybind11_lib.h\"],\n    compatible_with = get_compatible_with_portable(),\n    features = [\"-parse_headers\"],\n    visibility = tf_external_workspace_visible(visibility),\n    deps = [\n        \"@pybind11\",\n    ],\n)\n\ncc_library(\n    name = \"pybind11_status_headers\",\n    hdrs = [\n        \"py_exception_registry.h\",\n        \"pybind11_status.h\",\n        \"//tensorflow/c:headers\",\n        \"//tensorflow/c:tf_status_internal_headers\",\n        \"//tensorflow/c/eager:headers\",\n    ],\n    features = [\n        \"-parse_headers\",\n    ],\n    visibility = tf_external_workspace_visible(visibility),\n    deps = [\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core/common_runtime:core_cpu_headers_lib\",\n        \"//third_party/python_runtime:headers\",\n        \"@pybind11\",\n    ],\n)\n\ncc_library(\n    name = \"pybind11_status\",\n    hdrs = [\n        \"py_exception_registry.h\",\n        \"pybind11_status.h\",\n    ],\n    features = [\"-parse_headers\"],\n    visibility = tf_external_workspace_visible(visibility),\n    deps = [\n        \":pybind11_status_headers\",\n        \"//tensorflow/core:lib\",\n    ],\n)\n\ncc_library(\n    name = \"pybind11_proto\",\n    hdrs = [\"pybind11_proto.h\"],\n    features = [\"-parse_headers\"],\n    visibility = tf_external_workspace_visible(visibility),\n    deps = [\n        \"@com_google_absl//absl/strings\",\n        \"@pybind11\",\n    ],\n)\n\nfilegroup(\n    name = \"py_exception_registry_hdr\",\n    srcs = [\n        \"py_exception_registry.h\",\n    ],\n    visibility = [\"//visibility:public\"],\n)\n\nfilegroup(\n    name = \"numpy_hdr\",\n    srcs = [\"numpy.h\"],\n)\n\nfilegroup(\n    name = \"safe_ptr_hdr\",\n    srcs = [\"safe_ptr.h\"],\n)\n\nfilegroup(\n    name = \"ndarray_tensor_hdr\",\n    srcs = [\"ndarray_tensor.h\"],\n)\n\nfilegroup(\n    name = \"basic_hdrs\",\n    srcs = [\n        \"bfloat16.h\",\n        \"ndarray_tensor.h\",\n        \"ndarray_tensor_bridge.h\",\n        \"numpy.h\",\n        \"py_exception_registry.h\",\n        \"pybind11_status.h\",\n        \"safe_ptr.h\",\n        \"safe_pyobject_ptr.h\",\n    ],\n)\n\ncc_library(\n    name = \"py_func_lib\",\n    srcs = [\"py_func.cc\"],\n    hdrs = [\"py_func.h\"],\n    deps = [\n        \":ndarray_tensor\",\n        \":ndarray_tensor_bridge\",\n        \":numpy_lib\",\n        \":py_util\",\n        \":safe_ptr\",\n        \"//tensorflow/c:tf_status_helper\",\n        \"//tensorflow/c/eager:c_api\",\n        \"//tensorflow/c/eager:tfe_context_internal\",\n        \"//tensorflow/c/eager:tfe_tensorhandle_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:script_ops_op_lib\",\n        \"//tensorflow/core/common_runtime/eager:context\",\n        \"//tensorflow/core/common_runtime/eager:tensor_handle\",\n        \"//tensorflow/python/eager:pywrap_tfe_lib\",\n        \"//third_party/py/numpy:headers\",\n        \"//third_party/python_runtime:headers\",\n    ],\n    alwayslink = 1,\n)\n\ntf_python_pybind_extension(\n    name = \"_pywrap_py_func\",\n    srcs = [\"py_func_wrapper.cc\"],\n    deps = [\n        \"//tensorflow/python:py_func_headers_lib\",\n        \"//third_party/python_runtime:headers\",\n        \"@pybind11\",\n    ],\n)\n\ncc_library(\n    name = \"safe_pyobject_ptr\",\n    srcs = [\"safe_pyobject_ptr.cc\"],\n    hdrs = [\"safe_pyobject_ptr.h\"],\n    deps = [\n        \"//third_party/python_runtime:headers\",\n    ],\n)\n\ncc_library(\n    name = \"safe_pyobject_ptr_required_hdrs\",\n    textual_hdrs = [\"safe_pyobject_ptr.h\"],\n)\n\ncc_library(\n    name = \"safe_ptr\",\n    srcs = [\n        \"safe_ptr.cc\",\n        \"//tensorflow/c/eager:headers\",\n    ],\n    hdrs = [\"safe_ptr.h\"],\n    deps = [\n        \":safe_pyobject_ptr\",\n        \"//tensorflow/c:c_api_no_xla\",\n        \"//third_party/python_runtime:headers\",\n    ],\n)\n\ncc_library(\n    name = \"ndarray_tensor_headers\",\n    hdrs = [\n        \"bfloat16.h\",\n        \"ndarray_tensor.h\",\n        \"ndarray_tensor_bridge.h\",\n        \"numpy.h\",\n        \"safe_ptr.h\",\n        \"safe_pyobject_ptr.h\",\n        \"//tensorflow/c:headers\",\n        \"//tensorflow/c/eager:headers\",\n    ],\n    features = [\n        \"-parse_headers\",\n    ],\n    visibility = tf_external_workspace_visible(visibility + [\n        \"//tensorflow:ndarray_tensor_allow_list\",\n    ]),\n    deps = [\n        \":numpy_lib\",\n        \"//tensorflow/c:pywrap_required_hdrs\",\n        \"//tensorflow/c:tf_status_headers\",\n        \"//tensorflow/core:framework_internal_headers_lib\",\n        \"//tensorflow/core/common_runtime:core_cpu_headers_lib\",\n        \"//third_party/py/numpy:headers\",\n        \"//third_party/python_runtime:headers\",\n    ],\n)\n\ncc_library(\n    name = \"ndarray_tensor\",\n    srcs = [\"ndarray_tensor.cc\"],\n    hdrs = [\"ndarray_tensor.h\"],\n    visibility = tf_external_workspace_visible(visibility + [\n        \"//tensorflow:ndarray_tensor_allow_list\",\n    ]),\n    deps = [\n        \":bfloat16_lib\",\n        \":ndarray_tensor_bridge\",\n        \":numpy_lib\",\n        \":safe_ptr\",\n        \"//tensorflow/c:c_api_internal\",\n        \"//tensorflow/c:tf_status_helper\",\n        \"//tensorflow/c:tf_tensor_internal\",\n        \"//tensorflow/c/eager:tfe_context_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n    ],\n)\n\ncc_library(\n    name = \"py_seq_tensor\",\n    srcs = [\"py_seq_tensor.cc\"],\n    hdrs = [\"py_seq_tensor.h\"],\n    features = [\"-parse_headers\"],\n    deps = [\n        \":ndarray_tensor\",\n        \":ndarray_tensor_bridge\",\n        \":numpy_lib\",\n        \":py_util\",\n        \":safe_ptr\",\n        \"//tensorflow/c:tensor_interface\",\n        \"//tensorflow/c:tf_tensor_internal\",\n        \"//tensorflow/c/eager:c_api_internal\",\n        \"//tensorflow/c/eager:tfe_context_internal\",\n        \"//tensorflow/c/eager:tfe_tensorhandle_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//third_party/python_runtime:headers\",  # build_cleaner: keep; DNR: b/35864863\n    ],\n)\n\ncc_library(\n    name = \"py_util\",\n    srcs = [\"py_util.cc\"],\n    hdrs = [\"py_util.h\"],\n    deps = [\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:script_ops_op_lib\",\n        \"//tensorflow/core/platform:logging\",\n        \"//third_party/python_runtime:headers\",\n    ],\n)\n\ntf_py_test(\n    name = \"bfloat16_test\",\n    size = \"small\",\n    srcs = [\"bfloat16_test.py\"],\n    python_version = \"PY3\",\n    deps = [\n        \"//tensorflow/python:pywrap_tensorflow\",\n        \"//tensorflow/python/lib/io:lib\",\n        \"//tensorflow/python/platform:client_testlib\",\n    ],\n)\n", "/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// clang-format off\n// Must be included first.\n#include \"tensorflow/python/lib/core/numpy.h\"\n// clang-format on\n\n#include \"tensorflow/python/lib/core/ndarray_tensor_bridge.h\"\n\n#include <vector>\n\n#include \"tensorflow/c/c_api.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/platform/mutex.h\"\n#include \"tensorflow/python/lib/core/bfloat16.h\"\n#include \"tensorflow/python/lib/core/py_util.h\"\n\nnamespace tensorflow {\n\n// Mutex used to serialize accesses to cached vector of pointers to python\n// arrays to be dereferenced.\nstatic mutex* DelayedDecrefLock() {\n  static mutex* decref_lock = new mutex;\n  return decref_lock;\n}\n\n// Caches pointers to numpy arrays which need to be dereferenced.\nstatic std::vector<void*>* DecrefCache() {\n  static std::vector<void*>* decref_cache = new std::vector<void*>;\n  return decref_cache;\n}\n\n// Destructor passed to TF_NewTensor when it reuses a numpy buffer. Stores a\n// pointer to the pyobj in a buffer to be dereferenced later when we're actually\n// holding the GIL.\nvoid DelayedNumpyDecref(void* data, size_t len, void* obj) {\n  mutex_lock ml(*DelayedDecrefLock());\n  DecrefCache()->push_back(obj);\n}\n\n// Actually dereferences cached numpy arrays. REQUIRES being called while\n// holding the GIL.\nvoid ClearDecrefCache() {\n  std::vector<void*> cache_copy;\n  {\n    mutex_lock ml(*DelayedDecrefLock());\n    cache_copy.swap(*DecrefCache());\n  }\n  for (void* obj : cache_copy) {\n    Py_DECREF(reinterpret_cast<PyObject*>(obj));\n  }\n}\n\n// Structure which keeps a reference to a Tensor alive while numpy has a pointer\n// to it.\nstruct TensorReleaser {\n  // Python macro to include standard members.\n  PyObject_HEAD\n\n      // Destructor responsible for releasing the memory.\n      std::function<void()>* destructor;\n};\n\nextern PyTypeObject TensorReleaserType;\n\nstatic void TensorReleaser_dealloc(PyObject* pself) {\n  TensorReleaser* self = reinterpret_cast<TensorReleaser*>(pself);\n  (*self->destructor)();\n  delete self->destructor;\n  TensorReleaserType.tp_free(pself);\n}\n\n// clang-format off\nPyTypeObject TensorReleaserType = {\n    PyVarObject_HEAD_INIT(nullptr, 0) /* head init */\n    \"tensorflow_wrapper\",             /* tp_name */\n    sizeof(TensorReleaser),           /* tp_basicsize */\n    0,                                /* tp_itemsize */\n    /* methods */\n    TensorReleaser_dealloc,      /* tp_dealloc */\n#if PY_VERSION_HEX < 0x03080000\n    nullptr,                     /* tp_print */\n#else\n    0,                           /* tp_vectorcall_offset */\n#endif\n    nullptr,                     /* tp_getattr */\n    nullptr,                     /* tp_setattr */\n    nullptr,                     /* tp_compare */\n    nullptr,                     /* tp_repr */\n    nullptr,                     /* tp_as_number */\n    nullptr,                     /* tp_as_sequence */\n    nullptr,                     /* tp_as_mapping */\n    nullptr,                     /* tp_hash */\n    nullptr,                     /* tp_call */\n    nullptr,                     /* tp_str */\n    nullptr,                     /* tp_getattro */\n    nullptr,                     /* tp_setattro */\n    nullptr,                     /* tp_as_buffer */\n    Py_TPFLAGS_DEFAULT,          /* tp_flags */\n    \"Wrapped TensorFlow Tensor\", /* tp_doc */\n    nullptr,                     /* tp_traverse */\n    nullptr,                     /* tp_clear */\n    nullptr,                     /* tp_richcompare */\n};\n// clang-format on\n\nStatus TF_DataType_to_PyArray_TYPE(TF_DataType tf_datatype,\n                                   int* out_pyarray_type) {\n  switch (tf_datatype) {\n    case TF_HALF:\n      *out_pyarray_type = NPY_FLOAT16;\n      break;\n    case TF_FLOAT:\n      *out_pyarray_type = NPY_FLOAT32;\n      break;\n    case TF_DOUBLE:\n      *out_pyarray_type = NPY_FLOAT64;\n      break;\n    case TF_INT32:\n      *out_pyarray_type = NPY_INT32;\n      break;\n    case TF_UINT32:\n      *out_pyarray_type = NPY_UINT32;\n      break;\n    case TF_UINT8:\n      *out_pyarray_type = NPY_UINT8;\n      break;\n    case TF_UINT16:\n      *out_pyarray_type = NPY_UINT16;\n      break;\n    case TF_INT8:\n      *out_pyarray_type = NPY_INT8;\n      break;\n    case TF_INT16:\n      *out_pyarray_type = NPY_INT16;\n      break;\n    case TF_INT64:\n      *out_pyarray_type = NPY_INT64;\n      break;\n    case TF_UINT64:\n      *out_pyarray_type = NPY_UINT64;\n      break;\n    case TF_BOOL:\n      *out_pyarray_type = NPY_BOOL;\n      break;\n    case TF_COMPLEX64:\n      *out_pyarray_type = NPY_COMPLEX64;\n      break;\n    case TF_COMPLEX128:\n      *out_pyarray_type = NPY_COMPLEX128;\n      break;\n    case TF_STRING:\n      *out_pyarray_type = NPY_OBJECT;\n      break;\n    case TF_RESOURCE:\n      *out_pyarray_type = NPY_VOID;\n      break;\n    // TODO(keveman): These should be changed to NPY_VOID, and the type used for\n    // the resulting numpy array should be the custom struct types that we\n    // expect for quantized types.\n    case TF_QINT8:\n      *out_pyarray_type = NPY_INT8;\n      break;\n    case TF_QUINT8:\n      *out_pyarray_type = NPY_UINT8;\n      break;\n    case TF_QINT16:\n      *out_pyarray_type = NPY_INT16;\n      break;\n    case TF_QUINT16:\n      *out_pyarray_type = NPY_UINT16;\n      break;\n    case TF_QINT32:\n      *out_pyarray_type = NPY_INT32;\n      break;\n    case TF_BFLOAT16:\n      *out_pyarray_type = Bfloat16NumpyType();\n      break;\n    default:\n      return errors::Internal(\"Tensorflow type \", tf_datatype,\n                              \" not convertible to numpy dtype.\");\n  }\n  return OkStatus();\n}\n\nStatus ArrayFromMemory(int dim_size, npy_intp* dims, void* data, DataType dtype,\n                       std::function<void()> destructor, PyObject** result) {\n  if (dtype == DT_STRING || dtype == DT_RESOURCE) {\n    return errors::FailedPrecondition(\n        \"Cannot convert string or resource Tensors.\");\n  }\n\n  int type_num = -1;\n  Status s =\n      TF_DataType_to_PyArray_TYPE(static_cast<TF_DataType>(dtype), &type_num);\n  if (!s.ok()) {\n    return s;\n  }\n\n  if (dim_size > NPY_MAXDIMS) {\n    return errors::InvalidArgument(\n        \"Cannot convert tensor with \", dim_size,\n        \" dimensions to NumPy array. NumPy arrays can have at most \",\n        NPY_MAXDIMS, \" dimensions\");\n  }\n  auto* np_array = reinterpret_cast<PyArrayObject*>(\n      PyArray_SimpleNewFromData(dim_size, dims, type_num, data));\n  if (np_array == nullptr) {\n    string shape_str = absl::StrJoin(\n        absl::Span<npy_intp>{dims, static_cast<size_t>(dim_size)}, \", \");\n    if (PyErr_Occurred()) {\n      string exception_str = PyExceptionFetch();\n      PyErr_Clear();\n      return errors::InvalidArgument(\n          \"Failed to create numpy array from tensor of shape [\", shape_str,\n          \"]. Numpy error: \", exception_str);\n    }\n    return errors::Internal(\n        \"Failed to create numpy array from tensor of shape [\", shape_str, \"]\");\n  }\n\n  PyArray_CLEARFLAGS(np_array, NPY_ARRAY_OWNDATA);\n  if (PyType_Ready(&TensorReleaserType) == -1) {\n    return errors::Unknown(\"Python type initialization failed.\");\n  }\n  auto* releaser = reinterpret_cast<TensorReleaser*>(\n      TensorReleaserType.tp_alloc(&TensorReleaserType, 0));\n  releaser->destructor = new std::function<void()>(std::move(destructor));\n  if (PyArray_SetBaseObject(np_array, reinterpret_cast<PyObject*>(releaser)) ==\n      -1) {\n    Py_DECREF(releaser);\n    return errors::Unknown(\"Python array refused to use memory.\");\n  }\n  *result = reinterpret_cast<PyObject*>(np_array);\n  return OkStatus();\n}\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/python/eager/tensor_test.py", "tensorflow/python/lib/core/BUILD", "tensorflow/python/lib/core/ndarray_tensor_bridge.cc"], "buggy_code_start_loc": [517, 90, 15], "buggy_code_end_loc": [517, 90, 216], "fixing_code_start_loc": [518, 91, 16], "fixing_code_end_loc": [528, 92, 235], "type": "CWE-670", "message": "TensorFlow is an open source platform for machine learning. If a numpy array is created with a shape such that one element is zero and the others sum to a large number, an error will be raised. We have patched the issue in GitHub commit 2b56169c16e375c521a3bc8ea658811cc0793784. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2022-41884", "sourceIdentifier": "security-advisories@github.com", "published": "2022-11-18T22:15:13.573", "lastModified": "2022-11-22T21:53:09.703", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. If a numpy array is created with a shape such that one element is zero and the others sum to a large number, an error will be raised. We have patched the issue in GitHub commit 2b56169c16e375c521a3bc8ea658811cc0793784. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:R/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 4.8, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.2, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-670"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.8.4", "matchCriteriaId": "A694EEE1-BFB9-4E6C-B275-02DC2731961C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.9.0", "versionEndExcluding": "2.9.3", "matchCriteriaId": "9057B403-719C-4F10-BAB6-67F84786A89E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10.0:*:*:*:*:*:*:*", "matchCriteriaId": "6AE6CFC4-0232-4E1C-960D-268C87788735"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/2b56169c16e375c521a3bc8ea658811cc0793784", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jq6x-99hj-q636", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/2b56169c16e375c521a3bc8ea658811cc0793784"}}
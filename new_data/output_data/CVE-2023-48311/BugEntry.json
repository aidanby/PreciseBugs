{"buggy_code": ["\"\"\"\nA Spawner for JupyterHub that runs each user's server in a separate docker container\n\"\"\"\nimport asyncio\nimport inspect\nimport os\nimport string\nimport warnings\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import partial\nfrom io import BytesIO\nfrom pprint import pformat\nfrom tarfile import TarFile, TarInfo\nfrom textwrap import dedent, indent\nfrom urllib.parse import urlparse\n\nimport docker\nfrom docker.errors import APIError\nfrom docker.types import Mount\nfrom docker.utils import kwargs_from_env\nfrom escapism import escape\nfrom jupyterhub.spawner import Spawner\nfrom jupyterhub.traitlets import ByteSpecification, Callable\nfrom tornado import web\nfrom traitlets import (\n    Any,\n    Bool,\n    CaselessStrEnum,\n    Dict,\n    Float,\n    Int,\n    List,\n    Unicode,\n    Union,\n    default,\n    observe,\n    validate,\n)\n\nfrom .volumenamingstrategy import default_format_volume_name\n\n\nclass UnicodeOrFalse(Unicode):\n    info_text = \"a unicode string or False\"\n\n    def validate(self, obj, value):\n        if value is False:\n            return value\n\n        return super().validate(obj, value)\n\n\nimport jupyterhub\n\n_jupyterhub_xy = \"%i.%i\" % (jupyterhub.version_info[:2])\n\n\ndef _deep_merge(dest, src):\n    \"\"\"Merge dict `src` into `dest`, recursively\n\n    Modifies `dest` in-place, returns dest\n    \"\"\"\n    for key, value in src.items():\n        if key in dest:\n            dest_value = dest[key]\n            if isinstance(dest_value, dict) and isinstance(value, dict):\n                dest[key] = _deep_merge(dest_value, value)\n            else:\n                dest[key] = value\n        else:\n            dest[key] = value\n\n    return dest\n\n\nclass DockerSpawner(Spawner):\n    \"\"\"A Spawner for JupyterHub that runs each user's server in a separate docker container\"\"\"\n\n    def _eval_if_callable(self, x):\n        \"\"\"Evaluate x if it is callable\n\n        Or return x otherwise\n        \"\"\"\n        if callable(x):\n            return x(self)\n        return x\n\n    _executor = None\n\n    _deprecated_aliases = {\n        \"container_ip\": (\"host_ip\", \"0.9.*\"),\n        \"container_port\": (\"port\", \"0.9.*\"),\n        \"container_image\": (\"image\", \"0.9.*\"),\n        \"container_prefix\": (\"prefix\", \"0.10.0\"),\n        \"container_name_template\": (\"name_template\", \"0.10.0*\"),\n        \"remove_containers\": (\"remove\", \"0.10.0\"),\n        \"image_whitelist\": (\"allowed_images\", \"12.0\"),\n    }\n\n    @observe(*list(_deprecated_aliases))\n    def _deprecated_trait(self, change):\n        \"\"\"observer for deprecated traits\"\"\"\n        old_attr = change.name\n        new_attr, version = self._deprecated_aliases.get(old_attr)\n        new_value = getattr(self, new_attr)\n        if new_value != change.new:\n            # only warn if different\n            # protects backward-compatible config from warnings\n            # if they set the same value under both names\n            self.log.warning(\n                \"{cls}.{old} is deprecated in DockerSpawner {version}, use {cls}.{new} instead\".format(\n                    cls=self.__class__.__name__,\n                    old=old_attr,\n                    new=new_attr,\n                    version=version,\n                )\n            )\n            setattr(self, new_attr, change.new)\n\n    @property\n    def executor(self):\n        \"\"\"single global executor\"\"\"\n        cls = self.__class__\n        if cls._executor is None:\n            cls._executor = ThreadPoolExecutor(1)\n        return cls._executor\n\n    _client = None\n\n    @property\n    def client(self):\n        \"\"\"single global client instance\"\"\"\n        cls = self.__class__\n        if cls._client is None:\n            kwargs = {\"version\": \"auto\"}\n            if self.tls_config:\n                kwargs[\"tls\"] = docker.tls.TLSConfig(**self.tls_config)\n            kwargs.update(kwargs_from_env())\n            kwargs.update(self.client_kwargs)\n            client = docker.APIClient(**kwargs)\n            cls._client = client\n        return cls._client\n\n    @default(\"cmd\")\n    def _default_cmd(self):\n        # no default means use the image command\n        return None\n\n    object_id = Unicode()\n    # the type of object we create\n    object_type = \"container\"\n    # the field containing the object id\n    object_id_key = \"Id\"\n\n    @property\n    def container_id(self):\n        \"\"\"alias for object_id\"\"\"\n        return self.object_id\n\n    @property\n    def container_name(self):\n        \"\"\"alias for object_name\"\"\"\n        return self.object_name\n\n    # deprecate misleading container_ip, since\n    # it is not the ip in the container,\n    # but the host ip of the port forwarded to the container\n    # when use_internal_ip is False\n    container_ip = Unicode(\n        \"127.0.0.1\", help=\"Deprecated, use ``DockerSpawner.host_ip``\", config=True\n    )\n\n    host_ip = Unicode(\n        \"127.0.0.1\",\n        help=\"\"\"The ip address on the host on which to expose the container's port\n\n        Typically 127.0.0.1, but can be public interfaces as well\n        in cases where the Hub and/or proxy are on different machines\n        from the user containers.\n\n        Only used when ``use_internal_ip = False``.\n        \"\"\",\n        config=True,\n    )\n\n    @default('host_ip')\n    def _default_host_ip(self):\n        docker_host = os.getenv('DOCKER_HOST')\n        if docker_host:\n            urlinfo = urlparse(docker_host)\n            if urlinfo.scheme == 'tcp':\n                return urlinfo.hostname\n        return '127.0.0.1'\n\n    # unlike container_ip, container_port is the internal port\n    # on which the server is bound.\n    container_port = Int(\n        8888,\n        min=1,\n        max=65535,\n        help=\"Deprecated, use ``DockerSpawner.port``.\",\n        config=True,\n    )\n\n    # fix default port to 8888, used in the container\n\n    @default(\"port\")\n    def _port_default(self):\n        return 8888\n\n    # default to listening on all-interfaces in the container\n\n    @default(\"ip\")\n    def _ip_default(self):\n        return \"0.0.0.0\"\n\n    container_image = Unicode(\n        \"quay.io/jupyterhub/singleuser:%s\" % _jupyterhub_xy,\n        help=\"Deprecated, use ``DockerSpawner.image``.\",\n        config=True,\n    )\n\n    image = Unicode(\n        \"quay.io/jupyterhub/singleuser:%s\" % _jupyterhub_xy,\n        config=True,\n        help=\"\"\"The image to use for single-user servers.\n\n        This image should have the same version of jupyterhub as\n        the Hub itself installed.\n\n        If the default command of the image does not launch\n        jupyterhub-singleuser, set ``c.Spawner.cmd`` to\n        launch jupyterhub-singleuser, e.g.\n\n        Any of the jupyter docker-stacks should work without additional config,\n        as long as the version of jupyterhub in the image is compatible.\n        \"\"\",\n    )\n\n    image_whitelist = Union(\n        [Any(), Dict(), List()],\n        help=\"Deprecated, use ``DockerSpawner.allowed_images``.\",\n        config=True,\n    )\n\n    allowed_images = Union(\n        [Any(), Dict(), List()],\n        default_value={},\n        config=True,\n        help=\"\"\"\n        List or dict of images that users can run.\n\n        If specified, users will be presented with a form\n        from which they can select an image to run.\n\n        If a dictionary, the keys will be the options presented to users\n        and the values the actual images that will be launched.\n\n        If a list, will be cast to a dictionary where keys and values are the same\n        (i.e. a shortcut for presenting the actual images directly to users).\n\n        If a callable, will be called with the Spawner instance as its only argument.\n        The user is accessible as spawner.user.\n        The callable should return a dict or list as above.\n\n        .. versionchanged:: 12.0\n            ``DockerSpawner.image_whitelist`` renamed to ``allowed_images``\n\n        \"\"\",\n    )\n\n    @validate('allowed_images')\n    def _allowed_images_dict(self, proposal):\n        \"\"\"cast allowed_images to a dict\n\n        If passing a list, cast it to a {item:item}\n        dict where the keys and values are the same.\n        \"\"\"\n        allowed_images = proposal.value\n        if isinstance(allowed_images, list):\n            allowed_images = {item: item for item in allowed_images}\n        return allowed_images\n\n    def _get_allowed_images(self):\n        \"\"\"Evaluate allowed_images callable\n\n        Or return the list as-is if it's already a dict\n        \"\"\"\n        if callable(self.allowed_images):\n            allowed_images = self.allowed_images(self)\n            if not isinstance(allowed_images, dict):\n                # always return a dict\n                allowed_images = {item: item for item in allowed_images}\n            return allowed_images\n        return self.allowed_images\n\n    @default('options_form')\n    def _default_options_form(self):\n        allowed_images = self._get_allowed_images()\n        if len(allowed_images) <= 1:\n            # default form only when there are images to choose from\n            return ''\n        # form derived from wrapspawner.ProfileSpawner\n        option_t = '<option value=\"{image}\" {selected}>{image}</option>'\n        options = [\n            option_t.format(\n                image=image, selected='selected' if image == self.image else ''\n            )\n            for image in allowed_images\n        ]\n        return \"\"\"\n        <label for=\"image\">Select an image:</label>\n        <select class=\"form-control\" name=\"image\" required autofocus>\n        {options}\n        </select>\n        \"\"\".format(\n            options=options\n        )\n\n    def options_from_form(self, formdata):\n        \"\"\"Turn options formdata into user_options\"\"\"\n        options = {}\n        if 'image' in formdata:\n            options['image'] = formdata['image'][0]\n        return options\n\n    pull_policy = CaselessStrEnum(\n        [\"always\", \"ifnotpresent\", \"never\", \"skip\"],\n        default_value=\"ifnotpresent\",\n        config=True,\n        help=\"\"\"The policy for pulling the user docker image.\n\n        Choices:\n\n        - ifnotpresent: pull if the image is not already present (default)\n        - always: always pull the image to check for updates,\n          even if it is present\n        - never: never perform a pull, raise if image is not present\n        - skip: never perform a pull, skip the step entirely\n          (like never, but without raising when images are not present;\n          default for swarm)\n\n        .. versionadded: 12.0\n            'skip' option added. It is the default for swarm\n            because pre-pulling images on swarm clusters\n            doesn't make sense since the container is likely not\n            going to run on the same node where the image was pulled.\n        \"\"\",\n    )\n\n    container_prefix = Unicode(\n        config=True, help=\"Deprecated, use ``DockerSpawner.prefix``.\"\n    )\n\n    container_name_template = Unicode(\n        config=True, help=\"Deprecated, use ``DockerSpawner.name_template``.\"\n    )\n\n    prefix = Unicode(\n        \"jupyter\",\n        config=True,\n        help=dedent(\n            \"\"\"\n            Prefix for container names. See name_template for full container name for a particular\n            user's server.\n            \"\"\"\n        ),\n    )\n\n    name_template = Unicode(\n        config=True,\n        help=dedent(\n            \"\"\"\n            Name of the container or service: with {username}, {imagename}, {prefix}, {servername} replacements.\n            {raw_username} can be used for the original, not escaped username\n            (may contain uppercase, special characters).\n            It is important to include {servername} if JupyterHub's \"named\n            servers\" are enabled (``JupyterHub.allow_named_servers = True``).\n            If the server is named, the default name_template is\n            \"{prefix}-{username}--{servername}\". If it is unnamed, the default\n            name_template is \"{prefix}-{username}\".\n\n            Note: when using named servers,\n            it is important that the separator between {username} and {servername}\n            is not a character that can occur in an escaped {username},\n            and also not the single escape character '-'.\n            \"\"\"\n        ),\n    )\n\n    @default('name_template')\n    def _default_name_template(self):\n        if self.name:\n            return \"{prefix}-{username}--{servername}\"\n        else:\n            return \"{prefix}-{username}\"\n\n    client_kwargs = Dict(\n        config=True,\n        help=\"Extra keyword arguments to pass to the docker.Client constructor.\",\n    )\n\n    volumes = Dict(\n        config=True,\n        help=dedent(\n            \"\"\"\n            Map from host file/directory to container (guest) file/directory\n            mount point and (optionally) a mode. When specifying the\n            guest mount point (bind) for the volume, you may use a\n            dict or str. If a str, then the volume will default to a\n            read-write (mode=\"rw\"). With a dict, the bind is\n            identified by \"bind\" and the \"mode\" may be one of \"rw\"\n            (default), \"ro\" (read-only), \"z\" (public/shared SELinux\n            volume label), and \"Z\" (private/unshared SELinux volume\n            label).\n\n            If format_volume_name is not set,\n            default_format_volume_name is used for naming volumes.\n            In this case, if you use {username} in either the host or guest\n            file/directory path, it will be replaced with the current\n            user's name.\n            \"\"\"\n        ),\n    )\n\n    mounts = List(\n        config=True,\n        help=dedent(\n            \"\"\"\n            List of dict with keys to match docker.types.Mount for more advanced\n            configuration of mouted volumes.  As with volumes, if the default\n            format_volume_name is in use, you can use {username} in the source or\n            target paths, and it will be replaced with the current user's name.\n            \"\"\"\n        ),\n    )\n\n    move_certs_image = Unicode(\n        \"busybox:1.30.1\",\n        config=True,\n        help=\"\"\"The image used to stage internal SSL certificates.\n\n        Busybox is used because we just need an empty container\n        that waits while we stage files into the volume via .put_archive.\n        \"\"\",\n    )\n\n    async def move_certs(self, paths):\n        self.log.info(\"Staging internal ssl certs for %s\", self._log_name)\n        await self.pull_image(self.move_certs_image)\n        # create the volume\n        volume_name = self.format_volume_name(self.certs_volume_name, self)\n        # create volume passes even if it already exists\n        self.log.info(\"Creating ssl volume %s for %s\", volume_name, self._log_name)\n        await self.docker('create_volume', volume_name)\n\n        # create a tar archive of the internal cert files\n        # docker.put_archive takes a tarfile and a running container\n        # and unpacks the archive into the container\n        nb_paths = {}\n        tar_buf = BytesIO()\n        archive = TarFile(fileobj=tar_buf, mode='w')\n        for key, hub_path in paths.items():\n            fname = os.path.basename(hub_path)\n            nb_paths[key] = '/certs/' + fname\n            with open(hub_path, 'rb') as f:\n                content = f.read()\n            tarinfo = TarInfo(name=fname)\n            tarinfo.size = len(content)\n            tarinfo.mtime = os.stat(hub_path).st_mtime\n            tarinfo.mode = 0o644\n            archive.addfile(tarinfo, BytesIO(content))\n        archive.close()\n        tar_buf.seek(0)\n\n        # run a container to stage the certs,\n        # mounting the volume at /certs/\n        host_config = self.client.create_host_config(\n            binds={\n                volume_name: {\"bind\": \"/certs\", \"mode\": \"rw\"},\n            },\n        )\n        container = await self.docker(\n            'create_container',\n            self.move_certs_image,\n            volumes=[\"/certs\"],\n            host_config=host_config,\n        )\n\n        container_id = container['Id']\n        self.log.debug(\n            \"Container %s is creating ssl certs for %s\",\n            container_id[:12],\n            self._log_name,\n        )\n        # start the container\n        await self.docker('start', container_id)\n        # stage the archive to the container\n        try:\n            await self.docker(\n                'put_archive',\n                container=container_id,\n                path='/certs',\n                data=tar_buf,\n            )\n        finally:\n            await self.docker('remove_container', container_id)\n        return nb_paths\n\n    certs_volume_name = Unicode(\n        \"{prefix}ssl-{username}\",\n        config=True,\n        help=\"\"\"Volume name\n\n        The same string-templating applies to this\n        as other volume names.\n        \"\"\",\n    )\n\n    read_only_volumes = Dict(\n        config=True,\n        help=dedent(\n            \"\"\"\n            Map from host file/directory to container file/directory.\n            Volumes specified here will be read-only in the container.\n\n            If format_volume_name is not set,\n            default_format_volume_name is used for naming volumes.\n            In this case, if you use {username} in either the host or guest\n            file/directory path, it will be replaced with the current\n            user's name.\n            \"\"\"\n        ),\n    )\n\n    format_volume_name = Any(\n        help=\"\"\"Any callable that accepts a string template and a DockerSpawner instance as parameters in that order and returns a string.\n\n        Reusable implementations should go in dockerspawner.VolumeNamingStrategy, tests should go in ...\n        \"\"\"\n    ).tag(config=True)\n\n    @default(\"format_volume_name\")\n    def _get_default_format_volume_name(self):\n        return default_format_volume_name\n\n    use_docker_client_env = Bool(\n        True,\n        config=True,\n        help=\"Deprecated. Docker env variables are always used if present.\",\n    )\n\n    @observe(\"use_docker_client_env\")\n    def _client_env_changed(self):\n        self.log.warning(\n            \"DockerSpawner.use_docker_client_env is deprecated and ignored.\"\n            \"  Docker environment variables are always used if defined.\"\n        )\n\n    tls_config = Dict(\n        config=True,\n        help=\"\"\"Arguments to pass to docker TLS configuration.\n\n        See docker.client.TLSConfig constructor for options.\n        \"\"\",\n    )\n    tls = tls_verify = tls_ca = tls_cert = tls_key = tls_assert_hostname = Any(\n        config=True,\n        help=\"\"\"Deprecated, use ``DockerSpawner.tls_config`` dict to set any TLS options.\"\"\",\n    )\n\n    @observe(\n        \"tls\", \"tls_verify\", \"tls_ca\", \"tls_cert\", \"tls_key\", \"tls_assert_hostname\"\n    )\n    def _tls_changed(self, change):\n        self.log.warning(\n            \"%s config ignored, use %s.tls_config dict to set full TLS configuration.\",\n            change.name,\n            self.__class__.__name__,\n        )\n\n    remove_containers = Bool(\n        False, config=True, help=\"Deprecated, use ``DockerSpawner.remove``.\"\n    )\n\n    remove = Bool(\n        False,\n        config=True,\n        help=\"\"\"\n        If ``True``, delete containers when servers are stopped.\n\n        This will destroy any data in the container not stored in mounted volumes.\n        \"\"\",\n    )\n\n    @property\n    def will_resume(self):\n        # indicate that we will resume,\n        # so JupyterHub >= 0.7.1 won't cleanup our API token\n        return not self.remove\n\n    extra_create_kwargs = Union(\n        [Callable(), Dict()],\n        config=True,\n        help=\"\"\"Additional args to pass for container create\n\n        For example, to change the user the container is started as::\n\n            c.DockerSpawner.extra_create_kwargs = {\n                \"user\": \"root\" # Can also be an integer UID\n            }\n\n        The above is equivalent to ``docker run --user root``.\n\n        If a callable, will be called with the Spawner as the only argument,\n        must return the same dictionary structure, and may be async.\n\n        .. versionchanged:: 13\n\n            Added callable support.\n        \"\"\",\n    )\n    extra_host_config = Union(\n        [Callable(), Dict()],\n        config=True,\n        help=\"\"\"\n        Additional args to create_host_config for container create.\n\n        If a callable, will be called with the Spawner as the only argument,\n        must return the same dictionary structure, and may be async.\n\n        .. versionchanged:: 13\n\n            Added callable support.\n        \"\"\",\n    )\n\n    escape = Any(\n        help=\"\"\"Override escaping with any callable of the form escape(str)->str\n\n        This is used to ensure docker-safe container names, etc.\n\n        The default escaping should ensure safety and validity,\n        but can produce cumbersome strings in cases.\n\n        Set c.DockerSpawner.escape = 'legacy' to preserve the earlier, unsafe behavior\n        if it worked for you.\n\n        .. versionadded:: 12.0\n\n        .. versionchanged:: 12.0\n            Escaping has changed in 12.0 to ensure safety,\n            but existing deployments will get different container and volume names.\n        \"\"\",\n        config=True,\n    )\n\n    @default(\"escape\")\n    def _escape_default(self):\n        return self._escape\n\n    @validate(\"escape\")\n    def _validate_escape(self, proposal):\n        escape = proposal.value\n        if escape == \"legacy\":\n            return self._legacy_escape\n        if not callable(escape):\n            raise ValueError(\"DockerSpawner.escape must be callable, got %r\" % escape)\n        return escape\n\n    @staticmethod\n    def _escape(text):\n        # Make sure a substring matches the restrictions for DNS labels\n        # Note: '-' cannot be in safe_chars, as it is being used as escape character\n        # any '-' must be escaped to '-2d' to avoid collisions\n        safe_chars = set(string.ascii_lowercase + string.digits)\n        return escape(text, safe_chars, escape_char='-').lower()\n\n    @staticmethod\n    def _legacy_escape(text):\n        \"\"\"Legacy implementation of escape\n\n        Select with config c.DockerSpawner.escape = 'legacy'\n\n        Unsafe and doesn't work in all cases,\n        but allows opt-in to backward compatibility for an upgrading deployment.\n\n        Do not use for new deployments.\n        \"\"\"\n        safe_chars = set(string.ascii_letters + string.digits + \"-\")\n        return escape(text, safe_chars, escape_char='_')\n\n    hub_ip_connect = Unicode(\n        config=True,\n        help=\"DEPRECATED since JupyterHub 0.8. Use c.JupyterHub.hub_connect_ip.\",\n    )\n\n    @observe(\"hub_ip_connect\")\n    def _ip_connect_changed(self, change):\n        self.log.warning(\n            f\"Ignoring DockerSpawner.hub_ip_connect={change.new!r}, which has ben deprected since JupyterHub 0.8. Use c.JupyterHub.hub_connect_ip instead.\"\n        )\n\n    use_internal_ip = Bool(\n        False,\n        config=True,\n        help=dedent(\n            \"\"\"\n            Enable the usage of the internal docker ip. This is useful if you are running\n            jupyterhub (as a container) and the user containers within the same docker network.\n            E.g. by mounting the docker socket of the host into the jupyterhub container.\n            Default is ``True`` if using a docker network, ``False`` if bridge or host networking is used.\n            \"\"\"\n        ),\n    )\n\n    @default(\"use_internal_ip\")\n    def _default_use_ip(self):\n        # setting network_name to something other than bridge or host implies use_internal_ip\n        if self.network_name not in {\"bridge\", \"host\"}:\n            return True\n\n        else:\n            return False\n\n    use_internal_hostname = Bool(\n        False,\n        config=True,\n        help=dedent(\n            \"\"\"\n            Use the docker hostname for connecting.\n\n            instead of an IP address.\n            This should work in general when using docker networks,\n            and must be used when internal_ssl is enabled.\n            It is enabled by default if internal_ssl is enabled.\n            \"\"\"\n        ),\n    )\n\n    @default(\"use_internal_hostname\")\n    def _default_use_hostname(self):\n        # FIXME: replace getattr with self.internal_ssl\n        # when minimum jupyterhub is 1.0\n        return getattr(self, 'internal_ssl', False)\n\n    links = Dict(\n        config=True,\n        help=dedent(\n            \"\"\"\n            Specify docker link mapping to add to the container, e.g.\n\n                links = {'jupyterhub': 'jupyterhub'}\n\n            If the Hub is running in a Docker container,\n            this can simplify routing because all traffic will be using docker hostnames.\n            \"\"\"\n        ),\n    )\n\n    network_name = Unicode(\n        \"bridge\",\n        config=True,\n        help=dedent(\n            \"\"\"\n            Run the containers on this docker network.\n            If it is an internal docker network, the Hub should be on the same network,\n            as internal docker IP addresses will be used.\n            For bridge networking, external ports will be bound.\n            \"\"\"\n        ),\n    )\n\n    post_start_cmd = UnicodeOrFalse(\n        False,\n        config=True,\n        help=\"\"\"If specified, the command will be executed inside the container\n        after starting.\n        Similar to using 'docker exec'\n        \"\"\",\n    )\n\n    async def post_start_exec(self):\n        \"\"\"\n        Execute additional command inside the container after starting it.\n\n        e.g. calling 'docker exec'\n        \"\"\"\n\n        container = await self.get_object()\n        container_id = container[self.object_id_key]\n\n        exec_kwargs = {'cmd': self.post_start_cmd, 'container': container_id}\n        self.log.debug(\n            f\"Running post_start exec in {self.object_name}: {self.post_start_cmd}\"\n        )\n\n        exec_id = await self.docker(\"exec_create\", **exec_kwargs)\n\n        stdout, stderr = await self.docker(\"exec_start\", exec_id=exec_id, demux=True)\n\n        # docker-py uses None for empty output instead of empty bytestring\n        if stdout is None:\n            stdout = b''\n\n        # stderr is usually None instead of empty b''\n        # this includes error conditions like \"OCI runtime exec failed...\"\n        # but also most successful runs\n        if stderr is None:\n            # crude check for \"OCI runtime exec failed: ...\"\n            # switch message to stderr instead of stdout for warning-level output\n            if b'exec failed' in stdout:\n                stderr = stdout\n                stdout = b''\n            else:\n                stderr = b''\n\n        for name, stream, level in [\n            (\"stdout\", stdout, \"debug\"),\n            (\"stderr\", stderr, \"warning\"),\n        ]:\n            output = stream.decode(\"utf8\", \"replace\").strip()\n            if not output:\n                continue\n\n            if '\\n' in output:\n                # if multi-line, wrap to new line and indent\n                output = '\\n' + output\n                output = indent(output, \"    \")\n            log = getattr(self.log, level)\n            log(f\"post_start {name} in {self.object_name}: {output}\")\n\n    @property\n    def tls_client(self):\n        \"\"\"A tuple consisting of the TLS client certificate and key if they\n        have been provided, otherwise None.\n\n        \"\"\"\n        if self.tls_cert and self.tls_key:\n            return (self.tls_cert, self.tls_key)\n\n        return None\n\n    @property\n    def volume_mount_points(self):\n        \"\"\"\n        Volumes are declared in docker-py in two stages.  First, you declare\n        all the locations where you're going to mount volumes when you call\n        create_container.\n\n        Returns a sorted list of all the values in self.volumes or\n        self.read_only_volumes.\n        \"\"\"\n        return sorted([value[\"bind\"] for value in self.volume_binds.values()])\n\n    @property\n    def volume_binds(self):\n        \"\"\"\n        The second half of declaring a volume with docker-py happens when you\n        actually call start(). The required format is a dict of dicts that\n        looks like::\n\n            {\n                host_location: {'bind': container_location, 'mode': 'rw'}\n            }\n\n        Mode may be 'ro', 'rw', 'z', or 'Z'.\n        \"\"\"\n        binds = self._volumes_to_binds(self.volumes, {})\n        read_only_volumes = {}\n        # FIXME: replace getattr with self.internal_ssl\n        # when minimum jupyterhub is 1.0\n        if getattr(self, 'internal_ssl', False):\n            # add SSL volume as read-only\n            read_only_volumes[self.certs_volume_name] = '/certs'\n        read_only_volumes.update(self.read_only_volumes)\n        return self._volumes_to_binds(read_only_volumes, binds, mode=\"ro\")\n\n    @property\n    def mount_binds(self):\n        \"\"\"\n        A different way of specifying docker volumes using more advanced spec.\n        Converts mounts list of dict to a list of docker.types.Mount\n        \"\"\"\n\n        def _fmt(v):\n            return self.format_volume_name(v, self)\n\n        mounts = []\n        for mount in self.mounts:\n            args = dict(mount)\n            args[\"source\"] = _fmt(mount[\"source\"])\n            args[\"target\"] = _fmt(mount[\"target\"])\n            mounts.append(Mount(**args))\n        return mounts\n\n    _escaped_name = None\n\n    @property\n    def escaped_name(self):\n        \"\"\"Escape the username so it's safe for docker objects\"\"\"\n        if self._escaped_name is None:\n            self._escaped_name = self.escape(self.user.name)\n        return self._escaped_name\n\n    object_id = Unicode(allow_none=True)\n\n    def template_namespace(self):\n        escaped_image = self.image.replace(\"/\", \"-\").replace(\":\", \"-\")\n        server_name = getattr(self, \"name\", \"\")\n        safe_server_name = self.escape(server_name.lower())\n        return {\n            \"username\": self.escaped_name,\n            \"safe_username\": self.escaped_name,\n            \"raw_username\": self.user.name,\n            \"imagename\": escaped_image,\n            \"servername\": safe_server_name,\n            \"raw_servername\": server_name,\n            \"prefix\": self.prefix,\n        }\n\n    object_name = Unicode()\n\n    @default(\"object_name\")\n    def _object_name_default(self):\n        \"\"\"Render the name of our container/service using name_template\"\"\"\n        return self._render_templates(self.name_template)\n\n    @observe(\"image\")\n    def _image_changed(self, change):\n        # re-render object name if image changes\n        self.object_name = self._object_name_default()\n\n    def load_state(self, state):\n        super().load_state(state)\n        if \"container_id\" in state:\n            # backward-compatibility for dockerspawner < 0.10\n            self.object_id = state.get(\"container_id\")\n        else:\n            self.object_id = state.get(\"object_id\", \"\")\n\n        # override object_name from state if defined\n        # to avoid losing track of running servers\n        self.object_name = state.get(\"object_name\", None) or self.object_name\n\n        if self.object_id:\n            self.log.debug(\n                f\"Loaded state for {self._log_name}: {self.object_type}\"\n                f\" name={self.object_name}, id={self.object_id}\"\n            )\n\n    def get_state(self):\n        state = super().get_state()\n        if self.object_id:\n            state[\"object_id\"] = self.object_id\n            # persist object_name if running\n            # so that a change in the template doesn't lose track of running servers\n            state[\"object_name\"] = self.object_name\n            self.log.debug(\n                f\"Persisting state for {self._log_name}: {self.object_type}\"\n                f\" name={self.object_name}, id={self.object_id}\"\n            )\n        return state\n\n    def _env_keep_default(self):\n        \"\"\"Don't inherit any env from the parent process\"\"\"\n        return []\n\n    def get_env(self):\n        env = super().get_env()\n        env['JUPYTER_IMAGE_SPEC'] = self.image\n        return env\n\n    def _docker(self, method, *args, **kwargs):\n        \"\"\"wrapper for calling docker methods\n\n        to be passed to ThreadPoolExecutor\n        \"\"\"\n        m = getattr(self.client, method)\n        return m(*args, **kwargs)\n\n    def docker(self, method, *args, **kwargs):\n        \"\"\"Call a docker method in a background thread\n\n        returns a Future\n        \"\"\"\n        return asyncio.wrap_future(\n            self.executor.submit(self._docker, method, *args, **kwargs)\n        )\n\n    async def poll(self):\n        \"\"\"Check for my id in ``docker ps``\"\"\"\n        container = await self.get_object()\n        if not container:\n            self.log.warning(\"Container not found: %s\", self.container_name)\n            return 0\n\n        container_state = container[\"State\"]\n        self.log.debug(\n            \"Container %s status: %s\", self.container_id[:7], pformat(container_state)\n        )\n\n        if container_state[\"Running\"]:\n            return None\n\n        else:\n            return (\n                \"ExitCode={ExitCode}, \"\n                \"Error='{Error}', \"\n                \"FinishedAt={FinishedAt}\".format(**container_state)\n            )\n\n    async def get_object(self):\n        self.log.debug(\"Getting %s '%s'\", self.object_type, self.object_name)\n        try:\n            obj = await self.docker(\"inspect_%s\" % self.object_type, self.object_name)\n            self.object_id = obj[self.object_id_key]\n        except APIError as e:\n            if e.response.status_code == 404:\n                self.log.info(\n                    \"%s '%s' is gone\", self.object_type.title(), self.object_name\n                )\n                obj = None\n                # my container is gone, forget my id\n                self.object_id = \"\"\n            elif e.response.status_code == 500:\n                self.log.info(\n                    \"%s '%s' is on unhealthy node\",\n                    self.object_type.title(),\n                    self.object_name,\n                )\n                obj = None\n                # my container is unhealthy, forget my id\n                self.object_id = \"\"\n            else:\n                raise\n\n        return obj\n\n    async def get_command(self):\n        \"\"\"Get the command to run (full command + args)\"\"\"\n        if self.cmd:\n            cmd = self.cmd\n        else:\n            image_info = await self.docker(\"inspect_image\", self.image)\n            cmd = image_info[\"Config\"][\"Cmd\"]\n        return cmd + self.get_args()\n\n    async def remove_object(self):\n        self.log.info(\"Removing %s %s\", self.object_type, self.object_id)\n        # remove the container, as well as any associated volumes\n        try:\n            await self.docker(\"remove_\" + self.object_type, self.object_id, v=True)\n        except docker.errors.APIError as e:\n            if e.status_code == 409:\n                self.log.debug(\n                    \"Already removing %s: %s\", self.object_type, self.object_id\n                )\n            elif e.status_code == 404:\n                self.log.debug(\n                    \"Already removed %s: %s\", self.object_type, self.object_id\n                )\n            else:\n                raise\n\n    async def check_allowed(self, image):\n        allowed_images = self._get_allowed_images()\n        if not allowed_images:\n            return image\n        if image not in allowed_images:\n            raise web.HTTPError(\n                400,\n                \"Image {} not in allowed list: {}\".format(\n                    image, ', '.join(allowed_images)\n                ),\n            )\n        # resolve image alias to actual image name\n        return allowed_images[image]\n\n    @default('ssl_alt_names')\n    def _get_ssl_alt_names(self):\n        return ['DNS:' + self.internal_hostname]\n\n    mem_limit = Union(\n        [Callable(), ByteSpecification()],\n        help=\"\"\"\n        Maximum number of bytes a single-user notebook server is allowed to use.\n        Allows the following suffixes:\n          - K -> Kilobytes\n          - M -> Megabytes\n          - G -> Gigabytes\n          - T -> Terabytes\n        If the single user server tries to allocate more memory than this,\n        it will fail. There is no guarantee that the single-user notebook server\n        will be able to allocate this much memory - only that it can not\n        allocate more than this.\n\n        Alternatively to a string it can also be a callable that takes the spawner as\n        the only argument and returns a string:\n\n        def per_user_mem_limit(spawner):\n            username = spawner.user.name\n            ram_limits = {'alice': '4G', 'bob': '2G'}\n            return ram_limits.get(username, '1G')\n        c.DockerSpawner.mem_limit = per_user_mem_limit\n        \"\"\",\n    ).tag(config=True)\n\n    @validate('mem_limit')\n    def _mem_limit_str(self, proposal):\n        \"\"\"cast mem_limit to a str\"\"\"\n        return self._eval_if_callable(proposal.value)\n\n    cpu_limit = Union(\n        [Callable(), Float(allow_none=True)],\n        help=\"\"\"\n        CPU limit for containers\n\n        Will set cpu_quota = cpu_limit * cpu_period\n\n        The default cpu_period of 100ms will be used,\n        unless overridden in extra_host_config.\n\n        Alternatively to a single float,\n        cpu_limit can also be a callable that takes the spawner as\n        the only argument and returns a float:\n\n        def per_user_cpu_limit(spawner):\n            username = spawner.user.name\n            cpu_limits = {'alice': 2.5, 'bob': 2}\n            return cpu_limits.get(username, 1)\n        c.DockerSpawner.cpu_limit = per_user_cpu_limit\n        \"\"\",\n    ).tag(config=True)\n\n    @validate('cpu_limit')\n    def _cast_cpu_limit(self, proposal):\n        \"\"\"cast cpu_limit to a float if it's callable\"\"\"\n        return self._eval_if_callable(proposal.value)\n\n    async def create_object(self):\n        \"\"\"Create the container/service object\"\"\"\n\n        create_kwargs = dict(\n            image=self.image,\n            environment=self.get_env(),\n            volumes=self.volume_mount_points,\n            name=self.container_name,\n            command=(await self.get_command()),\n        )\n        extra_create_kwargs = self._eval_if_callable(self.extra_create_kwargs)\n        if inspect.isawaitable(extra_create_kwargs):\n            extra_create_kwargs = await extra_create_kwargs\n        extra_create_kwargs = self._render_templates(extra_create_kwargs)\n        extra_host_config = self._eval_if_callable(self.extra_host_config)\n        if inspect.isawaitable(extra_host_config):\n            extra_host_config = await extra_host_config\n        extra_host_config = self._render_templates(extra_host_config)\n\n        # ensure internal port is exposed\n        create_kwargs[\"ports\"] = {\"%i/tcp\" % self.port: None}\n\n        _deep_merge(create_kwargs, extra_create_kwargs)\n\n        # build the dictionary of keyword arguments for host_config\n        host_config = dict(\n            auto_remove=self.remove,\n            binds=self.volume_binds,\n            links=self.links,\n            mounts=self.mount_binds,\n        )\n\n        if getattr(self, \"mem_limit\", None) is not None:\n            host_config[\"mem_limit\"] = self.mem_limit\n\n        if getattr(self, \"cpu_limit\", None) is not None:\n            # docker cpu units are in microseconds\n            # cpu_period default is 100ms\n            # cpu_quota is cpu_period * cpu_limit\n            cpu_period = host_config[\"cpu_period\"] = extra_host_config.get(\n                \"cpu_period\", 100_000\n            )\n            host_config[\"cpu_quota\"] = int(self.cpu_limit * cpu_period)\n\n        if not self.use_internal_ip:\n            host_config[\"port_bindings\"] = {self.port: (self.host_ip,)}\n        _deep_merge(host_config, extra_host_config)\n        host_config.setdefault(\"network_mode\", self.network_name)\n\n        self.log.debug(\"Starting host with config: %s\", host_config)\n\n        host_config = self.client.create_host_config(**host_config)\n        create_kwargs.setdefault(\"host_config\", {}).update(host_config)\n\n        # create the container\n        obj = await self.docker(\"create_container\", **create_kwargs)\n        return obj\n\n    async def start_object(self):\n        \"\"\"Actually start the container/service\n\n        e.g. calling ``docker start``\n        \"\"\"\n        await self.docker(\"start\", self.container_id)\n\n    async def stop_object(self):\n        \"\"\"Stop the container/service\n\n        e.g. calling ``docker stop``. Does not remove the container.\n        \"\"\"\n        try:\n            await self.docker(\"stop\", self.container_id)\n        except APIError as e:\n            if e.status_code == 404:\n                self.log.debug(\n                    \"Already removed %s: %s\", self.object_type, self.object_id\n                )\n                return\n            else:\n                raise\n\n    async def pull_image(self, image):\n        \"\"\"Pull the image, if needed\n\n        - pulls it unconditionally if pull_policy == 'always'\n        - skipped entirely if pull_policy == 'skip' (default for swarm)\n        - otherwise, checks if it exists, and\n          - raises if pull_policy == 'never'\n          - pulls if pull_policy == 'ifnotpresent'\n        \"\"\"\n        if self.pull_policy == \"skip\":\n            self.log.debug(f\"Skipping pull of {image}\")\n            return\n        # docker wants to split repo:tag\n        # the part split(\"/\")[-1] allows having an image from a custom repo\n        # with port but without tag. For example: my.docker.repo:51150/foo would not\n        # pass this test, resulting in image=my.docker.repo:51150/foo and tag=latest\n        if ':' in image.split(\"/\")[-1]:\n            # rsplit splits from right to left, allowing to have a custom image repo with port\n            repo, tag = image.rsplit(':', 1)\n        else:\n            repo = image\n            tag = 'latest'\n\n        if self.pull_policy.lower() == 'always':\n            # always pull\n            self.log.info(\"pulling %s\", image)\n            await self.docker('pull', repo, tag)\n            # done\n            return\n        try:\n            # check if the image is present\n            await self.docker('inspect_image', image)\n        except docker.errors.NotFound:\n            if self.pull_policy == \"never\":\n                # never pull, raise because there is no such image\n                raise\n            elif self.pull_policy == \"ifnotpresent\":\n                # not present, pull it for the first time\n                self.log.info(\"pulling image %s\", image)\n                await self.docker('pull', repo, tag)\n\n    async def start(self):\n        \"\"\"Start the single-user server in a docker container.\n\n        If the container exists and ``c.DockerSpawner.remove`` is ``True``, then\n        the container is removed first. Otherwise, the existing containers\n        will be restarted.\n        \"\"\"\n        # image priority:\n        # 1. user options (from spawn options form)\n        # 2. self.image from config\n        image_option = self.user_options.get('image')\n        if image_option:\n            # save choice in self.image\n            self.image = await self.check_allowed(image_option)\n\n        image = self.image\n        await self.pull_image(image)\n\n        obj = await self.get_object()\n        if obj and self.remove:\n            self.log.warning(\n                \"Removing %s that should have been cleaned up: %s (id: %s)\",\n                self.object_type,\n                self.object_name,\n                self.object_id[:7],\n            )\n            await self.remove_object()\n\n            obj = None\n\n        if obj is None:\n            obj = await self.create_object()\n            self.object_id = obj[self.object_id_key]\n            self.log.info(\n                \"Created %s %s (id: %s) from image %s\",\n                self.object_type,\n                self.object_name,\n                self.object_id[:7],\n                self.image,\n            )\n\n        else:\n            self.log.info(\n                \"Found existing %s %s (id: %s)\",\n                self.object_type,\n                self.object_name,\n                self.object_id[:7],\n            )\n            # Handle re-using API token.\n            # Get the API token from the environment variables\n            # of the running container:\n            for line in obj[\"Config\"][\"Env\"]:\n                if line.startswith((\"JPY_API_TOKEN=\", \"JUPYTERHUB_API_TOKEN=\")):\n                    self.api_token = line.split(\"=\", 1)[1]\n                    break\n\n        # TODO: handle unpause\n        self.log.info(\n            \"Starting %s %s (id: %s)\",\n            self.object_type,\n            self.object_name,\n            self.container_id[:7],\n        )\n\n        # start the container\n        await self.start_object()\n\n        if self.post_start_cmd:\n            await self.post_start_exec()\n\n        ip, port = await self.get_ip_and_port()\n        return (ip, port)\n\n    @property\n    def internal_hostname(self):\n        \"\"\"Return our hostname\n\n        used with internal SSL\n        \"\"\"\n        return self.container_name\n\n    async def get_ip_and_port(self):\n        \"\"\"Queries Docker daemon for container's IP and port.\n\n        If you are using network_mode=host, you will need to override\n        this method as follows::\n\n            async def get_ip_and_port(self):\n                return self.host_ip, self.port\n\n        You will need to make sure host_ip and port\n        are correct, which depends on the route to the container\n        and the port it opens.\n        \"\"\"\n        if self.use_internal_hostname:\n            # internal ssl uses hostnames,\n            # required for domain-name matching with internal SSL\n            # TODO: should we always do this?\n            # are there any cases where internal_ip works\n            # and internal_hostname doesn't?\n            ip = self.internal_hostname\n            port = self.port\n        elif self.use_internal_ip:\n            resp = await self.docker(\"inspect_container\", self.container_id)\n            network_settings = resp[\"NetworkSettings\"]\n            if \"Networks\" in network_settings:\n                ip = self.get_network_ip(network_settings)\n            else:  # Fallback for old versions of docker (<1.9) without network management\n                ip = network_settings[\"IPAddress\"]\n            port = self.port\n        else:\n            resp = await self.docker(\"port\", self.container_id, self.port)\n            if resp is None:\n                raise RuntimeError(\"Failed to get port info for %s\" % self.container_id)\n\n            ip = resp[0][\"HostIp\"]\n            port = int(resp[0][\"HostPort\"])\n\n        if ip == \"0.0.0.0\":\n            ip = urlparse(self.client.base_url).hostname\n            if ip == \"localnpipe\":\n                ip = \"localhost\"\n\n        return ip, port\n\n    def get_network_ip(self, network_settings):\n        networks = network_settings[\"Networks\"]\n        if self.network_name not in networks:\n            raise Exception(\n                \"Unknown docker network '{network}'.\"\n                \" Did you create it with `docker network create <name>`?\".format(\n                    network=self.network_name\n                )\n            )\n\n        network = networks[self.network_name]\n        ip = network[\"IPAddress\"]\n        return ip\n\n    async def stop(self, now=False):\n        \"\"\"Stop the container\n\n        Will remove the container if ``c.DockerSpawner.remove`` is ``True``.\n\n        Consider using pause/unpause when docker-py adds support.\n        \"\"\"\n        self.log.info(\n            \"Stopping %s %s (id: %s)\",\n            self.object_type,\n            self.object_name,\n            self.object_id[:7],\n        )\n        await self.stop_object()\n\n        if self.remove:\n            await self.remove_object()\n            # clear object_id to avoid persisting removed state\n            self.object_id = \"\"\n\n        self.clear_state()\n\n    def _volumes_to_binds(self, volumes, binds, mode=\"rw\"):\n        \"\"\"Extract the volume mount points from volumes property.\n\n        Returns a dict of dict entries of the form::\n\n            {'/host/dir': {'bind': '/guest/dir': 'mode': 'rw'}}\n        \"\"\"\n\n        def _fmt(v):\n            return self.format_volume_name(v, self)\n\n        for k, v in volumes.items():\n            m = mode\n            if isinstance(v, dict):\n                if \"mode\" in v:\n                    m = v[\"mode\"]\n                v = v[\"bind\"]\n            binds[_fmt(k)] = {\"bind\": _fmt(v), \"mode\": m}\n        return binds\n\n    def _render_templates(self, obj, ns=None):\n        \"\"\"Recursively render template strings\n\n        Dives down into dicts, lists, tuples\n        and applies template formatting on all strings found in:\n        - list or tuple items\n        - dict keys or values\n\n        Always returns the original object structure.\n        \"\"\"\n        if ns is None:\n            ns = self.template_namespace()\n\n        _fmt = partial(self._render_templates, ns=ns)\n\n        if isinstance(obj, str):\n            try:\n                return obj.format(**ns)\n            except (ValueError, KeyError):\n                # not a valid format string\n                # to avoid crashing leave invalid templates unrendered\n                # otherwise, this unconditional formatting would not allow\n                # strings with `{` characters in them\n                return obj\n        elif isinstance(obj, dict):\n            return {_fmt(key): _fmt(value) for key, value in obj.items()}\n        elif isinstance(obj, (list, tuple)):\n            return type(obj)([_fmt(item) for item in obj])\n        else:\n            return obj\n\n\ndef _deprecated_method(old_name, new_name, version):\n    \"\"\"Create a deprecated method wrapper for a deprecated method name\"\"\"\n\n    def deprecated(self, *args, **kwargs):\n        warnings.warn(\n            (\n                \"{cls}.{old_name} is deprecated in DockerSpawner {version}.\"\n                \" Please use {cls}.{new_name} instead.\"\n            ).format(\n                cls=self.__class__.__name__,\n                old_name=old_name,\n                new_name=new_name,\n                version=version,\n            ),\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        old_method = getattr(self, new_name)\n        return old_method(*args, **kwargs)\n\n    return deprecated\n\n\n# deprecate white/blacklist method names\nfor _old_name, _new_name, _version in [\n    (\"check_image_whitelist\", \"check_allowed\", \"12.0\")\n]:\n    setattr(\n        DockerSpawner,\n        _old_name,\n        _deprecated_method(_old_name, _new_name, _version),\n    )\n", "# Changes in DockerSpawner\n\nFor detailed changes from the prior release, click on the version number, and\nits link will bring up a GitHub listing of changes. Use `git log` on the\ncommand line for details.\n\n## [Unreleased]\n\n## 13\n\n### [13.0] 2023-11-21\n\n([full changelog](https://github.com/jupyterhub/dockerspawner/compare/12.1.0...13.0.0))\n\n#### API and Breaking Changes\n\n- Remove deprecated, broken hub_ip_connect [#499](https://github.com/jupyterhub/dockerspawner/pull/499) ([@minrk](https://github.com/minrk))\n- Require python 3.8+ and jupyterhub 2.3.1+ [#488](https://github.com/jupyterhub/dockerspawner/pull/488) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n\n#### New features added\n\n- Switch default image to quay.io [#504](https://github.com/jupyterhub/dockerspawner/pull/504) ([@yuvipanda](https://github.com/yuvipanda), [@minrk](https://github.com/minrk), [@manics](https://github.com/manics))\n- allow extra_host_config and extra_create_kwargs to be callable [#500](https://github.com/jupyterhub/dockerspawner/pull/500) ([@minrk](https://github.com/minrk))\n\n#### Enhancements made\n\n- Merge host config/create_kwargs [#501](https://github.com/jupyterhub/dockerspawner/pull/501) ([@minrk](https://github.com/minrk))\n\n#### Bugs fixed\n\n- update object_name with current image [#466](https://github.com/jupyterhub/dockerspawner/pull/466) ([@floriandeboissieu](https://github.com/floriandeboissieu), [@minrk](https://github.com/minrk))\n- Fix imagename not to include letter ':' [#464](https://github.com/jupyterhub/dockerspawner/pull/464) ([@yamaton](https://github.com/yamaton), [@minrk](https://github.com/minrk))\n- clear object_id when removing object [#447](https://github.com/jupyterhub/dockerspawner/pull/447) ([@minrk](https://github.com/minrk), [@manics](https://github.com/manics))\n\n#### Maintenance and upkeep improvements\n\n- pre-commit: add pyupgrade and autoflake, simplify flake8 config [#489](https://github.com/jupyterhub/dockerspawner/pull/489) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n- Require python 3.8+ and jupyterhub 2.3.1+ [#488](https://github.com/jupyterhub/dockerspawner/pull/488) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n- Add dependabot.yaml to bump github actions [#487](https://github.com/jupyterhub/dockerspawner/pull/487) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n- Update release workflow and RELEASE.md, set version with tbump [#486](https://github.com/jupyterhub/dockerspawner/pull/486) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n- Refresh test workflow and associated config, accept podmain test failure for now [#485](https://github.com/jupyterhub/dockerspawner/pull/485) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n- Use python 3.11 on RTD [#482](https://github.com/jupyterhub/dockerspawner/pull/482) ([@minrk](https://github.com/minrk))\n- Add test strategy for JupyterHub v3.1.1 [#479](https://github.com/jupyterhub/dockerspawner/pull/479) ([@Sheila-nk](https://github.com/Sheila-nk), [@GeorgianaElena](https://github.com/GeorgianaElena), [@minrk](https://github.com/minrk))\n- test options_form and escape [#468](https://github.com/jupyterhub/dockerspawner/pull/468) ([@Sheila-nk](https://github.com/Sheila-nk), [@minrk](https://github.com/minrk))\n- test callable allowed_images and host_ip [#467](https://github.com/jupyterhub/dockerspawner/pull/467) ([@Sheila-nk](https://github.com/Sheila-nk), [@minrk](https://github.com/minrk))\n- Test jupyterhub2 [#443](https://github.com/jupyterhub/dockerspawner/pull/443) ([@manics](https://github.com/manics), [@minrk](https://github.com/minrk))\n\n#### Documentation improvements\n\n- Add extra_create_kwargs example, plus docs readability improvements [#493](https://github.com/jupyterhub/dockerspawner/pull/493) ([@matthewwiese](https://github.com/matthewwiese), [@manics](https://github.com/manics))\n- update versions in swarm example [#454](https://github.com/jupyterhub/dockerspawner/pull/454) ([@minrk](https://github.com/minrk), [@GeorgianaElena](https://github.com/GeorgianaElena))\n- add generate-certs service to internal-ssl example [#446](https://github.com/jupyterhub/dockerspawner/pull/446) ([@minrk](https://github.com/minrk), [@manics](https://github.com/manics))\n- Add Podman to docs [#444](https://github.com/jupyterhub/dockerspawner/pull/444) ([@manics](https://github.com/manics), [@minrk](https://github.com/minrk))\n\n#### Contributors to this release\n\nThe following people contributed discussions, new ideas, code and documentation contributions, and review.\nSee [our definition of contributors](https://github-activity.readthedocs.io/en/latest/#how-does-this-tool-define-contributions-in-the-reports).\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/dockerspawner/graphs/contributors?from=2021-07-22&to=2023-11-20&type=c))\n\n@consideRatio ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AconsideRatio+updated%3A2021-07-22..2023-11-20&type=Issues)) | @floriandeboissieu ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Afloriandeboissieu+updated%3A2021-07-22..2023-11-20&type=Issues)) | @gatoniel ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Agatoniel+updated%3A2021-07-22..2023-11-20&type=Issues)) | @GeorgianaElena ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AGeorgianaElena+updated%3A2021-07-22..2023-11-20&type=Issues)) | @manics ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amanics+updated%3A2021-07-22..2023-11-20&type=Issues)) | @matthewwiese ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amatthewwiese+updated%3A2021-07-22..2023-11-20&type=Issues)) | @minrk ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aminrk+updated%3A2021-07-22..2023-11-20&type=Issues)) | @Sheila-nk ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3ASheila-nk+updated%3A2021-07-22..2023-11-20&type=Issues)) | @yamaton ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ayamaton+updated%3A2021-07-22..2023-11-20&type=Issues)) | @yuvipanda ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ayuvipanda+updated%3A2021-07-22..2023-11-20&type=Issues))\n\n## 12\n\n### [12.1] 2021-07-22\n\n([full changelog](https://github.com/jupyterhub/dockerspawner/compare/12.0.0...12.1.0))\n\n#### Enhancements made\n\n- support cpu limit via cpu_quota / cpu_period [#435](https://github.com/jupyterhub/dockerspawner/pull/435) ([@minrk](https://github.com/minrk))\n- Log post_start exec output [#427](https://github.com/jupyterhub/dockerspawner/pull/427) ([@minrk](https://github.com/minrk))\n- Allow to specify a callable for `mem_limit` [#420](https://github.com/jupyterhub/dockerspawner/pull/420) ([@zeehio](https://github.com/zeehio))\n\n#### Maintenance and upkeep improvements\n\n- update release steps for main branch [#434](https://github.com/jupyterhub/dockerspawner/pull/434) ([@minrk](https://github.com/minrk))\n- more debug info from docker when tests fail [#433](https://github.com/jupyterhub/dockerspawner/pull/433) ([@minrk](https://github.com/minrk))\n\n#### Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/dockerspawner/graphs/contributors?from=2021-03-26&to=2021-07-19&type=c))\n\n[@1kastner](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3A1kastner+updated%3A2021-03-26..2021-07-19&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amanics+updated%3A2021-03-26..2021-07-19&type=Issues) | [@minrk](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aminrk+updated%3A2021-03-26..2021-07-19&type=Issues) | [@welcome](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Awelcome+updated%3A2021-03-26..2021-07-19&type=Issues) | [@zeehio](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Azeehio+updated%3A2021-03-26..2021-07-19&type=Issues)\n\n### [12.0] 2021-03-26\n\nThis is a big release!\n\nSeveral bugs have been fixed, especially in SwarmSpawner, and more configuration options added.\n\n#### New escaping scheme\n\nIn particular, the biggest backward-incompatible change to highlight\nis the container (and volume) name escaping scheme now produces DNS-safe results, which matches the behavior of kubespawner.\nThis is a stricter subset of characters than docker containers strictly require,\nbut many features don't work right without it.\nThe result is for certain user names and/or server names, their container and/or volume names will change.\nUpgrading existing deployments will result in disconnecting these users from their running containers and volumes, which means:\n\n- if there are running users across the upgrade,\n  some containers will need to be manually stopped\n- some volumes may need to be renamed, which [docker doesn't support](https://github.com/moby/moby/issues/31154),\n  but [can be done](https://github.com/moby/moby/issues/31154#issuecomment-360531460):\n\n  ```bash\n  docker volume create --name $new_volume\n  docker run --rm -it -v $old_volume:/from -v $new_volume:/to alpine ash -c \"cd /from ; cp -av . /to\"\n  docker volume rm $old_volume\n  ```\n\nThe main differences are:\n\n- The escape character is `-` instead of `_` which means `-` cannot itself be a safe character and must be escaped to `-2d`\n- Uppercase characters are now escaped (normalizing to lowercase at the username level is common)\n\nSo affected usernames are those with `-` or uppercase letters, or any that already needed escaping.\n\nYou can restore the pre-12.0 behavior with:\n\n```python\nc.DockerSpawner.escape = \"legacy\"\n```\n\n#### SystemUserSpawner.run_as_root\n\nAnother security-related change is the addition of `SystemUserSpawner.run_as_root`.\nPrior to 12.0, SystemUserSpawner always ran as root and relied on the container to use $NB_USER and $NB_UID to \"become\" the user.\nThis behavior meant that user containers based on images that lacked this behavior would all run as root.\nTo address this, `run_as_root` behavior is now opt-in\n\nAll changes are detailed below.\n\n([full changelog](https://github.com/jupyterhub/dockerspawner/compare/0.11.1...12.0.0))\n\n#### New features added\n\n- apply template formatting to all of extra_create_kwargs, extra_host_config [#409](https://github.com/jupyterhub/dockerspawner/pull/409) ([@minrk](https://github.com/minrk))\n- Add mounts option for more advanced binds [#406](https://github.com/jupyterhub/dockerspawner/pull/406) ([@minrk](https://github.com/minrk))\n- Add JUPYTER_IMAGE_SPEC to env. [#316](https://github.com/jupyterhub/dockerspawner/pull/316) ([@danielballan](https://github.com/danielballan))\n- Added post_start_cmd [#307](https://github.com/jupyterhub/dockerspawner/pull/307) ([@mohirio](https://github.com/mohirio))\n\n#### Enhancements made\n\n- Use default cmd=None to indicate using the image command [#415](https://github.com/jupyterhub/dockerspawner/pull/415) ([@minrk](https://github.com/minrk))\n- add 'skip' option for pull_policy [#411](https://github.com/jupyterhub/dockerspawner/pull/411) ([@minrk](https://github.com/minrk))\n- Add auto_remove to host_config [#318](https://github.com/jupyterhub/dockerspawner/pull/318) ([@jtpio](https://github.com/jtpio))\n- Make default name_template compatible with named servers. [#315](https://github.com/jupyterhub/dockerspawner/pull/315) ([@danielballan](https://github.com/danielballan))\n- SystemUserSpawner: Pass group id to the container [#304](https://github.com/jupyterhub/dockerspawner/pull/304) ([@zeehio](https://github.com/zeehio))\n- Allow lookup of host homedir via `pwd` [#302](https://github.com/jupyterhub/dockerspawner/pull/302) ([@AdrianoKF](https://github.com/AdrianoKF))\n\n#### Bugs fixed\n\n- (PATCH) SwarmSpawner, InvalidArgument: Incompatible options have been provided for the bind type mount. [#419](https://github.com/jupyterhub/dockerspawner/pull/419) ([@cmotadev](https://github.com/cmotadev))\n- Make sure that create_object() creates the service task [#396](https://github.com/jupyterhub/dockerspawner/pull/396) ([@girgink](https://github.com/girgink))\n- avoid name collisions when using named servers [#386](https://github.com/jupyterhub/dockerspawner/pull/386) ([@minrk](https://github.com/minrk))\n- Fix issue with pulling images from custom repos that contain a port [#334](https://github.com/jupyterhub/dockerspawner/pull/334) ([@raethlein](https://github.com/raethlein))\n\n#### Maintenance and upkeep improvements\n\n- async/await [#417](https://github.com/jupyterhub/dockerspawner/pull/417) ([@minrk](https://github.com/minrk))\n- stop building docs on circleci [#387](https://github.com/jupyterhub/dockerspawner/pull/387) ([@minrk](https://github.com/minrk))\n- Test with latest jh [#379](https://github.com/jupyterhub/dockerspawner/pull/379) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n- Fix RTD build [#378](https://github.com/jupyterhub/dockerspawner/pull/378) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n- Add release instructions and Travis deploy [#377](https://github.com/jupyterhub/dockerspawner/pull/377) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n- Fix tests [#374](https://github.com/jupyterhub/dockerspawner/pull/374) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n- Add README badges [#356](https://github.com/jupyterhub/dockerspawner/pull/356) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n\n#### Documentation improvements\n\n- Update swarm example [#418](https://github.com/jupyterhub/dockerspawner/pull/418) ([@minrk](https://github.com/minrk))\n- improve robustness of internal-ssl example [#416](https://github.com/jupyterhub/dockerspawner/pull/416) ([@minrk](https://github.com/minrk))\n- update versions in docker-image docs [#410](https://github.com/jupyterhub/dockerspawner/pull/410) ([@minrk](https://github.com/minrk))\n- Add GitHub Action readme badge [#408](https://github.com/jupyterhub/dockerspawner/pull/408) ([@consideRatio](https://github.com/consideRatio))\n- Switch CI to GitHub actions [#407](https://github.com/jupyterhub/dockerspawner/pull/407) ([@minrk](https://github.com/minrk))\n- touch up simple example [#405](https://github.com/jupyterhub/dockerspawner/pull/405) ([@minrk](https://github.com/minrk))\n- add example for selecting arbitrary image via options_form [#401](https://github.com/jupyterhub/dockerspawner/pull/401) ([@minrk](https://github.com/minrk))\n- Typo fix in the docs [#380](https://github.com/jupyterhub/dockerspawner/pull/380) ([@jtpio](https://github.com/jtpio))\n- Add docs [#375](https://github.com/jupyterhub/dockerspawner/pull/375) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n- Fix dead link in doc [#350](https://github.com/jupyterhub/dockerspawner/pull/350) ([@JocelynDelalande](https://github.com/JocelynDelalande))\n- Fix project name typo [#339](https://github.com/jupyterhub/dockerspawner/pull/339) ([@kinow](https://github.com/kinow))\n\n#### API and Breaking Changes\n\n- Make escaping DNS-safe [#414](https://github.com/jupyterhub/dockerspawner/pull/414) ([@minrk](https://github.com/minrk))\n- add SystemUserSpawner.run_as_root [#412](https://github.com/jupyterhub/dockerspawner/pull/412) ([@minrk](https://github.com/minrk))\n- Rename DockerSpawner.image_whitelist to allowed_images [#381](https://github.com/jupyterhub/dockerspawner/pull/381) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n\n#### Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/dockerspawner/graphs/contributors?from=2019-04-25&to=2021-03-24&type=c))\n\n[@1kastner](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3A1kastner+updated%3A2019-04-25..2021-03-24&type=Issues) | [@AdrianoKF](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AAdrianoKF+updated%3A2019-04-25..2021-03-24&type=Issues) | [@anmtan](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aanmtan+updated%3A2019-04-25..2021-03-24&type=Issues) | [@AnubhavUjjawal](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AAnubhavUjjawal+updated%3A2019-04-25..2021-03-24&type=Issues) | [@belfhi](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Abelfhi+updated%3A2019-04-25..2021-03-24&type=Issues) | [@bellackn](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Abellackn+updated%3A2019-04-25..2021-03-24&type=Issues) | [@bjornandre](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Abjornandre+updated%3A2019-04-25..2021-03-24&type=Issues) | [@blacksailer](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ablacksailer+updated%3A2019-04-25..2021-03-24&type=Issues) | [@cblomart](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Acblomart+updated%3A2019-04-25..2021-03-24&type=Issues) | [@choldgraf](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Acholdgraf+updated%3A2019-04-25..2021-03-24&type=Issues) | [@cmotadev](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Acmotadev+updated%3A2019-04-25..2021-03-24&type=Issues) | [@cmseal](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Acmseal+updated%3A2019-04-25..2021-03-24&type=Issues) | [@co60ca](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aco60ca+updated%3A2019-04-25..2021-03-24&type=Issues) | [@consideRatio](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AconsideRatio+updated%3A2019-04-25..2021-03-24&type=Issues) | [@cyliu0204](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Acyliu0204+updated%3A2019-04-25..2021-03-24&type=Issues) | [@danielballan](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Adanielballan+updated%3A2019-04-25..2021-03-24&type=Issues) | [@danlester](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Adanlester+updated%3A2019-04-25..2021-03-24&type=Issues) | [@efagerberg](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aefagerberg+updated%3A2019-04-25..2021-03-24&type=Issues) | [@gatoniel](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Agatoniel+updated%3A2019-04-25..2021-03-24&type=Issues) | [@GeorgianaElena](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AGeorgianaElena+updated%3A2019-04-25..2021-03-24&type=Issues) | [@girgink](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Agirgink+updated%3A2019-04-25..2021-03-24&type=Issues) | [@hugoJuhel](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AhugoJuhel+updated%3A2019-04-25..2021-03-24&type=Issues) | [@jameholme](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ajameholme+updated%3A2019-04-25..2021-03-24&type=Issues) | [@jamesdbrock](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ajamesdbrock+updated%3A2019-04-25..2021-03-24&type=Issues) | [@JocelynDelalande](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AJocelynDelalande+updated%3A2019-04-25..2021-03-24&type=Issues) | [@jtpio](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ajtpio+updated%3A2019-04-25..2021-03-24&type=Issues) | [@kinow](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Akinow+updated%3A2019-04-25..2021-03-24&type=Issues) | [@kkr78](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Akkr78+updated%3A2019-04-25..2021-03-24&type=Issues) | [@ltupin](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Altupin+updated%3A2019-04-25..2021-03-24&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amanics+updated%3A2019-04-25..2021-03-24&type=Issues) | [@mathematicalmichael](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amathematicalmichael+updated%3A2019-04-25..2021-03-24&type=Issues) | [@meeseeksmachine](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ameeseeksmachine+updated%3A2019-04-25..2021-03-24&type=Issues) | [@minrk](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aminrk+updated%3A2019-04-25..2021-03-24&type=Issues) | [@missingcharacter](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amissingcharacter+updated%3A2019-04-25..2021-03-24&type=Issues) | [@mohirio](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amohirio+updated%3A2019-04-25..2021-03-24&type=Issues) | [@myurasov](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amyurasov+updated%3A2019-04-25..2021-03-24&type=Issues) | [@nazeels](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Anazeels+updated%3A2019-04-25..2021-03-24&type=Issues) | [@nmvega](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Anmvega+updated%3A2019-04-25..2021-03-24&type=Issues) | [@nuraym](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Anuraym+updated%3A2019-04-25..2021-03-24&type=Issues) | [@parente](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aparente+updated%3A2019-04-25..2021-03-24&type=Issues) | [@raethlein](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Araethlein+updated%3A2019-04-25..2021-03-24&type=Issues) | [@sabuhish](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Asabuhish+updated%3A2019-04-25..2021-03-24&type=Issues) | [@sangramga](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Asangramga+updated%3A2019-04-25..2021-03-24&type=Issues) | [@support](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Asupport+updated%3A2019-04-25..2021-03-24&type=Issues) | [@TimoRoth](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3ATimoRoth+updated%3A2019-04-25..2021-03-24&type=Issues) | [@vlizanae](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Avlizanae+updated%3A2019-04-25..2021-03-24&type=Issues) | [@welcome](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Awelcome+updated%3A2019-04-25..2021-03-24&type=Issues) | [@Wildcarde](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AWildcarde+updated%3A2019-04-25..2021-03-24&type=Issues) | [@willingc](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Awillingc+updated%3A2019-04-25..2021-03-24&type=Issues) | [@wwj718](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Awwj718+updated%3A2019-04-25..2021-03-24&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ayuvipanda+updated%3A2019-04-25..2021-03-24&type=Issues) | [@z3ky](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Az3ky+updated%3A2019-04-25..2021-03-24&type=Issues) | [@zeehio](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Azeehio+updated%3A2019-04-25..2021-03-24&type=Issues) | [@zhiyuli](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Azhiyuli+updated%3A2019-04-25..2021-03-24&type=Issues)\n\n## 0.11\n\n### [0.11.1] - 2019-04-25\n\n- Fix some compatibility issues\n- Add more states to be recognized as pending for SwarmSpawner\n\n### [0.11.0] - 2019-03-01\n\n#### New features:\n\n- Support selecting docker spawner via JupyterHub 1.0's entrypoints:\n\n  ```python\n  c.JupyterHub.spawner_class = 'docker' # or 'docker-swarm' or 'docker-system-user'\n  ```\n\n- Support total internal SSL encryption with JupyterHub 1.0\n- Add new `DockerSpawner.pull_policy` to configure pulling of images.\n  Values are inspired by Kubernetes, and case-insensitive. Can be any of\n  \"IfNotPresent\" (new default), \"Always\", and \"Never\" (pre-0.11 behavior).\n  Now the image will be pulled by default if it is not present.\n- Add `image_whitelist` configuration which, if set, defines a default options\n  form for users to pick the desired image.\n  `image_whitelist` is a dict of `{'descriptive key': 'image:tag'}`.\n- Add `SwarmSpawner.extra_placement_spec` configuration for setting service placement\n\n#### Fixes:\n\n- Slow startup in SwarmSpawner could be treated as failures.\n\n## 0.10\n\n### [0.10.0] - 2018-09-03\n\n- Add `dockerspawner.SwarmSpawner` for spawning with Docker Swarm\n- Removed deprecated `extra_start_kwargs`\n- `host_ip` is configurable\n- Added `container_name_template` configuration for custom container naming\n\n## 0.9\n\n### [0.9.1] - 2017-08-23\n\n- Fix typo which would cause using the deprecated `.hub_ip_connect` configuration\n  with JupyterHub 0.8 to crash instead of warn in 0.9.0.\n\n### [0.9.0] - 2017-08-20\n\n0.9 cleans up some configuration and improves support for the transition from JupyterHub 0.8 to 0.9.\nIt also reduces some of the special arguments and env handling,\nallowing for more consistency with other Spawners,\nand fewer assumptions about the image that will be used by the Spawner.\n\nThe following is a minimal Dockerfile that works with DockerSpawner 0.9 and JupyterHub 0.7.2:\n\n```Dockerfile\nFROM python:3.6\nRUN pip install \\\n    jupyterhub==0.8.0 \\\n    'notebook==5.0.0'\n\n# Don't want to run as root!\nRUN useradd -m jovyan\nENV HOME=/home/jovyan\nWORKDIR $HOME\nUSER jovyan\n\nCMD [\"jupyterhub-singleuser\"]\n```\n\nIn particular:\n\n- any image with the correct version of JupyterHub installed (it should match JupyterHub) should work with DockerSpawner.\n- any image **based on one of the [jupyter/docker-stacks][]** should work with SystemUserSpawner.\n  There is no longer any need for the `jupyterhub/systemuser` docker image.\n- The jupyterhub/singleuser image is now built from the JupyterHub repo, not this one.\n- `jupyterhub/systemuser` image is deprecated.\n  `jupyterhub/systemuser` launches containers as root and relies on\n  the `NB_UID` and `NB_GID` handling of `jupyter/docker-stacks` to setup the user.\n- The default `jupyterhub/singleuser` image has tags for JupyterHub versions,\n  to ensure image compatibility with JupyterHub.\n  The default image is now `jupyterhub/singleuser:x.y`, where `x.y` is the major.minor version of\n  the current JupyterHub instance,\n  so DockerSpawner should work by default with JupyterHub 0.7 or 0.8\n  without needing to specify the image.\n- `Spawner.cmd` config is now supported, which can be used to override the CMD arg.\n  By default, the image's CMD is used.\n- `Spawner.get_args()` behavior is now properly inherited,\n  and args are appended to the spawn command as in other Spawners.\n- Arguments are now passed via `.get_args()` as in the base Spawner,\n  rather than custom environment variables which user images had to support.\n- `DockerSpawner.hub_ip_connect` is deprecated when running with JupyterHub 0.8.\n  Use `JupyterHub.hub_connect_ip` instead, which is used by all Spawners.\n\nSome configuration has been cleaned up to be clearer and more concise:\n\n- `DockerSpawner.container_image` is deprecated in favor of `DockerSpawner.image`.\n- `DockerSpawner.container_port` is deprecated in favor of existing `Spawner.port`.\n- Inaccurately named `DockerSpawner.container_ip` is deprecated in favor of `DockerSpawner.host_ip`\n  because it configures the host IP forwarded to the container.\n\n[jupyter/docker-stacks]: https://github.com/jupyter/docker-stacks\n\n## [0.8] - 2017-07-28\n\n- experimental fixes for running on Windows\n- added `DockerSpawner.client_kwargs` config to passthrough to the `docker.Client` constructor\n- workaround bug where Docker can report ports as strings\n- bump docker dependency to new `docker` package from `docker-py`\n\n## [0.7] - 2017-03-14\n\n- Only need to set `DockerSpawner.network_name` to run on a docker network,\n  instead of setting `host_config`, `network_name`, and `use_internal_ip` separately.\n- Set `mem_limit` on `host_config` for docker API 1.19\n- Match start keyword args on SystemUserSpawner to DockerSpawner\n\n## [0.6] - 2017-01-02\n\n- Add `DockerSpawner.format_volume_name` for custom naming strategies for mounted volumes.\n- Support `mem_limit` config introduced in JupyterHub 0.7.\n- Support `will_resume` flag necessary for resuming containers with\n  `DockerSpawner.remove_containers = False` and JupyterHub 0.7\n  (requires JupyterHub 0.7.1).\n\n## [0.5] - 2016-10-05\n\n- return ip, port from `DockerSpawner.start`, for future-compatibility (setting ip, port directly is deprecated in JupyterHub 0.7).\n- Support `{username}` in volume_mounts\n\n## [0.4] - 2016-06-07\n\n- get singleuser script from jupyterhub 0.6.1 (0.7 will require jupyterhub package to run singleuser script)\n- `get_ip_and_port()` is a tornado coroutine, rather than an asyncio coroutine, for consistency with the rest of the code.\n- more configuration for ports and mounts\n\n## [0.3] - 2016-04-22\n\n- Moved to jupyterhub org (`jupyterhub/singleuser`, `jupyterhub/systemuser` on Docker)\n- Add `rebase-singleuser` tool for building new single-user images on top of different bases\n- Base default docker images on `jupyter/scipy-notebook` from jupyter/docker-stacks\n- Fix environment setup to use `get_env` instead of `_env_default` (Needed for JupyterHub 0.5)\n\n## [0.2] - 2016-02-16\n\n- Add `DockerSpawner.links`\n- Use HostIp from docker port output\n- Make user home string template configurable\n\n## 0.1 - 2016-02-03\n\nFirst release\n\n[unreleased]: https://github.com/jupyterhub/dockerspawner/compare/13.0.0...HEAD\n[13.0]: https://github.com/jupyterhub/dockerspawner/compare/12.1.0...13.0.0\n[12.1]: https://github.com/jupyterhub/dockerspawner/compare/12.0.0...12.1.0\n[12.0]: https://github.com/jupyterhub/dockerspawner/compare/0.11.1...12.0.0\n[0.11.1]: https://github.com/jupyterhub/dockerspawner/compare/0.11.0...0.11.1\n[0.11.0]: https://github.com/jupyterhub/dockerspawner/compare/0.10.0...0.11.0\n[0.10.0]: https://github.com/jupyterhub/dockerspawner/compare/0.9.1...0.10.0\n[0.9.1]: https://github.com/jupyterhub/dockerspawner/compare/0.9.0...0.9.1\n[0.9.0]: https://github.com/jupyterhub/dockerspawner/compare/0.8.0...0.9.0\n[0.8]: https://github.com/jupyterhub/dockerspawner/compare/0.7.0...0.8.0\n[0.7]: https://github.com/jupyterhub/dockerspawner/compare/0.6.0...0.7.0\n[0.6]: https://github.com/jupyterhub/dockerspawner/compare/0.5.0...0.6.0\n[0.5]: https://github.com/jupyterhub/dockerspawner/compare/0.4.0...0.5.0\n[0.4]: https://github.com/jupyterhub/dockerspawner/compare/0.3.0...0.4.0\n[0.3]: https://github.com/jupyterhub/dockerspawner/compare/0.2.0...0.3.0\n[0.2]: https://github.com/jupyterhub/dockerspawner/compare/0.1.0...0.2.0\n", "c = get_config()  # noqa\n\n\noptions_form_tpl = \"\"\"\n<label for=\"image\">Image</label>\n<input name=\"image\" class=\"form-control\" placeholder=\"the image to launch (default: {default_image})\"></input>\n\"\"\"\n\n\ndef get_options_form(spawner):\n    return options_form_tpl.format(default_image=spawner.image)\n\n\nc.DockerSpawner.options_form = get_options_form\n\nfrom dockerspawner import DockerSpawner\n\n\nclass CustomDockerSpawner(DockerSpawner):\n    def options_from_form(self, formdata):\n        options = {}\n        image_form_list = formdata.get(\"image\", [])\n        if image_form_list and image_form_list[0]:\n            options[\"image\"] = image_form_list[0].strip()\n            self.log.info(f\"User selected image: {options['image']}\")\n        return options\n\n    def load_user_options(self, options):\n        image = options.get(\"image\")\n        if image:\n            self.log.info(f\"Loading image {image}\")\n            self.image = image\n\n\nc.JupyterHub.spawner_class = CustomDockerSpawner\n\n# the rest of the config is testing boilerplate\n# to make the Hub connectable from the containers\n\n# dummy for testing. Don't use this in production!\nc.JupyterHub.authenticator_class = \"dummy\"\n# while using dummy auth, make the *public* (proxy) interface private\nc.JupyterHub.ip = \"127.0.0.1\"\n\n# we need the hub to listen on all ips when it is in a container\nc.JupyterHub.hub_ip = \"0.0.0.0\"\n\n# may need to set hub_connect_ip to be connectable to containers\n# default hostname behavior usually works, though\n# c.JupyterHub.hub_connect_ip\n\n# pick a default image to use when none is specified\nc.DockerSpawner.image = \"jupyter/base-notebook\"\n\n# delete containers when they stop\nc.DockerSpawner.remove = True\n", "\"\"\"pytest config for dockerspawner tests\"\"\"\nimport inspect\nimport json\nimport os\nfrom textwrap import indent\nfrom unittest import mock\n\nimport jupyterhub\nimport netifaces\nimport pytest\nfrom docker import from_env as docker_from_env\nfrom docker.errors import APIError\nfrom jupyterhub import version_info as jh_version_info\nfrom jupyterhub.tests.conftest import app as jupyterhub_app  # noqa: F401\nfrom jupyterhub.tests.conftest import event_loop  # noqa: F401\nfrom jupyterhub.tests.conftest import io_loop  # noqa: F401\nfrom jupyterhub.tests.conftest import ssl_tmpdir  # noqa: F401\nfrom jupyterhub.tests.mocking import MockHub\n\nfrom dockerspawner import DockerSpawner, SwarmSpawner, SystemUserSpawner\n\n# import base jupyterhub fixtures\n\n# make Hub connectable from docker by default\n# do this here because the `app` fixture has already loaded configuration\nMockHub.hub_ip = \"0.0.0.0\"\n\nif os.environ.get(\"HUB_CONNECT_IP\"):\n    MockHub.hub_connect_ip = os.environ[\"HUB_CONNECT_IP\"]\nelse:\n    # get docker interface explicitly by default\n    # on GHA, the ip for hostname resolves to a 10.x\n    # address that is not connectable from within containers\n    # but the docker0 address is connectable\n    docker_interfaces = sorted(\n        iface for iface in netifaces.interfaces() if 'docker' in iface\n    )\n    if docker_interfaces:\n        iface = docker_interfaces[0]\n        print(f\"Found docker interfaces: {docker_interfaces}, using {iface}\")\n        MockHub.hub_connect_ip = netifaces.ifaddresses(docker_interfaces[0])[\n            netifaces.AF_INET\n        ][0]['addr']\n\n\ndef pytest_collection_modifyitems(items):\n    \"\"\"This function is automatically run by pytest passing all collected test\n    functions.\n\n    We use it to add asyncio marker to all async tests and assert we don't use\n    test functions that are async generators which wouldn't make sense.\n    \"\"\"\n    for item in items:\n        if inspect.iscoroutinefunction(item.obj):\n            item.add_marker('asyncio')\n        assert not inspect.isasyncgenfunction(item.obj)\n\n\n@pytest.fixture\ndef app(jupyterhub_app):  # noqa: F811\n    app = jupyterhub_app\n    app.config.DockerSpawner.prefix = \"dockerspawner-test\"\n    # If it's a prerelease e.g. (2, 0, 0, 'rc4', '') use full tag\n    if len(jh_version_info) > 3 and jh_version_info[3]:\n        tag = jupyterhub.__version__\n        app.config.DockerSpawner.image = f\"quay.io/jupyterhub/singleuser:{tag}\"\n    return app\n\n\n@pytest.fixture\ndef named_servers(app):\n    with mock.patch.dict(\n        app.tornado_settings,\n        {\"allow_named_servers\": True, \"named_server_limit_per_user\": 2},\n    ):\n        yield\n\n\n@pytest.fixture\ndef dockerspawner_configured_app(app, named_servers):\n    \"\"\"Configure JupyterHub to use DockerSpawner\"\"\"\n    # app.config.DockerSpawner.remove = True\n    with mock.patch.dict(app.tornado_settings, {\"spawner_class\": DockerSpawner}):\n        yield app\n\n\n@pytest.fixture\ndef swarmspawner_configured_app(app, named_servers):\n    \"\"\"Configure JupyterHub to use DockerSpawner\"\"\"\n    with mock.patch.dict(\n        app.tornado_settings, {\"spawner_class\": SwarmSpawner}\n    ), mock.patch.dict(app.config.SwarmSpawner, {\"network_name\": \"bridge\"}):\n        yield app\n\n\n@pytest.fixture\ndef systemuserspawner_configured_app(app, named_servers):\n    \"\"\"Configure JupyterHub to use DockerSpawner\"\"\"\n    with mock.patch.dict(app.tornado_settings, {\"spawner_class\": SystemUserSpawner}):\n        yield app\n\n\n@pytest.fixture(autouse=True, scope=\"session\")\ndef docker():\n    \"\"\"Fixture to return a connected docker client\n\n    cleans up any containers we leave in docker\n    \"\"\"\n    d = docker_from_env()\n    try:\n        yield d\n\n    finally:\n        # cleanup our containers\n        for c in d.containers.list(all=True):\n            if c.name.startswith(\"dockerspawner-test\"):\n                c.stop()\n                c.remove()\n        try:\n            services = d.services.list()\n        except (APIError, TypeError):\n            # e.g. services not available\n            # podman gives TypeError\n            return\n        else:\n            for s in services:\n                if s.name.startswith(\"dockerspawner-test\"):\n                    s.remove()\n\n\n# make sure reports are available during yield fixtures\n# from pytest docs: https://docs.pytest.org/en/latest/example/simple.html#making-test-result-information-available-in-fixtures\n\n\n@pytest.hookimpl(tryfirst=True, hookwrapper=True)\ndef pytest_runtest_makereport(item, call):\n    # execute all other hooks to obtain the report object\n    outcome = yield\n    rep = outcome.get_result()\n\n    # set a report attribute for each phase of a call, which can\n    # be \"setup\", \"call\", \"teardown\"\n\n    setattr(item, \"rep_\" + rep.when, rep)\n\n\n@pytest.fixture(autouse=True)\ndef debug_docker(request, docker):\n    \"\"\"Debug docker state after tests\"\"\"\n    yield\n    if not hasattr(request.node, 'rep_call'):\n        return\n    if not request.node.rep_call.failed:\n        return\n\n    print(\"executing test failed\", request.node.nodeid)\n    containers = docker.containers.list(all=True)\n    for c in containers:\n        print(f\"Container {c.name}: {c.status}\")\n\n    for c in containers:\n        logs = indent(c.logs().decode('utf8', 'replace'), '  ')\n        print(f\"Container {c.name} logs:\\n{logs}\")\n\n    for c in containers:\n        container_info = json.dumps(\n            docker.api.inspect_container(c.id),\n            indent=2,\n            sort_keys=True,\n        )\n        print(f\"Container {c.name}: {container_info}\")\n\n\n_username_counter = 0\n\n\n@pytest.fixture()\ndef username():\n    global _username_counter\n    _username_counter += 1\n    return f\"test-user-{_username_counter}\"\n", "\"\"\"Tests for DockerSpawner class\"\"\"\nimport asyncio\nimport json\nimport logging\nimport os\nimport string\nfrom unittest import mock\n\nimport docker\nimport pytest\nimport traitlets\nfrom escapism import escape\nfrom jupyterhub.tests.mocking import public_url\nfrom jupyterhub.tests.test_api import add_user, api_request\nfrom jupyterhub.utils import url_path_join\nfrom tornado.httpclient import AsyncHTTPClient\n\nfrom dockerspawner import DockerSpawner\n\n\ndef test_name_collision(dockerspawner_configured_app):\n    app = dockerspawner_configured_app\n    has_hyphen = \"user--foo\"\n    add_user(app.db, app, name=has_hyphen)\n    user = app.users[has_hyphen]\n    spawner1 = user.spawners[\"\"]\n    assert isinstance(spawner1, DockerSpawner)\n    assert spawner1.object_name == \"{}-{}\".format(\n        spawner1.prefix, has_hyphen.replace(\"-\", \"-2d\")\n    )\n\n    part1, part2 = [\"user\", \"foo\"]\n    add_user(app.db, app, name=part1)\n    user2 = app.users[part1]\n    spawner2 = user2.spawners[part2]\n    assert spawner1.object_name != spawner2.object_name\n\n\n@pytest.mark.parametrize(\"remove\", (True, False))\nasync def test_start_stop(dockerspawner_configured_app, remove):\n    app = dockerspawner_configured_app\n    name = \"has@\"\n    add_user(app.db, app, name=name)\n    user = app.users[name]\n    server_name = 'also-has@'\n    spawner = user.spawners[server_name]\n    assert isinstance(spawner, DockerSpawner)\n    spawner.remove = remove\n    token = user.new_api_token()\n    # start the server\n    r = await api_request(app, \"users\", name, \"servers\", server_name, method=\"post\")\n    pending = r.status_code == 202\n    while pending:\n        # request again\n        await asyncio.sleep(2)\n        r = await api_request(app, \"users\", name)\n        user_info = r.json()\n        pending = user_info[\"servers\"][server_name][\"pending\"]\n    assert r.status_code in {201, 200}, r.text\n\n    url = url_path_join(public_url(app, user), server_name, \"api/status\")\n    resp = await AsyncHTTPClient().fetch(\n        url, headers={\"Authorization\": \"token %s\" % token}\n    )\n    assert resp.effective_url == url\n    resp.rethrow()\n    assert \"kernels\" in resp.body.decode(\"utf-8\")\n\n    # stop the server\n    r = await api_request(app, \"users\", name, \"servers\", server_name, method=\"delete\")\n    pending = r.status_code == 202\n    while pending:\n        # request again\n        await asyncio.sleep(2)\n        r = await api_request(app, \"users\", name)\n        user_info = r.json()\n        pending = user_info[\"servers\"][server_name][\"pending\"]\n    assert r.status_code in {204, 200}, r.text\n    state = spawner.get_state()\n    if remove:\n        assert state == {}\n    else:\n        assert sorted(state) == [\"object_id\", \"object_name\"]\n\n\ndef allowed_images_callable(*_):\n    return [\"jupyterhub/singleuser:1.0\", \"jupyterhub/singleuser:1.1\"]\n\n\n@pytest.mark.parametrize(\n    \"allowed_images, image\",\n    [\n        (\n            {\n                \"1.0\": \"jupyterhub/singleuser:1.0\",\n                \"1.1\": \"jupyterhub/singleuser:1.1\",\n            },\n            \"1.0\",\n        ),\n        ([\"jupyterhub/singleuser:1.0\", \"jupyterhub/singleuser:1.1.0\"], \"1.1.0\"),\n        (allowed_images_callable, \"1.0\"),\n    ],\n)\nasync def test_allowed_image(dockerspawner_configured_app, allowed_images, image):\n    app = dockerspawner_configured_app\n    name = \"checker\"\n    add_user(app.db, app, name=name)\n    user = app.users[name]\n    assert isinstance(user.spawner, DockerSpawner)\n    user.spawner.remove_containers = True\n    user.spawner.allowed_images = allowed_images\n    token = user.new_api_token()\n    # start the server\n    r = await api_request(\n        app,\n        \"users\",\n        name,\n        \"server\",\n        method=\"post\",\n        data=json.dumps({\"image\": image}),\n    )\n\n    if image not in user.spawner._get_allowed_images():\n        with pytest.raises(Exception):\n            r.raise_for_status()\n        return\n    pending = r.status_code == 202\n    while pending:\n        # request again\n        await asyncio.sleep(2)\n        r = await api_request(app, \"users\", name)\n        user_info = r.json()\n        pending = user_info[\"servers\"][\"\"][\"pending\"]\n\n    url = url_path_join(public_url(app, user), \"api/status\")\n    resp = await AsyncHTTPClient().fetch(\n        url, headers={\"Authorization\": \"token %s\" % token}\n    )\n    assert resp.effective_url == url\n    resp.rethrow()\n\n    assert resp.headers['x-jupyterhub-version'].startswith(image)\n    r = await api_request(\n        app,\n        \"users\",\n        name,\n        \"server\",\n        method=\"delete\",\n    )\n    r.raise_for_status()\n\n\n@pytest.mark.xfail(\n    \"podman.sock\" in os.getenv(\"DOCKER_HOST\", \"\"), reason=\"Fails with Podman\"\n)\nasync def test_image_pull_policy(dockerspawner_configured_app):\n    app = dockerspawner_configured_app\n    name = \"gumby\"\n    add_user(app.db, app, name=name)\n    user = app.users[name]\n    assert isinstance(user.spawner, DockerSpawner)\n    spawner = user.spawners[\"\"]\n    spawner.image = \"jupyterhub/doesntexist:nosuchtag\"\n    with pytest.raises(docker.errors.NotFound):\n        spawner.image_pull_policy = \"never\"\n        await spawner.pull_image(spawner.image)\n\n    repo = \"busybox\"\n    tag = \"1.29.1\"  # a version that's definitely not latest\n    # ensure image isn't present\n    try:\n        await asyncio.wrap_future(spawner.docker(\"remove_image\", f\"{repo}:{tag}\"))\n    except docker.errors.ImageNotFound:\n        pass\n\n    spawner.pull_policy = \"ifnotpresent\"\n    image = f\"{repo}:{tag}\"\n    # should trigger a pull\n    await spawner.pull_image(image)\n    # verify that the image exists now\n    old_image_info = await asyncio.wrap_future(spawner.docker(\"inspect_image\", image))\n    print(old_image_info)\n\n    # now tag busybox:latest as our current version\n    # which is not latest!\n    await asyncio.wrap_future(spawner.docker(\"tag\", image, repo))\n\n    image = repo  # implicit :latest\n    spawner.pull_policy = \"ifnotpresent\"\n    # check with ifnotpresent shouldn't pull\n    await spawner.pull_image(image)\n    image_info = await asyncio.wrap_future(spawner.docker(\"inspect_image\", repo))\n    assert image_info[\"Id\"] == old_image_info[\"Id\"]\n\n    # run again with Always,\n    # should trigger a pull even though the image is present\n    spawner.pull_policy = \"always\"\n    await spawner.pull_image(image)\n    image_info = await asyncio.wrap_future(spawner.docker(\"inspect_image\", repo))\n    assert image_info[\"Id\"] != old_image_info[\"Id\"]\n\n    # run again with never, make sure it's still happy\n    spawner.pull_policy = \"never\"\n    await spawner.pull_image(image)\n\n\nasync def test_post_start(dockerspawner_configured_app, caplog):\n    app = dockerspawner_configured_app\n    name = \"post-start\"\n    add_user(app.db, app, name=name)\n    user = app.users[name]\n    spawner = user.spawners['']\n    log_name = \"dockerspawner\"\n    spawner.log = logging.getLogger(log_name)\n    spawner.remove = True\n\n    # mock out ip and port, no need for it\n    async def mock_ip_port():\n        return (\"127.0.0.1\", 1234)\n\n    spawner.get_ip_and_port = mock_ip_port\n\n    spawner.image = \"busybox:1.29.1\"\n    spawner.cmd = [\"sh\", \"-c\", \"sleep 300\"]\n    spawner.post_start_cmd = \"ls /\"\n\n    # verify that it's called during startup\n    finished_future = asyncio.Future()\n    finished_future.set_result(None)\n    mock_post_start = mock.Mock(return_value=finished_future)\n    with mock.patch.object(spawner, 'post_start_exec', mock_post_start):\n        await spawner.start()\n    mock_post_start.assert_called_once()\n\n    # verify log capture for 3 combinations:\n    # - success\n    # - failure\n    # - no such command (different failure)\n\n    for cmd, expected_stdout, expected_stderr in [\n        (\"true\", False, False),\n        (\"ls /\", True, False),\n        (\"ls /nosuchfile\", False, True),\n        (\"nosuchcommand\", False, True),\n        (\"echo\", False, False),\n    ]:\n        spawner.post_start_cmd = cmd\n        idx = len(caplog.records)\n        with caplog.at_level(logging.DEBUG, log_name):\n            await spawner.post_start_exec()\n        logged = \"\\n\".join(\n            f\"{rec.levelname}: {rec.message}\" for rec in caplog.records[idx:]\n        )\n        if expected_stdout:\n            assert \"DEBUG: post_start stdout\" in logged\n        else:\n            assert \"post_start stdout\" not in logged\n        if expected_stderr:\n            assert \"WARNING: post_start stderr\" in logged\n        else:\n            assert \"post_start stderr\" not in logged\n\n    await spawner.stop()\n\n\n@pytest.mark.skipif(\n    traitlets.__version__ < '5.0', reason=\"One test fails on traitlets < 5.0. See #420.\"\n)\n@pytest.mark.parametrize(\n    \"mem_limit, expected\",\n    [\n        (\"1G\", 1024**3),\n        (1_000_000, 1_000_000),\n        (None, None),\n        (lambda spawner: None, None),\n        (lambda spawner: \"2G\", 2 * 1024**3),\n        (lambda spawner: 1_000_000, 1_000_000),\n    ],\n)\ndef test_mem_limit(mem_limit, expected):\n    s = DockerSpawner(mem_limit=mem_limit)\n    assert s.mem_limit == expected\n\n\n@pytest.mark.parametrize(\n    \"cpu_limit, expected\",\n    [\n        (1, 1),\n        (None, None),\n        (1.5, 1.5),\n        (lambda spawner: None, None),\n        (lambda spawner: 2, 2),\n        (lambda spawner: 1.25, 1.25),\n    ],\n)\nasync def test_cpu_limit(dockerspawner_configured_app, cpu_limit, expected, username):\n    app = dockerspawner_configured_app\n    app.config.DockerSpawner.cpu_limit = cpu_limit\n    add_user(app.db, app, name=username)\n    user = app.users[username]\n    s = user.spawners[\"\"]\n    assert s.cpu_limit == expected\n    original_docker = s.docker\n\n    async def mock_docker(cmd, *args, **kwargs):\n        if cmd == \"create_container\":\n            return args, kwargs\n        else:\n            return await original_docker(cmd, *args, **kwargs)\n\n    with mock.patch.object(s, 'docker', new=mock_docker):\n        args, kwargs = await s.create_object()\n\n    print(kwargs)\n    host_config = kwargs['host_config']\n    if expected is not None:\n        assert host_config['CpuPeriod'] == 100_000\n        assert host_config['CpuQuota'] == int(expected * 100_000)\n    else:\n        assert 'CpuPeriod' not in host_config\n        assert 'CpuQuota' not in host_config\n\n\n@mock.patch.dict(os.environ, {\"DOCKER_HOST\": \"tcp://127.0.0.2\"}, clear=True)\ndef test_default_host_ip_reads_env_var():\n    spawner = DockerSpawner()\n    assert spawner._default_host_ip() == \"127.0.0.2\"\n\n\ndef test_default_options_form():\n    spawner = DockerSpawner()\n    spawner.allowed_images = {\"1.0\": \"jupyterhub/singleuser:1.0\"}\n    assert spawner._default_options_form() == ''\n    spawner.allowed_images[\"1.1\"] = \"jupyterhub/singleuser:1.1\"\n    assert (\n        spawner._default_options_form()\n        == \"\"\"\n        <label for=\"image\">Select an image:</label>\n        <select class=\"form-control\" name=\"image\" required autofocus>\n        ['<option value=\"1.0\" >1.0</option>', '<option value=\"1.1\" >1.1</option>']\n        </select>\n        \"\"\"\n    )\n\n\ndef test_options_from_form():\n    spawner = DockerSpawner()\n    formdata = {'image': ['1.0', '1.1']}\n    assert spawner.options_from_form(formdata) == {'image': '1.0'}\n\n\n@pytest.mark.parametrize(\"escape_type\", (\"legacy\", escape))\ndef test_validate_escape(escape_type):\n    spawner = DockerSpawner()\n    spawner.escape = escape_type\n    with pytest.raises(Exception):\n        spawner.escape = \"\"\n\n\ndef test_legacy_escape(dockerspawner_configured_app):\n    app = dockerspawner_configured_app\n    name = \"cont@iner\"\n    add_user(app.db, app, name=name)\n    user = app.users[name]\n    server_name = 'cont@iner_server'\n    spawner = user.spawners[server_name]\n    assert isinstance(spawner, DockerSpawner)\n    container_name_template = spawner.name_template\n    container_name = container_name_template.format(\n        prefix=\"jupyter\", username=name, servername=server_name\n    )\n    safe_chars = set(string.ascii_letters + string.digits + \"-\")\n    assert spawner._legacy_escape(container_name) == escape(\n        container_name, safe_chars, escape_char='_'\n    )\n"], "fixing_code": ["\"\"\"\nA Spawner for JupyterHub that runs each user's server in a separate docker container\n\"\"\"\nimport asyncio\nimport inspect\nimport os\nimport string\nimport warnings\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import partial\nfrom io import BytesIO\nfrom pprint import pformat\nfrom tarfile import TarFile, TarInfo\nfrom textwrap import dedent, indent\nfrom urllib.parse import urlparse\n\nimport docker\nfrom docker.errors import APIError\nfrom docker.types import Mount\nfrom docker.utils import kwargs_from_env\nfrom escapism import escape\nfrom jupyterhub.spawner import Spawner\nfrom jupyterhub.traitlets import ByteSpecification, Callable\nfrom tornado import web\nfrom traitlets import (\n    Any,\n    Bool,\n    CaselessStrEnum,\n    Dict,\n    Float,\n    Int,\n    List,\n    Unicode,\n    Union,\n    default,\n    observe,\n    validate,\n)\n\nfrom .volumenamingstrategy import default_format_volume_name\n\n\nclass UnicodeOrFalse(Unicode):\n    info_text = \"a unicode string or False\"\n\n    def validate(self, obj, value):\n        if value is False:\n            return value\n\n        return super().validate(obj, value)\n\n\nimport jupyterhub\n\n_jupyterhub_xy = \"%i.%i\" % (jupyterhub.version_info[:2])\n\n\ndef _deep_merge(dest, src):\n    \"\"\"Merge dict `src` into `dest`, recursively\n\n    Modifies `dest` in-place, returns dest\n    \"\"\"\n    for key, value in src.items():\n        if key in dest:\n            dest_value = dest[key]\n            if isinstance(dest_value, dict) and isinstance(value, dict):\n                dest[key] = _deep_merge(dest_value, value)\n            else:\n                dest[key] = value\n        else:\n            dest[key] = value\n\n    return dest\n\n\nclass DockerSpawner(Spawner):\n    \"\"\"A Spawner for JupyterHub that runs each user's server in a separate docker container\"\"\"\n\n    def _eval_if_callable(self, x):\n        \"\"\"Evaluate x if it is callable\n\n        Or return x otherwise\n        \"\"\"\n        if callable(x):\n            return x(self)\n        return x\n\n    _executor = None\n\n    _deprecated_aliases = {\n        \"container_ip\": (\"host_ip\", \"0.9.*\"),\n        \"container_port\": (\"port\", \"0.9.*\"),\n        \"container_image\": (\"image\", \"0.9.*\"),\n        \"container_prefix\": (\"prefix\", \"0.10.0\"),\n        \"container_name_template\": (\"name_template\", \"0.10.0*\"),\n        \"remove_containers\": (\"remove\", \"0.10.0\"),\n        \"image_whitelist\": (\"allowed_images\", \"12.0\"),\n    }\n\n    @observe(*list(_deprecated_aliases))\n    def _deprecated_trait(self, change):\n        \"\"\"observer for deprecated traits\"\"\"\n        old_attr = change.name\n        new_attr, version = self._deprecated_aliases.get(old_attr)\n        new_value = getattr(self, new_attr)\n        if new_value != change.new:\n            # only warn if different\n            # protects backward-compatible config from warnings\n            # if they set the same value under both names\n            self.log.warning(\n                \"{cls}.{old} is deprecated in DockerSpawner {version}, use {cls}.{new} instead\".format(\n                    cls=self.__class__.__name__,\n                    old=old_attr,\n                    new=new_attr,\n                    version=version,\n                )\n            )\n            setattr(self, new_attr, change.new)\n\n    @property\n    def executor(self):\n        \"\"\"single global executor\"\"\"\n        cls = self.__class__\n        if cls._executor is None:\n            cls._executor = ThreadPoolExecutor(1)\n        return cls._executor\n\n    _client = None\n\n    @property\n    def client(self):\n        \"\"\"single global client instance\"\"\"\n        cls = self.__class__\n        if cls._client is None:\n            kwargs = {\"version\": \"auto\"}\n            if self.tls_config:\n                kwargs[\"tls\"] = docker.tls.TLSConfig(**self.tls_config)\n            kwargs.update(kwargs_from_env())\n            kwargs.update(self.client_kwargs)\n            client = docker.APIClient(**kwargs)\n            cls._client = client\n        return cls._client\n\n    @default(\"cmd\")\n    def _default_cmd(self):\n        # no default means use the image command\n        return None\n\n    object_id = Unicode()\n    # the type of object we create\n    object_type = \"container\"\n    # the field containing the object id\n    object_id_key = \"Id\"\n\n    @property\n    def container_id(self):\n        \"\"\"alias for object_id\"\"\"\n        return self.object_id\n\n    @property\n    def container_name(self):\n        \"\"\"alias for object_name\"\"\"\n        return self.object_name\n\n    # deprecate misleading container_ip, since\n    # it is not the ip in the container,\n    # but the host ip of the port forwarded to the container\n    # when use_internal_ip is False\n    container_ip = Unicode(\n        \"127.0.0.1\", help=\"Deprecated, use ``DockerSpawner.host_ip``\", config=True\n    )\n\n    host_ip = Unicode(\n        \"127.0.0.1\",\n        help=\"\"\"The ip address on the host on which to expose the container's port\n\n        Typically 127.0.0.1, but can be public interfaces as well\n        in cases where the Hub and/or proxy are on different machines\n        from the user containers.\n\n        Only used when ``use_internal_ip = False``.\n        \"\"\",\n        config=True,\n    )\n\n    @default('host_ip')\n    def _default_host_ip(self):\n        docker_host = os.getenv('DOCKER_HOST')\n        if docker_host:\n            urlinfo = urlparse(docker_host)\n            if urlinfo.scheme == 'tcp':\n                return urlinfo.hostname\n        return '127.0.0.1'\n\n    # unlike container_ip, container_port is the internal port\n    # on which the server is bound.\n    container_port = Int(\n        8888,\n        min=1,\n        max=65535,\n        help=\"Deprecated, use ``DockerSpawner.port``.\",\n        config=True,\n    )\n\n    # fix default port to 8888, used in the container\n\n    @default(\"port\")\n    def _port_default(self):\n        return 8888\n\n    # default to listening on all-interfaces in the container\n\n    @default(\"ip\")\n    def _ip_default(self):\n        return \"0.0.0.0\"\n\n    container_image = Unicode(\n        \"quay.io/jupyterhub/singleuser:%s\" % _jupyterhub_xy,\n        help=\"Deprecated, use ``DockerSpawner.image``.\",\n        config=True,\n    )\n\n    image = Unicode(\n        \"quay.io/jupyterhub/singleuser:%s\" % _jupyterhub_xy,\n        config=True,\n        help=\"\"\"The image to use for single-user servers.\n\n        This image should have the same version of jupyterhub as\n        the Hub itself installed.\n\n        If the default command of the image does not launch\n        jupyterhub-singleuser, set ``c.Spawner.cmd`` to\n        launch jupyterhub-singleuser, e.g.\n\n        Any of the jupyter docker-stacks should work without additional config,\n        as long as the version of jupyterhub in the image is compatible.\n        \"\"\",\n    )\n\n    image_whitelist = Union(\n        [Any(), Dict(), List()],\n        help=\"Deprecated, use ``DockerSpawner.allowed_images``.\",\n        config=True,\n    )\n\n    allowed_images = Union(\n        [Any(), Dict(), List()],\n        default_value={},\n        config=True,\n        help=\"\"\"\n        List or dict of images that users can run.\n\n        If specified, users will be presented with a form\n        from which they can select an image to run.\n\n        If a dictionary, the keys will be the options presented to users\n        and the values the actual images that will be launched.\n\n        If a list, will be cast to a dictionary where keys and values are the same\n        (i.e. a shortcut for presenting the actual images directly to users).\n\n        If a callable, will be called with the Spawner instance as its only argument.\n        The user is accessible as spawner.user.\n        The callable should return a dict or list or None as above.\n\n        If empty (default), the value from ``image`` is used and\n        any attempt to specify the image via user_options will result in an error.\n\n        .. versionchanged:: 13\n            Empty allowed_images means no user-specified images are allowed.\n            This is the default.\n            Prior to 13, restricting to single image required a length-1 list,\n            e.g. ``allowed_images = [image]``.\n\n        .. versionadded:: 13\n            To allow any image, specify ``allowed_images = \"*\"``.\n\n        .. versionchanged:: 12.0\n            ``DockerSpawner.image_whitelist`` renamed to ``allowed_images``\n        \"\"\",\n    )\n\n    @validate('allowed_images')\n    def _validate_allowed_images(self, proposal):\n        \"\"\"cast allowed_images to a dict\n\n        If passing a list, cast it to a {item:item}\n        dict where the keys and values are the same.\n        \"\"\"\n        allowed_images = proposal[\"value\"]\n        if isinstance(allowed_images, str):\n            if allowed_images != \"*\":\n                raise ValueError(\n                    f\"'*' (all images) is the only accepted string value for allowed_images, got {allowed_images!r}. Use a list: `[{allowed_images!r}]` if you want to allow just one image.\"\n                )\n        elif isinstance(allowed_images, list):\n            allowed_images = {item: item for item in allowed_images}\n        return allowed_images\n\n    def _get_allowed_images(self):\n        \"\"\"Evaluate allowed_images callable\n\n        Always returns a dict or None\n        \"\"\"\n        if callable(self.allowed_images):\n            allowed_images = self.allowed_images(self)\n            return self._validate_allowed_images({\"value\": allowed_images})\n        return self.allowed_images\n\n    @default('options_form')\n    def _default_options_form(self):\n        allowed_images = self._get_allowed_images()\n        if allowed_images == \"*\" or len(allowed_images) <= 1:\n            # default form only when there are images to choose from\n            return ''\n        # form derived from wrapspawner.ProfileSpawner\n        option_t = '<option value=\"{image}\" {selected}>{image}</option>'\n        options = [\n            option_t.format(\n                image=image, selected='selected' if image == self.image else ''\n            )\n            for image in allowed_images\n        ]\n        return \"\"\"\n        <label for=\"image\">Select an image:</label>\n        <select class=\"form-control\" name=\"image\" required autofocus>\n        {options}\n        </select>\n        \"\"\".format(\n            options=options\n        )\n\n    def options_from_form(self, formdata):\n        \"\"\"Turn options formdata into user_options\"\"\"\n        options = {}\n        if 'image' in formdata:\n            options['image'] = formdata['image'][0]\n        return options\n\n    pull_policy = CaselessStrEnum(\n        [\"always\", \"ifnotpresent\", \"never\", \"skip\"],\n        default_value=\"ifnotpresent\",\n        config=True,\n        help=\"\"\"The policy for pulling the user docker image.\n\n        Choices:\n\n        - ifnotpresent: pull if the image is not already present (default)\n        - always: always pull the image to check for updates,\n          even if it is present\n        - never: never perform a pull, raise if image is not present\n        - skip: never perform a pull, skip the step entirely\n          (like never, but without raising when images are not present;\n          default for swarm)\n\n        .. versionadded: 12.0\n            'skip' option added. It is the default for swarm\n            because pre-pulling images on swarm clusters\n            doesn't make sense since the container is likely not\n            going to run on the same node where the image was pulled.\n        \"\"\",\n    )\n\n    container_prefix = Unicode(\n        config=True, help=\"Deprecated, use ``DockerSpawner.prefix``.\"\n    )\n\n    container_name_template = Unicode(\n        config=True, help=\"Deprecated, use ``DockerSpawner.name_template``.\"\n    )\n\n    prefix = Unicode(\n        \"jupyter\",\n        config=True,\n        help=dedent(\n            \"\"\"\n            Prefix for container names. See name_template for full container name for a particular\n            user's server.\n            \"\"\"\n        ),\n    )\n\n    name_template = Unicode(\n        config=True,\n        help=dedent(\n            \"\"\"\n            Name of the container or service: with {username}, {imagename}, {prefix}, {servername} replacements.\n            {raw_username} can be used for the original, not escaped username\n            (may contain uppercase, special characters).\n            It is important to include {servername} if JupyterHub's \"named\n            servers\" are enabled (``JupyterHub.allow_named_servers = True``).\n            If the server is named, the default name_template is\n            \"{prefix}-{username}--{servername}\". If it is unnamed, the default\n            name_template is \"{prefix}-{username}\".\n\n            Note: when using named servers,\n            it is important that the separator between {username} and {servername}\n            is not a character that can occur in an escaped {username},\n            and also not the single escape character '-'.\n            \"\"\"\n        ),\n    )\n\n    @default('name_template')\n    def _default_name_template(self):\n        if self.name:\n            return \"{prefix}-{username}--{servername}\"\n        else:\n            return \"{prefix}-{username}\"\n\n    client_kwargs = Dict(\n        config=True,\n        help=\"Extra keyword arguments to pass to the docker.Client constructor.\",\n    )\n\n    volumes = Dict(\n        config=True,\n        help=dedent(\n            \"\"\"\n            Map from host file/directory to container (guest) file/directory\n            mount point and (optionally) a mode. When specifying the\n            guest mount point (bind) for the volume, you may use a\n            dict or str. If a str, then the volume will default to a\n            read-write (mode=\"rw\"). With a dict, the bind is\n            identified by \"bind\" and the \"mode\" may be one of \"rw\"\n            (default), \"ro\" (read-only), \"z\" (public/shared SELinux\n            volume label), and \"Z\" (private/unshared SELinux volume\n            label).\n\n            If format_volume_name is not set,\n            default_format_volume_name is used for naming volumes.\n            In this case, if you use {username} in either the host or guest\n            file/directory path, it will be replaced with the current\n            user's name.\n            \"\"\"\n        ),\n    )\n\n    mounts = List(\n        config=True,\n        help=dedent(\n            \"\"\"\n            List of dict with keys to match docker.types.Mount for more advanced\n            configuration of mouted volumes.  As with volumes, if the default\n            format_volume_name is in use, you can use {username} in the source or\n            target paths, and it will be replaced with the current user's name.\n            \"\"\"\n        ),\n    )\n\n    move_certs_image = Unicode(\n        \"busybox:1.30.1\",\n        config=True,\n        help=\"\"\"The image used to stage internal SSL certificates.\n\n        Busybox is used because we just need an empty container\n        that waits while we stage files into the volume via .put_archive.\n        \"\"\",\n    )\n\n    async def move_certs(self, paths):\n        self.log.info(\"Staging internal ssl certs for %s\", self._log_name)\n        await self.pull_image(self.move_certs_image)\n        # create the volume\n        volume_name = self.format_volume_name(self.certs_volume_name, self)\n        # create volume passes even if it already exists\n        self.log.info(\"Creating ssl volume %s for %s\", volume_name, self._log_name)\n        await self.docker('create_volume', volume_name)\n\n        # create a tar archive of the internal cert files\n        # docker.put_archive takes a tarfile and a running container\n        # and unpacks the archive into the container\n        nb_paths = {}\n        tar_buf = BytesIO()\n        archive = TarFile(fileobj=tar_buf, mode='w')\n        for key, hub_path in paths.items():\n            fname = os.path.basename(hub_path)\n            nb_paths[key] = '/certs/' + fname\n            with open(hub_path, 'rb') as f:\n                content = f.read()\n            tarinfo = TarInfo(name=fname)\n            tarinfo.size = len(content)\n            tarinfo.mtime = os.stat(hub_path).st_mtime\n            tarinfo.mode = 0o644\n            archive.addfile(tarinfo, BytesIO(content))\n        archive.close()\n        tar_buf.seek(0)\n\n        # run a container to stage the certs,\n        # mounting the volume at /certs/\n        host_config = self.client.create_host_config(\n            binds={\n                volume_name: {\"bind\": \"/certs\", \"mode\": \"rw\"},\n            },\n        )\n        container = await self.docker(\n            'create_container',\n            self.move_certs_image,\n            volumes=[\"/certs\"],\n            host_config=host_config,\n        )\n\n        container_id = container['Id']\n        self.log.debug(\n            \"Container %s is creating ssl certs for %s\",\n            container_id[:12],\n            self._log_name,\n        )\n        # start the container\n        await self.docker('start', container_id)\n        # stage the archive to the container\n        try:\n            await self.docker(\n                'put_archive',\n                container=container_id,\n                path='/certs',\n                data=tar_buf,\n            )\n        finally:\n            await self.docker('remove_container', container_id)\n        return nb_paths\n\n    certs_volume_name = Unicode(\n        \"{prefix}ssl-{username}\",\n        config=True,\n        help=\"\"\"Volume name\n\n        The same string-templating applies to this\n        as other volume names.\n        \"\"\",\n    )\n\n    read_only_volumes = Dict(\n        config=True,\n        help=dedent(\n            \"\"\"\n            Map from host file/directory to container file/directory.\n            Volumes specified here will be read-only in the container.\n\n            If format_volume_name is not set,\n            default_format_volume_name is used for naming volumes.\n            In this case, if you use {username} in either the host or guest\n            file/directory path, it will be replaced with the current\n            user's name.\n            \"\"\"\n        ),\n    )\n\n    format_volume_name = Any(\n        help=\"\"\"Any callable that accepts a string template and a DockerSpawner instance as parameters in that order and returns a string.\n\n        Reusable implementations should go in dockerspawner.VolumeNamingStrategy, tests should go in ...\n        \"\"\"\n    ).tag(config=True)\n\n    @default(\"format_volume_name\")\n    def _get_default_format_volume_name(self):\n        return default_format_volume_name\n\n    use_docker_client_env = Bool(\n        True,\n        config=True,\n        help=\"Deprecated. Docker env variables are always used if present.\",\n    )\n\n    @observe(\"use_docker_client_env\")\n    def _client_env_changed(self):\n        self.log.warning(\n            \"DockerSpawner.use_docker_client_env is deprecated and ignored.\"\n            \"  Docker environment variables are always used if defined.\"\n        )\n\n    tls_config = Dict(\n        config=True,\n        help=\"\"\"Arguments to pass to docker TLS configuration.\n\n        See docker.client.TLSConfig constructor for options.\n        \"\"\",\n    )\n    tls = tls_verify = tls_ca = tls_cert = tls_key = tls_assert_hostname = Any(\n        config=True,\n        help=\"\"\"Deprecated, use ``DockerSpawner.tls_config`` dict to set any TLS options.\"\"\",\n    )\n\n    @observe(\n        \"tls\", \"tls_verify\", \"tls_ca\", \"tls_cert\", \"tls_key\", \"tls_assert_hostname\"\n    )\n    def _tls_changed(self, change):\n        self.log.warning(\n            \"%s config ignored, use %s.tls_config dict to set full TLS configuration.\",\n            change.name,\n            self.__class__.__name__,\n        )\n\n    remove_containers = Bool(\n        False, config=True, help=\"Deprecated, use ``DockerSpawner.remove``.\"\n    )\n\n    remove = Bool(\n        False,\n        config=True,\n        help=\"\"\"\n        If ``True``, delete containers when servers are stopped.\n\n        This will destroy any data in the container not stored in mounted volumes.\n        \"\"\",\n    )\n\n    @property\n    def will_resume(self):\n        # indicate that we will resume,\n        # so JupyterHub >= 0.7.1 won't cleanup our API token\n        return not self.remove\n\n    extra_create_kwargs = Union(\n        [Callable(), Dict()],\n        config=True,\n        help=\"\"\"Additional args to pass for container create\n\n        For example, to change the user the container is started as::\n\n            c.DockerSpawner.extra_create_kwargs = {\n                \"user\": \"root\" # Can also be an integer UID\n            }\n\n        The above is equivalent to ``docker run --user root``.\n\n        If a callable, will be called with the Spawner as the only argument,\n        must return the same dictionary structure, and may be async.\n\n        .. versionchanged:: 13\n\n            Added callable support.\n        \"\"\",\n    )\n    extra_host_config = Union(\n        [Callable(), Dict()],\n        config=True,\n        help=\"\"\"\n        Additional args to create_host_config for container create.\n\n        If a callable, will be called with the Spawner as the only argument,\n        must return the same dictionary structure, and may be async.\n\n        .. versionchanged:: 13\n\n            Added callable support.\n        \"\"\",\n    )\n\n    escape = Any(\n        help=\"\"\"Override escaping with any callable of the form escape(str)->str\n\n        This is used to ensure docker-safe container names, etc.\n\n        The default escaping should ensure safety and validity,\n        but can produce cumbersome strings in cases.\n\n        Set c.DockerSpawner.escape = 'legacy' to preserve the earlier, unsafe behavior\n        if it worked for you.\n\n        .. versionadded:: 12.0\n\n        .. versionchanged:: 12.0\n            Escaping has changed in 12.0 to ensure safety,\n            but existing deployments will get different container and volume names.\n        \"\"\",\n        config=True,\n    )\n\n    @default(\"escape\")\n    def _escape_default(self):\n        return self._escape\n\n    @validate(\"escape\")\n    def _validate_escape(self, proposal):\n        escape = proposal.value\n        if escape == \"legacy\":\n            return self._legacy_escape\n        if not callable(escape):\n            raise ValueError(\"DockerSpawner.escape must be callable, got %r\" % escape)\n        return escape\n\n    @staticmethod\n    def _escape(text):\n        # Make sure a substring matches the restrictions for DNS labels\n        # Note: '-' cannot be in safe_chars, as it is being used as escape character\n        # any '-' must be escaped to '-2d' to avoid collisions\n        safe_chars = set(string.ascii_lowercase + string.digits)\n        return escape(text, safe_chars, escape_char='-').lower()\n\n    @staticmethod\n    def _legacy_escape(text):\n        \"\"\"Legacy implementation of escape\n\n        Select with config c.DockerSpawner.escape = 'legacy'\n\n        Unsafe and doesn't work in all cases,\n        but allows opt-in to backward compatibility for an upgrading deployment.\n\n        Do not use for new deployments.\n        \"\"\"\n        safe_chars = set(string.ascii_letters + string.digits + \"-\")\n        return escape(text, safe_chars, escape_char='_')\n\n    hub_ip_connect = Unicode(\n        config=True,\n        help=\"DEPRECATED since JupyterHub 0.8. Use c.JupyterHub.hub_connect_ip.\",\n    )\n\n    @observe(\"hub_ip_connect\")\n    def _ip_connect_changed(self, change):\n        self.log.warning(\n            f\"Ignoring DockerSpawner.hub_ip_connect={change.new!r}, which has ben deprected since JupyterHub 0.8. Use c.JupyterHub.hub_connect_ip instead.\"\n        )\n\n    use_internal_ip = Bool(\n        False,\n        config=True,\n        help=dedent(\n            \"\"\"\n            Enable the usage of the internal docker ip. This is useful if you are running\n            jupyterhub (as a container) and the user containers within the same docker network.\n            E.g. by mounting the docker socket of the host into the jupyterhub container.\n            Default is ``True`` if using a docker network, ``False`` if bridge or host networking is used.\n            \"\"\"\n        ),\n    )\n\n    @default(\"use_internal_ip\")\n    def _default_use_ip(self):\n        # setting network_name to something other than bridge or host implies use_internal_ip\n        if self.network_name not in {\"bridge\", \"host\"}:\n            return True\n\n        else:\n            return False\n\n    use_internal_hostname = Bool(\n        False,\n        config=True,\n        help=dedent(\n            \"\"\"\n            Use the docker hostname for connecting.\n\n            instead of an IP address.\n            This should work in general when using docker networks,\n            and must be used when internal_ssl is enabled.\n            It is enabled by default if internal_ssl is enabled.\n            \"\"\"\n        ),\n    )\n\n    @default(\"use_internal_hostname\")\n    def _default_use_hostname(self):\n        # FIXME: replace getattr with self.internal_ssl\n        # when minimum jupyterhub is 1.0\n        return getattr(self, 'internal_ssl', False)\n\n    links = Dict(\n        config=True,\n        help=dedent(\n            \"\"\"\n            Specify docker link mapping to add to the container, e.g.\n\n                links = {'jupyterhub': 'jupyterhub'}\n\n            If the Hub is running in a Docker container,\n            this can simplify routing because all traffic will be using docker hostnames.\n            \"\"\"\n        ),\n    )\n\n    network_name = Unicode(\n        \"bridge\",\n        config=True,\n        help=dedent(\n            \"\"\"\n            Run the containers on this docker network.\n            If it is an internal docker network, the Hub should be on the same network,\n            as internal docker IP addresses will be used.\n            For bridge networking, external ports will be bound.\n            \"\"\"\n        ),\n    )\n\n    post_start_cmd = UnicodeOrFalse(\n        False,\n        config=True,\n        help=\"\"\"If specified, the command will be executed inside the container\n        after starting.\n        Similar to using 'docker exec'\n        \"\"\",\n    )\n\n    async def post_start_exec(self):\n        \"\"\"\n        Execute additional command inside the container after starting it.\n\n        e.g. calling 'docker exec'\n        \"\"\"\n\n        container = await self.get_object()\n        container_id = container[self.object_id_key]\n\n        exec_kwargs = {'cmd': self.post_start_cmd, 'container': container_id}\n        self.log.debug(\n            f\"Running post_start exec in {self.object_name}: {self.post_start_cmd}\"\n        )\n\n        exec_id = await self.docker(\"exec_create\", **exec_kwargs)\n\n        stdout, stderr = await self.docker(\"exec_start\", exec_id=exec_id, demux=True)\n\n        # docker-py uses None for empty output instead of empty bytestring\n        if stdout is None:\n            stdout = b''\n\n        # stderr is usually None instead of empty b''\n        # this includes error conditions like \"OCI runtime exec failed...\"\n        # but also most successful runs\n        if stderr is None:\n            # crude check for \"OCI runtime exec failed: ...\"\n            # switch message to stderr instead of stdout for warning-level output\n            if b'exec failed' in stdout:\n                stderr = stdout\n                stdout = b''\n            else:\n                stderr = b''\n\n        for name, stream, level in [\n            (\"stdout\", stdout, \"debug\"),\n            (\"stderr\", stderr, \"warning\"),\n        ]:\n            output = stream.decode(\"utf8\", \"replace\").strip()\n            if not output:\n                continue\n\n            if '\\n' in output:\n                # if multi-line, wrap to new line and indent\n                output = '\\n' + output\n                output = indent(output, \"    \")\n            log = getattr(self.log, level)\n            log(f\"post_start {name} in {self.object_name}: {output}\")\n\n    @property\n    def tls_client(self):\n        \"\"\"A tuple consisting of the TLS client certificate and key if they\n        have been provided, otherwise None.\n\n        \"\"\"\n        if self.tls_cert and self.tls_key:\n            return (self.tls_cert, self.tls_key)\n\n        return None\n\n    @property\n    def volume_mount_points(self):\n        \"\"\"\n        Volumes are declared in docker-py in two stages.  First, you declare\n        all the locations where you're going to mount volumes when you call\n        create_container.\n\n        Returns a sorted list of all the values in self.volumes or\n        self.read_only_volumes.\n        \"\"\"\n        return sorted([value[\"bind\"] for value in self.volume_binds.values()])\n\n    @property\n    def volume_binds(self):\n        \"\"\"\n        The second half of declaring a volume with docker-py happens when you\n        actually call start(). The required format is a dict of dicts that\n        looks like::\n\n            {\n                host_location: {'bind': container_location, 'mode': 'rw'}\n            }\n\n        Mode may be 'ro', 'rw', 'z', or 'Z'.\n        \"\"\"\n        binds = self._volumes_to_binds(self.volumes, {})\n        read_only_volumes = {}\n        # FIXME: replace getattr with self.internal_ssl\n        # when minimum jupyterhub is 1.0\n        if getattr(self, 'internal_ssl', False):\n            # add SSL volume as read-only\n            read_only_volumes[self.certs_volume_name] = '/certs'\n        read_only_volumes.update(self.read_only_volumes)\n        return self._volumes_to_binds(read_only_volumes, binds, mode=\"ro\")\n\n    @property\n    def mount_binds(self):\n        \"\"\"\n        A different way of specifying docker volumes using more advanced spec.\n        Converts mounts list of dict to a list of docker.types.Mount\n        \"\"\"\n\n        def _fmt(v):\n            return self.format_volume_name(v, self)\n\n        mounts = []\n        for mount in self.mounts:\n            args = dict(mount)\n            args[\"source\"] = _fmt(mount[\"source\"])\n            args[\"target\"] = _fmt(mount[\"target\"])\n            mounts.append(Mount(**args))\n        return mounts\n\n    _escaped_name = None\n\n    @property\n    def escaped_name(self):\n        \"\"\"Escape the username so it's safe for docker objects\"\"\"\n        if self._escaped_name is None:\n            self._escaped_name = self.escape(self.user.name)\n        return self._escaped_name\n\n    object_id = Unicode(allow_none=True)\n\n    def template_namespace(self):\n        escaped_image = self.image.replace(\"/\", \"-\").replace(\":\", \"-\")\n        server_name = getattr(self, \"name\", \"\")\n        safe_server_name = self.escape(server_name.lower())\n        return {\n            \"username\": self.escaped_name,\n            \"safe_username\": self.escaped_name,\n            \"raw_username\": self.user.name,\n            \"imagename\": escaped_image,\n            \"servername\": safe_server_name,\n            \"raw_servername\": server_name,\n            \"prefix\": self.prefix,\n        }\n\n    object_name = Unicode()\n\n    @default(\"object_name\")\n    def _object_name_default(self):\n        \"\"\"Render the name of our container/service using name_template\"\"\"\n        return self._render_templates(self.name_template)\n\n    @observe(\"image\")\n    def _image_changed(self, change):\n        # re-render object name if image changes\n        self.object_name = self._object_name_default()\n\n    def load_state(self, state):\n        super().load_state(state)\n        if \"container_id\" in state:\n            # backward-compatibility for dockerspawner < 0.10\n            self.object_id = state.get(\"container_id\")\n        else:\n            self.object_id = state.get(\"object_id\", \"\")\n\n        # override object_name from state if defined\n        # to avoid losing track of running servers\n        self.object_name = state.get(\"object_name\", None) or self.object_name\n\n        if self.object_id:\n            self.log.debug(\n                f\"Loaded state for {self._log_name}: {self.object_type}\"\n                f\" name={self.object_name}, id={self.object_id}\"\n            )\n\n    def get_state(self):\n        state = super().get_state()\n        if self.object_id:\n            state[\"object_id\"] = self.object_id\n            # persist object_name if running\n            # so that a change in the template doesn't lose track of running servers\n            state[\"object_name\"] = self.object_name\n            self.log.debug(\n                f\"Persisting state for {self._log_name}: {self.object_type}\"\n                f\" name={self.object_name}, id={self.object_id}\"\n            )\n        return state\n\n    def _env_keep_default(self):\n        \"\"\"Don't inherit any env from the parent process\"\"\"\n        return []\n\n    def get_env(self):\n        env = super().get_env()\n        env['JUPYTER_IMAGE_SPEC'] = self.image\n        return env\n\n    def _docker(self, method, *args, **kwargs):\n        \"\"\"wrapper for calling docker methods\n\n        to be passed to ThreadPoolExecutor\n        \"\"\"\n        m = getattr(self.client, method)\n        return m(*args, **kwargs)\n\n    def docker(self, method, *args, **kwargs):\n        \"\"\"Call a docker method in a background thread\n\n        returns a Future\n        \"\"\"\n        return asyncio.wrap_future(\n            self.executor.submit(self._docker, method, *args, **kwargs)\n        )\n\n    async def poll(self):\n        \"\"\"Check for my id in ``docker ps``\"\"\"\n        container = await self.get_object()\n        if not container:\n            self.log.warning(\"Container not found: %s\", self.container_name)\n            return 0\n\n        container_state = container[\"State\"]\n        self.log.debug(\n            \"Container %s status: %s\", self.container_id[:7], pformat(container_state)\n        )\n\n        if container_state[\"Running\"]:\n            return None\n\n        else:\n            return (\n                \"ExitCode={ExitCode}, \"\n                \"Error='{Error}', \"\n                \"FinishedAt={FinishedAt}\".format(**container_state)\n            )\n\n    async def get_object(self):\n        self.log.debug(\"Getting %s '%s'\", self.object_type, self.object_name)\n        try:\n            obj = await self.docker(\"inspect_%s\" % self.object_type, self.object_name)\n            self.object_id = obj[self.object_id_key]\n        except APIError as e:\n            if e.response.status_code == 404:\n                self.log.info(\n                    \"%s '%s' is gone\", self.object_type.title(), self.object_name\n                )\n                obj = None\n                # my container is gone, forget my id\n                self.object_id = \"\"\n            elif e.response.status_code == 500:\n                self.log.info(\n                    \"%s '%s' is on unhealthy node\",\n                    self.object_type.title(),\n                    self.object_name,\n                )\n                obj = None\n                # my container is unhealthy, forget my id\n                self.object_id = \"\"\n            else:\n                raise\n\n        return obj\n\n    async def get_command(self):\n        \"\"\"Get the command to run (full command + args)\"\"\"\n        if self.cmd:\n            cmd = self.cmd\n        else:\n            image_info = await self.docker(\"inspect_image\", self.image)\n            cmd = image_info[\"Config\"][\"Cmd\"]\n        return cmd + self.get_args()\n\n    async def remove_object(self):\n        self.log.info(\"Removing %s %s\", self.object_type, self.object_id)\n        # remove the container, as well as any associated volumes\n        try:\n            await self.docker(\"remove_\" + self.object_type, self.object_id, v=True)\n        except docker.errors.APIError as e:\n            if e.status_code == 409:\n                self.log.debug(\n                    \"Already removing %s: %s\", self.object_type, self.object_id\n                )\n            elif e.status_code == 404:\n                self.log.debug(\n                    \"Already removed %s: %s\", self.object_type, self.object_id\n                )\n            else:\n                raise\n\n    async def check_allowed(self, image):\n        allowed_images = self._get_allowed_images()\n        if allowed_images == \"*\":\n            return image\n        elif not allowed_images:\n            raise web.HTTPError(400, \"Specifying image to launch is not allowed\")\n        if image not in allowed_images:\n            raise web.HTTPError(\n                400,\n                \"Image {} not in allowed list: {}\".format(\n                    image, ', '.join(allowed_images)\n                ),\n            )\n        # resolve image alias to actual image name\n        return allowed_images[image]\n\n    @default('ssl_alt_names')\n    def _get_ssl_alt_names(self):\n        return ['DNS:' + self.internal_hostname]\n\n    mem_limit = Union(\n        [Callable(), ByteSpecification()],\n        help=\"\"\"\n        Maximum number of bytes a single-user notebook server is allowed to use.\n        Allows the following suffixes:\n          - K -> Kilobytes\n          - M -> Megabytes\n          - G -> Gigabytes\n          - T -> Terabytes\n        If the single user server tries to allocate more memory than this,\n        it will fail. There is no guarantee that the single-user notebook server\n        will be able to allocate this much memory - only that it can not\n        allocate more than this.\n\n        Alternatively to a string it can also be a callable that takes the spawner as\n        the only argument and returns a string:\n\n        def per_user_mem_limit(spawner):\n            username = spawner.user.name\n            ram_limits = {'alice': '4G', 'bob': '2G'}\n            return ram_limits.get(username, '1G')\n        c.DockerSpawner.mem_limit = per_user_mem_limit\n        \"\"\",\n    ).tag(config=True)\n\n    @validate('mem_limit')\n    def _mem_limit_str(self, proposal):\n        \"\"\"cast mem_limit to a str\"\"\"\n        return self._eval_if_callable(proposal.value)\n\n    cpu_limit = Union(\n        [Callable(), Float(allow_none=True)],\n        help=\"\"\"\n        CPU limit for containers\n\n        Will set cpu_quota = cpu_limit * cpu_period\n\n        The default cpu_period of 100ms will be used,\n        unless overridden in extra_host_config.\n\n        Alternatively to a single float,\n        cpu_limit can also be a callable that takes the spawner as\n        the only argument and returns a float:\n\n        def per_user_cpu_limit(spawner):\n            username = spawner.user.name\n            cpu_limits = {'alice': 2.5, 'bob': 2}\n            return cpu_limits.get(username, 1)\n        c.DockerSpawner.cpu_limit = per_user_cpu_limit\n        \"\"\",\n    ).tag(config=True)\n\n    @validate('cpu_limit')\n    def _cast_cpu_limit(self, proposal):\n        \"\"\"cast cpu_limit to a float if it's callable\"\"\"\n        return self._eval_if_callable(proposal.value)\n\n    async def create_object(self):\n        \"\"\"Create the container/service object\"\"\"\n\n        create_kwargs = dict(\n            image=self.image,\n            environment=self.get_env(),\n            volumes=self.volume_mount_points,\n            name=self.container_name,\n            command=(await self.get_command()),\n        )\n        extra_create_kwargs = self._eval_if_callable(self.extra_create_kwargs)\n        if inspect.isawaitable(extra_create_kwargs):\n            extra_create_kwargs = await extra_create_kwargs\n        extra_create_kwargs = self._render_templates(extra_create_kwargs)\n        extra_host_config = self._eval_if_callable(self.extra_host_config)\n        if inspect.isawaitable(extra_host_config):\n            extra_host_config = await extra_host_config\n        extra_host_config = self._render_templates(extra_host_config)\n\n        # ensure internal port is exposed\n        create_kwargs[\"ports\"] = {\"%i/tcp\" % self.port: None}\n\n        _deep_merge(create_kwargs, extra_create_kwargs)\n\n        # build the dictionary of keyword arguments for host_config\n        host_config = dict(\n            auto_remove=self.remove,\n            binds=self.volume_binds,\n            links=self.links,\n            mounts=self.mount_binds,\n        )\n\n        if getattr(self, \"mem_limit\", None) is not None:\n            host_config[\"mem_limit\"] = self.mem_limit\n\n        if getattr(self, \"cpu_limit\", None) is not None:\n            # docker cpu units are in microseconds\n            # cpu_period default is 100ms\n            # cpu_quota is cpu_period * cpu_limit\n            cpu_period = host_config[\"cpu_period\"] = extra_host_config.get(\n                \"cpu_period\", 100_000\n            )\n            host_config[\"cpu_quota\"] = int(self.cpu_limit * cpu_period)\n\n        if not self.use_internal_ip:\n            host_config[\"port_bindings\"] = {self.port: (self.host_ip,)}\n        _deep_merge(host_config, extra_host_config)\n        host_config.setdefault(\"network_mode\", self.network_name)\n\n        self.log.debug(\"Starting host with config: %s\", host_config)\n\n        host_config = self.client.create_host_config(**host_config)\n        create_kwargs.setdefault(\"host_config\", {}).update(host_config)\n\n        # create the container\n        obj = await self.docker(\"create_container\", **create_kwargs)\n        return obj\n\n    async def start_object(self):\n        \"\"\"Actually start the container/service\n\n        e.g. calling ``docker start``\n        \"\"\"\n        await self.docker(\"start\", self.container_id)\n\n    async def stop_object(self):\n        \"\"\"Stop the container/service\n\n        e.g. calling ``docker stop``. Does not remove the container.\n        \"\"\"\n        try:\n            await self.docker(\"stop\", self.container_id)\n        except APIError as e:\n            if e.status_code == 404:\n                self.log.debug(\n                    \"Already removed %s: %s\", self.object_type, self.object_id\n                )\n                return\n            else:\n                raise\n\n    async def pull_image(self, image):\n        \"\"\"Pull the image, if needed\n\n        - pulls it unconditionally if pull_policy == 'always'\n        - skipped entirely if pull_policy == 'skip' (default for swarm)\n        - otherwise, checks if it exists, and\n          - raises if pull_policy == 'never'\n          - pulls if pull_policy == 'ifnotpresent'\n        \"\"\"\n        if self.pull_policy == \"skip\":\n            self.log.debug(f\"Skipping pull of {image}\")\n            return\n        # docker wants to split repo:tag\n        # the part split(\"/\")[-1] allows having an image from a custom repo\n        # with port but without tag. For example: my.docker.repo:51150/foo would not\n        # pass this test, resulting in image=my.docker.repo:51150/foo and tag=latest\n        if ':' in image.split(\"/\")[-1]:\n            # rsplit splits from right to left, allowing to have a custom image repo with port\n            repo, tag = image.rsplit(':', 1)\n        else:\n            repo = image\n            tag = 'latest'\n\n        if self.pull_policy.lower() == 'always':\n            # always pull\n            self.log.info(\"pulling %s\", image)\n            await self.docker('pull', repo, tag)\n            # done\n            return\n        try:\n            # check if the image is present\n            await self.docker('inspect_image', image)\n        except docker.errors.NotFound:\n            if self.pull_policy == \"never\":\n                # never pull, raise because there is no such image\n                raise\n            elif self.pull_policy == \"ifnotpresent\":\n                # not present, pull it for the first time\n                self.log.info(\"pulling image %s\", image)\n                await self.docker('pull', repo, tag)\n\n    async def start(self):\n        \"\"\"Start the single-user server in a docker container.\n\n        If the container exists and ``c.DockerSpawner.remove`` is ``True``, then\n        the container is removed first. Otherwise, the existing containers\n        will be restarted.\n        \"\"\"\n        # image priority:\n        # 1. user options (from spawn options form)\n        # 2. self.image from config\n        image_option = self.user_options.get('image')\n        if image_option:\n            # save choice in self.image\n            self.image = await self.check_allowed(image_option)\n\n        image = self.image\n        await self.pull_image(image)\n\n        obj = await self.get_object()\n        if obj and self.remove:\n            self.log.warning(\n                \"Removing %s that should have been cleaned up: %s (id: %s)\",\n                self.object_type,\n                self.object_name,\n                self.object_id[:7],\n            )\n            await self.remove_object()\n\n            obj = None\n\n        if obj is None:\n            obj = await self.create_object()\n            self.object_id = obj[self.object_id_key]\n            self.log.info(\n                \"Created %s %s (id: %s) from image %s\",\n                self.object_type,\n                self.object_name,\n                self.object_id[:7],\n                self.image,\n            )\n\n        else:\n            self.log.info(\n                \"Found existing %s %s (id: %s)\",\n                self.object_type,\n                self.object_name,\n                self.object_id[:7],\n            )\n            # Handle re-using API token.\n            # Get the API token from the environment variables\n            # of the running container:\n            for line in obj[\"Config\"][\"Env\"]:\n                if line.startswith((\"JPY_API_TOKEN=\", \"JUPYTERHUB_API_TOKEN=\")):\n                    self.api_token = line.split(\"=\", 1)[1]\n                    break\n\n        # TODO: handle unpause\n        self.log.info(\n            \"Starting %s %s (id: %s)\",\n            self.object_type,\n            self.object_name,\n            self.container_id[:7],\n        )\n\n        # start the container\n        await self.start_object()\n\n        if self.post_start_cmd:\n            await self.post_start_exec()\n\n        ip, port = await self.get_ip_and_port()\n        return (ip, port)\n\n    @property\n    def internal_hostname(self):\n        \"\"\"Return our hostname\n\n        used with internal SSL\n        \"\"\"\n        return self.container_name\n\n    async def get_ip_and_port(self):\n        \"\"\"Queries Docker daemon for container's IP and port.\n\n        If you are using network_mode=host, you will need to override\n        this method as follows::\n\n            async def get_ip_and_port(self):\n                return self.host_ip, self.port\n\n        You will need to make sure host_ip and port\n        are correct, which depends on the route to the container\n        and the port it opens.\n        \"\"\"\n        if self.use_internal_hostname:\n            # internal ssl uses hostnames,\n            # required for domain-name matching with internal SSL\n            # TODO: should we always do this?\n            # are there any cases where internal_ip works\n            # and internal_hostname doesn't?\n            ip = self.internal_hostname\n            port = self.port\n        elif self.use_internal_ip:\n            resp = await self.docker(\"inspect_container\", self.container_id)\n            network_settings = resp[\"NetworkSettings\"]\n            if \"Networks\" in network_settings:\n                ip = self.get_network_ip(network_settings)\n            else:  # Fallback for old versions of docker (<1.9) without network management\n                ip = network_settings[\"IPAddress\"]\n            port = self.port\n        else:\n            resp = await self.docker(\"port\", self.container_id, self.port)\n            if resp is None:\n                raise RuntimeError(\"Failed to get port info for %s\" % self.container_id)\n\n            ip = resp[0][\"HostIp\"]\n            port = int(resp[0][\"HostPort\"])\n\n        if ip == \"0.0.0.0\":\n            ip = urlparse(self.client.base_url).hostname\n            if ip == \"localnpipe\":\n                ip = \"localhost\"\n\n        return ip, port\n\n    def get_network_ip(self, network_settings):\n        networks = network_settings[\"Networks\"]\n        if self.network_name not in networks:\n            raise Exception(\n                \"Unknown docker network '{network}'.\"\n                \" Did you create it with `docker network create <name>`?\".format(\n                    network=self.network_name\n                )\n            )\n\n        network = networks[self.network_name]\n        ip = network[\"IPAddress\"]\n        return ip\n\n    async def stop(self, now=False):\n        \"\"\"Stop the container\n\n        Will remove the container if ``c.DockerSpawner.remove`` is ``True``.\n\n        Consider using pause/unpause when docker-py adds support.\n        \"\"\"\n        self.log.info(\n            \"Stopping %s %s (id: %s)\",\n            self.object_type,\n            self.object_name,\n            self.object_id[:7],\n        )\n        await self.stop_object()\n\n        if self.remove:\n            await self.remove_object()\n            # clear object_id to avoid persisting removed state\n            self.object_id = \"\"\n\n        self.clear_state()\n\n    def _volumes_to_binds(self, volumes, binds, mode=\"rw\"):\n        \"\"\"Extract the volume mount points from volumes property.\n\n        Returns a dict of dict entries of the form::\n\n            {'/host/dir': {'bind': '/guest/dir': 'mode': 'rw'}}\n        \"\"\"\n\n        def _fmt(v):\n            return self.format_volume_name(v, self)\n\n        for k, v in volumes.items():\n            m = mode\n            if isinstance(v, dict):\n                if \"mode\" in v:\n                    m = v[\"mode\"]\n                v = v[\"bind\"]\n            binds[_fmt(k)] = {\"bind\": _fmt(v), \"mode\": m}\n        return binds\n\n    def _render_templates(self, obj, ns=None):\n        \"\"\"Recursively render template strings\n\n        Dives down into dicts, lists, tuples\n        and applies template formatting on all strings found in:\n        - list or tuple items\n        - dict keys or values\n\n        Always returns the original object structure.\n        \"\"\"\n        if ns is None:\n            ns = self.template_namespace()\n\n        _fmt = partial(self._render_templates, ns=ns)\n\n        if isinstance(obj, str):\n            try:\n                return obj.format(**ns)\n            except (ValueError, KeyError):\n                # not a valid format string\n                # to avoid crashing leave invalid templates unrendered\n                # otherwise, this unconditional formatting would not allow\n                # strings with `{` characters in them\n                return obj\n        elif isinstance(obj, dict):\n            return {_fmt(key): _fmt(value) for key, value in obj.items()}\n        elif isinstance(obj, (list, tuple)):\n            return type(obj)([_fmt(item) for item in obj])\n        else:\n            return obj\n\n\ndef _deprecated_method(old_name, new_name, version):\n    \"\"\"Create a deprecated method wrapper for a deprecated method name\"\"\"\n\n    def deprecated(self, *args, **kwargs):\n        warnings.warn(\n            (\n                \"{cls}.{old_name} is deprecated in DockerSpawner {version}.\"\n                \" Please use {cls}.{new_name} instead.\"\n            ).format(\n                cls=self.__class__.__name__,\n                old_name=old_name,\n                new_name=new_name,\n                version=version,\n            ),\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        old_method = getattr(self, new_name)\n        return old_method(*args, **kwargs)\n\n    return deprecated\n\n\n# deprecate white/blacklist method names\nfor _old_name, _new_name, _version in [\n    (\"check_image_whitelist\", \"check_allowed\", \"12.0\")\n]:\n    setattr(\n        DockerSpawner,\n        _old_name,\n        _deprecated_method(_old_name, _new_name, _version),\n    )\n", "# Changes in DockerSpawner\n\nFor detailed changes from the prior release, click on the version number, and\nits link will bring up a GitHub listing of changes. Use `git log` on the\ncommand line for details.\n\n## [Unreleased]\n\n## 13\n\n### [13.0] 2023-11-21\n\n([full changelog](https://github.com/jupyterhub/dockerspawner/compare/12.1.0...13.0.0))\n\n13.0 Fixes security vulnerability GHSA-hfgr-h3vc-p6c2, which allowed authenticated users to spawn arbitrary images\nunless `DockerSpawner.allowed_images` was specified.\n\n#### API and Breaking Changes\n\n- Add and require `DockerSpawner.allowed_images='*'` to allow any image to be spawned via `user_options`. (GHSA-hfgr-h3vc-p6c2)\n- Remove deprecated, broken hub_ip_connect [#499](https://github.com/jupyterhub/dockerspawner/pull/499) ([@minrk](https://github.com/minrk))\n- Require python 3.8+ and jupyterhub 2.3.1+ [#488](https://github.com/jupyterhub/dockerspawner/pull/488) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n\n#### New features added\n\n- Switch default image to quay.io [#504](https://github.com/jupyterhub/dockerspawner/pull/504) ([@yuvipanda](https://github.com/yuvipanda), [@minrk](https://github.com/minrk), [@manics](https://github.com/manics))\n- allow extra_host_config and extra_create_kwargs to be callable [#500](https://github.com/jupyterhub/dockerspawner/pull/500) ([@minrk](https://github.com/minrk))\n\n#### Enhancements made\n\n- Merge host config/create_kwargs [#501](https://github.com/jupyterhub/dockerspawner/pull/501) ([@minrk](https://github.com/minrk))\n\n#### Bugs fixed\n\n- update object_name with current image [#466](https://github.com/jupyterhub/dockerspawner/pull/466) ([@floriandeboissieu](https://github.com/floriandeboissieu), [@minrk](https://github.com/minrk))\n- Fix imagename not to include letter ':' [#464](https://github.com/jupyterhub/dockerspawner/pull/464) ([@yamaton](https://github.com/yamaton), [@minrk](https://github.com/minrk))\n- clear object_id when removing object [#447](https://github.com/jupyterhub/dockerspawner/pull/447) ([@minrk](https://github.com/minrk), [@manics](https://github.com/manics))\n\n#### Maintenance and upkeep improvements\n\n- pre-commit: add pyupgrade and autoflake, simplify flake8 config [#489](https://github.com/jupyterhub/dockerspawner/pull/489) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n- Require python 3.8+ and jupyterhub 2.3.1+ [#488](https://github.com/jupyterhub/dockerspawner/pull/488) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n- Add dependabot.yaml to bump github actions [#487](https://github.com/jupyterhub/dockerspawner/pull/487) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n- Update release workflow and RELEASE.md, set version with tbump [#486](https://github.com/jupyterhub/dockerspawner/pull/486) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n- Refresh test workflow and associated config, accept podmain test failure for now [#485](https://github.com/jupyterhub/dockerspawner/pull/485) ([@consideRatio](https://github.com/consideRatio), [@minrk](https://github.com/minrk))\n- Use python 3.11 on RTD [#482](https://github.com/jupyterhub/dockerspawner/pull/482) ([@minrk](https://github.com/minrk))\n- Add test strategy for JupyterHub v3.1.1 [#479](https://github.com/jupyterhub/dockerspawner/pull/479) ([@Sheila-nk](https://github.com/Sheila-nk), [@GeorgianaElena](https://github.com/GeorgianaElena), [@minrk](https://github.com/minrk))\n- test options_form and escape [#468](https://github.com/jupyterhub/dockerspawner/pull/468) ([@Sheila-nk](https://github.com/Sheila-nk), [@minrk](https://github.com/minrk))\n- test callable allowed_images and host_ip [#467](https://github.com/jupyterhub/dockerspawner/pull/467) ([@Sheila-nk](https://github.com/Sheila-nk), [@minrk](https://github.com/minrk))\n- Test jupyterhub2 [#443](https://github.com/jupyterhub/dockerspawner/pull/443) ([@manics](https://github.com/manics), [@minrk](https://github.com/minrk))\n\n#### Documentation improvements\n\n- Add extra_create_kwargs example, plus docs readability improvements [#493](https://github.com/jupyterhub/dockerspawner/pull/493) ([@matthewwiese](https://github.com/matthewwiese), [@manics](https://github.com/manics))\n- update versions in swarm example [#454](https://github.com/jupyterhub/dockerspawner/pull/454) ([@minrk](https://github.com/minrk), [@GeorgianaElena](https://github.com/GeorgianaElena))\n- add generate-certs service to internal-ssl example [#446](https://github.com/jupyterhub/dockerspawner/pull/446) ([@minrk](https://github.com/minrk), [@manics](https://github.com/manics))\n- Add Podman to docs [#444](https://github.com/jupyterhub/dockerspawner/pull/444) ([@manics](https://github.com/manics), [@minrk](https://github.com/minrk))\n\n#### Contributors to this release\n\nThe following people contributed discussions, new ideas, code and documentation contributions, and review.\nSee [our definition of contributors](https://github-activity.readthedocs.io/en/latest/#how-does-this-tool-define-contributions-in-the-reports).\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/dockerspawner/graphs/contributors?from=2021-07-22&to=2023-11-20&type=c))\n\n@consideRatio ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AconsideRatio+updated%3A2021-07-22..2023-11-20&type=Issues)) | @floriandeboissieu ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Afloriandeboissieu+updated%3A2021-07-22..2023-11-20&type=Issues)) | @gatoniel ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Agatoniel+updated%3A2021-07-22..2023-11-20&type=Issues)) | @GeorgianaElena ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AGeorgianaElena+updated%3A2021-07-22..2023-11-20&type=Issues)) | @manics ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amanics+updated%3A2021-07-22..2023-11-20&type=Issues)) | @matthewwiese ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amatthewwiese+updated%3A2021-07-22..2023-11-20&type=Issues)) | @minrk ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aminrk+updated%3A2021-07-22..2023-11-20&type=Issues)) | @Sheila-nk ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3ASheila-nk+updated%3A2021-07-22..2023-11-20&type=Issues)) | @yamaton ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ayamaton+updated%3A2021-07-22..2023-11-20&type=Issues)) | @yuvipanda ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ayuvipanda+updated%3A2021-07-22..2023-11-20&type=Issues))\n\n## 12\n\n### [12.1] 2021-07-22\n\n([full changelog](https://github.com/jupyterhub/dockerspawner/compare/12.0.0...12.1.0))\n\n#### Enhancements made\n\n- support cpu limit via cpu_quota / cpu_period [#435](https://github.com/jupyterhub/dockerspawner/pull/435) ([@minrk](https://github.com/minrk))\n- Log post_start exec output [#427](https://github.com/jupyterhub/dockerspawner/pull/427) ([@minrk](https://github.com/minrk))\n- Allow to specify a callable for `mem_limit` [#420](https://github.com/jupyterhub/dockerspawner/pull/420) ([@zeehio](https://github.com/zeehio))\n\n#### Maintenance and upkeep improvements\n\n- update release steps for main branch [#434](https://github.com/jupyterhub/dockerspawner/pull/434) ([@minrk](https://github.com/minrk))\n- more debug info from docker when tests fail [#433](https://github.com/jupyterhub/dockerspawner/pull/433) ([@minrk](https://github.com/minrk))\n\n#### Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/dockerspawner/graphs/contributors?from=2021-03-26&to=2021-07-19&type=c))\n\n[@1kastner](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3A1kastner+updated%3A2021-03-26..2021-07-19&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amanics+updated%3A2021-03-26..2021-07-19&type=Issues) | [@minrk](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aminrk+updated%3A2021-03-26..2021-07-19&type=Issues) | [@welcome](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Awelcome+updated%3A2021-03-26..2021-07-19&type=Issues) | [@zeehio](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Azeehio+updated%3A2021-03-26..2021-07-19&type=Issues)\n\n### [12.0] 2021-03-26\n\nThis is a big release!\n\nSeveral bugs have been fixed, especially in SwarmSpawner, and more configuration options added.\n\n#### New escaping scheme\n\nIn particular, the biggest backward-incompatible change to highlight\nis the container (and volume) name escaping scheme now produces DNS-safe results, which matches the behavior of kubespawner.\nThis is a stricter subset of characters than docker containers strictly require,\nbut many features don't work right without it.\nThe result is for certain user names and/or server names, their container and/or volume names will change.\nUpgrading existing deployments will result in disconnecting these users from their running containers and volumes, which means:\n\n- if there are running users across the upgrade,\n  some containers will need to be manually stopped\n- some volumes may need to be renamed, which [docker doesn't support](https://github.com/moby/moby/issues/31154),\n  but [can be done](https://github.com/moby/moby/issues/31154#issuecomment-360531460):\n\n  ```bash\n  docker volume create --name $new_volume\n  docker run --rm -it -v $old_volume:/from -v $new_volume:/to alpine ash -c \"cd /from ; cp -av . /to\"\n  docker volume rm $old_volume\n  ```\n\nThe main differences are:\n\n- The escape character is `-` instead of `_` which means `-` cannot itself be a safe character and must be escaped to `-2d`\n- Uppercase characters are now escaped (normalizing to lowercase at the username level is common)\n\nSo affected usernames are those with `-` or uppercase letters, or any that already needed escaping.\n\nYou can restore the pre-12.0 behavior with:\n\n```python\nc.DockerSpawner.escape = \"legacy\"\n```\n\n#### SystemUserSpawner.run_as_root\n\nAnother security-related change is the addition of `SystemUserSpawner.run_as_root`.\nPrior to 12.0, SystemUserSpawner always ran as root and relied on the container to use $NB_USER and $NB_UID to \"become\" the user.\nThis behavior meant that user containers based on images that lacked this behavior would all run as root.\nTo address this, `run_as_root` behavior is now opt-in\n\nAll changes are detailed below.\n\n([full changelog](https://github.com/jupyterhub/dockerspawner/compare/0.11.1...12.0.0))\n\n#### New features added\n\n- apply template formatting to all of extra_create_kwargs, extra_host_config [#409](https://github.com/jupyterhub/dockerspawner/pull/409) ([@minrk](https://github.com/minrk))\n- Add mounts option for more advanced binds [#406](https://github.com/jupyterhub/dockerspawner/pull/406) ([@minrk](https://github.com/minrk))\n- Add JUPYTER_IMAGE_SPEC to env. [#316](https://github.com/jupyterhub/dockerspawner/pull/316) ([@danielballan](https://github.com/danielballan))\n- Added post_start_cmd [#307](https://github.com/jupyterhub/dockerspawner/pull/307) ([@mohirio](https://github.com/mohirio))\n\n#### Enhancements made\n\n- Use default cmd=None to indicate using the image command [#415](https://github.com/jupyterhub/dockerspawner/pull/415) ([@minrk](https://github.com/minrk))\n- add 'skip' option for pull_policy [#411](https://github.com/jupyterhub/dockerspawner/pull/411) ([@minrk](https://github.com/minrk))\n- Add auto_remove to host_config [#318](https://github.com/jupyterhub/dockerspawner/pull/318) ([@jtpio](https://github.com/jtpio))\n- Make default name_template compatible with named servers. [#315](https://github.com/jupyterhub/dockerspawner/pull/315) ([@danielballan](https://github.com/danielballan))\n- SystemUserSpawner: Pass group id to the container [#304](https://github.com/jupyterhub/dockerspawner/pull/304) ([@zeehio](https://github.com/zeehio))\n- Allow lookup of host homedir via `pwd` [#302](https://github.com/jupyterhub/dockerspawner/pull/302) ([@AdrianoKF](https://github.com/AdrianoKF))\n\n#### Bugs fixed\n\n- (PATCH) SwarmSpawner, InvalidArgument: Incompatible options have been provided for the bind type mount. [#419](https://github.com/jupyterhub/dockerspawner/pull/419) ([@cmotadev](https://github.com/cmotadev))\n- Make sure that create_object() creates the service task [#396](https://github.com/jupyterhub/dockerspawner/pull/396) ([@girgink](https://github.com/girgink))\n- avoid name collisions when using named servers [#386](https://github.com/jupyterhub/dockerspawner/pull/386) ([@minrk](https://github.com/minrk))\n- Fix issue with pulling images from custom repos that contain a port [#334](https://github.com/jupyterhub/dockerspawner/pull/334) ([@raethlein](https://github.com/raethlein))\n\n#### Maintenance and upkeep improvements\n\n- async/await [#417](https://github.com/jupyterhub/dockerspawner/pull/417) ([@minrk](https://github.com/minrk))\n- stop building docs on circleci [#387](https://github.com/jupyterhub/dockerspawner/pull/387) ([@minrk](https://github.com/minrk))\n- Test with latest jh [#379](https://github.com/jupyterhub/dockerspawner/pull/379) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n- Fix RTD build [#378](https://github.com/jupyterhub/dockerspawner/pull/378) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n- Add release instructions and Travis deploy [#377](https://github.com/jupyterhub/dockerspawner/pull/377) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n- Fix tests [#374](https://github.com/jupyterhub/dockerspawner/pull/374) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n- Add README badges [#356](https://github.com/jupyterhub/dockerspawner/pull/356) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n\n#### Documentation improvements\n\n- Update swarm example [#418](https://github.com/jupyterhub/dockerspawner/pull/418) ([@minrk](https://github.com/minrk))\n- improve robustness of internal-ssl example [#416](https://github.com/jupyterhub/dockerspawner/pull/416) ([@minrk](https://github.com/minrk))\n- update versions in docker-image docs [#410](https://github.com/jupyterhub/dockerspawner/pull/410) ([@minrk](https://github.com/minrk))\n- Add GitHub Action readme badge [#408](https://github.com/jupyterhub/dockerspawner/pull/408) ([@consideRatio](https://github.com/consideRatio))\n- Switch CI to GitHub actions [#407](https://github.com/jupyterhub/dockerspawner/pull/407) ([@minrk](https://github.com/minrk))\n- touch up simple example [#405](https://github.com/jupyterhub/dockerspawner/pull/405) ([@minrk](https://github.com/minrk))\n- add example for selecting arbitrary image via options_form [#401](https://github.com/jupyterhub/dockerspawner/pull/401) ([@minrk](https://github.com/minrk))\n- Typo fix in the docs [#380](https://github.com/jupyterhub/dockerspawner/pull/380) ([@jtpio](https://github.com/jtpio))\n- Add docs [#375](https://github.com/jupyterhub/dockerspawner/pull/375) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n- Fix dead link in doc [#350](https://github.com/jupyterhub/dockerspawner/pull/350) ([@JocelynDelalande](https://github.com/JocelynDelalande))\n- Fix project name typo [#339](https://github.com/jupyterhub/dockerspawner/pull/339) ([@kinow](https://github.com/kinow))\n\n#### API and Breaking Changes\n\n- Make escaping DNS-safe [#414](https://github.com/jupyterhub/dockerspawner/pull/414) ([@minrk](https://github.com/minrk))\n- add SystemUserSpawner.run_as_root [#412](https://github.com/jupyterhub/dockerspawner/pull/412) ([@minrk](https://github.com/minrk))\n- Rename DockerSpawner.image_whitelist to allowed_images [#381](https://github.com/jupyterhub/dockerspawner/pull/381) ([@GeorgianaElena](https://github.com/GeorgianaElena))\n\n#### Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/dockerspawner/graphs/contributors?from=2019-04-25&to=2021-03-24&type=c))\n\n[@1kastner](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3A1kastner+updated%3A2019-04-25..2021-03-24&type=Issues) | [@AdrianoKF](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AAdrianoKF+updated%3A2019-04-25..2021-03-24&type=Issues) | [@anmtan](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aanmtan+updated%3A2019-04-25..2021-03-24&type=Issues) | [@AnubhavUjjawal](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AAnubhavUjjawal+updated%3A2019-04-25..2021-03-24&type=Issues) | [@belfhi](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Abelfhi+updated%3A2019-04-25..2021-03-24&type=Issues) | [@bellackn](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Abellackn+updated%3A2019-04-25..2021-03-24&type=Issues) | [@bjornandre](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Abjornandre+updated%3A2019-04-25..2021-03-24&type=Issues) | [@blacksailer](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ablacksailer+updated%3A2019-04-25..2021-03-24&type=Issues) | [@cblomart](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Acblomart+updated%3A2019-04-25..2021-03-24&type=Issues) | [@choldgraf](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Acholdgraf+updated%3A2019-04-25..2021-03-24&type=Issues) | [@cmotadev](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Acmotadev+updated%3A2019-04-25..2021-03-24&type=Issues) | [@cmseal](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Acmseal+updated%3A2019-04-25..2021-03-24&type=Issues) | [@co60ca](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aco60ca+updated%3A2019-04-25..2021-03-24&type=Issues) | [@consideRatio](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AconsideRatio+updated%3A2019-04-25..2021-03-24&type=Issues) | [@cyliu0204](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Acyliu0204+updated%3A2019-04-25..2021-03-24&type=Issues) | [@danielballan](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Adanielballan+updated%3A2019-04-25..2021-03-24&type=Issues) | [@danlester](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Adanlester+updated%3A2019-04-25..2021-03-24&type=Issues) | [@efagerberg](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aefagerberg+updated%3A2019-04-25..2021-03-24&type=Issues) | [@gatoniel](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Agatoniel+updated%3A2019-04-25..2021-03-24&type=Issues) | [@GeorgianaElena](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AGeorgianaElena+updated%3A2019-04-25..2021-03-24&type=Issues) | [@girgink](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Agirgink+updated%3A2019-04-25..2021-03-24&type=Issues) | [@hugoJuhel](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AhugoJuhel+updated%3A2019-04-25..2021-03-24&type=Issues) | [@jameholme](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ajameholme+updated%3A2019-04-25..2021-03-24&type=Issues) | [@jamesdbrock](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ajamesdbrock+updated%3A2019-04-25..2021-03-24&type=Issues) | [@JocelynDelalande](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AJocelynDelalande+updated%3A2019-04-25..2021-03-24&type=Issues) | [@jtpio](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ajtpio+updated%3A2019-04-25..2021-03-24&type=Issues) | [@kinow](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Akinow+updated%3A2019-04-25..2021-03-24&type=Issues) | [@kkr78](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Akkr78+updated%3A2019-04-25..2021-03-24&type=Issues) | [@ltupin](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Altupin+updated%3A2019-04-25..2021-03-24&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amanics+updated%3A2019-04-25..2021-03-24&type=Issues) | [@mathematicalmichael](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amathematicalmichael+updated%3A2019-04-25..2021-03-24&type=Issues) | [@meeseeksmachine](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ameeseeksmachine+updated%3A2019-04-25..2021-03-24&type=Issues) | [@minrk](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aminrk+updated%3A2019-04-25..2021-03-24&type=Issues) | [@missingcharacter](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amissingcharacter+updated%3A2019-04-25..2021-03-24&type=Issues) | [@mohirio](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amohirio+updated%3A2019-04-25..2021-03-24&type=Issues) | [@myurasov](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Amyurasov+updated%3A2019-04-25..2021-03-24&type=Issues) | [@nazeels](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Anazeels+updated%3A2019-04-25..2021-03-24&type=Issues) | [@nmvega](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Anmvega+updated%3A2019-04-25..2021-03-24&type=Issues) | [@nuraym](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Anuraym+updated%3A2019-04-25..2021-03-24&type=Issues) | [@parente](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Aparente+updated%3A2019-04-25..2021-03-24&type=Issues) | [@raethlein](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Araethlein+updated%3A2019-04-25..2021-03-24&type=Issues) | [@sabuhish](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Asabuhish+updated%3A2019-04-25..2021-03-24&type=Issues) | [@sangramga](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Asangramga+updated%3A2019-04-25..2021-03-24&type=Issues) | [@support](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Asupport+updated%3A2019-04-25..2021-03-24&type=Issues) | [@TimoRoth](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3ATimoRoth+updated%3A2019-04-25..2021-03-24&type=Issues) | [@vlizanae](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Avlizanae+updated%3A2019-04-25..2021-03-24&type=Issues) | [@welcome](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Awelcome+updated%3A2019-04-25..2021-03-24&type=Issues) | [@Wildcarde](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3AWildcarde+updated%3A2019-04-25..2021-03-24&type=Issues) | [@willingc](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Awillingc+updated%3A2019-04-25..2021-03-24&type=Issues) | [@wwj718](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Awwj718+updated%3A2019-04-25..2021-03-24&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Ayuvipanda+updated%3A2019-04-25..2021-03-24&type=Issues) | [@z3ky](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Az3ky+updated%3A2019-04-25..2021-03-24&type=Issues) | [@zeehio](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Azeehio+updated%3A2019-04-25..2021-03-24&type=Issues) | [@zhiyuli](https://github.com/search?q=repo%3Ajupyterhub%2Fdockerspawner+involves%3Azhiyuli+updated%3A2019-04-25..2021-03-24&type=Issues)\n\n## 0.11\n\n### [0.11.1] - 2019-04-25\n\n- Fix some compatibility issues\n- Add more states to be recognized as pending for SwarmSpawner\n\n### [0.11.0] - 2019-03-01\n\n#### New features:\n\n- Support selecting docker spawner via JupyterHub 1.0's entrypoints:\n\n  ```python\n  c.JupyterHub.spawner_class = 'docker' # or 'docker-swarm' or 'docker-system-user'\n  ```\n\n- Support total internal SSL encryption with JupyterHub 1.0\n- Add new `DockerSpawner.pull_policy` to configure pulling of images.\n  Values are inspired by Kubernetes, and case-insensitive. Can be any of\n  \"IfNotPresent\" (new default), \"Always\", and \"Never\" (pre-0.11 behavior).\n  Now the image will be pulled by default if it is not present.\n- Add `image_whitelist` configuration which, if set, defines a default options\n  form for users to pick the desired image.\n  `image_whitelist` is a dict of `{'descriptive key': 'image:tag'}`.\n- Add `SwarmSpawner.extra_placement_spec` configuration for setting service placement\n\n#### Fixes:\n\n- Slow startup in SwarmSpawner could be treated as failures.\n\n## 0.10\n\n### [0.10.0] - 2018-09-03\n\n- Add `dockerspawner.SwarmSpawner` for spawning with Docker Swarm\n- Removed deprecated `extra_start_kwargs`\n- `host_ip` is configurable\n- Added `container_name_template` configuration for custom container naming\n\n## 0.9\n\n### [0.9.1] - 2017-08-23\n\n- Fix typo which would cause using the deprecated `.hub_ip_connect` configuration\n  with JupyterHub 0.8 to crash instead of warn in 0.9.0.\n\n### [0.9.0] - 2017-08-20\n\n0.9 cleans up some configuration and improves support for the transition from JupyterHub 0.8 to 0.9.\nIt also reduces some of the special arguments and env handling,\nallowing for more consistency with other Spawners,\nand fewer assumptions about the image that will be used by the Spawner.\n\nThe following is a minimal Dockerfile that works with DockerSpawner 0.9 and JupyterHub 0.7.2:\n\n```Dockerfile\nFROM python:3.6\nRUN pip install \\\n    jupyterhub==0.8.0 \\\n    'notebook==5.0.0'\n\n# Don't want to run as root!\nRUN useradd -m jovyan\nENV HOME=/home/jovyan\nWORKDIR $HOME\nUSER jovyan\n\nCMD [\"jupyterhub-singleuser\"]\n```\n\nIn particular:\n\n- any image with the correct version of JupyterHub installed (it should match JupyterHub) should work with DockerSpawner.\n- any image **based on one of the [jupyter/docker-stacks][]** should work with SystemUserSpawner.\n  There is no longer any need for the `jupyterhub/systemuser` docker image.\n- The jupyterhub/singleuser image is now built from the JupyterHub repo, not this one.\n- `jupyterhub/systemuser` image is deprecated.\n  `jupyterhub/systemuser` launches containers as root and relies on\n  the `NB_UID` and `NB_GID` handling of `jupyter/docker-stacks` to setup the user.\n- The default `jupyterhub/singleuser` image has tags for JupyterHub versions,\n  to ensure image compatibility with JupyterHub.\n  The default image is now `jupyterhub/singleuser:x.y`, where `x.y` is the major.minor version of\n  the current JupyterHub instance,\n  so DockerSpawner should work by default with JupyterHub 0.7 or 0.8\n  without needing to specify the image.\n- `Spawner.cmd` config is now supported, which can be used to override the CMD arg.\n  By default, the image's CMD is used.\n- `Spawner.get_args()` behavior is now properly inherited,\n  and args are appended to the spawn command as in other Spawners.\n- Arguments are now passed via `.get_args()` as in the base Spawner,\n  rather than custom environment variables which user images had to support.\n- `DockerSpawner.hub_ip_connect` is deprecated when running with JupyterHub 0.8.\n  Use `JupyterHub.hub_connect_ip` instead, which is used by all Spawners.\n\nSome configuration has been cleaned up to be clearer and more concise:\n\n- `DockerSpawner.container_image` is deprecated in favor of `DockerSpawner.image`.\n- `DockerSpawner.container_port` is deprecated in favor of existing `Spawner.port`.\n- Inaccurately named `DockerSpawner.container_ip` is deprecated in favor of `DockerSpawner.host_ip`\n  because it configures the host IP forwarded to the container.\n\n[jupyter/docker-stacks]: https://github.com/jupyter/docker-stacks\n\n## [0.8] - 2017-07-28\n\n- experimental fixes for running on Windows\n- added `DockerSpawner.client_kwargs` config to passthrough to the `docker.Client` constructor\n- workaround bug where Docker can report ports as strings\n- bump docker dependency to new `docker` package from `docker-py`\n\n## [0.7] - 2017-03-14\n\n- Only need to set `DockerSpawner.network_name` to run on a docker network,\n  instead of setting `host_config`, `network_name`, and `use_internal_ip` separately.\n- Set `mem_limit` on `host_config` for docker API 1.19\n- Match start keyword args on SystemUserSpawner to DockerSpawner\n\n## [0.6] - 2017-01-02\n\n- Add `DockerSpawner.format_volume_name` for custom naming strategies for mounted volumes.\n- Support `mem_limit` config introduced in JupyterHub 0.7.\n- Support `will_resume` flag necessary for resuming containers with\n  `DockerSpawner.remove_containers = False` and JupyterHub 0.7\n  (requires JupyterHub 0.7.1).\n\n## [0.5] - 2016-10-05\n\n- return ip, port from `DockerSpawner.start`, for future-compatibility (setting ip, port directly is deprecated in JupyterHub 0.7).\n- Support `{username}` in volume_mounts\n\n## [0.4] - 2016-06-07\n\n- get singleuser script from jupyterhub 0.6.1 (0.7 will require jupyterhub package to run singleuser script)\n- `get_ip_and_port()` is a tornado coroutine, rather than an asyncio coroutine, for consistency with the rest of the code.\n- more configuration for ports and mounts\n\n## [0.3] - 2016-04-22\n\n- Moved to jupyterhub org (`jupyterhub/singleuser`, `jupyterhub/systemuser` on Docker)\n- Add `rebase-singleuser` tool for building new single-user images on top of different bases\n- Base default docker images on `jupyter/scipy-notebook` from jupyter/docker-stacks\n- Fix environment setup to use `get_env` instead of `_env_default` (Needed for JupyterHub 0.5)\n\n## [0.2] - 2016-02-16\n\n- Add `DockerSpawner.links`\n- Use HostIp from docker port output\n- Make user home string template configurable\n\n## 0.1 - 2016-02-03\n\nFirst release\n\n[unreleased]: https://github.com/jupyterhub/dockerspawner/compare/13.0.0...HEAD\n[13.0]: https://github.com/jupyterhub/dockerspawner/compare/12.1.0...13.0.0\n[12.1]: https://github.com/jupyterhub/dockerspawner/compare/12.0.0...12.1.0\n[12.0]: https://github.com/jupyterhub/dockerspawner/compare/0.11.1...12.0.0\n[0.11.1]: https://github.com/jupyterhub/dockerspawner/compare/0.11.0...0.11.1\n[0.11.0]: https://github.com/jupyterhub/dockerspawner/compare/0.10.0...0.11.0\n[0.10.0]: https://github.com/jupyterhub/dockerspawner/compare/0.9.1...0.10.0\n[0.9.1]: https://github.com/jupyterhub/dockerspawner/compare/0.9.0...0.9.1\n[0.9.0]: https://github.com/jupyterhub/dockerspawner/compare/0.8.0...0.9.0\n[0.8]: https://github.com/jupyterhub/dockerspawner/compare/0.7.0...0.8.0\n[0.7]: https://github.com/jupyterhub/dockerspawner/compare/0.6.0...0.7.0\n[0.6]: https://github.com/jupyterhub/dockerspawner/compare/0.5.0...0.6.0\n[0.5]: https://github.com/jupyterhub/dockerspawner/compare/0.4.0...0.5.0\n[0.4]: https://github.com/jupyterhub/dockerspawner/compare/0.3.0...0.4.0\n[0.3]: https://github.com/jupyterhub/dockerspawner/compare/0.2.0...0.3.0\n[0.2]: https://github.com/jupyterhub/dockerspawner/compare/0.1.0...0.2.0\n", "c = get_config()  # noqa\n\n\noptions_form_tpl = \"\"\"\n<label for=\"image\">Image</label>\n<input name=\"image\" class=\"form-control\" placeholder=\"the image to launch (default: {default_image})\"></input>\n\"\"\"\n\n\ndef get_options_form(spawner):\n    return options_form_tpl.format(default_image=spawner.image)\n\n\nc.DockerSpawner.options_form = get_options_form\n\n# specify that DockerSpawner should accept any image from user input\nc.DockerSpawner.allowed_images = \"*\"\n\n# tell JupyterHub to use DockerSpawner\nc.JupyterHub.spawner_class = \"docker\"\n\n# the rest of the config is testing boilerplate\n# to make the Hub connectable from the containers\n\n# dummy for testing. Don't use this in production!\nc.JupyterHub.authenticator_class = \"dummy\"\n# while using dummy auth, make the *public* (proxy) interface private\nc.JupyterHub.ip = \"127.0.0.1\"\n\n# we need the hub to listen on all ips when it is in a container\nc.JupyterHub.hub_ip = \"0.0.0.0\"\n\n# may need to set hub_connect_ip to be connectable to containers\n# default hostname behavior usually works, though\n# c.JupyterHub.hub_connect_ip\n\n# pick a default image to use when none is specified\nc.DockerSpawner.image = \"jupyter/base-notebook\"\n\n# delete containers when they stop\nc.DockerSpawner.remove = True\n", "\"\"\"pytest config for dockerspawner tests\"\"\"\nimport inspect\nimport json\nimport os\nfrom textwrap import indent\nfrom unittest import mock\n\nimport jupyterhub\nimport netifaces\nimport pytest\nfrom docker import from_env as docker_from_env\nfrom docker.errors import APIError\nfrom jupyterhub import version_info as jh_version_info\nfrom jupyterhub.tests.conftest import app as jupyterhub_app  # noqa: F401\nfrom jupyterhub.tests.conftest import event_loop  # noqa: F401\nfrom jupyterhub.tests.conftest import io_loop  # noqa: F401\nfrom jupyterhub.tests.conftest import ssl_tmpdir  # noqa: F401\nfrom jupyterhub.tests.conftest import user  # noqa: F401\nfrom jupyterhub.tests.mocking import MockHub\n\nfrom dockerspawner import DockerSpawner, SwarmSpawner, SystemUserSpawner\n\n# import base jupyterhub fixtures\n\n# make Hub connectable from docker by default\n# do this here because the `app` fixture has already loaded configuration\nMockHub.hub_ip = \"0.0.0.0\"\n\nif os.environ.get(\"HUB_CONNECT_IP\"):\n    MockHub.hub_connect_ip = os.environ[\"HUB_CONNECT_IP\"]\nelse:\n    # get docker interface explicitly by default\n    # on GHA, the ip for hostname resolves to a 10.x\n    # address that is not connectable from within containers\n    # but the docker0 address is connectable\n    docker_interfaces = sorted(\n        iface for iface in netifaces.interfaces() if 'docker' in iface\n    )\n    if docker_interfaces:\n        iface = docker_interfaces[0]\n        print(f\"Found docker interfaces: {docker_interfaces}, using {iface}\")\n        MockHub.hub_connect_ip = netifaces.ifaddresses(docker_interfaces[0])[\n            netifaces.AF_INET\n        ][0]['addr']\n\n\ndef pytest_collection_modifyitems(items):\n    \"\"\"This function is automatically run by pytest passing all collected test\n    functions.\n\n    We use it to add asyncio marker to all async tests and assert we don't use\n    test functions that are async generators which wouldn't make sense.\n    \"\"\"\n    for item in items:\n        if inspect.iscoroutinefunction(item.obj):\n            item.add_marker('asyncio')\n        assert not inspect.isasyncgenfunction(item.obj)\n\n\n@pytest.fixture\ndef app(jupyterhub_app):  # noqa: F811\n    app = jupyterhub_app\n    app.config.DockerSpawner.prefix = \"dockerspawner-test\"\n    # If it's a prerelease e.g. (2, 0, 0, 'rc4', '') use full tag\n    if len(jh_version_info) > 3 and jh_version_info[3]:\n        tag = jupyterhub.__version__\n        app.config.DockerSpawner.image = f\"quay.io/jupyterhub/singleuser:{tag}\"\n    return app\n\n\n@pytest.fixture\ndef named_servers(app):\n    with mock.patch.dict(\n        app.tornado_settings,\n        {\"allow_named_servers\": True, \"named_server_limit_per_user\": 2},\n    ):\n        yield\n\n\n@pytest.fixture\ndef dockerspawner_configured_app(app, named_servers):\n    \"\"\"Configure JupyterHub to use DockerSpawner\"\"\"\n    # app.config.DockerSpawner.remove = True\n    with mock.patch.dict(app.tornado_settings, {\"spawner_class\": DockerSpawner}):\n        yield app\n\n\n@pytest.fixture\ndef swarmspawner_configured_app(app, named_servers):\n    \"\"\"Configure JupyterHub to use DockerSpawner\"\"\"\n    with mock.patch.dict(\n        app.tornado_settings, {\"spawner_class\": SwarmSpawner}\n    ), mock.patch.dict(app.config.SwarmSpawner, {\"network_name\": \"bridge\"}):\n        yield app\n\n\n@pytest.fixture\ndef systemuserspawner_configured_app(app, named_servers):\n    \"\"\"Configure JupyterHub to use DockerSpawner\"\"\"\n    with mock.patch.dict(app.tornado_settings, {\"spawner_class\": SystemUserSpawner}):\n        yield app\n\n\n@pytest.fixture(autouse=True, scope=\"session\")\ndef docker():\n    \"\"\"Fixture to return a connected docker client\n\n    cleans up any containers we leave in docker\n    \"\"\"\n    d = docker_from_env()\n    try:\n        yield d\n\n    finally:\n        # cleanup our containers\n        for c in d.containers.list(all=True):\n            if c.name.startswith(\"dockerspawner-test\"):\n                c.stop()\n                c.remove()\n        try:\n            services = d.services.list()\n        except (APIError, TypeError):\n            # e.g. services not available\n            # podman gives TypeError\n            return\n        else:\n            for s in services:\n                if s.name.startswith(\"dockerspawner-test\"):\n                    s.remove()\n\n\n# make sure reports are available during yield fixtures\n# from pytest docs: https://docs.pytest.org/en/latest/example/simple.html#making-test-result-information-available-in-fixtures\n\n\n@pytest.hookimpl(tryfirst=True, hookwrapper=True)\ndef pytest_runtest_makereport(item, call):\n    # execute all other hooks to obtain the report object\n    outcome = yield\n    rep = outcome.get_result()\n\n    # set a report attribute for each phase of a call, which can\n    # be \"setup\", \"call\", \"teardown\"\n\n    setattr(item, \"rep_\" + rep.when, rep)\n\n\n@pytest.fixture(autouse=True)\ndef debug_docker(request, docker):\n    \"\"\"Debug docker state after tests\"\"\"\n    yield\n    if not hasattr(request.node, 'rep_call'):\n        return\n    if not request.node.rep_call.failed:\n        return\n\n    print(\"executing test failed\", request.node.nodeid)\n    containers = docker.containers.list(all=True)\n    for c in containers:\n        print(f\"Container {c.name}: {c.status}\")\n\n    for c in containers:\n        logs = indent(c.logs().decode('utf8', 'replace'), '  ')\n        print(f\"Container {c.name} logs:\\n{logs}\")\n\n    for c in containers:\n        container_info = json.dumps(\n            docker.api.inspect_container(c.id),\n            indent=2,\n            sort_keys=True,\n        )\n        print(f\"Container {c.name}: {container_info}\")\n\n\n_username_counter = 0\n\n\n@pytest.fixture()\ndef username():\n    global _username_counter\n    _username_counter += 1\n    return f\"test-user-{_username_counter}\"\n", "\"\"\"Tests for DockerSpawner class\"\"\"\nimport asyncio\nimport json\nimport logging\nimport os\nimport string\nfrom unittest import mock\n\nimport docker\nimport pytest\nimport traitlets\nfrom escapism import escape\nfrom jupyterhub.tests.mocking import public_url\nfrom jupyterhub.tests.test_api import add_user, api_request\nfrom jupyterhub.utils import url_path_join\nfrom tornado.httpclient import AsyncHTTPClient\n\nfrom dockerspawner import DockerSpawner\n\n\ndef test_name_collision(dockerspawner_configured_app):\n    app = dockerspawner_configured_app\n    has_hyphen = \"user--foo\"\n    add_user(app.db, app, name=has_hyphen)\n    user = app.users[has_hyphen]\n    spawner1 = user.spawners[\"\"]\n    assert isinstance(spawner1, DockerSpawner)\n    assert spawner1.object_name == \"{}-{}\".format(\n        spawner1.prefix, has_hyphen.replace(\"-\", \"-2d\")\n    )\n\n    part1, part2 = [\"user\", \"foo\"]\n    add_user(app.db, app, name=part1)\n    user2 = app.users[part1]\n    spawner2 = user2.spawners[part2]\n    assert spawner1.object_name != spawner2.object_name\n\n\n@pytest.mark.parametrize(\"remove\", (True, False))\nasync def test_start_stop(dockerspawner_configured_app, remove):\n    app = dockerspawner_configured_app\n    name = \"has@\"\n    add_user(app.db, app, name=name)\n    user = app.users[name]\n    server_name = 'also-has@'\n    spawner = user.spawners[server_name]\n    assert isinstance(spawner, DockerSpawner)\n    spawner.remove = remove\n    token = user.new_api_token()\n    # start the server\n    r = await api_request(app, \"users\", name, \"servers\", server_name, method=\"post\")\n    pending = r.status_code == 202\n    while pending:\n        # request again\n        await asyncio.sleep(2)\n        r = await api_request(app, \"users\", name)\n        user_info = r.json()\n        pending = user_info[\"servers\"][server_name][\"pending\"]\n    assert r.status_code in {201, 200}, r.text\n\n    url = url_path_join(public_url(app, user), server_name, \"api/status\")\n    resp = await AsyncHTTPClient().fetch(\n        url, headers={\"Authorization\": \"token %s\" % token}\n    )\n    assert resp.effective_url == url\n    resp.rethrow()\n    assert \"kernels\" in resp.body.decode(\"utf-8\")\n\n    # stop the server\n    r = await api_request(app, \"users\", name, \"servers\", server_name, method=\"delete\")\n    pending = r.status_code == 202\n    while pending:\n        # request again\n        await asyncio.sleep(2)\n        r = await api_request(app, \"users\", name)\n        user_info = r.json()\n        pending = user_info[\"servers\"][server_name][\"pending\"]\n    assert r.status_code in {204, 200}, r.text\n    state = spawner.get_state()\n    if remove:\n        assert state == {}\n    else:\n        assert sorted(state) == [\"object_id\", \"object_name\"]\n\n\ndef allowed_images_callable(*_):\n    return [\"quay.io/jupyterhub/singleuser:4.0\", \"quay.io/jupyterhub/singleuser:4\"]\n\n\n@pytest.mark.parametrize(\n    \"allowed_images, image, ok\",\n    [\n        (\n            {\n                \"4.0\": \"quay.io/jupyterhub/singleuser:4.0\",\n                \"4\": \"quay.io/jupyterhub/singleuser:4\",\n            },\n            \"4.0\",\n            True,\n        ),\n        (\n            {\n                \"4.0\": \"quay.io/jupyterhub/singleuser:4.0\",\n                \"4\": \"quay.io/jupyterhub/singleuser:4\",\n            },\n            None,\n            True,\n        ),\n        (\n            [\n                \"quay.io/jupyterhub/singleuser:4\",\n                \"quay.io/jupyterhub/singleuser:4.0\",\n            ],\n            \"not-in-list\",\n            False,\n        ),\n        (\n            [\n                \"quay.io/jupyterhub/singleuser:4.0\",\n                \"quay.io/jupyterhub/singleuser:4\",\n            ],\n            \"quay.io/jupyterhub/singleuser:4\",\n            True,\n        ),\n        (\n            allowed_images_callable,\n            \"quay.io/jupyterhub/singleuser:4.0\",\n            True,\n        ),\n        (\n            allowed_images_callable,\n            \"quay.io/jupyterhub/singleuser:3.0\",\n            False,\n        ),\n        (\n            None,\n            \"DEFAULT\",\n            False,\n        ),\n        (\n            None,\n            None,\n            True,\n        ),\n        (\n            # explicitly allow all\n            \"*\",\n            \"quay.io/jupyterhub/singleuser:4\",\n            True,\n        ),\n    ],\n)\nasync def test_allowed_image(\n    user, dockerspawner_configured_app, allowed_images, image, ok\n):\n    app = dockerspawner_configured_app\n    name = user.name\n    assert isinstance(user.spawner, DockerSpawner)\n    default_image = user.spawner.image  # default value\n    if image == \"DEFAULT\":\n        image = default_image\n    user.spawner.remove_containers = True\n    if allowed_images is not None:\n        user.spawner.allowed_images = allowed_images\n\n    if image:\n        request_body = json.dumps({\"image\": image})\n    else:\n        request_body = b\"\"\n    # start the server\n    r = await api_request(\n        app,\n        \"users\",\n        name,\n        \"server\",\n        method=\"post\",\n        data=request_body,\n    )\n\n    if not ok:\n        assert r.status_code == 400\n        return\n    else:\n        r.raise_for_status()\n\n    pending = r.status_code == 202\n    while pending:\n        # request again\n        await asyncio.sleep(1)\n        r = await api_request(app, \"users\", name)\n        user_info = r.json()\n        pending = user_info[\"servers\"][\"\"][\"pending\"]\n\n    if image is None:\n        expected_image = default_image\n    elif isinstance(allowed_images, (list, dict)):\n        expected_image = user.spawner._get_allowed_images()[image]\n    else:\n        expected_image = image\n\n    assert user.spawner.image == expected_image\n    obj = await user.spawner.get_object()\n    assert obj[\"Config\"][\"Image\"] == expected_image\n\n    r = await api_request(\n        app,\n        \"users\",\n        name,\n        \"server\",\n        method=\"delete\",\n    )\n    r.raise_for_status()\n\n\n@pytest.mark.xfail(\n    \"podman.sock\" in os.getenv(\"DOCKER_HOST\", \"\"), reason=\"Fails with Podman\"\n)\nasync def test_image_pull_policy(dockerspawner_configured_app):\n    app = dockerspawner_configured_app\n    name = \"gumby\"\n    add_user(app.db, app, name=name)\n    user = app.users[name]\n    assert isinstance(user.spawner, DockerSpawner)\n    spawner = user.spawners[\"\"]\n    spawner.image = \"jupyterhub/doesntexist:nosuchtag\"\n    with pytest.raises(docker.errors.NotFound):\n        spawner.image_pull_policy = \"never\"\n        await spawner.pull_image(spawner.image)\n\n    repo = \"busybox\"\n    tag = \"1.29.1\"  # a version that's definitely not latest\n    # ensure image isn't present\n    try:\n        await asyncio.wrap_future(spawner.docker(\"remove_image\", f\"{repo}:{tag}\"))\n    except docker.errors.ImageNotFound:\n        pass\n\n    spawner.pull_policy = \"ifnotpresent\"\n    image = f\"{repo}:{tag}\"\n    # should trigger a pull\n    await spawner.pull_image(image)\n    # verify that the image exists now\n    old_image_info = await asyncio.wrap_future(spawner.docker(\"inspect_image\", image))\n    print(old_image_info)\n\n    # now tag busybox:latest as our current version\n    # which is not latest!\n    await asyncio.wrap_future(spawner.docker(\"tag\", image, repo))\n\n    image = repo  # implicit :latest\n    spawner.pull_policy = \"ifnotpresent\"\n    # check with ifnotpresent shouldn't pull\n    await spawner.pull_image(image)\n    image_info = await asyncio.wrap_future(spawner.docker(\"inspect_image\", repo))\n    assert image_info[\"Id\"] == old_image_info[\"Id\"]\n\n    # run again with Always,\n    # should trigger a pull even though the image is present\n    spawner.pull_policy = \"always\"\n    await spawner.pull_image(image)\n    image_info = await asyncio.wrap_future(spawner.docker(\"inspect_image\", repo))\n    assert image_info[\"Id\"] != old_image_info[\"Id\"]\n\n    # run again with never, make sure it's still happy\n    spawner.pull_policy = \"never\"\n    await spawner.pull_image(image)\n\n\nasync def test_post_start(dockerspawner_configured_app, caplog):\n    app = dockerspawner_configured_app\n    name = \"post-start\"\n    add_user(app.db, app, name=name)\n    user = app.users[name]\n    spawner = user.spawners['']\n    log_name = \"dockerspawner\"\n    spawner.log = logging.getLogger(log_name)\n    spawner.remove = True\n\n    # mock out ip and port, no need for it\n    async def mock_ip_port():\n        return (\"127.0.0.1\", 1234)\n\n    spawner.get_ip_and_port = mock_ip_port\n\n    spawner.image = \"busybox:1.29.1\"\n    spawner.cmd = [\"sh\", \"-c\", \"sleep 300\"]\n    spawner.post_start_cmd = \"ls /\"\n\n    # verify that it's called during startup\n    finished_future = asyncio.Future()\n    finished_future.set_result(None)\n    mock_post_start = mock.Mock(return_value=finished_future)\n    with mock.patch.object(spawner, 'post_start_exec', mock_post_start):\n        await spawner.start()\n    mock_post_start.assert_called_once()\n\n    # verify log capture for 3 combinations:\n    # - success\n    # - failure\n    # - no such command (different failure)\n\n    for cmd, expected_stdout, expected_stderr in [\n        (\"true\", False, False),\n        (\"ls /\", True, False),\n        (\"ls /nosuchfile\", False, True),\n        (\"nosuchcommand\", False, True),\n        (\"echo\", False, False),\n    ]:\n        spawner.post_start_cmd = cmd\n        idx = len(caplog.records)\n        with caplog.at_level(logging.DEBUG, log_name):\n            await spawner.post_start_exec()\n        logged = \"\\n\".join(\n            f\"{rec.levelname}: {rec.message}\" for rec in caplog.records[idx:]\n        )\n        if expected_stdout:\n            assert \"DEBUG: post_start stdout\" in logged\n        else:\n            assert \"post_start stdout\" not in logged\n        if expected_stderr:\n            assert \"WARNING: post_start stderr\" in logged\n        else:\n            assert \"post_start stderr\" not in logged\n\n    await spawner.stop()\n\n\n@pytest.mark.skipif(\n    traitlets.__version__ < '5.0', reason=\"One test fails on traitlets < 5.0. See #420.\"\n)\n@pytest.mark.parametrize(\n    \"mem_limit, expected\",\n    [\n        (\"1G\", 1024**3),\n        (1_000_000, 1_000_000),\n        (None, None),\n        (lambda spawner: None, None),\n        (lambda spawner: \"2G\", 2 * 1024**3),\n        (lambda spawner: 1_000_000, 1_000_000),\n    ],\n)\ndef test_mem_limit(mem_limit, expected):\n    s = DockerSpawner(mem_limit=mem_limit)\n    assert s.mem_limit == expected\n\n\n@pytest.mark.parametrize(\n    \"cpu_limit, expected\",\n    [\n        (1, 1),\n        (None, None),\n        (1.5, 1.5),\n        (lambda spawner: None, None),\n        (lambda spawner: 2, 2),\n        (lambda spawner: 1.25, 1.25),\n    ],\n)\nasync def test_cpu_limit(dockerspawner_configured_app, cpu_limit, expected, username):\n    app = dockerspawner_configured_app\n    app.config.DockerSpawner.cpu_limit = cpu_limit\n    add_user(app.db, app, name=username)\n    user = app.users[username]\n    s = user.spawners[\"\"]\n    assert s.cpu_limit == expected\n    original_docker = s.docker\n\n    async def mock_docker(cmd, *args, **kwargs):\n        if cmd == \"create_container\":\n            return args, kwargs\n        else:\n            return await original_docker(cmd, *args, **kwargs)\n\n    with mock.patch.object(s, 'docker', new=mock_docker):\n        args, kwargs = await s.create_object()\n\n    print(kwargs)\n    host_config = kwargs['host_config']\n    if expected is not None:\n        assert host_config['CpuPeriod'] == 100_000\n        assert host_config['CpuQuota'] == int(expected * 100_000)\n    else:\n        assert 'CpuPeriod' not in host_config\n        assert 'CpuQuota' not in host_config\n\n\n@mock.patch.dict(os.environ, {\"DOCKER_HOST\": \"tcp://127.0.0.2\"}, clear=True)\ndef test_default_host_ip_reads_env_var():\n    spawner = DockerSpawner()\n    assert spawner._default_host_ip() == \"127.0.0.2\"\n\n\ndef test_default_options_form():\n    spawner = DockerSpawner()\n    spawner.allowed_images = {\"1.0\": \"jupyterhub/singleuser:1.0\"}\n    assert spawner._default_options_form() == ''\n    spawner.allowed_images[\"1.1\"] = \"jupyterhub/singleuser:1.1\"\n    assert (\n        spawner._default_options_form()\n        == \"\"\"\n        <label for=\"image\">Select an image:</label>\n        <select class=\"form-control\" name=\"image\" required autofocus>\n        ['<option value=\"1.0\" >1.0</option>', '<option value=\"1.1\" >1.1</option>']\n        </select>\n        \"\"\"\n    )\n\n\ndef test_options_from_form():\n    spawner = DockerSpawner()\n    formdata = {'image': ['1.0', '1.1']}\n    assert spawner.options_from_form(formdata) == {'image': '1.0'}\n\n\n@pytest.mark.parametrize(\"escape_type\", (\"legacy\", escape))\ndef test_validate_escape(escape_type):\n    spawner = DockerSpawner()\n    spawner.escape = escape_type\n    with pytest.raises(Exception):\n        spawner.escape = \"\"\n\n\ndef test_legacy_escape(dockerspawner_configured_app):\n    app = dockerspawner_configured_app\n    name = \"cont@iner\"\n    add_user(app.db, app, name=name)\n    user = app.users[name]\n    server_name = 'cont@iner_server'\n    spawner = user.spawners[server_name]\n    assert isinstance(spawner, DockerSpawner)\n    container_name_template = spawner.name_template\n    container_name = container_name_template.format(\n        prefix=\"jupyter\", username=name, servername=server_name\n    )\n    safe_chars = set(string.ascii_letters + string.digits + \"-\")\n    assert spawner._legacy_escape(container_name) == escape(\n        container_name, safe_chars, escape_char='_'\n    )\n"], "filenames": ["dockerspawner/dockerspawner.py", "docs/source/changelog.md", "examples/image_form/jupyterhub_config.py", "tests/conftest.py", "tests/test_dockerspawner.py"], "buggy_code_start_loc": [264, 14, 16, 17, 87], "buggy_code_end_loc": [1069, 16, 36, 17, 143], "fixing_code_start_loc": [264, 15, 16, 18, 87], "fixing_code_end_loc": [1085, 21, 21, 19, 205], "type": "NVD-CWE-noinfo", "message": "dockerspawner is a tool to spawn JupyterHub single user servers in Docker containers. Users of JupyterHub deployments running DockerSpawner starting with 0.11.0 without specifying `DockerSpawner.allowed_images` configuration allow users to launch _any_ pullable docker image, instead of restricting to only the single configured image, as intended. This issue has been addressed in commit `3ba4b665b` which has been included in dockerspawner release version 13. Users are advised to upgrade. Users unable to upgrade should explicitly set `DockerSpawner.allowed_images` to a non-empty list containing only the default image will result in the intended default behavior.", "other": {"cve": {"id": "CVE-2023-48311", "sourceIdentifier": "security-advisories@github.com", "published": "2023-12-08T20:15:07.573", "lastModified": "2023-12-13T18:39:26.447", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "dockerspawner is a tool to spawn JupyterHub single user servers in Docker containers. Users of JupyterHub deployments running DockerSpawner starting with 0.11.0 without specifying `DockerSpawner.allowed_images` configuration allow users to launch _any_ pullable docker image, instead of restricting to only the single configured image, as intended. This issue has been addressed in commit `3ba4b665b` which has been included in dockerspawner release version 13. Users are advised to upgrade. Users unable to upgrade should explicitly set `DockerSpawner.allowed_images` to a non-empty list containing only the default image will result in the intended default behavior."}, {"lang": "es", "value": "dockerspawner es una herramienta para generar servidores de usuario \u00fanico de JupyterHub en contenedores Docker. Los usuarios de implementaciones de JupyterHub que ejecutan DockerSpawner a partir de 0.11.0 sin especificar la configuraci\u00f3n `DockerSpawner.allowed_images` permiten a los usuarios _any_ pullable imagen acoplable extra\u00edble, en lugar de limitarse a una sola imagen configurada, como se pretende. Este problema se solucion\u00f3 en el commit `3ba4b665b` que se incluy\u00f3 en la versi\u00f3n 13 de dockerspawner. Se recomienda a los usuarios que actualicen. Los usuarios que no puedan actualizar deben configurar expl\u00edcitamente `DockerSpawner.allowed_images` en una lista no vac\u00eda que contenga solo la imagen predeterminada, lo que dar\u00e1 como resultado el comportamiento predeterminado previsto."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 4.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 1.4}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.0, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.1, "impactScore": 5.9}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:jupyter:dockerspawner:*:*:*:*:*:*:*:*", "versionStartIncluding": "0.11.0", "versionEndExcluding": "13.0", "matchCriteriaId": "E7A08B34-1654-4888-B9A9-104B28B76691"}]}]}], "references": [{"url": "https://github.com/jupyterhub/dockerspawner/commit/3ba4b665b6ca6027ea7a032d7ca3eab977574626", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/jupyterhub/dockerspawner/security/advisories/GHSA-hfgr-h3vc-p6c2", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/jupyterhub/dockerspawner/commit/3ba4b665b6ca6027ea7a032d7ca3eab977574626"}}
{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/platform/errors.h\"\n\nnamespace tensorflow {\n\nusing shape_inference::DimensionHandle;\nusing shape_inference::InferenceContext;\nusing shape_inference::ShapeHandle;\n\nnamespace {\n\nStatus SparseSparseMinOrMaxShapeFn(InferenceContext* c) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));  // a_indices\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));  // a_values\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));  // a_shape\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 2, &unused));  // b_indices\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(4), 1, &unused));  // b_values\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(5), 1, &unused));  // b_shape\n  c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,\n                             InferenceContext::kUnknownDim));\n  c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n  return Status::OK();\n}\n\n}  // namespace\n\nREGISTER_OP(\"SparseAddGrad\")\n    .Input(\"backprop_val_grad: T\")\n    .Input(\"a_indices: int64\")\n    .Input(\"b_indices: int64\")\n    .Input(\"sum_indices: int64\")\n    .Output(\"a_val_grad: T\")\n    .Output(\"b_val_grad: T\")\n    .Attr(\"T: numbertype\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle a_indices;\n      ShapeHandle b_indices;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &a_indices));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 2, &b_indices));\n      c->set_output(0, c->Vector(c->Dim(a_indices, 0)));\n      c->set_output(1, c->Vector(c->Dim(b_indices, 0)));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseAdd\")\n    .Input(\"a_indices: int64\")\n    .Input(\"a_values: T\")\n    .Input(\"a_shape: int64\")\n    .Input(\"b_indices: int64\")\n    .Input(\"b_values: T\")\n    .Input(\"b_shape: int64\")\n    .Input(\"thresh: Treal\")\n    .Output(\"sum_indices: int64\")\n    .Output(\"sum_values: T\")\n    .Output(\"sum_shape: int64\")\n    .Attr(\"T: numbertype\")\n    .Attr(\"Treal: realnumbertype\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle a_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &a_shape));\n      c->set_output(\n          0, c->Matrix(InferenceContext::kUnknownDim, c->Dim(a_shape, 0)));\n      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(2, a_shape);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseTensorDenseMatMul\")\n    .Input(\"a_indices: Tindices\")\n    .Input(\"a_values: T\")\n    .Input(\"a_shape: int64\")\n    .Input(\"b: T\")\n    .Output(\"product: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32,int64} = DT_INT64\")\n    .Attr(\"adjoint_a: bool = false\")\n    .Attr(\"adjoint_b: bool = false\")\n    .SetShapeFn([](InferenceContext* c) {\n      DimensionHandle unused_dim;\n      ShapeHandle unused;\n      ShapeHandle b;\n      ShapeHandle a_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));  // a_indices\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));  // a_values\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(2, &a_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(a_shape, 2, &a_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 2, &b));\n\n      bool adjoint_a;\n      bool adjoint_b;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"adjoint_a\", &adjoint_a));\n      TF_RETURN_IF_ERROR(c->GetAttr(\"adjoint_b\", &adjoint_b));\n\n      DimensionHandle output_right = c->Dim(b, adjoint_b ? 0 : 1);\n      DimensionHandle output_left = c->Dim(a_shape, adjoint_a ? 1 : 0);\n      DimensionHandle inner_left = c->Dim(a_shape, adjoint_a ? 0 : 1);\n      DimensionHandle inner_right = c->Dim(b, adjoint_b ? 1 : 0);\n      TF_RETURN_IF_ERROR(c->Merge(inner_left, inner_right, &unused_dim));\n      c->set_output(0, c->Matrix(output_left, output_right));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SerializeSparse\")\n    .Input(\"sparse_indices: int64\")\n    .Input(\"sparse_values: T\")\n    .Input(\"sparse_shape: int64\")\n    .Attr(\"T: type\")\n    .Output(\"serialized_sparse: out_type\")\n    .Attr(\"out_type: {string, variant} = DT_STRING\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n      c->set_output(0, c->Vector(3));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SerializeManySparse\")\n    .Input(\"sparse_indices: int64\")\n    .Input(\"sparse_values: T\")\n    .Input(\"sparse_shape: int64\")\n    .Attr(\"T: type\")\n    .Output(\"serialized_sparse: out_type\")\n    .Attr(\"out_type: {string, variant} = DT_STRING\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n      c->set_output(0, c->Matrix(InferenceContext::kUnknownDim, 3));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"DeserializeSparse\")\n    .Input(\"serialized_sparse: Tserialized\")\n    .Output(\"sparse_indices: int64\")\n    .Output(\"sparse_values: dtype\")\n    .Output(\"sparse_shape: int64\")\n    .Attr(\"dtype: type\")\n    .Attr(\"Tserialized: {string, variant} = DT_STRING\")\n    .SetShapeFn([](InferenceContext* c) {\n      // serialized sparse is [?, ..., ?, 3] vector.\n      DimensionHandle unused;\n      TF_RETURN_IF_ERROR(c->WithValue(c->Dim(c->input(0), -1), 3, &unused));\n      c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,\n                                 InferenceContext::kUnknownDim));\n      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(2, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"DeserializeManySparse\")\n    .Input(\"serialized_sparse: string\")\n    .Output(\"sparse_indices: int64\")\n    .Output(\"sparse_values: dtype\")\n    .Output(\"sparse_shape: int64\")\n    .Attr(\"dtype: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      // serialized sparse is [?,3] matrix.\n      ShapeHandle serialized_sparse;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &serialized_sparse));\n      DimensionHandle unused;\n      TF_RETURN_IF_ERROR(\n          c->WithValue(c->Dim(serialized_sparse, 1), 3, &unused));\n\n      c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,\n                                 InferenceContext::kUnknownDim));\n      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(2, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseToDense\")\n    .Input(\"sparse_indices: Tindices\")\n    .Input(\"output_shape: Tindices\")\n    .Input(\"sparse_values: T\")\n    .Input(\"default_value: T\")\n    .Attr(\"validate_indices: bool = true\")\n    .Attr(\"T: type\")\n    .Output(\"dense: T\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseConcat\")\n    .Input(\"indices: N * int64\")\n    .Input(\"values: N * T\")\n    .Input(\"shapes: N * int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"concat_dim: int\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      // These accumulates the sum.\n      DimensionHandle output_row_count = c->MakeDim(0ll);\n\n      // These are only merged.\n      DimensionHandle output_ind_cols = c->UnknownDim();\n      ShapeHandle output_shape = c->UnknownShape();\n\n      const int n = c->num_inputs() / 3;\n      for (int i = 0; i < n; i++) {\n        ShapeHandle ind;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), 2, &ind));\n        ShapeHandle val;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i + n), 1, &val));\n        ShapeHandle shape;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i + 2 * n), 1, &shape));\n\n        // Add to output_ind_rows.\n        DimensionHandle num_dim;\n        TF_RETURN_IF_ERROR(c->Merge(c->Dim(ind, 0), c->Dim(val, 0), &num_dim));\n        TF_RETURN_IF_ERROR(\n            c->Add(output_row_count, num_dim, &output_row_count));\n\n        // Merge into output_ind_cols and output_shape.\n        TF_RETURN_IF_ERROR(\n            c->Merge(output_ind_cols, c->Dim(ind, 1), &output_ind_cols));\n        TF_RETURN_IF_ERROR(c->Merge(output_shape, shape, &output_shape));\n      }\n\n      c->set_output(0, c->Matrix(output_row_count, output_ind_cols));\n      c->set_output(1, c->Vector(output_row_count));\n      c->set_output(2, output_shape);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseCross\")\n    .Input(\"indices: N * int64\")\n    .Input(\"values: sparse_types\")\n    .Input(\"shapes: N * int64\")\n    .Input(\"dense_inputs: dense_types\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: out_type\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"N: int >= 0\")\n    .Attr(\"hashed_output: bool\")\n    .Attr(\"num_buckets: int >= 0\")\n    .Attr(\"hash_key: int\")\n    .Attr(\"sparse_types: list({int64, string}) >= 0\")\n    .Attr(\"dense_types: list({int64, string}) >= 0\")\n    .Attr(\"out_type: {int64, string}\")\n    .Attr(\"internal_type: {int64, string}\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      c->set_output(0, c->Matrix(c->UnknownDim(), 2));\n      c->set_output(1, c->Vector(c->UnknownDim()));\n      c->set_output(2, c->Vector(2));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseCrossV2\")\n    .Input(\"indices: N * int64\")\n    .Input(\"values: sparse_types\")\n    .Input(\"shapes: N * int64\")\n    .Input(\"dense_inputs: dense_types\")\n    .Input(\"sep: string\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: string\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"N: int >= 0\")\n    .Attr(\"sparse_types: list({int64, string}) >= 0\")\n    .Attr(\"dense_types: list({int64, string}) >= 0\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      c->set_output(0, c->Matrix(c->UnknownDim(), 2));\n      c->set_output(1, c->Vector(c->UnknownDim()));\n      c->set_output(2, c->Vector(2));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseCrossHashed\")\n    .Input(\"indices: N * int64\")\n    .Input(\"values: sparse_types\")\n    .Input(\"shapes: N * int64\")\n    .Input(\"dense_inputs: dense_types\")\n    .Input(\"num_buckets: int64\")\n    .Input(\"strong_hash: bool\")\n    .Input(\"salt: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: int64\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"N: int >= 0\")\n    .Attr(\"sparse_types: list({int64, string}) >= 0\")\n    .Attr(\"dense_types: list({int64, string}) >= 0\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      c->set_output(0, c->Matrix(c->UnknownDim(), 2));\n      c->set_output(1, c->Vector(c->UnknownDim()));\n      c->set_output(2, c->Vector(2));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseSplit\")\n    .Input(\"split_dim: int64\")\n    .Input(\"indices: int64\")\n    .Input(\"values: T\")\n    .Input(\"shape: int64\")\n    .Output(\"output_indices: num_split * int64\")\n    .Output(\"output_values:  num_split * T\")\n    .Output(\"output_shape:   num_split * int64\")\n    .Attr(\"num_split: int >= 1\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape = c->input(3);\n      ShapeHandle output_indices =\n          c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\n      ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);\n      ShapeHandle output_shape = input_shape;\n\n      // Copy the outputs into the output ranges.\n      int num_splits = c->num_outputs() / 3;\n      int out_idx = 0;\n      for (int i = 0; i < num_splits; ++i)\n        c->set_output(out_idx++, output_indices);\n      for (int i = 0; i < num_splits; ++i)\n        c->set_output(out_idx++, output_values);\n      for (int i = 0; i < num_splits; ++i)\n        c->set_output(out_idx++, output_shape);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseSliceGrad\")\n    .Input(\"backprop_val_grad: T\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_start: int64\")\n    .Input(\"output_indices: int64\")\n    .Output(\"val_grad: T\")\n    .Attr(\"T: numbertype\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle indices;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &indices));\n      c->set_output(0, c->Vector(c->Dim(indices, 0)));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseSlice\")\n    .Input(\"indices: int64\")\n    .Input(\"values: T\")\n    .Input(\"shape: int64\")\n    .Input(\"start: int64\")\n    .Input(\"size: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape = c->input(2);\n      ShapeHandle output_indices =\n          c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\n      ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);\n      ShapeHandle output_shape = input_shape;\n\n      c->set_output(0, output_indices);\n      c->set_output(1, output_values);\n      c->set_output(2, output_shape);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseReorder\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_values: T\")\n    .Input(\"input_shape: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle indices;\n      ShapeHandle values;\n      ShapeHandle unused;\n\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &indices));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &values));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n\n      c->set_output(0, indices);\n      c->set_output(1, values);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseReshape\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_shape: int64\")\n    .Input(\"new_shape: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_shape: int64\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle indices;\n      ShapeHandle unused;\n      ShapeHandle new_shape;\n\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &indices));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &new_shape));\n\n      c->set_output(0, c->Matrix(c->Dim(indices, 0), c->Dim(new_shape, 0)));\n      c->set_output(1, new_shape);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseTensorDenseAdd\")\n    .Input(\"a_indices: Tindices\")\n    .Input(\"a_values: T\")\n    .Input(\"a_shape: Tindices\")\n    .Input(\"b: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: numbertype\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->input(3));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseReduceMax\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_values: T\")\n    .Input(\"input_shape: int64\")\n    .Input(\"reduction_axes: int32\")\n    .Attr(\"keep_dims: bool = False\")\n    .Output(\"output: T\")\n    .Attr(\"T: realnumbertype\")\n    .SetShapeFn(shape_inference::SparseReduceShapeFn);\n\nREGISTER_OP(\"SparseReduceMaxSparse\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_values: T\")\n    .Input(\"input_shape: int64\")\n    .Input(\"reduction_axes: int32\")\n    .Attr(\"keep_dims: bool = False\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"T: realnumbertype\")\n    .SetShapeFn(shape_inference::UnknownShape);\n\nREGISTER_OP(\"SparseReduceSum\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_values: T\")\n    .Input(\"input_shape: int64\")\n    .Input(\"reduction_axes: int32\")\n    .Attr(\"keep_dims: bool = False\")\n    .Output(\"output: T\")\n    .Attr(\"T: numbertype\")\n    .SetShapeFn(shape_inference::SparseReduceShapeFn);\n\nREGISTER_OP(\"SparseReduceSumSparse\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_values: T\")\n    .Input(\"input_shape: int64\")\n    .Input(\"reduction_axes: int32\")\n    .Attr(\"keep_dims: bool = False\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"T: numbertype\")\n    .SetShapeFn(shape_inference::UnknownShape);\n\n#define SPARSE_DENSE_CWISE_SIGNATURE()                           \\\n  Input(\"sp_indices: int64\")                                     \\\n      .Input(\"sp_values: T\")                                     \\\n      .Input(\"sp_shape: int64\")                                  \\\n      .Input(\"dense: T\")                                         \\\n      .Output(\"output: T\")                                       \\\n      .Attr(\"T: numbertype\")                                     \\\n      .SetShapeFn([](InferenceContext* c) {                      \\\n        ShapeHandle input;                                       \\\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &input)); \\\n        c->set_output(0, c->Vector(c->Dim(input, 0)));           \\\n        return Status::OK();                                     \\\n      })\n\nREGISTER_OP(\"SparseDenseCwiseMul\").SPARSE_DENSE_CWISE_SIGNATURE();\n\nREGISTER_OP(\"SparseDenseCwiseDiv\").SPARSE_DENSE_CWISE_SIGNATURE();\n\nREGISTER_OP(\"SparseDenseCwiseAdd\").SPARSE_DENSE_CWISE_SIGNATURE();\n\n#undef SPARSE_DENSE_CWISE_SIGNATURE\n\nREGISTER_OP(\"SparseSoftmax\")\n    .Input(\"sp_indices: int64\")\n    .Input(\"sp_values: T\")\n    .Input(\"sp_shape: int64\")\n    .Output(\"output: T\")\n    .Attr(\"T: {float, double}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      ShapeHandle values;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));  // sp_indices\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &values));  // sp_values\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n      c->set_output(0, values);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseSparseMaximum\")\n    .Input(\"a_indices: int64\")\n    .Input(\"a_values: T\")\n    .Input(\"a_shape: int64\")\n    .Input(\"b_indices: int64\")\n    .Input(\"b_values: T\")\n    .Input(\"b_shape: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Attr(\"T: realnumbertype\")\n    .SetShapeFn(SparseSparseMinOrMaxShapeFn);\n\nREGISTER_OP(\"SparseSparseMinimum\")\n    .Input(\"a_indices: int64\")\n    .Input(\"a_values: T\")\n    .Input(\"a_shape: int64\")\n    .Input(\"b_indices: int64\")\n    .Input(\"b_values: T\")\n    .Input(\"b_shape: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Attr(\"T: numbertype\")\n    .SetShapeFn(SparseSparseMinOrMaxShapeFn);\n\nREGISTER_OP(\"AddSparseToTensorsMap\")\n    .Input(\"sparse_indices: int64\")\n    .Input(\"sparse_values: T\")\n    .Input(\"sparse_shape: int64\")\n    .Output(\"sparse_handle: int64\")\n    .Attr(\"T: type\")\n    .Attr(\"container: string = ''\")\n    .Attr(\"shared_name: string = ''\")\n    .SetIsStateful()\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n      c->set_output(0, c->Scalar());\n      return Status::OK();\n    });\n\nREGISTER_OP(\"AddManySparseToTensorsMap\")\n    .Input(\"sparse_indices: int64\")\n    .Input(\"sparse_values: T\")\n    .Input(\"sparse_shape: int64\")\n    .Output(\"sparse_handles: int64\")\n    .Attr(\"T: type\")\n    .Attr(\"container: string = ''\")\n    .Attr(\"shared_name: string = ''\")\n    .SetIsStateful()\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n      c->set_output(0, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"TakeManySparseFromTensorsMap\")\n    .Input(\"sparse_handles: int64\")\n    .Output(\"sparse_indices: int64\")\n    .Output(\"sparse_values: dtype\")\n    .Output(\"sparse_shape: int64\")\n    .Attr(\"dtype: type\")\n    .Attr(\"container: string = ''\")\n    .Attr(\"shared_name: string = ''\")\n    .SetIsStateful()\n    .SetShapeFn([](InferenceContext* c) {\n      // serialized sparse is [?,1] matrix.\n      ShapeHandle sparse_handles;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &sparse_handles));\n\n      c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,\n                                 InferenceContext::kUnknownDim));\n      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(2, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseFillEmptyRows\")\n    .Input(\"indices: int64\")\n    .Input(\"values: T\")\n    .Input(\"dense_shape: int64\")\n    .Input(\"default_value: T\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Output(\"empty_row_indicator: bool\")\n    .Output(\"reverse_index_map: int64\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_indices = c->input(0);\n      TF_RETURN_IF_ERROR(c->WithRank(input_indices, 2, &input_indices));\n      ShapeHandle input_values = c->input(1);\n      TF_RETURN_IF_ERROR(c->WithRank(input_values, 1, &input_values));\n      ShapeHandle input_shape = c->input(2);\n      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 1, &input_shape));\n      ShapeHandle default_value = c->input(3);\n      TF_RETURN_IF_ERROR(c->WithRank(default_value, 0, &default_value));\n      DimensionHandle N = c->Dim(input_indices, 0);\n      TF_RETURN_IF_ERROR(c->Merge(N, c->Dim(input_values, 0), &N));\n      DimensionHandle unused_dim;\n      TF_RETURN_IF_ERROR(c->Merge(c->Dim(input_indices, 1),\n                                  c->Dim(input_shape, 0), &unused_dim));\n      if (c->Value(c->NumElements(input_shape)) == 0)\n        return errors::InvalidArgument(\"dense_shape must not be empty\");\n      ShapeHandle output_indices =\n          c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\n      ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);\n      ShapeHandle constant_input_shape;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(2, &constant_input_shape));\n      ShapeHandle empty_row_indicator =\n          c->Vector(c->Dim(constant_input_shape, 0));\n      ShapeHandle reverse_index_map = c->Vector(N);\n      c->set_output(0, output_indices);\n      c->set_output(1, output_values);\n      c->set_output(2, empty_row_indicator);\n      c->set_output(3, reverse_index_map);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseFillEmptyRowsGrad\")\n    .Input(\"reverse_index_map: int64\")\n    .Input(\"grad_values: T\")\n    .Output(\"d_values: T\")\n    .Output(\"d_default_value: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle reverse_index_map = c->input(0);\n      TF_RETURN_IF_ERROR(c->WithRank(reverse_index_map, 1, &reverse_index_map));\n      ShapeHandle grad_values = c->input(1);\n      TF_RETURN_IF_ERROR(c->WithRank(grad_values, 1, &grad_values));\n      c->set_output(0, reverse_index_map);\n      c->set_output(1, c->Scalar());\n      return Status::OK();\n    });\n\n}  // namespace tensorflow\n", "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for SerializeSparse.\"\"\"\n\nimport numpy as np\n\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import sparse_tensor as sparse_tensor_lib\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import sparse_ops\nfrom tensorflow.python.platform import test\n\n\nclass SerializeSparseTest(test.TestCase):\n\n  def _SparseTensorPlaceholder(self, dtype=None):\n    if dtype is None:\n      dtype = dtypes.int32\n    return sparse_tensor_lib.SparseTensor(\n        array_ops.placeholder(dtypes.int64),\n        array_ops.placeholder(dtype), array_ops.placeholder(dtypes.int64))\n\n  def _SparseTensorValue_5x6(self, permutation):\n    ind = np.array([[0, 0], [1, 0], [1, 3], [1, 4], [3, 2],\n                    [3, 3]]).astype(np.int64)\n    val = np.array([0, 10, 13, 14, 32, 33]).astype(np.int32)\n\n    ind = ind[permutation]\n    val = val[permutation]\n\n    shape = np.array([5, 6]).astype(np.int64)\n    return sparse_tensor_lib.SparseTensorValue(ind, val, shape)\n\n  def _SparseTensorValue_3x4(self, permutation):\n    ind = np.array([[0, 0], [1, 0], [1, 2], [1, 3], [2, 2],\n                    [2, 3]]).astype(np.int64)\n    val = np.array([0, 10, 13, 14, 32, 33]).astype(np.int32)\n\n    ind = ind[permutation]\n    val = val[permutation]\n\n    shape = np.array([3, 4]).astype(np.int64)\n    return sparse_tensor_lib.SparseTensorValue(ind, val, shape)\n\n  def _SparseTensorValue_1x1x1(self):\n    ind = np.array([[0, 0, 0]]).astype(np.int64)\n    val = np.array([0]).astype(np.int32)\n    shape = np.array([3, 4, 5]).astype(np.int64)\n    return sparse_tensor_lib.SparseTensorValue(ind, val, shape)\n\n  def _testSerializeDeserializeHelper(self,\n                                      serialize_fn,\n                                      deserialize_fn,\n                                      out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input = self._SparseTensorValue_5x6(np.arange(6))\n      serialized = serialize_fn(sp_input, out_type=out_type)\n      sp_deserialized = deserialize_fn(serialized, dtype=dtypes.int32)\n\n      indices, values, shape = self.evaluate(sp_deserialized)\n\n      self.assertAllEqual(indices, sp_input[0])\n      self.assertAllEqual(values, sp_input[1])\n      self.assertAllEqual(shape, sp_input[2])\n\n  def testSerializeDeserialize(self):\n    self._testSerializeDeserializeHelper(sparse_ops.serialize_sparse,\n                                         sparse_ops.deserialize_sparse)\n\n  def testVariantSerializeDeserialize(self):\n    self._testSerializeDeserializeHelper(sparse_ops.serialize_sparse,\n                                         sparse_ops.deserialize_sparse,\n                                         dtypes.variant)\n\n  def _testSerializeDeserializeBatchHelper(self,\n                                           serialize_fn,\n                                           deserialize_fn,\n                                           out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input = self._SparseTensorValue_5x6(np.arange(6))\n      serialized = serialize_fn(sp_input, out_type=out_type)\n      serialized = array_ops.stack([serialized, serialized])\n\n      sp_deserialized = deserialize_fn(serialized, dtype=dtypes.int32)\n\n      combined_indices, combined_values, combined_shape = sess.run(\n          sp_deserialized)\n\n      self.assertAllEqual(combined_indices[:6, 0], [0] * 6)  # minibatch 0\n      self.assertAllEqual(combined_indices[:6, 1:], sp_input[0])\n      self.assertAllEqual(combined_indices[6:, 0], [1] * 6)  # minibatch 1\n      self.assertAllEqual(combined_indices[6:, 1:], sp_input[0])\n      self.assertAllEqual(combined_values[:6], sp_input[1])\n      self.assertAllEqual(combined_values[6:], sp_input[1])\n      self.assertAllEqual(combined_shape, [2, 5, 6])\n\n  @test_util.run_deprecated_v1\n  def testSerializeDeserializeBatch(self):\n    self._testSerializeDeserializeBatchHelper(sparse_ops.serialize_sparse,\n                                              sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testSerializeDeserializeManyBatch(self):\n    self._testSerializeDeserializeBatchHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeDeserializeBatch(self):\n    self._testSerializeDeserializeBatchHelper(sparse_ops.serialize_sparse,\n                                              sparse_ops.deserialize_sparse,\n                                              dtypes.variant)\n\n  def _testSerializeDeserializeBatchInconsistentShapeHelper(\n      self, serialize_fn, deserialize_fn, out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input0 = self._SparseTensorValue_5x6(np.arange(6))\n      sp_input1 = self._SparseTensorValue_3x4(np.arange(6))\n      serialized0 = serialize_fn(sp_input0, out_type=out_type)\n      serialized1 = serialize_fn(sp_input1, out_type=out_type)\n      serialized = array_ops.stack([serialized0, serialized1])\n\n      sp_deserialized = deserialize_fn(serialized, dtype=dtypes.int32)\n\n      combined_indices, combined_values, combined_shape = sess.run(\n          sp_deserialized)\n\n      self.assertAllEqual(combined_indices[:6, 0], [0] * 6)  # minibatch 0\n      self.assertAllEqual(combined_indices[:6, 1:], sp_input0[0])\n      self.assertAllEqual(combined_indices[6:, 0], [1] * 6)  # minibatch 1\n      self.assertAllEqual(combined_indices[6:, 1:], sp_input1[0])\n      self.assertAllEqual(combined_values[:6], sp_input0[1])\n      self.assertAllEqual(combined_values[6:], sp_input1[1])\n      self.assertAllEqual(combined_shape, [2, 5, 6])\n\n  @test_util.run_deprecated_v1\n  def testSerializeDeserializeBatchInconsistentShape(self):\n    self._testSerializeDeserializeBatchInconsistentShapeHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeDeserializeBatchInconsistentShape(self):\n    self._testSerializeDeserializeBatchInconsistentShapeHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse,\n        dtypes.variant)\n\n  def _testSerializeDeserializeNestedBatchHelper(self,\n                                                 serialize_fn,\n                                                 deserialize_fn,\n                                                 out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input = self._SparseTensorValue_5x6(np.arange(6))\n      serialized = serialize_fn(sp_input, out_type=out_type)\n      serialized = array_ops.stack([serialized, serialized])\n      serialized = array_ops.stack([serialized, serialized])\n\n      sp_deserialized = deserialize_fn(serialized, dtype=dtypes.int32)\n\n      combined_indices, combined_values, combined_shape = sess.run(\n          sp_deserialized)\n\n      # minibatch 0\n      self.assertAllEqual(combined_indices[:6, :2], [[0, 0]] * 6)\n      self.assertAllEqual(combined_indices[:6, 2:], sp_input[0])\n      self.assertAllEqual(combined_values[:6], sp_input[1])\n      # minibatch 1\n      self.assertAllEqual(combined_indices[6:12, :2], [[0, 1]] * 6)\n      self.assertAllEqual(combined_indices[6:12, 2:], sp_input[0])\n      self.assertAllEqual(combined_values[6:12], sp_input[1])\n      # minibatch 2\n      self.assertAllEqual(combined_indices[12:18, :2], [[1, 0]] * 6)\n      self.assertAllEqual(combined_indices[12:18, 2:], sp_input[0])\n      self.assertAllEqual(combined_values[12:18], sp_input[1])\n      # minibatch 3\n      self.assertAllEqual(combined_indices[18:, :2], [[1, 1]] * 6)\n      self.assertAllEqual(combined_indices[18:, 2:], sp_input[0])\n      self.assertAllEqual(combined_values[18:], sp_input[1])\n\n      self.assertAllEqual(combined_shape, [2, 2, 5, 6])\n\n  @test_util.run_deprecated_v1\n  def testSerializeDeserializeNestedBatch(self):\n    self._testSerializeDeserializeNestedBatchHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeDeserializeNestedBatch(self):\n    self._testSerializeDeserializeNestedBatchHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse,\n        dtypes.variant)\n\n  def _testFeedSerializeDeserializeBatchHelper(self,\n                                               serialize_fn,\n                                               deserialize_fn,\n                                               out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input0 = self._SparseTensorPlaceholder()\n      sp_input1 = self._SparseTensorPlaceholder()\n      input0_val = self._SparseTensorValue_5x6(np.arange(6))\n      input1_val = self._SparseTensorValue_3x4(np.arange(6))\n      serialized0 = serialize_fn(sp_input0, out_type=out_type)\n      serialized1 = serialize_fn(sp_input1, out_type=out_type)\n      serialized_concat = array_ops.stack([serialized0, serialized1])\n\n      sp_deserialized = deserialize_fn(serialized_concat, dtype=dtypes.int32)\n\n      combined_indices, combined_values, combined_shape = sess.run(\n          sp_deserialized, {sp_input0: input0_val,\n                            sp_input1: input1_val})\n\n      self.assertAllEqual(combined_indices[:6, 0], [0] * 6)  # minibatch 0\n      self.assertAllEqual(combined_indices[:6, 1:], input0_val[0])\n      self.assertAllEqual(combined_indices[6:, 0], [1] * 6)  # minibatch 1\n      self.assertAllEqual(combined_indices[6:, 1:], input1_val[0])\n      self.assertAllEqual(combined_values[:6], input0_val[1])\n      self.assertAllEqual(combined_values[6:], input1_val[1])\n      self.assertAllEqual(combined_shape, [2, 5, 6])\n\n  @test_util.run_deprecated_v1\n  def testFeedSerializeDeserializeBatch(self):\n    self._testFeedSerializeDeserializeBatchHelper(sparse_ops.serialize_sparse,\n                                                  sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testFeedSerializeDeserializeManyBatch(self):\n    self._testFeedSerializeDeserializeBatchHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n\n  @test_util.run_deprecated_v1\n  def testFeedVariantSerializeDeserializeBatch(self):\n    self._testFeedSerializeDeserializeBatchHelper(sparse_ops.serialize_sparse,\n                                                  sparse_ops.deserialize_sparse,\n                                                  dtypes.variant)\n\n  def _testSerializeManyShapeHelper(self,\n                                    serialize_many_fn,\n                                    out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      # N == 4 because shape_value == [4, 5]\n      indices_value = np.array([[0, 0], [0, 1], [2, 0]], dtype=np.int64)\n      values_value = np.array([b\"a\", b\"b\", b\"c\"])\n      shape_value = np.array([4, 5], dtype=np.int64)\n      sparse_tensor = self._SparseTensorPlaceholder(dtype=dtypes.string)\n      serialized = serialize_many_fn(sparse_tensor, out_type=out_type)\n      serialized_value = sess.run(\n          serialized,\n          feed_dict={\n              sparse_tensor.indices: indices_value,\n              sparse_tensor.values: values_value,\n              sparse_tensor.dense_shape: shape_value\n          })\n      self.assertEqual(serialized_value.shape, (4, 3))\n\n  @test_util.run_deprecated_v1\n  def testSerializeManyShape(self):\n    self._testSerializeManyShapeHelper(sparse_ops.serialize_many_sparse)\n\n  def testVariantSerializeManyShape(self):\n    # NOTE: The following test is a no-op as it is currently not possible to\n    # convert the serialized variant value to a numpy value.\n    pass\n\n  def _testSerializeManyDeserializeBatchHelper(self,\n                                               serialize_many_fn,\n                                               deserialize_fn,\n                                               out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      # N == 4 because shape_value == [4, 5]\n      indices_value = np.array([[0, 0], [0, 1], [2, 0]], dtype=np.int64)\n      values_value = np.array([b\"a\", b\"b\", b\"c\"])\n      shape_value = np.array([4, 5], dtype=np.int64)\n      sparse_tensor = self._SparseTensorPlaceholder(dtype=dtypes.string)\n      serialized = serialize_many_fn(sparse_tensor, out_type=out_type)\n      deserialized = deserialize_fn(serialized, dtype=dtypes.string)\n      deserialized_value = sess.run(\n          deserialized,\n          feed_dict={\n              sparse_tensor.indices: indices_value,\n              sparse_tensor.values: values_value,\n              sparse_tensor.dense_shape: shape_value\n          })\n      self.assertAllEqual(deserialized_value.indices, indices_value)\n      self.assertAllEqual(deserialized_value.values, values_value)\n      self.assertAllEqual(deserialized_value.dense_shape, shape_value)\n\n  @test_util.run_deprecated_v1\n  def testSerializeManyDeserializeBatch(self):\n    self._testSerializeManyDeserializeBatchHelper(\n        sparse_ops.serialize_many_sparse, sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testSerializeManyDeserializeManyBatch(self):\n    self._testSerializeManyDeserializeBatchHelper(\n        sparse_ops.serialize_many_sparse, sparse_ops.deserialize_many_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeManyDeserializeBatch(self):\n    self._testSerializeManyDeserializeBatchHelper(\n        sparse_ops.serialize_many_sparse, sparse_ops.deserialize_sparse,\n        dtypes.variant)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeDeserializeScalar(self):\n    with self.session(use_gpu=False) as sess:\n      indices_value = np.array([[]], dtype=np.int64)\n      values_value = np.array([37], dtype=np.int32)\n      shape_value = np.array([], dtype=np.int64)\n      sparse_tensor = self._SparseTensorPlaceholder()\n      serialized = sparse_ops.serialize_sparse(\n          sparse_tensor, out_type=dtypes.variant)\n      deserialized = sparse_ops.deserialize_sparse(\n          serialized, dtype=dtypes.int32)\n      deserialized_value = sess.run(\n          deserialized,\n          feed_dict={\n              sparse_tensor.indices: indices_value,\n              sparse_tensor.values: values_value,\n              sparse_tensor.dense_shape: shape_value\n          })\n      self.assertAllEqual(deserialized_value.indices, indices_value)\n      self.assertAllEqual(deserialized_value.values, values_value)\n      self.assertAllEqual(deserialized_value.dense_shape, shape_value)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeDeserializeScalarBatch(self):\n    with self.session(use_gpu=False) as sess:\n      indices_value = np.array([[]], dtype=np.int64)\n      values_value = np.array([37], dtype=np.int32)\n      shape_value = np.array([], dtype=np.int64)\n      sparse_tensor = self._SparseTensorPlaceholder()\n      serialized = sparse_ops.serialize_sparse(\n          sparse_tensor, out_type=dtypes.variant)\n      stacked = array_ops.stack([serialized, serialized])\n      deserialized = sparse_ops.deserialize_sparse(stacked, dtype=dtypes.int32)\n      deserialized_value = sess.run(\n          deserialized,\n          feed_dict={\n              sparse_tensor.indices: indices_value,\n              sparse_tensor.values: values_value,\n              sparse_tensor.dense_shape: shape_value\n          })\n      self.assertAllEqual(deserialized_value.indices,\n                          np.array([[0], [1]], dtype=np.int64))\n      self.assertAllEqual(deserialized_value.values,\n                          np.array([37, 37], dtype=np.int32))\n      self.assertAllEqual(deserialized_value.dense_shape,\n                          np.array([2], dtype=np.int64))\n\n  def _testDeserializeFailsWrongTypeHelper(self,\n                                           serialize_fn,\n                                           deserialize_fn,\n                                           out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input0 = self._SparseTensorPlaceholder()\n      sp_input1 = self._SparseTensorPlaceholder()\n      input0_val = self._SparseTensorValue_5x6(np.arange(6))\n      input1_val = self._SparseTensorValue_3x4(np.arange(6))\n      serialized0 = serialize_fn(sp_input0, out_type=out_type)\n      serialized1 = serialize_fn(sp_input1, out_type=out_type)\n      serialized_concat = array_ops.stack([serialized0, serialized1])\n\n      sp_deserialized = deserialize_fn(serialized_concat, dtype=dtypes.int64)\n\n      with self.assertRaisesOpError(\n          r\"Requested SparseTensor of type int64 but \"\n          r\"SparseTensor\\[0\\].values.dtype\\(\\) == int32\"):\n        sess.run(sp_deserialized,\n                 {sp_input0: input0_val,\n                  sp_input1: input1_val})\n\n  @test_util.run_deprecated_v1\n  def testDeserializeFailsWrongType(self):\n    self._testDeserializeFailsWrongTypeHelper(sparse_ops.serialize_sparse,\n                                              sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testDeserializeManyFailsWrongType(self):\n    self._testDeserializeFailsWrongTypeHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantDeserializeFailsWrongType(self):\n    self._testDeserializeFailsWrongTypeHelper(sparse_ops.serialize_sparse,\n                                              sparse_ops.deserialize_sparse,\n                                              dtypes.variant)\n\n  def _testDeserializeFailsInconsistentRankHelper(self,\n                                                  serialize_fn,\n                                                  deserialize_fn,\n                                                  out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input0 = self._SparseTensorPlaceholder()\n      sp_input1 = self._SparseTensorPlaceholder()\n      input0_val = self._SparseTensorValue_5x6(np.arange(6))\n      input1_val = self._SparseTensorValue_1x1x1()\n      serialized0 = serialize_fn(sp_input0, out_type=out_type)\n      serialized1 = serialize_fn(sp_input1, out_type=out_type)\n      serialized_concat = array_ops.stack([serialized0, serialized1])\n\n      sp_deserialized = deserialize_fn(serialized_concat, dtype=dtypes.int32)\n\n      with self.assertRaisesOpError(\n          r\"Inconsistent shape across SparseTensors: rank prior to \"\n          r\"SparseTensor\\[1\\] was: 2 but rank of SparseTensor\\[1\\] is: 3\"):\n        sess.run(sp_deserialized,\n                 {sp_input0: input0_val,\n                  sp_input1: input1_val})\n\n  @test_util.run_deprecated_v1\n  def testDeserializeFailsInconsistentRank(self):\n    self._testDeserializeFailsInconsistentRankHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testDeserializeManyFailsInconsistentRank(self):\n    self._testDeserializeFailsInconsistentRankHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantDeserializeFailsInconsistentRank(self):\n    self._testDeserializeFailsInconsistentRankHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse,\n        dtypes.variant)\n\n  def _testDeserializeFailsInvalidProtoHelper(self,\n                                              serialize_fn,\n                                              deserialize_fn,\n                                              out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input0 = self._SparseTensorPlaceholder()\n      input0_val = self._SparseTensorValue_5x6(np.arange(6))\n      serialized0 = serialize_fn(sp_input0, out_type=out_type)\n      serialized1 = [\"a\", \"b\", \"c\"]\n      serialized_concat = array_ops.stack([serialized0, serialized1])\n\n      sp_deserialized = deserialize_fn(serialized_concat, dtype=dtypes.int32)\n\n      with self.assertRaisesOpError(r\"Could not parse serialized proto\"):\n        sess.run(sp_deserialized, {sp_input0: input0_val})\n\n  @test_util.run_deprecated_v1\n  def testDeserializeFailsInvalidProto(self):\n    self._testDeserializeFailsInvalidProtoHelper(sparse_ops.serialize_sparse,\n                                                 sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testDeserializeManyFailsInvalidProto(self):\n    self._testDeserializeFailsInvalidProtoHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n\n\nif __name__ == \"__main__\":\n  test.main()\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/platform/errors.h\"\n\nnamespace tensorflow {\n\nusing shape_inference::DimensionHandle;\nusing shape_inference::InferenceContext;\nusing shape_inference::ShapeHandle;\n\nnamespace {\n\nStatus SparseSparseMinOrMaxShapeFn(InferenceContext* c) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));  // a_indices\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));  // a_values\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));  // a_shape\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 2, &unused));  // b_indices\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(4), 1, &unused));  // b_values\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(5), 1, &unused));  // b_shape\n  c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,\n                             InferenceContext::kUnknownDim));\n  c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n  return Status::OK();\n}\n\n}  // namespace\n\nREGISTER_OP(\"SparseAddGrad\")\n    .Input(\"backprop_val_grad: T\")\n    .Input(\"a_indices: int64\")\n    .Input(\"b_indices: int64\")\n    .Input(\"sum_indices: int64\")\n    .Output(\"a_val_grad: T\")\n    .Output(\"b_val_grad: T\")\n    .Attr(\"T: numbertype\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle a_indices;\n      ShapeHandle b_indices;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &a_indices));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 2, &b_indices));\n      c->set_output(0, c->Vector(c->Dim(a_indices, 0)));\n      c->set_output(1, c->Vector(c->Dim(b_indices, 0)));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseAdd\")\n    .Input(\"a_indices: int64\")\n    .Input(\"a_values: T\")\n    .Input(\"a_shape: int64\")\n    .Input(\"b_indices: int64\")\n    .Input(\"b_values: T\")\n    .Input(\"b_shape: int64\")\n    .Input(\"thresh: Treal\")\n    .Output(\"sum_indices: int64\")\n    .Output(\"sum_values: T\")\n    .Output(\"sum_shape: int64\")\n    .Attr(\"T: numbertype\")\n    .Attr(\"Treal: realnumbertype\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle a_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &a_shape));\n      c->set_output(\n          0, c->Matrix(InferenceContext::kUnknownDim, c->Dim(a_shape, 0)));\n      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(2, a_shape);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseTensorDenseMatMul\")\n    .Input(\"a_indices: Tindices\")\n    .Input(\"a_values: T\")\n    .Input(\"a_shape: int64\")\n    .Input(\"b: T\")\n    .Output(\"product: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32,int64} = DT_INT64\")\n    .Attr(\"adjoint_a: bool = false\")\n    .Attr(\"adjoint_b: bool = false\")\n    .SetShapeFn([](InferenceContext* c) {\n      DimensionHandle unused_dim;\n      ShapeHandle unused;\n      ShapeHandle b;\n      ShapeHandle a_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));  // a_indices\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));  // a_values\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(2, &a_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(a_shape, 2, &a_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 2, &b));\n\n      bool adjoint_a;\n      bool adjoint_b;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"adjoint_a\", &adjoint_a));\n      TF_RETURN_IF_ERROR(c->GetAttr(\"adjoint_b\", &adjoint_b));\n\n      DimensionHandle output_right = c->Dim(b, adjoint_b ? 0 : 1);\n      DimensionHandle output_left = c->Dim(a_shape, adjoint_a ? 1 : 0);\n      DimensionHandle inner_left = c->Dim(a_shape, adjoint_a ? 0 : 1);\n      DimensionHandle inner_right = c->Dim(b, adjoint_b ? 1 : 0);\n      TF_RETURN_IF_ERROR(c->Merge(inner_left, inner_right, &unused_dim));\n      c->set_output(0, c->Matrix(output_left, output_right));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SerializeSparse\")\n    .Input(\"sparse_indices: int64\")\n    .Input(\"sparse_values: T\")\n    .Input(\"sparse_shape: int64\")\n    .Attr(\"T: type\")\n    .Output(\"serialized_sparse: out_type\")\n    .Attr(\"out_type: {string, variant} = DT_STRING\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n      c->set_output(0, c->Vector(3));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SerializeManySparse\")\n    .Input(\"sparse_indices: int64\")\n    .Input(\"sparse_values: T\")\n    .Input(\"sparse_shape: int64\")\n    .Attr(\"T: type\")\n    .Output(\"serialized_sparse: out_type\")\n    .Attr(\"out_type: {string, variant} = DT_STRING\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n      c->set_output(0, c->Matrix(InferenceContext::kUnknownDim, 3));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"DeserializeSparse\")\n    .Input(\"serialized_sparse: Tserialized\")\n    .Output(\"sparse_indices: int64\")\n    .Output(\"sparse_values: dtype\")\n    .Output(\"sparse_shape: int64\")\n    .Attr(\"dtype: type\")\n    .Attr(\"Tserialized: {string, variant} = DT_STRING\")\n    .SetShapeFn([](InferenceContext* c) {\n      // serialized sparse is [?, ..., ?, 3] vector.\n      ShapeHandle unused_shape;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &unused_shape));\n      DimensionHandle unused;\n      TF_RETURN_IF_ERROR(c->WithValue(c->Dim(c->input(0), -1), 3, &unused));\n      c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,\n                                 InferenceContext::kUnknownDim));\n      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(2, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"DeserializeManySparse\")\n    .Input(\"serialized_sparse: string\")\n    .Output(\"sparse_indices: int64\")\n    .Output(\"sparse_values: dtype\")\n    .Output(\"sparse_shape: int64\")\n    .Attr(\"dtype: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      // serialized sparse is [?,3] matrix.\n      ShapeHandle serialized_sparse;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &serialized_sparse));\n      DimensionHandle unused;\n      TF_RETURN_IF_ERROR(\n          c->WithValue(c->Dim(serialized_sparse, 1), 3, &unused));\n\n      c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,\n                                 InferenceContext::kUnknownDim));\n      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(2, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseToDense\")\n    .Input(\"sparse_indices: Tindices\")\n    .Input(\"output_shape: Tindices\")\n    .Input(\"sparse_values: T\")\n    .Input(\"default_value: T\")\n    .Attr(\"validate_indices: bool = true\")\n    .Attr(\"T: type\")\n    .Output(\"dense: T\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseConcat\")\n    .Input(\"indices: N * int64\")\n    .Input(\"values: N * T\")\n    .Input(\"shapes: N * int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"concat_dim: int\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      // These accumulates the sum.\n      DimensionHandle output_row_count = c->MakeDim(0ll);\n\n      // These are only merged.\n      DimensionHandle output_ind_cols = c->UnknownDim();\n      ShapeHandle output_shape = c->UnknownShape();\n\n      const int n = c->num_inputs() / 3;\n      for (int i = 0; i < n; i++) {\n        ShapeHandle ind;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), 2, &ind));\n        ShapeHandle val;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i + n), 1, &val));\n        ShapeHandle shape;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i + 2 * n), 1, &shape));\n\n        // Add to output_ind_rows.\n        DimensionHandle num_dim;\n        TF_RETURN_IF_ERROR(c->Merge(c->Dim(ind, 0), c->Dim(val, 0), &num_dim));\n        TF_RETURN_IF_ERROR(\n            c->Add(output_row_count, num_dim, &output_row_count));\n\n        // Merge into output_ind_cols and output_shape.\n        TF_RETURN_IF_ERROR(\n            c->Merge(output_ind_cols, c->Dim(ind, 1), &output_ind_cols));\n        TF_RETURN_IF_ERROR(c->Merge(output_shape, shape, &output_shape));\n      }\n\n      c->set_output(0, c->Matrix(output_row_count, output_ind_cols));\n      c->set_output(1, c->Vector(output_row_count));\n      c->set_output(2, output_shape);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseCross\")\n    .Input(\"indices: N * int64\")\n    .Input(\"values: sparse_types\")\n    .Input(\"shapes: N * int64\")\n    .Input(\"dense_inputs: dense_types\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: out_type\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"N: int >= 0\")\n    .Attr(\"hashed_output: bool\")\n    .Attr(\"num_buckets: int >= 0\")\n    .Attr(\"hash_key: int\")\n    .Attr(\"sparse_types: list({int64, string}) >= 0\")\n    .Attr(\"dense_types: list({int64, string}) >= 0\")\n    .Attr(\"out_type: {int64, string}\")\n    .Attr(\"internal_type: {int64, string}\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      c->set_output(0, c->Matrix(c->UnknownDim(), 2));\n      c->set_output(1, c->Vector(c->UnknownDim()));\n      c->set_output(2, c->Vector(2));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseCrossV2\")\n    .Input(\"indices: N * int64\")\n    .Input(\"values: sparse_types\")\n    .Input(\"shapes: N * int64\")\n    .Input(\"dense_inputs: dense_types\")\n    .Input(\"sep: string\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: string\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"N: int >= 0\")\n    .Attr(\"sparse_types: list({int64, string}) >= 0\")\n    .Attr(\"dense_types: list({int64, string}) >= 0\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      c->set_output(0, c->Matrix(c->UnknownDim(), 2));\n      c->set_output(1, c->Vector(c->UnknownDim()));\n      c->set_output(2, c->Vector(2));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseCrossHashed\")\n    .Input(\"indices: N * int64\")\n    .Input(\"values: sparse_types\")\n    .Input(\"shapes: N * int64\")\n    .Input(\"dense_inputs: dense_types\")\n    .Input(\"num_buckets: int64\")\n    .Input(\"strong_hash: bool\")\n    .Input(\"salt: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: int64\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"N: int >= 0\")\n    .Attr(\"sparse_types: list({int64, string}) >= 0\")\n    .Attr(\"dense_types: list({int64, string}) >= 0\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      c->set_output(0, c->Matrix(c->UnknownDim(), 2));\n      c->set_output(1, c->Vector(c->UnknownDim()));\n      c->set_output(2, c->Vector(2));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseSplit\")\n    .Input(\"split_dim: int64\")\n    .Input(\"indices: int64\")\n    .Input(\"values: T\")\n    .Input(\"shape: int64\")\n    .Output(\"output_indices: num_split * int64\")\n    .Output(\"output_values:  num_split * T\")\n    .Output(\"output_shape:   num_split * int64\")\n    .Attr(\"num_split: int >= 1\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape = c->input(3);\n      ShapeHandle output_indices =\n          c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\n      ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);\n      ShapeHandle output_shape = input_shape;\n\n      // Copy the outputs into the output ranges.\n      int num_splits = c->num_outputs() / 3;\n      int out_idx = 0;\n      for (int i = 0; i < num_splits; ++i)\n        c->set_output(out_idx++, output_indices);\n      for (int i = 0; i < num_splits; ++i)\n        c->set_output(out_idx++, output_values);\n      for (int i = 0; i < num_splits; ++i)\n        c->set_output(out_idx++, output_shape);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseSliceGrad\")\n    .Input(\"backprop_val_grad: T\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_start: int64\")\n    .Input(\"output_indices: int64\")\n    .Output(\"val_grad: T\")\n    .Attr(\"T: numbertype\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle indices;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &indices));\n      c->set_output(0, c->Vector(c->Dim(indices, 0)));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseSlice\")\n    .Input(\"indices: int64\")\n    .Input(\"values: T\")\n    .Input(\"shape: int64\")\n    .Input(\"start: int64\")\n    .Input(\"size: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape = c->input(2);\n      ShapeHandle output_indices =\n          c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\n      ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);\n      ShapeHandle output_shape = input_shape;\n\n      c->set_output(0, output_indices);\n      c->set_output(1, output_values);\n      c->set_output(2, output_shape);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseReorder\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_values: T\")\n    .Input(\"input_shape: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle indices;\n      ShapeHandle values;\n      ShapeHandle unused;\n\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &indices));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &values));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n\n      c->set_output(0, indices);\n      c->set_output(1, values);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseReshape\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_shape: int64\")\n    .Input(\"new_shape: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_shape: int64\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle indices;\n      ShapeHandle unused;\n      ShapeHandle new_shape;\n\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &indices));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &new_shape));\n\n      c->set_output(0, c->Matrix(c->Dim(indices, 0), c->Dim(new_shape, 0)));\n      c->set_output(1, new_shape);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseTensorDenseAdd\")\n    .Input(\"a_indices: Tindices\")\n    .Input(\"a_values: T\")\n    .Input(\"a_shape: Tindices\")\n    .Input(\"b: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: numbertype\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->input(3));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseReduceMax\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_values: T\")\n    .Input(\"input_shape: int64\")\n    .Input(\"reduction_axes: int32\")\n    .Attr(\"keep_dims: bool = False\")\n    .Output(\"output: T\")\n    .Attr(\"T: realnumbertype\")\n    .SetShapeFn(shape_inference::SparseReduceShapeFn);\n\nREGISTER_OP(\"SparseReduceMaxSparse\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_values: T\")\n    .Input(\"input_shape: int64\")\n    .Input(\"reduction_axes: int32\")\n    .Attr(\"keep_dims: bool = False\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"T: realnumbertype\")\n    .SetShapeFn(shape_inference::UnknownShape);\n\nREGISTER_OP(\"SparseReduceSum\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_values: T\")\n    .Input(\"input_shape: int64\")\n    .Input(\"reduction_axes: int32\")\n    .Attr(\"keep_dims: bool = False\")\n    .Output(\"output: T\")\n    .Attr(\"T: numbertype\")\n    .SetShapeFn(shape_inference::SparseReduceShapeFn);\n\nREGISTER_OP(\"SparseReduceSumSparse\")\n    .Input(\"input_indices: int64\")\n    .Input(\"input_values: T\")\n    .Input(\"input_shape: int64\")\n    .Input(\"reduction_axes: int32\")\n    .Attr(\"keep_dims: bool = False\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Output(\"output_shape: int64\")\n    .Attr(\"T: numbertype\")\n    .SetShapeFn(shape_inference::UnknownShape);\n\n#define SPARSE_DENSE_CWISE_SIGNATURE()                           \\\n  Input(\"sp_indices: int64\")                                     \\\n      .Input(\"sp_values: T\")                                     \\\n      .Input(\"sp_shape: int64\")                                  \\\n      .Input(\"dense: T\")                                         \\\n      .Output(\"output: T\")                                       \\\n      .Attr(\"T: numbertype\")                                     \\\n      .SetShapeFn([](InferenceContext* c) {                      \\\n        ShapeHandle input;                                       \\\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &input)); \\\n        c->set_output(0, c->Vector(c->Dim(input, 0)));           \\\n        return Status::OK();                                     \\\n      })\n\nREGISTER_OP(\"SparseDenseCwiseMul\").SPARSE_DENSE_CWISE_SIGNATURE();\n\nREGISTER_OP(\"SparseDenseCwiseDiv\").SPARSE_DENSE_CWISE_SIGNATURE();\n\nREGISTER_OP(\"SparseDenseCwiseAdd\").SPARSE_DENSE_CWISE_SIGNATURE();\n\n#undef SPARSE_DENSE_CWISE_SIGNATURE\n\nREGISTER_OP(\"SparseSoftmax\")\n    .Input(\"sp_indices: int64\")\n    .Input(\"sp_values: T\")\n    .Input(\"sp_shape: int64\")\n    .Output(\"output: T\")\n    .Attr(\"T: {float, double}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      ShapeHandle values;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));  // sp_indices\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &values));  // sp_values\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n      c->set_output(0, values);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseSparseMaximum\")\n    .Input(\"a_indices: int64\")\n    .Input(\"a_values: T\")\n    .Input(\"a_shape: int64\")\n    .Input(\"b_indices: int64\")\n    .Input(\"b_values: T\")\n    .Input(\"b_shape: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Attr(\"T: realnumbertype\")\n    .SetShapeFn(SparseSparseMinOrMaxShapeFn);\n\nREGISTER_OP(\"SparseSparseMinimum\")\n    .Input(\"a_indices: int64\")\n    .Input(\"a_values: T\")\n    .Input(\"a_shape: int64\")\n    .Input(\"b_indices: int64\")\n    .Input(\"b_values: T\")\n    .Input(\"b_shape: int64\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Attr(\"T: numbertype\")\n    .SetShapeFn(SparseSparseMinOrMaxShapeFn);\n\nREGISTER_OP(\"AddSparseToTensorsMap\")\n    .Input(\"sparse_indices: int64\")\n    .Input(\"sparse_values: T\")\n    .Input(\"sparse_shape: int64\")\n    .Output(\"sparse_handle: int64\")\n    .Attr(\"T: type\")\n    .Attr(\"container: string = ''\")\n    .Attr(\"shared_name: string = ''\")\n    .SetIsStateful()\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n      c->set_output(0, c->Scalar());\n      return Status::OK();\n    });\n\nREGISTER_OP(\"AddManySparseToTensorsMap\")\n    .Input(\"sparse_indices: int64\")\n    .Input(\"sparse_values: T\")\n    .Input(\"sparse_shape: int64\")\n    .Output(\"sparse_handles: int64\")\n    .Attr(\"T: type\")\n    .Attr(\"container: string = ''\")\n    .Attr(\"shared_name: string = ''\")\n    .SetIsStateful()\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &unused));\n      c->set_output(0, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"TakeManySparseFromTensorsMap\")\n    .Input(\"sparse_handles: int64\")\n    .Output(\"sparse_indices: int64\")\n    .Output(\"sparse_values: dtype\")\n    .Output(\"sparse_shape: int64\")\n    .Attr(\"dtype: type\")\n    .Attr(\"container: string = ''\")\n    .Attr(\"shared_name: string = ''\")\n    .SetIsStateful()\n    .SetShapeFn([](InferenceContext* c) {\n      // serialized sparse is [?,1] matrix.\n      ShapeHandle sparse_handles;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &sparse_handles));\n\n      c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,\n                                 InferenceContext::kUnknownDim));\n      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(2, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseFillEmptyRows\")\n    .Input(\"indices: int64\")\n    .Input(\"values: T\")\n    .Input(\"dense_shape: int64\")\n    .Input(\"default_value: T\")\n    .Output(\"output_indices: int64\")\n    .Output(\"output_values: T\")\n    .Output(\"empty_row_indicator: bool\")\n    .Output(\"reverse_index_map: int64\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_indices = c->input(0);\n      TF_RETURN_IF_ERROR(c->WithRank(input_indices, 2, &input_indices));\n      ShapeHandle input_values = c->input(1);\n      TF_RETURN_IF_ERROR(c->WithRank(input_values, 1, &input_values));\n      ShapeHandle input_shape = c->input(2);\n      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 1, &input_shape));\n      ShapeHandle default_value = c->input(3);\n      TF_RETURN_IF_ERROR(c->WithRank(default_value, 0, &default_value));\n      DimensionHandle N = c->Dim(input_indices, 0);\n      TF_RETURN_IF_ERROR(c->Merge(N, c->Dim(input_values, 0), &N));\n      DimensionHandle unused_dim;\n      TF_RETURN_IF_ERROR(c->Merge(c->Dim(input_indices, 1),\n                                  c->Dim(input_shape, 0), &unused_dim));\n      if (c->Value(c->NumElements(input_shape)) == 0)\n        return errors::InvalidArgument(\"dense_shape must not be empty\");\n      ShapeHandle output_indices =\n          c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\n      ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);\n      ShapeHandle constant_input_shape;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(2, &constant_input_shape));\n      ShapeHandle empty_row_indicator =\n          c->Vector(c->Dim(constant_input_shape, 0));\n      ShapeHandle reverse_index_map = c->Vector(N);\n      c->set_output(0, output_indices);\n      c->set_output(1, output_values);\n      c->set_output(2, empty_row_indicator);\n      c->set_output(3, reverse_index_map);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SparseFillEmptyRowsGrad\")\n    .Input(\"reverse_index_map: int64\")\n    .Input(\"grad_values: T\")\n    .Output(\"d_values: T\")\n    .Output(\"d_default_value: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle reverse_index_map = c->input(0);\n      TF_RETURN_IF_ERROR(c->WithRank(reverse_index_map, 1, &reverse_index_map));\n      ShapeHandle grad_values = c->input(1);\n      TF_RETURN_IF_ERROR(c->WithRank(grad_values, 1, &grad_values));\n      c->set_output(0, reverse_index_map);\n      c->set_output(1, c->Scalar());\n      return Status::OK();\n    });\n\n}  // namespace tensorflow\n", "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for SerializeSparse.\"\"\"\n\nimport numpy as np\n\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import sparse_tensor as sparse_tensor_lib\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gen_resource_variable_ops\nfrom tensorflow.python.ops import sparse_ops\nfrom tensorflow.python.platform import test\n\n\nclass SerializeSparseTest(test.TestCase):\n\n  def _SparseTensorPlaceholder(self, dtype=None):\n    if dtype is None:\n      dtype = dtypes.int32\n    return sparse_tensor_lib.SparseTensor(\n        array_ops.placeholder(dtypes.int64),\n        array_ops.placeholder(dtype), array_ops.placeholder(dtypes.int64))\n\n  def _SparseTensorValue_5x6(self, permutation):\n    ind = np.array([[0, 0], [1, 0], [1, 3], [1, 4], [3, 2],\n                    [3, 3]]).astype(np.int64)\n    val = np.array([0, 10, 13, 14, 32, 33]).astype(np.int32)\n\n    ind = ind[permutation]\n    val = val[permutation]\n\n    shape = np.array([5, 6]).astype(np.int64)\n    return sparse_tensor_lib.SparseTensorValue(ind, val, shape)\n\n  def _SparseTensorValue_3x4(self, permutation):\n    ind = np.array([[0, 0], [1, 0], [1, 2], [1, 3], [2, 2],\n                    [2, 3]]).astype(np.int64)\n    val = np.array([0, 10, 13, 14, 32, 33]).astype(np.int32)\n\n    ind = ind[permutation]\n    val = val[permutation]\n\n    shape = np.array([3, 4]).astype(np.int64)\n    return sparse_tensor_lib.SparseTensorValue(ind, val, shape)\n\n  def _SparseTensorValue_1x1x1(self):\n    ind = np.array([[0, 0, 0]]).astype(np.int64)\n    val = np.array([0]).astype(np.int32)\n    shape = np.array([3, 4, 5]).astype(np.int64)\n    return sparse_tensor_lib.SparseTensorValue(ind, val, shape)\n\n  def _testSerializeDeserializeHelper(self,\n                                      serialize_fn,\n                                      deserialize_fn,\n                                      out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input = self._SparseTensorValue_5x6(np.arange(6))\n      serialized = serialize_fn(sp_input, out_type=out_type)\n      sp_deserialized = deserialize_fn(serialized, dtype=dtypes.int32)\n\n      indices, values, shape = self.evaluate(sp_deserialized)\n\n      self.assertAllEqual(indices, sp_input[0])\n      self.assertAllEqual(values, sp_input[1])\n      self.assertAllEqual(shape, sp_input[2])\n\n  def testSerializeDeserialize(self):\n    self._testSerializeDeserializeHelper(sparse_ops.serialize_sparse,\n                                         sparse_ops.deserialize_sparse)\n\n  def testVariantSerializeDeserialize(self):\n    self._testSerializeDeserializeHelper(sparse_ops.serialize_sparse,\n                                         sparse_ops.deserialize_sparse,\n                                         dtypes.variant)\n\n  def _testSerializeDeserializeBatchHelper(self,\n                                           serialize_fn,\n                                           deserialize_fn,\n                                           out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input = self._SparseTensorValue_5x6(np.arange(6))\n      serialized = serialize_fn(sp_input, out_type=out_type)\n      serialized = array_ops.stack([serialized, serialized])\n\n      sp_deserialized = deserialize_fn(serialized, dtype=dtypes.int32)\n\n      combined_indices, combined_values, combined_shape = sess.run(\n          sp_deserialized)\n\n      self.assertAllEqual(combined_indices[:6, 0], [0] * 6)  # minibatch 0\n      self.assertAllEqual(combined_indices[:6, 1:], sp_input[0])\n      self.assertAllEqual(combined_indices[6:, 0], [1] * 6)  # minibatch 1\n      self.assertAllEqual(combined_indices[6:, 1:], sp_input[0])\n      self.assertAllEqual(combined_values[:6], sp_input[1])\n      self.assertAllEqual(combined_values[6:], sp_input[1])\n      self.assertAllEqual(combined_shape, [2, 5, 6])\n\n  @test_util.run_deprecated_v1\n  def testSerializeDeserializeBatch(self):\n    self._testSerializeDeserializeBatchHelper(sparse_ops.serialize_sparse,\n                                              sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testSerializeDeserializeManyBatch(self):\n    self._testSerializeDeserializeBatchHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeDeserializeBatch(self):\n    self._testSerializeDeserializeBatchHelper(sparse_ops.serialize_sparse,\n                                              sparse_ops.deserialize_sparse,\n                                              dtypes.variant)\n\n  def _testSerializeDeserializeBatchInconsistentShapeHelper(\n      self, serialize_fn, deserialize_fn, out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input0 = self._SparseTensorValue_5x6(np.arange(6))\n      sp_input1 = self._SparseTensorValue_3x4(np.arange(6))\n      serialized0 = serialize_fn(sp_input0, out_type=out_type)\n      serialized1 = serialize_fn(sp_input1, out_type=out_type)\n      serialized = array_ops.stack([serialized0, serialized1])\n\n      sp_deserialized = deserialize_fn(serialized, dtype=dtypes.int32)\n\n      combined_indices, combined_values, combined_shape = sess.run(\n          sp_deserialized)\n\n      self.assertAllEqual(combined_indices[:6, 0], [0] * 6)  # minibatch 0\n      self.assertAllEqual(combined_indices[:6, 1:], sp_input0[0])\n      self.assertAllEqual(combined_indices[6:, 0], [1] * 6)  # minibatch 1\n      self.assertAllEqual(combined_indices[6:, 1:], sp_input1[0])\n      self.assertAllEqual(combined_values[:6], sp_input0[1])\n      self.assertAllEqual(combined_values[6:], sp_input1[1])\n      self.assertAllEqual(combined_shape, [2, 5, 6])\n\n  @test_util.run_deprecated_v1\n  def testSerializeDeserializeBatchInconsistentShape(self):\n    self._testSerializeDeserializeBatchInconsistentShapeHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeDeserializeBatchInconsistentShape(self):\n    self._testSerializeDeserializeBatchInconsistentShapeHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse,\n        dtypes.variant)\n\n  def _testSerializeDeserializeNestedBatchHelper(self,\n                                                 serialize_fn,\n                                                 deserialize_fn,\n                                                 out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input = self._SparseTensorValue_5x6(np.arange(6))\n      serialized = serialize_fn(sp_input, out_type=out_type)\n      serialized = array_ops.stack([serialized, serialized])\n      serialized = array_ops.stack([serialized, serialized])\n\n      sp_deserialized = deserialize_fn(serialized, dtype=dtypes.int32)\n\n      combined_indices, combined_values, combined_shape = sess.run(\n          sp_deserialized)\n\n      # minibatch 0\n      self.assertAllEqual(combined_indices[:6, :2], [[0, 0]] * 6)\n      self.assertAllEqual(combined_indices[:6, 2:], sp_input[0])\n      self.assertAllEqual(combined_values[:6], sp_input[1])\n      # minibatch 1\n      self.assertAllEqual(combined_indices[6:12, :2], [[0, 1]] * 6)\n      self.assertAllEqual(combined_indices[6:12, 2:], sp_input[0])\n      self.assertAllEqual(combined_values[6:12], sp_input[1])\n      # minibatch 2\n      self.assertAllEqual(combined_indices[12:18, :2], [[1, 0]] * 6)\n      self.assertAllEqual(combined_indices[12:18, 2:], sp_input[0])\n      self.assertAllEqual(combined_values[12:18], sp_input[1])\n      # minibatch 3\n      self.assertAllEqual(combined_indices[18:, :2], [[1, 1]] * 6)\n      self.assertAllEqual(combined_indices[18:, 2:], sp_input[0])\n      self.assertAllEqual(combined_values[18:], sp_input[1])\n\n      self.assertAllEqual(combined_shape, [2, 2, 5, 6])\n\n  @test_util.run_deprecated_v1\n  def testSerializeDeserializeNestedBatch(self):\n    self._testSerializeDeserializeNestedBatchHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeDeserializeNestedBatch(self):\n    self._testSerializeDeserializeNestedBatchHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse,\n        dtypes.variant)\n\n  def _testFeedSerializeDeserializeBatchHelper(self,\n                                               serialize_fn,\n                                               deserialize_fn,\n                                               out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input0 = self._SparseTensorPlaceholder()\n      sp_input1 = self._SparseTensorPlaceholder()\n      input0_val = self._SparseTensorValue_5x6(np.arange(6))\n      input1_val = self._SparseTensorValue_3x4(np.arange(6))\n      serialized0 = serialize_fn(sp_input0, out_type=out_type)\n      serialized1 = serialize_fn(sp_input1, out_type=out_type)\n      serialized_concat = array_ops.stack([serialized0, serialized1])\n\n      sp_deserialized = deserialize_fn(serialized_concat, dtype=dtypes.int32)\n\n      combined_indices, combined_values, combined_shape = sess.run(\n          sp_deserialized, {sp_input0: input0_val,\n                            sp_input1: input1_val})\n\n      self.assertAllEqual(combined_indices[:6, 0], [0] * 6)  # minibatch 0\n      self.assertAllEqual(combined_indices[:6, 1:], input0_val[0])\n      self.assertAllEqual(combined_indices[6:, 0], [1] * 6)  # minibatch 1\n      self.assertAllEqual(combined_indices[6:, 1:], input1_val[0])\n      self.assertAllEqual(combined_values[:6], input0_val[1])\n      self.assertAllEqual(combined_values[6:], input1_val[1])\n      self.assertAllEqual(combined_shape, [2, 5, 6])\n\n  @test_util.run_deprecated_v1\n  def testFeedSerializeDeserializeBatch(self):\n    self._testFeedSerializeDeserializeBatchHelper(sparse_ops.serialize_sparse,\n                                                  sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testFeedSerializeDeserializeManyBatch(self):\n    self._testFeedSerializeDeserializeBatchHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n\n  @test_util.run_deprecated_v1\n  def testFeedVariantSerializeDeserializeBatch(self):\n    self._testFeedSerializeDeserializeBatchHelper(sparse_ops.serialize_sparse,\n                                                  sparse_ops.deserialize_sparse,\n                                                  dtypes.variant)\n\n  def _testSerializeManyShapeHelper(self,\n                                    serialize_many_fn,\n                                    out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      # N == 4 because shape_value == [4, 5]\n      indices_value = np.array([[0, 0], [0, 1], [2, 0]], dtype=np.int64)\n      values_value = np.array([b\"a\", b\"b\", b\"c\"])\n      shape_value = np.array([4, 5], dtype=np.int64)\n      sparse_tensor = self._SparseTensorPlaceholder(dtype=dtypes.string)\n      serialized = serialize_many_fn(sparse_tensor, out_type=out_type)\n      serialized_value = sess.run(\n          serialized,\n          feed_dict={\n              sparse_tensor.indices: indices_value,\n              sparse_tensor.values: values_value,\n              sparse_tensor.dense_shape: shape_value\n          })\n      self.assertEqual(serialized_value.shape, (4, 3))\n\n  @test_util.run_deprecated_v1\n  def testSerializeManyShape(self):\n    self._testSerializeManyShapeHelper(sparse_ops.serialize_many_sparse)\n\n  def testVariantSerializeManyShape(self):\n    # NOTE: The following test is a no-op as it is currently not possible to\n    # convert the serialized variant value to a numpy value.\n    pass\n\n  def _testSerializeManyDeserializeBatchHelper(self,\n                                               serialize_many_fn,\n                                               deserialize_fn,\n                                               out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      # N == 4 because shape_value == [4, 5]\n      indices_value = np.array([[0, 0], [0, 1], [2, 0]], dtype=np.int64)\n      values_value = np.array([b\"a\", b\"b\", b\"c\"])\n      shape_value = np.array([4, 5], dtype=np.int64)\n      sparse_tensor = self._SparseTensorPlaceholder(dtype=dtypes.string)\n      serialized = serialize_many_fn(sparse_tensor, out_type=out_type)\n      deserialized = deserialize_fn(serialized, dtype=dtypes.string)\n      deserialized_value = sess.run(\n          deserialized,\n          feed_dict={\n              sparse_tensor.indices: indices_value,\n              sparse_tensor.values: values_value,\n              sparse_tensor.dense_shape: shape_value\n          })\n      self.assertAllEqual(deserialized_value.indices, indices_value)\n      self.assertAllEqual(deserialized_value.values, values_value)\n      self.assertAllEqual(deserialized_value.dense_shape, shape_value)\n\n  @test_util.run_deprecated_v1\n  def testSerializeManyDeserializeBatch(self):\n    self._testSerializeManyDeserializeBatchHelper(\n        sparse_ops.serialize_many_sparse, sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testSerializeManyDeserializeManyBatch(self):\n    self._testSerializeManyDeserializeBatchHelper(\n        sparse_ops.serialize_many_sparse, sparse_ops.deserialize_many_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeManyDeserializeBatch(self):\n    self._testSerializeManyDeserializeBatchHelper(\n        sparse_ops.serialize_many_sparse, sparse_ops.deserialize_sparse,\n        dtypes.variant)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeDeserializeScalar(self):\n    with self.session(use_gpu=False) as sess:\n      indices_value = np.array([[]], dtype=np.int64)\n      values_value = np.array([37], dtype=np.int32)\n      shape_value = np.array([], dtype=np.int64)\n      sparse_tensor = self._SparseTensorPlaceholder()\n      serialized = sparse_ops.serialize_sparse(\n          sparse_tensor, out_type=dtypes.variant)\n      deserialized = sparse_ops.deserialize_sparse(\n          serialized, dtype=dtypes.int32)\n      deserialized_value = sess.run(\n          deserialized,\n          feed_dict={\n              sparse_tensor.indices: indices_value,\n              sparse_tensor.values: values_value,\n              sparse_tensor.dense_shape: shape_value\n          })\n      self.assertAllEqual(deserialized_value.indices, indices_value)\n      self.assertAllEqual(deserialized_value.values, values_value)\n      self.assertAllEqual(deserialized_value.dense_shape, shape_value)\n\n  @test_util.run_deprecated_v1\n  def testVariantSerializeDeserializeScalarBatch(self):\n    with self.session(use_gpu=False) as sess:\n      indices_value = np.array([[]], dtype=np.int64)\n      values_value = np.array([37], dtype=np.int32)\n      shape_value = np.array([], dtype=np.int64)\n      sparse_tensor = self._SparseTensorPlaceholder()\n      serialized = sparse_ops.serialize_sparse(\n          sparse_tensor, out_type=dtypes.variant)\n      stacked = array_ops.stack([serialized, serialized])\n      deserialized = sparse_ops.deserialize_sparse(stacked, dtype=dtypes.int32)\n      deserialized_value = sess.run(\n          deserialized,\n          feed_dict={\n              sparse_tensor.indices: indices_value,\n              sparse_tensor.values: values_value,\n              sparse_tensor.dense_shape: shape_value\n          })\n      self.assertAllEqual(deserialized_value.indices,\n                          np.array([[0], [1]], dtype=np.int64))\n      self.assertAllEqual(deserialized_value.values,\n                          np.array([37, 37], dtype=np.int32))\n      self.assertAllEqual(deserialized_value.dense_shape,\n                          np.array([2], dtype=np.int64))\n\n  def _testDeserializeFailsWrongTypeHelper(self,\n                                           serialize_fn,\n                                           deserialize_fn,\n                                           out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input0 = self._SparseTensorPlaceholder()\n      sp_input1 = self._SparseTensorPlaceholder()\n      input0_val = self._SparseTensorValue_5x6(np.arange(6))\n      input1_val = self._SparseTensorValue_3x4(np.arange(6))\n      serialized0 = serialize_fn(sp_input0, out_type=out_type)\n      serialized1 = serialize_fn(sp_input1, out_type=out_type)\n      serialized_concat = array_ops.stack([serialized0, serialized1])\n\n      sp_deserialized = deserialize_fn(serialized_concat, dtype=dtypes.int64)\n\n      with self.assertRaisesOpError(\n          r\"Requested SparseTensor of type int64 but \"\n          r\"SparseTensor\\[0\\].values.dtype\\(\\) == int32\"):\n        sess.run(sp_deserialized,\n                 {sp_input0: input0_val,\n                  sp_input1: input1_val})\n\n  @test_util.run_deprecated_v1\n  def testDeserializeFailsWrongType(self):\n    self._testDeserializeFailsWrongTypeHelper(sparse_ops.serialize_sparse,\n                                              sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testDeserializeManyFailsWrongType(self):\n    self._testDeserializeFailsWrongTypeHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantDeserializeFailsWrongType(self):\n    self._testDeserializeFailsWrongTypeHelper(sparse_ops.serialize_sparse,\n                                              sparse_ops.deserialize_sparse,\n                                              dtypes.variant)\n\n  def _testDeserializeFailsInconsistentRankHelper(self,\n                                                  serialize_fn,\n                                                  deserialize_fn,\n                                                  out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input0 = self._SparseTensorPlaceholder()\n      sp_input1 = self._SparseTensorPlaceholder()\n      input0_val = self._SparseTensorValue_5x6(np.arange(6))\n      input1_val = self._SparseTensorValue_1x1x1()\n      serialized0 = serialize_fn(sp_input0, out_type=out_type)\n      serialized1 = serialize_fn(sp_input1, out_type=out_type)\n      serialized_concat = array_ops.stack([serialized0, serialized1])\n\n      sp_deserialized = deserialize_fn(serialized_concat, dtype=dtypes.int32)\n\n      with self.assertRaisesOpError(\n          r\"Inconsistent shape across SparseTensors: rank prior to \"\n          r\"SparseTensor\\[1\\] was: 2 but rank of SparseTensor\\[1\\] is: 3\"):\n        sess.run(sp_deserialized,\n                 {sp_input0: input0_val,\n                  sp_input1: input1_val})\n\n  @test_util.run_deprecated_v1\n  def testDeserializeFailsInconsistentRank(self):\n    self._testDeserializeFailsInconsistentRankHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testDeserializeManyFailsInconsistentRank(self):\n    self._testDeserializeFailsInconsistentRankHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n\n  @test_util.run_deprecated_v1\n  def testVariantDeserializeFailsInconsistentRank(self):\n    self._testDeserializeFailsInconsistentRankHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_sparse,\n        dtypes.variant)\n\n  def _testDeserializeFailsInvalidProtoHelper(self,\n                                              serialize_fn,\n                                              deserialize_fn,\n                                              out_type=dtypes.string):\n    with self.cached_session(use_gpu=False) as sess:\n      sp_input0 = self._SparseTensorPlaceholder()\n      input0_val = self._SparseTensorValue_5x6(np.arange(6))\n      serialized0 = serialize_fn(sp_input0, out_type=out_type)\n      serialized1 = [\"a\", \"b\", \"c\"]\n      serialized_concat = array_ops.stack([serialized0, serialized1])\n\n      sp_deserialized = deserialize_fn(serialized_concat, dtype=dtypes.int32)\n\n      with self.assertRaisesOpError(r\"Could not parse serialized proto\"):\n        sess.run(sp_deserialized, {sp_input0: input0_val})\n\n  @test_util.run_deprecated_v1\n  def testDeserializeFailsInvalidProto(self):\n    self._testDeserializeFailsInvalidProtoHelper(sparse_ops.serialize_sparse,\n                                                 sparse_ops.deserialize_sparse)\n\n  @test_util.run_deprecated_v1\n  def testDeserializeManyFailsInvalidProto(self):\n    self._testDeserializeFailsInvalidProtoHelper(\n        sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n\n  def testDeserializeInvalidVariant(self):\n    mu = gen_resource_variable_ops.mutex_v2()\n    mu_lock = gen_resource_variable_ops.mutex_lock(mutex=mu)\n\n    @def_function.function\n    def f():\n      return sparse_ops.deserialize_sparse(\n          serialized_sparse=mu_lock, dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(ValueError, r\"Shape must be at least rank 1\"):\n      f()\n\n\nif __name__ == \"__main__\":\n  test.main()\n"], "filenames": ["tensorflow/core/ops/sparse_ops.cc", "tensorflow/python/kernel_tests/sparse_serialization_ops_test.py"], "buggy_code_start_loc": [18, 18], "buggy_code_end_loc": [161, 462], "fixing_code_start_loc": [19, 19], "fixing_code_end_loc": [165, 477], "type": "CWE-476", "message": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference code for `DeserializeSparse` can trigger a null pointer dereference. This is because the shape inference function assumes that the `serialize_sparse` tensor is a tensor with positive rank (and having `3` as the last dimension). The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-41215", "sourceIdentifier": "security-advisories@github.com", "published": "2021-11-05T21:15:09.003", "lastModified": "2021-11-09T16:24:53.437", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference code for `DeserializeSparse` can trigger a null pointer dereference. This is because the shape inference function assumes that the `serialize_sparse` tensor is a tensor with positive rank (and having `3` as the last dimension). The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. En las versiones afectadas, el c\u00f3digo de inferencia de forma para \"DeserializeSparse\" puede desencadenar una desreferencia de puntero null. Esto es debido a que la funci\u00f3n de inferencia de forma asume que el tensor \"serialize_sparse\" es un tensor con rango positivo (y que presenta \"3\" como \u00faltima dimensi\u00f3n). La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.7.0. Tambi\u00e9n ser\u00e1 incluida este commit en TensorFlow versi\u00f3n 2.6.1, TensorFlow versi\u00f3n 2.5.2 y TensorFlow versi\u00f3n 2.4.4, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango admitido"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-476"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.4.4", "matchCriteriaId": "455FB550-4C9C-4BD6-9F76-A627B62AB332"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.5.0", "versionEndExcluding": "2.5.2", "matchCriteriaId": "035CDF63-1548-4FB4-B8A9-B8D328FAF910"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:*:*:*:*:*:*:*", "matchCriteriaId": "651EA851-E660-4E53-9F3E-B6B69D91326B"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/d3738dd70f1c9ceb547258cbb82d853da8771850", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x3v8-c8qx-3j3r", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/d3738dd70f1c9ceb547258cbb82d853da8771850"}}
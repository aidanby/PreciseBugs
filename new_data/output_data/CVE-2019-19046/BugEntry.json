{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0+\n/*\n * ipmi_msghandler.c\n *\n * Incoming and outgoing message routing for an IPMI interface.\n *\n * Author: MontaVista Software, Inc.\n *         Corey Minyard <minyard@mvista.com>\n *         source@mvista.com\n *\n * Copyright 2002 MontaVista Software Inc.\n */\n\n#define pr_fmt(fmt) \"%s\" fmt, \"IPMI message handler: \"\n#define dev_fmt pr_fmt\n\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/poll.h>\n#include <linux/sched.h>\n#include <linux/seq_file.h>\n#include <linux/spinlock.h>\n#include <linux/mutex.h>\n#include <linux/slab.h>\n#include <linux/ipmi.h>\n#include <linux/ipmi_smi.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/proc_fs.h>\n#include <linux/rcupdate.h>\n#include <linux/interrupt.h>\n#include <linux/moduleparam.h>\n#include <linux/workqueue.h>\n#include <linux/uuid.h>\n#include <linux/nospec.h>\n\n#define IPMI_DRIVER_VERSION \"39.2\"\n\nstatic struct ipmi_recv_msg *ipmi_alloc_recv_msg(void);\nstatic int ipmi_init_msghandler(void);\nstatic void smi_recv_tasklet(unsigned long);\nstatic void handle_new_recv_msgs(struct ipmi_smi *intf);\nstatic void need_waiter(struct ipmi_smi *intf);\nstatic int handle_one_recv_msg(struct ipmi_smi *intf,\n\t\t\t       struct ipmi_smi_msg *msg);\n\nstatic bool initialized;\nstatic bool drvregistered;\n\nenum ipmi_panic_event_op {\n\tIPMI_SEND_PANIC_EVENT_NONE,\n\tIPMI_SEND_PANIC_EVENT,\n\tIPMI_SEND_PANIC_EVENT_STRING\n};\n#ifdef CONFIG_IPMI_PANIC_STRING\n#define IPMI_PANIC_DEFAULT IPMI_SEND_PANIC_EVENT_STRING\n#elif defined(CONFIG_IPMI_PANIC_EVENT)\n#define IPMI_PANIC_DEFAULT IPMI_SEND_PANIC_EVENT\n#else\n#define IPMI_PANIC_DEFAULT IPMI_SEND_PANIC_EVENT_NONE\n#endif\nstatic enum ipmi_panic_event_op ipmi_send_panic_event = IPMI_PANIC_DEFAULT;\n\nstatic int panic_op_write_handler(const char *val,\n\t\t\t\t  const struct kernel_param *kp)\n{\n\tchar valcp[16];\n\tchar *s;\n\n\tstrncpy(valcp, val, 15);\n\tvalcp[15] = '\\0';\n\n\ts = strstrip(valcp);\n\n\tif (strcmp(s, \"none\") == 0)\n\t\tipmi_send_panic_event = IPMI_SEND_PANIC_EVENT_NONE;\n\telse if (strcmp(s, \"event\") == 0)\n\t\tipmi_send_panic_event = IPMI_SEND_PANIC_EVENT;\n\telse if (strcmp(s, \"string\") == 0)\n\t\tipmi_send_panic_event = IPMI_SEND_PANIC_EVENT_STRING;\n\telse\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int panic_op_read_handler(char *buffer, const struct kernel_param *kp)\n{\n\tswitch (ipmi_send_panic_event) {\n\tcase IPMI_SEND_PANIC_EVENT_NONE:\n\t\tstrcpy(buffer, \"none\");\n\t\tbreak;\n\n\tcase IPMI_SEND_PANIC_EVENT:\n\t\tstrcpy(buffer, \"event\");\n\t\tbreak;\n\n\tcase IPMI_SEND_PANIC_EVENT_STRING:\n\t\tstrcpy(buffer, \"string\");\n\t\tbreak;\n\n\tdefault:\n\t\tstrcpy(buffer, \"???\");\n\t\tbreak;\n\t}\n\n\treturn strlen(buffer);\n}\n\nstatic const struct kernel_param_ops panic_op_ops = {\n\t.set = panic_op_write_handler,\n\t.get = panic_op_read_handler\n};\nmodule_param_cb(panic_op, &panic_op_ops, NULL, 0600);\nMODULE_PARM_DESC(panic_op, \"Sets if the IPMI driver will attempt to store panic information in the event log in the event of a panic.  Set to 'none' for no, 'event' for a single event, or 'string' for a generic event and the panic string in IPMI OEM events.\");\n\n\n#define MAX_EVENTS_IN_QUEUE\t25\n\n/* Remain in auto-maintenance mode for this amount of time (in ms). */\nstatic unsigned long maintenance_mode_timeout_ms = 30000;\nmodule_param(maintenance_mode_timeout_ms, ulong, 0644);\nMODULE_PARM_DESC(maintenance_mode_timeout_ms,\n\t\t \"The time (milliseconds) after the last maintenance message that the connection stays in maintenance mode.\");\n\n/*\n * Don't let a message sit in a queue forever, always time it with at lest\n * the max message timer.  This is in milliseconds.\n */\n#define MAX_MSG_TIMEOUT\t\t60000\n\n/*\n * Timeout times below are in milliseconds, and are done off a 1\n * second timer.  So setting the value to 1000 would mean anything\n * between 0 and 1000ms.  So really the only reasonable minimum\n * setting it 2000ms, which is between 1 and 2 seconds.\n */\n\n/* The default timeout for message retries. */\nstatic unsigned long default_retry_ms = 2000;\nmodule_param(default_retry_ms, ulong, 0644);\nMODULE_PARM_DESC(default_retry_ms,\n\t\t \"The time (milliseconds) between retry sends\");\n\n/* The default timeout for maintenance mode message retries. */\nstatic unsigned long default_maintenance_retry_ms = 3000;\nmodule_param(default_maintenance_retry_ms, ulong, 0644);\nMODULE_PARM_DESC(default_maintenance_retry_ms,\n\t\t \"The time (milliseconds) between retry sends in maintenance mode\");\n\n/* The default maximum number of retries */\nstatic unsigned int default_max_retries = 4;\nmodule_param(default_max_retries, uint, 0644);\nMODULE_PARM_DESC(default_max_retries,\n\t\t \"The time (milliseconds) between retry sends in maintenance mode\");\n\n/* Call every ~1000 ms. */\n#define IPMI_TIMEOUT_TIME\t1000\n\n/* How many jiffies does it take to get to the timeout time. */\n#define IPMI_TIMEOUT_JIFFIES\t((IPMI_TIMEOUT_TIME * HZ) / 1000)\n\n/*\n * Request events from the queue every second (this is the number of\n * IPMI_TIMEOUT_TIMES between event requests).  Hopefully, in the\n * future, IPMI will add a way to know immediately if an event is in\n * the queue and this silliness can go away.\n */\n#define IPMI_REQUEST_EV_TIME\t(1000 / (IPMI_TIMEOUT_TIME))\n\n/* How long should we cache dynamic device IDs? */\n#define IPMI_DYN_DEV_ID_EXPIRY\t(10 * HZ)\n\n/*\n * The main \"user\" data structure.\n */\nstruct ipmi_user {\n\tstruct list_head link;\n\n\t/*\n\t * Set to NULL when the user is destroyed, a pointer to myself\n\t * so srcu_dereference can be used on it.\n\t */\n\tstruct ipmi_user *self;\n\tstruct srcu_struct release_barrier;\n\n\tstruct kref refcount;\n\n\t/* The upper layer that handles receive messages. */\n\tconst struct ipmi_user_hndl *handler;\n\tvoid             *handler_data;\n\n\t/* The interface this user is bound to. */\n\tstruct ipmi_smi *intf;\n\n\t/* Does this interface receive IPMI events? */\n\tbool gets_events;\n\n\t/* Free must run in process context for RCU cleanup. */\n\tstruct work_struct remove_work;\n};\n\nstatic struct ipmi_user *acquire_ipmi_user(struct ipmi_user *user, int *index)\n\t__acquires(user->release_barrier)\n{\n\tstruct ipmi_user *ruser;\n\n\t*index = srcu_read_lock(&user->release_barrier);\n\truser = srcu_dereference(user->self, &user->release_barrier);\n\tif (!ruser)\n\t\tsrcu_read_unlock(&user->release_barrier, *index);\n\treturn ruser;\n}\n\nstatic void release_ipmi_user(struct ipmi_user *user, int index)\n{\n\tsrcu_read_unlock(&user->release_barrier, index);\n}\n\nstruct cmd_rcvr {\n\tstruct list_head link;\n\n\tstruct ipmi_user *user;\n\tunsigned char netfn;\n\tunsigned char cmd;\n\tunsigned int  chans;\n\n\t/*\n\t * This is used to form a linked lised during mass deletion.\n\t * Since this is in an RCU list, we cannot use the link above\n\t * or change any data until the RCU period completes.  So we\n\t * use this next variable during mass deletion so we can have\n\t * a list and don't have to wait and restart the search on\n\t * every individual deletion of a command.\n\t */\n\tstruct cmd_rcvr *next;\n};\n\nstruct seq_table {\n\tunsigned int         inuse : 1;\n\tunsigned int         broadcast : 1;\n\n\tunsigned long        timeout;\n\tunsigned long        orig_timeout;\n\tunsigned int         retries_left;\n\n\t/*\n\t * To verify on an incoming send message response that this is\n\t * the message that the response is for, we keep a sequence id\n\t * and increment it every time we send a message.\n\t */\n\tlong                 seqid;\n\n\t/*\n\t * This is held so we can properly respond to the message on a\n\t * timeout, and it is used to hold the temporary data for\n\t * retransmission, too.\n\t */\n\tstruct ipmi_recv_msg *recv_msg;\n};\n\n/*\n * Store the information in a msgid (long) to allow us to find a\n * sequence table entry from the msgid.\n */\n#define STORE_SEQ_IN_MSGID(seq, seqid) \\\n\t((((seq) & 0x3f) << 26) | ((seqid) & 0x3ffffff))\n\n#define GET_SEQ_FROM_MSGID(msgid, seq, seqid) \\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tseq = (((msgid) >> 26) & 0x3f);\t\t\t\t\\\n\t\tseqid = ((msgid) & 0x3ffffff);\t\t\t\t\\\n\t} while (0)\n\n#define NEXT_SEQID(seqid) (((seqid) + 1) & 0x3ffffff)\n\n#define IPMI_MAX_CHANNELS       16\nstruct ipmi_channel {\n\tunsigned char medium;\n\tunsigned char protocol;\n};\n\nstruct ipmi_channel_set {\n\tstruct ipmi_channel c[IPMI_MAX_CHANNELS];\n};\n\nstruct ipmi_my_addrinfo {\n\t/*\n\t * My slave address.  This is initialized to IPMI_BMC_SLAVE_ADDR,\n\t * but may be changed by the user.\n\t */\n\tunsigned char address;\n\n\t/*\n\t * My LUN.  This should generally stay the SMS LUN, but just in\n\t * case...\n\t */\n\tunsigned char lun;\n};\n\n/*\n * Note that the product id, manufacturer id, guid, and device id are\n * immutable in this structure, so dyn_mutex is not required for\n * accessing those.  If those change on a BMC, a new BMC is allocated.\n */\nstruct bmc_device {\n\tstruct platform_device pdev;\n\tstruct list_head       intfs; /* Interfaces on this BMC. */\n\tstruct ipmi_device_id  id;\n\tstruct ipmi_device_id  fetch_id;\n\tint                    dyn_id_set;\n\tunsigned long          dyn_id_expiry;\n\tstruct mutex           dyn_mutex; /* Protects id, intfs, & dyn* */\n\tguid_t                 guid;\n\tguid_t                 fetch_guid;\n\tint                    dyn_guid_set;\n\tstruct kref\t       usecount;\n\tstruct work_struct     remove_work;\n};\n#define to_bmc_device(x) container_of((x), struct bmc_device, pdev.dev)\n\nstatic int bmc_get_device_id(struct ipmi_smi *intf, struct bmc_device *bmc,\n\t\t\t     struct ipmi_device_id *id,\n\t\t\t     bool *guid_set, guid_t *guid);\n\n/*\n * Various statistics for IPMI, these index stats[] in the ipmi_smi\n * structure.\n */\nenum ipmi_stat_indexes {\n\t/* Commands we got from the user that were invalid. */\n\tIPMI_STAT_sent_invalid_commands = 0,\n\n\t/* Commands we sent to the MC. */\n\tIPMI_STAT_sent_local_commands,\n\n\t/* Responses from the MC that were delivered to a user. */\n\tIPMI_STAT_handled_local_responses,\n\n\t/* Responses from the MC that were not delivered to a user. */\n\tIPMI_STAT_unhandled_local_responses,\n\n\t/* Commands we sent out to the IPMB bus. */\n\tIPMI_STAT_sent_ipmb_commands,\n\n\t/* Commands sent on the IPMB that had errors on the SEND CMD */\n\tIPMI_STAT_sent_ipmb_command_errs,\n\n\t/* Each retransmit increments this count. */\n\tIPMI_STAT_retransmitted_ipmb_commands,\n\n\t/*\n\t * When a message times out (runs out of retransmits) this is\n\t * incremented.\n\t */\n\tIPMI_STAT_timed_out_ipmb_commands,\n\n\t/*\n\t * This is like above, but for broadcasts.  Broadcasts are\n\t * *not* included in the above count (they are expected to\n\t * time out).\n\t */\n\tIPMI_STAT_timed_out_ipmb_broadcasts,\n\n\t/* Responses I have sent to the IPMB bus. */\n\tIPMI_STAT_sent_ipmb_responses,\n\n\t/* The response was delivered to the user. */\n\tIPMI_STAT_handled_ipmb_responses,\n\n\t/* The response had invalid data in it. */\n\tIPMI_STAT_invalid_ipmb_responses,\n\n\t/* The response didn't have anyone waiting for it. */\n\tIPMI_STAT_unhandled_ipmb_responses,\n\n\t/* Commands we sent out to the IPMB bus. */\n\tIPMI_STAT_sent_lan_commands,\n\n\t/* Commands sent on the IPMB that had errors on the SEND CMD */\n\tIPMI_STAT_sent_lan_command_errs,\n\n\t/* Each retransmit increments this count. */\n\tIPMI_STAT_retransmitted_lan_commands,\n\n\t/*\n\t * When a message times out (runs out of retransmits) this is\n\t * incremented.\n\t */\n\tIPMI_STAT_timed_out_lan_commands,\n\n\t/* Responses I have sent to the IPMB bus. */\n\tIPMI_STAT_sent_lan_responses,\n\n\t/* The response was delivered to the user. */\n\tIPMI_STAT_handled_lan_responses,\n\n\t/* The response had invalid data in it. */\n\tIPMI_STAT_invalid_lan_responses,\n\n\t/* The response didn't have anyone waiting for it. */\n\tIPMI_STAT_unhandled_lan_responses,\n\n\t/* The command was delivered to the user. */\n\tIPMI_STAT_handled_commands,\n\n\t/* The command had invalid data in it. */\n\tIPMI_STAT_invalid_commands,\n\n\t/* The command didn't have anyone waiting for it. */\n\tIPMI_STAT_unhandled_commands,\n\n\t/* Invalid data in an event. */\n\tIPMI_STAT_invalid_events,\n\n\t/* Events that were received with the proper format. */\n\tIPMI_STAT_events,\n\n\t/* Retransmissions on IPMB that failed. */\n\tIPMI_STAT_dropped_rexmit_ipmb_commands,\n\n\t/* Retransmissions on LAN that failed. */\n\tIPMI_STAT_dropped_rexmit_lan_commands,\n\n\t/* This *must* remain last, add new values above this. */\n\tIPMI_NUM_STATS\n};\n\n\n#define IPMI_IPMB_NUM_SEQ\t64\nstruct ipmi_smi {\n\tstruct module *owner;\n\n\t/* What interface number are we? */\n\tint intf_num;\n\n\tstruct kref refcount;\n\n\t/* Set when the interface is being unregistered. */\n\tbool in_shutdown;\n\n\t/* Used for a list of interfaces. */\n\tstruct list_head link;\n\n\t/*\n\t * The list of upper layers that are using me.  seq_lock write\n\t * protects this.  Read protection is with srcu.\n\t */\n\tstruct list_head users;\n\tstruct srcu_struct users_srcu;\n\n\t/* Used for wake ups at startup. */\n\twait_queue_head_t waitq;\n\n\t/*\n\t * Prevents the interface from being unregistered when the\n\t * interface is used by being looked up through the BMC\n\t * structure.\n\t */\n\tstruct mutex bmc_reg_mutex;\n\n\tstruct bmc_device tmp_bmc;\n\tstruct bmc_device *bmc;\n\tbool bmc_registered;\n\tstruct list_head bmc_link;\n\tchar *my_dev_name;\n\tbool in_bmc_register;  /* Handle recursive situations.  Yuck. */\n\tstruct work_struct bmc_reg_work;\n\n\tconst struct ipmi_smi_handlers *handlers;\n\tvoid                     *send_info;\n\n\t/* Driver-model device for the system interface. */\n\tstruct device          *si_dev;\n\n\t/*\n\t * A table of sequence numbers for this interface.  We use the\n\t * sequence numbers for IPMB messages that go out of the\n\t * interface to match them up with their responses.  A routine\n\t * is called periodically to time the items in this list.\n\t */\n\tspinlock_t       seq_lock;\n\tstruct seq_table seq_table[IPMI_IPMB_NUM_SEQ];\n\tint curr_seq;\n\n\t/*\n\t * Messages queued for delivery.  If delivery fails (out of memory\n\t * for instance), They will stay in here to be processed later in a\n\t * periodic timer interrupt.  The tasklet is for handling received\n\t * messages directly from the handler.\n\t */\n\tspinlock_t       waiting_rcv_msgs_lock;\n\tstruct list_head waiting_rcv_msgs;\n\tatomic_t\t watchdog_pretimeouts_to_deliver;\n\tstruct tasklet_struct recv_tasklet;\n\n\tspinlock_t             xmit_msgs_lock;\n\tstruct list_head       xmit_msgs;\n\tstruct ipmi_smi_msg    *curr_msg;\n\tstruct list_head       hp_xmit_msgs;\n\n\t/*\n\t * The list of command receivers that are registered for commands\n\t * on this interface.\n\t */\n\tstruct mutex     cmd_rcvrs_mutex;\n\tstruct list_head cmd_rcvrs;\n\n\t/*\n\t * Events that were queues because no one was there to receive\n\t * them.\n\t */\n\tspinlock_t       events_lock; /* For dealing with event stuff. */\n\tstruct list_head waiting_events;\n\tunsigned int     waiting_events_count; /* How many events in queue? */\n\tchar             delivering_events;\n\tchar             event_msg_printed;\n\n\t/* How many users are waiting for events? */\n\tatomic_t         event_waiters;\n\tunsigned int     ticks_to_req_ev;\n\n\tspinlock_t       watch_lock; /* For dealing with watch stuff below. */\n\n\t/* How many users are waiting for commands? */\n\tunsigned int     command_waiters;\n\n\t/* How many users are waiting for watchdogs? */\n\tunsigned int     watchdog_waiters;\n\n\t/* How many users are waiting for message responses? */\n\tunsigned int     response_waiters;\n\n\t/*\n\t * Tells what the lower layer has last been asked to watch for,\n\t * messages and/or watchdogs.  Protected by watch_lock.\n\t */\n\tunsigned int     last_watch_mask;\n\n\t/*\n\t * The event receiver for my BMC, only really used at panic\n\t * shutdown as a place to store this.\n\t */\n\tunsigned char event_receiver;\n\tunsigned char event_receiver_lun;\n\tunsigned char local_sel_device;\n\tunsigned char local_event_generator;\n\n\t/* For handling of maintenance mode. */\n\tint maintenance_mode;\n\tbool maintenance_mode_enable;\n\tint auto_maintenance_timeout;\n\tspinlock_t maintenance_mode_lock; /* Used in a timer... */\n\n\t/*\n\t * If we are doing maintenance on something on IPMB, extend\n\t * the timeout time to avoid timeouts writing firmware and\n\t * such.\n\t */\n\tint ipmb_maintenance_mode_timeout;\n\n\t/*\n\t * A cheap hack, if this is non-null and a message to an\n\t * interface comes in with a NULL user, call this routine with\n\t * it.  Note that the message will still be freed by the\n\t * caller.  This only works on the system interface.\n\t *\n\t * Protected by bmc_reg_mutex.\n\t */\n\tvoid (*null_user_handler)(struct ipmi_smi *intf,\n\t\t\t\t  struct ipmi_recv_msg *msg);\n\n\t/*\n\t * When we are scanning the channels for an SMI, this will\n\t * tell which channel we are scanning.\n\t */\n\tint curr_channel;\n\n\t/* Channel information */\n\tstruct ipmi_channel_set *channel_list;\n\tunsigned int curr_working_cset; /* First index into the following. */\n\tstruct ipmi_channel_set wchannels[2];\n\tstruct ipmi_my_addrinfo addrinfo[IPMI_MAX_CHANNELS];\n\tbool channels_ready;\n\n\tatomic_t stats[IPMI_NUM_STATS];\n\n\t/*\n\t * run_to_completion duplicate of smb_info, smi_info\n\t * and ipmi_serial_info structures. Used to decrease numbers of\n\t * parameters passed by \"low\" level IPMI code.\n\t */\n\tint run_to_completion;\n};\n#define to_si_intf_from_dev(device) container_of(device, struct ipmi_smi, dev)\n\nstatic void __get_guid(struct ipmi_smi *intf);\nstatic void __ipmi_bmc_unregister(struct ipmi_smi *intf);\nstatic int __ipmi_bmc_register(struct ipmi_smi *intf,\n\t\t\t       struct ipmi_device_id *id,\n\t\t\t       bool guid_set, guid_t *guid, int intf_num);\nstatic int __scan_channels(struct ipmi_smi *intf, struct ipmi_device_id *id);\n\n\n/**\n * The driver model view of the IPMI messaging driver.\n */\nstatic struct platform_driver ipmidriver = {\n\t.driver = {\n\t\t.name = \"ipmi\",\n\t\t.bus = &platform_bus_type\n\t}\n};\n/*\n * This mutex keeps us from adding the same BMC twice.\n */\nstatic DEFINE_MUTEX(ipmidriver_mutex);\n\nstatic LIST_HEAD(ipmi_interfaces);\nstatic DEFINE_MUTEX(ipmi_interfaces_mutex);\nstatic struct srcu_struct ipmi_interfaces_srcu;\n\n/*\n * List of watchers that want to know when smi's are added and deleted.\n */\nstatic LIST_HEAD(smi_watchers);\nstatic DEFINE_MUTEX(smi_watchers_mutex);\n\n#define ipmi_inc_stat(intf, stat) \\\n\tatomic_inc(&(intf)->stats[IPMI_STAT_ ## stat])\n#define ipmi_get_stat(intf, stat) \\\n\t((unsigned int) atomic_read(&(intf)->stats[IPMI_STAT_ ## stat]))\n\nstatic const char * const addr_src_to_str[] = {\n\t\"invalid\", \"hotmod\", \"hardcoded\", \"SPMI\", \"ACPI\", \"SMBIOS\", \"PCI\",\n\t\"device-tree\", \"platform\"\n};\n\nconst char *ipmi_addr_src_to_str(enum ipmi_addr_src src)\n{\n\tif (src >= SI_LAST)\n\t\tsrc = 0; /* Invalid */\n\treturn addr_src_to_str[src];\n}\nEXPORT_SYMBOL(ipmi_addr_src_to_str);\n\nstatic int is_lan_addr(struct ipmi_addr *addr)\n{\n\treturn addr->addr_type == IPMI_LAN_ADDR_TYPE;\n}\n\nstatic int is_ipmb_addr(struct ipmi_addr *addr)\n{\n\treturn addr->addr_type == IPMI_IPMB_ADDR_TYPE;\n}\n\nstatic int is_ipmb_bcast_addr(struct ipmi_addr *addr)\n{\n\treturn addr->addr_type == IPMI_IPMB_BROADCAST_ADDR_TYPE;\n}\n\nstatic void free_recv_msg_list(struct list_head *q)\n{\n\tstruct ipmi_recv_msg *msg, *msg2;\n\n\tlist_for_each_entry_safe(msg, msg2, q, link) {\n\t\tlist_del(&msg->link);\n\t\tipmi_free_recv_msg(msg);\n\t}\n}\n\nstatic void free_smi_msg_list(struct list_head *q)\n{\n\tstruct ipmi_smi_msg *msg, *msg2;\n\n\tlist_for_each_entry_safe(msg, msg2, q, link) {\n\t\tlist_del(&msg->link);\n\t\tipmi_free_smi_msg(msg);\n\t}\n}\n\nstatic void clean_up_interface_data(struct ipmi_smi *intf)\n{\n\tint              i;\n\tstruct cmd_rcvr  *rcvr, *rcvr2;\n\tstruct list_head list;\n\n\ttasklet_kill(&intf->recv_tasklet);\n\n\tfree_smi_msg_list(&intf->waiting_rcv_msgs);\n\tfree_recv_msg_list(&intf->waiting_events);\n\n\t/*\n\t * Wholesale remove all the entries from the list in the\n\t * interface and wait for RCU to know that none are in use.\n\t */\n\tmutex_lock(&intf->cmd_rcvrs_mutex);\n\tINIT_LIST_HEAD(&list);\n\tlist_splice_init_rcu(&intf->cmd_rcvrs, &list, synchronize_rcu);\n\tmutex_unlock(&intf->cmd_rcvrs_mutex);\n\n\tlist_for_each_entry_safe(rcvr, rcvr2, &list, link)\n\t\tkfree(rcvr);\n\n\tfor (i = 0; i < IPMI_IPMB_NUM_SEQ; i++) {\n\t\tif ((intf->seq_table[i].inuse)\n\t\t\t\t\t&& (intf->seq_table[i].recv_msg))\n\t\t\tipmi_free_recv_msg(intf->seq_table[i].recv_msg);\n\t}\n}\n\nstatic void intf_free(struct kref *ref)\n{\n\tstruct ipmi_smi *intf = container_of(ref, struct ipmi_smi, refcount);\n\n\tclean_up_interface_data(intf);\n\tkfree(intf);\n}\n\nstruct watcher_entry {\n\tint              intf_num;\n\tstruct ipmi_smi  *intf;\n\tstruct list_head link;\n};\n\nint ipmi_smi_watcher_register(struct ipmi_smi_watcher *watcher)\n{\n\tstruct ipmi_smi *intf;\n\tint index, rv;\n\n\t/*\n\t * Make sure the driver is actually initialized, this handles\n\t * problems with initialization order.\n\t */\n\trv = ipmi_init_msghandler();\n\tif (rv)\n\t\treturn rv;\n\n\tmutex_lock(&smi_watchers_mutex);\n\n\tlist_add(&watcher->link, &smi_watchers);\n\n\tindex = srcu_read_lock(&ipmi_interfaces_srcu);\n\tlist_for_each_entry_rcu(intf, &ipmi_interfaces, link) {\n\t\tint intf_num = READ_ONCE(intf->intf_num);\n\n\t\tif (intf_num == -1)\n\t\t\tcontinue;\n\t\twatcher->new_smi(intf_num, intf->si_dev);\n\t}\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\n\tmutex_unlock(&smi_watchers_mutex);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(ipmi_smi_watcher_register);\n\nint ipmi_smi_watcher_unregister(struct ipmi_smi_watcher *watcher)\n{\n\tmutex_lock(&smi_watchers_mutex);\n\tlist_del(&watcher->link);\n\tmutex_unlock(&smi_watchers_mutex);\n\treturn 0;\n}\nEXPORT_SYMBOL(ipmi_smi_watcher_unregister);\n\n/*\n * Must be called with smi_watchers_mutex held.\n */\nstatic void\ncall_smi_watchers(int i, struct device *dev)\n{\n\tstruct ipmi_smi_watcher *w;\n\n\tmutex_lock(&smi_watchers_mutex);\n\tlist_for_each_entry(w, &smi_watchers, link) {\n\t\tif (try_module_get(w->owner)) {\n\t\t\tw->new_smi(i, dev);\n\t\t\tmodule_put(w->owner);\n\t\t}\n\t}\n\tmutex_unlock(&smi_watchers_mutex);\n}\n\nstatic int\nipmi_addr_equal(struct ipmi_addr *addr1, struct ipmi_addr *addr2)\n{\n\tif (addr1->addr_type != addr2->addr_type)\n\t\treturn 0;\n\n\tif (addr1->channel != addr2->channel)\n\t\treturn 0;\n\n\tif (addr1->addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE) {\n\t\tstruct ipmi_system_interface_addr *smi_addr1\n\t\t    = (struct ipmi_system_interface_addr *) addr1;\n\t\tstruct ipmi_system_interface_addr *smi_addr2\n\t\t    = (struct ipmi_system_interface_addr *) addr2;\n\t\treturn (smi_addr1->lun == smi_addr2->lun);\n\t}\n\n\tif (is_ipmb_addr(addr1) || is_ipmb_bcast_addr(addr1)) {\n\t\tstruct ipmi_ipmb_addr *ipmb_addr1\n\t\t    = (struct ipmi_ipmb_addr *) addr1;\n\t\tstruct ipmi_ipmb_addr *ipmb_addr2\n\t\t    = (struct ipmi_ipmb_addr *) addr2;\n\n\t\treturn ((ipmb_addr1->slave_addr == ipmb_addr2->slave_addr)\n\t\t\t&& (ipmb_addr1->lun == ipmb_addr2->lun));\n\t}\n\n\tif (is_lan_addr(addr1)) {\n\t\tstruct ipmi_lan_addr *lan_addr1\n\t\t\t= (struct ipmi_lan_addr *) addr1;\n\t\tstruct ipmi_lan_addr *lan_addr2\n\t\t    = (struct ipmi_lan_addr *) addr2;\n\n\t\treturn ((lan_addr1->remote_SWID == lan_addr2->remote_SWID)\n\t\t\t&& (lan_addr1->local_SWID == lan_addr2->local_SWID)\n\t\t\t&& (lan_addr1->session_handle\n\t\t\t    == lan_addr2->session_handle)\n\t\t\t&& (lan_addr1->lun == lan_addr2->lun));\n\t}\n\n\treturn 1;\n}\n\nint ipmi_validate_addr(struct ipmi_addr *addr, int len)\n{\n\tif (len < sizeof(struct ipmi_system_interface_addr))\n\t\treturn -EINVAL;\n\n\tif (addr->addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE) {\n\t\tif (addr->channel != IPMI_BMC_CHANNEL)\n\t\t\treturn -EINVAL;\n\t\treturn 0;\n\t}\n\n\tif ((addr->channel == IPMI_BMC_CHANNEL)\n\t    || (addr->channel >= IPMI_MAX_CHANNELS)\n\t    || (addr->channel < 0))\n\t\treturn -EINVAL;\n\n\tif (is_ipmb_addr(addr) || is_ipmb_bcast_addr(addr)) {\n\t\tif (len < sizeof(struct ipmi_ipmb_addr))\n\t\t\treturn -EINVAL;\n\t\treturn 0;\n\t}\n\n\tif (is_lan_addr(addr)) {\n\t\tif (len < sizeof(struct ipmi_lan_addr))\n\t\t\treturn -EINVAL;\n\t\treturn 0;\n\t}\n\n\treturn -EINVAL;\n}\nEXPORT_SYMBOL(ipmi_validate_addr);\n\nunsigned int ipmi_addr_length(int addr_type)\n{\n\tif (addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t\treturn sizeof(struct ipmi_system_interface_addr);\n\n\tif ((addr_type == IPMI_IPMB_ADDR_TYPE)\n\t\t\t|| (addr_type == IPMI_IPMB_BROADCAST_ADDR_TYPE))\n\t\treturn sizeof(struct ipmi_ipmb_addr);\n\n\tif (addr_type == IPMI_LAN_ADDR_TYPE)\n\t\treturn sizeof(struct ipmi_lan_addr);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(ipmi_addr_length);\n\nstatic int deliver_response(struct ipmi_smi *intf, struct ipmi_recv_msg *msg)\n{\n\tint rv = 0;\n\n\tif (!msg->user) {\n\t\t/* Special handling for NULL users. */\n\t\tif (intf->null_user_handler) {\n\t\t\tintf->null_user_handler(intf, msg);\n\t\t} else {\n\t\t\t/* No handler, so give up. */\n\t\t\trv = -EINVAL;\n\t\t}\n\t\tipmi_free_recv_msg(msg);\n\t} else if (oops_in_progress) {\n\t\t/*\n\t\t * If we are running in the panic context, calling the\n\t\t * receive handler doesn't much meaning and has a deadlock\n\t\t * risk.  At this moment, simply skip it in that case.\n\t\t */\n\t\tipmi_free_recv_msg(msg);\n\t} else {\n\t\tint index;\n\t\tstruct ipmi_user *user = acquire_ipmi_user(msg->user, &index);\n\n\t\tif (user) {\n\t\t\tuser->handler->ipmi_recv_hndl(msg, user->handler_data);\n\t\t\trelease_ipmi_user(user, index);\n\t\t} else {\n\t\t\t/* User went away, give up. */\n\t\t\tipmi_free_recv_msg(msg);\n\t\t\trv = -EINVAL;\n\t\t}\n\t}\n\n\treturn rv;\n}\n\nstatic void deliver_local_response(struct ipmi_smi *intf,\n\t\t\t\t   struct ipmi_recv_msg *msg)\n{\n\tif (deliver_response(intf, msg))\n\t\tipmi_inc_stat(intf, unhandled_local_responses);\n\telse\n\t\tipmi_inc_stat(intf, handled_local_responses);\n}\n\nstatic void deliver_err_response(struct ipmi_smi *intf,\n\t\t\t\t struct ipmi_recv_msg *msg, int err)\n{\n\tmsg->recv_type = IPMI_RESPONSE_RECV_TYPE;\n\tmsg->msg_data[0] = err;\n\tmsg->msg.netfn |= 1; /* Convert to a response. */\n\tmsg->msg.data_len = 1;\n\tmsg->msg.data = msg->msg_data;\n\tdeliver_local_response(intf, msg);\n}\n\nstatic void smi_add_watch(struct ipmi_smi *intf, unsigned int flags)\n{\n\tunsigned long iflags;\n\n\tif (!intf->handlers->set_need_watch)\n\t\treturn;\n\n\tspin_lock_irqsave(&intf->watch_lock, iflags);\n\tif (flags & IPMI_WATCH_MASK_CHECK_MESSAGES)\n\t\tintf->response_waiters++;\n\n\tif (flags & IPMI_WATCH_MASK_CHECK_WATCHDOG)\n\t\tintf->watchdog_waiters++;\n\n\tif (flags & IPMI_WATCH_MASK_CHECK_COMMANDS)\n\t\tintf->command_waiters++;\n\n\tif ((intf->last_watch_mask & flags) != flags) {\n\t\tintf->last_watch_mask |= flags;\n\t\tintf->handlers->set_need_watch(intf->send_info,\n\t\t\t\t\t       intf->last_watch_mask);\n\t}\n\tspin_unlock_irqrestore(&intf->watch_lock, iflags);\n}\n\nstatic void smi_remove_watch(struct ipmi_smi *intf, unsigned int flags)\n{\n\tunsigned long iflags;\n\n\tif (!intf->handlers->set_need_watch)\n\t\treturn;\n\n\tspin_lock_irqsave(&intf->watch_lock, iflags);\n\tif (flags & IPMI_WATCH_MASK_CHECK_MESSAGES)\n\t\tintf->response_waiters--;\n\n\tif (flags & IPMI_WATCH_MASK_CHECK_WATCHDOG)\n\t\tintf->watchdog_waiters--;\n\n\tif (flags & IPMI_WATCH_MASK_CHECK_COMMANDS)\n\t\tintf->command_waiters--;\n\n\tflags = 0;\n\tif (intf->response_waiters)\n\t\tflags |= IPMI_WATCH_MASK_CHECK_MESSAGES;\n\tif (intf->watchdog_waiters)\n\t\tflags |= IPMI_WATCH_MASK_CHECK_WATCHDOG;\n\tif (intf->command_waiters)\n\t\tflags |= IPMI_WATCH_MASK_CHECK_COMMANDS;\n\n\tif (intf->last_watch_mask != flags) {\n\t\tintf->last_watch_mask = flags;\n\t\tintf->handlers->set_need_watch(intf->send_info,\n\t\t\t\t\t       intf->last_watch_mask);\n\t}\n\tspin_unlock_irqrestore(&intf->watch_lock, iflags);\n}\n\n/*\n * Find the next sequence number not being used and add the given\n * message with the given timeout to the sequence table.  This must be\n * called with the interface's seq_lock held.\n */\nstatic int intf_next_seq(struct ipmi_smi      *intf,\n\t\t\t struct ipmi_recv_msg *recv_msg,\n\t\t\t unsigned long        timeout,\n\t\t\t int                  retries,\n\t\t\t int                  broadcast,\n\t\t\t unsigned char        *seq,\n\t\t\t long                 *seqid)\n{\n\tint          rv = 0;\n\tunsigned int i;\n\n\tif (timeout == 0)\n\t\ttimeout = default_retry_ms;\n\tif (retries < 0)\n\t\tretries = default_max_retries;\n\n\tfor (i = intf->curr_seq; (i+1)%IPMI_IPMB_NUM_SEQ != intf->curr_seq;\n\t\t\t\t\ti = (i+1)%IPMI_IPMB_NUM_SEQ) {\n\t\tif (!intf->seq_table[i].inuse)\n\t\t\tbreak;\n\t}\n\n\tif (!intf->seq_table[i].inuse) {\n\t\tintf->seq_table[i].recv_msg = recv_msg;\n\n\t\t/*\n\t\t * Start with the maximum timeout, when the send response\n\t\t * comes in we will start the real timer.\n\t\t */\n\t\tintf->seq_table[i].timeout = MAX_MSG_TIMEOUT;\n\t\tintf->seq_table[i].orig_timeout = timeout;\n\t\tintf->seq_table[i].retries_left = retries;\n\t\tintf->seq_table[i].broadcast = broadcast;\n\t\tintf->seq_table[i].inuse = 1;\n\t\tintf->seq_table[i].seqid = NEXT_SEQID(intf->seq_table[i].seqid);\n\t\t*seq = i;\n\t\t*seqid = intf->seq_table[i].seqid;\n\t\tintf->curr_seq = (i+1)%IPMI_IPMB_NUM_SEQ;\n\t\tsmi_add_watch(intf, IPMI_WATCH_MASK_CHECK_MESSAGES);\n\t\tneed_waiter(intf);\n\t} else {\n\t\trv = -EAGAIN;\n\t}\n\n\treturn rv;\n}\n\n/*\n * Return the receive message for the given sequence number and\n * release the sequence number so it can be reused.  Some other data\n * is passed in to be sure the message matches up correctly (to help\n * guard against message coming in after their timeout and the\n * sequence number being reused).\n */\nstatic int intf_find_seq(struct ipmi_smi      *intf,\n\t\t\t unsigned char        seq,\n\t\t\t short                channel,\n\t\t\t unsigned char        cmd,\n\t\t\t unsigned char        netfn,\n\t\t\t struct ipmi_addr     *addr,\n\t\t\t struct ipmi_recv_msg **recv_msg)\n{\n\tint           rv = -ENODEV;\n\tunsigned long flags;\n\n\tif (seq >= IPMI_IPMB_NUM_SEQ)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\tif (intf->seq_table[seq].inuse) {\n\t\tstruct ipmi_recv_msg *msg = intf->seq_table[seq].recv_msg;\n\n\t\tif ((msg->addr.channel == channel) && (msg->msg.cmd == cmd)\n\t\t\t\t&& (msg->msg.netfn == netfn)\n\t\t\t\t&& (ipmi_addr_equal(addr, &msg->addr))) {\n\t\t\t*recv_msg = msg;\n\t\t\tintf->seq_table[seq].inuse = 0;\n\t\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_MESSAGES);\n\t\t\trv = 0;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\n\treturn rv;\n}\n\n\n/* Start the timer for a specific sequence table entry. */\nstatic int intf_start_seq_timer(struct ipmi_smi *intf,\n\t\t\t\tlong       msgid)\n{\n\tint           rv = -ENODEV;\n\tunsigned long flags;\n\tunsigned char seq;\n\tunsigned long seqid;\n\n\n\tGET_SEQ_FROM_MSGID(msgid, seq, seqid);\n\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\t/*\n\t * We do this verification because the user can be deleted\n\t * while a message is outstanding.\n\t */\n\tif ((intf->seq_table[seq].inuse)\n\t\t\t\t&& (intf->seq_table[seq].seqid == seqid)) {\n\t\tstruct seq_table *ent = &intf->seq_table[seq];\n\t\tent->timeout = ent->orig_timeout;\n\t\trv = 0;\n\t}\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\n\treturn rv;\n}\n\n/* Got an error for the send message for a specific sequence number. */\nstatic int intf_err_seq(struct ipmi_smi *intf,\n\t\t\tlong         msgid,\n\t\t\tunsigned int err)\n{\n\tint                  rv = -ENODEV;\n\tunsigned long        flags;\n\tunsigned char        seq;\n\tunsigned long        seqid;\n\tstruct ipmi_recv_msg *msg = NULL;\n\n\n\tGET_SEQ_FROM_MSGID(msgid, seq, seqid);\n\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\t/*\n\t * We do this verification because the user can be deleted\n\t * while a message is outstanding.\n\t */\n\tif ((intf->seq_table[seq].inuse)\n\t\t\t\t&& (intf->seq_table[seq].seqid == seqid)) {\n\t\tstruct seq_table *ent = &intf->seq_table[seq];\n\n\t\tent->inuse = 0;\n\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_MESSAGES);\n\t\tmsg = ent->recv_msg;\n\t\trv = 0;\n\t}\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\n\tif (msg)\n\t\tdeliver_err_response(intf, msg, err);\n\n\treturn rv;\n}\n\nstatic void free_user_work(struct work_struct *work)\n{\n\tstruct ipmi_user *user = container_of(work, struct ipmi_user,\n\t\t\t\t\t      remove_work);\n\n\tcleanup_srcu_struct(&user->release_barrier);\n\tkfree(user);\n}\n\nint ipmi_create_user(unsigned int          if_num,\n\t\t     const struct ipmi_user_hndl *handler,\n\t\t     void                  *handler_data,\n\t\t     struct ipmi_user      **user)\n{\n\tunsigned long flags;\n\tstruct ipmi_user *new_user;\n\tint           rv, index;\n\tstruct ipmi_smi *intf;\n\n\t/*\n\t * There is no module usecount here, because it's not\n\t * required.  Since this can only be used by and called from\n\t * other modules, they will implicitly use this module, and\n\t * thus this can't be removed unless the other modules are\n\t * removed.\n\t */\n\n\tif (handler == NULL)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Make sure the driver is actually initialized, this handles\n\t * problems with initialization order.\n\t */\n\trv = ipmi_init_msghandler();\n\tif (rv)\n\t\treturn rv;\n\n\tnew_user = kmalloc(sizeof(*new_user), GFP_KERNEL);\n\tif (!new_user)\n\t\treturn -ENOMEM;\n\n\tindex = srcu_read_lock(&ipmi_interfaces_srcu);\n\tlist_for_each_entry_rcu(intf, &ipmi_interfaces, link) {\n\t\tif (intf->intf_num == if_num)\n\t\t\tgoto found;\n\t}\n\t/* Not found, return an error */\n\trv = -EINVAL;\n\tgoto out_kfree;\n\n found:\n\tINIT_WORK(&new_user->remove_work, free_user_work);\n\n\trv = init_srcu_struct(&new_user->release_barrier);\n\tif (rv)\n\t\tgoto out_kfree;\n\n\tif (!try_module_get(intf->owner)) {\n\t\trv = -ENODEV;\n\t\tgoto out_kfree;\n\t}\n\n\t/* Note that each existing user holds a refcount to the interface. */\n\tkref_get(&intf->refcount);\n\n\tkref_init(&new_user->refcount);\n\tnew_user->handler = handler;\n\tnew_user->handler_data = handler_data;\n\tnew_user->intf = intf;\n\tnew_user->gets_events = false;\n\n\trcu_assign_pointer(new_user->self, new_user);\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\tlist_add_rcu(&new_user->link, &intf->users);\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\tif (handler->ipmi_watchdog_pretimeout)\n\t\t/* User wants pretimeouts, so make sure to watch for them. */\n\t\tsmi_add_watch(intf, IPMI_WATCH_MASK_CHECK_WATCHDOG);\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\t*user = new_user;\n\treturn 0;\n\nout_kfree:\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\tkfree(new_user);\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_create_user);\n\nint ipmi_get_smi_info(int if_num, struct ipmi_smi_info *data)\n{\n\tint rv, index;\n\tstruct ipmi_smi *intf;\n\n\tindex = srcu_read_lock(&ipmi_interfaces_srcu);\n\tlist_for_each_entry_rcu(intf, &ipmi_interfaces, link) {\n\t\tif (intf->intf_num == if_num)\n\t\t\tgoto found;\n\t}\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\n\t/* Not found, return an error */\n\treturn -EINVAL;\n\nfound:\n\tif (!intf->handlers->get_smi_info)\n\t\trv = -ENOTTY;\n\telse\n\t\trv = intf->handlers->get_smi_info(intf->send_info, data);\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_get_smi_info);\n\nstatic void free_user(struct kref *ref)\n{\n\tstruct ipmi_user *user = container_of(ref, struct ipmi_user, refcount);\n\n\t/* SRCU cleanup must happen in task context. */\n\tschedule_work(&user->remove_work);\n}\n\nstatic void _ipmi_destroy_user(struct ipmi_user *user)\n{\n\tstruct ipmi_smi  *intf = user->intf;\n\tint              i;\n\tunsigned long    flags;\n\tstruct cmd_rcvr  *rcvr;\n\tstruct cmd_rcvr  *rcvrs = NULL;\n\n\tif (!acquire_ipmi_user(user, &i)) {\n\t\t/*\n\t\t * The user has already been cleaned up, just make sure\n\t\t * nothing is using it and return.\n\t\t */\n\t\tsynchronize_srcu(&user->release_barrier);\n\t\treturn;\n\t}\n\n\trcu_assign_pointer(user->self, NULL);\n\trelease_ipmi_user(user, i);\n\n\tsynchronize_srcu(&user->release_barrier);\n\n\tif (user->handler->shutdown)\n\t\tuser->handler->shutdown(user->handler_data);\n\n\tif (user->handler->ipmi_watchdog_pretimeout)\n\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_WATCHDOG);\n\n\tif (user->gets_events)\n\t\tatomic_dec(&intf->event_waiters);\n\n\t/* Remove the user from the interface's sequence table. */\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\tlist_del_rcu(&user->link);\n\n\tfor (i = 0; i < IPMI_IPMB_NUM_SEQ; i++) {\n\t\tif (intf->seq_table[i].inuse\n\t\t    && (intf->seq_table[i].recv_msg->user == user)) {\n\t\t\tintf->seq_table[i].inuse = 0;\n\t\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_MESSAGES);\n\t\t\tipmi_free_recv_msg(intf->seq_table[i].recv_msg);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\n\t/*\n\t * Remove the user from the command receiver's table.  First\n\t * we build a list of everything (not using the standard link,\n\t * since other things may be using it till we do\n\t * synchronize_srcu()) then free everything in that list.\n\t */\n\tmutex_lock(&intf->cmd_rcvrs_mutex);\n\tlist_for_each_entry_rcu(rcvr, &intf->cmd_rcvrs, link) {\n\t\tif (rcvr->user == user) {\n\t\t\tlist_del_rcu(&rcvr->link);\n\t\t\trcvr->next = rcvrs;\n\t\t\trcvrs = rcvr;\n\t\t}\n\t}\n\tmutex_unlock(&intf->cmd_rcvrs_mutex);\n\tsynchronize_rcu();\n\twhile (rcvrs) {\n\t\trcvr = rcvrs;\n\t\trcvrs = rcvr->next;\n\t\tkfree(rcvr);\n\t}\n\n\tkref_put(&intf->refcount, intf_free);\n\tmodule_put(intf->owner);\n}\n\nint ipmi_destroy_user(struct ipmi_user *user)\n{\n\t_ipmi_destroy_user(user);\n\n\tkref_put(&user->refcount, free_user);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(ipmi_destroy_user);\n\nint ipmi_get_version(struct ipmi_user *user,\n\t\t     unsigned char *major,\n\t\t     unsigned char *minor)\n{\n\tstruct ipmi_device_id id;\n\tint rv, index;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\trv = bmc_get_device_id(user->intf, NULL, &id, NULL, NULL);\n\tif (!rv) {\n\t\t*major = ipmi_version_major(&id);\n\t\t*minor = ipmi_version_minor(&id);\n\t}\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_get_version);\n\nint ipmi_set_my_address(struct ipmi_user *user,\n\t\t\tunsigned int  channel,\n\t\t\tunsigned char address)\n{\n\tint index, rv = 0;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tif (channel >= IPMI_MAX_CHANNELS) {\n\t\trv = -EINVAL;\n\t} else {\n\t\tchannel = array_index_nospec(channel, IPMI_MAX_CHANNELS);\n\t\tuser->intf->addrinfo[channel].address = address;\n\t}\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_set_my_address);\n\nint ipmi_get_my_address(struct ipmi_user *user,\n\t\t\tunsigned int  channel,\n\t\t\tunsigned char *address)\n{\n\tint index, rv = 0;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tif (channel >= IPMI_MAX_CHANNELS) {\n\t\trv = -EINVAL;\n\t} else {\n\t\tchannel = array_index_nospec(channel, IPMI_MAX_CHANNELS);\n\t\t*address = user->intf->addrinfo[channel].address;\n\t}\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_get_my_address);\n\nint ipmi_set_my_LUN(struct ipmi_user *user,\n\t\t    unsigned int  channel,\n\t\t    unsigned char LUN)\n{\n\tint index, rv = 0;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tif (channel >= IPMI_MAX_CHANNELS) {\n\t\trv = -EINVAL;\n\t} else {\n\t\tchannel = array_index_nospec(channel, IPMI_MAX_CHANNELS);\n\t\tuser->intf->addrinfo[channel].lun = LUN & 0x3;\n\t}\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_set_my_LUN);\n\nint ipmi_get_my_LUN(struct ipmi_user *user,\n\t\t    unsigned int  channel,\n\t\t    unsigned char *address)\n{\n\tint index, rv = 0;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tif (channel >= IPMI_MAX_CHANNELS) {\n\t\trv = -EINVAL;\n\t} else {\n\t\tchannel = array_index_nospec(channel, IPMI_MAX_CHANNELS);\n\t\t*address = user->intf->addrinfo[channel].lun;\n\t}\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_get_my_LUN);\n\nint ipmi_get_maintenance_mode(struct ipmi_user *user)\n{\n\tint mode, index;\n\tunsigned long flags;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tspin_lock_irqsave(&user->intf->maintenance_mode_lock, flags);\n\tmode = user->intf->maintenance_mode;\n\tspin_unlock_irqrestore(&user->intf->maintenance_mode_lock, flags);\n\trelease_ipmi_user(user, index);\n\n\treturn mode;\n}\nEXPORT_SYMBOL(ipmi_get_maintenance_mode);\n\nstatic void maintenance_mode_update(struct ipmi_smi *intf)\n{\n\tif (intf->handlers->set_maintenance_mode)\n\t\tintf->handlers->set_maintenance_mode(\n\t\t\tintf->send_info, intf->maintenance_mode_enable);\n}\n\nint ipmi_set_maintenance_mode(struct ipmi_user *user, int mode)\n{\n\tint rv = 0, index;\n\tunsigned long flags;\n\tstruct ipmi_smi *intf = user->intf;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tspin_lock_irqsave(&intf->maintenance_mode_lock, flags);\n\tif (intf->maintenance_mode != mode) {\n\t\tswitch (mode) {\n\t\tcase IPMI_MAINTENANCE_MODE_AUTO:\n\t\t\tintf->maintenance_mode_enable\n\t\t\t\t= (intf->auto_maintenance_timeout > 0);\n\t\t\tbreak;\n\n\t\tcase IPMI_MAINTENANCE_MODE_OFF:\n\t\t\tintf->maintenance_mode_enable = false;\n\t\t\tbreak;\n\n\t\tcase IPMI_MAINTENANCE_MODE_ON:\n\t\t\tintf->maintenance_mode_enable = true;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\trv = -EINVAL;\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tintf->maintenance_mode = mode;\n\n\t\tmaintenance_mode_update(intf);\n\t}\n out_unlock:\n\tspin_unlock_irqrestore(&intf->maintenance_mode_lock, flags);\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_set_maintenance_mode);\n\nint ipmi_set_gets_events(struct ipmi_user *user, bool val)\n{\n\tunsigned long        flags;\n\tstruct ipmi_smi      *intf = user->intf;\n\tstruct ipmi_recv_msg *msg, *msg2;\n\tstruct list_head     msgs;\n\tint index;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tINIT_LIST_HEAD(&msgs);\n\n\tspin_lock_irqsave(&intf->events_lock, flags);\n\tif (user->gets_events == val)\n\t\tgoto out;\n\n\tuser->gets_events = val;\n\n\tif (val) {\n\t\tif (atomic_inc_return(&intf->event_waiters) == 1)\n\t\t\tneed_waiter(intf);\n\t} else {\n\t\tatomic_dec(&intf->event_waiters);\n\t}\n\n\tif (intf->delivering_events)\n\t\t/*\n\t\t * Another thread is delivering events for this, so\n\t\t * let it handle any new events.\n\t\t */\n\t\tgoto out;\n\n\t/* Deliver any queued events. */\n\twhile (user->gets_events && !list_empty(&intf->waiting_events)) {\n\t\tlist_for_each_entry_safe(msg, msg2, &intf->waiting_events, link)\n\t\t\tlist_move_tail(&msg->link, &msgs);\n\t\tintf->waiting_events_count = 0;\n\t\tif (intf->event_msg_printed) {\n\t\t\tdev_warn(intf->si_dev, \"Event queue no longer full\\n\");\n\t\t\tintf->event_msg_printed = 0;\n\t\t}\n\n\t\tintf->delivering_events = 1;\n\t\tspin_unlock_irqrestore(&intf->events_lock, flags);\n\n\t\tlist_for_each_entry_safe(msg, msg2, &msgs, link) {\n\t\t\tmsg->user = user;\n\t\t\tkref_get(&user->refcount);\n\t\t\tdeliver_local_response(intf, msg);\n\t\t}\n\n\t\tspin_lock_irqsave(&intf->events_lock, flags);\n\t\tintf->delivering_events = 0;\n\t}\n\n out:\n\tspin_unlock_irqrestore(&intf->events_lock, flags);\n\trelease_ipmi_user(user, index);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(ipmi_set_gets_events);\n\nstatic struct cmd_rcvr *find_cmd_rcvr(struct ipmi_smi *intf,\n\t\t\t\t      unsigned char netfn,\n\t\t\t\t      unsigned char cmd,\n\t\t\t\t      unsigned char chan)\n{\n\tstruct cmd_rcvr *rcvr;\n\n\tlist_for_each_entry_rcu(rcvr, &intf->cmd_rcvrs, link) {\n\t\tif ((rcvr->netfn == netfn) && (rcvr->cmd == cmd)\n\t\t\t\t\t&& (rcvr->chans & (1 << chan)))\n\t\t\treturn rcvr;\n\t}\n\treturn NULL;\n}\n\nstatic int is_cmd_rcvr_exclusive(struct ipmi_smi *intf,\n\t\t\t\t unsigned char netfn,\n\t\t\t\t unsigned char cmd,\n\t\t\t\t unsigned int  chans)\n{\n\tstruct cmd_rcvr *rcvr;\n\n\tlist_for_each_entry_rcu(rcvr, &intf->cmd_rcvrs, link) {\n\t\tif ((rcvr->netfn == netfn) && (rcvr->cmd == cmd)\n\t\t\t\t\t&& (rcvr->chans & chans))\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nint ipmi_register_for_cmd(struct ipmi_user *user,\n\t\t\t  unsigned char netfn,\n\t\t\t  unsigned char cmd,\n\t\t\t  unsigned int  chans)\n{\n\tstruct ipmi_smi *intf = user->intf;\n\tstruct cmd_rcvr *rcvr;\n\tint rv = 0, index;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\trcvr = kmalloc(sizeof(*rcvr), GFP_KERNEL);\n\tif (!rcvr) {\n\t\trv = -ENOMEM;\n\t\tgoto out_release;\n\t}\n\trcvr->cmd = cmd;\n\trcvr->netfn = netfn;\n\trcvr->chans = chans;\n\trcvr->user = user;\n\n\tmutex_lock(&intf->cmd_rcvrs_mutex);\n\t/* Make sure the command/netfn is not already registered. */\n\tif (!is_cmd_rcvr_exclusive(intf, netfn, cmd, chans)) {\n\t\trv = -EBUSY;\n\t\tgoto out_unlock;\n\t}\n\n\tsmi_add_watch(intf, IPMI_WATCH_MASK_CHECK_COMMANDS);\n\n\tlist_add_rcu(&rcvr->link, &intf->cmd_rcvrs);\n\nout_unlock:\n\tmutex_unlock(&intf->cmd_rcvrs_mutex);\n\tif (rv)\n\t\tkfree(rcvr);\nout_release:\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_register_for_cmd);\n\nint ipmi_unregister_for_cmd(struct ipmi_user *user,\n\t\t\t    unsigned char netfn,\n\t\t\t    unsigned char cmd,\n\t\t\t    unsigned int  chans)\n{\n\tstruct ipmi_smi *intf = user->intf;\n\tstruct cmd_rcvr *rcvr;\n\tstruct cmd_rcvr *rcvrs = NULL;\n\tint i, rv = -ENOENT, index;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tmutex_lock(&intf->cmd_rcvrs_mutex);\n\tfor (i = 0; i < IPMI_NUM_CHANNELS; i++) {\n\t\tif (((1 << i) & chans) == 0)\n\t\t\tcontinue;\n\t\trcvr = find_cmd_rcvr(intf, netfn, cmd, i);\n\t\tif (rcvr == NULL)\n\t\t\tcontinue;\n\t\tif (rcvr->user == user) {\n\t\t\trv = 0;\n\t\t\trcvr->chans &= ~chans;\n\t\t\tif (rcvr->chans == 0) {\n\t\t\t\tlist_del_rcu(&rcvr->link);\n\t\t\t\trcvr->next = rcvrs;\n\t\t\t\trcvrs = rcvr;\n\t\t\t}\n\t\t}\n\t}\n\tmutex_unlock(&intf->cmd_rcvrs_mutex);\n\tsynchronize_rcu();\n\trelease_ipmi_user(user, index);\n\twhile (rcvrs) {\n\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_COMMANDS);\n\t\trcvr = rcvrs;\n\t\trcvrs = rcvr->next;\n\t\tkfree(rcvr);\n\t}\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_unregister_for_cmd);\n\nstatic unsigned char\nipmb_checksum(unsigned char *data, int size)\n{\n\tunsigned char csum = 0;\n\n\tfor (; size > 0; size--, data++)\n\t\tcsum += *data;\n\n\treturn -csum;\n}\n\nstatic inline void format_ipmb_msg(struct ipmi_smi_msg   *smi_msg,\n\t\t\t\t   struct kernel_ipmi_msg *msg,\n\t\t\t\t   struct ipmi_ipmb_addr *ipmb_addr,\n\t\t\t\t   long                  msgid,\n\t\t\t\t   unsigned char         ipmb_seq,\n\t\t\t\t   int                   broadcast,\n\t\t\t\t   unsigned char         source_address,\n\t\t\t\t   unsigned char         source_lun)\n{\n\tint i = broadcast;\n\n\t/* Format the IPMB header data. */\n\tsmi_msg->data[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\tsmi_msg->data[1] = IPMI_SEND_MSG_CMD;\n\tsmi_msg->data[2] = ipmb_addr->channel;\n\tif (broadcast)\n\t\tsmi_msg->data[3] = 0;\n\tsmi_msg->data[i+3] = ipmb_addr->slave_addr;\n\tsmi_msg->data[i+4] = (msg->netfn << 2) | (ipmb_addr->lun & 0x3);\n\tsmi_msg->data[i+5] = ipmb_checksum(&smi_msg->data[i + 3], 2);\n\tsmi_msg->data[i+6] = source_address;\n\tsmi_msg->data[i+7] = (ipmb_seq << 2) | source_lun;\n\tsmi_msg->data[i+8] = msg->cmd;\n\n\t/* Now tack on the data to the message. */\n\tif (msg->data_len > 0)\n\t\tmemcpy(&smi_msg->data[i + 9], msg->data, msg->data_len);\n\tsmi_msg->data_size = msg->data_len + 9;\n\n\t/* Now calculate the checksum and tack it on. */\n\tsmi_msg->data[i+smi_msg->data_size]\n\t\t= ipmb_checksum(&smi_msg->data[i + 6], smi_msg->data_size - 6);\n\n\t/*\n\t * Add on the checksum size and the offset from the\n\t * broadcast.\n\t */\n\tsmi_msg->data_size += 1 + i;\n\n\tsmi_msg->msgid = msgid;\n}\n\nstatic inline void format_lan_msg(struct ipmi_smi_msg   *smi_msg,\n\t\t\t\t  struct kernel_ipmi_msg *msg,\n\t\t\t\t  struct ipmi_lan_addr  *lan_addr,\n\t\t\t\t  long                  msgid,\n\t\t\t\t  unsigned char         ipmb_seq,\n\t\t\t\t  unsigned char         source_lun)\n{\n\t/* Format the IPMB header data. */\n\tsmi_msg->data[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\tsmi_msg->data[1] = IPMI_SEND_MSG_CMD;\n\tsmi_msg->data[2] = lan_addr->channel;\n\tsmi_msg->data[3] = lan_addr->session_handle;\n\tsmi_msg->data[4] = lan_addr->remote_SWID;\n\tsmi_msg->data[5] = (msg->netfn << 2) | (lan_addr->lun & 0x3);\n\tsmi_msg->data[6] = ipmb_checksum(&smi_msg->data[4], 2);\n\tsmi_msg->data[7] = lan_addr->local_SWID;\n\tsmi_msg->data[8] = (ipmb_seq << 2) | source_lun;\n\tsmi_msg->data[9] = msg->cmd;\n\n\t/* Now tack on the data to the message. */\n\tif (msg->data_len > 0)\n\t\tmemcpy(&smi_msg->data[10], msg->data, msg->data_len);\n\tsmi_msg->data_size = msg->data_len + 10;\n\n\t/* Now calculate the checksum and tack it on. */\n\tsmi_msg->data[smi_msg->data_size]\n\t\t= ipmb_checksum(&smi_msg->data[7], smi_msg->data_size - 7);\n\n\t/*\n\t * Add on the checksum size and the offset from the\n\t * broadcast.\n\t */\n\tsmi_msg->data_size += 1;\n\n\tsmi_msg->msgid = msgid;\n}\n\nstatic struct ipmi_smi_msg *smi_add_send_msg(struct ipmi_smi *intf,\n\t\t\t\t\t     struct ipmi_smi_msg *smi_msg,\n\t\t\t\t\t     int priority)\n{\n\tif (intf->curr_msg) {\n\t\tif (priority > 0)\n\t\t\tlist_add_tail(&smi_msg->link, &intf->hp_xmit_msgs);\n\t\telse\n\t\t\tlist_add_tail(&smi_msg->link, &intf->xmit_msgs);\n\t\tsmi_msg = NULL;\n\t} else {\n\t\tintf->curr_msg = smi_msg;\n\t}\n\n\treturn smi_msg;\n}\n\nstatic void smi_send(struct ipmi_smi *intf,\n\t\t     const struct ipmi_smi_handlers *handlers,\n\t\t     struct ipmi_smi_msg *smi_msg, int priority)\n{\n\tint run_to_completion = intf->run_to_completion;\n\tunsigned long flags = 0;\n\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&intf->xmit_msgs_lock, flags);\n\tsmi_msg = smi_add_send_msg(intf, smi_msg, priority);\n\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&intf->xmit_msgs_lock, flags);\n\n\tif (smi_msg)\n\t\thandlers->sender(intf->send_info, smi_msg);\n}\n\nstatic bool is_maintenance_mode_cmd(struct kernel_ipmi_msg *msg)\n{\n\treturn (((msg->netfn == IPMI_NETFN_APP_REQUEST)\n\t\t && ((msg->cmd == IPMI_COLD_RESET_CMD)\n\t\t     || (msg->cmd == IPMI_WARM_RESET_CMD)))\n\t\t|| (msg->netfn == IPMI_NETFN_FIRMWARE_REQUEST));\n}\n\nstatic int i_ipmi_req_sysintf(struct ipmi_smi        *intf,\n\t\t\t      struct ipmi_addr       *addr,\n\t\t\t      long                   msgid,\n\t\t\t      struct kernel_ipmi_msg *msg,\n\t\t\t      struct ipmi_smi_msg    *smi_msg,\n\t\t\t      struct ipmi_recv_msg   *recv_msg,\n\t\t\t      int                    retries,\n\t\t\t      unsigned int           retry_time_ms)\n{\n\tstruct ipmi_system_interface_addr *smi_addr;\n\n\tif (msg->netfn & 1)\n\t\t/* Responses are not allowed to the SMI. */\n\t\treturn -EINVAL;\n\n\tsmi_addr = (struct ipmi_system_interface_addr *) addr;\n\tif (smi_addr->lun > 3) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(&recv_msg->addr, smi_addr, sizeof(*smi_addr));\n\n\tif ((msg->netfn == IPMI_NETFN_APP_REQUEST)\n\t    && ((msg->cmd == IPMI_SEND_MSG_CMD)\n\t\t|| (msg->cmd == IPMI_GET_MSG_CMD)\n\t\t|| (msg->cmd == IPMI_READ_EVENT_MSG_BUFFER_CMD))) {\n\t\t/*\n\t\t * We don't let the user do these, since we manage\n\t\t * the sequence numbers.\n\t\t */\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tif (is_maintenance_mode_cmd(msg)) {\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&intf->maintenance_mode_lock, flags);\n\t\tintf->auto_maintenance_timeout\n\t\t\t= maintenance_mode_timeout_ms;\n\t\tif (!intf->maintenance_mode\n\t\t    && !intf->maintenance_mode_enable) {\n\t\t\tintf->maintenance_mode_enable = true;\n\t\t\tmaintenance_mode_update(intf);\n\t\t}\n\t\tspin_unlock_irqrestore(&intf->maintenance_mode_lock,\n\t\t\t\t       flags);\n\t}\n\n\tif (msg->data_len + 2 > IPMI_MAX_MSG_LENGTH) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tsmi_msg->data[0] = (msg->netfn << 2) | (smi_addr->lun & 0x3);\n\tsmi_msg->data[1] = msg->cmd;\n\tsmi_msg->msgid = msgid;\n\tsmi_msg->user_data = recv_msg;\n\tif (msg->data_len > 0)\n\t\tmemcpy(&smi_msg->data[2], msg->data, msg->data_len);\n\tsmi_msg->data_size = msg->data_len + 2;\n\tipmi_inc_stat(intf, sent_local_commands);\n\n\treturn 0;\n}\n\nstatic int i_ipmi_req_ipmb(struct ipmi_smi        *intf,\n\t\t\t   struct ipmi_addr       *addr,\n\t\t\t   long                   msgid,\n\t\t\t   struct kernel_ipmi_msg *msg,\n\t\t\t   struct ipmi_smi_msg    *smi_msg,\n\t\t\t   struct ipmi_recv_msg   *recv_msg,\n\t\t\t   unsigned char          source_address,\n\t\t\t   unsigned char          source_lun,\n\t\t\t   int                    retries,\n\t\t\t   unsigned int           retry_time_ms)\n{\n\tstruct ipmi_ipmb_addr *ipmb_addr;\n\tunsigned char ipmb_seq;\n\tlong seqid;\n\tint broadcast = 0;\n\tstruct ipmi_channel *chans;\n\tint rv = 0;\n\n\tif (addr->channel >= IPMI_MAX_CHANNELS) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tchans = READ_ONCE(intf->channel_list)->c;\n\n\tif (chans[addr->channel].medium != IPMI_CHANNEL_MEDIUM_IPMB) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tif (addr->addr_type == IPMI_IPMB_BROADCAST_ADDR_TYPE) {\n\t\t/*\n\t\t * Broadcasts add a zero at the beginning of the\n\t\t * message, but otherwise is the same as an IPMB\n\t\t * address.\n\t\t */\n\t\taddr->addr_type = IPMI_IPMB_ADDR_TYPE;\n\t\tbroadcast = 1;\n\t\tretries = 0; /* Don't retry broadcasts. */\n\t}\n\n\t/*\n\t * 9 for the header and 1 for the checksum, plus\n\t * possibly one for the broadcast.\n\t */\n\tif ((msg->data_len + 10 + broadcast) > IPMI_MAX_MSG_LENGTH) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tipmb_addr = (struct ipmi_ipmb_addr *) addr;\n\tif (ipmb_addr->lun > 3) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(&recv_msg->addr, ipmb_addr, sizeof(*ipmb_addr));\n\n\tif (recv_msg->msg.netfn & 0x1) {\n\t\t/*\n\t\t * It's a response, so use the user's sequence\n\t\t * from msgid.\n\t\t */\n\t\tipmi_inc_stat(intf, sent_ipmb_responses);\n\t\tformat_ipmb_msg(smi_msg, msg, ipmb_addr, msgid,\n\t\t\t\tmsgid, broadcast,\n\t\t\t\tsource_address, source_lun);\n\n\t\t/*\n\t\t * Save the receive message so we can use it\n\t\t * to deliver the response.\n\t\t */\n\t\tsmi_msg->user_data = recv_msg;\n\t} else {\n\t\t/* It's a command, so get a sequence for it. */\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&intf->seq_lock, flags);\n\n\t\tif (is_maintenance_mode_cmd(msg))\n\t\t\tintf->ipmb_maintenance_mode_timeout =\n\t\t\t\tmaintenance_mode_timeout_ms;\n\n\t\tif (intf->ipmb_maintenance_mode_timeout && retry_time_ms == 0)\n\t\t\t/* Different default in maintenance mode */\n\t\t\tretry_time_ms = default_maintenance_retry_ms;\n\n\t\t/*\n\t\t * Create a sequence number with a 1 second\n\t\t * timeout and 4 retries.\n\t\t */\n\t\trv = intf_next_seq(intf,\n\t\t\t\t   recv_msg,\n\t\t\t\t   retry_time_ms,\n\t\t\t\t   retries,\n\t\t\t\t   broadcast,\n\t\t\t\t   &ipmb_seq,\n\t\t\t\t   &seqid);\n\t\tif (rv)\n\t\t\t/*\n\t\t\t * We have used up all the sequence numbers,\n\t\t\t * probably, so abort.\n\t\t\t */\n\t\t\tgoto out_err;\n\n\t\tipmi_inc_stat(intf, sent_ipmb_commands);\n\n\t\t/*\n\t\t * Store the sequence number in the message,\n\t\t * so that when the send message response\n\t\t * comes back we can start the timer.\n\t\t */\n\t\tformat_ipmb_msg(smi_msg, msg, ipmb_addr,\n\t\t\t\tSTORE_SEQ_IN_MSGID(ipmb_seq, seqid),\n\t\t\t\tipmb_seq, broadcast,\n\t\t\t\tsource_address, source_lun);\n\n\t\t/*\n\t\t * Copy the message into the recv message data, so we\n\t\t * can retransmit it later if necessary.\n\t\t */\n\t\tmemcpy(recv_msg->msg_data, smi_msg->data,\n\t\t       smi_msg->data_size);\n\t\trecv_msg->msg.data = recv_msg->msg_data;\n\t\trecv_msg->msg.data_len = smi_msg->data_size;\n\n\t\t/*\n\t\t * We don't unlock until here, because we need\n\t\t * to copy the completed message into the\n\t\t * recv_msg before we release the lock.\n\t\t * Otherwise, race conditions may bite us.  I\n\t\t * know that's pretty paranoid, but I prefer\n\t\t * to be correct.\n\t\t */\nout_err:\n\t\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\t}\n\n\treturn rv;\n}\n\nstatic int i_ipmi_req_lan(struct ipmi_smi        *intf,\n\t\t\t  struct ipmi_addr       *addr,\n\t\t\t  long                   msgid,\n\t\t\t  struct kernel_ipmi_msg *msg,\n\t\t\t  struct ipmi_smi_msg    *smi_msg,\n\t\t\t  struct ipmi_recv_msg   *recv_msg,\n\t\t\t  unsigned char          source_lun,\n\t\t\t  int                    retries,\n\t\t\t  unsigned int           retry_time_ms)\n{\n\tstruct ipmi_lan_addr  *lan_addr;\n\tunsigned char ipmb_seq;\n\tlong seqid;\n\tstruct ipmi_channel *chans;\n\tint rv = 0;\n\n\tif (addr->channel >= IPMI_MAX_CHANNELS) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tchans = READ_ONCE(intf->channel_list)->c;\n\n\tif ((chans[addr->channel].medium\n\t\t\t\t!= IPMI_CHANNEL_MEDIUM_8023LAN)\n\t\t\t&& (chans[addr->channel].medium\n\t\t\t    != IPMI_CHANNEL_MEDIUM_ASYNC)) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\t/* 11 for the header and 1 for the checksum. */\n\tif ((msg->data_len + 12) > IPMI_MAX_MSG_LENGTH) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tlan_addr = (struct ipmi_lan_addr *) addr;\n\tif (lan_addr->lun > 3) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(&recv_msg->addr, lan_addr, sizeof(*lan_addr));\n\n\tif (recv_msg->msg.netfn & 0x1) {\n\t\t/*\n\t\t * It's a response, so use the user's sequence\n\t\t * from msgid.\n\t\t */\n\t\tipmi_inc_stat(intf, sent_lan_responses);\n\t\tformat_lan_msg(smi_msg, msg, lan_addr, msgid,\n\t\t\t       msgid, source_lun);\n\n\t\t/*\n\t\t * Save the receive message so we can use it\n\t\t * to deliver the response.\n\t\t */\n\t\tsmi_msg->user_data = recv_msg;\n\t} else {\n\t\t/* It's a command, so get a sequence for it. */\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&intf->seq_lock, flags);\n\n\t\t/*\n\t\t * Create a sequence number with a 1 second\n\t\t * timeout and 4 retries.\n\t\t */\n\t\trv = intf_next_seq(intf,\n\t\t\t\t   recv_msg,\n\t\t\t\t   retry_time_ms,\n\t\t\t\t   retries,\n\t\t\t\t   0,\n\t\t\t\t   &ipmb_seq,\n\t\t\t\t   &seqid);\n\t\tif (rv)\n\t\t\t/*\n\t\t\t * We have used up all the sequence numbers,\n\t\t\t * probably, so abort.\n\t\t\t */\n\t\t\tgoto out_err;\n\n\t\tipmi_inc_stat(intf, sent_lan_commands);\n\n\t\t/*\n\t\t * Store the sequence number in the message,\n\t\t * so that when the send message response\n\t\t * comes back we can start the timer.\n\t\t */\n\t\tformat_lan_msg(smi_msg, msg, lan_addr,\n\t\t\t       STORE_SEQ_IN_MSGID(ipmb_seq, seqid),\n\t\t\t       ipmb_seq, source_lun);\n\n\t\t/*\n\t\t * Copy the message into the recv message data, so we\n\t\t * can retransmit it later if necessary.\n\t\t */\n\t\tmemcpy(recv_msg->msg_data, smi_msg->data,\n\t\t       smi_msg->data_size);\n\t\trecv_msg->msg.data = recv_msg->msg_data;\n\t\trecv_msg->msg.data_len = smi_msg->data_size;\n\n\t\t/*\n\t\t * We don't unlock until here, because we need\n\t\t * to copy the completed message into the\n\t\t * recv_msg before we release the lock.\n\t\t * Otherwise, race conditions may bite us.  I\n\t\t * know that's pretty paranoid, but I prefer\n\t\t * to be correct.\n\t\t */\nout_err:\n\t\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\t}\n\n\treturn rv;\n}\n\n/*\n * Separate from ipmi_request so that the user does not have to be\n * supplied in certain circumstances (mainly at panic time).  If\n * messages are supplied, they will be freed, even if an error\n * occurs.\n */\nstatic int i_ipmi_request(struct ipmi_user     *user,\n\t\t\t  struct ipmi_smi      *intf,\n\t\t\t  struct ipmi_addr     *addr,\n\t\t\t  long                 msgid,\n\t\t\t  struct kernel_ipmi_msg *msg,\n\t\t\t  void                 *user_msg_data,\n\t\t\t  void                 *supplied_smi,\n\t\t\t  struct ipmi_recv_msg *supplied_recv,\n\t\t\t  int                  priority,\n\t\t\t  unsigned char        source_address,\n\t\t\t  unsigned char        source_lun,\n\t\t\t  int                  retries,\n\t\t\t  unsigned int         retry_time_ms)\n{\n\tstruct ipmi_smi_msg *smi_msg;\n\tstruct ipmi_recv_msg *recv_msg;\n\tint rv = 0;\n\n\tif (supplied_recv)\n\t\trecv_msg = supplied_recv;\n\telse {\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (recv_msg == NULL) {\n\t\t\trv = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\trecv_msg->user_msg_data = user_msg_data;\n\n\tif (supplied_smi)\n\t\tsmi_msg = (struct ipmi_smi_msg *) supplied_smi;\n\telse {\n\t\tsmi_msg = ipmi_alloc_smi_msg();\n\t\tif (smi_msg == NULL) {\n\t\t\tif (!supplied_recv)\n\t\t\t\tipmi_free_recv_msg(recv_msg);\n\t\t\trv = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\trcu_read_lock();\n\tif (intf->in_shutdown) {\n\t\trv = -ENODEV;\n\t\tgoto out_err;\n\t}\n\n\trecv_msg->user = user;\n\tif (user)\n\t\t/* The put happens when the message is freed. */\n\t\tkref_get(&user->refcount);\n\trecv_msg->msgid = msgid;\n\t/*\n\t * Store the message to send in the receive message so timeout\n\t * responses can get the proper response data.\n\t */\n\trecv_msg->msg = *msg;\n\n\tif (addr->addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE) {\n\t\trv = i_ipmi_req_sysintf(intf, addr, msgid, msg, smi_msg,\n\t\t\t\t\trecv_msg, retries, retry_time_ms);\n\t} else if (is_ipmb_addr(addr) || is_ipmb_bcast_addr(addr)) {\n\t\trv = i_ipmi_req_ipmb(intf, addr, msgid, msg, smi_msg, recv_msg,\n\t\t\t\t     source_address, source_lun,\n\t\t\t\t     retries, retry_time_ms);\n\t} else if (is_lan_addr(addr)) {\n\t\trv = i_ipmi_req_lan(intf, addr, msgid, msg, smi_msg, recv_msg,\n\t\t\t\t    source_lun, retries, retry_time_ms);\n\t} else {\n\t    /* Unknown address type. */\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\trv = -EINVAL;\n\t}\n\n\tif (rv) {\nout_err:\n\t\tipmi_free_smi_msg(smi_msg);\n\t\tipmi_free_recv_msg(recv_msg);\n\t} else {\n\t\tpr_debug(\"Send: %*ph\\n\", smi_msg->data_size, smi_msg->data);\n\n\t\tsmi_send(intf, intf->handlers, smi_msg, priority);\n\t}\n\trcu_read_unlock();\n\nout:\n\treturn rv;\n}\n\nstatic int check_addr(struct ipmi_smi  *intf,\n\t\t      struct ipmi_addr *addr,\n\t\t      unsigned char    *saddr,\n\t\t      unsigned char    *lun)\n{\n\tif (addr->channel >= IPMI_MAX_CHANNELS)\n\t\treturn -EINVAL;\n\taddr->channel = array_index_nospec(addr->channel, IPMI_MAX_CHANNELS);\n\t*lun = intf->addrinfo[addr->channel].lun;\n\t*saddr = intf->addrinfo[addr->channel].address;\n\treturn 0;\n}\n\nint ipmi_request_settime(struct ipmi_user *user,\n\t\t\t struct ipmi_addr *addr,\n\t\t\t long             msgid,\n\t\t\t struct kernel_ipmi_msg  *msg,\n\t\t\t void             *user_msg_data,\n\t\t\t int              priority,\n\t\t\t int              retries,\n\t\t\t unsigned int     retry_time_ms)\n{\n\tunsigned char saddr = 0, lun = 0;\n\tint rv, index;\n\n\tif (!user)\n\t\treturn -EINVAL;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\trv = check_addr(user->intf, addr, &saddr, &lun);\n\tif (!rv)\n\t\trv = i_ipmi_request(user,\n\t\t\t\t    user->intf,\n\t\t\t\t    addr,\n\t\t\t\t    msgid,\n\t\t\t\t    msg,\n\t\t\t\t    user_msg_data,\n\t\t\t\t    NULL, NULL,\n\t\t\t\t    priority,\n\t\t\t\t    saddr,\n\t\t\t\t    lun,\n\t\t\t\t    retries,\n\t\t\t\t    retry_time_ms);\n\n\trelease_ipmi_user(user, index);\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_request_settime);\n\nint ipmi_request_supply_msgs(struct ipmi_user     *user,\n\t\t\t     struct ipmi_addr     *addr,\n\t\t\t     long                 msgid,\n\t\t\t     struct kernel_ipmi_msg *msg,\n\t\t\t     void                 *user_msg_data,\n\t\t\t     void                 *supplied_smi,\n\t\t\t     struct ipmi_recv_msg *supplied_recv,\n\t\t\t     int                  priority)\n{\n\tunsigned char saddr = 0, lun = 0;\n\tint rv, index;\n\n\tif (!user)\n\t\treturn -EINVAL;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\trv = check_addr(user->intf, addr, &saddr, &lun);\n\tif (!rv)\n\t\trv = i_ipmi_request(user,\n\t\t\t\t    user->intf,\n\t\t\t\t    addr,\n\t\t\t\t    msgid,\n\t\t\t\t    msg,\n\t\t\t\t    user_msg_data,\n\t\t\t\t    supplied_smi,\n\t\t\t\t    supplied_recv,\n\t\t\t\t    priority,\n\t\t\t\t    saddr,\n\t\t\t\t    lun,\n\t\t\t\t    -1, 0);\n\n\trelease_ipmi_user(user, index);\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_request_supply_msgs);\n\nstatic void bmc_device_id_handler(struct ipmi_smi *intf,\n\t\t\t\t  struct ipmi_recv_msg *msg)\n{\n\tint rv;\n\n\tif ((msg->addr.addr_type != IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t\t\t|| (msg->msg.netfn != IPMI_NETFN_APP_RESPONSE)\n\t\t\t|| (msg->msg.cmd != IPMI_GET_DEVICE_ID_CMD)) {\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"invalid device_id msg: addr_type=%d netfn=%x cmd=%x\\n\",\n\t\t\t msg->addr.addr_type, msg->msg.netfn, msg->msg.cmd);\n\t\treturn;\n\t}\n\n\trv = ipmi_demangle_device_id(msg->msg.netfn, msg->msg.cmd,\n\t\t\tmsg->msg.data, msg->msg.data_len, &intf->bmc->fetch_id);\n\tif (rv) {\n\t\tdev_warn(intf->si_dev, \"device id demangle failed: %d\\n\", rv);\n\t\tintf->bmc->dyn_id_set = 0;\n\t} else {\n\t\t/*\n\t\t * Make sure the id data is available before setting\n\t\t * dyn_id_set.\n\t\t */\n\t\tsmp_wmb();\n\t\tintf->bmc->dyn_id_set = 1;\n\t}\n\n\twake_up(&intf->waitq);\n}\n\nstatic int\nsend_get_device_id_cmd(struct ipmi_smi *intf)\n{\n\tstruct ipmi_system_interface_addr si;\n\tstruct kernel_ipmi_msg msg;\n\n\tsi.addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsi.channel = IPMI_BMC_CHANNEL;\n\tsi.lun = 0;\n\n\tmsg.netfn = IPMI_NETFN_APP_REQUEST;\n\tmsg.cmd = IPMI_GET_DEVICE_ID_CMD;\n\tmsg.data = NULL;\n\tmsg.data_len = 0;\n\n\treturn i_ipmi_request(NULL,\n\t\t\t      intf,\n\t\t\t      (struct ipmi_addr *) &si,\n\t\t\t      0,\n\t\t\t      &msg,\n\t\t\t      intf,\n\t\t\t      NULL,\n\t\t\t      NULL,\n\t\t\t      0,\n\t\t\t      intf->addrinfo[0].address,\n\t\t\t      intf->addrinfo[0].lun,\n\t\t\t      -1, 0);\n}\n\nstatic int __get_device_id(struct ipmi_smi *intf, struct bmc_device *bmc)\n{\n\tint rv;\n\n\tbmc->dyn_id_set = 2;\n\n\tintf->null_user_handler = bmc_device_id_handler;\n\n\trv = send_get_device_id_cmd(intf);\n\tif (rv)\n\t\treturn rv;\n\n\twait_event(intf->waitq, bmc->dyn_id_set != 2);\n\n\tif (!bmc->dyn_id_set)\n\t\trv = -EIO; /* Something went wrong in the fetch. */\n\n\t/* dyn_id_set makes the id data available. */\n\tsmp_rmb();\n\n\tintf->null_user_handler = NULL;\n\n\treturn rv;\n}\n\n/*\n * Fetch the device id for the bmc/interface.  You must pass in either\n * bmc or intf, this code will get the other one.  If the data has\n * been recently fetched, this will just use the cached data.  Otherwise\n * it will run a new fetch.\n *\n * Except for the first time this is called (in ipmi_add_smi()),\n * this will always return good data;\n */\nstatic int __bmc_get_device_id(struct ipmi_smi *intf, struct bmc_device *bmc,\n\t\t\t       struct ipmi_device_id *id,\n\t\t\t       bool *guid_set, guid_t *guid, int intf_num)\n{\n\tint rv = 0;\n\tint prev_dyn_id_set, prev_guid_set;\n\tbool intf_set = intf != NULL;\n\n\tif (!intf) {\n\t\tmutex_lock(&bmc->dyn_mutex);\nretry_bmc_lock:\n\t\tif (list_empty(&bmc->intfs)) {\n\t\t\tmutex_unlock(&bmc->dyn_mutex);\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tintf = list_first_entry(&bmc->intfs, struct ipmi_smi,\n\t\t\t\t\tbmc_link);\n\t\tkref_get(&intf->refcount);\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\t\tmutex_lock(&intf->bmc_reg_mutex);\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tif (intf != list_first_entry(&bmc->intfs, struct ipmi_smi,\n\t\t\t\t\t     bmc_link)) {\n\t\t\tmutex_unlock(&intf->bmc_reg_mutex);\n\t\t\tkref_put(&intf->refcount, intf_free);\n\t\t\tgoto retry_bmc_lock;\n\t\t}\n\t} else {\n\t\tmutex_lock(&intf->bmc_reg_mutex);\n\t\tbmc = intf->bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tkref_get(&intf->refcount);\n\t}\n\n\t/* If we have a valid and current ID, just return that. */\n\tif (intf->in_bmc_register ||\n\t    (bmc->dyn_id_set && time_is_after_jiffies(bmc->dyn_id_expiry)))\n\t\tgoto out_noprocessing;\n\n\tprev_guid_set = bmc->dyn_guid_set;\n\t__get_guid(intf);\n\n\tprev_dyn_id_set = bmc->dyn_id_set;\n\trv = __get_device_id(intf, bmc);\n\tif (rv)\n\t\tgoto out;\n\n\t/*\n\t * The guid, device id, manufacturer id, and product id should\n\t * not change on a BMC.  If it does we have to do some dancing.\n\t */\n\tif (!intf->bmc_registered\n\t    || (!prev_guid_set && bmc->dyn_guid_set)\n\t    || (!prev_dyn_id_set && bmc->dyn_id_set)\n\t    || (prev_guid_set && bmc->dyn_guid_set\n\t\t&& !guid_equal(&bmc->guid, &bmc->fetch_guid))\n\t    || bmc->id.device_id != bmc->fetch_id.device_id\n\t    || bmc->id.manufacturer_id != bmc->fetch_id.manufacturer_id\n\t    || bmc->id.product_id != bmc->fetch_id.product_id) {\n\t\tstruct ipmi_device_id id = bmc->fetch_id;\n\t\tint guid_set = bmc->dyn_guid_set;\n\t\tguid_t guid;\n\n\t\tguid = bmc->fetch_guid;\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\n\t\t__ipmi_bmc_unregister(intf);\n\t\t/* Fill in the temporary BMC for good measure. */\n\t\tintf->bmc->id = id;\n\t\tintf->bmc->dyn_guid_set = guid_set;\n\t\tintf->bmc->guid = guid;\n\t\tif (__ipmi_bmc_register(intf, &id, guid_set, &guid, intf_num))\n\t\t\tneed_waiter(intf); /* Retry later on an error. */\n\t\telse\n\t\t\t__scan_channels(intf, &id);\n\n\n\t\tif (!intf_set) {\n\t\t\t/*\n\t\t\t * We weren't given the interface on the\n\t\t\t * command line, so restart the operation on\n\t\t\t * the next interface for the BMC.\n\t\t\t */\n\t\t\tmutex_unlock(&intf->bmc_reg_mutex);\n\t\t\tmutex_lock(&bmc->dyn_mutex);\n\t\t\tgoto retry_bmc_lock;\n\t\t}\n\n\t\t/* We have a new BMC, set it up. */\n\t\tbmc = intf->bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tgoto out_noprocessing;\n\t} else if (memcmp(&bmc->fetch_id, &bmc->id, sizeof(bmc->id)))\n\t\t/* Version info changes, scan the channels again. */\n\t\t__scan_channels(intf, &bmc->fetch_id);\n\n\tbmc->dyn_id_expiry = jiffies + IPMI_DYN_DEV_ID_EXPIRY;\n\nout:\n\tif (rv && prev_dyn_id_set) {\n\t\trv = 0; /* Ignore failures if we have previous data. */\n\t\tbmc->dyn_id_set = prev_dyn_id_set;\n\t}\n\tif (!rv) {\n\t\tbmc->id = bmc->fetch_id;\n\t\tif (bmc->dyn_guid_set)\n\t\t\tbmc->guid = bmc->fetch_guid;\n\t\telse if (prev_guid_set)\n\t\t\t/*\n\t\t\t * The guid used to be valid and it failed to fetch,\n\t\t\t * just use the cached value.\n\t\t\t */\n\t\t\tbmc->dyn_guid_set = prev_guid_set;\n\t}\nout_noprocessing:\n\tif (!rv) {\n\t\tif (id)\n\t\t\t*id = bmc->id;\n\n\t\tif (guid_set)\n\t\t\t*guid_set = bmc->dyn_guid_set;\n\n\t\tif (guid && bmc->dyn_guid_set)\n\t\t\t*guid =  bmc->guid;\n\t}\n\n\tmutex_unlock(&bmc->dyn_mutex);\n\tmutex_unlock(&intf->bmc_reg_mutex);\n\n\tkref_put(&intf->refcount, intf_free);\n\treturn rv;\n}\n\nstatic int bmc_get_device_id(struct ipmi_smi *intf, struct bmc_device *bmc,\n\t\t\t     struct ipmi_device_id *id,\n\t\t\t     bool *guid_set, guid_t *guid)\n{\n\treturn __bmc_get_device_id(intf, bmc, id, guid_set, guid, -1);\n}\n\nstatic ssize_t device_id_show(struct device *dev,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 10, \"%u\\n\", id.device_id);\n}\nstatic DEVICE_ATTR_RO(device_id);\n\nstatic ssize_t provides_device_sdrs_show(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 10, \"%u\\n\", (id.device_revision & 0x80) >> 7);\n}\nstatic DEVICE_ATTR_RO(provides_device_sdrs);\n\nstatic ssize_t revision_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 20, \"%u\\n\", id.device_revision & 0x0F);\n}\nstatic DEVICE_ATTR_RO(revision);\n\nstatic ssize_t firmware_revision_show(struct device *dev,\n\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t      char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 20, \"%u.%x\\n\", id.firmware_revision_1,\n\t\t\tid.firmware_revision_2);\n}\nstatic DEVICE_ATTR_RO(firmware_revision);\n\nstatic ssize_t ipmi_version_show(struct device *dev,\n\t\t\t\t struct device_attribute *attr,\n\t\t\t\t char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 20, \"%u.%u\\n\",\n\t\t\tipmi_version_major(&id),\n\t\t\tipmi_version_minor(&id));\n}\nstatic DEVICE_ATTR_RO(ipmi_version);\n\nstatic ssize_t add_dev_support_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 10, \"0x%02x\\n\", id.additional_device_support);\n}\nstatic DEVICE_ATTR(additional_device_support, S_IRUGO, add_dev_support_show,\n\t\t   NULL);\n\nstatic ssize_t manufacturer_id_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 20, \"0x%6.6x\\n\", id.manufacturer_id);\n}\nstatic DEVICE_ATTR_RO(manufacturer_id);\n\nstatic ssize_t product_id_show(struct device *dev,\n\t\t\t       struct device_attribute *attr,\n\t\t\t       char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 10, \"0x%4.4x\\n\", id.product_id);\n}\nstatic DEVICE_ATTR_RO(product_id);\n\nstatic ssize_t aux_firmware_rev_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 21, \"0x%02x 0x%02x 0x%02x 0x%02x\\n\",\n\t\t\tid.aux_firmware_revision[3],\n\t\t\tid.aux_firmware_revision[2],\n\t\t\tid.aux_firmware_revision[1],\n\t\t\tid.aux_firmware_revision[0]);\n}\nstatic DEVICE_ATTR(aux_firmware_revision, S_IRUGO, aux_firmware_rev_show, NULL);\n\nstatic ssize_t guid_show(struct device *dev, struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tbool guid_set;\n\tguid_t guid;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, NULL, &guid_set, &guid);\n\tif (rv)\n\t\treturn rv;\n\tif (!guid_set)\n\t\treturn -ENOENT;\n\n\treturn snprintf(buf, UUID_STRING_LEN + 1 + 1, \"%pUl\\n\", &guid);\n}\nstatic DEVICE_ATTR_RO(guid);\n\nstatic struct attribute *bmc_dev_attrs[] = {\n\t&dev_attr_device_id.attr,\n\t&dev_attr_provides_device_sdrs.attr,\n\t&dev_attr_revision.attr,\n\t&dev_attr_firmware_revision.attr,\n\t&dev_attr_ipmi_version.attr,\n\t&dev_attr_additional_device_support.attr,\n\t&dev_attr_manufacturer_id.attr,\n\t&dev_attr_product_id.attr,\n\t&dev_attr_aux_firmware_revision.attr,\n\t&dev_attr_guid.attr,\n\tNULL\n};\n\nstatic umode_t bmc_dev_attr_is_visible(struct kobject *kobj,\n\t\t\t\t       struct attribute *attr, int idx)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tumode_t mode = attr->mode;\n\tint rv;\n\n\tif (attr == &dev_attr_aux_firmware_revision.attr) {\n\t\tstruct ipmi_device_id id;\n\n\t\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\t\treturn (!rv && id.aux_firmware_revision_set) ? mode : 0;\n\t}\n\tif (attr == &dev_attr_guid.attr) {\n\t\tbool guid_set;\n\n\t\trv = bmc_get_device_id(NULL, bmc, NULL, &guid_set, NULL);\n\t\treturn (!rv && guid_set) ? mode : 0;\n\t}\n\treturn mode;\n}\n\nstatic const struct attribute_group bmc_dev_attr_group = {\n\t.attrs\t\t= bmc_dev_attrs,\n\t.is_visible\t= bmc_dev_attr_is_visible,\n};\n\nstatic const struct attribute_group *bmc_dev_attr_groups[] = {\n\t&bmc_dev_attr_group,\n\tNULL\n};\n\nstatic const struct device_type bmc_device_type = {\n\t.groups\t\t= bmc_dev_attr_groups,\n};\n\nstatic int __find_bmc_guid(struct device *dev, const void *data)\n{\n\tconst guid_t *guid = data;\n\tstruct bmc_device *bmc;\n\tint rv;\n\n\tif (dev->type != &bmc_device_type)\n\t\treturn 0;\n\n\tbmc = to_bmc_device(dev);\n\trv = bmc->dyn_guid_set && guid_equal(&bmc->guid, guid);\n\tif (rv)\n\t\trv = kref_get_unless_zero(&bmc->usecount);\n\treturn rv;\n}\n\n/*\n * Returns with the bmc's usecount incremented, if it is non-NULL.\n */\nstatic struct bmc_device *ipmi_find_bmc_guid(struct device_driver *drv,\n\t\t\t\t\t     guid_t *guid)\n{\n\tstruct device *dev;\n\tstruct bmc_device *bmc = NULL;\n\n\tdev = driver_find_device(drv, NULL, guid, __find_bmc_guid);\n\tif (dev) {\n\t\tbmc = to_bmc_device(dev);\n\t\tput_device(dev);\n\t}\n\treturn bmc;\n}\n\nstruct prod_dev_id {\n\tunsigned int  product_id;\n\tunsigned char device_id;\n};\n\nstatic int __find_bmc_prod_dev_id(struct device *dev, const void *data)\n{\n\tconst struct prod_dev_id *cid = data;\n\tstruct bmc_device *bmc;\n\tint rv;\n\n\tif (dev->type != &bmc_device_type)\n\t\treturn 0;\n\n\tbmc = to_bmc_device(dev);\n\trv = (bmc->id.product_id == cid->product_id\n\t      && bmc->id.device_id == cid->device_id);\n\tif (rv)\n\t\trv = kref_get_unless_zero(&bmc->usecount);\n\treturn rv;\n}\n\n/*\n * Returns with the bmc's usecount incremented, if it is non-NULL.\n */\nstatic struct bmc_device *ipmi_find_bmc_prod_dev_id(\n\tstruct device_driver *drv,\n\tunsigned int product_id, unsigned char device_id)\n{\n\tstruct prod_dev_id id = {\n\t\t.product_id = product_id,\n\t\t.device_id = device_id,\n\t};\n\tstruct device *dev;\n\tstruct bmc_device *bmc = NULL;\n\n\tdev = driver_find_device(drv, NULL, &id, __find_bmc_prod_dev_id);\n\tif (dev) {\n\t\tbmc = to_bmc_device(dev);\n\t\tput_device(dev);\n\t}\n\treturn bmc;\n}\n\nstatic DEFINE_IDA(ipmi_bmc_ida);\n\nstatic void\nrelease_bmc_device(struct device *dev)\n{\n\tkfree(to_bmc_device(dev));\n}\n\nstatic void cleanup_bmc_work(struct work_struct *work)\n{\n\tstruct bmc_device *bmc = container_of(work, struct bmc_device,\n\t\t\t\t\t      remove_work);\n\tint id = bmc->pdev.id; /* Unregister overwrites id */\n\n\tplatform_device_unregister(&bmc->pdev);\n\tida_simple_remove(&ipmi_bmc_ida, id);\n}\n\nstatic void\ncleanup_bmc_device(struct kref *ref)\n{\n\tstruct bmc_device *bmc = container_of(ref, struct bmc_device, usecount);\n\n\t/*\n\t * Remove the platform device in a work queue to avoid issues\n\t * with removing the device attributes while reading a device\n\t * attribute.\n\t */\n\tschedule_work(&bmc->remove_work);\n}\n\n/*\n * Must be called with intf->bmc_reg_mutex held.\n */\nstatic void __ipmi_bmc_unregister(struct ipmi_smi *intf)\n{\n\tstruct bmc_device *bmc = intf->bmc;\n\n\tif (!intf->bmc_registered)\n\t\treturn;\n\n\tsysfs_remove_link(&intf->si_dev->kobj, \"bmc\");\n\tsysfs_remove_link(&bmc->pdev.dev.kobj, intf->my_dev_name);\n\tkfree(intf->my_dev_name);\n\tintf->my_dev_name = NULL;\n\n\tmutex_lock(&bmc->dyn_mutex);\n\tlist_del(&intf->bmc_link);\n\tmutex_unlock(&bmc->dyn_mutex);\n\tintf->bmc = &intf->tmp_bmc;\n\tkref_put(&bmc->usecount, cleanup_bmc_device);\n\tintf->bmc_registered = false;\n}\n\nstatic void ipmi_bmc_unregister(struct ipmi_smi *intf)\n{\n\tmutex_lock(&intf->bmc_reg_mutex);\n\t__ipmi_bmc_unregister(intf);\n\tmutex_unlock(&intf->bmc_reg_mutex);\n}\n\n/*\n * Must be called with intf->bmc_reg_mutex held.\n */\nstatic int __ipmi_bmc_register(struct ipmi_smi *intf,\n\t\t\t       struct ipmi_device_id *id,\n\t\t\t       bool guid_set, guid_t *guid, int intf_num)\n{\n\tint               rv;\n\tstruct bmc_device *bmc;\n\tstruct bmc_device *old_bmc;\n\n\t/*\n\t * platform_device_register() can cause bmc_reg_mutex to\n\t * be claimed because of the is_visible functions of\n\t * the attributes.  Eliminate possible recursion and\n\t * release the lock.\n\t */\n\tintf->in_bmc_register = true;\n\tmutex_unlock(&intf->bmc_reg_mutex);\n\n\t/*\n\t * Try to find if there is an bmc_device struct\n\t * representing the interfaced BMC already\n\t */\n\tmutex_lock(&ipmidriver_mutex);\n\tif (guid_set)\n\t\told_bmc = ipmi_find_bmc_guid(&ipmidriver.driver, guid);\n\telse\n\t\told_bmc = ipmi_find_bmc_prod_dev_id(&ipmidriver.driver,\n\t\t\t\t\t\t    id->product_id,\n\t\t\t\t\t\t    id->device_id);\n\n\t/*\n\t * If there is already an bmc_device, free the new one,\n\t * otherwise register the new BMC device\n\t */\n\tif (old_bmc) {\n\t\tbmc = old_bmc;\n\t\t/*\n\t\t * Note: old_bmc already has usecount incremented by\n\t\t * the BMC find functions.\n\t\t */\n\t\tintf->bmc = old_bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tlist_add_tail(&intf->bmc_link, &bmc->intfs);\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\n\t\tdev_info(intf->si_dev,\n\t\t\t \"interfacing existing BMC (man_id: 0x%6.6x, prod_id: 0x%4.4x, dev_id: 0x%2.2x)\\n\",\n\t\t\t bmc->id.manufacturer_id,\n\t\t\t bmc->id.product_id,\n\t\t\t bmc->id.device_id);\n\t} else {\n\t\tbmc = kzalloc(sizeof(*bmc), GFP_KERNEL);\n\t\tif (!bmc) {\n\t\t\trv = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tINIT_LIST_HEAD(&bmc->intfs);\n\t\tmutex_init(&bmc->dyn_mutex);\n\t\tINIT_WORK(&bmc->remove_work, cleanup_bmc_work);\n\n\t\tbmc->id = *id;\n\t\tbmc->dyn_id_set = 1;\n\t\tbmc->dyn_guid_set = guid_set;\n\t\tbmc->guid = *guid;\n\t\tbmc->dyn_id_expiry = jiffies + IPMI_DYN_DEV_ID_EXPIRY;\n\n\t\tbmc->pdev.name = \"ipmi_bmc\";\n\n\t\trv = ida_simple_get(&ipmi_bmc_ida, 0, 0, GFP_KERNEL);\n\t\tif (rv < 0)\n\t\t\tgoto out;\n\t\tbmc->pdev.dev.driver = &ipmidriver.driver;\n\t\tbmc->pdev.id = rv;\n\t\tbmc->pdev.dev.release = release_bmc_device;\n\t\tbmc->pdev.dev.type = &bmc_device_type;\n\t\tkref_init(&bmc->usecount);\n\n\t\tintf->bmc = bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tlist_add_tail(&intf->bmc_link, &bmc->intfs);\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\n\t\trv = platform_device_register(&bmc->pdev);\n\t\tif (rv) {\n\t\t\tdev_err(intf->si_dev,\n\t\t\t\t\"Unable to register bmc device: %d\\n\",\n\t\t\t\trv);\n\t\t\tgoto out_list_del;\n\t\t}\n\n\t\tdev_info(intf->si_dev,\n\t\t\t \"Found new BMC (man_id: 0x%6.6x, prod_id: 0x%4.4x, dev_id: 0x%2.2x)\\n\",\n\t\t\t bmc->id.manufacturer_id,\n\t\t\t bmc->id.product_id,\n\t\t\t bmc->id.device_id);\n\t}\n\n\t/*\n\t * create symlink from system interface device to bmc device\n\t * and back.\n\t */\n\trv = sysfs_create_link(&intf->si_dev->kobj, &bmc->pdev.dev.kobj, \"bmc\");\n\tif (rv) {\n\t\tdev_err(intf->si_dev, \"Unable to create bmc symlink: %d\\n\", rv);\n\t\tgoto out_put_bmc;\n\t}\n\n\tif (intf_num == -1)\n\t\tintf_num = intf->intf_num;\n\tintf->my_dev_name = kasprintf(GFP_KERNEL, \"ipmi%d\", intf_num);\n\tif (!intf->my_dev_name) {\n\t\trv = -ENOMEM;\n\t\tdev_err(intf->si_dev, \"Unable to allocate link from BMC: %d\\n\",\n\t\t\trv);\n\t\tgoto out_unlink1;\n\t}\n\n\trv = sysfs_create_link(&bmc->pdev.dev.kobj, &intf->si_dev->kobj,\n\t\t\t       intf->my_dev_name);\n\tif (rv) {\n\t\tkfree(intf->my_dev_name);\n\t\tintf->my_dev_name = NULL;\n\t\tdev_err(intf->si_dev, \"Unable to create symlink to bmc: %d\\n\",\n\t\t\trv);\n\t\tgoto out_free_my_dev_name;\n\t}\n\n\tintf->bmc_registered = true;\n\nout:\n\tmutex_unlock(&ipmidriver_mutex);\n\tmutex_lock(&intf->bmc_reg_mutex);\n\tintf->in_bmc_register = false;\n\treturn rv;\n\n\nout_free_my_dev_name:\n\tkfree(intf->my_dev_name);\n\tintf->my_dev_name = NULL;\n\nout_unlink1:\n\tsysfs_remove_link(&intf->si_dev->kobj, \"bmc\");\n\nout_put_bmc:\n\tmutex_lock(&bmc->dyn_mutex);\n\tlist_del(&intf->bmc_link);\n\tmutex_unlock(&bmc->dyn_mutex);\n\tintf->bmc = &intf->tmp_bmc;\n\tkref_put(&bmc->usecount, cleanup_bmc_device);\n\tgoto out;\n\nout_list_del:\n\tmutex_lock(&bmc->dyn_mutex);\n\tlist_del(&intf->bmc_link);\n\tmutex_unlock(&bmc->dyn_mutex);\n\tintf->bmc = &intf->tmp_bmc;\n\tput_device(&bmc->pdev.dev);\n\tgoto out;\n}\n\nstatic int\nsend_guid_cmd(struct ipmi_smi *intf, int chan)\n{\n\tstruct kernel_ipmi_msg            msg;\n\tstruct ipmi_system_interface_addr si;\n\n\tsi.addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsi.channel = IPMI_BMC_CHANNEL;\n\tsi.lun = 0;\n\n\tmsg.netfn = IPMI_NETFN_APP_REQUEST;\n\tmsg.cmd = IPMI_GET_DEVICE_GUID_CMD;\n\tmsg.data = NULL;\n\tmsg.data_len = 0;\n\treturn i_ipmi_request(NULL,\n\t\t\t      intf,\n\t\t\t      (struct ipmi_addr *) &si,\n\t\t\t      0,\n\t\t\t      &msg,\n\t\t\t      intf,\n\t\t\t      NULL,\n\t\t\t      NULL,\n\t\t\t      0,\n\t\t\t      intf->addrinfo[0].address,\n\t\t\t      intf->addrinfo[0].lun,\n\t\t\t      -1, 0);\n}\n\nstatic void guid_handler(struct ipmi_smi *intf, struct ipmi_recv_msg *msg)\n{\n\tstruct bmc_device *bmc = intf->bmc;\n\n\tif ((msg->addr.addr_type != IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t    || (msg->msg.netfn != IPMI_NETFN_APP_RESPONSE)\n\t    || (msg->msg.cmd != IPMI_GET_DEVICE_GUID_CMD))\n\t\t/* Not for me */\n\t\treturn;\n\n\tif (msg->msg.data[0] != 0) {\n\t\t/* Error from getting the GUID, the BMC doesn't have one. */\n\t\tbmc->dyn_guid_set = 0;\n\t\tgoto out;\n\t}\n\n\tif (msg->msg.data_len < UUID_SIZE + 1) {\n\t\tbmc->dyn_guid_set = 0;\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"The GUID response from the BMC was too short, it was %d but should have been %d.  Assuming GUID is not available.\\n\",\n\t\t\t msg->msg.data_len, UUID_SIZE + 1);\n\t\tgoto out;\n\t}\n\n\tguid_copy(&bmc->fetch_guid, (guid_t *)(msg->msg.data + 1));\n\t/*\n\t * Make sure the guid data is available before setting\n\t * dyn_guid_set.\n\t */\n\tsmp_wmb();\n\tbmc->dyn_guid_set = 1;\n out:\n\twake_up(&intf->waitq);\n}\n\nstatic void __get_guid(struct ipmi_smi *intf)\n{\n\tint rv;\n\tstruct bmc_device *bmc = intf->bmc;\n\n\tbmc->dyn_guid_set = 2;\n\tintf->null_user_handler = guid_handler;\n\trv = send_guid_cmd(intf, 0);\n\tif (rv)\n\t\t/* Send failed, no GUID available. */\n\t\tbmc->dyn_guid_set = 0;\n\n\twait_event(intf->waitq, bmc->dyn_guid_set != 2);\n\n\t/* dyn_guid_set makes the guid data available. */\n\tsmp_rmb();\n\n\tintf->null_user_handler = NULL;\n}\n\nstatic int\nsend_channel_info_cmd(struct ipmi_smi *intf, int chan)\n{\n\tstruct kernel_ipmi_msg            msg;\n\tunsigned char                     data[1];\n\tstruct ipmi_system_interface_addr si;\n\n\tsi.addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsi.channel = IPMI_BMC_CHANNEL;\n\tsi.lun = 0;\n\n\tmsg.netfn = IPMI_NETFN_APP_REQUEST;\n\tmsg.cmd = IPMI_GET_CHANNEL_INFO_CMD;\n\tmsg.data = data;\n\tmsg.data_len = 1;\n\tdata[0] = chan;\n\treturn i_ipmi_request(NULL,\n\t\t\t      intf,\n\t\t\t      (struct ipmi_addr *) &si,\n\t\t\t      0,\n\t\t\t      &msg,\n\t\t\t      intf,\n\t\t\t      NULL,\n\t\t\t      NULL,\n\t\t\t      0,\n\t\t\t      intf->addrinfo[0].address,\n\t\t\t      intf->addrinfo[0].lun,\n\t\t\t      -1, 0);\n}\n\nstatic void\nchannel_handler(struct ipmi_smi *intf, struct ipmi_recv_msg *msg)\n{\n\tint rv = 0;\n\tint ch;\n\tunsigned int set = intf->curr_working_cset;\n\tstruct ipmi_channel *chans;\n\n\tif ((msg->addr.addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t    && (msg->msg.netfn == IPMI_NETFN_APP_RESPONSE)\n\t    && (msg->msg.cmd == IPMI_GET_CHANNEL_INFO_CMD)) {\n\t\t/* It's the one we want */\n\t\tif (msg->msg.data[0] != 0) {\n\t\t\t/* Got an error from the channel, just go on. */\n\n\t\t\tif (msg->msg.data[0] == IPMI_INVALID_COMMAND_ERR) {\n\t\t\t\t/*\n\t\t\t\t * If the MC does not support this\n\t\t\t\t * command, that is legal.  We just\n\t\t\t\t * assume it has one IPMB at channel\n\t\t\t\t * zero.\n\t\t\t\t */\n\t\t\t\tintf->wchannels[set].c[0].medium\n\t\t\t\t\t= IPMI_CHANNEL_MEDIUM_IPMB;\n\t\t\t\tintf->wchannels[set].c[0].protocol\n\t\t\t\t\t= IPMI_CHANNEL_PROTOCOL_IPMB;\n\n\t\t\t\tintf->channel_list = intf->wchannels + set;\n\t\t\t\tintf->channels_ready = true;\n\t\t\t\twake_up(&intf->waitq);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tgoto next_channel;\n\t\t}\n\t\tif (msg->msg.data_len < 4) {\n\t\t\t/* Message not big enough, just go on. */\n\t\t\tgoto next_channel;\n\t\t}\n\t\tch = intf->curr_channel;\n\t\tchans = intf->wchannels[set].c;\n\t\tchans[ch].medium = msg->msg.data[2] & 0x7f;\n\t\tchans[ch].protocol = msg->msg.data[3] & 0x1f;\n\n next_channel:\n\t\tintf->curr_channel++;\n\t\tif (intf->curr_channel >= IPMI_MAX_CHANNELS) {\n\t\t\tintf->channel_list = intf->wchannels + set;\n\t\t\tintf->channels_ready = true;\n\t\t\twake_up(&intf->waitq);\n\t\t} else {\n\t\t\tintf->channel_list = intf->wchannels + set;\n\t\t\tintf->channels_ready = true;\n\t\t\trv = send_channel_info_cmd(intf, intf->curr_channel);\n\t\t}\n\n\t\tif (rv) {\n\t\t\t/* Got an error somehow, just give up. */\n\t\t\tdev_warn(intf->si_dev,\n\t\t\t\t \"Error sending channel information for channel %d: %d\\n\",\n\t\t\t\t intf->curr_channel, rv);\n\n\t\t\tintf->channel_list = intf->wchannels + set;\n\t\t\tintf->channels_ready = true;\n\t\t\twake_up(&intf->waitq);\n\t\t}\n\t}\n out:\n\treturn;\n}\n\n/*\n * Must be holding intf->bmc_reg_mutex to call this.\n */\nstatic int __scan_channels(struct ipmi_smi *intf, struct ipmi_device_id *id)\n{\n\tint rv;\n\n\tif (ipmi_version_major(id) > 1\n\t\t\t|| (ipmi_version_major(id) == 1\n\t\t\t    && ipmi_version_minor(id) >= 5)) {\n\t\tunsigned int set;\n\n\t\t/*\n\t\t * Start scanning the channels to see what is\n\t\t * available.\n\t\t */\n\t\tset = !intf->curr_working_cset;\n\t\tintf->curr_working_cset = set;\n\t\tmemset(&intf->wchannels[set], 0,\n\t\t       sizeof(struct ipmi_channel_set));\n\n\t\tintf->null_user_handler = channel_handler;\n\t\tintf->curr_channel = 0;\n\t\trv = send_channel_info_cmd(intf, 0);\n\t\tif (rv) {\n\t\t\tdev_warn(intf->si_dev,\n\t\t\t\t \"Error sending channel information for channel 0, %d\\n\",\n\t\t\t\t rv);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\t/* Wait for the channel info to be read. */\n\t\twait_event(intf->waitq, intf->channels_ready);\n\t\tintf->null_user_handler = NULL;\n\t} else {\n\t\tunsigned int set = intf->curr_working_cset;\n\n\t\t/* Assume a single IPMB channel at zero. */\n\t\tintf->wchannels[set].c[0].medium = IPMI_CHANNEL_MEDIUM_IPMB;\n\t\tintf->wchannels[set].c[0].protocol = IPMI_CHANNEL_PROTOCOL_IPMB;\n\t\tintf->channel_list = intf->wchannels + set;\n\t\tintf->channels_ready = true;\n\t}\n\n\treturn 0;\n}\n\nstatic void ipmi_poll(struct ipmi_smi *intf)\n{\n\tif (intf->handlers->poll)\n\t\tintf->handlers->poll(intf->send_info);\n\t/* In case something came in */\n\thandle_new_recv_msgs(intf);\n}\n\nvoid ipmi_poll_interface(struct ipmi_user *user)\n{\n\tipmi_poll(user->intf);\n}\nEXPORT_SYMBOL(ipmi_poll_interface);\n\nstatic void redo_bmc_reg(struct work_struct *work)\n{\n\tstruct ipmi_smi *intf = container_of(work, struct ipmi_smi,\n\t\t\t\t\t     bmc_reg_work);\n\n\tif (!intf->in_shutdown)\n\t\tbmc_get_device_id(intf, NULL, NULL, NULL, NULL);\n\n\tkref_put(&intf->refcount, intf_free);\n}\n\nint ipmi_add_smi(struct module         *owner,\n\t\t const struct ipmi_smi_handlers *handlers,\n\t\t void\t\t       *send_info,\n\t\t struct device         *si_dev,\n\t\t unsigned char         slave_addr)\n{\n\tint              i, j;\n\tint              rv;\n\tstruct ipmi_smi *intf, *tintf;\n\tstruct list_head *link;\n\tstruct ipmi_device_id id;\n\n\t/*\n\t * Make sure the driver is actually initialized, this handles\n\t * problems with initialization order.\n\t */\n\trv = ipmi_init_msghandler();\n\tif (rv)\n\t\treturn rv;\n\n\tintf = kzalloc(sizeof(*intf), GFP_KERNEL);\n\tif (!intf)\n\t\treturn -ENOMEM;\n\n\trv = init_srcu_struct(&intf->users_srcu);\n\tif (rv) {\n\t\tkfree(intf);\n\t\treturn rv;\n\t}\n\n\tintf->owner = owner;\n\tintf->bmc = &intf->tmp_bmc;\n\tINIT_LIST_HEAD(&intf->bmc->intfs);\n\tmutex_init(&intf->bmc->dyn_mutex);\n\tINIT_LIST_HEAD(&intf->bmc_link);\n\tmutex_init(&intf->bmc_reg_mutex);\n\tintf->intf_num = -1; /* Mark it invalid for now. */\n\tkref_init(&intf->refcount);\n\tINIT_WORK(&intf->bmc_reg_work, redo_bmc_reg);\n\tintf->si_dev = si_dev;\n\tfor (j = 0; j < IPMI_MAX_CHANNELS; j++) {\n\t\tintf->addrinfo[j].address = IPMI_BMC_SLAVE_ADDR;\n\t\tintf->addrinfo[j].lun = 2;\n\t}\n\tif (slave_addr != 0)\n\t\tintf->addrinfo[0].address = slave_addr;\n\tINIT_LIST_HEAD(&intf->users);\n\tintf->handlers = handlers;\n\tintf->send_info = send_info;\n\tspin_lock_init(&intf->seq_lock);\n\tfor (j = 0; j < IPMI_IPMB_NUM_SEQ; j++) {\n\t\tintf->seq_table[j].inuse = 0;\n\t\tintf->seq_table[j].seqid = 0;\n\t}\n\tintf->curr_seq = 0;\n\tspin_lock_init(&intf->waiting_rcv_msgs_lock);\n\tINIT_LIST_HEAD(&intf->waiting_rcv_msgs);\n\ttasklet_init(&intf->recv_tasklet,\n\t\t     smi_recv_tasklet,\n\t\t     (unsigned long) intf);\n\tatomic_set(&intf->watchdog_pretimeouts_to_deliver, 0);\n\tspin_lock_init(&intf->xmit_msgs_lock);\n\tINIT_LIST_HEAD(&intf->xmit_msgs);\n\tINIT_LIST_HEAD(&intf->hp_xmit_msgs);\n\tspin_lock_init(&intf->events_lock);\n\tspin_lock_init(&intf->watch_lock);\n\tatomic_set(&intf->event_waiters, 0);\n\tintf->ticks_to_req_ev = IPMI_REQUEST_EV_TIME;\n\tINIT_LIST_HEAD(&intf->waiting_events);\n\tintf->waiting_events_count = 0;\n\tmutex_init(&intf->cmd_rcvrs_mutex);\n\tspin_lock_init(&intf->maintenance_mode_lock);\n\tINIT_LIST_HEAD(&intf->cmd_rcvrs);\n\tinit_waitqueue_head(&intf->waitq);\n\tfor (i = 0; i < IPMI_NUM_STATS; i++)\n\t\tatomic_set(&intf->stats[i], 0);\n\n\tmutex_lock(&ipmi_interfaces_mutex);\n\t/* Look for a hole in the numbers. */\n\ti = 0;\n\tlink = &ipmi_interfaces;\n\tlist_for_each_entry_rcu(tintf, &ipmi_interfaces, link) {\n\t\tif (tintf->intf_num != i) {\n\t\t\tlink = &tintf->link;\n\t\t\tbreak;\n\t\t}\n\t\ti++;\n\t}\n\t/* Add the new interface in numeric order. */\n\tif (i == 0)\n\t\tlist_add_rcu(&intf->link, &ipmi_interfaces);\n\telse\n\t\tlist_add_tail_rcu(&intf->link, link);\n\n\trv = handlers->start_processing(send_info, intf);\n\tif (rv)\n\t\tgoto out_err;\n\n\trv = __bmc_get_device_id(intf, NULL, &id, NULL, NULL, i);\n\tif (rv) {\n\t\tdev_err(si_dev, \"Unable to get the device id: %d\\n\", rv);\n\t\tgoto out_err_started;\n\t}\n\n\tmutex_lock(&intf->bmc_reg_mutex);\n\trv = __scan_channels(intf, &id);\n\tmutex_unlock(&intf->bmc_reg_mutex);\n\tif (rv)\n\t\tgoto out_err_bmc_reg;\n\n\t/*\n\t * Keep memory order straight for RCU readers.  Make\n\t * sure everything else is committed to memory before\n\t * setting intf_num to mark the interface valid.\n\t */\n\tsmp_wmb();\n\tintf->intf_num = i;\n\tmutex_unlock(&ipmi_interfaces_mutex);\n\n\t/* After this point the interface is legal to use. */\n\tcall_smi_watchers(i, intf->si_dev);\n\n\treturn 0;\n\n out_err_bmc_reg:\n\tipmi_bmc_unregister(intf);\n out_err_started:\n\tif (intf->handlers->shutdown)\n\t\tintf->handlers->shutdown(intf->send_info);\n out_err:\n\tlist_del_rcu(&intf->link);\n\tmutex_unlock(&ipmi_interfaces_mutex);\n\tsynchronize_srcu(&ipmi_interfaces_srcu);\n\tcleanup_srcu_struct(&intf->users_srcu);\n\tkref_put(&intf->refcount, intf_free);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_add_smi);\n\nstatic void deliver_smi_err_response(struct ipmi_smi *intf,\n\t\t\t\t     struct ipmi_smi_msg *msg,\n\t\t\t\t     unsigned char err)\n{\n\tmsg->rsp[0] = msg->data[0] | 4;\n\tmsg->rsp[1] = msg->data[1];\n\tmsg->rsp[2] = err;\n\tmsg->rsp_size = 3;\n\t/* It's an error, so it will never requeue, no need to check return. */\n\thandle_one_recv_msg(intf, msg);\n}\n\nstatic void cleanup_smi_msgs(struct ipmi_smi *intf)\n{\n\tint              i;\n\tstruct seq_table *ent;\n\tstruct ipmi_smi_msg *msg;\n\tstruct list_head *entry;\n\tstruct list_head tmplist;\n\n\t/* Clear out our transmit queues and hold the messages. */\n\tINIT_LIST_HEAD(&tmplist);\n\tlist_splice_tail(&intf->hp_xmit_msgs, &tmplist);\n\tlist_splice_tail(&intf->xmit_msgs, &tmplist);\n\n\t/* Current message first, to preserve order */\n\twhile (intf->curr_msg && !list_empty(&intf->waiting_rcv_msgs)) {\n\t\t/* Wait for the message to clear out. */\n\t\tschedule_timeout(1);\n\t}\n\n\t/* No need for locks, the interface is down. */\n\n\t/*\n\t * Return errors for all pending messages in queue and in the\n\t * tables waiting for remote responses.\n\t */\n\twhile (!list_empty(&tmplist)) {\n\t\tentry = tmplist.next;\n\t\tlist_del(entry);\n\t\tmsg = list_entry(entry, struct ipmi_smi_msg, link);\n\t\tdeliver_smi_err_response(intf, msg, IPMI_ERR_UNSPECIFIED);\n\t}\n\n\tfor (i = 0; i < IPMI_IPMB_NUM_SEQ; i++) {\n\t\tent = &intf->seq_table[i];\n\t\tif (!ent->inuse)\n\t\t\tcontinue;\n\t\tdeliver_err_response(intf, ent->recv_msg, IPMI_ERR_UNSPECIFIED);\n\t}\n}\n\nvoid ipmi_unregister_smi(struct ipmi_smi *intf)\n{\n\tstruct ipmi_smi_watcher *w;\n\tint intf_num = intf->intf_num, index;\n\n\tmutex_lock(&ipmi_interfaces_mutex);\n\tintf->intf_num = -1;\n\tintf->in_shutdown = true;\n\tlist_del_rcu(&intf->link);\n\tmutex_unlock(&ipmi_interfaces_mutex);\n\tsynchronize_srcu(&ipmi_interfaces_srcu);\n\n\t/* At this point no users can be added to the interface. */\n\n\t/*\n\t * Call all the watcher interfaces to tell them that\n\t * an interface is going away.\n\t */\n\tmutex_lock(&smi_watchers_mutex);\n\tlist_for_each_entry(w, &smi_watchers, link)\n\t\tw->smi_gone(intf_num);\n\tmutex_unlock(&smi_watchers_mutex);\n\n\tindex = srcu_read_lock(&intf->users_srcu);\n\twhile (!list_empty(&intf->users)) {\n\t\tstruct ipmi_user *user =\n\t\t\tcontainer_of(list_next_rcu(&intf->users),\n\t\t\t\t     struct ipmi_user, link);\n\n\t\t_ipmi_destroy_user(user);\n\t}\n\tsrcu_read_unlock(&intf->users_srcu, index);\n\n\tif (intf->handlers->shutdown)\n\t\tintf->handlers->shutdown(intf->send_info);\n\n\tcleanup_smi_msgs(intf);\n\n\tipmi_bmc_unregister(intf);\n\n\tcleanup_srcu_struct(&intf->users_srcu);\n\tkref_put(&intf->refcount, intf_free);\n}\nEXPORT_SYMBOL(ipmi_unregister_smi);\n\nstatic int handle_ipmb_get_msg_rsp(struct ipmi_smi *intf,\n\t\t\t\t   struct ipmi_smi_msg *msg)\n{\n\tstruct ipmi_ipmb_addr ipmb_addr;\n\tstruct ipmi_recv_msg  *recv_msg;\n\n\t/*\n\t * This is 11, not 10, because the response must contain a\n\t * completion code.\n\t */\n\tif (msg->rsp_size < 11) {\n\t\t/* Message not big enough, just ignore it. */\n\t\tipmi_inc_stat(intf, invalid_ipmb_responses);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the response, just ignore it. */\n\t\treturn 0;\n\t}\n\n\tipmb_addr.addr_type = IPMI_IPMB_ADDR_TYPE;\n\tipmb_addr.slave_addr = msg->rsp[6];\n\tipmb_addr.channel = msg->rsp[3] & 0x0f;\n\tipmb_addr.lun = msg->rsp[7] & 3;\n\n\t/*\n\t * It's a response from a remote entity.  Look up the sequence\n\t * number and handle the response.\n\t */\n\tif (intf_find_seq(intf,\n\t\t\t  msg->rsp[7] >> 2,\n\t\t\t  msg->rsp[3] & 0x0f,\n\t\t\t  msg->rsp[8],\n\t\t\t  (msg->rsp[4] >> 2) & (~1),\n\t\t\t  (struct ipmi_addr *) &ipmb_addr,\n\t\t\t  &recv_msg)) {\n\t\t/*\n\t\t * We were unable to find the sequence number,\n\t\t * so just nuke the message.\n\t\t */\n\t\tipmi_inc_stat(intf, unhandled_ipmb_responses);\n\t\treturn 0;\n\t}\n\n\tmemcpy(recv_msg->msg_data, &msg->rsp[9], msg->rsp_size - 9);\n\t/*\n\t * The other fields matched, so no need to set them, except\n\t * for netfn, which needs to be the response that was\n\t * returned, not the request value.\n\t */\n\trecv_msg->msg.netfn = msg->rsp[4] >> 2;\n\trecv_msg->msg.data = recv_msg->msg_data;\n\trecv_msg->msg.data_len = msg->rsp_size - 10;\n\trecv_msg->recv_type = IPMI_RESPONSE_RECV_TYPE;\n\tif (deliver_response(intf, recv_msg))\n\t\tipmi_inc_stat(intf, unhandled_ipmb_responses);\n\telse\n\t\tipmi_inc_stat(intf, handled_ipmb_responses);\n\n\treturn 0;\n}\n\nstatic int handle_ipmb_get_msg_cmd(struct ipmi_smi *intf,\n\t\t\t\t   struct ipmi_smi_msg *msg)\n{\n\tstruct cmd_rcvr          *rcvr;\n\tint                      rv = 0;\n\tunsigned char            netfn;\n\tunsigned char            cmd;\n\tunsigned char            chan;\n\tstruct ipmi_user         *user = NULL;\n\tstruct ipmi_ipmb_addr    *ipmb_addr;\n\tstruct ipmi_recv_msg     *recv_msg;\n\n\tif (msg->rsp_size < 10) {\n\t\t/* Message not big enough, just ignore it. */\n\t\tipmi_inc_stat(intf, invalid_commands);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the response, just ignore it. */\n\t\treturn 0;\n\t}\n\n\tnetfn = msg->rsp[4] >> 2;\n\tcmd = msg->rsp[8];\n\tchan = msg->rsp[3] & 0xf;\n\n\trcu_read_lock();\n\trcvr = find_cmd_rcvr(intf, netfn, cmd, chan);\n\tif (rcvr) {\n\t\tuser = rcvr->user;\n\t\tkref_get(&user->refcount);\n\t} else\n\t\tuser = NULL;\n\trcu_read_unlock();\n\n\tif (user == NULL) {\n\t\t/* We didn't find a user, deliver an error response. */\n\t\tipmi_inc_stat(intf, unhandled_commands);\n\n\t\tmsg->data[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\t\tmsg->data[1] = IPMI_SEND_MSG_CMD;\n\t\tmsg->data[2] = msg->rsp[3];\n\t\tmsg->data[3] = msg->rsp[6];\n\t\tmsg->data[4] = ((netfn + 1) << 2) | (msg->rsp[7] & 0x3);\n\t\tmsg->data[5] = ipmb_checksum(&msg->data[3], 2);\n\t\tmsg->data[6] = intf->addrinfo[msg->rsp[3] & 0xf].address;\n\t\t/* rqseq/lun */\n\t\tmsg->data[7] = (msg->rsp[7] & 0xfc) | (msg->rsp[4] & 0x3);\n\t\tmsg->data[8] = msg->rsp[8]; /* cmd */\n\t\tmsg->data[9] = IPMI_INVALID_CMD_COMPLETION_CODE;\n\t\tmsg->data[10] = ipmb_checksum(&msg->data[6], 4);\n\t\tmsg->data_size = 11;\n\n\t\tpr_debug(\"Invalid command: %*ph\\n\", msg->data_size, msg->data);\n\n\t\trcu_read_lock();\n\t\tif (!intf->in_shutdown) {\n\t\t\tsmi_send(intf, intf->handlers, msg, 0);\n\t\t\t/*\n\t\t\t * We used the message, so return the value\n\t\t\t * that causes it to not be freed or\n\t\t\t * queued.\n\t\t\t */\n\t\t\trv = -1;\n\t\t}\n\t\trcu_read_unlock();\n\t} else {\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (!recv_msg) {\n\t\t\t/*\n\t\t\t * We couldn't allocate memory for the\n\t\t\t * message, so requeue it for handling\n\t\t\t * later.\n\t\t\t */\n\t\t\trv = 1;\n\t\t\tkref_put(&user->refcount, free_user);\n\t\t} else {\n\t\t\t/* Extract the source address from the data. */\n\t\t\tipmb_addr = (struct ipmi_ipmb_addr *) &recv_msg->addr;\n\t\t\tipmb_addr->addr_type = IPMI_IPMB_ADDR_TYPE;\n\t\t\tipmb_addr->slave_addr = msg->rsp[6];\n\t\t\tipmb_addr->lun = msg->rsp[7] & 3;\n\t\t\tipmb_addr->channel = msg->rsp[3] & 0xf;\n\n\t\t\t/*\n\t\t\t * Extract the rest of the message information\n\t\t\t * from the IPMB header.\n\t\t\t */\n\t\t\trecv_msg->user = user;\n\t\t\trecv_msg->recv_type = IPMI_CMD_RECV_TYPE;\n\t\t\trecv_msg->msgid = msg->rsp[7] >> 2;\n\t\t\trecv_msg->msg.netfn = msg->rsp[4] >> 2;\n\t\t\trecv_msg->msg.cmd = msg->rsp[8];\n\t\t\trecv_msg->msg.data = recv_msg->msg_data;\n\n\t\t\t/*\n\t\t\t * We chop off 10, not 9 bytes because the checksum\n\t\t\t * at the end also needs to be removed.\n\t\t\t */\n\t\t\trecv_msg->msg.data_len = msg->rsp_size - 10;\n\t\t\tmemcpy(recv_msg->msg_data, &msg->rsp[9],\n\t\t\t       msg->rsp_size - 10);\n\t\t\tif (deliver_response(intf, recv_msg))\n\t\t\t\tipmi_inc_stat(intf, unhandled_commands);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf, handled_commands);\n\t\t}\n\t}\n\n\treturn rv;\n}\n\nstatic int handle_lan_get_msg_rsp(struct ipmi_smi *intf,\n\t\t\t\t  struct ipmi_smi_msg *msg)\n{\n\tstruct ipmi_lan_addr  lan_addr;\n\tstruct ipmi_recv_msg  *recv_msg;\n\n\n\t/*\n\t * This is 13, not 12, because the response must contain a\n\t * completion code.\n\t */\n\tif (msg->rsp_size < 13) {\n\t\t/* Message not big enough, just ignore it. */\n\t\tipmi_inc_stat(intf, invalid_lan_responses);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the response, just ignore it. */\n\t\treturn 0;\n\t}\n\n\tlan_addr.addr_type = IPMI_LAN_ADDR_TYPE;\n\tlan_addr.session_handle = msg->rsp[4];\n\tlan_addr.remote_SWID = msg->rsp[8];\n\tlan_addr.local_SWID = msg->rsp[5];\n\tlan_addr.channel = msg->rsp[3] & 0x0f;\n\tlan_addr.privilege = msg->rsp[3] >> 4;\n\tlan_addr.lun = msg->rsp[9] & 3;\n\n\t/*\n\t * It's a response from a remote entity.  Look up the sequence\n\t * number and handle the response.\n\t */\n\tif (intf_find_seq(intf,\n\t\t\t  msg->rsp[9] >> 2,\n\t\t\t  msg->rsp[3] & 0x0f,\n\t\t\t  msg->rsp[10],\n\t\t\t  (msg->rsp[6] >> 2) & (~1),\n\t\t\t  (struct ipmi_addr *) &lan_addr,\n\t\t\t  &recv_msg)) {\n\t\t/*\n\t\t * We were unable to find the sequence number,\n\t\t * so just nuke the message.\n\t\t */\n\t\tipmi_inc_stat(intf, unhandled_lan_responses);\n\t\treturn 0;\n\t}\n\n\tmemcpy(recv_msg->msg_data, &msg->rsp[11], msg->rsp_size - 11);\n\t/*\n\t * The other fields matched, so no need to set them, except\n\t * for netfn, which needs to be the response that was\n\t * returned, not the request value.\n\t */\n\trecv_msg->msg.netfn = msg->rsp[6] >> 2;\n\trecv_msg->msg.data = recv_msg->msg_data;\n\trecv_msg->msg.data_len = msg->rsp_size - 12;\n\trecv_msg->recv_type = IPMI_RESPONSE_RECV_TYPE;\n\tif (deliver_response(intf, recv_msg))\n\t\tipmi_inc_stat(intf, unhandled_lan_responses);\n\telse\n\t\tipmi_inc_stat(intf, handled_lan_responses);\n\n\treturn 0;\n}\n\nstatic int handle_lan_get_msg_cmd(struct ipmi_smi *intf,\n\t\t\t\t  struct ipmi_smi_msg *msg)\n{\n\tstruct cmd_rcvr          *rcvr;\n\tint                      rv = 0;\n\tunsigned char            netfn;\n\tunsigned char            cmd;\n\tunsigned char            chan;\n\tstruct ipmi_user         *user = NULL;\n\tstruct ipmi_lan_addr     *lan_addr;\n\tstruct ipmi_recv_msg     *recv_msg;\n\n\tif (msg->rsp_size < 12) {\n\t\t/* Message not big enough, just ignore it. */\n\t\tipmi_inc_stat(intf, invalid_commands);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the response, just ignore it. */\n\t\treturn 0;\n\t}\n\n\tnetfn = msg->rsp[6] >> 2;\n\tcmd = msg->rsp[10];\n\tchan = msg->rsp[3] & 0xf;\n\n\trcu_read_lock();\n\trcvr = find_cmd_rcvr(intf, netfn, cmd, chan);\n\tif (rcvr) {\n\t\tuser = rcvr->user;\n\t\tkref_get(&user->refcount);\n\t} else\n\t\tuser = NULL;\n\trcu_read_unlock();\n\n\tif (user == NULL) {\n\t\t/* We didn't find a user, just give up. */\n\t\tipmi_inc_stat(intf, unhandled_commands);\n\n\t\t/*\n\t\t * Don't do anything with these messages, just allow\n\t\t * them to be freed.\n\t\t */\n\t\trv = 0;\n\t} else {\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (!recv_msg) {\n\t\t\t/*\n\t\t\t * We couldn't allocate memory for the\n\t\t\t * message, so requeue it for handling later.\n\t\t\t */\n\t\t\trv = 1;\n\t\t\tkref_put(&user->refcount, free_user);\n\t\t} else {\n\t\t\t/* Extract the source address from the data. */\n\t\t\tlan_addr = (struct ipmi_lan_addr *) &recv_msg->addr;\n\t\t\tlan_addr->addr_type = IPMI_LAN_ADDR_TYPE;\n\t\t\tlan_addr->session_handle = msg->rsp[4];\n\t\t\tlan_addr->remote_SWID = msg->rsp[8];\n\t\t\tlan_addr->local_SWID = msg->rsp[5];\n\t\t\tlan_addr->lun = msg->rsp[9] & 3;\n\t\t\tlan_addr->channel = msg->rsp[3] & 0xf;\n\t\t\tlan_addr->privilege = msg->rsp[3] >> 4;\n\n\t\t\t/*\n\t\t\t * Extract the rest of the message information\n\t\t\t * from the IPMB header.\n\t\t\t */\n\t\t\trecv_msg->user = user;\n\t\t\trecv_msg->recv_type = IPMI_CMD_RECV_TYPE;\n\t\t\trecv_msg->msgid = msg->rsp[9] >> 2;\n\t\t\trecv_msg->msg.netfn = msg->rsp[6] >> 2;\n\t\t\trecv_msg->msg.cmd = msg->rsp[10];\n\t\t\trecv_msg->msg.data = recv_msg->msg_data;\n\n\t\t\t/*\n\t\t\t * We chop off 12, not 11 bytes because the checksum\n\t\t\t * at the end also needs to be removed.\n\t\t\t */\n\t\t\trecv_msg->msg.data_len = msg->rsp_size - 12;\n\t\t\tmemcpy(recv_msg->msg_data, &msg->rsp[11],\n\t\t\t       msg->rsp_size - 12);\n\t\t\tif (deliver_response(intf, recv_msg))\n\t\t\t\tipmi_inc_stat(intf, unhandled_commands);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf, handled_commands);\n\t\t}\n\t}\n\n\treturn rv;\n}\n\n/*\n * This routine will handle \"Get Message\" command responses with\n * channels that use an OEM Medium. The message format belongs to\n * the OEM.  See IPMI 2.0 specification, Chapter 6 and\n * Chapter 22, sections 22.6 and 22.24 for more details.\n */\nstatic int handle_oem_get_msg_cmd(struct ipmi_smi *intf,\n\t\t\t\t  struct ipmi_smi_msg *msg)\n{\n\tstruct cmd_rcvr       *rcvr;\n\tint                   rv = 0;\n\tunsigned char         netfn;\n\tunsigned char         cmd;\n\tunsigned char         chan;\n\tstruct ipmi_user *user = NULL;\n\tstruct ipmi_system_interface_addr *smi_addr;\n\tstruct ipmi_recv_msg  *recv_msg;\n\n\t/*\n\t * We expect the OEM SW to perform error checking\n\t * so we just do some basic sanity checks\n\t */\n\tif (msg->rsp_size < 4) {\n\t\t/* Message not big enough, just ignore it. */\n\t\tipmi_inc_stat(intf, invalid_commands);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the response, just ignore it. */\n\t\treturn 0;\n\t}\n\n\t/*\n\t * This is an OEM Message so the OEM needs to know how\n\t * handle the message. We do no interpretation.\n\t */\n\tnetfn = msg->rsp[0] >> 2;\n\tcmd = msg->rsp[1];\n\tchan = msg->rsp[3] & 0xf;\n\n\trcu_read_lock();\n\trcvr = find_cmd_rcvr(intf, netfn, cmd, chan);\n\tif (rcvr) {\n\t\tuser = rcvr->user;\n\t\tkref_get(&user->refcount);\n\t} else\n\t\tuser = NULL;\n\trcu_read_unlock();\n\n\tif (user == NULL) {\n\t\t/* We didn't find a user, just give up. */\n\t\tipmi_inc_stat(intf, unhandled_commands);\n\n\t\t/*\n\t\t * Don't do anything with these messages, just allow\n\t\t * them to be freed.\n\t\t */\n\n\t\trv = 0;\n\t} else {\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (!recv_msg) {\n\t\t\t/*\n\t\t\t * We couldn't allocate memory for the\n\t\t\t * message, so requeue it for handling\n\t\t\t * later.\n\t\t\t */\n\t\t\trv = 1;\n\t\t\tkref_put(&user->refcount, free_user);\n\t\t} else {\n\t\t\t/*\n\t\t\t * OEM Messages are expected to be delivered via\n\t\t\t * the system interface to SMS software.  We might\n\t\t\t * need to visit this again depending on OEM\n\t\t\t * requirements\n\t\t\t */\n\t\t\tsmi_addr = ((struct ipmi_system_interface_addr *)\n\t\t\t\t    &recv_msg->addr);\n\t\t\tsmi_addr->addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\t\t\tsmi_addr->channel = IPMI_BMC_CHANNEL;\n\t\t\tsmi_addr->lun = msg->rsp[0] & 3;\n\n\t\t\trecv_msg->user = user;\n\t\t\trecv_msg->user_msg_data = NULL;\n\t\t\trecv_msg->recv_type = IPMI_OEM_RECV_TYPE;\n\t\t\trecv_msg->msg.netfn = msg->rsp[0] >> 2;\n\t\t\trecv_msg->msg.cmd = msg->rsp[1];\n\t\t\trecv_msg->msg.data = recv_msg->msg_data;\n\n\t\t\t/*\n\t\t\t * The message starts at byte 4 which follows the\n\t\t\t * the Channel Byte in the \"GET MESSAGE\" command\n\t\t\t */\n\t\t\trecv_msg->msg.data_len = msg->rsp_size - 4;\n\t\t\tmemcpy(recv_msg->msg_data, &msg->rsp[4],\n\t\t\t       msg->rsp_size - 4);\n\t\t\tif (deliver_response(intf, recv_msg))\n\t\t\t\tipmi_inc_stat(intf, unhandled_commands);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf, handled_commands);\n\t\t}\n\t}\n\n\treturn rv;\n}\n\nstatic void copy_event_into_recv_msg(struct ipmi_recv_msg *recv_msg,\n\t\t\t\t     struct ipmi_smi_msg  *msg)\n{\n\tstruct ipmi_system_interface_addr *smi_addr;\n\n\trecv_msg->msgid = 0;\n\tsmi_addr = (struct ipmi_system_interface_addr *) &recv_msg->addr;\n\tsmi_addr->addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsmi_addr->channel = IPMI_BMC_CHANNEL;\n\tsmi_addr->lun = msg->rsp[0] & 3;\n\trecv_msg->recv_type = IPMI_ASYNC_EVENT_RECV_TYPE;\n\trecv_msg->msg.netfn = msg->rsp[0] >> 2;\n\trecv_msg->msg.cmd = msg->rsp[1];\n\tmemcpy(recv_msg->msg_data, &msg->rsp[3], msg->rsp_size - 3);\n\trecv_msg->msg.data = recv_msg->msg_data;\n\trecv_msg->msg.data_len = msg->rsp_size - 3;\n}\n\nstatic int handle_read_event_rsp(struct ipmi_smi *intf,\n\t\t\t\t struct ipmi_smi_msg *msg)\n{\n\tstruct ipmi_recv_msg *recv_msg, *recv_msg2;\n\tstruct list_head     msgs;\n\tstruct ipmi_user     *user;\n\tint rv = 0, deliver_count = 0, index;\n\tunsigned long        flags;\n\n\tif (msg->rsp_size < 19) {\n\t\t/* Message is too small to be an IPMB event. */\n\t\tipmi_inc_stat(intf, invalid_events);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the event, just ignore it. */\n\t\treturn 0;\n\t}\n\n\tINIT_LIST_HEAD(&msgs);\n\n\tspin_lock_irqsave(&intf->events_lock, flags);\n\n\tipmi_inc_stat(intf, events);\n\n\t/*\n\t * Allocate and fill in one message for every user that is\n\t * getting events.\n\t */\n\tindex = srcu_read_lock(&intf->users_srcu);\n\tlist_for_each_entry_rcu(user, &intf->users, link) {\n\t\tif (!user->gets_events)\n\t\t\tcontinue;\n\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (!recv_msg) {\n\t\t\trcu_read_unlock();\n\t\t\tlist_for_each_entry_safe(recv_msg, recv_msg2, &msgs,\n\t\t\t\t\t\t link) {\n\t\t\t\tlist_del(&recv_msg->link);\n\t\t\t\tipmi_free_recv_msg(recv_msg);\n\t\t\t}\n\t\t\t/*\n\t\t\t * We couldn't allocate memory for the\n\t\t\t * message, so requeue it for handling\n\t\t\t * later.\n\t\t\t */\n\t\t\trv = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tdeliver_count++;\n\n\t\tcopy_event_into_recv_msg(recv_msg, msg);\n\t\trecv_msg->user = user;\n\t\tkref_get(&user->refcount);\n\t\tlist_add_tail(&recv_msg->link, &msgs);\n\t}\n\tsrcu_read_unlock(&intf->users_srcu, index);\n\n\tif (deliver_count) {\n\t\t/* Now deliver all the messages. */\n\t\tlist_for_each_entry_safe(recv_msg, recv_msg2, &msgs, link) {\n\t\t\tlist_del(&recv_msg->link);\n\t\t\tdeliver_local_response(intf, recv_msg);\n\t\t}\n\t} else if (intf->waiting_events_count < MAX_EVENTS_IN_QUEUE) {\n\t\t/*\n\t\t * No one to receive the message, put it in queue if there's\n\t\t * not already too many things in the queue.\n\t\t */\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (!recv_msg) {\n\t\t\t/*\n\t\t\t * We couldn't allocate memory for the\n\t\t\t * message, so requeue it for handling\n\t\t\t * later.\n\t\t\t */\n\t\t\trv = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tcopy_event_into_recv_msg(recv_msg, msg);\n\t\tlist_add_tail(&recv_msg->link, &intf->waiting_events);\n\t\tintf->waiting_events_count++;\n\t} else if (!intf->event_msg_printed) {\n\t\t/*\n\t\t * There's too many things in the queue, discard this\n\t\t * message.\n\t\t */\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"Event queue full, discarding incoming events\\n\");\n\t\tintf->event_msg_printed = 1;\n\t}\n\n out:\n\tspin_unlock_irqrestore(&intf->events_lock, flags);\n\n\treturn rv;\n}\n\nstatic int handle_bmc_rsp(struct ipmi_smi *intf,\n\t\t\t  struct ipmi_smi_msg *msg)\n{\n\tstruct ipmi_recv_msg *recv_msg;\n\tstruct ipmi_system_interface_addr *smi_addr;\n\n\trecv_msg = (struct ipmi_recv_msg *) msg->user_data;\n\tif (recv_msg == NULL) {\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"IPMI message received with no owner. This could be because of a malformed message, or because of a hardware error.  Contact your hardware vendor for assistance.\\n\");\n\t\treturn 0;\n\t}\n\n\trecv_msg->recv_type = IPMI_RESPONSE_RECV_TYPE;\n\trecv_msg->msgid = msg->msgid;\n\tsmi_addr = ((struct ipmi_system_interface_addr *)\n\t\t    &recv_msg->addr);\n\tsmi_addr->addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsmi_addr->channel = IPMI_BMC_CHANNEL;\n\tsmi_addr->lun = msg->rsp[0] & 3;\n\trecv_msg->msg.netfn = msg->rsp[0] >> 2;\n\trecv_msg->msg.cmd = msg->rsp[1];\n\tmemcpy(recv_msg->msg_data, &msg->rsp[2], msg->rsp_size - 2);\n\trecv_msg->msg.data = recv_msg->msg_data;\n\trecv_msg->msg.data_len = msg->rsp_size - 2;\n\tdeliver_local_response(intf, recv_msg);\n\n\treturn 0;\n}\n\n/*\n * Handle a received message.  Return 1 if the message should be requeued,\n * 0 if the message should be freed, or -1 if the message should not\n * be freed or requeued.\n */\nstatic int handle_one_recv_msg(struct ipmi_smi *intf,\n\t\t\t       struct ipmi_smi_msg *msg)\n{\n\tint requeue;\n\tint chan;\n\n\tpr_debug(\"Recv: %*ph\\n\", msg->rsp_size, msg->rsp);\n\n\tif ((msg->data_size >= 2)\n\t    && (msg->data[0] == (IPMI_NETFN_APP_REQUEST << 2))\n\t    && (msg->data[1] == IPMI_SEND_MSG_CMD)\n\t    && (msg->user_data == NULL)) {\n\n\t\tif (intf->in_shutdown)\n\t\t\tgoto free_msg;\n\n\t\t/*\n\t\t * This is the local response to a command send, start\n\t\t * the timer for these.  The user_data will not be\n\t\t * NULL if this is a response send, and we will let\n\t\t * response sends just go through.\n\t\t */\n\n\t\t/*\n\t\t * Check for errors, if we get certain errors (ones\n\t\t * that mean basically we can try again later), we\n\t\t * ignore them and start the timer.  Otherwise we\n\t\t * report the error immediately.\n\t\t */\n\t\tif ((msg->rsp_size >= 3) && (msg->rsp[2] != 0)\n\t\t    && (msg->rsp[2] != IPMI_NODE_BUSY_ERR)\n\t\t    && (msg->rsp[2] != IPMI_LOST_ARBITRATION_ERR)\n\t\t    && (msg->rsp[2] != IPMI_BUS_ERR)\n\t\t    && (msg->rsp[2] != IPMI_NAK_ON_WRITE_ERR)) {\n\t\t\tint ch = msg->rsp[3] & 0xf;\n\t\t\tstruct ipmi_channel *chans;\n\n\t\t\t/* Got an error sending the message, handle it. */\n\n\t\t\tchans = READ_ONCE(intf->channel_list)->c;\n\t\t\tif ((chans[ch].medium == IPMI_CHANNEL_MEDIUM_8023LAN)\n\t\t\t    || (chans[ch].medium == IPMI_CHANNEL_MEDIUM_ASYNC))\n\t\t\t\tipmi_inc_stat(intf, sent_lan_command_errs);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf, sent_ipmb_command_errs);\n\t\t\tintf_err_seq(intf, msg->msgid, msg->rsp[2]);\n\t\t} else\n\t\t\t/* The message was sent, start the timer. */\n\t\t\tintf_start_seq_timer(intf, msg->msgid);\nfree_msg:\n\t\trequeue = 0;\n\t\tgoto out;\n\n\t} else if (msg->rsp_size < 2) {\n\t\t/* Message is too small to be correct. */\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"BMC returned too small a message for netfn %x cmd %x, got %d bytes\\n\",\n\t\t\t (msg->data[0] >> 2) | 1, msg->data[1], msg->rsp_size);\n\n\t\t/* Generate an error response for the message. */\n\t\tmsg->rsp[0] = msg->data[0] | (1 << 2);\n\t\tmsg->rsp[1] = msg->data[1];\n\t\tmsg->rsp[2] = IPMI_ERR_UNSPECIFIED;\n\t\tmsg->rsp_size = 3;\n\t} else if (((msg->rsp[0] >> 2) != ((msg->data[0] >> 2) | 1))\n\t\t   || (msg->rsp[1] != msg->data[1])) {\n\t\t/*\n\t\t * The NetFN and Command in the response is not even\n\t\t * marginally correct.\n\t\t */\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"BMC returned incorrect response, expected netfn %x cmd %x, got netfn %x cmd %x\\n\",\n\t\t\t (msg->data[0] >> 2) | 1, msg->data[1],\n\t\t\t msg->rsp[0] >> 2, msg->rsp[1]);\n\n\t\t/* Generate an error response for the message. */\n\t\tmsg->rsp[0] = msg->data[0] | (1 << 2);\n\t\tmsg->rsp[1] = msg->data[1];\n\t\tmsg->rsp[2] = IPMI_ERR_UNSPECIFIED;\n\t\tmsg->rsp_size = 3;\n\t}\n\n\tif ((msg->rsp[0] == ((IPMI_NETFN_APP_REQUEST|1) << 2))\n\t    && (msg->rsp[1] == IPMI_SEND_MSG_CMD)\n\t    && (msg->user_data != NULL)) {\n\t\t/*\n\t\t * It's a response to a response we sent.  For this we\n\t\t * deliver a send message response to the user.\n\t\t */\n\t\tstruct ipmi_recv_msg *recv_msg = msg->user_data;\n\n\t\trequeue = 0;\n\t\tif (msg->rsp_size < 2)\n\t\t\t/* Message is too small to be correct. */\n\t\t\tgoto out;\n\n\t\tchan = msg->data[2] & 0x0f;\n\t\tif (chan >= IPMI_MAX_CHANNELS)\n\t\t\t/* Invalid channel number */\n\t\t\tgoto out;\n\n\t\tif (!recv_msg)\n\t\t\tgoto out;\n\n\t\trecv_msg->recv_type = IPMI_RESPONSE_RESPONSE_TYPE;\n\t\trecv_msg->msg.data = recv_msg->msg_data;\n\t\trecv_msg->msg.data_len = 1;\n\t\trecv_msg->msg_data[0] = msg->rsp[2];\n\t\tdeliver_local_response(intf, recv_msg);\n\t} else if ((msg->rsp[0] == ((IPMI_NETFN_APP_REQUEST|1) << 2))\n\t\t   && (msg->rsp[1] == IPMI_GET_MSG_CMD)) {\n\t\tstruct ipmi_channel   *chans;\n\n\t\t/* It's from the receive queue. */\n\t\tchan = msg->rsp[3] & 0xf;\n\t\tif (chan >= IPMI_MAX_CHANNELS) {\n\t\t\t/* Invalid channel number */\n\t\t\trequeue = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\t/*\n\t\t * We need to make sure the channels have been initialized.\n\t\t * The channel_handler routine will set the \"curr_channel\"\n\t\t * equal to or greater than IPMI_MAX_CHANNELS when all the\n\t\t * channels for this interface have been initialized.\n\t\t */\n\t\tif (!intf->channels_ready) {\n\t\t\trequeue = 0; /* Throw the message away */\n\t\t\tgoto out;\n\t\t}\n\n\t\tchans = READ_ONCE(intf->channel_list)->c;\n\n\t\tswitch (chans[chan].medium) {\n\t\tcase IPMI_CHANNEL_MEDIUM_IPMB:\n\t\t\tif (msg->rsp[4] & 0x04) {\n\t\t\t\t/*\n\t\t\t\t * It's a response, so find the\n\t\t\t\t * requesting message and send it up.\n\t\t\t\t */\n\t\t\t\trequeue = handle_ipmb_get_msg_rsp(intf, msg);\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * It's a command to the SMS from some other\n\t\t\t\t * entity.  Handle that.\n\t\t\t\t */\n\t\t\t\trequeue = handle_ipmb_get_msg_cmd(intf, msg);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase IPMI_CHANNEL_MEDIUM_8023LAN:\n\t\tcase IPMI_CHANNEL_MEDIUM_ASYNC:\n\t\t\tif (msg->rsp[6] & 0x04) {\n\t\t\t\t/*\n\t\t\t\t * It's a response, so find the\n\t\t\t\t * requesting message and send it up.\n\t\t\t\t */\n\t\t\t\trequeue = handle_lan_get_msg_rsp(intf, msg);\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * It's a command to the SMS from some other\n\t\t\t\t * entity.  Handle that.\n\t\t\t\t */\n\t\t\t\trequeue = handle_lan_get_msg_cmd(intf, msg);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\t/* Check for OEM Channels.  Clients had better\n\t\t\t   register for these commands. */\n\t\t\tif ((chans[chan].medium >= IPMI_CHANNEL_MEDIUM_OEM_MIN)\n\t\t\t    && (chans[chan].medium\n\t\t\t\t<= IPMI_CHANNEL_MEDIUM_OEM_MAX)) {\n\t\t\t\trequeue = handle_oem_get_msg_cmd(intf, msg);\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * We don't handle the channel type, so just\n\t\t\t\t * free the message.\n\t\t\t\t */\n\t\t\t\trequeue = 0;\n\t\t\t}\n\t\t}\n\n\t} else if ((msg->rsp[0] == ((IPMI_NETFN_APP_REQUEST|1) << 2))\n\t\t   && (msg->rsp[1] == IPMI_READ_EVENT_MSG_BUFFER_CMD)) {\n\t\t/* It's an asynchronous event. */\n\t\trequeue = handle_read_event_rsp(intf, msg);\n\t} else {\n\t\t/* It's a response from the local BMC. */\n\t\trequeue = handle_bmc_rsp(intf, msg);\n\t}\n\n out:\n\treturn requeue;\n}\n\n/*\n * If there are messages in the queue or pretimeouts, handle them.\n */\nstatic void handle_new_recv_msgs(struct ipmi_smi *intf)\n{\n\tstruct ipmi_smi_msg  *smi_msg;\n\tunsigned long        flags = 0;\n\tint                  rv;\n\tint                  run_to_completion = intf->run_to_completion;\n\n\t/* See if any waiting messages need to be processed. */\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&intf->waiting_rcv_msgs_lock, flags);\n\twhile (!list_empty(&intf->waiting_rcv_msgs)) {\n\t\tsmi_msg = list_entry(intf->waiting_rcv_msgs.next,\n\t\t\t\t     struct ipmi_smi_msg, link);\n\t\tlist_del(&smi_msg->link);\n\t\tif (!run_to_completion)\n\t\t\tspin_unlock_irqrestore(&intf->waiting_rcv_msgs_lock,\n\t\t\t\t\t       flags);\n\t\trv = handle_one_recv_msg(intf, smi_msg);\n\t\tif (!run_to_completion)\n\t\t\tspin_lock_irqsave(&intf->waiting_rcv_msgs_lock, flags);\n\t\tif (rv > 0) {\n\t\t\t/*\n\t\t\t * To preserve message order, quit if we\n\t\t\t * can't handle a message.  Add the message\n\t\t\t * back at the head, this is safe because this\n\t\t\t * tasklet is the only thing that pulls the\n\t\t\t * messages.\n\t\t\t */\n\t\t\tlist_add(&smi_msg->link, &intf->waiting_rcv_msgs);\n\t\t\tbreak;\n\t\t} else {\n\t\t\tif (rv == 0)\n\t\t\t\t/* Message handled */\n\t\t\t\tipmi_free_smi_msg(smi_msg);\n\t\t\t/* If rv < 0, fatal error, del but don't free. */\n\t\t}\n\t}\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&intf->waiting_rcv_msgs_lock, flags);\n\n\t/*\n\t * If the pretimout count is non-zero, decrement one from it and\n\t * deliver pretimeouts to all the users.\n\t */\n\tif (atomic_add_unless(&intf->watchdog_pretimeouts_to_deliver, -1, 0)) {\n\t\tstruct ipmi_user *user;\n\t\tint index;\n\n\t\tindex = srcu_read_lock(&intf->users_srcu);\n\t\tlist_for_each_entry_rcu(user, &intf->users, link) {\n\t\t\tif (user->handler->ipmi_watchdog_pretimeout)\n\t\t\t\tuser->handler->ipmi_watchdog_pretimeout(\n\t\t\t\t\tuser->handler_data);\n\t\t}\n\t\tsrcu_read_unlock(&intf->users_srcu, index);\n\t}\n}\n\nstatic void smi_recv_tasklet(unsigned long val)\n{\n\tunsigned long flags = 0; /* keep us warning-free. */\n\tstruct ipmi_smi *intf = (struct ipmi_smi *) val;\n\tint run_to_completion = intf->run_to_completion;\n\tstruct ipmi_smi_msg *newmsg = NULL;\n\n\t/*\n\t * Start the next message if available.\n\t *\n\t * Do this here, not in the actual receiver, because we may deadlock\n\t * because the lower layer is allowed to hold locks while calling\n\t * message delivery.\n\t */\n\n\trcu_read_lock();\n\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&intf->xmit_msgs_lock, flags);\n\tif (intf->curr_msg == NULL && !intf->in_shutdown) {\n\t\tstruct list_head *entry = NULL;\n\n\t\t/* Pick the high priority queue first. */\n\t\tif (!list_empty(&intf->hp_xmit_msgs))\n\t\t\tentry = intf->hp_xmit_msgs.next;\n\t\telse if (!list_empty(&intf->xmit_msgs))\n\t\t\tentry = intf->xmit_msgs.next;\n\n\t\tif (entry) {\n\t\t\tlist_del(entry);\n\t\t\tnewmsg = list_entry(entry, struct ipmi_smi_msg, link);\n\t\t\tintf->curr_msg = newmsg;\n\t\t}\n\t}\n\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&intf->xmit_msgs_lock, flags);\n\tif (newmsg)\n\t\tintf->handlers->sender(intf->send_info, newmsg);\n\n\trcu_read_unlock();\n\n\thandle_new_recv_msgs(intf);\n}\n\n/* Handle a new message from the lower layer. */\nvoid ipmi_smi_msg_received(struct ipmi_smi *intf,\n\t\t\t   struct ipmi_smi_msg *msg)\n{\n\tunsigned long flags = 0; /* keep us warning-free. */\n\tint run_to_completion = intf->run_to_completion;\n\n\t/*\n\t * To preserve message order, we keep a queue and deliver from\n\t * a tasklet.\n\t */\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&intf->waiting_rcv_msgs_lock, flags);\n\tlist_add_tail(&msg->link, &intf->waiting_rcv_msgs);\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&intf->waiting_rcv_msgs_lock,\n\t\t\t\t       flags);\n\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&intf->xmit_msgs_lock, flags);\n\t/*\n\t * We can get an asynchronous event or receive message in addition\n\t * to commands we send.\n\t */\n\tif (msg == intf->curr_msg)\n\t\tintf->curr_msg = NULL;\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&intf->xmit_msgs_lock, flags);\n\n\tif (run_to_completion)\n\t\tsmi_recv_tasklet((unsigned long) intf);\n\telse\n\t\ttasklet_schedule(&intf->recv_tasklet);\n}\nEXPORT_SYMBOL(ipmi_smi_msg_received);\n\nvoid ipmi_smi_watchdog_pretimeout(struct ipmi_smi *intf)\n{\n\tif (intf->in_shutdown)\n\t\treturn;\n\n\tatomic_set(&intf->watchdog_pretimeouts_to_deliver, 1);\n\ttasklet_schedule(&intf->recv_tasklet);\n}\nEXPORT_SYMBOL(ipmi_smi_watchdog_pretimeout);\n\nstatic struct ipmi_smi_msg *\nsmi_from_recv_msg(struct ipmi_smi *intf, struct ipmi_recv_msg *recv_msg,\n\t\t  unsigned char seq, long seqid)\n{\n\tstruct ipmi_smi_msg *smi_msg = ipmi_alloc_smi_msg();\n\tif (!smi_msg)\n\t\t/*\n\t\t * If we can't allocate the message, then just return, we\n\t\t * get 4 retries, so this should be ok.\n\t\t */\n\t\treturn NULL;\n\n\tmemcpy(smi_msg->data, recv_msg->msg.data, recv_msg->msg.data_len);\n\tsmi_msg->data_size = recv_msg->msg.data_len;\n\tsmi_msg->msgid = STORE_SEQ_IN_MSGID(seq, seqid);\n\n\tpr_debug(\"Resend: %*ph\\n\", smi_msg->data_size, smi_msg->data);\n\n\treturn smi_msg;\n}\n\nstatic void check_msg_timeout(struct ipmi_smi *intf, struct seq_table *ent,\n\t\t\t      struct list_head *timeouts,\n\t\t\t      unsigned long timeout_period,\n\t\t\t      int slot, unsigned long *flags,\n\t\t\t      bool *need_timer)\n{\n\tstruct ipmi_recv_msg *msg;\n\n\tif (intf->in_shutdown)\n\t\treturn;\n\n\tif (!ent->inuse)\n\t\treturn;\n\n\tif (timeout_period < ent->timeout) {\n\t\tent->timeout -= timeout_period;\n\t\t*need_timer = true;\n\t\treturn;\n\t}\n\n\tif (ent->retries_left == 0) {\n\t\t/* The message has used all its retries. */\n\t\tent->inuse = 0;\n\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_MESSAGES);\n\t\tmsg = ent->recv_msg;\n\t\tlist_add_tail(&msg->link, timeouts);\n\t\tif (ent->broadcast)\n\t\t\tipmi_inc_stat(intf, timed_out_ipmb_broadcasts);\n\t\telse if (is_lan_addr(&ent->recv_msg->addr))\n\t\t\tipmi_inc_stat(intf, timed_out_lan_commands);\n\t\telse\n\t\t\tipmi_inc_stat(intf, timed_out_ipmb_commands);\n\t} else {\n\t\tstruct ipmi_smi_msg *smi_msg;\n\t\t/* More retries, send again. */\n\n\t\t*need_timer = true;\n\n\t\t/*\n\t\t * Start with the max timer, set to normal timer after\n\t\t * the message is sent.\n\t\t */\n\t\tent->timeout = MAX_MSG_TIMEOUT;\n\t\tent->retries_left--;\n\t\tsmi_msg = smi_from_recv_msg(intf, ent->recv_msg, slot,\n\t\t\t\t\t    ent->seqid);\n\t\tif (!smi_msg) {\n\t\t\tif (is_lan_addr(&ent->recv_msg->addr))\n\t\t\t\tipmi_inc_stat(intf,\n\t\t\t\t\t      dropped_rexmit_lan_commands);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf,\n\t\t\t\t\t      dropped_rexmit_ipmb_commands);\n\t\t\treturn;\n\t\t}\n\n\t\tspin_unlock_irqrestore(&intf->seq_lock, *flags);\n\n\t\t/*\n\t\t * Send the new message.  We send with a zero\n\t\t * priority.  It timed out, I doubt time is that\n\t\t * critical now, and high priority messages are really\n\t\t * only for messages to the local MC, which don't get\n\t\t * resent.\n\t\t */\n\t\tif (intf->handlers) {\n\t\t\tif (is_lan_addr(&ent->recv_msg->addr))\n\t\t\t\tipmi_inc_stat(intf,\n\t\t\t\t\t      retransmitted_lan_commands);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf,\n\t\t\t\t\t      retransmitted_ipmb_commands);\n\n\t\t\tsmi_send(intf, intf->handlers, smi_msg, 0);\n\t\t} else\n\t\t\tipmi_free_smi_msg(smi_msg);\n\n\t\tspin_lock_irqsave(&intf->seq_lock, *flags);\n\t}\n}\n\nstatic bool ipmi_timeout_handler(struct ipmi_smi *intf,\n\t\t\t\t unsigned long timeout_period)\n{\n\tstruct list_head     timeouts;\n\tstruct ipmi_recv_msg *msg, *msg2;\n\tunsigned long        flags;\n\tint                  i;\n\tbool                 need_timer = false;\n\n\tif (!intf->bmc_registered) {\n\t\tkref_get(&intf->refcount);\n\t\tif (!schedule_work(&intf->bmc_reg_work)) {\n\t\t\tkref_put(&intf->refcount, intf_free);\n\t\t\tneed_timer = true;\n\t\t}\n\t}\n\n\t/*\n\t * Go through the seq table and find any messages that\n\t * have timed out, putting them in the timeouts\n\t * list.\n\t */\n\tINIT_LIST_HEAD(&timeouts);\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\tif (intf->ipmb_maintenance_mode_timeout) {\n\t\tif (intf->ipmb_maintenance_mode_timeout <= timeout_period)\n\t\t\tintf->ipmb_maintenance_mode_timeout = 0;\n\t\telse\n\t\t\tintf->ipmb_maintenance_mode_timeout -= timeout_period;\n\t}\n\tfor (i = 0; i < IPMI_IPMB_NUM_SEQ; i++)\n\t\tcheck_msg_timeout(intf, &intf->seq_table[i],\n\t\t\t\t  &timeouts, timeout_period, i,\n\t\t\t\t  &flags, &need_timer);\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\n\tlist_for_each_entry_safe(msg, msg2, &timeouts, link)\n\t\tdeliver_err_response(intf, msg, IPMI_TIMEOUT_COMPLETION_CODE);\n\n\t/*\n\t * Maintenance mode handling.  Check the timeout\n\t * optimistically before we claim the lock.  It may\n\t * mean a timeout gets missed occasionally, but that\n\t * only means the timeout gets extended by one period\n\t * in that case.  No big deal, and it avoids the lock\n\t * most of the time.\n\t */\n\tif (intf->auto_maintenance_timeout > 0) {\n\t\tspin_lock_irqsave(&intf->maintenance_mode_lock, flags);\n\t\tif (intf->auto_maintenance_timeout > 0) {\n\t\t\tintf->auto_maintenance_timeout\n\t\t\t\t-= timeout_period;\n\t\t\tif (!intf->maintenance_mode\n\t\t\t    && (intf->auto_maintenance_timeout <= 0)) {\n\t\t\t\tintf->maintenance_mode_enable = false;\n\t\t\t\tmaintenance_mode_update(intf);\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irqrestore(&intf->maintenance_mode_lock,\n\t\t\t\t       flags);\n\t}\n\n\ttasklet_schedule(&intf->recv_tasklet);\n\n\treturn need_timer;\n}\n\nstatic void ipmi_request_event(struct ipmi_smi *intf)\n{\n\t/* No event requests when in maintenance mode. */\n\tif (intf->maintenance_mode_enable)\n\t\treturn;\n\n\tif (!intf->in_shutdown)\n\t\tintf->handlers->request_events(intf->send_info);\n}\n\nstatic struct timer_list ipmi_timer;\n\nstatic atomic_t stop_operation;\n\nstatic void ipmi_timeout(struct timer_list *unused)\n{\n\tstruct ipmi_smi *intf;\n\tbool need_timer = false;\n\tint index;\n\n\tif (atomic_read(&stop_operation))\n\t\treturn;\n\n\tindex = srcu_read_lock(&ipmi_interfaces_srcu);\n\tlist_for_each_entry_rcu(intf, &ipmi_interfaces, link) {\n\t\tif (atomic_read(&intf->event_waiters)) {\n\t\t\tintf->ticks_to_req_ev--;\n\t\t\tif (intf->ticks_to_req_ev == 0) {\n\t\t\t\tipmi_request_event(intf);\n\t\t\t\tintf->ticks_to_req_ev = IPMI_REQUEST_EV_TIME;\n\t\t\t}\n\t\t\tneed_timer = true;\n\t\t}\n\n\t\tneed_timer |= ipmi_timeout_handler(intf, IPMI_TIMEOUT_TIME);\n\t}\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\n\tif (need_timer)\n\t\tmod_timer(&ipmi_timer, jiffies + IPMI_TIMEOUT_JIFFIES);\n}\n\nstatic void need_waiter(struct ipmi_smi *intf)\n{\n\t/* Racy, but worst case we start the timer twice. */\n\tif (!timer_pending(&ipmi_timer))\n\t\tmod_timer(&ipmi_timer, jiffies + IPMI_TIMEOUT_JIFFIES);\n}\n\nstatic atomic_t smi_msg_inuse_count = ATOMIC_INIT(0);\nstatic atomic_t recv_msg_inuse_count = ATOMIC_INIT(0);\n\nstatic void free_smi_msg(struct ipmi_smi_msg *msg)\n{\n\tatomic_dec(&smi_msg_inuse_count);\n\tkfree(msg);\n}\n\nstruct ipmi_smi_msg *ipmi_alloc_smi_msg(void)\n{\n\tstruct ipmi_smi_msg *rv;\n\trv = kmalloc(sizeof(struct ipmi_smi_msg), GFP_ATOMIC);\n\tif (rv) {\n\t\trv->done = free_smi_msg;\n\t\trv->user_data = NULL;\n\t\tatomic_inc(&smi_msg_inuse_count);\n\t}\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_alloc_smi_msg);\n\nstatic void free_recv_msg(struct ipmi_recv_msg *msg)\n{\n\tatomic_dec(&recv_msg_inuse_count);\n\tkfree(msg);\n}\n\nstatic struct ipmi_recv_msg *ipmi_alloc_recv_msg(void)\n{\n\tstruct ipmi_recv_msg *rv;\n\n\trv = kmalloc(sizeof(struct ipmi_recv_msg), GFP_ATOMIC);\n\tif (rv) {\n\t\trv->user = NULL;\n\t\trv->done = free_recv_msg;\n\t\tatomic_inc(&recv_msg_inuse_count);\n\t}\n\treturn rv;\n}\n\nvoid ipmi_free_recv_msg(struct ipmi_recv_msg *msg)\n{\n\tif (msg->user)\n\t\tkref_put(&msg->user->refcount, free_user);\n\tmsg->done(msg);\n}\nEXPORT_SYMBOL(ipmi_free_recv_msg);\n\nstatic atomic_t panic_done_count = ATOMIC_INIT(0);\n\nstatic void dummy_smi_done_handler(struct ipmi_smi_msg *msg)\n{\n\tatomic_dec(&panic_done_count);\n}\n\nstatic void dummy_recv_done_handler(struct ipmi_recv_msg *msg)\n{\n\tatomic_dec(&panic_done_count);\n}\n\n/*\n * Inside a panic, send a message and wait for a response.\n */\nstatic void ipmi_panic_request_and_wait(struct ipmi_smi *intf,\n\t\t\t\t\tstruct ipmi_addr *addr,\n\t\t\t\t\tstruct kernel_ipmi_msg *msg)\n{\n\tstruct ipmi_smi_msg  smi_msg;\n\tstruct ipmi_recv_msg recv_msg;\n\tint rv;\n\n\tsmi_msg.done = dummy_smi_done_handler;\n\trecv_msg.done = dummy_recv_done_handler;\n\tatomic_add(2, &panic_done_count);\n\trv = i_ipmi_request(NULL,\n\t\t\t    intf,\n\t\t\t    addr,\n\t\t\t    0,\n\t\t\t    msg,\n\t\t\t    intf,\n\t\t\t    &smi_msg,\n\t\t\t    &recv_msg,\n\t\t\t    0,\n\t\t\t    intf->addrinfo[0].address,\n\t\t\t    intf->addrinfo[0].lun,\n\t\t\t    0, 1); /* Don't retry, and don't wait. */\n\tif (rv)\n\t\tatomic_sub(2, &panic_done_count);\n\telse if (intf->handlers->flush_messages)\n\t\tintf->handlers->flush_messages(intf->send_info);\n\n\twhile (atomic_read(&panic_done_count) != 0)\n\t\tipmi_poll(intf);\n}\n\nstatic void event_receiver_fetcher(struct ipmi_smi *intf,\n\t\t\t\t   struct ipmi_recv_msg *msg)\n{\n\tif ((msg->addr.addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t    && (msg->msg.netfn == IPMI_NETFN_SENSOR_EVENT_RESPONSE)\n\t    && (msg->msg.cmd == IPMI_GET_EVENT_RECEIVER_CMD)\n\t    && (msg->msg.data[0] == IPMI_CC_NO_ERROR)) {\n\t\t/* A get event receiver command, save it. */\n\t\tintf->event_receiver = msg->msg.data[1];\n\t\tintf->event_receiver_lun = msg->msg.data[2] & 0x3;\n\t}\n}\n\nstatic void device_id_fetcher(struct ipmi_smi *intf, struct ipmi_recv_msg *msg)\n{\n\tif ((msg->addr.addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t    && (msg->msg.netfn == IPMI_NETFN_APP_RESPONSE)\n\t    && (msg->msg.cmd == IPMI_GET_DEVICE_ID_CMD)\n\t    && (msg->msg.data[0] == IPMI_CC_NO_ERROR)) {\n\t\t/*\n\t\t * A get device id command, save if we are an event\n\t\t * receiver or generator.\n\t\t */\n\t\tintf->local_sel_device = (msg->msg.data[6] >> 2) & 1;\n\t\tintf->local_event_generator = (msg->msg.data[6] >> 5) & 1;\n\t}\n}\n\nstatic void send_panic_events(struct ipmi_smi *intf, char *str)\n{\n\tstruct kernel_ipmi_msg msg;\n\tunsigned char data[16];\n\tstruct ipmi_system_interface_addr *si;\n\tstruct ipmi_addr addr;\n\tchar *p = str;\n\tstruct ipmi_ipmb_addr *ipmb;\n\tint j;\n\n\tif (ipmi_send_panic_event == IPMI_SEND_PANIC_EVENT_NONE)\n\t\treturn;\n\n\tsi = (struct ipmi_system_interface_addr *) &addr;\n\tsi->addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsi->channel = IPMI_BMC_CHANNEL;\n\tsi->lun = 0;\n\n\t/* Fill in an event telling that we have failed. */\n\tmsg.netfn = 0x04; /* Sensor or Event. */\n\tmsg.cmd = 2; /* Platform event command. */\n\tmsg.data = data;\n\tmsg.data_len = 8;\n\tdata[0] = 0x41; /* Kernel generator ID, IPMI table 5-4 */\n\tdata[1] = 0x03; /* This is for IPMI 1.0. */\n\tdata[2] = 0x20; /* OS Critical Stop, IPMI table 36-3 */\n\tdata[4] = 0x6f; /* Sensor specific, IPMI table 36-1 */\n\tdata[5] = 0xa1; /* Runtime stop OEM bytes 2 & 3. */\n\n\t/*\n\t * Put a few breadcrumbs in.  Hopefully later we can add more things\n\t * to make the panic events more useful.\n\t */\n\tif (str) {\n\t\tdata[3] = str[0];\n\t\tdata[6] = str[1];\n\t\tdata[7] = str[2];\n\t}\n\n\t/* Send the event announcing the panic. */\n\tipmi_panic_request_and_wait(intf, &addr, &msg);\n\n\t/*\n\t * On every interface, dump a bunch of OEM event holding the\n\t * string.\n\t */\n\tif (ipmi_send_panic_event != IPMI_SEND_PANIC_EVENT_STRING || !str)\n\t\treturn;\n\n\t/*\n\t * intf_num is used as an marker to tell if the\n\t * interface is valid.  Thus we need a read barrier to\n\t * make sure data fetched before checking intf_num\n\t * won't be used.\n\t */\n\tsmp_rmb();\n\n\t/*\n\t * First job here is to figure out where to send the\n\t * OEM events.  There's no way in IPMI to send OEM\n\t * events using an event send command, so we have to\n\t * find the SEL to put them in and stick them in\n\t * there.\n\t */\n\n\t/* Get capabilities from the get device id. */\n\tintf->local_sel_device = 0;\n\tintf->local_event_generator = 0;\n\tintf->event_receiver = 0;\n\n\t/* Request the device info from the local MC. */\n\tmsg.netfn = IPMI_NETFN_APP_REQUEST;\n\tmsg.cmd = IPMI_GET_DEVICE_ID_CMD;\n\tmsg.data = NULL;\n\tmsg.data_len = 0;\n\tintf->null_user_handler = device_id_fetcher;\n\tipmi_panic_request_and_wait(intf, &addr, &msg);\n\n\tif (intf->local_event_generator) {\n\t\t/* Request the event receiver from the local MC. */\n\t\tmsg.netfn = IPMI_NETFN_SENSOR_EVENT_REQUEST;\n\t\tmsg.cmd = IPMI_GET_EVENT_RECEIVER_CMD;\n\t\tmsg.data = NULL;\n\t\tmsg.data_len = 0;\n\t\tintf->null_user_handler = event_receiver_fetcher;\n\t\tipmi_panic_request_and_wait(intf, &addr, &msg);\n\t}\n\tintf->null_user_handler = NULL;\n\n\t/*\n\t * Validate the event receiver.  The low bit must not\n\t * be 1 (it must be a valid IPMB address), it cannot\n\t * be zero, and it must not be my address.\n\t */\n\tif (((intf->event_receiver & 1) == 0)\n\t    && (intf->event_receiver != 0)\n\t    && (intf->event_receiver != intf->addrinfo[0].address)) {\n\t\t/*\n\t\t * The event receiver is valid, send an IPMB\n\t\t * message.\n\t\t */\n\t\tipmb = (struct ipmi_ipmb_addr *) &addr;\n\t\tipmb->addr_type = IPMI_IPMB_ADDR_TYPE;\n\t\tipmb->channel = 0; /* FIXME - is this right? */\n\t\tipmb->lun = intf->event_receiver_lun;\n\t\tipmb->slave_addr = intf->event_receiver;\n\t} else if (intf->local_sel_device) {\n\t\t/*\n\t\t * The event receiver was not valid (or was\n\t\t * me), but I am an SEL device, just dump it\n\t\t * in my SEL.\n\t\t */\n\t\tsi = (struct ipmi_system_interface_addr *) &addr;\n\t\tsi->addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\t\tsi->channel = IPMI_BMC_CHANNEL;\n\t\tsi->lun = 0;\n\t} else\n\t\treturn; /* No where to send the event. */\n\n\tmsg.netfn = IPMI_NETFN_STORAGE_REQUEST; /* Storage. */\n\tmsg.cmd = IPMI_ADD_SEL_ENTRY_CMD;\n\tmsg.data = data;\n\tmsg.data_len = 16;\n\n\tj = 0;\n\twhile (*p) {\n\t\tint size = strlen(p);\n\n\t\tif (size > 11)\n\t\t\tsize = 11;\n\t\tdata[0] = 0;\n\t\tdata[1] = 0;\n\t\tdata[2] = 0xf0; /* OEM event without timestamp. */\n\t\tdata[3] = intf->addrinfo[0].address;\n\t\tdata[4] = j++; /* sequence # */\n\t\t/*\n\t\t * Always give 11 bytes, so strncpy will fill\n\t\t * it with zeroes for me.\n\t\t */\n\t\tstrncpy(data+5, p, 11);\n\t\tp += size;\n\n\t\tipmi_panic_request_and_wait(intf, &addr, &msg);\n\t}\n}\n\nstatic int has_panicked;\n\nstatic int panic_event(struct notifier_block *this,\n\t\t       unsigned long         event,\n\t\t       void                  *ptr)\n{\n\tstruct ipmi_smi *intf;\n\tstruct ipmi_user *user;\n\n\tif (has_panicked)\n\t\treturn NOTIFY_DONE;\n\thas_panicked = 1;\n\n\t/* For every registered interface, set it to run to completion. */\n\tlist_for_each_entry_rcu(intf, &ipmi_interfaces, link) {\n\t\tif (!intf->handlers || intf->intf_num == -1)\n\t\t\t/* Interface is not ready. */\n\t\t\tcontinue;\n\n\t\tif (!intf->handlers->poll)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If we were interrupted while locking xmit_msgs_lock or\n\t\t * waiting_rcv_msgs_lock, the corresponding list may be\n\t\t * corrupted.  In this case, drop items on the list for\n\t\t * the safety.\n\t\t */\n\t\tif (!spin_trylock(&intf->xmit_msgs_lock)) {\n\t\t\tINIT_LIST_HEAD(&intf->xmit_msgs);\n\t\t\tINIT_LIST_HEAD(&intf->hp_xmit_msgs);\n\t\t} else\n\t\t\tspin_unlock(&intf->xmit_msgs_lock);\n\n\t\tif (!spin_trylock(&intf->waiting_rcv_msgs_lock))\n\t\t\tINIT_LIST_HEAD(&intf->waiting_rcv_msgs);\n\t\telse\n\t\t\tspin_unlock(&intf->waiting_rcv_msgs_lock);\n\n\t\tintf->run_to_completion = 1;\n\t\tif (intf->handlers->set_run_to_completion)\n\t\t\tintf->handlers->set_run_to_completion(intf->send_info,\n\t\t\t\t\t\t\t      1);\n\n\t\tlist_for_each_entry_rcu(user, &intf->users, link) {\n\t\t\tif (user->handler->ipmi_panic_handler)\n\t\t\t\tuser->handler->ipmi_panic_handler(\n\t\t\t\t\tuser->handler_data);\n\t\t}\n\n\t\tsend_panic_events(intf, ptr);\n\t}\n\n\treturn NOTIFY_DONE;\n}\n\n/* Must be called with ipmi_interfaces_mutex held. */\nstatic int ipmi_register_driver(void)\n{\n\tint rv;\n\n\tif (drvregistered)\n\t\treturn 0;\n\n\trv = driver_register(&ipmidriver.driver);\n\tif (rv)\n\t\tpr_err(\"Could not register IPMI driver\\n\");\n\telse\n\t\tdrvregistered = true;\n\treturn rv;\n}\n\nstatic struct notifier_block panic_block = {\n\t.notifier_call\t= panic_event,\n\t.next\t\t= NULL,\n\t.priority\t= 200\t/* priority: INT_MAX >= x >= 0 */\n};\n\nstatic int ipmi_init_msghandler(void)\n{\n\tint rv;\n\n\tmutex_lock(&ipmi_interfaces_mutex);\n\trv = ipmi_register_driver();\n\tif (rv)\n\t\tgoto out;\n\tif (initialized)\n\t\tgoto out;\n\n\tinit_srcu_struct(&ipmi_interfaces_srcu);\n\n\ttimer_setup(&ipmi_timer, ipmi_timeout, 0);\n\tmod_timer(&ipmi_timer, jiffies + IPMI_TIMEOUT_JIFFIES);\n\n\tatomic_notifier_chain_register(&panic_notifier_list, &panic_block);\n\n\tinitialized = true;\n\nout:\n\tmutex_unlock(&ipmi_interfaces_mutex);\n\treturn rv;\n}\n\nstatic int __init ipmi_init_msghandler_mod(void)\n{\n\tint rv;\n\n\tpr_info(\"version \" IPMI_DRIVER_VERSION \"\\n\");\n\n\tmutex_lock(&ipmi_interfaces_mutex);\n\trv = ipmi_register_driver();\n\tmutex_unlock(&ipmi_interfaces_mutex);\n\n\treturn rv;\n}\n\nstatic void __exit cleanup_ipmi(void)\n{\n\tint count;\n\n\tif (initialized) {\n\t\tatomic_notifier_chain_unregister(&panic_notifier_list,\n\t\t\t\t\t\t &panic_block);\n\n\t\t/*\n\t\t * This can't be called if any interfaces exist, so no worry\n\t\t * about shutting down the interfaces.\n\t\t */\n\n\t\t/*\n\t\t * Tell the timer to stop, then wait for it to stop.  This\n\t\t * avoids problems with race conditions removing the timer\n\t\t * here.\n\t\t */\n\t\tatomic_set(&stop_operation, 1);\n\t\tdel_timer_sync(&ipmi_timer);\n\n\t\tinitialized = false;\n\n\t\t/* Check for buffer leaks. */\n\t\tcount = atomic_read(&smi_msg_inuse_count);\n\t\tif (count != 0)\n\t\t\tpr_warn(\"SMI message count %d at exit\\n\", count);\n\t\tcount = atomic_read(&recv_msg_inuse_count);\n\t\tif (count != 0)\n\t\t\tpr_warn(\"recv message count %d at exit\\n\", count);\n\n\t\tcleanup_srcu_struct(&ipmi_interfaces_srcu);\n\t}\n\tif (drvregistered)\n\t\tdriver_unregister(&ipmidriver.driver);\n}\nmodule_exit(cleanup_ipmi);\n\nmodule_init(ipmi_init_msghandler_mod);\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Corey Minyard <minyard@mvista.com>\");\nMODULE_DESCRIPTION(\"Incoming and outgoing message routing for an IPMI\"\n\t\t   \" interface.\");\nMODULE_VERSION(IPMI_DRIVER_VERSION);\nMODULE_SOFTDEP(\"post: ipmi_devintf\");\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0+\n/*\n * ipmi_msghandler.c\n *\n * Incoming and outgoing message routing for an IPMI interface.\n *\n * Author: MontaVista Software, Inc.\n *         Corey Minyard <minyard@mvista.com>\n *         source@mvista.com\n *\n * Copyright 2002 MontaVista Software Inc.\n */\n\n#define pr_fmt(fmt) \"%s\" fmt, \"IPMI message handler: \"\n#define dev_fmt pr_fmt\n\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/poll.h>\n#include <linux/sched.h>\n#include <linux/seq_file.h>\n#include <linux/spinlock.h>\n#include <linux/mutex.h>\n#include <linux/slab.h>\n#include <linux/ipmi.h>\n#include <linux/ipmi_smi.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/proc_fs.h>\n#include <linux/rcupdate.h>\n#include <linux/interrupt.h>\n#include <linux/moduleparam.h>\n#include <linux/workqueue.h>\n#include <linux/uuid.h>\n#include <linux/nospec.h>\n\n#define IPMI_DRIVER_VERSION \"39.2\"\n\nstatic struct ipmi_recv_msg *ipmi_alloc_recv_msg(void);\nstatic int ipmi_init_msghandler(void);\nstatic void smi_recv_tasklet(unsigned long);\nstatic void handle_new_recv_msgs(struct ipmi_smi *intf);\nstatic void need_waiter(struct ipmi_smi *intf);\nstatic int handle_one_recv_msg(struct ipmi_smi *intf,\n\t\t\t       struct ipmi_smi_msg *msg);\n\nstatic bool initialized;\nstatic bool drvregistered;\n\nenum ipmi_panic_event_op {\n\tIPMI_SEND_PANIC_EVENT_NONE,\n\tIPMI_SEND_PANIC_EVENT,\n\tIPMI_SEND_PANIC_EVENT_STRING\n};\n#ifdef CONFIG_IPMI_PANIC_STRING\n#define IPMI_PANIC_DEFAULT IPMI_SEND_PANIC_EVENT_STRING\n#elif defined(CONFIG_IPMI_PANIC_EVENT)\n#define IPMI_PANIC_DEFAULT IPMI_SEND_PANIC_EVENT\n#else\n#define IPMI_PANIC_DEFAULT IPMI_SEND_PANIC_EVENT_NONE\n#endif\nstatic enum ipmi_panic_event_op ipmi_send_panic_event = IPMI_PANIC_DEFAULT;\n\nstatic int panic_op_write_handler(const char *val,\n\t\t\t\t  const struct kernel_param *kp)\n{\n\tchar valcp[16];\n\tchar *s;\n\n\tstrncpy(valcp, val, 15);\n\tvalcp[15] = '\\0';\n\n\ts = strstrip(valcp);\n\n\tif (strcmp(s, \"none\") == 0)\n\t\tipmi_send_panic_event = IPMI_SEND_PANIC_EVENT_NONE;\n\telse if (strcmp(s, \"event\") == 0)\n\t\tipmi_send_panic_event = IPMI_SEND_PANIC_EVENT;\n\telse if (strcmp(s, \"string\") == 0)\n\t\tipmi_send_panic_event = IPMI_SEND_PANIC_EVENT_STRING;\n\telse\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int panic_op_read_handler(char *buffer, const struct kernel_param *kp)\n{\n\tswitch (ipmi_send_panic_event) {\n\tcase IPMI_SEND_PANIC_EVENT_NONE:\n\t\tstrcpy(buffer, \"none\");\n\t\tbreak;\n\n\tcase IPMI_SEND_PANIC_EVENT:\n\t\tstrcpy(buffer, \"event\");\n\t\tbreak;\n\n\tcase IPMI_SEND_PANIC_EVENT_STRING:\n\t\tstrcpy(buffer, \"string\");\n\t\tbreak;\n\n\tdefault:\n\t\tstrcpy(buffer, \"???\");\n\t\tbreak;\n\t}\n\n\treturn strlen(buffer);\n}\n\nstatic const struct kernel_param_ops panic_op_ops = {\n\t.set = panic_op_write_handler,\n\t.get = panic_op_read_handler\n};\nmodule_param_cb(panic_op, &panic_op_ops, NULL, 0600);\nMODULE_PARM_DESC(panic_op, \"Sets if the IPMI driver will attempt to store panic information in the event log in the event of a panic.  Set to 'none' for no, 'event' for a single event, or 'string' for a generic event and the panic string in IPMI OEM events.\");\n\n\n#define MAX_EVENTS_IN_QUEUE\t25\n\n/* Remain in auto-maintenance mode for this amount of time (in ms). */\nstatic unsigned long maintenance_mode_timeout_ms = 30000;\nmodule_param(maintenance_mode_timeout_ms, ulong, 0644);\nMODULE_PARM_DESC(maintenance_mode_timeout_ms,\n\t\t \"The time (milliseconds) after the last maintenance message that the connection stays in maintenance mode.\");\n\n/*\n * Don't let a message sit in a queue forever, always time it with at lest\n * the max message timer.  This is in milliseconds.\n */\n#define MAX_MSG_TIMEOUT\t\t60000\n\n/*\n * Timeout times below are in milliseconds, and are done off a 1\n * second timer.  So setting the value to 1000 would mean anything\n * between 0 and 1000ms.  So really the only reasonable minimum\n * setting it 2000ms, which is between 1 and 2 seconds.\n */\n\n/* The default timeout for message retries. */\nstatic unsigned long default_retry_ms = 2000;\nmodule_param(default_retry_ms, ulong, 0644);\nMODULE_PARM_DESC(default_retry_ms,\n\t\t \"The time (milliseconds) between retry sends\");\n\n/* The default timeout for maintenance mode message retries. */\nstatic unsigned long default_maintenance_retry_ms = 3000;\nmodule_param(default_maintenance_retry_ms, ulong, 0644);\nMODULE_PARM_DESC(default_maintenance_retry_ms,\n\t\t \"The time (milliseconds) between retry sends in maintenance mode\");\n\n/* The default maximum number of retries */\nstatic unsigned int default_max_retries = 4;\nmodule_param(default_max_retries, uint, 0644);\nMODULE_PARM_DESC(default_max_retries,\n\t\t \"The time (milliseconds) between retry sends in maintenance mode\");\n\n/* Call every ~1000 ms. */\n#define IPMI_TIMEOUT_TIME\t1000\n\n/* How many jiffies does it take to get to the timeout time. */\n#define IPMI_TIMEOUT_JIFFIES\t((IPMI_TIMEOUT_TIME * HZ) / 1000)\n\n/*\n * Request events from the queue every second (this is the number of\n * IPMI_TIMEOUT_TIMES between event requests).  Hopefully, in the\n * future, IPMI will add a way to know immediately if an event is in\n * the queue and this silliness can go away.\n */\n#define IPMI_REQUEST_EV_TIME\t(1000 / (IPMI_TIMEOUT_TIME))\n\n/* How long should we cache dynamic device IDs? */\n#define IPMI_DYN_DEV_ID_EXPIRY\t(10 * HZ)\n\n/*\n * The main \"user\" data structure.\n */\nstruct ipmi_user {\n\tstruct list_head link;\n\n\t/*\n\t * Set to NULL when the user is destroyed, a pointer to myself\n\t * so srcu_dereference can be used on it.\n\t */\n\tstruct ipmi_user *self;\n\tstruct srcu_struct release_barrier;\n\n\tstruct kref refcount;\n\n\t/* The upper layer that handles receive messages. */\n\tconst struct ipmi_user_hndl *handler;\n\tvoid             *handler_data;\n\n\t/* The interface this user is bound to. */\n\tstruct ipmi_smi *intf;\n\n\t/* Does this interface receive IPMI events? */\n\tbool gets_events;\n\n\t/* Free must run in process context for RCU cleanup. */\n\tstruct work_struct remove_work;\n};\n\nstatic struct ipmi_user *acquire_ipmi_user(struct ipmi_user *user, int *index)\n\t__acquires(user->release_barrier)\n{\n\tstruct ipmi_user *ruser;\n\n\t*index = srcu_read_lock(&user->release_barrier);\n\truser = srcu_dereference(user->self, &user->release_barrier);\n\tif (!ruser)\n\t\tsrcu_read_unlock(&user->release_barrier, *index);\n\treturn ruser;\n}\n\nstatic void release_ipmi_user(struct ipmi_user *user, int index)\n{\n\tsrcu_read_unlock(&user->release_barrier, index);\n}\n\nstruct cmd_rcvr {\n\tstruct list_head link;\n\n\tstruct ipmi_user *user;\n\tunsigned char netfn;\n\tunsigned char cmd;\n\tunsigned int  chans;\n\n\t/*\n\t * This is used to form a linked lised during mass deletion.\n\t * Since this is in an RCU list, we cannot use the link above\n\t * or change any data until the RCU period completes.  So we\n\t * use this next variable during mass deletion so we can have\n\t * a list and don't have to wait and restart the search on\n\t * every individual deletion of a command.\n\t */\n\tstruct cmd_rcvr *next;\n};\n\nstruct seq_table {\n\tunsigned int         inuse : 1;\n\tunsigned int         broadcast : 1;\n\n\tunsigned long        timeout;\n\tunsigned long        orig_timeout;\n\tunsigned int         retries_left;\n\n\t/*\n\t * To verify on an incoming send message response that this is\n\t * the message that the response is for, we keep a sequence id\n\t * and increment it every time we send a message.\n\t */\n\tlong                 seqid;\n\n\t/*\n\t * This is held so we can properly respond to the message on a\n\t * timeout, and it is used to hold the temporary data for\n\t * retransmission, too.\n\t */\n\tstruct ipmi_recv_msg *recv_msg;\n};\n\n/*\n * Store the information in a msgid (long) to allow us to find a\n * sequence table entry from the msgid.\n */\n#define STORE_SEQ_IN_MSGID(seq, seqid) \\\n\t((((seq) & 0x3f) << 26) | ((seqid) & 0x3ffffff))\n\n#define GET_SEQ_FROM_MSGID(msgid, seq, seqid) \\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tseq = (((msgid) >> 26) & 0x3f);\t\t\t\t\\\n\t\tseqid = ((msgid) & 0x3ffffff);\t\t\t\t\\\n\t} while (0)\n\n#define NEXT_SEQID(seqid) (((seqid) + 1) & 0x3ffffff)\n\n#define IPMI_MAX_CHANNELS       16\nstruct ipmi_channel {\n\tunsigned char medium;\n\tunsigned char protocol;\n};\n\nstruct ipmi_channel_set {\n\tstruct ipmi_channel c[IPMI_MAX_CHANNELS];\n};\n\nstruct ipmi_my_addrinfo {\n\t/*\n\t * My slave address.  This is initialized to IPMI_BMC_SLAVE_ADDR,\n\t * but may be changed by the user.\n\t */\n\tunsigned char address;\n\n\t/*\n\t * My LUN.  This should generally stay the SMS LUN, but just in\n\t * case...\n\t */\n\tunsigned char lun;\n};\n\n/*\n * Note that the product id, manufacturer id, guid, and device id are\n * immutable in this structure, so dyn_mutex is not required for\n * accessing those.  If those change on a BMC, a new BMC is allocated.\n */\nstruct bmc_device {\n\tstruct platform_device pdev;\n\tstruct list_head       intfs; /* Interfaces on this BMC. */\n\tstruct ipmi_device_id  id;\n\tstruct ipmi_device_id  fetch_id;\n\tint                    dyn_id_set;\n\tunsigned long          dyn_id_expiry;\n\tstruct mutex           dyn_mutex; /* Protects id, intfs, & dyn* */\n\tguid_t                 guid;\n\tguid_t                 fetch_guid;\n\tint                    dyn_guid_set;\n\tstruct kref\t       usecount;\n\tstruct work_struct     remove_work;\n};\n#define to_bmc_device(x) container_of((x), struct bmc_device, pdev.dev)\n\nstatic int bmc_get_device_id(struct ipmi_smi *intf, struct bmc_device *bmc,\n\t\t\t     struct ipmi_device_id *id,\n\t\t\t     bool *guid_set, guid_t *guid);\n\n/*\n * Various statistics for IPMI, these index stats[] in the ipmi_smi\n * structure.\n */\nenum ipmi_stat_indexes {\n\t/* Commands we got from the user that were invalid. */\n\tIPMI_STAT_sent_invalid_commands = 0,\n\n\t/* Commands we sent to the MC. */\n\tIPMI_STAT_sent_local_commands,\n\n\t/* Responses from the MC that were delivered to a user. */\n\tIPMI_STAT_handled_local_responses,\n\n\t/* Responses from the MC that were not delivered to a user. */\n\tIPMI_STAT_unhandled_local_responses,\n\n\t/* Commands we sent out to the IPMB bus. */\n\tIPMI_STAT_sent_ipmb_commands,\n\n\t/* Commands sent on the IPMB that had errors on the SEND CMD */\n\tIPMI_STAT_sent_ipmb_command_errs,\n\n\t/* Each retransmit increments this count. */\n\tIPMI_STAT_retransmitted_ipmb_commands,\n\n\t/*\n\t * When a message times out (runs out of retransmits) this is\n\t * incremented.\n\t */\n\tIPMI_STAT_timed_out_ipmb_commands,\n\n\t/*\n\t * This is like above, but for broadcasts.  Broadcasts are\n\t * *not* included in the above count (they are expected to\n\t * time out).\n\t */\n\tIPMI_STAT_timed_out_ipmb_broadcasts,\n\n\t/* Responses I have sent to the IPMB bus. */\n\tIPMI_STAT_sent_ipmb_responses,\n\n\t/* The response was delivered to the user. */\n\tIPMI_STAT_handled_ipmb_responses,\n\n\t/* The response had invalid data in it. */\n\tIPMI_STAT_invalid_ipmb_responses,\n\n\t/* The response didn't have anyone waiting for it. */\n\tIPMI_STAT_unhandled_ipmb_responses,\n\n\t/* Commands we sent out to the IPMB bus. */\n\tIPMI_STAT_sent_lan_commands,\n\n\t/* Commands sent on the IPMB that had errors on the SEND CMD */\n\tIPMI_STAT_sent_lan_command_errs,\n\n\t/* Each retransmit increments this count. */\n\tIPMI_STAT_retransmitted_lan_commands,\n\n\t/*\n\t * When a message times out (runs out of retransmits) this is\n\t * incremented.\n\t */\n\tIPMI_STAT_timed_out_lan_commands,\n\n\t/* Responses I have sent to the IPMB bus. */\n\tIPMI_STAT_sent_lan_responses,\n\n\t/* The response was delivered to the user. */\n\tIPMI_STAT_handled_lan_responses,\n\n\t/* The response had invalid data in it. */\n\tIPMI_STAT_invalid_lan_responses,\n\n\t/* The response didn't have anyone waiting for it. */\n\tIPMI_STAT_unhandled_lan_responses,\n\n\t/* The command was delivered to the user. */\n\tIPMI_STAT_handled_commands,\n\n\t/* The command had invalid data in it. */\n\tIPMI_STAT_invalid_commands,\n\n\t/* The command didn't have anyone waiting for it. */\n\tIPMI_STAT_unhandled_commands,\n\n\t/* Invalid data in an event. */\n\tIPMI_STAT_invalid_events,\n\n\t/* Events that were received with the proper format. */\n\tIPMI_STAT_events,\n\n\t/* Retransmissions on IPMB that failed. */\n\tIPMI_STAT_dropped_rexmit_ipmb_commands,\n\n\t/* Retransmissions on LAN that failed. */\n\tIPMI_STAT_dropped_rexmit_lan_commands,\n\n\t/* This *must* remain last, add new values above this. */\n\tIPMI_NUM_STATS\n};\n\n\n#define IPMI_IPMB_NUM_SEQ\t64\nstruct ipmi_smi {\n\tstruct module *owner;\n\n\t/* What interface number are we? */\n\tint intf_num;\n\n\tstruct kref refcount;\n\n\t/* Set when the interface is being unregistered. */\n\tbool in_shutdown;\n\n\t/* Used for a list of interfaces. */\n\tstruct list_head link;\n\n\t/*\n\t * The list of upper layers that are using me.  seq_lock write\n\t * protects this.  Read protection is with srcu.\n\t */\n\tstruct list_head users;\n\tstruct srcu_struct users_srcu;\n\n\t/* Used for wake ups at startup. */\n\twait_queue_head_t waitq;\n\n\t/*\n\t * Prevents the interface from being unregistered when the\n\t * interface is used by being looked up through the BMC\n\t * structure.\n\t */\n\tstruct mutex bmc_reg_mutex;\n\n\tstruct bmc_device tmp_bmc;\n\tstruct bmc_device *bmc;\n\tbool bmc_registered;\n\tstruct list_head bmc_link;\n\tchar *my_dev_name;\n\tbool in_bmc_register;  /* Handle recursive situations.  Yuck. */\n\tstruct work_struct bmc_reg_work;\n\n\tconst struct ipmi_smi_handlers *handlers;\n\tvoid                     *send_info;\n\n\t/* Driver-model device for the system interface. */\n\tstruct device          *si_dev;\n\n\t/*\n\t * A table of sequence numbers for this interface.  We use the\n\t * sequence numbers for IPMB messages that go out of the\n\t * interface to match them up with their responses.  A routine\n\t * is called periodically to time the items in this list.\n\t */\n\tspinlock_t       seq_lock;\n\tstruct seq_table seq_table[IPMI_IPMB_NUM_SEQ];\n\tint curr_seq;\n\n\t/*\n\t * Messages queued for delivery.  If delivery fails (out of memory\n\t * for instance), They will stay in here to be processed later in a\n\t * periodic timer interrupt.  The tasklet is for handling received\n\t * messages directly from the handler.\n\t */\n\tspinlock_t       waiting_rcv_msgs_lock;\n\tstruct list_head waiting_rcv_msgs;\n\tatomic_t\t watchdog_pretimeouts_to_deliver;\n\tstruct tasklet_struct recv_tasklet;\n\n\tspinlock_t             xmit_msgs_lock;\n\tstruct list_head       xmit_msgs;\n\tstruct ipmi_smi_msg    *curr_msg;\n\tstruct list_head       hp_xmit_msgs;\n\n\t/*\n\t * The list of command receivers that are registered for commands\n\t * on this interface.\n\t */\n\tstruct mutex     cmd_rcvrs_mutex;\n\tstruct list_head cmd_rcvrs;\n\n\t/*\n\t * Events that were queues because no one was there to receive\n\t * them.\n\t */\n\tspinlock_t       events_lock; /* For dealing with event stuff. */\n\tstruct list_head waiting_events;\n\tunsigned int     waiting_events_count; /* How many events in queue? */\n\tchar             delivering_events;\n\tchar             event_msg_printed;\n\n\t/* How many users are waiting for events? */\n\tatomic_t         event_waiters;\n\tunsigned int     ticks_to_req_ev;\n\n\tspinlock_t       watch_lock; /* For dealing with watch stuff below. */\n\n\t/* How many users are waiting for commands? */\n\tunsigned int     command_waiters;\n\n\t/* How many users are waiting for watchdogs? */\n\tunsigned int     watchdog_waiters;\n\n\t/* How many users are waiting for message responses? */\n\tunsigned int     response_waiters;\n\n\t/*\n\t * Tells what the lower layer has last been asked to watch for,\n\t * messages and/or watchdogs.  Protected by watch_lock.\n\t */\n\tunsigned int     last_watch_mask;\n\n\t/*\n\t * The event receiver for my BMC, only really used at panic\n\t * shutdown as a place to store this.\n\t */\n\tunsigned char event_receiver;\n\tunsigned char event_receiver_lun;\n\tunsigned char local_sel_device;\n\tunsigned char local_event_generator;\n\n\t/* For handling of maintenance mode. */\n\tint maintenance_mode;\n\tbool maintenance_mode_enable;\n\tint auto_maintenance_timeout;\n\tspinlock_t maintenance_mode_lock; /* Used in a timer... */\n\n\t/*\n\t * If we are doing maintenance on something on IPMB, extend\n\t * the timeout time to avoid timeouts writing firmware and\n\t * such.\n\t */\n\tint ipmb_maintenance_mode_timeout;\n\n\t/*\n\t * A cheap hack, if this is non-null and a message to an\n\t * interface comes in with a NULL user, call this routine with\n\t * it.  Note that the message will still be freed by the\n\t * caller.  This only works on the system interface.\n\t *\n\t * Protected by bmc_reg_mutex.\n\t */\n\tvoid (*null_user_handler)(struct ipmi_smi *intf,\n\t\t\t\t  struct ipmi_recv_msg *msg);\n\n\t/*\n\t * When we are scanning the channels for an SMI, this will\n\t * tell which channel we are scanning.\n\t */\n\tint curr_channel;\n\n\t/* Channel information */\n\tstruct ipmi_channel_set *channel_list;\n\tunsigned int curr_working_cset; /* First index into the following. */\n\tstruct ipmi_channel_set wchannels[2];\n\tstruct ipmi_my_addrinfo addrinfo[IPMI_MAX_CHANNELS];\n\tbool channels_ready;\n\n\tatomic_t stats[IPMI_NUM_STATS];\n\n\t/*\n\t * run_to_completion duplicate of smb_info, smi_info\n\t * and ipmi_serial_info structures. Used to decrease numbers of\n\t * parameters passed by \"low\" level IPMI code.\n\t */\n\tint run_to_completion;\n};\n#define to_si_intf_from_dev(device) container_of(device, struct ipmi_smi, dev)\n\nstatic void __get_guid(struct ipmi_smi *intf);\nstatic void __ipmi_bmc_unregister(struct ipmi_smi *intf);\nstatic int __ipmi_bmc_register(struct ipmi_smi *intf,\n\t\t\t       struct ipmi_device_id *id,\n\t\t\t       bool guid_set, guid_t *guid, int intf_num);\nstatic int __scan_channels(struct ipmi_smi *intf, struct ipmi_device_id *id);\n\n\n/**\n * The driver model view of the IPMI messaging driver.\n */\nstatic struct platform_driver ipmidriver = {\n\t.driver = {\n\t\t.name = \"ipmi\",\n\t\t.bus = &platform_bus_type\n\t}\n};\n/*\n * This mutex keeps us from adding the same BMC twice.\n */\nstatic DEFINE_MUTEX(ipmidriver_mutex);\n\nstatic LIST_HEAD(ipmi_interfaces);\nstatic DEFINE_MUTEX(ipmi_interfaces_mutex);\nstatic struct srcu_struct ipmi_interfaces_srcu;\n\n/*\n * List of watchers that want to know when smi's are added and deleted.\n */\nstatic LIST_HEAD(smi_watchers);\nstatic DEFINE_MUTEX(smi_watchers_mutex);\n\n#define ipmi_inc_stat(intf, stat) \\\n\tatomic_inc(&(intf)->stats[IPMI_STAT_ ## stat])\n#define ipmi_get_stat(intf, stat) \\\n\t((unsigned int) atomic_read(&(intf)->stats[IPMI_STAT_ ## stat]))\n\nstatic const char * const addr_src_to_str[] = {\n\t\"invalid\", \"hotmod\", \"hardcoded\", \"SPMI\", \"ACPI\", \"SMBIOS\", \"PCI\",\n\t\"device-tree\", \"platform\"\n};\n\nconst char *ipmi_addr_src_to_str(enum ipmi_addr_src src)\n{\n\tif (src >= SI_LAST)\n\t\tsrc = 0; /* Invalid */\n\treturn addr_src_to_str[src];\n}\nEXPORT_SYMBOL(ipmi_addr_src_to_str);\n\nstatic int is_lan_addr(struct ipmi_addr *addr)\n{\n\treturn addr->addr_type == IPMI_LAN_ADDR_TYPE;\n}\n\nstatic int is_ipmb_addr(struct ipmi_addr *addr)\n{\n\treturn addr->addr_type == IPMI_IPMB_ADDR_TYPE;\n}\n\nstatic int is_ipmb_bcast_addr(struct ipmi_addr *addr)\n{\n\treturn addr->addr_type == IPMI_IPMB_BROADCAST_ADDR_TYPE;\n}\n\nstatic void free_recv_msg_list(struct list_head *q)\n{\n\tstruct ipmi_recv_msg *msg, *msg2;\n\n\tlist_for_each_entry_safe(msg, msg2, q, link) {\n\t\tlist_del(&msg->link);\n\t\tipmi_free_recv_msg(msg);\n\t}\n}\n\nstatic void free_smi_msg_list(struct list_head *q)\n{\n\tstruct ipmi_smi_msg *msg, *msg2;\n\n\tlist_for_each_entry_safe(msg, msg2, q, link) {\n\t\tlist_del(&msg->link);\n\t\tipmi_free_smi_msg(msg);\n\t}\n}\n\nstatic void clean_up_interface_data(struct ipmi_smi *intf)\n{\n\tint              i;\n\tstruct cmd_rcvr  *rcvr, *rcvr2;\n\tstruct list_head list;\n\n\ttasklet_kill(&intf->recv_tasklet);\n\n\tfree_smi_msg_list(&intf->waiting_rcv_msgs);\n\tfree_recv_msg_list(&intf->waiting_events);\n\n\t/*\n\t * Wholesale remove all the entries from the list in the\n\t * interface and wait for RCU to know that none are in use.\n\t */\n\tmutex_lock(&intf->cmd_rcvrs_mutex);\n\tINIT_LIST_HEAD(&list);\n\tlist_splice_init_rcu(&intf->cmd_rcvrs, &list, synchronize_rcu);\n\tmutex_unlock(&intf->cmd_rcvrs_mutex);\n\n\tlist_for_each_entry_safe(rcvr, rcvr2, &list, link)\n\t\tkfree(rcvr);\n\n\tfor (i = 0; i < IPMI_IPMB_NUM_SEQ; i++) {\n\t\tif ((intf->seq_table[i].inuse)\n\t\t\t\t\t&& (intf->seq_table[i].recv_msg))\n\t\t\tipmi_free_recv_msg(intf->seq_table[i].recv_msg);\n\t}\n}\n\nstatic void intf_free(struct kref *ref)\n{\n\tstruct ipmi_smi *intf = container_of(ref, struct ipmi_smi, refcount);\n\n\tclean_up_interface_data(intf);\n\tkfree(intf);\n}\n\nstruct watcher_entry {\n\tint              intf_num;\n\tstruct ipmi_smi  *intf;\n\tstruct list_head link;\n};\n\nint ipmi_smi_watcher_register(struct ipmi_smi_watcher *watcher)\n{\n\tstruct ipmi_smi *intf;\n\tint index, rv;\n\n\t/*\n\t * Make sure the driver is actually initialized, this handles\n\t * problems with initialization order.\n\t */\n\trv = ipmi_init_msghandler();\n\tif (rv)\n\t\treturn rv;\n\n\tmutex_lock(&smi_watchers_mutex);\n\n\tlist_add(&watcher->link, &smi_watchers);\n\n\tindex = srcu_read_lock(&ipmi_interfaces_srcu);\n\tlist_for_each_entry_rcu(intf, &ipmi_interfaces, link) {\n\t\tint intf_num = READ_ONCE(intf->intf_num);\n\n\t\tif (intf_num == -1)\n\t\t\tcontinue;\n\t\twatcher->new_smi(intf_num, intf->si_dev);\n\t}\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\n\tmutex_unlock(&smi_watchers_mutex);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(ipmi_smi_watcher_register);\n\nint ipmi_smi_watcher_unregister(struct ipmi_smi_watcher *watcher)\n{\n\tmutex_lock(&smi_watchers_mutex);\n\tlist_del(&watcher->link);\n\tmutex_unlock(&smi_watchers_mutex);\n\treturn 0;\n}\nEXPORT_SYMBOL(ipmi_smi_watcher_unregister);\n\n/*\n * Must be called with smi_watchers_mutex held.\n */\nstatic void\ncall_smi_watchers(int i, struct device *dev)\n{\n\tstruct ipmi_smi_watcher *w;\n\n\tmutex_lock(&smi_watchers_mutex);\n\tlist_for_each_entry(w, &smi_watchers, link) {\n\t\tif (try_module_get(w->owner)) {\n\t\t\tw->new_smi(i, dev);\n\t\t\tmodule_put(w->owner);\n\t\t}\n\t}\n\tmutex_unlock(&smi_watchers_mutex);\n}\n\nstatic int\nipmi_addr_equal(struct ipmi_addr *addr1, struct ipmi_addr *addr2)\n{\n\tif (addr1->addr_type != addr2->addr_type)\n\t\treturn 0;\n\n\tif (addr1->channel != addr2->channel)\n\t\treturn 0;\n\n\tif (addr1->addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE) {\n\t\tstruct ipmi_system_interface_addr *smi_addr1\n\t\t    = (struct ipmi_system_interface_addr *) addr1;\n\t\tstruct ipmi_system_interface_addr *smi_addr2\n\t\t    = (struct ipmi_system_interface_addr *) addr2;\n\t\treturn (smi_addr1->lun == smi_addr2->lun);\n\t}\n\n\tif (is_ipmb_addr(addr1) || is_ipmb_bcast_addr(addr1)) {\n\t\tstruct ipmi_ipmb_addr *ipmb_addr1\n\t\t    = (struct ipmi_ipmb_addr *) addr1;\n\t\tstruct ipmi_ipmb_addr *ipmb_addr2\n\t\t    = (struct ipmi_ipmb_addr *) addr2;\n\n\t\treturn ((ipmb_addr1->slave_addr == ipmb_addr2->slave_addr)\n\t\t\t&& (ipmb_addr1->lun == ipmb_addr2->lun));\n\t}\n\n\tif (is_lan_addr(addr1)) {\n\t\tstruct ipmi_lan_addr *lan_addr1\n\t\t\t= (struct ipmi_lan_addr *) addr1;\n\t\tstruct ipmi_lan_addr *lan_addr2\n\t\t    = (struct ipmi_lan_addr *) addr2;\n\n\t\treturn ((lan_addr1->remote_SWID == lan_addr2->remote_SWID)\n\t\t\t&& (lan_addr1->local_SWID == lan_addr2->local_SWID)\n\t\t\t&& (lan_addr1->session_handle\n\t\t\t    == lan_addr2->session_handle)\n\t\t\t&& (lan_addr1->lun == lan_addr2->lun));\n\t}\n\n\treturn 1;\n}\n\nint ipmi_validate_addr(struct ipmi_addr *addr, int len)\n{\n\tif (len < sizeof(struct ipmi_system_interface_addr))\n\t\treturn -EINVAL;\n\n\tif (addr->addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE) {\n\t\tif (addr->channel != IPMI_BMC_CHANNEL)\n\t\t\treturn -EINVAL;\n\t\treturn 0;\n\t}\n\n\tif ((addr->channel == IPMI_BMC_CHANNEL)\n\t    || (addr->channel >= IPMI_MAX_CHANNELS)\n\t    || (addr->channel < 0))\n\t\treturn -EINVAL;\n\n\tif (is_ipmb_addr(addr) || is_ipmb_bcast_addr(addr)) {\n\t\tif (len < sizeof(struct ipmi_ipmb_addr))\n\t\t\treturn -EINVAL;\n\t\treturn 0;\n\t}\n\n\tif (is_lan_addr(addr)) {\n\t\tif (len < sizeof(struct ipmi_lan_addr))\n\t\t\treturn -EINVAL;\n\t\treturn 0;\n\t}\n\n\treturn -EINVAL;\n}\nEXPORT_SYMBOL(ipmi_validate_addr);\n\nunsigned int ipmi_addr_length(int addr_type)\n{\n\tif (addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t\treturn sizeof(struct ipmi_system_interface_addr);\n\n\tif ((addr_type == IPMI_IPMB_ADDR_TYPE)\n\t\t\t|| (addr_type == IPMI_IPMB_BROADCAST_ADDR_TYPE))\n\t\treturn sizeof(struct ipmi_ipmb_addr);\n\n\tif (addr_type == IPMI_LAN_ADDR_TYPE)\n\t\treturn sizeof(struct ipmi_lan_addr);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(ipmi_addr_length);\n\nstatic int deliver_response(struct ipmi_smi *intf, struct ipmi_recv_msg *msg)\n{\n\tint rv = 0;\n\n\tif (!msg->user) {\n\t\t/* Special handling for NULL users. */\n\t\tif (intf->null_user_handler) {\n\t\t\tintf->null_user_handler(intf, msg);\n\t\t} else {\n\t\t\t/* No handler, so give up. */\n\t\t\trv = -EINVAL;\n\t\t}\n\t\tipmi_free_recv_msg(msg);\n\t} else if (oops_in_progress) {\n\t\t/*\n\t\t * If we are running in the panic context, calling the\n\t\t * receive handler doesn't much meaning and has a deadlock\n\t\t * risk.  At this moment, simply skip it in that case.\n\t\t */\n\t\tipmi_free_recv_msg(msg);\n\t} else {\n\t\tint index;\n\t\tstruct ipmi_user *user = acquire_ipmi_user(msg->user, &index);\n\n\t\tif (user) {\n\t\t\tuser->handler->ipmi_recv_hndl(msg, user->handler_data);\n\t\t\trelease_ipmi_user(user, index);\n\t\t} else {\n\t\t\t/* User went away, give up. */\n\t\t\tipmi_free_recv_msg(msg);\n\t\t\trv = -EINVAL;\n\t\t}\n\t}\n\n\treturn rv;\n}\n\nstatic void deliver_local_response(struct ipmi_smi *intf,\n\t\t\t\t   struct ipmi_recv_msg *msg)\n{\n\tif (deliver_response(intf, msg))\n\t\tipmi_inc_stat(intf, unhandled_local_responses);\n\telse\n\t\tipmi_inc_stat(intf, handled_local_responses);\n}\n\nstatic void deliver_err_response(struct ipmi_smi *intf,\n\t\t\t\t struct ipmi_recv_msg *msg, int err)\n{\n\tmsg->recv_type = IPMI_RESPONSE_RECV_TYPE;\n\tmsg->msg_data[0] = err;\n\tmsg->msg.netfn |= 1; /* Convert to a response. */\n\tmsg->msg.data_len = 1;\n\tmsg->msg.data = msg->msg_data;\n\tdeliver_local_response(intf, msg);\n}\n\nstatic void smi_add_watch(struct ipmi_smi *intf, unsigned int flags)\n{\n\tunsigned long iflags;\n\n\tif (!intf->handlers->set_need_watch)\n\t\treturn;\n\n\tspin_lock_irqsave(&intf->watch_lock, iflags);\n\tif (flags & IPMI_WATCH_MASK_CHECK_MESSAGES)\n\t\tintf->response_waiters++;\n\n\tif (flags & IPMI_WATCH_MASK_CHECK_WATCHDOG)\n\t\tintf->watchdog_waiters++;\n\n\tif (flags & IPMI_WATCH_MASK_CHECK_COMMANDS)\n\t\tintf->command_waiters++;\n\n\tif ((intf->last_watch_mask & flags) != flags) {\n\t\tintf->last_watch_mask |= flags;\n\t\tintf->handlers->set_need_watch(intf->send_info,\n\t\t\t\t\t       intf->last_watch_mask);\n\t}\n\tspin_unlock_irqrestore(&intf->watch_lock, iflags);\n}\n\nstatic void smi_remove_watch(struct ipmi_smi *intf, unsigned int flags)\n{\n\tunsigned long iflags;\n\n\tif (!intf->handlers->set_need_watch)\n\t\treturn;\n\n\tspin_lock_irqsave(&intf->watch_lock, iflags);\n\tif (flags & IPMI_WATCH_MASK_CHECK_MESSAGES)\n\t\tintf->response_waiters--;\n\n\tif (flags & IPMI_WATCH_MASK_CHECK_WATCHDOG)\n\t\tintf->watchdog_waiters--;\n\n\tif (flags & IPMI_WATCH_MASK_CHECK_COMMANDS)\n\t\tintf->command_waiters--;\n\n\tflags = 0;\n\tif (intf->response_waiters)\n\t\tflags |= IPMI_WATCH_MASK_CHECK_MESSAGES;\n\tif (intf->watchdog_waiters)\n\t\tflags |= IPMI_WATCH_MASK_CHECK_WATCHDOG;\n\tif (intf->command_waiters)\n\t\tflags |= IPMI_WATCH_MASK_CHECK_COMMANDS;\n\n\tif (intf->last_watch_mask != flags) {\n\t\tintf->last_watch_mask = flags;\n\t\tintf->handlers->set_need_watch(intf->send_info,\n\t\t\t\t\t       intf->last_watch_mask);\n\t}\n\tspin_unlock_irqrestore(&intf->watch_lock, iflags);\n}\n\n/*\n * Find the next sequence number not being used and add the given\n * message with the given timeout to the sequence table.  This must be\n * called with the interface's seq_lock held.\n */\nstatic int intf_next_seq(struct ipmi_smi      *intf,\n\t\t\t struct ipmi_recv_msg *recv_msg,\n\t\t\t unsigned long        timeout,\n\t\t\t int                  retries,\n\t\t\t int                  broadcast,\n\t\t\t unsigned char        *seq,\n\t\t\t long                 *seqid)\n{\n\tint          rv = 0;\n\tunsigned int i;\n\n\tif (timeout == 0)\n\t\ttimeout = default_retry_ms;\n\tif (retries < 0)\n\t\tretries = default_max_retries;\n\n\tfor (i = intf->curr_seq; (i+1)%IPMI_IPMB_NUM_SEQ != intf->curr_seq;\n\t\t\t\t\ti = (i+1)%IPMI_IPMB_NUM_SEQ) {\n\t\tif (!intf->seq_table[i].inuse)\n\t\t\tbreak;\n\t}\n\n\tif (!intf->seq_table[i].inuse) {\n\t\tintf->seq_table[i].recv_msg = recv_msg;\n\n\t\t/*\n\t\t * Start with the maximum timeout, when the send response\n\t\t * comes in we will start the real timer.\n\t\t */\n\t\tintf->seq_table[i].timeout = MAX_MSG_TIMEOUT;\n\t\tintf->seq_table[i].orig_timeout = timeout;\n\t\tintf->seq_table[i].retries_left = retries;\n\t\tintf->seq_table[i].broadcast = broadcast;\n\t\tintf->seq_table[i].inuse = 1;\n\t\tintf->seq_table[i].seqid = NEXT_SEQID(intf->seq_table[i].seqid);\n\t\t*seq = i;\n\t\t*seqid = intf->seq_table[i].seqid;\n\t\tintf->curr_seq = (i+1)%IPMI_IPMB_NUM_SEQ;\n\t\tsmi_add_watch(intf, IPMI_WATCH_MASK_CHECK_MESSAGES);\n\t\tneed_waiter(intf);\n\t} else {\n\t\trv = -EAGAIN;\n\t}\n\n\treturn rv;\n}\n\n/*\n * Return the receive message for the given sequence number and\n * release the sequence number so it can be reused.  Some other data\n * is passed in to be sure the message matches up correctly (to help\n * guard against message coming in after their timeout and the\n * sequence number being reused).\n */\nstatic int intf_find_seq(struct ipmi_smi      *intf,\n\t\t\t unsigned char        seq,\n\t\t\t short                channel,\n\t\t\t unsigned char        cmd,\n\t\t\t unsigned char        netfn,\n\t\t\t struct ipmi_addr     *addr,\n\t\t\t struct ipmi_recv_msg **recv_msg)\n{\n\tint           rv = -ENODEV;\n\tunsigned long flags;\n\n\tif (seq >= IPMI_IPMB_NUM_SEQ)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\tif (intf->seq_table[seq].inuse) {\n\t\tstruct ipmi_recv_msg *msg = intf->seq_table[seq].recv_msg;\n\n\t\tif ((msg->addr.channel == channel) && (msg->msg.cmd == cmd)\n\t\t\t\t&& (msg->msg.netfn == netfn)\n\t\t\t\t&& (ipmi_addr_equal(addr, &msg->addr))) {\n\t\t\t*recv_msg = msg;\n\t\t\tintf->seq_table[seq].inuse = 0;\n\t\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_MESSAGES);\n\t\t\trv = 0;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\n\treturn rv;\n}\n\n\n/* Start the timer for a specific sequence table entry. */\nstatic int intf_start_seq_timer(struct ipmi_smi *intf,\n\t\t\t\tlong       msgid)\n{\n\tint           rv = -ENODEV;\n\tunsigned long flags;\n\tunsigned char seq;\n\tunsigned long seqid;\n\n\n\tGET_SEQ_FROM_MSGID(msgid, seq, seqid);\n\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\t/*\n\t * We do this verification because the user can be deleted\n\t * while a message is outstanding.\n\t */\n\tif ((intf->seq_table[seq].inuse)\n\t\t\t\t&& (intf->seq_table[seq].seqid == seqid)) {\n\t\tstruct seq_table *ent = &intf->seq_table[seq];\n\t\tent->timeout = ent->orig_timeout;\n\t\trv = 0;\n\t}\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\n\treturn rv;\n}\n\n/* Got an error for the send message for a specific sequence number. */\nstatic int intf_err_seq(struct ipmi_smi *intf,\n\t\t\tlong         msgid,\n\t\t\tunsigned int err)\n{\n\tint                  rv = -ENODEV;\n\tunsigned long        flags;\n\tunsigned char        seq;\n\tunsigned long        seqid;\n\tstruct ipmi_recv_msg *msg = NULL;\n\n\n\tGET_SEQ_FROM_MSGID(msgid, seq, seqid);\n\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\t/*\n\t * We do this verification because the user can be deleted\n\t * while a message is outstanding.\n\t */\n\tif ((intf->seq_table[seq].inuse)\n\t\t\t\t&& (intf->seq_table[seq].seqid == seqid)) {\n\t\tstruct seq_table *ent = &intf->seq_table[seq];\n\n\t\tent->inuse = 0;\n\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_MESSAGES);\n\t\tmsg = ent->recv_msg;\n\t\trv = 0;\n\t}\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\n\tif (msg)\n\t\tdeliver_err_response(intf, msg, err);\n\n\treturn rv;\n}\n\nstatic void free_user_work(struct work_struct *work)\n{\n\tstruct ipmi_user *user = container_of(work, struct ipmi_user,\n\t\t\t\t\t      remove_work);\n\n\tcleanup_srcu_struct(&user->release_barrier);\n\tkfree(user);\n}\n\nint ipmi_create_user(unsigned int          if_num,\n\t\t     const struct ipmi_user_hndl *handler,\n\t\t     void                  *handler_data,\n\t\t     struct ipmi_user      **user)\n{\n\tunsigned long flags;\n\tstruct ipmi_user *new_user;\n\tint           rv, index;\n\tstruct ipmi_smi *intf;\n\n\t/*\n\t * There is no module usecount here, because it's not\n\t * required.  Since this can only be used by and called from\n\t * other modules, they will implicitly use this module, and\n\t * thus this can't be removed unless the other modules are\n\t * removed.\n\t */\n\n\tif (handler == NULL)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Make sure the driver is actually initialized, this handles\n\t * problems with initialization order.\n\t */\n\trv = ipmi_init_msghandler();\n\tif (rv)\n\t\treturn rv;\n\n\tnew_user = kmalloc(sizeof(*new_user), GFP_KERNEL);\n\tif (!new_user)\n\t\treturn -ENOMEM;\n\n\tindex = srcu_read_lock(&ipmi_interfaces_srcu);\n\tlist_for_each_entry_rcu(intf, &ipmi_interfaces, link) {\n\t\tif (intf->intf_num == if_num)\n\t\t\tgoto found;\n\t}\n\t/* Not found, return an error */\n\trv = -EINVAL;\n\tgoto out_kfree;\n\n found:\n\tINIT_WORK(&new_user->remove_work, free_user_work);\n\n\trv = init_srcu_struct(&new_user->release_barrier);\n\tif (rv)\n\t\tgoto out_kfree;\n\n\tif (!try_module_get(intf->owner)) {\n\t\trv = -ENODEV;\n\t\tgoto out_kfree;\n\t}\n\n\t/* Note that each existing user holds a refcount to the interface. */\n\tkref_get(&intf->refcount);\n\n\tkref_init(&new_user->refcount);\n\tnew_user->handler = handler;\n\tnew_user->handler_data = handler_data;\n\tnew_user->intf = intf;\n\tnew_user->gets_events = false;\n\n\trcu_assign_pointer(new_user->self, new_user);\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\tlist_add_rcu(&new_user->link, &intf->users);\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\tif (handler->ipmi_watchdog_pretimeout)\n\t\t/* User wants pretimeouts, so make sure to watch for them. */\n\t\tsmi_add_watch(intf, IPMI_WATCH_MASK_CHECK_WATCHDOG);\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\t*user = new_user;\n\treturn 0;\n\nout_kfree:\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\tkfree(new_user);\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_create_user);\n\nint ipmi_get_smi_info(int if_num, struct ipmi_smi_info *data)\n{\n\tint rv, index;\n\tstruct ipmi_smi *intf;\n\n\tindex = srcu_read_lock(&ipmi_interfaces_srcu);\n\tlist_for_each_entry_rcu(intf, &ipmi_interfaces, link) {\n\t\tif (intf->intf_num == if_num)\n\t\t\tgoto found;\n\t}\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\n\t/* Not found, return an error */\n\treturn -EINVAL;\n\nfound:\n\tif (!intf->handlers->get_smi_info)\n\t\trv = -ENOTTY;\n\telse\n\t\trv = intf->handlers->get_smi_info(intf->send_info, data);\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_get_smi_info);\n\nstatic void free_user(struct kref *ref)\n{\n\tstruct ipmi_user *user = container_of(ref, struct ipmi_user, refcount);\n\n\t/* SRCU cleanup must happen in task context. */\n\tschedule_work(&user->remove_work);\n}\n\nstatic void _ipmi_destroy_user(struct ipmi_user *user)\n{\n\tstruct ipmi_smi  *intf = user->intf;\n\tint              i;\n\tunsigned long    flags;\n\tstruct cmd_rcvr  *rcvr;\n\tstruct cmd_rcvr  *rcvrs = NULL;\n\n\tif (!acquire_ipmi_user(user, &i)) {\n\t\t/*\n\t\t * The user has already been cleaned up, just make sure\n\t\t * nothing is using it and return.\n\t\t */\n\t\tsynchronize_srcu(&user->release_barrier);\n\t\treturn;\n\t}\n\n\trcu_assign_pointer(user->self, NULL);\n\trelease_ipmi_user(user, i);\n\n\tsynchronize_srcu(&user->release_barrier);\n\n\tif (user->handler->shutdown)\n\t\tuser->handler->shutdown(user->handler_data);\n\n\tif (user->handler->ipmi_watchdog_pretimeout)\n\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_WATCHDOG);\n\n\tif (user->gets_events)\n\t\tatomic_dec(&intf->event_waiters);\n\n\t/* Remove the user from the interface's sequence table. */\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\tlist_del_rcu(&user->link);\n\n\tfor (i = 0; i < IPMI_IPMB_NUM_SEQ; i++) {\n\t\tif (intf->seq_table[i].inuse\n\t\t    && (intf->seq_table[i].recv_msg->user == user)) {\n\t\t\tintf->seq_table[i].inuse = 0;\n\t\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_MESSAGES);\n\t\t\tipmi_free_recv_msg(intf->seq_table[i].recv_msg);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\n\t/*\n\t * Remove the user from the command receiver's table.  First\n\t * we build a list of everything (not using the standard link,\n\t * since other things may be using it till we do\n\t * synchronize_srcu()) then free everything in that list.\n\t */\n\tmutex_lock(&intf->cmd_rcvrs_mutex);\n\tlist_for_each_entry_rcu(rcvr, &intf->cmd_rcvrs, link) {\n\t\tif (rcvr->user == user) {\n\t\t\tlist_del_rcu(&rcvr->link);\n\t\t\trcvr->next = rcvrs;\n\t\t\trcvrs = rcvr;\n\t\t}\n\t}\n\tmutex_unlock(&intf->cmd_rcvrs_mutex);\n\tsynchronize_rcu();\n\twhile (rcvrs) {\n\t\trcvr = rcvrs;\n\t\trcvrs = rcvr->next;\n\t\tkfree(rcvr);\n\t}\n\n\tkref_put(&intf->refcount, intf_free);\n\tmodule_put(intf->owner);\n}\n\nint ipmi_destroy_user(struct ipmi_user *user)\n{\n\t_ipmi_destroy_user(user);\n\n\tkref_put(&user->refcount, free_user);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(ipmi_destroy_user);\n\nint ipmi_get_version(struct ipmi_user *user,\n\t\t     unsigned char *major,\n\t\t     unsigned char *minor)\n{\n\tstruct ipmi_device_id id;\n\tint rv, index;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\trv = bmc_get_device_id(user->intf, NULL, &id, NULL, NULL);\n\tif (!rv) {\n\t\t*major = ipmi_version_major(&id);\n\t\t*minor = ipmi_version_minor(&id);\n\t}\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_get_version);\n\nint ipmi_set_my_address(struct ipmi_user *user,\n\t\t\tunsigned int  channel,\n\t\t\tunsigned char address)\n{\n\tint index, rv = 0;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tif (channel >= IPMI_MAX_CHANNELS) {\n\t\trv = -EINVAL;\n\t} else {\n\t\tchannel = array_index_nospec(channel, IPMI_MAX_CHANNELS);\n\t\tuser->intf->addrinfo[channel].address = address;\n\t}\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_set_my_address);\n\nint ipmi_get_my_address(struct ipmi_user *user,\n\t\t\tunsigned int  channel,\n\t\t\tunsigned char *address)\n{\n\tint index, rv = 0;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tif (channel >= IPMI_MAX_CHANNELS) {\n\t\trv = -EINVAL;\n\t} else {\n\t\tchannel = array_index_nospec(channel, IPMI_MAX_CHANNELS);\n\t\t*address = user->intf->addrinfo[channel].address;\n\t}\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_get_my_address);\n\nint ipmi_set_my_LUN(struct ipmi_user *user,\n\t\t    unsigned int  channel,\n\t\t    unsigned char LUN)\n{\n\tint index, rv = 0;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tif (channel >= IPMI_MAX_CHANNELS) {\n\t\trv = -EINVAL;\n\t} else {\n\t\tchannel = array_index_nospec(channel, IPMI_MAX_CHANNELS);\n\t\tuser->intf->addrinfo[channel].lun = LUN & 0x3;\n\t}\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_set_my_LUN);\n\nint ipmi_get_my_LUN(struct ipmi_user *user,\n\t\t    unsigned int  channel,\n\t\t    unsigned char *address)\n{\n\tint index, rv = 0;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tif (channel >= IPMI_MAX_CHANNELS) {\n\t\trv = -EINVAL;\n\t} else {\n\t\tchannel = array_index_nospec(channel, IPMI_MAX_CHANNELS);\n\t\t*address = user->intf->addrinfo[channel].lun;\n\t}\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_get_my_LUN);\n\nint ipmi_get_maintenance_mode(struct ipmi_user *user)\n{\n\tint mode, index;\n\tunsigned long flags;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tspin_lock_irqsave(&user->intf->maintenance_mode_lock, flags);\n\tmode = user->intf->maintenance_mode;\n\tspin_unlock_irqrestore(&user->intf->maintenance_mode_lock, flags);\n\trelease_ipmi_user(user, index);\n\n\treturn mode;\n}\nEXPORT_SYMBOL(ipmi_get_maintenance_mode);\n\nstatic void maintenance_mode_update(struct ipmi_smi *intf)\n{\n\tif (intf->handlers->set_maintenance_mode)\n\t\tintf->handlers->set_maintenance_mode(\n\t\t\tintf->send_info, intf->maintenance_mode_enable);\n}\n\nint ipmi_set_maintenance_mode(struct ipmi_user *user, int mode)\n{\n\tint rv = 0, index;\n\tunsigned long flags;\n\tstruct ipmi_smi *intf = user->intf;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tspin_lock_irqsave(&intf->maintenance_mode_lock, flags);\n\tif (intf->maintenance_mode != mode) {\n\t\tswitch (mode) {\n\t\tcase IPMI_MAINTENANCE_MODE_AUTO:\n\t\t\tintf->maintenance_mode_enable\n\t\t\t\t= (intf->auto_maintenance_timeout > 0);\n\t\t\tbreak;\n\n\t\tcase IPMI_MAINTENANCE_MODE_OFF:\n\t\t\tintf->maintenance_mode_enable = false;\n\t\t\tbreak;\n\n\t\tcase IPMI_MAINTENANCE_MODE_ON:\n\t\t\tintf->maintenance_mode_enable = true;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\trv = -EINVAL;\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tintf->maintenance_mode = mode;\n\n\t\tmaintenance_mode_update(intf);\n\t}\n out_unlock:\n\tspin_unlock_irqrestore(&intf->maintenance_mode_lock, flags);\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_set_maintenance_mode);\n\nint ipmi_set_gets_events(struct ipmi_user *user, bool val)\n{\n\tunsigned long        flags;\n\tstruct ipmi_smi      *intf = user->intf;\n\tstruct ipmi_recv_msg *msg, *msg2;\n\tstruct list_head     msgs;\n\tint index;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tINIT_LIST_HEAD(&msgs);\n\n\tspin_lock_irqsave(&intf->events_lock, flags);\n\tif (user->gets_events == val)\n\t\tgoto out;\n\n\tuser->gets_events = val;\n\n\tif (val) {\n\t\tif (atomic_inc_return(&intf->event_waiters) == 1)\n\t\t\tneed_waiter(intf);\n\t} else {\n\t\tatomic_dec(&intf->event_waiters);\n\t}\n\n\tif (intf->delivering_events)\n\t\t/*\n\t\t * Another thread is delivering events for this, so\n\t\t * let it handle any new events.\n\t\t */\n\t\tgoto out;\n\n\t/* Deliver any queued events. */\n\twhile (user->gets_events && !list_empty(&intf->waiting_events)) {\n\t\tlist_for_each_entry_safe(msg, msg2, &intf->waiting_events, link)\n\t\t\tlist_move_tail(&msg->link, &msgs);\n\t\tintf->waiting_events_count = 0;\n\t\tif (intf->event_msg_printed) {\n\t\t\tdev_warn(intf->si_dev, \"Event queue no longer full\\n\");\n\t\t\tintf->event_msg_printed = 0;\n\t\t}\n\n\t\tintf->delivering_events = 1;\n\t\tspin_unlock_irqrestore(&intf->events_lock, flags);\n\n\t\tlist_for_each_entry_safe(msg, msg2, &msgs, link) {\n\t\t\tmsg->user = user;\n\t\t\tkref_get(&user->refcount);\n\t\t\tdeliver_local_response(intf, msg);\n\t\t}\n\n\t\tspin_lock_irqsave(&intf->events_lock, flags);\n\t\tintf->delivering_events = 0;\n\t}\n\n out:\n\tspin_unlock_irqrestore(&intf->events_lock, flags);\n\trelease_ipmi_user(user, index);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(ipmi_set_gets_events);\n\nstatic struct cmd_rcvr *find_cmd_rcvr(struct ipmi_smi *intf,\n\t\t\t\t      unsigned char netfn,\n\t\t\t\t      unsigned char cmd,\n\t\t\t\t      unsigned char chan)\n{\n\tstruct cmd_rcvr *rcvr;\n\n\tlist_for_each_entry_rcu(rcvr, &intf->cmd_rcvrs, link) {\n\t\tif ((rcvr->netfn == netfn) && (rcvr->cmd == cmd)\n\t\t\t\t\t&& (rcvr->chans & (1 << chan)))\n\t\t\treturn rcvr;\n\t}\n\treturn NULL;\n}\n\nstatic int is_cmd_rcvr_exclusive(struct ipmi_smi *intf,\n\t\t\t\t unsigned char netfn,\n\t\t\t\t unsigned char cmd,\n\t\t\t\t unsigned int  chans)\n{\n\tstruct cmd_rcvr *rcvr;\n\n\tlist_for_each_entry_rcu(rcvr, &intf->cmd_rcvrs, link) {\n\t\tif ((rcvr->netfn == netfn) && (rcvr->cmd == cmd)\n\t\t\t\t\t&& (rcvr->chans & chans))\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nint ipmi_register_for_cmd(struct ipmi_user *user,\n\t\t\t  unsigned char netfn,\n\t\t\t  unsigned char cmd,\n\t\t\t  unsigned int  chans)\n{\n\tstruct ipmi_smi *intf = user->intf;\n\tstruct cmd_rcvr *rcvr;\n\tint rv = 0, index;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\trcvr = kmalloc(sizeof(*rcvr), GFP_KERNEL);\n\tif (!rcvr) {\n\t\trv = -ENOMEM;\n\t\tgoto out_release;\n\t}\n\trcvr->cmd = cmd;\n\trcvr->netfn = netfn;\n\trcvr->chans = chans;\n\trcvr->user = user;\n\n\tmutex_lock(&intf->cmd_rcvrs_mutex);\n\t/* Make sure the command/netfn is not already registered. */\n\tif (!is_cmd_rcvr_exclusive(intf, netfn, cmd, chans)) {\n\t\trv = -EBUSY;\n\t\tgoto out_unlock;\n\t}\n\n\tsmi_add_watch(intf, IPMI_WATCH_MASK_CHECK_COMMANDS);\n\n\tlist_add_rcu(&rcvr->link, &intf->cmd_rcvrs);\n\nout_unlock:\n\tmutex_unlock(&intf->cmd_rcvrs_mutex);\n\tif (rv)\n\t\tkfree(rcvr);\nout_release:\n\trelease_ipmi_user(user, index);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_register_for_cmd);\n\nint ipmi_unregister_for_cmd(struct ipmi_user *user,\n\t\t\t    unsigned char netfn,\n\t\t\t    unsigned char cmd,\n\t\t\t    unsigned int  chans)\n{\n\tstruct ipmi_smi *intf = user->intf;\n\tstruct cmd_rcvr *rcvr;\n\tstruct cmd_rcvr *rcvrs = NULL;\n\tint i, rv = -ENOENT, index;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\tmutex_lock(&intf->cmd_rcvrs_mutex);\n\tfor (i = 0; i < IPMI_NUM_CHANNELS; i++) {\n\t\tif (((1 << i) & chans) == 0)\n\t\t\tcontinue;\n\t\trcvr = find_cmd_rcvr(intf, netfn, cmd, i);\n\t\tif (rcvr == NULL)\n\t\t\tcontinue;\n\t\tif (rcvr->user == user) {\n\t\t\trv = 0;\n\t\t\trcvr->chans &= ~chans;\n\t\t\tif (rcvr->chans == 0) {\n\t\t\t\tlist_del_rcu(&rcvr->link);\n\t\t\t\trcvr->next = rcvrs;\n\t\t\t\trcvrs = rcvr;\n\t\t\t}\n\t\t}\n\t}\n\tmutex_unlock(&intf->cmd_rcvrs_mutex);\n\tsynchronize_rcu();\n\trelease_ipmi_user(user, index);\n\twhile (rcvrs) {\n\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_COMMANDS);\n\t\trcvr = rcvrs;\n\t\trcvrs = rcvr->next;\n\t\tkfree(rcvr);\n\t}\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_unregister_for_cmd);\n\nstatic unsigned char\nipmb_checksum(unsigned char *data, int size)\n{\n\tunsigned char csum = 0;\n\n\tfor (; size > 0; size--, data++)\n\t\tcsum += *data;\n\n\treturn -csum;\n}\n\nstatic inline void format_ipmb_msg(struct ipmi_smi_msg   *smi_msg,\n\t\t\t\t   struct kernel_ipmi_msg *msg,\n\t\t\t\t   struct ipmi_ipmb_addr *ipmb_addr,\n\t\t\t\t   long                  msgid,\n\t\t\t\t   unsigned char         ipmb_seq,\n\t\t\t\t   int                   broadcast,\n\t\t\t\t   unsigned char         source_address,\n\t\t\t\t   unsigned char         source_lun)\n{\n\tint i = broadcast;\n\n\t/* Format the IPMB header data. */\n\tsmi_msg->data[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\tsmi_msg->data[1] = IPMI_SEND_MSG_CMD;\n\tsmi_msg->data[2] = ipmb_addr->channel;\n\tif (broadcast)\n\t\tsmi_msg->data[3] = 0;\n\tsmi_msg->data[i+3] = ipmb_addr->slave_addr;\n\tsmi_msg->data[i+4] = (msg->netfn << 2) | (ipmb_addr->lun & 0x3);\n\tsmi_msg->data[i+5] = ipmb_checksum(&smi_msg->data[i + 3], 2);\n\tsmi_msg->data[i+6] = source_address;\n\tsmi_msg->data[i+7] = (ipmb_seq << 2) | source_lun;\n\tsmi_msg->data[i+8] = msg->cmd;\n\n\t/* Now tack on the data to the message. */\n\tif (msg->data_len > 0)\n\t\tmemcpy(&smi_msg->data[i + 9], msg->data, msg->data_len);\n\tsmi_msg->data_size = msg->data_len + 9;\n\n\t/* Now calculate the checksum and tack it on. */\n\tsmi_msg->data[i+smi_msg->data_size]\n\t\t= ipmb_checksum(&smi_msg->data[i + 6], smi_msg->data_size - 6);\n\n\t/*\n\t * Add on the checksum size and the offset from the\n\t * broadcast.\n\t */\n\tsmi_msg->data_size += 1 + i;\n\n\tsmi_msg->msgid = msgid;\n}\n\nstatic inline void format_lan_msg(struct ipmi_smi_msg   *smi_msg,\n\t\t\t\t  struct kernel_ipmi_msg *msg,\n\t\t\t\t  struct ipmi_lan_addr  *lan_addr,\n\t\t\t\t  long                  msgid,\n\t\t\t\t  unsigned char         ipmb_seq,\n\t\t\t\t  unsigned char         source_lun)\n{\n\t/* Format the IPMB header data. */\n\tsmi_msg->data[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\tsmi_msg->data[1] = IPMI_SEND_MSG_CMD;\n\tsmi_msg->data[2] = lan_addr->channel;\n\tsmi_msg->data[3] = lan_addr->session_handle;\n\tsmi_msg->data[4] = lan_addr->remote_SWID;\n\tsmi_msg->data[5] = (msg->netfn << 2) | (lan_addr->lun & 0x3);\n\tsmi_msg->data[6] = ipmb_checksum(&smi_msg->data[4], 2);\n\tsmi_msg->data[7] = lan_addr->local_SWID;\n\tsmi_msg->data[8] = (ipmb_seq << 2) | source_lun;\n\tsmi_msg->data[9] = msg->cmd;\n\n\t/* Now tack on the data to the message. */\n\tif (msg->data_len > 0)\n\t\tmemcpy(&smi_msg->data[10], msg->data, msg->data_len);\n\tsmi_msg->data_size = msg->data_len + 10;\n\n\t/* Now calculate the checksum and tack it on. */\n\tsmi_msg->data[smi_msg->data_size]\n\t\t= ipmb_checksum(&smi_msg->data[7], smi_msg->data_size - 7);\n\n\t/*\n\t * Add on the checksum size and the offset from the\n\t * broadcast.\n\t */\n\tsmi_msg->data_size += 1;\n\n\tsmi_msg->msgid = msgid;\n}\n\nstatic struct ipmi_smi_msg *smi_add_send_msg(struct ipmi_smi *intf,\n\t\t\t\t\t     struct ipmi_smi_msg *smi_msg,\n\t\t\t\t\t     int priority)\n{\n\tif (intf->curr_msg) {\n\t\tif (priority > 0)\n\t\t\tlist_add_tail(&smi_msg->link, &intf->hp_xmit_msgs);\n\t\telse\n\t\t\tlist_add_tail(&smi_msg->link, &intf->xmit_msgs);\n\t\tsmi_msg = NULL;\n\t} else {\n\t\tintf->curr_msg = smi_msg;\n\t}\n\n\treturn smi_msg;\n}\n\nstatic void smi_send(struct ipmi_smi *intf,\n\t\t     const struct ipmi_smi_handlers *handlers,\n\t\t     struct ipmi_smi_msg *smi_msg, int priority)\n{\n\tint run_to_completion = intf->run_to_completion;\n\tunsigned long flags = 0;\n\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&intf->xmit_msgs_lock, flags);\n\tsmi_msg = smi_add_send_msg(intf, smi_msg, priority);\n\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&intf->xmit_msgs_lock, flags);\n\n\tif (smi_msg)\n\t\thandlers->sender(intf->send_info, smi_msg);\n}\n\nstatic bool is_maintenance_mode_cmd(struct kernel_ipmi_msg *msg)\n{\n\treturn (((msg->netfn == IPMI_NETFN_APP_REQUEST)\n\t\t && ((msg->cmd == IPMI_COLD_RESET_CMD)\n\t\t     || (msg->cmd == IPMI_WARM_RESET_CMD)))\n\t\t|| (msg->netfn == IPMI_NETFN_FIRMWARE_REQUEST));\n}\n\nstatic int i_ipmi_req_sysintf(struct ipmi_smi        *intf,\n\t\t\t      struct ipmi_addr       *addr,\n\t\t\t      long                   msgid,\n\t\t\t      struct kernel_ipmi_msg *msg,\n\t\t\t      struct ipmi_smi_msg    *smi_msg,\n\t\t\t      struct ipmi_recv_msg   *recv_msg,\n\t\t\t      int                    retries,\n\t\t\t      unsigned int           retry_time_ms)\n{\n\tstruct ipmi_system_interface_addr *smi_addr;\n\n\tif (msg->netfn & 1)\n\t\t/* Responses are not allowed to the SMI. */\n\t\treturn -EINVAL;\n\n\tsmi_addr = (struct ipmi_system_interface_addr *) addr;\n\tif (smi_addr->lun > 3) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(&recv_msg->addr, smi_addr, sizeof(*smi_addr));\n\n\tif ((msg->netfn == IPMI_NETFN_APP_REQUEST)\n\t    && ((msg->cmd == IPMI_SEND_MSG_CMD)\n\t\t|| (msg->cmd == IPMI_GET_MSG_CMD)\n\t\t|| (msg->cmd == IPMI_READ_EVENT_MSG_BUFFER_CMD))) {\n\t\t/*\n\t\t * We don't let the user do these, since we manage\n\t\t * the sequence numbers.\n\t\t */\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tif (is_maintenance_mode_cmd(msg)) {\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&intf->maintenance_mode_lock, flags);\n\t\tintf->auto_maintenance_timeout\n\t\t\t= maintenance_mode_timeout_ms;\n\t\tif (!intf->maintenance_mode\n\t\t    && !intf->maintenance_mode_enable) {\n\t\t\tintf->maintenance_mode_enable = true;\n\t\t\tmaintenance_mode_update(intf);\n\t\t}\n\t\tspin_unlock_irqrestore(&intf->maintenance_mode_lock,\n\t\t\t\t       flags);\n\t}\n\n\tif (msg->data_len + 2 > IPMI_MAX_MSG_LENGTH) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tsmi_msg->data[0] = (msg->netfn << 2) | (smi_addr->lun & 0x3);\n\tsmi_msg->data[1] = msg->cmd;\n\tsmi_msg->msgid = msgid;\n\tsmi_msg->user_data = recv_msg;\n\tif (msg->data_len > 0)\n\t\tmemcpy(&smi_msg->data[2], msg->data, msg->data_len);\n\tsmi_msg->data_size = msg->data_len + 2;\n\tipmi_inc_stat(intf, sent_local_commands);\n\n\treturn 0;\n}\n\nstatic int i_ipmi_req_ipmb(struct ipmi_smi        *intf,\n\t\t\t   struct ipmi_addr       *addr,\n\t\t\t   long                   msgid,\n\t\t\t   struct kernel_ipmi_msg *msg,\n\t\t\t   struct ipmi_smi_msg    *smi_msg,\n\t\t\t   struct ipmi_recv_msg   *recv_msg,\n\t\t\t   unsigned char          source_address,\n\t\t\t   unsigned char          source_lun,\n\t\t\t   int                    retries,\n\t\t\t   unsigned int           retry_time_ms)\n{\n\tstruct ipmi_ipmb_addr *ipmb_addr;\n\tunsigned char ipmb_seq;\n\tlong seqid;\n\tint broadcast = 0;\n\tstruct ipmi_channel *chans;\n\tint rv = 0;\n\n\tif (addr->channel >= IPMI_MAX_CHANNELS) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tchans = READ_ONCE(intf->channel_list)->c;\n\n\tif (chans[addr->channel].medium != IPMI_CHANNEL_MEDIUM_IPMB) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tif (addr->addr_type == IPMI_IPMB_BROADCAST_ADDR_TYPE) {\n\t\t/*\n\t\t * Broadcasts add a zero at the beginning of the\n\t\t * message, but otherwise is the same as an IPMB\n\t\t * address.\n\t\t */\n\t\taddr->addr_type = IPMI_IPMB_ADDR_TYPE;\n\t\tbroadcast = 1;\n\t\tretries = 0; /* Don't retry broadcasts. */\n\t}\n\n\t/*\n\t * 9 for the header and 1 for the checksum, plus\n\t * possibly one for the broadcast.\n\t */\n\tif ((msg->data_len + 10 + broadcast) > IPMI_MAX_MSG_LENGTH) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tipmb_addr = (struct ipmi_ipmb_addr *) addr;\n\tif (ipmb_addr->lun > 3) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(&recv_msg->addr, ipmb_addr, sizeof(*ipmb_addr));\n\n\tif (recv_msg->msg.netfn & 0x1) {\n\t\t/*\n\t\t * It's a response, so use the user's sequence\n\t\t * from msgid.\n\t\t */\n\t\tipmi_inc_stat(intf, sent_ipmb_responses);\n\t\tformat_ipmb_msg(smi_msg, msg, ipmb_addr, msgid,\n\t\t\t\tmsgid, broadcast,\n\t\t\t\tsource_address, source_lun);\n\n\t\t/*\n\t\t * Save the receive message so we can use it\n\t\t * to deliver the response.\n\t\t */\n\t\tsmi_msg->user_data = recv_msg;\n\t} else {\n\t\t/* It's a command, so get a sequence for it. */\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&intf->seq_lock, flags);\n\n\t\tif (is_maintenance_mode_cmd(msg))\n\t\t\tintf->ipmb_maintenance_mode_timeout =\n\t\t\t\tmaintenance_mode_timeout_ms;\n\n\t\tif (intf->ipmb_maintenance_mode_timeout && retry_time_ms == 0)\n\t\t\t/* Different default in maintenance mode */\n\t\t\tretry_time_ms = default_maintenance_retry_ms;\n\n\t\t/*\n\t\t * Create a sequence number with a 1 second\n\t\t * timeout and 4 retries.\n\t\t */\n\t\trv = intf_next_seq(intf,\n\t\t\t\t   recv_msg,\n\t\t\t\t   retry_time_ms,\n\t\t\t\t   retries,\n\t\t\t\t   broadcast,\n\t\t\t\t   &ipmb_seq,\n\t\t\t\t   &seqid);\n\t\tif (rv)\n\t\t\t/*\n\t\t\t * We have used up all the sequence numbers,\n\t\t\t * probably, so abort.\n\t\t\t */\n\t\t\tgoto out_err;\n\n\t\tipmi_inc_stat(intf, sent_ipmb_commands);\n\n\t\t/*\n\t\t * Store the sequence number in the message,\n\t\t * so that when the send message response\n\t\t * comes back we can start the timer.\n\t\t */\n\t\tformat_ipmb_msg(smi_msg, msg, ipmb_addr,\n\t\t\t\tSTORE_SEQ_IN_MSGID(ipmb_seq, seqid),\n\t\t\t\tipmb_seq, broadcast,\n\t\t\t\tsource_address, source_lun);\n\n\t\t/*\n\t\t * Copy the message into the recv message data, so we\n\t\t * can retransmit it later if necessary.\n\t\t */\n\t\tmemcpy(recv_msg->msg_data, smi_msg->data,\n\t\t       smi_msg->data_size);\n\t\trecv_msg->msg.data = recv_msg->msg_data;\n\t\trecv_msg->msg.data_len = smi_msg->data_size;\n\n\t\t/*\n\t\t * We don't unlock until here, because we need\n\t\t * to copy the completed message into the\n\t\t * recv_msg before we release the lock.\n\t\t * Otherwise, race conditions may bite us.  I\n\t\t * know that's pretty paranoid, but I prefer\n\t\t * to be correct.\n\t\t */\nout_err:\n\t\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\t}\n\n\treturn rv;\n}\n\nstatic int i_ipmi_req_lan(struct ipmi_smi        *intf,\n\t\t\t  struct ipmi_addr       *addr,\n\t\t\t  long                   msgid,\n\t\t\t  struct kernel_ipmi_msg *msg,\n\t\t\t  struct ipmi_smi_msg    *smi_msg,\n\t\t\t  struct ipmi_recv_msg   *recv_msg,\n\t\t\t  unsigned char          source_lun,\n\t\t\t  int                    retries,\n\t\t\t  unsigned int           retry_time_ms)\n{\n\tstruct ipmi_lan_addr  *lan_addr;\n\tunsigned char ipmb_seq;\n\tlong seqid;\n\tstruct ipmi_channel *chans;\n\tint rv = 0;\n\n\tif (addr->channel >= IPMI_MAX_CHANNELS) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tchans = READ_ONCE(intf->channel_list)->c;\n\n\tif ((chans[addr->channel].medium\n\t\t\t\t!= IPMI_CHANNEL_MEDIUM_8023LAN)\n\t\t\t&& (chans[addr->channel].medium\n\t\t\t    != IPMI_CHANNEL_MEDIUM_ASYNC)) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\t/* 11 for the header and 1 for the checksum. */\n\tif ((msg->data_len + 12) > IPMI_MAX_MSG_LENGTH) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tlan_addr = (struct ipmi_lan_addr *) addr;\n\tif (lan_addr->lun > 3) {\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(&recv_msg->addr, lan_addr, sizeof(*lan_addr));\n\n\tif (recv_msg->msg.netfn & 0x1) {\n\t\t/*\n\t\t * It's a response, so use the user's sequence\n\t\t * from msgid.\n\t\t */\n\t\tipmi_inc_stat(intf, sent_lan_responses);\n\t\tformat_lan_msg(smi_msg, msg, lan_addr, msgid,\n\t\t\t       msgid, source_lun);\n\n\t\t/*\n\t\t * Save the receive message so we can use it\n\t\t * to deliver the response.\n\t\t */\n\t\tsmi_msg->user_data = recv_msg;\n\t} else {\n\t\t/* It's a command, so get a sequence for it. */\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&intf->seq_lock, flags);\n\n\t\t/*\n\t\t * Create a sequence number with a 1 second\n\t\t * timeout and 4 retries.\n\t\t */\n\t\trv = intf_next_seq(intf,\n\t\t\t\t   recv_msg,\n\t\t\t\t   retry_time_ms,\n\t\t\t\t   retries,\n\t\t\t\t   0,\n\t\t\t\t   &ipmb_seq,\n\t\t\t\t   &seqid);\n\t\tif (rv)\n\t\t\t/*\n\t\t\t * We have used up all the sequence numbers,\n\t\t\t * probably, so abort.\n\t\t\t */\n\t\t\tgoto out_err;\n\n\t\tipmi_inc_stat(intf, sent_lan_commands);\n\n\t\t/*\n\t\t * Store the sequence number in the message,\n\t\t * so that when the send message response\n\t\t * comes back we can start the timer.\n\t\t */\n\t\tformat_lan_msg(smi_msg, msg, lan_addr,\n\t\t\t       STORE_SEQ_IN_MSGID(ipmb_seq, seqid),\n\t\t\t       ipmb_seq, source_lun);\n\n\t\t/*\n\t\t * Copy the message into the recv message data, so we\n\t\t * can retransmit it later if necessary.\n\t\t */\n\t\tmemcpy(recv_msg->msg_data, smi_msg->data,\n\t\t       smi_msg->data_size);\n\t\trecv_msg->msg.data = recv_msg->msg_data;\n\t\trecv_msg->msg.data_len = smi_msg->data_size;\n\n\t\t/*\n\t\t * We don't unlock until here, because we need\n\t\t * to copy the completed message into the\n\t\t * recv_msg before we release the lock.\n\t\t * Otherwise, race conditions may bite us.  I\n\t\t * know that's pretty paranoid, but I prefer\n\t\t * to be correct.\n\t\t */\nout_err:\n\t\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\t}\n\n\treturn rv;\n}\n\n/*\n * Separate from ipmi_request so that the user does not have to be\n * supplied in certain circumstances (mainly at panic time).  If\n * messages are supplied, they will be freed, even if an error\n * occurs.\n */\nstatic int i_ipmi_request(struct ipmi_user     *user,\n\t\t\t  struct ipmi_smi      *intf,\n\t\t\t  struct ipmi_addr     *addr,\n\t\t\t  long                 msgid,\n\t\t\t  struct kernel_ipmi_msg *msg,\n\t\t\t  void                 *user_msg_data,\n\t\t\t  void                 *supplied_smi,\n\t\t\t  struct ipmi_recv_msg *supplied_recv,\n\t\t\t  int                  priority,\n\t\t\t  unsigned char        source_address,\n\t\t\t  unsigned char        source_lun,\n\t\t\t  int                  retries,\n\t\t\t  unsigned int         retry_time_ms)\n{\n\tstruct ipmi_smi_msg *smi_msg;\n\tstruct ipmi_recv_msg *recv_msg;\n\tint rv = 0;\n\n\tif (supplied_recv)\n\t\trecv_msg = supplied_recv;\n\telse {\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (recv_msg == NULL) {\n\t\t\trv = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\trecv_msg->user_msg_data = user_msg_data;\n\n\tif (supplied_smi)\n\t\tsmi_msg = (struct ipmi_smi_msg *) supplied_smi;\n\telse {\n\t\tsmi_msg = ipmi_alloc_smi_msg();\n\t\tif (smi_msg == NULL) {\n\t\t\tif (!supplied_recv)\n\t\t\t\tipmi_free_recv_msg(recv_msg);\n\t\t\trv = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\trcu_read_lock();\n\tif (intf->in_shutdown) {\n\t\trv = -ENODEV;\n\t\tgoto out_err;\n\t}\n\n\trecv_msg->user = user;\n\tif (user)\n\t\t/* The put happens when the message is freed. */\n\t\tkref_get(&user->refcount);\n\trecv_msg->msgid = msgid;\n\t/*\n\t * Store the message to send in the receive message so timeout\n\t * responses can get the proper response data.\n\t */\n\trecv_msg->msg = *msg;\n\n\tif (addr->addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE) {\n\t\trv = i_ipmi_req_sysintf(intf, addr, msgid, msg, smi_msg,\n\t\t\t\t\trecv_msg, retries, retry_time_ms);\n\t} else if (is_ipmb_addr(addr) || is_ipmb_bcast_addr(addr)) {\n\t\trv = i_ipmi_req_ipmb(intf, addr, msgid, msg, smi_msg, recv_msg,\n\t\t\t\t     source_address, source_lun,\n\t\t\t\t     retries, retry_time_ms);\n\t} else if (is_lan_addr(addr)) {\n\t\trv = i_ipmi_req_lan(intf, addr, msgid, msg, smi_msg, recv_msg,\n\t\t\t\t    source_lun, retries, retry_time_ms);\n\t} else {\n\t    /* Unknown address type. */\n\t\tipmi_inc_stat(intf, sent_invalid_commands);\n\t\trv = -EINVAL;\n\t}\n\n\tif (rv) {\nout_err:\n\t\tipmi_free_smi_msg(smi_msg);\n\t\tipmi_free_recv_msg(recv_msg);\n\t} else {\n\t\tpr_debug(\"Send: %*ph\\n\", smi_msg->data_size, smi_msg->data);\n\n\t\tsmi_send(intf, intf->handlers, smi_msg, priority);\n\t}\n\trcu_read_unlock();\n\nout:\n\treturn rv;\n}\n\nstatic int check_addr(struct ipmi_smi  *intf,\n\t\t      struct ipmi_addr *addr,\n\t\t      unsigned char    *saddr,\n\t\t      unsigned char    *lun)\n{\n\tif (addr->channel >= IPMI_MAX_CHANNELS)\n\t\treturn -EINVAL;\n\taddr->channel = array_index_nospec(addr->channel, IPMI_MAX_CHANNELS);\n\t*lun = intf->addrinfo[addr->channel].lun;\n\t*saddr = intf->addrinfo[addr->channel].address;\n\treturn 0;\n}\n\nint ipmi_request_settime(struct ipmi_user *user,\n\t\t\t struct ipmi_addr *addr,\n\t\t\t long             msgid,\n\t\t\t struct kernel_ipmi_msg  *msg,\n\t\t\t void             *user_msg_data,\n\t\t\t int              priority,\n\t\t\t int              retries,\n\t\t\t unsigned int     retry_time_ms)\n{\n\tunsigned char saddr = 0, lun = 0;\n\tint rv, index;\n\n\tif (!user)\n\t\treturn -EINVAL;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\trv = check_addr(user->intf, addr, &saddr, &lun);\n\tif (!rv)\n\t\trv = i_ipmi_request(user,\n\t\t\t\t    user->intf,\n\t\t\t\t    addr,\n\t\t\t\t    msgid,\n\t\t\t\t    msg,\n\t\t\t\t    user_msg_data,\n\t\t\t\t    NULL, NULL,\n\t\t\t\t    priority,\n\t\t\t\t    saddr,\n\t\t\t\t    lun,\n\t\t\t\t    retries,\n\t\t\t\t    retry_time_ms);\n\n\trelease_ipmi_user(user, index);\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_request_settime);\n\nint ipmi_request_supply_msgs(struct ipmi_user     *user,\n\t\t\t     struct ipmi_addr     *addr,\n\t\t\t     long                 msgid,\n\t\t\t     struct kernel_ipmi_msg *msg,\n\t\t\t     void                 *user_msg_data,\n\t\t\t     void                 *supplied_smi,\n\t\t\t     struct ipmi_recv_msg *supplied_recv,\n\t\t\t     int                  priority)\n{\n\tunsigned char saddr = 0, lun = 0;\n\tint rv, index;\n\n\tif (!user)\n\t\treturn -EINVAL;\n\n\tuser = acquire_ipmi_user(user, &index);\n\tif (!user)\n\t\treturn -ENODEV;\n\n\trv = check_addr(user->intf, addr, &saddr, &lun);\n\tif (!rv)\n\t\trv = i_ipmi_request(user,\n\t\t\t\t    user->intf,\n\t\t\t\t    addr,\n\t\t\t\t    msgid,\n\t\t\t\t    msg,\n\t\t\t\t    user_msg_data,\n\t\t\t\t    supplied_smi,\n\t\t\t\t    supplied_recv,\n\t\t\t\t    priority,\n\t\t\t\t    saddr,\n\t\t\t\t    lun,\n\t\t\t\t    -1, 0);\n\n\trelease_ipmi_user(user, index);\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_request_supply_msgs);\n\nstatic void bmc_device_id_handler(struct ipmi_smi *intf,\n\t\t\t\t  struct ipmi_recv_msg *msg)\n{\n\tint rv;\n\n\tif ((msg->addr.addr_type != IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t\t\t|| (msg->msg.netfn != IPMI_NETFN_APP_RESPONSE)\n\t\t\t|| (msg->msg.cmd != IPMI_GET_DEVICE_ID_CMD)) {\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"invalid device_id msg: addr_type=%d netfn=%x cmd=%x\\n\",\n\t\t\t msg->addr.addr_type, msg->msg.netfn, msg->msg.cmd);\n\t\treturn;\n\t}\n\n\trv = ipmi_demangle_device_id(msg->msg.netfn, msg->msg.cmd,\n\t\t\tmsg->msg.data, msg->msg.data_len, &intf->bmc->fetch_id);\n\tif (rv) {\n\t\tdev_warn(intf->si_dev, \"device id demangle failed: %d\\n\", rv);\n\t\tintf->bmc->dyn_id_set = 0;\n\t} else {\n\t\t/*\n\t\t * Make sure the id data is available before setting\n\t\t * dyn_id_set.\n\t\t */\n\t\tsmp_wmb();\n\t\tintf->bmc->dyn_id_set = 1;\n\t}\n\n\twake_up(&intf->waitq);\n}\n\nstatic int\nsend_get_device_id_cmd(struct ipmi_smi *intf)\n{\n\tstruct ipmi_system_interface_addr si;\n\tstruct kernel_ipmi_msg msg;\n\n\tsi.addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsi.channel = IPMI_BMC_CHANNEL;\n\tsi.lun = 0;\n\n\tmsg.netfn = IPMI_NETFN_APP_REQUEST;\n\tmsg.cmd = IPMI_GET_DEVICE_ID_CMD;\n\tmsg.data = NULL;\n\tmsg.data_len = 0;\n\n\treturn i_ipmi_request(NULL,\n\t\t\t      intf,\n\t\t\t      (struct ipmi_addr *) &si,\n\t\t\t      0,\n\t\t\t      &msg,\n\t\t\t      intf,\n\t\t\t      NULL,\n\t\t\t      NULL,\n\t\t\t      0,\n\t\t\t      intf->addrinfo[0].address,\n\t\t\t      intf->addrinfo[0].lun,\n\t\t\t      -1, 0);\n}\n\nstatic int __get_device_id(struct ipmi_smi *intf, struct bmc_device *bmc)\n{\n\tint rv;\n\n\tbmc->dyn_id_set = 2;\n\n\tintf->null_user_handler = bmc_device_id_handler;\n\n\trv = send_get_device_id_cmd(intf);\n\tif (rv)\n\t\treturn rv;\n\n\twait_event(intf->waitq, bmc->dyn_id_set != 2);\n\n\tif (!bmc->dyn_id_set)\n\t\trv = -EIO; /* Something went wrong in the fetch. */\n\n\t/* dyn_id_set makes the id data available. */\n\tsmp_rmb();\n\n\tintf->null_user_handler = NULL;\n\n\treturn rv;\n}\n\n/*\n * Fetch the device id for the bmc/interface.  You must pass in either\n * bmc or intf, this code will get the other one.  If the data has\n * been recently fetched, this will just use the cached data.  Otherwise\n * it will run a new fetch.\n *\n * Except for the first time this is called (in ipmi_add_smi()),\n * this will always return good data;\n */\nstatic int __bmc_get_device_id(struct ipmi_smi *intf, struct bmc_device *bmc,\n\t\t\t       struct ipmi_device_id *id,\n\t\t\t       bool *guid_set, guid_t *guid, int intf_num)\n{\n\tint rv = 0;\n\tint prev_dyn_id_set, prev_guid_set;\n\tbool intf_set = intf != NULL;\n\n\tif (!intf) {\n\t\tmutex_lock(&bmc->dyn_mutex);\nretry_bmc_lock:\n\t\tif (list_empty(&bmc->intfs)) {\n\t\t\tmutex_unlock(&bmc->dyn_mutex);\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tintf = list_first_entry(&bmc->intfs, struct ipmi_smi,\n\t\t\t\t\tbmc_link);\n\t\tkref_get(&intf->refcount);\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\t\tmutex_lock(&intf->bmc_reg_mutex);\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tif (intf != list_first_entry(&bmc->intfs, struct ipmi_smi,\n\t\t\t\t\t     bmc_link)) {\n\t\t\tmutex_unlock(&intf->bmc_reg_mutex);\n\t\t\tkref_put(&intf->refcount, intf_free);\n\t\t\tgoto retry_bmc_lock;\n\t\t}\n\t} else {\n\t\tmutex_lock(&intf->bmc_reg_mutex);\n\t\tbmc = intf->bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tkref_get(&intf->refcount);\n\t}\n\n\t/* If we have a valid and current ID, just return that. */\n\tif (intf->in_bmc_register ||\n\t    (bmc->dyn_id_set && time_is_after_jiffies(bmc->dyn_id_expiry)))\n\t\tgoto out_noprocessing;\n\n\tprev_guid_set = bmc->dyn_guid_set;\n\t__get_guid(intf);\n\n\tprev_dyn_id_set = bmc->dyn_id_set;\n\trv = __get_device_id(intf, bmc);\n\tif (rv)\n\t\tgoto out;\n\n\t/*\n\t * The guid, device id, manufacturer id, and product id should\n\t * not change on a BMC.  If it does we have to do some dancing.\n\t */\n\tif (!intf->bmc_registered\n\t    || (!prev_guid_set && bmc->dyn_guid_set)\n\t    || (!prev_dyn_id_set && bmc->dyn_id_set)\n\t    || (prev_guid_set && bmc->dyn_guid_set\n\t\t&& !guid_equal(&bmc->guid, &bmc->fetch_guid))\n\t    || bmc->id.device_id != bmc->fetch_id.device_id\n\t    || bmc->id.manufacturer_id != bmc->fetch_id.manufacturer_id\n\t    || bmc->id.product_id != bmc->fetch_id.product_id) {\n\t\tstruct ipmi_device_id id = bmc->fetch_id;\n\t\tint guid_set = bmc->dyn_guid_set;\n\t\tguid_t guid;\n\n\t\tguid = bmc->fetch_guid;\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\n\t\t__ipmi_bmc_unregister(intf);\n\t\t/* Fill in the temporary BMC for good measure. */\n\t\tintf->bmc->id = id;\n\t\tintf->bmc->dyn_guid_set = guid_set;\n\t\tintf->bmc->guid = guid;\n\t\tif (__ipmi_bmc_register(intf, &id, guid_set, &guid, intf_num))\n\t\t\tneed_waiter(intf); /* Retry later on an error. */\n\t\telse\n\t\t\t__scan_channels(intf, &id);\n\n\n\t\tif (!intf_set) {\n\t\t\t/*\n\t\t\t * We weren't given the interface on the\n\t\t\t * command line, so restart the operation on\n\t\t\t * the next interface for the BMC.\n\t\t\t */\n\t\t\tmutex_unlock(&intf->bmc_reg_mutex);\n\t\t\tmutex_lock(&bmc->dyn_mutex);\n\t\t\tgoto retry_bmc_lock;\n\t\t}\n\n\t\t/* We have a new BMC, set it up. */\n\t\tbmc = intf->bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tgoto out_noprocessing;\n\t} else if (memcmp(&bmc->fetch_id, &bmc->id, sizeof(bmc->id)))\n\t\t/* Version info changes, scan the channels again. */\n\t\t__scan_channels(intf, &bmc->fetch_id);\n\n\tbmc->dyn_id_expiry = jiffies + IPMI_DYN_DEV_ID_EXPIRY;\n\nout:\n\tif (rv && prev_dyn_id_set) {\n\t\trv = 0; /* Ignore failures if we have previous data. */\n\t\tbmc->dyn_id_set = prev_dyn_id_set;\n\t}\n\tif (!rv) {\n\t\tbmc->id = bmc->fetch_id;\n\t\tif (bmc->dyn_guid_set)\n\t\t\tbmc->guid = bmc->fetch_guid;\n\t\telse if (prev_guid_set)\n\t\t\t/*\n\t\t\t * The guid used to be valid and it failed to fetch,\n\t\t\t * just use the cached value.\n\t\t\t */\n\t\t\tbmc->dyn_guid_set = prev_guid_set;\n\t}\nout_noprocessing:\n\tif (!rv) {\n\t\tif (id)\n\t\t\t*id = bmc->id;\n\n\t\tif (guid_set)\n\t\t\t*guid_set = bmc->dyn_guid_set;\n\n\t\tif (guid && bmc->dyn_guid_set)\n\t\t\t*guid =  bmc->guid;\n\t}\n\n\tmutex_unlock(&bmc->dyn_mutex);\n\tmutex_unlock(&intf->bmc_reg_mutex);\n\n\tkref_put(&intf->refcount, intf_free);\n\treturn rv;\n}\n\nstatic int bmc_get_device_id(struct ipmi_smi *intf, struct bmc_device *bmc,\n\t\t\t     struct ipmi_device_id *id,\n\t\t\t     bool *guid_set, guid_t *guid)\n{\n\treturn __bmc_get_device_id(intf, bmc, id, guid_set, guid, -1);\n}\n\nstatic ssize_t device_id_show(struct device *dev,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 10, \"%u\\n\", id.device_id);\n}\nstatic DEVICE_ATTR_RO(device_id);\n\nstatic ssize_t provides_device_sdrs_show(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 10, \"%u\\n\", (id.device_revision & 0x80) >> 7);\n}\nstatic DEVICE_ATTR_RO(provides_device_sdrs);\n\nstatic ssize_t revision_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 20, \"%u\\n\", id.device_revision & 0x0F);\n}\nstatic DEVICE_ATTR_RO(revision);\n\nstatic ssize_t firmware_revision_show(struct device *dev,\n\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t      char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 20, \"%u.%x\\n\", id.firmware_revision_1,\n\t\t\tid.firmware_revision_2);\n}\nstatic DEVICE_ATTR_RO(firmware_revision);\n\nstatic ssize_t ipmi_version_show(struct device *dev,\n\t\t\t\t struct device_attribute *attr,\n\t\t\t\t char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 20, \"%u.%u\\n\",\n\t\t\tipmi_version_major(&id),\n\t\t\tipmi_version_minor(&id));\n}\nstatic DEVICE_ATTR_RO(ipmi_version);\n\nstatic ssize_t add_dev_support_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 10, \"0x%02x\\n\", id.additional_device_support);\n}\nstatic DEVICE_ATTR(additional_device_support, S_IRUGO, add_dev_support_show,\n\t\t   NULL);\n\nstatic ssize_t manufacturer_id_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 20, \"0x%6.6x\\n\", id.manufacturer_id);\n}\nstatic DEVICE_ATTR_RO(manufacturer_id);\n\nstatic ssize_t product_id_show(struct device *dev,\n\t\t\t       struct device_attribute *attr,\n\t\t\t       char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 10, \"0x%4.4x\\n\", id.product_id);\n}\nstatic DEVICE_ATTR_RO(product_id);\n\nstatic ssize_t aux_firmware_rev_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tstruct ipmi_device_id id;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\tif (rv)\n\t\treturn rv;\n\n\treturn snprintf(buf, 21, \"0x%02x 0x%02x 0x%02x 0x%02x\\n\",\n\t\t\tid.aux_firmware_revision[3],\n\t\t\tid.aux_firmware_revision[2],\n\t\t\tid.aux_firmware_revision[1],\n\t\t\tid.aux_firmware_revision[0]);\n}\nstatic DEVICE_ATTR(aux_firmware_revision, S_IRUGO, aux_firmware_rev_show, NULL);\n\nstatic ssize_t guid_show(struct device *dev, struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tbool guid_set;\n\tguid_t guid;\n\tint rv;\n\n\trv = bmc_get_device_id(NULL, bmc, NULL, &guid_set, &guid);\n\tif (rv)\n\t\treturn rv;\n\tif (!guid_set)\n\t\treturn -ENOENT;\n\n\treturn snprintf(buf, UUID_STRING_LEN + 1 + 1, \"%pUl\\n\", &guid);\n}\nstatic DEVICE_ATTR_RO(guid);\n\nstatic struct attribute *bmc_dev_attrs[] = {\n\t&dev_attr_device_id.attr,\n\t&dev_attr_provides_device_sdrs.attr,\n\t&dev_attr_revision.attr,\n\t&dev_attr_firmware_revision.attr,\n\t&dev_attr_ipmi_version.attr,\n\t&dev_attr_additional_device_support.attr,\n\t&dev_attr_manufacturer_id.attr,\n\t&dev_attr_product_id.attr,\n\t&dev_attr_aux_firmware_revision.attr,\n\t&dev_attr_guid.attr,\n\tNULL\n};\n\nstatic umode_t bmc_dev_attr_is_visible(struct kobject *kobj,\n\t\t\t\t       struct attribute *attr, int idx)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct bmc_device *bmc = to_bmc_device(dev);\n\tumode_t mode = attr->mode;\n\tint rv;\n\n\tif (attr == &dev_attr_aux_firmware_revision.attr) {\n\t\tstruct ipmi_device_id id;\n\n\t\trv = bmc_get_device_id(NULL, bmc, &id, NULL, NULL);\n\t\treturn (!rv && id.aux_firmware_revision_set) ? mode : 0;\n\t}\n\tif (attr == &dev_attr_guid.attr) {\n\t\tbool guid_set;\n\n\t\trv = bmc_get_device_id(NULL, bmc, NULL, &guid_set, NULL);\n\t\treturn (!rv && guid_set) ? mode : 0;\n\t}\n\treturn mode;\n}\n\nstatic const struct attribute_group bmc_dev_attr_group = {\n\t.attrs\t\t= bmc_dev_attrs,\n\t.is_visible\t= bmc_dev_attr_is_visible,\n};\n\nstatic const struct attribute_group *bmc_dev_attr_groups[] = {\n\t&bmc_dev_attr_group,\n\tNULL\n};\n\nstatic const struct device_type bmc_device_type = {\n\t.groups\t\t= bmc_dev_attr_groups,\n};\n\nstatic int __find_bmc_guid(struct device *dev, const void *data)\n{\n\tconst guid_t *guid = data;\n\tstruct bmc_device *bmc;\n\tint rv;\n\n\tif (dev->type != &bmc_device_type)\n\t\treturn 0;\n\n\tbmc = to_bmc_device(dev);\n\trv = bmc->dyn_guid_set && guid_equal(&bmc->guid, guid);\n\tif (rv)\n\t\trv = kref_get_unless_zero(&bmc->usecount);\n\treturn rv;\n}\n\n/*\n * Returns with the bmc's usecount incremented, if it is non-NULL.\n */\nstatic struct bmc_device *ipmi_find_bmc_guid(struct device_driver *drv,\n\t\t\t\t\t     guid_t *guid)\n{\n\tstruct device *dev;\n\tstruct bmc_device *bmc = NULL;\n\n\tdev = driver_find_device(drv, NULL, guid, __find_bmc_guid);\n\tif (dev) {\n\t\tbmc = to_bmc_device(dev);\n\t\tput_device(dev);\n\t}\n\treturn bmc;\n}\n\nstruct prod_dev_id {\n\tunsigned int  product_id;\n\tunsigned char device_id;\n};\n\nstatic int __find_bmc_prod_dev_id(struct device *dev, const void *data)\n{\n\tconst struct prod_dev_id *cid = data;\n\tstruct bmc_device *bmc;\n\tint rv;\n\n\tif (dev->type != &bmc_device_type)\n\t\treturn 0;\n\n\tbmc = to_bmc_device(dev);\n\trv = (bmc->id.product_id == cid->product_id\n\t      && bmc->id.device_id == cid->device_id);\n\tif (rv)\n\t\trv = kref_get_unless_zero(&bmc->usecount);\n\treturn rv;\n}\n\n/*\n * Returns with the bmc's usecount incremented, if it is non-NULL.\n */\nstatic struct bmc_device *ipmi_find_bmc_prod_dev_id(\n\tstruct device_driver *drv,\n\tunsigned int product_id, unsigned char device_id)\n{\n\tstruct prod_dev_id id = {\n\t\t.product_id = product_id,\n\t\t.device_id = device_id,\n\t};\n\tstruct device *dev;\n\tstruct bmc_device *bmc = NULL;\n\n\tdev = driver_find_device(drv, NULL, &id, __find_bmc_prod_dev_id);\n\tif (dev) {\n\t\tbmc = to_bmc_device(dev);\n\t\tput_device(dev);\n\t}\n\treturn bmc;\n}\n\nstatic DEFINE_IDA(ipmi_bmc_ida);\n\nstatic void\nrelease_bmc_device(struct device *dev)\n{\n\tkfree(to_bmc_device(dev));\n}\n\nstatic void cleanup_bmc_work(struct work_struct *work)\n{\n\tstruct bmc_device *bmc = container_of(work, struct bmc_device,\n\t\t\t\t\t      remove_work);\n\tint id = bmc->pdev.id; /* Unregister overwrites id */\n\n\tplatform_device_unregister(&bmc->pdev);\n\tida_simple_remove(&ipmi_bmc_ida, id);\n}\n\nstatic void\ncleanup_bmc_device(struct kref *ref)\n{\n\tstruct bmc_device *bmc = container_of(ref, struct bmc_device, usecount);\n\n\t/*\n\t * Remove the platform device in a work queue to avoid issues\n\t * with removing the device attributes while reading a device\n\t * attribute.\n\t */\n\tschedule_work(&bmc->remove_work);\n}\n\n/*\n * Must be called with intf->bmc_reg_mutex held.\n */\nstatic void __ipmi_bmc_unregister(struct ipmi_smi *intf)\n{\n\tstruct bmc_device *bmc = intf->bmc;\n\n\tif (!intf->bmc_registered)\n\t\treturn;\n\n\tsysfs_remove_link(&intf->si_dev->kobj, \"bmc\");\n\tsysfs_remove_link(&bmc->pdev.dev.kobj, intf->my_dev_name);\n\tkfree(intf->my_dev_name);\n\tintf->my_dev_name = NULL;\n\n\tmutex_lock(&bmc->dyn_mutex);\n\tlist_del(&intf->bmc_link);\n\tmutex_unlock(&bmc->dyn_mutex);\n\tintf->bmc = &intf->tmp_bmc;\n\tkref_put(&bmc->usecount, cleanup_bmc_device);\n\tintf->bmc_registered = false;\n}\n\nstatic void ipmi_bmc_unregister(struct ipmi_smi *intf)\n{\n\tmutex_lock(&intf->bmc_reg_mutex);\n\t__ipmi_bmc_unregister(intf);\n\tmutex_unlock(&intf->bmc_reg_mutex);\n}\n\n/*\n * Must be called with intf->bmc_reg_mutex held.\n */\nstatic int __ipmi_bmc_register(struct ipmi_smi *intf,\n\t\t\t       struct ipmi_device_id *id,\n\t\t\t       bool guid_set, guid_t *guid, int intf_num)\n{\n\tint               rv;\n\tstruct bmc_device *bmc;\n\tstruct bmc_device *old_bmc;\n\n\t/*\n\t * platform_device_register() can cause bmc_reg_mutex to\n\t * be claimed because of the is_visible functions of\n\t * the attributes.  Eliminate possible recursion and\n\t * release the lock.\n\t */\n\tintf->in_bmc_register = true;\n\tmutex_unlock(&intf->bmc_reg_mutex);\n\n\t/*\n\t * Try to find if there is an bmc_device struct\n\t * representing the interfaced BMC already\n\t */\n\tmutex_lock(&ipmidriver_mutex);\n\tif (guid_set)\n\t\told_bmc = ipmi_find_bmc_guid(&ipmidriver.driver, guid);\n\telse\n\t\told_bmc = ipmi_find_bmc_prod_dev_id(&ipmidriver.driver,\n\t\t\t\t\t\t    id->product_id,\n\t\t\t\t\t\t    id->device_id);\n\n\t/*\n\t * If there is already an bmc_device, free the new one,\n\t * otherwise register the new BMC device\n\t */\n\tif (old_bmc) {\n\t\tbmc = old_bmc;\n\t\t/*\n\t\t * Note: old_bmc already has usecount incremented by\n\t\t * the BMC find functions.\n\t\t */\n\t\tintf->bmc = old_bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tlist_add_tail(&intf->bmc_link, &bmc->intfs);\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\n\t\tdev_info(intf->si_dev,\n\t\t\t \"interfacing existing BMC (man_id: 0x%6.6x, prod_id: 0x%4.4x, dev_id: 0x%2.2x)\\n\",\n\t\t\t bmc->id.manufacturer_id,\n\t\t\t bmc->id.product_id,\n\t\t\t bmc->id.device_id);\n\t} else {\n\t\tbmc = kzalloc(sizeof(*bmc), GFP_KERNEL);\n\t\tif (!bmc) {\n\t\t\trv = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tINIT_LIST_HEAD(&bmc->intfs);\n\t\tmutex_init(&bmc->dyn_mutex);\n\t\tINIT_WORK(&bmc->remove_work, cleanup_bmc_work);\n\n\t\tbmc->id = *id;\n\t\tbmc->dyn_id_set = 1;\n\t\tbmc->dyn_guid_set = guid_set;\n\t\tbmc->guid = *guid;\n\t\tbmc->dyn_id_expiry = jiffies + IPMI_DYN_DEV_ID_EXPIRY;\n\n\t\tbmc->pdev.name = \"ipmi_bmc\";\n\n\t\trv = ida_simple_get(&ipmi_bmc_ida, 0, 0, GFP_KERNEL);\n\t\tif (rv < 0) {\n\t\t\tkfree(bmc);\n\t\t\tgoto out;\n\t\t}\n\n\t\tbmc->pdev.dev.driver = &ipmidriver.driver;\n\t\tbmc->pdev.id = rv;\n\t\tbmc->pdev.dev.release = release_bmc_device;\n\t\tbmc->pdev.dev.type = &bmc_device_type;\n\t\tkref_init(&bmc->usecount);\n\n\t\tintf->bmc = bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tlist_add_tail(&intf->bmc_link, &bmc->intfs);\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\n\t\trv = platform_device_register(&bmc->pdev);\n\t\tif (rv) {\n\t\t\tdev_err(intf->si_dev,\n\t\t\t\t\"Unable to register bmc device: %d\\n\",\n\t\t\t\trv);\n\t\t\tgoto out_list_del;\n\t\t}\n\n\t\tdev_info(intf->si_dev,\n\t\t\t \"Found new BMC (man_id: 0x%6.6x, prod_id: 0x%4.4x, dev_id: 0x%2.2x)\\n\",\n\t\t\t bmc->id.manufacturer_id,\n\t\t\t bmc->id.product_id,\n\t\t\t bmc->id.device_id);\n\t}\n\n\t/*\n\t * create symlink from system interface device to bmc device\n\t * and back.\n\t */\n\trv = sysfs_create_link(&intf->si_dev->kobj, &bmc->pdev.dev.kobj, \"bmc\");\n\tif (rv) {\n\t\tdev_err(intf->si_dev, \"Unable to create bmc symlink: %d\\n\", rv);\n\t\tgoto out_put_bmc;\n\t}\n\n\tif (intf_num == -1)\n\t\tintf_num = intf->intf_num;\n\tintf->my_dev_name = kasprintf(GFP_KERNEL, \"ipmi%d\", intf_num);\n\tif (!intf->my_dev_name) {\n\t\trv = -ENOMEM;\n\t\tdev_err(intf->si_dev, \"Unable to allocate link from BMC: %d\\n\",\n\t\t\trv);\n\t\tgoto out_unlink1;\n\t}\n\n\trv = sysfs_create_link(&bmc->pdev.dev.kobj, &intf->si_dev->kobj,\n\t\t\t       intf->my_dev_name);\n\tif (rv) {\n\t\tkfree(intf->my_dev_name);\n\t\tintf->my_dev_name = NULL;\n\t\tdev_err(intf->si_dev, \"Unable to create symlink to bmc: %d\\n\",\n\t\t\trv);\n\t\tgoto out_free_my_dev_name;\n\t}\n\n\tintf->bmc_registered = true;\n\nout:\n\tmutex_unlock(&ipmidriver_mutex);\n\tmutex_lock(&intf->bmc_reg_mutex);\n\tintf->in_bmc_register = false;\n\treturn rv;\n\n\nout_free_my_dev_name:\n\tkfree(intf->my_dev_name);\n\tintf->my_dev_name = NULL;\n\nout_unlink1:\n\tsysfs_remove_link(&intf->si_dev->kobj, \"bmc\");\n\nout_put_bmc:\n\tmutex_lock(&bmc->dyn_mutex);\n\tlist_del(&intf->bmc_link);\n\tmutex_unlock(&bmc->dyn_mutex);\n\tintf->bmc = &intf->tmp_bmc;\n\tkref_put(&bmc->usecount, cleanup_bmc_device);\n\tgoto out;\n\nout_list_del:\n\tmutex_lock(&bmc->dyn_mutex);\n\tlist_del(&intf->bmc_link);\n\tmutex_unlock(&bmc->dyn_mutex);\n\tintf->bmc = &intf->tmp_bmc;\n\tput_device(&bmc->pdev.dev);\n\tgoto out;\n}\n\nstatic int\nsend_guid_cmd(struct ipmi_smi *intf, int chan)\n{\n\tstruct kernel_ipmi_msg            msg;\n\tstruct ipmi_system_interface_addr si;\n\n\tsi.addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsi.channel = IPMI_BMC_CHANNEL;\n\tsi.lun = 0;\n\n\tmsg.netfn = IPMI_NETFN_APP_REQUEST;\n\tmsg.cmd = IPMI_GET_DEVICE_GUID_CMD;\n\tmsg.data = NULL;\n\tmsg.data_len = 0;\n\treturn i_ipmi_request(NULL,\n\t\t\t      intf,\n\t\t\t      (struct ipmi_addr *) &si,\n\t\t\t      0,\n\t\t\t      &msg,\n\t\t\t      intf,\n\t\t\t      NULL,\n\t\t\t      NULL,\n\t\t\t      0,\n\t\t\t      intf->addrinfo[0].address,\n\t\t\t      intf->addrinfo[0].lun,\n\t\t\t      -1, 0);\n}\n\nstatic void guid_handler(struct ipmi_smi *intf, struct ipmi_recv_msg *msg)\n{\n\tstruct bmc_device *bmc = intf->bmc;\n\n\tif ((msg->addr.addr_type != IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t    || (msg->msg.netfn != IPMI_NETFN_APP_RESPONSE)\n\t    || (msg->msg.cmd != IPMI_GET_DEVICE_GUID_CMD))\n\t\t/* Not for me */\n\t\treturn;\n\n\tif (msg->msg.data[0] != 0) {\n\t\t/* Error from getting the GUID, the BMC doesn't have one. */\n\t\tbmc->dyn_guid_set = 0;\n\t\tgoto out;\n\t}\n\n\tif (msg->msg.data_len < UUID_SIZE + 1) {\n\t\tbmc->dyn_guid_set = 0;\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"The GUID response from the BMC was too short, it was %d but should have been %d.  Assuming GUID is not available.\\n\",\n\t\t\t msg->msg.data_len, UUID_SIZE + 1);\n\t\tgoto out;\n\t}\n\n\tguid_copy(&bmc->fetch_guid, (guid_t *)(msg->msg.data + 1));\n\t/*\n\t * Make sure the guid data is available before setting\n\t * dyn_guid_set.\n\t */\n\tsmp_wmb();\n\tbmc->dyn_guid_set = 1;\n out:\n\twake_up(&intf->waitq);\n}\n\nstatic void __get_guid(struct ipmi_smi *intf)\n{\n\tint rv;\n\tstruct bmc_device *bmc = intf->bmc;\n\n\tbmc->dyn_guid_set = 2;\n\tintf->null_user_handler = guid_handler;\n\trv = send_guid_cmd(intf, 0);\n\tif (rv)\n\t\t/* Send failed, no GUID available. */\n\t\tbmc->dyn_guid_set = 0;\n\n\twait_event(intf->waitq, bmc->dyn_guid_set != 2);\n\n\t/* dyn_guid_set makes the guid data available. */\n\tsmp_rmb();\n\n\tintf->null_user_handler = NULL;\n}\n\nstatic int\nsend_channel_info_cmd(struct ipmi_smi *intf, int chan)\n{\n\tstruct kernel_ipmi_msg            msg;\n\tunsigned char                     data[1];\n\tstruct ipmi_system_interface_addr si;\n\n\tsi.addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsi.channel = IPMI_BMC_CHANNEL;\n\tsi.lun = 0;\n\n\tmsg.netfn = IPMI_NETFN_APP_REQUEST;\n\tmsg.cmd = IPMI_GET_CHANNEL_INFO_CMD;\n\tmsg.data = data;\n\tmsg.data_len = 1;\n\tdata[0] = chan;\n\treturn i_ipmi_request(NULL,\n\t\t\t      intf,\n\t\t\t      (struct ipmi_addr *) &si,\n\t\t\t      0,\n\t\t\t      &msg,\n\t\t\t      intf,\n\t\t\t      NULL,\n\t\t\t      NULL,\n\t\t\t      0,\n\t\t\t      intf->addrinfo[0].address,\n\t\t\t      intf->addrinfo[0].lun,\n\t\t\t      -1, 0);\n}\n\nstatic void\nchannel_handler(struct ipmi_smi *intf, struct ipmi_recv_msg *msg)\n{\n\tint rv = 0;\n\tint ch;\n\tunsigned int set = intf->curr_working_cset;\n\tstruct ipmi_channel *chans;\n\n\tif ((msg->addr.addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t    && (msg->msg.netfn == IPMI_NETFN_APP_RESPONSE)\n\t    && (msg->msg.cmd == IPMI_GET_CHANNEL_INFO_CMD)) {\n\t\t/* It's the one we want */\n\t\tif (msg->msg.data[0] != 0) {\n\t\t\t/* Got an error from the channel, just go on. */\n\n\t\t\tif (msg->msg.data[0] == IPMI_INVALID_COMMAND_ERR) {\n\t\t\t\t/*\n\t\t\t\t * If the MC does not support this\n\t\t\t\t * command, that is legal.  We just\n\t\t\t\t * assume it has one IPMB at channel\n\t\t\t\t * zero.\n\t\t\t\t */\n\t\t\t\tintf->wchannels[set].c[0].medium\n\t\t\t\t\t= IPMI_CHANNEL_MEDIUM_IPMB;\n\t\t\t\tintf->wchannels[set].c[0].protocol\n\t\t\t\t\t= IPMI_CHANNEL_PROTOCOL_IPMB;\n\n\t\t\t\tintf->channel_list = intf->wchannels + set;\n\t\t\t\tintf->channels_ready = true;\n\t\t\t\twake_up(&intf->waitq);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tgoto next_channel;\n\t\t}\n\t\tif (msg->msg.data_len < 4) {\n\t\t\t/* Message not big enough, just go on. */\n\t\t\tgoto next_channel;\n\t\t}\n\t\tch = intf->curr_channel;\n\t\tchans = intf->wchannels[set].c;\n\t\tchans[ch].medium = msg->msg.data[2] & 0x7f;\n\t\tchans[ch].protocol = msg->msg.data[3] & 0x1f;\n\n next_channel:\n\t\tintf->curr_channel++;\n\t\tif (intf->curr_channel >= IPMI_MAX_CHANNELS) {\n\t\t\tintf->channel_list = intf->wchannels + set;\n\t\t\tintf->channels_ready = true;\n\t\t\twake_up(&intf->waitq);\n\t\t} else {\n\t\t\tintf->channel_list = intf->wchannels + set;\n\t\t\tintf->channels_ready = true;\n\t\t\trv = send_channel_info_cmd(intf, intf->curr_channel);\n\t\t}\n\n\t\tif (rv) {\n\t\t\t/* Got an error somehow, just give up. */\n\t\t\tdev_warn(intf->si_dev,\n\t\t\t\t \"Error sending channel information for channel %d: %d\\n\",\n\t\t\t\t intf->curr_channel, rv);\n\n\t\t\tintf->channel_list = intf->wchannels + set;\n\t\t\tintf->channels_ready = true;\n\t\t\twake_up(&intf->waitq);\n\t\t}\n\t}\n out:\n\treturn;\n}\n\n/*\n * Must be holding intf->bmc_reg_mutex to call this.\n */\nstatic int __scan_channels(struct ipmi_smi *intf, struct ipmi_device_id *id)\n{\n\tint rv;\n\n\tif (ipmi_version_major(id) > 1\n\t\t\t|| (ipmi_version_major(id) == 1\n\t\t\t    && ipmi_version_minor(id) >= 5)) {\n\t\tunsigned int set;\n\n\t\t/*\n\t\t * Start scanning the channels to see what is\n\t\t * available.\n\t\t */\n\t\tset = !intf->curr_working_cset;\n\t\tintf->curr_working_cset = set;\n\t\tmemset(&intf->wchannels[set], 0,\n\t\t       sizeof(struct ipmi_channel_set));\n\n\t\tintf->null_user_handler = channel_handler;\n\t\tintf->curr_channel = 0;\n\t\trv = send_channel_info_cmd(intf, 0);\n\t\tif (rv) {\n\t\t\tdev_warn(intf->si_dev,\n\t\t\t\t \"Error sending channel information for channel 0, %d\\n\",\n\t\t\t\t rv);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\t/* Wait for the channel info to be read. */\n\t\twait_event(intf->waitq, intf->channels_ready);\n\t\tintf->null_user_handler = NULL;\n\t} else {\n\t\tunsigned int set = intf->curr_working_cset;\n\n\t\t/* Assume a single IPMB channel at zero. */\n\t\tintf->wchannels[set].c[0].medium = IPMI_CHANNEL_MEDIUM_IPMB;\n\t\tintf->wchannels[set].c[0].protocol = IPMI_CHANNEL_PROTOCOL_IPMB;\n\t\tintf->channel_list = intf->wchannels + set;\n\t\tintf->channels_ready = true;\n\t}\n\n\treturn 0;\n}\n\nstatic void ipmi_poll(struct ipmi_smi *intf)\n{\n\tif (intf->handlers->poll)\n\t\tintf->handlers->poll(intf->send_info);\n\t/* In case something came in */\n\thandle_new_recv_msgs(intf);\n}\n\nvoid ipmi_poll_interface(struct ipmi_user *user)\n{\n\tipmi_poll(user->intf);\n}\nEXPORT_SYMBOL(ipmi_poll_interface);\n\nstatic void redo_bmc_reg(struct work_struct *work)\n{\n\tstruct ipmi_smi *intf = container_of(work, struct ipmi_smi,\n\t\t\t\t\t     bmc_reg_work);\n\n\tif (!intf->in_shutdown)\n\t\tbmc_get_device_id(intf, NULL, NULL, NULL, NULL);\n\n\tkref_put(&intf->refcount, intf_free);\n}\n\nint ipmi_add_smi(struct module         *owner,\n\t\t const struct ipmi_smi_handlers *handlers,\n\t\t void\t\t       *send_info,\n\t\t struct device         *si_dev,\n\t\t unsigned char         slave_addr)\n{\n\tint              i, j;\n\tint              rv;\n\tstruct ipmi_smi *intf, *tintf;\n\tstruct list_head *link;\n\tstruct ipmi_device_id id;\n\n\t/*\n\t * Make sure the driver is actually initialized, this handles\n\t * problems with initialization order.\n\t */\n\trv = ipmi_init_msghandler();\n\tif (rv)\n\t\treturn rv;\n\n\tintf = kzalloc(sizeof(*intf), GFP_KERNEL);\n\tif (!intf)\n\t\treturn -ENOMEM;\n\n\trv = init_srcu_struct(&intf->users_srcu);\n\tif (rv) {\n\t\tkfree(intf);\n\t\treturn rv;\n\t}\n\n\tintf->owner = owner;\n\tintf->bmc = &intf->tmp_bmc;\n\tINIT_LIST_HEAD(&intf->bmc->intfs);\n\tmutex_init(&intf->bmc->dyn_mutex);\n\tINIT_LIST_HEAD(&intf->bmc_link);\n\tmutex_init(&intf->bmc_reg_mutex);\n\tintf->intf_num = -1; /* Mark it invalid for now. */\n\tkref_init(&intf->refcount);\n\tINIT_WORK(&intf->bmc_reg_work, redo_bmc_reg);\n\tintf->si_dev = si_dev;\n\tfor (j = 0; j < IPMI_MAX_CHANNELS; j++) {\n\t\tintf->addrinfo[j].address = IPMI_BMC_SLAVE_ADDR;\n\t\tintf->addrinfo[j].lun = 2;\n\t}\n\tif (slave_addr != 0)\n\t\tintf->addrinfo[0].address = slave_addr;\n\tINIT_LIST_HEAD(&intf->users);\n\tintf->handlers = handlers;\n\tintf->send_info = send_info;\n\tspin_lock_init(&intf->seq_lock);\n\tfor (j = 0; j < IPMI_IPMB_NUM_SEQ; j++) {\n\t\tintf->seq_table[j].inuse = 0;\n\t\tintf->seq_table[j].seqid = 0;\n\t}\n\tintf->curr_seq = 0;\n\tspin_lock_init(&intf->waiting_rcv_msgs_lock);\n\tINIT_LIST_HEAD(&intf->waiting_rcv_msgs);\n\ttasklet_init(&intf->recv_tasklet,\n\t\t     smi_recv_tasklet,\n\t\t     (unsigned long) intf);\n\tatomic_set(&intf->watchdog_pretimeouts_to_deliver, 0);\n\tspin_lock_init(&intf->xmit_msgs_lock);\n\tINIT_LIST_HEAD(&intf->xmit_msgs);\n\tINIT_LIST_HEAD(&intf->hp_xmit_msgs);\n\tspin_lock_init(&intf->events_lock);\n\tspin_lock_init(&intf->watch_lock);\n\tatomic_set(&intf->event_waiters, 0);\n\tintf->ticks_to_req_ev = IPMI_REQUEST_EV_TIME;\n\tINIT_LIST_HEAD(&intf->waiting_events);\n\tintf->waiting_events_count = 0;\n\tmutex_init(&intf->cmd_rcvrs_mutex);\n\tspin_lock_init(&intf->maintenance_mode_lock);\n\tINIT_LIST_HEAD(&intf->cmd_rcvrs);\n\tinit_waitqueue_head(&intf->waitq);\n\tfor (i = 0; i < IPMI_NUM_STATS; i++)\n\t\tatomic_set(&intf->stats[i], 0);\n\n\tmutex_lock(&ipmi_interfaces_mutex);\n\t/* Look for a hole in the numbers. */\n\ti = 0;\n\tlink = &ipmi_interfaces;\n\tlist_for_each_entry_rcu(tintf, &ipmi_interfaces, link) {\n\t\tif (tintf->intf_num != i) {\n\t\t\tlink = &tintf->link;\n\t\t\tbreak;\n\t\t}\n\t\ti++;\n\t}\n\t/* Add the new interface in numeric order. */\n\tif (i == 0)\n\t\tlist_add_rcu(&intf->link, &ipmi_interfaces);\n\telse\n\t\tlist_add_tail_rcu(&intf->link, link);\n\n\trv = handlers->start_processing(send_info, intf);\n\tif (rv)\n\t\tgoto out_err;\n\n\trv = __bmc_get_device_id(intf, NULL, &id, NULL, NULL, i);\n\tif (rv) {\n\t\tdev_err(si_dev, \"Unable to get the device id: %d\\n\", rv);\n\t\tgoto out_err_started;\n\t}\n\n\tmutex_lock(&intf->bmc_reg_mutex);\n\trv = __scan_channels(intf, &id);\n\tmutex_unlock(&intf->bmc_reg_mutex);\n\tif (rv)\n\t\tgoto out_err_bmc_reg;\n\n\t/*\n\t * Keep memory order straight for RCU readers.  Make\n\t * sure everything else is committed to memory before\n\t * setting intf_num to mark the interface valid.\n\t */\n\tsmp_wmb();\n\tintf->intf_num = i;\n\tmutex_unlock(&ipmi_interfaces_mutex);\n\n\t/* After this point the interface is legal to use. */\n\tcall_smi_watchers(i, intf->si_dev);\n\n\treturn 0;\n\n out_err_bmc_reg:\n\tipmi_bmc_unregister(intf);\n out_err_started:\n\tif (intf->handlers->shutdown)\n\t\tintf->handlers->shutdown(intf->send_info);\n out_err:\n\tlist_del_rcu(&intf->link);\n\tmutex_unlock(&ipmi_interfaces_mutex);\n\tsynchronize_srcu(&ipmi_interfaces_srcu);\n\tcleanup_srcu_struct(&intf->users_srcu);\n\tkref_put(&intf->refcount, intf_free);\n\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_add_smi);\n\nstatic void deliver_smi_err_response(struct ipmi_smi *intf,\n\t\t\t\t     struct ipmi_smi_msg *msg,\n\t\t\t\t     unsigned char err)\n{\n\tmsg->rsp[0] = msg->data[0] | 4;\n\tmsg->rsp[1] = msg->data[1];\n\tmsg->rsp[2] = err;\n\tmsg->rsp_size = 3;\n\t/* It's an error, so it will never requeue, no need to check return. */\n\thandle_one_recv_msg(intf, msg);\n}\n\nstatic void cleanup_smi_msgs(struct ipmi_smi *intf)\n{\n\tint              i;\n\tstruct seq_table *ent;\n\tstruct ipmi_smi_msg *msg;\n\tstruct list_head *entry;\n\tstruct list_head tmplist;\n\n\t/* Clear out our transmit queues and hold the messages. */\n\tINIT_LIST_HEAD(&tmplist);\n\tlist_splice_tail(&intf->hp_xmit_msgs, &tmplist);\n\tlist_splice_tail(&intf->xmit_msgs, &tmplist);\n\n\t/* Current message first, to preserve order */\n\twhile (intf->curr_msg && !list_empty(&intf->waiting_rcv_msgs)) {\n\t\t/* Wait for the message to clear out. */\n\t\tschedule_timeout(1);\n\t}\n\n\t/* No need for locks, the interface is down. */\n\n\t/*\n\t * Return errors for all pending messages in queue and in the\n\t * tables waiting for remote responses.\n\t */\n\twhile (!list_empty(&tmplist)) {\n\t\tentry = tmplist.next;\n\t\tlist_del(entry);\n\t\tmsg = list_entry(entry, struct ipmi_smi_msg, link);\n\t\tdeliver_smi_err_response(intf, msg, IPMI_ERR_UNSPECIFIED);\n\t}\n\n\tfor (i = 0; i < IPMI_IPMB_NUM_SEQ; i++) {\n\t\tent = &intf->seq_table[i];\n\t\tif (!ent->inuse)\n\t\t\tcontinue;\n\t\tdeliver_err_response(intf, ent->recv_msg, IPMI_ERR_UNSPECIFIED);\n\t}\n}\n\nvoid ipmi_unregister_smi(struct ipmi_smi *intf)\n{\n\tstruct ipmi_smi_watcher *w;\n\tint intf_num = intf->intf_num, index;\n\n\tmutex_lock(&ipmi_interfaces_mutex);\n\tintf->intf_num = -1;\n\tintf->in_shutdown = true;\n\tlist_del_rcu(&intf->link);\n\tmutex_unlock(&ipmi_interfaces_mutex);\n\tsynchronize_srcu(&ipmi_interfaces_srcu);\n\n\t/* At this point no users can be added to the interface. */\n\n\t/*\n\t * Call all the watcher interfaces to tell them that\n\t * an interface is going away.\n\t */\n\tmutex_lock(&smi_watchers_mutex);\n\tlist_for_each_entry(w, &smi_watchers, link)\n\t\tw->smi_gone(intf_num);\n\tmutex_unlock(&smi_watchers_mutex);\n\n\tindex = srcu_read_lock(&intf->users_srcu);\n\twhile (!list_empty(&intf->users)) {\n\t\tstruct ipmi_user *user =\n\t\t\tcontainer_of(list_next_rcu(&intf->users),\n\t\t\t\t     struct ipmi_user, link);\n\n\t\t_ipmi_destroy_user(user);\n\t}\n\tsrcu_read_unlock(&intf->users_srcu, index);\n\n\tif (intf->handlers->shutdown)\n\t\tintf->handlers->shutdown(intf->send_info);\n\n\tcleanup_smi_msgs(intf);\n\n\tipmi_bmc_unregister(intf);\n\n\tcleanup_srcu_struct(&intf->users_srcu);\n\tkref_put(&intf->refcount, intf_free);\n}\nEXPORT_SYMBOL(ipmi_unregister_smi);\n\nstatic int handle_ipmb_get_msg_rsp(struct ipmi_smi *intf,\n\t\t\t\t   struct ipmi_smi_msg *msg)\n{\n\tstruct ipmi_ipmb_addr ipmb_addr;\n\tstruct ipmi_recv_msg  *recv_msg;\n\n\t/*\n\t * This is 11, not 10, because the response must contain a\n\t * completion code.\n\t */\n\tif (msg->rsp_size < 11) {\n\t\t/* Message not big enough, just ignore it. */\n\t\tipmi_inc_stat(intf, invalid_ipmb_responses);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the response, just ignore it. */\n\t\treturn 0;\n\t}\n\n\tipmb_addr.addr_type = IPMI_IPMB_ADDR_TYPE;\n\tipmb_addr.slave_addr = msg->rsp[6];\n\tipmb_addr.channel = msg->rsp[3] & 0x0f;\n\tipmb_addr.lun = msg->rsp[7] & 3;\n\n\t/*\n\t * It's a response from a remote entity.  Look up the sequence\n\t * number and handle the response.\n\t */\n\tif (intf_find_seq(intf,\n\t\t\t  msg->rsp[7] >> 2,\n\t\t\t  msg->rsp[3] & 0x0f,\n\t\t\t  msg->rsp[8],\n\t\t\t  (msg->rsp[4] >> 2) & (~1),\n\t\t\t  (struct ipmi_addr *) &ipmb_addr,\n\t\t\t  &recv_msg)) {\n\t\t/*\n\t\t * We were unable to find the sequence number,\n\t\t * so just nuke the message.\n\t\t */\n\t\tipmi_inc_stat(intf, unhandled_ipmb_responses);\n\t\treturn 0;\n\t}\n\n\tmemcpy(recv_msg->msg_data, &msg->rsp[9], msg->rsp_size - 9);\n\t/*\n\t * The other fields matched, so no need to set them, except\n\t * for netfn, which needs to be the response that was\n\t * returned, not the request value.\n\t */\n\trecv_msg->msg.netfn = msg->rsp[4] >> 2;\n\trecv_msg->msg.data = recv_msg->msg_data;\n\trecv_msg->msg.data_len = msg->rsp_size - 10;\n\trecv_msg->recv_type = IPMI_RESPONSE_RECV_TYPE;\n\tif (deliver_response(intf, recv_msg))\n\t\tipmi_inc_stat(intf, unhandled_ipmb_responses);\n\telse\n\t\tipmi_inc_stat(intf, handled_ipmb_responses);\n\n\treturn 0;\n}\n\nstatic int handle_ipmb_get_msg_cmd(struct ipmi_smi *intf,\n\t\t\t\t   struct ipmi_smi_msg *msg)\n{\n\tstruct cmd_rcvr          *rcvr;\n\tint                      rv = 0;\n\tunsigned char            netfn;\n\tunsigned char            cmd;\n\tunsigned char            chan;\n\tstruct ipmi_user         *user = NULL;\n\tstruct ipmi_ipmb_addr    *ipmb_addr;\n\tstruct ipmi_recv_msg     *recv_msg;\n\n\tif (msg->rsp_size < 10) {\n\t\t/* Message not big enough, just ignore it. */\n\t\tipmi_inc_stat(intf, invalid_commands);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the response, just ignore it. */\n\t\treturn 0;\n\t}\n\n\tnetfn = msg->rsp[4] >> 2;\n\tcmd = msg->rsp[8];\n\tchan = msg->rsp[3] & 0xf;\n\n\trcu_read_lock();\n\trcvr = find_cmd_rcvr(intf, netfn, cmd, chan);\n\tif (rcvr) {\n\t\tuser = rcvr->user;\n\t\tkref_get(&user->refcount);\n\t} else\n\t\tuser = NULL;\n\trcu_read_unlock();\n\n\tif (user == NULL) {\n\t\t/* We didn't find a user, deliver an error response. */\n\t\tipmi_inc_stat(intf, unhandled_commands);\n\n\t\tmsg->data[0] = (IPMI_NETFN_APP_REQUEST << 2);\n\t\tmsg->data[1] = IPMI_SEND_MSG_CMD;\n\t\tmsg->data[2] = msg->rsp[3];\n\t\tmsg->data[3] = msg->rsp[6];\n\t\tmsg->data[4] = ((netfn + 1) << 2) | (msg->rsp[7] & 0x3);\n\t\tmsg->data[5] = ipmb_checksum(&msg->data[3], 2);\n\t\tmsg->data[6] = intf->addrinfo[msg->rsp[3] & 0xf].address;\n\t\t/* rqseq/lun */\n\t\tmsg->data[7] = (msg->rsp[7] & 0xfc) | (msg->rsp[4] & 0x3);\n\t\tmsg->data[8] = msg->rsp[8]; /* cmd */\n\t\tmsg->data[9] = IPMI_INVALID_CMD_COMPLETION_CODE;\n\t\tmsg->data[10] = ipmb_checksum(&msg->data[6], 4);\n\t\tmsg->data_size = 11;\n\n\t\tpr_debug(\"Invalid command: %*ph\\n\", msg->data_size, msg->data);\n\n\t\trcu_read_lock();\n\t\tif (!intf->in_shutdown) {\n\t\t\tsmi_send(intf, intf->handlers, msg, 0);\n\t\t\t/*\n\t\t\t * We used the message, so return the value\n\t\t\t * that causes it to not be freed or\n\t\t\t * queued.\n\t\t\t */\n\t\t\trv = -1;\n\t\t}\n\t\trcu_read_unlock();\n\t} else {\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (!recv_msg) {\n\t\t\t/*\n\t\t\t * We couldn't allocate memory for the\n\t\t\t * message, so requeue it for handling\n\t\t\t * later.\n\t\t\t */\n\t\t\trv = 1;\n\t\t\tkref_put(&user->refcount, free_user);\n\t\t} else {\n\t\t\t/* Extract the source address from the data. */\n\t\t\tipmb_addr = (struct ipmi_ipmb_addr *) &recv_msg->addr;\n\t\t\tipmb_addr->addr_type = IPMI_IPMB_ADDR_TYPE;\n\t\t\tipmb_addr->slave_addr = msg->rsp[6];\n\t\t\tipmb_addr->lun = msg->rsp[7] & 3;\n\t\t\tipmb_addr->channel = msg->rsp[3] & 0xf;\n\n\t\t\t/*\n\t\t\t * Extract the rest of the message information\n\t\t\t * from the IPMB header.\n\t\t\t */\n\t\t\trecv_msg->user = user;\n\t\t\trecv_msg->recv_type = IPMI_CMD_RECV_TYPE;\n\t\t\trecv_msg->msgid = msg->rsp[7] >> 2;\n\t\t\trecv_msg->msg.netfn = msg->rsp[4] >> 2;\n\t\t\trecv_msg->msg.cmd = msg->rsp[8];\n\t\t\trecv_msg->msg.data = recv_msg->msg_data;\n\n\t\t\t/*\n\t\t\t * We chop off 10, not 9 bytes because the checksum\n\t\t\t * at the end also needs to be removed.\n\t\t\t */\n\t\t\trecv_msg->msg.data_len = msg->rsp_size - 10;\n\t\t\tmemcpy(recv_msg->msg_data, &msg->rsp[9],\n\t\t\t       msg->rsp_size - 10);\n\t\t\tif (deliver_response(intf, recv_msg))\n\t\t\t\tipmi_inc_stat(intf, unhandled_commands);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf, handled_commands);\n\t\t}\n\t}\n\n\treturn rv;\n}\n\nstatic int handle_lan_get_msg_rsp(struct ipmi_smi *intf,\n\t\t\t\t  struct ipmi_smi_msg *msg)\n{\n\tstruct ipmi_lan_addr  lan_addr;\n\tstruct ipmi_recv_msg  *recv_msg;\n\n\n\t/*\n\t * This is 13, not 12, because the response must contain a\n\t * completion code.\n\t */\n\tif (msg->rsp_size < 13) {\n\t\t/* Message not big enough, just ignore it. */\n\t\tipmi_inc_stat(intf, invalid_lan_responses);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the response, just ignore it. */\n\t\treturn 0;\n\t}\n\n\tlan_addr.addr_type = IPMI_LAN_ADDR_TYPE;\n\tlan_addr.session_handle = msg->rsp[4];\n\tlan_addr.remote_SWID = msg->rsp[8];\n\tlan_addr.local_SWID = msg->rsp[5];\n\tlan_addr.channel = msg->rsp[3] & 0x0f;\n\tlan_addr.privilege = msg->rsp[3] >> 4;\n\tlan_addr.lun = msg->rsp[9] & 3;\n\n\t/*\n\t * It's a response from a remote entity.  Look up the sequence\n\t * number and handle the response.\n\t */\n\tif (intf_find_seq(intf,\n\t\t\t  msg->rsp[9] >> 2,\n\t\t\t  msg->rsp[3] & 0x0f,\n\t\t\t  msg->rsp[10],\n\t\t\t  (msg->rsp[6] >> 2) & (~1),\n\t\t\t  (struct ipmi_addr *) &lan_addr,\n\t\t\t  &recv_msg)) {\n\t\t/*\n\t\t * We were unable to find the sequence number,\n\t\t * so just nuke the message.\n\t\t */\n\t\tipmi_inc_stat(intf, unhandled_lan_responses);\n\t\treturn 0;\n\t}\n\n\tmemcpy(recv_msg->msg_data, &msg->rsp[11], msg->rsp_size - 11);\n\t/*\n\t * The other fields matched, so no need to set them, except\n\t * for netfn, which needs to be the response that was\n\t * returned, not the request value.\n\t */\n\trecv_msg->msg.netfn = msg->rsp[6] >> 2;\n\trecv_msg->msg.data = recv_msg->msg_data;\n\trecv_msg->msg.data_len = msg->rsp_size - 12;\n\trecv_msg->recv_type = IPMI_RESPONSE_RECV_TYPE;\n\tif (deliver_response(intf, recv_msg))\n\t\tipmi_inc_stat(intf, unhandled_lan_responses);\n\telse\n\t\tipmi_inc_stat(intf, handled_lan_responses);\n\n\treturn 0;\n}\n\nstatic int handle_lan_get_msg_cmd(struct ipmi_smi *intf,\n\t\t\t\t  struct ipmi_smi_msg *msg)\n{\n\tstruct cmd_rcvr          *rcvr;\n\tint                      rv = 0;\n\tunsigned char            netfn;\n\tunsigned char            cmd;\n\tunsigned char            chan;\n\tstruct ipmi_user         *user = NULL;\n\tstruct ipmi_lan_addr     *lan_addr;\n\tstruct ipmi_recv_msg     *recv_msg;\n\n\tif (msg->rsp_size < 12) {\n\t\t/* Message not big enough, just ignore it. */\n\t\tipmi_inc_stat(intf, invalid_commands);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the response, just ignore it. */\n\t\treturn 0;\n\t}\n\n\tnetfn = msg->rsp[6] >> 2;\n\tcmd = msg->rsp[10];\n\tchan = msg->rsp[3] & 0xf;\n\n\trcu_read_lock();\n\trcvr = find_cmd_rcvr(intf, netfn, cmd, chan);\n\tif (rcvr) {\n\t\tuser = rcvr->user;\n\t\tkref_get(&user->refcount);\n\t} else\n\t\tuser = NULL;\n\trcu_read_unlock();\n\n\tif (user == NULL) {\n\t\t/* We didn't find a user, just give up. */\n\t\tipmi_inc_stat(intf, unhandled_commands);\n\n\t\t/*\n\t\t * Don't do anything with these messages, just allow\n\t\t * them to be freed.\n\t\t */\n\t\trv = 0;\n\t} else {\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (!recv_msg) {\n\t\t\t/*\n\t\t\t * We couldn't allocate memory for the\n\t\t\t * message, so requeue it for handling later.\n\t\t\t */\n\t\t\trv = 1;\n\t\t\tkref_put(&user->refcount, free_user);\n\t\t} else {\n\t\t\t/* Extract the source address from the data. */\n\t\t\tlan_addr = (struct ipmi_lan_addr *) &recv_msg->addr;\n\t\t\tlan_addr->addr_type = IPMI_LAN_ADDR_TYPE;\n\t\t\tlan_addr->session_handle = msg->rsp[4];\n\t\t\tlan_addr->remote_SWID = msg->rsp[8];\n\t\t\tlan_addr->local_SWID = msg->rsp[5];\n\t\t\tlan_addr->lun = msg->rsp[9] & 3;\n\t\t\tlan_addr->channel = msg->rsp[3] & 0xf;\n\t\t\tlan_addr->privilege = msg->rsp[3] >> 4;\n\n\t\t\t/*\n\t\t\t * Extract the rest of the message information\n\t\t\t * from the IPMB header.\n\t\t\t */\n\t\t\trecv_msg->user = user;\n\t\t\trecv_msg->recv_type = IPMI_CMD_RECV_TYPE;\n\t\t\trecv_msg->msgid = msg->rsp[9] >> 2;\n\t\t\trecv_msg->msg.netfn = msg->rsp[6] >> 2;\n\t\t\trecv_msg->msg.cmd = msg->rsp[10];\n\t\t\trecv_msg->msg.data = recv_msg->msg_data;\n\n\t\t\t/*\n\t\t\t * We chop off 12, not 11 bytes because the checksum\n\t\t\t * at the end also needs to be removed.\n\t\t\t */\n\t\t\trecv_msg->msg.data_len = msg->rsp_size - 12;\n\t\t\tmemcpy(recv_msg->msg_data, &msg->rsp[11],\n\t\t\t       msg->rsp_size - 12);\n\t\t\tif (deliver_response(intf, recv_msg))\n\t\t\t\tipmi_inc_stat(intf, unhandled_commands);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf, handled_commands);\n\t\t}\n\t}\n\n\treturn rv;\n}\n\n/*\n * This routine will handle \"Get Message\" command responses with\n * channels that use an OEM Medium. The message format belongs to\n * the OEM.  See IPMI 2.0 specification, Chapter 6 and\n * Chapter 22, sections 22.6 and 22.24 for more details.\n */\nstatic int handle_oem_get_msg_cmd(struct ipmi_smi *intf,\n\t\t\t\t  struct ipmi_smi_msg *msg)\n{\n\tstruct cmd_rcvr       *rcvr;\n\tint                   rv = 0;\n\tunsigned char         netfn;\n\tunsigned char         cmd;\n\tunsigned char         chan;\n\tstruct ipmi_user *user = NULL;\n\tstruct ipmi_system_interface_addr *smi_addr;\n\tstruct ipmi_recv_msg  *recv_msg;\n\n\t/*\n\t * We expect the OEM SW to perform error checking\n\t * so we just do some basic sanity checks\n\t */\n\tif (msg->rsp_size < 4) {\n\t\t/* Message not big enough, just ignore it. */\n\t\tipmi_inc_stat(intf, invalid_commands);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the response, just ignore it. */\n\t\treturn 0;\n\t}\n\n\t/*\n\t * This is an OEM Message so the OEM needs to know how\n\t * handle the message. We do no interpretation.\n\t */\n\tnetfn = msg->rsp[0] >> 2;\n\tcmd = msg->rsp[1];\n\tchan = msg->rsp[3] & 0xf;\n\n\trcu_read_lock();\n\trcvr = find_cmd_rcvr(intf, netfn, cmd, chan);\n\tif (rcvr) {\n\t\tuser = rcvr->user;\n\t\tkref_get(&user->refcount);\n\t} else\n\t\tuser = NULL;\n\trcu_read_unlock();\n\n\tif (user == NULL) {\n\t\t/* We didn't find a user, just give up. */\n\t\tipmi_inc_stat(intf, unhandled_commands);\n\n\t\t/*\n\t\t * Don't do anything with these messages, just allow\n\t\t * them to be freed.\n\t\t */\n\n\t\trv = 0;\n\t} else {\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (!recv_msg) {\n\t\t\t/*\n\t\t\t * We couldn't allocate memory for the\n\t\t\t * message, so requeue it for handling\n\t\t\t * later.\n\t\t\t */\n\t\t\trv = 1;\n\t\t\tkref_put(&user->refcount, free_user);\n\t\t} else {\n\t\t\t/*\n\t\t\t * OEM Messages are expected to be delivered via\n\t\t\t * the system interface to SMS software.  We might\n\t\t\t * need to visit this again depending on OEM\n\t\t\t * requirements\n\t\t\t */\n\t\t\tsmi_addr = ((struct ipmi_system_interface_addr *)\n\t\t\t\t    &recv_msg->addr);\n\t\t\tsmi_addr->addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\t\t\tsmi_addr->channel = IPMI_BMC_CHANNEL;\n\t\t\tsmi_addr->lun = msg->rsp[0] & 3;\n\n\t\t\trecv_msg->user = user;\n\t\t\trecv_msg->user_msg_data = NULL;\n\t\t\trecv_msg->recv_type = IPMI_OEM_RECV_TYPE;\n\t\t\trecv_msg->msg.netfn = msg->rsp[0] >> 2;\n\t\t\trecv_msg->msg.cmd = msg->rsp[1];\n\t\t\trecv_msg->msg.data = recv_msg->msg_data;\n\n\t\t\t/*\n\t\t\t * The message starts at byte 4 which follows the\n\t\t\t * the Channel Byte in the \"GET MESSAGE\" command\n\t\t\t */\n\t\t\trecv_msg->msg.data_len = msg->rsp_size - 4;\n\t\t\tmemcpy(recv_msg->msg_data, &msg->rsp[4],\n\t\t\t       msg->rsp_size - 4);\n\t\t\tif (deliver_response(intf, recv_msg))\n\t\t\t\tipmi_inc_stat(intf, unhandled_commands);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf, handled_commands);\n\t\t}\n\t}\n\n\treturn rv;\n}\n\nstatic void copy_event_into_recv_msg(struct ipmi_recv_msg *recv_msg,\n\t\t\t\t     struct ipmi_smi_msg  *msg)\n{\n\tstruct ipmi_system_interface_addr *smi_addr;\n\n\trecv_msg->msgid = 0;\n\tsmi_addr = (struct ipmi_system_interface_addr *) &recv_msg->addr;\n\tsmi_addr->addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsmi_addr->channel = IPMI_BMC_CHANNEL;\n\tsmi_addr->lun = msg->rsp[0] & 3;\n\trecv_msg->recv_type = IPMI_ASYNC_EVENT_RECV_TYPE;\n\trecv_msg->msg.netfn = msg->rsp[0] >> 2;\n\trecv_msg->msg.cmd = msg->rsp[1];\n\tmemcpy(recv_msg->msg_data, &msg->rsp[3], msg->rsp_size - 3);\n\trecv_msg->msg.data = recv_msg->msg_data;\n\trecv_msg->msg.data_len = msg->rsp_size - 3;\n}\n\nstatic int handle_read_event_rsp(struct ipmi_smi *intf,\n\t\t\t\t struct ipmi_smi_msg *msg)\n{\n\tstruct ipmi_recv_msg *recv_msg, *recv_msg2;\n\tstruct list_head     msgs;\n\tstruct ipmi_user     *user;\n\tint rv = 0, deliver_count = 0, index;\n\tunsigned long        flags;\n\n\tif (msg->rsp_size < 19) {\n\t\t/* Message is too small to be an IPMB event. */\n\t\tipmi_inc_stat(intf, invalid_events);\n\t\treturn 0;\n\t}\n\n\tif (msg->rsp[2] != 0) {\n\t\t/* An error getting the event, just ignore it. */\n\t\treturn 0;\n\t}\n\n\tINIT_LIST_HEAD(&msgs);\n\n\tspin_lock_irqsave(&intf->events_lock, flags);\n\n\tipmi_inc_stat(intf, events);\n\n\t/*\n\t * Allocate and fill in one message for every user that is\n\t * getting events.\n\t */\n\tindex = srcu_read_lock(&intf->users_srcu);\n\tlist_for_each_entry_rcu(user, &intf->users, link) {\n\t\tif (!user->gets_events)\n\t\t\tcontinue;\n\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (!recv_msg) {\n\t\t\trcu_read_unlock();\n\t\t\tlist_for_each_entry_safe(recv_msg, recv_msg2, &msgs,\n\t\t\t\t\t\t link) {\n\t\t\t\tlist_del(&recv_msg->link);\n\t\t\t\tipmi_free_recv_msg(recv_msg);\n\t\t\t}\n\t\t\t/*\n\t\t\t * We couldn't allocate memory for the\n\t\t\t * message, so requeue it for handling\n\t\t\t * later.\n\t\t\t */\n\t\t\trv = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tdeliver_count++;\n\n\t\tcopy_event_into_recv_msg(recv_msg, msg);\n\t\trecv_msg->user = user;\n\t\tkref_get(&user->refcount);\n\t\tlist_add_tail(&recv_msg->link, &msgs);\n\t}\n\tsrcu_read_unlock(&intf->users_srcu, index);\n\n\tif (deliver_count) {\n\t\t/* Now deliver all the messages. */\n\t\tlist_for_each_entry_safe(recv_msg, recv_msg2, &msgs, link) {\n\t\t\tlist_del(&recv_msg->link);\n\t\t\tdeliver_local_response(intf, recv_msg);\n\t\t}\n\t} else if (intf->waiting_events_count < MAX_EVENTS_IN_QUEUE) {\n\t\t/*\n\t\t * No one to receive the message, put it in queue if there's\n\t\t * not already too many things in the queue.\n\t\t */\n\t\trecv_msg = ipmi_alloc_recv_msg();\n\t\tif (!recv_msg) {\n\t\t\t/*\n\t\t\t * We couldn't allocate memory for the\n\t\t\t * message, so requeue it for handling\n\t\t\t * later.\n\t\t\t */\n\t\t\trv = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tcopy_event_into_recv_msg(recv_msg, msg);\n\t\tlist_add_tail(&recv_msg->link, &intf->waiting_events);\n\t\tintf->waiting_events_count++;\n\t} else if (!intf->event_msg_printed) {\n\t\t/*\n\t\t * There's too many things in the queue, discard this\n\t\t * message.\n\t\t */\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"Event queue full, discarding incoming events\\n\");\n\t\tintf->event_msg_printed = 1;\n\t}\n\n out:\n\tspin_unlock_irqrestore(&intf->events_lock, flags);\n\n\treturn rv;\n}\n\nstatic int handle_bmc_rsp(struct ipmi_smi *intf,\n\t\t\t  struct ipmi_smi_msg *msg)\n{\n\tstruct ipmi_recv_msg *recv_msg;\n\tstruct ipmi_system_interface_addr *smi_addr;\n\n\trecv_msg = (struct ipmi_recv_msg *) msg->user_data;\n\tif (recv_msg == NULL) {\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"IPMI message received with no owner. This could be because of a malformed message, or because of a hardware error.  Contact your hardware vendor for assistance.\\n\");\n\t\treturn 0;\n\t}\n\n\trecv_msg->recv_type = IPMI_RESPONSE_RECV_TYPE;\n\trecv_msg->msgid = msg->msgid;\n\tsmi_addr = ((struct ipmi_system_interface_addr *)\n\t\t    &recv_msg->addr);\n\tsmi_addr->addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsmi_addr->channel = IPMI_BMC_CHANNEL;\n\tsmi_addr->lun = msg->rsp[0] & 3;\n\trecv_msg->msg.netfn = msg->rsp[0] >> 2;\n\trecv_msg->msg.cmd = msg->rsp[1];\n\tmemcpy(recv_msg->msg_data, &msg->rsp[2], msg->rsp_size - 2);\n\trecv_msg->msg.data = recv_msg->msg_data;\n\trecv_msg->msg.data_len = msg->rsp_size - 2;\n\tdeliver_local_response(intf, recv_msg);\n\n\treturn 0;\n}\n\n/*\n * Handle a received message.  Return 1 if the message should be requeued,\n * 0 if the message should be freed, or -1 if the message should not\n * be freed or requeued.\n */\nstatic int handle_one_recv_msg(struct ipmi_smi *intf,\n\t\t\t       struct ipmi_smi_msg *msg)\n{\n\tint requeue;\n\tint chan;\n\n\tpr_debug(\"Recv: %*ph\\n\", msg->rsp_size, msg->rsp);\n\n\tif ((msg->data_size >= 2)\n\t    && (msg->data[0] == (IPMI_NETFN_APP_REQUEST << 2))\n\t    && (msg->data[1] == IPMI_SEND_MSG_CMD)\n\t    && (msg->user_data == NULL)) {\n\n\t\tif (intf->in_shutdown)\n\t\t\tgoto free_msg;\n\n\t\t/*\n\t\t * This is the local response to a command send, start\n\t\t * the timer for these.  The user_data will not be\n\t\t * NULL if this is a response send, and we will let\n\t\t * response sends just go through.\n\t\t */\n\n\t\t/*\n\t\t * Check for errors, if we get certain errors (ones\n\t\t * that mean basically we can try again later), we\n\t\t * ignore them and start the timer.  Otherwise we\n\t\t * report the error immediately.\n\t\t */\n\t\tif ((msg->rsp_size >= 3) && (msg->rsp[2] != 0)\n\t\t    && (msg->rsp[2] != IPMI_NODE_BUSY_ERR)\n\t\t    && (msg->rsp[2] != IPMI_LOST_ARBITRATION_ERR)\n\t\t    && (msg->rsp[2] != IPMI_BUS_ERR)\n\t\t    && (msg->rsp[2] != IPMI_NAK_ON_WRITE_ERR)) {\n\t\t\tint ch = msg->rsp[3] & 0xf;\n\t\t\tstruct ipmi_channel *chans;\n\n\t\t\t/* Got an error sending the message, handle it. */\n\n\t\t\tchans = READ_ONCE(intf->channel_list)->c;\n\t\t\tif ((chans[ch].medium == IPMI_CHANNEL_MEDIUM_8023LAN)\n\t\t\t    || (chans[ch].medium == IPMI_CHANNEL_MEDIUM_ASYNC))\n\t\t\t\tipmi_inc_stat(intf, sent_lan_command_errs);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf, sent_ipmb_command_errs);\n\t\t\tintf_err_seq(intf, msg->msgid, msg->rsp[2]);\n\t\t} else\n\t\t\t/* The message was sent, start the timer. */\n\t\t\tintf_start_seq_timer(intf, msg->msgid);\nfree_msg:\n\t\trequeue = 0;\n\t\tgoto out;\n\n\t} else if (msg->rsp_size < 2) {\n\t\t/* Message is too small to be correct. */\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"BMC returned too small a message for netfn %x cmd %x, got %d bytes\\n\",\n\t\t\t (msg->data[0] >> 2) | 1, msg->data[1], msg->rsp_size);\n\n\t\t/* Generate an error response for the message. */\n\t\tmsg->rsp[0] = msg->data[0] | (1 << 2);\n\t\tmsg->rsp[1] = msg->data[1];\n\t\tmsg->rsp[2] = IPMI_ERR_UNSPECIFIED;\n\t\tmsg->rsp_size = 3;\n\t} else if (((msg->rsp[0] >> 2) != ((msg->data[0] >> 2) | 1))\n\t\t   || (msg->rsp[1] != msg->data[1])) {\n\t\t/*\n\t\t * The NetFN and Command in the response is not even\n\t\t * marginally correct.\n\t\t */\n\t\tdev_warn(intf->si_dev,\n\t\t\t \"BMC returned incorrect response, expected netfn %x cmd %x, got netfn %x cmd %x\\n\",\n\t\t\t (msg->data[0] >> 2) | 1, msg->data[1],\n\t\t\t msg->rsp[0] >> 2, msg->rsp[1]);\n\n\t\t/* Generate an error response for the message. */\n\t\tmsg->rsp[0] = msg->data[0] | (1 << 2);\n\t\tmsg->rsp[1] = msg->data[1];\n\t\tmsg->rsp[2] = IPMI_ERR_UNSPECIFIED;\n\t\tmsg->rsp_size = 3;\n\t}\n\n\tif ((msg->rsp[0] == ((IPMI_NETFN_APP_REQUEST|1) << 2))\n\t    && (msg->rsp[1] == IPMI_SEND_MSG_CMD)\n\t    && (msg->user_data != NULL)) {\n\t\t/*\n\t\t * It's a response to a response we sent.  For this we\n\t\t * deliver a send message response to the user.\n\t\t */\n\t\tstruct ipmi_recv_msg *recv_msg = msg->user_data;\n\n\t\trequeue = 0;\n\t\tif (msg->rsp_size < 2)\n\t\t\t/* Message is too small to be correct. */\n\t\t\tgoto out;\n\n\t\tchan = msg->data[2] & 0x0f;\n\t\tif (chan >= IPMI_MAX_CHANNELS)\n\t\t\t/* Invalid channel number */\n\t\t\tgoto out;\n\n\t\tif (!recv_msg)\n\t\t\tgoto out;\n\n\t\trecv_msg->recv_type = IPMI_RESPONSE_RESPONSE_TYPE;\n\t\trecv_msg->msg.data = recv_msg->msg_data;\n\t\trecv_msg->msg.data_len = 1;\n\t\trecv_msg->msg_data[0] = msg->rsp[2];\n\t\tdeliver_local_response(intf, recv_msg);\n\t} else if ((msg->rsp[0] == ((IPMI_NETFN_APP_REQUEST|1) << 2))\n\t\t   && (msg->rsp[1] == IPMI_GET_MSG_CMD)) {\n\t\tstruct ipmi_channel   *chans;\n\n\t\t/* It's from the receive queue. */\n\t\tchan = msg->rsp[3] & 0xf;\n\t\tif (chan >= IPMI_MAX_CHANNELS) {\n\t\t\t/* Invalid channel number */\n\t\t\trequeue = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\t/*\n\t\t * We need to make sure the channels have been initialized.\n\t\t * The channel_handler routine will set the \"curr_channel\"\n\t\t * equal to or greater than IPMI_MAX_CHANNELS when all the\n\t\t * channels for this interface have been initialized.\n\t\t */\n\t\tif (!intf->channels_ready) {\n\t\t\trequeue = 0; /* Throw the message away */\n\t\t\tgoto out;\n\t\t}\n\n\t\tchans = READ_ONCE(intf->channel_list)->c;\n\n\t\tswitch (chans[chan].medium) {\n\t\tcase IPMI_CHANNEL_MEDIUM_IPMB:\n\t\t\tif (msg->rsp[4] & 0x04) {\n\t\t\t\t/*\n\t\t\t\t * It's a response, so find the\n\t\t\t\t * requesting message and send it up.\n\t\t\t\t */\n\t\t\t\trequeue = handle_ipmb_get_msg_rsp(intf, msg);\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * It's a command to the SMS from some other\n\t\t\t\t * entity.  Handle that.\n\t\t\t\t */\n\t\t\t\trequeue = handle_ipmb_get_msg_cmd(intf, msg);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase IPMI_CHANNEL_MEDIUM_8023LAN:\n\t\tcase IPMI_CHANNEL_MEDIUM_ASYNC:\n\t\t\tif (msg->rsp[6] & 0x04) {\n\t\t\t\t/*\n\t\t\t\t * It's a response, so find the\n\t\t\t\t * requesting message and send it up.\n\t\t\t\t */\n\t\t\t\trequeue = handle_lan_get_msg_rsp(intf, msg);\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * It's a command to the SMS from some other\n\t\t\t\t * entity.  Handle that.\n\t\t\t\t */\n\t\t\t\trequeue = handle_lan_get_msg_cmd(intf, msg);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\t/* Check for OEM Channels.  Clients had better\n\t\t\t   register for these commands. */\n\t\t\tif ((chans[chan].medium >= IPMI_CHANNEL_MEDIUM_OEM_MIN)\n\t\t\t    && (chans[chan].medium\n\t\t\t\t<= IPMI_CHANNEL_MEDIUM_OEM_MAX)) {\n\t\t\t\trequeue = handle_oem_get_msg_cmd(intf, msg);\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * We don't handle the channel type, so just\n\t\t\t\t * free the message.\n\t\t\t\t */\n\t\t\t\trequeue = 0;\n\t\t\t}\n\t\t}\n\n\t} else if ((msg->rsp[0] == ((IPMI_NETFN_APP_REQUEST|1) << 2))\n\t\t   && (msg->rsp[1] == IPMI_READ_EVENT_MSG_BUFFER_CMD)) {\n\t\t/* It's an asynchronous event. */\n\t\trequeue = handle_read_event_rsp(intf, msg);\n\t} else {\n\t\t/* It's a response from the local BMC. */\n\t\trequeue = handle_bmc_rsp(intf, msg);\n\t}\n\n out:\n\treturn requeue;\n}\n\n/*\n * If there are messages in the queue or pretimeouts, handle them.\n */\nstatic void handle_new_recv_msgs(struct ipmi_smi *intf)\n{\n\tstruct ipmi_smi_msg  *smi_msg;\n\tunsigned long        flags = 0;\n\tint                  rv;\n\tint                  run_to_completion = intf->run_to_completion;\n\n\t/* See if any waiting messages need to be processed. */\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&intf->waiting_rcv_msgs_lock, flags);\n\twhile (!list_empty(&intf->waiting_rcv_msgs)) {\n\t\tsmi_msg = list_entry(intf->waiting_rcv_msgs.next,\n\t\t\t\t     struct ipmi_smi_msg, link);\n\t\tlist_del(&smi_msg->link);\n\t\tif (!run_to_completion)\n\t\t\tspin_unlock_irqrestore(&intf->waiting_rcv_msgs_lock,\n\t\t\t\t\t       flags);\n\t\trv = handle_one_recv_msg(intf, smi_msg);\n\t\tif (!run_to_completion)\n\t\t\tspin_lock_irqsave(&intf->waiting_rcv_msgs_lock, flags);\n\t\tif (rv > 0) {\n\t\t\t/*\n\t\t\t * To preserve message order, quit if we\n\t\t\t * can't handle a message.  Add the message\n\t\t\t * back at the head, this is safe because this\n\t\t\t * tasklet is the only thing that pulls the\n\t\t\t * messages.\n\t\t\t */\n\t\t\tlist_add(&smi_msg->link, &intf->waiting_rcv_msgs);\n\t\t\tbreak;\n\t\t} else {\n\t\t\tif (rv == 0)\n\t\t\t\t/* Message handled */\n\t\t\t\tipmi_free_smi_msg(smi_msg);\n\t\t\t/* If rv < 0, fatal error, del but don't free. */\n\t\t}\n\t}\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&intf->waiting_rcv_msgs_lock, flags);\n\n\t/*\n\t * If the pretimout count is non-zero, decrement one from it and\n\t * deliver pretimeouts to all the users.\n\t */\n\tif (atomic_add_unless(&intf->watchdog_pretimeouts_to_deliver, -1, 0)) {\n\t\tstruct ipmi_user *user;\n\t\tint index;\n\n\t\tindex = srcu_read_lock(&intf->users_srcu);\n\t\tlist_for_each_entry_rcu(user, &intf->users, link) {\n\t\t\tif (user->handler->ipmi_watchdog_pretimeout)\n\t\t\t\tuser->handler->ipmi_watchdog_pretimeout(\n\t\t\t\t\tuser->handler_data);\n\t\t}\n\t\tsrcu_read_unlock(&intf->users_srcu, index);\n\t}\n}\n\nstatic void smi_recv_tasklet(unsigned long val)\n{\n\tunsigned long flags = 0; /* keep us warning-free. */\n\tstruct ipmi_smi *intf = (struct ipmi_smi *) val;\n\tint run_to_completion = intf->run_to_completion;\n\tstruct ipmi_smi_msg *newmsg = NULL;\n\n\t/*\n\t * Start the next message if available.\n\t *\n\t * Do this here, not in the actual receiver, because we may deadlock\n\t * because the lower layer is allowed to hold locks while calling\n\t * message delivery.\n\t */\n\n\trcu_read_lock();\n\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&intf->xmit_msgs_lock, flags);\n\tif (intf->curr_msg == NULL && !intf->in_shutdown) {\n\t\tstruct list_head *entry = NULL;\n\n\t\t/* Pick the high priority queue first. */\n\t\tif (!list_empty(&intf->hp_xmit_msgs))\n\t\t\tentry = intf->hp_xmit_msgs.next;\n\t\telse if (!list_empty(&intf->xmit_msgs))\n\t\t\tentry = intf->xmit_msgs.next;\n\n\t\tif (entry) {\n\t\t\tlist_del(entry);\n\t\t\tnewmsg = list_entry(entry, struct ipmi_smi_msg, link);\n\t\t\tintf->curr_msg = newmsg;\n\t\t}\n\t}\n\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&intf->xmit_msgs_lock, flags);\n\tif (newmsg)\n\t\tintf->handlers->sender(intf->send_info, newmsg);\n\n\trcu_read_unlock();\n\n\thandle_new_recv_msgs(intf);\n}\n\n/* Handle a new message from the lower layer. */\nvoid ipmi_smi_msg_received(struct ipmi_smi *intf,\n\t\t\t   struct ipmi_smi_msg *msg)\n{\n\tunsigned long flags = 0; /* keep us warning-free. */\n\tint run_to_completion = intf->run_to_completion;\n\n\t/*\n\t * To preserve message order, we keep a queue and deliver from\n\t * a tasklet.\n\t */\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&intf->waiting_rcv_msgs_lock, flags);\n\tlist_add_tail(&msg->link, &intf->waiting_rcv_msgs);\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&intf->waiting_rcv_msgs_lock,\n\t\t\t\t       flags);\n\n\tif (!run_to_completion)\n\t\tspin_lock_irqsave(&intf->xmit_msgs_lock, flags);\n\t/*\n\t * We can get an asynchronous event or receive message in addition\n\t * to commands we send.\n\t */\n\tif (msg == intf->curr_msg)\n\t\tintf->curr_msg = NULL;\n\tif (!run_to_completion)\n\t\tspin_unlock_irqrestore(&intf->xmit_msgs_lock, flags);\n\n\tif (run_to_completion)\n\t\tsmi_recv_tasklet((unsigned long) intf);\n\telse\n\t\ttasklet_schedule(&intf->recv_tasklet);\n}\nEXPORT_SYMBOL(ipmi_smi_msg_received);\n\nvoid ipmi_smi_watchdog_pretimeout(struct ipmi_smi *intf)\n{\n\tif (intf->in_shutdown)\n\t\treturn;\n\n\tatomic_set(&intf->watchdog_pretimeouts_to_deliver, 1);\n\ttasklet_schedule(&intf->recv_tasklet);\n}\nEXPORT_SYMBOL(ipmi_smi_watchdog_pretimeout);\n\nstatic struct ipmi_smi_msg *\nsmi_from_recv_msg(struct ipmi_smi *intf, struct ipmi_recv_msg *recv_msg,\n\t\t  unsigned char seq, long seqid)\n{\n\tstruct ipmi_smi_msg *smi_msg = ipmi_alloc_smi_msg();\n\tif (!smi_msg)\n\t\t/*\n\t\t * If we can't allocate the message, then just return, we\n\t\t * get 4 retries, so this should be ok.\n\t\t */\n\t\treturn NULL;\n\n\tmemcpy(smi_msg->data, recv_msg->msg.data, recv_msg->msg.data_len);\n\tsmi_msg->data_size = recv_msg->msg.data_len;\n\tsmi_msg->msgid = STORE_SEQ_IN_MSGID(seq, seqid);\n\n\tpr_debug(\"Resend: %*ph\\n\", smi_msg->data_size, smi_msg->data);\n\n\treturn smi_msg;\n}\n\nstatic void check_msg_timeout(struct ipmi_smi *intf, struct seq_table *ent,\n\t\t\t      struct list_head *timeouts,\n\t\t\t      unsigned long timeout_period,\n\t\t\t      int slot, unsigned long *flags,\n\t\t\t      bool *need_timer)\n{\n\tstruct ipmi_recv_msg *msg;\n\n\tif (intf->in_shutdown)\n\t\treturn;\n\n\tif (!ent->inuse)\n\t\treturn;\n\n\tif (timeout_period < ent->timeout) {\n\t\tent->timeout -= timeout_period;\n\t\t*need_timer = true;\n\t\treturn;\n\t}\n\n\tif (ent->retries_left == 0) {\n\t\t/* The message has used all its retries. */\n\t\tent->inuse = 0;\n\t\tsmi_remove_watch(intf, IPMI_WATCH_MASK_CHECK_MESSAGES);\n\t\tmsg = ent->recv_msg;\n\t\tlist_add_tail(&msg->link, timeouts);\n\t\tif (ent->broadcast)\n\t\t\tipmi_inc_stat(intf, timed_out_ipmb_broadcasts);\n\t\telse if (is_lan_addr(&ent->recv_msg->addr))\n\t\t\tipmi_inc_stat(intf, timed_out_lan_commands);\n\t\telse\n\t\t\tipmi_inc_stat(intf, timed_out_ipmb_commands);\n\t} else {\n\t\tstruct ipmi_smi_msg *smi_msg;\n\t\t/* More retries, send again. */\n\n\t\t*need_timer = true;\n\n\t\t/*\n\t\t * Start with the max timer, set to normal timer after\n\t\t * the message is sent.\n\t\t */\n\t\tent->timeout = MAX_MSG_TIMEOUT;\n\t\tent->retries_left--;\n\t\tsmi_msg = smi_from_recv_msg(intf, ent->recv_msg, slot,\n\t\t\t\t\t    ent->seqid);\n\t\tif (!smi_msg) {\n\t\t\tif (is_lan_addr(&ent->recv_msg->addr))\n\t\t\t\tipmi_inc_stat(intf,\n\t\t\t\t\t      dropped_rexmit_lan_commands);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf,\n\t\t\t\t\t      dropped_rexmit_ipmb_commands);\n\t\t\treturn;\n\t\t}\n\n\t\tspin_unlock_irqrestore(&intf->seq_lock, *flags);\n\n\t\t/*\n\t\t * Send the new message.  We send with a zero\n\t\t * priority.  It timed out, I doubt time is that\n\t\t * critical now, and high priority messages are really\n\t\t * only for messages to the local MC, which don't get\n\t\t * resent.\n\t\t */\n\t\tif (intf->handlers) {\n\t\t\tif (is_lan_addr(&ent->recv_msg->addr))\n\t\t\t\tipmi_inc_stat(intf,\n\t\t\t\t\t      retransmitted_lan_commands);\n\t\t\telse\n\t\t\t\tipmi_inc_stat(intf,\n\t\t\t\t\t      retransmitted_ipmb_commands);\n\n\t\t\tsmi_send(intf, intf->handlers, smi_msg, 0);\n\t\t} else\n\t\t\tipmi_free_smi_msg(smi_msg);\n\n\t\tspin_lock_irqsave(&intf->seq_lock, *flags);\n\t}\n}\n\nstatic bool ipmi_timeout_handler(struct ipmi_smi *intf,\n\t\t\t\t unsigned long timeout_period)\n{\n\tstruct list_head     timeouts;\n\tstruct ipmi_recv_msg *msg, *msg2;\n\tunsigned long        flags;\n\tint                  i;\n\tbool                 need_timer = false;\n\n\tif (!intf->bmc_registered) {\n\t\tkref_get(&intf->refcount);\n\t\tif (!schedule_work(&intf->bmc_reg_work)) {\n\t\t\tkref_put(&intf->refcount, intf_free);\n\t\t\tneed_timer = true;\n\t\t}\n\t}\n\n\t/*\n\t * Go through the seq table and find any messages that\n\t * have timed out, putting them in the timeouts\n\t * list.\n\t */\n\tINIT_LIST_HEAD(&timeouts);\n\tspin_lock_irqsave(&intf->seq_lock, flags);\n\tif (intf->ipmb_maintenance_mode_timeout) {\n\t\tif (intf->ipmb_maintenance_mode_timeout <= timeout_period)\n\t\t\tintf->ipmb_maintenance_mode_timeout = 0;\n\t\telse\n\t\t\tintf->ipmb_maintenance_mode_timeout -= timeout_period;\n\t}\n\tfor (i = 0; i < IPMI_IPMB_NUM_SEQ; i++)\n\t\tcheck_msg_timeout(intf, &intf->seq_table[i],\n\t\t\t\t  &timeouts, timeout_period, i,\n\t\t\t\t  &flags, &need_timer);\n\tspin_unlock_irqrestore(&intf->seq_lock, flags);\n\n\tlist_for_each_entry_safe(msg, msg2, &timeouts, link)\n\t\tdeliver_err_response(intf, msg, IPMI_TIMEOUT_COMPLETION_CODE);\n\n\t/*\n\t * Maintenance mode handling.  Check the timeout\n\t * optimistically before we claim the lock.  It may\n\t * mean a timeout gets missed occasionally, but that\n\t * only means the timeout gets extended by one period\n\t * in that case.  No big deal, and it avoids the lock\n\t * most of the time.\n\t */\n\tif (intf->auto_maintenance_timeout > 0) {\n\t\tspin_lock_irqsave(&intf->maintenance_mode_lock, flags);\n\t\tif (intf->auto_maintenance_timeout > 0) {\n\t\t\tintf->auto_maintenance_timeout\n\t\t\t\t-= timeout_period;\n\t\t\tif (!intf->maintenance_mode\n\t\t\t    && (intf->auto_maintenance_timeout <= 0)) {\n\t\t\t\tintf->maintenance_mode_enable = false;\n\t\t\t\tmaintenance_mode_update(intf);\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irqrestore(&intf->maintenance_mode_lock,\n\t\t\t\t       flags);\n\t}\n\n\ttasklet_schedule(&intf->recv_tasklet);\n\n\treturn need_timer;\n}\n\nstatic void ipmi_request_event(struct ipmi_smi *intf)\n{\n\t/* No event requests when in maintenance mode. */\n\tif (intf->maintenance_mode_enable)\n\t\treturn;\n\n\tif (!intf->in_shutdown)\n\t\tintf->handlers->request_events(intf->send_info);\n}\n\nstatic struct timer_list ipmi_timer;\n\nstatic atomic_t stop_operation;\n\nstatic void ipmi_timeout(struct timer_list *unused)\n{\n\tstruct ipmi_smi *intf;\n\tbool need_timer = false;\n\tint index;\n\n\tif (atomic_read(&stop_operation))\n\t\treturn;\n\n\tindex = srcu_read_lock(&ipmi_interfaces_srcu);\n\tlist_for_each_entry_rcu(intf, &ipmi_interfaces, link) {\n\t\tif (atomic_read(&intf->event_waiters)) {\n\t\t\tintf->ticks_to_req_ev--;\n\t\t\tif (intf->ticks_to_req_ev == 0) {\n\t\t\t\tipmi_request_event(intf);\n\t\t\t\tintf->ticks_to_req_ev = IPMI_REQUEST_EV_TIME;\n\t\t\t}\n\t\t\tneed_timer = true;\n\t\t}\n\n\t\tneed_timer |= ipmi_timeout_handler(intf, IPMI_TIMEOUT_TIME);\n\t}\n\tsrcu_read_unlock(&ipmi_interfaces_srcu, index);\n\n\tif (need_timer)\n\t\tmod_timer(&ipmi_timer, jiffies + IPMI_TIMEOUT_JIFFIES);\n}\n\nstatic void need_waiter(struct ipmi_smi *intf)\n{\n\t/* Racy, but worst case we start the timer twice. */\n\tif (!timer_pending(&ipmi_timer))\n\t\tmod_timer(&ipmi_timer, jiffies + IPMI_TIMEOUT_JIFFIES);\n}\n\nstatic atomic_t smi_msg_inuse_count = ATOMIC_INIT(0);\nstatic atomic_t recv_msg_inuse_count = ATOMIC_INIT(0);\n\nstatic void free_smi_msg(struct ipmi_smi_msg *msg)\n{\n\tatomic_dec(&smi_msg_inuse_count);\n\tkfree(msg);\n}\n\nstruct ipmi_smi_msg *ipmi_alloc_smi_msg(void)\n{\n\tstruct ipmi_smi_msg *rv;\n\trv = kmalloc(sizeof(struct ipmi_smi_msg), GFP_ATOMIC);\n\tif (rv) {\n\t\trv->done = free_smi_msg;\n\t\trv->user_data = NULL;\n\t\tatomic_inc(&smi_msg_inuse_count);\n\t}\n\treturn rv;\n}\nEXPORT_SYMBOL(ipmi_alloc_smi_msg);\n\nstatic void free_recv_msg(struct ipmi_recv_msg *msg)\n{\n\tatomic_dec(&recv_msg_inuse_count);\n\tkfree(msg);\n}\n\nstatic struct ipmi_recv_msg *ipmi_alloc_recv_msg(void)\n{\n\tstruct ipmi_recv_msg *rv;\n\n\trv = kmalloc(sizeof(struct ipmi_recv_msg), GFP_ATOMIC);\n\tif (rv) {\n\t\trv->user = NULL;\n\t\trv->done = free_recv_msg;\n\t\tatomic_inc(&recv_msg_inuse_count);\n\t}\n\treturn rv;\n}\n\nvoid ipmi_free_recv_msg(struct ipmi_recv_msg *msg)\n{\n\tif (msg->user)\n\t\tkref_put(&msg->user->refcount, free_user);\n\tmsg->done(msg);\n}\nEXPORT_SYMBOL(ipmi_free_recv_msg);\n\nstatic atomic_t panic_done_count = ATOMIC_INIT(0);\n\nstatic void dummy_smi_done_handler(struct ipmi_smi_msg *msg)\n{\n\tatomic_dec(&panic_done_count);\n}\n\nstatic void dummy_recv_done_handler(struct ipmi_recv_msg *msg)\n{\n\tatomic_dec(&panic_done_count);\n}\n\n/*\n * Inside a panic, send a message and wait for a response.\n */\nstatic void ipmi_panic_request_and_wait(struct ipmi_smi *intf,\n\t\t\t\t\tstruct ipmi_addr *addr,\n\t\t\t\t\tstruct kernel_ipmi_msg *msg)\n{\n\tstruct ipmi_smi_msg  smi_msg;\n\tstruct ipmi_recv_msg recv_msg;\n\tint rv;\n\n\tsmi_msg.done = dummy_smi_done_handler;\n\trecv_msg.done = dummy_recv_done_handler;\n\tatomic_add(2, &panic_done_count);\n\trv = i_ipmi_request(NULL,\n\t\t\t    intf,\n\t\t\t    addr,\n\t\t\t    0,\n\t\t\t    msg,\n\t\t\t    intf,\n\t\t\t    &smi_msg,\n\t\t\t    &recv_msg,\n\t\t\t    0,\n\t\t\t    intf->addrinfo[0].address,\n\t\t\t    intf->addrinfo[0].lun,\n\t\t\t    0, 1); /* Don't retry, and don't wait. */\n\tif (rv)\n\t\tatomic_sub(2, &panic_done_count);\n\telse if (intf->handlers->flush_messages)\n\t\tintf->handlers->flush_messages(intf->send_info);\n\n\twhile (atomic_read(&panic_done_count) != 0)\n\t\tipmi_poll(intf);\n}\n\nstatic void event_receiver_fetcher(struct ipmi_smi *intf,\n\t\t\t\t   struct ipmi_recv_msg *msg)\n{\n\tif ((msg->addr.addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t    && (msg->msg.netfn == IPMI_NETFN_SENSOR_EVENT_RESPONSE)\n\t    && (msg->msg.cmd == IPMI_GET_EVENT_RECEIVER_CMD)\n\t    && (msg->msg.data[0] == IPMI_CC_NO_ERROR)) {\n\t\t/* A get event receiver command, save it. */\n\t\tintf->event_receiver = msg->msg.data[1];\n\t\tintf->event_receiver_lun = msg->msg.data[2] & 0x3;\n\t}\n}\n\nstatic void device_id_fetcher(struct ipmi_smi *intf, struct ipmi_recv_msg *msg)\n{\n\tif ((msg->addr.addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE)\n\t    && (msg->msg.netfn == IPMI_NETFN_APP_RESPONSE)\n\t    && (msg->msg.cmd == IPMI_GET_DEVICE_ID_CMD)\n\t    && (msg->msg.data[0] == IPMI_CC_NO_ERROR)) {\n\t\t/*\n\t\t * A get device id command, save if we are an event\n\t\t * receiver or generator.\n\t\t */\n\t\tintf->local_sel_device = (msg->msg.data[6] >> 2) & 1;\n\t\tintf->local_event_generator = (msg->msg.data[6] >> 5) & 1;\n\t}\n}\n\nstatic void send_panic_events(struct ipmi_smi *intf, char *str)\n{\n\tstruct kernel_ipmi_msg msg;\n\tunsigned char data[16];\n\tstruct ipmi_system_interface_addr *si;\n\tstruct ipmi_addr addr;\n\tchar *p = str;\n\tstruct ipmi_ipmb_addr *ipmb;\n\tint j;\n\n\tif (ipmi_send_panic_event == IPMI_SEND_PANIC_EVENT_NONE)\n\t\treturn;\n\n\tsi = (struct ipmi_system_interface_addr *) &addr;\n\tsi->addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\tsi->channel = IPMI_BMC_CHANNEL;\n\tsi->lun = 0;\n\n\t/* Fill in an event telling that we have failed. */\n\tmsg.netfn = 0x04; /* Sensor or Event. */\n\tmsg.cmd = 2; /* Platform event command. */\n\tmsg.data = data;\n\tmsg.data_len = 8;\n\tdata[0] = 0x41; /* Kernel generator ID, IPMI table 5-4 */\n\tdata[1] = 0x03; /* This is for IPMI 1.0. */\n\tdata[2] = 0x20; /* OS Critical Stop, IPMI table 36-3 */\n\tdata[4] = 0x6f; /* Sensor specific, IPMI table 36-1 */\n\tdata[5] = 0xa1; /* Runtime stop OEM bytes 2 & 3. */\n\n\t/*\n\t * Put a few breadcrumbs in.  Hopefully later we can add more things\n\t * to make the panic events more useful.\n\t */\n\tif (str) {\n\t\tdata[3] = str[0];\n\t\tdata[6] = str[1];\n\t\tdata[7] = str[2];\n\t}\n\n\t/* Send the event announcing the panic. */\n\tipmi_panic_request_and_wait(intf, &addr, &msg);\n\n\t/*\n\t * On every interface, dump a bunch of OEM event holding the\n\t * string.\n\t */\n\tif (ipmi_send_panic_event != IPMI_SEND_PANIC_EVENT_STRING || !str)\n\t\treturn;\n\n\t/*\n\t * intf_num is used as an marker to tell if the\n\t * interface is valid.  Thus we need a read barrier to\n\t * make sure data fetched before checking intf_num\n\t * won't be used.\n\t */\n\tsmp_rmb();\n\n\t/*\n\t * First job here is to figure out where to send the\n\t * OEM events.  There's no way in IPMI to send OEM\n\t * events using an event send command, so we have to\n\t * find the SEL to put them in and stick them in\n\t * there.\n\t */\n\n\t/* Get capabilities from the get device id. */\n\tintf->local_sel_device = 0;\n\tintf->local_event_generator = 0;\n\tintf->event_receiver = 0;\n\n\t/* Request the device info from the local MC. */\n\tmsg.netfn = IPMI_NETFN_APP_REQUEST;\n\tmsg.cmd = IPMI_GET_DEVICE_ID_CMD;\n\tmsg.data = NULL;\n\tmsg.data_len = 0;\n\tintf->null_user_handler = device_id_fetcher;\n\tipmi_panic_request_and_wait(intf, &addr, &msg);\n\n\tif (intf->local_event_generator) {\n\t\t/* Request the event receiver from the local MC. */\n\t\tmsg.netfn = IPMI_NETFN_SENSOR_EVENT_REQUEST;\n\t\tmsg.cmd = IPMI_GET_EVENT_RECEIVER_CMD;\n\t\tmsg.data = NULL;\n\t\tmsg.data_len = 0;\n\t\tintf->null_user_handler = event_receiver_fetcher;\n\t\tipmi_panic_request_and_wait(intf, &addr, &msg);\n\t}\n\tintf->null_user_handler = NULL;\n\n\t/*\n\t * Validate the event receiver.  The low bit must not\n\t * be 1 (it must be a valid IPMB address), it cannot\n\t * be zero, and it must not be my address.\n\t */\n\tif (((intf->event_receiver & 1) == 0)\n\t    && (intf->event_receiver != 0)\n\t    && (intf->event_receiver != intf->addrinfo[0].address)) {\n\t\t/*\n\t\t * The event receiver is valid, send an IPMB\n\t\t * message.\n\t\t */\n\t\tipmb = (struct ipmi_ipmb_addr *) &addr;\n\t\tipmb->addr_type = IPMI_IPMB_ADDR_TYPE;\n\t\tipmb->channel = 0; /* FIXME - is this right? */\n\t\tipmb->lun = intf->event_receiver_lun;\n\t\tipmb->slave_addr = intf->event_receiver;\n\t} else if (intf->local_sel_device) {\n\t\t/*\n\t\t * The event receiver was not valid (or was\n\t\t * me), but I am an SEL device, just dump it\n\t\t * in my SEL.\n\t\t */\n\t\tsi = (struct ipmi_system_interface_addr *) &addr;\n\t\tsi->addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;\n\t\tsi->channel = IPMI_BMC_CHANNEL;\n\t\tsi->lun = 0;\n\t} else\n\t\treturn; /* No where to send the event. */\n\n\tmsg.netfn = IPMI_NETFN_STORAGE_REQUEST; /* Storage. */\n\tmsg.cmd = IPMI_ADD_SEL_ENTRY_CMD;\n\tmsg.data = data;\n\tmsg.data_len = 16;\n\n\tj = 0;\n\twhile (*p) {\n\t\tint size = strlen(p);\n\n\t\tif (size > 11)\n\t\t\tsize = 11;\n\t\tdata[0] = 0;\n\t\tdata[1] = 0;\n\t\tdata[2] = 0xf0; /* OEM event without timestamp. */\n\t\tdata[3] = intf->addrinfo[0].address;\n\t\tdata[4] = j++; /* sequence # */\n\t\t/*\n\t\t * Always give 11 bytes, so strncpy will fill\n\t\t * it with zeroes for me.\n\t\t */\n\t\tstrncpy(data+5, p, 11);\n\t\tp += size;\n\n\t\tipmi_panic_request_and_wait(intf, &addr, &msg);\n\t}\n}\n\nstatic int has_panicked;\n\nstatic int panic_event(struct notifier_block *this,\n\t\t       unsigned long         event,\n\t\t       void                  *ptr)\n{\n\tstruct ipmi_smi *intf;\n\tstruct ipmi_user *user;\n\n\tif (has_panicked)\n\t\treturn NOTIFY_DONE;\n\thas_panicked = 1;\n\n\t/* For every registered interface, set it to run to completion. */\n\tlist_for_each_entry_rcu(intf, &ipmi_interfaces, link) {\n\t\tif (!intf->handlers || intf->intf_num == -1)\n\t\t\t/* Interface is not ready. */\n\t\t\tcontinue;\n\n\t\tif (!intf->handlers->poll)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If we were interrupted while locking xmit_msgs_lock or\n\t\t * waiting_rcv_msgs_lock, the corresponding list may be\n\t\t * corrupted.  In this case, drop items on the list for\n\t\t * the safety.\n\t\t */\n\t\tif (!spin_trylock(&intf->xmit_msgs_lock)) {\n\t\t\tINIT_LIST_HEAD(&intf->xmit_msgs);\n\t\t\tINIT_LIST_HEAD(&intf->hp_xmit_msgs);\n\t\t} else\n\t\t\tspin_unlock(&intf->xmit_msgs_lock);\n\n\t\tif (!spin_trylock(&intf->waiting_rcv_msgs_lock))\n\t\t\tINIT_LIST_HEAD(&intf->waiting_rcv_msgs);\n\t\telse\n\t\t\tspin_unlock(&intf->waiting_rcv_msgs_lock);\n\n\t\tintf->run_to_completion = 1;\n\t\tif (intf->handlers->set_run_to_completion)\n\t\t\tintf->handlers->set_run_to_completion(intf->send_info,\n\t\t\t\t\t\t\t      1);\n\n\t\tlist_for_each_entry_rcu(user, &intf->users, link) {\n\t\t\tif (user->handler->ipmi_panic_handler)\n\t\t\t\tuser->handler->ipmi_panic_handler(\n\t\t\t\t\tuser->handler_data);\n\t\t}\n\n\t\tsend_panic_events(intf, ptr);\n\t}\n\n\treturn NOTIFY_DONE;\n}\n\n/* Must be called with ipmi_interfaces_mutex held. */\nstatic int ipmi_register_driver(void)\n{\n\tint rv;\n\n\tif (drvregistered)\n\t\treturn 0;\n\n\trv = driver_register(&ipmidriver.driver);\n\tif (rv)\n\t\tpr_err(\"Could not register IPMI driver\\n\");\n\telse\n\t\tdrvregistered = true;\n\treturn rv;\n}\n\nstatic struct notifier_block panic_block = {\n\t.notifier_call\t= panic_event,\n\t.next\t\t= NULL,\n\t.priority\t= 200\t/* priority: INT_MAX >= x >= 0 */\n};\n\nstatic int ipmi_init_msghandler(void)\n{\n\tint rv;\n\n\tmutex_lock(&ipmi_interfaces_mutex);\n\trv = ipmi_register_driver();\n\tif (rv)\n\t\tgoto out;\n\tif (initialized)\n\t\tgoto out;\n\n\tinit_srcu_struct(&ipmi_interfaces_srcu);\n\n\ttimer_setup(&ipmi_timer, ipmi_timeout, 0);\n\tmod_timer(&ipmi_timer, jiffies + IPMI_TIMEOUT_JIFFIES);\n\n\tatomic_notifier_chain_register(&panic_notifier_list, &panic_block);\n\n\tinitialized = true;\n\nout:\n\tmutex_unlock(&ipmi_interfaces_mutex);\n\treturn rv;\n}\n\nstatic int __init ipmi_init_msghandler_mod(void)\n{\n\tint rv;\n\n\tpr_info(\"version \" IPMI_DRIVER_VERSION \"\\n\");\n\n\tmutex_lock(&ipmi_interfaces_mutex);\n\trv = ipmi_register_driver();\n\tmutex_unlock(&ipmi_interfaces_mutex);\n\n\treturn rv;\n}\n\nstatic void __exit cleanup_ipmi(void)\n{\n\tint count;\n\n\tif (initialized) {\n\t\tatomic_notifier_chain_unregister(&panic_notifier_list,\n\t\t\t\t\t\t &panic_block);\n\n\t\t/*\n\t\t * This can't be called if any interfaces exist, so no worry\n\t\t * about shutting down the interfaces.\n\t\t */\n\n\t\t/*\n\t\t * Tell the timer to stop, then wait for it to stop.  This\n\t\t * avoids problems with race conditions removing the timer\n\t\t * here.\n\t\t */\n\t\tatomic_set(&stop_operation, 1);\n\t\tdel_timer_sync(&ipmi_timer);\n\n\t\tinitialized = false;\n\n\t\t/* Check for buffer leaks. */\n\t\tcount = atomic_read(&smi_msg_inuse_count);\n\t\tif (count != 0)\n\t\t\tpr_warn(\"SMI message count %d at exit\\n\", count);\n\t\tcount = atomic_read(&recv_msg_inuse_count);\n\t\tif (count != 0)\n\t\t\tpr_warn(\"recv message count %d at exit\\n\", count);\n\n\t\tcleanup_srcu_struct(&ipmi_interfaces_srcu);\n\t}\n\tif (drvregistered)\n\t\tdriver_unregister(&ipmidriver.driver);\n}\nmodule_exit(cleanup_ipmi);\n\nmodule_init(ipmi_init_msghandler_mod);\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Corey Minyard <minyard@mvista.com>\");\nMODULE_DESCRIPTION(\"Incoming and outgoing message routing for an IPMI\"\n\t\t   \" interface.\");\nMODULE_VERSION(IPMI_DRIVER_VERSION);\nMODULE_SOFTDEP(\"post: ipmi_devintf\");\n"], "filenames": ["drivers/char/ipmi/ipmi_msghandler.c"], "buggy_code_start_loc": [3023], "buggy_code_end_loc": [3024], "fixing_code_start_loc": [3023], "fixing_code_end_loc": [3028], "type": "CWE-401", "message": "** DISPUTED ** A memory leak in the __ipmi_bmc_register() function in drivers/char/ipmi/ipmi_msghandler.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering ida_simple_get() failure, aka CID-4aa7afb0ee20. NOTE: third parties dispute the relevance of this because an attacker cannot realistically control this failure at probe time.", "other": {"cve": {"id": "CVE-2019-19046", "sourceIdentifier": "cve@mitre.org", "published": "2019-11-18T06:15:11.437", "lastModified": "2020-08-24T17:37:01.140", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "** DISPUTED ** A memory leak in the __ipmi_bmc_register() function in drivers/char/ipmi/ipmi_msghandler.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering ida_simple_get() failure, aka CID-4aa7afb0ee20. NOTE: third parties dispute the relevance of this because an attacker cannot realistically control this failure at probe time."}, {"lang": "es", "value": "** EN DISPUTA ** Una p\u00e9rdida de memoria en la funci\u00f3n __ipmi_bmc_register() en el archivo drivers/char/ipmi/ipmi_msghandler.c en el kernel de Linux versiones hasta la versi\u00f3n 5.3.11, permite a atacantes causar una denegaci\u00f3n de servicio (consumo de memoria) al desencadenar un fallo de la funci\u00f3n ida_simple_get (), tambi\u00e9n se conoce como CID-4aa7afb0ee20. NOTA: terceros discuten la relevancia de esto porque un atacante no puede controlar de manera realista esta falla en el momento de la investigaci\u00f3n."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:S/C:N/I:N/A:C", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 6.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.0, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-401"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "5.3.11", "matchCriteriaId": "EB2904AC-AD7A-498D-8619-CBB421E9165D"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:30:*:*:*:*:*:*:*", "matchCriteriaId": "97A4B8DF-58DA-4AB6-A1F9-331B36409BA3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:31:*:*:*:*:*:*:*", "matchCriteriaId": "80F0FA5D-8D3B-4C0E-81E2-87998286AF33"}, {"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:15.1:*:*:*:*:*:*:*", "matchCriteriaId": "B620311B-34A3-48A6-82DF-6F078D7A4493"}]}]}], "references": [{"url": "http://lists.opensuse.org/opensuse-security-announce/2019-12/msg00029.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://bugzilla.suse.com/show_bug.cgi?id=1157304", "source": "cve@mitre.org", "tags": ["Issue Tracking"]}, {"url": "https://github.com/torvalds/linux/commit/4aa7afb0ee20a97fbf0c5bab3df028d5fb85fdab", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/O3PSDE6PTOTVBK2YTKB2TFQP2SUBVSNF/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/PY7LJMSPAGRIKABJPDKQDTXYW3L5RX2T/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4302-1/", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/4319-1/", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/4325-1/", "source": "cve@mitre.org"}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/4aa7afb0ee20a97fbf0c5bab3df028d5fb85fdab"}}
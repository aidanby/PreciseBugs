{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0-or-later\n/*\n * Copyright (C) 2006, 2007, 2009 Rusty Russell, IBM Corporation\n * Copyright (C) 2009, 2010, 2011 Red Hat, Inc.\n * Copyright (C) 2009, 2010, 2011 Amit Shah <amit.shah@redhat.com>\n */\n#include <linux/cdev.h>\n#include <linux/debugfs.h>\n#include <linux/completion.h>\n#include <linux/device.h>\n#include <linux/err.h>\n#include <linux/freezer.h>\n#include <linux/fs.h>\n#include <linux/splice.h>\n#include <linux/pagemap.h>\n#include <linux/init.h>\n#include <linux/list.h>\n#include <linux/poll.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/virtio.h>\n#include <linux/virtio_console.h>\n#include <linux/wait.h>\n#include <linux/workqueue.h>\n#include <linux/module.h>\n#include <linux/dma-mapping.h>\n#include \"../tty/hvc/hvc_console.h\"\n\n#define is_rproc_enabled IS_ENABLED(CONFIG_REMOTEPROC)\n\n/*\n * This is a global struct for storing common data for all the devices\n * this driver handles.\n *\n * Mainly, it has a linked list for all the consoles in one place so\n * that callbacks from hvc for get_chars(), put_chars() work properly\n * across multiple devices and multiple ports per device.\n */\nstruct ports_driver_data {\n\t/* Used for registering chardevs */\n\tstruct class *class;\n\n\t/* Used for exporting per-port information to debugfs */\n\tstruct dentry *debugfs_dir;\n\n\t/* List of all the devices we're handling */\n\tstruct list_head portdevs;\n\n\t/*\n\t * This is used to keep track of the number of hvc consoles\n\t * spawned by this driver.  This number is given as the first\n\t * argument to hvc_alloc().  To correctly map an initial\n\t * console spawned via hvc_instantiate to the console being\n\t * hooked up via hvc_alloc, we need to pass the same vtermno.\n\t *\n\t * We also just assume the first console being initialised was\n\t * the first one that got used as the initial console.\n\t */\n\tunsigned int next_vtermno;\n\n\t/* All the console devices handled by this driver */\n\tstruct list_head consoles;\n};\nstatic struct ports_driver_data pdrvdata = { .next_vtermno = 1};\n\nstatic DEFINE_SPINLOCK(pdrvdata_lock);\nstatic DECLARE_COMPLETION(early_console_added);\n\n/* This struct holds information that's relevant only for console ports */\nstruct console {\n\t/* We'll place all consoles in a list in the pdrvdata struct */\n\tstruct list_head list;\n\n\t/* The hvc device associated with this console port */\n\tstruct hvc_struct *hvc;\n\n\t/* The size of the console */\n\tstruct winsize ws;\n\n\t/*\n\t * This number identifies the number that we used to register\n\t * with hvc in hvc_instantiate() and hvc_alloc(); this is the\n\t * number passed on by the hvc callbacks to us to\n\t * differentiate between the other console ports handled by\n\t * this driver\n\t */\n\tu32 vtermno;\n};\n\nstruct port_buffer {\n\tchar *buf;\n\n\t/* size of the buffer in *buf above */\n\tsize_t size;\n\n\t/* used length of the buffer */\n\tsize_t len;\n\t/* offset in the buf from which to consume data */\n\tsize_t offset;\n\n\t/* DMA address of buffer */\n\tdma_addr_t dma;\n\n\t/* Device we got DMA memory from */\n\tstruct device *dev;\n\n\t/* List of pending dma buffers to free */\n\tstruct list_head list;\n\n\t/* If sgpages == 0 then buf is used */\n\tunsigned int sgpages;\n\n\t/* sg is used if spages > 0. sg must be the last in is struct */\n\tstruct scatterlist sg[];\n};\n\n/*\n * This is a per-device struct that stores data common to all the\n * ports for that device (vdev->priv).\n */\nstruct ports_device {\n\t/* Next portdev in the list, head is in the pdrvdata struct */\n\tstruct list_head list;\n\n\t/*\n\t * Workqueue handlers where we process deferred work after\n\t * notification\n\t */\n\tstruct work_struct control_work;\n\tstruct work_struct config_work;\n\n\tstruct list_head ports;\n\n\t/* To protect the list of ports */\n\tspinlock_t ports_lock;\n\n\t/* To protect the vq operations for the control channel */\n\tspinlock_t c_ivq_lock;\n\tspinlock_t c_ovq_lock;\n\n\t/* max. number of ports this device can hold */\n\tu32 max_nr_ports;\n\n\t/* The virtio device we're associated with */\n\tstruct virtio_device *vdev;\n\n\t/*\n\t * A couple of virtqueues for the control channel: one for\n\t * guest->host transfers, one for host->guest transfers\n\t */\n\tstruct virtqueue *c_ivq, *c_ovq;\n\n\t/*\n\t * A control packet buffer for guest->host requests, protected\n\t * by c_ovq_lock.\n\t */\n\tstruct virtio_console_control cpkt;\n\n\t/* Array of per-port IO virtqueues */\n\tstruct virtqueue **in_vqs, **out_vqs;\n\n\t/* Major number for this device.  Ports will be created as minors. */\n\tint chr_major;\n};\n\nstruct port_stats {\n\tunsigned long bytes_sent, bytes_received, bytes_discarded;\n};\n\n/* This struct holds the per-port data */\nstruct port {\n\t/* Next port in the list, head is in the ports_device */\n\tstruct list_head list;\n\n\t/* Pointer to the parent virtio_console device */\n\tstruct ports_device *portdev;\n\n\t/* The current buffer from which data has to be fed to readers */\n\tstruct port_buffer *inbuf;\n\n\t/*\n\t * To protect the operations on the in_vq associated with this\n\t * port.  Has to be a spinlock because it can be called from\n\t * interrupt context (get_char()).\n\t */\n\tspinlock_t inbuf_lock;\n\n\t/* Protect the operations on the out_vq. */\n\tspinlock_t outvq_lock;\n\n\t/* The IO vqs for this port */\n\tstruct virtqueue *in_vq, *out_vq;\n\n\t/* File in the debugfs directory that exposes this port's information */\n\tstruct dentry *debugfs_file;\n\n\t/*\n\t * Keep count of the bytes sent, received and discarded for\n\t * this port for accounting and debugging purposes.  These\n\t * counts are not reset across port open / close events.\n\t */\n\tstruct port_stats stats;\n\n\t/*\n\t * The entries in this struct will be valid if this port is\n\t * hooked up to an hvc console\n\t */\n\tstruct console cons;\n\n\t/* Each port associates with a separate char device */\n\tstruct cdev *cdev;\n\tstruct device *dev;\n\n\t/* Reference-counting to handle port hot-unplugs and file operations */\n\tstruct kref kref;\n\n\t/* A waitqueue for poll() or blocking read operations */\n\twait_queue_head_t waitqueue;\n\n\t/* The 'name' of the port that we expose via sysfs properties */\n\tchar *name;\n\n\t/* We can notify apps of host connect / disconnect events via SIGIO */\n\tstruct fasync_struct *async_queue;\n\n\t/* The 'id' to identify the port with the Host */\n\tu32 id;\n\n\tbool outvq_full;\n\n\t/* Is the host device open */\n\tbool host_connected;\n\n\t/* We should allow only one process to open a port */\n\tbool guest_connected;\n};\n\n/* This is the very early arch-specified put chars function. */\nstatic int (*early_put_chars)(u32, const char *, int);\n\nstatic struct port *find_port_by_vtermno(u32 vtermno)\n{\n\tstruct port *port;\n\tstruct console *cons;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&pdrvdata_lock, flags);\n\tlist_for_each_entry(cons, &pdrvdata.consoles, list) {\n\t\tif (cons->vtermno == vtermno) {\n\t\t\tport = container_of(cons, struct port, cons);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tport = NULL;\nout:\n\tspin_unlock_irqrestore(&pdrvdata_lock, flags);\n\treturn port;\n}\n\nstatic struct port *find_port_by_devt_in_portdev(struct ports_device *portdev,\n\t\t\t\t\t\t dev_t dev)\n{\n\tstruct port *port;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&portdev->ports_lock, flags);\n\tlist_for_each_entry(port, &portdev->ports, list) {\n\t\tif (port->cdev->dev == dev) {\n\t\t\tkref_get(&port->kref);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tport = NULL;\nout:\n\tspin_unlock_irqrestore(&portdev->ports_lock, flags);\n\n\treturn port;\n}\n\nstatic struct port *find_port_by_devt(dev_t dev)\n{\n\tstruct ports_device *portdev;\n\tstruct port *port;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&pdrvdata_lock, flags);\n\tlist_for_each_entry(portdev, &pdrvdata.portdevs, list) {\n\t\tport = find_port_by_devt_in_portdev(portdev, dev);\n\t\tif (port)\n\t\t\tgoto out;\n\t}\n\tport = NULL;\nout:\n\tspin_unlock_irqrestore(&pdrvdata_lock, flags);\n\treturn port;\n}\n\nstatic struct port *find_port_by_id(struct ports_device *portdev, u32 id)\n{\n\tstruct port *port;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&portdev->ports_lock, flags);\n\tlist_for_each_entry(port, &portdev->ports, list)\n\t\tif (port->id == id)\n\t\t\tgoto out;\n\tport = NULL;\nout:\n\tspin_unlock_irqrestore(&portdev->ports_lock, flags);\n\n\treturn port;\n}\n\nstatic struct port *find_port_by_vq(struct ports_device *portdev,\n\t\t\t\t    struct virtqueue *vq)\n{\n\tstruct port *port;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&portdev->ports_lock, flags);\n\tlist_for_each_entry(port, &portdev->ports, list)\n\t\tif (port->in_vq == vq || port->out_vq == vq)\n\t\t\tgoto out;\n\tport = NULL;\nout:\n\tspin_unlock_irqrestore(&portdev->ports_lock, flags);\n\treturn port;\n}\n\nstatic bool is_console_port(struct port *port)\n{\n\tif (port->cons.hvc)\n\t\treturn true;\n\treturn false;\n}\n\nstatic bool is_rproc_serial(const struct virtio_device *vdev)\n{\n\treturn is_rproc_enabled && vdev->id.device == VIRTIO_ID_RPROC_SERIAL;\n}\n\nstatic inline bool use_multiport(struct ports_device *portdev)\n{\n\t/*\n\t * This condition can be true when put_chars is called from\n\t * early_init\n\t */\n\tif (!portdev->vdev)\n\t\treturn false;\n\treturn __virtio_test_bit(portdev->vdev, VIRTIO_CONSOLE_F_MULTIPORT);\n}\n\nstatic DEFINE_SPINLOCK(dma_bufs_lock);\nstatic LIST_HEAD(pending_free_dma_bufs);\n\nstatic void free_buf(struct port_buffer *buf, bool can_sleep)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < buf->sgpages; i++) {\n\t\tstruct page *page = sg_page(&buf->sg[i]);\n\t\tif (!page)\n\t\t\tbreak;\n\t\tput_page(page);\n\t}\n\n\tif (!buf->dev) {\n\t\tkfree(buf->buf);\n\t} else if (is_rproc_enabled) {\n\t\tunsigned long flags;\n\n\t\t/* dma_free_coherent requires interrupts to be enabled. */\n\t\tif (!can_sleep) {\n\t\t\t/* queue up dma-buffers to be freed later */\n\t\t\tspin_lock_irqsave(&dma_bufs_lock, flags);\n\t\t\tlist_add_tail(&buf->list, &pending_free_dma_bufs);\n\t\t\tspin_unlock_irqrestore(&dma_bufs_lock, flags);\n\t\t\treturn;\n\t\t}\n\t\tdma_free_coherent(buf->dev, buf->size, buf->buf, buf->dma);\n\n\t\t/* Release device refcnt and allow it to be freed */\n\t\tput_device(buf->dev);\n\t}\n\n\tkfree(buf);\n}\n\nstatic void reclaim_dma_bufs(void)\n{\n\tunsigned long flags;\n\tstruct port_buffer *buf, *tmp;\n\tLIST_HEAD(tmp_list);\n\n\tif (list_empty(&pending_free_dma_bufs))\n\t\treturn;\n\n\t/* Create a copy of the pending_free_dma_bufs while holding the lock */\n\tspin_lock_irqsave(&dma_bufs_lock, flags);\n\tlist_cut_position(&tmp_list, &pending_free_dma_bufs,\n\t\t\t  pending_free_dma_bufs.prev);\n\tspin_unlock_irqrestore(&dma_bufs_lock, flags);\n\n\t/* Release the dma buffers, without irqs enabled */\n\tlist_for_each_entry_safe(buf, tmp, &tmp_list, list) {\n\t\tlist_del(&buf->list);\n\t\tfree_buf(buf, true);\n\t}\n}\n\nstatic struct port_buffer *alloc_buf(struct virtio_device *vdev, size_t buf_size,\n\t\t\t\t     int pages)\n{\n\tstruct port_buffer *buf;\n\n\treclaim_dma_bufs();\n\n\t/*\n\t * Allocate buffer and the sg list. The sg list array is allocated\n\t * directly after the port_buffer struct.\n\t */\n\tbuf = kmalloc(struct_size(buf, sg, pages), GFP_KERNEL);\n\tif (!buf)\n\t\tgoto fail;\n\n\tbuf->sgpages = pages;\n\tif (pages > 0) {\n\t\tbuf->dev = NULL;\n\t\tbuf->buf = NULL;\n\t\treturn buf;\n\t}\n\n\tif (is_rproc_serial(vdev)) {\n\t\t/*\n\t\t * Allocate DMA memory from ancestor. When a virtio\n\t\t * device is created by remoteproc, the DMA memory is\n\t\t * associated with the parent device:\n\t\t * virtioY => remoteprocX#vdevYbuffer.\n\t\t */\n\t\tbuf->dev = vdev->dev.parent;\n\t\tif (!buf->dev)\n\t\t\tgoto free_buf;\n\n\t\t/* Increase device refcnt to avoid freeing it */\n\t\tget_device(buf->dev);\n\t\tbuf->buf = dma_alloc_coherent(buf->dev, buf_size, &buf->dma,\n\t\t\t\t\t      GFP_KERNEL);\n\t} else {\n\t\tbuf->dev = NULL;\n\t\tbuf->buf = kmalloc(buf_size, GFP_KERNEL);\n\t}\n\n\tif (!buf->buf)\n\t\tgoto free_buf;\n\tbuf->len = 0;\n\tbuf->offset = 0;\n\tbuf->size = buf_size;\n\treturn buf;\n\nfree_buf:\n\tkfree(buf);\nfail:\n\treturn NULL;\n}\n\n/* Callers should take appropriate locks */\nstatic struct port_buffer *get_inbuf(struct port *port)\n{\n\tstruct port_buffer *buf;\n\tunsigned int len;\n\n\tif (port->inbuf)\n\t\treturn port->inbuf;\n\n\tbuf = virtqueue_get_buf(port->in_vq, &len);\n\tif (buf) {\n\t\tbuf->len = len;\n\t\tbuf->offset = 0;\n\t\tport->stats.bytes_received += len;\n\t}\n\treturn buf;\n}\n\n/*\n * Create a scatter-gather list representing our input buffer and put\n * it in the queue.\n *\n * Callers should take appropriate locks.\n */\nstatic int add_inbuf(struct virtqueue *vq, struct port_buffer *buf)\n{\n\tstruct scatterlist sg[1];\n\tint ret;\n\n\tsg_init_one(sg, buf->buf, buf->size);\n\n\tret = virtqueue_add_inbuf(vq, sg, 1, buf, GFP_ATOMIC);\n\tvirtqueue_kick(vq);\n\tif (!ret)\n\t\tret = vq->num_free;\n\treturn ret;\n}\n\n/* Discard any unread data this port has. Callers lockers. */\nstatic void discard_port_data(struct port *port)\n{\n\tstruct port_buffer *buf;\n\tunsigned int err;\n\n\tif (!port->portdev) {\n\t\t/* Device has been unplugged.  vqs are already gone. */\n\t\treturn;\n\t}\n\tbuf = get_inbuf(port);\n\n\terr = 0;\n\twhile (buf) {\n\t\tport->stats.bytes_discarded += buf->len - buf->offset;\n\t\tif (add_inbuf(port->in_vq, buf) < 0) {\n\t\t\terr++;\n\t\t\tfree_buf(buf, false);\n\t\t}\n\t\tport->inbuf = NULL;\n\t\tbuf = get_inbuf(port);\n\t}\n\tif (err)\n\t\tdev_warn(port->dev, \"Errors adding %d buffers back to vq\\n\",\n\t\t\t err);\n}\n\nstatic bool port_has_data(struct port *port)\n{\n\tunsigned long flags;\n\tbool ret;\n\n\tret = false;\n\tspin_lock_irqsave(&port->inbuf_lock, flags);\n\tport->inbuf = get_inbuf(port);\n\tif (port->inbuf)\n\t\tret = true;\n\n\tspin_unlock_irqrestore(&port->inbuf_lock, flags);\n\treturn ret;\n}\n\nstatic ssize_t __send_control_msg(struct ports_device *portdev, u32 port_id,\n\t\t\t\t  unsigned int event, unsigned int value)\n{\n\tstruct scatterlist sg[1];\n\tstruct virtqueue *vq;\n\tunsigned int len;\n\n\tif (!use_multiport(portdev))\n\t\treturn 0;\n\n\tvq = portdev->c_ovq;\n\n\tspin_lock(&portdev->c_ovq_lock);\n\n\tportdev->cpkt.id = cpu_to_virtio32(portdev->vdev, port_id);\n\tportdev->cpkt.event = cpu_to_virtio16(portdev->vdev, event);\n\tportdev->cpkt.value = cpu_to_virtio16(portdev->vdev, value);\n\n\tsg_init_one(sg, &portdev->cpkt, sizeof(struct virtio_console_control));\n\n\tif (virtqueue_add_outbuf(vq, sg, 1, &portdev->cpkt, GFP_ATOMIC) == 0) {\n\t\tvirtqueue_kick(vq);\n\t\twhile (!virtqueue_get_buf(vq, &len)\n\t\t\t&& !virtqueue_is_broken(vq))\n\t\t\tcpu_relax();\n\t}\n\n\tspin_unlock(&portdev->c_ovq_lock);\n\treturn 0;\n}\n\nstatic ssize_t send_control_msg(struct port *port, unsigned int event,\n\t\t\t\tunsigned int value)\n{\n\t/* Did the port get unplugged before userspace closed it? */\n\tif (port->portdev)\n\t\treturn __send_control_msg(port->portdev, port->id, event, value);\n\treturn 0;\n}\n\n\n/* Callers must take the port->outvq_lock */\nstatic void reclaim_consumed_buffers(struct port *port)\n{\n\tstruct port_buffer *buf;\n\tunsigned int len;\n\n\tif (!port->portdev) {\n\t\t/* Device has been unplugged.  vqs are already gone. */\n\t\treturn;\n\t}\n\twhile ((buf = virtqueue_get_buf(port->out_vq, &len))) {\n\t\tfree_buf(buf, false);\n\t\tport->outvq_full = false;\n\t}\n}\n\nstatic ssize_t __send_to_port(struct port *port, struct scatterlist *sg,\n\t\t\t      int nents, size_t in_count,\n\t\t\t      void *data, bool nonblock)\n{\n\tstruct virtqueue *out_vq;\n\tint err;\n\tunsigned long flags;\n\tunsigned int len;\n\n\tout_vq = port->out_vq;\n\n\tspin_lock_irqsave(&port->outvq_lock, flags);\n\n\treclaim_consumed_buffers(port);\n\n\terr = virtqueue_add_outbuf(out_vq, sg, nents, data, GFP_ATOMIC);\n\n\t/* Tell Host to go! */\n\tvirtqueue_kick(out_vq);\n\n\tif (err) {\n\t\tin_count = 0;\n\t\tgoto done;\n\t}\n\n\tif (out_vq->num_free == 0)\n\t\tport->outvq_full = true;\n\n\tif (nonblock)\n\t\tgoto done;\n\n\t/*\n\t * Wait till the host acknowledges it pushed out the data we\n\t * sent.  This is done for data from the hvc_console; the tty\n\t * operations are performed with spinlocks held so we can't\n\t * sleep here.  An alternative would be to copy the data to a\n\t * buffer and relax the spinning requirement.  The downside is\n\t * we need to kmalloc a GFP_ATOMIC buffer each time the\n\t * console driver writes something out.\n\t */\n\twhile (!virtqueue_get_buf(out_vq, &len)\n\t\t&& !virtqueue_is_broken(out_vq))\n\t\tcpu_relax();\ndone:\n\tspin_unlock_irqrestore(&port->outvq_lock, flags);\n\n\tport->stats.bytes_sent += in_count;\n\t/*\n\t * We're expected to return the amount of data we wrote -- all\n\t * of it\n\t */\n\treturn in_count;\n}\n\n/*\n * Give out the data that's requested from the buffer that we have\n * queued up.\n */\nstatic ssize_t fill_readbuf(struct port *port, char __user *out_buf,\n\t\t\t    size_t out_count, bool to_user)\n{\n\tstruct port_buffer *buf;\n\tunsigned long flags;\n\n\tif (!out_count || !port_has_data(port))\n\t\treturn 0;\n\n\tbuf = port->inbuf;\n\tout_count = min(out_count, buf->len - buf->offset);\n\n\tif (to_user) {\n\t\tssize_t ret;\n\n\t\tret = copy_to_user(out_buf, buf->buf + buf->offset, out_count);\n\t\tif (ret)\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tmemcpy((__force char *)out_buf, buf->buf + buf->offset,\n\t\t       out_count);\n\t}\n\n\tbuf->offset += out_count;\n\n\tif (buf->offset == buf->len) {\n\t\t/*\n\t\t * We're done using all the data in this buffer.\n\t\t * Re-queue so that the Host can send us more data.\n\t\t */\n\t\tspin_lock_irqsave(&port->inbuf_lock, flags);\n\t\tport->inbuf = NULL;\n\n\t\tif (add_inbuf(port->in_vq, buf) < 0)\n\t\t\tdev_warn(port->dev, \"failed add_buf\\n\");\n\n\t\tspin_unlock_irqrestore(&port->inbuf_lock, flags);\n\t}\n\t/* Return the number of bytes actually copied */\n\treturn out_count;\n}\n\n/* The condition that must be true for polling to end */\nstatic bool will_read_block(struct port *port)\n{\n\tif (!port->guest_connected) {\n\t\t/* Port got hot-unplugged. Let's exit. */\n\t\treturn false;\n\t}\n\treturn !port_has_data(port) && port->host_connected;\n}\n\nstatic bool will_write_block(struct port *port)\n{\n\tbool ret;\n\n\tif (!port->guest_connected) {\n\t\t/* Port got hot-unplugged. Let's exit. */\n\t\treturn false;\n\t}\n\tif (!port->host_connected)\n\t\treturn true;\n\n\tspin_lock_irq(&port->outvq_lock);\n\t/*\n\t * Check if the Host has consumed any buffers since we last\n\t * sent data (this is only applicable for nonblocking ports).\n\t */\n\treclaim_consumed_buffers(port);\n\tret = port->outvq_full;\n\tspin_unlock_irq(&port->outvq_lock);\n\n\treturn ret;\n}\n\nstatic ssize_t port_fops_read(struct file *filp, char __user *ubuf,\n\t\t\t      size_t count, loff_t *offp)\n{\n\tstruct port *port;\n\tssize_t ret;\n\n\tport = filp->private_data;\n\n\t/* Port is hot-unplugged. */\n\tif (!port->guest_connected)\n\t\treturn -ENODEV;\n\n\tif (!port_has_data(port)) {\n\t\t/*\n\t\t * If nothing's connected on the host just return 0 in\n\t\t * case of list_empty; this tells the userspace app\n\t\t * that there's no connection\n\t\t */\n\t\tif (!port->host_connected)\n\t\t\treturn 0;\n\t\tif (filp->f_flags & O_NONBLOCK)\n\t\t\treturn -EAGAIN;\n\n\t\tret = wait_event_freezable(port->waitqueue,\n\t\t\t\t\t   !will_read_block(port));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\t/* Port got hot-unplugged while we were waiting above. */\n\tif (!port->guest_connected)\n\t\treturn -ENODEV;\n\t/*\n\t * We could've received a disconnection message while we were\n\t * waiting for more data.\n\t *\n\t * This check is not clubbed in the if() statement above as we\n\t * might receive some data as well as the host could get\n\t * disconnected after we got woken up from our wait.  So we\n\t * really want to give off whatever data we have and only then\n\t * check for host_connected.\n\t */\n\tif (!port_has_data(port) && !port->host_connected)\n\t\treturn 0;\n\n\treturn fill_readbuf(port, ubuf, count, true);\n}\n\nstatic int wait_port_writable(struct port *port, bool nonblock)\n{\n\tint ret;\n\n\tif (will_write_block(port)) {\n\t\tif (nonblock)\n\t\t\treturn -EAGAIN;\n\n\t\tret = wait_event_freezable(port->waitqueue,\n\t\t\t\t\t   !will_write_block(port));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\t/* Port got hot-unplugged. */\n\tif (!port->guest_connected)\n\t\treturn -ENODEV;\n\n\treturn 0;\n}\n\nstatic ssize_t port_fops_write(struct file *filp, const char __user *ubuf,\n\t\t\t       size_t count, loff_t *offp)\n{\n\tstruct port *port;\n\tstruct port_buffer *buf;\n\tssize_t ret;\n\tbool nonblock;\n\tstruct scatterlist sg[1];\n\n\t/* Userspace could be out to fool us */\n\tif (!count)\n\t\treturn 0;\n\n\tport = filp->private_data;\n\n\tnonblock = filp->f_flags & O_NONBLOCK;\n\n\tret = wait_port_writable(port, nonblock);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tcount = min((size_t)(32 * 1024), count);\n\n\tbuf = alloc_buf(port->portdev->vdev, count, 0);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = copy_from_user(buf->buf, ubuf, count);\n\tif (ret) {\n\t\tret = -EFAULT;\n\t\tgoto free_buf;\n\t}\n\n\t/*\n\t * We now ask send_buf() to not spin for generic ports -- we\n\t * can re-use the same code path that non-blocking file\n\t * descriptors take for blocking file descriptors since the\n\t * wait is already done and we're certain the write will go\n\t * through to the host.\n\t */\n\tnonblock = true;\n\tsg_init_one(sg, buf->buf, count);\n\tret = __send_to_port(port, sg, 1, count, buf, nonblock);\n\n\tif (nonblock && ret > 0)\n\t\tgoto out;\n\nfree_buf:\n\tfree_buf(buf, true);\nout:\n\treturn ret;\n}\n\nstruct sg_list {\n\tunsigned int n;\n\tunsigned int size;\n\tsize_t len;\n\tstruct scatterlist *sg;\n};\n\nstatic int pipe_to_sg(struct pipe_inode_info *pipe, struct pipe_buffer *buf,\n\t\t\tstruct splice_desc *sd)\n{\n\tstruct sg_list *sgl = sd->u.data;\n\tunsigned int offset, len;\n\n\tif (sgl->n == sgl->size)\n\t\treturn 0;\n\n\t/* Try lock this page */\n\tif (pipe_buf_try_steal(pipe, buf)) {\n\t\t/* Get reference and unlock page for moving */\n\t\tget_page(buf->page);\n\t\tunlock_page(buf->page);\n\n\t\tlen = min(buf->len, sd->len);\n\t\tsg_set_page(&(sgl->sg[sgl->n]), buf->page, len, buf->offset);\n\t} else {\n\t\t/* Failback to copying a page */\n\t\tstruct page *page = alloc_page(GFP_KERNEL);\n\t\tchar *src;\n\n\t\tif (!page)\n\t\t\treturn -ENOMEM;\n\n\t\toffset = sd->pos & ~PAGE_MASK;\n\n\t\tlen = sd->len;\n\t\tif (len + offset > PAGE_SIZE)\n\t\t\tlen = PAGE_SIZE - offset;\n\n\t\tsrc = kmap_atomic(buf->page);\n\t\tmemcpy(page_address(page) + offset, src + buf->offset, len);\n\t\tkunmap_atomic(src);\n\n\t\tsg_set_page(&(sgl->sg[sgl->n]), page, len, offset);\n\t}\n\tsgl->n++;\n\tsgl->len += len;\n\n\treturn len;\n}\n\n/* Faster zero-copy write by splicing */\nstatic ssize_t port_fops_splice_write(struct pipe_inode_info *pipe,\n\t\t\t\t      struct file *filp, loff_t *ppos,\n\t\t\t\t      size_t len, unsigned int flags)\n{\n\tstruct port *port = filp->private_data;\n\tstruct sg_list sgl;\n\tssize_t ret;\n\tstruct port_buffer *buf;\n\tstruct splice_desc sd = {\n\t\t.total_len = len,\n\t\t.flags = flags,\n\t\t.pos = *ppos,\n\t\t.u.data = &sgl,\n\t};\n\tunsigned int occupancy;\n\n\t/*\n\t * Rproc_serial does not yet support splice. To support splice\n\t * pipe_to_sg() must allocate dma-buffers and copy content from\n\t * regular pages to dma pages. And alloc_buf and free_buf must\n\t * support allocating and freeing such a list of dma-buffers.\n\t */\n\tif (is_rproc_serial(port->out_vq->vdev))\n\t\treturn -EINVAL;\n\n\tpipe_lock(pipe);\n\tret = 0;\n\tif (pipe_empty(pipe->head, pipe->tail))\n\t\tgoto error_out;\n\n\tret = wait_port_writable(port, filp->f_flags & O_NONBLOCK);\n\tif (ret < 0)\n\t\tgoto error_out;\n\n\toccupancy = pipe_occupancy(pipe->head, pipe->tail);\n\tbuf = alloc_buf(port->portdev->vdev, 0, occupancy);\n\n\tif (!buf) {\n\t\tret = -ENOMEM;\n\t\tgoto error_out;\n\t}\n\n\tsgl.n = 0;\n\tsgl.len = 0;\n\tsgl.size = occupancy;\n\tsgl.sg = buf->sg;\n\tsg_init_table(sgl.sg, sgl.size);\n\tret = __splice_from_pipe(pipe, &sd, pipe_to_sg);\n\tpipe_unlock(pipe);\n\tif (likely(ret > 0))\n\t\tret = __send_to_port(port, buf->sg, sgl.n, sgl.len, buf, true);\n\n\tif (unlikely(ret <= 0))\n\t\tfree_buf(buf, true);\n\treturn ret;\n\nerror_out:\n\tpipe_unlock(pipe);\n\treturn ret;\n}\n\nstatic __poll_t port_fops_poll(struct file *filp, poll_table *wait)\n{\n\tstruct port *port;\n\t__poll_t ret;\n\n\tport = filp->private_data;\n\tpoll_wait(filp, &port->waitqueue, wait);\n\n\tif (!port->guest_connected) {\n\t\t/* Port got unplugged */\n\t\treturn EPOLLHUP;\n\t}\n\tret = 0;\n\tif (!will_read_block(port))\n\t\tret |= EPOLLIN | EPOLLRDNORM;\n\tif (!will_write_block(port))\n\t\tret |= EPOLLOUT;\n\tif (!port->host_connected)\n\t\tret |= EPOLLHUP;\n\n\treturn ret;\n}\n\nstatic void remove_port(struct kref *kref);\n\nstatic int port_fops_release(struct inode *inode, struct file *filp)\n{\n\tstruct port *port;\n\n\tport = filp->private_data;\n\n\t/* Notify host of port being closed */\n\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_OPEN, 0);\n\n\tspin_lock_irq(&port->inbuf_lock);\n\tport->guest_connected = false;\n\n\tdiscard_port_data(port);\n\n\tspin_unlock_irq(&port->inbuf_lock);\n\n\tspin_lock_irq(&port->outvq_lock);\n\treclaim_consumed_buffers(port);\n\tspin_unlock_irq(&port->outvq_lock);\n\n\treclaim_dma_bufs();\n\t/*\n\t * Locks aren't necessary here as a port can't be opened after\n\t * unplug, and if a port isn't unplugged, a kref would already\n\t * exist for the port.  Plus, taking ports_lock here would\n\t * create a dependency on other locks taken by functions\n\t * inside remove_port if we're the last holder of the port,\n\t * creating many problems.\n\t */\n\tkref_put(&port->kref, remove_port);\n\n\treturn 0;\n}\n\nstatic int port_fops_open(struct inode *inode, struct file *filp)\n{\n\tstruct cdev *cdev = inode->i_cdev;\n\tstruct port *port;\n\tint ret;\n\n\t/* We get the port with a kref here */\n\tport = find_port_by_devt(cdev->dev);\n\tif (!port) {\n\t\t/* Port was unplugged before we could proceed */\n\t\treturn -ENXIO;\n\t}\n\tfilp->private_data = port;\n\n\t/*\n\t * Don't allow opening of console port devices -- that's done\n\t * via /dev/hvc\n\t */\n\tif (is_console_port(port)) {\n\t\tret = -ENXIO;\n\t\tgoto out;\n\t}\n\n\t/* Allow only one process to open a particular port at a time */\n\tspin_lock_irq(&port->inbuf_lock);\n\tif (port->guest_connected) {\n\t\tspin_unlock_irq(&port->inbuf_lock);\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tport->guest_connected = true;\n\tspin_unlock_irq(&port->inbuf_lock);\n\n\tspin_lock_irq(&port->outvq_lock);\n\t/*\n\t * There might be a chance that we missed reclaiming a few\n\t * buffers in the window of the port getting previously closed\n\t * and opening now.\n\t */\n\treclaim_consumed_buffers(port);\n\tspin_unlock_irq(&port->outvq_lock);\n\n\tnonseekable_open(inode, filp);\n\n\t/* Notify host of port being opened */\n\tsend_control_msg(filp->private_data, VIRTIO_CONSOLE_PORT_OPEN, 1);\n\n\treturn 0;\nout:\n\tkref_put(&port->kref, remove_port);\n\treturn ret;\n}\n\nstatic int port_fops_fasync(int fd, struct file *filp, int mode)\n{\n\tstruct port *port;\n\n\tport = filp->private_data;\n\treturn fasync_helper(fd, filp, mode, &port->async_queue);\n}\n\n/*\n * The file operations that we support: programs in the guest can open\n * a console device, read from it, write to it, poll for data and\n * close it.  The devices are at\n *   /dev/vport<device number>p<port number>\n */\nstatic const struct file_operations port_fops = {\n\t.owner = THIS_MODULE,\n\t.open  = port_fops_open,\n\t.read  = port_fops_read,\n\t.write = port_fops_write,\n\t.splice_write = port_fops_splice_write,\n\t.poll  = port_fops_poll,\n\t.release = port_fops_release,\n\t.fasync = port_fops_fasync,\n\t.llseek = no_llseek,\n};\n\n/*\n * The put_chars() callback is pretty straightforward.\n *\n * We turn the characters into a scatter-gather list, add it to the\n * output queue and then kick the Host.  Then we sit here waiting for\n * it to finish: inefficient in theory, but in practice\n * implementations will do it immediately.\n */\nstatic int put_chars(u32 vtermno, const char *buf, int count)\n{\n\tstruct port *port;\n\tstruct scatterlist sg[1];\n\tvoid *data;\n\tint ret;\n\n\tif (unlikely(early_put_chars))\n\t\treturn early_put_chars(vtermno, buf, count);\n\n\tport = find_port_by_vtermno(vtermno);\n\tif (!port)\n\t\treturn -EPIPE;\n\n\tdata = kmemdup(buf, count, GFP_ATOMIC);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tsg_init_one(sg, data, count);\n\tret = __send_to_port(port, sg, 1, count, data, false);\n\tkfree(data);\n\treturn ret;\n}\n\n/*\n * get_chars() is the callback from the hvc_console infrastructure\n * when an interrupt is received.\n *\n * We call out to fill_readbuf that gets us the required data from the\n * buffers that are queued up.\n */\nstatic int get_chars(u32 vtermno, char *buf, int count)\n{\n\tstruct port *port;\n\n\t/* If we've not set up the port yet, we have no input to give. */\n\tif (unlikely(early_put_chars))\n\t\treturn 0;\n\n\tport = find_port_by_vtermno(vtermno);\n\tif (!port)\n\t\treturn -EPIPE;\n\n\t/* If we don't have an input queue yet, we can't get input. */\n\tBUG_ON(!port->in_vq);\n\n\treturn fill_readbuf(port, (__force char __user *)buf, count, false);\n}\n\nstatic void resize_console(struct port *port)\n{\n\tstruct virtio_device *vdev;\n\n\t/* The port could have been hot-unplugged */\n\tif (!port || !is_console_port(port))\n\t\treturn;\n\n\tvdev = port->portdev->vdev;\n\n\t/* Don't test F_SIZE at all if we're rproc: not a valid feature! */\n\tif (!is_rproc_serial(vdev) &&\n\t    virtio_has_feature(vdev, VIRTIO_CONSOLE_F_SIZE))\n\t\thvc_resize(port->cons.hvc, port->cons.ws);\n}\n\n/* We set the configuration at this point, since we now have a tty */\nstatic int notifier_add_vio(struct hvc_struct *hp, int data)\n{\n\tstruct port *port;\n\n\tport = find_port_by_vtermno(hp->vtermno);\n\tif (!port)\n\t\treturn -EINVAL;\n\n\thp->irq_requested = 1;\n\tresize_console(port);\n\n\treturn 0;\n}\n\nstatic void notifier_del_vio(struct hvc_struct *hp, int data)\n{\n\thp->irq_requested = 0;\n}\n\n/* The operations for console ports. */\nstatic const struct hv_ops hv_ops = {\n\t.get_chars = get_chars,\n\t.put_chars = put_chars,\n\t.notifier_add = notifier_add_vio,\n\t.notifier_del = notifier_del_vio,\n\t.notifier_hangup = notifier_del_vio,\n};\n\n/*\n * Console drivers are initialized very early so boot messages can go\n * out, so we do things slightly differently from the generic virtio\n * initialization of the net and block drivers.\n *\n * At this stage, the console is output-only.  It's too early to set\n * up a virtqueue, so we let the drivers do some boutique early-output\n * thing.\n */\nint __init virtio_cons_early_init(int (*put_chars)(u32, const char *, int))\n{\n\tearly_put_chars = put_chars;\n\treturn hvc_instantiate(0, 0, &hv_ops);\n}\n\nstatic int init_port_console(struct port *port)\n{\n\tint ret;\n\n\t/*\n\t * The Host's telling us this port is a console port.  Hook it\n\t * up with an hvc console.\n\t *\n\t * To set up and manage our virtual console, we call\n\t * hvc_alloc().\n\t *\n\t * The first argument of hvc_alloc() is the virtual console\n\t * number.  The second argument is the parameter for the\n\t * notification mechanism (like irq number).  We currently\n\t * leave this as zero, virtqueues have implicit notifications.\n\t *\n\t * The third argument is a \"struct hv_ops\" containing the\n\t * put_chars() get_chars(), notifier_add() and notifier_del()\n\t * pointers.  The final argument is the output buffer size: we\n\t * can do any size, so we put PAGE_SIZE here.\n\t */\n\tport->cons.vtermno = pdrvdata.next_vtermno;\n\n\tport->cons.hvc = hvc_alloc(port->cons.vtermno, 0, &hv_ops, PAGE_SIZE);\n\tif (IS_ERR(port->cons.hvc)) {\n\t\tret = PTR_ERR(port->cons.hvc);\n\t\tdev_err(port->dev,\n\t\t\t\"error %d allocating hvc for port\\n\", ret);\n\t\tport->cons.hvc = NULL;\n\t\treturn ret;\n\t}\n\tspin_lock_irq(&pdrvdata_lock);\n\tpdrvdata.next_vtermno++;\n\tlist_add_tail(&port->cons.list, &pdrvdata.consoles);\n\tspin_unlock_irq(&pdrvdata_lock);\n\tport->guest_connected = true;\n\n\t/*\n\t * Start using the new console output if this is the first\n\t * console to come up.\n\t */\n\tif (early_put_chars)\n\t\tearly_put_chars = NULL;\n\n\t/* Notify host of port being opened */\n\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_OPEN, 1);\n\n\treturn 0;\n}\n\nstatic ssize_t show_port_name(struct device *dev,\n\t\t\t      struct device_attribute *attr, char *buffer)\n{\n\tstruct port *port;\n\n\tport = dev_get_drvdata(dev);\n\n\treturn sprintf(buffer, \"%s\\n\", port->name);\n}\n\nstatic DEVICE_ATTR(name, S_IRUGO, show_port_name, NULL);\n\nstatic struct attribute *port_sysfs_entries[] = {\n\t&dev_attr_name.attr,\n\tNULL\n};\n\nstatic const struct attribute_group port_attribute_group = {\n\t.name = NULL,\t\t/* put in device directory */\n\t.attrs = port_sysfs_entries,\n};\n\nstatic int port_debugfs_show(struct seq_file *s, void *data)\n{\n\tstruct port *port = s->private;\n\n\tseq_printf(s, \"name: %s\\n\", port->name ? port->name : \"\");\n\tseq_printf(s, \"guest_connected: %d\\n\", port->guest_connected);\n\tseq_printf(s, \"host_connected: %d\\n\", port->host_connected);\n\tseq_printf(s, \"outvq_full: %d\\n\", port->outvq_full);\n\tseq_printf(s, \"bytes_sent: %lu\\n\", port->stats.bytes_sent);\n\tseq_printf(s, \"bytes_received: %lu\\n\", port->stats.bytes_received);\n\tseq_printf(s, \"bytes_discarded: %lu\\n\", port->stats.bytes_discarded);\n\tseq_printf(s, \"is_console: %s\\n\",\n\t\t   is_console_port(port) ? \"yes\" : \"no\");\n\tseq_printf(s, \"console_vtermno: %u\\n\", port->cons.vtermno);\n\n\treturn 0;\n}\n\nDEFINE_SHOW_ATTRIBUTE(port_debugfs);\n\nstatic void set_console_size(struct port *port, u16 rows, u16 cols)\n{\n\tif (!port || !is_console_port(port))\n\t\treturn;\n\n\tport->cons.ws.ws_row = rows;\n\tport->cons.ws.ws_col = cols;\n}\n\nstatic int fill_queue(struct virtqueue *vq, spinlock_t *lock)\n{\n\tstruct port_buffer *buf;\n\tint nr_added_bufs;\n\tint ret;\n\n\tnr_added_bufs = 0;\n\tdo {\n\t\tbuf = alloc_buf(vq->vdev, PAGE_SIZE, 0);\n\t\tif (!buf)\n\t\t\treturn -ENOMEM;\n\n\t\tspin_lock_irq(lock);\n\t\tret = add_inbuf(vq, buf);\n\t\tif (ret < 0) {\n\t\t\tspin_unlock_irq(lock);\n\t\t\tfree_buf(buf, true);\n\t\t\treturn ret;\n\t\t}\n\t\tnr_added_bufs++;\n\t\tspin_unlock_irq(lock);\n\t} while (ret > 0);\n\n\treturn nr_added_bufs;\n}\n\nstatic void send_sigio_to_port(struct port *port)\n{\n\tif (port->async_queue && port->guest_connected)\n\t\tkill_fasync(&port->async_queue, SIGIO, POLL_OUT);\n}\n\nstatic int add_port(struct ports_device *portdev, u32 id)\n{\n\tchar debugfs_name[16];\n\tstruct port *port;\n\tdev_t devt;\n\tint err;\n\n\tport = kmalloc(sizeof(*port), GFP_KERNEL);\n\tif (!port) {\n\t\terr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tkref_init(&port->kref);\n\n\tport->portdev = portdev;\n\tport->id = id;\n\n\tport->name = NULL;\n\tport->inbuf = NULL;\n\tport->cons.hvc = NULL;\n\tport->async_queue = NULL;\n\n\tport->cons.ws.ws_row = port->cons.ws.ws_col = 0;\n\tport->cons.vtermno = 0;\n\n\tport->host_connected = port->guest_connected = false;\n\tport->stats = (struct port_stats) { 0 };\n\n\tport->outvq_full = false;\n\n\tport->in_vq = portdev->in_vqs[port->id];\n\tport->out_vq = portdev->out_vqs[port->id];\n\n\tport->cdev = cdev_alloc();\n\tif (!port->cdev) {\n\t\tdev_err(&port->portdev->vdev->dev, \"Error allocating cdev\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto free_port;\n\t}\n\tport->cdev->ops = &port_fops;\n\n\tdevt = MKDEV(portdev->chr_major, id);\n\terr = cdev_add(port->cdev, devt, 1);\n\tif (err < 0) {\n\t\tdev_err(&port->portdev->vdev->dev,\n\t\t\t\"Error %d adding cdev for port %u\\n\", err, id);\n\t\tgoto free_cdev;\n\t}\n\tport->dev = device_create(pdrvdata.class, &port->portdev->vdev->dev,\n\t\t\t\t  devt, port, \"vport%up%u\",\n\t\t\t\t  port->portdev->vdev->index, id);\n\tif (IS_ERR(port->dev)) {\n\t\terr = PTR_ERR(port->dev);\n\t\tdev_err(&port->portdev->vdev->dev,\n\t\t\t\"Error %d creating device for port %u\\n\",\n\t\t\terr, id);\n\t\tgoto free_cdev;\n\t}\n\n\tspin_lock_init(&port->inbuf_lock);\n\tspin_lock_init(&port->outvq_lock);\n\tinit_waitqueue_head(&port->waitqueue);\n\n\t/* We can safely ignore ENOSPC because it means\n\t * the queue already has buffers. Buffers are removed\n\t * only by virtcons_remove(), not by unplug_port()\n\t */\n\terr = fill_queue(port->in_vq, &port->inbuf_lock);\n\tif (err < 0 && err != -ENOSPC) {\n\t\tdev_err(port->dev, \"Error allocating inbufs\\n\");\n\t\tgoto free_device;\n\t}\n\n\tif (is_rproc_serial(port->portdev->vdev))\n\t\t/*\n\t\t * For rproc_serial assume remote processor is connected.\n\t\t * rproc_serial does not want the console port, only\n\t\t * the generic port implementation.\n\t\t */\n\t\tport->host_connected = true;\n\telse if (!use_multiport(port->portdev)) {\n\t\t/*\n\t\t * If we're not using multiport support,\n\t\t * this has to be a console port.\n\t\t */\n\t\terr = init_port_console(port);\n\t\tif (err)\n\t\t\tgoto free_inbufs;\n\t}\n\n\tspin_lock_irq(&portdev->ports_lock);\n\tlist_add_tail(&port->list, &port->portdev->ports);\n\tspin_unlock_irq(&portdev->ports_lock);\n\n\t/*\n\t * Tell the Host we're set so that it can send us various\n\t * configuration parameters for this port (eg, port name,\n\t * caching, whether this is a console port, etc.)\n\t */\n\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_READY, 1);\n\n\t/*\n\t * Finally, create the debugfs file that we can use to\n\t * inspect a port's state at any time\n\t */\n\tsnprintf(debugfs_name, sizeof(debugfs_name), \"vport%up%u\",\n\t\t port->portdev->vdev->index, id);\n\tport->debugfs_file = debugfs_create_file(debugfs_name, 0444,\n\t\t\t\t\t\t pdrvdata.debugfs_dir,\n\t\t\t\t\t\t port, &port_debugfs_fops);\n\treturn 0;\n\nfree_inbufs:\nfree_device:\n\tdevice_destroy(pdrvdata.class, port->dev->devt);\nfree_cdev:\n\tcdev_del(port->cdev);\nfree_port:\n\tkfree(port);\nfail:\n\t/* The host might want to notify management sw about port add failure */\n\t__send_control_msg(portdev, id, VIRTIO_CONSOLE_PORT_READY, 0);\n\treturn err;\n}\n\n/* No users remain, remove all port-specific data. */\nstatic void remove_port(struct kref *kref)\n{\n\tstruct port *port;\n\n\tport = container_of(kref, struct port, kref);\n\n\tkfree(port);\n}\n\nstatic void remove_port_data(struct port *port)\n{\n\tspin_lock_irq(&port->inbuf_lock);\n\t/* Remove unused data this port might have received. */\n\tdiscard_port_data(port);\n\tspin_unlock_irq(&port->inbuf_lock);\n\n\tspin_lock_irq(&port->outvq_lock);\n\treclaim_consumed_buffers(port);\n\tspin_unlock_irq(&port->outvq_lock);\n}\n\n/*\n * Port got unplugged.  Remove port from portdev's list and drop the\n * kref reference.  If no userspace has this port opened, it will\n * result in immediate removal the port.\n */\nstatic void unplug_port(struct port *port)\n{\n\tspin_lock_irq(&port->portdev->ports_lock);\n\tlist_del(&port->list);\n\tspin_unlock_irq(&port->portdev->ports_lock);\n\n\tspin_lock_irq(&port->inbuf_lock);\n\tif (port->guest_connected) {\n\t\t/* Let the app know the port is going down. */\n\t\tsend_sigio_to_port(port);\n\n\t\t/* Do this after sigio is actually sent */\n\t\tport->guest_connected = false;\n\t\tport->host_connected = false;\n\n\t\twake_up_interruptible(&port->waitqueue);\n\t}\n\tspin_unlock_irq(&port->inbuf_lock);\n\n\tif (is_console_port(port)) {\n\t\tspin_lock_irq(&pdrvdata_lock);\n\t\tlist_del(&port->cons.list);\n\t\tspin_unlock_irq(&pdrvdata_lock);\n\t\thvc_remove(port->cons.hvc);\n\t}\n\n\tremove_port_data(port);\n\n\t/*\n\t * We should just assume the device itself has gone off --\n\t * else a close on an open port later will try to send out a\n\t * control message.\n\t */\n\tport->portdev = NULL;\n\n\tsysfs_remove_group(&port->dev->kobj, &port_attribute_group);\n\tdevice_destroy(pdrvdata.class, port->dev->devt);\n\tcdev_del(port->cdev);\n\n\tdebugfs_remove(port->debugfs_file);\n\tkfree(port->name);\n\n\t/*\n\t * Locks around here are not necessary - a port can't be\n\t * opened after we removed the port struct from ports_list\n\t * above.\n\t */\n\tkref_put(&port->kref, remove_port);\n}\n\n/* Any private messages that the Host and Guest want to share */\nstatic void handle_control_message(struct virtio_device *vdev,\n\t\t\t\t   struct ports_device *portdev,\n\t\t\t\t   struct port_buffer *buf)\n{\n\tstruct virtio_console_control *cpkt;\n\tstruct port *port;\n\tsize_t name_size;\n\tint err;\n\n\tcpkt = (struct virtio_console_control *)(buf->buf + buf->offset);\n\n\tport = find_port_by_id(portdev, virtio32_to_cpu(vdev, cpkt->id));\n\tif (!port &&\n\t    cpkt->event != cpu_to_virtio16(vdev, VIRTIO_CONSOLE_PORT_ADD)) {\n\t\t/* No valid header at start of buffer.  Drop it. */\n\t\tdev_dbg(&portdev->vdev->dev,\n\t\t\t\"Invalid index %u in control packet\\n\", cpkt->id);\n\t\treturn;\n\t}\n\n\tswitch (virtio16_to_cpu(vdev, cpkt->event)) {\n\tcase VIRTIO_CONSOLE_PORT_ADD:\n\t\tif (port) {\n\t\t\tdev_dbg(&portdev->vdev->dev,\n\t\t\t\t\"Port %u already added\\n\", port->id);\n\t\t\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_READY, 1);\n\t\t\tbreak;\n\t\t}\n\t\tif (virtio32_to_cpu(vdev, cpkt->id) >=\n\t\t    portdev->max_nr_ports) {\n\t\t\tdev_warn(&portdev->vdev->dev,\n\t\t\t\t\"Request for adding port with \"\n\t\t\t\t\"out-of-bound id %u, max. supported id: %u\\n\",\n\t\t\t\tcpkt->id, portdev->max_nr_ports - 1);\n\t\t\tbreak;\n\t\t}\n\t\tadd_port(portdev, virtio32_to_cpu(vdev, cpkt->id));\n\t\tbreak;\n\tcase VIRTIO_CONSOLE_PORT_REMOVE:\n\t\tunplug_port(port);\n\t\tbreak;\n\tcase VIRTIO_CONSOLE_CONSOLE_PORT:\n\t\tif (!cpkt->value)\n\t\t\tbreak;\n\t\tif (is_console_port(port))\n\t\t\tbreak;\n\n\t\tinit_port_console(port);\n\t\tcomplete(&early_console_added);\n\t\t/*\n\t\t * Could remove the port here in case init fails - but\n\t\t * have to notify the host first.\n\t\t */\n\t\tbreak;\n\tcase VIRTIO_CONSOLE_RESIZE: {\n\t\tstruct {\n\t\t\t__u16 rows;\n\t\t\t__u16 cols;\n\t\t} size;\n\n\t\tif (!is_console_port(port))\n\t\t\tbreak;\n\n\t\tmemcpy(&size, buf->buf + buf->offset + sizeof(*cpkt),\n\t\t       sizeof(size));\n\t\tset_console_size(port, size.rows, size.cols);\n\n\t\tport->cons.hvc->irq_requested = 1;\n\t\tresize_console(port);\n\t\tbreak;\n\t}\n\tcase VIRTIO_CONSOLE_PORT_OPEN:\n\t\tport->host_connected = virtio16_to_cpu(vdev, cpkt->value);\n\t\twake_up_interruptible(&port->waitqueue);\n\t\t/*\n\t\t * If the host port got closed and the host had any\n\t\t * unconsumed buffers, we'll be able to reclaim them\n\t\t * now.\n\t\t */\n\t\tspin_lock_irq(&port->outvq_lock);\n\t\treclaim_consumed_buffers(port);\n\t\tspin_unlock_irq(&port->outvq_lock);\n\n\t\t/*\n\t\t * If the guest is connected, it'll be interested in\n\t\t * knowing the host connection state changed.\n\t\t */\n\t\tspin_lock_irq(&port->inbuf_lock);\n\t\tsend_sigio_to_port(port);\n\t\tspin_unlock_irq(&port->inbuf_lock);\n\t\tbreak;\n\tcase VIRTIO_CONSOLE_PORT_NAME:\n\t\t/*\n\t\t * If we woke up after hibernation, we can get this\n\t\t * again.  Skip it in that case.\n\t\t */\n\t\tif (port->name)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Skip the size of the header and the cpkt to get the size\n\t\t * of the name that was sent\n\t\t */\n\t\tname_size = buf->len - buf->offset - sizeof(*cpkt) + 1;\n\n\t\tport->name = kmalloc(name_size, GFP_KERNEL);\n\t\tif (!port->name) {\n\t\t\tdev_err(port->dev,\n\t\t\t\t\"Not enough space to store port name\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tstrncpy(port->name, buf->buf + buf->offset + sizeof(*cpkt),\n\t\t\tname_size - 1);\n\t\tport->name[name_size - 1] = 0;\n\n\t\t/*\n\t\t * Since we only have one sysfs attribute, 'name',\n\t\t * create it only if we have a name for the port.\n\t\t */\n\t\terr = sysfs_create_group(&port->dev->kobj,\n\t\t\t\t\t &port_attribute_group);\n\t\tif (err) {\n\t\t\tdev_err(port->dev,\n\t\t\t\t\"Error %d creating sysfs device attributes\\n\",\n\t\t\t\terr);\n\t\t} else {\n\t\t\t/*\n\t\t\t * Generate a udev event so that appropriate\n\t\t\t * symlinks can be created based on udev\n\t\t\t * rules.\n\t\t\t */\n\t\t\tkobject_uevent(&port->dev->kobj, KOBJ_CHANGE);\n\t\t}\n\t\tbreak;\n\t}\n}\n\nstatic void control_work_handler(struct work_struct *work)\n{\n\tstruct ports_device *portdev;\n\tstruct virtqueue *vq;\n\tstruct port_buffer *buf;\n\tunsigned int len;\n\n\tportdev = container_of(work, struct ports_device, control_work);\n\tvq = portdev->c_ivq;\n\n\tspin_lock(&portdev->c_ivq_lock);\n\twhile ((buf = virtqueue_get_buf(vq, &len))) {\n\t\tspin_unlock(&portdev->c_ivq_lock);\n\n\t\tbuf->len = len;\n\t\tbuf->offset = 0;\n\n\t\thandle_control_message(vq->vdev, portdev, buf);\n\n\t\tspin_lock(&portdev->c_ivq_lock);\n\t\tif (add_inbuf(portdev->c_ivq, buf) < 0) {\n\t\t\tdev_warn(&portdev->vdev->dev,\n\t\t\t\t \"Error adding buffer to queue\\n\");\n\t\t\tfree_buf(buf, false);\n\t\t}\n\t}\n\tspin_unlock(&portdev->c_ivq_lock);\n}\n\nstatic void flush_bufs(struct virtqueue *vq, bool can_sleep)\n{\n\tstruct port_buffer *buf;\n\tunsigned int len;\n\n\twhile ((buf = virtqueue_get_buf(vq, &len)))\n\t\tfree_buf(buf, can_sleep);\n}\n\nstatic void out_intr(struct virtqueue *vq)\n{\n\tstruct port *port;\n\n\tport = find_port_by_vq(vq->vdev->priv, vq);\n\tif (!port) {\n\t\tflush_bufs(vq, false);\n\t\treturn;\n\t}\n\n\twake_up_interruptible(&port->waitqueue);\n}\n\nstatic void in_intr(struct virtqueue *vq)\n{\n\tstruct port *port;\n\tunsigned long flags;\n\n\tport = find_port_by_vq(vq->vdev->priv, vq);\n\tif (!port) {\n\t\tflush_bufs(vq, false);\n\t\treturn;\n\t}\n\n\tspin_lock_irqsave(&port->inbuf_lock, flags);\n\tport->inbuf = get_inbuf(port);\n\n\t/*\n\t * Normally the port should not accept data when the port is\n\t * closed. For generic serial ports, the host won't (shouldn't)\n\t * send data till the guest is connected. But this condition\n\t * can be reached when a console port is not yet connected (no\n\t * tty is spawned) and the other side sends out data over the\n\t * vring, or when a remote devices start sending data before\n\t * the ports are opened.\n\t *\n\t * A generic serial port will discard data if not connected,\n\t * while console ports and rproc-serial ports accepts data at\n\t * any time. rproc-serial is initiated with guest_connected to\n\t * false because port_fops_open expects this. Console ports are\n\t * hooked up with an HVC console and is initialized with\n\t * guest_connected to true.\n\t */\n\n\tif (!port->guest_connected && !is_rproc_serial(port->portdev->vdev))\n\t\tdiscard_port_data(port);\n\n\t/* Send a SIGIO indicating new data in case the process asked for it */\n\tsend_sigio_to_port(port);\n\n\tspin_unlock_irqrestore(&port->inbuf_lock, flags);\n\n\twake_up_interruptible(&port->waitqueue);\n\n\tif (is_console_port(port) && hvc_poll(port->cons.hvc))\n\t\thvc_kick();\n}\n\nstatic void control_intr(struct virtqueue *vq)\n{\n\tstruct ports_device *portdev;\n\n\tportdev = vq->vdev->priv;\n\tschedule_work(&portdev->control_work);\n}\n\nstatic void config_intr(struct virtio_device *vdev)\n{\n\tstruct ports_device *portdev;\n\n\tportdev = vdev->priv;\n\n\tif (!use_multiport(portdev))\n\t\tschedule_work(&portdev->config_work);\n}\n\nstatic void config_work_handler(struct work_struct *work)\n{\n\tstruct ports_device *portdev;\n\n\tportdev = container_of(work, struct ports_device, config_work);\n\tif (!use_multiport(portdev)) {\n\t\tstruct virtio_device *vdev;\n\t\tstruct port *port;\n\t\tu16 rows, cols;\n\n\t\tvdev = portdev->vdev;\n\t\tvirtio_cread(vdev, struct virtio_console_config, cols, &cols);\n\t\tvirtio_cread(vdev, struct virtio_console_config, rows, &rows);\n\n\t\tport = find_port_by_id(portdev, 0);\n\t\tset_console_size(port, rows, cols);\n\n\t\t/*\n\t\t * We'll use this way of resizing only for legacy\n\t\t * support.  For newer userspace\n\t\t * (VIRTIO_CONSOLE_F_MULTPORT+), use control messages\n\t\t * to indicate console size changes so that it can be\n\t\t * done per-port.\n\t\t */\n\t\tresize_console(port);\n\t}\n}\n\nstatic int init_vqs(struct ports_device *portdev)\n{\n\tvq_callback_t **io_callbacks;\n\tchar **io_names;\n\tstruct virtqueue **vqs;\n\tu32 i, j, nr_ports, nr_queues;\n\tint err;\n\n\tnr_ports = portdev->max_nr_ports;\n\tnr_queues = use_multiport(portdev) ? (nr_ports + 1) * 2 : 2;\n\n\tvqs = kmalloc_array(nr_queues, sizeof(struct virtqueue *), GFP_KERNEL);\n\tio_callbacks = kmalloc_array(nr_queues, sizeof(vq_callback_t *),\n\t\t\t\t     GFP_KERNEL);\n\tio_names = kmalloc_array(nr_queues, sizeof(char *), GFP_KERNEL);\n\tportdev->in_vqs = kmalloc_array(nr_ports, sizeof(struct virtqueue *),\n\t\t\t\t\tGFP_KERNEL);\n\tportdev->out_vqs = kmalloc_array(nr_ports, sizeof(struct virtqueue *),\n\t\t\t\t\t GFP_KERNEL);\n\tif (!vqs || !io_callbacks || !io_names || !portdev->in_vqs ||\n\t    !portdev->out_vqs) {\n\t\terr = -ENOMEM;\n\t\tgoto free;\n\t}\n\n\t/*\n\t * For backward compat (newer host but older guest), the host\n\t * spawns a console port first and also inits the vqs for port\n\t * 0 before others.\n\t */\n\tj = 0;\n\tio_callbacks[j] = in_intr;\n\tio_callbacks[j + 1] = out_intr;\n\tio_names[j] = \"input\";\n\tio_names[j + 1] = \"output\";\n\tj += 2;\n\n\tif (use_multiport(portdev)) {\n\t\tio_callbacks[j] = control_intr;\n\t\tio_callbacks[j + 1] = NULL;\n\t\tio_names[j] = \"control-i\";\n\t\tio_names[j + 1] = \"control-o\";\n\n\t\tfor (i = 1; i < nr_ports; i++) {\n\t\t\tj += 2;\n\t\t\tio_callbacks[j] = in_intr;\n\t\t\tio_callbacks[j + 1] = out_intr;\n\t\t\tio_names[j] = \"input\";\n\t\t\tio_names[j + 1] = \"output\";\n\t\t}\n\t}\n\t/* Find the queues. */\n\terr = virtio_find_vqs(portdev->vdev, nr_queues, vqs,\n\t\t\t      io_callbacks,\n\t\t\t      (const char **)io_names, NULL);\n\tif (err)\n\t\tgoto free;\n\n\tj = 0;\n\tportdev->in_vqs[0] = vqs[0];\n\tportdev->out_vqs[0] = vqs[1];\n\tj += 2;\n\tif (use_multiport(portdev)) {\n\t\tportdev->c_ivq = vqs[j];\n\t\tportdev->c_ovq = vqs[j + 1];\n\n\t\tfor (i = 1; i < nr_ports; i++) {\n\t\t\tj += 2;\n\t\t\tportdev->in_vqs[i] = vqs[j];\n\t\t\tportdev->out_vqs[i] = vqs[j + 1];\n\t\t}\n\t}\n\tkfree(io_names);\n\tkfree(io_callbacks);\n\tkfree(vqs);\n\n\treturn 0;\n\nfree:\n\tkfree(portdev->out_vqs);\n\tkfree(portdev->in_vqs);\n\tkfree(io_names);\n\tkfree(io_callbacks);\n\tkfree(vqs);\n\n\treturn err;\n}\n\nstatic const struct file_operations portdev_fops = {\n\t.owner = THIS_MODULE,\n};\n\nstatic void remove_vqs(struct ports_device *portdev)\n{\n\tstruct virtqueue *vq;\n\n\tvirtio_device_for_each_vq(portdev->vdev, vq) {\n\t\tstruct port_buffer *buf;\n\n\t\tflush_bufs(vq, true);\n\t\twhile ((buf = virtqueue_detach_unused_buf(vq)))\n\t\t\tfree_buf(buf, true);\n\t}\n\tportdev->vdev->config->del_vqs(portdev->vdev);\n\tkfree(portdev->in_vqs);\n\tkfree(portdev->out_vqs);\n}\n\nstatic void virtcons_remove(struct virtio_device *vdev)\n{\n\tstruct ports_device *portdev;\n\tstruct port *port, *port2;\n\n\tportdev = vdev->priv;\n\n\tspin_lock_irq(&pdrvdata_lock);\n\tlist_del(&portdev->list);\n\tspin_unlock_irq(&pdrvdata_lock);\n\n\t/* Disable interrupts for vqs */\n\tvdev->config->reset(vdev);\n\t/* Finish up work that's lined up */\n\tif (use_multiport(portdev))\n\t\tcancel_work_sync(&portdev->control_work);\n\telse\n\t\tcancel_work_sync(&portdev->config_work);\n\n\tlist_for_each_entry_safe(port, port2, &portdev->ports, list)\n\t\tunplug_port(port);\n\n\tunregister_chrdev(portdev->chr_major, \"virtio-portsdev\");\n\n\t/*\n\t * When yanking out a device, we immediately lose the\n\t * (device-side) queues.  So there's no point in keeping the\n\t * guest side around till we drop our final reference.  This\n\t * also means that any ports which are in an open state will\n\t * have to just stop using the port, as the vqs are going\n\t * away.\n\t */\n\tremove_vqs(portdev);\n\tkfree(portdev);\n}\n\n/*\n * Once we're further in boot, we get probed like any other virtio\n * device.\n *\n * If the host also supports multiple console ports, we check the\n * config space to see how many ports the host has spawned.  We\n * initialize each port found.\n */\nstatic int virtcons_probe(struct virtio_device *vdev)\n{\n\tstruct ports_device *portdev;\n\tint err;\n\tbool multiport;\n\tbool early = early_put_chars != NULL;\n\n\t/* We only need a config space if features are offered */\n\tif (!vdev->config->get &&\n\t    (virtio_has_feature(vdev, VIRTIO_CONSOLE_F_SIZE)\n\t     || virtio_has_feature(vdev, VIRTIO_CONSOLE_F_MULTIPORT))) {\n\t\tdev_err(&vdev->dev, \"%s failure: config access disabled\\n\",\n\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Ensure to read early_put_chars now */\n\tbarrier();\n\n\tportdev = kmalloc(sizeof(*portdev), GFP_KERNEL);\n\tif (!portdev) {\n\t\terr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\t/* Attach this portdev to this virtio_device, and vice-versa. */\n\tportdev->vdev = vdev;\n\tvdev->priv = portdev;\n\n\tportdev->chr_major = register_chrdev(0, \"virtio-portsdev\",\n\t\t\t\t\t     &portdev_fops);\n\tif (portdev->chr_major < 0) {\n\t\tdev_err(&vdev->dev,\n\t\t\t\"Error %d registering chrdev for device %u\\n\",\n\t\t\tportdev->chr_major, vdev->index);\n\t\terr = portdev->chr_major;\n\t\tgoto free;\n\t}\n\n\tmultiport = false;\n\tportdev->max_nr_ports = 1;\n\n\t/* Don't test MULTIPORT at all if we're rproc: not a valid feature! */\n\tif (!is_rproc_serial(vdev) &&\n\t    virtio_cread_feature(vdev, VIRTIO_CONSOLE_F_MULTIPORT,\n\t\t\t\t struct virtio_console_config, max_nr_ports,\n\t\t\t\t &portdev->max_nr_ports) == 0) {\n\t\tmultiport = true;\n\t}\n\n\terr = init_vqs(portdev);\n\tif (err < 0) {\n\t\tdev_err(&vdev->dev, \"Error %d initializing vqs\\n\", err);\n\t\tgoto free_chrdev;\n\t}\n\n\tspin_lock_init(&portdev->ports_lock);\n\tINIT_LIST_HEAD(&portdev->ports);\n\tINIT_LIST_HEAD(&portdev->list);\n\n\tvirtio_device_ready(portdev->vdev);\n\n\tINIT_WORK(&portdev->config_work, &config_work_handler);\n\tINIT_WORK(&portdev->control_work, &control_work_handler);\n\n\tif (multiport) {\n\t\tspin_lock_init(&portdev->c_ivq_lock);\n\t\tspin_lock_init(&portdev->c_ovq_lock);\n\n\t\terr = fill_queue(portdev->c_ivq, &portdev->c_ivq_lock);\n\t\tif (err < 0) {\n\t\t\tdev_err(&vdev->dev,\n\t\t\t\t\"Error allocating buffers for control queue\\n\");\n\t\t\t/*\n\t\t\t * The host might want to notify mgmt sw about device\n\t\t\t * add failure.\n\t\t\t */\n\t\t\t__send_control_msg(portdev, VIRTIO_CONSOLE_BAD_ID,\n\t\t\t\t\t   VIRTIO_CONSOLE_DEVICE_READY, 0);\n\t\t\t/* Device was functional: we need full cleanup. */\n\t\t\tvirtcons_remove(vdev);\n\t\t\treturn err;\n\t\t}\n\t} else {\n\t\t/*\n\t\t * For backward compatibility: Create a console port\n\t\t * if we're running on older host.\n\t\t */\n\t\tadd_port(portdev, 0);\n\t}\n\n\tspin_lock_irq(&pdrvdata_lock);\n\tlist_add_tail(&portdev->list, &pdrvdata.portdevs);\n\tspin_unlock_irq(&pdrvdata_lock);\n\n\t__send_control_msg(portdev, VIRTIO_CONSOLE_BAD_ID,\n\t\t\t   VIRTIO_CONSOLE_DEVICE_READY, 1);\n\n\t/*\n\t * If there was an early virtio console, assume that there are no\n\t * other consoles. We need to wait until the hvc_alloc matches the\n\t * hvc_instantiate, otherwise tty_open will complain, resulting in\n\t * a \"Warning: unable to open an initial console\" boot failure.\n\t * Without multiport this is done in add_port above. With multiport\n\t * this might take some host<->guest communication - thus we have to\n\t * wait.\n\t */\n\tif (multiport && early)\n\t\twait_for_completion(&early_console_added);\n\n\treturn 0;\n\nfree_chrdev:\n\tunregister_chrdev(portdev->chr_major, \"virtio-portsdev\");\nfree:\n\tkfree(portdev);\nfail:\n\treturn err;\n}\n\nstatic const struct virtio_device_id id_table[] = {\n\t{ VIRTIO_ID_CONSOLE, VIRTIO_DEV_ANY_ID },\n\t{ 0 },\n};\nMODULE_DEVICE_TABLE(virtio, id_table);\n\nstatic const unsigned int features[] = {\n\tVIRTIO_CONSOLE_F_SIZE,\n\tVIRTIO_CONSOLE_F_MULTIPORT,\n};\n\nstatic const struct virtio_device_id rproc_serial_id_table[] = {\n#if IS_ENABLED(CONFIG_REMOTEPROC)\n\t{ VIRTIO_ID_RPROC_SERIAL, VIRTIO_DEV_ANY_ID },\n#endif\n\t{ 0 },\n};\nMODULE_DEVICE_TABLE(virtio, rproc_serial_id_table);\n\nstatic const unsigned int rproc_serial_features[] = {\n};\n\n#ifdef CONFIG_PM_SLEEP\nstatic int virtcons_freeze(struct virtio_device *vdev)\n{\n\tstruct ports_device *portdev;\n\tstruct port *port;\n\n\tportdev = vdev->priv;\n\n\tvdev->config->reset(vdev);\n\n\tif (use_multiport(portdev))\n\t\tvirtqueue_disable_cb(portdev->c_ivq);\n\tcancel_work_sync(&portdev->control_work);\n\tcancel_work_sync(&portdev->config_work);\n\t/*\n\t * Once more: if control_work_handler() was running, it would\n\t * enable the cb as the last step.\n\t */\n\tif (use_multiport(portdev))\n\t\tvirtqueue_disable_cb(portdev->c_ivq);\n\n\tlist_for_each_entry(port, &portdev->ports, list) {\n\t\tvirtqueue_disable_cb(port->in_vq);\n\t\tvirtqueue_disable_cb(port->out_vq);\n\t\t/*\n\t\t * We'll ask the host later if the new invocation has\n\t\t * the port opened or closed.\n\t\t */\n\t\tport->host_connected = false;\n\t\tremove_port_data(port);\n\t}\n\tremove_vqs(portdev);\n\n\treturn 0;\n}\n\nstatic int virtcons_restore(struct virtio_device *vdev)\n{\n\tstruct ports_device *portdev;\n\tstruct port *port;\n\tint ret;\n\n\tportdev = vdev->priv;\n\n\tret = init_vqs(portdev);\n\tif (ret)\n\t\treturn ret;\n\n\tvirtio_device_ready(portdev->vdev);\n\n\tif (use_multiport(portdev))\n\t\tfill_queue(portdev->c_ivq, &portdev->c_ivq_lock);\n\n\tlist_for_each_entry(port, &portdev->ports, list) {\n\t\tport->in_vq = portdev->in_vqs[port->id];\n\t\tport->out_vq = portdev->out_vqs[port->id];\n\n\t\tfill_queue(port->in_vq, &port->inbuf_lock);\n\n\t\t/* Get port open/close status on the host */\n\t\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_READY, 1);\n\n\t\t/*\n\t\t * If a port was open at the time of suspending, we\n\t\t * have to let the host know that it's still open.\n\t\t */\n\t\tif (port->guest_connected)\n\t\t\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_OPEN, 1);\n\t}\n\treturn 0;\n}\n#endif\n\nstatic struct virtio_driver virtio_console = {\n\t.feature_table = features,\n\t.feature_table_size = ARRAY_SIZE(features),\n\t.driver.name =\tKBUILD_MODNAME,\n\t.driver.owner =\tTHIS_MODULE,\n\t.id_table =\tid_table,\n\t.probe =\tvirtcons_probe,\n\t.remove =\tvirtcons_remove,\n\t.config_changed = config_intr,\n#ifdef CONFIG_PM_SLEEP\n\t.freeze =\tvirtcons_freeze,\n\t.restore =\tvirtcons_restore,\n#endif\n};\n\nstatic struct virtio_driver virtio_rproc_serial = {\n\t.feature_table = rproc_serial_features,\n\t.feature_table_size = ARRAY_SIZE(rproc_serial_features),\n\t.driver.name =\t\"virtio_rproc_serial\",\n\t.driver.owner =\tTHIS_MODULE,\n\t.id_table =\trproc_serial_id_table,\n\t.probe =\tvirtcons_probe,\n\t.remove =\tvirtcons_remove,\n};\n\nstatic int __init init(void)\n{\n\tint err;\n\n\tpdrvdata.class = class_create(THIS_MODULE, \"virtio-ports\");\n\tif (IS_ERR(pdrvdata.class)) {\n\t\terr = PTR_ERR(pdrvdata.class);\n\t\tpr_err(\"Error %d creating virtio-ports class\\n\", err);\n\t\treturn err;\n\t}\n\n\tpdrvdata.debugfs_dir = debugfs_create_dir(\"virtio-ports\", NULL);\n\tINIT_LIST_HEAD(&pdrvdata.consoles);\n\tINIT_LIST_HEAD(&pdrvdata.portdevs);\n\n\terr = register_virtio_driver(&virtio_console);\n\tif (err < 0) {\n\t\tpr_err(\"Error %d registering virtio driver\\n\", err);\n\t\tgoto free;\n\t}\n\terr = register_virtio_driver(&virtio_rproc_serial);\n\tif (err < 0) {\n\t\tpr_err(\"Error %d registering virtio rproc serial driver\\n\",\n\t\t       err);\n\t\tgoto unregister;\n\t}\n\treturn 0;\nunregister:\n\tunregister_virtio_driver(&virtio_console);\nfree:\n\tdebugfs_remove_recursive(pdrvdata.debugfs_dir);\n\tclass_destroy(pdrvdata.class);\n\treturn err;\n}\n\nstatic void __exit fini(void)\n{\n\treclaim_dma_bufs();\n\n\tunregister_virtio_driver(&virtio_console);\n\tunregister_virtio_driver(&virtio_rproc_serial);\n\n\tclass_destroy(pdrvdata.class);\n\tdebugfs_remove_recursive(pdrvdata.debugfs_dir);\n}\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_DESCRIPTION(\"Virtio console driver\");\nMODULE_LICENSE(\"GPL\");\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0-or-later\n/*\n * Copyright (C) 2006, 2007, 2009 Rusty Russell, IBM Corporation\n * Copyright (C) 2009, 2010, 2011 Red Hat, Inc.\n * Copyright (C) 2009, 2010, 2011 Amit Shah <amit.shah@redhat.com>\n */\n#include <linux/cdev.h>\n#include <linux/debugfs.h>\n#include <linux/completion.h>\n#include <linux/device.h>\n#include <linux/err.h>\n#include <linux/freezer.h>\n#include <linux/fs.h>\n#include <linux/splice.h>\n#include <linux/pagemap.h>\n#include <linux/init.h>\n#include <linux/list.h>\n#include <linux/poll.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/virtio.h>\n#include <linux/virtio_console.h>\n#include <linux/wait.h>\n#include <linux/workqueue.h>\n#include <linux/module.h>\n#include <linux/dma-mapping.h>\n#include \"../tty/hvc/hvc_console.h\"\n\n#define is_rproc_enabled IS_ENABLED(CONFIG_REMOTEPROC)\n\n/*\n * This is a global struct for storing common data for all the devices\n * this driver handles.\n *\n * Mainly, it has a linked list for all the consoles in one place so\n * that callbacks from hvc for get_chars(), put_chars() work properly\n * across multiple devices and multiple ports per device.\n */\nstruct ports_driver_data {\n\t/* Used for registering chardevs */\n\tstruct class *class;\n\n\t/* Used for exporting per-port information to debugfs */\n\tstruct dentry *debugfs_dir;\n\n\t/* List of all the devices we're handling */\n\tstruct list_head portdevs;\n\n\t/*\n\t * This is used to keep track of the number of hvc consoles\n\t * spawned by this driver.  This number is given as the first\n\t * argument to hvc_alloc().  To correctly map an initial\n\t * console spawned via hvc_instantiate to the console being\n\t * hooked up via hvc_alloc, we need to pass the same vtermno.\n\t *\n\t * We also just assume the first console being initialised was\n\t * the first one that got used as the initial console.\n\t */\n\tunsigned int next_vtermno;\n\n\t/* All the console devices handled by this driver */\n\tstruct list_head consoles;\n};\nstatic struct ports_driver_data pdrvdata = { .next_vtermno = 1};\n\nstatic DEFINE_SPINLOCK(pdrvdata_lock);\nstatic DECLARE_COMPLETION(early_console_added);\n\n/* This struct holds information that's relevant only for console ports */\nstruct console {\n\t/* We'll place all consoles in a list in the pdrvdata struct */\n\tstruct list_head list;\n\n\t/* The hvc device associated with this console port */\n\tstruct hvc_struct *hvc;\n\n\t/* The size of the console */\n\tstruct winsize ws;\n\n\t/*\n\t * This number identifies the number that we used to register\n\t * with hvc in hvc_instantiate() and hvc_alloc(); this is the\n\t * number passed on by the hvc callbacks to us to\n\t * differentiate between the other console ports handled by\n\t * this driver\n\t */\n\tu32 vtermno;\n};\n\nstruct port_buffer {\n\tchar *buf;\n\n\t/* size of the buffer in *buf above */\n\tsize_t size;\n\n\t/* used length of the buffer */\n\tsize_t len;\n\t/* offset in the buf from which to consume data */\n\tsize_t offset;\n\n\t/* DMA address of buffer */\n\tdma_addr_t dma;\n\n\t/* Device we got DMA memory from */\n\tstruct device *dev;\n\n\t/* List of pending dma buffers to free */\n\tstruct list_head list;\n\n\t/* If sgpages == 0 then buf is used */\n\tunsigned int sgpages;\n\n\t/* sg is used if spages > 0. sg must be the last in is struct */\n\tstruct scatterlist sg[];\n};\n\n/*\n * This is a per-device struct that stores data common to all the\n * ports for that device (vdev->priv).\n */\nstruct ports_device {\n\t/* Next portdev in the list, head is in the pdrvdata struct */\n\tstruct list_head list;\n\n\t/*\n\t * Workqueue handlers where we process deferred work after\n\t * notification\n\t */\n\tstruct work_struct control_work;\n\tstruct work_struct config_work;\n\n\tstruct list_head ports;\n\n\t/* To protect the list of ports */\n\tspinlock_t ports_lock;\n\n\t/* To protect the vq operations for the control channel */\n\tspinlock_t c_ivq_lock;\n\tspinlock_t c_ovq_lock;\n\n\t/* max. number of ports this device can hold */\n\tu32 max_nr_ports;\n\n\t/* The virtio device we're associated with */\n\tstruct virtio_device *vdev;\n\n\t/*\n\t * A couple of virtqueues for the control channel: one for\n\t * guest->host transfers, one for host->guest transfers\n\t */\n\tstruct virtqueue *c_ivq, *c_ovq;\n\n\t/*\n\t * A control packet buffer for guest->host requests, protected\n\t * by c_ovq_lock.\n\t */\n\tstruct virtio_console_control cpkt;\n\n\t/* Array of per-port IO virtqueues */\n\tstruct virtqueue **in_vqs, **out_vqs;\n\n\t/* Major number for this device.  Ports will be created as minors. */\n\tint chr_major;\n};\n\nstruct port_stats {\n\tunsigned long bytes_sent, bytes_received, bytes_discarded;\n};\n\n/* This struct holds the per-port data */\nstruct port {\n\t/* Next port in the list, head is in the ports_device */\n\tstruct list_head list;\n\n\t/* Pointer to the parent virtio_console device */\n\tstruct ports_device *portdev;\n\n\t/* The current buffer from which data has to be fed to readers */\n\tstruct port_buffer *inbuf;\n\n\t/*\n\t * To protect the operations on the in_vq associated with this\n\t * port.  Has to be a spinlock because it can be called from\n\t * interrupt context (get_char()).\n\t */\n\tspinlock_t inbuf_lock;\n\n\t/* Protect the operations on the out_vq. */\n\tspinlock_t outvq_lock;\n\n\t/* The IO vqs for this port */\n\tstruct virtqueue *in_vq, *out_vq;\n\n\t/* File in the debugfs directory that exposes this port's information */\n\tstruct dentry *debugfs_file;\n\n\t/*\n\t * Keep count of the bytes sent, received and discarded for\n\t * this port for accounting and debugging purposes.  These\n\t * counts are not reset across port open / close events.\n\t */\n\tstruct port_stats stats;\n\n\t/*\n\t * The entries in this struct will be valid if this port is\n\t * hooked up to an hvc console\n\t */\n\tstruct console cons;\n\n\t/* Each port associates with a separate char device */\n\tstruct cdev *cdev;\n\tstruct device *dev;\n\n\t/* Reference-counting to handle port hot-unplugs and file operations */\n\tstruct kref kref;\n\n\t/* A waitqueue for poll() or blocking read operations */\n\twait_queue_head_t waitqueue;\n\n\t/* The 'name' of the port that we expose via sysfs properties */\n\tchar *name;\n\n\t/* We can notify apps of host connect / disconnect events via SIGIO */\n\tstruct fasync_struct *async_queue;\n\n\t/* The 'id' to identify the port with the Host */\n\tu32 id;\n\n\tbool outvq_full;\n\n\t/* Is the host device open */\n\tbool host_connected;\n\n\t/* We should allow only one process to open a port */\n\tbool guest_connected;\n};\n\n/* This is the very early arch-specified put chars function. */\nstatic int (*early_put_chars)(u32, const char *, int);\n\nstatic struct port *find_port_by_vtermno(u32 vtermno)\n{\n\tstruct port *port;\n\tstruct console *cons;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&pdrvdata_lock, flags);\n\tlist_for_each_entry(cons, &pdrvdata.consoles, list) {\n\t\tif (cons->vtermno == vtermno) {\n\t\t\tport = container_of(cons, struct port, cons);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tport = NULL;\nout:\n\tspin_unlock_irqrestore(&pdrvdata_lock, flags);\n\treturn port;\n}\n\nstatic struct port *find_port_by_devt_in_portdev(struct ports_device *portdev,\n\t\t\t\t\t\t dev_t dev)\n{\n\tstruct port *port;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&portdev->ports_lock, flags);\n\tlist_for_each_entry(port, &portdev->ports, list) {\n\t\tif (port->cdev->dev == dev) {\n\t\t\tkref_get(&port->kref);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tport = NULL;\nout:\n\tspin_unlock_irqrestore(&portdev->ports_lock, flags);\n\n\treturn port;\n}\n\nstatic struct port *find_port_by_devt(dev_t dev)\n{\n\tstruct ports_device *portdev;\n\tstruct port *port;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&pdrvdata_lock, flags);\n\tlist_for_each_entry(portdev, &pdrvdata.portdevs, list) {\n\t\tport = find_port_by_devt_in_portdev(portdev, dev);\n\t\tif (port)\n\t\t\tgoto out;\n\t}\n\tport = NULL;\nout:\n\tspin_unlock_irqrestore(&pdrvdata_lock, flags);\n\treturn port;\n}\n\nstatic struct port *find_port_by_id(struct ports_device *portdev, u32 id)\n{\n\tstruct port *port;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&portdev->ports_lock, flags);\n\tlist_for_each_entry(port, &portdev->ports, list)\n\t\tif (port->id == id)\n\t\t\tgoto out;\n\tport = NULL;\nout:\n\tspin_unlock_irqrestore(&portdev->ports_lock, flags);\n\n\treturn port;\n}\n\nstatic struct port *find_port_by_vq(struct ports_device *portdev,\n\t\t\t\t    struct virtqueue *vq)\n{\n\tstruct port *port;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&portdev->ports_lock, flags);\n\tlist_for_each_entry(port, &portdev->ports, list)\n\t\tif (port->in_vq == vq || port->out_vq == vq)\n\t\t\tgoto out;\n\tport = NULL;\nout:\n\tspin_unlock_irqrestore(&portdev->ports_lock, flags);\n\treturn port;\n}\n\nstatic bool is_console_port(struct port *port)\n{\n\tif (port->cons.hvc)\n\t\treturn true;\n\treturn false;\n}\n\nstatic bool is_rproc_serial(const struct virtio_device *vdev)\n{\n\treturn is_rproc_enabled && vdev->id.device == VIRTIO_ID_RPROC_SERIAL;\n}\n\nstatic inline bool use_multiport(struct ports_device *portdev)\n{\n\t/*\n\t * This condition can be true when put_chars is called from\n\t * early_init\n\t */\n\tif (!portdev->vdev)\n\t\treturn false;\n\treturn __virtio_test_bit(portdev->vdev, VIRTIO_CONSOLE_F_MULTIPORT);\n}\n\nstatic DEFINE_SPINLOCK(dma_bufs_lock);\nstatic LIST_HEAD(pending_free_dma_bufs);\n\nstatic void free_buf(struct port_buffer *buf, bool can_sleep)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < buf->sgpages; i++) {\n\t\tstruct page *page = sg_page(&buf->sg[i]);\n\t\tif (!page)\n\t\t\tbreak;\n\t\tput_page(page);\n\t}\n\n\tif (!buf->dev) {\n\t\tkfree(buf->buf);\n\t} else if (is_rproc_enabled) {\n\t\tunsigned long flags;\n\n\t\t/* dma_free_coherent requires interrupts to be enabled. */\n\t\tif (!can_sleep) {\n\t\t\t/* queue up dma-buffers to be freed later */\n\t\t\tspin_lock_irqsave(&dma_bufs_lock, flags);\n\t\t\tlist_add_tail(&buf->list, &pending_free_dma_bufs);\n\t\t\tspin_unlock_irqrestore(&dma_bufs_lock, flags);\n\t\t\treturn;\n\t\t}\n\t\tdma_free_coherent(buf->dev, buf->size, buf->buf, buf->dma);\n\n\t\t/* Release device refcnt and allow it to be freed */\n\t\tput_device(buf->dev);\n\t}\n\n\tkfree(buf);\n}\n\nstatic void reclaim_dma_bufs(void)\n{\n\tunsigned long flags;\n\tstruct port_buffer *buf, *tmp;\n\tLIST_HEAD(tmp_list);\n\n\tif (list_empty(&pending_free_dma_bufs))\n\t\treturn;\n\n\t/* Create a copy of the pending_free_dma_bufs while holding the lock */\n\tspin_lock_irqsave(&dma_bufs_lock, flags);\n\tlist_cut_position(&tmp_list, &pending_free_dma_bufs,\n\t\t\t  pending_free_dma_bufs.prev);\n\tspin_unlock_irqrestore(&dma_bufs_lock, flags);\n\n\t/* Release the dma buffers, without irqs enabled */\n\tlist_for_each_entry_safe(buf, tmp, &tmp_list, list) {\n\t\tlist_del(&buf->list);\n\t\tfree_buf(buf, true);\n\t}\n}\n\nstatic struct port_buffer *alloc_buf(struct virtio_device *vdev, size_t buf_size,\n\t\t\t\t     int pages)\n{\n\tstruct port_buffer *buf;\n\n\treclaim_dma_bufs();\n\n\t/*\n\t * Allocate buffer and the sg list. The sg list array is allocated\n\t * directly after the port_buffer struct.\n\t */\n\tbuf = kmalloc(struct_size(buf, sg, pages), GFP_KERNEL);\n\tif (!buf)\n\t\tgoto fail;\n\n\tbuf->sgpages = pages;\n\tif (pages > 0) {\n\t\tbuf->dev = NULL;\n\t\tbuf->buf = NULL;\n\t\treturn buf;\n\t}\n\n\tif (is_rproc_serial(vdev)) {\n\t\t/*\n\t\t * Allocate DMA memory from ancestor. When a virtio\n\t\t * device is created by remoteproc, the DMA memory is\n\t\t * associated with the parent device:\n\t\t * virtioY => remoteprocX#vdevYbuffer.\n\t\t */\n\t\tbuf->dev = vdev->dev.parent;\n\t\tif (!buf->dev)\n\t\t\tgoto free_buf;\n\n\t\t/* Increase device refcnt to avoid freeing it */\n\t\tget_device(buf->dev);\n\t\tbuf->buf = dma_alloc_coherent(buf->dev, buf_size, &buf->dma,\n\t\t\t\t\t      GFP_KERNEL);\n\t} else {\n\t\tbuf->dev = NULL;\n\t\tbuf->buf = kmalloc(buf_size, GFP_KERNEL);\n\t}\n\n\tif (!buf->buf)\n\t\tgoto free_buf;\n\tbuf->len = 0;\n\tbuf->offset = 0;\n\tbuf->size = buf_size;\n\treturn buf;\n\nfree_buf:\n\tkfree(buf);\nfail:\n\treturn NULL;\n}\n\n/* Callers should take appropriate locks */\nstatic struct port_buffer *get_inbuf(struct port *port)\n{\n\tstruct port_buffer *buf;\n\tunsigned int len;\n\n\tif (port->inbuf)\n\t\treturn port->inbuf;\n\n\tbuf = virtqueue_get_buf(port->in_vq, &len);\n\tif (buf) {\n\t\tbuf->len = min_t(size_t, len, buf->size);\n\t\tbuf->offset = 0;\n\t\tport->stats.bytes_received += len;\n\t}\n\treturn buf;\n}\n\n/*\n * Create a scatter-gather list representing our input buffer and put\n * it in the queue.\n *\n * Callers should take appropriate locks.\n */\nstatic int add_inbuf(struct virtqueue *vq, struct port_buffer *buf)\n{\n\tstruct scatterlist sg[1];\n\tint ret;\n\n\tsg_init_one(sg, buf->buf, buf->size);\n\n\tret = virtqueue_add_inbuf(vq, sg, 1, buf, GFP_ATOMIC);\n\tvirtqueue_kick(vq);\n\tif (!ret)\n\t\tret = vq->num_free;\n\treturn ret;\n}\n\n/* Discard any unread data this port has. Callers lockers. */\nstatic void discard_port_data(struct port *port)\n{\n\tstruct port_buffer *buf;\n\tunsigned int err;\n\n\tif (!port->portdev) {\n\t\t/* Device has been unplugged.  vqs are already gone. */\n\t\treturn;\n\t}\n\tbuf = get_inbuf(port);\n\n\terr = 0;\n\twhile (buf) {\n\t\tport->stats.bytes_discarded += buf->len - buf->offset;\n\t\tif (add_inbuf(port->in_vq, buf) < 0) {\n\t\t\terr++;\n\t\t\tfree_buf(buf, false);\n\t\t}\n\t\tport->inbuf = NULL;\n\t\tbuf = get_inbuf(port);\n\t}\n\tif (err)\n\t\tdev_warn(port->dev, \"Errors adding %d buffers back to vq\\n\",\n\t\t\t err);\n}\n\nstatic bool port_has_data(struct port *port)\n{\n\tunsigned long flags;\n\tbool ret;\n\n\tret = false;\n\tspin_lock_irqsave(&port->inbuf_lock, flags);\n\tport->inbuf = get_inbuf(port);\n\tif (port->inbuf)\n\t\tret = true;\n\n\tspin_unlock_irqrestore(&port->inbuf_lock, flags);\n\treturn ret;\n}\n\nstatic ssize_t __send_control_msg(struct ports_device *portdev, u32 port_id,\n\t\t\t\t  unsigned int event, unsigned int value)\n{\n\tstruct scatterlist sg[1];\n\tstruct virtqueue *vq;\n\tunsigned int len;\n\n\tif (!use_multiport(portdev))\n\t\treturn 0;\n\n\tvq = portdev->c_ovq;\n\n\tspin_lock(&portdev->c_ovq_lock);\n\n\tportdev->cpkt.id = cpu_to_virtio32(portdev->vdev, port_id);\n\tportdev->cpkt.event = cpu_to_virtio16(portdev->vdev, event);\n\tportdev->cpkt.value = cpu_to_virtio16(portdev->vdev, value);\n\n\tsg_init_one(sg, &portdev->cpkt, sizeof(struct virtio_console_control));\n\n\tif (virtqueue_add_outbuf(vq, sg, 1, &portdev->cpkt, GFP_ATOMIC) == 0) {\n\t\tvirtqueue_kick(vq);\n\t\twhile (!virtqueue_get_buf(vq, &len)\n\t\t\t&& !virtqueue_is_broken(vq))\n\t\t\tcpu_relax();\n\t}\n\n\tspin_unlock(&portdev->c_ovq_lock);\n\treturn 0;\n}\n\nstatic ssize_t send_control_msg(struct port *port, unsigned int event,\n\t\t\t\tunsigned int value)\n{\n\t/* Did the port get unplugged before userspace closed it? */\n\tif (port->portdev)\n\t\treturn __send_control_msg(port->portdev, port->id, event, value);\n\treturn 0;\n}\n\n\n/* Callers must take the port->outvq_lock */\nstatic void reclaim_consumed_buffers(struct port *port)\n{\n\tstruct port_buffer *buf;\n\tunsigned int len;\n\n\tif (!port->portdev) {\n\t\t/* Device has been unplugged.  vqs are already gone. */\n\t\treturn;\n\t}\n\twhile ((buf = virtqueue_get_buf(port->out_vq, &len))) {\n\t\tfree_buf(buf, false);\n\t\tport->outvq_full = false;\n\t}\n}\n\nstatic ssize_t __send_to_port(struct port *port, struct scatterlist *sg,\n\t\t\t      int nents, size_t in_count,\n\t\t\t      void *data, bool nonblock)\n{\n\tstruct virtqueue *out_vq;\n\tint err;\n\tunsigned long flags;\n\tunsigned int len;\n\n\tout_vq = port->out_vq;\n\n\tspin_lock_irqsave(&port->outvq_lock, flags);\n\n\treclaim_consumed_buffers(port);\n\n\terr = virtqueue_add_outbuf(out_vq, sg, nents, data, GFP_ATOMIC);\n\n\t/* Tell Host to go! */\n\tvirtqueue_kick(out_vq);\n\n\tif (err) {\n\t\tin_count = 0;\n\t\tgoto done;\n\t}\n\n\tif (out_vq->num_free == 0)\n\t\tport->outvq_full = true;\n\n\tif (nonblock)\n\t\tgoto done;\n\n\t/*\n\t * Wait till the host acknowledges it pushed out the data we\n\t * sent.  This is done for data from the hvc_console; the tty\n\t * operations are performed with spinlocks held so we can't\n\t * sleep here.  An alternative would be to copy the data to a\n\t * buffer and relax the spinning requirement.  The downside is\n\t * we need to kmalloc a GFP_ATOMIC buffer each time the\n\t * console driver writes something out.\n\t */\n\twhile (!virtqueue_get_buf(out_vq, &len)\n\t\t&& !virtqueue_is_broken(out_vq))\n\t\tcpu_relax();\ndone:\n\tspin_unlock_irqrestore(&port->outvq_lock, flags);\n\n\tport->stats.bytes_sent += in_count;\n\t/*\n\t * We're expected to return the amount of data we wrote -- all\n\t * of it\n\t */\n\treturn in_count;\n}\n\n/*\n * Give out the data that's requested from the buffer that we have\n * queued up.\n */\nstatic ssize_t fill_readbuf(struct port *port, char __user *out_buf,\n\t\t\t    size_t out_count, bool to_user)\n{\n\tstruct port_buffer *buf;\n\tunsigned long flags;\n\n\tif (!out_count || !port_has_data(port))\n\t\treturn 0;\n\n\tbuf = port->inbuf;\n\tout_count = min(out_count, buf->len - buf->offset);\n\n\tif (to_user) {\n\t\tssize_t ret;\n\n\t\tret = copy_to_user(out_buf, buf->buf + buf->offset, out_count);\n\t\tif (ret)\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tmemcpy((__force char *)out_buf, buf->buf + buf->offset,\n\t\t       out_count);\n\t}\n\n\tbuf->offset += out_count;\n\n\tif (buf->offset == buf->len) {\n\t\t/*\n\t\t * We're done using all the data in this buffer.\n\t\t * Re-queue so that the Host can send us more data.\n\t\t */\n\t\tspin_lock_irqsave(&port->inbuf_lock, flags);\n\t\tport->inbuf = NULL;\n\n\t\tif (add_inbuf(port->in_vq, buf) < 0)\n\t\t\tdev_warn(port->dev, \"failed add_buf\\n\");\n\n\t\tspin_unlock_irqrestore(&port->inbuf_lock, flags);\n\t}\n\t/* Return the number of bytes actually copied */\n\treturn out_count;\n}\n\n/* The condition that must be true for polling to end */\nstatic bool will_read_block(struct port *port)\n{\n\tif (!port->guest_connected) {\n\t\t/* Port got hot-unplugged. Let's exit. */\n\t\treturn false;\n\t}\n\treturn !port_has_data(port) && port->host_connected;\n}\n\nstatic bool will_write_block(struct port *port)\n{\n\tbool ret;\n\n\tif (!port->guest_connected) {\n\t\t/* Port got hot-unplugged. Let's exit. */\n\t\treturn false;\n\t}\n\tif (!port->host_connected)\n\t\treturn true;\n\n\tspin_lock_irq(&port->outvq_lock);\n\t/*\n\t * Check if the Host has consumed any buffers since we last\n\t * sent data (this is only applicable for nonblocking ports).\n\t */\n\treclaim_consumed_buffers(port);\n\tret = port->outvq_full;\n\tspin_unlock_irq(&port->outvq_lock);\n\n\treturn ret;\n}\n\nstatic ssize_t port_fops_read(struct file *filp, char __user *ubuf,\n\t\t\t      size_t count, loff_t *offp)\n{\n\tstruct port *port;\n\tssize_t ret;\n\n\tport = filp->private_data;\n\n\t/* Port is hot-unplugged. */\n\tif (!port->guest_connected)\n\t\treturn -ENODEV;\n\n\tif (!port_has_data(port)) {\n\t\t/*\n\t\t * If nothing's connected on the host just return 0 in\n\t\t * case of list_empty; this tells the userspace app\n\t\t * that there's no connection\n\t\t */\n\t\tif (!port->host_connected)\n\t\t\treturn 0;\n\t\tif (filp->f_flags & O_NONBLOCK)\n\t\t\treturn -EAGAIN;\n\n\t\tret = wait_event_freezable(port->waitqueue,\n\t\t\t\t\t   !will_read_block(port));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\t/* Port got hot-unplugged while we were waiting above. */\n\tif (!port->guest_connected)\n\t\treturn -ENODEV;\n\t/*\n\t * We could've received a disconnection message while we were\n\t * waiting for more data.\n\t *\n\t * This check is not clubbed in the if() statement above as we\n\t * might receive some data as well as the host could get\n\t * disconnected after we got woken up from our wait.  So we\n\t * really want to give off whatever data we have and only then\n\t * check for host_connected.\n\t */\n\tif (!port_has_data(port) && !port->host_connected)\n\t\treturn 0;\n\n\treturn fill_readbuf(port, ubuf, count, true);\n}\n\nstatic int wait_port_writable(struct port *port, bool nonblock)\n{\n\tint ret;\n\n\tif (will_write_block(port)) {\n\t\tif (nonblock)\n\t\t\treturn -EAGAIN;\n\n\t\tret = wait_event_freezable(port->waitqueue,\n\t\t\t\t\t   !will_write_block(port));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\t/* Port got hot-unplugged. */\n\tif (!port->guest_connected)\n\t\treturn -ENODEV;\n\n\treturn 0;\n}\n\nstatic ssize_t port_fops_write(struct file *filp, const char __user *ubuf,\n\t\t\t       size_t count, loff_t *offp)\n{\n\tstruct port *port;\n\tstruct port_buffer *buf;\n\tssize_t ret;\n\tbool nonblock;\n\tstruct scatterlist sg[1];\n\n\t/* Userspace could be out to fool us */\n\tif (!count)\n\t\treturn 0;\n\n\tport = filp->private_data;\n\n\tnonblock = filp->f_flags & O_NONBLOCK;\n\n\tret = wait_port_writable(port, nonblock);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tcount = min((size_t)(32 * 1024), count);\n\n\tbuf = alloc_buf(port->portdev->vdev, count, 0);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = copy_from_user(buf->buf, ubuf, count);\n\tif (ret) {\n\t\tret = -EFAULT;\n\t\tgoto free_buf;\n\t}\n\n\t/*\n\t * We now ask send_buf() to not spin for generic ports -- we\n\t * can re-use the same code path that non-blocking file\n\t * descriptors take for blocking file descriptors since the\n\t * wait is already done and we're certain the write will go\n\t * through to the host.\n\t */\n\tnonblock = true;\n\tsg_init_one(sg, buf->buf, count);\n\tret = __send_to_port(port, sg, 1, count, buf, nonblock);\n\n\tif (nonblock && ret > 0)\n\t\tgoto out;\n\nfree_buf:\n\tfree_buf(buf, true);\nout:\n\treturn ret;\n}\n\nstruct sg_list {\n\tunsigned int n;\n\tunsigned int size;\n\tsize_t len;\n\tstruct scatterlist *sg;\n};\n\nstatic int pipe_to_sg(struct pipe_inode_info *pipe, struct pipe_buffer *buf,\n\t\t\tstruct splice_desc *sd)\n{\n\tstruct sg_list *sgl = sd->u.data;\n\tunsigned int offset, len;\n\n\tif (sgl->n == sgl->size)\n\t\treturn 0;\n\n\t/* Try lock this page */\n\tif (pipe_buf_try_steal(pipe, buf)) {\n\t\t/* Get reference and unlock page for moving */\n\t\tget_page(buf->page);\n\t\tunlock_page(buf->page);\n\n\t\tlen = min(buf->len, sd->len);\n\t\tsg_set_page(&(sgl->sg[sgl->n]), buf->page, len, buf->offset);\n\t} else {\n\t\t/* Failback to copying a page */\n\t\tstruct page *page = alloc_page(GFP_KERNEL);\n\t\tchar *src;\n\n\t\tif (!page)\n\t\t\treturn -ENOMEM;\n\n\t\toffset = sd->pos & ~PAGE_MASK;\n\n\t\tlen = sd->len;\n\t\tif (len + offset > PAGE_SIZE)\n\t\t\tlen = PAGE_SIZE - offset;\n\n\t\tsrc = kmap_atomic(buf->page);\n\t\tmemcpy(page_address(page) + offset, src + buf->offset, len);\n\t\tkunmap_atomic(src);\n\n\t\tsg_set_page(&(sgl->sg[sgl->n]), page, len, offset);\n\t}\n\tsgl->n++;\n\tsgl->len += len;\n\n\treturn len;\n}\n\n/* Faster zero-copy write by splicing */\nstatic ssize_t port_fops_splice_write(struct pipe_inode_info *pipe,\n\t\t\t\t      struct file *filp, loff_t *ppos,\n\t\t\t\t      size_t len, unsigned int flags)\n{\n\tstruct port *port = filp->private_data;\n\tstruct sg_list sgl;\n\tssize_t ret;\n\tstruct port_buffer *buf;\n\tstruct splice_desc sd = {\n\t\t.total_len = len,\n\t\t.flags = flags,\n\t\t.pos = *ppos,\n\t\t.u.data = &sgl,\n\t};\n\tunsigned int occupancy;\n\n\t/*\n\t * Rproc_serial does not yet support splice. To support splice\n\t * pipe_to_sg() must allocate dma-buffers and copy content from\n\t * regular pages to dma pages. And alloc_buf and free_buf must\n\t * support allocating and freeing such a list of dma-buffers.\n\t */\n\tif (is_rproc_serial(port->out_vq->vdev))\n\t\treturn -EINVAL;\n\n\tpipe_lock(pipe);\n\tret = 0;\n\tif (pipe_empty(pipe->head, pipe->tail))\n\t\tgoto error_out;\n\n\tret = wait_port_writable(port, filp->f_flags & O_NONBLOCK);\n\tif (ret < 0)\n\t\tgoto error_out;\n\n\toccupancy = pipe_occupancy(pipe->head, pipe->tail);\n\tbuf = alloc_buf(port->portdev->vdev, 0, occupancy);\n\n\tif (!buf) {\n\t\tret = -ENOMEM;\n\t\tgoto error_out;\n\t}\n\n\tsgl.n = 0;\n\tsgl.len = 0;\n\tsgl.size = occupancy;\n\tsgl.sg = buf->sg;\n\tsg_init_table(sgl.sg, sgl.size);\n\tret = __splice_from_pipe(pipe, &sd, pipe_to_sg);\n\tpipe_unlock(pipe);\n\tif (likely(ret > 0))\n\t\tret = __send_to_port(port, buf->sg, sgl.n, sgl.len, buf, true);\n\n\tif (unlikely(ret <= 0))\n\t\tfree_buf(buf, true);\n\treturn ret;\n\nerror_out:\n\tpipe_unlock(pipe);\n\treturn ret;\n}\n\nstatic __poll_t port_fops_poll(struct file *filp, poll_table *wait)\n{\n\tstruct port *port;\n\t__poll_t ret;\n\n\tport = filp->private_data;\n\tpoll_wait(filp, &port->waitqueue, wait);\n\n\tif (!port->guest_connected) {\n\t\t/* Port got unplugged */\n\t\treturn EPOLLHUP;\n\t}\n\tret = 0;\n\tif (!will_read_block(port))\n\t\tret |= EPOLLIN | EPOLLRDNORM;\n\tif (!will_write_block(port))\n\t\tret |= EPOLLOUT;\n\tif (!port->host_connected)\n\t\tret |= EPOLLHUP;\n\n\treturn ret;\n}\n\nstatic void remove_port(struct kref *kref);\n\nstatic int port_fops_release(struct inode *inode, struct file *filp)\n{\n\tstruct port *port;\n\n\tport = filp->private_data;\n\n\t/* Notify host of port being closed */\n\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_OPEN, 0);\n\n\tspin_lock_irq(&port->inbuf_lock);\n\tport->guest_connected = false;\n\n\tdiscard_port_data(port);\n\n\tspin_unlock_irq(&port->inbuf_lock);\n\n\tspin_lock_irq(&port->outvq_lock);\n\treclaim_consumed_buffers(port);\n\tspin_unlock_irq(&port->outvq_lock);\n\n\treclaim_dma_bufs();\n\t/*\n\t * Locks aren't necessary here as a port can't be opened after\n\t * unplug, and if a port isn't unplugged, a kref would already\n\t * exist for the port.  Plus, taking ports_lock here would\n\t * create a dependency on other locks taken by functions\n\t * inside remove_port if we're the last holder of the port,\n\t * creating many problems.\n\t */\n\tkref_put(&port->kref, remove_port);\n\n\treturn 0;\n}\n\nstatic int port_fops_open(struct inode *inode, struct file *filp)\n{\n\tstruct cdev *cdev = inode->i_cdev;\n\tstruct port *port;\n\tint ret;\n\n\t/* We get the port with a kref here */\n\tport = find_port_by_devt(cdev->dev);\n\tif (!port) {\n\t\t/* Port was unplugged before we could proceed */\n\t\treturn -ENXIO;\n\t}\n\tfilp->private_data = port;\n\n\t/*\n\t * Don't allow opening of console port devices -- that's done\n\t * via /dev/hvc\n\t */\n\tif (is_console_port(port)) {\n\t\tret = -ENXIO;\n\t\tgoto out;\n\t}\n\n\t/* Allow only one process to open a particular port at a time */\n\tspin_lock_irq(&port->inbuf_lock);\n\tif (port->guest_connected) {\n\t\tspin_unlock_irq(&port->inbuf_lock);\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tport->guest_connected = true;\n\tspin_unlock_irq(&port->inbuf_lock);\n\n\tspin_lock_irq(&port->outvq_lock);\n\t/*\n\t * There might be a chance that we missed reclaiming a few\n\t * buffers in the window of the port getting previously closed\n\t * and opening now.\n\t */\n\treclaim_consumed_buffers(port);\n\tspin_unlock_irq(&port->outvq_lock);\n\n\tnonseekable_open(inode, filp);\n\n\t/* Notify host of port being opened */\n\tsend_control_msg(filp->private_data, VIRTIO_CONSOLE_PORT_OPEN, 1);\n\n\treturn 0;\nout:\n\tkref_put(&port->kref, remove_port);\n\treturn ret;\n}\n\nstatic int port_fops_fasync(int fd, struct file *filp, int mode)\n{\n\tstruct port *port;\n\n\tport = filp->private_data;\n\treturn fasync_helper(fd, filp, mode, &port->async_queue);\n}\n\n/*\n * The file operations that we support: programs in the guest can open\n * a console device, read from it, write to it, poll for data and\n * close it.  The devices are at\n *   /dev/vport<device number>p<port number>\n */\nstatic const struct file_operations port_fops = {\n\t.owner = THIS_MODULE,\n\t.open  = port_fops_open,\n\t.read  = port_fops_read,\n\t.write = port_fops_write,\n\t.splice_write = port_fops_splice_write,\n\t.poll  = port_fops_poll,\n\t.release = port_fops_release,\n\t.fasync = port_fops_fasync,\n\t.llseek = no_llseek,\n};\n\n/*\n * The put_chars() callback is pretty straightforward.\n *\n * We turn the characters into a scatter-gather list, add it to the\n * output queue and then kick the Host.  Then we sit here waiting for\n * it to finish: inefficient in theory, but in practice\n * implementations will do it immediately.\n */\nstatic int put_chars(u32 vtermno, const char *buf, int count)\n{\n\tstruct port *port;\n\tstruct scatterlist sg[1];\n\tvoid *data;\n\tint ret;\n\n\tif (unlikely(early_put_chars))\n\t\treturn early_put_chars(vtermno, buf, count);\n\n\tport = find_port_by_vtermno(vtermno);\n\tif (!port)\n\t\treturn -EPIPE;\n\n\tdata = kmemdup(buf, count, GFP_ATOMIC);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tsg_init_one(sg, data, count);\n\tret = __send_to_port(port, sg, 1, count, data, false);\n\tkfree(data);\n\treturn ret;\n}\n\n/*\n * get_chars() is the callback from the hvc_console infrastructure\n * when an interrupt is received.\n *\n * We call out to fill_readbuf that gets us the required data from the\n * buffers that are queued up.\n */\nstatic int get_chars(u32 vtermno, char *buf, int count)\n{\n\tstruct port *port;\n\n\t/* If we've not set up the port yet, we have no input to give. */\n\tif (unlikely(early_put_chars))\n\t\treturn 0;\n\n\tport = find_port_by_vtermno(vtermno);\n\tif (!port)\n\t\treturn -EPIPE;\n\n\t/* If we don't have an input queue yet, we can't get input. */\n\tBUG_ON(!port->in_vq);\n\n\treturn fill_readbuf(port, (__force char __user *)buf, count, false);\n}\n\nstatic void resize_console(struct port *port)\n{\n\tstruct virtio_device *vdev;\n\n\t/* The port could have been hot-unplugged */\n\tif (!port || !is_console_port(port))\n\t\treturn;\n\n\tvdev = port->portdev->vdev;\n\n\t/* Don't test F_SIZE at all if we're rproc: not a valid feature! */\n\tif (!is_rproc_serial(vdev) &&\n\t    virtio_has_feature(vdev, VIRTIO_CONSOLE_F_SIZE))\n\t\thvc_resize(port->cons.hvc, port->cons.ws);\n}\n\n/* We set the configuration at this point, since we now have a tty */\nstatic int notifier_add_vio(struct hvc_struct *hp, int data)\n{\n\tstruct port *port;\n\n\tport = find_port_by_vtermno(hp->vtermno);\n\tif (!port)\n\t\treturn -EINVAL;\n\n\thp->irq_requested = 1;\n\tresize_console(port);\n\n\treturn 0;\n}\n\nstatic void notifier_del_vio(struct hvc_struct *hp, int data)\n{\n\thp->irq_requested = 0;\n}\n\n/* The operations for console ports. */\nstatic const struct hv_ops hv_ops = {\n\t.get_chars = get_chars,\n\t.put_chars = put_chars,\n\t.notifier_add = notifier_add_vio,\n\t.notifier_del = notifier_del_vio,\n\t.notifier_hangup = notifier_del_vio,\n};\n\n/*\n * Console drivers are initialized very early so boot messages can go\n * out, so we do things slightly differently from the generic virtio\n * initialization of the net and block drivers.\n *\n * At this stage, the console is output-only.  It's too early to set\n * up a virtqueue, so we let the drivers do some boutique early-output\n * thing.\n */\nint __init virtio_cons_early_init(int (*put_chars)(u32, const char *, int))\n{\n\tearly_put_chars = put_chars;\n\treturn hvc_instantiate(0, 0, &hv_ops);\n}\n\nstatic int init_port_console(struct port *port)\n{\n\tint ret;\n\n\t/*\n\t * The Host's telling us this port is a console port.  Hook it\n\t * up with an hvc console.\n\t *\n\t * To set up and manage our virtual console, we call\n\t * hvc_alloc().\n\t *\n\t * The first argument of hvc_alloc() is the virtual console\n\t * number.  The second argument is the parameter for the\n\t * notification mechanism (like irq number).  We currently\n\t * leave this as zero, virtqueues have implicit notifications.\n\t *\n\t * The third argument is a \"struct hv_ops\" containing the\n\t * put_chars() get_chars(), notifier_add() and notifier_del()\n\t * pointers.  The final argument is the output buffer size: we\n\t * can do any size, so we put PAGE_SIZE here.\n\t */\n\tport->cons.vtermno = pdrvdata.next_vtermno;\n\n\tport->cons.hvc = hvc_alloc(port->cons.vtermno, 0, &hv_ops, PAGE_SIZE);\n\tif (IS_ERR(port->cons.hvc)) {\n\t\tret = PTR_ERR(port->cons.hvc);\n\t\tdev_err(port->dev,\n\t\t\t\"error %d allocating hvc for port\\n\", ret);\n\t\tport->cons.hvc = NULL;\n\t\treturn ret;\n\t}\n\tspin_lock_irq(&pdrvdata_lock);\n\tpdrvdata.next_vtermno++;\n\tlist_add_tail(&port->cons.list, &pdrvdata.consoles);\n\tspin_unlock_irq(&pdrvdata_lock);\n\tport->guest_connected = true;\n\n\t/*\n\t * Start using the new console output if this is the first\n\t * console to come up.\n\t */\n\tif (early_put_chars)\n\t\tearly_put_chars = NULL;\n\n\t/* Notify host of port being opened */\n\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_OPEN, 1);\n\n\treturn 0;\n}\n\nstatic ssize_t show_port_name(struct device *dev,\n\t\t\t      struct device_attribute *attr, char *buffer)\n{\n\tstruct port *port;\n\n\tport = dev_get_drvdata(dev);\n\n\treturn sprintf(buffer, \"%s\\n\", port->name);\n}\n\nstatic DEVICE_ATTR(name, S_IRUGO, show_port_name, NULL);\n\nstatic struct attribute *port_sysfs_entries[] = {\n\t&dev_attr_name.attr,\n\tNULL\n};\n\nstatic const struct attribute_group port_attribute_group = {\n\t.name = NULL,\t\t/* put in device directory */\n\t.attrs = port_sysfs_entries,\n};\n\nstatic int port_debugfs_show(struct seq_file *s, void *data)\n{\n\tstruct port *port = s->private;\n\n\tseq_printf(s, \"name: %s\\n\", port->name ? port->name : \"\");\n\tseq_printf(s, \"guest_connected: %d\\n\", port->guest_connected);\n\tseq_printf(s, \"host_connected: %d\\n\", port->host_connected);\n\tseq_printf(s, \"outvq_full: %d\\n\", port->outvq_full);\n\tseq_printf(s, \"bytes_sent: %lu\\n\", port->stats.bytes_sent);\n\tseq_printf(s, \"bytes_received: %lu\\n\", port->stats.bytes_received);\n\tseq_printf(s, \"bytes_discarded: %lu\\n\", port->stats.bytes_discarded);\n\tseq_printf(s, \"is_console: %s\\n\",\n\t\t   is_console_port(port) ? \"yes\" : \"no\");\n\tseq_printf(s, \"console_vtermno: %u\\n\", port->cons.vtermno);\n\n\treturn 0;\n}\n\nDEFINE_SHOW_ATTRIBUTE(port_debugfs);\n\nstatic void set_console_size(struct port *port, u16 rows, u16 cols)\n{\n\tif (!port || !is_console_port(port))\n\t\treturn;\n\n\tport->cons.ws.ws_row = rows;\n\tport->cons.ws.ws_col = cols;\n}\n\nstatic int fill_queue(struct virtqueue *vq, spinlock_t *lock)\n{\n\tstruct port_buffer *buf;\n\tint nr_added_bufs;\n\tint ret;\n\n\tnr_added_bufs = 0;\n\tdo {\n\t\tbuf = alloc_buf(vq->vdev, PAGE_SIZE, 0);\n\t\tif (!buf)\n\t\t\treturn -ENOMEM;\n\n\t\tspin_lock_irq(lock);\n\t\tret = add_inbuf(vq, buf);\n\t\tif (ret < 0) {\n\t\t\tspin_unlock_irq(lock);\n\t\t\tfree_buf(buf, true);\n\t\t\treturn ret;\n\t\t}\n\t\tnr_added_bufs++;\n\t\tspin_unlock_irq(lock);\n\t} while (ret > 0);\n\n\treturn nr_added_bufs;\n}\n\nstatic void send_sigio_to_port(struct port *port)\n{\n\tif (port->async_queue && port->guest_connected)\n\t\tkill_fasync(&port->async_queue, SIGIO, POLL_OUT);\n}\n\nstatic int add_port(struct ports_device *portdev, u32 id)\n{\n\tchar debugfs_name[16];\n\tstruct port *port;\n\tdev_t devt;\n\tint err;\n\n\tport = kmalloc(sizeof(*port), GFP_KERNEL);\n\tif (!port) {\n\t\terr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tkref_init(&port->kref);\n\n\tport->portdev = portdev;\n\tport->id = id;\n\n\tport->name = NULL;\n\tport->inbuf = NULL;\n\tport->cons.hvc = NULL;\n\tport->async_queue = NULL;\n\n\tport->cons.ws.ws_row = port->cons.ws.ws_col = 0;\n\tport->cons.vtermno = 0;\n\n\tport->host_connected = port->guest_connected = false;\n\tport->stats = (struct port_stats) { 0 };\n\n\tport->outvq_full = false;\n\n\tport->in_vq = portdev->in_vqs[port->id];\n\tport->out_vq = portdev->out_vqs[port->id];\n\n\tport->cdev = cdev_alloc();\n\tif (!port->cdev) {\n\t\tdev_err(&port->portdev->vdev->dev, \"Error allocating cdev\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto free_port;\n\t}\n\tport->cdev->ops = &port_fops;\n\n\tdevt = MKDEV(portdev->chr_major, id);\n\terr = cdev_add(port->cdev, devt, 1);\n\tif (err < 0) {\n\t\tdev_err(&port->portdev->vdev->dev,\n\t\t\t\"Error %d adding cdev for port %u\\n\", err, id);\n\t\tgoto free_cdev;\n\t}\n\tport->dev = device_create(pdrvdata.class, &port->portdev->vdev->dev,\n\t\t\t\t  devt, port, \"vport%up%u\",\n\t\t\t\t  port->portdev->vdev->index, id);\n\tif (IS_ERR(port->dev)) {\n\t\terr = PTR_ERR(port->dev);\n\t\tdev_err(&port->portdev->vdev->dev,\n\t\t\t\"Error %d creating device for port %u\\n\",\n\t\t\terr, id);\n\t\tgoto free_cdev;\n\t}\n\n\tspin_lock_init(&port->inbuf_lock);\n\tspin_lock_init(&port->outvq_lock);\n\tinit_waitqueue_head(&port->waitqueue);\n\n\t/* We can safely ignore ENOSPC because it means\n\t * the queue already has buffers. Buffers are removed\n\t * only by virtcons_remove(), not by unplug_port()\n\t */\n\terr = fill_queue(port->in_vq, &port->inbuf_lock);\n\tif (err < 0 && err != -ENOSPC) {\n\t\tdev_err(port->dev, \"Error allocating inbufs\\n\");\n\t\tgoto free_device;\n\t}\n\n\tif (is_rproc_serial(port->portdev->vdev))\n\t\t/*\n\t\t * For rproc_serial assume remote processor is connected.\n\t\t * rproc_serial does not want the console port, only\n\t\t * the generic port implementation.\n\t\t */\n\t\tport->host_connected = true;\n\telse if (!use_multiport(port->portdev)) {\n\t\t/*\n\t\t * If we're not using multiport support,\n\t\t * this has to be a console port.\n\t\t */\n\t\terr = init_port_console(port);\n\t\tif (err)\n\t\t\tgoto free_inbufs;\n\t}\n\n\tspin_lock_irq(&portdev->ports_lock);\n\tlist_add_tail(&port->list, &port->portdev->ports);\n\tspin_unlock_irq(&portdev->ports_lock);\n\n\t/*\n\t * Tell the Host we're set so that it can send us various\n\t * configuration parameters for this port (eg, port name,\n\t * caching, whether this is a console port, etc.)\n\t */\n\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_READY, 1);\n\n\t/*\n\t * Finally, create the debugfs file that we can use to\n\t * inspect a port's state at any time\n\t */\n\tsnprintf(debugfs_name, sizeof(debugfs_name), \"vport%up%u\",\n\t\t port->portdev->vdev->index, id);\n\tport->debugfs_file = debugfs_create_file(debugfs_name, 0444,\n\t\t\t\t\t\t pdrvdata.debugfs_dir,\n\t\t\t\t\t\t port, &port_debugfs_fops);\n\treturn 0;\n\nfree_inbufs:\nfree_device:\n\tdevice_destroy(pdrvdata.class, port->dev->devt);\nfree_cdev:\n\tcdev_del(port->cdev);\nfree_port:\n\tkfree(port);\nfail:\n\t/* The host might want to notify management sw about port add failure */\n\t__send_control_msg(portdev, id, VIRTIO_CONSOLE_PORT_READY, 0);\n\treturn err;\n}\n\n/* No users remain, remove all port-specific data. */\nstatic void remove_port(struct kref *kref)\n{\n\tstruct port *port;\n\n\tport = container_of(kref, struct port, kref);\n\n\tkfree(port);\n}\n\nstatic void remove_port_data(struct port *port)\n{\n\tspin_lock_irq(&port->inbuf_lock);\n\t/* Remove unused data this port might have received. */\n\tdiscard_port_data(port);\n\tspin_unlock_irq(&port->inbuf_lock);\n\n\tspin_lock_irq(&port->outvq_lock);\n\treclaim_consumed_buffers(port);\n\tspin_unlock_irq(&port->outvq_lock);\n}\n\n/*\n * Port got unplugged.  Remove port from portdev's list and drop the\n * kref reference.  If no userspace has this port opened, it will\n * result in immediate removal the port.\n */\nstatic void unplug_port(struct port *port)\n{\n\tspin_lock_irq(&port->portdev->ports_lock);\n\tlist_del(&port->list);\n\tspin_unlock_irq(&port->portdev->ports_lock);\n\n\tspin_lock_irq(&port->inbuf_lock);\n\tif (port->guest_connected) {\n\t\t/* Let the app know the port is going down. */\n\t\tsend_sigio_to_port(port);\n\n\t\t/* Do this after sigio is actually sent */\n\t\tport->guest_connected = false;\n\t\tport->host_connected = false;\n\n\t\twake_up_interruptible(&port->waitqueue);\n\t}\n\tspin_unlock_irq(&port->inbuf_lock);\n\n\tif (is_console_port(port)) {\n\t\tspin_lock_irq(&pdrvdata_lock);\n\t\tlist_del(&port->cons.list);\n\t\tspin_unlock_irq(&pdrvdata_lock);\n\t\thvc_remove(port->cons.hvc);\n\t}\n\n\tremove_port_data(port);\n\n\t/*\n\t * We should just assume the device itself has gone off --\n\t * else a close on an open port later will try to send out a\n\t * control message.\n\t */\n\tport->portdev = NULL;\n\n\tsysfs_remove_group(&port->dev->kobj, &port_attribute_group);\n\tdevice_destroy(pdrvdata.class, port->dev->devt);\n\tcdev_del(port->cdev);\n\n\tdebugfs_remove(port->debugfs_file);\n\tkfree(port->name);\n\n\t/*\n\t * Locks around here are not necessary - a port can't be\n\t * opened after we removed the port struct from ports_list\n\t * above.\n\t */\n\tkref_put(&port->kref, remove_port);\n}\n\n/* Any private messages that the Host and Guest want to share */\nstatic void handle_control_message(struct virtio_device *vdev,\n\t\t\t\t   struct ports_device *portdev,\n\t\t\t\t   struct port_buffer *buf)\n{\n\tstruct virtio_console_control *cpkt;\n\tstruct port *port;\n\tsize_t name_size;\n\tint err;\n\n\tcpkt = (struct virtio_console_control *)(buf->buf + buf->offset);\n\n\tport = find_port_by_id(portdev, virtio32_to_cpu(vdev, cpkt->id));\n\tif (!port &&\n\t    cpkt->event != cpu_to_virtio16(vdev, VIRTIO_CONSOLE_PORT_ADD)) {\n\t\t/* No valid header at start of buffer.  Drop it. */\n\t\tdev_dbg(&portdev->vdev->dev,\n\t\t\t\"Invalid index %u in control packet\\n\", cpkt->id);\n\t\treturn;\n\t}\n\n\tswitch (virtio16_to_cpu(vdev, cpkt->event)) {\n\tcase VIRTIO_CONSOLE_PORT_ADD:\n\t\tif (port) {\n\t\t\tdev_dbg(&portdev->vdev->dev,\n\t\t\t\t\"Port %u already added\\n\", port->id);\n\t\t\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_READY, 1);\n\t\t\tbreak;\n\t\t}\n\t\tif (virtio32_to_cpu(vdev, cpkt->id) >=\n\t\t    portdev->max_nr_ports) {\n\t\t\tdev_warn(&portdev->vdev->dev,\n\t\t\t\t\"Request for adding port with \"\n\t\t\t\t\"out-of-bound id %u, max. supported id: %u\\n\",\n\t\t\t\tcpkt->id, portdev->max_nr_ports - 1);\n\t\t\tbreak;\n\t\t}\n\t\tadd_port(portdev, virtio32_to_cpu(vdev, cpkt->id));\n\t\tbreak;\n\tcase VIRTIO_CONSOLE_PORT_REMOVE:\n\t\tunplug_port(port);\n\t\tbreak;\n\tcase VIRTIO_CONSOLE_CONSOLE_PORT:\n\t\tif (!cpkt->value)\n\t\t\tbreak;\n\t\tif (is_console_port(port))\n\t\t\tbreak;\n\n\t\tinit_port_console(port);\n\t\tcomplete(&early_console_added);\n\t\t/*\n\t\t * Could remove the port here in case init fails - but\n\t\t * have to notify the host first.\n\t\t */\n\t\tbreak;\n\tcase VIRTIO_CONSOLE_RESIZE: {\n\t\tstruct {\n\t\t\t__u16 rows;\n\t\t\t__u16 cols;\n\t\t} size;\n\n\t\tif (!is_console_port(port))\n\t\t\tbreak;\n\n\t\tmemcpy(&size, buf->buf + buf->offset + sizeof(*cpkt),\n\t\t       sizeof(size));\n\t\tset_console_size(port, size.rows, size.cols);\n\n\t\tport->cons.hvc->irq_requested = 1;\n\t\tresize_console(port);\n\t\tbreak;\n\t}\n\tcase VIRTIO_CONSOLE_PORT_OPEN:\n\t\tport->host_connected = virtio16_to_cpu(vdev, cpkt->value);\n\t\twake_up_interruptible(&port->waitqueue);\n\t\t/*\n\t\t * If the host port got closed and the host had any\n\t\t * unconsumed buffers, we'll be able to reclaim them\n\t\t * now.\n\t\t */\n\t\tspin_lock_irq(&port->outvq_lock);\n\t\treclaim_consumed_buffers(port);\n\t\tspin_unlock_irq(&port->outvq_lock);\n\n\t\t/*\n\t\t * If the guest is connected, it'll be interested in\n\t\t * knowing the host connection state changed.\n\t\t */\n\t\tspin_lock_irq(&port->inbuf_lock);\n\t\tsend_sigio_to_port(port);\n\t\tspin_unlock_irq(&port->inbuf_lock);\n\t\tbreak;\n\tcase VIRTIO_CONSOLE_PORT_NAME:\n\t\t/*\n\t\t * If we woke up after hibernation, we can get this\n\t\t * again.  Skip it in that case.\n\t\t */\n\t\tif (port->name)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Skip the size of the header and the cpkt to get the size\n\t\t * of the name that was sent\n\t\t */\n\t\tname_size = buf->len - buf->offset - sizeof(*cpkt) + 1;\n\n\t\tport->name = kmalloc(name_size, GFP_KERNEL);\n\t\tif (!port->name) {\n\t\t\tdev_err(port->dev,\n\t\t\t\t\"Not enough space to store port name\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tstrncpy(port->name, buf->buf + buf->offset + sizeof(*cpkt),\n\t\t\tname_size - 1);\n\t\tport->name[name_size - 1] = 0;\n\n\t\t/*\n\t\t * Since we only have one sysfs attribute, 'name',\n\t\t * create it only if we have a name for the port.\n\t\t */\n\t\terr = sysfs_create_group(&port->dev->kobj,\n\t\t\t\t\t &port_attribute_group);\n\t\tif (err) {\n\t\t\tdev_err(port->dev,\n\t\t\t\t\"Error %d creating sysfs device attributes\\n\",\n\t\t\t\terr);\n\t\t} else {\n\t\t\t/*\n\t\t\t * Generate a udev event so that appropriate\n\t\t\t * symlinks can be created based on udev\n\t\t\t * rules.\n\t\t\t */\n\t\t\tkobject_uevent(&port->dev->kobj, KOBJ_CHANGE);\n\t\t}\n\t\tbreak;\n\t}\n}\n\nstatic void control_work_handler(struct work_struct *work)\n{\n\tstruct ports_device *portdev;\n\tstruct virtqueue *vq;\n\tstruct port_buffer *buf;\n\tunsigned int len;\n\n\tportdev = container_of(work, struct ports_device, control_work);\n\tvq = portdev->c_ivq;\n\n\tspin_lock(&portdev->c_ivq_lock);\n\twhile ((buf = virtqueue_get_buf(vq, &len))) {\n\t\tspin_unlock(&portdev->c_ivq_lock);\n\n\t\tbuf->len = min_t(size_t, len, buf->size);\n\t\tbuf->offset = 0;\n\n\t\thandle_control_message(vq->vdev, portdev, buf);\n\n\t\tspin_lock(&portdev->c_ivq_lock);\n\t\tif (add_inbuf(portdev->c_ivq, buf) < 0) {\n\t\t\tdev_warn(&portdev->vdev->dev,\n\t\t\t\t \"Error adding buffer to queue\\n\");\n\t\t\tfree_buf(buf, false);\n\t\t}\n\t}\n\tspin_unlock(&portdev->c_ivq_lock);\n}\n\nstatic void flush_bufs(struct virtqueue *vq, bool can_sleep)\n{\n\tstruct port_buffer *buf;\n\tunsigned int len;\n\n\twhile ((buf = virtqueue_get_buf(vq, &len)))\n\t\tfree_buf(buf, can_sleep);\n}\n\nstatic void out_intr(struct virtqueue *vq)\n{\n\tstruct port *port;\n\n\tport = find_port_by_vq(vq->vdev->priv, vq);\n\tif (!port) {\n\t\tflush_bufs(vq, false);\n\t\treturn;\n\t}\n\n\twake_up_interruptible(&port->waitqueue);\n}\n\nstatic void in_intr(struct virtqueue *vq)\n{\n\tstruct port *port;\n\tunsigned long flags;\n\n\tport = find_port_by_vq(vq->vdev->priv, vq);\n\tif (!port) {\n\t\tflush_bufs(vq, false);\n\t\treturn;\n\t}\n\n\tspin_lock_irqsave(&port->inbuf_lock, flags);\n\tport->inbuf = get_inbuf(port);\n\n\t/*\n\t * Normally the port should not accept data when the port is\n\t * closed. For generic serial ports, the host won't (shouldn't)\n\t * send data till the guest is connected. But this condition\n\t * can be reached when a console port is not yet connected (no\n\t * tty is spawned) and the other side sends out data over the\n\t * vring, or when a remote devices start sending data before\n\t * the ports are opened.\n\t *\n\t * A generic serial port will discard data if not connected,\n\t * while console ports and rproc-serial ports accepts data at\n\t * any time. rproc-serial is initiated with guest_connected to\n\t * false because port_fops_open expects this. Console ports are\n\t * hooked up with an HVC console and is initialized with\n\t * guest_connected to true.\n\t */\n\n\tif (!port->guest_connected && !is_rproc_serial(port->portdev->vdev))\n\t\tdiscard_port_data(port);\n\n\t/* Send a SIGIO indicating new data in case the process asked for it */\n\tsend_sigio_to_port(port);\n\n\tspin_unlock_irqrestore(&port->inbuf_lock, flags);\n\n\twake_up_interruptible(&port->waitqueue);\n\n\tif (is_console_port(port) && hvc_poll(port->cons.hvc))\n\t\thvc_kick();\n}\n\nstatic void control_intr(struct virtqueue *vq)\n{\n\tstruct ports_device *portdev;\n\n\tportdev = vq->vdev->priv;\n\tschedule_work(&portdev->control_work);\n}\n\nstatic void config_intr(struct virtio_device *vdev)\n{\n\tstruct ports_device *portdev;\n\n\tportdev = vdev->priv;\n\n\tif (!use_multiport(portdev))\n\t\tschedule_work(&portdev->config_work);\n}\n\nstatic void config_work_handler(struct work_struct *work)\n{\n\tstruct ports_device *portdev;\n\n\tportdev = container_of(work, struct ports_device, config_work);\n\tif (!use_multiport(portdev)) {\n\t\tstruct virtio_device *vdev;\n\t\tstruct port *port;\n\t\tu16 rows, cols;\n\n\t\tvdev = portdev->vdev;\n\t\tvirtio_cread(vdev, struct virtio_console_config, cols, &cols);\n\t\tvirtio_cread(vdev, struct virtio_console_config, rows, &rows);\n\n\t\tport = find_port_by_id(portdev, 0);\n\t\tset_console_size(port, rows, cols);\n\n\t\t/*\n\t\t * We'll use this way of resizing only for legacy\n\t\t * support.  For newer userspace\n\t\t * (VIRTIO_CONSOLE_F_MULTPORT+), use control messages\n\t\t * to indicate console size changes so that it can be\n\t\t * done per-port.\n\t\t */\n\t\tresize_console(port);\n\t}\n}\n\nstatic int init_vqs(struct ports_device *portdev)\n{\n\tvq_callback_t **io_callbacks;\n\tchar **io_names;\n\tstruct virtqueue **vqs;\n\tu32 i, j, nr_ports, nr_queues;\n\tint err;\n\n\tnr_ports = portdev->max_nr_ports;\n\tnr_queues = use_multiport(portdev) ? (nr_ports + 1) * 2 : 2;\n\n\tvqs = kmalloc_array(nr_queues, sizeof(struct virtqueue *), GFP_KERNEL);\n\tio_callbacks = kmalloc_array(nr_queues, sizeof(vq_callback_t *),\n\t\t\t\t     GFP_KERNEL);\n\tio_names = kmalloc_array(nr_queues, sizeof(char *), GFP_KERNEL);\n\tportdev->in_vqs = kmalloc_array(nr_ports, sizeof(struct virtqueue *),\n\t\t\t\t\tGFP_KERNEL);\n\tportdev->out_vqs = kmalloc_array(nr_ports, sizeof(struct virtqueue *),\n\t\t\t\t\t GFP_KERNEL);\n\tif (!vqs || !io_callbacks || !io_names || !portdev->in_vqs ||\n\t    !portdev->out_vqs) {\n\t\terr = -ENOMEM;\n\t\tgoto free;\n\t}\n\n\t/*\n\t * For backward compat (newer host but older guest), the host\n\t * spawns a console port first and also inits the vqs for port\n\t * 0 before others.\n\t */\n\tj = 0;\n\tio_callbacks[j] = in_intr;\n\tio_callbacks[j + 1] = out_intr;\n\tio_names[j] = \"input\";\n\tio_names[j + 1] = \"output\";\n\tj += 2;\n\n\tif (use_multiport(portdev)) {\n\t\tio_callbacks[j] = control_intr;\n\t\tio_callbacks[j + 1] = NULL;\n\t\tio_names[j] = \"control-i\";\n\t\tio_names[j + 1] = \"control-o\";\n\n\t\tfor (i = 1; i < nr_ports; i++) {\n\t\t\tj += 2;\n\t\t\tio_callbacks[j] = in_intr;\n\t\t\tio_callbacks[j + 1] = out_intr;\n\t\t\tio_names[j] = \"input\";\n\t\t\tio_names[j + 1] = \"output\";\n\t\t}\n\t}\n\t/* Find the queues. */\n\terr = virtio_find_vqs(portdev->vdev, nr_queues, vqs,\n\t\t\t      io_callbacks,\n\t\t\t      (const char **)io_names, NULL);\n\tif (err)\n\t\tgoto free;\n\n\tj = 0;\n\tportdev->in_vqs[0] = vqs[0];\n\tportdev->out_vqs[0] = vqs[1];\n\tj += 2;\n\tif (use_multiport(portdev)) {\n\t\tportdev->c_ivq = vqs[j];\n\t\tportdev->c_ovq = vqs[j + 1];\n\n\t\tfor (i = 1; i < nr_ports; i++) {\n\t\t\tj += 2;\n\t\t\tportdev->in_vqs[i] = vqs[j];\n\t\t\tportdev->out_vqs[i] = vqs[j + 1];\n\t\t}\n\t}\n\tkfree(io_names);\n\tkfree(io_callbacks);\n\tkfree(vqs);\n\n\treturn 0;\n\nfree:\n\tkfree(portdev->out_vqs);\n\tkfree(portdev->in_vqs);\n\tkfree(io_names);\n\tkfree(io_callbacks);\n\tkfree(vqs);\n\n\treturn err;\n}\n\nstatic const struct file_operations portdev_fops = {\n\t.owner = THIS_MODULE,\n};\n\nstatic void remove_vqs(struct ports_device *portdev)\n{\n\tstruct virtqueue *vq;\n\n\tvirtio_device_for_each_vq(portdev->vdev, vq) {\n\t\tstruct port_buffer *buf;\n\n\t\tflush_bufs(vq, true);\n\t\twhile ((buf = virtqueue_detach_unused_buf(vq)))\n\t\t\tfree_buf(buf, true);\n\t}\n\tportdev->vdev->config->del_vqs(portdev->vdev);\n\tkfree(portdev->in_vqs);\n\tkfree(portdev->out_vqs);\n}\n\nstatic void virtcons_remove(struct virtio_device *vdev)\n{\n\tstruct ports_device *portdev;\n\tstruct port *port, *port2;\n\n\tportdev = vdev->priv;\n\n\tspin_lock_irq(&pdrvdata_lock);\n\tlist_del(&portdev->list);\n\tspin_unlock_irq(&pdrvdata_lock);\n\n\t/* Disable interrupts for vqs */\n\tvdev->config->reset(vdev);\n\t/* Finish up work that's lined up */\n\tif (use_multiport(portdev))\n\t\tcancel_work_sync(&portdev->control_work);\n\telse\n\t\tcancel_work_sync(&portdev->config_work);\n\n\tlist_for_each_entry_safe(port, port2, &portdev->ports, list)\n\t\tunplug_port(port);\n\n\tunregister_chrdev(portdev->chr_major, \"virtio-portsdev\");\n\n\t/*\n\t * When yanking out a device, we immediately lose the\n\t * (device-side) queues.  So there's no point in keeping the\n\t * guest side around till we drop our final reference.  This\n\t * also means that any ports which are in an open state will\n\t * have to just stop using the port, as the vqs are going\n\t * away.\n\t */\n\tremove_vqs(portdev);\n\tkfree(portdev);\n}\n\n/*\n * Once we're further in boot, we get probed like any other virtio\n * device.\n *\n * If the host also supports multiple console ports, we check the\n * config space to see how many ports the host has spawned.  We\n * initialize each port found.\n */\nstatic int virtcons_probe(struct virtio_device *vdev)\n{\n\tstruct ports_device *portdev;\n\tint err;\n\tbool multiport;\n\tbool early = early_put_chars != NULL;\n\n\t/* We only need a config space if features are offered */\n\tif (!vdev->config->get &&\n\t    (virtio_has_feature(vdev, VIRTIO_CONSOLE_F_SIZE)\n\t     || virtio_has_feature(vdev, VIRTIO_CONSOLE_F_MULTIPORT))) {\n\t\tdev_err(&vdev->dev, \"%s failure: config access disabled\\n\",\n\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Ensure to read early_put_chars now */\n\tbarrier();\n\n\tportdev = kmalloc(sizeof(*portdev), GFP_KERNEL);\n\tif (!portdev) {\n\t\terr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\t/* Attach this portdev to this virtio_device, and vice-versa. */\n\tportdev->vdev = vdev;\n\tvdev->priv = portdev;\n\n\tportdev->chr_major = register_chrdev(0, \"virtio-portsdev\",\n\t\t\t\t\t     &portdev_fops);\n\tif (portdev->chr_major < 0) {\n\t\tdev_err(&vdev->dev,\n\t\t\t\"Error %d registering chrdev for device %u\\n\",\n\t\t\tportdev->chr_major, vdev->index);\n\t\terr = portdev->chr_major;\n\t\tgoto free;\n\t}\n\n\tmultiport = false;\n\tportdev->max_nr_ports = 1;\n\n\t/* Don't test MULTIPORT at all if we're rproc: not a valid feature! */\n\tif (!is_rproc_serial(vdev) &&\n\t    virtio_cread_feature(vdev, VIRTIO_CONSOLE_F_MULTIPORT,\n\t\t\t\t struct virtio_console_config, max_nr_ports,\n\t\t\t\t &portdev->max_nr_ports) == 0) {\n\t\tmultiport = true;\n\t}\n\n\terr = init_vqs(portdev);\n\tif (err < 0) {\n\t\tdev_err(&vdev->dev, \"Error %d initializing vqs\\n\", err);\n\t\tgoto free_chrdev;\n\t}\n\n\tspin_lock_init(&portdev->ports_lock);\n\tINIT_LIST_HEAD(&portdev->ports);\n\tINIT_LIST_HEAD(&portdev->list);\n\n\tvirtio_device_ready(portdev->vdev);\n\n\tINIT_WORK(&portdev->config_work, &config_work_handler);\n\tINIT_WORK(&portdev->control_work, &control_work_handler);\n\n\tif (multiport) {\n\t\tspin_lock_init(&portdev->c_ivq_lock);\n\t\tspin_lock_init(&portdev->c_ovq_lock);\n\n\t\terr = fill_queue(portdev->c_ivq, &portdev->c_ivq_lock);\n\t\tif (err < 0) {\n\t\t\tdev_err(&vdev->dev,\n\t\t\t\t\"Error allocating buffers for control queue\\n\");\n\t\t\t/*\n\t\t\t * The host might want to notify mgmt sw about device\n\t\t\t * add failure.\n\t\t\t */\n\t\t\t__send_control_msg(portdev, VIRTIO_CONSOLE_BAD_ID,\n\t\t\t\t\t   VIRTIO_CONSOLE_DEVICE_READY, 0);\n\t\t\t/* Device was functional: we need full cleanup. */\n\t\t\tvirtcons_remove(vdev);\n\t\t\treturn err;\n\t\t}\n\t} else {\n\t\t/*\n\t\t * For backward compatibility: Create a console port\n\t\t * if we're running on older host.\n\t\t */\n\t\tadd_port(portdev, 0);\n\t}\n\n\tspin_lock_irq(&pdrvdata_lock);\n\tlist_add_tail(&portdev->list, &pdrvdata.portdevs);\n\tspin_unlock_irq(&pdrvdata_lock);\n\n\t__send_control_msg(portdev, VIRTIO_CONSOLE_BAD_ID,\n\t\t\t   VIRTIO_CONSOLE_DEVICE_READY, 1);\n\n\t/*\n\t * If there was an early virtio console, assume that there are no\n\t * other consoles. We need to wait until the hvc_alloc matches the\n\t * hvc_instantiate, otherwise tty_open will complain, resulting in\n\t * a \"Warning: unable to open an initial console\" boot failure.\n\t * Without multiport this is done in add_port above. With multiport\n\t * this might take some host<->guest communication - thus we have to\n\t * wait.\n\t */\n\tif (multiport && early)\n\t\twait_for_completion(&early_console_added);\n\n\treturn 0;\n\nfree_chrdev:\n\tunregister_chrdev(portdev->chr_major, \"virtio-portsdev\");\nfree:\n\tkfree(portdev);\nfail:\n\treturn err;\n}\n\nstatic const struct virtio_device_id id_table[] = {\n\t{ VIRTIO_ID_CONSOLE, VIRTIO_DEV_ANY_ID },\n\t{ 0 },\n};\nMODULE_DEVICE_TABLE(virtio, id_table);\n\nstatic const unsigned int features[] = {\n\tVIRTIO_CONSOLE_F_SIZE,\n\tVIRTIO_CONSOLE_F_MULTIPORT,\n};\n\nstatic const struct virtio_device_id rproc_serial_id_table[] = {\n#if IS_ENABLED(CONFIG_REMOTEPROC)\n\t{ VIRTIO_ID_RPROC_SERIAL, VIRTIO_DEV_ANY_ID },\n#endif\n\t{ 0 },\n};\nMODULE_DEVICE_TABLE(virtio, rproc_serial_id_table);\n\nstatic const unsigned int rproc_serial_features[] = {\n};\n\n#ifdef CONFIG_PM_SLEEP\nstatic int virtcons_freeze(struct virtio_device *vdev)\n{\n\tstruct ports_device *portdev;\n\tstruct port *port;\n\n\tportdev = vdev->priv;\n\n\tvdev->config->reset(vdev);\n\n\tif (use_multiport(portdev))\n\t\tvirtqueue_disable_cb(portdev->c_ivq);\n\tcancel_work_sync(&portdev->control_work);\n\tcancel_work_sync(&portdev->config_work);\n\t/*\n\t * Once more: if control_work_handler() was running, it would\n\t * enable the cb as the last step.\n\t */\n\tif (use_multiport(portdev))\n\t\tvirtqueue_disable_cb(portdev->c_ivq);\n\n\tlist_for_each_entry(port, &portdev->ports, list) {\n\t\tvirtqueue_disable_cb(port->in_vq);\n\t\tvirtqueue_disable_cb(port->out_vq);\n\t\t/*\n\t\t * We'll ask the host later if the new invocation has\n\t\t * the port opened or closed.\n\t\t */\n\t\tport->host_connected = false;\n\t\tremove_port_data(port);\n\t}\n\tremove_vqs(portdev);\n\n\treturn 0;\n}\n\nstatic int virtcons_restore(struct virtio_device *vdev)\n{\n\tstruct ports_device *portdev;\n\tstruct port *port;\n\tint ret;\n\n\tportdev = vdev->priv;\n\n\tret = init_vqs(portdev);\n\tif (ret)\n\t\treturn ret;\n\n\tvirtio_device_ready(portdev->vdev);\n\n\tif (use_multiport(portdev))\n\t\tfill_queue(portdev->c_ivq, &portdev->c_ivq_lock);\n\n\tlist_for_each_entry(port, &portdev->ports, list) {\n\t\tport->in_vq = portdev->in_vqs[port->id];\n\t\tport->out_vq = portdev->out_vqs[port->id];\n\n\t\tfill_queue(port->in_vq, &port->inbuf_lock);\n\n\t\t/* Get port open/close status on the host */\n\t\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_READY, 1);\n\n\t\t/*\n\t\t * If a port was open at the time of suspending, we\n\t\t * have to let the host know that it's still open.\n\t\t */\n\t\tif (port->guest_connected)\n\t\t\tsend_control_msg(port, VIRTIO_CONSOLE_PORT_OPEN, 1);\n\t}\n\treturn 0;\n}\n#endif\n\nstatic struct virtio_driver virtio_console = {\n\t.feature_table = features,\n\t.feature_table_size = ARRAY_SIZE(features),\n\t.driver.name =\tKBUILD_MODNAME,\n\t.driver.owner =\tTHIS_MODULE,\n\t.id_table =\tid_table,\n\t.probe =\tvirtcons_probe,\n\t.remove =\tvirtcons_remove,\n\t.config_changed = config_intr,\n#ifdef CONFIG_PM_SLEEP\n\t.freeze =\tvirtcons_freeze,\n\t.restore =\tvirtcons_restore,\n#endif\n};\n\nstatic struct virtio_driver virtio_rproc_serial = {\n\t.feature_table = rproc_serial_features,\n\t.feature_table_size = ARRAY_SIZE(rproc_serial_features),\n\t.driver.name =\t\"virtio_rproc_serial\",\n\t.driver.owner =\tTHIS_MODULE,\n\t.id_table =\trproc_serial_id_table,\n\t.probe =\tvirtcons_probe,\n\t.remove =\tvirtcons_remove,\n};\n\nstatic int __init init(void)\n{\n\tint err;\n\n\tpdrvdata.class = class_create(THIS_MODULE, \"virtio-ports\");\n\tif (IS_ERR(pdrvdata.class)) {\n\t\terr = PTR_ERR(pdrvdata.class);\n\t\tpr_err(\"Error %d creating virtio-ports class\\n\", err);\n\t\treturn err;\n\t}\n\n\tpdrvdata.debugfs_dir = debugfs_create_dir(\"virtio-ports\", NULL);\n\tINIT_LIST_HEAD(&pdrvdata.consoles);\n\tINIT_LIST_HEAD(&pdrvdata.portdevs);\n\n\terr = register_virtio_driver(&virtio_console);\n\tif (err < 0) {\n\t\tpr_err(\"Error %d registering virtio driver\\n\", err);\n\t\tgoto free;\n\t}\n\terr = register_virtio_driver(&virtio_rproc_serial);\n\tif (err < 0) {\n\t\tpr_err(\"Error %d registering virtio rproc serial driver\\n\",\n\t\t       err);\n\t\tgoto unregister;\n\t}\n\treturn 0;\nunregister:\n\tunregister_virtio_driver(&virtio_console);\nfree:\n\tdebugfs_remove_recursive(pdrvdata.debugfs_dir);\n\tclass_destroy(pdrvdata.class);\n\treturn err;\n}\n\nstatic void __exit fini(void)\n{\n\treclaim_dma_bufs();\n\n\tunregister_virtio_driver(&virtio_console);\n\tunregister_virtio_driver(&virtio_rproc_serial);\n\n\tclass_destroy(pdrvdata.class);\n\tdebugfs_remove_recursive(pdrvdata.debugfs_dir);\n}\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_DESCRIPTION(\"Virtio console driver\");\nMODULE_LICENSE(\"GPL\");\n"], "filenames": ["drivers/char/virtio_console.c"], "buggy_code_start_loc": [478], "buggy_code_end_loc": [1713], "fixing_code_start_loc": [478], "fixing_code_end_loc": [1713], "type": "CWE-120", "message": "** DISPUTED ** In drivers/char/virtio_console.c in the Linux kernel before 5.13.4, data corruption or loss can be triggered by an untrusted device that supplies a buf->len value exceeding the buffer size. NOTE: the vendor indicates that the cited data corruption is not a vulnerability in any existing use case; the length validation was added solely for robustness in the face of anomalous host OS behavior.", "other": {"cve": {"id": "CVE-2021-38160", "sourceIdentifier": "cve@mitre.org", "published": "2021-08-07T04:15:06.967", "lastModified": "2022-01-01T17:58:24.493", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "** DISPUTED ** In drivers/char/virtio_console.c in the Linux kernel before 5.13.4, data corruption or loss can be triggered by an untrusted device that supplies a buf->len value exceeding the buffer size. NOTE: the vendor indicates that the cited data corruption is not a vulnerability in any existing use case; the length validation was added solely for robustness in the face of anomalous host OS behavior."}, {"lang": "es", "value": "** EN DISPUTA ** En el archivo drivers/char/virtio_console.c en el kernel de Linux versiones anteriores a 5.13.4, la corrupci\u00f3n o p\u00e9rdida de datos puede ser desencadenada por un dispositivo no fiable que suministre un valor buf-)len excediendo el tama\u00f1o del buffer. NOTA: El proveedor indica que la citada corrupci\u00f3n de datos no es una vulnerabilidad en ning\u00fan caso de uso existente; la validaci\u00f3n de la longitud se a\u00f1adi\u00f3 \u00fanicamente para la robustez frente a un comportamiento an\u00f3malo del sistema operativo anfitri\u00f3n."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:C/I:C/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 7.2}, "baseSeverity": "HIGH", "exploitabilityScore": 3.9, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-120"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "5.13.4", "matchCriteriaId": "4C85356F-2C6C-4FB9-B0CA-949711182223"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:hci_bootstrap_os:-:*:*:*:*:*:*:*", "matchCriteriaId": "1C767AA1-88B7-48F0-9F31-A89D16DCD52C"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:hci_compute_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "AD7447BC-F315-4298-A822-549942FC118B"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:netapp:hci_management_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "A3C19813-E823-456A-B1CE-EC0684CE1953"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:solidfire:-:*:*:*:*:*:*:*", "matchCriteriaId": "A6E9EF0C-AFA8-4F7B-9FDC-1E0F7C26E737"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:netapp:element_software:-:*:*:*:*:*:*:*", "matchCriteriaId": "85DF4B3F-4BBC-42B7-B729-096934523D63"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:hci_storage_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "02DEB4FB-A21D-4CB1-B522-EEE5093E8521"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:10.0:*:*:*:*:*:*:*", "matchCriteriaId": "07B237A9-69A3-4A9C-9DA0-4E06BD37AE73"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "F4CFF558-3C47-480D-A2F0-BABF26042943"}]}]}], "references": [{"url": "https://access.redhat.com/security/cve/cve-2021-38160", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://cdn.kernel.org/pub/linux/kernel/v5.x/ChangeLog-5.13.4", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/d00d8da5869a2608e97cfede094dfc5e11462a46", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2021/10/msg00010.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2021/12/msg00012.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20210902-0010/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.debian.org/security/2021/dsa-4978", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/d00d8da5869a2608e97cfede094dfc5e11462a46"}}
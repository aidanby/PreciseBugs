{"buggy_code": ["/*\n *  Copyright (c) 2015-present, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n *\n */\n#include <proxygen/lib/http/session/HTTPSession.h>\n\n#include <chrono>\n#include <fizz/protocol/AsyncFizzBase.h>\n#include <folly/Conv.h>\n#include <folly/CppAttributes.h>\n#include <folly/Random.h>\n#include <wangle/acceptor/ConnectionManager.h>\n#include <wangle/acceptor/SocketOptions.h>\n#include <proxygen/lib/http/HTTPHeaderSize.h>\n#include <proxygen/lib/http/codec/HTTPChecks.h>\n#include <proxygen/lib/http/codec/HTTP2Codec.h>\n#include <proxygen/lib/http/session/HTTPSessionController.h>\n#include <proxygen/lib/http/session/HTTPSessionStats.h>\n#include <folly/io/async/AsyncSSLSocket.h>\n#include <folly/io/Cursor.h>\n#include <folly/tracing/ScopedTraceSection.h>\n\nusing fizz::AsyncFizzBase;\nusing folly::AsyncSSLSocket;\nusing folly::AsyncSocket;\nusing folly::AsyncTransportWrapper;\nusing folly::AsyncTransport;\nusing folly::WriteFlags;\nusing folly::AsyncSocketException;\nusing folly::io::QueueAppender;\nusing folly::IOBuf;\nusing folly::IOBufQueue;\nusing folly::SocketAddress;\nusing wangle::TransportInfo;\nusing std::make_unique;\nusing std::pair;\nusing std::set;\nusing std::string;\nusing std::unique_ptr;\nusing std::vector;\n\nnamespace {\nstatic const uint32_t kMinReadSize = 1460;\nstatic const uint32_t kWriteReadyMax = 65536;\n\n// Lower = higher latency, better prioritization\n// Higher = lower latency, less prioritization\nstatic const uint32_t kMaxWritesPerLoop = 32;\n\nstatic constexpr folly::StringPiece kClientLabel =\n    \"EXPORTER HTTP CERTIFICATE client\";\nstatic constexpr folly::StringPiece kServerLabel =\n    \"EXPORTER HTTP CERTIFICATE server\";\n} // anonymous namespace\n\nnamespace proxygen {\n\nHTTPSession::WriteSegment::WriteSegment(\n    HTTPSession* session,\n    uint64_t length)\n  : session_(session),\n    length_(length) {\n}\n\nvoid\nHTTPSession::WriteSegment::remove() {\n  DCHECK(session_);\n  DCHECK(listHook.is_linked());\n  listHook.unlink();\n}\n\nvoid\nHTTPSession::WriteSegment::detach() {\n  remove();\n  session_ = nullptr;\n}\n\nvoid\nHTTPSession::WriteSegment::writeSuccess() noexcept {\n  // Unlink this write segment from the list before calling\n  // the session's onWriteSuccess() callback because, in the\n  // case where this is the last write for the connection,\n  // onWriteSuccess() looks for an empty write segment list\n  // as one of the criteria for shutting down the connection.\n  remove();\n\n  // session_ should never be nullptr for a successful write\n  // The session is only cleared after a write error or timeout, and all\n  // AsyncTransport write failures are fatal.  If session_ is nullptr at this\n  // point it means the AsyncTransport implementation is not failing\n  // subsequent writes correctly after an error.\n  session_->onWriteSuccess(length_);\n  delete this;\n}\n\nvoid\nHTTPSession::WriteSegment::writeErr(size_t bytesWritten,\n                                    const AsyncSocketException& ex) noexcept {\n  // After one segment fails to write, we clear the session_\n  // pointer in all subsequent write segments, so we ignore their\n  // writeError() callbacks.\n  if (session_) {\n    remove();\n    session_->onWriteError(bytesWritten, ex);\n  }\n  delete this;\n}\n\nHTTPSession::HTTPSession(\n  folly::HHWheelTimer* transactionTimeouts,\n  AsyncTransportWrapper::UniquePtr sock,\n  const SocketAddress& localAddr,\n  const SocketAddress& peerAddr,\n  HTTPSessionController* controller,\n  unique_ptr<HTTPCodec> codec,\n  const TransportInfo& tinfo,\n  InfoCallback* infoCallback):\n    HTTPSession(WheelTimerInstance(transactionTimeouts), std::move(sock),\n        localAddr, peerAddr, controller, std::move(codec),\n        tinfo, infoCallback) {\n}\n\nHTTPSession::HTTPSession(\n  const WheelTimerInstance& timeout,\n  AsyncTransportWrapper::UniquePtr sock,\n  const SocketAddress& localAddr,\n  const SocketAddress& peerAddr,\n  HTTPSessionController* controller,\n  unique_ptr<HTTPCodec> codec,\n  const TransportInfo& tinfo,\n  InfoCallback* infoCallback):\n    HTTPSessionBase(localAddr, peerAddr, controller, tinfo, infoCallback,\n                    std::move(codec)),\n    writeTimeout_(this),\n    txnEgressQueue_(isHTTP2CodecProtocol(codec_->getProtocol()) ?\n                    WheelTimerInstance(timeout) :\n                    WheelTimerInstance()),\n    sock_(std::move(sock)),\n    timeout_(timeout),\n    draining_(false),\n    started_(false),\n    writesDraining_(false),\n    resetAfterDrainingWrites_(false),\n    ingressError_(false),\n    flowControlTimeout_(this),\n    drainTimeout_(this),\n    reads_(SocketState::PAUSED),\n    writes_(SocketState::UNPAUSED),\n    ingressUpgraded_(false),\n    resetSocketOnShutdown_(false),\n    inLoopCallback_(false),\n    inResume_(false),\n    pendingPause_(false) {\n  byteEventTracker_ = std::make_shared<ByteEventTracker>(this);\n  initialReceiveWindow_ = receiveStreamWindowSize_ =\n    receiveSessionWindowSize_ = codec_->getDefaultWindowSize();\n\n  codec_.add<HTTPChecks>();\n\n  setupCodec();\n\n  nextEgressResults_.reserve(maxConcurrentIncomingStreams_);\n\n  if (infoCallback_) {\n    infoCallback_->onCreate(*this);\n  }\n\n  auto controllerPtr = getController();\n  if (controllerPtr) {\n    flowControlTimeout_.setTimeoutDuration(\n      controllerPtr->getSessionFlowControlTimeout());\n  }\n  attachToSessionController();\n\n  if (!sock_->isReplaySafe()) {\n    sock_->setReplaySafetyCallback(this);\n  }\n}\n\nuint32_t HTTPSession::getCertAuthSettingVal() {\n  uint32_t certAuthSettingVal = 0;\n  constexpr uint16_t settingLen = 4;\n  std::unique_ptr<folly::IOBuf> ekm;\n  folly::StringPiece label;\n  if (isUpstream()) {\n    label = kClientLabel;\n  } else {\n    label = kServerLabel;\n  }\n  auto fizzBase = getTransport()->getUnderlyingTransport<AsyncFizzBase>();\n  if (fizzBase) {\n    ekm = fizzBase->getEkm(label, nullptr, settingLen);\n  } else {\n    VLOG(4) << \"Underlying transport does not support secondary \"\n               \"authentication.\";\n    return certAuthSettingVal;\n  }\n  if (ekm && ekm->computeChainDataLength() == settingLen) {\n    folly::io::Cursor cursor(ekm.get());\n    uint32_t ekmVal = cursor.readBE<uint32_t>();\n    certAuthSettingVal = (ekmVal & 0x3fffffff) | 0x80000000;\n  }\n  return certAuthSettingVal;\n}\n\nbool HTTPSession::verifyCertAuthSetting(uint32_t value) {\n  uint32_t certAuthSettingVal = 0;\n  constexpr uint16_t settingLen = 4;\n  std::unique_ptr<folly::IOBuf> ekm;\n  folly::StringPiece label;\n  if (isUpstream()) {\n    label = kServerLabel;\n  } else {\n    label = kClientLabel;\n  }\n  auto fizzBase = getTransport()->getUnderlyingTransport<AsyncFizzBase>();\n  if (fizzBase) {\n    ekm = fizzBase->getEkm(label, nullptr, settingLen);\n  } else {\n    VLOG(4) << \"Underlying transport does not support secondary \"\n               \"authentication.\";\n    return false;\n  }\n  if (ekm && ekm->computeChainDataLength() == settingLen) {\n    folly::io::Cursor cursor(ekm.get());\n    uint32_t ekmVal = cursor.readBE<uint32_t>();\n    certAuthSettingVal = (ekmVal & 0x3fffffff) | 0x80000000;\n  } else {\n    return false;\n  }\n  if (certAuthSettingVal == value) {\n    return true;\n  } else {\n    return false;\n  }\n}\n\nvoid HTTPSession::setupCodec() {\n  if (!codec_->supportsParallelRequests()) {\n    // until we support upstream pipelining\n    maxConcurrentIncomingStreams_ = 1;\n    maxConcurrentOutgoingStreamsRemote_ = isDownstream() ? 0 : 1;\n  }\n\n  // If a secondary authentication manager is configured for this session, set\n  // the SETTINGS_HTTP_CERT_AUTH to indicate support for HTTP-layer certificate\n  // authentication.\n  uint32_t certAuthSettingVal = 0;\n  if (secondAuthManager_) {\n    certAuthSettingVal = getCertAuthSettingVal();\n  }\n  HTTPSettings* settings = codec_->getEgressSettings();\n  if (settings) {\n    settings->setSetting(SettingsId::MAX_CONCURRENT_STREAMS,\n                         maxConcurrentIncomingStreams_);\n    if (certAuthSettingVal != 0) {\n      settings->setSetting(SettingsId::SETTINGS_HTTP_CERT_AUTH,\n                           certAuthSettingVal);\n    }\n  }\n  codec_->generateConnectionPreface(writeBuf_);\n\n  if (codec_->supportsSessionFlowControl() && !connFlowControl_) {\n    connFlowControl_ = new FlowControlFilter(*this, writeBuf_, codec_.call());\n    codec_.addFilters(std::unique_ptr<FlowControlFilter>(connFlowControl_));\n    // if we really support switching from spdy <-> h2, we need to update\n    // existing flow control filter\n  }\n\n  codec_.setCallback(this);\n}\n\nHTTPSession::~HTTPSession() {\n  VLOG(4) << *this << \" closing\";\n\n  CHECK(transactions_.empty());\n  txnEgressQueue_.dropPriorityNodes();\n  CHECK(txnEgressQueue_.empty());\n  DCHECK(!sock_->getReadCallback());\n\n  if (writeTimeout_.isScheduled()) {\n    writeTimeout_.cancelTimeout();\n  }\n\n  if (flowControlTimeout_.isScheduled()) {\n    flowControlTimeout_.cancelTimeout();\n  }\n\n  runDestroyCallbacks();\n}\n\nvoid HTTPSession::startNow() {\n  CHECK(!started_);\n  started_ = true;\n  codec_->generateSettings(writeBuf_);\n  if (connFlowControl_) {\n    connFlowControl_->setReceiveWindowSize(writeBuf_,\n                                           receiveSessionWindowSize_);\n  }\n  // For HTTP/2 if we are currently draining it means we got notified to\n  // shutdown before we sent a SETTINGS frame, so we defer sending a GOAWAY\n  // util we've started and sent SETTINGS.\n  if (draining_) {\n    codec_->generateGoaway(writeBuf_,\n                           getGracefulGoawayAck(),\n                           ErrorCode::NO_ERROR);\n  }\n  scheduleWrite();\n  resumeReads();\n}\n\nvoid HTTPSession::setByteEventTracker(\n  std::shared_ptr<ByteEventTracker> byteEventTracker) {\n  if (byteEventTracker && byteEventTracker_) {\n    byteEventTracker->absorb(std::move(*byteEventTracker_));\n  }\n  byteEventTracker_ = byteEventTracker;\n  if (byteEventTracker_) {\n    byteEventTracker_->setCallback(this);\n    byteEventTracker_->setTTLBAStats(sessionStats_);\n  }\n}\n\nvoid HTTPSession::setSessionStats(HTTPSessionStats* stats) {\n  HTTPSessionBase::setSessionStats(stats);\n  if (byteEventTracker_) {\n    byteEventTracker_->setTTLBAStats(stats);\n  }\n}\n\nvoid HTTPSession::setFlowControl(size_t initialReceiveWindow,\n                                 size_t receiveStreamWindowSize,\n                                 size_t receiveSessionWindowSize) {\n  CHECK(!started_);\n  initialReceiveWindow_ = initialReceiveWindow;\n  receiveStreamWindowSize_ = receiveStreamWindowSize;\n  receiveSessionWindowSize_ = receiveSessionWindowSize;\n  HTTPSessionBase::setReadBufferLimit(receiveSessionWindowSize);\n  HTTPSettings* settings = codec_->getEgressSettings();\n  if (settings) {\n    settings->setSetting(SettingsId::INITIAL_WINDOW_SIZE,\n                         initialReceiveWindow_);\n  }\n}\n\nvoid HTTPSession::setEgressSettings(const SettingsList& inSettings) {\n  VLOG_IF(4, started_) << \"Must flush egress settings to peer\";\n  HTTPSettings* settings = codec_->getEgressSettings();\n  if (settings) {\n    for (const auto& setting: inSettings) {\n      settings->setSetting(setting.id, setting.value);\n    }\n  }\n}\n\nvoid HTTPSession::setMaxConcurrentIncomingStreams(uint32_t num) {\n  CHECK(!started_);\n  if (codec_->supportsParallelRequests()) {\n    maxConcurrentIncomingStreams_ = num;\n    HTTPSettings* settings = codec_->getEgressSettings();\n    if (settings) {\n      settings->setSetting(SettingsId::MAX_CONCURRENT_STREAMS,\n                           maxConcurrentIncomingStreams_);\n    }\n  }\n}\n\nvoid HTTPSession::setEgressBytesLimit(uint64_t bytesLimit) {\n  CHECK(!started_);\n  egressBytesLimit_ = bytesLimit;\n}\n\nvoid\nHTTPSession::readTimeoutExpired() noexcept {\n  VLOG(3) << \"session-level timeout on \" << *this;\n\n  if (liveTransactions_ != 0) {\n    // There's at least one open transaction with a read timeout scheduled.\n    // We got here because the session timeout == the transaction timeout.\n    // Ignore, since the transaction is going to timeout very soon.\n    VLOG(4) << *this <<\n        \"ignoring session timeout, transaction timeout imminent\";\n    resetTimeout();\n    return;\n  }\n\n  if (!transactions_.empty()) {\n    // There are one or more transactions, but none of them are live.\n    // That's valid if they've all received their full ingress messages\n    // and are waiting for their Handlers to process those messages.\n    VLOG(4) << *this <<\n        \"ignoring session timeout, no transactions awaiting reads\";\n    resetTimeout();\n    return;\n  }\n\n  VLOG(4) << *this << \" Timeout with nothing pending\";\n\n  setCloseReason(ConnectionCloseReason::TIMEOUT);\n  auto controller = getController();\n  if (controller) {\n    timeout_.scheduleTimeout(&drainTimeout_,\n                             controller->getGracefulShutdownTimeout());\n  }\n  notifyPendingShutdown();\n}\n\nvoid\nHTTPSession::writeTimeoutExpired() noexcept {\n  VLOG(4) << \"Write timeout for \" << *this;\n\n  CHECK(!pendingWrites_.empty());\n  DestructorGuard g(this);\n\n  setCloseReason(ConnectionCloseReason::TIMEOUT);\n  shutdownTransportWithReset(kErrorWriteTimeout);\n}\n\nvoid\nHTTPSession::flowControlTimeoutExpired() noexcept {\n  VLOG(4) << \"Flow control timeout for \" << *this;\n\n  DestructorGuard g(this);\n\n  setCloseReason(ConnectionCloseReason::TIMEOUT);\n  shutdownTransport(true, true);\n}\n\nvoid\nHTTPSession::describe(std::ostream& os) const {\n  os << \"proto=\" << getCodecProtocolString(codec_->getProtocol());\n  if (isDownstream()) {\n    os << \", UA=\" << codec_->getUserAgent()\n       << \", downstream=\" << getPeerAddress() << \", \" << getLocalAddress()\n       << \"=local\";\n  } else {\n    os << \", local=\" << getLocalAddress() << \", \" << getPeerAddress()\n       << \"=upstream\";\n  }\n}\n\nbool\nHTTPSession::isBusy() const {\n  return !transactions_.empty() || codec_->isBusy();\n}\n\nvoid\nHTTPSession::notifyPendingEgress() noexcept {\n  scheduleWrite();\n}\n\nvoid\nHTTPSession::notifyPendingShutdown() {\n  VLOG(4) << *this << \" notified pending shutdown\";\n  drain();\n}\n\nvoid\nHTTPSession::closeWhenIdle() {\n  // If drain() already called, this is a noop\n  drain();\n  // Generate the second GOAWAY now. No-op if second GOAWAY already sent.\n  if (codec_->generateGoaway(writeBuf_,\n                             codec_->getLastIncomingStreamID(),\n                             ErrorCode::NO_ERROR)) {\n    scheduleWrite();\n  }\n  if (!isBusy() && !hasMoreWrites()) {\n    // if we're already idle, close now\n    dropConnection();\n  }\n}\n\nvoid HTTPSession::immediateShutdown() {\n  if (isLoopCallbackScheduled()) {\n    cancelLoopCallback();\n  }\n  if (shutdownTransportCb_) {\n    shutdownTransportCb_.reset();\n  }\n  // checkForShutdown only closes the connection if these conditions are true\n  DCHECK(writesShutdown());\n  DCHECK(transactions_.empty());\n  checkForShutdown();\n}\n\nvoid\nHTTPSession::dropConnection() {\n  VLOG(4) << \"dropping \" << *this;\n  if (!sock_ || (readsShutdown() && writesShutdown())) {\n    VLOG(4) << *this << \" already shutdown\";\n    return;\n  }\n\n  setCloseReason(ConnectionCloseReason::SHUTDOWN);\n  if (transactions_.empty() && !hasMoreWrites()) {\n    DestructorGuard dg(this);\n    shutdownTransport(true, true);\n    // shutdownTransport might have generated a write (goaway)\n    // If so, writes will not be shutdown, so fall through to\n    // shutdownTransportWithReset.\n    if (readsShutdown() && writesShutdown()) {\n      immediateShutdown();\n      return;\n    }\n  }\n  shutdownTransportWithReset(kErrorDropped);\n}\n\nvoid HTTPSession::dumpConnectionState(uint8_t /*loglevel*/) {}\n\nbool HTTPSession::isUpstream() const {\n  return codec_->getTransportDirection() == TransportDirection::UPSTREAM;\n}\n\nbool HTTPSession::isDownstream() const {\n  return codec_->getTransportDirection() == TransportDirection::DOWNSTREAM;\n}\n\nvoid\nHTTPSession::getReadBuffer(void** buf, size_t* bufSize) {\n  FOLLY_SCOPED_TRACE_SECTION(\"HTTPSession - getReadBuffer\");\n  pair<void*,uint32_t> readSpace =\n    readBuf_.preallocate(kMinReadSize, HTTPSessionBase::maxReadBufferSize_);\n  *buf = readSpace.first;\n  *bufSize = readSpace.second;\n}\n\nvoid\nHTTPSession::readDataAvailable(size_t readSize) noexcept {\n  FOLLY_SCOPED_TRACE_SECTION(\n      \"HTTPSession - readDataAvailable\", \"readSize\", readSize);\n  VLOG(10) << \"read completed on \" << *this << \", bytes=\" << readSize;\n\n  DestructorGuard dg(this);\n  resetTimeout();\n  readBuf_.postallocate(readSize);\n\n  if (infoCallback_) {\n    infoCallback_->onRead(*this, readSize);\n  }\n\n  processReadData();\n}\n\nbool\nHTTPSession::isBufferMovable() noexcept {\n  return true;\n}\n\nvoid\nHTTPSession::readBufferAvailable(std::unique_ptr<IOBuf> readBuf) noexcept {\n  size_t readSize = readBuf->computeChainDataLength();\n  FOLLY_SCOPED_TRACE_SECTION(\n      \"HTTPSession - readBufferAvailable\", \"readSize\", readSize);\n  VLOG(5) << \"read completed on \" << *this << \", bytes=\" << readSize;\n\n  DestructorGuard dg(this);\n  resetTimeout();\n  readBuf_.append(std::move(readBuf));\n\n  if (infoCallback_) {\n    infoCallback_->onRead(*this, readSize);\n  }\n\n  processReadData();\n}\n\nvoid\nHTTPSession::processReadData() {\n  FOLLY_SCOPED_TRACE_SECTION(\"HTTPSession - processReadData\");\n  // skip any empty IOBufs before feeding CODEC.\n  while (readBuf_.front() != nullptr && readBuf_.front()->length() == 0) {\n    readBuf_.pop_front();\n  }\n\n  // Pass the ingress data through the codec to parse it. The codec\n  // will invoke various methods of the HTTPSession as callbacks.\n  const IOBuf* currentReadBuf;\n  // It's possible for the last buffer in a chain to be empty here.\n  // AsyncTransport saw fd activity so asked for a read buffer, but it was\n  // SSL traffic and not enough to decrypt a whole record.  Later we invoke\n  // this function from the loop callback.\n  while (!ingressError_ &&\n         readsUnpaused() &&\n         ((currentReadBuf = readBuf_.front()) != nullptr &&\n          currentReadBuf->length() != 0)) {\n    // We're about to parse, make sure the parser is not paused\n    codec_->setParserPaused(false);\n    size_t bytesParsed = codec_->onIngress(*currentReadBuf);\n    if (bytesParsed == 0) {\n      // If the codec didn't make any progress with current input, we\n      // better get more.\n      break;\n    }\n    readBuf_.trimStart(bytesParsed);\n  }\n}\n\nvoid\nHTTPSession::readEOF() noexcept {\n  DestructorGuard guard(this);\n  VLOG(4) << \"EOF on \" << *this;\n  // for SSL only: error without any bytes from the client might happen\n  // due to client-side issues with the SSL cert. Note that it can also\n  // happen if the client sends a SPDY frame header but no body.\n  if (infoCallback_\n      && transportInfo_.secure && getNumTxnServed() == 0 && readBuf_.empty()) {\n    infoCallback_->onIngressError(*this, kErrorClientSilent);\n  }\n\n  // Shut down reads, and also shut down writes if there are no\n  // transactions.  (If there are active transactions, leave the\n  // write side of the socket open so those transactions can\n  // finish generating responses.)\n  setCloseReason(ConnectionCloseReason::READ_EOF);\n  shutdownTransport(true, transactions_.empty());\n}\n\nvoid\nHTTPSession::readErr(const AsyncSocketException& ex) noexcept {\n  DestructorGuard guard(this);\n  VLOG(4) << \"read error on \" << *this << \": \" << ex.what();\n\n  auto sslEx = dynamic_cast<const folly::SSLException*>(&ex);\n  if (infoCallback_ && sslEx) {\n    if (sslEx->getSSLError() == folly::SSLError::CLIENT_RENEGOTIATION) {\n      infoCallback_->onIngressError(*this, kErrorClientRenegotiation);\n    }\n  }\n\n  // We're definitely finished reading. Don't close the write side\n  // of the socket if there are outstanding transactions, though.\n  // Instead, give the transactions a chance to produce any remaining\n  // output.\n  if (sslEx && sslEx->getSSLError() == folly::SSLError::SSL_ERROR) {\n    transportInfo_.sslError = ex.what();\n  }\n  setCloseReason(ConnectionCloseReason::IO_READ_ERROR);\n  shutdownTransport(true, transactions_.empty(), ex.what());\n}\n\nHTTPTransaction*\nHTTPSession::newPushedTransaction(\n  HTTPCodec::StreamID assocStreamId,\n  HTTPTransaction::PushHandler* handler) noexcept {\n  if (!codec_->supportsPushTransactions()) {\n    return nullptr;\n  }\n  CHECK(isDownstream());\n  CHECK_NOTNULL(handler);\n  if (draining_ || (outgoingStreams_ >= maxConcurrentOutgoingStreamsRemote_)) {\n    // This session doesn't support any more push transactions\n    // This could be an actual problem - since a single downstream SPDY session\n    // might be connected to N upstream hosts, each of which send M pushes,\n    // which exceeds the limit.\n    // should we queue?\n    return nullptr;\n  }\n\n  HTTPTransaction* txn = createTransaction(codec_->createStream(),\n                                           assocStreamId,\n                                           HTTPCodec::NoExAttributes);\n  if (!txn) {\n    return nullptr;\n  }\n\n  DestructorGuard dg(this);\n  auto txnID = txn->getID();\n  txn->setHandler(handler);\n  setNewTransactionPauseState(txnID);\n  return txn;\n}\n\nHTTPTransaction* FOLLY_NULLABLE\nHTTPSession::newExTransaction(\n    HTTPTransaction::Handler* handler,\n    HTTPCodec::StreamID controlStream,\n    bool unidirectional) noexcept {\n  CHECK(handler && controlStream > 0);\n  auto eSettings = codec_->getEgressSettings();\n  if (!eSettings || !eSettings->getSetting(SettingsId::ENABLE_EX_HEADERS, 0)) {\n    LOG(ERROR) << getCodecProtocolString(codec_->getProtocol())\n               << \" does not support ExTransaction\";\n    return nullptr;\n  }\n  if (draining_ || (outgoingStreams_ >= maxConcurrentOutgoingStreamsRemote_)) {\n    LOG(ERROR) << \"cannot support any more transactions in \" << *this;\n    return nullptr;\n  }\n\n  DCHECK(started_);\n  HTTPTransaction* txn =\n    createTransaction(codec_->createStream(),\n                      HTTPCodec::NoStream,\n                      HTTPCodec::ExAttributes(controlStream, unidirectional));\n  if (!txn) {\n    return nullptr;\n  }\n\n  DestructorGuard dg(this);\n  txn->setHandler(handler);\n  setNewTransactionPauseState(txn->getID());\n  return txn;\n}\n\nsize_t HTTPSession::getCodecSendWindowSize() const {\n  const HTTPSettings* settings = codec_->getIngressSettings();\n  if (settings) {\n    return settings->getSetting(SettingsId::INITIAL_WINDOW_SIZE,\n                                codec_->getDefaultWindowSize());\n  }\n  return codec_->getDefaultWindowSize();\n}\n\nvoid\nHTTPSession::setNewTransactionPauseState(HTTPCodec::StreamID streamID) {\n  if (!egressLimitExceeded()) {\n    return;\n  }\n\n  auto txn = findTransaction(streamID);\n  if (txn) {\n    // If writes are paused, start this txn off in the egress paused state\n    VLOG(4) << *this << \" starting streamID=\" << txn->getID()\n            << \" egress paused, numActiveWrites_=\" << numActiveWrites_;\n    txn->pauseEgress();\n  }\n}\n\nhttp2::PriorityUpdate\nHTTPSession::getMessagePriority(const HTTPMessage* msg) {\n  http2::PriorityUpdate h2Pri = http2::DefaultPriority;\n\n  // if HTTP2 priorities are enabled, get them from the message\n  // and ignore otherwise\n  if (getHTTP2PrioritiesEnabled() && msg) {\n    auto res = msg->getHTTP2Priority();\n    if (res) {\n      h2Pri.streamDependency = std::get<0>(*res);\n      h2Pri.exclusive = std::get<1>(*res);\n      h2Pri.weight = std::get<2>(*res);\n    } else {\n      // HTTPMessage with setPriority called explicitly\n      h2Pri.streamDependency =\n        codec_->mapPriorityToDependency(msg->getPriority());\n    }\n  }\n  return h2Pri;\n}\n\nvoid\nHTTPSession::onMessageBegin(HTTPCodec::StreamID streamID, HTTPMessage* msg) {\n  VLOG(4) << \"processing new msg streamID=\" << streamID << \" \" << *this;\n  if (infoCallback_) {\n    infoCallback_->onRequestBegin(*this);\n  }\n\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (txn) {\n    if (isDownstream() && txn->isPushed()) {\n      // Push streams are unidirectional (half-closed). If the downstream\n      // attempts to send ingress, abort with STREAM_CLOSED error.\n      HTTPException ex(HTTPException::Direction::INGRESS_AND_EGRESS,\n                       \"Downstream attempts to send ingress, abort.\");\n      ex.setCodecStatusCode(ErrorCode::STREAM_CLOSED);\n      txn->onError(ex);\n    }\n    return;  // If this transaction is already registered, no need to add it now\n  }\n\n  http2::PriorityUpdate messagePriority = getMessagePriority(msg);\n  txn = createTransaction(streamID, HTTPCodec::NoStream,\n                          HTTPCodec::NoExAttributes, messagePriority);\n  if (!txn) {\n    return;  // This could happen if the socket is bad.\n  }\n\n  if (!codec_->supportsParallelRequests() && getPipelineStreamCount() > 1) {\n    // The previous transaction hasn't completed yet. Pause reads until\n    // it completes; this requires pausing both transactions.\n\n    // HTTP/1.1 pipeline is detected, and which is incompactible with\n    // ByteEventTracker. Drain all the ByteEvents\n    CHECK(byteEventTracker_);\n    byteEventTracker_->drainByteEvents();\n\n    // drainByteEvents() may detach txn(s). Don't pause read if one txn left\n    if (getPipelineStreamCount() < 2) {\n      DCHECK(readsUnpaused());\n      return;\n    }\n\n    // There must be at least two transactions (we just checked). The previous\n    // txns haven't completed yet. Pause reads until they complete\n    DCHECK_GE(transactions_.size(), 2);\n    for (auto it = ++transactions_.rbegin(); it != transactions_.rend(); ++it) {\n      DCHECK(it->second.isIngressEOMSeen());\n      it->second.pauseIngress();\n    }\n    transactions_.rbegin()->second.pauseIngress();\n    DCHECK_EQ(liveTransactions_, 0);\n    DCHECK(readsPaused());\n  }\n}\n\nvoid\nHTTPSession::onPushMessageBegin(HTTPCodec::StreamID streamID,\n                                HTTPCodec::StreamID assocStreamID,\n                                HTTPMessage* msg) {\n  VLOG(4) << \"processing new push promise streamID=\" << streamID\n          << \" on assocStreamID=\" << assocStreamID << \" \" << *this;\n  if (infoCallback_) {\n    infoCallback_->onRequestBegin(*this);\n  }\n  if (assocStreamID == 0) {\n    VLOG(2) << \"push promise \" << streamID << \" should be associated with \"\n            << \"an active stream=\" << assocStreamID << \" \" << *this;\n    invalidStream(streamID, ErrorCode::PROTOCOL_ERROR);\n    return;\n  }\n\n  if (isDownstream()) {\n    VLOG(2) << \"push promise cannot be sent to upstream \" << *this;\n    invalidStream(streamID, ErrorCode::PROTOCOL_ERROR);\n    return;\n  }\n\n  HTTPTransaction* assocTxn = findTransaction(assocStreamID);\n  if (!assocTxn || assocTxn->isIngressEOMSeen()) {\n    VLOG(2) << \"cannot find the assocTxn=\" << assocTxn\n            << \", or assoc stream is already closed by upstream\" << *this;\n    invalidStream(streamID, ErrorCode::PROTOCOL_ERROR);\n    return;\n  }\n\n  http2::PriorityUpdate messagePriority = getMessagePriority(msg);\n  auto txn = createTransaction(streamID, assocStreamID,\n                               HTTPCodec::NoExAttributes, messagePriority);\n  if (!txn) {\n    return;  // This could happen if the socket is bad.\n  }\n\n  if (!assocTxn->onPushedTransaction(txn)) {\n    VLOG(1) << \"Failed to add pushed txn \" << streamID\n            << \" to assoc txn \" << assocStreamID << \" on \" << *this;\n    HTTPException ex(HTTPException::Direction::INGRESS_AND_EGRESS,\n      folly::to<std::string>(\"Failed to add pushed transaction \", streamID));\n    ex.setCodecStatusCode(ErrorCode::REFUSED_STREAM);\n    onError(streamID, ex, true);\n  }\n}\n\nvoid\nHTTPSession::onExMessageBegin(HTTPCodec::StreamID streamID,\n                              HTTPCodec::StreamID controlStream,\n                              bool unidirectional,\n                              HTTPMessage* msg) {\n  VLOG(4) << \"processing new ExMessage=\" << streamID\n          << \" on controlStream=\" << controlStream << \", \" << *this;\n  if (infoCallback_) {\n    infoCallback_->onRequestBegin(*this);\n  }\n  if (controlStream == 0) {\n    LOG(ERROR) << \"ExMessage=\" << streamID << \" should have an active control \"\n               << \"stream=\" << controlStream << \", \" << *this;\n    invalidStream(streamID, ErrorCode::PROTOCOL_ERROR);\n    return;\n  }\n\n  HTTPTransaction* controlTxn = findTransaction(controlStream);\n  if (!controlTxn) {\n    // control stream is broken, or remote sends a bogus stream id\n    LOG(ERROR) << \"no control stream=\" << controlStream << \", \" << *this;\n    return;\n  }\n\n  http2::PriorityUpdate messagePriority = getMessagePriority(msg);\n  auto txn = createTransaction(streamID,\n                               HTTPCodec::NoStream,\n                               HTTPCodec::ExAttributes(controlStream,\n                                                       unidirectional),\n                               messagePriority);\n  if (!txn) {\n    return;  // This could happen if the socket is bad.\n  }\n  // control stream may be paused if the upstream is not ready yet\n  if (controlTxn->isIngressPaused()) {\n    txn->pauseIngress();\n  }\n}\n\nvoid\nHTTPSession::onHeadersComplete(HTTPCodec::StreamID streamID,\n                               unique_ptr<HTTPMessage> msg) {\n  // The codec's parser detected the end of an ingress message's\n  // headers.\n  VLOG(4) << \"processing ingress headers complete for \" << *this <<\n      \", streamID=\" << streamID;\n\n  if (!codec_->isReusable()) {\n    setCloseReason(ConnectionCloseReason::REQ_NOTREUSABLE);\n  }\n\n  if (infoCallback_) {\n    infoCallback_->onIngressMessage(*this, *msg.get());\n  }\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    invalidStream(streamID);\n    return;\n  }\n\n  const char* sslCipher =\n      transportInfo_.sslCipher ? transportInfo_.sslCipher->c_str() : nullptr;\n  msg->setSecureInfo(transportInfo_.sslVersion, sslCipher);\n  msg->setSecure(transportInfo_.secure);\n\n  auto controlStreamID = txn->getControlStream();\n  if (controlStreamID) {\n    auto controlTxn = findTransaction(*controlStreamID);\n    if (!controlTxn) {\n      VLOG(2) << \"txn=\" << streamID << \" with a broken controlTxn=\"\n              << *controlStreamID << \" \" << *this;\n      HTTPException ex(\n          HTTPException::Direction::INGRESS_AND_EGRESS,\n          folly::to<std::string>(\"broken controlTxn \", *controlStreamID));\n      onError(streamID, ex, true);\n      return;\n    }\n\n    // Call onExTransaction() only for requests.\n    if (txn->isRemoteInitiated() && !controlTxn->onExTransaction(txn)) {\n      VLOG(2) << \"Failed to add exTxn=\" << streamID\n              << \" to controlTxn=\" << *controlStreamID << \", \" << *this;\n      HTTPException ex(\n          HTTPException::Direction::INGRESS_AND_EGRESS,\n          folly::to<std::string>(\"Fail to add exTxn \", streamID));\n      ex.setCodecStatusCode(ErrorCode::REFUSED_STREAM);\n      onError(streamID, ex, true);\n      return;\n    }\n  } else {\n    setupOnHeadersComplete(txn, msg.get());\n  }\n\n  // The txn may have already been aborted by the handler.\n  // Verify that the txn still exists before ingress callbacks.\n  txn = findTransaction(streamID);\n  if (!txn) {\n    return;\n  }\n\n  if (!txn->getHandler()) {\n    txn->sendAbort();\n    return;\n  }\n\n  // Tell the Transaction to start processing the message now\n  // that the full ingress headers have arrived.\n  txn->onIngressHeadersComplete(std::move(msg));\n}\n\nvoid\nHTTPSession::onBody(HTTPCodec::StreamID streamID,\n                    unique_ptr<IOBuf> chain, uint16_t padding) {\n  FOLLY_SCOPED_TRACE_SECTION(\"HTTPSession - onBody\");\n  DestructorGuard dg(this);\n  // The codec's parser detected part of the ingress message's\n  // entity-body.\n  uint64_t length = chain->computeChainDataLength();\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    if (connFlowControl_ &&\n        connFlowControl_->ingressBytesProcessed(writeBuf_, length)) {\n      scheduleWrite();\n    }\n    invalidStream(streamID);\n    return;\n  }\n\n  if (HTTPSessionBase::onBodyImpl(std::move(chain), length, padding, txn)) {\n    VLOG(4) << *this << \" pausing due to read limit exceeded.\";\n    pauseReads();\n  }\n}\n\nvoid HTTPSession::onChunkHeader(HTTPCodec::StreamID streamID,\n                                size_t length) {\n  // The codec's parser detected a chunk header (meaning that this\n  // connection probably is HTTP/1.1).\n  //\n  // After calling onChunkHeader(), the codec will call onBody() zero\n  // or more times and then call onChunkComplete().\n  //\n  // The reason for this callback on the chunk header is to support\n  // an optimization.  In general, the job of the codec is to present\n  // the HTTPSession with an abstract view of a message,\n  // with all the details of wire formatting hidden.  However, there's\n  // one important case where we want to know about chunking: reverse\n  // proxying where both the client and server streams are HTTP/1.1.\n  // In that scenario, we preserve the server's chunk boundaries when\n  // sending the response to the client, in order to avoid possibly\n  // making the egress packetization worse by rechunking.\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    invalidStream(streamID);\n    return;\n  }\n  txn->onIngressChunkHeader(length);\n}\n\nvoid HTTPSession::onChunkComplete(HTTPCodec::StreamID streamID) {\n  // The codec's parser detected the end of the message body chunk\n  // associated with the most recent call to onChunkHeader().\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    invalidStream(streamID);\n    return;\n  }\n  txn->onIngressChunkComplete();\n}\n\nvoid\nHTTPSession::onTrailersComplete(HTTPCodec::StreamID streamID,\n                                unique_ptr<HTTPHeaders> trailers) {\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    invalidStream(streamID);\n    return;\n  }\n  txn->onIngressTrailers(std::move(trailers));\n}\n\nvoid\nHTTPSession::onMessageComplete(HTTPCodec::StreamID streamID,\n                               bool upgrade) {\n  DestructorGuard dg(this);\n  // The codec's parser detected the end of the ingress message for\n  // this transaction.\n  VLOG(4) << \"processing ingress message complete for \" << *this <<\n    \", streamID=\" << streamID;\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    invalidStream(streamID);\n    return;\n  }\n\n  if (upgrade) {\n    /* Send the upgrade callback to the transaction and the handler.\n     * Currently we support upgrades for only HTTP sessions and not SPDY\n     * sessions.\n     */\n    ingressUpgraded_ = true;\n    txn->onIngressUpgrade(UpgradeProtocol::TCP);\n    return;\n  }\n\n  // txnIngressFinished = !1xx response\n  const bool txnIngressFinished =\n    txn->isDownstream() || !txn->extraResponseExpected();\n  if (txnIngressFinished) {\n    decrementTransactionCount(txn, true, false);\n  }\n  txn->onIngressEOM();\n\n  // The codec knows, based on the semantics of whatever protocol it\n  // supports, whether it's valid for any more ingress messages to arrive\n  // after this one.  For example, an HTTP/1.1 request containing\n  // \"Connection: close\" indicates the end of the ingress, whereas a\n  // SPDY session generally can handle more messages at any time.\n  //\n  // If the connection is not reusable, we close the read side of it\n  // but not the write side.  There are two reasons why more writes\n  // may occur after this point:\n  //   * If there are previous writes buffered up in the pendingWrites_\n  //     queue, we need to attempt to complete them.\n  //   * The Handler associated with the transaction may want to\n  //     produce more egress data when the ingress message is fully\n  //     complete.  (As a common example, an application that handles\n  //     form POSTs may not be able to even start generating a response\n  //     until it has received the full request body.)\n  //\n  // There may be additional checks that need to be performed that are\n  // specific to requests or responses, so we call the subclass too.\n  if (!codec_->isReusable() &&\n      txnIngressFinished &&\n      !codec_->supportsParallelRequests()) {\n    VLOG(4) << *this << \" cannot reuse ingress\";\n    shutdownTransport(true, false);\n  }\n}\n\nvoid HTTPSession::onError(HTTPCodec::StreamID streamID,\n                          const HTTPException& error, bool newTxn) {\n  DestructorGuard dg(this);\n  // The codec detected an error in the ingress stream, possibly bad\n  // syntax, a truncated message, or bad semantics in the frame.  If reads\n  // are paused, queue up the event; otherwise, process it now.\n  VLOG(4) << \"Error on \" << *this << \", streamID=\" << streamID\n          << \", \" << error;\n\n  if (ingressError_) {\n    return;\n  }\n  if (!codec_->supportsParallelRequests()) {\n    // this error should only prevent us from reading/handling more errors\n    // on serial streams\n    ingressError_ = true;\n    setCloseReason(ConnectionCloseReason::SESSION_PARSE_ERROR);\n  }\n  if ((streamID == 0) && infoCallback_) {\n    infoCallback_->onIngressError(*this, kErrorMessage);\n  }\n\n  if (!streamID) {\n    ingressError_ = true;\n    onSessionParseError(error);\n    return;\n  }\n\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    if (error.hasHttpStatusCode() && streamID != 0) {\n      // If the error has an HTTP code, then parsing was fine, it just was\n      // illegal in a higher level way\n      txn = createTransaction(streamID, HTTPCodec::NoStream,\n                              HTTPCodec::NoExAttributes);\n      if (infoCallback_) {\n        infoCallback_->onRequestBegin(*this);\n      }\n      if (txn) {\n        handleErrorDirectly(txn, error);\n      }\n    } else if (newTxn) {\n      onNewTransactionParseError(streamID, error);\n    } else {\n      VLOG(4) << *this << \" parse error with invalid transaction\";\n      invalidStream(streamID);\n    }\n    return;\n  }\n\n  if (!txn->getHandler() &&\n      txn->getEgressState() == HTTPTransactionEgressSM::State::Start) {\n    handleErrorDirectly(txn, error);\n    return;\n  }\n\n  txn->onError(error);\n  if (!codec_->isReusable() && transactions_.empty()) {\n    VLOG(4) << *this << \"shutdown from onError\";\n    setCloseReason(ConnectionCloseReason::SESSION_PARSE_ERROR);\n    shutdownTransport(true, true);\n  }\n}\n\nvoid HTTPSession::onAbort(HTTPCodec::StreamID streamID,\n                          ErrorCode code) {\n  VLOG(4) << \"stream abort on \" << *this << \", streamID=\" << streamID\n          << \", code=\" << getErrorCodeString(code);\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    VLOG(4) << *this << \" abort for unrecognized transaction, streamID= \"\n      << streamID;\n    return;\n  }\n  HTTPException ex(HTTPException::Direction::INGRESS_AND_EGRESS,\n    folly::to<std::string>(\"Stream aborted, streamID=\",\n      streamID, \", code=\", getErrorCodeString(code)));\n  ex.setProxygenError(kErrorStreamAbort);\n  ex.setCodecStatusCode(code);\n  DestructorGuard dg(this);\n  if (isDownstream() && !txn->getAssocTxnId() && code == ErrorCode::CANCEL) {\n    // Cancelling the assoc txn cancels all push txns\n    for (auto it = txn->getPushedTransactions().begin();\n         it != txn->getPushedTransactions().end(); ) {\n      auto pushTxn = findTransaction(*it);\n      ++it;\n      DCHECK(pushTxn != nullptr);\n      pushTxn->onError(ex);\n    }\n  }\n  auto exTxns = txn->getExTransactions();\n  for (auto it = exTxns.begin(); it != exTxns.end(); ++it) {\n    auto exTxn = findTransaction(*it);\n    if (exTxn) {\n      exTxn->onError(ex);\n    }\n  }\n  txn->onError(ex);\n}\n\nvoid HTTPSession::onGoaway(uint64_t lastGoodStreamID,\n                           ErrorCode code,\n                           std::unique_ptr<folly::IOBuf> debugData) {\n  DestructorGuard g(this);\n  VLOG(4) << \"GOAWAY on \" << *this << \", code=\" << getErrorCodeString(code);\n\n  setCloseReason(ConnectionCloseReason::GOAWAY);\n\n  // Drain active transactions and prevent new transactions\n  drain();\n\n  // We give the less-forceful onGoaway() first so that transactions have\n  // a chance to do stat tracking before potentially getting a forceful\n  // onError().\n  invokeOnAllTransactions(&HTTPTransaction::onGoaway, code);\n\n  // Abort transactions which have been initiated but not created\n  // successfully at the remote end. Upstream transactions are created\n  // with odd transaction IDs and downstream transactions with even IDs.\n  vector<HTTPCodec::StreamID> ids;\n  auto firstStream = HTTPCodec::NoStream;\n\n  for (const auto& txn: transactions_) {\n    auto streamID = txn.first;\n    if (((bool)(streamID & 0x01) == isUpstream()) &&\n        (streamID > lastGoodStreamID)) {\n      if (firstStream == HTTPCodec::NoStream) {\n        // transactions_ is a set so it should be sorted by stream id.\n        // We will defer adding the firstStream to the id list until\n        // we can determine whether we have a codec error code.\n        firstStream = streamID;\n        continue;\n      }\n\n      ids.push_back(streamID);\n    }\n  }\n\n\n  if (firstStream != HTTPCodec::NoStream && code != ErrorCode::NO_ERROR) {\n    // If we get a codec error, we will attempt to blame the first stream\n    // by delivering a specific error to it and let the rest of the streams\n    // get a normal unacknowledged stream error.\n    ProxygenError err = kErrorStreamUnacknowledged;\n    string debugInfo = (debugData) ?\n      folly::to<string>(\" with debug info: \", (char*)debugData->data()) : \"\";\n    HTTPException ex(HTTPException::Direction::INGRESS_AND_EGRESS,\n      folly::to<std::string>(getErrorString(err),\n        \" on transaction id: \", *firstStream,\n        \" with codec error: \", getErrorCodeString(code),\n        debugInfo));\n    ex.setProxygenError(err);\n    errorOnTransactionId(*firstStream, std::move(ex));\n  } else if (firstStream != HTTPCodec::NoStream) {\n    ids.push_back(*firstStream);\n  }\n\n  errorOnTransactionIds(ids, kErrorStreamUnacknowledged);\n}\n\nvoid HTTPSession::onPingRequest(uint64_t uniqueID) {\n  VLOG(4) << *this << \" got ping request with id=\" << uniqueID;\n\n  TimePoint timestamp = getCurrentTime();\n\n  // Insert the ping reply to the head of writeBuf_\n  folly::IOBufQueue pingBuf(folly::IOBufQueue::cacheChainLength());\n  codec_->generatePingReply(pingBuf, uniqueID);\n  size_t pingSize = pingBuf.chainLength();\n  pingBuf.append(writeBuf_.move());\n  writeBuf_.append(pingBuf.move());\n\n  if (byteEventTracker_) {\n    byteEventTracker_->addPingByteEvent(pingSize, timestamp, bytesScheduled_);\n  }\n\n  scheduleWrite();\n}\n\nvoid HTTPSession::onPingReply(uint64_t uniqueID) {\n  VLOG(4) << *this << \" got ping reply with id=\" << uniqueID;\n  if (infoCallback_) {\n    infoCallback_->onPingReplyReceived();\n  }\n}\n\nvoid HTTPSession::onWindowUpdate(HTTPCodec::StreamID streamID,\n                                 uint32_t amount) {\n  VLOG(4) << *this << \" got window update on streamID=\" << streamID << \" for \"\n          << amount << \" bytes.\";\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    // We MUST be using SPDY/3+ if we got WINDOW_UPDATE. The spec says that -\n    //\n    // A sender should ignore all the WINDOW_UPDATE frames associated with the\n    // stream after it send the last frame for the stream.\n    //\n    // TODO: Only ignore if this is from some past transaction\n    return;\n  }\n  txn->onIngressWindowUpdate(amount);\n}\n\nvoid HTTPSession::onSettings(const SettingsList& settings) {\n  DestructorGuard g(this);\n  for (auto& setting : settings) {\n    if (setting.id == SettingsId::INITIAL_WINDOW_SIZE) {\n      onSetSendWindow(setting.value);\n    } else if (setting.id == SettingsId::MAX_CONCURRENT_STREAMS) {\n      onSetMaxInitiatedStreams(setting.value);\n    } else if (setting.id == SettingsId::SETTINGS_HTTP_CERT_AUTH) {\n      if (!(verifyCertAuthSetting(setting.value))) {\n        return;\n      }\n    }\n  }\n  if (codec_->generateSettingsAck(writeBuf_) > 0) {\n    scheduleWrite();\n  }\n  if (infoCallback_) {\n    infoCallback_->onSettings(*this, settings);\n  }\n}\n\nvoid HTTPSession::onSettingsAck() {\n  VLOG(4) << *this << \" received settings ack\";\n  if (infoCallback_) {\n    infoCallback_->onSettingsAck(*this);\n  }\n}\n\nvoid HTTPSession::onPriority(HTTPCodec::StreamID streamID,\n                             const HTTPMessage::HTTPPriority& pri) {\n  if (!getHTTP2PrioritiesEnabled()) {\n    return;\n  }\n  http2::PriorityUpdate h2Pri{std::get<0>(pri), std::get<1>(pri),\n      std::get<2>(pri)};\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (txn) {\n    // existing txn, change pri\n    txn->onPriorityUpdate(h2Pri);\n  } else {\n    // virtual node\n    txnEgressQueue_.addOrUpdatePriorityNode(streamID, h2Pri);\n  }\n}\n\nvoid HTTPSession::onCertificateRequest(uint16_t requestId,\n                                       std::unique_ptr<IOBuf> authRequest) {\n  DestructorGuard dg(this);\n  VLOG(4) << \"CERTIFICATE_REQUEST on\" << *this << \", requestId=\" << requestId;\n\n  std::pair<uint16_t, std::unique_ptr<folly::IOBuf>> authenticator;\n  auto fizzBase = getTransport()->getUnderlyingTransport<AsyncFizzBase>();\n  if (fizzBase) {\n    if (isUpstream()) {\n      authenticator =\n          secondAuthManager_->getAuthenticator(*fizzBase,\n                                               TransportDirection::UPSTREAM,\n                                               requestId,\n                                               std::move(authRequest));\n    } else {\n      authenticator =\n          secondAuthManager_->getAuthenticator(*fizzBase,\n                                               TransportDirection::DOWNSTREAM,\n                                               requestId,\n                                               std::move(authRequest));\n    }\n  } else {\n    VLOG(4) << \"Underlying transport does not support secondary \"\n               \"authentication.\";\n    return;\n  }\n  if (codec_->generateCertificate(writeBuf_,\n                                  authenticator.first,\n                                  std::move(authenticator.second)) > 0) {\n    scheduleWrite();\n  }\n}\n\nvoid HTTPSession::onCertificate(uint16_t certId,\n                                std::unique_ptr<IOBuf> authenticator) {\n  DestructorGuard dg(this);\n  VLOG(4) << \"CERTIFICATE on\" << *this << \", certId=\" << certId;\n\n  bool isValid = false;\n  auto fizzBase = getTransport()->getUnderlyingTransport<AsyncFizzBase>();\n  if (fizzBase) {\n    if (isUpstream()) {\n      isValid = secondAuthManager_->validateAuthenticator(\n          *fizzBase,\n          TransportDirection::UPSTREAM,\n          certId,\n          std::move(authenticator));\n    } else {\n      isValid = secondAuthManager_->validateAuthenticator(\n          *fizzBase,\n          TransportDirection::DOWNSTREAM,\n          certId,\n          std::move(authenticator));\n    }\n  } else {\n    VLOG(4) << \"Underlying transport does not support secondary \"\n               \"authentication.\";\n    return;\n  }\n  if (isValid) {\n    VLOG(4) << \"Successfully validated the authenticator provided by the peer.\";\n  } else {\n    VLOG(4) << \"Failed to validate the authenticator provided by the peer\";\n  }\n}\n\nbool HTTPSession::onNativeProtocolUpgradeImpl(\n  HTTPCodec::StreamID streamID, std::unique_ptr<HTTPCodec> codec,\n  const std::string& protocolString) {\n  CHECK_EQ(streamID, 1);\n  HTTPTransaction* txn = findTransaction(streamID);\n  CHECK(txn);\n  // only HTTP1xCodec calls onNativeProtocolUpgrade\n  CHECK(!codec_->supportsParallelRequests());\n\n  // Reset to  defaults\n  maxConcurrentIncomingStreams_ = 100;\n  maxConcurrentOutgoingStreamsRemote_ = 10000;\n\n  // overwrite destination, delay current codec deletion until the end\n  // of the event loop\n  auto oldCodec = codec_.setDestination(std::move(codec));\n  sock_->getEventBase()->runInLoop([oldCodec = std::move(oldCodec)] () {});\n\n  onCodecChanged();\n\n  setupCodec();\n\n  // txn will be streamID=1, have to make a placeholder\n  (void)codec_->createStream();\n\n  // This can happen if flow control was not explicitly set, and it got the\n  // HTTP1xCodec defaults.  Reset to the new codec default\n  if (initialReceiveWindow_ == 0 || receiveStreamWindowSize_ == 0 ||\n      receiveSessionWindowSize_ == 0) {\n    initialReceiveWindow_ = receiveStreamWindowSize_ =\n      receiveSessionWindowSize_ = codec_->getDefaultWindowSize();\n  }\n\n  // trigger settings frame that would have gone out in startNow()\n  HTTPSettings* settings = codec_->getEgressSettings();\n  if (settings) {\n    settings->setSetting(SettingsId::INITIAL_WINDOW_SIZE,\n                         initialReceiveWindow_);\n  }\n  sendSettings();\n  if (connFlowControl_) {\n    connFlowControl_->setReceiveWindowSize(writeBuf_,\n                                           receiveSessionWindowSize_);\n    scheduleWrite();\n  }\n\n  // Convert the transaction that contained the Upgrade header\n  txn->reset(codec_->supportsStreamFlowControl(),\n             initialReceiveWindow_,\n             receiveStreamWindowSize_,\n             getCodecSendWindowSize());\n\n  if (!transportInfo_.secure &&\n      (!transportInfo_.appProtocol ||\n       transportInfo_.appProtocol->empty())) {\n    transportInfo_.appProtocol = std::make_shared<string>(\n      protocolString);\n  }\n\n  return true;\n}\n\nvoid HTTPSession::onSetSendWindow(uint32_t windowSize) {\n  VLOG(4) << *this << \" got send window size adjustment. new=\" << windowSize;\n  invokeOnAllTransactions(&HTTPTransaction::onIngressSetSendWindow,\n                          windowSize);\n}\n\nvoid HTTPSession::onSetMaxInitiatedStreams(uint32_t maxTxns) {\n  VLOG(4) << *this << \" got new maximum number of concurrent txns \"\n          << \"we can initiate: \" << maxTxns;\n  const bool didSupport = supportsMoreTransactions();\n  maxConcurrentOutgoingStreamsRemote_ = maxTxns;\n  if (infoCallback_ && didSupport != supportsMoreTransactions()) {\n    if (didSupport) {\n      infoCallback_->onSettingsOutgoingStreamsFull(*this);\n    } else {\n      infoCallback_->onSettingsOutgoingStreamsNotFull(*this);\n    }\n  }\n}\n\nsize_t HTTPSession::sendSettings() {\n  size_t size = codec_->generateSettings(writeBuf_);\n  scheduleWrite();\n  return size;\n}\n\nvoid HTTPSession::pauseIngress(HTTPTransaction* txn) noexcept {\n  VLOG(4) << *this << \" pausing streamID=\" << txn->getID() <<\n    \", liveTransactions_ was \" << liveTransactions_;\n  CHECK_GT(liveTransactions_, 0);\n  --liveTransactions_;\n  auto exTxns = txn->getExTransactions();\n  for (auto it = exTxns.begin(); it != exTxns.end(); ++it) {\n    auto exTxn = findTransaction(*it);\n    if (exTxn) {\n      exTxn->pauseIngress();\n    }\n  }\n\n  if (liveTransactions_ == 0) {\n    pauseReads();\n  }\n}\n\nvoid HTTPSession::resumeIngress(HTTPTransaction* txn) noexcept {\n  VLOG(4) << *this << \" resuming streamID=\" << txn->getID() <<\n      \", liveTransactions_ was \" << liveTransactions_;\n  ++liveTransactions_;\n  auto exTxns = txn->getExTransactions();\n  for (auto it = exTxns.begin(); it != exTxns.end(); ++it) {\n    auto exTxn = findTransaction(*it);\n    if (exTxn) {\n      exTxn->resumeIngress();\n    }\n  }\n\n  if (liveTransactions_ == 1) {\n    resumeReads();\n  }\n}\n\nvoid\nHTTPSession::transactionTimeout(HTTPTransaction* txn) noexcept {\n  // A transaction has timed out.  If the transaction does not have\n  // a Handler yet, because we haven't yet received the full request\n  // headers, we give it a DirectResponseHandler that generates an\n  // error page.\n  VLOG(3) << \"Transaction timeout for streamID=\" << txn->getID();\n  if (!codec_->supportsParallelRequests()) {\n    // this error should only prevent us from reading/handling more errors\n    // on serial streams\n    ingressError_ = true;\n  }\n\n  if (!txn->getHandler() &&\n      txn->getEgressState() == HTTPTransactionEgressSM::State::Start) {\n    VLOG(4) << *this << \" Timed out receiving headers\";\n    if (infoCallback_) {\n      infoCallback_->onIngressError(*this, kErrorTimeout);\n    }\n    if (codec_->supportsParallelRequests()) {\n      // This can only happen with HTTP/2 where the HEADERS frame is incomplete\n      // and we time out waiting for the CONTINUATION.  Abort the request.\n      //\n      // It would maybe be a little nicer to use the timeout handler for these\n      // also.\n      txn->sendAbort();\n      return;\n    }\n\n    VLOG(4) << *this << \" creating direct error handler\";\n    auto handler = getTransactionTimeoutHandler(txn);\n    txn->setHandler(handler);\n  }\n\n  // Tell the transaction about the timeout.  The transaction will\n  // communicate the timeout to the handler, and the handler will\n  // decide how to proceed.\n  txn->onIngressTimeout();\n}\n\nvoid HTTPSession::sendHeaders(HTTPTransaction* txn,\n                              const HTTPMessage& headers,\n                              HTTPHeaderSize* size,\n                              bool includeEOM) noexcept {\n  CHECK(started_);\n  unique_ptr<IOBuf> goawayBuf;\n  if (shouldShutdown()) {\n    // For HTTP/1.1, add Connection: close\n    // For SPDY, save the goaway for AFTER the request\n    auto writeBuf = writeBuf_.move();\n    drainImpl();\n    goawayBuf = writeBuf_.move();\n    writeBuf_.append(std::move(writeBuf));\n  }\n  if (isUpstream() || (txn->isPushed() && headers.isRequest())) {\n    // upstream picks priority\n    if (getHTTP2PrioritiesEnabled()) {\n      auto pri = getMessagePriority(&headers);\n      txn->onPriorityUpdate(pri);\n    }\n  }\n\n  const bool wasReusable = codec_->isReusable();\n  const uint64_t oldOffset = sessionByteOffset();\n  auto exAttributes = txn->getExAttributes();\n  auto assocStream = txn->getAssocTxnId();\n  if (exAttributes) {\n    codec_->generateExHeader(writeBuf_,\n                             txn->getID(),\n                             headers,\n                             *exAttributes,\n                             includeEOM,\n                             size);\n  } else if (headers.isRequest() && assocStream) {\n    // Only PUSH_PROMISE (not push response) has an associated stream\n    codec_->generatePushPromise(writeBuf_,\n                                txn->getID(),\n                                headers,\n                                *assocStream,\n                                includeEOM,\n                                size);\n  } else {\n    codec_->generateHeader(writeBuf_,\n                           txn->getID(),\n                           headers,\n                           includeEOM,\n                           size);\n  }\n  const uint64_t newOffset = sessionByteOffset();\n\n  // for push response count towards the MAX_CONCURRENT_STREAMS limit\n  if (isDownstream() && headers.isResponse() && txn->isPushed()) {\n    incrementOutgoingStreams();\n  }\n\n  // For all upstream headers, addFirstHeaderByteEvent should be added\n  // For all downstream, only response headers need addFirstHeaderByteEvent\n  bool shouldAddFirstHeaderByteEvent = isUpstream() ||\n                                       (isDownstream() && headers.isResponse());\n  if (shouldAddFirstHeaderByteEvent && newOffset > oldOffset &&\n      !txn->testAndSetFirstHeaderByteSent() && byteEventTracker_) {\n    byteEventTracker_->addFirstHeaderByteEvent(newOffset, txn);\n  }\n\n  if (size) {\n    VLOG(4) << *this << \" sending headers, size=\" << size->compressed\n            << \", uncompressedSize=\" << size->uncompressed;\n  }\n  if (goawayBuf) {\n    VLOG(4) << *this << \" moved GOAWAY to end of writeBuf\";\n    writeBuf_.append(std::move(goawayBuf));\n  }\n  if (includeEOM) {\n    commonEom(txn, 0, true);\n  }\n  scheduleWrite();\n  onHeadersSent(headers, wasReusable);\n}\n\nvoid\nHTTPSession::commonEom(\n    HTTPTransaction* txn,\n    size_t encodedSize,\n    bool piggybacked) noexcept {\n  HTTPSessionBase::handleLastByteEvents(\n    byteEventTracker_.get(), txn, encodedSize, sessionByteOffset(),\n    piggybacked);\n  onEgressMessageFinished(txn);\n}\n\nsize_t\nHTTPSession::sendBody(HTTPTransaction* txn,\n                      std::unique_ptr<folly::IOBuf> body,\n                      bool includeEOM,\n                      bool trackLastByteFlushed) noexcept {\n  uint64_t offset = sessionByteOffset();\n  size_t bodyLen = body ? body->computeChainDataLength(): 0;\n  size_t encodedSize = codec_->generateBody(writeBuf_,\n                                            txn->getID(),\n                                            std::move(body),\n                                            HTTPCodec::NoPadding,\n                                            includeEOM);\n  CHECK(inLoopCallback_);\n  pendingWriteSizeDelta_ -= bodyLen;\n  bodyBytesPerWriteBuf_ += bodyLen;\n  if (encodedSize > 0 && !txn->testAndSetFirstByteSent() && byteEventTracker_) {\n    byteEventTracker_->addFirstBodyByteEvent(offset, txn);\n  }\n\n  if (trackLastByteFlushed && encodedSize > 0 && byteEventTracker_) {\n    byteEventTracker_->addTrackedByteEvent(txn, offset + encodedSize);\n  }\n\n  if (includeEOM) {\n    VLOG(5) << *this << \" sending EOM in body for streamID=\" << txn->getID();\n    commonEom(txn, encodedSize, true);\n  }\n  return encodedSize;\n}\n\nsize_t HTTPSession::sendChunkHeader(HTTPTransaction* txn,\n    size_t length) noexcept {\n  size_t encodedSize = codec_->generateChunkHeader(writeBuf_,\n                                                   txn->getID(),\n                                                   length);\n  scheduleWrite();\n  return encodedSize;\n}\n\nsize_t HTTPSession::sendChunkTerminator(\n    HTTPTransaction* txn) noexcept {\n  size_t encodedSize = codec_->generateChunkTerminator(writeBuf_,\n                                                       txn->getID());\n  scheduleWrite();\n  return encodedSize;\n}\n\nvoid\nHTTPSession::onEgressMessageFinished(HTTPTransaction* txn, bool withRST) {\n  // If the semantics of the protocol don't permit more messages\n  // to be read or sent on this connection, close the socket in one or\n  // more directions.\n  CHECK(!transactions_.empty());\n\n  if (infoCallback_) {\n    infoCallback_->onRequestEnd(*this, txn->getMaxDeferredSize());\n  }\n  auto oldStreamCount = getPipelineStreamCount();\n  decrementTransactionCount(txn, false, true);\n  if (withRST || ((!codec_->isReusable() || readsShutdown()) &&\n                  transactions_.size() == 1)) {\n    // We should shutdown reads if we are closing with RST or we aren't\n    // interested in any further messages (ie if we are a downstream session).\n    // Upgraded sessions have independent ingress and egress, and the reads\n    // need not be shutdown on egress finish.\n    if (withRST) {\n      // Let any queued writes complete, but send a RST when done.\n      VLOG(4) << *this << \" resetting egress after this message\";\n      resetAfterDrainingWrites_ = true;\n      setCloseReason(ConnectionCloseReason::TRANSACTION_ABORT);\n      shutdownTransport(true, true);\n    } else {\n      // the reason is already set (either not reusable or readshutdown).\n\n      // Defer normal shutdowns until the end of the loop.  This\n      // handles an edge case with direct responses with Connection:\n      // close served before ingress EOM.  The remainder of the ingress\n      // message may be in the parse loop, so give it a chance to\n      // finish out and avoid a kErrorEOF\n\n      // we can get here during shutdown, in that case do not schedule a\n      // shutdown callback again\n      if (!shutdownTransportCb_) {\n        // Just for safety, the following bumps the refcount on this session\n        // to keep it live until the loopCb runs\n        shutdownTransportCb_.reset(new ShutdownTransportCallback(this));\n        sock_->getEventBase()->runInLoop(shutdownTransportCb_.get(), true);\n      }\n    }\n  } else {\n    maybeResumePausedPipelinedTransaction(oldStreamCount,\n                                          txn->getSequenceNumber());\n  }\n}\n\nsize_t HTTPSession::sendEOM(HTTPTransaction* txn,\n                            const HTTPHeaders* trailers) noexcept {\n\n  VLOG(4) << *this << \" sending EOM for streamID=\" << txn->getID()\n          << \" trailers=\" << (trailers ? \"yes\" : \"no\");\n\n  size_t encodedSize = 0;\n  if (trailers) {\n    encodedSize = codec_->generateTrailers(writeBuf_, txn->getID(), *trailers);\n  }\n\n  // Don't send EOM for HTTP2, when trailers sent.\n  // sendTrailers already flagged end of stream.\n  bool http2Trailers = trailers && isHTTP2CodecProtocol(codec_->getProtocol());\n  if (!http2Trailers) {\n    encodedSize += codec_->generateEOM(writeBuf_, txn->getID());\n  }\n\n  commonEom(txn, encodedSize, false);\n  return encodedSize;\n}\n\nsize_t HTTPSession::sendAbort(HTTPTransaction* txn,\n                              ErrorCode statusCode) noexcept {\n  // Ask the codec to generate an abort indicator for the transaction.\n  // Depending on the protocol, this may be a no-op.\n  // Schedule a network write to send out whatever egress we might\n  // have queued up.\n  VLOG(4) << *this << \" sending abort for streamID=\" << txn->getID();\n  // drain this transaction's writeBuf instead of flushing it\n  // then enqueue the abort directly into the Session buffer,\n  // hence with max priority.\n  size_t encodedSize = codec_->generateRstStream(writeBuf_,\n                                                 txn->getID(),\n                                                 statusCode);\n\n  if (!codec_->isReusable()) {\n    // HTTP 1x codec does not support per stream abort so this will\n    // render the codec not reusable\n    setCloseReason(ConnectionCloseReason::TRANSACTION_ABORT);\n  }\n\n  scheduleWrite();\n\n  // If the codec wasn't able to write a L7 message for the abort, then\n  // fall back to closing the transport with a TCP level RST\n  onEgressMessageFinished(txn, !encodedSize);\n  return encodedSize;\n}\n\nsize_t HTTPSession::sendPriority(HTTPTransaction* txn,\n                                 const http2::PriorityUpdate& pri) noexcept {\n  return sendPriorityImpl(txn->getID(), pri);\n}\n\nvoid HTTPSession::setSecondAuthManager(\n    std::unique_ptr<SecondaryAuthManager> secondAuthManager) {\n  secondAuthManager_ = std::move(secondAuthManager);\n}\n\nSecondaryAuthManager* HTTPSession::getSecondAuthManager() const {\n  return secondAuthManager_.get();\n}\n\n/**\n * Send a CERTIFICATE_REQUEST frame. If the underlying protocol doesn't\n * support secondary authentication, this is a no-op and 0 is returned.\n */\nsize_t HTTPSession::sendCertificateRequest(\n    std::unique_ptr<folly::IOBuf> certificateRequestContext,\n    std::vector<fizz::Extension> extensions) {\n  // Check if both sending and receiving peer have advertised valid\n  // SETTINGS_HTTP_CERT_AUTH setting. Otherwise, the frames for secondary\n  // authentication should not be sent.\n  auto ingressSettings = codec_->getIngressSettings();\n  auto egressSettings = codec_->getEgressSettings();\n  if (ingressSettings && egressSettings) {\n    if (ingressSettings->getSetting(SettingsId::SETTINGS_HTTP_CERT_AUTH, 0) ==\n            0 ||\n        egressSettings->getSetting(SettingsId::SETTINGS_HTTP_CERT_AUTH, 0) ==\n            0) {\n      VLOG(4) << \"Secondary certificate authentication is not supported.\";\n      return 0;\n    }\n  }\n  auto authRequest = secondAuthManager_->createAuthRequest(\n      std::move(certificateRequestContext), std::move(extensions));\n  auto encodedSize = codec_->generateCertificateRequest(\n      writeBuf_, authRequest.first, std::move(authRequest.second));\n  if (encodedSize > 0) {\n    scheduleWrite();\n  } else {\n    VLOG(4) << \"Failed to generate CERTIFICATE_REQUEST frame.\";\n  }\n  return encodedSize;\n}\n\nvoid HTTPSession::decrementTransactionCount(HTTPTransaction* txn,\n                                            bool ingressEOM,\n                                            bool egressEOM) {\n  if ((isUpstream() && !txn->isPushed()) ||\n      (isDownstream() && txn->isPushed())) {\n    if (ingressEOM && txn->testAndClearActive()) {\n      outgoingStreams_--;\n    }\n  } else {\n    if (egressEOM && txn->testAndClearActive()) {\n      incomingStreams_--;\n    }\n  }\n}\n\n// This is a kludgy function because it requires the caller to remember\n// the old value of pipelineStreamCount from before it calls\n// decrementTransactionCount.  I'm trying to avoid yet more state in\n// HTTPSession.  If decrementTransactionCount actually closed a stream\n// and there is still a pipelinable stream, then it was pipelining\nbool\nHTTPSession::maybeResumePausedPipelinedTransaction(\n  size_t oldStreamCount, uint32_t txnSeqn) {\n  if (!codec_->supportsParallelRequests() && !transactions_.empty() &&\n      getPipelineStreamCount() < oldStreamCount &&\n      getPipelineStreamCount() == 1) {\n    auto& nextTxn = transactions_.rbegin()->second;\n    DCHECK_EQ(nextTxn.getSequenceNumber(), txnSeqn + 1);\n    DCHECK(!nextTxn.isIngressComplete());\n    DCHECK(nextTxn.isIngressPaused());\n    VLOG(4) << \"Resuming paused pipelined txn \" << nextTxn;\n    nextTxn.resumeIngress();\n    return true;\n  }\n  return false;\n}\n\nvoid\nHTTPSession::detach(HTTPTransaction* txn) noexcept {\n  DestructorGuard guard(this);\n  HTTPCodec::StreamID streamID = txn->getID();\n  auto txnSeqn = txn->getSequenceNumber();\n  auto it = transactions_.find(txn->getID());\n  DCHECK(it != transactions_.end());\n\n  if (txn->isIngressPaused()) {\n    // Someone detached a transaction that was paused.  Make the resumeIngress\n    // call to keep liveTransactions_ in order\n    VLOG(4) << *this << \" detached paused transaction=\" << streamID;\n    resumeIngress(txn);\n  }\n\n  VLOG(4) << *this << \" removing streamID=\" << streamID <<\n    \", liveTransactions was \" << liveTransactions_;\n  CHECK_GT(liveTransactions_, 0);\n  liveTransactions_--;\n\n  if (txn->isPushed()) {\n    auto assocTxn = findTransaction(*txn->getAssocTxnId());\n    if (assocTxn) {\n      assocTxn->removePushedTransaction(streamID);\n    }\n  }\n  if (txn->getControlStream()) {\n    auto controlTxn = findTransaction(*txn->getControlStream());\n    if (controlTxn) {\n      controlTxn->removeExTransaction(streamID);\n    }\n  }\n\n  auto oldStreamCount = getPipelineStreamCount();\n  decrementTransactionCount(txn, true, true);\n  transactions_.erase(it);\n\n  if (transactions_.empty()) {\n    HTTPSessionBase::setLatestActive();\n    if (infoCallback_) {\n      infoCallback_->onDeactivateConnection(*this);\n    }\n    if (getConnectionManager()) {\n      getConnectionManager()->onDeactivated(*this);\n    }\n  } else {\n    if (infoCallback_) {\n      infoCallback_->onTransactionDetached(*this);\n    }\n  }\n\n  if (!readsShutdown()) {\n    if (maybeResumePausedPipelinedTransaction(oldStreamCount, txnSeqn)) {\n      return;\n    } else {\n      // this will resume reads if they were paused (eg: 0 HTTP transactions)\n      resumeReads();\n    }\n  }\n\n  if (liveTransactions_ == 0 && transactions_.empty() && !isScheduled()) {\n    resetTimeout();\n  }\n\n  // It's possible that this is the last transaction in the session,\n  // so check whether the conditions for shutdown are satisfied.\n  if (transactions_.empty()) {\n    if (shouldShutdown()) {\n      writesDraining_ = true;\n    }\n    // Handle the case where we are draining writes but all remaining\n    // transactions terminated with no egress.\n    if (writesDraining_ && !writesShutdown() && !hasMoreWrites()) {\n      shutdownTransport(false, true);\n      return;\n    }\n  }\n  checkForShutdown();\n}\n\nsize_t\nHTTPSession::sendWindowUpdate(HTTPTransaction* txn,\n                              uint32_t bytes) noexcept {\n  size_t sent = codec_->generateWindowUpdate(writeBuf_, txn->getID(), bytes);\n  if (sent) {\n    scheduleWrite();\n  }\n  return sent;\n}\n\nvoid\nHTTPSession::notifyIngressBodyProcessed(uint32_t bytes) noexcept {\n  if (HTTPSessionBase::notifyBodyProcessed(bytes)) {\n    resumeReads();\n  }\n  if (connFlowControl_ &&\n      connFlowControl_->ingressBytesProcessed(writeBuf_, bytes)) {\n    scheduleWrite();\n  }\n}\n\nvoid\nHTTPSession::notifyEgressBodyBuffered(int64_t bytes) noexcept {\n  pendingWriteSizeDelta_ += bytes;\n  // any net change requires us to update pause/resume state in the\n  // loop callback\n  if (pendingWriteSizeDelta_ > 0) {\n    // pause inline, resume in loop\n    updateWriteBufSize(0);\n  } else if (!isLoopCallbackScheduled()) {\n    sock_->getEventBase()->runInLoop(this);\n  }\n}\n\nbool HTTPSession::getCurrentTransportInfoWithoutUpdate(\n    TransportInfo* tinfo) const {\n  auto sock = sock_->getUnderlyingTransport<AsyncSocket>();\n  if (sock) {\n    tinfo->initWithSocket(sock);\n    return true;\n  }\n  return false;\n}\n\nbool HTTPSession::getCurrentTransportInfo(TransportInfo* tinfo) {\n  if (getCurrentTransportInfoWithoutUpdate(tinfo)) {\n    // some fields are the same with the setup transport info\n    tinfo->setupTime = transportInfo_.setupTime;\n    tinfo->secure = transportInfo_.secure;\n    tinfo->sslSetupTime = transportInfo_.sslSetupTime;\n    tinfo->sslVersion = transportInfo_.sslVersion;\n    tinfo->sslCipher = transportInfo_.sslCipher;\n    tinfo->sslResume = transportInfo_.sslResume;\n    tinfo->appProtocol = transportInfo_.appProtocol;\n    tinfo->sslError = transportInfo_.sslError;\n#if defined(__linux__) || defined(__FreeBSD__)\n    // update connection transport info with the latest RTT\n    if (tinfo->tcpinfo.tcpi_rtt > 0) {\n      transportInfo_.tcpinfo.tcpi_rtt = tinfo->tcpinfo.tcpi_rtt;\n      transportInfo_.rtt = std::chrono::microseconds(tinfo->tcpinfo.tcpi_rtt);\n    }\n    transportInfo_.rtx = tinfo->rtx;\n#endif\n    return true;\n  }\n  return false;\n}\n\nunique_ptr<IOBuf> HTTPSession::getNextToSend(bool* cork, bool* eom) {\n  // limit ourselves to one outstanding write at a time (onWriteSuccess calls\n  // scheduleWrite)\n  if (numActiveWrites_ > 0 || writesShutdown()) {\n    VLOG(4) << \"skipping write during this loop, numActiveWrites_=\" <<\n      numActiveWrites_ << \" writesShutdown()=\" << writesShutdown();\n    return nullptr;\n  }\n\n  // We always tack on at least one body packet to the current write buf\n  // This ensures that a short HTTPS response will go out in a single SSL record\n  while (!txnEgressQueue_.empty()) {\n    uint32_t toSend = kWriteReadyMax;\n    if (connFlowControl_) {\n      if (connFlowControl_->getAvailableSend() == 0) {\n        VLOG(4) << \"Session-level send window is full, skipping remaining \"\n                << \"body writes this loop\";\n        break;\n      }\n      toSend = std::min(toSend, connFlowControl_->getAvailableSend());\n    }\n    txnEgressQueue_.nextEgress(nextEgressResults_,\n                               isSpdyCodecProtocol(codec_->getProtocol()));\n    CHECK(!nextEgressResults_.empty()); // Queue was non empty, so this must be\n    // The maximum we will send for any transaction in this loop\n    uint32_t txnMaxToSend = toSend * nextEgressResults_.front().second;\n    if (txnMaxToSend == 0) {\n      // toSend is smaller than the number of transactions.  Give all egress\n      // to the first transaction\n      nextEgressResults_.erase(++nextEgressResults_.begin(),\n                               nextEgressResults_.end());\n      txnMaxToSend = std::min(toSend, egressBodySizeLimit_);\n      nextEgressResults_.front().second = 1;\n    }\n    if (nextEgressResults_.size() > 1 && txnMaxToSend > egressBodySizeLimit_) {\n      // Cap the max to egressBodySizeLimit_, and recompute toSend accordingly\n      txnMaxToSend = egressBodySizeLimit_;\n      toSend = txnMaxToSend / nextEgressResults_.front().second;\n    }\n    // split allowed by relative weight, with some minimum\n    for (auto txnPair: nextEgressResults_) {\n      uint32_t txnAllowed = txnPair.second * toSend;\n      if (nextEgressResults_.size() > 1) {\n        CHECK_LE(txnAllowed, egressBodySizeLimit_);\n      }\n      if (connFlowControl_) {\n        CHECK_LE(txnAllowed, connFlowControl_->getAvailableSend());\n      }\n      if (txnAllowed == 0) {\n        // The ratio * toSend was so small this txn gets nothing.\n        VLOG(4) << *this << \" breaking egress loop on 0 txnAllowed\";\n        break;\n      }\n\n      VLOG(4) << *this << \" egressing txnID=\" << txnPair.first->getID() <<\n        \" allowed=\" << txnAllowed;\n      txnPair.first->onWriteReady(txnAllowed, txnPair.second);\n    }\n    nextEgressResults_.clear();\n    // it can be empty because of HTTPTransaction rate limiting.  We should\n    // change rate limiting to clearPendingEgress while waiting.\n    if (!writeBuf_.empty()) {\n      break;\n    }\n  }\n  *eom = false;\n  if (byteEventTracker_) {\n    uint64_t needed = byteEventTracker_->preSend(cork, eom, bytesWritten_);\n    if (needed > 0) {\n      VLOG(5) << *this << \" writeBuf_.chainLength(): \"\n              << writeBuf_.chainLength() << \" txnEgressQueue_.empty(): \"\n              << txnEgressQueue_.empty();\n\n      if (needed < writeBuf_.chainLength()) {\n        // split the next EOM chunk\n        VLOG(5) << *this << \" splitting \" << needed << \" bytes out of a \"\n                << writeBuf_.chainLength() << \" bytes IOBuf\";\n        *cork = true;\n        if (sessionStats_) {\n          sessionStats_->recordTTLBAIOBSplitByEom();\n        }\n        return writeBuf_.split(needed);\n      } else {\n        CHECK_EQ(needed, writeBuf_.chainLength());\n      }\n    }\n  }\n\n  // cork if there are txns with pending egress and room to send them\n  *cork = !txnEgressQueue_.empty() && !isConnWindowFull();\n  return writeBuf_.move();\n}\n\nvoid\nHTTPSession::runLoopCallback() noexcept {\n  // We schedule this callback to run at the end of an event\n  // loop iteration if either of two conditions has happened:\n  //   * The session has generated some egress data (see scheduleWrite())\n  //   * Reads have become unpaused (see resumeReads())\n  DestructorGuard dg(this);\n  inLoopCallback_ = true;\n  auto scopeg = folly::makeGuard([this] {\n      inLoopCallback_ = false;\n      // This ScopeGuard needs to be under the above DestructorGuard\n      if (pendingWriteSizeDelta_) {\n        updateWriteBufSize(0);\n      }\n      checkForShutdown();\n    });\n  VLOG(5) << *this << \" in loop callback\";\n\n  for (uint32_t i = 0; i < kMaxWritesPerLoop; ++i) {\n    bodyBytesPerWriteBuf_ = 0;\n    if (isPrioritySampled()) {\n      invokeOnAllTransactions(\n        &HTTPTransaction::updateContentionsCount,\n        txnEgressQueue_.numPendingEgress());\n    }\n\n    bool cork = true;\n    bool eom = false;\n    unique_ptr<IOBuf> writeBuf = getNextToSend(&cork, &eom);\n\n    if (!writeBuf) {\n      break;\n    }\n    uint64_t len = writeBuf->computeChainDataLength();\n    VLOG(11) << *this\n             << \" bytes of egress to be written: \" << len\n             << \" cork:\" << cork << \" eom:\" << eom;\n    if (len == 0) {\n      checkForShutdown();\n      return;\n    }\n\n    if (isPrioritySampled()) {\n      invokeOnAllTransactions(\n        &HTTPTransaction::updateSessionBytesSheduled,\n        bodyBytesPerWriteBuf_);\n    }\n\n    WriteSegment* segment = new WriteSegment(this, len);\n    segment->setCork(cork);\n    segment->setEOR(eom);\n\n    pendingWrites_.push_back(*segment);\n    if (!writeTimeout_.isScheduled()) {\n      // Any performance concern here?\n      timeout_.scheduleTimeout(&writeTimeout_);\n    }\n    numActiveWrites_++;\n    VLOG(4) << *this << \" writing \" << len << \", activeWrites=\"\n             << numActiveWrites_ << \" cork=\" << cork << \" eom=\" << eom;\n    bytesScheduled_ += len;\n    sock_->writeChain(segment, std::move(writeBuf), segment->getFlags());\n    if (numActiveWrites_ > 0) {\n      updateWriteCount();\n      pendingWriteSizeDelta_ += len;\n      // updateWriteBufSize called in scope guard\n      break;\n    }\n    // writeChain can result in a writeError and trigger the shutdown code path\n  }\n  if (numActiveWrites_ == 0 && !writesShutdown() && hasMoreWrites() &&\n      (!connFlowControl_ || connFlowControl_->getAvailableSend())) {\n    scheduleWrite();\n  }\n\n  if (readsUnpaused()) {\n    processReadData();\n\n    // Install the read callback if necessary\n    if (readsUnpaused() && !sock_->getReadCallback()) {\n      sock_->setReadCB(this);\n    }\n  }\n  // checkForShutdown is now in ScopeGuard\n}\n\nvoid\nHTTPSession::scheduleWrite() {\n  // Do all the network writes for this connection in one batch at\n  // the end of the current event loop iteration.  Writing in a\n  // batch helps us packetize the network traffic more efficiently,\n  // as well as saving a few system calls.\n  if (!isLoopCallbackScheduled() &&\n      (writeBuf_.front() || !txnEgressQueue_.empty())) {\n    VLOG(5) << *this << \" scheduling write callback\";\n    sock_->getEventBase()->runInLoop(this);\n  }\n}\n\nvoid\nHTTPSession::updateWriteCount() {\n  if (numActiveWrites_ > 0 && writesUnpaused()) {\n    // Exceeded limit. Pause reading on the incoming stream.\n    VLOG(3) << \"Pausing egress for \" << *this;\n    writes_ = SocketState::PAUSED;\n  } else if (numActiveWrites_ == 0 && writesPaused()) {\n    // Dropped below limit. Resume reading on the incoming stream if needed.\n    VLOG(3) << \"Resuming egress for \" << *this;\n    writes_ = SocketState::UNPAUSED;\n  }\n}\n\nvoid\nHTTPSession::updateWriteBufSize(int64_t delta) {\n  // This is the sum of body bytes buffered within transactions_ and in\n  // the sock_'s write buffer.\n  delta += pendingWriteSizeDelta_;\n  pendingWriteSizeDelta_ = 0;\n  bool wasExceeded = egressLimitExceeded();\n  updatePendingWriteSize(delta);\n\n  if (egressLimitExceeded() && !wasExceeded) {\n    // Exceeded limit. Pause reading on the incoming stream.\n    if (inResume_) {\n      VLOG(3) << \"Pausing txn egress for \" << *this << \" deferred\";\n      pendingPause_ = true;\n    } else {\n      VLOG(3) << \"Pausing txn egress for \" << *this;\n      invokeOnAllTransactions(&HTTPTransaction::pauseEgress);\n    }\n  } else if (!egressLimitExceeded() && wasExceeded) {\n    // Dropped below limit. Resume reading on the incoming stream if needed.\n    if (inResume_) {\n      if (pendingPause_) {\n        VLOG(3) << \"Cancel deferred txn egress pause for \" << *this;\n        pendingPause_ = false;\n      } else {\n        VLOG(3) << \"Ignoring redundant resume for \" << *this;\n      }\n    } else {\n      VLOG(3) << \"Resuming txn egress for \" << *this;\n      resumeTransactions();\n    }\n  }\n}\n\nvoid\nHTTPSession::shutdownTransport(bool shutdownReads,\n                               bool shutdownWrites,\n                               const std::string& errorMsg) {\n  DestructorGuard guard(this);\n\n  // shutdowns not accounted for, shouldn't see any\n  setCloseReason(ConnectionCloseReason::UNKNOWN);\n\n  VLOG(4) << \"shutdown request for \" << *this << \": reads=\"\n          << shutdownReads << \" (currently \" << readsShutdown()\n          << \"), writes=\" << shutdownWrites << \" (currently \"\n          << writesShutdown() << \")\";\n\n  bool notifyEgressShutdown = false;\n  bool notifyIngressShutdown = false;\n\n  ProxygenError error;\n  if (!transportInfo_.sslError.empty()) {\n    error = kErrorSSL;\n  } else if (sock_->error()) {\n    VLOG(3) << \"shutdown request for \" << *this\n      << \" on bad socket. Shutting down writes too.\";\n    if (getConnectionCloseReason() == ConnectionCloseReason::IO_WRITE_ERROR) {\n      error = kErrorWrite;\n    } else {\n      error = kErrorConnectionReset;\n    }\n    shutdownWrites = true;\n  } else if (getConnectionCloseReason() == ConnectionCloseReason::TIMEOUT) {\n    error = kErrorTimeout;\n  } else {\n    error = kErrorEOF;\n  }\n\n  if (shutdownReads && !shutdownWrites && flowControlTimeout_.isScheduled()) {\n    // reads are dead and writes are blocked on a window update that will never\n    // come.  shutdown writes too.\n    VLOG(4) << *this << \" Converting read shutdown to read/write due to\"\n      \" flow control\";\n    shutdownWrites = true;\n  }\n\n  if (shutdownWrites && !writesShutdown()) {\n    if (codec_->generateGoaway(writeBuf_,\n                               codec_->getLastIncomingStreamID(),\n                               ErrorCode::NO_ERROR)) {\n      scheduleWrite();\n    }\n    if (!hasMoreWrites() &&\n        (transactions_.empty() || codec_->closeOnEgressComplete())) {\n      writes_ = SocketState::SHUTDOWN;\n      if (byteEventTracker_) {\n        byteEventTracker_->drainByteEvents();\n      }\n      if (resetAfterDrainingWrites_) {\n        VLOG(4) << *this << \" writes drained, sending RST\";\n        resetSocketOnShutdown_ = true;\n        shutdownReads = true;\n      } else {\n        VLOG(4) << *this << \" writes drained, closing\";\n        sock_->shutdownWriteNow();\n      }\n      notifyEgressShutdown = true;\n    } else if (!writesDraining_) {\n      writesDraining_ = true;\n      notifyEgressShutdown = true;\n    } // else writes are already draining; don't double notify\n  }\n\n  if (shutdownReads && !readsShutdown()) {\n    notifyIngressShutdown = true;\n    // TODO: send an RST if readBuf_ is non empty?\n    sock_->setReadCB(nullptr);\n    reads_ = SocketState::SHUTDOWN;\n    if (!transactions_.empty() && error == kErrorConnectionReset) {\n      if (infoCallback_ != nullptr) {\n        infoCallback_->onIngressError(*this, error);\n      }\n    } else if (error == kErrorEOF) {\n      // Report to the codec that the ingress stream has ended\n      codec_->onIngressEOF();\n      if (infoCallback_) {\n        infoCallback_->onIngressEOF();\n      }\n    }\n    // Once reads are shutdown the parser should stop processing\n    codec_->setParserPaused(true);\n  }\n\n  if (notifyIngressShutdown || notifyEgressShutdown) {\n    auto dir = (notifyIngressShutdown && notifyEgressShutdown)\n                   ? HTTPException::Direction::INGRESS_AND_EGRESS\n                   : (notifyIngressShutdown ? HTTPException::Direction::INGRESS\n                                            : HTTPException::Direction::EGRESS);\n    HTTPException ex(\n        dir,\n        folly::to<std::string>(\"Shutdown transport: \", getErrorString(error),\n                               errorMsg.empty() ? \"\" : \" \", errorMsg, \", \",\n                               getPeerAddress().describe()));\n    ex.setProxygenError(error);\n    invokeOnAllTransactions(&HTTPTransaction::onError, ex);\n  }\n\n  // Close the socket only after the onError() callback on the txns\n  // and handler has been detached.\n  checkForShutdown();\n}\n\nvoid HTTPSession::shutdownTransportWithReset(\n    ProxygenError errorCode,\n    const std::string& errorMsg) {\n  DestructorGuard guard(this);\n  VLOG(4) << \"shutdownTransportWithReset\";\n\n  if (!readsShutdown()) {\n    sock_->setReadCB(nullptr);\n    reads_ = SocketState::SHUTDOWN;\n  }\n\n  if (!writesShutdown()) {\n    writes_ = SocketState::SHUTDOWN;\n    IOBuf::destroy(writeBuf_.move());\n    while (!pendingWrites_.empty()) {\n      pendingWrites_.front().detach();\n      numActiveWrites_--;\n    }\n    VLOG(4) << *this << \" cancel write timer\";\n    writeTimeout_.cancelTimeout();\n    resetSocketOnShutdown_ = true;\n  }\n\n  errorOnAllTransactions(errorCode, errorMsg);\n  // drainByteEvents() can call detach(txn), which can in turn call\n  // shutdownTransport if we were already draining. To prevent double\n  // calling onError() to the transactions, we call drainByteEvents()\n  // after we've given the explicit error.\n  if (byteEventTracker_) {\n    byteEventTracker_->drainByteEvents();\n  }\n\n  // HTTPTransaction::onError could theoretically schedule more callbacks,\n  // so do this last.\n  if (isLoopCallbackScheduled()) {\n    cancelLoopCallback();\n  }\n  // onError() callbacks or drainByteEvents() could result in txns detaching\n  // due to CallbackGuards going out of scope. Close the socket only after\n  // the txns are detached.\n  checkForShutdown();\n}\n\nvoid\nHTTPSession::checkForShutdown() {\n  VLOG(10) << *this << \" checking for shutdown, readShutdown=\"\n           << readsShutdown() << \", writesShutdown=\" << writesShutdown()\n           << \", transaction set empty=\" << transactions_.empty();\n\n  // Two conditions are required to destroy the HTTPSession:\n  //   * All writes have been finished.\n  //   * There are no transactions remaining on the session.\n  if (writesShutdown() && transactions_.empty() &&\n      !isLoopCallbackScheduled()) {\n    VLOG(4) << \"destroying \" << *this;\n    sock_->setReadCB(nullptr);\n    auto asyncSocket = sock_->getUnderlyingTransport<folly::AsyncSocket>();\n    if (asyncSocket) {\n      asyncSocket->setBufferCallback(nullptr);\n    }\n    reads_ = SocketState::SHUTDOWN;\n    if (resetSocketOnShutdown_) {\n      sock_->closeWithReset();\n    } else {\n      sock_->closeNow();\n    }\n    destroy();\n  }\n}\n\nvoid\nHTTPSession::drain() {\n  if (!draining_) {\n    VLOG(4) << *this << \" draining\";\n    draining_ = true;\n    setCloseReason(ConnectionCloseReason::SHUTDOWN);\n\n    if (allTransactionsStarted()) {\n      drainImpl();\n    }\n    if (transactions_.empty() && isUpstream()) {\n      // We don't do this for downstream since we need to wait for\n      // inflight requests to arrive\n      VLOG(4) << *this << \" shutdown from drain\";\n      shutdownTransport(true, true);\n    }\n  } else {\n    VLOG(4) << *this << \" already draining\";\n  }\n}\n\nvoid HTTPSession::drainImpl() {\n  if (codec_->isReusable() || codec_->isWaitingToDrain()) {\n    setCloseReason(ConnectionCloseReason::SHUTDOWN);\n    // For HTTP/2, if we haven't started yet then we cannot send a GOAWAY frame\n    // since we haven't sent the initial SETTINGS frame. Defer sending that\n    // GOAWAY until the initial SETTINGS is sent.\n    if (started_) {\n      codec_->generateGoaway(writeBuf_,\n                             getGracefulGoawayAck(),\n                             ErrorCode::NO_ERROR);\n      scheduleWrite();\n    }\n  }\n}\n\nbool HTTPSession::shouldShutdown() const {\n  return draining_ &&\n    allTransactionsStarted() &&\n    (!codec_->supportsParallelRequests() ||\n     isUpstream() ||\n     !codec_->isReusable());\n}\n\nsize_t HTTPSession::sendPing() {\n  const size_t bytes = codec_->generatePingRequest(writeBuf_);\n  if (bytes) {\n    scheduleWrite();\n  }\n  return bytes;\n}\n\nHTTPCodec::StreamID HTTPSession::sendPriority(http2::PriorityUpdate pri) {\n  if (!codec_->supportsParallelRequests()) {\n    // For HTTP/1.1, don't call createStream()\n    return 0;\n  }\n  auto id = codec_->createStream();\n  sendPriority(id, pri);\n  return id;\n}\n\nsize_t HTTPSession::sendPriority(HTTPCodec::StreamID id,\n                                 http2::PriorityUpdate pri) {\n  auto res = sendPriorityImpl(id, pri);\n  txnEgressQueue_.addOrUpdatePriorityNode(id, pri);\n  return res;\n}\n\n\nsize_t HTTPSession::sendPriorityImpl(HTTPCodec::StreamID id,\n                                     http2::PriorityUpdate pri) {\n  CHECK_NE(id, 0);\n  const size_t bytes = codec_->generatePriority(\n    writeBuf_, id, std::make_tuple(pri.streamDependency,\n                                   pri.exclusive,\n                                   pri.weight));\n  if (bytes) {\n    scheduleWrite();\n  }\n  return bytes;\n}\n\nHTTPTransaction*\nHTTPSession::findTransaction(HTTPCodec::StreamID streamID) {\n  auto it = transactions_.find(streamID);\n  if (it == transactions_.end()) {\n    return nullptr;\n  } else {\n    return &it->second;\n  }\n}\n\nHTTPTransaction*\nHTTPSession::createTransaction(\n    HTTPCodec::StreamID streamID,\n    const folly::Optional<HTTPCodec::StreamID>& assocStreamID,\n    const folly::Optional<HTTPCodec::ExAttributes>& exAttributes,\n    const http2::PriorityUpdate& priority) {\n  if (!sock_->good() || transactions_.count(streamID)) {\n    // Refuse to add a transaction on a closing session or if a\n    // transaction of that ID already exists.\n    return nullptr;\n  }\n\n  if (transactions_.empty()) {\n    if (infoCallback_) {\n      infoCallback_->onActivateConnection(*this);\n    }\n    if (getConnectionManager()) {\n      getConnectionManager()->onActivated(*this);\n    }\n    HTTPSessionBase::onCreateTransaction();\n  }\n\n  auto matchPair = transactions_.emplace(\n    std::piecewise_construct,\n    std::forward_as_tuple(streamID),\n    std::forward_as_tuple(\n      codec_->getTransportDirection(), streamID, getNumTxnServed(), *this,\n      txnEgressQueue_, timeout_.getWheelTimer(), timeout_.getDefaultTimeout(),\n      sessionStats_,\n      codec_->supportsStreamFlowControl(),\n      initialReceiveWindow_,\n      getCodecSendWindowSize(),\n      priority,\n      assocStreamID,\n      exAttributes\n    ));\n\n  CHECK(matchPair.second) << \"Emplacement failed, despite earlier \"\n    \"existence check.\";\n\n  HTTPTransaction* txn = &matchPair.first->second;\n\n  if (isPrioritySampled()) {\n    txn->setPrioritySampled(true /* sampled */);\n  }\n\n  if (getNumTxnServed() > 0) {\n    auto stats = txn->getSessionStats();\n    if (stats != nullptr) {\n      stats->recordSessionReused();\n    }\n  }\n\n  VLOG(5) << *this << \" adding streamID=\" << txn->getID()\n          << \", liveTransactions_ was \" << liveTransactions_;\n\n  ++liveTransactions_;\n  incrementSeqNo();\n  txn->setReceiveWindow(receiveStreamWindowSize_);\n\n  if (isUpstream() && !txn->isPushed()) {\n    incrementOutgoingStreams();\n  // do not count towards MAX_CONCURRENT_STREAMS for PUSH_PROMISE\n  } else if (!(isDownstream() && txn->isPushed())) {\n    incomingStreams_++;\n  }\n\n  return txn;\n}\n\nvoid\nHTTPSession::incrementOutgoingStreams() {\n  outgoingStreams_++;\n  HTTPSessionBase::onNewOutgoingStream(outgoingStreams_);\n}\n\nvoid\nHTTPSession::onWriteSuccess(uint64_t bytesWritten) {\n  DestructorGuard dg(this);\n  bytesWritten_ += bytesWritten;\n  transportInfo_.totalBytes += bytesWritten;\n  CHECK(writeTimeout_.isScheduled());\n  if (pendingWrites_.empty()) {\n    VLOG(10) << \"Cancel write timer on last successful write\";\n    writeTimeout_.cancelTimeout();\n  } else {\n    VLOG(10) << \"Refresh write timer on writeSuccess\";\n    timeout_.scheduleTimeout(&writeTimeout_);\n  }\n\n  if (infoCallback_) {\n    infoCallback_->onWrite(*this, bytesWritten);\n  }\n\n  VLOG(5) << \"total bytesWritten_: \" << bytesWritten_;\n\n  // processByteEvents will return true if it has been replaced with another\n  // tracker in the middle and needs to be re-run.  Should happen at most\n  // once.  while with no body is intentional\n  while (byteEventTracker_ &&\n         byteEventTracker_->processByteEvents(\n           byteEventTracker_, bytesWritten_)) {} // pass\n\n  if ((!codec_->isReusable() || readsShutdown()) && (transactions_.empty())) {\n    if (!codec_->isReusable()) {\n      // Shouldn't happen unless there is a bug. This can only happen when\n      // someone calls shutdownTransport, but did not specify a reason before.\n      setCloseReason(ConnectionCloseReason::UNKNOWN);\n    }\n    VLOG(4) << *this << \" shutdown from onWriteSuccess\";\n    shutdownTransport(true, true);\n  }\n  numActiveWrites_--;\n  if (!inLoopCallback_) {\n    updateWriteCount();\n    // safe to resume here:\n    updateWriteBufSize(-folly::to<int64_t>(bytesWritten));\n    // PRIO_FIXME: this is done because of the corking business...\n    //             in the future we may want to have a pull model\n    //             whereby the socket asks us for a given amount of\n    //             data to send...\n    if (numActiveWrites_ == 0 && hasMoreWrites()) {\n      runLoopCallback();\n    }\n  }\n  onWriteCompleted();\n\n  if (egressBytesLimit_ > 0 && bytesWritten_ >= egressBytesLimit_) {\n    VLOG(4) << \"Egress limit reached, shutting down \"\n      \"session (egressed \" << bytesWritten_ << \", limit set to \"\n      << egressBytesLimit_ << \")\";\n    shutdownTransport(true, true);\n  }\n}\n\nvoid\nHTTPSession::onWriteError(size_t bytesWritten,\n                          const AsyncSocketException& ex) {\n  VLOG(4) << *this << \" write error: \" << ex.what();\n  if (infoCallback_) {\n    infoCallback_->onWrite(*this, bytesWritten);\n  }\n\n  auto sslEx = dynamic_cast<const folly::SSLException*>(&ex);\n  // Save the SSL error, if there was one.  It will be recorded later\n  if (sslEx && sslEx->getSSLError() == folly::SSLError::SSL_ERROR) {\n    transportInfo_.sslError = ex.what();\n  }\n\n  setCloseReason(ConnectionCloseReason::IO_WRITE_ERROR);\n  shutdownTransportWithReset(kErrorWrite, ex.what());\n}\n\nvoid\nHTTPSession::onWriteCompleted() {\n  if (!writesDraining_) {\n    return;\n  }\n\n  if (numActiveWrites_) {\n    return;\n  }\n\n  // Don't shutdown if there might be more writes\n  if (!pendingWrites_.empty()) {\n    return;\n  }\n\n  // All finished draining writes, so shut down the egress\n  shutdownTransport(false, true);\n}\n\nvoid HTTPSession::onSessionParseError(const HTTPException& error) {\n  VLOG(4) << *this << \" session layer parse error. Terminate the session.\";\n  if (error.hasCodecStatusCode()) {\n    std::unique_ptr<folly::IOBuf> errorMsg =\n      folly::IOBuf::copyBuffer(error.what());\n    codec_->generateGoaway(writeBuf_,\n                           codec_->getLastIncomingStreamID(),\n                           error.getCodecStatusCode(),\n                           isHTTP2CodecProtocol(codec_->getProtocol()) ?\n                           std::move(errorMsg) : nullptr);\n    scheduleWrite();\n  }\n  setCloseReason(ConnectionCloseReason::SESSION_PARSE_ERROR);\n  shutdownTransport(true, true);\n}\n\nvoid HTTPSession::onNewTransactionParseError(HTTPCodec::StreamID streamID,\n                                             const HTTPException& error) {\n  VLOG(4) << *this << \" parse error with new transaction\";\n  if (error.hasCodecStatusCode()) {\n    codec_->generateRstStream(writeBuf_, streamID, error.getCodecStatusCode());\n    scheduleWrite();\n  }\n  if (!codec_->isReusable()) {\n    // HTTP 1x codec does not support per stream abort so this will\n    // render the codec not reusable\n    setCloseReason(ConnectionCloseReason::SESSION_PARSE_ERROR);\n  }\n}\n\nvoid\nHTTPSession::pauseReads() {\n  // Make sure the parser is paused.  Note that if reads are shutdown\n  // before they are paused, we never make it past the if.\n  codec_->setParserPaused(true);\n  if (!readsUnpaused() ||\n      (codec_->supportsParallelRequests() &&\n       !ingressLimitExceeded())) {\n    return;\n  }\n  pauseReadsImpl();\n}\n\nvoid HTTPSession::pauseReadsImpl() {\n  VLOG(4) << *this << \": pausing reads\";\n  if (infoCallback_) {\n    infoCallback_->onIngressPaused(*this);\n  }\n  cancelTimeout();\n  sock_->setReadCB(nullptr);\n  reads_ = SocketState::PAUSED;\n}\n\nvoid\nHTTPSession::resumeReads() {\n  if (!readsPaused() ||\n      (codec_->supportsParallelRequests() &&\n       ingressLimitExceeded())) {\n    return;\n  }\n  resumeReadsImpl();\n}\n\nvoid HTTPSession::resumeReadsImpl() {\n  VLOG(4) << *this << \": resuming reads\";\n  resetTimeout();\n  reads_ = SocketState::UNPAUSED;\n  codec_->setParserPaused(false);\n  if (!isLoopCallbackScheduled()) {\n    sock_->getEventBase()->runInLoop(this);\n  }\n}\n\nbool\nHTTPSession::hasMoreWrites() const {\n  VLOG(10) << __PRETTY_FUNCTION__\n    << \" numActiveWrites_: \" << numActiveWrites_\n    << \" pendingWrites_.empty(): \" << pendingWrites_.empty()\n    << \" pendingWrites_.size(): \" << pendingWrites_.size()\n    << \" txnEgressQueue_.empty(): \" << txnEgressQueue_.empty();\n\n  return (numActiveWrites_ != 0) ||\n    !pendingWrites_.empty() || writeBuf_.front() ||\n    !txnEgressQueue_.empty();\n}\n\nvoid HTTPSession::errorOnAllTransactions(\n    ProxygenError err,\n    const std::string& errorMsg) {\n  std::vector<HTTPCodec::StreamID> ids;\n  for (const auto& txn: transactions_) {\n    ids.push_back(txn.first);\n  }\n  errorOnTransactionIds(ids, err, errorMsg);\n}\n\nvoid HTTPSession::errorOnTransactionIds(\n  const std::vector<HTTPCodec::StreamID>& ids,\n  ProxygenError err,\n  const std::string& errorMsg) {\n  std::string extraErrorMsg;\n  if (!errorMsg.empty()) {\n    extraErrorMsg = folly::to<std::string>(\". \", errorMsg);\n  }\n\n  for (auto id: ids) {\n    HTTPException ex(HTTPException::Direction::INGRESS_AND_EGRESS,\n      folly::to<std::string>(getErrorString(err),\n        \" on transaction id: \", id,\n        extraErrorMsg));\n    ex.setProxygenError(err);\n    errorOnTransactionId(id, std::move(ex));\n  }\n}\n\nvoid HTTPSession::errorOnTransactionId(\n    HTTPCodec::StreamID id,\n    HTTPException ex) {\n  auto txn = findTransaction(id);\n  if (txn != nullptr) {\n    txn->onError(std::move(ex));\n  }\n}\n\nvoid HTTPSession::resumeTransactions() {\n  CHECK(!inResume_);\n  inResume_ = true;\n  DestructorGuard g(this);\n  auto resumeFn = [] (HTTP2PriorityQueue&, HTTPCodec::StreamID,\n                      HTTPTransaction *txn, double) {\n    if (txn) {\n      txn->resumeEgress();\n    }\n    return false;\n  };\n  auto stopFn = [this] {\n    return (transactions_.empty() || egressLimitExceeded());\n  };\n\n  txnEgressQueue_.iterateBFS(resumeFn, stopFn, true /* all */);\n  inResume_ = false;\n  if (pendingPause_) {\n    VLOG(3) << \"Pausing txn egress for \" << *this;\n    pendingPause_ = false;\n    invokeOnAllTransactions(&HTTPTransaction::pauseEgress);\n  }\n}\n\nvoid HTTPSession::onConnectionSendWindowOpen() {\n  flowControlTimeout_.cancelTimeout();\n  // We can write more now. Schedule a write.\n  scheduleWrite();\n}\n\nvoid HTTPSession::onConnectionSendWindowClosed() {\n  if(!txnEgressQueue_.empty()) {\n    VLOG(4) << *this << \" session stalled by flow control\";\n    if (sessionStats_) {\n      sessionStats_->recordSessionStalled();\n    }\n  }\n  DCHECK(!flowControlTimeout_.isScheduled());\n  if (infoCallback_) {\n    infoCallback_->onFlowControlWindowClosed(*this);\n  }\n  auto timeout = flowControlTimeout_.getTimeoutDuration();\n  if (timeout != std::chrono::milliseconds(0)) {\n    timeout_.scheduleTimeout(&flowControlTimeout_, timeout);\n  } else {\n    timeout_.scheduleTimeout(&flowControlTimeout_);\n  }\n}\n\nHTTPCodec::StreamID HTTPSession::getGracefulGoawayAck() const {\n  if (!codec_->isReusable() || codec_->isWaitingToDrain()) {\n    // TODO: just track last stream ID inside HTTPSession since this logic\n    // is shared between HTTP/2 and SPDY\n    return codec_->getLastIncomingStreamID();\n  }\n  VLOG(4) << *this << \" getGracefulGoawayAck is reusable and not draining\";\n  // return the maximum possible stream id\n  return std::numeric_limits<int32_t>::max();\n}\n\nvoid HTTPSession::invalidStream(HTTPCodec::StreamID stream, ErrorCode code) {\n  if (!codec_->supportsParallelRequests()) {\n    LOG(ERROR) << \"Invalid stream on non-parallel codec.\";\n    return;\n  }\n\n  HTTPException err(HTTPException::Direction::INGRESS_AND_EGRESS,\n                    folly::to<std::string>(\"invalid stream=\", stream));\n  // TODO: Below line will change for HTTP/2 -- just call a const getter\n  // function for the status code.\n  err.setCodecStatusCode(code);\n  onError(stream, err, true);\n}\n\nvoid HTTPSession::onPingReplyLatency(int64_t latency) noexcept {\n  if (infoCallback_ && latency >= 0) {\n    infoCallback_->onPingReplySent(latency);\n  }\n}\n\nvoid HTTPSession::onDeleteAckEvent() noexcept {\n  if (readsShutdown()) {\n    shutdownTransport(true, transactions_.empty());\n  }\n}\n\nvoid HTTPSession::onEgressBuffered() {\n  if (infoCallback_) {\n    infoCallback_->onEgressBuffered(*this);\n  }\n}\n\nvoid HTTPSession::onEgressBufferCleared() {\n  if (infoCallback_) {\n    infoCallback_->onEgressBufferCleared(*this);\n  }\n}\n\nvoid HTTPSession::onReplaySafe() noexcept {\n  CHECK(sock_);\n  sock_->setReplaySafetyCallback(nullptr);\n\n  if (infoCallback_) {\n    infoCallback_->onFullHandshakeCompletion(*this);\n  }\n\n  for (auto callback : waitingForReplaySafety_) {\n    callback->onReplaySafe();\n  }\n  waitingForReplaySafety_.clear();\n}\n\nvoid HTTPSession::onLastByteEvent(\n    HTTPTransaction* txn, uint64_t eomOffset, bool eomTracked) noexcept {\n  if (!sock_->isEorTrackingEnabled() || !eomTracked) {\n    return;\n  }\n\n  if (eomOffset != sock_->getAppBytesWritten()) {\n    VLOG(2) << \"tracking ack to last app byte \" << eomOffset\n        << \" while \" << sock_->getAppBytesWritten()\n        << \" app bytes have already been written\";\n    return;\n  }\n\n  VLOG(5) << \"tracking raw last byte \" << sock_->getRawBytesWritten()\n          << \" while the app last byte is \" << eomOffset;\n\n  byteEventTracker_->addAckByteEvent(sock_->getRawBytesWritten(), txn);\n}\n\n\n\n} // proxygen\n"], "fixing_code": ["/*\n *  Copyright (c) 2015-present, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n *\n */\n#include <proxygen/lib/http/session/HTTPSession.h>\n\n#include <chrono>\n#include <fizz/protocol/AsyncFizzBase.h>\n#include <folly/Conv.h>\n#include <folly/CppAttributes.h>\n#include <folly/Random.h>\n#include <wangle/acceptor/ConnectionManager.h>\n#include <wangle/acceptor/SocketOptions.h>\n#include <proxygen/lib/http/HTTPHeaderSize.h>\n#include <proxygen/lib/http/codec/HTTPChecks.h>\n#include <proxygen/lib/http/codec/HTTP2Codec.h>\n#include <proxygen/lib/http/session/HTTPSessionController.h>\n#include <proxygen/lib/http/session/HTTPSessionStats.h>\n#include <folly/io/async/AsyncSSLSocket.h>\n#include <folly/io/Cursor.h>\n#include <folly/tracing/ScopedTraceSection.h>\n\nusing fizz::AsyncFizzBase;\nusing folly::AsyncSSLSocket;\nusing folly::AsyncSocket;\nusing folly::AsyncTransportWrapper;\nusing folly::AsyncTransport;\nusing folly::WriteFlags;\nusing folly::AsyncSocketException;\nusing folly::io::QueueAppender;\nusing folly::IOBuf;\nusing folly::IOBufQueue;\nusing folly::SocketAddress;\nusing wangle::TransportInfo;\nusing std::make_unique;\nusing std::pair;\nusing std::set;\nusing std::string;\nusing std::unique_ptr;\nusing std::vector;\n\nnamespace {\nstatic const uint32_t kMinReadSize = 1460;\nstatic const uint32_t kWriteReadyMax = 65536;\n\n// Lower = higher latency, better prioritization\n// Higher = lower latency, less prioritization\nstatic const uint32_t kMaxWritesPerLoop = 32;\n\nstatic constexpr folly::StringPiece kClientLabel =\n    \"EXPORTER HTTP CERTIFICATE client\";\nstatic constexpr folly::StringPiece kServerLabel =\n    \"EXPORTER HTTP CERTIFICATE server\";\n} // anonymous namespace\n\nnamespace proxygen {\n\nHTTPSession::WriteSegment::WriteSegment(\n    HTTPSession* session,\n    uint64_t length)\n  : session_(session),\n    length_(length) {\n}\n\nvoid\nHTTPSession::WriteSegment::remove() {\n  DCHECK(session_);\n  DCHECK(listHook.is_linked());\n  listHook.unlink();\n}\n\nvoid\nHTTPSession::WriteSegment::detach() {\n  remove();\n  session_ = nullptr;\n}\n\nvoid\nHTTPSession::WriteSegment::writeSuccess() noexcept {\n  // Unlink this write segment from the list before calling\n  // the session's onWriteSuccess() callback because, in the\n  // case where this is the last write for the connection,\n  // onWriteSuccess() looks for an empty write segment list\n  // as one of the criteria for shutting down the connection.\n  remove();\n\n  // session_ should never be nullptr for a successful write\n  // The session is only cleared after a write error or timeout, and all\n  // AsyncTransport write failures are fatal.  If session_ is nullptr at this\n  // point it means the AsyncTransport implementation is not failing\n  // subsequent writes correctly after an error.\n  session_->onWriteSuccess(length_);\n  delete this;\n}\n\nvoid\nHTTPSession::WriteSegment::writeErr(size_t bytesWritten,\n                                    const AsyncSocketException& ex) noexcept {\n  // After one segment fails to write, we clear the session_\n  // pointer in all subsequent write segments, so we ignore their\n  // writeError() callbacks.\n  if (session_) {\n    remove();\n    session_->onWriteError(bytesWritten, ex);\n  }\n  delete this;\n}\n\nHTTPSession::HTTPSession(\n  folly::HHWheelTimer* transactionTimeouts,\n  AsyncTransportWrapper::UniquePtr sock,\n  const SocketAddress& localAddr,\n  const SocketAddress& peerAddr,\n  HTTPSessionController* controller,\n  unique_ptr<HTTPCodec> codec,\n  const TransportInfo& tinfo,\n  InfoCallback* infoCallback):\n    HTTPSession(WheelTimerInstance(transactionTimeouts), std::move(sock),\n        localAddr, peerAddr, controller, std::move(codec),\n        tinfo, infoCallback) {\n}\n\nHTTPSession::HTTPSession(\n  const WheelTimerInstance& timeout,\n  AsyncTransportWrapper::UniquePtr sock,\n  const SocketAddress& localAddr,\n  const SocketAddress& peerAddr,\n  HTTPSessionController* controller,\n  unique_ptr<HTTPCodec> codec,\n  const TransportInfo& tinfo,\n  InfoCallback* infoCallback):\n    HTTPSessionBase(localAddr, peerAddr, controller, tinfo, infoCallback,\n                    std::move(codec)),\n    writeTimeout_(this),\n    txnEgressQueue_(isHTTP2CodecProtocol(codec_->getProtocol()) ?\n                    WheelTimerInstance(timeout) :\n                    WheelTimerInstance()),\n    sock_(std::move(sock)),\n    timeout_(timeout),\n    draining_(false),\n    started_(false),\n    writesDraining_(false),\n    resetAfterDrainingWrites_(false),\n    ingressError_(false),\n    flowControlTimeout_(this),\n    drainTimeout_(this),\n    reads_(SocketState::PAUSED),\n    writes_(SocketState::UNPAUSED),\n    ingressUpgraded_(false),\n    resetSocketOnShutdown_(false),\n    inLoopCallback_(false),\n    inResume_(false),\n    pendingPause_(false) {\n  byteEventTracker_ = std::make_shared<ByteEventTracker>(this);\n  initialReceiveWindow_ = receiveStreamWindowSize_ =\n    receiveSessionWindowSize_ = codec_->getDefaultWindowSize();\n\n  codec_.add<HTTPChecks>();\n\n  setupCodec();\n\n  nextEgressResults_.reserve(maxConcurrentIncomingStreams_);\n\n  if (infoCallback_) {\n    infoCallback_->onCreate(*this);\n  }\n\n  auto controllerPtr = getController();\n  if (controllerPtr) {\n    flowControlTimeout_.setTimeoutDuration(\n      controllerPtr->getSessionFlowControlTimeout());\n  }\n  attachToSessionController();\n\n  if (!sock_->isReplaySafe()) {\n    sock_->setReplaySafetyCallback(this);\n  }\n}\n\nuint32_t HTTPSession::getCertAuthSettingVal() {\n  uint32_t certAuthSettingVal = 0;\n  constexpr uint16_t settingLen = 4;\n  std::unique_ptr<folly::IOBuf> ekm;\n  folly::StringPiece label;\n  if (isUpstream()) {\n    label = kClientLabel;\n  } else {\n    label = kServerLabel;\n  }\n  auto fizzBase = getTransport()->getUnderlyingTransport<AsyncFizzBase>();\n  if (fizzBase) {\n    ekm = fizzBase->getEkm(label, nullptr, settingLen);\n  } else {\n    VLOG(4) << \"Underlying transport does not support secondary \"\n               \"authentication.\";\n    return certAuthSettingVal;\n  }\n  if (ekm && ekm->computeChainDataLength() == settingLen) {\n    folly::io::Cursor cursor(ekm.get());\n    uint32_t ekmVal = cursor.readBE<uint32_t>();\n    certAuthSettingVal = (ekmVal & 0x3fffffff) | 0x80000000;\n  }\n  return certAuthSettingVal;\n}\n\nbool HTTPSession::verifyCertAuthSetting(uint32_t value) {\n  uint32_t certAuthSettingVal = 0;\n  constexpr uint16_t settingLen = 4;\n  std::unique_ptr<folly::IOBuf> ekm;\n  folly::StringPiece label;\n  if (isUpstream()) {\n    label = kServerLabel;\n  } else {\n    label = kClientLabel;\n  }\n  auto fizzBase = getTransport()->getUnderlyingTransport<AsyncFizzBase>();\n  if (fizzBase) {\n    ekm = fizzBase->getEkm(label, nullptr, settingLen);\n  } else {\n    VLOG(4) << \"Underlying transport does not support secondary \"\n               \"authentication.\";\n    return false;\n  }\n  if (ekm && ekm->computeChainDataLength() == settingLen) {\n    folly::io::Cursor cursor(ekm.get());\n    uint32_t ekmVal = cursor.readBE<uint32_t>();\n    certAuthSettingVal = (ekmVal & 0x3fffffff) | 0x80000000;\n  } else {\n    return false;\n  }\n  if (certAuthSettingVal == value) {\n    return true;\n  } else {\n    return false;\n  }\n}\n\nvoid HTTPSession::setupCodec() {\n  if (!codec_->supportsParallelRequests()) {\n    // until we support upstream pipelining\n    maxConcurrentIncomingStreams_ = 1;\n    maxConcurrentOutgoingStreamsRemote_ = isDownstream() ? 0 : 1;\n  }\n\n  // If a secondary authentication manager is configured for this session, set\n  // the SETTINGS_HTTP_CERT_AUTH to indicate support for HTTP-layer certificate\n  // authentication.\n  uint32_t certAuthSettingVal = 0;\n  if (secondAuthManager_) {\n    certAuthSettingVal = getCertAuthSettingVal();\n  }\n  HTTPSettings* settings = codec_->getEgressSettings();\n  if (settings) {\n    settings->setSetting(SettingsId::MAX_CONCURRENT_STREAMS,\n                         maxConcurrentIncomingStreams_);\n    if (certAuthSettingVal != 0) {\n      settings->setSetting(SettingsId::SETTINGS_HTTP_CERT_AUTH,\n                           certAuthSettingVal);\n    }\n  }\n  codec_->generateConnectionPreface(writeBuf_);\n\n  if (codec_->supportsSessionFlowControl() && !connFlowControl_) {\n    connFlowControl_ = new FlowControlFilter(*this, writeBuf_, codec_.call());\n    codec_.addFilters(std::unique_ptr<FlowControlFilter>(connFlowControl_));\n    // if we really support switching from spdy <-> h2, we need to update\n    // existing flow control filter\n  }\n\n  codec_.setCallback(this);\n}\n\nHTTPSession::~HTTPSession() {\n  VLOG(4) << *this << \" closing\";\n\n  CHECK(transactions_.empty());\n  txnEgressQueue_.dropPriorityNodes();\n  CHECK(txnEgressQueue_.empty());\n  DCHECK(!sock_->getReadCallback());\n\n  if (writeTimeout_.isScheduled()) {\n    writeTimeout_.cancelTimeout();\n  }\n\n  if (flowControlTimeout_.isScheduled()) {\n    flowControlTimeout_.cancelTimeout();\n  }\n\n  runDestroyCallbacks();\n}\n\nvoid HTTPSession::startNow() {\n  CHECK(!started_);\n  started_ = true;\n  codec_->generateSettings(writeBuf_);\n  if (connFlowControl_) {\n    connFlowControl_->setReceiveWindowSize(writeBuf_,\n                                           receiveSessionWindowSize_);\n  }\n  // For HTTP/2 if we are currently draining it means we got notified to\n  // shutdown before we sent a SETTINGS frame, so we defer sending a GOAWAY\n  // util we've started and sent SETTINGS.\n  if (draining_) {\n    codec_->generateGoaway(writeBuf_,\n                           getGracefulGoawayAck(),\n                           ErrorCode::NO_ERROR);\n  }\n  scheduleWrite();\n  resumeReads();\n}\n\nvoid HTTPSession::setByteEventTracker(\n  std::shared_ptr<ByteEventTracker> byteEventTracker) {\n  if (byteEventTracker && byteEventTracker_) {\n    byteEventTracker->absorb(std::move(*byteEventTracker_));\n  }\n  byteEventTracker_ = byteEventTracker;\n  if (byteEventTracker_) {\n    byteEventTracker_->setCallback(this);\n    byteEventTracker_->setTTLBAStats(sessionStats_);\n  }\n}\n\nvoid HTTPSession::setSessionStats(HTTPSessionStats* stats) {\n  HTTPSessionBase::setSessionStats(stats);\n  if (byteEventTracker_) {\n    byteEventTracker_->setTTLBAStats(stats);\n  }\n}\n\nvoid HTTPSession::setFlowControl(size_t initialReceiveWindow,\n                                 size_t receiveStreamWindowSize,\n                                 size_t receiveSessionWindowSize) {\n  CHECK(!started_);\n  initialReceiveWindow_ = initialReceiveWindow;\n  receiveStreamWindowSize_ = receiveStreamWindowSize;\n  receiveSessionWindowSize_ = receiveSessionWindowSize;\n  HTTPSessionBase::setReadBufferLimit(receiveSessionWindowSize);\n  HTTPSettings* settings = codec_->getEgressSettings();\n  if (settings) {\n    settings->setSetting(SettingsId::INITIAL_WINDOW_SIZE,\n                         initialReceiveWindow_);\n  }\n}\n\nvoid HTTPSession::setEgressSettings(const SettingsList& inSettings) {\n  VLOG_IF(4, started_) << \"Must flush egress settings to peer\";\n  HTTPSettings* settings = codec_->getEgressSettings();\n  if (settings) {\n    for (const auto& setting: inSettings) {\n      settings->setSetting(setting.id, setting.value);\n    }\n  }\n}\n\nvoid HTTPSession::setMaxConcurrentIncomingStreams(uint32_t num) {\n  CHECK(!started_);\n  if (codec_->supportsParallelRequests()) {\n    maxConcurrentIncomingStreams_ = num;\n    HTTPSettings* settings = codec_->getEgressSettings();\n    if (settings) {\n      settings->setSetting(SettingsId::MAX_CONCURRENT_STREAMS,\n                           maxConcurrentIncomingStreams_);\n    }\n  }\n}\n\nvoid HTTPSession::setEgressBytesLimit(uint64_t bytesLimit) {\n  CHECK(!started_);\n  egressBytesLimit_ = bytesLimit;\n}\n\nvoid\nHTTPSession::readTimeoutExpired() noexcept {\n  VLOG(3) << \"session-level timeout on \" << *this;\n\n  if (liveTransactions_ != 0) {\n    // There's at least one open transaction with a read timeout scheduled.\n    // We got here because the session timeout == the transaction timeout.\n    // Ignore, since the transaction is going to timeout very soon.\n    VLOG(4) << *this <<\n        \"ignoring session timeout, transaction timeout imminent\";\n    resetTimeout();\n    return;\n  }\n\n  if (!transactions_.empty()) {\n    // There are one or more transactions, but none of them are live.\n    // That's valid if they've all received their full ingress messages\n    // and are waiting for their Handlers to process those messages.\n    VLOG(4) << *this <<\n        \"ignoring session timeout, no transactions awaiting reads\";\n    resetTimeout();\n    return;\n  }\n\n  VLOG(4) << *this << \" Timeout with nothing pending\";\n\n  setCloseReason(ConnectionCloseReason::TIMEOUT);\n  auto controller = getController();\n  if (controller) {\n    timeout_.scheduleTimeout(&drainTimeout_,\n                             controller->getGracefulShutdownTimeout());\n  }\n  notifyPendingShutdown();\n}\n\nvoid\nHTTPSession::writeTimeoutExpired() noexcept {\n  VLOG(4) << \"Write timeout for \" << *this;\n\n  CHECK(!pendingWrites_.empty());\n  DestructorGuard g(this);\n\n  setCloseReason(ConnectionCloseReason::TIMEOUT);\n  shutdownTransportWithReset(kErrorWriteTimeout);\n}\n\nvoid\nHTTPSession::flowControlTimeoutExpired() noexcept {\n  VLOG(4) << \"Flow control timeout for \" << *this;\n\n  DestructorGuard g(this);\n\n  setCloseReason(ConnectionCloseReason::TIMEOUT);\n  shutdownTransport(true, true);\n}\n\nvoid\nHTTPSession::describe(std::ostream& os) const {\n  os << \"proto=\" << getCodecProtocolString(codec_->getProtocol());\n  if (isDownstream()) {\n    os << \", UA=\" << codec_->getUserAgent()\n       << \", downstream=\" << getPeerAddress() << \", \" << getLocalAddress()\n       << \"=local\";\n  } else {\n    os << \", local=\" << getLocalAddress() << \", \" << getPeerAddress()\n       << \"=upstream\";\n  }\n}\n\nbool\nHTTPSession::isBusy() const {\n  return !transactions_.empty() || codec_->isBusy();\n}\n\nvoid\nHTTPSession::notifyPendingEgress() noexcept {\n  scheduleWrite();\n}\n\nvoid\nHTTPSession::notifyPendingShutdown() {\n  VLOG(4) << *this << \" notified pending shutdown\";\n  drain();\n}\n\nvoid\nHTTPSession::closeWhenIdle() {\n  // If drain() already called, this is a noop\n  drain();\n  // Generate the second GOAWAY now. No-op if second GOAWAY already sent.\n  if (codec_->generateGoaway(writeBuf_,\n                             codec_->getLastIncomingStreamID(),\n                             ErrorCode::NO_ERROR)) {\n    scheduleWrite();\n  }\n  if (!isBusy() && !hasMoreWrites()) {\n    // if we're already idle, close now\n    dropConnection();\n  }\n}\n\nvoid HTTPSession::immediateShutdown() {\n  if (isLoopCallbackScheduled()) {\n    cancelLoopCallback();\n  }\n  if (shutdownTransportCb_) {\n    shutdownTransportCb_.reset();\n  }\n  // checkForShutdown only closes the connection if these conditions are true\n  DCHECK(writesShutdown());\n  DCHECK(transactions_.empty());\n  checkForShutdown();\n}\n\nvoid\nHTTPSession::dropConnection() {\n  VLOG(4) << \"dropping \" << *this;\n  if (!sock_ || (readsShutdown() && writesShutdown())) {\n    VLOG(4) << *this << \" already shutdown\";\n    return;\n  }\n\n  setCloseReason(ConnectionCloseReason::SHUTDOWN);\n  if (transactions_.empty() && !hasMoreWrites()) {\n    DestructorGuard dg(this);\n    shutdownTransport(true, true);\n    // shutdownTransport might have generated a write (goaway)\n    // If so, writes will not be shutdown, so fall through to\n    // shutdownTransportWithReset.\n    if (readsShutdown() && writesShutdown()) {\n      immediateShutdown();\n      return;\n    }\n  }\n  shutdownTransportWithReset(kErrorDropped);\n}\n\nvoid HTTPSession::dumpConnectionState(uint8_t /*loglevel*/) {}\n\nbool HTTPSession::isUpstream() const {\n  return codec_->getTransportDirection() == TransportDirection::UPSTREAM;\n}\n\nbool HTTPSession::isDownstream() const {\n  return codec_->getTransportDirection() == TransportDirection::DOWNSTREAM;\n}\n\nvoid\nHTTPSession::getReadBuffer(void** buf, size_t* bufSize) {\n  FOLLY_SCOPED_TRACE_SECTION(\"HTTPSession - getReadBuffer\");\n  pair<void*,uint32_t> readSpace =\n    readBuf_.preallocate(kMinReadSize, HTTPSessionBase::maxReadBufferSize_);\n  *buf = readSpace.first;\n  *bufSize = readSpace.second;\n}\n\nvoid\nHTTPSession::readDataAvailable(size_t readSize) noexcept {\n  FOLLY_SCOPED_TRACE_SECTION(\n      \"HTTPSession - readDataAvailable\", \"readSize\", readSize);\n  VLOG(10) << \"read completed on \" << *this << \", bytes=\" << readSize;\n\n  DestructorGuard dg(this);\n  resetTimeout();\n  readBuf_.postallocate(readSize);\n\n  if (infoCallback_) {\n    infoCallback_->onRead(*this, readSize);\n  }\n\n  processReadData();\n}\n\nbool\nHTTPSession::isBufferMovable() noexcept {\n  return true;\n}\n\nvoid\nHTTPSession::readBufferAvailable(std::unique_ptr<IOBuf> readBuf) noexcept {\n  size_t readSize = readBuf->computeChainDataLength();\n  FOLLY_SCOPED_TRACE_SECTION(\n      \"HTTPSession - readBufferAvailable\", \"readSize\", readSize);\n  VLOG(5) << \"read completed on \" << *this << \", bytes=\" << readSize;\n\n  DestructorGuard dg(this);\n  resetTimeout();\n  readBuf_.append(std::move(readBuf));\n\n  if (infoCallback_) {\n    infoCallback_->onRead(*this, readSize);\n  }\n\n  processReadData();\n}\n\nvoid\nHTTPSession::processReadData() {\n  FOLLY_SCOPED_TRACE_SECTION(\"HTTPSession - processReadData\");\n  // skip any empty IOBufs before feeding CODEC.\n  while (readBuf_.front() != nullptr && readBuf_.front()->length() == 0) {\n    readBuf_.pop_front();\n  }\n\n  // Pass the ingress data through the codec to parse it. The codec\n  // will invoke various methods of the HTTPSession as callbacks.\n  const IOBuf* currentReadBuf;\n  // It's possible for the last buffer in a chain to be empty here.\n  // AsyncTransport saw fd activity so asked for a read buffer, but it was\n  // SSL traffic and not enough to decrypt a whole record.  Later we invoke\n  // this function from the loop callback.\n  while (!ingressError_ &&\n         readsUnpaused() &&\n         ((currentReadBuf = readBuf_.front()) != nullptr &&\n          currentReadBuf->length() != 0)) {\n    // We're about to parse, make sure the parser is not paused\n    codec_->setParserPaused(false);\n    size_t bytesParsed = codec_->onIngress(*currentReadBuf);\n    if (bytesParsed == 0) {\n      // If the codec didn't make any progress with current input, we\n      // better get more.\n      break;\n    }\n    readBuf_.trimStart(bytesParsed);\n  }\n}\n\nvoid\nHTTPSession::readEOF() noexcept {\n  DestructorGuard guard(this);\n  VLOG(4) << \"EOF on \" << *this;\n  // for SSL only: error without any bytes from the client might happen\n  // due to client-side issues with the SSL cert. Note that it can also\n  // happen if the client sends a SPDY frame header but no body.\n  if (infoCallback_\n      && transportInfo_.secure && getNumTxnServed() == 0 && readBuf_.empty()) {\n    infoCallback_->onIngressError(*this, kErrorClientSilent);\n  }\n\n  // Shut down reads, and also shut down writes if there are no\n  // transactions.  (If there are active transactions, leave the\n  // write side of the socket open so those transactions can\n  // finish generating responses.)\n  setCloseReason(ConnectionCloseReason::READ_EOF);\n  shutdownTransport(true, transactions_.empty());\n}\n\nvoid\nHTTPSession::readErr(const AsyncSocketException& ex) noexcept {\n  DestructorGuard guard(this);\n  VLOG(4) << \"read error on \" << *this << \": \" << ex.what();\n\n  auto sslEx = dynamic_cast<const folly::SSLException*>(&ex);\n  if (infoCallback_ && sslEx) {\n    if (sslEx->getSSLError() == folly::SSLError::CLIENT_RENEGOTIATION) {\n      infoCallback_->onIngressError(*this, kErrorClientRenegotiation);\n    }\n  }\n\n  // We're definitely finished reading. Don't close the write side\n  // of the socket if there are outstanding transactions, though.\n  // Instead, give the transactions a chance to produce any remaining\n  // output.\n  if (sslEx && sslEx->getSSLError() == folly::SSLError::SSL_ERROR) {\n    transportInfo_.sslError = ex.what();\n  }\n  setCloseReason(ConnectionCloseReason::IO_READ_ERROR);\n  shutdownTransport(true, transactions_.empty(), ex.what());\n}\n\nHTTPTransaction*\nHTTPSession::newPushedTransaction(\n  HTTPCodec::StreamID assocStreamId,\n  HTTPTransaction::PushHandler* handler) noexcept {\n  if (!codec_->supportsPushTransactions()) {\n    return nullptr;\n  }\n  CHECK(isDownstream());\n  CHECK_NOTNULL(handler);\n  if (draining_ || (outgoingStreams_ >= maxConcurrentOutgoingStreamsRemote_)) {\n    // This session doesn't support any more push transactions\n    // This could be an actual problem - since a single downstream SPDY session\n    // might be connected to N upstream hosts, each of which send M pushes,\n    // which exceeds the limit.\n    // should we queue?\n    return nullptr;\n  }\n\n  HTTPTransaction* txn = createTransaction(codec_->createStream(),\n                                           assocStreamId,\n                                           HTTPCodec::NoExAttributes);\n  if (!txn) {\n    return nullptr;\n  }\n\n  DestructorGuard dg(this);\n  auto txnID = txn->getID();\n  txn->setHandler(handler);\n  setNewTransactionPauseState(txnID);\n  return txn;\n}\n\nHTTPTransaction* FOLLY_NULLABLE\nHTTPSession::newExTransaction(\n    HTTPTransaction::Handler* handler,\n    HTTPCodec::StreamID controlStream,\n    bool unidirectional) noexcept {\n  CHECK(handler && controlStream > 0);\n  auto eSettings = codec_->getEgressSettings();\n  if (!eSettings || !eSettings->getSetting(SettingsId::ENABLE_EX_HEADERS, 0)) {\n    LOG(ERROR) << getCodecProtocolString(codec_->getProtocol())\n               << \" does not support ExTransaction\";\n    return nullptr;\n  }\n  if (draining_ || (outgoingStreams_ >= maxConcurrentOutgoingStreamsRemote_)) {\n    LOG(ERROR) << \"cannot support any more transactions in \" << *this;\n    return nullptr;\n  }\n\n  DCHECK(started_);\n  HTTPTransaction* txn =\n    createTransaction(codec_->createStream(),\n                      HTTPCodec::NoStream,\n                      HTTPCodec::ExAttributes(controlStream, unidirectional));\n  if (!txn) {\n    return nullptr;\n  }\n\n  DestructorGuard dg(this);\n  txn->setHandler(handler);\n  setNewTransactionPauseState(txn->getID());\n  return txn;\n}\n\nsize_t HTTPSession::getCodecSendWindowSize() const {\n  const HTTPSettings* settings = codec_->getIngressSettings();\n  if (settings) {\n    return settings->getSetting(SettingsId::INITIAL_WINDOW_SIZE,\n                                codec_->getDefaultWindowSize());\n  }\n  return codec_->getDefaultWindowSize();\n}\n\nvoid\nHTTPSession::setNewTransactionPauseState(HTTPCodec::StreamID streamID) {\n  if (!egressLimitExceeded()) {\n    return;\n  }\n\n  auto txn = findTransaction(streamID);\n  if (txn) {\n    // If writes are paused, start this txn off in the egress paused state\n    VLOG(4) << *this << \" starting streamID=\" << txn->getID()\n            << \" egress paused, numActiveWrites_=\" << numActiveWrites_;\n    txn->pauseEgress();\n  }\n}\n\nhttp2::PriorityUpdate\nHTTPSession::getMessagePriority(const HTTPMessage* msg) {\n  http2::PriorityUpdate h2Pri = http2::DefaultPriority;\n\n  // if HTTP2 priorities are enabled, get them from the message\n  // and ignore otherwise\n  if (getHTTP2PrioritiesEnabled() && msg) {\n    auto res = msg->getHTTP2Priority();\n    if (res) {\n      h2Pri.streamDependency = std::get<0>(*res);\n      h2Pri.exclusive = std::get<1>(*res);\n      h2Pri.weight = std::get<2>(*res);\n    } else {\n      // HTTPMessage with setPriority called explicitly\n      h2Pri.streamDependency =\n        codec_->mapPriorityToDependency(msg->getPriority());\n    }\n  }\n  return h2Pri;\n}\n\nvoid\nHTTPSession::onMessageBegin(HTTPCodec::StreamID streamID, HTTPMessage* msg) {\n  VLOG(4) << \"processing new msg streamID=\" << streamID << \" \" << *this;\n  if (infoCallback_) {\n    infoCallback_->onRequestBegin(*this);\n  }\n\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (txn) {\n    if (isDownstream() && txn->isPushed()) {\n      // Push streams are unidirectional (half-closed). If the downstream\n      // attempts to send ingress, abort with STREAM_CLOSED error.\n      HTTPException ex(HTTPException::Direction::INGRESS_AND_EGRESS,\n                       \"Downstream attempts to send ingress, abort.\");\n      ex.setCodecStatusCode(ErrorCode::STREAM_CLOSED);\n      txn->onError(ex);\n    }\n    return;  // If this transaction is already registered, no need to add it now\n  }\n\n  http2::PriorityUpdate messagePriority = getMessagePriority(msg);\n  txn = createTransaction(streamID, HTTPCodec::NoStream,\n                          HTTPCodec::NoExAttributes, messagePriority);\n  if (!txn) {\n    return;  // This could happen if the socket is bad.\n  }\n\n  if (!codec_->supportsParallelRequests() && getPipelineStreamCount() > 1) {\n    // The previous transaction hasn't completed yet. Pause reads until\n    // it completes; this requires pausing both transactions.\n\n    // HTTP/1.1 pipeline is detected, and which is incompactible with\n    // ByteEventTracker. Drain all the ByteEvents\n    CHECK(byteEventTracker_);\n    byteEventTracker_->drainByteEvents();\n\n    // drainByteEvents() may detach txn(s). Don't pause read if one txn left\n    if (getPipelineStreamCount() < 2) {\n      DCHECK(readsUnpaused());\n      return;\n    }\n\n    // There must be at least two transactions (we just checked). The previous\n    // txns haven't completed yet. Pause reads until they complete\n    DCHECK_GE(transactions_.size(), 2);\n    for (auto it = ++transactions_.rbegin(); it != transactions_.rend(); ++it) {\n      DCHECK(it->second.isIngressEOMSeen());\n      it->second.pauseIngress();\n    }\n    transactions_.rbegin()->second.pauseIngress();\n    DCHECK_EQ(liveTransactions_, 0);\n    DCHECK(readsPaused());\n  }\n}\n\nvoid\nHTTPSession::onPushMessageBegin(HTTPCodec::StreamID streamID,\n                                HTTPCodec::StreamID assocStreamID,\n                                HTTPMessage* msg) {\n  VLOG(4) << \"processing new push promise streamID=\" << streamID\n          << \" on assocStreamID=\" << assocStreamID << \" \" << *this;\n  if (infoCallback_) {\n    infoCallback_->onRequestBegin(*this);\n  }\n  if (assocStreamID == 0) {\n    VLOG(2) << \"push promise \" << streamID << \" should be associated with \"\n            << \"an active stream=\" << assocStreamID << \" \" << *this;\n    invalidStream(streamID, ErrorCode::PROTOCOL_ERROR);\n    return;\n  }\n\n  if (isDownstream()) {\n    VLOG(2) << \"push promise cannot be sent to upstream \" << *this;\n    invalidStream(streamID, ErrorCode::PROTOCOL_ERROR);\n    return;\n  }\n\n  HTTPTransaction* assocTxn = findTransaction(assocStreamID);\n  if (!assocTxn || assocTxn->isIngressEOMSeen()) {\n    VLOG(2) << \"cannot find the assocTxn=\" << assocTxn\n            << \", or assoc stream is already closed by upstream\" << *this;\n    invalidStream(streamID, ErrorCode::PROTOCOL_ERROR);\n    return;\n  }\n\n  http2::PriorityUpdate messagePriority = getMessagePriority(msg);\n  auto txn = createTransaction(streamID, assocStreamID,\n                               HTTPCodec::NoExAttributes, messagePriority);\n  if (!txn) {\n    return;  // This could happen if the socket is bad.\n  }\n\n  if (!assocTxn->onPushedTransaction(txn)) {\n    VLOG(1) << \"Failed to add pushed txn \" << streamID\n            << \" to assoc txn \" << assocStreamID << \" on \" << *this;\n    HTTPException ex(HTTPException::Direction::INGRESS_AND_EGRESS,\n      folly::to<std::string>(\"Failed to add pushed transaction \", streamID));\n    ex.setCodecStatusCode(ErrorCode::REFUSED_STREAM);\n    onError(streamID, ex, true);\n  }\n}\n\nvoid\nHTTPSession::onExMessageBegin(HTTPCodec::StreamID streamID,\n                              HTTPCodec::StreamID controlStream,\n                              bool unidirectional,\n                              HTTPMessage* msg) {\n  VLOG(4) << \"processing new ExMessage=\" << streamID\n          << \" on controlStream=\" << controlStream << \", \" << *this;\n  if (infoCallback_) {\n    infoCallback_->onRequestBegin(*this);\n  }\n  if (controlStream == 0) {\n    LOG(ERROR) << \"ExMessage=\" << streamID << \" should have an active control \"\n               << \"stream=\" << controlStream << \", \" << *this;\n    invalidStream(streamID, ErrorCode::PROTOCOL_ERROR);\n    return;\n  }\n\n  HTTPTransaction* controlTxn = findTransaction(controlStream);\n  if (!controlTxn) {\n    // control stream is broken, or remote sends a bogus stream id\n    LOG(ERROR) << \"no control stream=\" << controlStream << \", \" << *this;\n    return;\n  }\n\n  http2::PriorityUpdate messagePriority = getMessagePriority(msg);\n  auto txn = createTransaction(streamID,\n                               HTTPCodec::NoStream,\n                               HTTPCodec::ExAttributes(controlStream,\n                                                       unidirectional),\n                               messagePriority);\n  if (!txn) {\n    return;  // This could happen if the socket is bad.\n  }\n  // control stream may be paused if the upstream is not ready yet\n  if (controlTxn->isIngressPaused()) {\n    txn->pauseIngress();\n  }\n}\n\nvoid\nHTTPSession::onHeadersComplete(HTTPCodec::StreamID streamID,\n                               unique_ptr<HTTPMessage> msg) {\n  // The codec's parser detected the end of an ingress message's\n  // headers.\n  VLOG(4) << \"processing ingress headers complete for \" << *this <<\n      \", streamID=\" << streamID;\n\n  if (!codec_->isReusable()) {\n    setCloseReason(ConnectionCloseReason::REQ_NOTREUSABLE);\n  }\n\n  if (infoCallback_) {\n    infoCallback_->onIngressMessage(*this, *msg.get());\n  }\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    invalidStream(streamID);\n    return;\n  }\n\n  const char* sslCipher =\n      transportInfo_.sslCipher ? transportInfo_.sslCipher->c_str() : nullptr;\n  msg->setSecureInfo(transportInfo_.sslVersion, sslCipher);\n  msg->setSecure(transportInfo_.secure);\n\n  auto controlStreamID = txn->getControlStream();\n  if (controlStreamID) {\n    auto controlTxn = findTransaction(*controlStreamID);\n    if (!controlTxn) {\n      VLOG(2) << \"txn=\" << streamID << \" with a broken controlTxn=\"\n              << *controlStreamID << \" \" << *this;\n      HTTPException ex(\n          HTTPException::Direction::INGRESS_AND_EGRESS,\n          folly::to<std::string>(\"broken controlTxn \", *controlStreamID));\n      onError(streamID, ex, true);\n      return;\n    }\n\n    // Call onExTransaction() only for requests.\n    if (txn->isRemoteInitiated() && !controlTxn->onExTransaction(txn)) {\n      VLOG(2) << \"Failed to add exTxn=\" << streamID\n              << \" to controlTxn=\" << *controlStreamID << \", \" << *this;\n      HTTPException ex(\n          HTTPException::Direction::INGRESS_AND_EGRESS,\n          folly::to<std::string>(\"Fail to add exTxn \", streamID));\n      ex.setCodecStatusCode(ErrorCode::REFUSED_STREAM);\n      onError(streamID, ex, true);\n      return;\n    }\n  } else {\n    setupOnHeadersComplete(txn, msg.get());\n  }\n\n  // The txn may have already been aborted by the handler.\n  // Verify that the txn still exists before ingress callbacks.\n  txn = findTransaction(streamID);\n  if (!txn) {\n    return;\n  }\n\n  if (!txn->getHandler()) {\n    txn->sendAbort();\n    return;\n  }\n\n  // Tell the Transaction to start processing the message now\n  // that the full ingress headers have arrived.\n  txn->onIngressHeadersComplete(std::move(msg));\n}\n\nvoid\nHTTPSession::onBody(HTTPCodec::StreamID streamID,\n                    unique_ptr<IOBuf> chain, uint16_t padding) {\n  FOLLY_SCOPED_TRACE_SECTION(\"HTTPSession - onBody\");\n  DestructorGuard dg(this);\n  // The codec's parser detected part of the ingress message's\n  // entity-body.\n  uint64_t length = chain->computeChainDataLength();\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    if (connFlowControl_ &&\n        connFlowControl_->ingressBytesProcessed(writeBuf_, length)) {\n      scheduleWrite();\n    }\n    invalidStream(streamID);\n    return;\n  }\n\n  if (HTTPSessionBase::onBodyImpl(std::move(chain), length, padding, txn)) {\n    VLOG(4) << *this << \" pausing due to read limit exceeded.\";\n    pauseReads();\n  }\n}\n\nvoid HTTPSession::onChunkHeader(HTTPCodec::StreamID streamID,\n                                size_t length) {\n  // The codec's parser detected a chunk header (meaning that this\n  // connection probably is HTTP/1.1).\n  //\n  // After calling onChunkHeader(), the codec will call onBody() zero\n  // or more times and then call onChunkComplete().\n  //\n  // The reason for this callback on the chunk header is to support\n  // an optimization.  In general, the job of the codec is to present\n  // the HTTPSession with an abstract view of a message,\n  // with all the details of wire formatting hidden.  However, there's\n  // one important case where we want to know about chunking: reverse\n  // proxying where both the client and server streams are HTTP/1.1.\n  // In that scenario, we preserve the server's chunk boundaries when\n  // sending the response to the client, in order to avoid possibly\n  // making the egress packetization worse by rechunking.\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    invalidStream(streamID);\n    return;\n  }\n  txn->onIngressChunkHeader(length);\n}\n\nvoid HTTPSession::onChunkComplete(HTTPCodec::StreamID streamID) {\n  // The codec's parser detected the end of the message body chunk\n  // associated with the most recent call to onChunkHeader().\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    invalidStream(streamID);\n    return;\n  }\n  txn->onIngressChunkComplete();\n}\n\nvoid\nHTTPSession::onTrailersComplete(HTTPCodec::StreamID streamID,\n                                unique_ptr<HTTPHeaders> trailers) {\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    invalidStream(streamID);\n    return;\n  }\n  txn->onIngressTrailers(std::move(trailers));\n}\n\nvoid\nHTTPSession::onMessageComplete(HTTPCodec::StreamID streamID,\n                               bool upgrade) {\n  DestructorGuard dg(this);\n  // The codec's parser detected the end of the ingress message for\n  // this transaction.\n  VLOG(4) << \"processing ingress message complete for \" << *this <<\n    \", streamID=\" << streamID;\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    invalidStream(streamID);\n    return;\n  }\n\n  if (upgrade) {\n    /* Send the upgrade callback to the transaction and the handler.\n     * Currently we support upgrades for only HTTP sessions and not SPDY\n     * sessions.\n     */\n    ingressUpgraded_ = true;\n    txn->onIngressUpgrade(UpgradeProtocol::TCP);\n    return;\n  }\n\n  // txnIngressFinished = !1xx response\n  const bool txnIngressFinished =\n    txn->isDownstream() || !txn->extraResponseExpected();\n  if (txnIngressFinished) {\n    decrementTransactionCount(txn, true, false);\n  }\n  txn->onIngressEOM();\n\n  // The codec knows, based on the semantics of whatever protocol it\n  // supports, whether it's valid for any more ingress messages to arrive\n  // after this one.  For example, an HTTP/1.1 request containing\n  // \"Connection: close\" indicates the end of the ingress, whereas a\n  // SPDY session generally can handle more messages at any time.\n  //\n  // If the connection is not reusable, we close the read side of it\n  // but not the write side.  There are two reasons why more writes\n  // may occur after this point:\n  //   * If there are previous writes buffered up in the pendingWrites_\n  //     queue, we need to attempt to complete them.\n  //   * The Handler associated with the transaction may want to\n  //     produce more egress data when the ingress message is fully\n  //     complete.  (As a common example, an application that handles\n  //     form POSTs may not be able to even start generating a response\n  //     until it has received the full request body.)\n  //\n  // There may be additional checks that need to be performed that are\n  // specific to requests or responses, so we call the subclass too.\n  if (!codec_->isReusable() &&\n      txnIngressFinished &&\n      !codec_->supportsParallelRequests()) {\n    VLOG(4) << *this << \" cannot reuse ingress\";\n    shutdownTransport(true, false);\n  }\n}\n\nvoid HTTPSession::onError(HTTPCodec::StreamID streamID,\n                          const HTTPException& error, bool newTxn) {\n  DestructorGuard dg(this);\n  // The codec detected an error in the ingress stream, possibly bad\n  // syntax, a truncated message, or bad semantics in the frame.  If reads\n  // are paused, queue up the event; otherwise, process it now.\n  VLOG(4) << \"Error on \" << *this << \", streamID=\" << streamID\n          << \", \" << error;\n\n  if (ingressError_) {\n    return;\n  }\n  if (!codec_->supportsParallelRequests()) {\n    // this error should only prevent us from reading/handling more errors\n    // on serial streams\n    ingressError_ = true;\n    setCloseReason(ConnectionCloseReason::SESSION_PARSE_ERROR);\n  }\n  if ((streamID == 0) && infoCallback_) {\n    infoCallback_->onIngressError(*this, kErrorMessage);\n  }\n\n  if (!streamID) {\n    ingressError_ = true;\n    onSessionParseError(error);\n    return;\n  }\n\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    if (error.hasHttpStatusCode() && streamID != 0) {\n      // If the error has an HTTP code, then parsing was fine, it just was\n      // illegal in a higher level way\n      txn = createTransaction(streamID, HTTPCodec::NoStream,\n                              HTTPCodec::NoExAttributes);\n      if (infoCallback_) {\n        infoCallback_->onRequestBegin(*this);\n      }\n      if (txn) {\n        handleErrorDirectly(txn, error);\n      }\n    } else if (newTxn) {\n      onNewTransactionParseError(streamID, error);\n    } else {\n      VLOG(4) << *this << \" parse error with invalid transaction\";\n      invalidStream(streamID);\n    }\n    return;\n  }\n\n  if (!txn->getHandler() &&\n      txn->getEgressState() == HTTPTransactionEgressSM::State::Start) {\n    handleErrorDirectly(txn, error);\n    return;\n  }\n\n  txn->onError(error);\n  if (!codec_->isReusable() && transactions_.empty()) {\n    VLOG(4) << *this << \"shutdown from onError\";\n    setCloseReason(ConnectionCloseReason::SESSION_PARSE_ERROR);\n    shutdownTransport(true, true);\n  }\n}\n\nvoid HTTPSession::onAbort(HTTPCodec::StreamID streamID,\n                          ErrorCode code) {\n  VLOG(4) << \"stream abort on \" << *this << \", streamID=\" << streamID\n          << \", code=\" << getErrorCodeString(code);\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    VLOG(4) << *this << \" abort for unrecognized transaction, streamID= \"\n      << streamID;\n    return;\n  }\n  HTTPException ex(HTTPException::Direction::INGRESS_AND_EGRESS,\n    folly::to<std::string>(\"Stream aborted, streamID=\",\n      streamID, \", code=\", getErrorCodeString(code)));\n  ex.setProxygenError(kErrorStreamAbort);\n  ex.setCodecStatusCode(code);\n  DestructorGuard dg(this);\n  if (isDownstream() && !txn->getAssocTxnId() && code == ErrorCode::CANCEL) {\n    // Cancelling the assoc txn cancels all push txns\n    for (auto it = txn->getPushedTransactions().begin();\n         it != txn->getPushedTransactions().end(); ) {\n      auto pushTxn = findTransaction(*it);\n      ++it;\n      DCHECK(pushTxn != nullptr);\n      pushTxn->onError(ex);\n    }\n  }\n  auto exTxns = txn->getExTransactions();\n  for (auto it = exTxns.begin(); it != exTxns.end(); ++it) {\n    auto exTxn = findTransaction(*it);\n    if (exTxn) {\n      exTxn->onError(ex);\n    }\n  }\n  txn->onError(ex);\n}\n\nvoid HTTPSession::onGoaway(uint64_t lastGoodStreamID,\n                           ErrorCode code,\n                           std::unique_ptr<folly::IOBuf> debugData) {\n  DestructorGuard g(this);\n  VLOG(4) << \"GOAWAY on \" << *this << \", code=\" << getErrorCodeString(code);\n\n  setCloseReason(ConnectionCloseReason::GOAWAY);\n\n  // Drain active transactions and prevent new transactions\n  drain();\n\n  // We give the less-forceful onGoaway() first so that transactions have\n  // a chance to do stat tracking before potentially getting a forceful\n  // onError().\n  invokeOnAllTransactions(&HTTPTransaction::onGoaway, code);\n\n  // Abort transactions which have been initiated but not created\n  // successfully at the remote end. Upstream transactions are created\n  // with odd transaction IDs and downstream transactions with even IDs.\n  vector<HTTPCodec::StreamID> ids;\n  auto firstStream = HTTPCodec::NoStream;\n\n  for (const auto& txn: transactions_) {\n    auto streamID = txn.first;\n    if (((bool)(streamID & 0x01) == isUpstream()) &&\n        (streamID > lastGoodStreamID)) {\n      if (firstStream == HTTPCodec::NoStream) {\n        // transactions_ is a set so it should be sorted by stream id.\n        // We will defer adding the firstStream to the id list until\n        // we can determine whether we have a codec error code.\n        firstStream = streamID;\n        continue;\n      }\n\n      ids.push_back(streamID);\n    }\n  }\n\n\n  if (firstStream != HTTPCodec::NoStream && code != ErrorCode::NO_ERROR) {\n    // If we get a codec error, we will attempt to blame the first stream\n    // by delivering a specific error to it and let the rest of the streams\n    // get a normal unacknowledged stream error.\n    ProxygenError err = kErrorStreamUnacknowledged;\n    string debugInfo = (debugData) ?\n      folly::to<string>(\" with debug info: \", (char*)debugData->data()) : \"\";\n    HTTPException ex(HTTPException::Direction::INGRESS_AND_EGRESS,\n      folly::to<std::string>(getErrorString(err),\n        \" on transaction id: \", *firstStream,\n        \" with codec error: \", getErrorCodeString(code),\n        debugInfo));\n    ex.setProxygenError(err);\n    errorOnTransactionId(*firstStream, std::move(ex));\n  } else if (firstStream != HTTPCodec::NoStream) {\n    ids.push_back(*firstStream);\n  }\n\n  errorOnTransactionIds(ids, kErrorStreamUnacknowledged);\n}\n\nvoid HTTPSession::onPingRequest(uint64_t uniqueID) {\n  VLOG(4) << *this << \" got ping request with id=\" << uniqueID;\n\n  TimePoint timestamp = getCurrentTime();\n\n  // Insert the ping reply to the head of writeBuf_\n  folly::IOBufQueue pingBuf(folly::IOBufQueue::cacheChainLength());\n  codec_->generatePingReply(pingBuf, uniqueID);\n  size_t pingSize = pingBuf.chainLength();\n  pingBuf.append(writeBuf_.move());\n  writeBuf_.append(pingBuf.move());\n\n  if (byteEventTracker_) {\n    byteEventTracker_->addPingByteEvent(pingSize, timestamp, bytesScheduled_);\n  }\n\n  scheduleWrite();\n}\n\nvoid HTTPSession::onPingReply(uint64_t uniqueID) {\n  VLOG(4) << *this << \" got ping reply with id=\" << uniqueID;\n  if (infoCallback_) {\n    infoCallback_->onPingReplyReceived();\n  }\n}\n\nvoid HTTPSession::onWindowUpdate(HTTPCodec::StreamID streamID,\n                                 uint32_t amount) {\n  VLOG(4) << *this << \" got window update on streamID=\" << streamID << \" for \"\n          << amount << \" bytes.\";\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (!txn) {\n    // We MUST be using SPDY/3+ if we got WINDOW_UPDATE. The spec says that -\n    //\n    // A sender should ignore all the WINDOW_UPDATE frames associated with the\n    // stream after it send the last frame for the stream.\n    //\n    // TODO: Only ignore if this is from some past transaction\n    return;\n  }\n  txn->onIngressWindowUpdate(amount);\n}\n\nvoid HTTPSession::onSettings(const SettingsList& settings) {\n  DestructorGuard g(this);\n  for (auto& setting : settings) {\n    if (setting.id == SettingsId::INITIAL_WINDOW_SIZE) {\n      onSetSendWindow(setting.value);\n    } else if (setting.id == SettingsId::MAX_CONCURRENT_STREAMS) {\n      onSetMaxInitiatedStreams(setting.value);\n    } else if (setting.id == SettingsId::SETTINGS_HTTP_CERT_AUTH) {\n      if (!(verifyCertAuthSetting(setting.value))) {\n        return;\n      }\n    }\n  }\n  if (codec_->generateSettingsAck(writeBuf_) > 0) {\n    scheduleWrite();\n  }\n  if (infoCallback_) {\n    infoCallback_->onSettings(*this, settings);\n  }\n}\n\nvoid HTTPSession::onSettingsAck() {\n  VLOG(4) << *this << \" received settings ack\";\n  if (infoCallback_) {\n    infoCallback_->onSettingsAck(*this);\n  }\n}\n\nvoid HTTPSession::onPriority(HTTPCodec::StreamID streamID,\n                             const HTTPMessage::HTTPPriority& pri) {\n  if (!getHTTP2PrioritiesEnabled()) {\n    return;\n  }\n  http2::PriorityUpdate h2Pri{std::get<0>(pri), std::get<1>(pri),\n      std::get<2>(pri)};\n  HTTPTransaction* txn = findTransaction(streamID);\n  if (txn) {\n    // existing txn, change pri\n    txn->onPriorityUpdate(h2Pri);\n  } else {\n    // virtual node\n    txnEgressQueue_.addOrUpdatePriorityNode(streamID, h2Pri);\n  }\n}\n\nvoid HTTPSession::onCertificateRequest(uint16_t requestId,\n                                       std::unique_ptr<IOBuf> authRequest) {\n  DestructorGuard dg(this);\n  VLOG(4) << \"CERTIFICATE_REQUEST on\" << *this << \", requestId=\" << requestId;\n\n  if (!secondAuthManager_) {\n    return;\n  }\n\n  std::pair<uint16_t, std::unique_ptr<folly::IOBuf>> authenticator;\n  auto fizzBase = getTransport()->getUnderlyingTransport<AsyncFizzBase>();\n  if (fizzBase) {\n    if (isUpstream()) {\n      authenticator =\n          secondAuthManager_->getAuthenticator(*fizzBase,\n                                               TransportDirection::UPSTREAM,\n                                               requestId,\n                                               std::move(authRequest));\n    } else {\n      authenticator =\n          secondAuthManager_->getAuthenticator(*fizzBase,\n                                               TransportDirection::DOWNSTREAM,\n                                               requestId,\n                                               std::move(authRequest));\n    }\n  } else {\n    VLOG(4) << \"Underlying transport does not support secondary \"\n               \"authentication.\";\n    return;\n  }\n  if (codec_->generateCertificate(writeBuf_,\n                                  authenticator.first,\n                                  std::move(authenticator.second)) > 0) {\n    scheduleWrite();\n  }\n}\n\nvoid HTTPSession::onCertificate(uint16_t certId,\n                                std::unique_ptr<IOBuf> authenticator) {\n  DestructorGuard dg(this);\n  VLOG(4) << \"CERTIFICATE on\" << *this << \", certId=\" << certId;\n\n  if (!secondAuthManager_) {\n    return;\n  }\n\n  bool isValid = false;\n  auto fizzBase = getTransport()->getUnderlyingTransport<AsyncFizzBase>();\n  if (fizzBase) {\n    if (isUpstream()) {\n      isValid = secondAuthManager_->validateAuthenticator(\n          *fizzBase,\n          TransportDirection::UPSTREAM,\n          certId,\n          std::move(authenticator));\n    } else {\n      isValid = secondAuthManager_->validateAuthenticator(\n          *fizzBase,\n          TransportDirection::DOWNSTREAM,\n          certId,\n          std::move(authenticator));\n    }\n  } else {\n    VLOG(4) << \"Underlying transport does not support secondary \"\n               \"authentication.\";\n    return;\n  }\n  if (isValid) {\n    VLOG(4) << \"Successfully validated the authenticator provided by the peer.\";\n  } else {\n    VLOG(4) << \"Failed to validate the authenticator provided by the peer\";\n  }\n}\n\nbool HTTPSession::onNativeProtocolUpgradeImpl(\n  HTTPCodec::StreamID streamID, std::unique_ptr<HTTPCodec> codec,\n  const std::string& protocolString) {\n  CHECK_EQ(streamID, 1);\n  HTTPTransaction* txn = findTransaction(streamID);\n  CHECK(txn);\n  // only HTTP1xCodec calls onNativeProtocolUpgrade\n  CHECK(!codec_->supportsParallelRequests());\n\n  // Reset to  defaults\n  maxConcurrentIncomingStreams_ = 100;\n  maxConcurrentOutgoingStreamsRemote_ = 10000;\n\n  // overwrite destination, delay current codec deletion until the end\n  // of the event loop\n  auto oldCodec = codec_.setDestination(std::move(codec));\n  sock_->getEventBase()->runInLoop([oldCodec = std::move(oldCodec)] () {});\n\n  onCodecChanged();\n\n  setupCodec();\n\n  // txn will be streamID=1, have to make a placeholder\n  (void)codec_->createStream();\n\n  // This can happen if flow control was not explicitly set, and it got the\n  // HTTP1xCodec defaults.  Reset to the new codec default\n  if (initialReceiveWindow_ == 0 || receiveStreamWindowSize_ == 0 ||\n      receiveSessionWindowSize_ == 0) {\n    initialReceiveWindow_ = receiveStreamWindowSize_ =\n      receiveSessionWindowSize_ = codec_->getDefaultWindowSize();\n  }\n\n  // trigger settings frame that would have gone out in startNow()\n  HTTPSettings* settings = codec_->getEgressSettings();\n  if (settings) {\n    settings->setSetting(SettingsId::INITIAL_WINDOW_SIZE,\n                         initialReceiveWindow_);\n  }\n  sendSettings();\n  if (connFlowControl_) {\n    connFlowControl_->setReceiveWindowSize(writeBuf_,\n                                           receiveSessionWindowSize_);\n    scheduleWrite();\n  }\n\n  // Convert the transaction that contained the Upgrade header\n  txn->reset(codec_->supportsStreamFlowControl(),\n             initialReceiveWindow_,\n             receiveStreamWindowSize_,\n             getCodecSendWindowSize());\n\n  if (!transportInfo_.secure &&\n      (!transportInfo_.appProtocol ||\n       transportInfo_.appProtocol->empty())) {\n    transportInfo_.appProtocol = std::make_shared<string>(\n      protocolString);\n  }\n\n  return true;\n}\n\nvoid HTTPSession::onSetSendWindow(uint32_t windowSize) {\n  VLOG(4) << *this << \" got send window size adjustment. new=\" << windowSize;\n  invokeOnAllTransactions(&HTTPTransaction::onIngressSetSendWindow,\n                          windowSize);\n}\n\nvoid HTTPSession::onSetMaxInitiatedStreams(uint32_t maxTxns) {\n  VLOG(4) << *this << \" got new maximum number of concurrent txns \"\n          << \"we can initiate: \" << maxTxns;\n  const bool didSupport = supportsMoreTransactions();\n  maxConcurrentOutgoingStreamsRemote_ = maxTxns;\n  if (infoCallback_ && didSupport != supportsMoreTransactions()) {\n    if (didSupport) {\n      infoCallback_->onSettingsOutgoingStreamsFull(*this);\n    } else {\n      infoCallback_->onSettingsOutgoingStreamsNotFull(*this);\n    }\n  }\n}\n\nsize_t HTTPSession::sendSettings() {\n  size_t size = codec_->generateSettings(writeBuf_);\n  scheduleWrite();\n  return size;\n}\n\nvoid HTTPSession::pauseIngress(HTTPTransaction* txn) noexcept {\n  VLOG(4) << *this << \" pausing streamID=\" << txn->getID() <<\n    \", liveTransactions_ was \" << liveTransactions_;\n  CHECK_GT(liveTransactions_, 0);\n  --liveTransactions_;\n  auto exTxns = txn->getExTransactions();\n  for (auto it = exTxns.begin(); it != exTxns.end(); ++it) {\n    auto exTxn = findTransaction(*it);\n    if (exTxn) {\n      exTxn->pauseIngress();\n    }\n  }\n\n  if (liveTransactions_ == 0) {\n    pauseReads();\n  }\n}\n\nvoid HTTPSession::resumeIngress(HTTPTransaction* txn) noexcept {\n  VLOG(4) << *this << \" resuming streamID=\" << txn->getID() <<\n      \", liveTransactions_ was \" << liveTransactions_;\n  ++liveTransactions_;\n  auto exTxns = txn->getExTransactions();\n  for (auto it = exTxns.begin(); it != exTxns.end(); ++it) {\n    auto exTxn = findTransaction(*it);\n    if (exTxn) {\n      exTxn->resumeIngress();\n    }\n  }\n\n  if (liveTransactions_ == 1) {\n    resumeReads();\n  }\n}\n\nvoid\nHTTPSession::transactionTimeout(HTTPTransaction* txn) noexcept {\n  // A transaction has timed out.  If the transaction does not have\n  // a Handler yet, because we haven't yet received the full request\n  // headers, we give it a DirectResponseHandler that generates an\n  // error page.\n  VLOG(3) << \"Transaction timeout for streamID=\" << txn->getID();\n  if (!codec_->supportsParallelRequests()) {\n    // this error should only prevent us from reading/handling more errors\n    // on serial streams\n    ingressError_ = true;\n  }\n\n  if (!txn->getHandler() &&\n      txn->getEgressState() == HTTPTransactionEgressSM::State::Start) {\n    VLOG(4) << *this << \" Timed out receiving headers\";\n    if (infoCallback_) {\n      infoCallback_->onIngressError(*this, kErrorTimeout);\n    }\n    if (codec_->supportsParallelRequests()) {\n      // This can only happen with HTTP/2 where the HEADERS frame is incomplete\n      // and we time out waiting for the CONTINUATION.  Abort the request.\n      //\n      // It would maybe be a little nicer to use the timeout handler for these\n      // also.\n      txn->sendAbort();\n      return;\n    }\n\n    VLOG(4) << *this << \" creating direct error handler\";\n    auto handler = getTransactionTimeoutHandler(txn);\n    txn->setHandler(handler);\n  }\n\n  // Tell the transaction about the timeout.  The transaction will\n  // communicate the timeout to the handler, and the handler will\n  // decide how to proceed.\n  txn->onIngressTimeout();\n}\n\nvoid HTTPSession::sendHeaders(HTTPTransaction* txn,\n                              const HTTPMessage& headers,\n                              HTTPHeaderSize* size,\n                              bool includeEOM) noexcept {\n  CHECK(started_);\n  unique_ptr<IOBuf> goawayBuf;\n  if (shouldShutdown()) {\n    // For HTTP/1.1, add Connection: close\n    // For SPDY, save the goaway for AFTER the request\n    auto writeBuf = writeBuf_.move();\n    drainImpl();\n    goawayBuf = writeBuf_.move();\n    writeBuf_.append(std::move(writeBuf));\n  }\n  if (isUpstream() || (txn->isPushed() && headers.isRequest())) {\n    // upstream picks priority\n    if (getHTTP2PrioritiesEnabled()) {\n      auto pri = getMessagePriority(&headers);\n      txn->onPriorityUpdate(pri);\n    }\n  }\n\n  const bool wasReusable = codec_->isReusable();\n  const uint64_t oldOffset = sessionByteOffset();\n  auto exAttributes = txn->getExAttributes();\n  auto assocStream = txn->getAssocTxnId();\n  if (exAttributes) {\n    codec_->generateExHeader(writeBuf_,\n                             txn->getID(),\n                             headers,\n                             *exAttributes,\n                             includeEOM,\n                             size);\n  } else if (headers.isRequest() && assocStream) {\n    // Only PUSH_PROMISE (not push response) has an associated stream\n    codec_->generatePushPromise(writeBuf_,\n                                txn->getID(),\n                                headers,\n                                *assocStream,\n                                includeEOM,\n                                size);\n  } else {\n    codec_->generateHeader(writeBuf_,\n                           txn->getID(),\n                           headers,\n                           includeEOM,\n                           size);\n  }\n  const uint64_t newOffset = sessionByteOffset();\n\n  // for push response count towards the MAX_CONCURRENT_STREAMS limit\n  if (isDownstream() && headers.isResponse() && txn->isPushed()) {\n    incrementOutgoingStreams();\n  }\n\n  // For all upstream headers, addFirstHeaderByteEvent should be added\n  // For all downstream, only response headers need addFirstHeaderByteEvent\n  bool shouldAddFirstHeaderByteEvent = isUpstream() ||\n                                       (isDownstream() && headers.isResponse());\n  if (shouldAddFirstHeaderByteEvent && newOffset > oldOffset &&\n      !txn->testAndSetFirstHeaderByteSent() && byteEventTracker_) {\n    byteEventTracker_->addFirstHeaderByteEvent(newOffset, txn);\n  }\n\n  if (size) {\n    VLOG(4) << *this << \" sending headers, size=\" << size->compressed\n            << \", uncompressedSize=\" << size->uncompressed;\n  }\n  if (goawayBuf) {\n    VLOG(4) << *this << \" moved GOAWAY to end of writeBuf\";\n    writeBuf_.append(std::move(goawayBuf));\n  }\n  if (includeEOM) {\n    commonEom(txn, 0, true);\n  }\n  scheduleWrite();\n  onHeadersSent(headers, wasReusable);\n}\n\nvoid\nHTTPSession::commonEom(\n    HTTPTransaction* txn,\n    size_t encodedSize,\n    bool piggybacked) noexcept {\n  HTTPSessionBase::handleLastByteEvents(\n    byteEventTracker_.get(), txn, encodedSize, sessionByteOffset(),\n    piggybacked);\n  onEgressMessageFinished(txn);\n}\n\nsize_t\nHTTPSession::sendBody(HTTPTransaction* txn,\n                      std::unique_ptr<folly::IOBuf> body,\n                      bool includeEOM,\n                      bool trackLastByteFlushed) noexcept {\n  uint64_t offset = sessionByteOffset();\n  size_t bodyLen = body ? body->computeChainDataLength(): 0;\n  size_t encodedSize = codec_->generateBody(writeBuf_,\n                                            txn->getID(),\n                                            std::move(body),\n                                            HTTPCodec::NoPadding,\n                                            includeEOM);\n  CHECK(inLoopCallback_);\n  pendingWriteSizeDelta_ -= bodyLen;\n  bodyBytesPerWriteBuf_ += bodyLen;\n  if (encodedSize > 0 && !txn->testAndSetFirstByteSent() && byteEventTracker_) {\n    byteEventTracker_->addFirstBodyByteEvent(offset, txn);\n  }\n\n  if (trackLastByteFlushed && encodedSize > 0 && byteEventTracker_) {\n    byteEventTracker_->addTrackedByteEvent(txn, offset + encodedSize);\n  }\n\n  if (includeEOM) {\n    VLOG(5) << *this << \" sending EOM in body for streamID=\" << txn->getID();\n    commonEom(txn, encodedSize, true);\n  }\n  return encodedSize;\n}\n\nsize_t HTTPSession::sendChunkHeader(HTTPTransaction* txn,\n    size_t length) noexcept {\n  size_t encodedSize = codec_->generateChunkHeader(writeBuf_,\n                                                   txn->getID(),\n                                                   length);\n  scheduleWrite();\n  return encodedSize;\n}\n\nsize_t HTTPSession::sendChunkTerminator(\n    HTTPTransaction* txn) noexcept {\n  size_t encodedSize = codec_->generateChunkTerminator(writeBuf_,\n                                                       txn->getID());\n  scheduleWrite();\n  return encodedSize;\n}\n\nvoid\nHTTPSession::onEgressMessageFinished(HTTPTransaction* txn, bool withRST) {\n  // If the semantics of the protocol don't permit more messages\n  // to be read or sent on this connection, close the socket in one or\n  // more directions.\n  CHECK(!transactions_.empty());\n\n  if (infoCallback_) {\n    infoCallback_->onRequestEnd(*this, txn->getMaxDeferredSize());\n  }\n  auto oldStreamCount = getPipelineStreamCount();\n  decrementTransactionCount(txn, false, true);\n  if (withRST || ((!codec_->isReusable() || readsShutdown()) &&\n                  transactions_.size() == 1)) {\n    // We should shutdown reads if we are closing with RST or we aren't\n    // interested in any further messages (ie if we are a downstream session).\n    // Upgraded sessions have independent ingress and egress, and the reads\n    // need not be shutdown on egress finish.\n    if (withRST) {\n      // Let any queued writes complete, but send a RST when done.\n      VLOG(4) << *this << \" resetting egress after this message\";\n      resetAfterDrainingWrites_ = true;\n      setCloseReason(ConnectionCloseReason::TRANSACTION_ABORT);\n      shutdownTransport(true, true);\n    } else {\n      // the reason is already set (either not reusable or readshutdown).\n\n      // Defer normal shutdowns until the end of the loop.  This\n      // handles an edge case with direct responses with Connection:\n      // close served before ingress EOM.  The remainder of the ingress\n      // message may be in the parse loop, so give it a chance to\n      // finish out and avoid a kErrorEOF\n\n      // we can get here during shutdown, in that case do not schedule a\n      // shutdown callback again\n      if (!shutdownTransportCb_) {\n        // Just for safety, the following bumps the refcount on this session\n        // to keep it live until the loopCb runs\n        shutdownTransportCb_.reset(new ShutdownTransportCallback(this));\n        sock_->getEventBase()->runInLoop(shutdownTransportCb_.get(), true);\n      }\n    }\n  } else {\n    maybeResumePausedPipelinedTransaction(oldStreamCount,\n                                          txn->getSequenceNumber());\n  }\n}\n\nsize_t HTTPSession::sendEOM(HTTPTransaction* txn,\n                            const HTTPHeaders* trailers) noexcept {\n\n  VLOG(4) << *this << \" sending EOM for streamID=\" << txn->getID()\n          << \" trailers=\" << (trailers ? \"yes\" : \"no\");\n\n  size_t encodedSize = 0;\n  if (trailers) {\n    encodedSize = codec_->generateTrailers(writeBuf_, txn->getID(), *trailers);\n  }\n\n  // Don't send EOM for HTTP2, when trailers sent.\n  // sendTrailers already flagged end of stream.\n  bool http2Trailers = trailers && isHTTP2CodecProtocol(codec_->getProtocol());\n  if (!http2Trailers) {\n    encodedSize += codec_->generateEOM(writeBuf_, txn->getID());\n  }\n\n  commonEom(txn, encodedSize, false);\n  return encodedSize;\n}\n\nsize_t HTTPSession::sendAbort(HTTPTransaction* txn,\n                              ErrorCode statusCode) noexcept {\n  // Ask the codec to generate an abort indicator for the transaction.\n  // Depending on the protocol, this may be a no-op.\n  // Schedule a network write to send out whatever egress we might\n  // have queued up.\n  VLOG(4) << *this << \" sending abort for streamID=\" << txn->getID();\n  // drain this transaction's writeBuf instead of flushing it\n  // then enqueue the abort directly into the Session buffer,\n  // hence with max priority.\n  size_t encodedSize = codec_->generateRstStream(writeBuf_,\n                                                 txn->getID(),\n                                                 statusCode);\n\n  if (!codec_->isReusable()) {\n    // HTTP 1x codec does not support per stream abort so this will\n    // render the codec not reusable\n    setCloseReason(ConnectionCloseReason::TRANSACTION_ABORT);\n  }\n\n  scheduleWrite();\n\n  // If the codec wasn't able to write a L7 message for the abort, then\n  // fall back to closing the transport with a TCP level RST\n  onEgressMessageFinished(txn, !encodedSize);\n  return encodedSize;\n}\n\nsize_t HTTPSession::sendPriority(HTTPTransaction* txn,\n                                 const http2::PriorityUpdate& pri) noexcept {\n  return sendPriorityImpl(txn->getID(), pri);\n}\n\nvoid HTTPSession::setSecondAuthManager(\n    std::unique_ptr<SecondaryAuthManager> secondAuthManager) {\n  secondAuthManager_ = std::move(secondAuthManager);\n}\n\nSecondaryAuthManager* HTTPSession::getSecondAuthManager() const {\n  return secondAuthManager_.get();\n}\n\n/**\n * Send a CERTIFICATE_REQUEST frame. If the underlying protocol doesn't\n * support secondary authentication, this is a no-op and 0 is returned.\n */\nsize_t HTTPSession::sendCertificateRequest(\n    std::unique_ptr<folly::IOBuf> certificateRequestContext,\n    std::vector<fizz::Extension> extensions) {\n  // Check if both sending and receiving peer have advertised valid\n  // SETTINGS_HTTP_CERT_AUTH setting. Otherwise, the frames for secondary\n  // authentication should not be sent.\n  auto ingressSettings = codec_->getIngressSettings();\n  auto egressSettings = codec_->getEgressSettings();\n  if (ingressSettings && egressSettings) {\n    if (ingressSettings->getSetting(SettingsId::SETTINGS_HTTP_CERT_AUTH, 0) ==\n            0 ||\n        egressSettings->getSetting(SettingsId::SETTINGS_HTTP_CERT_AUTH, 0) ==\n            0) {\n      VLOG(4) << \"Secondary certificate authentication is not supported.\";\n      return 0;\n    }\n  }\n  auto authRequest = secondAuthManager_->createAuthRequest(\n      std::move(certificateRequestContext), std::move(extensions));\n  auto encodedSize = codec_->generateCertificateRequest(\n      writeBuf_, authRequest.first, std::move(authRequest.second));\n  if (encodedSize > 0) {\n    scheduleWrite();\n  } else {\n    VLOG(4) << \"Failed to generate CERTIFICATE_REQUEST frame.\";\n  }\n  return encodedSize;\n}\n\nvoid HTTPSession::decrementTransactionCount(HTTPTransaction* txn,\n                                            bool ingressEOM,\n                                            bool egressEOM) {\n  if ((isUpstream() && !txn->isPushed()) ||\n      (isDownstream() && txn->isPushed())) {\n    if (ingressEOM && txn->testAndClearActive()) {\n      outgoingStreams_--;\n    }\n  } else {\n    if (egressEOM && txn->testAndClearActive()) {\n      incomingStreams_--;\n    }\n  }\n}\n\n// This is a kludgy function because it requires the caller to remember\n// the old value of pipelineStreamCount from before it calls\n// decrementTransactionCount.  I'm trying to avoid yet more state in\n// HTTPSession.  If decrementTransactionCount actually closed a stream\n// and there is still a pipelinable stream, then it was pipelining\nbool\nHTTPSession::maybeResumePausedPipelinedTransaction(\n  size_t oldStreamCount, uint32_t txnSeqn) {\n  if (!codec_->supportsParallelRequests() && !transactions_.empty() &&\n      getPipelineStreamCount() < oldStreamCount &&\n      getPipelineStreamCount() == 1) {\n    auto& nextTxn = transactions_.rbegin()->second;\n    DCHECK_EQ(nextTxn.getSequenceNumber(), txnSeqn + 1);\n    DCHECK(!nextTxn.isIngressComplete());\n    DCHECK(nextTxn.isIngressPaused());\n    VLOG(4) << \"Resuming paused pipelined txn \" << nextTxn;\n    nextTxn.resumeIngress();\n    return true;\n  }\n  return false;\n}\n\nvoid\nHTTPSession::detach(HTTPTransaction* txn) noexcept {\n  DestructorGuard guard(this);\n  HTTPCodec::StreamID streamID = txn->getID();\n  auto txnSeqn = txn->getSequenceNumber();\n  auto it = transactions_.find(txn->getID());\n  DCHECK(it != transactions_.end());\n\n  if (txn->isIngressPaused()) {\n    // Someone detached a transaction that was paused.  Make the resumeIngress\n    // call to keep liveTransactions_ in order\n    VLOG(4) << *this << \" detached paused transaction=\" << streamID;\n    resumeIngress(txn);\n  }\n\n  VLOG(4) << *this << \" removing streamID=\" << streamID <<\n    \", liveTransactions was \" << liveTransactions_;\n  CHECK_GT(liveTransactions_, 0);\n  liveTransactions_--;\n\n  if (txn->isPushed()) {\n    auto assocTxn = findTransaction(*txn->getAssocTxnId());\n    if (assocTxn) {\n      assocTxn->removePushedTransaction(streamID);\n    }\n  }\n  if (txn->getControlStream()) {\n    auto controlTxn = findTransaction(*txn->getControlStream());\n    if (controlTxn) {\n      controlTxn->removeExTransaction(streamID);\n    }\n  }\n\n  auto oldStreamCount = getPipelineStreamCount();\n  decrementTransactionCount(txn, true, true);\n  transactions_.erase(it);\n\n  if (transactions_.empty()) {\n    HTTPSessionBase::setLatestActive();\n    if (infoCallback_) {\n      infoCallback_->onDeactivateConnection(*this);\n    }\n    if (getConnectionManager()) {\n      getConnectionManager()->onDeactivated(*this);\n    }\n  } else {\n    if (infoCallback_) {\n      infoCallback_->onTransactionDetached(*this);\n    }\n  }\n\n  if (!readsShutdown()) {\n    if (maybeResumePausedPipelinedTransaction(oldStreamCount, txnSeqn)) {\n      return;\n    } else {\n      // this will resume reads if they were paused (eg: 0 HTTP transactions)\n      resumeReads();\n    }\n  }\n\n  if (liveTransactions_ == 0 && transactions_.empty() && !isScheduled()) {\n    resetTimeout();\n  }\n\n  // It's possible that this is the last transaction in the session,\n  // so check whether the conditions for shutdown are satisfied.\n  if (transactions_.empty()) {\n    if (shouldShutdown()) {\n      writesDraining_ = true;\n    }\n    // Handle the case where we are draining writes but all remaining\n    // transactions terminated with no egress.\n    if (writesDraining_ && !writesShutdown() && !hasMoreWrites()) {\n      shutdownTransport(false, true);\n      return;\n    }\n  }\n  checkForShutdown();\n}\n\nsize_t\nHTTPSession::sendWindowUpdate(HTTPTransaction* txn,\n                              uint32_t bytes) noexcept {\n  size_t sent = codec_->generateWindowUpdate(writeBuf_, txn->getID(), bytes);\n  if (sent) {\n    scheduleWrite();\n  }\n  return sent;\n}\n\nvoid\nHTTPSession::notifyIngressBodyProcessed(uint32_t bytes) noexcept {\n  if (HTTPSessionBase::notifyBodyProcessed(bytes)) {\n    resumeReads();\n  }\n  if (connFlowControl_ &&\n      connFlowControl_->ingressBytesProcessed(writeBuf_, bytes)) {\n    scheduleWrite();\n  }\n}\n\nvoid\nHTTPSession::notifyEgressBodyBuffered(int64_t bytes) noexcept {\n  pendingWriteSizeDelta_ += bytes;\n  // any net change requires us to update pause/resume state in the\n  // loop callback\n  if (pendingWriteSizeDelta_ > 0) {\n    // pause inline, resume in loop\n    updateWriteBufSize(0);\n  } else if (!isLoopCallbackScheduled()) {\n    sock_->getEventBase()->runInLoop(this);\n  }\n}\n\nbool HTTPSession::getCurrentTransportInfoWithoutUpdate(\n    TransportInfo* tinfo) const {\n  auto sock = sock_->getUnderlyingTransport<AsyncSocket>();\n  if (sock) {\n    tinfo->initWithSocket(sock);\n    return true;\n  }\n  return false;\n}\n\nbool HTTPSession::getCurrentTransportInfo(TransportInfo* tinfo) {\n  if (getCurrentTransportInfoWithoutUpdate(tinfo)) {\n    // some fields are the same with the setup transport info\n    tinfo->setupTime = transportInfo_.setupTime;\n    tinfo->secure = transportInfo_.secure;\n    tinfo->sslSetupTime = transportInfo_.sslSetupTime;\n    tinfo->sslVersion = transportInfo_.sslVersion;\n    tinfo->sslCipher = transportInfo_.sslCipher;\n    tinfo->sslResume = transportInfo_.sslResume;\n    tinfo->appProtocol = transportInfo_.appProtocol;\n    tinfo->sslError = transportInfo_.sslError;\n#if defined(__linux__) || defined(__FreeBSD__)\n    // update connection transport info with the latest RTT\n    if (tinfo->tcpinfo.tcpi_rtt > 0) {\n      transportInfo_.tcpinfo.tcpi_rtt = tinfo->tcpinfo.tcpi_rtt;\n      transportInfo_.rtt = std::chrono::microseconds(tinfo->tcpinfo.tcpi_rtt);\n    }\n    transportInfo_.rtx = tinfo->rtx;\n#endif\n    return true;\n  }\n  return false;\n}\n\nunique_ptr<IOBuf> HTTPSession::getNextToSend(bool* cork, bool* eom) {\n  // limit ourselves to one outstanding write at a time (onWriteSuccess calls\n  // scheduleWrite)\n  if (numActiveWrites_ > 0 || writesShutdown()) {\n    VLOG(4) << \"skipping write during this loop, numActiveWrites_=\" <<\n      numActiveWrites_ << \" writesShutdown()=\" << writesShutdown();\n    return nullptr;\n  }\n\n  // We always tack on at least one body packet to the current write buf\n  // This ensures that a short HTTPS response will go out in a single SSL record\n  while (!txnEgressQueue_.empty()) {\n    uint32_t toSend = kWriteReadyMax;\n    if (connFlowControl_) {\n      if (connFlowControl_->getAvailableSend() == 0) {\n        VLOG(4) << \"Session-level send window is full, skipping remaining \"\n                << \"body writes this loop\";\n        break;\n      }\n      toSend = std::min(toSend, connFlowControl_->getAvailableSend());\n    }\n    txnEgressQueue_.nextEgress(nextEgressResults_,\n                               isSpdyCodecProtocol(codec_->getProtocol()));\n    CHECK(!nextEgressResults_.empty()); // Queue was non empty, so this must be\n    // The maximum we will send for any transaction in this loop\n    uint32_t txnMaxToSend = toSend * nextEgressResults_.front().second;\n    if (txnMaxToSend == 0) {\n      // toSend is smaller than the number of transactions.  Give all egress\n      // to the first transaction\n      nextEgressResults_.erase(++nextEgressResults_.begin(),\n                               nextEgressResults_.end());\n      txnMaxToSend = std::min(toSend, egressBodySizeLimit_);\n      nextEgressResults_.front().second = 1;\n    }\n    if (nextEgressResults_.size() > 1 && txnMaxToSend > egressBodySizeLimit_) {\n      // Cap the max to egressBodySizeLimit_, and recompute toSend accordingly\n      txnMaxToSend = egressBodySizeLimit_;\n      toSend = txnMaxToSend / nextEgressResults_.front().second;\n    }\n    // split allowed by relative weight, with some minimum\n    for (auto txnPair: nextEgressResults_) {\n      uint32_t txnAllowed = txnPair.second * toSend;\n      if (nextEgressResults_.size() > 1) {\n        CHECK_LE(txnAllowed, egressBodySizeLimit_);\n      }\n      if (connFlowControl_) {\n        CHECK_LE(txnAllowed, connFlowControl_->getAvailableSend());\n      }\n      if (txnAllowed == 0) {\n        // The ratio * toSend was so small this txn gets nothing.\n        VLOG(4) << *this << \" breaking egress loop on 0 txnAllowed\";\n        break;\n      }\n\n      VLOG(4) << *this << \" egressing txnID=\" << txnPair.first->getID() <<\n        \" allowed=\" << txnAllowed;\n      txnPair.first->onWriteReady(txnAllowed, txnPair.second);\n    }\n    nextEgressResults_.clear();\n    // it can be empty because of HTTPTransaction rate limiting.  We should\n    // change rate limiting to clearPendingEgress while waiting.\n    if (!writeBuf_.empty()) {\n      break;\n    }\n  }\n  *eom = false;\n  if (byteEventTracker_) {\n    uint64_t needed = byteEventTracker_->preSend(cork, eom, bytesWritten_);\n    if (needed > 0) {\n      VLOG(5) << *this << \" writeBuf_.chainLength(): \"\n              << writeBuf_.chainLength() << \" txnEgressQueue_.empty(): \"\n              << txnEgressQueue_.empty();\n\n      if (needed < writeBuf_.chainLength()) {\n        // split the next EOM chunk\n        VLOG(5) << *this << \" splitting \" << needed << \" bytes out of a \"\n                << writeBuf_.chainLength() << \" bytes IOBuf\";\n        *cork = true;\n        if (sessionStats_) {\n          sessionStats_->recordTTLBAIOBSplitByEom();\n        }\n        return writeBuf_.split(needed);\n      } else {\n        CHECK_EQ(needed, writeBuf_.chainLength());\n      }\n    }\n  }\n\n  // cork if there are txns with pending egress and room to send them\n  *cork = !txnEgressQueue_.empty() && !isConnWindowFull();\n  return writeBuf_.move();\n}\n\nvoid\nHTTPSession::runLoopCallback() noexcept {\n  // We schedule this callback to run at the end of an event\n  // loop iteration if either of two conditions has happened:\n  //   * The session has generated some egress data (see scheduleWrite())\n  //   * Reads have become unpaused (see resumeReads())\n  DestructorGuard dg(this);\n  inLoopCallback_ = true;\n  auto scopeg = folly::makeGuard([this] {\n      inLoopCallback_ = false;\n      // This ScopeGuard needs to be under the above DestructorGuard\n      if (pendingWriteSizeDelta_) {\n        updateWriteBufSize(0);\n      }\n      checkForShutdown();\n    });\n  VLOG(5) << *this << \" in loop callback\";\n\n  for (uint32_t i = 0; i < kMaxWritesPerLoop; ++i) {\n    bodyBytesPerWriteBuf_ = 0;\n    if (isPrioritySampled()) {\n      invokeOnAllTransactions(\n        &HTTPTransaction::updateContentionsCount,\n        txnEgressQueue_.numPendingEgress());\n    }\n\n    bool cork = true;\n    bool eom = false;\n    unique_ptr<IOBuf> writeBuf = getNextToSend(&cork, &eom);\n\n    if (!writeBuf) {\n      break;\n    }\n    uint64_t len = writeBuf->computeChainDataLength();\n    VLOG(11) << *this\n             << \" bytes of egress to be written: \" << len\n             << \" cork:\" << cork << \" eom:\" << eom;\n    if (len == 0) {\n      checkForShutdown();\n      return;\n    }\n\n    if (isPrioritySampled()) {\n      invokeOnAllTransactions(\n        &HTTPTransaction::updateSessionBytesSheduled,\n        bodyBytesPerWriteBuf_);\n    }\n\n    WriteSegment* segment = new WriteSegment(this, len);\n    segment->setCork(cork);\n    segment->setEOR(eom);\n\n    pendingWrites_.push_back(*segment);\n    if (!writeTimeout_.isScheduled()) {\n      // Any performance concern here?\n      timeout_.scheduleTimeout(&writeTimeout_);\n    }\n    numActiveWrites_++;\n    VLOG(4) << *this << \" writing \" << len << \", activeWrites=\"\n             << numActiveWrites_ << \" cork=\" << cork << \" eom=\" << eom;\n    bytesScheduled_ += len;\n    sock_->writeChain(segment, std::move(writeBuf), segment->getFlags());\n    if (numActiveWrites_ > 0) {\n      updateWriteCount();\n      pendingWriteSizeDelta_ += len;\n      // updateWriteBufSize called in scope guard\n      break;\n    }\n    // writeChain can result in a writeError and trigger the shutdown code path\n  }\n  if (numActiveWrites_ == 0 && !writesShutdown() && hasMoreWrites() &&\n      (!connFlowControl_ || connFlowControl_->getAvailableSend())) {\n    scheduleWrite();\n  }\n\n  if (readsUnpaused()) {\n    processReadData();\n\n    // Install the read callback if necessary\n    if (readsUnpaused() && !sock_->getReadCallback()) {\n      sock_->setReadCB(this);\n    }\n  }\n  // checkForShutdown is now in ScopeGuard\n}\n\nvoid\nHTTPSession::scheduleWrite() {\n  // Do all the network writes for this connection in one batch at\n  // the end of the current event loop iteration.  Writing in a\n  // batch helps us packetize the network traffic more efficiently,\n  // as well as saving a few system calls.\n  if (!isLoopCallbackScheduled() &&\n      (writeBuf_.front() || !txnEgressQueue_.empty())) {\n    VLOG(5) << *this << \" scheduling write callback\";\n    sock_->getEventBase()->runInLoop(this);\n  }\n}\n\nvoid\nHTTPSession::updateWriteCount() {\n  if (numActiveWrites_ > 0 && writesUnpaused()) {\n    // Exceeded limit. Pause reading on the incoming stream.\n    VLOG(3) << \"Pausing egress for \" << *this;\n    writes_ = SocketState::PAUSED;\n  } else if (numActiveWrites_ == 0 && writesPaused()) {\n    // Dropped below limit. Resume reading on the incoming stream if needed.\n    VLOG(3) << \"Resuming egress for \" << *this;\n    writes_ = SocketState::UNPAUSED;\n  }\n}\n\nvoid\nHTTPSession::updateWriteBufSize(int64_t delta) {\n  // This is the sum of body bytes buffered within transactions_ and in\n  // the sock_'s write buffer.\n  delta += pendingWriteSizeDelta_;\n  pendingWriteSizeDelta_ = 0;\n  bool wasExceeded = egressLimitExceeded();\n  updatePendingWriteSize(delta);\n\n  if (egressLimitExceeded() && !wasExceeded) {\n    // Exceeded limit. Pause reading on the incoming stream.\n    if (inResume_) {\n      VLOG(3) << \"Pausing txn egress for \" << *this << \" deferred\";\n      pendingPause_ = true;\n    } else {\n      VLOG(3) << \"Pausing txn egress for \" << *this;\n      invokeOnAllTransactions(&HTTPTransaction::pauseEgress);\n    }\n  } else if (!egressLimitExceeded() && wasExceeded) {\n    // Dropped below limit. Resume reading on the incoming stream if needed.\n    if (inResume_) {\n      if (pendingPause_) {\n        VLOG(3) << \"Cancel deferred txn egress pause for \" << *this;\n        pendingPause_ = false;\n      } else {\n        VLOG(3) << \"Ignoring redundant resume for \" << *this;\n      }\n    } else {\n      VLOG(3) << \"Resuming txn egress for \" << *this;\n      resumeTransactions();\n    }\n  }\n}\n\nvoid\nHTTPSession::shutdownTransport(bool shutdownReads,\n                               bool shutdownWrites,\n                               const std::string& errorMsg) {\n  DestructorGuard guard(this);\n\n  // shutdowns not accounted for, shouldn't see any\n  setCloseReason(ConnectionCloseReason::UNKNOWN);\n\n  VLOG(4) << \"shutdown request for \" << *this << \": reads=\"\n          << shutdownReads << \" (currently \" << readsShutdown()\n          << \"), writes=\" << shutdownWrites << \" (currently \"\n          << writesShutdown() << \")\";\n\n  bool notifyEgressShutdown = false;\n  bool notifyIngressShutdown = false;\n\n  ProxygenError error;\n  if (!transportInfo_.sslError.empty()) {\n    error = kErrorSSL;\n  } else if (sock_->error()) {\n    VLOG(3) << \"shutdown request for \" << *this\n      << \" on bad socket. Shutting down writes too.\";\n    if (getConnectionCloseReason() == ConnectionCloseReason::IO_WRITE_ERROR) {\n      error = kErrorWrite;\n    } else {\n      error = kErrorConnectionReset;\n    }\n    shutdownWrites = true;\n  } else if (getConnectionCloseReason() == ConnectionCloseReason::TIMEOUT) {\n    error = kErrorTimeout;\n  } else {\n    error = kErrorEOF;\n  }\n\n  if (shutdownReads && !shutdownWrites && flowControlTimeout_.isScheduled()) {\n    // reads are dead and writes are blocked on a window update that will never\n    // come.  shutdown writes too.\n    VLOG(4) << *this << \" Converting read shutdown to read/write due to\"\n      \" flow control\";\n    shutdownWrites = true;\n  }\n\n  if (shutdownWrites && !writesShutdown()) {\n    if (codec_->generateGoaway(writeBuf_,\n                               codec_->getLastIncomingStreamID(),\n                               ErrorCode::NO_ERROR)) {\n      scheduleWrite();\n    }\n    if (!hasMoreWrites() &&\n        (transactions_.empty() || codec_->closeOnEgressComplete())) {\n      writes_ = SocketState::SHUTDOWN;\n      if (byteEventTracker_) {\n        byteEventTracker_->drainByteEvents();\n      }\n      if (resetAfterDrainingWrites_) {\n        VLOG(4) << *this << \" writes drained, sending RST\";\n        resetSocketOnShutdown_ = true;\n        shutdownReads = true;\n      } else {\n        VLOG(4) << *this << \" writes drained, closing\";\n        sock_->shutdownWriteNow();\n      }\n      notifyEgressShutdown = true;\n    } else if (!writesDraining_) {\n      writesDraining_ = true;\n      notifyEgressShutdown = true;\n    } // else writes are already draining; don't double notify\n  }\n\n  if (shutdownReads && !readsShutdown()) {\n    notifyIngressShutdown = true;\n    // TODO: send an RST if readBuf_ is non empty?\n    sock_->setReadCB(nullptr);\n    reads_ = SocketState::SHUTDOWN;\n    if (!transactions_.empty() && error == kErrorConnectionReset) {\n      if (infoCallback_ != nullptr) {\n        infoCallback_->onIngressError(*this, error);\n      }\n    } else if (error == kErrorEOF) {\n      // Report to the codec that the ingress stream has ended\n      codec_->onIngressEOF();\n      if (infoCallback_) {\n        infoCallback_->onIngressEOF();\n      }\n    }\n    // Once reads are shutdown the parser should stop processing\n    codec_->setParserPaused(true);\n  }\n\n  if (notifyIngressShutdown || notifyEgressShutdown) {\n    auto dir = (notifyIngressShutdown && notifyEgressShutdown)\n                   ? HTTPException::Direction::INGRESS_AND_EGRESS\n                   : (notifyIngressShutdown ? HTTPException::Direction::INGRESS\n                                            : HTTPException::Direction::EGRESS);\n    HTTPException ex(\n        dir,\n        folly::to<std::string>(\"Shutdown transport: \", getErrorString(error),\n                               errorMsg.empty() ? \"\" : \" \", errorMsg, \", \",\n                               getPeerAddress().describe()));\n    ex.setProxygenError(error);\n    invokeOnAllTransactions(&HTTPTransaction::onError, ex);\n  }\n\n  // Close the socket only after the onError() callback on the txns\n  // and handler has been detached.\n  checkForShutdown();\n}\n\nvoid HTTPSession::shutdownTransportWithReset(\n    ProxygenError errorCode,\n    const std::string& errorMsg) {\n  DestructorGuard guard(this);\n  VLOG(4) << \"shutdownTransportWithReset\";\n\n  if (!readsShutdown()) {\n    sock_->setReadCB(nullptr);\n    reads_ = SocketState::SHUTDOWN;\n  }\n\n  if (!writesShutdown()) {\n    writes_ = SocketState::SHUTDOWN;\n    IOBuf::destroy(writeBuf_.move());\n    while (!pendingWrites_.empty()) {\n      pendingWrites_.front().detach();\n      numActiveWrites_--;\n    }\n    VLOG(4) << *this << \" cancel write timer\";\n    writeTimeout_.cancelTimeout();\n    resetSocketOnShutdown_ = true;\n  }\n\n  errorOnAllTransactions(errorCode, errorMsg);\n  // drainByteEvents() can call detach(txn), which can in turn call\n  // shutdownTransport if we were already draining. To prevent double\n  // calling onError() to the transactions, we call drainByteEvents()\n  // after we've given the explicit error.\n  if (byteEventTracker_) {\n    byteEventTracker_->drainByteEvents();\n  }\n\n  // HTTPTransaction::onError could theoretically schedule more callbacks,\n  // so do this last.\n  if (isLoopCallbackScheduled()) {\n    cancelLoopCallback();\n  }\n  // onError() callbacks or drainByteEvents() could result in txns detaching\n  // due to CallbackGuards going out of scope. Close the socket only after\n  // the txns are detached.\n  checkForShutdown();\n}\n\nvoid\nHTTPSession::checkForShutdown() {\n  VLOG(10) << *this << \" checking for shutdown, readShutdown=\"\n           << readsShutdown() << \", writesShutdown=\" << writesShutdown()\n           << \", transaction set empty=\" << transactions_.empty();\n\n  // Two conditions are required to destroy the HTTPSession:\n  //   * All writes have been finished.\n  //   * There are no transactions remaining on the session.\n  if (writesShutdown() && transactions_.empty() &&\n      !isLoopCallbackScheduled()) {\n    VLOG(4) << \"destroying \" << *this;\n    sock_->setReadCB(nullptr);\n    auto asyncSocket = sock_->getUnderlyingTransport<folly::AsyncSocket>();\n    if (asyncSocket) {\n      asyncSocket->setBufferCallback(nullptr);\n    }\n    reads_ = SocketState::SHUTDOWN;\n    if (resetSocketOnShutdown_) {\n      sock_->closeWithReset();\n    } else {\n      sock_->closeNow();\n    }\n    destroy();\n  }\n}\n\nvoid\nHTTPSession::drain() {\n  if (!draining_) {\n    VLOG(4) << *this << \" draining\";\n    draining_ = true;\n    setCloseReason(ConnectionCloseReason::SHUTDOWN);\n\n    if (allTransactionsStarted()) {\n      drainImpl();\n    }\n    if (transactions_.empty() && isUpstream()) {\n      // We don't do this for downstream since we need to wait for\n      // inflight requests to arrive\n      VLOG(4) << *this << \" shutdown from drain\";\n      shutdownTransport(true, true);\n    }\n  } else {\n    VLOG(4) << *this << \" already draining\";\n  }\n}\n\nvoid HTTPSession::drainImpl() {\n  if (codec_->isReusable() || codec_->isWaitingToDrain()) {\n    setCloseReason(ConnectionCloseReason::SHUTDOWN);\n    // For HTTP/2, if we haven't started yet then we cannot send a GOAWAY frame\n    // since we haven't sent the initial SETTINGS frame. Defer sending that\n    // GOAWAY until the initial SETTINGS is sent.\n    if (started_) {\n      codec_->generateGoaway(writeBuf_,\n                             getGracefulGoawayAck(),\n                             ErrorCode::NO_ERROR);\n      scheduleWrite();\n    }\n  }\n}\n\nbool HTTPSession::shouldShutdown() const {\n  return draining_ &&\n    allTransactionsStarted() &&\n    (!codec_->supportsParallelRequests() ||\n     isUpstream() ||\n     !codec_->isReusable());\n}\n\nsize_t HTTPSession::sendPing() {\n  const size_t bytes = codec_->generatePingRequest(writeBuf_);\n  if (bytes) {\n    scheduleWrite();\n  }\n  return bytes;\n}\n\nHTTPCodec::StreamID HTTPSession::sendPriority(http2::PriorityUpdate pri) {\n  if (!codec_->supportsParallelRequests()) {\n    // For HTTP/1.1, don't call createStream()\n    return 0;\n  }\n  auto id = codec_->createStream();\n  sendPriority(id, pri);\n  return id;\n}\n\nsize_t HTTPSession::sendPriority(HTTPCodec::StreamID id,\n                                 http2::PriorityUpdate pri) {\n  auto res = sendPriorityImpl(id, pri);\n  txnEgressQueue_.addOrUpdatePriorityNode(id, pri);\n  return res;\n}\n\n\nsize_t HTTPSession::sendPriorityImpl(HTTPCodec::StreamID id,\n                                     http2::PriorityUpdate pri) {\n  CHECK_NE(id, 0);\n  const size_t bytes = codec_->generatePriority(\n    writeBuf_, id, std::make_tuple(pri.streamDependency,\n                                   pri.exclusive,\n                                   pri.weight));\n  if (bytes) {\n    scheduleWrite();\n  }\n  return bytes;\n}\n\nHTTPTransaction*\nHTTPSession::findTransaction(HTTPCodec::StreamID streamID) {\n  auto it = transactions_.find(streamID);\n  if (it == transactions_.end()) {\n    return nullptr;\n  } else {\n    return &it->second;\n  }\n}\n\nHTTPTransaction*\nHTTPSession::createTransaction(\n    HTTPCodec::StreamID streamID,\n    const folly::Optional<HTTPCodec::StreamID>& assocStreamID,\n    const folly::Optional<HTTPCodec::ExAttributes>& exAttributes,\n    const http2::PriorityUpdate& priority) {\n  if (!sock_->good() || transactions_.count(streamID)) {\n    // Refuse to add a transaction on a closing session or if a\n    // transaction of that ID already exists.\n    return nullptr;\n  }\n\n  if (transactions_.empty()) {\n    if (infoCallback_) {\n      infoCallback_->onActivateConnection(*this);\n    }\n    if (getConnectionManager()) {\n      getConnectionManager()->onActivated(*this);\n    }\n    HTTPSessionBase::onCreateTransaction();\n  }\n\n  auto matchPair = transactions_.emplace(\n    std::piecewise_construct,\n    std::forward_as_tuple(streamID),\n    std::forward_as_tuple(\n      codec_->getTransportDirection(), streamID, getNumTxnServed(), *this,\n      txnEgressQueue_, timeout_.getWheelTimer(), timeout_.getDefaultTimeout(),\n      sessionStats_,\n      codec_->supportsStreamFlowControl(),\n      initialReceiveWindow_,\n      getCodecSendWindowSize(),\n      priority,\n      assocStreamID,\n      exAttributes\n    ));\n\n  CHECK(matchPair.second) << \"Emplacement failed, despite earlier \"\n    \"existence check.\";\n\n  HTTPTransaction* txn = &matchPair.first->second;\n\n  if (isPrioritySampled()) {\n    txn->setPrioritySampled(true /* sampled */);\n  }\n\n  if (getNumTxnServed() > 0) {\n    auto stats = txn->getSessionStats();\n    if (stats != nullptr) {\n      stats->recordSessionReused();\n    }\n  }\n\n  VLOG(5) << *this << \" adding streamID=\" << txn->getID()\n          << \", liveTransactions_ was \" << liveTransactions_;\n\n  ++liveTransactions_;\n  incrementSeqNo();\n  txn->setReceiveWindow(receiveStreamWindowSize_);\n\n  if (isUpstream() && !txn->isPushed()) {\n    incrementOutgoingStreams();\n  // do not count towards MAX_CONCURRENT_STREAMS for PUSH_PROMISE\n  } else if (!(isDownstream() && txn->isPushed())) {\n    incomingStreams_++;\n  }\n\n  return txn;\n}\n\nvoid\nHTTPSession::incrementOutgoingStreams() {\n  outgoingStreams_++;\n  HTTPSessionBase::onNewOutgoingStream(outgoingStreams_);\n}\n\nvoid\nHTTPSession::onWriteSuccess(uint64_t bytesWritten) {\n  DestructorGuard dg(this);\n  bytesWritten_ += bytesWritten;\n  transportInfo_.totalBytes += bytesWritten;\n  CHECK(writeTimeout_.isScheduled());\n  if (pendingWrites_.empty()) {\n    VLOG(10) << \"Cancel write timer on last successful write\";\n    writeTimeout_.cancelTimeout();\n  } else {\n    VLOG(10) << \"Refresh write timer on writeSuccess\";\n    timeout_.scheduleTimeout(&writeTimeout_);\n  }\n\n  if (infoCallback_) {\n    infoCallback_->onWrite(*this, bytesWritten);\n  }\n\n  VLOG(5) << \"total bytesWritten_: \" << bytesWritten_;\n\n  // processByteEvents will return true if it has been replaced with another\n  // tracker in the middle and needs to be re-run.  Should happen at most\n  // once.  while with no body is intentional\n  while (byteEventTracker_ &&\n         byteEventTracker_->processByteEvents(\n           byteEventTracker_, bytesWritten_)) {} // pass\n\n  if ((!codec_->isReusable() || readsShutdown()) && (transactions_.empty())) {\n    if (!codec_->isReusable()) {\n      // Shouldn't happen unless there is a bug. This can only happen when\n      // someone calls shutdownTransport, but did not specify a reason before.\n      setCloseReason(ConnectionCloseReason::UNKNOWN);\n    }\n    VLOG(4) << *this << \" shutdown from onWriteSuccess\";\n    shutdownTransport(true, true);\n  }\n  numActiveWrites_--;\n  if (!inLoopCallback_) {\n    updateWriteCount();\n    // safe to resume here:\n    updateWriteBufSize(-folly::to<int64_t>(bytesWritten));\n    // PRIO_FIXME: this is done because of the corking business...\n    //             in the future we may want to have a pull model\n    //             whereby the socket asks us for a given amount of\n    //             data to send...\n    if (numActiveWrites_ == 0 && hasMoreWrites()) {\n      runLoopCallback();\n    }\n  }\n  onWriteCompleted();\n\n  if (egressBytesLimit_ > 0 && bytesWritten_ >= egressBytesLimit_) {\n    VLOG(4) << \"Egress limit reached, shutting down \"\n      \"session (egressed \" << bytesWritten_ << \", limit set to \"\n      << egressBytesLimit_ << \")\";\n    shutdownTransport(true, true);\n  }\n}\n\nvoid\nHTTPSession::onWriteError(size_t bytesWritten,\n                          const AsyncSocketException& ex) {\n  VLOG(4) << *this << \" write error: \" << ex.what();\n  if (infoCallback_) {\n    infoCallback_->onWrite(*this, bytesWritten);\n  }\n\n  auto sslEx = dynamic_cast<const folly::SSLException*>(&ex);\n  // Save the SSL error, if there was one.  It will be recorded later\n  if (sslEx && sslEx->getSSLError() == folly::SSLError::SSL_ERROR) {\n    transportInfo_.sslError = ex.what();\n  }\n\n  setCloseReason(ConnectionCloseReason::IO_WRITE_ERROR);\n  shutdownTransportWithReset(kErrorWrite, ex.what());\n}\n\nvoid\nHTTPSession::onWriteCompleted() {\n  if (!writesDraining_) {\n    return;\n  }\n\n  if (numActiveWrites_) {\n    return;\n  }\n\n  // Don't shutdown if there might be more writes\n  if (!pendingWrites_.empty()) {\n    return;\n  }\n\n  // All finished draining writes, so shut down the egress\n  shutdownTransport(false, true);\n}\n\nvoid HTTPSession::onSessionParseError(const HTTPException& error) {\n  VLOG(4) << *this << \" session layer parse error. Terminate the session.\";\n  if (error.hasCodecStatusCode()) {\n    std::unique_ptr<folly::IOBuf> errorMsg =\n      folly::IOBuf::copyBuffer(error.what());\n    codec_->generateGoaway(writeBuf_,\n                           codec_->getLastIncomingStreamID(),\n                           error.getCodecStatusCode(),\n                           isHTTP2CodecProtocol(codec_->getProtocol()) ?\n                           std::move(errorMsg) : nullptr);\n    scheduleWrite();\n  }\n  setCloseReason(ConnectionCloseReason::SESSION_PARSE_ERROR);\n  shutdownTransport(true, true);\n}\n\nvoid HTTPSession::onNewTransactionParseError(HTTPCodec::StreamID streamID,\n                                             const HTTPException& error) {\n  VLOG(4) << *this << \" parse error with new transaction\";\n  if (error.hasCodecStatusCode()) {\n    codec_->generateRstStream(writeBuf_, streamID, error.getCodecStatusCode());\n    scheduleWrite();\n  }\n  if (!codec_->isReusable()) {\n    // HTTP 1x codec does not support per stream abort so this will\n    // render the codec not reusable\n    setCloseReason(ConnectionCloseReason::SESSION_PARSE_ERROR);\n  }\n}\n\nvoid\nHTTPSession::pauseReads() {\n  // Make sure the parser is paused.  Note that if reads are shutdown\n  // before they are paused, we never make it past the if.\n  codec_->setParserPaused(true);\n  if (!readsUnpaused() ||\n      (codec_->supportsParallelRequests() &&\n       !ingressLimitExceeded())) {\n    return;\n  }\n  pauseReadsImpl();\n}\n\nvoid HTTPSession::pauseReadsImpl() {\n  VLOG(4) << *this << \": pausing reads\";\n  if (infoCallback_) {\n    infoCallback_->onIngressPaused(*this);\n  }\n  cancelTimeout();\n  sock_->setReadCB(nullptr);\n  reads_ = SocketState::PAUSED;\n}\n\nvoid\nHTTPSession::resumeReads() {\n  if (!readsPaused() ||\n      (codec_->supportsParallelRequests() &&\n       ingressLimitExceeded())) {\n    return;\n  }\n  resumeReadsImpl();\n}\n\nvoid HTTPSession::resumeReadsImpl() {\n  VLOG(4) << *this << \": resuming reads\";\n  resetTimeout();\n  reads_ = SocketState::UNPAUSED;\n  codec_->setParserPaused(false);\n  if (!isLoopCallbackScheduled()) {\n    sock_->getEventBase()->runInLoop(this);\n  }\n}\n\nbool\nHTTPSession::hasMoreWrites() const {\n  VLOG(10) << __PRETTY_FUNCTION__\n    << \" numActiveWrites_: \" << numActiveWrites_\n    << \" pendingWrites_.empty(): \" << pendingWrites_.empty()\n    << \" pendingWrites_.size(): \" << pendingWrites_.size()\n    << \" txnEgressQueue_.empty(): \" << txnEgressQueue_.empty();\n\n  return (numActiveWrites_ != 0) ||\n    !pendingWrites_.empty() || writeBuf_.front() ||\n    !txnEgressQueue_.empty();\n}\n\nvoid HTTPSession::errorOnAllTransactions(\n    ProxygenError err,\n    const std::string& errorMsg) {\n  std::vector<HTTPCodec::StreamID> ids;\n  for (const auto& txn: transactions_) {\n    ids.push_back(txn.first);\n  }\n  errorOnTransactionIds(ids, err, errorMsg);\n}\n\nvoid HTTPSession::errorOnTransactionIds(\n  const std::vector<HTTPCodec::StreamID>& ids,\n  ProxygenError err,\n  const std::string& errorMsg) {\n  std::string extraErrorMsg;\n  if (!errorMsg.empty()) {\n    extraErrorMsg = folly::to<std::string>(\". \", errorMsg);\n  }\n\n  for (auto id: ids) {\n    HTTPException ex(HTTPException::Direction::INGRESS_AND_EGRESS,\n      folly::to<std::string>(getErrorString(err),\n        \" on transaction id: \", id,\n        extraErrorMsg));\n    ex.setProxygenError(err);\n    errorOnTransactionId(id, std::move(ex));\n  }\n}\n\nvoid HTTPSession::errorOnTransactionId(\n    HTTPCodec::StreamID id,\n    HTTPException ex) {\n  auto txn = findTransaction(id);\n  if (txn != nullptr) {\n    txn->onError(std::move(ex));\n  }\n}\n\nvoid HTTPSession::resumeTransactions() {\n  CHECK(!inResume_);\n  inResume_ = true;\n  DestructorGuard g(this);\n  auto resumeFn = [] (HTTP2PriorityQueue&, HTTPCodec::StreamID,\n                      HTTPTransaction *txn, double) {\n    if (txn) {\n      txn->resumeEgress();\n    }\n    return false;\n  };\n  auto stopFn = [this] {\n    return (transactions_.empty() || egressLimitExceeded());\n  };\n\n  txnEgressQueue_.iterateBFS(resumeFn, stopFn, true /* all */);\n  inResume_ = false;\n  if (pendingPause_) {\n    VLOG(3) << \"Pausing txn egress for \" << *this;\n    pendingPause_ = false;\n    invokeOnAllTransactions(&HTTPTransaction::pauseEgress);\n  }\n}\n\nvoid HTTPSession::onConnectionSendWindowOpen() {\n  flowControlTimeout_.cancelTimeout();\n  // We can write more now. Schedule a write.\n  scheduleWrite();\n}\n\nvoid HTTPSession::onConnectionSendWindowClosed() {\n  if(!txnEgressQueue_.empty()) {\n    VLOG(4) << *this << \" session stalled by flow control\";\n    if (sessionStats_) {\n      sessionStats_->recordSessionStalled();\n    }\n  }\n  DCHECK(!flowControlTimeout_.isScheduled());\n  if (infoCallback_) {\n    infoCallback_->onFlowControlWindowClosed(*this);\n  }\n  auto timeout = flowControlTimeout_.getTimeoutDuration();\n  if (timeout != std::chrono::milliseconds(0)) {\n    timeout_.scheduleTimeout(&flowControlTimeout_, timeout);\n  } else {\n    timeout_.scheduleTimeout(&flowControlTimeout_);\n  }\n}\n\nHTTPCodec::StreamID HTTPSession::getGracefulGoawayAck() const {\n  if (!codec_->isReusable() || codec_->isWaitingToDrain()) {\n    // TODO: just track last stream ID inside HTTPSession since this logic\n    // is shared between HTTP/2 and SPDY\n    return codec_->getLastIncomingStreamID();\n  }\n  VLOG(4) << *this << \" getGracefulGoawayAck is reusable and not draining\";\n  // return the maximum possible stream id\n  return std::numeric_limits<int32_t>::max();\n}\n\nvoid HTTPSession::invalidStream(HTTPCodec::StreamID stream, ErrorCode code) {\n  if (!codec_->supportsParallelRequests()) {\n    LOG(ERROR) << \"Invalid stream on non-parallel codec.\";\n    return;\n  }\n\n  HTTPException err(HTTPException::Direction::INGRESS_AND_EGRESS,\n                    folly::to<std::string>(\"invalid stream=\", stream));\n  // TODO: Below line will change for HTTP/2 -- just call a const getter\n  // function for the status code.\n  err.setCodecStatusCode(code);\n  onError(stream, err, true);\n}\n\nvoid HTTPSession::onPingReplyLatency(int64_t latency) noexcept {\n  if (infoCallback_ && latency >= 0) {\n    infoCallback_->onPingReplySent(latency);\n  }\n}\n\nvoid HTTPSession::onDeleteAckEvent() noexcept {\n  if (readsShutdown()) {\n    shutdownTransport(true, transactions_.empty());\n  }\n}\n\nvoid HTTPSession::onEgressBuffered() {\n  if (infoCallback_) {\n    infoCallback_->onEgressBuffered(*this);\n  }\n}\n\nvoid HTTPSession::onEgressBufferCleared() {\n  if (infoCallback_) {\n    infoCallback_->onEgressBufferCleared(*this);\n  }\n}\n\nvoid HTTPSession::onReplaySafe() noexcept {\n  CHECK(sock_);\n  sock_->setReplaySafetyCallback(nullptr);\n\n  if (infoCallback_) {\n    infoCallback_->onFullHandshakeCompletion(*this);\n  }\n\n  for (auto callback : waitingForReplaySafety_) {\n    callback->onReplaySafe();\n  }\n  waitingForReplaySafety_.clear();\n}\n\nvoid HTTPSession::onLastByteEvent(\n    HTTPTransaction* txn, uint64_t eomOffset, bool eomTracked) noexcept {\n  if (!sock_->isEorTrackingEnabled() || !eomTracked) {\n    return;\n  }\n\n  if (eomOffset != sock_->getAppBytesWritten()) {\n    VLOG(2) << \"tracking ack to last app byte \" << eomOffset\n        << \" while \" << sock_->getAppBytesWritten()\n        << \" app bytes have already been written\";\n    return;\n  }\n\n  VLOG(5) << \"tracking raw last byte \" << sock_->getRawBytesWritten()\n          << \" while the app last byte is \" << eomOffset;\n\n  byteEventTracker_->addAckByteEvent(sock_->getRawBytesWritten(), txn);\n}\n\n\n\n} // proxygen\n"], "filenames": ["proxygen/lib/http/session/HTTPSession.cpp"], "buggy_code_start_loc": [1351], "buggy_code_end_loc": [1383], "fixing_code_start_loc": [1352], "fixing_code_end_loc": [1392], "type": "CWE-20", "message": "Proxygen fails to validate that a secondary auth manager is set before dereferencing it. That can cause a denial of service issue when parsing a Certificate/CertificateRequest HTTP2 Frame over a fizz (TLS 1.3) transport. This issue affects Proxygen releases starting from v2018.10.29.00 until the fix in v2018.11.19.00.", "other": {"cve": {"id": "CVE-2018-6343", "sourceIdentifier": "cve-assign@fb.com", "published": "2018-12-31T22:29:00.527", "lastModified": "2019-10-09T23:41:47.377", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "Proxygen fails to validate that a secondary auth manager is set before dereferencing it. That can cause a denial of service issue when parsing a Certificate/CertificateRequest HTTP2 Frame over a fizz (TLS 1.3) transport. This issue affects Proxygen releases starting from v2018.10.29.00 until the fix in v2018.11.19.00."}, {"lang": "es", "value": "Proxygen no logra validar que un gestor de autenticaci\u00f3n secundario sea fijado antes de desreferenciarse. Esto podr\u00eda provocar una denegaci\u00f3n de servicio (DoS) cuando se analiza un frame HTTP2 \"Certificate/CertificateRequest\" sobre un transporte del tipo fizz (TLS 1.3). Este problema afecta a las distribuciones de Proxygen desde la versi\u00f3n v2018.10.29.00 hasta que se arregla en la v2018.10.29.00."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-20"}]}, {"source": "cve-assign@fb.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:facebook:proxygen:*:*:*:*:*:*:*:*", "versionStartIncluding": "2018.10.29.00", "versionEndExcluding": "2018.11.19.00", "matchCriteriaId": "2AE8279F-6D1C-49A7-BD94-40EEB7DA3B6F"}]}]}], "references": [{"url": "https://github.com/facebook/proxygen/commit/0600ebe59c3e82cd012def77ca9ca1918da74a71", "source": "cve-assign@fb.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/facebook/proxygen/commit/0600ebe59c3e82cd012def77ca9ca1918da74a71"}}
{"buggy_code": ["package fasthttp\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"html\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"mime\"\n\t\"net/http\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/andybalholm/brotli\"\n\t\"github.com/klauspost/compress/gzip\"\n\t\"github.com/valyala/bytebufferpool\"\n)\n\n// ServeFileBytesUncompressed returns HTTP response containing file contents\n// from the given path.\n//\n// Directory contents is returned if path points to directory.\n//\n// ServeFileBytes may be used for saving network traffic when serving files\n// with good compression ratio.\n//\n// See also RequestCtx.SendFileBytes.\nfunc ServeFileBytesUncompressed(ctx *RequestCtx, path []byte) {\n\tServeFileUncompressed(ctx, b2s(path))\n}\n\n// ServeFileUncompressed returns HTTP response containing file contents\n// from the given path.\n//\n// Directory contents is returned if path points to directory.\n//\n// ServeFile may be used for saving network traffic when serving files\n// with good compression ratio.\n//\n// See also RequestCtx.SendFile.\nfunc ServeFileUncompressed(ctx *RequestCtx, path string) {\n\tctx.Request.Header.DelBytes(strAcceptEncoding)\n\tServeFile(ctx, path)\n}\n\n// ServeFileBytes returns HTTP response containing compressed file contents\n// from the given path.\n//\n// HTTP response may contain uncompressed file contents in the following cases:\n//\n//   * Missing 'Accept-Encoding: gzip' request header.\n//   * No write access to directory containing the file.\n//\n// Directory contents is returned if path points to directory.\n//\n// Use ServeFileBytesUncompressed is you don't need serving compressed\n// file contents.\n//\n// See also RequestCtx.SendFileBytes.\nfunc ServeFileBytes(ctx *RequestCtx, path []byte) {\n\tServeFile(ctx, b2s(path))\n}\n\n// ServeFile returns HTTP response containing compressed file contents\n// from the given path.\n//\n// HTTP response may contain uncompressed file contents in the following cases:\n//\n//   * Missing 'Accept-Encoding: gzip' request header.\n//   * No write access to directory containing the file.\n//\n// Directory contents is returned if path points to directory.\n//\n// Use ServeFileUncompressed is you don't need serving compressed file contents.\n//\n// See also RequestCtx.SendFile.\nfunc ServeFile(ctx *RequestCtx, path string) {\n\trootFSOnce.Do(func() {\n\t\trootFSHandler = rootFS.NewRequestHandler()\n\t})\n\tif len(path) == 0 || path[0] != '/' {\n\t\t// extend relative path to absolute path\n\t\thasTrailingSlash := len(path) > 0 && path[len(path)-1] == '/'\n\t\tvar err error\n\t\tif path, err = filepath.Abs(path); err != nil {\n\t\t\tctx.Logger().Printf(\"cannot resolve path %q to absolute file path: %s\", path, err)\n\t\t\tctx.Error(\"Internal Server Error\", StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t\tif hasTrailingSlash {\n\t\t\tpath += \"/\"\n\t\t}\n\t}\n\tctx.Request.SetRequestURI(path)\n\trootFSHandler(ctx)\n}\n\nvar (\n\trootFSOnce sync.Once\n\trootFS     = &FS{\n\t\tRoot:               \"/\",\n\t\tGenerateIndexPages: true,\n\t\tCompress:           true,\n\t\tCompressBrotli:     true,\n\t\tAcceptByteRange:    true,\n\t}\n\trootFSHandler RequestHandler\n)\n\n// PathRewriteFunc must return new request path based on arbitrary ctx\n// info such as ctx.Path().\n//\n// Path rewriter is used in FS for translating the current request\n// to the local filesystem path relative to FS.Root.\n//\n// The returned path must not contain '/../' substrings due to security reasons,\n// since such paths may refer files outside FS.Root.\n//\n// The returned path may refer to ctx members. For example, ctx.Path().\ntype PathRewriteFunc func(ctx *RequestCtx) []byte\n\n// NewVHostPathRewriter returns path rewriter, which strips slashesCount\n// leading slashes from the path and prepends the path with request's host,\n// thus simplifying virtual hosting for static files.\n//\n// Examples:\n//\n//   * host=foobar.com, slashesCount=0, original path=\"/foo/bar\".\n//     Resulting path: \"/foobar.com/foo/bar\"\n//\n//   * host=img.aaa.com, slashesCount=1, original path=\"/images/123/456.jpg\"\n//     Resulting path: \"/img.aaa.com/123/456.jpg\"\n//\nfunc NewVHostPathRewriter(slashesCount int) PathRewriteFunc {\n\treturn func(ctx *RequestCtx) []byte {\n\t\tpath := stripLeadingSlashes(ctx.Path(), slashesCount)\n\t\thost := ctx.Host()\n\t\tif n := bytes.IndexByte(host, '/'); n >= 0 {\n\t\t\thost = nil\n\t\t}\n\t\tif len(host) == 0 {\n\t\t\thost = strInvalidHost\n\t\t}\n\t\tb := bytebufferpool.Get()\n\t\tb.B = append(b.B, '/')\n\t\tb.B = append(b.B, host...)\n\t\tb.B = append(b.B, path...)\n\t\tctx.URI().SetPathBytes(b.B)\n\t\tbytebufferpool.Put(b)\n\n\t\treturn ctx.Path()\n\t}\n}\n\nvar strInvalidHost = []byte(\"invalid-host\")\n\n// NewPathSlashesStripper returns path rewriter, which strips slashesCount\n// leading slashes from the path.\n//\n// Examples:\n//\n//   * slashesCount = 0, original path: \"/foo/bar\", result: \"/foo/bar\"\n//   * slashesCount = 1, original path: \"/foo/bar\", result: \"/bar\"\n//   * slashesCount = 2, original path: \"/foo/bar\", result: \"\"\n//\n// The returned path rewriter may be used as FS.PathRewrite .\nfunc NewPathSlashesStripper(slashesCount int) PathRewriteFunc {\n\treturn func(ctx *RequestCtx) []byte {\n\t\treturn stripLeadingSlashes(ctx.Path(), slashesCount)\n\t}\n}\n\n// NewPathPrefixStripper returns path rewriter, which removes prefixSize bytes\n// from the path prefix.\n//\n// Examples:\n//\n//   * prefixSize = 0, original path: \"/foo/bar\", result: \"/foo/bar\"\n//   * prefixSize = 3, original path: \"/foo/bar\", result: \"o/bar\"\n//   * prefixSize = 7, original path: \"/foo/bar\", result: \"r\"\n//\n// The returned path rewriter may be used as FS.PathRewrite .\nfunc NewPathPrefixStripper(prefixSize int) PathRewriteFunc {\n\treturn func(ctx *RequestCtx) []byte {\n\t\tpath := ctx.Path()\n\t\tif len(path) >= prefixSize {\n\t\t\tpath = path[prefixSize:]\n\t\t}\n\t\treturn path\n\t}\n}\n\n// FS represents settings for request handler serving static files\n// from the local filesystem.\n//\n// It is prohibited copying FS values. Create new values instead.\ntype FS struct {\n\tnoCopy noCopy //nolint:unused,structcheck\n\n\t// Path to the root directory to serve files from.\n\tRoot string\n\n\t// List of index file names to try opening during directory access.\n\t//\n\t// For example:\n\t//\n\t//     * index.html\n\t//     * index.htm\n\t//     * my-super-index.xml\n\t//\n\t// By default the list is empty.\n\tIndexNames []string\n\n\t// Index pages for directories without files matching IndexNames\n\t// are automatically generated if set.\n\t//\n\t// Directory index generation may be quite slow for directories\n\t// with many files (more than 1K), so it is discouraged enabling\n\t// index pages' generation for such directories.\n\t//\n\t// By default index pages aren't generated.\n\tGenerateIndexPages bool\n\n\t// Transparently compresses responses if set to true.\n\t//\n\t// The server tries minimizing CPU usage by caching compressed files.\n\t// It adds CompressedFileSuffix suffix to the original file name and\n\t// tries saving the resulting compressed file under the new file name.\n\t// So it is advisable to give the server write access to Root\n\t// and to all inner folders in order to minimize CPU usage when serving\n\t// compressed responses.\n\t//\n\t// Transparent compression is disabled by default.\n\tCompress bool\n\n\t// Uses brotli encoding and fallbacks to gzip in responses if set to true, uses gzip if set to false.\n\t//\n\t// This value has sense only if Compress is set.\n\t//\n\t// Brotli encoding is disabled by default.\n\tCompressBrotli bool\n\n\t// Enables byte range requests if set to true.\n\t//\n\t// Byte range requests are disabled by default.\n\tAcceptByteRange bool\n\n\t// Path rewriting function.\n\t//\n\t// By default request path is not modified.\n\tPathRewrite PathRewriteFunc\n\n\t// PathNotFound fires when file is not found in filesystem\n\t// this functions tries to replace \"Cannot open requested path\"\n\t// server response giving to the programmer the control of server flow.\n\t//\n\t// By default PathNotFound returns\n\t// \"Cannot open requested path\"\n\tPathNotFound RequestHandler\n\n\t// Expiration duration for inactive file handlers.\n\t//\n\t// FSHandlerCacheDuration is used by default.\n\tCacheDuration time.Duration\n\n\t// Suffix to add to the name of cached compressed file.\n\t//\n\t// This value has sense only if Compress is set.\n\t//\n\t// FSCompressedFileSuffix is used by default.\n\tCompressedFileSuffix string\n\n\t// Suffixes list to add to compressedFileSuffix depending on encoding\n\t//\n\t// This value has sense only if Compress is set.\n\t//\n\t// FSCompressedFileSuffixes is used by default.\n\tCompressedFileSuffixes map[string]string\n\n\t// If CleanStop is set, the channel can be closed to stop the cleanup handlers\n\t// for the FS RequestHandlers created with NewRequestHandler.\n\t// NEVER close this channel while the handler is still being used!\n\tCleanStop chan struct{}\n\n\tonce sync.Once\n\th    RequestHandler\n}\n\n// FSCompressedFileSuffix is the suffix FS adds to the original file names\n// when trying to store compressed file under the new file name.\n// See FS.Compress for details.\nconst FSCompressedFileSuffix = \".fasthttp.gz\"\n\n// FSCompressedFileSuffixes is the suffixes FS adds to the original file names depending on encoding\n// when trying to store compressed file under the new file name.\n// See FS.Compress for details.\nvar FSCompressedFileSuffixes = map[string]string{\n\t\"gzip\": \".fasthttp.gz\",\n\t\"br\":   \".fasthttp.br\",\n}\n\n// FSHandlerCacheDuration is the default expiration duration for inactive\n// file handlers opened by FS.\nconst FSHandlerCacheDuration = 10 * time.Second\n\n// FSHandler returns request handler serving static files from\n// the given root folder.\n//\n// stripSlashes indicates how many leading slashes must be stripped\n// from requested path before searching requested file in the root folder.\n// Examples:\n//\n//   * stripSlashes = 0, original path: \"/foo/bar\", result: \"/foo/bar\"\n//   * stripSlashes = 1, original path: \"/foo/bar\", result: \"/bar\"\n//   * stripSlashes = 2, original path: \"/foo/bar\", result: \"\"\n//\n// The returned request handler automatically generates index pages\n// for directories without index.html.\n//\n// The returned handler caches requested file handles\n// for FSHandlerCacheDuration.\n// Make sure your program has enough 'max open files' limit aka\n// 'ulimit -n' if root folder contains many files.\n//\n// Do not create multiple request handler instances for the same\n// (root, stripSlashes) arguments - just reuse a single instance.\n// Otherwise goroutine leak will occur.\nfunc FSHandler(root string, stripSlashes int) RequestHandler {\n\tfs := &FS{\n\t\tRoot:               root,\n\t\tIndexNames:         []string{\"index.html\"},\n\t\tGenerateIndexPages: true,\n\t\tAcceptByteRange:    true,\n\t}\n\tif stripSlashes > 0 {\n\t\tfs.PathRewrite = NewPathSlashesStripper(stripSlashes)\n\t}\n\treturn fs.NewRequestHandler()\n}\n\n// NewRequestHandler returns new request handler with the given FS settings.\n//\n// The returned handler caches requested file handles\n// for FS.CacheDuration.\n// Make sure your program has enough 'max open files' limit aka\n// 'ulimit -n' if FS.Root folder contains many files.\n//\n// Do not create multiple request handlers from a single FS instance -\n// just reuse a single request handler.\nfunc (fs *FS) NewRequestHandler() RequestHandler {\n\tfs.once.Do(fs.initRequestHandler)\n\treturn fs.h\n}\n\nfunc (fs *FS) initRequestHandler() {\n\troot := fs.Root\n\n\t// serve files from the current working directory if root is empty\n\tif len(root) == 0 {\n\t\troot = \".\"\n\t}\n\n\t// strip trailing slashes from the root path\n\tfor len(root) > 0 && root[len(root)-1] == '/' {\n\t\troot = root[:len(root)-1]\n\t}\n\n\tcacheDuration := fs.CacheDuration\n\tif cacheDuration <= 0 {\n\t\tcacheDuration = FSHandlerCacheDuration\n\t}\n\n\tcompressedFileSuffixes := fs.CompressedFileSuffixes\n\tif len(compressedFileSuffixes[\"br\"]) == 0 || len(compressedFileSuffixes[\"gzip\"]) == 0 ||\n\t\tcompressedFileSuffixes[\"br\"] == compressedFileSuffixes[\"gzip\"] {\n\t\tcompressedFileSuffixes = FSCompressedFileSuffixes\n\t}\n\n\tif len(fs.CompressedFileSuffix) > 0 {\n\t\tcompressedFileSuffixes[\"gzip\"] = fs.CompressedFileSuffix\n\t\tcompressedFileSuffixes[\"br\"] = FSCompressedFileSuffixes[\"br\"]\n\t}\n\n\th := &fsHandler{\n\t\troot:                   root,\n\t\tindexNames:             fs.IndexNames,\n\t\tpathRewrite:            fs.PathRewrite,\n\t\tgenerateIndexPages:     fs.GenerateIndexPages,\n\t\tcompress:               fs.Compress,\n\t\tcompressBrotli:         fs.CompressBrotli,\n\t\tpathNotFound:           fs.PathNotFound,\n\t\tacceptByteRange:        fs.AcceptByteRange,\n\t\tcacheDuration:          cacheDuration,\n\t\tcompressedFileSuffixes: compressedFileSuffixes,\n\t\tcache:                  make(map[string]*fsFile),\n\t\tcacheBrotli:            make(map[string]*fsFile),\n\t\tcacheGzip:              make(map[string]*fsFile),\n\t}\n\n\tgo func() {\n\t\tvar pendingFiles []*fsFile\n\n\t\tclean := func() {\n\t\t\tpendingFiles = h.cleanCache(pendingFiles)\n\t\t}\n\n\t\tif fs.CleanStop != nil {\n\t\t\tt := time.NewTicker(cacheDuration / 2)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-t.C:\n\t\t\t\t\tclean()\n\t\t\t\tcase _, stillOpen := <-fs.CleanStop:\n\t\t\t\t\t// Ignore values send on the channel, only stop when it is closed.\n\t\t\t\t\tif !stillOpen {\n\t\t\t\t\t\tt.Stop()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor {\n\t\t\ttime.Sleep(cacheDuration / 2)\n\t\t\tclean()\n\t\t}\n\t}()\n\n\tfs.h = h.handleRequest\n}\n\ntype fsHandler struct {\n\troot                   string\n\tindexNames             []string\n\tpathRewrite            PathRewriteFunc\n\tpathNotFound           RequestHandler\n\tgenerateIndexPages     bool\n\tcompress               bool\n\tcompressBrotli         bool\n\tacceptByteRange        bool\n\tcacheDuration          time.Duration\n\tcompressedFileSuffixes map[string]string\n\n\tcache       map[string]*fsFile\n\tcacheBrotli map[string]*fsFile\n\tcacheGzip   map[string]*fsFile\n\tcacheLock   sync.Mutex\n\n\tsmallFileReaderPool sync.Pool\n}\n\ntype fsFile struct {\n\th             *fsHandler\n\tf             *os.File\n\tdirIndex      []byte\n\tcontentType   string\n\tcontentLength int\n\tcompressed    bool\n\n\tlastModified    time.Time\n\tlastModifiedStr []byte\n\n\tt            time.Time\n\treadersCount int\n\n\tbigFiles     []*bigFileReader\n\tbigFilesLock sync.Mutex\n}\n\nfunc (ff *fsFile) NewReader() (io.Reader, error) {\n\tif ff.isBig() {\n\t\tr, err := ff.bigFileReader()\n\t\tif err != nil {\n\t\t\tff.decReadersCount()\n\t\t}\n\t\treturn r, err\n\t}\n\treturn ff.smallFileReader(), nil\n}\n\nfunc (ff *fsFile) smallFileReader() io.Reader {\n\tv := ff.h.smallFileReaderPool.Get()\n\tif v == nil {\n\t\tv = &fsSmallFileReader{}\n\t}\n\tr := v.(*fsSmallFileReader)\n\tr.ff = ff\n\tr.endPos = ff.contentLength\n\tif r.startPos > 0 {\n\t\tpanic(\"BUG: fsSmallFileReader with non-nil startPos found in the pool\")\n\t}\n\treturn r\n}\n\n// files bigger than this size are sent with sendfile\nconst maxSmallFileSize = 2 * 4096\n\nfunc (ff *fsFile) isBig() bool {\n\treturn ff.contentLength > maxSmallFileSize && len(ff.dirIndex) == 0\n}\n\nfunc (ff *fsFile) bigFileReader() (io.Reader, error) {\n\tif ff.f == nil {\n\t\tpanic(\"BUG: ff.f must be non-nil in bigFileReader\")\n\t}\n\n\tvar r io.Reader\n\n\tff.bigFilesLock.Lock()\n\tn := len(ff.bigFiles)\n\tif n > 0 {\n\t\tr = ff.bigFiles[n-1]\n\t\tff.bigFiles = ff.bigFiles[:n-1]\n\t}\n\tff.bigFilesLock.Unlock()\n\n\tif r != nil {\n\t\treturn r, nil\n\t}\n\n\tf, err := os.Open(ff.f.Name())\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot open already opened file: %w\", err)\n\t}\n\treturn &bigFileReader{\n\t\tf:  f,\n\t\tff: ff,\n\t\tr:  f,\n\t}, nil\n}\n\nfunc (ff *fsFile) Release() {\n\tif ff.f != nil {\n\t\tff.f.Close()\n\n\t\tif ff.isBig() {\n\t\t\tff.bigFilesLock.Lock()\n\t\t\tfor _, r := range ff.bigFiles {\n\t\t\t\tr.f.Close()\n\t\t\t}\n\t\t\tff.bigFilesLock.Unlock()\n\t\t}\n\t}\n}\n\nfunc (ff *fsFile) decReadersCount() {\n\tff.h.cacheLock.Lock()\n\tff.readersCount--\n\tif ff.readersCount < 0 {\n\t\tpanic(\"BUG: negative fsFile.readersCount!\")\n\t}\n\tff.h.cacheLock.Unlock()\n}\n\n// bigFileReader attempts to trigger sendfile\n// for sending big files over the wire.\ntype bigFileReader struct {\n\tf  *os.File\n\tff *fsFile\n\tr  io.Reader\n\tlr io.LimitedReader\n}\n\nfunc (r *bigFileReader) UpdateByteRange(startPos, endPos int) error {\n\tif _, err := r.f.Seek(int64(startPos), 0); err != nil {\n\t\treturn err\n\t}\n\tr.r = &r.lr\n\tr.lr.R = r.f\n\tr.lr.N = int64(endPos - startPos + 1)\n\treturn nil\n}\n\nfunc (r *bigFileReader) Read(p []byte) (int, error) {\n\treturn r.r.Read(p)\n}\n\nfunc (r *bigFileReader) WriteTo(w io.Writer) (int64, error) {\n\tif rf, ok := w.(io.ReaderFrom); ok {\n\t\t// fast path. Senfile must be triggered\n\t\treturn rf.ReadFrom(r.r)\n\t}\n\n\t// slow path\n\treturn copyZeroAlloc(w, r.r)\n}\n\nfunc (r *bigFileReader) Close() error {\n\tr.r = r.f\n\tn, err := r.f.Seek(0, 0)\n\tif err == nil {\n\t\tif n != 0 {\n\t\t\tpanic(\"BUG: File.Seek(0,0) returned (non-zero, nil)\")\n\t\t}\n\n\t\tff := r.ff\n\t\tff.bigFilesLock.Lock()\n\t\tff.bigFiles = append(ff.bigFiles, r)\n\t\tff.bigFilesLock.Unlock()\n\t} else {\n\t\tr.f.Close()\n\t}\n\tr.ff.decReadersCount()\n\treturn err\n}\n\ntype fsSmallFileReader struct {\n\tff       *fsFile\n\tstartPos int\n\tendPos   int\n}\n\nfunc (r *fsSmallFileReader) Close() error {\n\tff := r.ff\n\tff.decReadersCount()\n\tr.ff = nil\n\tr.startPos = 0\n\tr.endPos = 0\n\tff.h.smallFileReaderPool.Put(r)\n\treturn nil\n}\n\nfunc (r *fsSmallFileReader) UpdateByteRange(startPos, endPos int) error {\n\tr.startPos = startPos\n\tr.endPos = endPos + 1\n\treturn nil\n}\n\nfunc (r *fsSmallFileReader) Read(p []byte) (int, error) {\n\ttailLen := r.endPos - r.startPos\n\tif tailLen <= 0 {\n\t\treturn 0, io.EOF\n\t}\n\tif len(p) > tailLen {\n\t\tp = p[:tailLen]\n\t}\n\n\tff := r.ff\n\tif ff.f != nil {\n\t\tn, err := ff.f.ReadAt(p, int64(r.startPos))\n\t\tr.startPos += n\n\t\treturn n, err\n\t}\n\n\tn := copy(p, ff.dirIndex[r.startPos:])\n\tr.startPos += n\n\treturn n, nil\n}\n\nfunc (r *fsSmallFileReader) WriteTo(w io.Writer) (int64, error) {\n\tff := r.ff\n\n\tvar n int\n\tvar err error\n\tif ff.f == nil {\n\t\tn, err = w.Write(ff.dirIndex[r.startPos:r.endPos])\n\t\treturn int64(n), err\n\t}\n\n\tif rf, ok := w.(io.ReaderFrom); ok {\n\t\treturn rf.ReadFrom(r)\n\t}\n\n\tcurPos := r.startPos\n\tbufv := copyBufPool.Get()\n\tbuf := bufv.([]byte)\n\tfor err == nil {\n\t\ttailLen := r.endPos - curPos\n\t\tif tailLen <= 0 {\n\t\t\tbreak\n\t\t}\n\t\tif len(buf) > tailLen {\n\t\t\tbuf = buf[:tailLen]\n\t\t}\n\t\tn, err = ff.f.ReadAt(buf, int64(curPos))\n\t\tnw, errw := w.Write(buf[:n])\n\t\tcurPos += nw\n\t\tif errw == nil && nw != n {\n\t\t\tpanic(\"BUG: Write(p) returned (n, nil), where n != len(p)\")\n\t\t}\n\t\tif err == nil {\n\t\t\terr = errw\n\t\t}\n\t}\n\tcopyBufPool.Put(bufv)\n\n\tif err == io.EOF {\n\t\terr = nil\n\t}\n\treturn int64(curPos - r.startPos), err\n}\n\nfunc (h *fsHandler) cleanCache(pendingFiles []*fsFile) []*fsFile {\n\tvar filesToRelease []*fsFile\n\n\th.cacheLock.Lock()\n\n\t// Close files which couldn't be closed before due to non-zero\n\t// readers count on the previous run.\n\tvar remainingFiles []*fsFile\n\tfor _, ff := range pendingFiles {\n\t\tif ff.readersCount > 0 {\n\t\t\tremainingFiles = append(remainingFiles, ff)\n\t\t} else {\n\t\t\tfilesToRelease = append(filesToRelease, ff)\n\t\t}\n\t}\n\tpendingFiles = remainingFiles\n\n\tpendingFiles, filesToRelease = cleanCacheNolock(h.cache, pendingFiles, filesToRelease, h.cacheDuration)\n\tpendingFiles, filesToRelease = cleanCacheNolock(h.cacheBrotli, pendingFiles, filesToRelease, h.cacheDuration)\n\tpendingFiles, filesToRelease = cleanCacheNolock(h.cacheGzip, pendingFiles, filesToRelease, h.cacheDuration)\n\n\th.cacheLock.Unlock()\n\n\tfor _, ff := range filesToRelease {\n\t\tff.Release()\n\t}\n\n\treturn pendingFiles\n}\n\nfunc cleanCacheNolock(cache map[string]*fsFile, pendingFiles, filesToRelease []*fsFile, cacheDuration time.Duration) ([]*fsFile, []*fsFile) {\n\tt := time.Now()\n\tfor k, ff := range cache {\n\t\tif t.Sub(ff.t) > cacheDuration {\n\t\t\tif ff.readersCount > 0 {\n\t\t\t\t// There are pending readers on stale file handle,\n\t\t\t\t// so we cannot close it. Put it into pendingFiles\n\t\t\t\t// so it will be closed later.\n\t\t\t\tpendingFiles = append(pendingFiles, ff)\n\t\t\t} else {\n\t\t\t\tfilesToRelease = append(filesToRelease, ff)\n\t\t\t}\n\t\t\tdelete(cache, k)\n\t\t}\n\t}\n\treturn pendingFiles, filesToRelease\n}\n\nfunc (h *fsHandler) handleRequest(ctx *RequestCtx) {\n\tvar path []byte\n\tif h.pathRewrite != nil {\n\t\tpath = h.pathRewrite(ctx)\n\t} else {\n\t\tpath = ctx.Path()\n\t}\n\thasTrailingSlash := len(path) > 0 && path[len(path)-1] == '/'\n\tpath = stripTrailingSlashes(path)\n\n\tif n := bytes.IndexByte(path, 0); n >= 0 {\n\t\tctx.Logger().Printf(\"cannot serve path with nil byte at position %d: %q\", n, path)\n\t\tctx.Error(\"Are you a hacker?\", StatusBadRequest)\n\t\treturn\n\t}\n\tif h.pathRewrite != nil {\n\t\t// There is no need to check for '/../' if path = ctx.Path(),\n\t\t// since ctx.Path must normalize and sanitize the path.\n\n\t\tif n := bytes.Index(path, strSlashDotDotSlash); n >= 0 {\n\t\t\tctx.Logger().Printf(\"cannot serve path with '/../' at position %d due to security reasons: %q\", n, path)\n\t\t\tctx.Error(\"Internal Server Error\", StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t}\n\n\tmustCompress := false\n\tfileCache := h.cache\n\tfileEncoding := \"\"\n\tbyteRange := ctx.Request.Header.peek(strRange)\n\tif len(byteRange) == 0 && h.compress {\n\t\tif h.compressBrotli && ctx.Request.Header.HasAcceptEncodingBytes(strBr) {\n\t\t\tmustCompress = true\n\t\t\tfileCache = h.cacheBrotli\n\t\t\tfileEncoding = \"br\"\n\t\t} else if ctx.Request.Header.HasAcceptEncodingBytes(strGzip) {\n\t\t\tmustCompress = true\n\t\t\tfileCache = h.cacheGzip\n\t\t\tfileEncoding = \"gzip\"\n\t\t}\n\t}\n\n\th.cacheLock.Lock()\n\tff, ok := fileCache[string(path)]\n\tif ok {\n\t\tff.readersCount++\n\t}\n\th.cacheLock.Unlock()\n\n\tif !ok {\n\t\tpathStr := string(path)\n\t\tfilePath := h.root + pathStr\n\t\tvar err error\n\t\tff, err = h.openFSFile(filePath, mustCompress, fileEncoding)\n\t\tif mustCompress && err == errNoCreatePermission {\n\t\t\tctx.Logger().Printf(\"insufficient permissions for saving compressed file for %q. Serving uncompressed file. \"+\n\t\t\t\t\"Allow write access to the directory with this file in order to improve fasthttp performance\", filePath)\n\t\t\tmustCompress = false\n\t\t\tff, err = h.openFSFile(filePath, mustCompress, fileEncoding)\n\t\t}\n\t\tif err == errDirIndexRequired {\n\t\t\tif !hasTrailingSlash {\n\t\t\t\tctx.RedirectBytes(append(path, '/'), StatusFound)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tff, err = h.openIndexFile(ctx, filePath, mustCompress, fileEncoding)\n\t\t\tif err != nil {\n\t\t\t\tctx.Logger().Printf(\"cannot open dir index %q: %s\", filePath, err)\n\t\t\t\tctx.Error(\"Directory index is forbidden\", StatusForbidden)\n\t\t\t\treturn\n\t\t\t}\n\t\t} else if err != nil {\n\t\t\tctx.Logger().Printf(\"cannot open file %q: %s\", filePath, err)\n\t\t\tif h.pathNotFound == nil {\n\t\t\t\tctx.Error(\"Cannot open requested path\", StatusNotFound)\n\t\t\t} else {\n\t\t\t\tctx.SetStatusCode(StatusNotFound)\n\t\t\t\th.pathNotFound(ctx)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\th.cacheLock.Lock()\n\t\tff1, ok := fileCache[pathStr]\n\t\tif !ok {\n\t\t\tfileCache[pathStr] = ff\n\t\t\tff.readersCount++\n\t\t} else {\n\t\t\tff1.readersCount++\n\t\t}\n\t\th.cacheLock.Unlock()\n\n\t\tif ok {\n\t\t\t// The file has been already opened by another\n\t\t\t// goroutine, so close the current file and use\n\t\t\t// the file opened by another goroutine instead.\n\t\t\tff.Release()\n\t\t\tff = ff1\n\t\t}\n\t}\n\n\tif !ctx.IfModifiedSince(ff.lastModified) {\n\t\tff.decReadersCount()\n\t\tctx.NotModified()\n\t\treturn\n\t}\n\n\tr, err := ff.NewReader()\n\tif err != nil {\n\t\tctx.Logger().Printf(\"cannot obtain file reader for path=%q: %s\", path, err)\n\t\tctx.Error(\"Internal Server Error\", StatusInternalServerError)\n\t\treturn\n\t}\n\n\thdr := &ctx.Response.Header\n\tif ff.compressed {\n\t\tif fileEncoding == \"br\" {\n\t\t\thdr.SetCanonical(strContentEncoding, strBr)\n\t\t} else if fileEncoding == \"gzip\" {\n\t\t\thdr.SetCanonical(strContentEncoding, strGzip)\n\t\t}\n\t}\n\n\tstatusCode := StatusOK\n\tcontentLength := ff.contentLength\n\tif h.acceptByteRange {\n\t\thdr.SetCanonical(strAcceptRanges, strBytes)\n\t\tif len(byteRange) > 0 {\n\t\t\tstartPos, endPos, err := ParseByteRange(byteRange, contentLength)\n\t\t\tif err != nil {\n\t\t\t\tr.(io.Closer).Close()\n\t\t\t\tctx.Logger().Printf(\"cannot parse byte range %q for path=%q: %s\", byteRange, path, err)\n\t\t\t\tctx.Error(\"Range Not Satisfiable\", StatusRequestedRangeNotSatisfiable)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif err = r.(byteRangeUpdater).UpdateByteRange(startPos, endPos); err != nil {\n\t\t\t\tr.(io.Closer).Close()\n\t\t\t\tctx.Logger().Printf(\"cannot seek byte range %q for path=%q: %s\", byteRange, path, err)\n\t\t\t\tctx.Error(\"Internal Server Error\", StatusInternalServerError)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\thdr.SetContentRange(startPos, endPos, contentLength)\n\t\t\tcontentLength = endPos - startPos + 1\n\t\t\tstatusCode = StatusPartialContent\n\t\t}\n\t}\n\n\thdr.SetCanonical(strLastModified, ff.lastModifiedStr)\n\tif !ctx.IsHead() {\n\t\tctx.SetBodyStream(r, contentLength)\n\t} else {\n\t\tctx.Response.ResetBody()\n\t\tctx.Response.SkipBody = true\n\t\tctx.Response.Header.SetContentLength(contentLength)\n\t\tif rc, ok := r.(io.Closer); ok {\n\t\t\tif err := rc.Close(); err != nil {\n\t\t\t\tctx.Logger().Printf(\"cannot close file reader: %s\", err)\n\t\t\t\tctx.Error(\"Internal Server Error\", StatusInternalServerError)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\thdr.noDefaultContentType = true\n\tif len(hdr.ContentType()) == 0 {\n\t\tctx.SetContentType(ff.contentType)\n\t}\n\tctx.SetStatusCode(statusCode)\n}\n\ntype byteRangeUpdater interface {\n\tUpdateByteRange(startPos, endPos int) error\n}\n\n// ParseByteRange parses 'Range: bytes=...' header value.\n//\n// It follows https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.35 .\nfunc ParseByteRange(byteRange []byte, contentLength int) (startPos, endPos int, err error) {\n\tb := byteRange\n\tif !bytes.HasPrefix(b, strBytes) {\n\t\treturn 0, 0, fmt.Errorf(\"unsupported range units: %q. Expecting %q\", byteRange, strBytes)\n\t}\n\n\tb = b[len(strBytes):]\n\tif len(b) == 0 || b[0] != '=' {\n\t\treturn 0, 0, fmt.Errorf(\"missing byte range in %q\", byteRange)\n\t}\n\tb = b[1:]\n\n\tn := bytes.IndexByte(b, '-')\n\tif n < 0 {\n\t\treturn 0, 0, fmt.Errorf(\"missing the end position of byte range in %q\", byteRange)\n\t}\n\n\tif n == 0 {\n\t\tv, err := ParseUint(b[n+1:])\n\t\tif err != nil {\n\t\t\treturn 0, 0, err\n\t\t}\n\t\tstartPos := contentLength - v\n\t\tif startPos < 0 {\n\t\t\tstartPos = 0\n\t\t}\n\t\treturn startPos, contentLength - 1, nil\n\t}\n\n\tif startPos, err = ParseUint(b[:n]); err != nil {\n\t\treturn 0, 0, err\n\t}\n\tif startPos >= contentLength {\n\t\treturn 0, 0, fmt.Errorf(\"the start position of byte range cannot exceed %d. byte range %q\", contentLength-1, byteRange)\n\t}\n\n\tb = b[n+1:]\n\tif len(b) == 0 {\n\t\treturn startPos, contentLength - 1, nil\n\t}\n\n\tif endPos, err = ParseUint(b); err != nil {\n\t\treturn 0, 0, err\n\t}\n\tif endPos >= contentLength {\n\t\tendPos = contentLength - 1\n\t}\n\tif endPos < startPos {\n\t\treturn 0, 0, fmt.Errorf(\"the start position of byte range cannot exceed the end position. byte range %q\", byteRange)\n\t}\n\treturn startPos, endPos, nil\n}\n\nfunc (h *fsHandler) openIndexFile(ctx *RequestCtx, dirPath string, mustCompress bool, fileEncoding string) (*fsFile, error) {\n\tfor _, indexName := range h.indexNames {\n\t\tindexFilePath := dirPath + \"/\" + indexName\n\t\tff, err := h.openFSFile(indexFilePath, mustCompress, fileEncoding)\n\t\tif err == nil {\n\t\t\treturn ff, nil\n\t\t}\n\t\tif !os.IsNotExist(err) {\n\t\t\treturn nil, fmt.Errorf(\"cannot open file %q: %w\", indexFilePath, err)\n\t\t}\n\t}\n\n\tif !h.generateIndexPages {\n\t\treturn nil, fmt.Errorf(\"cannot access directory without index page. Directory %q\", dirPath)\n\t}\n\n\treturn h.createDirIndex(ctx.URI(), dirPath, mustCompress, fileEncoding)\n}\n\nvar (\n\terrDirIndexRequired   = errors.New(\"directory index required\")\n\terrNoCreatePermission = errors.New(\"no 'create file' permissions\")\n)\n\nfunc (h *fsHandler) createDirIndex(base *URI, dirPath string, mustCompress bool, fileEncoding string) (*fsFile, error) {\n\tw := &bytebufferpool.ByteBuffer{}\n\n\tbasePathEscaped := html.EscapeString(string(base.Path()))\n\tfmt.Fprintf(w, \"<html><head><title>%s</title><style>.dir { font-weight: bold }</style></head><body>\", basePathEscaped)\n\tfmt.Fprintf(w, \"<h1>%s</h1>\", basePathEscaped)\n\tfmt.Fprintf(w, \"<ul>\")\n\n\tif len(basePathEscaped) > 1 {\n\t\tvar parentURI URI\n\t\tbase.CopyTo(&parentURI)\n\t\tparentURI.Update(string(base.Path()) + \"/..\")\n\t\tparentPathEscaped := html.EscapeString(string(parentURI.Path()))\n\t\tfmt.Fprintf(w, `<li><a href=\"%s\" class=\"dir\">..</a></li>`, parentPathEscaped)\n\t}\n\n\tf, err := os.Open(dirPath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfileinfos, err := f.Readdir(0)\n\tf.Close()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfm := make(map[string]os.FileInfo, len(fileinfos))\n\tfilenames := make([]string, 0, len(fileinfos))\nnestedContinue:\n\tfor _, fi := range fileinfos {\n\t\tname := fi.Name()\n\t\tfor _, cfs := range h.compressedFileSuffixes {\n\t\t\tif strings.HasSuffix(name, cfs) {\n\t\t\t\t// Do not show compressed files on index page.\n\t\t\t\tcontinue nestedContinue\n\t\t\t}\n\t\t}\n\t\tfm[name] = fi\n\t\tfilenames = append(filenames, name)\n\t}\n\n\tvar u URI\n\tbase.CopyTo(&u)\n\tu.Update(string(u.Path()) + \"/\")\n\n\tsort.Strings(filenames)\n\tfor _, name := range filenames {\n\t\tu.Update(name)\n\t\tpathEscaped := html.EscapeString(string(u.Path()))\n\t\tfi := fm[name]\n\t\tauxStr := \"dir\"\n\t\tclassName := \"dir\"\n\t\tif !fi.IsDir() {\n\t\t\tauxStr = fmt.Sprintf(\"file, %d bytes\", fi.Size())\n\t\t\tclassName = \"file\"\n\t\t}\n\t\tfmt.Fprintf(w, `<li><a href=\"%s\" class=\"%s\">%s</a>, %s, last modified %s</li>`,\n\t\t\tpathEscaped, className, html.EscapeString(name), auxStr, fsModTime(fi.ModTime()))\n\t}\n\n\tfmt.Fprintf(w, \"</ul></body></html>\")\n\n\tif mustCompress {\n\t\tvar zbuf bytebufferpool.ByteBuffer\n\t\tif fileEncoding == \"br\" {\n\t\t\tzbuf.B = AppendBrotliBytesLevel(zbuf.B, w.B, CompressDefaultCompression)\n\t\t} else if fileEncoding == \"gzip\" {\n\t\t\tzbuf.B = AppendGzipBytesLevel(zbuf.B, w.B, CompressDefaultCompression)\n\t\t}\n\t\tw = &zbuf\n\t}\n\n\tdirIndex := w.B\n\tlastModified := time.Now()\n\tff := &fsFile{\n\t\th:               h,\n\t\tdirIndex:        dirIndex,\n\t\tcontentType:     \"text/html; charset=utf-8\",\n\t\tcontentLength:   len(dirIndex),\n\t\tcompressed:      mustCompress,\n\t\tlastModified:    lastModified,\n\t\tlastModifiedStr: AppendHTTPDate(nil, lastModified),\n\n\t\tt: lastModified,\n\t}\n\treturn ff, nil\n}\n\nconst (\n\tfsMinCompressRatio        = 0.8\n\tfsMaxCompressibleFileSize = 8 * 1024 * 1024\n)\n\nfunc (h *fsHandler) compressAndOpenFSFile(filePath string, fileEncoding string) (*fsFile, error) {\n\tf, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfileInfo, err := f.Stat()\n\tif err != nil {\n\t\tf.Close()\n\t\treturn nil, fmt.Errorf(\"cannot obtain info for file %q: %w\", filePath, err)\n\t}\n\n\tif fileInfo.IsDir() {\n\t\tf.Close()\n\t\treturn nil, errDirIndexRequired\n\t}\n\n\tif strings.HasSuffix(filePath, h.compressedFileSuffixes[fileEncoding]) ||\n\t\tfileInfo.Size() > fsMaxCompressibleFileSize ||\n\t\t!isFileCompressible(f, fsMinCompressRatio) {\n\t\treturn h.newFSFile(f, fileInfo, false, \"\")\n\t}\n\n\tcompressedFilePath := filePath + h.compressedFileSuffixes[fileEncoding]\n\tabsPath, err := filepath.Abs(compressedFilePath)\n\tif err != nil {\n\t\tf.Close()\n\t\treturn nil, fmt.Errorf(\"cannot determine absolute path for %q: %s\", compressedFilePath, err)\n\t}\n\n\tflock := getFileLock(absPath)\n\tflock.Lock()\n\tff, err := h.compressFileNolock(f, fileInfo, filePath, compressedFilePath, fileEncoding)\n\tflock.Unlock()\n\n\treturn ff, err\n}\n\nfunc (h *fsHandler) compressFileNolock(f *os.File, fileInfo os.FileInfo, filePath, compressedFilePath string, fileEncoding string) (*fsFile, error) {\n\t// Attempt to open compressed file created by another concurrent\n\t// goroutine.\n\t// It is safe opening such a file, since the file creation\n\t// is guarded by file mutex - see getFileLock call.\n\tif _, err := os.Stat(compressedFilePath); err == nil {\n\t\tf.Close()\n\t\treturn h.newCompressedFSFile(compressedFilePath, fileEncoding)\n\t}\n\n\t// Create temporary file, so concurrent goroutines don't use\n\t// it until it is created.\n\ttmpFilePath := compressedFilePath + \".tmp\"\n\tzf, err := os.Create(tmpFilePath)\n\tif err != nil {\n\t\tf.Close()\n\t\tif !os.IsPermission(err) {\n\t\t\treturn nil, fmt.Errorf(\"cannot create temporary file %q: %w\", tmpFilePath, err)\n\t\t}\n\t\treturn nil, errNoCreatePermission\n\t}\n\tif fileEncoding == \"br\" {\n\t\tzw := acquireStacklessBrotliWriter(zf, CompressDefaultCompression)\n\t\t_, err = copyZeroAlloc(zw, f)\n\t\tif err1 := zw.Flush(); err == nil {\n\t\t\terr = err1\n\t\t}\n\t\treleaseStacklessBrotliWriter(zw, CompressDefaultCompression)\n\t} else if fileEncoding == \"gzip\" {\n\t\tzw := acquireStacklessGzipWriter(zf, CompressDefaultCompression)\n\t\t_, err = copyZeroAlloc(zw, f)\n\t\tif err1 := zw.Flush(); err == nil {\n\t\t\terr = err1\n\t\t}\n\t\treleaseStacklessGzipWriter(zw, CompressDefaultCompression)\n\t}\n\tzf.Close()\n\tf.Close()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error when compressing file %q to %q: %w\", filePath, tmpFilePath, err)\n\t}\n\tif err = os.Chtimes(tmpFilePath, time.Now(), fileInfo.ModTime()); err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot change modification time to %s for tmp file %q: %s\",\n\t\t\tfileInfo.ModTime(), tmpFilePath, err)\n\t}\n\tif err = os.Rename(tmpFilePath, compressedFilePath); err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot move compressed file from %q to %q: %w\", tmpFilePath, compressedFilePath, err)\n\t}\n\treturn h.newCompressedFSFile(compressedFilePath, fileEncoding)\n}\n\nfunc (h *fsHandler) newCompressedFSFile(filePath string, fileEncoding string) (*fsFile, error) {\n\tf, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot open compressed file %q: %w\", filePath, err)\n\t}\n\tfileInfo, err := f.Stat()\n\tif err != nil {\n\t\tf.Close()\n\t\treturn nil, fmt.Errorf(\"cannot obtain info for compressed file %q: %w\", filePath, err)\n\t}\n\treturn h.newFSFile(f, fileInfo, true, fileEncoding)\n}\n\nfunc (h *fsHandler) openFSFile(filePath string, mustCompress bool, fileEncoding string) (*fsFile, error) {\n\tfilePathOriginal := filePath\n\tif mustCompress {\n\t\tfilePath += h.compressedFileSuffixes[fileEncoding]\n\t}\n\n\tf, err := os.Open(filePath)\n\tif err != nil {\n\t\tif mustCompress && os.IsNotExist(err) {\n\t\t\treturn h.compressAndOpenFSFile(filePathOriginal, fileEncoding)\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tfileInfo, err := f.Stat()\n\tif err != nil {\n\t\tf.Close()\n\t\treturn nil, fmt.Errorf(\"cannot obtain info for file %q: %w\", filePath, err)\n\t}\n\n\tif fileInfo.IsDir() {\n\t\tf.Close()\n\t\tif mustCompress {\n\t\t\treturn nil, fmt.Errorf(\"directory with unexpected suffix found: %q. Suffix: %q\",\n\t\t\t\tfilePath, h.compressedFileSuffixes[fileEncoding])\n\t\t}\n\t\treturn nil, errDirIndexRequired\n\t}\n\n\tif mustCompress {\n\t\tfileInfoOriginal, err := os.Stat(filePathOriginal)\n\t\tif err != nil {\n\t\t\tf.Close()\n\t\t\treturn nil, fmt.Errorf(\"cannot obtain info for original file %q: %w\", filePathOriginal, err)\n\t\t}\n\n\t\t// Only re-create the compressed file if there was more than a second between the mod times.\n\t\t// On MacOS the gzip seems to truncate the nanoseconds in the mod time causing the original file\n\t\t// to look newer than the gzipped file.\n\t\tif fileInfoOriginal.ModTime().Sub(fileInfo.ModTime()) >= time.Second {\n\t\t\t// The compressed file became stale. Re-create it.\n\t\t\tf.Close()\n\t\t\tos.Remove(filePath)\n\t\t\treturn h.compressAndOpenFSFile(filePathOriginal, fileEncoding)\n\t\t}\n\t}\n\n\treturn h.newFSFile(f, fileInfo, mustCompress, fileEncoding)\n}\n\nfunc (h *fsHandler) newFSFile(f *os.File, fileInfo os.FileInfo, compressed bool, fileEncoding string) (*fsFile, error) {\n\tn := fileInfo.Size()\n\tcontentLength := int(n)\n\tif n != int64(contentLength) {\n\t\tf.Close()\n\t\treturn nil, fmt.Errorf(\"too big file: %d bytes\", n)\n\t}\n\n\t// detect content-type\n\text := fileExtension(fileInfo.Name(), compressed, h.compressedFileSuffixes[fileEncoding])\n\tcontentType := mime.TypeByExtension(ext)\n\tif len(contentType) == 0 {\n\t\tdata, err := readFileHeader(f, compressed, fileEncoding)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"cannot read header of the file %q: %w\", f.Name(), err)\n\t\t}\n\t\tcontentType = http.DetectContentType(data)\n\t}\n\n\tlastModified := fileInfo.ModTime()\n\tff := &fsFile{\n\t\th:               h,\n\t\tf:               f,\n\t\tcontentType:     contentType,\n\t\tcontentLength:   contentLength,\n\t\tcompressed:      compressed,\n\t\tlastModified:    lastModified,\n\t\tlastModifiedStr: AppendHTTPDate(nil, lastModified),\n\n\t\tt: time.Now(),\n\t}\n\treturn ff, nil\n}\n\nfunc readFileHeader(f *os.File, compressed bool, fileEncoding string) ([]byte, error) {\n\tr := io.Reader(f)\n\tvar (\n\t\tbr *brotli.Reader\n\t\tzr *gzip.Reader\n\t)\n\tif compressed {\n\t\tvar err error\n\t\tif fileEncoding == \"br\" {\n\t\t\tif br, err = acquireBrotliReader(f); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tr = br\n\t\t} else if fileEncoding == \"gzip\" {\n\t\t\tif zr, err = acquireGzipReader(f); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tr = zr\n\t\t}\n\t}\n\n\tlr := &io.LimitedReader{\n\t\tR: r,\n\t\tN: 512,\n\t}\n\tdata, err := ioutil.ReadAll(lr)\n\tif _, err := f.Seek(0, 0); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif br != nil {\n\t\treleaseBrotliReader(br)\n\t}\n\n\tif zr != nil {\n\t\treleaseGzipReader(zr)\n\t}\n\n\treturn data, err\n}\n\nfunc stripLeadingSlashes(path []byte, stripSlashes int) []byte {\n\tfor stripSlashes > 0 && len(path) > 0 {\n\t\tif path[0] != '/' {\n\t\t\tpanic(\"BUG: path must start with slash\")\n\t\t}\n\t\tn := bytes.IndexByte(path[1:], '/')\n\t\tif n < 0 {\n\t\t\tpath = path[:0]\n\t\t\tbreak\n\t\t}\n\t\tpath = path[n+1:]\n\t\tstripSlashes--\n\t}\n\treturn path\n}\n\nfunc stripTrailingSlashes(path []byte) []byte {\n\tfor len(path) > 0 && path[len(path)-1] == '/' {\n\t\tpath = path[:len(path)-1]\n\t}\n\treturn path\n}\n\nfunc fileExtension(path string, compressed bool, compressedFileSuffix string) string {\n\tif compressed && strings.HasSuffix(path, compressedFileSuffix) {\n\t\tpath = path[:len(path)-len(compressedFileSuffix)]\n\t}\n\tn := strings.LastIndexByte(path, '.')\n\tif n < 0 {\n\t\treturn \"\"\n\t}\n\treturn path[n:]\n}\n\n// FileLastModified returns last modified time for the file.\nfunc FileLastModified(path string) (time.Time, error) {\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn zeroTime, err\n\t}\n\tfileInfo, err := f.Stat()\n\tf.Close()\n\tif err != nil {\n\t\treturn zeroTime, err\n\t}\n\treturn fsModTime(fileInfo.ModTime()), nil\n}\n\nfunc fsModTime(t time.Time) time.Time {\n\treturn t.In(time.UTC).Truncate(time.Second)\n}\n\nvar filesLockMap sync.Map\n\nfunc getFileLock(absPath string) *sync.Mutex {\n\tv, _ := filesLockMap.LoadOrStore(absPath, &sync.Mutex{})\n\tfilelock := v.(*sync.Mutex)\n\treturn filelock\n}\n", "package fasthttp\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"crypto/tls\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"mime/multipart\"\n\t\"net\"\n\t\"os\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n)\n\nvar errNoCertOrKeyProvided = errors.New(\"cert or key has not provided\")\n\nvar (\n\t// ErrAlreadyServing is returned when calling Serve on a Server\n\t// that is already serving connections.\n\tErrAlreadyServing = errors.New(\"Server is already serving connections\")\n)\n\n// ServeConn serves HTTP requests from the given connection\n// using the given handler.\n//\n// ServeConn returns nil if all requests from the c are successfully served.\n// It returns non-nil error otherwise.\n//\n// Connection c must immediately propagate all the data passed to Write()\n// to the client. Otherwise requests' processing may hang.\n//\n// ServeConn closes c before returning.\nfunc ServeConn(c net.Conn, handler RequestHandler) error {\n\tv := serverPool.Get()\n\tif v == nil {\n\t\tv = &Server{}\n\t}\n\ts := v.(*Server)\n\ts.Handler = handler\n\terr := s.ServeConn(c)\n\ts.Handler = nil\n\tserverPool.Put(v)\n\treturn err\n}\n\nvar serverPool sync.Pool\n\n// Serve serves incoming connections from the given listener\n// using the given handler.\n//\n// Serve blocks until the given listener returns permanent error.\nfunc Serve(ln net.Listener, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.Serve(ln)\n}\n\n// ServeTLS serves HTTPS requests from the given net.Listener\n// using the given handler.\n//\n// certFile and keyFile are paths to TLS certificate and key files.\nfunc ServeTLS(ln net.Listener, certFile, keyFile string, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ServeTLS(ln, certFile, keyFile)\n}\n\n// ServeTLSEmbed serves HTTPS requests from the given net.Listener\n// using the given handler.\n//\n// certData and keyData must contain valid TLS certificate and key data.\nfunc ServeTLSEmbed(ln net.Listener, certData, keyData []byte, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ServeTLSEmbed(ln, certData, keyData)\n}\n\n// ListenAndServe serves HTTP requests from the given TCP addr\n// using the given handler.\nfunc ListenAndServe(addr string, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ListenAndServe(addr)\n}\n\n// ListenAndServeUNIX serves HTTP requests from the given UNIX addr\n// using the given handler.\n//\n// The function deletes existing file at addr before starting serving.\n//\n// The server sets the given file mode for the UNIX addr.\nfunc ListenAndServeUNIX(addr string, mode os.FileMode, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ListenAndServeUNIX(addr, mode)\n}\n\n// ListenAndServeTLS serves HTTPS requests from the given TCP addr\n// using the given handler.\n//\n// certFile and keyFile are paths to TLS certificate and key files.\nfunc ListenAndServeTLS(addr, certFile, keyFile string, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ListenAndServeTLS(addr, certFile, keyFile)\n}\n\n// ListenAndServeTLSEmbed serves HTTPS requests from the given TCP addr\n// using the given handler.\n//\n// certData and keyData must contain valid TLS certificate and key data.\nfunc ListenAndServeTLSEmbed(addr string, certData, keyData []byte, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ListenAndServeTLSEmbed(addr, certData, keyData)\n}\n\n// RequestHandler must process incoming requests.\n//\n// RequestHandler must call ctx.TimeoutError() before returning\n// if it keeps references to ctx and/or its' members after the return.\n// Consider wrapping RequestHandler into TimeoutHandler if response time\n// must be limited.\ntype RequestHandler func(ctx *RequestCtx)\n\n// ServeHandler must process tls.Config.NextProto negotiated requests.\ntype ServeHandler func(c net.Conn) error\n\n// Server implements HTTP server.\n//\n// Default Server settings should satisfy the majority of Server users.\n// Adjust Server settings only if you really understand the consequences.\n//\n// It is forbidden copying Server instances. Create new Server instances\n// instead.\n//\n// It is safe to call Server methods from concurrently running goroutines.\ntype Server struct {\n\tnoCopy noCopy //nolint:unused,structcheck\n\n\t// Handler for processing incoming requests.\n\t//\n\t// Take into account that no `panic` recovery is done by `fasthttp` (thus any `panic` will take down the entire server).\n\t// Instead the user should use `recover` to handle these situations.\n\tHandler RequestHandler\n\n\t// ErrorHandler for returning a response in case of an error while receiving or parsing the request.\n\t//\n\t// The following is a non-exhaustive list of errors that can be expected as argument:\n\t//   * io.EOF\n\t//   * io.ErrUnexpectedEOF\n\t//   * ErrGetOnly\n\t//   * ErrSmallBuffer\n\t//   * ErrBodyTooLarge\n\t//   * ErrBrokenChunks\n\tErrorHandler func(ctx *RequestCtx, err error)\n\n\t// HeaderReceived is called after receiving the header\n\t//\n\t// non zero RequestConfig field values will overwrite the default configs\n\tHeaderReceived func(header *RequestHeader) RequestConfig\n\n\t// ContinueHandler is called after receiving the Expect 100 Continue Header\n\t//\n\t// https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.2.3\n\t// https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.1.1\n\t// Using ContinueHandler a server can make decisioning on whether or not\n\t// to read a potentially large request body based on the headers\n\t//\n\t// The default is to automatically read request bodies of Expect 100 Continue requests\n\t// like they are normal requests\n\tContinueHandler func(header *RequestHeader) bool\n\n\t// Server name for sending in response headers.\n\t//\n\t// Default server name is used if left blank.\n\tName string\n\n\t// The maximum number of concurrent connections the server may serve.\n\t//\n\t// DefaultConcurrency is used if not set.\n\t//\n\t// Concurrency only works if you either call Serve once, or only ServeConn multiple times.\n\t// It works with ListenAndServe as well.\n\tConcurrency int\n\n\t// Per-connection buffer size for requests' reading.\n\t// This also limits the maximum header size.\n\t//\n\t// Increase this buffer if your clients send multi-KB RequestURIs\n\t// and/or multi-KB headers (for example, BIG cookies).\n\t//\n\t// Default buffer size is used if not set.\n\tReadBufferSize int\n\n\t// Per-connection buffer size for responses' writing.\n\t//\n\t// Default buffer size is used if not set.\n\tWriteBufferSize int\n\n\t// ReadTimeout is the amount of time allowed to read\n\t// the full request including body. The connection's read\n\t// deadline is reset when the connection opens, or for\n\t// keep-alive connections after the first byte has been read.\n\t//\n\t// By default request read timeout is unlimited.\n\tReadTimeout time.Duration\n\n\t// WriteTimeout is the maximum duration before timing out\n\t// writes of the response. It is reset after the request handler\n\t// has returned.\n\t//\n\t// By default response write timeout is unlimited.\n\tWriteTimeout time.Duration\n\n\t// IdleTimeout is the maximum amount of time to wait for the\n\t// next request when keep-alive is enabled. If IdleTimeout\n\t// is zero, the value of ReadTimeout is used.\n\tIdleTimeout time.Duration\n\n\t// Maximum number of concurrent client connections allowed per IP.\n\t//\n\t// By default unlimited number of concurrent connections\n\t// may be established to the server from a single IP address.\n\tMaxConnsPerIP int\n\n\t// Maximum number of requests served per connection.\n\t//\n\t// The server closes connection after the last request.\n\t// 'Connection: close' header is added to the last response.\n\t//\n\t// By default unlimited number of requests may be served per connection.\n\tMaxRequestsPerConn int\n\n\t// MaxKeepaliveDuration is a no-op and only left here for backwards compatibility.\n\t// Deprecated: Use IdleTimeout instead.\n\tMaxKeepaliveDuration time.Duration\n\n\t// MaxIdleWorkerDuration is the maximum idle time of a single worker in the underlying\n\t// worker pool of the Server. Idle workers beyond this time will be cleared.\n\tMaxIdleWorkerDuration time.Duration\n\n\t// Period between tcp keep-alive messages.\n\t//\n\t// TCP keep-alive period is determined by operation system by default.\n\tTCPKeepalivePeriod time.Duration\n\n\t// Maximum request body size.\n\t//\n\t// The server rejects requests with bodies exceeding this limit.\n\t//\n\t// Request body size is limited by DefaultMaxRequestBodySize by default.\n\tMaxRequestBodySize int\n\n\t// Whether to disable keep-alive connections.\n\t//\n\t// The server will close all the incoming connections after sending\n\t// the first response to client if this option is set to true.\n\t//\n\t// By default keep-alive connections are enabled.\n\tDisableKeepalive bool\n\n\t// Whether to enable tcp keep-alive connections.\n\t//\n\t// Whether the operating system should send tcp keep-alive messages on the tcp connection.\n\t//\n\t// By default tcp keep-alive connections are disabled.\n\tTCPKeepalive bool\n\n\t// Aggressively reduces memory usage at the cost of higher CPU usage\n\t// if set to true.\n\t//\n\t// Try enabling this option only if the server consumes too much memory\n\t// serving mostly idle keep-alive connections. This may reduce memory\n\t// usage by more than 50%.\n\t//\n\t// Aggressive memory usage reduction is disabled by default.\n\tReduceMemoryUsage bool\n\n\t// Rejects all non-GET requests if set to true.\n\t//\n\t// This option is useful as anti-DoS protection for servers\n\t// accepting only GET requests. The request size is limited\n\t// by ReadBufferSize if GetOnly is set.\n\t//\n\t// Server accepts all the requests by default.\n\tGetOnly bool\n\n\t// Will not pre parse Multipart Form data if set to true.\n\t//\n\t// This option is useful for servers that desire to treat\n\t// multipart form data as a binary blob, or choose when to parse the data.\n\t//\n\t// Server pre parses multipart form data by default.\n\tDisablePreParseMultipartForm bool\n\n\t// Logs all errors, including the most frequent\n\t// 'connection reset by peer', 'broken pipe' and 'connection timeout'\n\t// errors. Such errors are common in production serving real-world\n\t// clients.\n\t//\n\t// By default the most frequent errors such as\n\t// 'connection reset by peer', 'broken pipe' and 'connection timeout'\n\t// are suppressed in order to limit output log traffic.\n\tLogAllErrors bool\n\n\t// Will not log potentially sensitive content in error logs\n\t//\n\t// This option is useful for servers that handle sensitive data\n\t// in the request/response.\n\t//\n\t// Server logs all full errors by default.\n\tSecureErrorLogMessage bool\n\n\t// Header names are passed as-is without normalization\n\t// if this option is set.\n\t//\n\t// Disabled header names' normalization may be useful only for proxying\n\t// incoming requests to other servers expecting case-sensitive\n\t// header names. See https://github.com/valyala/fasthttp/issues/57\n\t// for details.\n\t//\n\t// By default request and response header names are normalized, i.e.\n\t// The first letter and the first letters following dashes\n\t// are uppercased, while all the other letters are lowercased.\n\t// Examples:\n\t//\n\t//     * HOST -> Host\n\t//     * content-type -> Content-Type\n\t//     * cONTENT-lenGTH -> Content-Length\n\tDisableHeaderNamesNormalizing bool\n\n\t// SleepWhenConcurrencyLimitsExceeded is a duration to be slept of if\n\t// the concurrency limit in exceeded (default [when is 0]: don't sleep\n\t// and accept new connections immediately).\n\tSleepWhenConcurrencyLimitsExceeded time.Duration\n\n\t// NoDefaultServerHeader, when set to true, causes the default Server header\n\t// to be excluded from the Response.\n\t//\n\t// The default Server header value is the value of the Name field or an\n\t// internal default value in its absence. With this option set to true,\n\t// the only time a Server header will be sent is if a non-zero length\n\t// value is explicitly provided during a request.\n\tNoDefaultServerHeader bool\n\n\t// NoDefaultDate, when set to true, causes the default Date\n\t// header to be excluded from the Response.\n\t//\n\t// The default Date header value is the current date value. When\n\t// set to true, the Date will not be present.\n\tNoDefaultDate bool\n\n\t// NoDefaultContentType, when set to true, causes the default Content-Type\n\t// header to be excluded from the Response.\n\t//\n\t// The default Content-Type header value is the internal default value. When\n\t// set to true, the Content-Type will not be present.\n\tNoDefaultContentType bool\n\n\t// KeepHijackedConns is an opt-in disable of connection\n\t// close by fasthttp after connections' HijackHandler returns.\n\t// This allows to save goroutines, e.g. when fasthttp used to upgrade\n\t// http connections to WS and connection goes to another handler,\n\t// which will close it when needed.\n\tKeepHijackedConns bool\n\n\t// CloseOnShutdown when true adds a `Connection: close` header when when the server is shutting down.\n\tCloseOnShutdown bool\n\n\t// StreamRequestBody enables request body streaming,\n\t// and calls the handler sooner when given body is\n\t// larger then the current limit.\n\tStreamRequestBody bool\n\n\t// ConnState specifies an optional callback function that is\n\t// called when a client connection changes state. See the\n\t// ConnState type and associated constants for details.\n\tConnState func(net.Conn, ConnState)\n\n\t// Logger, which is used by RequestCtx.Logger().\n\t//\n\t// By default standard logger from log package is used.\n\tLogger Logger\n\n\t// TLSConfig optionally provides a TLS configuration for use\n\t// by ServeTLS, ServeTLSEmbed, ListenAndServeTLS, ListenAndServeTLSEmbed,\n\t// AppendCert, AppendCertEmbed and NextProto.\n\t//\n\t// Note that this value is cloned by ServeTLS, ServeTLSEmbed, ListenAndServeTLS\n\t// and ListenAndServeTLSEmbed, so it's not possible to modify the configuration\n\t// with methods like tls.Config.SetSessionTicketKeys.\n\t// To use SetSessionTicketKeys, use Server.Serve with a TLS Listener\n\t// instead.\n\tTLSConfig *tls.Config\n\n\tnextProtos map[string]ServeHandler\n\n\tconcurrency      uint32\n\tconcurrencyCh    chan struct{}\n\tperIPConnCounter perIPConnCounter\n\tserverName       atomic.Value\n\n\tctxPool        sync.Pool\n\treaderPool     sync.Pool\n\twriterPool     sync.Pool\n\thijackConnPool sync.Pool\n\n\t// We need to know our listeners and idle connections so we can close them in Shutdown().\n\tln []net.Listener\n\n\tidleConns   map[net.Conn]struct{}\n\tidleConnsMu sync.Mutex\n\n\tmu   sync.Mutex\n\topen int32\n\tstop int32\n\tdone chan struct{}\n}\n\n// TimeoutHandler creates RequestHandler, which returns StatusRequestTimeout\n// error with the given msg to the client if h didn't return during\n// the given duration.\n//\n// The returned handler may return StatusTooManyRequests error with the given\n// msg to the client if there are more than Server.Concurrency concurrent\n// handlers h are running at the moment.\nfunc TimeoutHandler(h RequestHandler, timeout time.Duration, msg string) RequestHandler {\n\treturn TimeoutWithCodeHandler(h, timeout, msg, StatusRequestTimeout)\n}\n\n// TimeoutWithCodeHandler creates RequestHandler, which returns an error with\n// the given msg and status code to the client  if h didn't return during\n// the given duration.\n//\n// The returned handler may return StatusTooManyRequests error with the given\n// msg to the client if there are more than Server.Concurrency concurrent\n// handlers h are running at the moment.\nfunc TimeoutWithCodeHandler(h RequestHandler, timeout time.Duration, msg string, statusCode int) RequestHandler {\n\tif timeout <= 0 {\n\t\treturn h\n\t}\n\n\treturn func(ctx *RequestCtx) {\n\t\tconcurrencyCh := ctx.s.concurrencyCh\n\t\tselect {\n\t\tcase concurrencyCh <- struct{}{}:\n\t\tdefault:\n\t\t\tctx.Error(msg, StatusTooManyRequests)\n\t\t\treturn\n\t\t}\n\n\t\tch := ctx.timeoutCh\n\t\tif ch == nil {\n\t\t\tch = make(chan struct{}, 1)\n\t\t\tctx.timeoutCh = ch\n\t\t}\n\t\tgo func() {\n\t\t\th(ctx)\n\t\t\tch <- struct{}{}\n\t\t\t<-concurrencyCh\n\t\t}()\n\t\tctx.timeoutTimer = initTimer(ctx.timeoutTimer, timeout)\n\t\tselect {\n\t\tcase <-ch:\n\t\tcase <-ctx.timeoutTimer.C:\n\t\t\tctx.TimeoutErrorWithCode(msg, statusCode)\n\t\t}\n\t\tstopTimer(ctx.timeoutTimer)\n\t}\n}\n\n//RequestConfig configure the per request deadline and body limits\ntype RequestConfig struct {\n\t// ReadTimeout is the maximum duration for reading the entire\n\t// request body.\n\t// a zero value means that default values will be honored\n\tReadTimeout time.Duration\n\t// WriteTimeout is the maximum duration before timing out\n\t// writes of the response.\n\t// a zero value means that default values will be honored\n\tWriteTimeout time.Duration\n\t// Maximum request body size.\n\t// a zero value means that default values will be honored\n\tMaxRequestBodySize int\n}\n\n// CompressHandler returns RequestHandler that transparently compresses\n// response body generated by h if the request contains 'gzip' or 'deflate'\n// 'Accept-Encoding' header.\nfunc CompressHandler(h RequestHandler) RequestHandler {\n\treturn CompressHandlerLevel(h, CompressDefaultCompression)\n}\n\n// CompressHandlerLevel returns RequestHandler that transparently compresses\n// response body generated by h if the request contains a 'gzip' or 'deflate'\n// 'Accept-Encoding' header.\n//\n// Level is the desired compression level:\n//\n//     * CompressNoCompression\n//     * CompressBestSpeed\n//     * CompressBestCompression\n//     * CompressDefaultCompression\n//     * CompressHuffmanOnly\nfunc CompressHandlerLevel(h RequestHandler, level int) RequestHandler {\n\treturn func(ctx *RequestCtx) {\n\t\th(ctx)\n\t\tif ctx.Request.Header.HasAcceptEncodingBytes(strGzip) {\n\t\t\tctx.Response.gzipBody(level) //nolint:errcheck\n\t\t} else if ctx.Request.Header.HasAcceptEncodingBytes(strDeflate) {\n\t\t\tctx.Response.deflateBody(level) //nolint:errcheck\n\t\t}\n\t}\n}\n\n// CompressHandlerBrotliLevel returns RequestHandler that transparently compresses\n// response body generated by h if the request contains a 'br', 'gzip' or 'deflate'\n// 'Accept-Encoding' header.\n//\n// brotliLevel is the desired compression level for brotli.\n//\n//     * CompressBrotliNoCompression\n//     * CompressBrotliBestSpeed\n//     * CompressBrotliBestCompression\n//     * CompressBrotliDefaultCompression\n//\n// otherLevel is the desired compression level for gzip and deflate.\n//\n//     * CompressNoCompression\n//     * CompressBestSpeed\n//     * CompressBestCompression\n//     * CompressDefaultCompression\n//     * CompressHuffmanOnly\nfunc CompressHandlerBrotliLevel(h RequestHandler, brotliLevel, otherLevel int) RequestHandler {\n\treturn func(ctx *RequestCtx) {\n\t\th(ctx)\n\t\tif ctx.Request.Header.HasAcceptEncodingBytes(strBr) {\n\t\t\tctx.Response.brotliBody(brotliLevel) //nolint:errcheck\n\t\t} else if ctx.Request.Header.HasAcceptEncodingBytes(strGzip) {\n\t\t\tctx.Response.gzipBody(otherLevel) //nolint:errcheck\n\t\t} else if ctx.Request.Header.HasAcceptEncodingBytes(strDeflate) {\n\t\t\tctx.Response.deflateBody(otherLevel) //nolint:errcheck\n\t\t}\n\t}\n}\n\n// RequestCtx contains incoming request and manages outgoing response.\n//\n// It is forbidden copying RequestCtx instances.\n//\n// RequestHandler should avoid holding references to incoming RequestCtx and/or\n// its' members after the return.\n// If holding RequestCtx references after the return is unavoidable\n// (for instance, ctx is passed to a separate goroutine and ctx lifetime cannot\n// be controlled), then the RequestHandler MUST call ctx.TimeoutError()\n// before return.\n//\n// It is unsafe modifying/reading RequestCtx instance from concurrently\n// running goroutines. The only exception is TimeoutError*, which may be called\n// while other goroutines accessing RequestCtx.\ntype RequestCtx struct {\n\tnoCopy noCopy //nolint:unused,structcheck\n\n\t// Incoming request.\n\t//\n\t// Copying Request by value is forbidden. Use pointer to Request instead.\n\tRequest Request\n\n\t// Outgoing response.\n\t//\n\t// Copying Response by value is forbidden. Use pointer to Response instead.\n\tResponse Response\n\n\tuserValues userData\n\n\tconnID         uint64\n\tconnRequestNum uint64\n\tconnTime       time.Time\n\tremoteAddr     net.Addr\n\n\ttime time.Time\n\n\tlogger ctxLogger\n\ts      *Server\n\tc      net.Conn\n\tfbr    firstByteReader\n\n\ttimeoutResponse *Response\n\ttimeoutCh       chan struct{}\n\ttimeoutTimer    *time.Timer\n\n\thijackHandler    HijackHandler\n\thijackNoResponse bool\n}\n\n// HijackHandler must process the hijacked connection c.\n//\n// If KeepHijackedConns is disabled, which is by default,\n// the connection c is automatically closed after returning from HijackHandler.\n//\n// The connection c must not be used after returning from the handler, if KeepHijackedConns is disabled.\n//\n// When KeepHijackedConns enabled, fasthttp will not Close() the connection,\n// you must do it when you need it. You must not use c in any way after calling Close().\ntype HijackHandler func(c net.Conn)\n\n// Hijack registers the given handler for connection hijacking.\n//\n// The handler is called after returning from RequestHandler\n// and sending http response. The current connection is passed\n// to the handler. The connection is automatically closed after\n// returning from the handler.\n//\n// The server skips calling the handler in the following cases:\n//\n//     * 'Connection: close' header exists in either request or response.\n//     * Unexpected error during response writing to the connection.\n//\n// The server stops processing requests from hijacked connections.\n//\n// Server limits such as Concurrency, ReadTimeout, WriteTimeout, etc.\n// aren't applied to hijacked connections.\n//\n// The handler must not retain references to ctx members.\n//\n// Arbitrary 'Connection: Upgrade' protocols may be implemented\n// with HijackHandler. For instance,\n//\n//     * WebSocket ( https://en.wikipedia.org/wiki/WebSocket )\n//     * HTTP/2.0 ( https://en.wikipedia.org/wiki/HTTP/2 )\n//\nfunc (ctx *RequestCtx) Hijack(handler HijackHandler) {\n\tctx.hijackHandler = handler\n}\n\n// HijackSetNoResponse changes the behavior of hijacking a request.\n// If HijackSetNoResponse is called with false fasthttp will send a response\n// to the client before calling the HijackHandler (default). If HijackSetNoResponse\n// is called with true no response is send back before calling the\n// HijackHandler supplied in the Hijack function.\nfunc (ctx *RequestCtx) HijackSetNoResponse(noResponse bool) {\n\tctx.hijackNoResponse = noResponse\n}\n\n// Hijacked returns true after Hijack is called.\nfunc (ctx *RequestCtx) Hijacked() bool {\n\treturn ctx.hijackHandler != nil\n}\n\n// SetUserValue stores the given value (arbitrary object)\n// under the given key in ctx.\n//\n// The value stored in ctx may be obtained by UserValue*.\n//\n// This functionality may be useful for passing arbitrary values between\n// functions involved in request processing.\n//\n// All the values are removed from ctx after returning from the top\n// RequestHandler. Additionally, Close method is called on each value\n// implementing io.Closer before removing the value from ctx.\nfunc (ctx *RequestCtx) SetUserValue(key string, value interface{}) {\n\tctx.userValues.Set(key, value)\n}\n\n// SetUserValueBytes stores the given value (arbitrary object)\n// under the given key in ctx.\n//\n// The value stored in ctx may be obtained by UserValue*.\n//\n// This functionality may be useful for passing arbitrary values between\n// functions involved in request processing.\n//\n// All the values stored in ctx are deleted after returning from RequestHandler.\nfunc (ctx *RequestCtx) SetUserValueBytes(key []byte, value interface{}) {\n\tctx.userValues.SetBytes(key, value)\n}\n\n// UserValue returns the value stored via SetUserValue* under the given key.\nfunc (ctx *RequestCtx) UserValue(key string) interface{} {\n\treturn ctx.userValues.Get(key)\n}\n\n// UserValueBytes returns the value stored via SetUserValue*\n// under the given key.\nfunc (ctx *RequestCtx) UserValueBytes(key []byte) interface{} {\n\treturn ctx.userValues.GetBytes(key)\n}\n\n// VisitUserValues calls visitor for each existing userValue.\n//\n// visitor must not retain references to key and value after returning.\n// Make key and/or value copies if you need storing them after returning.\nfunc (ctx *RequestCtx) VisitUserValues(visitor func([]byte, interface{})) {\n\tfor i, n := 0, len(ctx.userValues); i < n; i++ {\n\t\tkv := &ctx.userValues[i]\n\t\tvisitor(kv.key, kv.value)\n\t}\n}\n\n// ResetUserValues allows to reset user values from Request Context\nfunc (ctx *RequestCtx) ResetUserValues() {\n\tctx.userValues.Reset()\n}\n\n// RemoveUserValue removes the given key and the value under it in ctx.\nfunc (ctx *RequestCtx) RemoveUserValue(key string) {\n\tctx.userValues.Remove(key)\n}\n\n// RemoveUserValueBytes removes the given key and the value under it in ctx.\nfunc (ctx *RequestCtx) RemoveUserValueBytes(key []byte) {\n\tctx.userValues.RemoveBytes(key)\n}\n\ntype connTLSer interface {\n\tHandshake() error\n\tConnectionState() tls.ConnectionState\n}\n\n// IsTLS returns true if the underlying connection is tls.Conn.\n//\n// tls.Conn is an encrypted connection (aka SSL, HTTPS).\nfunc (ctx *RequestCtx) IsTLS() bool {\n\t// cast to (connTLSer) instead of (*tls.Conn), since it catches\n\t// cases with overridden tls.Conn such as:\n\t//\n\t// type customConn struct {\n\t//     *tls.Conn\n\t//\n\t//     // other custom fields here\n\t// }\n\n\t// perIPConn wraps the net.Conn in the Conn field\n\tif pic, ok := ctx.c.(*perIPConn); ok {\n\t\t_, ok := pic.Conn.(connTLSer)\n\t\treturn ok\n\t}\n\n\t_, ok := ctx.c.(connTLSer)\n\treturn ok\n}\n\n// TLSConnectionState returns TLS connection state.\n//\n// The function returns nil if the underlying connection isn't tls.Conn.\n//\n// The returned state may be used for verifying TLS version, client certificates,\n// etc.\nfunc (ctx *RequestCtx) TLSConnectionState() *tls.ConnectionState {\n\ttlsConn, ok := ctx.c.(connTLSer)\n\tif !ok {\n\t\treturn nil\n\t}\n\tstate := tlsConn.ConnectionState()\n\treturn &state\n}\n\n// Conn returns a reference to the underlying net.Conn.\n//\n// WARNING: Only use this method if you know what you are doing!\n//\n// Reading from or writing to the returned connection will end badly!\nfunc (ctx *RequestCtx) Conn() net.Conn {\n\treturn ctx.c\n}\n\nfunc (ctx *RequestCtx) reset() {\n\tctx.userValues.Reset()\n\tctx.Request.Reset()\n\tctx.Response.Reset()\n\tctx.fbr.reset()\n\n\tctx.connID = 0\n\tctx.connRequestNum = 0\n\tctx.connTime = zeroTime\n\tctx.remoteAddr = nil\n\tctx.time = zeroTime\n\tctx.s = nil\n\tctx.c = nil\n\n\tif ctx.timeoutResponse != nil {\n\t\tctx.timeoutResponse.Reset()\n\t}\n\n\tif ctx.timeoutTimer != nil {\n\t\tstopTimer(ctx.timeoutTimer)\n\t}\n\n\tctx.hijackHandler = nil\n\tctx.hijackNoResponse = false\n}\n\ntype firstByteReader struct {\n\tc        net.Conn\n\tch       byte\n\tbyteRead bool\n}\n\nfunc (r *firstByteReader) reset() {\n\tr.c = nil\n\tr.ch = 0\n\tr.byteRead = false\n}\n\nfunc (r *firstByteReader) Read(b []byte) (int, error) {\n\tif len(b) == 0 {\n\t\treturn 0, nil\n\t}\n\tnn := 0\n\tif !r.byteRead {\n\t\tb[0] = r.ch\n\t\tb = b[1:]\n\t\tr.byteRead = true\n\t\tnn = 1\n\t}\n\tn, err := r.c.Read(b)\n\treturn n + nn, err\n}\n\n// Logger is used for logging formatted messages.\ntype Logger interface {\n\t// Printf must have the same semantics as log.Printf.\n\tPrintf(format string, args ...interface{})\n}\n\nvar ctxLoggerLock sync.Mutex\n\ntype ctxLogger struct {\n\tctx    *RequestCtx\n\tlogger Logger\n}\n\nfunc (cl *ctxLogger) Printf(format string, args ...interface{}) {\n\tmsg := fmt.Sprintf(format, args...)\n\tctxLoggerLock.Lock()\n\tcl.logger.Printf(\"%.3f %s - %s\", time.Since(cl.ctx.ConnTime()).Seconds(), cl.ctx.String(), msg)\n\tctxLoggerLock.Unlock()\n}\n\nvar zeroTCPAddr = &net.TCPAddr{\n\tIP: net.IPv4zero,\n}\n\n// String returns unique string representation of the ctx.\n//\n// The returned value may be useful for logging.\nfunc (ctx *RequestCtx) String() string {\n\treturn fmt.Sprintf(\"#%016X - %s<->%s - %s %s\", ctx.ID(), ctx.LocalAddr(), ctx.RemoteAddr(), ctx.Request.Header.Method(), ctx.URI().FullURI())\n}\n\n// ID returns unique ID of the request.\nfunc (ctx *RequestCtx) ID() uint64 {\n\treturn (ctx.connID << 32) | ctx.connRequestNum\n}\n\n// ConnID returns unique connection ID.\n//\n// This ID may be used to match distinct requests to the same incoming\n// connection.\nfunc (ctx *RequestCtx) ConnID() uint64 {\n\treturn ctx.connID\n}\n\n// Time returns RequestHandler call time.\nfunc (ctx *RequestCtx) Time() time.Time {\n\treturn ctx.time\n}\n\n// ConnTime returns the time the server started serving the connection\n// the current request came from.\nfunc (ctx *RequestCtx) ConnTime() time.Time {\n\treturn ctx.connTime\n}\n\n// ConnRequestNum returns request sequence number\n// for the current connection.\n//\n// Sequence starts with 1.\nfunc (ctx *RequestCtx) ConnRequestNum() uint64 {\n\treturn ctx.connRequestNum\n}\n\n// SetConnectionClose sets 'Connection: close' response header and closes\n// connection after the RequestHandler returns.\nfunc (ctx *RequestCtx) SetConnectionClose() {\n\tctx.Response.SetConnectionClose()\n}\n\n// SetStatusCode sets response status code.\nfunc (ctx *RequestCtx) SetStatusCode(statusCode int) {\n\tctx.Response.SetStatusCode(statusCode)\n}\n\n// SetContentType sets response Content-Type.\nfunc (ctx *RequestCtx) SetContentType(contentType string) {\n\tctx.Response.Header.SetContentType(contentType)\n}\n\n// SetContentTypeBytes sets response Content-Type.\n//\n// It is safe modifying contentType buffer after function return.\nfunc (ctx *RequestCtx) SetContentTypeBytes(contentType []byte) {\n\tctx.Response.Header.SetContentTypeBytes(contentType)\n}\n\n// RequestURI returns RequestURI.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) RequestURI() []byte {\n\treturn ctx.Request.Header.RequestURI()\n}\n\n// URI returns requested uri.\n//\n// This uri is valid until your request handler returns.\nfunc (ctx *RequestCtx) URI() *URI {\n\treturn ctx.Request.URI()\n}\n\n// Referer returns request referer.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) Referer() []byte {\n\treturn ctx.Request.Header.Referer()\n}\n\n// UserAgent returns User-Agent header value from the request.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) UserAgent() []byte {\n\treturn ctx.Request.Header.UserAgent()\n}\n\n// Path returns requested path.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) Path() []byte {\n\treturn ctx.URI().Path()\n}\n\n// Host returns requested host.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) Host() []byte {\n\treturn ctx.URI().Host()\n}\n\n// QueryArgs returns query arguments from RequestURI.\n//\n// It doesn't return POST'ed arguments - use PostArgs() for this.\n//\n// See also PostArgs, FormValue and FormFile.\n//\n// These args are valid until your request handler returns.\nfunc (ctx *RequestCtx) QueryArgs() *Args {\n\treturn ctx.URI().QueryArgs()\n}\n\n// PostArgs returns POST arguments.\n//\n// It doesn't return query arguments from RequestURI - use QueryArgs for this.\n//\n// See also QueryArgs, FormValue and FormFile.\n//\n// These args are valid until your request handler returns.\nfunc (ctx *RequestCtx) PostArgs() *Args {\n\treturn ctx.Request.PostArgs()\n}\n\n// MultipartForm returns requests's multipart form.\n//\n// Returns ErrNoMultipartForm if request's content-type\n// isn't 'multipart/form-data'.\n//\n// All uploaded temporary files are automatically deleted after\n// returning from RequestHandler. Either move or copy uploaded files\n// into new place if you want retaining them.\n//\n// Use SaveMultipartFile function for permanently saving uploaded file.\n//\n// The returned form is valid until your request handler returns.\n//\n// See also FormFile and FormValue.\nfunc (ctx *RequestCtx) MultipartForm() (*multipart.Form, error) {\n\treturn ctx.Request.MultipartForm()\n}\n\n// FormFile returns uploaded file associated with the given multipart form key.\n//\n// The file is automatically deleted after returning from RequestHandler,\n// so either move or copy uploaded file into new place if you want retaining it.\n//\n// Use SaveMultipartFile function for permanently saving uploaded file.\n//\n// The returned file header is valid until your request handler returns.\nfunc (ctx *RequestCtx) FormFile(key string) (*multipart.FileHeader, error) {\n\tmf, err := ctx.MultipartForm()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif mf.File == nil {\n\t\treturn nil, err\n\t}\n\tfhh := mf.File[key]\n\tif fhh == nil {\n\t\treturn nil, ErrMissingFile\n\t}\n\treturn fhh[0], nil\n}\n\n// ErrMissingFile may be returned from FormFile when the is no uploaded file\n// associated with the given multipart form key.\nvar ErrMissingFile = errors.New(\"there is no uploaded file associated with the given key\")\n\n// SaveMultipartFile saves multipart file fh under the given filename path.\nfunc SaveMultipartFile(fh *multipart.FileHeader, path string) (err error) {\n\tvar (\n\t\tf  multipart.File\n\t\tff *os.File\n\t)\n\tf, err = fh.Open()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tvar ok bool\n\tif ff, ok = f.(*os.File); ok {\n\t\t// Windows can't rename files that are opened.\n\t\tif err = f.Close(); err != nil {\n\t\t\treturn\n\t\t}\n\n\t\t// If renaming fails we try the normal copying method.\n\t\t// Renaming could fail if the files are on different devices.\n\t\tif os.Rename(ff.Name(), path) == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\t// Reopen f for the code below.\n\t\tif f, err = fh.Open(); err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\n\tdefer func() {\n\t\te := f.Close()\n\t\tif err == nil {\n\t\t\terr = e\n\t\t}\n\t}()\n\n\tif ff, err = os.Create(path); err != nil {\n\t\treturn\n\t}\n\tdefer func() {\n\t\te := ff.Close()\n\t\tif err == nil {\n\t\t\terr = e\n\t\t}\n\t}()\n\t_, err = copyZeroAlloc(ff, f)\n\treturn\n}\n\n// FormValue returns form value associated with the given key.\n//\n// The value is searched in the following places:\n//\n//   * Query string.\n//   * POST or PUT body.\n//\n// There are more fine-grained methods for obtaining form values:\n//\n//   * QueryArgs for obtaining values from query string.\n//   * PostArgs for obtaining values from POST or PUT body.\n//   * MultipartForm for obtaining values from multipart form.\n//   * FormFile for obtaining uploaded files.\n//\n// The returned value is valid until your request handler returns.\nfunc (ctx *RequestCtx) FormValue(key string) []byte {\n\tv := ctx.QueryArgs().Peek(key)\n\tif len(v) > 0 {\n\t\treturn v\n\t}\n\tv = ctx.PostArgs().Peek(key)\n\tif len(v) > 0 {\n\t\treturn v\n\t}\n\tmf, err := ctx.MultipartForm()\n\tif err == nil && mf.Value != nil {\n\t\tvv := mf.Value[key]\n\t\tif len(vv) > 0 {\n\t\t\treturn []byte(vv[0])\n\t\t}\n\t}\n\treturn nil\n}\n\n// IsGet returns true if request method is GET.\nfunc (ctx *RequestCtx) IsGet() bool {\n\treturn ctx.Request.Header.IsGet()\n}\n\n// IsPost returns true if request method is POST.\nfunc (ctx *RequestCtx) IsPost() bool {\n\treturn ctx.Request.Header.IsPost()\n}\n\n// IsPut returns true if request method is PUT.\nfunc (ctx *RequestCtx) IsPut() bool {\n\treturn ctx.Request.Header.IsPut()\n}\n\n// IsDelete returns true if request method is DELETE.\nfunc (ctx *RequestCtx) IsDelete() bool {\n\treturn ctx.Request.Header.IsDelete()\n}\n\n// IsConnect returns true if request method is CONNECT.\nfunc (ctx *RequestCtx) IsConnect() bool {\n\treturn ctx.Request.Header.IsConnect()\n}\n\n// IsOptions returns true if request method is OPTIONS.\nfunc (ctx *RequestCtx) IsOptions() bool {\n\treturn ctx.Request.Header.IsOptions()\n}\n\n// IsTrace returns true if request method is TRACE.\nfunc (ctx *RequestCtx) IsTrace() bool {\n\treturn ctx.Request.Header.IsTrace()\n}\n\n// IsPatch returns true if request method is PATCH.\nfunc (ctx *RequestCtx) IsPatch() bool {\n\treturn ctx.Request.Header.IsPatch()\n}\n\n// Method return request method.\n//\n// Returned value is valid until your request handler returns.\nfunc (ctx *RequestCtx) Method() []byte {\n\treturn ctx.Request.Header.Method()\n}\n\n// IsHead returns true if request method is HEAD.\nfunc (ctx *RequestCtx) IsHead() bool {\n\treturn ctx.Request.Header.IsHead()\n}\n\n// RemoteAddr returns client address for the given request.\n//\n// Always returns non-nil result.\nfunc (ctx *RequestCtx) RemoteAddr() net.Addr {\n\tif ctx.remoteAddr != nil {\n\t\treturn ctx.remoteAddr\n\t}\n\tif ctx.c == nil {\n\t\treturn zeroTCPAddr\n\t}\n\taddr := ctx.c.RemoteAddr()\n\tif addr == nil {\n\t\treturn zeroTCPAddr\n\t}\n\treturn addr\n}\n\n// SetRemoteAddr sets remote address to the given value.\n//\n// Set nil value to resore default behaviour for using\n// connection remote address.\nfunc (ctx *RequestCtx) SetRemoteAddr(remoteAddr net.Addr) {\n\tctx.remoteAddr = remoteAddr\n}\n\n// LocalAddr returns server address for the given request.\n//\n// Always returns non-nil result.\nfunc (ctx *RequestCtx) LocalAddr() net.Addr {\n\tif ctx.c == nil {\n\t\treturn zeroTCPAddr\n\t}\n\taddr := ctx.c.LocalAddr()\n\tif addr == nil {\n\t\treturn zeroTCPAddr\n\t}\n\treturn addr\n}\n\n// RemoteIP returns the client ip the request came from.\n//\n// Always returns non-nil result.\nfunc (ctx *RequestCtx) RemoteIP() net.IP {\n\treturn addrToIP(ctx.RemoteAddr())\n}\n\n// LocalIP returns the server ip the request came to.\n//\n// Always returns non-nil result.\nfunc (ctx *RequestCtx) LocalIP() net.IP {\n\treturn addrToIP(ctx.LocalAddr())\n}\n\nfunc addrToIP(addr net.Addr) net.IP {\n\tx, ok := addr.(*net.TCPAddr)\n\tif !ok {\n\t\treturn net.IPv4zero\n\t}\n\treturn x.IP\n}\n\n// Error sets response status code to the given value and sets response body\n// to the given message.\n//\n// Warning: this will reset the response headers and body already set!\nfunc (ctx *RequestCtx) Error(msg string, statusCode int) {\n\tctx.Response.Reset()\n\tctx.SetStatusCode(statusCode)\n\tctx.SetContentTypeBytes(defaultContentType)\n\tctx.SetBodyString(msg)\n}\n\n// Success sets response Content-Type and body to the given values.\nfunc (ctx *RequestCtx) Success(contentType string, body []byte) {\n\tctx.SetContentType(contentType)\n\tctx.SetBody(body)\n}\n\n// SuccessString sets response Content-Type and body to the given values.\nfunc (ctx *RequestCtx) SuccessString(contentType, body string) {\n\tctx.SetContentType(contentType)\n\tctx.SetBodyString(body)\n}\n\n// Redirect sets 'Location: uri' response header and sets the given statusCode.\n//\n// statusCode must have one of the following values:\n//\n//    * StatusMovedPermanently (301)\n//    * StatusFound (302)\n//    * StatusSeeOther (303)\n//    * StatusTemporaryRedirect (307)\n//    * StatusPermanentRedirect (308)\n//\n// All other statusCode values are replaced by StatusFound (302).\n//\n// The redirect uri may be either absolute or relative to the current\n// request uri. Fasthttp will always send an absolute uri back to the client.\n// To send a relative uri you can use the following code:\n//\n//   strLocation = []byte(\"Location\") // Put this with your top level var () declarations.\n//   ctx.Response.Header.SetCanonical(strLocation, \"/relative?uri\")\n//   ctx.Response.SetStatusCode(fasthttp.StatusMovedPermanently)\n//\nfunc (ctx *RequestCtx) Redirect(uri string, statusCode int) {\n\tu := AcquireURI()\n\tctx.URI().CopyTo(u)\n\tu.Update(uri)\n\tctx.redirect(u.FullURI(), statusCode)\n\tReleaseURI(u)\n}\n\n// RedirectBytes sets 'Location: uri' response header and sets\n// the given statusCode.\n//\n// statusCode must have one of the following values:\n//\n//    * StatusMovedPermanently (301)\n//    * StatusFound (302)\n//    * StatusSeeOther (303)\n//    * StatusTemporaryRedirect (307)\n//    * StatusPermanentRedirect (308)\n//\n// All other statusCode values are replaced by StatusFound (302).\n//\n// The redirect uri may be either absolute or relative to the current\n// request uri. Fasthttp will always send an absolute uri back to the client.\n// To send a relative uri you can use the following code:\n//\n//   strLocation = []byte(\"Location\") // Put this with your top level var () declarations.\n//   ctx.Response.Header.SetCanonical(strLocation, \"/relative?uri\")\n//   ctx.Response.SetStatusCode(fasthttp.StatusMovedPermanently)\n//\nfunc (ctx *RequestCtx) RedirectBytes(uri []byte, statusCode int) {\n\ts := b2s(uri)\n\tctx.Redirect(s, statusCode)\n}\n\nfunc (ctx *RequestCtx) redirect(uri []byte, statusCode int) {\n\tctx.Response.Header.SetCanonical(strLocation, uri)\n\tstatusCode = getRedirectStatusCode(statusCode)\n\tctx.Response.SetStatusCode(statusCode)\n}\n\nfunc getRedirectStatusCode(statusCode int) int {\n\tif statusCode == StatusMovedPermanently || statusCode == StatusFound ||\n\t\tstatusCode == StatusSeeOther || statusCode == StatusTemporaryRedirect ||\n\t\tstatusCode == StatusPermanentRedirect {\n\t\treturn statusCode\n\t}\n\treturn StatusFound\n}\n\n// SetBody sets response body to the given value.\n//\n// It is safe re-using body argument after the function returns.\nfunc (ctx *RequestCtx) SetBody(body []byte) {\n\tctx.Response.SetBody(body)\n}\n\n// SetBodyString sets response body to the given value.\nfunc (ctx *RequestCtx) SetBodyString(body string) {\n\tctx.Response.SetBodyString(body)\n}\n\n// ResetBody resets response body contents.\nfunc (ctx *RequestCtx) ResetBody() {\n\tctx.Response.ResetBody()\n}\n\n// SendFile sends local file contents from the given path as response body.\n//\n// This is a shortcut to ServeFile(ctx, path).\n//\n// SendFile logs all the errors via ctx.Logger.\n//\n// See also ServeFile, FSHandler and FS.\nfunc (ctx *RequestCtx) SendFile(path string) {\n\tServeFile(ctx, path)\n}\n\n// SendFileBytes sends local file contents from the given path as response body.\n//\n// This is a shortcut to ServeFileBytes(ctx, path).\n//\n// SendFileBytes logs all the errors via ctx.Logger.\n//\n// See also ServeFileBytes, FSHandler and FS.\nfunc (ctx *RequestCtx) SendFileBytes(path []byte) {\n\tServeFileBytes(ctx, path)\n}\n\n// IfModifiedSince returns true if lastModified exceeds 'If-Modified-Since'\n// value from the request header.\n//\n// The function returns true also 'If-Modified-Since' request header is missing.\nfunc (ctx *RequestCtx) IfModifiedSince(lastModified time.Time) bool {\n\tifModStr := ctx.Request.Header.peek(strIfModifiedSince)\n\tif len(ifModStr) == 0 {\n\t\treturn true\n\t}\n\tifMod, err := ParseHTTPDate(ifModStr)\n\tif err != nil {\n\t\treturn true\n\t}\n\tlastModified = lastModified.Truncate(time.Second)\n\treturn ifMod.Before(lastModified)\n}\n\n// NotModified resets response and sets '304 Not Modified' response status code.\nfunc (ctx *RequestCtx) NotModified() {\n\tctx.Response.Reset()\n\tctx.SetStatusCode(StatusNotModified)\n}\n\n// NotFound resets response and sets '404 Not Found' response status code.\nfunc (ctx *RequestCtx) NotFound() {\n\tctx.Response.Reset()\n\tctx.SetStatusCode(StatusNotFound)\n\tctx.SetBodyString(\"404 Page not found\")\n}\n\n// Write writes p into response body.\nfunc (ctx *RequestCtx) Write(p []byte) (int, error) {\n\tctx.Response.AppendBody(p)\n\treturn len(p), nil\n}\n\n// WriteString appends s to response body.\nfunc (ctx *RequestCtx) WriteString(s string) (int, error) {\n\tctx.Response.AppendBodyString(s)\n\treturn len(s), nil\n}\n\n// PostBody returns POST request body.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) PostBody() []byte {\n\treturn ctx.Request.Body()\n}\n\n// SetBodyStream sets response body stream and, optionally body size.\n//\n// bodyStream.Close() is called after finishing reading all body data\n// if it implements io.Closer.\n//\n// If bodySize is >= 0, then bodySize bytes must be provided by bodyStream\n// before returning io.EOF.\n//\n// If bodySize < 0, then bodyStream is read until io.EOF.\n//\n// See also SetBodyStreamWriter.\nfunc (ctx *RequestCtx) SetBodyStream(bodyStream io.Reader, bodySize int) {\n\tctx.Response.SetBodyStream(bodyStream, bodySize)\n}\n\n// SetBodyStreamWriter registers the given stream writer for populating\n// response body.\n//\n// Access to RequestCtx and/or its' members is forbidden from sw.\n//\n// This function may be used in the following cases:\n//\n//     * if response body is too big (more than 10MB).\n//     * if response body is streamed from slow external sources.\n//     * if response body must be streamed to the client in chunks.\n//     (aka `http server push`).\nfunc (ctx *RequestCtx) SetBodyStreamWriter(sw StreamWriter) {\n\tctx.Response.SetBodyStreamWriter(sw)\n}\n\n// IsBodyStream returns true if response body is set via SetBodyStream*.\nfunc (ctx *RequestCtx) IsBodyStream() bool {\n\treturn ctx.Response.IsBodyStream()\n}\n\n// Logger returns logger, which may be used for logging arbitrary\n// request-specific messages inside RequestHandler.\n//\n// Each message logged via returned logger contains request-specific information\n// such as request id, request duration, local address, remote address,\n// request method and request url.\n//\n// It is safe re-using returned logger for logging multiple messages\n// for the current request.\n//\n// The returned logger is valid until your request handler returns.\nfunc (ctx *RequestCtx) Logger() Logger {\n\tif ctx.logger.ctx == nil {\n\t\tctx.logger.ctx = ctx\n\t}\n\tif ctx.logger.logger == nil {\n\t\tctx.logger.logger = ctx.s.logger()\n\t}\n\treturn &ctx.logger\n}\n\n// TimeoutError sets response status code to StatusRequestTimeout and sets\n// body to the given msg.\n//\n// All response modifications after TimeoutError call are ignored.\n//\n// TimeoutError MUST be called before returning from RequestHandler if there are\n// references to ctx and/or its members in other goroutines remain.\n//\n// Usage of this function is discouraged. Prefer eliminating ctx references\n// from pending goroutines instead of using this function.\nfunc (ctx *RequestCtx) TimeoutError(msg string) {\n\tctx.TimeoutErrorWithCode(msg, StatusRequestTimeout)\n}\n\n// TimeoutErrorWithCode sets response body to msg and response status\n// code to statusCode.\n//\n// All response modifications after TimeoutErrorWithCode call are ignored.\n//\n// TimeoutErrorWithCode MUST be called before returning from RequestHandler\n// if there are references to ctx and/or its members in other goroutines remain.\n//\n// Usage of this function is discouraged. Prefer eliminating ctx references\n// from pending goroutines instead of using this function.\nfunc (ctx *RequestCtx) TimeoutErrorWithCode(msg string, statusCode int) {\n\tvar resp Response\n\tresp.SetStatusCode(statusCode)\n\tresp.SetBodyString(msg)\n\tctx.TimeoutErrorWithResponse(&resp)\n}\n\n// TimeoutErrorWithResponse marks the ctx as timed out and sends the given\n// response to the client.\n//\n// All ctx modifications after TimeoutErrorWithResponse call are ignored.\n//\n// TimeoutErrorWithResponse MUST be called before returning from RequestHandler\n// if there are references to ctx and/or its members in other goroutines remain.\n//\n// Usage of this function is discouraged. Prefer eliminating ctx references\n// from pending goroutines instead of using this function.\nfunc (ctx *RequestCtx) TimeoutErrorWithResponse(resp *Response) {\n\trespCopy := &Response{}\n\tresp.CopyTo(respCopy)\n\tctx.timeoutResponse = respCopy\n}\n\n// NextProto adds nph to be processed when key is negotiated when TLS\n// connection is established.\n//\n// This function can only be called before the server is started.\nfunc (s *Server) NextProto(key string, nph ServeHandler) {\n\tif s.nextProtos == nil {\n\t\ts.nextProtos = make(map[string]ServeHandler)\n\t}\n\n\ts.configTLS()\n\ts.TLSConfig.NextProtos = append(s.TLSConfig.NextProtos, key)\n\ts.nextProtos[key] = nph\n}\n\nfunc (s *Server) getNextProto(c net.Conn) (proto string, err error) {\n\tif tlsConn, ok := c.(connTLSer); ok {\n\t\tif s.ReadTimeout > 0 {\n\t\t\tif err := c.SetReadDeadline(time.Now().Add(s.ReadTimeout)); err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetReadDeadline(%s): %s\", s.ReadTimeout, err))\n\t\t\t}\n\t\t}\n\n\t\tif s.WriteTimeout > 0 {\n\t\t\tif err := c.SetWriteDeadline(time.Now().Add(s.WriteTimeout)); err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetWriteDeadline(%s): %s\", s.WriteTimeout, err))\n\t\t\t}\n\t\t}\n\n\t\terr = tlsConn.Handshake()\n\t\tif err == nil {\n\t\t\tproto = tlsConn.ConnectionState().NegotiatedProtocol\n\t\t}\n\t}\n\treturn\n}\n\n// tcpKeepAliveListener sets TCP keep-alive timeouts on accepted\n// connections. It's used by ListenAndServe, ListenAndServeTLS and\n// ListenAndServeTLSEmbed so dead TCP connections (e.g. closing laptop mid-download)\n// eventually go away.\ntype tcpKeepaliveListener struct {\n\t*net.TCPListener\n\tkeepalive       bool\n\tkeepalivePeriod time.Duration\n}\n\nfunc (ln tcpKeepaliveListener) Accept() (net.Conn, error) {\n\ttc, err := ln.AcceptTCP()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := tc.SetKeepAlive(ln.keepalive); err != nil {\n\t\ttc.Close() //nolint:errcheck\n\t\treturn nil, err\n\t}\n\tif ln.keepalivePeriod > 0 {\n\t\tif err := tc.SetKeepAlivePeriod(ln.keepalivePeriod); err != nil {\n\t\t\ttc.Close() //nolint:errcheck\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn tc, nil\n}\n\n// ListenAndServe serves HTTP requests from the given TCP4 addr.\n//\n// Pass custom listener to Serve if you need listening on non-TCP4 media\n// such as IPv6.\n//\n// Accepted connections are configured to enable TCP keep-alives.\nfunc (s *Server) ListenAndServe(addr string) error {\n\tln, err := net.Listen(\"tcp4\", addr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif tcpln, ok := ln.(*net.TCPListener); ok {\n\t\treturn s.Serve(tcpKeepaliveListener{\n\t\t\tTCPListener:     tcpln,\n\t\t\tkeepalive:       s.TCPKeepalive,\n\t\t\tkeepalivePeriod: s.TCPKeepalivePeriod,\n\t\t})\n\t}\n\treturn s.Serve(ln)\n}\n\n// ListenAndServeUNIX serves HTTP requests from the given UNIX addr.\n//\n// The function deletes existing file at addr before starting serving.\n//\n// The server sets the given file mode for the UNIX addr.\nfunc (s *Server) ListenAndServeUNIX(addr string, mode os.FileMode) error {\n\tif err := os.Remove(addr); err != nil && !os.IsNotExist(err) {\n\t\treturn fmt.Errorf(\"unexpected error when trying to remove unix socket file %q: %w\", addr, err)\n\t}\n\tln, err := net.Listen(\"unix\", addr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err = os.Chmod(addr, mode); err != nil {\n\t\treturn fmt.Errorf(\"cannot chmod %#o for %q: %w\", mode, addr, err)\n\t}\n\treturn s.Serve(ln)\n}\n\n// ListenAndServeTLS serves HTTPS requests from the given TCP4 addr.\n//\n// certFile and keyFile are paths to TLS certificate and key files.\n//\n// Pass custom listener to Serve if you need listening on non-TCP4 media\n// such as IPv6.\n//\n// If the certFile or keyFile has not been provided to the server structure,\n// the function will use the previously added TLS configuration.\n//\n// Accepted connections are configured to enable TCP keep-alives.\nfunc (s *Server) ListenAndServeTLS(addr, certFile, keyFile string) error {\n\tln, err := net.Listen(\"tcp4\", addr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif tcpln, ok := ln.(*net.TCPListener); ok {\n\t\treturn s.ServeTLS(tcpKeepaliveListener{\n\t\t\tTCPListener:     tcpln,\n\t\t\tkeepalive:       s.TCPKeepalive,\n\t\t\tkeepalivePeriod: s.TCPKeepalivePeriod,\n\t\t}, certFile, keyFile)\n\t}\n\treturn s.ServeTLS(ln, certFile, keyFile)\n}\n\n// ListenAndServeTLSEmbed serves HTTPS requests from the given TCP4 addr.\n//\n// certData and keyData must contain valid TLS certificate and key data.\n//\n// Pass custom listener to Serve if you need listening on arbitrary media\n// such as IPv6.\n//\n// If the certFile or keyFile has not been provided the server structure,\n// the function will use previously added TLS configuration.\n//\n// Accepted connections are configured to enable TCP keep-alives.\nfunc (s *Server) ListenAndServeTLSEmbed(addr string, certData, keyData []byte) error {\n\tln, err := net.Listen(\"tcp4\", addr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif tcpln, ok := ln.(*net.TCPListener); ok {\n\t\treturn s.ServeTLSEmbed(tcpKeepaliveListener{\n\t\t\tTCPListener:     tcpln,\n\t\t\tkeepalive:       s.TCPKeepalive,\n\t\t\tkeepalivePeriod: s.TCPKeepalivePeriod,\n\t\t}, certData, keyData)\n\t}\n\treturn s.ServeTLSEmbed(ln, certData, keyData)\n}\n\n// ServeTLS serves HTTPS requests from the given listener.\n//\n// certFile and keyFile are paths to TLS certificate and key files.\n//\n// If the certFile or keyFile has not been provided the server structure,\n// the function will use previously added TLS configuration.\nfunc (s *Server) ServeTLS(ln net.Listener, certFile, keyFile string) error {\n\ts.mu.Lock()\n\terr := s.AppendCert(certFile, keyFile)\n\tif err != nil && err != errNoCertOrKeyProvided {\n\t\ts.mu.Unlock()\n\t\treturn err\n\t}\n\tif s.TLSConfig == nil {\n\t\ts.mu.Unlock()\n\t\treturn errNoCertOrKeyProvided\n\t}\n\n\t// BuildNameToCertificate has been deprecated since 1.14.\n\t// But since we also support older versions we'll keep this here.\n\ts.TLSConfig.BuildNameToCertificate() //nolint:staticcheck\n\n\ts.mu.Unlock()\n\n\treturn s.Serve(\n\t\ttls.NewListener(ln, s.TLSConfig.Clone()),\n\t)\n}\n\n// ServeTLSEmbed serves HTTPS requests from the given listener.\n//\n// certData and keyData must contain valid TLS certificate and key data.\n//\n// If the certFile or keyFile has not been provided the server structure,\n// the function will use previously added TLS configuration.\nfunc (s *Server) ServeTLSEmbed(ln net.Listener, certData, keyData []byte) error {\n\ts.mu.Lock()\n\n\terr := s.AppendCertEmbed(certData, keyData)\n\tif err != nil && err != errNoCertOrKeyProvided {\n\t\ts.mu.Unlock()\n\t\treturn err\n\t}\n\tif s.TLSConfig == nil {\n\t\ts.mu.Unlock()\n\t\treturn errNoCertOrKeyProvided\n\t}\n\n\t// BuildNameToCertificate has been deprecated since 1.14.\n\t// But since we also support older versions we'll keep this here.\n\ts.TLSConfig.BuildNameToCertificate() //nolint:staticcheck\n\n\ts.mu.Unlock()\n\n\treturn s.Serve(\n\t\ttls.NewListener(ln, s.TLSConfig.Clone()),\n\t)\n}\n\n// AppendCert appends certificate and keyfile to TLS Configuration.\n//\n// This function allows programmer to handle multiple domains\n// in one server structure. See examples/multidomain\nfunc (s *Server) AppendCert(certFile, keyFile string) error {\n\tif len(certFile) == 0 && len(keyFile) == 0 {\n\t\treturn errNoCertOrKeyProvided\n\t}\n\n\tcert, err := tls.LoadX509KeyPair(certFile, keyFile)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot load TLS key pair from certFile=%q and keyFile=%q: %w\", certFile, keyFile, err)\n\t}\n\n\ts.configTLS()\n\ts.TLSConfig.Certificates = append(s.TLSConfig.Certificates, cert)\n\n\treturn nil\n}\n\n// AppendCertEmbed does the same as AppendCert but using in-memory data.\nfunc (s *Server) AppendCertEmbed(certData, keyData []byte) error {\n\tif len(certData) == 0 && len(keyData) == 0 {\n\t\treturn errNoCertOrKeyProvided\n\t}\n\n\tcert, err := tls.X509KeyPair(certData, keyData)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot load TLS key pair from the provided certData(%d) and keyData(%d): %s\",\n\t\t\tlen(certData), len(keyData), err)\n\t}\n\n\ts.configTLS()\n\ts.TLSConfig.Certificates = append(s.TLSConfig.Certificates, cert)\n\n\treturn nil\n}\n\nfunc (s *Server) configTLS() {\n\tif s.TLSConfig == nil {\n\t\ts.TLSConfig = &tls.Config{}\n\t}\n}\n\n// DefaultConcurrency is the maximum number of concurrent connections\n// the Server may serve by default (i.e. if Server.Concurrency isn't set).\nconst DefaultConcurrency = 256 * 1024\n\n// Serve serves incoming connections from the given listener.\n//\n// Serve blocks until the given listener returns permanent error.\nfunc (s *Server) Serve(ln net.Listener) error {\n\tvar lastOverflowErrorTime time.Time\n\tvar lastPerIPErrorTime time.Time\n\tvar c net.Conn\n\tvar err error\n\n\tmaxWorkersCount := s.getConcurrency()\n\n\ts.mu.Lock()\n\t{\n\t\ts.ln = append(s.ln, ln)\n\t\tif s.done == nil {\n\t\t\ts.done = make(chan struct{})\n\t\t}\n\n\t\tif s.concurrencyCh == nil {\n\t\t\ts.concurrencyCh = make(chan struct{}, maxWorkersCount)\n\t\t}\n\t}\n\ts.mu.Unlock()\n\n\twp := &workerPool{\n\t\tWorkerFunc:            s.serveConn,\n\t\tMaxWorkersCount:       maxWorkersCount,\n\t\tLogAllErrors:          s.LogAllErrors,\n\t\tMaxIdleWorkerDuration: s.MaxIdleWorkerDuration,\n\t\tLogger:                s.logger(),\n\t\tconnState:             s.setState,\n\t}\n\twp.Start()\n\n\t// Count our waiting to accept a connection as an open connection.\n\t// This way we can't get into any weird state where just after accepting\n\t// a connection Shutdown is called which reads open as 0 because it isn't\n\t// incremented yet.\n\tatomic.AddInt32(&s.open, 1)\n\tdefer atomic.AddInt32(&s.open, -1)\n\n\tfor {\n\t\tif c, err = acceptConn(s, ln, &lastPerIPErrorTime); err != nil {\n\t\t\twp.Stop()\n\t\t\tif err == io.EOF {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\ts.setState(c, StateNew)\n\t\tatomic.AddInt32(&s.open, 1)\n\t\tif !wp.Serve(c) {\n\t\t\tatomic.AddInt32(&s.open, -1)\n\t\t\ts.writeFastError(c, StatusServiceUnavailable,\n\t\t\t\t\"The connection cannot be served because Server.Concurrency limit exceeded\")\n\t\t\tc.Close()\n\t\t\ts.setState(c, StateClosed)\n\t\t\tif time.Since(lastOverflowErrorTime) > time.Minute {\n\t\t\t\ts.logger().Printf(\"The incoming connection cannot be served, because %d concurrent connections are served. \"+\n\t\t\t\t\t\"Try increasing Server.Concurrency\", maxWorkersCount)\n\t\t\t\tlastOverflowErrorTime = time.Now()\n\t\t\t}\n\n\t\t\t// The current server reached concurrency limit,\n\t\t\t// so give other concurrently running servers a chance\n\t\t\t// accepting incoming connections on the same address.\n\t\t\t//\n\t\t\t// There is a hope other servers didn't reach their\n\t\t\t// concurrency limits yet :)\n\t\t\t//\n\t\t\t// See also: https://github.com/valyala/fasthttp/pull/485#discussion_r239994990\n\t\t\tif s.SleepWhenConcurrencyLimitsExceeded > 0 {\n\t\t\t\ttime.Sleep(s.SleepWhenConcurrencyLimitsExceeded)\n\t\t\t}\n\t\t}\n\t\tc = nil\n\t}\n}\n\n// Shutdown gracefully shuts down the server without interrupting any active connections.\n// Shutdown works by first closing all open listeners and then waiting indefinitely for all connections to return to idle and then shut down.\n//\n// When Shutdown is called, Serve, ListenAndServe, and ListenAndServeTLS immediately return nil.\n// Make sure the program doesn't exit and waits instead for Shutdown to return.\n//\n// Shutdown does not close keepalive connections so its recommended to set ReadTimeout and IdleTimeout to something else than 0.\nfunc (s *Server) Shutdown() error {\n\ts.mu.Lock()\n\tdefer s.mu.Unlock()\n\n\tatomic.StoreInt32(&s.stop, 1)\n\tdefer atomic.StoreInt32(&s.stop, 0)\n\n\tif s.ln == nil {\n\t\treturn nil\n\t}\n\n\tfor _, ln := range s.ln {\n\t\tif err := ln.Close(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif s.done != nil {\n\t\tclose(s.done)\n\t}\n\n\ts.closeIdleConns()\n\n\t// Closing the listener will make Serve() call Stop on the worker pool.\n\t// Setting .stop to 1 will make serveConn() break out of its loop.\n\t// Now we just have to wait until all workers are done.\n\tfor {\n\t\tif open := atomic.LoadInt32(&s.open); open == 0 {\n\t\t\tbreak\n\t\t}\n\t\t// This is not an optimal solution but using a sync.WaitGroup\n\t\t// here causes data races as it's hard to prevent Add() to be called\n\t\t// while Wait() is waiting.\n\t\ttime.Sleep(time.Millisecond * 100)\n\t}\n\n\ts.done = nil\n\ts.ln = nil\n\treturn nil\n}\n\nfunc acceptConn(s *Server, ln net.Listener, lastPerIPErrorTime *time.Time) (net.Conn, error) {\n\tfor {\n\t\tc, err := ln.Accept()\n\t\tif err != nil {\n\t\t\tif c != nil {\n\t\t\t\tpanic(\"BUG: net.Listener returned non-nil conn and non-nil error\")\n\t\t\t}\n\t\t\tif netErr, ok := err.(net.Error); ok && netErr.Temporary() {\n\t\t\t\ts.logger().Printf(\"Temporary error when accepting new connections: %s\", netErr)\n\t\t\t\ttime.Sleep(time.Second)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif err != io.EOF && !strings.Contains(err.Error(), \"use of closed network connection\") {\n\t\t\t\ts.logger().Printf(\"Permanent error when accepting new connections: %s\", err)\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn nil, io.EOF\n\t\t}\n\t\tif c == nil {\n\t\t\tpanic(\"BUG: net.Listener returned (nil, nil)\")\n\t\t}\n\t\tif s.MaxConnsPerIP > 0 {\n\t\t\tpic := wrapPerIPConn(s, c)\n\t\t\tif pic == nil {\n\t\t\t\tif time.Since(*lastPerIPErrorTime) > time.Minute {\n\t\t\t\t\ts.logger().Printf(\"The number of connections from %s exceeds MaxConnsPerIP=%d\",\n\t\t\t\t\t\tgetConnIP4(c), s.MaxConnsPerIP)\n\t\t\t\t\t*lastPerIPErrorTime = time.Now()\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tc = pic\n\t\t}\n\t\treturn c, nil\n\t}\n}\n\nfunc wrapPerIPConn(s *Server, c net.Conn) net.Conn {\n\tip := getUint32IP(c)\n\tif ip == 0 {\n\t\treturn c\n\t}\n\tn := s.perIPConnCounter.Register(ip)\n\tif n > s.MaxConnsPerIP {\n\t\ts.perIPConnCounter.Unregister(ip)\n\t\ts.writeFastError(c, StatusTooManyRequests, \"The number of connections from your ip exceeds MaxConnsPerIP\")\n\t\tc.Close()\n\t\treturn nil\n\t}\n\treturn acquirePerIPConn(c, ip, &s.perIPConnCounter)\n}\n\nvar defaultLogger = Logger(log.New(os.Stderr, \"\", log.LstdFlags))\n\nfunc (s *Server) logger() Logger {\n\tif s.Logger != nil {\n\t\treturn s.Logger\n\t}\n\treturn defaultLogger\n}\n\nvar (\n\t// ErrPerIPConnLimit may be returned from ServeConn if the number of connections\n\t// per ip exceeds Server.MaxConnsPerIP.\n\tErrPerIPConnLimit = errors.New(\"too many connections per ip\")\n\n\t// ErrConcurrencyLimit may be returned from ServeConn if the number\n\t// of concurrently served connections exceeds Server.Concurrency.\n\tErrConcurrencyLimit = errors.New(\"cannot serve the connection because Server.Concurrency concurrent connections are served\")\n)\n\n// ServeConn serves HTTP requests from the given connection.\n//\n// ServeConn returns nil if all requests from the c are successfully served.\n// It returns non-nil error otherwise.\n//\n// Connection c must immediately propagate all the data passed to Write()\n// to the client. Otherwise requests' processing may hang.\n//\n// ServeConn closes c before returning.\nfunc (s *Server) ServeConn(c net.Conn) error {\n\tif s.MaxConnsPerIP > 0 {\n\t\tpic := wrapPerIPConn(s, c)\n\t\tif pic == nil {\n\t\t\treturn ErrPerIPConnLimit\n\t\t}\n\t\tc = pic\n\t}\n\n\tn := atomic.AddUint32(&s.concurrency, 1)\n\tif n > uint32(s.getConcurrency()) {\n\t\tatomic.AddUint32(&s.concurrency, ^uint32(0))\n\t\ts.writeFastError(c, StatusServiceUnavailable, \"The connection cannot be served because Server.Concurrency limit exceeded\")\n\t\tc.Close()\n\t\treturn ErrConcurrencyLimit\n\t}\n\n\tatomic.AddInt32(&s.open, 1)\n\n\terr := s.serveConn(c)\n\n\tatomic.AddUint32(&s.concurrency, ^uint32(0))\n\n\tif err != errHijacked {\n\t\terr1 := c.Close()\n\t\ts.setState(c, StateClosed)\n\t\tif err == nil {\n\t\t\terr = err1\n\t\t}\n\t} else {\n\t\terr = nil\n\t\ts.setState(c, StateHijacked)\n\t}\n\treturn err\n}\n\nvar errHijacked = errors.New(\"connection has been hijacked\")\n\n// GetCurrentConcurrency returns a number of currently served\n// connections.\n//\n// This function is intended be used by monitoring systems\nfunc (s *Server) GetCurrentConcurrency() uint32 {\n\treturn atomic.LoadUint32(&s.concurrency)\n}\n\n// GetOpenConnectionsCount returns a number of opened connections.\n//\n// This function is intended be used by monitoring systems\nfunc (s *Server) GetOpenConnectionsCount() int32 {\n\tif atomic.LoadInt32(&s.stop) == 0 {\n\t\t// Decrement by one to avoid reporting the extra open value that gets\n\t\t// counted while the server is listening.\n\t\treturn atomic.LoadInt32(&s.open) - 1\n\t}\n\t// This is not perfect, because s.stop could have changed to zero\n\t// before we load the value of s.open. However, in the common case\n\t// this avoids underreporting open connections by 1 during server shutdown.\n\treturn atomic.LoadInt32(&s.open)\n}\n\nfunc (s *Server) getConcurrency() int {\n\tn := s.Concurrency\n\tif n <= 0 {\n\t\tn = DefaultConcurrency\n\t}\n\treturn n\n}\n\nvar globalConnID uint64\n\nfunc nextConnID() uint64 {\n\treturn atomic.AddUint64(&globalConnID, 1)\n}\n\n// DefaultMaxRequestBodySize is the maximum request body size the server\n// reads by default.\n//\n// See Server.MaxRequestBodySize for details.\nconst DefaultMaxRequestBodySize = 4 * 1024 * 1024\n\nfunc (s *Server) idleTimeout() time.Duration {\n\tif s.IdleTimeout != 0 {\n\t\treturn s.IdleTimeout\n\t}\n\treturn s.ReadTimeout\n}\n\nfunc (s *Server) serveConnCleanup() {\n\tatomic.AddInt32(&s.open, -1)\n\tatomic.AddUint32(&s.concurrency, ^uint32(0))\n}\n\nfunc (s *Server) serveConn(c net.Conn) (err error) {\n\tdefer s.serveConnCleanup()\n\tatomic.AddUint32(&s.concurrency, 1)\n\n\tvar proto string\n\tif proto, err = s.getNextProto(c); err != nil {\n\t\treturn\n\t}\n\tif handler, ok := s.nextProtos[proto]; ok {\n\t\t// Remove read or write deadlines that might have previously been set.\n\t\t// The next handler is responsible for setting its own deadlines.\n\t\tif s.ReadTimeout > 0 || s.WriteTimeout > 0 {\n\t\t\tif err := c.SetDeadline(zeroTime); err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetDeadline(zeroTime): %s\", err))\n\t\t\t}\n\t\t}\n\n\t\treturn handler(c)\n\t}\n\n\tvar serverName []byte\n\tif !s.NoDefaultServerHeader {\n\t\tserverName = s.getServerName()\n\t}\n\tconnRequestNum := uint64(0)\n\tconnID := nextConnID()\n\tconnTime := time.Now()\n\tmaxRequestBodySize := s.MaxRequestBodySize\n\tif maxRequestBodySize <= 0 {\n\t\tmaxRequestBodySize = DefaultMaxRequestBodySize\n\t}\n\twriteTimeout := s.WriteTimeout\n\tpreviousWriteTimeout := time.Duration(0)\n\n\tctx := s.acquireCtx(c)\n\tctx.connTime = connTime\n\tisTLS := ctx.IsTLS()\n\tvar (\n\t\tbr *bufio.Reader\n\t\tbw *bufio.Writer\n\n\t\ttimeoutResponse  *Response\n\t\thijackHandler    HijackHandler\n\t\thijackNoResponse bool\n\n\t\tconnectionClose bool\n\t\tisHTTP11        bool\n\n\t\tcontinueReadingRequest bool = true\n\t)\n\tfor {\n\t\tconnRequestNum++\n\n\t\t// If this is a keep-alive connection set the idle timeout.\n\t\tif connRequestNum > 1 {\n\t\t\tif d := s.idleTimeout(); d > 0 {\n\t\t\t\tif err := c.SetReadDeadline(time.Now().Add(d)); err != nil {\n\t\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetReadDeadline(%s): %s\", d, err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif !s.ReduceMemoryUsage || br != nil {\n\t\t\tif br == nil {\n\t\t\t\tbr = acquireReader(ctx)\n\t\t\t}\n\n\t\t\t// If this is a keep-alive connection we want to try and read the first bytes\n\t\t\t// within the idle time.\n\t\t\tif connRequestNum > 1 {\n\t\t\t\tvar b []byte\n\t\t\t\tb, err = br.Peek(1)\n\t\t\t\tif len(b) == 0 {\n\t\t\t\t\t// If reading from a keep-alive connection returns nothing it means\n\t\t\t\t\t// the connection was closed (either timeout or from the other side).\n\t\t\t\t\tif err != io.EOF {\n\t\t\t\t\t\terr = ErrNothingRead{err}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t// If this is a keep-alive connection acquireByteReader will try to peek\n\t\t\t// a couple of bytes already so the idle timeout will already be used.\n\t\t\tbr, err = acquireByteReader(&ctx)\n\t\t}\n\n\t\tctx.Request.isTLS = isTLS\n\t\tctx.Response.Header.noDefaultContentType = s.NoDefaultContentType\n\t\tctx.Response.Header.noDefaultDate = s.NoDefaultDate\n\n\t\t// Secure header error logs configuration\n\t\tctx.Request.Header.secureErrorLogMessage = s.SecureErrorLogMessage\n\t\tctx.Response.Header.secureErrorLogMessage = s.SecureErrorLogMessage\n\t\tctx.Request.secureErrorLogMessage = s.SecureErrorLogMessage\n\t\tctx.Response.secureErrorLogMessage = s.SecureErrorLogMessage\n\n\t\tif err == nil {\n\t\t\tif s.ReadTimeout > 0 {\n\t\t\t\tif err := c.SetReadDeadline(time.Now().Add(s.ReadTimeout)); err != nil {\n\t\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetReadDeadline(%s): %s\", s.ReadTimeout, err))\n\t\t\t\t}\n\t\t\t} else if s.IdleTimeout > 0 && connRequestNum > 1 {\n\t\t\t\t// If this was an idle connection and the server has an IdleTimeout but\n\t\t\t\t// no ReadTimeout then we should remove the ReadTimeout.\n\t\t\t\tif err := c.SetReadDeadline(zeroTime); err != nil {\n\t\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetReadDeadline(zeroTime): %s\", err))\n\t\t\t\t}\n\t\t\t}\n\t\t\tif s.DisableHeaderNamesNormalizing {\n\t\t\t\tctx.Request.Header.DisableNormalizing()\n\t\t\t\tctx.Response.Header.DisableNormalizing()\n\t\t\t}\n\n\t\t\t// Reading Headers.\n\t\t\t//\n\t\t\t// If we have pipline response in the outgoing buffer,\n\t\t\t// we only want to try and read the next headers once.\n\t\t\t// If we have to wait for the next request we flush the\n\t\t\t// outgoing buffer first so it doesn't have to wait.\n\t\t\tif bw != nil && bw.Buffered() > 0 {\n\t\t\t\terr = ctx.Request.Header.readLoop(br, false)\n\t\t\t\tif err == errNeedMore {\n\t\t\t\t\terr = bw.Flush()\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\n\t\t\t\t\terr = ctx.Request.Header.Read(br)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\terr = ctx.Request.Header.Read(br)\n\t\t\t}\n\n\t\t\tif err == nil {\n\t\t\t\tif onHdrRecv := s.HeaderReceived; onHdrRecv != nil {\n\t\t\t\t\treqConf := onHdrRecv(&ctx.Request.Header)\n\t\t\t\t\tif reqConf.ReadTimeout > 0 {\n\t\t\t\t\t\tdeadline := time.Now().Add(reqConf.ReadTimeout)\n\t\t\t\t\t\tif err := c.SetReadDeadline(deadline); err != nil {\n\t\t\t\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetReadDeadline(%s): %s\", deadline, err))\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif reqConf.MaxRequestBodySize > 0 {\n\t\t\t\t\t\tmaxRequestBodySize = reqConf.MaxRequestBodySize\n\t\t\t\t\t}\n\t\t\t\t\tif reqConf.WriteTimeout > 0 {\n\t\t\t\t\t\twriteTimeout = reqConf.WriteTimeout\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//read body\n\t\t\t\tif s.StreamRequestBody {\n\t\t\t\t\terr = ctx.Request.readBodyStream(br, maxRequestBodySize, s.GetOnly, !s.DisablePreParseMultipartForm)\n\t\t\t\t} else {\n\t\t\t\t\terr = ctx.Request.readLimitBody(br, maxRequestBodySize, s.GetOnly, !s.DisablePreParseMultipartForm)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif err == nil {\n\t\t\t\t// If we read any bytes off the wire, we're active.\n\t\t\t\ts.setState(c, StateActive)\n\t\t\t}\n\n\t\t\tif (s.ReduceMemoryUsage && br.Buffered() == 0) || err != nil {\n\t\t\t\treleaseReader(s, br)\n\t\t\t\tbr = nil\n\t\t\t}\n\t\t}\n\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\terr = nil\n\t\t\t} else if nr, ok := err.(ErrNothingRead); ok {\n\t\t\t\tif connRequestNum > 1 {\n\t\t\t\t\t// This is not the first request and we haven't read a single byte\n\t\t\t\t\t// of a new request yet. This means it's just a keep-alive connection\n\t\t\t\t\t// closing down either because the remote closed it or because\n\t\t\t\t\t// or a read timeout on our side. Either way just close the connection\n\t\t\t\t\t// and don't return any error response.\n\t\t\t\t\terr = nil\n\t\t\t\t} else {\n\t\t\t\t\terr = nr.error\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif err != nil {\n\t\t\t\tbw = s.writeErrorResponse(bw, ctx, serverName, err)\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\n\t\t// 'Expect: 100-continue' request handling.\n\t\t// See https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.2.3 for details.\n\t\tif ctx.Request.MayContinue() {\n\n\t\t\t// Allow the ability to deny reading the incoming request body\n\t\t\tif s.ContinueHandler != nil {\n\t\t\t\tif continueReadingRequest = s.ContinueHandler(&ctx.Request.Header); !continueReadingRequest {\n\t\t\t\t\tif br != nil {\n\t\t\t\t\t\tbr.Reset(ctx.c)\n\t\t\t\t\t}\n\n\t\t\t\t\tctx.SetStatusCode(StatusExpectationFailed)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif continueReadingRequest {\n\t\t\t\tif bw == nil {\n\t\t\t\t\tbw = acquireWriter(ctx)\n\t\t\t\t}\n\n\t\t\t\t// Send 'HTTP/1.1 100 Continue' response.\n\t\t\t\t_, err = bw.Write(strResponseContinue)\n\t\t\t\tif err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\terr = bw.Flush()\n\t\t\t\tif err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tif s.ReduceMemoryUsage {\n\t\t\t\t\treleaseWriter(s, bw)\n\t\t\t\t\tbw = nil\n\t\t\t\t}\n\n\t\t\t\t// Read request body.\n\t\t\t\tif br == nil {\n\t\t\t\t\tbr = acquireReader(ctx)\n\t\t\t\t}\n\n\t\t\t\tif s.StreamRequestBody {\n\t\t\t\t\terr = ctx.Request.ContinueReadBodyStream(br, maxRequestBodySize, !s.DisablePreParseMultipartForm)\n\t\t\t\t} else {\n\t\t\t\t\terr = ctx.Request.ContinueReadBody(br, maxRequestBodySize, !s.DisablePreParseMultipartForm)\n\t\t\t\t}\n\t\t\t\tif (s.ReduceMemoryUsage && br.Buffered() == 0) || err != nil {\n\t\t\t\t\treleaseReader(s, br)\n\t\t\t\t\tbr = nil\n\t\t\t\t}\n\t\t\t\tif err != nil {\n\t\t\t\t\tbw = s.writeErrorResponse(bw, ctx, serverName, err)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tconnectionClose = s.DisableKeepalive || ctx.Request.Header.ConnectionClose()\n\t\tisHTTP11 = ctx.Request.Header.IsHTTP11()\n\n\t\tif serverName != nil {\n\t\t\tctx.Response.Header.SetServerBytes(serverName)\n\t\t}\n\t\tctx.connID = connID\n\t\tctx.connRequestNum = connRequestNum\n\t\tctx.time = time.Now()\n\n\t\t// If a client denies a request the handler should not be called\n\t\tif continueReadingRequest {\n\t\t\ts.Handler(ctx)\n\t\t}\n\n\t\ttimeoutResponse = ctx.timeoutResponse\n\t\tif timeoutResponse != nil {\n\t\t\t// Acquire a new ctx because the old one will still be in use by the timeout out handler.\n\t\t\tctx = s.acquireCtx(c)\n\t\t\ttimeoutResponse.CopyTo(&ctx.Response)\n\t\t}\n\n\t\tif ctx.IsHead() {\n\t\t\tctx.Response.SkipBody = true\n\t\t}\n\n\t\thijackHandler = ctx.hijackHandler\n\t\tctx.hijackHandler = nil\n\t\thijackNoResponse = ctx.hijackNoResponse && hijackHandler != nil\n\t\tctx.hijackNoResponse = false\n\n\t\tif s.MaxRequestsPerConn > 0 && connRequestNum >= uint64(s.MaxRequestsPerConn) {\n\t\t\tctx.SetConnectionClose()\n\t\t}\n\n\t\tif writeTimeout > 0 {\n\t\t\tif err := c.SetWriteDeadline(time.Now().Add(writeTimeout)); err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetWriteDeadline(%s): %s\", writeTimeout, err))\n\t\t\t}\n\t\t\tpreviousWriteTimeout = writeTimeout\n\t\t} else if previousWriteTimeout > 0 {\n\t\t\t// We don't want a write timeout but we previously set one, remove it.\n\t\t\tif err := c.SetWriteDeadline(zeroTime); err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetWriteDeadline(zeroTime): %s\", err))\n\t\t\t}\n\t\t\tpreviousWriteTimeout = 0\n\t\t}\n\n\t\tconnectionClose = connectionClose || ctx.Response.ConnectionClose() || (s.CloseOnShutdown && atomic.LoadInt32(&s.stop) == 1)\n\t\tif connectionClose {\n\t\t\tctx.Response.Header.SetCanonical(strConnection, strClose)\n\t\t} else if !isHTTP11 {\n\t\t\t// Set 'Connection: keep-alive' response header for non-HTTP/1.1 request.\n\t\t\t// There is no need in setting this header for http/1.1, since in http/1.1\n\t\t\t// connections are keep-alive by default.\n\t\t\tctx.Response.Header.SetCanonical(strConnection, strKeepAlive)\n\t\t}\n\n\t\tif serverName != nil && len(ctx.Response.Header.Server()) == 0 {\n\t\t\tctx.Response.Header.SetServerBytes(serverName)\n\t\t}\n\n\t\tif !hijackNoResponse {\n\t\t\tif bw == nil {\n\t\t\t\tbw = acquireWriter(ctx)\n\t\t\t}\n\t\t\tif err = writeResponse(ctx, bw); err != nil {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Only flush the writer if we don't have another request in the pipeline.\n\t\t\t// This is a big of an ugly optimization for https://www.techempower.com/benchmarks/\n\t\t\t// This benchmark will send 16 pipelined requests. It is faster to pack as many responses\n\t\t\t// in a TCP packet and send it back at once than waiting for a flush every request.\n\t\t\t// In real world circumstances this behaviour could be argued as being wrong.\n\t\t\tif br == nil || br.Buffered() == 0 || connectionClose {\n\t\t\t\terr = bw.Flush()\n\t\t\t\tif err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif connectionClose {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif s.ReduceMemoryUsage && hijackHandler == nil {\n\t\t\t\treleaseWriter(s, bw)\n\t\t\t\tbw = nil\n\t\t\t}\n\t\t}\n\n\t\tif hijackHandler != nil {\n\t\t\tvar hjr io.Reader = c\n\t\t\tif br != nil {\n\t\t\t\thjr = br\n\t\t\t\tbr = nil\n\t\t\t}\n\t\t\tif bw != nil {\n\t\t\t\terr = bw.Flush()\n\t\t\t\tif err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\treleaseWriter(s, bw)\n\t\t\t\tbw = nil\n\t\t\t}\n\t\t\terr = c.SetDeadline(zeroTime)\n\t\t\tif err != nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tgo hijackConnHandler(ctx, hjr, c, s, hijackHandler)\n\t\t\terr = errHijacked\n\t\t\tbreak\n\t\t}\n\n\t\tif ctx.Request.bodyStream != nil {\n\t\t\tif rs, ok := ctx.Request.bodyStream.(*requestStream); ok {\n\t\t\t\treleaseRequestStream(rs)\n\t\t\t}\n\t\t}\n\n\t\ts.setState(c, StateIdle)\n\t\tctx.userValues.Reset()\n\t\tctx.Request.Reset()\n\t\tctx.Response.Reset()\n\n\t\tif atomic.LoadInt32(&s.stop) == 1 {\n\t\t\terr = nil\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif br != nil {\n\t\treleaseReader(s, br)\n\t}\n\tif bw != nil {\n\t\treleaseWriter(s, bw)\n\t}\n\tif hijackHandler == nil {\n\t\ts.releaseCtx(ctx)\n\t}\n\n\treturn\n}\n\nfunc (s *Server) setState(nc net.Conn, state ConnState) {\n\ts.trackConn(nc, state)\n\tif hook := s.ConnState; hook != nil {\n\t\thook(nc, state)\n\t}\n}\n\nfunc hijackConnHandler(ctx *RequestCtx, r io.Reader, c net.Conn, s *Server, h HijackHandler) {\n\thjc := s.acquireHijackConn(r, c)\n\th(hjc)\n\n\tif br, ok := r.(*bufio.Reader); ok {\n\t\treleaseReader(s, br)\n\t}\n\tif !s.KeepHijackedConns {\n\t\tc.Close()\n\t\ts.releaseHijackConn(hjc)\n\t}\n\ts.releaseCtx(ctx)\n}\n\nfunc (s *Server) acquireHijackConn(r io.Reader, c net.Conn) *hijackConn {\n\tv := s.hijackConnPool.Get()\n\tif v == nil {\n\t\thjc := &hijackConn{\n\t\t\tConn: c,\n\t\t\tr:    r,\n\t\t\ts:    s,\n\t\t}\n\t\treturn hjc\n\t}\n\thjc := v.(*hijackConn)\n\thjc.Conn = c\n\thjc.r = r\n\treturn hjc\n}\n\nfunc (s *Server) releaseHijackConn(hjc *hijackConn) {\n\thjc.Conn = nil\n\thjc.r = nil\n\ts.hijackConnPool.Put(hjc)\n}\n\ntype hijackConn struct {\n\tnet.Conn\n\tr io.Reader\n\ts *Server\n}\n\nfunc (c *hijackConn) UnsafeConn() net.Conn {\n\treturn c.Conn\n}\n\nfunc (c *hijackConn) Read(p []byte) (int, error) {\n\treturn c.r.Read(p)\n}\n\nfunc (c *hijackConn) Close() error {\n\tif !c.s.KeepHijackedConns {\n\t\t// when we do not keep hijacked connections,\n\t\t// it is closed in hijackConnHandler.\n\t\treturn nil\n\t}\n\n\tconn := c.Conn\n\tc.s.releaseHijackConn(c)\n\treturn conn.Close()\n}\n\n// LastTimeoutErrorResponse returns the last timeout response set\n// via TimeoutError* call.\n//\n// This function is intended for custom server implementations.\nfunc (ctx *RequestCtx) LastTimeoutErrorResponse() *Response {\n\treturn ctx.timeoutResponse\n}\n\nfunc writeResponse(ctx *RequestCtx, w *bufio.Writer) error {\n\tif ctx.timeoutResponse != nil {\n\t\tpanic(\"BUG: cannot write timed out response\")\n\t}\n\terr := ctx.Response.Write(w)\n\n\treturn err\n}\n\nconst (\n\tdefaultReadBufferSize  = 4096\n\tdefaultWriteBufferSize = 4096\n)\n\nfunc acquireByteReader(ctxP **RequestCtx) (*bufio.Reader, error) {\n\tctx := *ctxP\n\ts := ctx.s\n\tc := ctx.c\n\ts.releaseCtx(ctx)\n\n\t// Make GC happy, so it could garbage collect ctx\n\t// while we waiting for the next request.\n\tctx = nil\n\t*ctxP = nil\n\n\tvar b [1]byte\n\tn, err := c.Read(b[:])\n\n\tctx = s.acquireCtx(c)\n\t*ctxP = ctx\n\tif err != nil {\n\t\t// Treat all errors as EOF on unsuccessful read\n\t\t// of the first request byte.\n\t\treturn nil, io.EOF\n\t}\n\tif n != 1 {\n\t\tpanic(\"BUG: Reader must return at least one byte\")\n\t}\n\n\tctx.fbr.c = c\n\tctx.fbr.ch = b[0]\n\tctx.fbr.byteRead = false\n\tr := acquireReader(ctx)\n\tr.Reset(&ctx.fbr)\n\treturn r, nil\n}\n\nfunc acquireReader(ctx *RequestCtx) *bufio.Reader {\n\tv := ctx.s.readerPool.Get()\n\tif v == nil {\n\t\tn := ctx.s.ReadBufferSize\n\t\tif n <= 0 {\n\t\t\tn = defaultReadBufferSize\n\t\t}\n\t\treturn bufio.NewReaderSize(ctx.c, n)\n\t}\n\tr := v.(*bufio.Reader)\n\tr.Reset(ctx.c)\n\treturn r\n}\n\nfunc releaseReader(s *Server, r *bufio.Reader) {\n\ts.readerPool.Put(r)\n}\n\nfunc acquireWriter(ctx *RequestCtx) *bufio.Writer {\n\tv := ctx.s.writerPool.Get()\n\tif v == nil {\n\t\tn := ctx.s.WriteBufferSize\n\t\tif n <= 0 {\n\t\t\tn = defaultWriteBufferSize\n\t\t}\n\t\treturn bufio.NewWriterSize(ctx.c, n)\n\t}\n\tw := v.(*bufio.Writer)\n\tw.Reset(ctx.c)\n\treturn w\n}\n\nfunc releaseWriter(s *Server, w *bufio.Writer) {\n\ts.writerPool.Put(w)\n}\n\nfunc (s *Server) acquireCtx(c net.Conn) (ctx *RequestCtx) {\n\tv := s.ctxPool.Get()\n\tif v == nil {\n\t\tkeepBodyBuffer := !s.ReduceMemoryUsage\n\n\t\tctx = new(RequestCtx)\n\t\tctx.Request.keepBodyBuffer = keepBodyBuffer\n\t\tctx.Response.keepBodyBuffer = keepBodyBuffer\n\t} else {\n\t\tctx = v.(*RequestCtx)\n\t}\n\n\tctx.s = s\n\tctx.c = c\n\n\treturn ctx\n}\n\n// Init2 prepares ctx for passing to RequestHandler.\n//\n// conn is used only for determining local and remote addresses.\n//\n// This function is intended for custom Server implementations.\n// See https://github.com/valyala/httpteleport for details.\nfunc (ctx *RequestCtx) Init2(conn net.Conn, logger Logger, reduceMemoryUsage bool) {\n\tctx.c = conn\n\tctx.remoteAddr = nil\n\tctx.logger.logger = logger\n\tctx.connID = nextConnID()\n\tctx.s = fakeServer\n\tctx.connRequestNum = 0\n\tctx.connTime = time.Now()\n\n\tkeepBodyBuffer := !reduceMemoryUsage\n\tctx.Request.keepBodyBuffer = keepBodyBuffer\n\tctx.Response.keepBodyBuffer = keepBodyBuffer\n}\n\n// Init prepares ctx for passing to RequestHandler.\n//\n// remoteAddr and logger are optional. They are used by RequestCtx.Logger().\n//\n// This function is intended for custom Server implementations.\nfunc (ctx *RequestCtx) Init(req *Request, remoteAddr net.Addr, logger Logger) {\n\tif remoteAddr == nil {\n\t\tremoteAddr = zeroTCPAddr\n\t}\n\tc := &fakeAddrer{\n\t\tladdr: zeroTCPAddr,\n\t\traddr: remoteAddr,\n\t}\n\tif logger == nil {\n\t\tlogger = defaultLogger\n\t}\n\tctx.Init2(c, logger, true)\n\treq.CopyTo(&ctx.Request)\n}\n\n// Deadline returns the time when work done on behalf of this context\n// should be canceled. Deadline returns ok==false when no deadline is\n// set. Successive calls to Deadline return the same results.\n//\n// This method always returns 0, false and is only present to make\n// RequestCtx implement the context interface.\nfunc (ctx *RequestCtx) Deadline() (deadline time.Time, ok bool) {\n\treturn\n}\n\n// Done returns a channel that's closed when work done on behalf of this\n// context should be canceled. Done may return nil if this context can\n// never be canceled. Successive calls to Done return the same value.\nfunc (ctx *RequestCtx) Done() <-chan struct{} {\n\treturn ctx.s.done\n}\n\n// Err returns a non-nil error value after Done is closed,\n// successive calls to Err return the same error.\n// If Done is not yet closed, Err returns nil.\n// If Done is closed, Err returns a non-nil error explaining why:\n// Canceled if the context was canceled (via server Shutdown)\n// or DeadlineExceeded if the context's deadline passed.\nfunc (ctx *RequestCtx) Err() error {\n\tselect {\n\tcase <-ctx.s.done:\n\t\treturn context.Canceled\n\tdefault:\n\t\treturn nil\n\t}\n}\n\n// Value returns the value associated with this context for key, or nil\n// if no value is associated with key. Successive calls to Value with\n// the same key returns the same result.\n//\n// This method is present to make RequestCtx implement the context interface.\n// This method is the same as calling ctx.UserValue(key)\nfunc (ctx *RequestCtx) Value(key interface{}) interface{} {\n\tif keyString, ok := key.(string); ok {\n\t\treturn ctx.UserValue(keyString)\n\t}\n\treturn nil\n}\n\nvar fakeServer = &Server{\n\t// Initialize concurrencyCh for TimeoutHandler\n\tconcurrencyCh: make(chan struct{}, DefaultConcurrency),\n}\n\ntype fakeAddrer struct {\n\tnet.Conn\n\tladdr net.Addr\n\traddr net.Addr\n}\n\nfunc (fa *fakeAddrer) RemoteAddr() net.Addr {\n\treturn fa.raddr\n}\n\nfunc (fa *fakeAddrer) LocalAddr() net.Addr {\n\treturn fa.laddr\n}\n\nfunc (fa *fakeAddrer) Read(p []byte) (int, error) {\n\tpanic(\"BUG: unexpected Read call\")\n}\n\nfunc (fa *fakeAddrer) Write(p []byte) (int, error) {\n\tpanic(\"BUG: unexpected Write call\")\n}\n\nfunc (fa *fakeAddrer) Close() error {\n\tpanic(\"BUG: unexpected Close call\")\n}\n\nfunc (s *Server) releaseCtx(ctx *RequestCtx) {\n\tif ctx.timeoutResponse != nil {\n\t\tpanic(\"BUG: cannot release timed out RequestCtx\")\n\t}\n\n\tctx.reset()\n\ts.ctxPool.Put(ctx)\n}\n\nfunc (s *Server) getServerName() []byte {\n\tv := s.serverName.Load()\n\tvar serverName []byte\n\tif v == nil {\n\t\tserverName = []byte(s.Name)\n\t\tif len(serverName) == 0 {\n\t\t\tserverName = defaultServerName\n\t\t}\n\t\ts.serverName.Store(serverName)\n\t} else {\n\t\tserverName = v.([]byte)\n\t}\n\treturn serverName\n}\n\nfunc (s *Server) writeFastError(w io.Writer, statusCode int, msg string) {\n\tw.Write(formatStatusLine(nil, strHTTP11, statusCode, s2b(StatusMessage(statusCode)))) //nolint:errcheck\n\n\tserver := \"\"\n\tif !s.NoDefaultServerHeader {\n\t\tserver = fmt.Sprintf(\"Server: %s\\r\\n\", s.getServerName())\n\t}\n\n\tdate := \"\"\n\tif !s.NoDefaultDate {\n\t\tserverDateOnce.Do(updateServerDate)\n\t\tdate = fmt.Sprintf(\"Date: %s\\r\\n\", serverDate.Load())\n\t}\n\n\tfmt.Fprintf(w, \"Connection: close\\r\\n\"+\n\t\tserver+\n\t\tdate+\n\t\t\"Content-Type: text/plain\\r\\n\"+\n\t\t\"Content-Length: %d\\r\\n\"+\n\t\t\"\\r\\n\"+\n\t\t\"%s\",\n\t\tlen(msg), msg)\n}\n\nfunc defaultErrorHandler(ctx *RequestCtx, err error) {\n\tif _, ok := err.(*ErrSmallBuffer); ok {\n\t\tctx.Error(\"Too big request header\", StatusRequestHeaderFieldsTooLarge)\n\t} else if netErr, ok := err.(*net.OpError); ok && netErr.Timeout() {\n\t\tctx.Error(\"Request timeout\", StatusRequestTimeout)\n\t} else {\n\t\tctx.Error(\"Error when parsing request\", StatusBadRequest)\n\t}\n}\n\nfunc (s *Server) writeErrorResponse(bw *bufio.Writer, ctx *RequestCtx, serverName []byte, err error) *bufio.Writer {\n\terrorHandler := defaultErrorHandler\n\tif s.ErrorHandler != nil {\n\t\terrorHandler = s.ErrorHandler\n\t}\n\n\terrorHandler(ctx, err)\n\n\tif serverName != nil {\n\t\tctx.Response.Header.SetServerBytes(serverName)\n\t}\n\tctx.SetConnectionClose()\n\tif bw == nil {\n\t\tbw = acquireWriter(ctx)\n\t}\n\n\twriteResponse(ctx, bw) //nolint:errcheck\n\tctx.Response.Reset()\n\tbw.Flush()\n\n\treturn bw\n}\n\nfunc (s *Server) trackConn(c net.Conn, state ConnState) {\n\ts.idleConnsMu.Lock()\n\tswitch state {\n\tcase StateIdle:\n\t\tif s.idleConns == nil {\n\t\t\ts.idleConns = make(map[net.Conn]struct{})\n\t\t}\n\t\ts.idleConns[c] = struct{}{}\n\n\tdefault:\n\t\tdelete(s.idleConns, c)\n\t}\n\ts.idleConnsMu.Unlock()\n}\n\nfunc (s *Server) closeIdleConns() {\n\ts.idleConnsMu.Lock()\n\tfor c := range s.idleConns {\n\t\t_ = c.Close()\n\t}\n\ts.idleConns = nil\n\ts.idleConnsMu.Unlock()\n}\n\n// A ConnState represents the state of a client connection to a server.\n// It's used by the optional Server.ConnState hook.\ntype ConnState int\n\nconst (\n\t// StateNew represents a new connection that is expected to\n\t// send a request immediately. Connections begin at this\n\t// state and then transition to either StateActive or\n\t// StateClosed.\n\tStateNew ConnState = iota\n\n\t// StateActive represents a connection that has read 1 or more\n\t// bytes of a request. The Server.ConnState hook for\n\t// StateActive fires before the request has entered a handler\n\t// and doesn't fire again until the request has been\n\t// handled. After the request is handled, the state\n\t// transitions to StateClosed, StateHijacked, or StateIdle.\n\t// For HTTP/2, StateActive fires on the transition from zero\n\t// to one active request, and only transitions away once all\n\t// active requests are complete. That means that ConnState\n\t// cannot be used to do per-request work; ConnState only notes\n\t// the overall state of the connection.\n\tStateActive\n\n\t// StateIdle represents a connection that has finished\n\t// handling a request and is in the keep-alive state, waiting\n\t// for a new request. Connections transition from StateIdle\n\t// to either StateActive or StateClosed.\n\tStateIdle\n\n\t// StateHijacked represents a hijacked connection.\n\t// This is a terminal state. It does not transition to StateClosed.\n\tStateHijacked\n\n\t// StateClosed represents a closed connection.\n\t// This is a terminal state. Hijacked connections do not\n\t// transition to StateClosed.\n\tStateClosed\n)\n\nvar stateName = map[ConnState]string{\n\tStateNew:      \"new\",\n\tStateActive:   \"active\",\n\tStateIdle:     \"idle\",\n\tStateHijacked: \"hijacked\",\n\tStateClosed:   \"closed\",\n}\n\nfunc (c ConnState) String() string {\n\treturn stateName[c]\n}\n"], "fixing_code": ["package fasthttp\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"html\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"mime\"\n\t\"net/http\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/andybalholm/brotli\"\n\t\"github.com/klauspost/compress/gzip\"\n\t\"github.com/valyala/bytebufferpool\"\n)\n\n// ServeFileBytesUncompressed returns HTTP response containing file contents\n// from the given path.\n//\n// Directory contents is returned if path points to directory.\n//\n// ServeFileBytes may be used for saving network traffic when serving files\n// with good compression ratio.\n//\n// See also RequestCtx.SendFileBytes.\n//\n// WARNING: do not pass any user supplied paths to this function!\n// WARNING: if path is based on user input users will be able to request\n// any file on your filesystem! Use fasthttp.FS with a sane Root instead.\nfunc ServeFileBytesUncompressed(ctx *RequestCtx, path []byte) {\n\tServeFileUncompressed(ctx, b2s(path))\n}\n\n// ServeFileUncompressed returns HTTP response containing file contents\n// from the given path.\n//\n// Directory contents is returned if path points to directory.\n//\n// ServeFile may be used for saving network traffic when serving files\n// with good compression ratio.\n//\n// See also RequestCtx.SendFile.\n//\n// WARNING: do not pass any user supplied paths to this function!\n// WARNING: if path is based on user input users will be able to request\n// any file on your filesystem! Use fasthttp.FS with a sane Root instead.\nfunc ServeFileUncompressed(ctx *RequestCtx, path string) {\n\tctx.Request.Header.DelBytes(strAcceptEncoding)\n\tServeFile(ctx, path)\n}\n\n// ServeFileBytes returns HTTP response containing compressed file contents\n// from the given path.\n//\n// HTTP response may contain uncompressed file contents in the following cases:\n//\n//   * Missing 'Accept-Encoding: gzip' request header.\n//   * No write access to directory containing the file.\n//\n// Directory contents is returned if path points to directory.\n//\n// Use ServeFileBytesUncompressed is you don't need serving compressed\n// file contents.\n//\n// See also RequestCtx.SendFileBytes.\n//\n// WARNING: do not pass any user supplied paths to this function!\n// WARNING: if path is based on user input users will be able to request\n// any file on your filesystem! Use fasthttp.FS with a sane Root instead.\nfunc ServeFileBytes(ctx *RequestCtx, path []byte) {\n\tServeFile(ctx, b2s(path))\n}\n\n// ServeFile returns HTTP response containing compressed file contents\n// from the given path.\n//\n// HTTP response may contain uncompressed file contents in the following cases:\n//\n//   * Missing 'Accept-Encoding: gzip' request header.\n//   * No write access to directory containing the file.\n//\n// Directory contents is returned if path points to directory.\n//\n// Use ServeFileUncompressed is you don't need serving compressed file contents.\n//\n// See also RequestCtx.SendFile.\n//\n// WARNING: do not pass any user supplied paths to this function!\n// WARNING: if path is based on user input users will be able to request\n// any file on your filesystem! Use fasthttp.FS with a sane Root instead.\nfunc ServeFile(ctx *RequestCtx, path string) {\n\trootFSOnce.Do(func() {\n\t\trootFSHandler = rootFS.NewRequestHandler()\n\t})\n\tif len(path) == 0 || path[0] != '/' {\n\t\t// extend relative path to absolute path\n\t\thasTrailingSlash := len(path) > 0 && path[len(path)-1] == '/'\n\t\tvar err error\n\t\tif path, err = filepath.Abs(path); err != nil {\n\t\t\tctx.Logger().Printf(\"cannot resolve path %q to absolute file path: %s\", path, err)\n\t\t\tctx.Error(\"Internal Server Error\", StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t\tif hasTrailingSlash {\n\t\t\tpath += \"/\"\n\t\t}\n\t}\n\tctx.Request.SetRequestURI(path)\n\trootFSHandler(ctx)\n}\n\nvar (\n\trootFSOnce sync.Once\n\trootFS     = &FS{\n\t\tRoot:               \"/\",\n\t\tGenerateIndexPages: true,\n\t\tCompress:           true,\n\t\tCompressBrotli:     true,\n\t\tAcceptByteRange:    true,\n\t}\n\trootFSHandler RequestHandler\n)\n\n// PathRewriteFunc must return new request path based on arbitrary ctx\n// info such as ctx.Path().\n//\n// Path rewriter is used in FS for translating the current request\n// to the local filesystem path relative to FS.Root.\n//\n// The returned path must not contain '/../' substrings due to security reasons,\n// since such paths may refer files outside FS.Root.\n//\n// The returned path may refer to ctx members. For example, ctx.Path().\ntype PathRewriteFunc func(ctx *RequestCtx) []byte\n\n// NewVHostPathRewriter returns path rewriter, which strips slashesCount\n// leading slashes from the path and prepends the path with request's host,\n// thus simplifying virtual hosting for static files.\n//\n// Examples:\n//\n//   * host=foobar.com, slashesCount=0, original path=\"/foo/bar\".\n//     Resulting path: \"/foobar.com/foo/bar\"\n//\n//   * host=img.aaa.com, slashesCount=1, original path=\"/images/123/456.jpg\"\n//     Resulting path: \"/img.aaa.com/123/456.jpg\"\n//\nfunc NewVHostPathRewriter(slashesCount int) PathRewriteFunc {\n\treturn func(ctx *RequestCtx) []byte {\n\t\tpath := stripLeadingSlashes(ctx.Path(), slashesCount)\n\t\thost := ctx.Host()\n\t\tif n := bytes.IndexByte(host, '/'); n >= 0 {\n\t\t\thost = nil\n\t\t}\n\t\tif len(host) == 0 {\n\t\t\thost = strInvalidHost\n\t\t}\n\t\tb := bytebufferpool.Get()\n\t\tb.B = append(b.B, '/')\n\t\tb.B = append(b.B, host...)\n\t\tb.B = append(b.B, path...)\n\t\tctx.URI().SetPathBytes(b.B)\n\t\tbytebufferpool.Put(b)\n\n\t\treturn ctx.Path()\n\t}\n}\n\nvar strInvalidHost = []byte(\"invalid-host\")\n\n// NewPathSlashesStripper returns path rewriter, which strips slashesCount\n// leading slashes from the path.\n//\n// Examples:\n//\n//   * slashesCount = 0, original path: \"/foo/bar\", result: \"/foo/bar\"\n//   * slashesCount = 1, original path: \"/foo/bar\", result: \"/bar\"\n//   * slashesCount = 2, original path: \"/foo/bar\", result: \"\"\n//\n// The returned path rewriter may be used as FS.PathRewrite .\nfunc NewPathSlashesStripper(slashesCount int) PathRewriteFunc {\n\treturn func(ctx *RequestCtx) []byte {\n\t\treturn stripLeadingSlashes(ctx.Path(), slashesCount)\n\t}\n}\n\n// NewPathPrefixStripper returns path rewriter, which removes prefixSize bytes\n// from the path prefix.\n//\n// Examples:\n//\n//   * prefixSize = 0, original path: \"/foo/bar\", result: \"/foo/bar\"\n//   * prefixSize = 3, original path: \"/foo/bar\", result: \"o/bar\"\n//   * prefixSize = 7, original path: \"/foo/bar\", result: \"r\"\n//\n// The returned path rewriter may be used as FS.PathRewrite .\nfunc NewPathPrefixStripper(prefixSize int) PathRewriteFunc {\n\treturn func(ctx *RequestCtx) []byte {\n\t\tpath := ctx.Path()\n\t\tif len(path) >= prefixSize {\n\t\t\tpath = path[prefixSize:]\n\t\t}\n\t\treturn path\n\t}\n}\n\n// FS represents settings for request handler serving static files\n// from the local filesystem.\n//\n// It is prohibited copying FS values. Create new values instead.\ntype FS struct {\n\tnoCopy noCopy //nolint:unused,structcheck\n\n\t// Path to the root directory to serve files from.\n\tRoot string\n\n\t// List of index file names to try opening during directory access.\n\t//\n\t// For example:\n\t//\n\t//     * index.html\n\t//     * index.htm\n\t//     * my-super-index.xml\n\t//\n\t// By default the list is empty.\n\tIndexNames []string\n\n\t// Index pages for directories without files matching IndexNames\n\t// are automatically generated if set.\n\t//\n\t// Directory index generation may be quite slow for directories\n\t// with many files (more than 1K), so it is discouraged enabling\n\t// index pages' generation for such directories.\n\t//\n\t// By default index pages aren't generated.\n\tGenerateIndexPages bool\n\n\t// Transparently compresses responses if set to true.\n\t//\n\t// The server tries minimizing CPU usage by caching compressed files.\n\t// It adds CompressedFileSuffix suffix to the original file name and\n\t// tries saving the resulting compressed file under the new file name.\n\t// So it is advisable to give the server write access to Root\n\t// and to all inner folders in order to minimize CPU usage when serving\n\t// compressed responses.\n\t//\n\t// Transparent compression is disabled by default.\n\tCompress bool\n\n\t// Uses brotli encoding and fallbacks to gzip in responses if set to true, uses gzip if set to false.\n\t//\n\t// This value has sense only if Compress is set.\n\t//\n\t// Brotli encoding is disabled by default.\n\tCompressBrotli bool\n\n\t// Enables byte range requests if set to true.\n\t//\n\t// Byte range requests are disabled by default.\n\tAcceptByteRange bool\n\n\t// Path rewriting function.\n\t//\n\t// By default request path is not modified.\n\tPathRewrite PathRewriteFunc\n\n\t// PathNotFound fires when file is not found in filesystem\n\t// this functions tries to replace \"Cannot open requested path\"\n\t// server response giving to the programmer the control of server flow.\n\t//\n\t// By default PathNotFound returns\n\t// \"Cannot open requested path\"\n\tPathNotFound RequestHandler\n\n\t// Expiration duration for inactive file handlers.\n\t//\n\t// FSHandlerCacheDuration is used by default.\n\tCacheDuration time.Duration\n\n\t// Suffix to add to the name of cached compressed file.\n\t//\n\t// This value has sense only if Compress is set.\n\t//\n\t// FSCompressedFileSuffix is used by default.\n\tCompressedFileSuffix string\n\n\t// Suffixes list to add to compressedFileSuffix depending on encoding\n\t//\n\t// This value has sense only if Compress is set.\n\t//\n\t// FSCompressedFileSuffixes is used by default.\n\tCompressedFileSuffixes map[string]string\n\n\t// If CleanStop is set, the channel can be closed to stop the cleanup handlers\n\t// for the FS RequestHandlers created with NewRequestHandler.\n\t// NEVER close this channel while the handler is still being used!\n\tCleanStop chan struct{}\n\n\tonce sync.Once\n\th    RequestHandler\n}\n\n// FSCompressedFileSuffix is the suffix FS adds to the original file names\n// when trying to store compressed file under the new file name.\n// See FS.Compress for details.\nconst FSCompressedFileSuffix = \".fasthttp.gz\"\n\n// FSCompressedFileSuffixes is the suffixes FS adds to the original file names depending on encoding\n// when trying to store compressed file under the new file name.\n// See FS.Compress for details.\nvar FSCompressedFileSuffixes = map[string]string{\n\t\"gzip\": \".fasthttp.gz\",\n\t\"br\":   \".fasthttp.br\",\n}\n\n// FSHandlerCacheDuration is the default expiration duration for inactive\n// file handlers opened by FS.\nconst FSHandlerCacheDuration = 10 * time.Second\n\n// FSHandler returns request handler serving static files from\n// the given root folder.\n//\n// stripSlashes indicates how many leading slashes must be stripped\n// from requested path before searching requested file in the root folder.\n// Examples:\n//\n//   * stripSlashes = 0, original path: \"/foo/bar\", result: \"/foo/bar\"\n//   * stripSlashes = 1, original path: \"/foo/bar\", result: \"/bar\"\n//   * stripSlashes = 2, original path: \"/foo/bar\", result: \"\"\n//\n// The returned request handler automatically generates index pages\n// for directories without index.html.\n//\n// The returned handler caches requested file handles\n// for FSHandlerCacheDuration.\n// Make sure your program has enough 'max open files' limit aka\n// 'ulimit -n' if root folder contains many files.\n//\n// Do not create multiple request handler instances for the same\n// (root, stripSlashes) arguments - just reuse a single instance.\n// Otherwise goroutine leak will occur.\nfunc FSHandler(root string, stripSlashes int) RequestHandler {\n\tfs := &FS{\n\t\tRoot:               root,\n\t\tIndexNames:         []string{\"index.html\"},\n\t\tGenerateIndexPages: true,\n\t\tAcceptByteRange:    true,\n\t}\n\tif stripSlashes > 0 {\n\t\tfs.PathRewrite = NewPathSlashesStripper(stripSlashes)\n\t}\n\treturn fs.NewRequestHandler()\n}\n\n// NewRequestHandler returns new request handler with the given FS settings.\n//\n// The returned handler caches requested file handles\n// for FS.CacheDuration.\n// Make sure your program has enough 'max open files' limit aka\n// 'ulimit -n' if FS.Root folder contains many files.\n//\n// Do not create multiple request handlers from a single FS instance -\n// just reuse a single request handler.\nfunc (fs *FS) NewRequestHandler() RequestHandler {\n\tfs.once.Do(fs.initRequestHandler)\n\treturn fs.h\n}\n\nfunc (fs *FS) initRequestHandler() {\n\troot := fs.Root\n\n\t// serve files from the current working directory if root is empty\n\tif len(root) == 0 {\n\t\troot = \".\"\n\t}\n\n\t// strip trailing slashes from the root path\n\tfor len(root) > 0 && root[len(root)-1] == '/' {\n\t\troot = root[:len(root)-1]\n\t}\n\n\tcacheDuration := fs.CacheDuration\n\tif cacheDuration <= 0 {\n\t\tcacheDuration = FSHandlerCacheDuration\n\t}\n\n\tcompressedFileSuffixes := fs.CompressedFileSuffixes\n\tif len(compressedFileSuffixes[\"br\"]) == 0 || len(compressedFileSuffixes[\"gzip\"]) == 0 ||\n\t\tcompressedFileSuffixes[\"br\"] == compressedFileSuffixes[\"gzip\"] {\n\t\tcompressedFileSuffixes = FSCompressedFileSuffixes\n\t}\n\n\tif len(fs.CompressedFileSuffix) > 0 {\n\t\tcompressedFileSuffixes[\"gzip\"] = fs.CompressedFileSuffix\n\t\tcompressedFileSuffixes[\"br\"] = FSCompressedFileSuffixes[\"br\"]\n\t}\n\n\th := &fsHandler{\n\t\troot:                   root,\n\t\tindexNames:             fs.IndexNames,\n\t\tpathRewrite:            fs.PathRewrite,\n\t\tgenerateIndexPages:     fs.GenerateIndexPages,\n\t\tcompress:               fs.Compress,\n\t\tcompressBrotli:         fs.CompressBrotli,\n\t\tpathNotFound:           fs.PathNotFound,\n\t\tacceptByteRange:        fs.AcceptByteRange,\n\t\tcacheDuration:          cacheDuration,\n\t\tcompressedFileSuffixes: compressedFileSuffixes,\n\t\tcache:                  make(map[string]*fsFile),\n\t\tcacheBrotli:            make(map[string]*fsFile),\n\t\tcacheGzip:              make(map[string]*fsFile),\n\t}\n\n\tgo func() {\n\t\tvar pendingFiles []*fsFile\n\n\t\tclean := func() {\n\t\t\tpendingFiles = h.cleanCache(pendingFiles)\n\t\t}\n\n\t\tif fs.CleanStop != nil {\n\t\t\tt := time.NewTicker(cacheDuration / 2)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-t.C:\n\t\t\t\t\tclean()\n\t\t\t\tcase _, stillOpen := <-fs.CleanStop:\n\t\t\t\t\t// Ignore values send on the channel, only stop when it is closed.\n\t\t\t\t\tif !stillOpen {\n\t\t\t\t\t\tt.Stop()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor {\n\t\t\ttime.Sleep(cacheDuration / 2)\n\t\t\tclean()\n\t\t}\n\t}()\n\n\tfs.h = h.handleRequest\n}\n\ntype fsHandler struct {\n\troot                   string\n\tindexNames             []string\n\tpathRewrite            PathRewriteFunc\n\tpathNotFound           RequestHandler\n\tgenerateIndexPages     bool\n\tcompress               bool\n\tcompressBrotli         bool\n\tacceptByteRange        bool\n\tcacheDuration          time.Duration\n\tcompressedFileSuffixes map[string]string\n\n\tcache       map[string]*fsFile\n\tcacheBrotli map[string]*fsFile\n\tcacheGzip   map[string]*fsFile\n\tcacheLock   sync.Mutex\n\n\tsmallFileReaderPool sync.Pool\n}\n\ntype fsFile struct {\n\th             *fsHandler\n\tf             *os.File\n\tdirIndex      []byte\n\tcontentType   string\n\tcontentLength int\n\tcompressed    bool\n\n\tlastModified    time.Time\n\tlastModifiedStr []byte\n\n\tt            time.Time\n\treadersCount int\n\n\tbigFiles     []*bigFileReader\n\tbigFilesLock sync.Mutex\n}\n\nfunc (ff *fsFile) NewReader() (io.Reader, error) {\n\tif ff.isBig() {\n\t\tr, err := ff.bigFileReader()\n\t\tif err != nil {\n\t\t\tff.decReadersCount()\n\t\t}\n\t\treturn r, err\n\t}\n\treturn ff.smallFileReader(), nil\n}\n\nfunc (ff *fsFile) smallFileReader() io.Reader {\n\tv := ff.h.smallFileReaderPool.Get()\n\tif v == nil {\n\t\tv = &fsSmallFileReader{}\n\t}\n\tr := v.(*fsSmallFileReader)\n\tr.ff = ff\n\tr.endPos = ff.contentLength\n\tif r.startPos > 0 {\n\t\tpanic(\"BUG: fsSmallFileReader with non-nil startPos found in the pool\")\n\t}\n\treturn r\n}\n\n// files bigger than this size are sent with sendfile\nconst maxSmallFileSize = 2 * 4096\n\nfunc (ff *fsFile) isBig() bool {\n\treturn ff.contentLength > maxSmallFileSize && len(ff.dirIndex) == 0\n}\n\nfunc (ff *fsFile) bigFileReader() (io.Reader, error) {\n\tif ff.f == nil {\n\t\tpanic(\"BUG: ff.f must be non-nil in bigFileReader\")\n\t}\n\n\tvar r io.Reader\n\n\tff.bigFilesLock.Lock()\n\tn := len(ff.bigFiles)\n\tif n > 0 {\n\t\tr = ff.bigFiles[n-1]\n\t\tff.bigFiles = ff.bigFiles[:n-1]\n\t}\n\tff.bigFilesLock.Unlock()\n\n\tif r != nil {\n\t\treturn r, nil\n\t}\n\n\tf, err := os.Open(ff.f.Name())\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot open already opened file: %w\", err)\n\t}\n\treturn &bigFileReader{\n\t\tf:  f,\n\t\tff: ff,\n\t\tr:  f,\n\t}, nil\n}\n\nfunc (ff *fsFile) Release() {\n\tif ff.f != nil {\n\t\tff.f.Close()\n\n\t\tif ff.isBig() {\n\t\t\tff.bigFilesLock.Lock()\n\t\t\tfor _, r := range ff.bigFiles {\n\t\t\t\tr.f.Close()\n\t\t\t}\n\t\t\tff.bigFilesLock.Unlock()\n\t\t}\n\t}\n}\n\nfunc (ff *fsFile) decReadersCount() {\n\tff.h.cacheLock.Lock()\n\tff.readersCount--\n\tif ff.readersCount < 0 {\n\t\tpanic(\"BUG: negative fsFile.readersCount!\")\n\t}\n\tff.h.cacheLock.Unlock()\n}\n\n// bigFileReader attempts to trigger sendfile\n// for sending big files over the wire.\ntype bigFileReader struct {\n\tf  *os.File\n\tff *fsFile\n\tr  io.Reader\n\tlr io.LimitedReader\n}\n\nfunc (r *bigFileReader) UpdateByteRange(startPos, endPos int) error {\n\tif _, err := r.f.Seek(int64(startPos), 0); err != nil {\n\t\treturn err\n\t}\n\tr.r = &r.lr\n\tr.lr.R = r.f\n\tr.lr.N = int64(endPos - startPos + 1)\n\treturn nil\n}\n\nfunc (r *bigFileReader) Read(p []byte) (int, error) {\n\treturn r.r.Read(p)\n}\n\nfunc (r *bigFileReader) WriteTo(w io.Writer) (int64, error) {\n\tif rf, ok := w.(io.ReaderFrom); ok {\n\t\t// fast path. Senfile must be triggered\n\t\treturn rf.ReadFrom(r.r)\n\t}\n\n\t// slow path\n\treturn copyZeroAlloc(w, r.r)\n}\n\nfunc (r *bigFileReader) Close() error {\n\tr.r = r.f\n\tn, err := r.f.Seek(0, 0)\n\tif err == nil {\n\t\tif n != 0 {\n\t\t\tpanic(\"BUG: File.Seek(0,0) returned (non-zero, nil)\")\n\t\t}\n\n\t\tff := r.ff\n\t\tff.bigFilesLock.Lock()\n\t\tff.bigFiles = append(ff.bigFiles, r)\n\t\tff.bigFilesLock.Unlock()\n\t} else {\n\t\tr.f.Close()\n\t}\n\tr.ff.decReadersCount()\n\treturn err\n}\n\ntype fsSmallFileReader struct {\n\tff       *fsFile\n\tstartPos int\n\tendPos   int\n}\n\nfunc (r *fsSmallFileReader) Close() error {\n\tff := r.ff\n\tff.decReadersCount()\n\tr.ff = nil\n\tr.startPos = 0\n\tr.endPos = 0\n\tff.h.smallFileReaderPool.Put(r)\n\treturn nil\n}\n\nfunc (r *fsSmallFileReader) UpdateByteRange(startPos, endPos int) error {\n\tr.startPos = startPos\n\tr.endPos = endPos + 1\n\treturn nil\n}\n\nfunc (r *fsSmallFileReader) Read(p []byte) (int, error) {\n\ttailLen := r.endPos - r.startPos\n\tif tailLen <= 0 {\n\t\treturn 0, io.EOF\n\t}\n\tif len(p) > tailLen {\n\t\tp = p[:tailLen]\n\t}\n\n\tff := r.ff\n\tif ff.f != nil {\n\t\tn, err := ff.f.ReadAt(p, int64(r.startPos))\n\t\tr.startPos += n\n\t\treturn n, err\n\t}\n\n\tn := copy(p, ff.dirIndex[r.startPos:])\n\tr.startPos += n\n\treturn n, nil\n}\n\nfunc (r *fsSmallFileReader) WriteTo(w io.Writer) (int64, error) {\n\tff := r.ff\n\n\tvar n int\n\tvar err error\n\tif ff.f == nil {\n\t\tn, err = w.Write(ff.dirIndex[r.startPos:r.endPos])\n\t\treturn int64(n), err\n\t}\n\n\tif rf, ok := w.(io.ReaderFrom); ok {\n\t\treturn rf.ReadFrom(r)\n\t}\n\n\tcurPos := r.startPos\n\tbufv := copyBufPool.Get()\n\tbuf := bufv.([]byte)\n\tfor err == nil {\n\t\ttailLen := r.endPos - curPos\n\t\tif tailLen <= 0 {\n\t\t\tbreak\n\t\t}\n\t\tif len(buf) > tailLen {\n\t\t\tbuf = buf[:tailLen]\n\t\t}\n\t\tn, err = ff.f.ReadAt(buf, int64(curPos))\n\t\tnw, errw := w.Write(buf[:n])\n\t\tcurPos += nw\n\t\tif errw == nil && nw != n {\n\t\t\tpanic(\"BUG: Write(p) returned (n, nil), where n != len(p)\")\n\t\t}\n\t\tif err == nil {\n\t\t\terr = errw\n\t\t}\n\t}\n\tcopyBufPool.Put(bufv)\n\n\tif err == io.EOF {\n\t\terr = nil\n\t}\n\treturn int64(curPos - r.startPos), err\n}\n\nfunc (h *fsHandler) cleanCache(pendingFiles []*fsFile) []*fsFile {\n\tvar filesToRelease []*fsFile\n\n\th.cacheLock.Lock()\n\n\t// Close files which couldn't be closed before due to non-zero\n\t// readers count on the previous run.\n\tvar remainingFiles []*fsFile\n\tfor _, ff := range pendingFiles {\n\t\tif ff.readersCount > 0 {\n\t\t\tremainingFiles = append(remainingFiles, ff)\n\t\t} else {\n\t\t\tfilesToRelease = append(filesToRelease, ff)\n\t\t}\n\t}\n\tpendingFiles = remainingFiles\n\n\tpendingFiles, filesToRelease = cleanCacheNolock(h.cache, pendingFiles, filesToRelease, h.cacheDuration)\n\tpendingFiles, filesToRelease = cleanCacheNolock(h.cacheBrotli, pendingFiles, filesToRelease, h.cacheDuration)\n\tpendingFiles, filesToRelease = cleanCacheNolock(h.cacheGzip, pendingFiles, filesToRelease, h.cacheDuration)\n\n\th.cacheLock.Unlock()\n\n\tfor _, ff := range filesToRelease {\n\t\tff.Release()\n\t}\n\n\treturn pendingFiles\n}\n\nfunc cleanCacheNolock(cache map[string]*fsFile, pendingFiles, filesToRelease []*fsFile, cacheDuration time.Duration) ([]*fsFile, []*fsFile) {\n\tt := time.Now()\n\tfor k, ff := range cache {\n\t\tif t.Sub(ff.t) > cacheDuration {\n\t\t\tif ff.readersCount > 0 {\n\t\t\t\t// There are pending readers on stale file handle,\n\t\t\t\t// so we cannot close it. Put it into pendingFiles\n\t\t\t\t// so it will be closed later.\n\t\t\t\tpendingFiles = append(pendingFiles, ff)\n\t\t\t} else {\n\t\t\t\tfilesToRelease = append(filesToRelease, ff)\n\t\t\t}\n\t\t\tdelete(cache, k)\n\t\t}\n\t}\n\treturn pendingFiles, filesToRelease\n}\n\nfunc (h *fsHandler) handleRequest(ctx *RequestCtx) {\n\tvar path []byte\n\tif h.pathRewrite != nil {\n\t\tpath = h.pathRewrite(ctx)\n\t} else {\n\t\tpath = ctx.Path()\n\t}\n\thasTrailingSlash := len(path) > 0 && path[len(path)-1] == '/'\n\tpath = stripTrailingSlashes(path)\n\n\tif n := bytes.IndexByte(path, 0); n >= 0 {\n\t\tctx.Logger().Printf(\"cannot serve path with nil byte at position %d: %q\", n, path)\n\t\tctx.Error(\"Are you a hacker?\", StatusBadRequest)\n\t\treturn\n\t}\n\tif h.pathRewrite != nil {\n\t\t// There is no need to check for '/../' if path = ctx.Path(),\n\t\t// since ctx.Path must normalize and sanitize the path.\n\n\t\tif n := bytes.Index(path, strSlashDotDotSlash); n >= 0 {\n\t\t\tctx.Logger().Printf(\"cannot serve path with '/../' at position %d due to security reasons: %q\", n, path)\n\t\t\tctx.Error(\"Internal Server Error\", StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t}\n\n\tmustCompress := false\n\tfileCache := h.cache\n\tfileEncoding := \"\"\n\tbyteRange := ctx.Request.Header.peek(strRange)\n\tif len(byteRange) == 0 && h.compress {\n\t\tif h.compressBrotli && ctx.Request.Header.HasAcceptEncodingBytes(strBr) {\n\t\t\tmustCompress = true\n\t\t\tfileCache = h.cacheBrotli\n\t\t\tfileEncoding = \"br\"\n\t\t} else if ctx.Request.Header.HasAcceptEncodingBytes(strGzip) {\n\t\t\tmustCompress = true\n\t\t\tfileCache = h.cacheGzip\n\t\t\tfileEncoding = \"gzip\"\n\t\t}\n\t}\n\n\th.cacheLock.Lock()\n\tff, ok := fileCache[string(path)]\n\tif ok {\n\t\tff.readersCount++\n\t}\n\th.cacheLock.Unlock()\n\n\tif !ok {\n\t\tpathStr := string(path)\n\t\tfilePath := h.root + pathStr\n\t\tvar err error\n\t\tff, err = h.openFSFile(filePath, mustCompress, fileEncoding)\n\t\tif mustCompress && err == errNoCreatePermission {\n\t\t\tctx.Logger().Printf(\"insufficient permissions for saving compressed file for %q. Serving uncompressed file. \"+\n\t\t\t\t\"Allow write access to the directory with this file in order to improve fasthttp performance\", filePath)\n\t\t\tmustCompress = false\n\t\t\tff, err = h.openFSFile(filePath, mustCompress, fileEncoding)\n\t\t}\n\t\tif err == errDirIndexRequired {\n\t\t\tif !hasTrailingSlash {\n\t\t\t\tctx.RedirectBytes(append(path, '/'), StatusFound)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tff, err = h.openIndexFile(ctx, filePath, mustCompress, fileEncoding)\n\t\t\tif err != nil {\n\t\t\t\tctx.Logger().Printf(\"cannot open dir index %q: %s\", filePath, err)\n\t\t\t\tctx.Error(\"Directory index is forbidden\", StatusForbidden)\n\t\t\t\treturn\n\t\t\t}\n\t\t} else if err != nil {\n\t\t\tctx.Logger().Printf(\"cannot open file %q: %s\", filePath, err)\n\t\t\tif h.pathNotFound == nil {\n\t\t\t\tctx.Error(\"Cannot open requested path\", StatusNotFound)\n\t\t\t} else {\n\t\t\t\tctx.SetStatusCode(StatusNotFound)\n\t\t\t\th.pathNotFound(ctx)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\th.cacheLock.Lock()\n\t\tff1, ok := fileCache[pathStr]\n\t\tif !ok {\n\t\t\tfileCache[pathStr] = ff\n\t\t\tff.readersCount++\n\t\t} else {\n\t\t\tff1.readersCount++\n\t\t}\n\t\th.cacheLock.Unlock()\n\n\t\tif ok {\n\t\t\t// The file has been already opened by another\n\t\t\t// goroutine, so close the current file and use\n\t\t\t// the file opened by another goroutine instead.\n\t\t\tff.Release()\n\t\t\tff = ff1\n\t\t}\n\t}\n\n\tif !ctx.IfModifiedSince(ff.lastModified) {\n\t\tff.decReadersCount()\n\t\tctx.NotModified()\n\t\treturn\n\t}\n\n\tr, err := ff.NewReader()\n\tif err != nil {\n\t\tctx.Logger().Printf(\"cannot obtain file reader for path=%q: %s\", path, err)\n\t\tctx.Error(\"Internal Server Error\", StatusInternalServerError)\n\t\treturn\n\t}\n\n\thdr := &ctx.Response.Header\n\tif ff.compressed {\n\t\tif fileEncoding == \"br\" {\n\t\t\thdr.SetCanonical(strContentEncoding, strBr)\n\t\t} else if fileEncoding == \"gzip\" {\n\t\t\thdr.SetCanonical(strContentEncoding, strGzip)\n\t\t}\n\t}\n\n\tstatusCode := StatusOK\n\tcontentLength := ff.contentLength\n\tif h.acceptByteRange {\n\t\thdr.SetCanonical(strAcceptRanges, strBytes)\n\t\tif len(byteRange) > 0 {\n\t\t\tstartPos, endPos, err := ParseByteRange(byteRange, contentLength)\n\t\t\tif err != nil {\n\t\t\t\tr.(io.Closer).Close()\n\t\t\t\tctx.Logger().Printf(\"cannot parse byte range %q for path=%q: %s\", byteRange, path, err)\n\t\t\t\tctx.Error(\"Range Not Satisfiable\", StatusRequestedRangeNotSatisfiable)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif err = r.(byteRangeUpdater).UpdateByteRange(startPos, endPos); err != nil {\n\t\t\t\tr.(io.Closer).Close()\n\t\t\t\tctx.Logger().Printf(\"cannot seek byte range %q for path=%q: %s\", byteRange, path, err)\n\t\t\t\tctx.Error(\"Internal Server Error\", StatusInternalServerError)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\thdr.SetContentRange(startPos, endPos, contentLength)\n\t\t\tcontentLength = endPos - startPos + 1\n\t\t\tstatusCode = StatusPartialContent\n\t\t}\n\t}\n\n\thdr.SetCanonical(strLastModified, ff.lastModifiedStr)\n\tif !ctx.IsHead() {\n\t\tctx.SetBodyStream(r, contentLength)\n\t} else {\n\t\tctx.Response.ResetBody()\n\t\tctx.Response.SkipBody = true\n\t\tctx.Response.Header.SetContentLength(contentLength)\n\t\tif rc, ok := r.(io.Closer); ok {\n\t\t\tif err := rc.Close(); err != nil {\n\t\t\t\tctx.Logger().Printf(\"cannot close file reader: %s\", err)\n\t\t\t\tctx.Error(\"Internal Server Error\", StatusInternalServerError)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\thdr.noDefaultContentType = true\n\tif len(hdr.ContentType()) == 0 {\n\t\tctx.SetContentType(ff.contentType)\n\t}\n\tctx.SetStatusCode(statusCode)\n}\n\ntype byteRangeUpdater interface {\n\tUpdateByteRange(startPos, endPos int) error\n}\n\n// ParseByteRange parses 'Range: bytes=...' header value.\n//\n// It follows https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.35 .\nfunc ParseByteRange(byteRange []byte, contentLength int) (startPos, endPos int, err error) {\n\tb := byteRange\n\tif !bytes.HasPrefix(b, strBytes) {\n\t\treturn 0, 0, fmt.Errorf(\"unsupported range units: %q. Expecting %q\", byteRange, strBytes)\n\t}\n\n\tb = b[len(strBytes):]\n\tif len(b) == 0 || b[0] != '=' {\n\t\treturn 0, 0, fmt.Errorf(\"missing byte range in %q\", byteRange)\n\t}\n\tb = b[1:]\n\n\tn := bytes.IndexByte(b, '-')\n\tif n < 0 {\n\t\treturn 0, 0, fmt.Errorf(\"missing the end position of byte range in %q\", byteRange)\n\t}\n\n\tif n == 0 {\n\t\tv, err := ParseUint(b[n+1:])\n\t\tif err != nil {\n\t\t\treturn 0, 0, err\n\t\t}\n\t\tstartPos := contentLength - v\n\t\tif startPos < 0 {\n\t\t\tstartPos = 0\n\t\t}\n\t\treturn startPos, contentLength - 1, nil\n\t}\n\n\tif startPos, err = ParseUint(b[:n]); err != nil {\n\t\treturn 0, 0, err\n\t}\n\tif startPos >= contentLength {\n\t\treturn 0, 0, fmt.Errorf(\"the start position of byte range cannot exceed %d. byte range %q\", contentLength-1, byteRange)\n\t}\n\n\tb = b[n+1:]\n\tif len(b) == 0 {\n\t\treturn startPos, contentLength - 1, nil\n\t}\n\n\tif endPos, err = ParseUint(b); err != nil {\n\t\treturn 0, 0, err\n\t}\n\tif endPos >= contentLength {\n\t\tendPos = contentLength - 1\n\t}\n\tif endPos < startPos {\n\t\treturn 0, 0, fmt.Errorf(\"the start position of byte range cannot exceed the end position. byte range %q\", byteRange)\n\t}\n\treturn startPos, endPos, nil\n}\n\nfunc (h *fsHandler) openIndexFile(ctx *RequestCtx, dirPath string, mustCompress bool, fileEncoding string) (*fsFile, error) {\n\tfor _, indexName := range h.indexNames {\n\t\tindexFilePath := dirPath + \"/\" + indexName\n\t\tff, err := h.openFSFile(indexFilePath, mustCompress, fileEncoding)\n\t\tif err == nil {\n\t\t\treturn ff, nil\n\t\t}\n\t\tif !os.IsNotExist(err) {\n\t\t\treturn nil, fmt.Errorf(\"cannot open file %q: %w\", indexFilePath, err)\n\t\t}\n\t}\n\n\tif !h.generateIndexPages {\n\t\treturn nil, fmt.Errorf(\"cannot access directory without index page. Directory %q\", dirPath)\n\t}\n\n\treturn h.createDirIndex(ctx.URI(), dirPath, mustCompress, fileEncoding)\n}\n\nvar (\n\terrDirIndexRequired   = errors.New(\"directory index required\")\n\terrNoCreatePermission = errors.New(\"no 'create file' permissions\")\n)\n\nfunc (h *fsHandler) createDirIndex(base *URI, dirPath string, mustCompress bool, fileEncoding string) (*fsFile, error) {\n\tw := &bytebufferpool.ByteBuffer{}\n\n\tbasePathEscaped := html.EscapeString(string(base.Path()))\n\tfmt.Fprintf(w, \"<html><head><title>%s</title><style>.dir { font-weight: bold }</style></head><body>\", basePathEscaped)\n\tfmt.Fprintf(w, \"<h1>%s</h1>\", basePathEscaped)\n\tfmt.Fprintf(w, \"<ul>\")\n\n\tif len(basePathEscaped) > 1 {\n\t\tvar parentURI URI\n\t\tbase.CopyTo(&parentURI)\n\t\tparentURI.Update(string(base.Path()) + \"/..\")\n\t\tparentPathEscaped := html.EscapeString(string(parentURI.Path()))\n\t\tfmt.Fprintf(w, `<li><a href=\"%s\" class=\"dir\">..</a></li>`, parentPathEscaped)\n\t}\n\n\tf, err := os.Open(dirPath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfileinfos, err := f.Readdir(0)\n\tf.Close()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfm := make(map[string]os.FileInfo, len(fileinfos))\n\tfilenames := make([]string, 0, len(fileinfos))\nnestedContinue:\n\tfor _, fi := range fileinfos {\n\t\tname := fi.Name()\n\t\tfor _, cfs := range h.compressedFileSuffixes {\n\t\t\tif strings.HasSuffix(name, cfs) {\n\t\t\t\t// Do not show compressed files on index page.\n\t\t\t\tcontinue nestedContinue\n\t\t\t}\n\t\t}\n\t\tfm[name] = fi\n\t\tfilenames = append(filenames, name)\n\t}\n\n\tvar u URI\n\tbase.CopyTo(&u)\n\tu.Update(string(u.Path()) + \"/\")\n\n\tsort.Strings(filenames)\n\tfor _, name := range filenames {\n\t\tu.Update(name)\n\t\tpathEscaped := html.EscapeString(string(u.Path()))\n\t\tfi := fm[name]\n\t\tauxStr := \"dir\"\n\t\tclassName := \"dir\"\n\t\tif !fi.IsDir() {\n\t\t\tauxStr = fmt.Sprintf(\"file, %d bytes\", fi.Size())\n\t\t\tclassName = \"file\"\n\t\t}\n\t\tfmt.Fprintf(w, `<li><a href=\"%s\" class=\"%s\">%s</a>, %s, last modified %s</li>`,\n\t\t\tpathEscaped, className, html.EscapeString(name), auxStr, fsModTime(fi.ModTime()))\n\t}\n\n\tfmt.Fprintf(w, \"</ul></body></html>\")\n\n\tif mustCompress {\n\t\tvar zbuf bytebufferpool.ByteBuffer\n\t\tif fileEncoding == \"br\" {\n\t\t\tzbuf.B = AppendBrotliBytesLevel(zbuf.B, w.B, CompressDefaultCompression)\n\t\t} else if fileEncoding == \"gzip\" {\n\t\t\tzbuf.B = AppendGzipBytesLevel(zbuf.B, w.B, CompressDefaultCompression)\n\t\t}\n\t\tw = &zbuf\n\t}\n\n\tdirIndex := w.B\n\tlastModified := time.Now()\n\tff := &fsFile{\n\t\th:               h,\n\t\tdirIndex:        dirIndex,\n\t\tcontentType:     \"text/html; charset=utf-8\",\n\t\tcontentLength:   len(dirIndex),\n\t\tcompressed:      mustCompress,\n\t\tlastModified:    lastModified,\n\t\tlastModifiedStr: AppendHTTPDate(nil, lastModified),\n\n\t\tt: lastModified,\n\t}\n\treturn ff, nil\n}\n\nconst (\n\tfsMinCompressRatio        = 0.8\n\tfsMaxCompressibleFileSize = 8 * 1024 * 1024\n)\n\nfunc (h *fsHandler) compressAndOpenFSFile(filePath string, fileEncoding string) (*fsFile, error) {\n\tf, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfileInfo, err := f.Stat()\n\tif err != nil {\n\t\tf.Close()\n\t\treturn nil, fmt.Errorf(\"cannot obtain info for file %q: %w\", filePath, err)\n\t}\n\n\tif fileInfo.IsDir() {\n\t\tf.Close()\n\t\treturn nil, errDirIndexRequired\n\t}\n\n\tif strings.HasSuffix(filePath, h.compressedFileSuffixes[fileEncoding]) ||\n\t\tfileInfo.Size() > fsMaxCompressibleFileSize ||\n\t\t!isFileCompressible(f, fsMinCompressRatio) {\n\t\treturn h.newFSFile(f, fileInfo, false, \"\")\n\t}\n\n\tcompressedFilePath := filePath + h.compressedFileSuffixes[fileEncoding]\n\tabsPath, err := filepath.Abs(compressedFilePath)\n\tif err != nil {\n\t\tf.Close()\n\t\treturn nil, fmt.Errorf(\"cannot determine absolute path for %q: %s\", compressedFilePath, err)\n\t}\n\n\tflock := getFileLock(absPath)\n\tflock.Lock()\n\tff, err := h.compressFileNolock(f, fileInfo, filePath, compressedFilePath, fileEncoding)\n\tflock.Unlock()\n\n\treturn ff, err\n}\n\nfunc (h *fsHandler) compressFileNolock(f *os.File, fileInfo os.FileInfo, filePath, compressedFilePath string, fileEncoding string) (*fsFile, error) {\n\t// Attempt to open compressed file created by another concurrent\n\t// goroutine.\n\t// It is safe opening such a file, since the file creation\n\t// is guarded by file mutex - see getFileLock call.\n\tif _, err := os.Stat(compressedFilePath); err == nil {\n\t\tf.Close()\n\t\treturn h.newCompressedFSFile(compressedFilePath, fileEncoding)\n\t}\n\n\t// Create temporary file, so concurrent goroutines don't use\n\t// it until it is created.\n\ttmpFilePath := compressedFilePath + \".tmp\"\n\tzf, err := os.Create(tmpFilePath)\n\tif err != nil {\n\t\tf.Close()\n\t\tif !os.IsPermission(err) {\n\t\t\treturn nil, fmt.Errorf(\"cannot create temporary file %q: %w\", tmpFilePath, err)\n\t\t}\n\t\treturn nil, errNoCreatePermission\n\t}\n\tif fileEncoding == \"br\" {\n\t\tzw := acquireStacklessBrotliWriter(zf, CompressDefaultCompression)\n\t\t_, err = copyZeroAlloc(zw, f)\n\t\tif err1 := zw.Flush(); err == nil {\n\t\t\terr = err1\n\t\t}\n\t\treleaseStacklessBrotliWriter(zw, CompressDefaultCompression)\n\t} else if fileEncoding == \"gzip\" {\n\t\tzw := acquireStacklessGzipWriter(zf, CompressDefaultCompression)\n\t\t_, err = copyZeroAlloc(zw, f)\n\t\tif err1 := zw.Flush(); err == nil {\n\t\t\terr = err1\n\t\t}\n\t\treleaseStacklessGzipWriter(zw, CompressDefaultCompression)\n\t}\n\tzf.Close()\n\tf.Close()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error when compressing file %q to %q: %w\", filePath, tmpFilePath, err)\n\t}\n\tif err = os.Chtimes(tmpFilePath, time.Now(), fileInfo.ModTime()); err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot change modification time to %s for tmp file %q: %s\",\n\t\t\tfileInfo.ModTime(), tmpFilePath, err)\n\t}\n\tif err = os.Rename(tmpFilePath, compressedFilePath); err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot move compressed file from %q to %q: %w\", tmpFilePath, compressedFilePath, err)\n\t}\n\treturn h.newCompressedFSFile(compressedFilePath, fileEncoding)\n}\n\nfunc (h *fsHandler) newCompressedFSFile(filePath string, fileEncoding string) (*fsFile, error) {\n\tf, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot open compressed file %q: %w\", filePath, err)\n\t}\n\tfileInfo, err := f.Stat()\n\tif err != nil {\n\t\tf.Close()\n\t\treturn nil, fmt.Errorf(\"cannot obtain info for compressed file %q: %w\", filePath, err)\n\t}\n\treturn h.newFSFile(f, fileInfo, true, fileEncoding)\n}\n\nfunc (h *fsHandler) openFSFile(filePath string, mustCompress bool, fileEncoding string) (*fsFile, error) {\n\tfilePathOriginal := filePath\n\tif mustCompress {\n\t\tfilePath += h.compressedFileSuffixes[fileEncoding]\n\t}\n\n\tf, err := os.Open(filePath)\n\tif err != nil {\n\t\tif mustCompress && os.IsNotExist(err) {\n\t\t\treturn h.compressAndOpenFSFile(filePathOriginal, fileEncoding)\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tfileInfo, err := f.Stat()\n\tif err != nil {\n\t\tf.Close()\n\t\treturn nil, fmt.Errorf(\"cannot obtain info for file %q: %w\", filePath, err)\n\t}\n\n\tif fileInfo.IsDir() {\n\t\tf.Close()\n\t\tif mustCompress {\n\t\t\treturn nil, fmt.Errorf(\"directory with unexpected suffix found: %q. Suffix: %q\",\n\t\t\t\tfilePath, h.compressedFileSuffixes[fileEncoding])\n\t\t}\n\t\treturn nil, errDirIndexRequired\n\t}\n\n\tif mustCompress {\n\t\tfileInfoOriginal, err := os.Stat(filePathOriginal)\n\t\tif err != nil {\n\t\t\tf.Close()\n\t\t\treturn nil, fmt.Errorf(\"cannot obtain info for original file %q: %w\", filePathOriginal, err)\n\t\t}\n\n\t\t// Only re-create the compressed file if there was more than a second between the mod times.\n\t\t// On MacOS the gzip seems to truncate the nanoseconds in the mod time causing the original file\n\t\t// to look newer than the gzipped file.\n\t\tif fileInfoOriginal.ModTime().Sub(fileInfo.ModTime()) >= time.Second {\n\t\t\t// The compressed file became stale. Re-create it.\n\t\t\tf.Close()\n\t\t\tos.Remove(filePath)\n\t\t\treturn h.compressAndOpenFSFile(filePathOriginal, fileEncoding)\n\t\t}\n\t}\n\n\treturn h.newFSFile(f, fileInfo, mustCompress, fileEncoding)\n}\n\nfunc (h *fsHandler) newFSFile(f *os.File, fileInfo os.FileInfo, compressed bool, fileEncoding string) (*fsFile, error) {\n\tn := fileInfo.Size()\n\tcontentLength := int(n)\n\tif n != int64(contentLength) {\n\t\tf.Close()\n\t\treturn nil, fmt.Errorf(\"too big file: %d bytes\", n)\n\t}\n\n\t// detect content-type\n\text := fileExtension(fileInfo.Name(), compressed, h.compressedFileSuffixes[fileEncoding])\n\tcontentType := mime.TypeByExtension(ext)\n\tif len(contentType) == 0 {\n\t\tdata, err := readFileHeader(f, compressed, fileEncoding)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"cannot read header of the file %q: %w\", f.Name(), err)\n\t\t}\n\t\tcontentType = http.DetectContentType(data)\n\t}\n\n\tlastModified := fileInfo.ModTime()\n\tff := &fsFile{\n\t\th:               h,\n\t\tf:               f,\n\t\tcontentType:     contentType,\n\t\tcontentLength:   contentLength,\n\t\tcompressed:      compressed,\n\t\tlastModified:    lastModified,\n\t\tlastModifiedStr: AppendHTTPDate(nil, lastModified),\n\n\t\tt: time.Now(),\n\t}\n\treturn ff, nil\n}\n\nfunc readFileHeader(f *os.File, compressed bool, fileEncoding string) ([]byte, error) {\n\tr := io.Reader(f)\n\tvar (\n\t\tbr *brotli.Reader\n\t\tzr *gzip.Reader\n\t)\n\tif compressed {\n\t\tvar err error\n\t\tif fileEncoding == \"br\" {\n\t\t\tif br, err = acquireBrotliReader(f); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tr = br\n\t\t} else if fileEncoding == \"gzip\" {\n\t\t\tif zr, err = acquireGzipReader(f); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tr = zr\n\t\t}\n\t}\n\n\tlr := &io.LimitedReader{\n\t\tR: r,\n\t\tN: 512,\n\t}\n\tdata, err := ioutil.ReadAll(lr)\n\tif _, err := f.Seek(0, 0); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif br != nil {\n\t\treleaseBrotliReader(br)\n\t}\n\n\tif zr != nil {\n\t\treleaseGzipReader(zr)\n\t}\n\n\treturn data, err\n}\n\nfunc stripLeadingSlashes(path []byte, stripSlashes int) []byte {\n\tfor stripSlashes > 0 && len(path) > 0 {\n\t\tif path[0] != '/' {\n\t\t\tpanic(\"BUG: path must start with slash\")\n\t\t}\n\t\tn := bytes.IndexByte(path[1:], '/')\n\t\tif n < 0 {\n\t\t\tpath = path[:0]\n\t\t\tbreak\n\t\t}\n\t\tpath = path[n+1:]\n\t\tstripSlashes--\n\t}\n\treturn path\n}\n\nfunc stripTrailingSlashes(path []byte) []byte {\n\tfor len(path) > 0 && path[len(path)-1] == '/' {\n\t\tpath = path[:len(path)-1]\n\t}\n\treturn path\n}\n\nfunc fileExtension(path string, compressed bool, compressedFileSuffix string) string {\n\tif compressed && strings.HasSuffix(path, compressedFileSuffix) {\n\t\tpath = path[:len(path)-len(compressedFileSuffix)]\n\t}\n\tn := strings.LastIndexByte(path, '.')\n\tif n < 0 {\n\t\treturn \"\"\n\t}\n\treturn path[n:]\n}\n\n// FileLastModified returns last modified time for the file.\nfunc FileLastModified(path string) (time.Time, error) {\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn zeroTime, err\n\t}\n\tfileInfo, err := f.Stat()\n\tf.Close()\n\tif err != nil {\n\t\treturn zeroTime, err\n\t}\n\treturn fsModTime(fileInfo.ModTime()), nil\n}\n\nfunc fsModTime(t time.Time) time.Time {\n\treturn t.In(time.UTC).Truncate(time.Second)\n}\n\nvar filesLockMap sync.Map\n\nfunc getFileLock(absPath string) *sync.Mutex {\n\tv, _ := filesLockMap.LoadOrStore(absPath, &sync.Mutex{})\n\tfilelock := v.(*sync.Mutex)\n\treturn filelock\n}\n", "package fasthttp\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"crypto/tls\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"mime/multipart\"\n\t\"net\"\n\t\"os\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n)\n\nvar errNoCertOrKeyProvided = errors.New(\"cert or key has not provided\")\n\nvar (\n\t// ErrAlreadyServing is returned when calling Serve on a Server\n\t// that is already serving connections.\n\tErrAlreadyServing = errors.New(\"Server is already serving connections\")\n)\n\n// ServeConn serves HTTP requests from the given connection\n// using the given handler.\n//\n// ServeConn returns nil if all requests from the c are successfully served.\n// It returns non-nil error otherwise.\n//\n// Connection c must immediately propagate all the data passed to Write()\n// to the client. Otherwise requests' processing may hang.\n//\n// ServeConn closes c before returning.\nfunc ServeConn(c net.Conn, handler RequestHandler) error {\n\tv := serverPool.Get()\n\tif v == nil {\n\t\tv = &Server{}\n\t}\n\ts := v.(*Server)\n\ts.Handler = handler\n\terr := s.ServeConn(c)\n\ts.Handler = nil\n\tserverPool.Put(v)\n\treturn err\n}\n\nvar serverPool sync.Pool\n\n// Serve serves incoming connections from the given listener\n// using the given handler.\n//\n// Serve blocks until the given listener returns permanent error.\nfunc Serve(ln net.Listener, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.Serve(ln)\n}\n\n// ServeTLS serves HTTPS requests from the given net.Listener\n// using the given handler.\n//\n// certFile and keyFile are paths to TLS certificate and key files.\nfunc ServeTLS(ln net.Listener, certFile, keyFile string, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ServeTLS(ln, certFile, keyFile)\n}\n\n// ServeTLSEmbed serves HTTPS requests from the given net.Listener\n// using the given handler.\n//\n// certData and keyData must contain valid TLS certificate and key data.\nfunc ServeTLSEmbed(ln net.Listener, certData, keyData []byte, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ServeTLSEmbed(ln, certData, keyData)\n}\n\n// ListenAndServe serves HTTP requests from the given TCP addr\n// using the given handler.\nfunc ListenAndServe(addr string, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ListenAndServe(addr)\n}\n\n// ListenAndServeUNIX serves HTTP requests from the given UNIX addr\n// using the given handler.\n//\n// The function deletes existing file at addr before starting serving.\n//\n// The server sets the given file mode for the UNIX addr.\nfunc ListenAndServeUNIX(addr string, mode os.FileMode, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ListenAndServeUNIX(addr, mode)\n}\n\n// ListenAndServeTLS serves HTTPS requests from the given TCP addr\n// using the given handler.\n//\n// certFile and keyFile are paths to TLS certificate and key files.\nfunc ListenAndServeTLS(addr, certFile, keyFile string, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ListenAndServeTLS(addr, certFile, keyFile)\n}\n\n// ListenAndServeTLSEmbed serves HTTPS requests from the given TCP addr\n// using the given handler.\n//\n// certData and keyData must contain valid TLS certificate and key data.\nfunc ListenAndServeTLSEmbed(addr string, certData, keyData []byte, handler RequestHandler) error {\n\ts := &Server{\n\t\tHandler: handler,\n\t}\n\treturn s.ListenAndServeTLSEmbed(addr, certData, keyData)\n}\n\n// RequestHandler must process incoming requests.\n//\n// RequestHandler must call ctx.TimeoutError() before returning\n// if it keeps references to ctx and/or its' members after the return.\n// Consider wrapping RequestHandler into TimeoutHandler if response time\n// must be limited.\ntype RequestHandler func(ctx *RequestCtx)\n\n// ServeHandler must process tls.Config.NextProto negotiated requests.\ntype ServeHandler func(c net.Conn) error\n\n// Server implements HTTP server.\n//\n// Default Server settings should satisfy the majority of Server users.\n// Adjust Server settings only if you really understand the consequences.\n//\n// It is forbidden copying Server instances. Create new Server instances\n// instead.\n//\n// It is safe to call Server methods from concurrently running goroutines.\ntype Server struct {\n\tnoCopy noCopy //nolint:unused,structcheck\n\n\t// Handler for processing incoming requests.\n\t//\n\t// Take into account that no `panic` recovery is done by `fasthttp` (thus any `panic` will take down the entire server).\n\t// Instead the user should use `recover` to handle these situations.\n\tHandler RequestHandler\n\n\t// ErrorHandler for returning a response in case of an error while receiving or parsing the request.\n\t//\n\t// The following is a non-exhaustive list of errors that can be expected as argument:\n\t//   * io.EOF\n\t//   * io.ErrUnexpectedEOF\n\t//   * ErrGetOnly\n\t//   * ErrSmallBuffer\n\t//   * ErrBodyTooLarge\n\t//   * ErrBrokenChunks\n\tErrorHandler func(ctx *RequestCtx, err error)\n\n\t// HeaderReceived is called after receiving the header\n\t//\n\t// non zero RequestConfig field values will overwrite the default configs\n\tHeaderReceived func(header *RequestHeader) RequestConfig\n\n\t// ContinueHandler is called after receiving the Expect 100 Continue Header\n\t//\n\t// https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.2.3\n\t// https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.1.1\n\t// Using ContinueHandler a server can make decisioning on whether or not\n\t// to read a potentially large request body based on the headers\n\t//\n\t// The default is to automatically read request bodies of Expect 100 Continue requests\n\t// like they are normal requests\n\tContinueHandler func(header *RequestHeader) bool\n\n\t// Server name for sending in response headers.\n\t//\n\t// Default server name is used if left blank.\n\tName string\n\n\t// The maximum number of concurrent connections the server may serve.\n\t//\n\t// DefaultConcurrency is used if not set.\n\t//\n\t// Concurrency only works if you either call Serve once, or only ServeConn multiple times.\n\t// It works with ListenAndServe as well.\n\tConcurrency int\n\n\t// Per-connection buffer size for requests' reading.\n\t// This also limits the maximum header size.\n\t//\n\t// Increase this buffer if your clients send multi-KB RequestURIs\n\t// and/or multi-KB headers (for example, BIG cookies).\n\t//\n\t// Default buffer size is used if not set.\n\tReadBufferSize int\n\n\t// Per-connection buffer size for responses' writing.\n\t//\n\t// Default buffer size is used if not set.\n\tWriteBufferSize int\n\n\t// ReadTimeout is the amount of time allowed to read\n\t// the full request including body. The connection's read\n\t// deadline is reset when the connection opens, or for\n\t// keep-alive connections after the first byte has been read.\n\t//\n\t// By default request read timeout is unlimited.\n\tReadTimeout time.Duration\n\n\t// WriteTimeout is the maximum duration before timing out\n\t// writes of the response. It is reset after the request handler\n\t// has returned.\n\t//\n\t// By default response write timeout is unlimited.\n\tWriteTimeout time.Duration\n\n\t// IdleTimeout is the maximum amount of time to wait for the\n\t// next request when keep-alive is enabled. If IdleTimeout\n\t// is zero, the value of ReadTimeout is used.\n\tIdleTimeout time.Duration\n\n\t// Maximum number of concurrent client connections allowed per IP.\n\t//\n\t// By default unlimited number of concurrent connections\n\t// may be established to the server from a single IP address.\n\tMaxConnsPerIP int\n\n\t// Maximum number of requests served per connection.\n\t//\n\t// The server closes connection after the last request.\n\t// 'Connection: close' header is added to the last response.\n\t//\n\t// By default unlimited number of requests may be served per connection.\n\tMaxRequestsPerConn int\n\n\t// MaxKeepaliveDuration is a no-op and only left here for backwards compatibility.\n\t// Deprecated: Use IdleTimeout instead.\n\tMaxKeepaliveDuration time.Duration\n\n\t// MaxIdleWorkerDuration is the maximum idle time of a single worker in the underlying\n\t// worker pool of the Server. Idle workers beyond this time will be cleared.\n\tMaxIdleWorkerDuration time.Duration\n\n\t// Period between tcp keep-alive messages.\n\t//\n\t// TCP keep-alive period is determined by operation system by default.\n\tTCPKeepalivePeriod time.Duration\n\n\t// Maximum request body size.\n\t//\n\t// The server rejects requests with bodies exceeding this limit.\n\t//\n\t// Request body size is limited by DefaultMaxRequestBodySize by default.\n\tMaxRequestBodySize int\n\n\t// Whether to disable keep-alive connections.\n\t//\n\t// The server will close all the incoming connections after sending\n\t// the first response to client if this option is set to true.\n\t//\n\t// By default keep-alive connections are enabled.\n\tDisableKeepalive bool\n\n\t// Whether to enable tcp keep-alive connections.\n\t//\n\t// Whether the operating system should send tcp keep-alive messages on the tcp connection.\n\t//\n\t// By default tcp keep-alive connections are disabled.\n\tTCPKeepalive bool\n\n\t// Aggressively reduces memory usage at the cost of higher CPU usage\n\t// if set to true.\n\t//\n\t// Try enabling this option only if the server consumes too much memory\n\t// serving mostly idle keep-alive connections. This may reduce memory\n\t// usage by more than 50%.\n\t//\n\t// Aggressive memory usage reduction is disabled by default.\n\tReduceMemoryUsage bool\n\n\t// Rejects all non-GET requests if set to true.\n\t//\n\t// This option is useful as anti-DoS protection for servers\n\t// accepting only GET requests. The request size is limited\n\t// by ReadBufferSize if GetOnly is set.\n\t//\n\t// Server accepts all the requests by default.\n\tGetOnly bool\n\n\t// Will not pre parse Multipart Form data if set to true.\n\t//\n\t// This option is useful for servers that desire to treat\n\t// multipart form data as a binary blob, or choose when to parse the data.\n\t//\n\t// Server pre parses multipart form data by default.\n\tDisablePreParseMultipartForm bool\n\n\t// Logs all errors, including the most frequent\n\t// 'connection reset by peer', 'broken pipe' and 'connection timeout'\n\t// errors. Such errors are common in production serving real-world\n\t// clients.\n\t//\n\t// By default the most frequent errors such as\n\t// 'connection reset by peer', 'broken pipe' and 'connection timeout'\n\t// are suppressed in order to limit output log traffic.\n\tLogAllErrors bool\n\n\t// Will not log potentially sensitive content in error logs\n\t//\n\t// This option is useful for servers that handle sensitive data\n\t// in the request/response.\n\t//\n\t// Server logs all full errors by default.\n\tSecureErrorLogMessage bool\n\n\t// Header names are passed as-is without normalization\n\t// if this option is set.\n\t//\n\t// Disabled header names' normalization may be useful only for proxying\n\t// incoming requests to other servers expecting case-sensitive\n\t// header names. See https://github.com/valyala/fasthttp/issues/57\n\t// for details.\n\t//\n\t// By default request and response header names are normalized, i.e.\n\t// The first letter and the first letters following dashes\n\t// are uppercased, while all the other letters are lowercased.\n\t// Examples:\n\t//\n\t//     * HOST -> Host\n\t//     * content-type -> Content-Type\n\t//     * cONTENT-lenGTH -> Content-Length\n\tDisableHeaderNamesNormalizing bool\n\n\t// SleepWhenConcurrencyLimitsExceeded is a duration to be slept of if\n\t// the concurrency limit in exceeded (default [when is 0]: don't sleep\n\t// and accept new connections immediately).\n\tSleepWhenConcurrencyLimitsExceeded time.Duration\n\n\t// NoDefaultServerHeader, when set to true, causes the default Server header\n\t// to be excluded from the Response.\n\t//\n\t// The default Server header value is the value of the Name field or an\n\t// internal default value in its absence. With this option set to true,\n\t// the only time a Server header will be sent is if a non-zero length\n\t// value is explicitly provided during a request.\n\tNoDefaultServerHeader bool\n\n\t// NoDefaultDate, when set to true, causes the default Date\n\t// header to be excluded from the Response.\n\t//\n\t// The default Date header value is the current date value. When\n\t// set to true, the Date will not be present.\n\tNoDefaultDate bool\n\n\t// NoDefaultContentType, when set to true, causes the default Content-Type\n\t// header to be excluded from the Response.\n\t//\n\t// The default Content-Type header value is the internal default value. When\n\t// set to true, the Content-Type will not be present.\n\tNoDefaultContentType bool\n\n\t// KeepHijackedConns is an opt-in disable of connection\n\t// close by fasthttp after connections' HijackHandler returns.\n\t// This allows to save goroutines, e.g. when fasthttp used to upgrade\n\t// http connections to WS and connection goes to another handler,\n\t// which will close it when needed.\n\tKeepHijackedConns bool\n\n\t// CloseOnShutdown when true adds a `Connection: close` header when when the server is shutting down.\n\tCloseOnShutdown bool\n\n\t// StreamRequestBody enables request body streaming,\n\t// and calls the handler sooner when given body is\n\t// larger then the current limit.\n\tStreamRequestBody bool\n\n\t// ConnState specifies an optional callback function that is\n\t// called when a client connection changes state. See the\n\t// ConnState type and associated constants for details.\n\tConnState func(net.Conn, ConnState)\n\n\t// Logger, which is used by RequestCtx.Logger().\n\t//\n\t// By default standard logger from log package is used.\n\tLogger Logger\n\n\t// TLSConfig optionally provides a TLS configuration for use\n\t// by ServeTLS, ServeTLSEmbed, ListenAndServeTLS, ListenAndServeTLSEmbed,\n\t// AppendCert, AppendCertEmbed and NextProto.\n\t//\n\t// Note that this value is cloned by ServeTLS, ServeTLSEmbed, ListenAndServeTLS\n\t// and ListenAndServeTLSEmbed, so it's not possible to modify the configuration\n\t// with methods like tls.Config.SetSessionTicketKeys.\n\t// To use SetSessionTicketKeys, use Server.Serve with a TLS Listener\n\t// instead.\n\tTLSConfig *tls.Config\n\n\tnextProtos map[string]ServeHandler\n\n\tconcurrency      uint32\n\tconcurrencyCh    chan struct{}\n\tperIPConnCounter perIPConnCounter\n\tserverName       atomic.Value\n\n\tctxPool        sync.Pool\n\treaderPool     sync.Pool\n\twriterPool     sync.Pool\n\thijackConnPool sync.Pool\n\n\t// We need to know our listeners and idle connections so we can close them in Shutdown().\n\tln []net.Listener\n\n\tidleConns   map[net.Conn]struct{}\n\tidleConnsMu sync.Mutex\n\n\tmu   sync.Mutex\n\topen int32\n\tstop int32\n\tdone chan struct{}\n}\n\n// TimeoutHandler creates RequestHandler, which returns StatusRequestTimeout\n// error with the given msg to the client if h didn't return during\n// the given duration.\n//\n// The returned handler may return StatusTooManyRequests error with the given\n// msg to the client if there are more than Server.Concurrency concurrent\n// handlers h are running at the moment.\nfunc TimeoutHandler(h RequestHandler, timeout time.Duration, msg string) RequestHandler {\n\treturn TimeoutWithCodeHandler(h, timeout, msg, StatusRequestTimeout)\n}\n\n// TimeoutWithCodeHandler creates RequestHandler, which returns an error with\n// the given msg and status code to the client  if h didn't return during\n// the given duration.\n//\n// The returned handler may return StatusTooManyRequests error with the given\n// msg to the client if there are more than Server.Concurrency concurrent\n// handlers h are running at the moment.\nfunc TimeoutWithCodeHandler(h RequestHandler, timeout time.Duration, msg string, statusCode int) RequestHandler {\n\tif timeout <= 0 {\n\t\treturn h\n\t}\n\n\treturn func(ctx *RequestCtx) {\n\t\tconcurrencyCh := ctx.s.concurrencyCh\n\t\tselect {\n\t\tcase concurrencyCh <- struct{}{}:\n\t\tdefault:\n\t\t\tctx.Error(msg, StatusTooManyRequests)\n\t\t\treturn\n\t\t}\n\n\t\tch := ctx.timeoutCh\n\t\tif ch == nil {\n\t\t\tch = make(chan struct{}, 1)\n\t\t\tctx.timeoutCh = ch\n\t\t}\n\t\tgo func() {\n\t\t\th(ctx)\n\t\t\tch <- struct{}{}\n\t\t\t<-concurrencyCh\n\t\t}()\n\t\tctx.timeoutTimer = initTimer(ctx.timeoutTimer, timeout)\n\t\tselect {\n\t\tcase <-ch:\n\t\tcase <-ctx.timeoutTimer.C:\n\t\t\tctx.TimeoutErrorWithCode(msg, statusCode)\n\t\t}\n\t\tstopTimer(ctx.timeoutTimer)\n\t}\n}\n\n//RequestConfig configure the per request deadline and body limits\ntype RequestConfig struct {\n\t// ReadTimeout is the maximum duration for reading the entire\n\t// request body.\n\t// a zero value means that default values will be honored\n\tReadTimeout time.Duration\n\t// WriteTimeout is the maximum duration before timing out\n\t// writes of the response.\n\t// a zero value means that default values will be honored\n\tWriteTimeout time.Duration\n\t// Maximum request body size.\n\t// a zero value means that default values will be honored\n\tMaxRequestBodySize int\n}\n\n// CompressHandler returns RequestHandler that transparently compresses\n// response body generated by h if the request contains 'gzip' or 'deflate'\n// 'Accept-Encoding' header.\nfunc CompressHandler(h RequestHandler) RequestHandler {\n\treturn CompressHandlerLevel(h, CompressDefaultCompression)\n}\n\n// CompressHandlerLevel returns RequestHandler that transparently compresses\n// response body generated by h if the request contains a 'gzip' or 'deflate'\n// 'Accept-Encoding' header.\n//\n// Level is the desired compression level:\n//\n//     * CompressNoCompression\n//     * CompressBestSpeed\n//     * CompressBestCompression\n//     * CompressDefaultCompression\n//     * CompressHuffmanOnly\nfunc CompressHandlerLevel(h RequestHandler, level int) RequestHandler {\n\treturn func(ctx *RequestCtx) {\n\t\th(ctx)\n\t\tif ctx.Request.Header.HasAcceptEncodingBytes(strGzip) {\n\t\t\tctx.Response.gzipBody(level) //nolint:errcheck\n\t\t} else if ctx.Request.Header.HasAcceptEncodingBytes(strDeflate) {\n\t\t\tctx.Response.deflateBody(level) //nolint:errcheck\n\t\t}\n\t}\n}\n\n// CompressHandlerBrotliLevel returns RequestHandler that transparently compresses\n// response body generated by h if the request contains a 'br', 'gzip' or 'deflate'\n// 'Accept-Encoding' header.\n//\n// brotliLevel is the desired compression level for brotli.\n//\n//     * CompressBrotliNoCompression\n//     * CompressBrotliBestSpeed\n//     * CompressBrotliBestCompression\n//     * CompressBrotliDefaultCompression\n//\n// otherLevel is the desired compression level for gzip and deflate.\n//\n//     * CompressNoCompression\n//     * CompressBestSpeed\n//     * CompressBestCompression\n//     * CompressDefaultCompression\n//     * CompressHuffmanOnly\nfunc CompressHandlerBrotliLevel(h RequestHandler, brotliLevel, otherLevel int) RequestHandler {\n\treturn func(ctx *RequestCtx) {\n\t\th(ctx)\n\t\tif ctx.Request.Header.HasAcceptEncodingBytes(strBr) {\n\t\t\tctx.Response.brotliBody(brotliLevel) //nolint:errcheck\n\t\t} else if ctx.Request.Header.HasAcceptEncodingBytes(strGzip) {\n\t\t\tctx.Response.gzipBody(otherLevel) //nolint:errcheck\n\t\t} else if ctx.Request.Header.HasAcceptEncodingBytes(strDeflate) {\n\t\t\tctx.Response.deflateBody(otherLevel) //nolint:errcheck\n\t\t}\n\t}\n}\n\n// RequestCtx contains incoming request and manages outgoing response.\n//\n// It is forbidden copying RequestCtx instances.\n//\n// RequestHandler should avoid holding references to incoming RequestCtx and/or\n// its' members after the return.\n// If holding RequestCtx references after the return is unavoidable\n// (for instance, ctx is passed to a separate goroutine and ctx lifetime cannot\n// be controlled), then the RequestHandler MUST call ctx.TimeoutError()\n// before return.\n//\n// It is unsafe modifying/reading RequestCtx instance from concurrently\n// running goroutines. The only exception is TimeoutError*, which may be called\n// while other goroutines accessing RequestCtx.\ntype RequestCtx struct {\n\tnoCopy noCopy //nolint:unused,structcheck\n\n\t// Incoming request.\n\t//\n\t// Copying Request by value is forbidden. Use pointer to Request instead.\n\tRequest Request\n\n\t// Outgoing response.\n\t//\n\t// Copying Response by value is forbidden. Use pointer to Response instead.\n\tResponse Response\n\n\tuserValues userData\n\n\tconnID         uint64\n\tconnRequestNum uint64\n\tconnTime       time.Time\n\tremoteAddr     net.Addr\n\n\ttime time.Time\n\n\tlogger ctxLogger\n\ts      *Server\n\tc      net.Conn\n\tfbr    firstByteReader\n\n\ttimeoutResponse *Response\n\ttimeoutCh       chan struct{}\n\ttimeoutTimer    *time.Timer\n\n\thijackHandler    HijackHandler\n\thijackNoResponse bool\n}\n\n// HijackHandler must process the hijacked connection c.\n//\n// If KeepHijackedConns is disabled, which is by default,\n// the connection c is automatically closed after returning from HijackHandler.\n//\n// The connection c must not be used after returning from the handler, if KeepHijackedConns is disabled.\n//\n// When KeepHijackedConns enabled, fasthttp will not Close() the connection,\n// you must do it when you need it. You must not use c in any way after calling Close().\ntype HijackHandler func(c net.Conn)\n\n// Hijack registers the given handler for connection hijacking.\n//\n// The handler is called after returning from RequestHandler\n// and sending http response. The current connection is passed\n// to the handler. The connection is automatically closed after\n// returning from the handler.\n//\n// The server skips calling the handler in the following cases:\n//\n//     * 'Connection: close' header exists in either request or response.\n//     * Unexpected error during response writing to the connection.\n//\n// The server stops processing requests from hijacked connections.\n//\n// Server limits such as Concurrency, ReadTimeout, WriteTimeout, etc.\n// aren't applied to hijacked connections.\n//\n// The handler must not retain references to ctx members.\n//\n// Arbitrary 'Connection: Upgrade' protocols may be implemented\n// with HijackHandler. For instance,\n//\n//     * WebSocket ( https://en.wikipedia.org/wiki/WebSocket )\n//     * HTTP/2.0 ( https://en.wikipedia.org/wiki/HTTP/2 )\n//\nfunc (ctx *RequestCtx) Hijack(handler HijackHandler) {\n\tctx.hijackHandler = handler\n}\n\n// HijackSetNoResponse changes the behavior of hijacking a request.\n// If HijackSetNoResponse is called with false fasthttp will send a response\n// to the client before calling the HijackHandler (default). If HijackSetNoResponse\n// is called with true no response is send back before calling the\n// HijackHandler supplied in the Hijack function.\nfunc (ctx *RequestCtx) HijackSetNoResponse(noResponse bool) {\n\tctx.hijackNoResponse = noResponse\n}\n\n// Hijacked returns true after Hijack is called.\nfunc (ctx *RequestCtx) Hijacked() bool {\n\treturn ctx.hijackHandler != nil\n}\n\n// SetUserValue stores the given value (arbitrary object)\n// under the given key in ctx.\n//\n// The value stored in ctx may be obtained by UserValue*.\n//\n// This functionality may be useful for passing arbitrary values between\n// functions involved in request processing.\n//\n// All the values are removed from ctx after returning from the top\n// RequestHandler. Additionally, Close method is called on each value\n// implementing io.Closer before removing the value from ctx.\nfunc (ctx *RequestCtx) SetUserValue(key string, value interface{}) {\n\tctx.userValues.Set(key, value)\n}\n\n// SetUserValueBytes stores the given value (arbitrary object)\n// under the given key in ctx.\n//\n// The value stored in ctx may be obtained by UserValue*.\n//\n// This functionality may be useful for passing arbitrary values between\n// functions involved in request processing.\n//\n// All the values stored in ctx are deleted after returning from RequestHandler.\nfunc (ctx *RequestCtx) SetUserValueBytes(key []byte, value interface{}) {\n\tctx.userValues.SetBytes(key, value)\n}\n\n// UserValue returns the value stored via SetUserValue* under the given key.\nfunc (ctx *RequestCtx) UserValue(key string) interface{} {\n\treturn ctx.userValues.Get(key)\n}\n\n// UserValueBytes returns the value stored via SetUserValue*\n// under the given key.\nfunc (ctx *RequestCtx) UserValueBytes(key []byte) interface{} {\n\treturn ctx.userValues.GetBytes(key)\n}\n\n// VisitUserValues calls visitor for each existing userValue.\n//\n// visitor must not retain references to key and value after returning.\n// Make key and/or value copies if you need storing them after returning.\nfunc (ctx *RequestCtx) VisitUserValues(visitor func([]byte, interface{})) {\n\tfor i, n := 0, len(ctx.userValues); i < n; i++ {\n\t\tkv := &ctx.userValues[i]\n\t\tvisitor(kv.key, kv.value)\n\t}\n}\n\n// ResetUserValues allows to reset user values from Request Context\nfunc (ctx *RequestCtx) ResetUserValues() {\n\tctx.userValues.Reset()\n}\n\n// RemoveUserValue removes the given key and the value under it in ctx.\nfunc (ctx *RequestCtx) RemoveUserValue(key string) {\n\tctx.userValues.Remove(key)\n}\n\n// RemoveUserValueBytes removes the given key and the value under it in ctx.\nfunc (ctx *RequestCtx) RemoveUserValueBytes(key []byte) {\n\tctx.userValues.RemoveBytes(key)\n}\n\ntype connTLSer interface {\n\tHandshake() error\n\tConnectionState() tls.ConnectionState\n}\n\n// IsTLS returns true if the underlying connection is tls.Conn.\n//\n// tls.Conn is an encrypted connection (aka SSL, HTTPS).\nfunc (ctx *RequestCtx) IsTLS() bool {\n\t// cast to (connTLSer) instead of (*tls.Conn), since it catches\n\t// cases with overridden tls.Conn such as:\n\t//\n\t// type customConn struct {\n\t//     *tls.Conn\n\t//\n\t//     // other custom fields here\n\t// }\n\n\t// perIPConn wraps the net.Conn in the Conn field\n\tif pic, ok := ctx.c.(*perIPConn); ok {\n\t\t_, ok := pic.Conn.(connTLSer)\n\t\treturn ok\n\t}\n\n\t_, ok := ctx.c.(connTLSer)\n\treturn ok\n}\n\n// TLSConnectionState returns TLS connection state.\n//\n// The function returns nil if the underlying connection isn't tls.Conn.\n//\n// The returned state may be used for verifying TLS version, client certificates,\n// etc.\nfunc (ctx *RequestCtx) TLSConnectionState() *tls.ConnectionState {\n\ttlsConn, ok := ctx.c.(connTLSer)\n\tif !ok {\n\t\treturn nil\n\t}\n\tstate := tlsConn.ConnectionState()\n\treturn &state\n}\n\n// Conn returns a reference to the underlying net.Conn.\n//\n// WARNING: Only use this method if you know what you are doing!\n//\n// Reading from or writing to the returned connection will end badly!\nfunc (ctx *RequestCtx) Conn() net.Conn {\n\treturn ctx.c\n}\n\nfunc (ctx *RequestCtx) reset() {\n\tctx.userValues.Reset()\n\tctx.Request.Reset()\n\tctx.Response.Reset()\n\tctx.fbr.reset()\n\n\tctx.connID = 0\n\tctx.connRequestNum = 0\n\tctx.connTime = zeroTime\n\tctx.remoteAddr = nil\n\tctx.time = zeroTime\n\tctx.s = nil\n\tctx.c = nil\n\n\tif ctx.timeoutResponse != nil {\n\t\tctx.timeoutResponse.Reset()\n\t}\n\n\tif ctx.timeoutTimer != nil {\n\t\tstopTimer(ctx.timeoutTimer)\n\t}\n\n\tctx.hijackHandler = nil\n\tctx.hijackNoResponse = false\n}\n\ntype firstByteReader struct {\n\tc        net.Conn\n\tch       byte\n\tbyteRead bool\n}\n\nfunc (r *firstByteReader) reset() {\n\tr.c = nil\n\tr.ch = 0\n\tr.byteRead = false\n}\n\nfunc (r *firstByteReader) Read(b []byte) (int, error) {\n\tif len(b) == 0 {\n\t\treturn 0, nil\n\t}\n\tnn := 0\n\tif !r.byteRead {\n\t\tb[0] = r.ch\n\t\tb = b[1:]\n\t\tr.byteRead = true\n\t\tnn = 1\n\t}\n\tn, err := r.c.Read(b)\n\treturn n + nn, err\n}\n\n// Logger is used for logging formatted messages.\ntype Logger interface {\n\t// Printf must have the same semantics as log.Printf.\n\tPrintf(format string, args ...interface{})\n}\n\nvar ctxLoggerLock sync.Mutex\n\ntype ctxLogger struct {\n\tctx    *RequestCtx\n\tlogger Logger\n}\n\nfunc (cl *ctxLogger) Printf(format string, args ...interface{}) {\n\tmsg := fmt.Sprintf(format, args...)\n\tctxLoggerLock.Lock()\n\tcl.logger.Printf(\"%.3f %s - %s\", time.Since(cl.ctx.ConnTime()).Seconds(), cl.ctx.String(), msg)\n\tctxLoggerLock.Unlock()\n}\n\nvar zeroTCPAddr = &net.TCPAddr{\n\tIP: net.IPv4zero,\n}\n\n// String returns unique string representation of the ctx.\n//\n// The returned value may be useful for logging.\nfunc (ctx *RequestCtx) String() string {\n\treturn fmt.Sprintf(\"#%016X - %s<->%s - %s %s\", ctx.ID(), ctx.LocalAddr(), ctx.RemoteAddr(), ctx.Request.Header.Method(), ctx.URI().FullURI())\n}\n\n// ID returns unique ID of the request.\nfunc (ctx *RequestCtx) ID() uint64 {\n\treturn (ctx.connID << 32) | ctx.connRequestNum\n}\n\n// ConnID returns unique connection ID.\n//\n// This ID may be used to match distinct requests to the same incoming\n// connection.\nfunc (ctx *RequestCtx) ConnID() uint64 {\n\treturn ctx.connID\n}\n\n// Time returns RequestHandler call time.\nfunc (ctx *RequestCtx) Time() time.Time {\n\treturn ctx.time\n}\n\n// ConnTime returns the time the server started serving the connection\n// the current request came from.\nfunc (ctx *RequestCtx) ConnTime() time.Time {\n\treturn ctx.connTime\n}\n\n// ConnRequestNum returns request sequence number\n// for the current connection.\n//\n// Sequence starts with 1.\nfunc (ctx *RequestCtx) ConnRequestNum() uint64 {\n\treturn ctx.connRequestNum\n}\n\n// SetConnectionClose sets 'Connection: close' response header and closes\n// connection after the RequestHandler returns.\nfunc (ctx *RequestCtx) SetConnectionClose() {\n\tctx.Response.SetConnectionClose()\n}\n\n// SetStatusCode sets response status code.\nfunc (ctx *RequestCtx) SetStatusCode(statusCode int) {\n\tctx.Response.SetStatusCode(statusCode)\n}\n\n// SetContentType sets response Content-Type.\nfunc (ctx *RequestCtx) SetContentType(contentType string) {\n\tctx.Response.Header.SetContentType(contentType)\n}\n\n// SetContentTypeBytes sets response Content-Type.\n//\n// It is safe modifying contentType buffer after function return.\nfunc (ctx *RequestCtx) SetContentTypeBytes(contentType []byte) {\n\tctx.Response.Header.SetContentTypeBytes(contentType)\n}\n\n// RequestURI returns RequestURI.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) RequestURI() []byte {\n\treturn ctx.Request.Header.RequestURI()\n}\n\n// URI returns requested uri.\n//\n// This uri is valid until your request handler returns.\nfunc (ctx *RequestCtx) URI() *URI {\n\treturn ctx.Request.URI()\n}\n\n// Referer returns request referer.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) Referer() []byte {\n\treturn ctx.Request.Header.Referer()\n}\n\n// UserAgent returns User-Agent header value from the request.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) UserAgent() []byte {\n\treturn ctx.Request.Header.UserAgent()\n}\n\n// Path returns requested path.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) Path() []byte {\n\treturn ctx.URI().Path()\n}\n\n// Host returns requested host.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) Host() []byte {\n\treturn ctx.URI().Host()\n}\n\n// QueryArgs returns query arguments from RequestURI.\n//\n// It doesn't return POST'ed arguments - use PostArgs() for this.\n//\n// See also PostArgs, FormValue and FormFile.\n//\n// These args are valid until your request handler returns.\nfunc (ctx *RequestCtx) QueryArgs() *Args {\n\treturn ctx.URI().QueryArgs()\n}\n\n// PostArgs returns POST arguments.\n//\n// It doesn't return query arguments from RequestURI - use QueryArgs for this.\n//\n// See also QueryArgs, FormValue and FormFile.\n//\n// These args are valid until your request handler returns.\nfunc (ctx *RequestCtx) PostArgs() *Args {\n\treturn ctx.Request.PostArgs()\n}\n\n// MultipartForm returns requests's multipart form.\n//\n// Returns ErrNoMultipartForm if request's content-type\n// isn't 'multipart/form-data'.\n//\n// All uploaded temporary files are automatically deleted after\n// returning from RequestHandler. Either move or copy uploaded files\n// into new place if you want retaining them.\n//\n// Use SaveMultipartFile function for permanently saving uploaded file.\n//\n// The returned form is valid until your request handler returns.\n//\n// See also FormFile and FormValue.\nfunc (ctx *RequestCtx) MultipartForm() (*multipart.Form, error) {\n\treturn ctx.Request.MultipartForm()\n}\n\n// FormFile returns uploaded file associated with the given multipart form key.\n//\n// The file is automatically deleted after returning from RequestHandler,\n// so either move or copy uploaded file into new place if you want retaining it.\n//\n// Use SaveMultipartFile function for permanently saving uploaded file.\n//\n// The returned file header is valid until your request handler returns.\nfunc (ctx *RequestCtx) FormFile(key string) (*multipart.FileHeader, error) {\n\tmf, err := ctx.MultipartForm()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif mf.File == nil {\n\t\treturn nil, err\n\t}\n\tfhh := mf.File[key]\n\tif fhh == nil {\n\t\treturn nil, ErrMissingFile\n\t}\n\treturn fhh[0], nil\n}\n\n// ErrMissingFile may be returned from FormFile when the is no uploaded file\n// associated with the given multipart form key.\nvar ErrMissingFile = errors.New(\"there is no uploaded file associated with the given key\")\n\n// SaveMultipartFile saves multipart file fh under the given filename path.\nfunc SaveMultipartFile(fh *multipart.FileHeader, path string) (err error) {\n\tvar (\n\t\tf  multipart.File\n\t\tff *os.File\n\t)\n\tf, err = fh.Open()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tvar ok bool\n\tif ff, ok = f.(*os.File); ok {\n\t\t// Windows can't rename files that are opened.\n\t\tif err = f.Close(); err != nil {\n\t\t\treturn\n\t\t}\n\n\t\t// If renaming fails we try the normal copying method.\n\t\t// Renaming could fail if the files are on different devices.\n\t\tif os.Rename(ff.Name(), path) == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\t// Reopen f for the code below.\n\t\tif f, err = fh.Open(); err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\n\tdefer func() {\n\t\te := f.Close()\n\t\tif err == nil {\n\t\t\terr = e\n\t\t}\n\t}()\n\n\tif ff, err = os.Create(path); err != nil {\n\t\treturn\n\t}\n\tdefer func() {\n\t\te := ff.Close()\n\t\tif err == nil {\n\t\t\terr = e\n\t\t}\n\t}()\n\t_, err = copyZeroAlloc(ff, f)\n\treturn\n}\n\n// FormValue returns form value associated with the given key.\n//\n// The value is searched in the following places:\n//\n//   * Query string.\n//   * POST or PUT body.\n//\n// There are more fine-grained methods for obtaining form values:\n//\n//   * QueryArgs for obtaining values from query string.\n//   * PostArgs for obtaining values from POST or PUT body.\n//   * MultipartForm for obtaining values from multipart form.\n//   * FormFile for obtaining uploaded files.\n//\n// The returned value is valid until your request handler returns.\nfunc (ctx *RequestCtx) FormValue(key string) []byte {\n\tv := ctx.QueryArgs().Peek(key)\n\tif len(v) > 0 {\n\t\treturn v\n\t}\n\tv = ctx.PostArgs().Peek(key)\n\tif len(v) > 0 {\n\t\treturn v\n\t}\n\tmf, err := ctx.MultipartForm()\n\tif err == nil && mf.Value != nil {\n\t\tvv := mf.Value[key]\n\t\tif len(vv) > 0 {\n\t\t\treturn []byte(vv[0])\n\t\t}\n\t}\n\treturn nil\n}\n\n// IsGet returns true if request method is GET.\nfunc (ctx *RequestCtx) IsGet() bool {\n\treturn ctx.Request.Header.IsGet()\n}\n\n// IsPost returns true if request method is POST.\nfunc (ctx *RequestCtx) IsPost() bool {\n\treturn ctx.Request.Header.IsPost()\n}\n\n// IsPut returns true if request method is PUT.\nfunc (ctx *RequestCtx) IsPut() bool {\n\treturn ctx.Request.Header.IsPut()\n}\n\n// IsDelete returns true if request method is DELETE.\nfunc (ctx *RequestCtx) IsDelete() bool {\n\treturn ctx.Request.Header.IsDelete()\n}\n\n// IsConnect returns true if request method is CONNECT.\nfunc (ctx *RequestCtx) IsConnect() bool {\n\treturn ctx.Request.Header.IsConnect()\n}\n\n// IsOptions returns true if request method is OPTIONS.\nfunc (ctx *RequestCtx) IsOptions() bool {\n\treturn ctx.Request.Header.IsOptions()\n}\n\n// IsTrace returns true if request method is TRACE.\nfunc (ctx *RequestCtx) IsTrace() bool {\n\treturn ctx.Request.Header.IsTrace()\n}\n\n// IsPatch returns true if request method is PATCH.\nfunc (ctx *RequestCtx) IsPatch() bool {\n\treturn ctx.Request.Header.IsPatch()\n}\n\n// Method return request method.\n//\n// Returned value is valid until your request handler returns.\nfunc (ctx *RequestCtx) Method() []byte {\n\treturn ctx.Request.Header.Method()\n}\n\n// IsHead returns true if request method is HEAD.\nfunc (ctx *RequestCtx) IsHead() bool {\n\treturn ctx.Request.Header.IsHead()\n}\n\n// RemoteAddr returns client address for the given request.\n//\n// Always returns non-nil result.\nfunc (ctx *RequestCtx) RemoteAddr() net.Addr {\n\tif ctx.remoteAddr != nil {\n\t\treturn ctx.remoteAddr\n\t}\n\tif ctx.c == nil {\n\t\treturn zeroTCPAddr\n\t}\n\taddr := ctx.c.RemoteAddr()\n\tif addr == nil {\n\t\treturn zeroTCPAddr\n\t}\n\treturn addr\n}\n\n// SetRemoteAddr sets remote address to the given value.\n//\n// Set nil value to resore default behaviour for using\n// connection remote address.\nfunc (ctx *RequestCtx) SetRemoteAddr(remoteAddr net.Addr) {\n\tctx.remoteAddr = remoteAddr\n}\n\n// LocalAddr returns server address for the given request.\n//\n// Always returns non-nil result.\nfunc (ctx *RequestCtx) LocalAddr() net.Addr {\n\tif ctx.c == nil {\n\t\treturn zeroTCPAddr\n\t}\n\taddr := ctx.c.LocalAddr()\n\tif addr == nil {\n\t\treturn zeroTCPAddr\n\t}\n\treturn addr\n}\n\n// RemoteIP returns the client ip the request came from.\n//\n// Always returns non-nil result.\nfunc (ctx *RequestCtx) RemoteIP() net.IP {\n\treturn addrToIP(ctx.RemoteAddr())\n}\n\n// LocalIP returns the server ip the request came to.\n//\n// Always returns non-nil result.\nfunc (ctx *RequestCtx) LocalIP() net.IP {\n\treturn addrToIP(ctx.LocalAddr())\n}\n\nfunc addrToIP(addr net.Addr) net.IP {\n\tx, ok := addr.(*net.TCPAddr)\n\tif !ok {\n\t\treturn net.IPv4zero\n\t}\n\treturn x.IP\n}\n\n// Error sets response status code to the given value and sets response body\n// to the given message.\n//\n// Warning: this will reset the response headers and body already set!\nfunc (ctx *RequestCtx) Error(msg string, statusCode int) {\n\tctx.Response.Reset()\n\tctx.SetStatusCode(statusCode)\n\tctx.SetContentTypeBytes(defaultContentType)\n\tctx.SetBodyString(msg)\n}\n\n// Success sets response Content-Type and body to the given values.\nfunc (ctx *RequestCtx) Success(contentType string, body []byte) {\n\tctx.SetContentType(contentType)\n\tctx.SetBody(body)\n}\n\n// SuccessString sets response Content-Type and body to the given values.\nfunc (ctx *RequestCtx) SuccessString(contentType, body string) {\n\tctx.SetContentType(contentType)\n\tctx.SetBodyString(body)\n}\n\n// Redirect sets 'Location: uri' response header and sets the given statusCode.\n//\n// statusCode must have one of the following values:\n//\n//    * StatusMovedPermanently (301)\n//    * StatusFound (302)\n//    * StatusSeeOther (303)\n//    * StatusTemporaryRedirect (307)\n//    * StatusPermanentRedirect (308)\n//\n// All other statusCode values are replaced by StatusFound (302).\n//\n// The redirect uri may be either absolute or relative to the current\n// request uri. Fasthttp will always send an absolute uri back to the client.\n// To send a relative uri you can use the following code:\n//\n//   strLocation = []byte(\"Location\") // Put this with your top level var () declarations.\n//   ctx.Response.Header.SetCanonical(strLocation, \"/relative?uri\")\n//   ctx.Response.SetStatusCode(fasthttp.StatusMovedPermanently)\n//\nfunc (ctx *RequestCtx) Redirect(uri string, statusCode int) {\n\tu := AcquireURI()\n\tctx.URI().CopyTo(u)\n\tu.Update(uri)\n\tctx.redirect(u.FullURI(), statusCode)\n\tReleaseURI(u)\n}\n\n// RedirectBytes sets 'Location: uri' response header and sets\n// the given statusCode.\n//\n// statusCode must have one of the following values:\n//\n//    * StatusMovedPermanently (301)\n//    * StatusFound (302)\n//    * StatusSeeOther (303)\n//    * StatusTemporaryRedirect (307)\n//    * StatusPermanentRedirect (308)\n//\n// All other statusCode values are replaced by StatusFound (302).\n//\n// The redirect uri may be either absolute or relative to the current\n// request uri. Fasthttp will always send an absolute uri back to the client.\n// To send a relative uri you can use the following code:\n//\n//   strLocation = []byte(\"Location\") // Put this with your top level var () declarations.\n//   ctx.Response.Header.SetCanonical(strLocation, \"/relative?uri\")\n//   ctx.Response.SetStatusCode(fasthttp.StatusMovedPermanently)\n//\nfunc (ctx *RequestCtx) RedirectBytes(uri []byte, statusCode int) {\n\ts := b2s(uri)\n\tctx.Redirect(s, statusCode)\n}\n\nfunc (ctx *RequestCtx) redirect(uri []byte, statusCode int) {\n\tctx.Response.Header.SetCanonical(strLocation, uri)\n\tstatusCode = getRedirectStatusCode(statusCode)\n\tctx.Response.SetStatusCode(statusCode)\n}\n\nfunc getRedirectStatusCode(statusCode int) int {\n\tif statusCode == StatusMovedPermanently || statusCode == StatusFound ||\n\t\tstatusCode == StatusSeeOther || statusCode == StatusTemporaryRedirect ||\n\t\tstatusCode == StatusPermanentRedirect {\n\t\treturn statusCode\n\t}\n\treturn StatusFound\n}\n\n// SetBody sets response body to the given value.\n//\n// It is safe re-using body argument after the function returns.\nfunc (ctx *RequestCtx) SetBody(body []byte) {\n\tctx.Response.SetBody(body)\n}\n\n// SetBodyString sets response body to the given value.\nfunc (ctx *RequestCtx) SetBodyString(body string) {\n\tctx.Response.SetBodyString(body)\n}\n\n// ResetBody resets response body contents.\nfunc (ctx *RequestCtx) ResetBody() {\n\tctx.Response.ResetBody()\n}\n\n// SendFile sends local file contents from the given path as response body.\n//\n// This is a shortcut to ServeFile(ctx, path).\n//\n// SendFile logs all the errors via ctx.Logger.\n//\n// See also ServeFile, FSHandler and FS.\n//\n// WARNING: do not pass any user supplied paths to this function!\n// WARNING: if path is based on user input users will be able to request\n// any file on your filesystem! Use fasthttp.FS with a sane Root instead.\nfunc (ctx *RequestCtx) SendFile(path string) {\n\tServeFile(ctx, path)\n}\n\n// SendFileBytes sends local file contents from the given path as response body.\n//\n// This is a shortcut to ServeFileBytes(ctx, path).\n//\n// SendFileBytes logs all the errors via ctx.Logger.\n//\n// See also ServeFileBytes, FSHandler and FS.\n//\n// WARNING: do not pass any user supplied paths to this function!\n// WARNING: if path is based on user input users will be able to request\n// any file on your filesystem! Use fasthttp.FS with a sane Root instead.\nfunc (ctx *RequestCtx) SendFileBytes(path []byte) {\n\tServeFileBytes(ctx, path)\n}\n\n// IfModifiedSince returns true if lastModified exceeds 'If-Modified-Since'\n// value from the request header.\n//\n// The function returns true also 'If-Modified-Since' request header is missing.\nfunc (ctx *RequestCtx) IfModifiedSince(lastModified time.Time) bool {\n\tifModStr := ctx.Request.Header.peek(strIfModifiedSince)\n\tif len(ifModStr) == 0 {\n\t\treturn true\n\t}\n\tifMod, err := ParseHTTPDate(ifModStr)\n\tif err != nil {\n\t\treturn true\n\t}\n\tlastModified = lastModified.Truncate(time.Second)\n\treturn ifMod.Before(lastModified)\n}\n\n// NotModified resets response and sets '304 Not Modified' response status code.\nfunc (ctx *RequestCtx) NotModified() {\n\tctx.Response.Reset()\n\tctx.SetStatusCode(StatusNotModified)\n}\n\n// NotFound resets response and sets '404 Not Found' response status code.\nfunc (ctx *RequestCtx) NotFound() {\n\tctx.Response.Reset()\n\tctx.SetStatusCode(StatusNotFound)\n\tctx.SetBodyString(\"404 Page not found\")\n}\n\n// Write writes p into response body.\nfunc (ctx *RequestCtx) Write(p []byte) (int, error) {\n\tctx.Response.AppendBody(p)\n\treturn len(p), nil\n}\n\n// WriteString appends s to response body.\nfunc (ctx *RequestCtx) WriteString(s string) (int, error) {\n\tctx.Response.AppendBodyString(s)\n\treturn len(s), nil\n}\n\n// PostBody returns POST request body.\n//\n// The returned bytes are valid until your request handler returns.\nfunc (ctx *RequestCtx) PostBody() []byte {\n\treturn ctx.Request.Body()\n}\n\n// SetBodyStream sets response body stream and, optionally body size.\n//\n// bodyStream.Close() is called after finishing reading all body data\n// if it implements io.Closer.\n//\n// If bodySize is >= 0, then bodySize bytes must be provided by bodyStream\n// before returning io.EOF.\n//\n// If bodySize < 0, then bodyStream is read until io.EOF.\n//\n// See also SetBodyStreamWriter.\nfunc (ctx *RequestCtx) SetBodyStream(bodyStream io.Reader, bodySize int) {\n\tctx.Response.SetBodyStream(bodyStream, bodySize)\n}\n\n// SetBodyStreamWriter registers the given stream writer for populating\n// response body.\n//\n// Access to RequestCtx and/or its' members is forbidden from sw.\n//\n// This function may be used in the following cases:\n//\n//     * if response body is too big (more than 10MB).\n//     * if response body is streamed from slow external sources.\n//     * if response body must be streamed to the client in chunks.\n//     (aka `http server push`).\nfunc (ctx *RequestCtx) SetBodyStreamWriter(sw StreamWriter) {\n\tctx.Response.SetBodyStreamWriter(sw)\n}\n\n// IsBodyStream returns true if response body is set via SetBodyStream*.\nfunc (ctx *RequestCtx) IsBodyStream() bool {\n\treturn ctx.Response.IsBodyStream()\n}\n\n// Logger returns logger, which may be used for logging arbitrary\n// request-specific messages inside RequestHandler.\n//\n// Each message logged via returned logger contains request-specific information\n// such as request id, request duration, local address, remote address,\n// request method and request url.\n//\n// It is safe re-using returned logger for logging multiple messages\n// for the current request.\n//\n// The returned logger is valid until your request handler returns.\nfunc (ctx *RequestCtx) Logger() Logger {\n\tif ctx.logger.ctx == nil {\n\t\tctx.logger.ctx = ctx\n\t}\n\tif ctx.logger.logger == nil {\n\t\tctx.logger.logger = ctx.s.logger()\n\t}\n\treturn &ctx.logger\n}\n\n// TimeoutError sets response status code to StatusRequestTimeout and sets\n// body to the given msg.\n//\n// All response modifications after TimeoutError call are ignored.\n//\n// TimeoutError MUST be called before returning from RequestHandler if there are\n// references to ctx and/or its members in other goroutines remain.\n//\n// Usage of this function is discouraged. Prefer eliminating ctx references\n// from pending goroutines instead of using this function.\nfunc (ctx *RequestCtx) TimeoutError(msg string) {\n\tctx.TimeoutErrorWithCode(msg, StatusRequestTimeout)\n}\n\n// TimeoutErrorWithCode sets response body to msg and response status\n// code to statusCode.\n//\n// All response modifications after TimeoutErrorWithCode call are ignored.\n//\n// TimeoutErrorWithCode MUST be called before returning from RequestHandler\n// if there are references to ctx and/or its members in other goroutines remain.\n//\n// Usage of this function is discouraged. Prefer eliminating ctx references\n// from pending goroutines instead of using this function.\nfunc (ctx *RequestCtx) TimeoutErrorWithCode(msg string, statusCode int) {\n\tvar resp Response\n\tresp.SetStatusCode(statusCode)\n\tresp.SetBodyString(msg)\n\tctx.TimeoutErrorWithResponse(&resp)\n}\n\n// TimeoutErrorWithResponse marks the ctx as timed out and sends the given\n// response to the client.\n//\n// All ctx modifications after TimeoutErrorWithResponse call are ignored.\n//\n// TimeoutErrorWithResponse MUST be called before returning from RequestHandler\n// if there are references to ctx and/or its members in other goroutines remain.\n//\n// Usage of this function is discouraged. Prefer eliminating ctx references\n// from pending goroutines instead of using this function.\nfunc (ctx *RequestCtx) TimeoutErrorWithResponse(resp *Response) {\n\trespCopy := &Response{}\n\tresp.CopyTo(respCopy)\n\tctx.timeoutResponse = respCopy\n}\n\n// NextProto adds nph to be processed when key is negotiated when TLS\n// connection is established.\n//\n// This function can only be called before the server is started.\nfunc (s *Server) NextProto(key string, nph ServeHandler) {\n\tif s.nextProtos == nil {\n\t\ts.nextProtos = make(map[string]ServeHandler)\n\t}\n\n\ts.configTLS()\n\ts.TLSConfig.NextProtos = append(s.TLSConfig.NextProtos, key)\n\ts.nextProtos[key] = nph\n}\n\nfunc (s *Server) getNextProto(c net.Conn) (proto string, err error) {\n\tif tlsConn, ok := c.(connTLSer); ok {\n\t\tif s.ReadTimeout > 0 {\n\t\t\tif err := c.SetReadDeadline(time.Now().Add(s.ReadTimeout)); err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetReadDeadline(%s): %s\", s.ReadTimeout, err))\n\t\t\t}\n\t\t}\n\n\t\tif s.WriteTimeout > 0 {\n\t\t\tif err := c.SetWriteDeadline(time.Now().Add(s.WriteTimeout)); err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetWriteDeadline(%s): %s\", s.WriteTimeout, err))\n\t\t\t}\n\t\t}\n\n\t\terr = tlsConn.Handshake()\n\t\tif err == nil {\n\t\t\tproto = tlsConn.ConnectionState().NegotiatedProtocol\n\t\t}\n\t}\n\treturn\n}\n\n// tcpKeepAliveListener sets TCP keep-alive timeouts on accepted\n// connections. It's used by ListenAndServe, ListenAndServeTLS and\n// ListenAndServeTLSEmbed so dead TCP connections (e.g. closing laptop mid-download)\n// eventually go away.\ntype tcpKeepaliveListener struct {\n\t*net.TCPListener\n\tkeepalive       bool\n\tkeepalivePeriod time.Duration\n}\n\nfunc (ln tcpKeepaliveListener) Accept() (net.Conn, error) {\n\ttc, err := ln.AcceptTCP()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := tc.SetKeepAlive(ln.keepalive); err != nil {\n\t\ttc.Close() //nolint:errcheck\n\t\treturn nil, err\n\t}\n\tif ln.keepalivePeriod > 0 {\n\t\tif err := tc.SetKeepAlivePeriod(ln.keepalivePeriod); err != nil {\n\t\t\ttc.Close() //nolint:errcheck\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn tc, nil\n}\n\n// ListenAndServe serves HTTP requests from the given TCP4 addr.\n//\n// Pass custom listener to Serve if you need listening on non-TCP4 media\n// such as IPv6.\n//\n// Accepted connections are configured to enable TCP keep-alives.\nfunc (s *Server) ListenAndServe(addr string) error {\n\tln, err := net.Listen(\"tcp4\", addr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif tcpln, ok := ln.(*net.TCPListener); ok {\n\t\treturn s.Serve(tcpKeepaliveListener{\n\t\t\tTCPListener:     tcpln,\n\t\t\tkeepalive:       s.TCPKeepalive,\n\t\t\tkeepalivePeriod: s.TCPKeepalivePeriod,\n\t\t})\n\t}\n\treturn s.Serve(ln)\n}\n\n// ListenAndServeUNIX serves HTTP requests from the given UNIX addr.\n//\n// The function deletes existing file at addr before starting serving.\n//\n// The server sets the given file mode for the UNIX addr.\nfunc (s *Server) ListenAndServeUNIX(addr string, mode os.FileMode) error {\n\tif err := os.Remove(addr); err != nil && !os.IsNotExist(err) {\n\t\treturn fmt.Errorf(\"unexpected error when trying to remove unix socket file %q: %w\", addr, err)\n\t}\n\tln, err := net.Listen(\"unix\", addr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err = os.Chmod(addr, mode); err != nil {\n\t\treturn fmt.Errorf(\"cannot chmod %#o for %q: %w\", mode, addr, err)\n\t}\n\treturn s.Serve(ln)\n}\n\n// ListenAndServeTLS serves HTTPS requests from the given TCP4 addr.\n//\n// certFile and keyFile are paths to TLS certificate and key files.\n//\n// Pass custom listener to Serve if you need listening on non-TCP4 media\n// such as IPv6.\n//\n// If the certFile or keyFile has not been provided to the server structure,\n// the function will use the previously added TLS configuration.\n//\n// Accepted connections are configured to enable TCP keep-alives.\nfunc (s *Server) ListenAndServeTLS(addr, certFile, keyFile string) error {\n\tln, err := net.Listen(\"tcp4\", addr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif tcpln, ok := ln.(*net.TCPListener); ok {\n\t\treturn s.ServeTLS(tcpKeepaliveListener{\n\t\t\tTCPListener:     tcpln,\n\t\t\tkeepalive:       s.TCPKeepalive,\n\t\t\tkeepalivePeriod: s.TCPKeepalivePeriod,\n\t\t}, certFile, keyFile)\n\t}\n\treturn s.ServeTLS(ln, certFile, keyFile)\n}\n\n// ListenAndServeTLSEmbed serves HTTPS requests from the given TCP4 addr.\n//\n// certData and keyData must contain valid TLS certificate and key data.\n//\n// Pass custom listener to Serve if you need listening on arbitrary media\n// such as IPv6.\n//\n// If the certFile or keyFile has not been provided the server structure,\n// the function will use previously added TLS configuration.\n//\n// Accepted connections are configured to enable TCP keep-alives.\nfunc (s *Server) ListenAndServeTLSEmbed(addr string, certData, keyData []byte) error {\n\tln, err := net.Listen(\"tcp4\", addr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif tcpln, ok := ln.(*net.TCPListener); ok {\n\t\treturn s.ServeTLSEmbed(tcpKeepaliveListener{\n\t\t\tTCPListener:     tcpln,\n\t\t\tkeepalive:       s.TCPKeepalive,\n\t\t\tkeepalivePeriod: s.TCPKeepalivePeriod,\n\t\t}, certData, keyData)\n\t}\n\treturn s.ServeTLSEmbed(ln, certData, keyData)\n}\n\n// ServeTLS serves HTTPS requests from the given listener.\n//\n// certFile and keyFile are paths to TLS certificate and key files.\n//\n// If the certFile or keyFile has not been provided the server structure,\n// the function will use previously added TLS configuration.\nfunc (s *Server) ServeTLS(ln net.Listener, certFile, keyFile string) error {\n\ts.mu.Lock()\n\terr := s.AppendCert(certFile, keyFile)\n\tif err != nil && err != errNoCertOrKeyProvided {\n\t\ts.mu.Unlock()\n\t\treturn err\n\t}\n\tif s.TLSConfig == nil {\n\t\ts.mu.Unlock()\n\t\treturn errNoCertOrKeyProvided\n\t}\n\n\t// BuildNameToCertificate has been deprecated since 1.14.\n\t// But since we also support older versions we'll keep this here.\n\ts.TLSConfig.BuildNameToCertificate() //nolint:staticcheck\n\n\ts.mu.Unlock()\n\n\treturn s.Serve(\n\t\ttls.NewListener(ln, s.TLSConfig.Clone()),\n\t)\n}\n\n// ServeTLSEmbed serves HTTPS requests from the given listener.\n//\n// certData and keyData must contain valid TLS certificate and key data.\n//\n// If the certFile or keyFile has not been provided the server structure,\n// the function will use previously added TLS configuration.\nfunc (s *Server) ServeTLSEmbed(ln net.Listener, certData, keyData []byte) error {\n\ts.mu.Lock()\n\n\terr := s.AppendCertEmbed(certData, keyData)\n\tif err != nil && err != errNoCertOrKeyProvided {\n\t\ts.mu.Unlock()\n\t\treturn err\n\t}\n\tif s.TLSConfig == nil {\n\t\ts.mu.Unlock()\n\t\treturn errNoCertOrKeyProvided\n\t}\n\n\t// BuildNameToCertificate has been deprecated since 1.14.\n\t// But since we also support older versions we'll keep this here.\n\ts.TLSConfig.BuildNameToCertificate() //nolint:staticcheck\n\n\ts.mu.Unlock()\n\n\treturn s.Serve(\n\t\ttls.NewListener(ln, s.TLSConfig.Clone()),\n\t)\n}\n\n// AppendCert appends certificate and keyfile to TLS Configuration.\n//\n// This function allows programmer to handle multiple domains\n// in one server structure. See examples/multidomain\nfunc (s *Server) AppendCert(certFile, keyFile string) error {\n\tif len(certFile) == 0 && len(keyFile) == 0 {\n\t\treturn errNoCertOrKeyProvided\n\t}\n\n\tcert, err := tls.LoadX509KeyPair(certFile, keyFile)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot load TLS key pair from certFile=%q and keyFile=%q: %w\", certFile, keyFile, err)\n\t}\n\n\ts.configTLS()\n\ts.TLSConfig.Certificates = append(s.TLSConfig.Certificates, cert)\n\n\treturn nil\n}\n\n// AppendCertEmbed does the same as AppendCert but using in-memory data.\nfunc (s *Server) AppendCertEmbed(certData, keyData []byte) error {\n\tif len(certData) == 0 && len(keyData) == 0 {\n\t\treturn errNoCertOrKeyProvided\n\t}\n\n\tcert, err := tls.X509KeyPair(certData, keyData)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot load TLS key pair from the provided certData(%d) and keyData(%d): %s\",\n\t\t\tlen(certData), len(keyData), err)\n\t}\n\n\ts.configTLS()\n\ts.TLSConfig.Certificates = append(s.TLSConfig.Certificates, cert)\n\n\treturn nil\n}\n\nfunc (s *Server) configTLS() {\n\tif s.TLSConfig == nil {\n\t\ts.TLSConfig = &tls.Config{}\n\t}\n}\n\n// DefaultConcurrency is the maximum number of concurrent connections\n// the Server may serve by default (i.e. if Server.Concurrency isn't set).\nconst DefaultConcurrency = 256 * 1024\n\n// Serve serves incoming connections from the given listener.\n//\n// Serve blocks until the given listener returns permanent error.\nfunc (s *Server) Serve(ln net.Listener) error {\n\tvar lastOverflowErrorTime time.Time\n\tvar lastPerIPErrorTime time.Time\n\tvar c net.Conn\n\tvar err error\n\n\tmaxWorkersCount := s.getConcurrency()\n\n\ts.mu.Lock()\n\t{\n\t\ts.ln = append(s.ln, ln)\n\t\tif s.done == nil {\n\t\t\ts.done = make(chan struct{})\n\t\t}\n\n\t\tif s.concurrencyCh == nil {\n\t\t\ts.concurrencyCh = make(chan struct{}, maxWorkersCount)\n\t\t}\n\t}\n\ts.mu.Unlock()\n\n\twp := &workerPool{\n\t\tWorkerFunc:            s.serveConn,\n\t\tMaxWorkersCount:       maxWorkersCount,\n\t\tLogAllErrors:          s.LogAllErrors,\n\t\tMaxIdleWorkerDuration: s.MaxIdleWorkerDuration,\n\t\tLogger:                s.logger(),\n\t\tconnState:             s.setState,\n\t}\n\twp.Start()\n\n\t// Count our waiting to accept a connection as an open connection.\n\t// This way we can't get into any weird state where just after accepting\n\t// a connection Shutdown is called which reads open as 0 because it isn't\n\t// incremented yet.\n\tatomic.AddInt32(&s.open, 1)\n\tdefer atomic.AddInt32(&s.open, -1)\n\n\tfor {\n\t\tif c, err = acceptConn(s, ln, &lastPerIPErrorTime); err != nil {\n\t\t\twp.Stop()\n\t\t\tif err == io.EOF {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\ts.setState(c, StateNew)\n\t\tatomic.AddInt32(&s.open, 1)\n\t\tif !wp.Serve(c) {\n\t\t\tatomic.AddInt32(&s.open, -1)\n\t\t\ts.writeFastError(c, StatusServiceUnavailable,\n\t\t\t\t\"The connection cannot be served because Server.Concurrency limit exceeded\")\n\t\t\tc.Close()\n\t\t\ts.setState(c, StateClosed)\n\t\t\tif time.Since(lastOverflowErrorTime) > time.Minute {\n\t\t\t\ts.logger().Printf(\"The incoming connection cannot be served, because %d concurrent connections are served. \"+\n\t\t\t\t\t\"Try increasing Server.Concurrency\", maxWorkersCount)\n\t\t\t\tlastOverflowErrorTime = time.Now()\n\t\t\t}\n\n\t\t\t// The current server reached concurrency limit,\n\t\t\t// so give other concurrently running servers a chance\n\t\t\t// accepting incoming connections on the same address.\n\t\t\t//\n\t\t\t// There is a hope other servers didn't reach their\n\t\t\t// concurrency limits yet :)\n\t\t\t//\n\t\t\t// See also: https://github.com/valyala/fasthttp/pull/485#discussion_r239994990\n\t\t\tif s.SleepWhenConcurrencyLimitsExceeded > 0 {\n\t\t\t\ttime.Sleep(s.SleepWhenConcurrencyLimitsExceeded)\n\t\t\t}\n\t\t}\n\t\tc = nil\n\t}\n}\n\n// Shutdown gracefully shuts down the server without interrupting any active connections.\n// Shutdown works by first closing all open listeners and then waiting indefinitely for all connections to return to idle and then shut down.\n//\n// When Shutdown is called, Serve, ListenAndServe, and ListenAndServeTLS immediately return nil.\n// Make sure the program doesn't exit and waits instead for Shutdown to return.\n//\n// Shutdown does not close keepalive connections so its recommended to set ReadTimeout and IdleTimeout to something else than 0.\nfunc (s *Server) Shutdown() error {\n\ts.mu.Lock()\n\tdefer s.mu.Unlock()\n\n\tatomic.StoreInt32(&s.stop, 1)\n\tdefer atomic.StoreInt32(&s.stop, 0)\n\n\tif s.ln == nil {\n\t\treturn nil\n\t}\n\n\tfor _, ln := range s.ln {\n\t\tif err := ln.Close(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif s.done != nil {\n\t\tclose(s.done)\n\t}\n\n\ts.closeIdleConns()\n\n\t// Closing the listener will make Serve() call Stop on the worker pool.\n\t// Setting .stop to 1 will make serveConn() break out of its loop.\n\t// Now we just have to wait until all workers are done.\n\tfor {\n\t\tif open := atomic.LoadInt32(&s.open); open == 0 {\n\t\t\tbreak\n\t\t}\n\t\t// This is not an optimal solution but using a sync.WaitGroup\n\t\t// here causes data races as it's hard to prevent Add() to be called\n\t\t// while Wait() is waiting.\n\t\ttime.Sleep(time.Millisecond * 100)\n\t}\n\n\ts.done = nil\n\ts.ln = nil\n\treturn nil\n}\n\nfunc acceptConn(s *Server, ln net.Listener, lastPerIPErrorTime *time.Time) (net.Conn, error) {\n\tfor {\n\t\tc, err := ln.Accept()\n\t\tif err != nil {\n\t\t\tif c != nil {\n\t\t\t\tpanic(\"BUG: net.Listener returned non-nil conn and non-nil error\")\n\t\t\t}\n\t\t\tif netErr, ok := err.(net.Error); ok && netErr.Temporary() {\n\t\t\t\ts.logger().Printf(\"Temporary error when accepting new connections: %s\", netErr)\n\t\t\t\ttime.Sleep(time.Second)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif err != io.EOF && !strings.Contains(err.Error(), \"use of closed network connection\") {\n\t\t\t\ts.logger().Printf(\"Permanent error when accepting new connections: %s\", err)\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn nil, io.EOF\n\t\t}\n\t\tif c == nil {\n\t\t\tpanic(\"BUG: net.Listener returned (nil, nil)\")\n\t\t}\n\t\tif s.MaxConnsPerIP > 0 {\n\t\t\tpic := wrapPerIPConn(s, c)\n\t\t\tif pic == nil {\n\t\t\t\tif time.Since(*lastPerIPErrorTime) > time.Minute {\n\t\t\t\t\ts.logger().Printf(\"The number of connections from %s exceeds MaxConnsPerIP=%d\",\n\t\t\t\t\t\tgetConnIP4(c), s.MaxConnsPerIP)\n\t\t\t\t\t*lastPerIPErrorTime = time.Now()\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tc = pic\n\t\t}\n\t\treturn c, nil\n\t}\n}\n\nfunc wrapPerIPConn(s *Server, c net.Conn) net.Conn {\n\tip := getUint32IP(c)\n\tif ip == 0 {\n\t\treturn c\n\t}\n\tn := s.perIPConnCounter.Register(ip)\n\tif n > s.MaxConnsPerIP {\n\t\ts.perIPConnCounter.Unregister(ip)\n\t\ts.writeFastError(c, StatusTooManyRequests, \"The number of connections from your ip exceeds MaxConnsPerIP\")\n\t\tc.Close()\n\t\treturn nil\n\t}\n\treturn acquirePerIPConn(c, ip, &s.perIPConnCounter)\n}\n\nvar defaultLogger = Logger(log.New(os.Stderr, \"\", log.LstdFlags))\n\nfunc (s *Server) logger() Logger {\n\tif s.Logger != nil {\n\t\treturn s.Logger\n\t}\n\treturn defaultLogger\n}\n\nvar (\n\t// ErrPerIPConnLimit may be returned from ServeConn if the number of connections\n\t// per ip exceeds Server.MaxConnsPerIP.\n\tErrPerIPConnLimit = errors.New(\"too many connections per ip\")\n\n\t// ErrConcurrencyLimit may be returned from ServeConn if the number\n\t// of concurrently served connections exceeds Server.Concurrency.\n\tErrConcurrencyLimit = errors.New(\"cannot serve the connection because Server.Concurrency concurrent connections are served\")\n)\n\n// ServeConn serves HTTP requests from the given connection.\n//\n// ServeConn returns nil if all requests from the c are successfully served.\n// It returns non-nil error otherwise.\n//\n// Connection c must immediately propagate all the data passed to Write()\n// to the client. Otherwise requests' processing may hang.\n//\n// ServeConn closes c before returning.\nfunc (s *Server) ServeConn(c net.Conn) error {\n\tif s.MaxConnsPerIP > 0 {\n\t\tpic := wrapPerIPConn(s, c)\n\t\tif pic == nil {\n\t\t\treturn ErrPerIPConnLimit\n\t\t}\n\t\tc = pic\n\t}\n\n\tn := atomic.AddUint32(&s.concurrency, 1)\n\tif n > uint32(s.getConcurrency()) {\n\t\tatomic.AddUint32(&s.concurrency, ^uint32(0))\n\t\ts.writeFastError(c, StatusServiceUnavailable, \"The connection cannot be served because Server.Concurrency limit exceeded\")\n\t\tc.Close()\n\t\treturn ErrConcurrencyLimit\n\t}\n\n\tatomic.AddInt32(&s.open, 1)\n\n\terr := s.serveConn(c)\n\n\tatomic.AddUint32(&s.concurrency, ^uint32(0))\n\n\tif err != errHijacked {\n\t\terr1 := c.Close()\n\t\ts.setState(c, StateClosed)\n\t\tif err == nil {\n\t\t\terr = err1\n\t\t}\n\t} else {\n\t\terr = nil\n\t\ts.setState(c, StateHijacked)\n\t}\n\treturn err\n}\n\nvar errHijacked = errors.New(\"connection has been hijacked\")\n\n// GetCurrentConcurrency returns a number of currently served\n// connections.\n//\n// This function is intended be used by monitoring systems\nfunc (s *Server) GetCurrentConcurrency() uint32 {\n\treturn atomic.LoadUint32(&s.concurrency)\n}\n\n// GetOpenConnectionsCount returns a number of opened connections.\n//\n// This function is intended be used by monitoring systems\nfunc (s *Server) GetOpenConnectionsCount() int32 {\n\tif atomic.LoadInt32(&s.stop) == 0 {\n\t\t// Decrement by one to avoid reporting the extra open value that gets\n\t\t// counted while the server is listening.\n\t\treturn atomic.LoadInt32(&s.open) - 1\n\t}\n\t// This is not perfect, because s.stop could have changed to zero\n\t// before we load the value of s.open. However, in the common case\n\t// this avoids underreporting open connections by 1 during server shutdown.\n\treturn atomic.LoadInt32(&s.open)\n}\n\nfunc (s *Server) getConcurrency() int {\n\tn := s.Concurrency\n\tif n <= 0 {\n\t\tn = DefaultConcurrency\n\t}\n\treturn n\n}\n\nvar globalConnID uint64\n\nfunc nextConnID() uint64 {\n\treturn atomic.AddUint64(&globalConnID, 1)\n}\n\n// DefaultMaxRequestBodySize is the maximum request body size the server\n// reads by default.\n//\n// See Server.MaxRequestBodySize for details.\nconst DefaultMaxRequestBodySize = 4 * 1024 * 1024\n\nfunc (s *Server) idleTimeout() time.Duration {\n\tif s.IdleTimeout != 0 {\n\t\treturn s.IdleTimeout\n\t}\n\treturn s.ReadTimeout\n}\n\nfunc (s *Server) serveConnCleanup() {\n\tatomic.AddInt32(&s.open, -1)\n\tatomic.AddUint32(&s.concurrency, ^uint32(0))\n}\n\nfunc (s *Server) serveConn(c net.Conn) (err error) {\n\tdefer s.serveConnCleanup()\n\tatomic.AddUint32(&s.concurrency, 1)\n\n\tvar proto string\n\tif proto, err = s.getNextProto(c); err != nil {\n\t\treturn\n\t}\n\tif handler, ok := s.nextProtos[proto]; ok {\n\t\t// Remove read or write deadlines that might have previously been set.\n\t\t// The next handler is responsible for setting its own deadlines.\n\t\tif s.ReadTimeout > 0 || s.WriteTimeout > 0 {\n\t\t\tif err := c.SetDeadline(zeroTime); err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetDeadline(zeroTime): %s\", err))\n\t\t\t}\n\t\t}\n\n\t\treturn handler(c)\n\t}\n\n\tvar serverName []byte\n\tif !s.NoDefaultServerHeader {\n\t\tserverName = s.getServerName()\n\t}\n\tconnRequestNum := uint64(0)\n\tconnID := nextConnID()\n\tconnTime := time.Now()\n\tmaxRequestBodySize := s.MaxRequestBodySize\n\tif maxRequestBodySize <= 0 {\n\t\tmaxRequestBodySize = DefaultMaxRequestBodySize\n\t}\n\twriteTimeout := s.WriteTimeout\n\tpreviousWriteTimeout := time.Duration(0)\n\n\tctx := s.acquireCtx(c)\n\tctx.connTime = connTime\n\tisTLS := ctx.IsTLS()\n\tvar (\n\t\tbr *bufio.Reader\n\t\tbw *bufio.Writer\n\n\t\ttimeoutResponse  *Response\n\t\thijackHandler    HijackHandler\n\t\thijackNoResponse bool\n\n\t\tconnectionClose bool\n\t\tisHTTP11        bool\n\n\t\tcontinueReadingRequest bool = true\n\t)\n\tfor {\n\t\tconnRequestNum++\n\n\t\t// If this is a keep-alive connection set the idle timeout.\n\t\tif connRequestNum > 1 {\n\t\t\tif d := s.idleTimeout(); d > 0 {\n\t\t\t\tif err := c.SetReadDeadline(time.Now().Add(d)); err != nil {\n\t\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetReadDeadline(%s): %s\", d, err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif !s.ReduceMemoryUsage || br != nil {\n\t\t\tif br == nil {\n\t\t\t\tbr = acquireReader(ctx)\n\t\t\t}\n\n\t\t\t// If this is a keep-alive connection we want to try and read the first bytes\n\t\t\t// within the idle time.\n\t\t\tif connRequestNum > 1 {\n\t\t\t\tvar b []byte\n\t\t\t\tb, err = br.Peek(1)\n\t\t\t\tif len(b) == 0 {\n\t\t\t\t\t// If reading from a keep-alive connection returns nothing it means\n\t\t\t\t\t// the connection was closed (either timeout or from the other side).\n\t\t\t\t\tif err != io.EOF {\n\t\t\t\t\t\terr = ErrNothingRead{err}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t// If this is a keep-alive connection acquireByteReader will try to peek\n\t\t\t// a couple of bytes already so the idle timeout will already be used.\n\t\t\tbr, err = acquireByteReader(&ctx)\n\t\t}\n\n\t\tctx.Request.isTLS = isTLS\n\t\tctx.Response.Header.noDefaultContentType = s.NoDefaultContentType\n\t\tctx.Response.Header.noDefaultDate = s.NoDefaultDate\n\n\t\t// Secure header error logs configuration\n\t\tctx.Request.Header.secureErrorLogMessage = s.SecureErrorLogMessage\n\t\tctx.Response.Header.secureErrorLogMessage = s.SecureErrorLogMessage\n\t\tctx.Request.secureErrorLogMessage = s.SecureErrorLogMessage\n\t\tctx.Response.secureErrorLogMessage = s.SecureErrorLogMessage\n\n\t\tif err == nil {\n\t\t\tif s.ReadTimeout > 0 {\n\t\t\t\tif err := c.SetReadDeadline(time.Now().Add(s.ReadTimeout)); err != nil {\n\t\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetReadDeadline(%s): %s\", s.ReadTimeout, err))\n\t\t\t\t}\n\t\t\t} else if s.IdleTimeout > 0 && connRequestNum > 1 {\n\t\t\t\t// If this was an idle connection and the server has an IdleTimeout but\n\t\t\t\t// no ReadTimeout then we should remove the ReadTimeout.\n\t\t\t\tif err := c.SetReadDeadline(zeroTime); err != nil {\n\t\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetReadDeadline(zeroTime): %s\", err))\n\t\t\t\t}\n\t\t\t}\n\t\t\tif s.DisableHeaderNamesNormalizing {\n\t\t\t\tctx.Request.Header.DisableNormalizing()\n\t\t\t\tctx.Response.Header.DisableNormalizing()\n\t\t\t}\n\n\t\t\t// Reading Headers.\n\t\t\t//\n\t\t\t// If we have pipline response in the outgoing buffer,\n\t\t\t// we only want to try and read the next headers once.\n\t\t\t// If we have to wait for the next request we flush the\n\t\t\t// outgoing buffer first so it doesn't have to wait.\n\t\t\tif bw != nil && bw.Buffered() > 0 {\n\t\t\t\terr = ctx.Request.Header.readLoop(br, false)\n\t\t\t\tif err == errNeedMore {\n\t\t\t\t\terr = bw.Flush()\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\n\t\t\t\t\terr = ctx.Request.Header.Read(br)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\terr = ctx.Request.Header.Read(br)\n\t\t\t}\n\n\t\t\tif err == nil {\n\t\t\t\tif onHdrRecv := s.HeaderReceived; onHdrRecv != nil {\n\t\t\t\t\treqConf := onHdrRecv(&ctx.Request.Header)\n\t\t\t\t\tif reqConf.ReadTimeout > 0 {\n\t\t\t\t\t\tdeadline := time.Now().Add(reqConf.ReadTimeout)\n\t\t\t\t\t\tif err := c.SetReadDeadline(deadline); err != nil {\n\t\t\t\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetReadDeadline(%s): %s\", deadline, err))\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif reqConf.MaxRequestBodySize > 0 {\n\t\t\t\t\t\tmaxRequestBodySize = reqConf.MaxRequestBodySize\n\t\t\t\t\t}\n\t\t\t\t\tif reqConf.WriteTimeout > 0 {\n\t\t\t\t\t\twriteTimeout = reqConf.WriteTimeout\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//read body\n\t\t\t\tif s.StreamRequestBody {\n\t\t\t\t\terr = ctx.Request.readBodyStream(br, maxRequestBodySize, s.GetOnly, !s.DisablePreParseMultipartForm)\n\t\t\t\t} else {\n\t\t\t\t\terr = ctx.Request.readLimitBody(br, maxRequestBodySize, s.GetOnly, !s.DisablePreParseMultipartForm)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif err == nil {\n\t\t\t\t// If we read any bytes off the wire, we're active.\n\t\t\t\ts.setState(c, StateActive)\n\t\t\t}\n\n\t\t\tif (s.ReduceMemoryUsage && br.Buffered() == 0) || err != nil {\n\t\t\t\treleaseReader(s, br)\n\t\t\t\tbr = nil\n\t\t\t}\n\t\t}\n\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\terr = nil\n\t\t\t} else if nr, ok := err.(ErrNothingRead); ok {\n\t\t\t\tif connRequestNum > 1 {\n\t\t\t\t\t// This is not the first request and we haven't read a single byte\n\t\t\t\t\t// of a new request yet. This means it's just a keep-alive connection\n\t\t\t\t\t// closing down either because the remote closed it or because\n\t\t\t\t\t// or a read timeout on our side. Either way just close the connection\n\t\t\t\t\t// and don't return any error response.\n\t\t\t\t\terr = nil\n\t\t\t\t} else {\n\t\t\t\t\terr = nr.error\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif err != nil {\n\t\t\t\tbw = s.writeErrorResponse(bw, ctx, serverName, err)\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\n\t\t// 'Expect: 100-continue' request handling.\n\t\t// See https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.2.3 for details.\n\t\tif ctx.Request.MayContinue() {\n\n\t\t\t// Allow the ability to deny reading the incoming request body\n\t\t\tif s.ContinueHandler != nil {\n\t\t\t\tif continueReadingRequest = s.ContinueHandler(&ctx.Request.Header); !continueReadingRequest {\n\t\t\t\t\tif br != nil {\n\t\t\t\t\t\tbr.Reset(ctx.c)\n\t\t\t\t\t}\n\n\t\t\t\t\tctx.SetStatusCode(StatusExpectationFailed)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif continueReadingRequest {\n\t\t\t\tif bw == nil {\n\t\t\t\t\tbw = acquireWriter(ctx)\n\t\t\t\t}\n\n\t\t\t\t// Send 'HTTP/1.1 100 Continue' response.\n\t\t\t\t_, err = bw.Write(strResponseContinue)\n\t\t\t\tif err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\terr = bw.Flush()\n\t\t\t\tif err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tif s.ReduceMemoryUsage {\n\t\t\t\t\treleaseWriter(s, bw)\n\t\t\t\t\tbw = nil\n\t\t\t\t}\n\n\t\t\t\t// Read request body.\n\t\t\t\tif br == nil {\n\t\t\t\t\tbr = acquireReader(ctx)\n\t\t\t\t}\n\n\t\t\t\tif s.StreamRequestBody {\n\t\t\t\t\terr = ctx.Request.ContinueReadBodyStream(br, maxRequestBodySize, !s.DisablePreParseMultipartForm)\n\t\t\t\t} else {\n\t\t\t\t\terr = ctx.Request.ContinueReadBody(br, maxRequestBodySize, !s.DisablePreParseMultipartForm)\n\t\t\t\t}\n\t\t\t\tif (s.ReduceMemoryUsage && br.Buffered() == 0) || err != nil {\n\t\t\t\t\treleaseReader(s, br)\n\t\t\t\t\tbr = nil\n\t\t\t\t}\n\t\t\t\tif err != nil {\n\t\t\t\t\tbw = s.writeErrorResponse(bw, ctx, serverName, err)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tconnectionClose = s.DisableKeepalive || ctx.Request.Header.ConnectionClose()\n\t\tisHTTP11 = ctx.Request.Header.IsHTTP11()\n\n\t\tif serverName != nil {\n\t\t\tctx.Response.Header.SetServerBytes(serverName)\n\t\t}\n\t\tctx.connID = connID\n\t\tctx.connRequestNum = connRequestNum\n\t\tctx.time = time.Now()\n\n\t\t// If a client denies a request the handler should not be called\n\t\tif continueReadingRequest {\n\t\t\ts.Handler(ctx)\n\t\t}\n\n\t\ttimeoutResponse = ctx.timeoutResponse\n\t\tif timeoutResponse != nil {\n\t\t\t// Acquire a new ctx because the old one will still be in use by the timeout out handler.\n\t\t\tctx = s.acquireCtx(c)\n\t\t\ttimeoutResponse.CopyTo(&ctx.Response)\n\t\t}\n\n\t\tif ctx.IsHead() {\n\t\t\tctx.Response.SkipBody = true\n\t\t}\n\n\t\thijackHandler = ctx.hijackHandler\n\t\tctx.hijackHandler = nil\n\t\thijackNoResponse = ctx.hijackNoResponse && hijackHandler != nil\n\t\tctx.hijackNoResponse = false\n\n\t\tif s.MaxRequestsPerConn > 0 && connRequestNum >= uint64(s.MaxRequestsPerConn) {\n\t\t\tctx.SetConnectionClose()\n\t\t}\n\n\t\tif writeTimeout > 0 {\n\t\t\tif err := c.SetWriteDeadline(time.Now().Add(writeTimeout)); err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetWriteDeadline(%s): %s\", writeTimeout, err))\n\t\t\t}\n\t\t\tpreviousWriteTimeout = writeTimeout\n\t\t} else if previousWriteTimeout > 0 {\n\t\t\t// We don't want a write timeout but we previously set one, remove it.\n\t\t\tif err := c.SetWriteDeadline(zeroTime); err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\"BUG: error in SetWriteDeadline(zeroTime): %s\", err))\n\t\t\t}\n\t\t\tpreviousWriteTimeout = 0\n\t\t}\n\n\t\tconnectionClose = connectionClose || ctx.Response.ConnectionClose() || (s.CloseOnShutdown && atomic.LoadInt32(&s.stop) == 1)\n\t\tif connectionClose {\n\t\t\tctx.Response.Header.SetCanonical(strConnection, strClose)\n\t\t} else if !isHTTP11 {\n\t\t\t// Set 'Connection: keep-alive' response header for non-HTTP/1.1 request.\n\t\t\t// There is no need in setting this header for http/1.1, since in http/1.1\n\t\t\t// connections are keep-alive by default.\n\t\t\tctx.Response.Header.SetCanonical(strConnection, strKeepAlive)\n\t\t}\n\n\t\tif serverName != nil && len(ctx.Response.Header.Server()) == 0 {\n\t\t\tctx.Response.Header.SetServerBytes(serverName)\n\t\t}\n\n\t\tif !hijackNoResponse {\n\t\t\tif bw == nil {\n\t\t\t\tbw = acquireWriter(ctx)\n\t\t\t}\n\t\t\tif err = writeResponse(ctx, bw); err != nil {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Only flush the writer if we don't have another request in the pipeline.\n\t\t\t// This is a big of an ugly optimization for https://www.techempower.com/benchmarks/\n\t\t\t// This benchmark will send 16 pipelined requests. It is faster to pack as many responses\n\t\t\t// in a TCP packet and send it back at once than waiting for a flush every request.\n\t\t\t// In real world circumstances this behaviour could be argued as being wrong.\n\t\t\tif br == nil || br.Buffered() == 0 || connectionClose {\n\t\t\t\terr = bw.Flush()\n\t\t\t\tif err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif connectionClose {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif s.ReduceMemoryUsage && hijackHandler == nil {\n\t\t\t\treleaseWriter(s, bw)\n\t\t\t\tbw = nil\n\t\t\t}\n\t\t}\n\n\t\tif hijackHandler != nil {\n\t\t\tvar hjr io.Reader = c\n\t\t\tif br != nil {\n\t\t\t\thjr = br\n\t\t\t\tbr = nil\n\t\t\t}\n\t\t\tif bw != nil {\n\t\t\t\terr = bw.Flush()\n\t\t\t\tif err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\treleaseWriter(s, bw)\n\t\t\t\tbw = nil\n\t\t\t}\n\t\t\terr = c.SetDeadline(zeroTime)\n\t\t\tif err != nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tgo hijackConnHandler(ctx, hjr, c, s, hijackHandler)\n\t\t\terr = errHijacked\n\t\t\tbreak\n\t\t}\n\n\t\tif ctx.Request.bodyStream != nil {\n\t\t\tif rs, ok := ctx.Request.bodyStream.(*requestStream); ok {\n\t\t\t\treleaseRequestStream(rs)\n\t\t\t}\n\t\t}\n\n\t\ts.setState(c, StateIdle)\n\t\tctx.userValues.Reset()\n\t\tctx.Request.Reset()\n\t\tctx.Response.Reset()\n\n\t\tif atomic.LoadInt32(&s.stop) == 1 {\n\t\t\terr = nil\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif br != nil {\n\t\treleaseReader(s, br)\n\t}\n\tif bw != nil {\n\t\treleaseWriter(s, bw)\n\t}\n\tif hijackHandler == nil {\n\t\ts.releaseCtx(ctx)\n\t}\n\n\treturn\n}\n\nfunc (s *Server) setState(nc net.Conn, state ConnState) {\n\ts.trackConn(nc, state)\n\tif hook := s.ConnState; hook != nil {\n\t\thook(nc, state)\n\t}\n}\n\nfunc hijackConnHandler(ctx *RequestCtx, r io.Reader, c net.Conn, s *Server, h HijackHandler) {\n\thjc := s.acquireHijackConn(r, c)\n\th(hjc)\n\n\tif br, ok := r.(*bufio.Reader); ok {\n\t\treleaseReader(s, br)\n\t}\n\tif !s.KeepHijackedConns {\n\t\tc.Close()\n\t\ts.releaseHijackConn(hjc)\n\t}\n\ts.releaseCtx(ctx)\n}\n\nfunc (s *Server) acquireHijackConn(r io.Reader, c net.Conn) *hijackConn {\n\tv := s.hijackConnPool.Get()\n\tif v == nil {\n\t\thjc := &hijackConn{\n\t\t\tConn: c,\n\t\t\tr:    r,\n\t\t\ts:    s,\n\t\t}\n\t\treturn hjc\n\t}\n\thjc := v.(*hijackConn)\n\thjc.Conn = c\n\thjc.r = r\n\treturn hjc\n}\n\nfunc (s *Server) releaseHijackConn(hjc *hijackConn) {\n\thjc.Conn = nil\n\thjc.r = nil\n\ts.hijackConnPool.Put(hjc)\n}\n\ntype hijackConn struct {\n\tnet.Conn\n\tr io.Reader\n\ts *Server\n}\n\nfunc (c *hijackConn) UnsafeConn() net.Conn {\n\treturn c.Conn\n}\n\nfunc (c *hijackConn) Read(p []byte) (int, error) {\n\treturn c.r.Read(p)\n}\n\nfunc (c *hijackConn) Close() error {\n\tif !c.s.KeepHijackedConns {\n\t\t// when we do not keep hijacked connections,\n\t\t// it is closed in hijackConnHandler.\n\t\treturn nil\n\t}\n\n\tconn := c.Conn\n\tc.s.releaseHijackConn(c)\n\treturn conn.Close()\n}\n\n// LastTimeoutErrorResponse returns the last timeout response set\n// via TimeoutError* call.\n//\n// This function is intended for custom server implementations.\nfunc (ctx *RequestCtx) LastTimeoutErrorResponse() *Response {\n\treturn ctx.timeoutResponse\n}\n\nfunc writeResponse(ctx *RequestCtx, w *bufio.Writer) error {\n\tif ctx.timeoutResponse != nil {\n\t\tpanic(\"BUG: cannot write timed out response\")\n\t}\n\terr := ctx.Response.Write(w)\n\n\treturn err\n}\n\nconst (\n\tdefaultReadBufferSize  = 4096\n\tdefaultWriteBufferSize = 4096\n)\n\nfunc acquireByteReader(ctxP **RequestCtx) (*bufio.Reader, error) {\n\tctx := *ctxP\n\ts := ctx.s\n\tc := ctx.c\n\ts.releaseCtx(ctx)\n\n\t// Make GC happy, so it could garbage collect ctx\n\t// while we waiting for the next request.\n\tctx = nil\n\t*ctxP = nil\n\n\tvar b [1]byte\n\tn, err := c.Read(b[:])\n\n\tctx = s.acquireCtx(c)\n\t*ctxP = ctx\n\tif err != nil {\n\t\t// Treat all errors as EOF on unsuccessful read\n\t\t// of the first request byte.\n\t\treturn nil, io.EOF\n\t}\n\tif n != 1 {\n\t\tpanic(\"BUG: Reader must return at least one byte\")\n\t}\n\n\tctx.fbr.c = c\n\tctx.fbr.ch = b[0]\n\tctx.fbr.byteRead = false\n\tr := acquireReader(ctx)\n\tr.Reset(&ctx.fbr)\n\treturn r, nil\n}\n\nfunc acquireReader(ctx *RequestCtx) *bufio.Reader {\n\tv := ctx.s.readerPool.Get()\n\tif v == nil {\n\t\tn := ctx.s.ReadBufferSize\n\t\tif n <= 0 {\n\t\t\tn = defaultReadBufferSize\n\t\t}\n\t\treturn bufio.NewReaderSize(ctx.c, n)\n\t}\n\tr := v.(*bufio.Reader)\n\tr.Reset(ctx.c)\n\treturn r\n}\n\nfunc releaseReader(s *Server, r *bufio.Reader) {\n\ts.readerPool.Put(r)\n}\n\nfunc acquireWriter(ctx *RequestCtx) *bufio.Writer {\n\tv := ctx.s.writerPool.Get()\n\tif v == nil {\n\t\tn := ctx.s.WriteBufferSize\n\t\tif n <= 0 {\n\t\t\tn = defaultWriteBufferSize\n\t\t}\n\t\treturn bufio.NewWriterSize(ctx.c, n)\n\t}\n\tw := v.(*bufio.Writer)\n\tw.Reset(ctx.c)\n\treturn w\n}\n\nfunc releaseWriter(s *Server, w *bufio.Writer) {\n\ts.writerPool.Put(w)\n}\n\nfunc (s *Server) acquireCtx(c net.Conn) (ctx *RequestCtx) {\n\tv := s.ctxPool.Get()\n\tif v == nil {\n\t\tkeepBodyBuffer := !s.ReduceMemoryUsage\n\n\t\tctx = new(RequestCtx)\n\t\tctx.Request.keepBodyBuffer = keepBodyBuffer\n\t\tctx.Response.keepBodyBuffer = keepBodyBuffer\n\t} else {\n\t\tctx = v.(*RequestCtx)\n\t}\n\n\tctx.s = s\n\tctx.c = c\n\n\treturn ctx\n}\n\n// Init2 prepares ctx for passing to RequestHandler.\n//\n// conn is used only for determining local and remote addresses.\n//\n// This function is intended for custom Server implementations.\n// See https://github.com/valyala/httpteleport for details.\nfunc (ctx *RequestCtx) Init2(conn net.Conn, logger Logger, reduceMemoryUsage bool) {\n\tctx.c = conn\n\tctx.remoteAddr = nil\n\tctx.logger.logger = logger\n\tctx.connID = nextConnID()\n\tctx.s = fakeServer\n\tctx.connRequestNum = 0\n\tctx.connTime = time.Now()\n\n\tkeepBodyBuffer := !reduceMemoryUsage\n\tctx.Request.keepBodyBuffer = keepBodyBuffer\n\tctx.Response.keepBodyBuffer = keepBodyBuffer\n}\n\n// Init prepares ctx for passing to RequestHandler.\n//\n// remoteAddr and logger are optional. They are used by RequestCtx.Logger().\n//\n// This function is intended for custom Server implementations.\nfunc (ctx *RequestCtx) Init(req *Request, remoteAddr net.Addr, logger Logger) {\n\tif remoteAddr == nil {\n\t\tremoteAddr = zeroTCPAddr\n\t}\n\tc := &fakeAddrer{\n\t\tladdr: zeroTCPAddr,\n\t\traddr: remoteAddr,\n\t}\n\tif logger == nil {\n\t\tlogger = defaultLogger\n\t}\n\tctx.Init2(c, logger, true)\n\treq.CopyTo(&ctx.Request)\n}\n\n// Deadline returns the time when work done on behalf of this context\n// should be canceled. Deadline returns ok==false when no deadline is\n// set. Successive calls to Deadline return the same results.\n//\n// This method always returns 0, false and is only present to make\n// RequestCtx implement the context interface.\nfunc (ctx *RequestCtx) Deadline() (deadline time.Time, ok bool) {\n\treturn\n}\n\n// Done returns a channel that's closed when work done on behalf of this\n// context should be canceled. Done may return nil if this context can\n// never be canceled. Successive calls to Done return the same value.\nfunc (ctx *RequestCtx) Done() <-chan struct{} {\n\treturn ctx.s.done\n}\n\n// Err returns a non-nil error value after Done is closed,\n// successive calls to Err return the same error.\n// If Done is not yet closed, Err returns nil.\n// If Done is closed, Err returns a non-nil error explaining why:\n// Canceled if the context was canceled (via server Shutdown)\n// or DeadlineExceeded if the context's deadline passed.\nfunc (ctx *RequestCtx) Err() error {\n\tselect {\n\tcase <-ctx.s.done:\n\t\treturn context.Canceled\n\tdefault:\n\t\treturn nil\n\t}\n}\n\n// Value returns the value associated with this context for key, or nil\n// if no value is associated with key. Successive calls to Value with\n// the same key returns the same result.\n//\n// This method is present to make RequestCtx implement the context interface.\n// This method is the same as calling ctx.UserValue(key)\nfunc (ctx *RequestCtx) Value(key interface{}) interface{} {\n\tif keyString, ok := key.(string); ok {\n\t\treturn ctx.UserValue(keyString)\n\t}\n\treturn nil\n}\n\nvar fakeServer = &Server{\n\t// Initialize concurrencyCh for TimeoutHandler\n\tconcurrencyCh: make(chan struct{}, DefaultConcurrency),\n}\n\ntype fakeAddrer struct {\n\tnet.Conn\n\tladdr net.Addr\n\traddr net.Addr\n}\n\nfunc (fa *fakeAddrer) RemoteAddr() net.Addr {\n\treturn fa.raddr\n}\n\nfunc (fa *fakeAddrer) LocalAddr() net.Addr {\n\treturn fa.laddr\n}\n\nfunc (fa *fakeAddrer) Read(p []byte) (int, error) {\n\tpanic(\"BUG: unexpected Read call\")\n}\n\nfunc (fa *fakeAddrer) Write(p []byte) (int, error) {\n\tpanic(\"BUG: unexpected Write call\")\n}\n\nfunc (fa *fakeAddrer) Close() error {\n\tpanic(\"BUG: unexpected Close call\")\n}\n\nfunc (s *Server) releaseCtx(ctx *RequestCtx) {\n\tif ctx.timeoutResponse != nil {\n\t\tpanic(\"BUG: cannot release timed out RequestCtx\")\n\t}\n\n\tctx.reset()\n\ts.ctxPool.Put(ctx)\n}\n\nfunc (s *Server) getServerName() []byte {\n\tv := s.serverName.Load()\n\tvar serverName []byte\n\tif v == nil {\n\t\tserverName = []byte(s.Name)\n\t\tif len(serverName) == 0 {\n\t\t\tserverName = defaultServerName\n\t\t}\n\t\ts.serverName.Store(serverName)\n\t} else {\n\t\tserverName = v.([]byte)\n\t}\n\treturn serverName\n}\n\nfunc (s *Server) writeFastError(w io.Writer, statusCode int, msg string) {\n\tw.Write(formatStatusLine(nil, strHTTP11, statusCode, s2b(StatusMessage(statusCode)))) //nolint:errcheck\n\n\tserver := \"\"\n\tif !s.NoDefaultServerHeader {\n\t\tserver = fmt.Sprintf(\"Server: %s\\r\\n\", s.getServerName())\n\t}\n\n\tdate := \"\"\n\tif !s.NoDefaultDate {\n\t\tserverDateOnce.Do(updateServerDate)\n\t\tdate = fmt.Sprintf(\"Date: %s\\r\\n\", serverDate.Load())\n\t}\n\n\tfmt.Fprintf(w, \"Connection: close\\r\\n\"+\n\t\tserver+\n\t\tdate+\n\t\t\"Content-Type: text/plain\\r\\n\"+\n\t\t\"Content-Length: %d\\r\\n\"+\n\t\t\"\\r\\n\"+\n\t\t\"%s\",\n\t\tlen(msg), msg)\n}\n\nfunc defaultErrorHandler(ctx *RequestCtx, err error) {\n\tif _, ok := err.(*ErrSmallBuffer); ok {\n\t\tctx.Error(\"Too big request header\", StatusRequestHeaderFieldsTooLarge)\n\t} else if netErr, ok := err.(*net.OpError); ok && netErr.Timeout() {\n\t\tctx.Error(\"Request timeout\", StatusRequestTimeout)\n\t} else {\n\t\tctx.Error(\"Error when parsing request\", StatusBadRequest)\n\t}\n}\n\nfunc (s *Server) writeErrorResponse(bw *bufio.Writer, ctx *RequestCtx, serverName []byte, err error) *bufio.Writer {\n\terrorHandler := defaultErrorHandler\n\tif s.ErrorHandler != nil {\n\t\terrorHandler = s.ErrorHandler\n\t}\n\n\terrorHandler(ctx, err)\n\n\tif serverName != nil {\n\t\tctx.Response.Header.SetServerBytes(serverName)\n\t}\n\tctx.SetConnectionClose()\n\tif bw == nil {\n\t\tbw = acquireWriter(ctx)\n\t}\n\n\twriteResponse(ctx, bw) //nolint:errcheck\n\tctx.Response.Reset()\n\tbw.Flush()\n\n\treturn bw\n}\n\nfunc (s *Server) trackConn(c net.Conn, state ConnState) {\n\ts.idleConnsMu.Lock()\n\tswitch state {\n\tcase StateIdle:\n\t\tif s.idleConns == nil {\n\t\t\ts.idleConns = make(map[net.Conn]struct{})\n\t\t}\n\t\ts.idleConns[c] = struct{}{}\n\n\tdefault:\n\t\tdelete(s.idleConns, c)\n\t}\n\ts.idleConnsMu.Unlock()\n}\n\nfunc (s *Server) closeIdleConns() {\n\ts.idleConnsMu.Lock()\n\tfor c := range s.idleConns {\n\t\t_ = c.Close()\n\t}\n\ts.idleConns = nil\n\ts.idleConnsMu.Unlock()\n}\n\n// A ConnState represents the state of a client connection to a server.\n// It's used by the optional Server.ConnState hook.\ntype ConnState int\n\nconst (\n\t// StateNew represents a new connection that is expected to\n\t// send a request immediately. Connections begin at this\n\t// state and then transition to either StateActive or\n\t// StateClosed.\n\tStateNew ConnState = iota\n\n\t// StateActive represents a connection that has read 1 or more\n\t// bytes of a request. The Server.ConnState hook for\n\t// StateActive fires before the request has entered a handler\n\t// and doesn't fire again until the request has been\n\t// handled. After the request is handled, the state\n\t// transitions to StateClosed, StateHijacked, or StateIdle.\n\t// For HTTP/2, StateActive fires on the transition from zero\n\t// to one active request, and only transitions away once all\n\t// active requests are complete. That means that ConnState\n\t// cannot be used to do per-request work; ConnState only notes\n\t// the overall state of the connection.\n\tStateActive\n\n\t// StateIdle represents a connection that has finished\n\t// handling a request and is in the keep-alive state, waiting\n\t// for a new request. Connections transition from StateIdle\n\t// to either StateActive or StateClosed.\n\tStateIdle\n\n\t// StateHijacked represents a hijacked connection.\n\t// This is a terminal state. It does not transition to StateClosed.\n\tStateHijacked\n\n\t// StateClosed represents a closed connection.\n\t// This is a terminal state. Hijacked connections do not\n\t// transition to StateClosed.\n\tStateClosed\n)\n\nvar stateName = map[ConnState]string{\n\tStateNew:      \"new\",\n\tStateActive:   \"active\",\n\tStateIdle:     \"idle\",\n\tStateHijacked: \"hijacked\",\n\tStateClosed:   \"closed\",\n}\n\nfunc (c ConnState) String() string {\n\treturn stateName[c]\n}\n"], "filenames": ["fs.go", "server.go"], "buggy_code_start_loc": [32, 1340], "buggy_code_end_loc": [81, 1351], "fixing_code_start_loc": [33, 1341], "fixing_code_end_loc": [98, 1360], "type": "CWE-22", "message": "The package github.com/valyala/fasthttp before 1.34.0 are vulnerable to Directory Traversal via the ServeFile function, due to improper sanitization. It is possible to be exploited by using a backslash %5c character in the path. **Note:** This security issue impacts Windows users only.", "other": {"cve": {"id": "CVE-2022-21221", "sourceIdentifier": "report@snyk.io", "published": "2022-03-17T12:15:08.087", "lastModified": "2022-03-24T02:27:51.290", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The package github.com/valyala/fasthttp before 1.34.0 are vulnerable to Directory Traversal via the ServeFile function, due to improper sanitization. It is possible to be exploited by using a backslash %5c character in the path. **Note:** This security issue impacts Windows users only."}, {"lang": "es", "value": "El paquete github.com/valyala/fasthttp versiones anteriores a 1.34.0, es vulnerable a un Salto de Directorio por medio de la funci\u00f3n ServeFile, debido a un saneo inapropiado. Puede explotarse usando un car\u00e1cter de barra invertida %5c en la ruta. **Nota:** Este problema de seguridad afecta \u00fanicamente a usuarios de Windows"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "report@snyk.io", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-22"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:fasthttp_project:fasthttp:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.34.0", "matchCriteriaId": "B292937C-1EF2-4FD3-B714-90714DEC82E1"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:o:microsoft:windows:-:*:*:*:*:*:*:*", "matchCriteriaId": "A2572D17-1DE6-457B-99CC-64AFD54487EA"}]}]}], "references": [{"url": "https://github.com/valyala/fasthttp/commit/15262ecf3c602364639d465daba1e7f3604d00e8", "source": "report@snyk.io", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/valyala/fasthttp/commit/6b5bc7bb304975147b4af68df54ac214ed2554c1", "source": "report@snyk.io", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/valyala/fasthttp/issues/1226", "source": "report@snyk.io", "tags": ["Exploit", "Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/valyala/fasthttp/releases/tag/v1.34.0", "source": "report@snyk.io", "tags": ["Release Notes", "Third Party Advisory"]}, {"url": "https://snyk.io/vuln/SNYK-GOLANG-GITHUBCOMVALYALAFASTHTTP-2407866", "source": "report@snyk.io", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/valyala/fasthttp/commit/15262ecf3c602364639d465daba1e7f3604d00e8"}}
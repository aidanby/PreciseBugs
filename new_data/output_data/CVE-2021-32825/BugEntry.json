{"buggy_code": ["build\ncoverage.txt\n/ostree\n\n# Compiled Object files, Static and Dynamic libs (Shared Objects)\n*.o\n*.a\n*.so\n\n# Folders\n_obj\n_test\n.docsrv-resources\n\n# Architecture specific extensions/prefixes\n*.[568vq]\n[568vq].out\n\n*.cgo1.go\n*.cgo2.c\n_cgo_defun.c\n_cgo_gotypes.go\n_cgo_export.*\n\n_testmain.go\n\n*.exe\n*.test\n*.prof\nbblfshd\nbblfshctl\n", "package runtime\n\nimport (\n\t\"archive/tar\"\n\t\"compress/gzip\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/containers/image/types\"\n\t\"github.com/pkg/errors\"\n)\n\nfunc UnpackImage(src types.Image, target string) error {\n\tref := src.Reference()\n\tunpackLayer, err := getLayerUnpacker(ref)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\traw, err := ref.NewImageSource(nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, layer := range src.LayerInfos() {\n\t\trc, _, err := raw.GetBlob(layer)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := unpackLayer(target, rc); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc getLayerUnpacker(ref types.ImageReference) (func(string, io.Reader) error, error) {\n\ttransport := ref.Transport().Name()\n\tswitch transport {\n\tcase \"docker-daemon\":\n\t\treturn untar, nil\n\tcase \"docker\":\n\t\treturn untarGzip, nil\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unsupported transport: %s\", transport)\n\t}\n}\n\nfunc untarGzip(dest string, r io.Reader) error {\n\tgz, err := gzip.NewReader(r)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"error creating gzip reader\")\n\t}\n\tdefer gz.Close()\n\n\treturn untar(dest, gz)\n}\n\nfunc untar(dest string, r io.Reader) error {\n\tentries := make(map[string]bool)\n\tvar dirs []*tar.Header\n\ttr := tar.NewReader(r)\nloop:\n\tfor {\n\t\thdr, err := tr.Next()\n\t\tswitch err {\n\t\tcase io.EOF:\n\t\t\tbreak loop\n\t\tcase nil:\n\t\t\t// success, continue below\n\t\tdefault:\n\t\t\treturn errors.Wrapf(err, \"error advancing tar stream\")\n\t\t}\n\n\t\thdr.Name = filepath.Clean(hdr.Name)\n\t\tif !strings.HasSuffix(hdr.Name, string(os.PathSeparator)) {\n\t\t\t// Not the root directory, ensure that the parent directory exists\n\t\t\tparent := filepath.Dir(hdr.Name)\n\t\t\tparentPath := filepath.Join(dest, parent)\n\t\t\tif _, err2 := os.Lstat(parentPath); err2 != nil && os.IsNotExist(err2) {\n\t\t\t\tif err3 := os.MkdirAll(parentPath, 0755); err3 != nil {\n\t\t\t\t\treturn err3\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpath := filepath.Join(dest, hdr.Name)\n\t\tif entries[path] {\n\t\t\treturn fmt.Errorf(\"duplicate entry for %s\", path)\n\t\t}\n\t\tentries[path] = true\n\t\trel, err := filepath.Rel(dest, path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tinfo := hdr.FileInfo()\n\t\tif strings.HasPrefix(rel, \"..\"+string(os.PathSeparator)) {\n\t\t\treturn fmt.Errorf(\"%q is outside of %q\", hdr.Name, dest)\n\t\t}\n\n\t\tif strings.HasPrefix(info.Name(), \".wh.\") {\n\t\t\tpath = strings.Replace(path, \".wh.\", \"\", 1)\n\n\t\t\tif err := os.RemoveAll(path); err != nil {\n\t\t\t\treturn errors.Wrap(err, \"unable to delete whiteout path\")\n\t\t\t}\n\n\t\t\tcontinue loop\n\t\t}\n\n\t\tswitch hdr.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\tif fi, err := os.Lstat(path); !(err == nil && fi.IsDir()) {\n\t\t\t\tif err2 := os.MkdirAll(path, info.Mode()); err2 != nil {\n\t\t\t\t\treturn errors.Wrap(err2, \"error creating directory\")\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase tar.TypeReg, tar.TypeRegA:\n\t\t\tf, err := os.OpenFile(path, os.O_CREATE|os.O_WRONLY, info.Mode())\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"unable to open file\")\n\t\t\t}\n\n\t\t\tif _, err := io.Copy(f, tr); err != nil {\n\t\t\t\tf.Close()\n\t\t\t\treturn errors.Wrap(err, \"unable to copy\")\n\t\t\t}\n\t\t\tf.Close()\n\n\t\tcase tar.TypeLink:\n\t\t\ttarget := filepath.Join(dest, hdr.Linkname)\n\n\t\t\tif !strings.HasPrefix(target, dest) {\n\t\t\t\treturn fmt.Errorf(\"invalid hardlink %q -> %q\", target, hdr.Linkname)\n\t\t\t}\n\n\t\t\tif err := os.Link(target, path); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\tcase tar.TypeSymlink:\n\t\t\ttarget := filepath.Join(filepath.Dir(path), hdr.Linkname)\n\n\t\t\tif !strings.HasPrefix(target, dest) {\n\t\t\t\treturn fmt.Errorf(\"invalid symlink %q -> %q\", path, hdr.Linkname)\n\t\t\t}\n\n\t\t\terr := os.Symlink(hdr.Linkname, path)\n\t\t\tif err != nil {\n\t\t\t\tif os.IsExist(err) {\n\t\t\t\t\tif err := os.Remove(path); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\n\t\t\t\t\tif err := os.Symlink(hdr.Linkname, path); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase tar.TypeXGlobalHeader:\n\t\t\treturn nil\n\t\t}\n\t\t// Directory mtimes must be handled at the end to avoid further\n\t\t// file creation in them to modify the directory mtime\n\t\tif hdr.Typeflag == tar.TypeDir {\n\t\t\tdirs = append(dirs, hdr)\n\t\t}\n\t}\n\tfor _, hdr := range dirs {\n\t\tpath := filepath.Join(dest, hdr.Name)\n\n\t\tfinfo := hdr.FileInfo()\n\t\t// I believe the old version was using time.Now().UTC() to overcome an\n\t\t// invalid error from chtimes.....but here we lose hdr.AccessTime like this...\n\t\tif err := os.Chtimes(path, time.Now().UTC(), finfo.ModTime()); err != nil {\n\t\t\treturn errors.Wrap(err, \"error changing time\")\n\t\t}\n\t}\n\treturn nil\n}\n"], "fixing_code": [".idea/\n\n\nbuild\ncoverage.txt\n/ostree\n\n# Compiled Object files, Static and Dynamic libs (Shared Objects)\n*.o\n*.a\n*.so\n\n# Folders\n_obj\n_test\n.docsrv-resources\n\n# Architecture specific extensions/prefixes\n*.[568vq]\n[568vq].out\n\n*.cgo1.go\n*.cgo2.c\n_cgo_defun.c\n_cgo_gotypes.go\n_cgo_export.*\n\n_testmain.go\n\n*.exe\n*.test\n*.prof\nbblfshd\nbblfshctl\n", "package runtime\n\nimport (\n\t\"archive/tar\"\n\t\"compress/gzip\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/containers/image/types\"\n\t\"github.com/pkg/errors\"\n)\n\nfunc UnpackImage(src types.Image, target string) error {\n\tref := src.Reference()\n\tunpackLayer, err := getLayerUnpacker(ref)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\traw, err := ref.NewImageSource(nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, layer := range src.LayerInfos() {\n\t\trc, _, err := raw.GetBlob(layer)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := unpackLayer(target, rc); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc getLayerUnpacker(ref types.ImageReference) (func(string, io.Reader) error, error) {\n\ttransport := ref.Transport().Name()\n\tswitch transport {\n\tcase \"docker-daemon\":\n\t\treturn untar, nil\n\tcase \"docker\":\n\t\treturn untarGzip, nil\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unsupported transport: %s\", transport)\n\t}\n}\n\nfunc untarGzip(dest string, r io.Reader) error {\n\tgz, err := gzip.NewReader(r)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"error creating gzip reader\")\n\t}\n\tdefer gz.Close()\n\n\treturn untar(dest, gz)\n}\n\nfunc untar(dest string, r io.Reader) error {\n\tentries := make(map[string]bool)\n\tvar dirs []*tar.Header\n\ttr := tar.NewReader(r)\nloop:\n\tfor {\n\t\thdr, err := tr.Next()\n\t\tswitch err {\n\t\tcase io.EOF:\n\t\t\tbreak loop\n\t\tcase nil:\n\t\t\t// success, continue below\n\t\tdefault:\n\t\t\treturn errors.Wrapf(err, \"error advancing tar stream\")\n\t\t}\n\n\t\thdr.Name = filepath.Clean(hdr.Name)\n\t\tif !strings.HasSuffix(hdr.Name, string(os.PathSeparator)) {\n\t\t\t// Not the root directory, ensure that the parent directory exists\n\t\t\tparent := filepath.Dir(hdr.Name)\n\t\t\tparentPath := filepath.Join(dest, parent)\n\t\t\tif _, err2 := os.Lstat(parentPath); err2 != nil && os.IsNotExist(err2) {\n\t\t\t\tif err3 := os.MkdirAll(parentPath, 0755); err3 != nil {\n\t\t\t\t\treturn err3\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpath := filepath.Join(dest, hdr.Name)\n\t\tif entries[path] {\n\t\t\treturn fmt.Errorf(\"duplicate entry for %s\", path)\n\t\t}\n\t\tentries[path] = true\n\t\trel, err := filepath.Rel(dest, path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tinfo := hdr.FileInfo()\n\t\tif strings.HasPrefix(rel, \"..\"+string(os.PathSeparator)) {\n\t\t\treturn fmt.Errorf(\"%q is outside of %q\", hdr.Name, dest)\n\t\t}\n\n\t\tif strings.HasPrefix(info.Name(), \".wh.\") {\n\t\t\tpath = strings.Replace(path, \".wh.\", \"\", 1)\n\n\t\t\tif err := os.RemoveAll(path); err != nil {\n\t\t\t\treturn errors.Wrap(err, \"unable to delete whiteout path\")\n\t\t\t}\n\n\t\t\tcontinue loop\n\t\t}\n\n\t\tswitch hdr.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\tif fi, err := os.Lstat(path); !(err == nil && fi.IsDir()) {\n\t\t\t\tif err2 := os.MkdirAll(path, info.Mode()); err2 != nil {\n\t\t\t\t\treturn errors.Wrap(err2, \"error creating directory\")\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase tar.TypeReg, tar.TypeRegA:\n\t\t\tf, err := os.OpenFile(path, os.O_CREATE|os.O_WRONLY, info.Mode())\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"unable to open file\")\n\t\t\t}\n\n\t\t\tif _, err := io.Copy(f, tr); err != nil {\n\t\t\t\tf.Close()\n\t\t\t\treturn errors.Wrap(err, \"unable to copy\")\n\t\t\t}\n\t\t\tf.Close()\n\n\t\tcase tar.TypeLink:\n\t\t\ttarget := filepath.Join(dest, hdr.Linkname)\n\n\t\t\ttrueTarget, err := filepath.EvalSymlinks(target)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif !strings.HasPrefix(trueTarget, dest) {\n\t\t\t\treturn fmt.Errorf(\"hardlink %q -> %q outside destination\", target, hdr.Linkname)\n\t\t\t}\n\n\t\t\tif !strings.HasPrefix(target, dest) {\n\t\t\t\treturn fmt.Errorf(\"invalid hardlink %q -> %q\", target, hdr.Linkname)\n\t\t\t}\n\n\t\t\tif err := os.Link(target, path); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\tcase tar.TypeSymlink:\n\t\t\ttarget := filepath.Join(filepath.Dir(path), hdr.Linkname)\n\n\t\t\ttrueTarget, err := filepath.EvalSymlinks(target)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif !strings.HasPrefix(trueTarget, dest) {\n\t\t\t\treturn fmt.Errorf(\"hardlink %q -> %q outside destination\", target, hdr.Linkname)\n\t\t\t}\n\t\t\tif !strings.HasPrefix(target, dest) {\n\t\t\t\treturn fmt.Errorf(\"invalid symlink %q -> %q\", path, hdr.Linkname)\n\t\t\t}\n\n\t\t\terr := os.Symlink(hdr.Linkname, path)\n\t\t\tif err != nil {\n\t\t\t\tif os.IsExist(err) {\n\t\t\t\t\tif err := os.Remove(path); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\n\t\t\t\t\tif err := os.Symlink(hdr.Linkname, path); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase tar.TypeXGlobalHeader:\n\t\t\treturn nil\n\t\t}\n\t\t// Directory mtimes must be handled at the end to avoid further\n\t\t// file creation in them to modify the directory mtime\n\t\tif hdr.Typeflag == tar.TypeDir {\n\t\t\tdirs = append(dirs, hdr)\n\t\t}\n\t}\n\tfor _, hdr := range dirs {\n\t\tpath := filepath.Join(dest, hdr.Name)\n\n\t\tfinfo := hdr.FileInfo()\n\t\t// I believe the old version was using time.Now().UTC() to overcome an\n\t\t// invalid error from chtimes.....but here we lose hdr.AccessTime like this...\n\t\tif err := os.Chtimes(path, time.Now().UTC(), finfo.ModTime()); err != nil {\n\t\t\treturn errors.Wrap(err, \"error changing time\")\n\t\t}\n\t}\n\treturn nil\n}\n"], "filenames": [".gitignore", "runtime/unpack.go"], "buggy_code_start_loc": [0, 138], "buggy_code_end_loc": [0, 149], "fixing_code_start_loc": [1, 139], "fixing_code_end_loc": [4, 165], "type": "CWE-59", "message": "bblfshd is an open source self-hosted server for source code parsing. In bblfshd before commit 4265465b9b6fb5663c30ee43806126012066aad4 there is a \"zipslip\" vulnerability. The unsafe handling of symbolic links in an unpacking routine may enable attackers to read and/or write to arbitrary locations outside the designated target folder. This issue may lead to arbitrary file write (with same permissions as the program running the unpack operation) if the attacker can control the archive file. Additionally, if the attacker has read access to the unpacked files, he may be able to read arbitrary system files the parent process has permissions to read. For more details including a PoC see the referenced GHSL-2020-258.", "other": {"cve": {"id": "CVE-2021-32825", "sourceIdentifier": "security-advisories@github.com", "published": "2021-08-16T19:15:14.207", "lastModified": "2022-07-02T18:22:01.657", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "bblfshd is an open source self-hosted server for source code parsing. In bblfshd before commit 4265465b9b6fb5663c30ee43806126012066aad4 there is a \"zipslip\" vulnerability. The unsafe handling of symbolic links in an unpacking routine may enable attackers to read and/or write to arbitrary locations outside the designated target folder. This issue may lead to arbitrary file write (with same permissions as the program running the unpack operation) if the attacker can control the archive file. Additionally, if the attacker has read access to the unpacked files, he may be able to read arbitrary system files the parent process has permissions to read. For more details including a PoC see the referenced GHSL-2020-258."}, {"lang": "es", "value": "bblfshd es un servidor de c\u00f3digo abierto auto-alojado para el an\u00e1lisis de c\u00f3digo fuente. En bblfshd versiones anteriores al commit 4265465b9b6fb5663c30ee43806126012066aad4 se presenta una vulnerabilidad \"zipslip\". El manejo no seguro de los enlaces simb\u00f3licos en una rutina de desempaquetado puede permitir a atacantes leer y/o escribir en ubicaciones arbitrarias fuera de la carpeta de destino designada. Este problema puede conllevar una escritura arbitraria en el archivo (con los mismos permisos que el programa que ejecuta la operaci\u00f3n de desempaquetado) si el atacante puede controlar el archivo comprimido. Adicionalmente, si el atacante presenta acceso de lectura a los archivos desempaquetados, puede ser capaz de leer archivos arbitrario del sistema que el proceso parent presenta permisos para leer. Para mayor detalles, incluyendo un PoC, vea el GHSL-2020-258 referenciado."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 9.1, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.2}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:N/UI:R/S:C/C:L/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 2.7, "baseSeverity": "LOW"}, "exploitabilityScore": 1.0, "impactScore": 1.4}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:S/C:P/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 5.5}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.0, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-59"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-23"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:bblfshd_project:bblfshd:*:*:*:*:*:*:*:*", "versionEndExcluding": "2021-08-11", "matchCriteriaId": "91C61354-2EC3-415C-9AAB-97896DF238FD"}]}]}], "references": [{"url": "https://github.com/bblfsh/bblfshd/commit/4265465b9b6fb5663c30ee43806126012066aad4", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/bblfsh/bblfshd/pull/341", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://securitylab.github.com/advisories/GHSL-2020-258-zipslip-bblfshd/", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/bblfsh/bblfshd/commit/4265465b9b6fb5663c30ee43806126012066aad4"}}
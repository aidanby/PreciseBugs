{"buggy_code": ["package commands\n\nimport (\n\t\"context\"\n\t\"crypto/sha256\"\n\t\"encoding/base64\"\n\t\"fmt\"\n\t\"html\"\n\t\"net/http\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/coreos/go-oidc\"\n\t\"github.com/golang-jwt/jwt/v4\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"github.com/skratchdot/open-golang/open\"\n\t\"github.com/spf13/cobra\"\n\t\"golang.org/x/oauth2\"\n\n\t\"github.com/argoproj/argo-cd/v2/cmd/argocd/commands/headless\"\n\targocdclient \"github.com/argoproj/argo-cd/v2/pkg/apiclient\"\n\tsessionpkg \"github.com/argoproj/argo-cd/v2/pkg/apiclient/session\"\n\tsettingspkg \"github.com/argoproj/argo-cd/v2/pkg/apiclient/settings\"\n\t\"github.com/argoproj/argo-cd/v2/util/cli\"\n\t\"github.com/argoproj/argo-cd/v2/util/errors\"\n\tgrpc_util \"github.com/argoproj/argo-cd/v2/util/grpc\"\n\t\"github.com/argoproj/argo-cd/v2/util/io\"\n\tjwtutil \"github.com/argoproj/argo-cd/v2/util/jwt\"\n\t\"github.com/argoproj/argo-cd/v2/util/localconfig\"\n\toidcutil \"github.com/argoproj/argo-cd/v2/util/oidc\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n)\n\n// NewLoginCommand returns a new instance of `argocd login` command\nfunc NewLoginCommand(globalClientOpts *argocdclient.ClientOptions) *cobra.Command {\n\tvar (\n\t\tctxName  string\n\t\tusername string\n\t\tpassword string\n\t\tsso      bool\n\t\tssoPort  int\n\t)\n\tvar command = &cobra.Command{\n\t\tUse:   \"login SERVER\",\n\t\tShort: \"Log in to Argo CD\",\n\t\tLong:  \"Log in to Argo CD\",\n\t\tExample: `# Login to Argo CD using a username and password\nargocd login cd.argoproj.io\n\n# Login to Argo CD using SSO\nargocd login cd.argoproj.io --sso\n\n# Configure direct access using Kubernetes API server\nargocd login cd.argoproj.io --core`,\n\t\tRun: func(c *cobra.Command, args []string) {\n\t\t\tvar server string\n\n\t\t\tif len(args) != 1 && !globalClientOpts.PortForward && !globalClientOpts.Core {\n\t\t\t\tc.HelpFunc()(c, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\n\t\t\tif globalClientOpts.PortForward {\n\t\t\t\tserver = \"port-forward\"\n\t\t\t} else if globalClientOpts.Core {\n\t\t\t\tserver = \"kubernetes\"\n\t\t\t} else {\n\t\t\t\tserver = args[0]\n\t\t\t\ttlsTestResult, err := grpc_util.TestTLS(server)\n\t\t\t\terrors.CheckError(err)\n\t\t\t\tif !tlsTestResult.TLS {\n\t\t\t\t\tif !globalClientOpts.PlainText {\n\t\t\t\t\t\tif !cli.AskToProceed(\"WARNING: server is not configured with TLS. Proceed (y/n)? \") {\n\t\t\t\t\t\t\tos.Exit(1)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tglobalClientOpts.PlainText = true\n\t\t\t\t\t}\n\t\t\t\t} else if tlsTestResult.InsecureErr != nil {\n\t\t\t\t\tif !globalClientOpts.Insecure {\n\t\t\t\t\t\tif !cli.AskToProceed(fmt.Sprintf(\"WARNING: server certificate had error: %s. Proceed insecurely (y/n)? \", tlsTestResult.InsecureErr)) {\n\t\t\t\t\t\t\tos.Exit(1)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tglobalClientOpts.Insecure = true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tclientOpts := argocdclient.ClientOptions{\n\t\t\t\tConfigPath:           \"\",\n\t\t\t\tServerAddr:           server,\n\t\t\t\tInsecure:             globalClientOpts.Insecure,\n\t\t\t\tPlainText:            globalClientOpts.PlainText,\n\t\t\t\tClientCertFile:       globalClientOpts.ClientCertFile,\n\t\t\t\tClientCertKeyFile:    globalClientOpts.ClientCertKeyFile,\n\t\t\t\tGRPCWeb:              globalClientOpts.GRPCWeb,\n\t\t\t\tGRPCWebRootPath:      globalClientOpts.GRPCWebRootPath,\n\t\t\t\tPortForward:          globalClientOpts.PortForward,\n\t\t\t\tPortForwardNamespace: globalClientOpts.PortForwardNamespace,\n\t\t\t\tHeaders:              globalClientOpts.Headers,\n\t\t\t\tKubeOverrides:        globalClientOpts.KubeOverrides,\n\t\t\t}\n\n\t\t\tif ctxName == \"\" {\n\t\t\t\tctxName = server\n\t\t\t\tif globalClientOpts.GRPCWebRootPath != \"\" {\n\t\t\t\t\trootPath := strings.TrimRight(strings.TrimLeft(globalClientOpts.GRPCWebRootPath, \"/\"), \"/\")\n\t\t\t\t\tctxName = fmt.Sprintf(\"%s/%s\", server, rootPath)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Perform the login\n\t\t\tvar tokenString string\n\t\t\tvar refreshToken string\n\t\t\tif !globalClientOpts.Core {\n\t\t\t\tacdClient := headless.NewClientOrDie(&clientOpts, c)\n\t\t\t\tsetConn, setIf := acdClient.NewSettingsClientOrDie()\n\t\t\t\tdefer io.Close(setConn)\n\t\t\t\tif !sso {\n\t\t\t\t\ttokenString = passwordLogin(acdClient, username, password)\n\t\t\t\t} else {\n\t\t\t\t\tctx := context.Background()\n\t\t\t\t\thttpClient, err := acdClient.HTTPClient()\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\tctx = oidc.ClientContext(ctx, httpClient)\n\t\t\t\t\tacdSet, err := setIf.Get(ctx, &settingspkg.SettingsQuery{})\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\toauth2conf, provider, err := acdClient.OIDCConfig(ctx, acdSet)\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\ttokenString, refreshToken = oauth2Login(ctx, ssoPort, acdSet.GetOIDCConfig(), oauth2conf, provider)\n\t\t\t\t}\n\t\t\t\tparser := jwt.NewParser(jwt.WithoutClaimsValidation())\n\t\t\t\tclaims := jwt.MapClaims{}\n\t\t\t\t_, _, err := parser.ParseUnverified(tokenString, &claims)\n\t\t\t\terrors.CheckError(err)\n\t\t\t\tfmt.Printf(\"'%s' logged in successfully\\n\", userDisplayName(claims))\n\t\t\t}\n\n\t\t\t// login successful. Persist the config\n\t\t\tlocalCfg, err := localconfig.ReadLocalConfig(globalClientOpts.ConfigPath)\n\t\t\terrors.CheckError(err)\n\t\t\tif localCfg == nil {\n\t\t\t\tlocalCfg = &localconfig.LocalConfig{}\n\t\t\t}\n\t\t\tlocalCfg.UpsertServer(localconfig.Server{\n\t\t\t\tServer:          server,\n\t\t\t\tPlainText:       globalClientOpts.PlainText,\n\t\t\t\tInsecure:        globalClientOpts.Insecure,\n\t\t\t\tGRPCWeb:         globalClientOpts.GRPCWeb,\n\t\t\t\tGRPCWebRootPath: globalClientOpts.GRPCWebRootPath,\n\t\t\t\tCore:            globalClientOpts.Core,\n\t\t\t})\n\t\t\tlocalCfg.UpsertUser(localconfig.User{\n\t\t\t\tName:         ctxName,\n\t\t\t\tAuthToken:    tokenString,\n\t\t\t\tRefreshToken: refreshToken,\n\t\t\t})\n\t\t\tif ctxName == \"\" {\n\t\t\t\tctxName = server\n\t\t\t}\n\t\t\tlocalCfg.CurrentContext = ctxName\n\t\t\tlocalCfg.UpsertContext(localconfig.ContextRef{\n\t\t\t\tName:   ctxName,\n\t\t\t\tUser:   ctxName,\n\t\t\t\tServer: server,\n\t\t\t})\n\t\t\terr = localconfig.WriteLocalConfig(*localCfg, globalClientOpts.ConfigPath)\n\t\t\terrors.CheckError(err)\n\t\t\tfmt.Printf(\"Context '%s' updated\\n\", ctxName)\n\t\t},\n\t}\n\tcommand.Flags().StringVar(&ctxName, \"name\", \"\", \"name to use for the context\")\n\tcommand.Flags().StringVar(&username, \"username\", \"\", \"the username of an account to authenticate\")\n\tcommand.Flags().StringVar(&password, \"password\", \"\", \"the password of an account to authenticate\")\n\tcommand.Flags().BoolVar(&sso, \"sso\", false, \"perform SSO login\")\n\tcommand.Flags().IntVar(&ssoPort, \"sso-port\", DefaultSSOLocalPort, \"port to run local OAuth2 login application\")\n\treturn command\n}\n\nfunc userDisplayName(claims jwt.MapClaims) string {\n\tif email := jwtutil.StringField(claims, \"email\"); email != \"\" {\n\t\treturn email\n\t}\n\tif name := jwtutil.StringField(claims, \"name\"); name != \"\" {\n\t\treturn name\n\t}\n\treturn jwtutil.StringField(claims, \"sub\")\n}\n\n// oauth2Login opens a browser, runs a temporary HTTP server to delegate OAuth2 login flow and\n// returns the JWT token and a refresh token (if supported)\nfunc oauth2Login(ctx context.Context, port int, oidcSettings *settingspkg.OIDCConfig, oauth2conf *oauth2.Config, provider *oidc.Provider) (string, string) {\n\toauth2conf.RedirectURL = fmt.Sprintf(\"http://localhost:%d/auth/callback\", port)\n\toidcConf, err := oidcutil.ParseConfig(provider)\n\terrors.CheckError(err)\n\tlog.Debug(\"OIDC Configuration:\")\n\tlog.Debugf(\"  supported_scopes: %v\", oidcConf.ScopesSupported)\n\tlog.Debugf(\"  response_types_supported: %v\", oidcConf.ResponseTypesSupported)\n\n\t// handledRequests ensures we do not handle more requests than necessary\n\thandledRequests := 0\n\t// completionChan is to signal flow completed. Non-empty string indicates error\n\tcompletionChan := make(chan string)\n\t// stateNonce is an OAuth2 state nonce\n\tstateNonce := rand.RandString(10)\n\tvar tokenString string\n\tvar refreshToken string\n\n\thandleErr := func(w http.ResponseWriter, errMsg string) {\n\t\thttp.Error(w, html.EscapeString(errMsg), http.StatusBadRequest)\n\t\tcompletionChan <- errMsg\n\t}\n\n\t// PKCE implementation of https://tools.ietf.org/html/rfc7636\n\tcodeVerifier := rand.RandStringCharset(43, \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~\")\n\tcodeChallengeHash := sha256.Sum256([]byte(codeVerifier))\n\tcodeChallenge := base64.RawURLEncoding.EncodeToString(codeChallengeHash[:])\n\n\t// Authorization redirect callback from OAuth2 auth flow.\n\t// Handles both implicit and authorization code flow\n\tcallbackHandler := func(w http.ResponseWriter, r *http.Request) {\n\t\tlog.Debugf(\"Callback: %s\", r.URL)\n\n\t\tif formErr := r.FormValue(\"error\"); formErr != \"\" {\n\t\t\thandleErr(w, fmt.Sprintf(\"%s: %s\", formErr, r.FormValue(\"error_description\")))\n\t\t\treturn\n\t\t}\n\n\t\thandledRequests++\n\t\tif handledRequests > 2 {\n\t\t\t// Since implicit flow will redirect back to ourselves, this counter ensures we do not\n\t\t\t// fallinto a redirect loop (e.g. user visits the page by hand)\n\t\t\thandleErr(w, \"Unable to complete login flow: too many redirects\")\n\t\t\treturn\n\t\t}\n\n\t\tif len(r.Form) == 0 {\n\t\t\t// If we get here, no form data was set. We presume to be performing an implicit login\n\t\t\t// flow where the id_token is contained in a URL fragment, making it inaccessible to be\n\t\t\t// read from the request. This javascript will redirect the browser to send the\n\t\t\t// fragments as query parameters so our callback handler can read and return token.\n\t\t\tfmt.Fprintf(w, `<script>window.location.search = window.location.hash.substring(1)</script>`)\n\t\t\treturn\n\t\t}\n\n\t\tif state := r.FormValue(\"state\"); state != stateNonce {\n\t\t\thandleErr(w, \"Unknown state nonce\")\n\t\t\treturn\n\t\t}\n\n\t\ttokenString = r.FormValue(\"id_token\")\n\t\tif tokenString == \"\" {\n\t\t\tcode := r.FormValue(\"code\")\n\t\t\tif code == \"\" {\n\t\t\t\thandleErr(w, fmt.Sprintf(\"no code in request: %q\", r.Form))\n\t\t\t\treturn\n\t\t\t}\n\t\t\topts := []oauth2.AuthCodeOption{oauth2.SetAuthURLParam(\"code_verifier\", codeVerifier)}\n\t\t\ttok, err := oauth2conf.Exchange(ctx, code, opts...)\n\t\t\tif err != nil {\n\t\t\t\thandleErr(w, err.Error())\n\t\t\t\treturn\n\t\t\t}\n\t\t\tvar ok bool\n\t\t\ttokenString, ok = tok.Extra(\"id_token\").(string)\n\t\t\tif !ok {\n\t\t\t\thandleErr(w, \"no id_token in token response\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\trefreshToken, _ = tok.Extra(\"refresh_token\").(string)\n\t\t}\n\t\tsuccessPage := `\n\t\t<div style=\"height:100px; width:100%!; display:flex; flex-direction: column; justify-content: center; align-items:center; background-color:#2ecc71; color:white; font-size:22\"><div>Authentication successful!</div></div>\n\t\t<p style=\"margin-top:20px; font-size:18; text-align:center\">Authentication was successful, you can now return to CLI. This page will close automatically</p>\n\t\t<script>window.onload=function(){setTimeout(this.close, 4000)}</script>\n\t\t`\n\t\tfmt.Fprint(w, successPage)\n\t\tcompletionChan <- \"\"\n\t}\n\tsrv := &http.Server{Addr: \"localhost:\" + strconv.Itoa(port)}\n\thttp.HandleFunc(\"/auth/callback\", callbackHandler)\n\n\t// Redirect user to login & consent page to ask for permission for the scopes specified above.\n\tfmt.Printf(\"Opening browser for authentication\\n\")\n\n\tvar url string\n\tgrantType := oidcutil.InferGrantType(oidcConf)\n\topts := []oauth2.AuthCodeOption{oauth2.AccessTypeOffline}\n\tif claimsRequested := oidcSettings.GetIDTokenClaims(); claimsRequested != nil {\n\t\topts = oidcutil.AppendClaimsAuthenticationRequestParameter(opts, claimsRequested)\n\t}\n\n\tswitch grantType {\n\tcase oidcutil.GrantTypeAuthorizationCode:\n\t\topts = append(opts, oauth2.SetAuthURLParam(\"code_challenge\", codeChallenge))\n\t\topts = append(opts, oauth2.SetAuthURLParam(\"code_challenge_method\", \"S256\"))\n\t\turl = oauth2conf.AuthCodeURL(stateNonce, opts...)\n\tcase oidcutil.GrantTypeImplicit:\n\t\turl = oidcutil.ImplicitFlowURL(oauth2conf, stateNonce, opts...)\n\tdefault:\n\t\tlog.Fatalf(\"Unsupported grant type: %v\", grantType)\n\t}\n\tfmt.Printf(\"Performing %s flow login: %s\\n\", grantType, url)\n\ttime.Sleep(1 * time.Second)\n\terr = open.Start(url)\n\terrors.CheckError(err)\n\tgo func() {\n\t\tlog.Debugf(\"Listen: %s\", srv.Addr)\n\t\tif err := srv.ListenAndServe(); err != http.ErrServerClosed {\n\t\t\tlog.Fatalf(\"Temporary HTTP server failed: %s\", err)\n\t\t}\n\t}()\n\terrMsg := <-completionChan\n\tif errMsg != \"\" {\n\t\tlog.Fatal(errMsg)\n\t}\n\tfmt.Printf(\"Authentication successful\\n\")\n\tctx, cancel := context.WithTimeout(ctx, 1*time.Second)\n\tdefer cancel()\n\t_ = srv.Shutdown(ctx)\n\tlog.Debugf(\"Token: %s\", tokenString)\n\tlog.Debugf(\"Refresh Token: %s\", refreshToken)\n\treturn tokenString, refreshToken\n}\n\nfunc passwordLogin(acdClient argocdclient.Client, username, password string) string {\n\tusername, password = cli.PromptCredentials(username, password)\n\tsessConn, sessionIf := acdClient.NewSessionClientOrDie()\n\tdefer io.Close(sessConn)\n\tsessionRequest := sessionpkg.SessionCreateRequest{\n\t\tUsername: username,\n\t\tPassword: password,\n\t}\n\tcreatedSession, err := sessionIf.Create(context.Background(), &sessionRequest)\n\terrors.CheckError(err)\n\treturn createdSession.Token\n}\n", "package controller\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/argoproj/gitops-engine/pkg/sync\"\n\t\"github.com/argoproj/gitops-engine/pkg/sync/common\"\n\t\"github.com/argoproj/gitops-engine/pkg/utils/kube\"\n\tjsonpatch \"github.com/evanphx/json-patch\"\n\tlog \"github.com/sirupsen/logrus\"\n\tv1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured\"\n\t\"k8s.io/apimachinery/pkg/runtime/schema\"\n\t\"k8s.io/apimachinery/pkg/util/managedfields\"\n\t\"k8s.io/kubectl/pkg/util/openapi\"\n\n\tcdcommon \"github.com/argoproj/argo-cd/v2/common\"\n\t\"github.com/argoproj/argo-cd/v2/controller/metrics\"\n\t\"github.com/argoproj/argo-cd/v2/pkg/apis/application/v1alpha1\"\n\tlistersv1alpha1 \"github.com/argoproj/argo-cd/v2/pkg/client/listers/application/v1alpha1\"\n\t\"github.com/argoproj/argo-cd/v2/util/argo\"\n\t\"github.com/argoproj/argo-cd/v2/util/argo/diff\"\n\tlogutils \"github.com/argoproj/argo-cd/v2/util/log\"\n\t\"github.com/argoproj/argo-cd/v2/util/lua\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n)\n\nvar syncIdPrefix uint64 = 0\n\nconst (\n\t// EnvVarSyncWaveDelay is an environment variable which controls the delay in seconds between\n\t// each sync-wave\n\tEnvVarSyncWaveDelay = \"ARGOCD_SYNC_WAVE_DELAY\"\n)\n\nfunc (m *appStateManager) getOpenAPISchema(server string) (openapi.Resources, error) {\n\tcluster, err := m.liveStateCache.GetClusterCache(server)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn cluster.GetOpenAPISchema(), nil\n}\n\nfunc (m *appStateManager) getGVKParser(server string) (*managedfields.GvkParser, error) {\n\tcluster, err := m.liveStateCache.GetClusterCache(server)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn cluster.GetGVKParser(), nil\n}\n\nfunc (m *appStateManager) SyncAppState(app *v1alpha1.Application, state *v1alpha1.OperationState) {\n\t// Sync requests might be requested with ambiguous revisions (e.g. master, HEAD, v1.2.3).\n\t// This can change meaning when resuming operations (e.g a hook sync). After calculating a\n\t// concrete git commit SHA, the SHA is remembered in the status.operationState.syncResult field.\n\t// This ensures that when resuming an operation, we sync to the same revision that we initially\n\t// started with.\n\tvar revision string\n\tvar syncOp v1alpha1.SyncOperation\n\tvar syncRes *v1alpha1.SyncOperationResult\n\tvar source v1alpha1.ApplicationSource\n\n\tif state.Operation.Sync == nil {\n\t\tstate.Phase = common.OperationFailed\n\t\tstate.Message = \"Invalid operation request: no operation specified\"\n\t\treturn\n\t}\n\tsyncOp = *state.Operation.Sync\n\n\t// validates if it should fail the sync if it finds shared resources\n\thasSharedResource, sharedResourceMessage := hasSharedResourceCondition(app)\n\tif syncOp.SyncOptions.HasOption(\"FailOnSharedResource=true\") &&\n\t\thasSharedResource {\n\t\tstate.Phase = common.OperationFailed\n\t\tstate.Message = fmt.Sprintf(\"Shared resouce found: %s\", sharedResourceMessage)\n\t\treturn\n\t}\n\n\tif syncOp.Source == nil {\n\t\t// normal sync case (where source is taken from app.spec.source)\n\t\tsource = app.Spec.Source\n\t} else {\n\t\t// rollback case\n\t\tsource = *state.Operation.Sync.Source\n\t}\n\n\tif state.SyncResult != nil {\n\t\tsyncRes = state.SyncResult\n\t\trevision = state.SyncResult.Revision\n\t} else {\n\t\tsyncRes = &v1alpha1.SyncOperationResult{}\n\t\t// status.operationState.syncResult.source. must be set properly since auto-sync relies\n\t\t// on this information to decide if it should sync (if source is different than the last\n\t\t// sync attempt)\n\t\tsyncRes.Source = source\n\t\tstate.SyncResult = syncRes\n\t}\n\n\tif revision == \"\" {\n\t\t// if we get here, it means we did not remember a commit SHA which we should be syncing to.\n\t\t// This typically indicates we are just about to begin a brand new sync/rollback operation.\n\t\t// Take the value in the requested operation. We will resolve this to a SHA later.\n\t\trevision = syncOp.Revision\n\t}\n\n\tproj, err := argo.GetAppProject(&app.Spec, listersv1alpha1.NewAppProjectLister(m.projInformer.GetIndexer()), m.namespace, m.settingsMgr, m.db, context.TODO())\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = fmt.Sprintf(\"Failed to load application project: %v\", err)\n\t\treturn\n\t}\n\n\tcompareResult := m.CompareAppState(app, proj, revision, source, false, true, syncOp.Manifests)\n\t// We now have a concrete commit SHA. Save this in the sync result revision so that we remember\n\t// what we should be syncing to when resuming operations.\n\tsyncRes.Revision = compareResult.syncStatus.Revision\n\n\t// If there are any comparison or spec errors error conditions do not perform the operation\n\tif errConditions := app.Status.GetConditions(map[v1alpha1.ApplicationConditionType]bool{\n\t\tv1alpha1.ApplicationConditionComparisonError:  true,\n\t\tv1alpha1.ApplicationConditionInvalidSpecError: true,\n\t}); len(errConditions) > 0 {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = argo.FormatAppConditions(errConditions)\n\t\treturn\n\t}\n\n\tclst, err := m.db.GetCluster(context.Background(), app.Spec.Destination.Server)\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = err.Error()\n\t\treturn\n\t}\n\n\trawConfig := clst.RawRestConfig()\n\trestConfig := metrics.AddMetricsTransportWrapper(m.metricsServer, app, clst.RESTConfig())\n\n\tresourceOverrides, err := m.settingsMgr.GetResourceOverrides()\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = fmt.Sprintf(\"Failed to load resource overrides: %v\", err)\n\t\treturn\n\t}\n\n\tatomic.AddUint64(&syncIdPrefix, 1)\n\tsyncId := fmt.Sprintf(\"%05d-%s\", syncIdPrefix, rand.RandString(5))\n\n\tlogEntry := log.WithFields(log.Fields{\"application\": app.Name, \"syncId\": syncId})\n\tinitialResourcesRes := make([]common.ResourceSyncResult, 0)\n\tfor i, res := range syncRes.Resources {\n\t\tkey := kube.ResourceKey{Group: res.Group, Kind: res.Kind, Namespace: res.Namespace, Name: res.Name}\n\t\tinitialResourcesRes = append(initialResourcesRes, common.ResourceSyncResult{\n\t\t\tResourceKey: key,\n\t\t\tMessage:     res.Message,\n\t\t\tStatus:      res.Status,\n\t\t\tHookPhase:   res.HookPhase,\n\t\t\tHookType:    res.HookType,\n\t\t\tSyncPhase:   res.SyncPhase,\n\t\t\tVersion:     res.Version,\n\t\t\tOrder:       i + 1,\n\t\t})\n\t}\n\n\tprunePropagationPolicy := v1.DeletePropagationForeground\n\tswitch {\n\tcase syncOp.SyncOptions.HasOption(\"PrunePropagationPolicy=background\"):\n\t\tprunePropagationPolicy = v1.DeletePropagationBackground\n\tcase syncOp.SyncOptions.HasOption(\"PrunePropagationPolicy=foreground\"):\n\t\tprunePropagationPolicy = v1.DeletePropagationForeground\n\tcase syncOp.SyncOptions.HasOption(\"PrunePropagationPolicy=orphan\"):\n\t\tprunePropagationPolicy = v1.DeletePropagationOrphan\n\t}\n\n\topenAPISchema, err := m.getOpenAPISchema(clst.Server)\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = fmt.Sprintf(\"failed to load openAPISchema: %v\", err)\n\t\treturn\n\t}\n\n\treconciliationResult := compareResult.reconciliationResult\n\n\t// if RespectIgnoreDifferences is enabled, it should normalize the target\n\t// resources which in this case applies the live values in the configured\n\t// ignore differences fields.\n\tif syncOp.SyncOptions.HasOption(\"RespectIgnoreDifferences=true\") {\n\t\tpatchedTargets, err := normalizeTargetResources(compareResult)\n\t\tif err != nil {\n\t\t\tstate.Phase = common.OperationError\n\t\t\tstate.Message = fmt.Sprintf(\"Failed to normalize target resources: %s\", err)\n\t\t\treturn\n\t\t}\n\t\treconciliationResult.Target = patchedTargets\n\t}\n\n\tsyncCtx, cleanup, err := sync.NewSyncContext(\n\t\tcompareResult.syncStatus.Revision,\n\t\treconciliationResult,\n\t\trestConfig,\n\t\trawConfig,\n\t\tm.kubectl,\n\t\tapp.Spec.Destination.Namespace,\n\t\topenAPISchema,\n\t\tsync.WithLogr(logutils.NewLogrusLogger(logEntry)),\n\t\tsync.WithHealthOverride(lua.ResourceHealthOverrides(resourceOverrides)),\n\t\tsync.WithPermissionValidator(func(un *unstructured.Unstructured, res *v1.APIResource) error {\n\t\t\tif !proj.IsGroupKindPermitted(un.GroupVersionKind().GroupKind(), res.Namespaced) {\n\t\t\t\treturn fmt.Errorf(\"Resource %s:%s is not permitted in project %s.\", un.GroupVersionKind().Group, un.GroupVersionKind().Kind, proj.Name)\n\t\t\t}\n\t\t\tif res.Namespaced && !proj.IsDestinationPermitted(v1alpha1.ApplicationDestination{Namespace: un.GetNamespace(), Server: app.Spec.Destination.Server, Name: app.Spec.Destination.Name}) {\n\t\t\t\treturn fmt.Errorf(\"namespace %v is not permitted in project '%s'\", un.GetNamespace(), proj.Name)\n\t\t\t}\n\t\t\treturn nil\n\t\t}),\n\t\tsync.WithOperationSettings(syncOp.DryRun, syncOp.Prune, syncOp.SyncStrategy.Force(), syncOp.IsApplyStrategy() || len(syncOp.Resources) > 0),\n\t\tsync.WithInitialState(state.Phase, state.Message, initialResourcesRes, state.StartedAt),\n\t\tsync.WithResourcesFilter(func(key kube.ResourceKey, target *unstructured.Unstructured, live *unstructured.Unstructured) bool {\n\t\t\treturn len(syncOp.Resources) == 0 || argo.ContainsSyncResource(key.Name, key.Namespace, schema.GroupVersionKind{Kind: key.Kind, Group: key.Group}, syncOp.Resources)\n\t\t}),\n\t\tsync.WithManifestValidation(!syncOp.SyncOptions.HasOption(common.SyncOptionsDisableValidation)),\n\t\tsync.WithNamespaceCreation(syncOp.SyncOptions.HasOption(\"CreateNamespace=true\"), func(un *unstructured.Unstructured) bool {\n\t\t\tif un != nil && kube.GetAppInstanceLabel(un, cdcommon.LabelKeyAppInstance) != \"\" {\n\t\t\t\tkube.UnsetLabel(un, cdcommon.LabelKeyAppInstance)\n\t\t\t\treturn true\n\t\t\t}\n\t\t\treturn false\n\t\t}),\n\t\tsync.WithSyncWaveHook(delayBetweenSyncWaves),\n\t\tsync.WithPruneLast(syncOp.SyncOptions.HasOption(common.SyncOptionPruneLast)),\n\t\tsync.WithResourceModificationChecker(syncOp.SyncOptions.HasOption(\"ApplyOutOfSyncOnly=true\"), compareResult.diffResultList),\n\t\tsync.WithPrunePropagationPolicy(&prunePropagationPolicy),\n\t\tsync.WithReplace(syncOp.SyncOptions.HasOption(common.SyncOptionReplace)),\n\t)\n\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = fmt.Sprintf(\"failed to initialize sync context: %v\", err)\n\t\treturn\n\t}\n\n\tdefer cleanup()\n\n\tstart := time.Now()\n\n\tif state.Phase == common.OperationTerminating {\n\t\tsyncCtx.Terminate()\n\t} else {\n\t\tsyncCtx.Sync()\n\t}\n\tvar resState []common.ResourceSyncResult\n\tstate.Phase, state.Message, resState = syncCtx.GetState()\n\tstate.SyncResult.Resources = nil\n\tfor _, res := range resState {\n\t\tstate.SyncResult.Resources = append(state.SyncResult.Resources, &v1alpha1.ResourceResult{\n\t\t\tHookType:  res.HookType,\n\t\t\tGroup:     res.ResourceKey.Group,\n\t\t\tKind:      res.ResourceKey.Kind,\n\t\t\tNamespace: res.ResourceKey.Namespace,\n\t\t\tName:      res.ResourceKey.Name,\n\t\t\tVersion:   res.Version,\n\t\t\tSyncPhase: res.SyncPhase,\n\t\t\tHookPhase: res.HookPhase,\n\t\t\tStatus:    res.Status,\n\t\t\tMessage:   res.Message,\n\t\t})\n\t}\n\n\tlogEntry.WithField(\"duration\", time.Since(start)).Info(\"sync/terminate complete\")\n\n\tif !syncOp.DryRun && len(syncOp.Resources) == 0 && state.Phase.Successful() {\n\t\terr := m.persistRevisionHistory(app, compareResult.syncStatus.Revision, source, state.StartedAt)\n\t\tif err != nil {\n\t\t\tstate.Phase = common.OperationError\n\t\t\tstate.Message = fmt.Sprintf(\"failed to record sync to history: %v\", err)\n\t\t}\n\t}\n}\n\n// normalizeTargetResources will apply the diff normalization in all live and target resources.\n// Then it calculates the merge patch between the normalized live and the current live resources.\n// Finally it applies the merge patch in the normalized target resources. This is done to ensure\n// that target resources have the same ignored diff fields values from live ones to avoid them to\n// be applied in the cluster. Returns the list of normalized target resources.\nfunc normalizeTargetResources(cr *comparisonResult) ([]*unstructured.Unstructured, error) {\n\t// normalize live and target resources\n\tnormalized, err := diff.Normalize(cr.reconciliationResult.Live, cr.reconciliationResult.Target, cr.diffConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpatchedTargets := []*unstructured.Unstructured{}\n\tfor idx, live := range cr.reconciliationResult.Live {\n\t\tnormalizedTarget := normalized.Targets[idx]\n\t\tif normalizedTarget == nil {\n\t\t\tpatchedTargets = append(patchedTargets, nil)\n\t\t\tcontinue\n\t\t}\n\t\toriginalTarget := cr.reconciliationResult.Target[idx]\n\t\tif live == nil {\n\t\t\tpatchedTargets = append(patchedTargets, originalTarget)\n\t\t\tcontinue\n\t\t}\n\t\t// calculate targetPatch between normalized and target resource\n\t\ttargetPatch, err := getMergePatch(normalizedTarget, originalTarget)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// check if there is a patch to apply. An empty patch is identified by a '{}' string.\n\t\tif len(targetPatch) > 2 {\n\t\t\tlivePatch, err := getMergePatch(normalized.Lives[idx], live)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\t// generate a minimal patch that uses the fields from targetPatch (template)\n\t\t\t// with livePatch values\n\t\t\tpatch, err := compilePatch(targetPatch, livePatch)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tnormalizedTarget, err = applyMergePatch(normalizedTarget, patch)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t} else {\n\t\t\t// if there is no patch just use the original target\n\t\t\tnormalizedTarget = originalTarget\n\t\t}\n\t\tpatchedTargets = append(patchedTargets, normalizedTarget)\n\t}\n\treturn patchedTargets, nil\n}\n\n// compilePatch will generate a patch using the fields from templatePatch with\n// the values from valuePatch.\nfunc compilePatch(templatePatch, valuePatch []byte) ([]byte, error) {\n\ttemplateMap := make(map[string]interface{})\n\terr := json.Unmarshal(templatePatch, &templateMap)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvalueMap := make(map[string]interface{})\n\terr = json.Unmarshal(valuePatch, &valueMap)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresultMap := intersectMap(templateMap, valueMap)\n\treturn json.Marshal(resultMap)\n}\n\n// intersectMap will return map with the fields intersection from the 2 provided\n// maps populated with the valueMap values.\nfunc intersectMap(templateMap, valueMap map[string]interface{}) map[string]interface{} {\n\tresult := make(map[string]interface{})\n\tfor k, v := range templateMap {\n\t\tif innerTMap, ok := v.(map[string]interface{}); ok {\n\t\t\tif innerVMap, ok := valueMap[k].(map[string]interface{}); ok {\n\t\t\t\tresult[k] = intersectMap(innerTMap, innerVMap)\n\t\t\t}\n\t\t} else if innerTSlice, ok := v.([]interface{}); ok {\n\t\t\tif innerVSlice, ok := valueMap[k].([]interface{}); ok {\n\t\t\t\titems := []interface{}{}\n\t\t\t\tfor idx, innerTSliceValue := range innerTSlice {\n\t\t\t\t\tif idx < len(innerVSlice) {\n\t\t\t\t\t\tif tSliceValueMap, ok := innerTSliceValue.(map[string]interface{}); ok {\n\t\t\t\t\t\t\tif vSliceValueMap, ok := innerVSlice[idx].(map[string]interface{}); ok {\n\t\t\t\t\t\t\t\titem := intersectMap(tSliceValueMap, vSliceValueMap)\n\t\t\t\t\t\t\t\titems = append(items, item)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\titems = append(items, innerVSlice[idx])\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif len(items) > 0 {\n\t\t\t\t\tresult[k] = items\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif _, ok := valueMap[k]; ok {\n\t\t\t\tresult[k] = valueMap[k]\n\t\t\t}\n\t\t}\n\t}\n\treturn result\n}\n\n// getMergePatch calculates and returns the patch between the original and the\n// modified unstructures.\nfunc getMergePatch(original, modified *unstructured.Unstructured) ([]byte, error) {\n\toriginalJSON, err := original.MarshalJSON()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmodifiedJSON, err := modified.MarshalJSON()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn jsonpatch.CreateMergePatch(originalJSON, modifiedJSON)\n}\n\n// applyMergePatch will apply the given patch in the obj and return the patched\n// unstructure.\nfunc applyMergePatch(obj *unstructured.Unstructured, patch []byte) (*unstructured.Unstructured, error) {\n\toriginalJSON, err := obj.MarshalJSON()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpatchedJSON, err := jsonpatch.MergePatch(originalJSON, patch)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpatchedObj := &unstructured.Unstructured{}\n\t_, _, err = unstructured.UnstructuredJSONScheme.Decode(patchedJSON, nil, patchedObj)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn patchedObj, nil\n}\n\n// hasSharedResourceCondition will check if the Application has any resource that has already\n// been synced by another Application. If the resource is found in another Application it returns\n// true along with a human readable message of which specific resource has this condition.\nfunc hasSharedResourceCondition(app *v1alpha1.Application) (bool, string) {\n\tfor _, condition := range app.Status.Conditions {\n\t\tif condition.Type == v1alpha1.ApplicationConditionSharedResourceWarning {\n\t\t\treturn true, condition.Message\n\t\t}\n\t}\n\treturn false, \"\"\n}\n\n// delayBetweenSyncWaves is a gitops-engine SyncWaveHook which introduces an artificial delay\n// between each sync wave. We introduce an artificial delay in order give other controllers a\n// _chance_ to react to the spec change that we just applied. This is important because without\n// this, Argo CD will likely assess resource health too quickly (against the stale object), causing\n// hooks to fire prematurely. See: https://github.com/argoproj/argo-cd/issues/4669.\n// Note, this is not foolproof, since a proper fix would require the CRD record\n// status.observedGeneration coupled with a health.lua that verifies\n// status.observedGeneration == metadata.generation\nfunc delayBetweenSyncWaves(phase common.SyncPhase, wave int, finalWave bool) error {\n\tif !finalWave {\n\t\tdelaySec := 2\n\t\tif delaySecStr := os.Getenv(EnvVarSyncWaveDelay); delaySecStr != \"\" {\n\t\t\tif val, err := strconv.Atoi(delaySecStr); err == nil {\n\t\t\t\tdelaySec = val\n\t\t\t}\n\t\t}\n\t\tduration := time.Duration(delaySec) * time.Second\n\t\ttime.Sleep(duration)\n\t}\n\treturn nil\n}\n", "package apiclient\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/metadata\"\n\t\"google.golang.org/grpc/status\"\n\n\targocderrors \"github.com/argoproj/argo-cd/v2/util/errors\"\n\targoio \"github.com/argoproj/argo-cd/v2/util/io\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n)\n\nconst (\n\tframeHeaderLength = 5\n\tendOfStreamFlag   = 128\n)\n\ntype noopCodec struct{}\n\nfunc (noopCodec) Marshal(v interface{}) ([]byte, error) {\n\treturn v.([]byte), nil\n}\n\nfunc (noopCodec) Unmarshal(data []byte, v interface{}) error {\n\tpointer := v.(*[]byte)\n\t*pointer = data\n\treturn nil\n}\n\nfunc (noopCodec) Name() string {\n\treturn \"proto\"\n}\n\nfunc toFrame(msg []byte) []byte {\n\tframe := append([]byte{0, 0, 0, 0}, msg...)\n\tbinary.BigEndian.PutUint32(frame, uint32(len(msg)))\n\tframe = append([]byte{0}, frame...)\n\treturn frame\n}\n\nfunc (c *client) executeRequest(fullMethodName string, msg []byte, md metadata.MD) (*http.Response, error) {\n\tschema := \"https\"\n\tif c.PlainText {\n\t\tschema = \"http\"\n\t}\n\trootPath := strings.TrimRight(strings.TrimLeft(c.GRPCWebRootPath, \"/\"), \"/\")\n\n\tvar requestURL string\n\tif rootPath != \"\" {\n\t\trequestURL = fmt.Sprintf(\"%s://%s/%s%s\", schema, c.ServerAddr, rootPath, fullMethodName)\n\t} else {\n\t\trequestURL = fmt.Sprintf(\"%s://%s%s\", schema, c.ServerAddr, fullMethodName)\n\t}\n\treq, err := http.NewRequest(http.MethodPost, requestURL, bytes.NewReader(toFrame(msg)))\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor k, v := range md {\n\t\tif strings.HasPrefix(k, \":\") {\n\t\t\tcontinue\n\t\t}\n\t\tfor i := range v {\n\t\t\treq.Header.Set(k, v[i])\n\t\t}\n\t}\n\treq.Header.Set(\"content-type\", \"application/grpc-web+proto\")\n\n\tresp, err := c.httpClient.Do(req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif resp.StatusCode != http.StatusOK {\n\t\treturn nil, fmt.Errorf(\"%s %s failed with status code %d\", req.Method, req.URL, resp.StatusCode)\n\t}\n\tvar code codes.Code\n\tif statusStr := resp.Header.Get(\"Grpc-Status\"); statusStr != \"\" {\n\t\tstatusInt, err := strconv.ParseUint(statusStr, 10, 32)\n\t\tif err != nil {\n\t\t\tcode = codes.Unknown\n\t\t} else {\n\t\t\tcode = codes.Code(statusInt)\n\t\t}\n\t\tif code != codes.OK {\n\t\t\treturn nil, status.Error(code, resp.Header.Get(\"Grpc-Message\"))\n\t\t}\n\t}\n\treturn resp, nil\n}\n\nfunc (c *client) startGRPCProxy() (*grpc.Server, net.Listener, error) {\n\tserverAddr := fmt.Sprintf(\"%s/argocd-%s.sock\", os.TempDir(), rand.RandString(16))\n\tln, err := net.Listen(\"unix\", serverAddr)\n\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tproxySrv := grpc.NewServer(\n\t\tgrpc.ForceServerCodec(&noopCodec{}),\n\t\tgrpc.UnknownServiceHandler(func(srv interface{}, stream grpc.ServerStream) error {\n\t\t\tfullMethodName, ok := grpc.MethodFromServerStream(stream)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"Unable to get method name from stream context.\")\n\t\t\t}\n\t\t\tmsg := make([]byte, 0)\n\t\t\terr := stream.RecvMsg(&msg)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tmd, _ := metadata.FromIncomingContext(stream.Context())\n\n\t\t\tfor _, kv := range c.Headers {\n\t\t\t\tif len(strings.Split(kv, \":\"))%2 == 1 {\n\t\t\t\t\treturn fmt.Errorf(\"additional headers key/values must be separated by a colon(:): %s\", kv)\n\t\t\t\t}\n\t\t\t\tmd.Append(strings.Split(kv, \":\")[0], strings.Split(kv, \":\")[1])\n\t\t\t}\n\n\t\t\tresp, err := c.executeRequest(fullMethodName, msg, md)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tgo func() {\n\t\t\t\t<-stream.Context().Done()\n\t\t\t\targoio.Close(resp.Body)\n\t\t\t}()\n\t\t\tdefer argoio.Close(resp.Body)\n\t\t\tc.httpClient.CloseIdleConnections()\n\n\t\t\tfor {\n\t\t\t\theader := make([]byte, frameHeaderLength)\n\t\t\t\tif _, err := io.ReadAtLeast(resp.Body, header, frameHeaderLength); err != nil {\n\t\t\t\t\tif err == io.EOF {\n\t\t\t\t\t\terr = io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\tif header[0] == endOfStreamFlag {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\tlength := int(binary.BigEndian.Uint32(header[1:frameHeaderLength]))\n\t\t\t\tdata := make([]byte, length)\n\n\t\t\t\tif read, err := io.ReadAtLeast(resp.Body, data, length); err != nil {\n\t\t\t\t\tif err != io.EOF {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t} else if read < length {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif err := stream.SendMsg(data); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t}\n\t\t}))\n\tgo func() {\n\t\terr := proxySrv.Serve(ln)\n\t\targocderrors.CheckError(err)\n\t}()\n\treturn proxySrv, ln, nil\n}\n\n// useGRPCProxy ensures that grpc proxy server is started and return closer which stops server when no one uses it\nfunc (c *client) useGRPCProxy() (net.Addr, io.Closer, error) {\n\tc.proxyMutex.Lock()\n\tdefer c.proxyMutex.Unlock()\n\n\tif c.proxyListener == nil {\n\t\tvar err error\n\t\tc.proxyServer, c.proxyListener, err = c.startGRPCProxy()\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t}\n\tc.proxyUsersCount = c.proxyUsersCount + 1\n\n\treturn c.proxyListener.Addr(), argoio.NewCloser(func() error {\n\t\tc.proxyMutex.Lock()\n\t\tdefer c.proxyMutex.Unlock()\n\t\tc.proxyUsersCount = c.proxyUsersCount - 1\n\t\tif c.proxyUsersCount == 0 {\n\t\t\tc.proxyServer.Stop()\n\t\t\tc.proxyListener = nil\n\t\t\tc.proxyServer = nil\n\t\t\treturn nil\n\t\t}\n\t\treturn nil\n\t}), nil\n}\n", "package fixture\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\tgoerrors \"errors\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/argoproj/pkg/errors\"\n\tjsonpatch \"github.com/evanphx/json-patch\"\n\t\"github.com/ghodss/yaml\"\n\tlog \"github.com/sirupsen/logrus\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tv1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/client-go/dynamic\"\n\t\"k8s.io/client-go/kubernetes\"\n\t\"k8s.io/client-go/rest\"\n\t\"k8s.io/client-go/tools/clientcmd\"\n\n\t\"github.com/argoproj/argo-cd/v2/common\"\n\t\"github.com/argoproj/argo-cd/v2/pkg/apiclient\"\n\tsessionpkg \"github.com/argoproj/argo-cd/v2/pkg/apiclient/session\"\n\t\"github.com/argoproj/argo-cd/v2/pkg/apis/application/v1alpha1\"\n\tappclientset \"github.com/argoproj/argo-cd/v2/pkg/client/clientset/versioned\"\n\t. \"github.com/argoproj/argo-cd/v2/util/errors\"\n\tgrpcutil \"github.com/argoproj/argo-cd/v2/util/grpc\"\n\t\"github.com/argoproj/argo-cd/v2/util/io\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n\t\"github.com/argoproj/argo-cd/v2/util/settings\"\n)\n\nconst (\n\tdefaultApiServer        = \"localhost:8080\"\n\tdefaultAdminPassword    = \"password\"\n\tdefaultAdminUsername    = \"admin\"\n\tDefaultTestUserPassword = \"password\"\n\ttestingLabel            = \"e2e.argoproj.io\"\n\tArgoCDNamespace         = \"argocd-e2e\"\n\n\t// ensure all repos are in one directory tree, so we can easily clean them up\n\tTmpDir             = \"/tmp/argo-e2e\"\n\trepoDir            = \"testdata.git\"\n\tsubmoduleDir       = \"submodule.git\"\n\tsubmoduleParentDir = \"submoduleParent.git\"\n\n\tGuestbookPath = \"guestbook\"\n\n\tProjectName = \"argo-project\"\n\n\t// cmp plugin sock file path\n\tPluginSockFilePath = \"/app/config/plugin\"\n)\n\nconst (\n\tEnvAdminUsername = \"ARGOCD_E2E_ADMIN_USERNAME\"\n\tEnvAdminPassword = \"ARGOCD_E2E_ADMIN_PASSWORD\"\n)\n\nvar (\n\tid                  string\n\tdeploymentNamespace string\n\tname                string\n\tKubeClientset       kubernetes.Interface\n\tKubeConfig          *rest.Config\n\tDynamicClientset    dynamic.Interface\n\tAppClientset        appclientset.Interface\n\tArgoCDClientset     apiclient.Client\n\tadminUsername       string\n\tAdminPassword       string\n\tapiServerAddress    string\n\ttoken               string\n\tplainText           bool\n\ttestsRun            map[string]bool\n)\n\ntype RepoURLType string\n\ntype ACL struct {\n\tResource string\n\tAction   string\n\tScope    string\n}\n\nconst (\n\tRepoURLTypeFile                 = \"file\"\n\tRepoURLTypeHTTPS                = \"https\"\n\tRepoURLTypeHTTPSClientCert      = \"https-cc\"\n\tRepoURLTypeHTTPSSubmodule       = \"https-sub\"\n\tRepoURLTypeHTTPSSubmoduleParent = \"https-par\"\n\tRepoURLTypeSSH                  = \"ssh\"\n\tRepoURLTypeSSHSubmodule         = \"ssh-sub\"\n\tRepoURLTypeSSHSubmoduleParent   = \"ssh-par\"\n\tRepoURLTypeHelm                 = \"helm\"\n\tRepoURLTypeHelmParent           = \"helm-par\"\n\tRepoURLTypeHelmOCI              = \"helm-oci\"\n\tGitUsername                     = \"admin\"\n\tGitPassword                     = \"password\"\n\tGpgGoodKeyID                    = \"D56C4FCA57A46444\"\n\tHelmOCIRegistryURL              = \"localhost:5000/myrepo\"\n)\n\n// TestNamespace returns the namespace where Argo CD E2E test instance will be\n// running in.\nfunc TestNamespace() string {\n\treturn GetEnvWithDefault(\"ARGOCD_E2E_NAMESPACE\", ArgoCDNamespace)\n}\n\n// getKubeConfig creates new kubernetes client config using specified config path and config overrides variables\nfunc getKubeConfig(configPath string, overrides clientcmd.ConfigOverrides) *rest.Config {\n\tloadingRules := clientcmd.NewDefaultClientConfigLoadingRules()\n\tloadingRules.ExplicitPath = configPath\n\tclientConfig := clientcmd.NewInteractiveDeferredLoadingClientConfig(loadingRules, &overrides, os.Stdin)\n\n\trestConfig, err := clientConfig.ClientConfig()\n\tCheckError(err)\n\treturn restConfig\n}\n\nfunc GetEnvWithDefault(envName, defaultValue string) string {\n\tr := os.Getenv(envName)\n\tif r == \"\" {\n\t\treturn defaultValue\n\t}\n\treturn r\n}\n\n// IsRemote returns true when the tests are being run against a workload that\n// is running in a remote cluster.\nfunc IsRemote() bool {\n\tr := os.Getenv(\"ARGOCD_E2E_REMOTE\")\n\treturn r == \"true\"\n}\n\n// IsLocal returns when the tests are being run against a local workload\nfunc IsLocal() bool {\n\treturn !IsRemote()\n}\n\n// creates e2e tests fixture: ensures that Application CRD is installed, creates temporal namespace, starts repo and api server,\n// configure currently available cluster.\nfunc init() {\n\t// ensure we log all shell execs\n\tlog.SetLevel(log.DebugLevel)\n\t// set-up variables\n\tconfig := getKubeConfig(\"\", clientcmd.ConfigOverrides{})\n\tAppClientset = appclientset.NewForConfigOrDie(config)\n\tKubeClientset = kubernetes.NewForConfigOrDie(config)\n\tDynamicClientset = dynamic.NewForConfigOrDie(config)\n\tKubeConfig = config\n\n\tapiServerAddress = GetEnvWithDefault(apiclient.EnvArgoCDServer, defaultApiServer)\n\tadminUsername = GetEnvWithDefault(EnvAdminUsername, defaultAdminUsername)\n\tAdminPassword = GetEnvWithDefault(EnvAdminPassword, defaultAdminPassword)\n\n\ttlsTestResult, err := grpcutil.TestTLS(apiServerAddress)\n\tCheckError(err)\n\n\tArgoCDClientset, err = apiclient.NewClient(&apiclient.ClientOptions{Insecure: true, ServerAddr: apiServerAddress, PlainText: !tlsTestResult.TLS})\n\tCheckError(err)\n\n\tplainText = !tlsTestResult.TLS\n\n\tLoginAs(adminUsername)\n\n\tlog.WithFields(log.Fields{\"apiServerAddress\": apiServerAddress}).Info(\"initialized\")\n\n\t// Preload a list of tests that should be skipped\n\ttestsRun = make(map[string]bool)\n\trf := os.Getenv(\"ARGOCD_E2E_RECORD\")\n\tif rf == \"\" {\n\t\treturn\n\t}\n\tf, err := os.Open(rf)\n\tif err != nil {\n\t\tif goerrors.Is(err, os.ErrNotExist) {\n\t\t\treturn\n\t\t} else {\n\t\t\tpanic(fmt.Sprintf(\"Could not read record file %s: %v\", rf, err))\n\t\t}\n\t}\n\tdefer f.Close()\n\tscanner := bufio.NewScanner(f)\n\tfor scanner.Scan() {\n\t\ttestsRun[scanner.Text()] = true\n\t}\n\n}\n\nfunc loginAs(username, password string) {\n\tcloser, client, err := ArgoCDClientset.NewSessionClient()\n\tCheckError(err)\n\tdefer io.Close(closer)\n\n\tsessionResponse, err := client.Create(context.Background(), &sessionpkg.SessionCreateRequest{Username: username, Password: password})\n\tCheckError(err)\n\ttoken = sessionResponse.Token\n\n\tArgoCDClientset, err = apiclient.NewClient(&apiclient.ClientOptions{\n\t\tInsecure:   true,\n\t\tServerAddr: apiServerAddress,\n\t\tAuthToken:  token,\n\t\tPlainText:  plainText,\n\t})\n\tCheckError(err)\n}\n\nfunc LoginAs(username string) {\n\tpassword := DefaultTestUserPassword\n\tif username == \"admin\" {\n\t\tpassword = AdminPassword\n\t}\n\tloginAs(username, password)\n}\n\nfunc Name() string {\n\treturn name\n}\n\nfunc repoDirectory() string {\n\treturn path.Join(TmpDir, repoDir)\n}\n\nfunc submoduleDirectory() string {\n\treturn path.Join(TmpDir, submoduleDir)\n}\n\nfunc submoduleParentDirectory() string {\n\treturn path.Join(TmpDir, submoduleParentDir)\n}\n\nconst (\n\tEnvRepoURLTypeSSH                  = \"ARGOCD_E2E_REPO_SSH\"\n\tEnvRepoURLTypeSSHSubmodule         = \"ARGOCD_E2E_REPO_SSH_SUBMODULE\"\n\tEnvRepoURLTypeSSHSubmoduleParent   = \"ARGOCD_E2E_REPO_SSH_SUBMODULE_PARENT\"\n\tEnvRepoURLTypeHTTPS                = \"ARGOCD_E2E_REPO_HTTPS\"\n\tEnvRepoURLTypeHTTPSClientCert      = \"ARGOCD_E2E_REPO_HTTPS_CLIENT_CERT\"\n\tEnvRepoURLTypeHTTPSSubmodule       = \"ARGOCD_E2E_REPO_HTTPS_SUBMODULE\"\n\tEnvRepoURLTypeHTTPSSubmoduleParent = \"ARGOCD_E2E_REPO_HTTPS_SUBMODULE_PARENT\"\n\tEnvRepoURLTypeHelm                 = \"ARGOCD_E2E_REPO_HELM\"\n\tEnvRepoURLDefault                  = \"ARGOCD_E2E_REPO_DEFAULT\"\n)\n\nfunc RepoURL(urlType RepoURLType) string {\n\tswitch urlType {\n\t// Git server via SSH\n\tcase RepoURLTypeSSH:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeSSH, \"ssh://root@localhost:2222/tmp/argo-e2e/testdata.git\")\n\t// Git submodule repo\n\tcase RepoURLTypeSSHSubmodule:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeSSHSubmodule, \"ssh://root@localhost:2222/tmp/argo-e2e/submodule.git\")\n\t// Git submodule parent repo\n\tcase RepoURLTypeSSHSubmoduleParent:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeSSHSubmoduleParent, \"ssh://root@localhost:2222/tmp/argo-e2e/submoduleParent.git\")\n\t// Git server via HTTPS\n\tcase RepoURLTypeHTTPS:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHTTPS, \"https://localhost:9443/argo-e2e/testdata.git\")\n\t// Git server via HTTPS - Client Cert protected\n\tcase RepoURLTypeHTTPSClientCert:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHTTPSClientCert, \"https://localhost:9444/argo-e2e/testdata.git\")\n\tcase RepoURLTypeHTTPSSubmodule:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHTTPSSubmodule, \"https://localhost:9443/argo-e2e/submodule.git\")\n\t\t// Git submodule parent repo\n\tcase RepoURLTypeHTTPSSubmoduleParent:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHTTPSSubmoduleParent, \"https://localhost:9443/argo-e2e/submoduleParent.git\")\n\t// Default - file based Git repository\n\tcase RepoURLTypeHelm:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHelm, \"https://localhost:9444/argo-e2e/testdata.git/helm-repo/local\")\n\t// When Helm Repo has sub repos, this is the parent repo URL\n\tcase RepoURLTypeHelmParent:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHelm, \"https://localhost:9444/argo-e2e/testdata.git/helm-repo\")\n\tcase RepoURLTypeHelmOCI:\n\t\treturn HelmOCIRegistryURL\n\tdefault:\n\t\treturn GetEnvWithDefault(EnvRepoURLDefault, fmt.Sprintf(\"file://%s\", repoDirectory()))\n\t}\n}\n\nfunc RepoBaseURL(urlType RepoURLType) string {\n\treturn path.Base(RepoURL(urlType))\n}\n\nfunc DeploymentNamespace() string {\n\treturn deploymentNamespace\n}\n\n// creates a secret for the current test, this currently can only create a single secret\nfunc CreateSecret(username, password string) string {\n\tsecretName := fmt.Sprintf(\"argocd-e2e-%s\", name)\n\tFailOnErr(Run(\"\", \"kubectl\", \"create\", \"secret\", \"generic\", secretName,\n\t\t\"--from-literal=username=\"+username,\n\t\t\"--from-literal=password=\"+password,\n\t\t\"-n\", TestNamespace()))\n\tFailOnErr(Run(\"\", \"kubectl\", \"label\", \"secret\", secretName, testingLabel+\"=true\", \"-n\", TestNamespace()))\n\treturn secretName\n}\n\n// Convenience wrapper for updating argocd-cm\nfunc updateSettingConfigMap(updater func(cm *corev1.ConfigMap) error) {\n\tupdateGenericConfigMap(common.ArgoCDConfigMapName, updater)\n}\n\n// Convenience wrapper for updating argocd-cm-rbac\nfunc updateRBACConfigMap(updater func(cm *corev1.ConfigMap) error) {\n\tupdateGenericConfigMap(common.ArgoCDRBACConfigMapName, updater)\n}\n\n// Updates a given config map in argocd-e2e namespace\nfunc updateGenericConfigMap(name string, updater func(cm *corev1.ConfigMap) error) {\n\tcm, err := KubeClientset.CoreV1().ConfigMaps(TestNamespace()).Get(context.Background(), name, v1.GetOptions{})\n\terrors.CheckError(err)\n\tif cm.Data == nil {\n\t\tcm.Data = make(map[string]string)\n\t}\n\terrors.CheckError(updater(cm))\n\t_, err = KubeClientset.CoreV1().ConfigMaps(TestNamespace()).Update(context.Background(), cm, v1.UpdateOptions{})\n\terrors.CheckError(err)\n}\n\nfunc SetEnableManifestGeneration(val map[v1alpha1.ApplicationSourceType]bool) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tfor k, v := range val {\n\t\t\tcm.Data[fmt.Sprintf(\"%s.enable\", strings.ToLower(string(k)))] = strconv.FormatBool(v)\n\t\t}\n\t\treturn nil\n\t})\n}\n\nfunc SetResourceOverrides(overrides map[string]v1alpha1.ResourceOverride) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tif len(overrides) > 0 {\n\t\t\tyamlBytes, err := yaml.Marshal(overrides)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcm.Data[\"resource.customizations\"] = string(yamlBytes)\n\t\t} else {\n\t\t\tdelete(cm.Data, \"resource.customizations\")\n\t\t}\n\t\treturn nil\n\t})\n\n\tSetResourceOverridesSplitKeys(overrides)\n}\n\nfunc SetTrackingMethod(trackingMethod string) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tcm.Data[\"application.resourceTrackingMethod\"] = trackingMethod\n\t\treturn nil\n\t})\n}\n\nfunc SetResourceOverridesSplitKeys(overrides map[string]v1alpha1.ResourceOverride) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tfor k, v := range overrides {\n\t\t\tif v.HealthLua != \"\" {\n\t\t\t\tcm.Data[getResourceOverrideSplitKey(k, \"health\")] = v.HealthLua\n\t\t\t}\n\t\t\tcm.Data[getResourceOverrideSplitKey(k, \"useOpenLibs\")] = strconv.FormatBool(v.UseOpenLibs)\n\t\t\tif v.Actions != \"\" {\n\t\t\t\tcm.Data[getResourceOverrideSplitKey(k, \"actions\")] = v.Actions\n\t\t\t}\n\t\t\tif len(v.IgnoreDifferences.JSONPointers) > 0 ||\n\t\t\t\tlen(v.IgnoreDifferences.JQPathExpressions) > 0 ||\n\t\t\t\tlen(v.IgnoreDifferences.ManagedFieldsManagers) > 0 {\n\t\t\t\tyamlBytes, err := yaml.Marshal(v.IgnoreDifferences)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tcm.Data[getResourceOverrideSplitKey(k, \"ignoreDifferences\")] = string(yamlBytes)\n\t\t\t}\n\t\t\tif len(v.KnownTypeFields) > 0 {\n\t\t\t\tyamlBytes, err := yaml.Marshal(v.KnownTypeFields)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tcm.Data[getResourceOverrideSplitKey(k, \"knownTypeFields\")] = string(yamlBytes)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n}\n\nfunc getResourceOverrideSplitKey(key string, customizeType string) string {\n\tgroupKind := key\n\tparts := strings.Split(key, \"/\")\n\tif len(parts) == 2 {\n\t\tgroupKind = fmt.Sprintf(\"%s_%s\", parts[0], parts[1])\n\t}\n\treturn fmt.Sprintf(\"resource.customizations.%s.%s\", customizeType, groupKind)\n}\n\nfunc SetAccounts(accounts map[string][]string) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tfor k, v := range accounts {\n\t\t\tcm.Data[fmt.Sprintf(\"accounts.%s\", k)] = strings.Join(v, \",\")\n\t\t}\n\t\treturn nil\n\t})\n}\n\nfunc SetPermissions(permissions []ACL, username string, roleName string) {\n\tupdateRBACConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tvar aclstr string\n\n\t\tfor _, permission := range permissions {\n\t\t\taclstr += fmt.Sprintf(\"p, role:%s, %s, %s, %s, allow \\n\", roleName, permission.Resource, permission.Action, permission.Scope)\n\t\t}\n\n\t\taclstr += fmt.Sprintf(\"g, %s, role:%s\", username, roleName)\n\t\tcm.Data[\"policy.csv\"] = aclstr\n\n\t\treturn nil\n\t})\n}\n\nfunc SetConfigManagementPlugins(plugin ...v1alpha1.ConfigManagementPlugin) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tyamlBytes, err := yaml.Marshal(plugin)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcm.Data[\"configManagementPlugins\"] = string(yamlBytes)\n\t\treturn nil\n\t})\n}\n\nfunc SetResourceFilter(filters settings.ResourcesFilter) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\texclusions, err := yaml.Marshal(filters.ResourceExclusions)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tinclusions, err := yaml.Marshal(filters.ResourceInclusions)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcm.Data[\"resource.exclusions\"] = string(exclusions)\n\t\tcm.Data[\"resource.inclusions\"] = string(inclusions)\n\t\treturn nil\n\t})\n}\n\nfunc SetHelmRepos(repos ...settings.HelmRepoCredentials) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tyamlBytes, err := yaml.Marshal(repos)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcm.Data[\"helm.repositories\"] = string(yamlBytes)\n\t\treturn nil\n\t})\n}\n\nfunc SetRepos(repos ...settings.RepositoryCredentials) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tyamlBytes, err := yaml.Marshal(repos)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcm.Data[\"repositories\"] = string(yamlBytes)\n\t\treturn nil\n\t})\n}\n\nfunc SetProjectSpec(project string, spec v1alpha1.AppProjectSpec) {\n\tproj, err := AppClientset.ArgoprojV1alpha1().AppProjects(TestNamespace()).Get(context.Background(), project, v1.GetOptions{})\n\terrors.CheckError(err)\n\tproj.Spec = spec\n\t_, err = AppClientset.ArgoprojV1alpha1().AppProjects(TestNamespace()).Update(context.Background(), proj, v1.UpdateOptions{})\n\terrors.CheckError(err)\n}\n\nfunc SetParamInSettingConfigMap(key, value string) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tcm.Data[key] = value\n\t\treturn nil\n\t})\n}\n\nfunc EnsureCleanState(t *testing.T) {\n\t// In large scenarios, we can skip tests that already run\n\tSkipIfAlreadyRun(t)\n\t// Register this test after it has been run & was successfull\n\tt.Cleanup(func() {\n\t\tRecordTestRun(t)\n\t})\n\n\tstart := time.Now()\n\n\tpolicy := v1.DeletePropagationBackground\n\t// delete resources\n\t// kubectl delete apps --all\n\tCheckError(AppClientset.ArgoprojV1alpha1().Applications(TestNamespace()).DeleteCollection(context.Background(), v1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{}))\n\t// kubectl delete appprojects --field-selector metadata.name!=default\n\tCheckError(AppClientset.ArgoprojV1alpha1().AppProjects(TestNamespace()).DeleteCollection(context.Background(),\n\t\tv1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{FieldSelector: \"metadata.name!=default\"}))\n\t// kubectl delete secrets -l argocd.argoproj.io/secret-type=repo-config\n\tCheckError(KubeClientset.CoreV1().Secrets(TestNamespace()).DeleteCollection(context.Background(),\n\t\tv1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{LabelSelector: common.LabelKeySecretType + \"=\" + common.LabelValueSecretTypeRepository}))\n\t// kubectl delete secrets -l argocd.argoproj.io/secret-type=repo-creds\n\tCheckError(KubeClientset.CoreV1().Secrets(TestNamespace()).DeleteCollection(context.Background(),\n\t\tv1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{LabelSelector: common.LabelKeySecretType + \"=\" + common.LabelValueSecretTypeRepoCreds}))\n\t// kubectl delete secrets -l argocd.argoproj.io/secret-type=cluster\n\tCheckError(KubeClientset.CoreV1().Secrets(TestNamespace()).DeleteCollection(context.Background(),\n\t\tv1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{LabelSelector: common.LabelKeySecretType + \"=\" + common.LabelValueSecretTypeCluster}))\n\t// kubectl delete secrets -l e2e.argoproj.io=true\n\tCheckError(KubeClientset.CoreV1().Secrets(TestNamespace()).DeleteCollection(context.Background(),\n\t\tv1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{LabelSelector: testingLabel + \"=true\"}))\n\n\tFailOnErr(Run(\"\", \"kubectl\", \"delete\", \"ns\", \"-l\", testingLabel+\"=true\", \"--field-selector\", \"status.phase=Active\", \"--wait=false\"))\n\tFailOnErr(Run(\"\", \"kubectl\", \"delete\", \"crd\", \"-l\", testingLabel+\"=true\", \"--wait=false\"))\n\n\t// reset settings\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tcm.Data = map[string]string{}\n\t\treturn nil\n\t})\n\n\t// reset rbac\n\tupdateRBACConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tcm.Data = map[string]string{}\n\t\treturn nil\n\t})\n\n\t// We can switch user and as result in previous state we will have non-admin user, this case should be reset\n\tLoginAs(adminUsername)\n\n\t// reset gpg-keys config map\n\tupdateGenericConfigMap(common.ArgoCDGPGKeysConfigMapName, func(cm *corev1.ConfigMap) error {\n\t\tcm.Data = map[string]string{}\n\t\treturn nil\n\t})\n\n\tSetProjectSpec(\"default\", v1alpha1.AppProjectSpec{\n\t\tOrphanedResources:        nil,\n\t\tSourceRepos:              []string{\"*\"},\n\t\tDestinations:             []v1alpha1.ApplicationDestination{{Namespace: \"*\", Server: \"*\"}},\n\t\tClusterResourceWhitelist: []v1.GroupKind{{Group: \"*\", Kind: \"*\"}},\n\t})\n\n\t// Create separate project for testing gpg signature verification\n\tFailOnErr(RunCli(\"proj\", \"create\", \"gpg\"))\n\tSetProjectSpec(\"gpg\", v1alpha1.AppProjectSpec{\n\t\tOrphanedResources:        nil,\n\t\tSourceRepos:              []string{\"*\"},\n\t\tDestinations:             []v1alpha1.ApplicationDestination{{Namespace: \"*\", Server: \"*\"}},\n\t\tClusterResourceWhitelist: []v1.GroupKind{{Group: \"*\", Kind: \"*\"}},\n\t\tSignatureKeys:            []v1alpha1.SignatureKey{{KeyID: GpgGoodKeyID}},\n\t})\n\n\t// Recreate temp dir\n\tCheckError(os.RemoveAll(TmpDir))\n\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir))\n\n\t// random id - unique across test runs\n\tpostFix := \"-\" + strings.ToLower(rand.RandString(5))\n\tid = t.Name() + postFix\n\tname = DnsFriendly(t.Name(), \"\")\n\tdeploymentNamespace = DnsFriendly(fmt.Sprintf(\"argocd-e2e-%s\", t.Name()), postFix)\n\n\t// create TLS and SSH certificate directories\n\tif IsLocal() {\n\t\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+\"/app/config/tls\"))\n\t\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+\"/app/config/ssh\"))\n\t}\n\n\t// For signing during the tests\n\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+\"/gpg\"))\n\tFailOnErr(Run(\"\", \"chmod\", \"0700\", TmpDir+\"/gpg\"))\n\tprevGnuPGHome := os.Getenv(\"GNUPGHOME\")\n\tos.Setenv(\"GNUPGHOME\", TmpDir+\"/gpg\")\n\t// nolint:errcheck\n\tRun(\"\", \"pkill\", \"-9\", \"gpg-agent\")\n\tFailOnErr(Run(\"\", \"gpg\", \"--import\", \"../fixture/gpg/signingkey.asc\"))\n\tos.Setenv(\"GNUPGHOME\", prevGnuPGHome)\n\n\t// recreate GPG directories\n\tif IsLocal() {\n\t\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+\"/app/config/gpg/source\"))\n\t\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+\"/app/config/gpg/keys\"))\n\t\tFailOnErr(Run(\"\", \"chmod\", \"0700\", TmpDir+\"/app/config/gpg/keys\"))\n\t\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+PluginSockFilePath))\n\t\tFailOnErr(Run(\"\", \"chmod\", \"0700\", TmpDir+PluginSockFilePath))\n\t}\n\n\t// set-up tmp repo, must have unique name\n\tFailOnErr(Run(\"\", \"cp\", \"-Rf\", \"testdata\", repoDirectory()))\n\tFailOnErr(Run(repoDirectory(), \"chmod\", \"777\", \".\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"init\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"add\", \".\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"commit\", \"-q\", \"-m\", \"initial commit\"))\n\n\tif IsRemote() {\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"remote\", \"add\", \"origin\", os.Getenv(\"ARGOCD_E2E_GIT_SERVICE\")))\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"push\", \"origin\", \"master\", \"-f\"))\n\t}\n\n\t// create namespace\n\tFailOnErr(Run(\"\", \"kubectl\", \"create\", \"ns\", DeploymentNamespace()))\n\tFailOnErr(Run(\"\", \"kubectl\", \"label\", \"ns\", DeploymentNamespace(), testingLabel+\"=true\"))\n\n\tlog.WithFields(log.Fields{\"duration\": time.Since(start), \"name\": t.Name(), \"id\": id, \"username\": \"admin\", \"password\": \"password\"}).Info(\"clean state\")\n}\n\nfunc RunCli(args ...string) (string, error) {\n\treturn RunCliWithStdin(\"\", args...)\n}\n\nfunc RunCliWithStdin(stdin string, args ...string) (string, error) {\n\tif plainText {\n\t\targs = append(args, \"--plaintext\")\n\t}\n\n\targs = append(args, \"--server\", apiServerAddress, \"--auth-token\", token, \"--insecure\")\n\n\treturn RunWithStdin(stdin, \"\", \"../../dist/argocd\", args...)\n}\n\nfunc Patch(path string, jsonPatch string) {\n\n\tlog.WithFields(log.Fields{\"path\": path, \"jsonPatch\": jsonPatch}).Info(\"patching\")\n\n\tfilename := filepath.Join(repoDirectory(), path)\n\tbytes, err := ioutil.ReadFile(filename)\n\tCheckError(err)\n\n\tpatch, err := jsonpatch.DecodePatch([]byte(jsonPatch))\n\tCheckError(err)\n\n\tisYaml := strings.HasSuffix(filename, \".yaml\")\n\tif isYaml {\n\t\tlog.Info(\"converting YAML to JSON\")\n\t\tbytes, err = yaml.YAMLToJSON(bytes)\n\t\tCheckError(err)\n\t}\n\n\tlog.WithFields(log.Fields{\"bytes\": string(bytes)}).Info(\"JSON\")\n\n\tbytes, err = patch.Apply(bytes)\n\tCheckError(err)\n\n\tif isYaml {\n\t\tlog.Info(\"converting JSON back to YAML\")\n\t\tbytes, err = yaml.JSONToYAML(bytes)\n\t\tCheckError(err)\n\t}\n\n\tCheckError(ioutil.WriteFile(filename, bytes, 0644))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"diff\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"commit\", \"-am\", \"patch\"))\n\tif IsRemote() {\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"push\", \"-f\", \"origin\", \"master\"))\n\t}\n}\n\nfunc Delete(path string) {\n\n\tlog.WithFields(log.Fields{\"path\": path}).Info(\"deleting\")\n\n\tCheckError(os.Remove(filepath.Join(repoDirectory(), path)))\n\n\tFailOnErr(Run(repoDirectory(), \"git\", \"diff\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"commit\", \"-am\", \"delete\"))\n\tif IsRemote() {\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"push\", \"-f\", \"origin\", \"master\"))\n\t}\n}\n\nfunc WriteFile(path, contents string) {\n\tlog.WithFields(log.Fields{\"path\": path}).Info(\"adding\")\n\n\tCheckError(ioutil.WriteFile(filepath.Join(repoDirectory(), path), []byte(contents), 0644))\n}\n\nfunc AddFile(path, contents string) {\n\n\tWriteFile(path, contents)\n\n\tFailOnErr(Run(repoDirectory(), \"git\", \"diff\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"add\", \".\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"commit\", \"-am\", \"add file\"))\n\n\tif IsRemote() {\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"push\", \"-f\", \"origin\", \"master\"))\n\t}\n}\n\nfunc AddSignedFile(path, contents string) {\n\tWriteFile(path, contents)\n\n\tprevGnuPGHome := os.Getenv(\"GNUPGHOME\")\n\tos.Setenv(\"GNUPGHOME\", TmpDir+\"/gpg\")\n\tFailOnErr(Run(repoDirectory(), \"git\", \"diff\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"add\", \".\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"-c\", fmt.Sprintf(\"user.signingkey=%s\", GpgGoodKeyID), \"commit\", \"-S\", \"-am\", \"add file\"))\n\tos.Setenv(\"GNUPGHOME\", prevGnuPGHome)\n\tif IsRemote() {\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"push\", \"-f\", \"origin\", \"master\"))\n\t}\n}\n\n// create the resource by creating using \"kubectl apply\", with bonus templating\nfunc Declarative(filename string, values interface{}) (string, error) {\n\n\tbytes, err := ioutil.ReadFile(path.Join(\"testdata\", filename))\n\tCheckError(err)\n\n\ttmpFile, err := ioutil.TempFile(\"\", \"\")\n\tCheckError(err)\n\t_, err = tmpFile.WriteString(Tmpl(string(bytes), values))\n\tCheckError(err)\n\tdefer tmpFile.Close()\n\treturn Run(\"\", \"kubectl\", \"-n\", TestNamespace(), \"apply\", \"-f\", tmpFile.Name())\n}\n\nfunc CreateSubmoduleRepos(repoType string) {\n\n\t// set-up submodule repo\n\tFailOnErr(Run(\"\", \"cp\", \"-Rf\", \"testdata/git-submodule/\", submoduleDirectory()))\n\tFailOnErr(Run(submoduleDirectory(), \"chmod\", \"777\", \".\"))\n\tFailOnErr(Run(submoduleDirectory(), \"git\", \"init\"))\n\tFailOnErr(Run(submoduleDirectory(), \"git\", \"add\", \".\"))\n\tFailOnErr(Run(submoduleDirectory(), \"git\", \"commit\", \"-q\", \"-m\", \"initial commit\"))\n\n\tif IsRemote() {\n\t\tFailOnErr(Run(submoduleDirectory(), \"git\", \"remote\", \"add\", \"origin\", os.Getenv(\"ARGOCD_E2E_GIT_SERVICE_SUBMODULE\")))\n\t\tFailOnErr(Run(submoduleDirectory(), \"git\", \"push\", \"origin\", \"master\", \"-f\"))\n\t}\n\n\t// set-up submodule parent repo\n\tFailOnErr(Run(\"\", \"mkdir\", submoduleParentDirectory()))\n\tFailOnErr(Run(submoduleParentDirectory(), \"chmod\", \"777\", \".\"))\n\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"init\"))\n\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"add\", \".\"))\n\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"submodule\", \"add\", \"-b\", \"master\", \"../submodule.git\", \"submodule/test\"))\n\tif repoType == \"ssh\" {\n\t\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"config\", \"--file=.gitmodules\", \"submodule.submodule/test.url\", RepoURL(RepoURLTypeSSHSubmodule)))\n\t} else if repoType == \"https\" {\n\t\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"config\", \"--file=.gitmodules\", \"submodule.submodule/test.url\", RepoURL(RepoURLTypeHTTPSSubmodule)))\n\t}\n\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"add\", \"--all\"))\n\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"commit\", \"-q\", \"-m\", \"commit with submodule\"))\n\n\tif IsRemote() {\n\t\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"remote\", \"add\", \"origin\", os.Getenv(\"ARGOCD_E2E_GIT_SERVICE_SUBMODULE_PARENT\")))\n\t\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"push\", \"origin\", \"master\", \"-f\"))\n\t}\n}\n\n// RestartRepoServer performs a restart of the repo server deployment and waits\n// until the rollout has completed.\nfunc RestartRepoServer() {\n\tif IsRemote() {\n\t\tlog.Infof(\"Waiting for repo server to restart\")\n\t\tprefix := os.Getenv(\"ARGOCD_E2E_NAME_PREFIX\")\n\t\tworkload := \"argocd-repo-server\"\n\t\tif prefix != \"\" {\n\t\t\tworkload = prefix + \"-repo-server\"\n\t\t}\n\t\tFailOnErr(Run(\"\", \"kubectl\", \"rollout\", \"restart\", \"deployment\", workload))\n\t\tFailOnErr(Run(\"\", \"kubectl\", \"rollout\", \"status\", \"deployment\", workload))\n\t}\n}\n\n// RestartAPIServer performs a restart of the API server deployemt and waits\n// until the rollout has completed.\nfunc RestartAPIServer() {\n\tif IsRemote() {\n\t\tlog.Infof(\"Waiting for API server to restart\")\n\t\tprefix := os.Getenv(\"ARGOCD_E2E_NAME_PREFIX\")\n\t\tworkload := \"argocd-server\"\n\t\tif prefix != \"\" {\n\t\t\tworkload = prefix + \"-server\"\n\t\t}\n\t\tFailOnErr(Run(\"\", \"kubectl\", \"rollout\", \"restart\", \"deployment\", workload))\n\t\tFailOnErr(Run(\"\", \"kubectl\", \"rollout\", \"status\", \"deployment\", workload))\n\t}\n}\n\n// LocalOrRemotePath selects a path for a given application based on whether\n// tests are running local or remote.\nfunc LocalOrRemotePath(base string) string {\n\tif IsRemote() {\n\t\treturn base + \"/remote\"\n\t} else {\n\t\treturn base + \"/local\"\n\t}\n}\n\n// SkipOnEnv allows to skip a test when a given environment variable is set.\n// Environment variable names follow the ARGOCD_E2E_SKIP_<suffix> pattern,\n// and must be set to the string value 'true' in order to skip a test.\nfunc SkipOnEnv(t *testing.T, suffixes ...string) {\n\tfor _, suffix := range suffixes {\n\t\te := os.Getenv(\"ARGOCD_E2E_SKIP_\" + suffix)\n\t\tif e == \"true\" {\n\t\t\tt.Skip()\n\t\t}\n\t}\n}\n\n// SkipIfAlreadyRun skips a test if it has been already run by a previous\n// test cycle and was recorded.\nfunc SkipIfAlreadyRun(t *testing.T) {\n\tif _, ok := testsRun[t.Name()]; ok {\n\t\tt.Skip()\n\t}\n}\n\n// RecordTestRun records a test that has been run successfully to a text file,\n// so that it can be automatically skipped if requested.\nfunc RecordTestRun(t *testing.T) {\n\tif t.Skipped() || t.Failed() {\n\t\treturn\n\t}\n\trf := os.Getenv(\"ARGOCD_E2E_RECORD\")\n\tif rf == \"\" {\n\t\treturn\n\t}\n\tlog.Infof(\"Registering test execution at %s\", rf)\n\tf, err := os.OpenFile(rf, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)\n\tif err != nil {\n\t\tt.Fatalf(\"could not open record file %s: %v\", rf, err)\n\t}\n\tdefer f.Close()\n\tif _, err := f.WriteString(fmt.Sprintf(\"%s\\n\", t.Name())); err != nil {\n\t\tt.Fatalf(\"could not write to %s: %v\", rf, err)\n\t}\n}\n", "package e2e\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/argoproj/gitops-engine/pkg/health\"\n\t. \"github.com/argoproj/gitops-engine/pkg/sync/common\"\n\n\t. \"github.com/argoproj/argo-cd/v2/pkg/apis/application/v1alpha1\"\n\t\"github.com/argoproj/argo-cd/v2/test/e2e/fixture\"\n\t. \"github.com/argoproj/argo-cd/v2/test/e2e/fixture\"\n\t. \"github.com/argoproj/argo-cd/v2/test/e2e/fixture/app\"\n\t. \"github.com/argoproj/argo-cd/v2/util/errors\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n)\n\n// when you selectively sync, only selected resources should be synced, but the app will be out of sync\nfunc TestSelectiveSync(t *testing.T) {\n\tGiven(t).\n\t\tPath(\"guestbook\").\n\t\tSelectedResource(\":Service:guestbook-ui\").\n\t\tWhen().\n\t\tCreateApp().\n\t\tSync().\n\t\tThen().\n\t\tExpect(Success(\"\")).\n\t\tExpect(OperationPhaseIs(OperationSucceeded)).\n\t\tExpect(SyncStatusIs(SyncStatusCodeOutOfSync)).\n\t\tExpect(ResourceHealthIs(\"Service\", \"guestbook-ui\", health.HealthStatusHealthy)).\n\t\tExpect(ResourceHealthIs(\"Deployment\", \"guestbook-ui\", health.HealthStatusMissing))\n}\n\n// when running selective sync, hooks do not run\n// hooks don't run even if all resources are selected\nfunc TestSelectiveSyncDoesNotRunHooks(t *testing.T) {\n\tGiven(t).\n\t\tPath(\"hook\").\n\t\tSelectedResource(\":Pod:pod\").\n\t\tWhen().\n\t\tCreateApp().\n\t\tSync().\n\t\tThen().\n\t\tExpect(Success(\"\")).\n\t\tExpect(OperationPhaseIs(OperationSucceeded)).\n\t\tExpect(SyncStatusIs(SyncStatusCodeSynced)).\n\t\tExpect(HealthIs(health.HealthStatusHealthy)).\n\t\tExpect(ResourceHealthIs(\"Pod\", \"pod\", health.HealthStatusHealthy)).\n\t\tExpect(ResourceResultNumbering(1))\n}\n\nfunc TestSelectiveSyncWithoutNamespace(t *testing.T) {\n\tselectedResourceNamespace := getNewNamespace(t)\n\tdefer func() {\n\t\tif !t.Skipped() {\n\t\t\tFailOnErr(Run(\"\", \"kubectl\", \"delete\", \"namespace\", selectedResourceNamespace))\n\t\t}\n\t}()\n\tGiven(t).\n\t\tPrune(true).\n\t\tPath(\"guestbook-with-namespace\").\n\t\tAnd(func() {\n\t\t\tFailOnErr(Run(\"\", \"kubectl\", \"create\", \"namespace\", selectedResourceNamespace))\n\t\t}).\n\t\tSelectedResource(\"apps:Deployment:guestbook-ui\").\n\t\tWhen().\n\t\tPatchFile(\"guestbook-ui-deployment-ns.yaml\", fmt.Sprintf(`[{\"op\": \"replace\", \"path\": \"/metadata/namespace\", \"value\": \"%s\"}]`, selectedResourceNamespace)).\n\t\tPatchFile(\"guestbook-ui-svc-ns.yaml\", fmt.Sprintf(`[{\"op\": \"replace\", \"path\": \"/metadata/namespace\", \"value\": \"%s\"}]`, selectedResourceNamespace)).\n\t\tCreateApp().\n\t\tSync().\n\t\tThen().\n\t\tExpect(Success(\"\")).\n\t\tExpect(OperationPhaseIs(OperationSucceeded)).\n\t\tExpect(SyncStatusIs(SyncStatusCodeOutOfSync)).\n\t\tExpect(ResourceHealthWithNamespaceIs(\"Deployment\", \"guestbook-ui\", selectedResourceNamespace, health.HealthStatusHealthy)).\n\t\tExpect(ResourceHealthWithNamespaceIs(\"Deployment\", \"guestbook-ui\", fixture.DeploymentNamespace(), health.HealthStatusHealthy)).\n\t\tExpect(ResourceSyncStatusWithNamespaceIs(\"Deployment\", \"guestbook-ui\", selectedResourceNamespace, SyncStatusCodeSynced)).\n\t\tExpect(ResourceSyncStatusWithNamespaceIs(\"Deployment\", \"guestbook-ui\", fixture.DeploymentNamespace(), SyncStatusCodeSynced))\n}\n\n//In selectedResource to sync, namespace is provided\nfunc TestSelectiveSyncWithNamespace(t *testing.T) {\n\tselectedResourceNamespace := getNewNamespace(t)\n\tdefer func() {\n\t\tif !t.Skipped() {\n\t\t\tFailOnErr(Run(\"\", \"kubectl\", \"delete\", \"namespace\", selectedResourceNamespace))\n\t\t}\n\t}()\n\tGiven(t).\n\t\tPrune(true).\n\t\tPath(\"guestbook-with-namespace\").\n\t\tAnd(func() {\n\t\t\tFailOnErr(Run(\"\", \"kubectl\", \"create\", \"namespace\", selectedResourceNamespace))\n\t\t}).\n\t\tSelectedResource(fmt.Sprintf(\"apps:Deployment:%s/guestbook-ui\", selectedResourceNamespace)).\n\t\tWhen().\n\t\tPatchFile(\"guestbook-ui-deployment-ns.yaml\", fmt.Sprintf(`[{\"op\": \"replace\", \"path\": \"/metadata/namespace\", \"value\": \"%s\"}]`, selectedResourceNamespace)).\n\t\tPatchFile(\"guestbook-ui-svc-ns.yaml\", fmt.Sprintf(`[{\"op\": \"replace\", \"path\": \"/metadata/namespace\", \"value\": \"%s\"}]`, selectedResourceNamespace)).\n\t\tCreateApp().\n\t\tSync().\n\t\tThen().\n\t\tExpect(Success(\"\")).\n\t\tExpect(OperationPhaseIs(OperationSucceeded)).\n\t\tExpect(SyncStatusIs(SyncStatusCodeOutOfSync)).\n\t\tExpect(ResourceHealthWithNamespaceIs(\"Deployment\", \"guestbook-ui\", selectedResourceNamespace, health.HealthStatusHealthy)).\n\t\tExpect(ResourceHealthWithNamespaceIs(\"Deployment\", \"guestbook-ui\", fixture.DeploymentNamespace(), health.HealthStatusMissing)).\n\t\tExpect(ResourceSyncStatusWithNamespaceIs(\"Deployment\", \"guestbook-ui\", selectedResourceNamespace, SyncStatusCodeSynced)).\n\t\tExpect(ResourceSyncStatusWithNamespaceIs(\"Deployment\", \"guestbook-ui\", fixture.DeploymentNamespace(), SyncStatusCodeOutOfSync))\n}\n\nfunc getNewNamespace(t *testing.T) string {\n\tpostFix := \"-\" + strings.ToLower(rand.RandString(5))\n\tname := fixture.DnsFriendly(t.Name(), \"\")\n\treturn fixture.DnsFriendly(fmt.Sprintf(\"argocd-e2e-%s\", name), postFix)\n}\n", "package oidc\n\nimport (\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"html\"\n\t\"html/template\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"path\"\n\t\"strings\"\n\t\"time\"\n\n\tgooidc \"github.com/coreos/go-oidc\"\n\t\"github.com/golang-jwt/jwt/v4\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"golang.org/x/oauth2\"\n\n\t\"github.com/argoproj/argo-cd/v2/common\"\n\t\"github.com/argoproj/argo-cd/v2/server/settings/oidc\"\n\t\"github.com/argoproj/argo-cd/v2/util/crypto\"\n\t\"github.com/argoproj/argo-cd/v2/util/dex\"\n\thttputil \"github.com/argoproj/argo-cd/v2/util/http\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n\t\"github.com/argoproj/argo-cd/v2/util/settings\"\n)\n\nconst (\n\tGrantTypeAuthorizationCode = \"authorization_code\"\n\tGrantTypeImplicit          = \"implicit\"\n\tResponseTypeCode           = \"code\"\n)\n\n// OIDCConfiguration holds a subset of interested fields from the OIDC configuration spec\ntype OIDCConfiguration struct {\n\tIssuer                 string   `json:\"issuer\"`\n\tScopesSupported        []string `json:\"scopes_supported\"`\n\tResponseTypesSupported []string `json:\"response_types_supported\"`\n\tGrantTypesSupported    []string `json:\"grant_types_supported,omitempty\"`\n}\n\ntype ClaimsRequest struct {\n\tIDToken map[string]*oidc.Claim `json:\"id_token\"`\n}\n\ntype ClientApp struct {\n\t// OAuth2 client ID of this application (e.g. argo-cd)\n\tclientID string\n\t// OAuth2 client secret of this application\n\tclientSecret string\n\t// Callback URL for OAuth2 responses (e.g. https://argocd.example.com/auth/callback)\n\tredirectURI string\n\t// URL of the issuer (e.g. https://argocd.example.com/api/dex)\n\tissuerURL string\n\t// The URL endpoint at which the ArgoCD server is accessed.\n\tbaseHRef string\n\t// client is the HTTP client which is used to query the IDp\n\tclient *http.Client\n\t// secureCookie indicates if the cookie should be set with the Secure flag, meaning it should\n\t// only ever be sent over HTTPS. This value is inferred by the scheme of the redirectURI.\n\tsecureCookie bool\n\t// settings holds Argo CD settings\n\tsettings *settings.ArgoCDSettings\n\t// encryptionKey holds server encryption key\n\tencryptionKey []byte\n\t// provider is the OIDC provider\n\tprovider Provider\n}\n\nfunc GetScopesOrDefault(scopes []string) []string {\n\tif len(scopes) == 0 {\n\t\treturn []string{\"openid\", \"profile\", \"email\", \"groups\"}\n\t}\n\treturn scopes\n}\n\n// NewClientApp will register the Argo CD client app (either via Dex or external OIDC) and return an\n// object which has HTTP handlers for handling the HTTP responses for login and callback\nfunc NewClientApp(settings *settings.ArgoCDSettings, dexServerAddr, baseHRef string) (*ClientApp, error) {\n\tredirectURL, err := settings.RedirectURL()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tencryptionKey, err := settings.GetServerEncryptionKey()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ta := ClientApp{\n\t\tclientID:      settings.OAuth2ClientID(),\n\t\tclientSecret:  settings.OAuth2ClientSecret(),\n\t\tredirectURI:   redirectURL,\n\t\tissuerURL:     settings.IssuerURL(),\n\t\tbaseHRef:      baseHRef,\n\t\tencryptionKey: encryptionKey,\n\t}\n\tlog.Infof(\"Creating client app (%s)\", a.clientID)\n\tu, err := url.Parse(settings.URL)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parse redirect-uri: %v\", err)\n\t}\n\ttlsConfig := settings.OIDCTLSConfig()\n\ta.client = &http.Client{\n\t\tTransport: &http.Transport{\n\t\t\tTLSClientConfig: tlsConfig,\n\t\t\tProxy:           http.ProxyFromEnvironment,\n\t\t\tDial: (&net.Dialer{\n\t\t\t\tTimeout:   30 * time.Second,\n\t\t\t\tKeepAlive: 30 * time.Second,\n\t\t\t}).Dial,\n\t\t\tTLSHandshakeTimeout:   10 * time.Second,\n\t\t\tExpectContinueTimeout: 1 * time.Second,\n\t\t},\n\t}\n\tif settings.DexConfig != \"\" && settings.OIDCConfigRAW == \"\" {\n\t\ta.client.Transport = dex.NewDexRewriteURLRoundTripper(dexServerAddr, a.client.Transport)\n\t}\n\tif os.Getenv(common.EnvVarSSODebug) == \"1\" {\n\t\ta.client.Transport = httputil.DebugTransport{T: a.client.Transport}\n\t}\n\n\ta.provider = NewOIDCProvider(a.issuerURL, a.client)\n\t// NOTE: if we ever have replicas of Argo CD, this needs to switch to Redis cache\n\ta.secureCookie = bool(u.Scheme == \"https\")\n\ta.settings = settings\n\treturn &a, nil\n}\n\nfunc (a *ClientApp) oauth2Config(scopes []string) (*oauth2.Config, error) {\n\tendpoint, err := a.provider.Endpoint()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &oauth2.Config{\n\t\tClientID:     a.clientID,\n\t\tClientSecret: a.clientSecret,\n\t\tEndpoint:     *endpoint,\n\t\tScopes:       scopes,\n\t\tRedirectURL:  a.redirectURI,\n\t}, nil\n}\n\n// generateAppState creates an app state nonce\nfunc (a *ClientApp) generateAppState(returnURL string, w http.ResponseWriter) (string, error) {\n\trandStr := rand.RandString(10)\n\tif returnURL == \"\" {\n\t\treturnURL = a.baseHRef\n\t}\n\tcookieValue := fmt.Sprintf(\"%s:%s\", randStr, returnURL)\n\tif encrypted, err := crypto.Encrypt([]byte(cookieValue), a.encryptionKey); err != nil {\n\t\treturn \"\", err\n\t} else {\n\t\tcookieValue = hex.EncodeToString(encrypted)\n\t}\n\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     common.StateCookieName,\n\t\tValue:    cookieValue,\n\t\tExpires:  time.Now().Add(common.StateCookieMaxAge),\n\t\tHttpOnly: true,\n\t\tSameSite: http.SameSiteLaxMode,\n\t\tSecure:   a.secureCookie,\n\t})\n\treturn randStr, nil\n}\n\nfunc (a *ClientApp) verifyAppState(r *http.Request, w http.ResponseWriter, state string) (string, error) {\n\tc, err := r.Cookie(common.StateCookieName)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tval, err := hex.DecodeString(c.Value)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tval, err = crypto.Decrypt(val, a.encryptionKey)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tcookieVal := string(val)\n\treturnURL := a.baseHRef\n\tparts := strings.SplitN(cookieVal, \":\", 2)\n\tif len(parts) == 2 && parts[1] != \"\" {\n\t\treturnURL = parts[1]\n\t}\n\tif parts[0] != state {\n\t\treturn \"\", fmt.Errorf(\"invalid state in '%s' cookie\", common.AuthCookieName)\n\t}\n\t// set empty cookie to clear it\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     common.StateCookieName,\n\t\tValue:    \"\",\n\t\tHttpOnly: true,\n\t\tSameSite: http.SameSiteLaxMode,\n\t\tSecure:   a.secureCookie,\n\t})\n\treturn returnURL, nil\n}\n\n// isValidRedirectURL checks whether the given redirectURL matches on of the\n// allowed URLs to redirect to.\n//\n// In order to be considered valid,the protocol and host (including port) have\n// to match and if allowed path is not \"/\", redirectURL's path must be within\n// allowed URL's path.\nfunc isValidRedirectURL(redirectURL string, allowedURLs []string) bool {\n\tif redirectURL == \"\" {\n\t\treturn true\n\t}\n\tr, err := url.Parse(redirectURL)\n\tif err != nil {\n\t\treturn false\n\t}\n\t// We consider empty path the same as \"/\" for redirect URL\n\tif r.Path == \"\" {\n\t\tr.Path = \"/\"\n\t}\n\t// Prevent CRLF in the redirectURL\n\tif strings.ContainsAny(r.Path, \"\\r\\n\") {\n\t\treturn false\n\t}\n\tfor _, baseURL := range allowedURLs {\n\t\tb, err := url.Parse(baseURL)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\t// We consider empty path the same as \"/\" for allowed URL\n\t\tif b.Path == \"\" {\n\t\t\tb.Path = \"/\"\n\t\t}\n\t\t// scheme and host are mandatory to match.\n\t\tif b.Scheme == r.Scheme && b.Host == r.Host {\n\t\t\t// If path of redirectURL and allowedURL match, redirectURL is allowed\n\t\t\t//if b.Path == r.Path {\n\t\t\t//\treturn true\n\t\t\t//}\n\t\t\t// If path of redirectURL is within allowed URL's path, redirectURL is allowed\n\t\t\tif strings.HasPrefix(path.Clean(r.Path), b.Path) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\t// No match - redirect URL is not allowed\n\treturn false\n}\n\n// HandleLogin formulates the proper OAuth2 URL (auth code or implicit) and redirects the user to\n// the IDp login & consent page\nfunc (a *ClientApp) HandleLogin(w http.ResponseWriter, r *http.Request) {\n\toidcConf, err := a.provider.ParseConfig()\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tscopes := make([]string, 0)\n\tvar opts []oauth2.AuthCodeOption\n\tif config := a.settings.OIDCConfig(); config != nil {\n\t\tscopes = config.RequestedScopes\n\t\topts = AppendClaimsAuthenticationRequestParameter(opts, config.RequestedIDTokenClaims)\n\t}\n\toauth2Config, err := a.oauth2Config(GetScopesOrDefault(scopes))\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\treturnURL := r.FormValue(\"return_url\")\n\t// Check if return_url is valid, otherwise abort processing (see https://github.com/argoproj/argo-cd/pull/4780)\n\tif !isValidRedirectURL(returnURL, []string{a.settings.URL}) {\n\t\thttp.Error(w, \"Invalid redirect URL: the protocol and host (including port) must match and the path must be within allowed URLs if provided\", http.StatusBadRequest)\n\t\treturn\n\t}\n\tstateNonce, err := a.generateAppState(returnURL, w)\n\tif err != nil {\n\t\tlog.Errorf(\"Failed to initiate login flow: %v\", err)\n\t\thttp.Error(w, \"Failed to initiate login flow\", http.StatusInternalServerError)\n\t\treturn\n\t}\n\tgrantType := InferGrantType(oidcConf)\n\tvar url string\n\tswitch grantType {\n\tcase GrantTypeAuthorizationCode:\n\t\turl = oauth2Config.AuthCodeURL(stateNonce, opts...)\n\tcase GrantTypeImplicit:\n\t\turl = ImplicitFlowURL(oauth2Config, stateNonce, opts...)\n\tdefault:\n\t\thttp.Error(w, fmt.Sprintf(\"Unsupported grant type: %v\", grantType), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tlog.Infof(\"Performing %s flow login: %s\", grantType, url)\n\thttp.Redirect(w, r, url, http.StatusSeeOther)\n}\n\n// HandleCallback is the callback handler for an OAuth2 login flow\nfunc (a *ClientApp) HandleCallback(w http.ResponseWriter, r *http.Request) {\n\toauth2Config, err := a.oauth2Config(nil)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tlog.Infof(\"Callback: %s\", r.URL)\n\tif errMsg := r.FormValue(\"error\"); errMsg != \"\" {\n\t\terrorDesc := r.FormValue(\"error_description\")\n\t\thttp.Error(w, html.EscapeString(errMsg)+\": \"+html.EscapeString(errorDesc), http.StatusBadRequest)\n\t\treturn\n\t}\n\tcode := r.FormValue(\"code\")\n\tstate := r.FormValue(\"state\")\n\tif code == \"\" {\n\t\t// If code was not given, it implies implicit flow\n\t\ta.handleImplicitFlow(r, w, state)\n\t\treturn\n\t}\n\treturnURL, err := a.verifyAppState(r, w, state)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\tctx := gooidc.ClientContext(r.Context(), a.client)\n\ttoken, err := oauth2Config.Exchange(ctx, code)\n\tif err != nil {\n\t\thttp.Error(w, fmt.Sprintf(\"failed to get token: %v\", err), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tidTokenRAW, ok := token.Extra(\"id_token\").(string)\n\tif !ok {\n\t\thttp.Error(w, \"no id_token in token response\", http.StatusInternalServerError)\n\t\treturn\n\t}\n\tidToken, err := a.provider.Verify(a.clientID, idTokenRAW)\n\tif err != nil {\n\t\thttp.Error(w, fmt.Sprintf(\"invalid session token: %v\", err), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tpath := \"/\"\n\tif a.baseHRef != \"\" {\n\t\tpath = strings.TrimRight(strings.TrimLeft(a.baseHRef, \"/\"), \"/\")\n\t}\n\tcookiePath := fmt.Sprintf(\"path=/%s\", path)\n\tflags := []string{cookiePath, \"SameSite=lax\", \"httpOnly\"}\n\tif a.secureCookie {\n\t\tflags = append(flags, \"Secure\")\n\t}\n\tvar claims jwt.MapClaims\n\terr = idToken.Claims(&claims)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tif idTokenRAW != \"\" {\n\t\tcookies, err := httputil.MakeCookieMetadata(common.AuthCookieName, idTokenRAW, flags...)\n\t\tif err != nil {\n\t\t\tclaimsJSON, _ := json.Marshal(claims)\n\t\t\thttp.Error(w, fmt.Sprintf(\"claims=%s, err=%v\", claimsJSON, err), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tfor _, cookie := range cookies {\n\t\t\tw.Header().Add(\"Set-Cookie\", cookie)\n\t\t}\n\t}\n\n\tclaimsJSON, _ := json.Marshal(claims)\n\tlog.Infof(\"Web login successful. Claims: %s\", claimsJSON)\n\tif os.Getenv(common.EnvVarSSODebug) == \"1\" {\n\t\tclaimsJSON, _ := json.MarshalIndent(claims, \"\", \"  \")\n\t\trenderToken(w, a.redirectURI, idTokenRAW, token.RefreshToken, claimsJSON)\n\t} else {\n\t\thttp.Redirect(w, r, returnURL, http.StatusSeeOther)\n\t}\n}\n\nvar implicitFlowTmpl = template.Must(template.New(\"implicit.html\").Parse(`<script>\nvar hash = window.location.hash.substr(1);\nvar result = hash.split('&').reduce(function (result, item) {\n\tvar parts = item.split('=');\n\tresult[parts[0]] = parts[1];\n\treturn result;\n}, {});\nvar idToken = result['id_token'];\nvar state = result['state'];\nvar returnURL = \"{{ .ReturnURL }}\";\nif (state != \"\" && returnURL == \"\") {\n\twindow.location.href = window.location.href.split(\"#\")[0] + \"?state=\" + result['state'] + window.location.hash;\n} else if (returnURL != \"\") {\n\tdocument.cookie = \"{{ .CookieName }}=\" + idToken + \"; path=/\";\n\twindow.location.href = returnURL;\n}\n</script>`))\n\n// handleImplicitFlow completes an implicit OAuth2 flow. The id_token and state will be contained\n// in the URL fragment. The javascript client first redirects to the callback URL, supplying the\n// state nonce for verification, as well as looking up the return URL. Once verified, the client\n// stores the id_token from the fragment as a cookie. Finally it performs the final redirect back to\n// the return URL.\nfunc (a *ClientApp) handleImplicitFlow(r *http.Request, w http.ResponseWriter, state string) {\n\ttype implicitFlowValues struct {\n\t\tCookieName string\n\t\tReturnURL  string\n\t}\n\tvals := implicitFlowValues{\n\t\tCookieName: common.AuthCookieName,\n\t}\n\tif state != \"\" {\n\t\treturnURL, err := a.verifyAppState(r, w, state)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tvals.ReturnURL = returnURL\n\t}\n\trenderTemplate(w, implicitFlowTmpl, vals)\n}\n\n// ImplicitFlowURL is an adaptation of oauth2.Config::AuthCodeURL() which returns a URL\n// appropriate for an OAuth2 implicit login flow (as opposed to authorization code flow).\nfunc ImplicitFlowURL(c *oauth2.Config, state string, opts ...oauth2.AuthCodeOption) string {\n\topts = append(opts, oauth2.SetAuthURLParam(\"response_type\", \"id_token\"))\n\topts = append(opts, oauth2.SetAuthURLParam(\"nonce\", rand.RandString(10)))\n\treturn c.AuthCodeURL(state, opts...)\n}\n\n// OfflineAccess returns whether or not 'offline_access' is a supported scope\nfunc OfflineAccess(scopes []string) bool {\n\tif len(scopes) == 0 {\n\t\t// scopes_supported is a \"RECOMMENDED\" discovery claim, not a required\n\t\t// one. If missing, assume that the provider follows the spec and has\n\t\t// an \"offline_access\" scope.\n\t\treturn true\n\t}\n\t// See if scopes_supported has the \"offline_access\" scope.\n\tfor _, scope := range scopes {\n\t\tif scope == gooidc.ScopeOfflineAccess {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// InferGrantType infers the proper grant flow depending on the OAuth2 client config and OIDC configuration.\n// Returns either: \"authorization_code\" or \"implicit\"\nfunc InferGrantType(oidcConf *OIDCConfiguration) string {\n\t// Check the supported response types. If the list contains the response type 'code',\n\t// then grant type is 'authorization_code'. This is preferred over the implicit\n\t// grant type since refresh tokens cannot be issued that way.\n\tfor _, supportedType := range oidcConf.ResponseTypesSupported {\n\t\tif supportedType == ResponseTypeCode {\n\t\t\treturn GrantTypeAuthorizationCode\n\t\t}\n\t}\n\n\t// Assume implicit otherwise\n\treturn GrantTypeImplicit\n}\n\n// AppendClaimsAuthenticationRequestParameter appends a OIDC claims authentication request parameter\n// to `opts` with the `requestedClaims`\nfunc AppendClaimsAuthenticationRequestParameter(opts []oauth2.AuthCodeOption, requestedClaims map[string]*oidc.Claim) []oauth2.AuthCodeOption {\n\tif len(requestedClaims) == 0 {\n\t\treturn opts\n\t}\n\tlog.Infof(\"RequestedClaims: %s\\n\", requestedClaims)\n\tclaimsRequestParameter, err := createClaimsAuthenticationRequestParameter(requestedClaims)\n\tif err != nil {\n\t\tlog.Errorf(\"Failed to create OIDC claims authentication request parameter from config: %s\", err)\n\t\treturn opts\n\t}\n\treturn append(opts, claimsRequestParameter)\n}\n\nfunc createClaimsAuthenticationRequestParameter(requestedClaims map[string]*oidc.Claim) (oauth2.AuthCodeOption, error) {\n\tclaimsRequest := ClaimsRequest{IDToken: requestedClaims}\n\tclaimsRequestRAW, err := json.Marshal(claimsRequest)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn oauth2.SetAuthURLParam(\"claims\", string(claimsRequestRAW)), nil\n}\n", "package rand\n\nimport (\n\t\"math/rand\"\n\t\"time\"\n)\n\nconst letterBytes = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\nconst (\n\tletterIdxBits = 6                    // 6 bits to represent a letter index\n\tletterIdxMask = 1<<letterIdxBits - 1 // All 1-bits, as many as letterIdxBits\n\tletterIdxMax  = 63 / letterIdxBits   // # of letter indices fitting in 63 bits\n)\n\nvar src = rand.NewSource(time.Now().UnixNano())\n\n// RandString generates, from a given charset, a cryptographically-secure pseudo-random string of a given length.\nfunc RandString(n int) string {\n\treturn RandStringCharset(n, letterBytes)\n}\n\nfunc RandStringCharset(n int, charset string) string {\n\tb := make([]byte, n)\n\t// A src.Int63() generates 63 random bits, enough for letterIdxMax characters!\n\tfor i, cache, remain := n-1, src.Int63(), letterIdxMax; i >= 0; {\n\t\tif remain == 0 {\n\t\t\tcache, remain = src.Int63(), letterIdxMax\n\t\t}\n\t\tif idx := int(cache & letterIdxMask); idx < len(charset) {\n\t\t\tb[i] = charset[idx]\n\t\t\ti--\n\t\t}\n\t\tcache >>= letterIdxBits\n\t\tremain--\n\t}\n\treturn string(b)\n}\n", "package rand\n\nimport (\n\t\"testing\"\n)\n\nfunc TestRandString(t *testing.T) {\n\tss := RandStringCharset(10, \"A\")\n\tif ss != \"AAAAAAAAAA\" {\n\t\tt.Errorf(\"Expected 10 As, but got %q\", ss)\n\t}\n\tss = RandStringCharset(5, \"ABC123\")\n\tif len(ss) != 5 {\n\t\tt.Errorf(\"Expected random string of length 10, but got %q\", ss)\n\t}\n}\n"], "fixing_code": ["package commands\n\nimport (\n\t\"context\"\n\t\"crypto/sha256\"\n\t\"encoding/base64\"\n\t\"fmt\"\n\t\"html\"\n\t\"net/http\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/coreos/go-oidc\"\n\t\"github.com/golang-jwt/jwt/v4\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"github.com/skratchdot/open-golang/open\"\n\t\"github.com/spf13/cobra\"\n\t\"golang.org/x/oauth2\"\n\n\t\"github.com/argoproj/argo-cd/v2/cmd/argocd/commands/headless\"\n\targocdclient \"github.com/argoproj/argo-cd/v2/pkg/apiclient\"\n\tsessionpkg \"github.com/argoproj/argo-cd/v2/pkg/apiclient/session\"\n\tsettingspkg \"github.com/argoproj/argo-cd/v2/pkg/apiclient/settings\"\n\t\"github.com/argoproj/argo-cd/v2/util/cli\"\n\t\"github.com/argoproj/argo-cd/v2/util/errors\"\n\tgrpc_util \"github.com/argoproj/argo-cd/v2/util/grpc\"\n\t\"github.com/argoproj/argo-cd/v2/util/io\"\n\tjwtutil \"github.com/argoproj/argo-cd/v2/util/jwt\"\n\t\"github.com/argoproj/argo-cd/v2/util/localconfig\"\n\toidcutil \"github.com/argoproj/argo-cd/v2/util/oidc\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n)\n\n// NewLoginCommand returns a new instance of `argocd login` command\nfunc NewLoginCommand(globalClientOpts *argocdclient.ClientOptions) *cobra.Command {\n\tvar (\n\t\tctxName  string\n\t\tusername string\n\t\tpassword string\n\t\tsso      bool\n\t\tssoPort  int\n\t)\n\tvar command = &cobra.Command{\n\t\tUse:   \"login SERVER\",\n\t\tShort: \"Log in to Argo CD\",\n\t\tLong:  \"Log in to Argo CD\",\n\t\tExample: `# Login to Argo CD using a username and password\nargocd login cd.argoproj.io\n\n# Login to Argo CD using SSO\nargocd login cd.argoproj.io --sso\n\n# Configure direct access using Kubernetes API server\nargocd login cd.argoproj.io --core`,\n\t\tRun: func(c *cobra.Command, args []string) {\n\t\t\tvar server string\n\n\t\t\tif len(args) != 1 && !globalClientOpts.PortForward && !globalClientOpts.Core {\n\t\t\t\tc.HelpFunc()(c, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\n\t\t\tif globalClientOpts.PortForward {\n\t\t\t\tserver = \"port-forward\"\n\t\t\t} else if globalClientOpts.Core {\n\t\t\t\tserver = \"kubernetes\"\n\t\t\t} else {\n\t\t\t\tserver = args[0]\n\t\t\t\ttlsTestResult, err := grpc_util.TestTLS(server)\n\t\t\t\terrors.CheckError(err)\n\t\t\t\tif !tlsTestResult.TLS {\n\t\t\t\t\tif !globalClientOpts.PlainText {\n\t\t\t\t\t\tif !cli.AskToProceed(\"WARNING: server is not configured with TLS. Proceed (y/n)? \") {\n\t\t\t\t\t\t\tos.Exit(1)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tglobalClientOpts.PlainText = true\n\t\t\t\t\t}\n\t\t\t\t} else if tlsTestResult.InsecureErr != nil {\n\t\t\t\t\tif !globalClientOpts.Insecure {\n\t\t\t\t\t\tif !cli.AskToProceed(fmt.Sprintf(\"WARNING: server certificate had error: %s. Proceed insecurely (y/n)? \", tlsTestResult.InsecureErr)) {\n\t\t\t\t\t\t\tos.Exit(1)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tglobalClientOpts.Insecure = true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tclientOpts := argocdclient.ClientOptions{\n\t\t\t\tConfigPath:           \"\",\n\t\t\t\tServerAddr:           server,\n\t\t\t\tInsecure:             globalClientOpts.Insecure,\n\t\t\t\tPlainText:            globalClientOpts.PlainText,\n\t\t\t\tClientCertFile:       globalClientOpts.ClientCertFile,\n\t\t\t\tClientCertKeyFile:    globalClientOpts.ClientCertKeyFile,\n\t\t\t\tGRPCWeb:              globalClientOpts.GRPCWeb,\n\t\t\t\tGRPCWebRootPath:      globalClientOpts.GRPCWebRootPath,\n\t\t\t\tPortForward:          globalClientOpts.PortForward,\n\t\t\t\tPortForwardNamespace: globalClientOpts.PortForwardNamespace,\n\t\t\t\tHeaders:              globalClientOpts.Headers,\n\t\t\t\tKubeOverrides:        globalClientOpts.KubeOverrides,\n\t\t\t}\n\n\t\t\tif ctxName == \"\" {\n\t\t\t\tctxName = server\n\t\t\t\tif globalClientOpts.GRPCWebRootPath != \"\" {\n\t\t\t\t\trootPath := strings.TrimRight(strings.TrimLeft(globalClientOpts.GRPCWebRootPath, \"/\"), \"/\")\n\t\t\t\t\tctxName = fmt.Sprintf(\"%s/%s\", server, rootPath)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Perform the login\n\t\t\tvar tokenString string\n\t\t\tvar refreshToken string\n\t\t\tif !globalClientOpts.Core {\n\t\t\t\tacdClient := headless.NewClientOrDie(&clientOpts, c)\n\t\t\t\tsetConn, setIf := acdClient.NewSettingsClientOrDie()\n\t\t\t\tdefer io.Close(setConn)\n\t\t\t\tif !sso {\n\t\t\t\t\ttokenString = passwordLogin(acdClient, username, password)\n\t\t\t\t} else {\n\t\t\t\t\tctx := context.Background()\n\t\t\t\t\thttpClient, err := acdClient.HTTPClient()\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\tctx = oidc.ClientContext(ctx, httpClient)\n\t\t\t\t\tacdSet, err := setIf.Get(ctx, &settingspkg.SettingsQuery{})\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\toauth2conf, provider, err := acdClient.OIDCConfig(ctx, acdSet)\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\ttokenString, refreshToken = oauth2Login(ctx, ssoPort, acdSet.GetOIDCConfig(), oauth2conf, provider)\n\t\t\t\t}\n\t\t\t\tparser := jwt.NewParser(jwt.WithoutClaimsValidation())\n\t\t\t\tclaims := jwt.MapClaims{}\n\t\t\t\t_, _, err := parser.ParseUnverified(tokenString, &claims)\n\t\t\t\terrors.CheckError(err)\n\t\t\t\tfmt.Printf(\"'%s' logged in successfully\\n\", userDisplayName(claims))\n\t\t\t}\n\n\t\t\t// login successful. Persist the config\n\t\t\tlocalCfg, err := localconfig.ReadLocalConfig(globalClientOpts.ConfigPath)\n\t\t\terrors.CheckError(err)\n\t\t\tif localCfg == nil {\n\t\t\t\tlocalCfg = &localconfig.LocalConfig{}\n\t\t\t}\n\t\t\tlocalCfg.UpsertServer(localconfig.Server{\n\t\t\t\tServer:          server,\n\t\t\t\tPlainText:       globalClientOpts.PlainText,\n\t\t\t\tInsecure:        globalClientOpts.Insecure,\n\t\t\t\tGRPCWeb:         globalClientOpts.GRPCWeb,\n\t\t\t\tGRPCWebRootPath: globalClientOpts.GRPCWebRootPath,\n\t\t\t\tCore:            globalClientOpts.Core,\n\t\t\t})\n\t\t\tlocalCfg.UpsertUser(localconfig.User{\n\t\t\t\tName:         ctxName,\n\t\t\t\tAuthToken:    tokenString,\n\t\t\t\tRefreshToken: refreshToken,\n\t\t\t})\n\t\t\tif ctxName == \"\" {\n\t\t\t\tctxName = server\n\t\t\t}\n\t\t\tlocalCfg.CurrentContext = ctxName\n\t\t\tlocalCfg.UpsertContext(localconfig.ContextRef{\n\t\t\t\tName:   ctxName,\n\t\t\t\tUser:   ctxName,\n\t\t\t\tServer: server,\n\t\t\t})\n\t\t\terr = localconfig.WriteLocalConfig(*localCfg, globalClientOpts.ConfigPath)\n\t\t\terrors.CheckError(err)\n\t\t\tfmt.Printf(\"Context '%s' updated\\n\", ctxName)\n\t\t},\n\t}\n\tcommand.Flags().StringVar(&ctxName, \"name\", \"\", \"name to use for the context\")\n\tcommand.Flags().StringVar(&username, \"username\", \"\", \"the username of an account to authenticate\")\n\tcommand.Flags().StringVar(&password, \"password\", \"\", \"the password of an account to authenticate\")\n\tcommand.Flags().BoolVar(&sso, \"sso\", false, \"perform SSO login\")\n\tcommand.Flags().IntVar(&ssoPort, \"sso-port\", DefaultSSOLocalPort, \"port to run local OAuth2 login application\")\n\treturn command\n}\n\nfunc userDisplayName(claims jwt.MapClaims) string {\n\tif email := jwtutil.StringField(claims, \"email\"); email != \"\" {\n\t\treturn email\n\t}\n\tif name := jwtutil.StringField(claims, \"name\"); name != \"\" {\n\t\treturn name\n\t}\n\treturn jwtutil.StringField(claims, \"sub\")\n}\n\n// oauth2Login opens a browser, runs a temporary HTTP server to delegate OAuth2 login flow and\n// returns the JWT token and a refresh token (if supported)\nfunc oauth2Login(ctx context.Context, port int, oidcSettings *settingspkg.OIDCConfig, oauth2conf *oauth2.Config, provider *oidc.Provider) (string, string) {\n\toauth2conf.RedirectURL = fmt.Sprintf(\"http://localhost:%d/auth/callback\", port)\n\toidcConf, err := oidcutil.ParseConfig(provider)\n\terrors.CheckError(err)\n\tlog.Debug(\"OIDC Configuration:\")\n\tlog.Debugf(\"  supported_scopes: %v\", oidcConf.ScopesSupported)\n\tlog.Debugf(\"  response_types_supported: %v\", oidcConf.ResponseTypesSupported)\n\n\t// handledRequests ensures we do not handle more requests than necessary\n\thandledRequests := 0\n\t// completionChan is to signal flow completed. Non-empty string indicates error\n\tcompletionChan := make(chan string)\n\t// stateNonce is an OAuth2 state nonce\n\t// According to the spec (https://www.rfc-editor.org/rfc/rfc6749#section-10.10), this must be guessable with\n\t// probability <= 2^(-128). The following call generates one of 52^24 random strings, ~= 2^136 possibilities.\n\tstateNonce, err := rand.String(24)\n\terrors.CheckError(err)\n\tvar tokenString string\n\tvar refreshToken string\n\n\thandleErr := func(w http.ResponseWriter, errMsg string) {\n\t\thttp.Error(w, html.EscapeString(errMsg), http.StatusBadRequest)\n\t\tcompletionChan <- errMsg\n\t}\n\n\t// PKCE implementation of https://tools.ietf.org/html/rfc7636\n\tcodeVerifier, err := rand.StringFromCharset(43, \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~\")\n\terrors.CheckError(err)\n\tcodeChallengeHash := sha256.Sum256([]byte(codeVerifier))\n\tcodeChallenge := base64.RawURLEncoding.EncodeToString(codeChallengeHash[:])\n\n\t// Authorization redirect callback from OAuth2 auth flow.\n\t// Handles both implicit and authorization code flow\n\tcallbackHandler := func(w http.ResponseWriter, r *http.Request) {\n\t\tlog.Debugf(\"Callback: %s\", r.URL)\n\n\t\tif formErr := r.FormValue(\"error\"); formErr != \"\" {\n\t\t\thandleErr(w, fmt.Sprintf(\"%s: %s\", formErr, r.FormValue(\"error_description\")))\n\t\t\treturn\n\t\t}\n\n\t\thandledRequests++\n\t\tif handledRequests > 2 {\n\t\t\t// Since implicit flow will redirect back to ourselves, this counter ensures we do not\n\t\t\t// fallinto a redirect loop (e.g. user visits the page by hand)\n\t\t\thandleErr(w, \"Unable to complete login flow: too many redirects\")\n\t\t\treturn\n\t\t}\n\n\t\tif len(r.Form) == 0 {\n\t\t\t// If we get here, no form data was set. We presume to be performing an implicit login\n\t\t\t// flow where the id_token is contained in a URL fragment, making it inaccessible to be\n\t\t\t// read from the request. This javascript will redirect the browser to send the\n\t\t\t// fragments as query parameters so our callback handler can read and return token.\n\t\t\tfmt.Fprintf(w, `<script>window.location.search = window.location.hash.substring(1)</script>`)\n\t\t\treturn\n\t\t}\n\n\t\tif state := r.FormValue(\"state\"); state != stateNonce {\n\t\t\thandleErr(w, \"Unknown state nonce\")\n\t\t\treturn\n\t\t}\n\n\t\ttokenString = r.FormValue(\"id_token\")\n\t\tif tokenString == \"\" {\n\t\t\tcode := r.FormValue(\"code\")\n\t\t\tif code == \"\" {\n\t\t\t\thandleErr(w, fmt.Sprintf(\"no code in request: %q\", r.Form))\n\t\t\t\treturn\n\t\t\t}\n\t\t\topts := []oauth2.AuthCodeOption{oauth2.SetAuthURLParam(\"code_verifier\", codeVerifier)}\n\t\t\ttok, err := oauth2conf.Exchange(ctx, code, opts...)\n\t\t\tif err != nil {\n\t\t\t\thandleErr(w, err.Error())\n\t\t\t\treturn\n\t\t\t}\n\t\t\tvar ok bool\n\t\t\ttokenString, ok = tok.Extra(\"id_token\").(string)\n\t\t\tif !ok {\n\t\t\t\thandleErr(w, \"no id_token in token response\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\trefreshToken, _ = tok.Extra(\"refresh_token\").(string)\n\t\t}\n\t\tsuccessPage := `\n\t\t<div style=\"height:100px; width:100%!; display:flex; flex-direction: column; justify-content: center; align-items:center; background-color:#2ecc71; color:white; font-size:22\"><div>Authentication successful!</div></div>\n\t\t<p style=\"margin-top:20px; font-size:18; text-align:center\">Authentication was successful, you can now return to CLI. This page will close automatically</p>\n\t\t<script>window.onload=function(){setTimeout(this.close, 4000)}</script>\n\t\t`\n\t\tfmt.Fprint(w, successPage)\n\t\tcompletionChan <- \"\"\n\t}\n\tsrv := &http.Server{Addr: \"localhost:\" + strconv.Itoa(port)}\n\thttp.HandleFunc(\"/auth/callback\", callbackHandler)\n\n\t// Redirect user to login & consent page to ask for permission for the scopes specified above.\n\tfmt.Printf(\"Opening browser for authentication\\n\")\n\n\tvar url string\n\tgrantType := oidcutil.InferGrantType(oidcConf)\n\topts := []oauth2.AuthCodeOption{oauth2.AccessTypeOffline}\n\tif claimsRequested := oidcSettings.GetIDTokenClaims(); claimsRequested != nil {\n\t\topts = oidcutil.AppendClaimsAuthenticationRequestParameter(opts, claimsRequested)\n\t}\n\n\tswitch grantType {\n\tcase oidcutil.GrantTypeAuthorizationCode:\n\t\topts = append(opts, oauth2.SetAuthURLParam(\"code_challenge\", codeChallenge))\n\t\topts = append(opts, oauth2.SetAuthURLParam(\"code_challenge_method\", \"S256\"))\n\t\turl = oauth2conf.AuthCodeURL(stateNonce, opts...)\n\tcase oidcutil.GrantTypeImplicit:\n\t\turl, err = oidcutil.ImplicitFlowURL(oauth2conf, stateNonce, opts...)\n\t\terrors.CheckError(err)\n\tdefault:\n\t\tlog.Fatalf(\"Unsupported grant type: %v\", grantType)\n\t}\n\tfmt.Printf(\"Performing %s flow login: %s\\n\", grantType, url)\n\ttime.Sleep(1 * time.Second)\n\terr = open.Start(url)\n\terrors.CheckError(err)\n\tgo func() {\n\t\tlog.Debugf(\"Listen: %s\", srv.Addr)\n\t\tif err := srv.ListenAndServe(); err != http.ErrServerClosed {\n\t\t\tlog.Fatalf(\"Temporary HTTP server failed: %s\", err)\n\t\t}\n\t}()\n\terrMsg := <-completionChan\n\tif errMsg != \"\" {\n\t\tlog.Fatal(errMsg)\n\t}\n\tfmt.Printf(\"Authentication successful\\n\")\n\tctx, cancel := context.WithTimeout(ctx, 1*time.Second)\n\tdefer cancel()\n\t_ = srv.Shutdown(ctx)\n\tlog.Debugf(\"Token: %s\", tokenString)\n\tlog.Debugf(\"Refresh Token: %s\", refreshToken)\n\treturn tokenString, refreshToken\n}\n\nfunc passwordLogin(acdClient argocdclient.Client, username, password string) string {\n\tusername, password = cli.PromptCredentials(username, password)\n\tsessConn, sessionIf := acdClient.NewSessionClientOrDie()\n\tdefer io.Close(sessConn)\n\tsessionRequest := sessionpkg.SessionCreateRequest{\n\t\tUsername: username,\n\t\tPassword: password,\n\t}\n\tcreatedSession, err := sessionIf.Create(context.Background(), &sessionRequest)\n\terrors.CheckError(err)\n\treturn createdSession.Token\n}\n", "package controller\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/argoproj/gitops-engine/pkg/sync\"\n\t\"github.com/argoproj/gitops-engine/pkg/sync/common\"\n\t\"github.com/argoproj/gitops-engine/pkg/utils/kube\"\n\tjsonpatch \"github.com/evanphx/json-patch\"\n\tlog \"github.com/sirupsen/logrus\"\n\tv1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured\"\n\t\"k8s.io/apimachinery/pkg/runtime/schema\"\n\t\"k8s.io/apimachinery/pkg/util/managedfields\"\n\t\"k8s.io/kubectl/pkg/util/openapi\"\n\n\tcdcommon \"github.com/argoproj/argo-cd/v2/common\"\n\t\"github.com/argoproj/argo-cd/v2/controller/metrics\"\n\t\"github.com/argoproj/argo-cd/v2/pkg/apis/application/v1alpha1\"\n\tlistersv1alpha1 \"github.com/argoproj/argo-cd/v2/pkg/client/listers/application/v1alpha1\"\n\t\"github.com/argoproj/argo-cd/v2/util/argo\"\n\t\"github.com/argoproj/argo-cd/v2/util/argo/diff\"\n\tlogutils \"github.com/argoproj/argo-cd/v2/util/log\"\n\t\"github.com/argoproj/argo-cd/v2/util/lua\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n)\n\nvar syncIdPrefix uint64 = 0\n\nconst (\n\t// EnvVarSyncWaveDelay is an environment variable which controls the delay in seconds between\n\t// each sync-wave\n\tEnvVarSyncWaveDelay = \"ARGOCD_SYNC_WAVE_DELAY\"\n)\n\nfunc (m *appStateManager) getOpenAPISchema(server string) (openapi.Resources, error) {\n\tcluster, err := m.liveStateCache.GetClusterCache(server)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn cluster.GetOpenAPISchema(), nil\n}\n\nfunc (m *appStateManager) getGVKParser(server string) (*managedfields.GvkParser, error) {\n\tcluster, err := m.liveStateCache.GetClusterCache(server)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn cluster.GetGVKParser(), nil\n}\n\nfunc (m *appStateManager) SyncAppState(app *v1alpha1.Application, state *v1alpha1.OperationState) {\n\t// Sync requests might be requested with ambiguous revisions (e.g. master, HEAD, v1.2.3).\n\t// This can change meaning when resuming operations (e.g a hook sync). After calculating a\n\t// concrete git commit SHA, the SHA is remembered in the status.operationState.syncResult field.\n\t// This ensures that when resuming an operation, we sync to the same revision that we initially\n\t// started with.\n\tvar revision string\n\tvar syncOp v1alpha1.SyncOperation\n\tvar syncRes *v1alpha1.SyncOperationResult\n\tvar source v1alpha1.ApplicationSource\n\n\tif state.Operation.Sync == nil {\n\t\tstate.Phase = common.OperationFailed\n\t\tstate.Message = \"Invalid operation request: no operation specified\"\n\t\treturn\n\t}\n\tsyncOp = *state.Operation.Sync\n\n\t// validates if it should fail the sync if it finds shared resources\n\thasSharedResource, sharedResourceMessage := hasSharedResourceCondition(app)\n\tif syncOp.SyncOptions.HasOption(\"FailOnSharedResource=true\") &&\n\t\thasSharedResource {\n\t\tstate.Phase = common.OperationFailed\n\t\tstate.Message = fmt.Sprintf(\"Shared resouce found: %s\", sharedResourceMessage)\n\t\treturn\n\t}\n\n\tif syncOp.Source == nil {\n\t\t// normal sync case (where source is taken from app.spec.source)\n\t\tsource = app.Spec.Source\n\t} else {\n\t\t// rollback case\n\t\tsource = *state.Operation.Sync.Source\n\t}\n\n\tif state.SyncResult != nil {\n\t\tsyncRes = state.SyncResult\n\t\trevision = state.SyncResult.Revision\n\t} else {\n\t\tsyncRes = &v1alpha1.SyncOperationResult{}\n\t\t// status.operationState.syncResult.source. must be set properly since auto-sync relies\n\t\t// on this information to decide if it should sync (if source is different than the last\n\t\t// sync attempt)\n\t\tsyncRes.Source = source\n\t\tstate.SyncResult = syncRes\n\t}\n\n\tif revision == \"\" {\n\t\t// if we get here, it means we did not remember a commit SHA which we should be syncing to.\n\t\t// This typically indicates we are just about to begin a brand new sync/rollback operation.\n\t\t// Take the value in the requested operation. We will resolve this to a SHA later.\n\t\trevision = syncOp.Revision\n\t}\n\n\tproj, err := argo.GetAppProject(&app.Spec, listersv1alpha1.NewAppProjectLister(m.projInformer.GetIndexer()), m.namespace, m.settingsMgr, m.db, context.TODO())\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = fmt.Sprintf(\"Failed to load application project: %v\", err)\n\t\treturn\n\t}\n\n\tcompareResult := m.CompareAppState(app, proj, revision, source, false, true, syncOp.Manifests)\n\t// We now have a concrete commit SHA. Save this in the sync result revision so that we remember\n\t// what we should be syncing to when resuming operations.\n\tsyncRes.Revision = compareResult.syncStatus.Revision\n\n\t// If there are any comparison or spec errors error conditions do not perform the operation\n\tif errConditions := app.Status.GetConditions(map[v1alpha1.ApplicationConditionType]bool{\n\t\tv1alpha1.ApplicationConditionComparisonError:  true,\n\t\tv1alpha1.ApplicationConditionInvalidSpecError: true,\n\t}); len(errConditions) > 0 {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = argo.FormatAppConditions(errConditions)\n\t\treturn\n\t}\n\n\tclst, err := m.db.GetCluster(context.Background(), app.Spec.Destination.Server)\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = err.Error()\n\t\treturn\n\t}\n\n\trawConfig := clst.RawRestConfig()\n\trestConfig := metrics.AddMetricsTransportWrapper(m.metricsServer, app, clst.RESTConfig())\n\n\tresourceOverrides, err := m.settingsMgr.GetResourceOverrides()\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = fmt.Sprintf(\"Failed to load resource overrides: %v\", err)\n\t\treturn\n\t}\n\n\tatomic.AddUint64(&syncIdPrefix, 1)\n\trandSuffix, err := rand.String(5)\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = fmt.Sprintf(\"Failed generate random sync ID: %v\", err)\n\t\treturn\n\t}\n\tsyncId := fmt.Sprintf(\"%05d-%s\", syncIdPrefix, randSuffix)\n\n\tlogEntry := log.WithFields(log.Fields{\"application\": app.Name, \"syncId\": syncId})\n\tinitialResourcesRes := make([]common.ResourceSyncResult, 0)\n\tfor i, res := range syncRes.Resources {\n\t\tkey := kube.ResourceKey{Group: res.Group, Kind: res.Kind, Namespace: res.Namespace, Name: res.Name}\n\t\tinitialResourcesRes = append(initialResourcesRes, common.ResourceSyncResult{\n\t\t\tResourceKey: key,\n\t\t\tMessage:     res.Message,\n\t\t\tStatus:      res.Status,\n\t\t\tHookPhase:   res.HookPhase,\n\t\t\tHookType:    res.HookType,\n\t\t\tSyncPhase:   res.SyncPhase,\n\t\t\tVersion:     res.Version,\n\t\t\tOrder:       i + 1,\n\t\t})\n\t}\n\n\tprunePropagationPolicy := v1.DeletePropagationForeground\n\tswitch {\n\tcase syncOp.SyncOptions.HasOption(\"PrunePropagationPolicy=background\"):\n\t\tprunePropagationPolicy = v1.DeletePropagationBackground\n\tcase syncOp.SyncOptions.HasOption(\"PrunePropagationPolicy=foreground\"):\n\t\tprunePropagationPolicy = v1.DeletePropagationForeground\n\tcase syncOp.SyncOptions.HasOption(\"PrunePropagationPolicy=orphan\"):\n\t\tprunePropagationPolicy = v1.DeletePropagationOrphan\n\t}\n\n\topenAPISchema, err := m.getOpenAPISchema(clst.Server)\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = fmt.Sprintf(\"failed to load openAPISchema: %v\", err)\n\t\treturn\n\t}\n\n\treconciliationResult := compareResult.reconciliationResult\n\n\t// if RespectIgnoreDifferences is enabled, it should normalize the target\n\t// resources which in this case applies the live values in the configured\n\t// ignore differences fields.\n\tif syncOp.SyncOptions.HasOption(\"RespectIgnoreDifferences=true\") {\n\t\tpatchedTargets, err := normalizeTargetResources(compareResult)\n\t\tif err != nil {\n\t\t\tstate.Phase = common.OperationError\n\t\t\tstate.Message = fmt.Sprintf(\"Failed to normalize target resources: %s\", err)\n\t\t\treturn\n\t\t}\n\t\treconciliationResult.Target = patchedTargets\n\t}\n\n\tsyncCtx, cleanup, err := sync.NewSyncContext(\n\t\tcompareResult.syncStatus.Revision,\n\t\treconciliationResult,\n\t\trestConfig,\n\t\trawConfig,\n\t\tm.kubectl,\n\t\tapp.Spec.Destination.Namespace,\n\t\topenAPISchema,\n\t\tsync.WithLogr(logutils.NewLogrusLogger(logEntry)),\n\t\tsync.WithHealthOverride(lua.ResourceHealthOverrides(resourceOverrides)),\n\t\tsync.WithPermissionValidator(func(un *unstructured.Unstructured, res *v1.APIResource) error {\n\t\t\tif !proj.IsGroupKindPermitted(un.GroupVersionKind().GroupKind(), res.Namespaced) {\n\t\t\t\treturn fmt.Errorf(\"Resource %s:%s is not permitted in project %s.\", un.GroupVersionKind().Group, un.GroupVersionKind().Kind, proj.Name)\n\t\t\t}\n\t\t\tif res.Namespaced && !proj.IsDestinationPermitted(v1alpha1.ApplicationDestination{Namespace: un.GetNamespace(), Server: app.Spec.Destination.Server, Name: app.Spec.Destination.Name}) {\n\t\t\t\treturn fmt.Errorf(\"namespace %v is not permitted in project '%s'\", un.GetNamespace(), proj.Name)\n\t\t\t}\n\t\t\treturn nil\n\t\t}),\n\t\tsync.WithOperationSettings(syncOp.DryRun, syncOp.Prune, syncOp.SyncStrategy.Force(), syncOp.IsApplyStrategy() || len(syncOp.Resources) > 0),\n\t\tsync.WithInitialState(state.Phase, state.Message, initialResourcesRes, state.StartedAt),\n\t\tsync.WithResourcesFilter(func(key kube.ResourceKey, target *unstructured.Unstructured, live *unstructured.Unstructured) bool {\n\t\t\treturn len(syncOp.Resources) == 0 || argo.ContainsSyncResource(key.Name, key.Namespace, schema.GroupVersionKind{Kind: key.Kind, Group: key.Group}, syncOp.Resources)\n\t\t}),\n\t\tsync.WithManifestValidation(!syncOp.SyncOptions.HasOption(common.SyncOptionsDisableValidation)),\n\t\tsync.WithNamespaceCreation(syncOp.SyncOptions.HasOption(\"CreateNamespace=true\"), func(un *unstructured.Unstructured) bool {\n\t\t\tif un != nil && kube.GetAppInstanceLabel(un, cdcommon.LabelKeyAppInstance) != \"\" {\n\t\t\t\tkube.UnsetLabel(un, cdcommon.LabelKeyAppInstance)\n\t\t\t\treturn true\n\t\t\t}\n\t\t\treturn false\n\t\t}),\n\t\tsync.WithSyncWaveHook(delayBetweenSyncWaves),\n\t\tsync.WithPruneLast(syncOp.SyncOptions.HasOption(common.SyncOptionPruneLast)),\n\t\tsync.WithResourceModificationChecker(syncOp.SyncOptions.HasOption(\"ApplyOutOfSyncOnly=true\"), compareResult.diffResultList),\n\t\tsync.WithPrunePropagationPolicy(&prunePropagationPolicy),\n\t\tsync.WithReplace(syncOp.SyncOptions.HasOption(common.SyncOptionReplace)),\n\t)\n\n\tif err != nil {\n\t\tstate.Phase = common.OperationError\n\t\tstate.Message = fmt.Sprintf(\"failed to initialize sync context: %v\", err)\n\t\treturn\n\t}\n\n\tdefer cleanup()\n\n\tstart := time.Now()\n\n\tif state.Phase == common.OperationTerminating {\n\t\tsyncCtx.Terminate()\n\t} else {\n\t\tsyncCtx.Sync()\n\t}\n\tvar resState []common.ResourceSyncResult\n\tstate.Phase, state.Message, resState = syncCtx.GetState()\n\tstate.SyncResult.Resources = nil\n\tfor _, res := range resState {\n\t\tstate.SyncResult.Resources = append(state.SyncResult.Resources, &v1alpha1.ResourceResult{\n\t\t\tHookType:  res.HookType,\n\t\t\tGroup:     res.ResourceKey.Group,\n\t\t\tKind:      res.ResourceKey.Kind,\n\t\t\tNamespace: res.ResourceKey.Namespace,\n\t\t\tName:      res.ResourceKey.Name,\n\t\t\tVersion:   res.Version,\n\t\t\tSyncPhase: res.SyncPhase,\n\t\t\tHookPhase: res.HookPhase,\n\t\t\tStatus:    res.Status,\n\t\t\tMessage:   res.Message,\n\t\t})\n\t}\n\n\tlogEntry.WithField(\"duration\", time.Since(start)).Info(\"sync/terminate complete\")\n\n\tif !syncOp.DryRun && len(syncOp.Resources) == 0 && state.Phase.Successful() {\n\t\terr := m.persistRevisionHistory(app, compareResult.syncStatus.Revision, source, state.StartedAt)\n\t\tif err != nil {\n\t\t\tstate.Phase = common.OperationError\n\t\t\tstate.Message = fmt.Sprintf(\"failed to record sync to history: %v\", err)\n\t\t}\n\t}\n}\n\n// normalizeTargetResources will apply the diff normalization in all live and target resources.\n// Then it calculates the merge patch between the normalized live and the current live resources.\n// Finally it applies the merge patch in the normalized target resources. This is done to ensure\n// that target resources have the same ignored diff fields values from live ones to avoid them to\n// be applied in the cluster. Returns the list of normalized target resources.\nfunc normalizeTargetResources(cr *comparisonResult) ([]*unstructured.Unstructured, error) {\n\t// normalize live and target resources\n\tnormalized, err := diff.Normalize(cr.reconciliationResult.Live, cr.reconciliationResult.Target, cr.diffConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpatchedTargets := []*unstructured.Unstructured{}\n\tfor idx, live := range cr.reconciliationResult.Live {\n\t\tnormalizedTarget := normalized.Targets[idx]\n\t\tif normalizedTarget == nil {\n\t\t\tpatchedTargets = append(patchedTargets, nil)\n\t\t\tcontinue\n\t\t}\n\t\toriginalTarget := cr.reconciliationResult.Target[idx]\n\t\tif live == nil {\n\t\t\tpatchedTargets = append(patchedTargets, originalTarget)\n\t\t\tcontinue\n\t\t}\n\t\t// calculate targetPatch between normalized and target resource\n\t\ttargetPatch, err := getMergePatch(normalizedTarget, originalTarget)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// check if there is a patch to apply. An empty patch is identified by a '{}' string.\n\t\tif len(targetPatch) > 2 {\n\t\t\tlivePatch, err := getMergePatch(normalized.Lives[idx], live)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\t// generate a minimal patch that uses the fields from targetPatch (template)\n\t\t\t// with livePatch values\n\t\t\tpatch, err := compilePatch(targetPatch, livePatch)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tnormalizedTarget, err = applyMergePatch(normalizedTarget, patch)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t} else {\n\t\t\t// if there is no patch just use the original target\n\t\t\tnormalizedTarget = originalTarget\n\t\t}\n\t\tpatchedTargets = append(patchedTargets, normalizedTarget)\n\t}\n\treturn patchedTargets, nil\n}\n\n// compilePatch will generate a patch using the fields from templatePatch with\n// the values from valuePatch.\nfunc compilePatch(templatePatch, valuePatch []byte) ([]byte, error) {\n\ttemplateMap := make(map[string]interface{})\n\terr := json.Unmarshal(templatePatch, &templateMap)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvalueMap := make(map[string]interface{})\n\terr = json.Unmarshal(valuePatch, &valueMap)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresultMap := intersectMap(templateMap, valueMap)\n\treturn json.Marshal(resultMap)\n}\n\n// intersectMap will return map with the fields intersection from the 2 provided\n// maps populated with the valueMap values.\nfunc intersectMap(templateMap, valueMap map[string]interface{}) map[string]interface{} {\n\tresult := make(map[string]interface{})\n\tfor k, v := range templateMap {\n\t\tif innerTMap, ok := v.(map[string]interface{}); ok {\n\t\t\tif innerVMap, ok := valueMap[k].(map[string]interface{}); ok {\n\t\t\t\tresult[k] = intersectMap(innerTMap, innerVMap)\n\t\t\t}\n\t\t} else if innerTSlice, ok := v.([]interface{}); ok {\n\t\t\tif innerVSlice, ok := valueMap[k].([]interface{}); ok {\n\t\t\t\titems := []interface{}{}\n\t\t\t\tfor idx, innerTSliceValue := range innerTSlice {\n\t\t\t\t\tif idx < len(innerVSlice) {\n\t\t\t\t\t\tif tSliceValueMap, ok := innerTSliceValue.(map[string]interface{}); ok {\n\t\t\t\t\t\t\tif vSliceValueMap, ok := innerVSlice[idx].(map[string]interface{}); ok {\n\t\t\t\t\t\t\t\titem := intersectMap(tSliceValueMap, vSliceValueMap)\n\t\t\t\t\t\t\t\titems = append(items, item)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\titems = append(items, innerVSlice[idx])\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif len(items) > 0 {\n\t\t\t\t\tresult[k] = items\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif _, ok := valueMap[k]; ok {\n\t\t\t\tresult[k] = valueMap[k]\n\t\t\t}\n\t\t}\n\t}\n\treturn result\n}\n\n// getMergePatch calculates and returns the patch between the original and the\n// modified unstructures.\nfunc getMergePatch(original, modified *unstructured.Unstructured) ([]byte, error) {\n\toriginalJSON, err := original.MarshalJSON()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmodifiedJSON, err := modified.MarshalJSON()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn jsonpatch.CreateMergePatch(originalJSON, modifiedJSON)\n}\n\n// applyMergePatch will apply the given patch in the obj and return the patched\n// unstructure.\nfunc applyMergePatch(obj *unstructured.Unstructured, patch []byte) (*unstructured.Unstructured, error) {\n\toriginalJSON, err := obj.MarshalJSON()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpatchedJSON, err := jsonpatch.MergePatch(originalJSON, patch)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpatchedObj := &unstructured.Unstructured{}\n\t_, _, err = unstructured.UnstructuredJSONScheme.Decode(patchedJSON, nil, patchedObj)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn patchedObj, nil\n}\n\n// hasSharedResourceCondition will check if the Application has any resource that has already\n// been synced by another Application. If the resource is found in another Application it returns\n// true along with a human readable message of which specific resource has this condition.\nfunc hasSharedResourceCondition(app *v1alpha1.Application) (bool, string) {\n\tfor _, condition := range app.Status.Conditions {\n\t\tif condition.Type == v1alpha1.ApplicationConditionSharedResourceWarning {\n\t\t\treturn true, condition.Message\n\t\t}\n\t}\n\treturn false, \"\"\n}\n\n// delayBetweenSyncWaves is a gitops-engine SyncWaveHook which introduces an artificial delay\n// between each sync wave. We introduce an artificial delay in order give other controllers a\n// _chance_ to react to the spec change that we just applied. This is important because without\n// this, Argo CD will likely assess resource health too quickly (against the stale object), causing\n// hooks to fire prematurely. See: https://github.com/argoproj/argo-cd/issues/4669.\n// Note, this is not foolproof, since a proper fix would require the CRD record\n// status.observedGeneration coupled with a health.lua that verifies\n// status.observedGeneration == metadata.generation\nfunc delayBetweenSyncWaves(phase common.SyncPhase, wave int, finalWave bool) error {\n\tif !finalWave {\n\t\tdelaySec := 2\n\t\tif delaySecStr := os.Getenv(EnvVarSyncWaveDelay); delaySecStr != \"\" {\n\t\t\tif val, err := strconv.Atoi(delaySecStr); err == nil {\n\t\t\t\tdelaySec = val\n\t\t\t}\n\t\t}\n\t\tduration := time.Duration(delaySec) * time.Second\n\t\ttime.Sleep(duration)\n\t}\n\treturn nil\n}\n", "package apiclient\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/metadata\"\n\t\"google.golang.org/grpc/status\"\n\n\targocderrors \"github.com/argoproj/argo-cd/v2/util/errors\"\n\targoio \"github.com/argoproj/argo-cd/v2/util/io\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n)\n\nconst (\n\tframeHeaderLength = 5\n\tendOfStreamFlag   = 128\n)\n\ntype noopCodec struct{}\n\nfunc (noopCodec) Marshal(v interface{}) ([]byte, error) {\n\treturn v.([]byte), nil\n}\n\nfunc (noopCodec) Unmarshal(data []byte, v interface{}) error {\n\tpointer := v.(*[]byte)\n\t*pointer = data\n\treturn nil\n}\n\nfunc (noopCodec) Name() string {\n\treturn \"proto\"\n}\n\nfunc toFrame(msg []byte) []byte {\n\tframe := append([]byte{0, 0, 0, 0}, msg...)\n\tbinary.BigEndian.PutUint32(frame, uint32(len(msg)))\n\tframe = append([]byte{0}, frame...)\n\treturn frame\n}\n\nfunc (c *client) executeRequest(fullMethodName string, msg []byte, md metadata.MD) (*http.Response, error) {\n\tschema := \"https\"\n\tif c.PlainText {\n\t\tschema = \"http\"\n\t}\n\trootPath := strings.TrimRight(strings.TrimLeft(c.GRPCWebRootPath, \"/\"), \"/\")\n\n\tvar requestURL string\n\tif rootPath != \"\" {\n\t\trequestURL = fmt.Sprintf(\"%s://%s/%s%s\", schema, c.ServerAddr, rootPath, fullMethodName)\n\t} else {\n\t\trequestURL = fmt.Sprintf(\"%s://%s%s\", schema, c.ServerAddr, fullMethodName)\n\t}\n\treq, err := http.NewRequest(http.MethodPost, requestURL, bytes.NewReader(toFrame(msg)))\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor k, v := range md {\n\t\tif strings.HasPrefix(k, \":\") {\n\t\t\tcontinue\n\t\t}\n\t\tfor i := range v {\n\t\t\treq.Header.Set(k, v[i])\n\t\t}\n\t}\n\treq.Header.Set(\"content-type\", \"application/grpc-web+proto\")\n\n\tresp, err := c.httpClient.Do(req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif resp.StatusCode != http.StatusOK {\n\t\treturn nil, fmt.Errorf(\"%s %s failed with status code %d\", req.Method, req.URL, resp.StatusCode)\n\t}\n\tvar code codes.Code\n\tif statusStr := resp.Header.Get(\"Grpc-Status\"); statusStr != \"\" {\n\t\tstatusInt, err := strconv.ParseUint(statusStr, 10, 32)\n\t\tif err != nil {\n\t\t\tcode = codes.Unknown\n\t\t} else {\n\t\t\tcode = codes.Code(statusInt)\n\t\t}\n\t\tif code != codes.OK {\n\t\t\treturn nil, status.Error(code, resp.Header.Get(\"Grpc-Message\"))\n\t\t}\n\t}\n\treturn resp, nil\n}\n\nfunc (c *client) startGRPCProxy() (*grpc.Server, net.Listener, error) {\n\trandSuffix, err := rand.String(16)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to generate random socket filename: %w\", err)\n\t}\n\tserverAddr := fmt.Sprintf(\"%s/argocd-%s.sock\", os.TempDir(), randSuffix)\n\tln, err := net.Listen(\"unix\", serverAddr)\n\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tproxySrv := grpc.NewServer(\n\t\tgrpc.ForceServerCodec(&noopCodec{}),\n\t\tgrpc.UnknownServiceHandler(func(srv interface{}, stream grpc.ServerStream) error {\n\t\t\tfullMethodName, ok := grpc.MethodFromServerStream(stream)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"Unable to get method name from stream context.\")\n\t\t\t}\n\t\t\tmsg := make([]byte, 0)\n\t\t\terr := stream.RecvMsg(&msg)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tmd, _ := metadata.FromIncomingContext(stream.Context())\n\n\t\t\tfor _, kv := range c.Headers {\n\t\t\t\tif len(strings.Split(kv, \":\"))%2 == 1 {\n\t\t\t\t\treturn fmt.Errorf(\"additional headers key/values must be separated by a colon(:): %s\", kv)\n\t\t\t\t}\n\t\t\t\tmd.Append(strings.Split(kv, \":\")[0], strings.Split(kv, \":\")[1])\n\t\t\t}\n\n\t\t\tresp, err := c.executeRequest(fullMethodName, msg, md)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tgo func() {\n\t\t\t\t<-stream.Context().Done()\n\t\t\t\targoio.Close(resp.Body)\n\t\t\t}()\n\t\t\tdefer argoio.Close(resp.Body)\n\t\t\tc.httpClient.CloseIdleConnections()\n\n\t\t\tfor {\n\t\t\t\theader := make([]byte, frameHeaderLength)\n\t\t\t\tif _, err := io.ReadAtLeast(resp.Body, header, frameHeaderLength); err != nil {\n\t\t\t\t\tif err == io.EOF {\n\t\t\t\t\t\terr = io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\tif header[0] == endOfStreamFlag {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\tlength := int(binary.BigEndian.Uint32(header[1:frameHeaderLength]))\n\t\t\t\tdata := make([]byte, length)\n\n\t\t\t\tif read, err := io.ReadAtLeast(resp.Body, data, length); err != nil {\n\t\t\t\t\tif err != io.EOF {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t} else if read < length {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif err := stream.SendMsg(data); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t}\n\t\t}))\n\tgo func() {\n\t\terr := proxySrv.Serve(ln)\n\t\targocderrors.CheckError(err)\n\t}()\n\treturn proxySrv, ln, nil\n}\n\n// useGRPCProxy ensures that grpc proxy server is started and return closer which stops server when no one uses it\nfunc (c *client) useGRPCProxy() (net.Addr, io.Closer, error) {\n\tc.proxyMutex.Lock()\n\tdefer c.proxyMutex.Unlock()\n\n\tif c.proxyListener == nil {\n\t\tvar err error\n\t\tc.proxyServer, c.proxyListener, err = c.startGRPCProxy()\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t}\n\tc.proxyUsersCount = c.proxyUsersCount + 1\n\n\treturn c.proxyListener.Addr(), argoio.NewCloser(func() error {\n\t\tc.proxyMutex.Lock()\n\t\tdefer c.proxyMutex.Unlock()\n\t\tc.proxyUsersCount = c.proxyUsersCount - 1\n\t\tif c.proxyUsersCount == 0 {\n\t\t\tc.proxyServer.Stop()\n\t\t\tc.proxyListener = nil\n\t\t\tc.proxyServer = nil\n\t\t\treturn nil\n\t\t}\n\t\treturn nil\n\t}), nil\n}\n", "package fixture\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\tgoerrors \"errors\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/argoproj/pkg/errors\"\n\tjsonpatch \"github.com/evanphx/json-patch\"\n\t\"github.com/ghodss/yaml\"\n\tlog \"github.com/sirupsen/logrus\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tv1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/client-go/dynamic\"\n\t\"k8s.io/client-go/kubernetes\"\n\t\"k8s.io/client-go/rest\"\n\t\"k8s.io/client-go/tools/clientcmd\"\n\n\t\"github.com/argoproj/argo-cd/v2/common\"\n\t\"github.com/argoproj/argo-cd/v2/pkg/apiclient\"\n\tsessionpkg \"github.com/argoproj/argo-cd/v2/pkg/apiclient/session\"\n\t\"github.com/argoproj/argo-cd/v2/pkg/apis/application/v1alpha1\"\n\tappclientset \"github.com/argoproj/argo-cd/v2/pkg/client/clientset/versioned\"\n\t. \"github.com/argoproj/argo-cd/v2/util/errors\"\n\tgrpcutil \"github.com/argoproj/argo-cd/v2/util/grpc\"\n\t\"github.com/argoproj/argo-cd/v2/util/io\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n\t\"github.com/argoproj/argo-cd/v2/util/settings\"\n)\n\nconst (\n\tdefaultApiServer        = \"localhost:8080\"\n\tdefaultAdminPassword    = \"password\"\n\tdefaultAdminUsername    = \"admin\"\n\tDefaultTestUserPassword = \"password\"\n\ttestingLabel            = \"e2e.argoproj.io\"\n\tArgoCDNamespace         = \"argocd-e2e\"\n\n\t// ensure all repos are in one directory tree, so we can easily clean them up\n\tTmpDir             = \"/tmp/argo-e2e\"\n\trepoDir            = \"testdata.git\"\n\tsubmoduleDir       = \"submodule.git\"\n\tsubmoduleParentDir = \"submoduleParent.git\"\n\n\tGuestbookPath = \"guestbook\"\n\n\tProjectName = \"argo-project\"\n\n\t// cmp plugin sock file path\n\tPluginSockFilePath = \"/app/config/plugin\"\n)\n\nconst (\n\tEnvAdminUsername = \"ARGOCD_E2E_ADMIN_USERNAME\"\n\tEnvAdminPassword = \"ARGOCD_E2E_ADMIN_PASSWORD\"\n)\n\nvar (\n\tid                  string\n\tdeploymentNamespace string\n\tname                string\n\tKubeClientset       kubernetes.Interface\n\tKubeConfig          *rest.Config\n\tDynamicClientset    dynamic.Interface\n\tAppClientset        appclientset.Interface\n\tArgoCDClientset     apiclient.Client\n\tadminUsername       string\n\tAdminPassword       string\n\tapiServerAddress    string\n\ttoken               string\n\tplainText           bool\n\ttestsRun            map[string]bool\n)\n\ntype RepoURLType string\n\ntype ACL struct {\n\tResource string\n\tAction   string\n\tScope    string\n}\n\nconst (\n\tRepoURLTypeFile                 = \"file\"\n\tRepoURLTypeHTTPS                = \"https\"\n\tRepoURLTypeHTTPSClientCert      = \"https-cc\"\n\tRepoURLTypeHTTPSSubmodule       = \"https-sub\"\n\tRepoURLTypeHTTPSSubmoduleParent = \"https-par\"\n\tRepoURLTypeSSH                  = \"ssh\"\n\tRepoURLTypeSSHSubmodule         = \"ssh-sub\"\n\tRepoURLTypeSSHSubmoduleParent   = \"ssh-par\"\n\tRepoURLTypeHelm                 = \"helm\"\n\tRepoURLTypeHelmParent           = \"helm-par\"\n\tRepoURLTypeHelmOCI              = \"helm-oci\"\n\tGitUsername                     = \"admin\"\n\tGitPassword                     = \"password\"\n\tGpgGoodKeyID                    = \"D56C4FCA57A46444\"\n\tHelmOCIRegistryURL              = \"localhost:5000/myrepo\"\n)\n\n// TestNamespace returns the namespace where Argo CD E2E test instance will be\n// running in.\nfunc TestNamespace() string {\n\treturn GetEnvWithDefault(\"ARGOCD_E2E_NAMESPACE\", ArgoCDNamespace)\n}\n\n// getKubeConfig creates new kubernetes client config using specified config path and config overrides variables\nfunc getKubeConfig(configPath string, overrides clientcmd.ConfigOverrides) *rest.Config {\n\tloadingRules := clientcmd.NewDefaultClientConfigLoadingRules()\n\tloadingRules.ExplicitPath = configPath\n\tclientConfig := clientcmd.NewInteractiveDeferredLoadingClientConfig(loadingRules, &overrides, os.Stdin)\n\n\trestConfig, err := clientConfig.ClientConfig()\n\tCheckError(err)\n\treturn restConfig\n}\n\nfunc GetEnvWithDefault(envName, defaultValue string) string {\n\tr := os.Getenv(envName)\n\tif r == \"\" {\n\t\treturn defaultValue\n\t}\n\treturn r\n}\n\n// IsRemote returns true when the tests are being run against a workload that\n// is running in a remote cluster.\nfunc IsRemote() bool {\n\tr := os.Getenv(\"ARGOCD_E2E_REMOTE\")\n\treturn r == \"true\"\n}\n\n// IsLocal returns when the tests are being run against a local workload\nfunc IsLocal() bool {\n\treturn !IsRemote()\n}\n\n// creates e2e tests fixture: ensures that Application CRD is installed, creates temporal namespace, starts repo and api server,\n// configure currently available cluster.\nfunc init() {\n\t// ensure we log all shell execs\n\tlog.SetLevel(log.DebugLevel)\n\t// set-up variables\n\tconfig := getKubeConfig(\"\", clientcmd.ConfigOverrides{})\n\tAppClientset = appclientset.NewForConfigOrDie(config)\n\tKubeClientset = kubernetes.NewForConfigOrDie(config)\n\tDynamicClientset = dynamic.NewForConfigOrDie(config)\n\tKubeConfig = config\n\n\tapiServerAddress = GetEnvWithDefault(apiclient.EnvArgoCDServer, defaultApiServer)\n\tadminUsername = GetEnvWithDefault(EnvAdminUsername, defaultAdminUsername)\n\tAdminPassword = GetEnvWithDefault(EnvAdminPassword, defaultAdminPassword)\n\n\ttlsTestResult, err := grpcutil.TestTLS(apiServerAddress)\n\tCheckError(err)\n\n\tArgoCDClientset, err = apiclient.NewClient(&apiclient.ClientOptions{Insecure: true, ServerAddr: apiServerAddress, PlainText: !tlsTestResult.TLS})\n\tCheckError(err)\n\n\tplainText = !tlsTestResult.TLS\n\n\tLoginAs(adminUsername)\n\n\tlog.WithFields(log.Fields{\"apiServerAddress\": apiServerAddress}).Info(\"initialized\")\n\n\t// Preload a list of tests that should be skipped\n\ttestsRun = make(map[string]bool)\n\trf := os.Getenv(\"ARGOCD_E2E_RECORD\")\n\tif rf == \"\" {\n\t\treturn\n\t}\n\tf, err := os.Open(rf)\n\tif err != nil {\n\t\tif goerrors.Is(err, os.ErrNotExist) {\n\t\t\treturn\n\t\t} else {\n\t\t\tpanic(fmt.Sprintf(\"Could not read record file %s: %v\", rf, err))\n\t\t}\n\t}\n\tdefer f.Close()\n\tscanner := bufio.NewScanner(f)\n\tfor scanner.Scan() {\n\t\ttestsRun[scanner.Text()] = true\n\t}\n\n}\n\nfunc loginAs(username, password string) {\n\tcloser, client, err := ArgoCDClientset.NewSessionClient()\n\tCheckError(err)\n\tdefer io.Close(closer)\n\n\tsessionResponse, err := client.Create(context.Background(), &sessionpkg.SessionCreateRequest{Username: username, Password: password})\n\tCheckError(err)\n\ttoken = sessionResponse.Token\n\n\tArgoCDClientset, err = apiclient.NewClient(&apiclient.ClientOptions{\n\t\tInsecure:   true,\n\t\tServerAddr: apiServerAddress,\n\t\tAuthToken:  token,\n\t\tPlainText:  plainText,\n\t})\n\tCheckError(err)\n}\n\nfunc LoginAs(username string) {\n\tpassword := DefaultTestUserPassword\n\tif username == \"admin\" {\n\t\tpassword = AdminPassword\n\t}\n\tloginAs(username, password)\n}\n\nfunc Name() string {\n\treturn name\n}\n\nfunc repoDirectory() string {\n\treturn path.Join(TmpDir, repoDir)\n}\n\nfunc submoduleDirectory() string {\n\treturn path.Join(TmpDir, submoduleDir)\n}\n\nfunc submoduleParentDirectory() string {\n\treturn path.Join(TmpDir, submoduleParentDir)\n}\n\nconst (\n\tEnvRepoURLTypeSSH                  = \"ARGOCD_E2E_REPO_SSH\"\n\tEnvRepoURLTypeSSHSubmodule         = \"ARGOCD_E2E_REPO_SSH_SUBMODULE\"\n\tEnvRepoURLTypeSSHSubmoduleParent   = \"ARGOCD_E2E_REPO_SSH_SUBMODULE_PARENT\"\n\tEnvRepoURLTypeHTTPS                = \"ARGOCD_E2E_REPO_HTTPS\"\n\tEnvRepoURLTypeHTTPSClientCert      = \"ARGOCD_E2E_REPO_HTTPS_CLIENT_CERT\"\n\tEnvRepoURLTypeHTTPSSubmodule       = \"ARGOCD_E2E_REPO_HTTPS_SUBMODULE\"\n\tEnvRepoURLTypeHTTPSSubmoduleParent = \"ARGOCD_E2E_REPO_HTTPS_SUBMODULE_PARENT\"\n\tEnvRepoURLTypeHelm                 = \"ARGOCD_E2E_REPO_HELM\"\n\tEnvRepoURLDefault                  = \"ARGOCD_E2E_REPO_DEFAULT\"\n)\n\nfunc RepoURL(urlType RepoURLType) string {\n\tswitch urlType {\n\t// Git server via SSH\n\tcase RepoURLTypeSSH:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeSSH, \"ssh://root@localhost:2222/tmp/argo-e2e/testdata.git\")\n\t// Git submodule repo\n\tcase RepoURLTypeSSHSubmodule:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeSSHSubmodule, \"ssh://root@localhost:2222/tmp/argo-e2e/submodule.git\")\n\t// Git submodule parent repo\n\tcase RepoURLTypeSSHSubmoduleParent:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeSSHSubmoduleParent, \"ssh://root@localhost:2222/tmp/argo-e2e/submoduleParent.git\")\n\t// Git server via HTTPS\n\tcase RepoURLTypeHTTPS:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHTTPS, \"https://localhost:9443/argo-e2e/testdata.git\")\n\t// Git server via HTTPS - Client Cert protected\n\tcase RepoURLTypeHTTPSClientCert:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHTTPSClientCert, \"https://localhost:9444/argo-e2e/testdata.git\")\n\tcase RepoURLTypeHTTPSSubmodule:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHTTPSSubmodule, \"https://localhost:9443/argo-e2e/submodule.git\")\n\t\t// Git submodule parent repo\n\tcase RepoURLTypeHTTPSSubmoduleParent:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHTTPSSubmoduleParent, \"https://localhost:9443/argo-e2e/submoduleParent.git\")\n\t// Default - file based Git repository\n\tcase RepoURLTypeHelm:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHelm, \"https://localhost:9444/argo-e2e/testdata.git/helm-repo/local\")\n\t// When Helm Repo has sub repos, this is the parent repo URL\n\tcase RepoURLTypeHelmParent:\n\t\treturn GetEnvWithDefault(EnvRepoURLTypeHelm, \"https://localhost:9444/argo-e2e/testdata.git/helm-repo\")\n\tcase RepoURLTypeHelmOCI:\n\t\treturn HelmOCIRegistryURL\n\tdefault:\n\t\treturn GetEnvWithDefault(EnvRepoURLDefault, fmt.Sprintf(\"file://%s\", repoDirectory()))\n\t}\n}\n\nfunc RepoBaseURL(urlType RepoURLType) string {\n\treturn path.Base(RepoURL(urlType))\n}\n\nfunc DeploymentNamespace() string {\n\treturn deploymentNamespace\n}\n\n// creates a secret for the current test, this currently can only create a single secret\nfunc CreateSecret(username, password string) string {\n\tsecretName := fmt.Sprintf(\"argocd-e2e-%s\", name)\n\tFailOnErr(Run(\"\", \"kubectl\", \"create\", \"secret\", \"generic\", secretName,\n\t\t\"--from-literal=username=\"+username,\n\t\t\"--from-literal=password=\"+password,\n\t\t\"-n\", TestNamespace()))\n\tFailOnErr(Run(\"\", \"kubectl\", \"label\", \"secret\", secretName, testingLabel+\"=true\", \"-n\", TestNamespace()))\n\treturn secretName\n}\n\n// Convenience wrapper for updating argocd-cm\nfunc updateSettingConfigMap(updater func(cm *corev1.ConfigMap) error) {\n\tupdateGenericConfigMap(common.ArgoCDConfigMapName, updater)\n}\n\n// Convenience wrapper for updating argocd-cm-rbac\nfunc updateRBACConfigMap(updater func(cm *corev1.ConfigMap) error) {\n\tupdateGenericConfigMap(common.ArgoCDRBACConfigMapName, updater)\n}\n\n// Updates a given config map in argocd-e2e namespace\nfunc updateGenericConfigMap(name string, updater func(cm *corev1.ConfigMap) error) {\n\tcm, err := KubeClientset.CoreV1().ConfigMaps(TestNamespace()).Get(context.Background(), name, v1.GetOptions{})\n\terrors.CheckError(err)\n\tif cm.Data == nil {\n\t\tcm.Data = make(map[string]string)\n\t}\n\terrors.CheckError(updater(cm))\n\t_, err = KubeClientset.CoreV1().ConfigMaps(TestNamespace()).Update(context.Background(), cm, v1.UpdateOptions{})\n\terrors.CheckError(err)\n}\n\nfunc SetEnableManifestGeneration(val map[v1alpha1.ApplicationSourceType]bool) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tfor k, v := range val {\n\t\t\tcm.Data[fmt.Sprintf(\"%s.enable\", strings.ToLower(string(k)))] = strconv.FormatBool(v)\n\t\t}\n\t\treturn nil\n\t})\n}\n\nfunc SetResourceOverrides(overrides map[string]v1alpha1.ResourceOverride) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tif len(overrides) > 0 {\n\t\t\tyamlBytes, err := yaml.Marshal(overrides)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcm.Data[\"resource.customizations\"] = string(yamlBytes)\n\t\t} else {\n\t\t\tdelete(cm.Data, \"resource.customizations\")\n\t\t}\n\t\treturn nil\n\t})\n\n\tSetResourceOverridesSplitKeys(overrides)\n}\n\nfunc SetTrackingMethod(trackingMethod string) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tcm.Data[\"application.resourceTrackingMethod\"] = trackingMethod\n\t\treturn nil\n\t})\n}\n\nfunc SetResourceOverridesSplitKeys(overrides map[string]v1alpha1.ResourceOverride) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tfor k, v := range overrides {\n\t\t\tif v.HealthLua != \"\" {\n\t\t\t\tcm.Data[getResourceOverrideSplitKey(k, \"health\")] = v.HealthLua\n\t\t\t}\n\t\t\tcm.Data[getResourceOverrideSplitKey(k, \"useOpenLibs\")] = strconv.FormatBool(v.UseOpenLibs)\n\t\t\tif v.Actions != \"\" {\n\t\t\t\tcm.Data[getResourceOverrideSplitKey(k, \"actions\")] = v.Actions\n\t\t\t}\n\t\t\tif len(v.IgnoreDifferences.JSONPointers) > 0 ||\n\t\t\t\tlen(v.IgnoreDifferences.JQPathExpressions) > 0 ||\n\t\t\t\tlen(v.IgnoreDifferences.ManagedFieldsManagers) > 0 {\n\t\t\t\tyamlBytes, err := yaml.Marshal(v.IgnoreDifferences)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tcm.Data[getResourceOverrideSplitKey(k, \"ignoreDifferences\")] = string(yamlBytes)\n\t\t\t}\n\t\t\tif len(v.KnownTypeFields) > 0 {\n\t\t\t\tyamlBytes, err := yaml.Marshal(v.KnownTypeFields)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tcm.Data[getResourceOverrideSplitKey(k, \"knownTypeFields\")] = string(yamlBytes)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n}\n\nfunc getResourceOverrideSplitKey(key string, customizeType string) string {\n\tgroupKind := key\n\tparts := strings.Split(key, \"/\")\n\tif len(parts) == 2 {\n\t\tgroupKind = fmt.Sprintf(\"%s_%s\", parts[0], parts[1])\n\t}\n\treturn fmt.Sprintf(\"resource.customizations.%s.%s\", customizeType, groupKind)\n}\n\nfunc SetAccounts(accounts map[string][]string) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tfor k, v := range accounts {\n\t\t\tcm.Data[fmt.Sprintf(\"accounts.%s\", k)] = strings.Join(v, \",\")\n\t\t}\n\t\treturn nil\n\t})\n}\n\nfunc SetPermissions(permissions []ACL, username string, roleName string) {\n\tupdateRBACConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tvar aclstr string\n\n\t\tfor _, permission := range permissions {\n\t\t\taclstr += fmt.Sprintf(\"p, role:%s, %s, %s, %s, allow \\n\", roleName, permission.Resource, permission.Action, permission.Scope)\n\t\t}\n\n\t\taclstr += fmt.Sprintf(\"g, %s, role:%s\", username, roleName)\n\t\tcm.Data[\"policy.csv\"] = aclstr\n\n\t\treturn nil\n\t})\n}\n\nfunc SetConfigManagementPlugins(plugin ...v1alpha1.ConfigManagementPlugin) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tyamlBytes, err := yaml.Marshal(plugin)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcm.Data[\"configManagementPlugins\"] = string(yamlBytes)\n\t\treturn nil\n\t})\n}\n\nfunc SetResourceFilter(filters settings.ResourcesFilter) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\texclusions, err := yaml.Marshal(filters.ResourceExclusions)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tinclusions, err := yaml.Marshal(filters.ResourceInclusions)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcm.Data[\"resource.exclusions\"] = string(exclusions)\n\t\tcm.Data[\"resource.inclusions\"] = string(inclusions)\n\t\treturn nil\n\t})\n}\n\nfunc SetHelmRepos(repos ...settings.HelmRepoCredentials) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tyamlBytes, err := yaml.Marshal(repos)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcm.Data[\"helm.repositories\"] = string(yamlBytes)\n\t\treturn nil\n\t})\n}\n\nfunc SetRepos(repos ...settings.RepositoryCredentials) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tyamlBytes, err := yaml.Marshal(repos)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcm.Data[\"repositories\"] = string(yamlBytes)\n\t\treturn nil\n\t})\n}\n\nfunc SetProjectSpec(project string, spec v1alpha1.AppProjectSpec) {\n\tproj, err := AppClientset.ArgoprojV1alpha1().AppProjects(TestNamespace()).Get(context.Background(), project, v1.GetOptions{})\n\terrors.CheckError(err)\n\tproj.Spec = spec\n\t_, err = AppClientset.ArgoprojV1alpha1().AppProjects(TestNamespace()).Update(context.Background(), proj, v1.UpdateOptions{})\n\terrors.CheckError(err)\n}\n\nfunc SetParamInSettingConfigMap(key, value string) {\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tcm.Data[key] = value\n\t\treturn nil\n\t})\n}\n\nfunc EnsureCleanState(t *testing.T) {\n\t// In large scenarios, we can skip tests that already run\n\tSkipIfAlreadyRun(t)\n\t// Register this test after it has been run & was successfull\n\tt.Cleanup(func() {\n\t\tRecordTestRun(t)\n\t})\n\n\tstart := time.Now()\n\n\tpolicy := v1.DeletePropagationBackground\n\t// delete resources\n\t// kubectl delete apps --all\n\tCheckError(AppClientset.ArgoprojV1alpha1().Applications(TestNamespace()).DeleteCollection(context.Background(), v1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{}))\n\t// kubectl delete appprojects --field-selector metadata.name!=default\n\tCheckError(AppClientset.ArgoprojV1alpha1().AppProjects(TestNamespace()).DeleteCollection(context.Background(),\n\t\tv1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{FieldSelector: \"metadata.name!=default\"}))\n\t// kubectl delete secrets -l argocd.argoproj.io/secret-type=repo-config\n\tCheckError(KubeClientset.CoreV1().Secrets(TestNamespace()).DeleteCollection(context.Background(),\n\t\tv1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{LabelSelector: common.LabelKeySecretType + \"=\" + common.LabelValueSecretTypeRepository}))\n\t// kubectl delete secrets -l argocd.argoproj.io/secret-type=repo-creds\n\tCheckError(KubeClientset.CoreV1().Secrets(TestNamespace()).DeleteCollection(context.Background(),\n\t\tv1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{LabelSelector: common.LabelKeySecretType + \"=\" + common.LabelValueSecretTypeRepoCreds}))\n\t// kubectl delete secrets -l argocd.argoproj.io/secret-type=cluster\n\tCheckError(KubeClientset.CoreV1().Secrets(TestNamespace()).DeleteCollection(context.Background(),\n\t\tv1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{LabelSelector: common.LabelKeySecretType + \"=\" + common.LabelValueSecretTypeCluster}))\n\t// kubectl delete secrets -l e2e.argoproj.io=true\n\tCheckError(KubeClientset.CoreV1().Secrets(TestNamespace()).DeleteCollection(context.Background(),\n\t\tv1.DeleteOptions{PropagationPolicy: &policy}, v1.ListOptions{LabelSelector: testingLabel + \"=true\"}))\n\n\tFailOnErr(Run(\"\", \"kubectl\", \"delete\", \"ns\", \"-l\", testingLabel+\"=true\", \"--field-selector\", \"status.phase=Active\", \"--wait=false\"))\n\tFailOnErr(Run(\"\", \"kubectl\", \"delete\", \"crd\", \"-l\", testingLabel+\"=true\", \"--wait=false\"))\n\n\t// reset settings\n\tupdateSettingConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tcm.Data = map[string]string{}\n\t\treturn nil\n\t})\n\n\t// reset rbac\n\tupdateRBACConfigMap(func(cm *corev1.ConfigMap) error {\n\t\tcm.Data = map[string]string{}\n\t\treturn nil\n\t})\n\n\t// We can switch user and as result in previous state we will have non-admin user, this case should be reset\n\tLoginAs(adminUsername)\n\n\t// reset gpg-keys config map\n\tupdateGenericConfigMap(common.ArgoCDGPGKeysConfigMapName, func(cm *corev1.ConfigMap) error {\n\t\tcm.Data = map[string]string{}\n\t\treturn nil\n\t})\n\n\tSetProjectSpec(\"default\", v1alpha1.AppProjectSpec{\n\t\tOrphanedResources:        nil,\n\t\tSourceRepos:              []string{\"*\"},\n\t\tDestinations:             []v1alpha1.ApplicationDestination{{Namespace: \"*\", Server: \"*\"}},\n\t\tClusterResourceWhitelist: []v1.GroupKind{{Group: \"*\", Kind: \"*\"}},\n\t})\n\n\t// Create separate project for testing gpg signature verification\n\tFailOnErr(RunCli(\"proj\", \"create\", \"gpg\"))\n\tSetProjectSpec(\"gpg\", v1alpha1.AppProjectSpec{\n\t\tOrphanedResources:        nil,\n\t\tSourceRepos:              []string{\"*\"},\n\t\tDestinations:             []v1alpha1.ApplicationDestination{{Namespace: \"*\", Server: \"*\"}},\n\t\tClusterResourceWhitelist: []v1.GroupKind{{Group: \"*\", Kind: \"*\"}},\n\t\tSignatureKeys:            []v1alpha1.SignatureKey{{KeyID: GpgGoodKeyID}},\n\t})\n\n\t// Recreate temp dir\n\tCheckError(os.RemoveAll(TmpDir))\n\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir))\n\n\t// random id - unique across test runs\n\trandString, err := rand.String(5)\n\tCheckError(err)\n\tpostFix := \"-\" + strings.ToLower(randString)\n\tid = t.Name() + postFix\n\tname = DnsFriendly(t.Name(), \"\")\n\tdeploymentNamespace = DnsFriendly(fmt.Sprintf(\"argocd-e2e-%s\", t.Name()), postFix)\n\n\t// create TLS and SSH certificate directories\n\tif IsLocal() {\n\t\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+\"/app/config/tls\"))\n\t\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+\"/app/config/ssh\"))\n\t}\n\n\t// For signing during the tests\n\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+\"/gpg\"))\n\tFailOnErr(Run(\"\", \"chmod\", \"0700\", TmpDir+\"/gpg\"))\n\tprevGnuPGHome := os.Getenv(\"GNUPGHOME\")\n\tos.Setenv(\"GNUPGHOME\", TmpDir+\"/gpg\")\n\t// nolint:errcheck\n\tRun(\"\", \"pkill\", \"-9\", \"gpg-agent\")\n\tFailOnErr(Run(\"\", \"gpg\", \"--import\", \"../fixture/gpg/signingkey.asc\"))\n\tos.Setenv(\"GNUPGHOME\", prevGnuPGHome)\n\n\t// recreate GPG directories\n\tif IsLocal() {\n\t\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+\"/app/config/gpg/source\"))\n\t\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+\"/app/config/gpg/keys\"))\n\t\tFailOnErr(Run(\"\", \"chmod\", \"0700\", TmpDir+\"/app/config/gpg/keys\"))\n\t\tFailOnErr(Run(\"\", \"mkdir\", \"-p\", TmpDir+PluginSockFilePath))\n\t\tFailOnErr(Run(\"\", \"chmod\", \"0700\", TmpDir+PluginSockFilePath))\n\t}\n\n\t// set-up tmp repo, must have unique name\n\tFailOnErr(Run(\"\", \"cp\", \"-Rf\", \"testdata\", repoDirectory()))\n\tFailOnErr(Run(repoDirectory(), \"chmod\", \"777\", \".\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"init\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"add\", \".\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"commit\", \"-q\", \"-m\", \"initial commit\"))\n\n\tif IsRemote() {\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"remote\", \"add\", \"origin\", os.Getenv(\"ARGOCD_E2E_GIT_SERVICE\")))\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"push\", \"origin\", \"master\", \"-f\"))\n\t}\n\n\t// create namespace\n\tFailOnErr(Run(\"\", \"kubectl\", \"create\", \"ns\", DeploymentNamespace()))\n\tFailOnErr(Run(\"\", \"kubectl\", \"label\", \"ns\", DeploymentNamespace(), testingLabel+\"=true\"))\n\n\tlog.WithFields(log.Fields{\"duration\": time.Since(start), \"name\": t.Name(), \"id\": id, \"username\": \"admin\", \"password\": \"password\"}).Info(\"clean state\")\n}\n\nfunc RunCli(args ...string) (string, error) {\n\treturn RunCliWithStdin(\"\", args...)\n}\n\nfunc RunCliWithStdin(stdin string, args ...string) (string, error) {\n\tif plainText {\n\t\targs = append(args, \"--plaintext\")\n\t}\n\n\targs = append(args, \"--server\", apiServerAddress, \"--auth-token\", token, \"--insecure\")\n\n\treturn RunWithStdin(stdin, \"\", \"../../dist/argocd\", args...)\n}\n\nfunc Patch(path string, jsonPatch string) {\n\n\tlog.WithFields(log.Fields{\"path\": path, \"jsonPatch\": jsonPatch}).Info(\"patching\")\n\n\tfilename := filepath.Join(repoDirectory(), path)\n\tbytes, err := ioutil.ReadFile(filename)\n\tCheckError(err)\n\n\tpatch, err := jsonpatch.DecodePatch([]byte(jsonPatch))\n\tCheckError(err)\n\n\tisYaml := strings.HasSuffix(filename, \".yaml\")\n\tif isYaml {\n\t\tlog.Info(\"converting YAML to JSON\")\n\t\tbytes, err = yaml.YAMLToJSON(bytes)\n\t\tCheckError(err)\n\t}\n\n\tlog.WithFields(log.Fields{\"bytes\": string(bytes)}).Info(\"JSON\")\n\n\tbytes, err = patch.Apply(bytes)\n\tCheckError(err)\n\n\tif isYaml {\n\t\tlog.Info(\"converting JSON back to YAML\")\n\t\tbytes, err = yaml.JSONToYAML(bytes)\n\t\tCheckError(err)\n\t}\n\n\tCheckError(ioutil.WriteFile(filename, bytes, 0644))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"diff\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"commit\", \"-am\", \"patch\"))\n\tif IsRemote() {\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"push\", \"-f\", \"origin\", \"master\"))\n\t}\n}\n\nfunc Delete(path string) {\n\n\tlog.WithFields(log.Fields{\"path\": path}).Info(\"deleting\")\n\n\tCheckError(os.Remove(filepath.Join(repoDirectory(), path)))\n\n\tFailOnErr(Run(repoDirectory(), \"git\", \"diff\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"commit\", \"-am\", \"delete\"))\n\tif IsRemote() {\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"push\", \"-f\", \"origin\", \"master\"))\n\t}\n}\n\nfunc WriteFile(path, contents string) {\n\tlog.WithFields(log.Fields{\"path\": path}).Info(\"adding\")\n\n\tCheckError(ioutil.WriteFile(filepath.Join(repoDirectory(), path), []byte(contents), 0644))\n}\n\nfunc AddFile(path, contents string) {\n\n\tWriteFile(path, contents)\n\n\tFailOnErr(Run(repoDirectory(), \"git\", \"diff\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"add\", \".\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"commit\", \"-am\", \"add file\"))\n\n\tif IsRemote() {\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"push\", \"-f\", \"origin\", \"master\"))\n\t}\n}\n\nfunc AddSignedFile(path, contents string) {\n\tWriteFile(path, contents)\n\n\tprevGnuPGHome := os.Getenv(\"GNUPGHOME\")\n\tos.Setenv(\"GNUPGHOME\", TmpDir+\"/gpg\")\n\tFailOnErr(Run(repoDirectory(), \"git\", \"diff\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"add\", \".\"))\n\tFailOnErr(Run(repoDirectory(), \"git\", \"-c\", fmt.Sprintf(\"user.signingkey=%s\", GpgGoodKeyID), \"commit\", \"-S\", \"-am\", \"add file\"))\n\tos.Setenv(\"GNUPGHOME\", prevGnuPGHome)\n\tif IsRemote() {\n\t\tFailOnErr(Run(repoDirectory(), \"git\", \"push\", \"-f\", \"origin\", \"master\"))\n\t}\n}\n\n// create the resource by creating using \"kubectl apply\", with bonus templating\nfunc Declarative(filename string, values interface{}) (string, error) {\n\n\tbytes, err := ioutil.ReadFile(path.Join(\"testdata\", filename))\n\tCheckError(err)\n\n\ttmpFile, err := ioutil.TempFile(\"\", \"\")\n\tCheckError(err)\n\t_, err = tmpFile.WriteString(Tmpl(string(bytes), values))\n\tCheckError(err)\n\tdefer tmpFile.Close()\n\treturn Run(\"\", \"kubectl\", \"-n\", TestNamespace(), \"apply\", \"-f\", tmpFile.Name())\n}\n\nfunc CreateSubmoduleRepos(repoType string) {\n\n\t// set-up submodule repo\n\tFailOnErr(Run(\"\", \"cp\", \"-Rf\", \"testdata/git-submodule/\", submoduleDirectory()))\n\tFailOnErr(Run(submoduleDirectory(), \"chmod\", \"777\", \".\"))\n\tFailOnErr(Run(submoduleDirectory(), \"git\", \"init\"))\n\tFailOnErr(Run(submoduleDirectory(), \"git\", \"add\", \".\"))\n\tFailOnErr(Run(submoduleDirectory(), \"git\", \"commit\", \"-q\", \"-m\", \"initial commit\"))\n\n\tif IsRemote() {\n\t\tFailOnErr(Run(submoduleDirectory(), \"git\", \"remote\", \"add\", \"origin\", os.Getenv(\"ARGOCD_E2E_GIT_SERVICE_SUBMODULE\")))\n\t\tFailOnErr(Run(submoduleDirectory(), \"git\", \"push\", \"origin\", \"master\", \"-f\"))\n\t}\n\n\t// set-up submodule parent repo\n\tFailOnErr(Run(\"\", \"mkdir\", submoduleParentDirectory()))\n\tFailOnErr(Run(submoduleParentDirectory(), \"chmod\", \"777\", \".\"))\n\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"init\"))\n\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"add\", \".\"))\n\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"submodule\", \"add\", \"-b\", \"master\", \"../submodule.git\", \"submodule/test\"))\n\tif repoType == \"ssh\" {\n\t\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"config\", \"--file=.gitmodules\", \"submodule.submodule/test.url\", RepoURL(RepoURLTypeSSHSubmodule)))\n\t} else if repoType == \"https\" {\n\t\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"config\", \"--file=.gitmodules\", \"submodule.submodule/test.url\", RepoURL(RepoURLTypeHTTPSSubmodule)))\n\t}\n\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"add\", \"--all\"))\n\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"commit\", \"-q\", \"-m\", \"commit with submodule\"))\n\n\tif IsRemote() {\n\t\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"remote\", \"add\", \"origin\", os.Getenv(\"ARGOCD_E2E_GIT_SERVICE_SUBMODULE_PARENT\")))\n\t\tFailOnErr(Run(submoduleParentDirectory(), \"git\", \"push\", \"origin\", \"master\", \"-f\"))\n\t}\n}\n\n// RestartRepoServer performs a restart of the repo server deployment and waits\n// until the rollout has completed.\nfunc RestartRepoServer() {\n\tif IsRemote() {\n\t\tlog.Infof(\"Waiting for repo server to restart\")\n\t\tprefix := os.Getenv(\"ARGOCD_E2E_NAME_PREFIX\")\n\t\tworkload := \"argocd-repo-server\"\n\t\tif prefix != \"\" {\n\t\t\tworkload = prefix + \"-repo-server\"\n\t\t}\n\t\tFailOnErr(Run(\"\", \"kubectl\", \"rollout\", \"restart\", \"deployment\", workload))\n\t\tFailOnErr(Run(\"\", \"kubectl\", \"rollout\", \"status\", \"deployment\", workload))\n\t}\n}\n\n// RestartAPIServer performs a restart of the API server deployemt and waits\n// until the rollout has completed.\nfunc RestartAPIServer() {\n\tif IsRemote() {\n\t\tlog.Infof(\"Waiting for API server to restart\")\n\t\tprefix := os.Getenv(\"ARGOCD_E2E_NAME_PREFIX\")\n\t\tworkload := \"argocd-server\"\n\t\tif prefix != \"\" {\n\t\t\tworkload = prefix + \"-server\"\n\t\t}\n\t\tFailOnErr(Run(\"\", \"kubectl\", \"rollout\", \"restart\", \"deployment\", workload))\n\t\tFailOnErr(Run(\"\", \"kubectl\", \"rollout\", \"status\", \"deployment\", workload))\n\t}\n}\n\n// LocalOrRemotePath selects a path for a given application based on whether\n// tests are running local or remote.\nfunc LocalOrRemotePath(base string) string {\n\tif IsRemote() {\n\t\treturn base + \"/remote\"\n\t} else {\n\t\treturn base + \"/local\"\n\t}\n}\n\n// SkipOnEnv allows to skip a test when a given environment variable is set.\n// Environment variable names follow the ARGOCD_E2E_SKIP_<suffix> pattern,\n// and must be set to the string value 'true' in order to skip a test.\nfunc SkipOnEnv(t *testing.T, suffixes ...string) {\n\tfor _, suffix := range suffixes {\n\t\te := os.Getenv(\"ARGOCD_E2E_SKIP_\" + suffix)\n\t\tif e == \"true\" {\n\t\t\tt.Skip()\n\t\t}\n\t}\n}\n\n// SkipIfAlreadyRun skips a test if it has been already run by a previous\n// test cycle and was recorded.\nfunc SkipIfAlreadyRun(t *testing.T) {\n\tif _, ok := testsRun[t.Name()]; ok {\n\t\tt.Skip()\n\t}\n}\n\n// RecordTestRun records a test that has been run successfully to a text file,\n// so that it can be automatically skipped if requested.\nfunc RecordTestRun(t *testing.T) {\n\tif t.Skipped() || t.Failed() {\n\t\treturn\n\t}\n\trf := os.Getenv(\"ARGOCD_E2E_RECORD\")\n\tif rf == \"\" {\n\t\treturn\n\t}\n\tlog.Infof(\"Registering test execution at %s\", rf)\n\tf, err := os.OpenFile(rf, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)\n\tif err != nil {\n\t\tt.Fatalf(\"could not open record file %s: %v\", rf, err)\n\t}\n\tdefer f.Close()\n\tif _, err := f.WriteString(fmt.Sprintf(\"%s\\n\", t.Name())); err != nil {\n\t\tt.Fatalf(\"could not write to %s: %v\", rf, err)\n\t}\n}\n", "package e2e\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/argoproj/gitops-engine/pkg/health\"\n\t. \"github.com/argoproj/gitops-engine/pkg/sync/common\"\n\t\"github.com/stretchr/testify/require\"\n\n\t. \"github.com/argoproj/argo-cd/v2/pkg/apis/application/v1alpha1\"\n\t\"github.com/argoproj/argo-cd/v2/test/e2e/fixture\"\n\t. \"github.com/argoproj/argo-cd/v2/test/e2e/fixture\"\n\t. \"github.com/argoproj/argo-cd/v2/test/e2e/fixture/app\"\n\t. \"github.com/argoproj/argo-cd/v2/util/errors\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n)\n\n// when you selectively sync, only selected resources should be synced, but the app will be out of sync\nfunc TestSelectiveSync(t *testing.T) {\n\tGiven(t).\n\t\tPath(\"guestbook\").\n\t\tSelectedResource(\":Service:guestbook-ui\").\n\t\tWhen().\n\t\tCreateApp().\n\t\tSync().\n\t\tThen().\n\t\tExpect(Success(\"\")).\n\t\tExpect(OperationPhaseIs(OperationSucceeded)).\n\t\tExpect(SyncStatusIs(SyncStatusCodeOutOfSync)).\n\t\tExpect(ResourceHealthIs(\"Service\", \"guestbook-ui\", health.HealthStatusHealthy)).\n\t\tExpect(ResourceHealthIs(\"Deployment\", \"guestbook-ui\", health.HealthStatusMissing))\n}\n\n// when running selective sync, hooks do not run\n// hooks don't run even if all resources are selected\nfunc TestSelectiveSyncDoesNotRunHooks(t *testing.T) {\n\tGiven(t).\n\t\tPath(\"hook\").\n\t\tSelectedResource(\":Pod:pod\").\n\t\tWhen().\n\t\tCreateApp().\n\t\tSync().\n\t\tThen().\n\t\tExpect(Success(\"\")).\n\t\tExpect(OperationPhaseIs(OperationSucceeded)).\n\t\tExpect(SyncStatusIs(SyncStatusCodeSynced)).\n\t\tExpect(HealthIs(health.HealthStatusHealthy)).\n\t\tExpect(ResourceHealthIs(\"Pod\", \"pod\", health.HealthStatusHealthy)).\n\t\tExpect(ResourceResultNumbering(1))\n}\n\nfunc TestSelectiveSyncWithoutNamespace(t *testing.T) {\n\tselectedResourceNamespace := getNewNamespace(t)\n\tdefer func() {\n\t\tif !t.Skipped() {\n\t\t\tFailOnErr(Run(\"\", \"kubectl\", \"delete\", \"namespace\", selectedResourceNamespace))\n\t\t}\n\t}()\n\tGiven(t).\n\t\tPrune(true).\n\t\tPath(\"guestbook-with-namespace\").\n\t\tAnd(func() {\n\t\t\tFailOnErr(Run(\"\", \"kubectl\", \"create\", \"namespace\", selectedResourceNamespace))\n\t\t}).\n\t\tSelectedResource(\"apps:Deployment:guestbook-ui\").\n\t\tWhen().\n\t\tPatchFile(\"guestbook-ui-deployment-ns.yaml\", fmt.Sprintf(`[{\"op\": \"replace\", \"path\": \"/metadata/namespace\", \"value\": \"%s\"}]`, selectedResourceNamespace)).\n\t\tPatchFile(\"guestbook-ui-svc-ns.yaml\", fmt.Sprintf(`[{\"op\": \"replace\", \"path\": \"/metadata/namespace\", \"value\": \"%s\"}]`, selectedResourceNamespace)).\n\t\tCreateApp().\n\t\tSync().\n\t\tThen().\n\t\tExpect(Success(\"\")).\n\t\tExpect(OperationPhaseIs(OperationSucceeded)).\n\t\tExpect(SyncStatusIs(SyncStatusCodeOutOfSync)).\n\t\tExpect(ResourceHealthWithNamespaceIs(\"Deployment\", \"guestbook-ui\", selectedResourceNamespace, health.HealthStatusHealthy)).\n\t\tExpect(ResourceHealthWithNamespaceIs(\"Deployment\", \"guestbook-ui\", fixture.DeploymentNamespace(), health.HealthStatusHealthy)).\n\t\tExpect(ResourceSyncStatusWithNamespaceIs(\"Deployment\", \"guestbook-ui\", selectedResourceNamespace, SyncStatusCodeSynced)).\n\t\tExpect(ResourceSyncStatusWithNamespaceIs(\"Deployment\", \"guestbook-ui\", fixture.DeploymentNamespace(), SyncStatusCodeSynced))\n}\n\n//In selectedResource to sync, namespace is provided\nfunc TestSelectiveSyncWithNamespace(t *testing.T) {\n\tselectedResourceNamespace := getNewNamespace(t)\n\tdefer func() {\n\t\tif !t.Skipped() {\n\t\t\tFailOnErr(Run(\"\", \"kubectl\", \"delete\", \"namespace\", selectedResourceNamespace))\n\t\t}\n\t}()\n\tGiven(t).\n\t\tPrune(true).\n\t\tPath(\"guestbook-with-namespace\").\n\t\tAnd(func() {\n\t\t\tFailOnErr(Run(\"\", \"kubectl\", \"create\", \"namespace\", selectedResourceNamespace))\n\t\t}).\n\t\tSelectedResource(fmt.Sprintf(\"apps:Deployment:%s/guestbook-ui\", selectedResourceNamespace)).\n\t\tWhen().\n\t\tPatchFile(\"guestbook-ui-deployment-ns.yaml\", fmt.Sprintf(`[{\"op\": \"replace\", \"path\": \"/metadata/namespace\", \"value\": \"%s\"}]`, selectedResourceNamespace)).\n\t\tPatchFile(\"guestbook-ui-svc-ns.yaml\", fmt.Sprintf(`[{\"op\": \"replace\", \"path\": \"/metadata/namespace\", \"value\": \"%s\"}]`, selectedResourceNamespace)).\n\t\tCreateApp().\n\t\tSync().\n\t\tThen().\n\t\tExpect(Success(\"\")).\n\t\tExpect(OperationPhaseIs(OperationSucceeded)).\n\t\tExpect(SyncStatusIs(SyncStatusCodeOutOfSync)).\n\t\tExpect(ResourceHealthWithNamespaceIs(\"Deployment\", \"guestbook-ui\", selectedResourceNamespace, health.HealthStatusHealthy)).\n\t\tExpect(ResourceHealthWithNamespaceIs(\"Deployment\", \"guestbook-ui\", fixture.DeploymentNamespace(), health.HealthStatusMissing)).\n\t\tExpect(ResourceSyncStatusWithNamespaceIs(\"Deployment\", \"guestbook-ui\", selectedResourceNamespace, SyncStatusCodeSynced)).\n\t\tExpect(ResourceSyncStatusWithNamespaceIs(\"Deployment\", \"guestbook-ui\", fixture.DeploymentNamespace(), SyncStatusCodeOutOfSync))\n}\n\nfunc getNewNamespace(t *testing.T) string {\n\trandStr, err := rand.String(5)\n\trequire.NoError(t, err)\n\tpostFix := \"-\" + strings.ToLower(randStr)\n\tname := fixture.DnsFriendly(t.Name(), \"\")\n\treturn fixture.DnsFriendly(fmt.Sprintf(\"argocd-e2e-%s\", name), postFix)\n}\n", "package oidc\n\nimport (\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"html\"\n\t\"html/template\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"path\"\n\t\"strings\"\n\t\"time\"\n\n\tgooidc \"github.com/coreos/go-oidc\"\n\t\"github.com/golang-jwt/jwt/v4\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"golang.org/x/oauth2\"\n\n\t\"github.com/argoproj/argo-cd/v2/common\"\n\t\"github.com/argoproj/argo-cd/v2/server/settings/oidc\"\n\t\"github.com/argoproj/argo-cd/v2/util/crypto\"\n\t\"github.com/argoproj/argo-cd/v2/util/dex\"\n\thttputil \"github.com/argoproj/argo-cd/v2/util/http\"\n\t\"github.com/argoproj/argo-cd/v2/util/rand\"\n\t\"github.com/argoproj/argo-cd/v2/util/settings\"\n)\n\nconst (\n\tGrantTypeAuthorizationCode = \"authorization_code\"\n\tGrantTypeImplicit          = \"implicit\"\n\tResponseTypeCode           = \"code\"\n)\n\n// OIDCConfiguration holds a subset of interested fields from the OIDC configuration spec\ntype OIDCConfiguration struct {\n\tIssuer                 string   `json:\"issuer\"`\n\tScopesSupported        []string `json:\"scopes_supported\"`\n\tResponseTypesSupported []string `json:\"response_types_supported\"`\n\tGrantTypesSupported    []string `json:\"grant_types_supported,omitempty\"`\n}\n\ntype ClaimsRequest struct {\n\tIDToken map[string]*oidc.Claim `json:\"id_token\"`\n}\n\ntype ClientApp struct {\n\t// OAuth2 client ID of this application (e.g. argo-cd)\n\tclientID string\n\t// OAuth2 client secret of this application\n\tclientSecret string\n\t// Callback URL for OAuth2 responses (e.g. https://argocd.example.com/auth/callback)\n\tredirectURI string\n\t// URL of the issuer (e.g. https://argocd.example.com/api/dex)\n\tissuerURL string\n\t// The URL endpoint at which the ArgoCD server is accessed.\n\tbaseHRef string\n\t// client is the HTTP client which is used to query the IDp\n\tclient *http.Client\n\t// secureCookie indicates if the cookie should be set with the Secure flag, meaning it should\n\t// only ever be sent over HTTPS. This value is inferred by the scheme of the redirectURI.\n\tsecureCookie bool\n\t// settings holds Argo CD settings\n\tsettings *settings.ArgoCDSettings\n\t// encryptionKey holds server encryption key\n\tencryptionKey []byte\n\t// provider is the OIDC provider\n\tprovider Provider\n}\n\nfunc GetScopesOrDefault(scopes []string) []string {\n\tif len(scopes) == 0 {\n\t\treturn []string{\"openid\", \"profile\", \"email\", \"groups\"}\n\t}\n\treturn scopes\n}\n\n// NewClientApp will register the Argo CD client app (either via Dex or external OIDC) and return an\n// object which has HTTP handlers for handling the HTTP responses for login and callback\nfunc NewClientApp(settings *settings.ArgoCDSettings, dexServerAddr, baseHRef string) (*ClientApp, error) {\n\tredirectURL, err := settings.RedirectURL()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tencryptionKey, err := settings.GetServerEncryptionKey()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ta := ClientApp{\n\t\tclientID:      settings.OAuth2ClientID(),\n\t\tclientSecret:  settings.OAuth2ClientSecret(),\n\t\tredirectURI:   redirectURL,\n\t\tissuerURL:     settings.IssuerURL(),\n\t\tbaseHRef:      baseHRef,\n\t\tencryptionKey: encryptionKey,\n\t}\n\tlog.Infof(\"Creating client app (%s)\", a.clientID)\n\tu, err := url.Parse(settings.URL)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parse redirect-uri: %v\", err)\n\t}\n\ttlsConfig := settings.OIDCTLSConfig()\n\ta.client = &http.Client{\n\t\tTransport: &http.Transport{\n\t\t\tTLSClientConfig: tlsConfig,\n\t\t\tProxy:           http.ProxyFromEnvironment,\n\t\t\tDial: (&net.Dialer{\n\t\t\t\tTimeout:   30 * time.Second,\n\t\t\t\tKeepAlive: 30 * time.Second,\n\t\t\t}).Dial,\n\t\t\tTLSHandshakeTimeout:   10 * time.Second,\n\t\t\tExpectContinueTimeout: 1 * time.Second,\n\t\t},\n\t}\n\tif settings.DexConfig != \"\" && settings.OIDCConfigRAW == \"\" {\n\t\ta.client.Transport = dex.NewDexRewriteURLRoundTripper(dexServerAddr, a.client.Transport)\n\t}\n\tif os.Getenv(common.EnvVarSSODebug) == \"1\" {\n\t\ta.client.Transport = httputil.DebugTransport{T: a.client.Transport}\n\t}\n\n\ta.provider = NewOIDCProvider(a.issuerURL, a.client)\n\t// NOTE: if we ever have replicas of Argo CD, this needs to switch to Redis cache\n\ta.secureCookie = bool(u.Scheme == \"https\")\n\ta.settings = settings\n\treturn &a, nil\n}\n\nfunc (a *ClientApp) oauth2Config(scopes []string) (*oauth2.Config, error) {\n\tendpoint, err := a.provider.Endpoint()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &oauth2.Config{\n\t\tClientID:     a.clientID,\n\t\tClientSecret: a.clientSecret,\n\t\tEndpoint:     *endpoint,\n\t\tScopes:       scopes,\n\t\tRedirectURL:  a.redirectURI,\n\t}, nil\n}\n\n// generateAppState creates an app state nonce\nfunc (a *ClientApp) generateAppState(returnURL string, w http.ResponseWriter) (string, error) {\n\t// According to the spec (https://www.rfc-editor.org/rfc/rfc6749#section-10.10), this must be guessable with\n\t// probability <= 2^(-128). The following call generates one of 52^24 random strings, ~= 2^136 possibilities.\n\trandStr, err := rand.String(24)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to generate app state: %w\", err)\n\t}\n\tif returnURL == \"\" {\n\t\treturnURL = a.baseHRef\n\t}\n\tcookieValue := fmt.Sprintf(\"%s:%s\", randStr, returnURL)\n\tif encrypted, err := crypto.Encrypt([]byte(cookieValue), a.encryptionKey); err != nil {\n\t\treturn \"\", err\n\t} else {\n\t\tcookieValue = hex.EncodeToString(encrypted)\n\t}\n\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     common.StateCookieName,\n\t\tValue:    cookieValue,\n\t\tExpires:  time.Now().Add(common.StateCookieMaxAge),\n\t\tHttpOnly: true,\n\t\tSameSite: http.SameSiteLaxMode,\n\t\tSecure:   a.secureCookie,\n\t})\n\treturn randStr, nil\n}\n\nfunc (a *ClientApp) verifyAppState(r *http.Request, w http.ResponseWriter, state string) (string, error) {\n\tc, err := r.Cookie(common.StateCookieName)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tval, err := hex.DecodeString(c.Value)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tval, err = crypto.Decrypt(val, a.encryptionKey)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tcookieVal := string(val)\n\treturnURL := a.baseHRef\n\tparts := strings.SplitN(cookieVal, \":\", 2)\n\tif len(parts) == 2 && parts[1] != \"\" {\n\t\treturnURL = parts[1]\n\t}\n\tif parts[0] != state {\n\t\treturn \"\", fmt.Errorf(\"invalid state in '%s' cookie\", common.AuthCookieName)\n\t}\n\t// set empty cookie to clear it\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     common.StateCookieName,\n\t\tValue:    \"\",\n\t\tHttpOnly: true,\n\t\tSameSite: http.SameSiteLaxMode,\n\t\tSecure:   a.secureCookie,\n\t})\n\treturn returnURL, nil\n}\n\n// isValidRedirectURL checks whether the given redirectURL matches on of the\n// allowed URLs to redirect to.\n//\n// In order to be considered valid,the protocol and host (including port) have\n// to match and if allowed path is not \"/\", redirectURL's path must be within\n// allowed URL's path.\nfunc isValidRedirectURL(redirectURL string, allowedURLs []string) bool {\n\tif redirectURL == \"\" {\n\t\treturn true\n\t}\n\tr, err := url.Parse(redirectURL)\n\tif err != nil {\n\t\treturn false\n\t}\n\t// We consider empty path the same as \"/\" for redirect URL\n\tif r.Path == \"\" {\n\t\tr.Path = \"/\"\n\t}\n\t// Prevent CRLF in the redirectURL\n\tif strings.ContainsAny(r.Path, \"\\r\\n\") {\n\t\treturn false\n\t}\n\tfor _, baseURL := range allowedURLs {\n\t\tb, err := url.Parse(baseURL)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\t// We consider empty path the same as \"/\" for allowed URL\n\t\tif b.Path == \"\" {\n\t\t\tb.Path = \"/\"\n\t\t}\n\t\t// scheme and host are mandatory to match.\n\t\tif b.Scheme == r.Scheme && b.Host == r.Host {\n\t\t\t// If path of redirectURL and allowedURL match, redirectURL is allowed\n\t\t\t//if b.Path == r.Path {\n\t\t\t//\treturn true\n\t\t\t//}\n\t\t\t// If path of redirectURL is within allowed URL's path, redirectURL is allowed\n\t\t\tif strings.HasPrefix(path.Clean(r.Path), b.Path) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\t// No match - redirect URL is not allowed\n\treturn false\n}\n\n// HandleLogin formulates the proper OAuth2 URL (auth code or implicit) and redirects the user to\n// the IDp login & consent page\nfunc (a *ClientApp) HandleLogin(w http.ResponseWriter, r *http.Request) {\n\toidcConf, err := a.provider.ParseConfig()\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tscopes := make([]string, 0)\n\tvar opts []oauth2.AuthCodeOption\n\tif config := a.settings.OIDCConfig(); config != nil {\n\t\tscopes = config.RequestedScopes\n\t\topts = AppendClaimsAuthenticationRequestParameter(opts, config.RequestedIDTokenClaims)\n\t}\n\toauth2Config, err := a.oauth2Config(GetScopesOrDefault(scopes))\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\treturnURL := r.FormValue(\"return_url\")\n\t// Check if return_url is valid, otherwise abort processing (see https://github.com/argoproj/argo-cd/pull/4780)\n\tif !isValidRedirectURL(returnURL, []string{a.settings.URL}) {\n\t\thttp.Error(w, \"Invalid redirect URL: the protocol and host (including port) must match and the path must be within allowed URLs if provided\", http.StatusBadRequest)\n\t\treturn\n\t}\n\tstateNonce, err := a.generateAppState(returnURL, w)\n\tif err != nil {\n\t\tlog.Errorf(\"Failed to initiate login flow: %v\", err)\n\t\thttp.Error(w, \"Failed to initiate login flow\", http.StatusInternalServerError)\n\t\treturn\n\t}\n\tgrantType := InferGrantType(oidcConf)\n\tvar url string\n\tswitch grantType {\n\tcase GrantTypeAuthorizationCode:\n\t\turl = oauth2Config.AuthCodeURL(stateNonce, opts...)\n\tcase GrantTypeImplicit:\n\t\turl, err = ImplicitFlowURL(oauth2Config, stateNonce, opts...)\n\t\tif err != nil {\n\t\t\tlog.Errorf(\"Failed to initiate implicit login flow: %v\", err)\n\t\t\thttp.Error(w, \"Failed to initiate implicit login flow\", http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\tdefault:\n\t\thttp.Error(w, fmt.Sprintf(\"Unsupported grant type: %v\", grantType), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tlog.Infof(\"Performing %s flow login: %s\", grantType, url)\n\thttp.Redirect(w, r, url, http.StatusSeeOther)\n}\n\n// HandleCallback is the callback handler for an OAuth2 login flow\nfunc (a *ClientApp) HandleCallback(w http.ResponseWriter, r *http.Request) {\n\toauth2Config, err := a.oauth2Config(nil)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tlog.Infof(\"Callback: %s\", r.URL)\n\tif errMsg := r.FormValue(\"error\"); errMsg != \"\" {\n\t\terrorDesc := r.FormValue(\"error_description\")\n\t\thttp.Error(w, html.EscapeString(errMsg)+\": \"+html.EscapeString(errorDesc), http.StatusBadRequest)\n\t\treturn\n\t}\n\tcode := r.FormValue(\"code\")\n\tstate := r.FormValue(\"state\")\n\tif code == \"\" {\n\t\t// If code was not given, it implies implicit flow\n\t\ta.handleImplicitFlow(r, w, state)\n\t\treturn\n\t}\n\treturnURL, err := a.verifyAppState(r, w, state)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\tctx := gooidc.ClientContext(r.Context(), a.client)\n\ttoken, err := oauth2Config.Exchange(ctx, code)\n\tif err != nil {\n\t\thttp.Error(w, fmt.Sprintf(\"failed to get token: %v\", err), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tidTokenRAW, ok := token.Extra(\"id_token\").(string)\n\tif !ok {\n\t\thttp.Error(w, \"no id_token in token response\", http.StatusInternalServerError)\n\t\treturn\n\t}\n\tidToken, err := a.provider.Verify(a.clientID, idTokenRAW)\n\tif err != nil {\n\t\thttp.Error(w, fmt.Sprintf(\"invalid session token: %v\", err), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tpath := \"/\"\n\tif a.baseHRef != \"\" {\n\t\tpath = strings.TrimRight(strings.TrimLeft(a.baseHRef, \"/\"), \"/\")\n\t}\n\tcookiePath := fmt.Sprintf(\"path=/%s\", path)\n\tflags := []string{cookiePath, \"SameSite=lax\", \"httpOnly\"}\n\tif a.secureCookie {\n\t\tflags = append(flags, \"Secure\")\n\t}\n\tvar claims jwt.MapClaims\n\terr = idToken.Claims(&claims)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tif idTokenRAW != \"\" {\n\t\tcookies, err := httputil.MakeCookieMetadata(common.AuthCookieName, idTokenRAW, flags...)\n\t\tif err != nil {\n\t\t\tclaimsJSON, _ := json.Marshal(claims)\n\t\t\thttp.Error(w, fmt.Sprintf(\"claims=%s, err=%v\", claimsJSON, err), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tfor _, cookie := range cookies {\n\t\t\tw.Header().Add(\"Set-Cookie\", cookie)\n\t\t}\n\t}\n\n\tclaimsJSON, _ := json.Marshal(claims)\n\tlog.Infof(\"Web login successful. Claims: %s\", claimsJSON)\n\tif os.Getenv(common.EnvVarSSODebug) == \"1\" {\n\t\tclaimsJSON, _ := json.MarshalIndent(claims, \"\", \"  \")\n\t\trenderToken(w, a.redirectURI, idTokenRAW, token.RefreshToken, claimsJSON)\n\t} else {\n\t\thttp.Redirect(w, r, returnURL, http.StatusSeeOther)\n\t}\n}\n\nvar implicitFlowTmpl = template.Must(template.New(\"implicit.html\").Parse(`<script>\nvar hash = window.location.hash.substr(1);\nvar result = hash.split('&').reduce(function (result, item) {\n\tvar parts = item.split('=');\n\tresult[parts[0]] = parts[1];\n\treturn result;\n}, {});\nvar idToken = result['id_token'];\nvar state = result['state'];\nvar returnURL = \"{{ .ReturnURL }}\";\nif (state != \"\" && returnURL == \"\") {\n\twindow.location.href = window.location.href.split(\"#\")[0] + \"?state=\" + result['state'] + window.location.hash;\n} else if (returnURL != \"\") {\n\tdocument.cookie = \"{{ .CookieName }}=\" + idToken + \"; path=/\";\n\twindow.location.href = returnURL;\n}\n</script>`))\n\n// handleImplicitFlow completes an implicit OAuth2 flow. The id_token and state will be contained\n// in the URL fragment. The javascript client first redirects to the callback URL, supplying the\n// state nonce for verification, as well as looking up the return URL. Once verified, the client\n// stores the id_token from the fragment as a cookie. Finally it performs the final redirect back to\n// the return URL.\nfunc (a *ClientApp) handleImplicitFlow(r *http.Request, w http.ResponseWriter, state string) {\n\ttype implicitFlowValues struct {\n\t\tCookieName string\n\t\tReturnURL  string\n\t}\n\tvals := implicitFlowValues{\n\t\tCookieName: common.AuthCookieName,\n\t}\n\tif state != \"\" {\n\t\treturnURL, err := a.verifyAppState(r, w, state)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tvals.ReturnURL = returnURL\n\t}\n\trenderTemplate(w, implicitFlowTmpl, vals)\n}\n\n// ImplicitFlowURL is an adaptation of oauth2.Config::AuthCodeURL() which returns a URL\n// appropriate for an OAuth2 implicit login flow (as opposed to authorization code flow).\nfunc ImplicitFlowURL(c *oauth2.Config, state string, opts ...oauth2.AuthCodeOption) (string, error) {\n\topts = append(opts, oauth2.SetAuthURLParam(\"response_type\", \"id_token\"))\n\trandString, err := rand.String(24)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to generate nonce for implicit flow URL: %w\", err)\n\t}\n\topts = append(opts, oauth2.SetAuthURLParam(\"nonce\", randString))\n\treturn c.AuthCodeURL(state, opts...), nil\n}\n\n// OfflineAccess returns whether or not 'offline_access' is a supported scope\nfunc OfflineAccess(scopes []string) bool {\n\tif len(scopes) == 0 {\n\t\t// scopes_supported is a \"RECOMMENDED\" discovery claim, not a required\n\t\t// one. If missing, assume that the provider follows the spec and has\n\t\t// an \"offline_access\" scope.\n\t\treturn true\n\t}\n\t// See if scopes_supported has the \"offline_access\" scope.\n\tfor _, scope := range scopes {\n\t\tif scope == gooidc.ScopeOfflineAccess {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// InferGrantType infers the proper grant flow depending on the OAuth2 client config and OIDC configuration.\n// Returns either: \"authorization_code\" or \"implicit\"\nfunc InferGrantType(oidcConf *OIDCConfiguration) string {\n\t// Check the supported response types. If the list contains the response type 'code',\n\t// then grant type is 'authorization_code'. This is preferred over the implicit\n\t// grant type since refresh tokens cannot be issued that way.\n\tfor _, supportedType := range oidcConf.ResponseTypesSupported {\n\t\tif supportedType == ResponseTypeCode {\n\t\t\treturn GrantTypeAuthorizationCode\n\t\t}\n\t}\n\n\t// Assume implicit otherwise\n\treturn GrantTypeImplicit\n}\n\n// AppendClaimsAuthenticationRequestParameter appends a OIDC claims authentication request parameter\n// to `opts` with the `requestedClaims`\nfunc AppendClaimsAuthenticationRequestParameter(opts []oauth2.AuthCodeOption, requestedClaims map[string]*oidc.Claim) []oauth2.AuthCodeOption {\n\tif len(requestedClaims) == 0 {\n\t\treturn opts\n\t}\n\tlog.Infof(\"RequestedClaims: %s\\n\", requestedClaims)\n\tclaimsRequestParameter, err := createClaimsAuthenticationRequestParameter(requestedClaims)\n\tif err != nil {\n\t\tlog.Errorf(\"Failed to create OIDC claims authentication request parameter from config: %s\", err)\n\t\treturn opts\n\t}\n\treturn append(opts, claimsRequestParameter)\n}\n\nfunc createClaimsAuthenticationRequestParameter(requestedClaims map[string]*oidc.Claim) (oauth2.AuthCodeOption, error) {\n\tclaimsRequest := ClaimsRequest{IDToken: requestedClaims}\n\tclaimsRequestRAW, err := json.Marshal(claimsRequest)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn oauth2.SetAuthURLParam(\"claims\", string(claimsRequestRAW)), nil\n}\n", "package rand\n\nimport (\n\t\"crypto/rand\"\n\t\"fmt\"\n\t\"math/big\"\n)\n\nconst letterBytes = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n\n// String generates, from the set of capital and lowercase letters, a cryptographically-secure pseudo-random string of a given length.\nfunc String(n int) (string, error) {\n\treturn StringFromCharset(n, letterBytes)\n}\n\n// StringFromCharset generates, from a given charset, a cryptographically-secure pseudo-random string of a given length.\nfunc StringFromCharset(n int, charset string) (string, error) {\n\tb := make([]byte, n)\n\tmaxIdx := big.NewInt(int64(len(charset)))\n\tfor i := 0; i < n; i++ {\n\t\trandIdx, err := rand.Int(rand.Reader, maxIdx)\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"failed to generate random string: %w\", err)\n\t\t}\n\t\t// randIdx is necessarily safe to convert to int, because the max came from an int.\n\t\trandIdxInt := int(randIdx.Int64())\n\t\tb[i] = charset[randIdxInt]\n\t}\n\treturn string(b), nil\n}\n", "package rand\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestRandString(t *testing.T) {\n\tss, err := StringFromCharset(10, \"A\")\n\trequire.NoError(t, err)\n\tassert.Equal(t, \"AAAAAAAAAA\", ss)\n\n\tss, err = StringFromCharset(5, \"ABC123\")\n\trequire.NoError(t, err)\n\tassert.Len(t, ss, 5)\n}\n"], "filenames": ["cmd/argocd/commands/login.go", "controller/sync.go", "pkg/apiclient/grpcproxy.go", "test/e2e/fixture/fixture.go", "test/e2e/selective_sync_test.go", "util/oidc/oidc.go", "util/rand/rand.go", "util/rand/rand_test.go"], "buggy_code_start_loc": [205, 152, 103, 564, 9, 147, 4, 4], "buggy_code_end_loc": [300, 153, 104, 565, 114, 422, 37, 16], "fixing_code_start_loc": [205, 152, 103, 564, 10, 147, 4, 5], "fixing_code_end_loc": [305, 159, 108, 567, 117, 436, 30, 18], "type": "CWE-330", "message": "Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes. All versions of Argo CD starting with v0.11.0 are vulnerable to a variety of attacks when an SSO login is initiated from the Argo CD CLI or UI. The vulnerabilities are due to the use of insufficiently random values in parameters in Oauth2/OIDC login flows. In each case, using a relatively-predictable (time-based) seed in a non-cryptographically-secure pseudo-random number generator made the parameter less random than required by the relevant spec or by general best practices. In some cases, using too short a value made the entropy even less sufficient. The attacks on login flows which are meant to be mitigated by these parameters are difficult to accomplish but can have a high impact potentially granting an attacker admin access to Argo CD. Patches for this vulnerability has been released in the following Argo CD versions: v2.4.1, v2.3.5, v2.2.10 and v2.1.16. There are no known workarounds for this vulnerability.", "other": {"cve": {"id": "CVE-2022-31034", "sourceIdentifier": "security-advisories@github.com", "published": "2022-06-27T19:15:08.393", "lastModified": "2022-07-07T17:04:49.640", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes. All versions of Argo CD starting with v0.11.0 are vulnerable to a variety of attacks when an SSO login is initiated from the Argo CD CLI or UI. The vulnerabilities are due to the use of insufficiently random values in parameters in Oauth2/OIDC login flows. In each case, using a relatively-predictable (time-based) seed in a non-cryptographically-secure pseudo-random number generator made the parameter less random than required by the relevant spec or by general best practices. In some cases, using too short a value made the entropy even less sufficient. The attacks on login flows which are meant to be mitigated by these parameters are difficult to accomplish but can have a high impact potentially granting an attacker admin access to Argo CD. Patches for this vulnerability has been released in the following Argo CD versions: v2.4.1, v2.3.5, v2.2.10 and v2.1.16. There are no known workarounds for this vulnerability."}, {"lang": "es", "value": "Argo CD es una herramienta declarativa de entrega continua GitOps para Kubernetes. Todas las versiones de Argo CD a partir de la v0.11.0, son vulnerables a una variedad de ataques cuando es iniciado un inicio de sesi\u00f3n SSO desde la CLI o la UI de Argo CD. Las vulnerabilidades son debido a un uso de valores insuficientemente aleatorios en los par\u00e1metros de los flujos de inicio de sesi\u00f3n Oauth2/OIDC. En cada caso, el uso de una semilla relativamente predecible (basada en el tiempo) en un generador de n\u00fameros pseudoaleatorios no seguro desde el punto de vista criptogr\u00e1fico hizo que el par\u00e1metro fuera menos aleatorio de lo requerido por la especificaci\u00f3n correspondiente o por las mejores pr\u00e1cticas generales. En algunos casos, el uso de un valor demasiado corto hac\u00eda que la entrop\u00eda fuera a\u00fan menos suficiente. Los ataques a los flujos de inicio de sesi\u00f3n que pretenden mitigarse con estos par\u00e1metros son dif\u00edciles de llevar a cabo, pero pueden tener un alto impacto, pudiendo conceder a un atacante acceso de administrador a Argo CD. Han sido publicados parches para esta vulnerabilidad en las siguientes versiones de Argo CD: v2.4.1, v2.3.5, v2.2.10 y v2.1.16. No son conocidas mitigaciones para esta vulnerabilidad"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.3, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.6, "impactScore": 6.0}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-330"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-330"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:argo-cd:*:*:*:*:*:*:*:*", "versionStartIncluding": "0.11.0", "versionEndExcluding": "2.1.16", "matchCriteriaId": "C2BEAF66-C322-4487-9F18-4D074978F860"}, {"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:argo-cd:2.2.9:*:*:*:*:*:*:*", "matchCriteriaId": "906BD20E-517B-4340-BDCE-CD26EDFCAAE1"}, {"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:argo-cd:2.3.4:*:*:*:*:*:*:*", "matchCriteriaId": "7DDE2669-E1D4-4C23-96CD-94C900588F58"}, {"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:argo-cd:2.4.0:*:*:*:*:*:*:*", "matchCriteriaId": "7F3DB336-11F0-45EB-AED6-68224A55C3A2"}]}]}], "references": [{"url": "https://github.com/argoproj/argo-cd/commit/17f7f4f462bdb233e1b9b36f67099f41052d8cb0", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/argoproj/argo-cd/security/advisories/GHSA-2m7h-86qq-fp4v", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/argoproj/argo-cd/commit/17f7f4f462bdb233e1b9b36f67099f41052d8cb0"}}
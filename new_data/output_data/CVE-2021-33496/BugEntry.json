{"buggy_code": ["package cmd\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\n\t\"github.com/dutchcoders/transfer.sh/server\"\n\t\"github.com/fatih/color\"\n\t\"github.com/urfave/cli\"\n\t\"google.golang.org/api/googleapi\"\n)\n\nvar Version = \"1.2.2\"\nvar helpTemplate = `NAME:\n{{.Name}} - {{.Usage}}\n\nDESCRIPTION:\n{{.Description}}\n\nUSAGE:\n{{.Name}} {{if .Flags}}[flags] {{end}}command{{if .Flags}}{{end}} [arguments...]\n\nCOMMANDS:\n{{range .Commands}}{{join .Names \", \"}}{{ \"\\t\" }}{{.Usage}}\n{{end}}{{if .Flags}}\nFLAGS:\n{{range .Flags}}{{.}}\n{{end}}{{end}}\nVERSION:\n` + Version +\n\t`{{ \"\\n\"}}`\n\nvar globalFlags = []cli.Flag{\n\tcli.StringFlag{\n\t\tName:   \"listener\",\n\t\tUsage:  \"127.0.0.1:8080\",\n\t\tValue:  \"127.0.0.1:8080\",\n\t\tEnvVar: \"LISTENER\",\n\t},\n\t// redirect to https?\n\t// hostnames\n\tcli.StringFlag{\n\t\tName:   \"profile-listener\",\n\t\tUsage:  \"127.0.0.1:6060\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"PROFILE_LISTENER\",\n\t},\n\tcli.BoolFlag{\n\t\tName:   \"force-https\",\n\t\tUsage:  \"\",\n\t\tEnvVar: \"FORCE_HTTPS\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"tls-listener\",\n\t\tUsage:  \"127.0.0.1:8443\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"TLS_LISTENER\",\n\t},\n\tcli.BoolFlag{\n\t\tName:   \"tls-listener-only\",\n\t\tUsage:  \"\",\n\t\tEnvVar: \"TLS_LISTENER_ONLY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"tls-cert-file\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"TLS_CERT_FILE\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"tls-private-key\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"TLS_PRIVATE_KEY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"temp-path\",\n\t\tUsage:  \"path to temp files\",\n\t\tValue:  os.TempDir(),\n\t\tEnvVar: \"TEMP_PATH\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"web-path\",\n\t\tUsage:  \"path to static web files\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"WEB_PATH\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"proxy-path\",\n\t\tUsage:  \"path prefix when service is run behind a proxy\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"PROXY_PATH\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"proxy-port\",\n\t\tUsage:  \"port of the proxy when the service is run behind a proxy\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"PROXY_PORT\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"ga-key\",\n\t\tUsage:  \"key for google analytics (front end)\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"GA_KEY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"uservoice-key\",\n\t\tUsage:  \"key for user voice (front end)\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"USERVOICE_KEY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"provider\",\n\t\tUsage:  \"s3|gdrive|local\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"PROVIDER\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"s3-endpoint\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"S3_ENDPOINT\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"s3-region\",\n\t\tUsage:  \"\",\n\t\tValue:  \"eu-west-1\",\n\t\tEnvVar: \"S3_REGION\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"aws-access-key\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"AWS_ACCESS_KEY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"aws-secret-key\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"AWS_SECRET_KEY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"bucket\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"BUCKET\",\n\t},\n\tcli.BoolFlag{\n\t\tName:   \"s3-no-multipart\",\n\t\tUsage:  \"Disables S3 Multipart Puts\",\n\t\tEnvVar: \"S3_NO_MULTIPART\",\n\t},\n\tcli.BoolFlag{\n\t\tName:   \"s3-path-style\",\n\t\tUsage:  \"Forces path style URLs, required for Minio.\",\n\t\tEnvVar: \"S3_PATH_STYLE\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"gdrive-client-json-filepath\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"GDRIVE_CLIENT_JSON_FILEPATH\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"gdrive-local-config-path\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"GDRIVE_LOCAL_CONFIG_PATH\",\n\t},\n\tcli.IntFlag{\n\t\tName:   \"gdrive-chunk-size\",\n\t\tUsage:  \"\",\n\t\tValue:  googleapi.DefaultUploadChunkSize / 1024 / 1024,\n\t\tEnvVar: \"GDRIVE_CHUNK_SIZE\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"storj-access\",\n\t\tUsage:  \"Access for the project\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"STORJ_ACCESS\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"storj-bucket\",\n\t\tUsage:  \"Bucket to use within the project\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"STORJ_BUCKET\",\n\t},\n\tcli.IntFlag{\n\t\tName:   \"rate-limit\",\n\t\tUsage:  \"requests per minute\",\n\t\tValue:  0,\n\t\tEnvVar: \"RATE_LIMIT\",\n\t},\n\tcli.IntFlag{\n\t\tName:   \"purge-days\",\n\t\tUsage:  \"number of days after uploads are purged automatically\",\n\t\tValue:  0,\n\t\tEnvVar: \"PURGE_DAYS\",\n\t},\n\tcli.IntFlag{\n\t\tName:   \"purge-interval\",\n\t\tUsage:  \"interval in hours to run the automatic purge for\",\n\t\tValue:  0,\n\t\tEnvVar: \"PURGE_INTERVAL\",\n\t},\n\tcli.Int64Flag{\n\t\tName:   \"max-upload-size\",\n\t\tUsage:  \"max limit for upload, in kilobytes\",\n\t\tValue:  0,\n\t\tEnvVar: \"MAX_UPLOAD_SIZE\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"lets-encrypt-hosts\",\n\t\tUsage:  \"host1, host2\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"HOSTS\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"log\",\n\t\tUsage:  \"/var/log/transfersh.log\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"LOG\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"basedir\",\n\t\tUsage:  \"path to storage\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"BASEDIR\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"clamav-host\",\n\t\tUsage:  \"clamav-host\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"CLAMAV_HOST\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"virustotal-key\",\n\t\tUsage:  \"virustotal-key\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"VIRUSTOTAL_KEY\",\n\t},\n\tcli.BoolFlag{\n\t\tName:   \"profiler\",\n\t\tUsage:  \"enable profiling\",\n\t\tEnvVar: \"PROFILER\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"http-auth-user\",\n\t\tUsage:  \"user for http basic auth\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"HTTP_AUTH_USER\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"http-auth-pass\",\n\t\tUsage:  \"pass for http basic auth\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"HTTP_AUTH_PASS\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"ip-whitelist\",\n\t\tUsage:  \"comma separated list of ips allowed to connect to the service\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"IP_WHITELIST\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"ip-blacklist\",\n\t\tUsage:  \"comma separated list of ips not allowed to connect to the service\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"IP_BLACKLIST\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"cors-domains\",\n\t\tUsage:  \"comma separated list of domains allowed for CORS requests\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"CORS_DOMAINS\",\n\t},\n\tcli.Int64Flag{\n\t\tName:   \"random-token-length\",\n\t\tUsage:  \"\",\n\t\tValue:  6,\n\t\tEnvVar: \"RANDOM_TOKEN_LENGTH\",\n\t},\n}\n\ntype Cmd struct {\n\t*cli.App\n}\n\nfunc VersionAction(c *cli.Context) {\n\tfmt.Println(color.YellowString(fmt.Sprintf(\"transfer.sh %s: Easy file sharing from the command line\", Version)))\n}\n\nfunc New() *Cmd {\n\tlogger := log.New(os.Stdout, \"[transfer.sh]\", log.LstdFlags)\n\n\tapp := cli.NewApp()\n\tapp.Name = \"transfer.sh\"\n\tapp.Author = \"\"\n\tapp.Usage = \"transfer.sh\"\n\tapp.Description = `Easy file sharing from the command line`\n\tapp.Version = Version\n\tapp.Flags = globalFlags\n\tapp.CustomAppHelpTemplate = helpTemplate\n\tapp.Commands = []cli.Command{\n\t\t{\n\t\t\tName:   \"version\",\n\t\t\tAction: VersionAction,\n\t\t},\n\t}\n\n\tapp.Before = func(c *cli.Context) error {\n\t\treturn nil\n\t}\n\n\tapp.Action = func(c *cli.Context) {\n\t\toptions := []server.OptionFn{}\n\t\tif v := c.String(\"listener\"); v != \"\" {\n\t\t\toptions = append(options, server.Listener(v))\n\t\t}\n\n\t\tif v := c.String(\"cors-domains\"); v != \"\" {\n\t\t\toptions = append(options, server.CorsDomains(v))\n\t\t}\n\n\t\tif v := c.String(\"tls-listener\"); v == \"\" {\n\t\t} else if c.Bool(\"tls-listener-only\") {\n\t\t\toptions = append(options, server.TLSListener(v, true))\n\t\t} else {\n\t\t\toptions = append(options, server.TLSListener(v, false))\n\t\t}\n\n\t\tif v := c.String(\"profile-listener\"); v != \"\" {\n\t\t\toptions = append(options, server.ProfileListener(v))\n\t\t}\n\n\t\tif v := c.String(\"web-path\"); v != \"\" {\n\t\t\toptions = append(options, server.WebPath(v))\n\t\t}\n\n\t\tif v := c.String(\"proxy-path\"); v != \"\" {\n\t\t\toptions = append(options, server.ProxyPath(v))\n\t\t}\n\n\t\tif v := c.String(\"proxy-port\"); v != \"\" {\n\t\t\toptions = append(options, server.ProxyPort(v))\n\t\t}\n\n\t\tif v := c.String(\"ga-key\"); v != \"\" {\n\t\t\toptions = append(options, server.GoogleAnalytics(v))\n\t\t}\n\n\t\tif v := c.String(\"uservoice-key\"); v != \"\" {\n\t\t\toptions = append(options, server.UserVoice(v))\n\t\t}\n\n\t\tif v := c.String(\"temp-path\"); v != \"\" {\n\t\t\toptions = append(options, server.TempPath(v))\n\t\t}\n\n\t\tif v := c.String(\"log\"); v != \"\" {\n\t\t\toptions = append(options, server.LogFile(logger, v))\n\t\t} else {\n\t\t\toptions = append(options, server.Logger(logger))\n\t\t}\n\n\t\tif v := c.String(\"lets-encrypt-hosts\"); v != \"\" {\n\t\t\toptions = append(options, server.UseLetsEncrypt(strings.Split(v, \",\")))\n\t\t}\n\n\t\tif v := c.String(\"virustotal-key\"); v != \"\" {\n\t\t\toptions = append(options, server.VirustotalKey(v))\n\t\t}\n\n\t\tif v := c.String(\"clamav-host\"); v != \"\" {\n\t\t\toptions = append(options, server.ClamavHost(v))\n\t\t}\n\n\t\tif v := c.Int64(\"max-upload-size\"); v > 0 {\n\t\t\toptions = append(options, server.MaxUploadSize(v))\n\t\t}\n\n\t\tif v := c.Int(\"rate-limit\"); v > 0 {\n\t\t\toptions = append(options, server.RateLimit(v))\n\t\t}\n\n\t\tv := c.Int64(\"random-token-length\")\n\t\toptions = append(options, server.RandomTokenLength(v))\n\n\t\tpurgeDays := c.Int(\"purge-days\")\n\t\tpurgeInterval := c.Int(\"purge-interval\")\n\t\tif purgeDays > 0 && purgeInterval > 0 {\n\t\t\toptions = append(options, server.Purge(purgeDays, purgeInterval))\n\t\t}\n\n\t\tif cert := c.String(\"tls-cert-file\"); cert == \"\" {\n\t\t} else if pk := c.String(\"tls-private-key\"); pk == \"\" {\n\t\t} else {\n\t\t\toptions = append(options, server.TLSConfig(cert, pk))\n\t\t}\n\n\t\tif c.Bool(\"profiler\") {\n\t\t\toptions = append(options, server.EnableProfiler())\n\t\t}\n\n\t\tif c.Bool(\"force-https\") {\n\t\t\toptions = append(options, server.ForceHTTPs())\n\t\t}\n\n\t\tif httpAuthUser := c.String(\"http-auth-user\"); httpAuthUser == \"\" {\n\t\t} else if httpAuthPass := c.String(\"http-auth-pass\"); httpAuthPass == \"\" {\n\t\t} else {\n\t\t\toptions = append(options, server.HttpAuthCredentials(httpAuthUser, httpAuthPass))\n\t\t}\n\n\t\tapplyIPFilter := false\n\t\tipFilterOptions := server.IPFilterOptions{}\n\t\tif ipWhitelist := c.String(\"ip-whitelist\"); ipWhitelist != \"\" {\n\t\t\tapplyIPFilter = true\n\t\t\tipFilterOptions.AllowedIPs = strings.Split(ipWhitelist, \",\")\n\t\t\tipFilterOptions.BlockByDefault = true\n\t\t}\n\n\t\tif ipBlacklist := c.String(\"ip-blacklist\"); ipBlacklist != \"\" {\n\t\t\tapplyIPFilter = true\n\t\t\tipFilterOptions.BlockedIPs = strings.Split(ipBlacklist, \",\")\n\t\t}\n\n\t\tif applyIPFilter {\n\t\t\toptions = append(options, server.FilterOptions(ipFilterOptions))\n\t\t}\n\n\t\tswitch provider := c.String(\"provider\"); provider {\n\t\tcase \"s3\":\n\t\t\tif accessKey := c.String(\"aws-access-key\"); accessKey == \"\" {\n\t\t\t\tpanic(\"access-key not set.\")\n\t\t\t} else if secretKey := c.String(\"aws-secret-key\"); secretKey == \"\" {\n\t\t\t\tpanic(\"secret-key not set.\")\n\t\t\t} else if bucket := c.String(\"bucket\"); bucket == \"\" {\n\t\t\t\tpanic(\"bucket not set.\")\n\t\t\t} else if storage, err := server.NewS3Storage(accessKey, secretKey, bucket, purgeDays, c.String(\"s3-region\"), c.String(\"s3-endpoint\"), c.Bool(\"s3-no-multipart\"), c.Bool(\"s3-path-style\"), logger); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t} else {\n\t\t\t\toptions = append(options, server.UseStorage(storage))\n\t\t\t}\n\t\tcase \"gdrive\":\n\t\t\tchunkSize := c.Int(\"gdrive-chunk-size\")\n\n\t\t\tif clientJsonFilepath := c.String(\"gdrive-client-json-filepath\"); clientJsonFilepath == \"\" {\n\t\t\t\tpanic(\"client-json-filepath not set.\")\n\t\t\t} else if localConfigPath := c.String(\"gdrive-local-config-path\"); localConfigPath == \"\" {\n\t\t\t\tpanic(\"local-config-path not set.\")\n\t\t\t} else if basedir := c.String(\"basedir\"); basedir == \"\" {\n\t\t\t\tpanic(\"basedir not set.\")\n\t\t\t} else if storage, err := server.NewGDriveStorage(clientJsonFilepath, localConfigPath, basedir, chunkSize, logger); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t} else {\n\t\t\t\toptions = append(options, server.UseStorage(storage))\n\t\t\t}\n\t\tcase \"storj\":\n\t\t\tif access := c.String(\"storj-access\"); access == \"\" {\n\t\t\t\tpanic(\"storj-access not set.\")\n\t\t\t} else if bucket := c.String(\"storj-bucket\"); bucket == \"\" {\n\t\t\t\tpanic(\"storj-bucket not set.\")\n\t\t\t} else if storage, err := server.NewStorjStorage(access, bucket, purgeDays, logger); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t} else {\n\t\t\t\toptions = append(options, server.UseStorage(storage))\n\t\t\t}\n\t\tcase \"local\":\n\t\t\tif v := c.String(\"basedir\"); v == \"\" {\n\t\t\t\tpanic(\"basedir not set.\")\n\t\t\t} else if storage, err := server.NewLocalStorage(v, logger); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t} else {\n\t\t\t\toptions = append(options, server.UseStorage(storage))\n\t\t\t}\n\t\tdefault:\n\t\t\tpanic(\"Provider not set or invalid.\")\n\t\t}\n\n\t\tsrvr, err := server.New(\n\t\t\toptions...,\n\t\t)\n\n\t\tif err != nil {\n\t\t\tlogger.Println(color.RedString(\"Error starting server: %s\", err.Error()))\n\t\t\treturn\n\t\t}\n\n\t\tsrvr.Run()\n\t}\n\n\treturn &Cmd{\n\t\tApp: app,\n\t}\n}\n", "/*\nThe MIT License (MIT)\n\nCopyright (c) 2014-2017 DutchCoders [https://github.com/dutchcoders/]\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\npackage server\n\nimport (\n\t// _ \"transfer.sh/app/handlers\"\n\t// _ \"transfer.sh/app/utils\"\n\n\t\"archive/tar\"\n\t\"archive/zip\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\tblackfriday \"github.com/russross/blackfriday/v2\"\n\t\"html\"\n\thtml_template \"html/template\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"mime\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\ttext_template \"text/template\"\n\t\"time\"\n\n\t\"net\"\n\n\t\"encoding/base64\"\n\tweb \"github.com/dutchcoders/transfer.sh-web\"\n\t\"github.com/gorilla/mux\"\n\t\"github.com/microcosm-cc/bluemonday\"\n\t\"github.com/skip2/go-qrcode\"\n)\n\nconst getPathPart = \"get\"\n\nvar (\n\thtmlTemplates = initHTMLTemplates()\n\ttextTemplates = initTextTemplates()\n)\n\nfunc stripPrefix(path string) string {\n\treturn strings.Replace(path, web.Prefix+\"/\", \"\", -1)\n}\n\nfunc initTextTemplates() *text_template.Template {\n\ttemplateMap := text_template.FuncMap{\"format\": formatNumber}\n\n\t// Templates with functions available to them\n\tvar templates = text_template.New(\"\").Funcs(templateMap)\n\treturn templates\n}\n\nfunc initHTMLTemplates() *html_template.Template {\n\ttemplateMap := html_template.FuncMap{\"format\": formatNumber}\n\n\t// Templates with functions available to them\n\tvar templates = html_template.New(\"\").Funcs(templateMap)\n\n\treturn templates\n}\n\nfunc healthHandler(w http.ResponseWriter, r *http.Request) {\n\tfmt.Fprintf(w, \"Approaching Neutral Zone, all systems normal and functioning.\")\n}\n\n/* The preview handler will show a preview of the content for browsers (accept type text/html), and referer is not transfer.sh */\nfunc (s *Server) previewHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\ttoken := vars[\"token\"]\n\tfilename := vars[\"filename\"]\n\n\tmetadata, err := s.CheckMetadata(token, filename, false)\n\n\tif err != nil {\n\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t}\n\n\tcontentType := metadata.ContentType\n\tcontentLength, err := s.storage.Head(token, filename)\n\tif err != nil {\n\t\thttp.Error(w, http.StatusText(404), 404)\n\t\treturn\n\t}\n\n\tvar templatePath string\n\tvar content html_template.HTML\n\n\tswitch {\n\tcase strings.HasPrefix(contentType, \"image/\"):\n\t\ttemplatePath = \"download.image.html\"\n\tcase strings.HasPrefix(contentType, \"video/\"):\n\t\ttemplatePath = \"download.video.html\"\n\tcase strings.HasPrefix(contentType, \"audio/\"):\n\t\ttemplatePath = \"download.audio.html\"\n\tcase strings.HasPrefix(contentType, \"text/\"):\n\t\ttemplatePath = \"download.markdown.html\"\n\n\t\tvar reader io.ReadCloser\n\t\tif reader, _, err = s.storage.Get(token, filename); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tvar data []byte\n\t\tdata = make([]byte, _5M)\n\t\tif _, err = reader.Read(data); err != io.EOF && err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tif strings.HasPrefix(contentType, \"text/x-markdown\") || strings.HasPrefix(contentType, \"text/markdown\") {\n\t\t\tunsafe := blackfriday.Run(data)\n\t\t\toutput := bluemonday.UGCPolicy().SanitizeBytes(unsafe)\n\t\t\tcontent = html_template.HTML(output)\n\t\t} else if strings.HasPrefix(contentType, \"text/plain\") {\n\t\t\tcontent = html_template.HTML(fmt.Sprintf(\"<pre>%s</pre>\", html.EscapeString(string(data))))\n\t\t} else {\n\t\t\ttemplatePath = \"download.sandbox.html\"\n\t\t}\n\n\tdefault:\n\t\ttemplatePath = \"download.html\"\n\t}\n\n\trelativeURL, _ := url.Parse(path.Join(s.proxyPath, token, filename))\n\tresolvedURL := resolveURL(r, relativeURL, s.proxyPort)\n\trelativeURLGet, _ := url.Parse(path.Join(s.proxyPath, getPathPart, token, filename))\n\tresolvedURLGet := resolveURL(r, relativeURLGet, s.proxyPort)\n\tvar png []byte\n\tpng, err = qrcode.Encode(resolvedURL, qrcode.High, 150)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tqrCode := base64.StdEncoding.EncodeToString(png)\n\n\thostname := getURL(r, s.proxyPort).Host\n\twebAddress := resolveWebAddress(r, s.proxyPath, s.proxyPort)\n\n\tdata := struct {\n\t\tContentType    string\n\t\tContent        html_template.HTML\n\t\tFilename       string\n\t\tUrl            string\n\t\tUrlGet         string\n\t\tUrlRandomToken string\n\t\tHostname       string\n\t\tWebAddress     string\n\t\tContentLength  uint64\n\t\tGAKey          string\n\t\tUserVoiceKey   string\n\t\tQRCode         string\n\t}{\n\t\tcontentType,\n\t\tcontent,\n\t\tfilename,\n\t\tresolvedURL,\n\t\tresolvedURLGet,\n\t\ttoken,\n\t\thostname,\n\t\twebAddress,\n\t\tcontentLength,\n\t\ts.gaKey,\n\t\ts.userVoiceKey,\n\t\tqrCode,\n\t}\n\n\tif err := htmlTemplates.ExecuteTemplate(w, templatePath, data); err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n}\n\n// this handler will output html or text, depending on the\n// support of the client (Accept header).\n\nfunc (s *Server) viewHandler(w http.ResponseWriter, r *http.Request) {\n\t// vars := mux.Vars(r)\n\n\thostname := getURL(r, s.proxyPort).Host\n\twebAddress := resolveWebAddress(r, s.proxyPath, s.proxyPort)\n\n\tdata := struct {\n\t\tHostname     string\n\t\tWebAddress   string\n\t\tGAKey        string\n\t\tUserVoiceKey string\n\t}{\n\t\thostname,\n\t\twebAddress,\n\t\ts.gaKey,\n\t\ts.userVoiceKey,\n\t}\n\n\tif acceptsHTML(r.Header) {\n\t\tif err := htmlTemplates.ExecuteTemplate(w, \"index.html\", data); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t} else {\n\t\tif err := textTemplates.ExecuteTemplate(w, \"index.txt\", data); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (s *Server) notFoundHandler(w http.ResponseWriter, r *http.Request) {\n\thttp.Error(w, http.StatusText(404), 404)\n}\n\nfunc sanitize(fileName string) string {\n\treturn path.Clean(path.Base(fileName))\n}\n\nfunc (s *Server) postHandler(w http.ResponseWriter, r *http.Request) {\n\tif err := r.ParseMultipartForm(_24K); nil != err {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Error occurred copying to output stream\", 500)\n\t\treturn\n\t}\n\n\ttoken := Encode(INIT_SEED, s.randomTokenLength)\n\n\tw.Header().Set(\"Content-Type\", \"text/plain\")\n\n\tfor _, fheaders := range r.MultipartForm.File {\n\t\tfor _, fheader := range fheaders {\n\t\t\tfilename := sanitize(fheader.Filename)\n\t\t\tcontentType := fheader.Header.Get(\"Content-Type\")\n\n\t\t\tif contentType == \"\" {\n\t\t\t\tcontentType = mime.TypeByExtension(filepath.Ext(fheader.Filename))\n\t\t\t}\n\n\t\t\tvar f io.Reader\n\t\t\tvar err error\n\n\t\t\tif f, err = fheader.Open(); err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tvar b bytes.Buffer\n\n\t\t\tn, err := io.CopyN(&b, f, _24K+1)\n\t\t\tif err != nil && err != io.EOF {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tvar file *os.File\n\t\t\tvar reader io.Reader\n\n\t\t\tif n > _24K {\n\t\t\t\tfile, err = ioutil.TempFile(s.tempPath, \"transfer-\")\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\tn, err = io.Copy(file, io.MultiReader(&b, f))\n\t\t\t\tif err != nil {\n\t\t\t\t\tcleanTmpFile(file)\n\n\t\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\treader, err = os.Open(file.Name())\n\t\t\t} else {\n\t\t\t\treader = bytes.NewReader(b.Bytes())\n\t\t\t}\n\n\t\t\tcontentLength := n\n\n\t\t\tif s.maxUploadSize > 0 && contentLength > s.maxUploadSize {\n\t\t\t\tlog.Print(\"Entity too large\")\n\t\t\t\thttp.Error(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tmetadata := MetadataForRequest(contentType, s.randomTokenLength, r)\n\n\t\t\tbuffer := &bytes.Buffer{}\n\t\t\tif err := json.NewEncoder(buffer).Encode(metadata); err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, errors.New(\"Could not encode metadata\").Error(), 500)\n\n\t\t\t\tcleanTmpFile(file)\n\t\t\t\treturn\n\t\t\t} else if err := s.storage.Put(token, fmt.Sprintf(\"%s.metadata\", filename), buffer, \"text/json\", uint64(buffer.Len())); err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, errors.New(\"Could not save metadata\").Error(), 500)\n\n\t\t\t\tcleanTmpFile(file)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tlog.Printf(\"Uploading %s %s %d %s\", token, filename, contentLength, contentType)\n\n\t\t\tif err = s.storage.Put(token, filename, reader, contentType, uint64(contentLength)); err != nil {\n\t\t\t\tlog.Printf(\"Backend storage error: %s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\n\t\t\t}\n\n\t\t\tfilename = url.PathEscape(filename)\n\t\t\trelativeURL, _ := url.Parse(path.Join(s.proxyPath, token, filename))\n\t\t\tfmt.Fprintln(w, getURL(r, s.proxyPort).ResolveReference(relativeURL).String())\n\n\t\t\tcleanTmpFile(file)\n\t\t}\n\t}\n}\n\nfunc cleanTmpFile(f *os.File) {\n\tif f != nil {\n\t\terr := f.Close()\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Error closing tmpfile: %s (%s)\", err, f.Name())\n\t\t}\n\n\t\terr = os.Remove(f.Name())\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Error removing tmpfile: %s (%s)\", err, f.Name())\n\t\t}\n\t}\n}\n\ntype Metadata struct {\n\t// ContentType is the original uploading content type\n\tContentType string\n\t// Secret as knowledge to delete file\n\t// Secret string\n\t// Downloads is the actual number of downloads\n\tDownloads int\n\t// MaxDownloads contains the maximum numbers of downloads\n\tMaxDownloads int\n\t// MaxDate contains the max age of the file\n\tMaxDate time.Time\n\t// DeletionToken contains the token to match against for deletion\n\tDeletionToken string\n}\n\nfunc MetadataForRequest(contentType string, randomTokenLength int64, r *http.Request) Metadata {\n\tmetadata := Metadata{\n\t\tContentType:   strings.ToLower(contentType),\n\t\tMaxDate:       time.Time{},\n\t\tDownloads:     0,\n\t\tMaxDownloads:  -1,\n\t\tDeletionToken: Encode(INIT_SEED, randomTokenLength) + Encode(INIT_SEED, randomTokenLength),\n\t}\n\n\tif v := r.Header.Get(\"Max-Downloads\"); v == \"\" {\n\t} else if v, err := strconv.Atoi(v); err != nil {\n\t} else {\n\t\tmetadata.MaxDownloads = v\n\t}\n\n\tif v := r.Header.Get(\"Max-Days\"); v == \"\" {\n\t} else if v, err := strconv.Atoi(v); err != nil {\n\t} else {\n\t\tmetadata.MaxDate = time.Now().Add(time.Hour * 24 * time.Duration(v))\n\t}\n\n\treturn metadata\n}\n\nfunc (s *Server) putHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\tfilename := sanitize(vars[\"filename\"])\n\n\tcontentLength := r.ContentLength\n\n\tvar reader io.Reader\n\n\treader = r.Body\n\n\tdefer r.Body.Close()\n\n\tif contentLength == -1 {\n\t\t// queue file to disk, because s3 needs content length\n\t\tvar err error\n\t\tvar f io.Reader\n\n\t\tf = reader\n\n\t\tvar b bytes.Buffer\n\n\t\tn, err := io.CopyN(&b, f, _24K+1)\n\t\tif err != nil && err != io.EOF {\n\t\t\tlog.Printf(\"Error putting new file: %s\", err.Error())\n\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\treturn\n\t\t}\n\n\t\tvar file *os.File\n\n\t\tif n > _24K {\n\t\t\tfile, err = ioutil.TempFile(s.tempPath, \"transfer-\")\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tdefer cleanTmpFile(file)\n\n\t\t\tn, err = io.Copy(file, io.MultiReader(&b, f))\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\treader, err = os.Open(file.Name())\n\t\t} else {\n\t\t\treader = bytes.NewReader(b.Bytes())\n\t\t}\n\n\t\tcontentLength = n\n\t}\n\n\tif s.maxUploadSize > 0 && contentLength > s.maxUploadSize {\n\t\tlog.Print(\"Entity too large\")\n\t\thttp.Error(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\treturn\n\t}\n\n\tif contentLength == 0 {\n\t\tlog.Print(\"Empty content-length\")\n\t\thttp.Error(w, errors.New(\"Could not upload empty file\").Error(), 400)\n\t\treturn\n\t}\n\n\tcontentType := r.Header.Get(\"Content-Type\")\n\n\tif contentType == \"\" {\n\t\tcontentType = mime.TypeByExtension(filepath.Ext(vars[\"filename\"]))\n\t}\n\n\ttoken := Encode(INIT_SEED, s.randomTokenLength)\n\n\tmetadata := MetadataForRequest(contentType, s.randomTokenLength, r)\n\n\tbuffer := &bytes.Buffer{}\n\tif err := json.NewEncoder(buffer).Encode(metadata); err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, errors.New(\"Could not encode metadata\").Error(), 500)\n\t\treturn\n\t} else if err := s.storage.Put(token, fmt.Sprintf(\"%s.metadata\", filename), buffer, \"text/json\", uint64(buffer.Len())); err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, errors.New(\"Could not save metadata\").Error(), 500)\n\t\treturn\n\t}\n\n\tlog.Printf(\"Uploading %s %s %d %s\", token, filename, contentLength, contentType)\n\n\tvar err error\n\n\tif err = s.storage.Put(token, filename, reader, contentType, uint64(contentLength)); err != nil {\n\t\tlog.Printf(\"Error putting new file: %s\", err.Error())\n\t\thttp.Error(w, errors.New(\"Could not save file\").Error(), 500)\n\t\treturn\n\t}\n\n\t// w.Statuscode = 200\n\n\tw.Header().Set(\"Content-Type\", \"text/plain\")\n\n\tfilename = url.PathEscape(filename)\n\trelativeURL, _ := url.Parse(path.Join(s.proxyPath, token, filename))\n\tdeleteURL, _ := url.Parse(path.Join(s.proxyPath, token, filename, metadata.DeletionToken))\n\n\tw.Header().Set(\"X-Url-Delete\", resolveURL(r, deleteURL, s.proxyPort))\n\n\tfmt.Fprint(w, resolveURL(r, relativeURL, s.proxyPort))\n}\n\nfunc resolveURL(r *http.Request, u *url.URL, proxyPort string) string {\n\tr.URL.Path = \"\"\n\n\treturn getURL(r, proxyPort).ResolveReference(u).String()\n}\n\nfunc resolveKey(key, proxyPath string) string {\n\tif strings.HasPrefix(key, \"/\") {\n\t\tkey = key[1:]\n\t}\n\n\tif strings.HasPrefix(key, proxyPath) {\n\t\tkey = key[len(proxyPath):]\n\t}\n\n\tkey = strings.Replace(key, \"\\\\\", \"/\", -1)\n\n\treturn key\n}\n\nfunc resolveWebAddress(r *http.Request, proxyPath string, proxyPort string) string {\n\turl := getURL(r, proxyPort)\n\n\tvar webAddress string\n\n\tif len(proxyPath) == 0 {\n\t\twebAddress = fmt.Sprintf(\"%s://%s/\",\n\t\t\turl.ResolveReference(url).Scheme,\n\t\t\turl.ResolveReference(url).Host)\n\t} else {\n\t\twebAddress = fmt.Sprintf(\"%s://%s/%s\",\n\t\t\turl.ResolveReference(url).Scheme,\n\t\t\turl.ResolveReference(url).Host,\n\t\t\tproxyPath)\n\t}\n\n\treturn webAddress\n}\n\n// Similar to the logic found here:\n// https://github.com/golang/go/blob/release-branch.go1.14/src/net/http/clone.go#L22-L33\nfunc cloneURL(u *url.URL) *url.URL {\n\tc := &url.URL{}\n\t*c = *u\n\n\tif u.User != nil {\n\t\tc.User = &url.Userinfo{}\n\t\t*c.User = *u.User\n\t}\n\n\treturn c\n}\n\nfunc getURL(r *http.Request, proxyPort string) *url.URL {\n\tu := cloneURL(r.URL)\n\n\tif r.TLS != nil {\n\t\tu.Scheme = \"https\"\n\t} else if proto := r.Header.Get(\"X-Forwarded-Proto\"); proto != \"\" {\n\t\tu.Scheme = proto\n\t} else {\n\t\tu.Scheme = \"http\"\n\t}\n\n\tif u.Host == \"\" {\n\t\thost, port, err := net.SplitHostPort(r.Host)\n\t\tif err != nil {\n\t\t\thost = r.Host\n\t\t\tport = \"\"\n\t\t}\n\t\tif len(proxyPort) != 0 {\n\t\t\tport = proxyPort\n\t\t}\n\t\tif len(port) == 0 {\n\t\t\tu.Host = host\n\t\t} else {\n\t\t\tif port == \"80\" && u.Scheme == \"http\" {\n\t\t\t\tu.Host = host\n\t\t\t} else if port == \"443\" && u.Scheme == \"https\" {\n\t\t\t\tu.Host = host\n\t\t\t} else {\n\t\t\t\tu.Host = net.JoinHostPort(host, port)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn u\n}\n\nfunc (metadata Metadata) remainingLimitHeaderValues() (remainingDownloads, remainingDays string) {\n\tif metadata.MaxDate.IsZero() {\n\t\tremainingDays = \"n/a\"\n\t} else {\n\t\ttimeDifference := metadata.MaxDate.Sub(time.Now())\n\t\tremainingDays = strconv.Itoa(int(timeDifference.Hours()/24) + 1)\n\t}\n\n\tif metadata.MaxDownloads == -1 {\n\t\tremainingDownloads = \"n/a\"\n\t} else {\n\t\tremainingDownloads = strconv.Itoa(metadata.MaxDownloads - metadata.Downloads)\n\t}\n\n\treturn remainingDownloads, remainingDays\n}\n\nfunc (s *Server) Lock(token, filename string) error {\n\tkey := path.Join(token, filename)\n\n\tif _, ok := s.locks[key]; !ok {\n\t\ts.locks[key] = &sync.Mutex{}\n\t}\n\n\ts.locks[key].Lock()\n\n\treturn nil\n}\n\nfunc (s *Server) Unlock(token, filename string) error {\n\tkey := path.Join(token, filename)\n\ts.locks[key].Unlock()\n\n\treturn nil\n}\n\nfunc (s *Server) CheckMetadata(token, filename string, increaseDownload bool) (Metadata, error) {\n\ts.Lock(token, filename)\n\tdefer s.Unlock(token, filename)\n\n\tvar metadata Metadata\n\n\tr, _, err := s.storage.Get(token, fmt.Sprintf(\"%s.metadata\", filename))\n\tif err != nil {\n\t\treturn metadata, err\n\t}\n\n\tdefer r.Close()\n\n\tif err := json.NewDecoder(r).Decode(&metadata); err != nil {\n\t\treturn metadata, err\n\t} else if metadata.MaxDownloads != -1 && metadata.Downloads >= metadata.MaxDownloads {\n\t\treturn metadata, errors.New(\"MaxDownloads expired.\")\n\t} else if !metadata.MaxDate.IsZero() && time.Now().After(metadata.MaxDate) {\n\t\treturn metadata, errors.New(\"MaxDate expired.\")\n\t} else if metadata.MaxDownloads != -1 && increaseDownload {\n\t\t// todo(nl5887): mutex?\n\n\t\t// update number of downloads\n\t\tmetadata.Downloads++\n\n\t\tbuffer := &bytes.Buffer{}\n\t\tif err := json.NewEncoder(buffer).Encode(metadata); err != nil {\n\t\t\treturn metadata, errors.New(\"Could not encode metadata\")\n\t\t} else if err := s.storage.Put(token, fmt.Sprintf(\"%s.metadata\", filename), buffer, \"text/json\", uint64(buffer.Len())); err != nil {\n\t\t\treturn metadata, errors.New(\"Could not save metadata\")\n\t\t}\n\t}\n\n\treturn metadata, nil\n}\n\nfunc (s *Server) CheckDeletionToken(deletionToken, token, filename string) error {\n\ts.Lock(token, filename)\n\tdefer s.Unlock(token, filename)\n\n\tvar metadata Metadata\n\n\tr, _, err := s.storage.Get(token, fmt.Sprintf(\"%s.metadata\", filename))\n\tif s.storage.IsNotExist(err) {\n\t\treturn nil\n\t} else if err != nil {\n\t\treturn err\n\t}\n\n\tdefer r.Close()\n\n\tif err := json.NewDecoder(r).Decode(&metadata); err != nil {\n\t\treturn err\n\t} else if metadata.DeletionToken != deletionToken {\n\t\treturn errors.New(\"Deletion token doesn't match.\")\n\t}\n\n\treturn nil\n}\n\nfunc (s *Server) purgeHandler() {\n\tticker := time.NewTicker(s.purgeInterval)\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ticker.C:\n\t\t\t\terr := s.storage.Purge(s.purgeDays)\n\t\t\t\tlog.Printf(\"error cleaning up expired files: %v\", err)\n\t\t\t}\n\t\t}\n\t}()\n}\n\nfunc (s *Server) deleteHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\ttoken := vars[\"token\"]\n\tfilename := vars[\"filename\"]\n\tdeletionToken := vars[\"deletionToken\"]\n\n\tif err := s.CheckDeletionToken(deletionToken, token, filename); err != nil {\n\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t}\n\n\terr := s.storage.Delete(token, filename)\n\tif s.storage.IsNotExist(err) {\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Could not delete file.\", 500)\n\t\treturn\n\t}\n}\n\nfunc (s *Server) zipHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\tfiles := vars[\"files\"]\n\n\tzipfilename := fmt.Sprintf(\"transfersh-%d.zip\", uint16(time.Now().UnixNano()))\n\n\tw.Header().Set(\"Content-Type\", \"application/zip\")\n\tw.Header().Set(\"Content-Disposition\", fmt.Sprintf(\"attachment; filename=\\\"%s\\\"\", zipfilename))\n\tw.Header().Set(\"Connection\", \"close\")\n\n\tzw := zip.NewWriter(w)\n\n\tfor _, key := range strings.Split(files, \",\") {\n\t\tkey = resolveKey(key, s.proxyPath)\n\n\t\ttoken := strings.Split(key, \"/\")[0]\n\t\tfilename := sanitize(strings.Split(key, \"/\")[1])\n\n\t\tif _, err := s.CheckMetadata(token, filename, true); err != nil {\n\t\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\t\tcontinue\n\t\t}\n\n\t\treader, _, err := s.storage.Get(token, filename)\n\n\t\tif err != nil {\n\t\t\tif s.storage.IsNotExist(err) {\n\t\t\t\thttp.Error(w, \"File not found\", 404)\n\t\t\t\treturn\n\t\t\t} else {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, \"Could not retrieve file.\", 500)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tdefer reader.Close()\n\n\t\theader := &zip.FileHeader{\n\t\t\tName:         strings.Split(key, \"/\")[1],\n\t\t\tMethod:       zip.Store,\n\t\t\tModifiedTime: uint16(time.Now().UnixNano()),\n\t\t\tModifiedDate: uint16(time.Now().UnixNano()),\n\t\t}\n\n\t\tfw, err := zw.CreateHeader(header)\n\n\t\tif err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\n\t\tif _, err = io.Copy(fw, reader); err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\t}\n\n\tif err := zw.Close(); err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\treturn\n\t}\n}\n\nfunc (s *Server) tarGzHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\tfiles := vars[\"files\"]\n\n\ttarfilename := fmt.Sprintf(\"transfersh-%d.tar.gz\", uint16(time.Now().UnixNano()))\n\n\tw.Header().Set(\"Content-Type\", \"application/x-gzip\")\n\tw.Header().Set(\"Content-Disposition\", fmt.Sprintf(\"attachment; filename=\\\"%s\\\"\", tarfilename))\n\tw.Header().Set(\"Connection\", \"close\")\n\n\tos := gzip.NewWriter(w)\n\tdefer os.Close()\n\n\tzw := tar.NewWriter(os)\n\tdefer zw.Close()\n\n\tfor _, key := range strings.Split(files, \",\") {\n\t\tkey = resolveKey(key, s.proxyPath)\n\n\t\ttoken := strings.Split(key, \"/\")[0]\n\t\tfilename := sanitize(strings.Split(key, \"/\")[1])\n\n\t\tif _, err := s.CheckMetadata(token, filename, true); err != nil {\n\t\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\t\tcontinue\n\t\t}\n\n\t\treader, contentLength, err := s.storage.Get(token, filename)\n\t\tif err != nil {\n\t\t\tif s.storage.IsNotExist(err) {\n\t\t\t\thttp.Error(w, \"File not found\", 404)\n\t\t\t\treturn\n\t\t\t} else {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, \"Could not retrieve file.\", 500)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tdefer reader.Close()\n\n\t\theader := &tar.Header{\n\t\t\tName: strings.Split(key, \"/\")[1],\n\t\t\tSize: int64(contentLength),\n\t\t}\n\n\t\terr = zw.WriteHeader(header)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\n\t\tif _, err = io.Copy(zw, reader); err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (s *Server) tarHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\tfiles := vars[\"files\"]\n\n\ttarfilename := fmt.Sprintf(\"transfersh-%d.tar\", uint16(time.Now().UnixNano()))\n\n\tw.Header().Set(\"Content-Type\", \"application/x-tar\")\n\tw.Header().Set(\"Content-Disposition\", fmt.Sprintf(\"attachment; filename=\\\"%s\\\"\", tarfilename))\n\tw.Header().Set(\"Connection\", \"close\")\n\n\tzw := tar.NewWriter(w)\n\tdefer zw.Close()\n\n\tfor _, key := range strings.Split(files, \",\") {\n\t\tkey = resolveKey(key, s.proxyPath)\n\n\t\ttoken := strings.Split(key, \"/\")[0]\n\t\tfilename := strings.Split(key, \"/\")[1]\n\n\t\tif _, err := s.CheckMetadata(token, filename, true); err != nil {\n\t\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\t\tcontinue\n\t\t}\n\n\t\treader, contentLength, err := s.storage.Get(token, filename)\n\t\tif err != nil {\n\t\t\tif s.storage.IsNotExist(err) {\n\t\t\t\thttp.Error(w, \"File not found\", 404)\n\t\t\t\treturn\n\t\t\t} else {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, \"Could not retrieve file.\", 500)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tdefer reader.Close()\n\n\t\theader := &tar.Header{\n\t\t\tName: strings.Split(key, \"/\")[1],\n\t\t\tSize: int64(contentLength),\n\t\t}\n\n\t\terr = zw.WriteHeader(header)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\n\t\tif _, err = io.Copy(zw, reader); err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (s *Server) headHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\ttoken := vars[\"token\"]\n\tfilename := vars[\"filename\"]\n\n\tmetadata, err := s.CheckMetadata(token, filename, false)\n\n\tif err != nil {\n\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t}\n\n\tcontentType := metadata.ContentType\n\tcontentLength, err := s.storage.Head(token, filename)\n\tif s.storage.IsNotExist(err) {\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Could not retrieve file.\", 500)\n\t\treturn\n\t}\n\n\tremainingDownloads, remainingDays := metadata.remainingLimitHeaderValues()\n\n\tw.Header().Set(\"Content-Type\", contentType)\n\tw.Header().Set(\"Content-Length\", strconv.FormatUint(contentLength, 10))\n\tw.Header().Set(\"Connection\", \"close\")\n\tw.Header().Set(\"X-Remaining-Downloads\", remainingDownloads)\n\tw.Header().Set(\"X-Remaining-Days\", remainingDays)\n}\n\nfunc (s *Server) getHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\taction := vars[\"action\"]\n\ttoken := vars[\"token\"]\n\tfilename := vars[\"filename\"]\n\n\tmetadata, err := s.CheckMetadata(token, filename, true)\n\n\tif err != nil {\n\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t}\n\n\tcontentType := metadata.ContentType\n\treader, contentLength, err := s.storage.Get(token, filename)\n\tif s.storage.IsNotExist(err) {\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Could not retrieve file.\", 500)\n\t\treturn\n\t}\n\n\tdefer reader.Close()\n\n\tvar disposition string\n\n\tif action == \"inline\" {\n\t\tdisposition = \"inline\"\n\t} else {\n\t\tdisposition = \"attachment\"\n\t}\n\n\tremainingDownloads, remainingDays := metadata.remainingLimitHeaderValues()\n\n\tw.Header().Set(\"Content-Type\", contentType)\n\tw.Header().Set(\"Content-Length\", strconv.FormatUint(contentLength, 10))\n\tw.Header().Set(\"Content-Disposition\", fmt.Sprintf(\"%s; filename=\\\"%s\\\"\", disposition, filename))\n\tw.Header().Set(\"Connection\", \"keep-alive\")\n\tw.Header().Set(\"X-Remaining-Downloads\", remainingDownloads)\n\tw.Header().Set(\"X-Remaining-Days\", remainingDays)\n\n\tif disposition == \"inline\" && strings.Contains(contentType, \"html\") {\n\t\treader = ioutil.NopCloser(bluemonday.UGCPolicy().SanitizeReader(reader))\n\t}\n\n\tif w.Header().Get(\"Range\") == \"\" {\n\t\tif _, err = io.Copy(w, reader); err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Error occurred copying to output stream\", 500)\n\t\t\treturn\n\t\t}\n\n\t\treturn\n\t}\n\n\tfile, err := ioutil.TempFile(s.tempPath, \"range-\")\n\tif err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Error occurred copying to output stream\", 500)\n\t\treturn\n\t}\n\n\tdefer cleanTmpFile(file)\n\n\ttee := io.TeeReader(reader, file)\n\tfor {\n\t\tb := make([]byte, _5M)\n\t\t_, err = tee.Read(b)\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\n\t\tif err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Error occurred copying to output stream\", 500)\n\t\t\treturn\n\t\t}\n\t}\n\n\thttp.ServeContent(w, r, filename, time.Now(), file)\n}\n\nfunc (s *Server) RedirectHandler(h http.Handler) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tif !s.forceHTTPs {\n\t\t\t// we don't want to enforce https\n\t\t} else if r.URL.Path == \"/health.html\" {\n\t\t\t// health check url won't redirect\n\t\t} else if strings.HasSuffix(ipAddrFromRemoteAddr(r.Host), \".onion\") {\n\t\t\t// .onion addresses cannot get a valid certificate, so don't redirect\n\t\t} else if r.Header.Get(\"X-Forwarded-Proto\") == \"https\" {\n\t\t} else if r.URL.Scheme == \"https\" {\n\t\t} else {\n\t\t\tu := getURL(r, s.proxyPort)\n\t\t\tu.Scheme = \"https\"\n\n\t\t\thttp.Redirect(w, r, u.String(), http.StatusPermanentRedirect)\n\t\t\treturn\n\t\t}\n\n\t\th.ServeHTTP(w, r)\n\t}\n}\n\n// Create a log handler for every request it receives.\nfunc LoveHandler(h http.Handler) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"x-made-with\", \"<3 by DutchCoders\")\n\t\tw.Header().Set(\"x-served-by\", \"Proudly served by DutchCoders\")\n\t\tw.Header().Set(\"Server\", \"Transfer.sh HTTP Server 1.0\")\n\t\th.ServeHTTP(w, r)\n\t}\n}\n\nfunc IPFilterHandler(h http.Handler, ipFilterOptions *IPFilterOptions) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tif ipFilterOptions == nil {\n\t\t\th.ServeHTTP(w, r)\n\t\t} else {\n\t\t\tWrapIPFilter(h, *ipFilterOptions).ServeHTTP(w, r)\n\t\t}\n\t\treturn\n\t}\n}\n\nfunc (s *Server) BasicAuthHandler(h http.Handler) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tif s.AuthUser == \"\" || s.AuthPass == \"\" {\n\t\t\th.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\n\t\tw.Header().Set(\"WWW-Authenticate\", \"Basic realm=\\\"Restricted\\\"\")\n\n\t\tusername, password, authOK := r.BasicAuth()\n\t\tif authOK == false {\n\t\t\thttp.Error(w, \"Not authorized\", 401)\n\t\t\treturn\n\t\t}\n\n\t\tif username != s.AuthUser || password != s.AuthPass {\n\t\t\thttp.Error(w, \"Not authorized\", 401)\n\t\t\treturn\n\t\t}\n\n\t\th.ServeHTTP(w, r)\n\t}\n}\n"], "fixing_code": ["package cmd\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\n\t\"github.com/dutchcoders/transfer.sh/server\"\n\t\"github.com/fatih/color\"\n\t\"github.com/urfave/cli\"\n\t\"google.golang.org/api/googleapi\"\n)\n\nvar Version = \"1.2.4\"\nvar helpTemplate = `NAME:\n{{.Name}} - {{.Usage}}\n\nDESCRIPTION:\n{{.Description}}\n\nUSAGE:\n{{.Name}} {{if .Flags}}[flags] {{end}}command{{if .Flags}}{{end}} [arguments...]\n\nCOMMANDS:\n{{range .Commands}}{{join .Names \", \"}}{{ \"\\t\" }}{{.Usage}}\n{{end}}{{if .Flags}}\nFLAGS:\n{{range .Flags}}{{.}}\n{{end}}{{end}}\nVERSION:\n` + Version +\n\t`{{ \"\\n\"}}`\n\nvar globalFlags = []cli.Flag{\n\tcli.StringFlag{\n\t\tName:   \"listener\",\n\t\tUsage:  \"127.0.0.1:8080\",\n\t\tValue:  \"127.0.0.1:8080\",\n\t\tEnvVar: \"LISTENER\",\n\t},\n\t// redirect to https?\n\t// hostnames\n\tcli.StringFlag{\n\t\tName:   \"profile-listener\",\n\t\tUsage:  \"127.0.0.1:6060\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"PROFILE_LISTENER\",\n\t},\n\tcli.BoolFlag{\n\t\tName:   \"force-https\",\n\t\tUsage:  \"\",\n\t\tEnvVar: \"FORCE_HTTPS\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"tls-listener\",\n\t\tUsage:  \"127.0.0.1:8443\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"TLS_LISTENER\",\n\t},\n\tcli.BoolFlag{\n\t\tName:   \"tls-listener-only\",\n\t\tUsage:  \"\",\n\t\tEnvVar: \"TLS_LISTENER_ONLY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"tls-cert-file\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"TLS_CERT_FILE\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"tls-private-key\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"TLS_PRIVATE_KEY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"temp-path\",\n\t\tUsage:  \"path to temp files\",\n\t\tValue:  os.TempDir(),\n\t\tEnvVar: \"TEMP_PATH\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"web-path\",\n\t\tUsage:  \"path to static web files\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"WEB_PATH\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"proxy-path\",\n\t\tUsage:  \"path prefix when service is run behind a proxy\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"PROXY_PATH\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"proxy-port\",\n\t\tUsage:  \"port of the proxy when the service is run behind a proxy\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"PROXY_PORT\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"ga-key\",\n\t\tUsage:  \"key for google analytics (front end)\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"GA_KEY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"uservoice-key\",\n\t\tUsage:  \"key for user voice (front end)\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"USERVOICE_KEY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"provider\",\n\t\tUsage:  \"s3|gdrive|local\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"PROVIDER\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"s3-endpoint\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"S3_ENDPOINT\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"s3-region\",\n\t\tUsage:  \"\",\n\t\tValue:  \"eu-west-1\",\n\t\tEnvVar: \"S3_REGION\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"aws-access-key\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"AWS_ACCESS_KEY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"aws-secret-key\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"AWS_SECRET_KEY\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"bucket\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"BUCKET\",\n\t},\n\tcli.BoolFlag{\n\t\tName:   \"s3-no-multipart\",\n\t\tUsage:  \"Disables S3 Multipart Puts\",\n\t\tEnvVar: \"S3_NO_MULTIPART\",\n\t},\n\tcli.BoolFlag{\n\t\tName:   \"s3-path-style\",\n\t\tUsage:  \"Forces path style URLs, required for Minio.\",\n\t\tEnvVar: \"S3_PATH_STYLE\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"gdrive-client-json-filepath\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"GDRIVE_CLIENT_JSON_FILEPATH\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"gdrive-local-config-path\",\n\t\tUsage:  \"\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"GDRIVE_LOCAL_CONFIG_PATH\",\n\t},\n\tcli.IntFlag{\n\t\tName:   \"gdrive-chunk-size\",\n\t\tUsage:  \"\",\n\t\tValue:  googleapi.DefaultUploadChunkSize / 1024 / 1024,\n\t\tEnvVar: \"GDRIVE_CHUNK_SIZE\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"storj-access\",\n\t\tUsage:  \"Access for the project\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"STORJ_ACCESS\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"storj-bucket\",\n\t\tUsage:  \"Bucket to use within the project\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"STORJ_BUCKET\",\n\t},\n\tcli.IntFlag{\n\t\tName:   \"rate-limit\",\n\t\tUsage:  \"requests per minute\",\n\t\tValue:  0,\n\t\tEnvVar: \"RATE_LIMIT\",\n\t},\n\tcli.IntFlag{\n\t\tName:   \"purge-days\",\n\t\tUsage:  \"number of days after uploads are purged automatically\",\n\t\tValue:  0,\n\t\tEnvVar: \"PURGE_DAYS\",\n\t},\n\tcli.IntFlag{\n\t\tName:   \"purge-interval\",\n\t\tUsage:  \"interval in hours to run the automatic purge for\",\n\t\tValue:  0,\n\t\tEnvVar: \"PURGE_INTERVAL\",\n\t},\n\tcli.Int64Flag{\n\t\tName:   \"max-upload-size\",\n\t\tUsage:  \"max limit for upload, in kilobytes\",\n\t\tValue:  0,\n\t\tEnvVar: \"MAX_UPLOAD_SIZE\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"lets-encrypt-hosts\",\n\t\tUsage:  \"host1, host2\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"HOSTS\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"log\",\n\t\tUsage:  \"/var/log/transfersh.log\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"LOG\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"basedir\",\n\t\tUsage:  \"path to storage\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"BASEDIR\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"clamav-host\",\n\t\tUsage:  \"clamav-host\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"CLAMAV_HOST\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"virustotal-key\",\n\t\tUsage:  \"virustotal-key\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"VIRUSTOTAL_KEY\",\n\t},\n\tcli.BoolFlag{\n\t\tName:   \"profiler\",\n\t\tUsage:  \"enable profiling\",\n\t\tEnvVar: \"PROFILER\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"http-auth-user\",\n\t\tUsage:  \"user for http basic auth\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"HTTP_AUTH_USER\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"http-auth-pass\",\n\t\tUsage:  \"pass for http basic auth\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"HTTP_AUTH_PASS\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"ip-whitelist\",\n\t\tUsage:  \"comma separated list of ips allowed to connect to the service\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"IP_WHITELIST\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"ip-blacklist\",\n\t\tUsage:  \"comma separated list of ips not allowed to connect to the service\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"IP_BLACKLIST\",\n\t},\n\tcli.StringFlag{\n\t\tName:   \"cors-domains\",\n\t\tUsage:  \"comma separated list of domains allowed for CORS requests\",\n\t\tValue:  \"\",\n\t\tEnvVar: \"CORS_DOMAINS\",\n\t},\n\tcli.Int64Flag{\n\t\tName:   \"random-token-length\",\n\t\tUsage:  \"\",\n\t\tValue:  6,\n\t\tEnvVar: \"RANDOM_TOKEN_LENGTH\",\n\t},\n}\n\ntype Cmd struct {\n\t*cli.App\n}\n\nfunc VersionAction(c *cli.Context) {\n\tfmt.Println(color.YellowString(fmt.Sprintf(\"transfer.sh %s: Easy file sharing from the command line\", Version)))\n}\n\nfunc New() *Cmd {\n\tlogger := log.New(os.Stdout, \"[transfer.sh]\", log.LstdFlags)\n\n\tapp := cli.NewApp()\n\tapp.Name = \"transfer.sh\"\n\tapp.Author = \"\"\n\tapp.Usage = \"transfer.sh\"\n\tapp.Description = `Easy file sharing from the command line`\n\tapp.Version = Version\n\tapp.Flags = globalFlags\n\tapp.CustomAppHelpTemplate = helpTemplate\n\tapp.Commands = []cli.Command{\n\t\t{\n\t\t\tName:   \"version\",\n\t\t\tAction: VersionAction,\n\t\t},\n\t}\n\n\tapp.Before = func(c *cli.Context) error {\n\t\treturn nil\n\t}\n\n\tapp.Action = func(c *cli.Context) {\n\t\toptions := []server.OptionFn{}\n\t\tif v := c.String(\"listener\"); v != \"\" {\n\t\t\toptions = append(options, server.Listener(v))\n\t\t}\n\n\t\tif v := c.String(\"cors-domains\"); v != \"\" {\n\t\t\toptions = append(options, server.CorsDomains(v))\n\t\t}\n\n\t\tif v := c.String(\"tls-listener\"); v == \"\" {\n\t\t} else if c.Bool(\"tls-listener-only\") {\n\t\t\toptions = append(options, server.TLSListener(v, true))\n\t\t} else {\n\t\t\toptions = append(options, server.TLSListener(v, false))\n\t\t}\n\n\t\tif v := c.String(\"profile-listener\"); v != \"\" {\n\t\t\toptions = append(options, server.ProfileListener(v))\n\t\t}\n\n\t\tif v := c.String(\"web-path\"); v != \"\" {\n\t\t\toptions = append(options, server.WebPath(v))\n\t\t}\n\n\t\tif v := c.String(\"proxy-path\"); v != \"\" {\n\t\t\toptions = append(options, server.ProxyPath(v))\n\t\t}\n\n\t\tif v := c.String(\"proxy-port\"); v != \"\" {\n\t\t\toptions = append(options, server.ProxyPort(v))\n\t\t}\n\n\t\tif v := c.String(\"ga-key\"); v != \"\" {\n\t\t\toptions = append(options, server.GoogleAnalytics(v))\n\t\t}\n\n\t\tif v := c.String(\"uservoice-key\"); v != \"\" {\n\t\t\toptions = append(options, server.UserVoice(v))\n\t\t}\n\n\t\tif v := c.String(\"temp-path\"); v != \"\" {\n\t\t\toptions = append(options, server.TempPath(v))\n\t\t}\n\n\t\tif v := c.String(\"log\"); v != \"\" {\n\t\t\toptions = append(options, server.LogFile(logger, v))\n\t\t} else {\n\t\t\toptions = append(options, server.Logger(logger))\n\t\t}\n\n\t\tif v := c.String(\"lets-encrypt-hosts\"); v != \"\" {\n\t\t\toptions = append(options, server.UseLetsEncrypt(strings.Split(v, \",\")))\n\t\t}\n\n\t\tif v := c.String(\"virustotal-key\"); v != \"\" {\n\t\t\toptions = append(options, server.VirustotalKey(v))\n\t\t}\n\n\t\tif v := c.String(\"clamav-host\"); v != \"\" {\n\t\t\toptions = append(options, server.ClamavHost(v))\n\t\t}\n\n\t\tif v := c.Int64(\"max-upload-size\"); v > 0 {\n\t\t\toptions = append(options, server.MaxUploadSize(v))\n\t\t}\n\n\t\tif v := c.Int(\"rate-limit\"); v > 0 {\n\t\t\toptions = append(options, server.RateLimit(v))\n\t\t}\n\n\t\tv := c.Int64(\"random-token-length\")\n\t\toptions = append(options, server.RandomTokenLength(v))\n\n\t\tpurgeDays := c.Int(\"purge-days\")\n\t\tpurgeInterval := c.Int(\"purge-interval\")\n\t\tif purgeDays > 0 && purgeInterval > 0 {\n\t\t\toptions = append(options, server.Purge(purgeDays, purgeInterval))\n\t\t}\n\n\t\tif cert := c.String(\"tls-cert-file\"); cert == \"\" {\n\t\t} else if pk := c.String(\"tls-private-key\"); pk == \"\" {\n\t\t} else {\n\t\t\toptions = append(options, server.TLSConfig(cert, pk))\n\t\t}\n\n\t\tif c.Bool(\"profiler\") {\n\t\t\toptions = append(options, server.EnableProfiler())\n\t\t}\n\n\t\tif c.Bool(\"force-https\") {\n\t\t\toptions = append(options, server.ForceHTTPs())\n\t\t}\n\n\t\tif httpAuthUser := c.String(\"http-auth-user\"); httpAuthUser == \"\" {\n\t\t} else if httpAuthPass := c.String(\"http-auth-pass\"); httpAuthPass == \"\" {\n\t\t} else {\n\t\t\toptions = append(options, server.HttpAuthCredentials(httpAuthUser, httpAuthPass))\n\t\t}\n\n\t\tapplyIPFilter := false\n\t\tipFilterOptions := server.IPFilterOptions{}\n\t\tif ipWhitelist := c.String(\"ip-whitelist\"); ipWhitelist != \"\" {\n\t\t\tapplyIPFilter = true\n\t\t\tipFilterOptions.AllowedIPs = strings.Split(ipWhitelist, \",\")\n\t\t\tipFilterOptions.BlockByDefault = true\n\t\t}\n\n\t\tif ipBlacklist := c.String(\"ip-blacklist\"); ipBlacklist != \"\" {\n\t\t\tapplyIPFilter = true\n\t\t\tipFilterOptions.BlockedIPs = strings.Split(ipBlacklist, \",\")\n\t\t}\n\n\t\tif applyIPFilter {\n\t\t\toptions = append(options, server.FilterOptions(ipFilterOptions))\n\t\t}\n\n\t\tswitch provider := c.String(\"provider\"); provider {\n\t\tcase \"s3\":\n\t\t\tif accessKey := c.String(\"aws-access-key\"); accessKey == \"\" {\n\t\t\t\tpanic(\"access-key not set.\")\n\t\t\t} else if secretKey := c.String(\"aws-secret-key\"); secretKey == \"\" {\n\t\t\t\tpanic(\"secret-key not set.\")\n\t\t\t} else if bucket := c.String(\"bucket\"); bucket == \"\" {\n\t\t\t\tpanic(\"bucket not set.\")\n\t\t\t} else if storage, err := server.NewS3Storage(accessKey, secretKey, bucket, purgeDays, c.String(\"s3-region\"), c.String(\"s3-endpoint\"), c.Bool(\"s3-no-multipart\"), c.Bool(\"s3-path-style\"), logger); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t} else {\n\t\t\t\toptions = append(options, server.UseStorage(storage))\n\t\t\t}\n\t\tcase \"gdrive\":\n\t\t\tchunkSize := c.Int(\"gdrive-chunk-size\")\n\n\t\t\tif clientJsonFilepath := c.String(\"gdrive-client-json-filepath\"); clientJsonFilepath == \"\" {\n\t\t\t\tpanic(\"client-json-filepath not set.\")\n\t\t\t} else if localConfigPath := c.String(\"gdrive-local-config-path\"); localConfigPath == \"\" {\n\t\t\t\tpanic(\"local-config-path not set.\")\n\t\t\t} else if basedir := c.String(\"basedir\"); basedir == \"\" {\n\t\t\t\tpanic(\"basedir not set.\")\n\t\t\t} else if storage, err := server.NewGDriveStorage(clientJsonFilepath, localConfigPath, basedir, chunkSize, logger); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t} else {\n\t\t\t\toptions = append(options, server.UseStorage(storage))\n\t\t\t}\n\t\tcase \"storj\":\n\t\t\tif access := c.String(\"storj-access\"); access == \"\" {\n\t\t\t\tpanic(\"storj-access not set.\")\n\t\t\t} else if bucket := c.String(\"storj-bucket\"); bucket == \"\" {\n\t\t\t\tpanic(\"storj-bucket not set.\")\n\t\t\t} else if storage, err := server.NewStorjStorage(access, bucket, purgeDays, logger); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t} else {\n\t\t\t\toptions = append(options, server.UseStorage(storage))\n\t\t\t}\n\t\tcase \"local\":\n\t\t\tif v := c.String(\"basedir\"); v == \"\" {\n\t\t\t\tpanic(\"basedir not set.\")\n\t\t\t} else if storage, err := server.NewLocalStorage(v, logger); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t} else {\n\t\t\t\toptions = append(options, server.UseStorage(storage))\n\t\t\t}\n\t\tdefault:\n\t\t\tpanic(\"Provider not set or invalid.\")\n\t\t}\n\n\t\tsrvr, err := server.New(\n\t\t\toptions...,\n\t\t)\n\n\t\tif err != nil {\n\t\t\tlogger.Println(color.RedString(\"Error starting server: %s\", err.Error()))\n\t\t\treturn\n\t\t}\n\n\t\tsrvr.Run()\n\t}\n\n\treturn &Cmd{\n\t\tApp: app,\n\t}\n}\n", "/*\nThe MIT License (MIT)\n\nCopyright (c) 2014-2017 DutchCoders [https://github.com/dutchcoders/]\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\npackage server\n\nimport (\n\t// _ \"transfer.sh/app/handlers\"\n\t// _ \"transfer.sh/app/utils\"\n\n\t\"archive/tar\"\n\t\"archive/zip\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\tblackfriday \"github.com/russross/blackfriday/v2\"\n\t\"html\"\n\thtml_template \"html/template\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"mime\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\ttext_template \"text/template\"\n\t\"time\"\n\n\t\"net\"\n\n\t\"encoding/base64\"\n\tweb \"github.com/dutchcoders/transfer.sh-web\"\n\t\"github.com/gorilla/mux\"\n\t\"github.com/microcosm-cc/bluemonday\"\n\t\"github.com/skip2/go-qrcode\"\n)\n\nconst getPathPart = \"get\"\n\nvar (\n\thtmlTemplates = initHTMLTemplates()\n\ttextTemplates = initTextTemplates()\n)\n\nfunc stripPrefix(path string) string {\n\treturn strings.Replace(path, web.Prefix+\"/\", \"\", -1)\n}\n\nfunc initTextTemplates() *text_template.Template {\n\ttemplateMap := text_template.FuncMap{\"format\": formatNumber}\n\n\t// Templates with functions available to them\n\tvar templates = text_template.New(\"\").Funcs(templateMap)\n\treturn templates\n}\n\nfunc initHTMLTemplates() *html_template.Template {\n\ttemplateMap := html_template.FuncMap{\"format\": formatNumber}\n\n\t// Templates with functions available to them\n\tvar templates = html_template.New(\"\").Funcs(templateMap)\n\n\treturn templates\n}\n\nfunc healthHandler(w http.ResponseWriter, r *http.Request) {\n\tfmt.Fprintf(w, \"Approaching Neutral Zone, all systems normal and functioning.\")\n}\n\nfunc canContainsXSS(contentType string) bool {\n\tswitch {\n\tcase strings.Contains(contentType, \"cache-manifest\"):\n\t\tfallthrough\n\tcase strings.Contains(contentType, \"html\"):\n\t\tfallthrough\n\tcase strings.Contains(contentType, \"rdf\"):\n\t\tfallthrough\n\tcase strings.Contains(contentType, \"vtt\"):\n\t\tfallthrough\n\tcase strings.Contains(contentType, \"xml\"):\n\t\tfallthrough\n\tcase strings.Contains(contentType, \"xsl\"):\n\t\treturn true\n\tcase strings.Contains(contentType, \"x-mixed-replace\"):\n\t\treturn true\n\t}\n\n\treturn false\n}\n\n/* The preview handler will show a preview of the content for browsers (accept type text/html), and referer is not transfer.sh */\nfunc (s *Server) previewHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\ttoken := vars[\"token\"]\n\tfilename := vars[\"filename\"]\n\n\tmetadata, err := s.CheckMetadata(token, filename, false)\n\n\tif err != nil {\n\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t}\n\n\tcontentType := metadata.ContentType\n\tcontentLength, err := s.storage.Head(token, filename)\n\tif err != nil {\n\t\thttp.Error(w, http.StatusText(404), 404)\n\t\treturn\n\t}\n\n\tvar templatePath string\n\tvar content html_template.HTML\n\n\tswitch {\n\tcase strings.HasPrefix(contentType, \"image/\"):\n\t\ttemplatePath = \"download.image.html\"\n\tcase strings.HasPrefix(contentType, \"video/\"):\n\t\ttemplatePath = \"download.video.html\"\n\tcase strings.HasPrefix(contentType, \"audio/\"):\n\t\ttemplatePath = \"download.audio.html\"\n\tcase strings.HasPrefix(contentType, \"text/\"):\n\t\ttemplatePath = \"download.markdown.html\"\n\n\t\tvar reader io.ReadCloser\n\t\tif reader, _, err = s.storage.Get(token, filename); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tvar data []byte\n\t\tdata = make([]byte, _5M)\n\t\tif _, err = reader.Read(data); err != io.EOF && err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tif strings.HasPrefix(contentType, \"text/x-markdown\") || strings.HasPrefix(contentType, \"text/markdown\") {\n\t\t\tunsafe := blackfriday.Run(data)\n\t\t\toutput := bluemonday.UGCPolicy().SanitizeBytes(unsafe)\n\t\t\tcontent = html_template.HTML(output)\n\t\t} else if strings.HasPrefix(contentType, \"text/plain\") {\n\t\t\tcontent = html_template.HTML(fmt.Sprintf(\"<pre>%s</pre>\", html.EscapeString(string(data))))\n\t\t} else {\n\t\t\ttemplatePath = \"download.sandbox.html\"\n\t\t}\n\n\tdefault:\n\t\ttemplatePath = \"download.html\"\n\t}\n\n\trelativeURL, _ := url.Parse(path.Join(s.proxyPath, token, filename))\n\tresolvedURL := resolveURL(r, relativeURL, s.proxyPort)\n\trelativeURLGet, _ := url.Parse(path.Join(s.proxyPath, getPathPart, token, filename))\n\tresolvedURLGet := resolveURL(r, relativeURLGet, s.proxyPort)\n\tvar png []byte\n\tpng, err = qrcode.Encode(resolvedURL, qrcode.High, 150)\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tqrCode := base64.StdEncoding.EncodeToString(png)\n\n\thostname := getURL(r, s.proxyPort).Host\n\twebAddress := resolveWebAddress(r, s.proxyPath, s.proxyPort)\n\n\tdata := struct {\n\t\tContentType    string\n\t\tContent        html_template.HTML\n\t\tFilename       string\n\t\tUrl            string\n\t\tUrlGet         string\n\t\tUrlRandomToken string\n\t\tHostname       string\n\t\tWebAddress     string\n\t\tContentLength  uint64\n\t\tGAKey          string\n\t\tUserVoiceKey   string\n\t\tQRCode         string\n\t}{\n\t\tcontentType,\n\t\tcontent,\n\t\tfilename,\n\t\tresolvedURL,\n\t\tresolvedURLGet,\n\t\ttoken,\n\t\thostname,\n\t\twebAddress,\n\t\tcontentLength,\n\t\ts.gaKey,\n\t\ts.userVoiceKey,\n\t\tqrCode,\n\t}\n\n\tif err := htmlTemplates.ExecuteTemplate(w, templatePath, data); err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n}\n\n// this handler will output html or text, depending on the\n// support of the client (Accept header).\n\nfunc (s *Server) viewHandler(w http.ResponseWriter, r *http.Request) {\n\t// vars := mux.Vars(r)\n\n\thostname := getURL(r, s.proxyPort).Host\n\twebAddress := resolveWebAddress(r, s.proxyPath, s.proxyPort)\n\n\tdata := struct {\n\t\tHostname     string\n\t\tWebAddress   string\n\t\tGAKey        string\n\t\tUserVoiceKey string\n\t}{\n\t\thostname,\n\t\twebAddress,\n\t\ts.gaKey,\n\t\ts.userVoiceKey,\n\t}\n\n\tif acceptsHTML(r.Header) {\n\t\tif err := htmlTemplates.ExecuteTemplate(w, \"index.html\", data); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t} else {\n\t\tif err := textTemplates.ExecuteTemplate(w, \"index.txt\", data); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (s *Server) notFoundHandler(w http.ResponseWriter, r *http.Request) {\n\thttp.Error(w, http.StatusText(404), 404)\n}\n\nfunc sanitize(fileName string) string {\n\treturn path.Clean(path.Base(fileName))\n}\n\nfunc (s *Server) postHandler(w http.ResponseWriter, r *http.Request) {\n\tif err := r.ParseMultipartForm(_24K); nil != err {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Error occurred copying to output stream\", 500)\n\t\treturn\n\t}\n\n\ttoken := Encode(INIT_SEED, s.randomTokenLength)\n\n\tw.Header().Set(\"Content-Type\", \"text/plain\")\n\n\tfor _, fheaders := range r.MultipartForm.File {\n\t\tfor _, fheader := range fheaders {\n\t\t\tfilename := sanitize(fheader.Filename)\n\t\t\tcontentType := mime.TypeByExtension(filepath.Ext(fheader.Filename))\n\n\t\t\tvar f io.Reader\n\t\t\tvar err error\n\n\t\t\tif f, err = fheader.Open(); err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tvar b bytes.Buffer\n\n\t\t\tn, err := io.CopyN(&b, f, _24K+1)\n\t\t\tif err != nil && err != io.EOF {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tvar file *os.File\n\t\t\tvar reader io.Reader\n\n\t\t\tif n > _24K {\n\t\t\t\tfile, err = ioutil.TempFile(s.tempPath, \"transfer-\")\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\tn, err = io.Copy(file, io.MultiReader(&b, f))\n\t\t\t\tif err != nil {\n\t\t\t\t\tcleanTmpFile(file)\n\n\t\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\treader, err = os.Open(file.Name())\n\t\t\t} else {\n\t\t\t\treader = bytes.NewReader(b.Bytes())\n\t\t\t}\n\n\t\t\tcontentLength := n\n\n\t\t\tif s.maxUploadSize > 0 && contentLength > s.maxUploadSize {\n\t\t\t\tlog.Print(\"Entity too large\")\n\t\t\t\thttp.Error(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tmetadata := MetadataForRequest(contentType, s.randomTokenLength, r)\n\n\t\t\tbuffer := &bytes.Buffer{}\n\t\t\tif err := json.NewEncoder(buffer).Encode(metadata); err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, errors.New(\"Could not encode metadata\").Error(), 500)\n\n\t\t\t\tcleanTmpFile(file)\n\t\t\t\treturn\n\t\t\t} else if err := s.storage.Put(token, fmt.Sprintf(\"%s.metadata\", filename), buffer, \"text/json\", uint64(buffer.Len())); err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, errors.New(\"Could not save metadata\").Error(), 500)\n\n\t\t\t\tcleanTmpFile(file)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tlog.Printf(\"Uploading %s %s %d %s\", token, filename, contentLength, contentType)\n\n\t\t\tif err = s.storage.Put(token, filename, reader, contentType, uint64(contentLength)); err != nil {\n\t\t\t\tlog.Printf(\"Backend storage error: %s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\n\t\t\t}\n\n\t\t\tfilename = url.PathEscape(filename)\n\t\t\trelativeURL, _ := url.Parse(path.Join(s.proxyPath, token, filename))\n\t\t\tfmt.Fprintln(w, getURL(r, s.proxyPort).ResolveReference(relativeURL).String())\n\n\t\t\tcleanTmpFile(file)\n\t\t}\n\t}\n}\n\nfunc cleanTmpFile(f *os.File) {\n\tif f != nil {\n\t\terr := f.Close()\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Error closing tmpfile: %s (%s)\", err, f.Name())\n\t\t}\n\n\t\terr = os.Remove(f.Name())\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Error removing tmpfile: %s (%s)\", err, f.Name())\n\t\t}\n\t}\n}\n\ntype Metadata struct {\n\t// ContentType is the original uploading content type\n\tContentType string\n\t// Secret as knowledge to delete file\n\t// Secret string\n\t// Downloads is the actual number of downloads\n\tDownloads int\n\t// MaxDownloads contains the maximum numbers of downloads\n\tMaxDownloads int\n\t// MaxDate contains the max age of the file\n\tMaxDate time.Time\n\t// DeletionToken contains the token to match against for deletion\n\tDeletionToken string\n}\n\nfunc MetadataForRequest(contentType string, randomTokenLength int64, r *http.Request) Metadata {\n\tmetadata := Metadata{\n\t\tContentType:   strings.ToLower(contentType),\n\t\tMaxDate:       time.Time{},\n\t\tDownloads:     0,\n\t\tMaxDownloads:  -1,\n\t\tDeletionToken: Encode(INIT_SEED, randomTokenLength) + Encode(INIT_SEED, randomTokenLength),\n\t}\n\n\tif v := r.Header.Get(\"Max-Downloads\"); v == \"\" {\n\t} else if v, err := strconv.Atoi(v); err != nil {\n\t} else {\n\t\tmetadata.MaxDownloads = v\n\t}\n\n\tif v := r.Header.Get(\"Max-Days\"); v == \"\" {\n\t} else if v, err := strconv.Atoi(v); err != nil {\n\t} else {\n\t\tmetadata.MaxDate = time.Now().Add(time.Hour * 24 * time.Duration(v))\n\t}\n\n\treturn metadata\n}\n\nfunc (s *Server) putHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\tfilename := sanitize(vars[\"filename\"])\n\n\tcontentLength := r.ContentLength\n\n\tvar reader io.Reader\n\n\treader = r.Body\n\n\tdefer r.Body.Close()\n\n\tif contentLength == -1 {\n\t\t// queue file to disk, because s3 needs content length\n\t\tvar err error\n\t\tvar f io.Reader\n\n\t\tf = reader\n\n\t\tvar b bytes.Buffer\n\n\t\tn, err := io.CopyN(&b, f, _24K+1)\n\t\tif err != nil && err != io.EOF {\n\t\t\tlog.Printf(\"Error putting new file: %s\", err.Error())\n\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\treturn\n\t\t}\n\n\t\tvar file *os.File\n\n\t\tif n > _24K {\n\t\t\tfile, err = ioutil.TempFile(s.tempPath, \"transfer-\")\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tdefer cleanTmpFile(file)\n\n\t\t\tn, err = io.Copy(file, io.MultiReader(&b, f))\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\treader, err = os.Open(file.Name())\n\t\t} else {\n\t\t\treader = bytes.NewReader(b.Bytes())\n\t\t}\n\n\t\tcontentLength = n\n\t}\n\n\tif s.maxUploadSize > 0 && contentLength > s.maxUploadSize {\n\t\tlog.Print(\"Entity too large\")\n\t\thttp.Error(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\treturn\n\t}\n\n\tif contentLength == 0 {\n\t\tlog.Print(\"Empty content-length\")\n\t\thttp.Error(w, errors.New(\"Could not upload empty file\").Error(), 400)\n\t\treturn\n\t}\n\n\tcontentType := mime.TypeByExtension(filepath.Ext(vars[\"filename\"]))\n\n\ttoken := Encode(INIT_SEED, s.randomTokenLength)\n\n\tmetadata := MetadataForRequest(contentType, s.randomTokenLength, r)\n\n\tbuffer := &bytes.Buffer{}\n\tif err := json.NewEncoder(buffer).Encode(metadata); err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, errors.New(\"Could not encode metadata\").Error(), 500)\n\t\treturn\n\t} else if err := s.storage.Put(token, fmt.Sprintf(\"%s.metadata\", filename), buffer, \"text/json\", uint64(buffer.Len())); err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, errors.New(\"Could not save metadata\").Error(), 500)\n\t\treturn\n\t}\n\n\tlog.Printf(\"Uploading %s %s %d %s\", token, filename, contentLength, contentType)\n\n\tvar err error\n\n\tif err = s.storage.Put(token, filename, reader, contentType, uint64(contentLength)); err != nil {\n\t\tlog.Printf(\"Error putting new file: %s\", err.Error())\n\t\thttp.Error(w, errors.New(\"Could not save file\").Error(), 500)\n\t\treturn\n\t}\n\n\t// w.Statuscode = 200\n\n\tw.Header().Set(\"Content-Type\", \"text/plain\")\n\n\tfilename = url.PathEscape(filename)\n\trelativeURL, _ := url.Parse(path.Join(s.proxyPath, token, filename))\n\tdeleteURL, _ := url.Parse(path.Join(s.proxyPath, token, filename, metadata.DeletionToken))\n\n\tw.Header().Set(\"X-Url-Delete\", resolveURL(r, deleteURL, s.proxyPort))\n\n\tfmt.Fprint(w, resolveURL(r, relativeURL, s.proxyPort))\n}\n\nfunc resolveURL(r *http.Request, u *url.URL, proxyPort string) string {\n\tr.URL.Path = \"\"\n\n\treturn getURL(r, proxyPort).ResolveReference(u).String()\n}\n\nfunc resolveKey(key, proxyPath string) string {\n\tif strings.HasPrefix(key, \"/\") {\n\t\tkey = key[1:]\n\t}\n\n\tif strings.HasPrefix(key, proxyPath) {\n\t\tkey = key[len(proxyPath):]\n\t}\n\n\tkey = strings.Replace(key, \"\\\\\", \"/\", -1)\n\n\treturn key\n}\n\nfunc resolveWebAddress(r *http.Request, proxyPath string, proxyPort string) string {\n\turl := getURL(r, proxyPort)\n\n\tvar webAddress string\n\n\tif len(proxyPath) == 0 {\n\t\twebAddress = fmt.Sprintf(\"%s://%s/\",\n\t\t\turl.ResolveReference(url).Scheme,\n\t\t\turl.ResolveReference(url).Host)\n\t} else {\n\t\twebAddress = fmt.Sprintf(\"%s://%s/%s\",\n\t\t\turl.ResolveReference(url).Scheme,\n\t\t\turl.ResolveReference(url).Host,\n\t\t\tproxyPath)\n\t}\n\n\treturn webAddress\n}\n\n// Similar to the logic found here:\n// https://github.com/golang/go/blob/release-branch.go1.14/src/net/http/clone.go#L22-L33\nfunc cloneURL(u *url.URL) *url.URL {\n\tc := &url.URL{}\n\t*c = *u\n\n\tif u.User != nil {\n\t\tc.User = &url.Userinfo{}\n\t\t*c.User = *u.User\n\t}\n\n\treturn c\n}\n\nfunc getURL(r *http.Request, proxyPort string) *url.URL {\n\tu := cloneURL(r.URL)\n\n\tif r.TLS != nil {\n\t\tu.Scheme = \"https\"\n\t} else if proto := r.Header.Get(\"X-Forwarded-Proto\"); proto != \"\" {\n\t\tu.Scheme = proto\n\t} else {\n\t\tu.Scheme = \"http\"\n\t}\n\n\tif u.Host == \"\" {\n\t\thost, port, err := net.SplitHostPort(r.Host)\n\t\tif err != nil {\n\t\t\thost = r.Host\n\t\t\tport = \"\"\n\t\t}\n\t\tif len(proxyPort) != 0 {\n\t\t\tport = proxyPort\n\t\t}\n\t\tif len(port) == 0 {\n\t\t\tu.Host = host\n\t\t} else {\n\t\t\tif port == \"80\" && u.Scheme == \"http\" {\n\t\t\t\tu.Host = host\n\t\t\t} else if port == \"443\" && u.Scheme == \"https\" {\n\t\t\t\tu.Host = host\n\t\t\t} else {\n\t\t\t\tu.Host = net.JoinHostPort(host, port)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn u\n}\n\nfunc (metadata Metadata) remainingLimitHeaderValues() (remainingDownloads, remainingDays string) {\n\tif metadata.MaxDate.IsZero() {\n\t\tremainingDays = \"n/a\"\n\t} else {\n\t\ttimeDifference := metadata.MaxDate.Sub(time.Now())\n\t\tremainingDays = strconv.Itoa(int(timeDifference.Hours()/24) + 1)\n\t}\n\n\tif metadata.MaxDownloads == -1 {\n\t\tremainingDownloads = \"n/a\"\n\t} else {\n\t\tremainingDownloads = strconv.Itoa(metadata.MaxDownloads - metadata.Downloads)\n\t}\n\n\treturn remainingDownloads, remainingDays\n}\n\nfunc (s *Server) Lock(token, filename string) error {\n\tkey := path.Join(token, filename)\n\n\tif _, ok := s.locks[key]; !ok {\n\t\ts.locks[key] = &sync.Mutex{}\n\t}\n\n\ts.locks[key].Lock()\n\n\treturn nil\n}\n\nfunc (s *Server) Unlock(token, filename string) error {\n\tkey := path.Join(token, filename)\n\ts.locks[key].Unlock()\n\n\treturn nil\n}\n\nfunc (s *Server) CheckMetadata(token, filename string, increaseDownload bool) (Metadata, error) {\n\ts.Lock(token, filename)\n\tdefer s.Unlock(token, filename)\n\n\tvar metadata Metadata\n\n\tr, _, err := s.storage.Get(token, fmt.Sprintf(\"%s.metadata\", filename))\n\tif err != nil {\n\t\treturn metadata, err\n\t}\n\n\tdefer r.Close()\n\n\tif err := json.NewDecoder(r).Decode(&metadata); err != nil {\n\t\treturn metadata, err\n\t} else if metadata.MaxDownloads != -1 && metadata.Downloads >= metadata.MaxDownloads {\n\t\treturn metadata, errors.New(\"MaxDownloads expired.\")\n\t} else if !metadata.MaxDate.IsZero() && time.Now().After(metadata.MaxDate) {\n\t\treturn metadata, errors.New(\"MaxDate expired.\")\n\t} else if metadata.MaxDownloads != -1 && increaseDownload {\n\t\t// todo(nl5887): mutex?\n\n\t\t// update number of downloads\n\t\tmetadata.Downloads++\n\n\t\tbuffer := &bytes.Buffer{}\n\t\tif err := json.NewEncoder(buffer).Encode(metadata); err != nil {\n\t\t\treturn metadata, errors.New(\"Could not encode metadata\")\n\t\t} else if err := s.storage.Put(token, fmt.Sprintf(\"%s.metadata\", filename), buffer, \"text/json\", uint64(buffer.Len())); err != nil {\n\t\t\treturn metadata, errors.New(\"Could not save metadata\")\n\t\t}\n\t}\n\n\treturn metadata, nil\n}\n\nfunc (s *Server) CheckDeletionToken(deletionToken, token, filename string) error {\n\ts.Lock(token, filename)\n\tdefer s.Unlock(token, filename)\n\n\tvar metadata Metadata\n\n\tr, _, err := s.storage.Get(token, fmt.Sprintf(\"%s.metadata\", filename))\n\tif s.storage.IsNotExist(err) {\n\t\treturn errors.New(\"Metadata doesn't exist\")\n\t} else if err != nil {\n\t\treturn err\n\t}\n\n\tdefer r.Close()\n\n\tif err := json.NewDecoder(r).Decode(&metadata); err != nil {\n\t\treturn err\n\t} else if metadata.DeletionToken != deletionToken {\n\t\treturn errors.New(\"Deletion token doesn't match.\")\n\t}\n\n\treturn nil\n}\n\nfunc (s *Server) purgeHandler() {\n\tticker := time.NewTicker(s.purgeInterval)\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ticker.C:\n\t\t\t\terr := s.storage.Purge(s.purgeDays)\n\t\t\t\tlog.Printf(\"error cleaning up expired files: %v\", err)\n\t\t\t}\n\t\t}\n\t}()\n}\n\nfunc (s *Server) deleteHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\ttoken := vars[\"token\"]\n\tfilename := vars[\"filename\"]\n\tdeletionToken := vars[\"deletionToken\"]\n\n\tif err := s.CheckDeletionToken(deletionToken, token, filename); err != nil {\n\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t}\n\n\terr := s.storage.Delete(token, filename)\n\tif s.storage.IsNotExist(err) {\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Could not delete file.\", 500)\n\t\treturn\n\t}\n}\n\nfunc (s *Server) zipHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\tfiles := vars[\"files\"]\n\n\tzipfilename := fmt.Sprintf(\"transfersh-%d.zip\", uint16(time.Now().UnixNano()))\n\n\tw.Header().Set(\"Content-Type\", \"application/zip\")\n\tw.Header().Set(\"Content-Disposition\", fmt.Sprintf(\"attachment; filename=\\\"%s\\\"\", zipfilename))\n\tw.Header().Set(\"Connection\", \"close\")\n\n\tzw := zip.NewWriter(w)\n\n\tfor _, key := range strings.Split(files, \",\") {\n\t\tkey = resolveKey(key, s.proxyPath)\n\n\t\ttoken := strings.Split(key, \"/\")[0]\n\t\tfilename := sanitize(strings.Split(key, \"/\")[1])\n\n\t\tif _, err := s.CheckMetadata(token, filename, true); err != nil {\n\t\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\t\tcontinue\n\t\t}\n\n\t\treader, _, err := s.storage.Get(token, filename)\n\n\t\tif err != nil {\n\t\t\tif s.storage.IsNotExist(err) {\n\t\t\t\thttp.Error(w, \"File not found\", 404)\n\t\t\t\treturn\n\t\t\t} else {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, \"Could not retrieve file.\", 500)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tdefer reader.Close()\n\n\t\theader := &zip.FileHeader{\n\t\t\tName:         strings.Split(key, \"/\")[1],\n\t\t\tMethod:       zip.Store,\n\t\t\tModifiedTime: uint16(time.Now().UnixNano()),\n\t\t\tModifiedDate: uint16(time.Now().UnixNano()),\n\t\t}\n\n\t\tfw, err := zw.CreateHeader(header)\n\n\t\tif err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\n\t\tif _, err = io.Copy(fw, reader); err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\t}\n\n\tif err := zw.Close(); err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\treturn\n\t}\n}\n\nfunc (s *Server) tarGzHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\tfiles := vars[\"files\"]\n\n\ttarfilename := fmt.Sprintf(\"transfersh-%d.tar.gz\", uint16(time.Now().UnixNano()))\n\n\tw.Header().Set(\"Content-Type\", \"application/x-gzip\")\n\tw.Header().Set(\"Content-Disposition\", fmt.Sprintf(\"attachment; filename=\\\"%s\\\"\", tarfilename))\n\tw.Header().Set(\"Connection\", \"close\")\n\n\tos := gzip.NewWriter(w)\n\tdefer os.Close()\n\n\tzw := tar.NewWriter(os)\n\tdefer zw.Close()\n\n\tfor _, key := range strings.Split(files, \",\") {\n\t\tkey = resolveKey(key, s.proxyPath)\n\n\t\ttoken := strings.Split(key, \"/\")[0]\n\t\tfilename := sanitize(strings.Split(key, \"/\")[1])\n\n\t\tif _, err := s.CheckMetadata(token, filename, true); err != nil {\n\t\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\t\tcontinue\n\t\t}\n\n\t\treader, contentLength, err := s.storage.Get(token, filename)\n\t\tif err != nil {\n\t\t\tif s.storage.IsNotExist(err) {\n\t\t\t\thttp.Error(w, \"File not found\", 404)\n\t\t\t\treturn\n\t\t\t} else {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, \"Could not retrieve file.\", 500)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tdefer reader.Close()\n\n\t\theader := &tar.Header{\n\t\t\tName: strings.Split(key, \"/\")[1],\n\t\t\tSize: int64(contentLength),\n\t\t}\n\n\t\terr = zw.WriteHeader(header)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\n\t\tif _, err = io.Copy(zw, reader); err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (s *Server) tarHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\tfiles := vars[\"files\"]\n\n\ttarfilename := fmt.Sprintf(\"transfersh-%d.tar\", uint16(time.Now().UnixNano()))\n\n\tw.Header().Set(\"Content-Type\", \"application/x-tar\")\n\tw.Header().Set(\"Content-Disposition\", fmt.Sprintf(\"attachment; filename=\\\"%s\\\"\", tarfilename))\n\tw.Header().Set(\"Connection\", \"close\")\n\n\tzw := tar.NewWriter(w)\n\tdefer zw.Close()\n\n\tfor _, key := range strings.Split(files, \",\") {\n\t\tkey = resolveKey(key, s.proxyPath)\n\n\t\ttoken := strings.Split(key, \"/\")[0]\n\t\tfilename := strings.Split(key, \"/\")[1]\n\n\t\tif _, err := s.CheckMetadata(token, filename, true); err != nil {\n\t\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\t\tcontinue\n\t\t}\n\n\t\treader, contentLength, err := s.storage.Get(token, filename)\n\t\tif err != nil {\n\t\t\tif s.storage.IsNotExist(err) {\n\t\t\t\thttp.Error(w, \"File not found\", 404)\n\t\t\t\treturn\n\t\t\t} else {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, \"Could not retrieve file.\", 500)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tdefer reader.Close()\n\n\t\theader := &tar.Header{\n\t\t\tName: strings.Split(key, \"/\")[1],\n\t\t\tSize: int64(contentLength),\n\t\t}\n\n\t\terr = zw.WriteHeader(header)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\n\t\tif _, err = io.Copy(zw, reader); err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Internal server error.\", 500)\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (s *Server) headHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\ttoken := vars[\"token\"]\n\tfilename := vars[\"filename\"]\n\n\tmetadata, err := s.CheckMetadata(token, filename, false)\n\n\tif err != nil {\n\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t}\n\n\tcontentType := metadata.ContentType\n\tcontentLength, err := s.storage.Head(token, filename)\n\tif s.storage.IsNotExist(err) {\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Could not retrieve file.\", 500)\n\t\treturn\n\t}\n\n\tremainingDownloads, remainingDays := metadata.remainingLimitHeaderValues()\n\n\tw.Header().Set(\"Content-Type\", contentType)\n\tw.Header().Set(\"Content-Length\", strconv.FormatUint(contentLength, 10))\n\tw.Header().Set(\"Connection\", \"close\")\n\tw.Header().Set(\"X-Remaining-Downloads\", remainingDownloads)\n\tw.Header().Set(\"X-Remaining-Days\", remainingDays)\n}\n\nfunc (s *Server) getHandler(w http.ResponseWriter, r *http.Request) {\n\tvars := mux.Vars(r)\n\n\taction := vars[\"action\"]\n\ttoken := vars[\"token\"]\n\tfilename := vars[\"filename\"]\n\n\tmetadata, err := s.CheckMetadata(token, filename, true)\n\n\tif err != nil {\n\t\tlog.Printf(\"Error metadata: %s\", err.Error())\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t}\n\n\tcontentType := metadata.ContentType\n\treader, contentLength, err := s.storage.Get(token, filename)\n\tif s.storage.IsNotExist(err) {\n\t\thttp.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Could not retrieve file.\", 500)\n\t\treturn\n\t}\n\n\tdefer reader.Close()\n\n\tvar disposition string\n\n\tif action == \"inline\" {\n\t\tdisposition = \"inline\"\n\t} else {\n\t\tdisposition = \"attachment\"\n\t}\n\n\tremainingDownloads, remainingDays := metadata.remainingLimitHeaderValues()\n\n\tw.Header().Set(\"Content-Type\", contentType)\n\tw.Header().Set(\"Content-Length\", strconv.FormatUint(contentLength, 10))\n\tw.Header().Set(\"Content-Disposition\", fmt.Sprintf(\"%s; filename=\\\"%s\\\"\", disposition, filename))\n\tw.Header().Set(\"Connection\", \"keep-alive\")\n\tw.Header().Set(\"X-Remaining-Downloads\", remainingDownloads)\n\tw.Header().Set(\"X-Remaining-Days\", remainingDays)\n\n\tif disposition == \"inline\" && canContainsXSS(contentType) {\n\t\treader = ioutil.NopCloser(bluemonday.UGCPolicy().SanitizeReader(reader))\n\t}\n\n\tif w.Header().Get(\"Range\") == \"\" {\n\t\tif _, err = io.Copy(w, reader); err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Error occurred copying to output stream\", 500)\n\t\t\treturn\n\t\t}\n\n\t\treturn\n\t}\n\n\tfile, err := ioutil.TempFile(s.tempPath, \"range-\")\n\tif err != nil {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Error occurred copying to output stream\", 500)\n\t\treturn\n\t}\n\n\tdefer cleanTmpFile(file)\n\n\ttee := io.TeeReader(reader, file)\n\tfor {\n\t\tb := make([]byte, _5M)\n\t\t_, err = tee.Read(b)\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\n\t\tif err != nil {\n\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\thttp.Error(w, \"Error occurred copying to output stream\", 500)\n\t\t\treturn\n\t\t}\n\t}\n\n\thttp.ServeContent(w, r, filename, time.Now(), file)\n}\n\nfunc (s *Server) RedirectHandler(h http.Handler) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tif !s.forceHTTPs {\n\t\t\t// we don't want to enforce https\n\t\t} else if r.URL.Path == \"/health.html\" {\n\t\t\t// health check url won't redirect\n\t\t} else if strings.HasSuffix(ipAddrFromRemoteAddr(r.Host), \".onion\") {\n\t\t\t// .onion addresses cannot get a valid certificate, so don't redirect\n\t\t} else if r.Header.Get(\"X-Forwarded-Proto\") == \"https\" {\n\t\t} else if r.URL.Scheme == \"https\" {\n\t\t} else {\n\t\t\tu := getURL(r, s.proxyPort)\n\t\t\tu.Scheme = \"https\"\n\n\t\t\thttp.Redirect(w, r, u.String(), http.StatusPermanentRedirect)\n\t\t\treturn\n\t\t}\n\n\t\th.ServeHTTP(w, r)\n\t}\n}\n\n// Create a log handler for every request it receives.\nfunc LoveHandler(h http.Handler) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"x-made-with\", \"<3 by DutchCoders\")\n\t\tw.Header().Set(\"x-served-by\", \"Proudly served by DutchCoders\")\n\t\tw.Header().Set(\"Server\", \"Transfer.sh HTTP Server 1.0\")\n\t\th.ServeHTTP(w, r)\n\t}\n}\n\nfunc IPFilterHandler(h http.Handler, ipFilterOptions *IPFilterOptions) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tif ipFilterOptions == nil {\n\t\t\th.ServeHTTP(w, r)\n\t\t} else {\n\t\t\tWrapIPFilter(h, *ipFilterOptions).ServeHTTP(w, r)\n\t\t}\n\t\treturn\n\t}\n}\n\nfunc (s *Server) BasicAuthHandler(h http.Handler) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tif s.AuthUser == \"\" || s.AuthPass == \"\" {\n\t\t\th.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\n\t\tw.Header().Set(\"WWW-Authenticate\", \"Basic realm=\\\"Restricted\\\"\")\n\n\t\tusername, password, authOK := r.BasicAuth()\n\t\tif authOK == false {\n\t\t\thttp.Error(w, \"Not authorized\", 401)\n\t\t\treturn\n\t\t}\n\n\t\tif username != s.AuthUser || password != s.AuthPass {\n\t\t\thttp.Error(w, \"Not authorized\", 401)\n\t\t\treturn\n\t\t}\n\n\t\th.ServeHTTP(w, r)\n\t}\n}\n"], "filenames": ["cmd/cmd.go", "server/handlers.go"], "buggy_code_start_loc": [15, 94], "buggy_code_end_loc": [16, 1012], "fixing_code_start_loc": [15, 95], "fixing_code_end_loc": [16, 1025], "type": "CWE-79", "message": "Dutchcoders transfer.sh before 1.2.4 allows XSS via an inline view.", "other": {"cve": {"id": "CVE-2021-33496", "sourceIdentifier": "cve@mitre.org", "published": "2021-05-24T05:15:08.273", "lastModified": "2021-05-27T19:34:29.720", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Dutchcoders transfer.sh before 1.2.4 allows XSS via an inline view."}, {"lang": "es", "value": "Dutchcoders transfer.sh versiones anteriores a 1.2.4, permite un ataque de tipo XSS por medio de una vista en l\u00ednea"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 6.1, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 2.7}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:N/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-79"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:dutchcoders:transfer.sh:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.2.4", "matchCriteriaId": "83C42681-23E8-4D9F-AB2F-05CE88416FA2"}]}]}], "references": [{"url": "https://github.com/dutchcoders/transfer.sh/commit/9df18fdc69de2e71f30d8c1e6bfab2fda2e52eb4", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/dutchcoders/transfer.sh/pull/373", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/dutchcoders/transfer.sh/releases/tag/v1.2.4", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://vuln.ryotak.me/advisories/43", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/dutchcoders/transfer.sh/commit/9df18fdc69de2e71f30d8c1e6bfab2fda2e52eb4"}}
{"buggy_code": ["/*\n * Copyright (c) 2006 Oracle.  All rights reserved.\n *\n * This software is available to you under a choice of one of two\n * licenses.  You may choose to be licensed under the terms of the GNU\n * General Public License (GPL) Version 2, available from the file\n * COPYING in the main directory of this source tree, or the\n * OpenIB.org BSD license below:\n *\n *     Redistribution and use in source and binary forms, with or\n *     without modification, are permitted provided that the following\n *     conditions are met:\n *\n *      - Redistributions of source code must retain the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer.\n *\n *      - Redistributions in binary form must reproduce the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer in the documentation and/or other materials\n *        provided with the distribution.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <net/sock.h>\n#include <linux/in.h>\n#include <linux/export.h>\n#include <linux/time.h>\n#include <linux/rds.h>\n\n#include \"rds.h\"\n\nvoid rds_inc_init(struct rds_incoming *inc, struct rds_connection *conn,\n\t\t  __be32 saddr)\n{\n\tatomic_set(&inc->i_refcount, 1);\n\tINIT_LIST_HEAD(&inc->i_item);\n\tinc->i_conn = conn;\n\tinc->i_saddr = saddr;\n\tinc->i_rdma_cookie = 0;\n\tinc->i_rx_tstamp.tv_sec = 0;\n\tinc->i_rx_tstamp.tv_usec = 0;\n}\nEXPORT_SYMBOL_GPL(rds_inc_init);\n\nstatic void rds_inc_addref(struct rds_incoming *inc)\n{\n\trdsdebug(\"addref inc %p ref %d\\n\", inc, atomic_read(&inc->i_refcount));\n\tatomic_inc(&inc->i_refcount);\n}\n\nvoid rds_inc_put(struct rds_incoming *inc)\n{\n\trdsdebug(\"put inc %p ref %d\\n\", inc, atomic_read(&inc->i_refcount));\n\tif (atomic_dec_and_test(&inc->i_refcount)) {\n\t\tBUG_ON(!list_empty(&inc->i_item));\n\n\t\tinc->i_conn->c_trans->inc_free(inc);\n\t}\n}\nEXPORT_SYMBOL_GPL(rds_inc_put);\n\nstatic void rds_recv_rcvbuf_delta(struct rds_sock *rs, struct sock *sk,\n\t\t\t\t  struct rds_cong_map *map,\n\t\t\t\t  int delta, __be16 port)\n{\n\tint now_congested;\n\n\tif (delta == 0)\n\t\treturn;\n\n\trs->rs_rcv_bytes += delta;\n\tnow_congested = rs->rs_rcv_bytes > rds_sk_rcvbuf(rs);\n\n\trdsdebug(\"rs %p (%pI4:%u) recv bytes %d buf %d \"\n\t  \"now_cong %d delta %d\\n\",\n\t  rs, &rs->rs_bound_addr,\n\t  ntohs(rs->rs_bound_port), rs->rs_rcv_bytes,\n\t  rds_sk_rcvbuf(rs), now_congested, delta);\n\n\t/* wasn't -> am congested */\n\tif (!rs->rs_congested && now_congested) {\n\t\trs->rs_congested = 1;\n\t\trds_cong_set_bit(map, port);\n\t\trds_cong_queue_updates(map);\n\t}\n\t/* was -> aren't congested */\n\t/* Require more free space before reporting uncongested to prevent\n\t   bouncing cong/uncong state too often */\n\telse if (rs->rs_congested && (rs->rs_rcv_bytes < (rds_sk_rcvbuf(rs)/2))) {\n\t\trs->rs_congested = 0;\n\t\trds_cong_clear_bit(map, port);\n\t\trds_cong_queue_updates(map);\n\t}\n\n\t/* do nothing if no change in cong state */\n}\n\n/*\n * Process all extension headers that come with this message.\n */\nstatic void rds_recv_incoming_exthdrs(struct rds_incoming *inc, struct rds_sock *rs)\n{\n\tstruct rds_header *hdr = &inc->i_hdr;\n\tunsigned int pos = 0, type, len;\n\tunion {\n\t\tstruct rds_ext_header_version version;\n\t\tstruct rds_ext_header_rdma rdma;\n\t\tstruct rds_ext_header_rdma_dest rdma_dest;\n\t} buffer;\n\n\twhile (1) {\n\t\tlen = sizeof(buffer);\n\t\ttype = rds_message_next_extension(hdr, &pos, &buffer, &len);\n\t\tif (type == RDS_EXTHDR_NONE)\n\t\t\tbreak;\n\t\t/* Process extension header here */\n\t\tswitch (type) {\n\t\tcase RDS_EXTHDR_RDMA:\n\t\t\trds_rdma_unuse(rs, be32_to_cpu(buffer.rdma.h_rdma_rkey), 0);\n\t\t\tbreak;\n\n\t\tcase RDS_EXTHDR_RDMA_DEST:\n\t\t\t/* We ignore the size for now. We could stash it\n\t\t\t * somewhere and use it for error checking. */\n\t\t\tinc->i_rdma_cookie = rds_rdma_make_cookie(\n\t\t\t\t\tbe32_to_cpu(buffer.rdma_dest.h_rdma_rkey),\n\t\t\t\t\tbe32_to_cpu(buffer.rdma_dest.h_rdma_offset));\n\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n/*\n * The transport must make sure that this is serialized against other\n * rx and conn reset on this specific conn.\n *\n * We currently assert that only one fragmented message will be sent\n * down a connection at a time.  This lets us reassemble in the conn\n * instead of per-flow which means that we don't have to go digging through\n * flows to tear down partial reassembly progress on conn failure and\n * we save flow lookup and locking for each frag arrival.  It does mean\n * that small messages will wait behind large ones.  Fragmenting at all\n * is only to reduce the memory consumption of pre-posted buffers.\n *\n * The caller passes in saddr and daddr instead of us getting it from the\n * conn.  This lets loopback, who only has one conn for both directions,\n * tell us which roles the addrs in the conn are playing for this message.\n */\nvoid rds_recv_incoming(struct rds_connection *conn, __be32 saddr, __be32 daddr,\n\t\t       struct rds_incoming *inc, gfp_t gfp)\n{\n\tstruct rds_sock *rs = NULL;\n\tstruct sock *sk;\n\tunsigned long flags;\n\n\tinc->i_conn = conn;\n\tinc->i_rx_jiffies = jiffies;\n\n\trdsdebug(\"conn %p next %llu inc %p seq %llu len %u sport %u dport %u \"\n\t\t \"flags 0x%x rx_jiffies %lu\\n\", conn,\n\t\t (unsigned long long)conn->c_next_rx_seq,\n\t\t inc,\n\t\t (unsigned long long)be64_to_cpu(inc->i_hdr.h_sequence),\n\t\t be32_to_cpu(inc->i_hdr.h_len),\n\t\t be16_to_cpu(inc->i_hdr.h_sport),\n\t\t be16_to_cpu(inc->i_hdr.h_dport),\n\t\t inc->i_hdr.h_flags,\n\t\t inc->i_rx_jiffies);\n\n\t/*\n\t * Sequence numbers should only increase.  Messages get their\n\t * sequence number as they're queued in a sending conn.  They\n\t * can be dropped, though, if the sending socket is closed before\n\t * they hit the wire.  So sequence numbers can skip forward\n\t * under normal operation.  They can also drop back in the conn\n\t * failover case as previously sent messages are resent down the\n\t * new instance of a conn.  We drop those, otherwise we have\n\t * to assume that the next valid seq does not come after a\n\t * hole in the fragment stream.\n\t *\n\t * The headers don't give us a way to realize if fragments of\n\t * a message have been dropped.  We assume that frags that arrive\n\t * to a flow are part of the current message on the flow that is\n\t * being reassembled.  This means that senders can't drop messages\n\t * from the sending conn until all their frags are sent.\n\t *\n\t * XXX we could spend more on the wire to get more robust failure\n\t * detection, arguably worth it to avoid data corruption.\n\t */\n\tif (be64_to_cpu(inc->i_hdr.h_sequence) < conn->c_next_rx_seq &&\n\t    (inc->i_hdr.h_flags & RDS_FLAG_RETRANSMITTED)) {\n\t\trds_stats_inc(s_recv_drop_old_seq);\n\t\tgoto out;\n\t}\n\tconn->c_next_rx_seq = be64_to_cpu(inc->i_hdr.h_sequence) + 1;\n\n\tif (rds_sysctl_ping_enable && inc->i_hdr.h_dport == 0) {\n\t\trds_stats_inc(s_recv_ping);\n\t\trds_send_pong(conn, inc->i_hdr.h_sport);\n\t\tgoto out;\n\t}\n\n\trs = rds_find_bound(daddr, inc->i_hdr.h_dport);\n\tif (!rs) {\n\t\trds_stats_inc(s_recv_drop_no_sock);\n\t\tgoto out;\n\t}\n\n\t/* Process extension headers */\n\trds_recv_incoming_exthdrs(inc, rs);\n\n\t/* We can be racing with rds_release() which marks the socket dead. */\n\tsk = rds_rs_to_sk(rs);\n\n\t/* serialize with rds_release -> sock_orphan */\n\twrite_lock_irqsave(&rs->rs_recv_lock, flags);\n\tif (!sock_flag(sk, SOCK_DEAD)) {\n\t\trdsdebug(\"adding inc %p to rs %p's recv queue\\n\", inc, rs);\n\t\trds_stats_inc(s_recv_queued);\n\t\trds_recv_rcvbuf_delta(rs, sk, inc->i_conn->c_lcong,\n\t\t\t\t      be32_to_cpu(inc->i_hdr.h_len),\n\t\t\t\t      inc->i_hdr.h_dport);\n\t\tif (sock_flag(sk, SOCK_RCVTSTAMP))\n\t\t\tdo_gettimeofday(&inc->i_rx_tstamp);\n\t\trds_inc_addref(inc);\n\t\tlist_add_tail(&inc->i_item, &rs->rs_recv_queue);\n\t\t__rds_wake_sk_sleep(sk);\n\t} else {\n\t\trds_stats_inc(s_recv_drop_dead_sock);\n\t}\n\twrite_unlock_irqrestore(&rs->rs_recv_lock, flags);\n\nout:\n\tif (rs)\n\t\trds_sock_put(rs);\n}\nEXPORT_SYMBOL_GPL(rds_recv_incoming);\n\n/*\n * be very careful here.  This is being called as the condition in\n * wait_event_*() needs to cope with being called many times.\n */\nstatic int rds_next_incoming(struct rds_sock *rs, struct rds_incoming **inc)\n{\n\tunsigned long flags;\n\n\tif (!*inc) {\n\t\tread_lock_irqsave(&rs->rs_recv_lock, flags);\n\t\tif (!list_empty(&rs->rs_recv_queue)) {\n\t\t\t*inc = list_entry(rs->rs_recv_queue.next,\n\t\t\t\t\t  struct rds_incoming,\n\t\t\t\t\t  i_item);\n\t\t\trds_inc_addref(*inc);\n\t\t}\n\t\tread_unlock_irqrestore(&rs->rs_recv_lock, flags);\n\t}\n\n\treturn *inc != NULL;\n}\n\nstatic int rds_still_queued(struct rds_sock *rs, struct rds_incoming *inc,\n\t\t\t    int drop)\n{\n\tstruct sock *sk = rds_rs_to_sk(rs);\n\tint ret = 0;\n\tunsigned long flags;\n\n\twrite_lock_irqsave(&rs->rs_recv_lock, flags);\n\tif (!list_empty(&inc->i_item)) {\n\t\tret = 1;\n\t\tif (drop) {\n\t\t\t/* XXX make sure this i_conn is reliable */\n\t\t\trds_recv_rcvbuf_delta(rs, sk, inc->i_conn->c_lcong,\n\t\t\t\t\t      -be32_to_cpu(inc->i_hdr.h_len),\n\t\t\t\t\t      inc->i_hdr.h_dport);\n\t\t\tlist_del_init(&inc->i_item);\n\t\t\trds_inc_put(inc);\n\t\t}\n\t}\n\twrite_unlock_irqrestore(&rs->rs_recv_lock, flags);\n\n\trdsdebug(\"inc %p rs %p still %d dropped %d\\n\", inc, rs, ret, drop);\n\treturn ret;\n}\n\n/*\n * Pull errors off the error queue.\n * If msghdr is NULL, we will just purge the error queue.\n */\nint rds_notify_queue_get(struct rds_sock *rs, struct msghdr *msghdr)\n{\n\tstruct rds_notifier *notifier;\n\tstruct rds_rdma_notify cmsg = { 0 }; /* fill holes with zero */\n\tunsigned int count = 0, max_messages = ~0U;\n\tunsigned long flags;\n\tLIST_HEAD(copy);\n\tint err = 0;\n\n\n\t/* put_cmsg copies to user space and thus may sleep. We can't do this\n\t * with rs_lock held, so first grab as many notifications as we can stuff\n\t * in the user provided cmsg buffer. We don't try to copy more, to avoid\n\t * losing notifications - except when the buffer is so small that it wouldn't\n\t * even hold a single notification. Then we give him as much of this single\n\t * msg as we can squeeze in, and set MSG_CTRUNC.\n\t */\n\tif (msghdr) {\n\t\tmax_messages = msghdr->msg_controllen / CMSG_SPACE(sizeof(cmsg));\n\t\tif (!max_messages)\n\t\t\tmax_messages = 1;\n\t}\n\n\tspin_lock_irqsave(&rs->rs_lock, flags);\n\twhile (!list_empty(&rs->rs_notify_queue) && count < max_messages) {\n\t\tnotifier = list_entry(rs->rs_notify_queue.next,\n\t\t\t\tstruct rds_notifier, n_list);\n\t\tlist_move(&notifier->n_list, &copy);\n\t\tcount++;\n\t}\n\tspin_unlock_irqrestore(&rs->rs_lock, flags);\n\n\tif (!count)\n\t\treturn 0;\n\n\twhile (!list_empty(&copy)) {\n\t\tnotifier = list_entry(copy.next, struct rds_notifier, n_list);\n\n\t\tif (msghdr) {\n\t\t\tcmsg.user_token = notifier->n_user_token;\n\t\t\tcmsg.status = notifier->n_status;\n\n\t\t\terr = put_cmsg(msghdr, SOL_RDS, RDS_CMSG_RDMA_STATUS,\n\t\t\t\t       sizeof(cmsg), &cmsg);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tlist_del_init(&notifier->n_list);\n\t\tkfree(notifier);\n\t}\n\n\t/* If we bailed out because of an error in put_cmsg,\n\t * we may be left with one or more notifications that we\n\t * didn't process. Return them to the head of the list. */\n\tif (!list_empty(&copy)) {\n\t\tspin_lock_irqsave(&rs->rs_lock, flags);\n\t\tlist_splice(&copy, &rs->rs_notify_queue);\n\t\tspin_unlock_irqrestore(&rs->rs_lock, flags);\n\t}\n\n\treturn err;\n}\n\n/*\n * Queue a congestion notification\n */\nstatic int rds_notify_cong(struct rds_sock *rs, struct msghdr *msghdr)\n{\n\tuint64_t notify = rs->rs_cong_notify;\n\tunsigned long flags;\n\tint err;\n\n\terr = put_cmsg(msghdr, SOL_RDS, RDS_CMSG_CONG_UPDATE,\n\t\t\tsizeof(notify), &notify);\n\tif (err)\n\t\treturn err;\n\n\tspin_lock_irqsave(&rs->rs_lock, flags);\n\trs->rs_cong_notify &= ~notify;\n\tspin_unlock_irqrestore(&rs->rs_lock, flags);\n\n\treturn 0;\n}\n\n/*\n * Receive any control messages.\n */\nstatic int rds_cmsg_recv(struct rds_incoming *inc, struct msghdr *msg,\n\t\t\t struct rds_sock *rs)\n{\n\tint ret = 0;\n\n\tif (inc->i_rdma_cookie) {\n\t\tret = put_cmsg(msg, SOL_RDS, RDS_CMSG_RDMA_DEST,\n\t\t\t\tsizeof(inc->i_rdma_cookie), &inc->i_rdma_cookie);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif ((inc->i_rx_tstamp.tv_sec != 0) &&\n\t    sock_flag(rds_rs_to_sk(rs), SOCK_RCVTSTAMP)) {\n\t\tret = put_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMP,\n\t\t\t       sizeof(struct timeval),\n\t\t\t       &inc->i_rx_tstamp);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint rds_recvmsg(struct socket *sock, struct msghdr *msg, size_t size,\n\t\tint msg_flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct rds_sock *rs = rds_sk_to_rs(sk);\n\tlong timeo;\n\tint ret = 0, nonblock = msg_flags & MSG_DONTWAIT;\n\tDECLARE_SOCKADDR(struct sockaddr_in *, sin, msg->msg_name);\n\tstruct rds_incoming *inc = NULL;\n\n\t/* udp_recvmsg()->sock_recvtimeo() gets away without locking too.. */\n\ttimeo = sock_rcvtimeo(sk, nonblock);\n\n\trdsdebug(\"size %zu flags 0x%x timeo %ld\\n\", size, msg_flags, timeo);\n\n\tif (msg_flags & MSG_OOB)\n\t\tgoto out;\n\n\twhile (1) {\n\t\tstruct iov_iter save;\n\t\t/* If there are pending notifications, do those - and nothing else */\n\t\tif (!list_empty(&rs->rs_notify_queue)) {\n\t\t\tret = rds_notify_queue_get(rs, msg);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (rs->rs_cong_notify) {\n\t\t\tret = rds_notify_cong(rs, msg);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!rds_next_incoming(rs, &inc)) {\n\t\t\tif (nonblock) {\n\t\t\t\tret = -EAGAIN;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\ttimeo = wait_event_interruptible_timeout(*sk_sleep(sk),\n\t\t\t\t\t(!list_empty(&rs->rs_notify_queue) ||\n\t\t\t\t\t rs->rs_cong_notify ||\n\t\t\t\t\t rds_next_incoming(rs, &inc)), timeo);\n\t\t\trdsdebug(\"recvmsg woke inc %p timeo %ld\\n\", inc,\n\t\t\t\t timeo);\n\t\t\tif (timeo > 0 || timeo == MAX_SCHEDULE_TIMEOUT)\n\t\t\t\tcontinue;\n\n\t\t\tret = timeo;\n\t\t\tif (ret == 0)\n\t\t\t\tret = -ETIMEDOUT;\n\t\t\tbreak;\n\t\t}\n\n\t\trdsdebug(\"copying inc %p from %pI4:%u to user\\n\", inc,\n\t\t\t &inc->i_conn->c_faddr,\n\t\t\t ntohs(inc->i_hdr.h_sport));\n\t\tsave = msg->msg_iter;\n\t\tret = inc->i_conn->c_trans->inc_copy_to_user(inc, &msg->msg_iter);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * if the message we just copied isn't at the head of the\n\t\t * recv queue then someone else raced us to return it, try\n\t\t * to get the next message.\n\t\t */\n\t\tif (!rds_still_queued(rs, inc, !(msg_flags & MSG_PEEK))) {\n\t\t\trds_inc_put(inc);\n\t\t\tinc = NULL;\n\t\t\trds_stats_inc(s_recv_deliver_raced);\n\t\t\tmsg->msg_iter = save;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (ret < be32_to_cpu(inc->i_hdr.h_len)) {\n\t\t\tif (msg_flags & MSG_TRUNC)\n\t\t\t\tret = be32_to_cpu(inc->i_hdr.h_len);\n\t\t\tmsg->msg_flags |= MSG_TRUNC;\n\t\t}\n\n\t\tif (rds_cmsg_recv(inc, msg, rs)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\trds_stats_inc(s_recv_delivered);\n\n\t\tif (sin) {\n\t\t\tsin->sin_family = AF_INET;\n\t\t\tsin->sin_port = inc->i_hdr.h_sport;\n\t\t\tsin->sin_addr.s_addr = inc->i_saddr;\n\t\t\tmemset(sin->sin_zero, 0, sizeof(sin->sin_zero));\n\t\t\tmsg->msg_namelen = sizeof(*sin);\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (inc)\n\t\trds_inc_put(inc);\n\nout:\n\treturn ret;\n}\n\n/*\n * The socket is being shut down and we're asked to drop messages that were\n * queued for recvmsg.  The caller has unbound the socket so the receive path\n * won't queue any more incoming fragments or messages on the socket.\n */\nvoid rds_clear_recv_queue(struct rds_sock *rs)\n{\n\tstruct sock *sk = rds_rs_to_sk(rs);\n\tstruct rds_incoming *inc, *tmp;\n\tunsigned long flags;\n\n\twrite_lock_irqsave(&rs->rs_recv_lock, flags);\n\tlist_for_each_entry_safe(inc, tmp, &rs->rs_recv_queue, i_item) {\n\t\trds_recv_rcvbuf_delta(rs, sk, inc->i_conn->c_lcong,\n\t\t\t\t      -be32_to_cpu(inc->i_hdr.h_len),\n\t\t\t\t      inc->i_hdr.h_dport);\n\t\tlist_del_init(&inc->i_item);\n\t\trds_inc_put(inc);\n\t}\n\twrite_unlock_irqrestore(&rs->rs_recv_lock, flags);\n}\n\n/*\n * inc->i_saddr isn't used here because it is only set in the receive\n * path.\n */\nvoid rds_inc_info_copy(struct rds_incoming *inc,\n\t\t       struct rds_info_iterator *iter,\n\t\t       __be32 saddr, __be32 daddr, int flip)\n{\n\tstruct rds_info_message minfo;\n\n\tminfo.seq = be64_to_cpu(inc->i_hdr.h_sequence);\n\tminfo.len = be32_to_cpu(inc->i_hdr.h_len);\n\n\tif (flip) {\n\t\tminfo.laddr = daddr;\n\t\tminfo.faddr = saddr;\n\t\tminfo.lport = inc->i_hdr.h_dport;\n\t\tminfo.fport = inc->i_hdr.h_sport;\n\t} else {\n\t\tminfo.laddr = saddr;\n\t\tminfo.faddr = daddr;\n\t\tminfo.lport = inc->i_hdr.h_sport;\n\t\tminfo.fport = inc->i_hdr.h_dport;\n\t}\n\n\trds_info_copy(iter, &minfo, sizeof(minfo));\n}\n"], "fixing_code": ["/*\n * Copyright (c) 2006 Oracle.  All rights reserved.\n *\n * This software is available to you under a choice of one of two\n * licenses.  You may choose to be licensed under the terms of the GNU\n * General Public License (GPL) Version 2, available from the file\n * COPYING in the main directory of this source tree, or the\n * OpenIB.org BSD license below:\n *\n *     Redistribution and use in source and binary forms, with or\n *     without modification, are permitted provided that the following\n *     conditions are met:\n *\n *      - Redistributions of source code must retain the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer.\n *\n *      - Redistributions in binary form must reproduce the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer in the documentation and/or other materials\n *        provided with the distribution.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <net/sock.h>\n#include <linux/in.h>\n#include <linux/export.h>\n#include <linux/time.h>\n#include <linux/rds.h>\n\n#include \"rds.h\"\n\nvoid rds_inc_init(struct rds_incoming *inc, struct rds_connection *conn,\n\t\t  __be32 saddr)\n{\n\tatomic_set(&inc->i_refcount, 1);\n\tINIT_LIST_HEAD(&inc->i_item);\n\tinc->i_conn = conn;\n\tinc->i_saddr = saddr;\n\tinc->i_rdma_cookie = 0;\n\tinc->i_rx_tstamp.tv_sec = 0;\n\tinc->i_rx_tstamp.tv_usec = 0;\n}\nEXPORT_SYMBOL_GPL(rds_inc_init);\n\nstatic void rds_inc_addref(struct rds_incoming *inc)\n{\n\trdsdebug(\"addref inc %p ref %d\\n\", inc, atomic_read(&inc->i_refcount));\n\tatomic_inc(&inc->i_refcount);\n}\n\nvoid rds_inc_put(struct rds_incoming *inc)\n{\n\trdsdebug(\"put inc %p ref %d\\n\", inc, atomic_read(&inc->i_refcount));\n\tif (atomic_dec_and_test(&inc->i_refcount)) {\n\t\tBUG_ON(!list_empty(&inc->i_item));\n\n\t\tinc->i_conn->c_trans->inc_free(inc);\n\t}\n}\nEXPORT_SYMBOL_GPL(rds_inc_put);\n\nstatic void rds_recv_rcvbuf_delta(struct rds_sock *rs, struct sock *sk,\n\t\t\t\t  struct rds_cong_map *map,\n\t\t\t\t  int delta, __be16 port)\n{\n\tint now_congested;\n\n\tif (delta == 0)\n\t\treturn;\n\n\trs->rs_rcv_bytes += delta;\n\tnow_congested = rs->rs_rcv_bytes > rds_sk_rcvbuf(rs);\n\n\trdsdebug(\"rs %p (%pI4:%u) recv bytes %d buf %d \"\n\t  \"now_cong %d delta %d\\n\",\n\t  rs, &rs->rs_bound_addr,\n\t  ntohs(rs->rs_bound_port), rs->rs_rcv_bytes,\n\t  rds_sk_rcvbuf(rs), now_congested, delta);\n\n\t/* wasn't -> am congested */\n\tif (!rs->rs_congested && now_congested) {\n\t\trs->rs_congested = 1;\n\t\trds_cong_set_bit(map, port);\n\t\trds_cong_queue_updates(map);\n\t}\n\t/* was -> aren't congested */\n\t/* Require more free space before reporting uncongested to prevent\n\t   bouncing cong/uncong state too often */\n\telse if (rs->rs_congested && (rs->rs_rcv_bytes < (rds_sk_rcvbuf(rs)/2))) {\n\t\trs->rs_congested = 0;\n\t\trds_cong_clear_bit(map, port);\n\t\trds_cong_queue_updates(map);\n\t}\n\n\t/* do nothing if no change in cong state */\n}\n\n/*\n * Process all extension headers that come with this message.\n */\nstatic void rds_recv_incoming_exthdrs(struct rds_incoming *inc, struct rds_sock *rs)\n{\n\tstruct rds_header *hdr = &inc->i_hdr;\n\tunsigned int pos = 0, type, len;\n\tunion {\n\t\tstruct rds_ext_header_version version;\n\t\tstruct rds_ext_header_rdma rdma;\n\t\tstruct rds_ext_header_rdma_dest rdma_dest;\n\t} buffer;\n\n\twhile (1) {\n\t\tlen = sizeof(buffer);\n\t\ttype = rds_message_next_extension(hdr, &pos, &buffer, &len);\n\t\tif (type == RDS_EXTHDR_NONE)\n\t\t\tbreak;\n\t\t/* Process extension header here */\n\t\tswitch (type) {\n\t\tcase RDS_EXTHDR_RDMA:\n\t\t\trds_rdma_unuse(rs, be32_to_cpu(buffer.rdma.h_rdma_rkey), 0);\n\t\t\tbreak;\n\n\t\tcase RDS_EXTHDR_RDMA_DEST:\n\t\t\t/* We ignore the size for now. We could stash it\n\t\t\t * somewhere and use it for error checking. */\n\t\t\tinc->i_rdma_cookie = rds_rdma_make_cookie(\n\t\t\t\t\tbe32_to_cpu(buffer.rdma_dest.h_rdma_rkey),\n\t\t\t\t\tbe32_to_cpu(buffer.rdma_dest.h_rdma_offset));\n\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n/*\n * The transport must make sure that this is serialized against other\n * rx and conn reset on this specific conn.\n *\n * We currently assert that only one fragmented message will be sent\n * down a connection at a time.  This lets us reassemble in the conn\n * instead of per-flow which means that we don't have to go digging through\n * flows to tear down partial reassembly progress on conn failure and\n * we save flow lookup and locking for each frag arrival.  It does mean\n * that small messages will wait behind large ones.  Fragmenting at all\n * is only to reduce the memory consumption of pre-posted buffers.\n *\n * The caller passes in saddr and daddr instead of us getting it from the\n * conn.  This lets loopback, who only has one conn for both directions,\n * tell us which roles the addrs in the conn are playing for this message.\n */\nvoid rds_recv_incoming(struct rds_connection *conn, __be32 saddr, __be32 daddr,\n\t\t       struct rds_incoming *inc, gfp_t gfp)\n{\n\tstruct rds_sock *rs = NULL;\n\tstruct sock *sk;\n\tunsigned long flags;\n\n\tinc->i_conn = conn;\n\tinc->i_rx_jiffies = jiffies;\n\n\trdsdebug(\"conn %p next %llu inc %p seq %llu len %u sport %u dport %u \"\n\t\t \"flags 0x%x rx_jiffies %lu\\n\", conn,\n\t\t (unsigned long long)conn->c_next_rx_seq,\n\t\t inc,\n\t\t (unsigned long long)be64_to_cpu(inc->i_hdr.h_sequence),\n\t\t be32_to_cpu(inc->i_hdr.h_len),\n\t\t be16_to_cpu(inc->i_hdr.h_sport),\n\t\t be16_to_cpu(inc->i_hdr.h_dport),\n\t\t inc->i_hdr.h_flags,\n\t\t inc->i_rx_jiffies);\n\n\t/*\n\t * Sequence numbers should only increase.  Messages get their\n\t * sequence number as they're queued in a sending conn.  They\n\t * can be dropped, though, if the sending socket is closed before\n\t * they hit the wire.  So sequence numbers can skip forward\n\t * under normal operation.  They can also drop back in the conn\n\t * failover case as previously sent messages are resent down the\n\t * new instance of a conn.  We drop those, otherwise we have\n\t * to assume that the next valid seq does not come after a\n\t * hole in the fragment stream.\n\t *\n\t * The headers don't give us a way to realize if fragments of\n\t * a message have been dropped.  We assume that frags that arrive\n\t * to a flow are part of the current message on the flow that is\n\t * being reassembled.  This means that senders can't drop messages\n\t * from the sending conn until all their frags are sent.\n\t *\n\t * XXX we could spend more on the wire to get more robust failure\n\t * detection, arguably worth it to avoid data corruption.\n\t */\n\tif (be64_to_cpu(inc->i_hdr.h_sequence) < conn->c_next_rx_seq &&\n\t    (inc->i_hdr.h_flags & RDS_FLAG_RETRANSMITTED)) {\n\t\trds_stats_inc(s_recv_drop_old_seq);\n\t\tgoto out;\n\t}\n\tconn->c_next_rx_seq = be64_to_cpu(inc->i_hdr.h_sequence) + 1;\n\n\tif (rds_sysctl_ping_enable && inc->i_hdr.h_dport == 0) {\n\t\trds_stats_inc(s_recv_ping);\n\t\trds_send_pong(conn, inc->i_hdr.h_sport);\n\t\tgoto out;\n\t}\n\n\trs = rds_find_bound(daddr, inc->i_hdr.h_dport);\n\tif (!rs) {\n\t\trds_stats_inc(s_recv_drop_no_sock);\n\t\tgoto out;\n\t}\n\n\t/* Process extension headers */\n\trds_recv_incoming_exthdrs(inc, rs);\n\n\t/* We can be racing with rds_release() which marks the socket dead. */\n\tsk = rds_rs_to_sk(rs);\n\n\t/* serialize with rds_release -> sock_orphan */\n\twrite_lock_irqsave(&rs->rs_recv_lock, flags);\n\tif (!sock_flag(sk, SOCK_DEAD)) {\n\t\trdsdebug(\"adding inc %p to rs %p's recv queue\\n\", inc, rs);\n\t\trds_stats_inc(s_recv_queued);\n\t\trds_recv_rcvbuf_delta(rs, sk, inc->i_conn->c_lcong,\n\t\t\t\t      be32_to_cpu(inc->i_hdr.h_len),\n\t\t\t\t      inc->i_hdr.h_dport);\n\t\tif (sock_flag(sk, SOCK_RCVTSTAMP))\n\t\t\tdo_gettimeofday(&inc->i_rx_tstamp);\n\t\trds_inc_addref(inc);\n\t\tlist_add_tail(&inc->i_item, &rs->rs_recv_queue);\n\t\t__rds_wake_sk_sleep(sk);\n\t} else {\n\t\trds_stats_inc(s_recv_drop_dead_sock);\n\t}\n\twrite_unlock_irqrestore(&rs->rs_recv_lock, flags);\n\nout:\n\tif (rs)\n\t\trds_sock_put(rs);\n}\nEXPORT_SYMBOL_GPL(rds_recv_incoming);\n\n/*\n * be very careful here.  This is being called as the condition in\n * wait_event_*() needs to cope with being called many times.\n */\nstatic int rds_next_incoming(struct rds_sock *rs, struct rds_incoming **inc)\n{\n\tunsigned long flags;\n\n\tif (!*inc) {\n\t\tread_lock_irqsave(&rs->rs_recv_lock, flags);\n\t\tif (!list_empty(&rs->rs_recv_queue)) {\n\t\t\t*inc = list_entry(rs->rs_recv_queue.next,\n\t\t\t\t\t  struct rds_incoming,\n\t\t\t\t\t  i_item);\n\t\t\trds_inc_addref(*inc);\n\t\t}\n\t\tread_unlock_irqrestore(&rs->rs_recv_lock, flags);\n\t}\n\n\treturn *inc != NULL;\n}\n\nstatic int rds_still_queued(struct rds_sock *rs, struct rds_incoming *inc,\n\t\t\t    int drop)\n{\n\tstruct sock *sk = rds_rs_to_sk(rs);\n\tint ret = 0;\n\tunsigned long flags;\n\n\twrite_lock_irqsave(&rs->rs_recv_lock, flags);\n\tif (!list_empty(&inc->i_item)) {\n\t\tret = 1;\n\t\tif (drop) {\n\t\t\t/* XXX make sure this i_conn is reliable */\n\t\t\trds_recv_rcvbuf_delta(rs, sk, inc->i_conn->c_lcong,\n\t\t\t\t\t      -be32_to_cpu(inc->i_hdr.h_len),\n\t\t\t\t\t      inc->i_hdr.h_dport);\n\t\t\tlist_del_init(&inc->i_item);\n\t\t\trds_inc_put(inc);\n\t\t}\n\t}\n\twrite_unlock_irqrestore(&rs->rs_recv_lock, flags);\n\n\trdsdebug(\"inc %p rs %p still %d dropped %d\\n\", inc, rs, ret, drop);\n\treturn ret;\n}\n\n/*\n * Pull errors off the error queue.\n * If msghdr is NULL, we will just purge the error queue.\n */\nint rds_notify_queue_get(struct rds_sock *rs, struct msghdr *msghdr)\n{\n\tstruct rds_notifier *notifier;\n\tstruct rds_rdma_notify cmsg = { 0 }; /* fill holes with zero */\n\tunsigned int count = 0, max_messages = ~0U;\n\tunsigned long flags;\n\tLIST_HEAD(copy);\n\tint err = 0;\n\n\n\t/* put_cmsg copies to user space and thus may sleep. We can't do this\n\t * with rs_lock held, so first grab as many notifications as we can stuff\n\t * in the user provided cmsg buffer. We don't try to copy more, to avoid\n\t * losing notifications - except when the buffer is so small that it wouldn't\n\t * even hold a single notification. Then we give him as much of this single\n\t * msg as we can squeeze in, and set MSG_CTRUNC.\n\t */\n\tif (msghdr) {\n\t\tmax_messages = msghdr->msg_controllen / CMSG_SPACE(sizeof(cmsg));\n\t\tif (!max_messages)\n\t\t\tmax_messages = 1;\n\t}\n\n\tspin_lock_irqsave(&rs->rs_lock, flags);\n\twhile (!list_empty(&rs->rs_notify_queue) && count < max_messages) {\n\t\tnotifier = list_entry(rs->rs_notify_queue.next,\n\t\t\t\tstruct rds_notifier, n_list);\n\t\tlist_move(&notifier->n_list, &copy);\n\t\tcount++;\n\t}\n\tspin_unlock_irqrestore(&rs->rs_lock, flags);\n\n\tif (!count)\n\t\treturn 0;\n\n\twhile (!list_empty(&copy)) {\n\t\tnotifier = list_entry(copy.next, struct rds_notifier, n_list);\n\n\t\tif (msghdr) {\n\t\t\tcmsg.user_token = notifier->n_user_token;\n\t\t\tcmsg.status = notifier->n_status;\n\n\t\t\terr = put_cmsg(msghdr, SOL_RDS, RDS_CMSG_RDMA_STATUS,\n\t\t\t\t       sizeof(cmsg), &cmsg);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tlist_del_init(&notifier->n_list);\n\t\tkfree(notifier);\n\t}\n\n\t/* If we bailed out because of an error in put_cmsg,\n\t * we may be left with one or more notifications that we\n\t * didn't process. Return them to the head of the list. */\n\tif (!list_empty(&copy)) {\n\t\tspin_lock_irqsave(&rs->rs_lock, flags);\n\t\tlist_splice(&copy, &rs->rs_notify_queue);\n\t\tspin_unlock_irqrestore(&rs->rs_lock, flags);\n\t}\n\n\treturn err;\n}\n\n/*\n * Queue a congestion notification\n */\nstatic int rds_notify_cong(struct rds_sock *rs, struct msghdr *msghdr)\n{\n\tuint64_t notify = rs->rs_cong_notify;\n\tunsigned long flags;\n\tint err;\n\n\terr = put_cmsg(msghdr, SOL_RDS, RDS_CMSG_CONG_UPDATE,\n\t\t\tsizeof(notify), &notify);\n\tif (err)\n\t\treturn err;\n\n\tspin_lock_irqsave(&rs->rs_lock, flags);\n\trs->rs_cong_notify &= ~notify;\n\tspin_unlock_irqrestore(&rs->rs_lock, flags);\n\n\treturn 0;\n}\n\n/*\n * Receive any control messages.\n */\nstatic int rds_cmsg_recv(struct rds_incoming *inc, struct msghdr *msg,\n\t\t\t struct rds_sock *rs)\n{\n\tint ret = 0;\n\n\tif (inc->i_rdma_cookie) {\n\t\tret = put_cmsg(msg, SOL_RDS, RDS_CMSG_RDMA_DEST,\n\t\t\t\tsizeof(inc->i_rdma_cookie), &inc->i_rdma_cookie);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif ((inc->i_rx_tstamp.tv_sec != 0) &&\n\t    sock_flag(rds_rs_to_sk(rs), SOCK_RCVTSTAMP)) {\n\t\tret = put_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMP,\n\t\t\t       sizeof(struct timeval),\n\t\t\t       &inc->i_rx_tstamp);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint rds_recvmsg(struct socket *sock, struct msghdr *msg, size_t size,\n\t\tint msg_flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct rds_sock *rs = rds_sk_to_rs(sk);\n\tlong timeo;\n\tint ret = 0, nonblock = msg_flags & MSG_DONTWAIT;\n\tDECLARE_SOCKADDR(struct sockaddr_in *, sin, msg->msg_name);\n\tstruct rds_incoming *inc = NULL;\n\n\t/* udp_recvmsg()->sock_recvtimeo() gets away without locking too.. */\n\ttimeo = sock_rcvtimeo(sk, nonblock);\n\n\trdsdebug(\"size %zu flags 0x%x timeo %ld\\n\", size, msg_flags, timeo);\n\n\tif (msg_flags & MSG_OOB)\n\t\tgoto out;\n\n\twhile (1) {\n\t\tstruct iov_iter save;\n\t\t/* If there are pending notifications, do those - and nothing else */\n\t\tif (!list_empty(&rs->rs_notify_queue)) {\n\t\t\tret = rds_notify_queue_get(rs, msg);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (rs->rs_cong_notify) {\n\t\t\tret = rds_notify_cong(rs, msg);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!rds_next_incoming(rs, &inc)) {\n\t\t\tif (nonblock) {\n\t\t\t\tret = -EAGAIN;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\ttimeo = wait_event_interruptible_timeout(*sk_sleep(sk),\n\t\t\t\t\t(!list_empty(&rs->rs_notify_queue) ||\n\t\t\t\t\t rs->rs_cong_notify ||\n\t\t\t\t\t rds_next_incoming(rs, &inc)), timeo);\n\t\t\trdsdebug(\"recvmsg woke inc %p timeo %ld\\n\", inc,\n\t\t\t\t timeo);\n\t\t\tif (timeo > 0 || timeo == MAX_SCHEDULE_TIMEOUT)\n\t\t\t\tcontinue;\n\n\t\t\tret = timeo;\n\t\t\tif (ret == 0)\n\t\t\t\tret = -ETIMEDOUT;\n\t\t\tbreak;\n\t\t}\n\n\t\trdsdebug(\"copying inc %p from %pI4:%u to user\\n\", inc,\n\t\t\t &inc->i_conn->c_faddr,\n\t\t\t ntohs(inc->i_hdr.h_sport));\n\t\tsave = msg->msg_iter;\n\t\tret = inc->i_conn->c_trans->inc_copy_to_user(inc, &msg->msg_iter);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * if the message we just copied isn't at the head of the\n\t\t * recv queue then someone else raced us to return it, try\n\t\t * to get the next message.\n\t\t */\n\t\tif (!rds_still_queued(rs, inc, !(msg_flags & MSG_PEEK))) {\n\t\t\trds_inc_put(inc);\n\t\t\tinc = NULL;\n\t\t\trds_stats_inc(s_recv_deliver_raced);\n\t\t\tmsg->msg_iter = save;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (ret < be32_to_cpu(inc->i_hdr.h_len)) {\n\t\t\tif (msg_flags & MSG_TRUNC)\n\t\t\t\tret = be32_to_cpu(inc->i_hdr.h_len);\n\t\t\tmsg->msg_flags |= MSG_TRUNC;\n\t\t}\n\n\t\tif (rds_cmsg_recv(inc, msg, rs)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\trds_stats_inc(s_recv_delivered);\n\n\t\tif (sin) {\n\t\t\tsin->sin_family = AF_INET;\n\t\t\tsin->sin_port = inc->i_hdr.h_sport;\n\t\t\tsin->sin_addr.s_addr = inc->i_saddr;\n\t\t\tmemset(sin->sin_zero, 0, sizeof(sin->sin_zero));\n\t\t\tmsg->msg_namelen = sizeof(*sin);\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (inc)\n\t\trds_inc_put(inc);\n\nout:\n\treturn ret;\n}\n\n/*\n * The socket is being shut down and we're asked to drop messages that were\n * queued for recvmsg.  The caller has unbound the socket so the receive path\n * won't queue any more incoming fragments or messages on the socket.\n */\nvoid rds_clear_recv_queue(struct rds_sock *rs)\n{\n\tstruct sock *sk = rds_rs_to_sk(rs);\n\tstruct rds_incoming *inc, *tmp;\n\tunsigned long flags;\n\n\twrite_lock_irqsave(&rs->rs_recv_lock, flags);\n\tlist_for_each_entry_safe(inc, tmp, &rs->rs_recv_queue, i_item) {\n\t\trds_recv_rcvbuf_delta(rs, sk, inc->i_conn->c_lcong,\n\t\t\t\t      -be32_to_cpu(inc->i_hdr.h_len),\n\t\t\t\t      inc->i_hdr.h_dport);\n\t\tlist_del_init(&inc->i_item);\n\t\trds_inc_put(inc);\n\t}\n\twrite_unlock_irqrestore(&rs->rs_recv_lock, flags);\n}\n\n/*\n * inc->i_saddr isn't used here because it is only set in the receive\n * path.\n */\nvoid rds_inc_info_copy(struct rds_incoming *inc,\n\t\t       struct rds_info_iterator *iter,\n\t\t       __be32 saddr, __be32 daddr, int flip)\n{\n\tstruct rds_info_message minfo;\n\n\tminfo.seq = be64_to_cpu(inc->i_hdr.h_sequence);\n\tminfo.len = be32_to_cpu(inc->i_hdr.h_len);\n\n\tif (flip) {\n\t\tminfo.laddr = daddr;\n\t\tminfo.faddr = saddr;\n\t\tminfo.lport = inc->i_hdr.h_dport;\n\t\tminfo.fport = inc->i_hdr.h_sport;\n\t} else {\n\t\tminfo.laddr = saddr;\n\t\tminfo.faddr = daddr;\n\t\tminfo.lport = inc->i_hdr.h_sport;\n\t\tminfo.fport = inc->i_hdr.h_dport;\n\t}\n\n\tminfo.flags = 0;\n\n\trds_info_copy(iter, &minfo, sizeof(minfo));\n}\n"], "filenames": ["net/rds/recv.c"], "buggy_code_start_loc": [563], "buggy_code_end_loc": [563], "fixing_code_start_loc": [564], "fixing_code_end_loc": [566], "type": "CWE-200", "message": "The rds_inc_info_copy function in net/rds/recv.c in the Linux kernel through 4.6.3 does not initialize a certain structure member, which allows remote attackers to obtain sensitive information from kernel stack memory by reading an RDS message.", "other": {"cve": {"id": "CVE-2016-5244", "sourceIdentifier": "cve@mitre.org", "published": "2016-06-27T10:59:11.157", "lastModified": "2019-04-22T17:48:00.643", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The rds_inc_info_copy function in net/rds/recv.c in the Linux kernel through 4.6.3 does not initialize a certain structure member, which allows remote attackers to obtain sensitive information from kernel stack memory by reading an RDS message."}, {"lang": "es", "value": "La funci\u00f3n rds_inc_info_copy en net/rds/recv.c en el kernel de Linux hasta la versi\u00f3n 4.6.3 no inicializa un cierto miembro de estructura, lo que permite a atacantes remotos obtener informaci\u00f3n sensible de la memoria de pila del kernel leyendo un mensaje RDS."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-200"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:23:*:*:*:*:*:*:*", "matchCriteriaId": "E79AB8DD-C907-4038-A931-1A5A4CFB6A5B"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_real_time_extension:11:sp4:*:*:*:*:*:*", "matchCriteriaId": "99A38379-DBD3-4BF6-9A8F-95A3F553AD02"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:24:*:*:*:*:*:*:*", "matchCriteriaId": "C729D5D1-ED95-443A-9F53-5D7C2FD9B80C"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:suse:linux_enterprise_debuginfo:11:sp4:*:*:*:*:*:*", "matchCriteriaId": "F892F1B0-514C-42F7-90AE-12ACDFDC1033"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_real_time_extension:12:sp1:*:*:*:*:*:*", "matchCriteriaId": "18D823E3-E1F3-4A15-A9C7-1AB61C1B6703"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_server:11:extra:*:*:*:*:*:*", "matchCriteriaId": "AD1AEFA5-9D43-4DD2-9088-7B37D5F220C4"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:6.0:*:*:*:*:*:*:*", "matchCriteriaId": "2F6AB192-9D7D-4A9A-8995-E53A9DE9EAFC"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:suse:suse_linux_enterprise_software_development_kit:11:sp4:*:*:*:*:*:*", "matchCriteriaId": "CF719D1A-AA3A-42C9-9568-07DD4DB27A4B"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_workstation_extension:12:*:*:*:*:*:*:*", "matchCriteriaId": "9DFA18B6-2642-470A-A350-68947529EE5D"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:5:*:*:*:*:*:*:*", "matchCriteriaId": "AA9B3CC0-DF1C-4A86-B2A3-A9D428A5A6E6"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_desktop:12:*:*:*:*:*:*:*", "matchCriteriaId": "F1EB0F28-F23A-4969-8A3E-66DA2EFA40C3"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:suse:opensuse_leap:42.1:*:*:*:*:*:*:*", "matchCriteriaId": "4C3C4A93-990D-4E77-B998-6AA045CE6187"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_server:11:sp4:*:*:*:*:*:*", "matchCriteriaId": "55C5561F-BE86-4EEA-99D4-8697F8BD9DFE"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:suse:suse_linux_enterprise_software_development_kit:12:*:*:*:*:*:*:*", "matchCriteriaId": "D68314F2-4372-4215-8D5C-10A75BC8188D"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:22:*:*:*:*:*:*:*", "matchCriteriaId": "253C303A-E577-4488-93E6-68A8DD942C38"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "4.6.3", "matchCriteriaId": "FC099084-12C9-4396-ABC7-F389CFAD871E"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:suse:suse_linux_enterprise_server:12:*:*:*:*:*:*:*", "matchCriteriaId": "9C649194-B8C2-49F7-A819-C635EE584ABF"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=4116def2337991b39919f3b448326e21c40e0dbb", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-06/msg00044.html", "source": "cve@mitre.org"}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-06/msg00052.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-06/msg00054.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00000.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00007.html", "source": "cve@mitre.org"}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00044.html", "source": "cve@mitre.org"}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00055.html", "source": "cve@mitre.org"}, {"url": "http://www.debian.org/security/2016/dsa-3607", "source": "cve@mitre.org"}, {"url": "http://www.openwall.com/lists/oss-security/2016/06/03/5", "source": "cve@mitre.org", "tags": ["Mailing List", "Technical Description"]}, {"url": "http://www.oracle.com/technetwork/security-advisory/cpuoct2018-4428296.html", "source": "cve@mitre.org"}, {"url": "http://www.securityfocus.com/bid/91021", "source": "cve@mitre.org"}, {"url": "http://www.securitytracker.com/id/1041895", "source": "cve@mitre.org"}, {"url": "http://www.ubuntu.com/usn/USN-3070-1", "source": "cve@mitre.org"}, {"url": "http://www.ubuntu.com/usn/USN-3070-2", "source": "cve@mitre.org"}, {"url": "http://www.ubuntu.com/usn/USN-3070-3", "source": "cve@mitre.org"}, {"url": "http://www.ubuntu.com/usn/USN-3070-4", "source": "cve@mitre.org"}, {"url": "http://www.ubuntu.com/usn/USN-3071-1", "source": "cve@mitre.org"}, {"url": "http://www.ubuntu.com/usn/USN-3071-2", "source": "cve@mitre.org"}, {"url": "http://www.ubuntu.com/usn/USN-3072-1", "source": "cve@mitre.org"}, {"url": "http://www.ubuntu.com/usn/USN-3072-2", "source": "cve@mitre.org"}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1343337", "source": "cve@mitre.org", "tags": ["Issue Tracking"]}, {"url": "https://github.com/torvalds/linux/commit/4116def2337991b39919f3b448326e21c40e0dbb", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://patchwork.ozlabs.org/patch/629110/", "source": "cve@mitre.org", "tags": ["Patch"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/4116def2337991b39919f3b448326e21c40e0dbb"}}
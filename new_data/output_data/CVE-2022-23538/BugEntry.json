{"buggy_code": ["// Copyright (c) 2018-2021, Sylabs Inc. All rights reserved.\n// This software is licensed under a 3-clause BSD license. Please consult the\n// LICENSE.md file distributed with the sources of this project regarding your\n// rights to use or distribute this software.\n\npackage client\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\n\tjsonresp \"github.com/sylabs/json-resp\"\n\t\"golang.org/x/sync/errgroup\"\n)\n\n// DownloadImage will retrieve an image from the Container Library, saving it\n// into the specified io.Writer. The timeout value for this operation is set\n// within the context. It is recommended to use a large value (ie. 1800 seconds)\n// to prevent timeout when downloading large images.\nfunc (c *Client) DownloadImage(ctx context.Context, w io.Writer, arch, path, tag string, callback func(int64, io.Reader, io.Writer) error) error {\n\tif arch != \"\" && !c.apiAtLeast(ctx, APIVersionV2ArchTags) {\n\t\tc.Logger.Logf(\"This library does not support architecture specific tags\")\n\t\tc.Logger.Logf(\"The image returned may not be the requested architecture\")\n\t}\n\n\tif strings.Contains(path, \":\") {\n\t\treturn fmt.Errorf(\"malformed image path: %s\", path)\n\t}\n\n\tif tag == \"\" {\n\t\ttag = \"latest\"\n\t}\n\n\tapiPath := fmt.Sprintf(\"v1/imagefile/%s:%s\", strings.TrimPrefix(path, \"/\"), tag)\n\tq := url.Values{}\n\tq.Add(\"arch\", arch)\n\n\tc.Logger.Logf(\"Pulling from URL: %s\", apiPath)\n\n\treq, err := c.newRequest(ctx, http.MethodGet, apiPath, q.Encode(), nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tres, err := c.HTTPClient.Do(req)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer res.Body.Close()\n\n\tif res.StatusCode == http.StatusNotFound {\n\t\treturn fmt.Errorf(\"requested image was not found in the library\")\n\t}\n\n\tif res.StatusCode != http.StatusOK {\n\t\terr := jsonresp.ReadError(res.Body)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"download did not succeed: %v\", err)\n\t\t}\n\t\treturn fmt.Errorf(\"unexpected http status code: %d\", res.StatusCode)\n\t}\n\n\tc.Logger.Logf(\"OK response received, beginning body download\")\n\n\tif callback != nil {\n\t\terr = callback(res.ContentLength, res.Body, w)\n\t} else {\n\t\t_, err = io.Copy(w, res.Body)\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.Logger.Logf(\"Download complete\")\n\n\treturn nil\n}\n\n// partSpec defines one part of multi-part (concurrent) download.\ntype partSpec struct {\n\tStart      int64\n\tEnd        int64\n\tBufferSize int64\n}\n\n// Downloader defines concurrency (# of requests) and part size for download operation.\ntype Downloader struct {\n\t// Concurrency defines concurrency for multi-part downloads.\n\tConcurrency uint\n\n\t// PartSize specifies size of part for multi-part downloads. Default is 5 MiB.\n\tPartSize int64\n\n\t// BufferSize specifies buffer size used for multi-part downloader routine.\n\t// Default is 32 KiB.\n\tBufferSize int64\n}\n\n// httpGetRangeRequest performs HTTP GET range request to URL specified by 'u' in range start-end.\nfunc (c *Client) httpGetRangeRequest(ctx context.Context, url string, start, end int64) (*http.Response, error) {\n\treq, err := c.newRequestWithURL(ctx, http.MethodGet, url, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treq.Header.Add(\"Range\", fmt.Sprintf(\"bytes=%d-%d\", start, end))\n\n\treturn c.HTTPClient.Do(req)\n}\n\n// downloadFilePart writes range to dst as specified in bufferSpec.\nfunc (c *Client) downloadFilePart(ctx context.Context, dst *os.File, url string, ps *partSpec, pb ProgressBar) error {\n\tresp, err := c.httpGetRangeRequest(ctx, url, ps.Start, ps.End)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer resp.Body.Close()\n\n\t// allocate transfer buffer for part\n\tbuf := make([]byte, ps.BufferSize)\n\n\tfor bytesRead := int64(0); bytesRead < ps.End-ps.Start+1; {\n\t\tn, err := io.ReadFull(resp.Body, buf)\n\n\t\t// EOF and unexpected EOF shouldn't be handled as errors since short\n\t\t// reads are expected if the part size is less than buffer size e.g.\n\t\t// the last part if part isn't on size boundary.\n\t\tif err != nil && n == 0 {\n\t\t\treturn err\n\t\t}\n\n\t\tpb.IncrBy(n)\n\n\t\t// WriteAt() is a wrapper around pwrite() which is an atomic\n\t\t// seek-and-write operation.\n\t\tif _, err := dst.WriteAt(buf[:n], ps.Start+bytesRead); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tbytesRead += int64(n)\n\t}\n\treturn nil\n}\n\n// downloadWorker is a worker func for processing jobs in stripes channel.\nfunc (c *Client) downloadWorker(ctx context.Context, dst *os.File, url string, parts <-chan partSpec, pb ProgressBar) func() error {\n\treturn func() error {\n\t\tfor ps := range parts {\n\t\t\tif err := c.downloadFilePart(ctx, dst, url, &ps, pb); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n}\n\nfunc (c *Client) getContentLength(ctx context.Context, url string) (int64, error) {\n\t// Perform short request to determine content length.\n\tresp, err := c.httpGetRangeRequest(ctx, url, 0, 1024)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusPartialContent {\n\t\tif resp.StatusCode == http.StatusNotFound {\n\t\t\treturn 0, fmt.Errorf(\"requested image was not found in the library\")\n\t\t}\n\t\treturn 0, fmt.Errorf(\"unexpected HTTP status: %d\", resp.StatusCode)\n\t}\n\n\tvals := strings.Split(resp.Header.Get(\"Content-Range\"), \"/\")\n\treturn strconv.ParseInt(vals[1], 0, 64)\n}\n\n// NoopProgressBar implements ProgressBarInterface to allow disabling the progress bar\ntype NoopProgressBar struct{}\n\n// Init is a no-op\nfunc (*NoopProgressBar) Init(int64) {}\n\n// ProxyReader is a no-op\nfunc (*NoopProgressBar) ProxyReader(r io.Reader) io.ReadCloser { return io.NopCloser(r) }\n\n// IncrBy is a no-op\nfunc (*NoopProgressBar) IncrBy(int) {}\n\n// Abort is a no-op\nfunc (*NoopProgressBar) Abort(bool) {}\n\n// Wait is a no-op\nfunc (*NoopProgressBar) Wait() {}\n\n// ProgressBar provides a minimal interface for interacting with a progress bar.\n// Init is called prior to concurrent download operation.\ntype ProgressBar interface {\n\t// Initialize progress bar. Argument is size of file to set progress bar limit.\n\tInit(int64)\n\n\t// ProxyReader wraps r with metrics required for progress tracking. Only useful for\n\t// single stream downloads.\n\tProxyReader(io.Reader) io.ReadCloser\n\n\t// IncrBy increments the progress bar. It is called after each concurrent\n\t// buffer transfer.\n\tIncrBy(int)\n\n\t// Abort terminates the progress bar.\n\tAbort(bool)\n\n\t// Wait waits for the progress bar to complete.\n\tWait()\n}\n\n// ConcurrentDownloadImage implements a multi-part (concurrent) downloader for\n// Cloud Library images. spec is used to define transfer parameters. pb is an\n// optional progress bar interface.  If pb is nil, NoopProgressBar is used.\n//\n// The downloader will handle source files of all sizes and is not limited to\n// only files larger than Downloader.PartSize. It will automatically adjust the\n// concurrency for source files that do not meet minimum size for multi-part\n// downloads.\nfunc (c *Client) ConcurrentDownloadImage(ctx context.Context, dst *os.File, arch, path, tag string, spec *Downloader, pb ProgressBar) error {\n\tif pb == nil {\n\t\tpb = &NoopProgressBar{}\n\t}\n\n\tif arch != \"\" && !c.apiAtLeast(ctx, APIVersionV2ArchTags) {\n\t\tc.Logger.Logf(\"This library does not support architecture specific tags\")\n\t\tc.Logger.Logf(\"The image returned may not be the requested architecture\")\n\t}\n\n\tif strings.Contains(path, \":\") {\n\t\treturn fmt.Errorf(\"malformed image path: %s\", path)\n\t}\n\n\tif tag == \"\" {\n\t\ttag = \"latest\"\n\t}\n\n\tapiPath := fmt.Sprintf(\"v1/imagefile/%s:%s\", strings.TrimPrefix(path, \"/\"), tag)\n\tq := url.Values{}\n\tq.Add(\"arch\", arch)\n\n\tc.Logger.Logf(\"Pulling from URL: %s\", apiPath)\n\n\tcustomHTTPClient := &http.Client{\n\t\tTransport: c.HTTPClient.Transport,\n\t\tCheckRedirect: func(req *http.Request, via []*http.Request) error {\n\t\t\tif req.Response.StatusCode == http.StatusSeeOther {\n\t\t\t\treturn http.ErrUseLastResponse\n\t\t\t}\n\t\t\tmaxRedir := 10\n\t\t\tif len(via) >= maxRedir {\n\t\t\t\treturn fmt.Errorf(\"stopped after %d redirects\", maxRedir)\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t\tJar:     c.HTTPClient.Jar,\n\t\tTimeout: c.HTTPClient.Timeout,\n\t}\n\n\treq, err := c.newRequest(ctx, http.MethodGet, apiPath, q.Encode(), nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tres, err := customHTTPClient.Do(req)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer res.Body.Close()\n\n\tif res.StatusCode == http.StatusNotFound {\n\t\treturn fmt.Errorf(\"requested image was not found in the library\")\n\t}\n\n\tif res.StatusCode == http.StatusOK {\n\t\t// Library endpoint does not provide HTTP redirection response, treat as single stream, direct download\n\t\tc.Logger.Logf(\"Library endpoint does not support concurrent downloads; reverting to single stream\")\n\n\t\treturn c.singleStreamDownload(ctx, dst, res, pb)\n\t}\n\n\tif res.StatusCode != http.StatusSeeOther {\n\t\treturn fmt.Errorf(\"unexpected HTTP status %d: %v\", res.StatusCode, err)\n\t}\n\n\turl := res.Header.Get(\"Location\")\n\n\tcontentLength, err := c.getContentLength(ctx, url)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnumParts := uint(1 + (contentLength-1)/spec.PartSize)\n\n\tc.Logger.Logf(\"size: %d, parts: %d, concurrency: %d, partsize: %d, bufsize: %d\",\n\t\tcontentLength, numParts, spec.Concurrency, spec.PartSize, spec.BufferSize,\n\t)\n\n\tjobs := make(chan partSpec, numParts)\n\n\tg, ctx := errgroup.WithContext(ctx)\n\n\t// initialize progress bar\n\tpb.Init(contentLength)\n\n\t// if spec.Requests is greater than number of parts for requested file,\n\t// set concurrency to number of parts\n\tconcurrency := spec.Concurrency\n\tif numParts < spec.Concurrency {\n\t\tconcurrency = numParts\n\t}\n\n\t// start workers to manage concurrent HTTP requests\n\tfor workerID := uint(0); workerID <= concurrency; workerID++ {\n\t\tg.Go(c.downloadWorker(ctx, dst, url, jobs, pb))\n\t}\n\n\t// iterate over parts, adding to job queue\n\tfor part := uint(0); part < numParts; part++ {\n\t\tpartSize := spec.PartSize\n\t\tif part == numParts-1 {\n\t\t\tpartSize = contentLength - int64(numParts-1)*spec.PartSize\n\t\t}\n\n\t\tps := partSpec{\n\t\t\tStart:      int64(part) * spec.PartSize,\n\t\t\tEnd:        int64(part)*spec.PartSize + partSize - 1,\n\t\t\tBufferSize: spec.BufferSize,\n\t\t}\n\n\t\tjobs <- ps\n\t}\n\n\tclose(jobs)\n\n\t// wait on errgroup\n\terr = g.Wait()\n\tif err != nil {\n\t\t// cancel/remove progress bar on error\n\t\tpb.Abort(true)\n\t}\n\n\t// wait on progress bar\n\tpb.Wait()\n\n\treturn err\n}\n\nfunc (c *Client) singleStreamDownload(ctx context.Context, fp *os.File, res *http.Response, pb ProgressBar) error {\n\tcontentLength := int64(-1)\n\tval := res.Header.Get(\"Content-Length\")\n\tif val != \"\" {\n\t\tvar err error\n\t\tif contentLength, err = strconv.ParseInt(val, 0, 64); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tpb.Init(contentLength)\n\n\tproxyReader := pb.ProxyReader(res.Body)\n\tdefer proxyReader.Close()\n\n\tif _, err := io.Copy(fp, proxyReader); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n"], "fixing_code": ["// Copyright (c) 2018-2021, Sylabs Inc. All rights reserved.\n// This software is licensed under a 3-clause BSD license. Please consult the\n// LICENSE.md file distributed with the sources of this project regarding your\n// rights to use or distribute this software.\n\npackage client\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\n\tjsonresp \"github.com/sylabs/json-resp\"\n\t\"golang.org/x/sync/errgroup\"\n)\n\n// DownloadImage will retrieve an image from the Container Library, saving it\n// into the specified io.Writer. The timeout value for this operation is set\n// within the context. It is recommended to use a large value (ie. 1800 seconds)\n// to prevent timeout when downloading large images.\nfunc (c *Client) DownloadImage(ctx context.Context, w io.Writer, arch, path, tag string, callback func(int64, io.Reader, io.Writer) error) error {\n\tif arch != \"\" && !c.apiAtLeast(ctx, APIVersionV2ArchTags) {\n\t\tc.Logger.Logf(\"This library does not support architecture specific tags\")\n\t\tc.Logger.Logf(\"The image returned may not be the requested architecture\")\n\t}\n\n\tif strings.Contains(path, \":\") {\n\t\treturn fmt.Errorf(\"malformed image path: %s\", path)\n\t}\n\n\tif tag == \"\" {\n\t\ttag = \"latest\"\n\t}\n\n\tapiPath := fmt.Sprintf(\"v1/imagefile/%s:%s\", strings.TrimPrefix(path, \"/\"), tag)\n\tq := url.Values{}\n\tq.Add(\"arch\", arch)\n\n\tc.Logger.Logf(\"Pulling from URL: %s\", apiPath)\n\n\treq, err := c.newRequest(ctx, http.MethodGet, apiPath, q.Encode(), nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tres, err := c.HTTPClient.Do(req)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer res.Body.Close()\n\n\tif res.StatusCode == http.StatusNotFound {\n\t\treturn fmt.Errorf(\"requested image was not found in the library\")\n\t}\n\n\tif res.StatusCode != http.StatusOK {\n\t\terr := jsonresp.ReadError(res.Body)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"download did not succeed: %v\", err)\n\t\t}\n\t\treturn fmt.Errorf(\"unexpected http status code: %d\", res.StatusCode)\n\t}\n\n\tc.Logger.Logf(\"OK response received, beginning body download\")\n\n\tif callback != nil {\n\t\terr = callback(res.ContentLength, res.Body, w)\n\t} else {\n\t\t_, err = io.Copy(w, res.Body)\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.Logger.Logf(\"Download complete\")\n\n\treturn nil\n}\n\n// partSpec defines one part of multi-part (concurrent) download.\ntype partSpec struct {\n\tStart      int64\n\tEnd        int64\n\tBufferSize int64\n}\n\n// Downloader defines concurrency (# of requests) and part size for download operation.\ntype Downloader struct {\n\t// Concurrency defines concurrency for multi-part downloads.\n\tConcurrency uint\n\n\t// PartSize specifies size of part for multi-part downloads. Default is 5 MiB.\n\tPartSize int64\n\n\t// BufferSize specifies buffer size used for multi-part downloader routine.\n\t// Default is 32 KiB.\n\tBufferSize int64\n}\n\n// httpGetRangeRequest performs HTTP GET range request to URL specified by 'u' in range start-end.\nfunc (c *Client) httpGetRangeRequest(ctx context.Context, url string, start, end int64) (*http.Response, error) {\n\treq, err := http.NewRequestWithContext(ctx, http.MethodGet, url, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif v := c.UserAgent; v != \"\" {\n\t\treq.Header.Set(\"User-Agent\", v)\n\t}\n\n\treq.Header.Add(\"Range\", fmt.Sprintf(\"bytes=%d-%d\", start, end))\n\n\treturn c.HTTPClient.Do(req)\n}\n\n// downloadFilePart writes range to dst as specified in bufferSpec.\nfunc (c *Client) downloadFilePart(ctx context.Context, dst *os.File, url string, ps *partSpec, pb ProgressBar) error {\n\tresp, err := c.httpGetRangeRequest(ctx, url, ps.Start, ps.End)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer resp.Body.Close()\n\n\t// allocate transfer buffer for part\n\tbuf := make([]byte, ps.BufferSize)\n\n\tfor bytesRead := int64(0); bytesRead < ps.End-ps.Start+1; {\n\t\tn, err := io.ReadFull(resp.Body, buf)\n\n\t\t// EOF and unexpected EOF shouldn't be handled as errors since short\n\t\t// reads are expected if the part size is less than buffer size e.g.\n\t\t// the last part if part isn't on size boundary.\n\t\tif err != nil && n == 0 {\n\t\t\treturn err\n\t\t}\n\n\t\tpb.IncrBy(n)\n\n\t\t// WriteAt() is a wrapper around pwrite() which is an atomic\n\t\t// seek-and-write operation.\n\t\tif _, err := dst.WriteAt(buf[:n], ps.Start+bytesRead); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tbytesRead += int64(n)\n\t}\n\treturn nil\n}\n\n// downloadWorker is a worker func for processing jobs in stripes channel.\nfunc (c *Client) downloadWorker(ctx context.Context, dst *os.File, url string, parts <-chan partSpec, pb ProgressBar) func() error {\n\treturn func() error {\n\t\tfor ps := range parts {\n\t\t\tif err := c.downloadFilePart(ctx, dst, url, &ps, pb); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n}\n\nfunc (c *Client) getContentLength(ctx context.Context, url string) (int64, error) {\n\t// Perform short request to determine content length.\n\tresp, err := c.httpGetRangeRequest(ctx, url, 0, 1024)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusPartialContent {\n\t\tif resp.StatusCode == http.StatusNotFound {\n\t\t\treturn 0, fmt.Errorf(\"requested image was not found in the library\")\n\t\t}\n\t\treturn 0, fmt.Errorf(\"unexpected HTTP status: %d\", resp.StatusCode)\n\t}\n\n\tvals := strings.Split(resp.Header.Get(\"Content-Range\"), \"/\")\n\treturn strconv.ParseInt(vals[1], 0, 64)\n}\n\n// NoopProgressBar implements ProgressBarInterface to allow disabling the progress bar\ntype NoopProgressBar struct{}\n\n// Init is a no-op\nfunc (*NoopProgressBar) Init(int64) {}\n\n// ProxyReader is a no-op\nfunc (*NoopProgressBar) ProxyReader(r io.Reader) io.ReadCloser { return io.NopCloser(r) }\n\n// IncrBy is a no-op\nfunc (*NoopProgressBar) IncrBy(int) {}\n\n// Abort is a no-op\nfunc (*NoopProgressBar) Abort(bool) {}\n\n// Wait is a no-op\nfunc (*NoopProgressBar) Wait() {}\n\n// ProgressBar provides a minimal interface for interacting with a progress bar.\n// Init is called prior to concurrent download operation.\ntype ProgressBar interface {\n\t// Initialize progress bar. Argument is size of file to set progress bar limit.\n\tInit(int64)\n\n\t// ProxyReader wraps r with metrics required for progress tracking. Only useful for\n\t// single stream downloads.\n\tProxyReader(io.Reader) io.ReadCloser\n\n\t// IncrBy increments the progress bar. It is called after each concurrent\n\t// buffer transfer.\n\tIncrBy(int)\n\n\t// Abort terminates the progress bar.\n\tAbort(bool)\n\n\t// Wait waits for the progress bar to complete.\n\tWait()\n}\n\n// ConcurrentDownloadImage implements a multi-part (concurrent) downloader for\n// Cloud Library images. spec is used to define transfer parameters. pb is an\n// optional progress bar interface.  If pb is nil, NoopProgressBar is used.\n//\n// The downloader will handle source files of all sizes and is not limited to\n// only files larger than Downloader.PartSize. It will automatically adjust the\n// concurrency for source files that do not meet minimum size for multi-part\n// downloads.\nfunc (c *Client) ConcurrentDownloadImage(ctx context.Context, dst *os.File, arch, path, tag string, spec *Downloader, pb ProgressBar) error {\n\tif pb == nil {\n\t\tpb = &NoopProgressBar{}\n\t}\n\n\tif arch != \"\" && !c.apiAtLeast(ctx, APIVersionV2ArchTags) {\n\t\tc.Logger.Logf(\"This library does not support architecture specific tags\")\n\t\tc.Logger.Logf(\"The image returned may not be the requested architecture\")\n\t}\n\n\tif strings.Contains(path, \":\") {\n\t\treturn fmt.Errorf(\"malformed image path: %s\", path)\n\t}\n\n\tif tag == \"\" {\n\t\ttag = \"latest\"\n\t}\n\n\tapiPath := fmt.Sprintf(\"v1/imagefile/%s:%s\", strings.TrimPrefix(path, \"/\"), tag)\n\tq := url.Values{}\n\tq.Add(\"arch\", arch)\n\n\tc.Logger.Logf(\"Pulling from URL: %s\", apiPath)\n\n\tcustomHTTPClient := &http.Client{\n\t\tTransport: c.HTTPClient.Transport,\n\t\tCheckRedirect: func(req *http.Request, via []*http.Request) error {\n\t\t\tif req.Response.StatusCode == http.StatusSeeOther {\n\t\t\t\treturn http.ErrUseLastResponse\n\t\t\t}\n\t\t\tmaxRedir := 10\n\t\t\tif len(via) >= maxRedir {\n\t\t\t\treturn fmt.Errorf(\"stopped after %d redirects\", maxRedir)\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t\tJar:     c.HTTPClient.Jar,\n\t\tTimeout: c.HTTPClient.Timeout,\n\t}\n\n\treq, err := c.newRequest(ctx, http.MethodGet, apiPath, q.Encode(), nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tres, err := customHTTPClient.Do(req)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer res.Body.Close()\n\n\tif res.StatusCode == http.StatusNotFound {\n\t\treturn fmt.Errorf(\"requested image was not found in the library\")\n\t}\n\n\tif res.StatusCode == http.StatusOK {\n\t\t// Library endpoint does not provide HTTP redirection response, treat as single stream, direct download\n\t\tc.Logger.Logf(\"Library endpoint does not support concurrent downloads; reverting to single stream\")\n\n\t\treturn c.singleStreamDownload(ctx, dst, res, pb)\n\t}\n\n\tif res.StatusCode != http.StatusSeeOther {\n\t\treturn fmt.Errorf(\"unexpected HTTP status %d: %v\", res.StatusCode, err)\n\t}\n\n\turl := res.Header.Get(\"Location\")\n\n\tcontentLength, err := c.getContentLength(ctx, url)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnumParts := uint(1 + (contentLength-1)/spec.PartSize)\n\n\tc.Logger.Logf(\"size: %d, parts: %d, concurrency: %d, partsize: %d, bufsize: %d\",\n\t\tcontentLength, numParts, spec.Concurrency, spec.PartSize, spec.BufferSize,\n\t)\n\n\tjobs := make(chan partSpec, numParts)\n\n\tg, ctx := errgroup.WithContext(ctx)\n\n\t// initialize progress bar\n\tpb.Init(contentLength)\n\n\t// if spec.Requests is greater than number of parts for requested file,\n\t// set concurrency to number of parts\n\tconcurrency := spec.Concurrency\n\tif numParts < spec.Concurrency {\n\t\tconcurrency = numParts\n\t}\n\n\t// start workers to manage concurrent HTTP requests\n\tfor workerID := uint(0); workerID <= concurrency; workerID++ {\n\t\tg.Go(c.downloadWorker(ctx, dst, url, jobs, pb))\n\t}\n\n\t// iterate over parts, adding to job queue\n\tfor part := uint(0); part < numParts; part++ {\n\t\tpartSize := spec.PartSize\n\t\tif part == numParts-1 {\n\t\t\tpartSize = contentLength - int64(numParts-1)*spec.PartSize\n\t\t}\n\n\t\tps := partSpec{\n\t\t\tStart:      int64(part) * spec.PartSize,\n\t\t\tEnd:        int64(part)*spec.PartSize + partSize - 1,\n\t\t\tBufferSize: spec.BufferSize,\n\t\t}\n\n\t\tjobs <- ps\n\t}\n\n\tclose(jobs)\n\n\t// wait on errgroup\n\terr = g.Wait()\n\tif err != nil {\n\t\t// cancel/remove progress bar on error\n\t\tpb.Abort(true)\n\t}\n\n\t// wait on progress bar\n\tpb.Wait()\n\n\treturn err\n}\n\nfunc (c *Client) singleStreamDownload(ctx context.Context, fp *os.File, res *http.Response, pb ProgressBar) error {\n\tcontentLength := int64(-1)\n\tval := res.Header.Get(\"Content-Length\")\n\tif val != \"\" {\n\t\tvar err error\n\t\tif contentLength, err = strconv.ParseInt(val, 0, 64); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tpb.Init(contentLength)\n\n\tproxyReader := pb.ProxyReader(res.Body)\n\tdefer proxyReader.Close()\n\n\tif _, err := io.Copy(fp, proxyReader); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n"], "filenames": ["client/pull.go"], "buggy_code_start_loc": [107], "buggy_code_end_loc": [109], "fixing_code_start_loc": [107], "fixing_code_end_loc": [114], "type": "CWE-522", "message": "github.com/sylabs/scs-library-client is the Go client for the Singularity Container Services (SCS) Container Library Service. When the scs-library-client is used to pull a container image, with authentication, the HTTP Authorization header sent by the client to the library service may be incorrectly leaked to an S3 backing storage provider. This occurs in a specific flow, where the library service redirects the client to a backing S3 storage server, to perform a multi-part concurrent download. Depending on site configuration, the S3 service may be provided by a third party. An attacker with access to the S3 service may be able to extract user credentials, allowing them to impersonate the user. The vulnerable multi-part concurrent download flow, with redirect to S3, is only used when communicating with a Singularity Enterprise 1.x installation, or third party server implementing this flow. Interaction with Singularity Enterprise 2.x, and Singularity Container Services (cloud.sylabs.io), does not trigger the vulnerable flow. We encourage all users to update. Users who interact with a Singularity Enterprise 1.x installation, using a 3rd party S3 storage service, are advised to revoke and recreate their authentication tokens within Singularity Enterprise. There is no workaround available at this time.", "other": {"cve": {"id": "CVE-2022-23538", "sourceIdentifier": "security-advisories@github.com", "published": "2023-01-17T21:15:11.827", "lastModified": "2023-01-30T18:26:17.897", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "github.com/sylabs/scs-library-client is the Go client for the Singularity Container Services (SCS) Container Library Service. When the scs-library-client is used to pull a container image, with authentication, the HTTP Authorization header sent by the client to the library service may be incorrectly leaked to an S3 backing storage provider. This occurs in a specific flow, where the library service redirects the client to a backing S3 storage server, to perform a multi-part concurrent download. Depending on site configuration, the S3 service may be provided by a third party. An attacker with access to the S3 service may be able to extract user credentials, allowing them to impersonate the user. The vulnerable multi-part concurrent download flow, with redirect to S3, is only used when communicating with a Singularity Enterprise 1.x installation, or third party server implementing this flow. Interaction with Singularity Enterprise 2.x, and Singularity Container Services (cloud.sylabs.io), does not trigger the vulnerable flow. We encourage all users to update. Users who interact with a Singularity Enterprise 1.x installation, using a 3rd party S3 storage service, are advised to revoke and recreate their authentication tokens within Singularity Enterprise. There is no workaround available at this time."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:H/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 7.6, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.3, "impactScore": 4.7}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:U/C:H/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "HIGH", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 5.2, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 0.9, "impactScore": 4.2}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-522"}, {"lang": "en", "value": "CWE-601"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-522"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:sylabs:singularity_container_services_library:1.3.2:*:*:*:*:*:*:*", "matchCriteriaId": "9A32ADB2-29E9-4262-84B6-71E875603DE9"}, {"vulnerable": true, "criteria": "cpe:2.3:a:sylabs:singularity_container_services_library:1.3.3:*:*:*:*:*:*:*", "matchCriteriaId": "E51C9591-7BEC-4CAC-851F-483A4E11BC3C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:sylabs:singularity_container_services_library:1.4.0:*:*:*:*:*:*:*", "matchCriteriaId": "059F3C68-0B13-4CEE-87E3-517B65B48134"}, {"vulnerable": true, "criteria": "cpe:2.3:a:sylabs:singularity_container_services_library:1.4.1:*:*:*:*:*:*:*", "matchCriteriaId": "7233625A-BC6A-4DDB-B940-ED658448631E"}]}]}], "references": [{"url": "https://github.com/sylabs/scs-library-client/commit/68ac4cab5cda0afd8758ff5b5e2e57be6a22fcfa", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/sylabs/scs-library-client/commit/b5db2aacba6bf1231f42dd475cc32e6355ab47b2", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/sylabs/scs-library-client/commit/eebd7caaab310b1fa803e55b8fc1acd9dcd2d00c", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/sylabs/scs-library-client/security/advisories/GHSA-7p8m-22h4-9pj7", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/sylabs/scs-library-client/commit/68ac4cab5cda0afd8758ff5b5e2e57be6a22fcfa"}}
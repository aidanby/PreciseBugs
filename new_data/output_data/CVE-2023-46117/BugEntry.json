{"buggy_code": ["#!/usr/bin/env bash\n\nfunction banner_graber(){\n\tsource \"${SCRIPTPATH}\"/banners.txt\n\trandx=$(shuf -i 1-23 -n 1)\n\ttmp=\"banner${randx}\" \n\tbanner_code=${!tmp}\n\techo -e \"${banner_code}\"\n}\nfunction banner(){\n\tbanner_code=$(banner_graber)\n\tprintf \"\\n${bgreen}${banner_code}\"\n\tprintf \"\\n ${reconftw_version}                                 by @six2dez${reset}\\n\"\n}\n\n###############################################################################################################\n################################################### TOOLS #####################################################\n###############################################################################################################\n\nfunction check_version(){\n\ttimeout 10 git fetch\n\texit_status=$?\n\tif [ $exit_status -eq 0 ]; then\n\t\tBRANCH=$(git rev-parse --abbrev-ref HEAD)\n\t\tHEADHASH=$(git rev-parse HEAD)\n\t\tUPSTREAMHASH=$(git rev-parse \"${BRANCH}\"@\\{upstream\\})\n\t\tif [ \"$HEADHASH\" != \"$UPSTREAMHASH\" ]; then\n\t\t\tprintf \"\\n${yellow} There is a new version, run ./install.sh to get latest version${reset}\\n\\n\"\n\t\tfi\n\telse\n\t\tprintf \"\\n${bred} Unable to check updates ${reset}\\n\\n\"\n\tfi\n}\n\nfunction tools_installed(){\n\n\tprintf \"\\n\\n${bgreen}#######################################################################${reset}\\n\"\n\tprintf \"${bblue} Checking installed tools ${reset}\\n\\n\"\n\n\tallinstalled=true\n\n\t[ -n \"$GOPATH\" ] || { printf \"${bred} [*] GOPATH var\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -n \"$GOROOT\" ] || { printf \"${bred} [*] GOROOT var\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -n \"$PATH\" ] || { printf \"${bred} [*] PATH var\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/dorks_hunter/dorks_hunter.py\" ] || { printf \"${bred} [*] dorks_hunter\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/brutespray/brutespray.py\" ] || { printf \"${bred} [*] brutespray\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/fav-up/favUp.py\" ] || { printf \"${bred} [*] fav-up\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/Corsy/corsy.py\" ] || { printf \"${bred} [*] Corsy\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/testssl.sh/testssl.sh\" ] || { printf \"${bred} [*] testssl\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/CMSeeK/cmseek.py\" ] || { printf \"${bred} [*] CMSeeK\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${fuzz_wordlist}\" ] || { printf \"${bred} [*] OneListForAll\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${lfi_wordlist}\" ] || { printf \"${bred} [*] lfi_wordlist\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${ssti_wordlist}\" ] || { printf \"${bred} [*] ssti_wordlist\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${subs_wordlist}\" ] || { printf \"${bred} [*] subs_wordlist\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${subs_wordlist_big}\" ] || { printf \"${bred} [*] subs_wordlist_big\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${resolvers}\" ] || { printf \"${bred} [*] resolvers\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${resolvers_trusted}\" ] || { printf \"${bred} [*] resolvers_trusted\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/xnLinkFinder/xnLinkFinder.py\" ] || { printf \"${bred} [*] xnLinkFinder\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/waymore/waymore.py\" ] || { printf \"${bred} [*] waymore\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/commix/commix.py\" ] || { printf \"${bred} [*] commix\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/getjswords.py\" ] || { printf \"${bred} [*] getjswords   \t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/JSA/jsa.py\" ] || { printf \"${bred} [*] JSA\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/cloud_enum/cloud_enum.py\" ] || { printf \"${bred} [*] cloud_enum\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/ultimate-nmap-parser/ultimate-nmap-parser.sh\" ] || { printf \"${bred} [*] nmap-parse-output\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/pydictor/pydictor.py\" ] || { printf \"${bred} [*] pydictor   \t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/urless/urless/urless.py\" ] || { printf \"${bred} [*] urless\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/smuggler/smuggler.py\" ] || { printf \"${bred} [*] smuggler\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/regulator/main.py\" ] || { printf \"${bred} [*] regulator\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich github-endpoints &>/dev/null || { printf \"${bred} [*] github-endpoints\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich github-subdomains &>/dev/null || { printf \"${bred} [*] github-subdomains\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich gitlab-subdomains &>/dev/null || { printf \"${bred} [*] gitlab-subdomains\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich katana &>/dev/null || { printf \"${bred} [*] katana\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich wafw00f &>/dev/null || { printf \"${bred} [*] wafw00f\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich dnsvalidator &>/dev/null || { printf \"${bred} [*] dnsvalidator\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich gowitness &>/dev/null || { printf \"${bred} [*] gowitness\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich amass &>/dev/null || { printf \"${bred} [*] Amass\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich dnsx &>/dev/null || { printf \"${bred} [*] dnsx\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich gotator &>/dev/null || { printf \"${bred} [*] gotator\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich nuclei &>/dev/null || { printf \"${bred} [*] Nuclei\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -d ${NUCLEI_TEMPLATES_PATH} ] || { printf \"${bred} [*] Nuclei templates\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -d ${tools}/fuzzing-templates ] || { printf \"${bred} [*] Fuzzing templates\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich gf &>/dev/null || { printf \"${bred} [*] Gf\t\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich Gxss &>/dev/null || { printf \"${bred} [*] Gxss\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich subjs &>/dev/null || { printf \"${bred} [*] subjs\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich ffuf &>/dev/null || { printf \"${bred} [*] ffuf\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich massdns &>/dev/null || { printf \"${bred} [*] Massdns\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich qsreplace &>/dev/null || { printf \"${bred} [*] qsreplace\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich interlace &>/dev/null || { printf \"${bred} [*] interlace\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich anew &>/dev/null || { printf \"${bred} [*] Anew\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich unfurl &>/dev/null || { printf \"${bred} [*] unfurl\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich crlfuzz &>/dev/null || { printf \"${bred} [*] crlfuzz\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich httpx &>/dev/null || { printf \"${bred} [*] Httpx\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich jq &>/dev/null || { printf \"${bred} [*] jq\t\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich notify &>/dev/null || { printf \"${bred} [*] notify\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich dalfox &>/dev/null || { printf \"${bred} [*] dalfox\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich puredns &>/dev/null || { printf \"${bred} [*] puredns\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich emailfinder &>/dev/null || { printf \"${bred} [*] emailfinder\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich analyticsrelationships &>/dev/null || { printf \"${bred} [*] analyticsrelationships\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich mapcidr &>/dev/null || { printf \"${bred} [*] mapcidr\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich ppfuzz &>/dev/null || { printf \"${bred} [*] ppfuzz\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich cdncheck &>/dev/null || { printf \"${bred} [*] cdncheck\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich interactsh-client &>/dev/null || { printf \"${bred} [*] interactsh-client\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich tlsx &>/dev/null || { printf \"${bred} [*] tlsx\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich smap &>/dev/null || { printf \"${bred} [*] smap\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich gitdorks_go &>/dev/null || { printf \"${bred} [*] gitdorks_go\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich ripgen &>/dev/null || { printf \"${bred} [*] ripgen\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich dsieve &>/dev/null || { printf \"${bred} [*] dsieve\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich inscope &>/dev/null || { printf \"${bred} [*] inscope\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich enumerepo &>/dev/null || { printf \"${bred} [*] enumerepo\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich Web-Cache-Vulnerability-Scanner &>/dev/null || { printf \"${bred} [*] Web-Cache-Vulnerability-Scanner [NO]${reset}\\n\"; allinstalled=false;}\n\twhich subfinder &>/dev/null || { printf \"${bred} [*] subfinder\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich byp4xx &>/dev/null || { printf \"${bred} [*] byp4xx\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich ghauri &>/dev/null || { printf \"${bred} [*] ghauri\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich hakip2host &>/dev/null || { printf \"${bred} [*] hakip2host\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich gau &>/dev/null || { printf \"${bred} [*] gau\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich crt &>/dev/null || { printf \"${bred}  [*] crt\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich gitleaks &>/dev/null || { printf \"${bred} [*] gitleaks\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich trufflehog &>/dev/null || { printf \"${bred} [*] trufflehog\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich s3scanner &>/dev/null || { printf \"${bred} [*] s3scanner\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\t\n\tif [ \"${allinstalled}\" = true ]; then\n\t\tprintf \"${bgreen} Good! All installed! ${reset}\\n\\n\"\n\telse\n\t\tprintf \"\\n${yellow} Try running the installer script again ./install.sh\"\n\t\tprintf \"\\n${yellow} If it fails for any reason try to install manually the tools missed\"\n\t\tprintf \"\\n${yellow} Finally remember to set the ${bred}\\$tools${yellow} variable at the start of this script\"\n\t\tprintf \"\\n${yellow} If nothing works and the world is gonna end you can always ping me :D ${reset}\\n\\n\"\n\tfi\n\n\tprintf \"${bblue} Tools check finished\\n\"\n\tprintf \"${bgreen}#######################################################################\\n${reset}\"\n}\n\n###############################################################################################################\n################################################### OSINT #####################################################\n###############################################################################################################\n\nfunction google_dorks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$GOOGLE_DORKS\" = true ] && [ \"$OSINT\" = true ]; then\n\t\tpython3 $tools/dorks_hunter/dorks_hunter.py -d \"$domain\" -o osint/dorks.txt || { echo \"dorks_hunter command failed\"; exit 1; }\n\t\tend_func \"Results are saved in $domain/osint/dorks.txt\" \"${FUNCNAME[0]}\"\n\telse\n\t\tif [ \"$GOOGLE_DORKS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} are already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction github_dorks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$GITHUB_DORKS\" = true ] && [ \"$OSINT\" = true ]; then\n\t\tstart_func \"${FUNCNAME[0]}\" \"Github Dorks in process\"\n\t\tif [ -s \"${GITHUB_TOKENS}\" ]; then\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tgitdorks_go -gd $tools/gitdorks_go/Dorks/medium_dorks.txt -nws 20 -target \"$domain\" -tf \"${GITHUB_TOKENS}\" -ew 3 | anew -q osint/gitdorks.txt || { echo \"gitdorks_go/anew command failed\"; exit 1; }\n\t\t\telse\n\t\t\t\tgitdorks_go -gd $tools/gitdorks_go/Dorks/smalldorks.txt -nws 20 -target $domain -tf \"${GITHUB_TOKENS}\" -ew 3 | anew -q osint/gitdorks.txt || { echo \"gitdorks_go/anew command failed\"; exit 1; }\n\t\t\tfi\n\t\telse\n\t\t\tprintf \"\\n${bred} Required file ${GITHUB_TOKENS} not exists or empty${reset}\\n\"\n\t\tfi\n\t\tend_func \"Results are saved in $domain/osint/gitdorks.txt\" \"${FUNCNAME[0]}\"\n\telse\n\t\tif [ \"$GITHUB_DORKS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction github_repos(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$GITHUB_REPOS\" = true ] && [ \"$OSINT\" = true ]; then\n\t\tstart_func \"${FUNCNAME[0]}\" \"Github Repos analysis in process\"\n\n\t\tif [ -s \"${GITHUB_TOKENS}\" ]; then\n\t\t\tGH_TOKEN=$(cat ${GITHUB_TOKENS} | head -1)\n\t\t\techo $domain | unfurl format %r > .tmp/company_name.txt\n\t\t\tenumerepo -token-string \"${GH_TOKEN}\" -usernames .tmp/company_name.txt -o .tmp/company_repos.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \".tmp/company_repos.txt\" ] && jq -r '.[].repos[]|.url' < .tmp/company_repos.txt > .tmp/company_repos_url.txt 2>>\"$LOGFILE\"\n\t\t\tmkdir -p .tmp/github_repos 2>>\"$LOGFILE\" >>\"$LOGFILE\"\n\t\t\tmkdir -p .tmp/github 2>>\"$LOGFILE\" >>\"$LOGFILE\"\n\t\t\t[ -s \".tmp/company_repos_url.txt\" ] && interlace -tL .tmp/company_repos_url.txt -threads ${INTERLACE_THREADS} -c \"git clone _target_  .tmp/github_repos/_cleantarget_\" 2>>\"$LOGFILE\" >/dev/null 2>&1\n\t\t\t[ -d \".tmp/github/\" ] && ls .tmp/github_repos > .tmp/github_repos_folders.txt\n\t\t\t[ -s \".tmp/github_repos_folders.txt\" ] && interlace -tL .tmp/github_repos_folders.txt -threads ${INTERLACE_THREADS} -c \"gitleaks detect --source .tmp/github_repos/_target_ --no-banner --no-color -r .tmp/github/gh_secret_cleantarget_.json\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \".tmp/company_repos_url.txt\" ] && interlace -tL .tmp/company_repos_url.txt -threads ${INTERLACE_THREADS} -c \"trufflehog git _target_ -j 2>&1 | jq -c > _output_/_cleantarget_\" -o .tmp/github/ >>\"$LOGFILE\" 2>&1\n\t\t\tif [ -d \".tmp/github/\" ]; then\n\t\t\t\tcat .tmp/github/* 2>/dev/null | jq -c | jq -r > osint/github_company_secrets.json 2>>\"$LOGFILE\"\n\t\t\tfi\n\t\telse\n\t\t\tprintf \"\\n${bred} Required file ${GITHUB_TOKENS} not exists or empty${reset}\\n\"\n\t\tfi\n\t\tend_func \"Results are saved in $domain/osint/github_company_secrets.json\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$GITHUB_REPOS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction metadata(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$METADATA\" = true ] && [ \"$OSINT\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Scanning metadata in public files\"\n\t\tmetafinder -d \"$domain\" -l $METAFINDER_LIMIT -o osint -go -bi -ba &>> \"$LOGFILE\" || { echo \"metafinder command failed\"; exit 1; }\n\t\tmv \"osint/${domain}/\"*\".txt\" \"osint/\" 2>>\"$LOGFILE\"\n\t\trm -rf \"osint/${domain}\" 2>>\"$LOGFILE\"\n\t\tend_func \"Results are saved in $domain/osint/[software/authors/metadata_results].txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$METADATA\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$METADATA\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction postleaks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$POSTMAN_LEAKS\" = true ] && [ \"$OSINT\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Scanning for leaks in postman public directory\"\n\n\t\tpostleaksNg -k \"$domain\" > .tmp/postleaks.txt  || { echo \"postleaksNg command failed\"; exit 1; }\n\n\t\tend_func \"Results are saved in $domain/osint/[software/authors/metadata_results].txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$POSTMAN_LEAKS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$POSTMAN_LEAKS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction emails(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$EMAILS\" = true ] && [ \"$OSINT\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Searching emails/users/passwords leaks\"\n\t\temailfinder -d $domain 2>>\"$LOGFILE\" | anew -q .tmp/emailfinder.txt || { echo \"emailfinder command failed\"; exit 1; }\n\t\t[ -s \".tmp/emailfinder.txt\" ] && cat .tmp/emailfinder.txt | grep \"@\" | grep -iv \"|_\" | anew -q osint/emails.txt\n\n\t\tend_func \"Results are saved in $domain/osint/emails.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$EMAILS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$EMAILS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction domain_info(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$DOMAIN_INFO\" = true ] && [ \"$OSINT\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Searching domain info (whois, registrant name/email domains)\"\n\t\twhois -H $domain > osint/domain_info_general.txt || { echo \"whois command failed\"; exit 1; }\n\t\tif [ \"$DEEP\" = true ] || [ \"$REVERSE_WHOIS\" = true ]; then\n\t\t\ttimeout -k 1m ${AMASS_INTEL_TIMEOUT}m amass intel -d ${domain} -whois -timeout $AMASS_INTEL_TIMEOUT -o osint/domain_info_reverse_whois.txt 2>>\"$LOGFILE\" &>/dev/null\n\t\tfi\n\t\t\n\t\tcurl -s \"https://aadinternals.azurewebsites.net/api/tenantinfo?domainName=${domain}\" -H \"Origin: https://aadinternals.com\" | jq -r .domains[].name > osint/azure_tenant_domains.txt\n\n\t\tend_func \"Results are saved in $domain/osint/domain_info_[general/name/email/ip].txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$DOMAIN_INFO\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$DOMAIN_INFO\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction ip_info(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$IP_INFO\" = true ] && [ \"$OSINT\" = true ] && [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Searching ip info\"\n\t\tif [ -n \"$WHOISXML_API\" ]; then\n\t\t\tcurl \"https://reverse-ip.whoisxmlapi.com/api/v1?apiKey=${WHOISXML_API}&ip=${domain}\" 2>/dev/null | jq -r '.result[].name' 2>>\"$LOGFILE\" | sed -e \"s/$/ ${domain}/\" | anew -q osint/ip_${domain}_relations.txt\n\t\t\tcurl \"https://www.whoisxmlapi.com/whoisserver/WhoisService?apiKey=${WHOISXML_API}&domainName=${domain}&outputFormat=json&da=2&registryRawText=1&registrarRawText=1&ignoreRawTexts=1\" 2>/dev/null | jq 2>>\"$LOGFILE\" | anew -q osint/ip_${domain}_whois.txt\n\t\t\tcurl \"https://ip-geolocation.whoisxmlapi.com/api/v1?apiKey=${WHOISXML_API}&ipAddress=${domain}\" 2>/dev/null | jq -r '.ip,.location' 2>>\"$LOGFILE\" | anew -q osint/ip_${domain}_location.txt\n\t\t\tend_func \"Results are saved in $domain/osint/ip_[domain_relations|whois|location].txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tprintf \"\\n${yellow} No WHOISXML_API var defined, skipping function ${reset}\\n\"\n\t\tfi\n\telse\n\t\tif [ \"$IP_INFO\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ ! $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$IP_INFO\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n############################################### SUBDOMAINS ####################################################\n###############################################################################################################\n\nfunction subdomains_full(){\n\tNUMOFLINES_subs=\"0\"\n\tNUMOFLINES_probed=\"0\"\n\tprintf \"${bgreen}#######################################################################\\n\\n\"\n\t! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]] && printf \"${bblue} Subdomain Enumeration $domain\\n\\n\"\n\t[[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]] && printf \"${bblue} Scanning IP $domain\\n\\n\"\n\t[ -s \"subdomains/subdomains.txt\" ] && cp subdomains/subdomains.txt .tmp/subdomains_old.txt\n\t[ -s \"webs/webs.txt\" ] && cp webs/webs.txt .tmp/probed_old.txt\n\n\tif ( [ ! -f \"$called_fn_dir/.sub_active\" ] || [ ! -f \"$called_fn_dir/.sub_brute\" ] || [ ! -f \"$called_fn_dir/.sub_permut\" ] || [ ! -f \"$called_fn_dir/.sub_recursive_brute\" ] )  || [ \"$DIFF\" = true ] ; then\n\t\tresolvers_update\n\tfi\n\n\t[ -s \"${inScope_file}\" ] && cat ${inScope_file} | anew -q subdomains/subdomains.txt\n\n\tif ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]] && [ \"$SUBDOMAINS_GENERAL\" = true ]; then\n\t\tsub_passive\n\t\tsub_crt\n\t\tsub_active\n\t\tsub_noerror\n\t\tsub_brute\n\t\tsub_permut\n\t\tsub_regex_permut\n\t\t#sub_gpt\n\t\tsub_recursive_passive\n\t\tsub_recursive_brute\n\t\tsub_dns\n\t\tsub_scraping\n\t\tsub_analytics\n\telse \n\t\tnotification \"IP/CIDR detected, subdomains search skipped\" info\n\t\techo $domain | anew -q subdomains/subdomains.txt\n\tfi\n\n\twebprobe_simple\n\tif [ -s \"subdomains/subdomains.txt\" ]; then\n\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file subdomains/subdomains.txt\n\t\tNUMOFLINES_subs=$(cat subdomains/subdomains.txt 2>>\"$LOGFILE\" | anew .tmp/subdomains_old.txt | sed '/^$/d' | wc -l)\n\tfi\n\tif [ -s \"webs/webs.txt\" ]; then\n\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file webs/webs.txt\n\t\tNUMOFLINES_probed=$(cat webs/webs.txt 2>>\"$LOGFILE\" | anew .tmp/probed_old.txt | sed '/^$/d' | wc -l)\n\tfi\n\tprintf \"${bblue}\\n Total subdomains: ${reset}\\n\\n\"\n\tnotification \"- ${NUMOFLINES_subs} alive\" good\n\t[ -s \"subdomains/subdomains.txt\" ] && cat subdomains/subdomains.txt | sort\n\tnotification \"- ${NUMOFLINES_probed} new web probed\" good\n\t[ -s \"webs/webs.txt\" ] && cat webs/webs.txt | sort\n\tnotification \"Subdomain Enumeration Finished\" good\n\tprintf \"${bblue} Results are saved in $domain/subdomains/subdomains.txt and webs/webs.txt${reset}\\n\"\n\tprintf \"${bgreen}#######################################################################\\n\\n\"\n}\n\nfunction sub_passive(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBPASSIVE\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Passive Subdomain Enumeration\"\n\n\t\t[[ $RUNAMASS == true ]] && timeout -k 1m ${AMASS_ENUM_TIMEOUT} amass enum -passive -d $domain -config $AMASS_CONFIG -timeout $AMASS_ENUM_TIMEOUT -json .tmp/amass_json.json 2>>\"$LOGFILE\" &>/dev/null\n\t\t[ -s \".tmp/amass_json.json\" ] && cat .tmp/amass_json.json | jq -r '.name' | anew -q .tmp/amass_psub.txt\n\t\t[[ $RUNSUBFINDER == true ]] && subfinder -all -d \"$domain\" -silent -o .tmp/subfinder_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\n\t\tif [ -s \"${GITHUB_TOKENS}\" ]; then\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tgithub-subdomains -d $domain -t $GITHUB_TOKENS -o .tmp/github_subdomains_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\tgithub-subdomains -d $domain -k -q -t $GITHUB_TOKENS -o .tmp/github_subdomains_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\tfi\n\t\tif [ -s \"${GITLAB_TOKENS}\" ]; then\n\t\t\tgitlab-subdomains -d $domain -t $GITLAB_TOKENS > .tmp/gitlab_subdomains_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tif [ \"$INSCOPE\" = true ]; then\n\t\t\tcheck_inscope .tmp/amass_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tcheck_inscope .tmp/subfinder_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tcheck_inscope .tmp/github_subdomains_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tcheck_inscope .tmp/gitlab_subdomains_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tNUMOFLINES=$(find .tmp -type f -iname \"*_psub.txt\" -exec cat {} + | sed \"s/*.//\" | anew .tmp/passive_subs.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (passive)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBPASSIVE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_crt(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBCRT\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Crtsh Subdomain Enumeration\"\n\t\tcrt -s -json -l ${CTR_LIMIT} $domain 2>>\"$LOGFILE\" | jq -r '.[].subdomain' 2>>\"$LOGFILE\" | sed -e \"s/^\\\\*\\\\.//\" | anew -q .tmp/crtsh_subs_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/crtsh_subs_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/crtsh_subs_tmp.txt 2>>\"$LOGFILE\" | sed 's/\\*.//g' | anew .tmp/crtsh_subs.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (cert transparency)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBCRT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_active(){\n\tif [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Active Subdomain Enumeration\"\n\t\tfind .tmp -type f -iname \"*_subs.txt\" -exec cat {} + | anew -q .tmp/subs_no_resolved.txt\n\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/subs_no_resolved.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tresolvers_update_quick_local\n\t\t\t[ -s \".tmp/subs_no_resolved.txt\" ] && puredns resolve .tmp/subs_no_resolved.txt -w .tmp/subdomains_tmp.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\tresolvers_update_quick_axiom\n\t\t\t[ -s \".tmp/subs_no_resolved.txt\" ] && axiom-scan .tmp/subs_no_resolved.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subdomains_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\techo $domain | dnsx -retry 3 -silent -r $resolvers_trusted 2>>\"$LOGFILE\" | anew -q .tmp/subdomains_tmp.txt\n\t\tif [ \"$DEEP\" = true ]; then\n\t\t\tcat .tmp/subdomains_tmp.txt | tlsx -san -cn -silent -ro -c $TLSX_THREADS -p $TLS_PORTS | anew -q .tmp/subdomains_tmp.txt\n\t\telse\n\t\t\tcat .tmp/subdomains_tmp.txt | tlsx -san -cn -silent -ro -c $TLSX_THREADS | anew -q .tmp/subdomains_tmp.txt\n\t\tfi\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subdomains_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/subdomains_tmp.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} subs DNS resolved from passive\" ${FUNCNAME[0]}\n\telse\n\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\tfi\n}\n\nfunction sub_noerror(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBNOERROR\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Checking NOERROR DNS response\"\n\t\tif [[ $(echo \"${RANDOM}thistotallynotexist${RANDOM}.$domain\" | dnsx -r $resolvers -rcode noerror,nxdomain -retry 3 -silent | cut -d' ' -f2) == \"[NXDOMAIN]\" ]]; then \n\t\t\tresolvers_update_quick_local\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tdnsx -d $domain -r $resolvers -silent -rcode noerror -w $subs_wordlist_big | cut -d' ' -f1 | anew -q .tmp/subs_noerror.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\tdnsx -d $domain -r $resolvers -silent -rcode noerror -w $subs_wordlist | cut -d' ' -f1 | anew -q .tmp/subs_noerror.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subs_noerror.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tNUMOFLINES=$(cat .tmp/subs_noerror.txt 2>>\"$LOGFILE\" | sed \"s/*.//\" | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\t\tend_subfunc \"${NUMOFLINES} new subs (DNS noerror)\" ${FUNCNAME[0]}\n\t\telse \n\t\t\tprintf \"\\n${yellow} Detected DNSSEC black lies, skipping this technique ${reset}\\n\" \n\t\tfi\n\telse\n\t\tif [ \"$SUBBRUTE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_dns(){\n\tif [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : DNS Subdomain Enumeration and PTR search\"\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \"subdomains/subdomains.txt\" ] && cat subdomains/subdomains.txt | dnsx -r $resolvers_trusted -a -aaaa -cname -ns -ptr -mx -soa -silent -retry 3 -json -o subdomains/subdomains_dnsregs.json 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[], try .aaaa[], try .cname[], try .ns[], try .ptr[], try .mx[], try .soa[]' 2>/dev/null | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/subdomains_dns.txt\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | hakip2host | cut -d' ' -f 3 | unfurl -u domains | sed -e 's/*\\.//' -e 's/\\.$//' -e '/\\./!d' | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/subdomains_dns.txt\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try \"\\(.host) - \\(.a[])\"' 2>/dev/null | sort -u -k2 | anew -q subdomains/subdomains_ips.txt\n\t\t\tresolvers_update_quick_local\n\t\t\t[ -s \".tmp/subdomains_dns.txt\" ] && puredns resolve .tmp/subdomains_dns.txt -w .tmp/subdomains_dns_resolved.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\t[ -s \"subdomains/subdomains.txt\" ] && axiom-scan subdomains/subdomains.txt -m dnsx -retry 3 -a -aaaa -cname -ns -ptr -mx -soa -json -o subdomains/subdomains_dnsregs.json $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | anew -q .tmp/subdomains_dns_a_records.txt\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | hakip2host | cut -d' ' -f 3 | unfurl -u domains | sed -e 's/*\\.//' -e 's/\\.$//' -e '/\\./!d' | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/subdomains_dns.txt\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[], try .aaaa[], try .cname[], try .ns[], try .ptr[], try .mx[], try .soa[]' 2>/dev/null | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/subdomains_dns.txt\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try \"\\(.host) - \\(.a[])\"' 2>/dev/null | sort -u -k2 | anew -q subdomains/subdomains_ips.txt\n\t\t\tresolvers_update_quick_axiom\n\t\t\t[ -s \".tmp/subdomains_dns.txt\" ] && axiom-scan .tmp/subdomains_dns.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subdomains_dns_resolved.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subdomains_dns_resolved.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/subdomains_dns_resolved.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (dns resolution)\" ${FUNCNAME[0]}\n\telse\n\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\tfi\n}\n\nfunction sub_brute(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBBRUTE\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Bruteforce Subdomain Enumeration\"\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tresolvers_update_quick_local\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tpuredns bruteforce $subs_wordlist_big $domain -w .tmp/subs_brute.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\tpuredns bruteforce $subs_wordlist $domain -w .tmp/subs_brute.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/subs_brute.txt\" ] && puredns resolve .tmp/subs_brute.txt -w .tmp/subs_brute_valid.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\tresolvers_update_quick_axiom\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\taxiom-scan $subs_wordlist_big -m puredns-single $domain -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subs_brute.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\taxiom-scan $subs_wordlist -m puredns-single $domain -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subs_brute.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/subs_brute.txt\" ] && axiom-scan .tmp/subs_brute.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subs_brute_valid.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subs_brute_valid.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/subs_brute_valid.txt 2>>\"$LOGFILE\" | sed \"s/*.//\" | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (bruteforce)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBBRUTE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_scraping(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBSCRAPING\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Source code scraping subdomain search\"\n\t\ttouch .tmp/scrap_subs.txt\n\t\tif [ -s \"$dir/subdomains/subdomains.txt\" ]; then\n\t\t\tif [[ $(cat subdomains/subdomains.txt | wc -l) -le $DEEP_LIMIT ]] || [ \"$DEEP\" = true ] ; then\n\t\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\t\tresolvers_update_quick_local\n\t\t\t\t\tcat subdomains/subdomains.txt | httpx -follow-host-redirects -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info1.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t[ -s \".tmp/web_full_info1.txt\" ] && cat .tmp/web_full_info1.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && cat .tmp/probed_tmp_scrap.txt | httpx -tls-grab -tls-probe -csp-probe -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info2.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t[ -s \".tmp/web_full_info2.txt\" ] && cat .tmp/web_full_info2.txt | jq -r 'try .\"tls-grab\".\"dns_names\"[],try .csp.domains[],try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | sort -u | httpx -silent | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n\n\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && katana -silent -list .tmp/probed_tmp_scrap.txt -jc -kf all -c $KATANA_THREADS -d 3 -fs rdn -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\telse\n\t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && katana -silent -list .tmp/probed_tmp_scrap.txt -jc -kf all -c $KATANA_THREADS -d 2 -fs rdn -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\tfi\n\t\t\t\telse\n\t\t\t\t\tresolvers_update_quick_axiom\n\t\t\t\t\taxiom-scan subdomains/subdomains.txt -m httpx -follow-host-redirects -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info1.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t[ -s \".tmp/web_full_info1.txt\" ] && cat .tmp/web_full_info1.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && axiom-scan .tmp/probed_tmp_scrap.txt -m httpx -tls-grab -tls-probe -csp-probe -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info2.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t[ -s \".tmp/web_full_info2.txt\" ] && cat .tmp/web_full_info2.txt | jq -r 'try .\"tls-grab\".\"dns_names\"[],try .csp.domains[],try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | sort -u | httpx -silent | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && axiom-scan .tmp/probed_tmp_scrap.txt -m katana -jc -kf all -d 3 -fs rdn -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\telse\n\t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && axiom-scan .tmp/probed_tmp_scrap.txt -m katana -jc -kf all -d 2 -fs rdn -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\t\tsed -i '/^.\\{2048\\}./d' .tmp/katana.txt\n\t\t\t\t[ -s \".tmp/katana.txt\" ] && cat .tmp/katana.txt | unfurl -u domains 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/scrap_subs.txt\n\t\t\t\t[ -s \".tmp/scrap_subs.txt\" ] && puredns resolve .tmp/scrap_subs.txt -w .tmp/scrap_subs_resolved.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tif [ \"$INSCOPE\" = true ]; then\n\t\t\t\t\tcheck_inscope .tmp/scrap_subs_resolved.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\t\tNUMOFLINES=$(cat .tmp/scrap_subs_resolved.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | tee .tmp/diff_scrap.txt | sed '/^$/d' | wc -l)\n\t\t\t\t[ -s \".tmp/diff_scrap.txt\" ] && cat .tmp/diff_scrap.txt | httpx -follow-host-redirects -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info3.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t[ -s \".tmp/web_full_info3.txt\" ] && cat .tmp/web_full_info3.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n\t\t\t\tcat .tmp/web_full_info1.txt .tmp/web_full_info2.txt .tmp/web_full_info3.txt 2>>\"$LOGFILE\" | jq -s 'try .' | jq 'try unique_by(.input)' | jq 'try .[]' 2>>\"$LOGFILE\" > .tmp/web_full_info.txt\n\t\t\t\tend_subfunc \"${NUMOFLINES} new subs (code scraping)\" ${FUNCNAME[0]}\n\t\t\telse\n\t\t\t\tend_subfunc \"Skipping Subdomains Web Scraping: Too Many Subdomains\" ${FUNCNAME[0]}\n\t\t\tfi\n\t\telse\n\t\t\tend_subfunc \"No subdomains to search (code scraping)\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$SUBSCRAPING\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_analytics(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBANALYTICS\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Analytics Subdomain Enumeration\"\n\t\tif [ -s \".tmp/probed_tmp_scrap.txt\" ]; then\n\t\t\tmkdir -p .tmp/output_analytics/\n\t\t\tanalyticsrelationships -ch < .tmp/probed_tmp_scrap.txt >> .tmp/analytics_subs_tmp.txt 2>>\"$LOGFILE\"\n\n\t\t\t[ -s \".tmp/analytics_subs_tmp.txt\" ] && cat .tmp/analytics_subs_tmp.txt | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/|__ //\" | anew -q .tmp/analytics_subs_clean.txt\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tresolvers_update_quick_local\n\t\t\t\t[ -s \".tmp/analytics_subs_clean.txt\" ] && puredns resolve .tmp/analytics_subs_clean.txt -w .tmp/analytics_subs_resolved.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\tresolvers_update_quick_axiom\n\t\t\t\t[ -s \".tmp/analytics_subs_clean.txt\" ] && axiom-scan .tmp/analytics_subs_clean.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/analytics_subs_resolved.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\tfi\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/analytics_subs_resolved.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/analytics_subs_resolved.txt 2>>\"$LOGFILE\" | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (analytics relationship)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBANALYTICS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_permut(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBPERMUTE\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Permutations Subdomain Enumeration\"\n\t\tif [ \"$DEEP\" = true ] || [ \"$(cat subdomains/subdomains.txt | wc -l)\" -le $DEEP_LIMIT ] ; then\n\t\t\tif [ \"$PERMUTATIONS_OPTION\" = \"gotator\" ] ; then\n\t\t\t\t[ -s \"subdomains/subdomains.txt\" ] && gotator -sub subdomains/subdomains.txt -perm $tools/permutations_list.txt $GOTATOR_FLAGS -silent 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1.txt\n\t\t\telse\n\t\t\t\t[ -s \"subdomains/subdomains.txt\" ] && ripgen -d subdomains/subdomains.txt -w $tools/permutations_list.txt 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1.txt\n\t\t\tfi\n\t\telif [ \"$(cat .tmp/subs_no_resolved.txt | wc -l)\" -le $DEEP_LIMIT2 ]; then\n\t\t\tif [ \"$PERMUTATIONS_OPTION\" = \"gotator\" ] ; then\n\t\t\t\t[ -s \".tmp/subs_no_resolved.txt\" ] && gotator -sub .tmp/subs_no_resolved.txt -perm $tools/permutations_list.txt $GOTATOR_FLAGS -silent 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1.txt\n\t\t\telse\n\t\t\t\t[ -s \".tmp/subs_no_resolved.txt\" ] && ripgen -d .tmp/subs_no_resolved.txt -w $tools/permutations_list.txt 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1.txt\n\t\t\tfi\n\t\telse\n\t\t\tend_subfunc \"Skipping Permutations: Too Many Subdomains\" ${FUNCNAME[0]}\n\t\t\treturn 1\n\t\tfi\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tresolvers_update_quick_local\n\t\t\t[ -s \".tmp/gotator1.txt\" ] && puredns resolve .tmp/gotator1.txt -w .tmp/permute1.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\tresolvers_update_quick_axiom\n\t\t\t[ -s \".tmp/gotator1.txt\" ] && axiom-scan .tmp/gotator1.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/permute1.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\t\n\t\tif [ \"$PERMUTATIONS_OPTION\" = \"gotator\" ] ; then\n\t\t\t[ -s \".tmp/permute1.txt\" ] && gotator -sub .tmp/permute1.txt -perm $tools/permutations_list.txt $GOTATOR_FLAGS -silent 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator2.txt\n\t\telse\n\t\t\t[ -s \".tmp/permute1.txt\" ] && ripgen -d .tmp/permute1.txt -w $tools/permutations_list.txt 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator2.txt\n\t\tfi\n\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \".tmp/gotator2.txt\" ] && puredns resolve .tmp/gotator2.txt -w .tmp/permute2.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\t[ -s \".tmp/gotator2.txt\" ] && axiom-scan .tmp/gotator2.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/permute2.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tcat .tmp/permute1.txt .tmp/permute2.txt 2>>\"$LOGFILE\" | anew -q .tmp/permute_subs.txt\n\n\t\tif [ -s \".tmp/permute_subs.txt\" ]; then\n\t\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/permute_subs.txt\n\t\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/permute_subs.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tNUMOFLINES=$(cat .tmp/permute_subs.txt 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\telse\n\t\t\tNUMOFLINES=0\n\t\tfi\n\t\tend_subfunc \"${NUMOFLINES} new subs (permutations)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBPERMUTE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_regex_permut(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBREGEXPERMUTE\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Permutations by regex analysis\"\n\t\tcd \"$tools/regulator\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tpython3 main.py -t $domain -f ${dir}/subdomains/subdomains.txt -o ${dir}/.tmp/${domain}.brute\n\t\tcd \"$dir\" || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tresolvers_update_quick_local\n\t\t\t[ -s \".tmp/${domain}.brute\" ] && puredns resolve .tmp/${domain}.brute -w .tmp/regulator.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\tresolvers_update_quick_axiom\n\t\t\t[ -s \".tmp/${domain}.brute\" ] && axiom-scan .tmp/${domain}.brute -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/regulator.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\t\n\t\tif [ -s \".tmp/regulator.txt\" ]; then\n\t\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/regulator.txt\n\t\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/regulator.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tNUMOFLINES=$(cat .tmp/regulator.txt 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\telse\n\t\t\tNUMOFLINES=0\n\t\tfi\n\t\tend_subfunc \"${NUMOFLINES} new subs (permutations by regex)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBREGEXPERMUTE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_recursive_passive(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUB_RECURSIVE_PASSIVE\" = true ] && [ -s \"subdomains/subdomains.txt\" ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Subdomains recursive search passive\"\n\t\t# Passive recursive\n\t\t[ -s \"subdomains/subdomains.txt\" ] && dsieve -if subdomains/subdomains.txt -f 3 -top $DEEP_RECURSIVE_PASSIVE > .tmp/subdomains_recurs_top.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tresolvers_update_quick_local\n\t\t\t[ -s \".tmp/subdomains_recurs_top.txt\" ] && timeout -k 1m ${AMASS_ENUM_TIMEOUT}m amass enum -passive -df .tmp/subdomains_recurs_top.txt -nf subdomains/subdomains.txt -config $AMASS_CONFIG -timeout $AMASS_ENUM_TIMEOUT 2>>\"$LOGFILE\" | anew -q .tmp/passive_recursive.txt\n\t\t\t[ -s \".tmp/passive_recursive.txt\" ] && puredns resolve .tmp/passive_recursive.txt -w .tmp/passive_recurs_tmp.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" &>/dev/null\n\t\telse\n\t\t\tresolvers_update_quick_axiom\n\t\t\t[ -s \".tmp/subdomains_recurs_top.txt\" ] && axiom-scan .tmp/subdomains_recurs_top.txt -m amass -passive -o .tmp/amass_prec.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \".tmp/amass_prec.txt\" ] &&  cat .tmp/amass_prec.txt | anew -q .tmp/passive_recursive.txt\n\t\t\t[ -s \".tmp/passive_recursive.txt\" ] && axiom-scan .tmp/passive_recursive.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/passive_recurs_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/passive_recurs_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/passive_recurs_tmp.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed '/^$/d' | anew subdomains/subdomains.txt | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (recursive)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUB_RECURSIVE_PASSIVE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_recursive_brute(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUB_RECURSIVE_BRUTE\" = true ] && [ -s \"subdomains/subdomains.txt\" ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Subdomains recursive search active\"\n\t\tif [[ $(cat subdomains/subdomains.txt | wc -l) -le $DEEP_LIMIT ]] ; then\n\t\t\t[ ! -s \".tmp/subdomains_recurs_top.txt\" ] && dsieve -if subdomains/subdomains.txt -f 3 -top $DEEP_RECURSIVE_PASSIVE > .tmp/subdomains_recurs_top.txt\n\t\t\tripgen -d .tmp/subdomains_recurs_top.txt -w $subs_wordlist > .tmp/brute_recursive_wordlist.txt\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tresolvers_update_quick_local\n\t\t\t\t[ -s \".tmp/brute_recursive_wordlist.txt\" ] && puredns resolve .tmp/brute_recursive_wordlist.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -w .tmp/brute_recursive_result.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\tresolvers_update_quick_axiom\n\t\t\t\t[ -s \".tmp/brute_recursive_wordlist.txt\" ] && axiom-scan .tmp/brute_recursive_wordlist.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/brute_recursive_result.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/brute_recursive_result.txt\" ] && cat .tmp/brute_recursive_result.txt | anew -q .tmp/brute_recursive.txt\n\n\t\t\tif [ \"$PERMUTATIONS_OPTION\" = \"gotator\" ] ; then\n\t\t\t\t[ -s \".tmp/brute_recursive.txt\" ] && gotator -sub .tmp/brute_recursive.txt -perm $tools/permutations_list.txt $GOTATOR_FLAGS -silent 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1_recursive.txt\n\t\t\telse\n\t\t\t\t[ -s \".tmp/brute_recursive.txt\" ] && ripgen -d .tmp/brute_recursive.txt -w $tools/permutations_list.txt 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1_recursive.txt\n\t\t\tfi\n\t\t\t\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\t[ -s \".tmp/gotator1_recursive.txt\" ] && puredns resolve .tmp/gotator1_recursive.txt -w .tmp/permute1_recursive.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\t[ -s \".tmp/gotator1_recursive.txt\" ] && axiom-scan .tmp/gotator1_recursive.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/permute1_recursive.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\n\t\t\tif [ \"$PERMUTATIONS_OPTION\" = \"gotator\" ] ; then\n\t\t\t\t[ -s \".tmp/permute1_recursive.txt\" ] && gotator -sub .tmp/permute1_recursive.txt -perm $tools/permutations_list.txt $GOTATOR_FLAGS -silent 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator2_recursive.txt\n\t\t\telse\n\t\t\t\t[ -s \".tmp/permute1_recursive.txt\" ] && ripgen -d .tmp/permute1_recursive.txt -w $tools/permutations_list.txt 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator2_recursive.txt\n\t\t\tfi\n\t\t\t\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \".tmp/gotator2_recursive.txt\" ] && puredns resolve .tmp/gotator2_recursive.txt -w .tmp/permute2_recursive.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\t[ -s \".tmp/gotator2_recursive.txt\" ] && axiom-scan .tmp/gotator2_recursive.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/permute2_recursive.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\tcat .tmp/permute1_recursive.txt .tmp/permute2_recursive.txt 2>>\"$LOGFILE\" | anew -q .tmp/permute_recursive.txt\n\t\telse\n\t\t\tend_subfunc \"skipped in this mode or defined in reconftw.cfg\" ${FUNCNAME[0]}\n\t\tfi\n\t\tif [ \"$INSCOPE\" = true ]; then\n\t\t\tcheck_inscope .tmp/permute_recursive.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tcheck_inscope .tmp/brute_recursive.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\n\t\t# Last validation\n\t\tcat .tmp/permute_recursive.txt .tmp/brute_recursive.txt 2>>\"$LOGFILE\" | anew -q .tmp/brute_perm_recursive.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \".tmp/brute_recursive.txt\" ] && puredns resolve .tmp/brute_perm_recursive.txt -w .tmp/brute_perm_recursive_final.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\t[ -s \".tmp/brute_recursive.txt\" ] && axiom-scan .tmp/brute_perm_recursive.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/brute_perm_recursive_final.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\n\t\tNUMOFLINES=$(cat .tmp/brute_perm_recursive_final.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed '/^$/d' | anew subdomains/subdomains.txt | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (recursive active)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUB_RECURSIVE_BRUTE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction subtakeover(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBTAKEOVER\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Looking for possible subdomain and DNS takeover\"\n\t\ttouch .tmp/tko.txt\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tnuclei -update 2>>\"$LOGFILE\" >/dev/null\n\t\t\tcat subdomains/subdomains.txt .tmp/webs_all.txt 2>/dev/null | nuclei -silent -nh -tags takeover -severity info,low,medium,high,critical -retries 3 -rl $NUCLEI_RATELIMIT -t ${NUCLEI_TEMPLATES_PATH} -o .tmp/tko.txt\n\t\telse\n\t\t\tcat subdomains/subdomains.txt .tmp/webs_all.txt 2>>\"$LOGFILE\" | sed '/^$/d' | anew -q .tmp/webs_subs.txt\n\t\t\t[ -s \".tmp/webs_subs.txt\" ] && axiom-scan .tmp/webs_subs.txt -m nuclei --nuclei-templates ${NUCLEI_TEMPLATES_PATH} -tags takeover -nh -severity info,low,medium,high,critical -retries 3 -rl $NUCLEI_RATELIMIT -t ${NUCLEI_TEMPLATES_PATH} -o .tmp/tko.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\n\t\t# DNS_TAKEOVER\n\t\tcat .tmp/subs_no_resolved.txt .tmp/subdomains_dns.txt .tmp/scrap_subs.txt .tmp/analytics_subs_clean.txt .tmp/passive_recursive.txt 2>/dev/null | anew -q .tmp/subs_dns_tko.txt\n\t\tcat .tmp/subs_dns_tko.txt 2>/dev/null | dnstake -c $DNSTAKE_THREADS -s 2>>\"$LOGFILE\" | sed '/^$/d' | anew -q .tmp/tko.txt\n\n\t\tsed -i '/^$/d' .tmp/tko.txt\n\n\t\tNUMOFLINES=$(cat .tmp/tko.txt 2>>\"$LOGFILE\" | anew webs/takeover.txt | sed '/^$/d' | wc -l)\n\t\tif [ \"$NUMOFLINES\" -gt 0 ]; then\n\t\t\tnotification \"${NUMOFLINES} new possible takeovers found\" info\n\t\tfi\n\t\tend_func \"Results are saved in $domain/webs/takeover.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBTAKEOVER\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction zonetransfer(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$ZONETRANSFER\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Zone transfer check\"\n\t\tfor ns in $(dig +short ns \"$domain\"); do dig axfr \"$domain\" @\"$ns\" >> subdomains/zonetransfer.txt; done\n\t\tif [ -s \"subdomains/zonetransfer.txt\" ]; then\n\t\t\tif ! grep -q \"Transfer failed\" subdomains/zonetransfer.txt ; then notification \"Zone transfer found on ${domain}!\" info; fi\n\t\tfi\n\t\tend_func \"Results are saved in $domain/subdomains/zonetransfer.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$ZONETRANSFER\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$ZONETRANSFER\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction s3buckets(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$S3BUCKETS\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"AWS S3 buckets search\"\n\t\t# S3Scanner\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \"subdomains/subdomains.txt\" ] && s3scanner scan -f subdomains/subdomains.txt 2>>\"$LOGFILE\" | anew -q .tmp/s3buckets.txt\n\t\telse\n\t\t\taxiom-scan subdomains/subdomains.txt -m s3scanner -o .tmp/s3buckets_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \".tmp/s3buckets_tmp.txt\" ] && cat .tmp/s3buckets_tmp.txt .tmp/s3buckets_tmp2.txt 2>>\"$LOGFILE\" | anew -q .tmp/s3buckets.txt && sed -i '/^$/d' .tmp/s3buckets.txt\n\t\tfi\n\t\t# Cloudenum\n\t\tkeyword=${domain%%.*}\n\t\tpython3 ~/Tools/cloud_enum/cloud_enum.py -k $keyword -qs -l .tmp/output_cloud.txt 2>>\"$LOGFILE\" >/dev/null\n\n\t\tNUMOFLINES1=$(cat .tmp/output_cloud.txt 2>>\"$LOGFILE\" | sed '/^#/d' | sed '/^$/d' | anew subdomains/cloud_assets.txt | wc -l)\n\t\tif [ \"$NUMOFLINES1\" -gt 0 ]; then\n\t\t\tnotification \"${NUMOFLINES1} new cloud assets found\" info\n\t\tfi\n\t\tNUMOFLINES2=$(cat .tmp/s3buckets.txt 2>>\"$LOGFILE\" | grep -aiv \"not_exist\" | grep -aiv \"Warning:\" | grep -aiv \"invalid_name\" | grep -aiv \"^http\" | awk 'NF' | anew subdomains/s3buckets.txt | sed '/^$/d' | wc -l)\n\t\tif [ \"$NUMOFLINES2\" -gt 0 ]; then\n\t\t\tnotification \"${NUMOFLINES2} new S3 buckets found\" info\n\t\tfi\n\n\t\tend_func \"Results are saved in subdomains/s3buckets.txt and subdomains/cloud_assets.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$S3BUCKETS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$S3BUCKETS\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n########################################### WEB DETECTION #####################################################\n###############################################################################################################\n\nfunction webprobe_simple(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WEBPROBESIMPLE\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Http probing $domain\"\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tcat subdomains/subdomains.txt | httpx ${HTTPX_FLAGS} -no-color -json -random-agent -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -retries 2 -timeout $HTTPX_TIMEOUT -o .tmp/web_full_info_probe.txt 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\taxiom-scan subdomains/subdomains.txt -m httpx ${HTTPX_FLAGS} -no-color -json -random-agent -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -retries 2 -timeout $HTTPX_TIMEOUT -o .tmp/web_full_info_probe.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tcat .tmp/web_full_info.txt .tmp/web_full_info_probe.txt webs/web_full_info.txt 2>>\"$LOGFILE\" | jq -s 'try .' | jq 'try unique_by(.input)' | jq 'try .[]' 2>>\"$LOGFILE\" > webs/web_full_info.txt\n\t\t[ -s \"webs/web_full_info.txt\" ] && cat webs/web_full_info.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | anew -q .tmp/probed_tmp.txt\n\t\t[ -s \"webs/web_full_info.txt\" ] && cat webs/web_full_info.txt | jq -r 'try . |\"\\(.url) [\\(.status_code)] [\\(.title)] [\\(.webserver)] \\(.tech)\"' | grep \"$domain\" | anew -q webs/web_full_info_plain.txt\n\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/probed_tmp.txt\n\t\tNUMOFLINES=$(cat .tmp/probed_tmp.txt 2>>\"$LOGFILE\" | anew webs/webs.txt | sed '/^$/d' | wc -l)\n\t\tcat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tend_subfunc \"${NUMOFLINES} new websites resolved\" ${FUNCNAME[0]}\n\t\tif [ \"$PROXY\" = true ] && [ -n \"$proxy_url\" ] && [[ $(cat webs/webs.txt| wc -l) -le $DEEP_LIMIT2 ]]; then\n\t\t\tnotification \"Sending websites to proxy\" info\n\t\t\tffuf -mc all -w webs/webs.txt -u FUZZ -replay-proxy $proxy_url 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\telse\n\t\tif [ \"$WEBPROBESIMPLE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction webprobe_full(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WEBPROBEFULL\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Http probing non standard ports\"\n\t\tif [ -s \"subdomains/subdomains.txt\" ]; then\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tif [ -s \"subdomains/subdomains.txt\" ]; then\n\t\t\t\t\tcat subdomains/subdomains.txt | httpx -follow-host-redirects -random-agent -status-code -p $UNCOMMON_PORTS_WEB -threads $HTTPX_UNCOMMONPORTS_THREADS -timeout $HTTPX_UNCOMMONPORTS_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info_uncommon.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tif [ -s \"subdomains/subdomains.txt\" ]; then\n\t\t\t\t\taxiom-scan subdomains/subdomains.txt -m httpx -follow-host-redirects -H \\\"${HEADER}\\\" -status-code -p $UNCOMMON_PORTS_WEB -threads $HTTPX_UNCOMMONPORTS_THREADS -timeout $HTTPX_UNCOMMONPORTS_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info_uncommon.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\tfi\n\t\tfi\n\t\t[ -s \".tmp/web_full_info_uncommon.txt\" ] && cat .tmp/web_full_info_uncommon.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | anew -q .tmp/probed_uncommon_ports_tmp.txt\n\t\t[ -s \".tmp/web_full_info_uncommon.txt\" ] && cat .tmp/web_full_info_uncommon.txt | jq -r 'try . |\"\\(.url) [\\(.status_code)] [\\(.title)] [\\(.webserver)] \\(.tech)\"' | anew -q webs/web_full_info_uncommon_plain.txt\n\t\tif [ -s \".tmp/web_full_info_uncommon.txt\" ]; then\n\t\t\tif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then \n\t\t\t\tcat .tmp/web_full_info_uncommon.txt 2>>\"$LOGFILE\" | anew -q webs/web_full_info_uncommon.txt\n\t\t\telse\n\t\t\t\tcat .tmp/web_full_info_uncommon.txt 2>>\"$LOGFILE\" | grep \"$domain\" | anew -q webs/web_full_info_uncommon.txt\n\t\t\tfi\n\t\tfi\n\t\tNUMOFLINES=$(cat .tmp/probed_uncommon_ports_tmp.txt 2>>\"$LOGFILE\" | anew webs/webs_uncommon_ports.txt | sed '/^$/d' | wc -l)\n\t\tnotification \"Uncommon web ports: ${NUMOFLINES} new websites\" good\n\t\t[ -s \"webs/webs_uncommon_ports.txt\" ] && cat webs/webs_uncommon_ports.txt\n\t\tcat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tend_func \"Results are saved in $domain/webs/webs_uncommon_ports.txt\" ${FUNCNAME[0]}\n\t\tif [ \"$PROXY\" = true ] && [ -n \"$proxy_url\" ] && [[ $(cat webs/webs_uncommon_ports.txt| wc -l) -le $DEEP_LIMIT2 ]]; then\n\t\t\tnotification \"Sending websites with uncommon ports to proxy\" info\n\t\t\tffuf -mc all -w webs/webs_uncommon_ports.txt -u FUZZ -replay-proxy $proxy_url 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\telse\n\t\tif [ \"$WEBPROBEFULL\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction screenshot(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WEBSCREENSHOT\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Web Screenshots\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\t\n\t\tnum_lines=$(wc -l < .tmp/webs_all.txt)\n\t\tdynamic_gowitness_timeout=$(expr $num_lines \\* $GOWITNESS_TIMEOUT_PER_SITE)\n\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \".tmp/webs_all.txt\" ] && timeout -k 1m ${dynamic_gowitness_timeout}s gowitness file -f .tmp/webs_all.txt -t $GOWITNESS_THREADS $GOWITNESS_FLAGS 2>>\"$LOGFILE\"\n\t\telse\n\t\t\ttimeout -k 1m ${dynamic_gowitness_timeout}s axiom-scan .tmp/webs_all.txt -m gowitness -t $GOWITNESS_THREADS $GOWITNESS_FLAGS -o screenshots $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tend_func \"Results are saved in $domain/screenshots folder\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$WEBSCREENSHOT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction virtualhosts(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$VIRTUALHOSTS\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Virtual Hosts dicovery\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\tmkdir -p $dir/virtualhosts $dir/.tmp/virtualhosts\n\t\t\tinterlace -tL .tmp/webs_all.txt -threads ${INTERLACE_THREADS} -c \"ffuf -ac -t ${FFUF_THREADS} -rate ${FFUF_RATELIMIT} -H \\\"${HEADER}\\\" -H \\\"Host: FUZZ._cleantarget_\\\" -w ${fuzz_wordlist} -maxtime ${FFUF_MAXTIME} -u  _target_ -of json -o _output_/_cleantarget_.json\" -o $dir/.tmp/virtualhosts 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfor sub in $(cat .tmp/webs_all.txt); do\n\t\t\t\tsub_out=$(echo $sub | sed -e 's|^[^/]*//||' -e 's|/.*$||')\n\t\t\t\t[ -s \"$dir/.tmp/virtualhosts/${sub_out}.json\" ] && cat $dir/.tmp/virtualhosts/${sub_out}.json | jq -r 'try .results[] | \"\\(.status) \\(.length) \\(.url)\"' | sort | anew -q $dir/virtualhosts/${sub_out}.txt\n\t\t\tdone\n\t\t\tfind $dir/virtualhosts/ -type f -iname \"*.txt\" -exec cat {} + 2>>\"$LOGFILE\" | anew -q $dir/virtualhosts/virtualhosts_full.txt\n\t\t\tend_func \"Results are saved in $domain/virtualhosts/*subdomain*.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"No $domain/web/webs.txts file found, virtualhosts skipped \" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$VIRTUALHOSTS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n############################################# HOST SCAN #######################################################\n###############################################################################################################\n\nfunction favicon(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$FAVICON\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Favicon Ip Lookup\"\n\t\tcd \"$tools/fav-up\" || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tpython3 favUp.py -w \"$domain\" -sc -o favicontest.json 2>>\"$LOGFILE\" >/dev/null\n\t\tif [ -s \"favicontest.json\" ]; then\n\t\t\tcat favicontest.json | jq -r 'try .found_ips' 2>>\"$LOGFILE\" | grep -v \"not-found\" > favicontest.txt\n\t\t\tsed -i \"s/|/\\n/g\" favicontest.txt\n\t\t\tcat favicontest.txt 2>>\"$LOGFILE\"\n\t\t\tmv favicontest.txt $dir/hosts/favicontest.txt 2>>\"$LOGFILE\"\n\t\t\trm -f favicontest.json 2>>\"$LOGFILE\"\n\t\tfi\n\t\tcd \"$dir\" || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tend_func \"Results are saved in hosts/favicontest.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$FAVICON\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$FAVICON\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction portscan(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$PORTSCANNER\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Port scan\"\n\t\tif ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try . | \"\\(.host) \\(.a[0])\"' | anew -q .tmp/subs_ips.txt\n\t\t\t[ -s \".tmp/subs_ips.txt\" ] && awk '{ print $2 \" \" $1}' .tmp/subs_ips.txt | sort -k2 -n | anew -q hosts/subs_ips_vhosts.txt\n\t\t\t[ -s \"hosts/subs_ips_vhosts.txt\" ] && cat hosts/subs_ips_vhosts.txt | cut -d ' ' -f1 | grep -aEiv \"^(127|10|169\\.154|172\\.1[6789]|172\\.2[0-9]|172\\.3[01]|192\\.168)\\.\" | grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" | anew -q hosts/ips.txt\n\t\telse echo $domain | grep -aEiv \"^(127|10|169\\.154|172\\.1[6789]|172\\.2[0-9]|172\\.3[01]|192\\.168)\\.\" | grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" | anew -q hosts/ips.txt\n\t\tfi\n\t\t[ ! -s \"hosts/cdn_providers.txt\" ] && cat hosts/ips.txt 2>/dev/null | cdncheck -silent -resp -nc 2>/dev/null > hosts/cdn_providers.txt\n\t\t[ -s \"hosts/ips.txt\" ] && comm -23 <(cat hosts/ips.txt | sort -u) <(cat hosts/cdn_providers.txt | cut -d'[' -f1 | sed 's/[[:space:]]*$//' | sort -u) | grep -aEiv \"^(127|10|169\\.154|172\\.1[6789]|172\\.2[0-9]|172\\.3[01]|192\\.168)\\.\" | grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" | sort -u | anew -q .tmp/ips_nocdn.txt\n\t\tprintf \"${bblue}\\n Resolved IP addresses (No CDN) ${reset}\\n\\n\";\n\t\t[ -s \".tmp/ips_nocdn.txt\" ] && cat .tmp/ips_nocdn.txt | sort\n\t\tprintf \"${bblue}\\n Scanning ports... ${reset}\\n\\n\";\n\t\tif [ \"$PORTSCAN_PASSIVE\" = true ] && [ ! -f \"hosts/portscan_passive.txt\" ] && [ -s \".tmp/ips_nocdn.txt\" ] ; then\n\t\t\tsmap -iL .tmp/ips_nocdn.txt > hosts/portscan_passive.txt\n\t\tfi\n\t\tif [ \"$PORTSCAN_ACTIVE\" = true ]; then\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\t[ -s \".tmp/ips_nocdn.txt\" ] && $SUDO nmap --top-ports 200 -sV -n --max-retries 2 -Pn --open --script vulners -iL .tmp/ips_nocdn.txt -oA hosts/portscan_active 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\t[ -s \".tmp/ips_nocdn.txt\" ] && axiom-scan .tmp/ips_nocdn.txt -m nmapx --top-ports 200 -sV -n -Pn --open --max-retries 2 --script vulners -oA hosts/portscan_active $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\tfi\n\t\tend_func \"Results are saved in hosts/portscan_[passive|active].txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$PORTSCANNER\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction cdnprovider(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$CDN_IP\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"CDN provider check\"\n\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try . | .a[]' | grep -aEiv \"^(127|10|169\\.154|172\\.1[6789]|172\\.2[0-9]|172\\.3[01]|192\\.168)\\.\" | grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" | sort -u > .tmp/ips_cdn.txt\n\t\t[ -s \".tmp/ips_cdn.txt\" ] && cat .tmp/ips_cdn.txt | cdncheck -silent -resp -nc | anew -q $dir/hosts/cdn_providers.txt\n\t\tend_func \"Results are saved in hosts/cdn_providers.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$CDN_IP\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n############################################# WEB SCAN ########################################################\n###############################################################################################################\n\nfunction waf_checks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WAF_DETECTION\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Website's WAF detection\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\twafw00f -i .tmp/webs_all.txt -o .tmp/wafs.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\taxiom-scan .tmp/webs_all.txt -m wafw00f -o .tmp/wafs.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\tif [ -s \".tmp/wafs.txt\" ]; then\n\t\t\t\tcat .tmp/wafs.txt | sed -e 's/^[ \\t]*//' -e 's/ \\+ /\\t/g' -e '/(None)/d' | tr -s \"\\t\" \";\" > webs/webs_wafs.txt\n\t\t\t\tNUMOFLINES=$(cat webs/webs_wafs.txt 2>>\"$LOGFILE\" | sed '/^$/d' | wc -l)\n\t\t\t\tnotification \"${NUMOFLINES} websites protected by waf\" info\n\t\t\t\tend_func \"Results are saved in $domain/webs/webs_wafs.txt\" ${FUNCNAME[0]}\n\t\t\telse\n\t\t\t\tend_func \"No results found\" ${FUNCNAME[0]}\n\t\t\tfi\n\t\telse\n\t\t\tend_func \"No websites to scan\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$WAF_DETECTION\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction nuclei_check(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$NUCLEICHECK\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Templates based web scanner\"\n\t\tnuclei -update 2>>\"$LOGFILE\" >/dev/null\n\t\tmkdir -p nuclei_output\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\t[ ! -s \".tmp/webs_subs.txt\" ] && cat subdomains/subdomains.txt .tmp/webs_all.txt 2>>\"$LOGFILE\" | anew -q .tmp/webs_subs.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then                 # avoid globbing (expansion of *).\n\t\t\tIFS=',' read -ra severity_array <<< \"$NUCLEI_SEVERITY\"\n\t\t\tfor crit in \"${severity_array[@]}\"\n\t\t\tdo\n\t\t\t\tprintf \"${yellow}\\n Running : Nuclei $crit ${reset}\\n\\n\"\n\t\t\t\tcat .tmp/webs_subs.txt 2>/dev/null | nuclei $NUCLEI_FLAGS -severity $crit -nh -rl $NUCLEI_RATELIMIT -o nuclei_output/${crit}.txt\n\t\t\tdone\n\t\t\tprintf \"\\n\\n\"\n\t\telse\n\t\t\tif [ -s \".tmp/webs_subs.txt\" ]; then\n\t\t\t\tIFS=',' read -ra severity_array <<< \"$NUCLEI_SEVERITY\"\n\t\t\t\tfor crit in \"${severity_array[@]}\"\n\t\t\t\tdo\n\t\t\t\t\tprintf \"${yellow}\\n Running : Nuclei $crit, check results on nuclei_output folder${reset}\\n\\n\"\n\t\t\t\t\taxiom-scan .tmp/webs_subs.txt -m nuclei --nuclei-templates ${NUCLEI_TEMPLATES_PATH} -severity ${crit} -nh -rl $NUCLEI_RATELIMIT -o nuclei_output/${crit}.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t[ -s \"nuclei_output/${crit}.txt\" ] && cat nuclei_output/${crit}.txt\n\t\t\t\tdone\n\t\t\t\tprintf \"\\n\\n\"\n\t\t\tfi\n\t\tfi\n\t\tend_func \"Results are saved in $domain/nuclei_output folder\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$NUCLEICHECK\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction fuzz(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$FUZZ\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Web directory fuzzing\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\tmkdir -p $dir/fuzzing $dir/.tmp/fuzzing\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tinterlace -tL .tmp/webs_all.txt -threads ${INTERLACE_THREADS} -c \"ffuf ${FFUF_FLAGS} -t ${FFUF_THREADS} -rate ${FFUF_RATELIMIT} -H \\\"${HEADER}\\\" -w ${fuzz_wordlist} -maxtime ${FFUF_MAXTIME} -u _target_/FUZZ -o _output_/_cleantarget_.json\" -o $dir/.tmp/fuzzing 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfor sub in $(cat .tmp/webs_all.txt); do\n\t\t\t\t\tsub_out=$(echo $sub | sed -e 's|^[^/]*//||' -e 's|/.*$||')\n\t\t\t\t\t[ -s \"$dir/.tmp/fuzzing/${sub_out}.json\" ] && cat $dir/.tmp/fuzzing/${sub_out}.json | jq -r 'try .results[] | \"\\(.status) \\(.length) \\(.url)\"' | sort -k1 | anew -q $dir/fuzzing/${sub_out}.txt\n\t\t\t\tdone\n\t\t\t\tfind $dir/fuzzing/ -type f -iname \"*.txt\" -exec cat {} + 2>>\"$LOGFILE\" | sort -k1 | anew -q $dir/fuzzing/fuzzing_full.txt\n\t\t\telse\n\t\t\t\taxiom-exec \"mkdir -p /home/op/lists/seclists/Discovery/Web-Content/\" &>/dev/null\n\t\t\t\taxiom-exec \"wget -q -O - ${fuzzing_remote_list} > /home/op/lists/fuzz_wordlist.txt\" &>/dev/null\n\t\t\t\taxiom-exec \"wget -q -O - ${fuzzing_remote_list} > /home/op/lists/seclists/Discovery/Web-Content/big.txt\" &>/dev/null\n\t\t\t\taxiom-scan .tmp/webs_all.txt -m ffuf_base -H \"${HEADER}\" $FFUF_FLAGS -s -maxtime $FFUF_MAXTIME -o $dir/.tmp/ffuf-content.json $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfor sub in $(cat .tmp/webs_all.txt); do\n\t\t\t\t\tsub_out=$(echo $sub | sed -e 's|^[^/]*//||' -e 's|/.*$||')\n\t\t\t\t\t[ -s \"$dir/.tmp/ffuf-content.json\" ] && cat .tmp/ffuf-content.json | jq -r 'try .results[] | \"\\(.status) \\(.length) \\(.url)\"' | grep $sub | sort -k1 | anew -q fuzzing/${sub_out}.txt\n\t\t\t\tdone\n\t\t\t\tfind $dir/fuzzing/ -type f -iname \"*.txt\" -exec cat {} + 2>>\"$LOGFILE\" | sort -k1 | anew -q $dir/fuzzing/fuzzing_full.txt\n\t\t\tfi\n\t\t\tend_func \"Results are saved in $domain/fuzzing/*subdomain*.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"No $domain/web/webs.txts file found, fuzzing skipped \" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$FUZZ\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction cms_scanner(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$CMS_SCANNER\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"CMS Scanner\"\n\t\tmkdir -p $dir/cms && rm -rf $dir/cms/*\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\ttr '\\n' ',' < .tmp/webs_all.txt > .tmp/cms.txt\n\t\t\ttimeout -k 1m ${CMSSCAN_TIMEOUT}s python3 $tools/CMSeeK/cmseek.py -l .tmp/cms.txt --batch -r 2>>\"$LOGFILE\" &>/dev/null\n\t\t\texit_status=$?\n\t\t\tif [[ $exit_status -eq 125 ]]; then\n\t\t\t\techo \"TIMEOUT cmseek.py - investigate manually for $dir\" >> \"$LOGFILE\"\n\t\t\t\tend_func \"TIMEOUT cmseek.py - investigate manually for $dir\" ${FUNCNAME[0]}\n\t\t\t\treturn\n\t\t\telif [[ $exit_status -ne 0 ]]; then\n\t\t\t\techo \"ERROR cmseek.py - investigate manually for $dir\" >> \"$LOGFILE\"\n\t\t\t\tend_func \"ERROR cmseek.py - investigate manually for $dir\" ${FUNCNAME[0]}\n\t\t\t\treturn\n\t\t\tfi\t# otherwise Assume we have a successfully exited cmseek\n\t\t\tfor sub in $(cat .tmp/webs_all.txt); do\n\t\t\t\tsub_out=$(echo $sub | sed -e 's|^[^/]*//||' -e 's|/.*$||')\n\t\t\t\tcms_id=$(cat $tools/CMSeeK/Result/${sub_out}/cms.json 2>/dev/null | jq -r 'try .cms_id')\n\t\t\t\tif [ -z \"$cms_id\" ]; then\n\t\t\t\t\trm -rf $tools/CMSeeK/Result/${sub_out}\n\t\t\t\telse\n\t\t\t\t\tmv -f $tools/CMSeeK/Result/${sub_out} $dir/cms/ 2>>\"$LOGFILE\"\n\t\t\t\tfi\n\t\t\tdone\n\t\t\tend_func \"Results are saved in $domain/cms/*subdomain* folder\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"No $domain/web/webs.txts file found, cms scanner skipped\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$CMS_SCANNER\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction urlchecks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$URL_CHECK\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"URL Extraction\"\n\t\tmkdir -p js\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tif [ \"$URL_CHECK_PASSIVE\" = true ]; then\n\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\tcat .tmp/webs_all.txt | unfurl -u domains > .tmp/waymore_input.txt\n\t\t\t\t\t\tpython3 $tools/waymore/waymore.py -i .tmp/waymore_input.txt -mode U -f -oU .tmp/url_extract_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\telse\n\t\t\t\t\t\tcat .tmp/webs_all.txt | gau --threads $GAU_THREADS | anew -q .tmp/url_extract_tmp.txt\n\t\t\t\t\tfi\n\t\t\t\t\tif [ -s \"${GITHUB_TOKENS}\" ]; then\n\t\t\t\t\t\tgithub-endpoints -q -k -d $domain -t ${GITHUB_TOKENS} -o .tmp/github-endpoints.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\t[ -s \".tmp/github-endpoints.txt\" ] && cat .tmp/github-endpoints.txt | anew -q .tmp/url_extract_tmp.txt\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\t\tdiff_webs=$(diff <(sort -u .tmp/probed_tmp.txt 2>>\"$LOGFILE\") <(sort -u .tmp/webs_all.txt 2>>\"$LOGFILE\") | wc -l)\n\t\t\t\tif [ $diff_webs != \"0\" ] || [ ! -s \".tmp/katana.txt\" ]; then\n\t\t\t\t\tif [ \"$URL_CHECK_ACTIVE\" = true ]; then\n\t\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\t\tkatana -silent -list .tmp/webs_all.txt -jc -kf all -c $KATANA_THREADS -d 3 -fs rdn -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tkatana -silent -list .tmp/webs_all.txt -jc -kf all -c $KATANA_THREADS -d 2 -fs rdn -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\tfi\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tif [ \"$URL_CHECK_PASSIVE\" = true ]; then\n\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\tcat .tmp/webs_all.txt | unfurl -u domains > .tmp/waymore_input.txt\n\t\t\t\t\t\taxiom-scan .tmp/waymore_input.txt -m waymore -o .tmp/url_extract_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\telse\n\t\t\t\t\t\taxiom-scan .tmp/webs_all.txt -m gau -o .tmp/url_extract_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\tfi\n\t\t\t\t\tif [ -s \"${GITHUB_TOKENS}\" ]; then\n\t\t\t\t\t\tgithub-endpoints -q -k -d $domain -t ${GITHUB_TOKENS} -o .tmp/github-endpoints.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\t[ -s \".tmp/github-endpoints.txt\" ] && cat .tmp/github-endpoints.txt | anew -q .tmp/url_extract_tmp.txt\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\t\tdiff_webs=$(diff <(sort -u .tmp/probed_tmp.txt) <(sort -u .tmp/webs_all.txt) | wc -l)\n\t\t\t\tif [ $diff_webs != \"0\" ] || [ ! -s \".tmp/katana.txt\" ]; then\n\t\t\t\t\tif [ \"$URL_CHECK_ACTIVE\" = true ]; then\n\t\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\t\taxiom-scan .tmp/webs_all.txt -m katana -jc -kf all -d 3 -fs rdn -fs rdn -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\taxiom-scan .tmp/webs_all.txt -m katana -jc -kf all -d 2 -fs rdn -fs rdn -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\tfi\t\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\tfi\n\t\t\t[ -s \".tmp/katana.txt\" ] && sed -i '/^.\\{2048\\}./d' .tmp/katana.txt\n\t\t\t[ -s \".tmp/katana.txt\" ] && cat .tmp/katana.txt | anew -q .tmp/url_extract_tmp.txt\n\t\t\t[ -s \".tmp/url_extract_tmp.txt\" ] && cat .tmp/url_extract_tmp.txt | grep \"${domain}\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | grep -aEi \"\\.(js)\" | anew -q .tmp/url_extract_js.txt\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t[ -s \".tmp/url_extract_js.txt\" ] && interlace -tL .tmp/url_extract_js.txt -threads 10 -c \"python3 $tools/JSA/jsa.py -f target | anew -q .tmp/url_extract_tmp.txt\" &>/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/url_extract_tmp.txt\" ] &&  cat .tmp/url_extract_tmp.txt | grep \"${domain}\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | grep \"=\" | qsreplace -a 2>>\"$LOGFILE\" | grep -aEiv \"\\.(eot|jpg|jpeg|gif|css|tif|tiff|png|ttf|otf|woff|woff2|ico|pdf|svg|txt|js)$\" | anew -q .tmp/url_extract_tmp2.txt\n\t\t\t[ -s \".tmp/url_extract_tmp2.txt\" ] && cat .tmp/url_extract_tmp2.txt | python3 $tools/urless/urless/urless.py | anew -q .tmp/url_extract_uddup.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tNUMOFLINES=$(cat .tmp/url_extract_uddup.txt 2>>\"$LOGFILE\" | anew webs/url_extract.txt | sed '/^$/d' | wc -l)\n\t\t\tnotification \"${NUMOFLINES} new urls with params\" info\n\t\t\tend_func \"Results are saved in $domain/webs/url_extract.txt\" ${FUNCNAME[0]}\n\t\t\tif [ \"$PROXY\" = true ] && [ -n \"$proxy_url\" ] && [[ $(cat webs/url_extract.txt | wc -l) -le $DEEP_LIMIT2 ]]; then\n\t\t\t\tnotification \"Sending urls to proxy\" info\n\t\t\t\tffuf -mc all -w webs/url_extract.txt -u FUZZ -replay-proxy $proxy_url 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\tfi\n\telse\n\t\tif [ \"$URL_CHECK\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction url_gf(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$URL_GF\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Vulnerable Pattern Search\"\n\t\tmkdir -p gf\n\t\tif [ -s \"webs/url_extract.txt\" ]; then\n\t\t\tgf xss webs/url_extract.txt | anew -q gf/xss.txt\n\t\t\tgf ssti webs/url_extract.txt | anew -q gf/ssti.txt\n\t\t\tgf ssrf webs/url_extract.txt | anew -q gf/ssrf.txt\n\t\t\tgf sqli webs/url_extract.txt | anew -q gf/sqli.txt\n\t\t\tgf redirect webs/url_extract.txt | anew -q gf/redirect.txt\n\t\t\t[ -s \"gf/ssrf.txt\" ] && cat gf/ssrf.txt | anew -q gf/redirect.txt\n\t\t\tgf rce webs/url_extract.txt | anew -q gf/rce.txt\n\t\t\tgf potential webs/url_extract.txt | cut -d ':' -f3-5 |anew -q gf/potential.txt\n\t\t\t[ -s \".tmp/url_extract_tmp.txt\" ] && cat .tmp/url_extract_tmp.txt | grep -aEiv \"\\.(eot|jpg|jpeg|gif|css|tif|tiff|png|ttf|otf|woff|woff2|ico|pdf|svg|txt|js)$\" | unfurl -u format %s://%d%p 2>>\"$LOGFILE\" | anew -q gf/endpoints.txt\n\t\t\tgf lfi webs/url_extract.txt | anew -q gf/lfi.txt\n\t\tfi\n\t\tend_func \"Results are saved in $domain/gf folder\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$URL_GF\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction url_ext(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$URL_EXT\" = true ]; then\n\t\tif [ -s \".tmp/url_extract_tmp.txt\" ]; then\n\t\t\tstart_func ${FUNCNAME[0]} \"Urls by extension\"\n\t\t\text=(\"7z\" \"achee\" \"action\" \"adr\" \"apk\" \"arj\" \"ascx\" \"asmx\" \"asp\" \"aspx\" \"axd\" \"backup\" \"bak\" \"bat\" \"bin\" \"bkf\" \"bkp\" \"bok\" \"cab\" \"cer\" \"cfg\" \"cfm\" \"cfml\" \"cgi\" \"cnf\" \"conf\" \"config\" \"cpl\" \"crt\" \"csr\" \"csv\" \"dat\" \"db\" \"dbf\" \"deb\" \"dmg\" \"dmp\" \"doc\" \"docx\" \"drv\" \"email\" \"eml\" \"emlx\" \"env\" \"exe\" \"gadget\" \"gz\" \"html\" \"ica\" \"inf\" \"ini\" \"iso\" \"jar\" \"java\" \"jhtml\" \"json\" \"jsp\" \"key\" \"log\" \"lst\" \"mai\" \"mbox\" \"mbx\" \"md\" \"mdb\" \"msg\" \"msi\" \"nsf\" \"ods\" \"oft\" \"old\" \"ora\" \"ost\" \"pac\" \"passwd\" \"pcf\" \"pdf\" \"pem\" \"pgp\" \"php\" \"php3\" \"php4\" \"php5\" \"phtm\" \"phtml\" \"pkg\" \"pl\" \"plist\" \"pst\" \"pwd\" \"py\" \"rar\" \"rb\" \"rdp\" \"reg\" \"rpm\" \"rtf\" \"sav\" \"sh\" \"shtm\" \"shtml\" \"skr\" \"sql\" \"swf\" \"sys\" \"tar\" \"tar.gz\" \"tmp\" \"toast\" \"tpl\" \"txt\" \"url\" \"vcd\" \"vcf\" \"wml\" \"wpd\" \"wsdl\" \"wsf\" \"xls\" \"xlsm\" \"xlsx\" \"xml\" \"xsd\" \"yaml\" \"yml\" \"z\" \"zip\")\n\t\t\t#echo \"\" > webs/url_extract.txt\n\t\t\tfor t in \"${ext[@]}\"; do\n\t\t\t\tNUMOFLINES=$(cat .tmp/url_extract_tmp.txt | grep -aEi \"\\.(${t})($|\\/|\\?)\" | sort -u | sed '/^$/d' | wc -l)\n\t\t\t\tif [[ ${NUMOFLINES} -gt 0 ]]; then\n\t\t\t\t\techo -e \"\\n############################\\n + ${t} + \\n############################\\n\" >> webs/urls_by_ext.txt\n\t\t\t\t\tcat .tmp/url_extract_tmp.txt | grep -aEi \"\\.(${t})($|\\/|\\?)\" >> webs/urls_by_ext.txt\n\t\t\t\tfi\n\t\t\tdone\n\t\t\tend_func \"Results are saved in $domain/webs/urls_by_ext.txt\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$URL_EXT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction jschecks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$JSCHECKS\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Javascript Scan\"\n\t\tif [ -s \".tmp/url_extract_js.txt\" ]; then\n\t\t\tprintf \"${yellow} Running : Fetching Urls 1/5${reset}\\n\"\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tcat .tmp/url_extract_js.txt | subjs -ua \"Mozilla/5.0 (X11; Linux x86_64; rv:72.0) Gecko/20100101 Firefox/72.0\" -c 40 | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/subjslinks.txt\n\t\t\telse\n\t\t\t\taxiom-scan .tmp/url_extract_js.txt -m subjs -o .tmp/subjslinks.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/subjslinks.txt\" ] && cat .tmp/subjslinks.txt | egrep -iv \"\\.(eot|jpg|jpeg|gif|css|tif|tiff|png|ttf|otf|woff|woff2|ico|pdf|svg|txt|js)\" | anew -q js/nojs_links.txt\n\t\t\t[ -s \".tmp/subjslinks.txt\" ] && cat .tmp/subjslinks.txt | grep -iE \"\\.js($|\\?)\" | anew -q .tmp/url_extract_js.txt\n\t\t\tcat .tmp/url_extract_js.txt | python3 $tools/urless/urless/urless.py | anew -q js/url_extract_js.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tprintf \"${yellow} Running : Resolving JS Urls 2/5${reset}\\n\"\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\t[ -s \"js/url_extract_js.txt\" ] && cat js/url_extract_js.txt | httpx -follow-redirects -random-agent -silent -timeout $HTTPX_TIMEOUT -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -status-code -content-type -retries 2 -no-color | grep \"[200]\" | grep \"javascript\" | cut -d ' ' -f1 | anew -q js/js_livelinks.txt\n\t\t\telse\n\t\t\t\t[ -s \"js/url_extract_js.txt\" ] && axiom-scan js/url_extract_js.txt -m httpx -follow-host-redirects -H \\\"${HEADER}\\\" -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -content-type -retries 2 -no-color -o .tmp/js_livelinks.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t[ -s \".tmp/js_livelinks.txt\" ] && cat .tmp/js_livelinks.txt | anew .tmp/web_full_info.txt | grep \"[200]\" | grep \"javascript\" | cut -d ' ' -f1 | anew -q js/js_livelinks.txt\n\t\t\tfi\n\t\t\tprintf \"${yellow} Running : Gathering endpoints 3/5${reset}\\n\"\n\t\t\t[ -s \"js/js_livelinks.txt\" ] && python3 $tools/xnLinkFinder/xnLinkFinder.py -i js/js_livelinks.txt -sf subdomains/subdomains.txt -d $XNLINKFINDER_DEPTH -o .tmp/js_endpoints.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \"parameters.txt\" ] && rm -f parameters.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tif [ -s \".tmp/js_endpoints.txt\" ]; then\n\t\t\t\tsed -i '/^\\//!d' .tmp/js_endpoints.txt\n\t\t\t\tcat .tmp/js_endpoints.txt | anew -q js/js_endpoints.txt\n\t\t\tfi\n\t\t\tprintf \"${yellow} Running : Gathering secrets 4/5${reset}\\n\"\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\t[ -s \"js/js_livelinks.txt\" ] && cat js/js_livelinks.txt | Mantra -ua ${HEADER} -s | anew -q js/js_secrets.txt\n\t\t\telse\n\t\t\t\t[ -s \"js/js_livelinks.txt\" ] && axiom-scan js/js_livelinks.txt -m mantra -ua \\\"${HEADER}\\\" -s -o js/js_secrets.txt $AXIOM_EXTRA_ARGS &>/dev/null\n\t\t\tfi\n\t\t\t[ -s \"js/js_secrets.txt\" ] && sed -r \"s/\\x1B\\[([0-9]{1,3}(;[0-9]{1,2};?)?)?[mGK]//g\" -i js/js_secrets.txt\n\t\t\tprintf \"${yellow} Running : Building wordlist 5/5${reset}\\n\"\n\t\t\t[ -s \"js/js_livelinks.txt\" ] && interlace -tL js/js_livelinks.txt -threads ${INTERLACE_THREADS}  -c \"python3 $tools/getjswords.py '_target_' | anew -q webs/dict_words.txt\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\tend_func \"Results are saved in $domain/js folder\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"No JS urls found for $domain, function skipped\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$JSCHECKS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction wordlist_gen(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WORDLIST\" = true ];\tthen\n\t\tstart_func ${FUNCNAME[0]} \"Wordlist generation\"\n\t\tif [ -s \".tmp/url_extract_tmp.txt\" ]; then\n\t\t\tcat .tmp/url_extract_tmp.txt | unfurl -u keys 2>>\"$LOGFILE\" | sed 's/[][]//g' | sed 's/[#]//g' | sed 's/[}{]//g' | anew -q webs/dict_params.txt\n\t\t\tcat .tmp/url_extract_tmp.txt | unfurl -u values 2>>\"$LOGFILE\" | sed 's/[][]//g' | sed 's/[#]//g' | sed 's/[}{]//g' | anew -q webs/dict_values.txt\n\t\t\tcat .tmp/url_extract_tmp.txt | tr \"[:punct:]\" \"\\n\" | anew -q webs/dict_words.txt\n\t\tfi\n\t\t[ -s \".tmp/js_endpoints.txt\" ] && cat .tmp/js_endpoints.txt | unfurl -u format %s://%d%p 2>>\"$LOGFILE\" | anew -q webs/all_paths.txt\n\t\t[ -s \".tmp/url_extract_tmp.txt\" ] && cat .tmp/url_extract_tmp.txt | unfurl -u format %s://%d%p 2>>\"$LOGFILE\" | anew -q webs/all_paths.txt\n\t\tend_func \"Results are saved in $domain/webs/dict_[words|paths].txt\" ${FUNCNAME[0]}\n\t\tif [ \"$PROXY\" = true ] && [ -n \"$proxy_url\" ] && [[ $(cat webs/all_paths.txt | wc -l) -le $DEEP_LIMIT2 ]]; then\n\t\t\tnotification \"Sending urls to proxy\" info\n\t\t\tffuf -mc all -w webs/all_paths.txt -u FUZZ -replay-proxy $proxy_url 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\telse\n\t\tif [ \"$WORDLIST\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction wordlist_gen_roboxtractor(){\n\tif  { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$ROBOTSWORDLIST\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Robots wordlist generation\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\tcat .tmp/webs_all.txt | roboxtractor -m 1 -wb 2>/dev/null | anew -q webs/robots_wordlist.txt\n\t\tfi\n\t\tend_func \"Results are saved in $domain/webs/robots_wordlist.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$ROBOTSWORDLIST\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction password_dict(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$PASSWORD_DICT\" = true ];\tthen\n\t\tstart_func ${FUNCNAME[0]} \"Password dictionary generation\"\n\t\tword=${domain%%.*}\n\t\tpython3 $tools/pydictor/pydictor.py -extend $word --leet 0 1 2 11 21 --len ${PASSWORD_MIN_LENGTH} ${PASSWORD_MAX_LENGTH} -o webs/password_dict.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tend_func \"Results are saved in $domain/webs/password_dict.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$PASSWORD_DICT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n######################################### VULNERABILITIES #####################################################\n###############################################################################################################\n\nfunction brokenLinks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$BROKENLINKS\" = true ] ; then\n\t\tstart_func ${FUNCNAME[0]} \"Broken links checks\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tif [ ! -s \".tmp/katana.txt\" ]; then\n\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t[ -s \".tmp/webs_all.txt\" ] && katana -silent -list .tmp/webs_all.txt -jc -kf all -c $KATANA_THREADS -d 3 -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\telse\n\t\t\t\t\t[ -s \".tmp/webs_all.txt\" ] && katana -silent -list .tmp/webs_all.txt -jc -kf all -c $KATANA_THREADS -d 2 -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\tfi\n\t\t\t[ -s \".tmp/katana.txt\" ] && sed -i '/^.\\{2048\\}./d' .tmp/katana.txt\n\t\telse\n\t\t\tif [ ! -s \".tmp/katana.txt\" ]; then\n\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t[ -s \".tmp/webs_all.txt\" ] && axiom-scan .tmp/webs_all.txt -m katana -jc -kf all -d 3 -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\telse\n\t\t\t\t\t[ -s \".tmp/webs_all.txt\" ] && axiom-scan .tmp/webs_all.txt -m katana -jc -kf all -d 2 -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\t\t[ -s \".tmp/katana.txt\" ] && sed -i '/^.\\{2048\\}./d' .tmp/katana.txt\n\t\t\tfi\n\t\tfi\n\t\t[ -s \".tmp/katana.txt\" ] && cat .tmp/katana.txt | sort -u | httpx -follow-redirects -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -no-color | grep \"\\[4\" | cut -d ' ' -f1 | anew -q .tmp/brokenLinks_total.txt\n\t\tNUMOFLINES=$(cat .tmp/brokenLinks_total.txt 2>>\"$LOGFILE\" | anew vulns/brokenLinks.txt | sed '/^$/d' | wc -l)\n\t\tnotification \"${NUMOFLINES} new broken links found\" info\n\t\tend_func \"Results are saved in vulns/brokenLinks.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$BROKENLINKS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction xss(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$XSS\" = true ] && [ -s \"gf/xss.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"XSS Analysis\"\n\t\t[ -s \"gf/xss.txt\" ] && cat gf/xss.txt | qsreplace FUZZ | sed '/FUZZ/!d' | Gxss -c 100 -p Xss | qsreplace FUZZ | sed '/FUZZ/!d' | anew -q .tmp/xss_reflected.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\t\t\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tif [ -n \"$XSS_SERVER\" ]; then\n\t\t\t\t\t[ -s \".tmp/xss_reflected.txt\" ] && cat .tmp/xss_reflected.txt | dalfox pipe --silence --no-color --no-spinner --only-poc r --ignore-return 302,404,403 --skip-bav -b ${XSS_SERVER} -w $DALFOX_THREADS 2>>\"$LOGFILE\" | anew -q vulns/xss.txt\n\t\t\t\telse\n\t\t\t\t\tprintf \"${yellow}\\n No XSS_SERVER defined, blind xss skipped\\n\\n\"\n\t\t\t\t\t[ -s \".tmp/xss_reflected.txt\" ] && cat .tmp/xss_reflected.txt | dalfox pipe --silence --no-color --no-spinner --only-poc r --ignore-return 302,404,403 --skip-bav -w $DALFOX_THREADS 2>>\"$LOGFILE\" | anew -q vulns/xss.txt\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tif [[ $(cat .tmp/xss_reflected.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t\t\tif [ -n \"$XSS_SERVER\" ]; then\n\t\t\t\t\t\tcat .tmp/xss_reflected.txt | dalfox pipe --silence --no-color --no-spinner --skip-bav --skip-mining-dom --skip-mining-dict --only-poc r --ignore-return 302,404,403 -b ${XSS_SERVER} -w $DALFOX_THREADS 2>>\"$LOGFILE\" | anew -q vulns/xss.txt\n\t\t\t\t\telse\n\t\t\t\t\t\tprintf \"${yellow}\\n No XSS_SERVER defined, blind xss skipped\\n\\n\"\n\t\t\t\t\t\tcat .tmp/xss_reflected.txt | dalfox pipe --silence --no-color --no-spinner --skip-bav --skip-mining-dom --skip-mining-dict --only-poc r --ignore-return 302,404,403 -w $DALFOX_THREADS 2>>\"$LOGFILE\" | anew -q vulns/xss.txt\n\t\t\t\t\tfi\n\t\t\t\telse\n\t\t\t\t\tprintf \"${bred} Skipping XSS: Too many URLs to test, try with --deep flag${reset}\\n\"\n\t\t\t\tfi\n\t\t\tfi\n\t\telse\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tif [ -n \"$XSS_SERVER\" ]; then\n\t\t\t\t\t[ -s \".tmp/xss_reflected.txt\" ] && axiom-scan .tmp/xss_reflected.txt -m dalfox --skip-bav -b ${XSS_SERVER} -w $DALFOX_THREADS -o vulns/xss.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\telse\n\t\t\t\t\tprintf \"${yellow}\\n No XSS_SERVER defined, blind xss skipped\\n\\n\"\n\t\t\t\t\t[ -s \".tmp/xss_reflected.txt\" ] && axiom-scan .tmp/xss_reflected.txt -m dalfox --skip-bav -w $DALFOX_THREADS -o vulns/xss.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tif [[ $(cat .tmp/xss_reflected.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t\t\tif [ -n \"$XSS_SERVER\" ]; then\n\t\t\t\t\t\taxiom-scan .tmp/xss_reflected.txt -m dalfox --skip-bav --skip-grepping --skip-mining-all --skip-mining-dict -b ${XSS_SERVER} -w $DALFOX_THREADS -o vulns/xss.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\telse\n\t\t\t\t\t\tprintf \"${yellow}\\n No XSS_SERVER defined, blind xss skipped\\n\\n\"\n\t\t\t\t\t\taxiom-scan .tmp/xss_reflected.txt -m dalfox --skip-bav --skip-grepping --skip-mining-all --skip-mining-dict -w $DALFOX_THREADS -o vulns/xss.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\tfi\n\t\t\t\telse\n\t\t\t\t\tprintf \"${bred} Skipping XSS: Too many URLs to test, try with --deep flag${reset}\\n\"\n\t\t\t\tfi\n\t\t\tfi\n\t\tfi\n\t\tend_func \"Results are saved in vulns/xss.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$XSS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/xss.txt\" ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to XSS ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction cors(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$CORS\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"CORS Scan\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\t[ -s \".tmp/webs_all.txt\" ] && python3 $tools/Corsy/corsy.py -i .tmp/webs_all.txt -o vulns/cors.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tend_func \"Results are saved in vulns/cors.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$CORS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction open_redirect(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$OPEN_REDIRECT\" = true ] && [ -s \"gf/redirect.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Open redirects checks\"\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat gf/redirect.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tcat gf/redirect.txt | qsreplace FUZZ | sed '/FUZZ/!d' | anew -q .tmp/tmp_redirect.txt\n\t\t\tpython3 $tools/Oralyzer/oralyzer.py -l .tmp/tmp_redirect.txt -p $tools/Oralyzer/payloads.txt > vulns/redirect.txt\n\t\t\tsed -r -i \"s/\\x1B\\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g\" vulns/redirect.txt\n\t\t\tend_func \"Results are saved in vulns/redirect.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping Open redirects: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t\tfi\n\telse\n\t\tif [ \"$OPEN_REDIRECT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/redirect.txt\" ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to Open Redirect ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction ssrf_checks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SSRF_CHECKS\" = true ] && [ -s \"gf/ssrf.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"SSRF checks\"\n\t\tif [ -z \"$COLLAB_SERVER\" ]; then\n\t\t\tinteractsh-client &>.tmp/ssrf_callback.txt &\n\t\t\tsleep 2\n\t\t\tCOLLAB_SERVER_FIX=\"FFUFHASH.$(cat .tmp/ssrf_callback.txt | tail -n1 | cut -c 16-)\"\n\t\t\tCOLLAB_SERVER_URL=\"http://$COLLAB_SERVER_FIX\"\n\t\t\tINTERACT=true\n\t\telse\n\t\t\tCOLLAB_SERVER_FIX=\"FFUFHASH.$(echo ${COLLAB_SERVER} | sed -r \"s/https?:\\/\\///\")\"\n\t\t\tINTERACT=false\n\t\tfi\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat gf/ssrf.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tcat gf/ssrf.txt | qsreplace ${COLLAB_SERVER_FIX} | anew -q .tmp/tmp_ssrf.txt\n\t\t\tcat gf/ssrf.txt | qsreplace ${COLLAB_SERVER_URL} | anew -q .tmp/tmp_ssrf.txt\n\t\t\tffuf -v -H \"${HEADER}\" -t $FFUF_THREADS -rate $FFUF_RATELIMIT -w .tmp/tmp_ssrf.txt -u FUZZ 2>/dev/null | grep \"URL\" | sed 's/| URL | //' | anew -q vulns/ssrf_requested_url.txt\n\t\t\tffuf -v -w .tmp/tmp_ssrf.txt:W1,$tools/headers_inject.txt:W2 -H \"${HEADER}\" -H \"W2: ${COLLAB_SERVER_FIX}\" -t $FFUF_THREADS -rate $FFUF_RATELIMIT -u W1 2>/dev/null | anew -q vulns/ssrf_requested_headers.txt\n\t\t\tffuf -v -w .tmp/tmp_ssrf.txt:W1,$tools/headers_inject.txt:W2 -H \"${HEADER}\" -H \"W2: ${COLLAB_SERVER_URL}\" -t $FFUF_THREADS -rate $FFUF_RATELIMIT -u W1 2>/dev/null | anew -q vulns/ssrf_requested_headers.txt\n\t\t\tsleep 5\n\t\t\t[ -s \".tmp/ssrf_callback.txt\" ] && cat .tmp/ssrf_callback.txt | tail -n+11 | anew -q vulns/ssrf_callback.txt && NUMOFLINES=$(cat .tmp/ssrf_callback.txt | tail -n+12 | sed '/^$/d' | wc -l)\n\t\t\t[ \"$INTERACT\" = true ] && notification \"SSRF: ${NUMOFLINES} callbacks received\" info\n\t\t\tend_func \"Results are saved in vulns/ssrf_*\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping SSRF: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\t\tpkill -f interactsh-client &\n\telse\n\t\tif [ \"$SSRF_CHECKS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/ssrf.txt\" ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to SSRF ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction crlf_checks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$CRLF_CHECKS\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"CRLF checks\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/webs_all.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tcrlfuzz -l .tmp/webs_all.txt -o vulns/crlf.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tend_func \"Results are saved in vulns/crlf.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping CRLF: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$CRLF_CHECKS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction lfi(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$LFI\" = true ] && [ -s \"gf/lfi.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"LFI checks\"\n\t\tif [ -s \"gf/lfi.txt\" ]; then\n\t\t\tcat gf/lfi.txt | qsreplace FUZZ | sed '/FUZZ/!d' | anew -q .tmp/tmp_lfi.txt\n\t\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/tmp_lfi.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t\tinterlace -tL .tmp/tmp_lfi.txt -threads ${INTERLACE_THREADS} -c \"ffuf -v -r -t ${FFUF_THREADS} -rate ${FFUF_RATELIMIT} -H \\\"${HEADER}\\\" -w ${lfi_wordlist} -u \\\"_target_\\\" -mr \\\"root:\\\" \" 2>/dev/null | grep \"URL\" | sed 's/| URL | //' | anew -q vulns/lfi.txt\n\t\t\t\tend_func \"Results are saved in vulns/lfi.txt\" ${FUNCNAME[0]}\n\t\t\telse\n\t\t\t\tend_func \"Skipping LFI: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\t\tfi\n\t\tfi\n\telse\n\t\tif [ \"$LFI\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/lfi.txt\" ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to LFI ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction ssti(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SSTI\" = true ] && [ -s \"gf/ssti.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"SSTI checks\"\n\t\tif [ -s \"gf/ssti.txt\" ]; then\n\t\t\tcat gf/ssti.txt | qsreplace FUZZ | sed '/FUZZ/!d'  | anew -q .tmp/tmp_ssti.txt\n\t\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/tmp_ssti.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t\tinterlace -tL .tmp/tmp_ssti.txt -threads ${INTERLACE_THREADS} -c \"ffuf -v -r -t ${FFUF_THREADS} -rate ${FFUF_RATELIMIT} -H \\\"${HEADER}\\\" -w ${ssti_wordlist} -u \\\"_target_\\\" -mr \\\"ssti49\\\" \" 2>/dev/null | grep \"URL\" | sed 's/| URL | //' | anew -q vulns/ssti.txt\n\t\t\t\tend_func \"Results are saved in vulns/ssti.txt\" ${FUNCNAME[0]}\n\t\t\telse\n\t\t\t\tend_func \"Skipping SSTI: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\t\tfi\n\t\tfi\n\telse\n\t\tif [ \"$SSTI\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/ssti.txt\" ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to SSTI ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sqli(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SQLI\" = true ] && [ -s \"gf/sqli.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"SQLi checks\"\n\n\t\tcat gf/sqli.txt | qsreplace FUZZ | sed '/FUZZ/!d' | anew -q .tmp/tmp_sqli.txt\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/tmp_sqli.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tif [ \"$SQLMAP\" = true ];then\n\t\t\t\tpython3 $tools/sqlmap/sqlmap.py -m .tmp/tmp_sqli.txt -b -o --smart --batch --disable-coloring --random-agent --output-dir=vulns/sqlmap 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\tif [ \"$GHAURI\" = true ];then\n\t\t\t\tinterlace -tL .tmp/tmp_sqli.txt -threads ${INTERLACE_THREADS} -c \"ghauri -u _target_ --batch -H \\\"${HEADER}\\\" --force-ssl >> vulns/ghauri_log.txt\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\tend_func \"Results are saved in vulns/sqlmap folder\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping SQLi: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$SQLI\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/sqli.txt\" ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to SQLi ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction test_ssl(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$TEST_SSL\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"SSL Test\"\n\t\t$tools/testssl.sh/testssl.sh --quiet --color 0 -U -iL hosts/ips.txt 2>>\"$LOGFILE\" > vulns/testssl.txt\n\t\tend_func \"Results are saved in vulns/testssl.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$TEST_SSL\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction spraying(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SPRAY\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Password spraying\"\n\t\tcd \"$tools/brutespray\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tpython3 brutespray.py --file $dir/hosts/portscan_active.gnmap --threads $BRUTESPRAY_THREADS --hosts $BRUTESPRAY_CONCURRENCE -o $dir/vulns/brutespray 2>>\"$LOGFILE\" >/dev/null\n\t\tcd \"$dir\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tend_func \"Results are saved in vulns/brutespray folder\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SPRAY\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction command_injection(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$COMM_INJ\" = true ] && [ -s \"gf/rce.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Command Injection checks\"\n\t\t[ -s \"gf/rce.txt\" ] && cat gf/rce.txt | qsreplace FUZZ | sed '/FUZZ/!d'  | anew -q .tmp/tmp_rce.txt\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/tmp_rce.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t[ -s \".tmp/tmp_rce.txt\" ] && python3 $tools/commix/commix.py --batch -m .tmp/tmp_rce.txt --output-dir vulns/command_injection.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tend_func \"Results are saved in vulns/command_injection folder\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping Command injection: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$COMM_INJ\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/rce.txt\" ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to Command Injection ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction 4xxbypass(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$BYPASSER4XX\" = true ]; then\n\t\tif [[ $(cat fuzzing/fuzzing_full.txt 2>/dev/null | grep -E '^4' | grep -Ev '^404' | cut -d ' ' -f3 | wc -l) -le 1000 ]] || [ \"$DEEP\" = true ]; then\n\t\t\tstart_func \"403 bypass\"\n\t\t\tcat $dir/fuzzing/fuzzing_full.txt 2>/dev/null | grep -E '^4' | grep -Ev '^404' | cut -d ' ' -f3 > $dir/.tmp/403test.txt\n\t\t\tcd \"$tools/byp4xx\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\tbyp4xx -threads $BYP4XX_THREADS $dir/.tmp/403test.txt > $dir/.tmp/byp4xx.txt\n\t\t\tcd \"$dir\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\t[ -s \".tmp/byp4xx.txt\" ] && cat .tmp/byp4xx.txt | anew -q vulns/byp4xx.txt\n\t\t\tend_func \"Results are saved in vulns/byp4xx.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tnotification \"Too many urls to bypass, skipping\" warn\n\t\tfi\n\telse\n\t\tif [ \"$BYPASSER4XX\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction prototype_pollution(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$PROTO_POLLUTION\" = true ] ; then\n\t\tstart_func ${FUNCNAME[0]} \"Prototype Pollution checks\"\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat webs/url_extract.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t[ -s \"webs/url_extract.txt\" ] && ppfuzz -l webs/url_extract.txt -c $PPFUZZ_THREADS 2>/dev/null | anew -q .tmp/prototype_pollution.txt\n\t\t\t[ -s \".tmp/prototype_pollution.txt\" ] && cat .tmp/prototype_pollution.txt | sed -e '1,8d' | sed '/^\\[ERR/d' | anew -q vulns/prototype_pollution.txt\n\t\t\tend_func \"Results are saved in vulns/prototype_pollution.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping Prototype Pollution: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$PROTO_POLLUTION\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction smuggling(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SMUGGLING\" = true ] ; then\n\t\tstart_func ${FUNCNAME[0]} \"HTTP Request Smuggling checks\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/webs_all.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tcd \"$tools/smuggler\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\tcat $dir/.tmp/webs_all.txt | python3 smuggler.py -q --no-color 2>/dev/null | anew -q $dir/.tmp/smuggling.txt\n\t\t\tcd \"$dir\" || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\t[ -s \".tmp/smuggling.txt\" ] && cat .tmp/smuggling.txt | anew -q vulns/smuggling.txt\n\t\t\tend_func \"Results are saved in vulns/smuggling.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping Prototype Pollution: Too many webs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$SMUGGLING\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction webcache(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WEBCACHE\" = true ] ; then\n\t\tstart_func ${FUNCNAME[0]} \"Web Cache Poisoning checks\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/webs_all.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tcd \"$tools/Web-Cache-Vulnerability-Scanner\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\tWeb-Cache-Vulnerability-Scanner -u file:$dir/.tmp/webs_all.txt -v 0 2>/dev/null | anew -q $dir/.tmp/webcache.txt\n\t\t\tcd \"$dir\" || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\t[ -s \".tmp/webcache.txt\" ] && cat .tmp/webcache.txt | anew -q vulns/webcache.txt\n\t\t\tend_func \"Results are saved in vulns/webcache.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Web Cache Poisoning: Too many webs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$WEBCACHE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction fuzzparams(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$FUZZPARAMS\" = true ] ; then\n\t\tstart_func ${FUNCNAME[0]} \"Fuzzing params values checks\"\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat webs/url_extract.txt | wc -l) -le $DEEP_LIMIT2 ]]; then\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tnuclei -update 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tgit -C $tools/fuzzing-templates pull\n\t\t\t\tcat webs/url_extract.txt 2>/dev/null | nuclei -silent -retries 3 -rl $NUCLEI_RATELIMIT -t $tools/fuzzing-templates -o .tmp/fuzzparams.txt\n\t\t\telse\n\t\t\t\taxiom-exec \"git clone https://github.com/projectdiscovery/fuzzing-templates /home/op/fuzzing-templates\" &>/dev/null\n\t\t\t\taxiom-scan webs/url_extract.txt -m nuclei -nh -retries 3 -w /home/op/fuzzing-templates -rl $NUCLEI_RATELIMIT -o .tmp/fuzzparams.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/fuzzparams.txt\" ] && cat .tmp/fuzzparams.txt | anew -q vulns/fuzzparams.txt\n\t\t\tend_func \"Results are saved in vulns/fuzzparams.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Fuzzing params values: Too many entries to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$FUZZPARAMS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n########################################## OPTIONS & MGMT #####################################################\n###############################################################################################################\n\nfunction deleteOutScoped(){\n\tif [ -s \"$1\" ]; then\n\t\tcat $1 | while read outscoped\n\t\tdo\n\t\t\tif grep -q \"^[*]\" <<< $outscoped\n\t\t\tthen\n\t\t\t\toutscoped=\"${outscoped:1}\"\n\t\t\t\tsed -i /\"$outscoped$\"/d $2\n\t\t\telse\n\t\t\t\tsed -i /$outscoped/d $2\n\t\t\tfi\n\t\tdone\n\tfi\n}\n\nfunction getElapsedTime {\n\truntime=\"\"\n\tlocal T=$2-$1\n\tlocal D=$((T/60/60/24))\n\tlocal H=$((T/60/60%24))\n\tlocal M=$((T/60%60))\n\tlocal S=$((T%60))\n\t(( $D > 0 )) && runtime=\"$runtime$D days, \"\n\t(( $H > 0 )) && runtime=\"$runtime$H hours, \"\n\t(( $M > 0 )) && runtime=\"$runtime$M minutes, \"\n\truntime=\"$runtime$S seconds.\"\n}\n\nfunction zipSnedOutputFolder {\n\tzip_name1=$(date +\"%Y_%m_%d-%H.%M.%S\")\n\tzip_name=\"${zip_name1}_${domain}.zip\" 2>>\"$LOGFILE\" >/dev/null\n\t(cd \"$dir\" && zip -r \"$zip_name\" .)\n\n\techo \"Sending zip file \"${dir}/${zip_name}\"\"\n\tif [ -s \"${dir}/$zip_name\" ]; then\n\t\tsendToNotify \"$dir/$zip_name\"\n\t\trm -f \"${dir}/$zip_name\"\n\telse\n\t\tnotification \"No Zip file to send\" warn\n\tfi\n}\n\nfunction isAsciiText {\n\tIS_ASCII=\"False\";\n\tif [[ $(file $1 | grep -o 'ASCII text$') == \"ASCII text\" ]]; then\n\t\tIS_ASCII=\"True\";\n\telse\n\t\tIS_ASCII=\"False\";\n\tfi\n}\n\nfunction output(){\n\tmkdir -p $dir_output\n\tcp -r $dir $dir_output\n\t[[ \"$(dirname $dir)\" != \"$dir_output\" ]] && rm -rf \"$dir\"\n}\n\nfunction remove_big_files(){\n\teval rm -rf .tmp/gotator*.txt 2>>\"$LOGFILE\"\n\teval rm -rf .tmp/brute_recursive_wordlist.txt 2>>\"$LOGFILE\"\n\teval rm -rf .tmp/subs_dns_tko.txt  2>>\"$LOGFILE\"\n\teval rm -rf .tmp/subs_no_resolved.txt .tmp/subdomains_dns.txt .tmp/brute_dns_tko.txt .tmp/scrap_subs.txt .tmp/analytics_subs_clean.txt .tmp/gotator1.txt .tmp/gotator2.txt .tmp/passive_recursive.txt .tmp/brute_recursive_wordlist.txt .tmp/gotator1_recursive.txt .tmp/gotator2_recursive.txt 2>>\"$LOGFILE\"\n\teval find .tmp -type f -size +200M -exec rm -f {} + 2>>\"$LOGFILE\"\n}\n\nfunction notification(){\n\tif [ -n \"$1\" ] && [ -n \"$2\" ]; then\n\t\tcase $2 in\n\t\t\tinfo)\n\t\t\t\ttext=\"\\n${bblue} ${1} ${reset}\"\n\t\t\t\tprintf \"${text}\\n\" && printf \"${text} - ${domain}\\n\" | $NOTIFY\n\t\t\t;;\n\t\t\twarn)\n\t\t\t\ttext=\"\\n${yellow} ${1} ${reset}\"\n\t\t\t\tprintf \"${text}\\n\" && printf \"${text} - ${domain}\\n\" | $NOTIFY\n\t\t\t;;\n\t\t\terror)\n\t\t\t\ttext=\"\\n${bred} ${1} ${reset}\"\n\t\t\t\tprintf \"${text}\\n\" && printf \"${text} - ${domain}\\n\" | $NOTIFY\n\t\t\t;;\n\t\t\tgood)\n\t\t\t\ttext=\"\\n${bgreen} ${1} ${reset}\"\n\t\t\t\tprintf \"${text}\\n\" && printf \"${text} - ${domain}\\n\" | $NOTIFY\n\t\t\t;;\n\t\tesac\n\tfi\n}\n\nfunction transfer { \n\tif [ $# -eq 0 ]; then \n\t\techo \"No arguments specified.\\nUsage:\\n transfer <file|directory>\\n ... | transfer <file_name>\">&2\n\t\treturn 1\n\tfi\n\tif tty -s; then \n\t\tfile=\"$1\"\n\t\tfile_name=$(basename \"$file\")\n\t\tif [ ! -e \"$file\" ]; then \n\t\t\techo \"$file: No such file or directory\">&2\n\t\t\treturn 1\n\t\tfi\n\t\tif [ -d \"$file\" ]; then\n\t\t\tfile_name=\"$file_name.zip\"\n\t\t\t(cd \"$file\"&&zip -r -q - .) | curl --progress-bar --upload-file \"-\" \"https://transfer.sh/$file_name\" | tee /dev/null\n\t\telse \n\t\t\tcat \"$file\" | curl --progress-bar --upload-file \"-\" \"https://transfer.sh/$file_name\" | tee /dev/null\n\t\tfi\n\telse\n\t\tfile_name=$1\n\t\tcurl --progress-bar --upload-file \"-\" \"https://transfer.sh/$file_name\" | tee /dev/null\n\tfi\n}\n\nfunction sendToNotify {\n\tif [[ -z \"$1\" ]]; then\n\t\tprintf \"\\n${yellow} no file provided to send ${reset}\\n\"\n\telse\n\t\tif [[ -z \"$NOTIFY_CONFIG\" ]]; then\n\t\t\tNOTIFY_CONFIG=~/.config/notify/provider-config.yaml\n\t\tfi\n\t\tif [ -n \"$(find \"${1}\" -prune -size +8000000c)\" ]; then\n    \t\tprintf '%s is larger than 8MB, sending over transfer.sh\\n' \"${1}\"\n\t\t\ttransfer \"${1}\" | notify\n\t\t\treturn 0\n\t\tfi\n\t\tif grep -q '^ telegram\\|^telegram\\|^    telegram' $NOTIFY_CONFIG ; then\n\t\t\tnotification \"Sending ${domain} data over Telegram\" info\n\t\t\ttelegram_chat_id=$(cat ${NOTIFY_CONFIG} | grep '^    telegram_chat_id\\|^telegram_chat_id\\|^    telegram_chat_id' | xargs | cut -d' ' -f2)\n\t\t\ttelegram_key=$(cat ${NOTIFY_CONFIG} | grep '^    telegram_api_key\\|^telegram_api_key\\|^    telegram_apikey' | xargs | cut -d' ' -f2 )\n\t\t\tcurl -F document=@${1} \"https://api.telegram.org/bot${telegram_key}/sendDocument?chat_id=${telegram_chat_id}\" 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tif grep -q '^ discord\\|^discord\\|^    discord' $NOTIFY_CONFIG ; then\n\t\t\tnotification \"Sending ${domain} data over Discord\" info\n\t\t\tdiscord_url=$(cat ${NOTIFY_CONFIG} | grep '^ discord_webhook_url\\|^discord_webhook_url\\|^    discord_webhook_url' | xargs | cut -d' ' -f2)\n\t\t\tcurl -v -i -H \"Accept: application/json\" -H \"Content-Type: multipart/form-data\" -X POST -F file1=@${1} $discord_url 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tif [[ -n \"$slack_channel\" ]] && [[ -n \"$slack_auth\" ]]; then\n\t\t\tnotification \"Sending ${domain} data over Slack\" info\n\t\t\tcurl -F file=@${1} -F \"initial_comment=reconftw zip file\" -F channels=${slack_channel} -H \"Authorization: Bearer ${slack_auth}\" https://slack.com/api/files.upload 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\tfi\n}\n\nfunction start_func(){\n\tprintf \"${bgreen}#######################################################################\"\n\tnotification \"${2}\" info\n\techo \"[ $(date +\"%F %T\") ] Start function : ${1} \" >> \"${LOGFILE}\"\n\tstart=$(date +%s)\n}\n\nfunction end_func(){\n\ttouch $called_fn_dir/.${2}\n\tend=$(date +%s)\n\tgetElapsedTime $start $end\n\tnotification \"${2} Finished in ${runtime}\" info\n\techo \"[ $(date +\"%F %T\") ] End function : ${2} \" >> \"${LOGFILE}\"\n\tprintf \"${bblue} ${1} ${reset}\\n\"\n\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n}\n\nfunction start_subfunc(){\n\tnotification \"${2}\" warn\n\techo \"[ $(date +\"%F %T\") ] Start subfunction : ${1} \" >> \"${LOGFILE}\"\n\tstart_sub=$(date +%s)\n}\n\nfunction end_subfunc(){\n\ttouch $called_fn_dir/.${2}\n\tend_sub=$(date +%s)\n\tgetElapsedTime $start_sub $end_sub\n\tnotification \"${1} in ${runtime}\" good\n\techo \"[ $(date +\"%F %T\") ] End subfunction : ${1} \" >> \"${LOGFILE}\"\n}\n\nfunction check_inscope(){\n\tcat $1 | inscope > $1_tmp && cp $1_tmp $1 && rm -f $1_tmp\n}\n\nfunction resolvers_update(){\n\tif [ \"$generate_resolvers\" = true ]; then\n\t\tif [ ! \"$AXIOM\" = true ]; then\t\n\t\t\tif [ ! -s \"$resolvers\" ] || [[ $(find \"$resolvers\" -mtime +1 -print) ]] ; then\n\t\t\t\tnotification \"Resolvers seem older than 1 day\\n Generating custom resolvers...\" warn\n\t\t\t\teval rm -f $resolvers 2>>\"$LOGFILE\"\n\t\t\t\tdnsvalidator -tL https://public-dns.info/nameservers.txt -threads $DNSVALIDATOR_THREADS -o $resolvers 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tdnsvalidator -tL https://raw.githubusercontent.com/blechschmidt/massdns/master/lists/resolvers.txt -threads $DNSVALIDATOR_THREADS -o tmp_resolvers 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t[ -s \"tmp_resolvers\" ] && cat tmp_resolvers | anew -q $resolvers\n\t\t\t\t[ -s \"tmp_resolvers\" ] && rm -f tmp_resolvers 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t[ ! -s \"$resolvers\" ] && wget -q -O - ${resolvers_url} > $resolvers\n\t\t\t\t[ ! -s \"$resolvers_trusted\" ] && wget -q -O - ${resolvers_trusted_url} > $resolvers_trusted\n\t\t\t\tnotification \"Updated\\n\" good\n\t  \t\tfi\n\t\telse\n\t\t\tnotification \"Checking resolvers lists...\\n Accurate resolvers are the key to great results\\n This may take around 10 minutes if it's not updated\" warn\n\t\t\t# shellcheck disable=SC2016\n\t\t\taxiom-exec 'if [ $(find \"/home/op/lists/resolvers.txt\" -mtime +1 -print) ] || [ $(cat /home/op/lists/resolvers.txt | wc -l) -le 40 ] ; then dnsvalidator -tL https://public-dns.info/nameservers.txt -threads 200 -o /home/op/lists/resolvers.txt ; fi' &>/dev/null\n\t\t\taxiom-exec \"wget -q -O - ${resolvers_url} > /home/op/lists/resolvers.txt\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\taxiom-exec \"wget -q -O - ${resolvers_trusted_url} > /home/op/lists/resolvers_trusted.txt\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\tnotification \"Updated\\n\" good\n\t\tfi\n\t\tgenerate_resolvers=false\n\telse\n\t\n\t\tif  [ ! -s \"$resolvers\" ] || [[ $(find \"$resolvers\" -mtime +1 -print) ]] ; then\n\t\t\tnotification \"Resolvers seem older than 1 day\\n Downloading new resolvers...\" warn\n\t\t\twget -q -O - ${resolvers_url} > $resolvers\n\t\t\twget -q -O - ${resolvers_trusted_url} > $resolvers_trusted\n\t\t\tnotification \"Resolvers updated\\n\" good\n\t\tfi\n\tfi\n}\n\nfunction resolvers_update_quick_local(){\n\tif [ \"$update_resolvers\" = true ]; then\n\t\twget -q -O - ${resolvers_url} > $resolvers\n\t\twget -q -O - ${resolvers_trusted_url} > $resolvers_trusted\n\tfi\n}\n\nfunction resolvers_update_quick_axiom(){\n\taxiom-exec \"wget -q -O - ${resolvers_url} > /home/op/lists/resolvers.txt\" 2>>\"$LOGFILE\" >/dev/null\n\taxiom-exec \"wget -q -O - ${resolvers_trusted_url} > /home/op/lists/resolvers_trusted.txt\" 2>>\"$LOGFILE\" >/dev/null\n}\n\nfunction ipcidr_target(){\n\tIP_CIDR_REGEX='(((25[0-5]|2[0-4][0-9]|1?[0-9][0-9]?)\\.){3}(25[0-5]|2[0-4][0-9]|1?[0-9][0-9]?))(\\/([8-9]|[1-2][0-9]|3[0-2]))([^0-9.]|$)|(((25[0-5]|2[0-4][0-9]|1?[0-9][0-9]?)\\.){3}(25[0-5]|2[0-4][0-9]|1?[0-9][0-9]?)$)'\n\tif [[ $1 =~ ^$IP_CIDR_REGEX ]]; then\n\t\techo $1 | mapcidr -silent | anew -q target_reconftw_ipcidr.txt\n\t\tif [ -s \"./target_reconftw_ipcidr.txt\" ]; then \n\t\t\t[ \"$REVERSE_IP\" = true ] && cat ./target_reconftw_ipcidr.txt | hakip2host | cut -d' ' -f 3 | unfurl -u domains 2>/dev/null | sed -e 's/*\\.//' -e 's/\\.$//' -e '/\\./!d' | anew -q ./target_reconftw_ipcidr.txt\n\t\t\tif [[ $(cat ./target_reconftw_ipcidr.txt | wc -l) -eq 1 ]]; then\n\t\t\t\tdomain=$(cat ./target_reconftw_ipcidr.txt)\n\t\t\telif [[ $(cat ./target_reconftw_ipcidr.txt | wc -l) -gt 1 ]]; then\n\t\t\t\tunset domain\n\t\t\t\tlist=${PWD}/target_reconftw_ipcidr.txt\n\t\t\tfi\n\t\tfi\n\t\tif [ -n \"$2\" ]; then\n\t\t\tcat $list | anew -q $2\n\t\t\tsed -i '/\\/[0-9]*$/d' $2\n\t\tfi\n\tfi\n}\n\nfunction axiom_lauch(){\n\t# let's fire up a FLEET!\n\tif [ \"$AXIOM_FLEET_LAUNCH\" = true ] && [ -n \"$AXIOM_FLEET_NAME\" ] && [ -n \"$AXIOM_FLEET_COUNT\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Launching our Axiom fleet\"\n\t\tpython3 -m pip install --upgrade linode-cli 2>>\"$LOGFILE\" >/dev/null\n\t\t# Check to see if we have a fleet already, if so, SKIP THIS!\n\t\tNUMOFNODES=$(timeout 30 axiom-ls | grep -c \"$AXIOM_FLEET_NAME\")\n\t\tif [[ $NUMOFNODES -ge $AXIOM_FLEET_COUNT ]]; then\n\t\t\taxiom-select \"$AXIOM_FLEET_NAME*\"\n\t\t\tend_func \"Axiom fleet $AXIOM_FLEET_NAME already has $NUMOFNODES instances\"\n\t\telse\n\t\t\tif [[ $NUMOFNODES -eq 0 ]]; then\n\t\t\t\tstartcount=$AXIOM_FLEET_COUNT\n\t\t\telse\n\t\t\t\tstartcount=$((AXIOM_FLEET_COUNT-NUMOFNODES))\n\t\t\tfi\n\t\t\tAXIOM_ARGS=\" -i $startcount\"\n\t\t\t# Temporarily disabled multiple axiom regions\n\t\t\t# [ -n \"$AXIOM_FLEET_REGIONS\" ] && axiom_args=\"$axiom_args --regions=\\\"$AXIOM_FLEET_REGIONS\\\" \"\n\n\t\t\techo \"axiom-fleet ${AXIOM_FLEET_NAME} ${AXIOM_ARGS}\"\n\t\t\taxiom-fleet ${AXIOM_FLEET_NAME} ${AXIOM_ARGS}\n\t\t\taxiom-select \"$AXIOM_FLEET_NAME*\"\n\t\t\tif [ -n \"$AXIOM_POST_START\" ]; then\n\t\t\t\teval \"$AXIOM_POST_START\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\n\t\t\tNUMOFNODES=$(timeout 30 axiom-ls | grep -c \"$AXIOM_FLEET_NAME\" )\n\t\t\techo \"Axiom fleet $AXIOM_FLEET_NAME launched w/ $NUMOFNODES instances\" | $NOTIFY\n\t\t\tend_func \"Axiom fleet $AXIOM_FLEET_NAME launched w/ $NUMOFNODES instances\"\n\t\tfi\n\tfi\n}\n\nfunction axiom_shutdown(){\n\tif [ \"$AXIOM_FLEET_LAUNCH\" = true ] && [ \"$AXIOM_FLEET_SHUTDOWN\" = true ] && [ -n \"$AXIOM_FLEET_NAME\" ]; then\n\t\t#if [ \"$mode\" == \"subs_menu\" ] || [ \"$mode\" == \"list_recon\" ] || [ \"$mode\" == \"passive\" ] || [ \"$mode\" == \"all\" ]; then\n\t\tif [ \"$mode\" == \"subs_menu\" ] || [ \"$mode\" == \"passive\" ] || [ \"$mode\" == \"all\" ]; then\n\t\t\tnotification \"Automatic Axiom fleet shutdown is not enabled in this mode\" info\n\t\t\treturn\n\t\tfi\n\t\teval axiom-rm -f \"$AXIOM_FLEET_NAME*\"\n\t\techo \"Axiom fleet $AXIOM_FLEET_NAME shutdown\" | $NOTIFY\n\t\tnotification \"Axiom fleet $AXIOM_FLEET_NAME shutdown\" info\n\tfi\n}\n\nfunction axiom_selected(){\n\n\tif [[ ! $(axiom-ls | tail -n +2 | sed '$ d' | wc -l) -gt 0 ]]; then\n\t\tnotification \"\\n\\n${bred} No axiom instances running ${reset}\\n\\n\" error\n\t\texit\n\tfi\n\n\tif [[ ! $(cat ~/.axiom/selected.conf | sed '/^\\s*$/d' | wc -l) -gt 0 ]]; then\n\t\tnotification \"\\n\\n${bred} No axiom instances selected ${reset}\\n\\n\" error\n\t\texit\n\tfi\n}\n\nfunction start(){\n\n\tglobal_start=$(date +%s)\n\n\tif [ \"$NOTIFICATION\" = true ]; then\n\t\tNOTIFY=\"notify -silent\"\n\telse\n\t    NOTIFY=\"\"\n\tfi\n\t\n\tprintf \"\\n${bgreen}#######################################################################${reset}\"\n\tnotification \"Recon succesfully started on ${domain}\" good\n\t[ \"$SOFT_NOTIFICATION\" = true ] && echo \"Recon succesfully started on ${domain}\" | notify -silent\n\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tif [ \"$upgrade_before_running\" = true ]; then\n\t\t${SCRIPTPATH}/install.sh --tools\n\tfi\n\ttools_installed\n\n\t#[[ -n \"$domain\" ]] && ipcidr_target $domain\n\n\n\tif [ -z \"$domain\" ]; then\n\t\tif [ -n \"$list\" ]; then\n\t\t\tif [ -z \"$domain\" ]; then\n\t\t\t\tdomain=\"Multi\"\n\t\t\t\tdir=\"$SCRIPTPATH/Recon/$domain\"\n\t\t\t\tcalled_fn_dir=\"$dir\"/.called_fn\n\t\t\tfi\n\t\t\tif [[ \"$list\" = /* ]]; then\n\t\t\t\tinstall -D \"$list\" \"$dir\"/webs/webs.txt\n\t\t\telse\n\t\t\t\tinstall -D \"$SCRIPTPATH\"/\"$list\" \"$dir\"/webs/webs.txt\n\t\t\tfi\n\t\tfi\n\telse\n\t\tdir=\"$SCRIPTPATH/Recon/$domain\"\n\t\tcalled_fn_dir=\"$dir\"/.called_fn\n\tfi\n\n\tif [ -z \"$domain\" ]; then\n\t\tnotification \"\\n\\n${bred} No domain or list provided ${reset}\\n\\n\" error\n\t\texit\n\tfi\n\n\tif [ ! -d \"$called_fn_dir\" ]; then\n\t\tmkdir -p \"$called_fn_dir\"\n\tfi\n\tmkdir -p \"$dir\"\n\tcd \"$dir\"  || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tif [ \"$AXIOM\" = true ]; then\n\t\tif [ -n \"$domain\" ]; then\n\t\t\techo \"$domain\" | anew -q target.txt\n\t\t\tlist=\"${dir}/target.txt\"\n\t\tfi\n\tfi\n\tmkdir -p .tmp .log osint subdomains webs hosts vulns\n\n\tNOW=$(date +\"%F\")\n\tNOWT=$(date +\"%T\")\n\tLOGFILE=\"${dir}/.log/${NOW}_${NOWT}.txt\"\n\ttouch .log/${NOW}_${NOWT}.txt\n\techo \"Start ${NOW} ${NOWT}\" > \"${LOGFILE}\"\n\n\tprintf \"\\n\"\n\tprintf \"${bred} Target: ${domain}\\n\\n\"\n}\n\nfunction end(){\n\n\tfind $dir -type f -empty -print | grep -v '.called_fn' | grep -v '.log' | grep -v '.tmp' | xargs rm -f 2>>\"$LOGFILE\" >/dev/null\n\tfind $dir -type d -empty -print -delete 2>>\"$LOGFILE\" >/dev/null\n\n\techo \"End $(date +\"%F\") $(date +\"%T\")\" >> \"${LOGFILE}\"\n\n\tif [ ! \"$PRESERVE\" = true ]; then\n\t\tfind $dir -type f -empty | grep -v \"called_fn\" | xargs rm -f 2>>\"$LOGFILE\" >/dev/null\n\t\tfind $dir -type d -empty | grep -v \"called_fn\" | xargs rm -rf 2>>\"$LOGFILE\" >/dev/null\n\tfi\n\n\tif [ \"$REMOVETMP\" = true ]; then\n\t\trm -rf $dir/.tmp\n\tfi\n\n    if [ \"$REMOVELOG\" = true ]; then\n            rm -rf $dir/.log\n    fi \n\n\tif [ -n \"$dir_output\" ]; then\n\t\toutput\n\t\tfinaldir=$dir_output\n\telse\n\t\tfinaldir=$dir\n\tfi\n\t#Zip the output folder and send it via tg/discord/slack\n\tif [ \"$SENDZIPNOTIFY\" = true ]; then\n\t\tzipSnedOutputFolder\n\tfi\n\tglobal_end=$(date +%s)\n\tgetElapsedTime $global_start $global_end\n\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tnotification \"Finished Recon on: ${domain} under ${finaldir} in: ${runtime}\" good\n\t[ \"$SOFT_NOTIFICATION\" = true ] && echo \"Finished Recon on: ${domain} under ${finaldir} in: ${runtime}\" | notify -silent\n\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t#Seperator for more clear messges in telegram_Bot\n\techo \"******  Stay safe \ud83e\udda0 and secure \ud83d\udd10  ******\" | $NOTIFY\n}\n\n###############################################################################################################\n########################################### MODES & MENUS #####################################################\n###############################################################################################################\n\nfunction passive(){\n\tstart\n\tdomain_info\n\tip_info\n\temails\n\tgoogle_dorks\n\tgithub_dorks\n\tgithub_repos\n\tmetadata\n\tSUBNOERROR=false\n\tSUBANALYTICS=false\n\tSUBBRUTE=false\n\tSUBSCRAPING=false\n\tSUBPERMUTE=false\n\tSUBREGEXPERMUTE=false\n\tSUB_RECURSIVE_BRUTE=false\n\tWEBPROBESIMPLE=false\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_lauch\n\t\taxiom_selected\n\tfi\n\n\tsubdomains_full\n\tremove_big_files\n\tfavicon\n\tcdnprovider\n\tPORTSCAN_ACTIVE=false\n\tportscan\n\t\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_shutdown\n\tfi\n\n\tend\n}\n\nfunction all(){\n\tstart\n\trecon\n\tvulns\n\tend\n}\n\nfunction osint(){\n\tdomain_info\n\tip_info\n\temails\n\tgoogle_dorks\n\tgithub_dorks\n\tgithub_repos\n\tmetadata\n\tzonetransfer\n\tfavicon\n}\n\nfunction vulns(){\n\tif [ \"$VULNS_GENERAL\" = true ]; then\n\t\tcors\n\t\topen_redirect\n\t\tssrf_checks\n\t\tcrlf_checks\n\t\tlfi\n\t\tssti\n\t\tsqli\n\t\txss\n\t\tcommand_injection\n\t\tprototype_pollution\n\t\tsmuggling\n\t\twebcache\n\t\tspraying\n\t\tbrokenLinks\n\t\tfuzzparams\n\t\t4xxbypass\n\t\ttest_ssl\n\tfi\n}\n\nfunction multi_osint(){\n\n\tglobal_start=$(date +%s)\n\n\tif [ \"$NOTIFICATION\" = true ]; then\n\t\tNOTIFY=\"notify -silent\"\n\telse\n\t    NOTIFY=\"\"\n\tfi\n\n\t#[[ -n \"$domain\" ]] && ipcidr_target $domain\n\n\tif [ -s \"$list\" ]; then\n\t\tsed -i 's/\\r$//' $list\n\t\ttargets=$(cat $list)\n\telse\n\t\tnotification \"Target list not provided\" error\n\t\texit\n\tfi\n\n\tworkdir=$SCRIPTPATH/Recon/$multi\n\tmkdir -p $workdir  || { echo \"Failed to create directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tcd \"$workdir\"  || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tmkdir -p .tmp .called_fn osint subdomains webs hosts vulns\n\n\tNOW=$(date +\"%F\")\n\tNOWT=$(date +\"%T\")\n\tLOGFILE=\"${workdir}/.log/${NOW}_${NOWT}.txt\"\n\ttouch .log/${NOW}_${NOWT}.txt\n\techo \"Start ${NOW} ${NOWT}\" > \"${LOGFILE}\"\n\n\tfor domain in $targets; do\n\t\tdir=$workdir/targets/$domain\n\t\tcalled_fn_dir=$dir/.called_fn\n\t\tmkdir -p $dir\n\t\tcd \"$dir\"  || { echo \"Failed to cd directory '$dir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tmkdir -p .tmp .called_fn osint subdomains webs hosts vulns\n\t\tNOW=$(date +\"%F\")\n\t\tNOWT=$(date +\"%T\")\n\t\tLOGFILE=\"${dir}/.log/${NOW}_${NOWT}.txt\"\n\t\ttouch .log/${NOW}_${NOWT}.txt\n\t\techo \"Start ${NOW} ${NOWT}\" > \"${LOGFILE}\"\n\t\tdomain_info\n\t\tip_info\n\t\temails\n\t\tgoogle_dorks\n\t\tgithub_dorks\n\t\tgithub_repos\n\t\tmetadata\n\t\tzonetransfer\n\t\tfavicon\n\tdone\n\tcd \"$workdir\" || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tdir=$workdir\n\tdomain=$multi\n\tend\n}\n\n\nfunction recon(){\n\tdomain_info\n\tip_info\n\temails\n\tgoogle_dorks\n\tgithub_dorks\n\tgithub_repos\n\tmetadata\n\tzonetransfer\n\tfavicon\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_lauch\n\t\taxiom_selected\n\tfi\n\n\tsubdomains_full\n\twebprobe_full\n\tsubtakeover\n\tremove_big_files\n\ts3buckets\n\tscreenshot\n#\tvirtualhosts\n\tcdnprovider\n\tportscan\n\twaf_checks\n\tnuclei_check\n\tfuzz\n\turlchecks\n\tjschecks\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_shutdown\n\tfi\n\n\tcms_scanner\n\turl_gf\n\twordlist_gen\n\twordlist_gen_roboxtractor\n\tpassword_dict\n\turl_ext\n}\n\nfunction multi_recon(){\n\n\n\tglobal_start=$(date +%s)\n\n\tif [ \"$NOTIFICATION\" = true ]; then\n\t\tNOTIFY=\"notify -silent\"\n\telse\n\t    NOTIFY=\"\"\n\tfi\n\n\t#[[ -n \"$domain\" ]] && ipcidr_target $domain\n\n\tif [ -s \"$list\" ]; then\n\t\t sed -i 's/\\r$//' $list\n\t\ttargets=$(cat $list)\n\telse\n\t\tnotification \"Target list not provided\" error\n\t\texit\n\tfi\n\n\tworkdir=$SCRIPTPATH/Recon/$multi\n\tmkdir -p $workdir  || { echo \"Failed to create directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tcd \"$workdir\"  || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\n\tmkdir -p .tmp .log .called_fn osint subdomains webs hosts vulns\n\tNOW=$(date +\"%F\")\n\tNOWT=$(date +\"%T\")\n\tLOGFILE=\"${workdir}/.log/${NOW}_${NOWT}.txt\"\n\ttouch .log/${NOW}_${NOWT}.txt\n\techo \"Start ${NOW} ${NOWT}\" > \"${LOGFILE}\"\n\n\t[ -n \"$flist\" ] && LISTTOTAL=$(cat \"$flist\" | wc -l )\n\n\tfor domain in $targets; do\n\t\tdir=$workdir/targets/$domain\n\t\tcalled_fn_dir=$dir/.called_fn\n\t\tmkdir -p $dir\n\t\tcd \"$dir\"  || { echo \"Failed to cd directory '$dir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tmkdir -p .tmp .log .called_fn osint subdomains webs hosts vulns\n\n\t\tNOW=$(date +\"%F\")\n\t\tNOWT=$(date +\"%T\")\n\t\tLOGFILE=\"${dir}/.log/${NOW}_${NOWT}.txt\"\n\t\ttouch .log/${NOW}_${NOWT}.txt\n\t\techo \"Start ${NOW} ${NOWT}\" > \"${LOGFILE}\"\n\t\tloopstart=$(date +%s)\n\n\t\tdomain_info\n\t\tip_info\n\t\temails\n\t\tgoogle_dorks\n\t\tgithub_dorks\n\t\tgithub_repos\n\t\tmetadata\n\t\tzonetransfer\n\t\tfavicon\n\t\tcurrently=$(date +\"%H:%M:%S\")\n\t\tloopend=$(date +%s)\n\t\tgetElapsedTime $loopstart $loopend\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t\tprintf \"${bgreen} $domain finished 1st loop in ${runtime}  $currently ${reset}\\n\"\n\t\tif [ -n \"$flist\" ]; then\n\t\t\tPOSINLIST=$(eval grep -nrE \"^$domain$\" \"$flist\" | cut -f1 -d':')\n\t\t\tprintf \"\\n${yellow}  $domain is $POSINLIST of $LISTTOTAL${reset}\\n\"\n\t\tfi\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tdone\n\tcd \"$workdir\"  || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_lauch\n\t\taxiom_selected\n\tfi\n\n\tfor domain in $targets; do\n\t\tloopstart=$(date +%s)\n\t\tdir=$workdir/targets/$domain\n\t\tcalled_fn_dir=$dir/.called_fn\n\t\tcd \"$dir\"  || { echo \"Failed to cd directory '$dir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tsubdomains_full\n\t\twebprobe_full\n\t\tsubtakeover\n\t\tremove_big_files\n\t\tscreenshot\n#\t\tvirtualhosts\n\t\tcdnprovider\n\t\tportscan\n\t\tcurrently=$(date +\"%H:%M:%S\")\n\t\tloopend=$(date +%s)\n\t\tgetElapsedTime $loopstart $loopend\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t\tprintf \"${bgreen} $domain finished 2nd loop in ${runtime}  $currently ${reset}\\n\"\n\t\tif [ -n \"$flist\" ]; then\n\t\t\tPOSINLIST=$(eval grep -nrE \"^$domain$\" \"$flist\" | cut -f1 -d':')\n\t\t\tprintf \"\\n${yellow}  $domain is $POSINLIST of $LISTTOTAL${reset}\\n\"\n\t\tfi\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tdone\n\tcd \"$workdir\"  || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\n\tnotification \"############################# Total data ############################\" info\n\tNUMOFLINES_users_total=$(find . -type f -name 'users.txt' -exec cat {} + | anew osint/users.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_pwndb_total=$(find . -type f -name 'passwords.txt' -exec cat {} + | anew osint/passwords.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_software_total=$(find . -type f -name 'software.txt' -exec cat {} + | anew osint/software.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_authors_total=$(find . -type f -name 'authors.txt' -exec cat {} + | anew osint/authors.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_subs_total=$(find . -type f -name 'subdomains.txt' -exec cat {} + | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_subtko_total=$(find . -type f -name 'takeover.txt' -exec cat {} + | anew webs/takeover.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_webs_total=$(find . -type f -name 'webs.txt' -exec cat {} + | anew webs/webs.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_webs_total=$(find . -type f -name 'webs_uncommon_ports.txt' -exec cat {} + | anew webs/webs_uncommon_ports.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_ips_total=$(find . -type f -name 'ips.txt' -exec cat {} + | anew hosts/ips.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_cloudsprov_total=$(find . -type f -name 'cdn_providers.txt' -exec cat {} + | anew hosts/cdn_providers.txt | sed '/^$/d' | wc -l)\n\tfind . -type f -name 'portscan_active.txt' -exec cat {} + | tee -a hosts/portscan_active.txt >> \"$LOGFILE\" 2>&1 >/dev/null\n\tfind . -type f -name 'portscan_active.gnmap' -exec cat {} + | tee hosts/portscan_active.gnmap 2>>\"$LOGFILE\" >/dev/null\n\tfind . -type f -name 'portscan_passive.txt' -exec cat {} + | tee hosts/portscan_passive.txt 2>&1 >> \"$LOGFILE\" >/dev/null\n\n\tnotification \"- ${NUMOFLINES_users_total} total users found\" good\n\tnotification \"- ${NUMOFLINES_pwndb_total} total creds leaked\" good\n\tnotification \"- ${NUMOFLINES_software_total} total software found\" good\n\tnotification \"- ${NUMOFLINES_authors_total} total authors found\" good\n\tnotification \"- ${NUMOFLINES_subs_total} total subdomains\" good\n\tnotification \"- ${NUMOFLINES_subtko_total} total probably subdomain takeovers\" good\n\tnotification \"- ${NUMOFLINES_webs_total} total websites\" good\n\tnotification \"- ${NUMOFLINES_ips_total} total ips\" good\n\tnotification \"- ${NUMOFLINES_cloudsprov_total} total IPs belongs to cloud\" good\n\ts3buckets\n\twaf_checks\n\tnuclei_check\n\tfor domain in $targets; do\n\t\tloopstart=$(date +%s)\n\t\tdir=$workdir/targets/$domain\n\t\tcalled_fn_dir=$dir/.called_fn\n\t\tcd \"$dir\" || { echo \"Failed to cd directory '$dir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tloopstart=$(date +%s)\n\t\tfuzz\n\t\turlchecks\n\t\tjschecks\n\t\tcurrently=$(date +\"%H:%M:%S\")\n\t\tloopend=$(date +%s)\n\t\tgetElapsedTime $loopstart $loopend\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t\tprintf \"${bgreen} $domain finished 3rd loop in ${runtime}  $currently ${reset}\\n\"\n\t\tif [ -n \"$flist\" ]; then\n\t\t\tPOSINLIST=$(eval grep -nrE \"^$domain$\" \"$flist\" | cut -f1 -d':')\n\t\t\tprintf \"\\n${yellow}  $domain is $POSINLIST of $LISTTOTAL${reset}\\n\"\n\t\tfi\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tdone\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_shutdown\n\tfi\n\n\tfor domain in $targets; do\n\t\tloopstart=$(date +%s)\n\t\tdir=$workdir/targets/$domain\n        called_fn_dir=$dir/.called_fn \n\t\tcd \"$dir\" || { echo \"Failed to cd directory '$dir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tcms_scanner\n\t\turl_gf\n\t\twordlist_gen\n\t\twordlist_gen_roboxtractor\n\t\tpassword_dict\n\t\turl_ext\n\t\tcurrently=$(date +\"%H:%M:%S\")\n\t\tloopend=$(date +%s)\n\t\tgetElapsedTime $loopstart $loopend\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t\tprintf \"${bgreen} $domain finished final loop in ${runtime}  $currently ${reset}\\n\"\n\t\tif [ -n \"$flist\" ]; then\n\t\t\tPOSINLIST=$(eval grep -nrE \"^$domain$\" \"$flist\" | cut -f1 -d':')\n\t\t\tprintf \"\\n${yellow}  $domain is $POSINLIST of $LISTTOTAL${reset}\\n\"\n\t\tfi\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tdone\n\tcd \"$workdir\" || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tdir=$workdir\n\tdomain=$multi\n\tend\n}\n\nfunction subs_menu(){\n\tstart\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_lauch\n\t\taxiom_selected\n\tfi\n\n\tsubdomains_full\n\twebprobe_full\n\tsubtakeover\n\tremove_big_files\n\tscreenshot\n#\tvirtualhosts\n\tzonetransfer\n\ts3buckets\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_shutdown\n\tfi\n\n\tend\n}\n\nfunction webs_menu(){\n\tsubtakeover\n\tremove_big_files\n\tscreenshot\n#\tvirtualhosts\n\twaf_checks\n\tnuclei_check\n\tcms_scanner\n\tfuzz\n\turlchecks\n\tjschecks\n\turl_gf\n\twordlist_gen\n\twordlist_gen_roboxtractor\n\tpassword_dict\n\turl_ext\n\tvulns\n\tend\n}\n\nfunction help(){\n\tprintf \"\\n Usage: $0 [-d domain.tld] [-m name] [-l list.txt] [-x oos.txt] [-i in.txt] \"\n\tprintf \"\\n           \t      [-r] [-s] [-p] [-a] [-w] [-n] [-i] [-h] [-f] [--deep] [-o OUTPUT]\\n\\n\"\n\tprintf \" ${bblue}TARGET OPTIONS${reset}\\n\"\n\tprintf \"   -d domain.tld     Target domain\\n\"\n\tprintf \"   -m company        Target company name\\n\"\n\tprintf \"   -l list.txt       Targets list (One on each line)\\n\"\n\tprintf \"   -x oos.txt        Exclude subdomains list (Out Of Scope)\\n\"\n\tprintf \"   -i in.txt         Include subdomains list\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${bblue}MODE OPTIONS${reset}\\n\"\n\tprintf \"   -r, --recon       Recon - Perform full recon process (without attacks)\\n\"\n\tprintf \"   -s, --subdomains  Subdomains - Perform Subdomain Enumeration, Web probing and check for sub-tko\\n\"\n\tprintf \"   -p, --passive     Passive - Perform only passive steps\\n\"\n\tprintf \"   -a, --all         All - Perform all checks and active exploitations\\n\"\n\tprintf \"   -w, --web         Web - Perform web checks from list of subdomains\\n\"\n\tprintf \"   -n, --osint       OSINT - Check for public intel data\\n\"\n\tprintf \"   -c, --custom      Custom - Launches specific function against target, u need to know the function name first\\n\"\n\tprintf \"   -h                Help - Show help section\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${bblue}GENERAL OPTIONS${reset}\\n\"\n\tprintf \"   --deep            Deep scan (Enable some slow options for deeper scan)\\n\"\n\tprintf \"   -f config_file    Alternate reconftw.cfg file\\n\"\n\tprintf \"   -o output/path    Define output folder\\n\"\n\tprintf \"   -v, --vps         Axiom distributed VPS \\n\"\n\tprintf \"   -q                Rate limit in requests per second \\n\"\n\tprintf \" \\n\"\n\tprintf \" ${bblue}USAGE EXAMPLES${reset}\\n\"\n\tprintf \" ${byellow}Perform full recon (without attacks):${reset}\\n\"\n\tprintf \" ./reconftw.sh -d example.com -r\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Perform subdomain enumeration on multiple targets:${reset}\\n\"\n\tprintf \" ./reconftw.sh -l targets.txt -s\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Perform Web based scanning on a subdomains list:${reset}\\n\"\n\tprintf \" ./reconftw.sh -d example.com -l targets.txt -w\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Multidomain recon:${reset}\\n\"\n\tprintf \" ./reconftw.sh -m company -l domainlist.txt -r\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Perform full recon (with active attacks) along Out-Of-Scope subdomains list:${reset}\\n\"\n\tprintf \" ./reconftw.sh -d example.com -x out.txt -a\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Perform full recon and store output to specified directory:${reset}\\n\"\n\tprintf \" ./reconftw.sh -d example.com -r -o custom/path\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Run custom function:${reset}\\n\"\n\tprintf \" ./reconftw.sh -d example.com -c nuclei_check \\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Start the web server:${reset}\\n\"\n\tprintf \" ./reconftw.sh --web-server start\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Stop the web server:${reset}\\n\"\n\tprintf \" ./reconftw.sh --web-server stop\\n\"\n}\n\n###############################################################################################################\n############################################# WEB SERVER ######################################################\n###############################################################################################################\n\n# webserver initialization, thanks @lur1el, @d3vchac, @mx61tt and @dd4n1b0y <3\n\n\nfunction webserver(){\n\tprintf \"${bgreen} Web Interface    by @lur1el, @d3vchac, @mx61tt and @dd4n1b0y ${reset}\\n\"\n\tver=$(python3 -V 2>&1 | sed 's/.* \\([0-9]\\).\\([0-9]\\).*/\\1\\2/')\n\t\n    if [ \"$ver\" -lt \"31\" ]; then\n        echo \"The web interface requires python 3.10 or greater\"\n        exit 1\n    fi\n\n\tif [ \"$1\" == \"start\" ]; then\n\t\tipAddress=$(curl -s ifconfig.me) \n\n\t\tif [ \"$ipAddress\" != \"\" ]; then\n\t\t\tprintf \"\\n ${bblue}Starting web server... ${reset}\\n\"\n\t\t\tcd $SCRIPTPATH/web || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\t$SUDO source $SCRIPTPATH/web/.venv/bin/activate\n\t\t\t$SUDO screen -S ReconftwWebserver -X kill &>/dev/null\n\t\t\t$SUDO screen -dmS ReconftwWebserver python3 manage.py runserver $ipAddress:8001 &>/dev/null\n\t\t\t$SUDO service redis-server start &>/dev/null\n\t\t\t$SUDO screen -S ReconftwCelery -X kill &>/dev/null\n\t\t\t$SUDO screen -dmS ReconftwCelery python3 -m celery -A web worker -l info -P prefork -Q run_scans,default &>/dev/null\n\t\t\tprintf \" ${bblue}Web server started! ${reset}\\n\"\n\t\t\tprintf \" ${bblue}Service Address: http://$ipAddress:8001${reset}\\n\"\n\t\telse\n\t\t\tprintf \"\\n\"\n\t\t\tprintf \" ${red}Server IP address not found.${reset}\\n\"\n\t\t\tprintf \"\\n\"\n\t\t\tprintf \" ${bblue}Check if the server has internet connection.${reset}\\n\"\n\t\tfi\n\telif [ \"$1\" == \"stop\" ]; then\n\t\tprintf \"\\n ${bblue}Stoping web server... ${reset}\\n\"\n\t\t# $SUDO service postgresql stop\n\t\t$SUDO screen -S ReconftwWebserver -X kill &>/dev/null\n\t\t$SUDO service redis-server stop &>/dev/null\n\t\t$SUDO screen -S ReconftwCelery -X kill &>/dev/null\n\t\tprintf \" ${bblue}Web server stoped! ${reset}\\n\"\n\telse\n\t\tprintf \"\\n\"\n\t\tprintf \" ${red}Invalid action${reset}\\n\"\n\t\tprintf \"\\n\"\n\t\tprintf \" ${bblue}Valid actions: start/stop${reset}\\n\"\n\tfi\n}\n\n###############################################################################################################\n########################################### START SCRIPT  #####################################################\n###############################################################################################################\n\n# macOS PATH initialization, thanks @0xtavian <3\nif [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n\tPATH=\"/usr/local/opt/gnu-getopt/bin:$PATH\"\n\tPATH=\"/usr/local/opt/coreutils/libexec/gnubin:$PATH\"\nfi\n\nPROGARGS=$(getopt -o 'd:m:l:x:i:o:f:q:c:rspanwvh::' --long 'domain:,list:,recon,subdomains,passive,all,web,osint,deep,web-server,help,vps' -n 'reconFTW' -- \"$@\")\n\n\n# Note the quotes around \"$PROGARGS\": they are essential!\neval set -- \"$PROGARGS\"\nunset PROGARGS\n\nwhile true; do\n    case \"$1\" in\n        '-d'|'--domain')\n            domain=$2\n\t\t\tipcidr_target $2\n            shift 2\n            continue\n            ;;\n        '-m')\n            multi=$2\n            shift 2\n            continue\n            ;;\n        '-l'|'--list')\n\t\t\tlist=$2\n\t\t\tfor t in $(cat $list); do\n\t\t\t\tipcidr_target $t $list\n\t\t\tdone\n            shift 2\n            continue\n            ;;\n        '-x')\n            outOfScope_file=$2\n            shift 2\n            continue\n            ;;\n        '-i')\n            inScope_file=$2\n            shift 2\n            continue\n            ;;\n\n        # modes\n        '-r'|'--recon')\n            opt_mode='r'\n            shift\n            continue\n            ;;\n        '-s'|'--subdomains')\n            opt_mode='s'\n            shift\n            continue\n            ;;\n        '-p'|'--passive')\n            opt_mode='p'\n            shift\n            continue\n            ;;\n        '-a'|'--all')\n            opt_mode='a'\n            shift\n            continue\n            ;;\n        '-w'|'--web')\n            opt_mode='w'\n            shift\n            continue\n            ;;\n        '-n'|'--osint')\n            opt_mode='n'\n            shift\n            continue\n            ;;\n\t\t'-c'|'--custom')\n\t\t\tcustom_function=$2\n\t\t\topt_mode='c'\n            shift 2\n            continue\n            ;;\n        # extra stuff\n        '-o')\n\t\t\tif [[ \"$2\" != /* ]]; then\n            \tdir_output=$PWD/$2\n\t\t\telse\n\t\t\t\tdir_output=$2\n\t\t\tfi\n            shift 2\n            continue\n            ;;\n\t\t'-v'|'--vps')\n\t\t\twhich axiom-ls &>/dev/null || { printf \"\\n Axiom is needed for this mode and is not installed \\n You have to install it manually \\n\" && exit; allinstalled=false;}\n\t\t\tAXIOM=true\n            shift\n            continue\n            ;;\n        '-f')\n\t\t\tCUSTOM_CONFIG=$2\n            shift 2\n            continue\n            ;;\n\t\t'-q')\n\t\t\trate_limit=$2\n            shift 2\n            continue\n            ;;\n        '--deep')\n            opt_deep=true\n            shift\n            continue\n            ;;\n\n        '--')\n\t\t\tshift\n\t\t\tbreak\n\t\t    ;;\n        '--web-server')\n            . ./reconftw.cfg\n\t\t\tbanner\n\t\t\twebserver $3\n\t\t\texit 1\n\t\t    ;;\n        '--help'| '-h'| *)\n            # echo \"Unknown argument: $1\"\n            . ./reconftw.cfg\n\t\t\tbanner\n            help\n\t\t\ttools_installed\n\t\t\texit 1\n\t\t    ;;\n    esac\ndone\n\n# This is the first thing to do to read in alternate config\nSCRIPTPATH=\"$( cd \"$(dirname \"$0\")\" >/dev/null 2>&1 || exit ; pwd -P )\"\n. \"$SCRIPTPATH\"/reconftw.cfg || { echo \"Error importing reconftw.ctg\"; exit 1; }\nif [ -s \"$CUSTOM_CONFIG\" ]; then\n# shellcheck source=/home/six2dez/Tools/reconftw/custom_config.cfg\n. \"${CUSTOM_CONFIG}\" || { echo \"Error importing reconftw.ctg\"; exit 1; }\nfi\n\nif [ $opt_deep ]; then\n    DEEP=true\nfi\n\nif [ $rate_limit ]; then\n    NUCLEI_RATELIMIT=$rate_limit\n\tFFUF_RATELIMIT=$rate_limit\n\tHTTPX_RATELIMIT=$rate_limit\nfi\n\nif [ -n \"$outOfScope_file\" ]; then\n    isAsciiText $outOfScope_file\n    if [ \"False\" = \"$IS_ASCII\" ]\n    then\n        printf \"\\n\\n${bred} Out of Scope file is not a text file${reset}\\n\\n\"\n        exit\n    fi\nfi\n\nif [ -n \"$inScope_file\" ]; then\n    isAsciiText $inScope_file\n    if [ \"False\" = \"$IS_ASCII\" ]\n    then\n        printf \"\\n\\n${bred} In Scope file is not a text file${reset}\\n\\n\"\n        exit\n    fi\nfi\n\nif [[ $(id -u | grep -o '^0$') == \"0\" ]]; then\n    SUDO=\" \"\nelse\n    SUDO=\"sudo\"\nfi\n\nstartdir=${PWD}\n\nbanner\n\ncheck_version\n\nstartdir=${PWD}\nif [ -n \"$list\" ]; then\n\tif [[ \"$list\" = ./* ]]; then\n\t\tflist=\"${startdir}/${list:2}\"\n\telif [[ \"$list\" = ~* ]]; then\n\t\tflist=\"${HOME}/${list:2}\"\n\telif [[ \"$list\" = /* ]]; then\n\t\tflist=$list\n\telse\n\t\tflist=\"$startdir/$list\"\n\tfi\nelse\n\tflist=''\nfi\n\ncase $opt_mode in\n        'r')\n            if [ -n \"$multi\" ];\tthen\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"multi_recon\"\n\t\t\t\tfi\n\t\t\t\tmulti_recon\n\t\t\t\texit\n\t\t\tfi\n\t\t\tif [ -n \"$list\" ]; then\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"list_recon\"\n\t\t\t\tfi\n\t\t\t\tsed -i 's/\\r$//' $list\n\t\t\t\tfor domain in $(cat $list); do\n\t\t\t\t\tstart\n\t\t\t\t\trecon\n\t\t\t\t\tend\n\t\t\t\tdone\n\t\t\telse\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"recon\"\n\t\t\t\tfi\n\t\t\t\tstart\n\t\t\t\trecon\n\t\t\t\tend\n\t\t\tfi\n            ;;\n        's')\n            if [ -n \"$list\" ]; then\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"subs_menu\"\n\t\t\t\tfi\n\t\t\t\tsed -i 's/\\r$//' $list\n\t\t\t\tfor domain in $(cat $list); do\n\t\t\t\t\tsubs_menu\n\t\t\t\tdone\n\t\t\telse\n\t\t\t\tsubs_menu\n\t\t\tfi\n            ;;\n        'p')\n            if [ -n \"$list\" ]; then\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"passive\"\n\t\t\t\tfi\n\t\t\t\tsed -i 's/\\r$//' $list\n\t\t\t\tfor domain in $(cat $list); do\n\t\t\t\t\tpassive\n\t\t\t\tdone\n\t\t\telse\n\t\t\t\tpassive\n\t\t\tfi\n            ;;\n        'a')\n\t\t\texport VULNS_GENERAL=true\n            if [ -n \"$list\" ]; then\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"all\"\n\t\t\t\tfi\n\t\t\t\tsed -i 's/\\r$//' $list\n\t\t\t\tfor domain in $(cat $list); do\n\t\t\t\t\tall\n\t\t\t\tdone\n\t\t\telse\n\t\t\t\tall\n\t\t\tfi\n            ;;\n        'w')\n\t\t\tif [ -n \"$list\" ]; then\n\t\t\t\tstart\n\t\t\t\tif [[ \"$list\" = /* ]]; then\n\t\t\t\t\tcp $list $dir/webs/webs.txt\n\t\t\t\telse\n\t\t\t\t\tcp $SCRIPTPATH/$list $dir/webs/webs.txt\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tprintf \"\\n\\n${bred} Web mode needs a website list file as target (./reconftw.sh -l target.txt -w) ${reset}\\n\\n\"\n\t\t\t\texit\n\t\t\tfi\n\t\t\twebs_menu\n\t\t\texit\n            ;;\n        'n')\n\t\t\tPRESERVE=true\n\t\t\tif [ -n \"$multi\" ];\tthen\n\t\t\t\tmulti_osint\n\t\t\t\texit\n\t\t\tfi\n\t\t\tif [ -n \"$list\" ]; then\n\t\t\t\tsed -i 's/\\r$//' $list\n\t\t\t\twhile IFS= read -r domain; do\n\t\t\t\t\tstart\n\t\t\t\t\tosint\n\t\t\t\t\tend\n\t\t\t\tdone\n\t\t\telse\n\t\t\t\tstart\n\t\t\t\tosint\n\t\t\t\tend\n\t\t\tfi\n\t\t\t;;\n\t\t'c')\n\t\t\texport DIFF=true\n\t\t\tdir=\"$SCRIPTPATH/Recon/$domain\"\n\t\t\tcd $dir || { echo \"Failed to cd directory '$dir'\"; exit 1; }\n\t\t\tLOGFILE=\"${dir}/.log/${NOW}_${NOWT}.txt\"\n\t\t\tcalled_fn_dir=$dir/.called_fn \n\t\t\t$custom_function\n\t\t\tcd $SCRIPTPATH || { echo \"Failed to cd directory '$dir'\"; exit 1; }\n\t\t\texit\n            ;;\n        # No mode selected.  EXIT!\n\t\t*)\n            help\n            tools_installed\n            exit 1\n            ;;\nesac\n\n"], "fixing_code": ["#!/usr/bin/env bash\n\nfunction banner_graber(){\n\tsource \"${SCRIPTPATH}\"/banners.txt\n\trandx=$(shuf -i 1-23 -n 1)\n\ttmp=\"banner${randx}\" \n\tbanner_code=${!tmp}\n\techo -e \"${banner_code}\"\n}\nfunction banner(){\n\tbanner_code=$(banner_graber)\n\tprintf \"\\n${bgreen}${banner_code}\"\n\tprintf \"\\n ${reconftw_version}                                 by @six2dez${reset}\\n\"\n}\n\n###############################################################################################################\n################################################### TOOLS #####################################################\n###############################################################################################################\n\nfunction check_version(){\n\ttimeout 10 git fetch\n\texit_status=$?\n\tif [ $exit_status -eq 0 ]; then\n\t\tBRANCH=$(git rev-parse --abbrev-ref HEAD)\n\t\tHEADHASH=$(git rev-parse HEAD)\n\t\tUPSTREAMHASH=$(git rev-parse \"${BRANCH}\"@\\{upstream\\})\n\t\tif [ \"$HEADHASH\" != \"$UPSTREAMHASH\" ]; then\n\t\t\tprintf \"\\n${yellow} There is a new version, run ./install.sh to get latest version${reset}\\n\\n\"\n\t\tfi\n\telse\n\t\tprintf \"\\n${bred} Unable to check updates ${reset}\\n\\n\"\n\tfi\n}\n\nfunction tools_installed(){\n\n\tprintf \"\\n\\n${bgreen}#######################################################################${reset}\\n\"\n\tprintf \"${bblue} Checking installed tools ${reset}\\n\\n\"\n\n\tallinstalled=true\n\n\t[ -n \"$GOPATH\" ] || { printf \"${bred} [*] GOPATH var\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -n \"$GOROOT\" ] || { printf \"${bred} [*] GOROOT var\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -n \"$PATH\" ] || { printf \"${bred} [*] PATH var\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/dorks_hunter/dorks_hunter.py\" ] || { printf \"${bred} [*] dorks_hunter\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/brutespray/brutespray.py\" ] || { printf \"${bred} [*] brutespray\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/fav-up/favUp.py\" ] || { printf \"${bred} [*] fav-up\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/Corsy/corsy.py\" ] || { printf \"${bred} [*] Corsy\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/testssl.sh/testssl.sh\" ] || { printf \"${bred} [*] testssl\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/CMSeeK/cmseek.py\" ] || { printf \"${bred} [*] CMSeeK\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${fuzz_wordlist}\" ] || { printf \"${bred} [*] OneListForAll\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${lfi_wordlist}\" ] || { printf \"${bred} [*] lfi_wordlist\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${ssti_wordlist}\" ] || { printf \"${bred} [*] ssti_wordlist\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${subs_wordlist}\" ] || { printf \"${bred} [*] subs_wordlist\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${subs_wordlist_big}\" ] || { printf \"${bred} [*] subs_wordlist_big\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${resolvers}\" ] || { printf \"${bred} [*] resolvers\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"${resolvers_trusted}\" ] || { printf \"${bred} [*] resolvers_trusted\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/xnLinkFinder/xnLinkFinder.py\" ] || { printf \"${bred} [*] xnLinkFinder\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/waymore/waymore.py\" ] || { printf \"${bred} [*] waymore\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/commix/commix.py\" ] || { printf \"${bred} [*] commix\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/getjswords.py\" ] || { printf \"${bred} [*] getjswords   \t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/JSA/jsa.py\" ] || { printf \"${bred} [*] JSA\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/cloud_enum/cloud_enum.py\" ] || { printf \"${bred} [*] cloud_enum\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/ultimate-nmap-parser/ultimate-nmap-parser.sh\" ] || { printf \"${bred} [*] nmap-parse-output\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/pydictor/pydictor.py\" ] || { printf \"${bred} [*] pydictor   \t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/urless/urless/urless.py\" ] || { printf \"${bred} [*] urless\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/smuggler/smuggler.py\" ] || { printf \"${bred} [*] smuggler\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -f \"$tools/regulator/main.py\" ] || { printf \"${bred} [*] regulator\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich github-endpoints &>/dev/null || { printf \"${bred} [*] github-endpoints\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich github-subdomains &>/dev/null || { printf \"${bred} [*] github-subdomains\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich gitlab-subdomains &>/dev/null || { printf \"${bred} [*] gitlab-subdomains\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich katana &>/dev/null || { printf \"${bred} [*] katana\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich wafw00f &>/dev/null || { printf \"${bred} [*] wafw00f\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich dnsvalidator &>/dev/null || { printf \"${bred} [*] dnsvalidator\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich gowitness &>/dev/null || { printf \"${bred} [*] gowitness\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich amass &>/dev/null || { printf \"${bred} [*] Amass\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich dnsx &>/dev/null || { printf \"${bred} [*] dnsx\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich gotator &>/dev/null || { printf \"${bred} [*] gotator\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich nuclei &>/dev/null || { printf \"${bred} [*] Nuclei\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -d ${NUCLEI_TEMPLATES_PATH} ] || { printf \"${bred} [*] Nuclei templates\t[NO]${reset}\\n\"; allinstalled=false;}\n\t[ -d ${tools}/fuzzing-templates ] || { printf \"${bred} [*] Fuzzing templates\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich gf &>/dev/null || { printf \"${bred} [*] Gf\t\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich Gxss &>/dev/null || { printf \"${bred} [*] Gxss\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich subjs &>/dev/null || { printf \"${bred} [*] subjs\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich ffuf &>/dev/null || { printf \"${bred} [*] ffuf\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich massdns &>/dev/null || { printf \"${bred} [*] Massdns\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich qsreplace &>/dev/null || { printf \"${bred} [*] qsreplace\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich interlace &>/dev/null || { printf \"${bred} [*] interlace\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich anew &>/dev/null || { printf \"${bred} [*] Anew\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich unfurl &>/dev/null || { printf \"${bred} [*] unfurl\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich crlfuzz &>/dev/null || { printf \"${bred} [*] crlfuzz\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich httpx &>/dev/null || { printf \"${bred} [*] Httpx\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich jq &>/dev/null || { printf \"${bred} [*] jq\t\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich notify &>/dev/null || { printf \"${bred} [*] notify\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich dalfox &>/dev/null || { printf \"${bred} [*] dalfox\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich puredns &>/dev/null || { printf \"${bred} [*] puredns\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich emailfinder &>/dev/null || { printf \"${bred} [*] emailfinder\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich analyticsrelationships &>/dev/null || { printf \"${bred} [*] analyticsrelationships\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich mapcidr &>/dev/null || { printf \"${bred} [*] mapcidr\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich ppfuzz &>/dev/null || { printf \"${bred} [*] ppfuzz\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich cdncheck &>/dev/null || { printf \"${bred} [*] cdncheck\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich interactsh-client &>/dev/null || { printf \"${bred} [*] interactsh-client\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich tlsx &>/dev/null || { printf \"${bred} [*] tlsx\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich smap &>/dev/null || { printf \"${bred} [*] smap\t\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich gitdorks_go &>/dev/null || { printf \"${bred} [*] gitdorks_go\t\t[NO]${reset}\\n\"; allinstalled=false;}\n\twhich ripgen &>/dev/null || { printf \"${bred} [*] ripgen\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich dsieve &>/dev/null || { printf \"${bred} [*] dsieve\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich inscope &>/dev/null || { printf \"${bred} [*] inscope\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich enumerepo &>/dev/null || { printf \"${bred} [*] enumerepo\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich Web-Cache-Vulnerability-Scanner &>/dev/null || { printf \"${bred} [*] Web-Cache-Vulnerability-Scanner [NO]${reset}\\n\"; allinstalled=false;}\n\twhich subfinder &>/dev/null || { printf \"${bred} [*] subfinder\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich byp4xx &>/dev/null || { printf \"${bred} [*] byp4xx\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich ghauri &>/dev/null || { printf \"${bred} [*] ghauri\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich hakip2host &>/dev/null || { printf \"${bred} [*] hakip2host\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich gau &>/dev/null || { printf \"${bred} [*] gau\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich crt &>/dev/null || { printf \"${bred}  [*] crt\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich gitleaks &>/dev/null || { printf \"${bred} [*] gitleaks\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich trufflehog &>/dev/null || { printf \"${bred} [*] trufflehog\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\twhich s3scanner &>/dev/null || { printf \"${bred} [*] s3scanner\t\t\t[NO]${reset}\\n${reset}\"; allinstalled=false;}\n\t\n\tif [ \"${allinstalled}\" = true ]; then\n\t\tprintf \"${bgreen} Good! All installed! ${reset}\\n\\n\"\n\telse\n\t\tprintf \"\\n${yellow} Try running the installer script again ./install.sh\"\n\t\tprintf \"\\n${yellow} If it fails for any reason try to install manually the tools missed\"\n\t\tprintf \"\\n${yellow} Finally remember to set the ${bred}\\$tools${yellow} variable at the start of this script\"\n\t\tprintf \"\\n${yellow} If nothing works and the world is gonna end you can always ping me :D ${reset}\\n\\n\"\n\tfi\n\n\tprintf \"${bblue} Tools check finished\\n\"\n\tprintf \"${bgreen}#######################################################################\\n${reset}\"\n}\n\n###############################################################################################################\n################################################### OSINT #####################################################\n###############################################################################################################\n\nfunction google_dorks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$GOOGLE_DORKS\" = true ] && [ \"$OSINT\" = true ]; then\n\t\tpython3 $tools/dorks_hunter/dorks_hunter.py -d \"$domain\" -o osint/dorks.txt || { echo \"dorks_hunter command failed\"; exit 1; }\n\t\tend_func \"Results are saved in $domain/osint/dorks.txt\" \"${FUNCNAME[0]}\"\n\telse\n\t\tif [ \"$GOOGLE_DORKS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} are already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction github_dorks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$GITHUB_DORKS\" = true ] && [ \"$OSINT\" = true ]; then\n\t\tstart_func \"${FUNCNAME[0]}\" \"Github Dorks in process\"\n\t\tif [ -s \"${GITHUB_TOKENS}\" ]; then\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tgitdorks_go -gd $tools/gitdorks_go/Dorks/medium_dorks.txt -nws 20 -target \"$domain\" -tf \"${GITHUB_TOKENS}\" -ew 3 | anew -q osint/gitdorks.txt || { echo \"gitdorks_go/anew command failed\"; exit 1; }\n\t\t\telse\n\t\t\t\tgitdorks_go -gd $tools/gitdorks_go/Dorks/smalldorks.txt -nws 20 -target $domain -tf \"${GITHUB_TOKENS}\" -ew 3 | anew -q osint/gitdorks.txt || { echo \"gitdorks_go/anew command failed\"; exit 1; }\n\t\t\tfi\n\t\telse\n\t\t\tprintf \"\\n${bred} Required file ${GITHUB_TOKENS} not exists or empty${reset}\\n\"\n\t\tfi\n\t\tend_func \"Results are saved in $domain/osint/gitdorks.txt\" \"${FUNCNAME[0]}\"\n\telse\n\t\tif [ \"$GITHUB_DORKS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction github_repos(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$GITHUB_REPOS\" = true ] && [ \"$OSINT\" = true ]; then\n\t\tstart_func \"${FUNCNAME[0]}\" \"Github Repos analysis in process\"\n\n\t\tif [ -s \"${GITHUB_TOKENS}\" ]; then\n\t\t\tGH_TOKEN=$(cat ${GITHUB_TOKENS} | head -1)\n\t\t\techo $domain | unfurl format %r > .tmp/company_name.txt\n\t\t\tenumerepo -token-string \"${GH_TOKEN}\" -usernames .tmp/company_name.txt -o .tmp/company_repos.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \".tmp/company_repos.txt\" ] && jq -r '.[].repos[]|.url' < .tmp/company_repos.txt > .tmp/company_repos_url.txt 2>>\"$LOGFILE\"\n\t\t\tmkdir -p .tmp/github_repos 2>>\"$LOGFILE\" >>\"$LOGFILE\"\n\t\t\tmkdir -p .tmp/github 2>>\"$LOGFILE\" >>\"$LOGFILE\"\n\t\t\t[ -s \".tmp/company_repos_url.txt\" ] && interlace -tL .tmp/company_repos_url.txt -threads ${INTERLACE_THREADS} -c \"git clone _target_  .tmp/github_repos/_cleantarget_\" 2>>\"$LOGFILE\" >/dev/null 2>&1\n\t\t\t[ -d \".tmp/github/\" ] && ls .tmp/github_repos > .tmp/github_repos_folders.txt\n\t\t\t[ -s \".tmp/github_repos_folders.txt\" ] && interlace -tL .tmp/github_repos_folders.txt -threads ${INTERLACE_THREADS} -c \"gitleaks detect --source .tmp/github_repos/_target_ --no-banner --no-color -r .tmp/github/gh_secret_cleantarget_.json\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \".tmp/company_repos_url.txt\" ] && interlace -tL .tmp/company_repos_url.txt -threads ${INTERLACE_THREADS} -c \"trufflehog git _target_ -j 2>&1 | jq -c > _output_/_cleantarget_\" -o .tmp/github/ >>\"$LOGFILE\" 2>&1\n\t\t\tif [ -d \".tmp/github/\" ]; then\n\t\t\t\tcat .tmp/github/* 2>/dev/null | jq -c | jq -r > osint/github_company_secrets.json 2>>\"$LOGFILE\"\n\t\t\tfi\n\t\telse\n\t\t\tprintf \"\\n${bred} Required file ${GITHUB_TOKENS} not exists or empty${reset}\\n\"\n\t\tfi\n\t\tend_func \"Results are saved in $domain/osint/github_company_secrets.json\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$GITHUB_REPOS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction metadata(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$METADATA\" = true ] && [ \"$OSINT\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Scanning metadata in public files\"\n\t\tmetafinder -d \"$domain\" -l $METAFINDER_LIMIT -o osint -go -bi -ba &>> \"$LOGFILE\" || { echo \"metafinder command failed\"; exit 1; }\n\t\tmv \"osint/${domain}/\"*\".txt\" \"osint/\" 2>>\"$LOGFILE\"\n\t\trm -rf \"osint/${domain}\" 2>>\"$LOGFILE\"\n\t\tend_func \"Results are saved in $domain/osint/[software/authors/metadata_results].txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$METADATA\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$METADATA\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction postleaks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$POSTMAN_LEAKS\" = true ] && [ \"$OSINT\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Scanning for leaks in postman public directory\"\n\n\t\tpostleaksNg -k \"$domain\" > .tmp/postleaks.txt  || { echo \"postleaksNg command failed\"; exit 1; }\n\n\t\tend_func \"Results are saved in $domain/osint/[software/authors/metadata_results].txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$POSTMAN_LEAKS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$POSTMAN_LEAKS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction emails(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$EMAILS\" = true ] && [ \"$OSINT\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Searching emails/users/passwords leaks\"\n\t\temailfinder -d $domain 2>>\"$LOGFILE\" | anew -q .tmp/emailfinder.txt || { echo \"emailfinder command failed\"; exit 1; }\n\t\t[ -s \".tmp/emailfinder.txt\" ] && cat .tmp/emailfinder.txt | grep \"@\" | grep -iv \"|_\" | anew -q osint/emails.txt\n\n\t\tend_func \"Results are saved in $domain/osint/emails.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$EMAILS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$EMAILS\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction domain_info(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$DOMAIN_INFO\" = true ] && [ \"$OSINT\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Searching domain info (whois, registrant name/email domains)\"\n\t\twhois -H $domain > osint/domain_info_general.txt || { echo \"whois command failed\"; exit 1; }\n\t\tif [ \"$DEEP\" = true ] || [ \"$REVERSE_WHOIS\" = true ]; then\n\t\t\ttimeout -k 1m ${AMASS_INTEL_TIMEOUT}m amass intel -d ${domain} -whois -timeout $AMASS_INTEL_TIMEOUT -o osint/domain_info_reverse_whois.txt 2>>\"$LOGFILE\" &>/dev/null\n\t\tfi\n\t\t\n\t\tcurl -s \"https://aadinternals.azurewebsites.net/api/tenantinfo?domainName=${domain}\" -H \"Origin: https://aadinternals.com\" | jq -r .domains[].name > osint/azure_tenant_domains.txt\n\n\t\tend_func \"Results are saved in $domain/osint/domain_info_[general/name/email/ip].txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$DOMAIN_INFO\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$DOMAIN_INFO\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction ip_info(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$IP_INFO\" = true ] && [ \"$OSINT\" = true ] && [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Searching ip info\"\n\t\tif [ -n \"$WHOISXML_API\" ]; then\n\t\t\tcurl \"https://reverse-ip.whoisxmlapi.com/api/v1?apiKey=${WHOISXML_API}&ip=${domain}\" 2>/dev/null | jq -r '.result[].name' 2>>\"$LOGFILE\" | sed -e \"s/$/ ${domain}/\" | anew -q osint/ip_${domain}_relations.txt\n\t\t\tcurl \"https://www.whoisxmlapi.com/whoisserver/WhoisService?apiKey=${WHOISXML_API}&domainName=${domain}&outputFormat=json&da=2&registryRawText=1&registrarRawText=1&ignoreRawTexts=1\" 2>/dev/null | jq 2>>\"$LOGFILE\" | anew -q osint/ip_${domain}_whois.txt\n\t\t\tcurl \"https://ip-geolocation.whoisxmlapi.com/api/v1?apiKey=${WHOISXML_API}&ipAddress=${domain}\" 2>/dev/null | jq -r '.ip,.location' 2>>\"$LOGFILE\" | anew -q osint/ip_${domain}_location.txt\n\t\t\tend_func \"Results are saved in $domain/osint/ip_[domain_relations|whois|location].txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tprintf \"\\n${yellow} No WHOISXML_API var defined, skipping function ${reset}\\n\"\n\t\tfi\n\telse\n\t\tif [ \"$IP_INFO\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ ! $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$IP_INFO\" = false ] || [ \"$OSINT\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n############################################### SUBDOMAINS ####################################################\n###############################################################################################################\n\nfunction subdomains_full(){\n\tNUMOFLINES_subs=\"0\"\n\tNUMOFLINES_probed=\"0\"\n\tprintf \"${bgreen}#######################################################################\\n\\n\"\n\t! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]] && printf \"${bblue} Subdomain Enumeration $domain\\n\\n\"\n\t[[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]] && printf \"${bblue} Scanning IP $domain\\n\\n\"\n\t[ -s \"subdomains/subdomains.txt\" ] && cp subdomains/subdomains.txt .tmp/subdomains_old.txt\n\t[ -s \"webs/webs.txt\" ] && cp webs/webs.txt .tmp/probed_old.txt\n\n\tif ( [ ! -f \"$called_fn_dir/.sub_active\" ] || [ ! -f \"$called_fn_dir/.sub_brute\" ] || [ ! -f \"$called_fn_dir/.sub_permut\" ] || [ ! -f \"$called_fn_dir/.sub_recursive_brute\" ] )  || [ \"$DIFF\" = true ] ; then\n\t\tresolvers_update\n\tfi\n\n\t[ -s \"${inScope_file}\" ] && cat ${inScope_file} | anew -q subdomains/subdomains.txt\n\n\tif ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]] && [ \"$SUBDOMAINS_GENERAL\" = true ]; then\n\t\tsub_passive\n\t\tsub_crt\n\t\tsub_active\n\t\tsub_noerror\n\t\tsub_brute\n\t\tsub_permut\n\t\tsub_regex_permut\n\t\t#sub_gpt\n\t\tsub_recursive_passive\n\t\tsub_recursive_brute\n\t\tsub_dns\n\t\tsub_scraping\n\t\tsub_analytics\n\telse \n\t\tnotification \"IP/CIDR detected, subdomains search skipped\" info\n\t\techo $domain | anew -q subdomains/subdomains.txt\n\tfi\n\n\twebprobe_simple\n\tif [ -s \"subdomains/subdomains.txt\" ]; then\n\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file subdomains/subdomains.txt\n\t\tNUMOFLINES_subs=$(cat subdomains/subdomains.txt 2>>\"$LOGFILE\" | anew .tmp/subdomains_old.txt | sed '/^$/d' | wc -l)\n\tfi\n\tif [ -s \"webs/webs.txt\" ]; then\n\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file webs/webs.txt\n\t\tNUMOFLINES_probed=$(cat webs/webs.txt 2>>\"$LOGFILE\" | anew .tmp/probed_old.txt | sed '/^$/d' | wc -l)\n\tfi\n\tprintf \"${bblue}\\n Total subdomains: ${reset}\\n\\n\"\n\tnotification \"- ${NUMOFLINES_subs} alive\" good\n\t[ -s \"subdomains/subdomains.txt\" ] && cat subdomains/subdomains.txt | sort\n\tnotification \"- ${NUMOFLINES_probed} new web probed\" good\n\t[ -s \"webs/webs.txt\" ] && cat webs/webs.txt | sort\n\tnotification \"Subdomain Enumeration Finished\" good\n\tprintf \"${bblue} Results are saved in $domain/subdomains/subdomains.txt and webs/webs.txt${reset}\\n\"\n\tprintf \"${bgreen}#######################################################################\\n\\n\"\n}\n\nfunction sub_passive(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBPASSIVE\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Passive Subdomain Enumeration\"\n\n\t\t[[ $RUNAMASS == true ]] && timeout -k 1m ${AMASS_ENUM_TIMEOUT} amass enum -passive -d $domain -config $AMASS_CONFIG -timeout $AMASS_ENUM_TIMEOUT -json .tmp/amass_json.json 2>>\"$LOGFILE\" &>/dev/null\n\t\t[ -s \".tmp/amass_json.json\" ] && cat .tmp/amass_json.json | jq -r '.name' | anew -q .tmp/amass_psub.txt\n\t\t[[ $RUNSUBFINDER == true ]] && subfinder -all -d \"$domain\" -silent -o .tmp/subfinder_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\n\t\tif [ -s \"${GITHUB_TOKENS}\" ]; then\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tgithub-subdomains -d $domain -t $GITHUB_TOKENS -o .tmp/github_subdomains_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\tgithub-subdomains -d $domain -k -q -t $GITHUB_TOKENS -o .tmp/github_subdomains_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\tfi\n\t\tif [ -s \"${GITLAB_TOKENS}\" ]; then\n\t\t\tgitlab-subdomains -d $domain -t $GITLAB_TOKENS > .tmp/gitlab_subdomains_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tif [ \"$INSCOPE\" = true ]; then\n\t\t\tcheck_inscope .tmp/amass_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tcheck_inscope .tmp/subfinder_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tcheck_inscope .tmp/github_subdomains_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tcheck_inscope .tmp/gitlab_subdomains_psub.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tNUMOFLINES=$(find .tmp -type f -iname \"*_psub.txt\" -exec cat {} + | sed \"s/*.//\" | anew .tmp/passive_subs.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (passive)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBPASSIVE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_crt(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBCRT\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Crtsh Subdomain Enumeration\"\n\t\tcrt -s -json -l ${CTR_LIMIT} $domain 2>>\"$LOGFILE\" | jq -r '.[].subdomain' 2>>\"$LOGFILE\" | sed -e \"s/^\\\\*\\\\.//\" | anew -q .tmp/crtsh_subs_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/crtsh_subs_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/crtsh_subs_tmp.txt 2>>\"$LOGFILE\" | sed 's/\\*.//g' | anew .tmp/crtsh_subs.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (cert transparency)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBCRT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_active(){\n\tif [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Active Subdomain Enumeration\"\n\t\tfind .tmp -type f -iname \"*_subs.txt\" -exec cat {} + | anew -q .tmp/subs_no_resolved.txt\n\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/subs_no_resolved.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tresolvers_update_quick_local\n\t\t\t[ -s \".tmp/subs_no_resolved.txt\" ] && puredns resolve .tmp/subs_no_resolved.txt -w .tmp/subdomains_tmp.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\tresolvers_update_quick_axiom\n\t\t\t[ -s \".tmp/subs_no_resolved.txt\" ] && axiom-scan .tmp/subs_no_resolved.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subdomains_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\techo $domain | dnsx -retry 3 -silent -r $resolvers_trusted 2>>\"$LOGFILE\" | anew -q .tmp/subdomains_tmp.txt\n\t\tif [ \"$DEEP\" = true ]; then\n\t\t\tcat .tmp/subdomains_tmp.txt | tlsx -san -cn -silent -ro -c $TLSX_THREADS -p $TLS_PORTS | anew -q .tmp/subdomains_tmp.txt\n\t\telse\n\t\t\tcat .tmp/subdomains_tmp.txt | tlsx -san -cn -silent -ro -c $TLSX_THREADS | anew -q .tmp/subdomains_tmp.txt\n\t\tfi\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subdomains_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/subdomains_tmp.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} subs DNS resolved from passive\" ${FUNCNAME[0]}\n\telse\n\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\tfi\n}\n\nfunction sub_noerror(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBNOERROR\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Checking NOERROR DNS response\"\n\t\tif [[ $(echo \"${RANDOM}thistotallynotexist${RANDOM}.$domain\" | dnsx -r $resolvers -rcode noerror,nxdomain -retry 3 -silent | cut -d' ' -f2) == \"[NXDOMAIN]\" ]]; then \n\t\t\tresolvers_update_quick_local\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tdnsx -d $domain -r $resolvers -silent -rcode noerror -w $subs_wordlist_big | cut -d' ' -f1 | anew -q .tmp/subs_noerror.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\tdnsx -d $domain -r $resolvers -silent -rcode noerror -w $subs_wordlist | cut -d' ' -f1 | anew -q .tmp/subs_noerror.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subs_noerror.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tNUMOFLINES=$(cat .tmp/subs_noerror.txt 2>>\"$LOGFILE\" | sed \"s/*.//\" | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\t\tend_subfunc \"${NUMOFLINES} new subs (DNS noerror)\" ${FUNCNAME[0]}\n\t\telse \n\t\t\tprintf \"\\n${yellow} Detected DNSSEC black lies, skipping this technique ${reset}\\n\" \n\t\tfi\n\telse\n\t\tif [ \"$SUBBRUTE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_dns(){\n\tif [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : DNS Subdomain Enumeration and PTR search\"\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \"subdomains/subdomains.txt\" ] && cat subdomains/subdomains.txt | dnsx -r $resolvers_trusted -a -aaaa -cname -ns -ptr -mx -soa -silent -retry 3 -json -o subdomains/subdomains_dnsregs.json 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[], try .aaaa[], try .cname[], try .ns[], try .ptr[], try .mx[], try .soa[]' 2>/dev/null | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/subdomains_dns.txt\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | hakip2host | cut -d' ' -f 3 | unfurl -u domains | sed -e 's/*\\.//' -e 's/\\.$//' -e '/\\./!d' | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/subdomains_dns.txt\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try \"\\(.host) - \\(.a[])\"' 2>/dev/null | sort -u -k2 | anew -q subdomains/subdomains_ips.txt\n\t\t\tresolvers_update_quick_local\n\t\t\t[ -s \".tmp/subdomains_dns.txt\" ] && puredns resolve .tmp/subdomains_dns.txt -w .tmp/subdomains_dns_resolved.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\t[ -s \"subdomains/subdomains.txt\" ] && axiom-scan subdomains/subdomains.txt -m dnsx -retry 3 -a -aaaa -cname -ns -ptr -mx -soa -json -o subdomains/subdomains_dnsregs.json $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | anew -q .tmp/subdomains_dns_a_records.txt\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | hakip2host | cut -d' ' -f 3 | unfurl -u domains | sed -e 's/*\\.//' -e 's/\\.$//' -e '/\\./!d' | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/subdomains_dns.txt\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[], try .aaaa[], try .cname[], try .ns[], try .ptr[], try .mx[], try .soa[]' 2>/dev/null | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/subdomains_dns.txt\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try \"\\(.host) - \\(.a[])\"' 2>/dev/null | sort -u -k2 | anew -q subdomains/subdomains_ips.txt\n\t\t\tresolvers_update_quick_axiom\n\t\t\t[ -s \".tmp/subdomains_dns.txt\" ] && axiom-scan .tmp/subdomains_dns.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subdomains_dns_resolved.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subdomains_dns_resolved.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/subdomains_dns_resolved.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (dns resolution)\" ${FUNCNAME[0]}\n\telse\n\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\tfi\n}\n\nfunction sub_brute(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBBRUTE\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Bruteforce Subdomain Enumeration\"\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tresolvers_update_quick_local\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tpuredns bruteforce $subs_wordlist_big $domain -w .tmp/subs_brute.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\tpuredns bruteforce $subs_wordlist $domain -w .tmp/subs_brute.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/subs_brute.txt\" ] && puredns resolve .tmp/subs_brute.txt -w .tmp/subs_brute_valid.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\tresolvers_update_quick_axiom\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\taxiom-scan $subs_wordlist_big -m puredns-single $domain -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subs_brute.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\taxiom-scan $subs_wordlist -m puredns-single $domain -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subs_brute.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/subs_brute.txt\" ] && axiom-scan .tmp/subs_brute.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subs_brute_valid.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subs_brute_valid.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/subs_brute_valid.txt 2>>\"$LOGFILE\" | sed \"s/*.//\" | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (bruteforce)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBBRUTE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_scraping(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBSCRAPING\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Source code scraping subdomain search\"\n\t\ttouch .tmp/scrap_subs.txt\n\t\tif [ -s \"$dir/subdomains/subdomains.txt\" ]; then\n\t\t\tif [[ $(cat subdomains/subdomains.txt | wc -l) -le $DEEP_LIMIT ]] || [ \"$DEEP\" = true ] ; then\n\t\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\t\tresolvers_update_quick_local\n\t\t\t\t\tcat subdomains/subdomains.txt | httpx -follow-host-redirects -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info1.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t[ -s \".tmp/web_full_info1.txt\" ] && cat .tmp/web_full_info1.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && cat .tmp/probed_tmp_scrap.txt | httpx -tls-grab -tls-probe -csp-probe -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info2.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t[ -s \".tmp/web_full_info2.txt\" ] && cat .tmp/web_full_info2.txt | jq -r 'try .\"tls-grab\".\"dns_names\"[],try .csp.domains[],try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | sort -u | httpx -silent | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n\n\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && katana -silent -list .tmp/probed_tmp_scrap.txt -jc -kf all -c $KATANA_THREADS -d 3 -fs rdn -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\telse\n\t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && katana -silent -list .tmp/probed_tmp_scrap.txt -jc -kf all -c $KATANA_THREADS -d 2 -fs rdn -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\tfi\n\t\t\t\telse\n\t\t\t\t\tresolvers_update_quick_axiom\n\t\t\t\t\taxiom-scan subdomains/subdomains.txt -m httpx -follow-host-redirects -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info1.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t[ -s \".tmp/web_full_info1.txt\" ] && cat .tmp/web_full_info1.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && axiom-scan .tmp/probed_tmp_scrap.txt -m httpx -tls-grab -tls-probe -csp-probe -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info2.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t[ -s \".tmp/web_full_info2.txt\" ] && cat .tmp/web_full_info2.txt | jq -r 'try .\"tls-grab\".\"dns_names\"[],try .csp.domains[],try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | sort -u | httpx -silent | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && axiom-scan .tmp/probed_tmp_scrap.txt -m katana -jc -kf all -d 3 -fs rdn -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\telse\n\t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && axiom-scan .tmp/probed_tmp_scrap.txt -m katana -jc -kf all -d 2 -fs rdn -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\t\tsed -i '/^.\\{2048\\}./d' .tmp/katana.txt\n\t\t\t\t[ -s \".tmp/katana.txt\" ] && cat .tmp/katana.txt | unfurl -u domains 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/scrap_subs.txt\n\t\t\t\t[ -s \".tmp/scrap_subs.txt\" ] && puredns resolve .tmp/scrap_subs.txt -w .tmp/scrap_subs_resolved.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tif [ \"$INSCOPE\" = true ]; then\n\t\t\t\t\tcheck_inscope .tmp/scrap_subs_resolved.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\t\tNUMOFLINES=$(cat .tmp/scrap_subs_resolved.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | tee .tmp/diff_scrap.txt | sed '/^$/d' | wc -l)\n\t\t\t\t[ -s \".tmp/diff_scrap.txt\" ] && cat .tmp/diff_scrap.txt | httpx -follow-host-redirects -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info3.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t[ -s \".tmp/web_full_info3.txt\" ] && cat .tmp/web_full_info3.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n\t\t\t\tcat .tmp/web_full_info1.txt .tmp/web_full_info2.txt .tmp/web_full_info3.txt 2>>\"$LOGFILE\" | jq -s 'try .' | jq 'try unique_by(.input)' | jq 'try .[]' 2>>\"$LOGFILE\" > .tmp/web_full_info.txt\n\t\t\t\tend_subfunc \"${NUMOFLINES} new subs (code scraping)\" ${FUNCNAME[0]}\n\t\t\telse\n\t\t\t\tend_subfunc \"Skipping Subdomains Web Scraping: Too Many Subdomains\" ${FUNCNAME[0]}\n\t\t\tfi\n\t\telse\n\t\t\tend_subfunc \"No subdomains to search (code scraping)\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$SUBSCRAPING\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_analytics(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBANALYTICS\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Analytics Subdomain Enumeration\"\n\t\tif [ -s \".tmp/probed_tmp_scrap.txt\" ]; then\n\t\t\tmkdir -p .tmp/output_analytics/\n\t\t\tanalyticsrelationships -ch < .tmp/probed_tmp_scrap.txt >> .tmp/analytics_subs_tmp.txt 2>>\"$LOGFILE\"\n\n\t\t\t[ -s \".tmp/analytics_subs_tmp.txt\" ] && cat .tmp/analytics_subs_tmp.txt | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/|__ //\" | anew -q .tmp/analytics_subs_clean.txt\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tresolvers_update_quick_local\n\t\t\t\t[ -s \".tmp/analytics_subs_clean.txt\" ] && puredns resolve .tmp/analytics_subs_clean.txt -w .tmp/analytics_subs_resolved.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\tresolvers_update_quick_axiom\n\t\t\t\t[ -s \".tmp/analytics_subs_clean.txt\" ] && axiom-scan .tmp/analytics_subs_clean.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/analytics_subs_resolved.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\tfi\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/analytics_subs_resolved.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/analytics_subs_resolved.txt 2>>\"$LOGFILE\" | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (analytics relationship)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBANALYTICS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_permut(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBPERMUTE\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Permutations Subdomain Enumeration\"\n\t\tif [ \"$DEEP\" = true ] || [ \"$(cat subdomains/subdomains.txt | wc -l)\" -le $DEEP_LIMIT ] ; then\n\t\t\tif [ \"$PERMUTATIONS_OPTION\" = \"gotator\" ] ; then\n\t\t\t\t[ -s \"subdomains/subdomains.txt\" ] && gotator -sub subdomains/subdomains.txt -perm $tools/permutations_list.txt $GOTATOR_FLAGS -silent 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1.txt\n\t\t\telse\n\t\t\t\t[ -s \"subdomains/subdomains.txt\" ] && ripgen -d subdomains/subdomains.txt -w $tools/permutations_list.txt 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1.txt\n\t\t\tfi\n\t\telif [ \"$(cat .tmp/subs_no_resolved.txt | wc -l)\" -le $DEEP_LIMIT2 ]; then\n\t\t\tif [ \"$PERMUTATIONS_OPTION\" = \"gotator\" ] ; then\n\t\t\t\t[ -s \".tmp/subs_no_resolved.txt\" ] && gotator -sub .tmp/subs_no_resolved.txt -perm $tools/permutations_list.txt $GOTATOR_FLAGS -silent 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1.txt\n\t\t\telse\n\t\t\t\t[ -s \".tmp/subs_no_resolved.txt\" ] && ripgen -d .tmp/subs_no_resolved.txt -w $tools/permutations_list.txt 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1.txt\n\t\t\tfi\n\t\telse\n\t\t\tend_subfunc \"Skipping Permutations: Too Many Subdomains\" ${FUNCNAME[0]}\n\t\t\treturn 1\n\t\tfi\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tresolvers_update_quick_local\n\t\t\t[ -s \".tmp/gotator1.txt\" ] && puredns resolve .tmp/gotator1.txt -w .tmp/permute1.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\tresolvers_update_quick_axiom\n\t\t\t[ -s \".tmp/gotator1.txt\" ] && axiom-scan .tmp/gotator1.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/permute1.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\t\n\t\tif [ \"$PERMUTATIONS_OPTION\" = \"gotator\" ] ; then\n\t\t\t[ -s \".tmp/permute1.txt\" ] && gotator -sub .tmp/permute1.txt -perm $tools/permutations_list.txt $GOTATOR_FLAGS -silent 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator2.txt\n\t\telse\n\t\t\t[ -s \".tmp/permute1.txt\" ] && ripgen -d .tmp/permute1.txt -w $tools/permutations_list.txt 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator2.txt\n\t\tfi\n\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \".tmp/gotator2.txt\" ] && puredns resolve .tmp/gotator2.txt -w .tmp/permute2.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\t[ -s \".tmp/gotator2.txt\" ] && axiom-scan .tmp/gotator2.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/permute2.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tcat .tmp/permute1.txt .tmp/permute2.txt 2>>\"$LOGFILE\" | anew -q .tmp/permute_subs.txt\n\n\t\tif [ -s \".tmp/permute_subs.txt\" ]; then\n\t\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/permute_subs.txt\n\t\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/permute_subs.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tNUMOFLINES=$(cat .tmp/permute_subs.txt 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\telse\n\t\t\tNUMOFLINES=0\n\t\tfi\n\t\tend_subfunc \"${NUMOFLINES} new subs (permutations)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBPERMUTE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_regex_permut(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBREGEXPERMUTE\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Permutations by regex analysis\"\n\t\tcd \"$tools/regulator\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tpython3 main.py -t $domain -f ${dir}/subdomains/subdomains.txt -o ${dir}/.tmp/${domain}.brute\n\t\tcd \"$dir\" || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tresolvers_update_quick_local\n\t\t\t[ -s \".tmp/${domain}.brute\" ] && puredns resolve .tmp/${domain}.brute -w .tmp/regulator.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\tresolvers_update_quick_axiom\n\t\t\t[ -s \".tmp/${domain}.brute\" ] && axiom-scan .tmp/${domain}.brute -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/regulator.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\t\n\t\tif [ -s \".tmp/regulator.txt\" ]; then\n\t\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/regulator.txt\n\t\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/regulator.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tNUMOFLINES=$(cat .tmp/regulator.txt 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\t\telse\n\t\t\tNUMOFLINES=0\n\t\tfi\n\t\tend_subfunc \"${NUMOFLINES} new subs (permutations by regex)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBREGEXPERMUTE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_recursive_passive(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUB_RECURSIVE_PASSIVE\" = true ] && [ -s \"subdomains/subdomains.txt\" ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Subdomains recursive search passive\"\n\t\t# Passive recursive\n\t\t[ -s \"subdomains/subdomains.txt\" ] && dsieve -if subdomains/subdomains.txt -f 3 -top $DEEP_RECURSIVE_PASSIVE > .tmp/subdomains_recurs_top.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tresolvers_update_quick_local\n\t\t\t[ -s \".tmp/subdomains_recurs_top.txt\" ] && timeout -k 1m ${AMASS_ENUM_TIMEOUT}m amass enum -passive -df .tmp/subdomains_recurs_top.txt -nf subdomains/subdomains.txt -config $AMASS_CONFIG -timeout $AMASS_ENUM_TIMEOUT 2>>\"$LOGFILE\" | anew -q .tmp/passive_recursive.txt\n\t\t\t[ -s \".tmp/passive_recursive.txt\" ] && puredns resolve .tmp/passive_recursive.txt -w .tmp/passive_recurs_tmp.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" &>/dev/null\n\t\telse\n\t\t\tresolvers_update_quick_axiom\n\t\t\t[ -s \".tmp/subdomains_recurs_top.txt\" ] && axiom-scan .tmp/subdomains_recurs_top.txt -m amass -passive -o .tmp/amass_prec.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \".tmp/amass_prec.txt\" ] &&  cat .tmp/amass_prec.txt | anew -q .tmp/passive_recursive.txt\n\t\t\t[ -s \".tmp/passive_recursive.txt\" ] && axiom-scan .tmp/passive_recursive.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/passive_recurs_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/passive_recurs_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tNUMOFLINES=$(cat .tmp/passive_recurs_tmp.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed '/^$/d' | anew subdomains/subdomains.txt | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (recursive)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUB_RECURSIVE_PASSIVE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sub_recursive_brute(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUB_RECURSIVE_BRUTE\" = true ] && [ -s \"subdomains/subdomains.txt\" ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Subdomains recursive search active\"\n\t\tif [[ $(cat subdomains/subdomains.txt | wc -l) -le $DEEP_LIMIT ]] ; then\n\t\t\t[ ! -s \".tmp/subdomains_recurs_top.txt\" ] && dsieve -if subdomains/subdomains.txt -f 3 -top $DEEP_RECURSIVE_PASSIVE > .tmp/subdomains_recurs_top.txt\n\t\t\tripgen -d .tmp/subdomains_recurs_top.txt -w $subs_wordlist > .tmp/brute_recursive_wordlist.txt\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tresolvers_update_quick_local\n\t\t\t\t[ -s \".tmp/brute_recursive_wordlist.txt\" ] && puredns resolve .tmp/brute_recursive_wordlist.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -w .tmp/brute_recursive_result.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\tresolvers_update_quick_axiom\n\t\t\t\t[ -s \".tmp/brute_recursive_wordlist.txt\" ] && axiom-scan .tmp/brute_recursive_wordlist.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/brute_recursive_result.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/brute_recursive_result.txt\" ] && cat .tmp/brute_recursive_result.txt | anew -q .tmp/brute_recursive.txt\n\n\t\t\tif [ \"$PERMUTATIONS_OPTION\" = \"gotator\" ] ; then\n\t\t\t\t[ -s \".tmp/brute_recursive.txt\" ] && gotator -sub .tmp/brute_recursive.txt -perm $tools/permutations_list.txt $GOTATOR_FLAGS -silent 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1_recursive.txt\n\t\t\telse\n\t\t\t\t[ -s \".tmp/brute_recursive.txt\" ] && ripgen -d .tmp/brute_recursive.txt -w $tools/permutations_list.txt 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator1_recursive.txt\n\t\t\tfi\n\t\t\t\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\t[ -s \".tmp/gotator1_recursive.txt\" ] && puredns resolve .tmp/gotator1_recursive.txt -w .tmp/permute1_recursive.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\t[ -s \".tmp/gotator1_recursive.txt\" ] && axiom-scan .tmp/gotator1_recursive.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/permute1_recursive.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\n\t\t\tif [ \"$PERMUTATIONS_OPTION\" = \"gotator\" ] ; then\n\t\t\t\t[ -s \".tmp/permute1_recursive.txt\" ] && gotator -sub .tmp/permute1_recursive.txt -perm $tools/permutations_list.txt $GOTATOR_FLAGS -silent 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator2_recursive.txt\n\t\t\telse\n\t\t\t\t[ -s \".tmp/permute1_recursive.txt\" ] && ripgen -d .tmp/permute1_recursive.txt -w $tools/permutations_list.txt 2>>\"$LOGFILE\" | head -c $PERMUTATIONS_LIMIT > .tmp/gotator2_recursive.txt\n\t\t\tfi\n\t\t\t\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \".tmp/gotator2_recursive.txt\" ] && puredns resolve .tmp/gotator2_recursive.txt -w .tmp/permute2_recursive.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\t[ -s \".tmp/gotator2_recursive.txt\" ] && axiom-scan .tmp/gotator2_recursive.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/permute2_recursive.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\tcat .tmp/permute1_recursive.txt .tmp/permute2_recursive.txt 2>>\"$LOGFILE\" | anew -q .tmp/permute_recursive.txt\n\t\telse\n\t\t\tend_subfunc \"skipped in this mode or defined in reconftw.cfg\" ${FUNCNAME[0]}\n\t\tfi\n\t\tif [ \"$INSCOPE\" = true ]; then\n\t\t\tcheck_inscope .tmp/permute_recursive.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tcheck_inscope .tmp/brute_recursive.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\n\t\t# Last validation\n\t\tcat .tmp/permute_recursive.txt .tmp/brute_recursive.txt 2>>\"$LOGFILE\" | anew -q .tmp/brute_perm_recursive.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \".tmp/brute_recursive.txt\" ] && puredns resolve .tmp/brute_perm_recursive.txt -w .tmp/brute_perm_recursive_final.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\t[ -s \".tmp/brute_recursive.txt\" ] && axiom-scan .tmp/brute_perm_recursive.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/brute_perm_recursive_final.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\n\t\tNUMOFLINES=$(cat .tmp/brute_perm_recursive_final.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed '/^$/d' | anew subdomains/subdomains.txt | wc -l)\n\t\tend_subfunc \"${NUMOFLINES} new subs (recursive active)\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUB_RECURSIVE_BRUTE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction subtakeover(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SUBTAKEOVER\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Looking for possible subdomain and DNS takeover\"\n\t\ttouch .tmp/tko.txt\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tnuclei -update 2>>\"$LOGFILE\" >/dev/null\n\t\t\tcat subdomains/subdomains.txt .tmp/webs_all.txt 2>/dev/null | nuclei -silent -nh -tags takeover -severity info,low,medium,high,critical -retries 3 -rl $NUCLEI_RATELIMIT -t ${NUCLEI_TEMPLATES_PATH} -o .tmp/tko.txt\n\t\telse\n\t\t\tcat subdomains/subdomains.txt .tmp/webs_all.txt 2>>\"$LOGFILE\" | sed '/^$/d' | anew -q .tmp/webs_subs.txt\n\t\t\t[ -s \".tmp/webs_subs.txt\" ] && axiom-scan .tmp/webs_subs.txt -m nuclei --nuclei-templates ${NUCLEI_TEMPLATES_PATH} -tags takeover -nh -severity info,low,medium,high,critical -retries 3 -rl $NUCLEI_RATELIMIT -t ${NUCLEI_TEMPLATES_PATH} -o .tmp/tko.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\n\t\t# DNS_TAKEOVER\n\t\tcat .tmp/subs_no_resolved.txt .tmp/subdomains_dns.txt .tmp/scrap_subs.txt .tmp/analytics_subs_clean.txt .tmp/passive_recursive.txt 2>/dev/null | anew -q .tmp/subs_dns_tko.txt\n\t\tcat .tmp/subs_dns_tko.txt 2>/dev/null | dnstake -c $DNSTAKE_THREADS -s 2>>\"$LOGFILE\" | sed '/^$/d' | anew -q .tmp/tko.txt\n\n\t\tsed -i '/^$/d' .tmp/tko.txt\n\n\t\tNUMOFLINES=$(cat .tmp/tko.txt 2>>\"$LOGFILE\" | anew webs/takeover.txt | sed '/^$/d' | wc -l)\n\t\tif [ \"$NUMOFLINES\" -gt 0 ]; then\n\t\t\tnotification \"${NUMOFLINES} new possible takeovers found\" info\n\t\tfi\n\t\tend_func \"Results are saved in $domain/webs/takeover.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SUBTAKEOVER\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction zonetransfer(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$ZONETRANSFER\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Zone transfer check\"\n\t\tfor ns in $(dig +short ns \"$domain\"); do dig axfr \"$domain\" @\"$ns\" >> subdomains/zonetransfer.txt; done\n\t\tif [ -s \"subdomains/zonetransfer.txt\" ]; then\n\t\t\tif ! grep -q \"Transfer failed\" subdomains/zonetransfer.txt ; then notification \"Zone transfer found on ${domain}!\" info; fi\n\t\tfi\n\t\tend_func \"Results are saved in $domain/subdomains/zonetransfer.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$ZONETRANSFER\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$ZONETRANSFER\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction s3buckets(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$S3BUCKETS\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"AWS S3 buckets search\"\n\t\t# S3Scanner\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \"subdomains/subdomains.txt\" ] && s3scanner scan -f subdomains/subdomains.txt 2>>\"$LOGFILE\" | anew -q .tmp/s3buckets.txt\n\t\telse\n\t\t\taxiom-scan subdomains/subdomains.txt -m s3scanner -o .tmp/s3buckets_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \".tmp/s3buckets_tmp.txt\" ] && cat .tmp/s3buckets_tmp.txt .tmp/s3buckets_tmp2.txt 2>>\"$LOGFILE\" | anew -q .tmp/s3buckets.txt && sed -i '/^$/d' .tmp/s3buckets.txt\n\t\tfi\n\t\t# Cloudenum\n\t\tkeyword=${domain%%.*}\n\t\tpython3 ~/Tools/cloud_enum/cloud_enum.py -k $keyword -qs -l .tmp/output_cloud.txt 2>>\"$LOGFILE\" >/dev/null\n\n\t\tNUMOFLINES1=$(cat .tmp/output_cloud.txt 2>>\"$LOGFILE\" | sed '/^#/d' | sed '/^$/d' | anew subdomains/cloud_assets.txt | wc -l)\n\t\tif [ \"$NUMOFLINES1\" -gt 0 ]; then\n\t\t\tnotification \"${NUMOFLINES1} new cloud assets found\" info\n\t\tfi\n\t\tNUMOFLINES2=$(cat .tmp/s3buckets.txt 2>>\"$LOGFILE\" | grep -aiv \"not_exist\" | grep -aiv \"Warning:\" | grep -aiv \"invalid_name\" | grep -aiv \"^http\" | awk 'NF' | anew subdomains/s3buckets.txt | sed '/^$/d' | wc -l)\n\t\tif [ \"$NUMOFLINES2\" -gt 0 ]; then\n\t\t\tnotification \"${NUMOFLINES2} new S3 buckets found\" info\n\t\tfi\n\n\t\tend_func \"Results are saved in subdomains/s3buckets.txt and subdomains/cloud_assets.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$S3BUCKETS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$S3BUCKETS\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n########################################### WEB DETECTION #####################################################\n###############################################################################################################\n\nfunction webprobe_simple(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WEBPROBESIMPLE\" = true ]; then\n\t\tstart_subfunc ${FUNCNAME[0]} \"Running : Http probing $domain\"\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tcat subdomains/subdomains.txt | httpx ${HTTPX_FLAGS} -no-color -json -random-agent -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -retries 2 -timeout $HTTPX_TIMEOUT -o .tmp/web_full_info_probe.txt 2>>\"$LOGFILE\" >/dev/null\n\t\telse\n\t\t\taxiom-scan subdomains/subdomains.txt -m httpx ${HTTPX_FLAGS} -no-color -json -random-agent -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -retries 2 -timeout $HTTPX_TIMEOUT -o .tmp/web_full_info_probe.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tcat .tmp/web_full_info.txt .tmp/web_full_info_probe.txt webs/web_full_info.txt 2>>\"$LOGFILE\" | jq -s 'try .' | jq 'try unique_by(.input)' | jq 'try .[]' 2>>\"$LOGFILE\" > webs/web_full_info.txt\n\t\t[ -s \"webs/web_full_info.txt\" ] && cat webs/web_full_info.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | anew -q .tmp/probed_tmp.txt\n\t\t[ -s \"webs/web_full_info.txt\" ] && cat webs/web_full_info.txt | jq -r 'try . |\"\\(.url) [\\(.status_code)] [\\(.title)] [\\(.webserver)] \\(.tech)\"' | grep \"$domain\" | anew -q webs/web_full_info_plain.txt\n\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/probed_tmp.txt\n\t\tNUMOFLINES=$(cat .tmp/probed_tmp.txt 2>>\"$LOGFILE\" | anew webs/webs.txt | sed '/^$/d' | wc -l)\n\t\tcat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tend_subfunc \"${NUMOFLINES} new websites resolved\" ${FUNCNAME[0]}\n\t\tif [ \"$PROXY\" = true ] && [ -n \"$proxy_url\" ] && [[ $(cat webs/webs.txt| wc -l) -le $DEEP_LIMIT2 ]]; then\n\t\t\tnotification \"Sending websites to proxy\" info\n\t\t\tffuf -mc all -w webs/webs.txt -u FUZZ -replay-proxy $proxy_url 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\telse\n\t\tif [ \"$WEBPROBESIMPLE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction webprobe_full(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WEBPROBEFULL\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Http probing non standard ports\"\n\t\tif [ -s \"subdomains/subdomains.txt\" ]; then\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tif [ -s \"subdomains/subdomains.txt\" ]; then\n\t\t\t\t\tcat subdomains/subdomains.txt | httpx -follow-host-redirects -random-agent -status-code -p $UNCOMMON_PORTS_WEB -threads $HTTPX_UNCOMMONPORTS_THREADS -timeout $HTTPX_UNCOMMONPORTS_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info_uncommon.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tif [ -s \"subdomains/subdomains.txt\" ]; then\n\t\t\t\t\taxiom-scan subdomains/subdomains.txt -m httpx -follow-host-redirects -H \\\"${HEADER}\\\" -status-code -p $UNCOMMON_PORTS_WEB -threads $HTTPX_UNCOMMONPORTS_THREADS -timeout $HTTPX_UNCOMMONPORTS_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info_uncommon.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\tfi\n\t\tfi\n\t\t[ -s \".tmp/web_full_info_uncommon.txt\" ] && cat .tmp/web_full_info_uncommon.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | anew -q .tmp/probed_uncommon_ports_tmp.txt\n\t\t[ -s \".tmp/web_full_info_uncommon.txt\" ] && cat .tmp/web_full_info_uncommon.txt | jq -r 'try . |\"\\(.url) [\\(.status_code)] [\\(.title)] [\\(.webserver)] \\(.tech)\"' | anew -q webs/web_full_info_uncommon_plain.txt\n\t\tif [ -s \".tmp/web_full_info_uncommon.txt\" ]; then\n\t\t\tif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then \n\t\t\t\tcat .tmp/web_full_info_uncommon.txt 2>>\"$LOGFILE\" | anew -q webs/web_full_info_uncommon.txt\n\t\t\telse\n\t\t\t\tcat .tmp/web_full_info_uncommon.txt 2>>\"$LOGFILE\" | grep \"$domain\" | anew -q webs/web_full_info_uncommon.txt\n\t\t\tfi\n\t\tfi\n\t\tNUMOFLINES=$(cat .tmp/probed_uncommon_ports_tmp.txt 2>>\"$LOGFILE\" | anew webs/webs_uncommon_ports.txt | sed '/^$/d' | wc -l)\n\t\tnotification \"Uncommon web ports: ${NUMOFLINES} new websites\" good\n\t\t[ -s \"webs/webs_uncommon_ports.txt\" ] && cat webs/webs_uncommon_ports.txt\n\t\tcat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tend_func \"Results are saved in $domain/webs/webs_uncommon_ports.txt\" ${FUNCNAME[0]}\n\t\tif [ \"$PROXY\" = true ] && [ -n \"$proxy_url\" ] && [[ $(cat webs/webs_uncommon_ports.txt| wc -l) -le $DEEP_LIMIT2 ]]; then\n\t\t\tnotification \"Sending websites with uncommon ports to proxy\" info\n\t\t\tffuf -mc all -w webs/webs_uncommon_ports.txt -u FUZZ -replay-proxy $proxy_url 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\telse\n\t\tif [ \"$WEBPROBEFULL\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction screenshot(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WEBSCREENSHOT\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Web Screenshots\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\t\n\t\tnum_lines=$(wc -l < .tmp/webs_all.txt)\n\t\tdynamic_gowitness_timeout=$(expr $num_lines \\* $GOWITNESS_TIMEOUT_PER_SITE)\n\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t[ -s \".tmp/webs_all.txt\" ] && timeout -k 1m ${dynamic_gowitness_timeout}s gowitness file -f .tmp/webs_all.txt -t $GOWITNESS_THREADS $GOWITNESS_FLAGS 2>>\"$LOGFILE\"\n\t\telse\n\t\t\ttimeout -k 1m ${dynamic_gowitness_timeout}s axiom-scan .tmp/webs_all.txt -m gowitness -t $GOWITNESS_THREADS $GOWITNESS_FLAGS -o screenshots $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tend_func \"Results are saved in $domain/screenshots folder\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$WEBSCREENSHOT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction virtualhosts(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$VIRTUALHOSTS\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Virtual Hosts dicovery\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\tmkdir -p $dir/virtualhosts $dir/.tmp/virtualhosts\n\t\t\tinterlace -tL .tmp/webs_all.txt -threads ${INTERLACE_THREADS} -c \"ffuf -ac -t ${FFUF_THREADS} -rate ${FFUF_RATELIMIT} -H \\\"${HEADER}\\\" -H \\\"Host: FUZZ._cleantarget_\\\" -w ${fuzz_wordlist} -maxtime ${FFUF_MAXTIME} -u  _target_ -of json -o _output_/_cleantarget_.json\" -o $dir/.tmp/virtualhosts 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfor sub in $(cat .tmp/webs_all.txt); do\n\t\t\t\tsub_out=$(echo $sub | sed -e 's|^[^/]*//||' -e 's|/.*$||')\n\t\t\t\t[ -s \"$dir/.tmp/virtualhosts/${sub_out}.json\" ] && cat $dir/.tmp/virtualhosts/${sub_out}.json | jq -r 'try .results[] | \"\\(.status) \\(.length) \\(.url)\"' | sort | anew -q $dir/virtualhosts/${sub_out}.txt\n\t\t\tdone\n\t\t\tfind $dir/virtualhosts/ -type f -iname \"*.txt\" -exec cat {} + 2>>\"$LOGFILE\" | anew -q $dir/virtualhosts/virtualhosts_full.txt\n\t\t\tend_func \"Results are saved in $domain/virtualhosts/*subdomain*.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"No $domain/web/webs.txts file found, virtualhosts skipped \" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$VIRTUALHOSTS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n############################################# HOST SCAN #######################################################\n###############################################################################################################\n\nfunction favicon(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$FAVICON\" = true ] && ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\tstart_func ${FUNCNAME[0]} \"Favicon Ip Lookup\"\n\t\tcd \"$tools/fav-up\" || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tpython3 favUp.py -w \"$domain\" -sc -o favicontest.json 2>>\"$LOGFILE\" >/dev/null\n\t\tif [ -s \"favicontest.json\" ]; then\n\t\t\tcat favicontest.json | jq -r 'try .found_ips' 2>>\"$LOGFILE\" | grep -v \"not-found\" > favicontest.txt\n\t\t\tsed -i \"s/|/\\n/g\" favicontest.txt\n\t\t\tcat favicontest.txt 2>>\"$LOGFILE\"\n\t\t\tmv favicontest.txt $dir/hosts/favicontest.txt 2>>\"$LOGFILE\"\n\t\t\trm -f favicontest.json 2>>\"$LOGFILE\"\n\t\tfi\n\t\tcd \"$dir\" || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tend_func \"Results are saved in hosts/favicontest.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$FAVICON\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\treturn\n\t\telse\n\t\t\tif [ \"$FAVICON\" = false ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\t\telse\n\t\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\t\tfi\n\t\tfi\n\tfi\n}\n\nfunction portscan(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$PORTSCANNER\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Port scan\"\n\t\tif ! [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then\n\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try . | \"\\(.host) \\(.a[0])\"' | anew -q .tmp/subs_ips.txt\n\t\t\t[ -s \".tmp/subs_ips.txt\" ] && awk '{ print $2 \" \" $1}' .tmp/subs_ips.txt | sort -k2 -n | anew -q hosts/subs_ips_vhosts.txt\n\t\t\t[ -s \"hosts/subs_ips_vhosts.txt\" ] && cat hosts/subs_ips_vhosts.txt | cut -d ' ' -f1 | grep -aEiv \"^(127|10|169\\.154|172\\.1[6789]|172\\.2[0-9]|172\\.3[01]|192\\.168)\\.\" | grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" | anew -q hosts/ips.txt\n\t\telse echo $domain | grep -aEiv \"^(127|10|169\\.154|172\\.1[6789]|172\\.2[0-9]|172\\.3[01]|192\\.168)\\.\" | grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" | anew -q hosts/ips.txt\n\t\tfi\n\t\t[ ! -s \"hosts/cdn_providers.txt\" ] && cat hosts/ips.txt 2>/dev/null | cdncheck -silent -resp -nc 2>/dev/null > hosts/cdn_providers.txt\n\t\t[ -s \"hosts/ips.txt\" ] && comm -23 <(cat hosts/ips.txt | sort -u) <(cat hosts/cdn_providers.txt | cut -d'[' -f1 | sed 's/[[:space:]]*$//' | sort -u) | grep -aEiv \"^(127|10|169\\.154|172\\.1[6789]|172\\.2[0-9]|172\\.3[01]|192\\.168)\\.\" | grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" | sort -u | anew -q .tmp/ips_nocdn.txt\n\t\tprintf \"${bblue}\\n Resolved IP addresses (No CDN) ${reset}\\n\\n\";\n\t\t[ -s \".tmp/ips_nocdn.txt\" ] && cat .tmp/ips_nocdn.txt | sort\n\t\tprintf \"${bblue}\\n Scanning ports... ${reset}\\n\\n\";\n\t\tif [ \"$PORTSCAN_PASSIVE\" = true ] && [ ! -f \"hosts/portscan_passive.txt\" ] && [ -s \".tmp/ips_nocdn.txt\" ] ; then\n\t\t\tsmap -iL .tmp/ips_nocdn.txt > hosts/portscan_passive.txt\n\t\tfi\n\t\tif [ \"$PORTSCAN_ACTIVE\" = true ]; then\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\t[ -s \".tmp/ips_nocdn.txt\" ] && $SUDO nmap --top-ports 200 -sV -n --max-retries 2 -Pn --open --script vulners -iL .tmp/ips_nocdn.txt -oA hosts/portscan_active 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\t[ -s \".tmp/ips_nocdn.txt\" ] && axiom-scan .tmp/ips_nocdn.txt -m nmapx --top-ports 200 -sV -n -Pn --open --max-retries 2 --script vulners -oA hosts/portscan_active $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\tfi\n\t\tend_func \"Results are saved in hosts/portscan_[passive|active].txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$PORTSCANNER\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction cdnprovider(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$CDN_IP\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"CDN provider check\"\n\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try . | .a[]' | grep -aEiv \"^(127|10|169\\.154|172\\.1[6789]|172\\.2[0-9]|172\\.3[01]|192\\.168)\\.\" | grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" | sort -u > .tmp/ips_cdn.txt\n\t\t[ -s \".tmp/ips_cdn.txt\" ] && cat .tmp/ips_cdn.txt | cdncheck -silent -resp -nc | anew -q $dir/hosts/cdn_providers.txt\n\t\tend_func \"Results are saved in hosts/cdn_providers.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$CDN_IP\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n############################################# WEB SCAN ########################################################\n###############################################################################################################\n\nfunction waf_checks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WAF_DETECTION\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Website's WAF detection\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\twafw00f -i .tmp/webs_all.txt -o .tmp/wafs.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\telse\n\t\t\t\taxiom-scan .tmp/webs_all.txt -m wafw00f -o .tmp/wafs.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\tif [ -s \".tmp/wafs.txt\" ]; then\n\t\t\t\tcat .tmp/wafs.txt | sed -e 's/^[ \\t]*//' -e 's/ \\+ /\\t/g' -e '/(None)/d' | tr -s \"\\t\" \";\" > webs/webs_wafs.txt\n\t\t\t\tNUMOFLINES=$(cat webs/webs_wafs.txt 2>>\"$LOGFILE\" | sed '/^$/d' | wc -l)\n\t\t\t\tnotification \"${NUMOFLINES} websites protected by waf\" info\n\t\t\t\tend_func \"Results are saved in $domain/webs/webs_wafs.txt\" ${FUNCNAME[0]}\n\t\t\telse\n\t\t\t\tend_func \"No results found\" ${FUNCNAME[0]}\n\t\t\tfi\n\t\telse\n\t\t\tend_func \"No websites to scan\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$WAF_DETECTION\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction nuclei_check(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$NUCLEICHECK\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Templates based web scanner\"\n\t\tnuclei -update 2>>\"$LOGFILE\" >/dev/null\n\t\tmkdir -p nuclei_output\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\t[ ! -s \".tmp/webs_subs.txt\" ] && cat subdomains/subdomains.txt .tmp/webs_all.txt 2>>\"$LOGFILE\" | anew -q .tmp/webs_subs.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then                 # avoid globbing (expansion of *).\n\t\t\tIFS=',' read -ra severity_array <<< \"$NUCLEI_SEVERITY\"\n\t\t\tfor crit in \"${severity_array[@]}\"\n\t\t\tdo\n\t\t\t\tprintf \"${yellow}\\n Running : Nuclei $crit ${reset}\\n\\n\"\n\t\t\t\tcat .tmp/webs_subs.txt 2>/dev/null | nuclei $NUCLEI_FLAGS -severity $crit -nh -rl $NUCLEI_RATELIMIT -o nuclei_output/${crit}.txt\n\t\t\tdone\n\t\t\tprintf \"\\n\\n\"\n\t\telse\n\t\t\tif [ -s \".tmp/webs_subs.txt\" ]; then\n\t\t\t\tIFS=',' read -ra severity_array <<< \"$NUCLEI_SEVERITY\"\n\t\t\t\tfor crit in \"${severity_array[@]}\"\n\t\t\t\tdo\n\t\t\t\t\tprintf \"${yellow}\\n Running : Nuclei $crit, check results on nuclei_output folder${reset}\\n\\n\"\n\t\t\t\t\taxiom-scan .tmp/webs_subs.txt -m nuclei --nuclei-templates ${NUCLEI_TEMPLATES_PATH} -severity ${crit} -nh -rl $NUCLEI_RATELIMIT -o nuclei_output/${crit}.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t[ -s \"nuclei_output/${crit}.txt\" ] && cat nuclei_output/${crit}.txt\n\t\t\t\tdone\n\t\t\t\tprintf \"\\n\\n\"\n\t\t\tfi\n\t\tfi\n\t\tend_func \"Results are saved in $domain/nuclei_output folder\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$NUCLEICHECK\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction fuzz(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$FUZZ\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Web directory fuzzing\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\tmkdir -p $dir/fuzzing $dir/.tmp/fuzzing\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tinterlace -tL .tmp/webs_all.txt -threads ${INTERLACE_THREADS} -c \"ffuf ${FFUF_FLAGS} -t ${FFUF_THREADS} -rate ${FFUF_RATELIMIT} -H \\\"${HEADER}\\\" -w ${fuzz_wordlist} -maxtime ${FFUF_MAXTIME} -u _target_/FUZZ -o _output_/_cleantarget_.json\" -o $dir/.tmp/fuzzing 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfor sub in $(cat .tmp/webs_all.txt); do\n\t\t\t\t\tsub_out=$(echo $sub | sed -e 's|^[^/]*//||' -e 's|/.*$||')\n\t\t\t\t\t[ -s \"$dir/.tmp/fuzzing/${sub_out}.json\" ] && cat $dir/.tmp/fuzzing/${sub_out}.json | jq -r 'try .results[] | \"\\(.status) \\(.length) \\(.url)\"' | sort -k1 | anew -q $dir/fuzzing/${sub_out}.txt\n\t\t\t\tdone\n\t\t\t\tfind $dir/fuzzing/ -type f -iname \"*.txt\" -exec cat {} + 2>>\"$LOGFILE\" | sort -k1 | anew -q $dir/fuzzing/fuzzing_full.txt\n\t\t\telse\n\t\t\t\taxiom-exec \"mkdir -p /home/op/lists/seclists/Discovery/Web-Content/\" &>/dev/null\n\t\t\t\taxiom-exec \"wget -q -O - ${fuzzing_remote_list} > /home/op/lists/fuzz_wordlist.txt\" &>/dev/null\n\t\t\t\taxiom-exec \"wget -q -O - ${fuzzing_remote_list} > /home/op/lists/seclists/Discovery/Web-Content/big.txt\" &>/dev/null\n\t\t\t\taxiom-scan .tmp/webs_all.txt -m ffuf_base -H \"${HEADER}\" $FFUF_FLAGS -s -maxtime $FFUF_MAXTIME -o $dir/.tmp/ffuf-content.json $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfor sub in $(cat .tmp/webs_all.txt); do\n\t\t\t\t\tsub_out=$(echo $sub | sed -e 's|^[^/]*//||' -e 's|/.*$||')\n\t\t\t\t\t[ -s \"$dir/.tmp/ffuf-content.json\" ] && cat .tmp/ffuf-content.json | jq -r 'try .results[] | \"\\(.status) \\(.length) \\(.url)\"' | grep $sub | sort -k1 | anew -q fuzzing/${sub_out}.txt\n\t\t\t\tdone\n\t\t\t\tfind $dir/fuzzing/ -type f -iname \"*.txt\" -exec cat {} + 2>>\"$LOGFILE\" | sort -k1 | anew -q $dir/fuzzing/fuzzing_full.txt\n\t\t\tfi\n\t\t\tend_func \"Results are saved in $domain/fuzzing/*subdomain*.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"No $domain/web/webs.txts file found, fuzzing skipped \" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$FUZZ\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction cms_scanner(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$CMS_SCANNER\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"CMS Scanner\"\n\t\tmkdir -p $dir/cms && rm -rf $dir/cms/*\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\ttr '\\n' ',' < .tmp/webs_all.txt > .tmp/cms.txt\n\t\t\ttimeout -k 1m ${CMSSCAN_TIMEOUT}s python3 $tools/CMSeeK/cmseek.py -l .tmp/cms.txt --batch -r 2>>\"$LOGFILE\" &>/dev/null\n\t\t\texit_status=$?\n\t\t\tif [[ $exit_status -eq 125 ]]; then\n\t\t\t\techo \"TIMEOUT cmseek.py - investigate manually for $dir\" >> \"$LOGFILE\"\n\t\t\t\tend_func \"TIMEOUT cmseek.py - investigate manually for $dir\" ${FUNCNAME[0]}\n\t\t\t\treturn\n\t\t\telif [[ $exit_status -ne 0 ]]; then\n\t\t\t\techo \"ERROR cmseek.py - investigate manually for $dir\" >> \"$LOGFILE\"\n\t\t\t\tend_func \"ERROR cmseek.py - investigate manually for $dir\" ${FUNCNAME[0]}\n\t\t\t\treturn\n\t\t\tfi\t# otherwise Assume we have a successfully exited cmseek\n\t\t\tfor sub in $(cat .tmp/webs_all.txt); do\n\t\t\t\tsub_out=$(echo $sub | sed -e 's|^[^/]*//||' -e 's|/.*$||')\n\t\t\t\tcms_id=$(cat $tools/CMSeeK/Result/${sub_out}/cms.json 2>/dev/null | jq -r 'try .cms_id')\n\t\t\t\tif [ -z \"$cms_id\" ]; then\n\t\t\t\t\trm -rf $tools/CMSeeK/Result/${sub_out}\n\t\t\t\telse\n\t\t\t\t\tmv -f $tools/CMSeeK/Result/${sub_out} $dir/cms/ 2>>\"$LOGFILE\"\n\t\t\t\tfi\n\t\t\tdone\n\t\t\tend_func \"Results are saved in $domain/cms/*subdomain* folder\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"No $domain/web/webs.txts file found, cms scanner skipped\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$CMS_SCANNER\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction urlchecks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$URL_CHECK\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"URL Extraction\"\n\t\tmkdir -p js\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tif [ \"$URL_CHECK_PASSIVE\" = true ]; then\n\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\tcat .tmp/webs_all.txt | unfurl -u domains > .tmp/waymore_input.txt\n\t\t\t\t\t\tpython3 $tools/waymore/waymore.py -i .tmp/waymore_input.txt -mode U -f -oU .tmp/url_extract_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\telse\n\t\t\t\t\t\tcat .tmp/webs_all.txt | gau --threads $GAU_THREADS | anew -q .tmp/url_extract_tmp.txt\n\t\t\t\t\tfi\n\t\t\t\t\tif [ -s \"${GITHUB_TOKENS}\" ]; then\n\t\t\t\t\t\tgithub-endpoints -q -k -d $domain -t ${GITHUB_TOKENS} -o .tmp/github-endpoints.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\t[ -s \".tmp/github-endpoints.txt\" ] && cat .tmp/github-endpoints.txt | anew -q .tmp/url_extract_tmp.txt\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\t\tdiff_webs=$(diff <(sort -u .tmp/probed_tmp.txt 2>>\"$LOGFILE\") <(sort -u .tmp/webs_all.txt 2>>\"$LOGFILE\") | wc -l)\n\t\t\t\tif [ $diff_webs != \"0\" ] || [ ! -s \".tmp/katana.txt\" ]; then\n\t\t\t\t\tif [ \"$URL_CHECK_ACTIVE\" = true ]; then\n\t\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\t\tkatana -silent -list .tmp/webs_all.txt -jc -kf all -c $KATANA_THREADS -d 3 -fs rdn -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tkatana -silent -list .tmp/webs_all.txt -jc -kf all -c $KATANA_THREADS -d 2 -fs rdn -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\tfi\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tif [ \"$URL_CHECK_PASSIVE\" = true ]; then\n\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\tcat .tmp/webs_all.txt | unfurl -u domains > .tmp/waymore_input.txt\n\t\t\t\t\t\taxiom-scan .tmp/waymore_input.txt -m waymore -o .tmp/url_extract_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\telse\n\t\t\t\t\t\taxiom-scan .tmp/webs_all.txt -m gau -o .tmp/url_extract_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\tfi\n\t\t\t\t\tif [ -s \"${GITHUB_TOKENS}\" ]; then\n\t\t\t\t\t\tgithub-endpoints -q -k -d $domain -t ${GITHUB_TOKENS} -o .tmp/github-endpoints.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\t[ -s \".tmp/github-endpoints.txt\" ] && cat .tmp/github-endpoints.txt | anew -q .tmp/url_extract_tmp.txt\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\t\tdiff_webs=$(diff <(sort -u .tmp/probed_tmp.txt) <(sort -u .tmp/webs_all.txt) | wc -l)\n\t\t\t\tif [ $diff_webs != \"0\" ] || [ ! -s \".tmp/katana.txt\" ]; then\n\t\t\t\t\tif [ \"$URL_CHECK_ACTIVE\" = true ]; then\n\t\t\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t\t\taxiom-scan .tmp/webs_all.txt -m katana -jc -kf all -d 3 -fs rdn -fs rdn -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\taxiom-scan .tmp/webs_all.txt -m katana -jc -kf all -d 2 -fs rdn -fs rdn -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\t\tfi\t\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\tfi\n\t\t\t[ -s \".tmp/katana.txt\" ] && sed -i '/^.\\{2048\\}./d' .tmp/katana.txt\n\t\t\t[ -s \".tmp/katana.txt\" ] && cat .tmp/katana.txt | anew -q .tmp/url_extract_tmp.txt\n\t\t\t[ -s \".tmp/url_extract_tmp.txt\" ] && cat .tmp/url_extract_tmp.txt | grep \"${domain}\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | grep -aEi \"\\.(js)\" | anew -q .tmp/url_extract_js.txt\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t[ -s \".tmp/url_extract_js.txt\" ] && interlace -tL .tmp/url_extract_js.txt -threads 10 -c \"python3 $tools/JSA/jsa.py -f target | anew -q .tmp/url_extract_tmp.txt\" &>/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/url_extract_tmp.txt\" ] &&  cat .tmp/url_extract_tmp.txt | grep \"${domain}\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | grep \"=\" | qsreplace -a 2>>\"$LOGFILE\" | grep -aEiv \"\\.(eot|jpg|jpeg|gif|css|tif|tiff|png|ttf|otf|woff|woff2|ico|pdf|svg|txt|js)$\" | anew -q .tmp/url_extract_tmp2.txt\n\t\t\t[ -s \".tmp/url_extract_tmp2.txt\" ] && cat .tmp/url_extract_tmp2.txt | python3 $tools/urless/urless/urless.py | anew -q .tmp/url_extract_uddup.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tNUMOFLINES=$(cat .tmp/url_extract_uddup.txt 2>>\"$LOGFILE\" | anew webs/url_extract.txt | sed '/^$/d' | wc -l)\n\t\t\tnotification \"${NUMOFLINES} new urls with params\" info\n\t\t\tend_func \"Results are saved in $domain/webs/url_extract.txt\" ${FUNCNAME[0]}\n\t\t\tif [ \"$PROXY\" = true ] && [ -n \"$proxy_url\" ] && [[ $(cat webs/url_extract.txt | wc -l) -le $DEEP_LIMIT2 ]]; then\n\t\t\t\tnotification \"Sending urls to proxy\" info\n\t\t\t\tffuf -mc all -w webs/url_extract.txt -u FUZZ -replay-proxy $proxy_url 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\tfi\n\telse\n\t\tif [ \"$URL_CHECK\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction url_gf(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$URL_GF\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Vulnerable Pattern Search\"\n\t\tmkdir -p gf\n\t\tif [ -s \"webs/url_extract.txt\" ]; then\n\t\t\tgf xss webs/url_extract.txt | anew -q gf/xss.txt\n\t\t\tgf ssti webs/url_extract.txt | anew -q gf/ssti.txt\n\t\t\tgf ssrf webs/url_extract.txt | anew -q gf/ssrf.txt\n\t\t\tgf sqli webs/url_extract.txt | anew -q gf/sqli.txt\n\t\t\tgf redirect webs/url_extract.txt | anew -q gf/redirect.txt\n\t\t\t[ -s \"gf/ssrf.txt\" ] && cat gf/ssrf.txt | anew -q gf/redirect.txt\n\t\t\tgf rce webs/url_extract.txt | anew -q gf/rce.txt\n\t\t\tgf potential webs/url_extract.txt | cut -d ':' -f3-5 |anew -q gf/potential.txt\n\t\t\t[ -s \".tmp/url_extract_tmp.txt\" ] && cat .tmp/url_extract_tmp.txt | grep -aEiv \"\\.(eot|jpg|jpeg|gif|css|tif|tiff|png|ttf|otf|woff|woff2|ico|pdf|svg|txt|js)$\" | unfurl -u format %s://%d%p 2>>\"$LOGFILE\" | anew -q gf/endpoints.txt\n\t\t\tgf lfi webs/url_extract.txt | anew -q gf/lfi.txt\n\t\tfi\n\t\tend_func \"Results are saved in $domain/gf folder\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$URL_GF\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction url_ext(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$URL_EXT\" = true ]; then\n\t\tif [ -s \".tmp/url_extract_tmp.txt\" ]; then\n\t\t\tstart_func ${FUNCNAME[0]} \"Urls by extension\"\n\t\t\text=(\"7z\" \"achee\" \"action\" \"adr\" \"apk\" \"arj\" \"ascx\" \"asmx\" \"asp\" \"aspx\" \"axd\" \"backup\" \"bak\" \"bat\" \"bin\" \"bkf\" \"bkp\" \"bok\" \"cab\" \"cer\" \"cfg\" \"cfm\" \"cfml\" \"cgi\" \"cnf\" \"conf\" \"config\" \"cpl\" \"crt\" \"csr\" \"csv\" \"dat\" \"db\" \"dbf\" \"deb\" \"dmg\" \"dmp\" \"doc\" \"docx\" \"drv\" \"email\" \"eml\" \"emlx\" \"env\" \"exe\" \"gadget\" \"gz\" \"html\" \"ica\" \"inf\" \"ini\" \"iso\" \"jar\" \"java\" \"jhtml\" \"json\" \"jsp\" \"key\" \"log\" \"lst\" \"mai\" \"mbox\" \"mbx\" \"md\" \"mdb\" \"msg\" \"msi\" \"nsf\" \"ods\" \"oft\" \"old\" \"ora\" \"ost\" \"pac\" \"passwd\" \"pcf\" \"pdf\" \"pem\" \"pgp\" \"php\" \"php3\" \"php4\" \"php5\" \"phtm\" \"phtml\" \"pkg\" \"pl\" \"plist\" \"pst\" \"pwd\" \"py\" \"rar\" \"rb\" \"rdp\" \"reg\" \"rpm\" \"rtf\" \"sav\" \"sh\" \"shtm\" \"shtml\" \"skr\" \"sql\" \"swf\" \"sys\" \"tar\" \"tar.gz\" \"tmp\" \"toast\" \"tpl\" \"txt\" \"url\" \"vcd\" \"vcf\" \"wml\" \"wpd\" \"wsdl\" \"wsf\" \"xls\" \"xlsm\" \"xlsx\" \"xml\" \"xsd\" \"yaml\" \"yml\" \"z\" \"zip\")\n\t\t\t#echo \"\" > webs/url_extract.txt\n\t\t\tfor t in \"${ext[@]}\"; do\n\t\t\t\tNUMOFLINES=$(cat .tmp/url_extract_tmp.txt | grep -aEi \"\\.(${t})($|\\/|\\?)\" | sort -u | sed '/^$/d' | wc -l)\n\t\t\t\tif [[ ${NUMOFLINES} -gt 0 ]]; then\n\t\t\t\t\techo -e \"\\n############################\\n + ${t} + \\n############################\\n\" >> webs/urls_by_ext.txt\n\t\t\t\t\tcat .tmp/url_extract_tmp.txt | grep -aEi \"\\.(${t})($|\\/|\\?)\" >> webs/urls_by_ext.txt\n\t\t\t\tfi\n\t\t\tdone\n\t\t\tend_func \"Results are saved in $domain/webs/urls_by_ext.txt\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$URL_EXT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction jschecks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$JSCHECKS\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Javascript Scan\"\n\t\tif [ -s \".tmp/url_extract_js.txt\" ]; then\n\t\t\tprintf \"${yellow} Running : Fetching Urls 1/5${reset}\\n\"\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tcat .tmp/url_extract_js.txt | subjs -ua \"Mozilla/5.0 (X11; Linux x86_64; rv:72.0) Gecko/20100101 Firefox/72.0\" -c 40 | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/subjslinks.txt\n\t\t\telse\n\t\t\t\taxiom-scan .tmp/url_extract_js.txt -m subjs -o .tmp/subjslinks.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/subjslinks.txt\" ] && cat .tmp/subjslinks.txt | egrep -iv \"\\.(eot|jpg|jpeg|gif|css|tif|tiff|png|ttf|otf|woff|woff2|ico|pdf|svg|txt|js)\" | anew -q js/nojs_links.txt\n\t\t\t[ -s \".tmp/subjslinks.txt\" ] && cat .tmp/subjslinks.txt | grep -iE \"\\.js($|\\?)\" | anew -q .tmp/url_extract_js.txt\n\t\t\tcat .tmp/url_extract_js.txt | python3 $tools/urless/urless/urless.py | anew -q js/url_extract_js.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tprintf \"${yellow} Running : Resolving JS Urls 2/5${reset}\\n\"\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\t[ -s \"js/url_extract_js.txt\" ] && cat js/url_extract_js.txt | httpx -follow-redirects -random-agent -silent -timeout $HTTPX_TIMEOUT -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -status-code -content-type -retries 2 -no-color | grep \"[200]\" | grep \"javascript\" | cut -d ' ' -f1 | anew -q js/js_livelinks.txt\n\t\t\telse\n\t\t\t\t[ -s \"js/url_extract_js.txt\" ] && axiom-scan js/url_extract_js.txt -m httpx -follow-host-redirects -H \\\"${HEADER}\\\" -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -content-type -retries 2 -no-color -o .tmp/js_livelinks.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t[ -s \".tmp/js_livelinks.txt\" ] && cat .tmp/js_livelinks.txt | anew .tmp/web_full_info.txt | grep \"[200]\" | grep \"javascript\" | cut -d ' ' -f1 | anew -q js/js_livelinks.txt\n\t\t\tfi\n\t\t\tprintf \"${yellow} Running : Gathering endpoints 3/5${reset}\\n\"\n\t\t\t[ -s \"js/js_livelinks.txt\" ] && python3 $tools/xnLinkFinder/xnLinkFinder.py -i js/js_livelinks.txt -sf subdomains/subdomains.txt -d $XNLINKFINDER_DEPTH -o .tmp/js_endpoints.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t[ -s \"parameters.txt\" ] && rm -f parameters.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tif [ -s \".tmp/js_endpoints.txt\" ]; then\n\t\t\t\tsed -i '/^\\//!d' .tmp/js_endpoints.txt\n\t\t\t\tcat .tmp/js_endpoints.txt | anew -q js/js_endpoints.txt\n\t\t\tfi\n\t\t\tprintf \"${yellow} Running : Gathering secrets 4/5${reset}\\n\"\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\t[ -s \"js/js_livelinks.txt\" ] && cat js/js_livelinks.txt | Mantra -ua ${HEADER} -s | anew -q js/js_secrets.txt\n\t\t\telse\n\t\t\t\t[ -s \"js/js_livelinks.txt\" ] && axiom-scan js/js_livelinks.txt -m mantra -ua \\\"${HEADER}\\\" -s -o js/js_secrets.txt $AXIOM_EXTRA_ARGS &>/dev/null\n\t\t\tfi\n\t\t\t[ -s \"js/js_secrets.txt\" ] && sed -r \"s/\\x1B\\[([0-9]{1,3}(;[0-9]{1,2};?)?)?[mGK]//g\" -i js/js_secrets.txt\n\t\t\tprintf \"${yellow} Running : Building wordlist 5/5${reset}\\n\"\n\t\t\t[ -s \"js/js_livelinks.txt\" ] && interlace -tL js/js_livelinks.txt -threads ${INTERLACE_THREADS}  -c \"python3 $tools/getjswords.py '_target_' | anew -q webs/dict_words.txt\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\tend_func \"Results are saved in $domain/js folder\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"No JS urls found for $domain, function skipped\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$JSCHECKS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction wordlist_gen(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WORDLIST\" = true ];\tthen\n\t\tstart_func ${FUNCNAME[0]} \"Wordlist generation\"\n\t\tif [ -s \".tmp/url_extract_tmp.txt\" ]; then\n\t\t\tcat .tmp/url_extract_tmp.txt | unfurl -u keys 2>>\"$LOGFILE\" | sed 's/[][]//g' | sed 's/[#]//g' | sed 's/[}{]//g' | anew -q webs/dict_params.txt\n\t\t\tcat .tmp/url_extract_tmp.txt | unfurl -u values 2>>\"$LOGFILE\" | sed 's/[][]//g' | sed 's/[#]//g' | sed 's/[}{]//g' | anew -q webs/dict_values.txt\n\t\t\tcat .tmp/url_extract_tmp.txt | tr \"[:punct:]\" \"\\n\" | anew -q webs/dict_words.txt\n\t\tfi\n\t\t[ -s \".tmp/js_endpoints.txt\" ] && cat .tmp/js_endpoints.txt | unfurl -u format %s://%d%p 2>>\"$LOGFILE\" | anew -q webs/all_paths.txt\n\t\t[ -s \".tmp/url_extract_tmp.txt\" ] && cat .tmp/url_extract_tmp.txt | unfurl -u format %s://%d%p 2>>\"$LOGFILE\" | anew -q webs/all_paths.txt\n\t\tend_func \"Results are saved in $domain/webs/dict_[words|paths].txt\" ${FUNCNAME[0]}\n\t\tif [ \"$PROXY\" = true ] && [ -n \"$proxy_url\" ] && [[ $(cat webs/all_paths.txt | wc -l) -le $DEEP_LIMIT2 ]]; then\n\t\t\tnotification \"Sending urls to proxy\" info\n\t\t\tffuf -mc all -w webs/all_paths.txt -u FUZZ -replay-proxy $proxy_url 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\telse\n\t\tif [ \"$WORDLIST\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction wordlist_gen_roboxtractor(){\n\tif  { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$ROBOTSWORDLIST\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Robots wordlist generation\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ -s \".tmp/webs_all.txt\" ]; then\n\t\t\tcat .tmp/webs_all.txt | roboxtractor -m 1 -wb 2>/dev/null | anew -q webs/robots_wordlist.txt\n\t\tfi\n\t\tend_func \"Results are saved in $domain/webs/robots_wordlist.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$ROBOTSWORDLIST\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction password_dict(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$PASSWORD_DICT\" = true ];\tthen\n\t\tstart_func ${FUNCNAME[0]} \"Password dictionary generation\"\n\t\tword=${domain%%.*}\n\t\tpython3 $tools/pydictor/pydictor.py -extend $word --leet 0 1 2 11 21 --len ${PASSWORD_MIN_LENGTH} ${PASSWORD_MAX_LENGTH} -o webs/password_dict.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tend_func \"Results are saved in $domain/webs/password_dict.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$PASSWORD_DICT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n######################################### VULNERABILITIES #####################################################\n###############################################################################################################\n\nfunction brokenLinks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$BROKENLINKS\" = true ] ; then\n\t\tstart_func ${FUNCNAME[0]} \"Broken links checks\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\tif [ ! -s \".tmp/katana.txt\" ]; then\n\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t[ -s \".tmp/webs_all.txt\" ] && katana -silent -list .tmp/webs_all.txt -jc -kf all -c $KATANA_THREADS -d 3 -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\telse\n\t\t\t\t\t[ -s \".tmp/webs_all.txt\" ] && katana -silent -list .tmp/webs_all.txt -jc -kf all -c $KATANA_THREADS -d 2 -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\tfi\n\t\t\t[ -s \".tmp/katana.txt\" ] && sed -i '/^.\\{2048\\}./d' .tmp/katana.txt\n\t\telse\n\t\t\tif [ ! -s \".tmp/katana.txt\" ]; then\n\t\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\t\t[ -s \".tmp/webs_all.txt\" ] && axiom-scan .tmp/webs_all.txt -m katana -jc -kf all -d 3 -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\telse\n\t\t\t\t\t[ -s \".tmp/webs_all.txt\" ] && axiom-scan .tmp/webs_all.txt -m katana -jc -kf all -d 2 -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\t\t[ -s \".tmp/katana.txt\" ] && sed -i '/^.\\{2048\\}./d' .tmp/katana.txt\n\t\t\tfi\n\t\tfi\n\t\t[ -s \".tmp/katana.txt\" ] && cat .tmp/katana.txt | sort -u | httpx -follow-redirects -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -no-color | grep \"\\[4\" | cut -d ' ' -f1 | anew -q .tmp/brokenLinks_total.txt\n\t\tNUMOFLINES=$(cat .tmp/brokenLinks_total.txt 2>>\"$LOGFILE\" | anew vulns/brokenLinks.txt | sed '/^$/d' | wc -l)\n\t\tnotification \"${NUMOFLINES} new broken links found\" info\n\t\tend_func \"Results are saved in vulns/brokenLinks.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$BROKENLINKS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction xss(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$XSS\" = true ] && [ -s \"gf/xss.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"XSS Analysis\"\n\t\t[ -s \"gf/xss.txt\" ] && cat gf/xss.txt | qsreplace FUZZ | sed '/FUZZ/!d' | Gxss -c 100 -p Xss | qsreplace FUZZ | sed '/FUZZ/!d' | anew -q .tmp/xss_reflected.txt\n\t\tif [ ! \"$AXIOM\" = true ]; then\t\t\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tif [ -n \"$XSS_SERVER\" ]; then\n\t\t\t\t\t[ -s \".tmp/xss_reflected.txt\" ] && cat .tmp/xss_reflected.txt | dalfox pipe --silence --no-color --no-spinner --only-poc r --ignore-return 302,404,403 --skip-bav -b ${XSS_SERVER} -w $DALFOX_THREADS 2>>\"$LOGFILE\" | anew -q vulns/xss.txt\n\t\t\t\telse\n\t\t\t\t\tprintf \"${yellow}\\n No XSS_SERVER defined, blind xss skipped\\n\\n\"\n\t\t\t\t\t[ -s \".tmp/xss_reflected.txt\" ] && cat .tmp/xss_reflected.txt | dalfox pipe --silence --no-color --no-spinner --only-poc r --ignore-return 302,404,403 --skip-bav -w $DALFOX_THREADS 2>>\"$LOGFILE\" | anew -q vulns/xss.txt\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tif [[ $(cat .tmp/xss_reflected.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t\t\tif [ -n \"$XSS_SERVER\" ]; then\n\t\t\t\t\t\tcat .tmp/xss_reflected.txt | dalfox pipe --silence --no-color --no-spinner --skip-bav --skip-mining-dom --skip-mining-dict --only-poc r --ignore-return 302,404,403 -b ${XSS_SERVER} -w $DALFOX_THREADS 2>>\"$LOGFILE\" | anew -q vulns/xss.txt\n\t\t\t\t\telse\n\t\t\t\t\t\tprintf \"${yellow}\\n No XSS_SERVER defined, blind xss skipped\\n\\n\"\n\t\t\t\t\t\tcat .tmp/xss_reflected.txt | dalfox pipe --silence --no-color --no-spinner --skip-bav --skip-mining-dom --skip-mining-dict --only-poc r --ignore-return 302,404,403 -w $DALFOX_THREADS 2>>\"$LOGFILE\" | anew -q vulns/xss.txt\n\t\t\t\t\tfi\n\t\t\t\telse\n\t\t\t\t\tprintf \"${bred} Skipping XSS: Too many URLs to test, try with --deep flag${reset}\\n\"\n\t\t\t\tfi\n\t\t\tfi\n\t\telse\n\t\t\tif [ \"$DEEP\" = true ]; then\n\t\t\t\tif [ -n \"$XSS_SERVER\" ]; then\n\t\t\t\t\t[ -s \".tmp/xss_reflected.txt\" ] && axiom-scan .tmp/xss_reflected.txt -m dalfox --skip-bav -b ${XSS_SERVER} -w $DALFOX_THREADS -o vulns/xss.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\telse\n\t\t\t\t\tprintf \"${yellow}\\n No XSS_SERVER defined, blind xss skipped\\n\\n\"\n\t\t\t\t\t[ -s \".tmp/xss_reflected.txt\" ] && axiom-scan .tmp/xss_reflected.txt -m dalfox --skip-bav -w $DALFOX_THREADS -o vulns/xss.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tif [[ $(cat .tmp/xss_reflected.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t\t\tif [ -n \"$XSS_SERVER\" ]; then\n\t\t\t\t\t\taxiom-scan .tmp/xss_reflected.txt -m dalfox --skip-bav --skip-grepping --skip-mining-all --skip-mining-dict -b ${XSS_SERVER} -w $DALFOX_THREADS -o vulns/xss.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\telse\n\t\t\t\t\t\tprintf \"${yellow}\\n No XSS_SERVER defined, blind xss skipped\\n\\n\"\n\t\t\t\t\t\taxiom-scan .tmp/xss_reflected.txt -m dalfox --skip-bav --skip-grepping --skip-mining-all --skip-mining-dict -w $DALFOX_THREADS -o vulns/xss.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t\tfi\n\t\t\t\telse\n\t\t\t\t\tprintf \"${bred} Skipping XSS: Too many URLs to test, try with --deep flag${reset}\\n\"\n\t\t\t\tfi\n\t\t\tfi\n\t\tfi\n\t\tend_func \"Results are saved in vulns/xss.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$XSS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/xss.txt\" ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to XSS ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction cors(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$CORS\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"CORS Scan\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\t[ -s \".tmp/webs_all.txt\" ] && python3 $tools/Corsy/corsy.py -i .tmp/webs_all.txt -o vulns/cors.txt 2>>\"$LOGFILE\" >/dev/null\n\t\tend_func \"Results are saved in vulns/cors.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$CORS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction open_redirect(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$OPEN_REDIRECT\" = true ] && [ -s \"gf/redirect.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Open redirects checks\"\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat gf/redirect.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tcat gf/redirect.txt | qsreplace FUZZ | sed '/FUZZ/!d' | anew -q .tmp/tmp_redirect.txt\n\t\t\tpython3 $tools/Oralyzer/oralyzer.py -l .tmp/tmp_redirect.txt -p $tools/Oralyzer/payloads.txt > vulns/redirect.txt\n\t\t\tsed -r -i \"s/\\x1B\\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g\" vulns/redirect.txt\n\t\t\tend_func \"Results are saved in vulns/redirect.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping Open redirects: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t\tfi\n\telse\n\t\tif [ \"$OPEN_REDIRECT\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/redirect.txt\" ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to Open Redirect ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction ssrf_checks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SSRF_CHECKS\" = true ] && [ -s \"gf/ssrf.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"SSRF checks\"\n\t\tif [ -z \"$COLLAB_SERVER\" ]; then\n\t\t\tinteractsh-client &>.tmp/ssrf_callback.txt &\n\t\t\tsleep 2\n\t\t\tCOLLAB_SERVER_FIX=\"FFUFHASH.$(cat .tmp/ssrf_callback.txt | tail -n1 | cut -c 16-)\"\n\t\t\tCOLLAB_SERVER_URL=\"http://$COLLAB_SERVER_FIX\"\n\t\t\tINTERACT=true\n\t\telse\n\t\t\tCOLLAB_SERVER_FIX=\"FFUFHASH.$(echo ${COLLAB_SERVER} | sed -r \"s/https?:\\/\\///\")\"\n\t\t\tINTERACT=false\n\t\tfi\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat gf/ssrf.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tcat gf/ssrf.txt | qsreplace ${COLLAB_SERVER_FIX} | anew -q .tmp/tmp_ssrf.txt\n\t\t\tcat gf/ssrf.txt | qsreplace ${COLLAB_SERVER_URL} | anew -q .tmp/tmp_ssrf.txt\n\t\t\tffuf -v -H \"${HEADER}\" -t $FFUF_THREADS -rate $FFUF_RATELIMIT -w .tmp/tmp_ssrf.txt -u FUZZ 2>/dev/null | grep \"URL\" | sed 's/| URL | //' | anew -q vulns/ssrf_requested_url.txt\n\t\t\tffuf -v -w .tmp/tmp_ssrf.txt:W1,$tools/headers_inject.txt:W2 -H \"${HEADER}\" -H \"W2: ${COLLAB_SERVER_FIX}\" -t $FFUF_THREADS -rate $FFUF_RATELIMIT -u W1 2>/dev/null | anew -q vulns/ssrf_requested_headers.txt\n\t\t\tffuf -v -w .tmp/tmp_ssrf.txt:W1,$tools/headers_inject.txt:W2 -H \"${HEADER}\" -H \"W2: ${COLLAB_SERVER_URL}\" -t $FFUF_THREADS -rate $FFUF_RATELIMIT -u W1 2>/dev/null | anew -q vulns/ssrf_requested_headers.txt\n\t\t\tsleep 5\n\t\t\t[ -s \".tmp/ssrf_callback.txt\" ] && cat .tmp/ssrf_callback.txt | tail -n+11 | anew -q vulns/ssrf_callback.txt && NUMOFLINES=$(cat .tmp/ssrf_callback.txt | tail -n+12 | sed '/^$/d' | wc -l)\n\t\t\t[ \"$INTERACT\" = true ] && notification \"SSRF: ${NUMOFLINES} callbacks received\" info\n\t\t\tend_func \"Results are saved in vulns/ssrf_*\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping SSRF: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\t\tpkill -f interactsh-client &\n\telse\n\t\tif [ \"$SSRF_CHECKS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/ssrf.txt\" ]; then\n\t\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to SSRF ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction crlf_checks(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$CRLF_CHECKS\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"CRLF checks\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/webs_all.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tcrlfuzz -l .tmp/webs_all.txt -o vulns/crlf.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tend_func \"Results are saved in vulns/crlf.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping CRLF: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$CRLF_CHECKS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction lfi(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$LFI\" = true ] && [ -s \"gf/lfi.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"LFI checks\"\n\t\tif [ -s \"gf/lfi.txt\" ]; then\n\t\t\tcat gf/lfi.txt | qsreplace FUZZ | sed '/FUZZ/!d' | anew -q .tmp/tmp_lfi.txt\n\t\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/tmp_lfi.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t\tinterlace -tL .tmp/tmp_lfi.txt -threads ${INTERLACE_THREADS} -c \"ffuf -v -r -t ${FFUF_THREADS} -rate ${FFUF_RATELIMIT} -H \\\"${HEADER}\\\" -w ${lfi_wordlist} -u \\\"_target_\\\" -mr \\\"root:\\\" \" 2>/dev/null | grep \"URL\" | sed 's/| URL | //' | anew -q vulns/lfi.txt\n\t\t\t\tend_func \"Results are saved in vulns/lfi.txt\" ${FUNCNAME[0]}\n\t\t\telse\n\t\t\t\tend_func \"Skipping LFI: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\t\tfi\n\t\tfi\n\telse\n\t\tif [ \"$LFI\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/lfi.txt\" ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to LFI ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction ssti(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SSTI\" = true ] && [ -s \"gf/ssti.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"SSTI checks\"\n\t\tif [ -s \"gf/ssti.txt\" ]; then\n\t\t\tcat gf/ssti.txt | qsreplace FUZZ | sed '/FUZZ/!d'  | anew -q .tmp/tmp_ssti.txt\n\t\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/tmp_ssti.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t\tinterlace -tL .tmp/tmp_ssti.txt -threads ${INTERLACE_THREADS} -c \"ffuf -v -r -t ${FFUF_THREADS} -rate ${FFUF_RATELIMIT} -H \\\"${HEADER}\\\" -w ${ssti_wordlist} -u \\\"_target_\\\" -mr \\\"ssti49\\\" \" 2>/dev/null | grep \"URL\" | sed 's/| URL | //' | anew -q vulns/ssti.txt\n\t\t\t\tend_func \"Results are saved in vulns/ssti.txt\" ${FUNCNAME[0]}\n\t\t\telse\n\t\t\t\tend_func \"Skipping SSTI: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\t\tfi\n\t\tfi\n\telse\n\t\tif [ \"$SSTI\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/ssti.txt\" ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to SSTI ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction sqli(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SQLI\" = true ] && [ -s \"gf/sqli.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"SQLi checks\"\n\n\t\tcat gf/sqli.txt | qsreplace FUZZ | sed '/FUZZ/!d' | anew -q .tmp/tmp_sqli.txt\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/tmp_sqli.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tif [ \"$SQLMAP\" = true ];then\n\t\t\t\tpython3 $tools/sqlmap/sqlmap.py -m .tmp/tmp_sqli.txt -b -o --smart --batch --disable-coloring --random-agent --output-dir=vulns/sqlmap 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\tif [ \"$GHAURI\" = true ];then\n\t\t\t\tinterlace -tL .tmp/tmp_sqli.txt -threads ${INTERLACE_THREADS} -c \"ghauri -u _target_ --batch -H \\\"${HEADER}\\\" --force-ssl >> vulns/ghauri_log.txt\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\tend_func \"Results are saved in vulns/sqlmap folder\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping SQLi: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$SQLI\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/sqli.txt\" ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to SQLi ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction test_ssl(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$TEST_SSL\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"SSL Test\"\n\t\t$tools/testssl.sh/testssl.sh --quiet --color 0 -U -iL hosts/ips.txt 2>>\"$LOGFILE\" > vulns/testssl.txt\n\t\tend_func \"Results are saved in vulns/testssl.txt\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$TEST_SSL\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction spraying(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SPRAY\" = true ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Password spraying\"\n\t\tcd \"$tools/brutespray\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tpython3 brutespray.py --file $dir/hosts/portscan_active.gnmap --threads $BRUTESPRAY_THREADS --hosts $BRUTESPRAY_CONCURRENCE -o $dir/vulns/brutespray 2>>\"$LOGFILE\" >/dev/null\n\t\tcd \"$dir\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tend_func \"Results are saved in vulns/brutespray folder\" ${FUNCNAME[0]}\n\telse\n\t\tif [ \"$SPRAY\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction command_injection(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$COMM_INJ\" = true ] && [ -s \"gf/rce.txt\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Command Injection checks\"\n\t\t[ -s \"gf/rce.txt\" ] && cat gf/rce.txt | qsreplace FUZZ | sed '/FUZZ/!d'  | anew -q .tmp/tmp_rce.txt\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/tmp_rce.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t[ -s \".tmp/tmp_rce.txt\" ] && python3 $tools/commix/commix.py --batch -m .tmp/tmp_rce.txt --output-dir vulns/command_injection.txt 2>>\"$LOGFILE\" >/dev/null\n\t\t\tend_func \"Results are saved in vulns/command_injection folder\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping Command injection: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$COMM_INJ\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telif [ ! -s \"gf/rce.txt\" ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} No URLs potentially vulnerables to Command Injection ${reset}\\n\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction 4xxbypass(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$BYPASSER4XX\" = true ]; then\n\t\tif [[ $(cat fuzzing/fuzzing_full.txt 2>/dev/null | grep -E '^4' | grep -Ev '^404' | cut -d ' ' -f3 | wc -l) -le 1000 ]] || [ \"$DEEP\" = true ]; then\n\t\t\tstart_func \"403 bypass\"\n\t\t\tcat $dir/fuzzing/fuzzing_full.txt 2>/dev/null | grep -E '^4' | grep -Ev '^404' | cut -d ' ' -f3 > $dir/.tmp/403test.txt\n\t\t\tcd \"$tools/byp4xx\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\tbyp4xx -threads $BYP4XX_THREADS $dir/.tmp/403test.txt > $dir/.tmp/byp4xx.txt\n\t\t\tcd \"$dir\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\t[ -s \".tmp/byp4xx.txt\" ] && cat .tmp/byp4xx.txt | anew -q vulns/byp4xx.txt\n\t\t\tend_func \"Results are saved in vulns/byp4xx.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tnotification \"Too many urls to bypass, skipping\" warn\n\t\tfi\n\telse\n\t\tif [ \"$BYPASSER4XX\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction prototype_pollution(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$PROTO_POLLUTION\" = true ] ; then\n\t\tstart_func ${FUNCNAME[0]} \"Prototype Pollution checks\"\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat webs/url_extract.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\t[ -s \"webs/url_extract.txt\" ] && ppfuzz -l webs/url_extract.txt -c $PPFUZZ_THREADS 2>/dev/null | anew -q .tmp/prototype_pollution.txt\n\t\t\t[ -s \".tmp/prototype_pollution.txt\" ] && cat .tmp/prototype_pollution.txt | sed -e '1,8d' | sed '/^\\[ERR/d' | anew -q vulns/prototype_pollution.txt\n\t\t\tend_func \"Results are saved in vulns/prototype_pollution.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping Prototype Pollution: Too many URLs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$PROTO_POLLUTION\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction smuggling(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$SMUGGLING\" = true ] ; then\n\t\tstart_func ${FUNCNAME[0]} \"HTTP Request Smuggling checks\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/webs_all.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tcd \"$tools/smuggler\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\tcat $dir/.tmp/webs_all.txt | python3 smuggler.py -q --no-color 2>/dev/null | anew -q $dir/.tmp/smuggling.txt\n\t\t\tcd \"$dir\" || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\t[ -s \".tmp/smuggling.txt\" ] && cat .tmp/smuggling.txt | anew -q vulns/smuggling.txt\n\t\t\tend_func \"Results are saved in vulns/smuggling.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Skipping Prototype Pollution: Too many webs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$SMUGGLING\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction webcache(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$WEBCACHE\" = true ] ; then\n\t\tstart_func ${FUNCNAME[0]} \"Web Cache Poisoning checks\"\n\t\t[ ! -s \".tmp/webs_all.txt\" ] && cat webs/webs.txt webs/webs_uncommon_ports.txt 2>/dev/null | anew -q .tmp/webs_all.txt\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat .tmp/webs_all.txt | wc -l) -le $DEEP_LIMIT ]]; then\n\t\t\tcd \"$tools/Web-Cache-Vulnerability-Scanner\" || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\tWeb-Cache-Vulnerability-Scanner -u file:$dir/.tmp/webs_all.txt -v 0 2>/dev/null | anew -q $dir/.tmp/webcache.txt\n\t\t\tcd \"$dir\" || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\t[ -s \".tmp/webcache.txt\" ] && cat .tmp/webcache.txt | anew -q vulns/webcache.txt\n\t\t\tend_func \"Results are saved in vulns/webcache.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Web Cache Poisoning: Too many webs to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$WEBCACHE\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\nfunction fuzzparams(){\n\tif { [ ! -f \"$called_fn_dir/.${FUNCNAME[0]}\" ] || [ \"$DIFF\" = true ]; } && [ \"$FUZZPARAMS\" = true ] ; then\n\t\tstart_func ${FUNCNAME[0]} \"Fuzzing params values checks\"\n\t\tif [ \"$DEEP\" = true ] || [[ $(cat webs/url_extract.txt | wc -l) -le $DEEP_LIMIT2 ]]; then\n\t\t\tif [ ! \"$AXIOM\" = true ]; then\n\t\t\t\tnuclei -update 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tgit -C $tools/fuzzing-templates pull\n\t\t\t\tcat webs/url_extract.txt 2>/dev/null | nuclei -silent -retries 3 -rl $NUCLEI_RATELIMIT -t $tools/fuzzing-templates -o .tmp/fuzzparams.txt\n\t\t\telse\n\t\t\t\taxiom-exec \"git clone https://github.com/projectdiscovery/fuzzing-templates /home/op/fuzzing-templates\" &>/dev/null\n\t\t\t\taxiom-scan webs/url_extract.txt -m nuclei -nh -retries 3 -w /home/op/fuzzing-templates -rl $NUCLEI_RATELIMIT -o .tmp/fuzzparams.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\t\t\t[ -s \".tmp/fuzzparams.txt\" ] && cat .tmp/fuzzparams.txt | anew -q vulns/fuzzparams.txt\n\t\t\tend_func \"Results are saved in vulns/fuzzparams.txt\" ${FUNCNAME[0]}\n\t\telse\n\t\t\tend_func \"Fuzzing params values: Too many entries to test, try with --deep flag\" ${FUNCNAME[0]}\n\t\tfi\n\telse\n\t\tif [ \"$FUZZPARAMS\" = false ]; then\n\t\t\tprintf \"\\n${yellow} ${FUNCNAME[0]} skipped in this mode or defined in reconftw.cfg ${reset}\\n\"\n\t\telse\n\t\t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n\t\tfi\n\tfi\n}\n\n###############################################################################################################\n########################################## OPTIONS & MGMT #####################################################\n###############################################################################################################\n\nfunction deleteOutScoped(){\n\tif [ -s \"$1\" ]; then\n\t\tcat $1 | while read outscoped\n\t\tdo\n\t\t\tif grep -q \"^[*]\" <<< $outscoped\n\t\t\tthen\n\t\t\t\toutscoped=\"${outscoped:1}\"\n\t\t\t\tsed -i /\"$outscoped$\"/d $2\n\t\t\telse\n\t\t\t\tsed -i /$outscoped/d $2\n\t\t\tfi\n\t\tdone\n\tfi\n}\n\nfunction getElapsedTime {\n\truntime=\"\"\n\tlocal T=$2-$1\n\tlocal D=$((T/60/60/24))\n\tlocal H=$((T/60/60%24))\n\tlocal M=$((T/60%60))\n\tlocal S=$((T%60))\n\t(( $D > 0 )) && runtime=\"$runtime$D days, \"\n\t(( $H > 0 )) && runtime=\"$runtime$H hours, \"\n\t(( $M > 0 )) && runtime=\"$runtime$M minutes, \"\n\truntime=\"$runtime$S seconds.\"\n}\n\nfunction zipSnedOutputFolder {\n\tzip_name1=$(date +\"%Y_%m_%d-%H.%M.%S\")\n\tzip_name=\"${zip_name1}_${domain}.zip\" 2>>\"$LOGFILE\" >/dev/null\n\t(cd \"$dir\" && zip -r \"$zip_name\" .)\n\n\techo \"Sending zip file \"${dir}/${zip_name}\"\"\n\tif [ -s \"${dir}/$zip_name\" ]; then\n\t\tsendToNotify \"$dir/$zip_name\"\n\t\trm -f \"${dir}/$zip_name\"\n\telse\n\t\tnotification \"No Zip file to send\" warn\n\tfi\n}\n\nfunction isAsciiText {\n\tIS_ASCII=\"False\";\n\tif [[ $(file $1 | grep -o 'ASCII text$') == \"ASCII text\" ]]; then\n\t\tIS_ASCII=\"True\";\n\telse\n\t\tIS_ASCII=\"False\";\n\tfi\n}\n\nfunction output(){\n\tmkdir -p $dir_output\n\tcp -r $dir $dir_output\n\t[[ \"$(dirname $dir)\" != \"$dir_output\" ]] && rm -rf \"$dir\"\n}\n\nfunction remove_big_files(){\n\teval rm -rf .tmp/gotator*.txt 2>>\"$LOGFILE\"\n\teval rm -rf .tmp/brute_recursive_wordlist.txt 2>>\"$LOGFILE\"\n\teval rm -rf .tmp/subs_dns_tko.txt  2>>\"$LOGFILE\"\n\teval rm -rf .tmp/subs_no_resolved.txt .tmp/subdomains_dns.txt .tmp/brute_dns_tko.txt .tmp/scrap_subs.txt .tmp/analytics_subs_clean.txt .tmp/gotator1.txt .tmp/gotator2.txt .tmp/passive_recursive.txt .tmp/brute_recursive_wordlist.txt .tmp/gotator1_recursive.txt .tmp/gotator2_recursive.txt 2>>\"$LOGFILE\"\n\teval find .tmp -type f -size +200M -exec rm -f {} + 2>>\"$LOGFILE\"\n}\n\nfunction notification(){\n\tif [ -n \"$1\" ] && [ -n \"$2\" ]; then\n\t\tcase $2 in\n\t\t\tinfo)\n\t\t\t\ttext=\"\\n${bblue} ${1} ${reset}\"\n\t\t\t\tprintf \"${text}\\n\" && printf \"${text} - ${domain}\\n\" | $NOTIFY\n\t\t\t;;\n\t\t\twarn)\n\t\t\t\ttext=\"\\n${yellow} ${1} ${reset}\"\n\t\t\t\tprintf \"${text}\\n\" && printf \"${text} - ${domain}\\n\" | $NOTIFY\n\t\t\t;;\n\t\t\terror)\n\t\t\t\ttext=\"\\n${bred} ${1} ${reset}\"\n\t\t\t\tprintf \"${text}\\n\" && printf \"${text} - ${domain}\\n\" | $NOTIFY\n\t\t\t;;\n\t\t\tgood)\n\t\t\t\ttext=\"\\n${bgreen} ${1} ${reset}\"\n\t\t\t\tprintf \"${text}\\n\" && printf \"${text} - ${domain}\\n\" | $NOTIFY\n\t\t\t;;\n\t\tesac\n\tfi\n}\n\nfunction transfer { \n\tif [ $# -eq 0 ]; then \n\t\techo \"No arguments specified.\\nUsage:\\n transfer <file|directory>\\n ... | transfer <file_name>\">&2\n\t\treturn 1\n\tfi\n\tif tty -s; then \n\t\tfile=\"$1\"\n\t\tfile_name=$(basename \"$file\")\n\t\tif [ ! -e \"$file\" ]; then \n\t\t\techo \"$file: No such file or directory\">&2\n\t\t\treturn 1\n\t\tfi\n\t\tif [ -d \"$file\" ]; then\n\t\t\tfile_name=\"$file_name.zip\"\n\t\t\t(cd \"$file\"&&zip -r -q - .) | curl --progress-bar --upload-file \"-\" \"https://transfer.sh/$file_name\" | tee /dev/null\n\t\telse \n\t\t\tcat \"$file\" | curl --progress-bar --upload-file \"-\" \"https://transfer.sh/$file_name\" | tee /dev/null\n\t\tfi\n\telse\n\t\tfile_name=$1\n\t\tcurl --progress-bar --upload-file \"-\" \"https://transfer.sh/$file_name\" | tee /dev/null\n\tfi\n}\n\nfunction sendToNotify {\n\tif [[ -z \"$1\" ]]; then\n\t\tprintf \"\\n${yellow} no file provided to send ${reset}\\n\"\n\telse\n\t\tif [[ -z \"$NOTIFY_CONFIG\" ]]; then\n\t\t\tNOTIFY_CONFIG=~/.config/notify/provider-config.yaml\n\t\tfi\n\t\tif [ -n \"$(find \"${1}\" -prune -size +8000000c)\" ]; then\n    \t\tprintf '%s is larger than 8MB, sending over transfer.sh\\n' \"${1}\"\n\t\t\ttransfer \"${1}\" | notify\n\t\t\treturn 0\n\t\tfi\n\t\tif grep -q '^ telegram\\|^telegram\\|^    telegram' $NOTIFY_CONFIG ; then\n\t\t\tnotification \"Sending ${domain} data over Telegram\" info\n\t\t\ttelegram_chat_id=$(cat ${NOTIFY_CONFIG} | grep '^    telegram_chat_id\\|^telegram_chat_id\\|^    telegram_chat_id' | xargs | cut -d' ' -f2)\n\t\t\ttelegram_key=$(cat ${NOTIFY_CONFIG} | grep '^    telegram_api_key\\|^telegram_api_key\\|^    telegram_apikey' | xargs | cut -d' ' -f2 )\n\t\t\tcurl -F document=@${1} \"https://api.telegram.org/bot${telegram_key}/sendDocument?chat_id=${telegram_chat_id}\" 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tif grep -q '^ discord\\|^discord\\|^    discord' $NOTIFY_CONFIG ; then\n\t\t\tnotification \"Sending ${domain} data over Discord\" info\n\t\t\tdiscord_url=$(cat ${NOTIFY_CONFIG} | grep '^ discord_webhook_url\\|^discord_webhook_url\\|^    discord_webhook_url' | xargs | cut -d' ' -f2)\n\t\t\tcurl -v -i -H \"Accept: application/json\" -H \"Content-Type: multipart/form-data\" -X POST -F file1=@${1} $discord_url 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\t\tif [[ -n \"$slack_channel\" ]] && [[ -n \"$slack_auth\" ]]; then\n\t\t\tnotification \"Sending ${domain} data over Slack\" info\n\t\t\tcurl -F file=@${1} -F \"initial_comment=reconftw zip file\" -F channels=${slack_channel} -H \"Authorization: Bearer ${slack_auth}\" https://slack.com/api/files.upload 2>>\"$LOGFILE\" >/dev/null\n\t\tfi\n\tfi\n}\n\nfunction start_func(){\n\tprintf \"${bgreen}#######################################################################\"\n\tnotification \"${2}\" info\n\techo \"[ $(date +\"%F %T\") ] Start function : ${1} \" >> \"${LOGFILE}\"\n\tstart=$(date +%s)\n}\n\nfunction end_func(){\n\ttouch $called_fn_dir/.${2}\n\tend=$(date +%s)\n\tgetElapsedTime $start $end\n\tnotification \"${2} Finished in ${runtime}\" info\n\techo \"[ $(date +\"%F %T\") ] End function : ${2} \" >> \"${LOGFILE}\"\n\tprintf \"${bblue} ${1} ${reset}\\n\"\n\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n}\n\nfunction start_subfunc(){\n\tnotification \"${2}\" warn\n\techo \"[ $(date +\"%F %T\") ] Start subfunction : ${1} \" >> \"${LOGFILE}\"\n\tstart_sub=$(date +%s)\n}\n\nfunction end_subfunc(){\n\ttouch $called_fn_dir/.${2}\n\tend_sub=$(date +%s)\n\tgetElapsedTime $start_sub $end_sub\n\tnotification \"${1} in ${runtime}\" good\n\techo \"[ $(date +\"%F %T\") ] End subfunction : ${1} \" >> \"${LOGFILE}\"\n}\n\nfunction check_inscope(){\n\tcat $1 | inscope > $1_tmp && cp $1_tmp $1 && rm -f $1_tmp\n}\n\nfunction resolvers_update(){\n\tif [ \"$generate_resolvers\" = true ]; then\n\t\tif [ ! \"$AXIOM\" = true ]; then\t\n\t\t\tif [ ! -s \"$resolvers\" ] || [[ $(find \"$resolvers\" -mtime +1 -print) ]] ; then\n\t\t\t\tnotification \"Resolvers seem older than 1 day\\n Generating custom resolvers...\" warn\n\t\t\t\teval rm -f $resolvers 2>>\"$LOGFILE\"\n\t\t\t\tdnsvalidator -tL https://public-dns.info/nameservers.txt -threads $DNSVALIDATOR_THREADS -o $resolvers 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\tdnsvalidator -tL https://raw.githubusercontent.com/blechschmidt/massdns/master/lists/resolvers.txt -threads $DNSVALIDATOR_THREADS -o tmp_resolvers 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t[ -s \"tmp_resolvers\" ] && cat tmp_resolvers | anew -q $resolvers\n\t\t\t\t[ -s \"tmp_resolvers\" ] && rm -f tmp_resolvers 2>>\"$LOGFILE\" >/dev/null\n\t\t\t\t[ ! -s \"$resolvers\" ] && wget -q -O - ${resolvers_url} > $resolvers\n\t\t\t\t[ ! -s \"$resolvers_trusted\" ] && wget -q -O - ${resolvers_trusted_url} > $resolvers_trusted\n\t\t\t\tnotification \"Updated\\n\" good\n\t  \t\tfi\n\t\telse\n\t\t\tnotification \"Checking resolvers lists...\\n Accurate resolvers are the key to great results\\n This may take around 10 minutes if it's not updated\" warn\n\t\t\t# shellcheck disable=SC2016\n\t\t\taxiom-exec 'if [ $(find \"/home/op/lists/resolvers.txt\" -mtime +1 -print) ] || [ $(cat /home/op/lists/resolvers.txt | wc -l) -le 40 ] ; then dnsvalidator -tL https://public-dns.info/nameservers.txt -threads 200 -o /home/op/lists/resolvers.txt ; fi' &>/dev/null\n\t\t\taxiom-exec \"wget -q -O - ${resolvers_url} > /home/op/lists/resolvers.txt\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\taxiom-exec \"wget -q -O - ${resolvers_trusted_url} > /home/op/lists/resolvers_trusted.txt\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\tnotification \"Updated\\n\" good\n\t\tfi\n\t\tgenerate_resolvers=false\n\telse\n\t\n\t\tif  [ ! -s \"$resolvers\" ] || [[ $(find \"$resolvers\" -mtime +1 -print) ]] ; then\n\t\t\tnotification \"Resolvers seem older than 1 day\\n Downloading new resolvers...\" warn\n\t\t\twget -q -O - ${resolvers_url} > $resolvers\n\t\t\twget -q -O - ${resolvers_trusted_url} > $resolvers_trusted\n\t\t\tnotification \"Resolvers updated\\n\" good\n\t\tfi\n\tfi\n}\n\nfunction resolvers_update_quick_local(){\n\tif [ \"$update_resolvers\" = true ]; then\n\t\twget -q -O - ${resolvers_url} > $resolvers\n\t\twget -q -O - ${resolvers_trusted_url} > $resolvers_trusted\n\tfi\n}\n\nfunction resolvers_update_quick_axiom(){\n\taxiom-exec \"wget -q -O - ${resolvers_url} > /home/op/lists/resolvers.txt\" 2>>\"$LOGFILE\" >/dev/null\n\taxiom-exec \"wget -q -O - ${resolvers_trusted_url} > /home/op/lists/resolvers_trusted.txt\" 2>>\"$LOGFILE\" >/dev/null\n}\n\nfunction ipcidr_target(){\n\tIP_CIDR_REGEX='(((25[0-5]|2[0-4][0-9]|1?[0-9][0-9]?)\\.){3}(25[0-5]|2[0-4][0-9]|1?[0-9][0-9]?))(\\/([8-9]|[1-2][0-9]|3[0-2]))([^0-9.]|$)|(((25[0-5]|2[0-4][0-9]|1?[0-9][0-9]?)\\.){3}(25[0-5]|2[0-4][0-9]|1?[0-9][0-9]?)$)'\n\tif [[ $1 =~ ^$IP_CIDR_REGEX ]]; then\n\t\techo $1 | mapcidr -silent | anew -q target_reconftw_ipcidr.txt\n\t\tif [ -s \"./target_reconftw_ipcidr.txt\" ]; then \n\t\t\t[ \"$REVERSE_IP\" = true ] && cat ./target_reconftw_ipcidr.txt | hakip2host | cut -d' ' -f 3 | unfurl -u domains 2>/dev/null | sed -e 's/*\\.//' -e 's/\\.$//' -e '/\\./!d' | anew -q ./target_reconftw_ipcidr.txt\n\t\t\tif [[ $(cat ./target_reconftw_ipcidr.txt | wc -l) -eq 1 ]]; then\n\t\t\t\tdomain=$(cat ./target_reconftw_ipcidr.txt)\n\t\t\telif [[ $(cat ./target_reconftw_ipcidr.txt | wc -l) -gt 1 ]]; then\n\t\t\t\tunset domain\n\t\t\t\tlist=${PWD}/target_reconftw_ipcidr.txt\n\t\t\tfi\n\t\tfi\n\t\tif [ -n \"$2\" ]; then\n\t\t\tcat $list | anew -q $2\n\t\t\tsed -i '/\\/[0-9]*$/d' $2\n\t\tfi\n\tfi\n}\n\nfunction axiom_lauch(){\n\t# let's fire up a FLEET!\n\tif [ \"$AXIOM_FLEET_LAUNCH\" = true ] && [ -n \"$AXIOM_FLEET_NAME\" ] && [ -n \"$AXIOM_FLEET_COUNT\" ]; then\n\t\tstart_func ${FUNCNAME[0]} \"Launching our Axiom fleet\"\n\t\tpython3 -m pip install --upgrade linode-cli 2>>\"$LOGFILE\" >/dev/null\n\t\t# Check to see if we have a fleet already, if so, SKIP THIS!\n\t\tNUMOFNODES=$(timeout 30 axiom-ls | grep -c \"$AXIOM_FLEET_NAME\")\n\t\tif [[ $NUMOFNODES -ge $AXIOM_FLEET_COUNT ]]; then\n\t\t\taxiom-select \"$AXIOM_FLEET_NAME*\"\n\t\t\tend_func \"Axiom fleet $AXIOM_FLEET_NAME already has $NUMOFNODES instances\"\n\t\telse\n\t\t\tif [[ $NUMOFNODES -eq 0 ]]; then\n\t\t\t\tstartcount=$AXIOM_FLEET_COUNT\n\t\t\telse\n\t\t\t\tstartcount=$((AXIOM_FLEET_COUNT-NUMOFNODES))\n\t\t\tfi\n\t\t\tAXIOM_ARGS=\" -i $startcount\"\n\t\t\t# Temporarily disabled multiple axiom regions\n\t\t\t# [ -n \"$AXIOM_FLEET_REGIONS\" ] && axiom_args=\"$axiom_args --regions=\\\"$AXIOM_FLEET_REGIONS\\\" \"\n\n\t\t\techo \"axiom-fleet ${AXIOM_FLEET_NAME} ${AXIOM_ARGS}\"\n\t\t\taxiom-fleet ${AXIOM_FLEET_NAME} ${AXIOM_ARGS}\n\t\t\taxiom-select \"$AXIOM_FLEET_NAME*\"\n\t\t\tif [ -n \"$AXIOM_POST_START\" ]; then\n\t\t\t\teval \"$AXIOM_POST_START\" 2>>\"$LOGFILE\" >/dev/null\n\t\t\tfi\n\n\t\t\tNUMOFNODES=$(timeout 30 axiom-ls | grep -c \"$AXIOM_FLEET_NAME\" )\n\t\t\techo \"Axiom fleet $AXIOM_FLEET_NAME launched w/ $NUMOFNODES instances\" | $NOTIFY\n\t\t\tend_func \"Axiom fleet $AXIOM_FLEET_NAME launched w/ $NUMOFNODES instances\"\n\t\tfi\n\tfi\n}\n\nfunction axiom_shutdown(){\n\tif [ \"$AXIOM_FLEET_LAUNCH\" = true ] && [ \"$AXIOM_FLEET_SHUTDOWN\" = true ] && [ -n \"$AXIOM_FLEET_NAME\" ]; then\n\t\t#if [ \"$mode\" == \"subs_menu\" ] || [ \"$mode\" == \"list_recon\" ] || [ \"$mode\" == \"passive\" ] || [ \"$mode\" == \"all\" ]; then\n\t\tif [ \"$mode\" == \"subs_menu\" ] || [ \"$mode\" == \"passive\" ] || [ \"$mode\" == \"all\" ]; then\n\t\t\tnotification \"Automatic Axiom fleet shutdown is not enabled in this mode\" info\n\t\t\treturn\n\t\tfi\n\t\teval axiom-rm -f \"$AXIOM_FLEET_NAME*\"\n\t\techo \"Axiom fleet $AXIOM_FLEET_NAME shutdown\" | $NOTIFY\n\t\tnotification \"Axiom fleet $AXIOM_FLEET_NAME shutdown\" info\n\tfi\n}\n\nfunction axiom_selected(){\n\n\tif [[ ! $(axiom-ls | tail -n +2 | sed '$ d' | wc -l) -gt 0 ]]; then\n\t\tnotification \"\\n\\n${bred} No axiom instances running ${reset}\\n\\n\" error\n\t\texit\n\tfi\n\n\tif [[ ! $(cat ~/.axiom/selected.conf | sed '/^\\s*$/d' | wc -l) -gt 0 ]]; then\n\t\tnotification \"\\n\\n${bred} No axiom instances selected ${reset}\\n\\n\" error\n\t\texit\n\tfi\n}\n\nfunction start(){\n\n\tglobal_start=$(date +%s)\n\n\tif [ \"$NOTIFICATION\" = true ]; then\n\t\tNOTIFY=\"notify -silent\"\n\telse\n\t    NOTIFY=\"\"\n\tfi\n\t\n\tprintf \"\\n${bgreen}#######################################################################${reset}\"\n\tnotification \"Recon succesfully started on ${domain}\" good\n\t[ \"$SOFT_NOTIFICATION\" = true ] && echo \"Recon succesfully started on ${domain}\" | notify -silent\n\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tif [ \"$upgrade_before_running\" = true ]; then\n\t\t${SCRIPTPATH}/install.sh --tools\n\tfi\n\ttools_installed\n\n\t#[[ -n \"$domain\" ]] && ipcidr_target $domain\n\n\n\tif [ -z \"$domain\" ]; then\n\t\tif [ -n \"$list\" ]; then\n\t\t\tif [ -z \"$domain\" ]; then\n\t\t\t\tdomain=\"Multi\"\n\t\t\t\tdir=\"$SCRIPTPATH/Recon/$domain\"\n\t\t\t\tcalled_fn_dir=\"$dir\"/.called_fn\n\t\t\tfi\n\t\t\tif [[ \"$list\" = /* ]]; then\n\t\t\t\tinstall -D \"$list\" \"$dir\"/webs/webs.txt\n\t\t\telse\n\t\t\t\tinstall -D \"$SCRIPTPATH\"/\"$list\" \"$dir\"/webs/webs.txt\n\t\t\tfi\n\t\tfi\n\telse\n\t\tdir=\"$SCRIPTPATH/Recon/$domain\"\n\t\tcalled_fn_dir=\"$dir\"/.called_fn\n\tfi\n\n\tif [ -z \"$domain\" ]; then\n\t\tnotification \"\\n\\n${bred} No domain or list provided ${reset}\\n\\n\" error\n\t\texit\n\tfi\n\n\tif [ ! -d \"$called_fn_dir\" ]; then\n\t\tmkdir -p \"$called_fn_dir\"\n\tfi\n\tmkdir -p \"$dir\"\n\tcd \"$dir\"  || { echo \"Failed to cd directory in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tif [ \"$AXIOM\" = true ]; then\n\t\tif [ -n \"$domain\" ]; then\n\t\t\techo \"$domain\" | anew -q target.txt\n\t\t\tlist=\"${dir}/target.txt\"\n\t\tfi\n\tfi\n\tmkdir -p .tmp .log osint subdomains webs hosts vulns\n\n\tNOW=$(date +\"%F\")\n\tNOWT=$(date +\"%T\")\n\tLOGFILE=\"${dir}/.log/${NOW}_${NOWT}.txt\"\n\ttouch .log/${NOW}_${NOWT}.txt\n\techo \"Start ${NOW} ${NOWT}\" > \"${LOGFILE}\"\n\n\tprintf \"\\n\"\n\tprintf \"${bred} Target: ${domain}\\n\\n\"\n}\n\nfunction end(){\n\n\tfind $dir -type f -empty -print | grep -v '.called_fn' | grep -v '.log' | grep -v '.tmp' | xargs rm -f 2>>\"$LOGFILE\" >/dev/null\n\tfind $dir -type d -empty -print -delete 2>>\"$LOGFILE\" >/dev/null\n\n\techo \"End $(date +\"%F\") $(date +\"%T\")\" >> \"${LOGFILE}\"\n\n\tif [ ! \"$PRESERVE\" = true ]; then\n\t\tfind $dir -type f -empty | grep -v \"called_fn\" | xargs rm -f 2>>\"$LOGFILE\" >/dev/null\n\t\tfind $dir -type d -empty | grep -v \"called_fn\" | xargs rm -rf 2>>\"$LOGFILE\" >/dev/null\n\tfi\n\n\tif [ \"$REMOVETMP\" = true ]; then\n\t\trm -rf $dir/.tmp\n\tfi\n\n    if [ \"$REMOVELOG\" = true ]; then\n            rm -rf $dir/.log\n    fi \n\n\tif [ -n \"$dir_output\" ]; then\n\t\toutput\n\t\tfinaldir=$dir_output\n\telse\n\t\tfinaldir=$dir\n\tfi\n\t#Zip the output folder and send it via tg/discord/slack\n\tif [ \"$SENDZIPNOTIFY\" = true ]; then\n\t\tzipSnedOutputFolder\n\tfi\n\tglobal_end=$(date +%s)\n\tgetElapsedTime $global_start $global_end\n\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tnotification \"Finished Recon on: ${domain} under ${finaldir} in: ${runtime}\" good\n\t[ \"$SOFT_NOTIFICATION\" = true ] && echo \"Finished Recon on: ${domain} under ${finaldir} in: ${runtime}\" | notify -silent\n\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t#Seperator for more clear messges in telegram_Bot\n\techo \"******  Stay safe \ud83e\udda0 and secure \ud83d\udd10  ******\" | $NOTIFY\n}\n\n###############################################################################################################\n########################################### MODES & MENUS #####################################################\n###############################################################################################################\n\nfunction passive(){\n\tstart\n\tdomain_info\n\tip_info\n\temails\n\tgoogle_dorks\n\tgithub_dorks\n\tgithub_repos\n\tmetadata\n\tSUBNOERROR=false\n\tSUBANALYTICS=false\n\tSUBBRUTE=false\n\tSUBSCRAPING=false\n\tSUBPERMUTE=false\n\tSUBREGEXPERMUTE=false\n\tSUB_RECURSIVE_BRUTE=false\n\tWEBPROBESIMPLE=false\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_lauch\n\t\taxiom_selected\n\tfi\n\n\tsubdomains_full\n\tremove_big_files\n\tfavicon\n\tcdnprovider\n\tPORTSCAN_ACTIVE=false\n\tportscan\n\t\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_shutdown\n\tfi\n\n\tend\n}\n\nfunction all(){\n\tstart\n\trecon\n\tvulns\n\tend\n}\n\nfunction osint(){\n\tdomain_info\n\tip_info\n\temails\n\tgoogle_dorks\n\tgithub_dorks\n\tgithub_repos\n\tmetadata\n\tzonetransfer\n\tfavicon\n}\n\nfunction vulns(){\n\tif [ \"$VULNS_GENERAL\" = true ]; then\n\t\tcors\n\t\topen_redirect\n\t\tssrf_checks\n\t\tcrlf_checks\n\t\tlfi\n\t\tssti\n\t\tsqli\n\t\txss\n\t\tcommand_injection\n\t\tprototype_pollution\n\t\tsmuggling\n\t\twebcache\n\t\tspraying\n\t\tbrokenLinks\n\t\tfuzzparams\n\t\t4xxbypass\n\t\ttest_ssl\n\tfi\n}\n\nfunction multi_osint(){\n\n\tglobal_start=$(date +%s)\n\n\tif [ \"$NOTIFICATION\" = true ]; then\n\t\tNOTIFY=\"notify -silent\"\n\telse\n\t    NOTIFY=\"\"\n\tfi\n\n\t#[[ -n \"$domain\" ]] && ipcidr_target $domain\n\n\tif [ -s \"$list\" ]; then\n\t\tsed -i 's/\\r$//' $list\n\t\ttargets=$(cat $list)\n\telse\n\t\tnotification \"Target list not provided\" error\n\t\texit\n\tfi\n\n\tworkdir=$SCRIPTPATH/Recon/$multi\n\tmkdir -p $workdir  || { echo \"Failed to create directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tcd \"$workdir\"  || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tmkdir -p .tmp .called_fn osint subdomains webs hosts vulns\n\n\tNOW=$(date +\"%F\")\n\tNOWT=$(date +\"%T\")\n\tLOGFILE=\"${workdir}/.log/${NOW}_${NOWT}.txt\"\n\ttouch .log/${NOW}_${NOWT}.txt\n\techo \"Start ${NOW} ${NOWT}\" > \"${LOGFILE}\"\n\n\tfor domain in $targets; do\n\t\tdir=$workdir/targets/$domain\n\t\tcalled_fn_dir=$dir/.called_fn\n\t\tmkdir -p $dir\n\t\tcd \"$dir\"  || { echo \"Failed to cd directory '$dir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tmkdir -p .tmp .called_fn osint subdomains webs hosts vulns\n\t\tNOW=$(date +\"%F\")\n\t\tNOWT=$(date +\"%T\")\n\t\tLOGFILE=\"${dir}/.log/${NOW}_${NOWT}.txt\"\n\t\ttouch .log/${NOW}_${NOWT}.txt\n\t\techo \"Start ${NOW} ${NOWT}\" > \"${LOGFILE}\"\n\t\tdomain_info\n\t\tip_info\n\t\temails\n\t\tgoogle_dorks\n\t\tgithub_dorks\n\t\tgithub_repos\n\t\tmetadata\n\t\tzonetransfer\n\t\tfavicon\n\tdone\n\tcd \"$workdir\" || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tdir=$workdir\n\tdomain=$multi\n\tend\n}\n\n\nfunction recon(){\n\tdomain_info\n\tip_info\n\temails\n\tgoogle_dorks\n\tgithub_dorks\n\tgithub_repos\n\tmetadata\n\tzonetransfer\n\tfavicon\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_lauch\n\t\taxiom_selected\n\tfi\n\n\tsubdomains_full\n\twebprobe_full\n\tsubtakeover\n\tremove_big_files\n\ts3buckets\n\tscreenshot\n#\tvirtualhosts\n\tcdnprovider\n\tportscan\n\twaf_checks\n\tnuclei_check\n\tfuzz\n\turlchecks\n\tjschecks\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_shutdown\n\tfi\n\n\tcms_scanner\n\turl_gf\n\twordlist_gen\n\twordlist_gen_roboxtractor\n\tpassword_dict\n\turl_ext\n}\n\nfunction multi_recon(){\n\n\n\tglobal_start=$(date +%s)\n\n\tif [ \"$NOTIFICATION\" = true ]; then\n\t\tNOTIFY=\"notify -silent\"\n\telse\n\t    NOTIFY=\"\"\n\tfi\n\n\t#[[ -n \"$domain\" ]] && ipcidr_target $domain\n\n\tif [ -s \"$list\" ]; then\n\t\t sed -i 's/\\r$//' $list\n\t\ttargets=$(cat $list)\n\telse\n\t\tnotification \"Target list not provided\" error\n\t\texit\n\tfi\n\n\tworkdir=$SCRIPTPATH/Recon/$multi\n\tmkdir -p $workdir  || { echo \"Failed to create directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tcd \"$workdir\"  || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\n\tmkdir -p .tmp .log .called_fn osint subdomains webs hosts vulns\n\tNOW=$(date +\"%F\")\n\tNOWT=$(date +\"%T\")\n\tLOGFILE=\"${workdir}/.log/${NOW}_${NOWT}.txt\"\n\ttouch .log/${NOW}_${NOWT}.txt\n\techo \"Start ${NOW} ${NOWT}\" > \"${LOGFILE}\"\n\n\t[ -n \"$flist\" ] && LISTTOTAL=$(cat \"$flist\" | wc -l )\n\n\tfor domain in $targets; do\n\t\tdir=$workdir/targets/$domain\n\t\tcalled_fn_dir=$dir/.called_fn\n\t\tmkdir -p $dir\n\t\tcd \"$dir\"  || { echo \"Failed to cd directory '$dir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tmkdir -p .tmp .log .called_fn osint subdomains webs hosts vulns\n\n\t\tNOW=$(date +\"%F\")\n\t\tNOWT=$(date +\"%T\")\n\t\tLOGFILE=\"${dir}/.log/${NOW}_${NOWT}.txt\"\n\t\ttouch .log/${NOW}_${NOWT}.txt\n\t\techo \"Start ${NOW} ${NOWT}\" > \"${LOGFILE}\"\n\t\tloopstart=$(date +%s)\n\n\t\tdomain_info\n\t\tip_info\n\t\temails\n\t\tgoogle_dorks\n\t\tgithub_dorks\n\t\tgithub_repos\n\t\tmetadata\n\t\tzonetransfer\n\t\tfavicon\n\t\tcurrently=$(date +\"%H:%M:%S\")\n\t\tloopend=$(date +%s)\n\t\tgetElapsedTime $loopstart $loopend\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t\tprintf \"${bgreen} $domain finished 1st loop in ${runtime}  $currently ${reset}\\n\"\n\t\tif [ -n \"$flist\" ]; then\n\t\t\tPOSINLIST=$(eval grep -nrE \"^$domain$\" \"$flist\" | cut -f1 -d':')\n\t\t\tprintf \"\\n${yellow}  $domain is $POSINLIST of $LISTTOTAL${reset}\\n\"\n\t\tfi\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tdone\n\tcd \"$workdir\"  || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_lauch\n\t\taxiom_selected\n\tfi\n\n\tfor domain in $targets; do\n\t\tloopstart=$(date +%s)\n\t\tdir=$workdir/targets/$domain\n\t\tcalled_fn_dir=$dir/.called_fn\n\t\tcd \"$dir\"  || { echo \"Failed to cd directory '$dir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tsubdomains_full\n\t\twebprobe_full\n\t\tsubtakeover\n\t\tremove_big_files\n\t\tscreenshot\n#\t\tvirtualhosts\n\t\tcdnprovider\n\t\tportscan\n\t\tcurrently=$(date +\"%H:%M:%S\")\n\t\tloopend=$(date +%s)\n\t\tgetElapsedTime $loopstart $loopend\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t\tprintf \"${bgreen} $domain finished 2nd loop in ${runtime}  $currently ${reset}\\n\"\n\t\tif [ -n \"$flist\" ]; then\n\t\t\tPOSINLIST=$(eval grep -nrE \"^$domain$\" \"$flist\" | cut -f1 -d':')\n\t\t\tprintf \"\\n${yellow}  $domain is $POSINLIST of $LISTTOTAL${reset}\\n\"\n\t\tfi\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tdone\n\tcd \"$workdir\"  || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\n\tnotification \"############################# Total data ############################\" info\n\tNUMOFLINES_users_total=$(find . -type f -name 'users.txt' -exec cat {} + | anew osint/users.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_pwndb_total=$(find . -type f -name 'passwords.txt' -exec cat {} + | anew osint/passwords.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_software_total=$(find . -type f -name 'software.txt' -exec cat {} + | anew osint/software.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_authors_total=$(find . -type f -name 'authors.txt' -exec cat {} + | anew osint/authors.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_subs_total=$(find . -type f -name 'subdomains.txt' -exec cat {} + | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_subtko_total=$(find . -type f -name 'takeover.txt' -exec cat {} + | anew webs/takeover.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_webs_total=$(find . -type f -name 'webs.txt' -exec cat {} + | anew webs/webs.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_webs_total=$(find . -type f -name 'webs_uncommon_ports.txt' -exec cat {} + | anew webs/webs_uncommon_ports.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_ips_total=$(find . -type f -name 'ips.txt' -exec cat {} + | anew hosts/ips.txt | sed '/^$/d' | wc -l)\n\tNUMOFLINES_cloudsprov_total=$(find . -type f -name 'cdn_providers.txt' -exec cat {} + | anew hosts/cdn_providers.txt | sed '/^$/d' | wc -l)\n\tfind . -type f -name 'portscan_active.txt' -exec cat {} + | tee -a hosts/portscan_active.txt >> \"$LOGFILE\" 2>&1 >/dev/null\n\tfind . -type f -name 'portscan_active.gnmap' -exec cat {} + | tee hosts/portscan_active.gnmap 2>>\"$LOGFILE\" >/dev/null\n\tfind . -type f -name 'portscan_passive.txt' -exec cat {} + | tee hosts/portscan_passive.txt 2>&1 >> \"$LOGFILE\" >/dev/null\n\n\tnotification \"- ${NUMOFLINES_users_total} total users found\" good\n\tnotification \"- ${NUMOFLINES_pwndb_total} total creds leaked\" good\n\tnotification \"- ${NUMOFLINES_software_total} total software found\" good\n\tnotification \"- ${NUMOFLINES_authors_total} total authors found\" good\n\tnotification \"- ${NUMOFLINES_subs_total} total subdomains\" good\n\tnotification \"- ${NUMOFLINES_subtko_total} total probably subdomain takeovers\" good\n\tnotification \"- ${NUMOFLINES_webs_total} total websites\" good\n\tnotification \"- ${NUMOFLINES_ips_total} total ips\" good\n\tnotification \"- ${NUMOFLINES_cloudsprov_total} total IPs belongs to cloud\" good\n\ts3buckets\n\twaf_checks\n\tnuclei_check\n\tfor domain in $targets; do\n\t\tloopstart=$(date +%s)\n\t\tdir=$workdir/targets/$domain\n\t\tcalled_fn_dir=$dir/.called_fn\n\t\tcd \"$dir\" || { echo \"Failed to cd directory '$dir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tloopstart=$(date +%s)\n\t\tfuzz\n\t\turlchecks\n\t\tjschecks\n\t\tcurrently=$(date +\"%H:%M:%S\")\n\t\tloopend=$(date +%s)\n\t\tgetElapsedTime $loopstart $loopend\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t\tprintf \"${bgreen} $domain finished 3rd loop in ${runtime}  $currently ${reset}\\n\"\n\t\tif [ -n \"$flist\" ]; then\n\t\t\tPOSINLIST=$(eval grep -nrE \"^$domain$\" \"$flist\" | cut -f1 -d':')\n\t\t\tprintf \"\\n${yellow}  $domain is $POSINLIST of $LISTTOTAL${reset}\\n\"\n\t\tfi\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tdone\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_shutdown\n\tfi\n\n\tfor domain in $targets; do\n\t\tloopstart=$(date +%s)\n\t\tdir=$workdir/targets/$domain\n        called_fn_dir=$dir/.called_fn \n\t\tcd \"$dir\" || { echo \"Failed to cd directory '$dir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\tcms_scanner\n\t\turl_gf\n\t\twordlist_gen\n\t\twordlist_gen_roboxtractor\n\t\tpassword_dict\n\t\turl_ext\n\t\tcurrently=$(date +\"%H:%M:%S\")\n\t\tloopend=$(date +%s)\n\t\tgetElapsedTime $loopstart $loopend\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\t\tprintf \"${bgreen} $domain finished final loop in ${runtime}  $currently ${reset}\\n\"\n\t\tif [ -n \"$flist\" ]; then\n\t\t\tPOSINLIST=$(eval grep -nrE \"^$domain$\" \"$flist\" | cut -f1 -d':')\n\t\t\tprintf \"\\n${yellow}  $domain is $POSINLIST of $LISTTOTAL${reset}\\n\"\n\t\tfi\n\t\tprintf \"${bgreen}#######################################################################${reset}\\n\"\n\tdone\n\tcd \"$workdir\" || { echo \"Failed to cd directory '$workdir' in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\tdir=$workdir\n\tdomain=$multi\n\tend\n}\n\nfunction subs_menu(){\n\tstart\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_lauch\n\t\taxiom_selected\n\tfi\n\n\tsubdomains_full\n\twebprobe_full\n\tsubtakeover\n\tremove_big_files\n\tscreenshot\n#\tvirtualhosts\n\tzonetransfer\n\ts3buckets\n\n\tif [ \"$AXIOM\" = true ]; then\n\t\taxiom_shutdown\n\tfi\n\n\tend\n}\n\nfunction webs_menu(){\n\tsubtakeover\n\tremove_big_files\n\tscreenshot\n#\tvirtualhosts\n\twaf_checks\n\tnuclei_check\n\tcms_scanner\n\tfuzz\n\turlchecks\n\tjschecks\n\turl_gf\n\twordlist_gen\n\twordlist_gen_roboxtractor\n\tpassword_dict\n\turl_ext\n\tvulns\n\tend\n}\n\nfunction help(){\n\tprintf \"\\n Usage: $0 [-d domain.tld] [-m name] [-l list.txt] [-x oos.txt] [-i in.txt] \"\n\tprintf \"\\n           \t      [-r] [-s] [-p] [-a] [-w] [-n] [-i] [-h] [-f] [--deep] [-o OUTPUT]\\n\\n\"\n\tprintf \" ${bblue}TARGET OPTIONS${reset}\\n\"\n\tprintf \"   -d domain.tld     Target domain\\n\"\n\tprintf \"   -m company        Target company name\\n\"\n\tprintf \"   -l list.txt       Targets list (One on each line)\\n\"\n\tprintf \"   -x oos.txt        Exclude subdomains list (Out Of Scope)\\n\"\n\tprintf \"   -i in.txt         Include subdomains list\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${bblue}MODE OPTIONS${reset}\\n\"\n\tprintf \"   -r, --recon       Recon - Perform full recon process (without attacks)\\n\"\n\tprintf \"   -s, --subdomains  Subdomains - Perform Subdomain Enumeration, Web probing and check for sub-tko\\n\"\n\tprintf \"   -p, --passive     Passive - Perform only passive steps\\n\"\n\tprintf \"   -a, --all         All - Perform all checks and active exploitations\\n\"\n\tprintf \"   -w, --web         Web - Perform web checks from list of subdomains\\n\"\n\tprintf \"   -n, --osint       OSINT - Check for public intel data\\n\"\n\tprintf \"   -c, --custom      Custom - Launches specific function against target, u need to know the function name first\\n\"\n\tprintf \"   -h                Help - Show help section\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${bblue}GENERAL OPTIONS${reset}\\n\"\n\tprintf \"   --deep            Deep scan (Enable some slow options for deeper scan)\\n\"\n\tprintf \"   -f config_file    Alternate reconftw.cfg file\\n\"\n\tprintf \"   -o output/path    Define output folder\\n\"\n\tprintf \"   -v, --vps         Axiom distributed VPS \\n\"\n\tprintf \"   -q                Rate limit in requests per second \\n\"\n\tprintf \" \\n\"\n\tprintf \" ${bblue}USAGE EXAMPLES${reset}\\n\"\n\tprintf \" ${byellow}Perform full recon (without attacks):${reset}\\n\"\n\tprintf \" ./reconftw.sh -d example.com -r\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Perform subdomain enumeration on multiple targets:${reset}\\n\"\n\tprintf \" ./reconftw.sh -l targets.txt -s\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Perform Web based scanning on a subdomains list:${reset}\\n\"\n\tprintf \" ./reconftw.sh -d example.com -l targets.txt -w\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Multidomain recon:${reset}\\n\"\n\tprintf \" ./reconftw.sh -m company -l domainlist.txt -r\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Perform full recon (with active attacks) along Out-Of-Scope subdomains list:${reset}\\n\"\n\tprintf \" ./reconftw.sh -d example.com -x out.txt -a\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Perform full recon and store output to specified directory:${reset}\\n\"\n\tprintf \" ./reconftw.sh -d example.com -r -o custom/path\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Run custom function:${reset}\\n\"\n\tprintf \" ./reconftw.sh -d example.com -c nuclei_check \\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Start the web server:${reset}\\n\"\n\tprintf \" ./reconftw.sh --web-server start\\n\"\n\tprintf \" \\n\"\n\tprintf \" ${byellow}Stop the web server:${reset}\\n\"\n\tprintf \" ./reconftw.sh --web-server stop\\n\"\n}\n\n###############################################################################################################\n############################################# WEB SERVER ######################################################\n###############################################################################################################\n\n# webserver initialization, thanks @lur1el, @d3vchac, @mx61tt and @dd4n1b0y <3\n\n\nfunction webserver(){\n\tprintf \"${bgreen} Web Interface    by @lur1el, @d3vchac, @mx61tt and @dd4n1b0y ${reset}\\n\"\n\tver=$(python3 -V 2>&1 | sed 's/.* \\([0-9]\\).\\([0-9]\\).*/\\1\\2/')\n\t\n    if [ \"$ver\" -lt \"31\" ]; then\n        echo \"The web interface requires python 3.10 or greater\"\n        exit 1\n    fi\n\n\tif [ \"$1\" == \"start\" ]; then\n\t\tipAddress=$(curl -s ifconfig.me) \n\n\t\tif [ \"$ipAddress\" != \"\" ]; then\n\t\t\tprintf \"\\n ${bblue}Starting web server... ${reset}\\n\"\n\t\t\tcd $SCRIPTPATH/web || { echo \"Failed to cd to $dir in ${FUNCNAME[0]} @ line ${LINENO}\"; exit 1; }\n\t\t\t$SUDO source $SCRIPTPATH/web/.venv/bin/activate\n\t\t\t$SUDO screen -S ReconftwWebserver -X kill &>/dev/null\n\t\t\t$SUDO screen -dmS ReconftwWebserver python3 manage.py runserver $ipAddress:8001 &>/dev/null\n\t\t\t$SUDO service redis-server start &>/dev/null\n\t\t\t$SUDO screen -S ReconftwCelery -X kill &>/dev/null\n\t\t\t$SUDO screen -dmS ReconftwCelery python3 -m celery -A web worker -l info -P prefork -Q run_scans,default &>/dev/null\n\t\t\tprintf \" ${bblue}Web server started! ${reset}\\n\"\n\t\t\tprintf \" ${bblue}Service Address: http://$ipAddress:8001${reset}\\n\"\n\t\telse\n\t\t\tprintf \"\\n\"\n\t\t\tprintf \" ${red}Server IP address not found.${reset}\\n\"\n\t\t\tprintf \"\\n\"\n\t\t\tprintf \" ${bblue}Check if the server has internet connection.${reset}\\n\"\n\t\tfi\n\telif [ \"$1\" == \"stop\" ]; then\n\t\tprintf \"\\n ${bblue}Stoping web server... ${reset}\\n\"\n\t\t# $SUDO service postgresql stop\n\t\t$SUDO screen -S ReconftwWebserver -X kill &>/dev/null\n\t\t$SUDO service redis-server stop &>/dev/null\n\t\t$SUDO screen -S ReconftwCelery -X kill &>/dev/null\n\t\tprintf \" ${bblue}Web server stoped! ${reset}\\n\"\n\telse\n\t\tprintf \"\\n\"\n\t\tprintf \" ${red}Invalid action${reset}\\n\"\n\t\tprintf \"\\n\"\n\t\tprintf \" ${bblue}Valid actions: start/stop${reset}\\n\"\n\tfi\n}\n\n###############################################################################################################\n########################################### START SCRIPT  #####################################################\n###############################################################################################################\n\n# macOS PATH initialization, thanks @0xtavian <3\nif [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n\tPATH=\"/usr/local/opt/gnu-getopt/bin:$PATH\"\n\tPATH=\"/usr/local/opt/coreutils/libexec/gnubin:$PATH\"\nfi\n\nPROGARGS=$(getopt -o 'd:m:l:x:i:o:f:q:c:rspanwvh::' --long 'domain:,list:,recon,subdomains,passive,all,web,osint,deep,web-server,help,vps' -n 'reconFTW' -- \"$@\")\n\n\n# Note the quotes around \"$PROGARGS\": they are essential!\neval set -- \"$PROGARGS\"\nunset PROGARGS\n\nwhile true; do\n    case \"$1\" in\n        '-d'|'--domain')\n            domain=$2\n\t\t\tipcidr_target $2\n            shift 2\n            continue\n            ;;\n        '-m')\n            multi=$2\n            shift 2\n            continue\n            ;;\n        '-l'|'--list')\n\t\t\tlist=$2\n\t\t\tfor t in $(cat $list); do\n\t\t\t\tipcidr_target $t $list\n\t\t\tdone\n            shift 2\n            continue\n            ;;\n        '-x')\n            outOfScope_file=$2\n            shift 2\n            continue\n            ;;\n        '-i')\n            inScope_file=$2\n            shift 2\n            continue\n            ;;\n\n        # modes\n        '-r'|'--recon')\n            opt_mode='r'\n            shift\n            continue\n            ;;\n        '-s'|'--subdomains')\n            opt_mode='s'\n            shift\n            continue\n            ;;\n        '-p'|'--passive')\n            opt_mode='p'\n            shift\n            continue\n            ;;\n        '-a'|'--all')\n            opt_mode='a'\n            shift\n            continue\n            ;;\n        '-w'|'--web')\n            opt_mode='w'\n            shift\n            continue\n            ;;\n        '-n'|'--osint')\n            opt_mode='n'\n            shift\n            continue\n            ;;\n\t\t'-c'|'--custom')\n\t\t\tcustom_function=$2\n\t\t\topt_mode='c'\n            shift 2\n            continue\n            ;;\n        # extra stuff\n        '-o')\n\t\t\tif [[ \"$2\" != /* ]]; then\n            \tdir_output=$PWD/$2\n\t\t\telse\n\t\t\t\tdir_output=$2\n\t\t\tfi\n            shift 2\n            continue\n            ;;\n\t\t'-v'|'--vps')\n\t\t\twhich axiom-ls &>/dev/null || { printf \"\\n Axiom is needed for this mode and is not installed \\n You have to install it manually \\n\" && exit; allinstalled=false;}\n\t\t\tAXIOM=true\n            shift\n            continue\n            ;;\n        '-f')\n\t\t\tCUSTOM_CONFIG=$2\n            shift 2\n            continue\n            ;;\n\t\t'-q')\n\t\t\trate_limit=$2\n            shift 2\n            continue\n            ;;\n        '--deep')\n            opt_deep=true\n            shift\n            continue\n            ;;\n\n        '--')\n\t\t\tshift\n\t\t\tbreak\n\t\t    ;;\n        '--web-server')\n            . ./reconftw.cfg\n\t\t\tbanner\n\t\t\twebserver $3\n\t\t\texit 1\n\t\t    ;;\n        '--help'| '-h'| *)\n            # echo \"Unknown argument: $1\"\n            . ./reconftw.cfg\n\t\t\tbanner\n            help\n\t\t\ttools_installed\n\t\t\texit 1\n\t\t    ;;\n    esac\ndone\n\n# This is the first thing to do to read in alternate config\nSCRIPTPATH=\"$( cd \"$(dirname \"$0\")\" >/dev/null 2>&1 || exit ; pwd -P )\"\n. \"$SCRIPTPATH\"/reconftw.cfg || { echo \"Error importing reconftw.ctg\"; exit 1; }\nif [ -s \"$CUSTOM_CONFIG\" ]; then\n# shellcheck source=/home/six2dez/Tools/reconftw/custom_config.cfg\n. \"${CUSTOM_CONFIG}\" || { echo \"Error importing reconftw.ctg\"; exit 1; }\nfi\n\nif [ $opt_deep ]; then\n    DEEP=true\nfi\n\nif [ $rate_limit ]; then\n    NUCLEI_RATELIMIT=$rate_limit\n\tFFUF_RATELIMIT=$rate_limit\n\tHTTPX_RATELIMIT=$rate_limit\nfi\n\nif [ -n \"$outOfScope_file\" ]; then\n    isAsciiText $outOfScope_file\n    if [ \"False\" = \"$IS_ASCII\" ]\n    then\n        printf \"\\n\\n${bred} Out of Scope file is not a text file${reset}\\n\\n\"\n        exit\n    fi\nfi\n\nif [ -n \"$inScope_file\" ]; then\n    isAsciiText $inScope_file\n    if [ \"False\" = \"$IS_ASCII\" ]\n    then\n        printf \"\\n\\n${bred} In Scope file is not a text file${reset}\\n\\n\"\n        exit\n    fi\nfi\n\nif [[ $(id -u | grep -o '^0$') == \"0\" ]]; then\n    SUDO=\" \"\nelse\n    SUDO=\"sudo\"\nfi\n\nstartdir=${PWD}\n\nbanner\n\ncheck_version\n\nstartdir=${PWD}\nif [ -n \"$list\" ]; then\n\tif [[ \"$list\" = ./* ]]; then\n\t\tflist=\"${startdir}/${list:2}\"\n\telif [[ \"$list\" = ~* ]]; then\n\t\tflist=\"${HOME}/${list:2}\"\n\telif [[ \"$list\" = /* ]]; then\n\t\tflist=$list\n\telse\n\t\tflist=\"$startdir/$list\"\n\tfi\nelse\n\tflist=''\nfi\n\ncase $opt_mode in\n        'r')\n            if [ -n \"$multi\" ];\tthen\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"multi_recon\"\n\t\t\t\tfi\n\t\t\t\tmulti_recon\n\t\t\t\texit\n\t\t\tfi\n\t\t\tif [ -n \"$list\" ]; then\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"list_recon\"\n\t\t\t\tfi\n\t\t\t\tsed -i 's/\\r$//' $list\n\t\t\t\tfor domain in $(cat $list); do\n\t\t\t\t\tstart\n\t\t\t\t\trecon\n\t\t\t\t\tend\n\t\t\t\tdone\n\t\t\telse\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"recon\"\n\t\t\t\tfi\n\t\t\t\tstart\n\t\t\t\trecon\n\t\t\t\tend\n\t\t\tfi\n            ;;\n        's')\n            if [ -n \"$list\" ]; then\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"subs_menu\"\n\t\t\t\tfi\n\t\t\t\tsed -i 's/\\r$//' $list\n\t\t\t\tfor domain in $(cat $list); do\n\t\t\t\t\tsubs_menu\n\t\t\t\tdone\n\t\t\telse\n\t\t\t\tsubs_menu\n\t\t\tfi\n            ;;\n        'p')\n            if [ -n \"$list\" ]; then\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"passive\"\n\t\t\t\tfi\n\t\t\t\tsed -i 's/\\r$//' $list\n\t\t\t\tfor domain in $(cat $list); do\n\t\t\t\t\tpassive\n\t\t\t\tdone\n\t\t\telse\n\t\t\t\tpassive\n\t\t\tfi\n            ;;\n        'a')\n\t\t\texport VULNS_GENERAL=true\n            if [ -n \"$list\" ]; then\n\t\t\t\tif [ \"$AXIOM\" = true ]; then\n\t\t\t\t\tmode=\"all\"\n\t\t\t\tfi\n\t\t\t\tsed -i 's/\\r$//' $list\n\t\t\t\tfor domain in $(cat $list); do\n\t\t\t\t\tall\n\t\t\t\tdone\n\t\t\telse\n\t\t\t\tall\n\t\t\tfi\n            ;;\n        'w')\n\t\t\tif [ -n \"$list\" ]; then\n\t\t\t\tstart\n\t\t\t\tif [[ \"$list\" = /* ]]; then\n\t\t\t\t\tcp $list $dir/webs/webs.txt\n\t\t\t\telse\n\t\t\t\t\tcp $SCRIPTPATH/$list $dir/webs/webs.txt\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tprintf \"\\n\\n${bred} Web mode needs a website list file as target (./reconftw.sh -l target.txt -w) ${reset}\\n\\n\"\n\t\t\t\texit\n\t\t\tfi\n\t\t\twebs_menu\n\t\t\texit\n            ;;\n        'n')\n\t\t\tPRESERVE=true\n\t\t\tif [ -n \"$multi\" ];\tthen\n\t\t\t\tmulti_osint\n\t\t\t\texit\n\t\t\tfi\n\t\t\tif [ -n \"$list\" ]; then\n\t\t\t\tsed -i 's/\\r$//' $list\n\t\t\t\twhile IFS= read -r domain; do\n\t\t\t\t\tstart\n\t\t\t\t\tosint\n\t\t\t\t\tend\n\t\t\t\tdone\n\t\t\telse\n\t\t\t\tstart\n\t\t\t\tosint\n\t\t\t\tend\n\t\t\tfi\n\t\t\t;;\n\t\t'c')\n\t\t\texport DIFF=true\n\t\t\tdir=\"$SCRIPTPATH/Recon/$domain\"\n\t\t\tcd $dir || { echo \"Failed to cd directory '$dir'\"; exit 1; }\n\t\t\tLOGFILE=\"${dir}/.log/${NOW}_${NOWT}.txt\"\n\t\t\tcalled_fn_dir=$dir/.called_fn \n\t\t\t$custom_function\n\t\t\tcd $SCRIPTPATH || { echo \"Failed to cd directory '$dir'\"; exit 1; }\n\t\t\texit\n            ;;\n        # No mode selected.  EXIT!\n\t\t*)\n            help\n            tools_installed\n            exit 1\n            ;;\nesac\n\n"], "filenames": ["reconftw.sh"], "buggy_code_start_loc": [449], "buggy_code_end_loc": [1387], "fixing_code_start_loc": [449], "fixing_code_end_loc": [1387], "type": "CWE-78", "message": "reconFTW is a tool designed to perform automated recon on a target domain by running the best set of tools to perform scanning and finding out vulnerabilities. A vulnerability has been identified in reconftw where inadequate validation of retrieved subdomains may lead to a Remote Code Execution (RCE) attack. An attacker can exploit this vulnerability by crafting a malicious CSP entry on it's own domain. Successful exploitation can lead to the execution of arbitrary code within the context of the application, potentially compromising the system. This issue has been addressed in version 2.7.1.1 and all users are advised to upgrade. There are no known workarounds for this vulnerability.", "other": {"cve": {"id": "CVE-2023-46117", "sourceIdentifier": "security-advisories@github.com", "published": "2023-10-20T19:15:09.037", "lastModified": "2023-10-28T03:48:19.117", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "reconFTW is a tool designed to perform automated recon on a target domain by running the best set of tools to perform scanning and finding out vulnerabilities. A vulnerability has been identified in reconftw where inadequate validation of retrieved subdomains may lead to a Remote Code Execution (RCE) attack. An attacker can exploit this vulnerability by crafting a malicious CSP entry on it's own domain. Successful exploitation can lead to the execution of arbitrary code within the context of the application, potentially compromising the system. This issue has been addressed in version 2.7.1.1 and all users are advised to upgrade. There are no known workarounds for this vulnerability."}, {"lang": "es", "value": "reconFTW es una herramienta dise\u00f1ada para realizar un reconocimiento automatizado en un dominio de destino ejecutando el mejor conjunto de herramientas para realizar escaneos y descubrir vulnerabilidades. Se ha identificado una vulnerabilidad en reconftw donde la validaci\u00f3n inadecuada de los subdominios recuperados puede provocar un ataque de Remote Code Execution (RCE). Un atacante puede aprovechar esta vulnerabilidad creando una entrada CSP maliciosa en su propio dominio. Una explotaci\u00f3n exitosa puede conducir a la ejecuci\u00f3n de c\u00f3digo arbitrario dentro del contexto de la aplicaci\u00f3n, comprometiendo potencialmente el sistema. Este problema se solucion\u00f3 en la versi\u00f3n 2.7.1.1 y se recomienda a todos los usuarios que actualicen. No se conocen workarounds para esta vulnerabilidad."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}], "cvssMetricV30": [{"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.6, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 2.8, "impactScore": 6.0}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-78"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-78"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:six2dez:reconftw:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.7.1.1", "matchCriteriaId": "2668F9CE-3520-490A-8F35-197666112516"}]}]}], "references": [{"url": "https://github.com/six2dez/reconftw/commit/e639de356c0880fe5fe01a32de9d0c58afb5f086", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/six2dez/reconftw/security/advisories/GHSA-fxwr-vr9x-wvjp", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/six2dez/reconftw/commit/e639de356c0880fe5fe01a32de9d0c58afb5f086"}}
{"buggy_code": ["/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// Ops that looks up items from matrix.\n//\n// Input:\n//     Tensor[0]: Row number to lookup, dim.size == 1, int32\n//     Tensor[1]: 2-dimensional matrix of multi-dimensional items\n//                dim.size >= 2, any data type.\n//                first dimension is row, second dimension is column.\n//\n// Output:\n//   Output.dim[0] == Tensor[0].dim[0], num of lookups\n//   Output.dim[1] == Tensor[1].dim[1],  num of items per row\n//   Each item in output is a raw bytes copy of the corresponding item in input,\n//   or a dequantized value in the case of a uint8 input.\n//   When indices are out of bound, the ops will not succeed.\n//\n\n#include <stdint.h>\n\n#include <cstring>\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace builtin {\nnamespace embedding_lookup {\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* lookup;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &lookup));\n  TF_LITE_ENSURE_EQ(context, NumDimensions(lookup), 1);\n  TF_LITE_ENSURE_EQ(context, lookup->type, kTfLiteInt32);\n\n  const TfLiteTensor* value;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &value));\n  TF_LITE_ENSURE(context, NumDimensions(value) >= 2);\n\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(NumDimensions(value));\n\n  outputSize->data[0] = SizeOfDimension(lookup, 0);\n  outputSize->data[1] = SizeOfDimension(value, 1);\n  for (int i = 2; i < NumDimensions(value); i++) {\n    outputSize->data[i] = SizeOfDimension(value, i);\n  }\n  return context->ResizeTensor(context, output, outputSize);\n}\n\nTfLiteStatus EvalSimple(TfLiteContext* context, TfLiteNode* node,\n                        const TfLiteTensor* lookup, const TfLiteTensor* value,\n                        TfLiteTensor* output) {\n  const int row_size = SizeOfDimension(value, 0);\n  const int row_bytes = value->bytes / row_size;\n\n  char* output_raw = GetTensorData<char>(output);\n  const char* value_raw = GetTensorData<char>(value);\n  const int32_t* lookup_data = GetTensorData<int32_t>(lookup);\n  for (int i = 0; i < SizeOfDimension(lookup, 0); i++) {\n    int idx = lookup_data[i];\n    if (idx >= row_size || idx < 0) {\n      context->ReportError(context,\n                           \"Embedding Lookup: index out of bounds. \"\n                           \"Got %d, and bounds are [0, %d]\",\n                           idx, row_size - 1);\n      return kTfLiteError;\n    } else {\n      std::memcpy(output_raw + i * row_bytes, value_raw + idx * row_bytes,\n                  row_bytes);\n    }\n  }\n\n  return kTfLiteOk;\n}\n\nTfLiteStatus EvalHybrid(TfLiteContext* context, TfLiteNode* node,\n                        const TfLiteTensor* lookup, const TfLiteTensor* value,\n                        TfLiteTensor* output) {\n  const int row_size = SizeOfDimension(value, 0);\n  const double scaling_factor = value->params.scale;\n\n  // col_size after we flatten tensor into 2D.\n  int col_size = 1;\n  for (int i = 1; i < NumDimensions(value); i++) {\n    col_size *= SizeOfDimension(value, i);\n  }\n\n  float* output_ptr = GetTensorData<float>(output);\n  const int8_t* value_ptr = GetTensorData<int8_t>(value);\n  const int32_t* lookup_data = GetTensorData<int32_t>(lookup);\n\n  for (int i = 0; i < SizeOfDimension(lookup, 0); i++) {\n    int idx = lookup_data[i];\n    if (idx >= row_size || idx < 0) {\n      context->ReportError(context,\n                           \"Embedding Lookup: index out of bounds. \"\n                           \"Got %d, and bounds are [0, %d]\",\n                           idx, row_size - 1);\n      return kTfLiteError;\n    } else {\n      // Dequantize embedding values.\n      // TODO(alanchiao): refactor scalar multiply into separate function\n      // for ease of adding a neon equivalent if ever necessary.\n      for (int j = 0; j < col_size; j++) {\n        output_ptr[j + i * col_size] =\n            value_ptr[j + idx * col_size] * scaling_factor;\n      }\n    }\n  }\n\n  return kTfLiteOk;\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* lookup;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &lookup));\n  const TfLiteTensor* value;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &value));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  switch (value->type) {\n    case kTfLiteFloat32:\n      return EvalSimple(context, node, lookup, value, output);\n    case kTfLiteUInt8:\n    case kTfLiteInt8:\n      if (output->type == kTfLiteFloat32) {\n        return EvalHybrid(context, node, lookup, value, output);\n      } else {\n        return EvalSimple(context, node, lookup, value, output);\n      }\n    default:\n      context->ReportError(context, \"Type not currently supported.\");\n      return kTfLiteError;\n  }\n}\n\n}  // namespace embedding_lookup\n\nTfLiteRegistration* Register_EMBEDDING_LOOKUP() {\n  static TfLiteRegistration r = {nullptr, nullptr, embedding_lookup::Prepare,\n                                 embedding_lookup::Eval};\n  return &r;\n}\n\n}  // namespace builtin\n}  // namespace ops\n}  // namespace tflite\n"], "fixing_code": ["/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// Ops that looks up items from matrix.\n//\n// Input:\n//     Tensor[0]: Row number to lookup, dim.size == 1, int32\n//     Tensor[1]: 2-dimensional matrix of multi-dimensional items\n//                dim.size >= 2, any data type.\n//                first dimension is row, second dimension is column.\n//\n// Output:\n//   Output.dim[0] == Tensor[0].dim[0], num of lookups\n//   Output.dim[1] == Tensor[1].dim[1],  num of items per row\n//   Each item in output is a raw bytes copy of the corresponding item in input,\n//   or a dequantized value in the case of a uint8 input.\n//   When indices are out of bound, the ops will not succeed.\n//\n\n#include <stdint.h>\n\n#include <cstring>\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace builtin {\nnamespace embedding_lookup {\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* lookup;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &lookup));\n  TF_LITE_ENSURE_EQ(context, NumDimensions(lookup), 1);\n  TF_LITE_ENSURE_EQ(context, lookup->type, kTfLiteInt32);\n\n  const TfLiteTensor* value;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &value));\n  TF_LITE_ENSURE(context, NumDimensions(value) >= 2);\n\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(NumDimensions(value));\n\n  outputSize->data[0] = SizeOfDimension(lookup, 0);\n  outputSize->data[1] = SizeOfDimension(value, 1);\n  for (int i = 2; i < NumDimensions(value); i++) {\n    outputSize->data[i] = SizeOfDimension(value, i);\n  }\n  return context->ResizeTensor(context, output, outputSize);\n}\n\nTfLiteStatus EvalSimple(TfLiteContext* context, TfLiteNode* node,\n                        const TfLiteTensor* lookup, const TfLiteTensor* value,\n                        TfLiteTensor* output) {\n  const int row_size = SizeOfDimension(value, 0);\n  if (row_size == 0) {\n    // Propagate empty tensor if input is empty\n    return kTfLiteOk;\n  }\n  const int row_bytes = value->bytes / row_size;\n\n  char* output_raw = GetTensorData<char>(output);\n  const char* value_raw = GetTensorData<char>(value);\n  const int32_t* lookup_data = GetTensorData<int32_t>(lookup);\n  for (int i = 0; i < SizeOfDimension(lookup, 0); i++) {\n    int idx = lookup_data[i];\n    if (idx >= row_size || idx < 0) {\n      context->ReportError(context,\n                           \"Embedding Lookup: index out of bounds. \"\n                           \"Got %d, and bounds are [0, %d]\",\n                           idx, row_size - 1);\n      return kTfLiteError;\n    } else {\n      std::memcpy(output_raw + i * row_bytes, value_raw + idx * row_bytes,\n                  row_bytes);\n    }\n  }\n\n  return kTfLiteOk;\n}\n\nTfLiteStatus EvalHybrid(TfLiteContext* context, TfLiteNode* node,\n                        const TfLiteTensor* lookup, const TfLiteTensor* value,\n                        TfLiteTensor* output) {\n  const int row_size = SizeOfDimension(value, 0);\n  const double scaling_factor = value->params.scale;\n\n  // col_size after we flatten tensor into 2D.\n  int col_size = 1;\n  for (int i = 1; i < NumDimensions(value); i++) {\n    col_size *= SizeOfDimension(value, i);\n  }\n\n  float* output_ptr = GetTensorData<float>(output);\n  const int8_t* value_ptr = GetTensorData<int8_t>(value);\n  const int32_t* lookup_data = GetTensorData<int32_t>(lookup);\n\n  for (int i = 0; i < SizeOfDimension(lookup, 0); i++) {\n    int idx = lookup_data[i];\n    if (idx >= row_size || idx < 0) {\n      context->ReportError(context,\n                           \"Embedding Lookup: index out of bounds. \"\n                           \"Got %d, and bounds are [0, %d]\",\n                           idx, row_size - 1);\n      return kTfLiteError;\n    } else {\n      // Dequantize embedding values.\n      // TODO(alanchiao): refactor scalar multiply into separate function\n      // for ease of adding a neon equivalent if ever necessary.\n      for (int j = 0; j < col_size; j++) {\n        output_ptr[j + i * col_size] =\n            value_ptr[j + idx * col_size] * scaling_factor;\n      }\n    }\n  }\n\n  return kTfLiteOk;\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* lookup;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &lookup));\n  const TfLiteTensor* value;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &value));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  switch (value->type) {\n    case kTfLiteFloat32:\n      return EvalSimple(context, node, lookup, value, output);\n    case kTfLiteUInt8:\n    case kTfLiteInt8:\n      if (output->type == kTfLiteFloat32) {\n        return EvalHybrid(context, node, lookup, value, output);\n      } else {\n        return EvalSimple(context, node, lookup, value, output);\n      }\n    default:\n      context->ReportError(context, \"Type not currently supported.\");\n      return kTfLiteError;\n  }\n}\n\n}  // namespace embedding_lookup\n\nTfLiteRegistration* Register_EMBEDDING_LOOKUP() {\n  static TfLiteRegistration r = {nullptr, nullptr, embedding_lookup::Prepare,\n                                 embedding_lookup::Eval};\n  return &r;\n}\n\n}  // namespace builtin\n}  // namespace ops\n}  // namespace tflite\n"], "filenames": ["tensorflow/lite/kernels/embedding_lookup.cc"], "buggy_code_start_loc": [73], "buggy_code_end_loc": [73], "fixing_code_start_loc": [74], "fixing_code_end_loc": [78], "type": "CWE-369", "message": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `EmbeddingLookup` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/e4b29809543b250bc9b19678ec4776299dd569ba/tensorflow/lite/kernels/embedding_lookup.cc#L73-L74). An attacker can craft a model such that the first dimension of the `value` input is 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-29596", "sourceIdentifier": "security-advisories@github.com", "published": "2021-05-14T20:15:15.257", "lastModified": "2021-05-19T16:26:06.847", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `EmbeddingLookup` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/e4b29809543b250bc9b19678ec4776299dd569ba/tensorflow/lite/kernels/embedding_lookup.cc#L73-L74). An attacker can craft a model such that the first dimension of the `value` input is 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto de extremo a extremo para el aprendizaje autom\u00e1tico.&#xa0;La implementaci\u00f3n del operador TFLite \"EmbeddingLookup\" es vulnerable a un error de divisi\u00f3n por cero (https://github.com/tensorflow/tensorflow/blob/e4b29809543b250bc9b19678ec4776299dd569ba/tensorflow/lite/kernels/embedding_lookup.cc#L73-L74).&#xa0;Un atacante puede dise\u00f1ar un modelo de modo que la primera dimensi\u00f3n de la entrada de \"value\" sea 0. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.5.0.&#xa0;Tambi\u00e9n seleccionaremos este commit en TensorFlow versi\u00f3n 2.4.2, TensorFlow versi\u00f3n 2.3.3, TensorFlow versi\u00f3n 2.2.3 y TensorFlow versi\u00f3n 2.1.4, ya que estos tambi\u00e9n est\u00e1n afectados y a\u00fan est\u00e1n en el rango compatible"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:N/I:N/A:L", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "LOW", "baseScore": 2.5, "baseSeverity": "LOW"}, "exploitabilityScore": 1.0, "impactScore": 1.4}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 4.6}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-369"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.1.4", "matchCriteriaId": "323ABCCE-24EB-47CC-87F6-48C101477587"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.2.0", "versionEndExcluding": "2.2.3", "matchCriteriaId": "64ABA90C-0649-4BB0-89C9-83C14BBDCC0F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.3", "matchCriteriaId": "0F83E0CF-CBF6-4C24-8683-3E7A5DC95BA9"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.2", "matchCriteriaId": "8259531B-A8AC-4F8B-B60F-B69DE4767C03"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/f61c57bd425878be108ec787f4d96390579fb83e", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4vrf-ff7v-hpgr", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/f61c57bd425878be108ec787f4d96390579fb83e"}}
{"buggy_code": ["/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <stdint.h>\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/optimized/optimized_ops.h\"\n#include \"tensorflow/lite/kernels/internal/reference/reference_ops.h\"\n#include \"tensorflow/lite/kernels/internal/tensor.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace builtin {\nnamespace gather_nd {\nconstexpr int kParams = 0;\nconstexpr int kIndices = 1;\nconstexpr int kOutputTensor = 0;\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* params;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kParams, &params));\n  const TfLiteTensor* indices;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kIndices, &indices));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  switch (params->type) {\n    case kTfLiteFloat32:\n    case kTfLiteUInt8:\n    case kTfLiteInt8:\n    case kTfLiteInt16:\n    case kTfLiteInt64:\n    case kTfLiteInt32:\n    case kTfLiteString:\n      break;\n    default:\n      context->ReportError(\n          context, \"Params of type '%s' are not supported by gather_nd.\",\n          TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n  }\n  switch (indices->type) {\n    case kTfLiteInt64:\n    case kTfLiteInt32:\n      break;\n    default:\n      context->ReportError(\n          context, \"Indices of type '%s' are not supported by gather_nd.\",\n          TfLiteTypeGetName(indices->type));\n      return kTfLiteError;\n  }\n\n  const int params_rank = NumDimensions(params);\n  const int indices_rank = NumDimensions(indices);\n  const int indices_nd = SizeOfDimension(indices, indices_rank - 1);\n  if (params_rank < 1) {\n    context->ReportError(context, \"Params must be at least a vector.\");\n    return kTfLiteError;\n  }\n  if (indices_rank < 1) {\n    context->ReportError(context, \"Indices must be at least a vector.\");\n    return kTfLiteError;\n  }\n  if (indices_nd > params_rank) {\n    context->ReportError(\n        context, \"Index innermost dimension length must be <= params rank.\");\n    return kTfLiteError;\n  }\n\n  // Assign to output the input type.\n  output->type = params->type;\n\n  // The result shape is\n  // indices.shape[:-1] + params.shape[indices.shape[-1]:]\n  const int output_rank = indices_rank + params_rank - indices_nd - 1;\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(output_rank);\n  int output_index = 0;\n  for (int i = 0; i < indices_rank - 1; ++i) {\n    output_shape->data[output_index++] = indices->dims->data[i];\n  }\n  for (int i = indices_nd; i < params_rank; ++i) {\n    output_shape->data[output_index++] = params->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}\n\ntemplate <typename ParamsT, typename IndicesT>\nTfLiteStatus GatherNd(const TfLiteTensor* params, const TfLiteTensor* indices,\n                      TfLiteTensor* output) {\n  reference_ops::GatherNd(\n      GetTensorShape(params), GetTensorData<ParamsT>(params),\n      GetTensorShape(indices), GetTensorData<IndicesT>(indices),\n      GetTensorShape(output), GetTensorData<ParamsT>(output));\n  return kTfLiteOk;\n}\n\ntemplate <typename IndicesT>\nTfLiteStatus GatherNdString(const TfLiteTensor* params,\n                            const TfLiteTensor* indices, TfLiteTensor* output) {\n  reference_ops::GatherNdString(\n      GetTensorShape(params), params, GetTensorShape(indices),\n      GetTensorData<IndicesT>(indices), GetTensorShape(output), output);\n  return kTfLiteOk;\n}\n\ntemplate <typename IndicesT>\nTfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                          const TfLiteTensor* indices, TfLiteTensor* output) {\n  switch (params->type) {\n    case kTfLiteFloat32:\n      return GatherNd<float, IndicesT>(params, indices, output);\n    case kTfLiteUInt8:\n      return GatherNd<uint8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt8:\n      return GatherNd<int8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt16:\n      return GatherNd<int16_t, IndicesT>(params, indices, output);\n    case kTfLiteInt32:\n      return GatherNd<int32_t, IndicesT>(params, indices, output);\n    case kTfLiteInt64:\n      return GatherNd<int64_t, IndicesT>(params, indices, output);\n    case kTfLiteString:\n      return GatherNdString<IndicesT>(params, indices, output);\n    default:\n      context->ReportError(context,\n                           \"Params type '%s' are not supported by gather_nd.\",\n                           TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n  }\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* params;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kParams, &params));\n  const TfLiteTensor* indices;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kIndices, &indices));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  switch (indices->type) {\n    case kTfLiteInt32:\n      return EvalGatherNd<int32_t>(context, params, indices, output);\n    case kTfLiteInt64:\n      return EvalGatherNd<int64_t>(context, params, indices, output);\n    default:\n      context->ReportError(\n          context, \"Indices of type '%s' are not supported by gather_nd.\",\n          TfLiteTypeGetName(indices->type));\n      return kTfLiteError;\n  }\n}\n}  // namespace gather_nd\n\nTfLiteRegistration* Register_GATHER_ND() {\n  static TfLiteRegistration r = {/*init*/ nullptr, /*free*/ nullptr,\n                                 gather_nd::Prepare, gather_nd::Eval};\n  return &r;\n}\n}  // namespace builtin\n}  // namespace ops\n}  // namespace tflite\n"], "fixing_code": ["/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <stdint.h>\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/optimized/optimized_ops.h\"\n#include \"tensorflow/lite/kernels/internal/reference/reference_ops.h\"\n#include \"tensorflow/lite/kernels/internal/tensor.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace builtin {\nnamespace gather_nd {\nconstexpr int kParams = 0;\nconstexpr int kIndices = 1;\nconstexpr int kOutputTensor = 0;\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* params;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kParams, &params));\n  const TfLiteTensor* indices;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kIndices, &indices));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  switch (params->type) {\n    case kTfLiteFloat32:\n    case kTfLiteUInt8:\n    case kTfLiteInt8:\n    case kTfLiteInt16:\n    case kTfLiteInt64:\n    case kTfLiteInt32:\n    case kTfLiteString:\n      break;\n    default:\n      context->ReportError(\n          context, \"Params of type '%s' are not supported by gather_nd.\",\n          TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n  }\n  switch (indices->type) {\n    case kTfLiteInt64:\n    case kTfLiteInt32:\n      break;\n    default:\n      context->ReportError(\n          context, \"Indices of type '%s' are not supported by gather_nd.\",\n          TfLiteTypeGetName(indices->type));\n      return kTfLiteError;\n  }\n\n  const int params_rank = NumDimensions(params);\n  const int indices_rank = NumDimensions(indices);\n  const int indices_nd = SizeOfDimension(indices, indices_rank - 1);\n  if (params_rank < 1) {\n    context->ReportError(context, \"Params must be at least a vector.\");\n    return kTfLiteError;\n  }\n  if (indices_rank < 1) {\n    context->ReportError(context, \"Indices must be at least a vector.\");\n    return kTfLiteError;\n  }\n  if (indices_nd > params_rank) {\n    context->ReportError(\n        context, \"Index innermost dimension length must be <= params rank.\");\n    return kTfLiteError;\n  }\n\n  // Assign to output the input type.\n  output->type = params->type;\n\n  // The result shape is\n  // indices.shape[:-1] + params.shape[indices.shape[-1]:]\n  const int output_rank = indices_rank + params_rank - indices_nd - 1;\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(output_rank);\n  int output_index = 0;\n  for (int i = 0; i < indices_rank - 1; ++i) {\n    output_shape->data[output_index++] = indices->dims->data[i];\n  }\n  for (int i = indices_nd; i < params_rank; ++i) {\n    output_shape->data[output_index++] = params->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}\n\ntemplate <typename ParamsT, typename IndicesT>\nTfLiteStatus GatherNd(const TfLiteTensor* params, const TfLiteTensor* indices,\n                      TfLiteTensor* output) {\n  reference_ops::GatherNd(\n      GetTensorShape(params), GetTensorData<ParamsT>(params),\n      GetTensorShape(indices), GetTensorData<IndicesT>(indices),\n      GetTensorShape(output), GetTensorData<ParamsT>(output));\n  return kTfLiteOk;\n}\n\ntemplate <typename IndicesT>\nTfLiteStatus GatherNdString(const TfLiteTensor* params,\n                            const TfLiteTensor* indices, TfLiteTensor* output) {\n  reference_ops::GatherNdString(\n      GetTensorShape(params), params, GetTensorShape(indices),\n      GetTensorData<IndicesT>(indices), GetTensorShape(output), output);\n  return kTfLiteOk;\n}\n\ntemplate <typename IndicesT>\nTfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                          const TfLiteTensor* indices, TfLiteTensor* output) {\n  switch (params->type) {\n    case kTfLiteFloat32:\n      return GatherNd<float, IndicesT>(params, indices, output);\n    case kTfLiteUInt8:\n      return GatherNd<uint8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt8:\n      return GatherNd<int8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt16:\n      return GatherNd<int16_t, IndicesT>(params, indices, output);\n    case kTfLiteInt32:\n      return GatherNd<int32_t, IndicesT>(params, indices, output);\n    case kTfLiteInt64:\n      return GatherNd<int64_t, IndicesT>(params, indices, output);\n    case kTfLiteString:\n      return GatherNdString<IndicesT>(params, indices, output);\n    default:\n      context->ReportError(context,\n                           \"Params type '%s' are not supported by gather_nd.\",\n                           TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n  }\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* params;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kParams, &params));\n  const TfLiteTensor* indices;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kIndices, &indices));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // Prevent division by 0 in the helper\n  TF_LITE_ENSURE(context, NumElements(params) > 0);\n\n  switch (indices->type) {\n    case kTfLiteInt32:\n      return EvalGatherNd<int32_t>(context, params, indices, output);\n    case kTfLiteInt64:\n      return EvalGatherNd<int64_t>(context, params, indices, output);\n    default:\n      context->ReportError(\n          context, \"Indices of type '%s' are not supported by gather_nd.\",\n          TfLiteTypeGetName(indices->type));\n      return kTfLiteError;\n  }\n}\n}  // namespace gather_nd\n\nTfLiteRegistration* Register_GATHER_ND() {\n  static TfLiteRegistration r = {/*init*/ nullptr, /*free*/ nullptr,\n                                 gather_nd::Prepare, gather_nd::Eval};\n  return &r;\n}\n}  // namespace builtin\n}  // namespace ops\n}  // namespace tflite\n"], "filenames": ["tensorflow/lite/kernels/gather_nd.cc"], "buggy_code_start_loc": [157], "buggy_code_end_loc": [157], "fixing_code_start_loc": [158], "fixing_code_end_loc": [161], "type": "CWE-369", "message": "TensorFlow is an end-to-end open source platform for machine learning. The reference implementation of the `GatherNd` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7/tensorflow/lite/kernels/internal/reference/reference_ops.h#L966). An attacker can craft a model such that `params` input would be an empty tensor. In turn, `params_shape.Dims(.)` would be zero, in at least one dimension. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-29589", "sourceIdentifier": "security-advisories@github.com", "published": "2021-05-14T20:15:14.770", "lastModified": "2021-07-26T16:15:17.943", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an end-to-end open source platform for machine learning. The reference implementation of the `GatherNd` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7/tensorflow/lite/kernels/internal/reference/reference_ops.h#L966). An attacker can craft a model such that `params` input would be an empty tensor. In turn, `params_shape.Dims(.)` would be zero, in at least one dimension. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto de extremo a extremo para el aprendizaje autom\u00e1tico.&#xa0;La implementaci\u00f3n de referencia del operador TFLite \"GatherNd\" es vulnerable a un error de divisi\u00f3n por cero (https://github.com/tensorflow/tensorflow/blob/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7/tensorflow/lite/kernels/internal/reference/reference_ops.h#L966 ).&#xa0;Un atacante puede dise\u00f1ar un modelo tal que la entrada de \"params\" sea un tensor vac\u00edo.&#xa0;A su vez, la funci\u00f3n \"params_shape.Dims(.)\" ser\u00eda cero, en al menos una dimensi\u00f3n.&#xa0;La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.5.0.&#xa0;Tambi\u00e9n seleccionaremos este commit en TensorFlow versi\u00f3n 2.4.2, TensorFlow versi\u00f3n 2.3.3, TensorFlow versi\u00f3n 2.2.3 y TensorFlow versi\u00f3n 2.1.4, ya que estos tambi\u00e9n est\u00e1n afectados y a\u00fan est\u00e1n en el rango compatible"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:N/I:N/A:L", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "LOW", "baseScore": 2.5, "baseSeverity": "LOW"}, "exploitabilityScore": 1.0, "impactScore": 1.4}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 4.6}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-369"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.1.4", "matchCriteriaId": "323ABCCE-24EB-47CC-87F6-48C101477587"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.2.0", "versionEndExcluding": "2.2.3", "matchCriteriaId": "64ABA90C-0649-4BB0-89C9-83C14BBDCC0F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.3", "matchCriteriaId": "0F83E0CF-CBF6-4C24-8683-3E7A5DC95BA9"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.2", "matchCriteriaId": "8259531B-A8AC-4F8B-B60F-B69DE4767C03"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/8e45822aa0b9f5df4b4c64f221e64dc930a70a9d", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-3w67-q784-6w7c", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/8e45822aa0b9f5df4b4c64f221e64dc930a70a9d"}}
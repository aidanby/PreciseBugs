{"buggy_code": ["/*\n * Copyright (c) 2006, 2018 Oracle and/or its affiliates. All rights reserved.\n *\n * This software is available to you under a choice of one of two\n * licenses.  You may choose to be licensed under the terms of the GNU\n * General Public License (GPL) Version 2, available from the file\n * COPYING in the main directory of this source tree, or the\n * OpenIB.org BSD license below:\n *\n *     Redistribution and use in source and binary forms, with or\n *     without modification, are permitted provided that the following\n *     conditions are met:\n *\n *      - Redistributions of source code must retain the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer.\n *\n *      - Redistributions in binary form must reproduce the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer in the documentation and/or other materials\n *        provided with the distribution.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/in.h>\n#include <linux/module.h>\n#include <net/tcp.h>\n#include <net/net_namespace.h>\n#include <net/netns/generic.h>\n#include <net/addrconf.h>\n\n#include \"rds.h\"\n#include \"tcp.h\"\n\n/* only for info exporting */\nstatic DEFINE_SPINLOCK(rds_tcp_tc_list_lock);\nstatic LIST_HEAD(rds_tcp_tc_list);\n\n/* rds_tcp_tc_count counts only IPv4 connections.\n * rds6_tcp_tc_count counts both IPv4 and IPv6 connections.\n */\nstatic unsigned int rds_tcp_tc_count;\n#if IS_ENABLED(CONFIG_IPV6)\nstatic unsigned int rds6_tcp_tc_count;\n#endif\n\n/* Track rds_tcp_connection structs so they can be cleaned up */\nstatic DEFINE_SPINLOCK(rds_tcp_conn_lock);\nstatic LIST_HEAD(rds_tcp_conn_list);\nstatic atomic_t rds_tcp_unloading = ATOMIC_INIT(0);\n\nstatic struct kmem_cache *rds_tcp_conn_slab;\n\nstatic int rds_tcp_skbuf_handler(struct ctl_table *ctl, int write,\n\t\t\t\t void __user *buffer, size_t *lenp,\n\t\t\t\t loff_t *fpos);\n\nstatic int rds_tcp_min_sndbuf = SOCK_MIN_SNDBUF;\nstatic int rds_tcp_min_rcvbuf = SOCK_MIN_RCVBUF;\n\nstatic struct ctl_table rds_tcp_sysctl_table[] = {\n#define\tRDS_TCP_SNDBUF\t0\n\t{\n\t\t.procname       = \"rds_tcp_sndbuf\",\n\t\t/* data is per-net pointer */\n\t\t.maxlen         = sizeof(int),\n\t\t.mode           = 0644,\n\t\t.proc_handler   = rds_tcp_skbuf_handler,\n\t\t.extra1\t\t= &rds_tcp_min_sndbuf,\n\t},\n#define\tRDS_TCP_RCVBUF\t1\n\t{\n\t\t.procname       = \"rds_tcp_rcvbuf\",\n\t\t/* data is per-net pointer */\n\t\t.maxlen         = sizeof(int),\n\t\t.mode           = 0644,\n\t\t.proc_handler   = rds_tcp_skbuf_handler,\n\t\t.extra1\t\t= &rds_tcp_min_rcvbuf,\n\t},\n\t{ }\n};\n\n/* doing it this way avoids calling tcp_sk() */\nvoid rds_tcp_nonagle(struct socket *sock)\n{\n\tint val = 1;\n\n\tkernel_setsockopt(sock, SOL_TCP, TCP_NODELAY, (void *)&val,\n\t\t\t      sizeof(val));\n}\n\nu32 rds_tcp_write_seq(struct rds_tcp_connection *tc)\n{\n\t/* seq# of the last byte of data in tcp send buffer */\n\treturn tcp_sk(tc->t_sock->sk)->write_seq;\n}\n\nu32 rds_tcp_snd_una(struct rds_tcp_connection *tc)\n{\n\treturn tcp_sk(tc->t_sock->sk)->snd_una;\n}\n\nvoid rds_tcp_restore_callbacks(struct socket *sock,\n\t\t\t       struct rds_tcp_connection *tc)\n{\n\trdsdebug(\"restoring sock %p callbacks from tc %p\\n\", sock, tc);\n\twrite_lock_bh(&sock->sk->sk_callback_lock);\n\n\t/* done under the callback_lock to serialize with write_space */\n\tspin_lock(&rds_tcp_tc_list_lock);\n\tlist_del_init(&tc->t_list_item);\n#if IS_ENABLED(CONFIG_IPV6)\n\trds6_tcp_tc_count--;\n#endif\n\tif (!tc->t_cpath->cp_conn->c_isv6)\n\t\trds_tcp_tc_count--;\n\tspin_unlock(&rds_tcp_tc_list_lock);\n\n\ttc->t_sock = NULL;\n\n\tsock->sk->sk_write_space = tc->t_orig_write_space;\n\tsock->sk->sk_data_ready = tc->t_orig_data_ready;\n\tsock->sk->sk_state_change = tc->t_orig_state_change;\n\tsock->sk->sk_user_data = NULL;\n\n\twrite_unlock_bh(&sock->sk->sk_callback_lock);\n}\n\n/*\n * rds_tcp_reset_callbacks() switches the to the new sock and\n * returns the existing tc->t_sock.\n *\n * The only functions that set tc->t_sock are rds_tcp_set_callbacks\n * and rds_tcp_reset_callbacks.  Send and receive trust that\n * it is set.  The absence of RDS_CONN_UP bit protects those paths\n * from being called while it isn't set.\n */\nvoid rds_tcp_reset_callbacks(struct socket *sock,\n\t\t\t     struct rds_conn_path *cp)\n{\n\tstruct rds_tcp_connection *tc = cp->cp_transport_data;\n\tstruct socket *osock = tc->t_sock;\n\n\tif (!osock)\n\t\tgoto newsock;\n\n\t/* Need to resolve a duelling SYN between peers.\n\t * We have an outstanding SYN to this peer, which may\n\t * potentially have transitioned to the RDS_CONN_UP state,\n\t * so we must quiesce any send threads before resetting\n\t * cp_transport_data. We quiesce these threads by setting\n\t * cp_state to something other than RDS_CONN_UP, and then\n\t * waiting for any existing threads in rds_send_xmit to\n\t * complete release_in_xmit(). (Subsequent threads entering\n\t * rds_send_xmit() will bail on !rds_conn_up().\n\t *\n\t * However an incoming syn-ack at this point would end up\n\t * marking the conn as RDS_CONN_UP, and would again permit\n\t * rds_send_xmi() threads through, so ideally we would\n\t * synchronize on RDS_CONN_UP after lock_sock(), but cannot\n\t * do that: waiting on !RDS_IN_XMIT after lock_sock() may\n\t * end up deadlocking with tcp_sendmsg(), and the RDS_IN_XMIT\n\t * would not get set. As a result, we set c_state to\n\t * RDS_CONN_RESETTTING, to ensure that rds_tcp_state_change\n\t * cannot mark rds_conn_path_up() in the window before lock_sock()\n\t */\n\tatomic_set(&cp->cp_state, RDS_CONN_RESETTING);\n\twait_event(cp->cp_waitq, !test_bit(RDS_IN_XMIT, &cp->cp_flags));\n\tlock_sock(osock->sk);\n\t/* reset receive side state for rds_tcp_data_recv() for osock  */\n\tcancel_delayed_work_sync(&cp->cp_send_w);\n\tcancel_delayed_work_sync(&cp->cp_recv_w);\n\tif (tc->t_tinc) {\n\t\trds_inc_put(&tc->t_tinc->ti_inc);\n\t\ttc->t_tinc = NULL;\n\t}\n\ttc->t_tinc_hdr_rem = sizeof(struct rds_header);\n\ttc->t_tinc_data_rem = 0;\n\trds_tcp_restore_callbacks(osock, tc);\n\trelease_sock(osock->sk);\n\tsock_release(osock);\nnewsock:\n\trds_send_path_reset(cp);\n\tlock_sock(sock->sk);\n\trds_tcp_set_callbacks(sock, cp);\n\trelease_sock(sock->sk);\n}\n\n/* Add tc to rds_tcp_tc_list and set tc->t_sock. See comments\n * above rds_tcp_reset_callbacks for notes about synchronization\n * with data path\n */\nvoid rds_tcp_set_callbacks(struct socket *sock, struct rds_conn_path *cp)\n{\n\tstruct rds_tcp_connection *tc = cp->cp_transport_data;\n\n\trdsdebug(\"setting sock %p callbacks to tc %p\\n\", sock, tc);\n\twrite_lock_bh(&sock->sk->sk_callback_lock);\n\n\t/* done under the callback_lock to serialize with write_space */\n\tspin_lock(&rds_tcp_tc_list_lock);\n\tlist_add_tail(&tc->t_list_item, &rds_tcp_tc_list);\n#if IS_ENABLED(CONFIG_IPV6)\n\trds6_tcp_tc_count++;\n#endif\n\tif (!tc->t_cpath->cp_conn->c_isv6)\n\t\trds_tcp_tc_count++;\n\tspin_unlock(&rds_tcp_tc_list_lock);\n\n\t/* accepted sockets need our listen data ready undone */\n\tif (sock->sk->sk_data_ready == rds_tcp_listen_data_ready)\n\t\tsock->sk->sk_data_ready = sock->sk->sk_user_data;\n\n\ttc->t_sock = sock;\n\ttc->t_cpath = cp;\n\ttc->t_orig_data_ready = sock->sk->sk_data_ready;\n\ttc->t_orig_write_space = sock->sk->sk_write_space;\n\ttc->t_orig_state_change = sock->sk->sk_state_change;\n\n\tsock->sk->sk_user_data = cp;\n\tsock->sk->sk_data_ready = rds_tcp_data_ready;\n\tsock->sk->sk_write_space = rds_tcp_write_space;\n\tsock->sk->sk_state_change = rds_tcp_state_change;\n\n\twrite_unlock_bh(&sock->sk->sk_callback_lock);\n}\n\n/* Handle RDS_INFO_TCP_SOCKETS socket option.  It only returns IPv4\n * connections for backward compatibility.\n */\nstatic void rds_tcp_tc_info(struct socket *rds_sock, unsigned int len,\n\t\t\t    struct rds_info_iterator *iter,\n\t\t\t    struct rds_info_lengths *lens)\n{\n\tstruct rds_info_tcp_socket tsinfo;\n\tstruct rds_tcp_connection *tc;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rds_tcp_tc_list_lock, flags);\n\n\tif (len / sizeof(tsinfo) < rds_tcp_tc_count)\n\t\tgoto out;\n\n\tlist_for_each_entry(tc, &rds_tcp_tc_list, t_list_item) {\n\t\tstruct inet_sock *inet = inet_sk(tc->t_sock->sk);\n\n\t\tif (tc->t_cpath->cp_conn->c_isv6)\n\t\t\tcontinue;\n\n\t\ttsinfo.local_addr = inet->inet_saddr;\n\t\ttsinfo.local_port = inet->inet_sport;\n\t\ttsinfo.peer_addr = inet->inet_daddr;\n\t\ttsinfo.peer_port = inet->inet_dport;\n\n\t\ttsinfo.hdr_rem = tc->t_tinc_hdr_rem;\n\t\ttsinfo.data_rem = tc->t_tinc_data_rem;\n\t\ttsinfo.last_sent_nxt = tc->t_last_sent_nxt;\n\t\ttsinfo.last_expected_una = tc->t_last_expected_una;\n\t\ttsinfo.last_seen_una = tc->t_last_seen_una;\n\t\ttsinfo.tos = tc->t_cpath->cp_conn->c_tos;\n\n\t\trds_info_copy(iter, &tsinfo, sizeof(tsinfo));\n\t}\n\nout:\n\tlens->nr = rds_tcp_tc_count;\n\tlens->each = sizeof(tsinfo);\n\n\tspin_unlock_irqrestore(&rds_tcp_tc_list_lock, flags);\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\n/* Handle RDS6_INFO_TCP_SOCKETS socket option. It returns both IPv4 and\n * IPv6 connections. IPv4 connection address is returned in an IPv4 mapped\n * address.\n */\nstatic void rds6_tcp_tc_info(struct socket *sock, unsigned int len,\n\t\t\t     struct rds_info_iterator *iter,\n\t\t\t     struct rds_info_lengths *lens)\n{\n\tstruct rds6_info_tcp_socket tsinfo6;\n\tstruct rds_tcp_connection *tc;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rds_tcp_tc_list_lock, flags);\n\n\tif (len / sizeof(tsinfo6) < rds6_tcp_tc_count)\n\t\tgoto out;\n\n\tlist_for_each_entry(tc, &rds_tcp_tc_list, t_list_item) {\n\t\tstruct sock *sk = tc->t_sock->sk;\n\t\tstruct inet_sock *inet = inet_sk(sk);\n\n\t\ttsinfo6.local_addr = sk->sk_v6_rcv_saddr;\n\t\ttsinfo6.local_port = inet->inet_sport;\n\t\ttsinfo6.peer_addr = sk->sk_v6_daddr;\n\t\ttsinfo6.peer_port = inet->inet_dport;\n\n\t\ttsinfo6.hdr_rem = tc->t_tinc_hdr_rem;\n\t\ttsinfo6.data_rem = tc->t_tinc_data_rem;\n\t\ttsinfo6.last_sent_nxt = tc->t_last_sent_nxt;\n\t\ttsinfo6.last_expected_una = tc->t_last_expected_una;\n\t\ttsinfo6.last_seen_una = tc->t_last_seen_una;\n\n\t\trds_info_copy(iter, &tsinfo6, sizeof(tsinfo6));\n\t}\n\nout:\n\tlens->nr = rds6_tcp_tc_count;\n\tlens->each = sizeof(tsinfo6);\n\n\tspin_unlock_irqrestore(&rds_tcp_tc_list_lock, flags);\n}\n#endif\n\nstatic int rds_tcp_laddr_check(struct net *net, const struct in6_addr *addr,\n\t\t\t       __u32 scope_id)\n{\n\tstruct net_device *dev = NULL;\n#if IS_ENABLED(CONFIG_IPV6)\n\tint ret;\n#endif\n\n\tif (ipv6_addr_v4mapped(addr)) {\n\t\tif (inet_addr_type(net, addr->s6_addr32[3]) == RTN_LOCAL)\n\t\t\treturn 0;\n\t\treturn -EADDRNOTAVAIL;\n\t}\n\n\t/* If the scope_id is specified, check only those addresses\n\t * hosted on the specified interface.\n\t */\n\tif (scope_id != 0) {\n\t\trcu_read_lock();\n\t\tdev = dev_get_by_index_rcu(net, scope_id);\n\t\t/* scope_id is not valid... */\n\t\tif (!dev) {\n\t\t\trcu_read_unlock();\n\t\t\treturn -EADDRNOTAVAIL;\n\t\t}\n\t\trcu_read_unlock();\n\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\tret = ipv6_chk_addr(net, addr, dev, 0);\n\tif (ret)\n\t\treturn 0;\n#endif\n\treturn -EADDRNOTAVAIL;\n}\n\nstatic void rds_tcp_conn_free(void *arg)\n{\n\tstruct rds_tcp_connection *tc = arg;\n\tunsigned long flags;\n\n\trdsdebug(\"freeing tc %p\\n\", tc);\n\n\tspin_lock_irqsave(&rds_tcp_conn_lock, flags);\n\tif (!tc->t_tcp_node_detached)\n\t\tlist_del(&tc->t_tcp_node);\n\tspin_unlock_irqrestore(&rds_tcp_conn_lock, flags);\n\n\tkmem_cache_free(rds_tcp_conn_slab, tc);\n}\n\nstatic int rds_tcp_conn_alloc(struct rds_connection *conn, gfp_t gfp)\n{\n\tstruct rds_tcp_connection *tc;\n\tint i, j;\n\tint ret = 0;\n\n\tfor (i = 0; i < RDS_MPATH_WORKERS; i++) {\n\t\ttc = kmem_cache_alloc(rds_tcp_conn_slab, gfp);\n\t\tif (!tc) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\t\tmutex_init(&tc->t_conn_path_lock);\n\t\ttc->t_sock = NULL;\n\t\ttc->t_tinc = NULL;\n\t\ttc->t_tinc_hdr_rem = sizeof(struct rds_header);\n\t\ttc->t_tinc_data_rem = 0;\n\n\t\tconn->c_path[i].cp_transport_data = tc;\n\t\ttc->t_cpath = &conn->c_path[i];\n\t\ttc->t_tcp_node_detached = true;\n\n\t\trdsdebug(\"rds_conn_path [%d] tc %p\\n\", i,\n\t\t\t conn->c_path[i].cp_transport_data);\n\t}\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tfor (i = 0; i < RDS_MPATH_WORKERS; i++) {\n\t\ttc = conn->c_path[i].cp_transport_data;\n\t\ttc->t_tcp_node_detached = false;\n\t\tlist_add_tail(&tc->t_tcp_node, &rds_tcp_conn_list);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\nfail:\n\tif (ret) {\n\t\tfor (j = 0; j < i; j++)\n\t\t\trds_tcp_conn_free(conn->c_path[j].cp_transport_data);\n\t}\n\treturn ret;\n}\n\nstatic bool list_has_conn(struct list_head *list, struct rds_connection *conn)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\n\tlist_for_each_entry_safe(tc, _tc, list, t_tcp_node) {\n\t\tif (tc->t_cpath->cp_conn == conn)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic void rds_tcp_set_unloading(void)\n{\n\tatomic_set(&rds_tcp_unloading, 1);\n}\n\nstatic bool rds_tcp_is_unloading(struct rds_connection *conn)\n{\n\treturn atomic_read(&rds_tcp_unloading) != 0;\n}\n\nstatic void rds_tcp_destroy_conns(void)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tLIST_HEAD(tmp_list);\n\n\t/* avoid calling conn_destroy with irqs off */\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tif (!list_has_conn(&tmp_list, tc->t_cpath->cp_conn))\n\t\t\tlist_move_tail(&tc->t_tcp_node, &tmp_list);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node)\n\t\trds_conn_destroy(tc->t_cpath->cp_conn);\n}\n\nstatic void rds_tcp_exit(void);\n\nstatic u8 rds_tcp_get_tos_map(u8 tos)\n{\n\t/* all user tos mapped to default 0 for TCP transport */\n\treturn 0;\n}\n\nstruct rds_transport rds_tcp_transport = {\n\t.laddr_check\t\t= rds_tcp_laddr_check,\n\t.xmit_path_prepare\t= rds_tcp_xmit_path_prepare,\n\t.xmit_path_complete\t= rds_tcp_xmit_path_complete,\n\t.xmit\t\t\t= rds_tcp_xmit,\n\t.recv_path\t\t= rds_tcp_recv_path,\n\t.conn_alloc\t\t= rds_tcp_conn_alloc,\n\t.conn_free\t\t= rds_tcp_conn_free,\n\t.conn_path_connect\t= rds_tcp_conn_path_connect,\n\t.conn_path_shutdown\t= rds_tcp_conn_path_shutdown,\n\t.inc_copy_to_user\t= rds_tcp_inc_copy_to_user,\n\t.inc_free\t\t= rds_tcp_inc_free,\n\t.stats_info_copy\t= rds_tcp_stats_info_copy,\n\t.exit\t\t\t= rds_tcp_exit,\n\t.get_tos_map\t\t= rds_tcp_get_tos_map,\n\t.t_owner\t\t= THIS_MODULE,\n\t.t_name\t\t\t= \"tcp\",\n\t.t_type\t\t\t= RDS_TRANS_TCP,\n\t.t_prefer_loopback\t= 1,\n\t.t_mp_capable\t\t= 1,\n\t.t_unloading\t\t= rds_tcp_is_unloading,\n};\n\nstatic unsigned int rds_tcp_netid;\n\n/* per-network namespace private data for this module */\nstruct rds_tcp_net {\n\tstruct socket *rds_tcp_listen_sock;\n\tstruct work_struct rds_tcp_accept_w;\n\tstruct ctl_table_header *rds_tcp_sysctl;\n\tstruct ctl_table *ctl_table;\n\tint sndbuf_size;\n\tint rcvbuf_size;\n};\n\n/* All module specific customizations to the RDS-TCP socket should be done in\n * rds_tcp_tune() and applied after socket creation.\n */\nvoid rds_tcp_tune(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trds_tcp_nonagle(sock);\n\tlock_sock(sk);\n\tif (rtn->sndbuf_size > 0) {\n\t\tsk->sk_sndbuf = rtn->sndbuf_size;\n\t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n\t}\n\tif (rtn->rcvbuf_size > 0) {\n\t\tsk->sk_sndbuf = rtn->rcvbuf_size;\n\t\tsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\n\t}\n\trelease_sock(sk);\n}\n\nstatic void rds_tcp_accept_worker(struct work_struct *work)\n{\n\tstruct rds_tcp_net *rtn = container_of(work,\n\t\t\t\t\t       struct rds_tcp_net,\n\t\t\t\t\t       rds_tcp_accept_w);\n\n\twhile (rds_tcp_accept_one(rtn->rds_tcp_listen_sock) == 0)\n\t\tcond_resched();\n}\n\nvoid rds_tcp_accept_work(struct sock *sk)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\tqueue_work(rds_wq, &rtn->rds_tcp_accept_w);\n}\n\nstatic __net_init int rds_tcp_init_net(struct net *net)\n{\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\tstruct ctl_table *tbl;\n\tint err = 0;\n\n\tmemset(rtn, 0, sizeof(*rtn));\n\n\t/* {snd, rcv}buf_size default to 0, which implies we let the\n\t * stack pick the value, and permit auto-tuning of buffer size.\n\t */\n\tif (net == &init_net) {\n\t\ttbl = rds_tcp_sysctl_table;\n\t} else {\n\t\ttbl = kmemdup(rds_tcp_sysctl_table,\n\t\t\t      sizeof(rds_tcp_sysctl_table), GFP_KERNEL);\n\t\tif (!tbl) {\n\t\t\tpr_warn(\"could not set allocate syctl table\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\trtn->ctl_table = tbl;\n\t}\n\ttbl[RDS_TCP_SNDBUF].data = &rtn->sndbuf_size;\n\ttbl[RDS_TCP_RCVBUF].data = &rtn->rcvbuf_size;\n\trtn->rds_tcp_sysctl = register_net_sysctl(net, \"net/rds/tcp\", tbl);\n\tif (!rtn->rds_tcp_sysctl) {\n\t\tpr_warn(\"could not register sysctl\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n#if IS_ENABLED(CONFIG_IPV6)\n\trtn->rds_tcp_listen_sock = rds_tcp_listen_init(net, true);\n#else\n\trtn->rds_tcp_listen_sock = rds_tcp_listen_init(net, false);\n#endif\n\tif (!rtn->rds_tcp_listen_sock) {\n\t\tpr_warn(\"could not set up IPv6 listen sock\\n\");\n\n#if IS_ENABLED(CONFIG_IPV6)\n\t\t/* Try IPv4 as some systems disable IPv6 */\n\t\trtn->rds_tcp_listen_sock = rds_tcp_listen_init(net, false);\n\t\tif (!rtn->rds_tcp_listen_sock) {\n#endif\n\t\t\tunregister_net_sysctl_table(rtn->rds_tcp_sysctl);\n\t\t\trtn->rds_tcp_sysctl = NULL;\n\t\t\terr = -EAFNOSUPPORT;\n\t\t\tgoto fail;\n#if IS_ENABLED(CONFIG_IPV6)\n\t\t}\n#endif\n\t}\n\tINIT_WORK(&rtn->rds_tcp_accept_w, rds_tcp_accept_worker);\n\treturn 0;\n\nfail:\n\tif (net != &init_net)\n\t\tkfree(tbl);\n\treturn err;\n}\n\nstatic void rds_tcp_kill_sock(struct net *net)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tLIST_HEAD(tmp_list);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\tstruct socket *lsock = rtn->rds_tcp_listen_sock;\n\n\trtn->rds_tcp_listen_sock = NULL;\n\trds_tcp_listen_stop(lsock, &rtn->rds_tcp_accept_w);\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tstruct net *c_net = read_pnet(&tc->t_cpath->cp_conn->c_net);\n\n\t\tif (net != c_net || !tc->t_sock)\n\t\t\tcontinue;\n\t\tif (!list_has_conn(&tmp_list, tc->t_cpath->cp_conn)) {\n\t\t\tlist_move_tail(&tc->t_tcp_node, &tmp_list);\n\t\t} else {\n\t\t\tlist_del(&tc->t_tcp_node);\n\t\t\ttc->t_tcp_node_detached = true;\n\t\t}\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node)\n\t\trds_conn_destroy(tc->t_cpath->cp_conn);\n}\n\nstatic void __net_exit rds_tcp_exit_net(struct net *net)\n{\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trds_tcp_kill_sock(net);\n\n\tif (rtn->rds_tcp_sysctl)\n\t\tunregister_net_sysctl_table(rtn->rds_tcp_sysctl);\n\n\tif (net != &init_net)\n\t\tkfree(rtn->ctl_table);\n}\n\nstatic struct pernet_operations rds_tcp_net_ops = {\n\t.init = rds_tcp_init_net,\n\t.exit = rds_tcp_exit_net,\n\t.id = &rds_tcp_netid,\n\t.size = sizeof(struct rds_tcp_net),\n};\n\nvoid *rds_tcp_listen_sock_def_readable(struct net *net)\n{\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\tstruct socket *lsock = rtn->rds_tcp_listen_sock;\n\n\tif (!lsock)\n\t\treturn NULL;\n\n\treturn lsock->sk->sk_user_data;\n}\n\n/* when sysctl is used to modify some kernel socket parameters,this\n * function  resets the RDS connections in that netns  so that we can\n * restart with new parameters.  The assumption is that such reset\n * events are few and far-between.\n */\nstatic void rds_tcp_sysctl_reset(struct net *net)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tstruct net *c_net = read_pnet(&tc->t_cpath->cp_conn->c_net);\n\n\t\tif (net != c_net || !tc->t_sock)\n\t\t\tcontinue;\n\n\t\t/* reconnect with new parameters */\n\t\trds_conn_path_drop(tc->t_cpath, false);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n}\n\nstatic int rds_tcp_skbuf_handler(struct ctl_table *ctl, int write,\n\t\t\t\t void __user *buffer, size_t *lenp,\n\t\t\t\t loff_t *fpos)\n{\n\tstruct net *net = current->nsproxy->net_ns;\n\tint err;\n\n\terr = proc_dointvec_minmax(ctl, write, buffer, lenp, fpos);\n\tif (err < 0) {\n\t\tpr_warn(\"Invalid input. Must be >= %d\\n\",\n\t\t\t*(int *)(ctl->extra1));\n\t\treturn err;\n\t}\n\tif (write)\n\t\trds_tcp_sysctl_reset(net);\n\treturn 0;\n}\n\nstatic void rds_tcp_exit(void)\n{\n\trds_tcp_set_unloading();\n\tsynchronize_rcu();\n\trds_info_deregister_func(RDS_INFO_TCP_SOCKETS, rds_tcp_tc_info);\n#if IS_ENABLED(CONFIG_IPV6)\n\trds_info_deregister_func(RDS6_INFO_TCP_SOCKETS, rds6_tcp_tc_info);\n#endif\n\tunregister_pernet_device(&rds_tcp_net_ops);\n\trds_tcp_destroy_conns();\n\trds_trans_unregister(&rds_tcp_transport);\n\trds_tcp_recv_exit();\n\tkmem_cache_destroy(rds_tcp_conn_slab);\n}\nmodule_exit(rds_tcp_exit);\n\nstatic int rds_tcp_init(void)\n{\n\tint ret;\n\n\trds_tcp_conn_slab = kmem_cache_create(\"rds_tcp_connection\",\n\t\t\t\t\t      sizeof(struct rds_tcp_connection),\n\t\t\t\t\t      0, 0, NULL);\n\tif (!rds_tcp_conn_slab) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tret = rds_tcp_recv_init();\n\tif (ret)\n\t\tgoto out_slab;\n\n\tret = register_pernet_device(&rds_tcp_net_ops);\n\tif (ret)\n\t\tgoto out_recv;\n\n\trds_trans_register(&rds_tcp_transport);\n\n\trds_info_register_func(RDS_INFO_TCP_SOCKETS, rds_tcp_tc_info);\n#if IS_ENABLED(CONFIG_IPV6)\n\trds_info_register_func(RDS6_INFO_TCP_SOCKETS, rds6_tcp_tc_info);\n#endif\n\n\tgoto out;\nout_recv:\n\trds_tcp_recv_exit();\nout_slab:\n\tkmem_cache_destroy(rds_tcp_conn_slab);\nout:\n\treturn ret;\n}\nmodule_init(rds_tcp_init);\n\nMODULE_AUTHOR(\"Oracle Corporation <rds-devel@oss.oracle.com>\");\nMODULE_DESCRIPTION(\"RDS: TCP transport\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\n"], "fixing_code": ["/*\n * Copyright (c) 2006, 2018 Oracle and/or its affiliates. All rights reserved.\n *\n * This software is available to you under a choice of one of two\n * licenses.  You may choose to be licensed under the terms of the GNU\n * General Public License (GPL) Version 2, available from the file\n * COPYING in the main directory of this source tree, or the\n * OpenIB.org BSD license below:\n *\n *     Redistribution and use in source and binary forms, with or\n *     without modification, are permitted provided that the following\n *     conditions are met:\n *\n *      - Redistributions of source code must retain the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer.\n *\n *      - Redistributions in binary form must reproduce the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer in the documentation and/or other materials\n *        provided with the distribution.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/in.h>\n#include <linux/module.h>\n#include <net/tcp.h>\n#include <net/net_namespace.h>\n#include <net/netns/generic.h>\n#include <net/addrconf.h>\n\n#include \"rds.h\"\n#include \"tcp.h\"\n\n/* only for info exporting */\nstatic DEFINE_SPINLOCK(rds_tcp_tc_list_lock);\nstatic LIST_HEAD(rds_tcp_tc_list);\n\n/* rds_tcp_tc_count counts only IPv4 connections.\n * rds6_tcp_tc_count counts both IPv4 and IPv6 connections.\n */\nstatic unsigned int rds_tcp_tc_count;\n#if IS_ENABLED(CONFIG_IPV6)\nstatic unsigned int rds6_tcp_tc_count;\n#endif\n\n/* Track rds_tcp_connection structs so they can be cleaned up */\nstatic DEFINE_SPINLOCK(rds_tcp_conn_lock);\nstatic LIST_HEAD(rds_tcp_conn_list);\nstatic atomic_t rds_tcp_unloading = ATOMIC_INIT(0);\n\nstatic struct kmem_cache *rds_tcp_conn_slab;\n\nstatic int rds_tcp_skbuf_handler(struct ctl_table *ctl, int write,\n\t\t\t\t void __user *buffer, size_t *lenp,\n\t\t\t\t loff_t *fpos);\n\nstatic int rds_tcp_min_sndbuf = SOCK_MIN_SNDBUF;\nstatic int rds_tcp_min_rcvbuf = SOCK_MIN_RCVBUF;\n\nstatic struct ctl_table rds_tcp_sysctl_table[] = {\n#define\tRDS_TCP_SNDBUF\t0\n\t{\n\t\t.procname       = \"rds_tcp_sndbuf\",\n\t\t/* data is per-net pointer */\n\t\t.maxlen         = sizeof(int),\n\t\t.mode           = 0644,\n\t\t.proc_handler   = rds_tcp_skbuf_handler,\n\t\t.extra1\t\t= &rds_tcp_min_sndbuf,\n\t},\n#define\tRDS_TCP_RCVBUF\t1\n\t{\n\t\t.procname       = \"rds_tcp_rcvbuf\",\n\t\t/* data is per-net pointer */\n\t\t.maxlen         = sizeof(int),\n\t\t.mode           = 0644,\n\t\t.proc_handler   = rds_tcp_skbuf_handler,\n\t\t.extra1\t\t= &rds_tcp_min_rcvbuf,\n\t},\n\t{ }\n};\n\n/* doing it this way avoids calling tcp_sk() */\nvoid rds_tcp_nonagle(struct socket *sock)\n{\n\tint val = 1;\n\n\tkernel_setsockopt(sock, SOL_TCP, TCP_NODELAY, (void *)&val,\n\t\t\t      sizeof(val));\n}\n\nu32 rds_tcp_write_seq(struct rds_tcp_connection *tc)\n{\n\t/* seq# of the last byte of data in tcp send buffer */\n\treturn tcp_sk(tc->t_sock->sk)->write_seq;\n}\n\nu32 rds_tcp_snd_una(struct rds_tcp_connection *tc)\n{\n\treturn tcp_sk(tc->t_sock->sk)->snd_una;\n}\n\nvoid rds_tcp_restore_callbacks(struct socket *sock,\n\t\t\t       struct rds_tcp_connection *tc)\n{\n\trdsdebug(\"restoring sock %p callbacks from tc %p\\n\", sock, tc);\n\twrite_lock_bh(&sock->sk->sk_callback_lock);\n\n\t/* done under the callback_lock to serialize with write_space */\n\tspin_lock(&rds_tcp_tc_list_lock);\n\tlist_del_init(&tc->t_list_item);\n#if IS_ENABLED(CONFIG_IPV6)\n\trds6_tcp_tc_count--;\n#endif\n\tif (!tc->t_cpath->cp_conn->c_isv6)\n\t\trds_tcp_tc_count--;\n\tspin_unlock(&rds_tcp_tc_list_lock);\n\n\ttc->t_sock = NULL;\n\n\tsock->sk->sk_write_space = tc->t_orig_write_space;\n\tsock->sk->sk_data_ready = tc->t_orig_data_ready;\n\tsock->sk->sk_state_change = tc->t_orig_state_change;\n\tsock->sk->sk_user_data = NULL;\n\n\twrite_unlock_bh(&sock->sk->sk_callback_lock);\n}\n\n/*\n * rds_tcp_reset_callbacks() switches the to the new sock and\n * returns the existing tc->t_sock.\n *\n * The only functions that set tc->t_sock are rds_tcp_set_callbacks\n * and rds_tcp_reset_callbacks.  Send and receive trust that\n * it is set.  The absence of RDS_CONN_UP bit protects those paths\n * from being called while it isn't set.\n */\nvoid rds_tcp_reset_callbacks(struct socket *sock,\n\t\t\t     struct rds_conn_path *cp)\n{\n\tstruct rds_tcp_connection *tc = cp->cp_transport_data;\n\tstruct socket *osock = tc->t_sock;\n\n\tif (!osock)\n\t\tgoto newsock;\n\n\t/* Need to resolve a duelling SYN between peers.\n\t * We have an outstanding SYN to this peer, which may\n\t * potentially have transitioned to the RDS_CONN_UP state,\n\t * so we must quiesce any send threads before resetting\n\t * cp_transport_data. We quiesce these threads by setting\n\t * cp_state to something other than RDS_CONN_UP, and then\n\t * waiting for any existing threads in rds_send_xmit to\n\t * complete release_in_xmit(). (Subsequent threads entering\n\t * rds_send_xmit() will bail on !rds_conn_up().\n\t *\n\t * However an incoming syn-ack at this point would end up\n\t * marking the conn as RDS_CONN_UP, and would again permit\n\t * rds_send_xmi() threads through, so ideally we would\n\t * synchronize on RDS_CONN_UP after lock_sock(), but cannot\n\t * do that: waiting on !RDS_IN_XMIT after lock_sock() may\n\t * end up deadlocking with tcp_sendmsg(), and the RDS_IN_XMIT\n\t * would not get set. As a result, we set c_state to\n\t * RDS_CONN_RESETTTING, to ensure that rds_tcp_state_change\n\t * cannot mark rds_conn_path_up() in the window before lock_sock()\n\t */\n\tatomic_set(&cp->cp_state, RDS_CONN_RESETTING);\n\twait_event(cp->cp_waitq, !test_bit(RDS_IN_XMIT, &cp->cp_flags));\n\tlock_sock(osock->sk);\n\t/* reset receive side state for rds_tcp_data_recv() for osock  */\n\tcancel_delayed_work_sync(&cp->cp_send_w);\n\tcancel_delayed_work_sync(&cp->cp_recv_w);\n\tif (tc->t_tinc) {\n\t\trds_inc_put(&tc->t_tinc->ti_inc);\n\t\ttc->t_tinc = NULL;\n\t}\n\ttc->t_tinc_hdr_rem = sizeof(struct rds_header);\n\ttc->t_tinc_data_rem = 0;\n\trds_tcp_restore_callbacks(osock, tc);\n\trelease_sock(osock->sk);\n\tsock_release(osock);\nnewsock:\n\trds_send_path_reset(cp);\n\tlock_sock(sock->sk);\n\trds_tcp_set_callbacks(sock, cp);\n\trelease_sock(sock->sk);\n}\n\n/* Add tc to rds_tcp_tc_list and set tc->t_sock. See comments\n * above rds_tcp_reset_callbacks for notes about synchronization\n * with data path\n */\nvoid rds_tcp_set_callbacks(struct socket *sock, struct rds_conn_path *cp)\n{\n\tstruct rds_tcp_connection *tc = cp->cp_transport_data;\n\n\trdsdebug(\"setting sock %p callbacks to tc %p\\n\", sock, tc);\n\twrite_lock_bh(&sock->sk->sk_callback_lock);\n\n\t/* done under the callback_lock to serialize with write_space */\n\tspin_lock(&rds_tcp_tc_list_lock);\n\tlist_add_tail(&tc->t_list_item, &rds_tcp_tc_list);\n#if IS_ENABLED(CONFIG_IPV6)\n\trds6_tcp_tc_count++;\n#endif\n\tif (!tc->t_cpath->cp_conn->c_isv6)\n\t\trds_tcp_tc_count++;\n\tspin_unlock(&rds_tcp_tc_list_lock);\n\n\t/* accepted sockets need our listen data ready undone */\n\tif (sock->sk->sk_data_ready == rds_tcp_listen_data_ready)\n\t\tsock->sk->sk_data_ready = sock->sk->sk_user_data;\n\n\ttc->t_sock = sock;\n\ttc->t_cpath = cp;\n\ttc->t_orig_data_ready = sock->sk->sk_data_ready;\n\ttc->t_orig_write_space = sock->sk->sk_write_space;\n\ttc->t_orig_state_change = sock->sk->sk_state_change;\n\n\tsock->sk->sk_user_data = cp;\n\tsock->sk->sk_data_ready = rds_tcp_data_ready;\n\tsock->sk->sk_write_space = rds_tcp_write_space;\n\tsock->sk->sk_state_change = rds_tcp_state_change;\n\n\twrite_unlock_bh(&sock->sk->sk_callback_lock);\n}\n\n/* Handle RDS_INFO_TCP_SOCKETS socket option.  It only returns IPv4\n * connections for backward compatibility.\n */\nstatic void rds_tcp_tc_info(struct socket *rds_sock, unsigned int len,\n\t\t\t    struct rds_info_iterator *iter,\n\t\t\t    struct rds_info_lengths *lens)\n{\n\tstruct rds_info_tcp_socket tsinfo;\n\tstruct rds_tcp_connection *tc;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rds_tcp_tc_list_lock, flags);\n\n\tif (len / sizeof(tsinfo) < rds_tcp_tc_count)\n\t\tgoto out;\n\n\tlist_for_each_entry(tc, &rds_tcp_tc_list, t_list_item) {\n\t\tstruct inet_sock *inet = inet_sk(tc->t_sock->sk);\n\n\t\tif (tc->t_cpath->cp_conn->c_isv6)\n\t\t\tcontinue;\n\n\t\ttsinfo.local_addr = inet->inet_saddr;\n\t\ttsinfo.local_port = inet->inet_sport;\n\t\ttsinfo.peer_addr = inet->inet_daddr;\n\t\ttsinfo.peer_port = inet->inet_dport;\n\n\t\ttsinfo.hdr_rem = tc->t_tinc_hdr_rem;\n\t\ttsinfo.data_rem = tc->t_tinc_data_rem;\n\t\ttsinfo.last_sent_nxt = tc->t_last_sent_nxt;\n\t\ttsinfo.last_expected_una = tc->t_last_expected_una;\n\t\ttsinfo.last_seen_una = tc->t_last_seen_una;\n\t\ttsinfo.tos = tc->t_cpath->cp_conn->c_tos;\n\n\t\trds_info_copy(iter, &tsinfo, sizeof(tsinfo));\n\t}\n\nout:\n\tlens->nr = rds_tcp_tc_count;\n\tlens->each = sizeof(tsinfo);\n\n\tspin_unlock_irqrestore(&rds_tcp_tc_list_lock, flags);\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\n/* Handle RDS6_INFO_TCP_SOCKETS socket option. It returns both IPv4 and\n * IPv6 connections. IPv4 connection address is returned in an IPv4 mapped\n * address.\n */\nstatic void rds6_tcp_tc_info(struct socket *sock, unsigned int len,\n\t\t\t     struct rds_info_iterator *iter,\n\t\t\t     struct rds_info_lengths *lens)\n{\n\tstruct rds6_info_tcp_socket tsinfo6;\n\tstruct rds_tcp_connection *tc;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rds_tcp_tc_list_lock, flags);\n\n\tif (len / sizeof(tsinfo6) < rds6_tcp_tc_count)\n\t\tgoto out;\n\n\tlist_for_each_entry(tc, &rds_tcp_tc_list, t_list_item) {\n\t\tstruct sock *sk = tc->t_sock->sk;\n\t\tstruct inet_sock *inet = inet_sk(sk);\n\n\t\ttsinfo6.local_addr = sk->sk_v6_rcv_saddr;\n\t\ttsinfo6.local_port = inet->inet_sport;\n\t\ttsinfo6.peer_addr = sk->sk_v6_daddr;\n\t\ttsinfo6.peer_port = inet->inet_dport;\n\n\t\ttsinfo6.hdr_rem = tc->t_tinc_hdr_rem;\n\t\ttsinfo6.data_rem = tc->t_tinc_data_rem;\n\t\ttsinfo6.last_sent_nxt = tc->t_last_sent_nxt;\n\t\ttsinfo6.last_expected_una = tc->t_last_expected_una;\n\t\ttsinfo6.last_seen_una = tc->t_last_seen_una;\n\n\t\trds_info_copy(iter, &tsinfo6, sizeof(tsinfo6));\n\t}\n\nout:\n\tlens->nr = rds6_tcp_tc_count;\n\tlens->each = sizeof(tsinfo6);\n\n\tspin_unlock_irqrestore(&rds_tcp_tc_list_lock, flags);\n}\n#endif\n\nstatic int rds_tcp_laddr_check(struct net *net, const struct in6_addr *addr,\n\t\t\t       __u32 scope_id)\n{\n\tstruct net_device *dev = NULL;\n#if IS_ENABLED(CONFIG_IPV6)\n\tint ret;\n#endif\n\n\tif (ipv6_addr_v4mapped(addr)) {\n\t\tif (inet_addr_type(net, addr->s6_addr32[3]) == RTN_LOCAL)\n\t\t\treturn 0;\n\t\treturn -EADDRNOTAVAIL;\n\t}\n\n\t/* If the scope_id is specified, check only those addresses\n\t * hosted on the specified interface.\n\t */\n\tif (scope_id != 0) {\n\t\trcu_read_lock();\n\t\tdev = dev_get_by_index_rcu(net, scope_id);\n\t\t/* scope_id is not valid... */\n\t\tif (!dev) {\n\t\t\trcu_read_unlock();\n\t\t\treturn -EADDRNOTAVAIL;\n\t\t}\n\t\trcu_read_unlock();\n\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\tret = ipv6_chk_addr(net, addr, dev, 0);\n\tif (ret)\n\t\treturn 0;\n#endif\n\treturn -EADDRNOTAVAIL;\n}\n\nstatic void rds_tcp_conn_free(void *arg)\n{\n\tstruct rds_tcp_connection *tc = arg;\n\tunsigned long flags;\n\n\trdsdebug(\"freeing tc %p\\n\", tc);\n\n\tspin_lock_irqsave(&rds_tcp_conn_lock, flags);\n\tif (!tc->t_tcp_node_detached)\n\t\tlist_del(&tc->t_tcp_node);\n\tspin_unlock_irqrestore(&rds_tcp_conn_lock, flags);\n\n\tkmem_cache_free(rds_tcp_conn_slab, tc);\n}\n\nstatic int rds_tcp_conn_alloc(struct rds_connection *conn, gfp_t gfp)\n{\n\tstruct rds_tcp_connection *tc;\n\tint i, j;\n\tint ret = 0;\n\n\tfor (i = 0; i < RDS_MPATH_WORKERS; i++) {\n\t\ttc = kmem_cache_alloc(rds_tcp_conn_slab, gfp);\n\t\tif (!tc) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\t\tmutex_init(&tc->t_conn_path_lock);\n\t\ttc->t_sock = NULL;\n\t\ttc->t_tinc = NULL;\n\t\ttc->t_tinc_hdr_rem = sizeof(struct rds_header);\n\t\ttc->t_tinc_data_rem = 0;\n\n\t\tconn->c_path[i].cp_transport_data = tc;\n\t\ttc->t_cpath = &conn->c_path[i];\n\t\ttc->t_tcp_node_detached = true;\n\n\t\trdsdebug(\"rds_conn_path [%d] tc %p\\n\", i,\n\t\t\t conn->c_path[i].cp_transport_data);\n\t}\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tfor (i = 0; i < RDS_MPATH_WORKERS; i++) {\n\t\ttc = conn->c_path[i].cp_transport_data;\n\t\ttc->t_tcp_node_detached = false;\n\t\tlist_add_tail(&tc->t_tcp_node, &rds_tcp_conn_list);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\nfail:\n\tif (ret) {\n\t\tfor (j = 0; j < i; j++)\n\t\t\trds_tcp_conn_free(conn->c_path[j].cp_transport_data);\n\t}\n\treturn ret;\n}\n\nstatic bool list_has_conn(struct list_head *list, struct rds_connection *conn)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\n\tlist_for_each_entry_safe(tc, _tc, list, t_tcp_node) {\n\t\tif (tc->t_cpath->cp_conn == conn)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic void rds_tcp_set_unloading(void)\n{\n\tatomic_set(&rds_tcp_unloading, 1);\n}\n\nstatic bool rds_tcp_is_unloading(struct rds_connection *conn)\n{\n\treturn atomic_read(&rds_tcp_unloading) != 0;\n}\n\nstatic void rds_tcp_destroy_conns(void)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tLIST_HEAD(tmp_list);\n\n\t/* avoid calling conn_destroy with irqs off */\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tif (!list_has_conn(&tmp_list, tc->t_cpath->cp_conn))\n\t\t\tlist_move_tail(&tc->t_tcp_node, &tmp_list);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node)\n\t\trds_conn_destroy(tc->t_cpath->cp_conn);\n}\n\nstatic void rds_tcp_exit(void);\n\nstatic u8 rds_tcp_get_tos_map(u8 tos)\n{\n\t/* all user tos mapped to default 0 for TCP transport */\n\treturn 0;\n}\n\nstruct rds_transport rds_tcp_transport = {\n\t.laddr_check\t\t= rds_tcp_laddr_check,\n\t.xmit_path_prepare\t= rds_tcp_xmit_path_prepare,\n\t.xmit_path_complete\t= rds_tcp_xmit_path_complete,\n\t.xmit\t\t\t= rds_tcp_xmit,\n\t.recv_path\t\t= rds_tcp_recv_path,\n\t.conn_alloc\t\t= rds_tcp_conn_alloc,\n\t.conn_free\t\t= rds_tcp_conn_free,\n\t.conn_path_connect\t= rds_tcp_conn_path_connect,\n\t.conn_path_shutdown\t= rds_tcp_conn_path_shutdown,\n\t.inc_copy_to_user\t= rds_tcp_inc_copy_to_user,\n\t.inc_free\t\t= rds_tcp_inc_free,\n\t.stats_info_copy\t= rds_tcp_stats_info_copy,\n\t.exit\t\t\t= rds_tcp_exit,\n\t.get_tos_map\t\t= rds_tcp_get_tos_map,\n\t.t_owner\t\t= THIS_MODULE,\n\t.t_name\t\t\t= \"tcp\",\n\t.t_type\t\t\t= RDS_TRANS_TCP,\n\t.t_prefer_loopback\t= 1,\n\t.t_mp_capable\t\t= 1,\n\t.t_unloading\t\t= rds_tcp_is_unloading,\n};\n\nstatic unsigned int rds_tcp_netid;\n\n/* per-network namespace private data for this module */\nstruct rds_tcp_net {\n\tstruct socket *rds_tcp_listen_sock;\n\tstruct work_struct rds_tcp_accept_w;\n\tstruct ctl_table_header *rds_tcp_sysctl;\n\tstruct ctl_table *ctl_table;\n\tint sndbuf_size;\n\tint rcvbuf_size;\n};\n\n/* All module specific customizations to the RDS-TCP socket should be done in\n * rds_tcp_tune() and applied after socket creation.\n */\nvoid rds_tcp_tune(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trds_tcp_nonagle(sock);\n\tlock_sock(sk);\n\tif (rtn->sndbuf_size > 0) {\n\t\tsk->sk_sndbuf = rtn->sndbuf_size;\n\t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n\t}\n\tif (rtn->rcvbuf_size > 0) {\n\t\tsk->sk_sndbuf = rtn->rcvbuf_size;\n\t\tsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\n\t}\n\trelease_sock(sk);\n}\n\nstatic void rds_tcp_accept_worker(struct work_struct *work)\n{\n\tstruct rds_tcp_net *rtn = container_of(work,\n\t\t\t\t\t       struct rds_tcp_net,\n\t\t\t\t\t       rds_tcp_accept_w);\n\n\twhile (rds_tcp_accept_one(rtn->rds_tcp_listen_sock) == 0)\n\t\tcond_resched();\n}\n\nvoid rds_tcp_accept_work(struct sock *sk)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\tqueue_work(rds_wq, &rtn->rds_tcp_accept_w);\n}\n\nstatic __net_init int rds_tcp_init_net(struct net *net)\n{\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\tstruct ctl_table *tbl;\n\tint err = 0;\n\n\tmemset(rtn, 0, sizeof(*rtn));\n\n\t/* {snd, rcv}buf_size default to 0, which implies we let the\n\t * stack pick the value, and permit auto-tuning of buffer size.\n\t */\n\tif (net == &init_net) {\n\t\ttbl = rds_tcp_sysctl_table;\n\t} else {\n\t\ttbl = kmemdup(rds_tcp_sysctl_table,\n\t\t\t      sizeof(rds_tcp_sysctl_table), GFP_KERNEL);\n\t\tif (!tbl) {\n\t\t\tpr_warn(\"could not set allocate syctl table\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\trtn->ctl_table = tbl;\n\t}\n\ttbl[RDS_TCP_SNDBUF].data = &rtn->sndbuf_size;\n\ttbl[RDS_TCP_RCVBUF].data = &rtn->rcvbuf_size;\n\trtn->rds_tcp_sysctl = register_net_sysctl(net, \"net/rds/tcp\", tbl);\n\tif (!rtn->rds_tcp_sysctl) {\n\t\tpr_warn(\"could not register sysctl\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n#if IS_ENABLED(CONFIG_IPV6)\n\trtn->rds_tcp_listen_sock = rds_tcp_listen_init(net, true);\n#else\n\trtn->rds_tcp_listen_sock = rds_tcp_listen_init(net, false);\n#endif\n\tif (!rtn->rds_tcp_listen_sock) {\n\t\tpr_warn(\"could not set up IPv6 listen sock\\n\");\n\n#if IS_ENABLED(CONFIG_IPV6)\n\t\t/* Try IPv4 as some systems disable IPv6 */\n\t\trtn->rds_tcp_listen_sock = rds_tcp_listen_init(net, false);\n\t\tif (!rtn->rds_tcp_listen_sock) {\n#endif\n\t\t\tunregister_net_sysctl_table(rtn->rds_tcp_sysctl);\n\t\t\trtn->rds_tcp_sysctl = NULL;\n\t\t\terr = -EAFNOSUPPORT;\n\t\t\tgoto fail;\n#if IS_ENABLED(CONFIG_IPV6)\n\t\t}\n#endif\n\t}\n\tINIT_WORK(&rtn->rds_tcp_accept_w, rds_tcp_accept_worker);\n\treturn 0;\n\nfail:\n\tif (net != &init_net)\n\t\tkfree(tbl);\n\treturn err;\n}\n\nstatic void rds_tcp_kill_sock(struct net *net)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tLIST_HEAD(tmp_list);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\tstruct socket *lsock = rtn->rds_tcp_listen_sock;\n\n\trtn->rds_tcp_listen_sock = NULL;\n\trds_tcp_listen_stop(lsock, &rtn->rds_tcp_accept_w);\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tstruct net *c_net = read_pnet(&tc->t_cpath->cp_conn->c_net);\n\n\t\tif (net != c_net)\n\t\t\tcontinue;\n\t\tif (!list_has_conn(&tmp_list, tc->t_cpath->cp_conn)) {\n\t\t\tlist_move_tail(&tc->t_tcp_node, &tmp_list);\n\t\t} else {\n\t\t\tlist_del(&tc->t_tcp_node);\n\t\t\ttc->t_tcp_node_detached = true;\n\t\t}\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node)\n\t\trds_conn_destroy(tc->t_cpath->cp_conn);\n}\n\nstatic void __net_exit rds_tcp_exit_net(struct net *net)\n{\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trds_tcp_kill_sock(net);\n\n\tif (rtn->rds_tcp_sysctl)\n\t\tunregister_net_sysctl_table(rtn->rds_tcp_sysctl);\n\n\tif (net != &init_net)\n\t\tkfree(rtn->ctl_table);\n}\n\nstatic struct pernet_operations rds_tcp_net_ops = {\n\t.init = rds_tcp_init_net,\n\t.exit = rds_tcp_exit_net,\n\t.id = &rds_tcp_netid,\n\t.size = sizeof(struct rds_tcp_net),\n};\n\nvoid *rds_tcp_listen_sock_def_readable(struct net *net)\n{\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\tstruct socket *lsock = rtn->rds_tcp_listen_sock;\n\n\tif (!lsock)\n\t\treturn NULL;\n\n\treturn lsock->sk->sk_user_data;\n}\n\n/* when sysctl is used to modify some kernel socket parameters,this\n * function  resets the RDS connections in that netns  so that we can\n * restart with new parameters.  The assumption is that such reset\n * events are few and far-between.\n */\nstatic void rds_tcp_sysctl_reset(struct net *net)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tstruct net *c_net = read_pnet(&tc->t_cpath->cp_conn->c_net);\n\n\t\tif (net != c_net || !tc->t_sock)\n\t\t\tcontinue;\n\n\t\t/* reconnect with new parameters */\n\t\trds_conn_path_drop(tc->t_cpath, false);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n}\n\nstatic int rds_tcp_skbuf_handler(struct ctl_table *ctl, int write,\n\t\t\t\t void __user *buffer, size_t *lenp,\n\t\t\t\t loff_t *fpos)\n{\n\tstruct net *net = current->nsproxy->net_ns;\n\tint err;\n\n\terr = proc_dointvec_minmax(ctl, write, buffer, lenp, fpos);\n\tif (err < 0) {\n\t\tpr_warn(\"Invalid input. Must be >= %d\\n\",\n\t\t\t*(int *)(ctl->extra1));\n\t\treturn err;\n\t}\n\tif (write)\n\t\trds_tcp_sysctl_reset(net);\n\treturn 0;\n}\n\nstatic void rds_tcp_exit(void)\n{\n\trds_tcp_set_unloading();\n\tsynchronize_rcu();\n\trds_info_deregister_func(RDS_INFO_TCP_SOCKETS, rds_tcp_tc_info);\n#if IS_ENABLED(CONFIG_IPV6)\n\trds_info_deregister_func(RDS6_INFO_TCP_SOCKETS, rds6_tcp_tc_info);\n#endif\n\tunregister_pernet_device(&rds_tcp_net_ops);\n\trds_tcp_destroy_conns();\n\trds_trans_unregister(&rds_tcp_transport);\n\trds_tcp_recv_exit();\n\tkmem_cache_destroy(rds_tcp_conn_slab);\n}\nmodule_exit(rds_tcp_exit);\n\nstatic int rds_tcp_init(void)\n{\n\tint ret;\n\n\trds_tcp_conn_slab = kmem_cache_create(\"rds_tcp_connection\",\n\t\t\t\t\t      sizeof(struct rds_tcp_connection),\n\t\t\t\t\t      0, 0, NULL);\n\tif (!rds_tcp_conn_slab) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tret = rds_tcp_recv_init();\n\tif (ret)\n\t\tgoto out_slab;\n\n\tret = register_pernet_device(&rds_tcp_net_ops);\n\tif (ret)\n\t\tgoto out_recv;\n\n\trds_trans_register(&rds_tcp_transport);\n\n\trds_info_register_func(RDS_INFO_TCP_SOCKETS, rds_tcp_tc_info);\n#if IS_ENABLED(CONFIG_IPV6)\n\trds_info_register_func(RDS6_INFO_TCP_SOCKETS, rds6_tcp_tc_info);\n#endif\n\n\tgoto out;\nout_recv:\n\trds_tcp_recv_exit();\nout_slab:\n\tkmem_cache_destroy(rds_tcp_conn_slab);\nout:\n\treturn ret;\n}\nmodule_init(rds_tcp_init);\n\nMODULE_AUTHOR(\"Oracle Corporation <rds-devel@oss.oracle.com>\");\nMODULE_DESCRIPTION(\"RDS: TCP transport\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\n"], "filenames": ["net/rds/tcp.c"], "buggy_code_start_loc": [611], "buggy_code_end_loc": [612], "fixing_code_start_loc": [611], "fixing_code_end_loc": [612], "type": "CWE-362", "message": "An issue was discovered in rds_tcp_kill_sock in net/rds/tcp.c in the Linux kernel before 5.0.8. There is a race condition leading to a use-after-free, related to net namespace cleanup.", "other": {"cve": {"id": "CVE-2019-11815", "sourceIdentifier": "cve@mitre.org", "published": "2019-05-08T14:29:00.280", "lastModified": "2021-07-21T11:39:23.747", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "An issue was discovered in rds_tcp_kill_sock in net/rds/tcp.c in the Linux kernel before 5.0.8. There is a race condition leading to a use-after-free, related to net namespace cleanup."}, {"lang": "es", "value": "Se descubri\u00f3 un problema en rds_tcp_kill_sock en net/rds/tcp.c en el n\u00facleo de Linux anterior a la versi\u00f3n 5.0.8. Existe una condici\u00f3n de carrera que conduce a un uso despu\u00e9s de liberaci\u00f3n de memoria, relacionado con la limpieza del espacio de nombres de red."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:C/I:C/A:C", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 9.3}, "baseSeverity": "HIGH", "exploitabilityScore": 8.6, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-362"}, {"lang": "en", "value": "CWE-416"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.3", "versionEndExcluding": "4.4.179", "matchCriteriaId": "8176C84C-74F4-408B-8DE1-31754AA08894"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.9", "versionEndExcluding": "4.9.169", "matchCriteriaId": "B80909D0-45BB-44DD-982A-B9A8C4E68285"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.14", "versionEndExcluding": "4.14.112", "matchCriteriaId": "F0623A64-FD3D-4FB3-A3D5-252A1F4716AE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.19", "versionEndExcluding": "4.19.35", "matchCriteriaId": "36E8D561-D530-432B-9512-ECCD0D08E217"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "5.0", "versionEndExcluding": "5.0.8", "matchCriteriaId": "B8C3EB64-4B85-4C0E-B9BD-5342B604A466"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.1:rc1:*:*:*:*:*:*", "matchCriteriaId": "2258D313-BAF7-482D-98E0-79F2A448287B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.1:rc2:*:*:*:*:*:*", "matchCriteriaId": "1578A37C-C7CC-4B36-8668-6A1AED63B0A8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.1:rc3:*:*:*:*:*:*", "matchCriteriaId": "49BD6839-AB64-48DA-9D1D-18B4508AF652"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.1:rc4:*:*:*:*:*:*", "matchCriteriaId": "A1E5129A-F85C-432A-988D-6C3ED03EC04D"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:14.04:*:*:*:esm:*:*:*", "matchCriteriaId": "815D70A8-47D3-459C-A32C-9FEACA0659D1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:16.04:*:*:*:esm:*:*:*", "matchCriteriaId": "7A5301BF-1402-4BE0-A0F8-69FBE79BC6D6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:18.04:*:*:*:lts:*:*:*", "matchCriteriaId": "23A7C53F-B80F-4E6A-AFA9-58EEA84BE11D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:19.04:*:*:*:*:*:*:*", "matchCriteriaId": "CD783B0C-9246-47D9-A937-6144FE8BFF0F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:15.0:*:*:*:*:*:*:*", "matchCriteriaId": "F1E78106-58E6-4D59-990F-75DA575BFAD9"}, {"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:15.1:*:*:*:*:*:*:*", "matchCriteriaId": "B620311B-34A3-48A6-82DF-6F078D7A4493"}, {"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:42.3:*:*:*:*:*:*:*", "matchCriteriaId": "5F65DAB0-3DAD-49FF-BC73-3581CC3D5BF3"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:netapp:active_iq_unified_manager:*:*:*:*:*:vmware_vsphere:*:*", "versionStartIncluding": "9.5", "matchCriteriaId": "0CB28AF5-5AF0-4475-A7B6-12E1795FFDCB"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:hci_management_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "A3C19813-E823-456A-B1CE-EC0684CE1953"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:snapprotect:-:*:*:*:*:*:*:*", "matchCriteriaId": "F74F467A-0C81-40D9-BA06-40FB8EF02C04"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:solidfire:-:*:*:*:*:*:*:*", "matchCriteriaId": "A6E9EF0C-AFA8-4F7B-9FDC-1E0F7C26E737"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:storage_replication_adapter:7.2:*:*:*:*:vsphere:*:*", "matchCriteriaId": "3627515C-C752-4D43-B593-BF4DC512BF0F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:vasa_provider_for_clustered_data_ontap:*:*:*:*:*:*:*:*", "versionStartIncluding": "7.2", "matchCriteriaId": "13270F58-E106-48CE-9933-E68AABBBFC21"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:virtual_storage_console:*:*:*:*:*:vsphere:*:*", "versionStartIncluding": "7.2", "matchCriteriaId": "066C2961-E9C4-418E-82AF-1A7C35D5C085"}, {"vulnerable": true, "criteria": "cpe:2.3:h:netapp:hci_compute_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "AD7447BC-F315-4298-A822-549942FC118B"}, {"vulnerable": true, "criteria": "cpe:2.3:h:netapp:hci_storage_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "02DEB4FB-A21D-4CB1-B522-EEE5093E8521"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:cn1610_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "EB30733E-68FC-49C4-86C0-7FEE75C366BF"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:cn1610:-:*:*:*:*:*:*:*", "matchCriteriaId": "6361DAC6-600F-4B15-8797-D67F298F46FB"}]}]}], "references": [{"url": "http://lists.opensuse.org/opensuse-security-announce/2019-05/msg00037.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2019-05/msg00043.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2019-05/msg00071.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://packetstormsecurity.com/files/153799/Kernel-Live-Patch-Security-Notice-LSN-0053-1.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.securityfocus.com/bid/108283", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://cdn.kernel.org/pub/linux/kernel/v5.x/ChangeLog-5.0.8", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=cb66ddd156203daefb8d71158036b27b0e2caf63", "source": "cve@mitre.org", "tags": ["Exploit", "Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/cb66ddd156203daefb8d71158036b27b0e2caf63", "source": "cve@mitre.org", "tags": ["Exploit", "Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2019/06/msg00011.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://seclists.org/bugtraq/2019/Jun/26", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Mailing List", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20190719-0003/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://support.f5.com/csp/article/K32019083", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4005-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4008-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4008-3/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4068-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4068-2/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4118-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.debian.org/security/2019/dsa-4465", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/cb66ddd156203daefb8d71158036b27b0e2caf63"}}
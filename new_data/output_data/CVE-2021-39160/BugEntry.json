{"buggy_code": ["import os\nimport subprocess\nimport logging\nimport time\nimport argparse\nimport datetime\nfrom traitlets import Integer, default\nfrom traitlets.config import Configurable\nfrom functools import partial\n\n\ndef execute_cmd(cmd, **kwargs):\n    \"\"\"\n    Call given command, yielding output line by line\n    \"\"\"\n    yield '$ {}\\n'.format(' '.join(cmd))\n    kwargs['stdout'] = subprocess.PIPE\n    kwargs['stderr'] = subprocess.STDOUT\n\n    proc = subprocess.Popen(cmd, **kwargs)\n\n    # Capture output for logging.\n    # Each line will be yielded as text.\n    # This should behave the same as .readline(), but splits on `\\r` OR `\\n`,\n    # not just `\\n`.\n    buf = []\n\n    def flush():\n        line = b''.join(buf).decode('utf8', 'replace')\n        buf[:] = []\n        return line\n\n    c_last = ''\n    try:\n        for c in iter(partial(proc.stdout.read, 1), b''):\n            if c_last == b'\\r' and buf and c != b'\\n':\n                yield flush()\n            buf.append(c)\n            if c == b'\\n':\n                yield flush()\n            c_last = c\n    finally:\n        ret = proc.wait()\n        if ret != 0:\n            raise subprocess.CalledProcessError(ret, cmd)\n\n\nclass GitPuller(Configurable):\n    depth = Integer(\n        config=True,\n        help=\"\"\"\n        Depth (ie, commit count) of clone operations. Set this to 0 to make a\n        full depth clone.\n\n        Defaults to the value of the environment variable NBGITPULLER_DEPTH, or\n        1 if the the environment variable isn't set.\n        \"\"\"\n    )\n\n    @default('depth')\n    def _depth_default(self):\n        \"\"\"This is a workaround for setting the same default directly in the\n        definition of the traitlet above. Without it, the test fails because a\n        change in the environment variable has no impact. I think this is a\n        consequence of the tests not starting with a totally clean environment\n        where the GitPuller class hadn't been loaded already.\"\"\"\n        return int(os.environ.get('NBGITPULLER_DEPTH', 1))\n\n    def __init__(self, git_url, repo_dir, **kwargs):\n        assert git_url\n\n        self.git_url = git_url\n        self.branch_name = kwargs.pop(\"branch\")\n\n        if self.branch_name is None:\n            self.branch_name = self.resolve_default_branch()\n        elif not self.branch_exists(self.branch_name):\n            raise ValueError(f\"Branch: {self.branch_name} -- not found in repo: {self.git_url}\")\n\n        self.repo_dir = repo_dir\n        newargs = {k: v for k, v in kwargs.items() if v is not None}\n        super(GitPuller, self).__init__(**newargs)\n\n    def branch_exists(self, branch):\n        \"\"\"\n        This checks to make sure the branch we are told to access\n        exists in the repo\n        \"\"\"\n        try:\n            heads = subprocess.run(\n                [\"git\", \"ls-remote\", \"--heads\", self.git_url],\n                capture_output=True,\n                text=True,\n                check=True\n            )\n            tags = subprocess.run(\n                [\"git\", \"ls-remote\", \"--tags\", self.git_url],\n                capture_output=True,\n                text=True,\n                check=True\n            )\n            lines = heads.stdout.splitlines() + tags.stdout.splitlines()\n            branches = []\n            for line in lines:\n                _, ref = line.split()\n                refs, heads, branch_name = ref.split(\"/\", 2)\n                branches.append(branch_name)\n            return branch in branches\n        except subprocess.CalledProcessError:\n            m = f\"Problem accessing list of branches and/or tags: {self.git_url}\"\n            logging.exception(m)\n            raise ValueError(m)\n\n    def resolve_default_branch(self):\n        \"\"\"\n        This will resolve the default branch of the repo in\n        the case where the branch given does not exist\n        \"\"\"\n        try:\n            head_branch = subprocess.run(\n                [\"git\", \"ls-remote\", \"--symref\", self.git_url, \"HEAD\"],\n                capture_output=True,\n                text=True,\n                check=True\n            )\n            for line in head_branch.stdout.splitlines():\n                if line.startswith(\"ref:\"):\n                    # line resembles --> ref: refs/heads/main HEAD\n                    _, ref, head = line.split()\n                    refs, heads, branch_name = ref.split(\"/\", 2)\n                    return branch_name\n            raise ValueError(f\"default branch not found in {self.git_url}\")\n        except subprocess.CalledProcessError:\n            m = f\"Problem accessing HEAD branch: {self.git_url}\"\n            logging.exception(m)\n            raise ValueError(m)\n\n    def pull(self):\n        \"\"\"\n        Pull selected repo from a remote git repository,\n        while preserving user changes\n        \"\"\"\n        if not os.path.exists(self.repo_dir):\n            yield from self.initialize_repo()\n        else:\n            yield from self.update()\n\n    def initialize_repo(self):\n        \"\"\"\n        Clones repository\n        \"\"\"\n        logging.info('Repo {} doesn\\'t exist. Cloning...'.format(self.repo_dir))\n        clone_args = ['git', 'clone']\n        if self.depth and self.depth > 0:\n            clone_args.extend(['--depth', str(self.depth)])\n        clone_args.extend(['--branch', self.branch_name])\n        clone_args.extend([self.git_url, self.repo_dir])\n        yield from execute_cmd(clone_args)\n        logging.info('Repo {} initialized'.format(self.repo_dir))\n\n    def reset_deleted_files(self):\n        \"\"\"\n        Runs the equivalent of git checkout -- <file> for each file that was\n        deleted. This allows us to delete a file, hit an interact link, then get a\n        clean version of the file again.\n        \"\"\"\n\n        yield from self.ensure_lock()\n        deleted_files = subprocess.check_output([\n            'git', 'ls-files', '--deleted', '-z'\n        ], cwd=self.repo_dir).decode().strip().split('\\0')\n\n        for filename in deleted_files:\n            if filename:  # Filter out empty lines\n                yield from execute_cmd(['git', 'checkout', 'origin/{}'.format(self.branch_name), '--', filename], cwd=self.repo_dir)\n\n    def repo_is_dirty(self):\n        \"\"\"\n        Return true if repo is dirty\n        \"\"\"\n        try:\n            subprocess.check_call(['git', 'diff-files', '--quiet'], cwd=self.repo_dir)\n            # Return code is 0\n            return False\n        except subprocess.CalledProcessError:\n            return True\n\n    def update_remotes(self):\n        \"\"\"\n        Do a git fetch so our remotes are up to date\n        \"\"\"\n        yield from execute_cmd(['git', 'fetch'], cwd=self.repo_dir)\n\n    def find_upstream_changed(self, kind):\n        \"\"\"\n        Return list of files that have been changed upstream belonging to a particular kind of change\n        \"\"\"\n        output = subprocess.check_output([\n            'git', 'log', '..origin/{}'.format(self.branch_name),\n            '--oneline', '--name-status'\n        ], cwd=self.repo_dir).decode()\n        files = []\n        for line in output.split('\\n'):\n            if line.startswith(kind):\n                files.append(os.path.join(self.repo_dir, line.split('\\t', 1)[1]))\n\n        return files\n\n    def ensure_lock(self):\n        \"\"\"\n        Make sure we have the .git/lock required to do modifications on the repo\n\n        This must be called before any git commands that modify state. This isn't guaranteed\n        to be atomic, due to the nature of using files for locking. But it's the best we\n        can do right now.\n        \"\"\"\n        try:\n            lockpath = os.path.join(self.repo_dir, '.git', 'index.lock')\n            mtime = os.path.getmtime(lockpath)\n            # A lock file does exist\n            # If it's older than 10 minutes, we just assume it is stale and take over\n            # If not, we fail with an explicit error.\n            if time.time() - mtime > 600:\n                yield \"Stale .git/index.lock found, attempting to remove\"\n                os.remove(lockpath)\n                yield \"Stale .git/index.lock removed\"\n            else:\n                raise Exception('Recent .git/index.lock found, operation can not proceed. Try again in a few minutes.')\n        except FileNotFoundError:\n            # No lock is held by other processes, we are free to go\n            return\n\n    def rename_local_untracked(self):\n        \"\"\"\n        Rename local untracked files that would require pulls\n        \"\"\"\n        # Find what files have been added!\n        new_upstream_files = self.find_upstream_changed('A')\n        for f in new_upstream_files:\n            if os.path.exists(f):\n                # If there's a file extension, put the timestamp before that\n                ts = datetime.datetime.now().strftime('__%Y%m%d%H%M%S')\n                path_head, path_tail = os.path.split(f)\n                path_tail = ts.join(os.path.splitext(path_tail))\n                new_file_name = os.path.join(path_head, path_tail)\n                os.rename(f, new_file_name)\n                yield 'Renamed {} to {} to avoid conflict with upstream'.format(f, new_file_name)\n\n    def update(self):\n        \"\"\"\n        Do the pulling if necessary\n        \"\"\"\n        # Fetch remotes, so we know we're dealing with latest remote\n        yield from self.update_remotes()\n\n        # Rename local untracked files that might be overwritten by pull\n        yield from self.rename_local_untracked()\n\n        # Reset local files that have been deleted. We don't actually expect users to\n        # delete something that's present upstream and expect to keep it. This prevents\n        # unnecessary conflicts, and also allows users to click the link again to get\n        # a fresh copy of a file they might have screwed up.\n        yield from self.reset_deleted_files()\n\n        # If there are local changes, make a commit so we can do merges when pulling\n        # We also allow empty commits. On NFS (at least), sometimes repo_is_dirty returns a false\n        # positive, returning True even when there are no local changes (git diff-files seems to return\n        # bogus output?). While ideally that would not happen, allowing empty commits keeps us\n        # resilient to that issue.\n        # We explicitly set user info of the commits we are making, to keep that separate from\n        # whatever author info is set in system / repo config by the user. We pass '-c' to git\n        # itself (rather than to 'git commit') to temporarily set config variables. This is\n        # better than passing --author, since git treats author separately from committer.\n        if self.repo_is_dirty():\n            yield from self.ensure_lock()\n            yield from execute_cmd([\n                'git',\n                '-c', 'user.email=nbgitpuller@nbgitpuller.link',\n                '-c', 'user.name=nbgitpuller',\n                'commit',\n                '-am', 'Automatic commit by nbgitpuller',\n                '--allow-empty'\n            ], cwd=self.repo_dir)\n\n        # Merge master into local!\n        yield from self.ensure_lock()\n        yield from execute_cmd([\n            'git',\n            '-c', 'user.email=nbgitpuller@nbgitpuller.link',\n            '-c', 'user.name=nbgitpuller',\n            'merge',\n            '-Xours', 'origin/{}'.format(self.branch_name)\n        ], cwd=self.repo_dir)\n\n\ndef main():\n    \"\"\"\n    Synchronizes a github repository with a local repository.\n    \"\"\"\n    logging.basicConfig(\n        format='[%(asctime)s] %(levelname)s -- %(message)s',\n        level=logging.DEBUG)\n\n    parser = argparse.ArgumentParser(description='Synchronizes a github repository with a local repository.')\n    parser.add_argument('git_url', help='Url of the repo to sync')\n    parser.add_argument('branch_name', default=None, help='Branch of repo to sync', nargs='?')\n    parser.add_argument('repo_dir', default='.', help='Path to clone repo under', nargs='?')\n    args = parser.parse_args()\n\n    for line in GitPuller(\n        args.git_url,\n        args.repo_dir,\n        branch=args.branch_name if args.branch_name else None\n    ).pull():\n        print(line)\n\n\nif __name__ == '__main__':\n    main()\n"], "fixing_code": ["import os\nimport subprocess\nimport logging\nimport time\nimport argparse\nimport datetime\nfrom traitlets import Integer, default\nfrom traitlets.config import Configurable\nfrom functools import partial\n\n\ndef execute_cmd(cmd, **kwargs):\n    \"\"\"\n    Call given command, yielding output line by line\n    \"\"\"\n    yield '$ {}\\n'.format(' '.join(cmd))\n    kwargs['stdout'] = subprocess.PIPE\n    kwargs['stderr'] = subprocess.STDOUT\n\n    proc = subprocess.Popen(cmd, **kwargs)\n\n    # Capture output for logging.\n    # Each line will be yielded as text.\n    # This should behave the same as .readline(), but splits on `\\r` OR `\\n`,\n    # not just `\\n`.\n    buf = []\n\n    def flush():\n        line = b''.join(buf).decode('utf8', 'replace')\n        buf[:] = []\n        return line\n\n    c_last = ''\n    try:\n        for c in iter(partial(proc.stdout.read, 1), b''):\n            if c_last == b'\\r' and buf and c != b'\\n':\n                yield flush()\n            buf.append(c)\n            if c == b'\\n':\n                yield flush()\n            c_last = c\n    finally:\n        ret = proc.wait()\n        if ret != 0:\n            raise subprocess.CalledProcessError(ret, cmd)\n\n\nclass GitPuller(Configurable):\n    depth = Integer(\n        config=True,\n        help=\"\"\"\n        Depth (ie, commit count) of clone operations. Set this to 0 to make a\n        full depth clone.\n\n        Defaults to the value of the environment variable NBGITPULLER_DEPTH, or\n        1 if the the environment variable isn't set.\n        \"\"\"\n    )\n\n    @default('depth')\n    def _depth_default(self):\n        \"\"\"This is a workaround for setting the same default directly in the\n        definition of the traitlet above. Without it, the test fails because a\n        change in the environment variable has no impact. I think this is a\n        consequence of the tests not starting with a totally clean environment\n        where the GitPuller class hadn't been loaded already.\"\"\"\n        return int(os.environ.get('NBGITPULLER_DEPTH', 1))\n\n    def __init__(self, git_url, repo_dir, **kwargs):\n        assert git_url\n\n        self.git_url = git_url\n        self.branch_name = kwargs.pop(\"branch\")\n\n        if self.branch_name is None:\n            self.branch_name = self.resolve_default_branch()\n        elif not self.branch_exists(self.branch_name):\n            raise ValueError(f\"Branch: {self.branch_name} -- not found in repo: {self.git_url}\")\n\n        self.repo_dir = repo_dir\n        newargs = {k: v for k, v in kwargs.items() if v is not None}\n        super(GitPuller, self).__init__(**newargs)\n\n    def branch_exists(self, branch):\n        \"\"\"\n        This checks to make sure the branch we are told to access\n        exists in the repo\n        \"\"\"\n        try:\n            heads = subprocess.run(\n                [\"git\", \"ls-remote\", \"--heads\", \"--\", self.git_url],\n                capture_output=True,\n                text=True,\n                check=True\n            )\n            tags = subprocess.run(\n                [\"git\", \"ls-remote\", \"--tags\", \"--\", self.git_url],\n                capture_output=True,\n                text=True,\n                check=True\n            )\n            lines = heads.stdout.splitlines() + tags.stdout.splitlines()\n            branches = []\n            for line in lines:\n                _, ref = line.split()\n                refs, heads, branch_name = ref.split(\"/\", 2)\n                branches.append(branch_name)\n            return branch in branches\n        except subprocess.CalledProcessError:\n            m = f\"Problem accessing list of branches and/or tags: {self.git_url}\"\n            logging.exception(m)\n            raise ValueError(m)\n\n    def resolve_default_branch(self):\n        \"\"\"\n        This will resolve the default branch of the repo in\n        the case where the branch given does not exist\n        \"\"\"\n        try:\n            head_branch = subprocess.run(\n                [\"git\", \"ls-remote\", \"--symref\", \"--\", self.git_url, \"HEAD\"],\n                capture_output=True,\n                text=True,\n                check=True\n            )\n            for line in head_branch.stdout.splitlines():\n                if line.startswith(\"ref:\"):\n                    # line resembles --> ref: refs/heads/main HEAD\n                    _, ref, head = line.split()\n                    refs, heads, branch_name = ref.split(\"/\", 2)\n                    return branch_name\n            raise ValueError(f\"default branch not found in {self.git_url}\")\n        except subprocess.CalledProcessError:\n            m = f\"Problem accessing HEAD branch: {self.git_url}\"\n            logging.exception(m)\n            raise ValueError(m)\n\n    def pull(self):\n        \"\"\"\n        Pull selected repo from a remote git repository,\n        while preserving user changes\n        \"\"\"\n        if not os.path.exists(self.repo_dir):\n            yield from self.initialize_repo()\n        else:\n            yield from self.update()\n\n    def initialize_repo(self):\n        \"\"\"\n        Clones repository\n        \"\"\"\n        logging.info('Repo {} doesn\\'t exist. Cloning...'.format(self.repo_dir))\n        clone_args = ['git', 'clone']\n        if self.depth and self.depth > 0:\n            clone_args.extend(['--depth', str(self.depth)])\n        clone_args.extend(['--branch', self.branch_name])\n        clone_args.extend([\"--\", self.git_url, self.repo_dir])\n        yield from execute_cmd(clone_args)\n        logging.info('Repo {} initialized'.format(self.repo_dir))\n\n    def reset_deleted_files(self):\n        \"\"\"\n        Runs the equivalent of git checkout -- <file> for each file that was\n        deleted. This allows us to delete a file, hit an interact link, then get a\n        clean version of the file again.\n        \"\"\"\n\n        yield from self.ensure_lock()\n        deleted_files = subprocess.check_output([\n            'git', 'ls-files', '--deleted', '-z'\n        ], cwd=self.repo_dir).decode().strip().split('\\0')\n\n        for filename in deleted_files:\n            if filename:  # Filter out empty lines\n                yield from execute_cmd(['git', 'checkout', 'origin/{}'.format(self.branch_name), '--', filename], cwd=self.repo_dir)\n\n    def repo_is_dirty(self):\n        \"\"\"\n        Return true if repo is dirty\n        \"\"\"\n        try:\n            subprocess.check_call(['git', 'diff-files', '--quiet'], cwd=self.repo_dir)\n            # Return code is 0\n            return False\n        except subprocess.CalledProcessError:\n            return True\n\n    def update_remotes(self):\n        \"\"\"\n        Do a git fetch so our remotes are up to date\n        \"\"\"\n        yield from execute_cmd(['git', 'fetch'], cwd=self.repo_dir)\n\n    def find_upstream_changed(self, kind):\n        \"\"\"\n        Return list of files that have been changed upstream belonging to a particular kind of change\n        \"\"\"\n        output = subprocess.check_output([\n            'git', 'log', '..origin/{}'.format(self.branch_name),\n            '--oneline', '--name-status'\n        ], cwd=self.repo_dir).decode()\n        files = []\n        for line in output.split('\\n'):\n            if line.startswith(kind):\n                files.append(os.path.join(self.repo_dir, line.split('\\t', 1)[1]))\n\n        return files\n\n    def ensure_lock(self):\n        \"\"\"\n        Make sure we have the .git/lock required to do modifications on the repo\n\n        This must be called before any git commands that modify state. This isn't guaranteed\n        to be atomic, due to the nature of using files for locking. But it's the best we\n        can do right now.\n        \"\"\"\n        try:\n            lockpath = os.path.join(self.repo_dir, '.git', 'index.lock')\n            mtime = os.path.getmtime(lockpath)\n            # A lock file does exist\n            # If it's older than 10 minutes, we just assume it is stale and take over\n            # If not, we fail with an explicit error.\n            if time.time() - mtime > 600:\n                yield \"Stale .git/index.lock found, attempting to remove\"\n                os.remove(lockpath)\n                yield \"Stale .git/index.lock removed\"\n            else:\n                raise Exception('Recent .git/index.lock found, operation can not proceed. Try again in a few minutes.')\n        except FileNotFoundError:\n            # No lock is held by other processes, we are free to go\n            return\n\n    def rename_local_untracked(self):\n        \"\"\"\n        Rename local untracked files that would require pulls\n        \"\"\"\n        # Find what files have been added!\n        new_upstream_files = self.find_upstream_changed('A')\n        for f in new_upstream_files:\n            if os.path.exists(f):\n                # If there's a file extension, put the timestamp before that\n                ts = datetime.datetime.now().strftime('__%Y%m%d%H%M%S')\n                path_head, path_tail = os.path.split(f)\n                path_tail = ts.join(os.path.splitext(path_tail))\n                new_file_name = os.path.join(path_head, path_tail)\n                os.rename(f, new_file_name)\n                yield 'Renamed {} to {} to avoid conflict with upstream'.format(f, new_file_name)\n\n    def update(self):\n        \"\"\"\n        Do the pulling if necessary\n        \"\"\"\n        # Fetch remotes, so we know we're dealing with latest remote\n        yield from self.update_remotes()\n\n        # Rename local untracked files that might be overwritten by pull\n        yield from self.rename_local_untracked()\n\n        # Reset local files that have been deleted. We don't actually expect users to\n        # delete something that's present upstream and expect to keep it. This prevents\n        # unnecessary conflicts, and also allows users to click the link again to get\n        # a fresh copy of a file they might have screwed up.\n        yield from self.reset_deleted_files()\n\n        # If there are local changes, make a commit so we can do merges when pulling\n        # We also allow empty commits. On NFS (at least), sometimes repo_is_dirty returns a false\n        # positive, returning True even when there are no local changes (git diff-files seems to return\n        # bogus output?). While ideally that would not happen, allowing empty commits keeps us\n        # resilient to that issue.\n        # We explicitly set user info of the commits we are making, to keep that separate from\n        # whatever author info is set in system / repo config by the user. We pass '-c' to git\n        # itself (rather than to 'git commit') to temporarily set config variables. This is\n        # better than passing --author, since git treats author separately from committer.\n        if self.repo_is_dirty():\n            yield from self.ensure_lock()\n            yield from execute_cmd([\n                'git',\n                '-c', 'user.email=nbgitpuller@nbgitpuller.link',\n                '-c', 'user.name=nbgitpuller',\n                'commit',\n                '-am', 'Automatic commit by nbgitpuller',\n                '--allow-empty'\n            ], cwd=self.repo_dir)\n\n        # Merge master into local!\n        yield from self.ensure_lock()\n        yield from execute_cmd([\n            'git',\n            '-c', 'user.email=nbgitpuller@nbgitpuller.link',\n            '-c', 'user.name=nbgitpuller',\n            'merge',\n            '-Xours', 'origin/{}'.format(self.branch_name)\n        ], cwd=self.repo_dir)\n\n\ndef main():\n    \"\"\"\n    Synchronizes a github repository with a local repository.\n    \"\"\"\n    logging.basicConfig(\n        format='[%(asctime)s] %(levelname)s -- %(message)s',\n        level=logging.DEBUG)\n\n    parser = argparse.ArgumentParser(description='Synchronizes a github repository with a local repository.')\n    parser.add_argument('git_url', help='Url of the repo to sync')\n    parser.add_argument('branch_name', default=None, help='Branch of repo to sync', nargs='?')\n    parser.add_argument('repo_dir', default='.', help='Path to clone repo under', nargs='?')\n    args = parser.parse_args()\n\n    for line in GitPuller(\n        args.git_url,\n        args.repo_dir,\n        branch=args.branch_name if args.branch_name else None\n    ).pull():\n        print(line)\n\n\nif __name__ == '__main__':\n    main()\n"], "filenames": ["nbgitpuller/pull.py"], "buggy_code_start_loc": [91], "buggy_code_end_loc": [158], "fixing_code_start_loc": [91], "fixing_code_end_loc": [158], "type": "CWE-78", "message": "nbgitpuller is a Jupyter server extension to sync a git repository one-way to a local path. Due to unsanitized input, visiting maliciously crafted links could result in arbitrary code execution in the user environment. This has been resolved in version 0.10.2 and all users are advised to upgrade. No work around exist for users who can not upgrade.", "other": {"cve": {"id": "CVE-2021-39160", "sourceIdentifier": "security-advisories@github.com", "published": "2021-08-25T18:15:08.487", "lastModified": "2022-10-25T17:51:34.913", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "nbgitpuller is a Jupyter server extension to sync a git repository one-way to a local path. Due to unsanitized input, visiting maliciously crafted links could result in arbitrary code execution in the user environment. This has been resolved in version 0.10.2 and all users are advised to upgrade. No work around exist for users who can not upgrade."}, {"lang": "es", "value": "nbgitpuller es una extensi\u00f3n del servidor Jupyter para sincronizar un repositorio git de forma unidireccional a una ruta local. Debido a una entrada no saneada, visitar enlaces maliciosamente dise\u00f1ados podr\u00eda resultar en una ejecuci\u00f3n de c\u00f3digo arbitrario en el entorno del usuario. Esto ha sido resuelto en la versi\u00f3n 0.10.2 y se recomienda a todos los usuarios que actualicen. No se presenta ninguna soluci\u00f3n para usuarios que no puedan actualizar."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.6, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 2.8, "impactScore": 6.0}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-78"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-94"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:jupyterhub:nbgitpuller:*:*:*:*:*:*:*:*", "versionStartIncluding": "0.9.0", "versionEndExcluding": "0.10.2", "matchCriteriaId": "0B051DFF-5FCE-44EB-B203-D66E4D0E21E2"}]}]}], "references": [{"url": "https://github.com/jupyterhub/nbgitpuller/blob/main/CHANGELOG.md#0102---2021-08-25", "source": "security-advisories@github.com", "tags": ["Release Notes", "Third Party Advisory"]}, {"url": "https://github.com/jupyterhub/nbgitpuller/commit/07690644f29a566011dd0d7ba14cae3eb0490481", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/jupyterhub/nbgitpuller/security/advisories/GHSA-mq5p-2mcr-m52j", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/jupyterhub/nbgitpuller/commit/07690644f29a566011dd0d7ba14cae3eb0490481"}}
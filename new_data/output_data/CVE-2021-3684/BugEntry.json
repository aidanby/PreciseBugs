{"buggy_code": ["package assisted_installer_controller\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"math\"\n\t\"net\"\n\t\"os\"\n\t\"path\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\tmetal3v1alpha1 \"github.com/metal3-io/baremetal-operator/pkg/apis/metal3/v1alpha1\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/sirupsen/logrus\"\n\tcertificatesv1 \"k8s.io/api/certificates/v1\"\n\tv1 \"k8s.io/api/core/v1\"\n\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\n\t\"github.com/openshift/assisted-installer/src/common\"\n\t\"github.com/openshift/assisted-installer/src/inventory_client\"\n\t\"github.com/openshift/assisted-installer/src/k8s_client\"\n\t\"github.com/openshift/assisted-installer/src/ops\"\n\t\"github.com/openshift/assisted-installer/src/utils\"\n\t\"github.com/openshift/assisted-service/models\"\n\tmapiv1beta1 \"github.com/openshift/machine-api-operator/pkg/apis/machine/v1beta1\"\n)\n\nconst (\n\t// We retry 10 times in 30sec interval meaning that we tolerate the operator to be in failed\n\t// state for 5minutes.\n\tfailedOperatorRetry       = 10\n\tgeneralWaitTimeoutInt     = 30\n\tcontrollerLogsSecondsAgo  = 120 * 60\n\tconsoleOperatorName       = \"console\"\n\tingressConfigMapName      = \"default-ingress-cert\"\n\tingressConfigMapNamespace = \"openshift-config-managed\"\n\tdnsServiceName            = \"dns-default\"\n\tdnsServiceNamespace       = \"openshift-dns\"\n\tdnsOperatorNamespace      = \"openshift-dns-operator\"\n\tmaxDeletionAttempts       = 5\n\tmaxDNSServiceIPAttempts   = 45\n\tKeepWaiting               = false\n\tExitWaiting               = true\n\tcustomManifestsFile       = \"custom_manifests.yaml\"\n\tkubeconfigFileName        = \"kubeconfig-noingress\"\n)\n\nvar (\n\tretryPostManifestTimeout = 10 * time.Minute\n\tGeneralWaitInterval      = generalWaitTimeoutInt * time.Second\n\tGeneralProgressUpdateInt = 60 * time.Second\n\tLogsUploadPeriod         = 5 * time.Minute\n\tWaitTimeout              = 70 * time.Minute\n\tCompleteTimeout          = 30 * time.Minute\n\tDNSAddressRetryInterval  = 20 * time.Second\n\tDeletionRetryInterval    = 10 * time.Second\n\tLongWaitTimeout          = 10 * time.Hour\n\tCVOMaxTimeout            = 3 * time.Hour\n)\n\n// assisted installer controller is added to control installation process after  bootstrap pivot\n// assisted installer will deploy it on installation process\n// as a first step it will wait till nodes are added to cluster and update their status to Done\n\ntype ControllerConfig struct {\n\tClusterID             string `envconfig:\"CLUSTER_ID\" required:\"true\" `\n\tURL                   string `envconfig:\"INVENTORY_URL\" required:\"true\"`\n\tPullSecretToken       string `envconfig:\"PULL_SECRET_TOKEN\" required:\"true\"`\n\tSkipCertVerification  bool   `envconfig:\"SKIP_CERT_VERIFICATION\" required:\"false\" default:\"false\"`\n\tCACertPath            string `envconfig:\"CA_CERT_PATH\" required:\"false\" default:\"\"`\n\tNamespace             string `envconfig:\"NAMESPACE\" required:\"false\" default:\"assisted-installer\"`\n\tOpenshiftVersion      string `envconfig:\"OPENSHIFT_VERSION\" required:\"true\"`\n\tHighAvailabilityMode  string `envconfig:\"HIGH_AVAILABILITY_MODE\" required:\"false\" default:\"Full\"`\n\tWaitForClusterVersion bool   `envconfig:\"CHECK_CLUSTER_VERSION\" required:\"false\" default:\"false\"`\n\tMustGatherImage       string `envconfig:\"MUST_GATHER_IMAGE\" required:\"false\" default:\"\"`\n}\ntype Controller interface {\n\tWaitAndUpdateNodesStatus(status *ControllerStatus)\n}\n\ntype ControllerStatus struct {\n\terrCounter uint32\n\tcomponents map[string]bool\n\tlock       sync.Mutex\n}\n\ntype controller struct {\n\tControllerConfig\n\tStatus *ControllerStatus\n\tlog    *logrus.Logger\n\tops    ops.Ops\n\tic     inventory_client.InventoryClient\n\tkc     k8s_client.K8SClient\n}\n\nfunc NewController(log *logrus.Logger, cfg ControllerConfig, ops ops.Ops, ic inventory_client.InventoryClient, kc k8s_client.K8SClient) *controller {\n\treturn &controller{\n\t\tlog:              log,\n\t\tControllerConfig: cfg,\n\t\tops:              ops,\n\t\tic:               ic,\n\t\tkc:               kc,\n\t\tStatus:           NewControllerStatus(),\n\t}\n}\n\nfunc NewControllerStatus() *ControllerStatus {\n\treturn &ControllerStatus{\n\t\tcomponents: make(map[string]bool),\n\t}\n}\n\nfunc (status *ControllerStatus) Error() {\n\tatomic.AddUint32(&status.errCounter, 1)\n}\n\nfunc (status *ControllerStatus) HasError() bool {\n\treturn atomic.LoadUint32(&status.errCounter) > 0\n}\n\nfunc (status *ControllerStatus) OperatorError(component string) {\n\tstatus.lock.Lock()\n\tdefer status.lock.Unlock()\n\tstatus.components[component] = true\n}\n\nfunc (status *ControllerStatus) HasOperatorError() bool {\n\tstatus.lock.Lock()\n\tdefer status.lock.Unlock()\n\treturn len(status.components) > 0\n}\n\nfunc (status *ControllerStatus) GetOperatorsInError() []string {\n\tresult := make([]string, 0)\n\tstatus.lock.Lock()\n\tdefer status.lock.Unlock()\n\tfor op := range status.components {\n\t\tresult = append(result, op)\n\t}\n\treturn result\n}\n\nfunc logHostsStatus(log logrus.FieldLogger, hosts map[string]inventory_client.HostData) {\n\thostsStatus := make(map[string][]string)\n\tfor hostname, hostData := range hosts {\n\t\thostsStatus[hostname] = []string{\n\t\t\t*hostData.Host.Status,\n\t\t\tstring(hostData.Host.Progress.CurrentStage),\n\t\t\thostData.Host.Progress.ProgressInfo}\n\t}\n\tlog.Infof(\"Hosts status: %v\", hostsStatus)\n}\n\n// WaitAndUpdateNodesStatus waits till all nodes joins the cluster and become ready\n// it will update joined/done status\n// approve csr will run as routine and cancelled whenever all nodes are ready and joined\n// this will allow to run it and end only when it is needed\nfunc (c *controller) WaitAndUpdateNodesStatus(ctx context.Context, wg *sync.WaitGroup) {\n\tapproveCtx, approveCancel := context.WithCancel(ctx)\n\tdefer func() {\n\t\tapproveCancel()\n\t\tc.log.Infof(\"WaitAndUpdateNodesStatus finished\")\n\t\twg.Done()\n\t}()\n\t// starting approve csrs\n\tgo c.ApproveCsrs(approveCtx)\n\n\tc.log.Infof(\"Waiting till all nodes will join and update status to assisted installer\")\n\t_ = utils.WaitForPredicateWithContext(ctx, LongWaitTimeout, GeneralWaitInterval, c.waitAndUpdateNodesStatus)\n}\n\nfunc (c *controller) waitAndUpdateNodesStatus() bool {\n\tignoreStatuses := []string{models.HostStatusDisabled}\n\tvar hostsInError int\n\tctxReq := utils.GenerateRequestContext()\n\tlog := utils.RequestIDLogger(ctxReq, c.log)\n\n\tassistedNodesMap, err := c.ic.GetHosts(ctxReq, log, ignoreStatuses)\n\tif err != nil {\n\t\tlog.WithError(err).Error(\"Failed to get node map from the assisted service\")\n\t\treturn KeepWaiting\n\t}\n\n\tlogHostsStatus(log, assistedNodesMap)\n\n\thostsInProgressMap := common.GetHostsInStatus(assistedNodesMap, []string{models.HostStatusInstalled}, false)\n\terrNodesMap := common.GetHostsInStatus(hostsInProgressMap, []string{models.HostStatusError}, true)\n\thostsInError = len(errNodesMap)\n\n\t//if all hosts are in error, mark the failure and finish\n\tif hostsInError > 0 && hostsInError == len(hostsInProgressMap) {\n\t\tc.log.Infof(\"Done waiting for all the nodes. Nodes in error status: %d\\n\", hostsInError)\n\t\treturn ExitWaiting\n\t}\n\t//if all hosts are successfully installed, finish\n\tif len(hostsInProgressMap) == 0 {\n\t\tc.log.Infof(\"All nodes were successfully installed\")\n\t\treturn ExitWaiting\n\t}\n\t//otherwise, update the progress status and keep waiting\n\tlog.Infof(\"Checking if cluster nodes are ready. %d nodes remaining\", len(hostsInProgressMap))\n\tnodes, err := c.kc.ListNodes()\n\tif err != nil {\n\t\tlog.WithError(err).Error(\"Failed to get list of nodes from k8s client\")\n\t\treturn KeepWaiting\n\t}\n\tfor _, node := range nodes.Items {\n\t\thost, ok := hostsInProgressMap[strings.ToLower(node.Name)]\n\t\tif !ok {\n\t\t\tif _, ok := assistedNodesMap[strings.ToLower(node.Name)]; !ok {\n\t\t\t\tlog.Warnf(\"Node %s is not in inventory hosts\", strings.ToLower(node.Name))\n\t\t\t}\n\n\t\t\tcontinue\n\t\t}\n\t\tif common.IsK8sNodeIsReady(node) {\n\t\t\tlog.Infof(\"Found new ready node %s with inventory id %s, kubernetes id %s, updating its status to %s\",\n\t\t\t\tnode.Name, host.Host.ID.String(), node.Status.NodeInfo.SystemUUID, models.HostStageDone)\n\t\t\tif err := c.ic.UpdateHostInstallProgress(ctxReq, host.Host.ID.String(), models.HostStageDone, \"\"); err != nil {\n\t\t\t\tlog.WithError(err).Errorf(\"Failed to update node %s installation status\", node.Name)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t} else if host.Host.Progress.CurrentStage == models.HostStageConfiguring {\n\t\t\tlog.Infof(\"Found new joined node %s with inventory id %s, kubernetes id %s, updating its status to %s\",\n\t\t\t\tnode.Name, host.Host.ID.String(), node.Status.NodeInfo.SystemUUID, models.HostStageJoined)\n\t\t\tif err := c.ic.UpdateHostInstallProgress(ctxReq, host.Host.ID.String(), models.HostStageJoined, \"\"); err != nil {\n\t\t\t\tlog.WithError(err).Errorf(\"Failed to update node %s installation status\", node.Name)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t}\n\tc.updateConfiguringStatusIfNeeded(assistedNodesMap)\n\treturn KeepWaiting\n}\n\nfunc (c *controller) HackDNSAddressConflict(wg *sync.WaitGroup) {\n\n\tc.log.Infof(\"Making sure service %s can reserve the .10 address\", dnsServiceName)\n\n\tdefer func() {\n\t\tc.log.Infof(\"HackDNSAddressConflict finished\")\n\t\twg.Done()\n\t}()\n\tnetworks, err := c.kc.GetServiceNetworks()\n\tif err != nil || len(networks) == 0 {\n\t\tc.log.Errorf(\"Failed to get service networks: %s\", err)\n\t\treturn\n\t}\n\n\tip, _, _ := net.ParseCIDR(networks[0])\n\tip4 := ip.To4()\n\tif ip4 == nil {\n\t\tc.log.Infof(\"Service network is IPv6: %s, skipping the .10 address hack\", ip)\n\t\treturn\n\t}\n\tip4[3] = 10 // .10 is the conflicting address\n\n\tfor i := 0; i < maxDNSServiceIPAttempts; i++ {\n\t\tsvs, err := c.kc.ListServices(\"\")\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warnf(\"Failed to list running services, attempt %d/%d\", i+1, maxDNSServiceIPAttempts)\n\t\t\ttime.Sleep(DNSAddressRetryInterval)\n\t\t\tcontinue\n\t\t}\n\t\ts := c.findServiceByIP(ip4.String(), &svs.Items)\n\t\tif s == nil {\n\t\t\tc.log.Infof(\"No service found with IP %s, attempt %d/%d\", ip4, i+1, maxDNSServiceIPAttempts)\n\t\t\ttime.Sleep(DNSAddressRetryInterval)\n\t\t\tcontinue\n\t\t}\n\t\tif s.Name == dnsServiceName && s.Namespace == dnsServiceNamespace {\n\t\t\tc.log.Infof(\"Service %s has successfully taken IP %s\", dnsServiceName, ip4)\n\t\t\tbreak\n\t\t}\n\t\tc.log.Warnf(\"Deleting service %s in namespace %s whose IP %s conflicts with %s\", s.Name, s.Namespace, ip4, dnsServiceName)\n\t\tif err := c.killConflictingService(s); err != nil {\n\t\t\tc.log.WithError(err).Warnf(\"Failed to delete service %s in namespace %s\", s.Name, s.Namespace)\n\t\t\tcontinue\n\t\t}\n\t\tif err := c.deleteDNSOperatorPods(); err != nil {\n\t\t\tc.log.WithError(err).Warn(\"Failed to delete DNS operator pods\")\n\t\t}\n\t}\n}\n\nfunc (c *controller) findServiceByIP(ip string, services *[]v1.Service) *v1.Service {\n\tfor _, s := range *services {\n\t\tif s.Spec.ClusterIP == ip {\n\t\t\treturn &s\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (c *controller) killConflictingService(s *v1.Service) error {\n\treturn utils.Retry(maxDeletionAttempts, DeletionRetryInterval, c.log, func() error {\n\t\treturn c.kc.DeleteService(s.Name, s.Namespace)\n\t})\n}\n\nfunc (c *controller) deleteDNSOperatorPods() error {\n\treturn utils.Retry(maxDeletionAttempts, DeletionRetryInterval, c.log, func() error {\n\t\treturn c.kc.DeletePods(dnsOperatorNamespace)\n\t})\n}\n\nfunc (c *controller) getMCSLogs() (string, error) {\n\tlogs := \"\"\n\tnamespace := \"openshift-machine-config-operator\"\n\tpods, err := c.kc.GetPods(namespace, map[string]string{\"k8s-app\": \"machine-config-server\"}, \"\")\n\tif err != nil {\n\t\tc.log.WithError(err).Warnf(\"Failed to get mcs pods\")\n\t\treturn \"\", nil\n\t}\n\tfor _, pod := range pods {\n\t\tpodLogs, err := c.kc.GetPodLogs(namespace, pod.Name, generalWaitTimeoutInt*10)\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warnf(\"Failed to get logs of pod %s\", pod.Name)\n\t\t\treturn \"\", nil\n\t\t}\n\t\tlogs += podLogs\n\t}\n\treturn logs, nil\n}\n\nfunc (c *controller) updateConfiguringStatusIfNeeded(hosts map[string]inventory_client.HostData) {\n\tlogs, err := c.getMCSLogs()\n\tif err != nil {\n\t\treturn\n\t}\n\tcommon.SetConfiguringStatusForHosts(c.ic, hosts, logs, false, c.log)\n}\n\nfunc (c *controller) ApproveCsrs(ctx context.Context) {\n\tc.log.Infof(\"Start approving CSRs\")\n\tticker := time.NewTicker(GeneralWaitInterval)\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tc.log.Infof(\"Finish approving CSRs\")\n\t\t\treturn\n\t\tcase <-ticker.C:\n\t\t\tcsrs, err := c.kc.ListCsrs()\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tc.approveCsrs(csrs)\n\t\t}\n\t}\n}\n\nfunc (c controller) approveCsrs(csrs *certificatesv1.CertificateSigningRequestList) {\n\tfor i := range csrs.Items {\n\t\tcsr := csrs.Items[i]\n\t\tif !isCsrApproved(&csr) {\n\t\t\tc.log.Infof(\"Approving CSR %s\", csr.Name)\n\t\t\t// We can fail and it is ok, we will retry on the next time\n\t\t\t_ = c.kc.ApproveCsr(&csr)\n\t\t}\n\t}\n}\n\nfunc isCsrApproved(csr *certificatesv1.CertificateSigningRequest) bool {\n\tfor _, condition := range csr.Status.Conditions {\n\t\tif condition.Type == certificatesv1.CertificateApproved {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (c controller) PostInstallConfigs(ctx context.Context, wg *sync.WaitGroup) {\n\tdefer func() {\n\t\tc.log.Infof(\"Finished PostInstallConfigs\")\n\t\twg.Done()\n\t}()\n\terr := utils.WaitForPredicateWithContext(ctx, LongWaitTimeout, GeneralWaitInterval, func() bool {\n\t\tctxReq := utils.GenerateRequestContext()\n\t\tcluster, err := c.ic.GetCluster(ctx)\n\t\tif err != nil {\n\t\t\tutils.RequestIDLogger(ctxReq, c.log).WithError(err).Errorf(\"Failed to get cluster %s from assisted-service\", c.ClusterID)\n\t\t\treturn false\n\t\t}\n\t\treturn *cluster.Status == models.ClusterStatusFinalizing\n\t})\n\tif err != nil {\n\t\treturn\n\t}\n\n\terrMessage := \"\"\n\terr = c.postInstallConfigs(ctx)\n\t// context was cancelled, requires usage of WaitForPredicateWithContext\n\t// no reason to set error\n\tif ctx.Err() != nil {\n\t\treturn\n\t}\n\tif err != nil {\n\t\tc.log.Error(err)\n\t\terrMessage = err.Error()\n\t\tc.Status.Error()\n\t}\n\tsuccess := err == nil\n\tc.sendCompleteInstallation(ctx, success, errMessage)\n}\n\nfunc (c controller) postInstallConfigs(ctx context.Context) error {\n\tvar err error\n\n\tc.log.Infof(\"Waiting for cluster version operator: %t\", c.WaitForClusterVersion)\n\n\tif c.WaitForClusterVersion {\n\t\tif err = c.waitingForClusterVersion(ctx); err != nil {\n\t\t\treturn errors.Wrapf(err, \"Timeout while waiting for cluster version to be available\")\n\t\t}\n\t}\n\n\t// Unlabel run-level from assisted-installer namespace after the installation.\n\t// Keeping the `run-level` label represents a security risk as it overwrites the SecurityContext configurations\n\t// used for applications deployed in this namespace.\n\tdata := []byte(`{\"metadata\":{\"labels\":{\"$patch\": \"delete\", \"openshift.io/run-level\":\"0\"}}}`)\n\tc.log.Infof(\"Removing run-level label from %s namespace\", c.ControllerConfig.Namespace)\n\terr = c.kc.PatchNamespace(c.ControllerConfig.Namespace, data)\n\tif err != nil {\n\t\t// It is a conscious decision not to fail an installation if for any reason patching the namespace\n\t\t// in order to remove the `run-level` label has failed. This will be redesigned in the next release\n\t\t// so that the `run-level` label is not created in the first place.\n\t\tc.log.Warn(\"Failed to unlabel AI namespace after the installation.\")\n\t}\n\n\terr = utils.WaitForPredicateWithContext(ctx, WaitTimeout, GeneralWaitInterval, c.addRouterCAToClusterCA)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"Timeout while waiting router ca data\")\n\t}\n\n\tunpatch, err := utils.EtcdPatchRequired(c.ControllerConfig.OpenshiftVersion)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"Failed to patch etcd\")\n\t}\n\tif unpatch && c.HighAvailabilityMode != models.ClusterHighAvailabilityModeNone {\n\t\tif err = utils.WaitForPredicateWithContext(ctx, WaitTimeout, GeneralWaitInterval, c.unpatchEtcd); err != nil {\n\t\t\treturn errors.Wrapf(err, \"Timeout while trying to unpatch etcd\")\n\t\t}\n\t} else {\n\t\tc.log.Infof(\"Skipping etcd unpatch for cluster version %s\", c.ControllerConfig.OpenshiftVersion)\n\t}\n\n\tif err = utils.WaitForPredicateWithContext(ctx, WaitTimeout, GeneralWaitInterval, c.validateConsoleAvailability); err != nil {\n\t\treturn errors.Wrapf(err, \"Timeout while waiting for console to become available\")\n\t}\n\n\t// Apply post install manifests\n\terr = utils.WaitForPredicateWithContext(ctx, retryPostManifestTimeout, GeneralWaitInterval, c.applyPostInstallManifests)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"Failed to apply post manifests\")\n\t}\n\n\tif err != c.waitForOLMOperators(ctx) {\n\t\t// In case the timeout occur, we have to update the pending OLM operators to failed state,\n\t\t// so the assisted-service can update the cluster state to completed.\n\t\tif err = c.updatePendingOLMOperators(); err != nil {\n\t\t\treturn errors.Errorf(\"Timeout while waiting for some of the operators and not able to update its state\")\n\t\t}\n\t\treturn errors.Wrapf(err, \"Timeout while waiting for OLM operators be installed\")\n\t}\n\n\treturn nil\n}\n\nfunc (c controller) applyPostInstallManifests() bool {\n\tctx := utils.GenerateRequestContext()\n\ttempDir, err := ioutil.TempDir(\"\", \"controller-custom-manifests-\")\n\tif err != nil {\n\t\tc.log.WithError(err).Error(\"Failed to create temporary directory to create custom manifests.\")\n\t\treturn false\n\t}\n\tc.log.Infof(\"Created temporary directory %s to store custom manifest content.\", tempDir)\n\tdefer os.RemoveAll(tempDir)\n\n\tcustomManifestPath := path.Join(tempDir, customManifestsFile)\n\tif err = c.ic.DownloadFile(ctx, customManifestsFile, customManifestPath); err != nil {\n\t\treturn false\n\t}\n\n\tkubeconfigName, err := c.downloadKubeconfigNoingress(ctx, tempDir)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\terr = c.ops.CreateManifests(kubeconfigName, customManifestPath)\n\tif err != nil {\n\t\tc.log.WithError(err).Error(\"Failed to apply manifest file.\")\n\t\treturn false\n\t}\n\n\treturn true\n}\n\nfunc (c controller) UpdateBMHs(ctx context.Context, wg *sync.WaitGroup) {\n\tdefer func() {\n\t\tc.log.Infof(\"Finished UpdateBMHs\")\n\t\twg.Done()\n\t}()\n\t_ = utils.WaitForPredicateWithContext(ctx, time.Duration(1<<63-1), GeneralWaitInterval, func() bool {\n\t\tbmhs, err := c.kc.ListBMHs()\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Errorf(\"Failed to list BMH hosts\")\n\t\t\treturn false\n\t\t}\n\n\t\tc.log.Infof(\"Number of BMHs is %d\", len(bmhs.Items))\n\n\t\tmachines, err := c.unallocatedMachines(bmhs)\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Errorf(\"Failed to find unallocated machines\")\n\t\t\treturn false\n\t\t}\n\n\t\tc.log.Infof(\"Number of unallocated Machines is %d\", len(machines.Items))\n\n\t\tallUpdated := c.updateBMHs(&bmhs, machines)\n\t\tif allUpdated {\n\t\t\tc.log.Infof(\"Updated all the BMH CRs, finished successfully\")\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t})\n}\n\nfunc (c controller) unallocatedMachines(bmhList metal3v1alpha1.BareMetalHostList) (*mapiv1beta1.MachineList, error) {\n\tmachineList, err := c.kc.ListMachines()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tunallocatedList := &mapiv1beta1.MachineList{Items: machineList.Items[:0]}\n\n\tfor _, machine := range machineList.Items {\n\t\trole, ok := machine.Labels[\"machine.openshift.io/cluster-api-machine-role\"]\n\t\tif ok && role == \"worker\" {\n\t\t\tc.log.Infof(\"Found worker machine %s\", machine.Name)\n\t\t}\n\t\tunallocated := ok && role == \"worker\"\n\t\tfor _, bmh := range bmhList.Items {\n\t\t\tif bmh.Spec.ConsumerRef != nil && bmh.Spec.ConsumerRef.Name == machine.Name {\n\t\t\t\tunallocated = false\n\t\t\t}\n\t\t}\n\t\tif unallocated {\n\t\t\tunallocatedList.Items = append(unallocatedList.Items, machine)\n\t\t}\n\t}\n\treturn unallocatedList, nil\n}\n\nfunc (c controller) copyBMHAnnotationsToStatus(bmh *metal3v1alpha1.BareMetalHost) (bool, error) {\n\tannotations := bmh.GetAnnotations()\n\tcontent := []byte(annotations[metal3v1alpha1.StatusAnnotation])\n\n\tif annotations[metal3v1alpha1.StatusAnnotation] == \"\" {\n\t\tc.log.Infof(\"Skipping setting status of BMH host %s, status annotation not present\", bmh.Name)\n\t\treturn false, nil\n\t}\n\tobjStatus, err := c.unmarshalStatusAnnotation(content)\n\tif err != nil {\n\t\tc.log.WithError(err).Errorf(\"Failed to unmarshal status annotation of %s\", bmh.Name)\n\t\treturn false, err\n\t}\n\tbmh.Status = *objStatus\n\tif bmh.Status.LastUpdated.IsZero() {\n\t\t// Ensure the LastUpdated timestamp in set to avoid\n\t\t// infinite loops if the annotation only contained\n\t\t// part of the status information.\n\t\tt := metav1.Now()\n\t\tbmh.Status.LastUpdated = &t\n\t}\n\terr = c.kc.UpdateBMHStatus(bmh)\n\tif err != nil {\n\t\tc.log.WithError(err).Errorf(\"Failed to update status of BMH %s\", bmh.Name)\n\t\treturn false, err\n\t}\n\treturn true, nil\n}\n\nfunc (c controller) unmarshalStatusAnnotation(content []byte) (*metal3v1alpha1.BareMetalHostStatus, error) {\n\tbmhStatus := &metal3v1alpha1.BareMetalHostStatus{}\n\terr := json.Unmarshal(content, bmhStatus)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn bmhStatus, nil\n}\n\n// updateBMHWithProvisioning() If we are in None or Unmanaged state:\n// - set ExternallyProvisioned\n// - Removing pausedAnnotation from BMH master hosts\n// - set the consumer ref\nfunc (c controller) updateBMHWithProvisioning(bmh *metal3v1alpha1.BareMetalHost, machineList *mapiv1beta1.MachineList) error {\n\tif bmh.Status.Provisioning.State != metal3v1alpha1.StateNone && bmh.Status.Provisioning.State != metal3v1alpha1.StateUnmanaged {\n\t\tc.log.Infof(\"bmh %s Provisioning.State=%s - ignoring\", bmh.Name, bmh.Status.Provisioning.State)\n\t\treturn nil\n\t}\n\tvar err error\n\tneedsUpdate := !bmh.Spec.ExternallyProvisioned\n\tbmh.Spec.ExternallyProvisioned = true\n\t// when baremetal operator is enabled, we need to remove the pausedAnnotation\n\t// to indicated that the statusAnnotation is available. This is only on\n\t// the master nodes.\n\tannotations := bmh.GetAnnotations()\n\tif _, ok := annotations[metal3v1alpha1.PausedAnnotation]; ok {\n\t\tc.log.Infof(\"Removing pausedAnnotation from BMH host %s\", bmh.Name)\n\t\tdelete(annotations, metal3v1alpha1.PausedAnnotation)\n\t\tneedsUpdate = true\n\t}\n\tif bmh.Spec.ConsumerRef == nil {\n\t\terr = c.updateConsumerRef(bmh, machineList)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tneedsUpdate = true\n\t}\n\tif needsUpdate {\n\t\tc.log.Infof(\"Updating bmh %s\", bmh.Name)\n\t\terr = c.kc.UpdateBMH(bmh)\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"Failed to update BMH %s\", bmh.Name)\n\t\t}\n\t}\n\treturn nil\n}\n\n// updateBMHWithNOProvisioning()\n// - move the BMH status annotation to the Status sub resource\n// - set the consumer ref\nfunc (c controller) updateBMHWithNOProvisioning(bmh *metal3v1alpha1.BareMetalHost, machineList *mapiv1beta1.MachineList) error {\n\tstatusUpdated, err := c.copyBMHAnnotationsToStatus(bmh)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"Failed to copy BMH Annotations to Status %s\", bmh.Name)\n\t}\n\tif statusUpdated {\n\t\t// refresh the BMH after the StatusUpdate to get the new generation\n\t\tbmh, err = c.kc.GetBMH(bmh.Name)\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"Failed to refresh the BMH %s\", bmh.Name)\n\t\t}\n\t}\n\tneedsUpdate := false\n\tannotations := bmh.GetAnnotations()\n\tif _, ok := annotations[metal3v1alpha1.StatusAnnotation]; ok {\n\t\tdelete(annotations, metal3v1alpha1.StatusAnnotation)\n\t\tneedsUpdate = true\n\t}\n\n\tif bmh.Spec.ConsumerRef == nil {\n\t\terr = c.updateConsumerRef(bmh, machineList)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tneedsUpdate = true\n\t}\n\tif needsUpdate {\n\t\tc.log.Infof(\"Updating bmh %s\", bmh.Name)\n\t\terr = c.kc.UpdateBMH(bmh)\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"Failed to update BMH %s\", bmh.Name)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (c controller) updateConsumerRef(bmh *metal3v1alpha1.BareMetalHost, machineList *mapiv1beta1.MachineList) error {\n\t//\tupdate consumer ref for workers only in case machineset controller has already\n\t//\tcreated an unassigned Machine (base on machineset replica count)\n\tif len(machineList.Items) == 0 {\n\t\treturn fmt.Errorf(\"no available machine for bmh %s, need to wait for machineset controller to create one\", bmh.Name)\n\t}\n\tc.log.Infof(\"Updating consumer ref for bmh %s\", bmh.Name)\n\tmachine := &machineList.Items[0]\n\tmachineList.Items = machineList.Items[1:]\n\tbmh.Spec.ConsumerRef = &v1.ObjectReference{\n\t\tAPIVersion: machine.APIVersion,\n\t\tKind:       machine.Kind,\n\t\tNamespace:  machine.Namespace,\n\t\tName:       machine.Name,\n\t}\n\treturn nil\n}\n\nfunc (c controller) updateBMHs(bmhList *metal3v1alpha1.BareMetalHostList, machineList *mapiv1beta1.MachineList) bool {\n\tprovisioningExists, err := c.kc.IsMetalProvisioningExists()\n\tif err != nil {\n\t\tc.log.WithError(err).Errorf(\"Failed get IsMetalProvisioningExists\")\n\t\treturn false\n\t}\n\n\tallUpdated := true\n\tfor i := range bmhList.Items {\n\t\tbmh := bmhList.Items[i]\n\t\tc.log.Infof(\"Checking bmh %s\", bmh.Name)\n\n\t\tif provisioningExists {\n\t\t\terr = c.updateBMHWithProvisioning(&bmh, machineList)\n\t\t} else {\n\t\t\terr = c.updateBMHWithNOProvisioning(&bmh, machineList)\n\t\t}\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Errorf(\"Failed to update BMH %s\", bmh.Name)\n\t\t\tallUpdated = false\n\t\t\tcontinue\n\t\t}\n\t}\n\treturn allUpdated\n}\n\nfunc (c controller) unpatchEtcd() bool {\n\tc.log.Infof(\"Unpatching etcd\")\n\tif err := c.kc.UnPatchEtcd(); err != nil {\n\t\tc.log.Error(err)\n\t\treturn false\n\t}\n\treturn true\n}\n\n// AddRouterCAToClusterCA adds router CA to cluster CA in kubeconfig\nfunc (c controller) addRouterCAToClusterCA() bool {\n\tctx := utils.GenerateRequestContext()\n\tlog := utils.RequestIDLogger(ctx, c.log)\n\tlog.Infof(\"Start adding ingress ca to cluster\")\n\tcaConfigMap, err := c.kc.GetConfigMap(ingressConfigMapNamespace, ingressConfigMapName)\n\n\tif err != nil {\n\t\tlog.WithError(err).Errorf(\"fetching %s configmap from %s namespace\", ingressConfigMapName, ingressConfigMapNamespace)\n\t\treturn false\n\t}\n\tlog.Infof(\"Sending ingress certificate to inventory service. Certificate data %s\", caConfigMap.Data[\"ca-bundle.crt\"])\n\terr = c.ic.UploadIngressCa(ctx, caConfigMap.Data[\"ca-bundle.crt\"], c.ClusterID)\n\tif err != nil {\n\t\tlog.WithError(err).Errorf(\"Failed to upload ingress ca to assisted-service\")\n\t\treturn false\n\t}\n\tlog.Infof(\"Ingress ca successfully sent to inventory\")\n\treturn true\n\n}\n\nfunc (c controller) getMaximumOLMTimeout(operators []*models.MonitoredOperator) time.Duration {\n\ttimeout := WaitTimeout.Seconds()\n\tfor _, operator := range operators {\n\t\ttimeout = math.Max(float64(operator.TimeoutSeconds), timeout)\n\t}\n\n\treturn time.Duration(timeout * float64(time.Second))\n}\n\nfunc (c controller) getProgressingOLMOperators() ([]*models.MonitoredOperator, error) {\n\tret := make([]*models.MonitoredOperator, 0)\n\toperators, err := c.ic.GetClusterMonitoredOLMOperators(context.TODO(), c.ClusterID)\n\tif err != nil {\n\t\tc.log.WithError(err).Warningf(\"Failed to connect to assisted service\")\n\t\treturn ret, err\n\t}\n\tfor index := range operators {\n\t\tif operators[index].Status != models.OperatorStatusAvailable && operators[index].Status != models.OperatorStatusFailed {\n\t\t\tret = append(ret, &operators[index])\n\t\t}\n\t}\n\treturn ret, nil\n}\n\nfunc (c controller) updatePendingOLMOperators() error {\n\tc.log.Infof(\"Updating pending OLM operators\")\n\tctx := utils.GenerateRequestContext()\n\toperators, err := c.getProgressingOLMOperators()\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor _, operator := range operators {\n\t\tc.Status.OperatorError(operator.Name)\n\t\terr := c.ic.UpdateClusterOperator(ctx, c.ClusterID, operator.Name, models.OperatorStatusFailed, \"Waiting for operator timed out\")\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warnf(\"Failed to update olm %s status\", operator.Name)\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// waitForOLMOperators wait until all OLM monitored operators are available or failed.\nfunc (c controller) waitForOLMOperators(ctx context.Context) error {\n\toperators, err := c.getProgressingOLMOperators()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(operators) == 0 {\n\t\treturn nil\n\t}\n\n\thandlers := make(map[string]*ClusterServiceVersionHandler)\n\n\tfor index := range operators {\n\t\thandlers[operators[index].Name] = NewClusterServiceVersionHandler(c.kc, operators[index], c.Status)\n\t}\n\n\tareOLMOperatorsAvailable := func() bool {\n\t\tif len(handlers) == 0 {\n\t\t\treturn true\n\t\t}\n\n\t\tfor index := range handlers {\n\t\t\tif c.isOperatorAvailable(handlers[index]) {\n\t\t\t\tdelete(handlers, index)\n\t\t\t}\n\t\t}\n\t\treturn false\n\t}\n\n\twaitTimeout := c.getMaximumOLMTimeout(operators)\n\tc.log.Infof(\"Waiting for OLM operators for %v\", waitTimeout)\n\treturn utils.WaitForPredicateWithContext(ctx, waitTimeout, GeneralWaitInterval, areOLMOperatorsAvailable)\n}\n\n// validateConsoleAvailability checks if the console operator is available\nfunc (c controller) validateConsoleAvailability() bool {\n\treturn c.isOperatorAvailable(NewClusterOperatorHandler(c.kc, consoleOperatorName))\n}\n\n// waitingForClusterVersion checks the Cluster Version Operator availability in the\n// new OCP cluster. A success would be announced only when the service acknowledges\n// the CVO availability, in order to avoid unsycned scenarios.\n// In case cvo changes it message we will update timer but we want to have maximum timeout\n// for this context with timeout is used\nfunc (c controller) waitingForClusterVersion(ctx context.Context) error {\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, CVOMaxTimeout)\n\tdefer cancel()\n\tisClusterVersionAvailable := func(timer *time.Timer) bool {\n\t\treturn c.isOperatorAvailable(NewClusterVersionHandler(c.kc, timer))\n\t}\n\treturn utils.WaitForPredicateWithTimer(ctxWithTimeout, WaitTimeout, GeneralProgressUpdateInt, isClusterVersionAvailable)\n}\n\nfunc (c controller) sendCompleteInstallation(ctx context.Context, isSuccess bool, errorInfo string) {\n\tc.log.Infof(\"Start complete installation step, with params success: %t, error info: %s\", isSuccess, errorInfo)\n\t_ = utils.WaitForPredicateWithContext(ctx, CompleteTimeout, GeneralProgressUpdateInt, func() bool {\n\t\tctxReq := utils.GenerateRequestContext()\n\t\tif err := c.ic.CompleteInstallation(ctxReq, c.ClusterID, isSuccess, errorInfo); err != nil {\n\t\t\tutils.RequestIDLogger(ctxReq, c.log).Error(err)\n\t\t\treturn false\n\t\t}\n\t\treturn true\n\t})\n\tc.log.Infof(\"Done complete installation step\")\n}\n\n// logClusterOperatorsStatus logging cluster operators status\nfunc (c controller) logClusterOperatorsStatus() {\n\toperators, err := c.kc.ListClusterOperators()\n\tif err != nil {\n\t\tc.log.WithError(err).Warning(\"Failed to list cluster operators\")\n\t\treturn\n\t}\n\n\tfor _, operator := range operators.Items {\n\t\tc.log.Infof(\"Operator %s, statuses: %v\", operator.Name, operator.Status.Conditions)\n\t}\n}\n\n/**\n * This function upload the following logs at once to the service at the end of the installation process\n * It takes a lenient approach so if some logs are not available it ignores them and moves on\n * currently the bundled logs are:\n * - controller logs\n * - oc must-gather logs\n **/\nfunc (c controller) uploadSummaryLogs(podName string, namespace string, sinceSeconds int64) error {\n\tvar tarentries = make([]utils.TarEntry, 0)\n\tvar ok bool = true\n\tctx := utils.GenerateRequestContext()\n\n\tc.logClusterOperatorsStatus()\n\tif c.Status.HasError() || c.Status.HasOperatorError() {\n\t\tc.log.Infof(\"Uploading oc must-gather logs\")\n\t\timages := c.parseMustGatherImages()\n\t\tif tarfile, err := c.collectMustGatherLogs(ctx, images...); err == nil {\n\t\t\tif entry, tarerr := utils.NewTarEntryFromFile(tarfile); tarerr == nil {\n\t\t\t\ttarentries = append(tarentries, *entry)\n\t\t\t}\n\t\t} else {\n\t\t\tok = false\n\t\t}\n\t}\n\n\tc.log.Infof(\"Uploading logs for %s in %s\", podName, namespace)\n\tif podLogs, err := c.kc.GetPodLogsAsBuffer(namespace, podName, sinceSeconds); err == nil {\n\t\ttarentries = append(tarentries,\n\t\t\t*utils.NewTarEntry(podLogs, nil, int64(podLogs.Len()), fmt.Sprintf(\"%s.logs\", podName)))\n\t} else {\n\t\tok = false\n\t}\n\n\tif len(tarentries) == 0 {\n\t\treturn errors.New(\"No logs are available for sending summary logs\")\n\t}\n\n\t//write the combined input of the summary sources into a pipe and offload it\n\t//to the UploadLogs request to the assisted-service\n\tpr, pw := io.Pipe()\n\tdefer pr.Close()\n\n\tgo func() {\n\t\tdefer pw.Close()\n\t\terr := utils.WriteToTarGz(pw, tarentries)\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warnf(\"Failed to create tar.gz body of the log uplaod request\")\n\t\t}\n\t}()\n\t// if error will occur in goroutine above, the writer will be closed\n\t// and as a result upload will fail\n\terr := c.ic.UploadLogs(ctx, c.ClusterID, models.LogsTypeController, pr)\n\tif err != nil {\n\t\tutils.RequestIDLogger(ctx, c.log).WithError(err).Error(\"Failed to upload logs\")\n\t\treturn err\n\t}\n\n\tif !ok {\n\t\tmsg := \"Some Logs were not collected in summary\"\n\t\tc.log.Errorf(msg)\n\t\treturn errors.New(msg)\n\t}\n\n\treturn nil\n}\n\nfunc (c controller) parseMustGatherImages() []string {\n\timages := make([]string, 0)\n\tif c.MustGatherImage == \"\" {\n\t\tc.log.Infof(\"collecting must-gather logs into using image from release\")\n\t\treturn images\n\t}\n\n\tc.log.Infof(\"collecting must-gather logs using this image configuration %s\", c.MustGatherImage)\n\tvar imageMap map[string]string\n\terr := json.Unmarshal([]byte(c.MustGatherImage), &imageMap)\n\tif err != nil {\n\t\t//MustGatherImage is not a JSON. Pass it as is\n\t\timages = append(images, c.MustGatherImage)\n\t\treturn images\n\t}\n\n\t//Use the parsed MustGatherImage to find the images needed for collecting\n\t//the information\n\tif c.Status.HasError() {\n\t\t//general error - collect all data from the cluster using the standard image\n\t\timages = append(images, imageMap[\"ocp\"])\n\t}\n\n\tfor _, op := range c.Status.GetOperatorsInError() {\n\t\tif imageMap[op] != \"\" {\n\t\t\t//per failed operator - add feature image for collecting more\n\t\t\t//information about failed olm operators\n\t\t\timages = append(images, imageMap[op])\n\t\t}\n\t}\n\tc.log.Infof(\"collecting must-gather logs with images: %v\", images)\n\treturn images\n}\n\nfunc (c controller) downloadKubeconfigNoingress(ctx context.Context, dir string) (string, error) {\n\t// Download kubeconfig file\n\tkubeconfigPath := path.Join(dir, kubeconfigFileName)\n\terr := c.ic.DownloadFile(ctx, kubeconfigFileName, kubeconfigPath)\n\tif err != nil {\n\t\tc.log.Errorf(\"Failed to download noingress kubeconfig %v\\n\", err)\n\t\treturn \"\", err\n\t}\n\tc.log.Infof(\"Downloaded %s to %s.\", kubeconfigFileName, kubeconfigPath)\n\n\treturn kubeconfigPath, nil\n}\n\nfunc (c controller) collectMustGatherLogs(ctx context.Context, images ...string) (string, error) {\n\ttempDir, ferr := ioutil.TempDir(\"\", \"controller-must-gather-logs-\")\n\tif ferr != nil {\n\t\tc.log.Errorf(\"Failed to create temp directory for must-gather-logs %v\\n\", ferr)\n\t\treturn \"\", ferr\n\t}\n\n\tkubeconfigPath, err := c.downloadKubeconfigNoingress(ctx, tempDir)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\t//collect must gather logs\n\tlogtar, err := c.ops.GetMustGatherLogs(tempDir, kubeconfigPath, images...)\n\tif err != nil {\n\t\tc.log.Errorf(\"Failed to collect must-gather logs %v\\n\", err)\n\t\treturn \"\", err\n\t}\n\n\treturn logtar, nil\n}\n\n// Uploading logs every 5 minutes\n// We will take logs of assisted controller and upload them to assisted-service\n// by creating tar gz of them.\nfunc (c *controller) UploadLogs(ctx context.Context, wg *sync.WaitGroup) {\n\tpodName := \"\"\n\tticker := time.NewTicker(LogsUploadPeriod)\n\tprogressCtx := utils.GenerateRequestContext()\n\n\tdefer func() {\n\t\tc.log.Infof(\"Finished UploadLogs\")\n\t\twg.Done()\n\t}()\n\tc.log.Infof(\"Start sending logs\")\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif podName != \"\" {\n\t\t\t\tc.log.Infof(\"Upload final controller and cluster logs before exit\")\n\t\t\t\tc.ic.ClusterLogProgressReport(progressCtx, c.ClusterID, models.LogsStateRequested)\n\t\t\t\t_ = utils.WaitForPredicate(WaitTimeout, LogsUploadPeriod, func() bool {\n\t\t\t\t\terr := c.uploadSummaryLogs(podName, c.Namespace, controllerLogsSecondsAgo)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tc.log.Infof(\"retry uploading logs in 5 minutes...\")\n\t\t\t\t\t}\n\t\t\t\t\treturn err == nil\n\t\t\t\t})\n\t\t\t}\n\t\t\tc.ic.ClusterLogProgressReport(progressCtx, c.ClusterID, models.LogsStateCompleted)\n\t\t\treturn\n\t\tcase <-ticker.C:\n\t\t\tif podName == \"\" {\n\t\t\t\tpods, err := c.kc.GetPods(c.Namespace, map[string]string{\"job-name\": \"assisted-installer-controller\"},\n\t\t\t\t\tfmt.Sprintf(\"status.phase=%s\", v1.PodRunning))\n\t\t\t\tif err != nil {\n\t\t\t\t\tc.log.WithError(err).Warnf(\"Failed to get controller pod name\")\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif len(pods) < 1 {\n\t\t\t\t\tc.log.Infof(\"Didn't find myself, something strange had happened\")\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tpodName = pods[0].Name\n\t\t\t}\n\n\t\t\t//on normal flow, keep updating the controller log output every 5 minutes\n\t\t\tc.log.Infof(\"Start uploading controller logs (intermediate snapshot)\")\n\t\t\terr := common.UploadPodLogs(c.kc, c.ic, c.ClusterID, podName, c.Namespace, controllerLogsSecondsAgo, c.log)\n\t\t\tif err != nil {\n\t\t\t\tc.log.WithError(err).Warnf(\"Failed to upload controller logs\")\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (c controller) SetReadyState() {\n\tc.log.Infof(\"Start waiting to be ready\")\n\t_ = utils.WaitForPredicate(WaitTimeout, 1*time.Second, func() bool {\n\t\t_, err := c.ic.GetCluster(context.TODO())\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warningf(\"Failed to connect to assisted service\")\n\t\t\treturn false\n\t\t}\n\t\tc.log.Infof(\"assisted-service is available\")\n\n\t\t_, err = c.kc.ListNodes()\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warningf(\"Failed to connect to ocp cluster\")\n\t\t\treturn false\n\t\t}\n\t\tc.log.Infof(\"kube-apiserver is available\")\n\n\t\tc.log.Infof(\"Sending ready event\")\n\t\tif _, err := c.kc.CreateEvent(c.Namespace, common.AssistedControllerIsReadyEvent,\n\t\t\t\"Assisted controller managed to connect to assisted service and kube-apiserver and is ready to start\",\n\t\t\tcommon.AssistedControllerPrefix); err != nil && !apierrors.IsAlreadyExists(err) {\n\t\t\tc.log.WithError(err).Errorf(\"Failed to spawn event\")\n\t\t\treturn false\n\t\t}\n\n\t\treturn true\n\t})\n}\n", "package ops\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"strconv\"\n\t\"text/template\"\n\n\t\"io/ioutil\"\n\t\"os/exec\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"syscall\"\n\n\t\"github.com/pkg/errors\"\n\t\"github.com/sirupsen/logrus\"\n\n\t\"github.com/openshift/assisted-installer/src/config\"\n\t\"github.com/openshift/assisted-installer/src/inventory_client\"\n\t\"github.com/openshift/assisted-installer/src/utils\"\n)\n\n//go:generate mockgen -source=ops.go -package=ops -destination=mock_ops.go\ntype Ops interface {\n\tExecPrivilegeCommand(liveLogger io.Writer, command string, args ...string) (string, error)\n\tExecCommand(liveLogger io.Writer, command string, args ...string) (string, error)\n\tMkdir(dirName string) error\n\tWriteImageToDisk(ignitionPath string, device string, progressReporter inventory_client.InventoryClient, extra []string) error\n\tReboot() error\n\tSetBootOrder(device string) error\n\tExtractFromIgnition(ignitionPath string, fileToExtract string) error\n\tSystemctlAction(action string, args ...string) error\n\tPrepareController() error\n\tGetVGByPV(pvName string) (string, error)\n\tRemoveVG(vgName string) error\n\tRemoveLV(lvName, vgName string) error\n\tRemovePV(pvName string) error\n\tWipefs(device string) error\n\tGetMCSLogs() (string, error)\n\tUploadInstallationLogs(isBootstrap bool) (string, error)\n\tReloadHostFile(filepath string) error\n\tCreateOpenshiftSshManifest(filePath, template, sshPubKeyPath string) error\n\tGetMustGatherLogs(workDir, kubeconfigPath string, images ...string) (string, error)\n\tCreateRandomHostname(hostname string) error\n\tGetHostname() (string, error)\n\tEvaluateDiskSymlink(string) string\n\tCreateManifests(string, string) error\n}\n\nconst (\n\tcontrollerDeployFolder         = \"/assisted-installer-controller/deploy\"\n\tmanifestsFolder                = \"/opt/openshift/manifests\"\n\trenderedControllerCm           = \"assisted-installer-controller-cm.yaml\"\n\tcontrollerDeployCmTemplate     = \"assisted-installer-controller-cm.yaml.template\"\n\trenderedControllerPod          = \"assisted-installer-controller-pod.yaml\"\n\tcontrollerDeployPodTemplate    = \"assisted-installer-controller-pod.yaml.template\"\n\trenderedControllerSecret       = \"assisted-installer-controller-secret.yaml\"\n\tcontrollerDeploySecretTemplate = \"assisted-installer-controller-secret.yaml.template\"\n)\n\ntype ops struct {\n\tlog       *logrus.Logger\n\tlogWriter *utils.LogWriter\n\tcmdEnv    []string\n}\n\n// NewOps return a new ops interface\nfunc NewOps(logger *logrus.Logger, proxySet bool) Ops {\n\tcmdEnv := os.Environ()\n\tif proxySet && (config.GlobalConfig.HTTPProxy != \"\" || config.GlobalConfig.HTTPSProxy != \"\") {\n\t\tif config.GlobalConfig.HTTPProxy != \"\" {\n\t\t\tcmdEnv = append(cmdEnv, fmt.Sprintf(\"HTTP_PROXY=%s\", config.GlobalConfig.HTTPProxy))\n\t\t}\n\t\tif config.GlobalConfig.HTTPSProxy != \"\" {\n\t\t\tcmdEnv = append(cmdEnv, fmt.Sprintf(\"HTTPS_PROXY=%s\", config.GlobalConfig.HTTPSProxy))\n\t\t}\n\t\tif config.GlobalConfig.NoProxy != \"\" {\n\t\t\tcmdEnv = append(cmdEnv, fmt.Sprintf(\"NO_PROXY=%s\", config.GlobalConfig.NoProxy))\n\t\t}\n\t}\n\treturn &ops{logger, utils.NewLogWriter(logger), cmdEnv}\n}\n\n// ExecPrivilegeCommand execute a command in the host environment via nsenter\nfunc (o *ops) ExecPrivilegeCommand(liveLogger io.Writer, command string, args ...string) (string, error) {\n\tcommandBase := \"nsenter\"\n\targuments := []string{\"-t\", \"1\", \"-m\", \"-i\", \"--\", command}\n\targuments = append(arguments, args...)\n\treturn o.ExecCommand(liveLogger, commandBase, arguments...)\n}\n\ntype ExecCommandError struct {\n\tCommand    string\n\tArgs       []string\n\tEnv        []string\n\tExitErr    error\n\tOutput     string\n\tWaitStatus int\n}\n\nfunc (e *ExecCommandError) Error() string {\n\tlastOutput := e.Output\n\tif len(e.Output) > 200 {\n\t\tlastOutput = \"... \" + e.Output[len(e.Output)-200:]\n\t}\n\n\treturn fmt.Sprintf(\"failed executing %s %v, Error %s, LastOutput \\\"%s\\\"\", e.Command, e.Args, e.ExitErr, lastOutput)\n}\n\nfunc (e *ExecCommandError) DetailedError() string {\n\treturn fmt.Sprintf(\"failed executing %s %v, env vars %v, error %s, waitStatus %d, Output \\\"%s\\\"\", e.Command, e.Args, e.Env, e.ExitErr, e.WaitStatus, e.Output)\n}\n\n// ExecCommand executes command.\nfunc (o *ops) ExecCommand(liveLogger io.Writer, command string, args ...string) (string, error) {\n\n\tvar stdoutBuf bytes.Buffer\n\tcmd := exec.Command(command, args...)\n\tif liveLogger != nil {\n\t\tcmd.Stdout = io.MultiWriter(liveLogger, &stdoutBuf)\n\t\tcmd.Stderr = io.MultiWriter(liveLogger, &stdoutBuf)\n\t} else {\n\t\tcmd.Stdout = &stdoutBuf\n\t\tcmd.Stderr = &stdoutBuf\n\t}\n\tcmd.Env = o.cmdEnv\n\terr := cmd.Run()\n\toutput := strings.TrimSpace(stdoutBuf.String())\n\tif err != nil {\n\n\t\t// Get all lines from Error message\n\t\terrorIndex := strings.Index(output, \"Error\")\n\t\t// if Error not found return all output\n\t\tif errorIndex > -1 {\n\t\t\toutput = output[errorIndex:]\n\t\t}\n\n\t\texecErr := &ExecCommandError{\n\t\t\tCommand: command,\n\t\t\tArgs:    args,\n\t\t\tEnv:     cmd.Env,\n\t\t\tExitErr: err,\n\t\t\tOutput:  output,\n\t\t}\n\t\tif exitErr, ok := err.(*exec.ExitError); ok {\n\t\t\tif status, ok := exitErr.Sys().(syscall.WaitStatus); ok {\n\t\t\t\texecErr.WaitStatus = status.ExitStatus()\n\t\t\t}\n\t\t}\n\t\tif liveLogger != nil {\n\t\t\t//If the caller didn't provide liveLogger the log isn't interesting and might spam\n\t\t\to.log.Info(execErr.DetailedError())\n\t\t}\n\t\treturn output, execErr\n\t}\n\to.log.Debug(\"Command executed:\", \" command\", command, \" arguments\", args, \"env vars\", cmd.Env, \"output\", output)\n\treturn output, err\n}\n\nfunc (o *ops) Mkdir(dirName string) error {\n\to.log.Infof(\"Creating directory: %s\", dirName)\n\t_, err := o.ExecPrivilegeCommand(o.logWriter, \"mkdir\", \"-p\", dirName)\n\treturn err\n}\n\nfunc (o *ops) SystemctlAction(action string, args ...string) error {\n\to.log.Infof(\"Running systemctl %s %s\", action, args)\n\t_, err := o.ExecPrivilegeCommand(o.logWriter, \"systemctl\", append([]string{action}, args...)...)\n\tif err != nil {\n\t\to.log.Errorf(\"Failed executing systemctl %s %s\", action, args)\n\t}\n\treturn errors.Wrapf(err, \"Failed executing systemctl %s %s\", action, args)\n}\n\nfunc (o *ops) WriteImageToDisk(ignitionPath string, device string, progressReporter inventory_client.InventoryClient, extraArgs []string) error {\n\tallArgs := installerArgs(ignitionPath, device, extraArgs)\n\to.log.Infof(\"Writing image and ignition to disk with arguments: %v\", allArgs)\n\t_, err := o.ExecPrivilegeCommand(NewCoreosInstallerLogWriter(o.log, progressReporter, config.GlobalConfig.HostID),\n\t\t\"coreos-installer\", allArgs...)\n\treturn err\n}\n\nfunc (o *ops) EvaluateDiskSymlink(device string) string {\n\t// Overcome https://github.com/coreos/coreos-installer/issues/512 bug.\n\t// coreos-installer has a bug where when a disk has busy partitions, it will\n\t// print a confusing error message if that disk doesn't have a `/dev/*` style path.\n\t// The service may give us paths that don't have the `/dev/*` path format but instead\n\t// are symlinks to the actual `/dev/*` path. e.g. `/dev/disk/by-id/wwn-*`.\n\t// To fix the bug we simply resolve the symlink and pass the resolved link to coreos-installer.\n\tlinkTarget, err := filepath.EvalSymlinks(device)\n\tif err != nil {\n\t\to.log.Warnf(\"Failed to filepath.EvalSymlinks(%s): %s. Continuing with %s anyway.\",\n\t\t\tdevice, err.Error(), device)\n\t} else {\n\t\to.log.Infof(\"Resolving installation device %s symlink to %s \", device, linkTarget)\n\t\tdevice = linkTarget\n\t}\n\treturn device\n}\n\nfunc installerArgs(ignitionPath string, device string, extra []string) []string {\n\tallArgs := []string{\"install\", \"--insecure\", \"-i\", ignitionPath}\n\tif extra != nil {\n\t\tallArgs = append(allArgs, extra...)\n\t}\n\treturn append(allArgs, device)\n}\n\nfunc (o *ops) Reboot() error {\n\to.log.Info(\"Rebooting node\")\n\t_, err := o.ExecPrivilegeCommand(o.logWriter, \"shutdown\", \"-r\", \"+1\", \"'Installation completed, server is going to reboot.'\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to reboot node, err: %s\", err)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) SetBootOrder(device string) error {\n\t_, err := o.ExecPrivilegeCommand(nil, \"test\", \"-d\", \"/sys/firmware/efi\")\n\tif err != nil {\n\t\to.log.Info(\"setting the boot order on BIOS systems is not supported. Skipping...\")\n\t\treturn nil\n\t}\n\n\to.log.Info(\"Setting efibootmgr to boot from disk\")\n\n\t// efi-system is installed onto partition 2\n\t_, err = o.ExecPrivilegeCommand(o.logWriter, \"efibootmgr\", \"-d\", device, \"-p\", \"2\", \"-c\", \"-L\", \"Red Hat Enterprise Linux\", \"-l\", \"\\\\EFI\\\\redhat\\\\shimx64.efi\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to set efibootmgr to boot from disk %s, err: %s\", device, err)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) ExtractFromIgnition(ignitionPath string, fileToExtract string) error {\n\to.log.Infof(\"Getting pull secret from %s\", ignitionPath)\n\tignitionData, err := ioutil.ReadFile(ignitionPath)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to read %s : %e\", ignitionPath, err)\n\t\treturn err\n\t}\n\textractedContent, err := utils.GetFileContentFromIgnition(ignitionData, fileToExtract)\n\tif err != nil {\n\t\to.log.Error(\"Failed to parse ignition\")\n\t\treturn err\n\t}\n\n\ttmpFile := \"/opt/extracted_from_ignition.json\"\n\to.log.Infof(\"Writing extracted content to tmp file %s\", tmpFile)\n\t// #nosec\n\terr = ioutil.WriteFile(tmpFile, extractedContent, 0644)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while writing extracted content to %s\", tmpFile)\n\t\treturn err\n\t}\n\n\to.log.Infof(\"Moving %s to %s\", tmpFile, fileToExtract)\n\tdir := filepath.Dir(fileToExtract)\n\t_, err = o.ExecPrivilegeCommand(o.logWriter, \"mkdir\", \"-p\", filepath.Dir(fileToExtract))\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to create directory %s \", dir)\n\t\treturn err\n\t}\n\t_, err = o.ExecPrivilegeCommand(o.logWriter, \"mv\", tmpFile, fileToExtract)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while moving %s to %s\", tmpFile, fileToExtract)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) PrepareController() error {\n\n\tif err := o.renderControllerCm(); err != nil {\n\t\treturn err\n\t}\n\n\tif err := o.renderControllerSecret(); err != nil {\n\t\treturn err\n\t}\n\n\tif err := o.renderControllerPod(); err != nil {\n\t\treturn err\n\t}\n\n\t// Copy deploy files to manifestsFolder\n\tfiles, err := utils.FindFiles(controllerDeployFolder, utils.W_FILEONLY, \"*.yaml\")\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to get list of files from %s : %e\", controllerDeployFolder, err)\n\t\treturn err\n\t}\n\tfor _, file := range files {\n\t\terr := utils.CopyFile(file, filepath.Join(manifestsFolder, filepath.Base(file)))\n\t\tif err != nil {\n\t\t\to.log.Errorf(\"Failed to copy %s to %s. error :%e\", file, manifestsFolder, err)\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (o *ops) renderControllerCm() error {\n\tvar params = map[string]interface{}{\n\t\t\"InventoryUrl\":         config.GlobalConfig.URL,\n\t\t\"ClusterId\":            config.GlobalConfig.ClusterID,\n\t\t\"SkipCertVerification\": strconv.FormatBool(config.GlobalConfig.SkipCertVerification),\n\t\t\"CACertPath\":           config.GlobalConfig.CACertPath,\n\t\t\"HaMode\":               config.GlobalConfig.HighAvailabilityMode,\n\t\t\"CheckCVO\":             config.GlobalConfig.CheckClusterVersion,\n\t\t\"MustGatherImage\":      config.GlobalConfig.MustGatherImage,\n\t}\n\n\treturn o.renderDeploymentFiles(filepath.Join(controllerDeployFolder, controllerDeployCmTemplate),\n\t\tparams, renderedControllerCm)\n}\n\nfunc (o *ops) renderControllerSecret() error {\n\tvar params = map[string]interface{}{\n\t\t\"PullSecretToken\": config.GlobalConfig.PullSecretToken,\n\t}\n\n\treturn o.renderDeploymentFiles(filepath.Join(controllerDeployFolder, controllerDeploySecretTemplate),\n\t\tparams, renderedControllerSecret)\n}\n\nfunc (o *ops) renderControllerPod() error {\n\tvar params = map[string]interface{}{\n\t\t\"ControllerImage\":  config.GlobalConfig.ControllerImage,\n\t\t\"CACertPath\":       config.GlobalConfig.CACertPath,\n\t\t\"OpenshiftVersion\": config.GlobalConfig.OpenshiftVersion,\n\t}\n\n\tif config.GlobalConfig.ServiceIPs != \"\" {\n\t\tparams[\"ServiceIPs\"] = strings.Split(config.GlobalConfig.ServiceIPs, \",\")\n\t}\n\n\treturn o.renderDeploymentFiles(filepath.Join(controllerDeployFolder, controllerDeployPodTemplate),\n\t\tparams, renderedControllerPod)\n}\n\nfunc (o *ops) renderDeploymentFiles(srcTemplate string, params map[string]interface{}, dest string) error {\n\ttemplateData, err := ioutil.ReadFile(srcTemplate)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to read %s : %e\", srcTemplate, err)\n\t\treturn err\n\t}\n\to.log.Infof(\"Filling template file %s\", srcTemplate)\n\ttmpl := template.Must(template.New(\"assisted-controller\").Parse(string(templateData)))\n\tvar buf bytes.Buffer\n\tif err = tmpl.Execute(&buf, params); err != nil {\n\t\to.log.Errorf(\"Failed to render controller template: %e\", err)\n\t\treturn err\n\t}\n\n\tif err = o.Mkdir(manifestsFolder); err != nil {\n\t\to.log.Errorf(\"Failed to create manifests dir: %e\", err)\n\t\treturn err\n\t}\n\n\trenderedControllerYaml := filepath.Join(manifestsFolder, dest)\n\to.log.Infof(\"Writing rendered data to %s\", renderedControllerYaml)\n\t// #nosec\n\tif err = ioutil.WriteFile(renderedControllerYaml, buf.Bytes(), 0644); err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to write rendered data to %s : %e\", renderedControllerYaml, err)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) GetVGByPV(pvName string) (string, error) {\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"vgs\", \"--noheadings\", \"-o\", \"vg_name,pv_name\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to list VGs in the system\")\n\t\treturn \"\", err\n\t}\n\n\tlines := strings.Split(output, \"\\n\")\n\tfor _, line := range lines {\n\t\tres := strings.Fields(line)\n\t\tif len(res) < 2 {\n\t\t\tcontinue\n\t\t}\n\n\t\tif strings.Contains(res[1], pvName) {\n\t\t\treturn res[0], nil\n\t\t}\n\t}\n\treturn \"\", nil\n}\n\nfunc (o *ops) RemoveVG(vgName string) error {\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"vgremove\", vgName, \"-y\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to remove VG %s, output %s, error %s\", vgName, output, err)\n\t}\n\treturn err\n}\n\nfunc (o *ops) RemoveLV(lvName, vgName string) error {\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"lvremove\", fmt.Sprintf(\"/dev/%s/%s\", vgName, lvName), \"-y\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to remove LVM %s, output %s, error %s\", fmt.Sprintf(\"/dev/%s/%s\", vgName, lvName), output, err)\n\t}\n\treturn err\n}\n\nfunc (o *ops) RemovePV(pvName string) error {\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"pvremove\", pvName, \"-y\", \"-ff\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to remove PV %s, output %s, error %s\", pvName, output, err)\n\t}\n\treturn err\n}\n\nfunc (o *ops) Wipefs(device string) error {\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"wipefs\", \"-a\", device)\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to wipefs device %s, output %s, error %s\", device, output, err)\n\t}\n\treturn err\n}\n\nfunc (o *ops) GetMCSLogs() (string, error) {\n\n\tfiles, err := utils.FindFiles(\"/var/log/containers/\", utils.W_FILEONLY, \"*machine-config-server*.log\")\n\tif err != nil {\n\t\to.log.WithError(err).Errorf(\"Error occurred while trying to get list of files from %s\", \"/var/log/containers/\")\n\t\treturn \"\", err\n\t}\n\tif len(files) < 1 {\n\t\to.log.Warnf(\"MCS log file not found\")\n\t\treturn \"\", err\n\t}\n\t// There is theoretical option in case of static pod restart that there can be more than one file\n\t// we never saw it and it was decided not to handle it here\n\tlogs, err := ioutil.ReadFile(files[0])\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to read %s : %e\", files[0], err)\n\t\treturn \"\", err\n\t}\n\n\treturn string(logs), nil\n}\n\nfunc (o *ops) UploadInstallationLogs(isBootstrap bool) (string, error) {\n\tcommand := \"podman\"\n\targs := []string{\"run\", \"--rm\", \"--privileged\", \"--net=host\", \"--pid=host\", \"-v\", \"/run/systemd/journal/socket:/run/systemd/journal/socket\",\n\t\t\"-v\", \"/var/log:/var/log\", config.GlobalConfig.AgentImage, \"logs_sender\",\n\t\t\"-cluster-id\", config.GlobalConfig.ClusterID, \"-url\", config.GlobalConfig.URL,\n\t\t\"-host-id\", config.GlobalConfig.HostID,\n\t\t\"-pull-secret-token\", config.GlobalConfig.PullSecretToken,\n\t\tfmt.Sprintf(\"-insecure=%s\", strconv.FormatBool(config.GlobalConfig.SkipCertVerification)),\n\t\tfmt.Sprintf(\"-bootstrap=%s\", strconv.FormatBool(isBootstrap)),\n\t}\n\n\tif config.GlobalConfig.CACertPath != \"\" {\n\t\targs = append(args, fmt.Sprintf(\"-cacert=%s\", config.GlobalConfig.CACertPath))\n\t}\n\treturn o.ExecPrivilegeCommand(o.logWriter, command, args...)\n}\n\n// Sometimes we will need to reload container files from host\n// For example /etc/resolv.conf, it can't be changed with Z flag but is updated by bootkube.sh\n// and we need this update for dns resolve of kubeapi\nfunc (o *ops) ReloadHostFile(filepath string) error {\n\to.log.Infof(\"Reloading %s\", filepath)\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"cat\", filepath)\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to read %s on the host\", filepath)\n\t\treturn err\n\t}\n\tf, err := os.OpenFile(filepath, os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0644)\n\tdefer func() {\n\t\t_ = f.Close()\n\t}()\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to open local %s\", filepath)\n\t\treturn err\n\t}\n\t_, err = f.WriteString(output)\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to write host %s data to local\", filepath)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) CreateOpenshiftSshManifest(filePath, tmpl, sshPubKeyPath string) error {\n\to.log.Info(\"Create an openshift manifets for SSH public key\")\n\tsshPublicKey, err := o.ExecPrivilegeCommand(o.logWriter, \"cat\", sshPubKeyPath)\n\tif err != nil {\n\t\to.log.WithError(err).Errorf(\"Failed to read SSH pub key from %s\", sshPubKeyPath)\n\t\treturn err\n\t}\n\tf, err := os.Create(filePath)\n\tif err != nil {\n\t\to.log.WithError(err).Errorf(\"Failed to create %s\", filePath)\n\t\treturn err\n\t}\n\tdefer f.Close()\n\tt := template.Must(template.New(\"openshift SSH manifest\").Parse(tmpl))\n\tsshConfig := struct {\n\t\tSshPubKey string\n\t}{sshPublicKey}\n\tif err := t.Execute(f, sshConfig); err != nil {\n\t\to.log.WithError(err).Error(\"Failed to execute template\")\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) GetMustGatherLogs(workDir, kubeconfigPath string, images ...string) (string, error) {\n\t//invoke oc adm must-gather command in the working directory\n\tvar imageOption string = \"\"\n\tfor _, img := range images {\n\t\timageOption = imageOption + fmt.Sprintf(\" --image=%s\", img)\n\t}\n\n\tcommand := fmt.Sprintf(\"cd %s && oc --kubeconfig=%s adm must-gather%s\", workDir, kubeconfigPath, imageOption)\n\toutput, err := o.ExecCommand(o.logWriter, \"bash\", \"-c\", command)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\to.log.Info(output)\n\n\t//find the directory of logs which is the output of the command\n\t//this is a temp directory so we have to find it by its prefix\n\tfiles, err := utils.FindFiles(workDir, utils.W_DIRONLY, \"must-gather*\")\n\tif err != nil {\n\t\to.log.WithError(err).Errorf(\"Failed to read must-gather working dir %s\\n\", workDir)\n\t\treturn \"\", err\n\t}\n\n\tif len(files) == 0 {\n\t\tlerr := fmt.Errorf(\"Failed to find must-gather output\")\n\t\to.log.Errorf(lerr.Error())\n\t\treturn \"\", lerr\n\t}\n\tlogsDir := filepath.Base(files[0])\n\n\t//tar the log directory and return the path to the tarball\n\ttarName := \"must-gather.tar.gz\"\n\tcommand = fmt.Sprintf(\"cd %s && tar zcf %s %s\", workDir, tarName, logsDir)\n\t_, err = o.ExecCommand(o.logWriter, \"bash\", \"-c\", command)\n\tif err != nil {\n\t\to.log.WithError(err).Errorf(\"Failed to tar must-gather logs\\n\")\n\t\treturn \"\", err\n\t}\n\treturn path.Join(workDir, tarName), nil\n}\n\nfunc (o *ops) CreateRandomHostname(hostname string) error {\n\tcommand := fmt.Sprintf(\"echo %s > /etc/hostname\", hostname)\n\to.log.Infof(\"create random hostname with command %s\", command)\n\t_, err := o.ExecPrivilegeCommand(o.logWriter, \"bash\", \"-c\", command)\n\treturn err\n}\n\nfunc (o *ops) GetHostname() (string, error) {\n\treturn os.Hostname()\n}\n\nfunc (o *ops) CreateManifests(kubeconfig string, manifestFilePath string) error {\n\tcommand := fmt.Sprintf(\"oc --kubeconfig=%s apply -f %s\", kubeconfig, manifestFilePath)\n\toutput, err := o.ExecCommand(o.logWriter, \"bash\", \"-c\", command)\n\tif err != nil {\n\t\treturn err\n\t}\n\to.log.Infof(\"Applying custom manifest file %s succeed %s\", manifestFilePath, output)\n\n\treturn nil\n}\n"], "fixing_code": ["package assisted_installer_controller\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"math\"\n\t\"net\"\n\t\"os\"\n\t\"path\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\tmetal3v1alpha1 \"github.com/metal3-io/baremetal-operator/pkg/apis/metal3/v1alpha1\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/sirupsen/logrus\"\n\tcertificatesv1 \"k8s.io/api/certificates/v1\"\n\tv1 \"k8s.io/api/core/v1\"\n\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\n\t\"github.com/openshift/assisted-installer/src/common\"\n\t\"github.com/openshift/assisted-installer/src/inventory_client\"\n\t\"github.com/openshift/assisted-installer/src/k8s_client\"\n\t\"github.com/openshift/assisted-installer/src/ops\"\n\t\"github.com/openshift/assisted-installer/src/utils\"\n\t\"github.com/openshift/assisted-service/models\"\n\tmapiv1beta1 \"github.com/openshift/machine-api-operator/pkg/apis/machine/v1beta1\"\n)\n\nconst (\n\t// We retry 10 times in 30sec interval meaning that we tolerate the operator to be in failed\n\t// state for 5minutes.\n\tfailedOperatorRetry       = 10\n\tgeneralWaitTimeoutInt     = 30\n\tcontrollerLogsSecondsAgo  = 120 * 60\n\tconsoleOperatorName       = \"console\"\n\tingressConfigMapName      = \"default-ingress-cert\"\n\tingressConfigMapNamespace = \"openshift-config-managed\"\n\tdnsServiceName            = \"dns-default\"\n\tdnsServiceNamespace       = \"openshift-dns\"\n\tdnsOperatorNamespace      = \"openshift-dns-operator\"\n\tmaxDeletionAttempts       = 5\n\tmaxDNSServiceIPAttempts   = 45\n\tKeepWaiting               = false\n\tExitWaiting               = true\n\tcustomManifestsFile       = \"custom_manifests.yaml\"\n\tkubeconfigFileName        = \"kubeconfig-noingress\"\n)\n\nvar (\n\tretryPostManifestTimeout = 10 * time.Minute\n\tGeneralWaitInterval      = generalWaitTimeoutInt * time.Second\n\tGeneralProgressUpdateInt = 60 * time.Second\n\tLogsUploadPeriod         = 5 * time.Minute\n\tWaitTimeout              = 70 * time.Minute\n\tCompleteTimeout          = 30 * time.Minute\n\tDNSAddressRetryInterval  = 20 * time.Second\n\tDeletionRetryInterval    = 10 * time.Second\n\tLongWaitTimeout          = 10 * time.Hour\n\tCVOMaxTimeout            = 3 * time.Hour\n)\n\n// assisted installer controller is added to control installation process after  bootstrap pivot\n// assisted installer will deploy it on installation process\n// as a first step it will wait till nodes are added to cluster and update their status to Done\n\ntype ControllerConfig struct {\n\tClusterID             string `envconfig:\"CLUSTER_ID\" required:\"true\"`\n\tURL                   string `envconfig:\"INVENTORY_URL\" required:\"true\"`\n\tPullSecretToken       string `envconfig:\"PULL_SECRET_TOKEN\" required:\"true\" secret:\"true\"`\n\tSkipCertVerification  bool   `envconfig:\"SKIP_CERT_VERIFICATION\" required:\"false\" default:\"false\"`\n\tCACertPath            string `envconfig:\"CA_CERT_PATH\" required:\"false\" default:\"\"`\n\tNamespace             string `envconfig:\"NAMESPACE\" required:\"false\" default:\"assisted-installer\"`\n\tOpenshiftVersion      string `envconfig:\"OPENSHIFT_VERSION\" required:\"true\"`\n\tHighAvailabilityMode  string `envconfig:\"HIGH_AVAILABILITY_MODE\" required:\"false\" default:\"Full\"`\n\tWaitForClusterVersion bool   `envconfig:\"CHECK_CLUSTER_VERSION\" required:\"false\" default:\"false\"`\n\tMustGatherImage       string `envconfig:\"MUST_GATHER_IMAGE\" required:\"false\" default:\"\"`\n}\ntype Controller interface {\n\tWaitAndUpdateNodesStatus(status *ControllerStatus)\n}\n\ntype ControllerStatus struct {\n\terrCounter uint32\n\tcomponents map[string]bool\n\tlock       sync.Mutex\n}\n\ntype controller struct {\n\tControllerConfig\n\tStatus *ControllerStatus\n\tlog    *logrus.Logger\n\tops    ops.Ops\n\tic     inventory_client.InventoryClient\n\tkc     k8s_client.K8SClient\n}\n\nfunc NewController(log *logrus.Logger, cfg ControllerConfig, ops ops.Ops, ic inventory_client.InventoryClient, kc k8s_client.K8SClient) *controller {\n\treturn &controller{\n\t\tlog:              log,\n\t\tControllerConfig: cfg,\n\t\tops:              ops,\n\t\tic:               ic,\n\t\tkc:               kc,\n\t\tStatus:           NewControllerStatus(),\n\t}\n}\n\nfunc NewControllerStatus() *ControllerStatus {\n\treturn &ControllerStatus{\n\t\tcomponents: make(map[string]bool),\n\t}\n}\n\nfunc (status *ControllerStatus) Error() {\n\tatomic.AddUint32(&status.errCounter, 1)\n}\n\nfunc (status *ControllerStatus) HasError() bool {\n\treturn atomic.LoadUint32(&status.errCounter) > 0\n}\n\nfunc (status *ControllerStatus) OperatorError(component string) {\n\tstatus.lock.Lock()\n\tdefer status.lock.Unlock()\n\tstatus.components[component] = true\n}\n\nfunc (status *ControllerStatus) HasOperatorError() bool {\n\tstatus.lock.Lock()\n\tdefer status.lock.Unlock()\n\treturn len(status.components) > 0\n}\n\nfunc (status *ControllerStatus) GetOperatorsInError() []string {\n\tresult := make([]string, 0)\n\tstatus.lock.Lock()\n\tdefer status.lock.Unlock()\n\tfor op := range status.components {\n\t\tresult = append(result, op)\n\t}\n\treturn result\n}\n\nfunc logHostsStatus(log logrus.FieldLogger, hosts map[string]inventory_client.HostData) {\n\thostsStatus := make(map[string][]string)\n\tfor hostname, hostData := range hosts {\n\t\thostsStatus[hostname] = []string{\n\t\t\t*hostData.Host.Status,\n\t\t\tstring(hostData.Host.Progress.CurrentStage),\n\t\t\thostData.Host.Progress.ProgressInfo}\n\t}\n\tlog.Infof(\"Hosts status: %v\", hostsStatus)\n}\n\n// WaitAndUpdateNodesStatus waits till all nodes joins the cluster and become ready\n// it will update joined/done status\n// approve csr will run as routine and cancelled whenever all nodes are ready and joined\n// this will allow to run it and end only when it is needed\nfunc (c *controller) WaitAndUpdateNodesStatus(ctx context.Context, wg *sync.WaitGroup) {\n\tapproveCtx, approveCancel := context.WithCancel(ctx)\n\tdefer func() {\n\t\tapproveCancel()\n\t\tc.log.Infof(\"WaitAndUpdateNodesStatus finished\")\n\t\twg.Done()\n\t}()\n\t// starting approve csrs\n\tgo c.ApproveCsrs(approveCtx)\n\n\tc.log.Infof(\"Waiting till all nodes will join and update status to assisted installer\")\n\t_ = utils.WaitForPredicateWithContext(ctx, LongWaitTimeout, GeneralWaitInterval, c.waitAndUpdateNodesStatus)\n}\n\nfunc (c *controller) waitAndUpdateNodesStatus() bool {\n\tignoreStatuses := []string{models.HostStatusDisabled}\n\tvar hostsInError int\n\tctxReq := utils.GenerateRequestContext()\n\tlog := utils.RequestIDLogger(ctxReq, c.log)\n\n\tassistedNodesMap, err := c.ic.GetHosts(ctxReq, log, ignoreStatuses)\n\tif err != nil {\n\t\tlog.WithError(err).Error(\"Failed to get node map from the assisted service\")\n\t\treturn KeepWaiting\n\t}\n\n\tlogHostsStatus(log, assistedNodesMap)\n\n\thostsInProgressMap := common.GetHostsInStatus(assistedNodesMap, []string{models.HostStatusInstalled}, false)\n\terrNodesMap := common.GetHostsInStatus(hostsInProgressMap, []string{models.HostStatusError}, true)\n\thostsInError = len(errNodesMap)\n\n\t//if all hosts are in error, mark the failure and finish\n\tif hostsInError > 0 && hostsInError == len(hostsInProgressMap) {\n\t\tc.log.Infof(\"Done waiting for all the nodes. Nodes in error status: %d\\n\", hostsInError)\n\t\treturn ExitWaiting\n\t}\n\t//if all hosts are successfully installed, finish\n\tif len(hostsInProgressMap) == 0 {\n\t\tc.log.Infof(\"All nodes were successfully installed\")\n\t\treturn ExitWaiting\n\t}\n\t//otherwise, update the progress status and keep waiting\n\tlog.Infof(\"Checking if cluster nodes are ready. %d nodes remaining\", len(hostsInProgressMap))\n\tnodes, err := c.kc.ListNodes()\n\tif err != nil {\n\t\tlog.WithError(err).Error(\"Failed to get list of nodes from k8s client\")\n\t\treturn KeepWaiting\n\t}\n\tfor _, node := range nodes.Items {\n\t\thost, ok := hostsInProgressMap[strings.ToLower(node.Name)]\n\t\tif !ok {\n\t\t\tif _, ok := assistedNodesMap[strings.ToLower(node.Name)]; !ok {\n\t\t\t\tlog.Warnf(\"Node %s is not in inventory hosts\", strings.ToLower(node.Name))\n\t\t\t}\n\n\t\t\tcontinue\n\t\t}\n\t\tif common.IsK8sNodeIsReady(node) {\n\t\t\tlog.Infof(\"Found new ready node %s with inventory id %s, kubernetes id %s, updating its status to %s\",\n\t\t\t\tnode.Name, host.Host.ID.String(), node.Status.NodeInfo.SystemUUID, models.HostStageDone)\n\t\t\tif err := c.ic.UpdateHostInstallProgress(ctxReq, host.Host.ID.String(), models.HostStageDone, \"\"); err != nil {\n\t\t\t\tlog.WithError(err).Errorf(\"Failed to update node %s installation status\", node.Name)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t} else if host.Host.Progress.CurrentStage == models.HostStageConfiguring {\n\t\t\tlog.Infof(\"Found new joined node %s with inventory id %s, kubernetes id %s, updating its status to %s\",\n\t\t\t\tnode.Name, host.Host.ID.String(), node.Status.NodeInfo.SystemUUID, models.HostStageJoined)\n\t\t\tif err := c.ic.UpdateHostInstallProgress(ctxReq, host.Host.ID.String(), models.HostStageJoined, \"\"); err != nil {\n\t\t\t\tlog.WithError(err).Errorf(\"Failed to update node %s installation status\", node.Name)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t}\n\tc.updateConfiguringStatusIfNeeded(assistedNodesMap)\n\treturn KeepWaiting\n}\n\nfunc (c *controller) HackDNSAddressConflict(wg *sync.WaitGroup) {\n\n\tc.log.Infof(\"Making sure service %s can reserve the .10 address\", dnsServiceName)\n\n\tdefer func() {\n\t\tc.log.Infof(\"HackDNSAddressConflict finished\")\n\t\twg.Done()\n\t}()\n\tnetworks, err := c.kc.GetServiceNetworks()\n\tif err != nil || len(networks) == 0 {\n\t\tc.log.Errorf(\"Failed to get service networks: %s\", err)\n\t\treturn\n\t}\n\n\tip, _, _ := net.ParseCIDR(networks[0])\n\tip4 := ip.To4()\n\tif ip4 == nil {\n\t\tc.log.Infof(\"Service network is IPv6: %s, skipping the .10 address hack\", ip)\n\t\treturn\n\t}\n\tip4[3] = 10 // .10 is the conflicting address\n\n\tfor i := 0; i < maxDNSServiceIPAttempts; i++ {\n\t\tsvs, err := c.kc.ListServices(\"\")\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warnf(\"Failed to list running services, attempt %d/%d\", i+1, maxDNSServiceIPAttempts)\n\t\t\ttime.Sleep(DNSAddressRetryInterval)\n\t\t\tcontinue\n\t\t}\n\t\ts := c.findServiceByIP(ip4.String(), &svs.Items)\n\t\tif s == nil {\n\t\t\tc.log.Infof(\"No service found with IP %s, attempt %d/%d\", ip4, i+1, maxDNSServiceIPAttempts)\n\t\t\ttime.Sleep(DNSAddressRetryInterval)\n\t\t\tcontinue\n\t\t}\n\t\tif s.Name == dnsServiceName && s.Namespace == dnsServiceNamespace {\n\t\t\tc.log.Infof(\"Service %s has successfully taken IP %s\", dnsServiceName, ip4)\n\t\t\tbreak\n\t\t}\n\t\tc.log.Warnf(\"Deleting service %s in namespace %s whose IP %s conflicts with %s\", s.Name, s.Namespace, ip4, dnsServiceName)\n\t\tif err := c.killConflictingService(s); err != nil {\n\t\t\tc.log.WithError(err).Warnf(\"Failed to delete service %s in namespace %s\", s.Name, s.Namespace)\n\t\t\tcontinue\n\t\t}\n\t\tif err := c.deleteDNSOperatorPods(); err != nil {\n\t\t\tc.log.WithError(err).Warn(\"Failed to delete DNS operator pods\")\n\t\t}\n\t}\n}\n\nfunc (c *controller) findServiceByIP(ip string, services *[]v1.Service) *v1.Service {\n\tfor _, s := range *services {\n\t\tif s.Spec.ClusterIP == ip {\n\t\t\treturn &s\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (c *controller) killConflictingService(s *v1.Service) error {\n\treturn utils.Retry(maxDeletionAttempts, DeletionRetryInterval, c.log, func() error {\n\t\treturn c.kc.DeleteService(s.Name, s.Namespace)\n\t})\n}\n\nfunc (c *controller) deleteDNSOperatorPods() error {\n\treturn utils.Retry(maxDeletionAttempts, DeletionRetryInterval, c.log, func() error {\n\t\treturn c.kc.DeletePods(dnsOperatorNamespace)\n\t})\n}\n\nfunc (c *controller) getMCSLogs() (string, error) {\n\tlogs := \"\"\n\tnamespace := \"openshift-machine-config-operator\"\n\tpods, err := c.kc.GetPods(namespace, map[string]string{\"k8s-app\": \"machine-config-server\"}, \"\")\n\tif err != nil {\n\t\tc.log.WithError(err).Warnf(\"Failed to get mcs pods\")\n\t\treturn \"\", nil\n\t}\n\tfor _, pod := range pods {\n\t\tpodLogs, err := c.kc.GetPodLogs(namespace, pod.Name, generalWaitTimeoutInt*10)\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warnf(\"Failed to get logs of pod %s\", pod.Name)\n\t\t\treturn \"\", nil\n\t\t}\n\t\tlogs += podLogs\n\t}\n\treturn logs, nil\n}\n\nfunc (c *controller) updateConfiguringStatusIfNeeded(hosts map[string]inventory_client.HostData) {\n\tlogs, err := c.getMCSLogs()\n\tif err != nil {\n\t\treturn\n\t}\n\tcommon.SetConfiguringStatusForHosts(c.ic, hosts, logs, false, c.log)\n}\n\nfunc (c *controller) ApproveCsrs(ctx context.Context) {\n\tc.log.Infof(\"Start approving CSRs\")\n\tticker := time.NewTicker(GeneralWaitInterval)\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tc.log.Infof(\"Finish approving CSRs\")\n\t\t\treturn\n\t\tcase <-ticker.C:\n\t\t\tcsrs, err := c.kc.ListCsrs()\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tc.approveCsrs(csrs)\n\t\t}\n\t}\n}\n\nfunc (c controller) approveCsrs(csrs *certificatesv1.CertificateSigningRequestList) {\n\tfor i := range csrs.Items {\n\t\tcsr := csrs.Items[i]\n\t\tif !isCsrApproved(&csr) {\n\t\t\tc.log.Infof(\"Approving CSR %s\", csr.Name)\n\t\t\t// We can fail and it is ok, we will retry on the next time\n\t\t\t_ = c.kc.ApproveCsr(&csr)\n\t\t}\n\t}\n}\n\nfunc isCsrApproved(csr *certificatesv1.CertificateSigningRequest) bool {\n\tfor _, condition := range csr.Status.Conditions {\n\t\tif condition.Type == certificatesv1.CertificateApproved {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (c controller) PostInstallConfigs(ctx context.Context, wg *sync.WaitGroup) {\n\tdefer func() {\n\t\tc.log.Infof(\"Finished PostInstallConfigs\")\n\t\twg.Done()\n\t}()\n\terr := utils.WaitForPredicateWithContext(ctx, LongWaitTimeout, GeneralWaitInterval, func() bool {\n\t\tctxReq := utils.GenerateRequestContext()\n\t\tcluster, err := c.ic.GetCluster(ctx)\n\t\tif err != nil {\n\t\t\tutils.RequestIDLogger(ctxReq, c.log).WithError(err).Errorf(\"Failed to get cluster %s from assisted-service\", c.ClusterID)\n\t\t\treturn false\n\t\t}\n\t\treturn *cluster.Status == models.ClusterStatusFinalizing\n\t})\n\tif err != nil {\n\t\treturn\n\t}\n\n\terrMessage := \"\"\n\terr = c.postInstallConfigs(ctx)\n\t// context was cancelled, requires usage of WaitForPredicateWithContext\n\t// no reason to set error\n\tif ctx.Err() != nil {\n\t\treturn\n\t}\n\tif err != nil {\n\t\tc.log.Error(err)\n\t\terrMessage = err.Error()\n\t\tc.Status.Error()\n\t}\n\tsuccess := err == nil\n\tc.sendCompleteInstallation(ctx, success, errMessage)\n}\n\nfunc (c controller) postInstallConfigs(ctx context.Context) error {\n\tvar err error\n\n\tc.log.Infof(\"Waiting for cluster version operator: %t\", c.WaitForClusterVersion)\n\n\tif c.WaitForClusterVersion {\n\t\tif err = c.waitingForClusterVersion(ctx); err != nil {\n\t\t\treturn errors.Wrapf(err, \"Timeout while waiting for cluster version to be available\")\n\t\t}\n\t}\n\n\t// Unlabel run-level from assisted-installer namespace after the installation.\n\t// Keeping the `run-level` label represents a security risk as it overwrites the SecurityContext configurations\n\t// used for applications deployed in this namespace.\n\tdata := []byte(`{\"metadata\":{\"labels\":{\"$patch\": \"delete\", \"openshift.io/run-level\":\"0\"}}}`)\n\tc.log.Infof(\"Removing run-level label from %s namespace\", c.ControllerConfig.Namespace)\n\terr = c.kc.PatchNamespace(c.ControllerConfig.Namespace, data)\n\tif err != nil {\n\t\t// It is a conscious decision not to fail an installation if for any reason patching the namespace\n\t\t// in order to remove the `run-level` label has failed. This will be redesigned in the next release\n\t\t// so that the `run-level` label is not created in the first place.\n\t\tc.log.Warn(\"Failed to unlabel AI namespace after the installation.\")\n\t}\n\n\terr = utils.WaitForPredicateWithContext(ctx, WaitTimeout, GeneralWaitInterval, c.addRouterCAToClusterCA)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"Timeout while waiting router ca data\")\n\t}\n\n\tunpatch, err := utils.EtcdPatchRequired(c.ControllerConfig.OpenshiftVersion)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"Failed to patch etcd\")\n\t}\n\tif unpatch && c.HighAvailabilityMode != models.ClusterHighAvailabilityModeNone {\n\t\tif err = utils.WaitForPredicateWithContext(ctx, WaitTimeout, GeneralWaitInterval, c.unpatchEtcd); err != nil {\n\t\t\treturn errors.Wrapf(err, \"Timeout while trying to unpatch etcd\")\n\t\t}\n\t} else {\n\t\tc.log.Infof(\"Skipping etcd unpatch for cluster version %s\", c.ControllerConfig.OpenshiftVersion)\n\t}\n\n\tif err = utils.WaitForPredicateWithContext(ctx, WaitTimeout, GeneralWaitInterval, c.validateConsoleAvailability); err != nil {\n\t\treturn errors.Wrapf(err, \"Timeout while waiting for console to become available\")\n\t}\n\n\t// Apply post install manifests\n\terr = utils.WaitForPredicateWithContext(ctx, retryPostManifestTimeout, GeneralWaitInterval, c.applyPostInstallManifests)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"Failed to apply post manifests\")\n\t}\n\n\tif err != c.waitForOLMOperators(ctx) {\n\t\t// In case the timeout occur, we have to update the pending OLM operators to failed state,\n\t\t// so the assisted-service can update the cluster state to completed.\n\t\tif err = c.updatePendingOLMOperators(); err != nil {\n\t\t\treturn errors.Errorf(\"Timeout while waiting for some of the operators and not able to update its state\")\n\t\t}\n\t\treturn errors.Wrapf(err, \"Timeout while waiting for OLM operators be installed\")\n\t}\n\n\treturn nil\n}\n\nfunc (c controller) applyPostInstallManifests() bool {\n\tctx := utils.GenerateRequestContext()\n\ttempDir, err := ioutil.TempDir(\"\", \"controller-custom-manifests-\")\n\tif err != nil {\n\t\tc.log.WithError(err).Error(\"Failed to create temporary directory to create custom manifests.\")\n\t\treturn false\n\t}\n\tc.log.Infof(\"Created temporary directory %s to store custom manifest content.\", tempDir)\n\tdefer os.RemoveAll(tempDir)\n\n\tcustomManifestPath := path.Join(tempDir, customManifestsFile)\n\tif err = c.ic.DownloadFile(ctx, customManifestsFile, customManifestPath); err != nil {\n\t\treturn false\n\t}\n\n\tkubeconfigName, err := c.downloadKubeconfigNoingress(ctx, tempDir)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\terr = c.ops.CreateManifests(kubeconfigName, customManifestPath)\n\tif err != nil {\n\t\tc.log.WithError(err).Error(\"Failed to apply manifest file.\")\n\t\treturn false\n\t}\n\n\treturn true\n}\n\nfunc (c controller) UpdateBMHs(ctx context.Context, wg *sync.WaitGroup) {\n\tdefer func() {\n\t\tc.log.Infof(\"Finished UpdateBMHs\")\n\t\twg.Done()\n\t}()\n\t_ = utils.WaitForPredicateWithContext(ctx, time.Duration(1<<63-1), GeneralWaitInterval, func() bool {\n\t\tbmhs, err := c.kc.ListBMHs()\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Errorf(\"Failed to list BMH hosts\")\n\t\t\treturn false\n\t\t}\n\n\t\tc.log.Infof(\"Number of BMHs is %d\", len(bmhs.Items))\n\n\t\tmachines, err := c.unallocatedMachines(bmhs)\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Errorf(\"Failed to find unallocated machines\")\n\t\t\treturn false\n\t\t}\n\n\t\tc.log.Infof(\"Number of unallocated Machines is %d\", len(machines.Items))\n\n\t\tallUpdated := c.updateBMHs(&bmhs, machines)\n\t\tif allUpdated {\n\t\t\tc.log.Infof(\"Updated all the BMH CRs, finished successfully\")\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t})\n}\n\nfunc (c controller) unallocatedMachines(bmhList metal3v1alpha1.BareMetalHostList) (*mapiv1beta1.MachineList, error) {\n\tmachineList, err := c.kc.ListMachines()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tunallocatedList := &mapiv1beta1.MachineList{Items: machineList.Items[:0]}\n\n\tfor _, machine := range machineList.Items {\n\t\trole, ok := machine.Labels[\"machine.openshift.io/cluster-api-machine-role\"]\n\t\tif ok && role == \"worker\" {\n\t\t\tc.log.Infof(\"Found worker machine %s\", machine.Name)\n\t\t}\n\t\tunallocated := ok && role == \"worker\"\n\t\tfor _, bmh := range bmhList.Items {\n\t\t\tif bmh.Spec.ConsumerRef != nil && bmh.Spec.ConsumerRef.Name == machine.Name {\n\t\t\t\tunallocated = false\n\t\t\t}\n\t\t}\n\t\tif unallocated {\n\t\t\tunallocatedList.Items = append(unallocatedList.Items, machine)\n\t\t}\n\t}\n\treturn unallocatedList, nil\n}\n\nfunc (c controller) copyBMHAnnotationsToStatus(bmh *metal3v1alpha1.BareMetalHost) (bool, error) {\n\tannotations := bmh.GetAnnotations()\n\tcontent := []byte(annotations[metal3v1alpha1.StatusAnnotation])\n\n\tif annotations[metal3v1alpha1.StatusAnnotation] == \"\" {\n\t\tc.log.Infof(\"Skipping setting status of BMH host %s, status annotation not present\", bmh.Name)\n\t\treturn false, nil\n\t}\n\tobjStatus, err := c.unmarshalStatusAnnotation(content)\n\tif err != nil {\n\t\tc.log.WithError(err).Errorf(\"Failed to unmarshal status annotation of %s\", bmh.Name)\n\t\treturn false, err\n\t}\n\tbmh.Status = *objStatus\n\tif bmh.Status.LastUpdated.IsZero() {\n\t\t// Ensure the LastUpdated timestamp in set to avoid\n\t\t// infinite loops if the annotation only contained\n\t\t// part of the status information.\n\t\tt := metav1.Now()\n\t\tbmh.Status.LastUpdated = &t\n\t}\n\terr = c.kc.UpdateBMHStatus(bmh)\n\tif err != nil {\n\t\tc.log.WithError(err).Errorf(\"Failed to update status of BMH %s\", bmh.Name)\n\t\treturn false, err\n\t}\n\treturn true, nil\n}\n\nfunc (c controller) unmarshalStatusAnnotation(content []byte) (*metal3v1alpha1.BareMetalHostStatus, error) {\n\tbmhStatus := &metal3v1alpha1.BareMetalHostStatus{}\n\terr := json.Unmarshal(content, bmhStatus)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn bmhStatus, nil\n}\n\n// updateBMHWithProvisioning() If we are in None or Unmanaged state:\n// - set ExternallyProvisioned\n// - Removing pausedAnnotation from BMH master hosts\n// - set the consumer ref\nfunc (c controller) updateBMHWithProvisioning(bmh *metal3v1alpha1.BareMetalHost, machineList *mapiv1beta1.MachineList) error {\n\tif bmh.Status.Provisioning.State != metal3v1alpha1.StateNone && bmh.Status.Provisioning.State != metal3v1alpha1.StateUnmanaged {\n\t\tc.log.Infof(\"bmh %s Provisioning.State=%s - ignoring\", bmh.Name, bmh.Status.Provisioning.State)\n\t\treturn nil\n\t}\n\tvar err error\n\tneedsUpdate := !bmh.Spec.ExternallyProvisioned\n\tbmh.Spec.ExternallyProvisioned = true\n\t// when baremetal operator is enabled, we need to remove the pausedAnnotation\n\t// to indicated that the statusAnnotation is available. This is only on\n\t// the master nodes.\n\tannotations := bmh.GetAnnotations()\n\tif _, ok := annotations[metal3v1alpha1.PausedAnnotation]; ok {\n\t\tc.log.Infof(\"Removing pausedAnnotation from BMH host %s\", bmh.Name)\n\t\tdelete(annotations, metal3v1alpha1.PausedAnnotation)\n\t\tneedsUpdate = true\n\t}\n\tif bmh.Spec.ConsumerRef == nil {\n\t\terr = c.updateConsumerRef(bmh, machineList)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tneedsUpdate = true\n\t}\n\tif needsUpdate {\n\t\tc.log.Infof(\"Updating bmh %s\", bmh.Name)\n\t\terr = c.kc.UpdateBMH(bmh)\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"Failed to update BMH %s\", bmh.Name)\n\t\t}\n\t}\n\treturn nil\n}\n\n// updateBMHWithNOProvisioning()\n// - move the BMH status annotation to the Status sub resource\n// - set the consumer ref\nfunc (c controller) updateBMHWithNOProvisioning(bmh *metal3v1alpha1.BareMetalHost, machineList *mapiv1beta1.MachineList) error {\n\tstatusUpdated, err := c.copyBMHAnnotationsToStatus(bmh)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"Failed to copy BMH Annotations to Status %s\", bmh.Name)\n\t}\n\tif statusUpdated {\n\t\t// refresh the BMH after the StatusUpdate to get the new generation\n\t\tbmh, err = c.kc.GetBMH(bmh.Name)\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"Failed to refresh the BMH %s\", bmh.Name)\n\t\t}\n\t}\n\tneedsUpdate := false\n\tannotations := bmh.GetAnnotations()\n\tif _, ok := annotations[metal3v1alpha1.StatusAnnotation]; ok {\n\t\tdelete(annotations, metal3v1alpha1.StatusAnnotation)\n\t\tneedsUpdate = true\n\t}\n\n\tif bmh.Spec.ConsumerRef == nil {\n\t\terr = c.updateConsumerRef(bmh, machineList)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tneedsUpdate = true\n\t}\n\tif needsUpdate {\n\t\tc.log.Infof(\"Updating bmh %s\", bmh.Name)\n\t\terr = c.kc.UpdateBMH(bmh)\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"Failed to update BMH %s\", bmh.Name)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (c controller) updateConsumerRef(bmh *metal3v1alpha1.BareMetalHost, machineList *mapiv1beta1.MachineList) error {\n\t//\tupdate consumer ref for workers only in case machineset controller has already\n\t//\tcreated an unassigned Machine (base on machineset replica count)\n\tif len(machineList.Items) == 0 {\n\t\treturn fmt.Errorf(\"no available machine for bmh %s, need to wait for machineset controller to create one\", bmh.Name)\n\t}\n\tc.log.Infof(\"Updating consumer ref for bmh %s\", bmh.Name)\n\tmachine := &machineList.Items[0]\n\tmachineList.Items = machineList.Items[1:]\n\tbmh.Spec.ConsumerRef = &v1.ObjectReference{\n\t\tAPIVersion: machine.APIVersion,\n\t\tKind:       machine.Kind,\n\t\tNamespace:  machine.Namespace,\n\t\tName:       machine.Name,\n\t}\n\treturn nil\n}\n\nfunc (c controller) updateBMHs(bmhList *metal3v1alpha1.BareMetalHostList, machineList *mapiv1beta1.MachineList) bool {\n\tprovisioningExists, err := c.kc.IsMetalProvisioningExists()\n\tif err != nil {\n\t\tc.log.WithError(err).Errorf(\"Failed get IsMetalProvisioningExists\")\n\t\treturn false\n\t}\n\n\tallUpdated := true\n\tfor i := range bmhList.Items {\n\t\tbmh := bmhList.Items[i]\n\t\tc.log.Infof(\"Checking bmh %s\", bmh.Name)\n\n\t\tif provisioningExists {\n\t\t\terr = c.updateBMHWithProvisioning(&bmh, machineList)\n\t\t} else {\n\t\t\terr = c.updateBMHWithNOProvisioning(&bmh, machineList)\n\t\t}\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Errorf(\"Failed to update BMH %s\", bmh.Name)\n\t\t\tallUpdated = false\n\t\t\tcontinue\n\t\t}\n\t}\n\treturn allUpdated\n}\n\nfunc (c controller) unpatchEtcd() bool {\n\tc.log.Infof(\"Unpatching etcd\")\n\tif err := c.kc.UnPatchEtcd(); err != nil {\n\t\tc.log.Error(err)\n\t\treturn false\n\t}\n\treturn true\n}\n\n// AddRouterCAToClusterCA adds router CA to cluster CA in kubeconfig\nfunc (c controller) addRouterCAToClusterCA() bool {\n\tctx := utils.GenerateRequestContext()\n\tlog := utils.RequestIDLogger(ctx, c.log)\n\tlog.Infof(\"Start adding ingress ca to cluster\")\n\tcaConfigMap, err := c.kc.GetConfigMap(ingressConfigMapNamespace, ingressConfigMapName)\n\n\tif err != nil {\n\t\tlog.WithError(err).Errorf(\"fetching %s configmap from %s namespace\", ingressConfigMapName, ingressConfigMapNamespace)\n\t\treturn false\n\t}\n\tlog.Infof(\"Sending ingress certificate to inventory service. Certificate data %s\", caConfigMap.Data[\"ca-bundle.crt\"])\n\terr = c.ic.UploadIngressCa(ctx, caConfigMap.Data[\"ca-bundle.crt\"], c.ClusterID)\n\tif err != nil {\n\t\tlog.WithError(err).Errorf(\"Failed to upload ingress ca to assisted-service\")\n\t\treturn false\n\t}\n\tlog.Infof(\"Ingress ca successfully sent to inventory\")\n\treturn true\n\n}\n\nfunc (c controller) getMaximumOLMTimeout(operators []*models.MonitoredOperator) time.Duration {\n\ttimeout := WaitTimeout.Seconds()\n\tfor _, operator := range operators {\n\t\ttimeout = math.Max(float64(operator.TimeoutSeconds), timeout)\n\t}\n\n\treturn time.Duration(timeout * float64(time.Second))\n}\n\nfunc (c controller) getProgressingOLMOperators() ([]*models.MonitoredOperator, error) {\n\tret := make([]*models.MonitoredOperator, 0)\n\toperators, err := c.ic.GetClusterMonitoredOLMOperators(context.TODO(), c.ClusterID)\n\tif err != nil {\n\t\tc.log.WithError(err).Warningf(\"Failed to connect to assisted service\")\n\t\treturn ret, err\n\t}\n\tfor index := range operators {\n\t\tif operators[index].Status != models.OperatorStatusAvailable && operators[index].Status != models.OperatorStatusFailed {\n\t\t\tret = append(ret, &operators[index])\n\t\t}\n\t}\n\treturn ret, nil\n}\n\nfunc (c controller) updatePendingOLMOperators() error {\n\tc.log.Infof(\"Updating pending OLM operators\")\n\tctx := utils.GenerateRequestContext()\n\toperators, err := c.getProgressingOLMOperators()\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor _, operator := range operators {\n\t\tc.Status.OperatorError(operator.Name)\n\t\terr := c.ic.UpdateClusterOperator(ctx, c.ClusterID, operator.Name, models.OperatorStatusFailed, \"Waiting for operator timed out\")\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warnf(\"Failed to update olm %s status\", operator.Name)\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// waitForOLMOperators wait until all OLM monitored operators are available or failed.\nfunc (c controller) waitForOLMOperators(ctx context.Context) error {\n\toperators, err := c.getProgressingOLMOperators()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(operators) == 0 {\n\t\treturn nil\n\t}\n\n\thandlers := make(map[string]*ClusterServiceVersionHandler)\n\n\tfor index := range operators {\n\t\thandlers[operators[index].Name] = NewClusterServiceVersionHandler(c.kc, operators[index], c.Status)\n\t}\n\n\tareOLMOperatorsAvailable := func() bool {\n\t\tif len(handlers) == 0 {\n\t\t\treturn true\n\t\t}\n\n\t\tfor index := range handlers {\n\t\t\tif c.isOperatorAvailable(handlers[index]) {\n\t\t\t\tdelete(handlers, index)\n\t\t\t}\n\t\t}\n\t\treturn false\n\t}\n\n\twaitTimeout := c.getMaximumOLMTimeout(operators)\n\tc.log.Infof(\"Waiting for OLM operators for %v\", waitTimeout)\n\treturn utils.WaitForPredicateWithContext(ctx, waitTimeout, GeneralWaitInterval, areOLMOperatorsAvailable)\n}\n\n// validateConsoleAvailability checks if the console operator is available\nfunc (c controller) validateConsoleAvailability() bool {\n\treturn c.isOperatorAvailable(NewClusterOperatorHandler(c.kc, consoleOperatorName))\n}\n\n// waitingForClusterVersion checks the Cluster Version Operator availability in the\n// new OCP cluster. A success would be announced only when the service acknowledges\n// the CVO availability, in order to avoid unsycned scenarios.\n// In case cvo changes it message we will update timer but we want to have maximum timeout\n// for this context with timeout is used\nfunc (c controller) waitingForClusterVersion(ctx context.Context) error {\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, CVOMaxTimeout)\n\tdefer cancel()\n\tisClusterVersionAvailable := func(timer *time.Timer) bool {\n\t\treturn c.isOperatorAvailable(NewClusterVersionHandler(c.kc, timer))\n\t}\n\treturn utils.WaitForPredicateWithTimer(ctxWithTimeout, WaitTimeout, GeneralProgressUpdateInt, isClusterVersionAvailable)\n}\n\nfunc (c controller) sendCompleteInstallation(ctx context.Context, isSuccess bool, errorInfo string) {\n\tc.log.Infof(\"Start complete installation step, with params success: %t, error info: %s\", isSuccess, errorInfo)\n\t_ = utils.WaitForPredicateWithContext(ctx, CompleteTimeout, GeneralProgressUpdateInt, func() bool {\n\t\tctxReq := utils.GenerateRequestContext()\n\t\tif err := c.ic.CompleteInstallation(ctxReq, c.ClusterID, isSuccess, errorInfo); err != nil {\n\t\t\tutils.RequestIDLogger(ctxReq, c.log).Error(err)\n\t\t\treturn false\n\t\t}\n\t\treturn true\n\t})\n\tc.log.Infof(\"Done complete installation step\")\n}\n\n// logClusterOperatorsStatus logging cluster operators status\nfunc (c controller) logClusterOperatorsStatus() {\n\toperators, err := c.kc.ListClusterOperators()\n\tif err != nil {\n\t\tc.log.WithError(err).Warning(\"Failed to list cluster operators\")\n\t\treturn\n\t}\n\n\tfor _, operator := range operators.Items {\n\t\tc.log.Infof(\"Operator %s, statuses: %v\", operator.Name, operator.Status.Conditions)\n\t}\n}\n\n/**\n * This function upload the following logs at once to the service at the end of the installation process\n * It takes a lenient approach so if some logs are not available it ignores them and moves on\n * currently the bundled logs are:\n * - controller logs\n * - oc must-gather logs\n **/\nfunc (c controller) uploadSummaryLogs(podName string, namespace string, sinceSeconds int64) error {\n\tvar tarentries = make([]utils.TarEntry, 0)\n\tvar ok bool = true\n\tctx := utils.GenerateRequestContext()\n\n\tc.logClusterOperatorsStatus()\n\tif c.Status.HasError() || c.Status.HasOperatorError() {\n\t\tc.log.Infof(\"Uploading oc must-gather logs\")\n\t\timages := c.parseMustGatherImages()\n\t\tif tarfile, err := c.collectMustGatherLogs(ctx, images...); err == nil {\n\t\t\tif entry, tarerr := utils.NewTarEntryFromFile(tarfile); tarerr == nil {\n\t\t\t\ttarentries = append(tarentries, *entry)\n\t\t\t}\n\t\t} else {\n\t\t\tok = false\n\t\t}\n\t}\n\n\tc.log.Infof(\"Uploading logs for %s in %s\", podName, namespace)\n\tif podLogs, err := c.kc.GetPodLogsAsBuffer(namespace, podName, sinceSeconds); err == nil {\n\t\ttarentries = append(tarentries,\n\t\t\t*utils.NewTarEntry(podLogs, nil, int64(podLogs.Len()), fmt.Sprintf(\"%s.logs\", podName)))\n\t} else {\n\t\tok = false\n\t}\n\n\tif len(tarentries) == 0 {\n\t\treturn errors.New(\"No logs are available for sending summary logs\")\n\t}\n\n\t//write the combined input of the summary sources into a pipe and offload it\n\t//to the UploadLogs request to the assisted-service\n\tpr, pw := io.Pipe()\n\tdefer pr.Close()\n\n\tgo func() {\n\t\tdefer pw.Close()\n\t\terr := utils.WriteToTarGz(pw, tarentries)\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warnf(\"Failed to create tar.gz body of the log uplaod request\")\n\t\t}\n\t}()\n\t// if error will occur in goroutine above, the writer will be closed\n\t// and as a result upload will fail\n\terr := c.ic.UploadLogs(ctx, c.ClusterID, models.LogsTypeController, pr)\n\tif err != nil {\n\t\tutils.RequestIDLogger(ctx, c.log).WithError(err).Error(\"Failed to upload logs\")\n\t\treturn err\n\t}\n\n\tif !ok {\n\t\tmsg := \"Some Logs were not collected in summary\"\n\t\tc.log.Errorf(msg)\n\t\treturn errors.New(msg)\n\t}\n\n\treturn nil\n}\n\nfunc (c controller) parseMustGatherImages() []string {\n\timages := make([]string, 0)\n\tif c.MustGatherImage == \"\" {\n\t\tc.log.Infof(\"collecting must-gather logs into using image from release\")\n\t\treturn images\n\t}\n\n\tc.log.Infof(\"collecting must-gather logs using this image configuration %s\", c.MustGatherImage)\n\tvar imageMap map[string]string\n\terr := json.Unmarshal([]byte(c.MustGatherImage), &imageMap)\n\tif err != nil {\n\t\t//MustGatherImage is not a JSON. Pass it as is\n\t\timages = append(images, c.MustGatherImage)\n\t\treturn images\n\t}\n\n\t//Use the parsed MustGatherImage to find the images needed for collecting\n\t//the information\n\tif c.Status.HasError() {\n\t\t//general error - collect all data from the cluster using the standard image\n\t\timages = append(images, imageMap[\"ocp\"])\n\t}\n\n\tfor _, op := range c.Status.GetOperatorsInError() {\n\t\tif imageMap[op] != \"\" {\n\t\t\t//per failed operator - add feature image for collecting more\n\t\t\t//information about failed olm operators\n\t\t\timages = append(images, imageMap[op])\n\t\t}\n\t}\n\tc.log.Infof(\"collecting must-gather logs with images: %v\", images)\n\treturn images\n}\n\nfunc (c controller) downloadKubeconfigNoingress(ctx context.Context, dir string) (string, error) {\n\t// Download kubeconfig file\n\tkubeconfigPath := path.Join(dir, kubeconfigFileName)\n\terr := c.ic.DownloadFile(ctx, kubeconfigFileName, kubeconfigPath)\n\tif err != nil {\n\t\tc.log.Errorf(\"Failed to download noingress kubeconfig %v\\n\", err)\n\t\treturn \"\", err\n\t}\n\tc.log.Infof(\"Downloaded %s to %s.\", kubeconfigFileName, kubeconfigPath)\n\n\treturn kubeconfigPath, nil\n}\n\nfunc (c controller) collectMustGatherLogs(ctx context.Context, images ...string) (string, error) {\n\ttempDir, ferr := ioutil.TempDir(\"\", \"controller-must-gather-logs-\")\n\tif ferr != nil {\n\t\tc.log.Errorf(\"Failed to create temp directory for must-gather-logs %v\\n\", ferr)\n\t\treturn \"\", ferr\n\t}\n\n\tkubeconfigPath, err := c.downloadKubeconfigNoingress(ctx, tempDir)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\t//collect must gather logs\n\tlogtar, err := c.ops.GetMustGatherLogs(tempDir, kubeconfigPath, images...)\n\tif err != nil {\n\t\tc.log.Errorf(\"Failed to collect must-gather logs %v\\n\", err)\n\t\treturn \"\", err\n\t}\n\n\treturn logtar, nil\n}\n\n// Uploading logs every 5 minutes\n// We will take logs of assisted controller and upload them to assisted-service\n// by creating tar gz of them.\nfunc (c *controller) UploadLogs(ctx context.Context, wg *sync.WaitGroup) {\n\tpodName := \"\"\n\tticker := time.NewTicker(LogsUploadPeriod)\n\tprogressCtx := utils.GenerateRequestContext()\n\n\tdefer func() {\n\t\tc.log.Infof(\"Finished UploadLogs\")\n\t\twg.Done()\n\t}()\n\tc.log.Infof(\"Start sending logs\")\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif podName != \"\" {\n\t\t\t\tc.log.Infof(\"Upload final controller and cluster logs before exit\")\n\t\t\t\tc.ic.ClusterLogProgressReport(progressCtx, c.ClusterID, models.LogsStateRequested)\n\t\t\t\t_ = utils.WaitForPredicate(WaitTimeout, LogsUploadPeriod, func() bool {\n\t\t\t\t\terr := c.uploadSummaryLogs(podName, c.Namespace, controllerLogsSecondsAgo)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tc.log.Infof(\"retry uploading logs in 5 minutes...\")\n\t\t\t\t\t}\n\t\t\t\t\treturn err == nil\n\t\t\t\t})\n\t\t\t}\n\t\t\tc.ic.ClusterLogProgressReport(progressCtx, c.ClusterID, models.LogsStateCompleted)\n\t\t\treturn\n\t\tcase <-ticker.C:\n\t\t\tif podName == \"\" {\n\t\t\t\tpods, err := c.kc.GetPods(c.Namespace, map[string]string{\"job-name\": \"assisted-installer-controller\"},\n\t\t\t\t\tfmt.Sprintf(\"status.phase=%s\", v1.PodRunning))\n\t\t\t\tif err != nil {\n\t\t\t\t\tc.log.WithError(err).Warnf(\"Failed to get controller pod name\")\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif len(pods) < 1 {\n\t\t\t\t\tc.log.Infof(\"Didn't find myself, something strange had happened\")\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tpodName = pods[0].Name\n\t\t\t}\n\n\t\t\t//on normal flow, keep updating the controller log output every 5 minutes\n\t\t\tc.log.Infof(\"Start uploading controller logs (intermediate snapshot)\")\n\t\t\terr := common.UploadPodLogs(c.kc, c.ic, c.ClusterID, podName, c.Namespace, controllerLogsSecondsAgo, c.log)\n\t\t\tif err != nil {\n\t\t\t\tc.log.WithError(err).Warnf(\"Failed to upload controller logs\")\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (c controller) SetReadyState() {\n\tc.log.Infof(\"Start waiting to be ready\")\n\t_ = utils.WaitForPredicate(WaitTimeout, 1*time.Second, func() bool {\n\t\t_, err := c.ic.GetCluster(context.TODO())\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warningf(\"Failed to connect to assisted service\")\n\t\t\treturn false\n\t\t}\n\t\tc.log.Infof(\"assisted-service is available\")\n\n\t\t_, err = c.kc.ListNodes()\n\t\tif err != nil {\n\t\t\tc.log.WithError(err).Warningf(\"Failed to connect to ocp cluster\")\n\t\t\treturn false\n\t\t}\n\t\tc.log.Infof(\"kube-apiserver is available\")\n\n\t\tc.log.Infof(\"Sending ready event\")\n\t\tif _, err := c.kc.CreateEvent(c.Namespace, common.AssistedControllerIsReadyEvent,\n\t\t\t\"Assisted controller managed to connect to assisted service and kube-apiserver and is ready to start\",\n\t\t\tcommon.AssistedControllerPrefix); err != nil && !apierrors.IsAlreadyExists(err) {\n\t\t\tc.log.WithError(err).Errorf(\"Failed to spawn event\")\n\t\t\treturn false\n\t\t}\n\n\t\treturn true\n\t})\n}\n", "package ops\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"strconv\"\n\t\"text/template\"\n\n\t\"io/ioutil\"\n\t\"os/exec\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"syscall\"\n\n\t\"github.com/pkg/errors\"\n\t\"github.com/sirupsen/logrus\"\n\n\t\"github.com/openshift/assisted-installer/src/config\"\n\t\"github.com/openshift/assisted-installer/src/inventory_client\"\n\t\"github.com/openshift/assisted-installer/src/utils\"\n)\n\n//go:generate mockgen -source=ops.go -package=ops -destination=mock_ops.go\ntype Ops interface {\n\tExecPrivilegeCommand(liveLogger io.Writer, command string, args ...string) (string, error)\n\tExecCommand(liveLogger io.Writer, command string, args ...string) (string, error)\n\tMkdir(dirName string) error\n\tWriteImageToDisk(ignitionPath string, device string, progressReporter inventory_client.InventoryClient, extra []string) error\n\tReboot() error\n\tSetBootOrder(device string) error\n\tExtractFromIgnition(ignitionPath string, fileToExtract string) error\n\tSystemctlAction(action string, args ...string) error\n\tPrepareController() error\n\tGetVGByPV(pvName string) (string, error)\n\tRemoveVG(vgName string) error\n\tRemoveLV(lvName, vgName string) error\n\tRemovePV(pvName string) error\n\tWipefs(device string) error\n\tGetMCSLogs() (string, error)\n\tUploadInstallationLogs(isBootstrap bool) (string, error)\n\tReloadHostFile(filepath string) error\n\tCreateOpenshiftSshManifest(filePath, template, sshPubKeyPath string) error\n\tGetMustGatherLogs(workDir, kubeconfigPath string, images ...string) (string, error)\n\tCreateRandomHostname(hostname string) error\n\tGetHostname() (string, error)\n\tEvaluateDiskSymlink(string) string\n\tCreateManifests(string, string) error\n}\n\nconst (\n\tcontrollerDeployFolder         = \"/assisted-installer-controller/deploy\"\n\tmanifestsFolder                = \"/opt/openshift/manifests\"\n\trenderedControllerCm           = \"assisted-installer-controller-cm.yaml\"\n\tcontrollerDeployCmTemplate     = \"assisted-installer-controller-cm.yaml.template\"\n\trenderedControllerPod          = \"assisted-installer-controller-pod.yaml\"\n\tcontrollerDeployPodTemplate    = \"assisted-installer-controller-pod.yaml.template\"\n\trenderedControllerSecret       = \"assisted-installer-controller-secret.yaml\"\n\tcontrollerDeploySecretTemplate = \"assisted-installer-controller-secret.yaml.template\"\n)\n\ntype ops struct {\n\tlog       *logrus.Logger\n\tlogWriter *utils.LogWriter\n\tcmdEnv    []string\n}\n\n// NewOps return a new ops interface\nfunc NewOps(logger *logrus.Logger, proxySet bool) Ops {\n\tcmdEnv := os.Environ()\n\tif proxySet && (config.GlobalConfig.HTTPProxy != \"\" || config.GlobalConfig.HTTPSProxy != \"\") {\n\t\tif config.GlobalConfig.HTTPProxy != \"\" {\n\t\t\tcmdEnv = append(cmdEnv, fmt.Sprintf(\"HTTP_PROXY=%s\", config.GlobalConfig.HTTPProxy))\n\t\t}\n\t\tif config.GlobalConfig.HTTPSProxy != \"\" {\n\t\t\tcmdEnv = append(cmdEnv, fmt.Sprintf(\"HTTPS_PROXY=%s\", config.GlobalConfig.HTTPSProxy))\n\t\t}\n\t\tif config.GlobalConfig.NoProxy != \"\" {\n\t\t\tcmdEnv = append(cmdEnv, fmt.Sprintf(\"NO_PROXY=%s\", config.GlobalConfig.NoProxy))\n\t\t}\n\t}\n\treturn &ops{logger, utils.NewLogWriter(logger), cmdEnv}\n}\n\n// ExecPrivilegeCommand execute a command in the host environment via nsenter\nfunc (o *ops) ExecPrivilegeCommand(liveLogger io.Writer, command string, args ...string) (string, error) {\n\tcommandBase := \"nsenter\"\n\targuments := []string{\"-t\", \"1\", \"-m\", \"-i\", \"--\", command}\n\targuments = append(arguments, args...)\n\treturn o.ExecCommand(liveLogger, commandBase, arguments...)\n}\n\ntype ExecCommandError struct {\n\tCommand    string\n\tArgs       []string\n\tEnv        []string\n\tExitErr    error\n\tOutput     string\n\tWaitStatus int\n}\n\nfunc (e *ExecCommandError) Error() string {\n\tlastOutput := e.Output\n\tif len(e.Output) > 200 {\n\t\tlastOutput = \"... \" + e.Output[len(e.Output)-200:]\n\t}\n\n\treturn fmt.Sprintf(\"failed executing %s %v, Error %s, LastOutput \\\"%s\\\"\", e.Command, e.Args, e.ExitErr, lastOutput)\n}\n\nfunc (e *ExecCommandError) DetailedError() string {\n\treturn fmt.Sprintf(\"failed executing %s %v, env vars %v, error %s, waitStatus %d, Output \\\"%s\\\"\", e.Command, e.Args, e.Env, e.ExitErr, e.WaitStatus, e.Output)\n}\n\n// ExecCommand executes command.\nfunc (o *ops) ExecCommand(liveLogger io.Writer, command string, args ...string) (string, error) {\n\n\tvar stdoutBuf bytes.Buffer\n\tcmd := exec.Command(command, args...)\n\tif liveLogger != nil {\n\t\tcmd.Stdout = io.MultiWriter(liveLogger, &stdoutBuf)\n\t\tcmd.Stderr = io.MultiWriter(liveLogger, &stdoutBuf)\n\t} else {\n\t\tcmd.Stdout = &stdoutBuf\n\t\tcmd.Stderr = &stdoutBuf\n\t}\n\tcmd.Env = o.cmdEnv\n\terr := cmd.Run()\n\toutput := strings.TrimSpace(stdoutBuf.String())\n\tif err != nil {\n\n\t\t// Get all lines from Error message\n\t\terrorIndex := strings.Index(output, \"Error\")\n\t\t// if Error not found return all output\n\t\tif errorIndex > -1 {\n\t\t\toutput = output[errorIndex:]\n\t\t}\n\n\t\texecErr := &ExecCommandError{\n\t\t\tCommand: command,\n\t\t\tArgs:    args,\n\t\t\tEnv:     cmd.Env,\n\t\t\tExitErr: err,\n\t\t\tOutput:  output,\n\t\t}\n\t\tif exitErr, ok := err.(*exec.ExitError); ok {\n\t\t\tif status, ok := exitErr.Sys().(syscall.WaitStatus); ok {\n\t\t\t\texecErr.WaitStatus = status.ExitStatus()\n\t\t\t}\n\t\t}\n\t\tif liveLogger != nil {\n\t\t\t//If the caller didn't provide liveLogger the log isn't interesting and might spam\n\t\t\to.log.Info(execErr.DetailedError())\n\t\t}\n\t\treturn output, execErr\n\t}\n\to.log.Debug(\"Command executed:\", \" command\", command, \" arguments\", args, \"env vars\", cmd.Env, \"output\", output)\n\treturn output, err\n}\n\nfunc (o *ops) Mkdir(dirName string) error {\n\to.log.Infof(\"Creating directory: %s\", dirName)\n\t_, err := o.ExecPrivilegeCommand(o.logWriter, \"mkdir\", \"-p\", dirName)\n\treturn err\n}\n\nfunc (o *ops) SystemctlAction(action string, args ...string) error {\n\to.log.Infof(\"Running systemctl %s %s\", action, args)\n\t_, err := o.ExecPrivilegeCommand(o.logWriter, \"systemctl\", append([]string{action}, args...)...)\n\tif err != nil {\n\t\to.log.Errorf(\"Failed executing systemctl %s %s\", action, args)\n\t}\n\treturn errors.Wrapf(err, \"Failed executing systemctl %s %s\", action, args)\n}\n\nfunc (o *ops) WriteImageToDisk(ignitionPath string, device string, progressReporter inventory_client.InventoryClient, extraArgs []string) error {\n\tallArgs := installerArgs(ignitionPath, device, extraArgs)\n\to.log.Infof(\"Writing image and ignition to disk with arguments: %v\", allArgs)\n\t_, err := o.ExecPrivilegeCommand(NewCoreosInstallerLogWriter(o.log, progressReporter, config.GlobalConfig.HostID),\n\t\t\"coreos-installer\", allArgs...)\n\treturn err\n}\n\nfunc (o *ops) EvaluateDiskSymlink(device string) string {\n\t// Overcome https://github.com/coreos/coreos-installer/issues/512 bug.\n\t// coreos-installer has a bug where when a disk has busy partitions, it will\n\t// print a confusing error message if that disk doesn't have a `/dev/*` style path.\n\t// The service may give us paths that don't have the `/dev/*` path format but instead\n\t// are symlinks to the actual `/dev/*` path. e.g. `/dev/disk/by-id/wwn-*`.\n\t// To fix the bug we simply resolve the symlink and pass the resolved link to coreos-installer.\n\tlinkTarget, err := filepath.EvalSymlinks(device)\n\tif err != nil {\n\t\to.log.Warnf(\"Failed to filepath.EvalSymlinks(%s): %s. Continuing with %s anyway.\",\n\t\t\tdevice, err.Error(), device)\n\t} else {\n\t\to.log.Infof(\"Resolving installation device %s symlink to %s \", device, linkTarget)\n\t\tdevice = linkTarget\n\t}\n\treturn device\n}\n\nfunc installerArgs(ignitionPath string, device string, extra []string) []string {\n\tallArgs := []string{\"install\", \"--insecure\", \"-i\", ignitionPath}\n\tif extra != nil {\n\t\tallArgs = append(allArgs, extra...)\n\t}\n\treturn append(allArgs, device)\n}\n\nfunc (o *ops) Reboot() error {\n\to.log.Info(\"Rebooting node\")\n\t_, err := o.ExecPrivilegeCommand(o.logWriter, \"shutdown\", \"-r\", \"+1\", \"'Installation completed, server is going to reboot.'\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to reboot node, err: %s\", err)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) SetBootOrder(device string) error {\n\t_, err := o.ExecPrivilegeCommand(nil, \"test\", \"-d\", \"/sys/firmware/efi\")\n\tif err != nil {\n\t\to.log.Info(\"setting the boot order on BIOS systems is not supported. Skipping...\")\n\t\treturn nil\n\t}\n\n\to.log.Info(\"Setting efibootmgr to boot from disk\")\n\n\t// efi-system is installed onto partition 2\n\t_, err = o.ExecPrivilegeCommand(o.logWriter, \"efibootmgr\", \"-d\", device, \"-p\", \"2\", \"-c\", \"-L\", \"Red Hat Enterprise Linux\", \"-l\", \"\\\\EFI\\\\redhat\\\\shimx64.efi\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to set efibootmgr to boot from disk %s, err: %s\", device, err)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) ExtractFromIgnition(ignitionPath string, fileToExtract string) error {\n\to.log.Infof(\"Getting data from %s\", ignitionPath)\n\tignitionData, err := ioutil.ReadFile(ignitionPath)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to read %s : %e\", ignitionPath, err)\n\t\treturn err\n\t}\n\textractedContent, err := utils.GetFileContentFromIgnition(ignitionData, fileToExtract)\n\tif err != nil {\n\t\to.log.Error(\"Failed to parse ignition\")\n\t\treturn err\n\t}\n\n\ttmpFile := \"/opt/extracted_from_ignition.json\"\n\to.log.Infof(\"Writing extracted content to tmp file %s\", tmpFile)\n\t// #nosec\n\terr = ioutil.WriteFile(tmpFile, extractedContent, 0644)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while writing extracted content to %s\", tmpFile)\n\t\treturn err\n\t}\n\n\to.log.Infof(\"Moving %s to %s\", tmpFile, fileToExtract)\n\tdir := filepath.Dir(fileToExtract)\n\t_, err = o.ExecPrivilegeCommand(o.logWriter, \"mkdir\", \"-p\", filepath.Dir(fileToExtract))\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to create directory %s \", dir)\n\t\treturn err\n\t}\n\t_, err = o.ExecPrivilegeCommand(o.logWriter, \"mv\", tmpFile, fileToExtract)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while moving %s to %s\", tmpFile, fileToExtract)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) PrepareController() error {\n\n\tif err := o.renderControllerCm(); err != nil {\n\t\treturn err\n\t}\n\n\tif err := o.renderControllerSecret(); err != nil {\n\t\treturn err\n\t}\n\n\tif err := o.renderControllerPod(); err != nil {\n\t\treturn err\n\t}\n\n\t// Copy deploy files to manifestsFolder\n\tfiles, err := utils.FindFiles(controllerDeployFolder, utils.W_FILEONLY, \"*.yaml\")\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to get list of files from %s : %e\", controllerDeployFolder, err)\n\t\treturn err\n\t}\n\tfor _, file := range files {\n\t\terr := utils.CopyFile(file, filepath.Join(manifestsFolder, filepath.Base(file)))\n\t\tif err != nil {\n\t\t\to.log.Errorf(\"Failed to copy %s to %s. error :%e\", file, manifestsFolder, err)\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (o *ops) renderControllerCm() error {\n\tvar params = map[string]interface{}{\n\t\t\"InventoryUrl\":         config.GlobalConfig.URL,\n\t\t\"ClusterId\":            config.GlobalConfig.ClusterID,\n\t\t\"SkipCertVerification\": strconv.FormatBool(config.GlobalConfig.SkipCertVerification),\n\t\t\"CACertPath\":           config.GlobalConfig.CACertPath,\n\t\t\"HaMode\":               config.GlobalConfig.HighAvailabilityMode,\n\t\t\"CheckCVO\":             config.GlobalConfig.CheckClusterVersion,\n\t\t\"MustGatherImage\":      config.GlobalConfig.MustGatherImage,\n\t}\n\n\treturn o.renderDeploymentFiles(filepath.Join(controllerDeployFolder, controllerDeployCmTemplate),\n\t\tparams, renderedControllerCm)\n}\n\nfunc (o *ops) renderControllerSecret() error {\n\tvar params = map[string]interface{}{\n\t\t\"PullSecretToken\": config.GlobalConfig.PullSecretToken,\n\t}\n\n\treturn o.renderDeploymentFiles(filepath.Join(controllerDeployFolder, controllerDeploySecretTemplate),\n\t\tparams, renderedControllerSecret)\n}\n\nfunc (o *ops) renderControllerPod() error {\n\tvar params = map[string]interface{}{\n\t\t\"ControllerImage\":  config.GlobalConfig.ControllerImage,\n\t\t\"CACertPath\":       config.GlobalConfig.CACertPath,\n\t\t\"OpenshiftVersion\": config.GlobalConfig.OpenshiftVersion,\n\t}\n\n\tif config.GlobalConfig.ServiceIPs != \"\" {\n\t\tparams[\"ServiceIPs\"] = strings.Split(config.GlobalConfig.ServiceIPs, \",\")\n\t}\n\n\treturn o.renderDeploymentFiles(filepath.Join(controllerDeployFolder, controllerDeployPodTemplate),\n\t\tparams, renderedControllerPod)\n}\n\nfunc (o *ops) renderDeploymentFiles(srcTemplate string, params map[string]interface{}, dest string) error {\n\ttemplateData, err := ioutil.ReadFile(srcTemplate)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to read %s : %e\", srcTemplate, err)\n\t\treturn err\n\t}\n\to.log.Infof(\"Filling template file %s\", srcTemplate)\n\ttmpl := template.Must(template.New(\"assisted-controller\").Parse(string(templateData)))\n\tvar buf bytes.Buffer\n\tif err = tmpl.Execute(&buf, params); err != nil {\n\t\to.log.Errorf(\"Failed to render controller template: %e\", err)\n\t\treturn err\n\t}\n\n\tif err = o.Mkdir(manifestsFolder); err != nil {\n\t\to.log.Errorf(\"Failed to create manifests dir: %e\", err)\n\t\treturn err\n\t}\n\n\trenderedControllerYaml := filepath.Join(manifestsFolder, dest)\n\to.log.Infof(\"Writing rendered data to %s\", renderedControllerYaml)\n\t// #nosec\n\tif err = ioutil.WriteFile(renderedControllerYaml, buf.Bytes(), 0644); err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to write rendered data to %s : %e\", renderedControllerYaml, err)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) GetVGByPV(pvName string) (string, error) {\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"vgs\", \"--noheadings\", \"-o\", \"vg_name,pv_name\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to list VGs in the system\")\n\t\treturn \"\", err\n\t}\n\n\tlines := strings.Split(output, \"\\n\")\n\tfor _, line := range lines {\n\t\tres := strings.Fields(line)\n\t\tif len(res) < 2 {\n\t\t\tcontinue\n\t\t}\n\n\t\tif strings.Contains(res[1], pvName) {\n\t\t\treturn res[0], nil\n\t\t}\n\t}\n\treturn \"\", nil\n}\n\nfunc (o *ops) RemoveVG(vgName string) error {\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"vgremove\", vgName, \"-y\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to remove VG %s, output %s, error %s\", vgName, output, err)\n\t}\n\treturn err\n}\n\nfunc (o *ops) RemoveLV(lvName, vgName string) error {\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"lvremove\", fmt.Sprintf(\"/dev/%s/%s\", vgName, lvName), \"-y\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to remove LVM %s, output %s, error %s\", fmt.Sprintf(\"/dev/%s/%s\", vgName, lvName), output, err)\n\t}\n\treturn err\n}\n\nfunc (o *ops) RemovePV(pvName string) error {\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"pvremove\", pvName, \"-y\", \"-ff\")\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to remove PV %s, output %s, error %s\", pvName, output, err)\n\t}\n\treturn err\n}\n\nfunc (o *ops) Wipefs(device string) error {\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"wipefs\", \"-a\", device)\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to wipefs device %s, output %s, error %s\", device, output, err)\n\t}\n\treturn err\n}\n\nfunc (o *ops) GetMCSLogs() (string, error) {\n\n\tfiles, err := utils.FindFiles(\"/var/log/containers/\", utils.W_FILEONLY, \"*machine-config-server*.log\")\n\tif err != nil {\n\t\to.log.WithError(err).Errorf(\"Error occurred while trying to get list of files from %s\", \"/var/log/containers/\")\n\t\treturn \"\", err\n\t}\n\tif len(files) < 1 {\n\t\to.log.Warnf(\"MCS log file not found\")\n\t\treturn \"\", err\n\t}\n\t// There is theoretical option in case of static pod restart that there can be more than one file\n\t// we never saw it and it was decided not to handle it here\n\tlogs, err := ioutil.ReadFile(files[0])\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to read %s : %e\", files[0], err)\n\t\treturn \"\", err\n\t}\n\n\treturn string(logs), nil\n}\n\nfunc (o *ops) UploadInstallationLogs(isBootstrap bool) (string, error) {\n\tcommand := \"podman\"\n\targs := []string{\"run\", \"--rm\", \"--privileged\", \"--net=host\", \"--pid=host\", \"-v\", \"/run/systemd/journal/socket:/run/systemd/journal/socket\",\n\t\t\"-v\", \"/var/log:/var/log\", config.GlobalConfig.AgentImage, \"logs_sender\",\n\t\t\"-cluster-id\", config.GlobalConfig.ClusterID, \"-url\", config.GlobalConfig.URL,\n\t\t\"-host-id\", config.GlobalConfig.HostID,\n\t\t\"-pull-secret-token\", config.GlobalConfig.PullSecretToken,\n\t\tfmt.Sprintf(\"-insecure=%s\", strconv.FormatBool(config.GlobalConfig.SkipCertVerification)),\n\t\tfmt.Sprintf(\"-bootstrap=%s\", strconv.FormatBool(isBootstrap)),\n\t}\n\n\tif config.GlobalConfig.CACertPath != \"\" {\n\t\targs = append(args, fmt.Sprintf(\"-cacert=%s\", config.GlobalConfig.CACertPath))\n\t}\n\treturn o.ExecPrivilegeCommand(o.logWriter, command, args...)\n}\n\n// Sometimes we will need to reload container files from host\n// For example /etc/resolv.conf, it can't be changed with Z flag but is updated by bootkube.sh\n// and we need this update for dns resolve of kubeapi\nfunc (o *ops) ReloadHostFile(filepath string) error {\n\to.log.Infof(\"Reloading %s\", filepath)\n\toutput, err := o.ExecPrivilegeCommand(o.logWriter, \"cat\", filepath)\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to read %s on the host\", filepath)\n\t\treturn err\n\t}\n\tf, err := os.OpenFile(filepath, os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0644)\n\tdefer func() {\n\t\t_ = f.Close()\n\t}()\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to open local %s\", filepath)\n\t\treturn err\n\t}\n\t_, err = f.WriteString(output)\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to write host %s data to local\", filepath)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) CreateOpenshiftSshManifest(filePath, tmpl, sshPubKeyPath string) error {\n\to.log.Info(\"Create an openshift manifets for SSH public key\")\n\tsshPublicKey, err := o.ExecPrivilegeCommand(o.logWriter, \"cat\", sshPubKeyPath)\n\tif err != nil {\n\t\to.log.WithError(err).Errorf(\"Failed to read SSH pub key from %s\", sshPubKeyPath)\n\t\treturn err\n\t}\n\tf, err := os.Create(filePath)\n\tif err != nil {\n\t\to.log.WithError(err).Errorf(\"Failed to create %s\", filePath)\n\t\treturn err\n\t}\n\tdefer f.Close()\n\tt := template.Must(template.New(\"openshift SSH manifest\").Parse(tmpl))\n\tsshConfig := struct {\n\t\tSshPubKey string\n\t}{sshPublicKey}\n\tif err := t.Execute(f, sshConfig); err != nil {\n\t\to.log.WithError(err).Error(\"Failed to execute template\")\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (o *ops) GetMustGatherLogs(workDir, kubeconfigPath string, images ...string) (string, error) {\n\t//invoke oc adm must-gather command in the working directory\n\tvar imageOption string = \"\"\n\tfor _, img := range images {\n\t\timageOption = imageOption + fmt.Sprintf(\" --image=%s\", img)\n\t}\n\n\tcommand := fmt.Sprintf(\"cd %s && oc --kubeconfig=%s adm must-gather%s\", workDir, kubeconfigPath, imageOption)\n\toutput, err := o.ExecCommand(o.logWriter, \"bash\", \"-c\", command)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\to.log.Info(output)\n\n\t//find the directory of logs which is the output of the command\n\t//this is a temp directory so we have to find it by its prefix\n\tfiles, err := utils.FindFiles(workDir, utils.W_DIRONLY, \"must-gather*\")\n\tif err != nil {\n\t\to.log.WithError(err).Errorf(\"Failed to read must-gather working dir %s\\n\", workDir)\n\t\treturn \"\", err\n\t}\n\n\tif len(files) == 0 {\n\t\tlerr := fmt.Errorf(\"Failed to find must-gather output\")\n\t\to.log.Errorf(lerr.Error())\n\t\treturn \"\", lerr\n\t}\n\tlogsDir := filepath.Base(files[0])\n\n\t//tar the log directory and return the path to the tarball\n\ttarName := \"must-gather.tar.gz\"\n\tcommand = fmt.Sprintf(\"cd %s && tar zcf %s %s\", workDir, tarName, logsDir)\n\t_, err = o.ExecCommand(o.logWriter, \"bash\", \"-c\", command)\n\tif err != nil {\n\t\to.log.WithError(err).Errorf(\"Failed to tar must-gather logs\\n\")\n\t\treturn \"\", err\n\t}\n\treturn path.Join(workDir, tarName), nil\n}\n\nfunc (o *ops) CreateRandomHostname(hostname string) error {\n\tcommand := fmt.Sprintf(\"echo %s > /etc/hostname\", hostname)\n\to.log.Infof(\"create random hostname with command %s\", command)\n\t_, err := o.ExecPrivilegeCommand(o.logWriter, \"bash\", \"-c\", command)\n\treturn err\n}\n\nfunc (o *ops) GetHostname() (string, error) {\n\treturn os.Hostname()\n}\n\nfunc (o *ops) CreateManifests(kubeconfig string, manifestFilePath string) error {\n\tcommand := fmt.Sprintf(\"oc --kubeconfig=%s apply -f %s\", kubeconfig, manifestFilePath)\n\toutput, err := o.ExecCommand(o.logWriter, \"bash\", \"-c\", command)\n\tif err != nil {\n\t\treturn err\n\t}\n\to.log.Infof(\"Applying custom manifest file %s succeed %s\", manifestFilePath, output)\n\n\treturn nil\n}\n"], "filenames": ["src/assisted_installer_controller/assisted_installer_controller.go", "src/ops/ops.go"], "buggy_code_start_loc": [73, 241], "buggy_code_end_loc": [76, 242], "fixing_code_start_loc": [73, 241], "fixing_code_end_loc": [76, 242], "type": "CWE-532", "message": "A vulnerability was found in OpenShift Assisted Installer. During generation of the Discovery ISO, image pull secrets were leaked as plaintext in the installation logs. An authenticated user could exploit this by re-using the image pull secret to pull container images from the registry as the associated user.", "other": {"cve": {"id": "CVE-2021-3684", "sourceIdentifier": "secalert@redhat.com", "published": "2023-03-24T20:15:08.160", "lastModified": "2023-04-03T17:56:10.347", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A vulnerability was found in OpenShift Assisted Installer. During generation of the Discovery ISO, image pull secrets were leaked as plaintext in the installation logs. An authenticated user could exploit this by re-using the image pull secret to pull container images from the registry as the associated user."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-532"}]}, {"source": "secalert@redhat.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-532"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:redhat:openshift_assisted_installer:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.0.25.3", "matchCriteriaId": "15888A8B-A8B9-4EB6-B1DB-5C39D60DF658"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redhat:openshift_container_platform:4.6:*:*:*:*:*:*:*", "matchCriteriaId": "6B62E762-2878-455A-93C9-A5DB430D7BB5"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:o:redhat:enterprise_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "F4CFF558-3C47-480D-A2F0-BABF26042943"}]}]}], "references": [{"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1985962", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Vendor Advisory"]}, {"url": "https://github.com/openshift/assisted-installer/commit/2403dad3795406f2c5d923af0894e07bc8b0bdc4", "source": "secalert@redhat.com", "tags": ["Patch"]}, {"url": "https://github.com/openshift/assisted-installer/commit/f3800cfa3d64ce6dcd6f7b73f0578bb99bfdaf7a", "source": "secalert@redhat.com", "tags": ["Patch"]}]}, "github_commit_url": "https://github.com/openshift/assisted-installer/commit/2403dad3795406f2c5d923af0894e07bc8b0bdc4"}}
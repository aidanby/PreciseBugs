{"buggy_code": ["/* p_lx_elf.cpp --\n\n   This file is part of the UPX executable compressor.\n\n   Copyright (C) 1996-2022 Markus Franz Xaver Johannes Oberhumer\n   Copyright (C) 1996-2022 Laszlo Molnar\n   Copyright (C) 2000-2022 John F. Reiser\n   All Rights Reserved.\n\n   UPX and the UCL library are free software; you can redistribute them\n   and/or modify them under the terms of the GNU General Public License as\n   published by the Free Software Foundation; either version 2 of\n   the License, or (at your option) any later version.\n\n   This program is distributed in the hope that it will be useful,\n   but WITHOUT ANY WARRANTY; without even the implied warranty of\n   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n   GNU General Public License for more details.\n\n   You should have received a copy of the GNU General Public License\n   along with this program; see the file COPYING.\n   If not, write to the Free Software Foundation, Inc.,\n   59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.\n\n   Markus F.X.J. Oberhumer              Laszlo Molnar\n   <markus@oberhumer.com>               <ezerotven+github@gmail.com>\n\n   John F. Reiser\n   <jreiser@users.sourceforge.net>\n */\n\n\n#include \"conf.h\"\n\n#include \"file.h\"\n#include \"filter.h\"\n#include \"linker.h\"\n#include \"packer.h\"\n#include \"p_elf.h\"\n#include \"p_unix.h\"\n#include \"p_lx_exc.h\"\n#include \"p_lx_elf.h\"\n#include \"ui.h\"\n\ntypedef upx_uint32_t u32_t;  // easier to type; more narrow\ntypedef upx_uint64_t u64_t;  // easier to type; more narrow\n\n#define PT_LOAD32   Elf32_Phdr::PT_LOAD\n#define PT_LOAD64   Elf64_Phdr::PT_LOAD\n#define PT_NOTE32   Elf32_Phdr::PT_NOTE\n#define PT_NOTE64   Elf64_Phdr::PT_NOTE\n#define PT_GNU_STACK32  Elf32_Phdr::PT_GNU_STACK\n#define PT_GNU_STACK64  Elf64_Phdr::PT_GNU_STACK\n\n//static unsigned const EF_ARM_HASENTRY = 0x02;\nstatic unsigned const EF_ARM_EABI_VER4 = 0x04000000;\nstatic unsigned const EF_ARM_EABI_VER5 = 0x05000000;\n\nunsigned char PackLinuxElf::o_shstrtab[] = {  \\\n/*start*/       '\\0',\n/*offset  1*/   '.','n','o','t','e','.','g','n','u','.','b','u','i','l','d','-','i','d','\\0',\n/*offset 20*/   '.','s','h','s','t','r','t','a','b','\\0'\n};\n\n#define usizeof(x)      ((unsigned) sizeof(x))\n\nstatic unsigned\numin(unsigned a, unsigned b)\n{\n    return (a < b) ? a : b;\n}\n\nstatic upx_uint64_t\numin64(upx_uint64_t a, upx_uint64_t b)\n{\n    return (a < b) ? a : b;\n}\n\nstatic unsigned\nup4(unsigned x)\n{\n    return ~3u & (3+ x);\n}\n\n#if 0  //{ unused\nstatic unsigned\nup8(unsigned x)\n{\n    return ~7u & (7+ x);\n}\n#endif  //}\n\nstatic off_t\nfpad4(OutputFile *fo)\n{\n    off_t len = fo->st_size();\n    unsigned d = 3u & (0 - len);\n    unsigned zero = 0;\n    fo->write(&zero, d);\n    return d + len;\n}\n\nstatic off_t\nfpad8(OutputFile *fo)\n{\n    off_t len = fo->st_size();\n    unsigned d = 7u & (0 - len);\n    upx_uint64_t zero = 0;\n    fo->write(&zero, d);\n    return d + len;\n}\n\nstatic unsigned\nfunpad4(InputFile *fi)\n{\n    unsigned d = 3u & (0 - fi->tell());\n    if (d)\n        fi->seek(d, SEEK_CUR);\n    return d;\n}\n\nstatic void alloc_file_image(MemBuffer &mb, off_t size)\n{\n    assert(mem_size_valid_bytes(size));\n    if (mb.getVoidPtr() == nullptr) {\n        mb.alloc(size);\n    } else {\n        assert((u32_t)size <= mb.getSize());\n    }\n}\n\nint\nPackLinuxElf32::checkEhdr(Elf32_Ehdr const *ehdr) const\n{\n    const unsigned char * const buf = ehdr->e_ident;\n\n    if (0!=memcmp(buf, \"\\x7f\\x45\\x4c\\x46\", 4)  // \"\\177ELF\"\n    ||  buf[Elf32_Ehdr::EI_CLASS]!=ei_class\n    ||  buf[Elf32_Ehdr::EI_DATA] !=ei_data\n    ) {\n        return -1;\n    }\n    if (!memcmp(buf+8, \"FreeBSD\", 7))                   // branded\n        return 1;\n\n    int const type = get_te16(&ehdr->e_type);\n    if (type != Elf32_Ehdr::ET_EXEC && type != Elf32_Ehdr::ET_DYN)\n        return 2;\n    if (get_te16(&ehdr->e_machine) != (unsigned) e_machine)\n        return 3;\n    if (get_te32(&ehdr->e_version) != Elf32_Ehdr::EV_CURRENT)\n        return 4;\n    if (e_phnum < 1)\n        return 5;\n    if (get_te16(&ehdr->e_phentsize) != sizeof(Elf32_Phdr))\n        return 6;\n\n    if (type == Elf32_Ehdr::ET_EXEC) {\n        // check for Linux kernels\n        unsigned const entry = get_te32(&ehdr->e_entry);\n        if (entry == 0xC0100000)    // uncompressed vmlinux\n            return 1000;\n        if (entry == 0x00001000)    // compressed vmlinux\n            return 1001;\n        if (entry == 0x00100000)    // compressed bvmlinux\n            return 1002;\n    }\n\n    // FIXME: add more checks for kernels\n\n    // FIXME: add special checks for other ELF i386 formats, like\n    //        NetBSD, OpenBSD, Solaris, ....\n\n    // success\n    return 0;\n}\n\nint\nPackLinuxElf64::checkEhdr(Elf64_Ehdr const *ehdr) const\n{\n    const unsigned char * const buf = ehdr->e_ident;\n    unsigned char osabi0 = buf[Elf32_Ehdr::EI_OSABI];\n    if (0==osabi0) {\n        osabi0 = opt->o_unix.osabi0;\n    }\n\n    if (0!=memcmp(buf, \"\\x7f\\x45\\x4c\\x46\", 4)  // \"\\177ELF\"\n    ||  buf[Elf64_Ehdr::EI_CLASS]!=ei_class\n    ||  buf[Elf64_Ehdr::EI_DATA] !=ei_data\n    ||                     osabi0!=ei_osabi\n    ) {\n        return -1;\n    }\n    if (!memcmp(buf+8, \"FreeBSD\", 7))                   // branded\n        return 1;\n\n    int const type = get_te16(&ehdr->e_type);\n    if (type != Elf64_Ehdr::ET_EXEC && type != Elf64_Ehdr::ET_DYN)\n        return 2;\n    if (get_te16(&ehdr->e_machine) != (unsigned) e_machine)\n        return 3;\n    if (get_te32(&ehdr->e_version) != Elf64_Ehdr::EV_CURRENT)\n        return 4;\n    if (e_phnum < 1)\n        return 5;\n    if (get_te16(&ehdr->e_phentsize) != sizeof(Elf64_Phdr))\n        return 6;\n\n    if (type == Elf64_Ehdr::ET_EXEC) {\n        // check for Linux kernels\n        upx_uint64_t const entry = get_te64(&ehdr->e_entry);\n        if (entry == 0xC0100000)    // uncompressed vmlinux\n            return 1000;\n        if (entry == 0x00001000)    // compressed vmlinux\n            return 1001;\n        if (entry == 0x00100000)    // compressed bvmlinux\n            return 1002;\n    }\n\n    // FIXME: add more checks for kernels\n\n    // FIXME: add special checks for other ELF i386 formats, like\n    //        NetBSD, OpenBSD, Solaris, ....\n\n    // success\n    return 0;\n}\n\nPackLinuxElf::PackLinuxElf(InputFile *f)\n    : super(f), e_phnum(0), dynstr(nullptr),\n    sz_phdrs(0), sz_elf_hdrs(0), sz_pack2(0), sz_pack2a(0),\n    lg2_page(12), page_size(1u<<lg2_page), is_pie(0),\n    xct_off(0), xct_va(0), jni_onload_va(0),\n    user_init_va(0), user_init_off(0),\n    e_machine(0), ei_class(0), ei_data(0), ei_osabi(0), osabi_note(nullptr),\n    shstrtab(nullptr),\n    o_elf_shnum(0)\n{\n    memset(dt_table, 0, sizeof(dt_table));\n}\n\nPackLinuxElf::~PackLinuxElf()\n{\n}\n\nint PackLinuxElf32::is_LOAD32(Elf32_Phdr const *phdr) const\n{\n    // (1+ PT_LOPROC) can confuse!\n    return PT_LOAD32 == get_te32(&phdr->p_type);\n}\n\nvoid\nPackLinuxElf32::PackLinuxElf32help1(InputFile *f)\n{\n    e_type  = get_te16(&ehdri.e_type);\n    e_phnum = get_te16(&ehdri.e_phnum);\n    e_shnum = get_te16(&ehdri.e_shnum);\n    unsigned const e_phentsize = get_te16(&ehdri.e_phentsize);\n    if (ehdri.e_ident[Elf32_Ehdr::EI_CLASS]!=Elf32_Ehdr::ELFCLASS32\n    || sizeof(Elf32_Phdr) != e_phentsize\n    || (Elf32_Ehdr::ELFDATA2MSB == ehdri.e_ident[Elf32_Ehdr::EI_DATA]\n            && &N_BELE_RTP::be_policy != bele)\n    || (Elf32_Ehdr::ELFDATA2LSB == ehdri.e_ident[Elf32_Ehdr::EI_DATA]\n            && &N_BELE_RTP::le_policy != bele)) {\n        e_phoff = 0;\n        e_shoff = 0;\n        sz_phdrs = 0;\n        return;\n    }\n    if (0==e_phnum) throwCantUnpack(\"0==e_phnum\");\n    e_phoff = get_te32(&ehdri.e_phoff);\n    unsigned const last_Phdr = e_phoff + e_phnum * usizeof(Elf32_Phdr);\n    if (last_Phdr < e_phoff  // wrap-around\n    ||  e_phoff != sizeof(Elf32_Ehdr)  // must be contiguous\n    ||  (unsigned long)file_size < last_Phdr) {\n        throwCantUnpack(\"bad e_phoff\");\n    }\n    e_shoff = get_te32(&ehdri.e_shoff);\n    unsigned const last_Shdr = e_shoff + e_shnum * usizeof(Elf32_Shdr);\n    if (last_Shdr < e_shoff  // wrap-around\n    ||  (e_shnum && e_shoff < last_Phdr)\n    ||  (unsigned long)file_size < last_Shdr) {\n        if (opt->cmd == CMD_COMPRESS) {\n            throwCantUnpack(\"bad e_shoff\");\n        }\n    }\n    sz_phdrs = e_phnum * e_phentsize;\n\n    if (f && Elf32_Ehdr::ET_DYN!=e_type) {\n        unsigned const len = sz_phdrs + e_phoff;\n        alloc_file_image(file_image, len);\n        f->seek(0, SEEK_SET);\n        f->readx(file_image, len);\n        phdri= (Elf32_Phdr       *)(e_phoff + file_image);  // do not free() !!\n    }\n    if (f && Elf32_Ehdr::ET_DYN==e_type) {\n        // The DT_SYMTAB has no designated length.  Read the whole file.\n        alloc_file_image(file_image, file_size);\n        f->seek(0, SEEK_SET);\n        f->readx(file_image, file_size);\n        phdri= (Elf32_Phdr *)(e_phoff + file_image);  // do not free() !!\n        shdri= (Elf32_Shdr *)(e_shoff + file_image);  // do not free() !!\n        if (opt->cmd != CMD_COMPRESS) {\n            shdri = nullptr;\n        }\n        sec_dynsym = elf_find_section_type(Elf32_Shdr::SHT_DYNSYM);\n        if (sec_dynsym) {\n            unsigned t = get_te32(&sec_dynsym->sh_link);\n            if (e_shnum <= t)\n                throwCantPack(\"bad dynsym->sh_link\");\n            sec_dynstr = &shdri[t];\n        }\n\n        Elf32_Phdr const *phdr= phdri;\n        for (int j = e_phnum; --j>=0; ++phdr)\n        if (Elf32_Phdr::PT_DYNAMIC==get_te32(&phdr->p_type)) {\n            unsigned offset = check_pt_dynamic(phdr);\n            dynseg= (Elf32_Dyn const *)(offset + file_image);\n            invert_pt_dynamic(dynseg,\n                umin(get_te32(&phdr->p_filesz), file_size - offset));\n        }\n        else if (is_LOAD32(phdr)) {\n            check_pt_load(phdr);\n        }\n        // elf_find_dynamic() returns 0 if 0==dynseg.\n        dynstr =      (char const *)elf_find_dynamic(Elf32_Dyn::DT_STRTAB);\n        dynsym = (Elf32_Sym const *)elf_find_dynamic(Elf32_Dyn::DT_SYMTAB);\n        gashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_GNU_HASH);\n        hashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_HASH);\n        if (3& ((upx_uintptr_t)dynsym | (upx_uintptr_t)gashtab | (upx_uintptr_t)hashtab)) {\n            throwCantPack(\"unaligned DT_SYMTAB, DT_GNU_HASH, or DT_HASH/n\");\n        }\n        jni_onload_sym = elf_lookup(\"JNI_OnLoad\");\n        if (jni_onload_sym) {\n            jni_onload_va = get_te32(&jni_onload_sym->st_value);\n            jni_onload_va = 0;  // FIXME not understood; need example\n        }\n    }\n}\n\noff_t PackLinuxElf::pack3(OutputFile *fo, Filter &ft) // return length of output\n{\n    unsigned disp;\n    unsigned const zero = 0;\n    unsigned len = sz_pack2a;  // after headers and all PT_LOAD\n\n    unsigned const t = (4 & len) ^ ((!!xct_off)<<2);  // 0 or 4\n    fo->write(&zero, t);\n    len += t;  // force sz_pack2 (0 mod 8)  [see below]\n\n    set_te32(&disp, sz_elf_hdrs + usizeof(p_info) + usizeof(l_info) +\n        (!!xct_off & !!opt->o_unix.android_shlib));  // |1 iff android shlib\n    fo->write(&disp, sizeof(disp));  // offset(b_info)\n    len += sizeof(disp);\n    set_te32(&disp, len);  // distance back to beginning (detect dynamic reloc)\n    fo->write(&disp, sizeof(disp));\n    len += sizeof(disp);\n\n    if (xct_off) {  // is_shlib\n        upx_uint64_t const firstpc_va = (jni_onload_va\n            ? jni_onload_va\n            : user_init_va);\n        set_te32(&disp, firstpc_va - load_va);\n        fo->write(&disp, sizeof(disp));  // DT_INIT.d_val\n        len += sizeof(disp);\n\n        set_te32(&disp, hatch_off);\n        fo->write(&disp, sizeof(disp));  // offset(hatch)\n        len += sizeof(disp);\n\n        if (opt->o_unix.android_shlib) {\n            xct_off += asl_delta;  // the extra page\n        }\n        set_te32(&disp, overlay_offset - sizeof(linfo));\n        fo->write(&disp, sizeof(disp));  // &{l_info; p_info; b_info}\n        len += sizeof(disp);\n    }\n    sz_pack2 = len;  // 0 mod 8  [see above]\n\n    super::pack3(fo, ft);  // append the decompressor\n    set_te16(&linfo.l_lsize, up4(  // MATCH03: up4\n    get_te16(&linfo.l_lsize) + len - sz_pack2a));\n\n    return fpad4(fo);  // MATCH03\n}\n\n// C_BASE covers the convex hull of the PT_LOAD of the uncompressed module.\n// It has (PF_W & .p_flags), and is \".bss\": empty (0==.p_filesz, except a bug\n// in Linux kernel forces 0x1000==.p_filesz) with .p_memsz equal to the brk(0).\n// It is first in order to reserve all // pages, in particular so that if\n// (64K == .p_align) but at runtime (4K == PAGE_SIZE) then the Linux kernel\n// does not put [vdso] and [vvar] into alignment holes that the UPX runtime stub\n// will overwrite.\n//\n// Note that C_TEXT[.p_vaddr, +.p_memsz) is a subset of C_BASE.\n// This requires that the kernel process the ELFxx_Phdr in ascending order,\n// and does not mind the overlap.  The UPX runtime stub will \"re-program\"\n// the memory regions anyway.\nenum { // ordinals in ELFxx_Phdr[] of compressed output\n      C_BASE = 0  // reserve address space\n    , C_TEXT = 1  // compressed data and stub\n    , C_NOTE = 2  // PT_NOTE copied from input\n    , C_GSTK = 3  // PT_GNU_STACK; will be 2 if no PT_NOTE\n};\n\noff_t PackLinuxElf32::pack3(OutputFile *fo, Filter &ft)\n{\n    off_t flen = super::pack3(fo, ft);  // loader follows compressed PT_LOADs\n    // NOTE: PackLinuxElf::pack3  adjusted xct_off for the extra page\n\n    unsigned v_hole = sz_pack2 + lsize;\n    set_te32(&elfout.phdr[C_TEXT].p_filesz, v_hole);\n    set_te32(&elfout.phdr[C_TEXT].p_memsz,  v_hole);\n    // Then compressed gaps (including debuginfo.)\n    for (unsigned k = 0; k < e_phnum; ++k) {\n        Extent x;\n        x.size = find_LOAD_gap(phdri, k, e_phnum);\n        if (x.size) {\n            x.offset = get_te32(&phdri[k].p_offset) +\n                       get_te32(&phdri[k].p_filesz);\n            packExtent(x, nullptr, fo);\n        }\n    }\n    // write block end marker (uncompressed size 0)\n    b_info hdr; memset(&hdr, 0, sizeof(hdr));\n    set_le32(&hdr.sz_cpr, UPX_MAGIC_LE32);\n    fo->write(&hdr, sizeof(hdr));\n    flen = fpad4(fo);\n\n    set_te32(&elfout.phdr[C_TEXT].p_filesz, sz_pack2 + lsize);\n    set_te32(&elfout.phdr[C_TEXT].p_memsz,  sz_pack2 + lsize);\n    if (0==xct_off) { // not shared library\n        set_te32(&elfout.phdr[C_BASE].p_align, 0u - page_mask);\n        elfout.phdr[C_BASE].p_paddr = elfout.phdr[C_BASE].p_vaddr;\n        elfout.phdr[C_BASE].p_offset = 0;\n        // vbase handles ET_EXEC.  FIXME: pre-linking?\n        unsigned vbase = get_te32(&elfout.phdr[C_BASE].p_vaddr);\n        unsigned abrk = getbrk(phdri, e_phnum);\n        set_te32(&elfout.phdr[C_BASE].p_filesz, 0x1000);  // Linux kernel SIGSEGV if (0==.p_filesz)\n        set_te32(&elfout.phdr[C_BASE].p_memsz, abrk - vbase);\n        set_te32(&elfout.phdr[C_BASE].p_flags, Elf32_Phdr::PF_W|Elf32_Phdr::PF_R);\n        set_te32(&elfout.phdr[C_TEXT].p_vaddr, abrk= (page_mask & (~page_mask + abrk)));\n        elfout.phdr[C_TEXT].p_paddr = elfout.phdr[C_TEXT].p_vaddr;\n        set_te32(&elfout.ehdr.e_entry, abrk + get_te32(&elfout.ehdr.e_entry) - vbase);\n    }\n    if (0!=xct_off) {  // shared library\n        unsigned word = (Elf32_Ehdr::EM_ARM==e_machine) + load_va + sz_pack2;  // Thumb mode\n        set_te32(&file_image[user_init_off], word);  // set the hook\n\n        Elf32_Phdr *phdr = (Elf32_Phdr *)lowmem.subref(\n                \"bad e_phoff\", e_phoff, e_phnum * sizeof(Elf32_Phdr));\n        unsigned off = fo->st_size();\n        so_slide = 0;\n        for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n            unsigned const len  = get_te32(&phdr->p_filesz);\n            unsigned const ioff = get_te32(&phdr->p_offset);\n            unsigned       align= get_te32(&phdr->p_align);\n            unsigned const type = get_te32(&phdr->p_type);\n            if (Elf32_Phdr::PT_INTERP==type) {\n                // Rotate to highest position, so it can be lopped\n                // by decrementing e_phnum.\n                memcpy((unsigned char *)ibuf, phdr, sizeof(*phdr));  // extract\n                memmove(phdr, 1+phdr, (e_phnum - (1+ j))*sizeof(*phdr));  // overlapping\n                memcpy(&phdr[e_phnum - (1+ j)], (unsigned char *)ibuf, sizeof(*phdr));  // to top\n                --phdr; --e_phnum;\n                set_te16(&ehdri.e_phnum, e_phnum);\n                set_te16(&((Elf32_Ehdr *)(unsigned char *)lowmem)->e_phnum, e_phnum);\n                continue;\n            }\n            if (PT_LOAD32 == type) {\n                if ((xct_off - ioff) < len) { // Change length of compressed PT_LOAD.\n                    set_te32(&phdr->p_filesz, sz_pack2 + lsize - ioff);\n                    set_te32(&phdr->p_memsz,  sz_pack2 + lsize - ioff);\n                    if (user_init_off < xct_off) { // MIPS puts PT_DYNAMIC here\n                        // Allow for DT_INIT in a new [stolen] slot\n                        unsigned off2 = user_init_off - sizeof(word);\n                        fo->seek(off2, SEEK_SET);\n                        fo->rewrite(&file_image[off2], 2*sizeof(word));\n                    }\n                }\n                else if (xct_off < ioff) { // Slide subsequent PT_LOAD.\n                    if ((1u<<12) < align) {\n                        align = 1u<<12;\n                        set_te32(&phdr->p_align, align);\n                    }\n                    off += (align-1) & (ioff - off);\n                    fo->seek(  off, SEEK_SET);\n                    fo->write(&file_image[ioff], len);\n                    so_slide = off - ioff;\n                    set_te32(&phdr->p_offset, so_slide + ioff);\n                }\n                continue;  // all done with this PT_LOAD\n            }\n            if (xct_off < ioff)\n                set_te32(&phdr->p_offset, so_slide + ioff);\n        }  // end each Phdr\n\n        if (opt->o_unix.android_shlib) {\n            // Update {DYNAMIC}.sh_offset by so_slide.\n            Elf32_Shdr *shdr = (Elf32_Shdr *)lowmem.subref(\n                    \"bad e_shoff\", xct_off - asl_delta, e_shnum * sizeof(Elf32_Shdr));\n            for (unsigned j = 0; j < e_shnum; ++shdr, ++j) {\n                unsigned sh_type = get_te32(&shdr->sh_type);\n                if (Elf32_Shdr::SHT_DYNAMIC == get_te32(&shdr->sh_type)) {\n                    unsigned offset = get_te32(&shdr->sh_offset);\n                    set_te32(&shdr->sh_offset, so_slide + offset );\n                    fo->seek((j * sizeof(Elf32_Shdr)) + xct_off - asl_delta, SEEK_SET);\n                    fo->rewrite(shdr, sizeof(*shdr));\n                    fo->seek(0, SEEK_END);\n                }\n                if (Elf32_Shdr::SHT_REL == sh_type\n                &&  n_jmp_slot\n                &&  !strcmp(\".rel.plt\", get_te32(&shdr->sh_name) + shstrtab)) {\n                    unsigned f_off = elf_get_offset_from_address(plt_off);\n                    fo->seek(so_slide + f_off, SEEK_SET);  // FIXME: assumes PT_LOAD[1]\n                    fo->rewrite(&file_image[f_off], n_jmp_slot * 4);\n                 }\n            }\n        }\n        else { // !opt->o_unix.android_shlib)\n            ehdri.e_shnum = 0;\n            ehdri.e_shoff = 0;\n            ehdri.e_shstrndx = 0;\n        }\n    }\n    return flen;\n}\n\noff_t PackLinuxElf64::pack3(OutputFile *fo, Filter &ft)\n{\n    off_t flen = super::pack3(fo, ft);  // loader follows compressed PT_LOADs\n    // NOTE: PackLinuxElf::pack3  adjusted xct_off for the extra page\n\n    unsigned v_hole = sz_pack2 + lsize;\n    set_te64(&elfout.phdr[C_TEXT].p_filesz, v_hole);\n    set_te64(&elfout.phdr[C_TEXT].p_memsz,  v_hole);\n    // Then compressed gaps (including debuginfo.)\n    for (unsigned k = 0; k < e_phnum; ++k) {\n        Extent x;\n        x.size = find_LOAD_gap(phdri, k, e_phnum);\n        if (x.size) {\n            x.offset = get_te64(&phdri[k].p_offset) +\n                       get_te64(&phdri[k].p_filesz);\n            packExtent(x, nullptr, fo);\n        }\n    }\n    // write block end marker (uncompressed size 0)\n    b_info hdr; memset(&hdr, 0, sizeof(hdr));\n    set_le32(&hdr.sz_cpr, UPX_MAGIC_LE32);\n    fo->write(&hdr, sizeof(hdr));\n    flen = fpad4(fo);\n\n    set_te64(&elfout.phdr[C_TEXT].p_filesz, sz_pack2 + lsize);\n    set_te64(&elfout.phdr[C_TEXT].p_memsz,  sz_pack2 + lsize);\n    if (0==xct_off) { // not shared library\n        set_te64(&elfout.phdr[C_BASE].p_align, ((upx_uint64_t)0) - page_mask);\n        elfout.phdr[C_BASE].p_paddr = elfout.phdr[C_BASE].p_vaddr;\n        elfout.phdr[C_BASE].p_offset = 0;\n        upx_uint64_t abrk = getbrk(phdri, e_phnum);\n        // vbase handles ET_EXEC.  FIXME: pre-linking?\n        upx_uint64_t const vbase = get_te64(&elfout.phdr[C_BASE].p_vaddr);\n        set_te64(&elfout.phdr[C_BASE].p_filesz, 0x1000);  // Linux kernel SIGSEGV if (0==.p_filesz)\n        set_te64(&elfout.phdr[C_BASE].p_memsz, abrk - vbase);\n        set_te32(&elfout.phdr[C_BASE].p_flags, Elf32_Phdr::PF_W|Elf32_Phdr::PF_R);\n        set_te64(&elfout.phdr[C_TEXT].p_vaddr, abrk= (page_mask & (~page_mask + abrk)));\n        elfout.phdr[C_TEXT].p_paddr = elfout.phdr[C_TEXT].p_vaddr;\n        set_te64(&elfout.ehdr.e_entry, abrk + get_te64(&elfout.ehdr.e_entry) - vbase);\n    }\n    if (0!=xct_off) {  // shared library\n        upx_uint64_t word = load_va + sz_pack2;\n        set_te64(&file_image[user_init_off], word);  // set the hook\n\n        Elf64_Phdr *phdr = (Elf64_Phdr *)lowmem.subref(\n                \"bad e_phoff\", e_phoff, e_phnum * sizeof(Elf64_Phdr));\n        unsigned off = fo->st_size();\n        so_slide = 0;\n        for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n            upx_uint64_t const len  = get_te64(&phdr->p_filesz);\n            upx_uint64_t const ioff = get_te64(&phdri[j].p_offset);\n            upx_uint64_t       align= get_te64(&phdr->p_align);\n            unsigned const type = get_te32(&phdr->p_type);\n            if (Elf64_Phdr::PT_INTERP==type) {\n                // Rotate to highest position, so it can be lopped\n                // by decrementing e_phnum.\n                memcpy((unsigned char *)ibuf, phdr, sizeof(*phdr));  // extract\n                memmove(phdr, 1+phdr, (e_phnum - (1+ j))*sizeof(*phdr));  // overlapping\n                memcpy(&phdr[e_phnum - (1+ j)], (unsigned char *)ibuf, sizeof(*phdr));  // to top\n                --phdr; --e_phnum;\n                set_te16(&ehdri.e_phnum, e_phnum);\n                set_te16(&((Elf64_Ehdr *)(unsigned char *)lowmem)->e_phnum, e_phnum);\n                continue;\n            }\n            if (PT_LOAD64 == type) {\n                if ((xct_off - ioff) < len) { // Change length of compressed PT_LOAD.\n                    set_te64(&phdr->p_filesz, sz_pack2 + lsize);\n                    set_te64(&phdr->p_memsz,  sz_pack2 + lsize);\n                    if (user_init_off < xct_off) { // MIPS puts PT_DYNAMIC here\n                        // Allow for DT_INIT in a new [stolen] slot\n                        unsigned off2 = user_init_off - sizeof(word);\n                        fo->seek(off2, SEEK_SET);\n                        fo->rewrite(&file_image[off2], 2*sizeof(word));\n                    }\n                }\n                else if (j && (Elf64_Phdr::PF_W & get_te64(&phdr->p_flags))\n                     &&  xct_off < ioff) {  // Slide subsequent PT_LOAD.\n                    // AMD64 chip supports page sizes of 4KiB, 2MiB, and 1GiB;\n                    // the operating system chooses one.  .p_align typically\n                    // is a forward-looking 2MiB.  In 2009 Linux chooses 4KiB.\n                    // We choose 4KiB to waste less space.  If Linux chooses\n                    // 2MiB later, then our output will not run.\n                    if ((1u<<12) < align\n                    &&  Elf64_Ehdr::EM_X86_64 ==e_machine\n                    ) {\n                        align = 1u<<12;\n                        set_te64(&phdr->p_align, align);\n                    }\n                    off += (align-1) & (ioff - off);\n                    set_te64(&phdr->p_offset, off);\n                    so_slide = off - ioff;\n                    fo->seek(  off, SEEK_SET);\n                    fo->write(&file_image[ioff], len);\n                    off += len;\n                }\n                continue;  // all done with this PT_LOAD\n            }\n            if (xct_off < ioff)\n                set_te64(&phdr->p_offset, so_slide + ioff);\n        }  // end each Phdr\n\n        if (opt->o_unix.android_shlib) {\n            // Update {DYNAMIC}.sh_offset by so_slide.\n            Elf64_Shdr *shdr = (Elf64_Shdr *)lowmem.subref(\n                    \"bad e_shoff\", xct_off - asl_delta, e_shnum * sizeof(Elf64_Shdr));\n            for (unsigned j = 0; j < e_shnum; ++shdr, ++j) {\n                unsigned sh_type = get_te32(&shdr->sh_type);\n                if (Elf64_Shdr::SHT_DYNAMIC == sh_type) {\n                    upx_uint64_t offset = get_te64(&shdr->sh_offset);\n                    set_te64(&shdr->sh_offset, so_slide + offset);\n                    fo->seek((j * sizeof(Elf64_Shdr)) + xct_off - asl_delta, SEEK_SET);\n                    fo->rewrite(shdr, sizeof(*shdr));\n                    fo->seek(0, SEEK_END);\n                }\n                if (Elf64_Shdr::SHT_RELA == sh_type\n                &&  n_jmp_slot\n                &&  !strcmp(\".rela.plt\", get_te32(&shdr->sh_name) + shstrtab)) {\n                    upx_uint64_t f_off = elf_get_offset_from_address(plt_off);\n                    fo->seek(so_slide + f_off, SEEK_SET);  // FIXME: assumes PT_LOAD[1]\n                    fo->rewrite(&file_image[f_off], n_jmp_slot * 8);\n                }\n            }\n        }\n        else { // !opt->o_unix.android_shlib)\n            ehdri.e_shnum = 0;\n            ehdri.e_shoff = 0;\n            ehdri.e_shstrndx = 0;\n        }\n    }\n    return flen;\n}\n\nvoid\nPackLinuxElf::addStubEntrySections(Filter const *)\n{\n    addLoader(\"ELFMAINX\", nullptr);\n    if (hasLoaderSection(\"ELFMAINXu\")) {\n            // brk() trouble if static\n        addLoader(\"ELFMAINXu\", nullptr);\n    }\n   //addLoader(getDecompressorSections(), nullptr);\n    addLoader(\n        ( M_IS_NRV2E(ph.method) ? \"NRV_HEAD,NRV2E,NRV_TAIL\"\n        : M_IS_NRV2D(ph.method) ? \"NRV_HEAD,NRV2D,NRV_TAIL\"\n        : M_IS_NRV2B(ph.method) ? \"NRV_HEAD,NRV2B,NRV_TAIL\"\n        : M_IS_LZMA(ph.method)  ? \"LZMA_ELF00,LZMA_DEC20,LZMA_DEC30\"\n        : nullptr), nullptr);\n    if (hasLoaderSection(\"CFLUSH\"))\n        addLoader(\"CFLUSH\");\n    addLoader(\"ELFMAINY,IDENTSTR\", nullptr);\n    if (hasLoaderSection(\"ELFMAINZe\")) { // ppc64 big-endian only\n        addLoader(\"ELFMAINZe\", nullptr);\n    }\n    addLoader(\"+40,ELFMAINZ\", nullptr);\n    if (hasLoaderSection(\"ANDMAJNZ\")) { // Android trouble with args to DT_INIT\n        if (opt->o_unix.android_shlib) {\n            addLoader(\"ANDMAJNZ\", nullptr);  // constant PAGE_SIZE\n        }\n        else {\n            addLoader(\"ELFMAJNZ\", nullptr);  // PAGE_SIZE from AT_PAGESZ\n        }\n        addLoader(\"ELFMAKNZ\", nullptr);\n    }\n    if (hasLoaderSection(\"ELFMAINZu\")) {\n        addLoader(\"ELFMAINZu\", nullptr);\n    }\n    addLoader(\"FOLDEXEC\", nullptr);\n}\n\n\nvoid PackLinuxElf::defineSymbols(Filter const *)\n{\n    linker->defineSymbol(\"O_BINFO\", (!!opt->o_unix.is_ptinterp) | o_binfo);\n}\n\nvoid PackLinuxElf32::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf::defineSymbols(ft);\n}\n\nvoid PackLinuxElf64::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf::defineSymbols(ft);\n}\n\nPackLinuxElf32::PackLinuxElf32(InputFile *f)\n    : super(f), phdri(nullptr), shdri(nullptr),\n    gnu_stack(nullptr),\n    page_mask(~0u<<lg2_page),\n    dynseg(nullptr), hashtab(nullptr), hashend(nullptr),\n                     gashtab(nullptr), gashend(nullptr), dynsym(nullptr),\n    jni_onload_sym(nullptr),\n    sec_strndx(nullptr), sec_dynsym(nullptr), sec_dynstr(nullptr)\n    , symnum_end(0)\n{\n    memset(&ehdri, 0, sizeof(ehdri));\n    if (f) {\n        f->seek(0, SEEK_SET);\n        f->readx(&ehdri, sizeof(ehdri));\n    }\n}\n\nPackLinuxElf32::~PackLinuxElf32()\n{\n}\n\nPackLinuxElf64::PackLinuxElf64(InputFile *f)\n    : super(f), phdri(nullptr), shdri(nullptr),\n    gnu_stack(nullptr),\n    page_mask(~0ull<<lg2_page),\n    dynseg(nullptr), hashtab(nullptr), hashend(nullptr),\n                     gashtab(nullptr), gashend(nullptr), dynsym(nullptr),\n    jni_onload_sym(nullptr),\n    sec_strndx(nullptr), sec_dynsym(nullptr), sec_dynstr(nullptr)\n    , symnum_end(0)\n{\n    memset(&ehdri, 0, sizeof(ehdri));\n    if (f) {\n        f->seek(0, SEEK_SET);\n        f->readx(&ehdri, sizeof(ehdri));\n    }\n}\n\nPackLinuxElf64::~PackLinuxElf64()\n{\n}\n\n// FIXME: should be templated with PackLinuxElf32help1\nvoid\nPackLinuxElf64::PackLinuxElf64help1(InputFile *f)\n{\n    e_type  = get_te16(&ehdri.e_type);\n    e_phnum = get_te16(&ehdri.e_phnum);\n    e_shnum = get_te16(&ehdri.e_shnum);\n    unsigned const e_phentsize = get_te16(&ehdri.e_phentsize);\n    if (ehdri.e_ident[Elf64_Ehdr::EI_CLASS]!=Elf64_Ehdr::ELFCLASS64\n    || sizeof(Elf64_Phdr) != e_phentsize\n    || (Elf64_Ehdr::ELFDATA2MSB == ehdri.e_ident[Elf64_Ehdr::EI_DATA]\n            && &N_BELE_RTP::be_policy != bele)\n    || (Elf64_Ehdr::ELFDATA2LSB == ehdri.e_ident[Elf64_Ehdr::EI_DATA]\n            && &N_BELE_RTP::le_policy != bele)) {\n        e_phoff = 0;\n        e_shoff = 0;\n        sz_phdrs = 0;\n        return;\n    }\n    if (0==e_phnum) throwCantUnpack(\"0==e_phnum\");\n    e_phoff = get_te64(&ehdri.e_phoff);\n    upx_uint64_t const last_Phdr = e_phoff + e_phnum * sizeof(Elf64_Phdr);\n    if (last_Phdr < e_phoff  // wrap-around\n    ||  e_phoff != sizeof(Elf64_Ehdr)  // must be contiguous\n    ||  (unsigned long)file_size < last_Phdr) {\n        throwCantUnpack(\"bad e_phoff\");\n    }\n    e_shoff = get_te64(&ehdri.e_shoff);\n    upx_uint64_t const last_Shdr = e_shoff + e_shnum * sizeof(Elf64_Shdr);\n    if (last_Shdr < e_shoff  // wrap-around\n    ||  (e_shnum && e_shoff < last_Phdr)\n    ||  (unsigned long)file_size < last_Shdr) {\n        if (opt->cmd == CMD_COMPRESS) {\n            throwCantUnpack(\"bad e_shoff\");\n        }\n    }\n    sz_phdrs = e_phnum * e_phentsize;\n    sz_elf_hdrs = sz_phdrs + sizeof(Elf64_Ehdr);\n\n    if (f && Elf64_Ehdr::ET_DYN!=e_type) {\n        unsigned const len = sz_phdrs + e_phoff;\n        alloc_file_image(file_image, len);\n        f->seek(0, SEEK_SET);\n        f->readx(file_image, len);\n        phdri= (Elf64_Phdr       *)(e_phoff + file_image);  // do not free() !!\n    }\n    if (f && Elf64_Ehdr::ET_DYN==e_type) {\n        // The DT_SYMTAB has no designated length.  Read the whole file.\n        alloc_file_image(file_image, file_size);\n        f->seek(0, SEEK_SET);\n        f->readx(file_image, file_size);\n        phdri= (Elf64_Phdr *)(e_phoff + file_image);  // do not free() !!\n        shdri= (Elf64_Shdr *)(e_shoff + file_image);  // do not free() !!\n        if (opt->cmd != CMD_COMPRESS) {\n            shdri = nullptr;\n        }\n        sec_dynsym = elf_find_section_type(Elf64_Shdr::SHT_DYNSYM);\n        if (sec_dynsym) {\n            unsigned t = get_te32(&sec_dynsym->sh_link);\n            if (e_shnum <= t)\n                throwCantPack(\"bad dynsym->sh_link\");\n            sec_dynstr = &shdri[t];\n        }\n\n        Elf64_Phdr const *phdr= phdri;\n        for (int j = e_phnum; --j>=0; ++phdr)\n        if (Elf64_Phdr::PT_DYNAMIC==get_te32(&phdr->p_type)) {\n            upx_uint64_t offset = check_pt_dynamic(phdr);\n            dynseg= (Elf64_Dyn const *)(offset + file_image);\n            invert_pt_dynamic(dynseg,\n                umin(get_te64(&phdr->p_filesz), file_size - offset));\n        }\n        else if (PT_LOAD64==get_te32(&phdr->p_type)) {\n            check_pt_load(phdr);\n        }\n        // elf_find_dynamic() returns 0 if 0==dynseg.\n        dynstr =      (char const *)elf_find_dynamic(Elf64_Dyn::DT_STRTAB);\n        dynsym = (Elf64_Sym const *)elf_find_dynamic(Elf64_Dyn::DT_SYMTAB);\n        gashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_GNU_HASH);\n        hashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_HASH);\n        if (3& ((upx_uintptr_t)dynsym | (upx_uintptr_t)gashtab | (upx_uintptr_t)hashtab)) {\n            throwCantPack(\"unaligned DT_SYMTAB, DT_GNU_HASH, or DT_HASH/n\");\n        }\n        jni_onload_sym = elf_lookup(\"JNI_OnLoad\");\n        if (jni_onload_sym) {\n            jni_onload_va = get_te64(&jni_onload_sym->st_value);\n            jni_onload_va = 0;  // FIXME not understood; need example\n        }\n    }\n}\n\nLinker* PackLinuxElf64amd::newLinker() const\n{\n    return new ElfLinkerAMD64;\n}\n\nLinker* PackLinuxElf64arm::newLinker() const\n{\n    return new ElfLinkerArm64LE;\n}\n\nint const *\nPackLinuxElf::getCompressionMethods(int method, int level) const\n{\n    // No real dependency on LE32.\n    return Packer::getDefaultCompressionMethods_le32(method, level);\n}\n\nint const *\nPackLinuxElf32armLe::getCompressionMethods(int method, int level) const\n{\n    return Packer::getDefaultCompressionMethods_8(method, level);\n}\n\nint const *\nPackLinuxElf32armBe::getCompressionMethods(int method, int level) const\n{\n    return Packer::getDefaultCompressionMethods_8(method, level);\n}\n\nint const *\nPackLinuxElf32ppc::getFilters() const\n{\n    static const int filters[] = {\n        0xd0,\n    FT_END };\n    return filters;\n}\n\nint const *\nPackLinuxElf64ppcle::getFilters() const\n{\n    static const int filters[] = {\n        0xd0,\n    FT_END };\n    return filters;\n}\n\nint const *\nPackLinuxElf64ppc::getFilters() const\n{\n    static const int filters[] = {\n        0xd0,\n    FT_END };\n    return filters;\n}\n\nint const *\nPackLinuxElf64amd::getFilters() const\n{\n    static const int filters[] = {\n        0x49,\n    FT_END };\n    return filters;\n}\n\nint const *\nPackLinuxElf64arm::getFilters() const\n{\n    static const int filters[] = {\n        0x52,\n    FT_END };\n    return filters;\n}\n\nvoid PackLinuxElf32::patchLoader()\n{\n}\n\nvoid PackLinuxElf64::patchLoader()\n{\n}\n\nvoid PackLinuxElf32::ARM_updateLoader(OutputFile * /*fo*/)\n{\n    set_te32(&elfout.ehdr.e_entry, sz_pack2 +\n        linker->getSymbolOffset(\"_start\") +\n        get_te32(&elfout.phdr[C_TEXT].p_vaddr));\n}\n\nvoid PackLinuxElf32armLe::updateLoader(OutputFile *fo)\n{\n    ARM_updateLoader(fo);\n}\n\nvoid PackLinuxElf32armBe::updateLoader(OutputFile *fo)\n{\n    ARM_updateLoader(fo);\n}\n\nvoid PackLinuxElf32mipsel::updateLoader(OutputFile *fo)\n{\n    ARM_updateLoader(fo);  // not ARM specific; (no 32-bit immediates)\n}\n\nvoid PackLinuxElf32mipseb::updateLoader(OutputFile *fo)\n{\n    ARM_updateLoader(fo);  // not ARM specific; (no 32-bit immediates)\n}\n\nvoid PackLinuxElf32::updateLoader(OutputFile * /*fo*/)\n{\n    unsigned start = linker->getSymbolOffset(\"_start\");\n    unsigned vbase = get_te32(&elfout.phdr[C_TEXT].p_vaddr);\n    set_te32(&elfout.ehdr.e_entry, start + sz_pack2 + vbase);\n}\n\nvoid PackLinuxElf64::updateLoader(OutputFile * /*fo*/)\n{\n    if (xct_off) {\n        return;  // FIXME elfout has no values at all\n    }\n    upx_uint64_t const vbase = get_te64(&elfout.phdr[C_TEXT].p_vaddr);\n    unsigned start = linker->getSymbolOffset(\"_start\");\n\n    if (get_te16(&elfout.ehdr.e_machine)==Elf64_Ehdr::EM_PPC64\n    &&  elfout.ehdr.e_ident[Elf64_Ehdr::EI_DATA]==Elf64_Ehdr::ELFDATA2MSB) {\n        unsigned descr = linker->getSymbolOffset(\"entry_descr\");\n\n        // External relocation of PPC64 function descriptor.\n        upx_uint64_t dot_entry = start + sz_pack2 + vbase;\n        upx_byte *p = getLoader();\n\n        set_te64(&p[descr], dot_entry);\n        set_te64(&elfout.ehdr.e_entry, descr + sz_pack2 + vbase);\n    }\n    else {\n        set_te64(&elfout.ehdr.e_entry, start + sz_pack2 + vbase);\n    }\n}\n\nPackLinuxElf32ppc::PackLinuxElf32ppc(InputFile *f)\n    : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_PPC;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2MSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf32ppc::~PackLinuxElf32ppc()\n{\n}\n\nLinker* PackLinuxElf32ppc::newLinker() const\n{\n    return new ElfLinkerPpc32;\n}\n\nPackLinuxElf64ppcle::PackLinuxElf64ppcle(InputFile *f)\n    : super(f), lg2_page(16), page_size(1u<<lg2_page)\n{\n    e_machine = Elf64_Ehdr::EM_PPC64;\n    ei_class  = Elf64_Ehdr::ELFCLASS64;\n    ei_data   = Elf64_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf64_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf64ppc::PackLinuxElf64ppc(InputFile *f)\n    : super(f), lg2_page(16), page_size(1u<<lg2_page)\n{\n    e_machine = Elf64_Ehdr::EM_PPC64;\n    ei_class  = Elf64_Ehdr::ELFCLASS64;\n    ei_data   = Elf64_Ehdr::ELFDATA2MSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf64ppcle::~PackLinuxElf64ppcle()\n{\n}\n\nPackLinuxElf64ppc::~PackLinuxElf64ppc()\n{\n}\n\nLinker* PackLinuxElf64ppcle::newLinker() const\n{\n    return new ElfLinkerPpc64le;\n}\n\nLinker* PackLinuxElf64ppc::newLinker() const\n{\n    return new ElfLinkerPpc64;\n}\n\nPackLinuxElf64amd::PackLinuxElf64amd(InputFile *f)\n    : super(f)\n{\n    // Why did PackLinuxElf64Le set lg2_page = 16 ?\n    // It causes trouble for check_pt_dynamic() from canPack().\n    lg2_page = 12;  page_size = 1u<<lg2_page;\n    e_machine = Elf64_Ehdr::EM_X86_64;\n    ei_class = Elf64_Ehdr::ELFCLASS64;\n    ei_data = Elf64_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf64arm::PackLinuxElf64arm(InputFile *f)\n    : super(f)\n{\n    e_machine = Elf64_Ehdr::EM_AARCH64;\n    ei_class = Elf64_Ehdr::ELFCLASS64;\n    ei_data = Elf64_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf64amd::~PackLinuxElf64amd()\n{\n}\n\nPackLinuxElf64arm::~PackLinuxElf64arm()\n{\n}\n\nstatic unsigned\numax(unsigned a, unsigned b)\n{\n    if (a <= b) {\n        return b;\n    }\n    return a;\n}\n\nvoid PackLinuxElf32x86::addStubEntrySections(Filter const *ft)\n{\n    int const n_mru = ft->n_mru;  // FIXME: belongs to filter? packerf?\n\n// Rely on \"+80CXXXX\" [etc] in getDecompressorSections() packer_c.cpp */\n//    // Here is a quick summary of the format of the output file:\n//    linker->setLoaderAlignOffset(\n//            // Elf32_Ehdr\n//        sizeof(elfout.ehdr) +\n//            // Elf32_Phdr: 1 for exec86, 2 for sh86, 3 for elf86\n//        (get_te16(&elfout.ehdr.e_phentsize) * get_te16(&elfout.ehdr.e_phnum)) +\n//            // checksum UPX! lsize version format\n//        sizeof(l_info) +\n//            // PT_DYNAMIC with DT_NEEDED \"forwarded\" from original file\n//        ((get_te16(&elfout.ehdr.e_phnum)==3)\n//            ? (unsigned) get_te32(&elfout.phdr[C_NOTE].p_memsz)\n//            : 0) +\n//            // p_progid, p_filesize, p_blocksize\n//        sizeof(p_info) +\n//            // compressed data\n//        b_len + ph.c_len );\n\n            // entry to stub\n    addLoader(\"LEXEC000\", nullptr);\n\n    if (ft->id) {\n        { // decompr, unfilter are separate\n            addLoader(\"LXUNF000\", nullptr);\n            addLoader(\"LXUNF002\", nullptr);\n                if (0x80==(ft->id & 0xF0)) {\n                    if (256==n_mru) {\n                        addLoader(\"MRUBYTE0\", nullptr);\n                    }\n                    else if (n_mru) {\n                        addLoader(\"LXMRU005\", nullptr);\n                    }\n                    if (n_mru) {\n                        addLoader(\"LXMRU006\", nullptr);\n                    }\n                    else {\n                        addLoader(\"LXMRU007\", nullptr);\n                    }\n            }\n            else if (0x40==(ft->id & 0xF0)) {\n                addLoader(\"LXUNF008\", nullptr);\n            }\n            addLoader(\"LXUNF010\", nullptr);\n        }\n        if (n_mru) {\n            addLoader(\"LEXEC009\", nullptr);\n        }\n    }\n    addLoader(\"LEXEC010\", nullptr);\n    addLoader(getDecompressorSections(), nullptr);\n    addLoader(\"LEXEC015\", nullptr);\n    if (ft->id) {\n        {  // decompr, unfilter are separate\n            if (0x80!=(ft->id & 0xF0)) {\n                addLoader(\"LXUNF042\", nullptr);\n            }\n        }\n        addFilter32(ft->id);\n        { // decompr, unfilter are separate\n            if (0x80==(ft->id & 0xF0)) {\n                if (0==n_mru) {\n                    addLoader(\"LXMRU058\", nullptr);\n                }\n            }\n            addLoader(\"LXUNF035\", nullptr);\n        }\n    }\n    else {\n        addLoader(\"LEXEC017\", nullptr);\n    }\n\n    addLoader(\"IDENTSTR\", nullptr);\n    addLoader(\"LEXEC020\", nullptr);\n    addLoader(\"FOLDEXEC\", nullptr);\n}\n\nvoid PackLinuxElf32x86::defineSymbols(Filter const *const ft)\n{\n    PackLinuxElf32::defineSymbols(ft);\n\n    if (0x80==(ft->id & 0xF0)) {\n        int const mru = ft->n_mru ? 1+ ft->n_mru : 0;\n        if (mru && mru!=256) {\n            unsigned const is_pwr2 = (0==((mru -1) & mru));\n            linker->defineSymbol(\"NMRU\", mru - is_pwr2);\n        }\n    }\n}\n\nvoid\nPackLinuxElf32::buildLinuxLoader(\n    upx_byte const *const proto,\n    unsigned        const szproto,\n    upx_byte const *const fold,\n    unsigned        const szfold,\n    Filter const *ft\n)\n{\n    initLoader(proto, szproto);\n\n  if (0 < szfold) {\n    struct b_info h; memset(&h, 0, sizeof(h));\n    unsigned fold_hdrlen = 0;\n    cprElfHdr1 const *const hf = (cprElfHdr1 const *)fold;\n    fold_hdrlen = umax(0x80, usizeof(hf->ehdr) +\n        get_te16(&hf->ehdr.e_phentsize) * get_te16(&hf->ehdr.e_phnum) +\n            sizeof(l_info) );\n    h.sz_unc = ((szfold < fold_hdrlen) ? 0 : (szfold - fold_hdrlen));\n    h.b_method = (unsigned char) ph.method;\n    h.b_ftid = (unsigned char) ph.filter;\n    h.b_cto8 = (unsigned char) ph.filter_cto;\n    unsigned char const *const uncLoader = fold_hdrlen + fold;\n\n    MemBuffer mb_cprLoader;\n    mb_cprLoader.allocForCompression(h.sz_unc + (0==h.sz_unc));\n    h.sz_cpr = mb_cprLoader.getSize();\n    unsigned char *const cprLoader = (unsigned char *)mb_cprLoader;\n    {\n    unsigned h_sz_cpr = h.sz_cpr;\n    int r = upx_compress(uncLoader, h.sz_unc, sizeof(h) + cprLoader, &h_sz_cpr,\n        nullptr, ph.method, 10, nullptr, nullptr );\n    h.sz_cpr = h_sz_cpr;\n    if (r != UPX_E_OK || h.sz_cpr >= h.sz_unc)\n        throwInternalError(\"loader compression failed\");\n    }\n#if 0  //{  debugging only\n    if (M_IS_LZMA(ph.method)) {\n        ucl_uint tmp_len = h.sz_unc;  // LZMA uses this as EOF\n        MemBuffer mb_tmp(tmp_len);\n        unsigned char *tmp = (unsigned char *)mb_tmp;\n        memset(tmp, 0, tmp_len);\n        int r = upx_decompress(sizeof(h) + cprLoader, h.sz_cpr, tmp, &tmp_len, h.b_method, nullptr);\n        if (r == UPX_E_OUT_OF_MEMORY)\n            throwOutOfMemoryException();\n        printf(\"\\n%d %d: %d %d %d\\n\", h.b_method, r, h.sz_cpr, h.sz_unc, tmp_len);\n        for (unsigned j=0; j < h.sz_unc; ++j) if (tmp[j]!=uncLoader[j]) {\n            printf(\"%d: %x %x\\n\", j, tmp[j], uncLoader[j]);\n        }\n    }\n#endif  //}\n    unsigned const sz_cpr = h.sz_cpr;\n    set_te32(&h.sz_cpr, h.sz_cpr);\n    set_te32(&h.sz_unc, h.sz_unc);\n    memcpy(cprLoader, &h, sizeof(h));\n\n    // This adds the definition to the \"library\", to be used later.\n    linker->addSection(\"FOLDEXEC\", cprLoader, sizeof(h) + sz_cpr, 0);\n  }\n  else {\n    linker->addSection(\"FOLDEXEC\", \"\", 0, 0);\n  }\n\n    addStubEntrySections(ft);\n\n    if (0==xct_off)\n        defineSymbols(ft);  // main program only, not for shared lib\n    relocateLoader();\n}\n\nvoid\nPackLinuxElf64::buildLinuxLoader(\n    upx_byte const *const proto,\n    unsigned        const szproto,\n    upx_byte const *const fold,\n    unsigned        const szfold,\n    Filter const *ft\n)\n{\n    initLoader(proto, szproto);\n\n  if (0 < szfold) {\n    struct b_info h; memset(&h, 0, sizeof(h));\n    unsigned fold_hdrlen = 0;\n    cprElfHdr1 const *const hf = (cprElfHdr1 const *)fold;\n    fold_hdrlen = umax(0x80, usizeof(hf->ehdr) +\n        get_te16(&hf->ehdr.e_phentsize) * get_te16(&hf->ehdr.e_phnum) +\n            sizeof(l_info) );\n    h.sz_unc = ((szfold < fold_hdrlen) ? 0 : (szfold - fold_hdrlen));\n    h.b_method = (unsigned char) ph.method;\n    h.b_ftid = (unsigned char) ph.filter;\n    h.b_cto8 = (unsigned char) ph.filter_cto;\n    unsigned char const *const uncLoader = fold_hdrlen + fold;\n\n    MemBuffer mb_cprLoader;\n    mb_cprLoader.allocForCompression(h.sz_unc + (0==h.sz_unc));\n    h.sz_cpr = mb_cprLoader.getSize();\n    unsigned char *const cprLoader = (unsigned char *)mb_cprLoader;\n    {\n    unsigned h_sz_cpr = h.sz_cpr;\n    int r = upx_compress(uncLoader, h.sz_unc, sizeof(h) + cprLoader, &h_sz_cpr,\n        nullptr, forced_method(ph.method), 10, nullptr, nullptr );\n    h.sz_cpr = h_sz_cpr;\n    if (r != UPX_E_OK || h.sz_cpr >= h.sz_unc)\n        throwInternalError(\"loader compression failed\");\n    }\n#if 0  //{  debugging only\n    if (M_IS_LZMA(ph.method)) {\n        ucl_uint tmp_len = h.sz_unc;  // LZMA uses this as EOF\n        MemBuffer mb_tmp(tmp_len);\n        unsigned char *tmp = (unsigned char *)mb_tmp;\n        memset(tmp, 0, tmp_len);\n        int r = upx_decompress(sizeof(h) + cprLoader, h.sz_cpr, tmp, &tmp_len, h.b_method, nullptr);\n        if (r == UPX_E_OUT_OF_MEMORY)\n            throwOutOfMemoryException();\n        printf(\"\\n%d %d: %d %d %d\\n\", h.b_method, r, h.sz_cpr, h.sz_unc, tmp_len);\n        for (unsigned j=0; j < h.sz_unc; ++j) if (tmp[j]!=uncLoader[j]) {\n            printf(\"%d: %x %x\\n\", j, tmp[j], uncLoader[j]);\n        }\n    }\n#endif  //}\n    unsigned const sz_cpr = h.sz_cpr;\n    set_te32(&h.sz_cpr, h.sz_cpr);\n    set_te32(&h.sz_unc, h.sz_unc);\n    memcpy(cprLoader, &h, sizeof(h));\n\n    // This adds the definition to the \"library\", to be used later.\n    linker->addSection(\"FOLDEXEC\", cprLoader, sizeof(h) + sz_cpr, 0);\n  }\n  else {\n    linker->addSection(\"FOLDEXEC\", \"\", 0, 0);\n  }\n\n    addStubEntrySections(ft);\n\n    if (0==xct_off)\n        defineSymbols(ft);  // main program only, not for shared lib\n    relocateLoader();\n}\n\nvoid\nPackLinuxElf64amd::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf64::defineSymbols(ft);\n}\n\nstatic const\n#include \"stub/i386-linux.elf-entry.h\"\nstatic const\n#include \"stub/i386-linux.elf-fold.h\"\nstatic const\n#include \"stub/i386-linux.shlib-init.h\"\n\nvoid\nPackLinuxElf32x86::buildLoader(const Filter *ft)\n{\n    if (0!=xct_off) {  // shared library\n        buildLinuxLoader(\n            stub_i386_linux_shlib_init, sizeof(stub_i386_linux_shlib_init),\n            nullptr,                       0,                                ft );\n        return;\n    }\n    unsigned char tmp[sizeof(stub_i386_linux_elf_fold)];\n    memcpy(tmp, stub_i386_linux_elf_fold, sizeof(stub_i386_linux_elf_fold));\n    checkPatch(nullptr, 0, 0, 0);  // reset\n    if (opt->o_unix.is_ptinterp) {\n        unsigned j;\n        for (j = 0; j < sizeof(stub_i386_linux_elf_fold)-1; ++j) {\n            if (0x60==tmp[  j]\n            &&  0x47==tmp[1+j] ) {\n                /* put INC EDI before PUSHA: inhibits auxv_up for PT_INTERP */\n                tmp[  j] = 0x47;\n                tmp[1+j] = 0x60;\n                break;\n            }\n        }\n    }\n    buildLinuxLoader(\n        stub_i386_linux_elf_entry, sizeof(stub_i386_linux_elf_entry),\n        tmp,                       sizeof(stub_i386_linux_elf_fold),  ft );\n}\n\nstatic const\n#include \"stub/i386-bsd.elf-entry.h\"\nstatic const\n#include \"stub/i386-bsd.elf-fold.h\"\n\nvoid\nPackBSDElf32x86::buildLoader(const Filter *ft)\n{\n    unsigned char tmp[sizeof(stub_i386_bsd_elf_fold)];\n    memcpy(tmp, stub_i386_bsd_elf_fold, sizeof(stub_i386_bsd_elf_fold));\n    checkPatch(nullptr, 0, 0, 0);  // reset\n    if (opt->o_unix.is_ptinterp) {\n        unsigned j;\n        for (j = 0; j < sizeof(stub_i386_bsd_elf_fold)-1; ++j) {\n            if (0x60==tmp[  j]\n            &&  0x47==tmp[1+j] ) {\n                /* put INC EDI before PUSHA: inhibits auxv_up for PT_INTERP */\n                tmp[  j] = 0x47;\n                tmp[1+j] = 0x60;\n                break;\n            }\n        }\n    }\n    buildLinuxLoader(\n        stub_i386_bsd_elf_entry, sizeof(stub_i386_bsd_elf_entry),\n        tmp,                     sizeof(stub_i386_bsd_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/i386-netbsd.elf-entry.h\"\n\nstatic const\n#include \"stub/i386-netbsd.elf-fold.h\"\n\n#define WANT_NHDR_ENUM\n#include \"p_elf_enum.h\"\n\nvoid\nPackNetBSDElf32x86::buildLoader(const Filter *ft)\n{\n    unsigned char tmp[sizeof(stub_i386_netbsd_elf_fold)];\n    memcpy(tmp, stub_i386_netbsd_elf_fold, sizeof(stub_i386_netbsd_elf_fold));\n    checkPatch(nullptr, 0, 0, 0);  // reset\n    if (opt->o_unix.is_ptinterp) {\n        unsigned j;\n        for (j = 0; j < sizeof(stub_i386_netbsd_elf_fold)-1; ++j) {\n            if (0x60==tmp[  j]\n            &&  0x47==tmp[1+j] ) {\n                /* put INC EDI before PUSHA: inhibits auxv_up for PT_INTERP */\n                tmp[  j] = 0x47;\n                tmp[1+j] = 0x60;\n                break;\n            }\n        }\n    }\n    buildLinuxLoader(\n        stub_i386_netbsd_elf_entry, sizeof(stub_i386_netbsd_elf_entry),\n        tmp,                        sizeof(stub_i386_netbsd_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/i386-openbsd.elf-fold.h\"\n\nvoid\nPackOpenBSDElf32x86::buildLoader(const Filter *ft)\n{\n    unsigned char tmp[sizeof(stub_i386_openbsd_elf_fold)];\n    memcpy(tmp, stub_i386_openbsd_elf_fold, sizeof(stub_i386_openbsd_elf_fold));\n    checkPatch(nullptr, 0, 0, 0);  // reset\n    if (opt->o_unix.is_ptinterp) {\n        unsigned j;\n        for (j = 0; j < sizeof(stub_i386_openbsd_elf_fold)-1; ++j) {\n            if (0x60==tmp[  j]\n            &&  0x47==tmp[1+j] ) {\n                /* put INC EDI before PUSHA: inhibits auxv_up for PT_INTERP */\n                tmp[  j] = 0x47;\n                tmp[1+j] = 0x60;\n                break;\n            }\n        }\n    }\n    buildLinuxLoader(\n        stub_i386_bsd_elf_entry, sizeof(stub_i386_bsd_elf_entry),\n        tmp,                     sizeof(stub_i386_openbsd_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/arm.v5a-linux.elf-entry.h\"\nstatic const\n#include \"stub/arm.v5a-linux.elf-fold.h\"\nstatic const\n#include \"stub/arm.v5t-linux.shlib-init.h\"\n\nstatic const\n#include \"stub/arm.v4a-linux.elf-entry.h\"\nstatic const\n#include \"stub/arm.v4a-linux.elf-fold.h\"\n#if 0\nstatic const\n#include \"stub/arm.v4a-linux.shlib-init.h\"\n#endif\n\nstatic const\n#include \"stub/armeb.v4a-linux.elf-entry.h\"\nstatic const\n#include \"stub/armeb.v4a-linux.elf-fold.h\"\n\nvoid\nPackLinuxElf32armBe::buildLoader(Filter const *ft)\n{\n    buildLinuxLoader(\n        stub_armeb_v4a_linux_elf_entry, sizeof(stub_armeb_v4a_linux_elf_entry),\n        stub_armeb_v4a_linux_elf_fold,  sizeof(stub_armeb_v4a_linux_elf_fold), ft);\n}\n\nvoid\nPackLinuxElf32armLe::buildLoader(Filter const *ft)\n{\n    if (Elf32_Ehdr::ELFOSABI_LINUX==ei_osabi) {\n\n        if (0!=xct_off) {  // shared library\n            buildLinuxLoader(\n                stub_arm_v5t_linux_shlib_init, sizeof(stub_arm_v5t_linux_shlib_init),\n                nullptr,                      0,                                ft );\n            return;\n        }\n        buildLinuxLoader(\n            stub_arm_v5a_linux_elf_entry, sizeof(stub_arm_v5a_linux_elf_entry),\n            stub_arm_v5a_linux_elf_fold,  sizeof(stub_arm_v5a_linux_elf_fold), ft);\n    }\n    else {\n        buildLinuxLoader(\n            stub_arm_v4a_linux_elf_entry, sizeof(stub_arm_v4a_linux_elf_entry),\n            stub_arm_v4a_linux_elf_fold,  sizeof(stub_arm_v4a_linux_elf_fold), ft);\n    }\n}\n\nstatic const\n#include \"stub/mipsel.r3000-linux.elf-entry.h\"\nstatic const\n#include \"stub/mipsel.r3000-linux.elf-fold.h\"\nstatic const\n#include \"stub/mipsel.r3000-linux.shlib-init.h\"\n\nvoid\nPackLinuxElf32mipsel::buildLoader(Filter const *ft)\n{\n    if (0!=xct_off) {  // shared library\n        buildLinuxLoader(\n            stub_mipsel_r3000_linux_shlib_init, sizeof(stub_mipsel_r3000_linux_shlib_init),\n            nullptr,                        0,                                 ft );\n        return;\n    }\n    buildLinuxLoader(\n        stub_mipsel_r3000_linux_elf_entry, sizeof(stub_mipsel_r3000_linux_elf_entry),\n        stub_mipsel_r3000_linux_elf_fold,  sizeof(stub_mipsel_r3000_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/mips.r3000-linux.elf-entry.h\"\nstatic const\n#include \"stub/mips.r3000-linux.elf-fold.h\"\nstatic const\n#include \"stub/mips.r3000-linux.shlib-init.h\"\n\nvoid\nPackLinuxElf32mipseb::buildLoader(Filter const *ft)\n{\n    if (0!=xct_off) {  // shared library\n        buildLinuxLoader(\n            stub_mips_r3000_linux_shlib_init, sizeof(stub_mips_r3000_linux_shlib_init),\n            nullptr,                        0,                                 ft );\n        return;\n    }\n    buildLinuxLoader(\n        stub_mips_r3000_linux_elf_entry, sizeof(stub_mips_r3000_linux_elf_entry),\n        stub_mips_r3000_linux_elf_fold,  sizeof(stub_mips_r3000_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/powerpc-linux.elf-entry.h\"\nstatic const\n#include \"stub/powerpc-linux.elf-fold.h\"\n\nvoid\nPackLinuxElf32ppc::buildLoader(const Filter *ft)\n{\n    buildLinuxLoader(\n        stub_powerpc_linux_elf_entry, sizeof(stub_powerpc_linux_elf_entry),\n        stub_powerpc_linux_elf_fold,  sizeof(stub_powerpc_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/powerpc64le-linux.elf-entry.h\"\nstatic const\n#include \"stub/powerpc64le-linux.elf-fold.h\"\n\nvoid\nPackLinuxElf64ppcle::buildLoader(const Filter *ft)\n{\n    buildLinuxLoader(\n        stub_powerpc64le_linux_elf_entry, sizeof(stub_powerpc64le_linux_elf_entry),\n        stub_powerpc64le_linux_elf_fold,  sizeof(stub_powerpc64le_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/powerpc64-linux.elf-entry.h\"\nstatic const\n#include \"stub/powerpc64-linux.elf-fold.h\"\n\nvoid\nPackLinuxElf64ppc::buildLoader(const Filter *ft)\n{\n    buildLinuxLoader(\n        stub_powerpc64_linux_elf_entry, sizeof(stub_powerpc64_linux_elf_entry),\n        stub_powerpc64_linux_elf_fold,  sizeof(stub_powerpc64_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/amd64-linux.elf-entry.h\"\nstatic const\n#include \"stub/amd64-linux.elf-fold.h\"\nstatic const\n#include \"stub/amd64-linux.shlib-init.h\"\n\nvoid\nPackLinuxElf64amd::buildLoader(const Filter *ft)\n{\n    if (0!=xct_off) {  // shared library\n        buildLinuxLoader(\n            stub_amd64_linux_shlib_init, sizeof(stub_amd64_linux_shlib_init),\n            nullptr,                        0,                                 ft );\n        return;\n    }\n    buildLinuxLoader(\n        stub_amd64_linux_elf_entry, sizeof(stub_amd64_linux_elf_entry),\n        stub_amd64_linux_elf_fold,  sizeof(stub_amd64_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/arm64-linux.elf-entry.h\"\nstatic const\n#include \"stub/arm64-linux.elf-fold.h\"\nstatic const\n#include \"stub/arm64-linux.shlib-init.h\"\n\nvoid\nPackLinuxElf64arm::buildLoader(const Filter *ft)\n{\n    if (0!=xct_off) {  // shared library\n        buildLinuxLoader(\n            stub_arm64_linux_shlib_init, sizeof(stub_arm64_linux_shlib_init),\n            nullptr,                        0,                                 ft );\n        return;\n    }\n    buildLinuxLoader(\n        stub_arm64_linux_elf_entry, sizeof(stub_arm64_linux_elf_entry),\n        stub_arm64_linux_elf_fold,  sizeof(stub_arm64_linux_elf_fold), ft);\n}\n\nvoid\nPackLinuxElf32::invert_pt_dynamic(Elf32_Dyn const *dynp, unsigned headway)\n{\n    if (dt_table[Elf32_Dyn::DT_NULL]) {\n        return;  // not 1st time; do not change upx_dt_init\n    }\n    Elf32_Dyn const *const dynp0 = dynp;\n    unsigned ndx = 0;\n    unsigned const limit = headway / sizeof(*dynp);\n    if (dynp)\n    for (; ; ++ndx, ++dynp) {\n        if (limit <= ndx) {\n            throwCantPack(\"DT_NULL not found\");\n        }\n        unsigned const d_tag = get_te32(&dynp->d_tag);\n        if (d_tag < DT_NUM) {\n            if (Elf32_Dyn::DT_NEEDED != d_tag\n            &&  dt_table[d_tag]\n            &&    get_te32(&dynp->d_val)\n               != get_te32(&dynp0[-1+ dt_table[d_tag]].d_val)) {\n                char msg[50]; snprintf(msg, sizeof(msg),\n                    \"duplicate DT_%#x: [%#x] [%#x]\",\n                    d_tag, -1+ dt_table[d_tag], ndx);\n                throwCantPack(msg);\n            }\n            dt_table[d_tag] = 1+ ndx;\n        }\n        if (Elf32_Dyn::DT_NULL == d_tag) {\n            break;  // check here so that dt_table[DT_NULL] is set\n        }\n    }\n    upx_dt_init = 0;\n         if (dt_table[Elf32_Dyn::DT_INIT])          upx_dt_init = Elf32_Dyn::DT_INIT;\n    else if (dt_table[Elf32_Dyn::DT_PREINIT_ARRAY]) upx_dt_init = Elf32_Dyn::DT_PREINIT_ARRAY;\n    else if (dt_table[Elf32_Dyn::DT_INIT_ARRAY])    upx_dt_init = Elf32_Dyn::DT_INIT_ARRAY;\n\n    unsigned const z_str = dt_table[Elf32_Dyn::DT_STRSZ];\n    strtab_end = !z_str ? 0 : get_te64(&dynp0[-1+ z_str].d_val);\n    if (!z_str || (u64_t)file_size <= strtab_end) { // FIXME: weak\n        char msg[50]; snprintf(msg, sizeof(msg),\n            \"bad DT_STRSZ %#x\", strtab_end);\n        throwCantPack(msg);\n    }\n    unsigned const x_sym = dt_table[Elf32_Dyn::DT_SYMTAB];\n    unsigned const x_str = dt_table[Elf32_Dyn::DT_STRTAB];\n    if (x_sym && x_str) {\n        upx_uint32_t const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        upx_uint32_t const v_str = get_te32(&dynp0[-1+ x_str].d_val);\n        unsigned const  z_sym = dt_table[Elf32_Dyn::DT_SYMENT];\n        unsigned const sz_sym = !z_sym ? sizeof(Elf32_Sym)\n            : get_te32(&dynp0[-1+ z_sym].d_val);\n        if (sz_sym < sizeof(Elf32_Sym)) {\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_SYMENT %x\", sz_sym);\n            throwCantPack(msg);\n        }\n        if (v_sym < v_str) {\n            symnum_end = (v_str - v_sym) / sz_sym;\n        }\n        if (symnum_end < 1) {\n            throwCantPack(\"bad DT_SYMTAB\");\n        }\n    }\n    // DT_HASH often ends at DT_SYMTAB\n    // FIXME: sort DT_HASH, DT_GNU_HASH, STRTAB, SYMTAB, REL, RELA, JMPREL\n    // to partition the space.\n    unsigned const v_hsh = elf_unsigned_dynamic(Elf32_Dyn::DT_HASH);\n    if (v_hsh && file_image) {\n        hashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_HASH);\n        if (!hashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_HASH %#x\", v_hsh);\n            throwCantPack(msg);\n        }\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket]; (void)chains;\n\n        unsigned const v_sym = !x_sym ? 0 : get_te32(&dynp0[-1+ x_sym].d_val);\n        if ((unsigned)file_size <= nbucket/sizeof(*buckets)  // FIXME: weak\n        || !v_sym || (unsigned)file_size <= v_sym\n        || ((v_hsh < v_sym) && (v_sym - v_hsh) < sizeof(*buckets)*(2+ nbucket))\n        ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n        unsigned chmax = 0;\n        for (unsigned j= 0; j < nbucket; ++j) {\n            unsigned x = get_te32(&buckets[j]);\n            if (chmax < x) {\n                chmax = x;\n            }\n        }\n        if ((v_hsh < v_sym) && (v_sym - v_hsh) <\n                (sizeof(*buckets)*(2+ nbucket) + sizeof(*chains)*(1+ chmax))) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n    }\n    // DT_GNU_HASH often ends at DT_SYMTAB;  FIXME: not for Android?\n    unsigned const v_gsh = elf_unsigned_dynamic(Elf32_Dyn::DT_GNU_HASH);\n    if (v_gsh && file_image) {\n        gashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_GNU_HASH);\n        if (!gashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_GNU_HASH %#x\", v_gsh);\n            throwCantPack(msg);\n        }\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        unsigned const *const bitmask = (unsigned const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket]; (void)hasharr;\n        if (!n_bucket || (1u<<31) <= n_bucket  /* fie on fuzzers */\n        || (void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        //unsigned const *const gashend = &hasharr[n_bucket];  // minimum, except:\n        // Rust and Android trim unused zeroes from high end of hasharr[]\n        unsigned bmax = 0;\n        for (unsigned j= 0; j < n_bucket; ++j) {\n            unsigned bj = get_te32(&buckets[j]);\n            if (bj) {\n                if (bj < symbias) {\n                    char msg[90]; snprintf(msg, sizeof(msg),\n                            \"bad DT_GNU_HASH bucket[%d] < symbias{%#x}\\n\",\n                            bj, symbias);\n                    throwCantPack(msg);\n                }\n                if (bmax < bj) {\n                    bmax = bj;\n                }\n            }\n        }\n        if (1==n_bucket  && 0==buckets[0]\n        &&  1==n_bitmask && 0==bitmask[0]) {\n            // 2021-09-11 Rust on RaspberryPi apparently uses this to minimize space.\n            // But then the DT_GNU_HASH symbol lookup algorithm always fails?\n            // https://github.com/upx/upx/issues/525\n        } else\n        if ((1+ bmax) < symbias) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                    \"bad DT_GNU_HASH (1+ max_bucket)=%#x < symbias=%#x\", 1+ bmax, symbias);\n            throwCantPack(msg);\n        }\n        bmax -= symbias;\n\n        unsigned const v_sym = !x_sym ? 0 : get_te32(&dynp0[-1+ x_sym].d_val);\n        unsigned r = 0;\n        if (!n_bucket || !n_bitmask || !v_sym\n        || (r=1, ((-1+ n_bitmask) & n_bitmask))  // not a power of 2\n        || (r=2, (8*sizeof(unsigned) <= gnu_shift))  // shifted result always == 0\n        || (r=3, (n_bucket>>30))  // fie on fuzzers\n        || (r=4, (n_bitmask>>30))\n        || (r=5, ((file_size/sizeof(unsigned))\n                <= ((sizeof(*bitmask)/sizeof(unsigned))*n_bitmask + 2*n_bucket)))  // FIXME: weak\n        || (r=6, ((v_gsh < v_sym) && (v_sym - v_gsh) < (sizeof(unsigned)*4  // headers\n                + sizeof(*bitmask)*n_bitmask  // bitmask\n                + sizeof(*buckets)*n_bucket  // buckets\n                + sizeof(*hasharr)*(1+ bmax)  // hasharr\n            )) )\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_GNU_HASH n_bucket=%#x  n_bitmask=%#x  len=%#lx  r=%d\",\n                n_bucket, n_bitmask, (long unsigned)(v_sym - v_gsh), r);\n            throwCantPack(msg);\n        }\n    }\n    unsigned const e_shstrndx = get_te16(&ehdri.e_shstrndx);\n    if (e_shnum <= e_shstrndx\n    &&  !(0==e_shnum && 0==e_shstrndx) ) {\n        char msg[40]; snprintf(msg, sizeof(msg),\n            \"bad .e_shstrndx %d >= .e_shnum %d\", e_shstrndx, e_shnum);\n        throwCantPack(msg);\n    }\n}\n\nElf32_Phdr const *\nPackLinuxElf32::elf_find_ptype(unsigned type, Elf32_Phdr const *phdr, unsigned phnum)\n{\n    for (unsigned j = 0; j < phnum; ++j, ++phdr) {\n        if (type == get_te32(&phdr->p_type)) {\n            return phdr;\n        }\n    }\n    return nullptr;\n}\n\nElf64_Phdr const *\nPackLinuxElf64::elf_find_ptype(unsigned type, Elf64_Phdr const *phdr, unsigned phnum)\n{\n    for (unsigned j = 0; j < phnum; ++j, ++phdr) {\n        if (type == get_te32(&phdr->p_type)) {\n            return phdr;\n        }\n    }\n    return nullptr;\n}\n\nElf32_Shdr const *PackLinuxElf32::elf_find_section_name(\n    char const *const name\n) const\n{\n    Elf32_Shdr const *shdr = shdri;\n    if (!shdr) {\n        return nullptr;\n    }\n    int j = e_shnum;\n    for (; 0 <=--j; ++shdr) {\n        unsigned const sh_name = get_te32(&shdr->sh_name);\n        if ((u32_t)file_size <= sh_name) {  // FIXME: weak\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad Elf32_Shdr[%d].sh_name %#x\",\n                -1+ e_shnum -j, sh_name);\n            throwCantPack(msg);\n        }\n        if (0==strcmp(name, &shstrtab[sh_name])) {\n            return shdr;\n        }\n    }\n    return nullptr;\n}\n\nElf64_Shdr const *PackLinuxElf64::elf_find_section_name(\n    char const *const name\n) const\n{\n    Elf64_Shdr const *shdr = shdri;\n    if (!shdr) {\n        return nullptr;\n    }\n    int j = e_shnum;\n    for (; 0 <=--j; ++shdr) {\n        unsigned const sh_name = get_te32(&shdr->sh_name);\n        if ((u32_t)file_size <= sh_name) {  // FIXME: weak\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad Elf64_Shdr[%d].sh_name %#x\",\n                -1+ e_shnum -j, sh_name);\n            throwCantPack(msg);\n        }\n        if (0==strcmp(name, &shstrtab[sh_name])) {\n            return shdr;\n        }\n    }\n    return nullptr;\n}\n\nElf32_Shdr const *PackLinuxElf32::elf_find_section_type(\n    unsigned const type\n) const\n{\n    Elf32_Shdr const *shdr = shdri;\n    if (!shdr) {\n        return nullptr;\n    }\n    int j = e_shnum;\n    for (; 0 <=--j; ++shdr) {\n        if (type==get_te32(&shdr->sh_type)) {\n            return shdr;\n        }\n    }\n    return nullptr;\n}\n\nElf64_Shdr const *PackLinuxElf64::elf_find_section_type(\n    unsigned const type\n) const\n{\n    Elf64_Shdr const *shdr = shdri;\n    if (!shdr) {\n        return nullptr;\n    }\n    int j = e_shnum;\n    for (; 0 <=--j; ++shdr) {\n        if (type==get_te32(&shdr->sh_type)) {\n            return shdr;\n        }\n    }\n    return nullptr;\n}\n\nchar const *PackLinuxElf64::get_str_name(unsigned st_name, unsigned symnum) const\n{\n    if (strtab_end <= st_name) {\n        char msg[70]; snprintf(msg, sizeof(msg),\n            \"bad .st_name %#x in DT_SYMTAB[%d]\", st_name, symnum);\n        throwCantPack(msg);\n    }\n    return &dynstr[st_name];\n}\n\nchar const *PackLinuxElf64::get_dynsym_name(unsigned symnum, unsigned relnum) const\n{\n    if (symnum_end <= symnum) {\n        char msg[70]; snprintf(msg, sizeof(msg),\n            \"bad symnum %#x in Elf64_Rel[%d]\", symnum, relnum);\n        throwCantPack(msg);\n    }\n    return get_str_name(get_te32(&dynsym[symnum].st_name), symnum);\n}\n\nbool PackLinuxElf64::calls_crt1(Elf64_Rela const *rela, int sz)\n{\n    if (!dynsym || !dynstr || !rela) {\n        return false;\n    }\n    for (unsigned relnum= 0; 0 < sz; (sz -= sizeof(Elf64_Rela)), ++rela, ++relnum) {\n        unsigned const symnum = get_te64(&rela->r_info) >> 32;\n        char const *const symnam = get_dynsym_name(symnum, relnum);\n        if (0==strcmp(symnam, \"__libc_start_main\")  // glibc\n        ||  0==strcmp(symnam, \"__libc_init\")  // Android\n        ||  0==strcmp(symnam, \"__uClibc_main\")\n        ||  0==strcmp(symnam, \"__uClibc_start_main\"))\n            return true;\n    }\n    return false;\n}\n\nchar const *PackLinuxElf32::get_str_name(unsigned st_name, unsigned symnum) const\n{\n    if (strtab_end <= st_name) {\n        char msg[70]; snprintf(msg, sizeof(msg),\n            \"bad .st_name %#x in DT_SYMTAB[%d]\\n\", st_name, symnum);\n        throwCantPack(msg);\n    }\n    return &dynstr[st_name];\n}\n\nchar const *PackLinuxElf32::get_dynsym_name(unsigned symnum, unsigned relnum) const\n{\n    if (symnum_end <= symnum) {\n        char msg[70]; snprintf(msg, sizeof(msg),\n            \"bad symnum %#x in Elf32_Rel[%d]\\n\", symnum, relnum);\n        throwCantPack(msg);\n    }\n    return get_str_name(get_te32(&dynsym[symnum].st_name), symnum);\n}\n\nbool PackLinuxElf32::calls_crt1(Elf32_Rel const *rel, int sz)\n{\n    if (!dynsym || !dynstr || !rel) {\n        return false;\n    }\n    for (unsigned relnum= 0; 0 < sz; (sz -= sizeof(Elf32_Rel)), ++rel, ++relnum) {\n        unsigned const symnum = get_te32(&rel->r_info) >> 8;\n        char const *const symnam = get_dynsym_name(symnum, relnum);\n        if (0==strcmp(symnam, \"__libc_start_main\")  // glibc\n        ||  0==strcmp(symnam, \"__libc_init\")  // Android\n        ||  0==strcmp(symnam, \"__uClibc_main\")\n        ||  0==strcmp(symnam, \"__uClibc_start_main\"))\n            return true;\n    }\n    return false;\n}\n\n#define WANT_REL_ENUM\n#include \"p_elf_enum.h\"\n#undef WANT_REL_ENUM\n\nint PackLinuxElf32::canUnpack() // bool, except -1: format known, but not packed\n{\n    if (checkEhdr(&ehdri)) {\n        return false;\n    }\n    if (Elf32_Ehdr::ET_DYN==get_te16(&ehdri.e_type)) {\n        PackLinuxElf32help1(fi);\n    }\n    if (super::canUnpack()) {\n        return true;\n    }\n    return false;\n}\n\nbool PackLinuxElf32::canPack()\n{\n    union {\n        unsigned char buf[sizeof(Elf32_Ehdr) + 14*sizeof(Elf32_Phdr)];\n        //struct { Elf32_Ehdr ehdr; Elf32_Phdr phdr; } e;\n    } u;\n    COMPILE_TIME_ASSERT(sizeof(u.buf) <= 512)\n\n    fi->seek(0, SEEK_SET);\n    fi->readx(u.buf, sizeof(u.buf));\n    fi->seek(0, SEEK_SET);\n    Elf32_Ehdr const *const ehdr = (Elf32_Ehdr *) u.buf;\n\n    // now check the ELF header\n    if (checkEhdr(ehdr) != 0)\n        return false;\n\n    // additional requirements for linux/elf386\n    if (get_te16(&ehdr->e_ehsize) != sizeof(*ehdr)) {\n        throwCantPack(\"invalid Ehdr e_ehsize; try '--force-execve'\");\n        return false;\n    }\n    if (e_phoff != sizeof(*ehdr)) {// Phdrs not contiguous with Ehdr\n        throwCantPack(\"non-contiguous Ehdr/Phdr; try '--force-execve'\");\n        return false;\n    }\n\n    unsigned char osabi0 = u.buf[Elf32_Ehdr::EI_OSABI];\n    // The first PT_LOAD32 must cover the beginning of the file (0==p_offset).\n    Elf32_Phdr const *phdr = phdri;\n    note_size = 0;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        if (j >= 14) {\n            throwCantPack(\"too many ElfXX_Phdr; try '--force-execve'\");\n            return false;\n        }\n        unsigned const p_type = get_te32(&phdr->p_type);\n        unsigned const p_offset = get_te32(&phdr->p_offset);\n        if (1!=exetype && PT_LOAD32 == p_type) { // 1st PT_LOAD\n            exetype = 1;\n            load_va = get_te32(&phdr->p_vaddr);  // class data member\n\n            // Cast on next line is to avoid a compiler bug (incorrect complaint) in\n            // Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24215.1 for x64\n            // error C4319: '~': zero extending 'unsigned int' to 'upx_uint64_t' of greater size\n            unsigned const off = ~page_mask & (unsigned)load_va;\n\n            if (off && off == p_offset) { // specific hint\n                throwCantPack(\"Go-language PT_LOAD: try hemfix.c, or try '--force-execve'\");\n                // Fixing it inside upx fails because packExtent() reads original file.\n                return false;\n            }\n            if (0 != p_offset) { // 1st PT_LOAD must cover Ehdr and Phdr\n                throwCantPack(\"first PT_LOAD.p_offset != 0; try '--force-execve'\");\n                return false;\n            }\n            hatch_off = ~3u & (3+ get_te32(&phdr->p_memsz));\n        }\n        if (PT_NOTE32 == p_type) {\n            unsigned const x = get_te32(&phdr->p_memsz);\n            if ( sizeof(elfout.notes) < x  // beware overflow of note_size\n            ||  (sizeof(elfout.notes) < (note_size += x)) ) {\n                throwCantPack(\"PT_NOTEs too big; try '--force-execve'\");\n                return false;\n            }\n            if (osabi_note && Elf32_Ehdr::ELFOSABI_NONE==osabi0) { // Still seems to be generic.\n                struct {\n                    struct Elf32_Nhdr nhdr;\n                    char name[8];\n                    unsigned body;\n                } note;\n                memset(&note, 0, sizeof(note));\n                fi->seek(p_offset, SEEK_SET);\n                fi->readx(&note, sizeof(note));\n                fi->seek(0, SEEK_SET);\n                if (4==get_te32(&note.nhdr.descsz)\n                &&  1==get_te32(&note.nhdr.type)\n                // &&  0==note.end\n                &&  (1+ strlen(osabi_note))==get_te32(&note.nhdr.namesz)\n                &&  0==strcmp(osabi_note, (char const *)&note.name[0])\n                ) {\n                    osabi0 = ei_osabi;  // Specified by PT_NOTE.\n                }\n            }\n        }\n    }\n    if (Elf32_Ehdr::ELFOSABI_NONE ==osabi0\n    ||  Elf32_Ehdr::ELFOSABI_LINUX==osabi0) { // No EI_OSBAI, no PT_NOTE.\n        unsigned const arm_eabi = 0xff000000u & get_te32(&ehdr->e_flags);\n        if (Elf32_Ehdr::EM_ARM==e_machine\n        &&   (EF_ARM_EABI_VER5==arm_eabi\n          ||  EF_ARM_EABI_VER4==arm_eabi ) ) {\n            // armel-eabi armeb-eabi ARM Linux EABI version 4 is a mess.\n            ei_osabi = osabi0 = Elf32_Ehdr::ELFOSABI_LINUX;\n        }\n        else {\n            osabi0 = opt->o_unix.osabi0;  // Possibly specified by command-line.\n        }\n    }\n    if (osabi0!=ei_osabi) {\n        return false;\n    }\n\n    // We want to compress position-independent executable (gcc -pie)\n    // main programs, but compressing a shared library must be avoided\n    // because the result is no longer usable.  In theory, there is no way\n    // to tell them apart: both are just ET_DYN.  Also in theory,\n    // neither the presence nor the absence of any particular symbol name\n    // can be used to tell them apart; there are counterexamples.\n    // However, we will use the following heuristic suggested by\n    // Peter S. Mazinger <ps.m@gmx.net> September 2005:\n    // If a ET_DYN has __libc_start_main as a global undefined symbol,\n    // then the file is a position-independent executable main program\n    // (that depends on libc.so.6) and is eligible to be compressed.\n    // Otherwise (no __libc_start_main as global undefined): skip it.\n    // Also allow  __uClibc_main  and  __uClibc_start_main .\n\n    if (Elf32_Ehdr::ET_DYN==get_te16(&ehdr->e_type)) {\n        // The DT_SYMTAB has no designated length.  Read the whole file.\n        alloc_file_image(file_image, file_size);\n        fi->seek(0, SEEK_SET);\n        fi->readx(file_image, file_size);\n        memcpy(&ehdri, ehdr, sizeof(Elf32_Ehdr));\n        phdri= (Elf32_Phdr *)((size_t)e_phoff + file_image);  // do not free() !!\n        shdri= (Elf32_Shdr *)((size_t)e_shoff + file_image);  // do not free() !!\n\n        sec_strndx = nullptr;\n        shstrtab = nullptr;\n        if (e_shnum) {\n            unsigned const e_shstrndx = get_te16(&ehdr->e_shstrndx);\n            if (e_shstrndx) {\n                if (e_shnum <= e_shstrndx) {\n                    char msg[40]; snprintf(msg, sizeof(msg),\n                        \"bad e_shstrndx %#x >= e_shnum %d\", e_shstrndx, e_shnum);\n                    throwCantPack(msg);\n                }\n                sec_strndx = &shdri[e_shstrndx];\n                unsigned const sh_offset = get_te32(&sec_strndx->sh_offset);\n                if ((u32_t)file_size <= sh_offset) {\n                    char msg[50]; snprintf(msg, sizeof(msg),\n                        \"bad .e_shstrndx->sh_offset %#x\", sh_offset);\n                    throwCantPack(msg);\n                }\n                shstrtab = (char const *)(sh_offset + file_image);\n            }\n            sec_dynsym = elf_find_section_type(Elf32_Shdr::SHT_DYNSYM);\n            if (sec_dynsym) {\n                unsigned const sh_link = get_te32(&sec_dynsym->sh_link);\n                if (e_shnum <= sh_link) {\n                    char msg[50]; snprintf(msg, sizeof(msg),\n                        \"bad SHT_DYNSYM.sh_link %#x\", sh_link);\n                }\n                sec_dynstr = &shdri[sh_link];\n            }\n\n            if (sec_strndx) {\n                unsigned const sh_name = get_te32(&sec_strndx->sh_name);\n                if (Elf32_Shdr::SHT_STRTAB != get_te32(&sec_strndx->sh_type)\n                || (u32_t)file_size <= (sizeof(\".shstrtab\")\n                    + sh_name + (shstrtab - (const char *)&file_image[0]))\n                || (sh_name\n                  && 0!=strcmp((char const *)\".shstrtab\", &shstrtab[sh_name]))\n                ) {\n                    throwCantPack(\"bad e_shstrtab\");\n                }\n            }\n        }\n\n        Elf32_Phdr const *pload_x0(nullptr);  // first eXecutable PT_LOAD\n        phdr= phdri;\n        for (int j= e_phnum; --j>=0; ++phdr)\n        if (Elf32_Phdr::PT_DYNAMIC==get_te32(&phdr->p_type)) {\n            unsigned offset = check_pt_dynamic(phdr);\n            dynseg= (Elf32_Dyn const *)(offset + file_image);\n            invert_pt_dynamic(dynseg,\n                umin(get_te32(&phdr->p_filesz), file_size - offset));\n        }\n        else if (is_LOAD32(phdr)) {\n            if (!pload_x0\n            &&  Elf32_Phdr::PF_X & get_te32(&phdr->p_flags)\n            ) {\n                pload_x0 = phdr;\n            }\n            check_pt_load(phdr);\n        }\n        if (!pload_x0) {\n            throwCantPack(\"No PT_LOAD has (p_flags & PF_X)\");\n        }\n        // elf_find_dynamic() returns 0 if 0==dynseg.\n        dynstr=          (char const *)elf_find_dynamic(Elf32_Dyn::DT_STRTAB);\n        dynsym=     (Elf32_Sym const *)elf_find_dynamic(Elf32_Dyn::DT_SYMTAB);\n\n        if (opt->o_unix.force_pie\n        ||      Elf32_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf32_Dyn::DT_FLAGS_1)\n        ||  calls_crt1((Elf32_Rel const *)elf_find_dynamic(Elf32_Dyn::DT_REL),\n                                 (int)elf_unsigned_dynamic(Elf32_Dyn::DT_RELSZ))\n        ||  calls_crt1((Elf32_Rel const *)elf_find_dynamic(Elf32_Dyn::DT_JMPREL),\n                                 (int)elf_unsigned_dynamic(Elf32_Dyn::DT_PLTRELSZ))) {\n            is_pie = true;\n            goto proceed;  // calls C library init for main program\n        }\n\n        // Heuristic HACK for shared libraries (compare Darwin (MacOS) Dylib.)\n        // If there is an existing DT_INIT, and if everything that the dynamic\n        // linker ld-linux needs to perform relocations before calling DT_INIT\n        // resides below the first SHT_EXECINSTR Section in one PT_LOAD, then\n        // compress from the first executable Section to the end of that PT_LOAD.\n        // We must not alter anything that ld-linux might touch before it calls\n        // the DT_INIT function.\n        //\n        // Obviously this hack requires that the linker script put pieces\n        // into good positions when building the original shared library,\n        // and also requires ld-linux to behave.\n\n        // Apparently glibc-2.13.90 insists on 0==e_ident[EI_PAD..15],\n        // so compressing shared libraries may be doomed anyway.\n        // 2011-06-01: stub.shlib-init.S works around by installing hatch\n        // at end of .text.\n\n        if (/*jni_onload_sym ||*/ elf_find_dynamic(upx_dt_init)) {\n            if (this->e_machine!=Elf32_Ehdr::EM_386\n            &&  this->e_machine!=Elf32_Ehdr::EM_MIPS\n            &&  this->e_machine!=Elf32_Ehdr::EM_ARM)\n                goto abandon;  // need stub: EM_PPC\n            if (elf_has_dynamic(Elf32_Dyn::DT_TEXTREL)) {\n                throwCantPack(\"DT_TEXTREL found; re-compile with -fPIC\");\n                goto abandon;\n            }\n            if (!(Elf32_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf32_Dyn::DT_FLAGS_1))) {\n                // not explicitly PIE main program\n                if (Elf32_Ehdr::EM_ARM == e_machine  // Android is common\n                &&  !opt->o_unix.android_shlib  // but not explicit\n                ) {\n                    opt->info_mode++;\n                    info(\"note: use --android-shlib if appropriate\");\n                    opt->info_mode--;\n                }\n            }\n            Elf32_Shdr const *shdr = shdri;\n            xct_va = ~0u;\n            if (e_shnum) {\n                for (int j= e_shnum; --j>=0; ++shdr) {\n                    unsigned const sh_type = get_te32(&shdr->sh_type);\n                    if (Elf32_Shdr::SHF_EXECINSTR & get_te32(&shdr->sh_flags)) {\n                        xct_va = umin(xct_va, get_te32(&shdr->sh_addr));\n                    }\n                    // Hook the first slot of DT_PREINIT_ARRAY or DT_INIT_ARRAY.\n                    if ((     Elf32_Dyn::DT_PREINIT_ARRAY==upx_dt_init\n                        &&  Elf32_Shdr::SHT_PREINIT_ARRAY==sh_type)\n                    ||  (     Elf32_Dyn::DT_INIT_ARRAY   ==upx_dt_init\n                        &&  Elf32_Shdr::SHT_INIT_ARRAY   ==sh_type) ) {\n                        unsigned user_init_ava = get_te32(&shdr->sh_addr);\n                        user_init_off = get_te32(&shdr->sh_offset);\n                        if ((u32_t)file_size <= user_init_off) {\n                            char msg[70]; snprintf(msg, sizeof(msg),\n                                \"bad Elf32_Shdr[%d].sh_offset %#x\",\n                                -1+ e_shnum - j, user_init_off);\n                            throwCantPack(msg);\n                        }\n                        // Check that &file_image[user_init_off] has\n                        // *_RELATIVE relocation, and fetch user_init_va.\n                        // If Elf32_Rela then the actual value is in Rela.r_addend.\n                        int z_rel = dt_table[Elf32_Dyn::DT_REL];\n                        int z_rsz = dt_table[Elf32_Dyn::DT_RELSZ];\n                        if (z_rel && z_rsz) {\n                            unsigned rel_off = get_te32(&dynseg[-1+ z_rel].d_val);\n                            if ((unsigned)file_size <= rel_off) {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                     \"bad Elf32_Dynamic[DT_REL] %#x\\n\",\n                                     rel_off);\n                                throwCantPack(msg);\n                            }\n                            Elf32_Rel *rp = (Elf32_Rel *)&file_image[rel_off];\n                            unsigned relsz   = get_te32(&dynseg[-1+ z_rsz].d_val);\n                            if ((unsigned)file_size <= relsz) {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                     \"bad Elf32_Dynamic[DT_RELSZ] %#x\\n\",\n                                     relsz);\n                                throwCantPack(msg);\n                            }\n                            Elf32_Rel *last = (Elf32_Rel *)(relsz + (char *)rp);\n                            for (; rp < last; ++rp) {\n                                unsigned r_va = get_te32(&rp->r_offset);\n                                if (r_va == user_init_ava) { // found the Elf32_Rel\n                                    unsigned r_info = get_te32(&rp->r_info);\n                                    unsigned r_type = ELF32_R_TYPE(r_info);\n                                    if ((Elf32_Ehdr::EM_ARM == e_machine && R_ARM_RELATIVE == r_type)\n                                    ||  (Elf32_Ehdr::EM_386 == e_machine && R_386_RELATIVE == r_type) ) {\n                                        user_init_va = get_te32(&file_image[user_init_off]);\n                                    }\n                                    else {\n                                        char msg[50]; snprintf(msg, sizeof(msg),\n                                            \"bad relocation %#x DT_INIT_ARRAY[0]\",\n                                            r_info);\n                                        throwCantPack(msg);\n                                    }\n                                    break;\n                                }\n                            }\n                        }\n                        unsigned const p_filesz = get_te32(&pload_x0->p_filesz);\n                        if (!((user_init_va - xct_va) < p_filesz)) {\n                            // Not in executable portion of first executable PT_LOAD.\n                            if (0==user_init_va && opt->o_unix.android_shlib) {\n                                // Android allows (0 ==> skip) ?\n                                upx_dt_init = 0;  // force steal of 'extra' DT_NULL\n                                // XXX: FIXME: depends on SHT_DYNAMIC coming later\n                            }\n                            else {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                    \"bad init address %#x in Elf32_Shdr[%d].%#x\\n\",\n                                    (unsigned)user_init_va, -1+ e_shnum - j, user_init_off);\n                                throwCantPack(msg);\n                            }\n                        }\n                    }\n                    // By default /usr/bin/ld leaves 4 extra DT_NULL to support pre-linking.\n                    // Take one as a last resort.\n                    if ((Elf32_Dyn::DT_INIT==upx_dt_init || !upx_dt_init)\n                    &&  Elf32_Shdr::SHT_DYNAMIC == sh_type) {\n                        unsigned const n = get_te32(&shdr->sh_size) / sizeof(Elf32_Dyn);\n                        Elf32_Dyn *dynp = (Elf32_Dyn *)&file_image[get_te32(&shdr->sh_offset)];\n                        for (; Elf32_Dyn::DT_NULL != dynp->d_tag; ++dynp) {\n                            if (upx_dt_init == get_te32(&dynp->d_tag)) {\n                                break;  // re-found DT_INIT\n                            }\n                        }\n                        if ((1+ dynp) < (n+ dynseg)) { // not the terminator, so take it\n                            user_init_va = get_te32(&dynp->d_val);  // 0 if (0==upx_dt_init)\n                            set_te32(&dynp->d_tag, upx_dt_init = Elf32_Dyn::DT_INIT);\n                            user_init_off = (char const *)&dynp->d_val - (char const *)&file_image[0];\n                        }\n                    }\n                }\n            }\n            else { // no Sections; use heuristics\n                unsigned const strsz  = elf_unsigned_dynamic(Elf32_Dyn::DT_STRSZ);\n                unsigned const strtab = elf_unsigned_dynamic(Elf32_Dyn::DT_STRTAB);\n                unsigned const relsz  = elf_unsigned_dynamic(Elf32_Dyn::DT_RELSZ);\n                unsigned const rel    = elf_unsigned_dynamic(Elf32_Dyn::DT_REL);\n                unsigned const init   = elf_unsigned_dynamic(upx_dt_init);\n                if ((init == (relsz + rel   ) && rel    == (strsz + strtab))\n                ||  (init == (strsz + strtab) && strtab == (relsz + rel   ))\n                ) {\n                    xct_va = init;\n                    user_init_va = init;\n                    user_init_off = elf_get_offset_from_address(init);\n                }\n            }\n            // Rely on 0==elf_unsigned_dynamic(tag) if no such tag.\n            unsigned const va_gash = elf_unsigned_dynamic(Elf32_Dyn::DT_GNU_HASH);\n            unsigned const va_hash = elf_unsigned_dynamic(Elf32_Dyn::DT_HASH);\n            unsigned y = 0;\n            if ((y=1, xct_va < va_gash)  ||  (y=2, (0==va_gash && xct_va < va_hash))\n            ||  (y=3, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_STRTAB))\n            ||  (y=4, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_SYMTAB))\n            ||  (y=5, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_REL))\n            ||  (y=6, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_RELA))\n            ||  (y=7, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_JMPREL))\n            ||  (y=8, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_VERDEF))\n            ||  (y=9, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_VERSYM))\n            ||  (y=10, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_VERNEED)) ) {\n                static char const *which[] = {\n                    \"unknown\",\n                    \"DT_GNU_HASH\",\n                    \"DT_HASH\",\n                    \"DT_STRTAB\",\n                    \"DT_SYMTAB\",\n                    \"DT_REL\",\n                    \"DT_RELA\",\n                    \"DT_JMPREL\",\n                    \"DT_VERDEF\",\n                    \"DT_VERSYM\",\n                    \"DT_VERNEED\",\n                };\n                char buf[30]; snprintf(buf, sizeof(buf), \"%s above stub\", which[y]);\n                throwCantPack(buf);\n                goto abandon;\n            }\n            if (!opt->o_unix.android_shlib) {\n                phdr = phdri;\n                for (unsigned j= 0; j < e_phnum; ++phdr, ++j) {\n                    unsigned const vaddr = get_te32(&phdr->p_vaddr);\n                    if (PT_NOTE32 == get_te32(&phdr->p_type)\n                    && xct_va < vaddr) {\n                        char buf[40]; snprintf(buf, sizeof(buf),\n                           \"PT_NOTE %#x above stub\", vaddr);\n                        throwCantPack(buf);\n                        goto abandon;\n                    }\n                }\n            }\n            xct_off = elf_get_offset_from_address(xct_va);\n            if (opt->debug.debug_level) {\n                fprintf(stderr, \"shlib canPack: xct_va=%#lx  xct_off=%#lx\\n\",\n                    (long)xct_va, (long)xct_off);\n            }\n            goto proceed;  // But proper packing depends on checking xct_va.\n        }\n        else\n            throwCantPack(\"need DT_INIT; try \\\"void _init(void){}\\\"\");\nabandon:\n        return false;\nproceed: ;\n    }\n    // XXX Theoretically the following test should be first,\n    // but PackUnix::canPack() wants 0!=exetype ?\n    if (!super::canPack())\n        return false;\n    assert(exetype == 1);\n    exetype = 0;\n\n    // set options\n    opt->o_unix.blocksize = blocksize = file_size;\n    return true;\n}\n\nint PackLinuxElf64::canUnpack() // bool, except -1: format known, but not packed\n{\n    if (checkEhdr(&ehdri)) {\n        return false;\n    }\n    if (Elf64_Ehdr::ET_DYN==get_te16(&ehdri.e_type)) {\n        PackLinuxElf64help1(fi);\n        Elf64_Phdr const *phdr = phdri, *last_LOAD = nullptr;\n        for (unsigned j = 0; j < e_phnum; ++phdr, ++j)\n            if (Elf64_Phdr::PT_LOAD==get_te32(&phdr->p_type)) {\n                last_LOAD = phdr;\n            }\n        if (!last_LOAD)\n            return false;\n        off_t offset = get_te64(&last_LOAD->p_offset);\n        unsigned filesz = get_te64(&last_LOAD->p_filesz);\n        fi->seek(filesz+offset, SEEK_SET);\n        MemBuffer buf(32 + sizeof(overlay_offset));\n        fi->readx(buf, buf.getSize());\n        bool x = PackUnix::find_overlay_offset(buf);\n        if (x) {\n            return x;\n        }\n    }\n    if (super::canUnpack()) {\n        return true;\n    }\n    return false;\n}\n\nbool\nPackLinuxElf64::canPack()\n{\n    union {\n        unsigned char buf[sizeof(Elf64_Ehdr) + 14*sizeof(Elf64_Phdr)];\n        //struct { Elf64_Ehdr ehdr; Elf64_Phdr phdr; } e;\n    } u;\n    COMPILE_TIME_ASSERT(sizeof(u) <= 1024)\n\n    fi->readx(u.buf, sizeof(u.buf));\n    fi->seek(0, SEEK_SET);\n    Elf64_Ehdr const *const ehdr = (Elf64_Ehdr *) u.buf;\n\n    // now check the ELF header\n    if (checkEhdr(ehdr) != 0)\n        return false;\n\n    // additional requirements for linux/elf386\n    if (get_te16(&ehdr->e_ehsize) != sizeof(*ehdr)) {\n        throwCantPack(\"invalid Ehdr e_ehsize; try '--force-execve'\");\n        return false;\n    }\n    if (e_phoff != sizeof(*ehdr)) {// Phdrs not contiguous with Ehdr\n        throwCantPack(\"non-contiguous Ehdr/Phdr; try '--force-execve'\");\n        return false;\n    }\n\n    upx_uint64_t max_LOADsz = 0, max_offset = 0;\n    Elf64_Phdr const *phdr = phdri;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        if (j >= 14) {\n            throwCantPack(\"too many ElfXX_Phdr; try '--force-execve'\");\n            return false;\n        }\n        unsigned const p_type = get_te32(&phdr->p_type);\n        if (PT_LOAD64 == p_type) {\n            // The first PT_LOAD64 must cover the beginning of the file (0==p_offset).\n            if (1!= exetype) {\n                exetype = 1;\n                load_va = get_te64(&phdr->p_vaddr);  // class data member\n                upx_uint64_t const p_offset = get_te64(&phdr->p_offset);\n                upx_uint64_t const off = ~page_mask & load_va;\n                if (off && off == p_offset) { // specific hint\n                    throwCantPack(\"Go-language PT_LOAD: try hemfix.c, or try '--force-execve'\");\n                    // Fixing it inside upx fails because packExtent() reads original file.\n                    return false;\n                }\n                if (0 != p_offset) { // 1st PT_LOAD must cover Ehdr and Phdr\n                    throwCantPack(\"first PT_LOAD.p_offset != 0; try '--force-execve'\");\n                    return false;\n                }\n                // FIXME: bad for shlib!\n                hatch_off = ~3ul & (3+ get_te64(&phdr->p_memsz));\n            }\n            max_LOADsz = UPX_MAX(max_LOADsz, get_te64(&phdr->p_filesz));\n            max_offset = UPX_MAX(max_offset, get_te64(&phdr->p_filesz) + get_te64(&phdr->p_offset));\n        }\n    }\n    if (canUnpack() > 0) {\n        throwAlreadyPacked();\n    }\n    // We want to compress position-independent executable (gcc -pie)\n    // main programs, but compressing a shared library must be avoided\n    // because the result is no longer usable.  In theory, there is no way\n    // to tell them apart: both are just ET_DYN.  Also in theory,\n    // neither the presence nor the absence of any particular symbol name\n    // can be used to tell them apart; there are counterexamples.\n    // However, we will use the following heuristic suggested by\n    // Peter S. Mazinger <ps.m@gmx.net> September 2005:\n    // If a ET_DYN has __libc_start_main as a global undefined symbol,\n    // then the file is a position-independent executable main program\n    // (that depends on libc.so.6) and is eligible to be compressed.\n    // Otherwise (no __libc_start_main as global undefined): skip it.\n    // Also allow  __uClibc_main  and  __uClibc_start_main .\n\n    if (Elf64_Ehdr::ET_DYN==get_te16(&ehdr->e_type)) {\n        // The DT_SYMTAB has no designated length.  Read the whole file.\n        alloc_file_image(file_image, file_size);\n        fi->seek(0, SEEK_SET);\n        fi->readx(file_image, file_size);\n        memcpy(&ehdri, ehdr, sizeof(Elf64_Ehdr));\n        phdri= (Elf64_Phdr *)((size_t)e_phoff + file_image);  // do not free() !!\n        shdri= (Elf64_Shdr *)((size_t)e_shoff + file_image);  // do not free() !!\n\n        sec_strndx = nullptr;\n        shstrtab = nullptr;\n        if (e_shnum) {\n            unsigned const e_shstrndx = get_te16(&ehdr->e_shstrndx);\n            if (e_shstrndx) {\n                if (e_shnum <= e_shstrndx) {\n                    char msg[40]; snprintf(msg, sizeof(msg),\n                        \"bad e_shstrndx %#x >= e_shnum %d\", e_shstrndx, e_shnum);\n                    throwCantPack(msg);\n                }\n                sec_strndx = &shdri[e_shstrndx];\n                upx_uint64_t sh_offset = get_te64(&sec_strndx->sh_offset);\n                if ((u64_t)file_size <= sh_offset) {\n                    char msg[50]; snprintf(msg, sizeof(msg),\n                        \"bad .e_shstrndx->sh_offset %#lx\", (long unsigned)sh_offset);\n                    throwCantPack(msg);\n                }\n                shstrtab = (char const *)(sh_offset + file_image);\n            }\n            sec_dynsym = elf_find_section_type(Elf64_Shdr::SHT_DYNSYM);\n            if (sec_dynsym) {\n                upx_uint64_t const sh_link = get_te64(&sec_dynsym->sh_link);\n                if (e_shnum <= sh_link) {\n                    char msg[50]; snprintf(msg, sizeof(msg),\n                        \"bad SHT_DYNSYM.sh_link %#lx\", (long unsigned)sh_link);\n                }\n                sec_dynstr = &shdri[sh_link];\n            }\n\n            if (sec_strndx) {\n                unsigned const sh_name = get_te32(&sec_strndx->sh_name);\n                if (Elf64_Shdr::SHT_STRTAB != get_te32(&sec_strndx->sh_type)\n                || (u32_t)file_size <= (sizeof(\".shstrtab\")\n                    + sh_name + (shstrtab - (const char *)&file_image[0]))\n                || (sh_name\n                  && 0!=strcmp((char const *)\".shstrtab\", &shstrtab[sh_name]))\n                ) {\n                    throwCantPack(\"bad e_shstrtab\");\n                }\n            }\n        }\n\n        Elf64_Phdr const *pload_x0(nullptr);  // first eXecutable PT_LOAD\n        phdr= phdri;\n        for (int j= e_phnum; --j>=0; ++phdr)\n        if (Elf64_Phdr::PT_DYNAMIC==get_te32(&phdr->p_type)) {\n            upx_uint64_t offset = check_pt_dynamic(phdr);\n            dynseg= (Elf64_Dyn const *)(offset + file_image);\n            invert_pt_dynamic(dynseg,\n                umin(get_te64(&phdr->p_filesz), file_size - offset));\n        }\n        else if (PT_LOAD64==get_te32(&phdr->p_type)) {\n            if (!pload_x0\n            &&  Elf32_Phdr::PF_X & get_te32(&phdr->p_flags)\n            ) {\n                pload_x0 = phdr;\n            }\n            check_pt_load(phdr);\n        }\n        if (!pload_x0) {\n            throwCantPack(\"No PT_LOAD has (p_flags & PF_X)\");\n        }\n        // elf_find_dynamic() returns 0 if 0==dynseg.\n        dynstr=          (char const *)elf_find_dynamic(Elf64_Dyn::DT_STRTAB);\n        dynsym=     (Elf64_Sym const *)elf_find_dynamic(Elf64_Dyn::DT_SYMTAB);\n\n        if (opt->o_unix.force_pie\n        ||       Elf64_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf64_Dyn::DT_FLAGS_1)\n        ||  calls_crt1((Elf64_Rela const *)elf_find_dynamic(Elf64_Dyn::DT_RELA),\n                                  (int)elf_unsigned_dynamic(Elf64_Dyn::DT_RELASZ))\n        ||  calls_crt1((Elf64_Rela const *)elf_find_dynamic(Elf64_Dyn::DT_JMPREL),\n                                  (int)elf_unsigned_dynamic(Elf64_Dyn::DT_PLTRELSZ))) {\n            is_pie = true;\n            goto proceed;  // calls C library init for main program\n        }\n\n        // Heuristic HACK for shared libraries (compare Darwin (MacOS) Dylib.)\n        // If there is an existing DT_INIT, and if everything that the dynamic\n        // linker ld-linux needs to perform relocations before calling DT_INIT\n        // resides below the first SHT_EXECINSTR Section in one PT_LOAD, then\n        // compress from the first executable Section to the end of that PT_LOAD.\n        // We must not alter anything that ld-linux might touch before it calls\n        // the DT_INIT function.\n        //\n        // Obviously this hack requires that the linker script put pieces\n        // into good positions when building the original shared library,\n        // and also requires ld-linux to behave.\n\n        if (elf_find_dynamic(upx_dt_init)) {\n            if (elf_has_dynamic(Elf64_Dyn::DT_TEXTREL)) {\n                throwCantPack(\"DT_TEXTREL found; re-compile with -fPIC\");\n                goto abandon;\n            }\n            if (!(Elf64_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf64_Dyn::DT_FLAGS_1))) {\n                // not explicitly PIE main program\n                if (Elf64_Ehdr::EM_AARCH64 == e_machine  // Android is common\n                &&  !opt->o_unix.android_shlib  // but not explicit\n                ) {\n                    opt->info_mode++;\n                    info(\"note: use --android-shlib if appropriate\");\n                    opt->info_mode--;\n                }\n            }\n            Elf64_Shdr const *shdr = shdri;\n            xct_va = ~0ull;\n            if (e_shnum) {\n                for (int j= e_shnum; --j>=0; ++shdr) {\n                    unsigned const sh_type = get_te32(&shdr->sh_type);\n                    if (Elf64_Shdr::SHF_EXECINSTR & get_te64(&shdr->sh_flags)) {\n                        xct_va = umin(xct_va, get_te64(&shdr->sh_addr));\n                    }\n                    // Hook the first slot of DT_PREINIT_ARRAY or DT_INIT_ARRAY.\n                    if ((     Elf64_Dyn::DT_PREINIT_ARRAY==upx_dt_init\n                        &&  Elf64_Shdr::SHT_PREINIT_ARRAY==sh_type)\n                    ||  (     Elf64_Dyn::DT_INIT_ARRAY   ==upx_dt_init\n                        &&  Elf64_Shdr::SHT_INIT_ARRAY   ==sh_type) ) {\n                        unsigned user_init_ava = get_te32(&shdr->sh_addr);\n                        user_init_off = get_te64(&shdr->sh_offset);\n                        if ((u64_t)file_size <= user_init_off) {\n                            char msg[70]; snprintf(msg, sizeof(msg),\n                                \"bad Elf64_Shdr[%d].sh_offset %#x\",\n                                -1+ e_shnum - j, user_init_off);\n                            throwCantPack(msg);\n                        }\n                        // Check that &file_image[user_init_off] has\n                        // *_RELATIVE relocation, and fetch user_init_va.\n                        // If Elf64_Rela then the actual value is in Rela.r_addend.\n                        int z_rel = dt_table[Elf64_Dyn::DT_RELA];\n                        int z_rsz = dt_table[Elf64_Dyn::DT_RELASZ];\n                        if (z_rel && z_rsz) {\n                            upx_uint64_t rel_off = get_te64(&dynseg[-1+ z_rel].d_val);\n                            if ((u64_t)file_size <= rel_off) {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                     \"bad Elf64_Dynamic[DT_RELA] %#llx\\n\",\n                                     rel_off);\n                                throwCantPack(msg);\n                            }\n                            Elf64_Rela *rp = (Elf64_Rela *)&file_image[rel_off];\n                            upx_uint64_t relsz   = get_te64(&dynseg[-1+ z_rsz].d_val);\n                            if ((u64_t)file_size <= relsz) {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                     \"bad Elf64_Dynamic[DT_RELASZ] %#llx\\n\",\n                                     relsz);\n                                throwCantPack(msg);\n                            }\n                            Elf64_Rela *last = (Elf64_Rela *)(relsz + (char *)rp);\n                            for (; rp < last; ++rp) {\n                                upx_uint64_t r_va = get_te64(&rp->r_offset);\n                                if (r_va == user_init_ava) { // found the Elf64_Rela\n                                    upx_uint64_t r_info = get_te64(&rp->r_info);\n                                    unsigned r_type = ELF64_R_TYPE(r_info);\n                                    if (Elf64_Ehdr::EM_AARCH64 == e_machine\n                                    &&  R_AARCH64_RELATIVE == r_type) {\n                                        user_init_va = get_te64(&rp->r_addend);\n                                    }\n                                    else if (Elf64_Ehdr::EM_AARCH64 == e_machine\n                                    &&  R_AARCH64_ABS64 == r_type) {\n                                        user_init_va = get_te64(&file_image[user_init_off]);\n                                    }\n                                    else {\n                                        char msg[50]; snprintf(msg, sizeof(msg),\n                                            \"bad relocation %#llx DT_INIT_ARRAY[0]\",\n                                            r_info);\n                                        throwCantPack(msg);\n                                    }\n                                    break;\n                                }\n                            }\n                        }\n                        unsigned const p_filesz = get_te64(&pload_x0->p_filesz);\n                        if (!((user_init_va - xct_va) < p_filesz)) {\n                            // Not in executable portion of first executable PT_LOAD.\n                            if (0==user_init_va && opt->o_unix.android_shlib) {\n                                // Android allows (0 ==> skip) ?\n                                upx_dt_init = 0;  // force steal of 'extra' DT_NULL\n                                // XXX: FIXME: depends on SHT_DYNAMIC coming later\n                            }\n                            else {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                    \"bad init address %#x in Elf64_Shdr[%d].%#x\\n\",\n                                    (unsigned)user_init_va, -1+ e_shnum - j, user_init_off);\n                                throwCantPack(msg);\n                            }\n                        }\n                    }\n                    // By default /usr/bin/ld leaves 4 extra DT_NULL to support pre-linking.\n                    // Take one as a last resort.\n                    if ((Elf64_Dyn::DT_INIT==upx_dt_init || !upx_dt_init)\n                    &&  Elf64_Shdr::SHT_DYNAMIC == sh_type) {\n                        upx_uint64_t sh_offset = get_te64(&shdr->sh_offset);\n                        upx_uint64_t sh_size = get_te64(&shdr->sh_size);\n                        if ((upx_uint64_t)file_size < sh_size\n                        ||  (upx_uint64_t)file_size < sh_offset\n                        || ((upx_uint64_t)file_size - sh_offset) < sh_size) {\n                            throwCantPack(\"bad SHT_DYNAMIC\");\n                        }\n                        unsigned const n = sh_size / sizeof(Elf64_Dyn);\n                        Elf64_Dyn *dynp = (Elf64_Dyn *)&file_image[sh_offset];\n                        for (; Elf64_Dyn::DT_NULL != dynp->d_tag; ++dynp) {\n                            if (upx_dt_init == get_te64(&dynp->d_tag)) {\n                                break;  // re-found DT_INIT\n                            }\n                        }\n                        if ((1+ dynp) < (n+ dynseg)) { // not the terminator, so take it\n                            user_init_va = get_te64(&dynp->d_val);  // 0 if (0==upx_dt_init)\n                            set_te64(&dynp->d_tag, upx_dt_init = Elf64_Dyn::DT_INIT);\n                            user_init_off = (char const *)&dynp->d_val - (char const *)&file_image[0];\n                        }\n                    }\n                }\n            }\n            else { // no Sections; use heuristics\n                upx_uint64_t const strsz  = elf_unsigned_dynamic(Elf64_Dyn::DT_STRSZ);\n                upx_uint64_t const strtab = elf_unsigned_dynamic(Elf64_Dyn::DT_STRTAB);\n                upx_uint64_t const relsz  = elf_unsigned_dynamic(Elf64_Dyn::DT_RELSZ);\n                upx_uint64_t const rel    = elf_unsigned_dynamic(Elf64_Dyn::DT_REL);\n                upx_uint64_t const init   = elf_unsigned_dynamic(upx_dt_init);\n                if ((init == (relsz + rel   ) && rel    == (strsz + strtab))\n                ||  (init == (strsz + strtab) && strtab == (relsz + rel   ))\n                ) {\n                    xct_va = init;\n                    user_init_va = init;\n                    user_init_off = elf_get_offset_from_address(init);\n                }\n            }\n            // Rely on 0==elf_unsigned_dynamic(tag) if no such tag.\n            upx_uint64_t const va_gash = elf_unsigned_dynamic(Elf64_Dyn::DT_GNU_HASH);\n            upx_uint64_t const va_hash = elf_unsigned_dynamic(Elf64_Dyn::DT_HASH);\n            unsigned y = 0;\n            if ((y=1, xct_va < va_gash)  ||  (y=2, (0==va_gash && xct_va < va_hash))\n            ||  (y=3, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_STRTAB))\n            ||  (y=4, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_SYMTAB))\n            ||  (y=5, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_REL))\n            ||  (y=6, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_RELA))\n            ||  (y=7, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_JMPREL))\n            ||  (y=8, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_VERDEF))\n            ||  (y=9, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_VERSYM))\n            ||  (y=10, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_VERNEED)) ) {\n                static char const *which[] = {\n                    \"unknown\",\n                    \"DT_GNU_HASH\",\n                    \"DT_HASH\",\n                    \"DT_STRTAB\",\n                    \"DT_SYMTAB\",\n                    \"DT_REL\",\n                    \"DT_RELA\",\n                    \"DT_JMPREL\",\n                    \"DT_VERDEF\",\n                    \"DT_VERSYM\",\n                    \"DT_VERNEED\",\n                };\n                char buf[30]; snprintf(buf, sizeof(buf), \"%s above stub\", which[y]);\n                throwCantPack(buf);\n                goto abandon;\n            }\n            if (!opt->o_unix.android_shlib) {\n                phdr = phdri;\n                for (unsigned j= 0; j < e_phnum; ++phdr, ++j) {\n                    upx_uint64_t const vaddr = get_te64(&phdr->p_vaddr);\n                    if (PT_NOTE64 == get_te32(&phdr->p_type)\n                    && xct_va < vaddr) {\n                        char buf[40]; snprintf(buf, sizeof(buf),\n                           \"PT_NOTE %#lx above stub\", (unsigned long)vaddr);\n                        throwCantPack(buf);\n                        goto abandon;\n                    }\n                }\n            }\n            xct_off = elf_get_offset_from_address(xct_va);\n            if (opt->debug.debug_level) {\n                fprintf(stderr, \"shlib canPack: xct_va=%#lx  xct_off=%#lx\\n\",\n                    (long)xct_va, (long)xct_off);\n            }\n            goto proceed;  // But proper packing depends on checking xct_va.\n        }\n        else {\n            throwCantPack(\"need DT_INIT; try \\\"void _init(void){}\\\"\");\n        }\nabandon:\n        return false;\nproceed: ;\n    }\n    // XXX Theoretically the following test should be first,\n    // but PackUnix::canPack() wants 0!=exetype ?\n    if (!super::canPack())\n        return false;\n    assert(exetype == 1);\n    exetype = 0;\n\n    // set options\n    // this->blocksize: avoid over-allocating.\n    // (file_size - max_offset): debug info, non-globl symbols, etc.\n    opt->o_unix.blocksize = blocksize = UPX_MAX(max_LOADsz, file_size - max_offset);\n    return true;\n}\n\noff_t\nPackLinuxElf32::getbrk(Elf32_Phdr const *phdr, int nph) const\n{\n    off_t brka = 0;\n    for (int j = 0; j < nph; ++phdr, ++j) {\n        if (is_LOAD32(phdr)) {\n            off_t b = get_te32(&phdr->p_vaddr) + get_te32(&phdr->p_memsz);\n            if (b > brka)\n                brka = b;\n        }\n    }\n    return brka;\n}\n\noff_t\nPackLinuxElf32::getbase(const Elf32_Phdr *phdr, int nph) const\n{\n    off_t base = ~0u;\n    for (int j = 0; j < nph; ++phdr, ++j) {\n        if (is_LOAD32(phdr)) {\n            unsigned const vaddr = get_te32(&phdr->p_vaddr);\n            if (vaddr < (unsigned) base)\n                base = vaddr;\n        }\n    }\n    if (0!=base) {\n        return base;\n    }\n    return 0x12000;\n}\n\noff_t\nPackLinuxElf64::getbrk(const Elf64_Phdr *phdr, int nph) const\n{\n    off_t brka = 0;\n    for (int j = 0; j < nph; ++phdr, ++j) {\n        if (PT_LOAD64 == get_te32(&phdr->p_type)) {\n            off_t b = get_te64(&phdr->p_vaddr) + get_te64(&phdr->p_memsz);\n            if (b > brka)\n                brka = b;\n        }\n    }\n    return brka;\n}\n\nvoid\nPackLinuxElf32::generateElfHdr(\n    OutputFile *fo,\n    void const *proto,\n    unsigned const brka\n)\n{\n    cprElfHdr2 *const h2 = (cprElfHdr2 *)(void *)&elfout;\n    cprElfHdr3 *const h3 = (cprElfHdr3 *)(void *)&elfout;\n    h3->ehdr =         ((cprElfHdr3 const *)proto)->ehdr;\n    h3->phdr[C_BASE] = ((cprElfHdr3 const *)proto)->phdr[1];  // .data; .p_align\n    h3->phdr[C_TEXT] = ((cprElfHdr3 const *)proto)->phdr[0];  // .text\n    memset(&h3->linfo, 0, sizeof(h3->linfo));\n\n    h3->ehdr.e_type = ehdri.e_type;  // ET_EXEC vs ET_DYN (gcc -pie -fPIC)\n    h3->ehdr.e_ident[Elf32_Ehdr::EI_OSABI] = ei_osabi;\n    if (Elf32_Ehdr::EM_MIPS==e_machine) { // MIPS R3000  FIXME\n        h3->ehdr.e_ident[Elf32_Ehdr::EI_OSABI] = Elf32_Ehdr::ELFOSABI_NONE;\n        h3->ehdr.e_flags = ehdri.e_flags;\n    }\n\n    unsigned const phnum_i = get_te16(&h2->ehdr.e_phnum);\n    unsigned       phnum_o = phnum_i;\n\n    assert(get_te32(&h2->ehdr.e_phoff)     == sizeof(Elf32_Ehdr));\n                         h2->ehdr.e_shoff = 0;\n    assert(get_te16(&h2->ehdr.e_ehsize)    == sizeof(Elf32_Ehdr));\n    assert(get_te16(&h2->ehdr.e_phentsize) == sizeof(Elf32_Phdr));\n    if (o_elf_shnum) {\n        set_te16(&h2->ehdr.e_shentsize, sizeof(Elf32_Shdr));\n        h2->ehdr.e_shnum = o_elf_shnum;\n        h2->ehdr.e_shstrndx = o_elf_shnum - 1;\n    }\n    else {\n        // https://bugzilla.redhat.com/show_bug.cgi?id=2131609\n        // 0==.e_shnum is a special case for libbfd\n        // that requires 0==.e_shentsize in order to force \"no Shdrs\"\n        h2->ehdr.e_shentsize = 0;\n        h2->ehdr.e_shnum = 0;\n        h2->ehdr.e_shstrndx = 0;\n    }\n\n    sz_elf_hdrs = sizeof(*h2) - sizeof(linfo);  // default\n    if (gnu_stack) {\n        sz_elf_hdrs += sizeof(Elf32_Phdr);\n        memcpy(&h2->phdr[phnum_o++], gnu_stack, sizeof(*gnu_stack));\n        set_te16(&h2->ehdr.e_phnum, phnum_o);\n    }\n    o_binfo =  sizeof(Elf32_Ehdr) + sizeof(Elf32_Phdr)*phnum_o + sizeof(l_info) + sizeof(p_info);\n    set_te32(&h2->phdr[C_TEXT].p_filesz, sizeof(*h2));  // + identsize;\n              h2->phdr[C_TEXT].p_memsz = h2->phdr[C_TEXT].p_filesz;\n\n    for (unsigned j=0; j < phnum_i; ++j) {\n        if (is_LOAD32(&h3->phdr[j])) {\n            set_te32(&h3->phdr[j].p_align, page_size);\n        }\n    }\n\n    // Info for OS kernel to set the brk()\n    if (brka) {\n        // linux-2.6.14 binfmt_elf.c: SIGKILL if (0==.p_memsz) on a page boundary\n        upx_uint32_t lo_va_user = ~0u;  // infinity\n        for (int j= e_phnum; --j>=0; ) {\n            if (is_LOAD32(&phdri[j])) {\n                upx_uint32_t const vaddr = get_te32(&phdri[j].p_vaddr);\n                lo_va_user = umin(lo_va_user, vaddr);\n            }\n        }\n        set_te32(                 &h2->phdr[C_BASE].p_vaddr, lo_va_user);\n        h2->phdr[C_BASE].p_paddr = h2->phdr[C_BASE].p_vaddr;\n        h2->phdr[C_TEXT].p_vaddr = h2->phdr[C_BASE].p_vaddr;\n        h2->phdr[C_TEXT].p_paddr = h2->phdr[C_BASE].p_vaddr;\n        set_te32(&h2->phdr[C_BASE].p_type, PT_LOAD32);  // be sure\n        h2->phdr[C_BASE].p_offset = 0;\n        h2->phdr[C_BASE].p_filesz = 0;\n        // .p_memsz = brka;  temporary until sz_pack2\n        set_te32(&h2->phdr[C_BASE].p_memsz, brka - lo_va_user);\n        set_te32(&h2->phdr[C_BASE].p_flags, Elf32_Phdr::PF_R | Elf32_Phdr::PF_W);\n    }\n    if (ph.format==getFormat()) {\n        assert((2u+ !!gnu_stack) == phnum_o);\n        set_te32(&h2->phdr[C_TEXT].p_flags, ~Elf32_Phdr::PF_W & get_te32(&h2->phdr[C_TEXT].p_flags));\n        if (!gnu_stack) {\n            memset(&h2->linfo, 0, sizeof(h2->linfo));\n            fo->write(h2, sizeof(*h2));\n        }\n        else {\n            memset(&h3->linfo, 0, sizeof(h3->linfo));\n            fo->write(h3, sizeof(*h3));\n        }\n    }\n    else {\n        assert(false);  // unknown ph.format, PackLinuxElf32\n    }\n}\n\nvoid\nPackNetBSDElf32x86::generateElfHdr(\n    OutputFile *fo,\n    void const *proto,\n    unsigned const brka\n)\n{\n    super::generateElfHdr(fo, proto, brka);\n    cprElfHdr2 *const h2 = (cprElfHdr2 *)(void *)&elfout;\n\n    sz_elf_hdrs = sizeof(*h2) - sizeof(linfo);\n    unsigned note_offset = sz_elf_hdrs;\n\n    // Find the NetBSD PT_NOTE and the PaX PT_NOTE.\n    Elf32_Nhdr const *np_NetBSD = nullptr;  unsigned sz_NetBSD = 0;\n    Elf32_Nhdr const *np_PaX    = nullptr;  unsigned sz_PaX    = 0;\n    unsigned char *cp = (unsigned char *)note_body;\n    unsigned j;\n    for (j=0; j < note_size; ) {\n        Elf32_Nhdr const *const np = (Elf32_Nhdr const *)(void *)cp;\n        int k = sizeof(*np) + up4(get_te32(&np->namesz))\n            + up4(get_te32(&np->descsz));\n\n        if (NHDR_NETBSD_TAG == np->type && 7== np->namesz\n        &&  NETBSD_DESCSZ == np->descsz\n        &&  0==strcmp(ELF_NOTE_NETBSD_NAME,\n                /* &np->body */ (char const *)(1+ np))) {\n            np_NetBSD = np;\n            sz_NetBSD = k;\n        }\n        if (NHDR_PAX_TAG == np->type && 4== np->namesz\n        &&  PAX_DESCSZ==np->descsz\n        &&  0==strcmp(ELF_NOTE_PAX_NAME,\n                /* &np->body */ (char const *)(1+ np))) {\n            np_PaX = np;\n            sz_PaX = k;\n        }\n        cp += k;\n        j += k;\n    }\n\n    // Add PT_NOTE for the NetBSD note and PaX note, if any.\n    note_offset += (np_NetBSD ? sizeof(Elf32_Phdr) : 0);\n    note_offset += (np_PaX    ? sizeof(Elf32_Phdr) : 0);\n    Elf32_Phdr *phdr = &elfout.phdr[C_NOTE];\n    if (np_NetBSD) {\n        set_te32(&phdr->p_type, PT_NOTE32);\n        set_te32(&phdr->p_offset, note_offset);\n        set_te32(&phdr->p_vaddr, note_offset);\n        set_te32(&phdr->p_paddr, note_offset);\n        set_te32(&phdr->p_filesz, sz_NetBSD);\n        set_te32(&phdr->p_memsz,  sz_NetBSD);\n        set_te32(&phdr->p_flags, Elf32_Phdr::PF_R);\n        set_te32(&phdr->p_align, 4);\n\n        sz_elf_hdrs += sz_NetBSD + sizeof(*phdr);\n        note_offset += sz_NetBSD;\n        ++phdr;\n    }\n    if (np_PaX) {\n        set_te32(&phdr->p_type, PT_NOTE32);\n        set_te32(&phdr->p_offset, note_offset);\n        set_te32(&phdr->p_vaddr, note_offset);\n        set_te32(&phdr->p_paddr, note_offset);\n        set_te32(&phdr->p_filesz, sz_PaX);\n        set_te32(&phdr->p_memsz,  sz_PaX);\n        set_te32(&phdr->p_flags, Elf32_Phdr::PF_R);\n        set_te32(&phdr->p_align, 4);\n\n        /* &np_PaX->body[4] */\n        const unsigned char *p4 =  &(ACC_CCAST(const unsigned char *, (1+ np_PaX)))[4];\n        unsigned bits = get_te32(p4);\n        bits &= ~PAX_MPROTECT;\n        bits |=  PAX_NOMPROTECT;\n        set_te32(ACC_UNCONST_CAST(unsigned char *, p4), bits);\n\n        sz_elf_hdrs += sz_PaX + sizeof(*phdr);\n        note_offset += sz_PaX;\n        ++phdr;\n    }\n    set_te32(&h2->phdr[C_TEXT].p_filesz, note_offset);\n              h2->phdr[C_TEXT].p_memsz = h2->phdr[C_TEXT].p_filesz;\n\n    if (ph.format==getFormat()) {\n        set_te16(&h2->ehdr.e_phnum, !!sz_NetBSD + !!sz_PaX +\n        get_te16(&h2->ehdr.e_phnum));\n        fo->seek(0, SEEK_SET);\n        fo->rewrite(h2, sizeof(*h2) - sizeof(h2->linfo));\n\n        // The 'if' guards on these two calls to memcpy are required\n        // because the C Standard Committee did not debug the Standard\n        // before publishing.  An empty region (0==size) must nevertheless\n        // have a valid (non-nullptr) pointer.\n        if (sz_NetBSD) memcpy(&((char *)phdr)[0],         np_NetBSD, sz_NetBSD);\n        if (sz_PaX)    memcpy(&((char *)phdr)[sz_NetBSD], np_PaX,    sz_PaX);\n\n        fo->write(&elfout.phdr[C_NOTE],\n            &((char *)phdr)[sz_PaX + sz_NetBSD] - (char *)&elfout.phdr[C_NOTE]);\n\n        l_info foo; memset(&foo, 0, sizeof(foo));\n        fo->rewrite(&foo, sizeof(foo));\n    }\n    else {\n        assert(false);  // unknown ph.format, PackLinuxElf32\n    }\n}\n\nvoid\nPackOpenBSDElf32x86::generateElfHdr(\n    OutputFile *fo,\n    void const *proto,\n    unsigned const brka\n)\n{\n    cprElfHdr3 *const h3 = (cprElfHdr3 *)(void *)&elfout;\n    memcpy(h3, proto, sizeof(*h3));  // reads beyond, but OK\n    h3->ehdr.e_ident[Elf32_Ehdr::EI_OSABI] = ei_osabi;\n    assert(2==get_te16(&h3->ehdr.e_phnum));\n    set_te16(&h3->ehdr.e_phnum, 3);\n\n    assert(get_te32(&h3->ehdr.e_phoff)     == sizeof(Elf32_Ehdr));\n                         h3->ehdr.e_shoff = 0;\n    assert(get_te16(&h3->ehdr.e_ehsize)    == sizeof(Elf32_Ehdr));\n    assert(get_te16(&h3->ehdr.e_phentsize) == sizeof(Elf32_Phdr));\n    h3->ehdr.e_shentsize = 0;\n    h3->ehdr.e_shnum = 0;\n    h3->ehdr.e_shstrndx = 0;\n\n    struct {\n        Elf32_Nhdr nhdr;\n        char name[8];\n        unsigned body;\n    } elfnote;\n\n    unsigned const note_offset = sizeof(*h3) - sizeof(linfo);\n    sz_elf_hdrs = sizeof(elfnote) + note_offset;\n\n    set_te32(&h3->phdr[C_NOTE].p_type, PT_NOTE32);\n    set_te32(&h3->phdr[C_NOTE].p_offset, note_offset);\n    set_te32(&h3->phdr[C_NOTE].p_vaddr, note_offset);\n    set_te32(&h3->phdr[C_NOTE].p_paddr, note_offset);\n    set_te32(&h3->phdr[C_NOTE].p_filesz, sizeof(elfnote));\n    set_te32(&h3->phdr[C_NOTE].p_memsz,  sizeof(elfnote));\n    set_te32(&h3->phdr[C_NOTE].p_flags, Elf32_Phdr::PF_R);\n    set_te32(&h3->phdr[C_NOTE].p_align, 4);\n\n    // Q: Same as this->note_body[0 .. this->note_size-1] ?\n    set_te32(&elfnote.nhdr.namesz, 8);\n    set_te32(&elfnote.nhdr.descsz, OPENBSD_DESCSZ);\n    set_te32(&elfnote.nhdr.type,   NHDR_OPENBSD_TAG);\n    memcpy(elfnote.name, \"OpenBSD\", sizeof(elfnote.name));\n    elfnote.body = 0;\n\n    set_te32(&h3->phdr[C_TEXT].p_filesz, sz_elf_hdrs);\n              h3->phdr[C_TEXT].p_memsz = h3->phdr[C_TEXT].p_filesz;\n\n    unsigned const brkb = brka | ((0==(~page_mask & brka)) ? 0x20 : 0);\n    set_te32(&h3->phdr[C_BASE].p_type, PT_LOAD32);  // be sure\n    set_te32(&h3->phdr[C_BASE].p_offset, ~page_mask & brkb);\n    set_te32(&h3->phdr[C_BASE].p_vaddr, brkb);\n    set_te32(&h3->phdr[C_BASE].p_paddr, brkb);\n    h3->phdr[C_BASE].p_filesz = 0;\n    // Too many kernels have bugs when 0==.p_memsz\n    set_te32(&h3->phdr[C_BASE].p_memsz, 1);\n    set_te32(&h3->phdr[C_BASE].p_flags, Elf32_Phdr::PF_R | Elf32_Phdr::PF_W);\n\n    if (ph.format==getFormat()) {\n        memset(&h3->linfo, 0, sizeof(h3->linfo));\n        fo->write(h3, sizeof(*h3) - sizeof(h3->linfo));\n        fo->write(&elfnote, sizeof(elfnote));\n        fo->write(&h3->linfo, sizeof(h3->linfo));\n    }\n    else {\n        assert(false);  // unknown ph.format, PackLinuxElf32\n    }\n}\n\nvoid\nPackLinuxElf64::generateElfHdr(\n    OutputFile *fo,\n    void const *proto,\n    unsigned const brka\n)\n{\n    cprElfHdr2 *const h2 = (cprElfHdr2 *)(void *)&elfout;\n    cprElfHdr3 *const h3 = (cprElfHdr3 *)(void *)&elfout;\n    h3->ehdr =         ((cprElfHdr3 const *)proto)->ehdr;\n    h3->phdr[C_BASE] = ((cprElfHdr3 const *)proto)->phdr[1];  // .data; .p_align\n    h3->phdr[C_TEXT] = ((cprElfHdr3 const *)proto)->phdr[0];  // .text\n    memset(&h3->linfo, 0, sizeof(h3->linfo));\n\n    h3->ehdr.e_type = ehdri.e_type;  // ET_EXEC vs ET_DYN (gcc -pie -fPIC)\n    h3->ehdr.e_ident[Elf64_Ehdr::EI_OSABI] = ei_osabi;\n    if (Elf64_Ehdr::ELFOSABI_LINUX == ei_osabi  // proper\n    &&  Elf64_Ehdr::ELFOSABI_NONE  == ehdri.e_ident[Elf64_Ehdr::EI_OSABI]  // sloppy\n    ) { // propagate sloppiness so that decompression does not complain\n        h3->ehdr.e_ident[Elf64_Ehdr::EI_OSABI] = ehdri.e_ident[Elf64_Ehdr::EI_OSABI];\n    }\n    if (Elf64_Ehdr::EM_PPC64 == get_te16(&ehdri.e_machine)) {\n        h3->ehdr.e_flags = ehdri.e_flags;  // \"0x1, abiv1\" vs \"0x2, abiv2\"\n    }\n\n    unsigned const phnum_i = get_te16(&h2->ehdr.e_phnum);\n    unsigned       phnum_o = phnum_i;\n\n    assert(get_te64(&h2->ehdr.e_phoff)     == sizeof(Elf64_Ehdr));\n                         h2->ehdr.e_shoff = 0;\n    assert(get_te16(&h2->ehdr.e_ehsize)    == sizeof(Elf64_Ehdr));\n    assert(get_te16(&h2->ehdr.e_phentsize) == sizeof(Elf64_Phdr));\n    if (o_elf_shnum) {\n        set_te16(&h2->ehdr.e_shentsize, sizeof(Elf64_Shdr));\n        h2->ehdr.e_shnum = o_elf_shnum;\n        h2->ehdr.e_shstrndx = o_elf_shnum - 1;\n    }\n    else {\n        h2->ehdr.e_shentsize = 0;\n        h2->ehdr.e_shnum = 0;\n        h2->ehdr.e_shstrndx = 0;\n    }\n\n    sz_elf_hdrs = sizeof(*h2) - sizeof(linfo);  // default\n    if (gnu_stack) {\n        sz_elf_hdrs += sizeof(Elf64_Phdr);\n        memcpy(&h2->phdr[phnum_o++], gnu_stack, sizeof(*gnu_stack));\n        set_te16(&h2->ehdr.e_phnum, phnum_o);\n    }\n    o_binfo =  sizeof(Elf64_Ehdr) + sizeof(Elf64_Phdr)*phnum_o + sizeof(l_info) + sizeof(p_info);\n    set_te64(&h2->phdr[C_TEXT].p_filesz, sizeof(*h2));  // + identsize;\n                  h2->phdr[C_TEXT].p_memsz = h2->phdr[C_TEXT].p_filesz;\n\n    for (unsigned j=0; j < phnum_i; ++j) {\n        if (PT_LOAD64==get_te32(&h3->phdr[j].p_type)) {\n            set_te64(&h3->phdr[j].p_align, page_size);\n        }\n    }\n\n    // Info for OS kernel to set the brk()\n    if (brka) {\n        // linux-2.6.14 binfmt_elf.c: SIGKILL if (0==.p_memsz) on a page boundary\n        upx_uint64_t lo_va_user(~(upx_uint64_t)0);  // infinity\n        for (int j= e_phnum; --j>=0; ) {\n            if (PT_LOAD64 == get_te32(&phdri[j].p_type)) {\n                upx_uint64_t const vaddr = get_te64(&phdri[j].p_vaddr);\n                lo_va_user = umin64(lo_va_user, vaddr);\n            }\n        }\n        set_te64(                 &h2->phdr[C_BASE].p_vaddr, lo_va_user);\n        h2->phdr[C_BASE].p_paddr = h2->phdr[C_BASE].p_vaddr;\n        h2->phdr[C_TEXT].p_vaddr = h2->phdr[C_BASE].p_vaddr;\n        h2->phdr[C_TEXT].p_paddr = h2->phdr[C_BASE].p_vaddr;\n        set_te32(&h2->phdr[C_BASE].p_type, PT_LOAD64);  // be sure\n        h2->phdr[C_BASE].p_offset = 0;\n        h2->phdr[C_BASE].p_filesz = 0;\n        // .p_memsz = brka;  temporary until sz_pack2\n        set_te64(&h2->phdr[C_BASE].p_memsz, brka - lo_va_user);\n        set_te32(&h2->phdr[C_BASE].p_flags, Elf64_Phdr::PF_R | Elf64_Phdr::PF_W);\n    }\n    if (ph.format==getFormat()) {\n        assert((2u+ !!gnu_stack) == phnum_o);\n        set_te32(&h2->phdr[C_TEXT].p_flags, ~Elf64_Phdr::PF_W & get_te32(&h2->phdr[C_TEXT].p_flags));\n        if (!gnu_stack) {\n            memset(&h2->linfo, 0, sizeof(h2->linfo));\n            fo->write(h2, sizeof(*h2));\n        }\n        else {\n            memset(&h3->linfo, 0, sizeof(h3->linfo));\n            fo->write(h3, sizeof(*h3));\n        }\n    }\n    else {\n        assert(false);  // unknown ph.format, PackLinuxElf64\n    }\n}\n\n// Android shlib has ABS symbols that actually are relative.\nstatic char const abs_symbol_names[][14] = {\n      \"__bss_end__\"\n    ,  \"_bss_end__\"\n    , \"__bss_start\"\n    , \"__bss_start__\"\n    ,  \"_edata\"\n    ,  \"_end\"\n    , \"__end__\"\n    , \"\"\n};\n\nint\nPackLinuxElf32::adjABS(Elf32_Sym *sym, unsigned delta)\n{\n    unsigned st_name = get_te32(&sym->st_name);\n    for (int j = 0; abs_symbol_names[j][0]; ++j) {\n        if (!strcmp(abs_symbol_names[j], get_str_name(st_name, (unsigned)-1))) {\n            sym->st_value += delta;\n            return 1;\n        }\n    }\n    return 0;\n}\n\nint\nPackLinuxElf64::adjABS(Elf64_Sym *sym, unsigned delta)\n{\n    unsigned st_name = get_te32(&sym->st_name);\n    for (int j = 0; abs_symbol_names[j][0]; ++j) {\n        if (!strcmp(abs_symbol_names[j], get_str_name(st_name, (unsigned)-1))) {\n            sym->st_value += delta;\n            return 1;\n        }\n    }\n    return 0;\n}\n\nvoid PackLinuxElf32::pack1(OutputFile *fo, Filter & /*ft*/)\n{\n    fi->seek(0, SEEK_SET);\n    fi->readx(&ehdri, sizeof(ehdri));\n    assert(e_phoff == sizeof(Elf32_Ehdr));  // checked by canPack()\n    sz_phdrs = e_phnum * get_te16(&ehdri.e_phentsize);\n\n    // Remember all PT_NOTE, and find lg2_page from PT_LOAD.\n    Elf32_Phdr *phdr = phdri;\n    note_size = 0;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        if (PT_NOTE32 == get_te32(&phdr->p_type)) {\n            note_size += up4(get_te32(&phdr->p_filesz));\n        }\n    }\n    if (note_size) {\n        note_body.alloc(note_size);\n        note_size = 0;\n    }\n    phdr = phdri;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        unsigned const type = get_te32(&phdr->p_type);\n        if (PT_NOTE32 == type) {\n            unsigned const len = get_te32(&phdr->p_filesz);\n            fi->seek(get_te32(&phdr->p_offset), SEEK_SET);\n            fi->readx(&note_body[note_size], len);\n            note_size += up4(len);\n        }\n        if (PT_LOAD32 == type) {\n            unsigned x = get_te32(&phdr->p_align) >> lg2_page;\n            while (x>>=1) {\n                ++lg2_page;\n            }\n        }\n        if (PT_GNU_STACK32 == type) {\n            // MIPS stub cannot handle GNU_STACK yet.\n            if (Elf32_Ehdr::EM_MIPS != this->e_machine) {\n                gnu_stack = phdr;\n            }\n        }\n    }\n    page_size =  1u<<lg2_page;\n    page_mask = ~0u<<lg2_page;\n\n    progid = 0;  // getRandomId();  not useful, so do not clutter\n    sz_elf_hdrs = sizeof(ehdri) + sz_phdrs;\n    if (0!=xct_off) {  // shared library\n        sz_elf_hdrs = xct_off;\n        lowmem.alloc(xct_off + (!opt->o_unix.android_shlib\n            ? 0\n            : e_shnum * sizeof(Elf32_Shdr)));\n        memcpy(lowmem, file_image, xct_off);  // android omits Shdr here\n        fo->write(lowmem, xct_off);  // < SHF_EXECINSTR (typ: in .plt or .init)\n        if (opt->o_unix.android_shlib) {\n            // In order to pacify the runtime linker on Android \"O\" (\"Oreo\"),\n            // we will splice-in a 4KiB page that contains an \"extra\" copy\n            // of the Shdr, any PT_NOTE above xct_off, and shstrtab.\n            // File order: Ehdr, Phdr[], section contents below xct_off,\n            //    Shdr_copy[], PT_NOTEs.hi, shstrtab.\n            xct_va  += asl_delta;\n            //xct_off += asl_delta;  // not yet\n\n            // Relocate PT_DYNAMIC (in 2nd PT_LOAD)\n            Elf32_Dyn *dyn = const_cast<Elf32_Dyn *>(dynseg);\n            for (; dyn->d_tag; ++dyn) {\n                unsigned d_tag = get_te32(&dyn->d_tag);\n                if (Elf32_Dyn::DT_FINI       == d_tag\n                ||  Elf32_Dyn::DT_FINI_ARRAY == d_tag\n                ||  Elf32_Dyn::DT_INIT_ARRAY == d_tag\n                ||  Elf32_Dyn::DT_PREINIT_ARRAY == d_tag\n                ||  Elf32_Dyn::DT_PLTGOT     == d_tag) {\n                    unsigned d_val = get_te32(&dyn->d_val);\n                    set_te32(&dyn->d_val, asl_delta + d_val);\n                }\n            }\n\n            // Relocate dynsym (DT_SYMTAB) which is below xct_va\n            unsigned const off_dynsym = get_te32(&sec_dynsym->sh_offset);\n            unsigned const sz_dynsym  = get_te32(&sec_dynsym->sh_size);\n            Elf32_Sym *dyntym = (Elf32_Sym *)lowmem.subref(\n                \"bad dynsym\", off_dynsym, sz_dynsym);\n            Elf32_Sym *sym = dyntym;\n            for (int j = sz_dynsym / sizeof(Elf32_Sym); --j>=0; ++sym) {\n                unsigned symval = get_te32(&sym->st_value);\n                unsigned symsec = get_te16(&sym->st_shndx);\n                if (Elf32_Sym::SHN_UNDEF != symsec\n                &&  Elf32_Sym::SHN_ABS   != symsec\n                &&  xct_off <= symval) {\n                    set_te32(&sym->st_value, asl_delta + symval);\n                }\n                if (Elf32_Sym::SHN_ABS == symsec && xct_off <= symval) {\n                    adjABS(sym, asl_delta);\n                }\n            }\n\n            // Relocate Phdr virtual addresses, but not physical offsets and sizes\n            unsigned char buf_notes[512]; memset(buf_notes, 0, sizeof(buf_notes));\n            unsigned len_notes = 0;\n            phdr = (Elf32_Phdr *)lowmem.subref(\n                \"bad e_phoff\", e_phoff, e_phnum * sizeof(Elf32_Phdr));\n            for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n                upx_uint32_t offset = get_te32(&phdr->p_offset);\n                if (xct_off <= offset) { // above the extra page\n                    if (PT_NOTE32 == get_te32(&phdr->p_type)) {\n                        upx_uint32_t memsz = get_te32(&phdr->p_memsz);\n                        if (sizeof(buf_notes) < (memsz + len_notes)) {\n                            throwCantPack(\"PT_NOTEs too big\");\n                        }\n                        set_te32(&phdr->p_vaddr,\n                            len_notes + (e_shnum * sizeof(Elf32_Shdr)) + xct_off);\n                        phdr->p_offset = phdr->p_paddr = phdr->p_vaddr;\n                        memcpy(&buf_notes[len_notes], &file_image[offset], memsz);\n                        len_notes += memsz;\n                    }\n                    else {\n                        //set_te32(&phdr->p_offset, asl_delta + offset);  // physical\n                        upx_uint32_t addr = get_te32(&phdr->p_paddr);\n                        set_te32(&phdr->p_paddr, asl_delta + addr);\n                                     addr = get_te32(&phdr->p_vaddr);\n                        set_te32(&phdr->p_vaddr, asl_delta + addr);\n                    }\n                }\n                // .p_filesz,.p_memsz are updated in ::pack3\n            }\n\n            Elf32_Ehdr *const ehdr = (Elf32_Ehdr *)&lowmem[0];\n            upx_uint32_t e_entry = get_te32(&ehdr->e_entry);\n            if (xct_off < e_entry) {\n                set_te32(&ehdr->e_entry, asl_delta + e_entry);\n            }\n            // Relocate Shdr; and Rela, Rel (below xct_off)\n            set_te32(&ehdr->e_shoff, xct_off);\n            memcpy(&lowmem[xct_off], shdri, e_shnum * sizeof(Elf32_Shdr));\n            Elf32_Shdr *const shdro = (Elf32_Shdr *)&lowmem[xct_off];\n            Elf32_Shdr *shdr = shdro;\n            unsigned sz_shstrtab  = get_te32(&sec_strndx->sh_size);\n            for (unsigned j = 0; j < e_shnum; ++j, ++shdr) {\n\n                unsigned sh_type = get_te32(&shdr->sh_type);\n                unsigned sh_size = get_te32(&shdr->sh_size);\n                unsigned  sh_offset = get_te32(&shdr->sh_offset);\n                unsigned sh_entsize = get_te32(&shdr->sh_entsize);\n                unsigned   sh_flags = get_te32(&shdr->sh_flags);\n                if (xct_off <= sh_offset\n                // Omit .comment (0==.sh_addr; !SHF_ALLOC) etc.\n                && (shdr->sh_addr || Elf32_Shdr::SHF_ALLOC & sh_flags)\n                ) {\n                    //set_te32(&shdr->sh_offset, asl_delta + sh_offset);  // FIXME ??\n                    upx_uint32_t addr = get_te32(&shdr->sh_addr);\n                    set_te32(&shdr->sh_addr, asl_delta + addr);\n                }\n                if (Elf32_Shdr::SHT_RELA== sh_type) {\n                    if (sizeof(Elf32_Rela) != sh_entsize) {\n                        char msg[50];\n                        snprintf(msg, sizeof(msg), \"bad Rela.sh_entsize %u\", sh_entsize);\n                        throwCantPack(msg);\n                    }\n                    n_jmp_slot = 0;\n                    plt_off = ~0u;\n                    Elf32_Rela *const relb = (Elf32_Rela *)lowmem.subref(\n                         \"bad Rela offset\", sh_offset, sh_size);\n                    Elf32_Rela *rela = relb;\n                    for (int k = sh_size / sh_entsize; --k >= 0; ++rela) {\n                        unsigned r_addend = get_te32(&rela->r_addend);\n                        unsigned r_offset = get_te32(&rela->r_offset);\n                        unsigned r_info   = get_te32(&rela->r_info);\n                        unsigned r_type = ELF32_R_TYPE(r_info);\n                        if (xct_off <= r_offset) {\n                            set_te32(&rela->r_offset, asl_delta + r_offset);\n                        }\n                        if (Elf32_Ehdr::EM_ARM == e_machine) {\n                            if (R_ARM_RELATIVE == r_type) {\n                                if (xct_off <= r_addend) {\n                                    set_te32(&rela->r_addend, asl_delta + r_addend);\n                                }\n                            }\n                            if (R_ARM_JUMP_SLOT == r_type) {\n                                // .rela.plt contains offset of the \"first time\" target\n                                if (plt_off > r_offset) {\n                                    plt_off = r_offset;\n                                }\n                                unsigned d = elf_get_offset_from_address(r_offset);\n                                unsigned w = get_te32(&file_image[d]);\n                                if (xct_off <= w) {\n                                    set_te32(&file_image[d], asl_delta + w);\n                                }\n                                ++n_jmp_slot;\n                            }\n                        }\n                    }\n                    fo->seek(sh_offset, SEEK_SET);\n                    fo->rewrite(relb, sh_size);\n                }\n                if (Elf32_Shdr::SHT_REL == sh_type) {\n                    if (sizeof(Elf32_Rel) != sh_entsize) {\n                        char msg[50];\n                        snprintf(msg, sizeof(msg), \"bad Rel.sh_entsize %u\", sh_entsize);\n                        throwCantPack(msg);\n                    }\n                    n_jmp_slot = 0;\n                    plt_off = ~0u;\n                    Elf32_Rel *const rel0 = (Elf32_Rel *)lowmem.subref(\n                         \"bad Rel offset\", sh_offset, sh_size);\n                    Elf32_Rel *rel = rel0;\n                    for (int k = sh_size / sh_entsize; --k >= 0; ++rel) {\n                        unsigned r_offset = get_te32(&rel->r_offset);\n                        unsigned r_info = get_te32(&rel->r_info);\n                        unsigned r_type = ELF32_R_TYPE(r_info);\n                        unsigned d = elf_get_offset_from_address(r_offset);\n                        unsigned w = get_te32(&file_image[d]);\n                        if (xct_off <= r_offset) {\n                            set_te32(&rel->r_offset, asl_delta + r_offset);\n                        }\n                        if (Elf32_Ehdr::EM_ARM == e_machine) switch (r_type) {\n                            default: {\n                                char msg[90]; snprintf(msg, sizeof(msg),\n                                    \"unexpected relocation %#x [%#x]\",\n                                    r_type, -1 + (sh_size / sh_entsize) - k);\n                                throwCantPack(msg);\n                            } break;\n                            case R_ARM_ABS32:  // FALL THROUGH\n                            case R_ARM_GLOB_DAT: // FALL THROUGH\n                            case R_ARM_RELATIVE: {\n                                if (xct_off <= w) {\n                                    set_te32(&file_image[d], asl_delta + w);\n                                }\n                            } break;\n                            case R_ARM_JUMP_SLOT: {\n                                if (plt_off > r_offset) {\n                                    plt_off = r_offset;\n                                }\n                                if (xct_off <= w) {\n                                    set_te32(&file_image[d], asl_delta + w);\n                                }\n                                ++n_jmp_slot;\n                            }; break;\n                        }\n                    }\n                    fo->seek(sh_offset, SEEK_SET);\n                    fo->rewrite(rel0, sh_size);\n                }\n                if (Elf32_Shdr::SHT_NOTE == sh_type) {\n                    if (!(Elf32_Shdr::SHF_ALLOC & get_te32(&shdr->sh_flags))) {\n                        // example: version number of 'gold' linker (static binder)\n                        if (sizeof(buf_notes) < (sh_size + len_notes)) {\n                            throwCantPack(\"SHT_NOTEs too big\");\n                        }\n                        set_te32(&shdro[j].sh_offset,\n                            len_notes + (e_shnum * sizeof(Elf32_Shdr)) + xct_off);\n                        memcpy(&buf_notes[len_notes], &file_image[sh_offset], sh_size);\n                        len_notes += sh_size;\n                    }\n                    else { // SHF_ALLOC, thus already in PT_LOAD\n                        // Not sure why we need this conditional.\n                        // Anyway, some Android have multiple SHT_NOTE sections.\n                        if (xct_off <= sh_offset) {\n                            upx_uint32_t pos = xct_off + e_shnum * sizeof(Elf32_Shdr);\n                            set_te32(&shdr->sh_addr,   pos);\n                            set_te32(&shdr->sh_offset, pos);\n                        }\n                    }\n                }\n            }\n            // shstrndx will move\n            set_te32(&shdro[get_te16(&ehdri.e_shstrndx)].sh_offset,\n                len_notes + e_shnum * sizeof(Elf32_Shdr) + xct_off);\n\n            // (Re-)write all changes below xct_off\n            fo->seek(0, SEEK_SET);\n            fo->rewrite(lowmem, xct_off);\n\n            // New copy of Shdr\n            Elf32_Shdr blank; memset(&blank, 0, sizeof(blank));\n            set_te32(&blank.sh_offset, xct_off);  // hint for \"upx -d\"\n            fo->write(&blank, sizeof(blank));\n            fo->write(&shdro[1], (-1+ e_shnum) * sizeof(Elf32_Shdr));\n\n            if (len_notes) {\n                fo->write(buf_notes, len_notes);\n            }\n\n            // New copy of Shdr[.e_shstrndx].[ sh_offset, +.sh_size )\n            fo->write(shstrtab,  sz_shstrtab);\n\n            sz_elf_hdrs = fpad4(fo);\n            //xct_off += asl_delta;  // wait until ::pack3\n        }\n        memset(&linfo, 0, sizeof(linfo));\n        fo->write(&linfo, sizeof(linfo));\n    }\n\n    // if the preserve build-id option was specified\n    if (opt->o_unix.preserve_build_id) {\n        // set this so we can use elf_find_section_name\n        e_shnum = get_te16(&ehdri.e_shnum);\n        MemBuffer mb_shdri;\n        if (!shdri) {\n            mb_shdri.alloc(e_shnum * sizeof(Elf32_Shdr));\n            shdri = (Elf32_Shdr *)mb_shdri.getVoidPtr();\n            e_shoff = get_te32(&ehdri.e_shoff);\n            fi->seek(e_shoff, SEEK_SET);\n            fi->readx(shdri, e_shnum * sizeof(Elf32_Shdr));\n        }\n        //set the shstrtab\n        sec_strndx = &shdri[get_te16(&ehdri.e_shstrndx)];\n\n        unsigned sh_size = get_te32(&sec_strndx->sh_size);\n        mb_shstrtab.alloc(sh_size); shstrtab = (char *)mb_shstrtab.getVoidPtr();\n        fi->seek(0,SEEK_SET);\n        fi->seek(sec_strndx->sh_offset,SEEK_SET);\n        fi->readx(mb_shstrtab, sh_size);\n\n        Elf32_Shdr const *buildid = elf_find_section_name(\".note.gnu.build-id\");\n        if (buildid) {\n            unsigned bid_sh_size = get_te32(&buildid->sh_size);\n            buildid_data.alloc(bid_sh_size);\n            buildid_data.clear();\n            fi->seek(0,SEEK_SET);\n            fi->seek(buildid->sh_offset,SEEK_SET);\n            fi->readx((void *)buildid_data, bid_sh_size);\n\n            o_elf_shnum = 3;\n            memset(&shdrout,0,sizeof(shdrout));\n\n            //setup the build-id\n            memcpy(&shdrout.shdr[1], buildid, sizeof(shdrout.shdr[1]));\n            set_te32(&shdrout.shdr[1].sh_name, 1);\n\n            //setup the shstrtab\n            memcpy(&shdrout.shdr[2], sec_strndx, sizeof(shdrout.shdr[2]));\n            set_te32(&shdrout.shdr[2].sh_name, 20);\n            set_te32(&shdrout.shdr[2].sh_size, 29); //size of our static shstrtab\n        }\n    }\n}\n\nvoid PackLinuxElf32x86::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_i386_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackBSDElf32x86::pack1(OutputFile *fo, Filter &ft)\n{\n    PackLinuxElf32::pack1(fo, ft);\n    if (0!=xct_off) // shared library\n        return;\n    generateElfHdr(fo, stub_i386_bsd_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf32armLe::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    unsigned const e_flags = get_te32(&ehdri.e_flags);\n    cprElfHdr3 h3;\n    if (Elf32_Ehdr::ELFOSABI_LINUX==ei_osabi) {\n        memcpy(&h3, stub_arm_v5a_linux_elf_fold, sizeof(Elf32_Ehdr) + 2*sizeof(Elf32_Phdr));\n\n        h3.ehdr.e_ident[Elf32_Ehdr::EI_ABIVERSION] = e_flags>>24;\n    }\n    else {\n        memcpy(&h3, stub_arm_v4a_linux_elf_fold,        sizeof(Elf32_Ehdr) + 2*sizeof(Elf32_Phdr));\n    }\n    // Fighting over .e_ident[EI_ABIVERSION]: Debian armhf is latest culprit.\n    // So copy from input to output; but see PackLinuxElf32::generateElfHdr\n    memcpy(&h3.ehdr.e_ident[0], &ehdri.e_ident[0], sizeof(ehdri.e_ident));\n    set_te32(&h3.ehdr.e_flags, e_flags);\n    generateElfHdr(fo, &h3, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf32armBe::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    unsigned const e_flags = get_te32(&ehdri.e_flags);\n    cprElfHdr3 h3;\n    memcpy(&h3, stub_armeb_v4a_linux_elf_fold, sizeof(Elf32_Ehdr) + 2*sizeof(Elf32_Phdr));\n    set_te32(&h3.ehdr.e_flags, e_flags);\n    generateElfHdr(fo, &h3, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf32mipsel::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    cprElfHdr3 h3;\n    memcpy(&h3, stub_mipsel_r3000_linux_elf_fold, sizeof(Elf32_Ehdr) + 2*sizeof(Elf32_Phdr));\n    generateElfHdr(fo, &h3, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf32mipseb::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    cprElfHdr3 h3;\n    memcpy(&h3, stub_mips_r3000_linux_elf_fold, sizeof(Elf32_Ehdr) + 2*sizeof(Elf32_Phdr));\n    generateElfHdr(fo, &h3, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf32ppc::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_powerpc_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf64ppcle::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_powerpc64le_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf64ppc::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_powerpc64_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf64::asl_pack2_Shdrs(OutputFile *fo)\n{\n    // In order to pacify the runtime linker on Android \"O\" (\"Oreo\"),\n    // we will splice-in a 4KiB page that contains an \"extra\" copy\n    // of the Shdr, any PT_NOTE above xct_off, and shstrtab.\n    // File order: Ehdr, Phdr[], section contents below xct_off,\n    //    Shdr_copy[], PT_NOTEs.hi, shstrtab.\n    xct_va  += asl_delta;\n    //xct_off += asl_delta;  // not until ::pack3()\n\n    // Relocate PT_DYNAMIC (in PT_LOAD with PF_W)\n    Elf64_Dyn *dyn = const_cast<Elf64_Dyn *>(dynseg);\n    for (; dyn->d_tag; ++dyn) {\n        upx_uint64_t d_tag = get_te64(&dyn->d_tag);\n        if (Elf64_Dyn::DT_FINI       == d_tag\n        ||  Elf64_Dyn::DT_FINI_ARRAY == d_tag\n        ||  Elf64_Dyn::DT_INIT_ARRAY == d_tag\n        ||  Elf64_Dyn::DT_PREINIT_ARRAY == d_tag\n        ||  Elf64_Dyn::DT_PLTGOT      == d_tag) {\n            upx_uint64_t d_val = get_te64(&dyn->d_val);\n            set_te64(&dyn->d_val, asl_delta + d_val);\n        }\n    }\n    // Updated dynseg (.dynamic, in PT_DYNAMIC (PT_LOAD{PF_W})) has not been written.\n    // dynseg is in file_image[] but not in low_mem[].\n\n    // Relocate dynsym (DT_SYMTAB) which is below xct_va\n    upx_uint64_t const off_dynsym = get_te64(&sec_dynsym->sh_offset);\n    upx_uint64_t const sz_dynsym  = get_te64(&sec_dynsym->sh_size);\n    if ((upx_uint64_t)file_size < sz_dynsym\n    ||  (upx_uint64_t)file_size < off_dynsym\n    || ((upx_uint64_t)file_size - off_dynsym) < sz_dynsym) {\n        throwCantPack(\"bad DT_SYMTAB\");\n    }\n    Elf64_Sym *dyntym = (Elf64_Sym *)lowmem.subref(\n        \"bad dynsym\", off_dynsym, sz_dynsym);\n    Elf64_Sym *sym = dyntym;\n    for (int j = sz_dynsym / sizeof(Elf64_Sym); --j>=0; ++sym) {\n        upx_uint64_t symval = get_te64(&sym->st_value);\n        unsigned symsec = get_te16(&sym->st_shndx);\n        if (Elf64_Sym::SHN_UNDEF != symsec\n        &&  Elf64_Sym::SHN_ABS   != symsec\n        &&  xct_off <= symval) {\n            set_te64(&sym->st_value, asl_delta + symval);\n        }\n        if (Elf64_Sym::SHN_ABS == symsec && xct_off <= symval) {\n            adjABS(sym, asl_delta);\n        }\n    }\n\n    // Relocate Phdr virtual addresses, but not physical offsets and sizes\n    unsigned char buf_notes[512]; memset(buf_notes, 0, sizeof(buf_notes));\n    unsigned len_notes = 0;\n    Elf64_Phdr *phdr = (Elf64_Phdr *)lowmem.subref(\n        \"bad e_phoff\", e_phoff, e_phnum * sizeof(Elf64_Phdr));\n    for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n        upx_uint64_t offset = get_te64(&phdr->p_offset);\n        if (xct_off <= offset) { // above the extra page\n            if (PT_NOTE64 == get_te32(&phdr->p_type)) {\n                upx_uint64_t memsz = get_te64(&phdr->p_memsz);\n                if (sizeof(buf_notes) < (memsz + len_notes)) {\n                    throwCantPack(\"PT_NOTES too big\");\n                }\n                set_te64(&phdr->p_vaddr,\n                    len_notes + (e_shnum * sizeof(Elf64_Shdr)) + xct_off);\n                phdr->p_offset = phdr->p_paddr = phdr->p_vaddr;\n                memcpy(&buf_notes[len_notes], &file_image[offset], memsz);\n                len_notes += memsz;\n            }\n            else {\n                //set_te64(&phdr->p_offset, asl_delta + offset);  // physical\n                upx_uint64_t addr = get_te64(&phdr->p_paddr);\n                set_te64(&phdr->p_paddr, asl_delta + addr);\n                             addr = get_te64(&phdr->p_vaddr);\n                set_te64(&phdr->p_vaddr, asl_delta + addr);\n            }\n        }\n        // .p_filesz,.p_memsz are updated in ::pack3\n    }\n\n    Elf64_Ehdr *const ehdr = (Elf64_Ehdr *)&lowmem[0];\n    upx_uint64_t e_entry = get_te64(&ehdr->e_entry);\n    if (xct_off < e_entry) {\n        set_te64(&ehdr->e_entry, asl_delta + e_entry);\n    }\n    // Relocate Shdr; and Rela, Rel (below xct_off)\n    set_te64(&ehdr->e_shoff, xct_off);\n    memcpy(&lowmem[xct_off], shdri, e_shnum * sizeof(Elf64_Shdr));\n    Elf64_Shdr *const shdro = (Elf64_Shdr *)&lowmem[xct_off];\n    Elf64_Shdr *shdr = shdro;\n    upx_uint64_t sz_shstrtab  = get_te64(&sec_strndx->sh_size);\n    for (unsigned j = 0; j < e_shnum; ++j, ++shdr) {\n        unsigned sh_type = get_te32(&shdr->sh_type);\n        upx_uint64_t sh_size = get_te64(&shdr->sh_size);\n        upx_uint64_t sh_offset = get_te64(&shdr->sh_offset);\n        upx_uint64_t sh_entsize = get_te64(&shdr->sh_entsize);\n        if ((upx_uint64_t)file_size < sh_size\n        ||  (upx_uint64_t)file_size < sh_offset\n        || (Elf64_Shdr::SHT_NOBITS != sh_type\n           && ((upx_uint64_t)file_size - sh_offset) < sh_size) ) {\n            throwCantPack(\"bad SHT_STRNDX\");\n        }\n\n        if (xct_off <= sh_offset) {\n            upx_uint64_t addr = get_te64(&shdr->sh_addr);\n            set_te64(&shdr->sh_addr, asl_delta + addr);\n            set_te64(&shdr->sh_offset, asl_delta + sh_offset);\n        }\n        switch (sh_type) {\n        default: break;\n        case Elf64_Shdr::SHT_RELA: {\n            if (sizeof(Elf64_Rela) != sh_entsize) {\n                char msg[50];\n                snprintf(msg, sizeof(msg), \"bad Rela.sh_entsize %lu\", (long)sh_entsize);\n                throwCantPack(msg);\n            }\n            n_jmp_slot = 0;\n            plt_off = ~0ull;\n            Elf64_Rela *const relb = (Elf64_Rela *)lowmem.subref(\n                 \"bad Rela offset\", sh_offset, sh_size);\n            Elf64_Rela *rela = relb;\n            for (int k = sh_size / sh_entsize; --k >= 0; ++rela) {\n                upx_uint64_t r_addend = get_te64(&rela->r_addend);\n                upx_uint64_t r_offset = get_te64(&rela->r_offset);\n                upx_uint64_t r_info   = get_te64(&rela->r_info);\n                unsigned r_type = ELF64_R_TYPE(r_info);\n                if (xct_off <= r_offset) {\n                    set_te64(&rela->r_offset, asl_delta + r_offset);\n                }\n                if (Elf64_Ehdr::EM_AARCH64 == e_machine) switch (r_type) {\n                    default: {\n                        char msg[90]; snprintf(msg, sizeof(msg),\n                            \"unexpected relocation %#x [%#x]\",\n                            r_type, -1 + (unsigned)(sh_size / sh_entsize) - k);\n                        throwCantPack(msg);\n                    } break;\n                    case R_AARCH64_ABS64: // FALL THROUGH\n                    case R_AARCH64_GLOB_DAT: // FALL THROUGH\n                    case R_AARCH64_RELATIVE: {\n                        if (xct_off <= r_addend) {\n                            set_te64(&rela->r_addend, asl_delta + r_addend);\n                        }\n                    } break;\n                    case R_AARCH64_JUMP_SLOT: {\n                        // .rela.plt contains offset of the \"first time\" target\n                        if (plt_off > r_offset) {\n                            plt_off = r_offset;\n                        }\n                        upx_uint64_t d = elf_get_offset_from_address(r_offset);\n                        upx_uint64_t w = get_te64(&file_image[d]);\n                        if (xct_off <= w) {\n                            set_te64(&file_image[d], asl_delta + w);\n                        }\n                        ++n_jmp_slot;\n                    } break;\n                }\n            }\n        }; break;\n        case Elf64_Shdr::SHT_REL: {\n            if (sizeof(Elf64_Rel) != sh_entsize) {\n                char msg[50];\n                snprintf(msg, sizeof(msg), \"bad Rel.sh_entsize %lu\", (long)sh_entsize);\n                throwCantPack(msg);\n            }\n            Elf64_Rel *rel = (Elf64_Rel *)lowmem.subref(\n                    \"bad Rel sh_offset\", sh_offset, sh_size);\n            for (int k = sh_size / sh_entsize; --k >= 0; ++rel) {\n                upx_uint64_t r_offset = get_te64(&rel->r_offset);\n                if (xct_off <= r_offset) {\n                    set_te64(&rel->r_offset, asl_delta + r_offset);\n                }\n                // r_offset must be in 2nd PT_LOAD; .p_vaddr was already relocated\n                upx_uint64_t d = elf_get_offset_from_address(asl_delta + r_offset);\n                upx_uint64_t w = get_te64(&file_image[d]);\n                upx_uint64_t r_info = get_te64(&rel->r_info);\n                unsigned r_type = ELF64_R_TYPE(r_info);\n                if (xct_off <= w\n                &&  Elf64_Ehdr::EM_AARCH64 == e_machine\n                &&  (  R_AARCH64_RELATIVE  == r_type\n                    || R_AARCH64_JUMP_SLOT == r_type)) {\n                    set_te64(&file_image[d], asl_delta + w);\n                }\n            }\n        }; break;\n        case Elf64_Shdr::SHT_NOTE: {\n            if (!(Elf64_Shdr::SHF_ALLOC & get_te64(&shdr->sh_flags))) {\n                // example: version numer of 'gold' linker (static binder)\n                if (sizeof(buf_notes) < (sh_size + len_notes)) {\n                    throwCantPack(\"SHT_NOTEs too big\");\n                }\n                set_te64(&shdro[j].sh_offset,\n                    len_notes + (e_shnum * sizeof(Elf64_Shdr)) + xct_off);\n                memcpy(&buf_notes[len_notes], &file_image[sh_offset], sh_size);\n                len_notes += sh_size;\n            }\n            else { // SHF_ALLOC: in PT_LOAD; but move sh_addr and sh_offset\n                // Not sure why we need this conditional.\n                // Anyway, some Android have multiple SHT_NOTE sections.\n                if (xct_off <= sh_offset) {\n                    upx_uint64_t pos = xct_off + e_shnum * sizeof(Elf64_Shdr);\n                    set_te64(&shdr->sh_addr,   pos);\n                    set_te64(&shdr->sh_offset, pos);\n                }\n            }\n        }; break;\n        } // end switch (sh_type)\n    }\n    // shstrndx will move\n    set_te64(&shdro[get_te16(&ehdri.e_shstrndx)].sh_offset,\n        len_notes + e_shnum * sizeof(Elf64_Shdr) + xct_off);\n\n    // (Re-)write all changes below xct_off\n    fo->seek(0, SEEK_SET);\n    fo->rewrite(lowmem, xct_off);\n\n    // New copy of Shdr\n    Elf64_Shdr blank; memset(&blank, 0, sizeof(blank));\n    set_te64(&blank.sh_offset, xct_off);  // hint for \"upx -d\"\n    fo->write(&blank, sizeof(blank));\n    fo->write(&shdro[1], (-1+ e_shnum) * sizeof(Elf64_Shdr));\n\n    if (len_notes) {\n        fo->write(buf_notes, len_notes);\n    }\n\n    // New copy of Shdr[.e_shstrndx].[ sh_offset, +.sh_size )\n    fo->write(shstrtab,  sz_shstrtab);\n\n    sz_elf_hdrs = fpad8(fo);\n    total_out = sz_elf_hdrs;\n    total_in = xct_off;\n    //xct_off += asl_delta;  // wait until ::pack3\n\n    memset(&linfo, 0, sizeof(linfo));\n    fo->write(&linfo, sizeof(linfo));\n}\n\nvoid PackLinuxElf64::pack1(OutputFile * /*fo*/, Filter &ft)\n{\n    fi->seek(0, SEEK_SET);\n    fi->readx(&ehdri, sizeof(ehdri));\n    assert(e_phoff == sizeof(Elf64_Ehdr));  // checked by canPack()\n    sz_phdrs = e_phnum * get_te16(&ehdri.e_phentsize);\n\n// We compress separate pieces (usually each PT_LOAD, plus the gaps in the file\n// that are not covered by any PT_LOAD), but currently at run time there can be\n// only one decompressor method.\n// Therefore we must plan ahead because Packer::compressWithFilters tries\n// to find the smallest result among the available methods, for one piece only.\n// In the future we may allow more than one decompression method at run time.\n// For now we must choose only one, and force PackUnix::packExtent\n// (==> compressWithFilters) to use it.\n    int nfilters = 0;\n    {\n        int const *fp = getFilters();\n        while (FT_END != *fp++) {\n            ++nfilters;\n        }\n    }\n    {\n        int npieces = 1;  // tail after highest PT_LOAD\n        Elf64_Phdr *phdr = phdri;\n        for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n            if (PT_LOAD64 == get_te32(&phdr->p_type)) {\n                unsigned const  flags = get_te32(&phdr->p_flags);\n                unsigned       offset = get_te64(&phdr->p_offset);\n                if (!xct_off  // not shlib\n                  // new-style shlib: PT_LOAD[0] has symbol table\n                  // which must not be compressed, but also lacks PF_X\n                ||    (Elf64_Phdr::PF_X & flags)\n                  // Read-only, non-first PT_LOAD is _assumed_ to be compressible\n                ||  (!(Elf64_Phdr::PF_W & flags) && 0!=offset))\n                {\n                    ++npieces;  // will attempt compression of this PT_LOAD\n                }\n            }\n        }\n        uip->ui_total_passes += npieces;\n    }\n    int methods[256];\n    unsigned nmethods = prepareMethods(methods, ph.method, getCompressionMethods(M_ALL, ph.level));\n    if (1 < nmethods) { // Many are available, but we must choose only one\n        uip->ui_total_passes += 1;  // the batch for output\n        uip->ui_total_passes *= nmethods * (1+ nfilters);  // finding smallest total\n        PackHeader orig_ph = ph;\n        Filter orig_ft = ft;\n        unsigned max_offset = 0;\n        unsigned sz_best= ~0u;\n        int method_best = 0;\n        for (unsigned k = 0; k < nmethods; ++k) { // FIXME: parallelize; cost: working space\n            unsigned sz_this = 0;\n            Elf64_Phdr *phdr = phdri;\n            for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n                if (PT_LOAD64 == get_te32(&phdr->p_type)) {\n                    unsigned const  flags = get_te32(&phdr->p_flags);\n                    unsigned       offset = get_te64(&phdr->p_offset);\n                    unsigned       filesz = get_te64(&phdr->p_filesz);\n                    max_offset = UPX_MAX(max_offset, filesz + offset);\n                    if (!xct_off  // not shlib\n                      // new-style shlib: PT_LOAD[0] has symbol table\n                      // which must not be compressed, but also lacks PF_X\n                    ||    (Elf64_Phdr::PF_X & flags)\n                      // Read-only, non-first PT_LOAD is _assumed_ to be compressible\n                    ||  (!(Elf64_Phdr::PF_W & flags) && 0!=offset))\n                    {\n                        if (xct_off && 0==offset) { // old-style shlib\n                            offset  = xct_off;\n                            filesz -= xct_off;\n                        }\n                        fi->seek(offset, SEEK_SET);\n                        fi->readx(ibuf, filesz);\n                        ft = orig_ft;\n                        ph = orig_ph;\n                        ph.method = force_method(methods[k]);\n                        ph.u_len = filesz;\n                        compressWithFilters(&ft, OVERHEAD, NULL_cconf, 10, true);\n                        sz_this += ph.c_len;\n                    }\n                }\n            }\n            unsigned const sz_tail = file_size - max_offset;  // debuginfo, etc.\n            if (sz_tail) {\n                fi->seek(max_offset, SEEK_SET);\n                fi->readx(ibuf, sz_tail);\n                ft = orig_ft;\n                ph = orig_ph;\n                ph.method = force_method(methods[k]);\n                ph.u_len = sz_tail;\n                compressWithFilters(&ft, OVERHEAD, NULL_cconf, 10, true);\n                sz_this += ph.c_len;\n            }\n            // FIXME: loader size also depends on method\n            if (sz_best > sz_this) {\n                sz_best = sz_this;\n                method_best = methods[k];\n            }\n        }\n        ft = orig_ft;\n        ph = orig_ph;\n        ph.method = force_method(method_best);\n    }\n\n    note_size = 0;\n    Elf64_Phdr *phdr = phdri;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        if (PT_NOTE64 == get_te32(&phdr->p_type)) {\n            note_size += up4(get_te64(&phdr->p_filesz));\n        }\n    }\n    if (note_size) {\n        note_body.alloc(note_size);\n        note_size = 0;\n    }\n    phdr = phdri;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        unsigned const type = get_te32(&phdr->p_type);\n        if (PT_NOTE64 == type) {\n            unsigned const len = get_te64(&phdr->p_filesz);\n            fi->seek(get_te64(&phdr->p_offset), SEEK_SET);\n            fi->readx(&note_body[note_size], len);\n            note_size += up4(len);\n        }\n        if (PT_LOAD64 == type) {\n            unsigned x = get_te64(&phdr->p_align) >> lg2_page;\n            while (x>>=1) {\n                ++lg2_page;\n            }\n        }\n        if (PT_GNU_STACK64 == type) {\n            gnu_stack = phdr;\n        }\n    }\n    page_size =  1u  <<lg2_page;\n    page_mask = ~0ull<<lg2_page;\n\n    progid = 0;  // getRandomId();  not useful, so do not clutter\n    sz_elf_hdrs = sizeof(ehdri) + sz_phdrs;\n\n    // only execute if option present\n    if (opt->o_unix.preserve_build_id) {\n        // set this so we can use elf_find_section_name\n        e_shnum = get_te16(&ehdri.e_shnum);\n        MemBuffer mb_shdri;\n        if (!shdri) {\n            mb_shdri.alloc(e_shnum * sizeof(Elf64_Shdr));\n            shdri = (Elf64_Shdr *)mb_shdri.getVoidPtr();\n            e_shoff = get_te64(&ehdri.e_shoff);\n            fi->seek(e_shoff, SEEK_SET);\n            fi->readx(shdri, e_shnum * sizeof(Elf64_Shdr));\n        }\n        //set the shstrtab\n        sec_strndx = &shdri[get_te16(&ehdri.e_shstrndx)];\n\n        upx_uint64_t sh_size = get_te64(&sec_strndx->sh_size);\n        mb_shstrtab.alloc(sh_size); shstrtab = (char *)mb_shstrtab.getVoidPtr();\n        fi->seek(0,SEEK_SET);\n        fi->seek(sec_strndx->sh_offset,SEEK_SET);\n        fi->readx(mb_shstrtab, sh_size);\n\n        Elf64_Shdr const *buildid = elf_find_section_name(\".note.gnu.build-id\");\n        if (buildid) {\n            unsigned bid_sh_size = get_te32(&buildid->sh_size);\n            buildid_data.alloc(bid_sh_size);\n            buildid_data.clear();\n            fi->seek(0,SEEK_SET);\n            fi->seek(buildid->sh_offset,SEEK_SET);\n            fi->readx((void *)buildid_data, bid_sh_size);\n\n            o_elf_shnum = 3;\n            memset(&shdrout,0,sizeof(shdrout));\n\n            //setup the build-id\n            memcpy(&shdrout.shdr[1], buildid, sizeof(shdrout.shdr[1]));\n            set_te32(&shdrout.shdr[1].sh_name, 1);\n\n            //setup the shstrtab\n            memcpy(&shdrout.shdr[2], sec_strndx, sizeof(shdrout.shdr[2]));\n            set_te32(&shdrout.shdr[2].sh_name, 20);\n            set_te32(&shdrout.shdr[2].sh_size, 29); //size of our static shstrtab\n        }\n    }\n}\n\nvoid PackLinuxElf64amd::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_amd64_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf64arm::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_arm64_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\n// Determine length of gap between PT_LOAD phdr[k] and closest PT_LOAD\n// which follows in the file (or end-of-file).  Optimize for common case\n// where the PT_LOAD are adjacent ascending by .p_offset.  Assume no overlap.\n\nunsigned PackLinuxElf32::find_LOAD_gap(\n    Elf32_Phdr const *const phdr,\n    unsigned const k,\n    unsigned const nph\n)\n{\n    if (!is_LOAD32(&phdr[k])) {\n        return 0;\n    }\n    unsigned const hi = get_te32(&phdr[k].p_offset) +\n                        get_te32(&phdr[k].p_filesz);\n    unsigned lo = ph.u_file_size;\n    if (lo < hi)\n        throwCantPack(\"bad input: PT_LOAD beyond end-of-file\");\n    unsigned j = k;\n    for (;;) { // circular search, optimize for adjacent ascending\n        ++j;\n        if (nph==j) {\n            j = 0;\n        }\n        if (k==j) {\n            break;\n        }\n        if (is_LOAD32(&phdr[j])) {\n            unsigned const t = get_te32(&phdr[j].p_offset);\n            if ((t - hi) < (lo - hi)) {\n                lo = t;\n                if (hi==lo) {\n                    break;\n                }\n            }\n        }\n    }\n    return lo - hi;\n}\n\nint PackLinuxElf32::pack2(OutputFile *fo, Filter &ft)\n{\n    Extent x;\n    unsigned k;\n    bool const is_shlib = (0!=xct_off);\n\n    // count passes, set ptload vars\n    uip->ui_total_passes = 0;\n    for (k = 0; k < e_phnum; ++k) {\n        if (is_LOAD32(&phdri[k])) {\n            uip->ui_total_passes++;\n            if (find_LOAD_gap(phdri, k, e_phnum)) {\n                uip->ui_total_passes++;\n            }\n        }\n    }\n    uip->ui_total_passes -= !!is_shlib;  // not .data of shlib\n\n    // compress extents\n    unsigned hdr_u_len = (is_shlib ? xct_off : (sizeof(Elf32_Ehdr) + sz_phdrs));\n\n    total_in =  (is_shlib ?           0 : xct_off);\n    total_out = (is_shlib ? sz_elf_hdrs : xct_off);\n\n    uip->ui_pass = 0;\n    ft.addvalue = 0;\n\n    unsigned nk_f = 0; unsigned xsz_f = 0;\n    for (k = 0; k < e_phnum; ++k)\n    if (is_LOAD32(&phdri[k])\n    &&  Elf32_Phdr::PF_X & get_te32(&phdri[k].p_flags)) {\n        unsigned xsz =     get_te32(&phdri[k].p_filesz);\n        if (xsz_f < xsz) {\n            xsz_f = xsz;\n            nk_f = k;\n        }\n    }\n    int nx = 0;\n    for (k = 0; k < e_phnum; ++k)\n    if (is_LOAD32(&phdri[k])) {\n        if (ft.id < 0x40) {\n            // FIXME: ??    ft.addvalue = phdri[k].p_vaddr;\n        }\n        x.offset = get_te32(&phdri[k].p_offset);\n        x.size   = get_te32(&phdri[k].p_filesz);\n        if (!is_shlib || hdr_u_len < (u32_t)x.size) {\n            if (0 == nx) { // 1st PT_LOAD32 must cover Ehdr at 0==p_offset\n                unsigned const delta = hdr_u_len;\n                if (ft.id < 0x40) {\n                    // FIXME: ??     ft.addvalue += asl_delta;\n                }\n                if ((off_t)delta == x.size) { // PT_LOAD[0] with ElfXX.Ehdr only\n                    // QBE backend - http://c9x.me/compile/\n                    hdr_u_len = 0;  // no fiddling necessary!\n                    // &ft arg to packExtent will be zero becaue (k != nk_f)\n                }\n                else {\n                    x.offset += delta;\n                    x.size   -= delta;\n                }\n            }\n            // compressWithFilters() always assumes a \"loader\", so would\n            // throw NotCompressible for small .data Extents, which PowerPC\n            // sometimes marks as PF_X anyway.  So filter only first segment.\n            if (k == nk_f || !is_shlib) {\n                packExtent(x,\n                    (k==nk_f ? &ft : nullptr ), fo, hdr_u_len);\n            }\n            else {\n                total_in += x.size;\n            }\n        }\n        else {\n                total_in += x.size;\n        }\n        hdr_u_len = 0;\n        ++nx;\n    }\n    sz_pack2a = fpad4(fo);  // MATCH01\n\n    // Accounting only; ::pack3 will do the compression and output\n    for (k = 0; k < e_phnum; ++k) {\n        total_in += find_LOAD_gap(phdri, k, e_phnum);\n    }\n\n    if (total_in != (u32_t)file_size)\n        throwEOFException();\n\n    return 0;  // omit end-of-compression bhdr for now\n}\n\n// Determine length of gap between PT_LOAD phdr[k] and closest PT_LOAD\n// which follows in the file (or end-of-file).  Optimize for common case\n// where the PT_LOAD are adjacent ascending by .p_offset.  Assume no overlap.\n\nunsigned PackLinuxElf64::find_LOAD_gap(\n    Elf64_Phdr const *const phdr,\n    unsigned const k,\n    unsigned const nph\n)\n{\n    if (PT_LOAD64!=get_te32(&phdr[k].p_type)) {\n        return 0;\n    }\n    unsigned const hi = get_te64(&phdr[k].p_offset) +\n                        get_te64(&phdr[k].p_filesz);\n    unsigned lo = ph.u_file_size;\n    if (lo < hi)\n        throwCantPack(\"bad input: PT_LOAD beyond end-of-file\");\n    unsigned j = k;\n    for (;;) { // circular search, optimize for adjacent ascending\n        ++j;\n        if (nph==j) {\n            j = 0;\n        }\n        if (k==j) {\n            break;\n        }\n        if (PT_LOAD64==get_te32(&phdr[j].p_type)) {\n            unsigned const t = get_te64(&phdr[j].p_offset);\n            if ((t - hi) < (lo - hi)) {\n                lo = t;\n                if (hi==lo) {\n                    break;\n                }\n            }\n        }\n    }\n    return lo - hi;\n}\n\nint PackLinuxElf64::pack2(OutputFile *fo, Filter &ft)\n{\n    Extent x;\n    unsigned k;\n    unsigned const is_asl = (!!opt->o_unix.android_shlib) << 1;  // bit 1\n    unsigned const is_shlib = (0!=xct_off) | is_asl;\n\n    // count passes, set ptload vars\n    uip->ui_total_passes = 0;\n    for (k = 0; k < e_phnum; ++k) {\n        if (PT_LOAD64==get_te32(&phdri[k].p_type)) {\n            if (!is_shlib) {\n                uip->ui_total_passes++;\n            }\n            else {\n                unsigned p_flags = get_te32(&phdri[k].p_flags);\n                if (Elf64_Phdr::PF_W & p_flags) {\n                    // rtld might write, so cannot compress\n                }\n                else {\n                    upx_uint64_t p_filesz = get_te64(&phdri[k].p_filesz);\n                    // First PT_LOAD (partial) only if has instructions\n                    if (k || xct_off < p_filesz) {\n                        uip->ui_total_passes++;\n                    }\n                }\n            }\n            if (find_LOAD_gap(phdri, k, e_phnum)) {\n                uip->ui_total_passes++;\n            }\n        }\n    }\n\n    // compress extents\n    unsigned hdr_u_len = sizeof(Elf64_Ehdr) + sz_phdrs;\n\n    total_in =  0;\n    total_out = 0;\n    uip->ui_pass = 0;\n    ft.addvalue = 0;\n\n    if (is_shlib) { // prepare to alter Phdrs and Shdrs\n        lowmem.alloc(xct_off + (!is_asl\n            ? 0\n            : e_shnum * sizeof(Elf64_Shdr)));\n        memcpy(lowmem, file_image, xct_off);  // android omits Shdr here\n\n        if (is_asl) { // Android shared library\n            sz_elf_hdrs = xct_off;\n            fo->write(lowmem, xct_off);  // < SHF_EXECINSTR (typ: in .plt or .init)\n            total_in  = xct_off;\n            total_out = xct_off;\n\n            asl_pack2_Shdrs(fo);\n        }\n    }\n    unsigned nk_f = 0; upx_uint64_t xsz_f = 0;\n    for (k = 0; k < e_phnum; ++k)\n    if (PT_LOAD64==get_te32(&phdri[k].p_type)\n    &&  Elf64_Phdr::PF_X & get_te64(&phdri[k].p_flags)) {\n        upx_uint64_t xsz = get_te64(&phdri[k].p_filesz);\n        if (xsz_f < xsz) {\n            xsz_f = xsz;\n            nk_f = k;\n        }\n    }\n    int nx = 0;\n    for (k = 0; k < e_phnum; ++k)\n    if (PT_LOAD64==get_te32(&phdri[k].p_type)) {\n        if (ft.id < 0x40) {\n            // FIXME: ??    ft.addvalue = phdri[k].p_vaddr;\n        }\n        x.offset = get_te64(&phdri[k].p_offset);\n        x.size   = get_te64(&phdri[k].p_filesz);\n        if (is_shlib) {\n            if (x.offset <= xct_off) { // first PT_LOAD\n                unsigned const len = umin(x.size, xct_off - x.offset);\n                if (len && !is_asl) { // asl_pack2_Shdrs aleady handled\n                    fi->seek(x.offset, SEEK_SET);\n                    fi->readx(ibuf, x.size);\n                    total_in += len;\n\n                    fo->seek(x.offset, SEEK_SET);\n                    fo->write(ibuf, len);\n                    total_out += len;\n                }\n                if (len != x.size) {\n                    linfo.l_checksum = 0;\n                    linfo.l_magic = UPX_MAGIC_LE32;\n                    set_le16(&linfo.l_lsize, lsize);  // preliminary (0)\n                    linfo.l_version = (unsigned char)ph.version;\n                    linfo.l_format =  (unsigned char)ph.format;\n                    linfo_off = fo->tell();\n                    fo->write(&linfo, sizeof(linfo));\n                    total_out += sizeof(linfo);\n                    overlay_offset = total_out;\n\n                    p_info hbuf;\n                    set_te32(&hbuf.p_progid, 0);\n                    set_te32(&hbuf.p_filesize, file_size);\n                    set_te32(&hbuf.p_blocksize, blocksize);\n                    fo->write(&hbuf, sizeof(hbuf));\n                    total_out += sizeof(p_info);\n\n                    x.offset = 0;\n                    x.size = sz_elf_hdrs;\n                    if (is_asl) {\n                        x.size = hdr_u_len;\n                    }\n                    unsigned in_size = x.size;\n                    packExtent(x, nullptr, fo, 0, 0, true);\n                    total_in -= in_size;\n\n                    // The rest of first PT_LOAD (above xct_off)\n                    x.offset = xct_off;\n                    x.size = get_te64(&phdri[k].p_filesz) - len;\n                    packExtent(x, &ft, fo, 0, 0, true);\n                }\n            }\n            else {\n                if (!(Elf64_Phdr::PF_W & get_te64(&phdri[k].p_flags))) {\n                    // Read-only PT_LOAD, assume not written by relocations.\n                    // Also assume not the source for R_*_COPY relocation,\n                    // therefore compress it.\n                    packExtent(x, &ft, fo, 0, 0, true);\n                    // De-compressing will re-create it, but otherwise ignore it.\n                    Elf64_Phdr *phdro = (Elf64_Phdr *)(1+ (Elf64_Ehdr *)&lowmem[0]);\n                    set_te32(&phdro[k].p_type, Elf64_Phdr::PT_NULL);\n                }\n                else {\n                    // Read-write PT_LOAD.\n                    // rtld might relocate, so we cannot compress.\n                    // (Could compress if not relocated; complicates run-time.)\n                    // Postpone writing until \"slide\", but account for its size.\n                    total_in +=  x.size;\n                }\n            }\n        }\n        else  // main program, not shared library\n        if (hdr_u_len <= (u64_t)x.size) {\n            if (0 == nx) { // 1st PT_LOAD64 must cover Ehdr at 0==p_offset\n                unsigned const delta = hdr_u_len;\n                if (ft.id < 0x40) {\n                    // FIXME: ??     ft.addvalue += asl_delta;\n                }\n                if ((off_t)delta == x.size) { // PT_LOAD[0] with ElfXX.Ehdr only\n                    // QBE backend - http://c9x.me/compile/\n                    hdr_u_len = 0;  // no fiddling necessary!\n                    // &ft arg to packExtent will be zero becaue (k != nk_f)\n                }\n                else {\n                    total_in += delta - hdr_u_len;\n                    x.offset += delta;\n                    x.size   -= delta;\n                }\n            }\n            // compressWithFilters() always assumes a \"loader\", so would\n            // throw NotCompressible for small .data Extents, which PowerPC\n            // sometimes marks as PF_X anyway.  So filter only first segment.\n            if (k == nk_f || !is_shlib) {\n                packExtent(x,\n                    (k==nk_f ? &ft : nullptr ), fo, hdr_u_len, 0, true);\n            }\n            else {\n                total_in += x.size;\n            }\n        }\n        else {\n                total_in += x.size;\n        }\n        hdr_u_len = 0;\n        ++nx;\n    }\n    sz_pack2a = fpad4(fo);  // MATCH01\n\n    // Accounting only; ::pack3 will do the compression and output\n    for (k = 0; k < e_phnum; ++k) {\n        total_in += find_LOAD_gap(phdri, k, e_phnum);\n    }\n\n    if (total_in != (u32_t)file_size)\n        throwEOFException();\n\n    return 0;  // omit end-of-compression bhdr for now\n}\n\n// Filter 0x50, 0x51 assume HostPolicy::isLE\nstatic const int *\nARM_getFilters(bool const isBE)\n{\n    static const int f50[] = { 0x50, FT_END };\n    static const int f51[] = { 0x51, FT_END };\n    if (isBE)\n        return f51;\n    return f50;\n}\n\nconst int *\nPackLinuxElf32armBe::getFilters() const\n{\n    return ARM_getFilters(true);\n}\n\nconst int *\nPackLinuxElf32armLe::getFilters() const\n{\n    return ARM_getFilters(false);\n}\n\nconst int *\nPackLinuxElf32mipseb::getFilters() const\n{\n    static const int f_none[] = { FT_END };\n    return f_none;\n}\n\nconst int *\nPackLinuxElf32mipsel::getFilters() const\n{\n    static const int f_none[] = { FT_END };\n    return f_none;\n}\n\n// October 2011: QNX 6.3.0 has no unique signature?\nint PackLinuxElf32::ARM_is_QNX(void)\n{\n    if (Elf32_Ehdr::EM_ARM==get_te16(&ehdri.e_machine)\n    &&  Elf32_Ehdr::ELFDATA2MSB== ehdri.e_ident[Elf32_Ehdr::EI_DATA]\n    &&  Elf32_Ehdr::ELFOSABI_ARM==ehdri.e_ident[Elf32_Ehdr::EI_OSABI]\n    &&  0x100000==(page_mask & get_te32(&phdri[0].p_vaddr))) {\n        Elf32_Phdr const *phdr = phdri;\n        for (int j = get_te16(&ehdri.e_phnum); --j>=0; ++phdr) {\n            if (Elf32_Phdr::PT_INTERP==get_te32(&phdr->p_type)) {\n                char interp[64];\n                unsigned const sz_interp = get_te32(&phdr->p_filesz);\n                unsigned const pos_interp = get_te32(&phdr->p_offset);\n                if (sz_interp <= sizeof(interp)\n                &&  (sz_interp + pos_interp) <= (unsigned)file_size) {\n                    fi->seek(pos_interp, SEEK_SET);\n                    fi->readx(interp, sz_interp);\n                    for (int k = sz_interp - 5; k>=0; --k) {\n                        if (0==memcmp(\"ldqnx\", &interp[k], 5))\n                            return 1;\n                    }\n                }\n            }\n        }\n    }\n    return 0;\n}\n\nvoid PackLinuxElf32::ARM_defineSymbols(Filter const *ft)\n{\n    PackLinuxElf32::defineSymbols(ft);\n\n#define MAP_PRIVATE      2     /* UNIX standard */\n#define MAP_FIXED     0x10     /* UNIX standard */\n#define MAP_ANONYMOUS 0x20     /* UNIX standard */\n#define MAP_PRIVANON     3     /* QNX anonymous private memory */\n    unsigned mflg = MAP_PRIVATE | MAP_ANONYMOUS;\n    if (ARM_is_QNX())\n        mflg = MAP_PRIVANON;\n    linker->defineSymbol(\"MFLG\", mflg);\n}\n\nvoid PackLinuxElf32armLe::defineSymbols(Filter const *ft)\n{\n    ARM_defineSymbols(ft);\n}\n\nvoid PackLinuxElf32armBe::defineSymbols(Filter const *ft)\n{\n    ARM_defineSymbols(ft);\n}\n\nvoid PackLinuxElf64arm::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf64::defineSymbols(ft);\n\n#define MAP_PRIVATE      2     /* UNIX standard */\n#define MAP_FIXED     0x10     /* UNIX standard */\n#define MAP_ANONYMOUS 0x20     /* UNIX standard */\n#define MAP_PRIVANON     3     /* QNX anonymous private memory */\n    unsigned mflg = MAP_PRIVATE | MAP_ANONYMOUS;\n    //if (ARM_is_QNX())\n    //    mflg = MAP_PRIVANON;\n    linker->defineSymbol(\"MFLG\", mflg);\n}\n\nvoid PackLinuxElf32mipseb::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf32::defineSymbols(ft);\n}\n\nvoid PackLinuxElf32mipsel::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf32::defineSymbols(ft);\n}\n\nvoid PackLinuxElf32::pack4(OutputFile *fo, Filter &ft)\n{\n    overlay_offset = xct_off ? xct_off : (sz_elf_hdrs + sizeof(linfo));\n\n    if (opt->o_unix.preserve_build_id) {\n        // calc e_shoff here and write shdrout, then o_shstrtab\n        //NOTE: these are pushed last to ensure nothing is stepped on\n        //for the UPX structure.\n        unsigned const len = fpad4(fo);\n        set_te32(&elfout.ehdr.e_shoff,len);\n\n        int const ssize = sizeof(shdrout);\n\n        shdrout.shdr[2].sh_offset = len+ssize;\n        shdrout.shdr[1].sh_offset = shdrout.shdr[2].sh_offset+shdrout.shdr[2].sh_size;\n\n        fo->write(&shdrout, ssize);\n\n        fo->write(o_shstrtab,shdrout.shdr[2].sh_size);\n        fo->write(buildid_data,shdrout.shdr[1].sh_size);\n    }\n\n    // Cannot pre-round .p_memsz.  If .p_filesz < .p_memsz, then kernel\n    // tries to make .bss, which requires PF_W.\n    // But strict SELinux (or PaX, grSecurity) disallows PF_W with PF_X.\n    set_te32(&elfout.phdr[C_TEXT].p_filesz, sz_pack2 + lsize);\n              elfout.phdr[C_TEXT].p_memsz = elfout.phdr[C_TEXT].p_filesz;\n    super::pack4(fo, ft);  // write PackHeader and overlay_offset\n\n    fo->seek(0, SEEK_SET);\n    if (0!=xct_off) {  // shared library\n        { // Shouldn't this special case be handled earlier?\n            if (overlay_offset < xct_off) {\n                Elf32_Phdr *phdro = (Elf32_Phdr *)(&lowmem[sizeof(Elf32_Ehdr)]);\n                set_te32(&phdro->p_flags, Elf32_Phdr::PF_X | get_te32(&phdro->p_flags));\n            }\n        }\n        fo->rewrite(&lowmem[0], sizeof(ehdri) + e_phnum * sizeof(*phdri));\n        fo->seek(sz_elf_hdrs, SEEK_SET);\n        fo->rewrite(&linfo, sizeof(linfo));\n\n        if (jni_onload_va) {\n            unsigned tmp = sz_pack2 + get_te32(&elfout.phdr[C_TEXT].p_vaddr);\n            tmp |= (Elf32_Ehdr::EM_ARM==e_machine);  // THUMB mode\n            set_te32(&tmp, tmp);\n            fo->seek(ptr_udiff_bytes(&jni_onload_sym->st_value, file_image), SEEK_SET);\n            fo->rewrite(&tmp, sizeof(tmp));\n        }\n    }\n    else {\n        unsigned const reloc = get_te32(&elfout.phdr[C_TEXT].p_vaddr);\n        Elf32_Phdr *phdr = &elfout.phdr[C_NOTE];\n        unsigned const o_phnum = get_te16(&elfout.ehdr.e_phnum);\n        for (unsigned j = 2; j < o_phnum; ++j, ++phdr) {\n            if (PT_NOTE32 == get_te32(&phdr->p_type)) {\n                set_te32(            &phdr->p_vaddr,\n                    reloc + get_te32(&phdr->p_vaddr));\n                set_te32(            &phdr->p_paddr,\n                    reloc + get_te32(&phdr->p_paddr));\n            }\n        }\n        fo->rewrite(&elfout, sizeof(Elf32_Phdr) * o_phnum + sizeof(Elf32_Ehdr));\n        fo->seek(sz_elf_hdrs, SEEK_SET);  // skip over PT_NOTE bodies, if any\n        fo->rewrite(&linfo, sizeof(linfo));\n    }\n}\n\nvoid PackLinuxElf64::pack4(OutputFile *fo, Filter &ft)\n{\n    if (!xct_off) {\n        overlay_offset = sz_elf_hdrs + sizeof(linfo);\n    }\n\n    if (opt->o_unix.preserve_build_id) {\n        // calc e_shoff here and write shdrout, then o_shstrtab\n        //NOTE: these are pushed last to ensure nothing is stepped on\n        //for the UPX structure.\n        unsigned const len = fpad4(fo);\n        set_te64(&elfout.ehdr.e_shoff,len);\n\n        int const ssize = sizeof(shdrout);\n\n        shdrout.shdr[2].sh_offset = len+ssize;\n        shdrout.shdr[1].sh_offset = shdrout.shdr[2].sh_offset+shdrout.shdr[2].sh_size;\n\n        fo->write(&shdrout, ssize);\n\n        fo->write(o_shstrtab,shdrout.shdr[2].sh_size);\n        fo->write(buildid_data,shdrout.shdr[1].sh_size);\n    }\n\n    // Cannot pre-round .p_memsz.  If .p_filesz < .p_memsz, then kernel\n    // tries to make .bss, which requires PF_W.\n    // But strict SELinux (or PaX, grSecurity) disallows PF_W with PF_X.\n    set_te64(&elfout.phdr[C_TEXT].p_filesz, sz_pack2 + lsize);\n              elfout.phdr[C_TEXT].p_memsz = elfout.phdr[C_TEXT].p_filesz;\n    super::pack4(fo, ft);  // write PackHeader and overlay_offset\n\n    fo->seek(0, SEEK_SET);\n    if (0!=xct_off) {  // shared library\n        { // Shouldn't this special case be handled earlier?\n            if (overlay_offset < xct_off) {\n                Elf64_Phdr *phdro = (Elf64_Phdr *)(&lowmem[sizeof(Elf64_Ehdr)]);\n                set_te64(&phdro->p_flags, Elf64_Phdr::PF_X | get_te64(&phdro->p_flags));\n            }\n        }\n        fo->rewrite(&lowmem[0], sizeof(ehdri) + e_phnum * sizeof(Elf64_Phdr));\n        //fo->seek(xct_off, SEEK_SET);  // FIXME\n        //fo->rewrite(&linfo, sizeof(linfo));\n        fo->seek(linfo_off, SEEK_SET);\n        fo->rewrite(&linfo, sizeof(linfo));  // duplicate?\n    }\n    else {\n        if (PT_NOTE64 == get_te64(&elfout.phdr[C_NOTE].p_type)) {\n            upx_uint64_t const reloc = get_te64(&elfout.phdr[C_TEXT].p_vaddr);\n            set_te64(            &elfout.phdr[C_NOTE].p_vaddr,\n                reloc + get_te64(&elfout.phdr[C_NOTE].p_vaddr));\n            set_te64(            &elfout.phdr[C_NOTE].p_paddr,\n                reloc + get_te64(&elfout.phdr[C_NOTE].p_paddr));\n            fo->rewrite(&elfout, sz_elf_hdrs);\n            // FIXME   fo->rewrite(&elfnote, sizeof(elfnote));\n        }\n        else {\n            fo->rewrite(&elfout, sz_elf_hdrs);\n        }\n        fo->rewrite(&linfo, sizeof(linfo));\n    }\n}\n\nvoid\nPackLinuxElf32::unRel32(\n    unsigned dt_rel,\n    Elf32_Rel *rel0,\n    unsigned relsz,\n    MemBuffer &ptload1,\n    unsigned const load_off,\n    OutputFile *fo\n)\n{\n    Elf32_Rel *rel = rel0;\n    for (int k = relsz / sizeof(Elf32_Rel); --k >= 0; ++rel) {\n        unsigned r_offset = get_te32(&rel->r_offset);\n        unsigned r_info   = get_te32(&rel->r_info);\n        unsigned r_type = ELF32_R_TYPE(r_info);\n        if (xct_off <= r_offset) {\n            set_te32(&rel->r_offset, r_offset - asl_delta);\n        }\n        if (Elf32_Ehdr::EM_ARM == e_machine) {\n            if (R_ARM_RELATIVE == r_type) {\n                unsigned d = r_offset - load_off - asl_delta;\n                unsigned w = get_te32(&ptload1[d]);\n                if (xct_off <= w) {\n                    set_te32(&ptload1[d], w - asl_delta);\n                }\n            }\n            if (R_ARM_JUMP_SLOT == r_type) {\n                ++n_jmp_slot;\n                // .rel.plt contains offset of the \"first time\" target\n                unsigned d = r_offset - load_off - asl_delta;\n                if (plt_off > d) {\n                    plt_off = d;\n                }\n                unsigned w = get_te32(&ptload1[d]);\n                if (xct_off <= w) {\n                    set_te32(&ptload1[d], w - asl_delta);\n                }\n            }\n        }\n    }\n    fo->seek(dt_rel, SEEK_SET);\n    fo->rewrite(rel0, relsz);\n}\n\nvoid\nPackLinuxElf64::unRela64(\n    upx_uint64_t dt_rela,\n    Elf64_Rela *rela0,\n    unsigned relasz,\n    MemBuffer &ptload1,\n    upx_uint64_t const load_off,\n    upx_uint64_t old_dtinit,\n    OutputFile *fo\n)\n{\n    Elf64_Rela *rela = rela0;\n    for (int k = relasz / sizeof(Elf64_Rela); --k >= 0; ++rela) {\n        upx_uint64_t r_addend = get_te64(&rela->r_addend);\n        if (xct_off <= r_addend) {\n            r_addend -= asl_delta;\n            set_te64(&rela->r_addend, r_addend);\n        }\n\n        upx_uint64_t r_offset = get_te64(&rela->r_offset);\n        if (xct_off <= r_offset) {\n            r_offset -= asl_delta;\n            set_te64(&rela->r_offset, r_offset);\n        }\n\n        upx_uint64_t r_info   = get_te64(&rela->r_info);\n        unsigned r_type = ELF64_R_TYPE(r_info);\n        if (Elf64_Ehdr::EM_AARCH64 == e_machine) {\n            if (R_AARCH64_RELATIVE == r_type) {\n                if (old_dtinit == r_addend) {\n                    set_te64(&ptload1[r_offset - load_off], r_addend);\n                }\n            }\n            if (R_AARCH64_JUMP_SLOT == r_type) {\n                ++n_jmp_slot;\n                // .rela.plt contains offset of the \"first time\" target\n                upx_uint64_t d = r_offset - load_off;\n                if (plt_off > d) {\n                    plt_off = d;\n                }\n                upx_uint64_t w = get_te64(&ptload1[d]);\n                if (xct_off <= w) {\n                    set_te64(&ptload1[d], w - asl_delta);\n                }\n            }\n        }\n    }\n    fo->seek(dt_rela, SEEK_SET);\n    fo->rewrite(rela0, relasz);\n}\n\n// File layout of compressed .so (new-style: 3 or 4 PT_LOAD) shared library:\n// 1. new Elf headers: Ehdr, PT_LOAD (r-x), PT_LOAD (rw-, if any), non-PT_LOAD Phdrs\n// 2. Space for (original - 2) PT_LOAD Phdr\n// 3. Remaining original contents of file below xct_off\n// xct_off: (&lowest eXecutable Shdr section; in original PT_LOAD[0] or [1])\n// 4. l_info (12 bytes)\n// overlay_offset:\n// 5. p_info (12 bytes)\n// 6. compressed original Elf headers (prefixed by b_info as usual)\n// 7. compressed remainder of PT_LOAD above xct_off\n// 8. compressed read-only PT_LOAD above xct_off (if any)\n// 9. uncompressed Read-Write PT_LOAD (slide down N pages)\n// 10. int[6] tables for UPX runtime de-compressor\n// (new) DT_INIT:\n// 11. UPX runtime de-compressing loader\n// 12. compressed gaps between PT_LOADs (and EOF) above xct_off\n// 13. 32-byte pack header\n// 14. 4-byte overlay offset\n\nvoid PackLinuxElf64::un_shlib_1(\n    OutputFile *const fo,\n    MemBuffer &o_elfhdrs,\n    unsigned &c_adler,\n    unsigned &u_adler,\n    Elf64_Phdr const *const dynhdr,\n    unsigned const orig_file_size,\n    unsigned const szb_info\n)\n{\n    // Below xct_off is not compressed (for benefit of rtld.)\n    fi->seek(0, SEEK_SET);\n    unsigned const limit_dynhdr = get_te64(&dynhdr->p_offset) + get_te64(&dynhdr->p_filesz);\n    fi->readx(ibuf, limit_dynhdr);\n    overlay_offset -= sizeof(linfo);\n    loader_offset = 0;\n    xct_off = overlay_offset;\n    e_shoff = get_te64(&ehdri.e_shoff);\n    if (e_shoff && e_shnum\n    &&  (e_shoff + sizeof(Elf64_Shdr) * e_shnum) <= limit_dynhdr) { // --android-shlib\n        ibuf.subref(\"bad .e_shoff %#lx for %#lx\", e_shoff, sizeof(Elf64_Shdr) * e_shnum);\n        shdri = (Elf64_Shdr /*const*/ *)ibuf.subref(\n            \"bad Shdr table\", e_shoff, sizeof(Elf64_Shdr)*e_shnum);\n        upx_uint64_t xct_off2 = get_te64(&shdri->sh_offset);\n        if (e_shoff == xct_off2) {\n            xct_off = e_shoff;\n        }\n        // un-Relocate dynsym (DT_SYMTAB) which is below xct_off\n        dynstr = (char const *)elf_find_dynamic(Elf64_Dyn::DT_STRTAB);\n        sec_dynsym = elf_find_section_type(Elf64_Shdr::SHT_DYNSYM);\n        if (sec_dynsym) {\n            upx_uint64_t const off_dynsym = get_te64(&sec_dynsym->sh_offset);\n            upx_uint64_t const sz_dynsym  = get_te64(&sec_dynsym->sh_size);\n            if (orig_file_size < sz_dynsym\n            ||  orig_file_size < off_dynsym\n            || (orig_file_size - off_dynsym) < sz_dynsym) {\n                throwCantUnpack(\"bad SHT_DYNSYM\");\n            }\n            Elf64_Sym *const sym0 = (Elf64_Sym *)ibuf.subref(\n                \"bad dynsym\", off_dynsym, sz_dynsym);\n            Elf64_Sym *sym = sym0;\n            for (int j = sz_dynsym / sizeof(Elf64_Sym); --j>=0; ++sym) {\n                upx_uint64_t symval = get_te64(&sym->st_value);\n                unsigned symsec = get_te16(&sym->st_shndx);\n                if (Elf64_Sym::SHN_UNDEF != symsec\n                &&  Elf64_Sym::SHN_ABS   != symsec\n                &&  xct_off <= symval) {\n                    set_te64(&sym->st_value, symval - asl_delta);\n                }\n                if (Elf64_Sym::SHN_ABS == symsec && xct_off <= symval) {\n                    adjABS(sym, 0u - asl_delta);\n                }\n            }\n        }\n    }\n\n    // Decompress first Extent.  Old style covers [0, xct_off)\n    // which includes rtld constant data and eXecutable app code below DT_INIT.\n    // In old style, the first compressed Extent is redundant\n    // except for the compressed original Elf headers.\n    // New style covers just Elf headers: the rest below xct_off is\n    // rtld constant data: DT_*HASH, DT_SYMTAB, DT_STRTAB, etc.\n    // New style puts eXecutable app code in second PT_LOAD\n    // in order to mark Elf headers and rtld data as non-eXecutable.\n    fi->seek(xct_off, SEEK_SET);\n    struct {\n        struct l_info l;\n        struct p_info p;\n        struct b_info b;\n    } hdr;\n    fi->readx(&hdr, sizeof(hdr));\n    fi->seek(-(off_t)sizeof(struct b_info), SEEK_CUR);\n    if (hdr.l.l_magic != UPX_MAGIC_LE32\n    ||  hdr.l.l_lsize != (unsigned)lsize\n    ||  hdr.p.p_filesize != ph.u_file_size) {\n        throwCantUnpack(\"corrupt l_info/p_info\");\n    }\n    ph.c_len = get_te32(&hdr.b.sz_cpr);\n    ph.u_len = get_te32(&hdr.b.sz_unc);\n\n    unpackExtent(ph.u_len, fo,\n        c_adler, u_adler, false, szb_info);\n\n    // FIXME: what if no output file?  test mode (\"-t\") or list mode (\"-l\")\n    if (fo) {\n        InputFile u_fi;\n        // Recover original Elf headers from current output file\n        u_fi.open(fo->getName(), 0);\n        u_fi.readx((void *)o_elfhdrs,o_elfhdrs.getSize());\n        u_fi.close();\n\n        // Re-generate unmodified rtld data below xct_off\n        fo->write(&ibuf[ph.u_len], xct_off - ph.u_len);\n    }\n\n    Elf64_Phdr const *o_phdr = (Elf64_Phdr const *)(1+ (Elf64_Ehdr const *)(void const *)o_elfhdrs);\n    // Handle compressed PT_LOADs (must not have PF_W)\n    for (unsigned j = 0; j < e_phnum; ++j, ++o_phdr) {\n        unsigned type = get_te32(&o_phdr->p_type);\n        unsigned flags = get_te32(&o_phdr->p_flags);\n        if (PT_LOAD64 != type || Elf64_Phdr::PF_W & flags) {\n            continue;\n        }\n        unsigned vaddr = get_te64(&o_phdr->p_vaddr);\n        if (xct_off <= vaddr) { // not first PT_LOAD must position its output\n            if (fo) {\n                unsigned o_offset = get_te64(&o_phdr->p_offset);\n                fo->seek(o_offset, SEEK_SET);\n            }\n        }\n        // Peek at b_info to find sizes\n        fi->readx(&hdr.b, sizeof(hdr.b));\n        fi->seek(-(off_t)sizeof(struct b_info), SEEK_CUR);\n        ph.c_len = get_te32(&hdr.b.sz_cpr);\n        ph.u_len = get_te32(&hdr.b.sz_unc);\n        unpackExtent(ph.u_len, fo, c_adler, u_adler, false, szb_info);\n    }\n    funpad4(fi);\n    loader_offset = fi->tell();\n\n    // Handle PT_LOAD with PF_W: writeable, so not compressed.  \"Slide\"\n    o_phdr = (Elf64_Phdr const *)(1+ (Elf64_Ehdr const *)(void const *)o_elfhdrs);\n    Elf64_Phdr const *i_phdr = phdri;\n    for (unsigned j = 0; j < e_phnum; ++j, ++o_phdr, ++i_phdr) {\n        unsigned type = get_te32(&o_phdr->p_type);\n        unsigned flags = get_te32(&o_phdr->p_flags);\n        if (PT_LOAD64 != type || !(Elf64_Phdr::PF_W & flags)) {\n            continue;\n        }\n        unsigned filesz = get_te64(&o_phdr->p_filesz);\n        unsigned o_offset = get_te64(&o_phdr->p_offset);\n        unsigned i_offset = get_te64(&i_phdr->p_offset);\n        fi->seek(i_offset, SEEK_SET);\n        fi->readx(ibuf, filesz);\n        total_in += filesz;\n        if (fo) {\n            fo->seek(o_offset, SEEK_SET);\n            fo->write(ibuf, filesz);\n        }\n        total_out = filesz + o_offset;  // high-water mark\n    }\n\n    // Gaps between PT_LOAD will be handled by ::unpack()\n\n    // position fi at loader offset\n    fi->seek(loader_offset, SEEK_SET);\n}\n\nvoid PackLinuxElf64::un_DT_INIT(\n    unsigned old_dtinit,\n    Elf64_Phdr const *const phdro,\n    Elf64_Phdr const *const dynhdr,  // in phdri\n    OutputFile *fo,\n    unsigned is_asl\n)\n{\n    // DT_INIT must be restored.\n    // If android_shlib, then the asl_delta relocations must be un-done.\n    upx_uint64_t dt_pltrelsz(0), dt_jmprel(0);\n    upx_uint64_t dt_relasz(0), dt_rela(0);\n    upx_uint64_t const dyn_len = get_te64(&dynhdr->p_filesz);\n    upx_uint64_t const dyn_off = get_te64(&dynhdr->p_offset);\n    if ((unsigned long)file_size < (dyn_len + dyn_off)) {\n        char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad PT_DYNAMIC .p_filesz %#lx\", (long unsigned)dyn_len);\n        throwCantUnpack(msg);\n    }\n    fi->seek(dyn_off, SEEK_SET);\n    fi->readx(ibuf, dyn_len);\n    Elf64_Dyn *dyn = (Elf64_Dyn *)(void *)ibuf;\n    dynseg = dyn; invert_pt_dynamic(dynseg,\n        umin(dyn_len, file_size - dyn_off));\n    for (unsigned j2= 0; j2 < dyn_len; ++dyn, j2 += sizeof(*dyn)) {\n        upx_uint64_t const tag = get_te64(&dyn->d_tag);\n        upx_uint64_t       val = get_te64(&dyn->d_val);\n        if (is_asl) switch (tag) {\n        case Elf64_Dyn::DT_RELASZ:   { dt_relasz   = val; } break;\n        case Elf64_Dyn::DT_RELA:     { dt_rela     = val; } break;\n        case Elf64_Dyn::DT_PLTRELSZ: { dt_pltrelsz = val; } break;\n        case Elf64_Dyn::DT_JMPREL:   { dt_jmprel   = val; } break;\n\n        case Elf64_Dyn::DT_PLTGOT:\n        case Elf64_Dyn::DT_PREINIT_ARRAY:\n        case Elf64_Dyn::DT_INIT_ARRAY:\n        case Elf64_Dyn::DT_FINI_ARRAY:\n        case Elf64_Dyn::DT_FINI: {\n            set_te64(&dyn->d_val, val - asl_delta);\n        }; break;\n        } // end switch() on tag when is_asl\n        if (upx_dt_init == tag) {\n            if (Elf64_Dyn::DT_INIT == tag) {\n                set_te64(&dyn->d_val, old_dtinit);\n                if (!old_dtinit) { // compressor took the slot\n                    dyn->d_tag = Elf64_Dyn::DT_NULL;\n                    dyn->d_val = 0;\n                }\n            }\n            else if (Elf64_Dyn::DT_INIT_ARRAY    == tag\n            ||       Elf64_Dyn::DT_PREINIT_ARRAY == tag) {\n                // The slot must have a R_*_RELATIVE relocation (is_shlib,\n                // after all), but ElfXX_Rela ignores the initial contents!\n                // So changing the value will get ignored.  Do it anyway.\n                // FIXME: we must fix the Rela ?\n                Elf64_Phdr const *phdr = phdro;\n                for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n                    upx_uint64_t vaddr = get_te64(&phdr->p_vaddr);\n                    upx_uint64_t filesz = get_te64(&phdr->p_filesz);\n                    if ((val - vaddr) < filesz) {\n                        upx_uint64_t offset = get_te64(&phdr->p_offset);\n                        upx_uint64_t oldval;\n                        // Counter-act unRel64 if asl_delta\n                        set_te64(&oldval, old_dtinit + (is_asl ? asl_delta : 0));\n                        // FIXME? the in-memory copy?\n                        if (fo) {\n                            fo->seek((val - vaddr) + offset, SEEK_SET);\n                            fo->write(&oldval, sizeof(oldval));\n                        }\n                        break;\n                    }\n                }\n            }\n        }\n    }\n    if (fo) { // Write updated dt_*.val\n        upx_uint64_t dyn_offo = get_te64(&phdro[dynhdr - phdri].p_offset);\n        fo->seek(dyn_offo, SEEK_SET);\n        fo->rewrite(ibuf, dyn_len);\n    }\n    if (is_asl) {\n        lowmem.alloc(xct_off);\n        fi->seek(0, SEEK_SET);\n        fi->read(lowmem, xct_off);  // contains relocation tables\n        if (dt_relasz && dt_rela) {\n            Elf64_Rela *const rela0 = (Elf64_Rela *)lowmem.subref(\n                \"bad Rela offset\", dt_rela, dt_relasz);\n            unRela64(dt_rela, rela0, dt_relasz, ibuf, load_va, old_dtinit, fo);\n        }\n        if (dt_pltrelsz && dt_jmprel) { // FIXME:  overlap w/ DT_REL ?\n            Elf64_Rela *const jmp0 = (Elf64_Rela *)lowmem.subref(\n                \"bad Jmprel offset\", dt_jmprel, dt_pltrelsz);\n            unRela64(dt_jmprel, jmp0, dt_pltrelsz, ibuf, load_va, old_dtinit, fo);\n        }\n        // Modified relocation tables are re-written by unRela64\n    }\n}\n\nvoid PackLinuxElf64::unpack(OutputFile *fo)\n{\n    if (e_phoff != sizeof(Elf64_Ehdr)) {// Phdrs not contiguous with Ehdr\n        throwCantUnpack(\"bad e_phoff\");\n    }\n    unsigned const c_phnum = get_te16(&ehdri.e_phnum);\n    unsigned u_phnum = 0;\n    upx_uint64_t old_dtinit = 0;\n    unsigned is_asl = 0;  // is Android Shared Library\n\n    unsigned szb_info = sizeof(b_info);\n    {\n        upx_uint64_t const e_entry = get_te64(&ehdri.e_entry);\n        if (e_entry < 0x401180\n        &&  get_te16(&ehdri.e_machine)==Elf64_Ehdr::EM_386) { /* old style, 8-byte b_info */\n            szb_info = 2*sizeof(unsigned);\n        }\n    }\n\n    fi->seek(overlay_offset - sizeof(l_info), SEEK_SET);\n    fi->readx(&linfo, sizeof(linfo));\n    lsize = get_te16(&linfo.l_lsize);\n    if (UPX_MAGIC_LE32 != get_le32(&linfo.l_magic)) {\n        throwCantUnpack(\"l_info corrupted\");\n    }\n    p_info hbuf;  fi->readx(&hbuf, sizeof(hbuf));\n    unsigned orig_file_size = get_te32(&hbuf.p_filesize);\n    blocksize = get_te32(&hbuf.p_blocksize);\n    if ((u32_t)file_size > orig_file_size || blocksize > orig_file_size\n        || !mem_size_valid(1, blocksize, OVERHEAD))\n        throwCantUnpack(\"p_info corrupted\");\n\n    ibuf.alloc(blocksize + OVERHEAD);\n    b_info bhdr; memset(&bhdr, 0, sizeof(bhdr));\n    fi->readx(&bhdr, szb_info);\n    ph.u_len = get_te32(&bhdr.sz_unc);\n    ph.c_len = get_te32(&bhdr.sz_cpr);\n    if (ph.c_len > (unsigned)file_size || ph.c_len == 0 || ph.u_len == 0\n    ||  ph.u_len > orig_file_size)\n        throwCantUnpack(\"b_info corrupted\");\n    ph.filter_cto = bhdr.b_cto8;\n\n    MemBuffer u(ph.u_len);\n    Elf64_Ehdr *const ehdr = (Elf64_Ehdr *)&u[0];\n    Elf64_Phdr const *phdr = nullptr;\n    total_in = 0;\n    total_out = 0;\n    unsigned c_adler = upx_adler32(nullptr, 0);\n    unsigned u_adler = upx_adler32(nullptr, 0);\n\n    unsigned is_shlib = 0;\n    loader_offset = 0;\n    MemBuffer o_elfhdrs;\n    Elf64_Phdr const *const dynhdr = elf_find_ptype(Elf64_Phdr::PT_DYNAMIC, phdri, c_phnum);\n    if (dynhdr) {\n        upx_uint64_t dyn_offset = get_te64(&dynhdr->p_offset);\n        upx_uint64_t dyn_filesz = get_te64(&dynhdr->p_filesz);\n        dynseg = (Elf64_Dyn const *)ibuf.subref(\"bad DYNAMIC\", dyn_offset, dyn_filesz);\n        // Packed shlib? (ET_DYN without -fPIE)\n        if (!(Elf64_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf64_Dyn::DT_FLAGS_1))) {\n            is_shlib = 1;\n            u_phnum = get_te16(&ehdri.e_phnum);\n            o_elfhdrs.alloc(sz_elf_hdrs);\n            un_shlib_1(fo, o_elfhdrs, c_adler, u_adler, dynhdr, orig_file_size, szb_info);\n            *ehdr = ehdri;\n        }\n    }\n    else { // main executable\n        // Uncompress Ehdr and Phdrs: info for control of unpacking\n        if (ibuf.getSize() < ph.c_len)\n            throwCompressedDataViolation();\n        fi->readx(ibuf, ph.c_len);\n        decompress(ibuf, (upx_byte *)ehdr, false);\n        if (ehdr->e_type   !=ehdri.e_type\n        ||  ehdr->e_machine!=ehdri.e_machine\n        ||  ehdr->e_version!=ehdri.e_version\n            // less strict for EM_PPC64 to workaround earlier bug\n        ||  !( ehdr->e_flags==ehdri.e_flags\n            || Elf64_Ehdr::EM_PPC64 == get_te16(&ehdri.e_machine))\n        ||  ehdr->e_ehsize !=ehdri.e_ehsize\n            // check EI_MAG[0-3], EI_CLASS, EI_DATA, EI_VERSION\n        ||  memcmp(ehdr->e_ident, ehdri.e_ident, Elf64_Ehdr::EI_OSABI)) {\n            throwCantUnpack(\"ElfXX_Ehdr corrupted\");\n        }\n        // Rewind: prepare for data phase\n        fi->seek(- (off_t) (szb_info + ph.c_len), SEEK_CUR);\n\n        u_phnum = get_te16(&ehdr->e_phnum);\n#define MAX_ELF_HDR 1024\n        if ((umin64(MAX_ELF_HDR, ph.u_len) - sizeof(Elf64_Ehdr))/sizeof(Elf64_Phdr) < u_phnum) {\n            throwCantUnpack(\"bad compressed e_phnum\");\n        }\n        o_elfhdrs.alloc(sizeof(Elf64_Ehdr) + u_phnum * sizeof(Elf64_Phdr));\n        memcpy(o_elfhdrs, ehdr, o_elfhdrs.getSize());\n#undef MAX_ELF_HDR\n\n        // Decompress each PT_LOAD.\n        bool first_PF_X = true;\n        phdr = (Elf64_Phdr *) (void *) (1+ ehdr);  // uncompressed\n        for (unsigned j=0; j < u_phnum; ++phdr, ++j) {\n            if (PT_LOAD64==get_te32(&phdr->p_type)) {\n                unsigned const filesz = get_te64(&phdr->p_filesz);\n                unsigned const offset = get_te64(&phdr->p_offset);\n                if (fo)\n                    fo->seek(offset, SEEK_SET);\n                if (Elf64_Phdr::PF_X & get_te32(&phdr->p_flags)) {\n                    unpackExtent(filesz, fo,\n                        c_adler, u_adler, first_PF_X, szb_info);\n                    first_PF_X = false;\n                }\n                else {\n                    unpackExtent(filesz, fo,\n                        c_adler, u_adler, false, szb_info);\n                }\n            }\n        }\n    }\n\n    phdr = phdri;\n    load_va = 0;\n    for (unsigned j=0; j < c_phnum; ++j) {\n        if (PT_LOAD64==get_te32(&phdr->p_type)) {\n            load_va = get_te64(&phdr->p_vaddr);\n            break;\n        }\n    }\n    unsigned d_info[6];\n    unsigned sz_d_info = sizeof(d_info);\n    if (!is_shlib) {\n        if (get_te32(&phdri[0].p_flags) & Elf64_Phdr::PF_X) {\n            // Old style, such as upx-3.91 thru upx-3.95\n            switch (this->e_machine) { // FIXME: missing 32-bit EM_386 EM_ARM EM_PPC\n                default: {\n                    char msg[40]; snprintf(msg, sizeof(msg),\n                        \"Unknown architecture %d\", this->e_machine);\n                    throwCantUnpack(msg);\n                }; break;\n                case Elf64_Ehdr::EM_AARCH64: sz_d_info = 4 * sizeof(unsigned); break;\n                case Elf64_Ehdr::EM_PPC64:   sz_d_info = 3 * sizeof(unsigned); break;\n                case Elf64_Ehdr::EM_X86_64:  sz_d_info = 2 * sizeof(unsigned); break;\n            }\n        }\n        loader_offset = get_te64(&ehdri.e_entry) - load_va - sz_d_info;\n    }\n\n    if (0x1000==get_te64(&phdri[0].p_filesz)  // detect C_BASE style\n    &&  0==get_te64(&phdri[1].p_offset)\n    &&  0==get_te64(&phdri[0].p_offset)\n    &&     get_te64(&phdri[1].p_filesz) == get_te64(&phdri[1].p_memsz)) {\n        fi->seek(up4(get_te64(&phdr[1].p_memsz)), SEEK_SET);  // past the loader\n    }\n    else if (is_shlib\n    ||  ((unsigned)(get_te64(&ehdri.e_entry) - load_va) + up4(lsize) +\n                ph.getPackHeaderSize() + sizeof(overlay_offset))\n            < up4(file_size)) {\n        // Loader is not at end; skip past it.\n        if (loader_offset) {\n            fi->seek(loader_offset, SEEK_SET);\n        }\n        else {\n            funpad4(fi);  // MATCH01\n        }\n        fi->readx(d_info, sz_d_info);\n        if (is_shlib && 0==old_dtinit) {\n            old_dtinit = get_te32(&d_info[2 + (0==d_info[0])]);\n            is_asl = 1u& get_te32(&d_info[0 + (0==d_info[0])]);\n        }\n        fi->seek(lsize - sz_d_info, SEEK_CUR);\n    }\n\n    // The gaps between PT_LOAD and after last PT_LOAD\n    phdr = (Elf64_Phdr const *)(1+ (Elf64_Ehdr const *)(void const *)o_elfhdrs);\n    upx_uint64_t hi_offset(0);\n    for (unsigned j = 0; j < u_phnum; ++j) {\n        if (PT_LOAD64==phdr[j].p_type\n        &&  hi_offset < phdr[j].p_offset)\n            hi_offset = phdr[j].p_offset;\n    }\n    for (unsigned j = 0; j < u_phnum; ++j) {\n        unsigned const size = find_LOAD_gap(phdr, j, u_phnum);\n        if (size) {\n            unsigned const where = get_te64(&phdr[j].p_offset) +\n                                   get_te64(&phdr[j].p_filesz);\n            if (fo)\n                fo->seek(where, SEEK_SET);\n            unpackExtent(size, fo,\n                c_adler, u_adler, false, szb_info,\n                is_shlib && ((phdr[j].p_offset != hi_offset)));\n                // FIXME: should not depend on is_shlib ?\n        }\n    }\n\n    // check for end-of-file\n    fi->readx(&bhdr, szb_info);\n    unsigned const sz_unc = ph.u_len = get_te32(&bhdr.sz_unc);\n\n    if (sz_unc == 0) { // uncompressed size 0 -> EOF\n        // note: magic is always stored le32\n        unsigned const sz_cpr = get_le32(&bhdr.sz_cpr);\n        if (sz_cpr != UPX_MAGIC_LE32)  // sz_cpr must be h->magic\n            throwCompressedDataViolation();\n    }\n    else { // extra bytes after end?\n        throwCompressedDataViolation();\n    }\n\n    if (is_shlib) {\n        un_DT_INIT(old_dtinit, (Elf64_Phdr *)(1+ (Elf64_Ehdr *)(void *)o_elfhdrs), dynhdr, fo, is_asl);\n    }\n\n    // update header with totals\n    ph.c_len = total_in;\n    ph.u_len = total_out;\n\n    // all bytes must be written\n    if (fo && total_out != orig_file_size)\n        throwEOFException();\n\n    // finally test the checksums\n    if (ph.c_adler != c_adler || ph.u_adler != u_adler)\n        throwChecksumError();\n}\n\n\n/*************************************************************************\n//\n**************************************************************************/\n\nPackLinuxElf32x86::PackLinuxElf32x86(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_386;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf32x86::~PackLinuxElf32x86()\n{\n}\n\nint PackLinuxElf32x86::canUnpack() // bool, except -1: format known, but not packed\n{\n    if (super::canUnpack()) {\n        return true;\n    }\n    return false;\n}\n\nLinker* PackLinuxElf32x86::newLinker() const\n{\n    return new ElfLinkerX86;\n}\n\nPackBSDElf32x86::PackBSDElf32x86(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_386;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2LSB;\n}\n\nPackBSDElf32x86::~PackBSDElf32x86()\n{\n}\n\nPackFreeBSDElf32x86::PackFreeBSDElf32x86(InputFile *f) : super(f)\n{\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_FREEBSD;\n}\n\nPackFreeBSDElf32x86::~PackFreeBSDElf32x86()\n{\n}\n\nPackNetBSDElf32x86::PackNetBSDElf32x86(InputFile *f) : super(f)\n{\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_NETBSD;\n    osabi_note = \"NetBSD\";\n}\n\nPackNetBSDElf32x86::~PackNetBSDElf32x86()\n{\n}\n\nPackOpenBSDElf32x86::PackOpenBSDElf32x86(InputFile *f) : super(f)\n{\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_OPENBSD;\n    osabi_note = \"OpenBSD\";\n}\n\nPackOpenBSDElf32x86::~PackOpenBSDElf32x86()\n{\n}\n\nint const *\nPackLinuxElf32x86::getFilters() const\n{\n    static const int filters[] = {\n        0x49, 0x46,\n// FIXME 2002-11-11: We use stub/fold_elf86.asm, which calls the\n// decompressor multiple times, and unfilter is independent of decompress.\n// Currently only filters 0x49, 0x46, 0x80..0x87 can handle this;\n// and 0x80..0x87 are regarded as \"untested\".\n#if 0\n        0x26, 0x24, 0x11, 0x14, 0x13, 0x16, 0x25, 0x15, 0x12,\n#endif\n#if 0\n        0x83, 0x36, 0x26,\n              0x86, 0x80,\n        0x84, 0x87, 0x81,\n        0x82, 0x85,\n        0x24, 0x16, 0x13, 0x14, 0x11, 0x25, 0x15, 0x12,\n#endif\n    FT_END };\n    return filters;\n}\n\nPackLinuxElf32armLe::PackLinuxElf32armLe(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_ARM;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_ARM;\n}\n\nPackLinuxElf32armLe::~PackLinuxElf32armLe()\n{\n}\n\nPackLinuxElf32mipseb::PackLinuxElf32mipseb(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_MIPS;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2MSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf32mipseb::~PackLinuxElf32mipseb()\n{\n}\n\nPackLinuxElf32mipsel::PackLinuxElf32mipsel(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_MIPS;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf32mipsel::~PackLinuxElf32mipsel()\n{\n}\n\nLinker* PackLinuxElf32armLe::newLinker() const\n{\n    return new ElfLinkerArmLE();\n}\n\nLinker* PackLinuxElf32mipseb::newLinker() const\n{\n    return new ElfLinkerMipsBE();\n}\n\nLinker* PackLinuxElf32mipsel::newLinker() const\n{\n    return new ElfLinkerMipsLE();\n}\n\nPackLinuxElf32armBe::PackLinuxElf32armBe(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_ARM;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2MSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_ARM;\n}\n\nPackLinuxElf32armBe::~PackLinuxElf32armBe()\n{\n}\n\nLinker* PackLinuxElf32armBe::newLinker() const\n{\n    return new ElfLinkerArmBE();\n}\n\nunsigned\nPackLinuxElf32::elf_get_offset_from_address(unsigned addr) const\n{\n    Elf32_Phdr const *phdr = phdri;\n    int j = e_phnum;\n    for (; --j>=0; ++phdr) if (is_LOAD32(phdr)) {\n        unsigned const t = addr - get_te32(&phdr->p_vaddr);\n        if (t < get_te32(&phdr->p_filesz)) {\n            unsigned const p_offset = get_te32(&phdr->p_offset);\n            if ((u32_t)file_size <= p_offset) { // FIXME: weak\n                char msg[40]; snprintf(msg, sizeof(msg),\n                    \"bad Elf32_Phdr[%d].p_offset %x\",\n                    -1+ e_phnum - j, p_offset);\n                throwCantPack(msg);\n            }\n            return t + p_offset;\n        }\n    }\n    return 0;\n}\n\nu32_t  // returns .p_offset\nPackLinuxElf32::check_pt_load(Elf32_Phdr const *const phdr)\n{\n    u32_t filesz = get_te32(&phdr->p_filesz);\n    u32_t offset = get_te32(&phdr->p_offset), offend = filesz + offset;\n    u32_t vaddr  = get_te32(&phdr->p_vaddr);\n    u32_t paddr  = get_te32(&phdr->p_paddr);\n    u32_t align  = get_te32(&phdr->p_align);\n\n    if ((-1+ align) & (paddr ^ vaddr)\n    ||  (u32_t)file_size <= (u32_t)offset\n    ||  (u32_t)file_size <  (u32_t)offend\n    ||  (u32_t)file_size <= (u32_t)filesz) {\n        char msg[50]; snprintf(msg, sizeof(msg), \"bad PT_LOAD phdr[%u]\",\n            (unsigned)(phdr - phdri));\n        throwCantPack(msg);\n    }\n    return offset;\n}\n\nElf32_Dyn const *\nPackLinuxElf32::elf_has_dynamic(unsigned int key) const\n{\n    Elf32_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; Elf32_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te32(&dynp->d_tag)==key) {\n        return dynp;\n    }\n    return nullptr;\n}\n\nunsigned  // checked .p_offset; sz_dynseg set\nPackLinuxElf32::check_pt_dynamic(Elf32_Phdr const *const phdr)\n{\n    unsigned t = get_te32(&phdr->p_offset), s = sizeof(Elf32_Dyn) + t;\n    unsigned vaddr = get_te32(&phdr->p_vaddr);\n    unsigned filesz = get_te32(&phdr->p_filesz), memsz = get_te32(&phdr->p_memsz);\n    unsigned align = get_te32(&phdr->p_align);\n    if (file_size_u < t || s < t\n    ||  file_size_u < filesz\n    ||  file_size_u < (filesz + t)\n    ||  t < (e_phnum*sizeof(Elf32_Phdr) + sizeof(Elf32_Ehdr))\n    ||  (3 & t) || (7 & (filesz | memsz))  // .balign 4; 8==sizeof(Elf32_Dyn)\n    ||  (-1+ align) & (t ^ vaddr)\n    ||  file_size_u <= memsz\n    ||  filesz < sizeof(Elf32_Dyn)\n    ||  memsz  < sizeof(Elf32_Dyn)\n    ||  filesz < memsz) {\n        char msg[50]; snprintf(msg, sizeof(msg), \"bad PT_DYNAMIC phdr[%u]\",\n            (unsigned)(phdr - phdri));\n        throwCantPack(msg);\n    }\n    sz_dynseg = memsz;\n    return t;\n}\n\nvoid const *\nPackLinuxElf32::elf_find_dynamic(unsigned int key) const\n{\n    Elf32_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; (unsigned)((char const *)dynp - (char const *)dynseg) < sz_dynseg\n            && Elf32_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te32(&dynp->d_tag)==key) {\n        unsigned const t= elf_get_offset_from_address(get_te32(&dynp->d_val));\n        if (t && t < (unsigned)file_size) {\n            return t + file_image;\n        }\n        break;\n    }\n    return nullptr;\n}\n\nupx_uint64_t\nPackLinuxElf32::elf_unsigned_dynamic(unsigned int key) const\n{\n    Elf32_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; (unsigned)((char const *)dynp - (char const *)dynseg) < sz_dynseg\n            && Elf32_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te32(&dynp->d_tag)==key) {\n        return get_te32(&dynp->d_val);\n    }\n    return 0;\n}\n\nupx_uint64_t\nPackLinuxElf64::elf_get_offset_from_address(upx_uint64_t addr) const\n{\n    Elf64_Phdr const *phdr = phdri;\n    int j = e_phnum;\n    for (; --j>=0; ++phdr) if (PT_LOAD64 == get_te32(&phdr->p_type)) {\n        upx_uint64_t const t = addr - get_te64(&phdr->p_vaddr);\n        if (t < get_te64(&phdr->p_filesz)) {\n            upx_uint64_t const p_offset = get_te64(&phdr->p_offset);\n            if ((u64_t)file_size <= p_offset) { // FIXME: weak\n                char msg[40]; snprintf(msg, sizeof(msg),\n                    \"bad Elf64_Phdr[%d].p_offset %#lx\",\n                    -1+ e_phnum - j, (long unsigned)p_offset);\n                throwCantPack(msg);\n            }\n            return t + p_offset;\n        }\n    }\n    return 0;\n}\n\nu64_t  // returns .p_offset\nPackLinuxElf64::check_pt_load(Elf64_Phdr const *const phdr)\n{\n    u64_t filesz = get_te64(&phdr->p_filesz);\n    u64_t offset = get_te64(&phdr->p_offset), offend = filesz + offset;\n    u64_t vaddr  = get_te64(&phdr->p_vaddr);\n    u64_t paddr  = get_te64(&phdr->p_paddr);\n    u64_t align  = get_te64(&phdr->p_align);\n\n    if ((-1+ align) & (paddr ^ vaddr)\n    ||  (u64_t)file_size <= (u64_t)offset\n    ||  (u64_t)file_size <  (u64_t)offend\n    ||  (u64_t)file_size <= (u64_t)filesz) {\n        char msg[50]; snprintf(msg, sizeof(msg), \"bad PT_LOAD phdr[%u]\",\n            (unsigned)(phdr - phdri));\n        throwCantPack(msg);\n    }\n    return offset;\n}\n\nElf64_Dyn const *\nPackLinuxElf64::elf_has_dynamic(unsigned int key) const\n{\n    Elf64_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; Elf64_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te64(&dynp->d_tag)==key) {\n        return dynp;\n    }\n    return nullptr;\n}\n\nupx_uint64_t  // checked .p_offset; sz_dynseg set\nPackLinuxElf64::check_pt_dynamic(Elf64_Phdr const *const phdr)\n{\n    upx_uint64_t t = get_te64(&phdr->p_offset), s = sizeof(Elf64_Dyn) + t;\n    upx_uint64_t vaddr = get_te64(&phdr->p_vaddr);\n    upx_uint64_t filesz = get_te64(&phdr->p_filesz), memsz = get_te64(&phdr->p_memsz);\n    upx_uint64_t align = get_te64(&phdr->p_align);\n    if (file_size_u < t || s < t\n    ||  file_size_u < filesz\n    ||  file_size_u < (filesz + t)\n    ||  t < (e_phnum*sizeof(Elf64_Phdr) + sizeof(Elf64_Ehdr))\n    ||  (7 & t) || (0xf & (filesz | memsz))  // .balign 8; 16==sizeof(Elf64_Dyn)\n    ||  (-1+ align) & (t ^ vaddr)\n    ||  file_size_u <= memsz\n    ||  filesz < sizeof(Elf64_Dyn)\n    ||  memsz  < sizeof(Elf64_Dyn)\n    ||  filesz < memsz) {\n        char msg[50]; snprintf(msg, sizeof(msg), \"bad PT_DYNAMIC phdr[%u]\",\n            (unsigned)(phdr - phdri));\n        throwCantPack(msg);\n    }\n    sz_dynseg = memsz;\n    return t;\n}\n\nstatic int __acc_cdecl_qsort\nqcmp_unsigned(void const *const aa, void const *const bb)\n{\n    unsigned a = *(unsigned const *)aa;\n    unsigned b = *(unsigned const *)bb;\n    if (a < b) return -1;\n    if (a > b) return  1;\n    return  0;\n}\n\nvoid\nPackLinuxElf64::invert_pt_dynamic(Elf64_Dyn const *dynp, upx_uint64_t headway)\n{\n    if (dt_table[Elf64_Dyn::DT_NULL]) {\n        return;  // not 1st time; do not change upx_dt_init\n    }\n    Elf64_Dyn const *const dynp0 = dynp;\n    unsigned ndx = 0;\n    unsigned const limit = headway / sizeof(*dynp);\n    if (dynp)\n    for (; ; ++ndx, ++dynp) {\n        if (limit <= ndx) {\n            throwCantPack(\"DT_NULL not found\");\n        }\n        upx_uint64_t const d_tag = get_te64(&dynp->d_tag);\n        if (d_tag>>32) { // outrageous\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad Elf64_Dyn[%d].d_tag %#lx\", ndx, (long unsigned)d_tag);\n            throwCantPack(msg);\n        }\n        if (d_tag < DT_NUM) {\n            if (Elf64_Dyn::DT_NEEDED != d_tag\n            &&  dt_table[d_tag]\n            &&    get_te64(&dynp->d_val)\n               != get_te64(&dynp0[-1+ dt_table[d_tag]].d_val)) {\n                char msg[50]; snprintf(msg, sizeof(msg),\n                    \"duplicate DT_%#x: [%#x] [%#x]\",\n                    (unsigned)d_tag, -1+ dt_table[d_tag], ndx);\n                throwCantPack(msg);\n            }\n            dt_table[d_tag] = 1+ ndx;\n        }\n        if (Elf64_Dyn::DT_NULL == d_tag) {\n            break;  // check here so that dt_table[DT_NULL] is set\n        }\n    }\n    upx_dt_init = 0;\n         if (dt_table[Elf64_Dyn::DT_INIT])          upx_dt_init = Elf64_Dyn::DT_INIT;\n    else if (dt_table[Elf64_Dyn::DT_PREINIT_ARRAY]) upx_dt_init = Elf64_Dyn::DT_PREINIT_ARRAY;\n    else if (dt_table[Elf64_Dyn::DT_INIT_ARRAY])    upx_dt_init = Elf64_Dyn::DT_INIT_ARRAY;\n\n    unsigned const z_str = dt_table[Elf64_Dyn::DT_STRSZ];\n    strtab_end = !z_str ? 0 : get_te64(&dynp0[-1+ z_str].d_val);\n    if (!z_str || (u64_t)file_size <= strtab_end) { // FIXME: weak\n        char msg[50]; snprintf(msg, sizeof(msg),\n            \"bad DT_STRSZ %#x\", strtab_end);\n        throwCantPack(msg);\n    }\n\n    // DT_SYMTAB has no designated length.\n    // End it when next area else starts; often DT_STRTAB.  (FIXME)\n    unsigned const x_sym = dt_table[Elf64_Dyn::DT_SYMTAB];\n    unsigned const x_str = dt_table[Elf64_Dyn::DT_STRTAB];\n    if (x_sym && x_str) {\n        upx_uint64_t const v_sym = get_te64(&dynp0[-1+ x_sym].d_val);\n        upx_uint64_t const v_str = get_te64(&dynp0[-1+ x_str].d_val);\n        unsigned const  z_sym = dt_table[Elf64_Dyn::DT_SYMENT];\n        unsigned const sz_sym = !z_sym ? sizeof(Elf64_Sym)\n            : get_te64(&dynp0[-1+ z_sym].d_val);\n        if (sz_sym < sizeof(Elf64_Sym)) {\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_SYMENT %x\", sz_sym);\n            throwCantPack(msg);\n        }\n        if (v_sym < v_str) {\n            symnum_end = (v_str - v_sym) / sz_sym;\n        }\n        if (symnum_end < 1) {\n            throwCantPack(\"bad DT_SYMTAB\");\n        }\n    }\n    // DT_HASH, DT_GNU_HASH have no explicit length (except in ElfXX_Shdr),\n    // so it is hard to detect when the index of a hash chain is out-of-bounds.\n    // Workaround: Assume no overlap of DT_* tables.  Then any given table\n    // ends when another table begins.  So find the tables, and sort the offsets.\n    unsigned const dt_names[] = { // *.d_val are often in this order\n        Elf64_Dyn::DT_SYMTAB,\n        Elf64_Dyn::DT_VERSYM,\n        Elf64_Dyn::DT_VERNEED,\n        Elf64_Dyn::DT_HASH,\n        Elf64_Dyn::DT_GNU_HASH,\n        Elf64_Dyn::DT_STRTAB,\n        Elf64_Dyn::DT_VERDEF,\n        Elf64_Dyn::DT_REL,\n        Elf64_Dyn::DT_RELA,\n        Elf64_Dyn::DT_INIT,\n        0,\n    };\n    unsigned dt_offsets[sizeof(dt_names)/sizeof(dt_names[0])];\n    unsigned n_off = 0, k;\n    for (unsigned j=0; ((k = dt_names[j]),  k); ++j) {\n        dt_offsets[n_off] = 0;  // default to \"not found\"\n        if (k < DT_NUM) { // in range of easy table\n            if (dt_table[k]) { // present now\n                dt_offsets[n_off] = get_te64(&dynp0[-1+ dt_table[k]].d_val);\n            }\n        }\n        else {\n            if (file_image) { // why is this guard necessary?\n                dt_offsets[n_off] = elf_unsigned_dynamic(k);  // zero if not found\n            }\n        }\n        if (file_size <= dt_offsets[n_off]) {\n            char msg[60]; snprintf(msg, sizeof(msg), \"bad DT_{%#x} = %#x (beyond EOF)\",\n                dt_names[k], dt_offsets[n_off]);\n                throwCantPack(msg);\n        }\n        n_off += !!dt_offsets[n_off];\n    }\n    dt_offsets[n_off++] = file_size;  // sentinel\n    qsort(dt_offsets, n_off, sizeof(dt_offsets[0]), qcmp_unsigned);\n\n    unsigned const v_hsh = elf_unsigned_dynamic(Elf64_Dyn::DT_HASH);\n    if (v_hsh && file_image) {\n        hashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_HASH);\n        if (!hashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_HASH %#x\", v_hsh);\n            throwCantPack(msg);\n        }\n        for (unsigned j = 0; j < n_off; ++j) {\n            if (v_hsh == dt_offsets[j]) {\n                if (dt_offsets[1+ j]) {\n                    hashend = (unsigned const *)(void const *)\n                        ((dt_offsets[1+ j] - dt_offsets[j]) + (char const *)hashtab);\n                }\n                break;\n            }\n        }\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket]; (void)chains;\n\n        unsigned const v_sym = !x_sym ? 0 : get_te32(&dynp0[-1+ x_sym].d_val);\n        if ((unsigned)file_size <= nbucket/sizeof(*buckets)  // FIXME: weak\n        || !v_sym || (unsigned)file_size <= v_sym\n        || ((v_hsh < v_sym) && (v_sym - v_hsh) < sizeof(*buckets)*(2+ nbucket))\n        ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n        unsigned chmax = 0;\n        for (unsigned j= 0; j < nbucket; ++j) {\n            unsigned x = get_te32(&buckets[j]);\n            if (chmax < x) {\n                chmax = x;\n            }\n        }\n        if ((v_hsh < v_sym) && (v_sym - v_hsh) <\n                (sizeof(*buckets)*(2+ nbucket) + sizeof(*chains)*(1+ chmax))) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n    }\n    // DT_GNU_HASH often ends at DT_SYMTAB;  FIXME: not for Android?\n    unsigned const v_gsh = elf_unsigned_dynamic(Elf64_Dyn::DT_GNU_HASH);\n    if (v_gsh && file_image) {\n        gashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_GNU_HASH);\n        if (!gashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_GNU_HASH %#x\", v_gsh);\n            throwCantPack(msg);\n        }\n        for (unsigned j = 0; j < n_off; ++j) { // linear search of short table\n            if (v_gsh == dt_offsets[j]) {\n                if (dt_offsets[1+ j]) {\n                    gashend = (unsigned const *)(void const *)\n                        ((dt_offsets[1+ j] - dt_offsets[j]) + (char const *)gashtab);\n                }\n                break;\n            }\n        }\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket]; (void)hasharr;\n        if (!n_bucket || (1u<<31) <= n_bucket  /* fie on fuzzers */\n        || (void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        // unsigned const *const gashend = &hasharr[n_bucket];\n        // minimum, except:\n        // Rust and Android trim unused zeroes from high end of hasharr[]\n        unsigned bmax = 0;\n        for (unsigned j= 0; j < n_bucket; ++j) {\n            unsigned bj = get_te32(&buckets[j]);\n            if (bj) {\n                if (bj < symbias) {\n                    char msg[90]; snprintf(msg, sizeof(msg),\n                            \"bad DT_GNU_HASH bucket[%d] < symbias{%#x}\\n\",\n                            bj, symbias);\n                    throwCantPack(msg);\n                }\n                if (bmax < bj) {\n                    bmax = bj;\n                }\n            }\n        }\n        if (1==n_bucket  && 0==buckets[0]\n        &&  1==n_bitmask && 0==bitmask[0]) {\n            // 2021-09-11 Rust on RaspberryPi apparently uses this to minimize space.\n            // But then the DT_GNU_HASH symbol lookup algorithm always fails?\n            // https://github.com/upx/upx/issues/525\n        } else\n        if ((1+ bmax) < symbias) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                    \"bad DT_GNU_HASH (1+ max_bucket)=%#x < symbias=%#x\", 1+ bmax, symbias);\n            throwCantPack(msg);\n        }\n        bmax -= symbias;\n\n        // preliminary bound on gashend\n        Elf64_Shdr const *sec_gash = elf_find_section_type(Elf64_Shdr::SHT_GNU_HASH);\n        unsigned const off_symtab = elf_unsigned_dynamic(Elf64_Dyn::DT_SYMTAB);\n        unsigned const off_strtab = elf_unsigned_dynamic(Elf64_Dyn::DT_STRTAB);\n        unsigned const off_gshtab = elf_unsigned_dynamic(Elf64_Dyn::DT_GNU_HASH);\n        if (off_gshtab < file_size  // paranoia\n        &&  off_strtab < file_size\n        &&  off_symtab < file_size ) {\n            unsigned sz_gshtab = 0;\n            if (sec_gash && off_gshtab == get_te32(&sec_gash->sh_offset)) {\n               sz_gshtab = get_te32(&sec_gash->sh_size);\n            }\n            else { // heuristics\n                if (off_gshtab < off_strtab) {\n                    sz_gshtab = off_strtab - off_gshtab;\n                }\n                else if (off_gshtab < off_symtab) {\n                    sz_gshtab = off_symtab - off_gshtab;\n                }\n            }\n            if (sz_gshtab <= (file_size - off_gshtab)) {\n                gashend = (unsigned const *)(void const *)\n                    (sz_gshtab + (char const *)gashtab);\n            }\n        }\n\n        upx_uint64_t const v_sym = !x_sym ? 0 : get_te64(&dynp0[-1+ x_sym].d_val);\n        unsigned r = 0;\n        if (!n_bucket || !n_bitmask || !v_sym\n        || (r=1, ((-1+ n_bitmask) & n_bitmask))  // not a power of 2\n        || (r=2, (8*sizeof(upx_uint64_t) <= gnu_shift))  // shifted result always == 0\n        || (r=3, (n_bucket>>30))  // fie on fuzzers\n        || (r=4, (n_bitmask>>30))\n        || (r=5, ((file_size/sizeof(unsigned))\n                <= ((sizeof(*bitmask)/sizeof(unsigned))*n_bitmask + 2*n_bucket)))  // FIXME: weak\n        || (r=6, ((v_gsh < v_sym) && (v_sym - v_gsh) < (sizeof(unsigned)*4  // headers\n                + sizeof(*bitmask)*n_bitmask  // bitmask\n                + sizeof(*buckets)*n_bucket  // buckets\n                + sizeof(*hasharr)*(1+ bmax)  // hasharr\n            )) )\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_GNU_HASH n_bucket=%#x  n_bitmask=%#x  len=%#lx  r=%d\",\n                n_bucket, n_bitmask, (long unsigned)(v_sym - v_gsh), r);\n            throwCantPack(msg);\n        }\n    }\n    unsigned const e_shstrndx = get_te16(&ehdri.e_shstrndx);\n    if (e_shnum <= e_shstrndx\n    &&  !(0==e_shnum && 0==e_shstrndx) ) {\n        char msg[40]; snprintf(msg, sizeof(msg),\n            \"bad .e_shstrndx %d >= .e_shnum %d\", e_shstrndx, e_shnum);\n        throwCantPack(msg);\n    }\n}\n\nvoid const *\nPackLinuxElf64::elf_find_dynamic(unsigned int key) const\n{\n    Elf64_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; (unsigned)((char const *)dynp - (char const *)dynseg) < sz_dynseg\n            && Elf64_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te64(&dynp->d_tag)==key) {\n        upx_uint64_t const t= elf_get_offset_from_address(get_te64(&dynp->d_val));\n        if (t && t < (upx_uint64_t)file_size) {\n            return t + file_image;\n        }\n        break;\n    }\n    return nullptr;\n}\n\nupx_uint64_t\nPackLinuxElf64::elf_unsigned_dynamic(unsigned int key) const\n{\n    Elf64_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; (unsigned)((char const *)dynp - (char const *)dynseg) < sz_dynseg\n            && Elf64_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te64(&dynp->d_tag)==key) {\n        return get_te64(&dynp->d_val);\n    }\n    return 0;\n}\n\nunsigned PackLinuxElf::gnu_hash(char const *q)\n{\n    unsigned char const *p = (unsigned char const *)q;\n    unsigned h;\n\n    for (h= 5381; 0!=*p; ++p) {\n        h += *p + (h << 5);\n    }\n    return h;\n}\n\nunsigned PackLinuxElf::elf_hash(char const *p)\n{\n    unsigned h;\n    for (h= 0; 0!=*p; ++p) {\n        h = *p + (h<<4);\n        {\n            unsigned const t = 0xf0000000u & h;\n            h &= ~t;\n            h ^= t>>24;\n        }\n    }\n    return h;\n}\n\nElf32_Sym const *PackLinuxElf32::elf_lookup(char const *name) const\n{\n    if (hashtab && dynsym && dynstr) {\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket];\n        if ((unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*nbucket ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad nbucket %#x\\n\", nbucket);\n            throwCantPack(msg);\n        }\n        if (nbucket) {\n            unsigned const m = elf_hash(name) % nbucket;\n            unsigned si;\n            for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n                char const *const p= get_dynsym_name(si, (unsigned)-1);\n                if (0==strcmp(name, p)) {\n                    return &dynsym[si];\n                }\n            }\n        }\n    }\n    if (gashtab && dynsym && dynstr) {\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        unsigned const *const bitmask = &gashtab[4];\n        unsigned const *const buckets = &bitmask[n_bitmask];\n        unsigned const *const hasharr = &buckets[n_bucket];\n        if ((void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        if (!n_bitmask\n        || (unsigned)(file_size - ((char const *)bitmask - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*n_bitmask ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bitmask %#x\\n\", n_bitmask);\n            throwCantPack(msg);\n        }\n        if (n_bucket) {\n            unsigned const h = gnu_hash(name);\n            unsigned const hbit1 = 037& h;\n            unsigned const hbit2 = 037& (h>>gnu_shift);\n            unsigned const w = get_te32(&bitmask[(n_bitmask -1) & (h>>5)]);\n\n            if (1& (w>>hbit1) & (w>>hbit2)) {\n                unsigned bucket = get_te32(&buckets[h % n_bucket]);\n                if (n_bucket <= bucket) {\n                    char msg[90]; snprintf(msg, sizeof(msg),\n                            \"bad DT_GNU_HASH n_bucket{%#x} <= buckets[%d]{%#x}\\n\",\n                            n_bucket, h % n_bucket, bucket);\n                    throwCantPack(msg);\n                }\n                if (0!=bucket) {\n                    Elf32_Sym const *dsp = &dynsym[bucket];\n                    unsigned const *hp = &hasharr[bucket - symbias];\n                    do if (0==((h ^ get_te32(hp))>>1)) {\n                        unsigned st_name = get_te32(&dsp->st_name);\n                        char const *const p = get_str_name(st_name, (unsigned)-1);\n                        if (0==strcmp(name, p)) {\n                            return dsp;\n                        }\n                    } while (++dsp,\n                            (char const *)hp < (char const *)&file_image[file_size]\n                        &&  0==(1u& get_te32(hp++)));\n                }\n            }\n        }\n    }\n    // 2021-12-25  FIXME: Some Rust programs use\n    //    (1==n_bucket && 0==buckets[0] && 1==n_bitmask && 0==bitmask[0])\n    // to minimize space in DT_GNU_HASH. This causes the fancy lookup to fail.\n    // Is a fallback to linear seach assumed?\n    // 2022-03-12  Some Rust programs have 0==n_bucket.\n    return nullptr;\n\n}\n\nElf64_Sym const *PackLinuxElf64::elf_lookup(char const *name) const\n{\n    if (hashtab && dynsym && dynstr) {\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket];\n        if ((unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*nbucket ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad nbucket %#x\\n\", nbucket);\n            throwCantPack(msg);\n        }\n        if (nbucket) { // -rust-musl can have \"empty\" hashtab\n            unsigned const m = elf_hash(name) % nbucket;\n            unsigned si;\n            for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n                char const *const p= get_dynsym_name(si, (unsigned)-1);\n                if (0==strcmp(name, p)) {\n                    return &dynsym[si];\n                }\n            }\n        }\n    }\n    if (gashtab && dynsym && dynstr) {\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket];\n\n        if ((void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        if (!n_bitmask\n        || (unsigned)(file_size - ((char const *)bitmask - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*n_bitmask ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bitmask %#x\\n\", n_bitmask);\n            throwCantPack(msg);\n        }\n        if (n_bucket) { // -rust-musl can have \"empty\" gashtab\n            unsigned const h = gnu_hash(name);\n            unsigned const hbit1 = 077& h;\n            unsigned const hbit2 = 077& (h>>gnu_shift);\n            upx_uint64_t const w = get_te64(&bitmask[(n_bitmask -1) & (h>>6)]);\n            if (1& (w>>hbit1) & (w>>hbit2)) {\n                unsigned hhead = get_te32(&buckets[h % n_bucket]);\n                if (hhead) {\n                    Elf64_Sym const *dsp = &dynsym[hhead];\n                    unsigned const *hp = &hasharr[hhead - symbias];\n                    unsigned k;\n                    do {\n                        if (gashend <= hp) {\n                            char msg[120]; snprintf(msg, sizeof(msg),\n                                \"bad gnu_hash[%#tx]  head=%u\",\n                                hp - hasharr, hhead);\n                            throwCantPack(msg);\n                        }\n                        k = get_te32(hp);\n                        if (0==((h ^ k)>>1)) {\n                            unsigned const st_name = get_te32(&dsp->st_name);\n                            char const *const p = get_str_name(st_name, (unsigned)-1);\n                            if (0==strcmp(name, p)) {\n                                return dsp;\n                            }\n                        }\n                    } while (++dsp, ++hp, 0==(1u& k));\n                }\n            }\n        }\n    }\n    // 2021-12-25  FIXME: Some Rust programs use\n    //    (1==n_bucket && 0==buckets[0] && 1==n_bitmask && 0==bitmask[0])\n    // to minimize space in DT_GNU_HASH. This causes the fancy lookup to fail.\n    // Is a fallback to linear seach assumed?\n    // 2022-03-12  Some Rust programs have 0==n_bucket.\n    return nullptr;\n\n}\n\nvoid PackLinuxElf32::unpack(OutputFile *fo)\n{\n    if (e_phoff != sizeof(Elf32_Ehdr)) {// Phdrs not contiguous with Ehdr\n        throwCantUnpack(\"bad e_phoff\");\n    }\n    unsigned const c_phnum = get_te16(&ehdri.e_phnum);\n    unsigned old_dtinit = 0;\n    unsigned is_asl = 0;  // is Android Shared Library\n\n    unsigned szb_info = sizeof(b_info);\n    {\n        if (get_te32(&ehdri.e_entry) < 0x401180\n        &&  Elf32_Ehdr::EM_386 ==get_te16(&ehdri.e_machine)\n        &&  Elf32_Ehdr::ET_EXEC==get_te16(&ehdri.e_type)) {\n            // Beware ET_DYN.e_entry==0x10f0 (or so) does NOT qualify here.\n            /* old style, 8-byte b_info */\n            szb_info = 2*sizeof(unsigned);\n        }\n    }\n\n    fi->seek(overlay_offset - sizeof(l_info), SEEK_SET);\n    fi->readx(&linfo, sizeof(linfo));\n    lsize = get_te16(&linfo.l_lsize);\n    if (UPX_MAGIC_LE32 != get_le32(&linfo.l_magic)) {\n        throwCantUnpack(\"l_info corrupted\");\n    }\n    p_info hbuf;  fi->readx(&hbuf, sizeof(hbuf));\n    unsigned orig_file_size = get_te32(&hbuf.p_filesize);\n    blocksize = get_te32(&hbuf.p_blocksize);\n    if ((u32_t)file_size > orig_file_size || blocksize > orig_file_size\n        || !mem_size_valid(1, blocksize, OVERHEAD))\n        throwCantUnpack(\"p_info corrupted\");\n\n    ibuf.alloc(blocksize + OVERHEAD);\n    b_info bhdr; memset(&bhdr, 0, sizeof(bhdr));\n    fi->readx(&bhdr, szb_info);\n    ph.u_len = get_te32(&bhdr.sz_unc);\n    ph.c_len = get_te32(&bhdr.sz_cpr);\n    if (ph.c_len > (unsigned)file_size || ph.c_len == 0 || ph.u_len == 0\n    ||  ph.u_len > orig_file_size)\n        throwCantUnpack(\"b_info corrupted\");\n    ph.filter_cto = bhdr.b_cto8;\n\n    MemBuffer u(ph.u_len);\n    Elf32_Ehdr *const ehdr = (Elf32_Ehdr *)&u[0];\n    Elf32_Phdr const *phdr = nullptr;\n\n    // Uncompress Ehdr and Phdrs.\n    if (ibuf.getSize() < ph.c_len) {\n        throwCompressedDataViolation();\n    }\n    fi->readx(ibuf, ph.c_len);\n    decompress(ibuf, (upx_byte *)ehdr, false);\n    if (ehdr->e_type   !=ehdri.e_type\n    ||  ehdr->e_machine!=ehdri.e_machine\n    ||  ehdr->e_version!=ehdri.e_version\n    ||  ehdr->e_flags  !=ehdri.e_flags\n    ||  ehdr->e_ehsize !=ehdri.e_ehsize\n        // check EI_MAG[0-3], EI_CLASS, EI_DATA, EI_VERSION\n    ||  memcmp(ehdr->e_ident, ehdri.e_ident, Elf32_Ehdr::EI_OSABI)) {\n        throwCantUnpack(\"ElfXX_Ehdr corrupted\");\n    }\n    fi->seek(- (off_t) (szb_info + ph.c_len), SEEK_CUR);\n\n    unsigned const u_phnum = get_te16(&ehdr->e_phnum);\n    total_in = 0;\n    total_out = 0;\n    unsigned c_adler = upx_adler32(nullptr, 0);\n    unsigned u_adler = upx_adler32(nullptr, 0);\n#define MAX_ELF_HDR 512\n    if ((umin(MAX_ELF_HDR, ph.u_len) - sizeof(Elf32_Ehdr))/sizeof(Elf32_Phdr) < u_phnum) {\n        throwCantUnpack(\"bad compressed e_phnum\");\n    }\n#undef MAX_ELF_HDR\n\n    // Packed ET_EXE has no PT_DYNAMIC.\n    // Packed ET_DYN has original PT_DYNAMIC for info needed by rtld.\n    Elf32_Phdr const *const dynhdr = elf_find_ptype(Elf32_Phdr::PT_DYNAMIC, phdri, c_phnum);\n    bool const is_shlib = !!dynhdr;\n    if (is_shlib) {\n        // Unpack and output the Ehdr and Phdrs for real.\n        // This depends on position within input file fi.\n        unpackExtent(ph.u_len, fo,\n            c_adler, u_adler, false, szb_info);\n\n        // The first PT_LOAD.  Part is not compressed (for benefit of rtld.)\n        fi->seek(0, SEEK_SET);\n        fi->readx(ibuf, get_te32(&dynhdr->p_offset) + get_te32(&dynhdr->p_filesz));\n        overlay_offset -= sizeof(linfo);\n        xct_off = overlay_offset;\n        e_shoff = get_te32(&ehdri.e_shoff);\n        ibuf.subref(\"bad .e_shoff %#x for %#x\", e_shoff, sizeof(Elf32_Shdr) * e_shnum);\n        if (e_shoff && e_shnum) { // --android-shlib\n            shdri = (Elf32_Shdr /*const*/ *)ibuf.subref(\n                \"bad Shdr table\", e_shoff, sizeof(Elf32_Shdr)*e_shnum);\n            unsigned xct_off2 = get_te32(&shdri->sh_offset);\n            if (e_shoff == xct_off2) {\n                xct_off = e_shoff;\n            }\n            // un-Relocate dynsym (DT_SYMTAB) which is below xct_off\n            unsigned dyn_offset = get_te32(&dynhdr->p_offset);\n            unsigned dyn_filesz = get_te32(&dynhdr->p_filesz);\n            if (orig_file_size < dyn_offset\n            || (orig_file_size - dyn_offset) < dyn_filesz) {\n                throwCantUnpack(\"bad PT_DYNAMIC\");\n            }\n            dynseg = (Elf32_Dyn const *)ibuf.subref(\"bad DYNAMIC\", dyn_offset, dyn_filesz);\n            dynstr = (char const *)elf_find_dynamic(Elf32_Dyn::DT_STRTAB);\n            sec_dynsym = elf_find_section_type(Elf32_Shdr::SHT_DYNSYM);\n            if (sec_dynsym) {\n                unsigned const off_dynsym = get_te32(&sec_dynsym->sh_offset);\n                unsigned const sz_dynsym  = get_te32(&sec_dynsym->sh_size);\n                if (orig_file_size < sz_dynsym\n                ||  orig_file_size < off_dynsym\n                || (orig_file_size - off_dynsym) < sz_dynsym) {\n                    throwCantUnpack(\"bad SHT_DYNSYM\");\n                }\n                Elf32_Sym *const sym0 = (Elf32_Sym *)ibuf.subref(\n                    \"bad dynsym\", off_dynsym, sz_dynsym);\n                Elf32_Sym *sym = sym0;\n                for (int j = sz_dynsym / sizeof(Elf32_Sym); --j>=0; ++sym) {\n                    unsigned symval = get_te32(&sym->st_value);\n                    unsigned symsec = get_te16(&sym->st_shndx);\n                    if (Elf32_Sym::SHN_UNDEF != symsec\n                    &&  Elf32_Sym::SHN_ABS   != symsec\n                    &&  xct_off <= symval) {\n                        set_te32(&sym->st_value, symval - asl_delta);\n                    }\n                    if (Elf32_Sym::SHN_ABS == symsec && xct_off <= symval) {\n                        adjABS(sym, 0u - asl_delta);\n                    }\n                }\n            }\n        }\n        if (fo) {\n            fo->write(ibuf + ph.u_len, xct_off - ph.u_len);\n        }\n\n        total_in  = xct_off;\n        total_out = xct_off;\n        ph.u_len = 0;\n        // Position the input for next unpackExtent.\n        fi->seek(sizeof(linfo) + overlay_offset + sizeof(hbuf) + szb_info + ph.c_len, SEEK_SET);\n\n        // Decompress and unfilter the tail of first PT_LOAD.\n        phdr = (Elf32_Phdr *) (void *) (1+ ehdr);\n        for (unsigned j=0; j < u_phnum; ++phdr, ++j) {\n            if (is_LOAD32(phdr)) {\n                ph.u_len = get_te32(&phdr->p_filesz) - xct_off;\n                break;\n            }\n        }\n        unpackExtent(ph.u_len, fo,\n            c_adler, u_adler, false, szb_info);\n    }\n    else {  // main executable\n        // Decompress each PT_LOAD.\n        bool first_PF_X = true;\n        phdr = (Elf32_Phdr *) (void *) (1+ ehdr);  // uncompressed\n        for (unsigned j=0; j < u_phnum; ++phdr, ++j) {\n            if (is_LOAD32(phdr)) {\n                unsigned const filesz = get_te32(&phdr->p_filesz);\n                unsigned const offset = get_te32(&phdr->p_offset);\n                if (fo)\n                    fo->seek(offset, SEEK_SET);\n                if (Elf32_Phdr::PF_X & get_te32(&phdr->p_flags)) {\n                    unpackExtent(filesz, fo,\n                        c_adler, u_adler, first_PF_X, szb_info);\n                    first_PF_X = false;\n                }\n                else {\n                    unpackExtent(filesz, fo,\n                        c_adler, u_adler, false, szb_info);\n                }\n            }\n        }\n    }\n    phdr = phdri;\n    load_va = 0;\n    for (unsigned j=0; j < c_phnum; ++j) {\n        if (is_LOAD32(phdr)) {\n            load_va = get_te32(&phdr->p_vaddr);\n            break;\n        }\n    }\n    if (0x1000==get_te32(&phdri[0].p_filesz)  // detect C_BASE style\n    &&  0==get_te32(&phdri[1].p_offset)\n    &&  0==get_te32(&phdri[0].p_offset)\n    &&     get_te32(&phdri[1].p_filesz) == get_te32(&phdri[1].p_memsz)) {\n        fi->seek(up4(get_te32(&phdr[1].p_memsz)), SEEK_SET);  // past the loader\n    }\n    else if (is_shlib\n    ||  ((unsigned)(get_te32(&ehdri.e_entry) - load_va) + up4(lsize) +\n                ph.getPackHeaderSize() + sizeof(overlay_offset))\n            < up4(file_size)) {\n        // Loader is not at end; skip past it.\n        funpad4(fi);  // MATCH01\n        unsigned d_info[4]; fi->readx(d_info, sizeof(d_info));\n        if (0==old_dtinit) {\n            old_dtinit = get_te32(&d_info[2 + (0==d_info[0])]);\n            is_asl = 1u& get_te32(&d_info[0 + (0==d_info[0])]);\n        }\n        fi->seek(lsize - sizeof(d_info), SEEK_CUR);\n    }\n\n    // The gaps between PT_LOAD and after last PT_LOAD\n    phdr = (Elf32_Phdr *)&u[sizeof(*ehdr)];\n    unsigned hi_offset(0);\n    for (unsigned j = 0; j < u_phnum; ++j) {\n        unsigned offset = get_te32(&phdr[j].p_offset);\n        if (is_LOAD32(&phdr[j])\n        &&  hi_offset < offset)\n            hi_offset = offset;\n    }\n    for (unsigned j = 0; j < u_phnum; ++j) {\n        unsigned const size = find_LOAD_gap(phdr, j, u_phnum);\n        if (size) {\n            unsigned const offset = get_te32(&phdr[j].p_offset);\n            unsigned const where =  get_te32(&phdr[j].p_filesz) + offset;\n            if (fo)\n                fo->seek(where, SEEK_SET);\n            unpackExtent(size, fo,\n                c_adler, u_adler, false, szb_info,\n                is_shlib && (offset != hi_offset));\n                // FIXME: should not depend on is_shlib ?\n        }\n    }\n\n    // check for end-of-file\n    fi->readx(&bhdr, szb_info);\n    unsigned const sz_unc = ph.u_len = get_te32(&bhdr.sz_unc);\n\n    if (sz_unc == 0) { // uncompressed size 0 -> EOF\n        // note: magic is always stored le32\n        unsigned const sz_cpr = get_le32(&bhdr.sz_cpr);\n        if (sz_cpr != UPX_MAGIC_LE32)  // sz_cpr must be h->magic\n            throwCompressedDataViolation();\n    }\n    else { // extra bytes after end?\n        throwCompressedDataViolation();\n    }\n\n    if (is_shlib) {\n        // DT_INIT must be restored.\n        // If android_shlib, then the asl_delta relocations must be un-done.\n        int n_ptload = 0;\n        unsigned load_off = 0;\n        phdr = (Elf32_Phdr *)&u[sizeof(*ehdr)];\n        for (unsigned j= 0; j < u_phnum; ++j, ++phdr) {\n            if (is_LOAD32(phdr) && 0!=n_ptload++) {\n                load_off = get_te32(&phdr->p_offset);\n                load_va  = get_te32(&phdr->p_vaddr);\n                fi->seek(old_data_off, SEEK_SET);\n                fi->readx(ibuf, old_data_len);\n                total_in  += old_data_len;\n                total_out += old_data_len;\n\n                Elf32_Phdr const *udynhdr = (Elf32_Phdr *)&u[sizeof(*ehdr)];\n                for (unsigned j3= 0; j3 < u_phnum; ++j3, ++udynhdr)\n                if (Elf32_Phdr::PT_DYNAMIC==get_te32(&udynhdr->p_type)) {\n                    unsigned dt_pltrelsz(0), dt_jmprel(0);\n                    unsigned dt_relsz(0), dt_rel(0);\n                    unsigned const dyn_len = get_te32(&udynhdr->p_filesz);\n                    unsigned const dyn_off = get_te32(&udynhdr->p_offset);\n                    if ((unsigned long)file_size < (dyn_len + dyn_off)) {\n                        char msg[50]; snprintf(msg, sizeof(msg),\n                                \"bad PT_DYNAMIC .p_filesz %#x\", dyn_len);\n                        throwCantUnpack(msg);\n                    }\n                    if (dyn_off < load_off) {\n                        continue;  // Oops.  Not really is_shlib ?  [built by 'rust' ?]\n                    }\n                    Elf32_Dyn *dyn = (Elf32_Dyn *)((unsigned char *)ibuf +\n                        (dyn_off - load_off));\n                    dynseg = dyn; invert_pt_dynamic(dynseg,\n                        umin(dyn_len, file_size - dyn_off));\n                    for (unsigned j2= 0; j2 < dyn_len; ++dyn, j2 += sizeof(*dyn)) {\n                        unsigned const tag = get_te32(&dyn->d_tag);\n                        unsigned       val = get_te32(&dyn->d_val);\n                        if (is_asl) switch (tag) {\n                        case Elf32_Dyn::DT_RELSZ:    { dt_relsz    = val; } break;\n                        case Elf32_Dyn::DT_REL:      { dt_rel      = val; } break;\n                        case Elf32_Dyn::DT_PLTRELSZ: { dt_pltrelsz = val; } break;\n                        case Elf32_Dyn::DT_JMPREL:   { dt_jmprel   = val; } break;\n\n                        case Elf32_Dyn::DT_PLTGOT:\n                        case Elf32_Dyn::DT_PREINIT_ARRAY:\n                        case Elf32_Dyn::DT_INIT_ARRAY:\n                        case Elf32_Dyn::DT_FINI_ARRAY:\n                        case Elf32_Dyn::DT_FINI: {\n                            set_te32(&dyn->d_val, val -= asl_delta);\n                        }; break;\n                        } // end switch()\n                        if (upx_dt_init == tag) {\n                            if (Elf32_Dyn::DT_INIT == tag) {\n                                set_te32(&dyn->d_val, old_dtinit);\n                                if (!old_dtinit) { // compressor took the slot\n                                    dyn->d_tag = Elf32_Dyn::DT_NULL;\n                                    dyn->d_val = 0;\n                                }\n                            }\n                            else if (Elf32_Dyn::DT_INIT_ARRAY    == tag\n                            ||       Elf32_Dyn::DT_PREINIT_ARRAY == tag) {\n                                if (val < load_va || (unsigned)file_size < (unsigned)val) {\n                                    char msg[50]; snprintf(msg, sizeof(msg),\n                                            \"Bad Dynamic tag %#x %#x\",\n                                            (unsigned)tag, (unsigned)val);\n                                    throwCantUnpack(msg);\n                                }\n                                set_te32(&ibuf[val - load_va], old_dtinit\n                                    + (is_asl ? asl_delta : 0));  // counter-act unRel32\n                            }\n                        }\n                        // Modified DT_*.d_val are re-written later from ibuf[]\n                    }\n                    if (is_asl) {\n                        lowmem.alloc(xct_off);\n                        fi->seek(0, SEEK_SET);\n                        fi->read(lowmem, xct_off);  // contains relocation tables\n                        if (dt_relsz && dt_rel) {\n                            Elf32_Rel *const rel0 = (Elf32_Rel *)lowmem.subref(\n                                \"bad Rel offset\", dt_rel, dt_relsz);\n                            unRel32(dt_rel, rel0, dt_relsz, ibuf, load_va, fo);\n                        }\n                        if (dt_pltrelsz && dt_jmprel) { // FIXME:  overlap w/ DT_REL ?\n                            Elf32_Rel *const jmp0 = (Elf32_Rel *)lowmem.subref(\n                                \"bad Jmprel offset\", dt_jmprel, dt_pltrelsz);\n                            unRel32(dt_jmprel, jmp0, dt_pltrelsz, ibuf, load_va, fo);\n                        }\n                        // Modified relocation tables are re-written by unRel32\n                    }\n                }\n                if (fo) {\n                    fo->seek(get_te32(&phdr->p_offset), SEEK_SET);\n                    fo->rewrite(ibuf, old_data_len);\n                }\n            }\n        }\n    }\n\n    // update header with totals\n    ph.c_len = total_in;\n    ph.u_len = total_out;\n\n    // all bytes must be written\n    if (fo && total_out != orig_file_size)\n        throwEOFException();\n\n    // finally test the checksums\n    if (ph.c_adler != c_adler || ph.u_adler != u_adler)\n        throwChecksumError();\n}\n\nvoid PackLinuxElf::unpack(OutputFile * /*fo*/)\n{\n    throwCantUnpack(\"internal error\");\n}\n\n/* vim:set ts=4 sw=4 et: */\n"], "fixing_code": ["/* p_lx_elf.cpp --\n\n   This file is part of the UPX executable compressor.\n\n   Copyright (C) 1996-2022 Markus Franz Xaver Johannes Oberhumer\n   Copyright (C) 1996-2022 Laszlo Molnar\n   Copyright (C) 2000-2022 John F. Reiser\n   All Rights Reserved.\n\n   UPX and the UCL library are free software; you can redistribute them\n   and/or modify them under the terms of the GNU General Public License as\n   published by the Free Software Foundation; either version 2 of\n   the License, or (at your option) any later version.\n\n   This program is distributed in the hope that it will be useful,\n   but WITHOUT ANY WARRANTY; without even the implied warranty of\n   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n   GNU General Public License for more details.\n\n   You should have received a copy of the GNU General Public License\n   along with this program; see the file COPYING.\n   If not, write to the Free Software Foundation, Inc.,\n   59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.\n\n   Markus F.X.J. Oberhumer              Laszlo Molnar\n   <markus@oberhumer.com>               <ezerotven+github@gmail.com>\n\n   John F. Reiser\n   <jreiser@users.sourceforge.net>\n */\n\n\n#include \"conf.h\"\n\n#include \"file.h\"\n#include \"filter.h\"\n#include \"linker.h\"\n#include \"packer.h\"\n#include \"p_elf.h\"\n#include \"p_unix.h\"\n#include \"p_lx_exc.h\"\n#include \"p_lx_elf.h\"\n#include \"ui.h\"\n\ntypedef upx_uint32_t u32_t;  // easier to type; more narrow\ntypedef upx_uint64_t u64_t;  // easier to type; more narrow\n\n#define PT_LOAD32   Elf32_Phdr::PT_LOAD\n#define PT_LOAD64   Elf64_Phdr::PT_LOAD\n#define PT_NOTE32   Elf32_Phdr::PT_NOTE\n#define PT_NOTE64   Elf64_Phdr::PT_NOTE\n#define PT_GNU_STACK32  Elf32_Phdr::PT_GNU_STACK\n#define PT_GNU_STACK64  Elf64_Phdr::PT_GNU_STACK\n\n//static unsigned const EF_ARM_HASENTRY = 0x02;\nstatic unsigned const EF_ARM_EABI_VER4 = 0x04000000;\nstatic unsigned const EF_ARM_EABI_VER5 = 0x05000000;\n\nunsigned char PackLinuxElf::o_shstrtab[] = {  \\\n/*start*/       '\\0',\n/*offset  1*/   '.','n','o','t','e','.','g','n','u','.','b','u','i','l','d','-','i','d','\\0',\n/*offset 20*/   '.','s','h','s','t','r','t','a','b','\\0'\n};\n\n#define usizeof(x)      ((unsigned) sizeof(x))\n\nstatic unsigned\numin(unsigned a, unsigned b)\n{\n    return (a < b) ? a : b;\n}\n\nstatic upx_uint64_t\numin64(upx_uint64_t a, upx_uint64_t b)\n{\n    return (a < b) ? a : b;\n}\n\nstatic unsigned\nup4(unsigned x)\n{\n    return ~3u & (3+ x);\n}\n\n#if 0  //{ unused\nstatic unsigned\nup8(unsigned x)\n{\n    return ~7u & (7+ x);\n}\n#endif  //}\n\nstatic off_t\nfpad4(OutputFile *fo)\n{\n    off_t len = fo->st_size();\n    unsigned d = 3u & (0 - len);\n    unsigned zero = 0;\n    fo->write(&zero, d);\n    return d + len;\n}\n\nstatic off_t\nfpad8(OutputFile *fo)\n{\n    off_t len = fo->st_size();\n    unsigned d = 7u & (0 - len);\n    upx_uint64_t zero = 0;\n    fo->write(&zero, d);\n    return d + len;\n}\n\nstatic unsigned\nfunpad4(InputFile *fi)\n{\n    unsigned d = 3u & (0 - fi->tell());\n    if (d)\n        fi->seek(d, SEEK_CUR);\n    return d;\n}\n\nstatic void alloc_file_image(MemBuffer &mb, off_t size)\n{\n    assert(mem_size_valid_bytes(size));\n    if (mb.getVoidPtr() == nullptr) {\n        mb.alloc(size);\n    } else {\n        assert((u32_t)size <= mb.getSize());\n    }\n}\n\nint\nPackLinuxElf32::checkEhdr(Elf32_Ehdr const *ehdr) const\n{\n    const unsigned char * const buf = ehdr->e_ident;\n\n    if (0!=memcmp(buf, \"\\x7f\\x45\\x4c\\x46\", 4)  // \"\\177ELF\"\n    ||  buf[Elf32_Ehdr::EI_CLASS]!=ei_class\n    ||  buf[Elf32_Ehdr::EI_DATA] !=ei_data\n    ) {\n        return -1;\n    }\n    if (!memcmp(buf+8, \"FreeBSD\", 7))                   // branded\n        return 1;\n\n    int const type = get_te16(&ehdr->e_type);\n    if (type != Elf32_Ehdr::ET_EXEC && type != Elf32_Ehdr::ET_DYN)\n        return 2;\n    if (get_te16(&ehdr->e_machine) != (unsigned) e_machine)\n        return 3;\n    if (get_te32(&ehdr->e_version) != Elf32_Ehdr::EV_CURRENT)\n        return 4;\n    if (e_phnum < 1)\n        return 5;\n    if (get_te16(&ehdr->e_phentsize) != sizeof(Elf32_Phdr))\n        return 6;\n\n    if (type == Elf32_Ehdr::ET_EXEC) {\n        // check for Linux kernels\n        unsigned const entry = get_te32(&ehdr->e_entry);\n        if (entry == 0xC0100000)    // uncompressed vmlinux\n            return 1000;\n        if (entry == 0x00001000)    // compressed vmlinux\n            return 1001;\n        if (entry == 0x00100000)    // compressed bvmlinux\n            return 1002;\n    }\n\n    // FIXME: add more checks for kernels\n\n    // FIXME: add special checks for other ELF i386 formats, like\n    //        NetBSD, OpenBSD, Solaris, ....\n\n    // success\n    return 0;\n}\n\nint\nPackLinuxElf64::checkEhdr(Elf64_Ehdr const *ehdr) const\n{\n    const unsigned char * const buf = ehdr->e_ident;\n    unsigned char osabi0 = buf[Elf32_Ehdr::EI_OSABI];\n    if (0==osabi0) {\n        osabi0 = opt->o_unix.osabi0;\n    }\n\n    if (0!=memcmp(buf, \"\\x7f\\x45\\x4c\\x46\", 4)  // \"\\177ELF\"\n    ||  buf[Elf64_Ehdr::EI_CLASS]!=ei_class\n    ||  buf[Elf64_Ehdr::EI_DATA] !=ei_data\n    ||                     osabi0!=ei_osabi\n    ) {\n        return -1;\n    }\n    if (!memcmp(buf+8, \"FreeBSD\", 7))                   // branded\n        return 1;\n\n    int const type = get_te16(&ehdr->e_type);\n    if (type != Elf64_Ehdr::ET_EXEC && type != Elf64_Ehdr::ET_DYN)\n        return 2;\n    if (get_te16(&ehdr->e_machine) != (unsigned) e_machine)\n        return 3;\n    if (get_te32(&ehdr->e_version) != Elf64_Ehdr::EV_CURRENT)\n        return 4;\n    if (e_phnum < 1)\n        return 5;\n    if (get_te16(&ehdr->e_phentsize) != sizeof(Elf64_Phdr))\n        return 6;\n\n    if (type == Elf64_Ehdr::ET_EXEC) {\n        // check for Linux kernels\n        upx_uint64_t const entry = get_te64(&ehdr->e_entry);\n        if (entry == 0xC0100000)    // uncompressed vmlinux\n            return 1000;\n        if (entry == 0x00001000)    // compressed vmlinux\n            return 1001;\n        if (entry == 0x00100000)    // compressed bvmlinux\n            return 1002;\n    }\n\n    // FIXME: add more checks for kernels\n\n    // FIXME: add special checks for other ELF i386 formats, like\n    //        NetBSD, OpenBSD, Solaris, ....\n\n    // success\n    return 0;\n}\n\nPackLinuxElf::PackLinuxElf(InputFile *f)\n    : super(f), e_phnum(0), dynstr(nullptr),\n    sz_phdrs(0), sz_elf_hdrs(0), sz_pack2(0), sz_pack2a(0),\n    lg2_page(12), page_size(1u<<lg2_page), is_pie(0),\n    xct_off(0), xct_va(0), jni_onload_va(0),\n    user_init_va(0), user_init_off(0),\n    e_machine(0), ei_class(0), ei_data(0), ei_osabi(0), osabi_note(nullptr),\n    shstrtab(nullptr),\n    o_elf_shnum(0)\n{\n    memset(dt_table, 0, sizeof(dt_table));\n}\n\nPackLinuxElf::~PackLinuxElf()\n{\n}\n\nint PackLinuxElf32::is_LOAD32(Elf32_Phdr const *phdr) const\n{\n    // (1+ PT_LOPROC) can confuse!\n    return PT_LOAD32 == get_te32(&phdr->p_type);\n}\n\nvoid\nPackLinuxElf32::PackLinuxElf32help1(InputFile *f)\n{\n    e_type  = get_te16(&ehdri.e_type);\n    e_phnum = get_te16(&ehdri.e_phnum);\n    e_shnum = get_te16(&ehdri.e_shnum);\n    unsigned const e_phentsize = get_te16(&ehdri.e_phentsize);\n    if (memcmp((char const *)&ehdri, \"\\x7f\\x45\\x4c\\x46\", 4)  // \"\\177ELF\"\n    || ehdri.e_ident[Elf32_Ehdr::EI_CLASS]!=Elf32_Ehdr::ELFCLASS32\n    || sizeof(Elf32_Phdr) != e_phentsize\n    || (Elf32_Ehdr::ELFDATA2MSB == ehdri.e_ident[Elf32_Ehdr::EI_DATA]\n            && &N_BELE_RTP::be_policy != bele)\n    || (Elf32_Ehdr::ELFDATA2LSB == ehdri.e_ident[Elf32_Ehdr::EI_DATA]\n            && &N_BELE_RTP::le_policy != bele)) {\n        e_phoff = 0;\n        e_shoff = 0;\n        sz_phdrs = 0;\n        return;\n    }\n    if (0==e_phnum) throwCantUnpack(\"0==e_phnum\");\n    e_phoff = get_te32(&ehdri.e_phoff);\n    unsigned const last_Phdr = e_phoff + e_phnum * usizeof(Elf32_Phdr);\n    if (last_Phdr < e_phoff  // wrap-around\n    ||  e_phoff != sizeof(Elf32_Ehdr)  // must be contiguous\n    ||  (unsigned long)file_size < last_Phdr) {\n        throwCantUnpack(\"bad e_phoff\");\n    }\n    e_shoff = get_te32(&ehdri.e_shoff);\n    unsigned const last_Shdr = e_shoff + e_shnum * usizeof(Elf32_Shdr);\n    if (last_Shdr < e_shoff  // wrap-around\n    ||  (e_shnum && e_shoff < last_Phdr)\n    ||  (unsigned long)file_size < last_Shdr) {\n        if (opt->cmd == CMD_COMPRESS) {\n            throwCantUnpack(\"bad e_shoff\");\n        }\n    }\n    sz_phdrs = e_phnum * e_phentsize;\n\n    if (f && Elf32_Ehdr::ET_DYN!=e_type) {\n        unsigned const len = sz_phdrs + e_phoff;\n        alloc_file_image(file_image, len);\n        f->seek(0, SEEK_SET);\n        f->readx(file_image, len);\n        phdri= (Elf32_Phdr       *)(e_phoff + file_image);  // do not free() !!\n    }\n    if (f && Elf32_Ehdr::ET_DYN==e_type) {\n        // The DT_SYMTAB has no designated length.  Read the whole file.\n        alloc_file_image(file_image, file_size);\n        f->seek(0, SEEK_SET);\n        f->readx(file_image, file_size);\n        phdri= (Elf32_Phdr *)(e_phoff + file_image);  // do not free() !!\n        shdri= (Elf32_Shdr *)(e_shoff + file_image);  // do not free() !!\n        if (opt->cmd != CMD_COMPRESS) {\n            shdri = nullptr;\n        }\n        sec_dynsym = elf_find_section_type(Elf32_Shdr::SHT_DYNSYM);\n        if (sec_dynsym) {\n            unsigned t = get_te32(&sec_dynsym->sh_link);\n            if (e_shnum <= t)\n                throwCantPack(\"bad dynsym->sh_link\");\n            sec_dynstr = &shdri[t];\n        }\n\n        Elf32_Phdr const *phdr= phdri;\n        for (int j = e_phnum; --j>=0; ++phdr)\n        if (Elf32_Phdr::PT_DYNAMIC==get_te32(&phdr->p_type)) {\n            unsigned offset = check_pt_dynamic(phdr);\n            dynseg= (Elf32_Dyn const *)(offset + file_image);\n            invert_pt_dynamic(dynseg,\n                umin(get_te32(&phdr->p_filesz), file_size - offset));\n        }\n        else if (is_LOAD32(phdr)) {\n            check_pt_load(phdr);\n        }\n        // elf_find_dynamic() returns 0 if 0==dynseg.\n        dynstr =      (char const *)elf_find_dynamic(Elf32_Dyn::DT_STRTAB);\n        dynsym = (Elf32_Sym const *)elf_find_dynamic(Elf32_Dyn::DT_SYMTAB);\n        gashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_GNU_HASH);\n        hashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_HASH);\n        if (3& ((upx_uintptr_t)dynsym | (upx_uintptr_t)gashtab | (upx_uintptr_t)hashtab)) {\n            throwCantPack(\"unaligned DT_SYMTAB, DT_GNU_HASH, or DT_HASH/n\");\n        }\n        jni_onload_sym = elf_lookup(\"JNI_OnLoad\");\n        if (jni_onload_sym) {\n            jni_onload_va = get_te32(&jni_onload_sym->st_value);\n            jni_onload_va = 0;  // FIXME not understood; need example\n        }\n    }\n}\n\noff_t PackLinuxElf::pack3(OutputFile *fo, Filter &ft) // return length of output\n{\n    unsigned disp;\n    unsigned const zero = 0;\n    unsigned len = sz_pack2a;  // after headers and all PT_LOAD\n\n    unsigned const t = (4 & len) ^ ((!!xct_off)<<2);  // 0 or 4\n    fo->write(&zero, t);\n    len += t;  // force sz_pack2 (0 mod 8)  [see below]\n\n    set_te32(&disp, sz_elf_hdrs + usizeof(p_info) + usizeof(l_info) +\n        (!!xct_off & !!opt->o_unix.android_shlib));  // |1 iff android shlib\n    fo->write(&disp, sizeof(disp));  // offset(b_info)\n    len += sizeof(disp);\n    set_te32(&disp, len);  // distance back to beginning (detect dynamic reloc)\n    fo->write(&disp, sizeof(disp));\n    len += sizeof(disp);\n\n    if (xct_off) {  // is_shlib\n        upx_uint64_t const firstpc_va = (jni_onload_va\n            ? jni_onload_va\n            : user_init_va);\n        set_te32(&disp, firstpc_va - load_va);\n        fo->write(&disp, sizeof(disp));  // DT_INIT.d_val\n        len += sizeof(disp);\n\n        set_te32(&disp, hatch_off);\n        fo->write(&disp, sizeof(disp));  // offset(hatch)\n        len += sizeof(disp);\n\n        if (opt->o_unix.android_shlib) {\n            xct_off += asl_delta;  // the extra page\n        }\n        set_te32(&disp, overlay_offset - sizeof(linfo));\n        fo->write(&disp, sizeof(disp));  // &{l_info; p_info; b_info}\n        len += sizeof(disp);\n    }\n    sz_pack2 = len;  // 0 mod 8  [see above]\n\n    super::pack3(fo, ft);  // append the decompressor\n    set_te16(&linfo.l_lsize, up4(  // MATCH03: up4\n    get_te16(&linfo.l_lsize) + len - sz_pack2a));\n\n    return fpad4(fo);  // MATCH03\n}\n\n// C_BASE covers the convex hull of the PT_LOAD of the uncompressed module.\n// It has (PF_W & .p_flags), and is \".bss\": empty (0==.p_filesz, except a bug\n// in Linux kernel forces 0x1000==.p_filesz) with .p_memsz equal to the brk(0).\n// It is first in order to reserve all // pages, in particular so that if\n// (64K == .p_align) but at runtime (4K == PAGE_SIZE) then the Linux kernel\n// does not put [vdso] and [vvar] into alignment holes that the UPX runtime stub\n// will overwrite.\n//\n// Note that C_TEXT[.p_vaddr, +.p_memsz) is a subset of C_BASE.\n// This requires that the kernel process the ELFxx_Phdr in ascending order,\n// and does not mind the overlap.  The UPX runtime stub will \"re-program\"\n// the memory regions anyway.\nenum { // ordinals in ELFxx_Phdr[] of compressed output\n      C_BASE = 0  // reserve address space\n    , C_TEXT = 1  // compressed data and stub\n    , C_NOTE = 2  // PT_NOTE copied from input\n    , C_GSTK = 3  // PT_GNU_STACK; will be 2 if no PT_NOTE\n};\n\noff_t PackLinuxElf32::pack3(OutputFile *fo, Filter &ft)\n{\n    off_t flen = super::pack3(fo, ft);  // loader follows compressed PT_LOADs\n    // NOTE: PackLinuxElf::pack3  adjusted xct_off for the extra page\n\n    unsigned v_hole = sz_pack2 + lsize;\n    set_te32(&elfout.phdr[C_TEXT].p_filesz, v_hole);\n    set_te32(&elfout.phdr[C_TEXT].p_memsz,  v_hole);\n    // Then compressed gaps (including debuginfo.)\n    for (unsigned k = 0; k < e_phnum; ++k) {\n        Extent x;\n        x.size = find_LOAD_gap(phdri, k, e_phnum);\n        if (x.size) {\n            x.offset = get_te32(&phdri[k].p_offset) +\n                       get_te32(&phdri[k].p_filesz);\n            packExtent(x, nullptr, fo);\n        }\n    }\n    // write block end marker (uncompressed size 0)\n    b_info hdr; memset(&hdr, 0, sizeof(hdr));\n    set_le32(&hdr.sz_cpr, UPX_MAGIC_LE32);\n    fo->write(&hdr, sizeof(hdr));\n    flen = fpad4(fo);\n\n    set_te32(&elfout.phdr[C_TEXT].p_filesz, sz_pack2 + lsize);\n    set_te32(&elfout.phdr[C_TEXT].p_memsz,  sz_pack2 + lsize);\n    if (0==xct_off) { // not shared library\n        set_te32(&elfout.phdr[C_BASE].p_align, 0u - page_mask);\n        elfout.phdr[C_BASE].p_paddr = elfout.phdr[C_BASE].p_vaddr;\n        elfout.phdr[C_BASE].p_offset = 0;\n        // vbase handles ET_EXEC.  FIXME: pre-linking?\n        unsigned vbase = get_te32(&elfout.phdr[C_BASE].p_vaddr);\n        unsigned abrk = getbrk(phdri, e_phnum);\n        set_te32(&elfout.phdr[C_BASE].p_filesz, 0x1000);  // Linux kernel SIGSEGV if (0==.p_filesz)\n        set_te32(&elfout.phdr[C_BASE].p_memsz, abrk - vbase);\n        set_te32(&elfout.phdr[C_BASE].p_flags, Elf32_Phdr::PF_W|Elf32_Phdr::PF_R);\n        set_te32(&elfout.phdr[C_TEXT].p_vaddr, abrk= (page_mask & (~page_mask + abrk)));\n        elfout.phdr[C_TEXT].p_paddr = elfout.phdr[C_TEXT].p_vaddr;\n        set_te32(&elfout.ehdr.e_entry, abrk + get_te32(&elfout.ehdr.e_entry) - vbase);\n    }\n    if (0!=xct_off) {  // shared library\n        unsigned word = (Elf32_Ehdr::EM_ARM==e_machine) + load_va + sz_pack2;  // Thumb mode\n        set_te32(&file_image[user_init_off], word);  // set the hook\n\n        Elf32_Phdr *phdr = (Elf32_Phdr *)lowmem.subref(\n                \"bad e_phoff\", e_phoff, e_phnum * sizeof(Elf32_Phdr));\n        unsigned off = fo->st_size();\n        so_slide = 0;\n        for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n            unsigned const len  = get_te32(&phdr->p_filesz);\n            unsigned const ioff = get_te32(&phdr->p_offset);\n            unsigned       align= get_te32(&phdr->p_align);\n            unsigned const type = get_te32(&phdr->p_type);\n            if (Elf32_Phdr::PT_INTERP==type) {\n                // Rotate to highest position, so it can be lopped\n                // by decrementing e_phnum.\n                memcpy((unsigned char *)ibuf, phdr, sizeof(*phdr));  // extract\n                memmove(phdr, 1+phdr, (e_phnum - (1+ j))*sizeof(*phdr));  // overlapping\n                memcpy(&phdr[e_phnum - (1+ j)], (unsigned char *)ibuf, sizeof(*phdr));  // to top\n                --phdr; --e_phnum;\n                set_te16(&ehdri.e_phnum, e_phnum);\n                set_te16(&((Elf32_Ehdr *)(unsigned char *)lowmem)->e_phnum, e_phnum);\n                continue;\n            }\n            if (PT_LOAD32 == type) {\n                if ((xct_off - ioff) < len) { // Change length of compressed PT_LOAD.\n                    set_te32(&phdr->p_filesz, sz_pack2 + lsize - ioff);\n                    set_te32(&phdr->p_memsz,  sz_pack2 + lsize - ioff);\n                    if (user_init_off < xct_off) { // MIPS puts PT_DYNAMIC here\n                        // Allow for DT_INIT in a new [stolen] slot\n                        unsigned off2 = user_init_off - sizeof(word);\n                        fo->seek(off2, SEEK_SET);\n                        fo->rewrite(&file_image[off2], 2*sizeof(word));\n                    }\n                }\n                else if (xct_off < ioff) { // Slide subsequent PT_LOAD.\n                    if ((1u<<12) < align) {\n                        align = 1u<<12;\n                        set_te32(&phdr->p_align, align);\n                    }\n                    off += (align-1) & (ioff - off);\n                    fo->seek(  off, SEEK_SET);\n                    fo->write(&file_image[ioff], len);\n                    so_slide = off - ioff;\n                    set_te32(&phdr->p_offset, so_slide + ioff);\n                }\n                continue;  // all done with this PT_LOAD\n            }\n            if (xct_off < ioff)\n                set_te32(&phdr->p_offset, so_slide + ioff);\n        }  // end each Phdr\n\n        if (opt->o_unix.android_shlib) {\n            // Update {DYNAMIC}.sh_offset by so_slide.\n            Elf32_Shdr *shdr = (Elf32_Shdr *)lowmem.subref(\n                    \"bad e_shoff\", xct_off - asl_delta, e_shnum * sizeof(Elf32_Shdr));\n            for (unsigned j = 0; j < e_shnum; ++shdr, ++j) {\n                unsigned sh_type = get_te32(&shdr->sh_type);\n                if (Elf32_Shdr::SHT_DYNAMIC == get_te32(&shdr->sh_type)) {\n                    unsigned offset = get_te32(&shdr->sh_offset);\n                    set_te32(&shdr->sh_offset, so_slide + offset );\n                    fo->seek((j * sizeof(Elf32_Shdr)) + xct_off - asl_delta, SEEK_SET);\n                    fo->rewrite(shdr, sizeof(*shdr));\n                    fo->seek(0, SEEK_END);\n                }\n                if (Elf32_Shdr::SHT_REL == sh_type\n                &&  n_jmp_slot\n                &&  !strcmp(\".rel.plt\", get_te32(&shdr->sh_name) + shstrtab)) {\n                    unsigned f_off = elf_get_offset_from_address(plt_off);\n                    fo->seek(so_slide + f_off, SEEK_SET);  // FIXME: assumes PT_LOAD[1]\n                    fo->rewrite(&file_image[f_off], n_jmp_slot * 4);\n                 }\n            }\n        }\n        else { // !opt->o_unix.android_shlib)\n            ehdri.e_shnum = 0;\n            ehdri.e_shoff = 0;\n            ehdri.e_shstrndx = 0;\n        }\n    }\n    return flen;\n}\n\noff_t PackLinuxElf64::pack3(OutputFile *fo, Filter &ft)\n{\n    off_t flen = super::pack3(fo, ft);  // loader follows compressed PT_LOADs\n    // NOTE: PackLinuxElf::pack3  adjusted xct_off for the extra page\n\n    unsigned v_hole = sz_pack2 + lsize;\n    set_te64(&elfout.phdr[C_TEXT].p_filesz, v_hole);\n    set_te64(&elfout.phdr[C_TEXT].p_memsz,  v_hole);\n    // Then compressed gaps (including debuginfo.)\n    for (unsigned k = 0; k < e_phnum; ++k) {\n        Extent x;\n        x.size = find_LOAD_gap(phdri, k, e_phnum);\n        if (x.size) {\n            x.offset = get_te64(&phdri[k].p_offset) +\n                       get_te64(&phdri[k].p_filesz);\n            packExtent(x, nullptr, fo);\n        }\n    }\n    // write block end marker (uncompressed size 0)\n    b_info hdr; memset(&hdr, 0, sizeof(hdr));\n    set_le32(&hdr.sz_cpr, UPX_MAGIC_LE32);\n    fo->write(&hdr, sizeof(hdr));\n    flen = fpad4(fo);\n\n    set_te64(&elfout.phdr[C_TEXT].p_filesz, sz_pack2 + lsize);\n    set_te64(&elfout.phdr[C_TEXT].p_memsz,  sz_pack2 + lsize);\n    if (0==xct_off) { // not shared library\n        set_te64(&elfout.phdr[C_BASE].p_align, ((upx_uint64_t)0) - page_mask);\n        elfout.phdr[C_BASE].p_paddr = elfout.phdr[C_BASE].p_vaddr;\n        elfout.phdr[C_BASE].p_offset = 0;\n        upx_uint64_t abrk = getbrk(phdri, e_phnum);\n        // vbase handles ET_EXEC.  FIXME: pre-linking?\n        upx_uint64_t const vbase = get_te64(&elfout.phdr[C_BASE].p_vaddr);\n        set_te64(&elfout.phdr[C_BASE].p_filesz, 0x1000);  // Linux kernel SIGSEGV if (0==.p_filesz)\n        set_te64(&elfout.phdr[C_BASE].p_memsz, abrk - vbase);\n        set_te32(&elfout.phdr[C_BASE].p_flags, Elf32_Phdr::PF_W|Elf32_Phdr::PF_R);\n        set_te64(&elfout.phdr[C_TEXT].p_vaddr, abrk= (page_mask & (~page_mask + abrk)));\n        elfout.phdr[C_TEXT].p_paddr = elfout.phdr[C_TEXT].p_vaddr;\n        set_te64(&elfout.ehdr.e_entry, abrk + get_te64(&elfout.ehdr.e_entry) - vbase);\n    }\n    if (0!=xct_off) {  // shared library\n        upx_uint64_t word = load_va + sz_pack2;\n        set_te64(&file_image[user_init_off], word);  // set the hook\n\n        Elf64_Phdr *phdr = (Elf64_Phdr *)lowmem.subref(\n                \"bad e_phoff\", e_phoff, e_phnum * sizeof(Elf64_Phdr));\n        unsigned off = fo->st_size();\n        so_slide = 0;\n        for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n            upx_uint64_t const len  = get_te64(&phdr->p_filesz);\n            upx_uint64_t const ioff = get_te64(&phdri[j].p_offset);\n            upx_uint64_t       align= get_te64(&phdr->p_align);\n            unsigned const type = get_te32(&phdr->p_type);\n            if (Elf64_Phdr::PT_INTERP==type) {\n                // Rotate to highest position, so it can be lopped\n                // by decrementing e_phnum.\n                memcpy((unsigned char *)ibuf, phdr, sizeof(*phdr));  // extract\n                memmove(phdr, 1+phdr, (e_phnum - (1+ j))*sizeof(*phdr));  // overlapping\n                memcpy(&phdr[e_phnum - (1+ j)], (unsigned char *)ibuf, sizeof(*phdr));  // to top\n                --phdr; --e_phnum;\n                set_te16(&ehdri.e_phnum, e_phnum);\n                set_te16(&((Elf64_Ehdr *)(unsigned char *)lowmem)->e_phnum, e_phnum);\n                continue;\n            }\n            if (PT_LOAD64 == type) {\n                if ((xct_off - ioff) < len) { // Change length of compressed PT_LOAD.\n                    set_te64(&phdr->p_filesz, sz_pack2 + lsize);\n                    set_te64(&phdr->p_memsz,  sz_pack2 + lsize);\n                    if (user_init_off < xct_off) { // MIPS puts PT_DYNAMIC here\n                        // Allow for DT_INIT in a new [stolen] slot\n                        unsigned off2 = user_init_off - sizeof(word);\n                        fo->seek(off2, SEEK_SET);\n                        fo->rewrite(&file_image[off2], 2*sizeof(word));\n                    }\n                }\n                else if (j && (Elf64_Phdr::PF_W & get_te64(&phdr->p_flags))\n                     &&  xct_off < ioff) {  // Slide subsequent PT_LOAD.\n                    // AMD64 chip supports page sizes of 4KiB, 2MiB, and 1GiB;\n                    // the operating system chooses one.  .p_align typically\n                    // is a forward-looking 2MiB.  In 2009 Linux chooses 4KiB.\n                    // We choose 4KiB to waste less space.  If Linux chooses\n                    // 2MiB later, then our output will not run.\n                    if ((1u<<12) < align\n                    &&  Elf64_Ehdr::EM_X86_64 ==e_machine\n                    ) {\n                        align = 1u<<12;\n                        set_te64(&phdr->p_align, align);\n                    }\n                    off += (align-1) & (ioff - off);\n                    set_te64(&phdr->p_offset, off);\n                    so_slide = off - ioff;\n                    fo->seek(  off, SEEK_SET);\n                    fo->write(&file_image[ioff], len);\n                    off += len;\n                }\n                continue;  // all done with this PT_LOAD\n            }\n            if (xct_off < ioff)\n                set_te64(&phdr->p_offset, so_slide + ioff);\n        }  // end each Phdr\n\n        if (opt->o_unix.android_shlib) {\n            // Update {DYNAMIC}.sh_offset by so_slide.\n            Elf64_Shdr *shdr = (Elf64_Shdr *)lowmem.subref(\n                    \"bad e_shoff\", xct_off - asl_delta, e_shnum * sizeof(Elf64_Shdr));\n            for (unsigned j = 0; j < e_shnum; ++shdr, ++j) {\n                unsigned sh_type = get_te32(&shdr->sh_type);\n                if (Elf64_Shdr::SHT_DYNAMIC == sh_type) {\n                    upx_uint64_t offset = get_te64(&shdr->sh_offset);\n                    set_te64(&shdr->sh_offset, so_slide + offset);\n                    fo->seek((j * sizeof(Elf64_Shdr)) + xct_off - asl_delta, SEEK_SET);\n                    fo->rewrite(shdr, sizeof(*shdr));\n                    fo->seek(0, SEEK_END);\n                }\n                if (Elf64_Shdr::SHT_RELA == sh_type\n                &&  n_jmp_slot\n                &&  !strcmp(\".rela.plt\", get_te32(&shdr->sh_name) + shstrtab)) {\n                    upx_uint64_t f_off = elf_get_offset_from_address(plt_off);\n                    fo->seek(so_slide + f_off, SEEK_SET);  // FIXME: assumes PT_LOAD[1]\n                    fo->rewrite(&file_image[f_off], n_jmp_slot * 8);\n                }\n            }\n        }\n        else { // !opt->o_unix.android_shlib)\n            ehdri.e_shnum = 0;\n            ehdri.e_shoff = 0;\n            ehdri.e_shstrndx = 0;\n        }\n    }\n    return flen;\n}\n\nvoid\nPackLinuxElf::addStubEntrySections(Filter const *)\n{\n    addLoader(\"ELFMAINX\", nullptr);\n    if (hasLoaderSection(\"ELFMAINXu\")) {\n            // brk() trouble if static\n        addLoader(\"ELFMAINXu\", nullptr);\n    }\n   //addLoader(getDecompressorSections(), nullptr);\n    addLoader(\n        ( M_IS_NRV2E(ph.method) ? \"NRV_HEAD,NRV2E,NRV_TAIL\"\n        : M_IS_NRV2D(ph.method) ? \"NRV_HEAD,NRV2D,NRV_TAIL\"\n        : M_IS_NRV2B(ph.method) ? \"NRV_HEAD,NRV2B,NRV_TAIL\"\n        : M_IS_LZMA(ph.method)  ? \"LZMA_ELF00,LZMA_DEC20,LZMA_DEC30\"\n        : nullptr), nullptr);\n    if (hasLoaderSection(\"CFLUSH\"))\n        addLoader(\"CFLUSH\");\n    addLoader(\"ELFMAINY,IDENTSTR\", nullptr);\n    if (hasLoaderSection(\"ELFMAINZe\")) { // ppc64 big-endian only\n        addLoader(\"ELFMAINZe\", nullptr);\n    }\n    addLoader(\"+40,ELFMAINZ\", nullptr);\n    if (hasLoaderSection(\"ANDMAJNZ\")) { // Android trouble with args to DT_INIT\n        if (opt->o_unix.android_shlib) {\n            addLoader(\"ANDMAJNZ\", nullptr);  // constant PAGE_SIZE\n        }\n        else {\n            addLoader(\"ELFMAJNZ\", nullptr);  // PAGE_SIZE from AT_PAGESZ\n        }\n        addLoader(\"ELFMAKNZ\", nullptr);\n    }\n    if (hasLoaderSection(\"ELFMAINZu\")) {\n        addLoader(\"ELFMAINZu\", nullptr);\n    }\n    addLoader(\"FOLDEXEC\", nullptr);\n}\n\n\nvoid PackLinuxElf::defineSymbols(Filter const *)\n{\n    linker->defineSymbol(\"O_BINFO\", (!!opt->o_unix.is_ptinterp) | o_binfo);\n}\n\nvoid PackLinuxElf32::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf::defineSymbols(ft);\n}\n\nvoid PackLinuxElf64::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf::defineSymbols(ft);\n}\n\nPackLinuxElf32::PackLinuxElf32(InputFile *f)\n    : super(f), phdri(nullptr), shdri(nullptr),\n    gnu_stack(nullptr),\n    page_mask(~0u<<lg2_page),\n    dynseg(nullptr), hashtab(nullptr), hashend(nullptr),\n                     gashtab(nullptr), gashend(nullptr), dynsym(nullptr),\n    jni_onload_sym(nullptr),\n    sec_strndx(nullptr), sec_dynsym(nullptr), sec_dynstr(nullptr)\n    , symnum_end(0)\n{\n    memset(&ehdri, 0, sizeof(ehdri));\n    if (f) {\n        f->seek(0, SEEK_SET);\n        f->readx(&ehdri, sizeof(ehdri));\n    }\n}\n\nPackLinuxElf32::~PackLinuxElf32()\n{\n}\n\nPackLinuxElf64::PackLinuxElf64(InputFile *f)\n    : super(f), phdri(nullptr), shdri(nullptr),\n    gnu_stack(nullptr),\n    page_mask(~0ull<<lg2_page),\n    dynseg(nullptr), hashtab(nullptr), hashend(nullptr),\n                     gashtab(nullptr), gashend(nullptr), dynsym(nullptr),\n    jni_onload_sym(nullptr),\n    sec_strndx(nullptr), sec_dynsym(nullptr), sec_dynstr(nullptr)\n    , symnum_end(0)\n{\n    memset(&ehdri, 0, sizeof(ehdri));\n    if (f) {\n        f->seek(0, SEEK_SET);\n        f->readx(&ehdri, sizeof(ehdri));\n    }\n}\n\nPackLinuxElf64::~PackLinuxElf64()\n{\n}\n\n// FIXME: should be templated with PackLinuxElf32help1\nvoid\nPackLinuxElf64::PackLinuxElf64help1(InputFile *f)\n{\n    e_type  = get_te16(&ehdri.e_type);\n    e_phnum = get_te16(&ehdri.e_phnum);\n    e_shnum = get_te16(&ehdri.e_shnum);\n    unsigned const e_phentsize = get_te16(&ehdri.e_phentsize);\n    if (memcmp((char const *)&ehdri, \"\\x7f\\x45\\x4c\\x46\", 4)  // \"\\177ELF\"\n    || ehdri.e_ident[Elf64_Ehdr::EI_CLASS]!=Elf64_Ehdr::ELFCLASS64\n    || sizeof(Elf64_Phdr) != e_phentsize\n    || (Elf64_Ehdr::ELFDATA2MSB == ehdri.e_ident[Elf64_Ehdr::EI_DATA]\n            && &N_BELE_RTP::be_policy != bele)\n    || (Elf64_Ehdr::ELFDATA2LSB == ehdri.e_ident[Elf64_Ehdr::EI_DATA]\n            && &N_BELE_RTP::le_policy != bele)) {\n        e_phoff = 0;\n        e_shoff = 0;\n        sz_phdrs = 0;\n        return;\n    }\n    if (0==e_phnum) throwCantUnpack(\"0==e_phnum\");\n    e_phoff = get_te64(&ehdri.e_phoff);\n    upx_uint64_t const last_Phdr = e_phoff + e_phnum * sizeof(Elf64_Phdr);\n    if (last_Phdr < e_phoff  // wrap-around\n    ||  e_phoff != sizeof(Elf64_Ehdr)  // must be contiguous\n    ||  (unsigned long)file_size < last_Phdr) {\n        throwCantUnpack(\"bad e_phoff\");\n    }\n    e_shoff = get_te64(&ehdri.e_shoff);\n    upx_uint64_t const last_Shdr = e_shoff + e_shnum * sizeof(Elf64_Shdr);\n    if (last_Shdr < e_shoff  // wrap-around\n    ||  (e_shnum && e_shoff < last_Phdr)\n    ||  (unsigned long)file_size < last_Shdr) {\n        if (opt->cmd == CMD_COMPRESS) {\n            throwCantUnpack(\"bad e_shoff\");\n        }\n    }\n    sz_phdrs = e_phnum * e_phentsize;\n    sz_elf_hdrs = sz_phdrs + sizeof(Elf64_Ehdr);\n\n    if (f && Elf64_Ehdr::ET_DYN!=e_type) {\n        unsigned const len = sz_phdrs + e_phoff;\n        alloc_file_image(file_image, len);\n        f->seek(0, SEEK_SET);\n        f->readx(file_image, len);\n        phdri= (Elf64_Phdr       *)(e_phoff + file_image);  // do not free() !!\n    }\n    if (f && Elf64_Ehdr::ET_DYN==e_type) {\n        // The DT_SYMTAB has no designated length.  Read the whole file.\n        alloc_file_image(file_image, file_size);\n        f->seek(0, SEEK_SET);\n        f->readx(file_image, file_size);\n        phdri= (Elf64_Phdr *)(e_phoff + file_image);  // do not free() !!\n        shdri= (Elf64_Shdr *)(e_shoff + file_image);  // do not free() !!\n        if (opt->cmd != CMD_COMPRESS) {\n            shdri = nullptr;\n        }\n        sec_dynsym = elf_find_section_type(Elf64_Shdr::SHT_DYNSYM);\n        if (sec_dynsym) {\n            unsigned t = get_te32(&sec_dynsym->sh_link);\n            if (e_shnum <= t)\n                throwCantPack(\"bad dynsym->sh_link\");\n            sec_dynstr = &shdri[t];\n        }\n\n        Elf64_Phdr const *phdr= phdri;\n        for (int j = e_phnum; --j>=0; ++phdr)\n        if (Elf64_Phdr::PT_DYNAMIC==get_te32(&phdr->p_type)) {\n            upx_uint64_t offset = check_pt_dynamic(phdr);\n            dynseg= (Elf64_Dyn const *)(offset + file_image);\n            invert_pt_dynamic(dynseg,\n                umin(get_te64(&phdr->p_filesz), file_size - offset));\n        }\n        else if (PT_LOAD64==get_te32(&phdr->p_type)) {\n            check_pt_load(phdr);\n        }\n        // elf_find_dynamic() returns 0 if 0==dynseg.\n        dynstr =      (char const *)elf_find_dynamic(Elf64_Dyn::DT_STRTAB);\n        dynsym = (Elf64_Sym const *)elf_find_dynamic(Elf64_Dyn::DT_SYMTAB);\n        gashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_GNU_HASH);\n        hashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_HASH);\n        if (3& ((upx_uintptr_t)dynsym | (upx_uintptr_t)gashtab | (upx_uintptr_t)hashtab)) {\n            throwCantPack(\"unaligned DT_SYMTAB, DT_GNU_HASH, or DT_HASH/n\");\n        }\n        jni_onload_sym = elf_lookup(\"JNI_OnLoad\");\n        if (jni_onload_sym) {\n            jni_onload_va = get_te64(&jni_onload_sym->st_value);\n            jni_onload_va = 0;  // FIXME not understood; need example\n        }\n    }\n}\n\nLinker* PackLinuxElf64amd::newLinker() const\n{\n    return new ElfLinkerAMD64;\n}\n\nLinker* PackLinuxElf64arm::newLinker() const\n{\n    return new ElfLinkerArm64LE;\n}\n\nint const *\nPackLinuxElf::getCompressionMethods(int method, int level) const\n{\n    // No real dependency on LE32.\n    return Packer::getDefaultCompressionMethods_le32(method, level);\n}\n\nint const *\nPackLinuxElf32armLe::getCompressionMethods(int method, int level) const\n{\n    return Packer::getDefaultCompressionMethods_8(method, level);\n}\n\nint const *\nPackLinuxElf32armBe::getCompressionMethods(int method, int level) const\n{\n    return Packer::getDefaultCompressionMethods_8(method, level);\n}\n\nint const *\nPackLinuxElf32ppc::getFilters() const\n{\n    static const int filters[] = {\n        0xd0,\n    FT_END };\n    return filters;\n}\n\nint const *\nPackLinuxElf64ppcle::getFilters() const\n{\n    static const int filters[] = {\n        0xd0,\n    FT_END };\n    return filters;\n}\n\nint const *\nPackLinuxElf64ppc::getFilters() const\n{\n    static const int filters[] = {\n        0xd0,\n    FT_END };\n    return filters;\n}\n\nint const *\nPackLinuxElf64amd::getFilters() const\n{\n    static const int filters[] = {\n        0x49,\n    FT_END };\n    return filters;\n}\n\nint const *\nPackLinuxElf64arm::getFilters() const\n{\n    static const int filters[] = {\n        0x52,\n    FT_END };\n    return filters;\n}\n\nvoid PackLinuxElf32::patchLoader()\n{\n}\n\nvoid PackLinuxElf64::patchLoader()\n{\n}\n\nvoid PackLinuxElf32::ARM_updateLoader(OutputFile * /*fo*/)\n{\n    set_te32(&elfout.ehdr.e_entry, sz_pack2 +\n        linker->getSymbolOffset(\"_start\") +\n        get_te32(&elfout.phdr[C_TEXT].p_vaddr));\n}\n\nvoid PackLinuxElf32armLe::updateLoader(OutputFile *fo)\n{\n    ARM_updateLoader(fo);\n}\n\nvoid PackLinuxElf32armBe::updateLoader(OutputFile *fo)\n{\n    ARM_updateLoader(fo);\n}\n\nvoid PackLinuxElf32mipsel::updateLoader(OutputFile *fo)\n{\n    ARM_updateLoader(fo);  // not ARM specific; (no 32-bit immediates)\n}\n\nvoid PackLinuxElf32mipseb::updateLoader(OutputFile *fo)\n{\n    ARM_updateLoader(fo);  // not ARM specific; (no 32-bit immediates)\n}\n\nvoid PackLinuxElf32::updateLoader(OutputFile * /*fo*/)\n{\n    unsigned start = linker->getSymbolOffset(\"_start\");\n    unsigned vbase = get_te32(&elfout.phdr[C_TEXT].p_vaddr);\n    set_te32(&elfout.ehdr.e_entry, start + sz_pack2 + vbase);\n}\n\nvoid PackLinuxElf64::updateLoader(OutputFile * /*fo*/)\n{\n    if (xct_off) {\n        return;  // FIXME elfout has no values at all\n    }\n    upx_uint64_t const vbase = get_te64(&elfout.phdr[C_TEXT].p_vaddr);\n    unsigned start = linker->getSymbolOffset(\"_start\");\n\n    if (get_te16(&elfout.ehdr.e_machine)==Elf64_Ehdr::EM_PPC64\n    &&  elfout.ehdr.e_ident[Elf64_Ehdr::EI_DATA]==Elf64_Ehdr::ELFDATA2MSB) {\n        unsigned descr = linker->getSymbolOffset(\"entry_descr\");\n\n        // External relocation of PPC64 function descriptor.\n        upx_uint64_t dot_entry = start + sz_pack2 + vbase;\n        upx_byte *p = getLoader();\n\n        set_te64(&p[descr], dot_entry);\n        set_te64(&elfout.ehdr.e_entry, descr + sz_pack2 + vbase);\n    }\n    else {\n        set_te64(&elfout.ehdr.e_entry, start + sz_pack2 + vbase);\n    }\n}\n\nPackLinuxElf32ppc::PackLinuxElf32ppc(InputFile *f)\n    : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_PPC;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2MSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf32ppc::~PackLinuxElf32ppc()\n{\n}\n\nLinker* PackLinuxElf32ppc::newLinker() const\n{\n    return new ElfLinkerPpc32;\n}\n\nPackLinuxElf64ppcle::PackLinuxElf64ppcle(InputFile *f)\n    : super(f), lg2_page(16), page_size(1u<<lg2_page)\n{\n    e_machine = Elf64_Ehdr::EM_PPC64;\n    ei_class  = Elf64_Ehdr::ELFCLASS64;\n    ei_data   = Elf64_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf64_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf64ppc::PackLinuxElf64ppc(InputFile *f)\n    : super(f), lg2_page(16), page_size(1u<<lg2_page)\n{\n    e_machine = Elf64_Ehdr::EM_PPC64;\n    ei_class  = Elf64_Ehdr::ELFCLASS64;\n    ei_data   = Elf64_Ehdr::ELFDATA2MSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf64ppcle::~PackLinuxElf64ppcle()\n{\n}\n\nPackLinuxElf64ppc::~PackLinuxElf64ppc()\n{\n}\n\nLinker* PackLinuxElf64ppcle::newLinker() const\n{\n    return new ElfLinkerPpc64le;\n}\n\nLinker* PackLinuxElf64ppc::newLinker() const\n{\n    return new ElfLinkerPpc64;\n}\n\nPackLinuxElf64amd::PackLinuxElf64amd(InputFile *f)\n    : super(f)\n{\n    // Why did PackLinuxElf64Le set lg2_page = 16 ?\n    // It causes trouble for check_pt_dynamic() from canPack().\n    lg2_page = 12;  page_size = 1u<<lg2_page;\n    e_machine = Elf64_Ehdr::EM_X86_64;\n    ei_class = Elf64_Ehdr::ELFCLASS64;\n    ei_data = Elf64_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf64arm::PackLinuxElf64arm(InputFile *f)\n    : super(f)\n{\n    e_machine = Elf64_Ehdr::EM_AARCH64;\n    ei_class = Elf64_Ehdr::ELFCLASS64;\n    ei_data = Elf64_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf64amd::~PackLinuxElf64amd()\n{\n}\n\nPackLinuxElf64arm::~PackLinuxElf64arm()\n{\n}\n\nstatic unsigned\numax(unsigned a, unsigned b)\n{\n    if (a <= b) {\n        return b;\n    }\n    return a;\n}\n\nvoid PackLinuxElf32x86::addStubEntrySections(Filter const *ft)\n{\n    int const n_mru = ft->n_mru;  // FIXME: belongs to filter? packerf?\n\n// Rely on \"+80CXXXX\" [etc] in getDecompressorSections() packer_c.cpp */\n//    // Here is a quick summary of the format of the output file:\n//    linker->setLoaderAlignOffset(\n//            // Elf32_Ehdr\n//        sizeof(elfout.ehdr) +\n//            // Elf32_Phdr: 1 for exec86, 2 for sh86, 3 for elf86\n//        (get_te16(&elfout.ehdr.e_phentsize) * get_te16(&elfout.ehdr.e_phnum)) +\n//            // checksum UPX! lsize version format\n//        sizeof(l_info) +\n//            // PT_DYNAMIC with DT_NEEDED \"forwarded\" from original file\n//        ((get_te16(&elfout.ehdr.e_phnum)==3)\n//            ? (unsigned) get_te32(&elfout.phdr[C_NOTE].p_memsz)\n//            : 0) +\n//            // p_progid, p_filesize, p_blocksize\n//        sizeof(p_info) +\n//            // compressed data\n//        b_len + ph.c_len );\n\n            // entry to stub\n    addLoader(\"LEXEC000\", nullptr);\n\n    if (ft->id) {\n        { // decompr, unfilter are separate\n            addLoader(\"LXUNF000\", nullptr);\n            addLoader(\"LXUNF002\", nullptr);\n                if (0x80==(ft->id & 0xF0)) {\n                    if (256==n_mru) {\n                        addLoader(\"MRUBYTE0\", nullptr);\n                    }\n                    else if (n_mru) {\n                        addLoader(\"LXMRU005\", nullptr);\n                    }\n                    if (n_mru) {\n                        addLoader(\"LXMRU006\", nullptr);\n                    }\n                    else {\n                        addLoader(\"LXMRU007\", nullptr);\n                    }\n            }\n            else if (0x40==(ft->id & 0xF0)) {\n                addLoader(\"LXUNF008\", nullptr);\n            }\n            addLoader(\"LXUNF010\", nullptr);\n        }\n        if (n_mru) {\n            addLoader(\"LEXEC009\", nullptr);\n        }\n    }\n    addLoader(\"LEXEC010\", nullptr);\n    addLoader(getDecompressorSections(), nullptr);\n    addLoader(\"LEXEC015\", nullptr);\n    if (ft->id) {\n        {  // decompr, unfilter are separate\n            if (0x80!=(ft->id & 0xF0)) {\n                addLoader(\"LXUNF042\", nullptr);\n            }\n        }\n        addFilter32(ft->id);\n        { // decompr, unfilter are separate\n            if (0x80==(ft->id & 0xF0)) {\n                if (0==n_mru) {\n                    addLoader(\"LXMRU058\", nullptr);\n                }\n            }\n            addLoader(\"LXUNF035\", nullptr);\n        }\n    }\n    else {\n        addLoader(\"LEXEC017\", nullptr);\n    }\n\n    addLoader(\"IDENTSTR\", nullptr);\n    addLoader(\"LEXEC020\", nullptr);\n    addLoader(\"FOLDEXEC\", nullptr);\n}\n\nvoid PackLinuxElf32x86::defineSymbols(Filter const *const ft)\n{\n    PackLinuxElf32::defineSymbols(ft);\n\n    if (0x80==(ft->id & 0xF0)) {\n        int const mru = ft->n_mru ? 1+ ft->n_mru : 0;\n        if (mru && mru!=256) {\n            unsigned const is_pwr2 = (0==((mru -1) & mru));\n            linker->defineSymbol(\"NMRU\", mru - is_pwr2);\n        }\n    }\n}\n\nvoid\nPackLinuxElf32::buildLinuxLoader(\n    upx_byte const *const proto,\n    unsigned        const szproto,\n    upx_byte const *const fold,\n    unsigned        const szfold,\n    Filter const *ft\n)\n{\n    initLoader(proto, szproto);\n\n  if (0 < szfold) {\n    struct b_info h; memset(&h, 0, sizeof(h));\n    unsigned fold_hdrlen = 0;\n    cprElfHdr1 const *const hf = (cprElfHdr1 const *)fold;\n    fold_hdrlen = umax(0x80, usizeof(hf->ehdr) +\n        get_te16(&hf->ehdr.e_phentsize) * get_te16(&hf->ehdr.e_phnum) +\n            sizeof(l_info) );\n    h.sz_unc = ((szfold < fold_hdrlen) ? 0 : (szfold - fold_hdrlen));\n    h.b_method = (unsigned char) ph.method;\n    h.b_ftid = (unsigned char) ph.filter;\n    h.b_cto8 = (unsigned char) ph.filter_cto;\n    unsigned char const *const uncLoader = fold_hdrlen + fold;\n\n    MemBuffer mb_cprLoader;\n    mb_cprLoader.allocForCompression(h.sz_unc + (0==h.sz_unc));\n    h.sz_cpr = mb_cprLoader.getSize();\n    unsigned char *const cprLoader = (unsigned char *)mb_cprLoader;\n    {\n    unsigned h_sz_cpr = h.sz_cpr;\n    int r = upx_compress(uncLoader, h.sz_unc, sizeof(h) + cprLoader, &h_sz_cpr,\n        nullptr, ph.method, 10, nullptr, nullptr );\n    h.sz_cpr = h_sz_cpr;\n    if (r != UPX_E_OK || h.sz_cpr >= h.sz_unc)\n        throwInternalError(\"loader compression failed\");\n    }\n#if 0  //{  debugging only\n    if (M_IS_LZMA(ph.method)) {\n        ucl_uint tmp_len = h.sz_unc;  // LZMA uses this as EOF\n        MemBuffer mb_tmp(tmp_len);\n        unsigned char *tmp = (unsigned char *)mb_tmp;\n        memset(tmp, 0, tmp_len);\n        int r = upx_decompress(sizeof(h) + cprLoader, h.sz_cpr, tmp, &tmp_len, h.b_method, nullptr);\n        if (r == UPX_E_OUT_OF_MEMORY)\n            throwOutOfMemoryException();\n        printf(\"\\n%d %d: %d %d %d\\n\", h.b_method, r, h.sz_cpr, h.sz_unc, tmp_len);\n        for (unsigned j=0; j < h.sz_unc; ++j) if (tmp[j]!=uncLoader[j]) {\n            printf(\"%d: %x %x\\n\", j, tmp[j], uncLoader[j]);\n        }\n    }\n#endif  //}\n    unsigned const sz_cpr = h.sz_cpr;\n    set_te32(&h.sz_cpr, h.sz_cpr);\n    set_te32(&h.sz_unc, h.sz_unc);\n    memcpy(cprLoader, &h, sizeof(h));\n\n    // This adds the definition to the \"library\", to be used later.\n    linker->addSection(\"FOLDEXEC\", cprLoader, sizeof(h) + sz_cpr, 0);\n  }\n  else {\n    linker->addSection(\"FOLDEXEC\", \"\", 0, 0);\n  }\n\n    addStubEntrySections(ft);\n\n    if (0==xct_off)\n        defineSymbols(ft);  // main program only, not for shared lib\n    relocateLoader();\n}\n\nvoid\nPackLinuxElf64::buildLinuxLoader(\n    upx_byte const *const proto,\n    unsigned        const szproto,\n    upx_byte const *const fold,\n    unsigned        const szfold,\n    Filter const *ft\n)\n{\n    initLoader(proto, szproto);\n\n  if (0 < szfold) {\n    struct b_info h; memset(&h, 0, sizeof(h));\n    unsigned fold_hdrlen = 0;\n    cprElfHdr1 const *const hf = (cprElfHdr1 const *)fold;\n    fold_hdrlen = umax(0x80, usizeof(hf->ehdr) +\n        get_te16(&hf->ehdr.e_phentsize) * get_te16(&hf->ehdr.e_phnum) +\n            sizeof(l_info) );\n    h.sz_unc = ((szfold < fold_hdrlen) ? 0 : (szfold - fold_hdrlen));\n    h.b_method = (unsigned char) ph.method;\n    h.b_ftid = (unsigned char) ph.filter;\n    h.b_cto8 = (unsigned char) ph.filter_cto;\n    unsigned char const *const uncLoader = fold_hdrlen + fold;\n\n    MemBuffer mb_cprLoader;\n    mb_cprLoader.allocForCompression(h.sz_unc + (0==h.sz_unc));\n    h.sz_cpr = mb_cprLoader.getSize();\n    unsigned char *const cprLoader = (unsigned char *)mb_cprLoader;\n    {\n    unsigned h_sz_cpr = h.sz_cpr;\n    int r = upx_compress(uncLoader, h.sz_unc, sizeof(h) + cprLoader, &h_sz_cpr,\n        nullptr, forced_method(ph.method), 10, nullptr, nullptr );\n    h.sz_cpr = h_sz_cpr;\n    if (r != UPX_E_OK || h.sz_cpr >= h.sz_unc)\n        throwInternalError(\"loader compression failed\");\n    }\n#if 0  //{  debugging only\n    if (M_IS_LZMA(ph.method)) {\n        ucl_uint tmp_len = h.sz_unc;  // LZMA uses this as EOF\n        MemBuffer mb_tmp(tmp_len);\n        unsigned char *tmp = (unsigned char *)mb_tmp;\n        memset(tmp, 0, tmp_len);\n        int r = upx_decompress(sizeof(h) + cprLoader, h.sz_cpr, tmp, &tmp_len, h.b_method, nullptr);\n        if (r == UPX_E_OUT_OF_MEMORY)\n            throwOutOfMemoryException();\n        printf(\"\\n%d %d: %d %d %d\\n\", h.b_method, r, h.sz_cpr, h.sz_unc, tmp_len);\n        for (unsigned j=0; j < h.sz_unc; ++j) if (tmp[j]!=uncLoader[j]) {\n            printf(\"%d: %x %x\\n\", j, tmp[j], uncLoader[j]);\n        }\n    }\n#endif  //}\n    unsigned const sz_cpr = h.sz_cpr;\n    set_te32(&h.sz_cpr, h.sz_cpr);\n    set_te32(&h.sz_unc, h.sz_unc);\n    memcpy(cprLoader, &h, sizeof(h));\n\n    // This adds the definition to the \"library\", to be used later.\n    linker->addSection(\"FOLDEXEC\", cprLoader, sizeof(h) + sz_cpr, 0);\n  }\n  else {\n    linker->addSection(\"FOLDEXEC\", \"\", 0, 0);\n  }\n\n    addStubEntrySections(ft);\n\n    if (0==xct_off)\n        defineSymbols(ft);  // main program only, not for shared lib\n    relocateLoader();\n}\n\nvoid\nPackLinuxElf64amd::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf64::defineSymbols(ft);\n}\n\nstatic const\n#include \"stub/i386-linux.elf-entry.h\"\nstatic const\n#include \"stub/i386-linux.elf-fold.h\"\nstatic const\n#include \"stub/i386-linux.shlib-init.h\"\n\nvoid\nPackLinuxElf32x86::buildLoader(const Filter *ft)\n{\n    if (0!=xct_off) {  // shared library\n        buildLinuxLoader(\n            stub_i386_linux_shlib_init, sizeof(stub_i386_linux_shlib_init),\n            nullptr,                       0,                                ft );\n        return;\n    }\n    unsigned char tmp[sizeof(stub_i386_linux_elf_fold)];\n    memcpy(tmp, stub_i386_linux_elf_fold, sizeof(stub_i386_linux_elf_fold));\n    checkPatch(nullptr, 0, 0, 0);  // reset\n    if (opt->o_unix.is_ptinterp) {\n        unsigned j;\n        for (j = 0; j < sizeof(stub_i386_linux_elf_fold)-1; ++j) {\n            if (0x60==tmp[  j]\n            &&  0x47==tmp[1+j] ) {\n                /* put INC EDI before PUSHA: inhibits auxv_up for PT_INTERP */\n                tmp[  j] = 0x47;\n                tmp[1+j] = 0x60;\n                break;\n            }\n        }\n    }\n    buildLinuxLoader(\n        stub_i386_linux_elf_entry, sizeof(stub_i386_linux_elf_entry),\n        tmp,                       sizeof(stub_i386_linux_elf_fold),  ft );\n}\n\nstatic const\n#include \"stub/i386-bsd.elf-entry.h\"\nstatic const\n#include \"stub/i386-bsd.elf-fold.h\"\n\nvoid\nPackBSDElf32x86::buildLoader(const Filter *ft)\n{\n    unsigned char tmp[sizeof(stub_i386_bsd_elf_fold)];\n    memcpy(tmp, stub_i386_bsd_elf_fold, sizeof(stub_i386_bsd_elf_fold));\n    checkPatch(nullptr, 0, 0, 0);  // reset\n    if (opt->o_unix.is_ptinterp) {\n        unsigned j;\n        for (j = 0; j < sizeof(stub_i386_bsd_elf_fold)-1; ++j) {\n            if (0x60==tmp[  j]\n            &&  0x47==tmp[1+j] ) {\n                /* put INC EDI before PUSHA: inhibits auxv_up for PT_INTERP */\n                tmp[  j] = 0x47;\n                tmp[1+j] = 0x60;\n                break;\n            }\n        }\n    }\n    buildLinuxLoader(\n        stub_i386_bsd_elf_entry, sizeof(stub_i386_bsd_elf_entry),\n        tmp,                     sizeof(stub_i386_bsd_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/i386-netbsd.elf-entry.h\"\n\nstatic const\n#include \"stub/i386-netbsd.elf-fold.h\"\n\n#define WANT_NHDR_ENUM\n#include \"p_elf_enum.h\"\n\nvoid\nPackNetBSDElf32x86::buildLoader(const Filter *ft)\n{\n    unsigned char tmp[sizeof(stub_i386_netbsd_elf_fold)];\n    memcpy(tmp, stub_i386_netbsd_elf_fold, sizeof(stub_i386_netbsd_elf_fold));\n    checkPatch(nullptr, 0, 0, 0);  // reset\n    if (opt->o_unix.is_ptinterp) {\n        unsigned j;\n        for (j = 0; j < sizeof(stub_i386_netbsd_elf_fold)-1; ++j) {\n            if (0x60==tmp[  j]\n            &&  0x47==tmp[1+j] ) {\n                /* put INC EDI before PUSHA: inhibits auxv_up for PT_INTERP */\n                tmp[  j] = 0x47;\n                tmp[1+j] = 0x60;\n                break;\n            }\n        }\n    }\n    buildLinuxLoader(\n        stub_i386_netbsd_elf_entry, sizeof(stub_i386_netbsd_elf_entry),\n        tmp,                        sizeof(stub_i386_netbsd_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/i386-openbsd.elf-fold.h\"\n\nvoid\nPackOpenBSDElf32x86::buildLoader(const Filter *ft)\n{\n    unsigned char tmp[sizeof(stub_i386_openbsd_elf_fold)];\n    memcpy(tmp, stub_i386_openbsd_elf_fold, sizeof(stub_i386_openbsd_elf_fold));\n    checkPatch(nullptr, 0, 0, 0);  // reset\n    if (opt->o_unix.is_ptinterp) {\n        unsigned j;\n        for (j = 0; j < sizeof(stub_i386_openbsd_elf_fold)-1; ++j) {\n            if (0x60==tmp[  j]\n            &&  0x47==tmp[1+j] ) {\n                /* put INC EDI before PUSHA: inhibits auxv_up for PT_INTERP */\n                tmp[  j] = 0x47;\n                tmp[1+j] = 0x60;\n                break;\n            }\n        }\n    }\n    buildLinuxLoader(\n        stub_i386_bsd_elf_entry, sizeof(stub_i386_bsd_elf_entry),\n        tmp,                     sizeof(stub_i386_openbsd_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/arm.v5a-linux.elf-entry.h\"\nstatic const\n#include \"stub/arm.v5a-linux.elf-fold.h\"\nstatic const\n#include \"stub/arm.v5t-linux.shlib-init.h\"\n\nstatic const\n#include \"stub/arm.v4a-linux.elf-entry.h\"\nstatic const\n#include \"stub/arm.v4a-linux.elf-fold.h\"\n#if 0\nstatic const\n#include \"stub/arm.v4a-linux.shlib-init.h\"\n#endif\n\nstatic const\n#include \"stub/armeb.v4a-linux.elf-entry.h\"\nstatic const\n#include \"stub/armeb.v4a-linux.elf-fold.h\"\n\nvoid\nPackLinuxElf32armBe::buildLoader(Filter const *ft)\n{\n    buildLinuxLoader(\n        stub_armeb_v4a_linux_elf_entry, sizeof(stub_armeb_v4a_linux_elf_entry),\n        stub_armeb_v4a_linux_elf_fold,  sizeof(stub_armeb_v4a_linux_elf_fold), ft);\n}\n\nvoid\nPackLinuxElf32armLe::buildLoader(Filter const *ft)\n{\n    if (Elf32_Ehdr::ELFOSABI_LINUX==ei_osabi) {\n\n        if (0!=xct_off) {  // shared library\n            buildLinuxLoader(\n                stub_arm_v5t_linux_shlib_init, sizeof(stub_arm_v5t_linux_shlib_init),\n                nullptr,                      0,                                ft );\n            return;\n        }\n        buildLinuxLoader(\n            stub_arm_v5a_linux_elf_entry, sizeof(stub_arm_v5a_linux_elf_entry),\n            stub_arm_v5a_linux_elf_fold,  sizeof(stub_arm_v5a_linux_elf_fold), ft);\n    }\n    else {\n        buildLinuxLoader(\n            stub_arm_v4a_linux_elf_entry, sizeof(stub_arm_v4a_linux_elf_entry),\n            stub_arm_v4a_linux_elf_fold,  sizeof(stub_arm_v4a_linux_elf_fold), ft);\n    }\n}\n\nstatic const\n#include \"stub/mipsel.r3000-linux.elf-entry.h\"\nstatic const\n#include \"stub/mipsel.r3000-linux.elf-fold.h\"\nstatic const\n#include \"stub/mipsel.r3000-linux.shlib-init.h\"\n\nvoid\nPackLinuxElf32mipsel::buildLoader(Filter const *ft)\n{\n    if (0!=xct_off) {  // shared library\n        buildLinuxLoader(\n            stub_mipsel_r3000_linux_shlib_init, sizeof(stub_mipsel_r3000_linux_shlib_init),\n            nullptr,                        0,                                 ft );\n        return;\n    }\n    buildLinuxLoader(\n        stub_mipsel_r3000_linux_elf_entry, sizeof(stub_mipsel_r3000_linux_elf_entry),\n        stub_mipsel_r3000_linux_elf_fold,  sizeof(stub_mipsel_r3000_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/mips.r3000-linux.elf-entry.h\"\nstatic const\n#include \"stub/mips.r3000-linux.elf-fold.h\"\nstatic const\n#include \"stub/mips.r3000-linux.shlib-init.h\"\n\nvoid\nPackLinuxElf32mipseb::buildLoader(Filter const *ft)\n{\n    if (0!=xct_off) {  // shared library\n        buildLinuxLoader(\n            stub_mips_r3000_linux_shlib_init, sizeof(stub_mips_r3000_linux_shlib_init),\n            nullptr,                        0,                                 ft );\n        return;\n    }\n    buildLinuxLoader(\n        stub_mips_r3000_linux_elf_entry, sizeof(stub_mips_r3000_linux_elf_entry),\n        stub_mips_r3000_linux_elf_fold,  sizeof(stub_mips_r3000_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/powerpc-linux.elf-entry.h\"\nstatic const\n#include \"stub/powerpc-linux.elf-fold.h\"\n\nvoid\nPackLinuxElf32ppc::buildLoader(const Filter *ft)\n{\n    buildLinuxLoader(\n        stub_powerpc_linux_elf_entry, sizeof(stub_powerpc_linux_elf_entry),\n        stub_powerpc_linux_elf_fold,  sizeof(stub_powerpc_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/powerpc64le-linux.elf-entry.h\"\nstatic const\n#include \"stub/powerpc64le-linux.elf-fold.h\"\n\nvoid\nPackLinuxElf64ppcle::buildLoader(const Filter *ft)\n{\n    buildLinuxLoader(\n        stub_powerpc64le_linux_elf_entry, sizeof(stub_powerpc64le_linux_elf_entry),\n        stub_powerpc64le_linux_elf_fold,  sizeof(stub_powerpc64le_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/powerpc64-linux.elf-entry.h\"\nstatic const\n#include \"stub/powerpc64-linux.elf-fold.h\"\n\nvoid\nPackLinuxElf64ppc::buildLoader(const Filter *ft)\n{\n    buildLinuxLoader(\n        stub_powerpc64_linux_elf_entry, sizeof(stub_powerpc64_linux_elf_entry),\n        stub_powerpc64_linux_elf_fold,  sizeof(stub_powerpc64_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/amd64-linux.elf-entry.h\"\nstatic const\n#include \"stub/amd64-linux.elf-fold.h\"\nstatic const\n#include \"stub/amd64-linux.shlib-init.h\"\n\nvoid\nPackLinuxElf64amd::buildLoader(const Filter *ft)\n{\n    if (0!=xct_off) {  // shared library\n        buildLinuxLoader(\n            stub_amd64_linux_shlib_init, sizeof(stub_amd64_linux_shlib_init),\n            nullptr,                        0,                                 ft );\n        return;\n    }\n    buildLinuxLoader(\n        stub_amd64_linux_elf_entry, sizeof(stub_amd64_linux_elf_entry),\n        stub_amd64_linux_elf_fold,  sizeof(stub_amd64_linux_elf_fold), ft);\n}\n\nstatic const\n#include \"stub/arm64-linux.elf-entry.h\"\nstatic const\n#include \"stub/arm64-linux.elf-fold.h\"\nstatic const\n#include \"stub/arm64-linux.shlib-init.h\"\n\nvoid\nPackLinuxElf64arm::buildLoader(const Filter *ft)\n{\n    if (0!=xct_off) {  // shared library\n        buildLinuxLoader(\n            stub_arm64_linux_shlib_init, sizeof(stub_arm64_linux_shlib_init),\n            nullptr,                        0,                                 ft );\n        return;\n    }\n    buildLinuxLoader(\n        stub_arm64_linux_elf_entry, sizeof(stub_arm64_linux_elf_entry),\n        stub_arm64_linux_elf_fold,  sizeof(stub_arm64_linux_elf_fold), ft);\n}\n\nvoid\nPackLinuxElf32::invert_pt_dynamic(Elf32_Dyn const *dynp, unsigned headway)\n{\n    if (dt_table[Elf32_Dyn::DT_NULL]) {\n        return;  // not 1st time; do not change upx_dt_init\n    }\n    Elf32_Dyn const *const dynp0 = dynp;\n    unsigned ndx = 0;\n    unsigned const limit = headway / sizeof(*dynp);\n    if (dynp)\n    for (; ; ++ndx, ++dynp) {\n        if (limit <= ndx) {\n            throwCantPack(\"DT_NULL not found\");\n        }\n        unsigned const d_tag = get_te32(&dynp->d_tag);\n        if (d_tag < DT_NUM) {\n            if (Elf32_Dyn::DT_NEEDED != d_tag\n            &&  dt_table[d_tag]\n            &&    get_te32(&dynp->d_val)\n               != get_te32(&dynp0[-1+ dt_table[d_tag]].d_val)) {\n                char msg[50]; snprintf(msg, sizeof(msg),\n                    \"duplicate DT_%#x: [%#x] [%#x]\",\n                    d_tag, -1+ dt_table[d_tag], ndx);\n                throwCantPack(msg);\n            }\n            dt_table[d_tag] = 1+ ndx;\n        }\n        if (Elf32_Dyn::DT_NULL == d_tag) {\n            break;  // check here so that dt_table[DT_NULL] is set\n        }\n    }\n    upx_dt_init = 0;\n         if (dt_table[Elf32_Dyn::DT_INIT])          upx_dt_init = Elf32_Dyn::DT_INIT;\n    else if (dt_table[Elf32_Dyn::DT_PREINIT_ARRAY]) upx_dt_init = Elf32_Dyn::DT_PREINIT_ARRAY;\n    else if (dt_table[Elf32_Dyn::DT_INIT_ARRAY])    upx_dt_init = Elf32_Dyn::DT_INIT_ARRAY;\n\n    unsigned const z_str = dt_table[Elf32_Dyn::DT_STRSZ];\n    strtab_end = !z_str ? 0 : get_te64(&dynp0[-1+ z_str].d_val);\n    if (!z_str || (u64_t)file_size <= strtab_end) { // FIXME: weak\n        char msg[50]; snprintf(msg, sizeof(msg),\n            \"bad DT_STRSZ %#x\", strtab_end);\n        throwCantPack(msg);\n    }\n    unsigned const x_sym = dt_table[Elf32_Dyn::DT_SYMTAB];\n    unsigned const x_str = dt_table[Elf32_Dyn::DT_STRTAB];\n    if (x_sym && x_str) {\n        upx_uint32_t const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        upx_uint32_t const v_str = get_te32(&dynp0[-1+ x_str].d_val);\n        unsigned const  z_sym = dt_table[Elf32_Dyn::DT_SYMENT];\n        unsigned const sz_sym = !z_sym ? sizeof(Elf32_Sym)\n            : get_te32(&dynp0[-1+ z_sym].d_val);\n        if (sz_sym < sizeof(Elf32_Sym)) {\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_SYMENT %x\", sz_sym);\n            throwCantPack(msg);\n        }\n        if (v_sym < v_str) {\n            symnum_end = (v_str - v_sym) / sz_sym;\n        }\n        if (symnum_end < 1) {\n            throwCantPack(\"bad DT_SYMTAB\");\n        }\n    }\n    // DT_HASH often ends at DT_SYMTAB\n    // FIXME: sort DT_HASH, DT_GNU_HASH, STRTAB, SYMTAB, REL, RELA, JMPREL\n    // to partition the space.\n    unsigned const v_hsh = elf_unsigned_dynamic(Elf32_Dyn::DT_HASH);\n    if (v_hsh && file_image) {\n        hashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_HASH);\n        if (!hashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_HASH %#x\", v_hsh);\n            throwCantPack(msg);\n        }\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket]; (void)chains;\n\n        unsigned const v_sym = !x_sym ? 0 : get_te32(&dynp0[-1+ x_sym].d_val);\n        if ((unsigned)file_size <= nbucket/sizeof(*buckets)  // FIXME: weak\n        || !v_sym || (unsigned)file_size <= v_sym\n        || ((v_hsh < v_sym) && (v_sym - v_hsh) < sizeof(*buckets)*(2+ nbucket))\n        ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n        unsigned chmax = 0;\n        for (unsigned j= 0; j < nbucket; ++j) {\n            unsigned x = get_te32(&buckets[j]);\n            if (chmax < x) {\n                chmax = x;\n            }\n        }\n        if ((v_hsh < v_sym) && (v_sym - v_hsh) <\n                (sizeof(*buckets)*(2+ nbucket) + sizeof(*chains)*(1+ chmax))) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n    }\n    // DT_GNU_HASH often ends at DT_SYMTAB;  FIXME: not for Android?\n    unsigned const v_gsh = elf_unsigned_dynamic(Elf32_Dyn::DT_GNU_HASH);\n    if (v_gsh && file_image) {\n        gashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_GNU_HASH);\n        if (!gashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_GNU_HASH %#x\", v_gsh);\n            throwCantPack(msg);\n        }\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        unsigned const *const bitmask = (unsigned const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket]; (void)hasharr;\n        if (!n_bucket || (1u<<31) <= n_bucket  /* fie on fuzzers */\n        || (void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        //unsigned const *const gashend = &hasharr[n_bucket];  // minimum, except:\n        // Rust and Android trim unused zeroes from high end of hasharr[]\n        unsigned bmax = 0;\n        for (unsigned j= 0; j < n_bucket; ++j) {\n            unsigned bj = get_te32(&buckets[j]);\n            if (bj) {\n                if (bj < symbias) {\n                    char msg[90]; snprintf(msg, sizeof(msg),\n                            \"bad DT_GNU_HASH bucket[%d] < symbias{%#x}\\n\",\n                            bj, symbias);\n                    throwCantPack(msg);\n                }\n                if (bmax < bj) {\n                    bmax = bj;\n                }\n            }\n        }\n        if (1==n_bucket  && 0==buckets[0]\n        &&  1==n_bitmask && 0==bitmask[0]) {\n            // 2021-09-11 Rust on RaspberryPi apparently uses this to minimize space.\n            // But then the DT_GNU_HASH symbol lookup algorithm always fails?\n            // https://github.com/upx/upx/issues/525\n        } else\n        if ((1+ bmax) < symbias) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                    \"bad DT_GNU_HASH (1+ max_bucket)=%#x < symbias=%#x\", 1+ bmax, symbias);\n            throwCantPack(msg);\n        }\n        bmax -= symbias;\n\n        unsigned const v_sym = !x_sym ? 0 : get_te32(&dynp0[-1+ x_sym].d_val);\n        unsigned r = 0;\n        if (!n_bucket || !n_bitmask || !v_sym\n        || (r=1, ((-1+ n_bitmask) & n_bitmask))  // not a power of 2\n        || (r=2, (8*sizeof(unsigned) <= gnu_shift))  // shifted result always == 0\n        || (r=3, (n_bucket>>30))  // fie on fuzzers\n        || (r=4, (n_bitmask>>30))\n        || (r=5, ((file_size/sizeof(unsigned))\n                <= ((sizeof(*bitmask)/sizeof(unsigned))*n_bitmask + 2*n_bucket)))  // FIXME: weak\n        || (r=6, ((v_gsh < v_sym) && (v_sym - v_gsh) < (sizeof(unsigned)*4  // headers\n                + sizeof(*bitmask)*n_bitmask  // bitmask\n                + sizeof(*buckets)*n_bucket  // buckets\n                + sizeof(*hasharr)*(1+ bmax)  // hasharr\n            )) )\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_GNU_HASH n_bucket=%#x  n_bitmask=%#x  len=%#lx  r=%d\",\n                n_bucket, n_bitmask, (long unsigned)(v_sym - v_gsh), r);\n            throwCantPack(msg);\n        }\n    }\n    unsigned const e_shstrndx = get_te16(&ehdri.e_shstrndx);\n    if (e_shnum <= e_shstrndx\n    &&  !(0==e_shnum && 0==e_shstrndx) ) {\n        char msg[40]; snprintf(msg, sizeof(msg),\n            \"bad .e_shstrndx %d >= .e_shnum %d\", e_shstrndx, e_shnum);\n        throwCantPack(msg);\n    }\n}\n\nElf32_Phdr const *\nPackLinuxElf32::elf_find_ptype(unsigned type, Elf32_Phdr const *phdr, unsigned phnum)\n{\n    for (unsigned j = 0; j < phnum; ++j, ++phdr) {\n        if (type == get_te32(&phdr->p_type)) {\n            return phdr;\n        }\n    }\n    return nullptr;\n}\n\nElf64_Phdr const *\nPackLinuxElf64::elf_find_ptype(unsigned type, Elf64_Phdr const *phdr, unsigned phnum)\n{\n    for (unsigned j = 0; j < phnum; ++j, ++phdr) {\n        if (type == get_te32(&phdr->p_type)) {\n            return phdr;\n        }\n    }\n    return nullptr;\n}\n\nElf32_Shdr const *PackLinuxElf32::elf_find_section_name(\n    char const *const name\n) const\n{\n    Elf32_Shdr const *shdr = shdri;\n    if (!shdr) {\n        return nullptr;\n    }\n    int j = e_shnum;\n    for (; 0 <=--j; ++shdr) {\n        unsigned const sh_name = get_te32(&shdr->sh_name);\n        if ((u32_t)file_size <= sh_name) {  // FIXME: weak\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad Elf32_Shdr[%d].sh_name %#x\",\n                -1+ e_shnum -j, sh_name);\n            throwCantPack(msg);\n        }\n        if (0==strcmp(name, &shstrtab[sh_name])) {\n            return shdr;\n        }\n    }\n    return nullptr;\n}\n\nElf64_Shdr const *PackLinuxElf64::elf_find_section_name(\n    char const *const name\n) const\n{\n    Elf64_Shdr const *shdr = shdri;\n    if (!shdr) {\n        return nullptr;\n    }\n    int j = e_shnum;\n    for (; 0 <=--j; ++shdr) {\n        unsigned const sh_name = get_te32(&shdr->sh_name);\n        if ((u32_t)file_size <= sh_name) {  // FIXME: weak\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad Elf64_Shdr[%d].sh_name %#x\",\n                -1+ e_shnum -j, sh_name);\n            throwCantPack(msg);\n        }\n        if (0==strcmp(name, &shstrtab[sh_name])) {\n            return shdr;\n        }\n    }\n    return nullptr;\n}\n\nElf32_Shdr const *PackLinuxElf32::elf_find_section_type(\n    unsigned const type\n) const\n{\n    Elf32_Shdr const *shdr = shdri;\n    if (!shdr) {\n        return nullptr;\n    }\n    int j = e_shnum;\n    for (; 0 <=--j; ++shdr) {\n        if (type==get_te32(&shdr->sh_type)) {\n            return shdr;\n        }\n    }\n    return nullptr;\n}\n\nElf64_Shdr const *PackLinuxElf64::elf_find_section_type(\n    unsigned const type\n) const\n{\n    Elf64_Shdr const *shdr = shdri;\n    if (!shdr) {\n        return nullptr;\n    }\n    int j = e_shnum;\n    for (; 0 <=--j; ++shdr) {\n        if (type==get_te32(&shdr->sh_type)) {\n            return shdr;\n        }\n    }\n    return nullptr;\n}\n\nchar const *PackLinuxElf64::get_str_name(unsigned st_name, unsigned symnum) const\n{\n    if (strtab_end <= st_name) {\n        char msg[70]; snprintf(msg, sizeof(msg),\n            \"bad .st_name %#x in DT_SYMTAB[%d]\", st_name, symnum);\n        throwCantPack(msg);\n    }\n    return &dynstr[st_name];\n}\n\nchar const *PackLinuxElf64::get_dynsym_name(unsigned symnum, unsigned relnum) const\n{\n    if (symnum_end <= symnum) {\n        char msg[70]; snprintf(msg, sizeof(msg),\n            \"bad symnum %#x in Elf64_Rel[%d]\", symnum, relnum);\n        throwCantPack(msg);\n    }\n    return get_str_name(get_te32(&dynsym[symnum].st_name), symnum);\n}\n\nbool PackLinuxElf64::calls_crt1(Elf64_Rela const *rela, int sz)\n{\n    if (!dynsym || !dynstr || !rela) {\n        return false;\n    }\n    for (unsigned relnum= 0; 0 < sz; (sz -= sizeof(Elf64_Rela)), ++rela, ++relnum) {\n        unsigned const symnum = get_te64(&rela->r_info) >> 32;\n        char const *const symnam = get_dynsym_name(symnum, relnum);\n        if (0==strcmp(symnam, \"__libc_start_main\")  // glibc\n        ||  0==strcmp(symnam, \"__libc_init\")  // Android\n        ||  0==strcmp(symnam, \"__uClibc_main\")\n        ||  0==strcmp(symnam, \"__uClibc_start_main\"))\n            return true;\n    }\n    return false;\n}\n\nchar const *PackLinuxElf32::get_str_name(unsigned st_name, unsigned symnum) const\n{\n    if (strtab_end <= st_name) {\n        char msg[70]; snprintf(msg, sizeof(msg),\n            \"bad .st_name %#x in DT_SYMTAB[%d]\\n\", st_name, symnum);\n        throwCantPack(msg);\n    }\n    return &dynstr[st_name];\n}\n\nchar const *PackLinuxElf32::get_dynsym_name(unsigned symnum, unsigned relnum) const\n{\n    if (symnum_end <= symnum) {\n        char msg[70]; snprintf(msg, sizeof(msg),\n            \"bad symnum %#x in Elf32_Rel[%d]\\n\", symnum, relnum);\n        throwCantPack(msg);\n    }\n    return get_str_name(get_te32(&dynsym[symnum].st_name), symnum);\n}\n\nbool PackLinuxElf32::calls_crt1(Elf32_Rel const *rel, int sz)\n{\n    if (!dynsym || !dynstr || !rel) {\n        return false;\n    }\n    for (unsigned relnum= 0; 0 < sz; (sz -= sizeof(Elf32_Rel)), ++rel, ++relnum) {\n        unsigned const symnum = get_te32(&rel->r_info) >> 8;\n        char const *const symnam = get_dynsym_name(symnum, relnum);\n        if (0==strcmp(symnam, \"__libc_start_main\")  // glibc\n        ||  0==strcmp(symnam, \"__libc_init\")  // Android\n        ||  0==strcmp(symnam, \"__uClibc_main\")\n        ||  0==strcmp(symnam, \"__uClibc_start_main\"))\n            return true;\n    }\n    return false;\n}\n\n#define WANT_REL_ENUM\n#include \"p_elf_enum.h\"\n#undef WANT_REL_ENUM\n\nint PackLinuxElf32::canUnpack() // bool, except -1: format known, but not packed\n{\n    if (checkEhdr(&ehdri)) {\n        return false;\n    }\n    if (Elf32_Ehdr::ET_DYN==get_te16(&ehdri.e_type)) {\n        PackLinuxElf32help1(fi);\n    }\n    if (super::canUnpack()) {\n        return true;\n    }\n    return false;\n}\n\nbool PackLinuxElf32::canPack()\n{\n    union {\n        unsigned char buf[sizeof(Elf32_Ehdr) + 14*sizeof(Elf32_Phdr)];\n        //struct { Elf32_Ehdr ehdr; Elf32_Phdr phdr; } e;\n    } u;\n    COMPILE_TIME_ASSERT(sizeof(u.buf) <= 512)\n\n    fi->seek(0, SEEK_SET);\n    fi->readx(u.buf, sizeof(u.buf));\n    fi->seek(0, SEEK_SET);\n    Elf32_Ehdr const *const ehdr = (Elf32_Ehdr *) u.buf;\n\n    // now check the ELF header\n    if (checkEhdr(ehdr) != 0)\n        return false;\n\n    // additional requirements for linux/elf386\n    if (get_te16(&ehdr->e_ehsize) != sizeof(*ehdr)) {\n        throwCantPack(\"invalid Ehdr e_ehsize; try '--force-execve'\");\n        return false;\n    }\n    if (e_phoff != sizeof(*ehdr)) {// Phdrs not contiguous with Ehdr\n        throwCantPack(\"non-contiguous Ehdr/Phdr; try '--force-execve'\");\n        return false;\n    }\n\n    unsigned char osabi0 = u.buf[Elf32_Ehdr::EI_OSABI];\n    // The first PT_LOAD32 must cover the beginning of the file (0==p_offset).\n    Elf32_Phdr const *phdr = phdri;\n    note_size = 0;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        if (j >= 14) {\n            throwCantPack(\"too many ElfXX_Phdr; try '--force-execve'\");\n            return false;\n        }\n        unsigned const p_type = get_te32(&phdr->p_type);\n        unsigned const p_offset = get_te32(&phdr->p_offset);\n        if (1!=exetype && PT_LOAD32 == p_type) { // 1st PT_LOAD\n            exetype = 1;\n            load_va = get_te32(&phdr->p_vaddr);  // class data member\n\n            // Cast on next line is to avoid a compiler bug (incorrect complaint) in\n            // Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24215.1 for x64\n            // error C4319: '~': zero extending 'unsigned int' to 'upx_uint64_t' of greater size\n            unsigned const off = ~page_mask & (unsigned)load_va;\n\n            if (off && off == p_offset) { // specific hint\n                throwCantPack(\"Go-language PT_LOAD: try hemfix.c, or try '--force-execve'\");\n                // Fixing it inside upx fails because packExtent() reads original file.\n                return false;\n            }\n            if (0 != p_offset) { // 1st PT_LOAD must cover Ehdr and Phdr\n                throwCantPack(\"first PT_LOAD.p_offset != 0; try '--force-execve'\");\n                return false;\n            }\n            hatch_off = ~3u & (3+ get_te32(&phdr->p_memsz));\n        }\n        if (PT_NOTE32 == p_type) {\n            unsigned const x = get_te32(&phdr->p_memsz);\n            if ( sizeof(elfout.notes) < x  // beware overflow of note_size\n            ||  (sizeof(elfout.notes) < (note_size += x)) ) {\n                throwCantPack(\"PT_NOTEs too big; try '--force-execve'\");\n                return false;\n            }\n            if (osabi_note && Elf32_Ehdr::ELFOSABI_NONE==osabi0) { // Still seems to be generic.\n                struct {\n                    struct Elf32_Nhdr nhdr;\n                    char name[8];\n                    unsigned body;\n                } note;\n                memset(&note, 0, sizeof(note));\n                fi->seek(p_offset, SEEK_SET);\n                fi->readx(&note, sizeof(note));\n                fi->seek(0, SEEK_SET);\n                if (4==get_te32(&note.nhdr.descsz)\n                &&  1==get_te32(&note.nhdr.type)\n                // &&  0==note.end\n                &&  (1+ strlen(osabi_note))==get_te32(&note.nhdr.namesz)\n                &&  0==strcmp(osabi_note, (char const *)&note.name[0])\n                ) {\n                    osabi0 = ei_osabi;  // Specified by PT_NOTE.\n                }\n            }\n        }\n    }\n    if (Elf32_Ehdr::ELFOSABI_NONE ==osabi0\n    ||  Elf32_Ehdr::ELFOSABI_LINUX==osabi0) { // No EI_OSBAI, no PT_NOTE.\n        unsigned const arm_eabi = 0xff000000u & get_te32(&ehdr->e_flags);\n        if (Elf32_Ehdr::EM_ARM==e_machine\n        &&   (EF_ARM_EABI_VER5==arm_eabi\n          ||  EF_ARM_EABI_VER4==arm_eabi ) ) {\n            // armel-eabi armeb-eabi ARM Linux EABI version 4 is a mess.\n            ei_osabi = osabi0 = Elf32_Ehdr::ELFOSABI_LINUX;\n        }\n        else {\n            osabi0 = opt->o_unix.osabi0;  // Possibly specified by command-line.\n        }\n    }\n    if (osabi0!=ei_osabi) {\n        return false;\n    }\n\n    // We want to compress position-independent executable (gcc -pie)\n    // main programs, but compressing a shared library must be avoided\n    // because the result is no longer usable.  In theory, there is no way\n    // to tell them apart: both are just ET_DYN.  Also in theory,\n    // neither the presence nor the absence of any particular symbol name\n    // can be used to tell them apart; there are counterexamples.\n    // However, we will use the following heuristic suggested by\n    // Peter S. Mazinger <ps.m@gmx.net> September 2005:\n    // If a ET_DYN has __libc_start_main as a global undefined symbol,\n    // then the file is a position-independent executable main program\n    // (that depends on libc.so.6) and is eligible to be compressed.\n    // Otherwise (no __libc_start_main as global undefined): skip it.\n    // Also allow  __uClibc_main  and  __uClibc_start_main .\n\n    if (Elf32_Ehdr::ET_DYN==get_te16(&ehdr->e_type)) {\n        // The DT_SYMTAB has no designated length.  Read the whole file.\n        alloc_file_image(file_image, file_size);\n        fi->seek(0, SEEK_SET);\n        fi->readx(file_image, file_size);\n        memcpy(&ehdri, ehdr, sizeof(Elf32_Ehdr));\n        phdri= (Elf32_Phdr *)((size_t)e_phoff + file_image);  // do not free() !!\n        shdri= (Elf32_Shdr *)((size_t)e_shoff + file_image);  // do not free() !!\n\n        sec_strndx = nullptr;\n        shstrtab = nullptr;\n        if (e_shnum) {\n            unsigned const e_shstrndx = get_te16(&ehdr->e_shstrndx);\n            if (e_shstrndx) {\n                if (e_shnum <= e_shstrndx) {\n                    char msg[40]; snprintf(msg, sizeof(msg),\n                        \"bad e_shstrndx %#x >= e_shnum %d\", e_shstrndx, e_shnum);\n                    throwCantPack(msg);\n                }\n                sec_strndx = &shdri[e_shstrndx];\n                unsigned const sh_offset = get_te32(&sec_strndx->sh_offset);\n                if ((u32_t)file_size <= sh_offset) {\n                    char msg[50]; snprintf(msg, sizeof(msg),\n                        \"bad .e_shstrndx->sh_offset %#x\", sh_offset);\n                    throwCantPack(msg);\n                }\n                shstrtab = (char const *)(sh_offset + file_image);\n            }\n            sec_dynsym = elf_find_section_type(Elf32_Shdr::SHT_DYNSYM);\n            if (sec_dynsym) {\n                unsigned const sh_link = get_te32(&sec_dynsym->sh_link);\n                if (e_shnum <= sh_link) {\n                    char msg[50]; snprintf(msg, sizeof(msg),\n                        \"bad SHT_DYNSYM.sh_link %#x\", sh_link);\n                }\n                sec_dynstr = &shdri[sh_link];\n            }\n\n            if (sec_strndx) {\n                unsigned const sh_name = get_te32(&sec_strndx->sh_name);\n                if (Elf32_Shdr::SHT_STRTAB != get_te32(&sec_strndx->sh_type)\n                || (u32_t)file_size <= (sizeof(\".shstrtab\")\n                    + sh_name + (shstrtab - (const char *)&file_image[0]))\n                || (sh_name\n                  && 0!=strcmp((char const *)\".shstrtab\", &shstrtab[sh_name]))\n                ) {\n                    throwCantPack(\"bad e_shstrtab\");\n                }\n            }\n        }\n\n        Elf32_Phdr const *pload_x0(nullptr);  // first eXecutable PT_LOAD\n        phdr= phdri;\n        for (int j= e_phnum; --j>=0; ++phdr)\n        if (Elf32_Phdr::PT_DYNAMIC==get_te32(&phdr->p_type)) {\n            unsigned offset = check_pt_dynamic(phdr);\n            dynseg= (Elf32_Dyn const *)(offset + file_image);\n            invert_pt_dynamic(dynseg,\n                umin(get_te32(&phdr->p_filesz), file_size - offset));\n        }\n        else if (is_LOAD32(phdr)) {\n            if (!pload_x0\n            &&  Elf32_Phdr::PF_X & get_te32(&phdr->p_flags)\n            ) {\n                pload_x0 = phdr;\n            }\n            check_pt_load(phdr);\n        }\n        if (!pload_x0) {\n            throwCantPack(\"No PT_LOAD has (p_flags & PF_X)\");\n        }\n        // elf_find_dynamic() returns 0 if 0==dynseg.\n        dynstr=          (char const *)elf_find_dynamic(Elf32_Dyn::DT_STRTAB);\n        dynsym=     (Elf32_Sym const *)elf_find_dynamic(Elf32_Dyn::DT_SYMTAB);\n\n        if (opt->o_unix.force_pie\n        ||      Elf32_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf32_Dyn::DT_FLAGS_1)\n        ||  calls_crt1((Elf32_Rel const *)elf_find_dynamic(Elf32_Dyn::DT_REL),\n                                 (int)elf_unsigned_dynamic(Elf32_Dyn::DT_RELSZ))\n        ||  calls_crt1((Elf32_Rel const *)elf_find_dynamic(Elf32_Dyn::DT_JMPREL),\n                                 (int)elf_unsigned_dynamic(Elf32_Dyn::DT_PLTRELSZ))) {\n            is_pie = true;\n            goto proceed;  // calls C library init for main program\n        }\n\n        // Heuristic HACK for shared libraries (compare Darwin (MacOS) Dylib.)\n        // If there is an existing DT_INIT, and if everything that the dynamic\n        // linker ld-linux needs to perform relocations before calling DT_INIT\n        // resides below the first SHT_EXECINSTR Section in one PT_LOAD, then\n        // compress from the first executable Section to the end of that PT_LOAD.\n        // We must not alter anything that ld-linux might touch before it calls\n        // the DT_INIT function.\n        //\n        // Obviously this hack requires that the linker script put pieces\n        // into good positions when building the original shared library,\n        // and also requires ld-linux to behave.\n\n        // Apparently glibc-2.13.90 insists on 0==e_ident[EI_PAD..15],\n        // so compressing shared libraries may be doomed anyway.\n        // 2011-06-01: stub.shlib-init.S works around by installing hatch\n        // at end of .text.\n\n        if (/*jni_onload_sym ||*/ elf_find_dynamic(upx_dt_init)) {\n            if (this->e_machine!=Elf32_Ehdr::EM_386\n            &&  this->e_machine!=Elf32_Ehdr::EM_MIPS\n            &&  this->e_machine!=Elf32_Ehdr::EM_ARM)\n                goto abandon;  // need stub: EM_PPC\n            if (elf_has_dynamic(Elf32_Dyn::DT_TEXTREL)) {\n                throwCantPack(\"DT_TEXTREL found; re-compile with -fPIC\");\n                goto abandon;\n            }\n            if (!(Elf32_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf32_Dyn::DT_FLAGS_1))) {\n                // not explicitly PIE main program\n                if (Elf32_Ehdr::EM_ARM == e_machine  // Android is common\n                &&  !opt->o_unix.android_shlib  // but not explicit\n                ) {\n                    opt->info_mode++;\n                    info(\"note: use --android-shlib if appropriate\");\n                    opt->info_mode--;\n                }\n            }\n            Elf32_Shdr const *shdr = shdri;\n            xct_va = ~0u;\n            if (e_shnum) {\n                for (int j= e_shnum; --j>=0; ++shdr) {\n                    unsigned const sh_type = get_te32(&shdr->sh_type);\n                    if (Elf32_Shdr::SHF_EXECINSTR & get_te32(&shdr->sh_flags)) {\n                        xct_va = umin(xct_va, get_te32(&shdr->sh_addr));\n                    }\n                    // Hook the first slot of DT_PREINIT_ARRAY or DT_INIT_ARRAY.\n                    if ((     Elf32_Dyn::DT_PREINIT_ARRAY==upx_dt_init\n                        &&  Elf32_Shdr::SHT_PREINIT_ARRAY==sh_type)\n                    ||  (     Elf32_Dyn::DT_INIT_ARRAY   ==upx_dt_init\n                        &&  Elf32_Shdr::SHT_INIT_ARRAY   ==sh_type) ) {\n                        unsigned user_init_ava = get_te32(&shdr->sh_addr);\n                        user_init_off = get_te32(&shdr->sh_offset);\n                        if ((u32_t)file_size <= user_init_off) {\n                            char msg[70]; snprintf(msg, sizeof(msg),\n                                \"bad Elf32_Shdr[%d].sh_offset %#x\",\n                                -1+ e_shnum - j, user_init_off);\n                            throwCantPack(msg);\n                        }\n                        // Check that &file_image[user_init_off] has\n                        // *_RELATIVE relocation, and fetch user_init_va.\n                        // If Elf32_Rela then the actual value is in Rela.r_addend.\n                        int z_rel = dt_table[Elf32_Dyn::DT_REL];\n                        int z_rsz = dt_table[Elf32_Dyn::DT_RELSZ];\n                        if (z_rel && z_rsz) {\n                            unsigned rel_off = get_te32(&dynseg[-1+ z_rel].d_val);\n                            if ((unsigned)file_size <= rel_off) {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                     \"bad Elf32_Dynamic[DT_REL] %#x\\n\",\n                                     rel_off);\n                                throwCantPack(msg);\n                            }\n                            Elf32_Rel *rp = (Elf32_Rel *)&file_image[rel_off];\n                            unsigned relsz   = get_te32(&dynseg[-1+ z_rsz].d_val);\n                            if ((unsigned)file_size <= relsz) {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                     \"bad Elf32_Dynamic[DT_RELSZ] %#x\\n\",\n                                     relsz);\n                                throwCantPack(msg);\n                            }\n                            Elf32_Rel *last = (Elf32_Rel *)(relsz + (char *)rp);\n                            for (; rp < last; ++rp) {\n                                unsigned r_va = get_te32(&rp->r_offset);\n                                if (r_va == user_init_ava) { // found the Elf32_Rel\n                                    unsigned r_info = get_te32(&rp->r_info);\n                                    unsigned r_type = ELF32_R_TYPE(r_info);\n                                    if ((Elf32_Ehdr::EM_ARM == e_machine && R_ARM_RELATIVE == r_type)\n                                    ||  (Elf32_Ehdr::EM_386 == e_machine && R_386_RELATIVE == r_type) ) {\n                                        user_init_va = get_te32(&file_image[user_init_off]);\n                                    }\n                                    else {\n                                        char msg[50]; snprintf(msg, sizeof(msg),\n                                            \"bad relocation %#x DT_INIT_ARRAY[0]\",\n                                            r_info);\n                                        throwCantPack(msg);\n                                    }\n                                    break;\n                                }\n                            }\n                        }\n                        unsigned const p_filesz = get_te32(&pload_x0->p_filesz);\n                        if (!((user_init_va - xct_va) < p_filesz)) {\n                            // Not in executable portion of first executable PT_LOAD.\n                            if (0==user_init_va && opt->o_unix.android_shlib) {\n                                // Android allows (0 ==> skip) ?\n                                upx_dt_init = 0;  // force steal of 'extra' DT_NULL\n                                // XXX: FIXME: depends on SHT_DYNAMIC coming later\n                            }\n                            else {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                    \"bad init address %#x in Elf32_Shdr[%d].%#x\\n\",\n                                    (unsigned)user_init_va, -1+ e_shnum - j, user_init_off);\n                                throwCantPack(msg);\n                            }\n                        }\n                    }\n                    // By default /usr/bin/ld leaves 4 extra DT_NULL to support pre-linking.\n                    // Take one as a last resort.\n                    if ((Elf32_Dyn::DT_INIT==upx_dt_init || !upx_dt_init)\n                    &&  Elf32_Shdr::SHT_DYNAMIC == sh_type) {\n                        unsigned const n = get_te32(&shdr->sh_size) / sizeof(Elf32_Dyn);\n                        Elf32_Dyn *dynp = (Elf32_Dyn *)&file_image[get_te32(&shdr->sh_offset)];\n                        for (; Elf32_Dyn::DT_NULL != dynp->d_tag; ++dynp) {\n                            if (upx_dt_init == get_te32(&dynp->d_tag)) {\n                                break;  // re-found DT_INIT\n                            }\n                        }\n                        if ((1+ dynp) < (n+ dynseg)) { // not the terminator, so take it\n                            user_init_va = get_te32(&dynp->d_val);  // 0 if (0==upx_dt_init)\n                            set_te32(&dynp->d_tag, upx_dt_init = Elf32_Dyn::DT_INIT);\n                            user_init_off = (char const *)&dynp->d_val - (char const *)&file_image[0];\n                        }\n                    }\n                }\n            }\n            else { // no Sections; use heuristics\n                unsigned const strsz  = elf_unsigned_dynamic(Elf32_Dyn::DT_STRSZ);\n                unsigned const strtab = elf_unsigned_dynamic(Elf32_Dyn::DT_STRTAB);\n                unsigned const relsz  = elf_unsigned_dynamic(Elf32_Dyn::DT_RELSZ);\n                unsigned const rel    = elf_unsigned_dynamic(Elf32_Dyn::DT_REL);\n                unsigned const init   = elf_unsigned_dynamic(upx_dt_init);\n                if ((init == (relsz + rel   ) && rel    == (strsz + strtab))\n                ||  (init == (strsz + strtab) && strtab == (relsz + rel   ))\n                ) {\n                    xct_va = init;\n                    user_init_va = init;\n                    user_init_off = elf_get_offset_from_address(init);\n                }\n            }\n            // Rely on 0==elf_unsigned_dynamic(tag) if no such tag.\n            unsigned const va_gash = elf_unsigned_dynamic(Elf32_Dyn::DT_GNU_HASH);\n            unsigned const va_hash = elf_unsigned_dynamic(Elf32_Dyn::DT_HASH);\n            unsigned y = 0;\n            if ((y=1, xct_va < va_gash)  ||  (y=2, (0==va_gash && xct_va < va_hash))\n            ||  (y=3, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_STRTAB))\n            ||  (y=4, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_SYMTAB))\n            ||  (y=5, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_REL))\n            ||  (y=6, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_RELA))\n            ||  (y=7, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_JMPREL))\n            ||  (y=8, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_VERDEF))\n            ||  (y=9, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_VERSYM))\n            ||  (y=10, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_VERNEED)) ) {\n                static char const *which[] = {\n                    \"unknown\",\n                    \"DT_GNU_HASH\",\n                    \"DT_HASH\",\n                    \"DT_STRTAB\",\n                    \"DT_SYMTAB\",\n                    \"DT_REL\",\n                    \"DT_RELA\",\n                    \"DT_JMPREL\",\n                    \"DT_VERDEF\",\n                    \"DT_VERSYM\",\n                    \"DT_VERNEED\",\n                };\n                char buf[30]; snprintf(buf, sizeof(buf), \"%s above stub\", which[y]);\n                throwCantPack(buf);\n                goto abandon;\n            }\n            if (!opt->o_unix.android_shlib) {\n                phdr = phdri;\n                for (unsigned j= 0; j < e_phnum; ++phdr, ++j) {\n                    unsigned const vaddr = get_te32(&phdr->p_vaddr);\n                    if (PT_NOTE32 == get_te32(&phdr->p_type)\n                    && xct_va < vaddr) {\n                        char buf[40]; snprintf(buf, sizeof(buf),\n                           \"PT_NOTE %#x above stub\", vaddr);\n                        throwCantPack(buf);\n                        goto abandon;\n                    }\n                }\n            }\n            xct_off = elf_get_offset_from_address(xct_va);\n            if (opt->debug.debug_level) {\n                fprintf(stderr, \"shlib canPack: xct_va=%#lx  xct_off=%#lx\\n\",\n                    (long)xct_va, (long)xct_off);\n            }\n            goto proceed;  // But proper packing depends on checking xct_va.\n        }\n        else\n            throwCantPack(\"need DT_INIT; try \\\"void _init(void){}\\\"\");\nabandon:\n        return false;\nproceed: ;\n    }\n    // XXX Theoretically the following test should be first,\n    // but PackUnix::canPack() wants 0!=exetype ?\n    if (!super::canPack())\n        return false;\n    assert(exetype == 1);\n    exetype = 0;\n\n    // set options\n    opt->o_unix.blocksize = blocksize = file_size;\n    return true;\n}\n\nint PackLinuxElf64::canUnpack() // bool, except -1: format known, but not packed\n{\n    if (checkEhdr(&ehdri)) {\n        return false;\n    }\n    if (Elf64_Ehdr::ET_DYN==get_te16(&ehdri.e_type)) {\n        PackLinuxElf64help1(fi);\n        Elf64_Phdr const *phdr = phdri, *last_LOAD = nullptr;\n        for (unsigned j = 0; j < e_phnum; ++phdr, ++j)\n            if (Elf64_Phdr::PT_LOAD==get_te32(&phdr->p_type)) {\n                last_LOAD = phdr;\n            }\n        if (!last_LOAD)\n            return false;\n        off_t offset = get_te64(&last_LOAD->p_offset);\n        unsigned filesz = get_te64(&last_LOAD->p_filesz);\n        fi->seek(filesz+offset, SEEK_SET);\n        MemBuffer buf(32 + sizeof(overlay_offset));\n        fi->readx(buf, buf.getSize());\n        bool x = PackUnix::find_overlay_offset(buf);\n        if (x) {\n            return x;\n        }\n    }\n    if (super::canUnpack()) {\n        return true;\n    }\n    return false;\n}\n\nbool\nPackLinuxElf64::canPack()\n{\n    union {\n        unsigned char buf[sizeof(Elf64_Ehdr) + 14*sizeof(Elf64_Phdr)];\n        //struct { Elf64_Ehdr ehdr; Elf64_Phdr phdr; } e;\n    } u;\n    COMPILE_TIME_ASSERT(sizeof(u) <= 1024)\n\n    fi->readx(u.buf, sizeof(u.buf));\n    fi->seek(0, SEEK_SET);\n    Elf64_Ehdr const *const ehdr = (Elf64_Ehdr *) u.buf;\n\n    // now check the ELF header\n    if (checkEhdr(ehdr) != 0)\n        return false;\n\n    // additional requirements for linux/elf386\n    if (get_te16(&ehdr->e_ehsize) != sizeof(*ehdr)) {\n        throwCantPack(\"invalid Ehdr e_ehsize; try '--force-execve'\");\n        return false;\n    }\n    if (e_phoff != sizeof(*ehdr)) {// Phdrs not contiguous with Ehdr\n        throwCantPack(\"non-contiguous Ehdr/Phdr; try '--force-execve'\");\n        return false;\n    }\n\n    upx_uint64_t max_LOADsz = 0, max_offset = 0;\n    Elf64_Phdr const *phdr = phdri;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        if (j >= 14) {\n            throwCantPack(\"too many ElfXX_Phdr; try '--force-execve'\");\n            return false;\n        }\n        unsigned const p_type = get_te32(&phdr->p_type);\n        if (PT_LOAD64 == p_type) {\n            // The first PT_LOAD64 must cover the beginning of the file (0==p_offset).\n            if (1!= exetype) {\n                exetype = 1;\n                load_va = get_te64(&phdr->p_vaddr);  // class data member\n                upx_uint64_t const p_offset = get_te64(&phdr->p_offset);\n                upx_uint64_t const off = ~page_mask & load_va;\n                if (off && off == p_offset) { // specific hint\n                    throwCantPack(\"Go-language PT_LOAD: try hemfix.c, or try '--force-execve'\");\n                    // Fixing it inside upx fails because packExtent() reads original file.\n                    return false;\n                }\n                if (0 != p_offset) { // 1st PT_LOAD must cover Ehdr and Phdr\n                    throwCantPack(\"first PT_LOAD.p_offset != 0; try '--force-execve'\");\n                    return false;\n                }\n                // FIXME: bad for shlib!\n                hatch_off = ~3ul & (3+ get_te64(&phdr->p_memsz));\n            }\n            max_LOADsz = UPX_MAX(max_LOADsz, get_te64(&phdr->p_filesz));\n            max_offset = UPX_MAX(max_offset, get_te64(&phdr->p_filesz) + get_te64(&phdr->p_offset));\n        }\n    }\n    if (canUnpack() > 0) {\n        throwAlreadyPacked();\n    }\n    // We want to compress position-independent executable (gcc -pie)\n    // main programs, but compressing a shared library must be avoided\n    // because the result is no longer usable.  In theory, there is no way\n    // to tell them apart: both are just ET_DYN.  Also in theory,\n    // neither the presence nor the absence of any particular symbol name\n    // can be used to tell them apart; there are counterexamples.\n    // However, we will use the following heuristic suggested by\n    // Peter S. Mazinger <ps.m@gmx.net> September 2005:\n    // If a ET_DYN has __libc_start_main as a global undefined symbol,\n    // then the file is a position-independent executable main program\n    // (that depends on libc.so.6) and is eligible to be compressed.\n    // Otherwise (no __libc_start_main as global undefined): skip it.\n    // Also allow  __uClibc_main  and  __uClibc_start_main .\n\n    if (Elf64_Ehdr::ET_DYN==get_te16(&ehdr->e_type)) {\n        // The DT_SYMTAB has no designated length.  Read the whole file.\n        alloc_file_image(file_image, file_size);\n        fi->seek(0, SEEK_SET);\n        fi->readx(file_image, file_size);\n        memcpy(&ehdri, ehdr, sizeof(Elf64_Ehdr));\n        phdri= (Elf64_Phdr *)((size_t)e_phoff + file_image);  // do not free() !!\n        shdri= (Elf64_Shdr *)((size_t)e_shoff + file_image);  // do not free() !!\n\n        sec_strndx = nullptr;\n        shstrtab = nullptr;\n        if (e_shnum) {\n            unsigned const e_shstrndx = get_te16(&ehdr->e_shstrndx);\n            if (e_shstrndx) {\n                if (e_shnum <= e_shstrndx) {\n                    char msg[40]; snprintf(msg, sizeof(msg),\n                        \"bad e_shstrndx %#x >= e_shnum %d\", e_shstrndx, e_shnum);\n                    throwCantPack(msg);\n                }\n                sec_strndx = &shdri[e_shstrndx];\n                upx_uint64_t sh_offset = get_te64(&sec_strndx->sh_offset);\n                if ((u64_t)file_size <= sh_offset) {\n                    char msg[50]; snprintf(msg, sizeof(msg),\n                        \"bad .e_shstrndx->sh_offset %#lx\", (long unsigned)sh_offset);\n                    throwCantPack(msg);\n                }\n                shstrtab = (char const *)(sh_offset + file_image);\n            }\n            sec_dynsym = elf_find_section_type(Elf64_Shdr::SHT_DYNSYM);\n            if (sec_dynsym) {\n                upx_uint64_t const sh_link = get_te64(&sec_dynsym->sh_link);\n                if (e_shnum <= sh_link) {\n                    char msg[50]; snprintf(msg, sizeof(msg),\n                        \"bad SHT_DYNSYM.sh_link %#lx\", (long unsigned)sh_link);\n                }\n                sec_dynstr = &shdri[sh_link];\n            }\n\n            if (sec_strndx) {\n                unsigned const sh_name = get_te32(&sec_strndx->sh_name);\n                if (Elf64_Shdr::SHT_STRTAB != get_te32(&sec_strndx->sh_type)\n                || (u32_t)file_size <= (sizeof(\".shstrtab\")\n                    + sh_name + (shstrtab - (const char *)&file_image[0]))\n                || (sh_name\n                  && 0!=strcmp((char const *)\".shstrtab\", &shstrtab[sh_name]))\n                ) {\n                    throwCantPack(\"bad e_shstrtab\");\n                }\n            }\n        }\n\n        Elf64_Phdr const *pload_x0(nullptr);  // first eXecutable PT_LOAD\n        phdr= phdri;\n        for (int j= e_phnum; --j>=0; ++phdr)\n        if (Elf64_Phdr::PT_DYNAMIC==get_te32(&phdr->p_type)) {\n            upx_uint64_t offset = check_pt_dynamic(phdr);\n            dynseg= (Elf64_Dyn const *)(offset + file_image);\n            invert_pt_dynamic(dynseg,\n                umin(get_te64(&phdr->p_filesz), file_size - offset));\n        }\n        else if (PT_LOAD64==get_te32(&phdr->p_type)) {\n            if (!pload_x0\n            &&  Elf32_Phdr::PF_X & get_te32(&phdr->p_flags)\n            ) {\n                pload_x0 = phdr;\n            }\n            check_pt_load(phdr);\n        }\n        if (!pload_x0) {\n            throwCantPack(\"No PT_LOAD has (p_flags & PF_X)\");\n        }\n        // elf_find_dynamic() returns 0 if 0==dynseg.\n        dynstr=          (char const *)elf_find_dynamic(Elf64_Dyn::DT_STRTAB);\n        dynsym=     (Elf64_Sym const *)elf_find_dynamic(Elf64_Dyn::DT_SYMTAB);\n\n        if (opt->o_unix.force_pie\n        ||       Elf64_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf64_Dyn::DT_FLAGS_1)\n        ||  calls_crt1((Elf64_Rela const *)elf_find_dynamic(Elf64_Dyn::DT_RELA),\n                                  (int)elf_unsigned_dynamic(Elf64_Dyn::DT_RELASZ))\n        ||  calls_crt1((Elf64_Rela const *)elf_find_dynamic(Elf64_Dyn::DT_JMPREL),\n                                  (int)elf_unsigned_dynamic(Elf64_Dyn::DT_PLTRELSZ))) {\n            is_pie = true;\n            goto proceed;  // calls C library init for main program\n        }\n\n        // Heuristic HACK for shared libraries (compare Darwin (MacOS) Dylib.)\n        // If there is an existing DT_INIT, and if everything that the dynamic\n        // linker ld-linux needs to perform relocations before calling DT_INIT\n        // resides below the first SHT_EXECINSTR Section in one PT_LOAD, then\n        // compress from the first executable Section to the end of that PT_LOAD.\n        // We must not alter anything that ld-linux might touch before it calls\n        // the DT_INIT function.\n        //\n        // Obviously this hack requires that the linker script put pieces\n        // into good positions when building the original shared library,\n        // and also requires ld-linux to behave.\n\n        if (elf_find_dynamic(upx_dt_init)) {\n            if (elf_has_dynamic(Elf64_Dyn::DT_TEXTREL)) {\n                throwCantPack(\"DT_TEXTREL found; re-compile with -fPIC\");\n                goto abandon;\n            }\n            if (!(Elf64_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf64_Dyn::DT_FLAGS_1))) {\n                // not explicitly PIE main program\n                if (Elf64_Ehdr::EM_AARCH64 == e_machine  // Android is common\n                &&  !opt->o_unix.android_shlib  // but not explicit\n                ) {\n                    opt->info_mode++;\n                    info(\"note: use --android-shlib if appropriate\");\n                    opt->info_mode--;\n                }\n            }\n            Elf64_Shdr const *shdr = shdri;\n            xct_va = ~0ull;\n            if (e_shnum) {\n                for (int j= e_shnum; --j>=0; ++shdr) {\n                    unsigned const sh_type = get_te32(&shdr->sh_type);\n                    if (Elf64_Shdr::SHF_EXECINSTR & get_te64(&shdr->sh_flags)) {\n                        xct_va = umin(xct_va, get_te64(&shdr->sh_addr));\n                    }\n                    // Hook the first slot of DT_PREINIT_ARRAY or DT_INIT_ARRAY.\n                    if ((     Elf64_Dyn::DT_PREINIT_ARRAY==upx_dt_init\n                        &&  Elf64_Shdr::SHT_PREINIT_ARRAY==sh_type)\n                    ||  (     Elf64_Dyn::DT_INIT_ARRAY   ==upx_dt_init\n                        &&  Elf64_Shdr::SHT_INIT_ARRAY   ==sh_type) ) {\n                        unsigned user_init_ava = get_te32(&shdr->sh_addr);\n                        user_init_off = get_te64(&shdr->sh_offset);\n                        if ((u64_t)file_size <= user_init_off) {\n                            char msg[70]; snprintf(msg, sizeof(msg),\n                                \"bad Elf64_Shdr[%d].sh_offset %#x\",\n                                -1+ e_shnum - j, user_init_off);\n                            throwCantPack(msg);\n                        }\n                        // Check that &file_image[user_init_off] has\n                        // *_RELATIVE relocation, and fetch user_init_va.\n                        // If Elf64_Rela then the actual value is in Rela.r_addend.\n                        int z_rel = dt_table[Elf64_Dyn::DT_RELA];\n                        int z_rsz = dt_table[Elf64_Dyn::DT_RELASZ];\n                        if (z_rel && z_rsz) {\n                            upx_uint64_t rel_off = get_te64(&dynseg[-1+ z_rel].d_val);\n                            if ((u64_t)file_size <= rel_off) {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                     \"bad Elf64_Dynamic[DT_RELA] %#llx\\n\",\n                                     rel_off);\n                                throwCantPack(msg);\n                            }\n                            Elf64_Rela *rp = (Elf64_Rela *)&file_image[rel_off];\n                            upx_uint64_t relsz   = get_te64(&dynseg[-1+ z_rsz].d_val);\n                            if ((u64_t)file_size <= relsz) {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                     \"bad Elf64_Dynamic[DT_RELASZ] %#llx\\n\",\n                                     relsz);\n                                throwCantPack(msg);\n                            }\n                            Elf64_Rela *last = (Elf64_Rela *)(relsz + (char *)rp);\n                            for (; rp < last; ++rp) {\n                                upx_uint64_t r_va = get_te64(&rp->r_offset);\n                                if (r_va == user_init_ava) { // found the Elf64_Rela\n                                    upx_uint64_t r_info = get_te64(&rp->r_info);\n                                    unsigned r_type = ELF64_R_TYPE(r_info);\n                                    if (Elf64_Ehdr::EM_AARCH64 == e_machine\n                                    &&  R_AARCH64_RELATIVE == r_type) {\n                                        user_init_va = get_te64(&rp->r_addend);\n                                    }\n                                    else if (Elf64_Ehdr::EM_AARCH64 == e_machine\n                                    &&  R_AARCH64_ABS64 == r_type) {\n                                        user_init_va = get_te64(&file_image[user_init_off]);\n                                    }\n                                    else {\n                                        char msg[50]; snprintf(msg, sizeof(msg),\n                                            \"bad relocation %#llx DT_INIT_ARRAY[0]\",\n                                            r_info);\n                                        throwCantPack(msg);\n                                    }\n                                    break;\n                                }\n                            }\n                        }\n                        unsigned const p_filesz = get_te64(&pload_x0->p_filesz);\n                        if (!((user_init_va - xct_va) < p_filesz)) {\n                            // Not in executable portion of first executable PT_LOAD.\n                            if (0==user_init_va && opt->o_unix.android_shlib) {\n                                // Android allows (0 ==> skip) ?\n                                upx_dt_init = 0;  // force steal of 'extra' DT_NULL\n                                // XXX: FIXME: depends on SHT_DYNAMIC coming later\n                            }\n                            else {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                    \"bad init address %#x in Elf64_Shdr[%d].%#x\\n\",\n                                    (unsigned)user_init_va, -1+ e_shnum - j, user_init_off);\n                                throwCantPack(msg);\n                            }\n                        }\n                    }\n                    // By default /usr/bin/ld leaves 4 extra DT_NULL to support pre-linking.\n                    // Take one as a last resort.\n                    if ((Elf64_Dyn::DT_INIT==upx_dt_init || !upx_dt_init)\n                    &&  Elf64_Shdr::SHT_DYNAMIC == sh_type) {\n                        upx_uint64_t sh_offset = get_te64(&shdr->sh_offset);\n                        upx_uint64_t sh_size = get_te64(&shdr->sh_size);\n                        if ((upx_uint64_t)file_size < sh_size\n                        ||  (upx_uint64_t)file_size < sh_offset\n                        || ((upx_uint64_t)file_size - sh_offset) < sh_size) {\n                            throwCantPack(\"bad SHT_DYNAMIC\");\n                        }\n                        unsigned const n = sh_size / sizeof(Elf64_Dyn);\n                        Elf64_Dyn *dynp = (Elf64_Dyn *)&file_image[sh_offset];\n                        for (; Elf64_Dyn::DT_NULL != dynp->d_tag; ++dynp) {\n                            if (upx_dt_init == get_te64(&dynp->d_tag)) {\n                                break;  // re-found DT_INIT\n                            }\n                        }\n                        if ((1+ dynp) < (n+ dynseg)) { // not the terminator, so take it\n                            user_init_va = get_te64(&dynp->d_val);  // 0 if (0==upx_dt_init)\n                            set_te64(&dynp->d_tag, upx_dt_init = Elf64_Dyn::DT_INIT);\n                            user_init_off = (char const *)&dynp->d_val - (char const *)&file_image[0];\n                        }\n                    }\n                }\n            }\n            else { // no Sections; use heuristics\n                upx_uint64_t const strsz  = elf_unsigned_dynamic(Elf64_Dyn::DT_STRSZ);\n                upx_uint64_t const strtab = elf_unsigned_dynamic(Elf64_Dyn::DT_STRTAB);\n                upx_uint64_t const relsz  = elf_unsigned_dynamic(Elf64_Dyn::DT_RELSZ);\n                upx_uint64_t const rel    = elf_unsigned_dynamic(Elf64_Dyn::DT_REL);\n                upx_uint64_t const init   = elf_unsigned_dynamic(upx_dt_init);\n                if ((init == (relsz + rel   ) && rel    == (strsz + strtab))\n                ||  (init == (strsz + strtab) && strtab == (relsz + rel   ))\n                ) {\n                    xct_va = init;\n                    user_init_va = init;\n                    user_init_off = elf_get_offset_from_address(init);\n                }\n            }\n            // Rely on 0==elf_unsigned_dynamic(tag) if no such tag.\n            upx_uint64_t const va_gash = elf_unsigned_dynamic(Elf64_Dyn::DT_GNU_HASH);\n            upx_uint64_t const va_hash = elf_unsigned_dynamic(Elf64_Dyn::DT_HASH);\n            unsigned y = 0;\n            if ((y=1, xct_va < va_gash)  ||  (y=2, (0==va_gash && xct_va < va_hash))\n            ||  (y=3, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_STRTAB))\n            ||  (y=4, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_SYMTAB))\n            ||  (y=5, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_REL))\n            ||  (y=6, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_RELA))\n            ||  (y=7, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_JMPREL))\n            ||  (y=8, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_VERDEF))\n            ||  (y=9, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_VERSYM))\n            ||  (y=10, xct_va < elf_unsigned_dynamic(Elf64_Dyn::DT_VERNEED)) ) {\n                static char const *which[] = {\n                    \"unknown\",\n                    \"DT_GNU_HASH\",\n                    \"DT_HASH\",\n                    \"DT_STRTAB\",\n                    \"DT_SYMTAB\",\n                    \"DT_REL\",\n                    \"DT_RELA\",\n                    \"DT_JMPREL\",\n                    \"DT_VERDEF\",\n                    \"DT_VERSYM\",\n                    \"DT_VERNEED\",\n                };\n                char buf[30]; snprintf(buf, sizeof(buf), \"%s above stub\", which[y]);\n                throwCantPack(buf);\n                goto abandon;\n            }\n            if (!opt->o_unix.android_shlib) {\n                phdr = phdri;\n                for (unsigned j= 0; j < e_phnum; ++phdr, ++j) {\n                    upx_uint64_t const vaddr = get_te64(&phdr->p_vaddr);\n                    if (PT_NOTE64 == get_te32(&phdr->p_type)\n                    && xct_va < vaddr) {\n                        char buf[40]; snprintf(buf, sizeof(buf),\n                           \"PT_NOTE %#lx above stub\", (unsigned long)vaddr);\n                        throwCantPack(buf);\n                        goto abandon;\n                    }\n                }\n            }\n            xct_off = elf_get_offset_from_address(xct_va);\n            if (opt->debug.debug_level) {\n                fprintf(stderr, \"shlib canPack: xct_va=%#lx  xct_off=%#lx\\n\",\n                    (long)xct_va, (long)xct_off);\n            }\n            goto proceed;  // But proper packing depends on checking xct_va.\n        }\n        else {\n            throwCantPack(\"need DT_INIT; try \\\"void _init(void){}\\\"\");\n        }\nabandon:\n        return false;\nproceed: ;\n    }\n    // XXX Theoretically the following test should be first,\n    // but PackUnix::canPack() wants 0!=exetype ?\n    if (!super::canPack())\n        return false;\n    assert(exetype == 1);\n    exetype = 0;\n\n    // set options\n    // this->blocksize: avoid over-allocating.\n    // (file_size - max_offset): debug info, non-globl symbols, etc.\n    opt->o_unix.blocksize = blocksize = UPX_MAX(max_LOADsz, file_size - max_offset);\n    return true;\n}\n\noff_t\nPackLinuxElf32::getbrk(Elf32_Phdr const *phdr, int nph) const\n{\n    off_t brka = 0;\n    for (int j = 0; j < nph; ++phdr, ++j) {\n        if (is_LOAD32(phdr)) {\n            off_t b = get_te32(&phdr->p_vaddr) + get_te32(&phdr->p_memsz);\n            if (b > brka)\n                brka = b;\n        }\n    }\n    return brka;\n}\n\noff_t\nPackLinuxElf32::getbase(const Elf32_Phdr *phdr, int nph) const\n{\n    off_t base = ~0u;\n    for (int j = 0; j < nph; ++phdr, ++j) {\n        if (is_LOAD32(phdr)) {\n            unsigned const vaddr = get_te32(&phdr->p_vaddr);\n            if (vaddr < (unsigned) base)\n                base = vaddr;\n        }\n    }\n    if (0!=base) {\n        return base;\n    }\n    return 0x12000;\n}\n\noff_t\nPackLinuxElf64::getbrk(const Elf64_Phdr *phdr, int nph) const\n{\n    off_t brka = 0;\n    for (int j = 0; j < nph; ++phdr, ++j) {\n        if (PT_LOAD64 == get_te32(&phdr->p_type)) {\n            off_t b = get_te64(&phdr->p_vaddr) + get_te64(&phdr->p_memsz);\n            if (b > brka)\n                brka = b;\n        }\n    }\n    return brka;\n}\n\nvoid\nPackLinuxElf32::generateElfHdr(\n    OutputFile *fo,\n    void const *proto,\n    unsigned const brka\n)\n{\n    cprElfHdr2 *const h2 = (cprElfHdr2 *)(void *)&elfout;\n    cprElfHdr3 *const h3 = (cprElfHdr3 *)(void *)&elfout;\n    h3->ehdr =         ((cprElfHdr3 const *)proto)->ehdr;\n    h3->phdr[C_BASE] = ((cprElfHdr3 const *)proto)->phdr[1];  // .data; .p_align\n    h3->phdr[C_TEXT] = ((cprElfHdr3 const *)proto)->phdr[0];  // .text\n    memset(&h3->linfo, 0, sizeof(h3->linfo));\n\n    h3->ehdr.e_type = ehdri.e_type;  // ET_EXEC vs ET_DYN (gcc -pie -fPIC)\n    h3->ehdr.e_ident[Elf32_Ehdr::EI_OSABI] = ei_osabi;\n    if (Elf32_Ehdr::EM_MIPS==e_machine) { // MIPS R3000  FIXME\n        h3->ehdr.e_ident[Elf32_Ehdr::EI_OSABI] = Elf32_Ehdr::ELFOSABI_NONE;\n        h3->ehdr.e_flags = ehdri.e_flags;\n    }\n\n    unsigned const phnum_i = get_te16(&h2->ehdr.e_phnum);\n    unsigned       phnum_o = phnum_i;\n\n    assert(get_te32(&h2->ehdr.e_phoff)     == sizeof(Elf32_Ehdr));\n                         h2->ehdr.e_shoff = 0;\n    assert(get_te16(&h2->ehdr.e_ehsize)    == sizeof(Elf32_Ehdr));\n    assert(get_te16(&h2->ehdr.e_phentsize) == sizeof(Elf32_Phdr));\n    if (o_elf_shnum) {\n        set_te16(&h2->ehdr.e_shentsize, sizeof(Elf32_Shdr));\n        h2->ehdr.e_shnum = o_elf_shnum;\n        h2->ehdr.e_shstrndx = o_elf_shnum - 1;\n    }\n    else {\n        // https://bugzilla.redhat.com/show_bug.cgi?id=2131609\n        // 0==.e_shnum is a special case for libbfd\n        // that requires 0==.e_shentsize in order to force \"no Shdrs\"\n        h2->ehdr.e_shentsize = 0;\n        h2->ehdr.e_shnum = 0;\n        h2->ehdr.e_shstrndx = 0;\n    }\n\n    sz_elf_hdrs = sizeof(*h2) - sizeof(linfo);  // default\n    if (gnu_stack) {\n        sz_elf_hdrs += sizeof(Elf32_Phdr);\n        memcpy(&h2->phdr[phnum_o++], gnu_stack, sizeof(*gnu_stack));\n        set_te16(&h2->ehdr.e_phnum, phnum_o);\n    }\n    o_binfo =  sizeof(Elf32_Ehdr) + sizeof(Elf32_Phdr)*phnum_o + sizeof(l_info) + sizeof(p_info);\n    set_te32(&h2->phdr[C_TEXT].p_filesz, sizeof(*h2));  // + identsize;\n              h2->phdr[C_TEXT].p_memsz = h2->phdr[C_TEXT].p_filesz;\n\n    for (unsigned j=0; j < phnum_i; ++j) {\n        if (is_LOAD32(&h3->phdr[j])) {\n            set_te32(&h3->phdr[j].p_align, page_size);\n        }\n    }\n\n    // Info for OS kernel to set the brk()\n    if (brka) {\n        // linux-2.6.14 binfmt_elf.c: SIGKILL if (0==.p_memsz) on a page boundary\n        upx_uint32_t lo_va_user = ~0u;  // infinity\n        for (int j= e_phnum; --j>=0; ) {\n            if (is_LOAD32(&phdri[j])) {\n                upx_uint32_t const vaddr = get_te32(&phdri[j].p_vaddr);\n                lo_va_user = umin(lo_va_user, vaddr);\n            }\n        }\n        set_te32(                 &h2->phdr[C_BASE].p_vaddr, lo_va_user);\n        h2->phdr[C_BASE].p_paddr = h2->phdr[C_BASE].p_vaddr;\n        h2->phdr[C_TEXT].p_vaddr = h2->phdr[C_BASE].p_vaddr;\n        h2->phdr[C_TEXT].p_paddr = h2->phdr[C_BASE].p_vaddr;\n        set_te32(&h2->phdr[C_BASE].p_type, PT_LOAD32);  // be sure\n        h2->phdr[C_BASE].p_offset = 0;\n        h2->phdr[C_BASE].p_filesz = 0;\n        // .p_memsz = brka;  temporary until sz_pack2\n        set_te32(&h2->phdr[C_BASE].p_memsz, brka - lo_va_user);\n        set_te32(&h2->phdr[C_BASE].p_flags, Elf32_Phdr::PF_R | Elf32_Phdr::PF_W);\n    }\n    if (ph.format==getFormat()) {\n        assert((2u+ !!gnu_stack) == phnum_o);\n        set_te32(&h2->phdr[C_TEXT].p_flags, ~Elf32_Phdr::PF_W & get_te32(&h2->phdr[C_TEXT].p_flags));\n        if (!gnu_stack) {\n            memset(&h2->linfo, 0, sizeof(h2->linfo));\n            fo->write(h2, sizeof(*h2));\n        }\n        else {\n            memset(&h3->linfo, 0, sizeof(h3->linfo));\n            fo->write(h3, sizeof(*h3));\n        }\n    }\n    else {\n        assert(false);  // unknown ph.format, PackLinuxElf32\n    }\n}\n\nvoid\nPackNetBSDElf32x86::generateElfHdr(\n    OutputFile *fo,\n    void const *proto,\n    unsigned const brka\n)\n{\n    super::generateElfHdr(fo, proto, brka);\n    cprElfHdr2 *const h2 = (cprElfHdr2 *)(void *)&elfout;\n\n    sz_elf_hdrs = sizeof(*h2) - sizeof(linfo);\n    unsigned note_offset = sz_elf_hdrs;\n\n    // Find the NetBSD PT_NOTE and the PaX PT_NOTE.\n    Elf32_Nhdr const *np_NetBSD = nullptr;  unsigned sz_NetBSD = 0;\n    Elf32_Nhdr const *np_PaX    = nullptr;  unsigned sz_PaX    = 0;\n    unsigned char *cp = (unsigned char *)note_body;\n    unsigned j;\n    for (j=0; j < note_size; ) {\n        Elf32_Nhdr const *const np = (Elf32_Nhdr const *)(void *)cp;\n        int k = sizeof(*np) + up4(get_te32(&np->namesz))\n            + up4(get_te32(&np->descsz));\n\n        if (NHDR_NETBSD_TAG == np->type && 7== np->namesz\n        &&  NETBSD_DESCSZ == np->descsz\n        &&  0==strcmp(ELF_NOTE_NETBSD_NAME,\n                /* &np->body */ (char const *)(1+ np))) {\n            np_NetBSD = np;\n            sz_NetBSD = k;\n        }\n        if (NHDR_PAX_TAG == np->type && 4== np->namesz\n        &&  PAX_DESCSZ==np->descsz\n        &&  0==strcmp(ELF_NOTE_PAX_NAME,\n                /* &np->body */ (char const *)(1+ np))) {\n            np_PaX = np;\n            sz_PaX = k;\n        }\n        cp += k;\n        j += k;\n    }\n\n    // Add PT_NOTE for the NetBSD note and PaX note, if any.\n    note_offset += (np_NetBSD ? sizeof(Elf32_Phdr) : 0);\n    note_offset += (np_PaX    ? sizeof(Elf32_Phdr) : 0);\n    Elf32_Phdr *phdr = &elfout.phdr[C_NOTE];\n    if (np_NetBSD) {\n        set_te32(&phdr->p_type, PT_NOTE32);\n        set_te32(&phdr->p_offset, note_offset);\n        set_te32(&phdr->p_vaddr, note_offset);\n        set_te32(&phdr->p_paddr, note_offset);\n        set_te32(&phdr->p_filesz, sz_NetBSD);\n        set_te32(&phdr->p_memsz,  sz_NetBSD);\n        set_te32(&phdr->p_flags, Elf32_Phdr::PF_R);\n        set_te32(&phdr->p_align, 4);\n\n        sz_elf_hdrs += sz_NetBSD + sizeof(*phdr);\n        note_offset += sz_NetBSD;\n        ++phdr;\n    }\n    if (np_PaX) {\n        set_te32(&phdr->p_type, PT_NOTE32);\n        set_te32(&phdr->p_offset, note_offset);\n        set_te32(&phdr->p_vaddr, note_offset);\n        set_te32(&phdr->p_paddr, note_offset);\n        set_te32(&phdr->p_filesz, sz_PaX);\n        set_te32(&phdr->p_memsz,  sz_PaX);\n        set_te32(&phdr->p_flags, Elf32_Phdr::PF_R);\n        set_te32(&phdr->p_align, 4);\n\n        /* &np_PaX->body[4] */\n        const unsigned char *p4 =  &(ACC_CCAST(const unsigned char *, (1+ np_PaX)))[4];\n        unsigned bits = get_te32(p4);\n        bits &= ~PAX_MPROTECT;\n        bits |=  PAX_NOMPROTECT;\n        set_te32(ACC_UNCONST_CAST(unsigned char *, p4), bits);\n\n        sz_elf_hdrs += sz_PaX + sizeof(*phdr);\n        note_offset += sz_PaX;\n        ++phdr;\n    }\n    set_te32(&h2->phdr[C_TEXT].p_filesz, note_offset);\n              h2->phdr[C_TEXT].p_memsz = h2->phdr[C_TEXT].p_filesz;\n\n    if (ph.format==getFormat()) {\n        set_te16(&h2->ehdr.e_phnum, !!sz_NetBSD + !!sz_PaX +\n        get_te16(&h2->ehdr.e_phnum));\n        fo->seek(0, SEEK_SET);\n        fo->rewrite(h2, sizeof(*h2) - sizeof(h2->linfo));\n\n        // The 'if' guards on these two calls to memcpy are required\n        // because the C Standard Committee did not debug the Standard\n        // before publishing.  An empty region (0==size) must nevertheless\n        // have a valid (non-nullptr) pointer.\n        if (sz_NetBSD) memcpy(&((char *)phdr)[0],         np_NetBSD, sz_NetBSD);\n        if (sz_PaX)    memcpy(&((char *)phdr)[sz_NetBSD], np_PaX,    sz_PaX);\n\n        fo->write(&elfout.phdr[C_NOTE],\n            &((char *)phdr)[sz_PaX + sz_NetBSD] - (char *)&elfout.phdr[C_NOTE]);\n\n        l_info foo; memset(&foo, 0, sizeof(foo));\n        fo->rewrite(&foo, sizeof(foo));\n    }\n    else {\n        assert(false);  // unknown ph.format, PackLinuxElf32\n    }\n}\n\nvoid\nPackOpenBSDElf32x86::generateElfHdr(\n    OutputFile *fo,\n    void const *proto,\n    unsigned const brka\n)\n{\n    cprElfHdr3 *const h3 = (cprElfHdr3 *)(void *)&elfout;\n    memcpy(h3, proto, sizeof(*h3));  // reads beyond, but OK\n    h3->ehdr.e_ident[Elf32_Ehdr::EI_OSABI] = ei_osabi;\n    assert(2==get_te16(&h3->ehdr.e_phnum));\n    set_te16(&h3->ehdr.e_phnum, 3);\n\n    assert(get_te32(&h3->ehdr.e_phoff)     == sizeof(Elf32_Ehdr));\n                         h3->ehdr.e_shoff = 0;\n    assert(get_te16(&h3->ehdr.e_ehsize)    == sizeof(Elf32_Ehdr));\n    assert(get_te16(&h3->ehdr.e_phentsize) == sizeof(Elf32_Phdr));\n    h3->ehdr.e_shentsize = 0;\n    h3->ehdr.e_shnum = 0;\n    h3->ehdr.e_shstrndx = 0;\n\n    struct {\n        Elf32_Nhdr nhdr;\n        char name[8];\n        unsigned body;\n    } elfnote;\n\n    unsigned const note_offset = sizeof(*h3) - sizeof(linfo);\n    sz_elf_hdrs = sizeof(elfnote) + note_offset;\n\n    set_te32(&h3->phdr[C_NOTE].p_type, PT_NOTE32);\n    set_te32(&h3->phdr[C_NOTE].p_offset, note_offset);\n    set_te32(&h3->phdr[C_NOTE].p_vaddr, note_offset);\n    set_te32(&h3->phdr[C_NOTE].p_paddr, note_offset);\n    set_te32(&h3->phdr[C_NOTE].p_filesz, sizeof(elfnote));\n    set_te32(&h3->phdr[C_NOTE].p_memsz,  sizeof(elfnote));\n    set_te32(&h3->phdr[C_NOTE].p_flags, Elf32_Phdr::PF_R);\n    set_te32(&h3->phdr[C_NOTE].p_align, 4);\n\n    // Q: Same as this->note_body[0 .. this->note_size-1] ?\n    set_te32(&elfnote.nhdr.namesz, 8);\n    set_te32(&elfnote.nhdr.descsz, OPENBSD_DESCSZ);\n    set_te32(&elfnote.nhdr.type,   NHDR_OPENBSD_TAG);\n    memcpy(elfnote.name, \"OpenBSD\", sizeof(elfnote.name));\n    elfnote.body = 0;\n\n    set_te32(&h3->phdr[C_TEXT].p_filesz, sz_elf_hdrs);\n              h3->phdr[C_TEXT].p_memsz = h3->phdr[C_TEXT].p_filesz;\n\n    unsigned const brkb = brka | ((0==(~page_mask & brka)) ? 0x20 : 0);\n    set_te32(&h3->phdr[C_BASE].p_type, PT_LOAD32);  // be sure\n    set_te32(&h3->phdr[C_BASE].p_offset, ~page_mask & brkb);\n    set_te32(&h3->phdr[C_BASE].p_vaddr, brkb);\n    set_te32(&h3->phdr[C_BASE].p_paddr, brkb);\n    h3->phdr[C_BASE].p_filesz = 0;\n    // Too many kernels have bugs when 0==.p_memsz\n    set_te32(&h3->phdr[C_BASE].p_memsz, 1);\n    set_te32(&h3->phdr[C_BASE].p_flags, Elf32_Phdr::PF_R | Elf32_Phdr::PF_W);\n\n    if (ph.format==getFormat()) {\n        memset(&h3->linfo, 0, sizeof(h3->linfo));\n        fo->write(h3, sizeof(*h3) - sizeof(h3->linfo));\n        fo->write(&elfnote, sizeof(elfnote));\n        fo->write(&h3->linfo, sizeof(h3->linfo));\n    }\n    else {\n        assert(false);  // unknown ph.format, PackLinuxElf32\n    }\n}\n\nvoid\nPackLinuxElf64::generateElfHdr(\n    OutputFile *fo,\n    void const *proto,\n    unsigned const brka\n)\n{\n    cprElfHdr2 *const h2 = (cprElfHdr2 *)(void *)&elfout;\n    cprElfHdr3 *const h3 = (cprElfHdr3 *)(void *)&elfout;\n    h3->ehdr =         ((cprElfHdr3 const *)proto)->ehdr;\n    h3->phdr[C_BASE] = ((cprElfHdr3 const *)proto)->phdr[1];  // .data; .p_align\n    h3->phdr[C_TEXT] = ((cprElfHdr3 const *)proto)->phdr[0];  // .text\n    memset(&h3->linfo, 0, sizeof(h3->linfo));\n\n    h3->ehdr.e_type = ehdri.e_type;  // ET_EXEC vs ET_DYN (gcc -pie -fPIC)\n    h3->ehdr.e_ident[Elf64_Ehdr::EI_OSABI] = ei_osabi;\n    if (Elf64_Ehdr::ELFOSABI_LINUX == ei_osabi  // proper\n    &&  Elf64_Ehdr::ELFOSABI_NONE  == ehdri.e_ident[Elf64_Ehdr::EI_OSABI]  // sloppy\n    ) { // propagate sloppiness so that decompression does not complain\n        h3->ehdr.e_ident[Elf64_Ehdr::EI_OSABI] = ehdri.e_ident[Elf64_Ehdr::EI_OSABI];\n    }\n    if (Elf64_Ehdr::EM_PPC64 == get_te16(&ehdri.e_machine)) {\n        h3->ehdr.e_flags = ehdri.e_flags;  // \"0x1, abiv1\" vs \"0x2, abiv2\"\n    }\n\n    unsigned const phnum_i = get_te16(&h2->ehdr.e_phnum);\n    unsigned       phnum_o = phnum_i;\n\n    assert(get_te64(&h2->ehdr.e_phoff)     == sizeof(Elf64_Ehdr));\n                         h2->ehdr.e_shoff = 0;\n    assert(get_te16(&h2->ehdr.e_ehsize)    == sizeof(Elf64_Ehdr));\n    assert(get_te16(&h2->ehdr.e_phentsize) == sizeof(Elf64_Phdr));\n    if (o_elf_shnum) {\n        set_te16(&h2->ehdr.e_shentsize, sizeof(Elf64_Shdr));\n        h2->ehdr.e_shnum = o_elf_shnum;\n        h2->ehdr.e_shstrndx = o_elf_shnum - 1;\n    }\n    else {\n        h2->ehdr.e_shentsize = 0;\n        h2->ehdr.e_shnum = 0;\n        h2->ehdr.e_shstrndx = 0;\n    }\n\n    sz_elf_hdrs = sizeof(*h2) - sizeof(linfo);  // default\n    if (gnu_stack) {\n        sz_elf_hdrs += sizeof(Elf64_Phdr);\n        memcpy(&h2->phdr[phnum_o++], gnu_stack, sizeof(*gnu_stack));\n        set_te16(&h2->ehdr.e_phnum, phnum_o);\n    }\n    o_binfo =  sizeof(Elf64_Ehdr) + sizeof(Elf64_Phdr)*phnum_o + sizeof(l_info) + sizeof(p_info);\n    set_te64(&h2->phdr[C_TEXT].p_filesz, sizeof(*h2));  // + identsize;\n                  h2->phdr[C_TEXT].p_memsz = h2->phdr[C_TEXT].p_filesz;\n\n    for (unsigned j=0; j < phnum_i; ++j) {\n        if (PT_LOAD64==get_te32(&h3->phdr[j].p_type)) {\n            set_te64(&h3->phdr[j].p_align, page_size);\n        }\n    }\n\n    // Info for OS kernel to set the brk()\n    if (brka) {\n        // linux-2.6.14 binfmt_elf.c: SIGKILL if (0==.p_memsz) on a page boundary\n        upx_uint64_t lo_va_user(~(upx_uint64_t)0);  // infinity\n        for (int j= e_phnum; --j>=0; ) {\n            if (PT_LOAD64 == get_te32(&phdri[j].p_type)) {\n                upx_uint64_t const vaddr = get_te64(&phdri[j].p_vaddr);\n                lo_va_user = umin64(lo_va_user, vaddr);\n            }\n        }\n        set_te64(                 &h2->phdr[C_BASE].p_vaddr, lo_va_user);\n        h2->phdr[C_BASE].p_paddr = h2->phdr[C_BASE].p_vaddr;\n        h2->phdr[C_TEXT].p_vaddr = h2->phdr[C_BASE].p_vaddr;\n        h2->phdr[C_TEXT].p_paddr = h2->phdr[C_BASE].p_vaddr;\n        set_te32(&h2->phdr[C_BASE].p_type, PT_LOAD64);  // be sure\n        h2->phdr[C_BASE].p_offset = 0;\n        h2->phdr[C_BASE].p_filesz = 0;\n        // .p_memsz = brka;  temporary until sz_pack2\n        set_te64(&h2->phdr[C_BASE].p_memsz, brka - lo_va_user);\n        set_te32(&h2->phdr[C_BASE].p_flags, Elf64_Phdr::PF_R | Elf64_Phdr::PF_W);\n    }\n    if (ph.format==getFormat()) {\n        assert((2u+ !!gnu_stack) == phnum_o);\n        set_te32(&h2->phdr[C_TEXT].p_flags, ~Elf64_Phdr::PF_W & get_te32(&h2->phdr[C_TEXT].p_flags));\n        if (!gnu_stack) {\n            memset(&h2->linfo, 0, sizeof(h2->linfo));\n            fo->write(h2, sizeof(*h2));\n        }\n        else {\n            memset(&h3->linfo, 0, sizeof(h3->linfo));\n            fo->write(h3, sizeof(*h3));\n        }\n    }\n    else {\n        assert(false);  // unknown ph.format, PackLinuxElf64\n    }\n}\n\n// Android shlib has ABS symbols that actually are relative.\nstatic char const abs_symbol_names[][14] = {\n      \"__bss_end__\"\n    ,  \"_bss_end__\"\n    , \"__bss_start\"\n    , \"__bss_start__\"\n    ,  \"_edata\"\n    ,  \"_end\"\n    , \"__end__\"\n    , \"\"\n};\n\nint\nPackLinuxElf32::adjABS(Elf32_Sym *sym, unsigned delta)\n{\n    unsigned st_name = get_te32(&sym->st_name);\n    for (int j = 0; abs_symbol_names[j][0]; ++j) {\n        if (!strcmp(abs_symbol_names[j], get_str_name(st_name, (unsigned)-1))) {\n            sym->st_value += delta;\n            return 1;\n        }\n    }\n    return 0;\n}\n\nint\nPackLinuxElf64::adjABS(Elf64_Sym *sym, unsigned delta)\n{\n    unsigned st_name = get_te32(&sym->st_name);\n    for (int j = 0; abs_symbol_names[j][0]; ++j) {\n        if (!strcmp(abs_symbol_names[j], get_str_name(st_name, (unsigned)-1))) {\n            sym->st_value += delta;\n            return 1;\n        }\n    }\n    return 0;\n}\n\nvoid PackLinuxElf32::pack1(OutputFile *fo, Filter & /*ft*/)\n{\n    fi->seek(0, SEEK_SET);\n    fi->readx(&ehdri, sizeof(ehdri));\n    assert(e_phoff == sizeof(Elf32_Ehdr));  // checked by canPack()\n    sz_phdrs = e_phnum * get_te16(&ehdri.e_phentsize);\n\n    // Remember all PT_NOTE, and find lg2_page from PT_LOAD.\n    Elf32_Phdr *phdr = phdri;\n    note_size = 0;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        if (PT_NOTE32 == get_te32(&phdr->p_type)) {\n            note_size += up4(get_te32(&phdr->p_filesz));\n        }\n    }\n    if (note_size) {\n        note_body.alloc(note_size);\n        note_size = 0;\n    }\n    phdr = phdri;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        unsigned const type = get_te32(&phdr->p_type);\n        if (PT_NOTE32 == type) {\n            unsigned const len = get_te32(&phdr->p_filesz);\n            fi->seek(get_te32(&phdr->p_offset), SEEK_SET);\n            fi->readx(&note_body[note_size], len);\n            note_size += up4(len);\n        }\n        if (PT_LOAD32 == type) {\n            unsigned x = get_te32(&phdr->p_align) >> lg2_page;\n            while (x>>=1) {\n                ++lg2_page;\n            }\n        }\n        if (PT_GNU_STACK32 == type) {\n            // MIPS stub cannot handle GNU_STACK yet.\n            if (Elf32_Ehdr::EM_MIPS != this->e_machine) {\n                gnu_stack = phdr;\n            }\n        }\n    }\n    page_size =  1u<<lg2_page;\n    page_mask = ~0u<<lg2_page;\n\n    progid = 0;  // getRandomId();  not useful, so do not clutter\n    sz_elf_hdrs = sizeof(ehdri) + sz_phdrs;\n    if (0!=xct_off) {  // shared library\n        sz_elf_hdrs = xct_off;\n        lowmem.alloc(xct_off + (!opt->o_unix.android_shlib\n            ? 0\n            : e_shnum * sizeof(Elf32_Shdr)));\n        memcpy(lowmem, file_image, xct_off);  // android omits Shdr here\n        fo->write(lowmem, xct_off);  // < SHF_EXECINSTR (typ: in .plt or .init)\n        if (opt->o_unix.android_shlib) {\n            // In order to pacify the runtime linker on Android \"O\" (\"Oreo\"),\n            // we will splice-in a 4KiB page that contains an \"extra\" copy\n            // of the Shdr, any PT_NOTE above xct_off, and shstrtab.\n            // File order: Ehdr, Phdr[], section contents below xct_off,\n            //    Shdr_copy[], PT_NOTEs.hi, shstrtab.\n            xct_va  += asl_delta;\n            //xct_off += asl_delta;  // not yet\n\n            // Relocate PT_DYNAMIC (in 2nd PT_LOAD)\n            Elf32_Dyn *dyn = const_cast<Elf32_Dyn *>(dynseg);\n            for (; dyn->d_tag; ++dyn) {\n                unsigned d_tag = get_te32(&dyn->d_tag);\n                if (Elf32_Dyn::DT_FINI       == d_tag\n                ||  Elf32_Dyn::DT_FINI_ARRAY == d_tag\n                ||  Elf32_Dyn::DT_INIT_ARRAY == d_tag\n                ||  Elf32_Dyn::DT_PREINIT_ARRAY == d_tag\n                ||  Elf32_Dyn::DT_PLTGOT     == d_tag) {\n                    unsigned d_val = get_te32(&dyn->d_val);\n                    set_te32(&dyn->d_val, asl_delta + d_val);\n                }\n            }\n\n            // Relocate dynsym (DT_SYMTAB) which is below xct_va\n            unsigned const off_dynsym = get_te32(&sec_dynsym->sh_offset);\n            unsigned const sz_dynsym  = get_te32(&sec_dynsym->sh_size);\n            Elf32_Sym *dyntym = (Elf32_Sym *)lowmem.subref(\n                \"bad dynsym\", off_dynsym, sz_dynsym);\n            Elf32_Sym *sym = dyntym;\n            for (int j = sz_dynsym / sizeof(Elf32_Sym); --j>=0; ++sym) {\n                unsigned symval = get_te32(&sym->st_value);\n                unsigned symsec = get_te16(&sym->st_shndx);\n                if (Elf32_Sym::SHN_UNDEF != symsec\n                &&  Elf32_Sym::SHN_ABS   != symsec\n                &&  xct_off <= symval) {\n                    set_te32(&sym->st_value, asl_delta + symval);\n                }\n                if (Elf32_Sym::SHN_ABS == symsec && xct_off <= symval) {\n                    adjABS(sym, asl_delta);\n                }\n            }\n\n            // Relocate Phdr virtual addresses, but not physical offsets and sizes\n            unsigned char buf_notes[512]; memset(buf_notes, 0, sizeof(buf_notes));\n            unsigned len_notes = 0;\n            phdr = (Elf32_Phdr *)lowmem.subref(\n                \"bad e_phoff\", e_phoff, e_phnum * sizeof(Elf32_Phdr));\n            for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n                upx_uint32_t offset = get_te32(&phdr->p_offset);\n                if (xct_off <= offset) { // above the extra page\n                    if (PT_NOTE32 == get_te32(&phdr->p_type)) {\n                        upx_uint32_t memsz = get_te32(&phdr->p_memsz);\n                        if (sizeof(buf_notes) < (memsz + len_notes)) {\n                            throwCantPack(\"PT_NOTEs too big\");\n                        }\n                        set_te32(&phdr->p_vaddr,\n                            len_notes + (e_shnum * sizeof(Elf32_Shdr)) + xct_off);\n                        phdr->p_offset = phdr->p_paddr = phdr->p_vaddr;\n                        memcpy(&buf_notes[len_notes], &file_image[offset], memsz);\n                        len_notes += memsz;\n                    }\n                    else {\n                        //set_te32(&phdr->p_offset, asl_delta + offset);  // physical\n                        upx_uint32_t addr = get_te32(&phdr->p_paddr);\n                        set_te32(&phdr->p_paddr, asl_delta + addr);\n                                     addr = get_te32(&phdr->p_vaddr);\n                        set_te32(&phdr->p_vaddr, asl_delta + addr);\n                    }\n                }\n                // .p_filesz,.p_memsz are updated in ::pack3\n            }\n\n            Elf32_Ehdr *const ehdr = (Elf32_Ehdr *)&lowmem[0];\n            upx_uint32_t e_entry = get_te32(&ehdr->e_entry);\n            if (xct_off < e_entry) {\n                set_te32(&ehdr->e_entry, asl_delta + e_entry);\n            }\n            // Relocate Shdr; and Rela, Rel (below xct_off)\n            set_te32(&ehdr->e_shoff, xct_off);\n            memcpy(&lowmem[xct_off], shdri, e_shnum * sizeof(Elf32_Shdr));\n            Elf32_Shdr *const shdro = (Elf32_Shdr *)&lowmem[xct_off];\n            Elf32_Shdr *shdr = shdro;\n            unsigned sz_shstrtab  = get_te32(&sec_strndx->sh_size);\n            for (unsigned j = 0; j < e_shnum; ++j, ++shdr) {\n\n                unsigned sh_type = get_te32(&shdr->sh_type);\n                unsigned sh_size = get_te32(&shdr->sh_size);\n                unsigned  sh_offset = get_te32(&shdr->sh_offset);\n                unsigned sh_entsize = get_te32(&shdr->sh_entsize);\n                unsigned   sh_flags = get_te32(&shdr->sh_flags);\n                if (xct_off <= sh_offset\n                // Omit .comment (0==.sh_addr; !SHF_ALLOC) etc.\n                && (shdr->sh_addr || Elf32_Shdr::SHF_ALLOC & sh_flags)\n                ) {\n                    //set_te32(&shdr->sh_offset, asl_delta + sh_offset);  // FIXME ??\n                    upx_uint32_t addr = get_te32(&shdr->sh_addr);\n                    set_te32(&shdr->sh_addr, asl_delta + addr);\n                }\n                if (Elf32_Shdr::SHT_RELA== sh_type) {\n                    if (sizeof(Elf32_Rela) != sh_entsize) {\n                        char msg[50];\n                        snprintf(msg, sizeof(msg), \"bad Rela.sh_entsize %u\", sh_entsize);\n                        throwCantPack(msg);\n                    }\n                    n_jmp_slot = 0;\n                    plt_off = ~0u;\n                    Elf32_Rela *const relb = (Elf32_Rela *)lowmem.subref(\n                         \"bad Rela offset\", sh_offset, sh_size);\n                    Elf32_Rela *rela = relb;\n                    for (int k = sh_size / sh_entsize; --k >= 0; ++rela) {\n                        unsigned r_addend = get_te32(&rela->r_addend);\n                        unsigned r_offset = get_te32(&rela->r_offset);\n                        unsigned r_info   = get_te32(&rela->r_info);\n                        unsigned r_type = ELF32_R_TYPE(r_info);\n                        if (xct_off <= r_offset) {\n                            set_te32(&rela->r_offset, asl_delta + r_offset);\n                        }\n                        if (Elf32_Ehdr::EM_ARM == e_machine) {\n                            if (R_ARM_RELATIVE == r_type) {\n                                if (xct_off <= r_addend) {\n                                    set_te32(&rela->r_addend, asl_delta + r_addend);\n                                }\n                            }\n                            if (R_ARM_JUMP_SLOT == r_type) {\n                                // .rela.plt contains offset of the \"first time\" target\n                                if (plt_off > r_offset) {\n                                    plt_off = r_offset;\n                                }\n                                unsigned d = elf_get_offset_from_address(r_offset);\n                                unsigned w = get_te32(&file_image[d]);\n                                if (xct_off <= w) {\n                                    set_te32(&file_image[d], asl_delta + w);\n                                }\n                                ++n_jmp_slot;\n                            }\n                        }\n                    }\n                    fo->seek(sh_offset, SEEK_SET);\n                    fo->rewrite(relb, sh_size);\n                }\n                if (Elf32_Shdr::SHT_REL == sh_type) {\n                    if (sizeof(Elf32_Rel) != sh_entsize) {\n                        char msg[50];\n                        snprintf(msg, sizeof(msg), \"bad Rel.sh_entsize %u\", sh_entsize);\n                        throwCantPack(msg);\n                    }\n                    n_jmp_slot = 0;\n                    plt_off = ~0u;\n                    Elf32_Rel *const rel0 = (Elf32_Rel *)lowmem.subref(\n                         \"bad Rel offset\", sh_offset, sh_size);\n                    Elf32_Rel *rel = rel0;\n                    for (int k = sh_size / sh_entsize; --k >= 0; ++rel) {\n                        unsigned r_offset = get_te32(&rel->r_offset);\n                        unsigned r_info = get_te32(&rel->r_info);\n                        unsigned r_type = ELF32_R_TYPE(r_info);\n                        unsigned d = elf_get_offset_from_address(r_offset);\n                        unsigned w = get_te32(&file_image[d]);\n                        if (xct_off <= r_offset) {\n                            set_te32(&rel->r_offset, asl_delta + r_offset);\n                        }\n                        if (Elf32_Ehdr::EM_ARM == e_machine) switch (r_type) {\n                            default: {\n                                char msg[90]; snprintf(msg, sizeof(msg),\n                                    \"unexpected relocation %#x [%#x]\",\n                                    r_type, -1 + (sh_size / sh_entsize) - k);\n                                throwCantPack(msg);\n                            } break;\n                            case R_ARM_ABS32:  // FALL THROUGH\n                            case R_ARM_GLOB_DAT: // FALL THROUGH\n                            case R_ARM_RELATIVE: {\n                                if (xct_off <= w) {\n                                    set_te32(&file_image[d], asl_delta + w);\n                                }\n                            } break;\n                            case R_ARM_JUMP_SLOT: {\n                                if (plt_off > r_offset) {\n                                    plt_off = r_offset;\n                                }\n                                if (xct_off <= w) {\n                                    set_te32(&file_image[d], asl_delta + w);\n                                }\n                                ++n_jmp_slot;\n                            }; break;\n                        }\n                    }\n                    fo->seek(sh_offset, SEEK_SET);\n                    fo->rewrite(rel0, sh_size);\n                }\n                if (Elf32_Shdr::SHT_NOTE == sh_type) {\n                    if (!(Elf32_Shdr::SHF_ALLOC & get_te32(&shdr->sh_flags))) {\n                        // example: version number of 'gold' linker (static binder)\n                        if (sizeof(buf_notes) < (sh_size + len_notes)) {\n                            throwCantPack(\"SHT_NOTEs too big\");\n                        }\n                        set_te32(&shdro[j].sh_offset,\n                            len_notes + (e_shnum * sizeof(Elf32_Shdr)) + xct_off);\n                        memcpy(&buf_notes[len_notes], &file_image[sh_offset], sh_size);\n                        len_notes += sh_size;\n                    }\n                    else { // SHF_ALLOC, thus already in PT_LOAD\n                        // Not sure why we need this conditional.\n                        // Anyway, some Android have multiple SHT_NOTE sections.\n                        if (xct_off <= sh_offset) {\n                            upx_uint32_t pos = xct_off + e_shnum * sizeof(Elf32_Shdr);\n                            set_te32(&shdr->sh_addr,   pos);\n                            set_te32(&shdr->sh_offset, pos);\n                        }\n                    }\n                }\n            }\n            // shstrndx will move\n            set_te32(&shdro[get_te16(&ehdri.e_shstrndx)].sh_offset,\n                len_notes + e_shnum * sizeof(Elf32_Shdr) + xct_off);\n\n            // (Re-)write all changes below xct_off\n            fo->seek(0, SEEK_SET);\n            fo->rewrite(lowmem, xct_off);\n\n            // New copy of Shdr\n            Elf32_Shdr blank; memset(&blank, 0, sizeof(blank));\n            set_te32(&blank.sh_offset, xct_off);  // hint for \"upx -d\"\n            fo->write(&blank, sizeof(blank));\n            fo->write(&shdro[1], (-1+ e_shnum) * sizeof(Elf32_Shdr));\n\n            if (len_notes) {\n                fo->write(buf_notes, len_notes);\n            }\n\n            // New copy of Shdr[.e_shstrndx].[ sh_offset, +.sh_size )\n            fo->write(shstrtab,  sz_shstrtab);\n\n            sz_elf_hdrs = fpad4(fo);\n            //xct_off += asl_delta;  // wait until ::pack3\n        }\n        memset(&linfo, 0, sizeof(linfo));\n        fo->write(&linfo, sizeof(linfo));\n    }\n\n    // if the preserve build-id option was specified\n    if (opt->o_unix.preserve_build_id) {\n        // set this so we can use elf_find_section_name\n        e_shnum = get_te16(&ehdri.e_shnum);\n        MemBuffer mb_shdri;\n        if (!shdri) {\n            mb_shdri.alloc(e_shnum * sizeof(Elf32_Shdr));\n            shdri = (Elf32_Shdr *)mb_shdri.getVoidPtr();\n            e_shoff = get_te32(&ehdri.e_shoff);\n            fi->seek(e_shoff, SEEK_SET);\n            fi->readx(shdri, e_shnum * sizeof(Elf32_Shdr));\n        }\n        //set the shstrtab\n        sec_strndx = &shdri[get_te16(&ehdri.e_shstrndx)];\n\n        unsigned sh_size = get_te32(&sec_strndx->sh_size);\n        mb_shstrtab.alloc(sh_size); shstrtab = (char *)mb_shstrtab.getVoidPtr();\n        fi->seek(0,SEEK_SET);\n        fi->seek(sec_strndx->sh_offset,SEEK_SET);\n        fi->readx(mb_shstrtab, sh_size);\n\n        Elf32_Shdr const *buildid = elf_find_section_name(\".note.gnu.build-id\");\n        if (buildid) {\n            unsigned bid_sh_size = get_te32(&buildid->sh_size);\n            buildid_data.alloc(bid_sh_size);\n            buildid_data.clear();\n            fi->seek(0,SEEK_SET);\n            fi->seek(buildid->sh_offset,SEEK_SET);\n            fi->readx((void *)buildid_data, bid_sh_size);\n\n            o_elf_shnum = 3;\n            memset(&shdrout,0,sizeof(shdrout));\n\n            //setup the build-id\n            memcpy(&shdrout.shdr[1], buildid, sizeof(shdrout.shdr[1]));\n            set_te32(&shdrout.shdr[1].sh_name, 1);\n\n            //setup the shstrtab\n            memcpy(&shdrout.shdr[2], sec_strndx, sizeof(shdrout.shdr[2]));\n            set_te32(&shdrout.shdr[2].sh_name, 20);\n            set_te32(&shdrout.shdr[2].sh_size, 29); //size of our static shstrtab\n        }\n    }\n}\n\nvoid PackLinuxElf32x86::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_i386_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackBSDElf32x86::pack1(OutputFile *fo, Filter &ft)\n{\n    PackLinuxElf32::pack1(fo, ft);\n    if (0!=xct_off) // shared library\n        return;\n    generateElfHdr(fo, stub_i386_bsd_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf32armLe::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    unsigned const e_flags = get_te32(&ehdri.e_flags);\n    cprElfHdr3 h3;\n    if (Elf32_Ehdr::ELFOSABI_LINUX==ei_osabi) {\n        memcpy(&h3, stub_arm_v5a_linux_elf_fold, sizeof(Elf32_Ehdr) + 2*sizeof(Elf32_Phdr));\n\n        h3.ehdr.e_ident[Elf32_Ehdr::EI_ABIVERSION] = e_flags>>24;\n    }\n    else {\n        memcpy(&h3, stub_arm_v4a_linux_elf_fold,        sizeof(Elf32_Ehdr) + 2*sizeof(Elf32_Phdr));\n    }\n    // Fighting over .e_ident[EI_ABIVERSION]: Debian armhf is latest culprit.\n    // So copy from input to output; but see PackLinuxElf32::generateElfHdr\n    memcpy(&h3.ehdr.e_ident[0], &ehdri.e_ident[0], sizeof(ehdri.e_ident));\n    set_te32(&h3.ehdr.e_flags, e_flags);\n    generateElfHdr(fo, &h3, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf32armBe::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    unsigned const e_flags = get_te32(&ehdri.e_flags);\n    cprElfHdr3 h3;\n    memcpy(&h3, stub_armeb_v4a_linux_elf_fold, sizeof(Elf32_Ehdr) + 2*sizeof(Elf32_Phdr));\n    set_te32(&h3.ehdr.e_flags, e_flags);\n    generateElfHdr(fo, &h3, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf32mipsel::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    cprElfHdr3 h3;\n    memcpy(&h3, stub_mipsel_r3000_linux_elf_fold, sizeof(Elf32_Ehdr) + 2*sizeof(Elf32_Phdr));\n    generateElfHdr(fo, &h3, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf32mipseb::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    cprElfHdr3 h3;\n    memcpy(&h3, stub_mips_r3000_linux_elf_fold, sizeof(Elf32_Ehdr) + 2*sizeof(Elf32_Phdr));\n    generateElfHdr(fo, &h3, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf32ppc::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_powerpc_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf64ppcle::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_powerpc64le_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf64ppc::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_powerpc64_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf64::asl_pack2_Shdrs(OutputFile *fo)\n{\n    // In order to pacify the runtime linker on Android \"O\" (\"Oreo\"),\n    // we will splice-in a 4KiB page that contains an \"extra\" copy\n    // of the Shdr, any PT_NOTE above xct_off, and shstrtab.\n    // File order: Ehdr, Phdr[], section contents below xct_off,\n    //    Shdr_copy[], PT_NOTEs.hi, shstrtab.\n    xct_va  += asl_delta;\n    //xct_off += asl_delta;  // not until ::pack3()\n\n    // Relocate PT_DYNAMIC (in PT_LOAD with PF_W)\n    Elf64_Dyn *dyn = const_cast<Elf64_Dyn *>(dynseg);\n    for (; dyn->d_tag; ++dyn) {\n        upx_uint64_t d_tag = get_te64(&dyn->d_tag);\n        if (Elf64_Dyn::DT_FINI       == d_tag\n        ||  Elf64_Dyn::DT_FINI_ARRAY == d_tag\n        ||  Elf64_Dyn::DT_INIT_ARRAY == d_tag\n        ||  Elf64_Dyn::DT_PREINIT_ARRAY == d_tag\n        ||  Elf64_Dyn::DT_PLTGOT      == d_tag) {\n            upx_uint64_t d_val = get_te64(&dyn->d_val);\n            set_te64(&dyn->d_val, asl_delta + d_val);\n        }\n    }\n    // Updated dynseg (.dynamic, in PT_DYNAMIC (PT_LOAD{PF_W})) has not been written.\n    // dynseg is in file_image[] but not in low_mem[].\n\n    // Relocate dynsym (DT_SYMTAB) which is below xct_va\n    upx_uint64_t const off_dynsym = get_te64(&sec_dynsym->sh_offset);\n    upx_uint64_t const sz_dynsym  = get_te64(&sec_dynsym->sh_size);\n    if ((upx_uint64_t)file_size < sz_dynsym\n    ||  (upx_uint64_t)file_size < off_dynsym\n    || ((upx_uint64_t)file_size - off_dynsym) < sz_dynsym) {\n        throwCantPack(\"bad DT_SYMTAB\");\n    }\n    Elf64_Sym *dyntym = (Elf64_Sym *)lowmem.subref(\n        \"bad dynsym\", off_dynsym, sz_dynsym);\n    Elf64_Sym *sym = dyntym;\n    for (int j = sz_dynsym / sizeof(Elf64_Sym); --j>=0; ++sym) {\n        upx_uint64_t symval = get_te64(&sym->st_value);\n        unsigned symsec = get_te16(&sym->st_shndx);\n        if (Elf64_Sym::SHN_UNDEF != symsec\n        &&  Elf64_Sym::SHN_ABS   != symsec\n        &&  xct_off <= symval) {\n            set_te64(&sym->st_value, asl_delta + symval);\n        }\n        if (Elf64_Sym::SHN_ABS == symsec && xct_off <= symval) {\n            adjABS(sym, asl_delta);\n        }\n    }\n\n    // Relocate Phdr virtual addresses, but not physical offsets and sizes\n    unsigned char buf_notes[512]; memset(buf_notes, 0, sizeof(buf_notes));\n    unsigned len_notes = 0;\n    Elf64_Phdr *phdr = (Elf64_Phdr *)lowmem.subref(\n        \"bad e_phoff\", e_phoff, e_phnum * sizeof(Elf64_Phdr));\n    for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n        upx_uint64_t offset = get_te64(&phdr->p_offset);\n        if (xct_off <= offset) { // above the extra page\n            if (PT_NOTE64 == get_te32(&phdr->p_type)) {\n                upx_uint64_t memsz = get_te64(&phdr->p_memsz);\n                if (sizeof(buf_notes) < (memsz + len_notes)) {\n                    throwCantPack(\"PT_NOTES too big\");\n                }\n                set_te64(&phdr->p_vaddr,\n                    len_notes + (e_shnum * sizeof(Elf64_Shdr)) + xct_off);\n                phdr->p_offset = phdr->p_paddr = phdr->p_vaddr;\n                memcpy(&buf_notes[len_notes], &file_image[offset], memsz);\n                len_notes += memsz;\n            }\n            else {\n                //set_te64(&phdr->p_offset, asl_delta + offset);  // physical\n                upx_uint64_t addr = get_te64(&phdr->p_paddr);\n                set_te64(&phdr->p_paddr, asl_delta + addr);\n                             addr = get_te64(&phdr->p_vaddr);\n                set_te64(&phdr->p_vaddr, asl_delta + addr);\n            }\n        }\n        // .p_filesz,.p_memsz are updated in ::pack3\n    }\n\n    Elf64_Ehdr *const ehdr = (Elf64_Ehdr *)&lowmem[0];\n    upx_uint64_t e_entry = get_te64(&ehdr->e_entry);\n    if (xct_off < e_entry) {\n        set_te64(&ehdr->e_entry, asl_delta + e_entry);\n    }\n    // Relocate Shdr; and Rela, Rel (below xct_off)\n    set_te64(&ehdr->e_shoff, xct_off);\n    memcpy(&lowmem[xct_off], shdri, e_shnum * sizeof(Elf64_Shdr));\n    Elf64_Shdr *const shdro = (Elf64_Shdr *)&lowmem[xct_off];\n    Elf64_Shdr *shdr = shdro;\n    upx_uint64_t sz_shstrtab  = get_te64(&sec_strndx->sh_size);\n    for (unsigned j = 0; j < e_shnum; ++j, ++shdr) {\n        unsigned sh_type = get_te32(&shdr->sh_type);\n        upx_uint64_t sh_size = get_te64(&shdr->sh_size);\n        upx_uint64_t sh_offset = get_te64(&shdr->sh_offset);\n        upx_uint64_t sh_entsize = get_te64(&shdr->sh_entsize);\n        if ((upx_uint64_t)file_size < sh_size\n        ||  (upx_uint64_t)file_size < sh_offset\n        || (Elf64_Shdr::SHT_NOBITS != sh_type\n           && ((upx_uint64_t)file_size - sh_offset) < sh_size) ) {\n            throwCantPack(\"bad SHT_STRNDX\");\n        }\n\n        if (xct_off <= sh_offset) {\n            upx_uint64_t addr = get_te64(&shdr->sh_addr);\n            set_te64(&shdr->sh_addr, asl_delta + addr);\n            set_te64(&shdr->sh_offset, asl_delta + sh_offset);\n        }\n        switch (sh_type) {\n        default: break;\n        case Elf64_Shdr::SHT_RELA: {\n            if (sizeof(Elf64_Rela) != sh_entsize) {\n                char msg[50];\n                snprintf(msg, sizeof(msg), \"bad Rela.sh_entsize %lu\", (long)sh_entsize);\n                throwCantPack(msg);\n            }\n            n_jmp_slot = 0;\n            plt_off = ~0ull;\n            Elf64_Rela *const relb = (Elf64_Rela *)lowmem.subref(\n                 \"bad Rela offset\", sh_offset, sh_size);\n            Elf64_Rela *rela = relb;\n            for (int k = sh_size / sh_entsize; --k >= 0; ++rela) {\n                upx_uint64_t r_addend = get_te64(&rela->r_addend);\n                upx_uint64_t r_offset = get_te64(&rela->r_offset);\n                upx_uint64_t r_info   = get_te64(&rela->r_info);\n                unsigned r_type = ELF64_R_TYPE(r_info);\n                if (xct_off <= r_offset) {\n                    set_te64(&rela->r_offset, asl_delta + r_offset);\n                }\n                if (Elf64_Ehdr::EM_AARCH64 == e_machine) switch (r_type) {\n                    default: {\n                        char msg[90]; snprintf(msg, sizeof(msg),\n                            \"unexpected relocation %#x [%#x]\",\n                            r_type, -1 + (unsigned)(sh_size / sh_entsize) - k);\n                        throwCantPack(msg);\n                    } break;\n                    case R_AARCH64_ABS64: // FALL THROUGH\n                    case R_AARCH64_GLOB_DAT: // FALL THROUGH\n                    case R_AARCH64_RELATIVE: {\n                        if (xct_off <= r_addend) {\n                            set_te64(&rela->r_addend, asl_delta + r_addend);\n                        }\n                    } break;\n                    case R_AARCH64_JUMP_SLOT: {\n                        // .rela.plt contains offset of the \"first time\" target\n                        if (plt_off > r_offset) {\n                            plt_off = r_offset;\n                        }\n                        upx_uint64_t d = elf_get_offset_from_address(r_offset);\n                        upx_uint64_t w = get_te64(&file_image[d]);\n                        if (xct_off <= w) {\n                            set_te64(&file_image[d], asl_delta + w);\n                        }\n                        ++n_jmp_slot;\n                    } break;\n                }\n            }\n        }; break;\n        case Elf64_Shdr::SHT_REL: {\n            if (sizeof(Elf64_Rel) != sh_entsize) {\n                char msg[50];\n                snprintf(msg, sizeof(msg), \"bad Rel.sh_entsize %lu\", (long)sh_entsize);\n                throwCantPack(msg);\n            }\n            Elf64_Rel *rel = (Elf64_Rel *)lowmem.subref(\n                    \"bad Rel sh_offset\", sh_offset, sh_size);\n            for (int k = sh_size / sh_entsize; --k >= 0; ++rel) {\n                upx_uint64_t r_offset = get_te64(&rel->r_offset);\n                if (xct_off <= r_offset) {\n                    set_te64(&rel->r_offset, asl_delta + r_offset);\n                }\n                // r_offset must be in 2nd PT_LOAD; .p_vaddr was already relocated\n                upx_uint64_t d = elf_get_offset_from_address(asl_delta + r_offset);\n                upx_uint64_t w = get_te64(&file_image[d]);\n                upx_uint64_t r_info = get_te64(&rel->r_info);\n                unsigned r_type = ELF64_R_TYPE(r_info);\n                if (xct_off <= w\n                &&  Elf64_Ehdr::EM_AARCH64 == e_machine\n                &&  (  R_AARCH64_RELATIVE  == r_type\n                    || R_AARCH64_JUMP_SLOT == r_type)) {\n                    set_te64(&file_image[d], asl_delta + w);\n                }\n            }\n        }; break;\n        case Elf64_Shdr::SHT_NOTE: {\n            if (!(Elf64_Shdr::SHF_ALLOC & get_te64(&shdr->sh_flags))) {\n                // example: version numer of 'gold' linker (static binder)\n                if (sizeof(buf_notes) < (sh_size + len_notes)) {\n                    throwCantPack(\"SHT_NOTEs too big\");\n                }\n                set_te64(&shdro[j].sh_offset,\n                    len_notes + (e_shnum * sizeof(Elf64_Shdr)) + xct_off);\n                memcpy(&buf_notes[len_notes], &file_image[sh_offset], sh_size);\n                len_notes += sh_size;\n            }\n            else { // SHF_ALLOC: in PT_LOAD; but move sh_addr and sh_offset\n                // Not sure why we need this conditional.\n                // Anyway, some Android have multiple SHT_NOTE sections.\n                if (xct_off <= sh_offset) {\n                    upx_uint64_t pos = xct_off + e_shnum * sizeof(Elf64_Shdr);\n                    set_te64(&shdr->sh_addr,   pos);\n                    set_te64(&shdr->sh_offset, pos);\n                }\n            }\n        }; break;\n        } // end switch (sh_type)\n    }\n    // shstrndx will move\n    set_te64(&shdro[get_te16(&ehdri.e_shstrndx)].sh_offset,\n        len_notes + e_shnum * sizeof(Elf64_Shdr) + xct_off);\n\n    // (Re-)write all changes below xct_off\n    fo->seek(0, SEEK_SET);\n    fo->rewrite(lowmem, xct_off);\n\n    // New copy of Shdr\n    Elf64_Shdr blank; memset(&blank, 0, sizeof(blank));\n    set_te64(&blank.sh_offset, xct_off);  // hint for \"upx -d\"\n    fo->write(&blank, sizeof(blank));\n    fo->write(&shdro[1], (-1+ e_shnum) * sizeof(Elf64_Shdr));\n\n    if (len_notes) {\n        fo->write(buf_notes, len_notes);\n    }\n\n    // New copy of Shdr[.e_shstrndx].[ sh_offset, +.sh_size )\n    fo->write(shstrtab,  sz_shstrtab);\n\n    sz_elf_hdrs = fpad8(fo);\n    total_out = sz_elf_hdrs;\n    total_in = xct_off;\n    //xct_off += asl_delta;  // wait until ::pack3\n\n    memset(&linfo, 0, sizeof(linfo));\n    fo->write(&linfo, sizeof(linfo));\n}\n\nvoid PackLinuxElf64::pack1(OutputFile * /*fo*/, Filter &ft)\n{\n    fi->seek(0, SEEK_SET);\n    fi->readx(&ehdri, sizeof(ehdri));\n    assert(e_phoff == sizeof(Elf64_Ehdr));  // checked by canPack()\n    sz_phdrs = e_phnum * get_te16(&ehdri.e_phentsize);\n\n// We compress separate pieces (usually each PT_LOAD, plus the gaps in the file\n// that are not covered by any PT_LOAD), but currently at run time there can be\n// only one decompressor method.\n// Therefore we must plan ahead because Packer::compressWithFilters tries\n// to find the smallest result among the available methods, for one piece only.\n// In the future we may allow more than one decompression method at run time.\n// For now we must choose only one, and force PackUnix::packExtent\n// (==> compressWithFilters) to use it.\n    int nfilters = 0;\n    {\n        int const *fp = getFilters();\n        while (FT_END != *fp++) {\n            ++nfilters;\n        }\n    }\n    {\n        int npieces = 1;  // tail after highest PT_LOAD\n        Elf64_Phdr *phdr = phdri;\n        for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n            if (PT_LOAD64 == get_te32(&phdr->p_type)) {\n                unsigned const  flags = get_te32(&phdr->p_flags);\n                unsigned       offset = get_te64(&phdr->p_offset);\n                if (!xct_off  // not shlib\n                  // new-style shlib: PT_LOAD[0] has symbol table\n                  // which must not be compressed, but also lacks PF_X\n                ||    (Elf64_Phdr::PF_X & flags)\n                  // Read-only, non-first PT_LOAD is _assumed_ to be compressible\n                ||  (!(Elf64_Phdr::PF_W & flags) && 0!=offset))\n                {\n                    ++npieces;  // will attempt compression of this PT_LOAD\n                }\n            }\n        }\n        uip->ui_total_passes += npieces;\n    }\n    int methods[256];\n    unsigned nmethods = prepareMethods(methods, ph.method, getCompressionMethods(M_ALL, ph.level));\n    if (1 < nmethods) { // Many are available, but we must choose only one\n        uip->ui_total_passes += 1;  // the batch for output\n        uip->ui_total_passes *= nmethods * (1+ nfilters);  // finding smallest total\n        PackHeader orig_ph = ph;\n        Filter orig_ft = ft;\n        unsigned max_offset = 0;\n        unsigned sz_best= ~0u;\n        int method_best = 0;\n        for (unsigned k = 0; k < nmethods; ++k) { // FIXME: parallelize; cost: working space\n            unsigned sz_this = 0;\n            Elf64_Phdr *phdr = phdri;\n            for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n                if (PT_LOAD64 == get_te32(&phdr->p_type)) {\n                    unsigned const  flags = get_te32(&phdr->p_flags);\n                    unsigned       offset = get_te64(&phdr->p_offset);\n                    unsigned       filesz = get_te64(&phdr->p_filesz);\n                    max_offset = UPX_MAX(max_offset, filesz + offset);\n                    if (!xct_off  // not shlib\n                      // new-style shlib: PT_LOAD[0] has symbol table\n                      // which must not be compressed, but also lacks PF_X\n                    ||    (Elf64_Phdr::PF_X & flags)\n                      // Read-only, non-first PT_LOAD is _assumed_ to be compressible\n                    ||  (!(Elf64_Phdr::PF_W & flags) && 0!=offset))\n                    {\n                        if (xct_off && 0==offset) { // old-style shlib\n                            offset  = xct_off;\n                            filesz -= xct_off;\n                        }\n                        fi->seek(offset, SEEK_SET);\n                        fi->readx(ibuf, filesz);\n                        ft = orig_ft;\n                        ph = orig_ph;\n                        ph.method = force_method(methods[k]);\n                        ph.u_len = filesz;\n                        compressWithFilters(&ft, OVERHEAD, NULL_cconf, 10, true);\n                        sz_this += ph.c_len;\n                    }\n                }\n            }\n            unsigned const sz_tail = file_size - max_offset;  // debuginfo, etc.\n            if (sz_tail) {\n                fi->seek(max_offset, SEEK_SET);\n                fi->readx(ibuf, sz_tail);\n                ft = orig_ft;\n                ph = orig_ph;\n                ph.method = force_method(methods[k]);\n                ph.u_len = sz_tail;\n                compressWithFilters(&ft, OVERHEAD, NULL_cconf, 10, true);\n                sz_this += ph.c_len;\n            }\n            // FIXME: loader size also depends on method\n            if (sz_best > sz_this) {\n                sz_best = sz_this;\n                method_best = methods[k];\n            }\n        }\n        ft = orig_ft;\n        ph = orig_ph;\n        ph.method = force_method(method_best);\n    }\n\n    note_size = 0;\n    Elf64_Phdr *phdr = phdri;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        if (PT_NOTE64 == get_te32(&phdr->p_type)) {\n            note_size += up4(get_te64(&phdr->p_filesz));\n        }\n    }\n    if (note_size) {\n        note_body.alloc(note_size);\n        note_size = 0;\n    }\n    phdr = phdri;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        unsigned const type = get_te32(&phdr->p_type);\n        if (PT_NOTE64 == type) {\n            unsigned const len = get_te64(&phdr->p_filesz);\n            fi->seek(get_te64(&phdr->p_offset), SEEK_SET);\n            fi->readx(&note_body[note_size], len);\n            note_size += up4(len);\n        }\n        if (PT_LOAD64 == type) {\n            unsigned x = get_te64(&phdr->p_align) >> lg2_page;\n            while (x>>=1) {\n                ++lg2_page;\n            }\n        }\n        if (PT_GNU_STACK64 == type) {\n            gnu_stack = phdr;\n        }\n    }\n    page_size =  1u  <<lg2_page;\n    page_mask = ~0ull<<lg2_page;\n\n    progid = 0;  // getRandomId();  not useful, so do not clutter\n    sz_elf_hdrs = sizeof(ehdri) + sz_phdrs;\n\n    // only execute if option present\n    if (opt->o_unix.preserve_build_id) {\n        // set this so we can use elf_find_section_name\n        e_shnum = get_te16(&ehdri.e_shnum);\n        MemBuffer mb_shdri;\n        if (!shdri) {\n            mb_shdri.alloc(e_shnum * sizeof(Elf64_Shdr));\n            shdri = (Elf64_Shdr *)mb_shdri.getVoidPtr();\n            e_shoff = get_te64(&ehdri.e_shoff);\n            fi->seek(e_shoff, SEEK_SET);\n            fi->readx(shdri, e_shnum * sizeof(Elf64_Shdr));\n        }\n        //set the shstrtab\n        sec_strndx = &shdri[get_te16(&ehdri.e_shstrndx)];\n\n        upx_uint64_t sh_size = get_te64(&sec_strndx->sh_size);\n        mb_shstrtab.alloc(sh_size); shstrtab = (char *)mb_shstrtab.getVoidPtr();\n        fi->seek(0,SEEK_SET);\n        fi->seek(sec_strndx->sh_offset,SEEK_SET);\n        fi->readx(mb_shstrtab, sh_size);\n\n        Elf64_Shdr const *buildid = elf_find_section_name(\".note.gnu.build-id\");\n        if (buildid) {\n            unsigned bid_sh_size = get_te32(&buildid->sh_size);\n            buildid_data.alloc(bid_sh_size);\n            buildid_data.clear();\n            fi->seek(0,SEEK_SET);\n            fi->seek(buildid->sh_offset,SEEK_SET);\n            fi->readx((void *)buildid_data, bid_sh_size);\n\n            o_elf_shnum = 3;\n            memset(&shdrout,0,sizeof(shdrout));\n\n            //setup the build-id\n            memcpy(&shdrout.shdr[1], buildid, sizeof(shdrout.shdr[1]));\n            set_te32(&shdrout.shdr[1].sh_name, 1);\n\n            //setup the shstrtab\n            memcpy(&shdrout.shdr[2], sec_strndx, sizeof(shdrout.shdr[2]));\n            set_te32(&shdrout.shdr[2].sh_name, 20);\n            set_te32(&shdrout.shdr[2].sh_size, 29); //size of our static shstrtab\n        }\n    }\n}\n\nvoid PackLinuxElf64amd::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_amd64_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\nvoid PackLinuxElf64arm::pack1(OutputFile *fo, Filter &ft)\n{\n    super::pack1(fo, ft);\n    if (0!=xct_off)  // shared library\n        return;\n    generateElfHdr(fo, stub_arm64_linux_elf_fold, getbrk(phdri, e_phnum) );\n}\n\n// Determine length of gap between PT_LOAD phdr[k] and closest PT_LOAD\n// which follows in the file (or end-of-file).  Optimize for common case\n// where the PT_LOAD are adjacent ascending by .p_offset.  Assume no overlap.\n\nunsigned PackLinuxElf32::find_LOAD_gap(\n    Elf32_Phdr const *const phdr,\n    unsigned const k,\n    unsigned const nph\n)\n{\n    if (!is_LOAD32(&phdr[k])) {\n        return 0;\n    }\n    unsigned const hi = get_te32(&phdr[k].p_offset) +\n                        get_te32(&phdr[k].p_filesz);\n    unsigned lo = ph.u_file_size;\n    if (lo < hi)\n        throwCantPack(\"bad input: PT_LOAD beyond end-of-file\");\n    unsigned j = k;\n    for (;;) { // circular search, optimize for adjacent ascending\n        ++j;\n        if (nph==j) {\n            j = 0;\n        }\n        if (k==j) {\n            break;\n        }\n        if (is_LOAD32(&phdr[j])) {\n            unsigned const t = get_te32(&phdr[j].p_offset);\n            if ((t - hi) < (lo - hi)) {\n                lo = t;\n                if (hi==lo) {\n                    break;\n                }\n            }\n        }\n    }\n    return lo - hi;\n}\n\nint PackLinuxElf32::pack2(OutputFile *fo, Filter &ft)\n{\n    Extent x;\n    unsigned k;\n    bool const is_shlib = (0!=xct_off);\n\n    // count passes, set ptload vars\n    uip->ui_total_passes = 0;\n    for (k = 0; k < e_phnum; ++k) {\n        if (is_LOAD32(&phdri[k])) {\n            uip->ui_total_passes++;\n            if (find_LOAD_gap(phdri, k, e_phnum)) {\n                uip->ui_total_passes++;\n            }\n        }\n    }\n    uip->ui_total_passes -= !!is_shlib;  // not .data of shlib\n\n    // compress extents\n    unsigned hdr_u_len = (is_shlib ? xct_off : (sizeof(Elf32_Ehdr) + sz_phdrs));\n\n    total_in =  (is_shlib ?           0 : xct_off);\n    total_out = (is_shlib ? sz_elf_hdrs : xct_off);\n\n    uip->ui_pass = 0;\n    ft.addvalue = 0;\n\n    unsigned nk_f = 0; unsigned xsz_f = 0;\n    for (k = 0; k < e_phnum; ++k)\n    if (is_LOAD32(&phdri[k])\n    &&  Elf32_Phdr::PF_X & get_te32(&phdri[k].p_flags)) {\n        unsigned xsz =     get_te32(&phdri[k].p_filesz);\n        if (xsz_f < xsz) {\n            xsz_f = xsz;\n            nk_f = k;\n        }\n    }\n    int nx = 0;\n    for (k = 0; k < e_phnum; ++k)\n    if (is_LOAD32(&phdri[k])) {\n        if (ft.id < 0x40) {\n            // FIXME: ??    ft.addvalue = phdri[k].p_vaddr;\n        }\n        x.offset = get_te32(&phdri[k].p_offset);\n        x.size   = get_te32(&phdri[k].p_filesz);\n        if (!is_shlib || hdr_u_len < (u32_t)x.size) {\n            if (0 == nx) { // 1st PT_LOAD32 must cover Ehdr at 0==p_offset\n                unsigned const delta = hdr_u_len;\n                if (ft.id < 0x40) {\n                    // FIXME: ??     ft.addvalue += asl_delta;\n                }\n                if ((off_t)delta == x.size) { // PT_LOAD[0] with ElfXX.Ehdr only\n                    // QBE backend - http://c9x.me/compile/\n                    hdr_u_len = 0;  // no fiddling necessary!\n                    // &ft arg to packExtent will be zero becaue (k != nk_f)\n                }\n                else {\n                    x.offset += delta;\n                    x.size   -= delta;\n                }\n            }\n            // compressWithFilters() always assumes a \"loader\", so would\n            // throw NotCompressible for small .data Extents, which PowerPC\n            // sometimes marks as PF_X anyway.  So filter only first segment.\n            if (k == nk_f || !is_shlib) {\n                packExtent(x,\n                    (k==nk_f ? &ft : nullptr ), fo, hdr_u_len);\n            }\n            else {\n                total_in += x.size;\n            }\n        }\n        else {\n                total_in += x.size;\n        }\n        hdr_u_len = 0;\n        ++nx;\n    }\n    sz_pack2a = fpad4(fo);  // MATCH01\n\n    // Accounting only; ::pack3 will do the compression and output\n    for (k = 0; k < e_phnum; ++k) {\n        total_in += find_LOAD_gap(phdri, k, e_phnum);\n    }\n\n    if (total_in != (u32_t)file_size)\n        throwEOFException();\n\n    return 0;  // omit end-of-compression bhdr for now\n}\n\n// Determine length of gap between PT_LOAD phdr[k] and closest PT_LOAD\n// which follows in the file (or end-of-file).  Optimize for common case\n// where the PT_LOAD are adjacent ascending by .p_offset.  Assume no overlap.\n\nunsigned PackLinuxElf64::find_LOAD_gap(\n    Elf64_Phdr const *const phdr,\n    unsigned const k,\n    unsigned const nph\n)\n{\n    if (PT_LOAD64!=get_te32(&phdr[k].p_type)) {\n        return 0;\n    }\n    unsigned const hi = get_te64(&phdr[k].p_offset) +\n                        get_te64(&phdr[k].p_filesz);\n    unsigned lo = ph.u_file_size;\n    if (lo < hi)\n        throwCantPack(\"bad input: PT_LOAD beyond end-of-file\");\n    unsigned j = k;\n    for (;;) { // circular search, optimize for adjacent ascending\n        ++j;\n        if (nph==j) {\n            j = 0;\n        }\n        if (k==j) {\n            break;\n        }\n        if (PT_LOAD64==get_te32(&phdr[j].p_type)) {\n            unsigned const t = get_te64(&phdr[j].p_offset);\n            if ((t - hi) < (lo - hi)) {\n                lo = t;\n                if (hi==lo) {\n                    break;\n                }\n            }\n        }\n    }\n    return lo - hi;\n}\n\nint PackLinuxElf64::pack2(OutputFile *fo, Filter &ft)\n{\n    Extent x;\n    unsigned k;\n    unsigned const is_asl = (!!opt->o_unix.android_shlib) << 1;  // bit 1\n    unsigned const is_shlib = (0!=xct_off) | is_asl;\n\n    // count passes, set ptload vars\n    uip->ui_total_passes = 0;\n    for (k = 0; k < e_phnum; ++k) {\n        if (PT_LOAD64==get_te32(&phdri[k].p_type)) {\n            if (!is_shlib) {\n                uip->ui_total_passes++;\n            }\n            else {\n                unsigned p_flags = get_te32(&phdri[k].p_flags);\n                if (Elf64_Phdr::PF_W & p_flags) {\n                    // rtld might write, so cannot compress\n                }\n                else {\n                    upx_uint64_t p_filesz = get_te64(&phdri[k].p_filesz);\n                    // First PT_LOAD (partial) only if has instructions\n                    if (k || xct_off < p_filesz) {\n                        uip->ui_total_passes++;\n                    }\n                }\n            }\n            if (find_LOAD_gap(phdri, k, e_phnum)) {\n                uip->ui_total_passes++;\n            }\n        }\n    }\n\n    // compress extents\n    unsigned hdr_u_len = sizeof(Elf64_Ehdr) + sz_phdrs;\n\n    total_in =  0;\n    total_out = 0;\n    uip->ui_pass = 0;\n    ft.addvalue = 0;\n\n    if (is_shlib) { // prepare to alter Phdrs and Shdrs\n        lowmem.alloc(xct_off + (!is_asl\n            ? 0\n            : e_shnum * sizeof(Elf64_Shdr)));\n        memcpy(lowmem, file_image, xct_off);  // android omits Shdr here\n\n        if (is_asl) { // Android shared library\n            sz_elf_hdrs = xct_off;\n            fo->write(lowmem, xct_off);  // < SHF_EXECINSTR (typ: in .plt or .init)\n            total_in  = xct_off;\n            total_out = xct_off;\n\n            asl_pack2_Shdrs(fo);\n        }\n    }\n    unsigned nk_f = 0; upx_uint64_t xsz_f = 0;\n    for (k = 0; k < e_phnum; ++k)\n    if (PT_LOAD64==get_te32(&phdri[k].p_type)\n    &&  Elf64_Phdr::PF_X & get_te64(&phdri[k].p_flags)) {\n        upx_uint64_t xsz = get_te64(&phdri[k].p_filesz);\n        if (xsz_f < xsz) {\n            xsz_f = xsz;\n            nk_f = k;\n        }\n    }\n    int nx = 0;\n    for (k = 0; k < e_phnum; ++k)\n    if (PT_LOAD64==get_te32(&phdri[k].p_type)) {\n        if (ft.id < 0x40) {\n            // FIXME: ??    ft.addvalue = phdri[k].p_vaddr;\n        }\n        x.offset = get_te64(&phdri[k].p_offset);\n        x.size   = get_te64(&phdri[k].p_filesz);\n        if (is_shlib) {\n            if (x.offset <= xct_off) { // first PT_LOAD\n                unsigned const len = umin(x.size, xct_off - x.offset);\n                if (len && !is_asl) { // asl_pack2_Shdrs aleady handled\n                    fi->seek(x.offset, SEEK_SET);\n                    fi->readx(ibuf, x.size);\n                    total_in += len;\n\n                    fo->seek(x.offset, SEEK_SET);\n                    fo->write(ibuf, len);\n                    total_out += len;\n                }\n                if (len != x.size) {\n                    linfo.l_checksum = 0;\n                    linfo.l_magic = UPX_MAGIC_LE32;\n                    set_le16(&linfo.l_lsize, lsize);  // preliminary (0)\n                    linfo.l_version = (unsigned char)ph.version;\n                    linfo.l_format =  (unsigned char)ph.format;\n                    linfo_off = fo->tell();\n                    fo->write(&linfo, sizeof(linfo));\n                    total_out += sizeof(linfo);\n                    overlay_offset = total_out;\n\n                    p_info hbuf;\n                    set_te32(&hbuf.p_progid, 0);\n                    set_te32(&hbuf.p_filesize, file_size);\n                    set_te32(&hbuf.p_blocksize, blocksize);\n                    fo->write(&hbuf, sizeof(hbuf));\n                    total_out += sizeof(p_info);\n\n                    x.offset = 0;\n                    x.size = sz_elf_hdrs;\n                    if (is_asl) {\n                        x.size = hdr_u_len;\n                    }\n                    unsigned in_size = x.size;\n                    packExtent(x, nullptr, fo, 0, 0, true);\n                    total_in -= in_size;\n\n                    // The rest of first PT_LOAD (above xct_off)\n                    x.offset = xct_off;\n                    x.size = get_te64(&phdri[k].p_filesz) - len;\n                    packExtent(x, &ft, fo, 0, 0, true);\n                }\n            }\n            else {\n                if (!(Elf64_Phdr::PF_W & get_te64(&phdri[k].p_flags))) {\n                    // Read-only PT_LOAD, assume not written by relocations.\n                    // Also assume not the source for R_*_COPY relocation,\n                    // therefore compress it.\n                    packExtent(x, &ft, fo, 0, 0, true);\n                    // De-compressing will re-create it, but otherwise ignore it.\n                    Elf64_Phdr *phdro = (Elf64_Phdr *)(1+ (Elf64_Ehdr *)&lowmem[0]);\n                    set_te32(&phdro[k].p_type, Elf64_Phdr::PT_NULL);\n                }\n                else {\n                    // Read-write PT_LOAD.\n                    // rtld might relocate, so we cannot compress.\n                    // (Could compress if not relocated; complicates run-time.)\n                    // Postpone writing until \"slide\", but account for its size.\n                    total_in +=  x.size;\n                }\n            }\n        }\n        else  // main program, not shared library\n        if (hdr_u_len <= (u64_t)x.size) {\n            if (0 == nx) { // 1st PT_LOAD64 must cover Ehdr at 0==p_offset\n                unsigned const delta = hdr_u_len;\n                if (ft.id < 0x40) {\n                    // FIXME: ??     ft.addvalue += asl_delta;\n                }\n                if ((off_t)delta == x.size) { // PT_LOAD[0] with ElfXX.Ehdr only\n                    // QBE backend - http://c9x.me/compile/\n                    hdr_u_len = 0;  // no fiddling necessary!\n                    // &ft arg to packExtent will be zero becaue (k != nk_f)\n                }\n                else {\n                    total_in += delta - hdr_u_len;\n                    x.offset += delta;\n                    x.size   -= delta;\n                }\n            }\n            // compressWithFilters() always assumes a \"loader\", so would\n            // throw NotCompressible for small .data Extents, which PowerPC\n            // sometimes marks as PF_X anyway.  So filter only first segment.\n            if (k == nk_f || !is_shlib) {\n                packExtent(x,\n                    (k==nk_f ? &ft : nullptr ), fo, hdr_u_len, 0, true);\n            }\n            else {\n                total_in += x.size;\n            }\n        }\n        else {\n                total_in += x.size;\n        }\n        hdr_u_len = 0;\n        ++nx;\n    }\n    sz_pack2a = fpad4(fo);  // MATCH01\n\n    // Accounting only; ::pack3 will do the compression and output\n    for (k = 0; k < e_phnum; ++k) {\n        total_in += find_LOAD_gap(phdri, k, e_phnum);\n    }\n\n    if (total_in != (u32_t)file_size)\n        throwEOFException();\n\n    return 0;  // omit end-of-compression bhdr for now\n}\n\n// Filter 0x50, 0x51 assume HostPolicy::isLE\nstatic const int *\nARM_getFilters(bool const isBE)\n{\n    static const int f50[] = { 0x50, FT_END };\n    static const int f51[] = { 0x51, FT_END };\n    if (isBE)\n        return f51;\n    return f50;\n}\n\nconst int *\nPackLinuxElf32armBe::getFilters() const\n{\n    return ARM_getFilters(true);\n}\n\nconst int *\nPackLinuxElf32armLe::getFilters() const\n{\n    return ARM_getFilters(false);\n}\n\nconst int *\nPackLinuxElf32mipseb::getFilters() const\n{\n    static const int f_none[] = { FT_END };\n    return f_none;\n}\n\nconst int *\nPackLinuxElf32mipsel::getFilters() const\n{\n    static const int f_none[] = { FT_END };\n    return f_none;\n}\n\n// October 2011: QNX 6.3.0 has no unique signature?\nint PackLinuxElf32::ARM_is_QNX(void)\n{\n    if (Elf32_Ehdr::EM_ARM==get_te16(&ehdri.e_machine)\n    &&  Elf32_Ehdr::ELFDATA2MSB== ehdri.e_ident[Elf32_Ehdr::EI_DATA]\n    &&  Elf32_Ehdr::ELFOSABI_ARM==ehdri.e_ident[Elf32_Ehdr::EI_OSABI]\n    &&  0x100000==(page_mask & get_te32(&phdri[0].p_vaddr))) {\n        Elf32_Phdr const *phdr = phdri;\n        for (int j = get_te16(&ehdri.e_phnum); --j>=0; ++phdr) {\n            if (Elf32_Phdr::PT_INTERP==get_te32(&phdr->p_type)) {\n                char interp[64];\n                unsigned const sz_interp = get_te32(&phdr->p_filesz);\n                unsigned const pos_interp = get_te32(&phdr->p_offset);\n                if (sz_interp <= sizeof(interp)\n                &&  (sz_interp + pos_interp) <= (unsigned)file_size) {\n                    fi->seek(pos_interp, SEEK_SET);\n                    fi->readx(interp, sz_interp);\n                    for (int k = sz_interp - 5; k>=0; --k) {\n                        if (0==memcmp(\"ldqnx\", &interp[k], 5))\n                            return 1;\n                    }\n                }\n            }\n        }\n    }\n    return 0;\n}\n\nvoid PackLinuxElf32::ARM_defineSymbols(Filter const *ft)\n{\n    PackLinuxElf32::defineSymbols(ft);\n\n#define MAP_PRIVATE      2     /* UNIX standard */\n#define MAP_FIXED     0x10     /* UNIX standard */\n#define MAP_ANONYMOUS 0x20     /* UNIX standard */\n#define MAP_PRIVANON     3     /* QNX anonymous private memory */\n    unsigned mflg = MAP_PRIVATE | MAP_ANONYMOUS;\n    if (ARM_is_QNX())\n        mflg = MAP_PRIVANON;\n    linker->defineSymbol(\"MFLG\", mflg);\n}\n\nvoid PackLinuxElf32armLe::defineSymbols(Filter const *ft)\n{\n    ARM_defineSymbols(ft);\n}\n\nvoid PackLinuxElf32armBe::defineSymbols(Filter const *ft)\n{\n    ARM_defineSymbols(ft);\n}\n\nvoid PackLinuxElf64arm::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf64::defineSymbols(ft);\n\n#define MAP_PRIVATE      2     /* UNIX standard */\n#define MAP_FIXED     0x10     /* UNIX standard */\n#define MAP_ANONYMOUS 0x20     /* UNIX standard */\n#define MAP_PRIVANON     3     /* QNX anonymous private memory */\n    unsigned mflg = MAP_PRIVATE | MAP_ANONYMOUS;\n    //if (ARM_is_QNX())\n    //    mflg = MAP_PRIVANON;\n    linker->defineSymbol(\"MFLG\", mflg);\n}\n\nvoid PackLinuxElf32mipseb::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf32::defineSymbols(ft);\n}\n\nvoid PackLinuxElf32mipsel::defineSymbols(Filter const *ft)\n{\n    PackLinuxElf32::defineSymbols(ft);\n}\n\nvoid PackLinuxElf32::pack4(OutputFile *fo, Filter &ft)\n{\n    overlay_offset = xct_off ? xct_off : (sz_elf_hdrs + sizeof(linfo));\n\n    if (opt->o_unix.preserve_build_id) {\n        // calc e_shoff here and write shdrout, then o_shstrtab\n        //NOTE: these are pushed last to ensure nothing is stepped on\n        //for the UPX structure.\n        unsigned const len = fpad4(fo);\n        set_te32(&elfout.ehdr.e_shoff,len);\n\n        int const ssize = sizeof(shdrout);\n\n        shdrout.shdr[2].sh_offset = len+ssize;\n        shdrout.shdr[1].sh_offset = shdrout.shdr[2].sh_offset+shdrout.shdr[2].sh_size;\n\n        fo->write(&shdrout, ssize);\n\n        fo->write(o_shstrtab,shdrout.shdr[2].sh_size);\n        fo->write(buildid_data,shdrout.shdr[1].sh_size);\n    }\n\n    // Cannot pre-round .p_memsz.  If .p_filesz < .p_memsz, then kernel\n    // tries to make .bss, which requires PF_W.\n    // But strict SELinux (or PaX, grSecurity) disallows PF_W with PF_X.\n    set_te32(&elfout.phdr[C_TEXT].p_filesz, sz_pack2 + lsize);\n              elfout.phdr[C_TEXT].p_memsz = elfout.phdr[C_TEXT].p_filesz;\n    super::pack4(fo, ft);  // write PackHeader and overlay_offset\n\n    fo->seek(0, SEEK_SET);\n    if (0!=xct_off) {  // shared library\n        { // Shouldn't this special case be handled earlier?\n            if (overlay_offset < xct_off) {\n                Elf32_Phdr *phdro = (Elf32_Phdr *)(&lowmem[sizeof(Elf32_Ehdr)]);\n                set_te32(&phdro->p_flags, Elf32_Phdr::PF_X | get_te32(&phdro->p_flags));\n            }\n        }\n        fo->rewrite(&lowmem[0], sizeof(ehdri) + e_phnum * sizeof(*phdri));\n        fo->seek(sz_elf_hdrs, SEEK_SET);\n        fo->rewrite(&linfo, sizeof(linfo));\n\n        if (jni_onload_va) {\n            unsigned tmp = sz_pack2 + get_te32(&elfout.phdr[C_TEXT].p_vaddr);\n            tmp |= (Elf32_Ehdr::EM_ARM==e_machine);  // THUMB mode\n            set_te32(&tmp, tmp);\n            fo->seek(ptr_udiff_bytes(&jni_onload_sym->st_value, file_image), SEEK_SET);\n            fo->rewrite(&tmp, sizeof(tmp));\n        }\n    }\n    else {\n        unsigned const reloc = get_te32(&elfout.phdr[C_TEXT].p_vaddr);\n        Elf32_Phdr *phdr = &elfout.phdr[C_NOTE];\n        unsigned const o_phnum = get_te16(&elfout.ehdr.e_phnum);\n        for (unsigned j = 2; j < o_phnum; ++j, ++phdr) {\n            if (PT_NOTE32 == get_te32(&phdr->p_type)) {\n                set_te32(            &phdr->p_vaddr,\n                    reloc + get_te32(&phdr->p_vaddr));\n                set_te32(            &phdr->p_paddr,\n                    reloc + get_te32(&phdr->p_paddr));\n            }\n        }\n        fo->rewrite(&elfout, sizeof(Elf32_Phdr) * o_phnum + sizeof(Elf32_Ehdr));\n        fo->seek(sz_elf_hdrs, SEEK_SET);  // skip over PT_NOTE bodies, if any\n        fo->rewrite(&linfo, sizeof(linfo));\n    }\n}\n\nvoid PackLinuxElf64::pack4(OutputFile *fo, Filter &ft)\n{\n    if (!xct_off) {\n        overlay_offset = sz_elf_hdrs + sizeof(linfo);\n    }\n\n    if (opt->o_unix.preserve_build_id) {\n        // calc e_shoff here and write shdrout, then o_shstrtab\n        //NOTE: these are pushed last to ensure nothing is stepped on\n        //for the UPX structure.\n        unsigned const len = fpad4(fo);\n        set_te64(&elfout.ehdr.e_shoff,len);\n\n        int const ssize = sizeof(shdrout);\n\n        shdrout.shdr[2].sh_offset = len+ssize;\n        shdrout.shdr[1].sh_offset = shdrout.shdr[2].sh_offset+shdrout.shdr[2].sh_size;\n\n        fo->write(&shdrout, ssize);\n\n        fo->write(o_shstrtab,shdrout.shdr[2].sh_size);\n        fo->write(buildid_data,shdrout.shdr[1].sh_size);\n    }\n\n    // Cannot pre-round .p_memsz.  If .p_filesz < .p_memsz, then kernel\n    // tries to make .bss, which requires PF_W.\n    // But strict SELinux (or PaX, grSecurity) disallows PF_W with PF_X.\n    set_te64(&elfout.phdr[C_TEXT].p_filesz, sz_pack2 + lsize);\n              elfout.phdr[C_TEXT].p_memsz = elfout.phdr[C_TEXT].p_filesz;\n    super::pack4(fo, ft);  // write PackHeader and overlay_offset\n\n    fo->seek(0, SEEK_SET);\n    if (0!=xct_off) {  // shared library\n        { // Shouldn't this special case be handled earlier?\n            if (overlay_offset < xct_off) {\n                Elf64_Phdr *phdro = (Elf64_Phdr *)(&lowmem[sizeof(Elf64_Ehdr)]);\n                set_te64(&phdro->p_flags, Elf64_Phdr::PF_X | get_te64(&phdro->p_flags));\n            }\n        }\n        fo->rewrite(&lowmem[0], sizeof(ehdri) + e_phnum * sizeof(Elf64_Phdr));\n        //fo->seek(xct_off, SEEK_SET);  // FIXME\n        //fo->rewrite(&linfo, sizeof(linfo));\n        fo->seek(linfo_off, SEEK_SET);\n        fo->rewrite(&linfo, sizeof(linfo));  // duplicate?\n    }\n    else {\n        if (PT_NOTE64 == get_te64(&elfout.phdr[C_NOTE].p_type)) {\n            upx_uint64_t const reloc = get_te64(&elfout.phdr[C_TEXT].p_vaddr);\n            set_te64(            &elfout.phdr[C_NOTE].p_vaddr,\n                reloc + get_te64(&elfout.phdr[C_NOTE].p_vaddr));\n            set_te64(            &elfout.phdr[C_NOTE].p_paddr,\n                reloc + get_te64(&elfout.phdr[C_NOTE].p_paddr));\n            fo->rewrite(&elfout, sz_elf_hdrs);\n            // FIXME   fo->rewrite(&elfnote, sizeof(elfnote));\n        }\n        else {\n            fo->rewrite(&elfout, sz_elf_hdrs);\n        }\n        fo->rewrite(&linfo, sizeof(linfo));\n    }\n}\n\nvoid\nPackLinuxElf32::unRel32(\n    unsigned dt_rel,\n    Elf32_Rel *rel0,\n    unsigned relsz,\n    MemBuffer &ptload1,\n    unsigned const load_off,\n    OutputFile *fo\n)\n{\n    Elf32_Rel *rel = rel0;\n    for (int k = relsz / sizeof(Elf32_Rel); --k >= 0; ++rel) {\n        unsigned r_offset = get_te32(&rel->r_offset);\n        unsigned r_info   = get_te32(&rel->r_info);\n        unsigned r_type = ELF32_R_TYPE(r_info);\n        if (xct_off <= r_offset) {\n            set_te32(&rel->r_offset, r_offset - asl_delta);\n        }\n        if (Elf32_Ehdr::EM_ARM == e_machine) {\n            if (R_ARM_RELATIVE == r_type) {\n                unsigned d = r_offset - load_off - asl_delta;\n                unsigned w = get_te32(&ptload1[d]);\n                if (xct_off <= w) {\n                    set_te32(&ptload1[d], w - asl_delta);\n                }\n            }\n            if (R_ARM_JUMP_SLOT == r_type) {\n                ++n_jmp_slot;\n                // .rel.plt contains offset of the \"first time\" target\n                unsigned d = r_offset - load_off - asl_delta;\n                if (plt_off > d) {\n                    plt_off = d;\n                }\n                unsigned w = get_te32(&ptload1[d]);\n                if (xct_off <= w) {\n                    set_te32(&ptload1[d], w - asl_delta);\n                }\n            }\n        }\n    }\n    fo->seek(dt_rel, SEEK_SET);\n    fo->rewrite(rel0, relsz);\n}\n\nvoid\nPackLinuxElf64::unRela64(\n    upx_uint64_t dt_rela,\n    Elf64_Rela *rela0,\n    unsigned relasz,\n    MemBuffer &ptload1,\n    upx_uint64_t const load_off,\n    upx_uint64_t old_dtinit,\n    OutputFile *fo\n)\n{\n    Elf64_Rela *rela = rela0;\n    for (int k = relasz / sizeof(Elf64_Rela); --k >= 0; ++rela) {\n        upx_uint64_t r_addend = get_te64(&rela->r_addend);\n        if (xct_off <= r_addend) {\n            r_addend -= asl_delta;\n            set_te64(&rela->r_addend, r_addend);\n        }\n\n        upx_uint64_t r_offset = get_te64(&rela->r_offset);\n        if (xct_off <= r_offset) {\n            r_offset -= asl_delta;\n            set_te64(&rela->r_offset, r_offset);\n        }\n\n        upx_uint64_t r_info   = get_te64(&rela->r_info);\n        unsigned r_type = ELF64_R_TYPE(r_info);\n        if (Elf64_Ehdr::EM_AARCH64 == e_machine) {\n            if (R_AARCH64_RELATIVE == r_type) {\n                if (old_dtinit == r_addend) {\n                    set_te64(&ptload1[r_offset - load_off], r_addend);\n                }\n            }\n            if (R_AARCH64_JUMP_SLOT == r_type) {\n                ++n_jmp_slot;\n                // .rela.plt contains offset of the \"first time\" target\n                upx_uint64_t d = r_offset - load_off;\n                if (plt_off > d) {\n                    plt_off = d;\n                }\n                upx_uint64_t w = get_te64(&ptload1[d]);\n                if (xct_off <= w) {\n                    set_te64(&ptload1[d], w - asl_delta);\n                }\n            }\n        }\n    }\n    fo->seek(dt_rela, SEEK_SET);\n    fo->rewrite(rela0, relasz);\n}\n\n// File layout of compressed .so (new-style: 3 or 4 PT_LOAD) shared library:\n// 1. new Elf headers: Ehdr, PT_LOAD (r-x), PT_LOAD (rw-, if any), non-PT_LOAD Phdrs\n// 2. Space for (original - 2) PT_LOAD Phdr\n// 3. Remaining original contents of file below xct_off\n// xct_off: (&lowest eXecutable Shdr section; in original PT_LOAD[0] or [1])\n// 4. l_info (12 bytes)\n// overlay_offset:\n// 5. p_info (12 bytes)\n// 6. compressed original Elf headers (prefixed by b_info as usual)\n// 7. compressed remainder of PT_LOAD above xct_off\n// 8. compressed read-only PT_LOAD above xct_off (if any)\n// 9. uncompressed Read-Write PT_LOAD (slide down N pages)\n// 10. int[6] tables for UPX runtime de-compressor\n// (new) DT_INIT:\n// 11. UPX runtime de-compressing loader\n// 12. compressed gaps between PT_LOADs (and EOF) above xct_off\n// 13. 32-byte pack header\n// 14. 4-byte overlay offset\n\nvoid PackLinuxElf64::un_shlib_1(\n    OutputFile *const fo,\n    MemBuffer &o_elfhdrs,\n    unsigned &c_adler,\n    unsigned &u_adler,\n    Elf64_Phdr const *const dynhdr,\n    unsigned const orig_file_size,\n    unsigned const szb_info\n)\n{\n    // Below xct_off is not compressed (for benefit of rtld.)\n    fi->seek(0, SEEK_SET);\n    unsigned const limit_dynhdr = get_te64(&dynhdr->p_offset) + get_te64(&dynhdr->p_filesz);\n    fi->readx(ibuf, limit_dynhdr);\n    overlay_offset -= sizeof(linfo);\n    loader_offset = 0;\n    xct_off = overlay_offset;\n    e_shoff = get_te64(&ehdri.e_shoff);\n    if (e_shoff && e_shnum\n    &&  (e_shoff + sizeof(Elf64_Shdr) * e_shnum) <= limit_dynhdr) { // --android-shlib\n        ibuf.subref(\"bad .e_shoff %#lx for %#lx\", e_shoff, sizeof(Elf64_Shdr) * e_shnum);\n        shdri = (Elf64_Shdr /*const*/ *)ibuf.subref(\n            \"bad Shdr table\", e_shoff, sizeof(Elf64_Shdr)*e_shnum);\n        upx_uint64_t xct_off2 = get_te64(&shdri->sh_offset);\n        if (e_shoff == xct_off2) {\n            xct_off = e_shoff;\n        }\n        // un-Relocate dynsym (DT_SYMTAB) which is below xct_off\n        dynstr = (char const *)elf_find_dynamic(Elf64_Dyn::DT_STRTAB);\n        sec_dynsym = elf_find_section_type(Elf64_Shdr::SHT_DYNSYM);\n        if (sec_dynsym) {\n            upx_uint64_t const off_dynsym = get_te64(&sec_dynsym->sh_offset);\n            upx_uint64_t const sz_dynsym  = get_te64(&sec_dynsym->sh_size);\n            if (orig_file_size < sz_dynsym\n            ||  orig_file_size < off_dynsym\n            || (orig_file_size - off_dynsym) < sz_dynsym) {\n                throwCantUnpack(\"bad SHT_DYNSYM\");\n            }\n            Elf64_Sym *const sym0 = (Elf64_Sym *)ibuf.subref(\n                \"bad dynsym\", off_dynsym, sz_dynsym);\n            Elf64_Sym *sym = sym0;\n            for (int j = sz_dynsym / sizeof(Elf64_Sym); --j>=0; ++sym) {\n                upx_uint64_t symval = get_te64(&sym->st_value);\n                unsigned symsec = get_te16(&sym->st_shndx);\n                if (Elf64_Sym::SHN_UNDEF != symsec\n                &&  Elf64_Sym::SHN_ABS   != symsec\n                &&  xct_off <= symval) {\n                    set_te64(&sym->st_value, symval - asl_delta);\n                }\n                if (Elf64_Sym::SHN_ABS == symsec && xct_off <= symval) {\n                    adjABS(sym, 0u - asl_delta);\n                }\n            }\n        }\n    }\n\n    // Decompress first Extent.  Old style covers [0, xct_off)\n    // which includes rtld constant data and eXecutable app code below DT_INIT.\n    // In old style, the first compressed Extent is redundant\n    // except for the compressed original Elf headers.\n    // New style covers just Elf headers: the rest below xct_off is\n    // rtld constant data: DT_*HASH, DT_SYMTAB, DT_STRTAB, etc.\n    // New style puts eXecutable app code in second PT_LOAD\n    // in order to mark Elf headers and rtld data as non-eXecutable.\n    fi->seek(xct_off, SEEK_SET);\n    struct {\n        struct l_info l;\n        struct p_info p;\n        struct b_info b;\n    } hdr;\n    fi->readx(&hdr, sizeof(hdr));\n    fi->seek(-(off_t)sizeof(struct b_info), SEEK_CUR);\n    if (hdr.l.l_magic != UPX_MAGIC_LE32\n    ||  hdr.l.l_lsize != (unsigned)lsize\n    ||  hdr.p.p_filesize != ph.u_file_size) {\n        throwCantUnpack(\"corrupt l_info/p_info\");\n    }\n    ph.c_len = get_te32(&hdr.b.sz_cpr);\n    ph.u_len = get_te32(&hdr.b.sz_unc);\n\n    unpackExtent(ph.u_len, fo,\n        c_adler, u_adler, false, szb_info);\n\n    // FIXME: what if no output file?  test mode (\"-t\") or list mode (\"-l\")\n    if (fo) {\n        InputFile u_fi;\n        // Recover original Elf headers from current output file\n        u_fi.open(fo->getName(), 0);\n        u_fi.readx((void *)o_elfhdrs,o_elfhdrs.getSize());\n        u_fi.close();\n\n        // Re-generate unmodified rtld data below xct_off\n        fo->write(&ibuf[ph.u_len], xct_off - ph.u_len);\n    }\n\n    Elf64_Phdr const *o_phdr = (Elf64_Phdr const *)(1+ (Elf64_Ehdr const *)(void const *)o_elfhdrs);\n    // Handle compressed PT_LOADs (must not have PF_W)\n    for (unsigned j = 0; j < e_phnum; ++j, ++o_phdr) {\n        unsigned type = get_te32(&o_phdr->p_type);\n        unsigned flags = get_te32(&o_phdr->p_flags);\n        if (PT_LOAD64 != type || Elf64_Phdr::PF_W & flags) {\n            continue;\n        }\n        unsigned vaddr = get_te64(&o_phdr->p_vaddr);\n        if (xct_off <= vaddr) { // not first PT_LOAD must position its output\n            if (fo) {\n                unsigned o_offset = get_te64(&o_phdr->p_offset);\n                fo->seek(o_offset, SEEK_SET);\n            }\n        }\n        // Peek at b_info to find sizes\n        fi->readx(&hdr.b, sizeof(hdr.b));\n        fi->seek(-(off_t)sizeof(struct b_info), SEEK_CUR);\n        ph.c_len = get_te32(&hdr.b.sz_cpr);\n        ph.u_len = get_te32(&hdr.b.sz_unc);\n        unpackExtent(ph.u_len, fo, c_adler, u_adler, false, szb_info);\n    }\n    funpad4(fi);\n    loader_offset = fi->tell();\n\n    // Handle PT_LOAD with PF_W: writeable, so not compressed.  \"Slide\"\n    o_phdr = (Elf64_Phdr const *)(1+ (Elf64_Ehdr const *)(void const *)o_elfhdrs);\n    Elf64_Phdr const *i_phdr = phdri;\n    for (unsigned j = 0; j < e_phnum; ++j, ++o_phdr, ++i_phdr) {\n        unsigned type = get_te32(&o_phdr->p_type);\n        unsigned flags = get_te32(&o_phdr->p_flags);\n        if (PT_LOAD64 != type || !(Elf64_Phdr::PF_W & flags)) {\n            continue;\n        }\n        unsigned filesz = get_te64(&o_phdr->p_filesz);\n        unsigned o_offset = get_te64(&o_phdr->p_offset);\n        unsigned i_offset = get_te64(&i_phdr->p_offset);\n        fi->seek(i_offset, SEEK_SET);\n        fi->readx(ibuf, filesz);\n        total_in += filesz;\n        if (fo) {\n            fo->seek(o_offset, SEEK_SET);\n            fo->write(ibuf, filesz);\n        }\n        total_out = filesz + o_offset;  // high-water mark\n    }\n\n    // Gaps between PT_LOAD will be handled by ::unpack()\n\n    // position fi at loader offset\n    fi->seek(loader_offset, SEEK_SET);\n}\n\nvoid PackLinuxElf64::un_DT_INIT(\n    unsigned old_dtinit,\n    Elf64_Phdr const *const phdro,\n    Elf64_Phdr const *const dynhdr,  // in phdri\n    OutputFile *fo,\n    unsigned is_asl\n)\n{\n    // DT_INIT must be restored.\n    // If android_shlib, then the asl_delta relocations must be un-done.\n    upx_uint64_t dt_pltrelsz(0), dt_jmprel(0);\n    upx_uint64_t dt_relasz(0), dt_rela(0);\n    upx_uint64_t const dyn_len = get_te64(&dynhdr->p_filesz);\n    upx_uint64_t const dyn_off = get_te64(&dynhdr->p_offset);\n    if ((unsigned long)file_size < (dyn_len + dyn_off)) {\n        char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad PT_DYNAMIC .p_filesz %#lx\", (long unsigned)dyn_len);\n        throwCantUnpack(msg);\n    }\n    fi->seek(dyn_off, SEEK_SET);\n    fi->readx(ibuf, dyn_len);\n    Elf64_Dyn *dyn = (Elf64_Dyn *)(void *)ibuf;\n    dynseg = dyn; invert_pt_dynamic(dynseg,\n        umin(dyn_len, file_size - dyn_off));\n    for (unsigned j2= 0; j2 < dyn_len; ++dyn, j2 += sizeof(*dyn)) {\n        upx_uint64_t const tag = get_te64(&dyn->d_tag);\n        upx_uint64_t       val = get_te64(&dyn->d_val);\n        if (is_asl) switch (tag) {\n        case Elf64_Dyn::DT_RELASZ:   { dt_relasz   = val; } break;\n        case Elf64_Dyn::DT_RELA:     { dt_rela     = val; } break;\n        case Elf64_Dyn::DT_PLTRELSZ: { dt_pltrelsz = val; } break;\n        case Elf64_Dyn::DT_JMPREL:   { dt_jmprel   = val; } break;\n\n        case Elf64_Dyn::DT_PLTGOT:\n        case Elf64_Dyn::DT_PREINIT_ARRAY:\n        case Elf64_Dyn::DT_INIT_ARRAY:\n        case Elf64_Dyn::DT_FINI_ARRAY:\n        case Elf64_Dyn::DT_FINI: {\n            set_te64(&dyn->d_val, val - asl_delta);\n        }; break;\n        } // end switch() on tag when is_asl\n        if (upx_dt_init == tag) {\n            if (Elf64_Dyn::DT_INIT == tag) {\n                set_te64(&dyn->d_val, old_dtinit);\n                if (!old_dtinit) { // compressor took the slot\n                    dyn->d_tag = Elf64_Dyn::DT_NULL;\n                    dyn->d_val = 0;\n                }\n            }\n            else if (Elf64_Dyn::DT_INIT_ARRAY    == tag\n            ||       Elf64_Dyn::DT_PREINIT_ARRAY == tag) {\n                // The slot must have a R_*_RELATIVE relocation (is_shlib,\n                // after all), but ElfXX_Rela ignores the initial contents!\n                // So changing the value will get ignored.  Do it anyway.\n                // FIXME: we must fix the Rela ?\n                Elf64_Phdr const *phdr = phdro;\n                for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n                    upx_uint64_t vaddr = get_te64(&phdr->p_vaddr);\n                    upx_uint64_t filesz = get_te64(&phdr->p_filesz);\n                    if ((val - vaddr) < filesz) {\n                        upx_uint64_t offset = get_te64(&phdr->p_offset);\n                        upx_uint64_t oldval;\n                        // Counter-act unRel64 if asl_delta\n                        set_te64(&oldval, old_dtinit + (is_asl ? asl_delta : 0));\n                        // FIXME? the in-memory copy?\n                        if (fo) {\n                            fo->seek((val - vaddr) + offset, SEEK_SET);\n                            fo->write(&oldval, sizeof(oldval));\n                        }\n                        break;\n                    }\n                }\n            }\n        }\n    }\n    if (fo) { // Write updated dt_*.val\n        upx_uint64_t dyn_offo = get_te64(&phdro[dynhdr - phdri].p_offset);\n        fo->seek(dyn_offo, SEEK_SET);\n        fo->rewrite(ibuf, dyn_len);\n    }\n    if (is_asl) {\n        lowmem.alloc(xct_off);\n        fi->seek(0, SEEK_SET);\n        fi->read(lowmem, xct_off);  // contains relocation tables\n        if (dt_relasz && dt_rela) {\n            Elf64_Rela *const rela0 = (Elf64_Rela *)lowmem.subref(\n                \"bad Rela offset\", dt_rela, dt_relasz);\n            unRela64(dt_rela, rela0, dt_relasz, ibuf, load_va, old_dtinit, fo);\n        }\n        if (dt_pltrelsz && dt_jmprel) { // FIXME:  overlap w/ DT_REL ?\n            Elf64_Rela *const jmp0 = (Elf64_Rela *)lowmem.subref(\n                \"bad Jmprel offset\", dt_jmprel, dt_pltrelsz);\n            unRela64(dt_jmprel, jmp0, dt_pltrelsz, ibuf, load_va, old_dtinit, fo);\n        }\n        // Modified relocation tables are re-written by unRela64\n    }\n}\n\nvoid PackLinuxElf64::unpack(OutputFile *fo)\n{\n    if (e_phoff != sizeof(Elf64_Ehdr)) {// Phdrs not contiguous with Ehdr\n        throwCantUnpack(\"bad e_phoff\");\n    }\n    unsigned const c_phnum = get_te16(&ehdri.e_phnum);\n    unsigned u_phnum = 0;\n    upx_uint64_t old_dtinit = 0;\n    unsigned is_asl = 0;  // is Android Shared Library\n\n    unsigned szb_info = sizeof(b_info);\n    {\n        upx_uint64_t const e_entry = get_te64(&ehdri.e_entry);\n        if (e_entry < 0x401180\n        &&  get_te16(&ehdri.e_machine)==Elf64_Ehdr::EM_386) { /* old style, 8-byte b_info */\n            szb_info = 2*sizeof(unsigned);\n        }\n    }\n\n    fi->seek(overlay_offset - sizeof(l_info), SEEK_SET);\n    fi->readx(&linfo, sizeof(linfo));\n    lsize = get_te16(&linfo.l_lsize);\n    if (UPX_MAGIC_LE32 != get_le32(&linfo.l_magic)) {\n        throwCantUnpack(\"l_info corrupted\");\n    }\n    p_info hbuf;  fi->readx(&hbuf, sizeof(hbuf));\n    unsigned orig_file_size = get_te32(&hbuf.p_filesize);\n    blocksize = get_te32(&hbuf.p_blocksize);\n    if ((u32_t)file_size > orig_file_size || blocksize > orig_file_size\n        || !mem_size_valid(1, blocksize, OVERHEAD))\n        throwCantUnpack(\"p_info corrupted\");\n\n    ibuf.alloc(blocksize + OVERHEAD);\n    b_info bhdr; memset(&bhdr, 0, sizeof(bhdr));\n    fi->readx(&bhdr, szb_info);\n    ph.u_len = get_te32(&bhdr.sz_unc);\n    ph.c_len = get_te32(&bhdr.sz_cpr);\n    if (ph.c_len > (unsigned)file_size || ph.c_len == 0 || ph.u_len == 0\n    ||  ph.u_len > orig_file_size)\n        throwCantUnpack(\"b_info corrupted\");\n    ph.filter_cto = bhdr.b_cto8;\n\n    MemBuffer u(ph.u_len);\n    Elf64_Ehdr *const ehdr = (Elf64_Ehdr *)&u[0];\n    Elf64_Phdr const *phdr = nullptr;\n    total_in = 0;\n    total_out = 0;\n    unsigned c_adler = upx_adler32(nullptr, 0);\n    unsigned u_adler = upx_adler32(nullptr, 0);\n\n    unsigned is_shlib = 0;\n    loader_offset = 0;\n    MemBuffer o_elfhdrs;\n    Elf64_Phdr const *const dynhdr = elf_find_ptype(Elf64_Phdr::PT_DYNAMIC, phdri, c_phnum);\n    if (dynhdr) {\n        upx_uint64_t dyn_offset = get_te64(&dynhdr->p_offset);\n        upx_uint64_t dyn_filesz = get_te64(&dynhdr->p_filesz);\n        dynseg = (Elf64_Dyn const *)ibuf.subref(\"bad DYNAMIC\", dyn_offset, dyn_filesz);\n        // Packed shlib? (ET_DYN without -fPIE)\n        if (!(Elf64_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf64_Dyn::DT_FLAGS_1))) {\n            is_shlib = 1;\n            u_phnum = get_te16(&ehdri.e_phnum);\n            o_elfhdrs.alloc(sz_elf_hdrs);\n            un_shlib_1(fo, o_elfhdrs, c_adler, u_adler, dynhdr, orig_file_size, szb_info);\n            *ehdr = ehdri;\n        }\n    }\n    else { // main executable\n        // Uncompress Ehdr and Phdrs: info for control of unpacking\n        if (ibuf.getSize() < ph.c_len)\n            throwCompressedDataViolation();\n        fi->readx(ibuf, ph.c_len);\n        decompress(ibuf, (upx_byte *)ehdr, false);\n        if (ehdr->e_type   !=ehdri.e_type\n        ||  ehdr->e_machine!=ehdri.e_machine\n        ||  ehdr->e_version!=ehdri.e_version\n            // less strict for EM_PPC64 to workaround earlier bug\n        ||  !( ehdr->e_flags==ehdri.e_flags\n            || Elf64_Ehdr::EM_PPC64 == get_te16(&ehdri.e_machine))\n        ||  ehdr->e_ehsize !=ehdri.e_ehsize\n            // check EI_MAG[0-3], EI_CLASS, EI_DATA, EI_VERSION\n        ||  memcmp(ehdr->e_ident, ehdri.e_ident, Elf64_Ehdr::EI_OSABI)) {\n            throwCantUnpack(\"ElfXX_Ehdr corrupted\");\n        }\n        // Rewind: prepare for data phase\n        fi->seek(- (off_t) (szb_info + ph.c_len), SEEK_CUR);\n\n        u_phnum = get_te16(&ehdr->e_phnum);\n#define MAX_ELF_HDR 1024\n        if ((umin64(MAX_ELF_HDR, ph.u_len) - sizeof(Elf64_Ehdr))/sizeof(Elf64_Phdr) < u_phnum) {\n            throwCantUnpack(\"bad compressed e_phnum\");\n        }\n        o_elfhdrs.alloc(sizeof(Elf64_Ehdr) + u_phnum * sizeof(Elf64_Phdr));\n        memcpy(o_elfhdrs, ehdr, o_elfhdrs.getSize());\n#undef MAX_ELF_HDR\n\n        // Decompress each PT_LOAD.\n        bool first_PF_X = true;\n        phdr = (Elf64_Phdr *) (void *) (1+ ehdr);  // uncompressed\n        for (unsigned j=0; j < u_phnum; ++phdr, ++j) {\n            if (PT_LOAD64==get_te32(&phdr->p_type)) {\n                unsigned const filesz = get_te64(&phdr->p_filesz);\n                unsigned const offset = get_te64(&phdr->p_offset);\n                if (fo)\n                    fo->seek(offset, SEEK_SET);\n                if (Elf64_Phdr::PF_X & get_te32(&phdr->p_flags)) {\n                    unpackExtent(filesz, fo,\n                        c_adler, u_adler, first_PF_X, szb_info);\n                    first_PF_X = false;\n                }\n                else {\n                    unpackExtent(filesz, fo,\n                        c_adler, u_adler, false, szb_info);\n                }\n            }\n        }\n    }\n\n    phdr = phdri;\n    load_va = 0;\n    for (unsigned j=0; j < c_phnum; ++j) {\n        if (PT_LOAD64==get_te32(&phdr->p_type)) {\n            load_va = get_te64(&phdr->p_vaddr);\n            break;\n        }\n    }\n    unsigned d_info[6];\n    unsigned sz_d_info = sizeof(d_info);\n    if (!is_shlib) {\n        if (get_te32(&phdri[0].p_flags) & Elf64_Phdr::PF_X) {\n            // Old style, such as upx-3.91 thru upx-3.95\n            switch (this->e_machine) { // FIXME: missing 32-bit EM_386 EM_ARM EM_PPC\n                default: {\n                    char msg[40]; snprintf(msg, sizeof(msg),\n                        \"Unknown architecture %d\", this->e_machine);\n                    throwCantUnpack(msg);\n                }; break;\n                case Elf64_Ehdr::EM_AARCH64: sz_d_info = 4 * sizeof(unsigned); break;\n                case Elf64_Ehdr::EM_PPC64:   sz_d_info = 3 * sizeof(unsigned); break;\n                case Elf64_Ehdr::EM_X86_64:  sz_d_info = 2 * sizeof(unsigned); break;\n            }\n        }\n        loader_offset = get_te64(&ehdri.e_entry) - load_va - sz_d_info;\n    }\n\n    if (0x1000==get_te64(&phdri[0].p_filesz)  // detect C_BASE style\n    &&  0==get_te64(&phdri[1].p_offset)\n    &&  0==get_te64(&phdri[0].p_offset)\n    &&     get_te64(&phdri[1].p_filesz) == get_te64(&phdri[1].p_memsz)) {\n        fi->seek(up4(get_te64(&phdr[1].p_memsz)), SEEK_SET);  // past the loader\n    }\n    else if (is_shlib\n    ||  ((unsigned)(get_te64(&ehdri.e_entry) - load_va) + up4(lsize) +\n                ph.getPackHeaderSize() + sizeof(overlay_offset))\n            < up4(file_size)) {\n        // Loader is not at end; skip past it.\n        if (loader_offset) {\n            fi->seek(loader_offset, SEEK_SET);\n        }\n        else {\n            funpad4(fi);  // MATCH01\n        }\n        fi->readx(d_info, sz_d_info);\n        if (is_shlib && 0==old_dtinit) {\n            old_dtinit = get_te32(&d_info[2 + (0==d_info[0])]);\n            is_asl = 1u& get_te32(&d_info[0 + (0==d_info[0])]);\n        }\n        fi->seek(lsize - sz_d_info, SEEK_CUR);\n    }\n\n    // The gaps between PT_LOAD and after last PT_LOAD\n    phdr = (Elf64_Phdr const *)(1+ (Elf64_Ehdr const *)(void const *)o_elfhdrs);\n    upx_uint64_t hi_offset(0);\n    for (unsigned j = 0; j < u_phnum; ++j) {\n        if (PT_LOAD64==phdr[j].p_type\n        &&  hi_offset < phdr[j].p_offset)\n            hi_offset = phdr[j].p_offset;\n    }\n    for (unsigned j = 0; j < u_phnum; ++j) {\n        unsigned const size = find_LOAD_gap(phdr, j, u_phnum);\n        if (size) {\n            unsigned const where = get_te64(&phdr[j].p_offset) +\n                                   get_te64(&phdr[j].p_filesz);\n            if (fo)\n                fo->seek(where, SEEK_SET);\n            unpackExtent(size, fo,\n                c_adler, u_adler, false, szb_info,\n                is_shlib && ((phdr[j].p_offset != hi_offset)));\n                // FIXME: should not depend on is_shlib ?\n        }\n    }\n\n    // check for end-of-file\n    fi->readx(&bhdr, szb_info);\n    unsigned const sz_unc = ph.u_len = get_te32(&bhdr.sz_unc);\n\n    if (sz_unc == 0) { // uncompressed size 0 -> EOF\n        // note: magic is always stored le32\n        unsigned const sz_cpr = get_le32(&bhdr.sz_cpr);\n        if (sz_cpr != UPX_MAGIC_LE32)  // sz_cpr must be h->magic\n            throwCompressedDataViolation();\n    }\n    else { // extra bytes after end?\n        throwCompressedDataViolation();\n    }\n\n    if (is_shlib) {\n        un_DT_INIT(old_dtinit, (Elf64_Phdr *)(1+ (Elf64_Ehdr *)(void *)o_elfhdrs), dynhdr, fo, is_asl);\n    }\n\n    // update header with totals\n    ph.c_len = total_in;\n    ph.u_len = total_out;\n\n    // all bytes must be written\n    if (fo && total_out != orig_file_size)\n        throwEOFException();\n\n    // finally test the checksums\n    if (ph.c_adler != c_adler || ph.u_adler != u_adler)\n        throwChecksumError();\n}\n\n\n/*************************************************************************\n//\n**************************************************************************/\n\nPackLinuxElf32x86::PackLinuxElf32x86(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_386;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf32x86::~PackLinuxElf32x86()\n{\n}\n\nint PackLinuxElf32x86::canUnpack() // bool, except -1: format known, but not packed\n{\n    if (super::canUnpack()) {\n        return true;\n    }\n    return false;\n}\n\nLinker* PackLinuxElf32x86::newLinker() const\n{\n    return new ElfLinkerX86;\n}\n\nPackBSDElf32x86::PackBSDElf32x86(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_386;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2LSB;\n}\n\nPackBSDElf32x86::~PackBSDElf32x86()\n{\n}\n\nPackFreeBSDElf32x86::PackFreeBSDElf32x86(InputFile *f) : super(f)\n{\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_FREEBSD;\n}\n\nPackFreeBSDElf32x86::~PackFreeBSDElf32x86()\n{\n}\n\nPackNetBSDElf32x86::PackNetBSDElf32x86(InputFile *f) : super(f)\n{\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_NETBSD;\n    osabi_note = \"NetBSD\";\n}\n\nPackNetBSDElf32x86::~PackNetBSDElf32x86()\n{\n}\n\nPackOpenBSDElf32x86::PackOpenBSDElf32x86(InputFile *f) : super(f)\n{\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_OPENBSD;\n    osabi_note = \"OpenBSD\";\n}\n\nPackOpenBSDElf32x86::~PackOpenBSDElf32x86()\n{\n}\n\nint const *\nPackLinuxElf32x86::getFilters() const\n{\n    static const int filters[] = {\n        0x49, 0x46,\n// FIXME 2002-11-11: We use stub/fold_elf86.asm, which calls the\n// decompressor multiple times, and unfilter is independent of decompress.\n// Currently only filters 0x49, 0x46, 0x80..0x87 can handle this;\n// and 0x80..0x87 are regarded as \"untested\".\n#if 0\n        0x26, 0x24, 0x11, 0x14, 0x13, 0x16, 0x25, 0x15, 0x12,\n#endif\n#if 0\n        0x83, 0x36, 0x26,\n              0x86, 0x80,\n        0x84, 0x87, 0x81,\n        0x82, 0x85,\n        0x24, 0x16, 0x13, 0x14, 0x11, 0x25, 0x15, 0x12,\n#endif\n    FT_END };\n    return filters;\n}\n\nPackLinuxElf32armLe::PackLinuxElf32armLe(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_ARM;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_ARM;\n}\n\nPackLinuxElf32armLe::~PackLinuxElf32armLe()\n{\n}\n\nPackLinuxElf32mipseb::PackLinuxElf32mipseb(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_MIPS;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2MSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf32mipseb::~PackLinuxElf32mipseb()\n{\n}\n\nPackLinuxElf32mipsel::PackLinuxElf32mipsel(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_MIPS;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2LSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_LINUX;\n}\n\nPackLinuxElf32mipsel::~PackLinuxElf32mipsel()\n{\n}\n\nLinker* PackLinuxElf32armLe::newLinker() const\n{\n    return new ElfLinkerArmLE();\n}\n\nLinker* PackLinuxElf32mipseb::newLinker() const\n{\n    return new ElfLinkerMipsBE();\n}\n\nLinker* PackLinuxElf32mipsel::newLinker() const\n{\n    return new ElfLinkerMipsLE();\n}\n\nPackLinuxElf32armBe::PackLinuxElf32armBe(InputFile *f) : super(f)\n{\n    e_machine = Elf32_Ehdr::EM_ARM;\n    ei_class  = Elf32_Ehdr::ELFCLASS32;\n    ei_data   = Elf32_Ehdr::ELFDATA2MSB;\n    ei_osabi  = Elf32_Ehdr::ELFOSABI_ARM;\n}\n\nPackLinuxElf32armBe::~PackLinuxElf32armBe()\n{\n}\n\nLinker* PackLinuxElf32armBe::newLinker() const\n{\n    return new ElfLinkerArmBE();\n}\n\nunsigned\nPackLinuxElf32::elf_get_offset_from_address(unsigned addr) const\n{\n    Elf32_Phdr const *phdr = phdri;\n    int j = e_phnum;\n    for (; --j>=0; ++phdr) if (is_LOAD32(phdr)) {\n        unsigned const t = addr - get_te32(&phdr->p_vaddr);\n        if (t < get_te32(&phdr->p_filesz)) {\n            unsigned const p_offset = get_te32(&phdr->p_offset);\n            if ((u32_t)file_size <= p_offset) { // FIXME: weak\n                char msg[40]; snprintf(msg, sizeof(msg),\n                    \"bad Elf32_Phdr[%d].p_offset %x\",\n                    -1+ e_phnum - j, p_offset);\n                throwCantPack(msg);\n            }\n            return t + p_offset;\n        }\n    }\n    return 0;\n}\n\nu32_t  // returns .p_offset\nPackLinuxElf32::check_pt_load(Elf32_Phdr const *const phdr)\n{\n    u32_t filesz = get_te32(&phdr->p_filesz);\n    u32_t offset = get_te32(&phdr->p_offset), offend = filesz + offset;\n    u32_t vaddr  = get_te32(&phdr->p_vaddr);\n    u32_t paddr  = get_te32(&phdr->p_paddr);\n    u32_t align  = get_te32(&phdr->p_align);\n\n    if ((-1+ align) & (paddr ^ vaddr)\n    ||  (u32_t)file_size <= (u32_t)offset\n    ||  (u32_t)file_size <  (u32_t)offend\n    ||  (u32_t)file_size <= (u32_t)filesz) {\n        char msg[50]; snprintf(msg, sizeof(msg), \"bad PT_LOAD phdr[%u]\",\n            (unsigned)(phdr - phdri));\n        throwCantPack(msg);\n    }\n    return offset;\n}\n\nElf32_Dyn const *\nPackLinuxElf32::elf_has_dynamic(unsigned int key) const\n{\n    Elf32_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; Elf32_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te32(&dynp->d_tag)==key) {\n        return dynp;\n    }\n    return nullptr;\n}\n\nunsigned  // checked .p_offset; sz_dynseg set\nPackLinuxElf32::check_pt_dynamic(Elf32_Phdr const *const phdr)\n{\n    unsigned t = get_te32(&phdr->p_offset), s = sizeof(Elf32_Dyn) + t;\n    unsigned vaddr = get_te32(&phdr->p_vaddr);\n    unsigned filesz = get_te32(&phdr->p_filesz), memsz = get_te32(&phdr->p_memsz);\n    unsigned align = get_te32(&phdr->p_align);\n    if (file_size_u < t || s < t\n    ||  file_size_u < filesz\n    ||  file_size_u < (filesz + t)\n    ||  t < (e_phnum*sizeof(Elf32_Phdr) + sizeof(Elf32_Ehdr))\n    ||  (3 & t) || (7 & (filesz | memsz))  // .balign 4; 8==sizeof(Elf32_Dyn)\n    ||  (-1+ align) & (t ^ vaddr)\n    ||  file_size_u <= memsz\n    ||  filesz < sizeof(Elf32_Dyn)\n    ||  memsz  < sizeof(Elf32_Dyn)\n    ||  filesz < memsz) {\n        char msg[50]; snprintf(msg, sizeof(msg), \"bad PT_DYNAMIC phdr[%u]\",\n            (unsigned)(phdr - phdri));\n        throwCantPack(msg);\n    }\n    sz_dynseg = memsz;\n    return t;\n}\n\nvoid const *\nPackLinuxElf32::elf_find_dynamic(unsigned int key) const\n{\n    Elf32_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; (unsigned)((char const *)dynp - (char const *)dynseg) < sz_dynseg\n            && Elf32_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te32(&dynp->d_tag)==key) {\n        unsigned const t= elf_get_offset_from_address(get_te32(&dynp->d_val));\n        if (t && t < (unsigned)file_size) {\n            return t + file_image;\n        }\n        break;\n    }\n    return nullptr;\n}\n\nupx_uint64_t\nPackLinuxElf32::elf_unsigned_dynamic(unsigned int key) const\n{\n    Elf32_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; (unsigned)((char const *)dynp - (char const *)dynseg) < sz_dynseg\n            && Elf32_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te32(&dynp->d_tag)==key) {\n        return get_te32(&dynp->d_val);\n    }\n    return 0;\n}\n\nupx_uint64_t\nPackLinuxElf64::elf_get_offset_from_address(upx_uint64_t addr) const\n{\n    Elf64_Phdr const *phdr = phdri;\n    int j = e_phnum;\n    for (; --j>=0; ++phdr) if (PT_LOAD64 == get_te32(&phdr->p_type)) {\n        upx_uint64_t const t = addr - get_te64(&phdr->p_vaddr);\n        if (t < get_te64(&phdr->p_filesz)) {\n            upx_uint64_t const p_offset = get_te64(&phdr->p_offset);\n            if ((u64_t)file_size <= p_offset) { // FIXME: weak\n                char msg[40]; snprintf(msg, sizeof(msg),\n                    \"bad Elf64_Phdr[%d].p_offset %#lx\",\n                    -1+ e_phnum - j, (long unsigned)p_offset);\n                throwCantPack(msg);\n            }\n            return t + p_offset;\n        }\n    }\n    return 0;\n}\n\nu64_t  // returns .p_offset\nPackLinuxElf64::check_pt_load(Elf64_Phdr const *const phdr)\n{\n    u64_t filesz = get_te64(&phdr->p_filesz);\n    u64_t offset = get_te64(&phdr->p_offset), offend = filesz + offset;\n    u64_t vaddr  = get_te64(&phdr->p_vaddr);\n    u64_t paddr  = get_te64(&phdr->p_paddr);\n    u64_t align  = get_te64(&phdr->p_align);\n\n    if ((-1+ align) & (paddr ^ vaddr)\n    ||  (u64_t)file_size <= (u64_t)offset\n    ||  (u64_t)file_size <  (u64_t)offend\n    ||  (u64_t)file_size <= (u64_t)filesz) {\n        char msg[50]; snprintf(msg, sizeof(msg), \"bad PT_LOAD phdr[%u]\",\n            (unsigned)(phdr - phdri));\n        throwCantPack(msg);\n    }\n    return offset;\n}\n\nElf64_Dyn const *\nPackLinuxElf64::elf_has_dynamic(unsigned int key) const\n{\n    Elf64_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; Elf64_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te64(&dynp->d_tag)==key) {\n        return dynp;\n    }\n    return nullptr;\n}\n\nupx_uint64_t  // checked .p_offset; sz_dynseg set\nPackLinuxElf64::check_pt_dynamic(Elf64_Phdr const *const phdr)\n{\n    upx_uint64_t t = get_te64(&phdr->p_offset), s = sizeof(Elf64_Dyn) + t;\n    upx_uint64_t vaddr = get_te64(&phdr->p_vaddr);\n    upx_uint64_t filesz = get_te64(&phdr->p_filesz), memsz = get_te64(&phdr->p_memsz);\n    upx_uint64_t align = get_te64(&phdr->p_align);\n    if (file_size_u < t || s < t\n    ||  file_size_u < filesz\n    ||  file_size_u < (filesz + t)\n    ||  t < (e_phnum*sizeof(Elf64_Phdr) + sizeof(Elf64_Ehdr))\n    ||  (7 & t) || (0xf & (filesz | memsz))  // .balign 8; 16==sizeof(Elf64_Dyn)\n    ||  (-1+ align) & (t ^ vaddr)\n    ||  file_size_u <= memsz\n    ||  filesz < sizeof(Elf64_Dyn)\n    ||  memsz  < sizeof(Elf64_Dyn)\n    ||  filesz < memsz) {\n        char msg[50]; snprintf(msg, sizeof(msg), \"bad PT_DYNAMIC phdr[%u]\",\n            (unsigned)(phdr - phdri));\n        throwCantPack(msg);\n    }\n    sz_dynseg = memsz;\n    return t;\n}\n\nstatic int __acc_cdecl_qsort\nqcmp_unsigned(void const *const aa, void const *const bb)\n{\n    unsigned a = *(unsigned const *)aa;\n    unsigned b = *(unsigned const *)bb;\n    if (a < b) return -1;\n    if (a > b) return  1;\n    return  0;\n}\n\nvoid\nPackLinuxElf64::invert_pt_dynamic(Elf64_Dyn const *dynp, upx_uint64_t headway)\n{\n    if (dt_table[Elf64_Dyn::DT_NULL]) {\n        return;  // not 1st time; do not change upx_dt_init\n    }\n    Elf64_Dyn const *const dynp0 = dynp;\n    unsigned ndx = 0;\n    unsigned const limit = headway / sizeof(*dynp);\n    if (dynp)\n    for (; ; ++ndx, ++dynp) {\n        if (limit <= ndx) {\n            throwCantPack(\"DT_NULL not found\");\n        }\n        upx_uint64_t const d_tag = get_te64(&dynp->d_tag);\n        if (d_tag>>32) { // outrageous\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad Elf64_Dyn[%d].d_tag %#lx\", ndx, (long unsigned)d_tag);\n            throwCantPack(msg);\n        }\n        if (d_tag < DT_NUM) {\n            if (Elf64_Dyn::DT_NEEDED != d_tag\n            &&  dt_table[d_tag]\n            &&    get_te64(&dynp->d_val)\n               != get_te64(&dynp0[-1+ dt_table[d_tag]].d_val)) {\n                char msg[50]; snprintf(msg, sizeof(msg),\n                    \"duplicate DT_%#x: [%#x] [%#x]\",\n                    (unsigned)d_tag, -1+ dt_table[d_tag], ndx);\n                throwCantPack(msg);\n            }\n            dt_table[d_tag] = 1+ ndx;\n        }\n        if (Elf64_Dyn::DT_NULL == d_tag) {\n            break;  // check here so that dt_table[DT_NULL] is set\n        }\n    }\n    upx_dt_init = 0;\n         if (dt_table[Elf64_Dyn::DT_INIT])          upx_dt_init = Elf64_Dyn::DT_INIT;\n    else if (dt_table[Elf64_Dyn::DT_PREINIT_ARRAY]) upx_dt_init = Elf64_Dyn::DT_PREINIT_ARRAY;\n    else if (dt_table[Elf64_Dyn::DT_INIT_ARRAY])    upx_dt_init = Elf64_Dyn::DT_INIT_ARRAY;\n\n    unsigned const z_str = dt_table[Elf64_Dyn::DT_STRSZ];\n    strtab_end = !z_str ? 0 : get_te64(&dynp0[-1+ z_str].d_val);\n    if (!z_str || (u64_t)file_size <= strtab_end) { // FIXME: weak\n        char msg[50]; snprintf(msg, sizeof(msg),\n            \"bad DT_STRSZ %#x\", strtab_end);\n        throwCantPack(msg);\n    }\n\n    // DT_SYMTAB has no designated length.\n    // End it when next area else starts; often DT_STRTAB.  (FIXME)\n    unsigned const x_sym = dt_table[Elf64_Dyn::DT_SYMTAB];\n    unsigned const x_str = dt_table[Elf64_Dyn::DT_STRTAB];\n    if (x_sym && x_str) {\n        upx_uint64_t const v_sym = get_te64(&dynp0[-1+ x_sym].d_val);\n        upx_uint64_t const v_str = get_te64(&dynp0[-1+ x_str].d_val);\n        unsigned const  z_sym = dt_table[Elf64_Dyn::DT_SYMENT];\n        unsigned const sz_sym = !z_sym ? sizeof(Elf64_Sym)\n            : get_te64(&dynp0[-1+ z_sym].d_val);\n        if (sz_sym < sizeof(Elf64_Sym)) {\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_SYMENT %x\", sz_sym);\n            throwCantPack(msg);\n        }\n        if (v_sym < v_str) {\n            symnum_end = (v_str - v_sym) / sz_sym;\n        }\n        if (symnum_end < 1) {\n            throwCantPack(\"bad DT_SYMTAB\");\n        }\n    }\n    // DT_HASH, DT_GNU_HASH have no explicit length (except in ElfXX_Shdr),\n    // so it is hard to detect when the index of a hash chain is out-of-bounds.\n    // Workaround: Assume no overlap of DT_* tables.  Then any given table\n    // ends when another table begins.  So find the tables, and sort the offsets.\n    unsigned const dt_names[] = { // *.d_val are often in this order\n        Elf64_Dyn::DT_SYMTAB,\n        Elf64_Dyn::DT_VERSYM,\n        Elf64_Dyn::DT_VERNEED,\n        Elf64_Dyn::DT_HASH,\n        Elf64_Dyn::DT_GNU_HASH,\n        Elf64_Dyn::DT_STRTAB,\n        Elf64_Dyn::DT_VERDEF,\n        Elf64_Dyn::DT_REL,\n        Elf64_Dyn::DT_RELA,\n        Elf64_Dyn::DT_INIT,\n        0,\n    };\n    unsigned dt_offsets[sizeof(dt_names)/sizeof(dt_names[0])];\n    unsigned n_off = 0, k;\n    for (unsigned j=0; ((k = dt_names[j]),  k); ++j) {\n        dt_offsets[n_off] = 0;  // default to \"not found\"\n        if (k < DT_NUM) { // in range of easy table\n            if (dt_table[k]) { // present now\n                dt_offsets[n_off] = get_te64(&dynp0[-1+ dt_table[k]].d_val);\n            }\n        }\n        else {\n            if (file_image) { // why is this guard necessary?\n                dt_offsets[n_off] = elf_unsigned_dynamic(k);  // zero if not found\n            }\n        }\n        if (file_size <= dt_offsets[n_off]) {\n            char msg[60]; snprintf(msg, sizeof(msg), \"bad DT_{%#x} = %#x (beyond EOF)\",\n                k, dt_offsets[n_off]);\n                throwCantPack(msg);\n        }\n        n_off += !!dt_offsets[n_off];\n    }\n    dt_offsets[n_off++] = file_size;  // sentinel\n    qsort(dt_offsets, n_off, sizeof(dt_offsets[0]), qcmp_unsigned);\n\n    unsigned const v_hsh = elf_unsigned_dynamic(Elf64_Dyn::DT_HASH);\n    if (v_hsh && file_image) {\n        hashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_HASH);\n        if (!hashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_HASH %#x\", v_hsh);\n            throwCantPack(msg);\n        }\n        for (unsigned j = 0; j < n_off; ++j) {\n            if (v_hsh == dt_offsets[j]) {\n                if (dt_offsets[1+ j]) {\n                    hashend = (unsigned const *)(void const *)\n                        ((dt_offsets[1+ j] - dt_offsets[j]) + (char const *)hashtab);\n                }\n                break;\n            }\n        }\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket]; (void)chains;\n\n        unsigned const v_sym = !x_sym ? 0 : get_te32(&dynp0[-1+ x_sym].d_val);\n        if ((unsigned)file_size <= nbucket/sizeof(*buckets)  // FIXME: weak\n        || !v_sym || (unsigned)file_size <= v_sym\n        || ((v_hsh < v_sym) && (v_sym - v_hsh) < sizeof(*buckets)*(2+ nbucket))\n        ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n        unsigned chmax = 0;\n        for (unsigned j= 0; j < nbucket; ++j) {\n            unsigned x = get_te32(&buckets[j]);\n            if (chmax < x) {\n                chmax = x;\n            }\n        }\n        if ((v_hsh < v_sym) && (v_sym - v_hsh) <\n                (sizeof(*buckets)*(2+ nbucket) + sizeof(*chains)*(1+ chmax))) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n    }\n    // DT_GNU_HASH often ends at DT_SYMTAB;  FIXME: not for Android?\n    unsigned const v_gsh = elf_unsigned_dynamic(Elf64_Dyn::DT_GNU_HASH);\n    if (v_gsh && file_image) {\n        gashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_GNU_HASH);\n        if (!gashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_GNU_HASH %#x\", v_gsh);\n            throwCantPack(msg);\n        }\n        for (unsigned j = 0; j < n_off; ++j) { // linear search of short table\n            if (v_gsh == dt_offsets[j]) {\n                if (dt_offsets[1+ j]) {\n                    gashend = (unsigned const *)(void const *)\n                        ((dt_offsets[1+ j] - dt_offsets[j]) + (char const *)gashtab);\n                }\n                break;\n            }\n        }\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket]; (void)hasharr;\n        if (!n_bucket || (1u<<31) <= n_bucket  /* fie on fuzzers */\n        || (void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        // unsigned const *const gashend = &hasharr[n_bucket];\n        // minimum, except:\n        // Rust and Android trim unused zeroes from high end of hasharr[]\n        unsigned bmax = 0;\n        for (unsigned j= 0; j < n_bucket; ++j) {\n            unsigned bj = get_te32(&buckets[j]);\n            if (bj) {\n                if (bj < symbias) {\n                    char msg[90]; snprintf(msg, sizeof(msg),\n                            \"bad DT_GNU_HASH bucket[%d] < symbias{%#x}\\n\",\n                            bj, symbias);\n                    throwCantPack(msg);\n                }\n                if (bmax < bj) {\n                    bmax = bj;\n                }\n            }\n        }\n        if (1==n_bucket  && 0==buckets[0]\n        &&  1==n_bitmask && 0==bitmask[0]) {\n            // 2021-09-11 Rust on RaspberryPi apparently uses this to minimize space.\n            // But then the DT_GNU_HASH symbol lookup algorithm always fails?\n            // https://github.com/upx/upx/issues/525\n        } else\n        if ((1+ bmax) < symbias) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                    \"bad DT_GNU_HASH (1+ max_bucket)=%#x < symbias=%#x\", 1+ bmax, symbias);\n            throwCantPack(msg);\n        }\n        bmax -= symbias;\n\n        // preliminary bound on gashend\n        Elf64_Shdr const *sec_gash = elf_find_section_type(Elf64_Shdr::SHT_GNU_HASH);\n        unsigned const off_symtab = elf_unsigned_dynamic(Elf64_Dyn::DT_SYMTAB);\n        unsigned const off_strtab = elf_unsigned_dynamic(Elf64_Dyn::DT_STRTAB);\n        unsigned const off_gshtab = elf_unsigned_dynamic(Elf64_Dyn::DT_GNU_HASH);\n        if (off_gshtab < file_size  // paranoia\n        &&  off_strtab < file_size\n        &&  off_symtab < file_size ) {\n            unsigned sz_gshtab = 0;\n            if (sec_gash && off_gshtab == get_te32(&sec_gash->sh_offset)) {\n               sz_gshtab = get_te32(&sec_gash->sh_size);\n            }\n            else { // heuristics\n                if (off_gshtab < off_strtab) {\n                    sz_gshtab = off_strtab - off_gshtab;\n                }\n                else if (off_gshtab < off_symtab) {\n                    sz_gshtab = off_symtab - off_gshtab;\n                }\n            }\n            if (sz_gshtab <= (file_size - off_gshtab)) {\n                gashend = (unsigned const *)(void const *)\n                    (sz_gshtab + (char const *)gashtab);\n            }\n        }\n\n        upx_uint64_t const v_sym = !x_sym ? 0 : get_te64(&dynp0[-1+ x_sym].d_val);\n        unsigned r = 0;\n        if (!n_bucket || !n_bitmask || !v_sym\n        || (r=1, ((-1+ n_bitmask) & n_bitmask))  // not a power of 2\n        || (r=2, (8*sizeof(upx_uint64_t) <= gnu_shift))  // shifted result always == 0\n        || (r=3, (n_bucket>>30))  // fie on fuzzers\n        || (r=4, (n_bitmask>>30))\n        || (r=5, ((file_size/sizeof(unsigned))\n                <= ((sizeof(*bitmask)/sizeof(unsigned))*n_bitmask + 2*n_bucket)))  // FIXME: weak\n        || (r=6, ((v_gsh < v_sym) && (v_sym - v_gsh) < (sizeof(unsigned)*4  // headers\n                + sizeof(*bitmask)*n_bitmask  // bitmask\n                + sizeof(*buckets)*n_bucket  // buckets\n                + sizeof(*hasharr)*(1+ bmax)  // hasharr\n            )) )\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_GNU_HASH n_bucket=%#x  n_bitmask=%#x  len=%#lx  r=%d\",\n                n_bucket, n_bitmask, (long unsigned)(v_sym - v_gsh), r);\n            throwCantPack(msg);\n        }\n    }\n    unsigned const e_shstrndx = get_te16(&ehdri.e_shstrndx);\n    if (e_shnum <= e_shstrndx\n    &&  !(0==e_shnum && 0==e_shstrndx) ) {\n        char msg[40]; snprintf(msg, sizeof(msg),\n            \"bad .e_shstrndx %d >= .e_shnum %d\", e_shstrndx, e_shnum);\n        throwCantPack(msg);\n    }\n}\n\nvoid const *\nPackLinuxElf64::elf_find_dynamic(unsigned int key) const\n{\n    Elf64_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; (unsigned)((char const *)dynp - (char const *)dynseg) < sz_dynseg\n            && Elf64_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te64(&dynp->d_tag)==key) {\n        upx_uint64_t const t= elf_get_offset_from_address(get_te64(&dynp->d_val));\n        if (t && t < (upx_uint64_t)file_size) {\n            return t + file_image;\n        }\n        break;\n    }\n    return nullptr;\n}\n\nupx_uint64_t\nPackLinuxElf64::elf_unsigned_dynamic(unsigned int key) const\n{\n    Elf64_Dyn const *dynp= dynseg;\n    if (dynp)\n    for (; (unsigned)((char const *)dynp - (char const *)dynseg) < sz_dynseg\n            && Elf64_Dyn::DT_NULL!=dynp->d_tag; ++dynp) if (get_te64(&dynp->d_tag)==key) {\n        return get_te64(&dynp->d_val);\n    }\n    return 0;\n}\n\nunsigned PackLinuxElf::gnu_hash(char const *q)\n{\n    unsigned char const *p = (unsigned char const *)q;\n    unsigned h;\n\n    for (h= 5381; 0!=*p; ++p) {\n        h += *p + (h << 5);\n    }\n    return h;\n}\n\nunsigned PackLinuxElf::elf_hash(char const *p)\n{\n    unsigned h;\n    for (h= 0; 0!=*p; ++p) {\n        h = *p + (h<<4);\n        {\n            unsigned const t = 0xf0000000u & h;\n            h &= ~t;\n            h ^= t>>24;\n        }\n    }\n    return h;\n}\n\nElf32_Sym const *PackLinuxElf32::elf_lookup(char const *name) const\n{\n    if (hashtab && dynsym && dynstr) {\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket];\n        if ((unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*nbucket ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad nbucket %#x\\n\", nbucket);\n            throwCantPack(msg);\n        }\n        if (nbucket) {\n            unsigned const m = elf_hash(name) % nbucket;\n            unsigned si;\n            for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n                char const *const p= get_dynsym_name(si, (unsigned)-1);\n                if (0==strcmp(name, p)) {\n                    return &dynsym[si];\n                }\n            }\n        }\n    }\n    if (gashtab && dynsym && dynstr) {\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        unsigned const *const bitmask = &gashtab[4];\n        unsigned const *const buckets = &bitmask[n_bitmask];\n        unsigned const *const hasharr = &buckets[n_bucket];\n        if ((void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        if (!n_bitmask\n        || (unsigned)(file_size - ((char const *)bitmask - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*n_bitmask ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bitmask %#x\\n\", n_bitmask);\n            throwCantPack(msg);\n        }\n        if (n_bucket) {\n            unsigned const h = gnu_hash(name);\n            unsigned const hbit1 = 037& h;\n            unsigned const hbit2 = 037& (h>>gnu_shift);\n            unsigned const w = get_te32(&bitmask[(n_bitmask -1) & (h>>5)]);\n\n            if (1& (w>>hbit1) & (w>>hbit2)) {\n                unsigned bucket = get_te32(&buckets[h % n_bucket]);\n                if (n_bucket <= bucket) {\n                    char msg[90]; snprintf(msg, sizeof(msg),\n                            \"bad DT_GNU_HASH n_bucket{%#x} <= buckets[%d]{%#x}\\n\",\n                            n_bucket, h % n_bucket, bucket);\n                    throwCantPack(msg);\n                }\n                if (0!=bucket) {\n                    Elf32_Sym const *dsp = &dynsym[bucket];\n                    unsigned const *hp = &hasharr[bucket - symbias];\n                    do if (0==((h ^ get_te32(hp))>>1)) {\n                        unsigned st_name = get_te32(&dsp->st_name);\n                        char const *const p = get_str_name(st_name, (unsigned)-1);\n                        if (0==strcmp(name, p)) {\n                            return dsp;\n                        }\n                    } while (++dsp,\n                            (char const *)hp < (char const *)&file_image[file_size]\n                        &&  0==(1u& get_te32(hp++)));\n                }\n            }\n        }\n    }\n    // 2021-12-25  FIXME: Some Rust programs use\n    //    (1==n_bucket && 0==buckets[0] && 1==n_bitmask && 0==bitmask[0])\n    // to minimize space in DT_GNU_HASH. This causes the fancy lookup to fail.\n    // Is a fallback to linear seach assumed?\n    // 2022-03-12  Some Rust programs have 0==n_bucket.\n    return nullptr;\n\n}\n\nElf64_Sym const *PackLinuxElf64::elf_lookup(char const *name) const\n{\n    if (hashtab && dynsym && dynstr) {\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket];\n        if ((unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*nbucket ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad nbucket %#x\\n\", nbucket);\n            throwCantPack(msg);\n        }\n        if (nbucket) { // -rust-musl can have \"empty\" hashtab\n            unsigned const m = elf_hash(name) % nbucket;\n            unsigned si;\n            for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n                char const *const p= get_dynsym_name(si, (unsigned)-1);\n                if (0==strcmp(name, p)) {\n                    return &dynsym[si];\n                }\n            }\n        }\n    }\n    if (gashtab && dynsym && dynstr) {\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket];\n\n        if ((void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        if (!n_bitmask\n        || (unsigned)(file_size - ((char const *)bitmask - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*n_bitmask ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bitmask %#x\\n\", n_bitmask);\n            throwCantPack(msg);\n        }\n        if (n_bucket) { // -rust-musl can have \"empty\" gashtab\n            unsigned const h = gnu_hash(name);\n            unsigned const hbit1 = 077& h;\n            unsigned const hbit2 = 077& (h>>gnu_shift);\n            upx_uint64_t const w = get_te64(&bitmask[(n_bitmask -1) & (h>>6)]);\n            if (1& (w>>hbit1) & (w>>hbit2)) {\n                unsigned hhead = get_te32(&buckets[h % n_bucket]);\n                if (hhead) {\n                    Elf64_Sym const *dsp = &dynsym[hhead];\n                    unsigned const *hp = &hasharr[hhead - symbias];\n                    unsigned k;\n                    do {\n                        if (gashend <= hp) {\n                            char msg[120]; snprintf(msg, sizeof(msg),\n                                \"bad gnu_hash[%#tx]  head=%u\",\n                                hp - hasharr, hhead);\n                            throwCantPack(msg);\n                        }\n                        k = get_te32(hp);\n                        if (0==((h ^ k)>>1)) {\n                            unsigned const st_name = get_te32(&dsp->st_name);\n                            char const *const p = get_str_name(st_name, (unsigned)-1);\n                            if (0==strcmp(name, p)) {\n                                return dsp;\n                            }\n                        }\n                    } while (++dsp, ++hp, 0==(1u& k));\n                }\n            }\n        }\n    }\n    // 2021-12-25  FIXME: Some Rust programs use\n    //    (1==n_bucket && 0==buckets[0] && 1==n_bitmask && 0==bitmask[0])\n    // to minimize space in DT_GNU_HASH. This causes the fancy lookup to fail.\n    // Is a fallback to linear seach assumed?\n    // 2022-03-12  Some Rust programs have 0==n_bucket.\n    return nullptr;\n\n}\n\nvoid PackLinuxElf32::unpack(OutputFile *fo)\n{\n    if (e_phoff != sizeof(Elf32_Ehdr)) {// Phdrs not contiguous with Ehdr\n        throwCantUnpack(\"bad e_phoff\");\n    }\n    unsigned const c_phnum = get_te16(&ehdri.e_phnum);\n    unsigned old_dtinit = 0;\n    unsigned is_asl = 0;  // is Android Shared Library\n\n    unsigned szb_info = sizeof(b_info);\n    {\n        if (get_te32(&ehdri.e_entry) < 0x401180\n        &&  Elf32_Ehdr::EM_386 ==get_te16(&ehdri.e_machine)\n        &&  Elf32_Ehdr::ET_EXEC==get_te16(&ehdri.e_type)) {\n            // Beware ET_DYN.e_entry==0x10f0 (or so) does NOT qualify here.\n            /* old style, 8-byte b_info */\n            szb_info = 2*sizeof(unsigned);\n        }\n    }\n\n    fi->seek(overlay_offset - sizeof(l_info), SEEK_SET);\n    fi->readx(&linfo, sizeof(linfo));\n    lsize = get_te16(&linfo.l_lsize);\n    if (UPX_MAGIC_LE32 != get_le32(&linfo.l_magic)) {\n        throwCantUnpack(\"l_info corrupted\");\n    }\n    p_info hbuf;  fi->readx(&hbuf, sizeof(hbuf));\n    unsigned orig_file_size = get_te32(&hbuf.p_filesize);\n    blocksize = get_te32(&hbuf.p_blocksize);\n    if ((u32_t)file_size > orig_file_size || blocksize > orig_file_size\n        || !mem_size_valid(1, blocksize, OVERHEAD))\n        throwCantUnpack(\"p_info corrupted\");\n\n    ibuf.alloc(blocksize + OVERHEAD);\n    b_info bhdr; memset(&bhdr, 0, sizeof(bhdr));\n    fi->readx(&bhdr, szb_info);\n    ph.u_len = get_te32(&bhdr.sz_unc);\n    ph.c_len = get_te32(&bhdr.sz_cpr);\n    if (ph.c_len > (unsigned)file_size || ph.c_len == 0 || ph.u_len == 0\n    ||  ph.u_len > orig_file_size)\n        throwCantUnpack(\"b_info corrupted\");\n    ph.filter_cto = bhdr.b_cto8;\n\n    MemBuffer u(ph.u_len);\n    Elf32_Ehdr *const ehdr = (Elf32_Ehdr *)&u[0];\n    Elf32_Phdr const *phdr = nullptr;\n\n    // Uncompress Ehdr and Phdrs.\n    if (ibuf.getSize() < ph.c_len) {\n        throwCompressedDataViolation();\n    }\n    fi->readx(ibuf, ph.c_len);\n    decompress(ibuf, (upx_byte *)ehdr, false);\n    if (ehdr->e_type   !=ehdri.e_type\n    ||  ehdr->e_machine!=ehdri.e_machine\n    ||  ehdr->e_version!=ehdri.e_version\n    ||  ehdr->e_flags  !=ehdri.e_flags\n    ||  ehdr->e_ehsize !=ehdri.e_ehsize\n        // check EI_MAG[0-3], EI_CLASS, EI_DATA, EI_VERSION\n    ||  memcmp(ehdr->e_ident, ehdri.e_ident, Elf32_Ehdr::EI_OSABI)) {\n        throwCantUnpack(\"ElfXX_Ehdr corrupted\");\n    }\n    fi->seek(- (off_t) (szb_info + ph.c_len), SEEK_CUR);\n\n    unsigned const u_phnum = get_te16(&ehdr->e_phnum);\n    total_in = 0;\n    total_out = 0;\n    unsigned c_adler = upx_adler32(nullptr, 0);\n    unsigned u_adler = upx_adler32(nullptr, 0);\n#define MAX_ELF_HDR 512\n    if ((umin(MAX_ELF_HDR, ph.u_len) - sizeof(Elf32_Ehdr))/sizeof(Elf32_Phdr) < u_phnum) {\n        throwCantUnpack(\"bad compressed e_phnum\");\n    }\n#undef MAX_ELF_HDR\n\n    // Packed ET_EXE has no PT_DYNAMIC.\n    // Packed ET_DYN has original PT_DYNAMIC for info needed by rtld.\n    Elf32_Phdr const *const dynhdr = elf_find_ptype(Elf32_Phdr::PT_DYNAMIC, phdri, c_phnum);\n    bool const is_shlib = !!dynhdr;\n    if (is_shlib) {\n        // Unpack and output the Ehdr and Phdrs for real.\n        // This depends on position within input file fi.\n        unpackExtent(ph.u_len, fo,\n            c_adler, u_adler, false, szb_info);\n\n        // The first PT_LOAD.  Part is not compressed (for benefit of rtld.)\n        fi->seek(0, SEEK_SET);\n        fi->readx(ibuf, get_te32(&dynhdr->p_offset) + get_te32(&dynhdr->p_filesz));\n        overlay_offset -= sizeof(linfo);\n        xct_off = overlay_offset;\n        e_shoff = get_te32(&ehdri.e_shoff);\n        ibuf.subref(\"bad .e_shoff %#x for %#x\", e_shoff, sizeof(Elf32_Shdr) * e_shnum);\n        if (e_shoff && e_shnum) { // --android-shlib\n            shdri = (Elf32_Shdr /*const*/ *)ibuf.subref(\n                \"bad Shdr table\", e_shoff, sizeof(Elf32_Shdr)*e_shnum);\n            unsigned xct_off2 = get_te32(&shdri->sh_offset);\n            if (e_shoff == xct_off2) {\n                xct_off = e_shoff;\n            }\n            // un-Relocate dynsym (DT_SYMTAB) which is below xct_off\n            unsigned dyn_offset = get_te32(&dynhdr->p_offset);\n            unsigned dyn_filesz = get_te32(&dynhdr->p_filesz);\n            if (orig_file_size < dyn_offset\n            || (orig_file_size - dyn_offset) < dyn_filesz) {\n                throwCantUnpack(\"bad PT_DYNAMIC\");\n            }\n            dynseg = (Elf32_Dyn const *)ibuf.subref(\"bad DYNAMIC\", dyn_offset, dyn_filesz);\n            dynstr = (char const *)elf_find_dynamic(Elf32_Dyn::DT_STRTAB);\n            sec_dynsym = elf_find_section_type(Elf32_Shdr::SHT_DYNSYM);\n            if (sec_dynsym) {\n                unsigned const off_dynsym = get_te32(&sec_dynsym->sh_offset);\n                unsigned const sz_dynsym  = get_te32(&sec_dynsym->sh_size);\n                if (orig_file_size < sz_dynsym\n                ||  orig_file_size < off_dynsym\n                || (orig_file_size - off_dynsym) < sz_dynsym) {\n                    throwCantUnpack(\"bad SHT_DYNSYM\");\n                }\n                Elf32_Sym *const sym0 = (Elf32_Sym *)ibuf.subref(\n                    \"bad dynsym\", off_dynsym, sz_dynsym);\n                Elf32_Sym *sym = sym0;\n                for (int j = sz_dynsym / sizeof(Elf32_Sym); --j>=0; ++sym) {\n                    unsigned symval = get_te32(&sym->st_value);\n                    unsigned symsec = get_te16(&sym->st_shndx);\n                    if (Elf32_Sym::SHN_UNDEF != symsec\n                    &&  Elf32_Sym::SHN_ABS   != symsec\n                    &&  xct_off <= symval) {\n                        set_te32(&sym->st_value, symval - asl_delta);\n                    }\n                    if (Elf32_Sym::SHN_ABS == symsec && xct_off <= symval) {\n                        adjABS(sym, 0u - asl_delta);\n                    }\n                }\n            }\n        }\n        if (fo) {\n            fo->write(ibuf + ph.u_len, xct_off - ph.u_len);\n        }\n\n        total_in  = xct_off;\n        total_out = xct_off;\n        ph.u_len = 0;\n        // Position the input for next unpackExtent.\n        fi->seek(sizeof(linfo) + overlay_offset + sizeof(hbuf) + szb_info + ph.c_len, SEEK_SET);\n\n        // Decompress and unfilter the tail of first PT_LOAD.\n        phdr = (Elf32_Phdr *) (void *) (1+ ehdr);\n        for (unsigned j=0; j < u_phnum; ++phdr, ++j) {\n            if (is_LOAD32(phdr)) {\n                ph.u_len = get_te32(&phdr->p_filesz) - xct_off;\n                break;\n            }\n        }\n        unpackExtent(ph.u_len, fo,\n            c_adler, u_adler, false, szb_info);\n    }\n    else {  // main executable\n        // Decompress each PT_LOAD.\n        bool first_PF_X = true;\n        phdr = (Elf32_Phdr *) (void *) (1+ ehdr);  // uncompressed\n        for (unsigned j=0; j < u_phnum; ++phdr, ++j) {\n            if (is_LOAD32(phdr)) {\n                unsigned const filesz = get_te32(&phdr->p_filesz);\n                unsigned const offset = get_te32(&phdr->p_offset);\n                if (fo)\n                    fo->seek(offset, SEEK_SET);\n                if (Elf32_Phdr::PF_X & get_te32(&phdr->p_flags)) {\n                    unpackExtent(filesz, fo,\n                        c_adler, u_adler, first_PF_X, szb_info);\n                    first_PF_X = false;\n                }\n                else {\n                    unpackExtent(filesz, fo,\n                        c_adler, u_adler, false, szb_info);\n                }\n            }\n        }\n    }\n    phdr = phdri;\n    load_va = 0;\n    for (unsigned j=0; j < c_phnum; ++j) {\n        if (is_LOAD32(phdr)) {\n            load_va = get_te32(&phdr->p_vaddr);\n            break;\n        }\n    }\n    if (0x1000==get_te32(&phdri[0].p_filesz)  // detect C_BASE style\n    &&  0==get_te32(&phdri[1].p_offset)\n    &&  0==get_te32(&phdri[0].p_offset)\n    &&     get_te32(&phdri[1].p_filesz) == get_te32(&phdri[1].p_memsz)) {\n        fi->seek(up4(get_te32(&phdr[1].p_memsz)), SEEK_SET);  // past the loader\n    }\n    else if (is_shlib\n    ||  ((unsigned)(get_te32(&ehdri.e_entry) - load_va) + up4(lsize) +\n                ph.getPackHeaderSize() + sizeof(overlay_offset))\n            < up4(file_size)) {\n        // Loader is not at end; skip past it.\n        funpad4(fi);  // MATCH01\n        unsigned d_info[4]; fi->readx(d_info, sizeof(d_info));\n        if (0==old_dtinit) {\n            old_dtinit = get_te32(&d_info[2 + (0==d_info[0])]);\n            is_asl = 1u& get_te32(&d_info[0 + (0==d_info[0])]);\n        }\n        fi->seek(lsize - sizeof(d_info), SEEK_CUR);\n    }\n\n    // The gaps between PT_LOAD and after last PT_LOAD\n    phdr = (Elf32_Phdr *)&u[sizeof(*ehdr)];\n    unsigned hi_offset(0);\n    for (unsigned j = 0; j < u_phnum; ++j) {\n        unsigned offset = get_te32(&phdr[j].p_offset);\n        if (is_LOAD32(&phdr[j])\n        &&  hi_offset < offset)\n            hi_offset = offset;\n    }\n    for (unsigned j = 0; j < u_phnum; ++j) {\n        unsigned const size = find_LOAD_gap(phdr, j, u_phnum);\n        if (size) {\n            unsigned const offset = get_te32(&phdr[j].p_offset);\n            unsigned const where =  get_te32(&phdr[j].p_filesz) + offset;\n            if (fo)\n                fo->seek(where, SEEK_SET);\n            unpackExtent(size, fo,\n                c_adler, u_adler, false, szb_info,\n                is_shlib && (offset != hi_offset));\n                // FIXME: should not depend on is_shlib ?\n        }\n    }\n\n    // check for end-of-file\n    fi->readx(&bhdr, szb_info);\n    unsigned const sz_unc = ph.u_len = get_te32(&bhdr.sz_unc);\n\n    if (sz_unc == 0) { // uncompressed size 0 -> EOF\n        // note: magic is always stored le32\n        unsigned const sz_cpr = get_le32(&bhdr.sz_cpr);\n        if (sz_cpr != UPX_MAGIC_LE32)  // sz_cpr must be h->magic\n            throwCompressedDataViolation();\n    }\n    else { // extra bytes after end?\n        throwCompressedDataViolation();\n    }\n\n    if (is_shlib) {\n        // DT_INIT must be restored.\n        // If android_shlib, then the asl_delta relocations must be un-done.\n        int n_ptload = 0;\n        unsigned load_off = 0;\n        phdr = (Elf32_Phdr *)&u[sizeof(*ehdr)];\n        for (unsigned j= 0; j < u_phnum; ++j, ++phdr) {\n            if (is_LOAD32(phdr) && 0!=n_ptload++) {\n                load_off = get_te32(&phdr->p_offset);\n                load_va  = get_te32(&phdr->p_vaddr);\n                fi->seek(old_data_off, SEEK_SET);\n                fi->readx(ibuf, old_data_len);\n                total_in  += old_data_len;\n                total_out += old_data_len;\n\n                Elf32_Phdr const *udynhdr = (Elf32_Phdr *)&u[sizeof(*ehdr)];\n                for (unsigned j3= 0; j3 < u_phnum; ++j3, ++udynhdr)\n                if (Elf32_Phdr::PT_DYNAMIC==get_te32(&udynhdr->p_type)) {\n                    unsigned dt_pltrelsz(0), dt_jmprel(0);\n                    unsigned dt_relsz(0), dt_rel(0);\n                    unsigned const dyn_len = get_te32(&udynhdr->p_filesz);\n                    unsigned const dyn_off = get_te32(&udynhdr->p_offset);\n                    if ((unsigned long)file_size < (dyn_len + dyn_off)) {\n                        char msg[50]; snprintf(msg, sizeof(msg),\n                                \"bad PT_DYNAMIC .p_filesz %#x\", dyn_len);\n                        throwCantUnpack(msg);\n                    }\n                    if (dyn_off < load_off) {\n                        continue;  // Oops.  Not really is_shlib ?  [built by 'rust' ?]\n                    }\n                    Elf32_Dyn *dyn = (Elf32_Dyn *)((unsigned char *)ibuf +\n                        (dyn_off - load_off));\n                    dynseg = dyn; invert_pt_dynamic(dynseg,\n                        umin(dyn_len, file_size - dyn_off));\n                    for (unsigned j2= 0; j2 < dyn_len; ++dyn, j2 += sizeof(*dyn)) {\n                        unsigned const tag = get_te32(&dyn->d_tag);\n                        unsigned       val = get_te32(&dyn->d_val);\n                        if (is_asl) switch (tag) {\n                        case Elf32_Dyn::DT_RELSZ:    { dt_relsz    = val; } break;\n                        case Elf32_Dyn::DT_REL:      { dt_rel      = val; } break;\n                        case Elf32_Dyn::DT_PLTRELSZ: { dt_pltrelsz = val; } break;\n                        case Elf32_Dyn::DT_JMPREL:   { dt_jmprel   = val; } break;\n\n                        case Elf32_Dyn::DT_PLTGOT:\n                        case Elf32_Dyn::DT_PREINIT_ARRAY:\n                        case Elf32_Dyn::DT_INIT_ARRAY:\n                        case Elf32_Dyn::DT_FINI_ARRAY:\n                        case Elf32_Dyn::DT_FINI: {\n                            set_te32(&dyn->d_val, val -= asl_delta);\n                        }; break;\n                        } // end switch()\n                        if (upx_dt_init == tag) {\n                            if (Elf32_Dyn::DT_INIT == tag) {\n                                set_te32(&dyn->d_val, old_dtinit);\n                                if (!old_dtinit) { // compressor took the slot\n                                    dyn->d_tag = Elf32_Dyn::DT_NULL;\n                                    dyn->d_val = 0;\n                                }\n                            }\n                            else if (Elf32_Dyn::DT_INIT_ARRAY    == tag\n                            ||       Elf32_Dyn::DT_PREINIT_ARRAY == tag) {\n                                if (val < load_va || (unsigned)file_size < (unsigned)val) {\n                                    char msg[50]; snprintf(msg, sizeof(msg),\n                                            \"Bad Dynamic tag %#x %#x\",\n                                            (unsigned)tag, (unsigned)val);\n                                    throwCantUnpack(msg);\n                                }\n                                set_te32(&ibuf[val - load_va], old_dtinit\n                                    + (is_asl ? asl_delta : 0));  // counter-act unRel32\n                            }\n                        }\n                        // Modified DT_*.d_val are re-written later from ibuf[]\n                    }\n                    if (is_asl) {\n                        lowmem.alloc(xct_off);\n                        fi->seek(0, SEEK_SET);\n                        fi->read(lowmem, xct_off);  // contains relocation tables\n                        if (dt_relsz && dt_rel) {\n                            Elf32_Rel *const rel0 = (Elf32_Rel *)lowmem.subref(\n                                \"bad Rel offset\", dt_rel, dt_relsz);\n                            unRel32(dt_rel, rel0, dt_relsz, ibuf, load_va, fo);\n                        }\n                        if (dt_pltrelsz && dt_jmprel) { // FIXME:  overlap w/ DT_REL ?\n                            Elf32_Rel *const jmp0 = (Elf32_Rel *)lowmem.subref(\n                                \"bad Jmprel offset\", dt_jmprel, dt_pltrelsz);\n                            unRel32(dt_jmprel, jmp0, dt_pltrelsz, ibuf, load_va, fo);\n                        }\n                        // Modified relocation tables are re-written by unRel32\n                    }\n                }\n                if (fo) {\n                    fo->seek(get_te32(&phdr->p_offset), SEEK_SET);\n                    fo->rewrite(ibuf, old_data_len);\n                }\n            }\n        }\n    }\n\n    // update header with totals\n    ph.c_len = total_in;\n    ph.u_len = total_out;\n\n    // all bytes must be written\n    if (fo && total_out != orig_file_size)\n        throwEOFException();\n\n    // finally test the checksums\n    if (ph.c_adler != c_adler || ph.u_adler != u_adler)\n        throwChecksumError();\n}\n\nvoid PackLinuxElf::unpack(OutputFile * /*fo*/)\n{\n    throwCantUnpack(\"internal error\");\n}\n\n/* vim:set ts=4 sw=4 et: */\n"], "filenames": ["src/p_lx_elf.cpp"], "buggy_code_start_loc": [259], "buggy_code_end_loc": [5784], "fixing_code_start_loc": [259], "fixing_code_end_loc": [5786], "type": "CWE-119", "message": "A Segmentation fault was found in UPX in PackLinuxElf64::invert_pt_dynamic() in p_lx_elf.cpp. An attacker with a crafted input file allows invalid memory address access that could lead to a denial of service.", "other": {"cve": {"id": "CVE-2023-23457", "sourceIdentifier": "patrick@puiterwijk.org", "published": "2023-01-12T19:15:24.810", "lastModified": "2023-01-23T15:06:17.923", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A Segmentation fault was found in UPX in PackLinuxElf64::invert_pt_dynamic() in p_lx_elf.cpp. An attacker with a crafted input file allows invalid memory address access that could lead to a denial of service."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-119"}]}, {"source": "patrick@puiterwijk.org", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-119"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:upx_project:upx:*:*:*:*:*:*:*:*", "versionEndExcluding": "2022-11-23", "matchCriteriaId": "191334EB-C1FD-4A4C-A48A-139452FD5DF4"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:36:*:*:*:*:*:*:*", "matchCriteriaId": "5C675112-476C-4D7C-BCB9-A2FB2D0BC9FD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:37:*:*:*:*:*:*:*", "matchCriteriaId": "E30D0E6F-4AE8-4284-8716-991DFA48CC5D"}]}]}], "references": [{"url": "https://bugzilla.redhat.com/show_bug.cgi?id=2160382", "source": "patrick@puiterwijk.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/upx/upx/commit/779b648c5f6aa9b33f4728f79dd4d0efec0bf860", "source": "patrick@puiterwijk.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/upx/upx/issues/631", "source": "patrick@puiterwijk.org", "tags": ["Exploit", "Patch", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/EL3BVKIGG3SH6I3KPOYQAWCBD4UMPOPI/", "source": "patrick@puiterwijk.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/TGEP3FBNRZXGLIA2B2ICMB32JVMPREFZ/", "source": "patrick@puiterwijk.org", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/upx/upx/commit/779b648c5f6aa9b33f4728f79dd4d0efec0bf860"}}
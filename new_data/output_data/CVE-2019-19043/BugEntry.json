{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0\n/* Copyright(c) 2013 - 2018 Intel Corporation. */\n\n#include <linux/etherdevice.h>\n#include <linux/of_net.h>\n#include <linux/pci.h>\n#include <linux/bpf.h>\n\n/* Local includes */\n#include \"i40e.h\"\n#include \"i40e_diag.h\"\n#include \"i40e_xsk.h\"\n#include <net/udp_tunnel.h>\n#include <net/xdp_sock.h>\n/* All i40e tracepoints are defined by the include below, which\n * must be included exactly once across the whole kernel with\n * CREATE_TRACE_POINTS defined\n */\n#define CREATE_TRACE_POINTS\n#include \"i40e_trace.h\"\n\nconst char i40e_driver_name[] = \"i40e\";\nstatic const char i40e_driver_string[] =\n\t\t\t\"Intel(R) Ethernet Connection XL710 Network Driver\";\n\n#define DRV_KERN \"-k\"\n\n#define DRV_VERSION_MAJOR 2\n#define DRV_VERSION_MINOR 8\n#define DRV_VERSION_BUILD 20\n#define DRV_VERSION __stringify(DRV_VERSION_MAJOR) \".\" \\\n\t     __stringify(DRV_VERSION_MINOR) \".\" \\\n\t     __stringify(DRV_VERSION_BUILD)    DRV_KERN\nconst char i40e_driver_version_str[] = DRV_VERSION;\nstatic const char i40e_copyright[] = \"Copyright (c) 2013 - 2019 Intel Corporation.\";\n\n/* a bit of forward declarations */\nstatic void i40e_vsi_reinit_locked(struct i40e_vsi *vsi);\nstatic void i40e_handle_reset_warning(struct i40e_pf *pf, bool lock_acquired);\nstatic int i40e_add_vsi(struct i40e_vsi *vsi);\nstatic int i40e_add_veb(struct i40e_veb *veb, struct i40e_vsi *vsi);\nstatic int i40e_setup_pf_switch(struct i40e_pf *pf, bool reinit);\nstatic int i40e_setup_misc_vector(struct i40e_pf *pf);\nstatic void i40e_determine_queue_usage(struct i40e_pf *pf);\nstatic int i40e_setup_pf_filter_control(struct i40e_pf *pf);\nstatic void i40e_prep_for_reset(struct i40e_pf *pf, bool lock_acquired);\nstatic int i40e_reset(struct i40e_pf *pf);\nstatic void i40e_rebuild(struct i40e_pf *pf, bool reinit, bool lock_acquired);\nstatic int i40e_setup_misc_vector_for_recovery_mode(struct i40e_pf *pf);\nstatic int i40e_restore_interrupt_scheme(struct i40e_pf *pf);\nstatic bool i40e_check_recovery_mode(struct i40e_pf *pf);\nstatic int i40e_init_recovery_mode(struct i40e_pf *pf, struct i40e_hw *hw);\nstatic void i40e_fdir_sb_setup(struct i40e_pf *pf);\nstatic int i40e_veb_get_bw_info(struct i40e_veb *veb);\nstatic int i40e_get_capabilities(struct i40e_pf *pf,\n\t\t\t\t enum i40e_admin_queue_opc list_type);\n\n\n/* i40e_pci_tbl - PCI Device ID Table\n *\n * Last entry must be all 0s\n *\n * { Vendor ID, Device ID, SubVendor ID, SubDevice ID,\n *   Class, Class Mask, private data (not used) }\n */\nstatic const struct pci_device_id i40e_pci_tbl[] = {\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_SFP_XL710), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QEMU), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_KX_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_KX_C), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_A), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_C), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T4), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T_BC), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_SFP), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_KX_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_SFP_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_1G_BASE_T_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_SFP_I_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_20G_KR2), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_20G_KR2_A), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_X710_N3000), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_XXV710_N3000), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_25G_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_25G_SFP28), 0},\n\t/* required last entry */\n\t{0, }\n};\nMODULE_DEVICE_TABLE(pci, i40e_pci_tbl);\n\n#define I40E_MAX_VF_COUNT 128\nstatic int debug = -1;\nmodule_param(debug, uint, 0);\nMODULE_PARM_DESC(debug, \"Debug level (0=none,...,16=all), Debug mask (0x8XXXXXXX)\");\n\nMODULE_AUTHOR(\"Intel Corporation, <e1000-devel@lists.sourceforge.net>\");\nMODULE_DESCRIPTION(\"Intel(R) Ethernet Connection XL710 Network Driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_VERSION(DRV_VERSION);\n\nstatic struct workqueue_struct *i40e_wq;\n\n/**\n * i40e_allocate_dma_mem_d - OS specific memory alloc for shared code\n * @hw:   pointer to the HW structure\n * @mem:  ptr to mem struct to fill out\n * @size: size of memory requested\n * @alignment: what to align the allocation to\n **/\nint i40e_allocate_dma_mem_d(struct i40e_hw *hw, struct i40e_dma_mem *mem,\n\t\t\t    u64 size, u32 alignment)\n{\n\tstruct i40e_pf *pf = (struct i40e_pf *)hw->back;\n\n\tmem->size = ALIGN(size, alignment);\n\tmem->va = dma_alloc_coherent(&pf->pdev->dev, mem->size, &mem->pa,\n\t\t\t\t     GFP_KERNEL);\n\tif (!mem->va)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n/**\n * i40e_free_dma_mem_d - OS specific memory free for shared code\n * @hw:   pointer to the HW structure\n * @mem:  ptr to mem struct to free\n **/\nint i40e_free_dma_mem_d(struct i40e_hw *hw, struct i40e_dma_mem *mem)\n{\n\tstruct i40e_pf *pf = (struct i40e_pf *)hw->back;\n\n\tdma_free_coherent(&pf->pdev->dev, mem->size, mem->va, mem->pa);\n\tmem->va = NULL;\n\tmem->pa = 0;\n\tmem->size = 0;\n\n\treturn 0;\n}\n\n/**\n * i40e_allocate_virt_mem_d - OS specific memory alloc for shared code\n * @hw:   pointer to the HW structure\n * @mem:  ptr to mem struct to fill out\n * @size: size of memory requested\n **/\nint i40e_allocate_virt_mem_d(struct i40e_hw *hw, struct i40e_virt_mem *mem,\n\t\t\t     u32 size)\n{\n\tmem->size = size;\n\tmem->va = kzalloc(size, GFP_KERNEL);\n\n\tif (!mem->va)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n/**\n * i40e_free_virt_mem_d - OS specific memory free for shared code\n * @hw:   pointer to the HW structure\n * @mem:  ptr to mem struct to free\n **/\nint i40e_free_virt_mem_d(struct i40e_hw *hw, struct i40e_virt_mem *mem)\n{\n\t/* it's ok to kfree a NULL pointer */\n\tkfree(mem->va);\n\tmem->va = NULL;\n\tmem->size = 0;\n\n\treturn 0;\n}\n\n/**\n * i40e_get_lump - find a lump of free generic resource\n * @pf: board private structure\n * @pile: the pile of resource to search\n * @needed: the number of items needed\n * @id: an owner id to stick on the items assigned\n *\n * Returns the base item index of the lump, or negative for error\n *\n * The search_hint trick and lack of advanced fit-finding only work\n * because we're highly likely to have all the same size lump requests.\n * Linear search time and any fragmentation should be minimal.\n **/\nstatic int i40e_get_lump(struct i40e_pf *pf, struct i40e_lump_tracking *pile,\n\t\t\t u16 needed, u16 id)\n{\n\tint ret = -ENOMEM;\n\tint i, j;\n\n\tif (!pile || needed == 0 || id >= I40E_PILE_VALID_BIT) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"param err: pile=%s needed=%d id=0x%04x\\n\",\n\t\t\t pile ? \"<valid>\" : \"<null>\", needed, id);\n\t\treturn -EINVAL;\n\t}\n\n\t/* start the linear search with an imperfect hint */\n\ti = pile->search_hint;\n\twhile (i < pile->num_entries) {\n\t\t/* skip already allocated entries */\n\t\tif (pile->list[i] & I40E_PILE_VALID_BIT) {\n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* do we have enough in this lump? */\n\t\tfor (j = 0; (j < needed) && ((i+j) < pile->num_entries); j++) {\n\t\t\tif (pile->list[i+j] & I40E_PILE_VALID_BIT)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (j == needed) {\n\t\t\t/* there was enough, so assign it to the requestor */\n\t\t\tfor (j = 0; j < needed; j++)\n\t\t\t\tpile->list[i+j] = id | I40E_PILE_VALID_BIT;\n\t\t\tret = i;\n\t\t\tpile->search_hint = i + j;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* not enough, so skip over it and continue looking */\n\t\ti += j;\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_put_lump - return a lump of generic resource\n * @pile: the pile of resource to search\n * @index: the base item index\n * @id: the owner id of the items assigned\n *\n * Returns the count of items in the lump\n **/\nstatic int i40e_put_lump(struct i40e_lump_tracking *pile, u16 index, u16 id)\n{\n\tint valid_id = (id | I40E_PILE_VALID_BIT);\n\tint count = 0;\n\tint i;\n\n\tif (!pile || index >= pile->num_entries)\n\t\treturn -EINVAL;\n\n\tfor (i = index;\n\t     i < pile->num_entries && pile->list[i] == valid_id;\n\t     i++) {\n\t\tpile->list[i] = 0;\n\t\tcount++;\n\t}\n\n\tif (count && index < pile->search_hint)\n\t\tpile->search_hint = index;\n\n\treturn count;\n}\n\n/**\n * i40e_find_vsi_from_id - searches for the vsi with the given id\n * @pf: the pf structure to search for the vsi\n * @id: id of the vsi it is searching for\n **/\nstruct i40e_vsi *i40e_find_vsi_from_id(struct i40e_pf *pf, u16 id)\n{\n\tint i;\n\n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i] && (pf->vsi[i]->id == id))\n\t\t\treturn pf->vsi[i];\n\n\treturn NULL;\n}\n\n/**\n * i40e_service_event_schedule - Schedule the service task to wake up\n * @pf: board private structure\n *\n * If not already scheduled, this puts the task into the work queue\n **/\nvoid i40e_service_event_schedule(struct i40e_pf *pf)\n{\n\tif ((!test_bit(__I40E_DOWN, pf->state) &&\n\t     !test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state)) ||\n\t      test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\tqueue_work(i40e_wq, &pf->service_task);\n}\n\n/**\n * i40e_tx_timeout - Respond to a Tx Hang\n * @netdev: network interface device structure\n *\n * If any port has noticed a Tx timeout, it is likely that the whole\n * device is munged, not just the one netdev port, so go for the full\n * reset.\n **/\nstatic void i40e_tx_timeout(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_ring *tx_ring = NULL;\n\tunsigned int i, hung_queue = 0;\n\tu32 head, val;\n\n\tpf->tx_timeout_count++;\n\n\t/* find the stopped queue the same way the stack does */\n\tfor (i = 0; i < netdev->num_tx_queues; i++) {\n\t\tstruct netdev_queue *q;\n\t\tunsigned long trans_start;\n\n\t\tq = netdev_get_tx_queue(netdev, i);\n\t\ttrans_start = q->trans_start;\n\t\tif (netif_xmit_stopped(q) &&\n\t\t    time_after(jiffies,\n\t\t\t       (trans_start + netdev->watchdog_timeo))) {\n\t\t\thung_queue = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == netdev->num_tx_queues) {\n\t\tnetdev_info(netdev, \"tx_timeout: no netdev hung queue found\\n\");\n\t} else {\n\t\t/* now that we have an index, find the tx_ring struct */\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\t\tif (vsi->tx_rings[i] && vsi->tx_rings[i]->desc) {\n\t\t\t\tif (hung_queue ==\n\t\t\t\t    vsi->tx_rings[i]->queue_index) {\n\t\t\t\t\ttx_ring = vsi->tx_rings[i];\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (time_after(jiffies, (pf->tx_timeout_last_recovery + HZ*20)))\n\t\tpf->tx_timeout_recovery_level = 1;  /* reset after some time */\n\telse if (time_before(jiffies,\n\t\t      (pf->tx_timeout_last_recovery + netdev->watchdog_timeo)))\n\t\treturn;   /* don't do any new action before the next timeout */\n\n\t/* don't kick off another recovery if one is already pending */\n\tif (test_and_set_bit(__I40E_TIMEOUT_RECOVERY_PENDING, pf->state))\n\t\treturn;\n\n\tif (tx_ring) {\n\t\thead = i40e_get_head(tx_ring);\n\t\t/* Read interrupt register */\n\t\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\t\tval = rd32(&pf->hw,\n\t\t\t     I40E_PFINT_DYN_CTLN(tx_ring->q_vector->v_idx +\n\t\t\t\t\t\ttx_ring->vsi->base_vector - 1));\n\t\telse\n\t\t\tval = rd32(&pf->hw, I40E_PFINT_DYN_CTL0);\n\n\t\tnetdev_info(netdev, \"tx_timeout: VSI_seid: %d, Q %d, NTC: 0x%x, HWB: 0x%x, NTU: 0x%x, TAIL: 0x%x, INT: 0x%x\\n\",\n\t\t\t    vsi->seid, hung_queue, tx_ring->next_to_clean,\n\t\t\t    head, tx_ring->next_to_use,\n\t\t\t    readl(tx_ring->tail), val);\n\t}\n\n\tpf->tx_timeout_last_recovery = jiffies;\n\tnetdev_info(netdev, \"tx_timeout recovery level %d, hung_queue %d\\n\",\n\t\t    pf->tx_timeout_recovery_level, hung_queue);\n\n\tswitch (pf->tx_timeout_recovery_level) {\n\tcase 1:\n\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\tbreak;\n\tcase 2:\n\t\tset_bit(__I40E_CORE_RESET_REQUESTED, pf->state);\n\t\tbreak;\n\tcase 3:\n\t\tset_bit(__I40E_GLOBAL_RESET_REQUESTED, pf->state);\n\t\tbreak;\n\tdefault:\n\t\tnetdev_err(netdev, \"tx_timeout recovery unsuccessful\\n\");\n\t\tbreak;\n\t}\n\n\ti40e_service_event_schedule(pf);\n\tpf->tx_timeout_recovery_level++;\n}\n\n/**\n * i40e_get_vsi_stats_struct - Get System Network Statistics\n * @vsi: the VSI we care about\n *\n * Returns the address of the device statistics structure.\n * The statistics are actually updated from the service task.\n **/\nstruct rtnl_link_stats64 *i40e_get_vsi_stats_struct(struct i40e_vsi *vsi)\n{\n\treturn &vsi->net_stats;\n}\n\n/**\n * i40e_get_netdev_stats_struct_tx - populate stats from a Tx ring\n * @ring: Tx ring to get statistics from\n * @stats: statistics entry to be updated\n **/\nstatic void i40e_get_netdev_stats_struct_tx(struct i40e_ring *ring,\n\t\t\t\t\t    struct rtnl_link_stats64 *stats)\n{\n\tu64 bytes, packets;\n\tunsigned int start;\n\n\tdo {\n\t\tstart = u64_stats_fetch_begin_irq(&ring->syncp);\n\t\tpackets = ring->stats.packets;\n\t\tbytes   = ring->stats.bytes;\n\t} while (u64_stats_fetch_retry_irq(&ring->syncp, start));\n\n\tstats->tx_packets += packets;\n\tstats->tx_bytes   += bytes;\n}\n\n/**\n * i40e_get_netdev_stats_struct - Get statistics for netdev interface\n * @netdev: network interface device structure\n * @stats: data structure to store statistics\n *\n * Returns the address of the device statistics structure.\n * The statistics are actually updated from the service task.\n **/\nstatic void i40e_get_netdev_stats_struct(struct net_device *netdev,\n\t\t\t\t  struct rtnl_link_stats64 *stats)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct rtnl_link_stats64 *vsi_stats = i40e_get_vsi_stats_struct(vsi);\n\tstruct i40e_ring *ring;\n\tint i;\n\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tif (!vsi->tx_rings)\n\t\treturn;\n\n\trcu_read_lock();\n\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\tu64 bytes, packets;\n\t\tunsigned int start;\n\n\t\tring = READ_ONCE(vsi->tx_rings[i]);\n\t\tif (!ring)\n\t\t\tcontinue;\n\t\ti40e_get_netdev_stats_struct_tx(ring, stats);\n\n\t\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t\tring++;\n\t\t\ti40e_get_netdev_stats_struct_tx(ring, stats);\n\t\t}\n\n\t\tring++;\n\t\tdo {\n\t\t\tstart   = u64_stats_fetch_begin_irq(&ring->syncp);\n\t\t\tpackets = ring->stats.packets;\n\t\t\tbytes   = ring->stats.bytes;\n\t\t} while (u64_stats_fetch_retry_irq(&ring->syncp, start));\n\n\t\tstats->rx_packets += packets;\n\t\tstats->rx_bytes   += bytes;\n\n\t}\n\trcu_read_unlock();\n\n\t/* following stats updated by i40e_watchdog_subtask() */\n\tstats->multicast\t= vsi_stats->multicast;\n\tstats->tx_errors\t= vsi_stats->tx_errors;\n\tstats->tx_dropped\t= vsi_stats->tx_dropped;\n\tstats->rx_errors\t= vsi_stats->rx_errors;\n\tstats->rx_dropped\t= vsi_stats->rx_dropped;\n\tstats->rx_crc_errors\t= vsi_stats->rx_crc_errors;\n\tstats->rx_length_errors\t= vsi_stats->rx_length_errors;\n}\n\n/**\n * i40e_vsi_reset_stats - Resets all stats of the given vsi\n * @vsi: the VSI to have its stats reset\n **/\nvoid i40e_vsi_reset_stats(struct i40e_vsi *vsi)\n{\n\tstruct rtnl_link_stats64 *ns;\n\tint i;\n\n\tif (!vsi)\n\t\treturn;\n\n\tns = i40e_get_vsi_stats_struct(vsi);\n\tmemset(ns, 0, sizeof(*ns));\n\tmemset(&vsi->net_stats_offsets, 0, sizeof(vsi->net_stats_offsets));\n\tmemset(&vsi->eth_stats, 0, sizeof(vsi->eth_stats));\n\tmemset(&vsi->eth_stats_offsets, 0, sizeof(vsi->eth_stats_offsets));\n\tif (vsi->rx_rings && vsi->rx_rings[0]) {\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\t\tmemset(&vsi->rx_rings[i]->stats, 0,\n\t\t\t       sizeof(vsi->rx_rings[i]->stats));\n\t\t\tmemset(&vsi->rx_rings[i]->rx_stats, 0,\n\t\t\t       sizeof(vsi->rx_rings[i]->rx_stats));\n\t\t\tmemset(&vsi->tx_rings[i]->stats, 0,\n\t\t\t       sizeof(vsi->tx_rings[i]->stats));\n\t\t\tmemset(&vsi->tx_rings[i]->tx_stats, 0,\n\t\t\t       sizeof(vsi->tx_rings[i]->tx_stats));\n\t\t}\n\t}\n\tvsi->stat_offsets_loaded = false;\n}\n\n/**\n * i40e_pf_reset_stats - Reset all of the stats for the given PF\n * @pf: the PF to be reset\n **/\nvoid i40e_pf_reset_stats(struct i40e_pf *pf)\n{\n\tint i;\n\n\tmemset(&pf->stats, 0, sizeof(pf->stats));\n\tmemset(&pf->stats_offsets, 0, sizeof(pf->stats_offsets));\n\tpf->stat_offsets_loaded = false;\n\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (pf->veb[i]) {\n\t\t\tmemset(&pf->veb[i]->stats, 0,\n\t\t\t       sizeof(pf->veb[i]->stats));\n\t\t\tmemset(&pf->veb[i]->stats_offsets, 0,\n\t\t\t       sizeof(pf->veb[i]->stats_offsets));\n\t\t\tmemset(&pf->veb[i]->tc_stats, 0,\n\t\t\t       sizeof(pf->veb[i]->tc_stats));\n\t\t\tmemset(&pf->veb[i]->tc_stats_offsets, 0,\n\t\t\t       sizeof(pf->veb[i]->tc_stats_offsets));\n\t\t\tpf->veb[i]->stat_offsets_loaded = false;\n\t\t}\n\t}\n\tpf->hw_csum_rx_error = 0;\n}\n\n/**\n * i40e_stat_update48 - read and update a 48 bit stat from the chip\n * @hw: ptr to the hardware info\n * @hireg: the high 32 bit reg to read\n * @loreg: the low 32 bit reg to read\n * @offset_loaded: has the initial offset been loaded yet\n * @offset: ptr to current offset value\n * @stat: ptr to the stat\n *\n * Since the device stats are not reset at PFReset, they likely will not\n * be zeroed when the driver starts.  We'll save the first values read\n * and use them as offsets to be subtracted from the raw values in order\n * to report stats that count from zero.  In the process, we also manage\n * the potential roll-over.\n **/\nstatic void i40e_stat_update48(struct i40e_hw *hw, u32 hireg, u32 loreg,\n\t\t\t       bool offset_loaded, u64 *offset, u64 *stat)\n{\n\tu64 new_data;\n\n\tif (hw->device_id == I40E_DEV_ID_QEMU) {\n\t\tnew_data = rd32(hw, loreg);\n\t\tnew_data |= ((u64)(rd32(hw, hireg) & 0xFFFF)) << 32;\n\t} else {\n\t\tnew_data = rd64(hw, loreg);\n\t}\n\tif (!offset_loaded)\n\t\t*offset = new_data;\n\tif (likely(new_data >= *offset))\n\t\t*stat = new_data - *offset;\n\telse\n\t\t*stat = (new_data + BIT_ULL(48)) - *offset;\n\t*stat &= 0xFFFFFFFFFFFFULL;\n}\n\n/**\n * i40e_stat_update32 - read and update a 32 bit stat from the chip\n * @hw: ptr to the hardware info\n * @reg: the hw reg to read\n * @offset_loaded: has the initial offset been loaded yet\n * @offset: ptr to current offset value\n * @stat: ptr to the stat\n **/\nstatic void i40e_stat_update32(struct i40e_hw *hw, u32 reg,\n\t\t\t       bool offset_loaded, u64 *offset, u64 *stat)\n{\n\tu32 new_data;\n\n\tnew_data = rd32(hw, reg);\n\tif (!offset_loaded)\n\t\t*offset = new_data;\n\tif (likely(new_data >= *offset))\n\t\t*stat = (u32)(new_data - *offset);\n\telse\n\t\t*stat = (u32)((new_data + BIT_ULL(32)) - *offset);\n}\n\n/**\n * i40e_stat_update_and_clear32 - read and clear hw reg, update a 32 bit stat\n * @hw: ptr to the hardware info\n * @reg: the hw reg to read and clear\n * @stat: ptr to the stat\n **/\nstatic void i40e_stat_update_and_clear32(struct i40e_hw *hw, u32 reg, u64 *stat)\n{\n\tu32 new_data = rd32(hw, reg);\n\n\twr32(hw, reg, 1); /* must write a nonzero value to clear register */\n\t*stat += new_data;\n}\n\n/**\n * i40e_update_eth_stats - Update VSI-specific ethernet statistics counters.\n * @vsi: the VSI to be updated\n **/\nvoid i40e_update_eth_stats(struct i40e_vsi *vsi)\n{\n\tint stat_idx = le16_to_cpu(vsi->info.stat_counter_idx);\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_eth_stats *oes;\n\tstruct i40e_eth_stats *es;     /* device's eth stats */\n\n\tes = &vsi->eth_stats;\n\toes = &vsi->eth_stats_offsets;\n\n\t/* Gather up the stats that the hw collects */\n\ti40e_stat_update32(hw, I40E_GLV_TEPC(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_errors, &es->tx_errors);\n\ti40e_stat_update32(hw, I40E_GLV_RDPC(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_discards, &es->rx_discards);\n\ti40e_stat_update32(hw, I40E_GLV_RUPP(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_unknown_protocol, &es->rx_unknown_protocol);\n\n\ti40e_stat_update48(hw, I40E_GLV_GORCH(stat_idx),\n\t\t\t   I40E_GLV_GORCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_bytes, &es->rx_bytes);\n\ti40e_stat_update48(hw, I40E_GLV_UPRCH(stat_idx),\n\t\t\t   I40E_GLV_UPRCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_unicast, &es->rx_unicast);\n\ti40e_stat_update48(hw, I40E_GLV_MPRCH(stat_idx),\n\t\t\t   I40E_GLV_MPRCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_multicast, &es->rx_multicast);\n\ti40e_stat_update48(hw, I40E_GLV_BPRCH(stat_idx),\n\t\t\t   I40E_GLV_BPRCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_broadcast, &es->rx_broadcast);\n\n\ti40e_stat_update48(hw, I40E_GLV_GOTCH(stat_idx),\n\t\t\t   I40E_GLV_GOTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_bytes, &es->tx_bytes);\n\ti40e_stat_update48(hw, I40E_GLV_UPTCH(stat_idx),\n\t\t\t   I40E_GLV_UPTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_unicast, &es->tx_unicast);\n\ti40e_stat_update48(hw, I40E_GLV_MPTCH(stat_idx),\n\t\t\t   I40E_GLV_MPTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_multicast, &es->tx_multicast);\n\ti40e_stat_update48(hw, I40E_GLV_BPTCH(stat_idx),\n\t\t\t   I40E_GLV_BPTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_broadcast, &es->tx_broadcast);\n\tvsi->stat_offsets_loaded = true;\n}\n\n/**\n * i40e_update_veb_stats - Update Switch component statistics\n * @veb: the VEB being updated\n **/\nvoid i40e_update_veb_stats(struct i40e_veb *veb)\n{\n\tstruct i40e_pf *pf = veb->pf;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_eth_stats *oes;\n\tstruct i40e_eth_stats *es;     /* device's eth stats */\n\tstruct i40e_veb_tc_stats *veb_oes;\n\tstruct i40e_veb_tc_stats *veb_es;\n\tint i, idx = 0;\n\n\tidx = veb->stats_idx;\n\tes = &veb->stats;\n\toes = &veb->stats_offsets;\n\tveb_es = &veb->tc_stats;\n\tveb_oes = &veb->tc_stats_offsets;\n\n\t/* Gather up the stats that the hw collects */\n\ti40e_stat_update32(hw, I40E_GLSW_TDPC(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_discards, &es->tx_discards);\n\tif (hw->revision_id > 0)\n\t\ti40e_stat_update32(hw, I40E_GLSW_RUPP(idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &oes->rx_unknown_protocol,\n\t\t\t\t   &es->rx_unknown_protocol);\n\ti40e_stat_update48(hw, I40E_GLSW_GORCH(idx), I40E_GLSW_GORCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_bytes, &es->rx_bytes);\n\ti40e_stat_update48(hw, I40E_GLSW_UPRCH(idx), I40E_GLSW_UPRCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_unicast, &es->rx_unicast);\n\ti40e_stat_update48(hw, I40E_GLSW_MPRCH(idx), I40E_GLSW_MPRCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_multicast, &es->rx_multicast);\n\ti40e_stat_update48(hw, I40E_GLSW_BPRCH(idx), I40E_GLSW_BPRCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_broadcast, &es->rx_broadcast);\n\n\ti40e_stat_update48(hw, I40E_GLSW_GOTCH(idx), I40E_GLSW_GOTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_bytes, &es->tx_bytes);\n\ti40e_stat_update48(hw, I40E_GLSW_UPTCH(idx), I40E_GLSW_UPTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_unicast, &es->tx_unicast);\n\ti40e_stat_update48(hw, I40E_GLSW_MPTCH(idx), I40E_GLSW_MPTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_multicast, &es->tx_multicast);\n\ti40e_stat_update48(hw, I40E_GLSW_BPTCH(idx), I40E_GLSW_BPTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_broadcast, &es->tx_broadcast);\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_RPCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_RPCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_rx_packets[i],\n\t\t\t\t   &veb_es->tc_rx_packets[i]);\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_RBCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_RBCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_rx_bytes[i],\n\t\t\t\t   &veb_es->tc_rx_bytes[i]);\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_TPCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_TPCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_tx_packets[i],\n\t\t\t\t   &veb_es->tc_tx_packets[i]);\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_TBCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_TBCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_tx_bytes[i],\n\t\t\t\t   &veb_es->tc_tx_bytes[i]);\n\t}\n\tveb->stat_offsets_loaded = true;\n}\n\n/**\n * i40e_update_vsi_stats - Update the vsi statistics counters.\n * @vsi: the VSI to be updated\n *\n * There are a few instances where we store the same stat in a\n * couple of different structs.  This is partly because we have\n * the netdev stats that need to be filled out, which is slightly\n * different from the \"eth_stats\" defined by the chip and used in\n * VF communications.  We sort it out here.\n **/\nstatic void i40e_update_vsi_stats(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct rtnl_link_stats64 *ons;\n\tstruct rtnl_link_stats64 *ns;   /* netdev stats */\n\tstruct i40e_eth_stats *oes;\n\tstruct i40e_eth_stats *es;     /* device's eth stats */\n\tu32 tx_restart, tx_busy;\n\tstruct i40e_ring *p;\n\tu32 rx_page, rx_buf;\n\tu64 bytes, packets;\n\tunsigned int start;\n\tu64 tx_linearize;\n\tu64 tx_force_wb;\n\tu64 rx_p, rx_b;\n\tu64 tx_p, tx_b;\n\tu16 q;\n\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state) ||\n\t    test_bit(__I40E_CONFIG_BUSY, pf->state))\n\t\treturn;\n\n\tns = i40e_get_vsi_stats_struct(vsi);\n\tons = &vsi->net_stats_offsets;\n\tes = &vsi->eth_stats;\n\toes = &vsi->eth_stats_offsets;\n\n\t/* Gather up the netdev and vsi stats that the driver collects\n\t * on the fly during packet processing\n\t */\n\trx_b = rx_p = 0;\n\ttx_b = tx_p = 0;\n\ttx_restart = tx_busy = tx_linearize = tx_force_wb = 0;\n\trx_page = 0;\n\trx_buf = 0;\n\trcu_read_lock();\n\tfor (q = 0; q < vsi->num_queue_pairs; q++) {\n\t\t/* locate Tx ring */\n\t\tp = READ_ONCE(vsi->tx_rings[q]);\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin_irq(&p->syncp);\n\t\t\tpackets = p->stats.packets;\n\t\t\tbytes = p->stats.bytes;\n\t\t} while (u64_stats_fetch_retry_irq(&p->syncp, start));\n\t\ttx_b += bytes;\n\t\ttx_p += packets;\n\t\ttx_restart += p->tx_stats.restart_queue;\n\t\ttx_busy += p->tx_stats.tx_busy;\n\t\ttx_linearize += p->tx_stats.tx_linearize;\n\t\ttx_force_wb += p->tx_stats.tx_force_wb;\n\n\t\t/* Rx queue is part of the same block as Tx queue */\n\t\tp = &p[1];\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin_irq(&p->syncp);\n\t\t\tpackets = p->stats.packets;\n\t\t\tbytes = p->stats.bytes;\n\t\t} while (u64_stats_fetch_retry_irq(&p->syncp, start));\n\t\trx_b += bytes;\n\t\trx_p += packets;\n\t\trx_buf += p->rx_stats.alloc_buff_failed;\n\t\trx_page += p->rx_stats.alloc_page_failed;\n\t}\n\trcu_read_unlock();\n\tvsi->tx_restart = tx_restart;\n\tvsi->tx_busy = tx_busy;\n\tvsi->tx_linearize = tx_linearize;\n\tvsi->tx_force_wb = tx_force_wb;\n\tvsi->rx_page_failed = rx_page;\n\tvsi->rx_buf_failed = rx_buf;\n\n\tns->rx_packets = rx_p;\n\tns->rx_bytes = rx_b;\n\tns->tx_packets = tx_p;\n\tns->tx_bytes = tx_b;\n\n\t/* update netdev stats from eth stats */\n\ti40e_update_eth_stats(vsi);\n\tons->tx_errors = oes->tx_errors;\n\tns->tx_errors = es->tx_errors;\n\tons->multicast = oes->rx_multicast;\n\tns->multicast = es->rx_multicast;\n\tons->rx_dropped = oes->rx_discards;\n\tns->rx_dropped = es->rx_discards;\n\tons->tx_dropped = oes->tx_discards;\n\tns->tx_dropped = es->tx_discards;\n\n\t/* pull in a couple PF stats if this is the main vsi */\n\tif (vsi == pf->vsi[pf->lan_vsi]) {\n\t\tns->rx_crc_errors = pf->stats.crc_errors;\n\t\tns->rx_errors = pf->stats.crc_errors + pf->stats.illegal_bytes;\n\t\tns->rx_length_errors = pf->stats.rx_length_errors;\n\t}\n}\n\n/**\n * i40e_update_pf_stats - Update the PF statistics counters.\n * @pf: the PF to be updated\n **/\nstatic void i40e_update_pf_stats(struct i40e_pf *pf)\n{\n\tstruct i40e_hw_port_stats *osd = &pf->stats_offsets;\n\tstruct i40e_hw_port_stats *nsd = &pf->stats;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\tint i;\n\n\ti40e_stat_update48(hw, I40E_GLPRT_GORCH(hw->port),\n\t\t\t   I40E_GLPRT_GORCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_bytes, &nsd->eth.rx_bytes);\n\ti40e_stat_update48(hw, I40E_GLPRT_GOTCH(hw->port),\n\t\t\t   I40E_GLPRT_GOTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_bytes, &nsd->eth.tx_bytes);\n\ti40e_stat_update32(hw, I40E_GLPRT_RDPC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_discards,\n\t\t\t   &nsd->eth.rx_discards);\n\ti40e_stat_update48(hw, I40E_GLPRT_UPRCH(hw->port),\n\t\t\t   I40E_GLPRT_UPRCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_unicast,\n\t\t\t   &nsd->eth.rx_unicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_MPRCH(hw->port),\n\t\t\t   I40E_GLPRT_MPRCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_multicast,\n\t\t\t   &nsd->eth.rx_multicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_BPRCH(hw->port),\n\t\t\t   I40E_GLPRT_BPRCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_broadcast,\n\t\t\t   &nsd->eth.rx_broadcast);\n\ti40e_stat_update48(hw, I40E_GLPRT_UPTCH(hw->port),\n\t\t\t   I40E_GLPRT_UPTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_unicast,\n\t\t\t   &nsd->eth.tx_unicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_MPTCH(hw->port),\n\t\t\t   I40E_GLPRT_MPTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_multicast,\n\t\t\t   &nsd->eth.tx_multicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_BPTCH(hw->port),\n\t\t\t   I40E_GLPRT_BPTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_broadcast,\n\t\t\t   &nsd->eth.tx_broadcast);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_TDOLD(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_dropped_link_down,\n\t\t\t   &nsd->tx_dropped_link_down);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_CRCERRS(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->crc_errors, &nsd->crc_errors);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_ILLERRC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->illegal_bytes, &nsd->illegal_bytes);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_MLFC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->mac_local_faults,\n\t\t\t   &nsd->mac_local_faults);\n\ti40e_stat_update32(hw, I40E_GLPRT_MRFC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->mac_remote_faults,\n\t\t\t   &nsd->mac_remote_faults);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_RLEC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_length_errors,\n\t\t\t   &nsd->rx_length_errors);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_LXONRXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xon_rx, &nsd->link_xon_rx);\n\ti40e_stat_update32(hw, I40E_GLPRT_LXONTXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xon_tx, &nsd->link_xon_tx);\n\ti40e_stat_update32(hw, I40E_GLPRT_LXOFFRXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xoff_rx, &nsd->link_xoff_rx);\n\ti40e_stat_update32(hw, I40E_GLPRT_LXOFFTXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xoff_tx, &nsd->link_xoff_tx);\n\n\tfor (i = 0; i < 8; i++) {\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXOFFRXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xoff_rx[i],\n\t\t\t\t   &nsd->priority_xoff_rx[i]);\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXONRXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xon_rx[i],\n\t\t\t\t   &nsd->priority_xon_rx[i]);\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXONTXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xon_tx[i],\n\t\t\t\t   &nsd->priority_xon_tx[i]);\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXOFFTXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xoff_tx[i],\n\t\t\t\t   &nsd->priority_xoff_tx[i]);\n\t\ti40e_stat_update32(hw,\n\t\t\t\t   I40E_GLPRT_RXON2OFFCNT(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xon_2_xoff[i],\n\t\t\t\t   &nsd->priority_xon_2_xoff[i]);\n\t}\n\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC64H(hw->port),\n\t\t\t   I40E_GLPRT_PRC64L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_64, &nsd->rx_size_64);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC127H(hw->port),\n\t\t\t   I40E_GLPRT_PRC127L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_127, &nsd->rx_size_127);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC255H(hw->port),\n\t\t\t   I40E_GLPRT_PRC255L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_255, &nsd->rx_size_255);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC511H(hw->port),\n\t\t\t   I40E_GLPRT_PRC511L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_511, &nsd->rx_size_511);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC1023H(hw->port),\n\t\t\t   I40E_GLPRT_PRC1023L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_1023, &nsd->rx_size_1023);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC1522H(hw->port),\n\t\t\t   I40E_GLPRT_PRC1522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_1522, &nsd->rx_size_1522);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC9522H(hw->port),\n\t\t\t   I40E_GLPRT_PRC9522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_big, &nsd->rx_size_big);\n\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC64H(hw->port),\n\t\t\t   I40E_GLPRT_PTC64L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_64, &nsd->tx_size_64);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC127H(hw->port),\n\t\t\t   I40E_GLPRT_PTC127L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_127, &nsd->tx_size_127);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC255H(hw->port),\n\t\t\t   I40E_GLPRT_PTC255L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_255, &nsd->tx_size_255);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC511H(hw->port),\n\t\t\t   I40E_GLPRT_PTC511L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_511, &nsd->tx_size_511);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC1023H(hw->port),\n\t\t\t   I40E_GLPRT_PTC1023L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_1023, &nsd->tx_size_1023);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC1522H(hw->port),\n\t\t\t   I40E_GLPRT_PTC1522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_1522, &nsd->tx_size_1522);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC9522H(hw->port),\n\t\t\t   I40E_GLPRT_PTC9522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_big, &nsd->tx_size_big);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_RUC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_undersize, &nsd->rx_undersize);\n\ti40e_stat_update32(hw, I40E_GLPRT_RFC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_fragments, &nsd->rx_fragments);\n\ti40e_stat_update32(hw, I40E_GLPRT_ROC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_oversize, &nsd->rx_oversize);\n\ti40e_stat_update32(hw, I40E_GLPRT_RJC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_jabber, &nsd->rx_jabber);\n\n\t/* FDIR stats */\n\ti40e_stat_update_and_clear32(hw,\n\t\t\tI40E_GLQF_PCNT(I40E_FD_ATR_STAT_IDX(hw->pf_id)),\n\t\t\t&nsd->fd_atr_match);\n\ti40e_stat_update_and_clear32(hw,\n\t\t\tI40E_GLQF_PCNT(I40E_FD_SB_STAT_IDX(hw->pf_id)),\n\t\t\t&nsd->fd_sb_match);\n\ti40e_stat_update_and_clear32(hw,\n\t\t\tI40E_GLQF_PCNT(I40E_FD_ATR_TUNNEL_STAT_IDX(hw->pf_id)),\n\t\t\t&nsd->fd_atr_tunnel_match);\n\n\tval = rd32(hw, I40E_PRTPM_EEE_STAT);\n\tnsd->tx_lpi_status =\n\t\t       (val & I40E_PRTPM_EEE_STAT_TX_LPI_STATUS_MASK) >>\n\t\t\tI40E_PRTPM_EEE_STAT_TX_LPI_STATUS_SHIFT;\n\tnsd->rx_lpi_status =\n\t\t       (val & I40E_PRTPM_EEE_STAT_RX_LPI_STATUS_MASK) >>\n\t\t\tI40E_PRTPM_EEE_STAT_RX_LPI_STATUS_SHIFT;\n\ti40e_stat_update32(hw, I40E_PRTPM_TLPIC,\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_lpi_count, &nsd->tx_lpi_count);\n\ti40e_stat_update32(hw, I40E_PRTPM_RLPIC,\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_lpi_count, &nsd->rx_lpi_count);\n\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED &&\n\t    !test_bit(__I40E_FD_SB_AUTO_DISABLED, pf->state))\n\t\tnsd->fd_sb_status = true;\n\telse\n\t\tnsd->fd_sb_status = false;\n\n\tif (pf->flags & I40E_FLAG_FD_ATR_ENABLED &&\n\t    !test_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state))\n\t\tnsd->fd_atr_status = true;\n\telse\n\t\tnsd->fd_atr_status = false;\n\n\tpf->stat_offsets_loaded = true;\n}\n\n/**\n * i40e_update_stats - Update the various statistics counters.\n * @vsi: the VSI to be updated\n *\n * Update the various stats for this VSI and its related entities.\n **/\nvoid i40e_update_stats(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (vsi == pf->vsi[pf->lan_vsi])\n\t\ti40e_update_pf_stats(pf);\n\n\ti40e_update_vsi_stats(vsi);\n}\n\n/**\n * i40e_count_filters - counts VSI mac filters\n * @vsi: the VSI to be searched\n *\n * Returns count of mac filters\n **/\nint i40e_count_filters(struct i40e_vsi *vsi)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tint bkt;\n\tint cnt = 0;\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist)\n\t\t++cnt;\n\n\treturn cnt;\n}\n\n/**\n * i40e_find_filter - Search VSI filter list for specific mac/vlan filter\n * @vsi: the VSI to be searched\n * @macaddr: the MAC address\n * @vlan: the vlan\n *\n * Returns ptr to the filter object or NULL\n **/\nstatic struct i40e_mac_filter *i40e_find_filter(struct i40e_vsi *vsi,\n\t\t\t\t\t\tconst u8 *macaddr, s16 vlan)\n{\n\tstruct i40e_mac_filter *f;\n\tu64 key;\n\n\tif (!vsi || !macaddr)\n\t\treturn NULL;\n\n\tkey = i40e_addr_to_hkey(macaddr);\n\thash_for_each_possible(vsi->mac_filter_hash, f, hlist, key) {\n\t\tif ((ether_addr_equal(macaddr, f->macaddr)) &&\n\t\t    (vlan == f->vlan))\n\t\t\treturn f;\n\t}\n\treturn NULL;\n}\n\n/**\n * i40e_find_mac - Find a mac addr in the macvlan filters list\n * @vsi: the VSI to be searched\n * @macaddr: the MAC address we are searching for\n *\n * Returns the first filter with the provided MAC address or NULL if\n * MAC address was not found\n **/\nstruct i40e_mac_filter *i40e_find_mac(struct i40e_vsi *vsi, const u8 *macaddr)\n{\n\tstruct i40e_mac_filter *f;\n\tu64 key;\n\n\tif (!vsi || !macaddr)\n\t\treturn NULL;\n\n\tkey = i40e_addr_to_hkey(macaddr);\n\thash_for_each_possible(vsi->mac_filter_hash, f, hlist, key) {\n\t\tif ((ether_addr_equal(macaddr, f->macaddr)))\n\t\t\treturn f;\n\t}\n\treturn NULL;\n}\n\n/**\n * i40e_is_vsi_in_vlan - Check if VSI is in vlan mode\n * @vsi: the VSI to be searched\n *\n * Returns true if VSI is in vlan mode or false otherwise\n **/\nbool i40e_is_vsi_in_vlan(struct i40e_vsi *vsi)\n{\n\t/* If we have a PVID, always operate in VLAN mode */\n\tif (vsi->info.pvid)\n\t\treturn true;\n\n\t/* We need to operate in VLAN mode whenever we have any filters with\n\t * a VLAN other than I40E_VLAN_ALL. We could check the table each\n\t * time, incurring search cost repeatedly. However, we can notice two\n\t * things:\n\t *\n\t * 1) the only place where we can gain a VLAN filter is in\n\t *    i40e_add_filter.\n\t *\n\t * 2) the only place where filters are actually removed is in\n\t *    i40e_sync_filters_subtask.\n\t *\n\t * Thus, we can simply use a boolean value, has_vlan_filters which we\n\t * will set to true when we add a VLAN filter in i40e_add_filter. Then\n\t * we have to perform the full search after deleting filters in\n\t * i40e_sync_filters_subtask, but we already have to search\n\t * filters here and can perform the check at the same time. This\n\t * results in avoiding embedding a loop for VLAN mode inside another\n\t * loop over all the filters, and should maintain correctness as noted\n\t * above.\n\t */\n\treturn vsi->has_vlan_filter;\n}\n\n/**\n * i40e_correct_mac_vlan_filters - Correct non-VLAN filters if necessary\n * @vsi: the VSI to configure\n * @tmp_add_list: list of filters ready to be added\n * @tmp_del_list: list of filters ready to be deleted\n * @vlan_filters: the number of active VLAN filters\n *\n * Update VLAN=0 and VLAN=-1 (I40E_VLAN_ANY) filters properly so that they\n * behave as expected. If we have any active VLAN filters remaining or about\n * to be added then we need to update non-VLAN filters to be marked as VLAN=0\n * so that they only match against untagged traffic. If we no longer have any\n * active VLAN filters, we need to make all non-VLAN filters marked as VLAN=-1\n * so that they match against both tagged and untagged traffic. In this way,\n * we ensure that we correctly receive the desired traffic. This ensures that\n * when we have an active VLAN we will receive only untagged traffic and\n * traffic matching active VLANs. If we have no active VLANs then we will\n * operate in non-VLAN mode and receive all traffic, tagged or untagged.\n *\n * Finally, in a similar fashion, this function also corrects filters when\n * there is an active PVID assigned to this VSI.\n *\n * In case of memory allocation failure return -ENOMEM. Otherwise, return 0.\n *\n * This function is only expected to be called from within\n * i40e_sync_vsi_filters.\n *\n * NOTE: This function expects to be called while under the\n * mac_filter_hash_lock\n */\nstatic int i40e_correct_mac_vlan_filters(struct i40e_vsi *vsi,\n\t\t\t\t\t struct hlist_head *tmp_add_list,\n\t\t\t\t\t struct hlist_head *tmp_del_list,\n\t\t\t\t\t int vlan_filters)\n{\n\ts16 pvid = le16_to_cpu(vsi->info.pvid);\n\tstruct i40e_mac_filter *f, *add_head;\n\tstruct i40e_new_mac_filter *new;\n\tstruct hlist_node *h;\n\tint bkt, new_vlan;\n\n\t/* To determine if a particular filter needs to be replaced we\n\t * have the three following conditions:\n\t *\n\t * a) if we have a PVID assigned, then all filters which are\n\t *    not marked as VLAN=PVID must be replaced with filters that\n\t *    are.\n\t * b) otherwise, if we have any active VLANS, all filters\n\t *    which are marked as VLAN=-1 must be replaced with\n\t *    filters marked as VLAN=0\n\t * c) finally, if we do not have any active VLANS, all filters\n\t *    which are marked as VLAN=0 must be replaced with filters\n\t *    marked as VLAN=-1\n\t */\n\n\t/* Update the filters about to be added in place */\n\thlist_for_each_entry(new, tmp_add_list, hlist) {\n\t\tif (pvid && new->f->vlan != pvid)\n\t\t\tnew->f->vlan = pvid;\n\t\telse if (vlan_filters && new->f->vlan == I40E_VLAN_ANY)\n\t\t\tnew->f->vlan = 0;\n\t\telse if (!vlan_filters && new->f->vlan == 0)\n\t\t\tnew->f->vlan = I40E_VLAN_ANY;\n\t}\n\n\t/* Update the remaining active filters */\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\t/* Combine the checks for whether a filter needs to be changed\n\t\t * and then determine the new VLAN inside the if block, in\n\t\t * order to avoid duplicating code for adding the new filter\n\t\t * then deleting the old filter.\n\t\t */\n\t\tif ((pvid && f->vlan != pvid) ||\n\t\t    (vlan_filters && f->vlan == I40E_VLAN_ANY) ||\n\t\t    (!vlan_filters && f->vlan == 0)) {\n\t\t\t/* Determine the new vlan we will be adding */\n\t\t\tif (pvid)\n\t\t\t\tnew_vlan = pvid;\n\t\t\telse if (vlan_filters)\n\t\t\t\tnew_vlan = 0;\n\t\t\telse\n\t\t\t\tnew_vlan = I40E_VLAN_ANY;\n\n\t\t\t/* Create the new filter */\n\t\t\tadd_head = i40e_add_filter(vsi, f->macaddr, new_vlan);\n\t\t\tif (!add_head)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\t/* Create a temporary i40e_new_mac_filter */\n\t\t\tnew = kzalloc(sizeof(*new), GFP_ATOMIC);\n\t\t\tif (!new)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tnew->f = add_head;\n\t\t\tnew->state = add_head->state;\n\n\t\t\t/* Add the new filter to the tmp list */\n\t\t\thlist_add_head(&new->hlist, tmp_add_list);\n\n\t\t\t/* Put the original filter into the delete list */\n\t\t\tf->state = I40E_FILTER_REMOVE;\n\t\t\thash_del(&f->hlist);\n\t\t\thlist_add_head(&f->hlist, tmp_del_list);\n\t\t}\n\t}\n\n\tvsi->has_vlan_filter = !!vlan_filters;\n\n\treturn 0;\n}\n\n/**\n * i40e_rm_default_mac_filter - Remove the default MAC filter set by NVM\n * @vsi: the PF Main VSI - inappropriate for any other VSI\n * @macaddr: the MAC address\n *\n * Remove whatever filter the firmware set up so the driver can manage\n * its own filtering intelligently.\n **/\nstatic void i40e_rm_default_mac_filter(struct i40e_vsi *vsi, u8 *macaddr)\n{\n\tstruct i40e_aqc_remove_macvlan_element_data element;\n\tstruct i40e_pf *pf = vsi->back;\n\n\t/* Only appropriate for the PF main VSI */\n\tif (vsi->type != I40E_VSI_MAIN)\n\t\treturn;\n\n\tmemset(&element, 0, sizeof(element));\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\t/* Ignore error returns, some firmware does it this way... */\n\telement.flags = I40E_AQC_MACVLAN_DEL_PERFECT_MATCH;\n\ti40e_aq_remove_macvlan(&pf->hw, vsi->seid, &element, 1, NULL);\n\n\tmemset(&element, 0, sizeof(element));\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\t/* ...and some firmware does it this way. */\n\telement.flags = I40E_AQC_MACVLAN_DEL_PERFECT_MATCH |\n\t\t\tI40E_AQC_MACVLAN_DEL_IGNORE_VLAN;\n\ti40e_aq_remove_macvlan(&pf->hw, vsi->seid, &element, 1, NULL);\n}\n\n/**\n * i40e_add_filter - Add a mac/vlan filter to the VSI\n * @vsi: the VSI to be searched\n * @macaddr: the MAC address\n * @vlan: the vlan\n *\n * Returns ptr to the filter object or NULL when no memory available.\n *\n * NOTE: This function is expected to be called with mac_filter_hash_lock\n * being held.\n **/\nstruct i40e_mac_filter *i40e_add_filter(struct i40e_vsi *vsi,\n\t\t\t\t\tconst u8 *macaddr, s16 vlan)\n{\n\tstruct i40e_mac_filter *f;\n\tu64 key;\n\n\tif (!vsi || !macaddr)\n\t\treturn NULL;\n\n\tf = i40e_find_filter(vsi, macaddr, vlan);\n\tif (!f) {\n\t\tf = kzalloc(sizeof(*f), GFP_ATOMIC);\n\t\tif (!f)\n\t\t\treturn NULL;\n\n\t\t/* Update the boolean indicating if we need to function in\n\t\t * VLAN mode.\n\t\t */\n\t\tif (vlan >= 0)\n\t\t\tvsi->has_vlan_filter = true;\n\n\t\tether_addr_copy(f->macaddr, macaddr);\n\t\tf->vlan = vlan;\n\t\tf->state = I40E_FILTER_NEW;\n\t\tINIT_HLIST_NODE(&f->hlist);\n\n\t\tkey = i40e_addr_to_hkey(macaddr);\n\t\thash_add(vsi->mac_filter_hash, &f->hlist, key);\n\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, vsi->back->state);\n\t}\n\n\t/* If we're asked to add a filter that has been marked for removal, it\n\t * is safe to simply restore it to active state. __i40e_del_filter\n\t * will have simply deleted any filters which were previously marked\n\t * NEW or FAILED, so if it is currently marked REMOVE it must have\n\t * previously been ACTIVE. Since we haven't yet run the sync filters\n\t * task, just restore this filter to the ACTIVE state so that the\n\t * sync task leaves it in place\n\t */\n\tif (f->state == I40E_FILTER_REMOVE)\n\t\tf->state = I40E_FILTER_ACTIVE;\n\n\treturn f;\n}\n\n/**\n * __i40e_del_filter - Remove a specific filter from the VSI\n * @vsi: VSI to remove from\n * @f: the filter to remove from the list\n *\n * This function should be called instead of i40e_del_filter only if you know\n * the exact filter you will remove already, such as via i40e_find_filter or\n * i40e_find_mac.\n *\n * NOTE: This function is expected to be called with mac_filter_hash_lock\n * being held.\n * ANOTHER NOTE: This function MUST be called from within the context of\n * the \"safe\" variants of any list iterators, e.g. list_for_each_entry_safe()\n * instead of list_for_each_entry().\n **/\nvoid __i40e_del_filter(struct i40e_vsi *vsi, struct i40e_mac_filter *f)\n{\n\tif (!f)\n\t\treturn;\n\n\t/* If the filter was never added to firmware then we can just delete it\n\t * directly and we don't want to set the status to remove or else an\n\t * admin queue command will unnecessarily fire.\n\t */\n\tif ((f->state == I40E_FILTER_FAILED) ||\n\t    (f->state == I40E_FILTER_NEW)) {\n\t\thash_del(&f->hlist);\n\t\tkfree(f);\n\t} else {\n\t\tf->state = I40E_FILTER_REMOVE;\n\t}\n\n\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\tset_bit(__I40E_MACVLAN_SYNC_PENDING, vsi->back->state);\n}\n\n/**\n * i40e_del_filter - Remove a MAC/VLAN filter from the VSI\n * @vsi: the VSI to be searched\n * @macaddr: the MAC address\n * @vlan: the VLAN\n *\n * NOTE: This function is expected to be called with mac_filter_hash_lock\n * being held.\n * ANOTHER NOTE: This function MUST be called from within the context of\n * the \"safe\" variants of any list iterators, e.g. list_for_each_entry_safe()\n * instead of list_for_each_entry().\n **/\nvoid i40e_del_filter(struct i40e_vsi *vsi, const u8 *macaddr, s16 vlan)\n{\n\tstruct i40e_mac_filter *f;\n\n\tif (!vsi || !macaddr)\n\t\treturn;\n\n\tf = i40e_find_filter(vsi, macaddr, vlan);\n\t__i40e_del_filter(vsi, f);\n}\n\n/**\n * i40e_add_mac_filter - Add a MAC filter for all active VLANs\n * @vsi: the VSI to be searched\n * @macaddr: the mac address to be filtered\n *\n * If we're not in VLAN mode, just add the filter to I40E_VLAN_ANY. Otherwise,\n * go through all the macvlan filters and add a macvlan filter for each\n * unique vlan that already exists. If a PVID has been assigned, instead only\n * add the macaddr to that VLAN.\n *\n * Returns last filter added on success, else NULL\n **/\nstruct i40e_mac_filter *i40e_add_mac_filter(struct i40e_vsi *vsi,\n\t\t\t\t\t    const u8 *macaddr)\n{\n\tstruct i40e_mac_filter *f, *add = NULL;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\tif (vsi->info.pvid)\n\t\treturn i40e_add_filter(vsi, macaddr,\n\t\t\t\t       le16_to_cpu(vsi->info.pvid));\n\n\tif (!i40e_is_vsi_in_vlan(vsi))\n\t\treturn i40e_add_filter(vsi, macaddr, I40E_VLAN_ANY);\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (f->state == I40E_FILTER_REMOVE)\n\t\t\tcontinue;\n\t\tadd = i40e_add_filter(vsi, macaddr, f->vlan);\n\t\tif (!add)\n\t\t\treturn NULL;\n\t}\n\n\treturn add;\n}\n\n/**\n * i40e_del_mac_filter - Remove a MAC filter from all VLANs\n * @vsi: the VSI to be searched\n * @macaddr: the mac address to be removed\n *\n * Removes a given MAC address from a VSI regardless of what VLAN it has been\n * associated with.\n *\n * Returns 0 for success, or error\n **/\nint i40e_del_mac_filter(struct i40e_vsi *vsi, const u8 *macaddr)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tbool found = false;\n\tint bkt;\n\n\tlockdep_assert_held(&vsi->mac_filter_hash_lock);\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (ether_addr_equal(macaddr, f->macaddr)) {\n\t\t\t__i40e_del_filter(vsi, f);\n\t\t\tfound = true;\n\t\t}\n\t}\n\n\tif (found)\n\t\treturn 0;\n\telse\n\t\treturn -ENOENT;\n}\n\n/**\n * i40e_set_mac - NDO callback to set mac address\n * @netdev: network interface device structure\n * @p: pointer to an address structure\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_set_mac(struct net_device *netdev, void *p)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct sockaddr *addr = p;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\tif (ether_addr_equal(netdev->dev_addr, addr->sa_data)) {\n\t\tnetdev_info(netdev, \"already using mac address %pM\\n\",\n\t\t\t    addr->sa_data);\n\t\treturn 0;\n\t}\n\n\tif (test_bit(__I40E_DOWN, pf->state) ||\n\t    test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\treturn -EADDRNOTAVAIL;\n\n\tif (ether_addr_equal(hw->mac.addr, addr->sa_data))\n\t\tnetdev_info(netdev, \"returning to hw mac address %pM\\n\",\n\t\t\t    hw->mac.addr);\n\telse\n\t\tnetdev_info(netdev, \"set new mac address %pM\\n\", addr->sa_data);\n\n\t/* Copy the address first, so that we avoid a possible race with\n\t * .set_rx_mode().\n\t * - Remove old address from MAC filter\n\t * - Copy new address\n\t * - Add new address to MAC filter\n\t */\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\ti40e_del_mac_filter(vsi, netdev->dev_addr);\n\tether_addr_copy(netdev->dev_addr, addr->sa_data);\n\ti40e_add_mac_filter(vsi, netdev->dev_addr);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\ti40e_status ret;\n\n\t\tret = i40e_aq_mac_address_write(hw, I40E_AQC_WRITE_TYPE_LAA_WOL,\n\t\t\t\t\t\taddr->sa_data, NULL);\n\t\tif (ret)\n\t\t\tnetdev_info(netdev, \"Ignoring error from firmware on LAA update, status %s, AQ ret %s\\n\",\n\t\t\t\t    i40e_stat_str(hw, ret),\n\t\t\t\t    i40e_aq_str(hw, hw->aq.asq_last_status));\n\t}\n\n\t/* schedule our worker thread which will take care of\n\t * applying the new filter changes\n\t */\n\ti40e_service_event_schedule(pf);\n\treturn 0;\n}\n\n/**\n * i40e_config_rss_aq - Prepare for RSS using AQ commands\n * @vsi: vsi structure\n * @seed: RSS hash seed\n **/\nstatic int i40e_config_rss_aq(struct i40e_vsi *vsi, const u8 *seed,\n\t\t\t      u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret = 0;\n\n\tif (seed) {\n\t\tstruct i40e_aqc_get_set_rss_key_data *seed_dw =\n\t\t\t(struct i40e_aqc_get_set_rss_key_data *)seed;\n\t\tret = i40e_aq_set_rss_key(hw, vsi->id, seed_dw);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot set RSS key, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\tif (lut) {\n\t\tbool pf_lut = vsi->type == I40E_VSI_MAIN ? true : false;\n\n\t\tret = i40e_aq_set_rss_lut(hw, vsi->id, pf_lut, lut, lut_size);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot set RSS lut, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn ret;\n}\n\n/**\n * i40e_vsi_config_rss - Prepare for VSI(VMDq) RSS if used\n * @vsi: VSI structure\n **/\nstatic int i40e_vsi_config_rss(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 seed[I40E_HKEY_ARRAY_SIZE];\n\tu8 *lut;\n\tint ret;\n\n\tif (!(pf->hw_features & I40E_HW_RSS_AQ_CAPABLE))\n\t\treturn 0;\n\tif (!vsi->rss_size)\n\t\tvsi->rss_size = min_t(int, pf->alloc_rss_size,\n\t\t\t\t      vsi->num_queue_pairs);\n\tif (!vsi->rss_size)\n\t\treturn -EINVAL;\n\tlut = kzalloc(vsi->rss_table_size, GFP_KERNEL);\n\tif (!lut)\n\t\treturn -ENOMEM;\n\n\t/* Use the user configured hash keys and lookup table if there is one,\n\t * otherwise use default\n\t */\n\tif (vsi->rss_lut_user)\n\t\tmemcpy(lut, vsi->rss_lut_user, vsi->rss_table_size);\n\telse\n\t\ti40e_fill_rss_lut(pf, lut, vsi->rss_table_size, vsi->rss_size);\n\tif (vsi->rss_hkey_user)\n\t\tmemcpy(seed, vsi->rss_hkey_user, I40E_HKEY_ARRAY_SIZE);\n\telse\n\t\tnetdev_rss_key_fill((void *)seed, I40E_HKEY_ARRAY_SIZE);\n\tret = i40e_config_rss_aq(vsi, seed, lut, vsi->rss_table_size);\n\tkfree(lut);\n\treturn ret;\n}\n\n/**\n * i40e_vsi_setup_queue_map_mqprio - Prepares mqprio based tc_config\n * @vsi: the VSI being configured,\n * @ctxt: VSI context structure\n * @enabled_tc: number of traffic classes to enable\n *\n * Prepares VSI tc_config to have queue configurations based on MQPRIO options.\n **/\nstatic int i40e_vsi_setup_queue_map_mqprio(struct i40e_vsi *vsi,\n\t\t\t\t\t   struct i40e_vsi_context *ctxt,\n\t\t\t\t\t   u8 enabled_tc)\n{\n\tu16 qcount = 0, max_qcount, qmap, sections = 0;\n\tint i, override_q, pow, num_qps, ret;\n\tu8 netdev_tc = 0, offset = 0;\n\n\tif (vsi->type != I40E_VSI_MAIN)\n\t\treturn -EINVAL;\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\tvsi->tc_config.numtc = vsi->mqprio_qopt.qopt.num_tc;\n\tvsi->tc_config.enabled_tc = enabled_tc ? enabled_tc : 1;\n\tnum_qps = vsi->mqprio_qopt.qopt.count[0];\n\n\t/* find the next higher power-of-2 of num queue pairs */\n\tpow = ilog2(num_qps);\n\tif (!is_power_of_2(num_qps))\n\t\tpow++;\n\tqmap = (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t(pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t/* Setup queue offset/count for all TCs for given VSI */\n\tmax_qcount = vsi->mqprio_qopt.qopt.count[0];\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t/* See if the given TC is enabled for the given VSI */\n\t\tif (vsi->tc_config.enabled_tc & BIT(i)) {\n\t\t\toffset = vsi->mqprio_qopt.qopt.offset[i];\n\t\t\tqcount = vsi->mqprio_qopt.qopt.count[i];\n\t\t\tif (qcount > max_qcount)\n\t\t\t\tmax_qcount = qcount;\n\t\t\tvsi->tc_config.tc_info[i].qoffset = offset;\n\t\t\tvsi->tc_config.tc_info[i].qcount = qcount;\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = netdev_tc++;\n\t\t} else {\n\t\t\t/* TC is not enabled so set the offset to\n\t\t\t * default queue and allocate one queue\n\t\t\t * for the given TC.\n\t\t\t */\n\t\t\tvsi->tc_config.tc_info[i].qoffset = 0;\n\t\t\tvsi->tc_config.tc_info[i].qcount = 1;\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = 0;\n\t\t}\n\t}\n\n\t/* Set actual Tx/Rx queue pairs */\n\tvsi->num_queue_pairs = offset + qcount;\n\n\t/* Setup queue TC[0].qmap for given VSI context */\n\tctxt->info.tc_mapping[0] = cpu_to_le16(qmap);\n\tctxt->info.mapping_flags |= cpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\tctxt->info.queue_mapping[0] = cpu_to_le16(vsi->base_queue);\n\tctxt->info.valid_sections |= cpu_to_le16(sections);\n\n\t/* Reconfigure RSS for main VSI with max queue count */\n\tvsi->rss_size = max_qcount;\n\tret = i40e_vsi_config_rss(vsi);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to reconfig rss for num_queues (%u)\\n\",\n\t\t\t max_qcount);\n\t\treturn ret;\n\t}\n\tvsi->reconfig_rss = true;\n\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\"Reconfigured rss with num_queues (%u)\\n\", max_qcount);\n\n\t/* Find queue count available for channel VSIs and starting offset\n\t * for channel VSIs\n\t */\n\toverride_q = vsi->mqprio_qopt.qopt.count[0];\n\tif (override_q && override_q < vsi->num_queue_pairs) {\n\t\tvsi->cnt_q_avail = vsi->num_queue_pairs - override_q;\n\t\tvsi->next_base_queue = override_q;\n\t}\n\treturn 0;\n}\n\n/**\n * i40e_vsi_setup_queue_map - Setup a VSI queue map based on enabled_tc\n * @vsi: the VSI being setup\n * @ctxt: VSI context structure\n * @enabled_tc: Enabled TCs bitmap\n * @is_add: True if called before Add VSI\n *\n * Setup VSI queue mapping for enabled traffic classes.\n **/\nstatic void i40e_vsi_setup_queue_map(struct i40e_vsi *vsi,\n\t\t\t\t     struct i40e_vsi_context *ctxt,\n\t\t\t\t     u8 enabled_tc,\n\t\t\t\t     bool is_add)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu16 sections = 0;\n\tu8 netdev_tc = 0;\n\tu16 numtc = 1;\n\tu16 qcount;\n\tu8 offset;\n\tu16 qmap;\n\tint i;\n\tu16 num_tc_qps = 0;\n\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\toffset = 0;\n\n\t/* Number of queues per enabled TC */\n\tnum_tc_qps = vsi->alloc_queue_pairs;\n\tif (enabled_tc && (vsi->back->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\t/* Find numtc from enabled TC bitmap */\n\t\tfor (i = 0, numtc = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t\tif (enabled_tc & BIT(i)) /* TC is enabled */\n\t\t\t\tnumtc++;\n\t\t}\n\t\tif (!numtc) {\n\t\t\tdev_warn(&pf->pdev->dev, \"DCB is enabled but no TC enabled, forcing TC0\\n\");\n\t\t\tnumtc = 1;\n\t\t}\n\t\tnum_tc_qps = num_tc_qps / numtc;\n\t\tnum_tc_qps = min_t(int, num_tc_qps,\n\t\t\t\t   i40e_pf_get_max_q_per_tc(pf));\n\t}\n\n\tvsi->tc_config.numtc = numtc;\n\tvsi->tc_config.enabled_tc = enabled_tc ? enabled_tc : 1;\n\n\t/* Do not allow use more TC queue pairs than MSI-X vectors exist */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\tnum_tc_qps = min_t(int, num_tc_qps, pf->num_lan_msix);\n\n\t/* Setup queue offset/count for all TCs for given VSI */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t/* See if the given TC is enabled for the given VSI */\n\t\tif (vsi->tc_config.enabled_tc & BIT(i)) {\n\t\t\t/* TC is enabled */\n\t\t\tint pow, num_qps;\n\n\t\t\tswitch (vsi->type) {\n\t\t\tcase I40E_VSI_MAIN:\n\t\t\t\tif (!(pf->flags & (I40E_FLAG_FD_SB_ENABLED |\n\t\t\t\t    I40E_FLAG_FD_ATR_ENABLED)) ||\n\t\t\t\t    vsi->tc_config.enabled_tc != 1) {\n\t\t\t\t\tqcount = min_t(int, pf->alloc_rss_size,\n\t\t\t\t\t\t       num_tc_qps);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t/* fall through */\n\t\t\tcase I40E_VSI_FDIR:\n\t\t\tcase I40E_VSI_SRIOV:\n\t\t\tcase I40E_VSI_VMDQ2:\n\t\t\tdefault:\n\t\t\t\tqcount = num_tc_qps;\n\t\t\t\tWARN_ON(i != 0);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tvsi->tc_config.tc_info[i].qoffset = offset;\n\t\t\tvsi->tc_config.tc_info[i].qcount = qcount;\n\n\t\t\t/* find the next higher power-of-2 of num queue pairs */\n\t\t\tnum_qps = qcount;\n\t\t\tpow = 0;\n\t\t\twhile (num_qps && (BIT_ULL(pow) < qcount)) {\n\t\t\t\tpow++;\n\t\t\t\tnum_qps >>= 1;\n\t\t\t}\n\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = netdev_tc++;\n\t\t\tqmap =\n\t\t\t    (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t\t    (pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t\t\toffset += qcount;\n\t\t} else {\n\t\t\t/* TC is not enabled so set the offset to\n\t\t\t * default queue and allocate one queue\n\t\t\t * for the given TC.\n\t\t\t */\n\t\t\tvsi->tc_config.tc_info[i].qoffset = 0;\n\t\t\tvsi->tc_config.tc_info[i].qcount = 1;\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = 0;\n\n\t\t\tqmap = 0;\n\t\t}\n\t\tctxt->info.tc_mapping[i] = cpu_to_le16(qmap);\n\t}\n\n\t/* Set actual Tx/Rx queue pairs */\n\tvsi->num_queue_pairs = offset;\n\tif ((vsi->type == I40E_VSI_MAIN) && (numtc == 1)) {\n\t\tif (vsi->req_queue_pairs > 0)\n\t\t\tvsi->num_queue_pairs = vsi->req_queue_pairs;\n\t\telse if (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\t\tvsi->num_queue_pairs = pf->num_lan_msix;\n\t}\n\n\t/* Scheduler section valid can only be set for ADD VSI */\n\tif (is_add) {\n\t\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\n\t\tctxt->info.up_enable_bits = enabled_tc;\n\t}\n\tif (vsi->type == I40E_VSI_SRIOV) {\n\t\tctxt->info.mapping_flags |=\n\t\t\t\t     cpu_to_le16(I40E_AQ_VSI_QUE_MAP_NONCONTIG);\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tctxt->info.queue_mapping[i] =\n\t\t\t\t\t       cpu_to_le16(vsi->base_queue + i);\n\t} else {\n\t\tctxt->info.mapping_flags |=\n\t\t\t\t\tcpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\t\tctxt->info.queue_mapping[0] = cpu_to_le16(vsi->base_queue);\n\t}\n\tctxt->info.valid_sections |= cpu_to_le16(sections);\n}\n\n/**\n * i40e_addr_sync - Callback for dev_(mc|uc)_sync to add address\n * @netdev: the netdevice\n * @addr: address to add\n *\n * Called by __dev_(mc|uc)_sync when an address needs to be added. We call\n * __dev_(uc|mc)_sync from .set_rx_mode and guarantee to hold the hash lock.\n */\nstatic int i40e_addr_sync(struct net_device *netdev, const u8 *addr)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tif (i40e_add_mac_filter(vsi, addr))\n\t\treturn 0;\n\telse\n\t\treturn -ENOMEM;\n}\n\n/**\n * i40e_addr_unsync - Callback for dev_(mc|uc)_sync to remove address\n * @netdev: the netdevice\n * @addr: address to add\n *\n * Called by __dev_(mc|uc)_sync when an address needs to be removed. We call\n * __dev_(uc|mc)_sync from .set_rx_mode and guarantee to hold the hash lock.\n */\nstatic int i40e_addr_unsync(struct net_device *netdev, const u8 *addr)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\t/* Under some circumstances, we might receive a request to delete\n\t * our own device address from our uc list. Because we store the\n\t * device address in the VSI's MAC/VLAN filter list, we need to ignore\n\t * such requests and not delete our device address from this list.\n\t */\n\tif (ether_addr_equal(addr, netdev->dev_addr))\n\t\treturn 0;\n\n\ti40e_del_mac_filter(vsi, addr);\n\n\treturn 0;\n}\n\n/**\n * i40e_set_rx_mode - NDO callback to set the netdev filters\n * @netdev: network interface device structure\n **/\nstatic void i40e_set_rx_mode(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\n\t__dev_uc_sync(netdev, i40e_addr_sync, i40e_addr_unsync);\n\t__dev_mc_sync(netdev, i40e_addr_sync, i40e_addr_unsync);\n\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\t/* check for other flag changes */\n\tif (vsi->current_netdev_flags != vsi->netdev->flags) {\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, vsi->back->state);\n\t}\n}\n\n/**\n * i40e_undo_del_filter_entries - Undo the changes made to MAC filter entries\n * @vsi: Pointer to VSI struct\n * @from: Pointer to list which contains MAC filter entries - changes to\n *        those entries needs to be undone.\n *\n * MAC filter entries from this list were slated for deletion.\n **/\nstatic void i40e_undo_del_filter_entries(struct i40e_vsi *vsi,\n\t\t\t\t\t struct hlist_head *from)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\n\thlist_for_each_entry_safe(f, h, from, hlist) {\n\t\tu64 key = i40e_addr_to_hkey(f->macaddr);\n\n\t\t/* Move the element back into MAC filter list*/\n\t\thlist_del(&f->hlist);\n\t\thash_add(vsi->mac_filter_hash, &f->hlist, key);\n\t}\n}\n\n/**\n * i40e_undo_add_filter_entries - Undo the changes made to MAC filter entries\n * @vsi: Pointer to vsi struct\n * @from: Pointer to list which contains MAC filter entries - changes to\n *        those entries needs to be undone.\n *\n * MAC filter entries from this list were slated for addition.\n **/\nstatic void i40e_undo_add_filter_entries(struct i40e_vsi *vsi,\n\t\t\t\t\t struct hlist_head *from)\n{\n\tstruct i40e_new_mac_filter *new;\n\tstruct hlist_node *h;\n\n\thlist_for_each_entry_safe(new, h, from, hlist) {\n\t\t/* We can simply free the wrapper structure */\n\t\thlist_del(&new->hlist);\n\t\tkfree(new);\n\t}\n}\n\n/**\n * i40e_next_entry - Get the next non-broadcast filter from a list\n * @next: pointer to filter in list\n *\n * Returns the next non-broadcast filter in the list. Required so that we\n * ignore broadcast filters within the list, since these are not handled via\n * the normal firmware update path.\n */\nstatic\nstruct i40e_new_mac_filter *i40e_next_filter(struct i40e_new_mac_filter *next)\n{\n\thlist_for_each_entry_continue(next, hlist) {\n\t\tif (!is_broadcast_ether_addr(next->f->macaddr))\n\t\t\treturn next;\n\t}\n\n\treturn NULL;\n}\n\n/**\n * i40e_update_filter_state - Update filter state based on return data\n * from firmware\n * @count: Number of filters added\n * @add_list: return data from fw\n * @add_head: pointer to first filter in current batch\n *\n * MAC filter entries from list were slated to be added to device. Returns\n * number of successful filters. Note that 0 does NOT mean success!\n **/\nstatic int\ni40e_update_filter_state(int count,\n\t\t\t struct i40e_aqc_add_macvlan_element_data *add_list,\n\t\t\t struct i40e_new_mac_filter *add_head)\n{\n\tint retval = 0;\n\tint i;\n\n\tfor (i = 0; i < count; i++) {\n\t\t/* Always check status of each filter. We don't need to check\n\t\t * the firmware return status because we pre-set the filter\n\t\t * status to I40E_AQC_MM_ERR_NO_RES when sending the filter\n\t\t * request to the adminq. Thus, if it no longer matches then\n\t\t * we know the filter is active.\n\t\t */\n\t\tif (add_list[i].match_method == I40E_AQC_MM_ERR_NO_RES) {\n\t\t\tadd_head->state = I40E_FILTER_FAILED;\n\t\t} else {\n\t\t\tadd_head->state = I40E_FILTER_ACTIVE;\n\t\t\tretval++;\n\t\t}\n\n\t\tadd_head = i40e_next_filter(add_head);\n\t\tif (!add_head)\n\t\t\tbreak;\n\t}\n\n\treturn retval;\n}\n\n/**\n * i40e_aqc_del_filters - Request firmware to delete a set of filters\n * @vsi: ptr to the VSI\n * @vsi_name: name to display in messages\n * @list: the list of filters to send to firmware\n * @num_del: the number of filters to delete\n * @retval: Set to -EIO on failure to delete\n *\n * Send a request to firmware via AdminQ to delete a set of filters. Uses\n * *retval instead of a return value so that success does not force ret_val to\n * be set to 0. This ensures that a sequence of calls to this function\n * preserve the previous value of *retval on successful delete.\n */\nstatic\nvoid i40e_aqc_del_filters(struct i40e_vsi *vsi, const char *vsi_name,\n\t\t\t  struct i40e_aqc_remove_macvlan_element_data *list,\n\t\t\t  int num_del, int *retval)\n{\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\ti40e_status aq_ret;\n\tint aq_err;\n\n\taq_ret = i40e_aq_remove_macvlan(hw, vsi->seid, list, num_del, NULL);\n\taq_err = hw->aq.asq_last_status;\n\n\t/* Explicitly ignore and do not report when firmware returns ENOENT */\n\tif (aq_ret && !(aq_err == I40E_AQ_RC_ENOENT)) {\n\t\t*retval = -EIO;\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"ignoring delete macvlan error on %s, err %s, aq_err %s\\n\",\n\t\t\t vsi_name, i40e_stat_str(hw, aq_ret),\n\t\t\t i40e_aq_str(hw, aq_err));\n\t}\n}\n\n/**\n * i40e_aqc_add_filters - Request firmware to add a set of filters\n * @vsi: ptr to the VSI\n * @vsi_name: name to display in messages\n * @list: the list of filters to send to firmware\n * @add_head: Position in the add hlist\n * @num_add: the number of filters to add\n *\n * Send a request to firmware via AdminQ to add a chunk of filters. Will set\n * __I40E_VSI_OVERFLOW_PROMISC bit in vsi->state if the firmware has run out of\n * space for more filters.\n */\nstatic\nvoid i40e_aqc_add_filters(struct i40e_vsi *vsi, const char *vsi_name,\n\t\t\t  struct i40e_aqc_add_macvlan_element_data *list,\n\t\t\t  struct i40e_new_mac_filter *add_head,\n\t\t\t  int num_add)\n{\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tint aq_err, fcnt;\n\n\ti40e_aq_add_macvlan(hw, vsi->seid, list, num_add, NULL);\n\taq_err = hw->aq.asq_last_status;\n\tfcnt = i40e_update_filter_state(num_add, list, add_head);\n\n\tif (fcnt != num_add) {\n\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\tset_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t\t \"Error %s adding RX filters on %s, promiscuous mode forced on\\n\",\n\t\t\t\t i40e_aq_str(hw, aq_err), vsi_name);\n\t\t} else if (vsi->type == I40E_VSI_SRIOV ||\n\t\t\t   vsi->type == I40E_VSI_VMDQ1 ||\n\t\t\t   vsi->type == I40E_VSI_VMDQ2) {\n\t\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t\t \"Error %s adding RX filters on %s, please set promiscuous on manually for %s\\n\",\n\t\t\t\t i40e_aq_str(hw, aq_err), vsi_name, vsi_name);\n\t\t} else {\n\t\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t\t \"Error %s adding RX filters on %s, incorrect VSI type: %i.\\n\",\n\t\t\t\t i40e_aq_str(hw, aq_err), vsi_name, vsi->type);\n\t\t}\n\t}\n}\n\n/**\n * i40e_aqc_broadcast_filter - Set promiscuous broadcast flags\n * @vsi: pointer to the VSI\n * @vsi_name: the VSI name\n * @f: filter data\n *\n * This function sets or clears the promiscuous broadcast flags for VLAN\n * filters in order to properly receive broadcast frames. Assumes that only\n * broadcast filters are passed.\n *\n * Returns status indicating success or failure;\n **/\nstatic i40e_status\ni40e_aqc_broadcast_filter(struct i40e_vsi *vsi, const char *vsi_name,\n\t\t\t  struct i40e_mac_filter *f)\n{\n\tbool enable = f->state == I40E_FILTER_NEW;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\ti40e_status aq_ret;\n\n\tif (f->vlan == I40E_VLAN_ANY) {\n\t\taq_ret = i40e_aq_set_vsi_broadcast(hw,\n\t\t\t\t\t\t   vsi->seid,\n\t\t\t\t\t\t   enable,\n\t\t\t\t\t\t   NULL);\n\t} else {\n\t\taq_ret = i40e_aq_set_vsi_bc_promisc_on_vlan(hw,\n\t\t\t\t\t\t\t    vsi->seid,\n\t\t\t\t\t\t\t    enable,\n\t\t\t\t\t\t\t    f->vlan,\n\t\t\t\t\t\t\t    NULL);\n\t}\n\n\tif (aq_ret) {\n\t\tset_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t \"Error %s, forcing overflow promiscuous on %s\\n\",\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status),\n\t\t\t vsi_name);\n\t}\n\n\treturn aq_ret;\n}\n\n/**\n * i40e_set_promiscuous - set promiscuous mode\n * @pf: board private structure\n * @promisc: promisc on or off\n *\n * There are different ways of setting promiscuous mode on a PF depending on\n * what state/environment we're in.  This identifies and sets it appropriately.\n * Returns 0 on success.\n **/\nstatic int i40e_set_promiscuous(struct i40e_pf *pf, bool promisc)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status aq_ret;\n\n\tif (vsi->type == I40E_VSI_MAIN &&\n\t    pf->lan_veb != I40E_NO_VEB &&\n\t    !(pf->flags & I40E_FLAG_MFP_ENABLED)) {\n\t\t/* set defport ON for Main VSI instead of true promisc\n\t\t * this way we will get all unicast/multicast and VLAN\n\t\t * promisc behavior but will not get VF or VMDq traffic\n\t\t * replicated on the Main VSI.\n\t\t */\n\t\tif (promisc)\n\t\t\taq_ret = i40e_aq_set_default_vsi(hw,\n\t\t\t\t\t\t\t vsi->seid,\n\t\t\t\t\t\t\t NULL);\n\t\telse\n\t\t\taq_ret = i40e_aq_clear_default_vsi(hw,\n\t\t\t\t\t\t\t   vsi->seid,\n\t\t\t\t\t\t\t   NULL);\n\t\tif (aq_ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Set default VSI failed, err %s, aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t} else {\n\t\taq_ret = i40e_aq_set_vsi_unicast_promiscuous(\n\t\t\t\t\t\t  hw,\n\t\t\t\t\t\t  vsi->seid,\n\t\t\t\t\t\t  promisc, NULL,\n\t\t\t\t\t\t  true);\n\t\tif (aq_ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"set unicast promisc failed, err %s, aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t\taq_ret = i40e_aq_set_vsi_multicast_promiscuous(\n\t\t\t\t\t\t  hw,\n\t\t\t\t\t\t  vsi->seid,\n\t\t\t\t\t\t  promisc, NULL);\n\t\tif (aq_ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"set multicast promisc failed, err %s, aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t}\n\n\tif (!aq_ret)\n\t\tpf->cur_promisc = promisc;\n\n\treturn aq_ret;\n}\n\n/**\n * i40e_sync_vsi_filters - Update the VSI filter list to the HW\n * @vsi: ptr to the VSI\n *\n * Push any outstanding VSI filter changes through the AdminQ.\n *\n * Returns 0 or error value\n **/\nint i40e_sync_vsi_filters(struct i40e_vsi *vsi)\n{\n\tstruct hlist_head tmp_add_list, tmp_del_list;\n\tstruct i40e_mac_filter *f;\n\tstruct i40e_new_mac_filter *new, *add_head = NULL;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tbool old_overflow, new_overflow;\n\tunsigned int failed_filters = 0;\n\tunsigned int vlan_filters = 0;\n\tchar vsi_name[16] = \"PF\";\n\tint filter_list_len = 0;\n\ti40e_status aq_ret = 0;\n\tu32 changed_flags = 0;\n\tstruct hlist_node *h;\n\tstruct i40e_pf *pf;\n\tint num_add = 0;\n\tint num_del = 0;\n\tint retval = 0;\n\tu16 cmd_flags;\n\tint list_size;\n\tint bkt;\n\n\t/* empty array typed pointers, kcalloc later */\n\tstruct i40e_aqc_add_macvlan_element_data *add_list;\n\tstruct i40e_aqc_remove_macvlan_element_data *del_list;\n\n\twhile (test_and_set_bit(__I40E_VSI_SYNCING_FILTERS, vsi->state))\n\t\tusleep_range(1000, 2000);\n\tpf = vsi->back;\n\n\told_overflow = test_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\n\tif (vsi->netdev) {\n\t\tchanged_flags = vsi->current_netdev_flags ^ vsi->netdev->flags;\n\t\tvsi->current_netdev_flags = vsi->netdev->flags;\n\t}\n\n\tINIT_HLIST_HEAD(&tmp_add_list);\n\tINIT_HLIST_HEAD(&tmp_del_list);\n\n\tif (vsi->type == I40E_VSI_SRIOV)\n\t\tsnprintf(vsi_name, sizeof(vsi_name) - 1, \"VF %d\", vsi->vf_id);\n\telse if (vsi->type != I40E_VSI_MAIN)\n\t\tsnprintf(vsi_name, sizeof(vsi_name) - 1, \"vsi %d\", vsi->seid);\n\n\tif (vsi->flags & I40E_VSI_FLAG_FILTER_CHANGED) {\n\t\tvsi->flags &= ~I40E_VSI_FLAG_FILTER_CHANGED;\n\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\t/* Create a list of filters to delete. */\n\t\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\t\tif (f->state == I40E_FILTER_REMOVE) {\n\t\t\t\t/* Move the element into temporary del_list */\n\t\t\t\thash_del(&f->hlist);\n\t\t\t\thlist_add_head(&f->hlist, &tmp_del_list);\n\n\t\t\t\t/* Avoid counting removed filters */\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (f->state == I40E_FILTER_NEW) {\n\t\t\t\t/* Create a temporary i40e_new_mac_filter */\n\t\t\t\tnew = kzalloc(sizeof(*new), GFP_ATOMIC);\n\t\t\t\tif (!new)\n\t\t\t\t\tgoto err_no_memory_locked;\n\n\t\t\t\t/* Store pointer to the real filter */\n\t\t\t\tnew->f = f;\n\t\t\t\tnew->state = f->state;\n\n\t\t\t\t/* Add it to the hash list */\n\t\t\t\thlist_add_head(&new->hlist, &tmp_add_list);\n\t\t\t}\n\n\t\t\t/* Count the number of active (current and new) VLAN\n\t\t\t * filters we have now. Does not count filters which\n\t\t\t * are marked for deletion.\n\t\t\t */\n\t\t\tif (f->vlan > 0)\n\t\t\t\tvlan_filters++;\n\t\t}\n\n\t\tretval = i40e_correct_mac_vlan_filters(vsi,\n\t\t\t\t\t\t       &tmp_add_list,\n\t\t\t\t\t\t       &tmp_del_list,\n\t\t\t\t\t\t       vlan_filters);\n\t\tif (retval)\n\t\t\tgoto err_no_memory_locked;\n\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t}\n\n\t/* Now process 'del_list' outside the lock */\n\tif (!hlist_empty(&tmp_del_list)) {\n\t\tfilter_list_len = hw->aq.asq_buf_size /\n\t\t\t    sizeof(struct i40e_aqc_remove_macvlan_element_data);\n\t\tlist_size = filter_list_len *\n\t\t\t    sizeof(struct i40e_aqc_remove_macvlan_element_data);\n\t\tdel_list = kzalloc(list_size, GFP_ATOMIC);\n\t\tif (!del_list)\n\t\t\tgoto err_no_memory;\n\n\t\thlist_for_each_entry_safe(f, h, &tmp_del_list, hlist) {\n\t\t\tcmd_flags = 0;\n\n\t\t\t/* handle broadcast filters by updating the broadcast\n\t\t\t * promiscuous flag and release filter list.\n\t\t\t */\n\t\t\tif (is_broadcast_ether_addr(f->macaddr)) {\n\t\t\t\ti40e_aqc_broadcast_filter(vsi, vsi_name, f);\n\n\t\t\t\thlist_del(&f->hlist);\n\t\t\t\tkfree(f);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* add to delete list */\n\t\t\tether_addr_copy(del_list[num_del].mac_addr, f->macaddr);\n\t\t\tif (f->vlan == I40E_VLAN_ANY) {\n\t\t\t\tdel_list[num_del].vlan_tag = 0;\n\t\t\t\tcmd_flags |= I40E_AQC_MACVLAN_DEL_IGNORE_VLAN;\n\t\t\t} else {\n\t\t\t\tdel_list[num_del].vlan_tag =\n\t\t\t\t\tcpu_to_le16((u16)(f->vlan));\n\t\t\t}\n\n\t\t\tcmd_flags |= I40E_AQC_MACVLAN_DEL_PERFECT_MATCH;\n\t\t\tdel_list[num_del].flags = cmd_flags;\n\t\t\tnum_del++;\n\n\t\t\t/* flush a full buffer */\n\t\t\tif (num_del == filter_list_len) {\n\t\t\t\ti40e_aqc_del_filters(vsi, vsi_name, del_list,\n\t\t\t\t\t\t     num_del, &retval);\n\t\t\t\tmemset(del_list, 0, list_size);\n\t\t\t\tnum_del = 0;\n\t\t\t}\n\t\t\t/* Release memory for MAC filter entries which were\n\t\t\t * synced up with HW.\n\t\t\t */\n\t\t\thlist_del(&f->hlist);\n\t\t\tkfree(f);\n\t\t}\n\n\t\tif (num_del) {\n\t\t\ti40e_aqc_del_filters(vsi, vsi_name, del_list,\n\t\t\t\t\t     num_del, &retval);\n\t\t}\n\n\t\tkfree(del_list);\n\t\tdel_list = NULL;\n\t}\n\n\tif (!hlist_empty(&tmp_add_list)) {\n\t\t/* Do all the adds now. */\n\t\tfilter_list_len = hw->aq.asq_buf_size /\n\t\t\t       sizeof(struct i40e_aqc_add_macvlan_element_data);\n\t\tlist_size = filter_list_len *\n\t\t\t       sizeof(struct i40e_aqc_add_macvlan_element_data);\n\t\tadd_list = kzalloc(list_size, GFP_ATOMIC);\n\t\tif (!add_list)\n\t\t\tgoto err_no_memory;\n\n\t\tnum_add = 0;\n\t\thlist_for_each_entry_safe(new, h, &tmp_add_list, hlist) {\n\t\t\t/* handle broadcast filters by updating the broadcast\n\t\t\t * promiscuous flag instead of adding a MAC filter.\n\t\t\t */\n\t\t\tif (is_broadcast_ether_addr(new->f->macaddr)) {\n\t\t\t\tif (i40e_aqc_broadcast_filter(vsi, vsi_name,\n\t\t\t\t\t\t\t      new->f))\n\t\t\t\t\tnew->state = I40E_FILTER_FAILED;\n\t\t\t\telse\n\t\t\t\t\tnew->state = I40E_FILTER_ACTIVE;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* add to add array */\n\t\t\tif (num_add == 0)\n\t\t\t\tadd_head = new;\n\t\t\tcmd_flags = 0;\n\t\t\tether_addr_copy(add_list[num_add].mac_addr,\n\t\t\t\t\tnew->f->macaddr);\n\t\t\tif (new->f->vlan == I40E_VLAN_ANY) {\n\t\t\t\tadd_list[num_add].vlan_tag = 0;\n\t\t\t\tcmd_flags |= I40E_AQC_MACVLAN_ADD_IGNORE_VLAN;\n\t\t\t} else {\n\t\t\t\tadd_list[num_add].vlan_tag =\n\t\t\t\t\tcpu_to_le16((u16)(new->f->vlan));\n\t\t\t}\n\t\t\tadd_list[num_add].queue_number = 0;\n\t\t\t/* set invalid match method for later detection */\n\t\t\tadd_list[num_add].match_method = I40E_AQC_MM_ERR_NO_RES;\n\t\t\tcmd_flags |= I40E_AQC_MACVLAN_ADD_PERFECT_MATCH;\n\t\t\tadd_list[num_add].flags = cpu_to_le16(cmd_flags);\n\t\t\tnum_add++;\n\n\t\t\t/* flush a full buffer */\n\t\t\tif (num_add == filter_list_len) {\n\t\t\t\ti40e_aqc_add_filters(vsi, vsi_name, add_list,\n\t\t\t\t\t\t     add_head, num_add);\n\t\t\t\tmemset(add_list, 0, list_size);\n\t\t\t\tnum_add = 0;\n\t\t\t}\n\t\t}\n\t\tif (num_add) {\n\t\t\ti40e_aqc_add_filters(vsi, vsi_name, add_list, add_head,\n\t\t\t\t\t     num_add);\n\t\t}\n\t\t/* Now move all of the filters from the temp add list back to\n\t\t * the VSI's list.\n\t\t */\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\thlist_for_each_entry_safe(new, h, &tmp_add_list, hlist) {\n\t\t\t/* Only update the state if we're still NEW */\n\t\t\tif (new->f->state == I40E_FILTER_NEW)\n\t\t\t\tnew->f->state = new->state;\n\t\t\thlist_del(&new->hlist);\n\t\t\tkfree(new);\n\t\t}\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t\tkfree(add_list);\n\t\tadd_list = NULL;\n\t}\n\n\t/* Determine the number of active and failed filters. */\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\tvsi->active_filters = 0;\n\thash_for_each(vsi->mac_filter_hash, bkt, f, hlist) {\n\t\tif (f->state == I40E_FILTER_ACTIVE)\n\t\t\tvsi->active_filters++;\n\t\telse if (f->state == I40E_FILTER_FAILED)\n\t\t\tfailed_filters++;\n\t}\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\t/* Check if we are able to exit overflow promiscuous mode. We can\n\t * safely exit if we didn't just enter, we no longer have any failed\n\t * filters, and we have reduced filters below the threshold value.\n\t */\n\tif (old_overflow && !failed_filters &&\n\t    vsi->active_filters < vsi->promisc_threshold) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"filter logjam cleared on %s, leaving overflow promiscuous mode\\n\",\n\t\t\t vsi_name);\n\t\tclear_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\tvsi->promisc_threshold = 0;\n\t}\n\n\t/* if the VF is not trusted do not do promisc */\n\tif ((vsi->type == I40E_VSI_SRIOV) && !pf->vf[vsi->vf_id].trusted) {\n\t\tclear_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\tgoto out;\n\t}\n\n\tnew_overflow = test_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\n\t/* If we are entering overflow promiscuous, we need to calculate a new\n\t * threshold for when we are safe to exit\n\t */\n\tif (!old_overflow && new_overflow)\n\t\tvsi->promisc_threshold = (vsi->active_filters * 3) / 4;\n\n\t/* check for changes in promiscuous modes */\n\tif (changed_flags & IFF_ALLMULTI) {\n\t\tbool cur_multipromisc;\n\n\t\tcur_multipromisc = !!(vsi->current_netdev_flags & IFF_ALLMULTI);\n\t\taq_ret = i40e_aq_set_vsi_multicast_promiscuous(&vsi->back->hw,\n\t\t\t\t\t\t\t       vsi->seid,\n\t\t\t\t\t\t\t       cur_multipromisc,\n\t\t\t\t\t\t\t       NULL);\n\t\tif (aq_ret) {\n\t\t\tretval = i40e_aq_rc_to_posix(aq_ret,\n\t\t\t\t\t\t     hw->aq.asq_last_status);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"set multi promisc failed on %s, err %s aq_err %s\\n\",\n\t\t\t\t vsi_name,\n\t\t\t\t i40e_stat_str(hw, aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t} else {\n\t\t\tdev_info(&pf->pdev->dev, \"%s is %s allmulti mode.\\n\",\n\t\t\t\t vsi->netdev->name,\n\t\t\t\t cur_multipromisc ? \"entering\" : \"leaving\");\n\t\t}\n\t}\n\n\tif ((changed_flags & IFF_PROMISC) || old_overflow != new_overflow) {\n\t\tbool cur_promisc;\n\n\t\tcur_promisc = (!!(vsi->current_netdev_flags & IFF_PROMISC) ||\n\t\t\t       new_overflow);\n\t\taq_ret = i40e_set_promiscuous(pf, cur_promisc);\n\t\tif (aq_ret) {\n\t\t\tretval = i40e_aq_rc_to_posix(aq_ret,\n\t\t\t\t\t\t     hw->aq.asq_last_status);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Setting promiscuous %s failed on %s, err %s aq_err %s\\n\",\n\t\t\t\t cur_promisc ? \"on\" : \"off\",\n\t\t\t\t vsi_name,\n\t\t\t\t i40e_stat_str(hw, aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t}\nout:\n\t/* if something went wrong then set the changed flag so we try again */\n\tif (retval)\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\n\tclear_bit(__I40E_VSI_SYNCING_FILTERS, vsi->state);\n\treturn retval;\n\nerr_no_memory:\n\t/* Restore elements on the temporary add and delete lists */\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\nerr_no_memory_locked:\n\ti40e_undo_del_filter_entries(vsi, &tmp_del_list);\n\ti40e_undo_add_filter_entries(vsi, &tmp_add_list);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\tclear_bit(__I40E_VSI_SYNCING_FILTERS, vsi->state);\n\treturn -ENOMEM;\n}\n\n/**\n * i40e_sync_filters_subtask - Sync the VSI filter list with HW\n * @pf: board private structure\n **/\nstatic void i40e_sync_filters_subtask(struct i40e_pf *pf)\n{\n\tint v;\n\n\tif (!pf)\n\t\treturn;\n\tif (!test_and_clear_bit(__I40E_MACVLAN_SYNC_PENDING, pf->state))\n\t\treturn;\n\tif (test_and_set_bit(__I40E_VF_DISABLE, pf->state)) {\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, pf->state);\n\t\treturn;\n\t}\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v] &&\n\t\t    (pf->vsi[v]->flags & I40E_VSI_FLAG_FILTER_CHANGED)) {\n\t\t\tint ret = i40e_sync_vsi_filters(pf->vsi[v]);\n\n\t\t\tif (ret) {\n\t\t\t\t/* come back and try again later */\n\t\t\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING,\n\t\t\t\t\tpf->state);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tclear_bit(__I40E_VF_DISABLE, pf->state);\n}\n\n/**\n * i40e_max_xdp_frame_size - returns the maximum allowed frame size for XDP\n * @vsi: the vsi\n **/\nstatic int i40e_max_xdp_frame_size(struct i40e_vsi *vsi)\n{\n\tif (PAGE_SIZE >= 8192 || (vsi->back->flags & I40E_FLAG_LEGACY_RX))\n\t\treturn I40E_RXBUFFER_2048;\n\telse\n\t\treturn I40E_RXBUFFER_3072;\n}\n\n/**\n * i40e_change_mtu - NDO callback to change the Maximum Transfer Unit\n * @netdev: network interface device structure\n * @new_mtu: new value for maximum frame size\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tint frame_size = new_mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\n\n\t\tif (frame_size > i40e_max_xdp_frame_size(vsi))\n\t\t\treturn -EINVAL;\n\t}\n\n\tnetdev_info(netdev, \"changing MTU from %d to %d\\n\",\n\t\t    netdev->mtu, new_mtu);\n\tnetdev->mtu = new_mtu;\n\tif (netif_running(netdev))\n\t\ti40e_vsi_reinit_locked(vsi);\n\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\tset_bit(__I40E_CLIENT_L2_CHANGE, pf->state);\n\treturn 0;\n}\n\n/**\n * i40e_ioctl - Access the hwtstamp interface\n * @netdev: network interface device structure\n * @ifr: interface request data\n * @cmd: ioctl command\n **/\nint i40e_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_pf *pf = np->vsi->back;\n\n\tswitch (cmd) {\n\tcase SIOCGHWTSTAMP:\n\t\treturn i40e_ptp_get_ts_config(pf, ifr);\n\tcase SIOCSHWTSTAMP:\n\t\treturn i40e_ptp_set_ts_config(pf, ifr);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n/**\n * i40e_vlan_stripping_enable - Turn on vlan stripping for the VSI\n * @vsi: the vsi being adjusted\n **/\nvoid i40e_vlan_stripping_enable(struct i40e_vsi *vsi)\n{\n\tstruct i40e_vsi_context ctxt;\n\ti40e_status ret;\n\n\t/* Don't modify stripping options if a port VLAN is active */\n\tif (vsi->info.pvid)\n\t\treturn;\n\n\tif ((vsi->info.valid_sections &\n\t     cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID)) &&\n\t    ((vsi->info.port_vlan_flags & I40E_AQ_VSI_PVLAN_MODE_MASK) == 0))\n\t\treturn;  /* already enabled */\n\n\tvsi->info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\tvsi->info.port_vlan_flags = I40E_AQ_VSI_PVLAN_MODE_ALL |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_EMOD_STR_BOTH;\n\n\tctxt.seid = vsi->seid;\n\tctxt.info = vsi->info;\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"update vlan stripping failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&vsi->back->hw, ret),\n\t\t\t i40e_aq_str(&vsi->back->hw,\n\t\t\t\t     vsi->back->hw.aq.asq_last_status));\n\t}\n}\n\n/**\n * i40e_vlan_stripping_disable - Turn off vlan stripping for the VSI\n * @vsi: the vsi being adjusted\n **/\nvoid i40e_vlan_stripping_disable(struct i40e_vsi *vsi)\n{\n\tstruct i40e_vsi_context ctxt;\n\ti40e_status ret;\n\n\t/* Don't modify stripping options if a port VLAN is active */\n\tif (vsi->info.pvid)\n\t\treturn;\n\n\tif ((vsi->info.valid_sections &\n\t     cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID)) &&\n\t    ((vsi->info.port_vlan_flags & I40E_AQ_VSI_PVLAN_EMOD_MASK) ==\n\t     I40E_AQ_VSI_PVLAN_EMOD_MASK))\n\t\treturn;  /* already disabled */\n\n\tvsi->info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\tvsi->info.port_vlan_flags = I40E_AQ_VSI_PVLAN_MODE_ALL |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_EMOD_NOTHING;\n\n\tctxt.seid = vsi->seid;\n\tctxt.info = vsi->info;\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"update vlan stripping failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&vsi->back->hw, ret),\n\t\t\t i40e_aq_str(&vsi->back->hw,\n\t\t\t\t     vsi->back->hw.aq.asq_last_status));\n\t}\n}\n\n/**\n * i40e_add_vlan_all_mac - Add a MAC/VLAN filter for each existing MAC address\n * @vsi: the vsi being configured\n * @vid: vlan id to be added (0 = untagged only , -1 = any)\n *\n * This is a helper function for adding a new MAC/VLAN filter with the\n * specified VLAN for each existing MAC address already in the hash table.\n * This function does *not* perform any accounting to update filters based on\n * VLAN mode.\n *\n * NOTE: this function expects to be called while under the\n * mac_filter_hash_lock\n **/\nint i40e_add_vlan_all_mac(struct i40e_vsi *vsi, s16 vid)\n{\n\tstruct i40e_mac_filter *f, *add_f;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (f->state == I40E_FILTER_REMOVE)\n\t\t\tcontinue;\n\t\tadd_f = i40e_add_filter(vsi, f->macaddr, vid);\n\t\tif (!add_f) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"Could not add vlan filter %d for %pM\\n\",\n\t\t\t\t vid, f->macaddr);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_add_vlan - Add VSI membership for given VLAN\n * @vsi: the VSI being configured\n * @vid: VLAN id to be added\n **/\nint i40e_vsi_add_vlan(struct i40e_vsi *vsi, u16 vid)\n{\n\tint err;\n\n\tif (vsi->info.pvid)\n\t\treturn -EINVAL;\n\n\t/* The network stack will attempt to add VID=0, with the intention to\n\t * receive priority tagged packets with a VLAN of 0. Our HW receives\n\t * these packets by default when configured to receive untagged\n\t * packets, so we don't need to add a filter for this case.\n\t * Additionally, HW interprets adding a VID=0 filter as meaning to\n\t * receive *only* tagged traffic and stops receiving untagged traffic.\n\t * Thus, we do not want to actually add a filter for VID=0\n\t */\n\tif (!vid)\n\t\treturn 0;\n\n\t/* Locked once because all functions invoked below iterates list*/\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\terr = i40e_add_vlan_all_mac(vsi, vid);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\tif (err)\n\t\treturn err;\n\n\t/* schedule our worker thread which will take care of\n\t * applying the new filter changes\n\t */\n\ti40e_service_event_schedule(vsi->back);\n\treturn 0;\n}\n\n/**\n * i40e_rm_vlan_all_mac - Remove MAC/VLAN pair for all MAC with the given VLAN\n * @vsi: the vsi being configured\n * @vid: vlan id to be removed (0 = untagged only , -1 = any)\n *\n * This function should be used to remove all VLAN filters which match the\n * given VID. It does not schedule the service event and does not take the\n * mac_filter_hash_lock so it may be combined with other operations under\n * a single invocation of the mac_filter_hash_lock.\n *\n * NOTE: this function expects to be called while under the\n * mac_filter_hash_lock\n */\nvoid i40e_rm_vlan_all_mac(struct i40e_vsi *vsi, s16 vid)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (f->vlan == vid)\n\t\t\t__i40e_del_filter(vsi, f);\n\t}\n}\n\n/**\n * i40e_vsi_kill_vlan - Remove VSI membership for given VLAN\n * @vsi: the VSI being configured\n * @vid: VLAN id to be removed\n **/\nvoid i40e_vsi_kill_vlan(struct i40e_vsi *vsi, u16 vid)\n{\n\tif (!vid || vsi->info.pvid)\n\t\treturn;\n\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\ti40e_rm_vlan_all_mac(vsi, vid);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\t/* schedule our worker thread which will take care of\n\t * applying the new filter changes\n\t */\n\ti40e_service_event_schedule(vsi->back);\n}\n\n/**\n * i40e_vlan_rx_add_vid - Add a vlan id filter to HW offload\n * @netdev: network interface to be adjusted\n * @proto: unused protocol value\n * @vid: vlan id to be added\n *\n * net_device_ops implementation for adding vlan ids\n **/\nstatic int i40e_vlan_rx_add_vid(struct net_device *netdev,\n\t\t\t\t__always_unused __be16 proto, u16 vid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tint ret = 0;\n\n\tif (vid >= VLAN_N_VID)\n\t\treturn -EINVAL;\n\n\tret = i40e_vsi_add_vlan(vsi, vid);\n\tif (!ret)\n\t\tset_bit(vid, vsi->active_vlans);\n\n\treturn ret;\n}\n\n/**\n * i40e_vlan_rx_add_vid_up - Add a vlan id filter to HW offload in UP path\n * @netdev: network interface to be adjusted\n * @proto: unused protocol value\n * @vid: vlan id to be added\n **/\nstatic void i40e_vlan_rx_add_vid_up(struct net_device *netdev,\n\t\t\t\t    __always_unused __be16 proto, u16 vid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tif (vid >= VLAN_N_VID)\n\t\treturn;\n\tset_bit(vid, vsi->active_vlans);\n}\n\n/**\n * i40e_vlan_rx_kill_vid - Remove a vlan id filter from HW offload\n * @netdev: network interface to be adjusted\n * @proto: unused protocol value\n * @vid: vlan id to be removed\n *\n * net_device_ops implementation for removing vlan ids\n **/\nstatic int i40e_vlan_rx_kill_vid(struct net_device *netdev,\n\t\t\t\t __always_unused __be16 proto, u16 vid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\t/* return code is ignored as there is nothing a user\n\t * can do about failure to remove and a log message was\n\t * already printed from the other function\n\t */\n\ti40e_vsi_kill_vlan(vsi, vid);\n\n\tclear_bit(vid, vsi->active_vlans);\n\n\treturn 0;\n}\n\n/**\n * i40e_restore_vlan - Reinstate vlans when vsi/netdev comes back up\n * @vsi: the vsi being brought back up\n **/\nstatic void i40e_restore_vlan(struct i40e_vsi *vsi)\n{\n\tu16 vid;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\tif (vsi->netdev->features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\ti40e_vlan_stripping_enable(vsi);\n\telse\n\t\ti40e_vlan_stripping_disable(vsi);\n\n\tfor_each_set_bit(vid, vsi->active_vlans, VLAN_N_VID)\n\t\ti40e_vlan_rx_add_vid_up(vsi->netdev, htons(ETH_P_8021Q),\n\t\t\t\t\tvid);\n}\n\n/**\n * i40e_vsi_add_pvid - Add pvid for the VSI\n * @vsi: the vsi being adjusted\n * @vid: the vlan id to set as a PVID\n **/\nint i40e_vsi_add_pvid(struct i40e_vsi *vsi, u16 vid)\n{\n\tstruct i40e_vsi_context ctxt;\n\ti40e_status ret;\n\n\tvsi->info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\tvsi->info.pvid = cpu_to_le16(vid);\n\tvsi->info.port_vlan_flags = I40E_AQ_VSI_PVLAN_MODE_TAGGED |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_INSERT_PVID |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_EMOD_STR;\n\n\tctxt.seid = vsi->seid;\n\tctxt.info = vsi->info;\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"add pvid failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&vsi->back->hw, ret),\n\t\t\t i40e_aq_str(&vsi->back->hw,\n\t\t\t\t     vsi->back->hw.aq.asq_last_status));\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_remove_pvid - Remove the pvid from the VSI\n * @vsi: the vsi being adjusted\n *\n * Just use the vlan_rx_register() service to put it back to normal\n **/\nvoid i40e_vsi_remove_pvid(struct i40e_vsi *vsi)\n{\n\tvsi->info.pvid = 0;\n\n\ti40e_vlan_stripping_disable(vsi);\n}\n\n/**\n * i40e_vsi_setup_tx_resources - Allocate VSI Tx queue resources\n * @vsi: ptr to the VSI\n *\n * If this function returns with an error, then it's possible one or\n * more of the rings is populated (while the rest are not).  It is the\n * callers duty to clean those orphaned rings.\n *\n * Return 0 on success, negative on failure\n **/\nstatic int i40e_vsi_setup_tx_resources(struct i40e_vsi *vsi)\n{\n\tint i, err = 0;\n\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_setup_tx_descriptors(vsi->tx_rings[i]);\n\n\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\treturn err;\n\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_setup_tx_descriptors(vsi->xdp_rings[i]);\n\n\treturn err;\n}\n\n/**\n * i40e_vsi_free_tx_resources - Free Tx resources for VSI queues\n * @vsi: ptr to the VSI\n *\n * Free VSI's transmit software resources\n **/\nstatic void i40e_vsi_free_tx_resources(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\tif (vsi->tx_rings) {\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tif (vsi->tx_rings[i] && vsi->tx_rings[i]->desc)\n\t\t\t\ti40e_free_tx_resources(vsi->tx_rings[i]);\n\t}\n\n\tif (vsi->xdp_rings) {\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tif (vsi->xdp_rings[i] && vsi->xdp_rings[i]->desc)\n\t\t\t\ti40e_free_tx_resources(vsi->xdp_rings[i]);\n\t}\n}\n\n/**\n * i40e_vsi_setup_rx_resources - Allocate VSI queues Rx resources\n * @vsi: ptr to the VSI\n *\n * If this function returns with an error, then it's possible one or\n * more of the rings is populated (while the rest are not).  It is the\n * callers duty to clean those orphaned rings.\n *\n * Return 0 on success, negative on failure\n **/\nstatic int i40e_vsi_setup_rx_resources(struct i40e_vsi *vsi)\n{\n\tint i, err = 0;\n\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_setup_rx_descriptors(vsi->rx_rings[i]);\n\treturn err;\n}\n\n/**\n * i40e_vsi_free_rx_resources - Free Rx Resources for VSI queues\n * @vsi: ptr to the VSI\n *\n * Free all receive software resources\n **/\nstatic void i40e_vsi_free_rx_resources(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\tif (!vsi->rx_rings)\n\t\treturn;\n\n\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\tif (vsi->rx_rings[i] && vsi->rx_rings[i]->desc)\n\t\t\ti40e_free_rx_resources(vsi->rx_rings[i]);\n}\n\n/**\n * i40e_config_xps_tx_ring - Configure XPS for a Tx ring\n * @ring: The Tx ring to configure\n *\n * This enables/disables XPS for a given Tx descriptor ring\n * based on the TCs enabled for the VSI that ring belongs to.\n **/\nstatic void i40e_config_xps_tx_ring(struct i40e_ring *ring)\n{\n\tint cpu;\n\n\tif (!ring->q_vector || !ring->netdev || ring->ch)\n\t\treturn;\n\n\t/* We only initialize XPS once, so as not to overwrite user settings */\n\tif (test_and_set_bit(__I40E_TX_XPS_INIT_DONE, ring->state))\n\t\treturn;\n\n\tcpu = cpumask_local_spread(ring->q_vector->v_idx, -1);\n\tnetif_set_xps_queue(ring->netdev, get_cpu_mask(cpu),\n\t\t\t    ring->queue_index);\n}\n\n/**\n * i40e_xsk_umem - Retrieve the AF_XDP ZC if XDP and ZC is enabled\n * @ring: The Tx or Rx ring\n *\n * Returns the UMEM or NULL.\n **/\nstatic struct xdp_umem *i40e_xsk_umem(struct i40e_ring *ring)\n{\n\tbool xdp_on = i40e_enabled_xdp_vsi(ring->vsi);\n\tint qid = ring->queue_index;\n\n\tif (ring_is_xdp(ring))\n\t\tqid -= ring->vsi->alloc_queue_pairs;\n\n\tif (!xdp_on || !test_bit(qid, ring->vsi->af_xdp_zc_qps))\n\t\treturn NULL;\n\n\treturn xdp_get_umem_from_qid(ring->vsi->netdev, qid);\n}\n\n/**\n * i40e_configure_tx_ring - Configure a transmit ring context and rest\n * @ring: The Tx ring to configure\n *\n * Configure the Tx descriptor ring in the HMC context.\n **/\nstatic int i40e_configure_tx_ring(struct i40e_ring *ring)\n{\n\tstruct i40e_vsi *vsi = ring->vsi;\n\tu16 pf_q = vsi->base_queue + ring->queue_index;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tstruct i40e_hmc_obj_txq tx_ctx;\n\ti40e_status err = 0;\n\tu32 qtx_ctl = 0;\n\n\tif (ring_is_xdp(ring))\n\t\tring->xsk_umem = i40e_xsk_umem(ring);\n\n\t/* some ATR related tx ring init */\n\tif (vsi->back->flags & I40E_FLAG_FD_ATR_ENABLED) {\n\t\tring->atr_sample_rate = vsi->back->atr_sample_rate;\n\t\tring->atr_count = 0;\n\t} else {\n\t\tring->atr_sample_rate = 0;\n\t}\n\n\t/* configure XPS */\n\ti40e_config_xps_tx_ring(ring);\n\n\t/* clear the context structure first */\n\tmemset(&tx_ctx, 0, sizeof(tx_ctx));\n\n\ttx_ctx.new_context = 1;\n\ttx_ctx.base = (ring->dma / 128);\n\ttx_ctx.qlen = ring->count;\n\ttx_ctx.fd_ena = !!(vsi->back->flags & (I40E_FLAG_FD_SB_ENABLED |\n\t\t\t\t\t       I40E_FLAG_FD_ATR_ENABLED));\n\ttx_ctx.timesync_ena = !!(vsi->back->flags & I40E_FLAG_PTP);\n\t/* FDIR VSI tx ring can still use RS bit and writebacks */\n\tif (vsi->type != I40E_VSI_FDIR)\n\t\ttx_ctx.head_wb_ena = 1;\n\ttx_ctx.head_wb_addr = ring->dma +\n\t\t\t      (ring->count * sizeof(struct i40e_tx_desc));\n\n\t/* As part of VSI creation/update, FW allocates certain\n\t * Tx arbitration queue sets for each TC enabled for\n\t * the VSI. The FW returns the handles to these queue\n\t * sets as part of the response buffer to Add VSI,\n\t * Update VSI, etc. AQ commands. It is expected that\n\t * these queue set handles be associated with the Tx\n\t * queues by the driver as part of the TX queue context\n\t * initialization. This has to be done regardless of\n\t * DCB as by default everything is mapped to TC0.\n\t */\n\n\tif (ring->ch)\n\t\ttx_ctx.rdylist =\n\t\t\tle16_to_cpu(ring->ch->info.qs_handle[ring->dcb_tc]);\n\n\telse\n\t\ttx_ctx.rdylist = le16_to_cpu(vsi->info.qs_handle[ring->dcb_tc]);\n\n\ttx_ctx.rdylist_act = 0;\n\n\t/* clear the context in the HMC */\n\terr = i40e_clear_lan_tx_queue_context(hw, pf_q);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to clear LAN Tx queue context on Tx ring %d (pf_q %d), error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* set the context in the HMC */\n\terr = i40e_set_lan_tx_queue_context(hw, pf_q, &tx_ctx);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to set LAN Tx queue context on Tx ring %d (pf_q %d, error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Now associate this queue with this PCI function */\n\tif (ring->ch) {\n\t\tif (ring->ch->type == I40E_VSI_VMDQ2)\n\t\t\tqtx_ctl = I40E_QTX_CTL_VM_QUEUE;\n\t\telse\n\t\t\treturn -EINVAL;\n\n\t\tqtx_ctl |= (ring->ch->vsi_number <<\n\t\t\t    I40E_QTX_CTL_VFVM_INDX_SHIFT) &\n\t\t\t    I40E_QTX_CTL_VFVM_INDX_MASK;\n\t} else {\n\t\tif (vsi->type == I40E_VSI_VMDQ2) {\n\t\t\tqtx_ctl = I40E_QTX_CTL_VM_QUEUE;\n\t\t\tqtx_ctl |= ((vsi->id) << I40E_QTX_CTL_VFVM_INDX_SHIFT) &\n\t\t\t\t    I40E_QTX_CTL_VFVM_INDX_MASK;\n\t\t} else {\n\t\t\tqtx_ctl = I40E_QTX_CTL_PF_QUEUE;\n\t\t}\n\t}\n\n\tqtx_ctl |= ((hw->pf_id << I40E_QTX_CTL_PF_INDX_SHIFT) &\n\t\t    I40E_QTX_CTL_PF_INDX_MASK);\n\twr32(hw, I40E_QTX_CTL(pf_q), qtx_ctl);\n\ti40e_flush(hw);\n\n\t/* cache tail off for easier writes later */\n\tring->tail = hw->hw_addr + I40E_QTX_TAIL(pf_q);\n\n\treturn 0;\n}\n\n/**\n * i40e_configure_rx_ring - Configure a receive ring context\n * @ring: The Rx ring to configure\n *\n * Configure the Rx descriptor ring in the HMC context.\n **/\nstatic int i40e_configure_rx_ring(struct i40e_ring *ring)\n{\n\tstruct i40e_vsi *vsi = ring->vsi;\n\tu32 chain_len = vsi->back->hw.func_caps.rx_buf_chain_len;\n\tu16 pf_q = vsi->base_queue + ring->queue_index;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tstruct i40e_hmc_obj_rxq rx_ctx;\n\ti40e_status err = 0;\n\tbool ok;\n\tint ret;\n\n\tbitmap_zero(ring->state, __I40E_RING_STATE_NBITS);\n\n\t/* clear the context structure first */\n\tmemset(&rx_ctx, 0, sizeof(rx_ctx));\n\n\tif (ring->vsi->type == I40E_VSI_MAIN)\n\t\txdp_rxq_info_unreg_mem_model(&ring->xdp_rxq);\n\n\tring->xsk_umem = i40e_xsk_umem(ring);\n\tif (ring->xsk_umem) {\n\t\tring->rx_buf_len = ring->xsk_umem->chunk_size_nohr -\n\t\t\t\t   XDP_PACKET_HEADROOM;\n\t\t/* For AF_XDP ZC, we disallow packets to span on\n\t\t * multiple buffers, thus letting us skip that\n\t\t * handling in the fast-path.\n\t\t */\n\t\tchain_len = 1;\n\t\tring->zca.free = i40e_zca_free;\n\t\tret = xdp_rxq_info_reg_mem_model(&ring->xdp_rxq,\n\t\t\t\t\t\t MEM_TYPE_ZERO_COPY,\n\t\t\t\t\t\t &ring->zca);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Registered XDP mem model MEM_TYPE_ZERO_COPY on Rx ring %d\\n\",\n\t\t\t ring->queue_index);\n\n\t} else {\n\t\tring->rx_buf_len = vsi->rx_buf_len;\n\t\tif (ring->vsi->type == I40E_VSI_MAIN) {\n\t\t\tret = xdp_rxq_info_reg_mem_model(&ring->xdp_rxq,\n\t\t\t\t\t\t\t MEM_TYPE_PAGE_SHARED,\n\t\t\t\t\t\t\t NULL);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\trx_ctx.dbuff = DIV_ROUND_UP(ring->rx_buf_len,\n\t\t\t\t    BIT_ULL(I40E_RXQ_CTX_DBUFF_SHIFT));\n\n\trx_ctx.base = (ring->dma / 128);\n\trx_ctx.qlen = ring->count;\n\n\t/* use 32 byte descriptors */\n\trx_ctx.dsize = 1;\n\n\t/* descriptor type is always zero\n\t * rx_ctx.dtype = 0;\n\t */\n\trx_ctx.hsplit_0 = 0;\n\n\trx_ctx.rxmax = min_t(u16, vsi->max_frame, chain_len * ring->rx_buf_len);\n\tif (hw->revision_id == 0)\n\t\trx_ctx.lrxqthresh = 0;\n\telse\n\t\trx_ctx.lrxqthresh = 1;\n\trx_ctx.crcstrip = 1;\n\trx_ctx.l2tsel = 1;\n\t/* this controls whether VLAN is stripped from inner headers */\n\trx_ctx.showiv = 0;\n\t/* set the prefena field to 1 because the manual says to */\n\trx_ctx.prefena = 1;\n\n\t/* clear the context in the HMC */\n\terr = i40e_clear_lan_rx_queue_context(hw, pf_q);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to clear LAN Rx queue context on Rx ring %d (pf_q %d), error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* set the context in the HMC */\n\terr = i40e_set_lan_rx_queue_context(hw, pf_q, &rx_ctx);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to set LAN Rx queue context on Rx ring %d (pf_q %d), error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* configure Rx buffer alignment */\n\tif (!vsi->netdev || (vsi->back->flags & I40E_FLAG_LEGACY_RX))\n\t\tclear_ring_build_skb_enabled(ring);\n\telse\n\t\tset_ring_build_skb_enabled(ring);\n\n\t/* cache tail for quicker writes, and clear the reg before use */\n\tring->tail = hw->hw_addr + I40E_QRX_TAIL(pf_q);\n\twritel(0, ring->tail);\n\n\tok = ring->xsk_umem ?\n\t     i40e_alloc_rx_buffers_zc(ring, I40E_DESC_UNUSED(ring)) :\n\t     !i40e_alloc_rx_buffers(ring, I40E_DESC_UNUSED(ring));\n\tif (!ok) {\n\t\t/* Log this in case the user has forgotten to give the kernel\n\t\t * any buffers, even later in the application.\n\t\t */\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to allocate some buffers on %sRx ring %d (pf_q %d)\\n\",\n\t\t\t ring->xsk_umem ? \"UMEM enabled \" : \"\",\n\t\t\t ring->queue_index, pf_q);\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_configure_tx - Configure the VSI for Tx\n * @vsi: VSI structure describing this set of rings and resources\n *\n * Configure the Tx VSI for operation.\n **/\nstatic int i40e_vsi_configure_tx(struct i40e_vsi *vsi)\n{\n\tint err = 0;\n\tu16 i;\n\n\tfor (i = 0; (i < vsi->num_queue_pairs) && !err; i++)\n\t\terr = i40e_configure_tx_ring(vsi->tx_rings[i]);\n\n\tif (err || !i40e_enabled_xdp_vsi(vsi))\n\t\treturn err;\n\n\tfor (i = 0; (i < vsi->num_queue_pairs) && !err; i++)\n\t\terr = i40e_configure_tx_ring(vsi->xdp_rings[i]);\n\n\treturn err;\n}\n\n/**\n * i40e_vsi_configure_rx - Configure the VSI for Rx\n * @vsi: the VSI being configured\n *\n * Configure the Rx VSI for operation.\n **/\nstatic int i40e_vsi_configure_rx(struct i40e_vsi *vsi)\n{\n\tint err = 0;\n\tu16 i;\n\n\tif (!vsi->netdev || (vsi->back->flags & I40E_FLAG_LEGACY_RX)) {\n\t\tvsi->max_frame = I40E_MAX_RXBUFFER;\n\t\tvsi->rx_buf_len = I40E_RXBUFFER_2048;\n#if (PAGE_SIZE < 8192)\n\t} else if (!I40E_2K_TOO_SMALL_WITH_PADDING &&\n\t\t   (vsi->netdev->mtu <= ETH_DATA_LEN)) {\n\t\tvsi->max_frame = I40E_RXBUFFER_1536 - NET_IP_ALIGN;\n\t\tvsi->rx_buf_len = I40E_RXBUFFER_1536 - NET_IP_ALIGN;\n#endif\n\t} else {\n\t\tvsi->max_frame = I40E_MAX_RXBUFFER;\n\t\tvsi->rx_buf_len = (PAGE_SIZE < 8192) ? I40E_RXBUFFER_3072 :\n\t\t\t\t\t\t       I40E_RXBUFFER_2048;\n\t}\n\n\t/* set up individual rings */\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_configure_rx_ring(vsi->rx_rings[i]);\n\n\treturn err;\n}\n\n/**\n * i40e_vsi_config_dcb_rings - Update rings to reflect DCB TC\n * @vsi: ptr to the VSI\n **/\nstatic void i40e_vsi_config_dcb_rings(struct i40e_vsi *vsi)\n{\n\tstruct i40e_ring *tx_ring, *rx_ring;\n\tu16 qoffset, qcount;\n\tint i, n;\n\n\tif (!(vsi->back->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\t/* Reset the TC information */\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\t\trx_ring = vsi->rx_rings[i];\n\t\t\ttx_ring = vsi->tx_rings[i];\n\t\t\trx_ring->dcb_tc = 0;\n\t\t\ttx_ring->dcb_tc = 0;\n\t\t}\n\t\treturn;\n\t}\n\n\tfor (n = 0; n < I40E_MAX_TRAFFIC_CLASS; n++) {\n\t\tif (!(vsi->tc_config.enabled_tc & BIT_ULL(n)))\n\t\t\tcontinue;\n\n\t\tqoffset = vsi->tc_config.tc_info[n].qoffset;\n\t\tqcount = vsi->tc_config.tc_info[n].qcount;\n\t\tfor (i = qoffset; i < (qoffset + qcount); i++) {\n\t\t\trx_ring = vsi->rx_rings[i];\n\t\t\ttx_ring = vsi->tx_rings[i];\n\t\t\trx_ring->dcb_tc = n;\n\t\t\ttx_ring->dcb_tc = n;\n\t\t}\n\t}\n}\n\n/**\n * i40e_set_vsi_rx_mode - Call set_rx_mode on a VSI\n * @vsi: ptr to the VSI\n **/\nstatic void i40e_set_vsi_rx_mode(struct i40e_vsi *vsi)\n{\n\tif (vsi->netdev)\n\t\ti40e_set_rx_mode(vsi->netdev);\n}\n\n/**\n * i40e_fdir_filter_restore - Restore the Sideband Flow Director filters\n * @vsi: Pointer to the targeted VSI\n *\n * This function replays the hlist on the hw where all the SB Flow Director\n * filters were saved.\n **/\nstatic void i40e_fdir_filter_restore(struct i40e_vsi *vsi)\n{\n\tstruct i40e_fdir_filter *filter;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct hlist_node *node;\n\n\tif (!(pf->flags & I40E_FLAG_FD_SB_ENABLED))\n\t\treturn;\n\n\t/* Reset FDir counters as we're replaying all existing filters */\n\tpf->fd_tcp4_filter_cnt = 0;\n\tpf->fd_udp4_filter_cnt = 0;\n\tpf->fd_sctp4_filter_cnt = 0;\n\tpf->fd_ip4_filter_cnt = 0;\n\n\thlist_for_each_entry_safe(filter, node,\n\t\t\t\t  &pf->fdir_filter_list, fdir_node) {\n\t\ti40e_add_del_fdir(vsi, filter, true);\n\t}\n}\n\n/**\n * i40e_vsi_configure - Set up the VSI for action\n * @vsi: the VSI being configured\n **/\nstatic int i40e_vsi_configure(struct i40e_vsi *vsi)\n{\n\tint err;\n\n\ti40e_set_vsi_rx_mode(vsi);\n\ti40e_restore_vlan(vsi);\n\ti40e_vsi_config_dcb_rings(vsi);\n\terr = i40e_vsi_configure_tx(vsi);\n\tif (!err)\n\t\terr = i40e_vsi_configure_rx(vsi);\n\n\treturn err;\n}\n\n/**\n * i40e_vsi_configure_msix - MSIX mode Interrupt Config in the HW\n * @vsi: the VSI being configured\n **/\nstatic void i40e_vsi_configure_msix(struct i40e_vsi *vsi)\n{\n\tbool has_xdp = i40e_enabled_xdp_vsi(vsi);\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 vector;\n\tint i, q;\n\tu32 qp;\n\n\t/* The interrupt indexing is offset by 1 in the PFINT_ITRn\n\t * and PFINT_LNKLSTn registers, e.g.:\n\t *   PFINT_ITRn[0..n-1] gets msix-1..msix-n  (qpair interrupts)\n\t */\n\tqp = vsi->base_queue;\n\tvector = vsi->base_vector;\n\tfor (i = 0; i < vsi->num_q_vectors; i++, vector++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[i];\n\n\t\tq_vector->rx.next_update = jiffies + 1;\n\t\tq_vector->rx.target_itr =\n\t\t\tITR_TO_REG(vsi->rx_rings[i]->itr_setting);\n\t\twr32(hw, I40E_PFINT_ITRN(I40E_RX_ITR, vector - 1),\n\t\t     q_vector->rx.target_itr >> 1);\n\t\tq_vector->rx.current_itr = q_vector->rx.target_itr;\n\n\t\tq_vector->tx.next_update = jiffies + 1;\n\t\tq_vector->tx.target_itr =\n\t\t\tITR_TO_REG(vsi->tx_rings[i]->itr_setting);\n\t\twr32(hw, I40E_PFINT_ITRN(I40E_TX_ITR, vector - 1),\n\t\t     q_vector->tx.target_itr >> 1);\n\t\tq_vector->tx.current_itr = q_vector->tx.target_itr;\n\n\t\twr32(hw, I40E_PFINT_RATEN(vector - 1),\n\t\t     i40e_intrl_usec_to_reg(vsi->int_rate_limit));\n\n\t\t/* Linked list for the queuepairs assigned to this vector */\n\t\twr32(hw, I40E_PFINT_LNKLSTN(vector - 1), qp);\n\t\tfor (q = 0; q < q_vector->num_ringpairs; q++) {\n\t\t\tu32 nextqp = has_xdp ? qp + vsi->alloc_queue_pairs : qp;\n\t\t\tu32 val;\n\n\t\t\tval = I40E_QINT_RQCTL_CAUSE_ENA_MASK |\n\t\t\t      (I40E_RX_ITR << I40E_QINT_RQCTL_ITR_INDX_SHIFT) |\n\t\t\t      (vector << I40E_QINT_RQCTL_MSIX_INDX_SHIFT) |\n\t\t\t      (nextqp << I40E_QINT_RQCTL_NEXTQ_INDX_SHIFT) |\n\t\t\t      (I40E_QUEUE_TYPE_TX <<\n\t\t\t       I40E_QINT_RQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\t\twr32(hw, I40E_QINT_RQCTL(qp), val);\n\n\t\t\tif (has_xdp) {\n\t\t\t\tval = I40E_QINT_TQCTL_CAUSE_ENA_MASK |\n\t\t\t\t      (I40E_TX_ITR << I40E_QINT_TQCTL_ITR_INDX_SHIFT) |\n\t\t\t\t      (vector << I40E_QINT_TQCTL_MSIX_INDX_SHIFT) |\n\t\t\t\t      (qp << I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT) |\n\t\t\t\t      (I40E_QUEUE_TYPE_TX <<\n\t\t\t\t       I40E_QINT_TQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\t\t\twr32(hw, I40E_QINT_TQCTL(nextqp), val);\n\t\t\t}\n\n\t\t\tval = I40E_QINT_TQCTL_CAUSE_ENA_MASK |\n\t\t\t      (I40E_TX_ITR << I40E_QINT_TQCTL_ITR_INDX_SHIFT) |\n\t\t\t      (vector << I40E_QINT_TQCTL_MSIX_INDX_SHIFT) |\n\t\t\t      ((qp + 1) << I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT) |\n\t\t\t      (I40E_QUEUE_TYPE_RX <<\n\t\t\t       I40E_QINT_TQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\t\t/* Terminate the linked list */\n\t\t\tif (q == (q_vector->num_ringpairs - 1))\n\t\t\t\tval |= (I40E_QUEUE_END_OF_LIST <<\n\t\t\t\t\tI40E_QINT_TQCTL_NEXTQ_INDX_SHIFT);\n\n\t\t\twr32(hw, I40E_QINT_TQCTL(qp), val);\n\t\t\tqp++;\n\t\t}\n\t}\n\n\ti40e_flush(hw);\n}\n\n/**\n * i40e_enable_misc_int_causes - enable the non-queue interrupts\n * @pf: pointer to private device data structure\n **/\nstatic void i40e_enable_misc_int_causes(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\n\t/* clear things first */\n\twr32(hw, I40E_PFINT_ICR0_ENA, 0);  /* disable all */\n\trd32(hw, I40E_PFINT_ICR0);         /* read to clear */\n\n\tval = I40E_PFINT_ICR0_ENA_ECC_ERR_MASK       |\n\t      I40E_PFINT_ICR0_ENA_MAL_DETECT_MASK    |\n\t      I40E_PFINT_ICR0_ENA_GRST_MASK          |\n\t      I40E_PFINT_ICR0_ENA_PCI_EXCEPTION_MASK |\n\t      I40E_PFINT_ICR0_ENA_GPIO_MASK          |\n\t      I40E_PFINT_ICR0_ENA_HMC_ERR_MASK       |\n\t      I40E_PFINT_ICR0_ENA_VFLR_MASK          |\n\t      I40E_PFINT_ICR0_ENA_ADMINQ_MASK;\n\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED)\n\t\tval |= I40E_PFINT_ICR0_ENA_PE_CRITERR_MASK;\n\n\tif (pf->flags & I40E_FLAG_PTP)\n\t\tval |= I40E_PFINT_ICR0_ENA_TIMESYNC_MASK;\n\n\twr32(hw, I40E_PFINT_ICR0_ENA, val);\n\n\t/* SW_ITR_IDX = 0, but don't change INTENA */\n\twr32(hw, I40E_PFINT_DYN_CTL0, I40E_PFINT_DYN_CTL0_SW_ITR_INDX_MASK |\n\t\t\t\t\tI40E_PFINT_DYN_CTL0_INTENA_MSK_MASK);\n\n\t/* OTHER_ITR_IDX = 0 */\n\twr32(hw, I40E_PFINT_STAT_CTL0, 0);\n}\n\n/**\n * i40e_configure_msi_and_legacy - Legacy mode interrupt config in the HW\n * @vsi: the VSI being configured\n **/\nstatic void i40e_configure_msi_and_legacy(struct i40e_vsi *vsi)\n{\n\tu32 nextqp = i40e_enabled_xdp_vsi(vsi) ? vsi->alloc_queue_pairs : 0;\n\tstruct i40e_q_vector *q_vector = vsi->q_vectors[0];\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\n\t/* set the ITR configuration */\n\tq_vector->rx.next_update = jiffies + 1;\n\tq_vector->rx.target_itr = ITR_TO_REG(vsi->rx_rings[0]->itr_setting);\n\twr32(hw, I40E_PFINT_ITR0(I40E_RX_ITR), q_vector->rx.target_itr >> 1);\n\tq_vector->rx.current_itr = q_vector->rx.target_itr;\n\tq_vector->tx.next_update = jiffies + 1;\n\tq_vector->tx.target_itr = ITR_TO_REG(vsi->tx_rings[0]->itr_setting);\n\twr32(hw, I40E_PFINT_ITR0(I40E_TX_ITR), q_vector->tx.target_itr >> 1);\n\tq_vector->tx.current_itr = q_vector->tx.target_itr;\n\n\ti40e_enable_misc_int_causes(pf);\n\n\t/* FIRSTQ_INDX = 0, FIRSTQ_TYPE = 0 (rx) */\n\twr32(hw, I40E_PFINT_LNKLST0, 0);\n\n\t/* Associate the queue pair to the vector and enable the queue int */\n\tval = I40E_QINT_RQCTL_CAUSE_ENA_MASK\t\t       |\n\t      (I40E_RX_ITR << I40E_QINT_RQCTL_ITR_INDX_SHIFT)  |\n\t      (nextqp\t   << I40E_QINT_RQCTL_NEXTQ_INDX_SHIFT)|\n\t      (I40E_QUEUE_TYPE_TX << I40E_QINT_TQCTL_NEXTQ_TYPE_SHIFT);\n\n\twr32(hw, I40E_QINT_RQCTL(0), val);\n\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tval = I40E_QINT_TQCTL_CAUSE_ENA_MASK\t\t     |\n\t\t      (I40E_TX_ITR << I40E_QINT_TQCTL_ITR_INDX_SHIFT)|\n\t\t      (I40E_QUEUE_TYPE_TX\n\t\t       << I40E_QINT_TQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\twr32(hw, I40E_QINT_TQCTL(nextqp), val);\n\t}\n\n\tval = I40E_QINT_TQCTL_CAUSE_ENA_MASK\t\t      |\n\t      (I40E_TX_ITR << I40E_QINT_TQCTL_ITR_INDX_SHIFT) |\n\t      (I40E_QUEUE_END_OF_LIST << I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT);\n\n\twr32(hw, I40E_QINT_TQCTL(0), val);\n\ti40e_flush(hw);\n}\n\n/**\n * i40e_irq_dynamic_disable_icr0 - Disable default interrupt generation for icr0\n * @pf: board private structure\n **/\nvoid i40e_irq_dynamic_disable_icr0(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\n\twr32(hw, I40E_PFINT_DYN_CTL0,\n\t     I40E_ITR_NONE << I40E_PFINT_DYN_CTLN_ITR_INDX_SHIFT);\n\ti40e_flush(hw);\n}\n\n/**\n * i40e_irq_dynamic_enable_icr0 - Enable default interrupt generation for icr0\n * @pf: board private structure\n **/\nvoid i40e_irq_dynamic_enable_icr0(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\n\tval = I40E_PFINT_DYN_CTL0_INTENA_MASK   |\n\t      I40E_PFINT_DYN_CTL0_CLEARPBA_MASK |\n\t      (I40E_ITR_NONE << I40E_PFINT_DYN_CTL0_ITR_INDX_SHIFT);\n\n\twr32(hw, I40E_PFINT_DYN_CTL0, val);\n\ti40e_flush(hw);\n}\n\n/**\n * i40e_msix_clean_rings - MSIX mode Interrupt Handler\n * @irq: interrupt number\n * @data: pointer to a q_vector\n **/\nstatic irqreturn_t i40e_msix_clean_rings(int irq, void *data)\n{\n\tstruct i40e_q_vector *q_vector = data;\n\n\tif (!q_vector->tx.ring && !q_vector->rx.ring)\n\t\treturn IRQ_HANDLED;\n\n\tnapi_schedule_irqoff(&q_vector->napi);\n\n\treturn IRQ_HANDLED;\n}\n\n/**\n * i40e_irq_affinity_notify - Callback for affinity changes\n * @notify: context as to what irq was changed\n * @mask: the new affinity mask\n *\n * This is a callback function used by the irq_set_affinity_notifier function\n * so that we may register to receive changes to the irq affinity masks.\n **/\nstatic void i40e_irq_affinity_notify(struct irq_affinity_notify *notify,\n\t\t\t\t     const cpumask_t *mask)\n{\n\tstruct i40e_q_vector *q_vector =\n\t\tcontainer_of(notify, struct i40e_q_vector, affinity_notify);\n\n\tcpumask_copy(&q_vector->affinity_mask, mask);\n}\n\n/**\n * i40e_irq_affinity_release - Callback for affinity notifier release\n * @ref: internal core kernel usage\n *\n * This is a callback function used by the irq_set_affinity_notifier function\n * to inform the current notification subscriber that they will no longer\n * receive notifications.\n **/\nstatic void i40e_irq_affinity_release(struct kref *ref) {}\n\n/**\n * i40e_vsi_request_irq_msix - Initialize MSI-X interrupts\n * @vsi: the VSI being configured\n * @basename: name for the vector\n *\n * Allocates MSI-X vectors and requests interrupts from the kernel.\n **/\nstatic int i40e_vsi_request_irq_msix(struct i40e_vsi *vsi, char *basename)\n{\n\tint q_vectors = vsi->num_q_vectors;\n\tstruct i40e_pf *pf = vsi->back;\n\tint base = vsi->base_vector;\n\tint rx_int_idx = 0;\n\tint tx_int_idx = 0;\n\tint vector, err;\n\tint irq_num;\n\tint cpu;\n\n\tfor (vector = 0; vector < q_vectors; vector++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[vector];\n\n\t\tirq_num = pf->msix_entries[base + vector].vector;\n\n\t\tif (q_vector->tx.ring && q_vector->rx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name) - 1,\n\t\t\t\t \"%s-%s-%d\", basename, \"TxRx\", rx_int_idx++);\n\t\t\ttx_int_idx++;\n\t\t} else if (q_vector->rx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name) - 1,\n\t\t\t\t \"%s-%s-%d\", basename, \"rx\", rx_int_idx++);\n\t\t} else if (q_vector->tx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name) - 1,\n\t\t\t\t \"%s-%s-%d\", basename, \"tx\", tx_int_idx++);\n\t\t} else {\n\t\t\t/* skip this unused q_vector */\n\t\t\tcontinue;\n\t\t}\n\t\terr = request_irq(irq_num,\n\t\t\t\t  vsi->irq_handler,\n\t\t\t\t  0,\n\t\t\t\t  q_vector->name,\n\t\t\t\t  q_vector);\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"MSIX request_irq failed, error: %d\\n\", err);\n\t\t\tgoto free_queue_irqs;\n\t\t}\n\n\t\t/* register for affinity change notifications */\n\t\tq_vector->affinity_notify.notify = i40e_irq_affinity_notify;\n\t\tq_vector->affinity_notify.release = i40e_irq_affinity_release;\n\t\tirq_set_affinity_notifier(irq_num, &q_vector->affinity_notify);\n\t\t/* Spread affinity hints out across online CPUs.\n\t\t *\n\t\t * get_cpu_mask returns a static constant mask with\n\t\t * a permanent lifetime so it's ok to pass to\n\t\t * irq_set_affinity_hint without making a copy.\n\t\t */\n\t\tcpu = cpumask_local_spread(q_vector->v_idx, -1);\n\t\tirq_set_affinity_hint(irq_num, get_cpu_mask(cpu));\n\t}\n\n\tvsi->irqs_ready = true;\n\treturn 0;\n\nfree_queue_irqs:\n\twhile (vector) {\n\t\tvector--;\n\t\tirq_num = pf->msix_entries[base + vector].vector;\n\t\tirq_set_affinity_notifier(irq_num, NULL);\n\t\tirq_set_affinity_hint(irq_num, NULL);\n\t\tfree_irq(irq_num, &vsi->q_vectors[vector]);\n\t}\n\treturn err;\n}\n\n/**\n * i40e_vsi_disable_irq - Mask off queue interrupt generation on the VSI\n * @vsi: the VSI being un-configured\n **/\nstatic void i40e_vsi_disable_irq(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint base = vsi->base_vector;\n\tint i;\n\n\t/* disable interrupt causation from each queue */\n\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\tu32 val;\n\n\t\tval = rd32(hw, I40E_QINT_TQCTL(vsi->tx_rings[i]->reg_idx));\n\t\tval &= ~I40E_QINT_TQCTL_CAUSE_ENA_MASK;\n\t\twr32(hw, I40E_QINT_TQCTL(vsi->tx_rings[i]->reg_idx), val);\n\n\t\tval = rd32(hw, I40E_QINT_RQCTL(vsi->rx_rings[i]->reg_idx));\n\t\tval &= ~I40E_QINT_RQCTL_CAUSE_ENA_MASK;\n\t\twr32(hw, I40E_QINT_RQCTL(vsi->rx_rings[i]->reg_idx), val);\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tcontinue;\n\t\twr32(hw, I40E_QINT_TQCTL(vsi->xdp_rings[i]->reg_idx), 0);\n\t}\n\n\t/* disable each interrupt */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tfor (i = vsi->base_vector;\n\t\t     i < (vsi->num_q_vectors + vsi->base_vector); i++)\n\t\t\twr32(hw, I40E_PFINT_DYN_CTLN(i - 1), 0);\n\n\t\ti40e_flush(hw);\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++)\n\t\t\tsynchronize_irq(pf->msix_entries[i + base].vector);\n\t} else {\n\t\t/* Legacy and MSI mode - this stops all interrupt handling */\n\t\twr32(hw, I40E_PFINT_ICR0_ENA, 0);\n\t\twr32(hw, I40E_PFINT_DYN_CTL0, 0);\n\t\ti40e_flush(hw);\n\t\tsynchronize_irq(pf->pdev->irq);\n\t}\n}\n\n/**\n * i40e_vsi_enable_irq - Enable IRQ for the given VSI\n * @vsi: the VSI being configured\n **/\nstatic int i40e_vsi_enable_irq(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++)\n\t\t\ti40e_irq_dynamic_enable(vsi, i);\n\t} else {\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\t}\n\n\ti40e_flush(&pf->hw);\n\treturn 0;\n}\n\n/**\n * i40e_free_misc_vector - Free the vector that handles non-queue events\n * @pf: board private structure\n **/\nstatic void i40e_free_misc_vector(struct i40e_pf *pf)\n{\n\t/* Disable ICR 0 */\n\twr32(&pf->hw, I40E_PFINT_ICR0_ENA, 0);\n\ti40e_flush(&pf->hw);\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED && pf->msix_entries) {\n\t\tsynchronize_irq(pf->msix_entries[0].vector);\n\t\tfree_irq(pf->msix_entries[0].vector, pf);\n\t\tclear_bit(__I40E_MISC_IRQ_REQUESTED, pf->state);\n\t}\n}\n\n/**\n * i40e_intr - MSI/Legacy and non-queue interrupt handler\n * @irq: interrupt number\n * @data: pointer to a q_vector\n *\n * This is the handler used for all MSI/Legacy interrupts, and deals\n * with both queue and non-queue interrupts.  This is also used in\n * MSIX mode to handle the non-queue interrupts.\n **/\nstatic irqreturn_t i40e_intr(int irq, void *data)\n{\n\tstruct i40e_pf *pf = (struct i40e_pf *)data;\n\tstruct i40e_hw *hw = &pf->hw;\n\tirqreturn_t ret = IRQ_NONE;\n\tu32 icr0, icr0_remaining;\n\tu32 val, ena_mask;\n\n\ticr0 = rd32(hw, I40E_PFINT_ICR0);\n\tena_mask = rd32(hw, I40E_PFINT_ICR0_ENA);\n\n\t/* if sharing a legacy IRQ, we might get called w/o an intr pending */\n\tif ((icr0 & I40E_PFINT_ICR0_INTEVENT_MASK) == 0)\n\t\tgoto enable_intr;\n\n\t/* if interrupt but no bits showing, must be SWINT */\n\tif (((icr0 & ~I40E_PFINT_ICR0_INTEVENT_MASK) == 0) ||\n\t    (icr0 & I40E_PFINT_ICR0_SWINT_MASK))\n\t\tpf->sw_int_count++;\n\n\tif ((pf->flags & I40E_FLAG_IWARP_ENABLED) &&\n\t    (icr0 & I40E_PFINT_ICR0_ENA_PE_CRITERR_MASK)) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_PE_CRITERR_MASK;\n\t\tdev_dbg(&pf->pdev->dev, \"cleared PE_CRITERR\\n\");\n\t\tset_bit(__I40E_CORE_RESET_REQUESTED, pf->state);\n\t}\n\n\t/* only q0 is used in MSI/Legacy mode, and none are used in MSIX */\n\tif (icr0 & I40E_PFINT_ICR0_QUEUE_0_MASK) {\n\t\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[0];\n\n\t\t/* We do not have a way to disarm Queue causes while leaving\n\t\t * interrupt enabled for all other causes, ideally\n\t\t * interrupt should be disabled while we are in NAPI but\n\t\t * this is not a performance path and napi_schedule()\n\t\t * can deal with rescheduling.\n\t\t */\n\t\tif (!test_bit(__I40E_DOWN, pf->state))\n\t\t\tnapi_schedule_irqoff(&q_vector->napi);\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_ADMINQ_MASK) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_ADMINQ_MASK;\n\t\tset_bit(__I40E_ADMINQ_EVENT_PENDING, pf->state);\n\t\ti40e_debug(&pf->hw, I40E_DEBUG_NVM, \"AdminQ event\\n\");\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_MAL_DETECT_MASK) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_MAL_DETECT_MASK;\n\t\tset_bit(__I40E_MDD_EVENT_PENDING, pf->state);\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_VFLR_MASK) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_VFLR_MASK;\n\t\tset_bit(__I40E_VFLR_EVENT_PENDING, pf->state);\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_GRST_MASK) {\n\t\tif (!test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\t\tset_bit(__I40E_RESET_INTR_RECEIVED, pf->state);\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_GRST_MASK;\n\t\tval = rd32(hw, I40E_GLGEN_RSTAT);\n\t\tval = (val & I40E_GLGEN_RSTAT_RESET_TYPE_MASK)\n\t\t       >> I40E_GLGEN_RSTAT_RESET_TYPE_SHIFT;\n\t\tif (val == I40E_RESET_CORER) {\n\t\t\tpf->corer_count++;\n\t\t} else if (val == I40E_RESET_GLOBR) {\n\t\t\tpf->globr_count++;\n\t\t} else if (val == I40E_RESET_EMPR) {\n\t\t\tpf->empr_count++;\n\t\t\tset_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state);\n\t\t}\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_HMC_ERR_MASK) {\n\t\ticr0 &= ~I40E_PFINT_ICR0_HMC_ERR_MASK;\n\t\tdev_info(&pf->pdev->dev, \"HMC error interrupt\\n\");\n\t\tdev_info(&pf->pdev->dev, \"HMC error info 0x%x, HMC error data 0x%x\\n\",\n\t\t\t rd32(hw, I40E_PFHMC_ERRORINFO),\n\t\t\t rd32(hw, I40E_PFHMC_ERRORDATA));\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_TIMESYNC_MASK) {\n\t\tu32 prttsyn_stat = rd32(hw, I40E_PRTTSYN_STAT_0);\n\n\t\tif (prttsyn_stat & I40E_PRTTSYN_STAT_0_TXTIME_MASK) {\n\t\t\ticr0 &= ~I40E_PFINT_ICR0_ENA_TIMESYNC_MASK;\n\t\t\ti40e_ptp_tx_hwtstamp(pf);\n\t\t}\n\t}\n\n\t/* If a critical error is pending we have no choice but to reset the\n\t * device.\n\t * Report and mask out any remaining unexpected interrupts.\n\t */\n\ticr0_remaining = icr0 & ena_mask;\n\tif (icr0_remaining) {\n\t\tdev_info(&pf->pdev->dev, \"unhandled interrupt icr0=0x%08x\\n\",\n\t\t\t icr0_remaining);\n\t\tif ((icr0_remaining & I40E_PFINT_ICR0_PE_CRITERR_MASK) ||\n\t\t    (icr0_remaining & I40E_PFINT_ICR0_PCI_EXCEPTION_MASK) ||\n\t\t    (icr0_remaining & I40E_PFINT_ICR0_ECC_ERR_MASK)) {\n\t\t\tdev_info(&pf->pdev->dev, \"device will be reset\\n\");\n\t\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\t\ti40e_service_event_schedule(pf);\n\t\t}\n\t\tena_mask &= ~icr0_remaining;\n\t}\n\tret = IRQ_HANDLED;\n\nenable_intr:\n\t/* re-enable interrupt causes */\n\twr32(hw, I40E_PFINT_ICR0_ENA, ena_mask);\n\tif (!test_bit(__I40E_DOWN, pf->state) ||\n\t    test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\ti40e_service_event_schedule(pf);\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_clean_fdir_tx_irq - Reclaim resources after transmit completes\n * @tx_ring:  tx ring to clean\n * @budget:   how many cleans we're allowed\n *\n * Returns true if there's any budget left (e.g. the clean is finished)\n **/\nstatic bool i40e_clean_fdir_tx_irq(struct i40e_ring *tx_ring, int budget)\n{\n\tstruct i40e_vsi *vsi = tx_ring->vsi;\n\tu16 i = tx_ring->next_to_clean;\n\tstruct i40e_tx_buffer *tx_buf;\n\tstruct i40e_tx_desc *tx_desc;\n\n\ttx_buf = &tx_ring->tx_bi[i];\n\ttx_desc = I40E_TX_DESC(tx_ring, i);\n\ti -= tx_ring->count;\n\n\tdo {\n\t\tstruct i40e_tx_desc *eop_desc = tx_buf->next_to_watch;\n\n\t\t/* if next_to_watch is not set then there is no work pending */\n\t\tif (!eop_desc)\n\t\t\tbreak;\n\n\t\t/* prevent any other reads prior to eop_desc */\n\t\tsmp_rmb();\n\n\t\t/* if the descriptor isn't done, no work yet to do */\n\t\tif (!(eop_desc->cmd_type_offset_bsz &\n\t\t      cpu_to_le64(I40E_TX_DESC_DTYPE_DESC_DONE)))\n\t\t\tbreak;\n\n\t\t/* clear next_to_watch to prevent false hangs */\n\t\ttx_buf->next_to_watch = NULL;\n\n\t\ttx_desc->buffer_addr = 0;\n\t\ttx_desc->cmd_type_offset_bsz = 0;\n\t\t/* move past filter desc */\n\t\ttx_buf++;\n\t\ttx_desc++;\n\t\ti++;\n\t\tif (unlikely(!i)) {\n\t\t\ti -= tx_ring->count;\n\t\t\ttx_buf = tx_ring->tx_bi;\n\t\t\ttx_desc = I40E_TX_DESC(tx_ring, 0);\n\t\t}\n\t\t/* unmap skb header data */\n\t\tdma_unmap_single(tx_ring->dev,\n\t\t\t\t dma_unmap_addr(tx_buf, dma),\n\t\t\t\t dma_unmap_len(tx_buf, len),\n\t\t\t\t DMA_TO_DEVICE);\n\t\tif (tx_buf->tx_flags & I40E_TX_FLAGS_FD_SB)\n\t\t\tkfree(tx_buf->raw_buf);\n\n\t\ttx_buf->raw_buf = NULL;\n\t\ttx_buf->tx_flags = 0;\n\t\ttx_buf->next_to_watch = NULL;\n\t\tdma_unmap_len_set(tx_buf, len, 0);\n\t\ttx_desc->buffer_addr = 0;\n\t\ttx_desc->cmd_type_offset_bsz = 0;\n\n\t\t/* move us past the eop_desc for start of next FD desc */\n\t\ttx_buf++;\n\t\ttx_desc++;\n\t\ti++;\n\t\tif (unlikely(!i)) {\n\t\t\ti -= tx_ring->count;\n\t\t\ttx_buf = tx_ring->tx_bi;\n\t\t\ttx_desc = I40E_TX_DESC(tx_ring, 0);\n\t\t}\n\n\t\t/* update budget accounting */\n\t\tbudget--;\n\t} while (likely(budget));\n\n\ti += tx_ring->count;\n\ttx_ring->next_to_clean = i;\n\n\tif (vsi->back->flags & I40E_FLAG_MSIX_ENABLED)\n\t\ti40e_irq_dynamic_enable(vsi, tx_ring->q_vector->v_idx);\n\n\treturn budget > 0;\n}\n\n/**\n * i40e_fdir_clean_ring - Interrupt Handler for FDIR SB ring\n * @irq: interrupt number\n * @data: pointer to a q_vector\n **/\nstatic irqreturn_t i40e_fdir_clean_ring(int irq, void *data)\n{\n\tstruct i40e_q_vector *q_vector = data;\n\tstruct i40e_vsi *vsi;\n\n\tif (!q_vector->tx.ring)\n\t\treturn IRQ_HANDLED;\n\n\tvsi = q_vector->tx.ring->vsi;\n\ti40e_clean_fdir_tx_irq(q_vector->tx.ring, vsi->work_limit);\n\n\treturn IRQ_HANDLED;\n}\n\n/**\n * i40e_map_vector_to_qp - Assigns the queue pair to the vector\n * @vsi: the VSI being configured\n * @v_idx: vector index\n * @qp_idx: queue pair index\n **/\nstatic void i40e_map_vector_to_qp(struct i40e_vsi *vsi, int v_idx, int qp_idx)\n{\n\tstruct i40e_q_vector *q_vector = vsi->q_vectors[v_idx];\n\tstruct i40e_ring *tx_ring = vsi->tx_rings[qp_idx];\n\tstruct i40e_ring *rx_ring = vsi->rx_rings[qp_idx];\n\n\ttx_ring->q_vector = q_vector;\n\ttx_ring->next = q_vector->tx.ring;\n\tq_vector->tx.ring = tx_ring;\n\tq_vector->tx.count++;\n\n\t/* Place XDP Tx ring in the same q_vector ring list as regular Tx */\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tstruct i40e_ring *xdp_ring = vsi->xdp_rings[qp_idx];\n\n\t\txdp_ring->q_vector = q_vector;\n\t\txdp_ring->next = q_vector->tx.ring;\n\t\tq_vector->tx.ring = xdp_ring;\n\t\tq_vector->tx.count++;\n\t}\n\n\trx_ring->q_vector = q_vector;\n\trx_ring->next = q_vector->rx.ring;\n\tq_vector->rx.ring = rx_ring;\n\tq_vector->rx.count++;\n}\n\n/**\n * i40e_vsi_map_rings_to_vectors - Maps descriptor rings to vectors\n * @vsi: the VSI being configured\n *\n * This function maps descriptor rings to the queue-specific vectors\n * we were allotted through the MSI-X enabling code.  Ideally, we'd have\n * one vector per queue pair, but on a constrained vector budget, we\n * group the queue pairs as \"efficiently\" as possible.\n **/\nstatic void i40e_vsi_map_rings_to_vectors(struct i40e_vsi *vsi)\n{\n\tint qp_remaining = vsi->num_queue_pairs;\n\tint q_vectors = vsi->num_q_vectors;\n\tint num_ringpairs;\n\tint v_start = 0;\n\tint qp_idx = 0;\n\n\t/* If we don't have enough vectors for a 1-to-1 mapping, we'll have to\n\t * group them so there are multiple queues per vector.\n\t * It is also important to go through all the vectors available to be\n\t * sure that if we don't use all the vectors, that the remaining vectors\n\t * are cleared. This is especially important when decreasing the\n\t * number of queues in use.\n\t */\n\tfor (; v_start < q_vectors; v_start++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[v_start];\n\n\t\tnum_ringpairs = DIV_ROUND_UP(qp_remaining, q_vectors - v_start);\n\n\t\tq_vector->num_ringpairs = num_ringpairs;\n\t\tq_vector->reg_idx = q_vector->v_idx + vsi->base_vector - 1;\n\n\t\tq_vector->rx.count = 0;\n\t\tq_vector->tx.count = 0;\n\t\tq_vector->rx.ring = NULL;\n\t\tq_vector->tx.ring = NULL;\n\n\t\twhile (num_ringpairs--) {\n\t\t\ti40e_map_vector_to_qp(vsi, v_start, qp_idx);\n\t\t\tqp_idx++;\n\t\t\tqp_remaining--;\n\t\t}\n\t}\n}\n\n/**\n * i40e_vsi_request_irq - Request IRQ from the OS\n * @vsi: the VSI being configured\n * @basename: name for the vector\n **/\nstatic int i40e_vsi_request_irq(struct i40e_vsi *vsi, char *basename)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint err;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\terr = i40e_vsi_request_irq_msix(vsi, basename);\n\telse if (pf->flags & I40E_FLAG_MSI_ENABLED)\n\t\terr = request_irq(pf->pdev->irq, i40e_intr, 0,\n\t\t\t\t  pf->int_name, pf);\n\telse\n\t\terr = request_irq(pf->pdev->irq, i40e_intr, IRQF_SHARED,\n\t\t\t\t  pf->int_name, pf);\n\n\tif (err)\n\t\tdev_info(&pf->pdev->dev, \"request_irq failed, Error %d\\n\", err);\n\n\treturn err;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\n/**\n * i40e_netpoll - A Polling 'interrupt' handler\n * @netdev: network interface device structure\n *\n * This is used by netconsole to send skbs without having to re-enable\n * interrupts.  It's not called while the normal interrupt routine is executing.\n **/\nstatic void i40e_netpoll(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tint i;\n\n\t/* if interface is down do nothing */\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++)\n\t\t\ti40e_msix_clean_rings(0, vsi->q_vectors[i]);\n\t} else {\n\t\ti40e_intr(pf->pdev->irq, netdev);\n\t}\n}\n#endif\n\n#define I40E_QTX_ENA_WAIT_COUNT 50\n\n/**\n * i40e_pf_txq_wait - Wait for a PF's Tx queue to be enabled or disabled\n * @pf: the PF being configured\n * @pf_q: the PF queue\n * @enable: enable or disable state of the queue\n *\n * This routine will wait for the given Tx queue of the PF to reach the\n * enabled or disabled state.\n * Returns -ETIMEDOUT in case of failing to reach the requested state after\n * multiple retries; else will return 0 in case of success.\n **/\nstatic int i40e_pf_txq_wait(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tint i;\n\tu32 tx_reg;\n\n\tfor (i = 0; i < I40E_QUEUE_WAIT_RETRY_LIMIT; i++) {\n\t\ttx_reg = rd32(&pf->hw, I40E_QTX_ENA(pf_q));\n\t\tif (enable == !!(tx_reg & I40E_QTX_ENA_QENA_STAT_MASK))\n\t\t\tbreak;\n\n\t\tusleep_range(10, 20);\n\t}\n\tif (i >= I40E_QUEUE_WAIT_RETRY_LIMIT)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\n/**\n * i40e_control_tx_q - Start or stop a particular Tx queue\n * @pf: the PF structure\n * @pf_q: the PF queue to configure\n * @enable: start or stop the queue\n *\n * This function enables or disables a single queue. Note that any delay\n * required after the operation is expected to be handled by the caller of\n * this function.\n **/\nstatic void i40e_control_tx_q(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 tx_reg;\n\tint i;\n\n\t/* warn the TX unit of coming changes */\n\ti40e_pre_tx_queue_cfg(&pf->hw, pf_q, enable);\n\tif (!enable)\n\t\tusleep_range(10, 20);\n\n\tfor (i = 0; i < I40E_QTX_ENA_WAIT_COUNT; i++) {\n\t\ttx_reg = rd32(hw, I40E_QTX_ENA(pf_q));\n\t\tif (((tx_reg >> I40E_QTX_ENA_QENA_REQ_SHIFT) & 1) ==\n\t\t    ((tx_reg >> I40E_QTX_ENA_QENA_STAT_SHIFT) & 1))\n\t\t\tbreak;\n\t\tusleep_range(1000, 2000);\n\t}\n\n\t/* Skip if the queue is already in the requested state */\n\tif (enable == !!(tx_reg & I40E_QTX_ENA_QENA_STAT_MASK))\n\t\treturn;\n\n\t/* turn on/off the queue */\n\tif (enable) {\n\t\twr32(hw, I40E_QTX_HEAD(pf_q), 0);\n\t\ttx_reg |= I40E_QTX_ENA_QENA_REQ_MASK;\n\t} else {\n\t\ttx_reg &= ~I40E_QTX_ENA_QENA_REQ_MASK;\n\t}\n\n\twr32(hw, I40E_QTX_ENA(pf_q), tx_reg);\n}\n\n/**\n * i40e_control_wait_tx_q - Start/stop Tx queue and wait for completion\n * @seid: VSI SEID\n * @pf: the PF structure\n * @pf_q: the PF queue to configure\n * @is_xdp: true if the queue is used for XDP\n * @enable: start or stop the queue\n **/\nint i40e_control_wait_tx_q(int seid, struct i40e_pf *pf, int pf_q,\n\t\t\t   bool is_xdp, bool enable)\n{\n\tint ret;\n\n\ti40e_control_tx_q(pf, pf_q, enable);\n\n\t/* wait for the change to finish */\n\tret = i40e_pf_txq_wait(pf, pf_q, enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d %sTx ring %d %sable timeout\\n\",\n\t\t\t seid, (is_xdp ? \"XDP \" : \"\"), pf_q,\n\t\t\t (enable ? \"en\" : \"dis\"));\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_vsi_control_tx - Start or stop a VSI's rings\n * @vsi: the VSI being configured\n * @enable: start or stop the rings\n **/\nstatic int i40e_vsi_control_tx(struct i40e_vsi *vsi, bool enable)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q, ret = 0;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\tret = i40e_control_wait_tx_q(vsi->seid, pf,\n\t\t\t\t\t     pf_q,\n\t\t\t\t\t     false /*is xdp*/, enable);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tcontinue;\n\n\t\tret = i40e_control_wait_tx_q(vsi->seid, pf,\n\t\t\t\t\t     pf_q + vsi->alloc_queue_pairs,\n\t\t\t\t\t     true /*is xdp*/, enable);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\treturn ret;\n}\n\n/**\n * i40e_pf_rxq_wait - Wait for a PF's Rx queue to be enabled or disabled\n * @pf: the PF being configured\n * @pf_q: the PF queue\n * @enable: enable or disable state of the queue\n *\n * This routine will wait for the given Rx queue of the PF to reach the\n * enabled or disabled state.\n * Returns -ETIMEDOUT in case of failing to reach the requested state after\n * multiple retries; else will return 0 in case of success.\n **/\nstatic int i40e_pf_rxq_wait(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tint i;\n\tu32 rx_reg;\n\n\tfor (i = 0; i < I40E_QUEUE_WAIT_RETRY_LIMIT; i++) {\n\t\trx_reg = rd32(&pf->hw, I40E_QRX_ENA(pf_q));\n\t\tif (enable == !!(rx_reg & I40E_QRX_ENA_QENA_STAT_MASK))\n\t\t\tbreak;\n\n\t\tusleep_range(10, 20);\n\t}\n\tif (i >= I40E_QUEUE_WAIT_RETRY_LIMIT)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\n/**\n * i40e_control_rx_q - Start or stop a particular Rx queue\n * @pf: the PF structure\n * @pf_q: the PF queue to configure\n * @enable: start or stop the queue\n *\n * This function enables or disables a single queue. Note that\n * any delay required after the operation is expected to be\n * handled by the caller of this function.\n **/\nstatic void i40e_control_rx_q(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 rx_reg;\n\tint i;\n\n\tfor (i = 0; i < I40E_QTX_ENA_WAIT_COUNT; i++) {\n\t\trx_reg = rd32(hw, I40E_QRX_ENA(pf_q));\n\t\tif (((rx_reg >> I40E_QRX_ENA_QENA_REQ_SHIFT) & 1) ==\n\t\t    ((rx_reg >> I40E_QRX_ENA_QENA_STAT_SHIFT) & 1))\n\t\t\tbreak;\n\t\tusleep_range(1000, 2000);\n\t}\n\n\t/* Skip if the queue is already in the requested state */\n\tif (enable == !!(rx_reg & I40E_QRX_ENA_QENA_STAT_MASK))\n\t\treturn;\n\n\t/* turn on/off the queue */\n\tif (enable)\n\t\trx_reg |= I40E_QRX_ENA_QENA_REQ_MASK;\n\telse\n\t\trx_reg &= ~I40E_QRX_ENA_QENA_REQ_MASK;\n\n\twr32(hw, I40E_QRX_ENA(pf_q), rx_reg);\n}\n\n/**\n * i40e_control_wait_rx_q\n * @pf: the PF structure\n * @pf_q: queue being configured\n * @enable: start or stop the rings\n *\n * This function enables or disables a single queue along with waiting\n * for the change to finish. The caller of this function should handle\n * the delays needed in the case of disabling queues.\n **/\nint i40e_control_wait_rx_q(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tint ret = 0;\n\n\ti40e_control_rx_q(pf, pf_q, enable);\n\n\t/* wait for the change to finish */\n\tret = i40e_pf_rxq_wait(pf, pf_q, enable);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ret;\n}\n\n/**\n * i40e_vsi_control_rx - Start or stop a VSI's rings\n * @vsi: the VSI being configured\n * @enable: start or stop the rings\n **/\nstatic int i40e_vsi_control_rx(struct i40e_vsi *vsi, bool enable)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q, ret = 0;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\tret = i40e_control_wait_rx_q(pf, pf_q, enable);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d Rx ring %d %sable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Due to HW errata, on Rx disable only, the register can indicate done\n\t * before it really is. Needs 50ms to be sure\n\t */\n\tif (!enable)\n\t\tmdelay(50);\n\n\treturn ret;\n}\n\n/**\n * i40e_vsi_start_rings - Start a VSI's rings\n * @vsi: the VSI being configured\n **/\nint i40e_vsi_start_rings(struct i40e_vsi *vsi)\n{\n\tint ret = 0;\n\n\t/* do rx first for enable and last for disable */\n\tret = i40e_vsi_control_rx(vsi, true);\n\tif (ret)\n\t\treturn ret;\n\tret = i40e_vsi_control_tx(vsi, true);\n\n\treturn ret;\n}\n\n/**\n * i40e_vsi_stop_rings - Stop a VSI's rings\n * @vsi: the VSI being configured\n **/\nvoid i40e_vsi_stop_rings(struct i40e_vsi *vsi)\n{\n\t/* When port TX is suspended, don't wait */\n\tif (test_bit(__I40E_PORT_SUSPENDED, vsi->back->state))\n\t\treturn i40e_vsi_stop_rings_no_wait(vsi);\n\n\t/* do rx first for enable and last for disable\n\t * Ignore return value, we need to shutdown whatever we can\n\t */\n\ti40e_vsi_control_tx(vsi, false);\n\ti40e_vsi_control_rx(vsi, false);\n}\n\n/**\n * i40e_vsi_stop_rings_no_wait - Stop a VSI's rings and do not delay\n * @vsi: the VSI being shutdown\n *\n * This function stops all the rings for a VSI but does not delay to verify\n * that rings have been disabled. It is expected that the caller is shutting\n * down multiple VSIs at once and will delay together for all the VSIs after\n * initiating the shutdown. This is particularly useful for shutting down lots\n * of VFs together. Otherwise, a large delay can be incurred while configuring\n * each VSI in serial.\n **/\nvoid i40e_vsi_stop_rings_no_wait(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\ti40e_control_tx_q(pf, pf_q, false);\n\t\ti40e_control_rx_q(pf, pf_q, false);\n\t}\n}\n\n/**\n * i40e_vsi_free_irq - Free the irq association with the OS\n * @vsi: the VSI being configured\n **/\nstatic void i40e_vsi_free_irq(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint base = vsi->base_vector;\n\tu32 val, qp;\n\tint i;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tif (!vsi->q_vectors)\n\t\t\treturn;\n\n\t\tif (!vsi->irqs_ready)\n\t\t\treturn;\n\n\t\tvsi->irqs_ready = false;\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++) {\n\t\t\tint irq_num;\n\t\t\tu16 vector;\n\n\t\t\tvector = i + base;\n\t\t\tirq_num = pf->msix_entries[vector].vector;\n\n\t\t\t/* free only the irqs that were actually requested */\n\t\t\tif (!vsi->q_vectors[i] ||\n\t\t\t    !vsi->q_vectors[i]->num_ringpairs)\n\t\t\t\tcontinue;\n\n\t\t\t/* clear the affinity notifier in the IRQ descriptor */\n\t\t\tirq_set_affinity_notifier(irq_num, NULL);\n\t\t\t/* remove our suggested affinity mask for this IRQ */\n\t\t\tirq_set_affinity_hint(irq_num, NULL);\n\t\t\tsynchronize_irq(irq_num);\n\t\t\tfree_irq(irq_num, vsi->q_vectors[i]);\n\n\t\t\t/* Tear down the interrupt queue link list\n\t\t\t *\n\t\t\t * We know that they come in pairs and always\n\t\t\t * the Rx first, then the Tx.  To clear the\n\t\t\t * link list, stick the EOL value into the\n\t\t\t * next_q field of the registers.\n\t\t\t */\n\t\t\tval = rd32(hw, I40E_PFINT_LNKLSTN(vector - 1));\n\t\t\tqp = (val & I40E_PFINT_LNKLSTN_FIRSTQ_INDX_MASK)\n\t\t\t\t>> I40E_PFINT_LNKLSTN_FIRSTQ_INDX_SHIFT;\n\t\t\tval |= I40E_QUEUE_END_OF_LIST\n\t\t\t\t<< I40E_PFINT_LNKLSTN_FIRSTQ_INDX_SHIFT;\n\t\t\twr32(hw, I40E_PFINT_LNKLSTN(vector - 1), val);\n\n\t\t\twhile (qp != I40E_QUEUE_END_OF_LIST) {\n\t\t\t\tu32 next;\n\n\t\t\t\tval = rd32(hw, I40E_QINT_RQCTL(qp));\n\n\t\t\t\tval &= ~(I40E_QINT_RQCTL_MSIX_INDX_MASK  |\n\t\t\t\t\t I40E_QINT_RQCTL_MSIX0_INDX_MASK |\n\t\t\t\t\t I40E_QINT_RQCTL_CAUSE_ENA_MASK  |\n\t\t\t\t\t I40E_QINT_RQCTL_INTEVENT_MASK);\n\n\t\t\t\tval |= (I40E_QINT_RQCTL_ITR_INDX_MASK |\n\t\t\t\t\t I40E_QINT_RQCTL_NEXTQ_INDX_MASK);\n\n\t\t\t\twr32(hw, I40E_QINT_RQCTL(qp), val);\n\n\t\t\t\tval = rd32(hw, I40E_QINT_TQCTL(qp));\n\n\t\t\t\tnext = (val & I40E_QINT_TQCTL_NEXTQ_INDX_MASK)\n\t\t\t\t\t>> I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT;\n\n\t\t\t\tval &= ~(I40E_QINT_TQCTL_MSIX_INDX_MASK  |\n\t\t\t\t\t I40E_QINT_TQCTL_MSIX0_INDX_MASK |\n\t\t\t\t\t I40E_QINT_TQCTL_CAUSE_ENA_MASK  |\n\t\t\t\t\t I40E_QINT_TQCTL_INTEVENT_MASK);\n\n\t\t\t\tval |= (I40E_QINT_TQCTL_ITR_INDX_MASK |\n\t\t\t\t\t I40E_QINT_TQCTL_NEXTQ_INDX_MASK);\n\n\t\t\t\twr32(hw, I40E_QINT_TQCTL(qp), val);\n\t\t\t\tqp = next;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfree_irq(pf->pdev->irq, pf);\n\n\t\tval = rd32(hw, I40E_PFINT_LNKLST0);\n\t\tqp = (val & I40E_PFINT_LNKLSTN_FIRSTQ_INDX_MASK)\n\t\t\t>> I40E_PFINT_LNKLSTN_FIRSTQ_INDX_SHIFT;\n\t\tval |= I40E_QUEUE_END_OF_LIST\n\t\t\t<< I40E_PFINT_LNKLST0_FIRSTQ_INDX_SHIFT;\n\t\twr32(hw, I40E_PFINT_LNKLST0, val);\n\n\t\tval = rd32(hw, I40E_QINT_RQCTL(qp));\n\t\tval &= ~(I40E_QINT_RQCTL_MSIX_INDX_MASK  |\n\t\t\t I40E_QINT_RQCTL_MSIX0_INDX_MASK |\n\t\t\t I40E_QINT_RQCTL_CAUSE_ENA_MASK  |\n\t\t\t I40E_QINT_RQCTL_INTEVENT_MASK);\n\n\t\tval |= (I40E_QINT_RQCTL_ITR_INDX_MASK |\n\t\t\tI40E_QINT_RQCTL_NEXTQ_INDX_MASK);\n\n\t\twr32(hw, I40E_QINT_RQCTL(qp), val);\n\n\t\tval = rd32(hw, I40E_QINT_TQCTL(qp));\n\n\t\tval &= ~(I40E_QINT_TQCTL_MSIX_INDX_MASK  |\n\t\t\t I40E_QINT_TQCTL_MSIX0_INDX_MASK |\n\t\t\t I40E_QINT_TQCTL_CAUSE_ENA_MASK  |\n\t\t\t I40E_QINT_TQCTL_INTEVENT_MASK);\n\n\t\tval |= (I40E_QINT_TQCTL_ITR_INDX_MASK |\n\t\t\tI40E_QINT_TQCTL_NEXTQ_INDX_MASK);\n\n\t\twr32(hw, I40E_QINT_TQCTL(qp), val);\n\t}\n}\n\n/**\n * i40e_free_q_vector - Free memory allocated for specific interrupt vector\n * @vsi: the VSI being configured\n * @v_idx: Index of vector to be freed\n *\n * This function frees the memory allocated to the q_vector.  In addition if\n * NAPI is enabled it will delete any references to the NAPI struct prior\n * to freeing the q_vector.\n **/\nstatic void i40e_free_q_vector(struct i40e_vsi *vsi, int v_idx)\n{\n\tstruct i40e_q_vector *q_vector = vsi->q_vectors[v_idx];\n\tstruct i40e_ring *ring;\n\n\tif (!q_vector)\n\t\treturn;\n\n\t/* disassociate q_vector from rings */\n\ti40e_for_each_ring(ring, q_vector->tx)\n\t\tring->q_vector = NULL;\n\n\ti40e_for_each_ring(ring, q_vector->rx)\n\t\tring->q_vector = NULL;\n\n\t/* only VSI w/ an associated netdev is set up w/ NAPI */\n\tif (vsi->netdev)\n\t\tnetif_napi_del(&q_vector->napi);\n\n\tvsi->q_vectors[v_idx] = NULL;\n\n\tkfree_rcu(q_vector, rcu);\n}\n\n/**\n * i40e_vsi_free_q_vectors - Free memory allocated for interrupt vectors\n * @vsi: the VSI being un-configured\n *\n * This frees the memory allocated to the q_vectors and\n * deletes references to the NAPI struct.\n **/\nstatic void i40e_vsi_free_q_vectors(struct i40e_vsi *vsi)\n{\n\tint v_idx;\n\n\tfor (v_idx = 0; v_idx < vsi->num_q_vectors; v_idx++)\n\t\ti40e_free_q_vector(vsi, v_idx);\n}\n\n/**\n * i40e_reset_interrupt_capability - Disable interrupt setup in OS\n * @pf: board private structure\n **/\nstatic void i40e_reset_interrupt_capability(struct i40e_pf *pf)\n{\n\t/* If we're in Legacy mode, the interrupt was cleaned in vsi_close */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tpci_disable_msix(pf->pdev);\n\t\tkfree(pf->msix_entries);\n\t\tpf->msix_entries = NULL;\n\t\tkfree(pf->irq_pile);\n\t\tpf->irq_pile = NULL;\n\t} else if (pf->flags & I40E_FLAG_MSI_ENABLED) {\n\t\tpci_disable_msi(pf->pdev);\n\t}\n\tpf->flags &= ~(I40E_FLAG_MSIX_ENABLED | I40E_FLAG_MSI_ENABLED);\n}\n\n/**\n * i40e_clear_interrupt_scheme - Clear the current interrupt scheme settings\n * @pf: board private structure\n *\n * We go through and clear interrupt specific resources and reset the structure\n * to pre-load conditions\n **/\nstatic void i40e_clear_interrupt_scheme(struct i40e_pf *pf)\n{\n\tint i;\n\n\ti40e_free_misc_vector(pf);\n\n\ti40e_put_lump(pf->irq_pile, pf->iwarp_base_vector,\n\t\t      I40E_IWARP_IRQ_PILE_ID);\n\n\ti40e_put_lump(pf->irq_pile, 0, I40E_PILE_VALID_BIT-1);\n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i])\n\t\t\ti40e_vsi_free_q_vectors(pf->vsi[i]);\n\ti40e_reset_interrupt_capability(pf);\n}\n\n/**\n * i40e_napi_enable_all - Enable NAPI for all q_vectors in the VSI\n * @vsi: the VSI being configured\n **/\nstatic void i40e_napi_enable_all(struct i40e_vsi *vsi)\n{\n\tint q_idx;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\tfor (q_idx = 0; q_idx < vsi->num_q_vectors; q_idx++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[q_idx];\n\n\t\tif (q_vector->rx.ring || q_vector->tx.ring)\n\t\t\tnapi_enable(&q_vector->napi);\n\t}\n}\n\n/**\n * i40e_napi_disable_all - Disable NAPI for all q_vectors in the VSI\n * @vsi: the VSI being configured\n **/\nstatic void i40e_napi_disable_all(struct i40e_vsi *vsi)\n{\n\tint q_idx;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\tfor (q_idx = 0; q_idx < vsi->num_q_vectors; q_idx++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[q_idx];\n\n\t\tif (q_vector->rx.ring || q_vector->tx.ring)\n\t\t\tnapi_disable(&q_vector->napi);\n\t}\n}\n\n/**\n * i40e_vsi_close - Shut down a VSI\n * @vsi: the vsi to be quelled\n **/\nstatic void i40e_vsi_close(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tif (!test_and_set_bit(__I40E_VSI_DOWN, vsi->state))\n\t\ti40e_down(vsi);\n\ti40e_vsi_free_irq(vsi);\n\ti40e_vsi_free_tx_resources(vsi);\n\ti40e_vsi_free_rx_resources(vsi);\n\tvsi->current_netdev_flags = 0;\n\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\tif (test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\tset_bit(__I40E_CLIENT_RESET, pf->state);\n}\n\n/**\n * i40e_quiesce_vsi - Pause a given VSI\n * @vsi: the VSI being paused\n **/\nstatic void i40e_quiesce_vsi(struct i40e_vsi *vsi)\n{\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tset_bit(__I40E_VSI_NEEDS_RESTART, vsi->state);\n\tif (vsi->netdev && netif_running(vsi->netdev))\n\t\tvsi->netdev->netdev_ops->ndo_stop(vsi->netdev);\n\telse\n\t\ti40e_vsi_close(vsi);\n}\n\n/**\n * i40e_unquiesce_vsi - Resume a given VSI\n * @vsi: the VSI being resumed\n **/\nstatic void i40e_unquiesce_vsi(struct i40e_vsi *vsi)\n{\n\tif (!test_and_clear_bit(__I40E_VSI_NEEDS_RESTART, vsi->state))\n\t\treturn;\n\n\tif (vsi->netdev && netif_running(vsi->netdev))\n\t\tvsi->netdev->netdev_ops->ndo_open(vsi->netdev);\n\telse\n\t\ti40e_vsi_open(vsi);   /* this clears the DOWN bit */\n}\n\n/**\n * i40e_pf_quiesce_all_vsi - Pause all VSIs on a PF\n * @pf: the PF\n **/\nstatic void i40e_pf_quiesce_all_vsi(struct i40e_pf *pf)\n{\n\tint v;\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v])\n\t\t\ti40e_quiesce_vsi(pf->vsi[v]);\n\t}\n}\n\n/**\n * i40e_pf_unquiesce_all_vsi - Resume all VSIs on a PF\n * @pf: the PF\n **/\nstatic void i40e_pf_unquiesce_all_vsi(struct i40e_pf *pf)\n{\n\tint v;\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v])\n\t\t\ti40e_unquiesce_vsi(pf->vsi[v]);\n\t}\n}\n\n/**\n * i40e_vsi_wait_queues_disabled - Wait for VSI's queues to be disabled\n * @vsi: the VSI being configured\n *\n * Wait until all queues on a given VSI have been disabled.\n **/\nint i40e_vsi_wait_queues_disabled(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q, ret;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\t/* Check and wait for the Tx queue */\n\t\tret = i40e_pf_txq_wait(pf, pf_q, false);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d Tx ring %d disable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tgoto wait_rx;\n\n\t\t/* Check and wait for the XDP Tx queue */\n\t\tret = i40e_pf_txq_wait(pf, pf_q + vsi->alloc_queue_pairs,\n\t\t\t\t       false);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d XDP Tx ring %d disable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t\t\treturn ret;\n\t\t}\nwait_rx:\n\t\t/* Check and wait for the Rx queue */\n\t\tret = i40e_pf_rxq_wait(pf, pf_q, false);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d Rx ring %d disable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n#ifdef CONFIG_I40E_DCB\n/**\n * i40e_pf_wait_queues_disabled - Wait for all queues of PF VSIs to be disabled\n * @pf: the PF\n *\n * This function waits for the queues to be in disabled state for all the\n * VSIs that are managed by this PF.\n **/\nstatic int i40e_pf_wait_queues_disabled(struct i40e_pf *pf)\n{\n\tint v, ret = 0;\n\n\tfor (v = 0; v < pf->hw.func_caps.num_vsis; v++) {\n\t\tif (pf->vsi[v]) {\n\t\t\tret = i40e_vsi_wait_queues_disabled(pf->vsi[v]);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n#endif\n\n/**\n * i40e_get_iscsi_tc_map - Return TC map for iSCSI APP\n * @pf: pointer to PF\n *\n * Get TC map for ISCSI PF type that will include iSCSI TC\n * and LAN TC.\n **/\nstatic u8 i40e_get_iscsi_tc_map(struct i40e_pf *pf)\n{\n\tstruct i40e_dcb_app_priority_table app;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 enabled_tc = 1; /* TC0 is always enabled */\n\tu8 tc, i;\n\t/* Get the iSCSI APP TLV */\n\tstruct i40e_dcbx_config *dcbcfg = &hw->local_dcbx_config;\n\n\tfor (i = 0; i < dcbcfg->numapps; i++) {\n\t\tapp = dcbcfg->app[i];\n\t\tif (app.selector == I40E_APP_SEL_TCPIP &&\n\t\t    app.protocolid == I40E_APP_PROTOID_ISCSI) {\n\t\t\ttc = dcbcfg->etscfg.prioritytable[app.priority];\n\t\t\tenabled_tc |= BIT(tc);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn enabled_tc;\n}\n\n/**\n * i40e_dcb_get_num_tc -  Get the number of TCs from DCBx config\n * @dcbcfg: the corresponding DCBx configuration structure\n *\n * Return the number of TCs from given DCBx configuration\n **/\nstatic u8 i40e_dcb_get_num_tc(struct i40e_dcbx_config *dcbcfg)\n{\n\tint i, tc_unused = 0;\n\tu8 num_tc = 0;\n\tu8 ret = 0;\n\n\t/* Scan the ETS Config Priority Table to find\n\t * traffic class enabled for a given priority\n\t * and create a bitmask of enabled TCs\n\t */\n\tfor (i = 0; i < I40E_MAX_USER_PRIORITY; i++)\n\t\tnum_tc |= BIT(dcbcfg->etscfg.prioritytable[i]);\n\n\t/* Now scan the bitmask to check for\n\t * contiguous TCs starting with TC0\n\t */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (num_tc & BIT(i)) {\n\t\t\tif (!tc_unused) {\n\t\t\t\tret++;\n\t\t\t} else {\n\t\t\t\tpr_err(\"Non-contiguous TC - Disabling DCB\\n\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t} else {\n\t\t\ttc_unused = 1;\n\t\t}\n\t}\n\n\t/* There is always at least TC0 */\n\tif (!ret)\n\t\tret = 1;\n\n\treturn ret;\n}\n\n/**\n * i40e_dcb_get_enabled_tc - Get enabled traffic classes\n * @dcbcfg: the corresponding DCBx configuration structure\n *\n * Query the current DCB configuration and return the number of\n * traffic classes enabled from the given DCBX config\n **/\nstatic u8 i40e_dcb_get_enabled_tc(struct i40e_dcbx_config *dcbcfg)\n{\n\tu8 num_tc = i40e_dcb_get_num_tc(dcbcfg);\n\tu8 enabled_tc = 1;\n\tu8 i;\n\n\tfor (i = 0; i < num_tc; i++)\n\t\tenabled_tc |= BIT(i);\n\n\treturn enabled_tc;\n}\n\n/**\n * i40e_mqprio_get_enabled_tc - Get enabled traffic classes\n * @pf: PF being queried\n *\n * Query the current MQPRIO configuration and return the number of\n * traffic classes enabled.\n **/\nstatic u8 i40e_mqprio_get_enabled_tc(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tu8 num_tc = vsi->mqprio_qopt.qopt.num_tc;\n\tu8 enabled_tc = 1, i;\n\n\tfor (i = 1; i < num_tc; i++)\n\t\tenabled_tc |= BIT(i);\n\treturn enabled_tc;\n}\n\n/**\n * i40e_pf_get_num_tc - Get enabled traffic classes for PF\n * @pf: PF being queried\n *\n * Return number of traffic classes enabled for the given PF\n **/\nstatic u8 i40e_pf_get_num_tc(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 i, enabled_tc = 1;\n\tu8 num_tc = 0;\n\tstruct i40e_dcbx_config *dcbcfg = &hw->local_dcbx_config;\n\n\tif (pf->flags & I40E_FLAG_TC_MQPRIO)\n\t\treturn pf->vsi[pf->lan_vsi]->mqprio_qopt.qopt.num_tc;\n\n\t/* If neither MQPRIO nor DCB is enabled, then always use single TC */\n\tif (!(pf->flags & I40E_FLAG_DCB_ENABLED))\n\t\treturn 1;\n\n\t/* SFP mode will be enabled for all TCs on port */\n\tif (!(pf->flags & I40E_FLAG_MFP_ENABLED))\n\t\treturn i40e_dcb_get_num_tc(dcbcfg);\n\n\t/* MFP mode return count of enabled TCs for this PF */\n\tif (pf->hw.func_caps.iscsi)\n\t\tenabled_tc =  i40e_get_iscsi_tc_map(pf);\n\telse\n\t\treturn 1; /* Only TC0 */\n\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (enabled_tc & BIT(i))\n\t\t\tnum_tc++;\n\t}\n\treturn num_tc;\n}\n\n/**\n * i40e_pf_get_pf_tc_map - Get bitmap for enabled traffic classes\n * @pf: PF being queried\n *\n * Return a bitmap for enabled traffic classes for this PF.\n **/\nstatic u8 i40e_pf_get_tc_map(struct i40e_pf *pf)\n{\n\tif (pf->flags & I40E_FLAG_TC_MQPRIO)\n\t\treturn i40e_mqprio_get_enabled_tc(pf);\n\n\t/* If neither MQPRIO nor DCB is enabled for this PF then just return\n\t * default TC\n\t */\n\tif (!(pf->flags & I40E_FLAG_DCB_ENABLED))\n\t\treturn I40E_DEFAULT_TRAFFIC_CLASS;\n\n\t/* SFP mode we want PF to be enabled for all TCs */\n\tif (!(pf->flags & I40E_FLAG_MFP_ENABLED))\n\t\treturn i40e_dcb_get_enabled_tc(&pf->hw.local_dcbx_config);\n\n\t/* MFP enabled and iSCSI PF type */\n\tif (pf->hw.func_caps.iscsi)\n\t\treturn i40e_get_iscsi_tc_map(pf);\n\telse\n\t\treturn I40E_DEFAULT_TRAFFIC_CLASS;\n}\n\n/**\n * i40e_vsi_get_bw_info - Query VSI BW Information\n * @vsi: the VSI being queried\n *\n * Returns 0 on success, negative value on failure\n **/\nstatic int i40e_vsi_get_bw_info(struct i40e_vsi *vsi)\n{\n\tstruct i40e_aqc_query_vsi_ets_sla_config_resp bw_ets_config = {0};\n\tstruct i40e_aqc_query_vsi_bw_config_resp bw_config = {0};\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret;\n\tu32 tc_bw_max;\n\tint i;\n\n\t/* Get the VSI level BW configuration */\n\tret = i40e_aq_query_vsi_bw_config(hw, vsi->seid, &bw_config, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi bw config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EINVAL;\n\t}\n\n\t/* Get the VSI level BW configuration per TC */\n\tret = i40e_aq_query_vsi_ets_sla_config(hw, vsi->seid, &bw_ets_config,\n\t\t\t\t\t       NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi ets bw config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EINVAL;\n\t}\n\n\tif (bw_config.tc_valid_bits != bw_ets_config.tc_valid_bits) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Enabled TCs mismatch from querying VSI BW info 0x%08x 0x%08x\\n\",\n\t\t\t bw_config.tc_valid_bits,\n\t\t\t bw_ets_config.tc_valid_bits);\n\t\t/* Still continuing */\n\t}\n\n\tvsi->bw_limit = le16_to_cpu(bw_config.port_bw_limit);\n\tvsi->bw_max_quanta = bw_config.max_bw;\n\ttc_bw_max = le16_to_cpu(bw_ets_config.tc_bw_max[0]) |\n\t\t    (le16_to_cpu(bw_ets_config.tc_bw_max[1]) << 16);\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tvsi->bw_ets_share_credits[i] = bw_ets_config.share_credits[i];\n\t\tvsi->bw_ets_limit_credits[i] =\n\t\t\t\t\tle16_to_cpu(bw_ets_config.credits[i]);\n\t\t/* 3 bits out of 4 for each TC */\n\t\tvsi->bw_ets_max_quanta[i] = (u8)((tc_bw_max >> (i*4)) & 0x7);\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_configure_bw_alloc - Configure VSI BW allocation per TC\n * @vsi: the VSI being configured\n * @enabled_tc: TC bitmap\n * @bw_share: BW shared credits per TC\n *\n * Returns 0 on success, negative value on failure\n **/\nstatic int i40e_vsi_configure_bw_alloc(struct i40e_vsi *vsi, u8 enabled_tc,\n\t\t\t\t       u8 *bw_share)\n{\n\tstruct i40e_aqc_configure_vsi_tc_bw_data bw_data;\n\tstruct i40e_pf *pf = vsi->back;\n\ti40e_status ret;\n\tint i;\n\n\t/* There is no need to reset BW when mqprio mode is on.  */\n\tif (pf->flags & I40E_FLAG_TC_MQPRIO)\n\t\treturn 0;\n\tif (!vsi->mqprio_qopt.qopt.hw && !(pf->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\tret = i40e_set_bw_limit(vsi, vsi->seid, 0);\n\t\tif (ret)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed to reset tx rate for vsi->seid %u\\n\",\n\t\t\t\t vsi->seid);\n\t\treturn ret;\n\t}\n\tbw_data.tc_valid_bits = enabled_tc;\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tbw_data.tc_bw_credits[i] = bw_share[i];\n\n\tret = i40e_aq_config_vsi_tc_bw(&pf->hw, vsi->seid, &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"AQ command Config VSI BW allocation per TC failed = %d\\n\",\n\t\t\t pf->hw.aq.asq_last_status);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tvsi->info.qs_handle[i] = bw_data.qs_handles[i];\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_config_netdev_tc - Setup the netdev TC configuration\n * @vsi: the VSI being configured\n * @enabled_tc: TC map to be enabled\n *\n **/\nstatic void i40e_vsi_config_netdev_tc(struct i40e_vsi *vsi, u8 enabled_tc)\n{\n\tstruct net_device *netdev = vsi->netdev;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 netdev_tc = 0;\n\tint i;\n\tstruct i40e_dcbx_config *dcbcfg = &hw->local_dcbx_config;\n\n\tif (!netdev)\n\t\treturn;\n\n\tif (!enabled_tc) {\n\t\tnetdev_reset_tc(netdev);\n\t\treturn;\n\t}\n\n\t/* Set up actual enabled TCs on the VSI */\n\tif (netdev_set_num_tc(netdev, vsi->tc_config.numtc))\n\t\treturn;\n\n\t/* set per TC queues for the VSI */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t/* Only set TC queues for enabled tcs\n\t\t *\n\t\t * e.g. For a VSI that has TC0 and TC3 enabled the\n\t\t * enabled_tc bitmap would be 0x00001001; the driver\n\t\t * will set the numtc for netdev as 2 that will be\n\t\t * referenced by the netdev layer as TC 0 and 1.\n\t\t */\n\t\tif (vsi->tc_config.enabled_tc & BIT(i))\n\t\t\tnetdev_set_tc_queue(netdev,\n\t\t\t\t\tvsi->tc_config.tc_info[i].netdev_tc,\n\t\t\t\t\tvsi->tc_config.tc_info[i].qcount,\n\t\t\t\t\tvsi->tc_config.tc_info[i].qoffset);\n\t}\n\n\tif (pf->flags & I40E_FLAG_TC_MQPRIO)\n\t\treturn;\n\n\t/* Assign UP2TC map for the VSI */\n\tfor (i = 0; i < I40E_MAX_USER_PRIORITY; i++) {\n\t\t/* Get the actual TC# for the UP */\n\t\tu8 ets_tc = dcbcfg->etscfg.prioritytable[i];\n\t\t/* Get the mapped netdev TC# for the UP */\n\t\tnetdev_tc =  vsi->tc_config.tc_info[ets_tc].netdev_tc;\n\t\tnetdev_set_prio_tc_map(netdev, i, netdev_tc);\n\t}\n}\n\n/**\n * i40e_vsi_update_queue_map - Update our copy of VSi info with new queue map\n * @vsi: the VSI being configured\n * @ctxt: the ctxt buffer returned from AQ VSI update param command\n **/\nstatic void i40e_vsi_update_queue_map(struct i40e_vsi *vsi,\n\t\t\t\t      struct i40e_vsi_context *ctxt)\n{\n\t/* copy just the sections touched not the entire info\n\t * since not all sections are valid as returned by\n\t * update vsi params\n\t */\n\tvsi->info.mapping_flags = ctxt->info.mapping_flags;\n\tmemcpy(&vsi->info.queue_mapping,\n\t       &ctxt->info.queue_mapping, sizeof(vsi->info.queue_mapping));\n\tmemcpy(&vsi->info.tc_mapping, ctxt->info.tc_mapping,\n\t       sizeof(vsi->info.tc_mapping));\n}\n\n/**\n * i40e_vsi_config_tc - Configure VSI Tx Scheduler for given TC map\n * @vsi: VSI to be configured\n * @enabled_tc: TC bitmap\n *\n * This configures a particular VSI for TCs that are mapped to the\n * given TC bitmap. It uses default bandwidth share for TCs across\n * VSIs to configure TC for a particular VSI.\n *\n * NOTE:\n * It is expected that the VSI queues have been quisced before calling\n * this function.\n **/\nstatic int i40e_vsi_config_tc(struct i40e_vsi *vsi, u8 enabled_tc)\n{\n\tu8 bw_share[I40E_MAX_TRAFFIC_CLASS] = {0};\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tint ret = 0;\n\tint i;\n\n\t/* Check if enabled_tc is same as existing or new TCs */\n\tif (vsi->tc_config.enabled_tc == enabled_tc &&\n\t    vsi->mqprio_qopt.mode != TC_MQPRIO_MODE_CHANNEL)\n\t\treturn ret;\n\n\t/* Enable ETS TCs with equal BW Share for now across all VSIs */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (enabled_tc & BIT(i))\n\t\t\tbw_share[i] = 1;\n\t}\n\n\tret = i40e_vsi_configure_bw_alloc(vsi, enabled_tc, bw_share);\n\tif (ret) {\n\t\tstruct i40e_aqc_query_vsi_bw_config_resp bw_config = {0};\n\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed configuring TC map %d for VSI %d\\n\",\n\t\t\t enabled_tc, vsi->seid);\n\t\tret = i40e_aq_query_vsi_bw_config(hw, vsi->seid,\n\t\t\t\t\t\t  &bw_config, NULL);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed querying vsi bw info, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t\tgoto out;\n\t\t}\n\t\tif ((bw_config.tc_valid_bits & enabled_tc) != enabled_tc) {\n\t\t\tu8 valid_tc = bw_config.tc_valid_bits & enabled_tc;\n\n\t\t\tif (!valid_tc)\n\t\t\t\tvalid_tc = bw_config.tc_valid_bits;\n\t\t\t/* Always enable TC0, no matter what */\n\t\t\tvalid_tc |= 1;\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Requested tc 0x%x, but FW reports 0x%x as valid. Attempting to use 0x%x.\\n\",\n\t\t\t\t enabled_tc, bw_config.tc_valid_bits, valid_tc);\n\t\t\tenabled_tc = valid_tc;\n\t\t}\n\n\t\tret = i40e_vsi_configure_bw_alloc(vsi, enabled_tc, bw_share);\n\t\tif (ret) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Unable to  configure TC map %d for VSI %d\\n\",\n\t\t\t\tenabled_tc, vsi->seid);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/* Update Queue Pairs Mapping for currently enabled UPs */\n\tctxt.seid = vsi->seid;\n\tctxt.pf_num = vsi->back->hw.pf_id;\n\tctxt.vf_num = 0;\n\tctxt.uplink_seid = vsi->uplink_seid;\n\tctxt.info = vsi->info;\n\tif (vsi->back->flags & I40E_FLAG_TC_MQPRIO) {\n\t\tret = i40e_vsi_setup_queue_map_mqprio(vsi, &ctxt, enabled_tc);\n\t\tif (ret)\n\t\t\tgoto out;\n\t} else {\n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, false);\n\t}\n\n\t/* On destroying the qdisc, reset vsi->rss_size, as number of enabled\n\t * queues changed.\n\t */\n\tif (!vsi->mqprio_qopt.qopt.hw && vsi->reconfig_rss) {\n\t\tvsi->rss_size = min_t(int, vsi->back->alloc_rss_size,\n\t\t\t\t      vsi->num_queue_pairs);\n\t\tret = i40e_vsi_config_rss(vsi);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"Failed to reconfig rss for num_queues\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tvsi->reconfig_rss = false;\n\t}\n\tif (vsi->back->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_QUEUE_OPT_VALID);\n\t\tctxt.info.queueing_opt_flags |= I40E_AQ_VSI_QUE_OPT_TCP_ENA;\n\t}\n\n\t/* Update the VSI after updating the VSI queue-mapping\n\t * information\n\t */\n\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Update vsi tc config failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(hw, ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\t/* update the local VSI info with updated queue map */\n\ti40e_vsi_update_queue_map(vsi, &ctxt);\n\tvsi->info.valid_sections = 0;\n\n\t/* Update current VSI BW information */\n\tret = i40e_vsi_get_bw_info(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed updating vsi bw info, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(hw, ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\t/* Update the netdev TC setup */\n\ti40e_vsi_config_netdev_tc(vsi, enabled_tc);\nout:\n\treturn ret;\n}\n\n/**\n * i40e_get_link_speed - Returns link speed for the interface\n * @vsi: VSI to be configured\n *\n **/\nstatic int i40e_get_link_speed(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tswitch (pf->hw.phy.link_info.link_speed) {\n\tcase I40E_LINK_SPEED_40GB:\n\t\treturn 40000;\n\tcase I40E_LINK_SPEED_25GB:\n\t\treturn 25000;\n\tcase I40E_LINK_SPEED_20GB:\n\t\treturn 20000;\n\tcase I40E_LINK_SPEED_10GB:\n\t\treturn 10000;\n\tcase I40E_LINK_SPEED_1GB:\n\t\treturn 1000;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\n/**\n * i40e_set_bw_limit - setup BW limit for Tx traffic based on max_tx_rate\n * @vsi: VSI to be configured\n * @seid: seid of the channel/VSI\n * @max_tx_rate: max TX rate to be configured as BW limit\n *\n * Helper function to set BW limit for a given VSI\n **/\nint i40e_set_bw_limit(struct i40e_vsi *vsi, u16 seid, u64 max_tx_rate)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu64 credits = 0;\n\tint speed = 0;\n\tint ret = 0;\n\n\tspeed = i40e_get_link_speed(vsi);\n\tif (max_tx_rate > speed) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Invalid max tx rate %llu specified for VSI seid %d.\",\n\t\t\tmax_tx_rate, seid);\n\t\treturn -EINVAL;\n\t}\n\tif (max_tx_rate && max_tx_rate < 50) {\n\t\tdev_warn(&pf->pdev->dev,\n\t\t\t \"Setting max tx rate to minimum usable value of 50Mbps.\\n\");\n\t\tmax_tx_rate = 50;\n\t}\n\n\t/* Tx rate credits are in values of 50Mbps, 0 is disabled */\n\tcredits = max_tx_rate;\n\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\tret = i40e_aq_config_vsi_bw_limit(&pf->hw, seid, credits,\n\t\t\t\t\t  I40E_MAX_BW_INACTIVE_ACCUM, NULL);\n\tif (ret)\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed set tx rate (%llu Mbps) for vsi->seid %u, err %s aq_err %s\\n\",\n\t\t\tmax_tx_rate, seid, i40e_stat_str(&pf->hw, ret),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\treturn ret;\n}\n\n/**\n * i40e_remove_queue_channels - Remove queue channels for the TCs\n * @vsi: VSI to be configured\n *\n * Remove queue channels for the TCs\n **/\nstatic void i40e_remove_queue_channels(struct i40e_vsi *vsi)\n{\n\tenum i40e_admin_queue_err last_aq_status;\n\tstruct i40e_cloud_filter *cfilter;\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct hlist_node *node;\n\tint ret, i;\n\n\t/* Reset rss size that was stored when reconfiguring rss for\n\t * channel VSIs with non-power-of-2 queue count.\n\t */\n\tvsi->current_rss_size = 0;\n\n\t/* perform cleanup for channels if they exist */\n\tif (list_empty(&vsi->ch_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tstruct i40e_vsi *p_vsi;\n\n\t\tlist_del(&ch->list);\n\t\tp_vsi = ch->parent_vsi;\n\t\tif (!p_vsi || !ch->initialized) {\n\t\t\tkfree(ch);\n\t\t\tcontinue;\n\t\t}\n\t\t/* Reset queue contexts */\n\t\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\t\tstruct i40e_ring *tx_ring, *rx_ring;\n\t\t\tu16 pf_q;\n\n\t\t\tpf_q = ch->base_queue + i;\n\t\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\t\ttx_ring->ch = NULL;\n\n\t\t\trx_ring = vsi->rx_rings[pf_q];\n\t\t\trx_ring->ch = NULL;\n\t\t}\n\n\t\t/* Reset BW configured for this VSI via mqprio */\n\t\tret = i40e_set_bw_limit(vsi, ch->seid, 0);\n\t\tif (ret)\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"Failed to reset tx rate for ch->seid %u\\n\",\n\t\t\t\t ch->seid);\n\n\t\t/* delete cloud filters associated with this channel */\n\t\thlist_for_each_entry_safe(cfilter, node,\n\t\t\t\t\t  &pf->cloud_filter_list, cloud_node) {\n\t\t\tif (cfilter->seid != ch->seid)\n\t\t\t\tcontinue;\n\n\t\t\thash_del(&cfilter->cloud_node);\n\t\t\tif (cfilter->dst_port)\n\t\t\t\tret = i40e_add_del_cloud_filter_big_buf(vsi,\n\t\t\t\t\t\t\t\t\tcfilter,\n\t\t\t\t\t\t\t\t\tfalse);\n\t\t\telse\n\t\t\t\tret = i40e_add_del_cloud_filter(vsi, cfilter,\n\t\t\t\t\t\t\t\tfalse);\n\t\t\tlast_aq_status = pf->hw.aq.asq_last_status;\n\t\t\tif (ret)\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"Failed to delete cloud filter, err %s aq_err %s\\n\",\n\t\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\t\tkfree(cfilter);\n\t\t}\n\n\t\t/* delete VSI from FW */\n\t\tret = i40e_aq_delete_element(&vsi->back->hw, ch->seid,\n\t\t\t\t\t     NULL);\n\t\tif (ret)\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"unable to remove channel (%d) for parent VSI(%d)\\n\",\n\t\t\t\tch->seid, p_vsi->seid);\n\t\tkfree(ch);\n\t}\n\tINIT_LIST_HEAD(&vsi->ch_list);\n}\n\n/**\n * i40e_is_any_channel - channel exist or not\n * @vsi: ptr to VSI to which channels are associated with\n *\n * Returns true or false if channel(s) exist for associated VSI or not\n **/\nstatic bool i40e_is_any_channel(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tif (ch->initialized)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n/**\n * i40e_get_max_queues_for_channel\n * @vsi: ptr to VSI to which channels are associated with\n *\n * Helper function which returns max value among the queue counts set on the\n * channels/TCs created.\n **/\nstatic int i40e_get_max_queues_for_channel(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\tint max = 0;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tif (!ch->initialized)\n\t\t\tcontinue;\n\t\tif (ch->num_queue_pairs > max)\n\t\t\tmax = ch->num_queue_pairs;\n\t}\n\n\treturn max;\n}\n\n/**\n * i40e_validate_num_queues - validate num_queues w.r.t channel\n * @pf: ptr to PF device\n * @num_queues: number of queues\n * @vsi: the parent VSI\n * @reconfig_rss: indicates should the RSS be reconfigured or not\n *\n * This function validates number of queues in the context of new channel\n * which is being established and determines if RSS should be reconfigured\n * or not for parent VSI.\n **/\nstatic int i40e_validate_num_queues(struct i40e_pf *pf, int num_queues,\n\t\t\t\t    struct i40e_vsi *vsi, bool *reconfig_rss)\n{\n\tint max_ch_queues;\n\n\tif (!reconfig_rss)\n\t\treturn -EINVAL;\n\n\t*reconfig_rss = false;\n\tif (vsi->current_rss_size) {\n\t\tif (num_queues > vsi->current_rss_size) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Error: num_queues (%d) > vsi's current_size(%d)\\n\",\n\t\t\t\tnum_queues, vsi->current_rss_size);\n\t\t\treturn -EINVAL;\n\t\t} else if ((num_queues < vsi->current_rss_size) &&\n\t\t\t   (!is_power_of_2(num_queues))) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Error: num_queues (%d) < vsi's current_size(%d), but not power of 2\\n\",\n\t\t\t\tnum_queues, vsi->current_rss_size);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!is_power_of_2(num_queues)) {\n\t\t/* Find the max num_queues configured for channel if channel\n\t\t * exist.\n\t\t * if channel exist, then enforce 'num_queues' to be more than\n\t\t * max ever queues configured for channel.\n\t\t */\n\t\tmax_ch_queues = i40e_get_max_queues_for_channel(vsi);\n\t\tif (num_queues < max_ch_queues) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Error: num_queues (%d) < max queues configured for channel(%d)\\n\",\n\t\t\t\tnum_queues, max_ch_queues);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t*reconfig_rss = true;\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_reconfig_rss - reconfig RSS based on specified rss_size\n * @vsi: the VSI being setup\n * @rss_size: size of RSS, accordingly LUT gets reprogrammed\n *\n * This function reconfigures RSS by reprogramming LUTs using 'rss_size'\n **/\nstatic int i40e_vsi_reconfig_rss(struct i40e_vsi *vsi, u16 rss_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 seed[I40E_HKEY_ARRAY_SIZE];\n\tstruct i40e_hw *hw = &pf->hw;\n\tint local_rss_size;\n\tu8 *lut;\n\tint ret;\n\n\tif (!vsi->rss_size)\n\t\treturn -EINVAL;\n\n\tif (rss_size > vsi->rss_size)\n\t\treturn -EINVAL;\n\n\tlocal_rss_size = min_t(int, vsi->rss_size, rss_size);\n\tlut = kzalloc(vsi->rss_table_size, GFP_KERNEL);\n\tif (!lut)\n\t\treturn -ENOMEM;\n\n\t/* Ignoring user configured lut if there is one */\n\ti40e_fill_rss_lut(pf, lut, vsi->rss_table_size, local_rss_size);\n\n\t/* Use user configured hash key if there is one, otherwise\n\t * use default.\n\t */\n\tif (vsi->rss_hkey_user)\n\t\tmemcpy(seed, vsi->rss_hkey_user, I40E_HKEY_ARRAY_SIZE);\n\telse\n\t\tnetdev_rss_key_fill((void *)seed, I40E_HKEY_ARRAY_SIZE);\n\n\tret = i40e_config_rss(vsi, seed, lut, vsi->rss_table_size);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Cannot set RSS lut, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(hw, ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\tkfree(lut);\n\t\treturn ret;\n\t}\n\tkfree(lut);\n\n\t/* Do the update w.r.t. storing rss_size */\n\tif (!vsi->orig_rss_size)\n\t\tvsi->orig_rss_size = vsi->rss_size;\n\tvsi->current_rss_size = local_rss_size;\n\n\treturn ret;\n}\n\n/**\n * i40e_channel_setup_queue_map - Setup a channel queue map\n * @pf: ptr to PF device\n * @vsi: the VSI being setup\n * @ctxt: VSI context structure\n * @ch: ptr to channel structure\n *\n * Setup queue map for a specific channel\n **/\nstatic void i40e_channel_setup_queue_map(struct i40e_pf *pf,\n\t\t\t\t\t struct i40e_vsi_context *ctxt,\n\t\t\t\t\t struct i40e_channel *ch)\n{\n\tu16 qcount, qmap, sections = 0;\n\tu8 offset = 0;\n\tint pow;\n\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\n\tqcount = min_t(int, ch->num_queue_pairs, pf->num_lan_msix);\n\tch->num_queue_pairs = qcount;\n\n\t/* find the next higher power-of-2 of num queue pairs */\n\tpow = ilog2(qcount);\n\tif (!is_power_of_2(qcount))\n\t\tpow++;\n\n\tqmap = (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t(pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t/* Setup queue TC[0].qmap for given VSI context */\n\tctxt->info.tc_mapping[0] = cpu_to_le16(qmap);\n\n\tctxt->info.up_enable_bits = 0x1; /* TC0 enabled */\n\tctxt->info.mapping_flags |= cpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\tctxt->info.queue_mapping[0] = cpu_to_le16(ch->base_queue);\n\tctxt->info.valid_sections |= cpu_to_le16(sections);\n}\n\n/**\n * i40e_add_channel - add a channel by adding VSI\n * @pf: ptr to PF device\n * @uplink_seid: underlying HW switching element (VEB) ID\n * @ch: ptr to channel structure\n *\n * Add a channel (VSI) using add_vsi and queue_map\n **/\nstatic int i40e_add_channel(struct i40e_pf *pf, u16 uplink_seid,\n\t\t\t    struct i40e_channel *ch)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tu8 enabled_tc = 0x1; /* TC0 enabled */\n\tint ret;\n\n\tif (ch->type != I40E_VSI_VMDQ2) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"add new vsi failed, ch->type %d\\n\", ch->type);\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tctxt.pf_num = hw->pf_id;\n\tctxt.vf_num = 0;\n\tctxt.uplink_seid = uplink_seid;\n\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\tif (ch->type == I40E_VSI_VMDQ2)\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_VMDQ2;\n\n\tif (pf->flags & I40E_FLAG_VEB_MODE_ENABLED) {\n\t\tctxt.info.valid_sections |=\n\t\t     cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\tctxt.info.switch_id =\n\t\t   cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t}\n\n\t/* Set queue map for a given VSI context */\n\ti40e_channel_setup_queue_map(pf, &ctxt, ch);\n\n\t/* Now time to create VSI */\n\tret = i40e_aq_add_vsi(hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"add new vsi failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\treturn -ENOENT;\n\t}\n\n\t/* Success, update channel, set enabled_tc only if the channel\n\t * is not a macvlan\n\t */\n\tch->enabled_tc = !i40e_is_channel_macvlan(ch) && enabled_tc;\n\tch->seid = ctxt.seid;\n\tch->vsi_number = ctxt.vsi_number;\n\tch->stat_counter_idx = cpu_to_le16(ctxt.info.stat_counter_idx);\n\n\t/* copy just the sections touched not the entire info\n\t * since not all sections are valid as returned by\n\t * update vsi params\n\t */\n\tch->info.mapping_flags = ctxt.info.mapping_flags;\n\tmemcpy(&ch->info.queue_mapping,\n\t       &ctxt.info.queue_mapping, sizeof(ctxt.info.queue_mapping));\n\tmemcpy(&ch->info.tc_mapping, ctxt.info.tc_mapping,\n\t       sizeof(ctxt.info.tc_mapping));\n\n\treturn 0;\n}\n\nstatic int i40e_channel_config_bw(struct i40e_vsi *vsi, struct i40e_channel *ch,\n\t\t\t\t  u8 *bw_share)\n{\n\tstruct i40e_aqc_configure_vsi_tc_bw_data bw_data;\n\ti40e_status ret;\n\tint i;\n\n\tbw_data.tc_valid_bits = ch->enabled_tc;\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tbw_data.tc_bw_credits[i] = bw_share[i];\n\n\tret = i40e_aq_config_vsi_tc_bw(&vsi->back->hw, ch->seid,\n\t\t\t\t       &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Config VSI BW allocation per TC failed, aq_err: %d for new_vsi->seid %u\\n\",\n\t\t\t vsi->back->hw.aq.asq_last_status, ch->seid);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tch->info.qs_handle[i] = bw_data.qs_handles[i];\n\n\treturn 0;\n}\n\n/**\n * i40e_channel_config_tx_ring - config TX ring associated with new channel\n * @pf: ptr to PF device\n * @vsi: the VSI being setup\n * @ch: ptr to channel structure\n *\n * Configure TX rings associated with channel (VSI) since queues are being\n * from parent VSI.\n **/\nstatic int i40e_channel_config_tx_ring(struct i40e_pf *pf,\n\t\t\t\t       struct i40e_vsi *vsi,\n\t\t\t\t       struct i40e_channel *ch)\n{\n\ti40e_status ret;\n\tint i;\n\tu8 bw_share[I40E_MAX_TRAFFIC_CLASS] = {0};\n\n\t/* Enable ETS TCs with equal BW Share for now across all VSIs */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (ch->enabled_tc & BIT(i))\n\t\t\tbw_share[i] = 1;\n\t}\n\n\t/* configure BW for new VSI */\n\tret = i40e_channel_config_bw(vsi, ch, bw_share);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed configuring TC map %d for channel (seid %u)\\n\",\n\t\t\t ch->enabled_tc, ch->seid);\n\t\treturn ret;\n\t}\n\n\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\tstruct i40e_ring *tx_ring, *rx_ring;\n\t\tu16 pf_q;\n\n\t\tpf_q = ch->base_queue + i;\n\n\t\t/* Get to TX ring ptr of main VSI, for re-setup TX queue\n\t\t * context\n\t\t */\n\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\ttx_ring->ch = ch;\n\n\t\t/* Get the RX ring ptr */\n\t\trx_ring = vsi->rx_rings[pf_q];\n\t\trx_ring->ch = ch;\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_setup_hw_channel - setup new channel\n * @pf: ptr to PF device\n * @vsi: the VSI being setup\n * @ch: ptr to channel structure\n * @uplink_seid: underlying HW switching element (VEB) ID\n * @type: type of channel to be created (VMDq2/VF)\n *\n * Setup new channel (VSI) based on specified type (VMDq2/VF)\n * and configures TX rings accordingly\n **/\nstatic inline int i40e_setup_hw_channel(struct i40e_pf *pf,\n\t\t\t\t\tstruct i40e_vsi *vsi,\n\t\t\t\t\tstruct i40e_channel *ch,\n\t\t\t\t\tu16 uplink_seid, u8 type)\n{\n\tint ret;\n\n\tch->initialized = false;\n\tch->base_queue = vsi->next_base_queue;\n\tch->type = type;\n\n\t/* Proceed with creation of channel (VMDq2) VSI */\n\tret = i40e_add_channel(pf, uplink_seid, ch);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to add_channel using uplink_seid %u\\n\",\n\t\t\t uplink_seid);\n\t\treturn ret;\n\t}\n\n\t/* Mark the successful creation of channel */\n\tch->initialized = true;\n\n\t/* Reconfigure TX queues using QTX_CTL register */\n\tret = i40e_channel_config_tx_ring(pf, vsi, ch);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to configure TX rings for channel %u\\n\",\n\t\t\t ch->seid);\n\t\treturn ret;\n\t}\n\n\t/* update 'next_base_queue' */\n\tvsi->next_base_queue = vsi->next_base_queue + ch->num_queue_pairs;\n\tdev_dbg(&pf->pdev->dev,\n\t\t\"Added channel: vsi_seid %u, vsi_number %u, stat_counter_idx %u, num_queue_pairs %u, pf->next_base_queue %d\\n\",\n\t\tch->seid, ch->vsi_number, ch->stat_counter_idx,\n\t\tch->num_queue_pairs,\n\t\tvsi->next_base_queue);\n\treturn ret;\n}\n\n/**\n * i40e_setup_channel - setup new channel using uplink element\n * @pf: ptr to PF device\n * @type: type of channel to be created (VMDq2/VF)\n * @uplink_seid: underlying HW switching element (VEB) ID\n * @ch: ptr to channel structure\n *\n * Setup new channel (VSI) based on specified type (VMDq2/VF)\n * and uplink switching element (uplink_seid)\n **/\nstatic bool i40e_setup_channel(struct i40e_pf *pf, struct i40e_vsi *vsi,\n\t\t\t       struct i40e_channel *ch)\n{\n\tu8 vsi_type;\n\tu16 seid;\n\tint ret;\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\tvsi_type = I40E_VSI_VMDQ2;\n\t} else {\n\t\tdev_err(&pf->pdev->dev, \"unsupported parent vsi type(%d)\\n\",\n\t\t\tvsi->type);\n\t\treturn false;\n\t}\n\n\t/* underlying switching element */\n\tseid = pf->vsi[pf->lan_vsi]->uplink_seid;\n\n\t/* create channel (VSI), configure TX rings */\n\tret = i40e_setup_hw_channel(pf, vsi, ch, seid, vsi_type);\n\tif (ret) {\n\t\tdev_err(&pf->pdev->dev, \"failed to setup hw_channel\\n\");\n\t\treturn false;\n\t}\n\n\treturn ch->initialized ? true : false;\n}\n\n/**\n * i40e_validate_and_set_switch_mode - sets up switch mode correctly\n * @vsi: ptr to VSI which has PF backing\n *\n * Sets up switch mode correctly if it needs to be changed and perform\n * what are allowed modes.\n **/\nstatic int i40e_validate_and_set_switch_mode(struct i40e_vsi *vsi)\n{\n\tu8 mode;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret;\n\n\tret = i40e_get_capabilities(pf, i40e_aqc_opc_list_dev_capabilities);\n\tif (ret)\n\t\treturn -EINVAL;\n\n\tif (hw->dev_caps.switch_mode) {\n\t\t/* if switch mode is set, support mode2 (non-tunneled for\n\t\t * cloud filter) for now\n\t\t */\n\t\tu32 switch_mode = hw->dev_caps.switch_mode &\n\t\t\t\t  I40E_SWITCH_MODE_MASK;\n\t\tif (switch_mode >= I40E_CLOUD_FILTER_MODE1) {\n\t\t\tif (switch_mode == I40E_CLOUD_FILTER_MODE2)\n\t\t\t\treturn 0;\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Invalid switch_mode (%d), only non-tunneled mode for cloud filter is supported\\n\",\n\t\t\t\thw->dev_caps.switch_mode);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t/* Set Bit 7 to be valid */\n\tmode = I40E_AQ_SET_SWITCH_BIT7_VALID;\n\n\t/* Set L4type for TCP support */\n\tmode |= I40E_AQ_SET_SWITCH_L4_TYPE_TCP;\n\n\t/* Set cloud filter mode */\n\tmode |= I40E_AQ_SET_SWITCH_MODE_NON_TUNNEL;\n\n\t/* Prep mode field for set_switch_config */\n\tret = i40e_aq_set_switch_config(hw, pf->last_sw_conf_flags,\n\t\t\t\t\tpf->last_sw_conf_valid_flags,\n\t\t\t\t\tmode, NULL);\n\tif (ret && hw->aq.asq_last_status != I40E_AQ_RC_ESRCH)\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"couldn't set switch config bits, err %s aq_err %s\\n\",\n\t\t\ti40e_stat_str(hw, ret),\n\t\t\ti40e_aq_str(hw,\n\t\t\t\t    hw->aq.asq_last_status));\n\n\treturn ret;\n}\n\n/**\n * i40e_create_queue_channel - function to create channel\n * @vsi: VSI to be configured\n * @ch: ptr to channel (it contains channel specific params)\n *\n * This function creates channel (VSI) using num_queues specified by user,\n * reconfigs RSS if needed.\n **/\nint i40e_create_queue_channel(struct i40e_vsi *vsi,\n\t\t\t      struct i40e_channel *ch)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tbool reconfig_rss;\n\tint err;\n\n\tif (!ch)\n\t\treturn -EINVAL;\n\n\tif (!ch->num_queue_pairs) {\n\t\tdev_err(&pf->pdev->dev, \"Invalid num_queues requested: %d\\n\",\n\t\t\tch->num_queue_pairs);\n\t\treturn -EINVAL;\n\t}\n\n\t/* validate user requested num_queues for channel */\n\terr = i40e_validate_num_queues(pf, ch->num_queue_pairs, vsi,\n\t\t\t\t       &reconfig_rss);\n\tif (err) {\n\t\tdev_info(&pf->pdev->dev, \"Failed to validate num_queues (%d)\\n\",\n\t\t\t ch->num_queue_pairs);\n\t\treturn -EINVAL;\n\t}\n\n\t/* By default we are in VEPA mode, if this is the first VF/VMDq\n\t * VSI to be added switch to VEB mode.\n\t */\n\tif ((!(pf->flags & I40E_FLAG_VEB_MODE_ENABLED)) ||\n\t    (!i40e_is_any_channel(vsi))) {\n\t\tif (!is_power_of_2(vsi->tc_config.tc_info[0].qcount)) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Failed to create channel. Override queues (%u) not power of 2\\n\",\n\t\t\t\tvsi->tc_config.tc_info[0].qcount);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!(pf->flags & I40E_FLAG_VEB_MODE_ENABLED)) {\n\t\t\tpf->flags |= I40E_FLAG_VEB_MODE_ENABLED;\n\n\t\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\t\tif (pf->flags & I40E_FLAG_TC_MQPRIO)\n\t\t\t\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG,\n\t\t\t\t\t\t      true);\n\t\t\t\telse\n\t\t\t\t\ti40e_do_reset_safe(pf,\n\t\t\t\t\t\t\t   I40E_PF_RESET_FLAG);\n\t\t\t}\n\t\t}\n\t\t/* now onwards for main VSI, number of queues will be value\n\t\t * of TC0's queue count\n\t\t */\n\t}\n\n\t/* By this time, vsi->cnt_q_avail shall be set to non-zero and\n\t * it should be more than num_queues\n\t */\n\tif (!vsi->cnt_q_avail || vsi->cnt_q_avail < ch->num_queue_pairs) {\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Error: cnt_q_avail (%u) less than num_queues %d\\n\",\n\t\t\tvsi->cnt_q_avail, ch->num_queue_pairs);\n\t\treturn -EINVAL;\n\t}\n\n\t/* reconfig_rss only if vsi type is MAIN_VSI */\n\tif (reconfig_rss && (vsi->type == I40E_VSI_MAIN)) {\n\t\terr = i40e_vsi_reconfig_rss(vsi, ch->num_queue_pairs);\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Error: unable to reconfig rss for num_queues (%u)\\n\",\n\t\t\t\t ch->num_queue_pairs);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!i40e_setup_channel(pf, vsi, ch)) {\n\t\tdev_info(&pf->pdev->dev, \"Failed to setup channel\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev_info(&pf->pdev->dev,\n\t\t \"Setup channel (id:%u) utilizing num_queues %d\\n\",\n\t\t ch->seid, ch->num_queue_pairs);\n\n\t/* configure VSI for BW limit */\n\tif (ch->max_tx_rate) {\n\t\tu64 credits = ch->max_tx_rate;\n\n\t\tif (i40e_set_bw_limit(vsi, ch->seid, ch->max_tx_rate))\n\t\t\treturn -EINVAL;\n\n\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\tch->max_tx_rate,\n\t\t\tcredits,\n\t\t\tch->seid);\n\t}\n\n\t/* in case of VF, this will be main SRIOV VSI */\n\tch->parent_vsi = vsi;\n\n\t/* and update main_vsi's count for queue_available to use */\n\tvsi->cnt_q_avail -= ch->num_queue_pairs;\n\n\treturn 0;\n}\n\n/**\n * i40e_configure_queue_channels - Add queue channel for the given TCs\n * @vsi: VSI to be configured\n *\n * Configures queue channel mapping to the given TCs\n **/\nstatic int i40e_configure_queue_channels(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch;\n\tu64 max_rate = 0;\n\tint ret = 0, i;\n\n\t/* Create app vsi with the TCs. Main VSI with TC0 is already set up */\n\tvsi->tc_seid_map[0] = vsi->seid;\n\tfor (i = 1; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (vsi->tc_config.enabled_tc & BIT(i)) {\n\t\t\tch = kzalloc(sizeof(*ch), GFP_KERNEL);\n\t\t\tif (!ch) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto err_free;\n\t\t\t}\n\n\t\t\tINIT_LIST_HEAD(&ch->list);\n\t\t\tch->num_queue_pairs =\n\t\t\t\tvsi->tc_config.tc_info[i].qcount;\n\t\t\tch->base_queue =\n\t\t\t\tvsi->tc_config.tc_info[i].qoffset;\n\n\t\t\t/* Bandwidth limit through tc interface is in bytes/s,\n\t\t\t * change to Mbit/s\n\t\t\t */\n\t\t\tmax_rate = vsi->mqprio_qopt.max_rate[i];\n\t\t\tdo_div(max_rate, I40E_BW_MBPS_DIVISOR);\n\t\t\tch->max_tx_rate = max_rate;\n\n\t\t\tlist_add_tail(&ch->list, &vsi->ch_list);\n\n\t\t\tret = i40e_create_queue_channel(vsi, ch);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\t\"Failed creating queue channel with TC%d: queues %d\\n\",\n\t\t\t\t\ti, ch->num_queue_pairs);\n\t\t\t\tgoto err_free;\n\t\t\t}\n\t\t\tvsi->tc_seid_map[i] = ch->seid;\n\t\t}\n\t}\n\treturn ret;\n\nerr_free:\n\ti40e_remove_queue_channels(vsi);\n\treturn ret;\n}\n\n/**\n * i40e_veb_config_tc - Configure TCs for given VEB\n * @veb: given VEB\n * @enabled_tc: TC bitmap\n *\n * Configures given TC bitmap for VEB (switching) element\n **/\nint i40e_veb_config_tc(struct i40e_veb *veb, u8 enabled_tc)\n{\n\tstruct i40e_aqc_configure_switching_comp_bw_config_data bw_data = {0};\n\tstruct i40e_pf *pf = veb->pf;\n\tint ret = 0;\n\tint i;\n\n\t/* No TCs or already enabled TCs just return */\n\tif (!enabled_tc || veb->enabled_tc == enabled_tc)\n\t\treturn ret;\n\n\tbw_data.tc_valid_bits = enabled_tc;\n\t/* bw_data.absolute_credits is not set (relative) */\n\n\t/* Enable ETS TCs with equal BW Share for now */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (enabled_tc & BIT(i))\n\t\t\tbw_data.tc_bw_share_credits[i] = 1;\n\t}\n\n\tret = i40e_aq_config_switch_comp_bw_config(&pf->hw, veb->seid,\n\t\t\t\t\t\t   &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VEB bw config failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\t/* Update the BW information */\n\tret = i40e_veb_get_bw_info(veb);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed getting veb bw config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n\nout:\n\treturn ret;\n}\n\n#ifdef CONFIG_I40E_DCB\n/**\n * i40e_dcb_reconfigure - Reconfigure all VEBs and VSIs\n * @pf: PF struct\n *\n * Reconfigure VEB/VSIs on a given PF; it is assumed that\n * the caller would've quiesce all the VSIs before calling\n * this function\n **/\nstatic void i40e_dcb_reconfigure(struct i40e_pf *pf)\n{\n\tu8 tc_map = 0;\n\tint ret;\n\tu8 v;\n\n\t/* Enable the TCs available on PF to all VEBs */\n\ttc_map = i40e_pf_get_tc_map(pf);\n\tfor (v = 0; v < I40E_MAX_VEB; v++) {\n\t\tif (!pf->veb[v])\n\t\t\tcontinue;\n\t\tret = i40e_veb_config_tc(pf->veb[v], tc_map);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed configuring TC for VEB seid=%d\\n\",\n\t\t\t\t pf->veb[v]->seid);\n\t\t\t/* Will try to configure as many components */\n\t\t}\n\t}\n\n\t/* Update each VSI */\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (!pf->vsi[v])\n\t\t\tcontinue;\n\n\t\t/* - Enable all TCs for the LAN VSI\n\t\t * - For all others keep them at TC0 for now\n\t\t */\n\t\tif (v == pf->lan_vsi)\n\t\t\ttc_map = i40e_pf_get_tc_map(pf);\n\t\telse\n\t\t\ttc_map = I40E_DEFAULT_TRAFFIC_CLASS;\n\n\t\tret = i40e_vsi_config_tc(pf->vsi[v], tc_map);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed configuring TC for VSI seid=%d\\n\",\n\t\t\t\t pf->vsi[v]->seid);\n\t\t\t/* Will try to configure as many components */\n\t\t} else {\n\t\t\t/* Re-configure VSI vectors based on updated TC map */\n\t\t\ti40e_vsi_map_rings_to_vectors(pf->vsi[v]);\n\t\t\tif (pf->vsi[v]->netdev)\n\t\t\t\ti40e_dcbnl_set_all(pf->vsi[v]);\n\t\t}\n\t}\n}\n\n/**\n * i40e_resume_port_tx - Resume port Tx\n * @pf: PF struct\n *\n * Resume a port's Tx and issue a PF reset in case of failure to\n * resume.\n **/\nstatic int i40e_resume_port_tx(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret;\n\n\tret = i40e_aq_resume_port_tx(hw, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Resume Port Tx failed, err %s aq_err %s\\n\",\n\t\t\t  i40e_stat_str(&pf->hw, ret),\n\t\t\t  i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\t/* Schedule PF reset to recover */\n\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\ti40e_service_event_schedule(pf);\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_init_pf_dcb - Initialize DCB configuration\n * @pf: PF being configured\n *\n * Query the current DCB configuration and cache it\n * in the hardware structure\n **/\nstatic int i40e_init_pf_dcb(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint err = 0;\n\n\t/* Do not enable DCB for SW1 and SW2 images even if the FW is capable\n\t * Also do not enable DCBx if FW LLDP agent is disabled\n\t */\n\tif ((pf->hw_features & I40E_HW_NO_DCB_SUPPORT) ||\n\t    (pf->flags & I40E_FLAG_DISABLE_FW_LLDP)) {\n\t\tdev_info(&pf->pdev->dev, \"DCB is not supported or FW LLDP is disabled\\n\");\n\t\terr = I40E_NOT_SUPPORTED;\n\t\tgoto out;\n\t}\n\n\terr = i40e_init_dcb(hw, true);\n\tif (!err) {\n\t\t/* Device/Function is not DCBX capable */\n\t\tif ((!hw->func_caps.dcb) ||\n\t\t    (hw->dcbx_status == I40E_DCBX_STATUS_DISABLED)) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"DCBX offload is not supported or is disabled for this PF.\\n\");\n\t\t} else {\n\t\t\t/* When status is not DISABLED then DCBX in FW */\n\t\t\tpf->dcbx_cap = DCB_CAP_DCBX_LLD_MANAGED |\n\t\t\t\t       DCB_CAP_DCBX_VER_IEEE;\n\n\t\t\tpf->flags |= I40E_FLAG_DCB_CAPABLE;\n\t\t\t/* Enable DCB tagging only when more than one TC\n\t\t\t * or explicitly disable if only one TC\n\t\t\t */\n\t\t\tif (i40e_dcb_get_num_tc(&hw->local_dcbx_config) > 1)\n\t\t\t\tpf->flags |= I40E_FLAG_DCB_ENABLED;\n\t\t\telse\n\t\t\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"DCBX offload is supported for this PF.\\n\");\n\t\t}\n\t} else if (pf->hw.aq.asq_last_status == I40E_AQ_RC_EPERM) {\n\t\tdev_info(&pf->pdev->dev, \"FW LLDP disabled for this PF.\\n\");\n\t\tpf->flags |= I40E_FLAG_DISABLE_FW_LLDP;\n\t} else {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Query for DCB configuration failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, err),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n\nout:\n\treturn err;\n}\n#endif /* CONFIG_I40E_DCB */\n#define SPEED_SIZE 14\n#define FC_SIZE 8\n/**\n * i40e_print_link_message - print link up or down\n * @vsi: the VSI for which link needs a message\n * @isup: true of link is up, false otherwise\n */\nvoid i40e_print_link_message(struct i40e_vsi *vsi, bool isup)\n{\n\tenum i40e_aq_link_speed new_speed;\n\tstruct i40e_pf *pf = vsi->back;\n\tchar *speed = \"Unknown\";\n\tchar *fc = \"Unknown\";\n\tchar *fec = \"\";\n\tchar *req_fec = \"\";\n\tchar *an = \"\";\n\n\tif (isup)\n\t\tnew_speed = pf->hw.phy.link_info.link_speed;\n\telse\n\t\tnew_speed = I40E_LINK_SPEED_UNKNOWN;\n\n\tif ((vsi->current_isup == isup) && (vsi->current_speed == new_speed))\n\t\treturn;\n\tvsi->current_isup = isup;\n\tvsi->current_speed = new_speed;\n\tif (!isup) {\n\t\tnetdev_info(vsi->netdev, \"NIC Link is Down\\n\");\n\t\treturn;\n\t}\n\n\t/* Warn user if link speed on NPAR enabled partition is not at\n\t * least 10GB\n\t */\n\tif (pf->hw.func_caps.npar_enable &&\n\t    (pf->hw.phy.link_info.link_speed == I40E_LINK_SPEED_1GB ||\n\t     pf->hw.phy.link_info.link_speed == I40E_LINK_SPEED_100MB))\n\t\tnetdev_warn(vsi->netdev,\n\t\t\t    \"The partition detected link speed that is less than 10Gbps\\n\");\n\n\tswitch (pf->hw.phy.link_info.link_speed) {\n\tcase I40E_LINK_SPEED_40GB:\n\t\tspeed = \"40 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_20GB:\n\t\tspeed = \"20 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_25GB:\n\t\tspeed = \"25 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_10GB:\n\t\tspeed = \"10 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_5GB:\n\t\tspeed = \"5 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_2_5GB:\n\t\tspeed = \"2.5 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_1GB:\n\t\tspeed = \"1000 M\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_100MB:\n\t\tspeed = \"100 M\";\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tswitch (pf->hw.fc.current_mode) {\n\tcase I40E_FC_FULL:\n\t\tfc = \"RX/TX\";\n\t\tbreak;\n\tcase I40E_FC_TX_PAUSE:\n\t\tfc = \"TX\";\n\t\tbreak;\n\tcase I40E_FC_RX_PAUSE:\n\t\tfc = \"RX\";\n\t\tbreak;\n\tdefault:\n\t\tfc = \"None\";\n\t\tbreak;\n\t}\n\n\tif (pf->hw.phy.link_info.link_speed == I40E_LINK_SPEED_25GB) {\n\t\treq_fec = \"None\";\n\t\tfec = \"None\";\n\t\tan = \"False\";\n\n\t\tif (pf->hw.phy.link_info.an_info & I40E_AQ_AN_COMPLETED)\n\t\t\tan = \"True\";\n\n\t\tif (pf->hw.phy.link_info.fec_info &\n\t\t    I40E_AQ_CONFIG_FEC_KR_ENA)\n\t\t\tfec = \"CL74 FC-FEC/BASE-R\";\n\t\telse if (pf->hw.phy.link_info.fec_info &\n\t\t\t I40E_AQ_CONFIG_FEC_RS_ENA)\n\t\t\tfec = \"CL108 RS-FEC\";\n\n\t\t/* 'CL108 RS-FEC' should be displayed when RS is requested, or\n\t\t * both RS and FC are requested\n\t\t */\n\t\tif (vsi->back->hw.phy.link_info.req_fec_info &\n\t\t    (I40E_AQ_REQUEST_FEC_KR | I40E_AQ_REQUEST_FEC_RS)) {\n\t\t\tif (vsi->back->hw.phy.link_info.req_fec_info &\n\t\t\t    I40E_AQ_REQUEST_FEC_RS)\n\t\t\t\treq_fec = \"CL108 RS-FEC\";\n\t\t\telse\n\t\t\t\treq_fec = \"CL74 FC-FEC/BASE-R\";\n\t\t}\n\t\tnetdev_info(vsi->netdev,\n\t\t\t    \"NIC Link is Up, %sbps Full Duplex, Requested FEC: %s, Negotiated FEC: %s, Autoneg: %s, Flow Control: %s\\n\",\n\t\t\t    speed, req_fec, fec, an, fc);\n\t} else {\n\t\tnetdev_info(vsi->netdev,\n\t\t\t    \"NIC Link is Up, %sbps Full Duplex, Flow Control: %s\\n\",\n\t\t\t    speed, fc);\n\t}\n\n}\n\n/**\n * i40e_up_complete - Finish the last steps of bringing up a connection\n * @vsi: the VSI being configured\n **/\nstatic int i40e_up_complete(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint err;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\ti40e_vsi_configure_msix(vsi);\n\telse\n\t\ti40e_configure_msi_and_legacy(vsi);\n\n\t/* start rings */\n\terr = i40e_vsi_start_rings(vsi);\n\tif (err)\n\t\treturn err;\n\n\tclear_bit(__I40E_VSI_DOWN, vsi->state);\n\ti40e_napi_enable_all(vsi);\n\ti40e_vsi_enable_irq(vsi);\n\n\tif ((pf->hw.phy.link_info.link_info & I40E_AQ_LINK_UP) &&\n\t    (vsi->netdev)) {\n\t\ti40e_print_link_message(vsi, true);\n\t\tnetif_tx_start_all_queues(vsi->netdev);\n\t\tnetif_carrier_on(vsi->netdev);\n\t}\n\n\t/* replay FDIR SB filters */\n\tif (vsi->type == I40E_VSI_FDIR) {\n\t\t/* reset fd counters */\n\t\tpf->fd_add_err = 0;\n\t\tpf->fd_atr_cnt = 0;\n\t\ti40e_fdir_filter_restore(vsi);\n\t}\n\n\t/* On the next run of the service_task, notify any clients of the new\n\t * opened netdev\n\t */\n\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\ti40e_service_event_schedule(pf);\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_reinit_locked - Reset the VSI\n * @vsi: the VSI being configured\n *\n * Rebuild the ring structs after some configuration\n * has changed, e.g. MTU size.\n **/\nstatic void i40e_vsi_reinit_locked(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tWARN_ON(in_interrupt());\n\twhile (test_and_set_bit(__I40E_CONFIG_BUSY, pf->state))\n\t\tusleep_range(1000, 2000);\n\ti40e_down(vsi);\n\n\ti40e_up(vsi);\n\tclear_bit(__I40E_CONFIG_BUSY, pf->state);\n}\n\n/**\n * i40e_up - Bring the connection back up after being down\n * @vsi: the VSI being configured\n **/\nint i40e_up(struct i40e_vsi *vsi)\n{\n\tint err;\n\n\terr = i40e_vsi_configure(vsi);\n\tif (!err)\n\t\terr = i40e_up_complete(vsi);\n\n\treturn err;\n}\n\n/**\n * i40e_force_link_state - Force the link status\n * @pf: board private structure\n * @is_up: whether the link state should be forced up or down\n **/\nstatic i40e_status i40e_force_link_state(struct i40e_pf *pf, bool is_up)\n{\n\tstruct i40e_aq_get_phy_abilities_resp abilities;\n\tstruct i40e_aq_set_phy_config config = {0};\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status err;\n\tu64 mask;\n\tu8 speed;\n\n\t/* Card might've been put in an unstable state by other drivers\n\t * and applications, which causes incorrect speed values being\n\t * set on startup. In order to clear speed registers, we call\n\t * get_phy_capabilities twice, once to get initial state of\n\t * available speeds, and once to get current PHY config.\n\t */\n\terr = i40e_aq_get_phy_capabilities(hw, false, true, &abilities,\n\t\t\t\t\t   NULL);\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"failed to get phy cap., ret =  %s last_status =  %s\\n\",\n\t\t\ti40e_stat_str(hw, err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn err;\n\t}\n\tspeed = abilities.link_speed;\n\n\t/* Get the current phy config */\n\terr = i40e_aq_get_phy_capabilities(hw, false, false, &abilities,\n\t\t\t\t\t   NULL);\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"failed to get phy cap., ret =  %s last_status =  %s\\n\",\n\t\t\ti40e_stat_str(hw, err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn err;\n\t}\n\n\t/* If link needs to go up, but was not forced to go down,\n\t * and its speed values are OK, no need for a flap\n\t */\n\tif (is_up && abilities.phy_type != 0 && abilities.link_speed != 0)\n\t\treturn I40E_SUCCESS;\n\n\t/* To force link we need to set bits for all supported PHY types,\n\t * but there are now more than 32, so we need to split the bitmap\n\t * across two fields.\n\t */\n\tmask = I40E_PHY_TYPES_BITMASK;\n\tconfig.phy_type = is_up ? cpu_to_le32((u32)(mask & 0xffffffff)) : 0;\n\tconfig.phy_type_ext = is_up ? (u8)((mask >> 32) & 0xff) : 0;\n\t/* Copy the old settings, except of phy_type */\n\tconfig.abilities = abilities.abilities;\n\tif (abilities.link_speed != 0)\n\t\tconfig.link_speed = abilities.link_speed;\n\telse\n\t\tconfig.link_speed = speed;\n\tconfig.eee_capability = abilities.eee_capability;\n\tconfig.eeer = abilities.eeer_val;\n\tconfig.low_power_ctrl = abilities.d3_lpan;\n\tconfig.fec_config = abilities.fec_cfg_curr_mod_ext_info &\n\t\t\t    I40E_AQ_PHY_FEC_CONFIG_MASK;\n\terr = i40e_aq_set_phy_config(hw, &config, NULL);\n\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"set phy config ret =  %s last_status =  %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, err),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn err;\n\t}\n\n\t/* Update the link info */\n\terr = i40e_update_link_info(hw);\n\tif (err) {\n\t\t/* Wait a little bit (on 40G cards it sometimes takes a really\n\t\t * long time for link to come back from the atomic reset)\n\t\t * and try once more\n\t\t */\n\t\tmsleep(1000);\n\t\ti40e_update_link_info(hw);\n\t}\n\n\ti40e_aq_set_link_restart_an(hw, true, NULL);\n\n\treturn I40E_SUCCESS;\n}\n\n/**\n * i40e_down - Shutdown the connection processing\n * @vsi: the VSI being stopped\n **/\nvoid i40e_down(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\t/* It is assumed that the caller of this function\n\t * sets the vsi->state __I40E_VSI_DOWN bit.\n\t */\n\tif (vsi->netdev) {\n\t\tnetif_carrier_off(vsi->netdev);\n\t\tnetif_tx_disable(vsi->netdev);\n\t}\n\ti40e_vsi_disable_irq(vsi);\n\ti40e_vsi_stop_rings(vsi);\n\tif (vsi->type == I40E_VSI_MAIN &&\n\t    vsi->back->flags & I40E_FLAG_LINK_DOWN_ON_CLOSE_ENABLED)\n\t\ti40e_force_link_state(vsi->back, false);\n\ti40e_napi_disable_all(vsi);\n\n\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\ti40e_clean_tx_ring(vsi->tx_rings[i]);\n\t\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t\t/* Make sure that in-progress ndo_xdp_xmit\n\t\t\t * calls are completed.\n\t\t\t */\n\t\t\tsynchronize_rcu();\n\t\t\ti40e_clean_tx_ring(vsi->xdp_rings[i]);\n\t\t}\n\t\ti40e_clean_rx_ring(vsi->rx_rings[i]);\n\t}\n\n}\n\n/**\n * i40e_validate_mqprio_qopt- validate queue mapping info\n * @vsi: the VSI being configured\n * @mqprio_qopt: queue parametrs\n **/\nstatic int i40e_validate_mqprio_qopt(struct i40e_vsi *vsi,\n\t\t\t\t     struct tc_mqprio_qopt_offload *mqprio_qopt)\n{\n\tu64 sum_max_rate = 0;\n\tu64 max_rate = 0;\n\tint i;\n\n\tif (mqprio_qopt->qopt.offset[0] != 0 ||\n\t    mqprio_qopt->qopt.num_tc < 1 ||\n\t    mqprio_qopt->qopt.num_tc > I40E_MAX_TRAFFIC_CLASS)\n\t\treturn -EINVAL;\n\tfor (i = 0; ; i++) {\n\t\tif (!mqprio_qopt->qopt.count[i])\n\t\t\treturn -EINVAL;\n\t\tif (mqprio_qopt->min_rate[i]) {\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"Invalid min tx rate (greater than 0) specified\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmax_rate = mqprio_qopt->max_rate[i];\n\t\tdo_div(max_rate, I40E_BW_MBPS_DIVISOR);\n\t\tsum_max_rate += max_rate;\n\n\t\tif (i >= mqprio_qopt->qopt.num_tc - 1)\n\t\t\tbreak;\n\t\tif (mqprio_qopt->qopt.offset[i + 1] !=\n\t\t    (mqprio_qopt->qopt.offset[i] + mqprio_qopt->qopt.count[i]))\n\t\t\treturn -EINVAL;\n\t}\n\tif (vsi->num_queue_pairs <\n\t    (mqprio_qopt->qopt.offset[i] + mqprio_qopt->qopt.count[i])) {\n\t\treturn -EINVAL;\n\t}\n\tif (sum_max_rate > i40e_get_link_speed(vsi)) {\n\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\"Invalid max tx rate specified\\n\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\n/**\n * i40e_vsi_set_default_tc_config - set default values for tc configuration\n * @vsi: the VSI being configured\n **/\nstatic void i40e_vsi_set_default_tc_config(struct i40e_vsi *vsi)\n{\n\tu16 qcount;\n\tint i;\n\n\t/* Only TC0 is enabled */\n\tvsi->tc_config.numtc = 1;\n\tvsi->tc_config.enabled_tc = 1;\n\tqcount = min_t(int, vsi->alloc_queue_pairs,\n\t\t       i40e_pf_get_max_q_per_tc(vsi->back));\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t/* For the TC that is not enabled set the offset to to default\n\t\t * queue and allocate one queue for the given TC.\n\t\t */\n\t\tvsi->tc_config.tc_info[i].qoffset = 0;\n\t\tif (i == 0)\n\t\t\tvsi->tc_config.tc_info[i].qcount = qcount;\n\t\telse\n\t\t\tvsi->tc_config.tc_info[i].qcount = 1;\n\t\tvsi->tc_config.tc_info[i].netdev_tc = 0;\n\t}\n}\n\n/**\n * i40e_del_macvlan_filter\n * @hw: pointer to the HW structure\n * @seid: seid of the channel VSI\n * @macaddr: the mac address to apply as a filter\n * @aq_err: store the admin Q error\n *\n * This function deletes a mac filter on the channel VSI which serves as the\n * macvlan. Returns 0 on success.\n **/\nstatic i40e_status i40e_del_macvlan_filter(struct i40e_hw *hw, u16 seid,\n\t\t\t\t\t   const u8 *macaddr, int *aq_err)\n{\n\tstruct i40e_aqc_remove_macvlan_element_data element;\n\ti40e_status status;\n\n\tmemset(&element, 0, sizeof(element));\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\telement.flags = I40E_AQC_MACVLAN_DEL_PERFECT_MATCH;\n\tstatus = i40e_aq_remove_macvlan(hw, seid, &element, 1, NULL);\n\t*aq_err = hw->aq.asq_last_status;\n\n\treturn status;\n}\n\n/**\n * i40e_add_macvlan_filter\n * @hw: pointer to the HW structure\n * @seid: seid of the channel VSI\n * @macaddr: the mac address to apply as a filter\n * @aq_err: store the admin Q error\n *\n * This function adds a mac filter on the channel VSI which serves as the\n * macvlan. Returns 0 on success.\n **/\nstatic i40e_status i40e_add_macvlan_filter(struct i40e_hw *hw, u16 seid,\n\t\t\t\t\t   const u8 *macaddr, int *aq_err)\n{\n\tstruct i40e_aqc_add_macvlan_element_data element;\n\ti40e_status status;\n\tu16 cmd_flags = 0;\n\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\telement.queue_number = 0;\n\telement.match_method = I40E_AQC_MM_ERR_NO_RES;\n\tcmd_flags |= I40E_AQC_MACVLAN_ADD_PERFECT_MATCH;\n\telement.flags = cpu_to_le16(cmd_flags);\n\tstatus = i40e_aq_add_macvlan(hw, seid, &element, 1, NULL);\n\t*aq_err = hw->aq.asq_last_status;\n\n\treturn status;\n}\n\n/**\n * i40e_reset_ch_rings - Reset the queue contexts in a channel\n * @vsi: the VSI we want to access\n * @ch: the channel we want to access\n */\nstatic void i40e_reset_ch_rings(struct i40e_vsi *vsi, struct i40e_channel *ch)\n{\n\tstruct i40e_ring *tx_ring, *rx_ring;\n\tu16 pf_q;\n\tint i;\n\n\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\tpf_q = ch->base_queue + i;\n\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\ttx_ring->ch = NULL;\n\t\trx_ring = vsi->rx_rings[pf_q];\n\t\trx_ring->ch = NULL;\n\t}\n}\n\n/**\n * i40e_free_macvlan_channels\n * @vsi: the VSI we want to access\n *\n * This function frees the Qs of the channel VSI from\n * the stack and also deletes the channel VSIs which\n * serve as macvlans.\n */\nstatic void i40e_free_macvlan_channels(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\tint ret;\n\n\tif (list_empty(&vsi->macvlan_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tstruct i40e_vsi *parent_vsi;\n\n\t\tif (i40e_is_channel_macvlan(ch)) {\n\t\t\ti40e_reset_ch_rings(vsi, ch);\n\t\t\tclear_bit(ch->fwd->bit_no, vsi->fwd_bitmask);\n\t\t\tnetdev_unbind_sb_channel(vsi->netdev, ch->fwd->netdev);\n\t\t\tnetdev_set_sb_channel(ch->fwd->netdev, 0);\n\t\t\tkfree(ch->fwd);\n\t\t\tch->fwd = NULL;\n\t\t}\n\n\t\tlist_del(&ch->list);\n\t\tparent_vsi = ch->parent_vsi;\n\t\tif (!parent_vsi || !ch->initialized) {\n\t\t\tkfree(ch);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* remove the VSI */\n\t\tret = i40e_aq_delete_element(&vsi->back->hw, ch->seid,\n\t\t\t\t\t     NULL);\n\t\tif (ret)\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"unable to remove channel (%d) for parent VSI(%d)\\n\",\n\t\t\t\tch->seid, parent_vsi->seid);\n\t\tkfree(ch);\n\t}\n\tvsi->macvlan_cnt = 0;\n}\n\n/**\n * i40e_fwd_ring_up - bring the macvlan device up\n * @vsi: the VSI we want to access\n * @vdev: macvlan netdevice\n * @fwd: the private fwd structure\n */\nstatic int i40e_fwd_ring_up(struct i40e_vsi *vsi, struct net_device *vdev,\n\t\t\t    struct i40e_fwd_adapter *fwd)\n{\n\tint ret = 0, num_tc = 1,  i, aq_err;\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\tif (list_empty(&vsi->macvlan_list))\n\t\treturn -EINVAL;\n\n\t/* Go through the list and find an available channel */\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tif (!i40e_is_channel_macvlan(ch)) {\n\t\t\tch->fwd = fwd;\n\t\t\t/* record configuration for macvlan interface in vdev */\n\t\t\tfor (i = 0; i < num_tc; i++)\n\t\t\t\tnetdev_bind_sb_channel_queue(vsi->netdev, vdev,\n\t\t\t\t\t\t\t     i,\n\t\t\t\t\t\t\t     ch->num_queue_pairs,\n\t\t\t\t\t\t\t     ch->base_queue);\n\t\t\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\t\t\tstruct i40e_ring *tx_ring, *rx_ring;\n\t\t\t\tu16 pf_q;\n\n\t\t\t\tpf_q = ch->base_queue + i;\n\n\t\t\t\t/* Get to TX ring ptr */\n\t\t\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\t\t\ttx_ring->ch = ch;\n\n\t\t\t\t/* Get the RX ring ptr */\n\t\t\t\trx_ring = vsi->rx_rings[pf_q];\n\t\t\t\trx_ring->ch = ch;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Guarantee all rings are updated before we update the\n\t * MAC address filter.\n\t */\n\twmb();\n\n\t/* Add a mac filter */\n\tret = i40e_add_macvlan_filter(hw, ch->seid, vdev->dev_addr, &aq_err);\n\tif (ret) {\n\t\t/* if we cannot add the MAC rule then disable the offload */\n\t\tmacvlan_release_l2fw_offload(vdev);\n\t\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\t\tstruct i40e_ring *rx_ring;\n\t\t\tu16 pf_q;\n\n\t\t\tpf_q = ch->base_queue + i;\n\t\t\trx_ring = vsi->rx_rings[pf_q];\n\t\t\trx_ring->netdev = NULL;\n\t\t}\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Error adding mac filter on macvlan err %s, aq_err %s\\n\",\n\t\t\t  i40e_stat_str(hw, ret),\n\t\t\t  i40e_aq_str(hw, aq_err));\n\t\tnetdev_err(vdev, \"L2fwd offload disabled to L2 filter error\\n\");\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_setup_macvlans - create the channels which will be macvlans\n * @vsi: the VSI we want to access\n * @macvlan_cnt: no. of macvlans to be setup\n * @qcnt: no. of Qs per macvlan\n * @vdev: macvlan netdevice\n */\nstatic int i40e_setup_macvlans(struct i40e_vsi *vsi, u16 macvlan_cnt, u16 qcnt,\n\t\t\t       struct net_device *vdev)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tu16 sections, qmap, num_qps;\n\tstruct i40e_channel *ch;\n\tint i, pow, ret = 0;\n\tu8 offset = 0;\n\n\tif (vsi->type != I40E_VSI_MAIN || !macvlan_cnt)\n\t\treturn -EINVAL;\n\n\tnum_qps = vsi->num_queue_pairs - (macvlan_cnt * qcnt);\n\n\t/* find the next higher power-of-2 of num queue pairs */\n\tpow = fls(roundup_pow_of_two(num_qps) - 1);\n\n\tqmap = (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t(pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t/* Setup context bits for the main VSI */\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tctxt.seid = vsi->seid;\n\tctxt.pf_num = vsi->back->hw.pf_id;\n\tctxt.vf_num = 0;\n\tctxt.uplink_seid = vsi->uplink_seid;\n\tctxt.info = vsi->info;\n\tctxt.info.tc_mapping[0] = cpu_to_le16(qmap);\n\tctxt.info.mapping_flags |= cpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\tctxt.info.queue_mapping[0] = cpu_to_le16(vsi->base_queue);\n\tctxt.info.valid_sections |= cpu_to_le16(sections);\n\n\t/* Reconfigure RSS for main VSI with new max queue count */\n\tvsi->rss_size = max_t(u16, num_qps, qcnt);\n\tret = i40e_vsi_config_rss(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed to reconfig RSS for num_queues (%u)\\n\",\n\t\t\t vsi->rss_size);\n\t\treturn ret;\n\t}\n\tvsi->reconfig_rss = true;\n\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\"Reconfigured RSS with num_queues (%u)\\n\", vsi->rss_size);\n\tvsi->next_base_queue = num_qps;\n\tvsi->cnt_q_avail = vsi->num_queue_pairs - num_qps;\n\n\t/* Update the VSI after updating the VSI queue-mapping\n\t * information\n\t */\n\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Update vsi tc config failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(hw, ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn ret;\n\t}\n\t/* update the local VSI info with updated queue map */\n\ti40e_vsi_update_queue_map(vsi, &ctxt);\n\tvsi->info.valid_sections = 0;\n\n\t/* Create channels for macvlans */\n\tINIT_LIST_HEAD(&vsi->macvlan_list);\n\tfor (i = 0; i < macvlan_cnt; i++) {\n\t\tch = kzalloc(sizeof(*ch), GFP_KERNEL);\n\t\tif (!ch) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_free;\n\t\t}\n\t\tINIT_LIST_HEAD(&ch->list);\n\t\tch->num_queue_pairs = qcnt;\n\t\tif (!i40e_setup_channel(pf, vsi, ch)) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_free;\n\t\t}\n\t\tch->parent_vsi = vsi;\n\t\tvsi->cnt_q_avail -= ch->num_queue_pairs;\n\t\tvsi->macvlan_cnt++;\n\t\tlist_add_tail(&ch->list, &vsi->macvlan_list);\n\t}\n\n\treturn ret;\n\nerr_free:\n\tdev_info(&pf->pdev->dev, \"Failed to setup macvlans\\n\");\n\ti40e_free_macvlan_channels(vsi);\n\n\treturn ret;\n}\n\n/**\n * i40e_fwd_add - configure macvlans\n * @netdev: net device to configure\n * @vdev: macvlan netdevice\n **/\nstatic void *i40e_fwd_add(struct net_device *netdev, struct net_device *vdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tu16 q_per_macvlan = 0, macvlan_cnt = 0, vectors;\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_fwd_adapter *fwd;\n\tint avail_macvlan, ret;\n\n\tif ((pf->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\tnetdev_info(netdev, \"Macvlans are not supported when DCB is enabled\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tif ((pf->flags & I40E_FLAG_TC_MQPRIO)) {\n\t\tnetdev_info(netdev, \"Macvlans are not supported when HW TC offload is on\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tif (pf->num_lan_msix < I40E_MIN_MACVLAN_VECTORS) {\n\t\tnetdev_info(netdev, \"Not enough vectors available to support macvlans\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\t/* The macvlan device has to be a single Q device so that the\n\t * tc_to_txq field can be reused to pick the tx queue.\n\t */\n\tif (netif_is_multiqueue(vdev))\n\t\treturn ERR_PTR(-ERANGE);\n\n\tif (!vsi->macvlan_cnt) {\n\t\t/* reserve bit 0 for the pf device */\n\t\tset_bit(0, vsi->fwd_bitmask);\n\n\t\t/* Try to reserve as many queues as possible for macvlans. First\n\t\t * reserve 3/4th of max vectors, then half, then quarter and\n\t\t * calculate Qs per macvlan as you go\n\t\t */\n\t\tvectors = pf->num_lan_msix;\n\t\tif (vectors <= I40E_MAX_MACVLANS && vectors > 64) {\n\t\t\t/* allocate 4 Qs per macvlan and 32 Qs to the PF*/\n\t\t\tq_per_macvlan = 4;\n\t\t\tmacvlan_cnt = (vectors - 32) / 4;\n\t\t} else if (vectors <= 64 && vectors > 32) {\n\t\t\t/* allocate 2 Qs per macvlan and 16 Qs to the PF*/\n\t\t\tq_per_macvlan = 2;\n\t\t\tmacvlan_cnt = (vectors - 16) / 2;\n\t\t} else if (vectors <= 32 && vectors > 16) {\n\t\t\t/* allocate 1 Q per macvlan and 16 Qs to the PF*/\n\t\t\tq_per_macvlan = 1;\n\t\t\tmacvlan_cnt = vectors - 16;\n\t\t} else if (vectors <= 16 && vectors > 8) {\n\t\t\t/* allocate 1 Q per macvlan and 8 Qs to the PF */\n\t\t\tq_per_macvlan = 1;\n\t\t\tmacvlan_cnt = vectors - 8;\n\t\t} else {\n\t\t\t/* allocate 1 Q per macvlan and 1 Q to the PF */\n\t\t\tq_per_macvlan = 1;\n\t\t\tmacvlan_cnt = vectors - 1;\n\t\t}\n\n\t\tif (macvlan_cnt == 0)\n\t\t\treturn ERR_PTR(-EBUSY);\n\n\t\t/* Quiesce VSI queues */\n\t\ti40e_quiesce_vsi(vsi);\n\n\t\t/* sets up the macvlans but does not \"enable\" them */\n\t\tret = i40e_setup_macvlans(vsi, macvlan_cnt, q_per_macvlan,\n\t\t\t\t\t  vdev);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\n\t\t/* Unquiesce VSI */\n\t\ti40e_unquiesce_vsi(vsi);\n\t}\n\tavail_macvlan = find_first_zero_bit(vsi->fwd_bitmask,\n\t\t\t\t\t    vsi->macvlan_cnt);\n\tif (avail_macvlan >= I40E_MAX_MACVLANS)\n\t\treturn ERR_PTR(-EBUSY);\n\n\t/* create the fwd struct */\n\tfwd = kzalloc(sizeof(*fwd), GFP_KERNEL);\n\tif (!fwd)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tset_bit(avail_macvlan, vsi->fwd_bitmask);\n\tfwd->bit_no = avail_macvlan;\n\tnetdev_set_sb_channel(vdev, avail_macvlan);\n\tfwd->netdev = vdev;\n\n\tif (!netif_running(netdev))\n\t\treturn fwd;\n\n\t/* Set fwd ring up */\n\tret = i40e_fwd_ring_up(vsi, vdev, fwd);\n\tif (ret) {\n\t\t/* unbind the queues and drop the subordinate channel config */\n\t\tnetdev_unbind_sb_channel(netdev, vdev);\n\t\tnetdev_set_sb_channel(vdev, 0);\n\n\t\tkfree(fwd);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\treturn fwd;\n}\n\n/**\n * i40e_del_all_macvlans - Delete all the mac filters on the channels\n * @vsi: the VSI we want to access\n */\nstatic void i40e_del_all_macvlans(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint aq_err, ret = 0;\n\n\tif (list_empty(&vsi->macvlan_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tif (i40e_is_channel_macvlan(ch)) {\n\t\t\tret = i40e_del_macvlan_filter(hw, ch->seid,\n\t\t\t\t\t\t      i40e_channel_mac(ch),\n\t\t\t\t\t\t      &aq_err);\n\t\t\tif (!ret) {\n\t\t\t\t/* Reset queue contexts */\n\t\t\t\ti40e_reset_ch_rings(vsi, ch);\n\t\t\t\tclear_bit(ch->fwd->bit_no, vsi->fwd_bitmask);\n\t\t\t\tnetdev_unbind_sb_channel(vsi->netdev,\n\t\t\t\t\t\t\t ch->fwd->netdev);\n\t\t\t\tnetdev_set_sb_channel(ch->fwd->netdev, 0);\n\t\t\t\tkfree(ch->fwd);\n\t\t\t\tch->fwd = NULL;\n\t\t\t}\n\t\t}\n\t}\n}\n\n/**\n * i40e_fwd_del - delete macvlan interfaces\n * @netdev: net device to configure\n * @vdev: macvlan netdevice\n */\nstatic void i40e_fwd_del(struct net_device *netdev, void *vdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_fwd_adapter *fwd = vdev;\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint aq_err, ret = 0;\n\n\t/* Find the channel associated with the macvlan and del mac filter */\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tif (i40e_is_channel_macvlan(ch) &&\n\t\t    ether_addr_equal(i40e_channel_mac(ch),\n\t\t\t\t     fwd->netdev->dev_addr)) {\n\t\t\tret = i40e_del_macvlan_filter(hw, ch->seid,\n\t\t\t\t\t\t      i40e_channel_mac(ch),\n\t\t\t\t\t\t      &aq_err);\n\t\t\tif (!ret) {\n\t\t\t\t/* Reset queue contexts */\n\t\t\t\ti40e_reset_ch_rings(vsi, ch);\n\t\t\t\tclear_bit(ch->fwd->bit_no, vsi->fwd_bitmask);\n\t\t\t\tnetdev_unbind_sb_channel(netdev, fwd->netdev);\n\t\t\t\tnetdev_set_sb_channel(fwd->netdev, 0);\n\t\t\t\tkfree(ch->fwd);\n\t\t\t\tch->fwd = NULL;\n\t\t\t} else {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"Error deleting mac filter on macvlan err %s, aq_err %s\\n\",\n\t\t\t\t\t  i40e_stat_str(hw, ret),\n\t\t\t\t\t  i40e_aq_str(hw, aq_err));\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n/**\n * i40e_setup_tc - configure multiple traffic classes\n * @netdev: net device to configure\n * @type_data: tc offload data\n **/\nstatic int i40e_setup_tc(struct net_device *netdev, void *type_data)\n{\n\tstruct tc_mqprio_qopt_offload *mqprio_qopt = type_data;\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 enabled_tc = 0, num_tc, hw;\n\tbool need_reset = false;\n\tint old_queue_pairs;\n\tint ret = -EINVAL;\n\tu16 mode;\n\tint i;\n\n\told_queue_pairs = vsi->num_queue_pairs;\n\tnum_tc = mqprio_qopt->qopt.num_tc;\n\thw = mqprio_qopt->qopt.hw;\n\tmode = mqprio_qopt->mode;\n\tif (!hw) {\n\t\tpf->flags &= ~I40E_FLAG_TC_MQPRIO;\n\t\tmemcpy(&vsi->mqprio_qopt, mqprio_qopt, sizeof(*mqprio_qopt));\n\t\tgoto config_tc;\n\t}\n\n\t/* Check if MFP enabled */\n\tif (pf->flags & I40E_FLAG_MFP_ENABLED) {\n\t\tnetdev_info(netdev,\n\t\t\t    \"Configuring TC not supported in MFP mode\\n\");\n\t\treturn ret;\n\t}\n\tswitch (mode) {\n\tcase TC_MQPRIO_MODE_DCB:\n\t\tpf->flags &= ~I40E_FLAG_TC_MQPRIO;\n\n\t\t/* Check if DCB enabled to continue */\n\t\tif (!(pf->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"DCB is not enabled for adapter\\n\");\n\t\t\treturn ret;\n\t\t}\n\n\t\t/* Check whether tc count is within enabled limit */\n\t\tif (num_tc > i40e_pf_get_num_tc(pf)) {\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"TC count greater than enabled on link for adapter\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tbreak;\n\tcase TC_MQPRIO_MODE_CHANNEL:\n\t\tif (pf->flags & I40E_FLAG_DCB_ENABLED) {\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"Full offload of TC Mqprio options is not supported when DCB is enabled\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\t\treturn ret;\n\t\tret = i40e_validate_mqprio_qopt(vsi, mqprio_qopt);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tmemcpy(&vsi->mqprio_qopt, mqprio_qopt,\n\t\t       sizeof(*mqprio_qopt));\n\t\tpf->flags |= I40E_FLAG_TC_MQPRIO;\n\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\nconfig_tc:\n\t/* Generate TC map for number of tc requested */\n\tfor (i = 0; i < num_tc; i++)\n\t\tenabled_tc |= BIT(i);\n\n\t/* Requesting same TC configuration as already enabled */\n\tif (enabled_tc == vsi->tc_config.enabled_tc &&\n\t    mode != TC_MQPRIO_MODE_CHANNEL)\n\t\treturn 0;\n\n\t/* Quiesce VSI queues */\n\ti40e_quiesce_vsi(vsi);\n\n\tif (!hw && !(pf->flags & I40E_FLAG_TC_MQPRIO))\n\t\ti40e_remove_queue_channels(vsi);\n\n\t/* Configure VSI for enabled TCs */\n\tret = i40e_vsi_config_tc(vsi, enabled_tc);\n\tif (ret) {\n\t\tnetdev_info(netdev, \"Failed configuring TC for VSI seid=%d\\n\",\n\t\t\t    vsi->seid);\n\t\tneed_reset = true;\n\t\tgoto exit;\n\t} else {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Setup channel (id:%u) utilizing num_queues %d\\n\",\n\t\t\t vsi->seid, vsi->tc_config.tc_info[0].qcount);\n\t}\n\n\tif (pf->flags & I40E_FLAG_TC_MQPRIO) {\n\t\tif (vsi->mqprio_qopt.max_rate[0]) {\n\t\t\tu64 max_tx_rate = vsi->mqprio_qopt.max_rate[0];\n\n\t\t\tdo_div(max_tx_rate, I40E_BW_MBPS_DIVISOR);\n\t\t\tret = i40e_set_bw_limit(vsi, vsi->seid, max_tx_rate);\n\t\t\tif (!ret) {\n\t\t\t\tu64 credits = max_tx_rate;\n\n\t\t\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\t\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\t\t\tmax_tx_rate,\n\t\t\t\t\tcredits,\n\t\t\t\t\tvsi->seid);\n\t\t\t} else {\n\t\t\t\tneed_reset = true;\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tret = i40e_configure_queue_channels(vsi);\n\t\tif (ret) {\n\t\t\tvsi->num_queue_pairs = old_queue_pairs;\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"Failed configuring queue channels\\n\");\n\t\t\tneed_reset = true;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\nexit:\n\t/* Reset the configuration data to defaults, only TC0 is enabled */\n\tif (need_reset) {\n\t\ti40e_vsi_set_default_tc_config(vsi);\n\t\tneed_reset = false;\n\t}\n\n\t/* Unquiesce VSI */\n\ti40e_unquiesce_vsi(vsi);\n\treturn ret;\n}\n\n/**\n * i40e_set_cld_element - sets cloud filter element data\n * @filter: cloud filter rule\n * @cld: ptr to cloud filter element data\n *\n * This is helper function to copy data into cloud filter element\n **/\nstatic inline void\ni40e_set_cld_element(struct i40e_cloud_filter *filter,\n\t\t     struct i40e_aqc_cloud_filters_element_data *cld)\n{\n\tint i, j;\n\tu32 ipa;\n\n\tmemset(cld, 0, sizeof(*cld));\n\tether_addr_copy(cld->outer_mac, filter->dst_mac);\n\tether_addr_copy(cld->inner_mac, filter->src_mac);\n\n\tif (filter->n_proto != ETH_P_IP && filter->n_proto != ETH_P_IPV6)\n\t\treturn;\n\n\tif (filter->n_proto == ETH_P_IPV6) {\n#define IPV6_MAX_INDEX\t(ARRAY_SIZE(filter->dst_ipv6) - 1)\n\t\tfor (i = 0, j = 0; i < ARRAY_SIZE(filter->dst_ipv6);\n\t\t     i++, j += 2) {\n\t\t\tipa = be32_to_cpu(filter->dst_ipv6[IPV6_MAX_INDEX - i]);\n\t\t\tipa = cpu_to_le32(ipa);\n\t\t\tmemcpy(&cld->ipaddr.raw_v6.data[j], &ipa, sizeof(ipa));\n\t\t}\n\t} else {\n\t\tipa = be32_to_cpu(filter->dst_ipv4);\n\t\tmemcpy(&cld->ipaddr.v4.data, &ipa, sizeof(ipa));\n\t}\n\n\tcld->inner_vlan = cpu_to_le16(ntohs(filter->vlan_id));\n\n\t/* tenant_id is not supported by FW now, once the support is enabled\n\t * fill the cld->tenant_id with cpu_to_le32(filter->tenant_id)\n\t */\n\tif (filter->tenant_id)\n\t\treturn;\n}\n\n/**\n * i40e_add_del_cloud_filter - Add/del cloud filter\n * @vsi: pointer to VSI\n * @filter: cloud filter rule\n * @add: if true, add, if false, delete\n *\n * Add or delete a cloud filter for a specific flow spec.\n * Returns 0 if the filter were successfully added.\n **/\nint i40e_add_del_cloud_filter(struct i40e_vsi *vsi,\n\t\t\t      struct i40e_cloud_filter *filter, bool add)\n{\n\tstruct i40e_aqc_cloud_filters_element_data cld_filter;\n\tstruct i40e_pf *pf = vsi->back;\n\tint ret;\n\tstatic const u16 flag_table[128] = {\n\t\t[I40E_CLOUD_FILTER_FLAGS_OMAC]  =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_OMAC,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC]  =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC_IVLAN]  =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC_IVLAN,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC_TEN_ID] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC_TEN_ID,\n\t\t[I40E_CLOUD_FILTER_FLAGS_OMAC_TEN_ID_IMAC] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_OMAC_TEN_ID_IMAC,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC_IVLAN_TEN_ID] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC_IVLAN_TEN_ID,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IIP] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IIP,\n\t};\n\n\tif (filter->flags >= ARRAY_SIZE(flag_table))\n\t\treturn I40E_ERR_CONFIG;\n\n\t/* copy element needed to add cloud filter from filter */\n\ti40e_set_cld_element(filter, &cld_filter);\n\n\tif (filter->tunnel_type != I40E_CLOUD_TNL_TYPE_NONE)\n\t\tcld_filter.flags = cpu_to_le16(filter->tunnel_type <<\n\t\t\t\t\t     I40E_AQC_ADD_CLOUD_TNL_TYPE_SHIFT);\n\n\tif (filter->n_proto == ETH_P_IPV6)\n\t\tcld_filter.flags |= cpu_to_le16(flag_table[filter->flags] |\n\t\t\t\t\t\tI40E_AQC_ADD_CLOUD_FLAGS_IPV6);\n\telse\n\t\tcld_filter.flags |= cpu_to_le16(flag_table[filter->flags] |\n\t\t\t\t\t\tI40E_AQC_ADD_CLOUD_FLAGS_IPV4);\n\n\tif (add)\n\t\tret = i40e_aq_add_cloud_filters(&pf->hw, filter->seid,\n\t\t\t\t\t\t&cld_filter, 1);\n\telse\n\t\tret = i40e_aq_rem_cloud_filters(&pf->hw, filter->seid,\n\t\t\t\t\t\t&cld_filter, 1);\n\tif (ret)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Failed to %s cloud filter using l4 port %u, err %d aq_err %d\\n\",\n\t\t\tadd ? \"add\" : \"delete\", filter->dst_port, ret,\n\t\t\tpf->hw.aq.asq_last_status);\n\telse\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"%s cloud filter for VSI: %d\\n\",\n\t\t\t add ? \"Added\" : \"Deleted\", filter->seid);\n\treturn ret;\n}\n\n/**\n * i40e_add_del_cloud_filter_big_buf - Add/del cloud filter using big_buf\n * @vsi: pointer to VSI\n * @filter: cloud filter rule\n * @add: if true, add, if false, delete\n *\n * Add or delete a cloud filter for a specific flow spec using big buffer.\n * Returns 0 if the filter were successfully added.\n **/\nint i40e_add_del_cloud_filter_big_buf(struct i40e_vsi *vsi,\n\t\t\t\t      struct i40e_cloud_filter *filter,\n\t\t\t\t      bool add)\n{\n\tstruct i40e_aqc_cloud_filters_element_bb cld_filter;\n\tstruct i40e_pf *pf = vsi->back;\n\tint ret;\n\n\t/* Both (src/dst) valid mac_addr are not supported */\n\tif ((is_valid_ether_addr(filter->dst_mac) &&\n\t     is_valid_ether_addr(filter->src_mac)) ||\n\t    (is_multicast_ether_addr(filter->dst_mac) &&\n\t     is_multicast_ether_addr(filter->src_mac)))\n\t\treturn -EOPNOTSUPP;\n\n\t/* Big buffer cloud filter needs 'L4 port' to be non-zero. Also, UDP\n\t * ports are not supported via big buffer now.\n\t */\n\tif (!filter->dst_port || filter->ip_proto == IPPROTO_UDP)\n\t\treturn -EOPNOTSUPP;\n\n\t/* adding filter using src_port/src_ip is not supported at this stage */\n\tif (filter->src_port || filter->src_ipv4 ||\n\t    !ipv6_addr_any(&filter->ip.v6.src_ip6))\n\t\treturn -EOPNOTSUPP;\n\n\t/* copy element needed to add cloud filter from filter */\n\ti40e_set_cld_element(filter, &cld_filter.element);\n\n\tif (is_valid_ether_addr(filter->dst_mac) ||\n\t    is_valid_ether_addr(filter->src_mac) ||\n\t    is_multicast_ether_addr(filter->dst_mac) ||\n\t    is_multicast_ether_addr(filter->src_mac)) {\n\t\t/* MAC + IP : unsupported mode */\n\t\tif (filter->dst_ipv4)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\t/* since we validated that L4 port must be valid before\n\t\t * we get here, start with respective \"flags\" value\n\t\t * and update if vlan is present or not\n\t\t */\n\t\tcld_filter.element.flags =\n\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FILTER_MAC_PORT);\n\n\t\tif (filter->vlan_id) {\n\t\t\tcld_filter.element.flags =\n\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FILTER_MAC_VLAN_PORT);\n\t\t}\n\n\t} else if (filter->dst_ipv4 ||\n\t\t   !ipv6_addr_any(&filter->ip.v6.dst_ip6)) {\n\t\tcld_filter.element.flags =\n\t\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FILTER_IP_PORT);\n\t\tif (filter->n_proto == ETH_P_IPV6)\n\t\t\tcld_filter.element.flags |=\n\t\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FLAGS_IPV6);\n\t\telse\n\t\t\tcld_filter.element.flags |=\n\t\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FLAGS_IPV4);\n\t} else {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"either mac or ip has to be valid for cloud filter\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Now copy L4 port in Byte 6..7 in general fields */\n\tcld_filter.general_fields[I40E_AQC_ADD_CLOUD_FV_FLU_0X16_WORD0] =\n\t\t\t\t\t\tbe16_to_cpu(filter->dst_port);\n\n\tif (add) {\n\t\t/* Validate current device switch mode, change if necessary */\n\t\tret = i40e_validate_and_set_switch_mode(vsi);\n\t\tif (ret) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"failed to set switch mode, ret %d\\n\",\n\t\t\t\tret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = i40e_aq_add_cloud_filters_bb(&pf->hw, filter->seid,\n\t\t\t\t\t\t   &cld_filter, 1);\n\t} else {\n\t\tret = i40e_aq_rem_cloud_filters_bb(&pf->hw, filter->seid,\n\t\t\t\t\t\t   &cld_filter, 1);\n\t}\n\n\tif (ret)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Failed to %s cloud filter(big buffer) err %d aq_err %d\\n\",\n\t\t\tadd ? \"add\" : \"delete\", ret, pf->hw.aq.asq_last_status);\n\telse\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"%s cloud filter for VSI: %d, L4 port: %d\\n\",\n\t\t\t add ? \"add\" : \"delete\", filter->seid,\n\t\t\t ntohs(filter->dst_port));\n\treturn ret;\n}\n\n/**\n * i40e_parse_cls_flower - Parse tc flower filters provided by kernel\n * @vsi: Pointer to VSI\n * @cls_flower: Pointer to struct flow_cls_offload\n * @filter: Pointer to cloud filter structure\n *\n **/\nstatic int i40e_parse_cls_flower(struct i40e_vsi *vsi,\n\t\t\t\t struct flow_cls_offload *f,\n\t\t\t\t struct i40e_cloud_filter *filter)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(f);\n\tstruct flow_dissector *dissector = rule->match.dissector;\n\tu16 n_proto_mask = 0, n_proto_key = 0, addr_type = 0;\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 field_flags = 0;\n\n\tif (dissector->used_keys &\n\t    ~(BIT(FLOW_DISSECTOR_KEY_CONTROL) |\n\t      BIT(FLOW_DISSECTOR_KEY_BASIC) |\n\t      BIT(FLOW_DISSECTOR_KEY_ETH_ADDRS) |\n\t      BIT(FLOW_DISSECTOR_KEY_VLAN) |\n\t      BIT(FLOW_DISSECTOR_KEY_IPV4_ADDRS) |\n\t      BIT(FLOW_DISSECTOR_KEY_IPV6_ADDRS) |\n\t      BIT(FLOW_DISSECTOR_KEY_PORTS) |\n\t      BIT(FLOW_DISSECTOR_KEY_ENC_KEYID))) {\n\t\tdev_err(&pf->pdev->dev, \"Unsupported key used: 0x%x\\n\",\n\t\t\tdissector->used_keys);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ENC_KEYID)) {\n\t\tstruct flow_match_enc_keyid match;\n\n\t\tflow_rule_match_enc_keyid(rule, &match);\n\t\tif (match.mask->keyid != 0)\n\t\t\tfield_flags |= I40E_CLOUD_FIELD_TEN_ID;\n\n\t\tfilter->tenant_id = be32_to_cpu(match.key->keyid);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_BASIC)) {\n\t\tstruct flow_match_basic match;\n\n\t\tflow_rule_match_basic(rule, &match);\n\t\tn_proto_key = ntohs(match.key->n_proto);\n\t\tn_proto_mask = ntohs(match.mask->n_proto);\n\n\t\tif (n_proto_key == ETH_P_ALL) {\n\t\t\tn_proto_key = 0;\n\t\t\tn_proto_mask = 0;\n\t\t}\n\t\tfilter->n_proto = n_proto_key & n_proto_mask;\n\t\tfilter->ip_proto = match.key->ip_proto;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tstruct flow_match_eth_addrs match;\n\n\t\tflow_rule_match_eth_addrs(rule, &match);\n\n\t\t/* use is_broadcast and is_zero to check for all 0xf or 0 */\n\t\tif (!is_zero_ether_addr(match.mask->dst)) {\n\t\t\tif (is_broadcast_ether_addr(match.mask->dst)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_OMAC;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ether dest mask %pM\\n\",\n\t\t\t\t\tmatch.mask->dst);\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tif (!is_zero_ether_addr(match.mask->src)) {\n\t\t\tif (is_broadcast_ether_addr(match.mask->src)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IMAC;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ether src mask %pM\\n\",\n\t\t\t\t\tmatch.mask->src);\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\t\tether_addr_copy(filter->dst_mac, match.key->dst);\n\t\tether_addr_copy(filter->src_mac, match.key->src);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_VLAN)) {\n\t\tstruct flow_match_vlan match;\n\n\t\tflow_rule_match_vlan(rule, &match);\n\t\tif (match.mask->vlan_id) {\n\t\t\tif (match.mask->vlan_id == VLAN_VID_MASK) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IVLAN;\n\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad vlan mask 0x%04x\\n\",\n\t\t\t\t\tmatch.mask->vlan_id);\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tfilter->vlan_id = cpu_to_be16(match.key->vlan_id);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_CONTROL)) {\n\t\tstruct flow_match_control match;\n\n\t\tflow_rule_match_control(rule, &match);\n\t\taddr_type = match.key->addr_type;\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {\n\t\tstruct flow_match_ipv4_addrs match;\n\n\t\tflow_rule_match_ipv4_addrs(rule, &match);\n\t\tif (match.mask->dst) {\n\t\t\tif (match.mask->dst == cpu_to_be32(0xffffffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ip dst mask %pI4b\\n\",\n\t\t\t\t\t&match.mask->dst);\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tif (match.mask->src) {\n\t\t\tif (match.mask->src == cpu_to_be32(0xffffffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ip src mask %pI4b\\n\",\n\t\t\t\t\t&match.mask->src);\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tif (field_flags & I40E_CLOUD_FIELD_TEN_ID) {\n\t\t\tdev_err(&pf->pdev->dev, \"Tenant id not allowed for ip filter\\n\");\n\t\t\treturn I40E_ERR_CONFIG;\n\t\t}\n\t\tfilter->dst_ipv4 = match.key->dst;\n\t\tfilter->src_ipv4 = match.key->src;\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV6_ADDRS) {\n\t\tstruct flow_match_ipv6_addrs match;\n\n\t\tflow_rule_match_ipv6_addrs(rule, &match);\n\n\t\t/* src and dest IPV6 address should not be LOOPBACK\n\t\t * (0:0:0:0:0:0:0:1), which can be represented as ::1\n\t\t */\n\t\tif (ipv6_addr_loopback(&match.key->dst) ||\n\t\t    ipv6_addr_loopback(&match.key->src)) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Bad ipv6, addr is LOOPBACK\\n\");\n\t\t\treturn I40E_ERR_CONFIG;\n\t\t}\n\t\tif (!ipv6_addr_any(&match.mask->dst) ||\n\t\t    !ipv6_addr_any(&match.mask->src))\n\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\n\t\tmemcpy(&filter->src_ipv6, &match.key->src.s6_addr32,\n\t\t       sizeof(filter->src_ipv6));\n\t\tmemcpy(&filter->dst_ipv6, &match.key->dst.s6_addr32,\n\t\t       sizeof(filter->dst_ipv6));\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS)) {\n\t\tstruct flow_match_ports match;\n\n\t\tflow_rule_match_ports(rule, &match);\n\t\tif (match.mask->src) {\n\t\t\tif (match.mask->src == cpu_to_be16(0xffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad src port mask 0x%04x\\n\",\n\t\t\t\t\tbe16_to_cpu(match.mask->src));\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tif (match.mask->dst) {\n\t\t\tif (match.mask->dst == cpu_to_be16(0xffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad dst port mask 0x%04x\\n\",\n\t\t\t\t\tbe16_to_cpu(match.mask->dst));\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tfilter->dst_port = match.key->dst;\n\t\tfilter->src_port = match.key->src;\n\n\t\tswitch (filter->ip_proto) {\n\t\tcase IPPROTO_TCP:\n\t\tcase IPPROTO_UDP:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Only UDP and TCP transport are supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tfilter->flags = field_flags;\n\treturn 0;\n}\n\n/**\n * i40e_handle_tclass: Forward to a traffic class on the device\n * @vsi: Pointer to VSI\n * @tc: traffic class index on the device\n * @filter: Pointer to cloud filter structure\n *\n **/\nstatic int i40e_handle_tclass(struct i40e_vsi *vsi, u32 tc,\n\t\t\t      struct i40e_cloud_filter *filter)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\n\t/* direct to a traffic class on the same device */\n\tif (tc == 0) {\n\t\tfilter->seid = vsi->seid;\n\t\treturn 0;\n\t} else if (vsi->tc_config.enabled_tc & BIT(tc)) {\n\t\tif (!filter->dst_port) {\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"Specify destination port to direct to traffic class that is not default\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (list_empty(&vsi->ch_list))\n\t\t\treturn -EINVAL;\n\t\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list,\n\t\t\t\t\t list) {\n\t\t\tif (ch->seid == vsi->tc_seid_map[tc])\n\t\t\t\tfilter->seid = ch->seid;\n\t\t}\n\t\treturn 0;\n\t}\n\tdev_err(&vsi->back->pdev->dev, \"TC is not enabled\\n\");\n\treturn -EINVAL;\n}\n\n/**\n * i40e_configure_clsflower - Configure tc flower filters\n * @vsi: Pointer to VSI\n * @cls_flower: Pointer to struct flow_cls_offload\n *\n **/\nstatic int i40e_configure_clsflower(struct i40e_vsi *vsi,\n\t\t\t\t    struct flow_cls_offload *cls_flower)\n{\n\tint tc = tc_classid_to_hwtc(vsi->netdev, cls_flower->classid);\n\tstruct i40e_cloud_filter *filter = NULL;\n\tstruct i40e_pf *pf = vsi->back;\n\tint err = 0;\n\n\tif (tc < 0) {\n\t\tdev_err(&vsi->back->pdev->dev, \"Invalid traffic class\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state) ||\n\t    test_bit(__I40E_RESET_INTR_RECEIVED, pf->state))\n\t\treturn -EBUSY;\n\n\tif (pf->fdir_pf_active_filters ||\n\t    (!hlist_empty(&pf->fdir_filter_list))) {\n\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\"Flow Director Sideband filters exists, turn ntuple off to configure cloud filters\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (vsi->back->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\"Disable Flow Director Sideband, configuring Cloud filters via tc-flower\\n\");\n\t\tvsi->back->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\tvsi->back->flags |= I40E_FLAG_FD_SB_TO_CLOUD_FILTER;\n\t}\n\n\tfilter = kzalloc(sizeof(*filter), GFP_KERNEL);\n\tif (!filter)\n\t\treturn -ENOMEM;\n\n\tfilter->cookie = cls_flower->cookie;\n\n\terr = i40e_parse_cls_flower(vsi, cls_flower, filter);\n\tif (err < 0)\n\t\tgoto err;\n\n\terr = i40e_handle_tclass(vsi, tc, filter);\n\tif (err < 0)\n\t\tgoto err;\n\n\t/* Add cloud filter */\n\tif (filter->dst_port)\n\t\terr = i40e_add_del_cloud_filter_big_buf(vsi, filter, true);\n\telse\n\t\terr = i40e_add_del_cloud_filter(vsi, filter, true);\n\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to add cloud filter, err %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, err));\n\t\tgoto err;\n\t}\n\n\t/* add filter to the ordered list */\n\tINIT_HLIST_NODE(&filter->cloud_node);\n\n\thlist_add_head(&filter->cloud_node, &pf->cloud_filter_list);\n\n\tpf->num_cloud_filters++;\n\n\treturn err;\nerr:\n\tkfree(filter);\n\treturn err;\n}\n\n/**\n * i40e_find_cloud_filter - Find the could filter in the list\n * @vsi: Pointer to VSI\n * @cookie: filter specific cookie\n *\n **/\nstatic struct i40e_cloud_filter *i40e_find_cloud_filter(struct i40e_vsi *vsi,\n\t\t\t\t\t\t\tunsigned long *cookie)\n{\n\tstruct i40e_cloud_filter *filter = NULL;\n\tstruct hlist_node *node2;\n\n\thlist_for_each_entry_safe(filter, node2,\n\t\t\t\t  &vsi->back->cloud_filter_list, cloud_node)\n\t\tif (!memcmp(cookie, &filter->cookie, sizeof(filter->cookie)))\n\t\t\treturn filter;\n\treturn NULL;\n}\n\n/**\n * i40e_delete_clsflower - Remove tc flower filters\n * @vsi: Pointer to VSI\n * @cls_flower: Pointer to struct flow_cls_offload\n *\n **/\nstatic int i40e_delete_clsflower(struct i40e_vsi *vsi,\n\t\t\t\t struct flow_cls_offload *cls_flower)\n{\n\tstruct i40e_cloud_filter *filter = NULL;\n\tstruct i40e_pf *pf = vsi->back;\n\tint err = 0;\n\n\tfilter = i40e_find_cloud_filter(vsi, &cls_flower->cookie);\n\n\tif (!filter)\n\t\treturn -EINVAL;\n\n\thash_del(&filter->cloud_node);\n\n\tif (filter->dst_port)\n\t\terr = i40e_add_del_cloud_filter_big_buf(vsi, filter, false);\n\telse\n\t\terr = i40e_add_del_cloud_filter(vsi, filter, false);\n\n\tkfree(filter);\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to delete cloud filter, err %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, err));\n\t\treturn i40e_aq_rc_to_posix(err, pf->hw.aq.asq_last_status);\n\t}\n\n\tpf->num_cloud_filters--;\n\tif (!pf->num_cloud_filters)\n\t\tif ((pf->flags & I40E_FLAG_FD_SB_TO_CLOUD_FILTER) &&\n\t\t    !(pf->flags & I40E_FLAG_FD_SB_INACTIVE)) {\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_TO_CLOUD_FILTER;\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_INACTIVE;\n\t\t}\n\treturn 0;\n}\n\n/**\n * i40e_setup_tc_cls_flower - flower classifier offloads\n * @netdev: net device to configure\n * @type_data: offload data\n **/\nstatic int i40e_setup_tc_cls_flower(struct i40e_netdev_priv *np,\n\t\t\t\t    struct flow_cls_offload *cls_flower)\n{\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tswitch (cls_flower->command) {\n\tcase FLOW_CLS_REPLACE:\n\t\treturn i40e_configure_clsflower(vsi, cls_flower);\n\tcase FLOW_CLS_DESTROY:\n\t\treturn i40e_delete_clsflower(vsi, cls_flower);\n\tcase FLOW_CLS_STATS:\n\t\treturn -EOPNOTSUPP;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int i40e_setup_tc_block_cb(enum tc_setup_type type, void *type_data,\n\t\t\t\t  void *cb_priv)\n{\n\tstruct i40e_netdev_priv *np = cb_priv;\n\n\tif (!tc_cls_can_offload_and_chain0(np->vsi->netdev, type_data))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (type) {\n\tcase TC_SETUP_CLSFLOWER:\n\t\treturn i40e_setup_tc_cls_flower(np, type_data);\n\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic LIST_HEAD(i40e_block_cb_list);\n\nstatic int __i40e_setup_tc(struct net_device *netdev, enum tc_setup_type type,\n\t\t\t   void *type_data)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\n\tswitch (type) {\n\tcase TC_SETUP_QDISC_MQPRIO:\n\t\treturn i40e_setup_tc(netdev, type_data);\n\tcase TC_SETUP_BLOCK:\n\t\treturn flow_block_cb_setup_simple(type_data,\n\t\t\t\t\t\t  &i40e_block_cb_list,\n\t\t\t\t\t\t  i40e_setup_tc_block_cb,\n\t\t\t\t\t\t  np, np, true);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n/**\n * i40e_open - Called when a network interface is made active\n * @netdev: network interface device structure\n *\n * The open entry point is called when a network interface is made\n * active by the system (IFF_UP).  At this point all resources needed\n * for transmit and receive operations are allocated, the interrupt\n * handler is registered with the OS, the netdev watchdog subtask is\n * enabled, and the stack is notified that the interface is ready.\n *\n * Returns 0 on success, negative value on failure\n **/\nint i40e_open(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tint err;\n\n\t/* disallow open during test or if eeprom is broken */\n\tif (test_bit(__I40E_TESTING, pf->state) ||\n\t    test_bit(__I40E_BAD_EEPROM, pf->state))\n\t\treturn -EBUSY;\n\n\tnetif_carrier_off(netdev);\n\n\tif (i40e_force_link_state(pf, true))\n\t\treturn -EAGAIN;\n\n\terr = i40e_vsi_open(vsi);\n\tif (err)\n\t\treturn err;\n\n\t/* configure global TSO hardware offload settings */\n\twr32(&pf->hw, I40E_GLLAN_TSOMSK_F, be32_to_cpu(TCP_FLAG_PSH |\n\t\t\t\t\t\t       TCP_FLAG_FIN) >> 16);\n\twr32(&pf->hw, I40E_GLLAN_TSOMSK_M, be32_to_cpu(TCP_FLAG_PSH |\n\t\t\t\t\t\t       TCP_FLAG_FIN |\n\t\t\t\t\t\t       TCP_FLAG_CWR) >> 16);\n\twr32(&pf->hw, I40E_GLLAN_TSOMSK_L, be32_to_cpu(TCP_FLAG_CWR) >> 16);\n\n\tudp_tunnel_get_rx_info(netdev);\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_open -\n * @vsi: the VSI to open\n *\n * Finish initialization of the VSI.\n *\n * Returns 0 on success, negative value on failure\n *\n * Note: expects to be called while under rtnl_lock()\n **/\nint i40e_vsi_open(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tchar int_name[I40E_INT_NAME_STR_LEN];\n\tint err;\n\n\t/* allocate descriptors */\n\terr = i40e_vsi_setup_tx_resources(vsi);\n\tif (err)\n\t\tgoto err_setup_tx;\n\terr = i40e_vsi_setup_rx_resources(vsi);\n\tif (err)\n\t\tgoto err_setup_rx;\n\n\terr = i40e_vsi_configure(vsi);\n\tif (err)\n\t\tgoto err_setup_rx;\n\n\tif (vsi->netdev) {\n\t\tsnprintf(int_name, sizeof(int_name) - 1, \"%s-%s\",\n\t\t\t dev_driver_string(&pf->pdev->dev), vsi->netdev->name);\n\t\terr = i40e_vsi_request_irq(vsi, int_name);\n\t\tif (err)\n\t\t\tgoto err_setup_rx;\n\n\t\t/* Notify the stack of the actual queue counts. */\n\t\terr = netif_set_real_num_tx_queues(vsi->netdev,\n\t\t\t\t\t\t   vsi->num_queue_pairs);\n\t\tif (err)\n\t\t\tgoto err_set_queues;\n\n\t\terr = netif_set_real_num_rx_queues(vsi->netdev,\n\t\t\t\t\t\t   vsi->num_queue_pairs);\n\t\tif (err)\n\t\t\tgoto err_set_queues;\n\n\t} else if (vsi->type == I40E_VSI_FDIR) {\n\t\tsnprintf(int_name, sizeof(int_name) - 1, \"%s-%s:fdir\",\n\t\t\t dev_driver_string(&pf->pdev->dev),\n\t\t\t dev_name(&pf->pdev->dev));\n\t\terr = i40e_vsi_request_irq(vsi, int_name);\n\n\t} else {\n\t\terr = -EINVAL;\n\t\tgoto err_setup_rx;\n\t}\n\n\terr = i40e_up_complete(vsi);\n\tif (err)\n\t\tgoto err_up_complete;\n\n\treturn 0;\n\nerr_up_complete:\n\ti40e_down(vsi);\nerr_set_queues:\n\ti40e_vsi_free_irq(vsi);\nerr_setup_rx:\n\ti40e_vsi_free_rx_resources(vsi);\nerr_setup_tx:\n\ti40e_vsi_free_tx_resources(vsi);\n\tif (vsi == pf->vsi[pf->lan_vsi])\n\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG, true);\n\n\treturn err;\n}\n\n/**\n * i40e_fdir_filter_exit - Cleans up the Flow Director accounting\n * @pf: Pointer to PF\n *\n * This function destroys the hlist where all the Flow Director\n * filters were saved.\n **/\nstatic void i40e_fdir_filter_exit(struct i40e_pf *pf)\n{\n\tstruct i40e_fdir_filter *filter;\n\tstruct i40e_flex_pit *pit_entry, *tmp;\n\tstruct hlist_node *node2;\n\n\thlist_for_each_entry_safe(filter, node2,\n\t\t\t\t  &pf->fdir_filter_list, fdir_node) {\n\t\thlist_del(&filter->fdir_node);\n\t\tkfree(filter);\n\t}\n\n\tlist_for_each_entry_safe(pit_entry, tmp, &pf->l3_flex_pit_list, list) {\n\t\tlist_del(&pit_entry->list);\n\t\tkfree(pit_entry);\n\t}\n\tINIT_LIST_HEAD(&pf->l3_flex_pit_list);\n\n\tlist_for_each_entry_safe(pit_entry, tmp, &pf->l4_flex_pit_list, list) {\n\t\tlist_del(&pit_entry->list);\n\t\tkfree(pit_entry);\n\t}\n\tINIT_LIST_HEAD(&pf->l4_flex_pit_list);\n\n\tpf->fdir_pf_active_filters = 0;\n\tpf->fd_tcp4_filter_cnt = 0;\n\tpf->fd_udp4_filter_cnt = 0;\n\tpf->fd_sctp4_filter_cnt = 0;\n\tpf->fd_ip4_filter_cnt = 0;\n\n\t/* Reprogram the default input set for TCP/IPv4 */\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_TCP,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t/* Reprogram the default input set for UDP/IPv4 */\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_UDP,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t/* Reprogram the default input set for SCTP/IPv4 */\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_SCTP,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t/* Reprogram the default input set for Other/IPv4 */\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_OTHER,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK);\n\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_FRAG_IPV4,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK);\n}\n\n/**\n * i40e_cloud_filter_exit - Cleans up the cloud filters\n * @pf: Pointer to PF\n *\n * This function destroys the hlist where all the cloud filters\n * were saved.\n **/\nstatic void i40e_cloud_filter_exit(struct i40e_pf *pf)\n{\n\tstruct i40e_cloud_filter *cfilter;\n\tstruct hlist_node *node;\n\n\thlist_for_each_entry_safe(cfilter, node,\n\t\t\t\t  &pf->cloud_filter_list, cloud_node) {\n\t\thlist_del(&cfilter->cloud_node);\n\t\tkfree(cfilter);\n\t}\n\tpf->num_cloud_filters = 0;\n\n\tif ((pf->flags & I40E_FLAG_FD_SB_TO_CLOUD_FILTER) &&\n\t    !(pf->flags & I40E_FLAG_FD_SB_INACTIVE)) {\n\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_TO_CLOUD_FILTER;\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_INACTIVE;\n\t}\n}\n\n/**\n * i40e_close - Disables a network interface\n * @netdev: network interface device structure\n *\n * The close entry point is called when an interface is de-activated\n * by the OS.  The hardware is still under the driver's control, but\n * this netdev interface is disabled.\n *\n * Returns 0, this is not allowed to fail\n **/\nint i40e_close(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\ti40e_vsi_close(vsi);\n\n\treturn 0;\n}\n\n/**\n * i40e_do_reset - Start a PF or Core Reset sequence\n * @pf: board private structure\n * @reset_flags: which reset is requested\n * @lock_acquired: indicates whether or not the lock has been acquired\n * before this function was called.\n *\n * The essential difference in resets is that the PF Reset\n * doesn't clear the packet buffers, doesn't reset the PE\n * firmware, and doesn't bother the other PFs on the chip.\n **/\nvoid i40e_do_reset(struct i40e_pf *pf, u32 reset_flags, bool lock_acquired)\n{\n\tu32 val;\n\n\tWARN_ON(in_interrupt());\n\n\n\t/* do the biggest reset indicated */\n\tif (reset_flags & BIT_ULL(__I40E_GLOBAL_RESET_REQUESTED)) {\n\n\t\t/* Request a Global Reset\n\t\t *\n\t\t * This will start the chip's countdown to the actual full\n\t\t * chip reset event, and a warning interrupt to be sent\n\t\t * to all PFs, including the requestor.  Our handler\n\t\t * for the warning interrupt will deal with the shutdown\n\t\t * and recovery of the switch setup.\n\t\t */\n\t\tdev_dbg(&pf->pdev->dev, \"GlobalR requested\\n\");\n\t\tval = rd32(&pf->hw, I40E_GLGEN_RTRIG);\n\t\tval |= I40E_GLGEN_RTRIG_GLOBR_MASK;\n\t\twr32(&pf->hw, I40E_GLGEN_RTRIG, val);\n\n\t} else if (reset_flags & BIT_ULL(__I40E_CORE_RESET_REQUESTED)) {\n\n\t\t/* Request a Core Reset\n\t\t *\n\t\t * Same as Global Reset, except does *not* include the MAC/PHY\n\t\t */\n\t\tdev_dbg(&pf->pdev->dev, \"CoreR requested\\n\");\n\t\tval = rd32(&pf->hw, I40E_GLGEN_RTRIG);\n\t\tval |= I40E_GLGEN_RTRIG_CORER_MASK;\n\t\twr32(&pf->hw, I40E_GLGEN_RTRIG, val);\n\t\ti40e_flush(&pf->hw);\n\n\t} else if (reset_flags & I40E_PF_RESET_FLAG) {\n\n\t\t/* Request a PF Reset\n\t\t *\n\t\t * Resets only the PF-specific registers\n\t\t *\n\t\t * This goes directly to the tear-down and rebuild of\n\t\t * the switch, since we need to do all the recovery as\n\t\t * for the Core Reset.\n\t\t */\n\t\tdev_dbg(&pf->pdev->dev, \"PFR requested\\n\");\n\t\ti40e_handle_reset_warning(pf, lock_acquired);\n\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t pf->flags & I40E_FLAG_DISABLE_FW_LLDP ?\n\t\t\t \"FW LLDP is disabled\\n\" :\n\t\t\t \"FW LLDP is enabled\\n\");\n\n\t} else if (reset_flags & BIT_ULL(__I40E_REINIT_REQUESTED)) {\n\t\tint v;\n\n\t\t/* Find the VSI(s) that requested a re-init */\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI reinit requested\\n\");\n\t\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\t\tstruct i40e_vsi *vsi = pf->vsi[v];\n\n\t\t\tif (vsi != NULL &&\n\t\t\t    test_and_clear_bit(__I40E_VSI_REINIT_REQUESTED,\n\t\t\t\t\t       vsi->state))\n\t\t\t\ti40e_vsi_reinit_locked(pf->vsi[v]);\n\t\t}\n\t} else if (reset_flags & BIT_ULL(__I40E_DOWN_REQUESTED)) {\n\t\tint v;\n\n\t\t/* Find the VSI(s) that needs to be brought down */\n\t\tdev_info(&pf->pdev->dev, \"VSI down requested\\n\");\n\t\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\t\tstruct i40e_vsi *vsi = pf->vsi[v];\n\n\t\t\tif (vsi != NULL &&\n\t\t\t    test_and_clear_bit(__I40E_VSI_DOWN_REQUESTED,\n\t\t\t\t\t       vsi->state)) {\n\t\t\t\tset_bit(__I40E_VSI_DOWN, vsi->state);\n\t\t\t\ti40e_down(vsi);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"bad reset request 0x%08x\\n\", reset_flags);\n\t}\n}\n\n#ifdef CONFIG_I40E_DCB\n/**\n * i40e_dcb_need_reconfig - Check if DCB needs reconfig\n * @pf: board private structure\n * @old_cfg: current DCB config\n * @new_cfg: new DCB config\n **/\nbool i40e_dcb_need_reconfig(struct i40e_pf *pf,\n\t\t\t    struct i40e_dcbx_config *old_cfg,\n\t\t\t    struct i40e_dcbx_config *new_cfg)\n{\n\tbool need_reconfig = false;\n\n\t/* Check if ETS configuration has changed */\n\tif (memcmp(&new_cfg->etscfg,\n\t\t   &old_cfg->etscfg,\n\t\t   sizeof(new_cfg->etscfg))) {\n\t\t/* If Priority Table has changed reconfig is needed */\n\t\tif (memcmp(&new_cfg->etscfg.prioritytable,\n\t\t\t   &old_cfg->etscfg.prioritytable,\n\t\t\t   sizeof(new_cfg->etscfg.prioritytable))) {\n\t\t\tneed_reconfig = true;\n\t\t\tdev_dbg(&pf->pdev->dev, \"ETS UP2TC changed.\\n\");\n\t\t}\n\n\t\tif (memcmp(&new_cfg->etscfg.tcbwtable,\n\t\t\t   &old_cfg->etscfg.tcbwtable,\n\t\t\t   sizeof(new_cfg->etscfg.tcbwtable)))\n\t\t\tdev_dbg(&pf->pdev->dev, \"ETS TC BW Table changed.\\n\");\n\n\t\tif (memcmp(&new_cfg->etscfg.tsatable,\n\t\t\t   &old_cfg->etscfg.tsatable,\n\t\t\t   sizeof(new_cfg->etscfg.tsatable)))\n\t\t\tdev_dbg(&pf->pdev->dev, \"ETS TSA Table changed.\\n\");\n\t}\n\n\t/* Check if PFC configuration has changed */\n\tif (memcmp(&new_cfg->pfc,\n\t\t   &old_cfg->pfc,\n\t\t   sizeof(new_cfg->pfc))) {\n\t\tneed_reconfig = true;\n\t\tdev_dbg(&pf->pdev->dev, \"PFC config change detected.\\n\");\n\t}\n\n\t/* Check if APP Table has changed */\n\tif (memcmp(&new_cfg->app,\n\t\t   &old_cfg->app,\n\t\t   sizeof(new_cfg->app))) {\n\t\tneed_reconfig = true;\n\t\tdev_dbg(&pf->pdev->dev, \"APP Table change detected.\\n\");\n\t}\n\n\tdev_dbg(&pf->pdev->dev, \"dcb need_reconfig=%d\\n\", need_reconfig);\n\treturn need_reconfig;\n}\n\n/**\n * i40e_handle_lldp_event - Handle LLDP Change MIB event\n * @pf: board private structure\n * @e: event info posted on ARQ\n **/\nstatic int i40e_handle_lldp_event(struct i40e_pf *pf,\n\t\t\t\t  struct i40e_arq_event_info *e)\n{\n\tstruct i40e_aqc_lldp_get_mib *mib =\n\t\t(struct i40e_aqc_lldp_get_mib *)&e->desc.params.raw;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_dcbx_config tmp_dcbx_cfg;\n\tbool need_reconfig = false;\n\tint ret = 0;\n\tu8 type;\n\n\t/* Not DCB capable or capability disabled */\n\tif (!(pf->flags & I40E_FLAG_DCB_CAPABLE))\n\t\treturn ret;\n\n\t/* Ignore if event is not for Nearest Bridge */\n\ttype = ((mib->type >> I40E_AQ_LLDP_BRIDGE_TYPE_SHIFT)\n\t\t& I40E_AQ_LLDP_BRIDGE_TYPE_MASK);\n\tdev_dbg(&pf->pdev->dev, \"LLDP event mib bridge type 0x%x\\n\", type);\n\tif (type != I40E_AQ_LLDP_BRIDGE_TYPE_NEAREST_BRIDGE)\n\t\treturn ret;\n\n\t/* Check MIB Type and return if event for Remote MIB update */\n\ttype = mib->type & I40E_AQ_LLDP_MIB_TYPE_MASK;\n\tdev_dbg(&pf->pdev->dev,\n\t\t\"LLDP event mib type %s\\n\", type ? \"remote\" : \"local\");\n\tif (type == I40E_AQ_LLDP_MIB_REMOTE) {\n\t\t/* Update the remote cached instance and return */\n\t\tret = i40e_aq_get_dcb_config(hw, I40E_AQ_LLDP_MIB_REMOTE,\n\t\t\t\tI40E_AQ_LLDP_BRIDGE_TYPE_NEAREST_BRIDGE,\n\t\t\t\t&hw->remote_dcbx_config);\n\t\tgoto exit;\n\t}\n\n\t/* Store the old configuration */\n\ttmp_dcbx_cfg = hw->local_dcbx_config;\n\n\t/* Reset the old DCBx configuration data */\n\tmemset(&hw->local_dcbx_config, 0, sizeof(hw->local_dcbx_config));\n\t/* Get updated DCBX data from firmware */\n\tret = i40e_get_dcb_config(&pf->hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed querying DCB configuration data from firmware, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto exit;\n\t}\n\n\t/* No change detected in DCBX configs */\n\tif (!memcmp(&tmp_dcbx_cfg, &hw->local_dcbx_config,\n\t\t    sizeof(tmp_dcbx_cfg))) {\n\t\tdev_dbg(&pf->pdev->dev, \"No change detected in DCBX configuration.\\n\");\n\t\tgoto exit;\n\t}\n\n\tneed_reconfig = i40e_dcb_need_reconfig(pf, &tmp_dcbx_cfg,\n\t\t\t\t\t       &hw->local_dcbx_config);\n\n\ti40e_dcbnl_flush_apps(pf, &tmp_dcbx_cfg, &hw->local_dcbx_config);\n\n\tif (!need_reconfig)\n\t\tgoto exit;\n\n\t/* Enable DCB tagging only when more than one TC */\n\tif (i40e_dcb_get_num_tc(&hw->local_dcbx_config) > 1)\n\t\tpf->flags |= I40E_FLAG_DCB_ENABLED;\n\telse\n\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\n\tset_bit(__I40E_PORT_SUSPENDED, pf->state);\n\t/* Reconfiguration needed quiesce all VSIs */\n\ti40e_pf_quiesce_all_vsi(pf);\n\n\t/* Changes in configuration update VEB/VSI */\n\ti40e_dcb_reconfigure(pf);\n\n\tret = i40e_resume_port_tx(pf);\n\n\tclear_bit(__I40E_PORT_SUSPENDED, pf->state);\n\t/* In case of error no point in resuming VSIs */\n\tif (ret)\n\t\tgoto exit;\n\n\t/* Wait for the PF's queues to be disabled */\n\tret = i40e_pf_wait_queues_disabled(pf);\n\tif (ret) {\n\t\t/* Schedule PF reset to recover */\n\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\ti40e_service_event_schedule(pf);\n\t} else {\n\t\ti40e_pf_unquiesce_all_vsi(pf);\n\t\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\t\tset_bit(__I40E_CLIENT_L2_CHANGE, pf->state);\n\t}\n\nexit:\n\treturn ret;\n}\n#endif /* CONFIG_I40E_DCB */\n\n/**\n * i40e_do_reset_safe - Protected reset path for userland calls.\n * @pf: board private structure\n * @reset_flags: which reset is requested\n *\n **/\nvoid i40e_do_reset_safe(struct i40e_pf *pf, u32 reset_flags)\n{\n\trtnl_lock();\n\ti40e_do_reset(pf, reset_flags, true);\n\trtnl_unlock();\n}\n\n/**\n * i40e_handle_lan_overflow_event - Handler for LAN queue overflow event\n * @pf: board private structure\n * @e: event info posted on ARQ\n *\n * Handler for LAN Queue Overflow Event generated by the firmware for PF\n * and VF queues\n **/\nstatic void i40e_handle_lan_overflow_event(struct i40e_pf *pf,\n\t\t\t\t\t   struct i40e_arq_event_info *e)\n{\n\tstruct i40e_aqc_lan_overflow *data =\n\t\t(struct i40e_aqc_lan_overflow *)&e->desc.params.raw;\n\tu32 queue = le32_to_cpu(data->prtdcb_rupto);\n\tu32 qtx_ctl = le32_to_cpu(data->otx_ctl);\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vf *vf;\n\tu16 vf_id;\n\n\tdev_dbg(&pf->pdev->dev, \"overflow Rx Queue Number = %d QTX_CTL=0x%08x\\n\",\n\t\tqueue, qtx_ctl);\n\n\t/* Queue belongs to VF, find the VF and issue VF reset */\n\tif (((qtx_ctl & I40E_QTX_CTL_PFVF_Q_MASK)\n\t    >> I40E_QTX_CTL_PFVF_Q_SHIFT) == I40E_QTX_CTL_VF_QUEUE) {\n\t\tvf_id = (u16)((qtx_ctl & I40E_QTX_CTL_VFVM_INDX_MASK)\n\t\t\t >> I40E_QTX_CTL_VFVM_INDX_SHIFT);\n\t\tvf_id -= hw->func_caps.vf_base_id;\n\t\tvf = &pf->vf[vf_id];\n\t\ti40e_vc_notify_vf_reset(vf);\n\t\t/* Allow VF to process pending reset notification */\n\t\tmsleep(20);\n\t\ti40e_reset_vf(vf, false);\n\t}\n}\n\n/**\n * i40e_get_cur_guaranteed_fd_count - Get the consumed guaranteed FD filters\n * @pf: board private structure\n **/\nu32 i40e_get_cur_guaranteed_fd_count(struct i40e_pf *pf)\n{\n\tu32 val, fcnt_prog;\n\n\tval = rd32(&pf->hw, I40E_PFQF_FDSTAT);\n\tfcnt_prog = (val & I40E_PFQF_FDSTAT_GUARANT_CNT_MASK);\n\treturn fcnt_prog;\n}\n\n/**\n * i40e_get_current_fd_count - Get total FD filters programmed for this PF\n * @pf: board private structure\n **/\nu32 i40e_get_current_fd_count(struct i40e_pf *pf)\n{\n\tu32 val, fcnt_prog;\n\n\tval = rd32(&pf->hw, I40E_PFQF_FDSTAT);\n\tfcnt_prog = (val & I40E_PFQF_FDSTAT_GUARANT_CNT_MASK) +\n\t\t    ((val & I40E_PFQF_FDSTAT_BEST_CNT_MASK) >>\n\t\t      I40E_PFQF_FDSTAT_BEST_CNT_SHIFT);\n\treturn fcnt_prog;\n}\n\n/**\n * i40e_get_global_fd_count - Get total FD filters programmed on device\n * @pf: board private structure\n **/\nu32 i40e_get_global_fd_count(struct i40e_pf *pf)\n{\n\tu32 val, fcnt_prog;\n\n\tval = rd32(&pf->hw, I40E_GLQF_FDCNT_0);\n\tfcnt_prog = (val & I40E_GLQF_FDCNT_0_GUARANT_CNT_MASK) +\n\t\t    ((val & I40E_GLQF_FDCNT_0_BESTCNT_MASK) >>\n\t\t     I40E_GLQF_FDCNT_0_BESTCNT_SHIFT);\n\treturn fcnt_prog;\n}\n\n/**\n * i40e_reenable_fdir_sb - Restore FDir SB capability\n * @pf: board private structure\n **/\nstatic void i40e_reenable_fdir_sb(struct i40e_pf *pf)\n{\n\tif (test_and_clear_bit(__I40E_FD_SB_AUTO_DISABLED, pf->state))\n\t\tif ((pf->flags & I40E_FLAG_FD_SB_ENABLED) &&\n\t\t    (I40E_DEBUG_FD & pf->hw.debug_mask))\n\t\t\tdev_info(&pf->pdev->dev, \"FD Sideband/ntuple is being enabled since we have space in the table now\\n\");\n}\n\n/**\n * i40e_reenable_fdir_atr - Restore FDir ATR capability\n * @pf: board private structure\n **/\nstatic void i40e_reenable_fdir_atr(struct i40e_pf *pf)\n{\n\tif (test_and_clear_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state)) {\n\t\t/* ATR uses the same filtering logic as SB rules. It only\n\t\t * functions properly if the input set mask is at the default\n\t\t * settings. It is safe to restore the default input set\n\t\t * because there are no active TCPv4 filter rules.\n\t\t */\n\t\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_TCP,\n\t\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t\tif ((pf->flags & I40E_FLAG_FD_ATR_ENABLED) &&\n\t\t    (I40E_DEBUG_FD & pf->hw.debug_mask))\n\t\t\tdev_info(&pf->pdev->dev, \"ATR is being enabled since we have space in the table and there are no conflicting ntuple rules\\n\");\n\t}\n}\n\n/**\n * i40e_delete_invalid_filter - Delete an invalid FDIR filter\n * @pf: board private structure\n * @filter: FDir filter to remove\n */\nstatic void i40e_delete_invalid_filter(struct i40e_pf *pf,\n\t\t\t\t       struct i40e_fdir_filter *filter)\n{\n\t/* Update counters */\n\tpf->fdir_pf_active_filters--;\n\tpf->fd_inv = 0;\n\n\tswitch (filter->flow_type) {\n\tcase TCP_V4_FLOW:\n\t\tpf->fd_tcp4_filter_cnt--;\n\t\tbreak;\n\tcase UDP_V4_FLOW:\n\t\tpf->fd_udp4_filter_cnt--;\n\t\tbreak;\n\tcase SCTP_V4_FLOW:\n\t\tpf->fd_sctp4_filter_cnt--;\n\t\tbreak;\n\tcase IP_USER_FLOW:\n\t\tswitch (filter->ip4_proto) {\n\t\tcase IPPROTO_TCP:\n\t\t\tpf->fd_tcp4_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_UDP:\n\t\t\tpf->fd_udp4_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_SCTP:\n\t\t\tpf->fd_sctp4_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_IP:\n\t\t\tpf->fd_ip4_filter_cnt--;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n\n\t/* Remove the filter from the list and free memory */\n\thlist_del(&filter->fdir_node);\n\tkfree(filter);\n}\n\n/**\n * i40e_fdir_check_and_reenable - Function to reenabe FD ATR or SB if disabled\n * @pf: board private structure\n **/\nvoid i40e_fdir_check_and_reenable(struct i40e_pf *pf)\n{\n\tstruct i40e_fdir_filter *filter;\n\tu32 fcnt_prog, fcnt_avail;\n\tstruct hlist_node *node;\n\n\tif (test_bit(__I40E_FD_FLUSH_REQUESTED, pf->state))\n\t\treturn;\n\n\t/* Check if we have enough room to re-enable FDir SB capability. */\n\tfcnt_prog = i40e_get_global_fd_count(pf);\n\tfcnt_avail = pf->fdir_pf_filter_count;\n\tif ((fcnt_prog < (fcnt_avail - I40E_FDIR_BUFFER_HEAD_ROOM)) ||\n\t    (pf->fd_add_err == 0) ||\n\t    (i40e_get_current_atr_cnt(pf) < pf->fd_atr_cnt))\n\t\ti40e_reenable_fdir_sb(pf);\n\n\t/* We should wait for even more space before re-enabling ATR.\n\t * Additionally, we cannot enable ATR as long as we still have TCP SB\n\t * rules active.\n\t */\n\tif ((fcnt_prog < (fcnt_avail - I40E_FDIR_BUFFER_HEAD_ROOM_FOR_ATR)) &&\n\t    (pf->fd_tcp4_filter_cnt == 0))\n\t\ti40e_reenable_fdir_atr(pf);\n\n\t/* if hw had a problem adding a filter, delete it */\n\tif (pf->fd_inv > 0) {\n\t\thlist_for_each_entry_safe(filter, node,\n\t\t\t\t\t  &pf->fdir_filter_list, fdir_node)\n\t\t\tif (filter->fd_id == pf->fd_inv)\n\t\t\t\ti40e_delete_invalid_filter(pf, filter);\n\t}\n}\n\n#define I40E_MIN_FD_FLUSH_INTERVAL 10\n#define I40E_MIN_FD_FLUSH_SB_ATR_UNSTABLE 30\n/**\n * i40e_fdir_flush_and_replay - Function to flush all FD filters and replay SB\n * @pf: board private structure\n **/\nstatic void i40e_fdir_flush_and_replay(struct i40e_pf *pf)\n{\n\tunsigned long min_flush_time;\n\tint flush_wait_retry = 50;\n\tbool disable_atr = false;\n\tint fd_room;\n\tint reg;\n\n\tif (!time_after(jiffies, pf->fd_flush_timestamp +\n\t\t\t\t (I40E_MIN_FD_FLUSH_INTERVAL * HZ)))\n\t\treturn;\n\n\t/* If the flush is happening too quick and we have mostly SB rules we\n\t * should not re-enable ATR for some time.\n\t */\n\tmin_flush_time = pf->fd_flush_timestamp +\n\t\t\t (I40E_MIN_FD_FLUSH_SB_ATR_UNSTABLE * HZ);\n\tfd_room = pf->fdir_pf_filter_count - pf->fdir_pf_active_filters;\n\n\tif (!(time_after(jiffies, min_flush_time)) &&\n\t    (fd_room < I40E_FDIR_BUFFER_HEAD_ROOM_FOR_ATR)) {\n\t\tif (I40E_DEBUG_FD & pf->hw.debug_mask)\n\t\t\tdev_info(&pf->pdev->dev, \"ATR disabled, not enough FD filter space.\\n\");\n\t\tdisable_atr = true;\n\t}\n\n\tpf->fd_flush_timestamp = jiffies;\n\tset_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state);\n\t/* flush all filters */\n\twr32(&pf->hw, I40E_PFQF_CTL_1,\n\t     I40E_PFQF_CTL_1_CLEARFDTABLE_MASK);\n\ti40e_flush(&pf->hw);\n\tpf->fd_flush_cnt++;\n\tpf->fd_add_err = 0;\n\tdo {\n\t\t/* Check FD flush status every 5-6msec */\n\t\tusleep_range(5000, 6000);\n\t\treg = rd32(&pf->hw, I40E_PFQF_CTL_1);\n\t\tif (!(reg & I40E_PFQF_CTL_1_CLEARFDTABLE_MASK))\n\t\t\tbreak;\n\t} while (flush_wait_retry--);\n\tif (reg & I40E_PFQF_CTL_1_CLEARFDTABLE_MASK) {\n\t\tdev_warn(&pf->pdev->dev, \"FD table did not flush, needs more time\\n\");\n\t} else {\n\t\t/* replay sideband filters */\n\t\ti40e_fdir_filter_restore(pf->vsi[pf->lan_vsi]);\n\t\tif (!disable_atr && !pf->fd_tcp4_filter_cnt)\n\t\t\tclear_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state);\n\t\tclear_bit(__I40E_FD_FLUSH_REQUESTED, pf->state);\n\t\tif (I40E_DEBUG_FD & pf->hw.debug_mask)\n\t\t\tdev_info(&pf->pdev->dev, \"FD Filter table flushed and FD-SB replayed.\\n\");\n\t}\n}\n\n/**\n * i40e_get_current_atr_count - Get the count of total FD ATR filters programmed\n * @pf: board private structure\n **/\nu32 i40e_get_current_atr_cnt(struct i40e_pf *pf)\n{\n\treturn i40e_get_current_fd_count(pf) - pf->fdir_pf_active_filters;\n}\n\n/* We can see up to 256 filter programming desc in transit if the filters are\n * being applied really fast; before we see the first\n * filter miss error on Rx queue 0. Accumulating enough error messages before\n * reacting will make sure we don't cause flush too often.\n */\n#define I40E_MAX_FD_PROGRAM_ERROR 256\n\n/**\n * i40e_fdir_reinit_subtask - Worker thread to reinit FDIR filter table\n * @pf: board private structure\n **/\nstatic void i40e_fdir_reinit_subtask(struct i40e_pf *pf)\n{\n\n\t/* if interface is down do nothing */\n\tif (test_bit(__I40E_DOWN, pf->state))\n\t\treturn;\n\n\tif (test_bit(__I40E_FD_FLUSH_REQUESTED, pf->state))\n\t\ti40e_fdir_flush_and_replay(pf);\n\n\ti40e_fdir_check_and_reenable(pf);\n\n}\n\n/**\n * i40e_vsi_link_event - notify VSI of a link event\n * @vsi: vsi to be notified\n * @link_up: link up or down\n **/\nstatic void i40e_vsi_link_event(struct i40e_vsi *vsi, bool link_up)\n{\n\tif (!vsi || test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tswitch (vsi->type) {\n\tcase I40E_VSI_MAIN:\n\t\tif (!vsi->netdev || !vsi->netdev_registered)\n\t\t\tbreak;\n\n\t\tif (link_up) {\n\t\t\tnetif_carrier_on(vsi->netdev);\n\t\t\tnetif_tx_wake_all_queues(vsi->netdev);\n\t\t} else {\n\t\t\tnetif_carrier_off(vsi->netdev);\n\t\t\tnetif_tx_stop_all_queues(vsi->netdev);\n\t\t}\n\t\tbreak;\n\n\tcase I40E_VSI_SRIOV:\n\tcase I40E_VSI_VMDQ2:\n\tcase I40E_VSI_CTRL:\n\tcase I40E_VSI_IWARP:\n\tcase I40E_VSI_MIRROR:\n\tdefault:\n\t\t/* there is no notification for other VSIs */\n\t\tbreak;\n\t}\n}\n\n/**\n * i40e_veb_link_event - notify elements on the veb of a link event\n * @veb: veb to be notified\n * @link_up: link up or down\n **/\nstatic void i40e_veb_link_event(struct i40e_veb *veb, bool link_up)\n{\n\tstruct i40e_pf *pf;\n\tint i;\n\n\tif (!veb || !veb->pf)\n\t\treturn;\n\tpf = veb->pf;\n\n\t/* depth first... */\n\tfor (i = 0; i < I40E_MAX_VEB; i++)\n\t\tif (pf->veb[i] && (pf->veb[i]->uplink_seid == veb->seid))\n\t\t\ti40e_veb_link_event(pf->veb[i], link_up);\n\n\t/* ... now the local VSIs */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i] && (pf->vsi[i]->uplink_seid == veb->seid))\n\t\t\ti40e_vsi_link_event(pf->vsi[i], link_up);\n}\n\n/**\n * i40e_link_event - Update netif_carrier status\n * @pf: board private structure\n **/\nstatic void i40e_link_event(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tu8 new_link_speed, old_link_speed;\n\ti40e_status status;\n\tbool new_link, old_link;\n\n\t/* set this to force the get_link_status call to refresh state */\n\tpf->hw.phy.get_link_info = true;\n\told_link = (pf->hw.phy.link_info_old.link_info & I40E_AQ_LINK_UP);\n\tstatus = i40e_get_link_status(&pf->hw, &new_link);\n\n\t/* On success, disable temp link polling */\n\tif (status == I40E_SUCCESS) {\n\t\tclear_bit(__I40E_TEMP_LINK_POLLING, pf->state);\n\t} else {\n\t\t/* Enable link polling temporarily until i40e_get_link_status\n\t\t * returns I40E_SUCCESS\n\t\t */\n\t\tset_bit(__I40E_TEMP_LINK_POLLING, pf->state);\n\t\tdev_dbg(&pf->pdev->dev, \"couldn't get link state, status: %d\\n\",\n\t\t\tstatus);\n\t\treturn;\n\t}\n\n\told_link_speed = pf->hw.phy.link_info_old.link_speed;\n\tnew_link_speed = pf->hw.phy.link_info.link_speed;\n\n\tif (new_link == old_link &&\n\t    new_link_speed == old_link_speed &&\n\t    (test_bit(__I40E_VSI_DOWN, vsi->state) ||\n\t     new_link == netif_carrier_ok(vsi->netdev)))\n\t\treturn;\n\n\ti40e_print_link_message(vsi, new_link);\n\n\t/* Notify the base of the switch tree connected to\n\t * the link.  Floating VEBs are not notified.\n\t */\n\tif (pf->lan_veb < I40E_MAX_VEB && pf->veb[pf->lan_veb])\n\t\ti40e_veb_link_event(pf->veb[pf->lan_veb], new_link);\n\telse\n\t\ti40e_vsi_link_event(vsi, new_link);\n\n\tif (pf->vf)\n\t\ti40e_vc_notify_link_state(pf);\n\n\tif (pf->flags & I40E_FLAG_PTP)\n\t\ti40e_ptp_set_increment(pf);\n}\n\n/**\n * i40e_watchdog_subtask - periodic checks not using event driven response\n * @pf: board private structure\n **/\nstatic void i40e_watchdog_subtask(struct i40e_pf *pf)\n{\n\tint i;\n\n\t/* if interface is down do nothing */\n\tif (test_bit(__I40E_DOWN, pf->state) ||\n\t    test_bit(__I40E_CONFIG_BUSY, pf->state))\n\t\treturn;\n\n\t/* make sure we don't do these things too often */\n\tif (time_before(jiffies, (pf->service_timer_previous +\n\t\t\t\t  pf->service_timer_period)))\n\t\treturn;\n\tpf->service_timer_previous = jiffies;\n\n\tif ((pf->flags & I40E_FLAG_LINK_POLLING_ENABLED) ||\n\t    test_bit(__I40E_TEMP_LINK_POLLING, pf->state))\n\t\ti40e_link_event(pf);\n\n\t/* Update the stats for active netdevs so the network stack\n\t * can look at updated numbers whenever it cares to\n\t */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i] && pf->vsi[i]->netdev)\n\t\t\ti40e_update_stats(pf->vsi[i]);\n\n\tif (pf->flags & I40E_FLAG_VEB_STATS_ENABLED) {\n\t\t/* Update the stats for the active switching components */\n\t\tfor (i = 0; i < I40E_MAX_VEB; i++)\n\t\t\tif (pf->veb[i])\n\t\t\t\ti40e_update_veb_stats(pf->veb[i]);\n\t}\n\n\ti40e_ptp_rx_hang(pf);\n\ti40e_ptp_tx_hang(pf);\n}\n\n/**\n * i40e_reset_subtask - Set up for resetting the device and driver\n * @pf: board private structure\n **/\nstatic void i40e_reset_subtask(struct i40e_pf *pf)\n{\n\tu32 reset_flags = 0;\n\n\tif (test_bit(__I40E_REINIT_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_REINIT_REQUESTED);\n\t\tclear_bit(__I40E_REINIT_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_PF_RESET_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_PF_RESET_REQUESTED);\n\t\tclear_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_CORE_RESET_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_CORE_RESET_REQUESTED);\n\t\tclear_bit(__I40E_CORE_RESET_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_GLOBAL_RESET_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_GLOBAL_RESET_REQUESTED);\n\t\tclear_bit(__I40E_GLOBAL_RESET_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_DOWN_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_DOWN_REQUESTED);\n\t\tclear_bit(__I40E_DOWN_REQUESTED, pf->state);\n\t}\n\n\t/* If there's a recovery already waiting, it takes\n\t * precedence before starting a new reset sequence.\n\t */\n\tif (test_bit(__I40E_RESET_INTR_RECEIVED, pf->state)) {\n\t\ti40e_prep_for_reset(pf, false);\n\t\ti40e_reset(pf);\n\t\ti40e_rebuild(pf, false, false);\n\t}\n\n\t/* If we're already down or resetting, just bail */\n\tif (reset_flags &&\n\t    !test_bit(__I40E_DOWN, pf->state) &&\n\t    !test_bit(__I40E_CONFIG_BUSY, pf->state)) {\n\t\ti40e_do_reset(pf, reset_flags, false);\n\t}\n}\n\n/**\n * i40e_handle_link_event - Handle link event\n * @pf: board private structure\n * @e: event info posted on ARQ\n **/\nstatic void i40e_handle_link_event(struct i40e_pf *pf,\n\t\t\t\t   struct i40e_arq_event_info *e)\n{\n\tstruct i40e_aqc_get_link_status *status =\n\t\t(struct i40e_aqc_get_link_status *)&e->desc.params.raw;\n\n\t/* Do a new status request to re-enable LSE reporting\n\t * and load new status information into the hw struct\n\t * This completely ignores any state information\n\t * in the ARQ event info, instead choosing to always\n\t * issue the AQ update link status command.\n\t */\n\ti40e_link_event(pf);\n\n\t/* Check if module meets thermal requirements */\n\tif (status->phy_type == I40E_PHY_TYPE_NOT_SUPPORTED_HIGH_TEMP) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Rx/Tx is disabled on this device because the module does not meet thermal requirements.\\n\");\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Refer to the Intel(R) Ethernet Adapters and Devices User Guide for a list of supported modules.\\n\");\n\t} else {\n\t\t/* check for unqualified module, if link is down, suppress\n\t\t * the message if link was forced to be down.\n\t\t */\n\t\tif ((status->link_info & I40E_AQ_MEDIA_AVAILABLE) &&\n\t\t    (!(status->an_info & I40E_AQ_QUALIFIED_MODULE)) &&\n\t\t    (!(status->link_info & I40E_AQ_LINK_UP)) &&\n\t\t    (!(pf->flags & I40E_FLAG_LINK_DOWN_ON_CLOSE_ENABLED))) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Rx/Tx is disabled on this device because an unsupported SFP module type was detected.\\n\");\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Refer to the Intel(R) Ethernet Adapters and Devices User Guide for a list of supported modules.\\n\");\n\t\t}\n\t}\n}\n\n/**\n * i40e_clean_adminq_subtask - Clean the AdminQ rings\n * @pf: board private structure\n **/\nstatic void i40e_clean_adminq_subtask(struct i40e_pf *pf)\n{\n\tstruct i40e_arq_event_info event;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 pending, i = 0;\n\ti40e_status ret;\n\tu16 opcode;\n\tu32 oldval;\n\tu32 val;\n\n\t/* Do not run clean AQ when PF reset fails */\n\tif (test_bit(__I40E_RESET_FAILED, pf->state))\n\t\treturn;\n\n\t/* check for error indications */\n\tval = rd32(&pf->hw, pf->hw.aq.arq.len);\n\toldval = val;\n\tif (val & I40E_PF_ARQLEN_ARQVFE_MASK) {\n\t\tif (hw->debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ VF Error detected\\n\");\n\t\tval &= ~I40E_PF_ARQLEN_ARQVFE_MASK;\n\t}\n\tif (val & I40E_PF_ARQLEN_ARQOVFL_MASK) {\n\t\tif (hw->debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ Overflow Error detected\\n\");\n\t\tval &= ~I40E_PF_ARQLEN_ARQOVFL_MASK;\n\t\tpf->arq_overflows++;\n\t}\n\tif (val & I40E_PF_ARQLEN_ARQCRIT_MASK) {\n\t\tif (hw->debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ Critical Error detected\\n\");\n\t\tval &= ~I40E_PF_ARQLEN_ARQCRIT_MASK;\n\t}\n\tif (oldval != val)\n\t\twr32(&pf->hw, pf->hw.aq.arq.len, val);\n\n\tval = rd32(&pf->hw, pf->hw.aq.asq.len);\n\toldval = val;\n\tif (val & I40E_PF_ATQLEN_ATQVFE_MASK) {\n\t\tif (pf->hw.debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ASQ VF Error detected\\n\");\n\t\tval &= ~I40E_PF_ATQLEN_ATQVFE_MASK;\n\t}\n\tif (val & I40E_PF_ATQLEN_ATQOVFL_MASK) {\n\t\tif (pf->hw.debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ASQ Overflow Error detected\\n\");\n\t\tval &= ~I40E_PF_ATQLEN_ATQOVFL_MASK;\n\t}\n\tif (val & I40E_PF_ATQLEN_ATQCRIT_MASK) {\n\t\tif (pf->hw.debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ASQ Critical Error detected\\n\");\n\t\tval &= ~I40E_PF_ATQLEN_ATQCRIT_MASK;\n\t}\n\tif (oldval != val)\n\t\twr32(&pf->hw, pf->hw.aq.asq.len, val);\n\n\tevent.buf_len = I40E_MAX_AQ_BUF_SIZE;\n\tevent.msg_buf = kzalloc(event.buf_len, GFP_KERNEL);\n\tif (!event.msg_buf)\n\t\treturn;\n\n\tdo {\n\t\tret = i40e_clean_arq_element(hw, &event, &pending);\n\t\tif (ret == I40E_ERR_ADMIN_QUEUE_NO_WORK)\n\t\t\tbreak;\n\t\telse if (ret) {\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ event error %d\\n\", ret);\n\t\t\tbreak;\n\t\t}\n\n\t\topcode = le16_to_cpu(event.desc.opcode);\n\t\tswitch (opcode) {\n\n\t\tcase i40e_aqc_opc_get_link_status:\n\t\t\ti40e_handle_link_event(pf, &event);\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_send_msg_to_pf:\n\t\t\tret = i40e_vc_process_vf_msg(pf,\n\t\t\t\t\tle16_to_cpu(event.desc.retval),\n\t\t\t\t\tle32_to_cpu(event.desc.cookie_high),\n\t\t\t\t\tle32_to_cpu(event.desc.cookie_low),\n\t\t\t\t\tevent.msg_buf,\n\t\t\t\t\tevent.msg_len);\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_lldp_update_mib:\n\t\t\tdev_dbg(&pf->pdev->dev, \"ARQ: Update LLDP MIB event received\\n\");\n#ifdef CONFIG_I40E_DCB\n\t\t\trtnl_lock();\n\t\t\tret = i40e_handle_lldp_event(pf, &event);\n\t\t\trtnl_unlock();\n#endif /* CONFIG_I40E_DCB */\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_event_lan_overflow:\n\t\t\tdev_dbg(&pf->pdev->dev, \"ARQ LAN queue overflow event received\\n\");\n\t\t\ti40e_handle_lan_overflow_event(pf, &event);\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_send_msg_to_peer:\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ: Msg from other pf\\n\");\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_nvm_erase:\n\t\tcase i40e_aqc_opc_nvm_update:\n\t\tcase i40e_aqc_opc_oem_post_update:\n\t\t\ti40e_debug(&pf->hw, I40E_DEBUG_NVM,\n\t\t\t\t   \"ARQ NVM operation 0x%04x completed\\n\",\n\t\t\t\t   opcode);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"ARQ: Unknown event 0x%04x ignored\\n\",\n\t\t\t\t opcode);\n\t\t\tbreak;\n\t\t}\n\t} while (i++ < pf->adminq_work_limit);\n\n\tif (i < pf->adminq_work_limit)\n\t\tclear_bit(__I40E_ADMINQ_EVENT_PENDING, pf->state);\n\n\t/* re-enable Admin queue interrupt cause */\n\tval = rd32(hw, I40E_PFINT_ICR0_ENA);\n\tval |=  I40E_PFINT_ICR0_ENA_ADMINQ_MASK;\n\twr32(hw, I40E_PFINT_ICR0_ENA, val);\n\ti40e_flush(hw);\n\n\tkfree(event.msg_buf);\n}\n\n/**\n * i40e_verify_eeprom - make sure eeprom is good to use\n * @pf: board private structure\n **/\nstatic void i40e_verify_eeprom(struct i40e_pf *pf)\n{\n\tint err;\n\n\terr = i40e_diag_eeprom_test(&pf->hw);\n\tif (err) {\n\t\t/* retry in case of garbage read */\n\t\terr = i40e_diag_eeprom_test(&pf->hw);\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev, \"eeprom check failed (%d), Tx/Rx traffic disabled\\n\",\n\t\t\t\t err);\n\t\t\tset_bit(__I40E_BAD_EEPROM, pf->state);\n\t\t}\n\t}\n\n\tif (!err && test_bit(__I40E_BAD_EEPROM, pf->state)) {\n\t\tdev_info(&pf->pdev->dev, \"eeprom check passed, Tx/Rx traffic enabled\\n\");\n\t\tclear_bit(__I40E_BAD_EEPROM, pf->state);\n\t}\n}\n\n/**\n * i40e_enable_pf_switch_lb\n * @pf: pointer to the PF structure\n *\n * enable switch loop back or die - no point in a return value\n **/\nstatic void i40e_enable_pf_switch_lb(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_vsi_context ctxt;\n\tint ret;\n\n\tctxt.seid = pf->main_vsi_seid;\n\tctxt.pf_num = pf->hw.pf_id;\n\tctxt.vf_num = 0;\n\tret = i40e_aq_get_vsi_params(&pf->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn;\n\t}\n\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\tctxt.info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\tctxt.info.switch_id |= cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"update vsi switch failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n}\n\n/**\n * i40e_disable_pf_switch_lb\n * @pf: pointer to the PF structure\n *\n * disable switch loop back or die - no point in a return value\n **/\nstatic void i40e_disable_pf_switch_lb(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_vsi_context ctxt;\n\tint ret;\n\n\tctxt.seid = pf->main_vsi_seid;\n\tctxt.pf_num = pf->hw.pf_id;\n\tctxt.vf_num = 0;\n\tret = i40e_aq_get_vsi_params(&pf->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn;\n\t}\n\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\tctxt.info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\tctxt.info.switch_id &= ~cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"update vsi switch failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n}\n\n/**\n * i40e_config_bridge_mode - Configure the HW bridge mode\n * @veb: pointer to the bridge instance\n *\n * Configure the loop back mode for the LAN VSI that is downlink to the\n * specified HW bridge instance. It is expected this function is called\n * when a new HW bridge is instantiated.\n **/\nstatic void i40e_config_bridge_mode(struct i40e_veb *veb)\n{\n\tstruct i40e_pf *pf = veb->pf;\n\n\tif (pf->hw.debug_mask & I40E_DEBUG_LAN)\n\t\tdev_info(&pf->pdev->dev, \"enabling bridge mode: %s\\n\",\n\t\t\t veb->bridge_mode == BRIDGE_MODE_VEPA ? \"VEPA\" : \"VEB\");\n\tif (veb->bridge_mode & BRIDGE_MODE_VEPA)\n\t\ti40e_disable_pf_switch_lb(pf);\n\telse\n\t\ti40e_enable_pf_switch_lb(pf);\n}\n\n/**\n * i40e_reconstitute_veb - rebuild the VEB and anything connected to it\n * @veb: pointer to the VEB instance\n *\n * This is a recursive function that first builds the attached VSIs then\n * recurses in to build the next layer of VEB.  We track the connections\n * through our own index numbers because the seid's from the HW could\n * change across the reset.\n **/\nstatic int i40e_reconstitute_veb(struct i40e_veb *veb)\n{\n\tstruct i40e_vsi *ctl_vsi = NULL;\n\tstruct i40e_pf *pf = veb->pf;\n\tint v, veb_idx;\n\tint ret;\n\n\t/* build VSI that owns this VEB, temporarily attached to base VEB */\n\tfor (v = 0; v < pf->num_alloc_vsi && !ctl_vsi; v++) {\n\t\tif (pf->vsi[v] &&\n\t\t    pf->vsi[v]->veb_idx == veb->idx &&\n\t\t    pf->vsi[v]->flags & I40E_VSI_FLAG_VEB_OWNER) {\n\t\t\tctl_vsi = pf->vsi[v];\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!ctl_vsi) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"missing owner VSI for veb_idx %d\\n\", veb->idx);\n\t\tret = -ENOENT;\n\t\tgoto end_reconstitute;\n\t}\n\tif (ctl_vsi != pf->vsi[pf->lan_vsi])\n\t\tctl_vsi->uplink_seid = pf->vsi[pf->lan_vsi]->uplink_seid;\n\tret = i40e_add_vsi(ctl_vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"rebuild of veb_idx %d owner VSI failed: %d\\n\",\n\t\t\t veb->idx, ret);\n\t\tgoto end_reconstitute;\n\t}\n\ti40e_vsi_reset_stats(ctl_vsi);\n\n\t/* create the VEB in the switch and move the VSI onto the VEB */\n\tret = i40e_add_veb(veb, ctl_vsi);\n\tif (ret)\n\t\tgoto end_reconstitute;\n\n\tif (pf->flags & I40E_FLAG_VEB_MODE_ENABLED)\n\t\tveb->bridge_mode = BRIDGE_MODE_VEB;\n\telse\n\t\tveb->bridge_mode = BRIDGE_MODE_VEPA;\n\ti40e_config_bridge_mode(veb);\n\n\t/* create the remaining VSIs attached to this VEB */\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (!pf->vsi[v] || pf->vsi[v] == ctl_vsi)\n\t\t\tcontinue;\n\n\t\tif (pf->vsi[v]->veb_idx == veb->idx) {\n\t\t\tstruct i40e_vsi *vsi = pf->vsi[v];\n\n\t\t\tvsi->uplink_seid = veb->seid;\n\t\t\tret = i40e_add_vsi(vsi);\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"rebuild of vsi_idx %d failed: %d\\n\",\n\t\t\t\t\t v, ret);\n\t\t\t\tgoto end_reconstitute;\n\t\t\t}\n\t\t\ti40e_vsi_reset_stats(vsi);\n\t\t}\n\t}\n\n\t/* create any VEBs attached to this VEB - RECURSION */\n\tfor (veb_idx = 0; veb_idx < I40E_MAX_VEB; veb_idx++) {\n\t\tif (pf->veb[veb_idx] && pf->veb[veb_idx]->veb_idx == veb->idx) {\n\t\t\tpf->veb[veb_idx]->uplink_seid = veb->seid;\n\t\t\tret = i40e_reconstitute_veb(pf->veb[veb_idx]);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\nend_reconstitute:\n\treturn ret;\n}\n\n/**\n * i40e_get_capabilities - get info about the HW\n * @pf: the PF struct\n **/\nstatic int i40e_get_capabilities(struct i40e_pf *pf,\n\t\t\t\t enum i40e_admin_queue_opc list_type)\n{\n\tstruct i40e_aqc_list_capabilities_element_resp *cap_buf;\n\tu16 data_size;\n\tint buf_len;\n\tint err;\n\n\tbuf_len = 40 * sizeof(struct i40e_aqc_list_capabilities_element_resp);\n\tdo {\n\t\tcap_buf = kzalloc(buf_len, GFP_KERNEL);\n\t\tif (!cap_buf)\n\t\t\treturn -ENOMEM;\n\n\t\t/* this loads the data into the hw struct for us */\n\t\terr = i40e_aq_discover_capabilities(&pf->hw, cap_buf, buf_len,\n\t\t\t\t\t\t    &data_size, list_type,\n\t\t\t\t\t\t    NULL);\n\t\t/* data loaded, buffer no longer needed */\n\t\tkfree(cap_buf);\n\n\t\tif (pf->hw.aq.asq_last_status == I40E_AQ_RC_ENOMEM) {\n\t\t\t/* retry with a larger buffer */\n\t\t\tbuf_len = data_size;\n\t\t} else if (pf->hw.aq.asq_last_status != I40E_AQ_RC_OK) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"capability discovery failed, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, err),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn -ENODEV;\n\t\t}\n\t} while (err);\n\n\tif (pf->hw.debug_mask & I40E_DEBUG_USER) {\n\t\tif (list_type == i40e_aqc_opc_list_func_capabilities) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"pf=%d, num_vfs=%d, msix_pf=%d, msix_vf=%d, fd_g=%d, fd_b=%d, pf_max_q=%d num_vsi=%d\\n\",\n\t\t\t\t pf->hw.pf_id, pf->hw.func_caps.num_vfs,\n\t\t\t\t pf->hw.func_caps.num_msix_vectors,\n\t\t\t\t pf->hw.func_caps.num_msix_vectors_vf,\n\t\t\t\t pf->hw.func_caps.fd_filters_guaranteed,\n\t\t\t\t pf->hw.func_caps.fd_filters_best_effort,\n\t\t\t\t pf->hw.func_caps.num_tx_qp,\n\t\t\t\t pf->hw.func_caps.num_vsis);\n\t\t} else if (list_type == i40e_aqc_opc_list_dev_capabilities) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"switch_mode=0x%04x, function_valid=0x%08x\\n\",\n\t\t\t\t pf->hw.dev_caps.switch_mode,\n\t\t\t\t pf->hw.dev_caps.valid_functions);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"SR-IOV=%d, num_vfs for all function=%u\\n\",\n\t\t\t\t pf->hw.dev_caps.sr_iov_1_1,\n\t\t\t\t pf->hw.dev_caps.num_vfs);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"num_vsis=%u, num_rx:%u, num_tx=%u\\n\",\n\t\t\t\t pf->hw.dev_caps.num_vsis,\n\t\t\t\t pf->hw.dev_caps.num_rx_qp,\n\t\t\t\t pf->hw.dev_caps.num_tx_qp);\n\t\t}\n\t}\n\tif (list_type == i40e_aqc_opc_list_func_capabilities) {\n#define DEF_NUM_VSI (1 + (pf->hw.func_caps.fcoe ? 1 : 0) \\\n\t\t       + pf->hw.func_caps.num_vfs)\n\t\tif (pf->hw.revision_id == 0 &&\n\t\t    pf->hw.func_caps.num_vsis < DEF_NUM_VSI) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"got num_vsis %d, setting num_vsis to %d\\n\",\n\t\t\t\t pf->hw.func_caps.num_vsis, DEF_NUM_VSI);\n\t\t\tpf->hw.func_caps.num_vsis = DEF_NUM_VSI;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int i40e_vsi_clear(struct i40e_vsi *vsi);\n\n/**\n * i40e_fdir_sb_setup - initialize the Flow Director resources for Sideband\n * @pf: board private structure\n **/\nstatic void i40e_fdir_sb_setup(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi;\n\n\t/* quick workaround for an NVM issue that leaves a critical register\n\t * uninitialized\n\t */\n\tif (!rd32(&pf->hw, I40E_GLQF_HKEY(0))) {\n\t\tstatic const u32 hkey[] = {\n\t\t\t0xe640d33f, 0xcdfe98ab, 0x73fa7161, 0x0d7a7d36,\n\t\t\t0xeacb7d61, 0xaa4f05b6, 0x9c5c89ed, 0xfc425ddb,\n\t\t\t0xa4654832, 0xfc7461d4, 0x8f827619, 0xf5c63c21,\n\t\t\t0x95b3a76d};\n\t\tint i;\n\n\t\tfor (i = 0; i <= I40E_GLQF_HKEY_MAX_INDEX; i++)\n\t\t\twr32(&pf->hw, I40E_GLQF_HKEY(i), hkey[i]);\n\t}\n\n\tif (!(pf->flags & I40E_FLAG_FD_SB_ENABLED))\n\t\treturn;\n\n\t/* find existing VSI and see if it needs configuring */\n\tvsi = i40e_find_vsi_by_type(pf, I40E_VSI_FDIR);\n\n\t/* create a new VSI if none exists */\n\tif (!vsi) {\n\t\tvsi = i40e_vsi_setup(pf, I40E_VSI_FDIR,\n\t\t\t\t     pf->vsi[pf->lan_vsi]->seid, 0);\n\t\tif (!vsi) {\n\t\t\tdev_info(&pf->pdev->dev, \"Couldn't create FDir VSI\\n\");\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t\t\treturn;\n\t\t}\n\t}\n\n\ti40e_vsi_setup_irqhandler(vsi, i40e_fdir_clean_ring);\n}\n\n/**\n * i40e_fdir_teardown - release the Flow Director resources\n * @pf: board private structure\n **/\nstatic void i40e_fdir_teardown(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi;\n\n\ti40e_fdir_filter_exit(pf);\n\tvsi = i40e_find_vsi_by_type(pf, I40E_VSI_FDIR);\n\tif (vsi)\n\t\ti40e_vsi_release(vsi);\n}\n\n/**\n * i40e_rebuild_cloud_filters - Rebuilds cloud filters for VSIs\n * @vsi: PF main vsi\n * @seid: seid of main or channel VSIs\n *\n * Rebuilds cloud filters associated with main VSI and channel VSIs if they\n * existed before reset\n **/\nstatic int i40e_rebuild_cloud_filters(struct i40e_vsi *vsi, u16 seid)\n{\n\tstruct i40e_cloud_filter *cfilter;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct hlist_node *node;\n\ti40e_status ret;\n\n\t/* Add cloud filters back if they exist */\n\thlist_for_each_entry_safe(cfilter, node, &pf->cloud_filter_list,\n\t\t\t\t  cloud_node) {\n\t\tif (cfilter->seid != seid)\n\t\t\tcontinue;\n\n\t\tif (cfilter->dst_port)\n\t\t\tret = i40e_add_del_cloud_filter_big_buf(vsi, cfilter,\n\t\t\t\t\t\t\t\ttrue);\n\t\telse\n\t\t\tret = i40e_add_del_cloud_filter(vsi, cfilter, true);\n\n\t\tif (ret) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Failed to rebuild cloud filter, err %s aq_err %s\\n\",\n\t\t\t\ti40e_stat_str(&pf->hw, ret),\n\t\t\t\ti40e_aq_str(&pf->hw,\n\t\t\t\t\t    pf->hw.aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\n/**\n * i40e_rebuild_channels - Rebuilds channel VSIs if they existed before reset\n * @vsi: PF main vsi\n *\n * Rebuilds channel VSIs if they existed before reset\n **/\nstatic int i40e_rebuild_channels(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\ti40e_status ret;\n\n\tif (list_empty(&vsi->ch_list))\n\t\treturn 0;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tif (!ch->initialized)\n\t\t\tbreak;\n\t\t/* Proceed with creation of channel (VMDq2) VSI */\n\t\tret = i40e_add_channel(vsi->back, vsi->uplink_seid, ch);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"failed to rebuild channels using uplink_seid %u\\n\",\n\t\t\t\t vsi->uplink_seid);\n\t\t\treturn ret;\n\t\t}\n\t\t/* Reconfigure TX queues using QTX_CTL register */\n\t\tret = i40e_channel_config_tx_ring(vsi->back, vsi, ch);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"failed to configure TX rings for channel %u\\n\",\n\t\t\t\t ch->seid);\n\t\t\treturn ret;\n\t\t}\n\t\t/* update 'next_base_queue' */\n\t\tvsi->next_base_queue = vsi->next_base_queue +\n\t\t\t\t\t\t\tch->num_queue_pairs;\n\t\tif (ch->max_tx_rate) {\n\t\t\tu64 credits = ch->max_tx_rate;\n\n\t\t\tif (i40e_set_bw_limit(vsi, ch->seid,\n\t\t\t\t\t      ch->max_tx_rate))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\t\tch->max_tx_rate,\n\t\t\t\tcredits,\n\t\t\t\tch->seid);\n\t\t}\n\t\tret = i40e_rebuild_cloud_filters(vsi, ch->seid);\n\t\tif (ret) {\n\t\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\t\"Failed to rebuild cloud filters for channel VSI %u\\n\",\n\t\t\t\tch->seid);\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\n/**\n * i40e_prep_for_reset - prep for the core to reset\n * @pf: board private structure\n * @lock_acquired: indicates whether or not the lock has been acquired\n * before this function was called.\n *\n * Close up the VFs and other things in prep for PF Reset.\n  **/\nstatic void i40e_prep_for_reset(struct i40e_pf *pf, bool lock_acquired)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret = 0;\n\tu32 v;\n\n\tclear_bit(__I40E_RESET_INTR_RECEIVED, pf->state);\n\tif (test_and_set_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\treturn;\n\tif (i40e_check_asq_alive(&pf->hw))\n\t\ti40e_vc_notify_reset(pf);\n\n\tdev_dbg(&pf->pdev->dev, \"Tearing down internal switch for reset\\n\");\n\n\t/* quiesce the VSIs and their queues that are not already DOWN */\n\t/* pf_quiesce_all_vsi modifies netdev structures -rtnl_lock needed */\n\tif (!lock_acquired)\n\t\trtnl_lock();\n\ti40e_pf_quiesce_all_vsi(pf);\n\tif (!lock_acquired)\n\t\trtnl_unlock();\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v])\n\t\t\tpf->vsi[v]->seid = 0;\n\t}\n\n\ti40e_shutdown_adminq(&pf->hw);\n\n\t/* call shutdown HMC */\n\tif (hw->hmc.hmc_obj) {\n\t\tret = i40e_shutdown_lan_hmc(hw);\n\t\tif (ret)\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"shutdown_lan_hmc failed: %d\\n\", ret);\n\t}\n\n\t/* Save the current PTP time so that we can restore the time after the\n\t * reset completes.\n\t */\n\ti40e_ptp_save_hw_time(pf);\n}\n\n/**\n * i40e_send_version - update firmware with driver version\n * @pf: PF struct\n */\nstatic void i40e_send_version(struct i40e_pf *pf)\n{\n\tstruct i40e_driver_version dv;\n\n\tdv.major_version = DRV_VERSION_MAJOR;\n\tdv.minor_version = DRV_VERSION_MINOR;\n\tdv.build_version = DRV_VERSION_BUILD;\n\tdv.subbuild_version = 0;\n\tstrlcpy(dv.driver_string, DRV_VERSION, sizeof(dv.driver_string));\n\ti40e_aq_send_driver_version(&pf->hw, &dv, NULL);\n}\n\n/**\n * i40e_get_oem_version - get OEM specific version information\n * @hw: pointer to the hardware structure\n **/\nstatic void i40e_get_oem_version(struct i40e_hw *hw)\n{\n\tu16 block_offset = 0xffff;\n\tu16 block_length = 0;\n\tu16 capabilities = 0;\n\tu16 gen_snap = 0;\n\tu16 release = 0;\n\n#define I40E_SR_NVM_OEM_VERSION_PTR\t\t0x1B\n#define I40E_NVM_OEM_LENGTH_OFFSET\t\t0x00\n#define I40E_NVM_OEM_CAPABILITIES_OFFSET\t0x01\n#define I40E_NVM_OEM_GEN_OFFSET\t\t\t0x02\n#define I40E_NVM_OEM_RELEASE_OFFSET\t\t0x03\n#define I40E_NVM_OEM_CAPABILITIES_MASK\t\t0x000F\n#define I40E_NVM_OEM_LENGTH\t\t\t3\n\n\t/* Check if pointer to OEM version block is valid. */\n\ti40e_read_nvm_word(hw, I40E_SR_NVM_OEM_VERSION_PTR, &block_offset);\n\tif (block_offset == 0xffff)\n\t\treturn;\n\n\t/* Check if OEM version block has correct length. */\n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_LENGTH_OFFSET,\n\t\t\t   &block_length);\n\tif (block_length < I40E_NVM_OEM_LENGTH)\n\t\treturn;\n\n\t/* Check if OEM version format is as expected. */\n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_CAPABILITIES_OFFSET,\n\t\t\t   &capabilities);\n\tif ((capabilities & I40E_NVM_OEM_CAPABILITIES_MASK) != 0)\n\t\treturn;\n\n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_GEN_OFFSET,\n\t\t\t   &gen_snap);\n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_RELEASE_OFFSET,\n\t\t\t   &release);\n\thw->nvm.oem_ver = (gen_snap << I40E_OEM_SNAP_SHIFT) | release;\n\thw->nvm.eetrack = I40E_OEM_EETRACK_ID;\n}\n\n/**\n * i40e_reset - wait for core reset to finish reset, reset pf if corer not seen\n * @pf: board private structure\n **/\nstatic int i40e_reset(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret;\n\n\tret = i40e_pf_reset(hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"PF reset failed, %d\\n\", ret);\n\t\tset_bit(__I40E_RESET_FAILED, pf->state);\n\t\tclear_bit(__I40E_RESET_RECOVERY_PENDING, pf->state);\n\t} else {\n\t\tpf->pfr_count++;\n\t}\n\treturn ret;\n}\n\n/**\n * i40e_rebuild - rebuild using a saved config\n * @pf: board private structure\n * @reinit: if the Main VSI needs to re-initialized.\n * @lock_acquired: indicates whether or not the lock has been acquired\n * before this function was called.\n **/\nstatic void i40e_rebuild(struct i40e_pf *pf, bool reinit, bool lock_acquired)\n{\n\tint old_recovery_mode_bit = test_bit(__I40E_RECOVERY_MODE, pf->state);\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 set_fc_aq_fail = 0;\n\ti40e_status ret;\n\tu32 val;\n\tint v;\n\n\tif (test_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state) &&\n\t    i40e_check_recovery_mode(pf)) {\n\t\ti40e_set_ethtool_ops(pf->vsi[pf->lan_vsi]->netdev);\n\t}\n\n\tif (test_bit(__I40E_DOWN, pf->state) &&\n\t    !test_bit(__I40E_RECOVERY_MODE, pf->state) &&\n\t    !old_recovery_mode_bit)\n\t\tgoto clear_recovery;\n\tdev_dbg(&pf->pdev->dev, \"Rebuilding internal switch\\n\");\n\n\t/* rebuild the basics for the AdminQ, HMC, and initial HW switch */\n\tret = i40e_init_adminq(&pf->hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"Rebuild AdminQ failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto clear_recovery;\n\t}\n\ti40e_get_oem_version(&pf->hw);\n\n\tif (test_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state) &&\n\t    ((hw->aq.fw_maj_ver == 4 && hw->aq.fw_min_ver <= 33) ||\n\t     hw->aq.fw_maj_ver < 4) && hw->mac.type == I40E_MAC_XL710) {\n\t\t/* The following delay is necessary for 4.33 firmware and older\n\t\t * to recover after EMP reset. 200 ms should suffice but we\n\t\t * put here 300 ms to be sure that FW is ready to operate\n\t\t * after reset.\n\t\t */\n\t\tmdelay(300);\n\t}\n\n\t/* re-verify the eeprom if we just had an EMP reset */\n\tif (test_and_clear_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state))\n\t\ti40e_verify_eeprom(pf);\n\n\t/* if we are going out of or into recovery mode we have to act\n\t * accordingly with regard to resources initialization\n\t * and deinitialization\n\t */\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state) ||\n\t    old_recovery_mode_bit) {\n\t\tif (i40e_get_capabilities(pf,\n\t\t\t\t\t  i40e_aqc_opc_list_func_capabilities))\n\t\t\tgoto end_unlock;\n\n\t\tif (test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\t\t/* we're staying in recovery mode so we'll reinitialize\n\t\t\t * misc vector here\n\t\t\t */\n\t\t\tif (i40e_setup_misc_vector_for_recovery_mode(pf))\n\t\t\t\tgoto end_unlock;\n\t\t} else {\n\t\t\tif (!lock_acquired)\n\t\t\t\trtnl_lock();\n\t\t\t/* we're going out of recovery mode so we'll free\n\t\t\t * the IRQ allocated specifically for recovery mode\n\t\t\t * and restore the interrupt scheme\n\t\t\t */\n\t\t\tfree_irq(pf->pdev->irq, pf);\n\t\t\ti40e_clear_interrupt_scheme(pf);\n\t\t\tif (i40e_restore_interrupt_scheme(pf))\n\t\t\t\tgoto end_unlock;\n\t\t}\n\n\t\t/* tell the firmware that we're starting */\n\t\ti40e_send_version(pf);\n\n\t\t/* bail out in case recovery mode was detected, as there is\n\t\t * no need for further configuration.\n\t\t */\n\t\tgoto end_unlock;\n\t}\n\n\ti40e_clear_pxe_mode(hw);\n\tret = i40e_get_capabilities(pf, i40e_aqc_opc_list_func_capabilities);\n\tif (ret)\n\t\tgoto end_core_reset;\n\n\tret = i40e_init_lan_hmc(hw, hw->func_caps.num_tx_qp,\n\t\t\t\thw->func_caps.num_rx_qp, 0, 0);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"init_lan_hmc failed: %d\\n\", ret);\n\t\tgoto end_core_reset;\n\t}\n\tret = i40e_configure_lan_hmc(hw, I40E_HMC_MODEL_DIRECT_ONLY);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"configure_lan_hmc failed: %d\\n\", ret);\n\t\tgoto end_core_reset;\n\t}\n\n\t/* Enable FW to write a default DCB config on link-up */\n\ti40e_aq_set_dcb_parameters(hw, true, NULL);\n\n#ifdef CONFIG_I40E_DCB\n\tret = i40e_init_pf_dcb(pf);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"DCB init failed %d, disabled\\n\", ret);\n\t\tpf->flags &= ~I40E_FLAG_DCB_CAPABLE;\n\t\t/* Continue without DCB enabled */\n\t}\n#endif /* CONFIG_I40E_DCB */\n\t/* do basic switch setup */\n\tif (!lock_acquired)\n\t\trtnl_lock();\n\tret = i40e_setup_pf_switch(pf, reinit);\n\tif (ret)\n\t\tgoto end_unlock;\n\n\t/* The driver only wants link up/down and module qualification\n\t * reports from firmware.  Note the negative logic.\n\t */\n\tret = i40e_aq_set_phy_int_mask(&pf->hw,\n\t\t\t\t       ~(I40E_AQ_EVENT_LINK_UPDOWN |\n\t\t\t\t\t I40E_AQ_EVENT_MEDIA_NA |\n\t\t\t\t\t I40E_AQ_EVENT_MODULE_QUAL_FAIL), NULL);\n\tif (ret)\n\t\tdev_info(&pf->pdev->dev, \"set phy mask fail, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t/* make sure our flow control settings are restored */\n\tret = i40e_set_fc(&pf->hw, &set_fc_aq_fail, true);\n\tif (ret)\n\t\tdev_dbg(&pf->pdev->dev, \"setting flow control: ret = %s last_status = %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, ret),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t/* Rebuild the VSIs and VEBs that existed before reset.\n\t * They are still in our local switch element arrays, so only\n\t * need to rebuild the switch model in the HW.\n\t *\n\t * If there were VEBs but the reconstitution failed, we'll try\n\t * try to recover minimal use by getting the basic PF VSI working.\n\t */\n\tif (vsi->uplink_seid != pf->mac_seid) {\n\t\tdev_dbg(&pf->pdev->dev, \"attempting to rebuild switch\\n\");\n\t\t/* find the one VEB connected to the MAC, and find orphans */\n\t\tfor (v = 0; v < I40E_MAX_VEB; v++) {\n\t\t\tif (!pf->veb[v])\n\t\t\t\tcontinue;\n\n\t\t\tif (pf->veb[v]->uplink_seid == pf->mac_seid ||\n\t\t\t    pf->veb[v]->uplink_seid == 0) {\n\t\t\t\tret = i40e_reconstitute_veb(pf->veb[v]);\n\n\t\t\t\tif (!ret)\n\t\t\t\t\tcontinue;\n\n\t\t\t\t/* If Main VEB failed, we're in deep doodoo,\n\t\t\t\t * so give up rebuilding the switch and set up\n\t\t\t\t * for minimal rebuild of PF VSI.\n\t\t\t\t * If orphan failed, we'll report the error\n\t\t\t\t * but try to keep going.\n\t\t\t\t */\n\t\t\t\tif (pf->veb[v]->uplink_seid == pf->mac_seid) {\n\t\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t\t \"rebuild of switch failed: %d, will try to set up simple PF connection\\n\",\n\t\t\t\t\t\t ret);\n\t\t\t\t\tvsi->uplink_seid = pf->mac_seid;\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (pf->veb[v]->uplink_seid == 0) {\n\t\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t\t \"rebuild of orphan VEB failed: %d\\n\",\n\t\t\t\t\t\t ret);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (vsi->uplink_seid == pf->mac_seid) {\n\t\tdev_dbg(&pf->pdev->dev, \"attempting to rebuild PF VSI\\n\");\n\t\t/* no VEB, so rebuild only the Main VSI */\n\t\tret = i40e_add_vsi(vsi);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"rebuild of Main VSI failed: %d\\n\", ret);\n\t\t\tgoto end_unlock;\n\t\t}\n\t}\n\n\tif (vsi->mqprio_qopt.max_rate[0]) {\n\t\tu64 max_tx_rate = vsi->mqprio_qopt.max_rate[0];\n\t\tu64 credits = 0;\n\n\t\tdo_div(max_tx_rate, I40E_BW_MBPS_DIVISOR);\n\t\tret = i40e_set_bw_limit(vsi, vsi->seid, max_tx_rate);\n\t\tif (ret)\n\t\t\tgoto end_unlock;\n\n\t\tcredits = max_tx_rate;\n\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\tmax_tx_rate,\n\t\t\tcredits,\n\t\t\tvsi->seid);\n\t}\n\n\tret = i40e_rebuild_cloud_filters(vsi, vsi->seid);\n\tif (ret)\n\t\tgoto end_unlock;\n\n\t/* PF Main VSI is rebuild by now, go ahead and rebuild channel VSIs\n\t * for this main VSI if they exist\n\t */\n\tret = i40e_rebuild_channels(vsi);\n\tif (ret)\n\t\tgoto end_unlock;\n\n\t/* Reconfigure hardware for allowing smaller MSS in the case\n\t * of TSO, so that we avoid the MDD being fired and causing\n\t * a reset in the case of small MSS+TSO.\n\t */\n#define I40E_REG_MSS          0x000E64DC\n#define I40E_REG_MSS_MIN_MASK 0x3FF0000\n#define I40E_64BYTE_MSS       0x400000\n\tval = rd32(hw, I40E_REG_MSS);\n\tif ((val & I40E_REG_MSS_MIN_MASK) > I40E_64BYTE_MSS) {\n\t\tval &= ~I40E_REG_MSS_MIN_MASK;\n\t\tval |= I40E_64BYTE_MSS;\n\t\twr32(hw, I40E_REG_MSS, val);\n\t}\n\n\tif (pf->hw_features & I40E_HW_RESTART_AUTONEG) {\n\t\tmsleep(75);\n\t\tret = i40e_aq_set_link_restart_an(&pf->hw, true, NULL);\n\t\tif (ret)\n\t\t\tdev_info(&pf->pdev->dev, \"link restart failed, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t}\n\t/* reinit the misc interrupt */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\tret = i40e_setup_misc_vector(pf);\n\n\t/* Add a filter to drop all Flow control frames from any VSI from being\n\t * transmitted. By doing so we stop a malicious VF from sending out\n\t * PAUSE or PFC frames and potentially controlling traffic for other\n\t * PF/VF VSIs.\n\t * The FW can still send Flow control frames if enabled.\n\t */\n\ti40e_add_filter_to_drop_tx_flow_control_frames(&pf->hw,\n\t\t\t\t\t\t       pf->main_vsi_seid);\n\n\t/* restart the VSIs that were rebuilt and running before the reset */\n\ti40e_pf_unquiesce_all_vsi(pf);\n\n\t/* Release the RTNL lock before we start resetting VFs */\n\tif (!lock_acquired)\n\t\trtnl_unlock();\n\n\t/* Restore promiscuous settings */\n\tret = i40e_set_promiscuous(pf, pf->cur_promisc);\n\tif (ret)\n\t\tdev_warn(&pf->pdev->dev,\n\t\t\t \"Failed to restore promiscuous setting: %s, err %s aq_err %s\\n\",\n\t\t\t pf->cur_promisc ? \"on\" : \"off\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\ti40e_reset_all_vfs(pf, true);\n\n\t/* tell the firmware that we're starting */\n\ti40e_send_version(pf);\n\n\t/* We've already released the lock, so don't do it again */\n\tgoto end_core_reset;\n\nend_unlock:\n\tif (!lock_acquired)\n\t\trtnl_unlock();\nend_core_reset:\n\tclear_bit(__I40E_RESET_FAILED, pf->state);\nclear_recovery:\n\tclear_bit(__I40E_RESET_RECOVERY_PENDING, pf->state);\n\tclear_bit(__I40E_TIMEOUT_RECOVERY_PENDING, pf->state);\n}\n\n/**\n * i40e_reset_and_rebuild - reset and rebuild using a saved config\n * @pf: board private structure\n * @reinit: if the Main VSI needs to re-initialized.\n * @lock_acquired: indicates whether or not the lock has been acquired\n * before this function was called.\n **/\nstatic void i40e_reset_and_rebuild(struct i40e_pf *pf, bool reinit,\n\t\t\t\t   bool lock_acquired)\n{\n\tint ret;\n\t/* Now we wait for GRST to settle out.\n\t * We don't have to delete the VEBs or VSIs from the hw switch\n\t * because the reset will make them disappear.\n\t */\n\tret = i40e_reset(pf);\n\tif (!ret)\n\t\ti40e_rebuild(pf, reinit, lock_acquired);\n}\n\n/**\n * i40e_handle_reset_warning - prep for the PF to reset, reset and rebuild\n * @pf: board private structure\n *\n * Close up the VFs and other things in prep for a Core Reset,\n * then get ready to rebuild the world.\n * @lock_acquired: indicates whether or not the lock has been acquired\n * before this function was called.\n **/\nstatic void i40e_handle_reset_warning(struct i40e_pf *pf, bool lock_acquired)\n{\n\ti40e_prep_for_reset(pf, lock_acquired);\n\ti40e_reset_and_rebuild(pf, false, lock_acquired);\n}\n\n/**\n * i40e_handle_mdd_event\n * @pf: pointer to the PF structure\n *\n * Called from the MDD irq handler to identify possibly malicious vfs\n **/\nstatic void i40e_handle_mdd_event(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tbool mdd_detected = false;\n\tstruct i40e_vf *vf;\n\tu32 reg;\n\tint i;\n\n\tif (!test_bit(__I40E_MDD_EVENT_PENDING, pf->state))\n\t\treturn;\n\n\t/* find what triggered the MDD event */\n\treg = rd32(hw, I40E_GL_MDET_TX);\n\tif (reg & I40E_GL_MDET_TX_VALID_MASK) {\n\t\tu8 pf_num = (reg & I40E_GL_MDET_TX_PF_NUM_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_PF_NUM_SHIFT;\n\t\tu16 vf_num = (reg & I40E_GL_MDET_TX_VF_NUM_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_VF_NUM_SHIFT;\n\t\tu8 event = (reg & I40E_GL_MDET_TX_EVENT_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_EVENT_SHIFT;\n\t\tu16 queue = ((reg & I40E_GL_MDET_TX_QUEUE_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_QUEUE_SHIFT) -\n\t\t\t\tpf->hw.func_caps.base_queue;\n\t\tif (netif_msg_tx_err(pf))\n\t\t\tdev_info(&pf->pdev->dev, \"Malicious Driver Detection event 0x%02x on TX queue %d PF number 0x%02x VF number 0x%02x\\n\",\n\t\t\t\t event, queue, pf_num, vf_num);\n\t\twr32(hw, I40E_GL_MDET_TX, 0xffffffff);\n\t\tmdd_detected = true;\n\t}\n\treg = rd32(hw, I40E_GL_MDET_RX);\n\tif (reg & I40E_GL_MDET_RX_VALID_MASK) {\n\t\tu8 func = (reg & I40E_GL_MDET_RX_FUNCTION_MASK) >>\n\t\t\t\tI40E_GL_MDET_RX_FUNCTION_SHIFT;\n\t\tu8 event = (reg & I40E_GL_MDET_RX_EVENT_MASK) >>\n\t\t\t\tI40E_GL_MDET_RX_EVENT_SHIFT;\n\t\tu16 queue = ((reg & I40E_GL_MDET_RX_QUEUE_MASK) >>\n\t\t\t\tI40E_GL_MDET_RX_QUEUE_SHIFT) -\n\t\t\t\tpf->hw.func_caps.base_queue;\n\t\tif (netif_msg_rx_err(pf))\n\t\t\tdev_info(&pf->pdev->dev, \"Malicious Driver Detection event 0x%02x on RX queue %d of function 0x%02x\\n\",\n\t\t\t\t event, queue, func);\n\t\twr32(hw, I40E_GL_MDET_RX, 0xffffffff);\n\t\tmdd_detected = true;\n\t}\n\n\tif (mdd_detected) {\n\t\treg = rd32(hw, I40E_PF_MDET_TX);\n\t\tif (reg & I40E_PF_MDET_TX_VALID_MASK) {\n\t\t\twr32(hw, I40E_PF_MDET_TX, 0xFFFF);\n\t\t\tdev_dbg(&pf->pdev->dev, \"TX driver issue detected on PF\\n\");\n\t\t}\n\t\treg = rd32(hw, I40E_PF_MDET_RX);\n\t\tif (reg & I40E_PF_MDET_RX_VALID_MASK) {\n\t\t\twr32(hw, I40E_PF_MDET_RX, 0xFFFF);\n\t\t\tdev_dbg(&pf->pdev->dev, \"RX driver issue detected on PF\\n\");\n\t\t}\n\t}\n\n\t/* see if one of the VFs needs its hand slapped */\n\tfor (i = 0; i < pf->num_alloc_vfs && mdd_detected; i++) {\n\t\tvf = &(pf->vf[i]);\n\t\treg = rd32(hw, I40E_VP_MDET_TX(i));\n\t\tif (reg & I40E_VP_MDET_TX_VALID_MASK) {\n\t\t\twr32(hw, I40E_VP_MDET_TX(i), 0xFFFF);\n\t\t\tvf->num_mdd_events++;\n\t\t\tdev_info(&pf->pdev->dev, \"TX driver issue detected on VF %d\\n\",\n\t\t\t\t i);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Use PF Control I/F to re-enable the VF\\n\");\n\t\t\tset_bit(I40E_VF_STATE_DISABLED, &vf->vf_states);\n\t\t}\n\n\t\treg = rd32(hw, I40E_VP_MDET_RX(i));\n\t\tif (reg & I40E_VP_MDET_RX_VALID_MASK) {\n\t\t\twr32(hw, I40E_VP_MDET_RX(i), 0xFFFF);\n\t\t\tvf->num_mdd_events++;\n\t\t\tdev_info(&pf->pdev->dev, \"RX driver issue detected on VF %d\\n\",\n\t\t\t\t i);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Use PF Control I/F to re-enable the VF\\n\");\n\t\t\tset_bit(I40E_VF_STATE_DISABLED, &vf->vf_states);\n\t\t}\n\t}\n\n\t/* re-enable mdd interrupt cause */\n\tclear_bit(__I40E_MDD_EVENT_PENDING, pf->state);\n\treg = rd32(hw, I40E_PFINT_ICR0_ENA);\n\treg |=  I40E_PFINT_ICR0_ENA_MAL_DETECT_MASK;\n\twr32(hw, I40E_PFINT_ICR0_ENA, reg);\n\ti40e_flush(hw);\n}\n\nstatic const char *i40e_tunnel_name(u8 type)\n{\n\tswitch (type) {\n\tcase UDP_TUNNEL_TYPE_VXLAN:\n\t\treturn \"vxlan\";\n\tcase UDP_TUNNEL_TYPE_GENEVE:\n\t\treturn \"geneve\";\n\tdefault:\n\t\treturn \"unknown\";\n\t}\n}\n\n/**\n * i40e_sync_udp_filters - Trigger a sync event for existing UDP filters\n * @pf: board private structure\n **/\nstatic void i40e_sync_udp_filters(struct i40e_pf *pf)\n{\n\tint i;\n\n\t/* loop through and set pending bit for all active UDP filters */\n\tfor (i = 0; i < I40E_MAX_PF_UDP_OFFLOAD_PORTS; i++) {\n\t\tif (pf->udp_ports[i].port)\n\t\t\tpf->pending_udp_bitmap |= BIT_ULL(i);\n\t}\n\n\tset_bit(__I40E_UDP_FILTER_SYNC_PENDING, pf->state);\n}\n\n/**\n * i40e_sync_udp_filters_subtask - Sync the VSI filter list with HW\n * @pf: board private structure\n **/\nstatic void i40e_sync_udp_filters_subtask(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 filter_index, type;\n\tu16 port;\n\tint i;\n\n\tif (!test_and_clear_bit(__I40E_UDP_FILTER_SYNC_PENDING, pf->state))\n\t\treturn;\n\n\t/* acquire RTNL to maintain state of flags and port requests */\n\trtnl_lock();\n\n\tfor (i = 0; i < I40E_MAX_PF_UDP_OFFLOAD_PORTS; i++) {\n\t\tif (pf->pending_udp_bitmap & BIT_ULL(i)) {\n\t\t\tstruct i40e_udp_port_config *udp_port;\n\t\t\ti40e_status ret = 0;\n\n\t\t\tudp_port = &pf->udp_ports[i];\n\t\t\tpf->pending_udp_bitmap &= ~BIT_ULL(i);\n\n\t\t\tport = READ_ONCE(udp_port->port);\n\t\t\ttype = READ_ONCE(udp_port->type);\n\t\t\tfilter_index = READ_ONCE(udp_port->filter_index);\n\n\t\t\t/* release RTNL while we wait on AQ command */\n\t\t\trtnl_unlock();\n\n\t\t\tif (port)\n\t\t\t\tret = i40e_aq_add_udp_tunnel(hw, port,\n\t\t\t\t\t\t\t     type,\n\t\t\t\t\t\t\t     &filter_index,\n\t\t\t\t\t\t\t     NULL);\n\t\t\telse if (filter_index != I40E_UDP_PORT_INDEX_UNUSED)\n\t\t\t\tret = i40e_aq_del_udp_tunnel(hw, filter_index,\n\t\t\t\t\t\t\t     NULL);\n\n\t\t\t/* reacquire RTNL so we can update filter_index */\n\t\t\trtnl_lock();\n\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"%s %s port %d, index %d failed, err %s aq_err %s\\n\",\n\t\t\t\t\t i40e_tunnel_name(type),\n\t\t\t\t\t port ? \"add\" : \"delete\",\n\t\t\t\t\t port,\n\t\t\t\t\t filter_index,\n\t\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\t\tif (port) {\n\t\t\t\t\t/* failed to add, just reset port,\n\t\t\t\t\t * drop pending bit for any deletion\n\t\t\t\t\t */\n\t\t\t\t\tudp_port->port = 0;\n\t\t\t\t\tpf->pending_udp_bitmap &= ~BIT_ULL(i);\n\t\t\t\t}\n\t\t\t} else if (port) {\n\t\t\t\t/* record filter index on success */\n\t\t\t\tudp_port->filter_index = filter_index;\n\t\t\t}\n\t\t}\n\t}\n\n\trtnl_unlock();\n}\n\n/**\n * i40e_service_task - Run the driver's async subtasks\n * @work: pointer to work_struct containing our data\n **/\nstatic void i40e_service_task(struct work_struct *work)\n{\n\tstruct i40e_pf *pf = container_of(work,\n\t\t\t\t\t  struct i40e_pf,\n\t\t\t\t\t  service_task);\n\tunsigned long start_time = jiffies;\n\n\t/* don't bother with service tasks if a reset is in progress */\n\tif (test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state) ||\n\t    test_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn;\n\n\tif (test_and_set_bit(__I40E_SERVICE_SCHED, pf->state))\n\t\treturn;\n\n\tif (!test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\ti40e_detect_recover_hung(pf->vsi[pf->lan_vsi]);\n\t\ti40e_sync_filters_subtask(pf);\n\t\ti40e_reset_subtask(pf);\n\t\ti40e_handle_mdd_event(pf);\n\t\ti40e_vc_process_vflr_event(pf);\n\t\ti40e_watchdog_subtask(pf);\n\t\ti40e_fdir_reinit_subtask(pf);\n\t\tif (test_and_clear_bit(__I40E_CLIENT_RESET, pf->state)) {\n\t\t\t/* Client subtask will reopen next time through. */\n\t\t\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi],\n\t\t\t\t\t\t\t   true);\n\t\t} else {\n\t\t\ti40e_client_subtask(pf);\n\t\t\tif (test_and_clear_bit(__I40E_CLIENT_L2_CHANGE,\n\t\t\t\t\t       pf->state))\n\t\t\t\ti40e_notify_client_of_l2_param_changes(\n\t\t\t\t\t\t\t\tpf->vsi[pf->lan_vsi]);\n\t\t}\n\t\ti40e_sync_filters_subtask(pf);\n\t\ti40e_sync_udp_filters_subtask(pf);\n\t} else {\n\t\ti40e_reset_subtask(pf);\n\t}\n\n\ti40e_clean_adminq_subtask(pf);\n\n\t/* flush memory to make sure state is correct before next watchdog */\n\tsmp_mb__before_atomic();\n\tclear_bit(__I40E_SERVICE_SCHED, pf->state);\n\n\t/* If the tasks have taken longer than one timer cycle or there\n\t * is more work to be done, reschedule the service task now\n\t * rather than wait for the timer to tick again.\n\t */\n\tif (time_after(jiffies, (start_time + pf->service_timer_period)) ||\n\t    test_bit(__I40E_ADMINQ_EVENT_PENDING, pf->state)\t\t ||\n\t    test_bit(__I40E_MDD_EVENT_PENDING, pf->state)\t\t ||\n\t    test_bit(__I40E_VFLR_EVENT_PENDING, pf->state))\n\t\ti40e_service_event_schedule(pf);\n}\n\n/**\n * i40e_service_timer - timer callback\n * @data: pointer to PF struct\n **/\nstatic void i40e_service_timer(struct timer_list *t)\n{\n\tstruct i40e_pf *pf = from_timer(pf, t, service_timer);\n\n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\ti40e_service_event_schedule(pf);\n}\n\n/**\n * i40e_set_num_rings_in_vsi - Determine number of rings in the VSI\n * @vsi: the VSI being configured\n **/\nstatic int i40e_set_num_rings_in_vsi(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tswitch (vsi->type) {\n\tcase I40E_VSI_MAIN:\n\t\tvsi->alloc_queue_pairs = pf->num_lan_qps;\n\t\tif (!vsi->num_tx_desc)\n\t\t\tvsi->num_tx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (!vsi->num_rx_desc)\n\t\t\tvsi->num_rx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\t\tvsi->num_q_vectors = pf->num_lan_msix;\n\t\telse\n\t\t\tvsi->num_q_vectors = 1;\n\n\t\tbreak;\n\n\tcase I40E_VSI_FDIR:\n\t\tvsi->alloc_queue_pairs = 1;\n\t\tvsi->num_tx_desc = ALIGN(I40E_FDIR_RING_COUNT,\n\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tvsi->num_rx_desc = ALIGN(I40E_FDIR_RING_COUNT,\n\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tvsi->num_q_vectors = pf->num_fdsb_msix;\n\t\tbreak;\n\n\tcase I40E_VSI_VMDQ2:\n\t\tvsi->alloc_queue_pairs = pf->num_vmdq_qps;\n\t\tif (!vsi->num_tx_desc)\n\t\t\tvsi->num_tx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (!vsi->num_rx_desc)\n\t\t\tvsi->num_rx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tvsi->num_q_vectors = pf->num_vmdq_msix;\n\t\tbreak;\n\n\tcase I40E_VSI_SRIOV:\n\t\tvsi->alloc_queue_pairs = pf->num_vf_qps;\n\t\tif (!vsi->num_tx_desc)\n\t\t\tvsi->num_tx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (!vsi->num_rx_desc)\n\t\t\tvsi->num_rx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tbreak;\n\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn -ENODATA;\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_alloc_arrays - Allocate queue and vector pointer arrays for the vsi\n * @vsi: VSI pointer\n * @alloc_qvectors: a bool to specify if q_vectors need to be allocated.\n *\n * On error: returns error code (negative)\n * On success: returns 0\n **/\nstatic int i40e_vsi_alloc_arrays(struct i40e_vsi *vsi, bool alloc_qvectors)\n{\n\tstruct i40e_ring **next_rings;\n\tint size;\n\tint ret = 0;\n\n\t/* allocate memory for both Tx, XDP Tx and Rx ring pointers */\n\tsize = sizeof(struct i40e_ring *) * vsi->alloc_queue_pairs *\n\t       (i40e_enabled_xdp_vsi(vsi) ? 3 : 2);\n\tvsi->tx_rings = kzalloc(size, GFP_KERNEL);\n\tif (!vsi->tx_rings)\n\t\treturn -ENOMEM;\n\tnext_rings = vsi->tx_rings + vsi->alloc_queue_pairs;\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tvsi->xdp_rings = next_rings;\n\t\tnext_rings += vsi->alloc_queue_pairs;\n\t}\n\tvsi->rx_rings = next_rings;\n\n\tif (alloc_qvectors) {\n\t\t/* allocate memory for q_vector pointers */\n\t\tsize = sizeof(struct i40e_q_vector *) * vsi->num_q_vectors;\n\t\tvsi->q_vectors = kzalloc(size, GFP_KERNEL);\n\t\tif (!vsi->q_vectors) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_vectors;\n\t\t}\n\t}\n\treturn ret;\n\nerr_vectors:\n\tkfree(vsi->tx_rings);\n\treturn ret;\n}\n\n/**\n * i40e_vsi_mem_alloc - Allocates the next available struct vsi in the PF\n * @pf: board private structure\n * @type: type of VSI\n *\n * On error: returns error code (negative)\n * On success: returns vsi index in PF (positive)\n **/\nstatic int i40e_vsi_mem_alloc(struct i40e_pf *pf, enum i40e_vsi_type type)\n{\n\tint ret = -ENODEV;\n\tstruct i40e_vsi *vsi;\n\tint vsi_idx;\n\tint i;\n\n\t/* Need to protect the allocation of the VSIs at the PF level */\n\tmutex_lock(&pf->switch_mutex);\n\n\t/* VSI list may be fragmented if VSI creation/destruction has\n\t * been happening.  We can afford to do a quick scan to look\n\t * for any free VSIs in the list.\n\t *\n\t * find next empty vsi slot, looping back around if necessary\n\t */\n\ti = pf->next_vsi;\n\twhile (i < pf->num_alloc_vsi && pf->vsi[i])\n\t\ti++;\n\tif (i >= pf->num_alloc_vsi) {\n\t\ti = 0;\n\t\twhile (i < pf->next_vsi && pf->vsi[i])\n\t\t\ti++;\n\t}\n\n\tif (i < pf->num_alloc_vsi && !pf->vsi[i]) {\n\t\tvsi_idx = i;             /* Found one! */\n\t} else {\n\t\tret = -ENODEV;\n\t\tgoto unlock_pf;  /* out of VSI slots! */\n\t}\n\tpf->next_vsi = ++i;\n\n\tvsi = kzalloc(sizeof(*vsi), GFP_KERNEL);\n\tif (!vsi) {\n\t\tret = -ENOMEM;\n\t\tgoto unlock_pf;\n\t}\n\tvsi->type = type;\n\tvsi->back = pf;\n\tset_bit(__I40E_VSI_DOWN, vsi->state);\n\tvsi->flags = 0;\n\tvsi->idx = vsi_idx;\n\tvsi->int_rate_limit = 0;\n\tvsi->rss_table_size = (vsi->type == I40E_VSI_MAIN) ?\n\t\t\t\tpf->rss_table_size : 64;\n\tvsi->netdev_registered = false;\n\tvsi->work_limit = I40E_DEFAULT_IRQ_WORK;\n\thash_init(vsi->mac_filter_hash);\n\tvsi->irqs_ready = false;\n\n\tif (type == I40E_VSI_MAIN) {\n\t\tvsi->af_xdp_zc_qps = bitmap_zalloc(pf->num_lan_qps, GFP_KERNEL);\n\t\tif (!vsi->af_xdp_zc_qps)\n\t\t\tgoto err_rings;\n\t}\n\n\tret = i40e_set_num_rings_in_vsi(vsi);\n\tif (ret)\n\t\tgoto err_rings;\n\n\tret = i40e_vsi_alloc_arrays(vsi, true);\n\tif (ret)\n\t\tgoto err_rings;\n\n\t/* Setup default MSIX irq handler for VSI */\n\ti40e_vsi_setup_irqhandler(vsi, i40e_msix_clean_rings);\n\n\t/* Initialize VSI lock */\n\tspin_lock_init(&vsi->mac_filter_hash_lock);\n\tpf->vsi[vsi_idx] = vsi;\n\tret = vsi_idx;\n\tgoto unlock_pf;\n\nerr_rings:\n\tbitmap_free(vsi->af_xdp_zc_qps);\n\tpf->next_vsi = i - 1;\n\tkfree(vsi);\nunlock_pf:\n\tmutex_unlock(&pf->switch_mutex);\n\treturn ret;\n}\n\n/**\n * i40e_vsi_free_arrays - Free queue and vector pointer arrays for the VSI\n * @vsi: VSI pointer\n * @free_qvectors: a bool to specify if q_vectors need to be freed.\n *\n * On error: returns error code (negative)\n * On success: returns 0\n **/\nstatic void i40e_vsi_free_arrays(struct i40e_vsi *vsi, bool free_qvectors)\n{\n\t/* free the ring and vector containers */\n\tif (free_qvectors) {\n\t\tkfree(vsi->q_vectors);\n\t\tvsi->q_vectors = NULL;\n\t}\n\tkfree(vsi->tx_rings);\n\tvsi->tx_rings = NULL;\n\tvsi->rx_rings = NULL;\n\tvsi->xdp_rings = NULL;\n}\n\n/**\n * i40e_clear_rss_config_user - clear the user configured RSS hash keys\n * and lookup table\n * @vsi: Pointer to VSI structure\n */\nstatic void i40e_clear_rss_config_user(struct i40e_vsi *vsi)\n{\n\tif (!vsi)\n\t\treturn;\n\n\tkfree(vsi->rss_hkey_user);\n\tvsi->rss_hkey_user = NULL;\n\n\tkfree(vsi->rss_lut_user);\n\tvsi->rss_lut_user = NULL;\n}\n\n/**\n * i40e_vsi_clear - Deallocate the VSI provided\n * @vsi: the VSI being un-configured\n **/\nstatic int i40e_vsi_clear(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf;\n\n\tif (!vsi)\n\t\treturn 0;\n\n\tif (!vsi->back)\n\t\tgoto free_vsi;\n\tpf = vsi->back;\n\n\tmutex_lock(&pf->switch_mutex);\n\tif (!pf->vsi[vsi->idx]) {\n\t\tdev_err(&pf->pdev->dev, \"pf->vsi[%d] is NULL, just free vsi[%d](type %d)\\n\",\n\t\t\tvsi->idx, vsi->idx, vsi->type);\n\t\tgoto unlock_vsi;\n\t}\n\n\tif (pf->vsi[vsi->idx] != vsi) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"pf->vsi[%d](type %d) != vsi[%d](type %d): no free!\\n\",\n\t\t\tpf->vsi[vsi->idx]->idx,\n\t\t\tpf->vsi[vsi->idx]->type,\n\t\t\tvsi->idx, vsi->type);\n\t\tgoto unlock_vsi;\n\t}\n\n\t/* updates the PF for this cleared vsi */\n\ti40e_put_lump(pf->qp_pile, vsi->base_queue, vsi->idx);\n\ti40e_put_lump(pf->irq_pile, vsi->base_vector, vsi->idx);\n\n\tbitmap_free(vsi->af_xdp_zc_qps);\n\ti40e_vsi_free_arrays(vsi, true);\n\ti40e_clear_rss_config_user(vsi);\n\n\tpf->vsi[vsi->idx] = NULL;\n\tif (vsi->idx < pf->next_vsi)\n\t\tpf->next_vsi = vsi->idx;\n\nunlock_vsi:\n\tmutex_unlock(&pf->switch_mutex);\nfree_vsi:\n\tkfree(vsi);\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_clear_rings - Deallocates the Rx and Tx rings for the provided VSI\n * @vsi: the VSI being cleaned\n **/\nstatic void i40e_vsi_clear_rings(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\tif (vsi->tx_rings && vsi->tx_rings[0]) {\n\t\tfor (i = 0; i < vsi->alloc_queue_pairs; i++) {\n\t\t\tkfree_rcu(vsi->tx_rings[i], rcu);\n\t\t\tvsi->tx_rings[i] = NULL;\n\t\t\tvsi->rx_rings[i] = NULL;\n\t\t\tif (vsi->xdp_rings)\n\t\t\t\tvsi->xdp_rings[i] = NULL;\n\t\t}\n\t}\n}\n\n/**\n * i40e_alloc_rings - Allocates the Rx and Tx rings for the provided VSI\n * @vsi: the VSI being configured\n **/\nstatic int i40e_alloc_rings(struct i40e_vsi *vsi)\n{\n\tint i, qpv = i40e_enabled_xdp_vsi(vsi) ? 3 : 2;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_ring *ring;\n\n\t/* Set basic values in the rings to be used later during open() */\n\tfor (i = 0; i < vsi->alloc_queue_pairs; i++) {\n\t\t/* allocate space for both Tx and Rx in one shot */\n\t\tring = kcalloc(qpv, sizeof(struct i40e_ring), GFP_KERNEL);\n\t\tif (!ring)\n\t\t\tgoto err_out;\n\n\t\tring->queue_index = i;\n\t\tring->reg_idx = vsi->base_queue + i;\n\t\tring->ring_active = false;\n\t\tring->vsi = vsi;\n\t\tring->netdev = vsi->netdev;\n\t\tring->dev = &pf->pdev->dev;\n\t\tring->count = vsi->num_tx_desc;\n\t\tring->size = 0;\n\t\tring->dcb_tc = 0;\n\t\tif (vsi->back->hw_features & I40E_HW_WB_ON_ITR_CAPABLE)\n\t\t\tring->flags = I40E_TXR_FLAGS_WB_ON_ITR;\n\t\tring->itr_setting = pf->tx_itr_default;\n\t\tvsi->tx_rings[i] = ring++;\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tgoto setup_rx;\n\n\t\tring->queue_index = vsi->alloc_queue_pairs + i;\n\t\tring->reg_idx = vsi->base_queue + ring->queue_index;\n\t\tring->ring_active = false;\n\t\tring->vsi = vsi;\n\t\tring->netdev = NULL;\n\t\tring->dev = &pf->pdev->dev;\n\t\tring->count = vsi->num_tx_desc;\n\t\tring->size = 0;\n\t\tring->dcb_tc = 0;\n\t\tif (vsi->back->hw_features & I40E_HW_WB_ON_ITR_CAPABLE)\n\t\t\tring->flags = I40E_TXR_FLAGS_WB_ON_ITR;\n\t\tset_ring_xdp(ring);\n\t\tring->itr_setting = pf->tx_itr_default;\n\t\tvsi->xdp_rings[i] = ring++;\n\nsetup_rx:\n\t\tring->queue_index = i;\n\t\tring->reg_idx = vsi->base_queue + i;\n\t\tring->ring_active = false;\n\t\tring->vsi = vsi;\n\t\tring->netdev = vsi->netdev;\n\t\tring->dev = &pf->pdev->dev;\n\t\tring->count = vsi->num_rx_desc;\n\t\tring->size = 0;\n\t\tring->dcb_tc = 0;\n\t\tring->itr_setting = pf->rx_itr_default;\n\t\tvsi->rx_rings[i] = ring;\n\t}\n\n\treturn 0;\n\nerr_out:\n\ti40e_vsi_clear_rings(vsi);\n\treturn -ENOMEM;\n}\n\n/**\n * i40e_reserve_msix_vectors - Reserve MSI-X vectors in the kernel\n * @pf: board private structure\n * @vectors: the number of MSI-X vectors to request\n *\n * Returns the number of vectors reserved, or error\n **/\nstatic int i40e_reserve_msix_vectors(struct i40e_pf *pf, int vectors)\n{\n\tvectors = pci_enable_msix_range(pf->pdev, pf->msix_entries,\n\t\t\t\t\tI40E_MIN_MSIX, vectors);\n\tif (vectors < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"MSI-X vector reservation failed: %d\\n\", vectors);\n\t\tvectors = 0;\n\t}\n\n\treturn vectors;\n}\n\n/**\n * i40e_init_msix - Setup the MSIX capability\n * @pf: board private structure\n *\n * Work with the OS to set up the MSIX vectors needed.\n *\n * Returns the number of vectors reserved or negative on failure\n **/\nstatic int i40e_init_msix(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint cpus, extra_vectors;\n\tint vectors_left;\n\tint v_budget, i;\n\tint v_actual;\n\tint iwarp_requested = 0;\n\n\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\treturn -ENODEV;\n\n\t/* The number of vectors we'll request will be comprised of:\n\t *   - Add 1 for \"other\" cause for Admin Queue events, etc.\n\t *   - The number of LAN queue pairs\n\t *\t- Queues being used for RSS.\n\t *\t\tWe don't need as many as max_rss_size vectors.\n\t *\t\tuse rss_size instead in the calculation since that\n\t *\t\tis governed by number of cpus in the system.\n\t *\t- assumes symmetric Tx/Rx pairing\n\t *   - The number of VMDq pairs\n\t *   - The CPU count within the NUMA node if iWARP is enabled\n\t * Once we count this up, try the request.\n\t *\n\t * If we can't get what we want, we'll simplify to nearly nothing\n\t * and try again.  If that still fails, we punt.\n\t */\n\tvectors_left = hw->func_caps.num_msix_vectors;\n\tv_budget = 0;\n\n\t/* reserve one vector for miscellaneous handler */\n\tif (vectors_left) {\n\t\tv_budget++;\n\t\tvectors_left--;\n\t}\n\n\t/* reserve some vectors for the main PF traffic queues. Initially we\n\t * only reserve at most 50% of the available vectors, in the case that\n\t * the number of online CPUs is large. This ensures that we can enable\n\t * extra features as well. Once we've enabled the other features, we\n\t * will use any remaining vectors to reach as close as we can to the\n\t * number of online CPUs.\n\t */\n\tcpus = num_online_cpus();\n\tpf->num_lan_msix = min_t(int, cpus, vectors_left / 2);\n\tvectors_left -= pf->num_lan_msix;\n\n\t/* reserve one vector for sideband flow director */\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\tif (vectors_left) {\n\t\t\tpf->num_fdsb_msix = 1;\n\t\t\tv_budget++;\n\t\t\tvectors_left--;\n\t\t} else {\n\t\t\tpf->num_fdsb_msix = 0;\n\t\t}\n\t}\n\n\t/* can we reserve enough for iWARP? */\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tiwarp_requested = pf->num_iwarp_msix;\n\n\t\tif (!vectors_left)\n\t\t\tpf->num_iwarp_msix = 0;\n\t\telse if (vectors_left < pf->num_iwarp_msix)\n\t\t\tpf->num_iwarp_msix = 1;\n\t\tv_budget += pf->num_iwarp_msix;\n\t\tvectors_left -= pf->num_iwarp_msix;\n\t}\n\n\t/* any vectors left over go for VMDq support */\n\tif (pf->flags & I40E_FLAG_VMDQ_ENABLED) {\n\t\tif (!vectors_left) {\n\t\t\tpf->num_vmdq_msix = 0;\n\t\t\tpf->num_vmdq_qps = 0;\n\t\t} else {\n\t\t\tint vmdq_vecs_wanted =\n\t\t\t\tpf->num_vmdq_vsis * pf->num_vmdq_qps;\n\t\t\tint vmdq_vecs =\n\t\t\t\tmin_t(int, vectors_left, vmdq_vecs_wanted);\n\n\t\t\t/* if we're short on vectors for what's desired, we limit\n\t\t\t * the queues per vmdq.  If this is still more than are\n\t\t\t * available, the user will need to change the number of\n\t\t\t * queues/vectors used by the PF later with the ethtool\n\t\t\t * channels command\n\t\t\t */\n\t\t\tif (vectors_left < vmdq_vecs_wanted) {\n\t\t\t\tpf->num_vmdq_qps = 1;\n\t\t\t\tvmdq_vecs_wanted = pf->num_vmdq_vsis;\n\t\t\t\tvmdq_vecs = min_t(int,\n\t\t\t\t\t\t  vectors_left,\n\t\t\t\t\t\t  vmdq_vecs_wanted);\n\t\t\t}\n\t\t\tpf->num_vmdq_msix = pf->num_vmdq_qps;\n\n\t\t\tv_budget += vmdq_vecs;\n\t\t\tvectors_left -= vmdq_vecs;\n\t\t}\n\t}\n\n\t/* On systems with a large number of SMP cores, we previously limited\n\t * the number of vectors for num_lan_msix to be at most 50% of the\n\t * available vectors, to allow for other features. Now, we add back\n\t * the remaining vectors. However, we ensure that the total\n\t * num_lan_msix will not exceed num_online_cpus(). To do this, we\n\t * calculate the number of vectors we can add without going over the\n\t * cap of CPUs. For systems with a small number of CPUs this will be\n\t * zero.\n\t */\n\textra_vectors = min_t(int, cpus - pf->num_lan_msix, vectors_left);\n\tpf->num_lan_msix += extra_vectors;\n\tvectors_left -= extra_vectors;\n\n\tWARN(vectors_left < 0,\n\t     \"Calculation of remaining vectors underflowed. This is an accounting bug when determining total MSI-X vectors.\\n\");\n\n\tv_budget += pf->num_lan_msix;\n\tpf->msix_entries = kcalloc(v_budget, sizeof(struct msix_entry),\n\t\t\t\t   GFP_KERNEL);\n\tif (!pf->msix_entries)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < v_budget; i++)\n\t\tpf->msix_entries[i].entry = i;\n\tv_actual = i40e_reserve_msix_vectors(pf, v_budget);\n\n\tif (v_actual < I40E_MIN_MSIX) {\n\t\tpf->flags &= ~I40E_FLAG_MSIX_ENABLED;\n\t\tkfree(pf->msix_entries);\n\t\tpf->msix_entries = NULL;\n\t\tpci_disable_msix(pf->pdev);\n\t\treturn -ENODEV;\n\n\t} else if (v_actual == I40E_MIN_MSIX) {\n\t\t/* Adjust for minimal MSIX use */\n\t\tpf->num_vmdq_vsis = 0;\n\t\tpf->num_vmdq_qps = 0;\n\t\tpf->num_lan_qps = 1;\n\t\tpf->num_lan_msix = 1;\n\n\t} else if (v_actual != v_budget) {\n\t\t/* If we have limited resources, we will start with no vectors\n\t\t * for the special features and then allocate vectors to some\n\t\t * of these features based on the policy and at the end disable\n\t\t * the features that did not get any vectors.\n\t\t */\n\t\tint vec;\n\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"MSI-X vector limit reached with %d, wanted %d, attempting to redistribute vectors\\n\",\n\t\t\t v_actual, v_budget);\n\t\t/* reserve the misc vector */\n\t\tvec = v_actual - 1;\n\n\t\t/* Scale vector usage down */\n\t\tpf->num_vmdq_msix = 1;    /* force VMDqs to only one vector */\n\t\tpf->num_vmdq_vsis = 1;\n\t\tpf->num_vmdq_qps = 1;\n\n\t\t/* partition out the remaining vectors */\n\t\tswitch (vec) {\n\t\tcase 2:\n\t\t\tpf->num_lan_msix = 1;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\t\t\tpf->num_lan_msix = 1;\n\t\t\t\tpf->num_iwarp_msix = 1;\n\t\t\t} else {\n\t\t\t\tpf->num_lan_msix = 2;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\t\t\tpf->num_iwarp_msix = min_t(int, (vec / 3),\n\t\t\t\t\t\t iwarp_requested);\n\t\t\t\tpf->num_vmdq_vsis = min_t(int, (vec / 3),\n\t\t\t\t\t\t  I40E_DEFAULT_NUM_VMDQ_VSI);\n\t\t\t} else {\n\t\t\t\tpf->num_vmdq_vsis = min_t(int, (vec / 2),\n\t\t\t\t\t\t  I40E_DEFAULT_NUM_VMDQ_VSI);\n\t\t\t}\n\t\t\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\t\t\tpf->num_fdsb_msix = 1;\n\t\t\t\tvec--;\n\t\t\t}\n\t\t\tpf->num_lan_msix = min_t(int,\n\t\t\t       (vec - (pf->num_iwarp_msix + pf->num_vmdq_vsis)),\n\t\t\t\t\t\t\t      pf->num_lan_msix);\n\t\t\tpf->num_lan_qps = pf->num_lan_msix;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif ((pf->flags & I40E_FLAG_FD_SB_ENABLED) &&\n\t    (pf->num_fdsb_msix == 0)) {\n\t\tdev_info(&pf->pdev->dev, \"Sideband Flowdir disabled, not enough MSI-X vectors\\n\");\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t}\n\tif ((pf->flags & I40E_FLAG_VMDQ_ENABLED) &&\n\t    (pf->num_vmdq_msix == 0)) {\n\t\tdev_info(&pf->pdev->dev, \"VMDq disabled, not enough MSI-X vectors\\n\");\n\t\tpf->flags &= ~I40E_FLAG_VMDQ_ENABLED;\n\t}\n\n\tif ((pf->flags & I40E_FLAG_IWARP_ENABLED) &&\n\t    (pf->num_iwarp_msix == 0)) {\n\t\tdev_info(&pf->pdev->dev, \"IWARP disabled, not enough MSI-X vectors\\n\");\n\t\tpf->flags &= ~I40E_FLAG_IWARP_ENABLED;\n\t}\n\ti40e_debug(&pf->hw, I40E_DEBUG_INIT,\n\t\t   \"MSI-X vector distribution: PF %d, VMDq %d, FDSB %d, iWARP %d\\n\",\n\t\t   pf->num_lan_msix,\n\t\t   pf->num_vmdq_msix * pf->num_vmdq_vsis,\n\t\t   pf->num_fdsb_msix,\n\t\t   pf->num_iwarp_msix);\n\n\treturn v_actual;\n}\n\n/**\n * i40e_vsi_alloc_q_vector - Allocate memory for a single interrupt vector\n * @vsi: the VSI being configured\n * @v_idx: index of the vector in the vsi struct\n * @cpu: cpu to be used on affinity_mask\n *\n * We allocate one q_vector.  If allocation fails we return -ENOMEM.\n **/\nstatic int i40e_vsi_alloc_q_vector(struct i40e_vsi *vsi, int v_idx, int cpu)\n{\n\tstruct i40e_q_vector *q_vector;\n\n\t/* allocate q_vector */\n\tq_vector = kzalloc(sizeof(struct i40e_q_vector), GFP_KERNEL);\n\tif (!q_vector)\n\t\treturn -ENOMEM;\n\n\tq_vector->vsi = vsi;\n\tq_vector->v_idx = v_idx;\n\tcpumask_copy(&q_vector->affinity_mask, cpu_possible_mask);\n\n\tif (vsi->netdev)\n\t\tnetif_napi_add(vsi->netdev, &q_vector->napi,\n\t\t\t       i40e_napi_poll, NAPI_POLL_WEIGHT);\n\n\t/* tie q_vector and vsi together */\n\tvsi->q_vectors[v_idx] = q_vector;\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_alloc_q_vectors - Allocate memory for interrupt vectors\n * @vsi: the VSI being configured\n *\n * We allocate one q_vector per queue interrupt.  If allocation fails we\n * return -ENOMEM.\n **/\nstatic int i40e_vsi_alloc_q_vectors(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint err, v_idx, num_q_vectors, current_cpu;\n\n\t/* if not MSIX, give the one vector only to the LAN VSI */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\tnum_q_vectors = vsi->num_q_vectors;\n\telse if (vsi == pf->vsi[pf->lan_vsi])\n\t\tnum_q_vectors = 1;\n\telse\n\t\treturn -EINVAL;\n\n\tcurrent_cpu = cpumask_first(cpu_online_mask);\n\n\tfor (v_idx = 0; v_idx < num_q_vectors; v_idx++) {\n\t\terr = i40e_vsi_alloc_q_vector(vsi, v_idx, current_cpu);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t\tcurrent_cpu = cpumask_next(current_cpu, cpu_online_mask);\n\t\tif (unlikely(current_cpu >= nr_cpu_ids))\n\t\t\tcurrent_cpu = cpumask_first(cpu_online_mask);\n\t}\n\n\treturn 0;\n\nerr_out:\n\twhile (v_idx--)\n\t\ti40e_free_q_vector(vsi, v_idx);\n\n\treturn err;\n}\n\n/**\n * i40e_init_interrupt_scheme - Determine proper interrupt scheme\n * @pf: board private structure to initialize\n **/\nstatic int i40e_init_interrupt_scheme(struct i40e_pf *pf)\n{\n\tint vectors = 0;\n\tssize_t size;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tvectors = i40e_init_msix(pf);\n\t\tif (vectors < 0) {\n\t\t\tpf->flags &= ~(I40E_FLAG_MSIX_ENABLED\t|\n\t\t\t\t       I40E_FLAG_IWARP_ENABLED\t|\n\t\t\t\t       I40E_FLAG_RSS_ENABLED\t|\n\t\t\t\t       I40E_FLAG_DCB_CAPABLE\t|\n\t\t\t\t       I40E_FLAG_DCB_ENABLED\t|\n\t\t\t\t       I40E_FLAG_SRIOV_ENABLED\t|\n\t\t\t\t       I40E_FLAG_FD_SB_ENABLED\t|\n\t\t\t\t       I40E_FLAG_FD_ATR_ENABLED\t|\n\t\t\t\t       I40E_FLAG_VMDQ_ENABLED);\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\n\t\t\t/* rework the queue expectations without MSIX */\n\t\t\ti40e_determine_queue_usage(pf);\n\t\t}\n\t}\n\n\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED) &&\n\t    (pf->flags & I40E_FLAG_MSI_ENABLED)) {\n\t\tdev_info(&pf->pdev->dev, \"MSI-X not available, trying MSI\\n\");\n\t\tvectors = pci_enable_msi(pf->pdev);\n\t\tif (vectors < 0) {\n\t\t\tdev_info(&pf->pdev->dev, \"MSI init failed - %d\\n\",\n\t\t\t\t vectors);\n\t\t\tpf->flags &= ~I40E_FLAG_MSI_ENABLED;\n\t\t}\n\t\tvectors = 1;  /* one MSI or Legacy vector */\n\t}\n\n\tif (!(pf->flags & (I40E_FLAG_MSIX_ENABLED | I40E_FLAG_MSI_ENABLED)))\n\t\tdev_info(&pf->pdev->dev, \"MSI-X and MSI not available, falling back to Legacy IRQ\\n\");\n\n\t/* set up vector assignment tracking */\n\tsize = sizeof(struct i40e_lump_tracking) + (sizeof(u16) * vectors);\n\tpf->irq_pile = kzalloc(size, GFP_KERNEL);\n\tif (!pf->irq_pile)\n\t\treturn -ENOMEM;\n\n\tpf->irq_pile->num_entries = vectors;\n\tpf->irq_pile->search_hint = 0;\n\n\t/* track first vector for misc interrupts, ignore return */\n\t(void)i40e_get_lump(pf, pf->irq_pile, 1, I40E_PILE_VALID_BIT - 1);\n\n\treturn 0;\n}\n\n/**\n * i40e_restore_interrupt_scheme - Restore the interrupt scheme\n * @pf: private board data structure\n *\n * Restore the interrupt scheme that was cleared when we suspended the\n * device. This should be called during resume to re-allocate the q_vectors\n * and reacquire IRQs.\n */\nstatic int i40e_restore_interrupt_scheme(struct i40e_pf *pf)\n{\n\tint err, i;\n\n\t/* We cleared the MSI and MSI-X flags when disabling the old interrupt\n\t * scheme. We need to re-enabled them here in order to attempt to\n\t * re-acquire the MSI or MSI-X vectors\n\t */\n\tpf->flags |= (I40E_FLAG_MSIX_ENABLED | I40E_FLAG_MSI_ENABLED);\n\n\terr = i40e_init_interrupt_scheme(pf);\n\tif (err)\n\t\treturn err;\n\n\t/* Now that we've re-acquired IRQs, we need to remap the vectors and\n\t * rings together again.\n\t */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i]) {\n\t\t\terr = i40e_vsi_alloc_q_vectors(pf->vsi[i]);\n\t\t\tif (err)\n\t\t\t\tgoto err_unwind;\n\t\t\ti40e_vsi_map_rings_to_vectors(pf->vsi[i]);\n\t\t}\n\t}\n\n\terr = i40e_setup_misc_vector(pf);\n\tif (err)\n\t\tgoto err_unwind;\n\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED)\n\t\ti40e_client_update_msix_info(pf);\n\n\treturn 0;\n\nerr_unwind:\n\twhile (i--) {\n\t\tif (pf->vsi[i])\n\t\t\ti40e_vsi_free_q_vectors(pf->vsi[i]);\n\t}\n\n\treturn err;\n}\n\n/**\n * i40e_setup_misc_vector_for_recovery_mode - Setup the misc vector to handle\n * non queue events in recovery mode\n * @pf: board private structure\n *\n * This sets up the handler for MSIX 0 or MSI/legacy, which is used to manage\n * the non-queue interrupts, e.g. AdminQ and errors in recovery mode.\n * This is handled differently than in recovery mode since no Tx/Rx resources\n * are being allocated.\n **/\nstatic int i40e_setup_misc_vector_for_recovery_mode(struct i40e_pf *pf)\n{\n\tint err;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\terr = i40e_setup_misc_vector(pf);\n\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"MSI-X misc vector request failed, error %d\\n\",\n\t\t\t\t err);\n\t\t\treturn err;\n\t\t}\n\t} else {\n\t\tu32 flags = pf->flags & I40E_FLAG_MSI_ENABLED ? 0 : IRQF_SHARED;\n\n\t\terr = request_irq(pf->pdev->irq, i40e_intr, flags,\n\t\t\t\t  pf->int_name, pf);\n\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"MSI/legacy misc vector request failed, error %d\\n\",\n\t\t\t\t err);\n\t\t\treturn err;\n\t\t}\n\t\ti40e_enable_misc_int_causes(pf);\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_setup_misc_vector - Setup the misc vector to handle non queue events\n * @pf: board private structure\n *\n * This sets up the handler for MSIX 0, which is used to manage the\n * non-queue interrupts, e.g. AdminQ and errors.  This is not used\n * when in MSI or Legacy interrupt mode.\n **/\nstatic int i40e_setup_misc_vector(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint err = 0;\n\n\t/* Only request the IRQ once, the first time through. */\n\tif (!test_and_set_bit(__I40E_MISC_IRQ_REQUESTED, pf->state)) {\n\t\terr = request_irq(pf->msix_entries[0].vector,\n\t\t\t\t  i40e_intr, 0, pf->int_name, pf);\n\t\tif (err) {\n\t\t\tclear_bit(__I40E_MISC_IRQ_REQUESTED, pf->state);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"request_irq for %s failed: %d\\n\",\n\t\t\t\t pf->int_name, err);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\ti40e_enable_misc_int_causes(pf);\n\n\t/* associate no queues to the misc vector */\n\twr32(hw, I40E_PFINT_LNKLST0, I40E_QUEUE_END_OF_LIST);\n\twr32(hw, I40E_PFINT_ITR0(I40E_RX_ITR), I40E_ITR_8K >> 1);\n\n\ti40e_flush(hw);\n\n\ti40e_irq_dynamic_enable_icr0(pf);\n\n\treturn err;\n}\n\n/**\n * i40e_get_rss_aq - Get RSS keys and lut by using AQ commands\n * @vsi: Pointer to vsi structure\n * @seed: Buffter to store the hash keys\n * @lut: Buffer to store the lookup table entries\n * @lut_size: Size of buffer to store the lookup table entries\n *\n * Return 0 on success, negative on failure\n */\nstatic int i40e_get_rss_aq(struct i40e_vsi *vsi, const u8 *seed,\n\t\t\t   u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret = 0;\n\n\tif (seed) {\n\t\tret = i40e_aq_get_rss_key(hw, vsi->id,\n\t\t\t(struct i40e_aqc_get_set_rss_key_data *)seed);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot get RSS key, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (lut) {\n\t\tbool pf_lut = vsi->type == I40E_VSI_MAIN ? true : false;\n\n\t\tret = i40e_aq_get_rss_lut(hw, vsi->id, pf_lut, lut, lut_size);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot get RSS lut, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_config_rss_reg - Configure RSS keys and lut by writing registers\n * @vsi: Pointer to vsi structure\n * @seed: RSS hash seed\n * @lut: Lookup table\n * @lut_size: Lookup table size\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_config_rss_reg(struct i40e_vsi *vsi, const u8 *seed,\n\t\t\t       const u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 vf_id = vsi->vf_id;\n\tu8 i;\n\n\t/* Fill out hash function seed */\n\tif (seed) {\n\t\tu32 *seed_dw = (u32 *)seed;\n\n\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\tfor (i = 0; i <= I40E_PFQF_HKEY_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_PFQF_HKEY(i), seed_dw[i]);\n\t\t} else if (vsi->type == I40E_VSI_SRIOV) {\n\t\t\tfor (i = 0; i <= I40E_VFQF_HKEY1_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_VFQF_HKEY1(i, vf_id), seed_dw[i]);\n\t\t} else {\n\t\t\tdev_err(&pf->pdev->dev, \"Cannot set RSS seed - invalid VSI type\\n\");\n\t\t}\n\t}\n\n\tif (lut) {\n\t\tu32 *lut_dw = (u32 *)lut;\n\n\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\tif (lut_size != I40E_HLUT_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\t\t\tfor (i = 0; i <= I40E_PFQF_HLUT_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_PFQF_HLUT(i), lut_dw[i]);\n\t\t} else if (vsi->type == I40E_VSI_SRIOV) {\n\t\t\tif (lut_size != I40E_VF_HLUT_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\t\t\tfor (i = 0; i <= I40E_VFQF_HLUT_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_VFQF_HLUT1(i, vf_id), lut_dw[i]);\n\t\t} else {\n\t\t\tdev_err(&pf->pdev->dev, \"Cannot set RSS LUT - invalid VSI type\\n\");\n\t\t}\n\t}\n\ti40e_flush(hw);\n\n\treturn 0;\n}\n\n/**\n * i40e_get_rss_reg - Get the RSS keys and lut by reading registers\n * @vsi: Pointer to VSI structure\n * @seed: Buffer to store the keys\n * @lut: Buffer to store the lookup table entries\n * @lut_size: Size of buffer to store the lookup table entries\n *\n * Returns 0 on success, negative on failure\n */\nstatic int i40e_get_rss_reg(struct i40e_vsi *vsi, u8 *seed,\n\t\t\t    u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 i;\n\n\tif (seed) {\n\t\tu32 *seed_dw = (u32 *)seed;\n\n\t\tfor (i = 0; i <= I40E_PFQF_HKEY_MAX_INDEX; i++)\n\t\t\tseed_dw[i] = i40e_read_rx_ctl(hw, I40E_PFQF_HKEY(i));\n\t}\n\tif (lut) {\n\t\tu32 *lut_dw = (u32 *)lut;\n\n\t\tif (lut_size != I40E_HLUT_ARRAY_SIZE)\n\t\t\treturn -EINVAL;\n\t\tfor (i = 0; i <= I40E_PFQF_HLUT_MAX_INDEX; i++)\n\t\t\tlut_dw[i] = rd32(hw, I40E_PFQF_HLUT(i));\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_config_rss - Configure RSS keys and lut\n * @vsi: Pointer to VSI structure\n * @seed: RSS hash seed\n * @lut: Lookup table\n * @lut_size: Lookup table size\n *\n * Returns 0 on success, negative on failure\n */\nint i40e_config_rss(struct i40e_vsi *vsi, u8 *seed, u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (pf->hw_features & I40E_HW_RSS_AQ_CAPABLE)\n\t\treturn i40e_config_rss_aq(vsi, seed, lut, lut_size);\n\telse\n\t\treturn i40e_config_rss_reg(vsi, seed, lut, lut_size);\n}\n\n/**\n * i40e_get_rss - Get RSS keys and lut\n * @vsi: Pointer to VSI structure\n * @seed: Buffer to store the keys\n * @lut: Buffer to store the lookup table entries\n * @lut_size: Size of buffer to store the lookup table entries\n *\n * Returns 0 on success, negative on failure\n */\nint i40e_get_rss(struct i40e_vsi *vsi, u8 *seed, u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (pf->hw_features & I40E_HW_RSS_AQ_CAPABLE)\n\t\treturn i40e_get_rss_aq(vsi, seed, lut, lut_size);\n\telse\n\t\treturn i40e_get_rss_reg(vsi, seed, lut, lut_size);\n}\n\n/**\n * i40e_fill_rss_lut - Fill the RSS lookup table with default values\n * @pf: Pointer to board private structure\n * @lut: Lookup table\n * @rss_table_size: Lookup table size\n * @rss_size: Range of queue number for hashing\n */\nvoid i40e_fill_rss_lut(struct i40e_pf *pf, u8 *lut,\n\t\t       u16 rss_table_size, u16 rss_size)\n{\n\tu16 i;\n\n\tfor (i = 0; i < rss_table_size; i++)\n\t\tlut[i] = i % rss_size;\n}\n\n/**\n * i40e_pf_config_rss - Prepare for RSS if used\n * @pf: board private structure\n **/\nstatic int i40e_pf_config_rss(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tu8 seed[I40E_HKEY_ARRAY_SIZE];\n\tu8 *lut;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 reg_val;\n\tu64 hena;\n\tint ret;\n\n\t/* By default we enable TCP/UDP with IPv4/IPv6 ptypes */\n\thena = (u64)i40e_read_rx_ctl(hw, I40E_PFQF_HENA(0)) |\n\t\t((u64)i40e_read_rx_ctl(hw, I40E_PFQF_HENA(1)) << 32);\n\thena |= i40e_pf_get_default_rss_hena(pf);\n\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(0), (u32)hena);\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(1), (u32)(hena >> 32));\n\n\t/* Determine the RSS table size based on the hardware capabilities */\n\treg_val = i40e_read_rx_ctl(hw, I40E_PFQF_CTL_0);\n\treg_val = (pf->rss_table_size == 512) ?\n\t\t\t(reg_val | I40E_PFQF_CTL_0_HASHLUTSIZE_512) :\n\t\t\t(reg_val & ~I40E_PFQF_CTL_0_HASHLUTSIZE_512);\n\ti40e_write_rx_ctl(hw, I40E_PFQF_CTL_0, reg_val);\n\n\t/* Determine the RSS size of the VSI */\n\tif (!vsi->rss_size) {\n\t\tu16 qcount;\n\t\t/* If the firmware does something weird during VSI init, we\n\t\t * could end up with zero TCs. Check for that to avoid\n\t\t * divide-by-zero. It probably won't pass traffic, but it also\n\t\t * won't panic.\n\t\t */\n\t\tqcount = vsi->num_queue_pairs /\n\t\t\t (vsi->tc_config.numtc ? vsi->tc_config.numtc : 1);\n\t\tvsi->rss_size = min_t(int, pf->alloc_rss_size, qcount);\n\t}\n\tif (!vsi->rss_size)\n\t\treturn -EINVAL;\n\n\tlut = kzalloc(vsi->rss_table_size, GFP_KERNEL);\n\tif (!lut)\n\t\treturn -ENOMEM;\n\n\t/* Use user configured lut if there is one, otherwise use default */\n\tif (vsi->rss_lut_user)\n\t\tmemcpy(lut, vsi->rss_lut_user, vsi->rss_table_size);\n\telse\n\t\ti40e_fill_rss_lut(pf, lut, vsi->rss_table_size, vsi->rss_size);\n\n\t/* Use user configured hash key if there is one, otherwise\n\t * use default.\n\t */\n\tif (vsi->rss_hkey_user)\n\t\tmemcpy(seed, vsi->rss_hkey_user, I40E_HKEY_ARRAY_SIZE);\n\telse\n\t\tnetdev_rss_key_fill((void *)seed, I40E_HKEY_ARRAY_SIZE);\n\tret = i40e_config_rss(vsi, seed, lut, vsi->rss_table_size);\n\tkfree(lut);\n\n\treturn ret;\n}\n\n/**\n * i40e_reconfig_rss_queues - change number of queues for rss and rebuild\n * @pf: board private structure\n * @queue_count: the requested queue count for rss.\n *\n * returns 0 if rss is not enabled, if enabled returns the final rss queue\n * count which may be different from the requested queue count.\n * Note: expects to be called while under rtnl_lock()\n **/\nint i40e_reconfig_rss_queues(struct i40e_pf *pf, int queue_count)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tint new_rss_size;\n\n\tif (!(pf->flags & I40E_FLAG_RSS_ENABLED))\n\t\treturn 0;\n\n\tqueue_count = min_t(int, queue_count, num_online_cpus());\n\tnew_rss_size = min_t(int, queue_count, pf->rss_size_max);\n\n\tif (queue_count != vsi->num_queue_pairs) {\n\t\tu16 qcount;\n\n\t\tvsi->req_queue_pairs = queue_count;\n\t\ti40e_prep_for_reset(pf, true);\n\n\t\tpf->alloc_rss_size = new_rss_size;\n\n\t\ti40e_reset_and_rebuild(pf, true, true);\n\n\t\t/* Discard the user configured hash keys and lut, if less\n\t\t * queues are enabled.\n\t\t */\n\t\tif (queue_count < vsi->rss_size) {\n\t\t\ti40e_clear_rss_config_user(vsi);\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"discard user configured hash keys and lut\\n\");\n\t\t}\n\n\t\t/* Reset vsi->rss_size, as number of enabled queues changed */\n\t\tqcount = vsi->num_queue_pairs / vsi->tc_config.numtc;\n\t\tvsi->rss_size = min_t(int, pf->alloc_rss_size, qcount);\n\n\t\ti40e_pf_config_rss(pf);\n\t}\n\tdev_info(&pf->pdev->dev, \"User requested queue count/HW max RSS count:  %d/%d\\n\",\n\t\t vsi->req_queue_pairs, pf->rss_size_max);\n\treturn pf->alloc_rss_size;\n}\n\n/**\n * i40e_get_partition_bw_setting - Retrieve BW settings for this PF partition\n * @pf: board private structure\n **/\ni40e_status i40e_get_partition_bw_setting(struct i40e_pf *pf)\n{\n\ti40e_status status;\n\tbool min_valid, max_valid;\n\tu32 max_bw, min_bw;\n\n\tstatus = i40e_read_bw_from_alt_ram(&pf->hw, &max_bw, &min_bw,\n\t\t\t\t\t   &min_valid, &max_valid);\n\n\tif (!status) {\n\t\tif (min_valid)\n\t\t\tpf->min_bw = min_bw;\n\t\tif (max_valid)\n\t\t\tpf->max_bw = max_bw;\n\t}\n\n\treturn status;\n}\n\n/**\n * i40e_set_partition_bw_setting - Set BW settings for this PF partition\n * @pf: board private structure\n **/\ni40e_status i40e_set_partition_bw_setting(struct i40e_pf *pf)\n{\n\tstruct i40e_aqc_configure_partition_bw_data bw_data;\n\ti40e_status status;\n\n\t/* Set the valid bit for this PF */\n\tbw_data.pf_valid_bits = cpu_to_le16(BIT(pf->hw.pf_id));\n\tbw_data.max_bw[pf->hw.pf_id] = pf->max_bw & I40E_ALT_BW_VALUE_MASK;\n\tbw_data.min_bw[pf->hw.pf_id] = pf->min_bw & I40E_ALT_BW_VALUE_MASK;\n\n\t/* Set the new bandwidths */\n\tstatus = i40e_aq_configure_partition_bw(&pf->hw, &bw_data, NULL);\n\n\treturn status;\n}\n\n/**\n * i40e_commit_partition_bw_setting - Commit BW settings for this PF partition\n * @pf: board private structure\n **/\ni40e_status i40e_commit_partition_bw_setting(struct i40e_pf *pf)\n{\n\t/* Commit temporary BW setting to permanent NVM image */\n\tenum i40e_admin_queue_err last_aq_status;\n\ti40e_status ret;\n\tu16 nvm_word;\n\n\tif (pf->hw.partition_id != 1) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Commit BW only works on partition 1! This is partition %d\",\n\t\t\t pf->hw.partition_id);\n\t\tret = I40E_NOT_SUPPORTED;\n\t\tgoto bw_commit_out;\n\t}\n\n\t/* Acquire NVM for read access */\n\tret = i40e_acquire_nvm(&pf->hw, I40E_RESOURCE_READ);\n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Cannot acquire NVM for read access, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\tgoto bw_commit_out;\n\t}\n\n\t/* Read word 0x10 of NVM - SW compatibility word 1 */\n\tret = i40e_aq_read_nvm(&pf->hw,\n\t\t\t       I40E_SR_NVM_CONTROL_WORD,\n\t\t\t       0x10, sizeof(nvm_word), &nvm_word,\n\t\t\t       false, NULL);\n\t/* Save off last admin queue command status before releasing\n\t * the NVM\n\t */\n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\ti40e_release_nvm(&pf->hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"NVM read error, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\tgoto bw_commit_out;\n\t}\n\n\t/* Wait a bit for NVM release to complete */\n\tmsleep(50);\n\n\t/* Acquire NVM for write access */\n\tret = i40e_acquire_nvm(&pf->hw, I40E_RESOURCE_WRITE);\n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Cannot acquire NVM for write access, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\tgoto bw_commit_out;\n\t}\n\t/* Write it back out unchanged to initiate update NVM,\n\t * which will force a write of the shadow (alt) RAM to\n\t * the NVM - thus storing the bandwidth values permanently.\n\t */\n\tret = i40e_aq_update_nvm(&pf->hw,\n\t\t\t\t I40E_SR_NVM_CONTROL_WORD,\n\t\t\t\t 0x10, sizeof(nvm_word),\n\t\t\t\t &nvm_word, true, 0, NULL);\n\t/* Save off last admin queue command status before releasing\n\t * the NVM\n\t */\n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\ti40e_release_nvm(&pf->hw);\n\tif (ret)\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"BW settings NOT SAVED, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\nbw_commit_out:\n\n\treturn ret;\n}\n\n/**\n * i40e_sw_init - Initialize general software structures (struct i40e_pf)\n * @pf: board private structure to initialize\n *\n * i40e_sw_init initializes the Adapter private data structure.\n * Fields are initialized based on PCI device information and\n * OS network device settings (MTU size).\n **/\nstatic int i40e_sw_init(struct i40e_pf *pf)\n{\n\tint err = 0;\n\tint size;\n\n\t/* Set default capability flags */\n\tpf->flags = I40E_FLAG_RX_CSUM_ENABLED |\n\t\t    I40E_FLAG_MSI_ENABLED     |\n\t\t    I40E_FLAG_MSIX_ENABLED;\n\n\t/* Set default ITR */\n\tpf->rx_itr_default = I40E_ITR_RX_DEF;\n\tpf->tx_itr_default = I40E_ITR_TX_DEF;\n\n\t/* Depending on PF configurations, it is possible that the RSS\n\t * maximum might end up larger than the available queues\n\t */\n\tpf->rss_size_max = BIT(pf->hw.func_caps.rss_table_entry_width);\n\tpf->alloc_rss_size = 1;\n\tpf->rss_table_size = pf->hw.func_caps.rss_table_size;\n\tpf->rss_size_max = min_t(int, pf->rss_size_max,\n\t\t\t\t pf->hw.func_caps.num_tx_qp);\n\tif (pf->hw.func_caps.rss) {\n\t\tpf->flags |= I40E_FLAG_RSS_ENABLED;\n\t\tpf->alloc_rss_size = min_t(int, pf->rss_size_max,\n\t\t\t\t\t   num_online_cpus());\n\t}\n\n\t/* MFP mode enabled */\n\tif (pf->hw.func_caps.npar_enable || pf->hw.func_caps.flex10_enable) {\n\t\tpf->flags |= I40E_FLAG_MFP_ENABLED;\n\t\tdev_info(&pf->pdev->dev, \"MFP mode Enabled\\n\");\n\t\tif (i40e_get_partition_bw_setting(pf)) {\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"Could not get partition bw settings\\n\");\n\t\t} else {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Partition BW Min = %8.8x, Max = %8.8x\\n\",\n\t\t\t\t pf->min_bw, pf->max_bw);\n\n\t\t\t/* nudge the Tx scheduler */\n\t\t\ti40e_set_partition_bw_setting(pf);\n\t\t}\n\t}\n\n\tif ((pf->hw.func_caps.fd_filters_guaranteed > 0) ||\n\t    (pf->hw.func_caps.fd_filters_best_effort > 0)) {\n\t\tpf->flags |= I40E_FLAG_FD_ATR_ENABLED;\n\t\tpf->atr_sample_rate = I40E_DEFAULT_ATR_SAMPLE_RATE;\n\t\tif (pf->flags & I40E_FLAG_MFP_ENABLED &&\n\t\t    pf->hw.num_partitions > 1)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Flow Director Sideband mode Disabled in MFP mode\\n\");\n\t\telse\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\tpf->fdir_pf_filter_count =\n\t\t\t\t pf->hw.func_caps.fd_filters_guaranteed;\n\t\tpf->hw.fdir_shared_filter_count =\n\t\t\t\t pf->hw.func_caps.fd_filters_best_effort;\n\t}\n\n\tif (pf->hw.mac.type == I40E_MAC_X722) {\n\t\tpf->hw_features |= (I40E_HW_RSS_AQ_CAPABLE |\n\t\t\t\t    I40E_HW_128_QP_RSS_CAPABLE |\n\t\t\t\t    I40E_HW_ATR_EVICT_CAPABLE |\n\t\t\t\t    I40E_HW_WB_ON_ITR_CAPABLE |\n\t\t\t\t    I40E_HW_MULTIPLE_TCP_UDP_RSS_PCTYPE |\n\t\t\t\t    I40E_HW_NO_PCI_LINK_CHECK |\n\t\t\t\t    I40E_HW_USE_SET_LLDP_MIB |\n\t\t\t\t    I40E_HW_GENEVE_OFFLOAD_CAPABLE |\n\t\t\t\t    I40E_HW_PTP_L4_CAPABLE |\n\t\t\t\t    I40E_HW_WOL_MC_MAGIC_PKT_WAKE |\n\t\t\t\t    I40E_HW_OUTER_UDP_CSUM_CAPABLE);\n\n#define I40E_FDEVICT_PCTYPE_DEFAULT 0xc03\n\t\tif (rd32(&pf->hw, I40E_GLQF_FDEVICTENA(1)) !=\n\t\t    I40E_FDEVICT_PCTYPE_DEFAULT) {\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"FD EVICT PCTYPES are not right, disable FD HW EVICT\\n\");\n\t\t\tpf->hw_features &= ~I40E_HW_ATR_EVICT_CAPABLE;\n\t\t}\n\t} else if ((pf->hw.aq.api_maj_ver > 1) ||\n\t\t   ((pf->hw.aq.api_maj_ver == 1) &&\n\t\t    (pf->hw.aq.api_min_ver > 4))) {\n\t\t/* Supported in FW API version higher than 1.4 */\n\t\tpf->hw_features |= I40E_HW_GENEVE_OFFLOAD_CAPABLE;\n\t}\n\n\t/* Enable HW ATR eviction if possible */\n\tif (pf->hw_features & I40E_HW_ATR_EVICT_CAPABLE)\n\t\tpf->flags |= I40E_FLAG_HW_ATR_EVICT_ENABLED;\n\n\tif ((pf->hw.mac.type == I40E_MAC_XL710) &&\n\t    (((pf->hw.aq.fw_maj_ver == 4) && (pf->hw.aq.fw_min_ver < 33)) ||\n\t    (pf->hw.aq.fw_maj_ver < 4))) {\n\t\tpf->hw_features |= I40E_HW_RESTART_AUTONEG;\n\t\t/* No DCB support  for FW < v4.33 */\n\t\tpf->hw_features |= I40E_HW_NO_DCB_SUPPORT;\n\t}\n\n\t/* Disable FW LLDP if FW < v4.3 */\n\tif ((pf->hw.mac.type == I40E_MAC_XL710) &&\n\t    (((pf->hw.aq.fw_maj_ver == 4) && (pf->hw.aq.fw_min_ver < 3)) ||\n\t    (pf->hw.aq.fw_maj_ver < 4)))\n\t\tpf->hw_features |= I40E_HW_STOP_FW_LLDP;\n\n\t/* Use the FW Set LLDP MIB API if FW > v4.40 */\n\tif ((pf->hw.mac.type == I40E_MAC_XL710) &&\n\t    (((pf->hw.aq.fw_maj_ver == 4) && (pf->hw.aq.fw_min_ver >= 40)) ||\n\t    (pf->hw.aq.fw_maj_ver >= 5)))\n\t\tpf->hw_features |= I40E_HW_USE_SET_LLDP_MIB;\n\n\t/* Enable PTP L4 if FW > v6.0 */\n\tif (pf->hw.mac.type == I40E_MAC_XL710 &&\n\t    pf->hw.aq.fw_maj_ver >= 6)\n\t\tpf->hw_features |= I40E_HW_PTP_L4_CAPABLE;\n\n\tif (pf->hw.func_caps.vmdq && num_online_cpus() != 1) {\n\t\tpf->num_vmdq_vsis = I40E_DEFAULT_NUM_VMDQ_VSI;\n\t\tpf->flags |= I40E_FLAG_VMDQ_ENABLED;\n\t\tpf->num_vmdq_qps = i40e_default_queues_per_vmdq(pf);\n\t}\n\n\tif (pf->hw.func_caps.iwarp && num_online_cpus() != 1) {\n\t\tpf->flags |= I40E_FLAG_IWARP_ENABLED;\n\t\t/* IWARP needs one extra vector for CQP just like MISC.*/\n\t\tpf->num_iwarp_msix = (int)num_online_cpus() + 1;\n\t}\n\t/* Stopping FW LLDP engine is supported on XL710 and X722\n\t * starting from FW versions determined in i40e_init_adminq.\n\t * Stopping the FW LLDP engine is not supported on XL710\n\t * if NPAR is functioning so unset this hw flag in this case.\n\t */\n\tif (pf->hw.mac.type == I40E_MAC_XL710 &&\n\t    pf->hw.func_caps.npar_enable &&\n\t    (pf->hw.flags & I40E_HW_FLAG_FW_LLDP_STOPPABLE))\n\t\tpf->hw.flags &= ~I40E_HW_FLAG_FW_LLDP_STOPPABLE;\n\n#ifdef CONFIG_PCI_IOV\n\tif (pf->hw.func_caps.num_vfs && pf->hw.partition_id == 1) {\n\t\tpf->num_vf_qps = I40E_DEFAULT_QUEUES_PER_VF;\n\t\tpf->flags |= I40E_FLAG_SRIOV_ENABLED;\n\t\tpf->num_req_vfs = min_t(int,\n\t\t\t\t\tpf->hw.func_caps.num_vfs,\n\t\t\t\t\tI40E_MAX_VF_COUNT);\n\t}\n#endif /* CONFIG_PCI_IOV */\n\tpf->eeprom_version = 0xDEAD;\n\tpf->lan_veb = I40E_NO_VEB;\n\tpf->lan_vsi = I40E_NO_VSI;\n\n\t/* By default FW has this off for performance reasons */\n\tpf->flags &= ~I40E_FLAG_VEB_STATS_ENABLED;\n\n\t/* set up queue assignment tracking */\n\tsize = sizeof(struct i40e_lump_tracking)\n\t\t+ (sizeof(u16) * pf->hw.func_caps.num_tx_qp);\n\tpf->qp_pile = kzalloc(size, GFP_KERNEL);\n\tif (!pf->qp_pile) {\n\t\terr = -ENOMEM;\n\t\tgoto sw_init_done;\n\t}\n\tpf->qp_pile->num_entries = pf->hw.func_caps.num_tx_qp;\n\tpf->qp_pile->search_hint = 0;\n\n\tpf->tx_timeout_recovery_level = 1;\n\n\tmutex_init(&pf->switch_mutex);\n\nsw_init_done:\n\treturn err;\n}\n\n/**\n * i40e_set_ntuple - set the ntuple feature flag and take action\n * @pf: board private structure to initialize\n * @features: the feature set that the stack is suggesting\n *\n * returns a bool to indicate if reset needs to happen\n **/\nbool i40e_set_ntuple(struct i40e_pf *pf, netdev_features_t features)\n{\n\tbool need_reset = false;\n\n\t/* Check if Flow Director n-tuple support was enabled or disabled.  If\n\t * the state changed, we need to reset.\n\t */\n\tif (features & NETIF_F_NTUPLE) {\n\t\t/* Enable filters and mark for reset */\n\t\tif (!(pf->flags & I40E_FLAG_FD_SB_ENABLED))\n\t\t\tneed_reset = true;\n\t\t/* enable FD_SB only if there is MSI-X vector and no cloud\n\t\t * filters exist\n\t\t */\n\t\tif (pf->num_fdsb_msix > 0 && !pf->num_cloud_filters) {\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_INACTIVE;\n\t\t}\n\t} else {\n\t\t/* turn off filters, mark for reset and clear SW filter list */\n\t\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\t\tneed_reset = true;\n\t\t\ti40e_fdir_filter_exit(pf);\n\t\t}\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\tclear_bit(__I40E_FD_SB_AUTO_DISABLED, pf->state);\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\n\t\t/* reset fd counters */\n\t\tpf->fd_add_err = 0;\n\t\tpf->fd_atr_cnt = 0;\n\t\t/* if ATR was auto disabled it can be re-enabled. */\n\t\tif (test_and_clear_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state))\n\t\t\tif ((pf->flags & I40E_FLAG_FD_ATR_ENABLED) &&\n\t\t\t    (I40E_DEBUG_FD & pf->hw.debug_mask))\n\t\t\t\tdev_info(&pf->pdev->dev, \"ATR re-enabled.\\n\");\n\t}\n\treturn need_reset;\n}\n\n/**\n * i40e_clear_rss_lut - clear the rx hash lookup table\n * @vsi: the VSI being configured\n **/\nstatic void i40e_clear_rss_lut(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 vf_id = vsi->vf_id;\n\tu8 i;\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\tfor (i = 0; i <= I40E_PFQF_HLUT_MAX_INDEX; i++)\n\t\t\twr32(hw, I40E_PFQF_HLUT(i), 0);\n\t} else if (vsi->type == I40E_VSI_SRIOV) {\n\t\tfor (i = 0; i <= I40E_VFQF_HLUT_MAX_INDEX; i++)\n\t\t\ti40e_write_rx_ctl(hw, I40E_VFQF_HLUT1(i, vf_id), 0);\n\t} else {\n\t\tdev_err(&pf->pdev->dev, \"Cannot set RSS LUT - invalid VSI type\\n\");\n\t}\n}\n\n/**\n * i40e_set_features - set the netdev feature flags\n * @netdev: ptr to the netdev being adjusted\n * @features: the feature set that the stack is suggesting\n * Note: expects to be called while under rtnl_lock()\n **/\nstatic int i40e_set_features(struct net_device *netdev,\n\t\t\t     netdev_features_t features)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tbool need_reset;\n\n\tif (features & NETIF_F_RXHASH && !(netdev->features & NETIF_F_RXHASH))\n\t\ti40e_pf_config_rss(pf);\n\telse if (!(features & NETIF_F_RXHASH) &&\n\t\t netdev->features & NETIF_F_RXHASH)\n\t\ti40e_clear_rss_lut(vsi);\n\n\tif (features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\ti40e_vlan_stripping_enable(vsi);\n\telse\n\t\ti40e_vlan_stripping_disable(vsi);\n\n\tif (!(features & NETIF_F_HW_TC) && pf->num_cloud_filters) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Offloaded tc filters active, can't turn hw_tc_offload off\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!(features & NETIF_F_HW_L2FW_DOFFLOAD) && vsi->macvlan_cnt)\n\t\ti40e_del_all_macvlans(vsi);\n\n\tneed_reset = i40e_set_ntuple(pf, features);\n\n\tif (need_reset)\n\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG, true);\n\n\treturn 0;\n}\n\n/**\n * i40e_get_udp_port_idx - Lookup a possibly offloaded for Rx UDP port\n * @pf: board private structure\n * @port: The UDP port to look up\n *\n * Returns the index number or I40E_MAX_PF_UDP_OFFLOAD_PORTS if port not found\n **/\nstatic u8 i40e_get_udp_port_idx(struct i40e_pf *pf, u16 port)\n{\n\tu8 i;\n\n\tfor (i = 0; i < I40E_MAX_PF_UDP_OFFLOAD_PORTS; i++) {\n\t\t/* Do not report ports with pending deletions as\n\t\t * being available.\n\t\t */\n\t\tif (!port && (pf->pending_udp_bitmap & BIT_ULL(i)))\n\t\t\tcontinue;\n\t\tif (pf->udp_ports[i].port == port)\n\t\t\treturn i;\n\t}\n\n\treturn i;\n}\n\n/**\n * i40e_udp_tunnel_add - Get notifications about UDP tunnel ports that come up\n * @netdev: This physical port's netdev\n * @ti: Tunnel endpoint information\n **/\nstatic void i40e_udp_tunnel_add(struct net_device *netdev,\n\t\t\t\tstruct udp_tunnel_info *ti)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tu16 port = ntohs(ti->port);\n\tu8 next_idx;\n\tu8 idx;\n\n\tidx = i40e_get_udp_port_idx(pf, port);\n\n\t/* Check if port already exists */\n\tif (idx < I40E_MAX_PF_UDP_OFFLOAD_PORTS) {\n\t\tnetdev_info(netdev, \"port %d already offloaded\\n\", port);\n\t\treturn;\n\t}\n\n\t/* Now check if there is space to add the new port */\n\tnext_idx = i40e_get_udp_port_idx(pf, 0);\n\n\tif (next_idx == I40E_MAX_PF_UDP_OFFLOAD_PORTS) {\n\t\tnetdev_info(netdev, \"maximum number of offloaded UDP ports reached, not adding port %d\\n\",\n\t\t\t    port);\n\t\treturn;\n\t}\n\n\tswitch (ti->type) {\n\tcase UDP_TUNNEL_TYPE_VXLAN:\n\t\tpf->udp_ports[next_idx].type = I40E_AQC_TUNNEL_TYPE_VXLAN;\n\t\tbreak;\n\tcase UDP_TUNNEL_TYPE_GENEVE:\n\t\tif (!(pf->hw_features & I40E_HW_GENEVE_OFFLOAD_CAPABLE))\n\t\t\treturn;\n\t\tpf->udp_ports[next_idx].type = I40E_AQC_TUNNEL_TYPE_NGE;\n\t\tbreak;\n\tdefault:\n\t\treturn;\n\t}\n\n\t/* New port: add it and mark its index in the bitmap */\n\tpf->udp_ports[next_idx].port = port;\n\tpf->udp_ports[next_idx].filter_index = I40E_UDP_PORT_INDEX_UNUSED;\n\tpf->pending_udp_bitmap |= BIT_ULL(next_idx);\n\tset_bit(__I40E_UDP_FILTER_SYNC_PENDING, pf->state);\n}\n\n/**\n * i40e_udp_tunnel_del - Get notifications about UDP tunnel ports that go away\n * @netdev: This physical port's netdev\n * @ti: Tunnel endpoint information\n **/\nstatic void i40e_udp_tunnel_del(struct net_device *netdev,\n\t\t\t\tstruct udp_tunnel_info *ti)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tu16 port = ntohs(ti->port);\n\tu8 idx;\n\n\tidx = i40e_get_udp_port_idx(pf, port);\n\n\t/* Check if port already exists */\n\tif (idx >= I40E_MAX_PF_UDP_OFFLOAD_PORTS)\n\t\tgoto not_found;\n\n\tswitch (ti->type) {\n\tcase UDP_TUNNEL_TYPE_VXLAN:\n\t\tif (pf->udp_ports[idx].type != I40E_AQC_TUNNEL_TYPE_VXLAN)\n\t\t\tgoto not_found;\n\t\tbreak;\n\tcase UDP_TUNNEL_TYPE_GENEVE:\n\t\tif (pf->udp_ports[idx].type != I40E_AQC_TUNNEL_TYPE_NGE)\n\t\t\tgoto not_found;\n\t\tbreak;\n\tdefault:\n\t\tgoto not_found;\n\t}\n\n\t/* if port exists, set it to 0 (mark for deletion)\n\t * and make it pending\n\t */\n\tpf->udp_ports[idx].port = 0;\n\n\t/* Toggle pending bit instead of setting it. This way if we are\n\t * deleting a port that has yet to be added we just clear the pending\n\t * bit and don't have to worry about it.\n\t */\n\tpf->pending_udp_bitmap ^= BIT_ULL(idx);\n\tset_bit(__I40E_UDP_FILTER_SYNC_PENDING, pf->state);\n\n\treturn;\nnot_found:\n\tnetdev_warn(netdev, \"UDP port %d was not found, not deleting\\n\",\n\t\t    port);\n}\n\nstatic int i40e_get_phys_port_id(struct net_device *netdev,\n\t\t\t\t struct netdev_phys_item_id *ppid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_pf *pf = np->vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\tif (!(pf->hw_features & I40E_HW_PORT_ID_VALID))\n\t\treturn -EOPNOTSUPP;\n\n\tppid->id_len = min_t(int, sizeof(hw->mac.port_addr), sizeof(ppid->id));\n\tmemcpy(ppid->id, hw->mac.port_addr, ppid->id_len);\n\n\treturn 0;\n}\n\n/**\n * i40e_ndo_fdb_add - add an entry to the hardware database\n * @ndm: the input from the stack\n * @tb: pointer to array of nladdr (unused)\n * @dev: the net device pointer\n * @addr: the MAC address entry being added\n * @vid: VLAN ID\n * @flags: instructions from stack about fdb operation\n */\nstatic int i40e_ndo_fdb_add(struct ndmsg *ndm, struct nlattr *tb[],\n\t\t\t    struct net_device *dev,\n\t\t\t    const unsigned char *addr, u16 vid,\n\t\t\t    u16 flags,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_pf *pf = np->vsi->back;\n\tint err = 0;\n\n\tif (!(pf->flags & I40E_FLAG_SRIOV_ENABLED))\n\t\treturn -EOPNOTSUPP;\n\n\tif (vid) {\n\t\tpr_info(\"%s: vlans aren't supported yet for dev_uc|mc_add()\\n\", dev->name);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Hardware does not support aging addresses so if a\n\t * ndm_state is given only allow permanent addresses\n\t */\n\tif (ndm->ndm_state && !(ndm->ndm_state & NUD_PERMANENT)) {\n\t\tnetdev_info(dev, \"FDB only supports static addresses\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (is_unicast_ether_addr(addr) || is_link_local_ether_addr(addr))\n\t\terr = dev_uc_add_excl(dev, addr);\n\telse if (is_multicast_ether_addr(addr))\n\t\terr = dev_mc_add_excl(dev, addr);\n\telse\n\t\terr = -EINVAL;\n\n\t/* Only return duplicate errors if NLM_F_EXCL is set */\n\tif (err == -EEXIST && !(flags & NLM_F_EXCL))\n\t\terr = 0;\n\n\treturn err;\n}\n\n/**\n * i40e_ndo_bridge_setlink - Set the hardware bridge mode\n * @dev: the netdev being configured\n * @nlh: RTNL message\n * @flags: bridge flags\n * @extack: netlink extended ack\n *\n * Inserts a new hardware bridge if not already created and\n * enables the bridging mode requested (VEB or VEPA). If the\n * hardware bridge has already been inserted and the request\n * is to change the mode then that requires a PF reset to\n * allow rebuild of the components with required hardware\n * bridge mode enabled.\n *\n * Note: expects to be called while under rtnl_lock()\n **/\nstatic int i40e_ndo_bridge_setlink(struct net_device *dev,\n\t\t\t\t   struct nlmsghdr *nlh,\n\t\t\t\t   u16 flags,\n\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_veb *veb = NULL;\n\tstruct nlattr *attr, *br_spec;\n\tint i, rem;\n\n\t/* Only for PF VSI for now */\n\tif (vsi->seid != pf->vsi[pf->lan_vsi]->seid)\n\t\treturn -EOPNOTSUPP;\n\n\t/* Find the HW bridge for PF VSI */\n\tfor (i = 0; i < I40E_MAX_VEB && !veb; i++) {\n\t\tif (pf->veb[i] && pf->veb[i]->seid == vsi->uplink_seid)\n\t\t\tveb = pf->veb[i];\n\t}\n\n\tbr_spec = nlmsg_find_attr(nlh, sizeof(struct ifinfomsg), IFLA_AF_SPEC);\n\n\tnla_for_each_nested(attr, br_spec, rem) {\n\t\t__u16 mode;\n\n\t\tif (nla_type(attr) != IFLA_BRIDGE_MODE)\n\t\t\tcontinue;\n\n\t\tmode = nla_get_u16(attr);\n\t\tif ((mode != BRIDGE_MODE_VEPA) &&\n\t\t    (mode != BRIDGE_MODE_VEB))\n\t\t\treturn -EINVAL;\n\n\t\t/* Insert a new HW bridge */\n\t\tif (!veb) {\n\t\t\tveb = i40e_veb_setup(pf, 0, vsi->uplink_seid, vsi->seid,\n\t\t\t\t\t     vsi->tc_config.enabled_tc);\n\t\t\tif (veb) {\n\t\t\t\tveb->bridge_mode = mode;\n\t\t\t\ti40e_config_bridge_mode(veb);\n\t\t\t} else {\n\t\t\t\t/* No Bridge HW offload available */\n\t\t\t\treturn -ENOENT;\n\t\t\t}\n\t\t\tbreak;\n\t\t} else if (mode != veb->bridge_mode) {\n\t\t\t/* Existing HW bridge but different mode needs reset */\n\t\t\tveb->bridge_mode = mode;\n\t\t\t/* TODO: If no VFs or VMDq VSIs, disallow VEB mode */\n\t\t\tif (mode == BRIDGE_MODE_VEB)\n\t\t\t\tpf->flags |= I40E_FLAG_VEB_MODE_ENABLED;\n\t\t\telse\n\t\t\t\tpf->flags &= ~I40E_FLAG_VEB_MODE_ENABLED;\n\t\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG, true);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_ndo_bridge_getlink - Get the hardware bridge mode\n * @skb: skb buff\n * @pid: process id\n * @seq: RTNL message seq #\n * @dev: the netdev being configured\n * @filter_mask: unused\n * @nlflags: netlink flags passed in\n *\n * Return the mode in which the hardware bridge is operating in\n * i.e VEB or VEPA.\n **/\nstatic int i40e_ndo_bridge_getlink(struct sk_buff *skb, u32 pid, u32 seq,\n\t\t\t\t   struct net_device *dev,\n\t\t\t\t   u32 __always_unused filter_mask,\n\t\t\t\t   int nlflags)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_veb *veb = NULL;\n\tint i;\n\n\t/* Only for PF VSI for now */\n\tif (vsi->seid != pf->vsi[pf->lan_vsi]->seid)\n\t\treturn -EOPNOTSUPP;\n\n\t/* Find the HW bridge for the PF VSI */\n\tfor (i = 0; i < I40E_MAX_VEB && !veb; i++) {\n\t\tif (pf->veb[i] && pf->veb[i]->seid == vsi->uplink_seid)\n\t\t\tveb = pf->veb[i];\n\t}\n\n\tif (!veb)\n\t\treturn 0;\n\n\treturn ndo_dflt_bridge_getlink(skb, pid, seq, dev, veb->bridge_mode,\n\t\t\t\t       0, 0, nlflags, filter_mask, NULL);\n}\n\n/**\n * i40e_features_check - Validate encapsulated packet conforms to limits\n * @skb: skb buff\n * @dev: This physical port's netdev\n * @features: Offload features that the stack believes apply\n **/\nstatic netdev_features_t i40e_features_check(struct sk_buff *skb,\n\t\t\t\t\t     struct net_device *dev,\n\t\t\t\t\t     netdev_features_t features)\n{\n\tsize_t len;\n\n\t/* No point in doing any of this if neither checksum nor GSO are\n\t * being requested for this frame.  We can rule out both by just\n\t * checking for CHECKSUM_PARTIAL\n\t */\n\tif (skb->ip_summed != CHECKSUM_PARTIAL)\n\t\treturn features;\n\n\t/* We cannot support GSO if the MSS is going to be less than\n\t * 64 bytes.  If it is then we need to drop support for GSO.\n\t */\n\tif (skb_is_gso(skb) && (skb_shinfo(skb)->gso_size < 64))\n\t\tfeatures &= ~NETIF_F_GSO_MASK;\n\n\t/* MACLEN can support at most 63 words */\n\tlen = skb_network_header(skb) - skb->data;\n\tif (len & ~(63 * 2))\n\t\tgoto out_err;\n\n\t/* IPLEN and EIPLEN can support at most 127 dwords */\n\tlen = skb_transport_header(skb) - skb_network_header(skb);\n\tif (len & ~(127 * 4))\n\t\tgoto out_err;\n\n\tif (skb->encapsulation) {\n\t\t/* L4TUNLEN can support 127 words */\n\t\tlen = skb_inner_network_header(skb) - skb_transport_header(skb);\n\t\tif (len & ~(127 * 2))\n\t\t\tgoto out_err;\n\n\t\t/* IPLEN can support at most 127 dwords */\n\t\tlen = skb_inner_transport_header(skb) -\n\t\t      skb_inner_network_header(skb);\n\t\tif (len & ~(127 * 4))\n\t\t\tgoto out_err;\n\t}\n\n\t/* No need to validate L4LEN as TCP is the only protocol with a\n\t * a flexible value and we support all possible values supported\n\t * by TCP, which is at most 15 dwords\n\t */\n\n\treturn features;\nout_err:\n\treturn features & ~(NETIF_F_CSUM_MASK | NETIF_F_GSO_MASK);\n}\n\n/**\n * i40e_xdp_setup - add/remove an XDP program\n * @vsi: VSI to changed\n * @prog: XDP program\n **/\nstatic int i40e_xdp_setup(struct i40e_vsi *vsi,\n\t\t\t  struct bpf_prog *prog)\n{\n\tint frame_size = vsi->netdev->mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct bpf_prog *old_prog;\n\tbool need_reset;\n\tint i;\n\n\t/* Don't allow frames that span over multiple buffers */\n\tif (frame_size > vsi->rx_buf_len)\n\t\treturn -EINVAL;\n\n\tif (!i40e_enabled_xdp_vsi(vsi) && !prog)\n\t\treturn 0;\n\n\t/* When turning XDP on->off/off->on we reset and rebuild the rings. */\n\tneed_reset = (i40e_enabled_xdp_vsi(vsi) != !!prog);\n\n\tif (need_reset)\n\t\ti40e_prep_for_reset(pf, true);\n\n\told_prog = xchg(&vsi->xdp_prog, prog);\n\n\tif (need_reset)\n\t\ti40e_reset_and_rebuild(pf, true, true);\n\n\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\tWRITE_ONCE(vsi->rx_rings[i]->xdp_prog, vsi->xdp_prog);\n\n\tif (old_prog)\n\t\tbpf_prog_put(old_prog);\n\n\t/* Kick start the NAPI context if there is an AF_XDP socket open\n\t * on that queue id. This so that receiving will start.\n\t */\n\tif (need_reset && prog)\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tif (vsi->xdp_rings[i]->xsk_umem)\n\t\t\t\t(void)i40e_xsk_wakeup(vsi->netdev, i,\n\t\t\t\t\t\t      XDP_WAKEUP_RX);\n\n\treturn 0;\n}\n\n/**\n * i40e_enter_busy_conf - Enters busy config state\n * @vsi: vsi\n *\n * Returns 0 on success, <0 for failure.\n **/\nstatic int i40e_enter_busy_conf(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint timeout = 50;\n\n\twhile (test_and_set_bit(__I40E_CONFIG_BUSY, pf->state)) {\n\t\ttimeout--;\n\t\tif (!timeout)\n\t\t\treturn -EBUSY;\n\t\tusleep_range(1000, 2000);\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_exit_busy_conf - Exits busy config state\n * @vsi: vsi\n **/\nstatic void i40e_exit_busy_conf(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tclear_bit(__I40E_CONFIG_BUSY, pf->state);\n}\n\n/**\n * i40e_queue_pair_reset_stats - Resets all statistics for a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n **/\nstatic void i40e_queue_pair_reset_stats(struct i40e_vsi *vsi, int queue_pair)\n{\n\tmemset(&vsi->rx_rings[queue_pair]->rx_stats, 0,\n\t       sizeof(vsi->rx_rings[queue_pair]->rx_stats));\n\tmemset(&vsi->tx_rings[queue_pair]->stats, 0,\n\t       sizeof(vsi->tx_rings[queue_pair]->stats));\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tmemset(&vsi->xdp_rings[queue_pair]->stats, 0,\n\t\t       sizeof(vsi->xdp_rings[queue_pair]->stats));\n\t}\n}\n\n/**\n * i40e_queue_pair_clean_rings - Cleans all the rings of a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n **/\nstatic void i40e_queue_pair_clean_rings(struct i40e_vsi *vsi, int queue_pair)\n{\n\ti40e_clean_tx_ring(vsi->tx_rings[queue_pair]);\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t/* Make sure that in-progress ndo_xdp_xmit calls are\n\t\t * completed.\n\t\t */\n\t\tsynchronize_rcu();\n\t\ti40e_clean_tx_ring(vsi->xdp_rings[queue_pair]);\n\t}\n\ti40e_clean_rx_ring(vsi->rx_rings[queue_pair]);\n}\n\n/**\n * i40e_queue_pair_toggle_napi - Enables/disables NAPI for a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n * @enable: true for enable, false for disable\n **/\nstatic void i40e_queue_pair_toggle_napi(struct i40e_vsi *vsi, int queue_pair,\n\t\t\t\t\tbool enable)\n{\n\tstruct i40e_ring *rxr = vsi->rx_rings[queue_pair];\n\tstruct i40e_q_vector *q_vector = rxr->q_vector;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\t/* All rings in a qp belong to the same qvector. */\n\tif (q_vector->rx.ring || q_vector->tx.ring) {\n\t\tif (enable)\n\t\t\tnapi_enable(&q_vector->napi);\n\t\telse\n\t\t\tnapi_disable(&q_vector->napi);\n\t}\n}\n\n/**\n * i40e_queue_pair_toggle_rings - Enables/disables all rings for a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n * @enable: true for enable, false for disable\n *\n * Returns 0 on success, <0 on failure.\n **/\nstatic int i40e_queue_pair_toggle_rings(struct i40e_vsi *vsi, int queue_pair,\n\t\t\t\t\tbool enable)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint pf_q, ret = 0;\n\n\tpf_q = vsi->base_queue + queue_pair;\n\tret = i40e_control_wait_tx_q(vsi->seid, pf, pf_q,\n\t\t\t\t     false /*is xdp*/, enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d Tx ring %d %sable timeout\\n\",\n\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t\treturn ret;\n\t}\n\n\ti40e_control_rx_q(pf, pf_q, enable);\n\tret = i40e_pf_rxq_wait(pf, pf_q, enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d Rx ring %d %sable timeout\\n\",\n\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t\treturn ret;\n\t}\n\n\t/* Due to HW errata, on Rx disable only, the register can\n\t * indicate done before it really is. Needs 50ms to be sure\n\t */\n\tif (!enable)\n\t\tmdelay(50);\n\n\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\treturn ret;\n\n\tret = i40e_control_wait_tx_q(vsi->seid, pf,\n\t\t\t\t     pf_q + vsi->alloc_queue_pairs,\n\t\t\t\t     true /*is xdp*/, enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d XDP Tx ring %d %sable timeout\\n\",\n\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_queue_pair_enable_irq - Enables interrupts for a queue pair\n * @vsi: vsi\n * @queue_pair: queue_pair\n **/\nstatic void i40e_queue_pair_enable_irq(struct i40e_vsi *vsi, int queue_pair)\n{\n\tstruct i40e_ring *rxr = vsi->rx_rings[queue_pair];\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t/* All rings in a qp belong to the same qvector. */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\ti40e_irq_dynamic_enable(vsi, rxr->q_vector->v_idx);\n\telse\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\n\ti40e_flush(hw);\n}\n\n/**\n * i40e_queue_pair_disable_irq - Disables interrupts for a queue pair\n * @vsi: vsi\n * @queue_pair: queue_pair\n **/\nstatic void i40e_queue_pair_disable_irq(struct i40e_vsi *vsi, int queue_pair)\n{\n\tstruct i40e_ring *rxr = vsi->rx_rings[queue_pair];\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t/* For simplicity, instead of removing the qp interrupt causes\n\t * from the interrupt linked list, we simply disable the interrupt, and\n\t * leave the list intact.\n\t *\n\t * All rings in a qp belong to the same qvector.\n\t */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tu32 intpf = vsi->base_vector + rxr->q_vector->v_idx;\n\n\t\twr32(hw, I40E_PFINT_DYN_CTLN(intpf - 1), 0);\n\t\ti40e_flush(hw);\n\t\tsynchronize_irq(pf->msix_entries[intpf].vector);\n\t} else {\n\t\t/* Legacy and MSI mode - this stops all interrupt handling */\n\t\twr32(hw, I40E_PFINT_ICR0_ENA, 0);\n\t\twr32(hw, I40E_PFINT_DYN_CTL0, 0);\n\t\ti40e_flush(hw);\n\t\tsynchronize_irq(pf->pdev->irq);\n\t}\n}\n\n/**\n * i40e_queue_pair_disable - Disables a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n *\n * Returns 0 on success, <0 on failure.\n **/\nint i40e_queue_pair_disable(struct i40e_vsi *vsi, int queue_pair)\n{\n\tint err;\n\n\terr = i40e_enter_busy_conf(vsi);\n\tif (err)\n\t\treturn err;\n\n\ti40e_queue_pair_disable_irq(vsi, queue_pair);\n\terr = i40e_queue_pair_toggle_rings(vsi, queue_pair, false /* off */);\n\ti40e_queue_pair_toggle_napi(vsi, queue_pair, false /* off */);\n\ti40e_queue_pair_clean_rings(vsi, queue_pair);\n\ti40e_queue_pair_reset_stats(vsi, queue_pair);\n\n\treturn err;\n}\n\n/**\n * i40e_queue_pair_enable - Enables a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n *\n * Returns 0 on success, <0 on failure.\n **/\nint i40e_queue_pair_enable(struct i40e_vsi *vsi, int queue_pair)\n{\n\tint err;\n\n\terr = i40e_configure_tx_ring(vsi->tx_rings[queue_pair]);\n\tif (err)\n\t\treturn err;\n\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\terr = i40e_configure_tx_ring(vsi->xdp_rings[queue_pair]);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = i40e_configure_rx_ring(vsi->rx_rings[queue_pair]);\n\tif (err)\n\t\treturn err;\n\n\terr = i40e_queue_pair_toggle_rings(vsi, queue_pair, true /* on */);\n\ti40e_queue_pair_toggle_napi(vsi, queue_pair, true /* on */);\n\ti40e_queue_pair_enable_irq(vsi, queue_pair);\n\n\ti40e_exit_busy_conf(vsi);\n\n\treturn err;\n}\n\n/**\n * i40e_xdp - implements ndo_bpf for i40e\n * @dev: netdevice\n * @xdp: XDP command\n **/\nstatic int i40e_xdp(struct net_device *dev,\n\t\t    struct netdev_bpf *xdp)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tif (vsi->type != I40E_VSI_MAIN)\n\t\treturn -EINVAL;\n\n\tswitch (xdp->command) {\n\tcase XDP_SETUP_PROG:\n\t\treturn i40e_xdp_setup(vsi, xdp->prog);\n\tcase XDP_QUERY_PROG:\n\t\txdp->prog_id = vsi->xdp_prog ? vsi->xdp_prog->aux->id : 0;\n\t\treturn 0;\n\tcase XDP_SETUP_XSK_UMEM:\n\t\treturn i40e_xsk_umem_setup(vsi, xdp->xsk.umem,\n\t\t\t\t\t   xdp->xsk.queue_id);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic const struct net_device_ops i40e_netdev_ops = {\n\t.ndo_open\t\t= i40e_open,\n\t.ndo_stop\t\t= i40e_close,\n\t.ndo_start_xmit\t\t= i40e_lan_xmit_frame,\n\t.ndo_get_stats64\t= i40e_get_netdev_stats_struct,\n\t.ndo_set_rx_mode\t= i40e_set_rx_mode,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= i40e_set_mac,\n\t.ndo_change_mtu\t\t= i40e_change_mtu,\n\t.ndo_do_ioctl\t\t= i40e_ioctl,\n\t.ndo_tx_timeout\t\t= i40e_tx_timeout,\n\t.ndo_vlan_rx_add_vid\t= i40e_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= i40e_vlan_rx_kill_vid,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= i40e_netpoll,\n#endif\n\t.ndo_setup_tc\t\t= __i40e_setup_tc,\n\t.ndo_set_features\t= i40e_set_features,\n\t.ndo_set_vf_mac\t\t= i40e_ndo_set_vf_mac,\n\t.ndo_set_vf_vlan\t= i40e_ndo_set_vf_port_vlan,\n\t.ndo_set_vf_rate\t= i40e_ndo_set_vf_bw,\n\t.ndo_get_vf_config\t= i40e_ndo_get_vf_config,\n\t.ndo_set_vf_link_state\t= i40e_ndo_set_vf_link_state,\n\t.ndo_set_vf_spoofchk\t= i40e_ndo_set_vf_spoofchk,\n\t.ndo_set_vf_trust\t= i40e_ndo_set_vf_trust,\n\t.ndo_udp_tunnel_add\t= i40e_udp_tunnel_add,\n\t.ndo_udp_tunnel_del\t= i40e_udp_tunnel_del,\n\t.ndo_get_phys_port_id\t= i40e_get_phys_port_id,\n\t.ndo_fdb_add\t\t= i40e_ndo_fdb_add,\n\t.ndo_features_check\t= i40e_features_check,\n\t.ndo_bridge_getlink\t= i40e_ndo_bridge_getlink,\n\t.ndo_bridge_setlink\t= i40e_ndo_bridge_setlink,\n\t.ndo_bpf\t\t= i40e_xdp,\n\t.ndo_xdp_xmit\t\t= i40e_xdp_xmit,\n\t.ndo_xsk_wakeup\t        = i40e_xsk_wakeup,\n\t.ndo_dfwd_add_station\t= i40e_fwd_add,\n\t.ndo_dfwd_del_station\t= i40e_fwd_del,\n};\n\n/**\n * i40e_config_netdev - Setup the netdev flags\n * @vsi: the VSI being configured\n *\n * Returns 0 on success, negative value on failure\n **/\nstatic int i40e_config_netdev(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_netdev_priv *np;\n\tstruct net_device *netdev;\n\tu8 broadcast[ETH_ALEN];\n\tu8 mac_addr[ETH_ALEN];\n\tint etherdev_size;\n\tnetdev_features_t hw_enc_features;\n\tnetdev_features_t hw_features;\n\n\tetherdev_size = sizeof(struct i40e_netdev_priv);\n\tnetdev = alloc_etherdev_mq(etherdev_size, vsi->alloc_queue_pairs);\n\tif (!netdev)\n\t\treturn -ENOMEM;\n\n\tvsi->netdev = netdev;\n\tnp = netdev_priv(netdev);\n\tnp->vsi = vsi;\n\n\thw_enc_features = NETIF_F_SG\t\t\t|\n\t\t\t  NETIF_F_IP_CSUM\t\t|\n\t\t\t  NETIF_F_IPV6_CSUM\t\t|\n\t\t\t  NETIF_F_HIGHDMA\t\t|\n\t\t\t  NETIF_F_SOFT_FEATURES\t\t|\n\t\t\t  NETIF_F_TSO\t\t\t|\n\t\t\t  NETIF_F_TSO_ECN\t\t|\n\t\t\t  NETIF_F_TSO6\t\t\t|\n\t\t\t  NETIF_F_GSO_GRE\t\t|\n\t\t\t  NETIF_F_GSO_GRE_CSUM\t\t|\n\t\t\t  NETIF_F_GSO_PARTIAL\t\t|\n\t\t\t  NETIF_F_GSO_IPXIP4\t\t|\n\t\t\t  NETIF_F_GSO_IPXIP6\t\t|\n\t\t\t  NETIF_F_GSO_UDP_TUNNEL\t|\n\t\t\t  NETIF_F_GSO_UDP_TUNNEL_CSUM\t|\n\t\t\t  NETIF_F_SCTP_CRC\t\t|\n\t\t\t  NETIF_F_RXHASH\t\t|\n\t\t\t  NETIF_F_RXCSUM\t\t|\n\t\t\t  0;\n\n\tif (!(pf->hw_features & I40E_HW_OUTER_UDP_CSUM_CAPABLE))\n\t\tnetdev->gso_partial_features |= NETIF_F_GSO_UDP_TUNNEL_CSUM;\n\n\tnetdev->gso_partial_features |= NETIF_F_GSO_GRE_CSUM;\n\n\tnetdev->hw_enc_features |= hw_enc_features;\n\n\t/* record features VLANs can make use of */\n\tnetdev->vlan_features |= hw_enc_features | NETIF_F_TSO_MANGLEID;\n\n\t/* enable macvlan offloads */\n\tnetdev->hw_features |= NETIF_F_HW_L2FW_DOFFLOAD;\n\n\thw_features = hw_enc_features\t\t|\n\t\t      NETIF_F_HW_VLAN_CTAG_TX\t|\n\t\t      NETIF_F_HW_VLAN_CTAG_RX;\n\n\tif (!(pf->flags & I40E_FLAG_MFP_ENABLED))\n\t\thw_features |= NETIF_F_NTUPLE | NETIF_F_HW_TC;\n\n\tnetdev->hw_features |= hw_features;\n\n\tnetdev->features |= hw_features | NETIF_F_HW_VLAN_CTAG_FILTER;\n\tnetdev->hw_enc_features |= NETIF_F_TSO_MANGLEID;\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\tSET_NETDEV_DEV(netdev, &pf->pdev->dev);\n\t\tether_addr_copy(mac_addr, hw->mac.perm_addr);\n\t\t/* The following steps are necessary for two reasons. First,\n\t\t * some older NVM configurations load a default MAC-VLAN\n\t\t * filter that will accept any tagged packet, and we want to\n\t\t * replace this with a normal filter. Additionally, it is\n\t\t * possible our MAC address was provided by the platform using\n\t\t * Open Firmware or similar.\n\t\t *\n\t\t * Thus, we need to remove the default filter and install one\n\t\t * specific to the MAC address.\n\t\t */\n\t\ti40e_rm_default_mac_filter(vsi, mac_addr);\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\ti40e_add_mac_filter(vsi, mac_addr);\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t} else {\n\t\t/* Relate the VSI_VMDQ name to the VSI_MAIN name. Note that we\n\t\t * are still limited by IFNAMSIZ, but we're adding 'v%d\\0' to\n\t\t * the end, which is 4 bytes long, so force truncation of the\n\t\t * original name by IFNAMSIZ - 4\n\t\t */\n\t\tsnprintf(netdev->name, IFNAMSIZ, \"%.*sv%%d\",\n\t\t\t IFNAMSIZ - 4,\n\t\t\t pf->vsi[pf->lan_vsi]->netdev->name);\n\t\teth_random_addr(mac_addr);\n\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\ti40e_add_mac_filter(vsi, mac_addr);\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t}\n\n\t/* Add the broadcast filter so that we initially will receive\n\t * broadcast packets. Note that when a new VLAN is first added the\n\t * driver will convert all filters marked I40E_VLAN_ANY into VLAN\n\t * specific filters as part of transitioning into \"vlan\" operation.\n\t * When more VLANs are added, the driver will copy each existing MAC\n\t * filter and add it for the new VLAN.\n\t *\n\t * Broadcast filters are handled specially by\n\t * i40e_sync_filters_subtask, as the driver must to set the broadcast\n\t * promiscuous bit instead of adding this directly as a MAC/VLAN\n\t * filter. The subtask will update the correct broadcast promiscuous\n\t * bits as VLANs become active or inactive.\n\t */\n\teth_broadcast_addr(broadcast);\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\ti40e_add_mac_filter(vsi, broadcast);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\tether_addr_copy(netdev->dev_addr, mac_addr);\n\tether_addr_copy(netdev->perm_addr, mac_addr);\n\n\t/* i40iw_net_event() reads 16 bytes from neigh->primary_key */\n\tnetdev->neigh_priv_len = sizeof(u32) * 4;\n\n\tnetdev->priv_flags |= IFF_UNICAST_FLT;\n\tnetdev->priv_flags |= IFF_SUPP_NOFCS;\n\t/* Setup netdev TC information */\n\ti40e_vsi_config_netdev_tc(vsi, vsi->tc_config.enabled_tc);\n\n\tnetdev->netdev_ops = &i40e_netdev_ops;\n\tnetdev->watchdog_timeo = 5 * HZ;\n\ti40e_set_ethtool_ops(netdev);\n\n\t/* MTU range: 68 - 9706 */\n\tnetdev->min_mtu = ETH_MIN_MTU;\n\tnetdev->max_mtu = I40E_MAX_RXBUFFER - I40E_PACKET_HDR_PAD;\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_delete - Delete a VSI from the switch\n * @vsi: the VSI being removed\n *\n * Returns 0 on success, negative value on failure\n **/\nstatic void i40e_vsi_delete(struct i40e_vsi *vsi)\n{\n\t/* remove default VSI is not allowed */\n\tif (vsi == vsi->back->vsi[vsi->back->lan_vsi])\n\t\treturn;\n\n\ti40e_aq_delete_element(&vsi->back->hw, vsi->seid, NULL);\n}\n\n/**\n * i40e_is_vsi_uplink_mode_veb - Check if the VSI's uplink bridge mode is VEB\n * @vsi: the VSI being queried\n *\n * Returns 1 if HW bridge mode is VEB and return 0 in case of VEPA mode\n **/\nint i40e_is_vsi_uplink_mode_veb(struct i40e_vsi *vsi)\n{\n\tstruct i40e_veb *veb;\n\tstruct i40e_pf *pf = vsi->back;\n\n\t/* Uplink is not a bridge so default to VEB */\n\tif (vsi->veb_idx >= I40E_MAX_VEB)\n\t\treturn 1;\n\n\tveb = pf->veb[vsi->veb_idx];\n\tif (!veb) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"There is no veb associated with the bridge\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\t/* Uplink is a bridge in VEPA mode */\n\tif (veb->bridge_mode & BRIDGE_MODE_VEPA) {\n\t\treturn 0;\n\t} else {\n\t\t/* Uplink is a bridge in VEB mode */\n\t\treturn 1;\n\t}\n\n\t/* VEPA is now default bridge, so return 0 */\n\treturn 0;\n}\n\n/**\n * i40e_add_vsi - Add a VSI to the switch\n * @vsi: the VSI being configured\n *\n * This initializes a VSI context depending on the VSI type to be added and\n * passes it down to the add_vsi aq command.\n **/\nstatic int i40e_add_vsi(struct i40e_vsi *vsi)\n{\n\tint ret = -ENODEV;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\tu8 enabled_tc = 0x1; /* TC0 enabled */\n\tint f_count = 0;\n\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tswitch (vsi->type) {\n\tcase I40E_VSI_MAIN:\n\t\t/* The PF's main VSI is already setup as part of the\n\t\t * device initialization, so we'll not bother with\n\t\t * the add_vsi call, but we will retrieve the current\n\t\t * VSI context.\n\t\t */\n\t\tctxt.seid = pf->main_vsi_seid;\n\t\tctxt.pf_num = pf->hw.pf_id;\n\t\tctxt.vf_num = 0;\n\t\tret = i40e_aq_get_vsi_params(&pf->hw, &ctxt, NULL);\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"couldn't get PF vsi config, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tvsi->info = ctxt.info;\n\t\tvsi->info.valid_sections = 0;\n\n\t\tvsi->seid = ctxt.seid;\n\t\tvsi->id = ctxt.vsi_number;\n\n\t\tenabled_tc = i40e_pf_get_tc_map(pf);\n\n\t\t/* Source pruning is enabled by default, so the flag is\n\t\t * negative logic - if it's set, we need to fiddle with\n\t\t * the VSI to disable source pruning.\n\t\t */\n\t\tif (pf->flags & I40E_FLAG_SOURCE_PRUNING_DISABLED) {\n\t\t\tmemset(&ctxt, 0, sizeof(ctxt));\n\t\t\tctxt.seid = pf->main_vsi_seid;\n\t\t\tctxt.pf_num = pf->hw.pf_id;\n\t\t\tctxt.vf_num = 0;\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\t     cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t\t   cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_LOCAL_LB);\n\t\t\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"update vsi failed, err %s aq_err %s\\n\",\n\t\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\t\tret = -ENOENT;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t\t/* MFP mode setup queue map and update VSI */\n\t\tif ((pf->flags & I40E_FLAG_MFP_ENABLED) &&\n\t\t    !(pf->hw.func_caps.iscsi)) { /* NIC type PF */\n\t\t\tmemset(&ctxt, 0, sizeof(ctxt));\n\t\t\tctxt.seid = pf->main_vsi_seid;\n\t\t\tctxt.pf_num = pf->hw.pf_id;\n\t\t\tctxt.vf_num = 0;\n\t\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, false);\n\t\t\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"update vsi failed, err %s aq_err %s\\n\",\n\t\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t    pf->hw.aq.asq_last_status));\n\t\t\t\tret = -ENOENT;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\t/* update the local VSI info queue map */\n\t\t\ti40e_vsi_update_queue_map(vsi, &ctxt);\n\t\t\tvsi->info.valid_sections = 0;\n\t\t} else {\n\t\t\t/* Default/Main VSI is only enabled for TC0\n\t\t\t * reconfigure it to enable all TCs that are\n\t\t\t * available on the port in SFP mode.\n\t\t\t * For MFP case the iSCSI PF would use this\n\t\t\t * flow to enable LAN+iSCSI TC.\n\t\t\t */\n\t\t\tret = i40e_vsi_config_tc(vsi, enabled_tc);\n\t\t\tif (ret) {\n\t\t\t\t/* Single TC condition is not fatal,\n\t\t\t\t * message and continue\n\t\t\t\t */\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"failed to configure TCs for main VSI tc_map 0x%08x, err %s aq_err %s\\n\",\n\t\t\t\t\t enabled_tc,\n\t\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t    pf->hw.aq.asq_last_status));\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase I40E_VSI_FDIR:\n\t\tctxt.pf_num = hw->pf_id;\n\t\tctxt.vf_num = 0;\n\t\tctxt.uplink_seid = vsi->uplink_seid;\n\t\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\t\tif ((pf->flags & I40E_FLAG_VEB_MODE_ENABLED) &&\n\t\t    (i40e_is_vsi_uplink_mode_veb(vsi))) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t     cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t   cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t\t}\n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, true);\n\t\tbreak;\n\n\tcase I40E_VSI_VMDQ2:\n\t\tctxt.pf_num = hw->pf_id;\n\t\tctxt.vf_num = 0;\n\t\tctxt.uplink_seid = vsi->uplink_seid;\n\t\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_VMDQ2;\n\n\t\t/* This VSI is connected to VEB so the switch_id\n\t\t * should be set to zero by default.\n\t\t */\n\t\tif (i40e_is_vsi_uplink_mode_veb(vsi)) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t\t}\n\n\t\t/* Setup the VSI tx/rx queue map for TC0 only for now */\n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, true);\n\t\tbreak;\n\n\tcase I40E_VSI_SRIOV:\n\t\tctxt.pf_num = hw->pf_id;\n\t\tctxt.vf_num = vsi->vf_id + hw->func_caps.vf_base_id;\n\t\tctxt.uplink_seid = vsi->uplink_seid;\n\t\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_VF;\n\n\t\t/* This VSI is connected to VEB so the switch_id\n\t\t * should be set to zero by default.\n\t\t */\n\t\tif (i40e_is_vsi_uplink_mode_veb(vsi)) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t\t}\n\n\t\tif (vsi->back->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_QUEUE_OPT_VALID);\n\t\t\tctxt.info.queueing_opt_flags |=\n\t\t\t\t(I40E_AQ_VSI_QUE_OPT_TCP_ENA |\n\t\t\t\t I40E_AQ_VSI_QUE_OPT_RSS_LUT_VSI);\n\t\t}\n\n\t\tctxt.info.valid_sections |= cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\t\tctxt.info.port_vlan_flags |= I40E_AQ_VSI_PVLAN_MODE_ALL;\n\t\tif (pf->vf[vsi->vf_id].spoofchk) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_SECURITY_VALID);\n\t\t\tctxt.info.sec_flags |=\n\t\t\t\t(I40E_AQ_VSI_SEC_FLAG_ENABLE_VLAN_CHK |\n\t\t\t\t I40E_AQ_VSI_SEC_FLAG_ENABLE_MAC_CHK);\n\t\t}\n\t\t/* Setup the VSI tx/rx queue map for TC0 only for now */\n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, true);\n\t\tbreak;\n\n\tcase I40E_VSI_IWARP:\n\t\t/* send down message to iWARP */\n\t\tbreak;\n\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n\n\tif (vsi->type != I40E_VSI_MAIN) {\n\t\tret = i40e_aq_add_vsi(hw, &ctxt, NULL);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"add vsi failed, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\tret = -ENOENT;\n\t\t\tgoto err;\n\t\t}\n\t\tvsi->info = ctxt.info;\n\t\tvsi->info.valid_sections = 0;\n\t\tvsi->seid = ctxt.seid;\n\t\tvsi->id = ctxt.vsi_number;\n\t}\n\n\tvsi->active_filters = 0;\n\tclear_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t/* If macvlan filters already exist, force them to get loaded */\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tf->state = I40E_FILTER_NEW;\n\t\tf_count++;\n\t}\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\tif (f_count) {\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, pf->state);\n\t}\n\n\t/* Update VSI BW information */\n\tret = i40e_vsi_get_bw_info(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get vsi bw info, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\t/* VSI is already added so not tearing that up */\n\t\tret = 0;\n\t}\n\nerr:\n\treturn ret;\n}\n\n/**\n * i40e_vsi_release - Delete a VSI and free its resources\n * @vsi: the VSI being removed\n *\n * Returns 0 on success or < 0 on error\n **/\nint i40e_vsi_release(struct i40e_vsi *vsi)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tstruct i40e_veb *veb = NULL;\n\tstruct i40e_pf *pf;\n\tu16 uplink_seid;\n\tint i, n, bkt;\n\n\tpf = vsi->back;\n\n\t/* release of a VEB-owner or last VSI is not allowed */\n\tif (vsi->flags & I40E_VSI_FLAG_VEB_OWNER) {\n\t\tdev_info(&pf->pdev->dev, \"VSI %d has existing VEB %d\\n\",\n\t\t\t vsi->seid, vsi->uplink_seid);\n\t\treturn -ENODEV;\n\t}\n\tif (vsi == pf->vsi[pf->lan_vsi] &&\n\t    !test_bit(__I40E_DOWN, pf->state)) {\n\t\tdev_info(&pf->pdev->dev, \"Can't remove PF VSI\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tuplink_seid = vsi->uplink_seid;\n\tif (vsi->type != I40E_VSI_SRIOV) {\n\t\tif (vsi->netdev_registered) {\n\t\t\tvsi->netdev_registered = false;\n\t\t\tif (vsi->netdev) {\n\t\t\t\t/* results in a call to i40e_close() */\n\t\t\t\tunregister_netdev(vsi->netdev);\n\t\t\t}\n\t\t} else {\n\t\t\ti40e_vsi_close(vsi);\n\t\t}\n\t\ti40e_vsi_disable_irq(vsi);\n\t}\n\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\n\t/* clear the sync flag on all filters */\n\tif (vsi->netdev) {\n\t\t__dev_uc_unsync(vsi->netdev, NULL);\n\t\t__dev_mc_unsync(vsi->netdev, NULL);\n\t}\n\n\t/* make sure any remaining filters are marked for deletion */\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist)\n\t\t__i40e_del_filter(vsi, f);\n\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\ti40e_sync_vsi_filters(vsi);\n\n\ti40e_vsi_delete(vsi);\n\ti40e_vsi_free_q_vectors(vsi);\n\tif (vsi->netdev) {\n\t\tfree_netdev(vsi->netdev);\n\t\tvsi->netdev = NULL;\n\t}\n\ti40e_vsi_clear_rings(vsi);\n\ti40e_vsi_clear(vsi);\n\n\t/* If this was the last thing on the VEB, except for the\n\t * controlling VSI, remove the VEB, which puts the controlling\n\t * VSI onto the next level down in the switch.\n\t *\n\t * Well, okay, there's one more exception here: don't remove\n\t * the orphan VEBs yet.  We'll wait for an explicit remove request\n\t * from up the network stack.\n\t */\n\tfor (n = 0, i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i] &&\n\t\t    pf->vsi[i]->uplink_seid == uplink_seid &&\n\t\t    (pf->vsi[i]->flags & I40E_VSI_FLAG_VEB_OWNER) == 0) {\n\t\t\tn++;      /* count the VSIs */\n\t\t}\n\t}\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (!pf->veb[i])\n\t\t\tcontinue;\n\t\tif (pf->veb[i]->uplink_seid == uplink_seid)\n\t\t\tn++;     /* count the VEBs */\n\t\tif (pf->veb[i]->seid == uplink_seid)\n\t\t\tveb = pf->veb[i];\n\t}\n\tif (n == 0 && veb && veb->uplink_seid != 0)\n\t\ti40e_veb_release(veb);\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_setup_vectors - Set up the q_vectors for the given VSI\n * @vsi: ptr to the VSI\n *\n * This should only be called after i40e_vsi_mem_alloc() which allocates the\n * corresponding SW VSI structure and initializes num_queue_pairs for the\n * newly allocated VSI.\n *\n * Returns 0 on success or negative on failure\n **/\nstatic int i40e_vsi_setup_vectors(struct i40e_vsi *vsi)\n{\n\tint ret = -ENOENT;\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (vsi->q_vectors[0]) {\n\t\tdev_info(&pf->pdev->dev, \"VSI %d has existing q_vectors\\n\",\n\t\t\t vsi->seid);\n\t\treturn -EEXIST;\n\t}\n\n\tif (vsi->base_vector) {\n\t\tdev_info(&pf->pdev->dev, \"VSI %d has non-zero base vector %d\\n\",\n\t\t\t vsi->seid, vsi->base_vector);\n\t\treturn -EEXIST;\n\t}\n\n\tret = i40e_vsi_alloc_q_vectors(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to allocate %d q_vector for VSI %d, ret=%d\\n\",\n\t\t\t vsi->num_q_vectors, vsi->seid, ret);\n\t\tvsi->num_q_vectors = 0;\n\t\tgoto vector_setup_out;\n\t}\n\n\t/* In Legacy mode, we do not have to get any other vector since we\n\t * piggyback on the misc/ICR0 for queue interrupts.\n\t*/\n\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\treturn ret;\n\tif (vsi->num_q_vectors)\n\t\tvsi->base_vector = i40e_get_lump(pf, pf->irq_pile,\n\t\t\t\t\t\t vsi->num_q_vectors, vsi->idx);\n\tif (vsi->base_vector < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to get tracking for %d vectors for VSI %d, err=%d\\n\",\n\t\t\t vsi->num_q_vectors, vsi->seid, vsi->base_vector);\n\t\ti40e_vsi_free_q_vectors(vsi);\n\t\tret = -ENOENT;\n\t\tgoto vector_setup_out;\n\t}\n\nvector_setup_out:\n\treturn ret;\n}\n\n/**\n * i40e_vsi_reinit_setup - return and reallocate resources for a VSI\n * @vsi: pointer to the vsi.\n *\n * This re-allocates a vsi's queue resources.\n *\n * Returns pointer to the successfully allocated and configured VSI sw struct\n * on success, otherwise returns NULL on failure.\n **/\nstatic struct i40e_vsi *i40e_vsi_reinit_setup(struct i40e_vsi *vsi)\n{\n\tu16 alloc_queue_pairs;\n\tstruct i40e_pf *pf;\n\tu8 enabled_tc;\n\tint ret;\n\n\tif (!vsi)\n\t\treturn NULL;\n\n\tpf = vsi->back;\n\n\ti40e_put_lump(pf->qp_pile, vsi->base_queue, vsi->idx);\n\ti40e_vsi_clear_rings(vsi);\n\n\ti40e_vsi_free_arrays(vsi, false);\n\ti40e_set_num_rings_in_vsi(vsi);\n\tret = i40e_vsi_alloc_arrays(vsi, false);\n\tif (ret)\n\t\tgoto err_vsi;\n\n\talloc_queue_pairs = vsi->alloc_queue_pairs *\n\t\t\t    (i40e_enabled_xdp_vsi(vsi) ? 2 : 1);\n\n\tret = i40e_get_lump(pf, pf->qp_pile, alloc_queue_pairs, vsi->idx);\n\tif (ret < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to get tracking for %d queues for VSI %d err %d\\n\",\n\t\t\t alloc_queue_pairs, vsi->seid, ret);\n\t\tgoto err_vsi;\n\t}\n\tvsi->base_queue = ret;\n\n\t/* Update the FW view of the VSI. Force a reset of TC and queue\n\t * layout configurations.\n\t */\n\tenabled_tc = pf->vsi[pf->lan_vsi]->tc_config.enabled_tc;\n\tpf->vsi[pf->lan_vsi]->tc_config.enabled_tc = 0;\n\tpf->vsi[pf->lan_vsi]->seid = pf->main_vsi_seid;\n\ti40e_vsi_config_tc(pf->vsi[pf->lan_vsi], enabled_tc);\n\tif (vsi->type == I40E_VSI_MAIN)\n\t\ti40e_rm_default_mac_filter(vsi, pf->hw.mac.perm_addr);\n\n\t/* assign it some queues */\n\tret = i40e_alloc_rings(vsi);\n\tif (ret)\n\t\tgoto err_rings;\n\n\t/* map all of the rings to the q_vectors */\n\ti40e_vsi_map_rings_to_vectors(vsi);\n\treturn vsi;\n\nerr_rings:\n\ti40e_vsi_free_q_vectors(vsi);\n\tif (vsi->netdev_registered) {\n\t\tvsi->netdev_registered = false;\n\t\tunregister_netdev(vsi->netdev);\n\t\tfree_netdev(vsi->netdev);\n\t\tvsi->netdev = NULL;\n\t}\n\ti40e_aq_delete_element(&pf->hw, vsi->seid, NULL);\nerr_vsi:\n\ti40e_vsi_clear(vsi);\n\treturn NULL;\n}\n\n/**\n * i40e_vsi_setup - Set up a VSI by a given type\n * @pf: board private structure\n * @type: VSI type\n * @uplink_seid: the switch element to link to\n * @param1: usage depends upon VSI type. For VF types, indicates VF id\n *\n * This allocates the sw VSI structure and its queue resources, then add a VSI\n * to the identified VEB.\n *\n * Returns pointer to the successfully allocated and configure VSI sw struct on\n * success, otherwise returns NULL on failure.\n **/\nstruct i40e_vsi *i40e_vsi_setup(struct i40e_pf *pf, u8 type,\n\t\t\t\tu16 uplink_seid, u32 param1)\n{\n\tstruct i40e_vsi *vsi = NULL;\n\tstruct i40e_veb *veb = NULL;\n\tu16 alloc_queue_pairs;\n\tint ret, i;\n\tint v_idx;\n\n\t/* The requested uplink_seid must be either\n\t *     - the PF's port seid\n\t *              no VEB is needed because this is the PF\n\t *              or this is a Flow Director special case VSI\n\t *     - seid of an existing VEB\n\t *     - seid of a VSI that owns an existing VEB\n\t *     - seid of a VSI that doesn't own a VEB\n\t *              a new VEB is created and the VSI becomes the owner\n\t *     - seid of the PF VSI, which is what creates the first VEB\n\t *              this is a special case of the previous\n\t *\n\t * Find which uplink_seid we were given and create a new VEB if needed\n\t */\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (pf->veb[i] && pf->veb[i]->seid == uplink_seid) {\n\t\t\tveb = pf->veb[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!veb && uplink_seid != pf->mac_seid) {\n\n\t\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\t\tif (pf->vsi[i] && pf->vsi[i]->seid == uplink_seid) {\n\t\t\t\tvsi = pf->vsi[i];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!vsi) {\n\t\t\tdev_info(&pf->pdev->dev, \"no such uplink_seid %d\\n\",\n\t\t\t\t uplink_seid);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (vsi->uplink_seid == pf->mac_seid)\n\t\t\tveb = i40e_veb_setup(pf, 0, pf->mac_seid, vsi->seid,\n\t\t\t\t\t     vsi->tc_config.enabled_tc);\n\t\telse if ((vsi->flags & I40E_VSI_FLAG_VEB_OWNER) == 0)\n\t\t\tveb = i40e_veb_setup(pf, 0, vsi->uplink_seid, vsi->seid,\n\t\t\t\t\t     vsi->tc_config.enabled_tc);\n\t\tif (veb) {\n\t\t\tif (vsi->seid != pf->vsi[pf->lan_vsi]->seid) {\n\t\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t\t \"New VSI creation error, uplink seid of LAN VSI expected.\\n\");\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t\t/* We come up by default in VEPA mode if SRIOV is not\n\t\t\t * already enabled, in which case we can't force VEPA\n\t\t\t * mode.\n\t\t\t */\n\t\t\tif (!(pf->flags & I40E_FLAG_VEB_MODE_ENABLED)) {\n\t\t\t\tveb->bridge_mode = BRIDGE_MODE_VEPA;\n\t\t\t\tpf->flags &= ~I40E_FLAG_VEB_MODE_ENABLED;\n\t\t\t}\n\t\t\ti40e_config_bridge_mode(veb);\n\t\t}\n\t\tfor (i = 0; i < I40E_MAX_VEB && !veb; i++) {\n\t\t\tif (pf->veb[i] && pf->veb[i]->seid == vsi->uplink_seid)\n\t\t\t\tveb = pf->veb[i];\n\t\t}\n\t\tif (!veb) {\n\t\t\tdev_info(&pf->pdev->dev, \"couldn't add VEB\\n\");\n\t\t\treturn NULL;\n\t\t}\n\n\t\tvsi->flags |= I40E_VSI_FLAG_VEB_OWNER;\n\t\tuplink_seid = veb->seid;\n\t}\n\n\t/* get vsi sw struct */\n\tv_idx = i40e_vsi_mem_alloc(pf, type);\n\tif (v_idx < 0)\n\t\tgoto err_alloc;\n\tvsi = pf->vsi[v_idx];\n\tif (!vsi)\n\t\tgoto err_alloc;\n\tvsi->type = type;\n\tvsi->veb_idx = (veb ? veb->idx : I40E_NO_VEB);\n\n\tif (type == I40E_VSI_MAIN)\n\t\tpf->lan_vsi = v_idx;\n\telse if (type == I40E_VSI_SRIOV)\n\t\tvsi->vf_id = param1;\n\t/* assign it some queues */\n\talloc_queue_pairs = vsi->alloc_queue_pairs *\n\t\t\t    (i40e_enabled_xdp_vsi(vsi) ? 2 : 1);\n\n\tret = i40e_get_lump(pf, pf->qp_pile, alloc_queue_pairs, vsi->idx);\n\tif (ret < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to get tracking for %d queues for VSI %d err=%d\\n\",\n\t\t\t alloc_queue_pairs, vsi->seid, ret);\n\t\tgoto err_vsi;\n\t}\n\tvsi->base_queue = ret;\n\n\t/* get a VSI from the hardware */\n\tvsi->uplink_seid = uplink_seid;\n\tret = i40e_add_vsi(vsi);\n\tif (ret)\n\t\tgoto err_vsi;\n\n\tswitch (vsi->type) {\n\t/* setup the netdev if needed */\n\tcase I40E_VSI_MAIN:\n\tcase I40E_VSI_VMDQ2:\n\t\tret = i40e_config_netdev(vsi);\n\t\tif (ret)\n\t\t\tgoto err_netdev;\n\t\tret = register_netdev(vsi->netdev);\n\t\tif (ret)\n\t\t\tgoto err_netdev;\n\t\tvsi->netdev_registered = true;\n\t\tnetif_carrier_off(vsi->netdev);\n#ifdef CONFIG_I40E_DCB\n\t\t/* Setup DCB netlink interface */\n\t\ti40e_dcbnl_setup(vsi);\n#endif /* CONFIG_I40E_DCB */\n\t\t/* fall through */\n\n\tcase I40E_VSI_FDIR:\n\t\t/* set up vectors and rings if needed */\n\t\tret = i40e_vsi_setup_vectors(vsi);\n\t\tif (ret)\n\t\t\tgoto err_msix;\n\n\t\tret = i40e_alloc_rings(vsi);\n\t\tif (ret)\n\t\t\tgoto err_rings;\n\n\t\t/* map all of the rings to the q_vectors */\n\t\ti40e_vsi_map_rings_to_vectors(vsi);\n\n\t\ti40e_vsi_reset_stats(vsi);\n\t\tbreak;\n\n\tdefault:\n\t\t/* no netdev or rings for the other VSI types */\n\t\tbreak;\n\t}\n\n\tif ((pf->hw_features & I40E_HW_RSS_AQ_CAPABLE) &&\n\t    (vsi->type == I40E_VSI_VMDQ2)) {\n\t\tret = i40e_vsi_config_rss(vsi);\n\t}\n\treturn vsi;\n\nerr_rings:\n\ti40e_vsi_free_q_vectors(vsi);\nerr_msix:\n\tif (vsi->netdev_registered) {\n\t\tvsi->netdev_registered = false;\n\t\tunregister_netdev(vsi->netdev);\n\t\tfree_netdev(vsi->netdev);\n\t\tvsi->netdev = NULL;\n\t}\nerr_netdev:\n\ti40e_aq_delete_element(&pf->hw, vsi->seid, NULL);\nerr_vsi:\n\ti40e_vsi_clear(vsi);\nerr_alloc:\n\treturn NULL;\n}\n\n/**\n * i40e_veb_get_bw_info - Query VEB BW information\n * @veb: the veb to query\n *\n * Query the Tx scheduler BW configuration data for given VEB\n **/\nstatic int i40e_veb_get_bw_info(struct i40e_veb *veb)\n{\n\tstruct i40e_aqc_query_switching_comp_ets_config_resp ets_data;\n\tstruct i40e_aqc_query_switching_comp_bw_config_resp bw_data;\n\tstruct i40e_pf *pf = veb->pf;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 tc_bw_max;\n\tint ret = 0;\n\tint i;\n\n\tret = i40e_aq_query_switch_comp_bw_config(hw, veb->seid,\n\t\t\t\t\t\t  &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"query veb bw config failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\tret = i40e_aq_query_switch_comp_ets_config(hw, veb->seid,\n\t\t\t\t\t\t   &ets_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"query veb bw ets config failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\tveb->bw_limit = le16_to_cpu(ets_data.port_bw_limit);\n\tveb->bw_max_quanta = ets_data.tc_bw_max;\n\tveb->is_abs_credits = bw_data.absolute_credits_enable;\n\tveb->enabled_tc = ets_data.tc_valid_bits;\n\ttc_bw_max = le16_to_cpu(bw_data.tc_bw_max[0]) |\n\t\t    (le16_to_cpu(bw_data.tc_bw_max[1]) << 16);\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tveb->bw_tc_share_credits[i] = bw_data.tc_bw_share_credits[i];\n\t\tveb->bw_tc_limit_credits[i] =\n\t\t\t\t\tle16_to_cpu(bw_data.tc_bw_limits[i]);\n\t\tveb->bw_tc_max_quanta[i] = ((tc_bw_max >> (i*4)) & 0x7);\n\t}\n\nout:\n\treturn ret;\n}\n\n/**\n * i40e_veb_mem_alloc - Allocates the next available struct veb in the PF\n * @pf: board private structure\n *\n * On error: returns error code (negative)\n * On success: returns vsi index in PF (positive)\n **/\nstatic int i40e_veb_mem_alloc(struct i40e_pf *pf)\n{\n\tint ret = -ENOENT;\n\tstruct i40e_veb *veb;\n\tint i;\n\n\t/* Need to protect the allocation of switch elements at the PF level */\n\tmutex_lock(&pf->switch_mutex);\n\n\t/* VEB list may be fragmented if VEB creation/destruction has\n\t * been happening.  We can afford to do a quick scan to look\n\t * for any free slots in the list.\n\t *\n\t * find next empty veb slot, looping back around if necessary\n\t */\n\ti = 0;\n\twhile ((i < I40E_MAX_VEB) && (pf->veb[i] != NULL))\n\t\ti++;\n\tif (i >= I40E_MAX_VEB) {\n\t\tret = -ENOMEM;\n\t\tgoto err_alloc_veb;  /* out of VEB slots! */\n\t}\n\n\tveb = kzalloc(sizeof(*veb), GFP_KERNEL);\n\tif (!veb) {\n\t\tret = -ENOMEM;\n\t\tgoto err_alloc_veb;\n\t}\n\tveb->pf = pf;\n\tveb->idx = i;\n\tveb->enabled_tc = 1;\n\n\tpf->veb[i] = veb;\n\tret = i;\nerr_alloc_veb:\n\tmutex_unlock(&pf->switch_mutex);\n\treturn ret;\n}\n\n/**\n * i40e_switch_branch_release - Delete a branch of the switch tree\n * @branch: where to start deleting\n *\n * This uses recursion to find the tips of the branch to be\n * removed, deleting until we get back to and can delete this VEB.\n **/\nstatic void i40e_switch_branch_release(struct i40e_veb *branch)\n{\n\tstruct i40e_pf *pf = branch->pf;\n\tu16 branch_seid = branch->seid;\n\tu16 veb_idx = branch->idx;\n\tint i;\n\n\t/* release any VEBs on this VEB - RECURSION */\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (!pf->veb[i])\n\t\t\tcontinue;\n\t\tif (pf->veb[i]->uplink_seid == branch->seid)\n\t\t\ti40e_switch_branch_release(pf->veb[i]);\n\t}\n\n\t/* Release the VSIs on this VEB, but not the owner VSI.\n\t *\n\t * NOTE: Removing the last VSI on a VEB has the SIDE EFFECT of removing\n\t *       the VEB itself, so don't use (*branch) after this loop.\n\t */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (!pf->vsi[i])\n\t\t\tcontinue;\n\t\tif (pf->vsi[i]->uplink_seid == branch_seid &&\n\t\t   (pf->vsi[i]->flags & I40E_VSI_FLAG_VEB_OWNER) == 0) {\n\t\t\ti40e_vsi_release(pf->vsi[i]);\n\t\t}\n\t}\n\n\t/* There's one corner case where the VEB might not have been\n\t * removed, so double check it here and remove it if needed.\n\t * This case happens if the veb was created from the debugfs\n\t * commands and no VSIs were added to it.\n\t */\n\tif (pf->veb[veb_idx])\n\t\ti40e_veb_release(pf->veb[veb_idx]);\n}\n\n/**\n * i40e_veb_clear - remove veb struct\n * @veb: the veb to remove\n **/\nstatic void i40e_veb_clear(struct i40e_veb *veb)\n{\n\tif (!veb)\n\t\treturn;\n\n\tif (veb->pf) {\n\t\tstruct i40e_pf *pf = veb->pf;\n\n\t\tmutex_lock(&pf->switch_mutex);\n\t\tif (pf->veb[veb->idx] == veb)\n\t\t\tpf->veb[veb->idx] = NULL;\n\t\tmutex_unlock(&pf->switch_mutex);\n\t}\n\n\tkfree(veb);\n}\n\n/**\n * i40e_veb_release - Delete a VEB and free its resources\n * @veb: the VEB being removed\n **/\nvoid i40e_veb_release(struct i40e_veb *veb)\n{\n\tstruct i40e_vsi *vsi = NULL;\n\tstruct i40e_pf *pf;\n\tint i, n = 0;\n\n\tpf = veb->pf;\n\n\t/* find the remaining VSI and check for extras */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i] && pf->vsi[i]->uplink_seid == veb->seid) {\n\t\t\tn++;\n\t\t\tvsi = pf->vsi[i];\n\t\t}\n\t}\n\tif (n != 1) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"can't remove VEB %d with %d VSIs left\\n\",\n\t\t\t veb->seid, n);\n\t\treturn;\n\t}\n\n\t/* move the remaining VSI to uplink veb */\n\tvsi->flags &= ~I40E_VSI_FLAG_VEB_OWNER;\n\tif (veb->uplink_seid) {\n\t\tvsi->uplink_seid = veb->uplink_seid;\n\t\tif (veb->uplink_seid == pf->mac_seid)\n\t\t\tvsi->veb_idx = I40E_NO_VEB;\n\t\telse\n\t\t\tvsi->veb_idx = veb->veb_idx;\n\t} else {\n\t\t/* floating VEB */\n\t\tvsi->uplink_seid = pf->vsi[pf->lan_vsi]->uplink_seid;\n\t\tvsi->veb_idx = pf->vsi[pf->lan_vsi]->veb_idx;\n\t}\n\n\ti40e_aq_delete_element(&pf->hw, veb->seid, NULL);\n\ti40e_veb_clear(veb);\n}\n\n/**\n * i40e_add_veb - create the VEB in the switch\n * @veb: the VEB to be instantiated\n * @vsi: the controlling VSI\n **/\nstatic int i40e_add_veb(struct i40e_veb *veb, struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = veb->pf;\n\tbool enable_stats = !!(pf->flags & I40E_FLAG_VEB_STATS_ENABLED);\n\tint ret;\n\n\tret = i40e_aq_add_veb(&pf->hw, veb->uplink_seid, vsi->seid,\n\t\t\t      veb->enabled_tc, false,\n\t\t\t      &veb->seid, enable_stats, NULL);\n\n\t/* get a VEB from the hardware */\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't add VEB, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EPERM;\n\t}\n\n\t/* get statistics counter */\n\tret = i40e_aq_get_veb_parameters(&pf->hw, veb->seid, NULL, NULL,\n\t\t\t\t\t &veb->stats_idx, NULL, NULL, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get VEB statistics idx, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EPERM;\n\t}\n\tret = i40e_veb_get_bw_info(veb);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get VEB bw info, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\ti40e_aq_delete_element(&pf->hw, veb->seid, NULL);\n\t\treturn -ENOENT;\n\t}\n\n\tvsi->uplink_seid = veb->seid;\n\tvsi->veb_idx = veb->idx;\n\tvsi->flags |= I40E_VSI_FLAG_VEB_OWNER;\n\n\treturn 0;\n}\n\n/**\n * i40e_veb_setup - Set up a VEB\n * @pf: board private structure\n * @flags: VEB setup flags\n * @uplink_seid: the switch element to link to\n * @vsi_seid: the initial VSI seid\n * @enabled_tc: Enabled TC bit-map\n *\n * This allocates the sw VEB structure and links it into the switch\n * It is possible and legal for this to be a duplicate of an already\n * existing VEB.  It is also possible for both uplink and vsi seids\n * to be zero, in order to create a floating VEB.\n *\n * Returns pointer to the successfully allocated VEB sw struct on\n * success, otherwise returns NULL on failure.\n **/\nstruct i40e_veb *i40e_veb_setup(struct i40e_pf *pf, u16 flags,\n\t\t\t\tu16 uplink_seid, u16 vsi_seid,\n\t\t\t\tu8 enabled_tc)\n{\n\tstruct i40e_veb *veb, *uplink_veb = NULL;\n\tint vsi_idx, veb_idx;\n\tint ret;\n\n\t/* if one seid is 0, the other must be 0 to create a floating relay */\n\tif ((uplink_seid == 0 || vsi_seid == 0) &&\n\t    (uplink_seid + vsi_seid != 0)) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"one, not both seid's are 0: uplink=%d vsi=%d\\n\",\n\t\t\t uplink_seid, vsi_seid);\n\t\treturn NULL;\n\t}\n\n\t/* make sure there is such a vsi and uplink */\n\tfor (vsi_idx = 0; vsi_idx < pf->num_alloc_vsi; vsi_idx++)\n\t\tif (pf->vsi[vsi_idx] && pf->vsi[vsi_idx]->seid == vsi_seid)\n\t\t\tbreak;\n\tif (vsi_idx == pf->num_alloc_vsi && vsi_seid != 0) {\n\t\tdev_info(&pf->pdev->dev, \"vsi seid %d not found\\n\",\n\t\t\t vsi_seid);\n\t\treturn NULL;\n\t}\n\n\tif (uplink_seid && uplink_seid != pf->mac_seid) {\n\t\tfor (veb_idx = 0; veb_idx < I40E_MAX_VEB; veb_idx++) {\n\t\t\tif (pf->veb[veb_idx] &&\n\t\t\t    pf->veb[veb_idx]->seid == uplink_seid) {\n\t\t\t\tuplink_veb = pf->veb[veb_idx];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!uplink_veb) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"uplink seid %d not found\\n\", uplink_seid);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* get veb sw struct */\n\tveb_idx = i40e_veb_mem_alloc(pf);\n\tif (veb_idx < 0)\n\t\tgoto err_alloc;\n\tveb = pf->veb[veb_idx];\n\tveb->flags = flags;\n\tveb->uplink_seid = uplink_seid;\n\tveb->veb_idx = (uplink_veb ? uplink_veb->idx : I40E_NO_VEB);\n\tveb->enabled_tc = (enabled_tc ? enabled_tc : 0x1);\n\n\t/* create the VEB in the switch */\n\tret = i40e_add_veb(veb, pf->vsi[vsi_idx]);\n\tif (ret)\n\t\tgoto err_veb;\n\tif (vsi_idx == pf->lan_vsi)\n\t\tpf->lan_veb = veb->idx;\n\n\treturn veb;\n\nerr_veb:\n\ti40e_veb_clear(veb);\nerr_alloc:\n\treturn NULL;\n}\n\n/**\n * i40e_setup_pf_switch_element - set PF vars based on switch type\n * @pf: board private structure\n * @ele: element we are building info from\n * @num_reported: total number of elements\n * @printconfig: should we print the contents\n *\n * helper function to assist in extracting a few useful SEID values.\n **/\nstatic void i40e_setup_pf_switch_element(struct i40e_pf *pf,\n\t\t\t\tstruct i40e_aqc_switch_config_element_resp *ele,\n\t\t\t\tu16 num_reported, bool printconfig)\n{\n\tu16 downlink_seid = le16_to_cpu(ele->downlink_seid);\n\tu16 uplink_seid = le16_to_cpu(ele->uplink_seid);\n\tu8 element_type = ele->element_type;\n\tu16 seid = le16_to_cpu(ele->seid);\n\n\tif (printconfig)\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"type=%d seid=%d uplink=%d downlink=%d\\n\",\n\t\t\t element_type, seid, uplink_seid, downlink_seid);\n\n\tswitch (element_type) {\n\tcase I40E_SWITCH_ELEMENT_TYPE_MAC:\n\t\tpf->mac_seid = seid;\n\t\tbreak;\n\tcase I40E_SWITCH_ELEMENT_TYPE_VEB:\n\t\t/* Main VEB? */\n\t\tif (uplink_seid != pf->mac_seid)\n\t\t\tbreak;\n\t\tif (pf->lan_veb >= I40E_MAX_VEB) {\n\t\t\tint v;\n\n\t\t\t/* find existing or else empty VEB */\n\t\t\tfor (v = 0; v < I40E_MAX_VEB; v++) {\n\t\t\t\tif (pf->veb[v] && (pf->veb[v]->seid == seid)) {\n\t\t\t\t\tpf->lan_veb = v;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (pf->lan_veb >= I40E_MAX_VEB) {\n\t\t\t\tv = i40e_veb_mem_alloc(pf);\n\t\t\t\tif (v < 0)\n\t\t\t\t\tbreak;\n\t\t\t\tpf->lan_veb = v;\n\t\t\t}\n\t\t}\n\t\tif (pf->lan_veb >= I40E_MAX_VEB)\n\t\t\tbreak;\n\n\t\tpf->veb[pf->lan_veb]->seid = seid;\n\t\tpf->veb[pf->lan_veb]->uplink_seid = pf->mac_seid;\n\t\tpf->veb[pf->lan_veb]->pf = pf;\n\t\tpf->veb[pf->lan_veb]->veb_idx = I40E_NO_VEB;\n\t\tbreak;\n\tcase I40E_SWITCH_ELEMENT_TYPE_VSI:\n\t\tif (num_reported != 1)\n\t\t\tbreak;\n\t\t/* This is immediately after a reset so we can assume this is\n\t\t * the PF's VSI\n\t\t */\n\t\tpf->mac_seid = uplink_seid;\n\t\tpf->pf_seid = downlink_seid;\n\t\tpf->main_vsi_seid = seid;\n\t\tif (printconfig)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"pf_seid=%d main_vsi_seid=%d\\n\",\n\t\t\t\t pf->pf_seid, pf->main_vsi_seid);\n\t\tbreak;\n\tcase I40E_SWITCH_ELEMENT_TYPE_PF:\n\tcase I40E_SWITCH_ELEMENT_TYPE_VF:\n\tcase I40E_SWITCH_ELEMENT_TYPE_EMP:\n\tcase I40E_SWITCH_ELEMENT_TYPE_BMC:\n\tcase I40E_SWITCH_ELEMENT_TYPE_PE:\n\tcase I40E_SWITCH_ELEMENT_TYPE_PA:\n\t\t/* ignore these for now */\n\t\tbreak;\n\tdefault:\n\t\tdev_info(&pf->pdev->dev, \"unknown element type=%d seid=%d\\n\",\n\t\t\t element_type, seid);\n\t\tbreak;\n\t}\n}\n\n/**\n * i40e_fetch_switch_configuration - Get switch config from firmware\n * @pf: board private structure\n * @printconfig: should we print the contents\n *\n * Get the current switch configuration from the device and\n * extract a few useful SEID values.\n **/\nint i40e_fetch_switch_configuration(struct i40e_pf *pf, bool printconfig)\n{\n\tstruct i40e_aqc_get_switch_config_resp *sw_config;\n\tu16 next_seid = 0;\n\tint ret = 0;\n\tu8 *aq_buf;\n\tint i;\n\n\taq_buf = kzalloc(I40E_AQ_LARGE_BUF, GFP_KERNEL);\n\tif (!aq_buf)\n\t\treturn -ENOMEM;\n\n\tsw_config = (struct i40e_aqc_get_switch_config_resp *)aq_buf;\n\tdo {\n\t\tu16 num_reported, num_total;\n\n\t\tret = i40e_aq_get_switch_config(&pf->hw, sw_config,\n\t\t\t\t\t\tI40E_AQ_LARGE_BUF,\n\t\t\t\t\t\t&next_seid, NULL);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"get switch config failed err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\tkfree(aq_buf);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tnum_reported = le16_to_cpu(sw_config->header.num_reported);\n\t\tnum_total = le16_to_cpu(sw_config->header.num_total);\n\n\t\tif (printconfig)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"header: %d reported %d total\\n\",\n\t\t\t\t num_reported, num_total);\n\n\t\tfor (i = 0; i < num_reported; i++) {\n\t\t\tstruct i40e_aqc_switch_config_element_resp *ele =\n\t\t\t\t&sw_config->element[i];\n\n\t\t\ti40e_setup_pf_switch_element(pf, ele, num_reported,\n\t\t\t\t\t\t     printconfig);\n\t\t}\n\t} while (next_seid != 0);\n\n\tkfree(aq_buf);\n\treturn ret;\n}\n\n/**\n * i40e_setup_pf_switch - Setup the HW switch on startup or after reset\n * @pf: board private structure\n * @reinit: if the Main VSI needs to re-initialized.\n *\n * Returns 0 on success, negative value on failure\n **/\nstatic int i40e_setup_pf_switch(struct i40e_pf *pf, bool reinit)\n{\n\tu16 flags = 0;\n\tint ret;\n\n\t/* find out what's out there already */\n\tret = i40e_fetch_switch_configuration(pf, false);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't fetch switch config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn ret;\n\t}\n\ti40e_pf_reset_stats(pf);\n\n\t/* set the switch config bit for the whole device to\n\t * support limited promisc or true promisc\n\t * when user requests promisc. The default is limited\n\t * promisc.\n\t*/\n\n\tif ((pf->hw.pf_id == 0) &&\n\t    !(pf->flags & I40E_FLAG_TRUE_PROMISC_SUPPORT)) {\n\t\tflags = I40E_AQ_SET_SWITCH_CFG_PROMISC;\n\t\tpf->last_sw_conf_flags = flags;\n\t}\n\n\tif (pf->hw.pf_id == 0) {\n\t\tu16 valid_flags;\n\n\t\tvalid_flags = I40E_AQ_SET_SWITCH_CFG_PROMISC;\n\t\tret = i40e_aq_set_switch_config(&pf->hw, flags, valid_flags, 0,\n\t\t\t\t\t\tNULL);\n\t\tif (ret && pf->hw.aq.asq_last_status != I40E_AQ_RC_ESRCH) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"couldn't set switch config bits, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\t/* not a fatal problem, just keep going */\n\t\t}\n\t\tpf->last_sw_conf_valid_flags = valid_flags;\n\t}\n\n\t/* first time setup */\n\tif (pf->lan_vsi == I40E_NO_VSI || reinit) {\n\t\tstruct i40e_vsi *vsi = NULL;\n\t\tu16 uplink_seid;\n\n\t\t/* Set up the PF VSI associated with the PF's main VSI\n\t\t * that is already in the HW switch\n\t\t */\n\t\tif (pf->lan_veb < I40E_MAX_VEB && pf->veb[pf->lan_veb])\n\t\t\tuplink_seid = pf->veb[pf->lan_veb]->seid;\n\t\telse\n\t\t\tuplink_seid = pf->mac_seid;\n\t\tif (pf->lan_vsi == I40E_NO_VSI)\n\t\t\tvsi = i40e_vsi_setup(pf, I40E_VSI_MAIN, uplink_seid, 0);\n\t\telse if (reinit)\n\t\t\tvsi = i40e_vsi_reinit_setup(pf->vsi[pf->lan_vsi]);\n\t\tif (!vsi) {\n\t\t\tdev_info(&pf->pdev->dev, \"setup of MAIN VSI failed\\n\");\n\t\t\ti40e_cloud_filter_exit(pf);\n\t\t\ti40e_fdir_teardown(pf);\n\t\t\treturn -EAGAIN;\n\t\t}\n\t} else {\n\t\t/* force a reset of TC and queue layout configurations */\n\t\tu8 enabled_tc = pf->vsi[pf->lan_vsi]->tc_config.enabled_tc;\n\n\t\tpf->vsi[pf->lan_vsi]->tc_config.enabled_tc = 0;\n\t\tpf->vsi[pf->lan_vsi]->seid = pf->main_vsi_seid;\n\t\ti40e_vsi_config_tc(pf->vsi[pf->lan_vsi], enabled_tc);\n\t}\n\ti40e_vlan_stripping_disable(pf->vsi[pf->lan_vsi]);\n\n\ti40e_fdir_sb_setup(pf);\n\n\t/* Setup static PF queue filter control settings */\n\tret = i40e_setup_pf_filter_control(pf);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"setup_pf_filter_control failed: %d\\n\",\n\t\t\t ret);\n\t\t/* Failure here should not stop continuing other steps */\n\t}\n\n\t/* enable RSS in the HW, even for only one queue, as the stack can use\n\t * the hash\n\t */\n\tif ((pf->flags & I40E_FLAG_RSS_ENABLED))\n\t\ti40e_pf_config_rss(pf);\n\n\t/* fill in link information and enable LSE reporting */\n\ti40e_link_event(pf);\n\n\t/* Initialize user-specific link properties */\n\tpf->fc_autoneg_status = ((pf->hw.phy.link_info.an_info &\n\t\t\t\t  I40E_AQ_AN_COMPLETED) ? true : false);\n\n\ti40e_ptp_init(pf);\n\n\t/* repopulate tunnel port filters */\n\ti40e_sync_udp_filters(pf);\n\n\treturn ret;\n}\n\n/**\n * i40e_determine_queue_usage - Work out queue distribution\n * @pf: board private structure\n **/\nstatic void i40e_determine_queue_usage(struct i40e_pf *pf)\n{\n\tint queues_left;\n\tint q_max;\n\n\tpf->num_lan_qps = 0;\n\n\t/* Find the max queues to be put into basic use.  We'll always be\n\t * using TC0, whether or not DCB is running, and TC0 will get the\n\t * big RSS set.\n\t */\n\tqueues_left = pf->hw.func_caps.num_tx_qp;\n\n\tif ((queues_left == 1) ||\n\t    !(pf->flags & I40E_FLAG_MSIX_ENABLED)) {\n\t\t/* one qp for PF, no queues for anything else */\n\t\tqueues_left = 0;\n\t\tpf->alloc_rss_size = pf->num_lan_qps = 1;\n\n\t\t/* make sure all the fancies are disabled */\n\t\tpf->flags &= ~(I40E_FLAG_RSS_ENABLED\t|\n\t\t\t       I40E_FLAG_IWARP_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_SB_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_ATR_ENABLED\t|\n\t\t\t       I40E_FLAG_DCB_CAPABLE\t|\n\t\t\t       I40E_FLAG_DCB_ENABLED\t|\n\t\t\t       I40E_FLAG_SRIOV_ENABLED\t|\n\t\t\t       I40E_FLAG_VMDQ_ENABLED);\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t} else if (!(pf->flags & (I40E_FLAG_RSS_ENABLED |\n\t\t\t\t  I40E_FLAG_FD_SB_ENABLED |\n\t\t\t\t  I40E_FLAG_FD_ATR_ENABLED |\n\t\t\t\t  I40E_FLAG_DCB_CAPABLE))) {\n\t\t/* one qp for PF */\n\t\tpf->alloc_rss_size = pf->num_lan_qps = 1;\n\t\tqueues_left -= pf->num_lan_qps;\n\n\t\tpf->flags &= ~(I40E_FLAG_RSS_ENABLED\t|\n\t\t\t       I40E_FLAG_IWARP_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_SB_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_ATR_ENABLED\t|\n\t\t\t       I40E_FLAG_DCB_ENABLED\t|\n\t\t\t       I40E_FLAG_VMDQ_ENABLED);\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t} else {\n\t\t/* Not enough queues for all TCs */\n\t\tif ((pf->flags & I40E_FLAG_DCB_CAPABLE) &&\n\t\t    (queues_left < I40E_MAX_TRAFFIC_CLASS)) {\n\t\t\tpf->flags &= ~(I40E_FLAG_DCB_CAPABLE |\n\t\t\t\t\tI40E_FLAG_DCB_ENABLED);\n\t\t\tdev_info(&pf->pdev->dev, \"not enough queues for DCB. DCB is disabled.\\n\");\n\t\t}\n\n\t\t/* limit lan qps to the smaller of qps, cpus or msix */\n\t\tq_max = max_t(int, pf->rss_size_max, num_online_cpus());\n\t\tq_max = min_t(int, q_max, pf->hw.func_caps.num_tx_qp);\n\t\tq_max = min_t(int, q_max, pf->hw.func_caps.num_msix_vectors);\n\t\tpf->num_lan_qps = q_max;\n\n\t\tqueues_left -= pf->num_lan_qps;\n\t}\n\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\tif (queues_left > 1) {\n\t\t\tqueues_left -= 1; /* save 1 queue for FD */\n\t\t} else {\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t\t\tdev_info(&pf->pdev->dev, \"not enough queues for Flow Director. Flow Director feature is disabled\\n\");\n\t\t}\n\t}\n\n\tif ((pf->flags & I40E_FLAG_SRIOV_ENABLED) &&\n\t    pf->num_vf_qps && pf->num_req_vfs && queues_left) {\n\t\tpf->num_req_vfs = min_t(int, pf->num_req_vfs,\n\t\t\t\t\t(queues_left / pf->num_vf_qps));\n\t\tqueues_left -= (pf->num_req_vfs * pf->num_vf_qps);\n\t}\n\n\tif ((pf->flags & I40E_FLAG_VMDQ_ENABLED) &&\n\t    pf->num_vmdq_vsis && pf->num_vmdq_qps && queues_left) {\n\t\tpf->num_vmdq_vsis = min_t(int, pf->num_vmdq_vsis,\n\t\t\t\t\t  (queues_left / pf->num_vmdq_qps));\n\t\tqueues_left -= (pf->num_vmdq_vsis * pf->num_vmdq_qps);\n\t}\n\n\tpf->queues_left = queues_left;\n\tdev_dbg(&pf->pdev->dev,\n\t\t\"qs_avail=%d FD SB=%d lan_qs=%d lan_tc0=%d vf=%d*%d vmdq=%d*%d, remaining=%d\\n\",\n\t\tpf->hw.func_caps.num_tx_qp,\n\t\t!!(pf->flags & I40E_FLAG_FD_SB_ENABLED),\n\t\tpf->num_lan_qps, pf->alloc_rss_size, pf->num_req_vfs,\n\t\tpf->num_vf_qps, pf->num_vmdq_vsis, pf->num_vmdq_qps,\n\t\tqueues_left);\n}\n\n/**\n * i40e_setup_pf_filter_control - Setup PF static filter control\n * @pf: PF to be setup\n *\n * i40e_setup_pf_filter_control sets up a PF's initial filter control\n * settings. If PE/FCoE are enabled then it will also set the per PF\n * based filter sizes required for them. It also enables Flow director,\n * ethertype and macvlan type filter settings for the pf.\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_setup_pf_filter_control(struct i40e_pf *pf)\n{\n\tstruct i40e_filter_control_settings *settings = &pf->filter_settings;\n\n\tsettings->hash_lut_size = I40E_HASH_LUT_SIZE_128;\n\n\t/* Flow Director is enabled */\n\tif (pf->flags & (I40E_FLAG_FD_SB_ENABLED | I40E_FLAG_FD_ATR_ENABLED))\n\t\tsettings->enable_fdir = true;\n\n\t/* Ethtype and MACVLAN filters enabled for PF */\n\tsettings->enable_ethtype = true;\n\tsettings->enable_macvlan = true;\n\n\tif (i40e_set_filter_control(&pf->hw, settings))\n\t\treturn -ENOENT;\n\n\treturn 0;\n}\n\n#define INFO_STRING_LEN 255\n#define REMAIN(__x) (INFO_STRING_LEN - (__x))\nstatic void i40e_print_features(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tchar *buf;\n\tint i;\n\n\tbuf = kmalloc(INFO_STRING_LEN, GFP_KERNEL);\n\tif (!buf)\n\t\treturn;\n\n\ti = snprintf(buf, INFO_STRING_LEN, \"Features: PF-id[%d]\", hw->pf_id);\n#ifdef CONFIG_PCI_IOV\n\ti += snprintf(&buf[i], REMAIN(i), \" VFs: %d\", pf->num_req_vfs);\n#endif\n\ti += snprintf(&buf[i], REMAIN(i), \" VSIs: %d QP: %d\",\n\t\t      pf->hw.func_caps.num_vsis,\n\t\t      pf->vsi[pf->lan_vsi]->num_queue_pairs);\n\tif (pf->flags & I40E_FLAG_RSS_ENABLED)\n\t\ti += snprintf(&buf[i], REMAIN(i), \" RSS\");\n\tif (pf->flags & I40E_FLAG_FD_ATR_ENABLED)\n\t\ti += snprintf(&buf[i], REMAIN(i), \" FD_ATR\");\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\ti += snprintf(&buf[i], REMAIN(i), \" FD_SB\");\n\t\ti += snprintf(&buf[i], REMAIN(i), \" NTUPLE\");\n\t}\n\tif (pf->flags & I40E_FLAG_DCB_CAPABLE)\n\t\ti += snprintf(&buf[i], REMAIN(i), \" DCB\");\n\ti += snprintf(&buf[i], REMAIN(i), \" VxLAN\");\n\ti += snprintf(&buf[i], REMAIN(i), \" Geneve\");\n\tif (pf->flags & I40E_FLAG_PTP)\n\t\ti += snprintf(&buf[i], REMAIN(i), \" PTP\");\n\tif (pf->flags & I40E_FLAG_VEB_MODE_ENABLED)\n\t\ti += snprintf(&buf[i], REMAIN(i), \" VEB\");\n\telse\n\t\ti += snprintf(&buf[i], REMAIN(i), \" VEPA\");\n\n\tdev_info(&pf->pdev->dev, \"%s\\n\", buf);\n\tkfree(buf);\n\tWARN_ON(i > INFO_STRING_LEN);\n}\n\n/**\n * i40e_get_platform_mac_addr - get platform-specific MAC address\n * @pdev: PCI device information struct\n * @pf: board private structure\n *\n * Look up the MAC address for the device. First we'll try\n * eth_platform_get_mac_address, which will check Open Firmware, or arch\n * specific fallback. Otherwise, we'll default to the stored value in\n * firmware.\n **/\nstatic void i40e_get_platform_mac_addr(struct pci_dev *pdev, struct i40e_pf *pf)\n{\n\tif (eth_platform_get_mac_address(&pdev->dev, pf->hw.mac.addr))\n\t\ti40e_get_mac_addr(&pf->hw, pf->hw.mac.addr);\n}\n\n/**\n * i40e_set_fec_in_flags - helper function for setting FEC options in flags\n * @fec_cfg: FEC option to set in flags\n * @flags: ptr to flags in which we set FEC option\n **/\nvoid i40e_set_fec_in_flags(u8 fec_cfg, u32 *flags)\n{\n\tif (fec_cfg & I40E_AQ_SET_FEC_AUTO)\n\t\t*flags |= I40E_FLAG_RS_FEC | I40E_FLAG_BASE_R_FEC;\n\tif ((fec_cfg & I40E_AQ_SET_FEC_REQUEST_RS) ||\n\t    (fec_cfg & I40E_AQ_SET_FEC_ABILITY_RS)) {\n\t\t*flags |= I40E_FLAG_RS_FEC;\n\t\t*flags &= ~I40E_FLAG_BASE_R_FEC;\n\t}\n\tif ((fec_cfg & I40E_AQ_SET_FEC_REQUEST_KR) ||\n\t    (fec_cfg & I40E_AQ_SET_FEC_ABILITY_KR)) {\n\t\t*flags |= I40E_FLAG_BASE_R_FEC;\n\t\t*flags &= ~I40E_FLAG_RS_FEC;\n\t}\n\tif (fec_cfg == 0)\n\t\t*flags &= ~(I40E_FLAG_RS_FEC | I40E_FLAG_BASE_R_FEC);\n}\n\n/**\n * i40e_check_recovery_mode - check if we are running transition firmware\n * @pf: board private structure\n *\n * Check registers indicating the firmware runs in recovery mode. Sets the\n * appropriate driver state.\n *\n * Returns true if the recovery mode was detected, false otherwise\n **/\nstatic bool i40e_check_recovery_mode(struct i40e_pf *pf)\n{\n\tu32 val = rd32(&pf->hw, I40E_GL_FWSTS) & I40E_GL_FWSTS_FWS1B_MASK;\n\tbool is_recovery_mode = false;\n\n\tif (pf->hw.mac.type == I40E_MAC_XL710)\n\t\tis_recovery_mode =\n\t\tval == I40E_XL710_GL_FWSTS_FWS1B_REC_MOD_CORER_MASK ||\n\t\tval == I40E_XL710_GL_FWSTS_FWS1B_REC_MOD_GLOBR_MASK ||\n\t\tval == I40E_XL710_GL_FWSTS_FWS1B_REC_MOD_TRANSITION_MASK ||\n\t\tval == I40E_XL710_GL_FWSTS_FWS1B_REC_MOD_NVM_MASK;\n\tif (pf->hw.mac.type == I40E_MAC_X722)\n\t\tis_recovery_mode =\n\t\tval == I40E_X722_GL_FWSTS_FWS1B_REC_MOD_CORER_MASK ||\n\t\tval == I40E_X722_GL_FWSTS_FWS1B_REC_MOD_GLOBR_MASK;\n\tif (is_recovery_mode) {\n\t\tdev_notice(&pf->pdev->dev, \"Firmware recovery mode detected. Limiting functionality.\\n\");\n\t\tdev_notice(&pf->pdev->dev, \"Refer to the Intel(R) Ethernet Adapters and Devices User Guide for details on firmware recovery mode.\\n\");\n\t\tset_bit(__I40E_RECOVERY_MODE, pf->state);\n\n\t\treturn true;\n\t}\n\tif (test_and_clear_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\tdev_info(&pf->pdev->dev, \"Reinitializing in normal mode with full functionality.\\n\");\n\n\treturn false;\n}\n\n/**\n * i40e_pf_loop_reset - perform reset in a loop.\n * @pf: board private structure\n *\n * This function is useful when a NIC is about to enter recovery mode.\n * When a NIC's internal data structures are corrupted the NIC's\n * firmware is going to enter recovery mode.\n * Right after a POR it takes about 7 minutes for firmware to enter\n * recovery mode. Until that time a NIC is in some kind of intermediate\n * state. After that time period the NIC almost surely enters\n * recovery mode. The only way for a driver to detect intermediate\n * state is to issue a series of pf-resets and check a return value.\n * If a PF reset returns success then the firmware could be in recovery\n * mode so the caller of this code needs to check for recovery mode\n * if this function returns success. There is a little chance that\n * firmware will hang in intermediate state forever.\n * Since waiting 7 minutes is quite a lot of time this function waits\n * 10 seconds and then gives up by returning an error.\n *\n * Return 0 on success, negative on failure.\n **/\nstatic i40e_status i40e_pf_loop_reset(struct i40e_pf *pf)\n{\n\tconst unsigned short MAX_CNT = 1000;\n\tconst unsigned short MSECS = 10;\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret;\n\tint cnt;\n\n\tfor (cnt = 0; cnt < MAX_CNT; ++cnt) {\n\t\tret = i40e_pf_reset(hw);\n\t\tif (!ret)\n\t\t\tbreak;\n\t\tmsleep(MSECS);\n\t}\n\n\tif (cnt == MAX_CNT) {\n\t\tdev_info(&pf->pdev->dev, \"PF reset failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tpf->pfr_count++;\n\treturn ret;\n}\n\n/**\n * i40e_init_recovery_mode - initialize subsystems needed in recovery mode\n * @pf: board private structure\n * @hw: ptr to the hardware info\n *\n * This function does a minimal setup of all subsystems needed for running\n * recovery mode.\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_init_recovery_mode(struct i40e_pf *pf, struct i40e_hw *hw)\n{\n\tstruct i40e_vsi *vsi;\n\tint err;\n\tint v_idx;\n\n\tpci_save_state(pf->pdev);\n\n\t/* set up periodic task facility */\n\ttimer_setup(&pf->service_timer, i40e_service_timer, 0);\n\tpf->service_timer_period = HZ;\n\n\tINIT_WORK(&pf->service_task, i40e_service_task);\n\tclear_bit(__I40E_SERVICE_SCHED, pf->state);\n\n\terr = i40e_init_interrupt_scheme(pf);\n\tif (err)\n\t\tgoto err_switch_setup;\n\n\t/* The number of VSIs reported by the FW is the minimum guaranteed\n\t * to us; HW supports far more and we share the remaining pool with\n\t * the other PFs. We allocate space for more than the guarantee with\n\t * the understanding that we might not get them all later.\n\t */\n\tif (pf->hw.func_caps.num_vsis < I40E_MIN_VSI_ALLOC)\n\t\tpf->num_alloc_vsi = I40E_MIN_VSI_ALLOC;\n\telse\n\t\tpf->num_alloc_vsi = pf->hw.func_caps.num_vsis;\n\n\t/* Set up the vsi struct and our local tracking of the MAIN PF vsi. */\n\tpf->vsi = kcalloc(pf->num_alloc_vsi, sizeof(struct i40e_vsi *),\n\t\t\t  GFP_KERNEL);\n\tif (!pf->vsi) {\n\t\terr = -ENOMEM;\n\t\tgoto err_switch_setup;\n\t}\n\n\t/* We allocate one VSI which is needed as absolute minimum\n\t * in order to register the netdev\n\t */\n\tv_idx = i40e_vsi_mem_alloc(pf, I40E_VSI_MAIN);\n\tif (v_idx < 0)\n\t\tgoto err_switch_setup;\n\tpf->lan_vsi = v_idx;\n\tvsi = pf->vsi[v_idx];\n\tif (!vsi)\n\t\tgoto err_switch_setup;\n\tvsi->alloc_queue_pairs = 1;\n\terr = i40e_config_netdev(vsi);\n\tif (err)\n\t\tgoto err_switch_setup;\n\terr = register_netdev(vsi->netdev);\n\tif (err)\n\t\tgoto err_switch_setup;\n\tvsi->netdev_registered = true;\n\ti40e_dbg_pf_init(pf);\n\n\terr = i40e_setup_misc_vector_for_recovery_mode(pf);\n\tif (err)\n\t\tgoto err_switch_setup;\n\n\t/* tell the firmware that we're starting */\n\ti40e_send_version(pf);\n\n\t/* since everything's happy, start the service_task timer */\n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\n\treturn 0;\n\nerr_switch_setup:\n\ti40e_reset_interrupt_capability(pf);\n\tdel_timer_sync(&pf->service_timer);\n\ti40e_shutdown_adminq(hw);\n\tiounmap(hw->hw_addr);\n\tpci_disable_pcie_error_reporting(pf->pdev);\n\tpci_release_mem_regions(pf->pdev);\n\tpci_disable_device(pf->pdev);\n\tkfree(pf);\n\n\treturn err;\n}\n\n/**\n * i40e_probe - Device initialization routine\n * @pdev: PCI device information struct\n * @ent: entry in i40e_pci_tbl\n *\n * i40e_probe initializes a PF identified by a pci_dev structure.\n * The OS initialization, configuring of the PF private structure,\n * and a hardware reset occur.\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct i40e_aq_get_phy_abilities_resp abilities;\n\tstruct i40e_pf *pf;\n\tstruct i40e_hw *hw;\n\tstatic u16 pfs_found;\n\tu16 wol_nvm_bits;\n\tu16 link_status;\n\tint err;\n\tu32 val;\n\tu32 i;\n\tu8 set_fc_aq_fail;\n\n\terr = pci_enable_device_mem(pdev);\n\tif (err)\n\t\treturn err;\n\n\t/* set up for high or low dma */\n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (err) {\n\t\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\t\tif (err) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"DMA configuration failed: 0x%x\\n\", err);\n\t\t\tgoto err_dma;\n\t\t}\n\t}\n\n\t/* set up pci connections */\n\terr = pci_request_mem_regions(pdev, i40e_driver_name);\n\tif (err) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"pci_request_selected_regions failed %d\\n\", err);\n\t\tgoto err_pci_reg;\n\t}\n\n\tpci_enable_pcie_error_reporting(pdev);\n\tpci_set_master(pdev);\n\n\t/* Now that we have a PCI connection, we need to do the\n\t * low level device setup.  This is primarily setting up\n\t * the Admin Queue structures and then querying for the\n\t * device's current profile information.\n\t */\n\tpf = kzalloc(sizeof(*pf), GFP_KERNEL);\n\tif (!pf) {\n\t\terr = -ENOMEM;\n\t\tgoto err_pf_alloc;\n\t}\n\tpf->next_vsi = 0;\n\tpf->pdev = pdev;\n\tset_bit(__I40E_DOWN, pf->state);\n\n\thw = &pf->hw;\n\thw->back = pf;\n\n\tpf->ioremap_len = min_t(int, pci_resource_len(pdev, 0),\n\t\t\t\tI40E_MAX_CSR_SPACE);\n\t/* We believe that the highest register to read is\n\t * I40E_GLGEN_STAT_CLEAR, so we check if the BAR size\n\t * is not less than that before mapping to prevent a\n\t * kernel panic.\n\t */\n\tif (pf->ioremap_len < I40E_GLGEN_STAT_CLEAR) {\n\t\tdev_err(&pdev->dev, \"Cannot map registers, bar size 0x%X too small, aborting\\n\",\n\t\t\tpf->ioremap_len);\n\t\terr = -ENOMEM;\n\t\tgoto err_ioremap;\n\t}\n\thw->hw_addr = ioremap(pci_resource_start(pdev, 0), pf->ioremap_len);\n\tif (!hw->hw_addr) {\n\t\terr = -EIO;\n\t\tdev_info(&pdev->dev, \"ioremap(0x%04x, 0x%04x) failed: 0x%x\\n\",\n\t\t\t (unsigned int)pci_resource_start(pdev, 0),\n\t\t\t pf->ioremap_len, err);\n\t\tgoto err_ioremap;\n\t}\n\thw->vendor_id = pdev->vendor;\n\thw->device_id = pdev->device;\n\tpci_read_config_byte(pdev, PCI_REVISION_ID, &hw->revision_id);\n\thw->subsystem_vendor_id = pdev->subsystem_vendor;\n\thw->subsystem_device_id = pdev->subsystem_device;\n\thw->bus.device = PCI_SLOT(pdev->devfn);\n\thw->bus.func = PCI_FUNC(pdev->devfn);\n\thw->bus.bus_id = pdev->bus->number;\n\tpf->instance = pfs_found;\n\n\t/* Select something other than the 802.1ad ethertype for the\n\t * switch to use internally and drop on ingress.\n\t */\n\thw->switch_tag = 0xffff;\n\thw->first_tag = ETH_P_8021AD;\n\thw->second_tag = ETH_P_8021Q;\n\n\tINIT_LIST_HEAD(&pf->l3_flex_pit_list);\n\tINIT_LIST_HEAD(&pf->l4_flex_pit_list);\n\tINIT_LIST_HEAD(&pf->ddp_old_prof);\n\n\t/* set up the locks for the AQ, do this only once in probe\n\t * and destroy them only once in remove\n\t */\n\tmutex_init(&hw->aq.asq_mutex);\n\tmutex_init(&hw->aq.arq_mutex);\n\n\tpf->msg_enable = netif_msg_init(debug,\n\t\t\t\t\tNETIF_MSG_DRV |\n\t\t\t\t\tNETIF_MSG_PROBE |\n\t\t\t\t\tNETIF_MSG_LINK);\n\tif (debug < -1)\n\t\tpf->hw.debug_mask = debug;\n\n\t/* do a special CORER for clearing PXE mode once at init */\n\tif (hw->revision_id == 0 &&\n\t    (rd32(hw, I40E_GLLAN_RCTL_0) & I40E_GLLAN_RCTL_0_PXE_MODE_MASK)) {\n\t\twr32(hw, I40E_GLGEN_RTRIG, I40E_GLGEN_RTRIG_CORER_MASK);\n\t\ti40e_flush(hw);\n\t\tmsleep(200);\n\t\tpf->corer_count++;\n\n\t\ti40e_clear_pxe_mode(hw);\n\t}\n\n\t/* Reset here to make sure all is clean and to define PF 'n' */\n\ti40e_clear_hw(hw);\n\n\terr = i40e_set_mac_type(hw);\n\tif (err) {\n\t\tdev_warn(&pdev->dev, \"unidentified MAC or BLANK NVM: %d\\n\",\n\t\t\t err);\n\t\tgoto err_pf_reset;\n\t}\n\n\terr = i40e_pf_loop_reset(pf);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"Initial pf_reset failed: %d\\n\", err);\n\t\tgoto err_pf_reset;\n\t}\n\n\ti40e_check_recovery_mode(pf);\n\n\thw->aq.num_arq_entries = I40E_AQ_LEN;\n\thw->aq.num_asq_entries = I40E_AQ_LEN;\n\thw->aq.arq_buf_size = I40E_MAX_AQ_BUF_SIZE;\n\thw->aq.asq_buf_size = I40E_MAX_AQ_BUF_SIZE;\n\tpf->adminq_work_limit = I40E_AQ_WORK_LIMIT;\n\n\tsnprintf(pf->int_name, sizeof(pf->int_name) - 1,\n\t\t \"%s-%s:misc\",\n\t\t dev_driver_string(&pf->pdev->dev), dev_name(&pdev->dev));\n\n\terr = i40e_init_shared_code(hw);\n\tif (err) {\n\t\tdev_warn(&pdev->dev, \"unidentified MAC or BLANK NVM: %d\\n\",\n\t\t\t err);\n\t\tgoto err_pf_reset;\n\t}\n\n\t/* set up a default setting for link flow control */\n\tpf->hw.fc.requested_mode = I40E_FC_NONE;\n\n\terr = i40e_init_adminq(hw);\n\tif (err) {\n\t\tif (err == I40E_ERR_FIRMWARE_API_VERSION)\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"The driver for the device stopped because the NVM image v%u.%u is newer than expected v%u.%u. You must install the most recent version of the network driver.\\n\",\n\t\t\t\t hw->aq.api_maj_ver,\n\t\t\t\t hw->aq.api_min_ver,\n\t\t\t\t I40E_FW_API_VERSION_MAJOR,\n\t\t\t\t I40E_FW_MINOR_VERSION(hw));\n\t\telse\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"The driver for the device stopped because the device firmware failed to init. Try updating your NVM image.\\n\");\n\n\t\tgoto err_pf_reset;\n\t}\n\ti40e_get_oem_version(hw);\n\n\t/* provide nvm, fw, api versions, vendor:device id, subsys vendor:device id */\n\tdev_info(&pdev->dev, \"fw %d.%d.%05d api %d.%d nvm %s [%04x:%04x] [%04x:%04x]\\n\",\n\t\t hw->aq.fw_maj_ver, hw->aq.fw_min_ver, hw->aq.fw_build,\n\t\t hw->aq.api_maj_ver, hw->aq.api_min_ver,\n\t\t i40e_nvm_version_str(hw), hw->vendor_id, hw->device_id,\n\t\t hw->subsystem_vendor_id, hw->subsystem_device_id);\n\n\tif (hw->aq.api_maj_ver == I40E_FW_API_VERSION_MAJOR &&\n\t    hw->aq.api_min_ver > I40E_FW_MINOR_VERSION(hw))\n\t\tdev_info(&pdev->dev,\n\t\t\t \"The driver for the device detected a newer version of the NVM image v%u.%u than expected v%u.%u. Please install the most recent version of the network driver.\\n\",\n\t\t\t hw->aq.api_maj_ver,\n\t\t\t hw->aq.api_min_ver,\n\t\t\t I40E_FW_API_VERSION_MAJOR,\n\t\t\t I40E_FW_MINOR_VERSION(hw));\n\telse if (hw->aq.api_maj_ver == 1 && hw->aq.api_min_ver < 4)\n\t\tdev_info(&pdev->dev,\n\t\t\t \"The driver for the device detected an older version of the NVM image v%u.%u than expected v%u.%u. Please update the NVM image.\\n\",\n\t\t\t hw->aq.api_maj_ver,\n\t\t\t hw->aq.api_min_ver,\n\t\t\t I40E_FW_API_VERSION_MAJOR,\n\t\t\t I40E_FW_MINOR_VERSION(hw));\n\n\ti40e_verify_eeprom(pf);\n\n\t/* Rev 0 hardware was never productized */\n\tif (hw->revision_id < 1)\n\t\tdev_warn(&pdev->dev, \"This device is a pre-production adapter/LOM. Please be aware there may be issues with your hardware. If you are experiencing problems please contact your Intel or hardware representative who provided you with this hardware.\\n\");\n\n\ti40e_clear_pxe_mode(hw);\n\n\terr = i40e_get_capabilities(pf, i40e_aqc_opc_list_func_capabilities);\n\tif (err)\n\t\tgoto err_adminq_setup;\n\n\terr = i40e_sw_init(pf);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"sw_init failed: %d\\n\", err);\n\t\tgoto err_sw_init;\n\t}\n\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\treturn i40e_init_recovery_mode(pf, hw);\n\n\terr = i40e_init_lan_hmc(hw, hw->func_caps.num_tx_qp,\n\t\t\t\thw->func_caps.num_rx_qp, 0, 0);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"init_lan_hmc failed: %d\\n\", err);\n\t\tgoto err_init_lan_hmc;\n\t}\n\n\terr = i40e_configure_lan_hmc(hw, I40E_HMC_MODEL_DIRECT_ONLY);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"configure_lan_hmc failed: %d\\n\", err);\n\t\terr = -ENOENT;\n\t\tgoto err_configure_lan_hmc;\n\t}\n\n\t/* Disable LLDP for NICs that have firmware versions lower than v4.3.\n\t * Ignore error return codes because if it was already disabled via\n\t * hardware settings this will fail\n\t */\n\tif (pf->hw_features & I40E_HW_STOP_FW_LLDP) {\n\t\tdev_info(&pdev->dev, \"Stopping firmware LLDP agent.\\n\");\n\t\ti40e_aq_stop_lldp(hw, true, false, NULL);\n\t}\n\n\t/* allow a platform config to override the HW addr */\n\ti40e_get_platform_mac_addr(pdev, pf);\n\n\tif (!is_valid_ether_addr(hw->mac.addr)) {\n\t\tdev_info(&pdev->dev, \"invalid MAC address %pM\\n\", hw->mac.addr);\n\t\terr = -EIO;\n\t\tgoto err_mac_addr;\n\t}\n\tdev_info(&pdev->dev, \"MAC address: %pM\\n\", hw->mac.addr);\n\tether_addr_copy(hw->mac.perm_addr, hw->mac.addr);\n\ti40e_get_port_mac_addr(hw, hw->mac.port_addr);\n\tif (is_valid_ether_addr(hw->mac.port_addr))\n\t\tpf->hw_features |= I40E_HW_PORT_ID_VALID;\n\n\tpci_set_drvdata(pdev, pf);\n\tpci_save_state(pdev);\n\n\tdev_info(&pdev->dev,\n\t\t (pf->flags & I40E_FLAG_DISABLE_FW_LLDP) ?\n\t\t\t\"FW LLDP is disabled\\n\" :\n\t\t\t\"FW LLDP is enabled\\n\");\n\n\t/* Enable FW to write default DCB config on link-up */\n\ti40e_aq_set_dcb_parameters(hw, true, NULL);\n\n#ifdef CONFIG_I40E_DCB\n\terr = i40e_init_pf_dcb(pf);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"DCB init failed %d, disabled\\n\", err);\n\t\tpf->flags &= ~(I40E_FLAG_DCB_CAPABLE | I40E_FLAG_DCB_ENABLED);\n\t\t/* Continue without DCB enabled */\n\t}\n#endif /* CONFIG_I40E_DCB */\n\n\t/* set up periodic task facility */\n\ttimer_setup(&pf->service_timer, i40e_service_timer, 0);\n\tpf->service_timer_period = HZ;\n\n\tINIT_WORK(&pf->service_task, i40e_service_task);\n\tclear_bit(__I40E_SERVICE_SCHED, pf->state);\n\n\t/* NVM bit on means WoL disabled for the port */\n\ti40e_read_nvm_word(hw, I40E_SR_NVM_WAKE_ON_LAN, &wol_nvm_bits);\n\tif (BIT (hw->port) & wol_nvm_bits || hw->partition_id != 1)\n\t\tpf->wol_en = false;\n\telse\n\t\tpf->wol_en = true;\n\tdevice_set_wakeup_enable(&pf->pdev->dev, pf->wol_en);\n\n\t/* set up the main switch operations */\n\ti40e_determine_queue_usage(pf);\n\terr = i40e_init_interrupt_scheme(pf);\n\tif (err)\n\t\tgoto err_switch_setup;\n\n\t/* The number of VSIs reported by the FW is the minimum guaranteed\n\t * to us; HW supports far more and we share the remaining pool with\n\t * the other PFs. We allocate space for more than the guarantee with\n\t * the understanding that we might not get them all later.\n\t */\n\tif (pf->hw.func_caps.num_vsis < I40E_MIN_VSI_ALLOC)\n\t\tpf->num_alloc_vsi = I40E_MIN_VSI_ALLOC;\n\telse\n\t\tpf->num_alloc_vsi = pf->hw.func_caps.num_vsis;\n\n\t/* Set up the *vsi struct and our local tracking of the MAIN PF vsi. */\n\tpf->vsi = kcalloc(pf->num_alloc_vsi, sizeof(struct i40e_vsi *),\n\t\t\t  GFP_KERNEL);\n\tif (!pf->vsi) {\n\t\terr = -ENOMEM;\n\t\tgoto err_switch_setup;\n\t}\n\n#ifdef CONFIG_PCI_IOV\n\t/* prep for VF support */\n\tif ((pf->flags & I40E_FLAG_SRIOV_ENABLED) &&\n\t    (pf->flags & I40E_FLAG_MSIX_ENABLED) &&\n\t    !test_bit(__I40E_BAD_EEPROM, pf->state)) {\n\t\tif (pci_num_vf(pdev))\n\t\t\tpf->flags |= I40E_FLAG_VEB_MODE_ENABLED;\n\t}\n#endif\n\terr = i40e_setup_pf_switch(pf, false);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"setup_pf_switch failed: %d\\n\", err);\n\t\tgoto err_vsis;\n\t}\n\tINIT_LIST_HEAD(&pf->vsi[pf->lan_vsi]->ch_list);\n\n\t/* Make sure flow control is set according to current settings */\n\terr = i40e_set_fc(hw, &set_fc_aq_fail, true);\n\tif (set_fc_aq_fail & I40E_SET_FC_AQ_FAIL_GET)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Set fc with err %s aq_err %s on get_phy_cap\\n\",\n\t\t\ti40e_stat_str(hw, err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\tif (set_fc_aq_fail & I40E_SET_FC_AQ_FAIL_SET)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Set fc with err %s aq_err %s on set_phy_config\\n\",\n\t\t\ti40e_stat_str(hw, err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\tif (set_fc_aq_fail & I40E_SET_FC_AQ_FAIL_UPDATE)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Set fc with err %s aq_err %s on get_link_info\\n\",\n\t\t\ti40e_stat_str(hw, err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\n\t/* if FDIR VSI was set up, start it now */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i] && pf->vsi[i]->type == I40E_VSI_FDIR) {\n\t\t\ti40e_vsi_open(pf->vsi[i]);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* The driver only wants link up/down and module qualification\n\t * reports from firmware.  Note the negative logic.\n\t */\n\terr = i40e_aq_set_phy_int_mask(&pf->hw,\n\t\t\t\t       ~(I40E_AQ_EVENT_LINK_UPDOWN |\n\t\t\t\t\t I40E_AQ_EVENT_MEDIA_NA |\n\t\t\t\t\t I40E_AQ_EVENT_MODULE_QUAL_FAIL), NULL);\n\tif (err)\n\t\tdev_info(&pf->pdev->dev, \"set phy mask fail, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, err),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t/* Reconfigure hardware for allowing smaller MSS in the case\n\t * of TSO, so that we avoid the MDD being fired and causing\n\t * a reset in the case of small MSS+TSO.\n\t */\n\tval = rd32(hw, I40E_REG_MSS);\n\tif ((val & I40E_REG_MSS_MIN_MASK) > I40E_64BYTE_MSS) {\n\t\tval &= ~I40E_REG_MSS_MIN_MASK;\n\t\tval |= I40E_64BYTE_MSS;\n\t\twr32(hw, I40E_REG_MSS, val);\n\t}\n\n\tif (pf->hw_features & I40E_HW_RESTART_AUTONEG) {\n\t\tmsleep(75);\n\t\terr = i40e_aq_set_link_restart_an(&pf->hw, true, NULL);\n\t\tif (err)\n\t\t\tdev_info(&pf->pdev->dev, \"link restart failed, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, err),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t}\n\t/* The main driver is (mostly) up and happy. We need to set this state\n\t * before setting up the misc vector or we get a race and the vector\n\t * ends up disabled forever.\n\t */\n\tclear_bit(__I40E_DOWN, pf->state);\n\n\t/* In case of MSIX we are going to setup the misc vector right here\n\t * to handle admin queue events etc. In case of legacy and MSI\n\t * the misc functionality and queue processing is combined in\n\t * the same vector and that gets setup at open.\n\t */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\terr = i40e_setup_misc_vector(pf);\n\t\tif (err) {\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"setup of misc vector failed: %d\\n\", err);\n\t\t\tgoto err_vsis;\n\t\t}\n\t}\n\n#ifdef CONFIG_PCI_IOV\n\t/* prep for VF support */\n\tif ((pf->flags & I40E_FLAG_SRIOV_ENABLED) &&\n\t    (pf->flags & I40E_FLAG_MSIX_ENABLED) &&\n\t    !test_bit(__I40E_BAD_EEPROM, pf->state)) {\n\t\t/* disable link interrupts for VFs */\n\t\tval = rd32(hw, I40E_PFGEN_PORTMDIO_NUM);\n\t\tval &= ~I40E_PFGEN_PORTMDIO_NUM_VFLINK_STAT_ENA_MASK;\n\t\twr32(hw, I40E_PFGEN_PORTMDIO_NUM, val);\n\t\ti40e_flush(hw);\n\n\t\tif (pci_num_vf(pdev)) {\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"Active VFs found, allocating resources.\\n\");\n\t\t\terr = i40e_alloc_vfs(pf, pci_num_vf(pdev));\n\t\t\tif (err)\n\t\t\t\tdev_info(&pdev->dev,\n\t\t\t\t\t \"Error %d allocating resources for existing VFs\\n\",\n\t\t\t\t\t err);\n\t\t}\n\t}\n#endif /* CONFIG_PCI_IOV */\n\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tpf->iwarp_base_vector = i40e_get_lump(pf, pf->irq_pile,\n\t\t\t\t\t\t      pf->num_iwarp_msix,\n\t\t\t\t\t\t      I40E_IWARP_IRQ_PILE_ID);\n\t\tif (pf->iwarp_base_vector < 0) {\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"failed to get tracking for %d vectors for IWARP err=%d\\n\",\n\t\t\t\t pf->num_iwarp_msix, pf->iwarp_base_vector);\n\t\t\tpf->flags &= ~I40E_FLAG_IWARP_ENABLED;\n\t\t}\n\t}\n\n\ti40e_dbg_pf_init(pf);\n\n\t/* tell the firmware that we're starting */\n\ti40e_send_version(pf);\n\n\t/* since everything's happy, start the service_task timer */\n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\n\t/* add this PF to client device list and launch a client service task */\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\terr = i40e_lan_add_device(pf);\n\t\tif (err)\n\t\t\tdev_info(&pdev->dev, \"Failed to add PF to client API service list: %d\\n\",\n\t\t\t\t err);\n\t}\n\n#define PCI_SPEED_SIZE 8\n#define PCI_WIDTH_SIZE 8\n\t/* Devices on the IOSF bus do not have this information\n\t * and will report PCI Gen 1 x 1 by default so don't bother\n\t * checking them.\n\t */\n\tif (!(pf->hw_features & I40E_HW_NO_PCI_LINK_CHECK)) {\n\t\tchar speed[PCI_SPEED_SIZE] = \"Unknown\";\n\t\tchar width[PCI_WIDTH_SIZE] = \"Unknown\";\n\n\t\t/* Get the negotiated link width and speed from PCI config\n\t\t * space\n\t\t */\n\t\tpcie_capability_read_word(pf->pdev, PCI_EXP_LNKSTA,\n\t\t\t\t\t  &link_status);\n\n\t\ti40e_set_pci_config_data(hw, link_status);\n\n\t\tswitch (hw->bus.speed) {\n\t\tcase i40e_bus_speed_8000:\n\t\t\tstrlcpy(speed, \"8.0\", PCI_SPEED_SIZE); break;\n\t\tcase i40e_bus_speed_5000:\n\t\t\tstrlcpy(speed, \"5.0\", PCI_SPEED_SIZE); break;\n\t\tcase i40e_bus_speed_2500:\n\t\t\tstrlcpy(speed, \"2.5\", PCI_SPEED_SIZE); break;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tswitch (hw->bus.width) {\n\t\tcase i40e_bus_width_pcie_x8:\n\t\t\tstrlcpy(width, \"8\", PCI_WIDTH_SIZE); break;\n\t\tcase i40e_bus_width_pcie_x4:\n\t\t\tstrlcpy(width, \"4\", PCI_WIDTH_SIZE); break;\n\t\tcase i40e_bus_width_pcie_x2:\n\t\t\tstrlcpy(width, \"2\", PCI_WIDTH_SIZE); break;\n\t\tcase i40e_bus_width_pcie_x1:\n\t\t\tstrlcpy(width, \"1\", PCI_WIDTH_SIZE); break;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tdev_info(&pdev->dev, \"PCI-Express: Speed %sGT/s Width x%s\\n\",\n\t\t\t speed, width);\n\n\t\tif (hw->bus.width < i40e_bus_width_pcie_x8 ||\n\t\t    hw->bus.speed < i40e_bus_speed_8000) {\n\t\t\tdev_warn(&pdev->dev, \"PCI-Express bandwidth available for this device may be insufficient for optimal performance.\\n\");\n\t\t\tdev_warn(&pdev->dev, \"Please move the device to a different PCI-e link with more lanes and/or higher transfer rate.\\n\");\n\t\t}\n\t}\n\n\t/* get the requested speeds from the fw */\n\terr = i40e_aq_get_phy_capabilities(hw, false, false, &abilities, NULL);\n\tif (err)\n\t\tdev_dbg(&pf->pdev->dev, \"get requested speeds ret =  %s last_status =  %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, err),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\tpf->hw.phy.link_info.requested_speeds = abilities.link_speed;\n\n\t/* set the FEC config due to the board capabilities */\n\ti40e_set_fec_in_flags(abilities.fec_cfg_curr_mod_ext_info, &pf->flags);\n\n\t/* get the supported phy types from the fw */\n\terr = i40e_aq_get_phy_capabilities(hw, false, true, &abilities, NULL);\n\tif (err)\n\t\tdev_dbg(&pf->pdev->dev, \"get supported phy types ret =  %s last_status =  %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, err),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t/* Add a filter to drop all Flow control frames from any VSI from being\n\t * transmitted. By doing so we stop a malicious VF from sending out\n\t * PAUSE or PFC frames and potentially controlling traffic for other\n\t * PF/VF VSIs.\n\t * The FW can still send Flow control frames if enabled.\n\t */\n\ti40e_add_filter_to_drop_tx_flow_control_frames(&pf->hw,\n\t\t\t\t\t\t       pf->main_vsi_seid);\n\n\tif ((pf->hw.device_id == I40E_DEV_ID_10G_BASE_T) ||\n\t\t(pf->hw.device_id == I40E_DEV_ID_10G_BASE_T4))\n\t\tpf->hw_features |= I40E_HW_PHY_CONTROLS_LEDS;\n\tif (pf->hw.device_id == I40E_DEV_ID_SFP_I_X722)\n\t\tpf->hw_features |= I40E_HW_HAVE_CRT_RETIMER;\n\t/* print a string summarizing features */\n\ti40e_print_features(pf);\n\n\treturn 0;\n\n\t/* Unwind what we've done if something failed in the setup */\nerr_vsis:\n\tset_bit(__I40E_DOWN, pf->state);\n\ti40e_clear_interrupt_scheme(pf);\n\tkfree(pf->vsi);\nerr_switch_setup:\n\ti40e_reset_interrupt_capability(pf);\n\tdel_timer_sync(&pf->service_timer);\nerr_mac_addr:\nerr_configure_lan_hmc:\n\t(void)i40e_shutdown_lan_hmc(hw);\nerr_init_lan_hmc:\n\tkfree(pf->qp_pile);\nerr_sw_init:\nerr_adminq_setup:\nerr_pf_reset:\n\tiounmap(hw->hw_addr);\nerr_ioremap:\n\tkfree(pf);\nerr_pf_alloc:\n\tpci_disable_pcie_error_reporting(pdev);\n\tpci_release_mem_regions(pdev);\nerr_pci_reg:\nerr_dma:\n\tpci_disable_device(pdev);\n\treturn err;\n}\n\n/**\n * i40e_remove - Device removal routine\n * @pdev: PCI device information struct\n *\n * i40e_remove is called by the PCI subsystem to alert the driver\n * that is should release a PCI device.  This could be caused by a\n * Hot-Plug event, or because the driver is going to be removed from\n * memory.\n **/\nstatic void i40e_remove(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret_code;\n\tint i;\n\n\ti40e_dbg_pf_exit(pf);\n\n\ti40e_ptp_stop(pf);\n\n\t/* Disable RSS in hw */\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(0), 0);\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(1), 0);\n\n\t/* no more scheduling of any task */\n\tset_bit(__I40E_SUSPENDED, pf->state);\n\tset_bit(__I40E_DOWN, pf->state);\n\tif (pf->service_timer.function)\n\t\tdel_timer_sync(&pf->service_timer);\n\tif (pf->service_task.func)\n\t\tcancel_work_sync(&pf->service_task);\n\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\tstruct i40e_vsi *vsi = pf->vsi[0];\n\n\t\t/* We know that we have allocated only one vsi for this PF,\n\t\t * it was just for registering netdevice, so the interface\n\t\t * could be visible in the 'ifconfig' output\n\t\t */\n\t\tunregister_netdev(vsi->netdev);\n\t\tfree_netdev(vsi->netdev);\n\n\t\tgoto unmap;\n\t}\n\n\t/* Client close must be called explicitly here because the timer\n\t * has been stopped.\n\t */\n\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi], false);\n\n\tif (pf->flags & I40E_FLAG_SRIOV_ENABLED) {\n\t\ti40e_free_vfs(pf);\n\t\tpf->flags &= ~I40E_FLAG_SRIOV_ENABLED;\n\t}\n\n\ti40e_fdir_teardown(pf);\n\n\t/* If there is a switch structure or any orphans, remove them.\n\t * This will leave only the PF's VSI remaining.\n\t */\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (!pf->veb[i])\n\t\t\tcontinue;\n\n\t\tif (pf->veb[i]->uplink_seid == pf->mac_seid ||\n\t\t    pf->veb[i]->uplink_seid == 0)\n\t\t\ti40e_switch_branch_release(pf->veb[i]);\n\t}\n\n\t/* Now we can shutdown the PF's VSI, just before we kill\n\t * adminq and hmc.\n\t */\n\tif (pf->vsi[pf->lan_vsi])\n\t\ti40e_vsi_release(pf->vsi[pf->lan_vsi]);\n\n\ti40e_cloud_filter_exit(pf);\n\n\t/* remove attached clients */\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tret_code = i40e_lan_del_device(pf);\n\t\tif (ret_code)\n\t\t\tdev_warn(&pdev->dev, \"Failed to delete client device: %d\\n\",\n\t\t\t\t ret_code);\n\t}\n\n\t/* shutdown and destroy the HMC */\n\tif (hw->hmc.hmc_obj) {\n\t\tret_code = i40e_shutdown_lan_hmc(hw);\n\t\tif (ret_code)\n\t\t\tdev_warn(&pdev->dev,\n\t\t\t\t \"Failed to destroy the HMC resources: %d\\n\",\n\t\t\t\t ret_code);\n\t}\n\nunmap:\n\t/* Free MSI/legacy interrupt 0 when in recovery mode. */\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state) &&\n\t    !(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\tfree_irq(pf->pdev->irq, pf);\n\n\t/* shutdown the adminq */\n\ti40e_shutdown_adminq(hw);\n\n\t/* destroy the locks only once, here */\n\tmutex_destroy(&hw->aq.arq_mutex);\n\tmutex_destroy(&hw->aq.asq_mutex);\n\n\t/* Clear all dynamic memory lists of rings, q_vectors, and VSIs */\n\trtnl_lock();\n\ti40e_clear_interrupt_scheme(pf);\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i]) {\n\t\t\tif (!test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\t\t\ti40e_vsi_clear_rings(pf->vsi[i]);\n\t\t\ti40e_vsi_clear(pf->vsi[i]);\n\t\t\tpf->vsi[i] = NULL;\n\t\t}\n\t}\n\trtnl_unlock();\n\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tkfree(pf->veb[i]);\n\t\tpf->veb[i] = NULL;\n\t}\n\n\tkfree(pf->qp_pile);\n\tkfree(pf->vsi);\n\n\tiounmap(hw->hw_addr);\n\tkfree(pf);\n\tpci_release_mem_regions(pdev);\n\n\tpci_disable_pcie_error_reporting(pdev);\n\tpci_disable_device(pdev);\n}\n\n/**\n * i40e_pci_error_detected - warning that something funky happened in PCI land\n * @pdev: PCI device information struct\n * @error: the type of PCI error\n *\n * Called to warn that something happened and the error handling steps\n * are in progress.  Allows the driver to quiesce things, be ready for\n * remediation.\n **/\nstatic pci_ers_result_t i40e_pci_error_detected(struct pci_dev *pdev,\n\t\t\t\t\t\tenum pci_channel_state error)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\tdev_info(&pdev->dev, \"%s: error %d\\n\", __func__, error);\n\n\tif (!pf) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"Cannot recover - error happened during device probe\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\t/* shutdown all operations */\n\tif (!test_bit(__I40E_SUSPENDED, pf->state))\n\t\ti40e_prep_for_reset(pf, false);\n\n\t/* Request a slot reset */\n\treturn PCI_ERS_RESULT_NEED_RESET;\n}\n\n/**\n * i40e_pci_error_slot_reset - a PCI slot reset just happened\n * @pdev: PCI device information struct\n *\n * Called to find if the driver can work with the device now that\n * the pci slot has been reset.  If a basic connection seems good\n * (registers are readable and have sane content) then return a\n * happy little PCI_ERS_RESULT_xxx.\n **/\nstatic pci_ers_result_t i40e_pci_error_slot_reset(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\tpci_ers_result_t result;\n\tu32 reg;\n\n\tdev_dbg(&pdev->dev, \"%s\\n\", __func__);\n\tif (pci_enable_device_mem(pdev)) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"Cannot re-enable PCI device after reset.\\n\");\n\t\tresult = PCI_ERS_RESULT_DISCONNECT;\n\t} else {\n\t\tpci_set_master(pdev);\n\t\tpci_restore_state(pdev);\n\t\tpci_save_state(pdev);\n\t\tpci_wake_from_d3(pdev, false);\n\n\t\treg = rd32(&pf->hw, I40E_GLGEN_RTRIG);\n\t\tif (reg == 0)\n\t\t\tresult = PCI_ERS_RESULT_RECOVERED;\n\t\telse\n\t\t\tresult = PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\treturn result;\n}\n\n/**\n * i40e_pci_error_reset_prepare - prepare device driver for pci reset\n * @pdev: PCI device information struct\n */\nstatic void i40e_pci_error_reset_prepare(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\ti40e_prep_for_reset(pf, false);\n}\n\n/**\n * i40e_pci_error_reset_done - pci reset done, device driver reset can begin\n * @pdev: PCI device information struct\n */\nstatic void i40e_pci_error_reset_done(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\ti40e_reset_and_rebuild(pf, false, false);\n}\n\n/**\n * i40e_pci_error_resume - restart operations after PCI error recovery\n * @pdev: PCI device information struct\n *\n * Called to allow the driver to bring things back up after PCI error\n * and/or reset recovery has finished.\n **/\nstatic void i40e_pci_error_resume(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\tdev_dbg(&pdev->dev, \"%s\\n\", __func__);\n\tif (test_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn;\n\n\ti40e_handle_reset_warning(pf, false);\n}\n\n/**\n * i40e_enable_mc_magic_wake - enable multicast magic packet wake up\n * using the mac_address_write admin q function\n * @pf: pointer to i40e_pf struct\n **/\nstatic void i40e_enable_mc_magic_wake(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret;\n\tu8 mac_addr[6];\n\tu16 flags = 0;\n\n\t/* Get current MAC address in case it's an LAA */\n\tif (pf->vsi[pf->lan_vsi] && pf->vsi[pf->lan_vsi]->netdev) {\n\t\tether_addr_copy(mac_addr,\n\t\t\t\tpf->vsi[pf->lan_vsi]->netdev->dev_addr);\n\t} else {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to retrieve MAC address; using default\\n\");\n\t\tether_addr_copy(mac_addr, hw->mac.addr);\n\t}\n\n\t/* The FW expects the mac address write cmd to first be called with\n\t * one of these flags before calling it again with the multicast\n\t * enable flags.\n\t */\n\tflags = I40E_AQC_WRITE_TYPE_LAA_WOL;\n\n\tif (hw->func_caps.flex10_enable && hw->partition_id != 1)\n\t\tflags = I40E_AQC_WRITE_TYPE_LAA_ONLY;\n\n\tret = i40e_aq_mac_address_write(hw, flags, mac_addr, NULL);\n\tif (ret) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to update MAC address registers; cannot enable Multicast Magic packet wake up\");\n\t\treturn;\n\t}\n\n\tflags = I40E_AQC_MC_MAG_EN\n\t\t\t| I40E_AQC_WOL_PRESERVE_ON_PFR\n\t\t\t| I40E_AQC_WRITE_TYPE_UPDATE_MC_MAG;\n\tret = i40e_aq_mac_address_write(hw, flags, mac_addr, NULL);\n\tif (ret)\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to enable Multicast Magic Packet wake up\\n\");\n}\n\n/**\n * i40e_shutdown - PCI callback for shutting down\n * @pdev: PCI device information struct\n **/\nstatic void i40e_shutdown(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\tstruct i40e_hw *hw = &pf->hw;\n\n\tset_bit(__I40E_SUSPENDED, pf->state);\n\tset_bit(__I40E_DOWN, pf->state);\n\n\tdel_timer_sync(&pf->service_timer);\n\tcancel_work_sync(&pf->service_task);\n\ti40e_cloud_filter_exit(pf);\n\ti40e_fdir_teardown(pf);\n\n\t/* Client close must be called explicitly here because the timer\n\t * has been stopped.\n\t */\n\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi], false);\n\n\tif (pf->wol_en && (pf->hw_features & I40E_HW_WOL_MC_MAGIC_PKT_WAKE))\n\t\ti40e_enable_mc_magic_wake(pf);\n\n\ti40e_prep_for_reset(pf, false);\n\n\twr32(hw, I40E_PFPM_APM,\n\t     (pf->wol_en ? I40E_PFPM_APM_APME_MASK : 0));\n\twr32(hw, I40E_PFPM_WUFC,\n\t     (pf->wol_en ? I40E_PFPM_WUFC_MAG_MASK : 0));\n\n\t/* Free MSI/legacy interrupt 0 when in recovery mode. */\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state) &&\n\t    !(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\tfree_irq(pf->pdev->irq, pf);\n\n\t/* Since we're going to destroy queues during the\n\t * i40e_clear_interrupt_scheme() we should hold the RTNL lock for this\n\t * whole section\n\t */\n\trtnl_lock();\n\ti40e_clear_interrupt_scheme(pf);\n\trtnl_unlock();\n\n\tif (system_state == SYSTEM_POWER_OFF) {\n\t\tpci_wake_from_d3(pdev, pf->wol_en);\n\t\tpci_set_power_state(pdev, PCI_D3hot);\n\t}\n}\n\n/**\n * i40e_suspend - PM callback for moving to D3\n * @dev: generic device information structure\n **/\nstatic int __maybe_unused i40e_suspend(struct device *dev)\n{\n\tstruct i40e_pf *pf = dev_get_drvdata(dev);\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t/* If we're already suspended, then there is nothing to do */\n\tif (test_and_set_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn 0;\n\n\tset_bit(__I40E_DOWN, pf->state);\n\n\t/* Ensure service task will not be running */\n\tdel_timer_sync(&pf->service_timer);\n\tcancel_work_sync(&pf->service_task);\n\n\t/* Client close must be called explicitly here because the timer\n\t * has been stopped.\n\t */\n\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi], false);\n\n\tif (pf->wol_en && (pf->hw_features & I40E_HW_WOL_MC_MAGIC_PKT_WAKE))\n\t\ti40e_enable_mc_magic_wake(pf);\n\n\t/* Since we're going to destroy queues during the\n\t * i40e_clear_interrupt_scheme() we should hold the RTNL lock for this\n\t * whole section\n\t */\n\trtnl_lock();\n\n\ti40e_prep_for_reset(pf, true);\n\n\twr32(hw, I40E_PFPM_APM, (pf->wol_en ? I40E_PFPM_APM_APME_MASK : 0));\n\twr32(hw, I40E_PFPM_WUFC, (pf->wol_en ? I40E_PFPM_WUFC_MAG_MASK : 0));\n\n\t/* Clear the interrupt scheme and release our IRQs so that the system\n\t * can safely hibernate even when there are a large number of CPUs.\n\t * Otherwise hibernation might fail when mapping all the vectors back\n\t * to CPU0.\n\t */\n\ti40e_clear_interrupt_scheme(pf);\n\n\trtnl_unlock();\n\n\treturn 0;\n}\n\n/**\n * i40e_resume - PM callback for waking up from D3\n * @dev: generic device information structure\n **/\nstatic int __maybe_unused i40e_resume(struct device *dev)\n{\n\tstruct i40e_pf *pf = dev_get_drvdata(dev);\n\tint err;\n\n\t/* If we're not suspended, then there is nothing to do */\n\tif (!test_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn 0;\n\n\t/* We need to hold the RTNL lock prior to restoring interrupt schemes,\n\t * since we're going to be restoring queues\n\t */\n\trtnl_lock();\n\n\t/* We cleared the interrupt scheme when we suspended, so we need to\n\t * restore it now to resume device functionality.\n\t */\n\terr = i40e_restore_interrupt_scheme(pf);\n\tif (err) {\n\t\tdev_err(dev, \"Cannot restore interrupt scheme: %d\\n\",\n\t\t\terr);\n\t}\n\n\tclear_bit(__I40E_DOWN, pf->state);\n\ti40e_reset_and_rebuild(pf, false, true);\n\n\trtnl_unlock();\n\n\t/* Clear suspended state last after everything is recovered */\n\tclear_bit(__I40E_SUSPENDED, pf->state);\n\n\t/* Restart the service task */\n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\n\treturn 0;\n}\n\nstatic const struct pci_error_handlers i40e_err_handler = {\n\t.error_detected = i40e_pci_error_detected,\n\t.slot_reset = i40e_pci_error_slot_reset,\n\t.reset_prepare = i40e_pci_error_reset_prepare,\n\t.reset_done = i40e_pci_error_reset_done,\n\t.resume = i40e_pci_error_resume,\n};\n\nstatic SIMPLE_DEV_PM_OPS(i40e_pm_ops, i40e_suspend, i40e_resume);\n\nstatic struct pci_driver i40e_driver = {\n\t.name     = i40e_driver_name,\n\t.id_table = i40e_pci_tbl,\n\t.probe    = i40e_probe,\n\t.remove   = i40e_remove,\n\t.driver   = {\n\t\t.pm = &i40e_pm_ops,\n\t},\n\t.shutdown = i40e_shutdown,\n\t.err_handler = &i40e_err_handler,\n\t.sriov_configure = i40e_pci_sriov_configure,\n};\n\n/**\n * i40e_init_module - Driver registration routine\n *\n * i40e_init_module is the first routine called when the driver is\n * loaded. All it does is register with the PCI subsystem.\n **/\nstatic int __init i40e_init_module(void)\n{\n\tpr_info(\"%s: %s - version %s\\n\", i40e_driver_name,\n\t\ti40e_driver_string, i40e_driver_version_str);\n\tpr_info(\"%s: %s\\n\", i40e_driver_name, i40e_copyright);\n\n\t/* There is no need to throttle the number of active tasks because\n\t * each device limits its own task using a state bit for scheduling\n\t * the service task, and the device tasks do not interfere with each\n\t * other, so we don't set a max task limit. We must set WQ_MEM_RECLAIM\n\t * since we need to be able to guarantee forward progress even under\n\t * memory pressure.\n\t */\n\ti40e_wq = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0, i40e_driver_name);\n\tif (!i40e_wq) {\n\t\tpr_err(\"%s: Failed to create workqueue\\n\", i40e_driver_name);\n\t\treturn -ENOMEM;\n\t}\n\n\ti40e_dbg_init();\n\treturn pci_register_driver(&i40e_driver);\n}\nmodule_init(i40e_init_module);\n\n/**\n * i40e_exit_module - Driver exit cleanup routine\n *\n * i40e_exit_module is called just before the driver is removed\n * from memory.\n **/\nstatic void __exit i40e_exit_module(void)\n{\n\tpci_unregister_driver(&i40e_driver);\n\tdestroy_workqueue(i40e_wq);\n\ti40e_dbg_exit();\n}\nmodule_exit(i40e_exit_module);\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0\n/* Copyright(c) 2013 - 2018 Intel Corporation. */\n\n#include <linux/etherdevice.h>\n#include <linux/of_net.h>\n#include <linux/pci.h>\n#include <linux/bpf.h>\n\n/* Local includes */\n#include \"i40e.h\"\n#include \"i40e_diag.h\"\n#include \"i40e_xsk.h\"\n#include <net/udp_tunnel.h>\n#include <net/xdp_sock.h>\n/* All i40e tracepoints are defined by the include below, which\n * must be included exactly once across the whole kernel with\n * CREATE_TRACE_POINTS defined\n */\n#define CREATE_TRACE_POINTS\n#include \"i40e_trace.h\"\n\nconst char i40e_driver_name[] = \"i40e\";\nstatic const char i40e_driver_string[] =\n\t\t\t\"Intel(R) Ethernet Connection XL710 Network Driver\";\n\n#define DRV_KERN \"-k\"\n\n#define DRV_VERSION_MAJOR 2\n#define DRV_VERSION_MINOR 8\n#define DRV_VERSION_BUILD 20\n#define DRV_VERSION __stringify(DRV_VERSION_MAJOR) \".\" \\\n\t     __stringify(DRV_VERSION_MINOR) \".\" \\\n\t     __stringify(DRV_VERSION_BUILD)    DRV_KERN\nconst char i40e_driver_version_str[] = DRV_VERSION;\nstatic const char i40e_copyright[] = \"Copyright (c) 2013 - 2019 Intel Corporation.\";\n\n/* a bit of forward declarations */\nstatic void i40e_vsi_reinit_locked(struct i40e_vsi *vsi);\nstatic void i40e_handle_reset_warning(struct i40e_pf *pf, bool lock_acquired);\nstatic int i40e_add_vsi(struct i40e_vsi *vsi);\nstatic int i40e_add_veb(struct i40e_veb *veb, struct i40e_vsi *vsi);\nstatic int i40e_setup_pf_switch(struct i40e_pf *pf, bool reinit);\nstatic int i40e_setup_misc_vector(struct i40e_pf *pf);\nstatic void i40e_determine_queue_usage(struct i40e_pf *pf);\nstatic int i40e_setup_pf_filter_control(struct i40e_pf *pf);\nstatic void i40e_prep_for_reset(struct i40e_pf *pf, bool lock_acquired);\nstatic int i40e_reset(struct i40e_pf *pf);\nstatic void i40e_rebuild(struct i40e_pf *pf, bool reinit, bool lock_acquired);\nstatic int i40e_setup_misc_vector_for_recovery_mode(struct i40e_pf *pf);\nstatic int i40e_restore_interrupt_scheme(struct i40e_pf *pf);\nstatic bool i40e_check_recovery_mode(struct i40e_pf *pf);\nstatic int i40e_init_recovery_mode(struct i40e_pf *pf, struct i40e_hw *hw);\nstatic void i40e_fdir_sb_setup(struct i40e_pf *pf);\nstatic int i40e_veb_get_bw_info(struct i40e_veb *veb);\nstatic int i40e_get_capabilities(struct i40e_pf *pf,\n\t\t\t\t enum i40e_admin_queue_opc list_type);\n\n\n/* i40e_pci_tbl - PCI Device ID Table\n *\n * Last entry must be all 0s\n *\n * { Vendor ID, Device ID, SubVendor ID, SubDevice ID,\n *   Class, Class Mask, private data (not used) }\n */\nstatic const struct pci_device_id i40e_pci_tbl[] = {\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_SFP_XL710), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QEMU), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_KX_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_KX_C), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_A), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_C), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T4), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T_BC), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_SFP), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_KX_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_SFP_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_1G_BASE_T_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_SFP_I_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_20G_KR2), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_20G_KR2_A), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_X710_N3000), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_XXV710_N3000), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_25G_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_25G_SFP28), 0},\n\t/* required last entry */\n\t{0, }\n};\nMODULE_DEVICE_TABLE(pci, i40e_pci_tbl);\n\n#define I40E_MAX_VF_COUNT 128\nstatic int debug = -1;\nmodule_param(debug, uint, 0);\nMODULE_PARM_DESC(debug, \"Debug level (0=none,...,16=all), Debug mask (0x8XXXXXXX)\");\n\nMODULE_AUTHOR(\"Intel Corporation, <e1000-devel@lists.sourceforge.net>\");\nMODULE_DESCRIPTION(\"Intel(R) Ethernet Connection XL710 Network Driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_VERSION(DRV_VERSION);\n\nstatic struct workqueue_struct *i40e_wq;\n\n/**\n * i40e_allocate_dma_mem_d - OS specific memory alloc for shared code\n * @hw:   pointer to the HW structure\n * @mem:  ptr to mem struct to fill out\n * @size: size of memory requested\n * @alignment: what to align the allocation to\n **/\nint i40e_allocate_dma_mem_d(struct i40e_hw *hw, struct i40e_dma_mem *mem,\n\t\t\t    u64 size, u32 alignment)\n{\n\tstruct i40e_pf *pf = (struct i40e_pf *)hw->back;\n\n\tmem->size = ALIGN(size, alignment);\n\tmem->va = dma_alloc_coherent(&pf->pdev->dev, mem->size, &mem->pa,\n\t\t\t\t     GFP_KERNEL);\n\tif (!mem->va)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n/**\n * i40e_free_dma_mem_d - OS specific memory free for shared code\n * @hw:   pointer to the HW structure\n * @mem:  ptr to mem struct to free\n **/\nint i40e_free_dma_mem_d(struct i40e_hw *hw, struct i40e_dma_mem *mem)\n{\n\tstruct i40e_pf *pf = (struct i40e_pf *)hw->back;\n\n\tdma_free_coherent(&pf->pdev->dev, mem->size, mem->va, mem->pa);\n\tmem->va = NULL;\n\tmem->pa = 0;\n\tmem->size = 0;\n\n\treturn 0;\n}\n\n/**\n * i40e_allocate_virt_mem_d - OS specific memory alloc for shared code\n * @hw:   pointer to the HW structure\n * @mem:  ptr to mem struct to fill out\n * @size: size of memory requested\n **/\nint i40e_allocate_virt_mem_d(struct i40e_hw *hw, struct i40e_virt_mem *mem,\n\t\t\t     u32 size)\n{\n\tmem->size = size;\n\tmem->va = kzalloc(size, GFP_KERNEL);\n\n\tif (!mem->va)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n/**\n * i40e_free_virt_mem_d - OS specific memory free for shared code\n * @hw:   pointer to the HW structure\n * @mem:  ptr to mem struct to free\n **/\nint i40e_free_virt_mem_d(struct i40e_hw *hw, struct i40e_virt_mem *mem)\n{\n\t/* it's ok to kfree a NULL pointer */\n\tkfree(mem->va);\n\tmem->va = NULL;\n\tmem->size = 0;\n\n\treturn 0;\n}\n\n/**\n * i40e_get_lump - find a lump of free generic resource\n * @pf: board private structure\n * @pile: the pile of resource to search\n * @needed: the number of items needed\n * @id: an owner id to stick on the items assigned\n *\n * Returns the base item index of the lump, or negative for error\n *\n * The search_hint trick and lack of advanced fit-finding only work\n * because we're highly likely to have all the same size lump requests.\n * Linear search time and any fragmentation should be minimal.\n **/\nstatic int i40e_get_lump(struct i40e_pf *pf, struct i40e_lump_tracking *pile,\n\t\t\t u16 needed, u16 id)\n{\n\tint ret = -ENOMEM;\n\tint i, j;\n\n\tif (!pile || needed == 0 || id >= I40E_PILE_VALID_BIT) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"param err: pile=%s needed=%d id=0x%04x\\n\",\n\t\t\t pile ? \"<valid>\" : \"<null>\", needed, id);\n\t\treturn -EINVAL;\n\t}\n\n\t/* start the linear search with an imperfect hint */\n\ti = pile->search_hint;\n\twhile (i < pile->num_entries) {\n\t\t/* skip already allocated entries */\n\t\tif (pile->list[i] & I40E_PILE_VALID_BIT) {\n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* do we have enough in this lump? */\n\t\tfor (j = 0; (j < needed) && ((i+j) < pile->num_entries); j++) {\n\t\t\tif (pile->list[i+j] & I40E_PILE_VALID_BIT)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (j == needed) {\n\t\t\t/* there was enough, so assign it to the requestor */\n\t\t\tfor (j = 0; j < needed; j++)\n\t\t\t\tpile->list[i+j] = id | I40E_PILE_VALID_BIT;\n\t\t\tret = i;\n\t\t\tpile->search_hint = i + j;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* not enough, so skip over it and continue looking */\n\t\ti += j;\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_put_lump - return a lump of generic resource\n * @pile: the pile of resource to search\n * @index: the base item index\n * @id: the owner id of the items assigned\n *\n * Returns the count of items in the lump\n **/\nstatic int i40e_put_lump(struct i40e_lump_tracking *pile, u16 index, u16 id)\n{\n\tint valid_id = (id | I40E_PILE_VALID_BIT);\n\tint count = 0;\n\tint i;\n\n\tif (!pile || index >= pile->num_entries)\n\t\treturn -EINVAL;\n\n\tfor (i = index;\n\t     i < pile->num_entries && pile->list[i] == valid_id;\n\t     i++) {\n\t\tpile->list[i] = 0;\n\t\tcount++;\n\t}\n\n\tif (count && index < pile->search_hint)\n\t\tpile->search_hint = index;\n\n\treturn count;\n}\n\n/**\n * i40e_find_vsi_from_id - searches for the vsi with the given id\n * @pf: the pf structure to search for the vsi\n * @id: id of the vsi it is searching for\n **/\nstruct i40e_vsi *i40e_find_vsi_from_id(struct i40e_pf *pf, u16 id)\n{\n\tint i;\n\n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i] && (pf->vsi[i]->id == id))\n\t\t\treturn pf->vsi[i];\n\n\treturn NULL;\n}\n\n/**\n * i40e_service_event_schedule - Schedule the service task to wake up\n * @pf: board private structure\n *\n * If not already scheduled, this puts the task into the work queue\n **/\nvoid i40e_service_event_schedule(struct i40e_pf *pf)\n{\n\tif ((!test_bit(__I40E_DOWN, pf->state) &&\n\t     !test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state)) ||\n\t      test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\tqueue_work(i40e_wq, &pf->service_task);\n}\n\n/**\n * i40e_tx_timeout - Respond to a Tx Hang\n * @netdev: network interface device structure\n *\n * If any port has noticed a Tx timeout, it is likely that the whole\n * device is munged, not just the one netdev port, so go for the full\n * reset.\n **/\nstatic void i40e_tx_timeout(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_ring *tx_ring = NULL;\n\tunsigned int i, hung_queue = 0;\n\tu32 head, val;\n\n\tpf->tx_timeout_count++;\n\n\t/* find the stopped queue the same way the stack does */\n\tfor (i = 0; i < netdev->num_tx_queues; i++) {\n\t\tstruct netdev_queue *q;\n\t\tunsigned long trans_start;\n\n\t\tq = netdev_get_tx_queue(netdev, i);\n\t\ttrans_start = q->trans_start;\n\t\tif (netif_xmit_stopped(q) &&\n\t\t    time_after(jiffies,\n\t\t\t       (trans_start + netdev->watchdog_timeo))) {\n\t\t\thung_queue = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == netdev->num_tx_queues) {\n\t\tnetdev_info(netdev, \"tx_timeout: no netdev hung queue found\\n\");\n\t} else {\n\t\t/* now that we have an index, find the tx_ring struct */\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\t\tif (vsi->tx_rings[i] && vsi->tx_rings[i]->desc) {\n\t\t\t\tif (hung_queue ==\n\t\t\t\t    vsi->tx_rings[i]->queue_index) {\n\t\t\t\t\ttx_ring = vsi->tx_rings[i];\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (time_after(jiffies, (pf->tx_timeout_last_recovery + HZ*20)))\n\t\tpf->tx_timeout_recovery_level = 1;  /* reset after some time */\n\telse if (time_before(jiffies,\n\t\t      (pf->tx_timeout_last_recovery + netdev->watchdog_timeo)))\n\t\treturn;   /* don't do any new action before the next timeout */\n\n\t/* don't kick off another recovery if one is already pending */\n\tif (test_and_set_bit(__I40E_TIMEOUT_RECOVERY_PENDING, pf->state))\n\t\treturn;\n\n\tif (tx_ring) {\n\t\thead = i40e_get_head(tx_ring);\n\t\t/* Read interrupt register */\n\t\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\t\tval = rd32(&pf->hw,\n\t\t\t     I40E_PFINT_DYN_CTLN(tx_ring->q_vector->v_idx +\n\t\t\t\t\t\ttx_ring->vsi->base_vector - 1));\n\t\telse\n\t\t\tval = rd32(&pf->hw, I40E_PFINT_DYN_CTL0);\n\n\t\tnetdev_info(netdev, \"tx_timeout: VSI_seid: %d, Q %d, NTC: 0x%x, HWB: 0x%x, NTU: 0x%x, TAIL: 0x%x, INT: 0x%x\\n\",\n\t\t\t    vsi->seid, hung_queue, tx_ring->next_to_clean,\n\t\t\t    head, tx_ring->next_to_use,\n\t\t\t    readl(tx_ring->tail), val);\n\t}\n\n\tpf->tx_timeout_last_recovery = jiffies;\n\tnetdev_info(netdev, \"tx_timeout recovery level %d, hung_queue %d\\n\",\n\t\t    pf->tx_timeout_recovery_level, hung_queue);\n\n\tswitch (pf->tx_timeout_recovery_level) {\n\tcase 1:\n\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\tbreak;\n\tcase 2:\n\t\tset_bit(__I40E_CORE_RESET_REQUESTED, pf->state);\n\t\tbreak;\n\tcase 3:\n\t\tset_bit(__I40E_GLOBAL_RESET_REQUESTED, pf->state);\n\t\tbreak;\n\tdefault:\n\t\tnetdev_err(netdev, \"tx_timeout recovery unsuccessful\\n\");\n\t\tbreak;\n\t}\n\n\ti40e_service_event_schedule(pf);\n\tpf->tx_timeout_recovery_level++;\n}\n\n/**\n * i40e_get_vsi_stats_struct - Get System Network Statistics\n * @vsi: the VSI we care about\n *\n * Returns the address of the device statistics structure.\n * The statistics are actually updated from the service task.\n **/\nstruct rtnl_link_stats64 *i40e_get_vsi_stats_struct(struct i40e_vsi *vsi)\n{\n\treturn &vsi->net_stats;\n}\n\n/**\n * i40e_get_netdev_stats_struct_tx - populate stats from a Tx ring\n * @ring: Tx ring to get statistics from\n * @stats: statistics entry to be updated\n **/\nstatic void i40e_get_netdev_stats_struct_tx(struct i40e_ring *ring,\n\t\t\t\t\t    struct rtnl_link_stats64 *stats)\n{\n\tu64 bytes, packets;\n\tunsigned int start;\n\n\tdo {\n\t\tstart = u64_stats_fetch_begin_irq(&ring->syncp);\n\t\tpackets = ring->stats.packets;\n\t\tbytes   = ring->stats.bytes;\n\t} while (u64_stats_fetch_retry_irq(&ring->syncp, start));\n\n\tstats->tx_packets += packets;\n\tstats->tx_bytes   += bytes;\n}\n\n/**\n * i40e_get_netdev_stats_struct - Get statistics for netdev interface\n * @netdev: network interface device structure\n * @stats: data structure to store statistics\n *\n * Returns the address of the device statistics structure.\n * The statistics are actually updated from the service task.\n **/\nstatic void i40e_get_netdev_stats_struct(struct net_device *netdev,\n\t\t\t\t  struct rtnl_link_stats64 *stats)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct rtnl_link_stats64 *vsi_stats = i40e_get_vsi_stats_struct(vsi);\n\tstruct i40e_ring *ring;\n\tint i;\n\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tif (!vsi->tx_rings)\n\t\treturn;\n\n\trcu_read_lock();\n\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\tu64 bytes, packets;\n\t\tunsigned int start;\n\n\t\tring = READ_ONCE(vsi->tx_rings[i]);\n\t\tif (!ring)\n\t\t\tcontinue;\n\t\ti40e_get_netdev_stats_struct_tx(ring, stats);\n\n\t\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t\tring++;\n\t\t\ti40e_get_netdev_stats_struct_tx(ring, stats);\n\t\t}\n\n\t\tring++;\n\t\tdo {\n\t\t\tstart   = u64_stats_fetch_begin_irq(&ring->syncp);\n\t\t\tpackets = ring->stats.packets;\n\t\t\tbytes   = ring->stats.bytes;\n\t\t} while (u64_stats_fetch_retry_irq(&ring->syncp, start));\n\n\t\tstats->rx_packets += packets;\n\t\tstats->rx_bytes   += bytes;\n\n\t}\n\trcu_read_unlock();\n\n\t/* following stats updated by i40e_watchdog_subtask() */\n\tstats->multicast\t= vsi_stats->multicast;\n\tstats->tx_errors\t= vsi_stats->tx_errors;\n\tstats->tx_dropped\t= vsi_stats->tx_dropped;\n\tstats->rx_errors\t= vsi_stats->rx_errors;\n\tstats->rx_dropped\t= vsi_stats->rx_dropped;\n\tstats->rx_crc_errors\t= vsi_stats->rx_crc_errors;\n\tstats->rx_length_errors\t= vsi_stats->rx_length_errors;\n}\n\n/**\n * i40e_vsi_reset_stats - Resets all stats of the given vsi\n * @vsi: the VSI to have its stats reset\n **/\nvoid i40e_vsi_reset_stats(struct i40e_vsi *vsi)\n{\n\tstruct rtnl_link_stats64 *ns;\n\tint i;\n\n\tif (!vsi)\n\t\treturn;\n\n\tns = i40e_get_vsi_stats_struct(vsi);\n\tmemset(ns, 0, sizeof(*ns));\n\tmemset(&vsi->net_stats_offsets, 0, sizeof(vsi->net_stats_offsets));\n\tmemset(&vsi->eth_stats, 0, sizeof(vsi->eth_stats));\n\tmemset(&vsi->eth_stats_offsets, 0, sizeof(vsi->eth_stats_offsets));\n\tif (vsi->rx_rings && vsi->rx_rings[0]) {\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\t\tmemset(&vsi->rx_rings[i]->stats, 0,\n\t\t\t       sizeof(vsi->rx_rings[i]->stats));\n\t\t\tmemset(&vsi->rx_rings[i]->rx_stats, 0,\n\t\t\t       sizeof(vsi->rx_rings[i]->rx_stats));\n\t\t\tmemset(&vsi->tx_rings[i]->stats, 0,\n\t\t\t       sizeof(vsi->tx_rings[i]->stats));\n\t\t\tmemset(&vsi->tx_rings[i]->tx_stats, 0,\n\t\t\t       sizeof(vsi->tx_rings[i]->tx_stats));\n\t\t}\n\t}\n\tvsi->stat_offsets_loaded = false;\n}\n\n/**\n * i40e_pf_reset_stats - Reset all of the stats for the given PF\n * @pf: the PF to be reset\n **/\nvoid i40e_pf_reset_stats(struct i40e_pf *pf)\n{\n\tint i;\n\n\tmemset(&pf->stats, 0, sizeof(pf->stats));\n\tmemset(&pf->stats_offsets, 0, sizeof(pf->stats_offsets));\n\tpf->stat_offsets_loaded = false;\n\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (pf->veb[i]) {\n\t\t\tmemset(&pf->veb[i]->stats, 0,\n\t\t\t       sizeof(pf->veb[i]->stats));\n\t\t\tmemset(&pf->veb[i]->stats_offsets, 0,\n\t\t\t       sizeof(pf->veb[i]->stats_offsets));\n\t\t\tmemset(&pf->veb[i]->tc_stats, 0,\n\t\t\t       sizeof(pf->veb[i]->tc_stats));\n\t\t\tmemset(&pf->veb[i]->tc_stats_offsets, 0,\n\t\t\t       sizeof(pf->veb[i]->tc_stats_offsets));\n\t\t\tpf->veb[i]->stat_offsets_loaded = false;\n\t\t}\n\t}\n\tpf->hw_csum_rx_error = 0;\n}\n\n/**\n * i40e_stat_update48 - read and update a 48 bit stat from the chip\n * @hw: ptr to the hardware info\n * @hireg: the high 32 bit reg to read\n * @loreg: the low 32 bit reg to read\n * @offset_loaded: has the initial offset been loaded yet\n * @offset: ptr to current offset value\n * @stat: ptr to the stat\n *\n * Since the device stats are not reset at PFReset, they likely will not\n * be zeroed when the driver starts.  We'll save the first values read\n * and use them as offsets to be subtracted from the raw values in order\n * to report stats that count from zero.  In the process, we also manage\n * the potential roll-over.\n **/\nstatic void i40e_stat_update48(struct i40e_hw *hw, u32 hireg, u32 loreg,\n\t\t\t       bool offset_loaded, u64 *offset, u64 *stat)\n{\n\tu64 new_data;\n\n\tif (hw->device_id == I40E_DEV_ID_QEMU) {\n\t\tnew_data = rd32(hw, loreg);\n\t\tnew_data |= ((u64)(rd32(hw, hireg) & 0xFFFF)) << 32;\n\t} else {\n\t\tnew_data = rd64(hw, loreg);\n\t}\n\tif (!offset_loaded)\n\t\t*offset = new_data;\n\tif (likely(new_data >= *offset))\n\t\t*stat = new_data - *offset;\n\telse\n\t\t*stat = (new_data + BIT_ULL(48)) - *offset;\n\t*stat &= 0xFFFFFFFFFFFFULL;\n}\n\n/**\n * i40e_stat_update32 - read and update a 32 bit stat from the chip\n * @hw: ptr to the hardware info\n * @reg: the hw reg to read\n * @offset_loaded: has the initial offset been loaded yet\n * @offset: ptr to current offset value\n * @stat: ptr to the stat\n **/\nstatic void i40e_stat_update32(struct i40e_hw *hw, u32 reg,\n\t\t\t       bool offset_loaded, u64 *offset, u64 *stat)\n{\n\tu32 new_data;\n\n\tnew_data = rd32(hw, reg);\n\tif (!offset_loaded)\n\t\t*offset = new_data;\n\tif (likely(new_data >= *offset))\n\t\t*stat = (u32)(new_data - *offset);\n\telse\n\t\t*stat = (u32)((new_data + BIT_ULL(32)) - *offset);\n}\n\n/**\n * i40e_stat_update_and_clear32 - read and clear hw reg, update a 32 bit stat\n * @hw: ptr to the hardware info\n * @reg: the hw reg to read and clear\n * @stat: ptr to the stat\n **/\nstatic void i40e_stat_update_and_clear32(struct i40e_hw *hw, u32 reg, u64 *stat)\n{\n\tu32 new_data = rd32(hw, reg);\n\n\twr32(hw, reg, 1); /* must write a nonzero value to clear register */\n\t*stat += new_data;\n}\n\n/**\n * i40e_update_eth_stats - Update VSI-specific ethernet statistics counters.\n * @vsi: the VSI to be updated\n **/\nvoid i40e_update_eth_stats(struct i40e_vsi *vsi)\n{\n\tint stat_idx = le16_to_cpu(vsi->info.stat_counter_idx);\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_eth_stats *oes;\n\tstruct i40e_eth_stats *es;     /* device's eth stats */\n\n\tes = &vsi->eth_stats;\n\toes = &vsi->eth_stats_offsets;\n\n\t/* Gather up the stats that the hw collects */\n\ti40e_stat_update32(hw, I40E_GLV_TEPC(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_errors, &es->tx_errors);\n\ti40e_stat_update32(hw, I40E_GLV_RDPC(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_discards, &es->rx_discards);\n\ti40e_stat_update32(hw, I40E_GLV_RUPP(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_unknown_protocol, &es->rx_unknown_protocol);\n\n\ti40e_stat_update48(hw, I40E_GLV_GORCH(stat_idx),\n\t\t\t   I40E_GLV_GORCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_bytes, &es->rx_bytes);\n\ti40e_stat_update48(hw, I40E_GLV_UPRCH(stat_idx),\n\t\t\t   I40E_GLV_UPRCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_unicast, &es->rx_unicast);\n\ti40e_stat_update48(hw, I40E_GLV_MPRCH(stat_idx),\n\t\t\t   I40E_GLV_MPRCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_multicast, &es->rx_multicast);\n\ti40e_stat_update48(hw, I40E_GLV_BPRCH(stat_idx),\n\t\t\t   I40E_GLV_BPRCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_broadcast, &es->rx_broadcast);\n\n\ti40e_stat_update48(hw, I40E_GLV_GOTCH(stat_idx),\n\t\t\t   I40E_GLV_GOTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_bytes, &es->tx_bytes);\n\ti40e_stat_update48(hw, I40E_GLV_UPTCH(stat_idx),\n\t\t\t   I40E_GLV_UPTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_unicast, &es->tx_unicast);\n\ti40e_stat_update48(hw, I40E_GLV_MPTCH(stat_idx),\n\t\t\t   I40E_GLV_MPTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_multicast, &es->tx_multicast);\n\ti40e_stat_update48(hw, I40E_GLV_BPTCH(stat_idx),\n\t\t\t   I40E_GLV_BPTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_broadcast, &es->tx_broadcast);\n\tvsi->stat_offsets_loaded = true;\n}\n\n/**\n * i40e_update_veb_stats - Update Switch component statistics\n * @veb: the VEB being updated\n **/\nvoid i40e_update_veb_stats(struct i40e_veb *veb)\n{\n\tstruct i40e_pf *pf = veb->pf;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_eth_stats *oes;\n\tstruct i40e_eth_stats *es;     /* device's eth stats */\n\tstruct i40e_veb_tc_stats *veb_oes;\n\tstruct i40e_veb_tc_stats *veb_es;\n\tint i, idx = 0;\n\n\tidx = veb->stats_idx;\n\tes = &veb->stats;\n\toes = &veb->stats_offsets;\n\tveb_es = &veb->tc_stats;\n\tveb_oes = &veb->tc_stats_offsets;\n\n\t/* Gather up the stats that the hw collects */\n\ti40e_stat_update32(hw, I40E_GLSW_TDPC(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_discards, &es->tx_discards);\n\tif (hw->revision_id > 0)\n\t\ti40e_stat_update32(hw, I40E_GLSW_RUPP(idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &oes->rx_unknown_protocol,\n\t\t\t\t   &es->rx_unknown_protocol);\n\ti40e_stat_update48(hw, I40E_GLSW_GORCH(idx), I40E_GLSW_GORCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_bytes, &es->rx_bytes);\n\ti40e_stat_update48(hw, I40E_GLSW_UPRCH(idx), I40E_GLSW_UPRCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_unicast, &es->rx_unicast);\n\ti40e_stat_update48(hw, I40E_GLSW_MPRCH(idx), I40E_GLSW_MPRCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_multicast, &es->rx_multicast);\n\ti40e_stat_update48(hw, I40E_GLSW_BPRCH(idx), I40E_GLSW_BPRCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_broadcast, &es->rx_broadcast);\n\n\ti40e_stat_update48(hw, I40E_GLSW_GOTCH(idx), I40E_GLSW_GOTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_bytes, &es->tx_bytes);\n\ti40e_stat_update48(hw, I40E_GLSW_UPTCH(idx), I40E_GLSW_UPTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_unicast, &es->tx_unicast);\n\ti40e_stat_update48(hw, I40E_GLSW_MPTCH(idx), I40E_GLSW_MPTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_multicast, &es->tx_multicast);\n\ti40e_stat_update48(hw, I40E_GLSW_BPTCH(idx), I40E_GLSW_BPTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_broadcast, &es->tx_broadcast);\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_RPCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_RPCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_rx_packets[i],\n\t\t\t\t   &veb_es->tc_rx_packets[i]);\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_RBCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_RBCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_rx_bytes[i],\n\t\t\t\t   &veb_es->tc_rx_bytes[i]);\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_TPCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_TPCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_tx_packets[i],\n\t\t\t\t   &veb_es->tc_tx_packets[i]);\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_TBCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_TBCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_tx_bytes[i],\n\t\t\t\t   &veb_es->tc_tx_bytes[i]);\n\t}\n\tveb->stat_offsets_loaded = true;\n}\n\n/**\n * i40e_update_vsi_stats - Update the vsi statistics counters.\n * @vsi: the VSI to be updated\n *\n * There are a few instances where we store the same stat in a\n * couple of different structs.  This is partly because we have\n * the netdev stats that need to be filled out, which is slightly\n * different from the \"eth_stats\" defined by the chip and used in\n * VF communications.  We sort it out here.\n **/\nstatic void i40e_update_vsi_stats(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct rtnl_link_stats64 *ons;\n\tstruct rtnl_link_stats64 *ns;   /* netdev stats */\n\tstruct i40e_eth_stats *oes;\n\tstruct i40e_eth_stats *es;     /* device's eth stats */\n\tu32 tx_restart, tx_busy;\n\tstruct i40e_ring *p;\n\tu32 rx_page, rx_buf;\n\tu64 bytes, packets;\n\tunsigned int start;\n\tu64 tx_linearize;\n\tu64 tx_force_wb;\n\tu64 rx_p, rx_b;\n\tu64 tx_p, tx_b;\n\tu16 q;\n\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state) ||\n\t    test_bit(__I40E_CONFIG_BUSY, pf->state))\n\t\treturn;\n\n\tns = i40e_get_vsi_stats_struct(vsi);\n\tons = &vsi->net_stats_offsets;\n\tes = &vsi->eth_stats;\n\toes = &vsi->eth_stats_offsets;\n\n\t/* Gather up the netdev and vsi stats that the driver collects\n\t * on the fly during packet processing\n\t */\n\trx_b = rx_p = 0;\n\ttx_b = tx_p = 0;\n\ttx_restart = tx_busy = tx_linearize = tx_force_wb = 0;\n\trx_page = 0;\n\trx_buf = 0;\n\trcu_read_lock();\n\tfor (q = 0; q < vsi->num_queue_pairs; q++) {\n\t\t/* locate Tx ring */\n\t\tp = READ_ONCE(vsi->tx_rings[q]);\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin_irq(&p->syncp);\n\t\t\tpackets = p->stats.packets;\n\t\t\tbytes = p->stats.bytes;\n\t\t} while (u64_stats_fetch_retry_irq(&p->syncp, start));\n\t\ttx_b += bytes;\n\t\ttx_p += packets;\n\t\ttx_restart += p->tx_stats.restart_queue;\n\t\ttx_busy += p->tx_stats.tx_busy;\n\t\ttx_linearize += p->tx_stats.tx_linearize;\n\t\ttx_force_wb += p->tx_stats.tx_force_wb;\n\n\t\t/* Rx queue is part of the same block as Tx queue */\n\t\tp = &p[1];\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin_irq(&p->syncp);\n\t\t\tpackets = p->stats.packets;\n\t\t\tbytes = p->stats.bytes;\n\t\t} while (u64_stats_fetch_retry_irq(&p->syncp, start));\n\t\trx_b += bytes;\n\t\trx_p += packets;\n\t\trx_buf += p->rx_stats.alloc_buff_failed;\n\t\trx_page += p->rx_stats.alloc_page_failed;\n\t}\n\trcu_read_unlock();\n\tvsi->tx_restart = tx_restart;\n\tvsi->tx_busy = tx_busy;\n\tvsi->tx_linearize = tx_linearize;\n\tvsi->tx_force_wb = tx_force_wb;\n\tvsi->rx_page_failed = rx_page;\n\tvsi->rx_buf_failed = rx_buf;\n\n\tns->rx_packets = rx_p;\n\tns->rx_bytes = rx_b;\n\tns->tx_packets = tx_p;\n\tns->tx_bytes = tx_b;\n\n\t/* update netdev stats from eth stats */\n\ti40e_update_eth_stats(vsi);\n\tons->tx_errors = oes->tx_errors;\n\tns->tx_errors = es->tx_errors;\n\tons->multicast = oes->rx_multicast;\n\tns->multicast = es->rx_multicast;\n\tons->rx_dropped = oes->rx_discards;\n\tns->rx_dropped = es->rx_discards;\n\tons->tx_dropped = oes->tx_discards;\n\tns->tx_dropped = es->tx_discards;\n\n\t/* pull in a couple PF stats if this is the main vsi */\n\tif (vsi == pf->vsi[pf->lan_vsi]) {\n\t\tns->rx_crc_errors = pf->stats.crc_errors;\n\t\tns->rx_errors = pf->stats.crc_errors + pf->stats.illegal_bytes;\n\t\tns->rx_length_errors = pf->stats.rx_length_errors;\n\t}\n}\n\n/**\n * i40e_update_pf_stats - Update the PF statistics counters.\n * @pf: the PF to be updated\n **/\nstatic void i40e_update_pf_stats(struct i40e_pf *pf)\n{\n\tstruct i40e_hw_port_stats *osd = &pf->stats_offsets;\n\tstruct i40e_hw_port_stats *nsd = &pf->stats;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\tint i;\n\n\ti40e_stat_update48(hw, I40E_GLPRT_GORCH(hw->port),\n\t\t\t   I40E_GLPRT_GORCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_bytes, &nsd->eth.rx_bytes);\n\ti40e_stat_update48(hw, I40E_GLPRT_GOTCH(hw->port),\n\t\t\t   I40E_GLPRT_GOTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_bytes, &nsd->eth.tx_bytes);\n\ti40e_stat_update32(hw, I40E_GLPRT_RDPC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_discards,\n\t\t\t   &nsd->eth.rx_discards);\n\ti40e_stat_update48(hw, I40E_GLPRT_UPRCH(hw->port),\n\t\t\t   I40E_GLPRT_UPRCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_unicast,\n\t\t\t   &nsd->eth.rx_unicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_MPRCH(hw->port),\n\t\t\t   I40E_GLPRT_MPRCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_multicast,\n\t\t\t   &nsd->eth.rx_multicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_BPRCH(hw->port),\n\t\t\t   I40E_GLPRT_BPRCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_broadcast,\n\t\t\t   &nsd->eth.rx_broadcast);\n\ti40e_stat_update48(hw, I40E_GLPRT_UPTCH(hw->port),\n\t\t\t   I40E_GLPRT_UPTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_unicast,\n\t\t\t   &nsd->eth.tx_unicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_MPTCH(hw->port),\n\t\t\t   I40E_GLPRT_MPTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_multicast,\n\t\t\t   &nsd->eth.tx_multicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_BPTCH(hw->port),\n\t\t\t   I40E_GLPRT_BPTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_broadcast,\n\t\t\t   &nsd->eth.tx_broadcast);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_TDOLD(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_dropped_link_down,\n\t\t\t   &nsd->tx_dropped_link_down);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_CRCERRS(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->crc_errors, &nsd->crc_errors);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_ILLERRC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->illegal_bytes, &nsd->illegal_bytes);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_MLFC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->mac_local_faults,\n\t\t\t   &nsd->mac_local_faults);\n\ti40e_stat_update32(hw, I40E_GLPRT_MRFC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->mac_remote_faults,\n\t\t\t   &nsd->mac_remote_faults);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_RLEC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_length_errors,\n\t\t\t   &nsd->rx_length_errors);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_LXONRXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xon_rx, &nsd->link_xon_rx);\n\ti40e_stat_update32(hw, I40E_GLPRT_LXONTXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xon_tx, &nsd->link_xon_tx);\n\ti40e_stat_update32(hw, I40E_GLPRT_LXOFFRXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xoff_rx, &nsd->link_xoff_rx);\n\ti40e_stat_update32(hw, I40E_GLPRT_LXOFFTXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xoff_tx, &nsd->link_xoff_tx);\n\n\tfor (i = 0; i < 8; i++) {\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXOFFRXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xoff_rx[i],\n\t\t\t\t   &nsd->priority_xoff_rx[i]);\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXONRXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xon_rx[i],\n\t\t\t\t   &nsd->priority_xon_rx[i]);\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXONTXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xon_tx[i],\n\t\t\t\t   &nsd->priority_xon_tx[i]);\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXOFFTXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xoff_tx[i],\n\t\t\t\t   &nsd->priority_xoff_tx[i]);\n\t\ti40e_stat_update32(hw,\n\t\t\t\t   I40E_GLPRT_RXON2OFFCNT(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xon_2_xoff[i],\n\t\t\t\t   &nsd->priority_xon_2_xoff[i]);\n\t}\n\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC64H(hw->port),\n\t\t\t   I40E_GLPRT_PRC64L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_64, &nsd->rx_size_64);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC127H(hw->port),\n\t\t\t   I40E_GLPRT_PRC127L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_127, &nsd->rx_size_127);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC255H(hw->port),\n\t\t\t   I40E_GLPRT_PRC255L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_255, &nsd->rx_size_255);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC511H(hw->port),\n\t\t\t   I40E_GLPRT_PRC511L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_511, &nsd->rx_size_511);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC1023H(hw->port),\n\t\t\t   I40E_GLPRT_PRC1023L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_1023, &nsd->rx_size_1023);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC1522H(hw->port),\n\t\t\t   I40E_GLPRT_PRC1522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_1522, &nsd->rx_size_1522);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC9522H(hw->port),\n\t\t\t   I40E_GLPRT_PRC9522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_big, &nsd->rx_size_big);\n\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC64H(hw->port),\n\t\t\t   I40E_GLPRT_PTC64L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_64, &nsd->tx_size_64);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC127H(hw->port),\n\t\t\t   I40E_GLPRT_PTC127L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_127, &nsd->tx_size_127);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC255H(hw->port),\n\t\t\t   I40E_GLPRT_PTC255L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_255, &nsd->tx_size_255);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC511H(hw->port),\n\t\t\t   I40E_GLPRT_PTC511L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_511, &nsd->tx_size_511);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC1023H(hw->port),\n\t\t\t   I40E_GLPRT_PTC1023L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_1023, &nsd->tx_size_1023);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC1522H(hw->port),\n\t\t\t   I40E_GLPRT_PTC1522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_1522, &nsd->tx_size_1522);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC9522H(hw->port),\n\t\t\t   I40E_GLPRT_PTC9522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_big, &nsd->tx_size_big);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_RUC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_undersize, &nsd->rx_undersize);\n\ti40e_stat_update32(hw, I40E_GLPRT_RFC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_fragments, &nsd->rx_fragments);\n\ti40e_stat_update32(hw, I40E_GLPRT_ROC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_oversize, &nsd->rx_oversize);\n\ti40e_stat_update32(hw, I40E_GLPRT_RJC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_jabber, &nsd->rx_jabber);\n\n\t/* FDIR stats */\n\ti40e_stat_update_and_clear32(hw,\n\t\t\tI40E_GLQF_PCNT(I40E_FD_ATR_STAT_IDX(hw->pf_id)),\n\t\t\t&nsd->fd_atr_match);\n\ti40e_stat_update_and_clear32(hw,\n\t\t\tI40E_GLQF_PCNT(I40E_FD_SB_STAT_IDX(hw->pf_id)),\n\t\t\t&nsd->fd_sb_match);\n\ti40e_stat_update_and_clear32(hw,\n\t\t\tI40E_GLQF_PCNT(I40E_FD_ATR_TUNNEL_STAT_IDX(hw->pf_id)),\n\t\t\t&nsd->fd_atr_tunnel_match);\n\n\tval = rd32(hw, I40E_PRTPM_EEE_STAT);\n\tnsd->tx_lpi_status =\n\t\t       (val & I40E_PRTPM_EEE_STAT_TX_LPI_STATUS_MASK) >>\n\t\t\tI40E_PRTPM_EEE_STAT_TX_LPI_STATUS_SHIFT;\n\tnsd->rx_lpi_status =\n\t\t       (val & I40E_PRTPM_EEE_STAT_RX_LPI_STATUS_MASK) >>\n\t\t\tI40E_PRTPM_EEE_STAT_RX_LPI_STATUS_SHIFT;\n\ti40e_stat_update32(hw, I40E_PRTPM_TLPIC,\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_lpi_count, &nsd->tx_lpi_count);\n\ti40e_stat_update32(hw, I40E_PRTPM_RLPIC,\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_lpi_count, &nsd->rx_lpi_count);\n\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED &&\n\t    !test_bit(__I40E_FD_SB_AUTO_DISABLED, pf->state))\n\t\tnsd->fd_sb_status = true;\n\telse\n\t\tnsd->fd_sb_status = false;\n\n\tif (pf->flags & I40E_FLAG_FD_ATR_ENABLED &&\n\t    !test_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state))\n\t\tnsd->fd_atr_status = true;\n\telse\n\t\tnsd->fd_atr_status = false;\n\n\tpf->stat_offsets_loaded = true;\n}\n\n/**\n * i40e_update_stats - Update the various statistics counters.\n * @vsi: the VSI to be updated\n *\n * Update the various stats for this VSI and its related entities.\n **/\nvoid i40e_update_stats(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (vsi == pf->vsi[pf->lan_vsi])\n\t\ti40e_update_pf_stats(pf);\n\n\ti40e_update_vsi_stats(vsi);\n}\n\n/**\n * i40e_count_filters - counts VSI mac filters\n * @vsi: the VSI to be searched\n *\n * Returns count of mac filters\n **/\nint i40e_count_filters(struct i40e_vsi *vsi)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tint bkt;\n\tint cnt = 0;\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist)\n\t\t++cnt;\n\n\treturn cnt;\n}\n\n/**\n * i40e_find_filter - Search VSI filter list for specific mac/vlan filter\n * @vsi: the VSI to be searched\n * @macaddr: the MAC address\n * @vlan: the vlan\n *\n * Returns ptr to the filter object or NULL\n **/\nstatic struct i40e_mac_filter *i40e_find_filter(struct i40e_vsi *vsi,\n\t\t\t\t\t\tconst u8 *macaddr, s16 vlan)\n{\n\tstruct i40e_mac_filter *f;\n\tu64 key;\n\n\tif (!vsi || !macaddr)\n\t\treturn NULL;\n\n\tkey = i40e_addr_to_hkey(macaddr);\n\thash_for_each_possible(vsi->mac_filter_hash, f, hlist, key) {\n\t\tif ((ether_addr_equal(macaddr, f->macaddr)) &&\n\t\t    (vlan == f->vlan))\n\t\t\treturn f;\n\t}\n\treturn NULL;\n}\n\n/**\n * i40e_find_mac - Find a mac addr in the macvlan filters list\n * @vsi: the VSI to be searched\n * @macaddr: the MAC address we are searching for\n *\n * Returns the first filter with the provided MAC address or NULL if\n * MAC address was not found\n **/\nstruct i40e_mac_filter *i40e_find_mac(struct i40e_vsi *vsi, const u8 *macaddr)\n{\n\tstruct i40e_mac_filter *f;\n\tu64 key;\n\n\tif (!vsi || !macaddr)\n\t\treturn NULL;\n\n\tkey = i40e_addr_to_hkey(macaddr);\n\thash_for_each_possible(vsi->mac_filter_hash, f, hlist, key) {\n\t\tif ((ether_addr_equal(macaddr, f->macaddr)))\n\t\t\treturn f;\n\t}\n\treturn NULL;\n}\n\n/**\n * i40e_is_vsi_in_vlan - Check if VSI is in vlan mode\n * @vsi: the VSI to be searched\n *\n * Returns true if VSI is in vlan mode or false otherwise\n **/\nbool i40e_is_vsi_in_vlan(struct i40e_vsi *vsi)\n{\n\t/* If we have a PVID, always operate in VLAN mode */\n\tif (vsi->info.pvid)\n\t\treturn true;\n\n\t/* We need to operate in VLAN mode whenever we have any filters with\n\t * a VLAN other than I40E_VLAN_ALL. We could check the table each\n\t * time, incurring search cost repeatedly. However, we can notice two\n\t * things:\n\t *\n\t * 1) the only place where we can gain a VLAN filter is in\n\t *    i40e_add_filter.\n\t *\n\t * 2) the only place where filters are actually removed is in\n\t *    i40e_sync_filters_subtask.\n\t *\n\t * Thus, we can simply use a boolean value, has_vlan_filters which we\n\t * will set to true when we add a VLAN filter in i40e_add_filter. Then\n\t * we have to perform the full search after deleting filters in\n\t * i40e_sync_filters_subtask, but we already have to search\n\t * filters here and can perform the check at the same time. This\n\t * results in avoiding embedding a loop for VLAN mode inside another\n\t * loop over all the filters, and should maintain correctness as noted\n\t * above.\n\t */\n\treturn vsi->has_vlan_filter;\n}\n\n/**\n * i40e_correct_mac_vlan_filters - Correct non-VLAN filters if necessary\n * @vsi: the VSI to configure\n * @tmp_add_list: list of filters ready to be added\n * @tmp_del_list: list of filters ready to be deleted\n * @vlan_filters: the number of active VLAN filters\n *\n * Update VLAN=0 and VLAN=-1 (I40E_VLAN_ANY) filters properly so that they\n * behave as expected. If we have any active VLAN filters remaining or about\n * to be added then we need to update non-VLAN filters to be marked as VLAN=0\n * so that they only match against untagged traffic. If we no longer have any\n * active VLAN filters, we need to make all non-VLAN filters marked as VLAN=-1\n * so that they match against both tagged and untagged traffic. In this way,\n * we ensure that we correctly receive the desired traffic. This ensures that\n * when we have an active VLAN we will receive only untagged traffic and\n * traffic matching active VLANs. If we have no active VLANs then we will\n * operate in non-VLAN mode and receive all traffic, tagged or untagged.\n *\n * Finally, in a similar fashion, this function also corrects filters when\n * there is an active PVID assigned to this VSI.\n *\n * In case of memory allocation failure return -ENOMEM. Otherwise, return 0.\n *\n * This function is only expected to be called from within\n * i40e_sync_vsi_filters.\n *\n * NOTE: This function expects to be called while under the\n * mac_filter_hash_lock\n */\nstatic int i40e_correct_mac_vlan_filters(struct i40e_vsi *vsi,\n\t\t\t\t\t struct hlist_head *tmp_add_list,\n\t\t\t\t\t struct hlist_head *tmp_del_list,\n\t\t\t\t\t int vlan_filters)\n{\n\ts16 pvid = le16_to_cpu(vsi->info.pvid);\n\tstruct i40e_mac_filter *f, *add_head;\n\tstruct i40e_new_mac_filter *new;\n\tstruct hlist_node *h;\n\tint bkt, new_vlan;\n\n\t/* To determine if a particular filter needs to be replaced we\n\t * have the three following conditions:\n\t *\n\t * a) if we have a PVID assigned, then all filters which are\n\t *    not marked as VLAN=PVID must be replaced with filters that\n\t *    are.\n\t * b) otherwise, if we have any active VLANS, all filters\n\t *    which are marked as VLAN=-1 must be replaced with\n\t *    filters marked as VLAN=0\n\t * c) finally, if we do not have any active VLANS, all filters\n\t *    which are marked as VLAN=0 must be replaced with filters\n\t *    marked as VLAN=-1\n\t */\n\n\t/* Update the filters about to be added in place */\n\thlist_for_each_entry(new, tmp_add_list, hlist) {\n\t\tif (pvid && new->f->vlan != pvid)\n\t\t\tnew->f->vlan = pvid;\n\t\telse if (vlan_filters && new->f->vlan == I40E_VLAN_ANY)\n\t\t\tnew->f->vlan = 0;\n\t\telse if (!vlan_filters && new->f->vlan == 0)\n\t\t\tnew->f->vlan = I40E_VLAN_ANY;\n\t}\n\n\t/* Update the remaining active filters */\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\t/* Combine the checks for whether a filter needs to be changed\n\t\t * and then determine the new VLAN inside the if block, in\n\t\t * order to avoid duplicating code for adding the new filter\n\t\t * then deleting the old filter.\n\t\t */\n\t\tif ((pvid && f->vlan != pvid) ||\n\t\t    (vlan_filters && f->vlan == I40E_VLAN_ANY) ||\n\t\t    (!vlan_filters && f->vlan == 0)) {\n\t\t\t/* Determine the new vlan we will be adding */\n\t\t\tif (pvid)\n\t\t\t\tnew_vlan = pvid;\n\t\t\telse if (vlan_filters)\n\t\t\t\tnew_vlan = 0;\n\t\t\telse\n\t\t\t\tnew_vlan = I40E_VLAN_ANY;\n\n\t\t\t/* Create the new filter */\n\t\t\tadd_head = i40e_add_filter(vsi, f->macaddr, new_vlan);\n\t\t\tif (!add_head)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\t/* Create a temporary i40e_new_mac_filter */\n\t\t\tnew = kzalloc(sizeof(*new), GFP_ATOMIC);\n\t\t\tif (!new)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tnew->f = add_head;\n\t\t\tnew->state = add_head->state;\n\n\t\t\t/* Add the new filter to the tmp list */\n\t\t\thlist_add_head(&new->hlist, tmp_add_list);\n\n\t\t\t/* Put the original filter into the delete list */\n\t\t\tf->state = I40E_FILTER_REMOVE;\n\t\t\thash_del(&f->hlist);\n\t\t\thlist_add_head(&f->hlist, tmp_del_list);\n\t\t}\n\t}\n\n\tvsi->has_vlan_filter = !!vlan_filters;\n\n\treturn 0;\n}\n\n/**\n * i40e_rm_default_mac_filter - Remove the default MAC filter set by NVM\n * @vsi: the PF Main VSI - inappropriate for any other VSI\n * @macaddr: the MAC address\n *\n * Remove whatever filter the firmware set up so the driver can manage\n * its own filtering intelligently.\n **/\nstatic void i40e_rm_default_mac_filter(struct i40e_vsi *vsi, u8 *macaddr)\n{\n\tstruct i40e_aqc_remove_macvlan_element_data element;\n\tstruct i40e_pf *pf = vsi->back;\n\n\t/* Only appropriate for the PF main VSI */\n\tif (vsi->type != I40E_VSI_MAIN)\n\t\treturn;\n\n\tmemset(&element, 0, sizeof(element));\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\t/* Ignore error returns, some firmware does it this way... */\n\telement.flags = I40E_AQC_MACVLAN_DEL_PERFECT_MATCH;\n\ti40e_aq_remove_macvlan(&pf->hw, vsi->seid, &element, 1, NULL);\n\n\tmemset(&element, 0, sizeof(element));\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\t/* ...and some firmware does it this way. */\n\telement.flags = I40E_AQC_MACVLAN_DEL_PERFECT_MATCH |\n\t\t\tI40E_AQC_MACVLAN_DEL_IGNORE_VLAN;\n\ti40e_aq_remove_macvlan(&pf->hw, vsi->seid, &element, 1, NULL);\n}\n\n/**\n * i40e_add_filter - Add a mac/vlan filter to the VSI\n * @vsi: the VSI to be searched\n * @macaddr: the MAC address\n * @vlan: the vlan\n *\n * Returns ptr to the filter object or NULL when no memory available.\n *\n * NOTE: This function is expected to be called with mac_filter_hash_lock\n * being held.\n **/\nstruct i40e_mac_filter *i40e_add_filter(struct i40e_vsi *vsi,\n\t\t\t\t\tconst u8 *macaddr, s16 vlan)\n{\n\tstruct i40e_mac_filter *f;\n\tu64 key;\n\n\tif (!vsi || !macaddr)\n\t\treturn NULL;\n\n\tf = i40e_find_filter(vsi, macaddr, vlan);\n\tif (!f) {\n\t\tf = kzalloc(sizeof(*f), GFP_ATOMIC);\n\t\tif (!f)\n\t\t\treturn NULL;\n\n\t\t/* Update the boolean indicating if we need to function in\n\t\t * VLAN mode.\n\t\t */\n\t\tif (vlan >= 0)\n\t\t\tvsi->has_vlan_filter = true;\n\n\t\tether_addr_copy(f->macaddr, macaddr);\n\t\tf->vlan = vlan;\n\t\tf->state = I40E_FILTER_NEW;\n\t\tINIT_HLIST_NODE(&f->hlist);\n\n\t\tkey = i40e_addr_to_hkey(macaddr);\n\t\thash_add(vsi->mac_filter_hash, &f->hlist, key);\n\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, vsi->back->state);\n\t}\n\n\t/* If we're asked to add a filter that has been marked for removal, it\n\t * is safe to simply restore it to active state. __i40e_del_filter\n\t * will have simply deleted any filters which were previously marked\n\t * NEW or FAILED, so if it is currently marked REMOVE it must have\n\t * previously been ACTIVE. Since we haven't yet run the sync filters\n\t * task, just restore this filter to the ACTIVE state so that the\n\t * sync task leaves it in place\n\t */\n\tif (f->state == I40E_FILTER_REMOVE)\n\t\tf->state = I40E_FILTER_ACTIVE;\n\n\treturn f;\n}\n\n/**\n * __i40e_del_filter - Remove a specific filter from the VSI\n * @vsi: VSI to remove from\n * @f: the filter to remove from the list\n *\n * This function should be called instead of i40e_del_filter only if you know\n * the exact filter you will remove already, such as via i40e_find_filter or\n * i40e_find_mac.\n *\n * NOTE: This function is expected to be called with mac_filter_hash_lock\n * being held.\n * ANOTHER NOTE: This function MUST be called from within the context of\n * the \"safe\" variants of any list iterators, e.g. list_for_each_entry_safe()\n * instead of list_for_each_entry().\n **/\nvoid __i40e_del_filter(struct i40e_vsi *vsi, struct i40e_mac_filter *f)\n{\n\tif (!f)\n\t\treturn;\n\n\t/* If the filter was never added to firmware then we can just delete it\n\t * directly and we don't want to set the status to remove or else an\n\t * admin queue command will unnecessarily fire.\n\t */\n\tif ((f->state == I40E_FILTER_FAILED) ||\n\t    (f->state == I40E_FILTER_NEW)) {\n\t\thash_del(&f->hlist);\n\t\tkfree(f);\n\t} else {\n\t\tf->state = I40E_FILTER_REMOVE;\n\t}\n\n\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\tset_bit(__I40E_MACVLAN_SYNC_PENDING, vsi->back->state);\n}\n\n/**\n * i40e_del_filter - Remove a MAC/VLAN filter from the VSI\n * @vsi: the VSI to be searched\n * @macaddr: the MAC address\n * @vlan: the VLAN\n *\n * NOTE: This function is expected to be called with mac_filter_hash_lock\n * being held.\n * ANOTHER NOTE: This function MUST be called from within the context of\n * the \"safe\" variants of any list iterators, e.g. list_for_each_entry_safe()\n * instead of list_for_each_entry().\n **/\nvoid i40e_del_filter(struct i40e_vsi *vsi, const u8 *macaddr, s16 vlan)\n{\n\tstruct i40e_mac_filter *f;\n\n\tif (!vsi || !macaddr)\n\t\treturn;\n\n\tf = i40e_find_filter(vsi, macaddr, vlan);\n\t__i40e_del_filter(vsi, f);\n}\n\n/**\n * i40e_add_mac_filter - Add a MAC filter for all active VLANs\n * @vsi: the VSI to be searched\n * @macaddr: the mac address to be filtered\n *\n * If we're not in VLAN mode, just add the filter to I40E_VLAN_ANY. Otherwise,\n * go through all the macvlan filters and add a macvlan filter for each\n * unique vlan that already exists. If a PVID has been assigned, instead only\n * add the macaddr to that VLAN.\n *\n * Returns last filter added on success, else NULL\n **/\nstruct i40e_mac_filter *i40e_add_mac_filter(struct i40e_vsi *vsi,\n\t\t\t\t\t    const u8 *macaddr)\n{\n\tstruct i40e_mac_filter *f, *add = NULL;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\tif (vsi->info.pvid)\n\t\treturn i40e_add_filter(vsi, macaddr,\n\t\t\t\t       le16_to_cpu(vsi->info.pvid));\n\n\tif (!i40e_is_vsi_in_vlan(vsi))\n\t\treturn i40e_add_filter(vsi, macaddr, I40E_VLAN_ANY);\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (f->state == I40E_FILTER_REMOVE)\n\t\t\tcontinue;\n\t\tadd = i40e_add_filter(vsi, macaddr, f->vlan);\n\t\tif (!add)\n\t\t\treturn NULL;\n\t}\n\n\treturn add;\n}\n\n/**\n * i40e_del_mac_filter - Remove a MAC filter from all VLANs\n * @vsi: the VSI to be searched\n * @macaddr: the mac address to be removed\n *\n * Removes a given MAC address from a VSI regardless of what VLAN it has been\n * associated with.\n *\n * Returns 0 for success, or error\n **/\nint i40e_del_mac_filter(struct i40e_vsi *vsi, const u8 *macaddr)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tbool found = false;\n\tint bkt;\n\n\tlockdep_assert_held(&vsi->mac_filter_hash_lock);\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (ether_addr_equal(macaddr, f->macaddr)) {\n\t\t\t__i40e_del_filter(vsi, f);\n\t\t\tfound = true;\n\t\t}\n\t}\n\n\tif (found)\n\t\treturn 0;\n\telse\n\t\treturn -ENOENT;\n}\n\n/**\n * i40e_set_mac - NDO callback to set mac address\n * @netdev: network interface device structure\n * @p: pointer to an address structure\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_set_mac(struct net_device *netdev, void *p)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct sockaddr *addr = p;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\tif (ether_addr_equal(netdev->dev_addr, addr->sa_data)) {\n\t\tnetdev_info(netdev, \"already using mac address %pM\\n\",\n\t\t\t    addr->sa_data);\n\t\treturn 0;\n\t}\n\n\tif (test_bit(__I40E_DOWN, pf->state) ||\n\t    test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\treturn -EADDRNOTAVAIL;\n\n\tif (ether_addr_equal(hw->mac.addr, addr->sa_data))\n\t\tnetdev_info(netdev, \"returning to hw mac address %pM\\n\",\n\t\t\t    hw->mac.addr);\n\telse\n\t\tnetdev_info(netdev, \"set new mac address %pM\\n\", addr->sa_data);\n\n\t/* Copy the address first, so that we avoid a possible race with\n\t * .set_rx_mode().\n\t * - Remove old address from MAC filter\n\t * - Copy new address\n\t * - Add new address to MAC filter\n\t */\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\ti40e_del_mac_filter(vsi, netdev->dev_addr);\n\tether_addr_copy(netdev->dev_addr, addr->sa_data);\n\ti40e_add_mac_filter(vsi, netdev->dev_addr);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\ti40e_status ret;\n\n\t\tret = i40e_aq_mac_address_write(hw, I40E_AQC_WRITE_TYPE_LAA_WOL,\n\t\t\t\t\t\taddr->sa_data, NULL);\n\t\tif (ret)\n\t\t\tnetdev_info(netdev, \"Ignoring error from firmware on LAA update, status %s, AQ ret %s\\n\",\n\t\t\t\t    i40e_stat_str(hw, ret),\n\t\t\t\t    i40e_aq_str(hw, hw->aq.asq_last_status));\n\t}\n\n\t/* schedule our worker thread which will take care of\n\t * applying the new filter changes\n\t */\n\ti40e_service_event_schedule(pf);\n\treturn 0;\n}\n\n/**\n * i40e_config_rss_aq - Prepare for RSS using AQ commands\n * @vsi: vsi structure\n * @seed: RSS hash seed\n **/\nstatic int i40e_config_rss_aq(struct i40e_vsi *vsi, const u8 *seed,\n\t\t\t      u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret = 0;\n\n\tif (seed) {\n\t\tstruct i40e_aqc_get_set_rss_key_data *seed_dw =\n\t\t\t(struct i40e_aqc_get_set_rss_key_data *)seed;\n\t\tret = i40e_aq_set_rss_key(hw, vsi->id, seed_dw);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot set RSS key, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\tif (lut) {\n\t\tbool pf_lut = vsi->type == I40E_VSI_MAIN ? true : false;\n\n\t\tret = i40e_aq_set_rss_lut(hw, vsi->id, pf_lut, lut, lut_size);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot set RSS lut, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn ret;\n}\n\n/**\n * i40e_vsi_config_rss - Prepare for VSI(VMDq) RSS if used\n * @vsi: VSI structure\n **/\nstatic int i40e_vsi_config_rss(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 seed[I40E_HKEY_ARRAY_SIZE];\n\tu8 *lut;\n\tint ret;\n\n\tif (!(pf->hw_features & I40E_HW_RSS_AQ_CAPABLE))\n\t\treturn 0;\n\tif (!vsi->rss_size)\n\t\tvsi->rss_size = min_t(int, pf->alloc_rss_size,\n\t\t\t\t      vsi->num_queue_pairs);\n\tif (!vsi->rss_size)\n\t\treturn -EINVAL;\n\tlut = kzalloc(vsi->rss_table_size, GFP_KERNEL);\n\tif (!lut)\n\t\treturn -ENOMEM;\n\n\t/* Use the user configured hash keys and lookup table if there is one,\n\t * otherwise use default\n\t */\n\tif (vsi->rss_lut_user)\n\t\tmemcpy(lut, vsi->rss_lut_user, vsi->rss_table_size);\n\telse\n\t\ti40e_fill_rss_lut(pf, lut, vsi->rss_table_size, vsi->rss_size);\n\tif (vsi->rss_hkey_user)\n\t\tmemcpy(seed, vsi->rss_hkey_user, I40E_HKEY_ARRAY_SIZE);\n\telse\n\t\tnetdev_rss_key_fill((void *)seed, I40E_HKEY_ARRAY_SIZE);\n\tret = i40e_config_rss_aq(vsi, seed, lut, vsi->rss_table_size);\n\tkfree(lut);\n\treturn ret;\n}\n\n/**\n * i40e_vsi_setup_queue_map_mqprio - Prepares mqprio based tc_config\n * @vsi: the VSI being configured,\n * @ctxt: VSI context structure\n * @enabled_tc: number of traffic classes to enable\n *\n * Prepares VSI tc_config to have queue configurations based on MQPRIO options.\n **/\nstatic int i40e_vsi_setup_queue_map_mqprio(struct i40e_vsi *vsi,\n\t\t\t\t\t   struct i40e_vsi_context *ctxt,\n\t\t\t\t\t   u8 enabled_tc)\n{\n\tu16 qcount = 0, max_qcount, qmap, sections = 0;\n\tint i, override_q, pow, num_qps, ret;\n\tu8 netdev_tc = 0, offset = 0;\n\n\tif (vsi->type != I40E_VSI_MAIN)\n\t\treturn -EINVAL;\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\tvsi->tc_config.numtc = vsi->mqprio_qopt.qopt.num_tc;\n\tvsi->tc_config.enabled_tc = enabled_tc ? enabled_tc : 1;\n\tnum_qps = vsi->mqprio_qopt.qopt.count[0];\n\n\t/* find the next higher power-of-2 of num queue pairs */\n\tpow = ilog2(num_qps);\n\tif (!is_power_of_2(num_qps))\n\t\tpow++;\n\tqmap = (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t(pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t/* Setup queue offset/count for all TCs for given VSI */\n\tmax_qcount = vsi->mqprio_qopt.qopt.count[0];\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t/* See if the given TC is enabled for the given VSI */\n\t\tif (vsi->tc_config.enabled_tc & BIT(i)) {\n\t\t\toffset = vsi->mqprio_qopt.qopt.offset[i];\n\t\t\tqcount = vsi->mqprio_qopt.qopt.count[i];\n\t\t\tif (qcount > max_qcount)\n\t\t\t\tmax_qcount = qcount;\n\t\t\tvsi->tc_config.tc_info[i].qoffset = offset;\n\t\t\tvsi->tc_config.tc_info[i].qcount = qcount;\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = netdev_tc++;\n\t\t} else {\n\t\t\t/* TC is not enabled so set the offset to\n\t\t\t * default queue and allocate one queue\n\t\t\t * for the given TC.\n\t\t\t */\n\t\t\tvsi->tc_config.tc_info[i].qoffset = 0;\n\t\t\tvsi->tc_config.tc_info[i].qcount = 1;\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = 0;\n\t\t}\n\t}\n\n\t/* Set actual Tx/Rx queue pairs */\n\tvsi->num_queue_pairs = offset + qcount;\n\n\t/* Setup queue TC[0].qmap for given VSI context */\n\tctxt->info.tc_mapping[0] = cpu_to_le16(qmap);\n\tctxt->info.mapping_flags |= cpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\tctxt->info.queue_mapping[0] = cpu_to_le16(vsi->base_queue);\n\tctxt->info.valid_sections |= cpu_to_le16(sections);\n\n\t/* Reconfigure RSS for main VSI with max queue count */\n\tvsi->rss_size = max_qcount;\n\tret = i40e_vsi_config_rss(vsi);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to reconfig rss for num_queues (%u)\\n\",\n\t\t\t max_qcount);\n\t\treturn ret;\n\t}\n\tvsi->reconfig_rss = true;\n\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\"Reconfigured rss with num_queues (%u)\\n\", max_qcount);\n\n\t/* Find queue count available for channel VSIs and starting offset\n\t * for channel VSIs\n\t */\n\toverride_q = vsi->mqprio_qopt.qopt.count[0];\n\tif (override_q && override_q < vsi->num_queue_pairs) {\n\t\tvsi->cnt_q_avail = vsi->num_queue_pairs - override_q;\n\t\tvsi->next_base_queue = override_q;\n\t}\n\treturn 0;\n}\n\n/**\n * i40e_vsi_setup_queue_map - Setup a VSI queue map based on enabled_tc\n * @vsi: the VSI being setup\n * @ctxt: VSI context structure\n * @enabled_tc: Enabled TCs bitmap\n * @is_add: True if called before Add VSI\n *\n * Setup VSI queue mapping for enabled traffic classes.\n **/\nstatic void i40e_vsi_setup_queue_map(struct i40e_vsi *vsi,\n\t\t\t\t     struct i40e_vsi_context *ctxt,\n\t\t\t\t     u8 enabled_tc,\n\t\t\t\t     bool is_add)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu16 sections = 0;\n\tu8 netdev_tc = 0;\n\tu16 numtc = 1;\n\tu16 qcount;\n\tu8 offset;\n\tu16 qmap;\n\tint i;\n\tu16 num_tc_qps = 0;\n\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\toffset = 0;\n\n\t/* Number of queues per enabled TC */\n\tnum_tc_qps = vsi->alloc_queue_pairs;\n\tif (enabled_tc && (vsi->back->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\t/* Find numtc from enabled TC bitmap */\n\t\tfor (i = 0, numtc = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t\tif (enabled_tc & BIT(i)) /* TC is enabled */\n\t\t\t\tnumtc++;\n\t\t}\n\t\tif (!numtc) {\n\t\t\tdev_warn(&pf->pdev->dev, \"DCB is enabled but no TC enabled, forcing TC0\\n\");\n\t\t\tnumtc = 1;\n\t\t}\n\t\tnum_tc_qps = num_tc_qps / numtc;\n\t\tnum_tc_qps = min_t(int, num_tc_qps,\n\t\t\t\t   i40e_pf_get_max_q_per_tc(pf));\n\t}\n\n\tvsi->tc_config.numtc = numtc;\n\tvsi->tc_config.enabled_tc = enabled_tc ? enabled_tc : 1;\n\n\t/* Do not allow use more TC queue pairs than MSI-X vectors exist */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\tnum_tc_qps = min_t(int, num_tc_qps, pf->num_lan_msix);\n\n\t/* Setup queue offset/count for all TCs for given VSI */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t/* See if the given TC is enabled for the given VSI */\n\t\tif (vsi->tc_config.enabled_tc & BIT(i)) {\n\t\t\t/* TC is enabled */\n\t\t\tint pow, num_qps;\n\n\t\t\tswitch (vsi->type) {\n\t\t\tcase I40E_VSI_MAIN:\n\t\t\t\tif (!(pf->flags & (I40E_FLAG_FD_SB_ENABLED |\n\t\t\t\t    I40E_FLAG_FD_ATR_ENABLED)) ||\n\t\t\t\t    vsi->tc_config.enabled_tc != 1) {\n\t\t\t\t\tqcount = min_t(int, pf->alloc_rss_size,\n\t\t\t\t\t\t       num_tc_qps);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t/* fall through */\n\t\t\tcase I40E_VSI_FDIR:\n\t\t\tcase I40E_VSI_SRIOV:\n\t\t\tcase I40E_VSI_VMDQ2:\n\t\t\tdefault:\n\t\t\t\tqcount = num_tc_qps;\n\t\t\t\tWARN_ON(i != 0);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tvsi->tc_config.tc_info[i].qoffset = offset;\n\t\t\tvsi->tc_config.tc_info[i].qcount = qcount;\n\n\t\t\t/* find the next higher power-of-2 of num queue pairs */\n\t\t\tnum_qps = qcount;\n\t\t\tpow = 0;\n\t\t\twhile (num_qps && (BIT_ULL(pow) < qcount)) {\n\t\t\t\tpow++;\n\t\t\t\tnum_qps >>= 1;\n\t\t\t}\n\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = netdev_tc++;\n\t\t\tqmap =\n\t\t\t    (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t\t    (pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t\t\toffset += qcount;\n\t\t} else {\n\t\t\t/* TC is not enabled so set the offset to\n\t\t\t * default queue and allocate one queue\n\t\t\t * for the given TC.\n\t\t\t */\n\t\t\tvsi->tc_config.tc_info[i].qoffset = 0;\n\t\t\tvsi->tc_config.tc_info[i].qcount = 1;\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = 0;\n\n\t\t\tqmap = 0;\n\t\t}\n\t\tctxt->info.tc_mapping[i] = cpu_to_le16(qmap);\n\t}\n\n\t/* Set actual Tx/Rx queue pairs */\n\tvsi->num_queue_pairs = offset;\n\tif ((vsi->type == I40E_VSI_MAIN) && (numtc == 1)) {\n\t\tif (vsi->req_queue_pairs > 0)\n\t\t\tvsi->num_queue_pairs = vsi->req_queue_pairs;\n\t\telse if (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\t\tvsi->num_queue_pairs = pf->num_lan_msix;\n\t}\n\n\t/* Scheduler section valid can only be set for ADD VSI */\n\tif (is_add) {\n\t\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\n\t\tctxt->info.up_enable_bits = enabled_tc;\n\t}\n\tif (vsi->type == I40E_VSI_SRIOV) {\n\t\tctxt->info.mapping_flags |=\n\t\t\t\t     cpu_to_le16(I40E_AQ_VSI_QUE_MAP_NONCONTIG);\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tctxt->info.queue_mapping[i] =\n\t\t\t\t\t       cpu_to_le16(vsi->base_queue + i);\n\t} else {\n\t\tctxt->info.mapping_flags |=\n\t\t\t\t\tcpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\t\tctxt->info.queue_mapping[0] = cpu_to_le16(vsi->base_queue);\n\t}\n\tctxt->info.valid_sections |= cpu_to_le16(sections);\n}\n\n/**\n * i40e_addr_sync - Callback for dev_(mc|uc)_sync to add address\n * @netdev: the netdevice\n * @addr: address to add\n *\n * Called by __dev_(mc|uc)_sync when an address needs to be added. We call\n * __dev_(uc|mc)_sync from .set_rx_mode and guarantee to hold the hash lock.\n */\nstatic int i40e_addr_sync(struct net_device *netdev, const u8 *addr)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tif (i40e_add_mac_filter(vsi, addr))\n\t\treturn 0;\n\telse\n\t\treturn -ENOMEM;\n}\n\n/**\n * i40e_addr_unsync - Callback for dev_(mc|uc)_sync to remove address\n * @netdev: the netdevice\n * @addr: address to add\n *\n * Called by __dev_(mc|uc)_sync when an address needs to be removed. We call\n * __dev_(uc|mc)_sync from .set_rx_mode and guarantee to hold the hash lock.\n */\nstatic int i40e_addr_unsync(struct net_device *netdev, const u8 *addr)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\t/* Under some circumstances, we might receive a request to delete\n\t * our own device address from our uc list. Because we store the\n\t * device address in the VSI's MAC/VLAN filter list, we need to ignore\n\t * such requests and not delete our device address from this list.\n\t */\n\tif (ether_addr_equal(addr, netdev->dev_addr))\n\t\treturn 0;\n\n\ti40e_del_mac_filter(vsi, addr);\n\n\treturn 0;\n}\n\n/**\n * i40e_set_rx_mode - NDO callback to set the netdev filters\n * @netdev: network interface device structure\n **/\nstatic void i40e_set_rx_mode(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\n\t__dev_uc_sync(netdev, i40e_addr_sync, i40e_addr_unsync);\n\t__dev_mc_sync(netdev, i40e_addr_sync, i40e_addr_unsync);\n\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\t/* check for other flag changes */\n\tif (vsi->current_netdev_flags != vsi->netdev->flags) {\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, vsi->back->state);\n\t}\n}\n\n/**\n * i40e_undo_del_filter_entries - Undo the changes made to MAC filter entries\n * @vsi: Pointer to VSI struct\n * @from: Pointer to list which contains MAC filter entries - changes to\n *        those entries needs to be undone.\n *\n * MAC filter entries from this list were slated for deletion.\n **/\nstatic void i40e_undo_del_filter_entries(struct i40e_vsi *vsi,\n\t\t\t\t\t struct hlist_head *from)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\n\thlist_for_each_entry_safe(f, h, from, hlist) {\n\t\tu64 key = i40e_addr_to_hkey(f->macaddr);\n\n\t\t/* Move the element back into MAC filter list*/\n\t\thlist_del(&f->hlist);\n\t\thash_add(vsi->mac_filter_hash, &f->hlist, key);\n\t}\n}\n\n/**\n * i40e_undo_add_filter_entries - Undo the changes made to MAC filter entries\n * @vsi: Pointer to vsi struct\n * @from: Pointer to list which contains MAC filter entries - changes to\n *        those entries needs to be undone.\n *\n * MAC filter entries from this list were slated for addition.\n **/\nstatic void i40e_undo_add_filter_entries(struct i40e_vsi *vsi,\n\t\t\t\t\t struct hlist_head *from)\n{\n\tstruct i40e_new_mac_filter *new;\n\tstruct hlist_node *h;\n\n\thlist_for_each_entry_safe(new, h, from, hlist) {\n\t\t/* We can simply free the wrapper structure */\n\t\thlist_del(&new->hlist);\n\t\tkfree(new);\n\t}\n}\n\n/**\n * i40e_next_entry - Get the next non-broadcast filter from a list\n * @next: pointer to filter in list\n *\n * Returns the next non-broadcast filter in the list. Required so that we\n * ignore broadcast filters within the list, since these are not handled via\n * the normal firmware update path.\n */\nstatic\nstruct i40e_new_mac_filter *i40e_next_filter(struct i40e_new_mac_filter *next)\n{\n\thlist_for_each_entry_continue(next, hlist) {\n\t\tif (!is_broadcast_ether_addr(next->f->macaddr))\n\t\t\treturn next;\n\t}\n\n\treturn NULL;\n}\n\n/**\n * i40e_update_filter_state - Update filter state based on return data\n * from firmware\n * @count: Number of filters added\n * @add_list: return data from fw\n * @add_head: pointer to first filter in current batch\n *\n * MAC filter entries from list were slated to be added to device. Returns\n * number of successful filters. Note that 0 does NOT mean success!\n **/\nstatic int\ni40e_update_filter_state(int count,\n\t\t\t struct i40e_aqc_add_macvlan_element_data *add_list,\n\t\t\t struct i40e_new_mac_filter *add_head)\n{\n\tint retval = 0;\n\tint i;\n\n\tfor (i = 0; i < count; i++) {\n\t\t/* Always check status of each filter. We don't need to check\n\t\t * the firmware return status because we pre-set the filter\n\t\t * status to I40E_AQC_MM_ERR_NO_RES when sending the filter\n\t\t * request to the adminq. Thus, if it no longer matches then\n\t\t * we know the filter is active.\n\t\t */\n\t\tif (add_list[i].match_method == I40E_AQC_MM_ERR_NO_RES) {\n\t\t\tadd_head->state = I40E_FILTER_FAILED;\n\t\t} else {\n\t\t\tadd_head->state = I40E_FILTER_ACTIVE;\n\t\t\tretval++;\n\t\t}\n\n\t\tadd_head = i40e_next_filter(add_head);\n\t\tif (!add_head)\n\t\t\tbreak;\n\t}\n\n\treturn retval;\n}\n\n/**\n * i40e_aqc_del_filters - Request firmware to delete a set of filters\n * @vsi: ptr to the VSI\n * @vsi_name: name to display in messages\n * @list: the list of filters to send to firmware\n * @num_del: the number of filters to delete\n * @retval: Set to -EIO on failure to delete\n *\n * Send a request to firmware via AdminQ to delete a set of filters. Uses\n * *retval instead of a return value so that success does not force ret_val to\n * be set to 0. This ensures that a sequence of calls to this function\n * preserve the previous value of *retval on successful delete.\n */\nstatic\nvoid i40e_aqc_del_filters(struct i40e_vsi *vsi, const char *vsi_name,\n\t\t\t  struct i40e_aqc_remove_macvlan_element_data *list,\n\t\t\t  int num_del, int *retval)\n{\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\ti40e_status aq_ret;\n\tint aq_err;\n\n\taq_ret = i40e_aq_remove_macvlan(hw, vsi->seid, list, num_del, NULL);\n\taq_err = hw->aq.asq_last_status;\n\n\t/* Explicitly ignore and do not report when firmware returns ENOENT */\n\tif (aq_ret && !(aq_err == I40E_AQ_RC_ENOENT)) {\n\t\t*retval = -EIO;\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"ignoring delete macvlan error on %s, err %s, aq_err %s\\n\",\n\t\t\t vsi_name, i40e_stat_str(hw, aq_ret),\n\t\t\t i40e_aq_str(hw, aq_err));\n\t}\n}\n\n/**\n * i40e_aqc_add_filters - Request firmware to add a set of filters\n * @vsi: ptr to the VSI\n * @vsi_name: name to display in messages\n * @list: the list of filters to send to firmware\n * @add_head: Position in the add hlist\n * @num_add: the number of filters to add\n *\n * Send a request to firmware via AdminQ to add a chunk of filters. Will set\n * __I40E_VSI_OVERFLOW_PROMISC bit in vsi->state if the firmware has run out of\n * space for more filters.\n */\nstatic\nvoid i40e_aqc_add_filters(struct i40e_vsi *vsi, const char *vsi_name,\n\t\t\t  struct i40e_aqc_add_macvlan_element_data *list,\n\t\t\t  struct i40e_new_mac_filter *add_head,\n\t\t\t  int num_add)\n{\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tint aq_err, fcnt;\n\n\ti40e_aq_add_macvlan(hw, vsi->seid, list, num_add, NULL);\n\taq_err = hw->aq.asq_last_status;\n\tfcnt = i40e_update_filter_state(num_add, list, add_head);\n\n\tif (fcnt != num_add) {\n\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\tset_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t\t \"Error %s adding RX filters on %s, promiscuous mode forced on\\n\",\n\t\t\t\t i40e_aq_str(hw, aq_err), vsi_name);\n\t\t} else if (vsi->type == I40E_VSI_SRIOV ||\n\t\t\t   vsi->type == I40E_VSI_VMDQ1 ||\n\t\t\t   vsi->type == I40E_VSI_VMDQ2) {\n\t\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t\t \"Error %s adding RX filters on %s, please set promiscuous on manually for %s\\n\",\n\t\t\t\t i40e_aq_str(hw, aq_err), vsi_name, vsi_name);\n\t\t} else {\n\t\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t\t \"Error %s adding RX filters on %s, incorrect VSI type: %i.\\n\",\n\t\t\t\t i40e_aq_str(hw, aq_err), vsi_name, vsi->type);\n\t\t}\n\t}\n}\n\n/**\n * i40e_aqc_broadcast_filter - Set promiscuous broadcast flags\n * @vsi: pointer to the VSI\n * @vsi_name: the VSI name\n * @f: filter data\n *\n * This function sets or clears the promiscuous broadcast flags for VLAN\n * filters in order to properly receive broadcast frames. Assumes that only\n * broadcast filters are passed.\n *\n * Returns status indicating success or failure;\n **/\nstatic i40e_status\ni40e_aqc_broadcast_filter(struct i40e_vsi *vsi, const char *vsi_name,\n\t\t\t  struct i40e_mac_filter *f)\n{\n\tbool enable = f->state == I40E_FILTER_NEW;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\ti40e_status aq_ret;\n\n\tif (f->vlan == I40E_VLAN_ANY) {\n\t\taq_ret = i40e_aq_set_vsi_broadcast(hw,\n\t\t\t\t\t\t   vsi->seid,\n\t\t\t\t\t\t   enable,\n\t\t\t\t\t\t   NULL);\n\t} else {\n\t\taq_ret = i40e_aq_set_vsi_bc_promisc_on_vlan(hw,\n\t\t\t\t\t\t\t    vsi->seid,\n\t\t\t\t\t\t\t    enable,\n\t\t\t\t\t\t\t    f->vlan,\n\t\t\t\t\t\t\t    NULL);\n\t}\n\n\tif (aq_ret) {\n\t\tset_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t \"Error %s, forcing overflow promiscuous on %s\\n\",\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status),\n\t\t\t vsi_name);\n\t}\n\n\treturn aq_ret;\n}\n\n/**\n * i40e_set_promiscuous - set promiscuous mode\n * @pf: board private structure\n * @promisc: promisc on or off\n *\n * There are different ways of setting promiscuous mode on a PF depending on\n * what state/environment we're in.  This identifies and sets it appropriately.\n * Returns 0 on success.\n **/\nstatic int i40e_set_promiscuous(struct i40e_pf *pf, bool promisc)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status aq_ret;\n\n\tif (vsi->type == I40E_VSI_MAIN &&\n\t    pf->lan_veb != I40E_NO_VEB &&\n\t    !(pf->flags & I40E_FLAG_MFP_ENABLED)) {\n\t\t/* set defport ON for Main VSI instead of true promisc\n\t\t * this way we will get all unicast/multicast and VLAN\n\t\t * promisc behavior but will not get VF or VMDq traffic\n\t\t * replicated on the Main VSI.\n\t\t */\n\t\tif (promisc)\n\t\t\taq_ret = i40e_aq_set_default_vsi(hw,\n\t\t\t\t\t\t\t vsi->seid,\n\t\t\t\t\t\t\t NULL);\n\t\telse\n\t\t\taq_ret = i40e_aq_clear_default_vsi(hw,\n\t\t\t\t\t\t\t   vsi->seid,\n\t\t\t\t\t\t\t   NULL);\n\t\tif (aq_ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Set default VSI failed, err %s, aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t} else {\n\t\taq_ret = i40e_aq_set_vsi_unicast_promiscuous(\n\t\t\t\t\t\t  hw,\n\t\t\t\t\t\t  vsi->seid,\n\t\t\t\t\t\t  promisc, NULL,\n\t\t\t\t\t\t  true);\n\t\tif (aq_ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"set unicast promisc failed, err %s, aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t\taq_ret = i40e_aq_set_vsi_multicast_promiscuous(\n\t\t\t\t\t\t  hw,\n\t\t\t\t\t\t  vsi->seid,\n\t\t\t\t\t\t  promisc, NULL);\n\t\tif (aq_ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"set multicast promisc failed, err %s, aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t}\n\n\tif (!aq_ret)\n\t\tpf->cur_promisc = promisc;\n\n\treturn aq_ret;\n}\n\n/**\n * i40e_sync_vsi_filters - Update the VSI filter list to the HW\n * @vsi: ptr to the VSI\n *\n * Push any outstanding VSI filter changes through the AdminQ.\n *\n * Returns 0 or error value\n **/\nint i40e_sync_vsi_filters(struct i40e_vsi *vsi)\n{\n\tstruct hlist_head tmp_add_list, tmp_del_list;\n\tstruct i40e_mac_filter *f;\n\tstruct i40e_new_mac_filter *new, *add_head = NULL;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tbool old_overflow, new_overflow;\n\tunsigned int failed_filters = 0;\n\tunsigned int vlan_filters = 0;\n\tchar vsi_name[16] = \"PF\";\n\tint filter_list_len = 0;\n\ti40e_status aq_ret = 0;\n\tu32 changed_flags = 0;\n\tstruct hlist_node *h;\n\tstruct i40e_pf *pf;\n\tint num_add = 0;\n\tint num_del = 0;\n\tint retval = 0;\n\tu16 cmd_flags;\n\tint list_size;\n\tint bkt;\n\n\t/* empty array typed pointers, kcalloc later */\n\tstruct i40e_aqc_add_macvlan_element_data *add_list;\n\tstruct i40e_aqc_remove_macvlan_element_data *del_list;\n\n\twhile (test_and_set_bit(__I40E_VSI_SYNCING_FILTERS, vsi->state))\n\t\tusleep_range(1000, 2000);\n\tpf = vsi->back;\n\n\told_overflow = test_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\n\tif (vsi->netdev) {\n\t\tchanged_flags = vsi->current_netdev_flags ^ vsi->netdev->flags;\n\t\tvsi->current_netdev_flags = vsi->netdev->flags;\n\t}\n\n\tINIT_HLIST_HEAD(&tmp_add_list);\n\tINIT_HLIST_HEAD(&tmp_del_list);\n\n\tif (vsi->type == I40E_VSI_SRIOV)\n\t\tsnprintf(vsi_name, sizeof(vsi_name) - 1, \"VF %d\", vsi->vf_id);\n\telse if (vsi->type != I40E_VSI_MAIN)\n\t\tsnprintf(vsi_name, sizeof(vsi_name) - 1, \"vsi %d\", vsi->seid);\n\n\tif (vsi->flags & I40E_VSI_FLAG_FILTER_CHANGED) {\n\t\tvsi->flags &= ~I40E_VSI_FLAG_FILTER_CHANGED;\n\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\t/* Create a list of filters to delete. */\n\t\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\t\tif (f->state == I40E_FILTER_REMOVE) {\n\t\t\t\t/* Move the element into temporary del_list */\n\t\t\t\thash_del(&f->hlist);\n\t\t\t\thlist_add_head(&f->hlist, &tmp_del_list);\n\n\t\t\t\t/* Avoid counting removed filters */\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (f->state == I40E_FILTER_NEW) {\n\t\t\t\t/* Create a temporary i40e_new_mac_filter */\n\t\t\t\tnew = kzalloc(sizeof(*new), GFP_ATOMIC);\n\t\t\t\tif (!new)\n\t\t\t\t\tgoto err_no_memory_locked;\n\n\t\t\t\t/* Store pointer to the real filter */\n\t\t\t\tnew->f = f;\n\t\t\t\tnew->state = f->state;\n\n\t\t\t\t/* Add it to the hash list */\n\t\t\t\thlist_add_head(&new->hlist, &tmp_add_list);\n\t\t\t}\n\n\t\t\t/* Count the number of active (current and new) VLAN\n\t\t\t * filters we have now. Does not count filters which\n\t\t\t * are marked for deletion.\n\t\t\t */\n\t\t\tif (f->vlan > 0)\n\t\t\t\tvlan_filters++;\n\t\t}\n\n\t\tretval = i40e_correct_mac_vlan_filters(vsi,\n\t\t\t\t\t\t       &tmp_add_list,\n\t\t\t\t\t\t       &tmp_del_list,\n\t\t\t\t\t\t       vlan_filters);\n\t\tif (retval)\n\t\t\tgoto err_no_memory_locked;\n\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t}\n\n\t/* Now process 'del_list' outside the lock */\n\tif (!hlist_empty(&tmp_del_list)) {\n\t\tfilter_list_len = hw->aq.asq_buf_size /\n\t\t\t    sizeof(struct i40e_aqc_remove_macvlan_element_data);\n\t\tlist_size = filter_list_len *\n\t\t\t    sizeof(struct i40e_aqc_remove_macvlan_element_data);\n\t\tdel_list = kzalloc(list_size, GFP_ATOMIC);\n\t\tif (!del_list)\n\t\t\tgoto err_no_memory;\n\n\t\thlist_for_each_entry_safe(f, h, &tmp_del_list, hlist) {\n\t\t\tcmd_flags = 0;\n\n\t\t\t/* handle broadcast filters by updating the broadcast\n\t\t\t * promiscuous flag and release filter list.\n\t\t\t */\n\t\t\tif (is_broadcast_ether_addr(f->macaddr)) {\n\t\t\t\ti40e_aqc_broadcast_filter(vsi, vsi_name, f);\n\n\t\t\t\thlist_del(&f->hlist);\n\t\t\t\tkfree(f);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* add to delete list */\n\t\t\tether_addr_copy(del_list[num_del].mac_addr, f->macaddr);\n\t\t\tif (f->vlan == I40E_VLAN_ANY) {\n\t\t\t\tdel_list[num_del].vlan_tag = 0;\n\t\t\t\tcmd_flags |= I40E_AQC_MACVLAN_DEL_IGNORE_VLAN;\n\t\t\t} else {\n\t\t\t\tdel_list[num_del].vlan_tag =\n\t\t\t\t\tcpu_to_le16((u16)(f->vlan));\n\t\t\t}\n\n\t\t\tcmd_flags |= I40E_AQC_MACVLAN_DEL_PERFECT_MATCH;\n\t\t\tdel_list[num_del].flags = cmd_flags;\n\t\t\tnum_del++;\n\n\t\t\t/* flush a full buffer */\n\t\t\tif (num_del == filter_list_len) {\n\t\t\t\ti40e_aqc_del_filters(vsi, vsi_name, del_list,\n\t\t\t\t\t\t     num_del, &retval);\n\t\t\t\tmemset(del_list, 0, list_size);\n\t\t\t\tnum_del = 0;\n\t\t\t}\n\t\t\t/* Release memory for MAC filter entries which were\n\t\t\t * synced up with HW.\n\t\t\t */\n\t\t\thlist_del(&f->hlist);\n\t\t\tkfree(f);\n\t\t}\n\n\t\tif (num_del) {\n\t\t\ti40e_aqc_del_filters(vsi, vsi_name, del_list,\n\t\t\t\t\t     num_del, &retval);\n\t\t}\n\n\t\tkfree(del_list);\n\t\tdel_list = NULL;\n\t}\n\n\tif (!hlist_empty(&tmp_add_list)) {\n\t\t/* Do all the adds now. */\n\t\tfilter_list_len = hw->aq.asq_buf_size /\n\t\t\t       sizeof(struct i40e_aqc_add_macvlan_element_data);\n\t\tlist_size = filter_list_len *\n\t\t\t       sizeof(struct i40e_aqc_add_macvlan_element_data);\n\t\tadd_list = kzalloc(list_size, GFP_ATOMIC);\n\t\tif (!add_list)\n\t\t\tgoto err_no_memory;\n\n\t\tnum_add = 0;\n\t\thlist_for_each_entry_safe(new, h, &tmp_add_list, hlist) {\n\t\t\t/* handle broadcast filters by updating the broadcast\n\t\t\t * promiscuous flag instead of adding a MAC filter.\n\t\t\t */\n\t\t\tif (is_broadcast_ether_addr(new->f->macaddr)) {\n\t\t\t\tif (i40e_aqc_broadcast_filter(vsi, vsi_name,\n\t\t\t\t\t\t\t      new->f))\n\t\t\t\t\tnew->state = I40E_FILTER_FAILED;\n\t\t\t\telse\n\t\t\t\t\tnew->state = I40E_FILTER_ACTIVE;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* add to add array */\n\t\t\tif (num_add == 0)\n\t\t\t\tadd_head = new;\n\t\t\tcmd_flags = 0;\n\t\t\tether_addr_copy(add_list[num_add].mac_addr,\n\t\t\t\t\tnew->f->macaddr);\n\t\t\tif (new->f->vlan == I40E_VLAN_ANY) {\n\t\t\t\tadd_list[num_add].vlan_tag = 0;\n\t\t\t\tcmd_flags |= I40E_AQC_MACVLAN_ADD_IGNORE_VLAN;\n\t\t\t} else {\n\t\t\t\tadd_list[num_add].vlan_tag =\n\t\t\t\t\tcpu_to_le16((u16)(new->f->vlan));\n\t\t\t}\n\t\t\tadd_list[num_add].queue_number = 0;\n\t\t\t/* set invalid match method for later detection */\n\t\t\tadd_list[num_add].match_method = I40E_AQC_MM_ERR_NO_RES;\n\t\t\tcmd_flags |= I40E_AQC_MACVLAN_ADD_PERFECT_MATCH;\n\t\t\tadd_list[num_add].flags = cpu_to_le16(cmd_flags);\n\t\t\tnum_add++;\n\n\t\t\t/* flush a full buffer */\n\t\t\tif (num_add == filter_list_len) {\n\t\t\t\ti40e_aqc_add_filters(vsi, vsi_name, add_list,\n\t\t\t\t\t\t     add_head, num_add);\n\t\t\t\tmemset(add_list, 0, list_size);\n\t\t\t\tnum_add = 0;\n\t\t\t}\n\t\t}\n\t\tif (num_add) {\n\t\t\ti40e_aqc_add_filters(vsi, vsi_name, add_list, add_head,\n\t\t\t\t\t     num_add);\n\t\t}\n\t\t/* Now move all of the filters from the temp add list back to\n\t\t * the VSI's list.\n\t\t */\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\thlist_for_each_entry_safe(new, h, &tmp_add_list, hlist) {\n\t\t\t/* Only update the state if we're still NEW */\n\t\t\tif (new->f->state == I40E_FILTER_NEW)\n\t\t\t\tnew->f->state = new->state;\n\t\t\thlist_del(&new->hlist);\n\t\t\tkfree(new);\n\t\t}\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t\tkfree(add_list);\n\t\tadd_list = NULL;\n\t}\n\n\t/* Determine the number of active and failed filters. */\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\tvsi->active_filters = 0;\n\thash_for_each(vsi->mac_filter_hash, bkt, f, hlist) {\n\t\tif (f->state == I40E_FILTER_ACTIVE)\n\t\t\tvsi->active_filters++;\n\t\telse if (f->state == I40E_FILTER_FAILED)\n\t\t\tfailed_filters++;\n\t}\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\t/* Check if we are able to exit overflow promiscuous mode. We can\n\t * safely exit if we didn't just enter, we no longer have any failed\n\t * filters, and we have reduced filters below the threshold value.\n\t */\n\tif (old_overflow && !failed_filters &&\n\t    vsi->active_filters < vsi->promisc_threshold) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"filter logjam cleared on %s, leaving overflow promiscuous mode\\n\",\n\t\t\t vsi_name);\n\t\tclear_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\tvsi->promisc_threshold = 0;\n\t}\n\n\t/* if the VF is not trusted do not do promisc */\n\tif ((vsi->type == I40E_VSI_SRIOV) && !pf->vf[vsi->vf_id].trusted) {\n\t\tclear_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\tgoto out;\n\t}\n\n\tnew_overflow = test_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\n\t/* If we are entering overflow promiscuous, we need to calculate a new\n\t * threshold for when we are safe to exit\n\t */\n\tif (!old_overflow && new_overflow)\n\t\tvsi->promisc_threshold = (vsi->active_filters * 3) / 4;\n\n\t/* check for changes in promiscuous modes */\n\tif (changed_flags & IFF_ALLMULTI) {\n\t\tbool cur_multipromisc;\n\n\t\tcur_multipromisc = !!(vsi->current_netdev_flags & IFF_ALLMULTI);\n\t\taq_ret = i40e_aq_set_vsi_multicast_promiscuous(&vsi->back->hw,\n\t\t\t\t\t\t\t       vsi->seid,\n\t\t\t\t\t\t\t       cur_multipromisc,\n\t\t\t\t\t\t\t       NULL);\n\t\tif (aq_ret) {\n\t\t\tretval = i40e_aq_rc_to_posix(aq_ret,\n\t\t\t\t\t\t     hw->aq.asq_last_status);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"set multi promisc failed on %s, err %s aq_err %s\\n\",\n\t\t\t\t vsi_name,\n\t\t\t\t i40e_stat_str(hw, aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t} else {\n\t\t\tdev_info(&pf->pdev->dev, \"%s is %s allmulti mode.\\n\",\n\t\t\t\t vsi->netdev->name,\n\t\t\t\t cur_multipromisc ? \"entering\" : \"leaving\");\n\t\t}\n\t}\n\n\tif ((changed_flags & IFF_PROMISC) || old_overflow != new_overflow) {\n\t\tbool cur_promisc;\n\n\t\tcur_promisc = (!!(vsi->current_netdev_flags & IFF_PROMISC) ||\n\t\t\t       new_overflow);\n\t\taq_ret = i40e_set_promiscuous(pf, cur_promisc);\n\t\tif (aq_ret) {\n\t\t\tretval = i40e_aq_rc_to_posix(aq_ret,\n\t\t\t\t\t\t     hw->aq.asq_last_status);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Setting promiscuous %s failed on %s, err %s aq_err %s\\n\",\n\t\t\t\t cur_promisc ? \"on\" : \"off\",\n\t\t\t\t vsi_name,\n\t\t\t\t i40e_stat_str(hw, aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t}\nout:\n\t/* if something went wrong then set the changed flag so we try again */\n\tif (retval)\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\n\tclear_bit(__I40E_VSI_SYNCING_FILTERS, vsi->state);\n\treturn retval;\n\nerr_no_memory:\n\t/* Restore elements on the temporary add and delete lists */\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\nerr_no_memory_locked:\n\ti40e_undo_del_filter_entries(vsi, &tmp_del_list);\n\ti40e_undo_add_filter_entries(vsi, &tmp_add_list);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\tclear_bit(__I40E_VSI_SYNCING_FILTERS, vsi->state);\n\treturn -ENOMEM;\n}\n\n/**\n * i40e_sync_filters_subtask - Sync the VSI filter list with HW\n * @pf: board private structure\n **/\nstatic void i40e_sync_filters_subtask(struct i40e_pf *pf)\n{\n\tint v;\n\n\tif (!pf)\n\t\treturn;\n\tif (!test_and_clear_bit(__I40E_MACVLAN_SYNC_PENDING, pf->state))\n\t\treturn;\n\tif (test_and_set_bit(__I40E_VF_DISABLE, pf->state)) {\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, pf->state);\n\t\treturn;\n\t}\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v] &&\n\t\t    (pf->vsi[v]->flags & I40E_VSI_FLAG_FILTER_CHANGED)) {\n\t\t\tint ret = i40e_sync_vsi_filters(pf->vsi[v]);\n\n\t\t\tif (ret) {\n\t\t\t\t/* come back and try again later */\n\t\t\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING,\n\t\t\t\t\tpf->state);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tclear_bit(__I40E_VF_DISABLE, pf->state);\n}\n\n/**\n * i40e_max_xdp_frame_size - returns the maximum allowed frame size for XDP\n * @vsi: the vsi\n **/\nstatic int i40e_max_xdp_frame_size(struct i40e_vsi *vsi)\n{\n\tif (PAGE_SIZE >= 8192 || (vsi->back->flags & I40E_FLAG_LEGACY_RX))\n\t\treturn I40E_RXBUFFER_2048;\n\telse\n\t\treturn I40E_RXBUFFER_3072;\n}\n\n/**\n * i40e_change_mtu - NDO callback to change the Maximum Transfer Unit\n * @netdev: network interface device structure\n * @new_mtu: new value for maximum frame size\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tint frame_size = new_mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\n\n\t\tif (frame_size > i40e_max_xdp_frame_size(vsi))\n\t\t\treturn -EINVAL;\n\t}\n\n\tnetdev_info(netdev, \"changing MTU from %d to %d\\n\",\n\t\t    netdev->mtu, new_mtu);\n\tnetdev->mtu = new_mtu;\n\tif (netif_running(netdev))\n\t\ti40e_vsi_reinit_locked(vsi);\n\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\tset_bit(__I40E_CLIENT_L2_CHANGE, pf->state);\n\treturn 0;\n}\n\n/**\n * i40e_ioctl - Access the hwtstamp interface\n * @netdev: network interface device structure\n * @ifr: interface request data\n * @cmd: ioctl command\n **/\nint i40e_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_pf *pf = np->vsi->back;\n\n\tswitch (cmd) {\n\tcase SIOCGHWTSTAMP:\n\t\treturn i40e_ptp_get_ts_config(pf, ifr);\n\tcase SIOCSHWTSTAMP:\n\t\treturn i40e_ptp_set_ts_config(pf, ifr);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n/**\n * i40e_vlan_stripping_enable - Turn on vlan stripping for the VSI\n * @vsi: the vsi being adjusted\n **/\nvoid i40e_vlan_stripping_enable(struct i40e_vsi *vsi)\n{\n\tstruct i40e_vsi_context ctxt;\n\ti40e_status ret;\n\n\t/* Don't modify stripping options if a port VLAN is active */\n\tif (vsi->info.pvid)\n\t\treturn;\n\n\tif ((vsi->info.valid_sections &\n\t     cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID)) &&\n\t    ((vsi->info.port_vlan_flags & I40E_AQ_VSI_PVLAN_MODE_MASK) == 0))\n\t\treturn;  /* already enabled */\n\n\tvsi->info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\tvsi->info.port_vlan_flags = I40E_AQ_VSI_PVLAN_MODE_ALL |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_EMOD_STR_BOTH;\n\n\tctxt.seid = vsi->seid;\n\tctxt.info = vsi->info;\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"update vlan stripping failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&vsi->back->hw, ret),\n\t\t\t i40e_aq_str(&vsi->back->hw,\n\t\t\t\t     vsi->back->hw.aq.asq_last_status));\n\t}\n}\n\n/**\n * i40e_vlan_stripping_disable - Turn off vlan stripping for the VSI\n * @vsi: the vsi being adjusted\n **/\nvoid i40e_vlan_stripping_disable(struct i40e_vsi *vsi)\n{\n\tstruct i40e_vsi_context ctxt;\n\ti40e_status ret;\n\n\t/* Don't modify stripping options if a port VLAN is active */\n\tif (vsi->info.pvid)\n\t\treturn;\n\n\tif ((vsi->info.valid_sections &\n\t     cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID)) &&\n\t    ((vsi->info.port_vlan_flags & I40E_AQ_VSI_PVLAN_EMOD_MASK) ==\n\t     I40E_AQ_VSI_PVLAN_EMOD_MASK))\n\t\treturn;  /* already disabled */\n\n\tvsi->info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\tvsi->info.port_vlan_flags = I40E_AQ_VSI_PVLAN_MODE_ALL |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_EMOD_NOTHING;\n\n\tctxt.seid = vsi->seid;\n\tctxt.info = vsi->info;\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"update vlan stripping failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&vsi->back->hw, ret),\n\t\t\t i40e_aq_str(&vsi->back->hw,\n\t\t\t\t     vsi->back->hw.aq.asq_last_status));\n\t}\n}\n\n/**\n * i40e_add_vlan_all_mac - Add a MAC/VLAN filter for each existing MAC address\n * @vsi: the vsi being configured\n * @vid: vlan id to be added (0 = untagged only , -1 = any)\n *\n * This is a helper function for adding a new MAC/VLAN filter with the\n * specified VLAN for each existing MAC address already in the hash table.\n * This function does *not* perform any accounting to update filters based on\n * VLAN mode.\n *\n * NOTE: this function expects to be called while under the\n * mac_filter_hash_lock\n **/\nint i40e_add_vlan_all_mac(struct i40e_vsi *vsi, s16 vid)\n{\n\tstruct i40e_mac_filter *f, *add_f;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (f->state == I40E_FILTER_REMOVE)\n\t\t\tcontinue;\n\t\tadd_f = i40e_add_filter(vsi, f->macaddr, vid);\n\t\tif (!add_f) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"Could not add vlan filter %d for %pM\\n\",\n\t\t\t\t vid, f->macaddr);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_add_vlan - Add VSI membership for given VLAN\n * @vsi: the VSI being configured\n * @vid: VLAN id to be added\n **/\nint i40e_vsi_add_vlan(struct i40e_vsi *vsi, u16 vid)\n{\n\tint err;\n\n\tif (vsi->info.pvid)\n\t\treturn -EINVAL;\n\n\t/* The network stack will attempt to add VID=0, with the intention to\n\t * receive priority tagged packets with a VLAN of 0. Our HW receives\n\t * these packets by default when configured to receive untagged\n\t * packets, so we don't need to add a filter for this case.\n\t * Additionally, HW interprets adding a VID=0 filter as meaning to\n\t * receive *only* tagged traffic and stops receiving untagged traffic.\n\t * Thus, we do not want to actually add a filter for VID=0\n\t */\n\tif (!vid)\n\t\treturn 0;\n\n\t/* Locked once because all functions invoked below iterates list*/\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\terr = i40e_add_vlan_all_mac(vsi, vid);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\tif (err)\n\t\treturn err;\n\n\t/* schedule our worker thread which will take care of\n\t * applying the new filter changes\n\t */\n\ti40e_service_event_schedule(vsi->back);\n\treturn 0;\n}\n\n/**\n * i40e_rm_vlan_all_mac - Remove MAC/VLAN pair for all MAC with the given VLAN\n * @vsi: the vsi being configured\n * @vid: vlan id to be removed (0 = untagged only , -1 = any)\n *\n * This function should be used to remove all VLAN filters which match the\n * given VID. It does not schedule the service event and does not take the\n * mac_filter_hash_lock so it may be combined with other operations under\n * a single invocation of the mac_filter_hash_lock.\n *\n * NOTE: this function expects to be called while under the\n * mac_filter_hash_lock\n */\nvoid i40e_rm_vlan_all_mac(struct i40e_vsi *vsi, s16 vid)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (f->vlan == vid)\n\t\t\t__i40e_del_filter(vsi, f);\n\t}\n}\n\n/**\n * i40e_vsi_kill_vlan - Remove VSI membership for given VLAN\n * @vsi: the VSI being configured\n * @vid: VLAN id to be removed\n **/\nvoid i40e_vsi_kill_vlan(struct i40e_vsi *vsi, u16 vid)\n{\n\tif (!vid || vsi->info.pvid)\n\t\treturn;\n\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\ti40e_rm_vlan_all_mac(vsi, vid);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\t/* schedule our worker thread which will take care of\n\t * applying the new filter changes\n\t */\n\ti40e_service_event_schedule(vsi->back);\n}\n\n/**\n * i40e_vlan_rx_add_vid - Add a vlan id filter to HW offload\n * @netdev: network interface to be adjusted\n * @proto: unused protocol value\n * @vid: vlan id to be added\n *\n * net_device_ops implementation for adding vlan ids\n **/\nstatic int i40e_vlan_rx_add_vid(struct net_device *netdev,\n\t\t\t\t__always_unused __be16 proto, u16 vid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tint ret = 0;\n\n\tif (vid >= VLAN_N_VID)\n\t\treturn -EINVAL;\n\n\tret = i40e_vsi_add_vlan(vsi, vid);\n\tif (!ret)\n\t\tset_bit(vid, vsi->active_vlans);\n\n\treturn ret;\n}\n\n/**\n * i40e_vlan_rx_add_vid_up - Add a vlan id filter to HW offload in UP path\n * @netdev: network interface to be adjusted\n * @proto: unused protocol value\n * @vid: vlan id to be added\n **/\nstatic void i40e_vlan_rx_add_vid_up(struct net_device *netdev,\n\t\t\t\t    __always_unused __be16 proto, u16 vid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tif (vid >= VLAN_N_VID)\n\t\treturn;\n\tset_bit(vid, vsi->active_vlans);\n}\n\n/**\n * i40e_vlan_rx_kill_vid - Remove a vlan id filter from HW offload\n * @netdev: network interface to be adjusted\n * @proto: unused protocol value\n * @vid: vlan id to be removed\n *\n * net_device_ops implementation for removing vlan ids\n **/\nstatic int i40e_vlan_rx_kill_vid(struct net_device *netdev,\n\t\t\t\t __always_unused __be16 proto, u16 vid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\t/* return code is ignored as there is nothing a user\n\t * can do about failure to remove and a log message was\n\t * already printed from the other function\n\t */\n\ti40e_vsi_kill_vlan(vsi, vid);\n\n\tclear_bit(vid, vsi->active_vlans);\n\n\treturn 0;\n}\n\n/**\n * i40e_restore_vlan - Reinstate vlans when vsi/netdev comes back up\n * @vsi: the vsi being brought back up\n **/\nstatic void i40e_restore_vlan(struct i40e_vsi *vsi)\n{\n\tu16 vid;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\tif (vsi->netdev->features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\ti40e_vlan_stripping_enable(vsi);\n\telse\n\t\ti40e_vlan_stripping_disable(vsi);\n\n\tfor_each_set_bit(vid, vsi->active_vlans, VLAN_N_VID)\n\t\ti40e_vlan_rx_add_vid_up(vsi->netdev, htons(ETH_P_8021Q),\n\t\t\t\t\tvid);\n}\n\n/**\n * i40e_vsi_add_pvid - Add pvid for the VSI\n * @vsi: the vsi being adjusted\n * @vid: the vlan id to set as a PVID\n **/\nint i40e_vsi_add_pvid(struct i40e_vsi *vsi, u16 vid)\n{\n\tstruct i40e_vsi_context ctxt;\n\ti40e_status ret;\n\n\tvsi->info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\tvsi->info.pvid = cpu_to_le16(vid);\n\tvsi->info.port_vlan_flags = I40E_AQ_VSI_PVLAN_MODE_TAGGED |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_INSERT_PVID |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_EMOD_STR;\n\n\tctxt.seid = vsi->seid;\n\tctxt.info = vsi->info;\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"add pvid failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&vsi->back->hw, ret),\n\t\t\t i40e_aq_str(&vsi->back->hw,\n\t\t\t\t     vsi->back->hw.aq.asq_last_status));\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_remove_pvid - Remove the pvid from the VSI\n * @vsi: the vsi being adjusted\n *\n * Just use the vlan_rx_register() service to put it back to normal\n **/\nvoid i40e_vsi_remove_pvid(struct i40e_vsi *vsi)\n{\n\tvsi->info.pvid = 0;\n\n\ti40e_vlan_stripping_disable(vsi);\n}\n\n/**\n * i40e_vsi_setup_tx_resources - Allocate VSI Tx queue resources\n * @vsi: ptr to the VSI\n *\n * If this function returns with an error, then it's possible one or\n * more of the rings is populated (while the rest are not).  It is the\n * callers duty to clean those orphaned rings.\n *\n * Return 0 on success, negative on failure\n **/\nstatic int i40e_vsi_setup_tx_resources(struct i40e_vsi *vsi)\n{\n\tint i, err = 0;\n\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_setup_tx_descriptors(vsi->tx_rings[i]);\n\n\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\treturn err;\n\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_setup_tx_descriptors(vsi->xdp_rings[i]);\n\n\treturn err;\n}\n\n/**\n * i40e_vsi_free_tx_resources - Free Tx resources for VSI queues\n * @vsi: ptr to the VSI\n *\n * Free VSI's transmit software resources\n **/\nstatic void i40e_vsi_free_tx_resources(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\tif (vsi->tx_rings) {\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tif (vsi->tx_rings[i] && vsi->tx_rings[i]->desc)\n\t\t\t\ti40e_free_tx_resources(vsi->tx_rings[i]);\n\t}\n\n\tif (vsi->xdp_rings) {\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tif (vsi->xdp_rings[i] && vsi->xdp_rings[i]->desc)\n\t\t\t\ti40e_free_tx_resources(vsi->xdp_rings[i]);\n\t}\n}\n\n/**\n * i40e_vsi_setup_rx_resources - Allocate VSI queues Rx resources\n * @vsi: ptr to the VSI\n *\n * If this function returns with an error, then it's possible one or\n * more of the rings is populated (while the rest are not).  It is the\n * callers duty to clean those orphaned rings.\n *\n * Return 0 on success, negative on failure\n **/\nstatic int i40e_vsi_setup_rx_resources(struct i40e_vsi *vsi)\n{\n\tint i, err = 0;\n\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_setup_rx_descriptors(vsi->rx_rings[i]);\n\treturn err;\n}\n\n/**\n * i40e_vsi_free_rx_resources - Free Rx Resources for VSI queues\n * @vsi: ptr to the VSI\n *\n * Free all receive software resources\n **/\nstatic void i40e_vsi_free_rx_resources(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\tif (!vsi->rx_rings)\n\t\treturn;\n\n\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\tif (vsi->rx_rings[i] && vsi->rx_rings[i]->desc)\n\t\t\ti40e_free_rx_resources(vsi->rx_rings[i]);\n}\n\n/**\n * i40e_config_xps_tx_ring - Configure XPS for a Tx ring\n * @ring: The Tx ring to configure\n *\n * This enables/disables XPS for a given Tx descriptor ring\n * based on the TCs enabled for the VSI that ring belongs to.\n **/\nstatic void i40e_config_xps_tx_ring(struct i40e_ring *ring)\n{\n\tint cpu;\n\n\tif (!ring->q_vector || !ring->netdev || ring->ch)\n\t\treturn;\n\n\t/* We only initialize XPS once, so as not to overwrite user settings */\n\tif (test_and_set_bit(__I40E_TX_XPS_INIT_DONE, ring->state))\n\t\treturn;\n\n\tcpu = cpumask_local_spread(ring->q_vector->v_idx, -1);\n\tnetif_set_xps_queue(ring->netdev, get_cpu_mask(cpu),\n\t\t\t    ring->queue_index);\n}\n\n/**\n * i40e_xsk_umem - Retrieve the AF_XDP ZC if XDP and ZC is enabled\n * @ring: The Tx or Rx ring\n *\n * Returns the UMEM or NULL.\n **/\nstatic struct xdp_umem *i40e_xsk_umem(struct i40e_ring *ring)\n{\n\tbool xdp_on = i40e_enabled_xdp_vsi(ring->vsi);\n\tint qid = ring->queue_index;\n\n\tif (ring_is_xdp(ring))\n\t\tqid -= ring->vsi->alloc_queue_pairs;\n\n\tif (!xdp_on || !test_bit(qid, ring->vsi->af_xdp_zc_qps))\n\t\treturn NULL;\n\n\treturn xdp_get_umem_from_qid(ring->vsi->netdev, qid);\n}\n\n/**\n * i40e_configure_tx_ring - Configure a transmit ring context and rest\n * @ring: The Tx ring to configure\n *\n * Configure the Tx descriptor ring in the HMC context.\n **/\nstatic int i40e_configure_tx_ring(struct i40e_ring *ring)\n{\n\tstruct i40e_vsi *vsi = ring->vsi;\n\tu16 pf_q = vsi->base_queue + ring->queue_index;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tstruct i40e_hmc_obj_txq tx_ctx;\n\ti40e_status err = 0;\n\tu32 qtx_ctl = 0;\n\n\tif (ring_is_xdp(ring))\n\t\tring->xsk_umem = i40e_xsk_umem(ring);\n\n\t/* some ATR related tx ring init */\n\tif (vsi->back->flags & I40E_FLAG_FD_ATR_ENABLED) {\n\t\tring->atr_sample_rate = vsi->back->atr_sample_rate;\n\t\tring->atr_count = 0;\n\t} else {\n\t\tring->atr_sample_rate = 0;\n\t}\n\n\t/* configure XPS */\n\ti40e_config_xps_tx_ring(ring);\n\n\t/* clear the context structure first */\n\tmemset(&tx_ctx, 0, sizeof(tx_ctx));\n\n\ttx_ctx.new_context = 1;\n\ttx_ctx.base = (ring->dma / 128);\n\ttx_ctx.qlen = ring->count;\n\ttx_ctx.fd_ena = !!(vsi->back->flags & (I40E_FLAG_FD_SB_ENABLED |\n\t\t\t\t\t       I40E_FLAG_FD_ATR_ENABLED));\n\ttx_ctx.timesync_ena = !!(vsi->back->flags & I40E_FLAG_PTP);\n\t/* FDIR VSI tx ring can still use RS bit and writebacks */\n\tif (vsi->type != I40E_VSI_FDIR)\n\t\ttx_ctx.head_wb_ena = 1;\n\ttx_ctx.head_wb_addr = ring->dma +\n\t\t\t      (ring->count * sizeof(struct i40e_tx_desc));\n\n\t/* As part of VSI creation/update, FW allocates certain\n\t * Tx arbitration queue sets for each TC enabled for\n\t * the VSI. The FW returns the handles to these queue\n\t * sets as part of the response buffer to Add VSI,\n\t * Update VSI, etc. AQ commands. It is expected that\n\t * these queue set handles be associated with the Tx\n\t * queues by the driver as part of the TX queue context\n\t * initialization. This has to be done regardless of\n\t * DCB as by default everything is mapped to TC0.\n\t */\n\n\tif (ring->ch)\n\t\ttx_ctx.rdylist =\n\t\t\tle16_to_cpu(ring->ch->info.qs_handle[ring->dcb_tc]);\n\n\telse\n\t\ttx_ctx.rdylist = le16_to_cpu(vsi->info.qs_handle[ring->dcb_tc]);\n\n\ttx_ctx.rdylist_act = 0;\n\n\t/* clear the context in the HMC */\n\terr = i40e_clear_lan_tx_queue_context(hw, pf_q);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to clear LAN Tx queue context on Tx ring %d (pf_q %d), error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* set the context in the HMC */\n\terr = i40e_set_lan_tx_queue_context(hw, pf_q, &tx_ctx);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to set LAN Tx queue context on Tx ring %d (pf_q %d, error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Now associate this queue with this PCI function */\n\tif (ring->ch) {\n\t\tif (ring->ch->type == I40E_VSI_VMDQ2)\n\t\t\tqtx_ctl = I40E_QTX_CTL_VM_QUEUE;\n\t\telse\n\t\t\treturn -EINVAL;\n\n\t\tqtx_ctl |= (ring->ch->vsi_number <<\n\t\t\t    I40E_QTX_CTL_VFVM_INDX_SHIFT) &\n\t\t\t    I40E_QTX_CTL_VFVM_INDX_MASK;\n\t} else {\n\t\tif (vsi->type == I40E_VSI_VMDQ2) {\n\t\t\tqtx_ctl = I40E_QTX_CTL_VM_QUEUE;\n\t\t\tqtx_ctl |= ((vsi->id) << I40E_QTX_CTL_VFVM_INDX_SHIFT) &\n\t\t\t\t    I40E_QTX_CTL_VFVM_INDX_MASK;\n\t\t} else {\n\t\t\tqtx_ctl = I40E_QTX_CTL_PF_QUEUE;\n\t\t}\n\t}\n\n\tqtx_ctl |= ((hw->pf_id << I40E_QTX_CTL_PF_INDX_SHIFT) &\n\t\t    I40E_QTX_CTL_PF_INDX_MASK);\n\twr32(hw, I40E_QTX_CTL(pf_q), qtx_ctl);\n\ti40e_flush(hw);\n\n\t/* cache tail off for easier writes later */\n\tring->tail = hw->hw_addr + I40E_QTX_TAIL(pf_q);\n\n\treturn 0;\n}\n\n/**\n * i40e_configure_rx_ring - Configure a receive ring context\n * @ring: The Rx ring to configure\n *\n * Configure the Rx descriptor ring in the HMC context.\n **/\nstatic int i40e_configure_rx_ring(struct i40e_ring *ring)\n{\n\tstruct i40e_vsi *vsi = ring->vsi;\n\tu32 chain_len = vsi->back->hw.func_caps.rx_buf_chain_len;\n\tu16 pf_q = vsi->base_queue + ring->queue_index;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tstruct i40e_hmc_obj_rxq rx_ctx;\n\ti40e_status err = 0;\n\tbool ok;\n\tint ret;\n\n\tbitmap_zero(ring->state, __I40E_RING_STATE_NBITS);\n\n\t/* clear the context structure first */\n\tmemset(&rx_ctx, 0, sizeof(rx_ctx));\n\n\tif (ring->vsi->type == I40E_VSI_MAIN)\n\t\txdp_rxq_info_unreg_mem_model(&ring->xdp_rxq);\n\n\tring->xsk_umem = i40e_xsk_umem(ring);\n\tif (ring->xsk_umem) {\n\t\tring->rx_buf_len = ring->xsk_umem->chunk_size_nohr -\n\t\t\t\t   XDP_PACKET_HEADROOM;\n\t\t/* For AF_XDP ZC, we disallow packets to span on\n\t\t * multiple buffers, thus letting us skip that\n\t\t * handling in the fast-path.\n\t\t */\n\t\tchain_len = 1;\n\t\tring->zca.free = i40e_zca_free;\n\t\tret = xdp_rxq_info_reg_mem_model(&ring->xdp_rxq,\n\t\t\t\t\t\t MEM_TYPE_ZERO_COPY,\n\t\t\t\t\t\t &ring->zca);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Registered XDP mem model MEM_TYPE_ZERO_COPY on Rx ring %d\\n\",\n\t\t\t ring->queue_index);\n\n\t} else {\n\t\tring->rx_buf_len = vsi->rx_buf_len;\n\t\tif (ring->vsi->type == I40E_VSI_MAIN) {\n\t\t\tret = xdp_rxq_info_reg_mem_model(&ring->xdp_rxq,\n\t\t\t\t\t\t\t MEM_TYPE_PAGE_SHARED,\n\t\t\t\t\t\t\t NULL);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\trx_ctx.dbuff = DIV_ROUND_UP(ring->rx_buf_len,\n\t\t\t\t    BIT_ULL(I40E_RXQ_CTX_DBUFF_SHIFT));\n\n\trx_ctx.base = (ring->dma / 128);\n\trx_ctx.qlen = ring->count;\n\n\t/* use 32 byte descriptors */\n\trx_ctx.dsize = 1;\n\n\t/* descriptor type is always zero\n\t * rx_ctx.dtype = 0;\n\t */\n\trx_ctx.hsplit_0 = 0;\n\n\trx_ctx.rxmax = min_t(u16, vsi->max_frame, chain_len * ring->rx_buf_len);\n\tif (hw->revision_id == 0)\n\t\trx_ctx.lrxqthresh = 0;\n\telse\n\t\trx_ctx.lrxqthresh = 1;\n\trx_ctx.crcstrip = 1;\n\trx_ctx.l2tsel = 1;\n\t/* this controls whether VLAN is stripped from inner headers */\n\trx_ctx.showiv = 0;\n\t/* set the prefena field to 1 because the manual says to */\n\trx_ctx.prefena = 1;\n\n\t/* clear the context in the HMC */\n\terr = i40e_clear_lan_rx_queue_context(hw, pf_q);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to clear LAN Rx queue context on Rx ring %d (pf_q %d), error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* set the context in the HMC */\n\terr = i40e_set_lan_rx_queue_context(hw, pf_q, &rx_ctx);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to set LAN Rx queue context on Rx ring %d (pf_q %d), error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* configure Rx buffer alignment */\n\tif (!vsi->netdev || (vsi->back->flags & I40E_FLAG_LEGACY_RX))\n\t\tclear_ring_build_skb_enabled(ring);\n\telse\n\t\tset_ring_build_skb_enabled(ring);\n\n\t/* cache tail for quicker writes, and clear the reg before use */\n\tring->tail = hw->hw_addr + I40E_QRX_TAIL(pf_q);\n\twritel(0, ring->tail);\n\n\tok = ring->xsk_umem ?\n\t     i40e_alloc_rx_buffers_zc(ring, I40E_DESC_UNUSED(ring)) :\n\t     !i40e_alloc_rx_buffers(ring, I40E_DESC_UNUSED(ring));\n\tif (!ok) {\n\t\t/* Log this in case the user has forgotten to give the kernel\n\t\t * any buffers, even later in the application.\n\t\t */\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to allocate some buffers on %sRx ring %d (pf_q %d)\\n\",\n\t\t\t ring->xsk_umem ? \"UMEM enabled \" : \"\",\n\t\t\t ring->queue_index, pf_q);\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_configure_tx - Configure the VSI for Tx\n * @vsi: VSI structure describing this set of rings and resources\n *\n * Configure the Tx VSI for operation.\n **/\nstatic int i40e_vsi_configure_tx(struct i40e_vsi *vsi)\n{\n\tint err = 0;\n\tu16 i;\n\n\tfor (i = 0; (i < vsi->num_queue_pairs) && !err; i++)\n\t\terr = i40e_configure_tx_ring(vsi->tx_rings[i]);\n\n\tif (err || !i40e_enabled_xdp_vsi(vsi))\n\t\treturn err;\n\n\tfor (i = 0; (i < vsi->num_queue_pairs) && !err; i++)\n\t\terr = i40e_configure_tx_ring(vsi->xdp_rings[i]);\n\n\treturn err;\n}\n\n/**\n * i40e_vsi_configure_rx - Configure the VSI for Rx\n * @vsi: the VSI being configured\n *\n * Configure the Rx VSI for operation.\n **/\nstatic int i40e_vsi_configure_rx(struct i40e_vsi *vsi)\n{\n\tint err = 0;\n\tu16 i;\n\n\tif (!vsi->netdev || (vsi->back->flags & I40E_FLAG_LEGACY_RX)) {\n\t\tvsi->max_frame = I40E_MAX_RXBUFFER;\n\t\tvsi->rx_buf_len = I40E_RXBUFFER_2048;\n#if (PAGE_SIZE < 8192)\n\t} else if (!I40E_2K_TOO_SMALL_WITH_PADDING &&\n\t\t   (vsi->netdev->mtu <= ETH_DATA_LEN)) {\n\t\tvsi->max_frame = I40E_RXBUFFER_1536 - NET_IP_ALIGN;\n\t\tvsi->rx_buf_len = I40E_RXBUFFER_1536 - NET_IP_ALIGN;\n#endif\n\t} else {\n\t\tvsi->max_frame = I40E_MAX_RXBUFFER;\n\t\tvsi->rx_buf_len = (PAGE_SIZE < 8192) ? I40E_RXBUFFER_3072 :\n\t\t\t\t\t\t       I40E_RXBUFFER_2048;\n\t}\n\n\t/* set up individual rings */\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_configure_rx_ring(vsi->rx_rings[i]);\n\n\treturn err;\n}\n\n/**\n * i40e_vsi_config_dcb_rings - Update rings to reflect DCB TC\n * @vsi: ptr to the VSI\n **/\nstatic void i40e_vsi_config_dcb_rings(struct i40e_vsi *vsi)\n{\n\tstruct i40e_ring *tx_ring, *rx_ring;\n\tu16 qoffset, qcount;\n\tint i, n;\n\n\tif (!(vsi->back->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\t/* Reset the TC information */\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\t\trx_ring = vsi->rx_rings[i];\n\t\t\ttx_ring = vsi->tx_rings[i];\n\t\t\trx_ring->dcb_tc = 0;\n\t\t\ttx_ring->dcb_tc = 0;\n\t\t}\n\t\treturn;\n\t}\n\n\tfor (n = 0; n < I40E_MAX_TRAFFIC_CLASS; n++) {\n\t\tif (!(vsi->tc_config.enabled_tc & BIT_ULL(n)))\n\t\t\tcontinue;\n\n\t\tqoffset = vsi->tc_config.tc_info[n].qoffset;\n\t\tqcount = vsi->tc_config.tc_info[n].qcount;\n\t\tfor (i = qoffset; i < (qoffset + qcount); i++) {\n\t\t\trx_ring = vsi->rx_rings[i];\n\t\t\ttx_ring = vsi->tx_rings[i];\n\t\t\trx_ring->dcb_tc = n;\n\t\t\ttx_ring->dcb_tc = n;\n\t\t}\n\t}\n}\n\n/**\n * i40e_set_vsi_rx_mode - Call set_rx_mode on a VSI\n * @vsi: ptr to the VSI\n **/\nstatic void i40e_set_vsi_rx_mode(struct i40e_vsi *vsi)\n{\n\tif (vsi->netdev)\n\t\ti40e_set_rx_mode(vsi->netdev);\n}\n\n/**\n * i40e_fdir_filter_restore - Restore the Sideband Flow Director filters\n * @vsi: Pointer to the targeted VSI\n *\n * This function replays the hlist on the hw where all the SB Flow Director\n * filters were saved.\n **/\nstatic void i40e_fdir_filter_restore(struct i40e_vsi *vsi)\n{\n\tstruct i40e_fdir_filter *filter;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct hlist_node *node;\n\n\tif (!(pf->flags & I40E_FLAG_FD_SB_ENABLED))\n\t\treturn;\n\n\t/* Reset FDir counters as we're replaying all existing filters */\n\tpf->fd_tcp4_filter_cnt = 0;\n\tpf->fd_udp4_filter_cnt = 0;\n\tpf->fd_sctp4_filter_cnt = 0;\n\tpf->fd_ip4_filter_cnt = 0;\n\n\thlist_for_each_entry_safe(filter, node,\n\t\t\t\t  &pf->fdir_filter_list, fdir_node) {\n\t\ti40e_add_del_fdir(vsi, filter, true);\n\t}\n}\n\n/**\n * i40e_vsi_configure - Set up the VSI for action\n * @vsi: the VSI being configured\n **/\nstatic int i40e_vsi_configure(struct i40e_vsi *vsi)\n{\n\tint err;\n\n\ti40e_set_vsi_rx_mode(vsi);\n\ti40e_restore_vlan(vsi);\n\ti40e_vsi_config_dcb_rings(vsi);\n\terr = i40e_vsi_configure_tx(vsi);\n\tif (!err)\n\t\terr = i40e_vsi_configure_rx(vsi);\n\n\treturn err;\n}\n\n/**\n * i40e_vsi_configure_msix - MSIX mode Interrupt Config in the HW\n * @vsi: the VSI being configured\n **/\nstatic void i40e_vsi_configure_msix(struct i40e_vsi *vsi)\n{\n\tbool has_xdp = i40e_enabled_xdp_vsi(vsi);\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 vector;\n\tint i, q;\n\tu32 qp;\n\n\t/* The interrupt indexing is offset by 1 in the PFINT_ITRn\n\t * and PFINT_LNKLSTn registers, e.g.:\n\t *   PFINT_ITRn[0..n-1] gets msix-1..msix-n  (qpair interrupts)\n\t */\n\tqp = vsi->base_queue;\n\tvector = vsi->base_vector;\n\tfor (i = 0; i < vsi->num_q_vectors; i++, vector++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[i];\n\n\t\tq_vector->rx.next_update = jiffies + 1;\n\t\tq_vector->rx.target_itr =\n\t\t\tITR_TO_REG(vsi->rx_rings[i]->itr_setting);\n\t\twr32(hw, I40E_PFINT_ITRN(I40E_RX_ITR, vector - 1),\n\t\t     q_vector->rx.target_itr >> 1);\n\t\tq_vector->rx.current_itr = q_vector->rx.target_itr;\n\n\t\tq_vector->tx.next_update = jiffies + 1;\n\t\tq_vector->tx.target_itr =\n\t\t\tITR_TO_REG(vsi->tx_rings[i]->itr_setting);\n\t\twr32(hw, I40E_PFINT_ITRN(I40E_TX_ITR, vector - 1),\n\t\t     q_vector->tx.target_itr >> 1);\n\t\tq_vector->tx.current_itr = q_vector->tx.target_itr;\n\n\t\twr32(hw, I40E_PFINT_RATEN(vector - 1),\n\t\t     i40e_intrl_usec_to_reg(vsi->int_rate_limit));\n\n\t\t/* Linked list for the queuepairs assigned to this vector */\n\t\twr32(hw, I40E_PFINT_LNKLSTN(vector - 1), qp);\n\t\tfor (q = 0; q < q_vector->num_ringpairs; q++) {\n\t\t\tu32 nextqp = has_xdp ? qp + vsi->alloc_queue_pairs : qp;\n\t\t\tu32 val;\n\n\t\t\tval = I40E_QINT_RQCTL_CAUSE_ENA_MASK |\n\t\t\t      (I40E_RX_ITR << I40E_QINT_RQCTL_ITR_INDX_SHIFT) |\n\t\t\t      (vector << I40E_QINT_RQCTL_MSIX_INDX_SHIFT) |\n\t\t\t      (nextqp << I40E_QINT_RQCTL_NEXTQ_INDX_SHIFT) |\n\t\t\t      (I40E_QUEUE_TYPE_TX <<\n\t\t\t       I40E_QINT_RQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\t\twr32(hw, I40E_QINT_RQCTL(qp), val);\n\n\t\t\tif (has_xdp) {\n\t\t\t\tval = I40E_QINT_TQCTL_CAUSE_ENA_MASK |\n\t\t\t\t      (I40E_TX_ITR << I40E_QINT_TQCTL_ITR_INDX_SHIFT) |\n\t\t\t\t      (vector << I40E_QINT_TQCTL_MSIX_INDX_SHIFT) |\n\t\t\t\t      (qp << I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT) |\n\t\t\t\t      (I40E_QUEUE_TYPE_TX <<\n\t\t\t\t       I40E_QINT_TQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\t\t\twr32(hw, I40E_QINT_TQCTL(nextqp), val);\n\t\t\t}\n\n\t\t\tval = I40E_QINT_TQCTL_CAUSE_ENA_MASK |\n\t\t\t      (I40E_TX_ITR << I40E_QINT_TQCTL_ITR_INDX_SHIFT) |\n\t\t\t      (vector << I40E_QINT_TQCTL_MSIX_INDX_SHIFT) |\n\t\t\t      ((qp + 1) << I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT) |\n\t\t\t      (I40E_QUEUE_TYPE_RX <<\n\t\t\t       I40E_QINT_TQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\t\t/* Terminate the linked list */\n\t\t\tif (q == (q_vector->num_ringpairs - 1))\n\t\t\t\tval |= (I40E_QUEUE_END_OF_LIST <<\n\t\t\t\t\tI40E_QINT_TQCTL_NEXTQ_INDX_SHIFT);\n\n\t\t\twr32(hw, I40E_QINT_TQCTL(qp), val);\n\t\t\tqp++;\n\t\t}\n\t}\n\n\ti40e_flush(hw);\n}\n\n/**\n * i40e_enable_misc_int_causes - enable the non-queue interrupts\n * @pf: pointer to private device data structure\n **/\nstatic void i40e_enable_misc_int_causes(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\n\t/* clear things first */\n\twr32(hw, I40E_PFINT_ICR0_ENA, 0);  /* disable all */\n\trd32(hw, I40E_PFINT_ICR0);         /* read to clear */\n\n\tval = I40E_PFINT_ICR0_ENA_ECC_ERR_MASK       |\n\t      I40E_PFINT_ICR0_ENA_MAL_DETECT_MASK    |\n\t      I40E_PFINT_ICR0_ENA_GRST_MASK          |\n\t      I40E_PFINT_ICR0_ENA_PCI_EXCEPTION_MASK |\n\t      I40E_PFINT_ICR0_ENA_GPIO_MASK          |\n\t      I40E_PFINT_ICR0_ENA_HMC_ERR_MASK       |\n\t      I40E_PFINT_ICR0_ENA_VFLR_MASK          |\n\t      I40E_PFINT_ICR0_ENA_ADMINQ_MASK;\n\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED)\n\t\tval |= I40E_PFINT_ICR0_ENA_PE_CRITERR_MASK;\n\n\tif (pf->flags & I40E_FLAG_PTP)\n\t\tval |= I40E_PFINT_ICR0_ENA_TIMESYNC_MASK;\n\n\twr32(hw, I40E_PFINT_ICR0_ENA, val);\n\n\t/* SW_ITR_IDX = 0, but don't change INTENA */\n\twr32(hw, I40E_PFINT_DYN_CTL0, I40E_PFINT_DYN_CTL0_SW_ITR_INDX_MASK |\n\t\t\t\t\tI40E_PFINT_DYN_CTL0_INTENA_MSK_MASK);\n\n\t/* OTHER_ITR_IDX = 0 */\n\twr32(hw, I40E_PFINT_STAT_CTL0, 0);\n}\n\n/**\n * i40e_configure_msi_and_legacy - Legacy mode interrupt config in the HW\n * @vsi: the VSI being configured\n **/\nstatic void i40e_configure_msi_and_legacy(struct i40e_vsi *vsi)\n{\n\tu32 nextqp = i40e_enabled_xdp_vsi(vsi) ? vsi->alloc_queue_pairs : 0;\n\tstruct i40e_q_vector *q_vector = vsi->q_vectors[0];\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\n\t/* set the ITR configuration */\n\tq_vector->rx.next_update = jiffies + 1;\n\tq_vector->rx.target_itr = ITR_TO_REG(vsi->rx_rings[0]->itr_setting);\n\twr32(hw, I40E_PFINT_ITR0(I40E_RX_ITR), q_vector->rx.target_itr >> 1);\n\tq_vector->rx.current_itr = q_vector->rx.target_itr;\n\tq_vector->tx.next_update = jiffies + 1;\n\tq_vector->tx.target_itr = ITR_TO_REG(vsi->tx_rings[0]->itr_setting);\n\twr32(hw, I40E_PFINT_ITR0(I40E_TX_ITR), q_vector->tx.target_itr >> 1);\n\tq_vector->tx.current_itr = q_vector->tx.target_itr;\n\n\ti40e_enable_misc_int_causes(pf);\n\n\t/* FIRSTQ_INDX = 0, FIRSTQ_TYPE = 0 (rx) */\n\twr32(hw, I40E_PFINT_LNKLST0, 0);\n\n\t/* Associate the queue pair to the vector and enable the queue int */\n\tval = I40E_QINT_RQCTL_CAUSE_ENA_MASK\t\t       |\n\t      (I40E_RX_ITR << I40E_QINT_RQCTL_ITR_INDX_SHIFT)  |\n\t      (nextqp\t   << I40E_QINT_RQCTL_NEXTQ_INDX_SHIFT)|\n\t      (I40E_QUEUE_TYPE_TX << I40E_QINT_TQCTL_NEXTQ_TYPE_SHIFT);\n\n\twr32(hw, I40E_QINT_RQCTL(0), val);\n\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tval = I40E_QINT_TQCTL_CAUSE_ENA_MASK\t\t     |\n\t\t      (I40E_TX_ITR << I40E_QINT_TQCTL_ITR_INDX_SHIFT)|\n\t\t      (I40E_QUEUE_TYPE_TX\n\t\t       << I40E_QINT_TQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\twr32(hw, I40E_QINT_TQCTL(nextqp), val);\n\t}\n\n\tval = I40E_QINT_TQCTL_CAUSE_ENA_MASK\t\t      |\n\t      (I40E_TX_ITR << I40E_QINT_TQCTL_ITR_INDX_SHIFT) |\n\t      (I40E_QUEUE_END_OF_LIST << I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT);\n\n\twr32(hw, I40E_QINT_TQCTL(0), val);\n\ti40e_flush(hw);\n}\n\n/**\n * i40e_irq_dynamic_disable_icr0 - Disable default interrupt generation for icr0\n * @pf: board private structure\n **/\nvoid i40e_irq_dynamic_disable_icr0(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\n\twr32(hw, I40E_PFINT_DYN_CTL0,\n\t     I40E_ITR_NONE << I40E_PFINT_DYN_CTLN_ITR_INDX_SHIFT);\n\ti40e_flush(hw);\n}\n\n/**\n * i40e_irq_dynamic_enable_icr0 - Enable default interrupt generation for icr0\n * @pf: board private structure\n **/\nvoid i40e_irq_dynamic_enable_icr0(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\n\tval = I40E_PFINT_DYN_CTL0_INTENA_MASK   |\n\t      I40E_PFINT_DYN_CTL0_CLEARPBA_MASK |\n\t      (I40E_ITR_NONE << I40E_PFINT_DYN_CTL0_ITR_INDX_SHIFT);\n\n\twr32(hw, I40E_PFINT_DYN_CTL0, val);\n\ti40e_flush(hw);\n}\n\n/**\n * i40e_msix_clean_rings - MSIX mode Interrupt Handler\n * @irq: interrupt number\n * @data: pointer to a q_vector\n **/\nstatic irqreturn_t i40e_msix_clean_rings(int irq, void *data)\n{\n\tstruct i40e_q_vector *q_vector = data;\n\n\tif (!q_vector->tx.ring && !q_vector->rx.ring)\n\t\treturn IRQ_HANDLED;\n\n\tnapi_schedule_irqoff(&q_vector->napi);\n\n\treturn IRQ_HANDLED;\n}\n\n/**\n * i40e_irq_affinity_notify - Callback for affinity changes\n * @notify: context as to what irq was changed\n * @mask: the new affinity mask\n *\n * This is a callback function used by the irq_set_affinity_notifier function\n * so that we may register to receive changes to the irq affinity masks.\n **/\nstatic void i40e_irq_affinity_notify(struct irq_affinity_notify *notify,\n\t\t\t\t     const cpumask_t *mask)\n{\n\tstruct i40e_q_vector *q_vector =\n\t\tcontainer_of(notify, struct i40e_q_vector, affinity_notify);\n\n\tcpumask_copy(&q_vector->affinity_mask, mask);\n}\n\n/**\n * i40e_irq_affinity_release - Callback for affinity notifier release\n * @ref: internal core kernel usage\n *\n * This is a callback function used by the irq_set_affinity_notifier function\n * to inform the current notification subscriber that they will no longer\n * receive notifications.\n **/\nstatic void i40e_irq_affinity_release(struct kref *ref) {}\n\n/**\n * i40e_vsi_request_irq_msix - Initialize MSI-X interrupts\n * @vsi: the VSI being configured\n * @basename: name for the vector\n *\n * Allocates MSI-X vectors and requests interrupts from the kernel.\n **/\nstatic int i40e_vsi_request_irq_msix(struct i40e_vsi *vsi, char *basename)\n{\n\tint q_vectors = vsi->num_q_vectors;\n\tstruct i40e_pf *pf = vsi->back;\n\tint base = vsi->base_vector;\n\tint rx_int_idx = 0;\n\tint tx_int_idx = 0;\n\tint vector, err;\n\tint irq_num;\n\tint cpu;\n\n\tfor (vector = 0; vector < q_vectors; vector++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[vector];\n\n\t\tirq_num = pf->msix_entries[base + vector].vector;\n\n\t\tif (q_vector->tx.ring && q_vector->rx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name) - 1,\n\t\t\t\t \"%s-%s-%d\", basename, \"TxRx\", rx_int_idx++);\n\t\t\ttx_int_idx++;\n\t\t} else if (q_vector->rx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name) - 1,\n\t\t\t\t \"%s-%s-%d\", basename, \"rx\", rx_int_idx++);\n\t\t} else if (q_vector->tx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name) - 1,\n\t\t\t\t \"%s-%s-%d\", basename, \"tx\", tx_int_idx++);\n\t\t} else {\n\t\t\t/* skip this unused q_vector */\n\t\t\tcontinue;\n\t\t}\n\t\terr = request_irq(irq_num,\n\t\t\t\t  vsi->irq_handler,\n\t\t\t\t  0,\n\t\t\t\t  q_vector->name,\n\t\t\t\t  q_vector);\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"MSIX request_irq failed, error: %d\\n\", err);\n\t\t\tgoto free_queue_irqs;\n\t\t}\n\n\t\t/* register for affinity change notifications */\n\t\tq_vector->affinity_notify.notify = i40e_irq_affinity_notify;\n\t\tq_vector->affinity_notify.release = i40e_irq_affinity_release;\n\t\tirq_set_affinity_notifier(irq_num, &q_vector->affinity_notify);\n\t\t/* Spread affinity hints out across online CPUs.\n\t\t *\n\t\t * get_cpu_mask returns a static constant mask with\n\t\t * a permanent lifetime so it's ok to pass to\n\t\t * irq_set_affinity_hint without making a copy.\n\t\t */\n\t\tcpu = cpumask_local_spread(q_vector->v_idx, -1);\n\t\tirq_set_affinity_hint(irq_num, get_cpu_mask(cpu));\n\t}\n\n\tvsi->irqs_ready = true;\n\treturn 0;\n\nfree_queue_irqs:\n\twhile (vector) {\n\t\tvector--;\n\t\tirq_num = pf->msix_entries[base + vector].vector;\n\t\tirq_set_affinity_notifier(irq_num, NULL);\n\t\tirq_set_affinity_hint(irq_num, NULL);\n\t\tfree_irq(irq_num, &vsi->q_vectors[vector]);\n\t}\n\treturn err;\n}\n\n/**\n * i40e_vsi_disable_irq - Mask off queue interrupt generation on the VSI\n * @vsi: the VSI being un-configured\n **/\nstatic void i40e_vsi_disable_irq(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint base = vsi->base_vector;\n\tint i;\n\n\t/* disable interrupt causation from each queue */\n\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\tu32 val;\n\n\t\tval = rd32(hw, I40E_QINT_TQCTL(vsi->tx_rings[i]->reg_idx));\n\t\tval &= ~I40E_QINT_TQCTL_CAUSE_ENA_MASK;\n\t\twr32(hw, I40E_QINT_TQCTL(vsi->tx_rings[i]->reg_idx), val);\n\n\t\tval = rd32(hw, I40E_QINT_RQCTL(vsi->rx_rings[i]->reg_idx));\n\t\tval &= ~I40E_QINT_RQCTL_CAUSE_ENA_MASK;\n\t\twr32(hw, I40E_QINT_RQCTL(vsi->rx_rings[i]->reg_idx), val);\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tcontinue;\n\t\twr32(hw, I40E_QINT_TQCTL(vsi->xdp_rings[i]->reg_idx), 0);\n\t}\n\n\t/* disable each interrupt */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tfor (i = vsi->base_vector;\n\t\t     i < (vsi->num_q_vectors + vsi->base_vector); i++)\n\t\t\twr32(hw, I40E_PFINT_DYN_CTLN(i - 1), 0);\n\n\t\ti40e_flush(hw);\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++)\n\t\t\tsynchronize_irq(pf->msix_entries[i + base].vector);\n\t} else {\n\t\t/* Legacy and MSI mode - this stops all interrupt handling */\n\t\twr32(hw, I40E_PFINT_ICR0_ENA, 0);\n\t\twr32(hw, I40E_PFINT_DYN_CTL0, 0);\n\t\ti40e_flush(hw);\n\t\tsynchronize_irq(pf->pdev->irq);\n\t}\n}\n\n/**\n * i40e_vsi_enable_irq - Enable IRQ for the given VSI\n * @vsi: the VSI being configured\n **/\nstatic int i40e_vsi_enable_irq(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++)\n\t\t\ti40e_irq_dynamic_enable(vsi, i);\n\t} else {\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\t}\n\n\ti40e_flush(&pf->hw);\n\treturn 0;\n}\n\n/**\n * i40e_free_misc_vector - Free the vector that handles non-queue events\n * @pf: board private structure\n **/\nstatic void i40e_free_misc_vector(struct i40e_pf *pf)\n{\n\t/* Disable ICR 0 */\n\twr32(&pf->hw, I40E_PFINT_ICR0_ENA, 0);\n\ti40e_flush(&pf->hw);\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED && pf->msix_entries) {\n\t\tsynchronize_irq(pf->msix_entries[0].vector);\n\t\tfree_irq(pf->msix_entries[0].vector, pf);\n\t\tclear_bit(__I40E_MISC_IRQ_REQUESTED, pf->state);\n\t}\n}\n\n/**\n * i40e_intr - MSI/Legacy and non-queue interrupt handler\n * @irq: interrupt number\n * @data: pointer to a q_vector\n *\n * This is the handler used for all MSI/Legacy interrupts, and deals\n * with both queue and non-queue interrupts.  This is also used in\n * MSIX mode to handle the non-queue interrupts.\n **/\nstatic irqreturn_t i40e_intr(int irq, void *data)\n{\n\tstruct i40e_pf *pf = (struct i40e_pf *)data;\n\tstruct i40e_hw *hw = &pf->hw;\n\tirqreturn_t ret = IRQ_NONE;\n\tu32 icr0, icr0_remaining;\n\tu32 val, ena_mask;\n\n\ticr0 = rd32(hw, I40E_PFINT_ICR0);\n\tena_mask = rd32(hw, I40E_PFINT_ICR0_ENA);\n\n\t/* if sharing a legacy IRQ, we might get called w/o an intr pending */\n\tif ((icr0 & I40E_PFINT_ICR0_INTEVENT_MASK) == 0)\n\t\tgoto enable_intr;\n\n\t/* if interrupt but no bits showing, must be SWINT */\n\tif (((icr0 & ~I40E_PFINT_ICR0_INTEVENT_MASK) == 0) ||\n\t    (icr0 & I40E_PFINT_ICR0_SWINT_MASK))\n\t\tpf->sw_int_count++;\n\n\tif ((pf->flags & I40E_FLAG_IWARP_ENABLED) &&\n\t    (icr0 & I40E_PFINT_ICR0_ENA_PE_CRITERR_MASK)) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_PE_CRITERR_MASK;\n\t\tdev_dbg(&pf->pdev->dev, \"cleared PE_CRITERR\\n\");\n\t\tset_bit(__I40E_CORE_RESET_REQUESTED, pf->state);\n\t}\n\n\t/* only q0 is used in MSI/Legacy mode, and none are used in MSIX */\n\tif (icr0 & I40E_PFINT_ICR0_QUEUE_0_MASK) {\n\t\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[0];\n\n\t\t/* We do not have a way to disarm Queue causes while leaving\n\t\t * interrupt enabled for all other causes, ideally\n\t\t * interrupt should be disabled while we are in NAPI but\n\t\t * this is not a performance path and napi_schedule()\n\t\t * can deal with rescheduling.\n\t\t */\n\t\tif (!test_bit(__I40E_DOWN, pf->state))\n\t\t\tnapi_schedule_irqoff(&q_vector->napi);\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_ADMINQ_MASK) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_ADMINQ_MASK;\n\t\tset_bit(__I40E_ADMINQ_EVENT_PENDING, pf->state);\n\t\ti40e_debug(&pf->hw, I40E_DEBUG_NVM, \"AdminQ event\\n\");\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_MAL_DETECT_MASK) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_MAL_DETECT_MASK;\n\t\tset_bit(__I40E_MDD_EVENT_PENDING, pf->state);\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_VFLR_MASK) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_VFLR_MASK;\n\t\tset_bit(__I40E_VFLR_EVENT_PENDING, pf->state);\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_GRST_MASK) {\n\t\tif (!test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\t\tset_bit(__I40E_RESET_INTR_RECEIVED, pf->state);\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_GRST_MASK;\n\t\tval = rd32(hw, I40E_GLGEN_RSTAT);\n\t\tval = (val & I40E_GLGEN_RSTAT_RESET_TYPE_MASK)\n\t\t       >> I40E_GLGEN_RSTAT_RESET_TYPE_SHIFT;\n\t\tif (val == I40E_RESET_CORER) {\n\t\t\tpf->corer_count++;\n\t\t} else if (val == I40E_RESET_GLOBR) {\n\t\t\tpf->globr_count++;\n\t\t} else if (val == I40E_RESET_EMPR) {\n\t\t\tpf->empr_count++;\n\t\t\tset_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state);\n\t\t}\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_HMC_ERR_MASK) {\n\t\ticr0 &= ~I40E_PFINT_ICR0_HMC_ERR_MASK;\n\t\tdev_info(&pf->pdev->dev, \"HMC error interrupt\\n\");\n\t\tdev_info(&pf->pdev->dev, \"HMC error info 0x%x, HMC error data 0x%x\\n\",\n\t\t\t rd32(hw, I40E_PFHMC_ERRORINFO),\n\t\t\t rd32(hw, I40E_PFHMC_ERRORDATA));\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_TIMESYNC_MASK) {\n\t\tu32 prttsyn_stat = rd32(hw, I40E_PRTTSYN_STAT_0);\n\n\t\tif (prttsyn_stat & I40E_PRTTSYN_STAT_0_TXTIME_MASK) {\n\t\t\ticr0 &= ~I40E_PFINT_ICR0_ENA_TIMESYNC_MASK;\n\t\t\ti40e_ptp_tx_hwtstamp(pf);\n\t\t}\n\t}\n\n\t/* If a critical error is pending we have no choice but to reset the\n\t * device.\n\t * Report and mask out any remaining unexpected interrupts.\n\t */\n\ticr0_remaining = icr0 & ena_mask;\n\tif (icr0_remaining) {\n\t\tdev_info(&pf->pdev->dev, \"unhandled interrupt icr0=0x%08x\\n\",\n\t\t\t icr0_remaining);\n\t\tif ((icr0_remaining & I40E_PFINT_ICR0_PE_CRITERR_MASK) ||\n\t\t    (icr0_remaining & I40E_PFINT_ICR0_PCI_EXCEPTION_MASK) ||\n\t\t    (icr0_remaining & I40E_PFINT_ICR0_ECC_ERR_MASK)) {\n\t\t\tdev_info(&pf->pdev->dev, \"device will be reset\\n\");\n\t\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\t\ti40e_service_event_schedule(pf);\n\t\t}\n\t\tena_mask &= ~icr0_remaining;\n\t}\n\tret = IRQ_HANDLED;\n\nenable_intr:\n\t/* re-enable interrupt causes */\n\twr32(hw, I40E_PFINT_ICR0_ENA, ena_mask);\n\tif (!test_bit(__I40E_DOWN, pf->state) ||\n\t    test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\ti40e_service_event_schedule(pf);\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_clean_fdir_tx_irq - Reclaim resources after transmit completes\n * @tx_ring:  tx ring to clean\n * @budget:   how many cleans we're allowed\n *\n * Returns true if there's any budget left (e.g. the clean is finished)\n **/\nstatic bool i40e_clean_fdir_tx_irq(struct i40e_ring *tx_ring, int budget)\n{\n\tstruct i40e_vsi *vsi = tx_ring->vsi;\n\tu16 i = tx_ring->next_to_clean;\n\tstruct i40e_tx_buffer *tx_buf;\n\tstruct i40e_tx_desc *tx_desc;\n\n\ttx_buf = &tx_ring->tx_bi[i];\n\ttx_desc = I40E_TX_DESC(tx_ring, i);\n\ti -= tx_ring->count;\n\n\tdo {\n\t\tstruct i40e_tx_desc *eop_desc = tx_buf->next_to_watch;\n\n\t\t/* if next_to_watch is not set then there is no work pending */\n\t\tif (!eop_desc)\n\t\t\tbreak;\n\n\t\t/* prevent any other reads prior to eop_desc */\n\t\tsmp_rmb();\n\n\t\t/* if the descriptor isn't done, no work yet to do */\n\t\tif (!(eop_desc->cmd_type_offset_bsz &\n\t\t      cpu_to_le64(I40E_TX_DESC_DTYPE_DESC_DONE)))\n\t\t\tbreak;\n\n\t\t/* clear next_to_watch to prevent false hangs */\n\t\ttx_buf->next_to_watch = NULL;\n\n\t\ttx_desc->buffer_addr = 0;\n\t\ttx_desc->cmd_type_offset_bsz = 0;\n\t\t/* move past filter desc */\n\t\ttx_buf++;\n\t\ttx_desc++;\n\t\ti++;\n\t\tif (unlikely(!i)) {\n\t\t\ti -= tx_ring->count;\n\t\t\ttx_buf = tx_ring->tx_bi;\n\t\t\ttx_desc = I40E_TX_DESC(tx_ring, 0);\n\t\t}\n\t\t/* unmap skb header data */\n\t\tdma_unmap_single(tx_ring->dev,\n\t\t\t\t dma_unmap_addr(tx_buf, dma),\n\t\t\t\t dma_unmap_len(tx_buf, len),\n\t\t\t\t DMA_TO_DEVICE);\n\t\tif (tx_buf->tx_flags & I40E_TX_FLAGS_FD_SB)\n\t\t\tkfree(tx_buf->raw_buf);\n\n\t\ttx_buf->raw_buf = NULL;\n\t\ttx_buf->tx_flags = 0;\n\t\ttx_buf->next_to_watch = NULL;\n\t\tdma_unmap_len_set(tx_buf, len, 0);\n\t\ttx_desc->buffer_addr = 0;\n\t\ttx_desc->cmd_type_offset_bsz = 0;\n\n\t\t/* move us past the eop_desc for start of next FD desc */\n\t\ttx_buf++;\n\t\ttx_desc++;\n\t\ti++;\n\t\tif (unlikely(!i)) {\n\t\t\ti -= tx_ring->count;\n\t\t\ttx_buf = tx_ring->tx_bi;\n\t\t\ttx_desc = I40E_TX_DESC(tx_ring, 0);\n\t\t}\n\n\t\t/* update budget accounting */\n\t\tbudget--;\n\t} while (likely(budget));\n\n\ti += tx_ring->count;\n\ttx_ring->next_to_clean = i;\n\n\tif (vsi->back->flags & I40E_FLAG_MSIX_ENABLED)\n\t\ti40e_irq_dynamic_enable(vsi, tx_ring->q_vector->v_idx);\n\n\treturn budget > 0;\n}\n\n/**\n * i40e_fdir_clean_ring - Interrupt Handler for FDIR SB ring\n * @irq: interrupt number\n * @data: pointer to a q_vector\n **/\nstatic irqreturn_t i40e_fdir_clean_ring(int irq, void *data)\n{\n\tstruct i40e_q_vector *q_vector = data;\n\tstruct i40e_vsi *vsi;\n\n\tif (!q_vector->tx.ring)\n\t\treturn IRQ_HANDLED;\n\n\tvsi = q_vector->tx.ring->vsi;\n\ti40e_clean_fdir_tx_irq(q_vector->tx.ring, vsi->work_limit);\n\n\treturn IRQ_HANDLED;\n}\n\n/**\n * i40e_map_vector_to_qp - Assigns the queue pair to the vector\n * @vsi: the VSI being configured\n * @v_idx: vector index\n * @qp_idx: queue pair index\n **/\nstatic void i40e_map_vector_to_qp(struct i40e_vsi *vsi, int v_idx, int qp_idx)\n{\n\tstruct i40e_q_vector *q_vector = vsi->q_vectors[v_idx];\n\tstruct i40e_ring *tx_ring = vsi->tx_rings[qp_idx];\n\tstruct i40e_ring *rx_ring = vsi->rx_rings[qp_idx];\n\n\ttx_ring->q_vector = q_vector;\n\ttx_ring->next = q_vector->tx.ring;\n\tq_vector->tx.ring = tx_ring;\n\tq_vector->tx.count++;\n\n\t/* Place XDP Tx ring in the same q_vector ring list as regular Tx */\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tstruct i40e_ring *xdp_ring = vsi->xdp_rings[qp_idx];\n\n\t\txdp_ring->q_vector = q_vector;\n\t\txdp_ring->next = q_vector->tx.ring;\n\t\tq_vector->tx.ring = xdp_ring;\n\t\tq_vector->tx.count++;\n\t}\n\n\trx_ring->q_vector = q_vector;\n\trx_ring->next = q_vector->rx.ring;\n\tq_vector->rx.ring = rx_ring;\n\tq_vector->rx.count++;\n}\n\n/**\n * i40e_vsi_map_rings_to_vectors - Maps descriptor rings to vectors\n * @vsi: the VSI being configured\n *\n * This function maps descriptor rings to the queue-specific vectors\n * we were allotted through the MSI-X enabling code.  Ideally, we'd have\n * one vector per queue pair, but on a constrained vector budget, we\n * group the queue pairs as \"efficiently\" as possible.\n **/\nstatic void i40e_vsi_map_rings_to_vectors(struct i40e_vsi *vsi)\n{\n\tint qp_remaining = vsi->num_queue_pairs;\n\tint q_vectors = vsi->num_q_vectors;\n\tint num_ringpairs;\n\tint v_start = 0;\n\tint qp_idx = 0;\n\n\t/* If we don't have enough vectors for a 1-to-1 mapping, we'll have to\n\t * group them so there are multiple queues per vector.\n\t * It is also important to go through all the vectors available to be\n\t * sure that if we don't use all the vectors, that the remaining vectors\n\t * are cleared. This is especially important when decreasing the\n\t * number of queues in use.\n\t */\n\tfor (; v_start < q_vectors; v_start++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[v_start];\n\n\t\tnum_ringpairs = DIV_ROUND_UP(qp_remaining, q_vectors - v_start);\n\n\t\tq_vector->num_ringpairs = num_ringpairs;\n\t\tq_vector->reg_idx = q_vector->v_idx + vsi->base_vector - 1;\n\n\t\tq_vector->rx.count = 0;\n\t\tq_vector->tx.count = 0;\n\t\tq_vector->rx.ring = NULL;\n\t\tq_vector->tx.ring = NULL;\n\n\t\twhile (num_ringpairs--) {\n\t\t\ti40e_map_vector_to_qp(vsi, v_start, qp_idx);\n\t\t\tqp_idx++;\n\t\t\tqp_remaining--;\n\t\t}\n\t}\n}\n\n/**\n * i40e_vsi_request_irq - Request IRQ from the OS\n * @vsi: the VSI being configured\n * @basename: name for the vector\n **/\nstatic int i40e_vsi_request_irq(struct i40e_vsi *vsi, char *basename)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint err;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\terr = i40e_vsi_request_irq_msix(vsi, basename);\n\telse if (pf->flags & I40E_FLAG_MSI_ENABLED)\n\t\terr = request_irq(pf->pdev->irq, i40e_intr, 0,\n\t\t\t\t  pf->int_name, pf);\n\telse\n\t\terr = request_irq(pf->pdev->irq, i40e_intr, IRQF_SHARED,\n\t\t\t\t  pf->int_name, pf);\n\n\tif (err)\n\t\tdev_info(&pf->pdev->dev, \"request_irq failed, Error %d\\n\", err);\n\n\treturn err;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\n/**\n * i40e_netpoll - A Polling 'interrupt' handler\n * @netdev: network interface device structure\n *\n * This is used by netconsole to send skbs without having to re-enable\n * interrupts.  It's not called while the normal interrupt routine is executing.\n **/\nstatic void i40e_netpoll(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tint i;\n\n\t/* if interface is down do nothing */\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++)\n\t\t\ti40e_msix_clean_rings(0, vsi->q_vectors[i]);\n\t} else {\n\t\ti40e_intr(pf->pdev->irq, netdev);\n\t}\n}\n#endif\n\n#define I40E_QTX_ENA_WAIT_COUNT 50\n\n/**\n * i40e_pf_txq_wait - Wait for a PF's Tx queue to be enabled or disabled\n * @pf: the PF being configured\n * @pf_q: the PF queue\n * @enable: enable or disable state of the queue\n *\n * This routine will wait for the given Tx queue of the PF to reach the\n * enabled or disabled state.\n * Returns -ETIMEDOUT in case of failing to reach the requested state after\n * multiple retries; else will return 0 in case of success.\n **/\nstatic int i40e_pf_txq_wait(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tint i;\n\tu32 tx_reg;\n\n\tfor (i = 0; i < I40E_QUEUE_WAIT_RETRY_LIMIT; i++) {\n\t\ttx_reg = rd32(&pf->hw, I40E_QTX_ENA(pf_q));\n\t\tif (enable == !!(tx_reg & I40E_QTX_ENA_QENA_STAT_MASK))\n\t\t\tbreak;\n\n\t\tusleep_range(10, 20);\n\t}\n\tif (i >= I40E_QUEUE_WAIT_RETRY_LIMIT)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\n/**\n * i40e_control_tx_q - Start or stop a particular Tx queue\n * @pf: the PF structure\n * @pf_q: the PF queue to configure\n * @enable: start or stop the queue\n *\n * This function enables or disables a single queue. Note that any delay\n * required after the operation is expected to be handled by the caller of\n * this function.\n **/\nstatic void i40e_control_tx_q(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 tx_reg;\n\tint i;\n\n\t/* warn the TX unit of coming changes */\n\ti40e_pre_tx_queue_cfg(&pf->hw, pf_q, enable);\n\tif (!enable)\n\t\tusleep_range(10, 20);\n\n\tfor (i = 0; i < I40E_QTX_ENA_WAIT_COUNT; i++) {\n\t\ttx_reg = rd32(hw, I40E_QTX_ENA(pf_q));\n\t\tif (((tx_reg >> I40E_QTX_ENA_QENA_REQ_SHIFT) & 1) ==\n\t\t    ((tx_reg >> I40E_QTX_ENA_QENA_STAT_SHIFT) & 1))\n\t\t\tbreak;\n\t\tusleep_range(1000, 2000);\n\t}\n\n\t/* Skip if the queue is already in the requested state */\n\tif (enable == !!(tx_reg & I40E_QTX_ENA_QENA_STAT_MASK))\n\t\treturn;\n\n\t/* turn on/off the queue */\n\tif (enable) {\n\t\twr32(hw, I40E_QTX_HEAD(pf_q), 0);\n\t\ttx_reg |= I40E_QTX_ENA_QENA_REQ_MASK;\n\t} else {\n\t\ttx_reg &= ~I40E_QTX_ENA_QENA_REQ_MASK;\n\t}\n\n\twr32(hw, I40E_QTX_ENA(pf_q), tx_reg);\n}\n\n/**\n * i40e_control_wait_tx_q - Start/stop Tx queue and wait for completion\n * @seid: VSI SEID\n * @pf: the PF structure\n * @pf_q: the PF queue to configure\n * @is_xdp: true if the queue is used for XDP\n * @enable: start or stop the queue\n **/\nint i40e_control_wait_tx_q(int seid, struct i40e_pf *pf, int pf_q,\n\t\t\t   bool is_xdp, bool enable)\n{\n\tint ret;\n\n\ti40e_control_tx_q(pf, pf_q, enable);\n\n\t/* wait for the change to finish */\n\tret = i40e_pf_txq_wait(pf, pf_q, enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d %sTx ring %d %sable timeout\\n\",\n\t\t\t seid, (is_xdp ? \"XDP \" : \"\"), pf_q,\n\t\t\t (enable ? \"en\" : \"dis\"));\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_vsi_control_tx - Start or stop a VSI's rings\n * @vsi: the VSI being configured\n * @enable: start or stop the rings\n **/\nstatic int i40e_vsi_control_tx(struct i40e_vsi *vsi, bool enable)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q, ret = 0;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\tret = i40e_control_wait_tx_q(vsi->seid, pf,\n\t\t\t\t\t     pf_q,\n\t\t\t\t\t     false /*is xdp*/, enable);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tcontinue;\n\n\t\tret = i40e_control_wait_tx_q(vsi->seid, pf,\n\t\t\t\t\t     pf_q + vsi->alloc_queue_pairs,\n\t\t\t\t\t     true /*is xdp*/, enable);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\treturn ret;\n}\n\n/**\n * i40e_pf_rxq_wait - Wait for a PF's Rx queue to be enabled or disabled\n * @pf: the PF being configured\n * @pf_q: the PF queue\n * @enable: enable or disable state of the queue\n *\n * This routine will wait for the given Rx queue of the PF to reach the\n * enabled or disabled state.\n * Returns -ETIMEDOUT in case of failing to reach the requested state after\n * multiple retries; else will return 0 in case of success.\n **/\nstatic int i40e_pf_rxq_wait(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tint i;\n\tu32 rx_reg;\n\n\tfor (i = 0; i < I40E_QUEUE_WAIT_RETRY_LIMIT; i++) {\n\t\trx_reg = rd32(&pf->hw, I40E_QRX_ENA(pf_q));\n\t\tif (enable == !!(rx_reg & I40E_QRX_ENA_QENA_STAT_MASK))\n\t\t\tbreak;\n\n\t\tusleep_range(10, 20);\n\t}\n\tif (i >= I40E_QUEUE_WAIT_RETRY_LIMIT)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\n/**\n * i40e_control_rx_q - Start or stop a particular Rx queue\n * @pf: the PF structure\n * @pf_q: the PF queue to configure\n * @enable: start or stop the queue\n *\n * This function enables or disables a single queue. Note that\n * any delay required after the operation is expected to be\n * handled by the caller of this function.\n **/\nstatic void i40e_control_rx_q(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 rx_reg;\n\tint i;\n\n\tfor (i = 0; i < I40E_QTX_ENA_WAIT_COUNT; i++) {\n\t\trx_reg = rd32(hw, I40E_QRX_ENA(pf_q));\n\t\tif (((rx_reg >> I40E_QRX_ENA_QENA_REQ_SHIFT) & 1) ==\n\t\t    ((rx_reg >> I40E_QRX_ENA_QENA_STAT_SHIFT) & 1))\n\t\t\tbreak;\n\t\tusleep_range(1000, 2000);\n\t}\n\n\t/* Skip if the queue is already in the requested state */\n\tif (enable == !!(rx_reg & I40E_QRX_ENA_QENA_STAT_MASK))\n\t\treturn;\n\n\t/* turn on/off the queue */\n\tif (enable)\n\t\trx_reg |= I40E_QRX_ENA_QENA_REQ_MASK;\n\telse\n\t\trx_reg &= ~I40E_QRX_ENA_QENA_REQ_MASK;\n\n\twr32(hw, I40E_QRX_ENA(pf_q), rx_reg);\n}\n\n/**\n * i40e_control_wait_rx_q\n * @pf: the PF structure\n * @pf_q: queue being configured\n * @enable: start or stop the rings\n *\n * This function enables or disables a single queue along with waiting\n * for the change to finish. The caller of this function should handle\n * the delays needed in the case of disabling queues.\n **/\nint i40e_control_wait_rx_q(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tint ret = 0;\n\n\ti40e_control_rx_q(pf, pf_q, enable);\n\n\t/* wait for the change to finish */\n\tret = i40e_pf_rxq_wait(pf, pf_q, enable);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ret;\n}\n\n/**\n * i40e_vsi_control_rx - Start or stop a VSI's rings\n * @vsi: the VSI being configured\n * @enable: start or stop the rings\n **/\nstatic int i40e_vsi_control_rx(struct i40e_vsi *vsi, bool enable)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q, ret = 0;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\tret = i40e_control_wait_rx_q(pf, pf_q, enable);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d Rx ring %d %sable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Due to HW errata, on Rx disable only, the register can indicate done\n\t * before it really is. Needs 50ms to be sure\n\t */\n\tif (!enable)\n\t\tmdelay(50);\n\n\treturn ret;\n}\n\n/**\n * i40e_vsi_start_rings - Start a VSI's rings\n * @vsi: the VSI being configured\n **/\nint i40e_vsi_start_rings(struct i40e_vsi *vsi)\n{\n\tint ret = 0;\n\n\t/* do rx first for enable and last for disable */\n\tret = i40e_vsi_control_rx(vsi, true);\n\tif (ret)\n\t\treturn ret;\n\tret = i40e_vsi_control_tx(vsi, true);\n\n\treturn ret;\n}\n\n/**\n * i40e_vsi_stop_rings - Stop a VSI's rings\n * @vsi: the VSI being configured\n **/\nvoid i40e_vsi_stop_rings(struct i40e_vsi *vsi)\n{\n\t/* When port TX is suspended, don't wait */\n\tif (test_bit(__I40E_PORT_SUSPENDED, vsi->back->state))\n\t\treturn i40e_vsi_stop_rings_no_wait(vsi);\n\n\t/* do rx first for enable and last for disable\n\t * Ignore return value, we need to shutdown whatever we can\n\t */\n\ti40e_vsi_control_tx(vsi, false);\n\ti40e_vsi_control_rx(vsi, false);\n}\n\n/**\n * i40e_vsi_stop_rings_no_wait - Stop a VSI's rings and do not delay\n * @vsi: the VSI being shutdown\n *\n * This function stops all the rings for a VSI but does not delay to verify\n * that rings have been disabled. It is expected that the caller is shutting\n * down multiple VSIs at once and will delay together for all the VSIs after\n * initiating the shutdown. This is particularly useful for shutting down lots\n * of VFs together. Otherwise, a large delay can be incurred while configuring\n * each VSI in serial.\n **/\nvoid i40e_vsi_stop_rings_no_wait(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\ti40e_control_tx_q(pf, pf_q, false);\n\t\ti40e_control_rx_q(pf, pf_q, false);\n\t}\n}\n\n/**\n * i40e_vsi_free_irq - Free the irq association with the OS\n * @vsi: the VSI being configured\n **/\nstatic void i40e_vsi_free_irq(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint base = vsi->base_vector;\n\tu32 val, qp;\n\tint i;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tif (!vsi->q_vectors)\n\t\t\treturn;\n\n\t\tif (!vsi->irqs_ready)\n\t\t\treturn;\n\n\t\tvsi->irqs_ready = false;\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++) {\n\t\t\tint irq_num;\n\t\t\tu16 vector;\n\n\t\t\tvector = i + base;\n\t\t\tirq_num = pf->msix_entries[vector].vector;\n\n\t\t\t/* free only the irqs that were actually requested */\n\t\t\tif (!vsi->q_vectors[i] ||\n\t\t\t    !vsi->q_vectors[i]->num_ringpairs)\n\t\t\t\tcontinue;\n\n\t\t\t/* clear the affinity notifier in the IRQ descriptor */\n\t\t\tirq_set_affinity_notifier(irq_num, NULL);\n\t\t\t/* remove our suggested affinity mask for this IRQ */\n\t\t\tirq_set_affinity_hint(irq_num, NULL);\n\t\t\tsynchronize_irq(irq_num);\n\t\t\tfree_irq(irq_num, vsi->q_vectors[i]);\n\n\t\t\t/* Tear down the interrupt queue link list\n\t\t\t *\n\t\t\t * We know that they come in pairs and always\n\t\t\t * the Rx first, then the Tx.  To clear the\n\t\t\t * link list, stick the EOL value into the\n\t\t\t * next_q field of the registers.\n\t\t\t */\n\t\t\tval = rd32(hw, I40E_PFINT_LNKLSTN(vector - 1));\n\t\t\tqp = (val & I40E_PFINT_LNKLSTN_FIRSTQ_INDX_MASK)\n\t\t\t\t>> I40E_PFINT_LNKLSTN_FIRSTQ_INDX_SHIFT;\n\t\t\tval |= I40E_QUEUE_END_OF_LIST\n\t\t\t\t<< I40E_PFINT_LNKLSTN_FIRSTQ_INDX_SHIFT;\n\t\t\twr32(hw, I40E_PFINT_LNKLSTN(vector - 1), val);\n\n\t\t\twhile (qp != I40E_QUEUE_END_OF_LIST) {\n\t\t\t\tu32 next;\n\n\t\t\t\tval = rd32(hw, I40E_QINT_RQCTL(qp));\n\n\t\t\t\tval &= ~(I40E_QINT_RQCTL_MSIX_INDX_MASK  |\n\t\t\t\t\t I40E_QINT_RQCTL_MSIX0_INDX_MASK |\n\t\t\t\t\t I40E_QINT_RQCTL_CAUSE_ENA_MASK  |\n\t\t\t\t\t I40E_QINT_RQCTL_INTEVENT_MASK);\n\n\t\t\t\tval |= (I40E_QINT_RQCTL_ITR_INDX_MASK |\n\t\t\t\t\t I40E_QINT_RQCTL_NEXTQ_INDX_MASK);\n\n\t\t\t\twr32(hw, I40E_QINT_RQCTL(qp), val);\n\n\t\t\t\tval = rd32(hw, I40E_QINT_TQCTL(qp));\n\n\t\t\t\tnext = (val & I40E_QINT_TQCTL_NEXTQ_INDX_MASK)\n\t\t\t\t\t>> I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT;\n\n\t\t\t\tval &= ~(I40E_QINT_TQCTL_MSIX_INDX_MASK  |\n\t\t\t\t\t I40E_QINT_TQCTL_MSIX0_INDX_MASK |\n\t\t\t\t\t I40E_QINT_TQCTL_CAUSE_ENA_MASK  |\n\t\t\t\t\t I40E_QINT_TQCTL_INTEVENT_MASK);\n\n\t\t\t\tval |= (I40E_QINT_TQCTL_ITR_INDX_MASK |\n\t\t\t\t\t I40E_QINT_TQCTL_NEXTQ_INDX_MASK);\n\n\t\t\t\twr32(hw, I40E_QINT_TQCTL(qp), val);\n\t\t\t\tqp = next;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfree_irq(pf->pdev->irq, pf);\n\n\t\tval = rd32(hw, I40E_PFINT_LNKLST0);\n\t\tqp = (val & I40E_PFINT_LNKLSTN_FIRSTQ_INDX_MASK)\n\t\t\t>> I40E_PFINT_LNKLSTN_FIRSTQ_INDX_SHIFT;\n\t\tval |= I40E_QUEUE_END_OF_LIST\n\t\t\t<< I40E_PFINT_LNKLST0_FIRSTQ_INDX_SHIFT;\n\t\twr32(hw, I40E_PFINT_LNKLST0, val);\n\n\t\tval = rd32(hw, I40E_QINT_RQCTL(qp));\n\t\tval &= ~(I40E_QINT_RQCTL_MSIX_INDX_MASK  |\n\t\t\t I40E_QINT_RQCTL_MSIX0_INDX_MASK |\n\t\t\t I40E_QINT_RQCTL_CAUSE_ENA_MASK  |\n\t\t\t I40E_QINT_RQCTL_INTEVENT_MASK);\n\n\t\tval |= (I40E_QINT_RQCTL_ITR_INDX_MASK |\n\t\t\tI40E_QINT_RQCTL_NEXTQ_INDX_MASK);\n\n\t\twr32(hw, I40E_QINT_RQCTL(qp), val);\n\n\t\tval = rd32(hw, I40E_QINT_TQCTL(qp));\n\n\t\tval &= ~(I40E_QINT_TQCTL_MSIX_INDX_MASK  |\n\t\t\t I40E_QINT_TQCTL_MSIX0_INDX_MASK |\n\t\t\t I40E_QINT_TQCTL_CAUSE_ENA_MASK  |\n\t\t\t I40E_QINT_TQCTL_INTEVENT_MASK);\n\n\t\tval |= (I40E_QINT_TQCTL_ITR_INDX_MASK |\n\t\t\tI40E_QINT_TQCTL_NEXTQ_INDX_MASK);\n\n\t\twr32(hw, I40E_QINT_TQCTL(qp), val);\n\t}\n}\n\n/**\n * i40e_free_q_vector - Free memory allocated for specific interrupt vector\n * @vsi: the VSI being configured\n * @v_idx: Index of vector to be freed\n *\n * This function frees the memory allocated to the q_vector.  In addition if\n * NAPI is enabled it will delete any references to the NAPI struct prior\n * to freeing the q_vector.\n **/\nstatic void i40e_free_q_vector(struct i40e_vsi *vsi, int v_idx)\n{\n\tstruct i40e_q_vector *q_vector = vsi->q_vectors[v_idx];\n\tstruct i40e_ring *ring;\n\n\tif (!q_vector)\n\t\treturn;\n\n\t/* disassociate q_vector from rings */\n\ti40e_for_each_ring(ring, q_vector->tx)\n\t\tring->q_vector = NULL;\n\n\ti40e_for_each_ring(ring, q_vector->rx)\n\t\tring->q_vector = NULL;\n\n\t/* only VSI w/ an associated netdev is set up w/ NAPI */\n\tif (vsi->netdev)\n\t\tnetif_napi_del(&q_vector->napi);\n\n\tvsi->q_vectors[v_idx] = NULL;\n\n\tkfree_rcu(q_vector, rcu);\n}\n\n/**\n * i40e_vsi_free_q_vectors - Free memory allocated for interrupt vectors\n * @vsi: the VSI being un-configured\n *\n * This frees the memory allocated to the q_vectors and\n * deletes references to the NAPI struct.\n **/\nstatic void i40e_vsi_free_q_vectors(struct i40e_vsi *vsi)\n{\n\tint v_idx;\n\n\tfor (v_idx = 0; v_idx < vsi->num_q_vectors; v_idx++)\n\t\ti40e_free_q_vector(vsi, v_idx);\n}\n\n/**\n * i40e_reset_interrupt_capability - Disable interrupt setup in OS\n * @pf: board private structure\n **/\nstatic void i40e_reset_interrupt_capability(struct i40e_pf *pf)\n{\n\t/* If we're in Legacy mode, the interrupt was cleaned in vsi_close */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tpci_disable_msix(pf->pdev);\n\t\tkfree(pf->msix_entries);\n\t\tpf->msix_entries = NULL;\n\t\tkfree(pf->irq_pile);\n\t\tpf->irq_pile = NULL;\n\t} else if (pf->flags & I40E_FLAG_MSI_ENABLED) {\n\t\tpci_disable_msi(pf->pdev);\n\t}\n\tpf->flags &= ~(I40E_FLAG_MSIX_ENABLED | I40E_FLAG_MSI_ENABLED);\n}\n\n/**\n * i40e_clear_interrupt_scheme - Clear the current interrupt scheme settings\n * @pf: board private structure\n *\n * We go through and clear interrupt specific resources and reset the structure\n * to pre-load conditions\n **/\nstatic void i40e_clear_interrupt_scheme(struct i40e_pf *pf)\n{\n\tint i;\n\n\ti40e_free_misc_vector(pf);\n\n\ti40e_put_lump(pf->irq_pile, pf->iwarp_base_vector,\n\t\t      I40E_IWARP_IRQ_PILE_ID);\n\n\ti40e_put_lump(pf->irq_pile, 0, I40E_PILE_VALID_BIT-1);\n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i])\n\t\t\ti40e_vsi_free_q_vectors(pf->vsi[i]);\n\ti40e_reset_interrupt_capability(pf);\n}\n\n/**\n * i40e_napi_enable_all - Enable NAPI for all q_vectors in the VSI\n * @vsi: the VSI being configured\n **/\nstatic void i40e_napi_enable_all(struct i40e_vsi *vsi)\n{\n\tint q_idx;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\tfor (q_idx = 0; q_idx < vsi->num_q_vectors; q_idx++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[q_idx];\n\n\t\tif (q_vector->rx.ring || q_vector->tx.ring)\n\t\t\tnapi_enable(&q_vector->napi);\n\t}\n}\n\n/**\n * i40e_napi_disable_all - Disable NAPI for all q_vectors in the VSI\n * @vsi: the VSI being configured\n **/\nstatic void i40e_napi_disable_all(struct i40e_vsi *vsi)\n{\n\tint q_idx;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\tfor (q_idx = 0; q_idx < vsi->num_q_vectors; q_idx++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[q_idx];\n\n\t\tif (q_vector->rx.ring || q_vector->tx.ring)\n\t\t\tnapi_disable(&q_vector->napi);\n\t}\n}\n\n/**\n * i40e_vsi_close - Shut down a VSI\n * @vsi: the vsi to be quelled\n **/\nstatic void i40e_vsi_close(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tif (!test_and_set_bit(__I40E_VSI_DOWN, vsi->state))\n\t\ti40e_down(vsi);\n\ti40e_vsi_free_irq(vsi);\n\ti40e_vsi_free_tx_resources(vsi);\n\ti40e_vsi_free_rx_resources(vsi);\n\tvsi->current_netdev_flags = 0;\n\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\tif (test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\tset_bit(__I40E_CLIENT_RESET, pf->state);\n}\n\n/**\n * i40e_quiesce_vsi - Pause a given VSI\n * @vsi: the VSI being paused\n **/\nstatic void i40e_quiesce_vsi(struct i40e_vsi *vsi)\n{\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tset_bit(__I40E_VSI_NEEDS_RESTART, vsi->state);\n\tif (vsi->netdev && netif_running(vsi->netdev))\n\t\tvsi->netdev->netdev_ops->ndo_stop(vsi->netdev);\n\telse\n\t\ti40e_vsi_close(vsi);\n}\n\n/**\n * i40e_unquiesce_vsi - Resume a given VSI\n * @vsi: the VSI being resumed\n **/\nstatic void i40e_unquiesce_vsi(struct i40e_vsi *vsi)\n{\n\tif (!test_and_clear_bit(__I40E_VSI_NEEDS_RESTART, vsi->state))\n\t\treturn;\n\n\tif (vsi->netdev && netif_running(vsi->netdev))\n\t\tvsi->netdev->netdev_ops->ndo_open(vsi->netdev);\n\telse\n\t\ti40e_vsi_open(vsi);   /* this clears the DOWN bit */\n}\n\n/**\n * i40e_pf_quiesce_all_vsi - Pause all VSIs on a PF\n * @pf: the PF\n **/\nstatic void i40e_pf_quiesce_all_vsi(struct i40e_pf *pf)\n{\n\tint v;\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v])\n\t\t\ti40e_quiesce_vsi(pf->vsi[v]);\n\t}\n}\n\n/**\n * i40e_pf_unquiesce_all_vsi - Resume all VSIs on a PF\n * @pf: the PF\n **/\nstatic void i40e_pf_unquiesce_all_vsi(struct i40e_pf *pf)\n{\n\tint v;\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v])\n\t\t\ti40e_unquiesce_vsi(pf->vsi[v]);\n\t}\n}\n\n/**\n * i40e_vsi_wait_queues_disabled - Wait for VSI's queues to be disabled\n * @vsi: the VSI being configured\n *\n * Wait until all queues on a given VSI have been disabled.\n **/\nint i40e_vsi_wait_queues_disabled(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q, ret;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\t/* Check and wait for the Tx queue */\n\t\tret = i40e_pf_txq_wait(pf, pf_q, false);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d Tx ring %d disable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tgoto wait_rx;\n\n\t\t/* Check and wait for the XDP Tx queue */\n\t\tret = i40e_pf_txq_wait(pf, pf_q + vsi->alloc_queue_pairs,\n\t\t\t\t       false);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d XDP Tx ring %d disable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t\t\treturn ret;\n\t\t}\nwait_rx:\n\t\t/* Check and wait for the Rx queue */\n\t\tret = i40e_pf_rxq_wait(pf, pf_q, false);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d Rx ring %d disable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n#ifdef CONFIG_I40E_DCB\n/**\n * i40e_pf_wait_queues_disabled - Wait for all queues of PF VSIs to be disabled\n * @pf: the PF\n *\n * This function waits for the queues to be in disabled state for all the\n * VSIs that are managed by this PF.\n **/\nstatic int i40e_pf_wait_queues_disabled(struct i40e_pf *pf)\n{\n\tint v, ret = 0;\n\n\tfor (v = 0; v < pf->hw.func_caps.num_vsis; v++) {\n\t\tif (pf->vsi[v]) {\n\t\t\tret = i40e_vsi_wait_queues_disabled(pf->vsi[v]);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n#endif\n\n/**\n * i40e_get_iscsi_tc_map - Return TC map for iSCSI APP\n * @pf: pointer to PF\n *\n * Get TC map for ISCSI PF type that will include iSCSI TC\n * and LAN TC.\n **/\nstatic u8 i40e_get_iscsi_tc_map(struct i40e_pf *pf)\n{\n\tstruct i40e_dcb_app_priority_table app;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 enabled_tc = 1; /* TC0 is always enabled */\n\tu8 tc, i;\n\t/* Get the iSCSI APP TLV */\n\tstruct i40e_dcbx_config *dcbcfg = &hw->local_dcbx_config;\n\n\tfor (i = 0; i < dcbcfg->numapps; i++) {\n\t\tapp = dcbcfg->app[i];\n\t\tif (app.selector == I40E_APP_SEL_TCPIP &&\n\t\t    app.protocolid == I40E_APP_PROTOID_ISCSI) {\n\t\t\ttc = dcbcfg->etscfg.prioritytable[app.priority];\n\t\t\tenabled_tc |= BIT(tc);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn enabled_tc;\n}\n\n/**\n * i40e_dcb_get_num_tc -  Get the number of TCs from DCBx config\n * @dcbcfg: the corresponding DCBx configuration structure\n *\n * Return the number of TCs from given DCBx configuration\n **/\nstatic u8 i40e_dcb_get_num_tc(struct i40e_dcbx_config *dcbcfg)\n{\n\tint i, tc_unused = 0;\n\tu8 num_tc = 0;\n\tu8 ret = 0;\n\n\t/* Scan the ETS Config Priority Table to find\n\t * traffic class enabled for a given priority\n\t * and create a bitmask of enabled TCs\n\t */\n\tfor (i = 0; i < I40E_MAX_USER_PRIORITY; i++)\n\t\tnum_tc |= BIT(dcbcfg->etscfg.prioritytable[i]);\n\n\t/* Now scan the bitmask to check for\n\t * contiguous TCs starting with TC0\n\t */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (num_tc & BIT(i)) {\n\t\t\tif (!tc_unused) {\n\t\t\t\tret++;\n\t\t\t} else {\n\t\t\t\tpr_err(\"Non-contiguous TC - Disabling DCB\\n\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t} else {\n\t\t\ttc_unused = 1;\n\t\t}\n\t}\n\n\t/* There is always at least TC0 */\n\tif (!ret)\n\t\tret = 1;\n\n\treturn ret;\n}\n\n/**\n * i40e_dcb_get_enabled_tc - Get enabled traffic classes\n * @dcbcfg: the corresponding DCBx configuration structure\n *\n * Query the current DCB configuration and return the number of\n * traffic classes enabled from the given DCBX config\n **/\nstatic u8 i40e_dcb_get_enabled_tc(struct i40e_dcbx_config *dcbcfg)\n{\n\tu8 num_tc = i40e_dcb_get_num_tc(dcbcfg);\n\tu8 enabled_tc = 1;\n\tu8 i;\n\n\tfor (i = 0; i < num_tc; i++)\n\t\tenabled_tc |= BIT(i);\n\n\treturn enabled_tc;\n}\n\n/**\n * i40e_mqprio_get_enabled_tc - Get enabled traffic classes\n * @pf: PF being queried\n *\n * Query the current MQPRIO configuration and return the number of\n * traffic classes enabled.\n **/\nstatic u8 i40e_mqprio_get_enabled_tc(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tu8 num_tc = vsi->mqprio_qopt.qopt.num_tc;\n\tu8 enabled_tc = 1, i;\n\n\tfor (i = 1; i < num_tc; i++)\n\t\tenabled_tc |= BIT(i);\n\treturn enabled_tc;\n}\n\n/**\n * i40e_pf_get_num_tc - Get enabled traffic classes for PF\n * @pf: PF being queried\n *\n * Return number of traffic classes enabled for the given PF\n **/\nstatic u8 i40e_pf_get_num_tc(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 i, enabled_tc = 1;\n\tu8 num_tc = 0;\n\tstruct i40e_dcbx_config *dcbcfg = &hw->local_dcbx_config;\n\n\tif (pf->flags & I40E_FLAG_TC_MQPRIO)\n\t\treturn pf->vsi[pf->lan_vsi]->mqprio_qopt.qopt.num_tc;\n\n\t/* If neither MQPRIO nor DCB is enabled, then always use single TC */\n\tif (!(pf->flags & I40E_FLAG_DCB_ENABLED))\n\t\treturn 1;\n\n\t/* SFP mode will be enabled for all TCs on port */\n\tif (!(pf->flags & I40E_FLAG_MFP_ENABLED))\n\t\treturn i40e_dcb_get_num_tc(dcbcfg);\n\n\t/* MFP mode return count of enabled TCs for this PF */\n\tif (pf->hw.func_caps.iscsi)\n\t\tenabled_tc =  i40e_get_iscsi_tc_map(pf);\n\telse\n\t\treturn 1; /* Only TC0 */\n\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (enabled_tc & BIT(i))\n\t\t\tnum_tc++;\n\t}\n\treturn num_tc;\n}\n\n/**\n * i40e_pf_get_pf_tc_map - Get bitmap for enabled traffic classes\n * @pf: PF being queried\n *\n * Return a bitmap for enabled traffic classes for this PF.\n **/\nstatic u8 i40e_pf_get_tc_map(struct i40e_pf *pf)\n{\n\tif (pf->flags & I40E_FLAG_TC_MQPRIO)\n\t\treturn i40e_mqprio_get_enabled_tc(pf);\n\n\t/* If neither MQPRIO nor DCB is enabled for this PF then just return\n\t * default TC\n\t */\n\tif (!(pf->flags & I40E_FLAG_DCB_ENABLED))\n\t\treturn I40E_DEFAULT_TRAFFIC_CLASS;\n\n\t/* SFP mode we want PF to be enabled for all TCs */\n\tif (!(pf->flags & I40E_FLAG_MFP_ENABLED))\n\t\treturn i40e_dcb_get_enabled_tc(&pf->hw.local_dcbx_config);\n\n\t/* MFP enabled and iSCSI PF type */\n\tif (pf->hw.func_caps.iscsi)\n\t\treturn i40e_get_iscsi_tc_map(pf);\n\telse\n\t\treturn I40E_DEFAULT_TRAFFIC_CLASS;\n}\n\n/**\n * i40e_vsi_get_bw_info - Query VSI BW Information\n * @vsi: the VSI being queried\n *\n * Returns 0 on success, negative value on failure\n **/\nstatic int i40e_vsi_get_bw_info(struct i40e_vsi *vsi)\n{\n\tstruct i40e_aqc_query_vsi_ets_sla_config_resp bw_ets_config = {0};\n\tstruct i40e_aqc_query_vsi_bw_config_resp bw_config = {0};\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret;\n\tu32 tc_bw_max;\n\tint i;\n\n\t/* Get the VSI level BW configuration */\n\tret = i40e_aq_query_vsi_bw_config(hw, vsi->seid, &bw_config, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi bw config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EINVAL;\n\t}\n\n\t/* Get the VSI level BW configuration per TC */\n\tret = i40e_aq_query_vsi_ets_sla_config(hw, vsi->seid, &bw_ets_config,\n\t\t\t\t\t       NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi ets bw config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EINVAL;\n\t}\n\n\tif (bw_config.tc_valid_bits != bw_ets_config.tc_valid_bits) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Enabled TCs mismatch from querying VSI BW info 0x%08x 0x%08x\\n\",\n\t\t\t bw_config.tc_valid_bits,\n\t\t\t bw_ets_config.tc_valid_bits);\n\t\t/* Still continuing */\n\t}\n\n\tvsi->bw_limit = le16_to_cpu(bw_config.port_bw_limit);\n\tvsi->bw_max_quanta = bw_config.max_bw;\n\ttc_bw_max = le16_to_cpu(bw_ets_config.tc_bw_max[0]) |\n\t\t    (le16_to_cpu(bw_ets_config.tc_bw_max[1]) << 16);\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tvsi->bw_ets_share_credits[i] = bw_ets_config.share_credits[i];\n\t\tvsi->bw_ets_limit_credits[i] =\n\t\t\t\t\tle16_to_cpu(bw_ets_config.credits[i]);\n\t\t/* 3 bits out of 4 for each TC */\n\t\tvsi->bw_ets_max_quanta[i] = (u8)((tc_bw_max >> (i*4)) & 0x7);\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_configure_bw_alloc - Configure VSI BW allocation per TC\n * @vsi: the VSI being configured\n * @enabled_tc: TC bitmap\n * @bw_share: BW shared credits per TC\n *\n * Returns 0 on success, negative value on failure\n **/\nstatic int i40e_vsi_configure_bw_alloc(struct i40e_vsi *vsi, u8 enabled_tc,\n\t\t\t\t       u8 *bw_share)\n{\n\tstruct i40e_aqc_configure_vsi_tc_bw_data bw_data;\n\tstruct i40e_pf *pf = vsi->back;\n\ti40e_status ret;\n\tint i;\n\n\t/* There is no need to reset BW when mqprio mode is on.  */\n\tif (pf->flags & I40E_FLAG_TC_MQPRIO)\n\t\treturn 0;\n\tif (!vsi->mqprio_qopt.qopt.hw && !(pf->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\tret = i40e_set_bw_limit(vsi, vsi->seid, 0);\n\t\tif (ret)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed to reset tx rate for vsi->seid %u\\n\",\n\t\t\t\t vsi->seid);\n\t\treturn ret;\n\t}\n\tbw_data.tc_valid_bits = enabled_tc;\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tbw_data.tc_bw_credits[i] = bw_share[i];\n\n\tret = i40e_aq_config_vsi_tc_bw(&pf->hw, vsi->seid, &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"AQ command Config VSI BW allocation per TC failed = %d\\n\",\n\t\t\t pf->hw.aq.asq_last_status);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tvsi->info.qs_handle[i] = bw_data.qs_handles[i];\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_config_netdev_tc - Setup the netdev TC configuration\n * @vsi: the VSI being configured\n * @enabled_tc: TC map to be enabled\n *\n **/\nstatic void i40e_vsi_config_netdev_tc(struct i40e_vsi *vsi, u8 enabled_tc)\n{\n\tstruct net_device *netdev = vsi->netdev;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 netdev_tc = 0;\n\tint i;\n\tstruct i40e_dcbx_config *dcbcfg = &hw->local_dcbx_config;\n\n\tif (!netdev)\n\t\treturn;\n\n\tif (!enabled_tc) {\n\t\tnetdev_reset_tc(netdev);\n\t\treturn;\n\t}\n\n\t/* Set up actual enabled TCs on the VSI */\n\tif (netdev_set_num_tc(netdev, vsi->tc_config.numtc))\n\t\treturn;\n\n\t/* set per TC queues for the VSI */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t/* Only set TC queues for enabled tcs\n\t\t *\n\t\t * e.g. For a VSI that has TC0 and TC3 enabled the\n\t\t * enabled_tc bitmap would be 0x00001001; the driver\n\t\t * will set the numtc for netdev as 2 that will be\n\t\t * referenced by the netdev layer as TC 0 and 1.\n\t\t */\n\t\tif (vsi->tc_config.enabled_tc & BIT(i))\n\t\t\tnetdev_set_tc_queue(netdev,\n\t\t\t\t\tvsi->tc_config.tc_info[i].netdev_tc,\n\t\t\t\t\tvsi->tc_config.tc_info[i].qcount,\n\t\t\t\t\tvsi->tc_config.tc_info[i].qoffset);\n\t}\n\n\tif (pf->flags & I40E_FLAG_TC_MQPRIO)\n\t\treturn;\n\n\t/* Assign UP2TC map for the VSI */\n\tfor (i = 0; i < I40E_MAX_USER_PRIORITY; i++) {\n\t\t/* Get the actual TC# for the UP */\n\t\tu8 ets_tc = dcbcfg->etscfg.prioritytable[i];\n\t\t/* Get the mapped netdev TC# for the UP */\n\t\tnetdev_tc =  vsi->tc_config.tc_info[ets_tc].netdev_tc;\n\t\tnetdev_set_prio_tc_map(netdev, i, netdev_tc);\n\t}\n}\n\n/**\n * i40e_vsi_update_queue_map - Update our copy of VSi info with new queue map\n * @vsi: the VSI being configured\n * @ctxt: the ctxt buffer returned from AQ VSI update param command\n **/\nstatic void i40e_vsi_update_queue_map(struct i40e_vsi *vsi,\n\t\t\t\t      struct i40e_vsi_context *ctxt)\n{\n\t/* copy just the sections touched not the entire info\n\t * since not all sections are valid as returned by\n\t * update vsi params\n\t */\n\tvsi->info.mapping_flags = ctxt->info.mapping_flags;\n\tmemcpy(&vsi->info.queue_mapping,\n\t       &ctxt->info.queue_mapping, sizeof(vsi->info.queue_mapping));\n\tmemcpy(&vsi->info.tc_mapping, ctxt->info.tc_mapping,\n\t       sizeof(vsi->info.tc_mapping));\n}\n\n/**\n * i40e_vsi_config_tc - Configure VSI Tx Scheduler for given TC map\n * @vsi: VSI to be configured\n * @enabled_tc: TC bitmap\n *\n * This configures a particular VSI for TCs that are mapped to the\n * given TC bitmap. It uses default bandwidth share for TCs across\n * VSIs to configure TC for a particular VSI.\n *\n * NOTE:\n * It is expected that the VSI queues have been quisced before calling\n * this function.\n **/\nstatic int i40e_vsi_config_tc(struct i40e_vsi *vsi, u8 enabled_tc)\n{\n\tu8 bw_share[I40E_MAX_TRAFFIC_CLASS] = {0};\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tint ret = 0;\n\tint i;\n\n\t/* Check if enabled_tc is same as existing or new TCs */\n\tif (vsi->tc_config.enabled_tc == enabled_tc &&\n\t    vsi->mqprio_qopt.mode != TC_MQPRIO_MODE_CHANNEL)\n\t\treturn ret;\n\n\t/* Enable ETS TCs with equal BW Share for now across all VSIs */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (enabled_tc & BIT(i))\n\t\t\tbw_share[i] = 1;\n\t}\n\n\tret = i40e_vsi_configure_bw_alloc(vsi, enabled_tc, bw_share);\n\tif (ret) {\n\t\tstruct i40e_aqc_query_vsi_bw_config_resp bw_config = {0};\n\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed configuring TC map %d for VSI %d\\n\",\n\t\t\t enabled_tc, vsi->seid);\n\t\tret = i40e_aq_query_vsi_bw_config(hw, vsi->seid,\n\t\t\t\t\t\t  &bw_config, NULL);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed querying vsi bw info, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(hw, ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t\tgoto out;\n\t\t}\n\t\tif ((bw_config.tc_valid_bits & enabled_tc) != enabled_tc) {\n\t\t\tu8 valid_tc = bw_config.tc_valid_bits & enabled_tc;\n\n\t\t\tif (!valid_tc)\n\t\t\t\tvalid_tc = bw_config.tc_valid_bits;\n\t\t\t/* Always enable TC0, no matter what */\n\t\t\tvalid_tc |= 1;\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Requested tc 0x%x, but FW reports 0x%x as valid. Attempting to use 0x%x.\\n\",\n\t\t\t\t enabled_tc, bw_config.tc_valid_bits, valid_tc);\n\t\t\tenabled_tc = valid_tc;\n\t\t}\n\n\t\tret = i40e_vsi_configure_bw_alloc(vsi, enabled_tc, bw_share);\n\t\tif (ret) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Unable to  configure TC map %d for VSI %d\\n\",\n\t\t\t\tenabled_tc, vsi->seid);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/* Update Queue Pairs Mapping for currently enabled UPs */\n\tctxt.seid = vsi->seid;\n\tctxt.pf_num = vsi->back->hw.pf_id;\n\tctxt.vf_num = 0;\n\tctxt.uplink_seid = vsi->uplink_seid;\n\tctxt.info = vsi->info;\n\tif (vsi->back->flags & I40E_FLAG_TC_MQPRIO) {\n\t\tret = i40e_vsi_setup_queue_map_mqprio(vsi, &ctxt, enabled_tc);\n\t\tif (ret)\n\t\t\tgoto out;\n\t} else {\n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, false);\n\t}\n\n\t/* On destroying the qdisc, reset vsi->rss_size, as number of enabled\n\t * queues changed.\n\t */\n\tif (!vsi->mqprio_qopt.qopt.hw && vsi->reconfig_rss) {\n\t\tvsi->rss_size = min_t(int, vsi->back->alloc_rss_size,\n\t\t\t\t      vsi->num_queue_pairs);\n\t\tret = i40e_vsi_config_rss(vsi);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"Failed to reconfig rss for num_queues\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tvsi->reconfig_rss = false;\n\t}\n\tif (vsi->back->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_QUEUE_OPT_VALID);\n\t\tctxt.info.queueing_opt_flags |= I40E_AQ_VSI_QUE_OPT_TCP_ENA;\n\t}\n\n\t/* Update the VSI after updating the VSI queue-mapping\n\t * information\n\t */\n\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Update vsi tc config failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(hw, ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\t/* update the local VSI info with updated queue map */\n\ti40e_vsi_update_queue_map(vsi, &ctxt);\n\tvsi->info.valid_sections = 0;\n\n\t/* Update current VSI BW information */\n\tret = i40e_vsi_get_bw_info(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed updating vsi bw info, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(hw, ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\t/* Update the netdev TC setup */\n\ti40e_vsi_config_netdev_tc(vsi, enabled_tc);\nout:\n\treturn ret;\n}\n\n/**\n * i40e_get_link_speed - Returns link speed for the interface\n * @vsi: VSI to be configured\n *\n **/\nstatic int i40e_get_link_speed(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tswitch (pf->hw.phy.link_info.link_speed) {\n\tcase I40E_LINK_SPEED_40GB:\n\t\treturn 40000;\n\tcase I40E_LINK_SPEED_25GB:\n\t\treturn 25000;\n\tcase I40E_LINK_SPEED_20GB:\n\t\treturn 20000;\n\tcase I40E_LINK_SPEED_10GB:\n\t\treturn 10000;\n\tcase I40E_LINK_SPEED_1GB:\n\t\treturn 1000;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\n/**\n * i40e_set_bw_limit - setup BW limit for Tx traffic based on max_tx_rate\n * @vsi: VSI to be configured\n * @seid: seid of the channel/VSI\n * @max_tx_rate: max TX rate to be configured as BW limit\n *\n * Helper function to set BW limit for a given VSI\n **/\nint i40e_set_bw_limit(struct i40e_vsi *vsi, u16 seid, u64 max_tx_rate)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu64 credits = 0;\n\tint speed = 0;\n\tint ret = 0;\n\n\tspeed = i40e_get_link_speed(vsi);\n\tif (max_tx_rate > speed) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Invalid max tx rate %llu specified for VSI seid %d.\",\n\t\t\tmax_tx_rate, seid);\n\t\treturn -EINVAL;\n\t}\n\tif (max_tx_rate && max_tx_rate < 50) {\n\t\tdev_warn(&pf->pdev->dev,\n\t\t\t \"Setting max tx rate to minimum usable value of 50Mbps.\\n\");\n\t\tmax_tx_rate = 50;\n\t}\n\n\t/* Tx rate credits are in values of 50Mbps, 0 is disabled */\n\tcredits = max_tx_rate;\n\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\tret = i40e_aq_config_vsi_bw_limit(&pf->hw, seid, credits,\n\t\t\t\t\t  I40E_MAX_BW_INACTIVE_ACCUM, NULL);\n\tif (ret)\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed set tx rate (%llu Mbps) for vsi->seid %u, err %s aq_err %s\\n\",\n\t\t\tmax_tx_rate, seid, i40e_stat_str(&pf->hw, ret),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\treturn ret;\n}\n\n/**\n * i40e_remove_queue_channels - Remove queue channels for the TCs\n * @vsi: VSI to be configured\n *\n * Remove queue channels for the TCs\n **/\nstatic void i40e_remove_queue_channels(struct i40e_vsi *vsi)\n{\n\tenum i40e_admin_queue_err last_aq_status;\n\tstruct i40e_cloud_filter *cfilter;\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct hlist_node *node;\n\tint ret, i;\n\n\t/* Reset rss size that was stored when reconfiguring rss for\n\t * channel VSIs with non-power-of-2 queue count.\n\t */\n\tvsi->current_rss_size = 0;\n\n\t/* perform cleanup for channels if they exist */\n\tif (list_empty(&vsi->ch_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tstruct i40e_vsi *p_vsi;\n\n\t\tlist_del(&ch->list);\n\t\tp_vsi = ch->parent_vsi;\n\t\tif (!p_vsi || !ch->initialized) {\n\t\t\tkfree(ch);\n\t\t\tcontinue;\n\t\t}\n\t\t/* Reset queue contexts */\n\t\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\t\tstruct i40e_ring *tx_ring, *rx_ring;\n\t\t\tu16 pf_q;\n\n\t\t\tpf_q = ch->base_queue + i;\n\t\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\t\ttx_ring->ch = NULL;\n\n\t\t\trx_ring = vsi->rx_rings[pf_q];\n\t\t\trx_ring->ch = NULL;\n\t\t}\n\n\t\t/* Reset BW configured for this VSI via mqprio */\n\t\tret = i40e_set_bw_limit(vsi, ch->seid, 0);\n\t\tif (ret)\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"Failed to reset tx rate for ch->seid %u\\n\",\n\t\t\t\t ch->seid);\n\n\t\t/* delete cloud filters associated with this channel */\n\t\thlist_for_each_entry_safe(cfilter, node,\n\t\t\t\t\t  &pf->cloud_filter_list, cloud_node) {\n\t\t\tif (cfilter->seid != ch->seid)\n\t\t\t\tcontinue;\n\n\t\t\thash_del(&cfilter->cloud_node);\n\t\t\tif (cfilter->dst_port)\n\t\t\t\tret = i40e_add_del_cloud_filter_big_buf(vsi,\n\t\t\t\t\t\t\t\t\tcfilter,\n\t\t\t\t\t\t\t\t\tfalse);\n\t\t\telse\n\t\t\t\tret = i40e_add_del_cloud_filter(vsi, cfilter,\n\t\t\t\t\t\t\t\tfalse);\n\t\t\tlast_aq_status = pf->hw.aq.asq_last_status;\n\t\t\tif (ret)\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"Failed to delete cloud filter, err %s aq_err %s\\n\",\n\t\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\t\tkfree(cfilter);\n\t\t}\n\n\t\t/* delete VSI from FW */\n\t\tret = i40e_aq_delete_element(&vsi->back->hw, ch->seid,\n\t\t\t\t\t     NULL);\n\t\tif (ret)\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"unable to remove channel (%d) for parent VSI(%d)\\n\",\n\t\t\t\tch->seid, p_vsi->seid);\n\t\tkfree(ch);\n\t}\n\tINIT_LIST_HEAD(&vsi->ch_list);\n}\n\n/**\n * i40e_is_any_channel - channel exist or not\n * @vsi: ptr to VSI to which channels are associated with\n *\n * Returns true or false if channel(s) exist for associated VSI or not\n **/\nstatic bool i40e_is_any_channel(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tif (ch->initialized)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n/**\n * i40e_get_max_queues_for_channel\n * @vsi: ptr to VSI to which channels are associated with\n *\n * Helper function which returns max value among the queue counts set on the\n * channels/TCs created.\n **/\nstatic int i40e_get_max_queues_for_channel(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\tint max = 0;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tif (!ch->initialized)\n\t\t\tcontinue;\n\t\tif (ch->num_queue_pairs > max)\n\t\t\tmax = ch->num_queue_pairs;\n\t}\n\n\treturn max;\n}\n\n/**\n * i40e_validate_num_queues - validate num_queues w.r.t channel\n * @pf: ptr to PF device\n * @num_queues: number of queues\n * @vsi: the parent VSI\n * @reconfig_rss: indicates should the RSS be reconfigured or not\n *\n * This function validates number of queues in the context of new channel\n * which is being established and determines if RSS should be reconfigured\n * or not for parent VSI.\n **/\nstatic int i40e_validate_num_queues(struct i40e_pf *pf, int num_queues,\n\t\t\t\t    struct i40e_vsi *vsi, bool *reconfig_rss)\n{\n\tint max_ch_queues;\n\n\tif (!reconfig_rss)\n\t\treturn -EINVAL;\n\n\t*reconfig_rss = false;\n\tif (vsi->current_rss_size) {\n\t\tif (num_queues > vsi->current_rss_size) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Error: num_queues (%d) > vsi's current_size(%d)\\n\",\n\t\t\t\tnum_queues, vsi->current_rss_size);\n\t\t\treturn -EINVAL;\n\t\t} else if ((num_queues < vsi->current_rss_size) &&\n\t\t\t   (!is_power_of_2(num_queues))) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Error: num_queues (%d) < vsi's current_size(%d), but not power of 2\\n\",\n\t\t\t\tnum_queues, vsi->current_rss_size);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!is_power_of_2(num_queues)) {\n\t\t/* Find the max num_queues configured for channel if channel\n\t\t * exist.\n\t\t * if channel exist, then enforce 'num_queues' to be more than\n\t\t * max ever queues configured for channel.\n\t\t */\n\t\tmax_ch_queues = i40e_get_max_queues_for_channel(vsi);\n\t\tif (num_queues < max_ch_queues) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Error: num_queues (%d) < max queues configured for channel(%d)\\n\",\n\t\t\t\tnum_queues, max_ch_queues);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t*reconfig_rss = true;\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_reconfig_rss - reconfig RSS based on specified rss_size\n * @vsi: the VSI being setup\n * @rss_size: size of RSS, accordingly LUT gets reprogrammed\n *\n * This function reconfigures RSS by reprogramming LUTs using 'rss_size'\n **/\nstatic int i40e_vsi_reconfig_rss(struct i40e_vsi *vsi, u16 rss_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 seed[I40E_HKEY_ARRAY_SIZE];\n\tstruct i40e_hw *hw = &pf->hw;\n\tint local_rss_size;\n\tu8 *lut;\n\tint ret;\n\n\tif (!vsi->rss_size)\n\t\treturn -EINVAL;\n\n\tif (rss_size > vsi->rss_size)\n\t\treturn -EINVAL;\n\n\tlocal_rss_size = min_t(int, vsi->rss_size, rss_size);\n\tlut = kzalloc(vsi->rss_table_size, GFP_KERNEL);\n\tif (!lut)\n\t\treturn -ENOMEM;\n\n\t/* Ignoring user configured lut if there is one */\n\ti40e_fill_rss_lut(pf, lut, vsi->rss_table_size, local_rss_size);\n\n\t/* Use user configured hash key if there is one, otherwise\n\t * use default.\n\t */\n\tif (vsi->rss_hkey_user)\n\t\tmemcpy(seed, vsi->rss_hkey_user, I40E_HKEY_ARRAY_SIZE);\n\telse\n\t\tnetdev_rss_key_fill((void *)seed, I40E_HKEY_ARRAY_SIZE);\n\n\tret = i40e_config_rss(vsi, seed, lut, vsi->rss_table_size);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Cannot set RSS lut, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(hw, ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\tkfree(lut);\n\t\treturn ret;\n\t}\n\tkfree(lut);\n\n\t/* Do the update w.r.t. storing rss_size */\n\tif (!vsi->orig_rss_size)\n\t\tvsi->orig_rss_size = vsi->rss_size;\n\tvsi->current_rss_size = local_rss_size;\n\n\treturn ret;\n}\n\n/**\n * i40e_channel_setup_queue_map - Setup a channel queue map\n * @pf: ptr to PF device\n * @vsi: the VSI being setup\n * @ctxt: VSI context structure\n * @ch: ptr to channel structure\n *\n * Setup queue map for a specific channel\n **/\nstatic void i40e_channel_setup_queue_map(struct i40e_pf *pf,\n\t\t\t\t\t struct i40e_vsi_context *ctxt,\n\t\t\t\t\t struct i40e_channel *ch)\n{\n\tu16 qcount, qmap, sections = 0;\n\tu8 offset = 0;\n\tint pow;\n\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\n\tqcount = min_t(int, ch->num_queue_pairs, pf->num_lan_msix);\n\tch->num_queue_pairs = qcount;\n\n\t/* find the next higher power-of-2 of num queue pairs */\n\tpow = ilog2(qcount);\n\tif (!is_power_of_2(qcount))\n\t\tpow++;\n\n\tqmap = (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t(pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t/* Setup queue TC[0].qmap for given VSI context */\n\tctxt->info.tc_mapping[0] = cpu_to_le16(qmap);\n\n\tctxt->info.up_enable_bits = 0x1; /* TC0 enabled */\n\tctxt->info.mapping_flags |= cpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\tctxt->info.queue_mapping[0] = cpu_to_le16(ch->base_queue);\n\tctxt->info.valid_sections |= cpu_to_le16(sections);\n}\n\n/**\n * i40e_add_channel - add a channel by adding VSI\n * @pf: ptr to PF device\n * @uplink_seid: underlying HW switching element (VEB) ID\n * @ch: ptr to channel structure\n *\n * Add a channel (VSI) using add_vsi and queue_map\n **/\nstatic int i40e_add_channel(struct i40e_pf *pf, u16 uplink_seid,\n\t\t\t    struct i40e_channel *ch)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tu8 enabled_tc = 0x1; /* TC0 enabled */\n\tint ret;\n\n\tif (ch->type != I40E_VSI_VMDQ2) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"add new vsi failed, ch->type %d\\n\", ch->type);\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tctxt.pf_num = hw->pf_id;\n\tctxt.vf_num = 0;\n\tctxt.uplink_seid = uplink_seid;\n\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\tif (ch->type == I40E_VSI_VMDQ2)\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_VMDQ2;\n\n\tif (pf->flags & I40E_FLAG_VEB_MODE_ENABLED) {\n\t\tctxt.info.valid_sections |=\n\t\t     cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\tctxt.info.switch_id =\n\t\t   cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t}\n\n\t/* Set queue map for a given VSI context */\n\ti40e_channel_setup_queue_map(pf, &ctxt, ch);\n\n\t/* Now time to create VSI */\n\tret = i40e_aq_add_vsi(hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"add new vsi failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\treturn -ENOENT;\n\t}\n\n\t/* Success, update channel, set enabled_tc only if the channel\n\t * is not a macvlan\n\t */\n\tch->enabled_tc = !i40e_is_channel_macvlan(ch) && enabled_tc;\n\tch->seid = ctxt.seid;\n\tch->vsi_number = ctxt.vsi_number;\n\tch->stat_counter_idx = cpu_to_le16(ctxt.info.stat_counter_idx);\n\n\t/* copy just the sections touched not the entire info\n\t * since not all sections are valid as returned by\n\t * update vsi params\n\t */\n\tch->info.mapping_flags = ctxt.info.mapping_flags;\n\tmemcpy(&ch->info.queue_mapping,\n\t       &ctxt.info.queue_mapping, sizeof(ctxt.info.queue_mapping));\n\tmemcpy(&ch->info.tc_mapping, ctxt.info.tc_mapping,\n\t       sizeof(ctxt.info.tc_mapping));\n\n\treturn 0;\n}\n\nstatic int i40e_channel_config_bw(struct i40e_vsi *vsi, struct i40e_channel *ch,\n\t\t\t\t  u8 *bw_share)\n{\n\tstruct i40e_aqc_configure_vsi_tc_bw_data bw_data;\n\ti40e_status ret;\n\tint i;\n\n\tbw_data.tc_valid_bits = ch->enabled_tc;\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tbw_data.tc_bw_credits[i] = bw_share[i];\n\n\tret = i40e_aq_config_vsi_tc_bw(&vsi->back->hw, ch->seid,\n\t\t\t\t       &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Config VSI BW allocation per TC failed, aq_err: %d for new_vsi->seid %u\\n\",\n\t\t\t vsi->back->hw.aq.asq_last_status, ch->seid);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tch->info.qs_handle[i] = bw_data.qs_handles[i];\n\n\treturn 0;\n}\n\n/**\n * i40e_channel_config_tx_ring - config TX ring associated with new channel\n * @pf: ptr to PF device\n * @vsi: the VSI being setup\n * @ch: ptr to channel structure\n *\n * Configure TX rings associated with channel (VSI) since queues are being\n * from parent VSI.\n **/\nstatic int i40e_channel_config_tx_ring(struct i40e_pf *pf,\n\t\t\t\t       struct i40e_vsi *vsi,\n\t\t\t\t       struct i40e_channel *ch)\n{\n\ti40e_status ret;\n\tint i;\n\tu8 bw_share[I40E_MAX_TRAFFIC_CLASS] = {0};\n\n\t/* Enable ETS TCs with equal BW Share for now across all VSIs */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (ch->enabled_tc & BIT(i))\n\t\t\tbw_share[i] = 1;\n\t}\n\n\t/* configure BW for new VSI */\n\tret = i40e_channel_config_bw(vsi, ch, bw_share);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed configuring TC map %d for channel (seid %u)\\n\",\n\t\t\t ch->enabled_tc, ch->seid);\n\t\treturn ret;\n\t}\n\n\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\tstruct i40e_ring *tx_ring, *rx_ring;\n\t\tu16 pf_q;\n\n\t\tpf_q = ch->base_queue + i;\n\n\t\t/* Get to TX ring ptr of main VSI, for re-setup TX queue\n\t\t * context\n\t\t */\n\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\ttx_ring->ch = ch;\n\n\t\t/* Get the RX ring ptr */\n\t\trx_ring = vsi->rx_rings[pf_q];\n\t\trx_ring->ch = ch;\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_setup_hw_channel - setup new channel\n * @pf: ptr to PF device\n * @vsi: the VSI being setup\n * @ch: ptr to channel structure\n * @uplink_seid: underlying HW switching element (VEB) ID\n * @type: type of channel to be created (VMDq2/VF)\n *\n * Setup new channel (VSI) based on specified type (VMDq2/VF)\n * and configures TX rings accordingly\n **/\nstatic inline int i40e_setup_hw_channel(struct i40e_pf *pf,\n\t\t\t\t\tstruct i40e_vsi *vsi,\n\t\t\t\t\tstruct i40e_channel *ch,\n\t\t\t\t\tu16 uplink_seid, u8 type)\n{\n\tint ret;\n\n\tch->initialized = false;\n\tch->base_queue = vsi->next_base_queue;\n\tch->type = type;\n\n\t/* Proceed with creation of channel (VMDq2) VSI */\n\tret = i40e_add_channel(pf, uplink_seid, ch);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to add_channel using uplink_seid %u\\n\",\n\t\t\t uplink_seid);\n\t\treturn ret;\n\t}\n\n\t/* Mark the successful creation of channel */\n\tch->initialized = true;\n\n\t/* Reconfigure TX queues using QTX_CTL register */\n\tret = i40e_channel_config_tx_ring(pf, vsi, ch);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to configure TX rings for channel %u\\n\",\n\t\t\t ch->seid);\n\t\treturn ret;\n\t}\n\n\t/* update 'next_base_queue' */\n\tvsi->next_base_queue = vsi->next_base_queue + ch->num_queue_pairs;\n\tdev_dbg(&pf->pdev->dev,\n\t\t\"Added channel: vsi_seid %u, vsi_number %u, stat_counter_idx %u, num_queue_pairs %u, pf->next_base_queue %d\\n\",\n\t\tch->seid, ch->vsi_number, ch->stat_counter_idx,\n\t\tch->num_queue_pairs,\n\t\tvsi->next_base_queue);\n\treturn ret;\n}\n\n/**\n * i40e_setup_channel - setup new channel using uplink element\n * @pf: ptr to PF device\n * @type: type of channel to be created (VMDq2/VF)\n * @uplink_seid: underlying HW switching element (VEB) ID\n * @ch: ptr to channel structure\n *\n * Setup new channel (VSI) based on specified type (VMDq2/VF)\n * and uplink switching element (uplink_seid)\n **/\nstatic bool i40e_setup_channel(struct i40e_pf *pf, struct i40e_vsi *vsi,\n\t\t\t       struct i40e_channel *ch)\n{\n\tu8 vsi_type;\n\tu16 seid;\n\tint ret;\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\tvsi_type = I40E_VSI_VMDQ2;\n\t} else {\n\t\tdev_err(&pf->pdev->dev, \"unsupported parent vsi type(%d)\\n\",\n\t\t\tvsi->type);\n\t\treturn false;\n\t}\n\n\t/* underlying switching element */\n\tseid = pf->vsi[pf->lan_vsi]->uplink_seid;\n\n\t/* create channel (VSI), configure TX rings */\n\tret = i40e_setup_hw_channel(pf, vsi, ch, seid, vsi_type);\n\tif (ret) {\n\t\tdev_err(&pf->pdev->dev, \"failed to setup hw_channel\\n\");\n\t\treturn false;\n\t}\n\n\treturn ch->initialized ? true : false;\n}\n\n/**\n * i40e_validate_and_set_switch_mode - sets up switch mode correctly\n * @vsi: ptr to VSI which has PF backing\n *\n * Sets up switch mode correctly if it needs to be changed and perform\n * what are allowed modes.\n **/\nstatic int i40e_validate_and_set_switch_mode(struct i40e_vsi *vsi)\n{\n\tu8 mode;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret;\n\n\tret = i40e_get_capabilities(pf, i40e_aqc_opc_list_dev_capabilities);\n\tif (ret)\n\t\treturn -EINVAL;\n\n\tif (hw->dev_caps.switch_mode) {\n\t\t/* if switch mode is set, support mode2 (non-tunneled for\n\t\t * cloud filter) for now\n\t\t */\n\t\tu32 switch_mode = hw->dev_caps.switch_mode &\n\t\t\t\t  I40E_SWITCH_MODE_MASK;\n\t\tif (switch_mode >= I40E_CLOUD_FILTER_MODE1) {\n\t\t\tif (switch_mode == I40E_CLOUD_FILTER_MODE2)\n\t\t\t\treturn 0;\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Invalid switch_mode (%d), only non-tunneled mode for cloud filter is supported\\n\",\n\t\t\t\thw->dev_caps.switch_mode);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t/* Set Bit 7 to be valid */\n\tmode = I40E_AQ_SET_SWITCH_BIT7_VALID;\n\n\t/* Set L4type for TCP support */\n\tmode |= I40E_AQ_SET_SWITCH_L4_TYPE_TCP;\n\n\t/* Set cloud filter mode */\n\tmode |= I40E_AQ_SET_SWITCH_MODE_NON_TUNNEL;\n\n\t/* Prep mode field for set_switch_config */\n\tret = i40e_aq_set_switch_config(hw, pf->last_sw_conf_flags,\n\t\t\t\t\tpf->last_sw_conf_valid_flags,\n\t\t\t\t\tmode, NULL);\n\tif (ret && hw->aq.asq_last_status != I40E_AQ_RC_ESRCH)\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"couldn't set switch config bits, err %s aq_err %s\\n\",\n\t\t\ti40e_stat_str(hw, ret),\n\t\t\ti40e_aq_str(hw,\n\t\t\t\t    hw->aq.asq_last_status));\n\n\treturn ret;\n}\n\n/**\n * i40e_create_queue_channel - function to create channel\n * @vsi: VSI to be configured\n * @ch: ptr to channel (it contains channel specific params)\n *\n * This function creates channel (VSI) using num_queues specified by user,\n * reconfigs RSS if needed.\n **/\nint i40e_create_queue_channel(struct i40e_vsi *vsi,\n\t\t\t      struct i40e_channel *ch)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tbool reconfig_rss;\n\tint err;\n\n\tif (!ch)\n\t\treturn -EINVAL;\n\n\tif (!ch->num_queue_pairs) {\n\t\tdev_err(&pf->pdev->dev, \"Invalid num_queues requested: %d\\n\",\n\t\t\tch->num_queue_pairs);\n\t\treturn -EINVAL;\n\t}\n\n\t/* validate user requested num_queues for channel */\n\terr = i40e_validate_num_queues(pf, ch->num_queue_pairs, vsi,\n\t\t\t\t       &reconfig_rss);\n\tif (err) {\n\t\tdev_info(&pf->pdev->dev, \"Failed to validate num_queues (%d)\\n\",\n\t\t\t ch->num_queue_pairs);\n\t\treturn -EINVAL;\n\t}\n\n\t/* By default we are in VEPA mode, if this is the first VF/VMDq\n\t * VSI to be added switch to VEB mode.\n\t */\n\tif ((!(pf->flags & I40E_FLAG_VEB_MODE_ENABLED)) ||\n\t    (!i40e_is_any_channel(vsi))) {\n\t\tif (!is_power_of_2(vsi->tc_config.tc_info[0].qcount)) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Failed to create channel. Override queues (%u) not power of 2\\n\",\n\t\t\t\tvsi->tc_config.tc_info[0].qcount);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!(pf->flags & I40E_FLAG_VEB_MODE_ENABLED)) {\n\t\t\tpf->flags |= I40E_FLAG_VEB_MODE_ENABLED;\n\n\t\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\t\tif (pf->flags & I40E_FLAG_TC_MQPRIO)\n\t\t\t\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG,\n\t\t\t\t\t\t      true);\n\t\t\t\telse\n\t\t\t\t\ti40e_do_reset_safe(pf,\n\t\t\t\t\t\t\t   I40E_PF_RESET_FLAG);\n\t\t\t}\n\t\t}\n\t\t/* now onwards for main VSI, number of queues will be value\n\t\t * of TC0's queue count\n\t\t */\n\t}\n\n\t/* By this time, vsi->cnt_q_avail shall be set to non-zero and\n\t * it should be more than num_queues\n\t */\n\tif (!vsi->cnt_q_avail || vsi->cnt_q_avail < ch->num_queue_pairs) {\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Error: cnt_q_avail (%u) less than num_queues %d\\n\",\n\t\t\tvsi->cnt_q_avail, ch->num_queue_pairs);\n\t\treturn -EINVAL;\n\t}\n\n\t/* reconfig_rss only if vsi type is MAIN_VSI */\n\tif (reconfig_rss && (vsi->type == I40E_VSI_MAIN)) {\n\t\terr = i40e_vsi_reconfig_rss(vsi, ch->num_queue_pairs);\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Error: unable to reconfig rss for num_queues (%u)\\n\",\n\t\t\t\t ch->num_queue_pairs);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!i40e_setup_channel(pf, vsi, ch)) {\n\t\tdev_info(&pf->pdev->dev, \"Failed to setup channel\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev_info(&pf->pdev->dev,\n\t\t \"Setup channel (id:%u) utilizing num_queues %d\\n\",\n\t\t ch->seid, ch->num_queue_pairs);\n\n\t/* configure VSI for BW limit */\n\tif (ch->max_tx_rate) {\n\t\tu64 credits = ch->max_tx_rate;\n\n\t\tif (i40e_set_bw_limit(vsi, ch->seid, ch->max_tx_rate))\n\t\t\treturn -EINVAL;\n\n\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\tch->max_tx_rate,\n\t\t\tcredits,\n\t\t\tch->seid);\n\t}\n\n\t/* in case of VF, this will be main SRIOV VSI */\n\tch->parent_vsi = vsi;\n\n\t/* and update main_vsi's count for queue_available to use */\n\tvsi->cnt_q_avail -= ch->num_queue_pairs;\n\n\treturn 0;\n}\n\n/**\n * i40e_configure_queue_channels - Add queue channel for the given TCs\n * @vsi: VSI to be configured\n *\n * Configures queue channel mapping to the given TCs\n **/\nstatic int i40e_configure_queue_channels(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch;\n\tu64 max_rate = 0;\n\tint ret = 0, i;\n\n\t/* Create app vsi with the TCs. Main VSI with TC0 is already set up */\n\tvsi->tc_seid_map[0] = vsi->seid;\n\tfor (i = 1; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (vsi->tc_config.enabled_tc & BIT(i)) {\n\t\t\tch = kzalloc(sizeof(*ch), GFP_KERNEL);\n\t\t\tif (!ch) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto err_free;\n\t\t\t}\n\n\t\t\tINIT_LIST_HEAD(&ch->list);\n\t\t\tch->num_queue_pairs =\n\t\t\t\tvsi->tc_config.tc_info[i].qcount;\n\t\t\tch->base_queue =\n\t\t\t\tvsi->tc_config.tc_info[i].qoffset;\n\n\t\t\t/* Bandwidth limit through tc interface is in bytes/s,\n\t\t\t * change to Mbit/s\n\t\t\t */\n\t\t\tmax_rate = vsi->mqprio_qopt.max_rate[i];\n\t\t\tdo_div(max_rate, I40E_BW_MBPS_DIVISOR);\n\t\t\tch->max_tx_rate = max_rate;\n\n\t\t\tlist_add_tail(&ch->list, &vsi->ch_list);\n\n\t\t\tret = i40e_create_queue_channel(vsi, ch);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\t\"Failed creating queue channel with TC%d: queues %d\\n\",\n\t\t\t\t\ti, ch->num_queue_pairs);\n\t\t\t\tgoto err_free;\n\t\t\t}\n\t\t\tvsi->tc_seid_map[i] = ch->seid;\n\t\t}\n\t}\n\treturn ret;\n\nerr_free:\n\ti40e_remove_queue_channels(vsi);\n\treturn ret;\n}\n\n/**\n * i40e_veb_config_tc - Configure TCs for given VEB\n * @veb: given VEB\n * @enabled_tc: TC bitmap\n *\n * Configures given TC bitmap for VEB (switching) element\n **/\nint i40e_veb_config_tc(struct i40e_veb *veb, u8 enabled_tc)\n{\n\tstruct i40e_aqc_configure_switching_comp_bw_config_data bw_data = {0};\n\tstruct i40e_pf *pf = veb->pf;\n\tint ret = 0;\n\tint i;\n\n\t/* No TCs or already enabled TCs just return */\n\tif (!enabled_tc || veb->enabled_tc == enabled_tc)\n\t\treturn ret;\n\n\tbw_data.tc_valid_bits = enabled_tc;\n\t/* bw_data.absolute_credits is not set (relative) */\n\n\t/* Enable ETS TCs with equal BW Share for now */\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (enabled_tc & BIT(i))\n\t\t\tbw_data.tc_bw_share_credits[i] = 1;\n\t}\n\n\tret = i40e_aq_config_switch_comp_bw_config(&pf->hw, veb->seid,\n\t\t\t\t\t\t   &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VEB bw config failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\t/* Update the BW information */\n\tret = i40e_veb_get_bw_info(veb);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed getting veb bw config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n\nout:\n\treturn ret;\n}\n\n#ifdef CONFIG_I40E_DCB\n/**\n * i40e_dcb_reconfigure - Reconfigure all VEBs and VSIs\n * @pf: PF struct\n *\n * Reconfigure VEB/VSIs on a given PF; it is assumed that\n * the caller would've quiesce all the VSIs before calling\n * this function\n **/\nstatic void i40e_dcb_reconfigure(struct i40e_pf *pf)\n{\n\tu8 tc_map = 0;\n\tint ret;\n\tu8 v;\n\n\t/* Enable the TCs available on PF to all VEBs */\n\ttc_map = i40e_pf_get_tc_map(pf);\n\tfor (v = 0; v < I40E_MAX_VEB; v++) {\n\t\tif (!pf->veb[v])\n\t\t\tcontinue;\n\t\tret = i40e_veb_config_tc(pf->veb[v], tc_map);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed configuring TC for VEB seid=%d\\n\",\n\t\t\t\t pf->veb[v]->seid);\n\t\t\t/* Will try to configure as many components */\n\t\t}\n\t}\n\n\t/* Update each VSI */\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (!pf->vsi[v])\n\t\t\tcontinue;\n\n\t\t/* - Enable all TCs for the LAN VSI\n\t\t * - For all others keep them at TC0 for now\n\t\t */\n\t\tif (v == pf->lan_vsi)\n\t\t\ttc_map = i40e_pf_get_tc_map(pf);\n\t\telse\n\t\t\ttc_map = I40E_DEFAULT_TRAFFIC_CLASS;\n\n\t\tret = i40e_vsi_config_tc(pf->vsi[v], tc_map);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed configuring TC for VSI seid=%d\\n\",\n\t\t\t\t pf->vsi[v]->seid);\n\t\t\t/* Will try to configure as many components */\n\t\t} else {\n\t\t\t/* Re-configure VSI vectors based on updated TC map */\n\t\t\ti40e_vsi_map_rings_to_vectors(pf->vsi[v]);\n\t\t\tif (pf->vsi[v]->netdev)\n\t\t\t\ti40e_dcbnl_set_all(pf->vsi[v]);\n\t\t}\n\t}\n}\n\n/**\n * i40e_resume_port_tx - Resume port Tx\n * @pf: PF struct\n *\n * Resume a port's Tx and issue a PF reset in case of failure to\n * resume.\n **/\nstatic int i40e_resume_port_tx(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret;\n\n\tret = i40e_aq_resume_port_tx(hw, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Resume Port Tx failed, err %s aq_err %s\\n\",\n\t\t\t  i40e_stat_str(&pf->hw, ret),\n\t\t\t  i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\t/* Schedule PF reset to recover */\n\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\ti40e_service_event_schedule(pf);\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_init_pf_dcb - Initialize DCB configuration\n * @pf: PF being configured\n *\n * Query the current DCB configuration and cache it\n * in the hardware structure\n **/\nstatic int i40e_init_pf_dcb(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint err = 0;\n\n\t/* Do not enable DCB for SW1 and SW2 images even if the FW is capable\n\t * Also do not enable DCBx if FW LLDP agent is disabled\n\t */\n\tif ((pf->hw_features & I40E_HW_NO_DCB_SUPPORT) ||\n\t    (pf->flags & I40E_FLAG_DISABLE_FW_LLDP)) {\n\t\tdev_info(&pf->pdev->dev, \"DCB is not supported or FW LLDP is disabled\\n\");\n\t\terr = I40E_NOT_SUPPORTED;\n\t\tgoto out;\n\t}\n\n\terr = i40e_init_dcb(hw, true);\n\tif (!err) {\n\t\t/* Device/Function is not DCBX capable */\n\t\tif ((!hw->func_caps.dcb) ||\n\t\t    (hw->dcbx_status == I40E_DCBX_STATUS_DISABLED)) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"DCBX offload is not supported or is disabled for this PF.\\n\");\n\t\t} else {\n\t\t\t/* When status is not DISABLED then DCBX in FW */\n\t\t\tpf->dcbx_cap = DCB_CAP_DCBX_LLD_MANAGED |\n\t\t\t\t       DCB_CAP_DCBX_VER_IEEE;\n\n\t\t\tpf->flags |= I40E_FLAG_DCB_CAPABLE;\n\t\t\t/* Enable DCB tagging only when more than one TC\n\t\t\t * or explicitly disable if only one TC\n\t\t\t */\n\t\t\tif (i40e_dcb_get_num_tc(&hw->local_dcbx_config) > 1)\n\t\t\t\tpf->flags |= I40E_FLAG_DCB_ENABLED;\n\t\t\telse\n\t\t\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"DCBX offload is supported for this PF.\\n\");\n\t\t}\n\t} else if (pf->hw.aq.asq_last_status == I40E_AQ_RC_EPERM) {\n\t\tdev_info(&pf->pdev->dev, \"FW LLDP disabled for this PF.\\n\");\n\t\tpf->flags |= I40E_FLAG_DISABLE_FW_LLDP;\n\t} else {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Query for DCB configuration failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, err),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n\nout:\n\treturn err;\n}\n#endif /* CONFIG_I40E_DCB */\n#define SPEED_SIZE 14\n#define FC_SIZE 8\n/**\n * i40e_print_link_message - print link up or down\n * @vsi: the VSI for which link needs a message\n * @isup: true of link is up, false otherwise\n */\nvoid i40e_print_link_message(struct i40e_vsi *vsi, bool isup)\n{\n\tenum i40e_aq_link_speed new_speed;\n\tstruct i40e_pf *pf = vsi->back;\n\tchar *speed = \"Unknown\";\n\tchar *fc = \"Unknown\";\n\tchar *fec = \"\";\n\tchar *req_fec = \"\";\n\tchar *an = \"\";\n\n\tif (isup)\n\t\tnew_speed = pf->hw.phy.link_info.link_speed;\n\telse\n\t\tnew_speed = I40E_LINK_SPEED_UNKNOWN;\n\n\tif ((vsi->current_isup == isup) && (vsi->current_speed == new_speed))\n\t\treturn;\n\tvsi->current_isup = isup;\n\tvsi->current_speed = new_speed;\n\tif (!isup) {\n\t\tnetdev_info(vsi->netdev, \"NIC Link is Down\\n\");\n\t\treturn;\n\t}\n\n\t/* Warn user if link speed on NPAR enabled partition is not at\n\t * least 10GB\n\t */\n\tif (pf->hw.func_caps.npar_enable &&\n\t    (pf->hw.phy.link_info.link_speed == I40E_LINK_SPEED_1GB ||\n\t     pf->hw.phy.link_info.link_speed == I40E_LINK_SPEED_100MB))\n\t\tnetdev_warn(vsi->netdev,\n\t\t\t    \"The partition detected link speed that is less than 10Gbps\\n\");\n\n\tswitch (pf->hw.phy.link_info.link_speed) {\n\tcase I40E_LINK_SPEED_40GB:\n\t\tspeed = \"40 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_20GB:\n\t\tspeed = \"20 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_25GB:\n\t\tspeed = \"25 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_10GB:\n\t\tspeed = \"10 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_5GB:\n\t\tspeed = \"5 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_2_5GB:\n\t\tspeed = \"2.5 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_1GB:\n\t\tspeed = \"1000 M\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_100MB:\n\t\tspeed = \"100 M\";\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tswitch (pf->hw.fc.current_mode) {\n\tcase I40E_FC_FULL:\n\t\tfc = \"RX/TX\";\n\t\tbreak;\n\tcase I40E_FC_TX_PAUSE:\n\t\tfc = \"TX\";\n\t\tbreak;\n\tcase I40E_FC_RX_PAUSE:\n\t\tfc = \"RX\";\n\t\tbreak;\n\tdefault:\n\t\tfc = \"None\";\n\t\tbreak;\n\t}\n\n\tif (pf->hw.phy.link_info.link_speed == I40E_LINK_SPEED_25GB) {\n\t\treq_fec = \"None\";\n\t\tfec = \"None\";\n\t\tan = \"False\";\n\n\t\tif (pf->hw.phy.link_info.an_info & I40E_AQ_AN_COMPLETED)\n\t\t\tan = \"True\";\n\n\t\tif (pf->hw.phy.link_info.fec_info &\n\t\t    I40E_AQ_CONFIG_FEC_KR_ENA)\n\t\t\tfec = \"CL74 FC-FEC/BASE-R\";\n\t\telse if (pf->hw.phy.link_info.fec_info &\n\t\t\t I40E_AQ_CONFIG_FEC_RS_ENA)\n\t\t\tfec = \"CL108 RS-FEC\";\n\n\t\t/* 'CL108 RS-FEC' should be displayed when RS is requested, or\n\t\t * both RS and FC are requested\n\t\t */\n\t\tif (vsi->back->hw.phy.link_info.req_fec_info &\n\t\t    (I40E_AQ_REQUEST_FEC_KR | I40E_AQ_REQUEST_FEC_RS)) {\n\t\t\tif (vsi->back->hw.phy.link_info.req_fec_info &\n\t\t\t    I40E_AQ_REQUEST_FEC_RS)\n\t\t\t\treq_fec = \"CL108 RS-FEC\";\n\t\t\telse\n\t\t\t\treq_fec = \"CL74 FC-FEC/BASE-R\";\n\t\t}\n\t\tnetdev_info(vsi->netdev,\n\t\t\t    \"NIC Link is Up, %sbps Full Duplex, Requested FEC: %s, Negotiated FEC: %s, Autoneg: %s, Flow Control: %s\\n\",\n\t\t\t    speed, req_fec, fec, an, fc);\n\t} else {\n\t\tnetdev_info(vsi->netdev,\n\t\t\t    \"NIC Link is Up, %sbps Full Duplex, Flow Control: %s\\n\",\n\t\t\t    speed, fc);\n\t}\n\n}\n\n/**\n * i40e_up_complete - Finish the last steps of bringing up a connection\n * @vsi: the VSI being configured\n **/\nstatic int i40e_up_complete(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint err;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\ti40e_vsi_configure_msix(vsi);\n\telse\n\t\ti40e_configure_msi_and_legacy(vsi);\n\n\t/* start rings */\n\terr = i40e_vsi_start_rings(vsi);\n\tif (err)\n\t\treturn err;\n\n\tclear_bit(__I40E_VSI_DOWN, vsi->state);\n\ti40e_napi_enable_all(vsi);\n\ti40e_vsi_enable_irq(vsi);\n\n\tif ((pf->hw.phy.link_info.link_info & I40E_AQ_LINK_UP) &&\n\t    (vsi->netdev)) {\n\t\ti40e_print_link_message(vsi, true);\n\t\tnetif_tx_start_all_queues(vsi->netdev);\n\t\tnetif_carrier_on(vsi->netdev);\n\t}\n\n\t/* replay FDIR SB filters */\n\tif (vsi->type == I40E_VSI_FDIR) {\n\t\t/* reset fd counters */\n\t\tpf->fd_add_err = 0;\n\t\tpf->fd_atr_cnt = 0;\n\t\ti40e_fdir_filter_restore(vsi);\n\t}\n\n\t/* On the next run of the service_task, notify any clients of the new\n\t * opened netdev\n\t */\n\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\ti40e_service_event_schedule(pf);\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_reinit_locked - Reset the VSI\n * @vsi: the VSI being configured\n *\n * Rebuild the ring structs after some configuration\n * has changed, e.g. MTU size.\n **/\nstatic void i40e_vsi_reinit_locked(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tWARN_ON(in_interrupt());\n\twhile (test_and_set_bit(__I40E_CONFIG_BUSY, pf->state))\n\t\tusleep_range(1000, 2000);\n\ti40e_down(vsi);\n\n\ti40e_up(vsi);\n\tclear_bit(__I40E_CONFIG_BUSY, pf->state);\n}\n\n/**\n * i40e_up - Bring the connection back up after being down\n * @vsi: the VSI being configured\n **/\nint i40e_up(struct i40e_vsi *vsi)\n{\n\tint err;\n\n\terr = i40e_vsi_configure(vsi);\n\tif (!err)\n\t\terr = i40e_up_complete(vsi);\n\n\treturn err;\n}\n\n/**\n * i40e_force_link_state - Force the link status\n * @pf: board private structure\n * @is_up: whether the link state should be forced up or down\n **/\nstatic i40e_status i40e_force_link_state(struct i40e_pf *pf, bool is_up)\n{\n\tstruct i40e_aq_get_phy_abilities_resp abilities;\n\tstruct i40e_aq_set_phy_config config = {0};\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status err;\n\tu64 mask;\n\tu8 speed;\n\n\t/* Card might've been put in an unstable state by other drivers\n\t * and applications, which causes incorrect speed values being\n\t * set on startup. In order to clear speed registers, we call\n\t * get_phy_capabilities twice, once to get initial state of\n\t * available speeds, and once to get current PHY config.\n\t */\n\terr = i40e_aq_get_phy_capabilities(hw, false, true, &abilities,\n\t\t\t\t\t   NULL);\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"failed to get phy cap., ret =  %s last_status =  %s\\n\",\n\t\t\ti40e_stat_str(hw, err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn err;\n\t}\n\tspeed = abilities.link_speed;\n\n\t/* Get the current phy config */\n\terr = i40e_aq_get_phy_capabilities(hw, false, false, &abilities,\n\t\t\t\t\t   NULL);\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"failed to get phy cap., ret =  %s last_status =  %s\\n\",\n\t\t\ti40e_stat_str(hw, err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn err;\n\t}\n\n\t/* If link needs to go up, but was not forced to go down,\n\t * and its speed values are OK, no need for a flap\n\t */\n\tif (is_up && abilities.phy_type != 0 && abilities.link_speed != 0)\n\t\treturn I40E_SUCCESS;\n\n\t/* To force link we need to set bits for all supported PHY types,\n\t * but there are now more than 32, so we need to split the bitmap\n\t * across two fields.\n\t */\n\tmask = I40E_PHY_TYPES_BITMASK;\n\tconfig.phy_type = is_up ? cpu_to_le32((u32)(mask & 0xffffffff)) : 0;\n\tconfig.phy_type_ext = is_up ? (u8)((mask >> 32) & 0xff) : 0;\n\t/* Copy the old settings, except of phy_type */\n\tconfig.abilities = abilities.abilities;\n\tif (abilities.link_speed != 0)\n\t\tconfig.link_speed = abilities.link_speed;\n\telse\n\t\tconfig.link_speed = speed;\n\tconfig.eee_capability = abilities.eee_capability;\n\tconfig.eeer = abilities.eeer_val;\n\tconfig.low_power_ctrl = abilities.d3_lpan;\n\tconfig.fec_config = abilities.fec_cfg_curr_mod_ext_info &\n\t\t\t    I40E_AQ_PHY_FEC_CONFIG_MASK;\n\terr = i40e_aq_set_phy_config(hw, &config, NULL);\n\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"set phy config ret =  %s last_status =  %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, err),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn err;\n\t}\n\n\t/* Update the link info */\n\terr = i40e_update_link_info(hw);\n\tif (err) {\n\t\t/* Wait a little bit (on 40G cards it sometimes takes a really\n\t\t * long time for link to come back from the atomic reset)\n\t\t * and try once more\n\t\t */\n\t\tmsleep(1000);\n\t\ti40e_update_link_info(hw);\n\t}\n\n\ti40e_aq_set_link_restart_an(hw, true, NULL);\n\n\treturn I40E_SUCCESS;\n}\n\n/**\n * i40e_down - Shutdown the connection processing\n * @vsi: the VSI being stopped\n **/\nvoid i40e_down(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\t/* It is assumed that the caller of this function\n\t * sets the vsi->state __I40E_VSI_DOWN bit.\n\t */\n\tif (vsi->netdev) {\n\t\tnetif_carrier_off(vsi->netdev);\n\t\tnetif_tx_disable(vsi->netdev);\n\t}\n\ti40e_vsi_disable_irq(vsi);\n\ti40e_vsi_stop_rings(vsi);\n\tif (vsi->type == I40E_VSI_MAIN &&\n\t    vsi->back->flags & I40E_FLAG_LINK_DOWN_ON_CLOSE_ENABLED)\n\t\ti40e_force_link_state(vsi->back, false);\n\ti40e_napi_disable_all(vsi);\n\n\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\ti40e_clean_tx_ring(vsi->tx_rings[i]);\n\t\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t\t/* Make sure that in-progress ndo_xdp_xmit\n\t\t\t * calls are completed.\n\t\t\t */\n\t\t\tsynchronize_rcu();\n\t\t\ti40e_clean_tx_ring(vsi->xdp_rings[i]);\n\t\t}\n\t\ti40e_clean_rx_ring(vsi->rx_rings[i]);\n\t}\n\n}\n\n/**\n * i40e_validate_mqprio_qopt- validate queue mapping info\n * @vsi: the VSI being configured\n * @mqprio_qopt: queue parametrs\n **/\nstatic int i40e_validate_mqprio_qopt(struct i40e_vsi *vsi,\n\t\t\t\t     struct tc_mqprio_qopt_offload *mqprio_qopt)\n{\n\tu64 sum_max_rate = 0;\n\tu64 max_rate = 0;\n\tint i;\n\n\tif (mqprio_qopt->qopt.offset[0] != 0 ||\n\t    mqprio_qopt->qopt.num_tc < 1 ||\n\t    mqprio_qopt->qopt.num_tc > I40E_MAX_TRAFFIC_CLASS)\n\t\treturn -EINVAL;\n\tfor (i = 0; ; i++) {\n\t\tif (!mqprio_qopt->qopt.count[i])\n\t\t\treturn -EINVAL;\n\t\tif (mqprio_qopt->min_rate[i]) {\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"Invalid min tx rate (greater than 0) specified\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmax_rate = mqprio_qopt->max_rate[i];\n\t\tdo_div(max_rate, I40E_BW_MBPS_DIVISOR);\n\t\tsum_max_rate += max_rate;\n\n\t\tif (i >= mqprio_qopt->qopt.num_tc - 1)\n\t\t\tbreak;\n\t\tif (mqprio_qopt->qopt.offset[i + 1] !=\n\t\t    (mqprio_qopt->qopt.offset[i] + mqprio_qopt->qopt.count[i]))\n\t\t\treturn -EINVAL;\n\t}\n\tif (vsi->num_queue_pairs <\n\t    (mqprio_qopt->qopt.offset[i] + mqprio_qopt->qopt.count[i])) {\n\t\treturn -EINVAL;\n\t}\n\tif (sum_max_rate > i40e_get_link_speed(vsi)) {\n\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\"Invalid max tx rate specified\\n\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\n/**\n * i40e_vsi_set_default_tc_config - set default values for tc configuration\n * @vsi: the VSI being configured\n **/\nstatic void i40e_vsi_set_default_tc_config(struct i40e_vsi *vsi)\n{\n\tu16 qcount;\n\tint i;\n\n\t/* Only TC0 is enabled */\n\tvsi->tc_config.numtc = 1;\n\tvsi->tc_config.enabled_tc = 1;\n\tqcount = min_t(int, vsi->alloc_queue_pairs,\n\t\t       i40e_pf_get_max_q_per_tc(vsi->back));\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t/* For the TC that is not enabled set the offset to to default\n\t\t * queue and allocate one queue for the given TC.\n\t\t */\n\t\tvsi->tc_config.tc_info[i].qoffset = 0;\n\t\tif (i == 0)\n\t\t\tvsi->tc_config.tc_info[i].qcount = qcount;\n\t\telse\n\t\t\tvsi->tc_config.tc_info[i].qcount = 1;\n\t\tvsi->tc_config.tc_info[i].netdev_tc = 0;\n\t}\n}\n\n/**\n * i40e_del_macvlan_filter\n * @hw: pointer to the HW structure\n * @seid: seid of the channel VSI\n * @macaddr: the mac address to apply as a filter\n * @aq_err: store the admin Q error\n *\n * This function deletes a mac filter on the channel VSI which serves as the\n * macvlan. Returns 0 on success.\n **/\nstatic i40e_status i40e_del_macvlan_filter(struct i40e_hw *hw, u16 seid,\n\t\t\t\t\t   const u8 *macaddr, int *aq_err)\n{\n\tstruct i40e_aqc_remove_macvlan_element_data element;\n\ti40e_status status;\n\n\tmemset(&element, 0, sizeof(element));\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\telement.flags = I40E_AQC_MACVLAN_DEL_PERFECT_MATCH;\n\tstatus = i40e_aq_remove_macvlan(hw, seid, &element, 1, NULL);\n\t*aq_err = hw->aq.asq_last_status;\n\n\treturn status;\n}\n\n/**\n * i40e_add_macvlan_filter\n * @hw: pointer to the HW structure\n * @seid: seid of the channel VSI\n * @macaddr: the mac address to apply as a filter\n * @aq_err: store the admin Q error\n *\n * This function adds a mac filter on the channel VSI which serves as the\n * macvlan. Returns 0 on success.\n **/\nstatic i40e_status i40e_add_macvlan_filter(struct i40e_hw *hw, u16 seid,\n\t\t\t\t\t   const u8 *macaddr, int *aq_err)\n{\n\tstruct i40e_aqc_add_macvlan_element_data element;\n\ti40e_status status;\n\tu16 cmd_flags = 0;\n\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\telement.queue_number = 0;\n\telement.match_method = I40E_AQC_MM_ERR_NO_RES;\n\tcmd_flags |= I40E_AQC_MACVLAN_ADD_PERFECT_MATCH;\n\telement.flags = cpu_to_le16(cmd_flags);\n\tstatus = i40e_aq_add_macvlan(hw, seid, &element, 1, NULL);\n\t*aq_err = hw->aq.asq_last_status;\n\n\treturn status;\n}\n\n/**\n * i40e_reset_ch_rings - Reset the queue contexts in a channel\n * @vsi: the VSI we want to access\n * @ch: the channel we want to access\n */\nstatic void i40e_reset_ch_rings(struct i40e_vsi *vsi, struct i40e_channel *ch)\n{\n\tstruct i40e_ring *tx_ring, *rx_ring;\n\tu16 pf_q;\n\tint i;\n\n\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\tpf_q = ch->base_queue + i;\n\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\ttx_ring->ch = NULL;\n\t\trx_ring = vsi->rx_rings[pf_q];\n\t\trx_ring->ch = NULL;\n\t}\n}\n\n/**\n * i40e_free_macvlan_channels\n * @vsi: the VSI we want to access\n *\n * This function frees the Qs of the channel VSI from\n * the stack and also deletes the channel VSIs which\n * serve as macvlans.\n */\nstatic void i40e_free_macvlan_channels(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\tint ret;\n\n\tif (list_empty(&vsi->macvlan_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tstruct i40e_vsi *parent_vsi;\n\n\t\tif (i40e_is_channel_macvlan(ch)) {\n\t\t\ti40e_reset_ch_rings(vsi, ch);\n\t\t\tclear_bit(ch->fwd->bit_no, vsi->fwd_bitmask);\n\t\t\tnetdev_unbind_sb_channel(vsi->netdev, ch->fwd->netdev);\n\t\t\tnetdev_set_sb_channel(ch->fwd->netdev, 0);\n\t\t\tkfree(ch->fwd);\n\t\t\tch->fwd = NULL;\n\t\t}\n\n\t\tlist_del(&ch->list);\n\t\tparent_vsi = ch->parent_vsi;\n\t\tif (!parent_vsi || !ch->initialized) {\n\t\t\tkfree(ch);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* remove the VSI */\n\t\tret = i40e_aq_delete_element(&vsi->back->hw, ch->seid,\n\t\t\t\t\t     NULL);\n\t\tif (ret)\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"unable to remove channel (%d) for parent VSI(%d)\\n\",\n\t\t\t\tch->seid, parent_vsi->seid);\n\t\tkfree(ch);\n\t}\n\tvsi->macvlan_cnt = 0;\n}\n\n/**\n * i40e_fwd_ring_up - bring the macvlan device up\n * @vsi: the VSI we want to access\n * @vdev: macvlan netdevice\n * @fwd: the private fwd structure\n */\nstatic int i40e_fwd_ring_up(struct i40e_vsi *vsi, struct net_device *vdev,\n\t\t\t    struct i40e_fwd_adapter *fwd)\n{\n\tint ret = 0, num_tc = 1,  i, aq_err;\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\tif (list_empty(&vsi->macvlan_list))\n\t\treturn -EINVAL;\n\n\t/* Go through the list and find an available channel */\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tif (!i40e_is_channel_macvlan(ch)) {\n\t\t\tch->fwd = fwd;\n\t\t\t/* record configuration for macvlan interface in vdev */\n\t\t\tfor (i = 0; i < num_tc; i++)\n\t\t\t\tnetdev_bind_sb_channel_queue(vsi->netdev, vdev,\n\t\t\t\t\t\t\t     i,\n\t\t\t\t\t\t\t     ch->num_queue_pairs,\n\t\t\t\t\t\t\t     ch->base_queue);\n\t\t\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\t\t\tstruct i40e_ring *tx_ring, *rx_ring;\n\t\t\t\tu16 pf_q;\n\n\t\t\t\tpf_q = ch->base_queue + i;\n\n\t\t\t\t/* Get to TX ring ptr */\n\t\t\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\t\t\ttx_ring->ch = ch;\n\n\t\t\t\t/* Get the RX ring ptr */\n\t\t\t\trx_ring = vsi->rx_rings[pf_q];\n\t\t\t\trx_ring->ch = ch;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Guarantee all rings are updated before we update the\n\t * MAC address filter.\n\t */\n\twmb();\n\n\t/* Add a mac filter */\n\tret = i40e_add_macvlan_filter(hw, ch->seid, vdev->dev_addr, &aq_err);\n\tif (ret) {\n\t\t/* if we cannot add the MAC rule then disable the offload */\n\t\tmacvlan_release_l2fw_offload(vdev);\n\t\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\t\tstruct i40e_ring *rx_ring;\n\t\t\tu16 pf_q;\n\n\t\t\tpf_q = ch->base_queue + i;\n\t\t\trx_ring = vsi->rx_rings[pf_q];\n\t\t\trx_ring->netdev = NULL;\n\t\t}\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Error adding mac filter on macvlan err %s, aq_err %s\\n\",\n\t\t\t  i40e_stat_str(hw, ret),\n\t\t\t  i40e_aq_str(hw, aq_err));\n\t\tnetdev_err(vdev, \"L2fwd offload disabled to L2 filter error\\n\");\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_setup_macvlans - create the channels which will be macvlans\n * @vsi: the VSI we want to access\n * @macvlan_cnt: no. of macvlans to be setup\n * @qcnt: no. of Qs per macvlan\n * @vdev: macvlan netdevice\n */\nstatic int i40e_setup_macvlans(struct i40e_vsi *vsi, u16 macvlan_cnt, u16 qcnt,\n\t\t\t       struct net_device *vdev)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tu16 sections, qmap, num_qps;\n\tstruct i40e_channel *ch;\n\tint i, pow, ret = 0;\n\tu8 offset = 0;\n\n\tif (vsi->type != I40E_VSI_MAIN || !macvlan_cnt)\n\t\treturn -EINVAL;\n\n\tnum_qps = vsi->num_queue_pairs - (macvlan_cnt * qcnt);\n\n\t/* find the next higher power-of-2 of num queue pairs */\n\tpow = fls(roundup_pow_of_two(num_qps) - 1);\n\n\tqmap = (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t(pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t/* Setup context bits for the main VSI */\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tctxt.seid = vsi->seid;\n\tctxt.pf_num = vsi->back->hw.pf_id;\n\tctxt.vf_num = 0;\n\tctxt.uplink_seid = vsi->uplink_seid;\n\tctxt.info = vsi->info;\n\tctxt.info.tc_mapping[0] = cpu_to_le16(qmap);\n\tctxt.info.mapping_flags |= cpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\tctxt.info.queue_mapping[0] = cpu_to_le16(vsi->base_queue);\n\tctxt.info.valid_sections |= cpu_to_le16(sections);\n\n\t/* Reconfigure RSS for main VSI with new max queue count */\n\tvsi->rss_size = max_t(u16, num_qps, qcnt);\n\tret = i40e_vsi_config_rss(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed to reconfig RSS for num_queues (%u)\\n\",\n\t\t\t vsi->rss_size);\n\t\treturn ret;\n\t}\n\tvsi->reconfig_rss = true;\n\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\"Reconfigured RSS with num_queues (%u)\\n\", vsi->rss_size);\n\tvsi->next_base_queue = num_qps;\n\tvsi->cnt_q_avail = vsi->num_queue_pairs - num_qps;\n\n\t/* Update the VSI after updating the VSI queue-mapping\n\t * information\n\t */\n\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Update vsi tc config failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(hw, ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn ret;\n\t}\n\t/* update the local VSI info with updated queue map */\n\ti40e_vsi_update_queue_map(vsi, &ctxt);\n\tvsi->info.valid_sections = 0;\n\n\t/* Create channels for macvlans */\n\tINIT_LIST_HEAD(&vsi->macvlan_list);\n\tfor (i = 0; i < macvlan_cnt; i++) {\n\t\tch = kzalloc(sizeof(*ch), GFP_KERNEL);\n\t\tif (!ch) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_free;\n\t\t}\n\t\tINIT_LIST_HEAD(&ch->list);\n\t\tch->num_queue_pairs = qcnt;\n\t\tif (!i40e_setup_channel(pf, vsi, ch)) {\n\t\t\tret = -EINVAL;\n\t\t\tkfree(ch);\n\t\t\tgoto err_free;\n\t\t}\n\t\tch->parent_vsi = vsi;\n\t\tvsi->cnt_q_avail -= ch->num_queue_pairs;\n\t\tvsi->macvlan_cnt++;\n\t\tlist_add_tail(&ch->list, &vsi->macvlan_list);\n\t}\n\n\treturn ret;\n\nerr_free:\n\tdev_info(&pf->pdev->dev, \"Failed to setup macvlans\\n\");\n\ti40e_free_macvlan_channels(vsi);\n\n\treturn ret;\n}\n\n/**\n * i40e_fwd_add - configure macvlans\n * @netdev: net device to configure\n * @vdev: macvlan netdevice\n **/\nstatic void *i40e_fwd_add(struct net_device *netdev, struct net_device *vdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tu16 q_per_macvlan = 0, macvlan_cnt = 0, vectors;\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_fwd_adapter *fwd;\n\tint avail_macvlan, ret;\n\n\tif ((pf->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\tnetdev_info(netdev, \"Macvlans are not supported when DCB is enabled\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tif ((pf->flags & I40E_FLAG_TC_MQPRIO)) {\n\t\tnetdev_info(netdev, \"Macvlans are not supported when HW TC offload is on\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tif (pf->num_lan_msix < I40E_MIN_MACVLAN_VECTORS) {\n\t\tnetdev_info(netdev, \"Not enough vectors available to support macvlans\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\t/* The macvlan device has to be a single Q device so that the\n\t * tc_to_txq field can be reused to pick the tx queue.\n\t */\n\tif (netif_is_multiqueue(vdev))\n\t\treturn ERR_PTR(-ERANGE);\n\n\tif (!vsi->macvlan_cnt) {\n\t\t/* reserve bit 0 for the pf device */\n\t\tset_bit(0, vsi->fwd_bitmask);\n\n\t\t/* Try to reserve as many queues as possible for macvlans. First\n\t\t * reserve 3/4th of max vectors, then half, then quarter and\n\t\t * calculate Qs per macvlan as you go\n\t\t */\n\t\tvectors = pf->num_lan_msix;\n\t\tif (vectors <= I40E_MAX_MACVLANS && vectors > 64) {\n\t\t\t/* allocate 4 Qs per macvlan and 32 Qs to the PF*/\n\t\t\tq_per_macvlan = 4;\n\t\t\tmacvlan_cnt = (vectors - 32) / 4;\n\t\t} else if (vectors <= 64 && vectors > 32) {\n\t\t\t/* allocate 2 Qs per macvlan and 16 Qs to the PF*/\n\t\t\tq_per_macvlan = 2;\n\t\t\tmacvlan_cnt = (vectors - 16) / 2;\n\t\t} else if (vectors <= 32 && vectors > 16) {\n\t\t\t/* allocate 1 Q per macvlan and 16 Qs to the PF*/\n\t\t\tq_per_macvlan = 1;\n\t\t\tmacvlan_cnt = vectors - 16;\n\t\t} else if (vectors <= 16 && vectors > 8) {\n\t\t\t/* allocate 1 Q per macvlan and 8 Qs to the PF */\n\t\t\tq_per_macvlan = 1;\n\t\t\tmacvlan_cnt = vectors - 8;\n\t\t} else {\n\t\t\t/* allocate 1 Q per macvlan and 1 Q to the PF */\n\t\t\tq_per_macvlan = 1;\n\t\t\tmacvlan_cnt = vectors - 1;\n\t\t}\n\n\t\tif (macvlan_cnt == 0)\n\t\t\treturn ERR_PTR(-EBUSY);\n\n\t\t/* Quiesce VSI queues */\n\t\ti40e_quiesce_vsi(vsi);\n\n\t\t/* sets up the macvlans but does not \"enable\" them */\n\t\tret = i40e_setup_macvlans(vsi, macvlan_cnt, q_per_macvlan,\n\t\t\t\t\t  vdev);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\n\t\t/* Unquiesce VSI */\n\t\ti40e_unquiesce_vsi(vsi);\n\t}\n\tavail_macvlan = find_first_zero_bit(vsi->fwd_bitmask,\n\t\t\t\t\t    vsi->macvlan_cnt);\n\tif (avail_macvlan >= I40E_MAX_MACVLANS)\n\t\treturn ERR_PTR(-EBUSY);\n\n\t/* create the fwd struct */\n\tfwd = kzalloc(sizeof(*fwd), GFP_KERNEL);\n\tif (!fwd)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tset_bit(avail_macvlan, vsi->fwd_bitmask);\n\tfwd->bit_no = avail_macvlan;\n\tnetdev_set_sb_channel(vdev, avail_macvlan);\n\tfwd->netdev = vdev;\n\n\tif (!netif_running(netdev))\n\t\treturn fwd;\n\n\t/* Set fwd ring up */\n\tret = i40e_fwd_ring_up(vsi, vdev, fwd);\n\tif (ret) {\n\t\t/* unbind the queues and drop the subordinate channel config */\n\t\tnetdev_unbind_sb_channel(netdev, vdev);\n\t\tnetdev_set_sb_channel(vdev, 0);\n\n\t\tkfree(fwd);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\treturn fwd;\n}\n\n/**\n * i40e_del_all_macvlans - Delete all the mac filters on the channels\n * @vsi: the VSI we want to access\n */\nstatic void i40e_del_all_macvlans(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint aq_err, ret = 0;\n\n\tif (list_empty(&vsi->macvlan_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tif (i40e_is_channel_macvlan(ch)) {\n\t\t\tret = i40e_del_macvlan_filter(hw, ch->seid,\n\t\t\t\t\t\t      i40e_channel_mac(ch),\n\t\t\t\t\t\t      &aq_err);\n\t\t\tif (!ret) {\n\t\t\t\t/* Reset queue contexts */\n\t\t\t\ti40e_reset_ch_rings(vsi, ch);\n\t\t\t\tclear_bit(ch->fwd->bit_no, vsi->fwd_bitmask);\n\t\t\t\tnetdev_unbind_sb_channel(vsi->netdev,\n\t\t\t\t\t\t\t ch->fwd->netdev);\n\t\t\t\tnetdev_set_sb_channel(ch->fwd->netdev, 0);\n\t\t\t\tkfree(ch->fwd);\n\t\t\t\tch->fwd = NULL;\n\t\t\t}\n\t\t}\n\t}\n}\n\n/**\n * i40e_fwd_del - delete macvlan interfaces\n * @netdev: net device to configure\n * @vdev: macvlan netdevice\n */\nstatic void i40e_fwd_del(struct net_device *netdev, void *vdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_fwd_adapter *fwd = vdev;\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint aq_err, ret = 0;\n\n\t/* Find the channel associated with the macvlan and del mac filter */\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tif (i40e_is_channel_macvlan(ch) &&\n\t\t    ether_addr_equal(i40e_channel_mac(ch),\n\t\t\t\t     fwd->netdev->dev_addr)) {\n\t\t\tret = i40e_del_macvlan_filter(hw, ch->seid,\n\t\t\t\t\t\t      i40e_channel_mac(ch),\n\t\t\t\t\t\t      &aq_err);\n\t\t\tif (!ret) {\n\t\t\t\t/* Reset queue contexts */\n\t\t\t\ti40e_reset_ch_rings(vsi, ch);\n\t\t\t\tclear_bit(ch->fwd->bit_no, vsi->fwd_bitmask);\n\t\t\t\tnetdev_unbind_sb_channel(netdev, fwd->netdev);\n\t\t\t\tnetdev_set_sb_channel(fwd->netdev, 0);\n\t\t\t\tkfree(ch->fwd);\n\t\t\t\tch->fwd = NULL;\n\t\t\t} else {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"Error deleting mac filter on macvlan err %s, aq_err %s\\n\",\n\t\t\t\t\t  i40e_stat_str(hw, ret),\n\t\t\t\t\t  i40e_aq_str(hw, aq_err));\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n/**\n * i40e_setup_tc - configure multiple traffic classes\n * @netdev: net device to configure\n * @type_data: tc offload data\n **/\nstatic int i40e_setup_tc(struct net_device *netdev, void *type_data)\n{\n\tstruct tc_mqprio_qopt_offload *mqprio_qopt = type_data;\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 enabled_tc = 0, num_tc, hw;\n\tbool need_reset = false;\n\tint old_queue_pairs;\n\tint ret = -EINVAL;\n\tu16 mode;\n\tint i;\n\n\told_queue_pairs = vsi->num_queue_pairs;\n\tnum_tc = mqprio_qopt->qopt.num_tc;\n\thw = mqprio_qopt->qopt.hw;\n\tmode = mqprio_qopt->mode;\n\tif (!hw) {\n\t\tpf->flags &= ~I40E_FLAG_TC_MQPRIO;\n\t\tmemcpy(&vsi->mqprio_qopt, mqprio_qopt, sizeof(*mqprio_qopt));\n\t\tgoto config_tc;\n\t}\n\n\t/* Check if MFP enabled */\n\tif (pf->flags & I40E_FLAG_MFP_ENABLED) {\n\t\tnetdev_info(netdev,\n\t\t\t    \"Configuring TC not supported in MFP mode\\n\");\n\t\treturn ret;\n\t}\n\tswitch (mode) {\n\tcase TC_MQPRIO_MODE_DCB:\n\t\tpf->flags &= ~I40E_FLAG_TC_MQPRIO;\n\n\t\t/* Check if DCB enabled to continue */\n\t\tif (!(pf->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"DCB is not enabled for adapter\\n\");\n\t\t\treturn ret;\n\t\t}\n\n\t\t/* Check whether tc count is within enabled limit */\n\t\tif (num_tc > i40e_pf_get_num_tc(pf)) {\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"TC count greater than enabled on link for adapter\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tbreak;\n\tcase TC_MQPRIO_MODE_CHANNEL:\n\t\tif (pf->flags & I40E_FLAG_DCB_ENABLED) {\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"Full offload of TC Mqprio options is not supported when DCB is enabled\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\t\treturn ret;\n\t\tret = i40e_validate_mqprio_qopt(vsi, mqprio_qopt);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tmemcpy(&vsi->mqprio_qopt, mqprio_qopt,\n\t\t       sizeof(*mqprio_qopt));\n\t\tpf->flags |= I40E_FLAG_TC_MQPRIO;\n\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\nconfig_tc:\n\t/* Generate TC map for number of tc requested */\n\tfor (i = 0; i < num_tc; i++)\n\t\tenabled_tc |= BIT(i);\n\n\t/* Requesting same TC configuration as already enabled */\n\tif (enabled_tc == vsi->tc_config.enabled_tc &&\n\t    mode != TC_MQPRIO_MODE_CHANNEL)\n\t\treturn 0;\n\n\t/* Quiesce VSI queues */\n\ti40e_quiesce_vsi(vsi);\n\n\tif (!hw && !(pf->flags & I40E_FLAG_TC_MQPRIO))\n\t\ti40e_remove_queue_channels(vsi);\n\n\t/* Configure VSI for enabled TCs */\n\tret = i40e_vsi_config_tc(vsi, enabled_tc);\n\tif (ret) {\n\t\tnetdev_info(netdev, \"Failed configuring TC for VSI seid=%d\\n\",\n\t\t\t    vsi->seid);\n\t\tneed_reset = true;\n\t\tgoto exit;\n\t} else {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Setup channel (id:%u) utilizing num_queues %d\\n\",\n\t\t\t vsi->seid, vsi->tc_config.tc_info[0].qcount);\n\t}\n\n\tif (pf->flags & I40E_FLAG_TC_MQPRIO) {\n\t\tif (vsi->mqprio_qopt.max_rate[0]) {\n\t\t\tu64 max_tx_rate = vsi->mqprio_qopt.max_rate[0];\n\n\t\t\tdo_div(max_tx_rate, I40E_BW_MBPS_DIVISOR);\n\t\t\tret = i40e_set_bw_limit(vsi, vsi->seid, max_tx_rate);\n\t\t\tif (!ret) {\n\t\t\t\tu64 credits = max_tx_rate;\n\n\t\t\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\t\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\t\t\tmax_tx_rate,\n\t\t\t\t\tcredits,\n\t\t\t\t\tvsi->seid);\n\t\t\t} else {\n\t\t\t\tneed_reset = true;\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tret = i40e_configure_queue_channels(vsi);\n\t\tif (ret) {\n\t\t\tvsi->num_queue_pairs = old_queue_pairs;\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"Failed configuring queue channels\\n\");\n\t\t\tneed_reset = true;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\nexit:\n\t/* Reset the configuration data to defaults, only TC0 is enabled */\n\tif (need_reset) {\n\t\ti40e_vsi_set_default_tc_config(vsi);\n\t\tneed_reset = false;\n\t}\n\n\t/* Unquiesce VSI */\n\ti40e_unquiesce_vsi(vsi);\n\treturn ret;\n}\n\n/**\n * i40e_set_cld_element - sets cloud filter element data\n * @filter: cloud filter rule\n * @cld: ptr to cloud filter element data\n *\n * This is helper function to copy data into cloud filter element\n **/\nstatic inline void\ni40e_set_cld_element(struct i40e_cloud_filter *filter,\n\t\t     struct i40e_aqc_cloud_filters_element_data *cld)\n{\n\tint i, j;\n\tu32 ipa;\n\n\tmemset(cld, 0, sizeof(*cld));\n\tether_addr_copy(cld->outer_mac, filter->dst_mac);\n\tether_addr_copy(cld->inner_mac, filter->src_mac);\n\n\tif (filter->n_proto != ETH_P_IP && filter->n_proto != ETH_P_IPV6)\n\t\treturn;\n\n\tif (filter->n_proto == ETH_P_IPV6) {\n#define IPV6_MAX_INDEX\t(ARRAY_SIZE(filter->dst_ipv6) - 1)\n\t\tfor (i = 0, j = 0; i < ARRAY_SIZE(filter->dst_ipv6);\n\t\t     i++, j += 2) {\n\t\t\tipa = be32_to_cpu(filter->dst_ipv6[IPV6_MAX_INDEX - i]);\n\t\t\tipa = cpu_to_le32(ipa);\n\t\t\tmemcpy(&cld->ipaddr.raw_v6.data[j], &ipa, sizeof(ipa));\n\t\t}\n\t} else {\n\t\tipa = be32_to_cpu(filter->dst_ipv4);\n\t\tmemcpy(&cld->ipaddr.v4.data, &ipa, sizeof(ipa));\n\t}\n\n\tcld->inner_vlan = cpu_to_le16(ntohs(filter->vlan_id));\n\n\t/* tenant_id is not supported by FW now, once the support is enabled\n\t * fill the cld->tenant_id with cpu_to_le32(filter->tenant_id)\n\t */\n\tif (filter->tenant_id)\n\t\treturn;\n}\n\n/**\n * i40e_add_del_cloud_filter - Add/del cloud filter\n * @vsi: pointer to VSI\n * @filter: cloud filter rule\n * @add: if true, add, if false, delete\n *\n * Add or delete a cloud filter for a specific flow spec.\n * Returns 0 if the filter were successfully added.\n **/\nint i40e_add_del_cloud_filter(struct i40e_vsi *vsi,\n\t\t\t      struct i40e_cloud_filter *filter, bool add)\n{\n\tstruct i40e_aqc_cloud_filters_element_data cld_filter;\n\tstruct i40e_pf *pf = vsi->back;\n\tint ret;\n\tstatic const u16 flag_table[128] = {\n\t\t[I40E_CLOUD_FILTER_FLAGS_OMAC]  =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_OMAC,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC]  =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC_IVLAN]  =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC_IVLAN,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC_TEN_ID] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC_TEN_ID,\n\t\t[I40E_CLOUD_FILTER_FLAGS_OMAC_TEN_ID_IMAC] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_OMAC_TEN_ID_IMAC,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC_IVLAN_TEN_ID] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC_IVLAN_TEN_ID,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IIP] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IIP,\n\t};\n\n\tif (filter->flags >= ARRAY_SIZE(flag_table))\n\t\treturn I40E_ERR_CONFIG;\n\n\t/* copy element needed to add cloud filter from filter */\n\ti40e_set_cld_element(filter, &cld_filter);\n\n\tif (filter->tunnel_type != I40E_CLOUD_TNL_TYPE_NONE)\n\t\tcld_filter.flags = cpu_to_le16(filter->tunnel_type <<\n\t\t\t\t\t     I40E_AQC_ADD_CLOUD_TNL_TYPE_SHIFT);\n\n\tif (filter->n_proto == ETH_P_IPV6)\n\t\tcld_filter.flags |= cpu_to_le16(flag_table[filter->flags] |\n\t\t\t\t\t\tI40E_AQC_ADD_CLOUD_FLAGS_IPV6);\n\telse\n\t\tcld_filter.flags |= cpu_to_le16(flag_table[filter->flags] |\n\t\t\t\t\t\tI40E_AQC_ADD_CLOUD_FLAGS_IPV4);\n\n\tif (add)\n\t\tret = i40e_aq_add_cloud_filters(&pf->hw, filter->seid,\n\t\t\t\t\t\t&cld_filter, 1);\n\telse\n\t\tret = i40e_aq_rem_cloud_filters(&pf->hw, filter->seid,\n\t\t\t\t\t\t&cld_filter, 1);\n\tif (ret)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Failed to %s cloud filter using l4 port %u, err %d aq_err %d\\n\",\n\t\t\tadd ? \"add\" : \"delete\", filter->dst_port, ret,\n\t\t\tpf->hw.aq.asq_last_status);\n\telse\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"%s cloud filter for VSI: %d\\n\",\n\t\t\t add ? \"Added\" : \"Deleted\", filter->seid);\n\treturn ret;\n}\n\n/**\n * i40e_add_del_cloud_filter_big_buf - Add/del cloud filter using big_buf\n * @vsi: pointer to VSI\n * @filter: cloud filter rule\n * @add: if true, add, if false, delete\n *\n * Add or delete a cloud filter for a specific flow spec using big buffer.\n * Returns 0 if the filter were successfully added.\n **/\nint i40e_add_del_cloud_filter_big_buf(struct i40e_vsi *vsi,\n\t\t\t\t      struct i40e_cloud_filter *filter,\n\t\t\t\t      bool add)\n{\n\tstruct i40e_aqc_cloud_filters_element_bb cld_filter;\n\tstruct i40e_pf *pf = vsi->back;\n\tint ret;\n\n\t/* Both (src/dst) valid mac_addr are not supported */\n\tif ((is_valid_ether_addr(filter->dst_mac) &&\n\t     is_valid_ether_addr(filter->src_mac)) ||\n\t    (is_multicast_ether_addr(filter->dst_mac) &&\n\t     is_multicast_ether_addr(filter->src_mac)))\n\t\treturn -EOPNOTSUPP;\n\n\t/* Big buffer cloud filter needs 'L4 port' to be non-zero. Also, UDP\n\t * ports are not supported via big buffer now.\n\t */\n\tif (!filter->dst_port || filter->ip_proto == IPPROTO_UDP)\n\t\treturn -EOPNOTSUPP;\n\n\t/* adding filter using src_port/src_ip is not supported at this stage */\n\tif (filter->src_port || filter->src_ipv4 ||\n\t    !ipv6_addr_any(&filter->ip.v6.src_ip6))\n\t\treturn -EOPNOTSUPP;\n\n\t/* copy element needed to add cloud filter from filter */\n\ti40e_set_cld_element(filter, &cld_filter.element);\n\n\tif (is_valid_ether_addr(filter->dst_mac) ||\n\t    is_valid_ether_addr(filter->src_mac) ||\n\t    is_multicast_ether_addr(filter->dst_mac) ||\n\t    is_multicast_ether_addr(filter->src_mac)) {\n\t\t/* MAC + IP : unsupported mode */\n\t\tif (filter->dst_ipv4)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\t/* since we validated that L4 port must be valid before\n\t\t * we get here, start with respective \"flags\" value\n\t\t * and update if vlan is present or not\n\t\t */\n\t\tcld_filter.element.flags =\n\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FILTER_MAC_PORT);\n\n\t\tif (filter->vlan_id) {\n\t\t\tcld_filter.element.flags =\n\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FILTER_MAC_VLAN_PORT);\n\t\t}\n\n\t} else if (filter->dst_ipv4 ||\n\t\t   !ipv6_addr_any(&filter->ip.v6.dst_ip6)) {\n\t\tcld_filter.element.flags =\n\t\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FILTER_IP_PORT);\n\t\tif (filter->n_proto == ETH_P_IPV6)\n\t\t\tcld_filter.element.flags |=\n\t\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FLAGS_IPV6);\n\t\telse\n\t\t\tcld_filter.element.flags |=\n\t\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FLAGS_IPV4);\n\t} else {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"either mac or ip has to be valid for cloud filter\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Now copy L4 port in Byte 6..7 in general fields */\n\tcld_filter.general_fields[I40E_AQC_ADD_CLOUD_FV_FLU_0X16_WORD0] =\n\t\t\t\t\t\tbe16_to_cpu(filter->dst_port);\n\n\tif (add) {\n\t\t/* Validate current device switch mode, change if necessary */\n\t\tret = i40e_validate_and_set_switch_mode(vsi);\n\t\tif (ret) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"failed to set switch mode, ret %d\\n\",\n\t\t\t\tret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = i40e_aq_add_cloud_filters_bb(&pf->hw, filter->seid,\n\t\t\t\t\t\t   &cld_filter, 1);\n\t} else {\n\t\tret = i40e_aq_rem_cloud_filters_bb(&pf->hw, filter->seid,\n\t\t\t\t\t\t   &cld_filter, 1);\n\t}\n\n\tif (ret)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Failed to %s cloud filter(big buffer) err %d aq_err %d\\n\",\n\t\t\tadd ? \"add\" : \"delete\", ret, pf->hw.aq.asq_last_status);\n\telse\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"%s cloud filter for VSI: %d, L4 port: %d\\n\",\n\t\t\t add ? \"add\" : \"delete\", filter->seid,\n\t\t\t ntohs(filter->dst_port));\n\treturn ret;\n}\n\n/**\n * i40e_parse_cls_flower - Parse tc flower filters provided by kernel\n * @vsi: Pointer to VSI\n * @cls_flower: Pointer to struct flow_cls_offload\n * @filter: Pointer to cloud filter structure\n *\n **/\nstatic int i40e_parse_cls_flower(struct i40e_vsi *vsi,\n\t\t\t\t struct flow_cls_offload *f,\n\t\t\t\t struct i40e_cloud_filter *filter)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(f);\n\tstruct flow_dissector *dissector = rule->match.dissector;\n\tu16 n_proto_mask = 0, n_proto_key = 0, addr_type = 0;\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 field_flags = 0;\n\n\tif (dissector->used_keys &\n\t    ~(BIT(FLOW_DISSECTOR_KEY_CONTROL) |\n\t      BIT(FLOW_DISSECTOR_KEY_BASIC) |\n\t      BIT(FLOW_DISSECTOR_KEY_ETH_ADDRS) |\n\t      BIT(FLOW_DISSECTOR_KEY_VLAN) |\n\t      BIT(FLOW_DISSECTOR_KEY_IPV4_ADDRS) |\n\t      BIT(FLOW_DISSECTOR_KEY_IPV6_ADDRS) |\n\t      BIT(FLOW_DISSECTOR_KEY_PORTS) |\n\t      BIT(FLOW_DISSECTOR_KEY_ENC_KEYID))) {\n\t\tdev_err(&pf->pdev->dev, \"Unsupported key used: 0x%x\\n\",\n\t\t\tdissector->used_keys);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ENC_KEYID)) {\n\t\tstruct flow_match_enc_keyid match;\n\n\t\tflow_rule_match_enc_keyid(rule, &match);\n\t\tif (match.mask->keyid != 0)\n\t\t\tfield_flags |= I40E_CLOUD_FIELD_TEN_ID;\n\n\t\tfilter->tenant_id = be32_to_cpu(match.key->keyid);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_BASIC)) {\n\t\tstruct flow_match_basic match;\n\n\t\tflow_rule_match_basic(rule, &match);\n\t\tn_proto_key = ntohs(match.key->n_proto);\n\t\tn_proto_mask = ntohs(match.mask->n_proto);\n\n\t\tif (n_proto_key == ETH_P_ALL) {\n\t\t\tn_proto_key = 0;\n\t\t\tn_proto_mask = 0;\n\t\t}\n\t\tfilter->n_proto = n_proto_key & n_proto_mask;\n\t\tfilter->ip_proto = match.key->ip_proto;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tstruct flow_match_eth_addrs match;\n\n\t\tflow_rule_match_eth_addrs(rule, &match);\n\n\t\t/* use is_broadcast and is_zero to check for all 0xf or 0 */\n\t\tif (!is_zero_ether_addr(match.mask->dst)) {\n\t\t\tif (is_broadcast_ether_addr(match.mask->dst)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_OMAC;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ether dest mask %pM\\n\",\n\t\t\t\t\tmatch.mask->dst);\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tif (!is_zero_ether_addr(match.mask->src)) {\n\t\t\tif (is_broadcast_ether_addr(match.mask->src)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IMAC;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ether src mask %pM\\n\",\n\t\t\t\t\tmatch.mask->src);\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\t\tether_addr_copy(filter->dst_mac, match.key->dst);\n\t\tether_addr_copy(filter->src_mac, match.key->src);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_VLAN)) {\n\t\tstruct flow_match_vlan match;\n\n\t\tflow_rule_match_vlan(rule, &match);\n\t\tif (match.mask->vlan_id) {\n\t\t\tif (match.mask->vlan_id == VLAN_VID_MASK) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IVLAN;\n\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad vlan mask 0x%04x\\n\",\n\t\t\t\t\tmatch.mask->vlan_id);\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tfilter->vlan_id = cpu_to_be16(match.key->vlan_id);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_CONTROL)) {\n\t\tstruct flow_match_control match;\n\n\t\tflow_rule_match_control(rule, &match);\n\t\taddr_type = match.key->addr_type;\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {\n\t\tstruct flow_match_ipv4_addrs match;\n\n\t\tflow_rule_match_ipv4_addrs(rule, &match);\n\t\tif (match.mask->dst) {\n\t\t\tif (match.mask->dst == cpu_to_be32(0xffffffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ip dst mask %pI4b\\n\",\n\t\t\t\t\t&match.mask->dst);\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tif (match.mask->src) {\n\t\t\tif (match.mask->src == cpu_to_be32(0xffffffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ip src mask %pI4b\\n\",\n\t\t\t\t\t&match.mask->src);\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tif (field_flags & I40E_CLOUD_FIELD_TEN_ID) {\n\t\t\tdev_err(&pf->pdev->dev, \"Tenant id not allowed for ip filter\\n\");\n\t\t\treturn I40E_ERR_CONFIG;\n\t\t}\n\t\tfilter->dst_ipv4 = match.key->dst;\n\t\tfilter->src_ipv4 = match.key->src;\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV6_ADDRS) {\n\t\tstruct flow_match_ipv6_addrs match;\n\n\t\tflow_rule_match_ipv6_addrs(rule, &match);\n\n\t\t/* src and dest IPV6 address should not be LOOPBACK\n\t\t * (0:0:0:0:0:0:0:1), which can be represented as ::1\n\t\t */\n\t\tif (ipv6_addr_loopback(&match.key->dst) ||\n\t\t    ipv6_addr_loopback(&match.key->src)) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Bad ipv6, addr is LOOPBACK\\n\");\n\t\t\treturn I40E_ERR_CONFIG;\n\t\t}\n\t\tif (!ipv6_addr_any(&match.mask->dst) ||\n\t\t    !ipv6_addr_any(&match.mask->src))\n\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\n\t\tmemcpy(&filter->src_ipv6, &match.key->src.s6_addr32,\n\t\t       sizeof(filter->src_ipv6));\n\t\tmemcpy(&filter->dst_ipv6, &match.key->dst.s6_addr32,\n\t\t       sizeof(filter->dst_ipv6));\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS)) {\n\t\tstruct flow_match_ports match;\n\n\t\tflow_rule_match_ports(rule, &match);\n\t\tif (match.mask->src) {\n\t\t\tif (match.mask->src == cpu_to_be16(0xffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad src port mask 0x%04x\\n\",\n\t\t\t\t\tbe16_to_cpu(match.mask->src));\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tif (match.mask->dst) {\n\t\t\tif (match.mask->dst == cpu_to_be16(0xffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad dst port mask 0x%04x\\n\",\n\t\t\t\t\tbe16_to_cpu(match.mask->dst));\n\t\t\t\treturn I40E_ERR_CONFIG;\n\t\t\t}\n\t\t}\n\n\t\tfilter->dst_port = match.key->dst;\n\t\tfilter->src_port = match.key->src;\n\n\t\tswitch (filter->ip_proto) {\n\t\tcase IPPROTO_TCP:\n\t\tcase IPPROTO_UDP:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Only UDP and TCP transport are supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tfilter->flags = field_flags;\n\treturn 0;\n}\n\n/**\n * i40e_handle_tclass: Forward to a traffic class on the device\n * @vsi: Pointer to VSI\n * @tc: traffic class index on the device\n * @filter: Pointer to cloud filter structure\n *\n **/\nstatic int i40e_handle_tclass(struct i40e_vsi *vsi, u32 tc,\n\t\t\t      struct i40e_cloud_filter *filter)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\n\t/* direct to a traffic class on the same device */\n\tif (tc == 0) {\n\t\tfilter->seid = vsi->seid;\n\t\treturn 0;\n\t} else if (vsi->tc_config.enabled_tc & BIT(tc)) {\n\t\tif (!filter->dst_port) {\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"Specify destination port to direct to traffic class that is not default\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (list_empty(&vsi->ch_list))\n\t\t\treturn -EINVAL;\n\t\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list,\n\t\t\t\t\t list) {\n\t\t\tif (ch->seid == vsi->tc_seid_map[tc])\n\t\t\t\tfilter->seid = ch->seid;\n\t\t}\n\t\treturn 0;\n\t}\n\tdev_err(&vsi->back->pdev->dev, \"TC is not enabled\\n\");\n\treturn -EINVAL;\n}\n\n/**\n * i40e_configure_clsflower - Configure tc flower filters\n * @vsi: Pointer to VSI\n * @cls_flower: Pointer to struct flow_cls_offload\n *\n **/\nstatic int i40e_configure_clsflower(struct i40e_vsi *vsi,\n\t\t\t\t    struct flow_cls_offload *cls_flower)\n{\n\tint tc = tc_classid_to_hwtc(vsi->netdev, cls_flower->classid);\n\tstruct i40e_cloud_filter *filter = NULL;\n\tstruct i40e_pf *pf = vsi->back;\n\tint err = 0;\n\n\tif (tc < 0) {\n\t\tdev_err(&vsi->back->pdev->dev, \"Invalid traffic class\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state) ||\n\t    test_bit(__I40E_RESET_INTR_RECEIVED, pf->state))\n\t\treturn -EBUSY;\n\n\tif (pf->fdir_pf_active_filters ||\n\t    (!hlist_empty(&pf->fdir_filter_list))) {\n\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\"Flow Director Sideband filters exists, turn ntuple off to configure cloud filters\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (vsi->back->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\"Disable Flow Director Sideband, configuring Cloud filters via tc-flower\\n\");\n\t\tvsi->back->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\tvsi->back->flags |= I40E_FLAG_FD_SB_TO_CLOUD_FILTER;\n\t}\n\n\tfilter = kzalloc(sizeof(*filter), GFP_KERNEL);\n\tif (!filter)\n\t\treturn -ENOMEM;\n\n\tfilter->cookie = cls_flower->cookie;\n\n\terr = i40e_parse_cls_flower(vsi, cls_flower, filter);\n\tif (err < 0)\n\t\tgoto err;\n\n\terr = i40e_handle_tclass(vsi, tc, filter);\n\tif (err < 0)\n\t\tgoto err;\n\n\t/* Add cloud filter */\n\tif (filter->dst_port)\n\t\terr = i40e_add_del_cloud_filter_big_buf(vsi, filter, true);\n\telse\n\t\terr = i40e_add_del_cloud_filter(vsi, filter, true);\n\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to add cloud filter, err %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, err));\n\t\tgoto err;\n\t}\n\n\t/* add filter to the ordered list */\n\tINIT_HLIST_NODE(&filter->cloud_node);\n\n\thlist_add_head(&filter->cloud_node, &pf->cloud_filter_list);\n\n\tpf->num_cloud_filters++;\n\n\treturn err;\nerr:\n\tkfree(filter);\n\treturn err;\n}\n\n/**\n * i40e_find_cloud_filter - Find the could filter in the list\n * @vsi: Pointer to VSI\n * @cookie: filter specific cookie\n *\n **/\nstatic struct i40e_cloud_filter *i40e_find_cloud_filter(struct i40e_vsi *vsi,\n\t\t\t\t\t\t\tunsigned long *cookie)\n{\n\tstruct i40e_cloud_filter *filter = NULL;\n\tstruct hlist_node *node2;\n\n\thlist_for_each_entry_safe(filter, node2,\n\t\t\t\t  &vsi->back->cloud_filter_list, cloud_node)\n\t\tif (!memcmp(cookie, &filter->cookie, sizeof(filter->cookie)))\n\t\t\treturn filter;\n\treturn NULL;\n}\n\n/**\n * i40e_delete_clsflower - Remove tc flower filters\n * @vsi: Pointer to VSI\n * @cls_flower: Pointer to struct flow_cls_offload\n *\n **/\nstatic int i40e_delete_clsflower(struct i40e_vsi *vsi,\n\t\t\t\t struct flow_cls_offload *cls_flower)\n{\n\tstruct i40e_cloud_filter *filter = NULL;\n\tstruct i40e_pf *pf = vsi->back;\n\tint err = 0;\n\n\tfilter = i40e_find_cloud_filter(vsi, &cls_flower->cookie);\n\n\tif (!filter)\n\t\treturn -EINVAL;\n\n\thash_del(&filter->cloud_node);\n\n\tif (filter->dst_port)\n\t\terr = i40e_add_del_cloud_filter_big_buf(vsi, filter, false);\n\telse\n\t\terr = i40e_add_del_cloud_filter(vsi, filter, false);\n\n\tkfree(filter);\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to delete cloud filter, err %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, err));\n\t\treturn i40e_aq_rc_to_posix(err, pf->hw.aq.asq_last_status);\n\t}\n\n\tpf->num_cloud_filters--;\n\tif (!pf->num_cloud_filters)\n\t\tif ((pf->flags & I40E_FLAG_FD_SB_TO_CLOUD_FILTER) &&\n\t\t    !(pf->flags & I40E_FLAG_FD_SB_INACTIVE)) {\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_TO_CLOUD_FILTER;\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_INACTIVE;\n\t\t}\n\treturn 0;\n}\n\n/**\n * i40e_setup_tc_cls_flower - flower classifier offloads\n * @netdev: net device to configure\n * @type_data: offload data\n **/\nstatic int i40e_setup_tc_cls_flower(struct i40e_netdev_priv *np,\n\t\t\t\t    struct flow_cls_offload *cls_flower)\n{\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tswitch (cls_flower->command) {\n\tcase FLOW_CLS_REPLACE:\n\t\treturn i40e_configure_clsflower(vsi, cls_flower);\n\tcase FLOW_CLS_DESTROY:\n\t\treturn i40e_delete_clsflower(vsi, cls_flower);\n\tcase FLOW_CLS_STATS:\n\t\treturn -EOPNOTSUPP;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int i40e_setup_tc_block_cb(enum tc_setup_type type, void *type_data,\n\t\t\t\t  void *cb_priv)\n{\n\tstruct i40e_netdev_priv *np = cb_priv;\n\n\tif (!tc_cls_can_offload_and_chain0(np->vsi->netdev, type_data))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (type) {\n\tcase TC_SETUP_CLSFLOWER:\n\t\treturn i40e_setup_tc_cls_flower(np, type_data);\n\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic LIST_HEAD(i40e_block_cb_list);\n\nstatic int __i40e_setup_tc(struct net_device *netdev, enum tc_setup_type type,\n\t\t\t   void *type_data)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\n\tswitch (type) {\n\tcase TC_SETUP_QDISC_MQPRIO:\n\t\treturn i40e_setup_tc(netdev, type_data);\n\tcase TC_SETUP_BLOCK:\n\t\treturn flow_block_cb_setup_simple(type_data,\n\t\t\t\t\t\t  &i40e_block_cb_list,\n\t\t\t\t\t\t  i40e_setup_tc_block_cb,\n\t\t\t\t\t\t  np, np, true);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n/**\n * i40e_open - Called when a network interface is made active\n * @netdev: network interface device structure\n *\n * The open entry point is called when a network interface is made\n * active by the system (IFF_UP).  At this point all resources needed\n * for transmit and receive operations are allocated, the interrupt\n * handler is registered with the OS, the netdev watchdog subtask is\n * enabled, and the stack is notified that the interface is ready.\n *\n * Returns 0 on success, negative value on failure\n **/\nint i40e_open(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tint err;\n\n\t/* disallow open during test or if eeprom is broken */\n\tif (test_bit(__I40E_TESTING, pf->state) ||\n\t    test_bit(__I40E_BAD_EEPROM, pf->state))\n\t\treturn -EBUSY;\n\n\tnetif_carrier_off(netdev);\n\n\tif (i40e_force_link_state(pf, true))\n\t\treturn -EAGAIN;\n\n\terr = i40e_vsi_open(vsi);\n\tif (err)\n\t\treturn err;\n\n\t/* configure global TSO hardware offload settings */\n\twr32(&pf->hw, I40E_GLLAN_TSOMSK_F, be32_to_cpu(TCP_FLAG_PSH |\n\t\t\t\t\t\t       TCP_FLAG_FIN) >> 16);\n\twr32(&pf->hw, I40E_GLLAN_TSOMSK_M, be32_to_cpu(TCP_FLAG_PSH |\n\t\t\t\t\t\t       TCP_FLAG_FIN |\n\t\t\t\t\t\t       TCP_FLAG_CWR) >> 16);\n\twr32(&pf->hw, I40E_GLLAN_TSOMSK_L, be32_to_cpu(TCP_FLAG_CWR) >> 16);\n\n\tudp_tunnel_get_rx_info(netdev);\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_open -\n * @vsi: the VSI to open\n *\n * Finish initialization of the VSI.\n *\n * Returns 0 on success, negative value on failure\n *\n * Note: expects to be called while under rtnl_lock()\n **/\nint i40e_vsi_open(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tchar int_name[I40E_INT_NAME_STR_LEN];\n\tint err;\n\n\t/* allocate descriptors */\n\terr = i40e_vsi_setup_tx_resources(vsi);\n\tif (err)\n\t\tgoto err_setup_tx;\n\terr = i40e_vsi_setup_rx_resources(vsi);\n\tif (err)\n\t\tgoto err_setup_rx;\n\n\terr = i40e_vsi_configure(vsi);\n\tif (err)\n\t\tgoto err_setup_rx;\n\n\tif (vsi->netdev) {\n\t\tsnprintf(int_name, sizeof(int_name) - 1, \"%s-%s\",\n\t\t\t dev_driver_string(&pf->pdev->dev), vsi->netdev->name);\n\t\terr = i40e_vsi_request_irq(vsi, int_name);\n\t\tif (err)\n\t\t\tgoto err_setup_rx;\n\n\t\t/* Notify the stack of the actual queue counts. */\n\t\terr = netif_set_real_num_tx_queues(vsi->netdev,\n\t\t\t\t\t\t   vsi->num_queue_pairs);\n\t\tif (err)\n\t\t\tgoto err_set_queues;\n\n\t\terr = netif_set_real_num_rx_queues(vsi->netdev,\n\t\t\t\t\t\t   vsi->num_queue_pairs);\n\t\tif (err)\n\t\t\tgoto err_set_queues;\n\n\t} else if (vsi->type == I40E_VSI_FDIR) {\n\t\tsnprintf(int_name, sizeof(int_name) - 1, \"%s-%s:fdir\",\n\t\t\t dev_driver_string(&pf->pdev->dev),\n\t\t\t dev_name(&pf->pdev->dev));\n\t\terr = i40e_vsi_request_irq(vsi, int_name);\n\n\t} else {\n\t\terr = -EINVAL;\n\t\tgoto err_setup_rx;\n\t}\n\n\terr = i40e_up_complete(vsi);\n\tif (err)\n\t\tgoto err_up_complete;\n\n\treturn 0;\n\nerr_up_complete:\n\ti40e_down(vsi);\nerr_set_queues:\n\ti40e_vsi_free_irq(vsi);\nerr_setup_rx:\n\ti40e_vsi_free_rx_resources(vsi);\nerr_setup_tx:\n\ti40e_vsi_free_tx_resources(vsi);\n\tif (vsi == pf->vsi[pf->lan_vsi])\n\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG, true);\n\n\treturn err;\n}\n\n/**\n * i40e_fdir_filter_exit - Cleans up the Flow Director accounting\n * @pf: Pointer to PF\n *\n * This function destroys the hlist where all the Flow Director\n * filters were saved.\n **/\nstatic void i40e_fdir_filter_exit(struct i40e_pf *pf)\n{\n\tstruct i40e_fdir_filter *filter;\n\tstruct i40e_flex_pit *pit_entry, *tmp;\n\tstruct hlist_node *node2;\n\n\thlist_for_each_entry_safe(filter, node2,\n\t\t\t\t  &pf->fdir_filter_list, fdir_node) {\n\t\thlist_del(&filter->fdir_node);\n\t\tkfree(filter);\n\t}\n\n\tlist_for_each_entry_safe(pit_entry, tmp, &pf->l3_flex_pit_list, list) {\n\t\tlist_del(&pit_entry->list);\n\t\tkfree(pit_entry);\n\t}\n\tINIT_LIST_HEAD(&pf->l3_flex_pit_list);\n\n\tlist_for_each_entry_safe(pit_entry, tmp, &pf->l4_flex_pit_list, list) {\n\t\tlist_del(&pit_entry->list);\n\t\tkfree(pit_entry);\n\t}\n\tINIT_LIST_HEAD(&pf->l4_flex_pit_list);\n\n\tpf->fdir_pf_active_filters = 0;\n\tpf->fd_tcp4_filter_cnt = 0;\n\tpf->fd_udp4_filter_cnt = 0;\n\tpf->fd_sctp4_filter_cnt = 0;\n\tpf->fd_ip4_filter_cnt = 0;\n\n\t/* Reprogram the default input set for TCP/IPv4 */\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_TCP,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t/* Reprogram the default input set for UDP/IPv4 */\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_UDP,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t/* Reprogram the default input set for SCTP/IPv4 */\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_SCTP,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t/* Reprogram the default input set for Other/IPv4 */\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_OTHER,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK);\n\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_FRAG_IPV4,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK);\n}\n\n/**\n * i40e_cloud_filter_exit - Cleans up the cloud filters\n * @pf: Pointer to PF\n *\n * This function destroys the hlist where all the cloud filters\n * were saved.\n **/\nstatic void i40e_cloud_filter_exit(struct i40e_pf *pf)\n{\n\tstruct i40e_cloud_filter *cfilter;\n\tstruct hlist_node *node;\n\n\thlist_for_each_entry_safe(cfilter, node,\n\t\t\t\t  &pf->cloud_filter_list, cloud_node) {\n\t\thlist_del(&cfilter->cloud_node);\n\t\tkfree(cfilter);\n\t}\n\tpf->num_cloud_filters = 0;\n\n\tif ((pf->flags & I40E_FLAG_FD_SB_TO_CLOUD_FILTER) &&\n\t    !(pf->flags & I40E_FLAG_FD_SB_INACTIVE)) {\n\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_TO_CLOUD_FILTER;\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_INACTIVE;\n\t}\n}\n\n/**\n * i40e_close - Disables a network interface\n * @netdev: network interface device structure\n *\n * The close entry point is called when an interface is de-activated\n * by the OS.  The hardware is still under the driver's control, but\n * this netdev interface is disabled.\n *\n * Returns 0, this is not allowed to fail\n **/\nint i40e_close(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\ti40e_vsi_close(vsi);\n\n\treturn 0;\n}\n\n/**\n * i40e_do_reset - Start a PF or Core Reset sequence\n * @pf: board private structure\n * @reset_flags: which reset is requested\n * @lock_acquired: indicates whether or not the lock has been acquired\n * before this function was called.\n *\n * The essential difference in resets is that the PF Reset\n * doesn't clear the packet buffers, doesn't reset the PE\n * firmware, and doesn't bother the other PFs on the chip.\n **/\nvoid i40e_do_reset(struct i40e_pf *pf, u32 reset_flags, bool lock_acquired)\n{\n\tu32 val;\n\n\tWARN_ON(in_interrupt());\n\n\n\t/* do the biggest reset indicated */\n\tif (reset_flags & BIT_ULL(__I40E_GLOBAL_RESET_REQUESTED)) {\n\n\t\t/* Request a Global Reset\n\t\t *\n\t\t * This will start the chip's countdown to the actual full\n\t\t * chip reset event, and a warning interrupt to be sent\n\t\t * to all PFs, including the requestor.  Our handler\n\t\t * for the warning interrupt will deal with the shutdown\n\t\t * and recovery of the switch setup.\n\t\t */\n\t\tdev_dbg(&pf->pdev->dev, \"GlobalR requested\\n\");\n\t\tval = rd32(&pf->hw, I40E_GLGEN_RTRIG);\n\t\tval |= I40E_GLGEN_RTRIG_GLOBR_MASK;\n\t\twr32(&pf->hw, I40E_GLGEN_RTRIG, val);\n\n\t} else if (reset_flags & BIT_ULL(__I40E_CORE_RESET_REQUESTED)) {\n\n\t\t/* Request a Core Reset\n\t\t *\n\t\t * Same as Global Reset, except does *not* include the MAC/PHY\n\t\t */\n\t\tdev_dbg(&pf->pdev->dev, \"CoreR requested\\n\");\n\t\tval = rd32(&pf->hw, I40E_GLGEN_RTRIG);\n\t\tval |= I40E_GLGEN_RTRIG_CORER_MASK;\n\t\twr32(&pf->hw, I40E_GLGEN_RTRIG, val);\n\t\ti40e_flush(&pf->hw);\n\n\t} else if (reset_flags & I40E_PF_RESET_FLAG) {\n\n\t\t/* Request a PF Reset\n\t\t *\n\t\t * Resets only the PF-specific registers\n\t\t *\n\t\t * This goes directly to the tear-down and rebuild of\n\t\t * the switch, since we need to do all the recovery as\n\t\t * for the Core Reset.\n\t\t */\n\t\tdev_dbg(&pf->pdev->dev, \"PFR requested\\n\");\n\t\ti40e_handle_reset_warning(pf, lock_acquired);\n\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t pf->flags & I40E_FLAG_DISABLE_FW_LLDP ?\n\t\t\t \"FW LLDP is disabled\\n\" :\n\t\t\t \"FW LLDP is enabled\\n\");\n\n\t} else if (reset_flags & BIT_ULL(__I40E_REINIT_REQUESTED)) {\n\t\tint v;\n\n\t\t/* Find the VSI(s) that requested a re-init */\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI reinit requested\\n\");\n\t\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\t\tstruct i40e_vsi *vsi = pf->vsi[v];\n\n\t\t\tif (vsi != NULL &&\n\t\t\t    test_and_clear_bit(__I40E_VSI_REINIT_REQUESTED,\n\t\t\t\t\t       vsi->state))\n\t\t\t\ti40e_vsi_reinit_locked(pf->vsi[v]);\n\t\t}\n\t} else if (reset_flags & BIT_ULL(__I40E_DOWN_REQUESTED)) {\n\t\tint v;\n\n\t\t/* Find the VSI(s) that needs to be brought down */\n\t\tdev_info(&pf->pdev->dev, \"VSI down requested\\n\");\n\t\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\t\tstruct i40e_vsi *vsi = pf->vsi[v];\n\n\t\t\tif (vsi != NULL &&\n\t\t\t    test_and_clear_bit(__I40E_VSI_DOWN_REQUESTED,\n\t\t\t\t\t       vsi->state)) {\n\t\t\t\tset_bit(__I40E_VSI_DOWN, vsi->state);\n\t\t\t\ti40e_down(vsi);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"bad reset request 0x%08x\\n\", reset_flags);\n\t}\n}\n\n#ifdef CONFIG_I40E_DCB\n/**\n * i40e_dcb_need_reconfig - Check if DCB needs reconfig\n * @pf: board private structure\n * @old_cfg: current DCB config\n * @new_cfg: new DCB config\n **/\nbool i40e_dcb_need_reconfig(struct i40e_pf *pf,\n\t\t\t    struct i40e_dcbx_config *old_cfg,\n\t\t\t    struct i40e_dcbx_config *new_cfg)\n{\n\tbool need_reconfig = false;\n\n\t/* Check if ETS configuration has changed */\n\tif (memcmp(&new_cfg->etscfg,\n\t\t   &old_cfg->etscfg,\n\t\t   sizeof(new_cfg->etscfg))) {\n\t\t/* If Priority Table has changed reconfig is needed */\n\t\tif (memcmp(&new_cfg->etscfg.prioritytable,\n\t\t\t   &old_cfg->etscfg.prioritytable,\n\t\t\t   sizeof(new_cfg->etscfg.prioritytable))) {\n\t\t\tneed_reconfig = true;\n\t\t\tdev_dbg(&pf->pdev->dev, \"ETS UP2TC changed.\\n\");\n\t\t}\n\n\t\tif (memcmp(&new_cfg->etscfg.tcbwtable,\n\t\t\t   &old_cfg->etscfg.tcbwtable,\n\t\t\t   sizeof(new_cfg->etscfg.tcbwtable)))\n\t\t\tdev_dbg(&pf->pdev->dev, \"ETS TC BW Table changed.\\n\");\n\n\t\tif (memcmp(&new_cfg->etscfg.tsatable,\n\t\t\t   &old_cfg->etscfg.tsatable,\n\t\t\t   sizeof(new_cfg->etscfg.tsatable)))\n\t\t\tdev_dbg(&pf->pdev->dev, \"ETS TSA Table changed.\\n\");\n\t}\n\n\t/* Check if PFC configuration has changed */\n\tif (memcmp(&new_cfg->pfc,\n\t\t   &old_cfg->pfc,\n\t\t   sizeof(new_cfg->pfc))) {\n\t\tneed_reconfig = true;\n\t\tdev_dbg(&pf->pdev->dev, \"PFC config change detected.\\n\");\n\t}\n\n\t/* Check if APP Table has changed */\n\tif (memcmp(&new_cfg->app,\n\t\t   &old_cfg->app,\n\t\t   sizeof(new_cfg->app))) {\n\t\tneed_reconfig = true;\n\t\tdev_dbg(&pf->pdev->dev, \"APP Table change detected.\\n\");\n\t}\n\n\tdev_dbg(&pf->pdev->dev, \"dcb need_reconfig=%d\\n\", need_reconfig);\n\treturn need_reconfig;\n}\n\n/**\n * i40e_handle_lldp_event - Handle LLDP Change MIB event\n * @pf: board private structure\n * @e: event info posted on ARQ\n **/\nstatic int i40e_handle_lldp_event(struct i40e_pf *pf,\n\t\t\t\t  struct i40e_arq_event_info *e)\n{\n\tstruct i40e_aqc_lldp_get_mib *mib =\n\t\t(struct i40e_aqc_lldp_get_mib *)&e->desc.params.raw;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_dcbx_config tmp_dcbx_cfg;\n\tbool need_reconfig = false;\n\tint ret = 0;\n\tu8 type;\n\n\t/* Not DCB capable or capability disabled */\n\tif (!(pf->flags & I40E_FLAG_DCB_CAPABLE))\n\t\treturn ret;\n\n\t/* Ignore if event is not for Nearest Bridge */\n\ttype = ((mib->type >> I40E_AQ_LLDP_BRIDGE_TYPE_SHIFT)\n\t\t& I40E_AQ_LLDP_BRIDGE_TYPE_MASK);\n\tdev_dbg(&pf->pdev->dev, \"LLDP event mib bridge type 0x%x\\n\", type);\n\tif (type != I40E_AQ_LLDP_BRIDGE_TYPE_NEAREST_BRIDGE)\n\t\treturn ret;\n\n\t/* Check MIB Type and return if event for Remote MIB update */\n\ttype = mib->type & I40E_AQ_LLDP_MIB_TYPE_MASK;\n\tdev_dbg(&pf->pdev->dev,\n\t\t\"LLDP event mib type %s\\n\", type ? \"remote\" : \"local\");\n\tif (type == I40E_AQ_LLDP_MIB_REMOTE) {\n\t\t/* Update the remote cached instance and return */\n\t\tret = i40e_aq_get_dcb_config(hw, I40E_AQ_LLDP_MIB_REMOTE,\n\t\t\t\tI40E_AQ_LLDP_BRIDGE_TYPE_NEAREST_BRIDGE,\n\t\t\t\t&hw->remote_dcbx_config);\n\t\tgoto exit;\n\t}\n\n\t/* Store the old configuration */\n\ttmp_dcbx_cfg = hw->local_dcbx_config;\n\n\t/* Reset the old DCBx configuration data */\n\tmemset(&hw->local_dcbx_config, 0, sizeof(hw->local_dcbx_config));\n\t/* Get updated DCBX data from firmware */\n\tret = i40e_get_dcb_config(&pf->hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed querying DCB configuration data from firmware, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto exit;\n\t}\n\n\t/* No change detected in DCBX configs */\n\tif (!memcmp(&tmp_dcbx_cfg, &hw->local_dcbx_config,\n\t\t    sizeof(tmp_dcbx_cfg))) {\n\t\tdev_dbg(&pf->pdev->dev, \"No change detected in DCBX configuration.\\n\");\n\t\tgoto exit;\n\t}\n\n\tneed_reconfig = i40e_dcb_need_reconfig(pf, &tmp_dcbx_cfg,\n\t\t\t\t\t       &hw->local_dcbx_config);\n\n\ti40e_dcbnl_flush_apps(pf, &tmp_dcbx_cfg, &hw->local_dcbx_config);\n\n\tif (!need_reconfig)\n\t\tgoto exit;\n\n\t/* Enable DCB tagging only when more than one TC */\n\tif (i40e_dcb_get_num_tc(&hw->local_dcbx_config) > 1)\n\t\tpf->flags |= I40E_FLAG_DCB_ENABLED;\n\telse\n\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\n\tset_bit(__I40E_PORT_SUSPENDED, pf->state);\n\t/* Reconfiguration needed quiesce all VSIs */\n\ti40e_pf_quiesce_all_vsi(pf);\n\n\t/* Changes in configuration update VEB/VSI */\n\ti40e_dcb_reconfigure(pf);\n\n\tret = i40e_resume_port_tx(pf);\n\n\tclear_bit(__I40E_PORT_SUSPENDED, pf->state);\n\t/* In case of error no point in resuming VSIs */\n\tif (ret)\n\t\tgoto exit;\n\n\t/* Wait for the PF's queues to be disabled */\n\tret = i40e_pf_wait_queues_disabled(pf);\n\tif (ret) {\n\t\t/* Schedule PF reset to recover */\n\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\ti40e_service_event_schedule(pf);\n\t} else {\n\t\ti40e_pf_unquiesce_all_vsi(pf);\n\t\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\t\tset_bit(__I40E_CLIENT_L2_CHANGE, pf->state);\n\t}\n\nexit:\n\treturn ret;\n}\n#endif /* CONFIG_I40E_DCB */\n\n/**\n * i40e_do_reset_safe - Protected reset path for userland calls.\n * @pf: board private structure\n * @reset_flags: which reset is requested\n *\n **/\nvoid i40e_do_reset_safe(struct i40e_pf *pf, u32 reset_flags)\n{\n\trtnl_lock();\n\ti40e_do_reset(pf, reset_flags, true);\n\trtnl_unlock();\n}\n\n/**\n * i40e_handle_lan_overflow_event - Handler for LAN queue overflow event\n * @pf: board private structure\n * @e: event info posted on ARQ\n *\n * Handler for LAN Queue Overflow Event generated by the firmware for PF\n * and VF queues\n **/\nstatic void i40e_handle_lan_overflow_event(struct i40e_pf *pf,\n\t\t\t\t\t   struct i40e_arq_event_info *e)\n{\n\tstruct i40e_aqc_lan_overflow *data =\n\t\t(struct i40e_aqc_lan_overflow *)&e->desc.params.raw;\n\tu32 queue = le32_to_cpu(data->prtdcb_rupto);\n\tu32 qtx_ctl = le32_to_cpu(data->otx_ctl);\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vf *vf;\n\tu16 vf_id;\n\n\tdev_dbg(&pf->pdev->dev, \"overflow Rx Queue Number = %d QTX_CTL=0x%08x\\n\",\n\t\tqueue, qtx_ctl);\n\n\t/* Queue belongs to VF, find the VF and issue VF reset */\n\tif (((qtx_ctl & I40E_QTX_CTL_PFVF_Q_MASK)\n\t    >> I40E_QTX_CTL_PFVF_Q_SHIFT) == I40E_QTX_CTL_VF_QUEUE) {\n\t\tvf_id = (u16)((qtx_ctl & I40E_QTX_CTL_VFVM_INDX_MASK)\n\t\t\t >> I40E_QTX_CTL_VFVM_INDX_SHIFT);\n\t\tvf_id -= hw->func_caps.vf_base_id;\n\t\tvf = &pf->vf[vf_id];\n\t\ti40e_vc_notify_vf_reset(vf);\n\t\t/* Allow VF to process pending reset notification */\n\t\tmsleep(20);\n\t\ti40e_reset_vf(vf, false);\n\t}\n}\n\n/**\n * i40e_get_cur_guaranteed_fd_count - Get the consumed guaranteed FD filters\n * @pf: board private structure\n **/\nu32 i40e_get_cur_guaranteed_fd_count(struct i40e_pf *pf)\n{\n\tu32 val, fcnt_prog;\n\n\tval = rd32(&pf->hw, I40E_PFQF_FDSTAT);\n\tfcnt_prog = (val & I40E_PFQF_FDSTAT_GUARANT_CNT_MASK);\n\treturn fcnt_prog;\n}\n\n/**\n * i40e_get_current_fd_count - Get total FD filters programmed for this PF\n * @pf: board private structure\n **/\nu32 i40e_get_current_fd_count(struct i40e_pf *pf)\n{\n\tu32 val, fcnt_prog;\n\n\tval = rd32(&pf->hw, I40E_PFQF_FDSTAT);\n\tfcnt_prog = (val & I40E_PFQF_FDSTAT_GUARANT_CNT_MASK) +\n\t\t    ((val & I40E_PFQF_FDSTAT_BEST_CNT_MASK) >>\n\t\t      I40E_PFQF_FDSTAT_BEST_CNT_SHIFT);\n\treturn fcnt_prog;\n}\n\n/**\n * i40e_get_global_fd_count - Get total FD filters programmed on device\n * @pf: board private structure\n **/\nu32 i40e_get_global_fd_count(struct i40e_pf *pf)\n{\n\tu32 val, fcnt_prog;\n\n\tval = rd32(&pf->hw, I40E_GLQF_FDCNT_0);\n\tfcnt_prog = (val & I40E_GLQF_FDCNT_0_GUARANT_CNT_MASK) +\n\t\t    ((val & I40E_GLQF_FDCNT_0_BESTCNT_MASK) >>\n\t\t     I40E_GLQF_FDCNT_0_BESTCNT_SHIFT);\n\treturn fcnt_prog;\n}\n\n/**\n * i40e_reenable_fdir_sb - Restore FDir SB capability\n * @pf: board private structure\n **/\nstatic void i40e_reenable_fdir_sb(struct i40e_pf *pf)\n{\n\tif (test_and_clear_bit(__I40E_FD_SB_AUTO_DISABLED, pf->state))\n\t\tif ((pf->flags & I40E_FLAG_FD_SB_ENABLED) &&\n\t\t    (I40E_DEBUG_FD & pf->hw.debug_mask))\n\t\t\tdev_info(&pf->pdev->dev, \"FD Sideband/ntuple is being enabled since we have space in the table now\\n\");\n}\n\n/**\n * i40e_reenable_fdir_atr - Restore FDir ATR capability\n * @pf: board private structure\n **/\nstatic void i40e_reenable_fdir_atr(struct i40e_pf *pf)\n{\n\tif (test_and_clear_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state)) {\n\t\t/* ATR uses the same filtering logic as SB rules. It only\n\t\t * functions properly if the input set mask is at the default\n\t\t * settings. It is safe to restore the default input set\n\t\t * because there are no active TCPv4 filter rules.\n\t\t */\n\t\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_TCP,\n\t\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t\tif ((pf->flags & I40E_FLAG_FD_ATR_ENABLED) &&\n\t\t    (I40E_DEBUG_FD & pf->hw.debug_mask))\n\t\t\tdev_info(&pf->pdev->dev, \"ATR is being enabled since we have space in the table and there are no conflicting ntuple rules\\n\");\n\t}\n}\n\n/**\n * i40e_delete_invalid_filter - Delete an invalid FDIR filter\n * @pf: board private structure\n * @filter: FDir filter to remove\n */\nstatic void i40e_delete_invalid_filter(struct i40e_pf *pf,\n\t\t\t\t       struct i40e_fdir_filter *filter)\n{\n\t/* Update counters */\n\tpf->fdir_pf_active_filters--;\n\tpf->fd_inv = 0;\n\n\tswitch (filter->flow_type) {\n\tcase TCP_V4_FLOW:\n\t\tpf->fd_tcp4_filter_cnt--;\n\t\tbreak;\n\tcase UDP_V4_FLOW:\n\t\tpf->fd_udp4_filter_cnt--;\n\t\tbreak;\n\tcase SCTP_V4_FLOW:\n\t\tpf->fd_sctp4_filter_cnt--;\n\t\tbreak;\n\tcase IP_USER_FLOW:\n\t\tswitch (filter->ip4_proto) {\n\t\tcase IPPROTO_TCP:\n\t\t\tpf->fd_tcp4_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_UDP:\n\t\t\tpf->fd_udp4_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_SCTP:\n\t\t\tpf->fd_sctp4_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_IP:\n\t\t\tpf->fd_ip4_filter_cnt--;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n\n\t/* Remove the filter from the list and free memory */\n\thlist_del(&filter->fdir_node);\n\tkfree(filter);\n}\n\n/**\n * i40e_fdir_check_and_reenable - Function to reenabe FD ATR or SB if disabled\n * @pf: board private structure\n **/\nvoid i40e_fdir_check_and_reenable(struct i40e_pf *pf)\n{\n\tstruct i40e_fdir_filter *filter;\n\tu32 fcnt_prog, fcnt_avail;\n\tstruct hlist_node *node;\n\n\tif (test_bit(__I40E_FD_FLUSH_REQUESTED, pf->state))\n\t\treturn;\n\n\t/* Check if we have enough room to re-enable FDir SB capability. */\n\tfcnt_prog = i40e_get_global_fd_count(pf);\n\tfcnt_avail = pf->fdir_pf_filter_count;\n\tif ((fcnt_prog < (fcnt_avail - I40E_FDIR_BUFFER_HEAD_ROOM)) ||\n\t    (pf->fd_add_err == 0) ||\n\t    (i40e_get_current_atr_cnt(pf) < pf->fd_atr_cnt))\n\t\ti40e_reenable_fdir_sb(pf);\n\n\t/* We should wait for even more space before re-enabling ATR.\n\t * Additionally, we cannot enable ATR as long as we still have TCP SB\n\t * rules active.\n\t */\n\tif ((fcnt_prog < (fcnt_avail - I40E_FDIR_BUFFER_HEAD_ROOM_FOR_ATR)) &&\n\t    (pf->fd_tcp4_filter_cnt == 0))\n\t\ti40e_reenable_fdir_atr(pf);\n\n\t/* if hw had a problem adding a filter, delete it */\n\tif (pf->fd_inv > 0) {\n\t\thlist_for_each_entry_safe(filter, node,\n\t\t\t\t\t  &pf->fdir_filter_list, fdir_node)\n\t\t\tif (filter->fd_id == pf->fd_inv)\n\t\t\t\ti40e_delete_invalid_filter(pf, filter);\n\t}\n}\n\n#define I40E_MIN_FD_FLUSH_INTERVAL 10\n#define I40E_MIN_FD_FLUSH_SB_ATR_UNSTABLE 30\n/**\n * i40e_fdir_flush_and_replay - Function to flush all FD filters and replay SB\n * @pf: board private structure\n **/\nstatic void i40e_fdir_flush_and_replay(struct i40e_pf *pf)\n{\n\tunsigned long min_flush_time;\n\tint flush_wait_retry = 50;\n\tbool disable_atr = false;\n\tint fd_room;\n\tint reg;\n\n\tif (!time_after(jiffies, pf->fd_flush_timestamp +\n\t\t\t\t (I40E_MIN_FD_FLUSH_INTERVAL * HZ)))\n\t\treturn;\n\n\t/* If the flush is happening too quick and we have mostly SB rules we\n\t * should not re-enable ATR for some time.\n\t */\n\tmin_flush_time = pf->fd_flush_timestamp +\n\t\t\t (I40E_MIN_FD_FLUSH_SB_ATR_UNSTABLE * HZ);\n\tfd_room = pf->fdir_pf_filter_count - pf->fdir_pf_active_filters;\n\n\tif (!(time_after(jiffies, min_flush_time)) &&\n\t    (fd_room < I40E_FDIR_BUFFER_HEAD_ROOM_FOR_ATR)) {\n\t\tif (I40E_DEBUG_FD & pf->hw.debug_mask)\n\t\t\tdev_info(&pf->pdev->dev, \"ATR disabled, not enough FD filter space.\\n\");\n\t\tdisable_atr = true;\n\t}\n\n\tpf->fd_flush_timestamp = jiffies;\n\tset_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state);\n\t/* flush all filters */\n\twr32(&pf->hw, I40E_PFQF_CTL_1,\n\t     I40E_PFQF_CTL_1_CLEARFDTABLE_MASK);\n\ti40e_flush(&pf->hw);\n\tpf->fd_flush_cnt++;\n\tpf->fd_add_err = 0;\n\tdo {\n\t\t/* Check FD flush status every 5-6msec */\n\t\tusleep_range(5000, 6000);\n\t\treg = rd32(&pf->hw, I40E_PFQF_CTL_1);\n\t\tif (!(reg & I40E_PFQF_CTL_1_CLEARFDTABLE_MASK))\n\t\t\tbreak;\n\t} while (flush_wait_retry--);\n\tif (reg & I40E_PFQF_CTL_1_CLEARFDTABLE_MASK) {\n\t\tdev_warn(&pf->pdev->dev, \"FD table did not flush, needs more time\\n\");\n\t} else {\n\t\t/* replay sideband filters */\n\t\ti40e_fdir_filter_restore(pf->vsi[pf->lan_vsi]);\n\t\tif (!disable_atr && !pf->fd_tcp4_filter_cnt)\n\t\t\tclear_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state);\n\t\tclear_bit(__I40E_FD_FLUSH_REQUESTED, pf->state);\n\t\tif (I40E_DEBUG_FD & pf->hw.debug_mask)\n\t\t\tdev_info(&pf->pdev->dev, \"FD Filter table flushed and FD-SB replayed.\\n\");\n\t}\n}\n\n/**\n * i40e_get_current_atr_count - Get the count of total FD ATR filters programmed\n * @pf: board private structure\n **/\nu32 i40e_get_current_atr_cnt(struct i40e_pf *pf)\n{\n\treturn i40e_get_current_fd_count(pf) - pf->fdir_pf_active_filters;\n}\n\n/* We can see up to 256 filter programming desc in transit if the filters are\n * being applied really fast; before we see the first\n * filter miss error on Rx queue 0. Accumulating enough error messages before\n * reacting will make sure we don't cause flush too often.\n */\n#define I40E_MAX_FD_PROGRAM_ERROR 256\n\n/**\n * i40e_fdir_reinit_subtask - Worker thread to reinit FDIR filter table\n * @pf: board private structure\n **/\nstatic void i40e_fdir_reinit_subtask(struct i40e_pf *pf)\n{\n\n\t/* if interface is down do nothing */\n\tif (test_bit(__I40E_DOWN, pf->state))\n\t\treturn;\n\n\tif (test_bit(__I40E_FD_FLUSH_REQUESTED, pf->state))\n\t\ti40e_fdir_flush_and_replay(pf);\n\n\ti40e_fdir_check_and_reenable(pf);\n\n}\n\n/**\n * i40e_vsi_link_event - notify VSI of a link event\n * @vsi: vsi to be notified\n * @link_up: link up or down\n **/\nstatic void i40e_vsi_link_event(struct i40e_vsi *vsi, bool link_up)\n{\n\tif (!vsi || test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tswitch (vsi->type) {\n\tcase I40E_VSI_MAIN:\n\t\tif (!vsi->netdev || !vsi->netdev_registered)\n\t\t\tbreak;\n\n\t\tif (link_up) {\n\t\t\tnetif_carrier_on(vsi->netdev);\n\t\t\tnetif_tx_wake_all_queues(vsi->netdev);\n\t\t} else {\n\t\t\tnetif_carrier_off(vsi->netdev);\n\t\t\tnetif_tx_stop_all_queues(vsi->netdev);\n\t\t}\n\t\tbreak;\n\n\tcase I40E_VSI_SRIOV:\n\tcase I40E_VSI_VMDQ2:\n\tcase I40E_VSI_CTRL:\n\tcase I40E_VSI_IWARP:\n\tcase I40E_VSI_MIRROR:\n\tdefault:\n\t\t/* there is no notification for other VSIs */\n\t\tbreak;\n\t}\n}\n\n/**\n * i40e_veb_link_event - notify elements on the veb of a link event\n * @veb: veb to be notified\n * @link_up: link up or down\n **/\nstatic void i40e_veb_link_event(struct i40e_veb *veb, bool link_up)\n{\n\tstruct i40e_pf *pf;\n\tint i;\n\n\tif (!veb || !veb->pf)\n\t\treturn;\n\tpf = veb->pf;\n\n\t/* depth first... */\n\tfor (i = 0; i < I40E_MAX_VEB; i++)\n\t\tif (pf->veb[i] && (pf->veb[i]->uplink_seid == veb->seid))\n\t\t\ti40e_veb_link_event(pf->veb[i], link_up);\n\n\t/* ... now the local VSIs */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i] && (pf->vsi[i]->uplink_seid == veb->seid))\n\t\t\ti40e_vsi_link_event(pf->vsi[i], link_up);\n}\n\n/**\n * i40e_link_event - Update netif_carrier status\n * @pf: board private structure\n **/\nstatic void i40e_link_event(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tu8 new_link_speed, old_link_speed;\n\ti40e_status status;\n\tbool new_link, old_link;\n\n\t/* set this to force the get_link_status call to refresh state */\n\tpf->hw.phy.get_link_info = true;\n\told_link = (pf->hw.phy.link_info_old.link_info & I40E_AQ_LINK_UP);\n\tstatus = i40e_get_link_status(&pf->hw, &new_link);\n\n\t/* On success, disable temp link polling */\n\tif (status == I40E_SUCCESS) {\n\t\tclear_bit(__I40E_TEMP_LINK_POLLING, pf->state);\n\t} else {\n\t\t/* Enable link polling temporarily until i40e_get_link_status\n\t\t * returns I40E_SUCCESS\n\t\t */\n\t\tset_bit(__I40E_TEMP_LINK_POLLING, pf->state);\n\t\tdev_dbg(&pf->pdev->dev, \"couldn't get link state, status: %d\\n\",\n\t\t\tstatus);\n\t\treturn;\n\t}\n\n\told_link_speed = pf->hw.phy.link_info_old.link_speed;\n\tnew_link_speed = pf->hw.phy.link_info.link_speed;\n\n\tif (new_link == old_link &&\n\t    new_link_speed == old_link_speed &&\n\t    (test_bit(__I40E_VSI_DOWN, vsi->state) ||\n\t     new_link == netif_carrier_ok(vsi->netdev)))\n\t\treturn;\n\n\ti40e_print_link_message(vsi, new_link);\n\n\t/* Notify the base of the switch tree connected to\n\t * the link.  Floating VEBs are not notified.\n\t */\n\tif (pf->lan_veb < I40E_MAX_VEB && pf->veb[pf->lan_veb])\n\t\ti40e_veb_link_event(pf->veb[pf->lan_veb], new_link);\n\telse\n\t\ti40e_vsi_link_event(vsi, new_link);\n\n\tif (pf->vf)\n\t\ti40e_vc_notify_link_state(pf);\n\n\tif (pf->flags & I40E_FLAG_PTP)\n\t\ti40e_ptp_set_increment(pf);\n}\n\n/**\n * i40e_watchdog_subtask - periodic checks not using event driven response\n * @pf: board private structure\n **/\nstatic void i40e_watchdog_subtask(struct i40e_pf *pf)\n{\n\tint i;\n\n\t/* if interface is down do nothing */\n\tif (test_bit(__I40E_DOWN, pf->state) ||\n\t    test_bit(__I40E_CONFIG_BUSY, pf->state))\n\t\treturn;\n\n\t/* make sure we don't do these things too often */\n\tif (time_before(jiffies, (pf->service_timer_previous +\n\t\t\t\t  pf->service_timer_period)))\n\t\treturn;\n\tpf->service_timer_previous = jiffies;\n\n\tif ((pf->flags & I40E_FLAG_LINK_POLLING_ENABLED) ||\n\t    test_bit(__I40E_TEMP_LINK_POLLING, pf->state))\n\t\ti40e_link_event(pf);\n\n\t/* Update the stats for active netdevs so the network stack\n\t * can look at updated numbers whenever it cares to\n\t */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i] && pf->vsi[i]->netdev)\n\t\t\ti40e_update_stats(pf->vsi[i]);\n\n\tif (pf->flags & I40E_FLAG_VEB_STATS_ENABLED) {\n\t\t/* Update the stats for the active switching components */\n\t\tfor (i = 0; i < I40E_MAX_VEB; i++)\n\t\t\tif (pf->veb[i])\n\t\t\t\ti40e_update_veb_stats(pf->veb[i]);\n\t}\n\n\ti40e_ptp_rx_hang(pf);\n\ti40e_ptp_tx_hang(pf);\n}\n\n/**\n * i40e_reset_subtask - Set up for resetting the device and driver\n * @pf: board private structure\n **/\nstatic void i40e_reset_subtask(struct i40e_pf *pf)\n{\n\tu32 reset_flags = 0;\n\n\tif (test_bit(__I40E_REINIT_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_REINIT_REQUESTED);\n\t\tclear_bit(__I40E_REINIT_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_PF_RESET_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_PF_RESET_REQUESTED);\n\t\tclear_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_CORE_RESET_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_CORE_RESET_REQUESTED);\n\t\tclear_bit(__I40E_CORE_RESET_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_GLOBAL_RESET_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_GLOBAL_RESET_REQUESTED);\n\t\tclear_bit(__I40E_GLOBAL_RESET_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_DOWN_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_DOWN_REQUESTED);\n\t\tclear_bit(__I40E_DOWN_REQUESTED, pf->state);\n\t}\n\n\t/* If there's a recovery already waiting, it takes\n\t * precedence before starting a new reset sequence.\n\t */\n\tif (test_bit(__I40E_RESET_INTR_RECEIVED, pf->state)) {\n\t\ti40e_prep_for_reset(pf, false);\n\t\ti40e_reset(pf);\n\t\ti40e_rebuild(pf, false, false);\n\t}\n\n\t/* If we're already down or resetting, just bail */\n\tif (reset_flags &&\n\t    !test_bit(__I40E_DOWN, pf->state) &&\n\t    !test_bit(__I40E_CONFIG_BUSY, pf->state)) {\n\t\ti40e_do_reset(pf, reset_flags, false);\n\t}\n}\n\n/**\n * i40e_handle_link_event - Handle link event\n * @pf: board private structure\n * @e: event info posted on ARQ\n **/\nstatic void i40e_handle_link_event(struct i40e_pf *pf,\n\t\t\t\t   struct i40e_arq_event_info *e)\n{\n\tstruct i40e_aqc_get_link_status *status =\n\t\t(struct i40e_aqc_get_link_status *)&e->desc.params.raw;\n\n\t/* Do a new status request to re-enable LSE reporting\n\t * and load new status information into the hw struct\n\t * This completely ignores any state information\n\t * in the ARQ event info, instead choosing to always\n\t * issue the AQ update link status command.\n\t */\n\ti40e_link_event(pf);\n\n\t/* Check if module meets thermal requirements */\n\tif (status->phy_type == I40E_PHY_TYPE_NOT_SUPPORTED_HIGH_TEMP) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Rx/Tx is disabled on this device because the module does not meet thermal requirements.\\n\");\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Refer to the Intel(R) Ethernet Adapters and Devices User Guide for a list of supported modules.\\n\");\n\t} else {\n\t\t/* check for unqualified module, if link is down, suppress\n\t\t * the message if link was forced to be down.\n\t\t */\n\t\tif ((status->link_info & I40E_AQ_MEDIA_AVAILABLE) &&\n\t\t    (!(status->an_info & I40E_AQ_QUALIFIED_MODULE)) &&\n\t\t    (!(status->link_info & I40E_AQ_LINK_UP)) &&\n\t\t    (!(pf->flags & I40E_FLAG_LINK_DOWN_ON_CLOSE_ENABLED))) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Rx/Tx is disabled on this device because an unsupported SFP module type was detected.\\n\");\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Refer to the Intel(R) Ethernet Adapters and Devices User Guide for a list of supported modules.\\n\");\n\t\t}\n\t}\n}\n\n/**\n * i40e_clean_adminq_subtask - Clean the AdminQ rings\n * @pf: board private structure\n **/\nstatic void i40e_clean_adminq_subtask(struct i40e_pf *pf)\n{\n\tstruct i40e_arq_event_info event;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 pending, i = 0;\n\ti40e_status ret;\n\tu16 opcode;\n\tu32 oldval;\n\tu32 val;\n\n\t/* Do not run clean AQ when PF reset fails */\n\tif (test_bit(__I40E_RESET_FAILED, pf->state))\n\t\treturn;\n\n\t/* check for error indications */\n\tval = rd32(&pf->hw, pf->hw.aq.arq.len);\n\toldval = val;\n\tif (val & I40E_PF_ARQLEN_ARQVFE_MASK) {\n\t\tif (hw->debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ VF Error detected\\n\");\n\t\tval &= ~I40E_PF_ARQLEN_ARQVFE_MASK;\n\t}\n\tif (val & I40E_PF_ARQLEN_ARQOVFL_MASK) {\n\t\tif (hw->debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ Overflow Error detected\\n\");\n\t\tval &= ~I40E_PF_ARQLEN_ARQOVFL_MASK;\n\t\tpf->arq_overflows++;\n\t}\n\tif (val & I40E_PF_ARQLEN_ARQCRIT_MASK) {\n\t\tif (hw->debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ Critical Error detected\\n\");\n\t\tval &= ~I40E_PF_ARQLEN_ARQCRIT_MASK;\n\t}\n\tif (oldval != val)\n\t\twr32(&pf->hw, pf->hw.aq.arq.len, val);\n\n\tval = rd32(&pf->hw, pf->hw.aq.asq.len);\n\toldval = val;\n\tif (val & I40E_PF_ATQLEN_ATQVFE_MASK) {\n\t\tif (pf->hw.debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ASQ VF Error detected\\n\");\n\t\tval &= ~I40E_PF_ATQLEN_ATQVFE_MASK;\n\t}\n\tif (val & I40E_PF_ATQLEN_ATQOVFL_MASK) {\n\t\tif (pf->hw.debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ASQ Overflow Error detected\\n\");\n\t\tval &= ~I40E_PF_ATQLEN_ATQOVFL_MASK;\n\t}\n\tif (val & I40E_PF_ATQLEN_ATQCRIT_MASK) {\n\t\tif (pf->hw.debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ASQ Critical Error detected\\n\");\n\t\tval &= ~I40E_PF_ATQLEN_ATQCRIT_MASK;\n\t}\n\tif (oldval != val)\n\t\twr32(&pf->hw, pf->hw.aq.asq.len, val);\n\n\tevent.buf_len = I40E_MAX_AQ_BUF_SIZE;\n\tevent.msg_buf = kzalloc(event.buf_len, GFP_KERNEL);\n\tif (!event.msg_buf)\n\t\treturn;\n\n\tdo {\n\t\tret = i40e_clean_arq_element(hw, &event, &pending);\n\t\tif (ret == I40E_ERR_ADMIN_QUEUE_NO_WORK)\n\t\t\tbreak;\n\t\telse if (ret) {\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ event error %d\\n\", ret);\n\t\t\tbreak;\n\t\t}\n\n\t\topcode = le16_to_cpu(event.desc.opcode);\n\t\tswitch (opcode) {\n\n\t\tcase i40e_aqc_opc_get_link_status:\n\t\t\ti40e_handle_link_event(pf, &event);\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_send_msg_to_pf:\n\t\t\tret = i40e_vc_process_vf_msg(pf,\n\t\t\t\t\tle16_to_cpu(event.desc.retval),\n\t\t\t\t\tle32_to_cpu(event.desc.cookie_high),\n\t\t\t\t\tle32_to_cpu(event.desc.cookie_low),\n\t\t\t\t\tevent.msg_buf,\n\t\t\t\t\tevent.msg_len);\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_lldp_update_mib:\n\t\t\tdev_dbg(&pf->pdev->dev, \"ARQ: Update LLDP MIB event received\\n\");\n#ifdef CONFIG_I40E_DCB\n\t\t\trtnl_lock();\n\t\t\tret = i40e_handle_lldp_event(pf, &event);\n\t\t\trtnl_unlock();\n#endif /* CONFIG_I40E_DCB */\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_event_lan_overflow:\n\t\t\tdev_dbg(&pf->pdev->dev, \"ARQ LAN queue overflow event received\\n\");\n\t\t\ti40e_handle_lan_overflow_event(pf, &event);\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_send_msg_to_peer:\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ: Msg from other pf\\n\");\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_nvm_erase:\n\t\tcase i40e_aqc_opc_nvm_update:\n\t\tcase i40e_aqc_opc_oem_post_update:\n\t\t\ti40e_debug(&pf->hw, I40E_DEBUG_NVM,\n\t\t\t\t   \"ARQ NVM operation 0x%04x completed\\n\",\n\t\t\t\t   opcode);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"ARQ: Unknown event 0x%04x ignored\\n\",\n\t\t\t\t opcode);\n\t\t\tbreak;\n\t\t}\n\t} while (i++ < pf->adminq_work_limit);\n\n\tif (i < pf->adminq_work_limit)\n\t\tclear_bit(__I40E_ADMINQ_EVENT_PENDING, pf->state);\n\n\t/* re-enable Admin queue interrupt cause */\n\tval = rd32(hw, I40E_PFINT_ICR0_ENA);\n\tval |=  I40E_PFINT_ICR0_ENA_ADMINQ_MASK;\n\twr32(hw, I40E_PFINT_ICR0_ENA, val);\n\ti40e_flush(hw);\n\n\tkfree(event.msg_buf);\n}\n\n/**\n * i40e_verify_eeprom - make sure eeprom is good to use\n * @pf: board private structure\n **/\nstatic void i40e_verify_eeprom(struct i40e_pf *pf)\n{\n\tint err;\n\n\terr = i40e_diag_eeprom_test(&pf->hw);\n\tif (err) {\n\t\t/* retry in case of garbage read */\n\t\terr = i40e_diag_eeprom_test(&pf->hw);\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev, \"eeprom check failed (%d), Tx/Rx traffic disabled\\n\",\n\t\t\t\t err);\n\t\t\tset_bit(__I40E_BAD_EEPROM, pf->state);\n\t\t}\n\t}\n\n\tif (!err && test_bit(__I40E_BAD_EEPROM, pf->state)) {\n\t\tdev_info(&pf->pdev->dev, \"eeprom check passed, Tx/Rx traffic enabled\\n\");\n\t\tclear_bit(__I40E_BAD_EEPROM, pf->state);\n\t}\n}\n\n/**\n * i40e_enable_pf_switch_lb\n * @pf: pointer to the PF structure\n *\n * enable switch loop back or die - no point in a return value\n **/\nstatic void i40e_enable_pf_switch_lb(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_vsi_context ctxt;\n\tint ret;\n\n\tctxt.seid = pf->main_vsi_seid;\n\tctxt.pf_num = pf->hw.pf_id;\n\tctxt.vf_num = 0;\n\tret = i40e_aq_get_vsi_params(&pf->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn;\n\t}\n\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\tctxt.info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\tctxt.info.switch_id |= cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"update vsi switch failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n}\n\n/**\n * i40e_disable_pf_switch_lb\n * @pf: pointer to the PF structure\n *\n * disable switch loop back or die - no point in a return value\n **/\nstatic void i40e_disable_pf_switch_lb(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_vsi_context ctxt;\n\tint ret;\n\n\tctxt.seid = pf->main_vsi_seid;\n\tctxt.pf_num = pf->hw.pf_id;\n\tctxt.vf_num = 0;\n\tret = i40e_aq_get_vsi_params(&pf->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn;\n\t}\n\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\tctxt.info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\tctxt.info.switch_id &= ~cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"update vsi switch failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n}\n\n/**\n * i40e_config_bridge_mode - Configure the HW bridge mode\n * @veb: pointer to the bridge instance\n *\n * Configure the loop back mode for the LAN VSI that is downlink to the\n * specified HW bridge instance. It is expected this function is called\n * when a new HW bridge is instantiated.\n **/\nstatic void i40e_config_bridge_mode(struct i40e_veb *veb)\n{\n\tstruct i40e_pf *pf = veb->pf;\n\n\tif (pf->hw.debug_mask & I40E_DEBUG_LAN)\n\t\tdev_info(&pf->pdev->dev, \"enabling bridge mode: %s\\n\",\n\t\t\t veb->bridge_mode == BRIDGE_MODE_VEPA ? \"VEPA\" : \"VEB\");\n\tif (veb->bridge_mode & BRIDGE_MODE_VEPA)\n\t\ti40e_disable_pf_switch_lb(pf);\n\telse\n\t\ti40e_enable_pf_switch_lb(pf);\n}\n\n/**\n * i40e_reconstitute_veb - rebuild the VEB and anything connected to it\n * @veb: pointer to the VEB instance\n *\n * This is a recursive function that first builds the attached VSIs then\n * recurses in to build the next layer of VEB.  We track the connections\n * through our own index numbers because the seid's from the HW could\n * change across the reset.\n **/\nstatic int i40e_reconstitute_veb(struct i40e_veb *veb)\n{\n\tstruct i40e_vsi *ctl_vsi = NULL;\n\tstruct i40e_pf *pf = veb->pf;\n\tint v, veb_idx;\n\tint ret;\n\n\t/* build VSI that owns this VEB, temporarily attached to base VEB */\n\tfor (v = 0; v < pf->num_alloc_vsi && !ctl_vsi; v++) {\n\t\tif (pf->vsi[v] &&\n\t\t    pf->vsi[v]->veb_idx == veb->idx &&\n\t\t    pf->vsi[v]->flags & I40E_VSI_FLAG_VEB_OWNER) {\n\t\t\tctl_vsi = pf->vsi[v];\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!ctl_vsi) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"missing owner VSI for veb_idx %d\\n\", veb->idx);\n\t\tret = -ENOENT;\n\t\tgoto end_reconstitute;\n\t}\n\tif (ctl_vsi != pf->vsi[pf->lan_vsi])\n\t\tctl_vsi->uplink_seid = pf->vsi[pf->lan_vsi]->uplink_seid;\n\tret = i40e_add_vsi(ctl_vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"rebuild of veb_idx %d owner VSI failed: %d\\n\",\n\t\t\t veb->idx, ret);\n\t\tgoto end_reconstitute;\n\t}\n\ti40e_vsi_reset_stats(ctl_vsi);\n\n\t/* create the VEB in the switch and move the VSI onto the VEB */\n\tret = i40e_add_veb(veb, ctl_vsi);\n\tif (ret)\n\t\tgoto end_reconstitute;\n\n\tif (pf->flags & I40E_FLAG_VEB_MODE_ENABLED)\n\t\tveb->bridge_mode = BRIDGE_MODE_VEB;\n\telse\n\t\tveb->bridge_mode = BRIDGE_MODE_VEPA;\n\ti40e_config_bridge_mode(veb);\n\n\t/* create the remaining VSIs attached to this VEB */\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (!pf->vsi[v] || pf->vsi[v] == ctl_vsi)\n\t\t\tcontinue;\n\n\t\tif (pf->vsi[v]->veb_idx == veb->idx) {\n\t\t\tstruct i40e_vsi *vsi = pf->vsi[v];\n\n\t\t\tvsi->uplink_seid = veb->seid;\n\t\t\tret = i40e_add_vsi(vsi);\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"rebuild of vsi_idx %d failed: %d\\n\",\n\t\t\t\t\t v, ret);\n\t\t\t\tgoto end_reconstitute;\n\t\t\t}\n\t\t\ti40e_vsi_reset_stats(vsi);\n\t\t}\n\t}\n\n\t/* create any VEBs attached to this VEB - RECURSION */\n\tfor (veb_idx = 0; veb_idx < I40E_MAX_VEB; veb_idx++) {\n\t\tif (pf->veb[veb_idx] && pf->veb[veb_idx]->veb_idx == veb->idx) {\n\t\t\tpf->veb[veb_idx]->uplink_seid = veb->seid;\n\t\t\tret = i40e_reconstitute_veb(pf->veb[veb_idx]);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\nend_reconstitute:\n\treturn ret;\n}\n\n/**\n * i40e_get_capabilities - get info about the HW\n * @pf: the PF struct\n **/\nstatic int i40e_get_capabilities(struct i40e_pf *pf,\n\t\t\t\t enum i40e_admin_queue_opc list_type)\n{\n\tstruct i40e_aqc_list_capabilities_element_resp *cap_buf;\n\tu16 data_size;\n\tint buf_len;\n\tint err;\n\n\tbuf_len = 40 * sizeof(struct i40e_aqc_list_capabilities_element_resp);\n\tdo {\n\t\tcap_buf = kzalloc(buf_len, GFP_KERNEL);\n\t\tif (!cap_buf)\n\t\t\treturn -ENOMEM;\n\n\t\t/* this loads the data into the hw struct for us */\n\t\terr = i40e_aq_discover_capabilities(&pf->hw, cap_buf, buf_len,\n\t\t\t\t\t\t    &data_size, list_type,\n\t\t\t\t\t\t    NULL);\n\t\t/* data loaded, buffer no longer needed */\n\t\tkfree(cap_buf);\n\n\t\tif (pf->hw.aq.asq_last_status == I40E_AQ_RC_ENOMEM) {\n\t\t\t/* retry with a larger buffer */\n\t\t\tbuf_len = data_size;\n\t\t} else if (pf->hw.aq.asq_last_status != I40E_AQ_RC_OK) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"capability discovery failed, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, err),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn -ENODEV;\n\t\t}\n\t} while (err);\n\n\tif (pf->hw.debug_mask & I40E_DEBUG_USER) {\n\t\tif (list_type == i40e_aqc_opc_list_func_capabilities) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"pf=%d, num_vfs=%d, msix_pf=%d, msix_vf=%d, fd_g=%d, fd_b=%d, pf_max_q=%d num_vsi=%d\\n\",\n\t\t\t\t pf->hw.pf_id, pf->hw.func_caps.num_vfs,\n\t\t\t\t pf->hw.func_caps.num_msix_vectors,\n\t\t\t\t pf->hw.func_caps.num_msix_vectors_vf,\n\t\t\t\t pf->hw.func_caps.fd_filters_guaranteed,\n\t\t\t\t pf->hw.func_caps.fd_filters_best_effort,\n\t\t\t\t pf->hw.func_caps.num_tx_qp,\n\t\t\t\t pf->hw.func_caps.num_vsis);\n\t\t} else if (list_type == i40e_aqc_opc_list_dev_capabilities) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"switch_mode=0x%04x, function_valid=0x%08x\\n\",\n\t\t\t\t pf->hw.dev_caps.switch_mode,\n\t\t\t\t pf->hw.dev_caps.valid_functions);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"SR-IOV=%d, num_vfs for all function=%u\\n\",\n\t\t\t\t pf->hw.dev_caps.sr_iov_1_1,\n\t\t\t\t pf->hw.dev_caps.num_vfs);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"num_vsis=%u, num_rx:%u, num_tx=%u\\n\",\n\t\t\t\t pf->hw.dev_caps.num_vsis,\n\t\t\t\t pf->hw.dev_caps.num_rx_qp,\n\t\t\t\t pf->hw.dev_caps.num_tx_qp);\n\t\t}\n\t}\n\tif (list_type == i40e_aqc_opc_list_func_capabilities) {\n#define DEF_NUM_VSI (1 + (pf->hw.func_caps.fcoe ? 1 : 0) \\\n\t\t       + pf->hw.func_caps.num_vfs)\n\t\tif (pf->hw.revision_id == 0 &&\n\t\t    pf->hw.func_caps.num_vsis < DEF_NUM_VSI) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"got num_vsis %d, setting num_vsis to %d\\n\",\n\t\t\t\t pf->hw.func_caps.num_vsis, DEF_NUM_VSI);\n\t\t\tpf->hw.func_caps.num_vsis = DEF_NUM_VSI;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int i40e_vsi_clear(struct i40e_vsi *vsi);\n\n/**\n * i40e_fdir_sb_setup - initialize the Flow Director resources for Sideband\n * @pf: board private structure\n **/\nstatic void i40e_fdir_sb_setup(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi;\n\n\t/* quick workaround for an NVM issue that leaves a critical register\n\t * uninitialized\n\t */\n\tif (!rd32(&pf->hw, I40E_GLQF_HKEY(0))) {\n\t\tstatic const u32 hkey[] = {\n\t\t\t0xe640d33f, 0xcdfe98ab, 0x73fa7161, 0x0d7a7d36,\n\t\t\t0xeacb7d61, 0xaa4f05b6, 0x9c5c89ed, 0xfc425ddb,\n\t\t\t0xa4654832, 0xfc7461d4, 0x8f827619, 0xf5c63c21,\n\t\t\t0x95b3a76d};\n\t\tint i;\n\n\t\tfor (i = 0; i <= I40E_GLQF_HKEY_MAX_INDEX; i++)\n\t\t\twr32(&pf->hw, I40E_GLQF_HKEY(i), hkey[i]);\n\t}\n\n\tif (!(pf->flags & I40E_FLAG_FD_SB_ENABLED))\n\t\treturn;\n\n\t/* find existing VSI and see if it needs configuring */\n\tvsi = i40e_find_vsi_by_type(pf, I40E_VSI_FDIR);\n\n\t/* create a new VSI if none exists */\n\tif (!vsi) {\n\t\tvsi = i40e_vsi_setup(pf, I40E_VSI_FDIR,\n\t\t\t\t     pf->vsi[pf->lan_vsi]->seid, 0);\n\t\tif (!vsi) {\n\t\t\tdev_info(&pf->pdev->dev, \"Couldn't create FDir VSI\\n\");\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t\t\treturn;\n\t\t}\n\t}\n\n\ti40e_vsi_setup_irqhandler(vsi, i40e_fdir_clean_ring);\n}\n\n/**\n * i40e_fdir_teardown - release the Flow Director resources\n * @pf: board private structure\n **/\nstatic void i40e_fdir_teardown(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi;\n\n\ti40e_fdir_filter_exit(pf);\n\tvsi = i40e_find_vsi_by_type(pf, I40E_VSI_FDIR);\n\tif (vsi)\n\t\ti40e_vsi_release(vsi);\n}\n\n/**\n * i40e_rebuild_cloud_filters - Rebuilds cloud filters for VSIs\n * @vsi: PF main vsi\n * @seid: seid of main or channel VSIs\n *\n * Rebuilds cloud filters associated with main VSI and channel VSIs if they\n * existed before reset\n **/\nstatic int i40e_rebuild_cloud_filters(struct i40e_vsi *vsi, u16 seid)\n{\n\tstruct i40e_cloud_filter *cfilter;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct hlist_node *node;\n\ti40e_status ret;\n\n\t/* Add cloud filters back if they exist */\n\thlist_for_each_entry_safe(cfilter, node, &pf->cloud_filter_list,\n\t\t\t\t  cloud_node) {\n\t\tif (cfilter->seid != seid)\n\t\t\tcontinue;\n\n\t\tif (cfilter->dst_port)\n\t\t\tret = i40e_add_del_cloud_filter_big_buf(vsi, cfilter,\n\t\t\t\t\t\t\t\ttrue);\n\t\telse\n\t\t\tret = i40e_add_del_cloud_filter(vsi, cfilter, true);\n\n\t\tif (ret) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Failed to rebuild cloud filter, err %s aq_err %s\\n\",\n\t\t\t\ti40e_stat_str(&pf->hw, ret),\n\t\t\t\ti40e_aq_str(&pf->hw,\n\t\t\t\t\t    pf->hw.aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\n/**\n * i40e_rebuild_channels - Rebuilds channel VSIs if they existed before reset\n * @vsi: PF main vsi\n *\n * Rebuilds channel VSIs if they existed before reset\n **/\nstatic int i40e_rebuild_channels(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\ti40e_status ret;\n\n\tif (list_empty(&vsi->ch_list))\n\t\treturn 0;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tif (!ch->initialized)\n\t\t\tbreak;\n\t\t/* Proceed with creation of channel (VMDq2) VSI */\n\t\tret = i40e_add_channel(vsi->back, vsi->uplink_seid, ch);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"failed to rebuild channels using uplink_seid %u\\n\",\n\t\t\t\t vsi->uplink_seid);\n\t\t\treturn ret;\n\t\t}\n\t\t/* Reconfigure TX queues using QTX_CTL register */\n\t\tret = i40e_channel_config_tx_ring(vsi->back, vsi, ch);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"failed to configure TX rings for channel %u\\n\",\n\t\t\t\t ch->seid);\n\t\t\treturn ret;\n\t\t}\n\t\t/* update 'next_base_queue' */\n\t\tvsi->next_base_queue = vsi->next_base_queue +\n\t\t\t\t\t\t\tch->num_queue_pairs;\n\t\tif (ch->max_tx_rate) {\n\t\t\tu64 credits = ch->max_tx_rate;\n\n\t\t\tif (i40e_set_bw_limit(vsi, ch->seid,\n\t\t\t\t\t      ch->max_tx_rate))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\t\tch->max_tx_rate,\n\t\t\t\tcredits,\n\t\t\t\tch->seid);\n\t\t}\n\t\tret = i40e_rebuild_cloud_filters(vsi, ch->seid);\n\t\tif (ret) {\n\t\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\t\"Failed to rebuild cloud filters for channel VSI %u\\n\",\n\t\t\t\tch->seid);\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\n/**\n * i40e_prep_for_reset - prep for the core to reset\n * @pf: board private structure\n * @lock_acquired: indicates whether or not the lock has been acquired\n * before this function was called.\n *\n * Close up the VFs and other things in prep for PF Reset.\n  **/\nstatic void i40e_prep_for_reset(struct i40e_pf *pf, bool lock_acquired)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret = 0;\n\tu32 v;\n\n\tclear_bit(__I40E_RESET_INTR_RECEIVED, pf->state);\n\tif (test_and_set_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\treturn;\n\tif (i40e_check_asq_alive(&pf->hw))\n\t\ti40e_vc_notify_reset(pf);\n\n\tdev_dbg(&pf->pdev->dev, \"Tearing down internal switch for reset\\n\");\n\n\t/* quiesce the VSIs and their queues that are not already DOWN */\n\t/* pf_quiesce_all_vsi modifies netdev structures -rtnl_lock needed */\n\tif (!lock_acquired)\n\t\trtnl_lock();\n\ti40e_pf_quiesce_all_vsi(pf);\n\tif (!lock_acquired)\n\t\trtnl_unlock();\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v])\n\t\t\tpf->vsi[v]->seid = 0;\n\t}\n\n\ti40e_shutdown_adminq(&pf->hw);\n\n\t/* call shutdown HMC */\n\tif (hw->hmc.hmc_obj) {\n\t\tret = i40e_shutdown_lan_hmc(hw);\n\t\tif (ret)\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"shutdown_lan_hmc failed: %d\\n\", ret);\n\t}\n\n\t/* Save the current PTP time so that we can restore the time after the\n\t * reset completes.\n\t */\n\ti40e_ptp_save_hw_time(pf);\n}\n\n/**\n * i40e_send_version - update firmware with driver version\n * @pf: PF struct\n */\nstatic void i40e_send_version(struct i40e_pf *pf)\n{\n\tstruct i40e_driver_version dv;\n\n\tdv.major_version = DRV_VERSION_MAJOR;\n\tdv.minor_version = DRV_VERSION_MINOR;\n\tdv.build_version = DRV_VERSION_BUILD;\n\tdv.subbuild_version = 0;\n\tstrlcpy(dv.driver_string, DRV_VERSION, sizeof(dv.driver_string));\n\ti40e_aq_send_driver_version(&pf->hw, &dv, NULL);\n}\n\n/**\n * i40e_get_oem_version - get OEM specific version information\n * @hw: pointer to the hardware structure\n **/\nstatic void i40e_get_oem_version(struct i40e_hw *hw)\n{\n\tu16 block_offset = 0xffff;\n\tu16 block_length = 0;\n\tu16 capabilities = 0;\n\tu16 gen_snap = 0;\n\tu16 release = 0;\n\n#define I40E_SR_NVM_OEM_VERSION_PTR\t\t0x1B\n#define I40E_NVM_OEM_LENGTH_OFFSET\t\t0x00\n#define I40E_NVM_OEM_CAPABILITIES_OFFSET\t0x01\n#define I40E_NVM_OEM_GEN_OFFSET\t\t\t0x02\n#define I40E_NVM_OEM_RELEASE_OFFSET\t\t0x03\n#define I40E_NVM_OEM_CAPABILITIES_MASK\t\t0x000F\n#define I40E_NVM_OEM_LENGTH\t\t\t3\n\n\t/* Check if pointer to OEM version block is valid. */\n\ti40e_read_nvm_word(hw, I40E_SR_NVM_OEM_VERSION_PTR, &block_offset);\n\tif (block_offset == 0xffff)\n\t\treturn;\n\n\t/* Check if OEM version block has correct length. */\n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_LENGTH_OFFSET,\n\t\t\t   &block_length);\n\tif (block_length < I40E_NVM_OEM_LENGTH)\n\t\treturn;\n\n\t/* Check if OEM version format is as expected. */\n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_CAPABILITIES_OFFSET,\n\t\t\t   &capabilities);\n\tif ((capabilities & I40E_NVM_OEM_CAPABILITIES_MASK) != 0)\n\t\treturn;\n\n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_GEN_OFFSET,\n\t\t\t   &gen_snap);\n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_RELEASE_OFFSET,\n\t\t\t   &release);\n\thw->nvm.oem_ver = (gen_snap << I40E_OEM_SNAP_SHIFT) | release;\n\thw->nvm.eetrack = I40E_OEM_EETRACK_ID;\n}\n\n/**\n * i40e_reset - wait for core reset to finish reset, reset pf if corer not seen\n * @pf: board private structure\n **/\nstatic int i40e_reset(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret;\n\n\tret = i40e_pf_reset(hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"PF reset failed, %d\\n\", ret);\n\t\tset_bit(__I40E_RESET_FAILED, pf->state);\n\t\tclear_bit(__I40E_RESET_RECOVERY_PENDING, pf->state);\n\t} else {\n\t\tpf->pfr_count++;\n\t}\n\treturn ret;\n}\n\n/**\n * i40e_rebuild - rebuild using a saved config\n * @pf: board private structure\n * @reinit: if the Main VSI needs to re-initialized.\n * @lock_acquired: indicates whether or not the lock has been acquired\n * before this function was called.\n **/\nstatic void i40e_rebuild(struct i40e_pf *pf, bool reinit, bool lock_acquired)\n{\n\tint old_recovery_mode_bit = test_bit(__I40E_RECOVERY_MODE, pf->state);\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 set_fc_aq_fail = 0;\n\ti40e_status ret;\n\tu32 val;\n\tint v;\n\n\tif (test_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state) &&\n\t    i40e_check_recovery_mode(pf)) {\n\t\ti40e_set_ethtool_ops(pf->vsi[pf->lan_vsi]->netdev);\n\t}\n\n\tif (test_bit(__I40E_DOWN, pf->state) &&\n\t    !test_bit(__I40E_RECOVERY_MODE, pf->state) &&\n\t    !old_recovery_mode_bit)\n\t\tgoto clear_recovery;\n\tdev_dbg(&pf->pdev->dev, \"Rebuilding internal switch\\n\");\n\n\t/* rebuild the basics for the AdminQ, HMC, and initial HW switch */\n\tret = i40e_init_adminq(&pf->hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"Rebuild AdminQ failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto clear_recovery;\n\t}\n\ti40e_get_oem_version(&pf->hw);\n\n\tif (test_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state) &&\n\t    ((hw->aq.fw_maj_ver == 4 && hw->aq.fw_min_ver <= 33) ||\n\t     hw->aq.fw_maj_ver < 4) && hw->mac.type == I40E_MAC_XL710) {\n\t\t/* The following delay is necessary for 4.33 firmware and older\n\t\t * to recover after EMP reset. 200 ms should suffice but we\n\t\t * put here 300 ms to be sure that FW is ready to operate\n\t\t * after reset.\n\t\t */\n\t\tmdelay(300);\n\t}\n\n\t/* re-verify the eeprom if we just had an EMP reset */\n\tif (test_and_clear_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state))\n\t\ti40e_verify_eeprom(pf);\n\n\t/* if we are going out of or into recovery mode we have to act\n\t * accordingly with regard to resources initialization\n\t * and deinitialization\n\t */\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state) ||\n\t    old_recovery_mode_bit) {\n\t\tif (i40e_get_capabilities(pf,\n\t\t\t\t\t  i40e_aqc_opc_list_func_capabilities))\n\t\t\tgoto end_unlock;\n\n\t\tif (test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\t\t/* we're staying in recovery mode so we'll reinitialize\n\t\t\t * misc vector here\n\t\t\t */\n\t\t\tif (i40e_setup_misc_vector_for_recovery_mode(pf))\n\t\t\t\tgoto end_unlock;\n\t\t} else {\n\t\t\tif (!lock_acquired)\n\t\t\t\trtnl_lock();\n\t\t\t/* we're going out of recovery mode so we'll free\n\t\t\t * the IRQ allocated specifically for recovery mode\n\t\t\t * and restore the interrupt scheme\n\t\t\t */\n\t\t\tfree_irq(pf->pdev->irq, pf);\n\t\t\ti40e_clear_interrupt_scheme(pf);\n\t\t\tif (i40e_restore_interrupt_scheme(pf))\n\t\t\t\tgoto end_unlock;\n\t\t}\n\n\t\t/* tell the firmware that we're starting */\n\t\ti40e_send_version(pf);\n\n\t\t/* bail out in case recovery mode was detected, as there is\n\t\t * no need for further configuration.\n\t\t */\n\t\tgoto end_unlock;\n\t}\n\n\ti40e_clear_pxe_mode(hw);\n\tret = i40e_get_capabilities(pf, i40e_aqc_opc_list_func_capabilities);\n\tif (ret)\n\t\tgoto end_core_reset;\n\n\tret = i40e_init_lan_hmc(hw, hw->func_caps.num_tx_qp,\n\t\t\t\thw->func_caps.num_rx_qp, 0, 0);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"init_lan_hmc failed: %d\\n\", ret);\n\t\tgoto end_core_reset;\n\t}\n\tret = i40e_configure_lan_hmc(hw, I40E_HMC_MODEL_DIRECT_ONLY);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"configure_lan_hmc failed: %d\\n\", ret);\n\t\tgoto end_core_reset;\n\t}\n\n\t/* Enable FW to write a default DCB config on link-up */\n\ti40e_aq_set_dcb_parameters(hw, true, NULL);\n\n#ifdef CONFIG_I40E_DCB\n\tret = i40e_init_pf_dcb(pf);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"DCB init failed %d, disabled\\n\", ret);\n\t\tpf->flags &= ~I40E_FLAG_DCB_CAPABLE;\n\t\t/* Continue without DCB enabled */\n\t}\n#endif /* CONFIG_I40E_DCB */\n\t/* do basic switch setup */\n\tif (!lock_acquired)\n\t\trtnl_lock();\n\tret = i40e_setup_pf_switch(pf, reinit);\n\tif (ret)\n\t\tgoto end_unlock;\n\n\t/* The driver only wants link up/down and module qualification\n\t * reports from firmware.  Note the negative logic.\n\t */\n\tret = i40e_aq_set_phy_int_mask(&pf->hw,\n\t\t\t\t       ~(I40E_AQ_EVENT_LINK_UPDOWN |\n\t\t\t\t\t I40E_AQ_EVENT_MEDIA_NA |\n\t\t\t\t\t I40E_AQ_EVENT_MODULE_QUAL_FAIL), NULL);\n\tif (ret)\n\t\tdev_info(&pf->pdev->dev, \"set phy mask fail, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t/* make sure our flow control settings are restored */\n\tret = i40e_set_fc(&pf->hw, &set_fc_aq_fail, true);\n\tif (ret)\n\t\tdev_dbg(&pf->pdev->dev, \"setting flow control: ret = %s last_status = %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, ret),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t/* Rebuild the VSIs and VEBs that existed before reset.\n\t * They are still in our local switch element arrays, so only\n\t * need to rebuild the switch model in the HW.\n\t *\n\t * If there were VEBs but the reconstitution failed, we'll try\n\t * try to recover minimal use by getting the basic PF VSI working.\n\t */\n\tif (vsi->uplink_seid != pf->mac_seid) {\n\t\tdev_dbg(&pf->pdev->dev, \"attempting to rebuild switch\\n\");\n\t\t/* find the one VEB connected to the MAC, and find orphans */\n\t\tfor (v = 0; v < I40E_MAX_VEB; v++) {\n\t\t\tif (!pf->veb[v])\n\t\t\t\tcontinue;\n\n\t\t\tif (pf->veb[v]->uplink_seid == pf->mac_seid ||\n\t\t\t    pf->veb[v]->uplink_seid == 0) {\n\t\t\t\tret = i40e_reconstitute_veb(pf->veb[v]);\n\n\t\t\t\tif (!ret)\n\t\t\t\t\tcontinue;\n\n\t\t\t\t/* If Main VEB failed, we're in deep doodoo,\n\t\t\t\t * so give up rebuilding the switch and set up\n\t\t\t\t * for minimal rebuild of PF VSI.\n\t\t\t\t * If orphan failed, we'll report the error\n\t\t\t\t * but try to keep going.\n\t\t\t\t */\n\t\t\t\tif (pf->veb[v]->uplink_seid == pf->mac_seid) {\n\t\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t\t \"rebuild of switch failed: %d, will try to set up simple PF connection\\n\",\n\t\t\t\t\t\t ret);\n\t\t\t\t\tvsi->uplink_seid = pf->mac_seid;\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (pf->veb[v]->uplink_seid == 0) {\n\t\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t\t \"rebuild of orphan VEB failed: %d\\n\",\n\t\t\t\t\t\t ret);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (vsi->uplink_seid == pf->mac_seid) {\n\t\tdev_dbg(&pf->pdev->dev, \"attempting to rebuild PF VSI\\n\");\n\t\t/* no VEB, so rebuild only the Main VSI */\n\t\tret = i40e_add_vsi(vsi);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"rebuild of Main VSI failed: %d\\n\", ret);\n\t\t\tgoto end_unlock;\n\t\t}\n\t}\n\n\tif (vsi->mqprio_qopt.max_rate[0]) {\n\t\tu64 max_tx_rate = vsi->mqprio_qopt.max_rate[0];\n\t\tu64 credits = 0;\n\n\t\tdo_div(max_tx_rate, I40E_BW_MBPS_DIVISOR);\n\t\tret = i40e_set_bw_limit(vsi, vsi->seid, max_tx_rate);\n\t\tif (ret)\n\t\t\tgoto end_unlock;\n\n\t\tcredits = max_tx_rate;\n\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\tmax_tx_rate,\n\t\t\tcredits,\n\t\t\tvsi->seid);\n\t}\n\n\tret = i40e_rebuild_cloud_filters(vsi, vsi->seid);\n\tif (ret)\n\t\tgoto end_unlock;\n\n\t/* PF Main VSI is rebuild by now, go ahead and rebuild channel VSIs\n\t * for this main VSI if they exist\n\t */\n\tret = i40e_rebuild_channels(vsi);\n\tif (ret)\n\t\tgoto end_unlock;\n\n\t/* Reconfigure hardware for allowing smaller MSS in the case\n\t * of TSO, so that we avoid the MDD being fired and causing\n\t * a reset in the case of small MSS+TSO.\n\t */\n#define I40E_REG_MSS          0x000E64DC\n#define I40E_REG_MSS_MIN_MASK 0x3FF0000\n#define I40E_64BYTE_MSS       0x400000\n\tval = rd32(hw, I40E_REG_MSS);\n\tif ((val & I40E_REG_MSS_MIN_MASK) > I40E_64BYTE_MSS) {\n\t\tval &= ~I40E_REG_MSS_MIN_MASK;\n\t\tval |= I40E_64BYTE_MSS;\n\t\twr32(hw, I40E_REG_MSS, val);\n\t}\n\n\tif (pf->hw_features & I40E_HW_RESTART_AUTONEG) {\n\t\tmsleep(75);\n\t\tret = i40e_aq_set_link_restart_an(&pf->hw, true, NULL);\n\t\tif (ret)\n\t\t\tdev_info(&pf->pdev->dev, \"link restart failed, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t}\n\t/* reinit the misc interrupt */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\tret = i40e_setup_misc_vector(pf);\n\n\t/* Add a filter to drop all Flow control frames from any VSI from being\n\t * transmitted. By doing so we stop a malicious VF from sending out\n\t * PAUSE or PFC frames and potentially controlling traffic for other\n\t * PF/VF VSIs.\n\t * The FW can still send Flow control frames if enabled.\n\t */\n\ti40e_add_filter_to_drop_tx_flow_control_frames(&pf->hw,\n\t\t\t\t\t\t       pf->main_vsi_seid);\n\n\t/* restart the VSIs that were rebuilt and running before the reset */\n\ti40e_pf_unquiesce_all_vsi(pf);\n\n\t/* Release the RTNL lock before we start resetting VFs */\n\tif (!lock_acquired)\n\t\trtnl_unlock();\n\n\t/* Restore promiscuous settings */\n\tret = i40e_set_promiscuous(pf, pf->cur_promisc);\n\tif (ret)\n\t\tdev_warn(&pf->pdev->dev,\n\t\t\t \"Failed to restore promiscuous setting: %s, err %s aq_err %s\\n\",\n\t\t\t pf->cur_promisc ? \"on\" : \"off\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\ti40e_reset_all_vfs(pf, true);\n\n\t/* tell the firmware that we're starting */\n\ti40e_send_version(pf);\n\n\t/* We've already released the lock, so don't do it again */\n\tgoto end_core_reset;\n\nend_unlock:\n\tif (!lock_acquired)\n\t\trtnl_unlock();\nend_core_reset:\n\tclear_bit(__I40E_RESET_FAILED, pf->state);\nclear_recovery:\n\tclear_bit(__I40E_RESET_RECOVERY_PENDING, pf->state);\n\tclear_bit(__I40E_TIMEOUT_RECOVERY_PENDING, pf->state);\n}\n\n/**\n * i40e_reset_and_rebuild - reset and rebuild using a saved config\n * @pf: board private structure\n * @reinit: if the Main VSI needs to re-initialized.\n * @lock_acquired: indicates whether or not the lock has been acquired\n * before this function was called.\n **/\nstatic void i40e_reset_and_rebuild(struct i40e_pf *pf, bool reinit,\n\t\t\t\t   bool lock_acquired)\n{\n\tint ret;\n\t/* Now we wait for GRST to settle out.\n\t * We don't have to delete the VEBs or VSIs from the hw switch\n\t * because the reset will make them disappear.\n\t */\n\tret = i40e_reset(pf);\n\tif (!ret)\n\t\ti40e_rebuild(pf, reinit, lock_acquired);\n}\n\n/**\n * i40e_handle_reset_warning - prep for the PF to reset, reset and rebuild\n * @pf: board private structure\n *\n * Close up the VFs and other things in prep for a Core Reset,\n * then get ready to rebuild the world.\n * @lock_acquired: indicates whether or not the lock has been acquired\n * before this function was called.\n **/\nstatic void i40e_handle_reset_warning(struct i40e_pf *pf, bool lock_acquired)\n{\n\ti40e_prep_for_reset(pf, lock_acquired);\n\ti40e_reset_and_rebuild(pf, false, lock_acquired);\n}\n\n/**\n * i40e_handle_mdd_event\n * @pf: pointer to the PF structure\n *\n * Called from the MDD irq handler to identify possibly malicious vfs\n **/\nstatic void i40e_handle_mdd_event(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tbool mdd_detected = false;\n\tstruct i40e_vf *vf;\n\tu32 reg;\n\tint i;\n\n\tif (!test_bit(__I40E_MDD_EVENT_PENDING, pf->state))\n\t\treturn;\n\n\t/* find what triggered the MDD event */\n\treg = rd32(hw, I40E_GL_MDET_TX);\n\tif (reg & I40E_GL_MDET_TX_VALID_MASK) {\n\t\tu8 pf_num = (reg & I40E_GL_MDET_TX_PF_NUM_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_PF_NUM_SHIFT;\n\t\tu16 vf_num = (reg & I40E_GL_MDET_TX_VF_NUM_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_VF_NUM_SHIFT;\n\t\tu8 event = (reg & I40E_GL_MDET_TX_EVENT_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_EVENT_SHIFT;\n\t\tu16 queue = ((reg & I40E_GL_MDET_TX_QUEUE_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_QUEUE_SHIFT) -\n\t\t\t\tpf->hw.func_caps.base_queue;\n\t\tif (netif_msg_tx_err(pf))\n\t\t\tdev_info(&pf->pdev->dev, \"Malicious Driver Detection event 0x%02x on TX queue %d PF number 0x%02x VF number 0x%02x\\n\",\n\t\t\t\t event, queue, pf_num, vf_num);\n\t\twr32(hw, I40E_GL_MDET_TX, 0xffffffff);\n\t\tmdd_detected = true;\n\t}\n\treg = rd32(hw, I40E_GL_MDET_RX);\n\tif (reg & I40E_GL_MDET_RX_VALID_MASK) {\n\t\tu8 func = (reg & I40E_GL_MDET_RX_FUNCTION_MASK) >>\n\t\t\t\tI40E_GL_MDET_RX_FUNCTION_SHIFT;\n\t\tu8 event = (reg & I40E_GL_MDET_RX_EVENT_MASK) >>\n\t\t\t\tI40E_GL_MDET_RX_EVENT_SHIFT;\n\t\tu16 queue = ((reg & I40E_GL_MDET_RX_QUEUE_MASK) >>\n\t\t\t\tI40E_GL_MDET_RX_QUEUE_SHIFT) -\n\t\t\t\tpf->hw.func_caps.base_queue;\n\t\tif (netif_msg_rx_err(pf))\n\t\t\tdev_info(&pf->pdev->dev, \"Malicious Driver Detection event 0x%02x on RX queue %d of function 0x%02x\\n\",\n\t\t\t\t event, queue, func);\n\t\twr32(hw, I40E_GL_MDET_RX, 0xffffffff);\n\t\tmdd_detected = true;\n\t}\n\n\tif (mdd_detected) {\n\t\treg = rd32(hw, I40E_PF_MDET_TX);\n\t\tif (reg & I40E_PF_MDET_TX_VALID_MASK) {\n\t\t\twr32(hw, I40E_PF_MDET_TX, 0xFFFF);\n\t\t\tdev_dbg(&pf->pdev->dev, \"TX driver issue detected on PF\\n\");\n\t\t}\n\t\treg = rd32(hw, I40E_PF_MDET_RX);\n\t\tif (reg & I40E_PF_MDET_RX_VALID_MASK) {\n\t\t\twr32(hw, I40E_PF_MDET_RX, 0xFFFF);\n\t\t\tdev_dbg(&pf->pdev->dev, \"RX driver issue detected on PF\\n\");\n\t\t}\n\t}\n\n\t/* see if one of the VFs needs its hand slapped */\n\tfor (i = 0; i < pf->num_alloc_vfs && mdd_detected; i++) {\n\t\tvf = &(pf->vf[i]);\n\t\treg = rd32(hw, I40E_VP_MDET_TX(i));\n\t\tif (reg & I40E_VP_MDET_TX_VALID_MASK) {\n\t\t\twr32(hw, I40E_VP_MDET_TX(i), 0xFFFF);\n\t\t\tvf->num_mdd_events++;\n\t\t\tdev_info(&pf->pdev->dev, \"TX driver issue detected on VF %d\\n\",\n\t\t\t\t i);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Use PF Control I/F to re-enable the VF\\n\");\n\t\t\tset_bit(I40E_VF_STATE_DISABLED, &vf->vf_states);\n\t\t}\n\n\t\treg = rd32(hw, I40E_VP_MDET_RX(i));\n\t\tif (reg & I40E_VP_MDET_RX_VALID_MASK) {\n\t\t\twr32(hw, I40E_VP_MDET_RX(i), 0xFFFF);\n\t\t\tvf->num_mdd_events++;\n\t\t\tdev_info(&pf->pdev->dev, \"RX driver issue detected on VF %d\\n\",\n\t\t\t\t i);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Use PF Control I/F to re-enable the VF\\n\");\n\t\t\tset_bit(I40E_VF_STATE_DISABLED, &vf->vf_states);\n\t\t}\n\t}\n\n\t/* re-enable mdd interrupt cause */\n\tclear_bit(__I40E_MDD_EVENT_PENDING, pf->state);\n\treg = rd32(hw, I40E_PFINT_ICR0_ENA);\n\treg |=  I40E_PFINT_ICR0_ENA_MAL_DETECT_MASK;\n\twr32(hw, I40E_PFINT_ICR0_ENA, reg);\n\ti40e_flush(hw);\n}\n\nstatic const char *i40e_tunnel_name(u8 type)\n{\n\tswitch (type) {\n\tcase UDP_TUNNEL_TYPE_VXLAN:\n\t\treturn \"vxlan\";\n\tcase UDP_TUNNEL_TYPE_GENEVE:\n\t\treturn \"geneve\";\n\tdefault:\n\t\treturn \"unknown\";\n\t}\n}\n\n/**\n * i40e_sync_udp_filters - Trigger a sync event for existing UDP filters\n * @pf: board private structure\n **/\nstatic void i40e_sync_udp_filters(struct i40e_pf *pf)\n{\n\tint i;\n\n\t/* loop through and set pending bit for all active UDP filters */\n\tfor (i = 0; i < I40E_MAX_PF_UDP_OFFLOAD_PORTS; i++) {\n\t\tif (pf->udp_ports[i].port)\n\t\t\tpf->pending_udp_bitmap |= BIT_ULL(i);\n\t}\n\n\tset_bit(__I40E_UDP_FILTER_SYNC_PENDING, pf->state);\n}\n\n/**\n * i40e_sync_udp_filters_subtask - Sync the VSI filter list with HW\n * @pf: board private structure\n **/\nstatic void i40e_sync_udp_filters_subtask(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 filter_index, type;\n\tu16 port;\n\tint i;\n\n\tif (!test_and_clear_bit(__I40E_UDP_FILTER_SYNC_PENDING, pf->state))\n\t\treturn;\n\n\t/* acquire RTNL to maintain state of flags and port requests */\n\trtnl_lock();\n\n\tfor (i = 0; i < I40E_MAX_PF_UDP_OFFLOAD_PORTS; i++) {\n\t\tif (pf->pending_udp_bitmap & BIT_ULL(i)) {\n\t\t\tstruct i40e_udp_port_config *udp_port;\n\t\t\ti40e_status ret = 0;\n\n\t\t\tudp_port = &pf->udp_ports[i];\n\t\t\tpf->pending_udp_bitmap &= ~BIT_ULL(i);\n\n\t\t\tport = READ_ONCE(udp_port->port);\n\t\t\ttype = READ_ONCE(udp_port->type);\n\t\t\tfilter_index = READ_ONCE(udp_port->filter_index);\n\n\t\t\t/* release RTNL while we wait on AQ command */\n\t\t\trtnl_unlock();\n\n\t\t\tif (port)\n\t\t\t\tret = i40e_aq_add_udp_tunnel(hw, port,\n\t\t\t\t\t\t\t     type,\n\t\t\t\t\t\t\t     &filter_index,\n\t\t\t\t\t\t\t     NULL);\n\t\t\telse if (filter_index != I40E_UDP_PORT_INDEX_UNUSED)\n\t\t\t\tret = i40e_aq_del_udp_tunnel(hw, filter_index,\n\t\t\t\t\t\t\t     NULL);\n\n\t\t\t/* reacquire RTNL so we can update filter_index */\n\t\t\trtnl_lock();\n\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"%s %s port %d, index %d failed, err %s aq_err %s\\n\",\n\t\t\t\t\t i40e_tunnel_name(type),\n\t\t\t\t\t port ? \"add\" : \"delete\",\n\t\t\t\t\t port,\n\t\t\t\t\t filter_index,\n\t\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\t\tif (port) {\n\t\t\t\t\t/* failed to add, just reset port,\n\t\t\t\t\t * drop pending bit for any deletion\n\t\t\t\t\t */\n\t\t\t\t\tudp_port->port = 0;\n\t\t\t\t\tpf->pending_udp_bitmap &= ~BIT_ULL(i);\n\t\t\t\t}\n\t\t\t} else if (port) {\n\t\t\t\t/* record filter index on success */\n\t\t\t\tudp_port->filter_index = filter_index;\n\t\t\t}\n\t\t}\n\t}\n\n\trtnl_unlock();\n}\n\n/**\n * i40e_service_task - Run the driver's async subtasks\n * @work: pointer to work_struct containing our data\n **/\nstatic void i40e_service_task(struct work_struct *work)\n{\n\tstruct i40e_pf *pf = container_of(work,\n\t\t\t\t\t  struct i40e_pf,\n\t\t\t\t\t  service_task);\n\tunsigned long start_time = jiffies;\n\n\t/* don't bother with service tasks if a reset is in progress */\n\tif (test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state) ||\n\t    test_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn;\n\n\tif (test_and_set_bit(__I40E_SERVICE_SCHED, pf->state))\n\t\treturn;\n\n\tif (!test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\ti40e_detect_recover_hung(pf->vsi[pf->lan_vsi]);\n\t\ti40e_sync_filters_subtask(pf);\n\t\ti40e_reset_subtask(pf);\n\t\ti40e_handle_mdd_event(pf);\n\t\ti40e_vc_process_vflr_event(pf);\n\t\ti40e_watchdog_subtask(pf);\n\t\ti40e_fdir_reinit_subtask(pf);\n\t\tif (test_and_clear_bit(__I40E_CLIENT_RESET, pf->state)) {\n\t\t\t/* Client subtask will reopen next time through. */\n\t\t\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi],\n\t\t\t\t\t\t\t   true);\n\t\t} else {\n\t\t\ti40e_client_subtask(pf);\n\t\t\tif (test_and_clear_bit(__I40E_CLIENT_L2_CHANGE,\n\t\t\t\t\t       pf->state))\n\t\t\t\ti40e_notify_client_of_l2_param_changes(\n\t\t\t\t\t\t\t\tpf->vsi[pf->lan_vsi]);\n\t\t}\n\t\ti40e_sync_filters_subtask(pf);\n\t\ti40e_sync_udp_filters_subtask(pf);\n\t} else {\n\t\ti40e_reset_subtask(pf);\n\t}\n\n\ti40e_clean_adminq_subtask(pf);\n\n\t/* flush memory to make sure state is correct before next watchdog */\n\tsmp_mb__before_atomic();\n\tclear_bit(__I40E_SERVICE_SCHED, pf->state);\n\n\t/* If the tasks have taken longer than one timer cycle or there\n\t * is more work to be done, reschedule the service task now\n\t * rather than wait for the timer to tick again.\n\t */\n\tif (time_after(jiffies, (start_time + pf->service_timer_period)) ||\n\t    test_bit(__I40E_ADMINQ_EVENT_PENDING, pf->state)\t\t ||\n\t    test_bit(__I40E_MDD_EVENT_PENDING, pf->state)\t\t ||\n\t    test_bit(__I40E_VFLR_EVENT_PENDING, pf->state))\n\t\ti40e_service_event_schedule(pf);\n}\n\n/**\n * i40e_service_timer - timer callback\n * @data: pointer to PF struct\n **/\nstatic void i40e_service_timer(struct timer_list *t)\n{\n\tstruct i40e_pf *pf = from_timer(pf, t, service_timer);\n\n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\ti40e_service_event_schedule(pf);\n}\n\n/**\n * i40e_set_num_rings_in_vsi - Determine number of rings in the VSI\n * @vsi: the VSI being configured\n **/\nstatic int i40e_set_num_rings_in_vsi(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tswitch (vsi->type) {\n\tcase I40E_VSI_MAIN:\n\t\tvsi->alloc_queue_pairs = pf->num_lan_qps;\n\t\tif (!vsi->num_tx_desc)\n\t\t\tvsi->num_tx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (!vsi->num_rx_desc)\n\t\t\tvsi->num_rx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\t\tvsi->num_q_vectors = pf->num_lan_msix;\n\t\telse\n\t\t\tvsi->num_q_vectors = 1;\n\n\t\tbreak;\n\n\tcase I40E_VSI_FDIR:\n\t\tvsi->alloc_queue_pairs = 1;\n\t\tvsi->num_tx_desc = ALIGN(I40E_FDIR_RING_COUNT,\n\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tvsi->num_rx_desc = ALIGN(I40E_FDIR_RING_COUNT,\n\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tvsi->num_q_vectors = pf->num_fdsb_msix;\n\t\tbreak;\n\n\tcase I40E_VSI_VMDQ2:\n\t\tvsi->alloc_queue_pairs = pf->num_vmdq_qps;\n\t\tif (!vsi->num_tx_desc)\n\t\t\tvsi->num_tx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (!vsi->num_rx_desc)\n\t\t\tvsi->num_rx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tvsi->num_q_vectors = pf->num_vmdq_msix;\n\t\tbreak;\n\n\tcase I40E_VSI_SRIOV:\n\t\tvsi->alloc_queue_pairs = pf->num_vf_qps;\n\t\tif (!vsi->num_tx_desc)\n\t\t\tvsi->num_tx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (!vsi->num_rx_desc)\n\t\t\tvsi->num_rx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tbreak;\n\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn -ENODATA;\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_alloc_arrays - Allocate queue and vector pointer arrays for the vsi\n * @vsi: VSI pointer\n * @alloc_qvectors: a bool to specify if q_vectors need to be allocated.\n *\n * On error: returns error code (negative)\n * On success: returns 0\n **/\nstatic int i40e_vsi_alloc_arrays(struct i40e_vsi *vsi, bool alloc_qvectors)\n{\n\tstruct i40e_ring **next_rings;\n\tint size;\n\tint ret = 0;\n\n\t/* allocate memory for both Tx, XDP Tx and Rx ring pointers */\n\tsize = sizeof(struct i40e_ring *) * vsi->alloc_queue_pairs *\n\t       (i40e_enabled_xdp_vsi(vsi) ? 3 : 2);\n\tvsi->tx_rings = kzalloc(size, GFP_KERNEL);\n\tif (!vsi->tx_rings)\n\t\treturn -ENOMEM;\n\tnext_rings = vsi->tx_rings + vsi->alloc_queue_pairs;\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tvsi->xdp_rings = next_rings;\n\t\tnext_rings += vsi->alloc_queue_pairs;\n\t}\n\tvsi->rx_rings = next_rings;\n\n\tif (alloc_qvectors) {\n\t\t/* allocate memory for q_vector pointers */\n\t\tsize = sizeof(struct i40e_q_vector *) * vsi->num_q_vectors;\n\t\tvsi->q_vectors = kzalloc(size, GFP_KERNEL);\n\t\tif (!vsi->q_vectors) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_vectors;\n\t\t}\n\t}\n\treturn ret;\n\nerr_vectors:\n\tkfree(vsi->tx_rings);\n\treturn ret;\n}\n\n/**\n * i40e_vsi_mem_alloc - Allocates the next available struct vsi in the PF\n * @pf: board private structure\n * @type: type of VSI\n *\n * On error: returns error code (negative)\n * On success: returns vsi index in PF (positive)\n **/\nstatic int i40e_vsi_mem_alloc(struct i40e_pf *pf, enum i40e_vsi_type type)\n{\n\tint ret = -ENODEV;\n\tstruct i40e_vsi *vsi;\n\tint vsi_idx;\n\tint i;\n\n\t/* Need to protect the allocation of the VSIs at the PF level */\n\tmutex_lock(&pf->switch_mutex);\n\n\t/* VSI list may be fragmented if VSI creation/destruction has\n\t * been happening.  We can afford to do a quick scan to look\n\t * for any free VSIs in the list.\n\t *\n\t * find next empty vsi slot, looping back around if necessary\n\t */\n\ti = pf->next_vsi;\n\twhile (i < pf->num_alloc_vsi && pf->vsi[i])\n\t\ti++;\n\tif (i >= pf->num_alloc_vsi) {\n\t\ti = 0;\n\t\twhile (i < pf->next_vsi && pf->vsi[i])\n\t\t\ti++;\n\t}\n\n\tif (i < pf->num_alloc_vsi && !pf->vsi[i]) {\n\t\tvsi_idx = i;             /* Found one! */\n\t} else {\n\t\tret = -ENODEV;\n\t\tgoto unlock_pf;  /* out of VSI slots! */\n\t}\n\tpf->next_vsi = ++i;\n\n\tvsi = kzalloc(sizeof(*vsi), GFP_KERNEL);\n\tif (!vsi) {\n\t\tret = -ENOMEM;\n\t\tgoto unlock_pf;\n\t}\n\tvsi->type = type;\n\tvsi->back = pf;\n\tset_bit(__I40E_VSI_DOWN, vsi->state);\n\tvsi->flags = 0;\n\tvsi->idx = vsi_idx;\n\tvsi->int_rate_limit = 0;\n\tvsi->rss_table_size = (vsi->type == I40E_VSI_MAIN) ?\n\t\t\t\tpf->rss_table_size : 64;\n\tvsi->netdev_registered = false;\n\tvsi->work_limit = I40E_DEFAULT_IRQ_WORK;\n\thash_init(vsi->mac_filter_hash);\n\tvsi->irqs_ready = false;\n\n\tif (type == I40E_VSI_MAIN) {\n\t\tvsi->af_xdp_zc_qps = bitmap_zalloc(pf->num_lan_qps, GFP_KERNEL);\n\t\tif (!vsi->af_xdp_zc_qps)\n\t\t\tgoto err_rings;\n\t}\n\n\tret = i40e_set_num_rings_in_vsi(vsi);\n\tif (ret)\n\t\tgoto err_rings;\n\n\tret = i40e_vsi_alloc_arrays(vsi, true);\n\tif (ret)\n\t\tgoto err_rings;\n\n\t/* Setup default MSIX irq handler for VSI */\n\ti40e_vsi_setup_irqhandler(vsi, i40e_msix_clean_rings);\n\n\t/* Initialize VSI lock */\n\tspin_lock_init(&vsi->mac_filter_hash_lock);\n\tpf->vsi[vsi_idx] = vsi;\n\tret = vsi_idx;\n\tgoto unlock_pf;\n\nerr_rings:\n\tbitmap_free(vsi->af_xdp_zc_qps);\n\tpf->next_vsi = i - 1;\n\tkfree(vsi);\nunlock_pf:\n\tmutex_unlock(&pf->switch_mutex);\n\treturn ret;\n}\n\n/**\n * i40e_vsi_free_arrays - Free queue and vector pointer arrays for the VSI\n * @vsi: VSI pointer\n * @free_qvectors: a bool to specify if q_vectors need to be freed.\n *\n * On error: returns error code (negative)\n * On success: returns 0\n **/\nstatic void i40e_vsi_free_arrays(struct i40e_vsi *vsi, bool free_qvectors)\n{\n\t/* free the ring and vector containers */\n\tif (free_qvectors) {\n\t\tkfree(vsi->q_vectors);\n\t\tvsi->q_vectors = NULL;\n\t}\n\tkfree(vsi->tx_rings);\n\tvsi->tx_rings = NULL;\n\tvsi->rx_rings = NULL;\n\tvsi->xdp_rings = NULL;\n}\n\n/**\n * i40e_clear_rss_config_user - clear the user configured RSS hash keys\n * and lookup table\n * @vsi: Pointer to VSI structure\n */\nstatic void i40e_clear_rss_config_user(struct i40e_vsi *vsi)\n{\n\tif (!vsi)\n\t\treturn;\n\n\tkfree(vsi->rss_hkey_user);\n\tvsi->rss_hkey_user = NULL;\n\n\tkfree(vsi->rss_lut_user);\n\tvsi->rss_lut_user = NULL;\n}\n\n/**\n * i40e_vsi_clear - Deallocate the VSI provided\n * @vsi: the VSI being un-configured\n **/\nstatic int i40e_vsi_clear(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf;\n\n\tif (!vsi)\n\t\treturn 0;\n\n\tif (!vsi->back)\n\t\tgoto free_vsi;\n\tpf = vsi->back;\n\n\tmutex_lock(&pf->switch_mutex);\n\tif (!pf->vsi[vsi->idx]) {\n\t\tdev_err(&pf->pdev->dev, \"pf->vsi[%d] is NULL, just free vsi[%d](type %d)\\n\",\n\t\t\tvsi->idx, vsi->idx, vsi->type);\n\t\tgoto unlock_vsi;\n\t}\n\n\tif (pf->vsi[vsi->idx] != vsi) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"pf->vsi[%d](type %d) != vsi[%d](type %d): no free!\\n\",\n\t\t\tpf->vsi[vsi->idx]->idx,\n\t\t\tpf->vsi[vsi->idx]->type,\n\t\t\tvsi->idx, vsi->type);\n\t\tgoto unlock_vsi;\n\t}\n\n\t/* updates the PF for this cleared vsi */\n\ti40e_put_lump(pf->qp_pile, vsi->base_queue, vsi->idx);\n\ti40e_put_lump(pf->irq_pile, vsi->base_vector, vsi->idx);\n\n\tbitmap_free(vsi->af_xdp_zc_qps);\n\ti40e_vsi_free_arrays(vsi, true);\n\ti40e_clear_rss_config_user(vsi);\n\n\tpf->vsi[vsi->idx] = NULL;\n\tif (vsi->idx < pf->next_vsi)\n\t\tpf->next_vsi = vsi->idx;\n\nunlock_vsi:\n\tmutex_unlock(&pf->switch_mutex);\nfree_vsi:\n\tkfree(vsi);\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_clear_rings - Deallocates the Rx and Tx rings for the provided VSI\n * @vsi: the VSI being cleaned\n **/\nstatic void i40e_vsi_clear_rings(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\tif (vsi->tx_rings && vsi->tx_rings[0]) {\n\t\tfor (i = 0; i < vsi->alloc_queue_pairs; i++) {\n\t\t\tkfree_rcu(vsi->tx_rings[i], rcu);\n\t\t\tvsi->tx_rings[i] = NULL;\n\t\t\tvsi->rx_rings[i] = NULL;\n\t\t\tif (vsi->xdp_rings)\n\t\t\t\tvsi->xdp_rings[i] = NULL;\n\t\t}\n\t}\n}\n\n/**\n * i40e_alloc_rings - Allocates the Rx and Tx rings for the provided VSI\n * @vsi: the VSI being configured\n **/\nstatic int i40e_alloc_rings(struct i40e_vsi *vsi)\n{\n\tint i, qpv = i40e_enabled_xdp_vsi(vsi) ? 3 : 2;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_ring *ring;\n\n\t/* Set basic values in the rings to be used later during open() */\n\tfor (i = 0; i < vsi->alloc_queue_pairs; i++) {\n\t\t/* allocate space for both Tx and Rx in one shot */\n\t\tring = kcalloc(qpv, sizeof(struct i40e_ring), GFP_KERNEL);\n\t\tif (!ring)\n\t\t\tgoto err_out;\n\n\t\tring->queue_index = i;\n\t\tring->reg_idx = vsi->base_queue + i;\n\t\tring->ring_active = false;\n\t\tring->vsi = vsi;\n\t\tring->netdev = vsi->netdev;\n\t\tring->dev = &pf->pdev->dev;\n\t\tring->count = vsi->num_tx_desc;\n\t\tring->size = 0;\n\t\tring->dcb_tc = 0;\n\t\tif (vsi->back->hw_features & I40E_HW_WB_ON_ITR_CAPABLE)\n\t\t\tring->flags = I40E_TXR_FLAGS_WB_ON_ITR;\n\t\tring->itr_setting = pf->tx_itr_default;\n\t\tvsi->tx_rings[i] = ring++;\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tgoto setup_rx;\n\n\t\tring->queue_index = vsi->alloc_queue_pairs + i;\n\t\tring->reg_idx = vsi->base_queue + ring->queue_index;\n\t\tring->ring_active = false;\n\t\tring->vsi = vsi;\n\t\tring->netdev = NULL;\n\t\tring->dev = &pf->pdev->dev;\n\t\tring->count = vsi->num_tx_desc;\n\t\tring->size = 0;\n\t\tring->dcb_tc = 0;\n\t\tif (vsi->back->hw_features & I40E_HW_WB_ON_ITR_CAPABLE)\n\t\t\tring->flags = I40E_TXR_FLAGS_WB_ON_ITR;\n\t\tset_ring_xdp(ring);\n\t\tring->itr_setting = pf->tx_itr_default;\n\t\tvsi->xdp_rings[i] = ring++;\n\nsetup_rx:\n\t\tring->queue_index = i;\n\t\tring->reg_idx = vsi->base_queue + i;\n\t\tring->ring_active = false;\n\t\tring->vsi = vsi;\n\t\tring->netdev = vsi->netdev;\n\t\tring->dev = &pf->pdev->dev;\n\t\tring->count = vsi->num_rx_desc;\n\t\tring->size = 0;\n\t\tring->dcb_tc = 0;\n\t\tring->itr_setting = pf->rx_itr_default;\n\t\tvsi->rx_rings[i] = ring;\n\t}\n\n\treturn 0;\n\nerr_out:\n\ti40e_vsi_clear_rings(vsi);\n\treturn -ENOMEM;\n}\n\n/**\n * i40e_reserve_msix_vectors - Reserve MSI-X vectors in the kernel\n * @pf: board private structure\n * @vectors: the number of MSI-X vectors to request\n *\n * Returns the number of vectors reserved, or error\n **/\nstatic int i40e_reserve_msix_vectors(struct i40e_pf *pf, int vectors)\n{\n\tvectors = pci_enable_msix_range(pf->pdev, pf->msix_entries,\n\t\t\t\t\tI40E_MIN_MSIX, vectors);\n\tif (vectors < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"MSI-X vector reservation failed: %d\\n\", vectors);\n\t\tvectors = 0;\n\t}\n\n\treturn vectors;\n}\n\n/**\n * i40e_init_msix - Setup the MSIX capability\n * @pf: board private structure\n *\n * Work with the OS to set up the MSIX vectors needed.\n *\n * Returns the number of vectors reserved or negative on failure\n **/\nstatic int i40e_init_msix(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint cpus, extra_vectors;\n\tint vectors_left;\n\tint v_budget, i;\n\tint v_actual;\n\tint iwarp_requested = 0;\n\n\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\treturn -ENODEV;\n\n\t/* The number of vectors we'll request will be comprised of:\n\t *   - Add 1 for \"other\" cause for Admin Queue events, etc.\n\t *   - The number of LAN queue pairs\n\t *\t- Queues being used for RSS.\n\t *\t\tWe don't need as many as max_rss_size vectors.\n\t *\t\tuse rss_size instead in the calculation since that\n\t *\t\tis governed by number of cpus in the system.\n\t *\t- assumes symmetric Tx/Rx pairing\n\t *   - The number of VMDq pairs\n\t *   - The CPU count within the NUMA node if iWARP is enabled\n\t * Once we count this up, try the request.\n\t *\n\t * If we can't get what we want, we'll simplify to nearly nothing\n\t * and try again.  If that still fails, we punt.\n\t */\n\tvectors_left = hw->func_caps.num_msix_vectors;\n\tv_budget = 0;\n\n\t/* reserve one vector for miscellaneous handler */\n\tif (vectors_left) {\n\t\tv_budget++;\n\t\tvectors_left--;\n\t}\n\n\t/* reserve some vectors for the main PF traffic queues. Initially we\n\t * only reserve at most 50% of the available vectors, in the case that\n\t * the number of online CPUs is large. This ensures that we can enable\n\t * extra features as well. Once we've enabled the other features, we\n\t * will use any remaining vectors to reach as close as we can to the\n\t * number of online CPUs.\n\t */\n\tcpus = num_online_cpus();\n\tpf->num_lan_msix = min_t(int, cpus, vectors_left / 2);\n\tvectors_left -= pf->num_lan_msix;\n\n\t/* reserve one vector for sideband flow director */\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\tif (vectors_left) {\n\t\t\tpf->num_fdsb_msix = 1;\n\t\t\tv_budget++;\n\t\t\tvectors_left--;\n\t\t} else {\n\t\t\tpf->num_fdsb_msix = 0;\n\t\t}\n\t}\n\n\t/* can we reserve enough for iWARP? */\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tiwarp_requested = pf->num_iwarp_msix;\n\n\t\tif (!vectors_left)\n\t\t\tpf->num_iwarp_msix = 0;\n\t\telse if (vectors_left < pf->num_iwarp_msix)\n\t\t\tpf->num_iwarp_msix = 1;\n\t\tv_budget += pf->num_iwarp_msix;\n\t\tvectors_left -= pf->num_iwarp_msix;\n\t}\n\n\t/* any vectors left over go for VMDq support */\n\tif (pf->flags & I40E_FLAG_VMDQ_ENABLED) {\n\t\tif (!vectors_left) {\n\t\t\tpf->num_vmdq_msix = 0;\n\t\t\tpf->num_vmdq_qps = 0;\n\t\t} else {\n\t\t\tint vmdq_vecs_wanted =\n\t\t\t\tpf->num_vmdq_vsis * pf->num_vmdq_qps;\n\t\t\tint vmdq_vecs =\n\t\t\t\tmin_t(int, vectors_left, vmdq_vecs_wanted);\n\n\t\t\t/* if we're short on vectors for what's desired, we limit\n\t\t\t * the queues per vmdq.  If this is still more than are\n\t\t\t * available, the user will need to change the number of\n\t\t\t * queues/vectors used by the PF later with the ethtool\n\t\t\t * channels command\n\t\t\t */\n\t\t\tif (vectors_left < vmdq_vecs_wanted) {\n\t\t\t\tpf->num_vmdq_qps = 1;\n\t\t\t\tvmdq_vecs_wanted = pf->num_vmdq_vsis;\n\t\t\t\tvmdq_vecs = min_t(int,\n\t\t\t\t\t\t  vectors_left,\n\t\t\t\t\t\t  vmdq_vecs_wanted);\n\t\t\t}\n\t\t\tpf->num_vmdq_msix = pf->num_vmdq_qps;\n\n\t\t\tv_budget += vmdq_vecs;\n\t\t\tvectors_left -= vmdq_vecs;\n\t\t}\n\t}\n\n\t/* On systems with a large number of SMP cores, we previously limited\n\t * the number of vectors for num_lan_msix to be at most 50% of the\n\t * available vectors, to allow for other features. Now, we add back\n\t * the remaining vectors. However, we ensure that the total\n\t * num_lan_msix will not exceed num_online_cpus(). To do this, we\n\t * calculate the number of vectors we can add without going over the\n\t * cap of CPUs. For systems with a small number of CPUs this will be\n\t * zero.\n\t */\n\textra_vectors = min_t(int, cpus - pf->num_lan_msix, vectors_left);\n\tpf->num_lan_msix += extra_vectors;\n\tvectors_left -= extra_vectors;\n\n\tWARN(vectors_left < 0,\n\t     \"Calculation of remaining vectors underflowed. This is an accounting bug when determining total MSI-X vectors.\\n\");\n\n\tv_budget += pf->num_lan_msix;\n\tpf->msix_entries = kcalloc(v_budget, sizeof(struct msix_entry),\n\t\t\t\t   GFP_KERNEL);\n\tif (!pf->msix_entries)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < v_budget; i++)\n\t\tpf->msix_entries[i].entry = i;\n\tv_actual = i40e_reserve_msix_vectors(pf, v_budget);\n\n\tif (v_actual < I40E_MIN_MSIX) {\n\t\tpf->flags &= ~I40E_FLAG_MSIX_ENABLED;\n\t\tkfree(pf->msix_entries);\n\t\tpf->msix_entries = NULL;\n\t\tpci_disable_msix(pf->pdev);\n\t\treturn -ENODEV;\n\n\t} else if (v_actual == I40E_MIN_MSIX) {\n\t\t/* Adjust for minimal MSIX use */\n\t\tpf->num_vmdq_vsis = 0;\n\t\tpf->num_vmdq_qps = 0;\n\t\tpf->num_lan_qps = 1;\n\t\tpf->num_lan_msix = 1;\n\n\t} else if (v_actual != v_budget) {\n\t\t/* If we have limited resources, we will start with no vectors\n\t\t * for the special features and then allocate vectors to some\n\t\t * of these features based on the policy and at the end disable\n\t\t * the features that did not get any vectors.\n\t\t */\n\t\tint vec;\n\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"MSI-X vector limit reached with %d, wanted %d, attempting to redistribute vectors\\n\",\n\t\t\t v_actual, v_budget);\n\t\t/* reserve the misc vector */\n\t\tvec = v_actual - 1;\n\n\t\t/* Scale vector usage down */\n\t\tpf->num_vmdq_msix = 1;    /* force VMDqs to only one vector */\n\t\tpf->num_vmdq_vsis = 1;\n\t\tpf->num_vmdq_qps = 1;\n\n\t\t/* partition out the remaining vectors */\n\t\tswitch (vec) {\n\t\tcase 2:\n\t\t\tpf->num_lan_msix = 1;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\t\t\tpf->num_lan_msix = 1;\n\t\t\t\tpf->num_iwarp_msix = 1;\n\t\t\t} else {\n\t\t\t\tpf->num_lan_msix = 2;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\t\t\tpf->num_iwarp_msix = min_t(int, (vec / 3),\n\t\t\t\t\t\t iwarp_requested);\n\t\t\t\tpf->num_vmdq_vsis = min_t(int, (vec / 3),\n\t\t\t\t\t\t  I40E_DEFAULT_NUM_VMDQ_VSI);\n\t\t\t} else {\n\t\t\t\tpf->num_vmdq_vsis = min_t(int, (vec / 2),\n\t\t\t\t\t\t  I40E_DEFAULT_NUM_VMDQ_VSI);\n\t\t\t}\n\t\t\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\t\t\tpf->num_fdsb_msix = 1;\n\t\t\t\tvec--;\n\t\t\t}\n\t\t\tpf->num_lan_msix = min_t(int,\n\t\t\t       (vec - (pf->num_iwarp_msix + pf->num_vmdq_vsis)),\n\t\t\t\t\t\t\t      pf->num_lan_msix);\n\t\t\tpf->num_lan_qps = pf->num_lan_msix;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif ((pf->flags & I40E_FLAG_FD_SB_ENABLED) &&\n\t    (pf->num_fdsb_msix == 0)) {\n\t\tdev_info(&pf->pdev->dev, \"Sideband Flowdir disabled, not enough MSI-X vectors\\n\");\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t}\n\tif ((pf->flags & I40E_FLAG_VMDQ_ENABLED) &&\n\t    (pf->num_vmdq_msix == 0)) {\n\t\tdev_info(&pf->pdev->dev, \"VMDq disabled, not enough MSI-X vectors\\n\");\n\t\tpf->flags &= ~I40E_FLAG_VMDQ_ENABLED;\n\t}\n\n\tif ((pf->flags & I40E_FLAG_IWARP_ENABLED) &&\n\t    (pf->num_iwarp_msix == 0)) {\n\t\tdev_info(&pf->pdev->dev, \"IWARP disabled, not enough MSI-X vectors\\n\");\n\t\tpf->flags &= ~I40E_FLAG_IWARP_ENABLED;\n\t}\n\ti40e_debug(&pf->hw, I40E_DEBUG_INIT,\n\t\t   \"MSI-X vector distribution: PF %d, VMDq %d, FDSB %d, iWARP %d\\n\",\n\t\t   pf->num_lan_msix,\n\t\t   pf->num_vmdq_msix * pf->num_vmdq_vsis,\n\t\t   pf->num_fdsb_msix,\n\t\t   pf->num_iwarp_msix);\n\n\treturn v_actual;\n}\n\n/**\n * i40e_vsi_alloc_q_vector - Allocate memory for a single interrupt vector\n * @vsi: the VSI being configured\n * @v_idx: index of the vector in the vsi struct\n * @cpu: cpu to be used on affinity_mask\n *\n * We allocate one q_vector.  If allocation fails we return -ENOMEM.\n **/\nstatic int i40e_vsi_alloc_q_vector(struct i40e_vsi *vsi, int v_idx, int cpu)\n{\n\tstruct i40e_q_vector *q_vector;\n\n\t/* allocate q_vector */\n\tq_vector = kzalloc(sizeof(struct i40e_q_vector), GFP_KERNEL);\n\tif (!q_vector)\n\t\treturn -ENOMEM;\n\n\tq_vector->vsi = vsi;\n\tq_vector->v_idx = v_idx;\n\tcpumask_copy(&q_vector->affinity_mask, cpu_possible_mask);\n\n\tif (vsi->netdev)\n\t\tnetif_napi_add(vsi->netdev, &q_vector->napi,\n\t\t\t       i40e_napi_poll, NAPI_POLL_WEIGHT);\n\n\t/* tie q_vector and vsi together */\n\tvsi->q_vectors[v_idx] = q_vector;\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_alloc_q_vectors - Allocate memory for interrupt vectors\n * @vsi: the VSI being configured\n *\n * We allocate one q_vector per queue interrupt.  If allocation fails we\n * return -ENOMEM.\n **/\nstatic int i40e_vsi_alloc_q_vectors(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint err, v_idx, num_q_vectors, current_cpu;\n\n\t/* if not MSIX, give the one vector only to the LAN VSI */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\tnum_q_vectors = vsi->num_q_vectors;\n\telse if (vsi == pf->vsi[pf->lan_vsi])\n\t\tnum_q_vectors = 1;\n\telse\n\t\treturn -EINVAL;\n\n\tcurrent_cpu = cpumask_first(cpu_online_mask);\n\n\tfor (v_idx = 0; v_idx < num_q_vectors; v_idx++) {\n\t\terr = i40e_vsi_alloc_q_vector(vsi, v_idx, current_cpu);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t\tcurrent_cpu = cpumask_next(current_cpu, cpu_online_mask);\n\t\tif (unlikely(current_cpu >= nr_cpu_ids))\n\t\t\tcurrent_cpu = cpumask_first(cpu_online_mask);\n\t}\n\n\treturn 0;\n\nerr_out:\n\twhile (v_idx--)\n\t\ti40e_free_q_vector(vsi, v_idx);\n\n\treturn err;\n}\n\n/**\n * i40e_init_interrupt_scheme - Determine proper interrupt scheme\n * @pf: board private structure to initialize\n **/\nstatic int i40e_init_interrupt_scheme(struct i40e_pf *pf)\n{\n\tint vectors = 0;\n\tssize_t size;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tvectors = i40e_init_msix(pf);\n\t\tif (vectors < 0) {\n\t\t\tpf->flags &= ~(I40E_FLAG_MSIX_ENABLED\t|\n\t\t\t\t       I40E_FLAG_IWARP_ENABLED\t|\n\t\t\t\t       I40E_FLAG_RSS_ENABLED\t|\n\t\t\t\t       I40E_FLAG_DCB_CAPABLE\t|\n\t\t\t\t       I40E_FLAG_DCB_ENABLED\t|\n\t\t\t\t       I40E_FLAG_SRIOV_ENABLED\t|\n\t\t\t\t       I40E_FLAG_FD_SB_ENABLED\t|\n\t\t\t\t       I40E_FLAG_FD_ATR_ENABLED\t|\n\t\t\t\t       I40E_FLAG_VMDQ_ENABLED);\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\n\t\t\t/* rework the queue expectations without MSIX */\n\t\t\ti40e_determine_queue_usage(pf);\n\t\t}\n\t}\n\n\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED) &&\n\t    (pf->flags & I40E_FLAG_MSI_ENABLED)) {\n\t\tdev_info(&pf->pdev->dev, \"MSI-X not available, trying MSI\\n\");\n\t\tvectors = pci_enable_msi(pf->pdev);\n\t\tif (vectors < 0) {\n\t\t\tdev_info(&pf->pdev->dev, \"MSI init failed - %d\\n\",\n\t\t\t\t vectors);\n\t\t\tpf->flags &= ~I40E_FLAG_MSI_ENABLED;\n\t\t}\n\t\tvectors = 1;  /* one MSI or Legacy vector */\n\t}\n\n\tif (!(pf->flags & (I40E_FLAG_MSIX_ENABLED | I40E_FLAG_MSI_ENABLED)))\n\t\tdev_info(&pf->pdev->dev, \"MSI-X and MSI not available, falling back to Legacy IRQ\\n\");\n\n\t/* set up vector assignment tracking */\n\tsize = sizeof(struct i40e_lump_tracking) + (sizeof(u16) * vectors);\n\tpf->irq_pile = kzalloc(size, GFP_KERNEL);\n\tif (!pf->irq_pile)\n\t\treturn -ENOMEM;\n\n\tpf->irq_pile->num_entries = vectors;\n\tpf->irq_pile->search_hint = 0;\n\n\t/* track first vector for misc interrupts, ignore return */\n\t(void)i40e_get_lump(pf, pf->irq_pile, 1, I40E_PILE_VALID_BIT - 1);\n\n\treturn 0;\n}\n\n/**\n * i40e_restore_interrupt_scheme - Restore the interrupt scheme\n * @pf: private board data structure\n *\n * Restore the interrupt scheme that was cleared when we suspended the\n * device. This should be called during resume to re-allocate the q_vectors\n * and reacquire IRQs.\n */\nstatic int i40e_restore_interrupt_scheme(struct i40e_pf *pf)\n{\n\tint err, i;\n\n\t/* We cleared the MSI and MSI-X flags when disabling the old interrupt\n\t * scheme. We need to re-enabled them here in order to attempt to\n\t * re-acquire the MSI or MSI-X vectors\n\t */\n\tpf->flags |= (I40E_FLAG_MSIX_ENABLED | I40E_FLAG_MSI_ENABLED);\n\n\terr = i40e_init_interrupt_scheme(pf);\n\tif (err)\n\t\treturn err;\n\n\t/* Now that we've re-acquired IRQs, we need to remap the vectors and\n\t * rings together again.\n\t */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i]) {\n\t\t\terr = i40e_vsi_alloc_q_vectors(pf->vsi[i]);\n\t\t\tif (err)\n\t\t\t\tgoto err_unwind;\n\t\t\ti40e_vsi_map_rings_to_vectors(pf->vsi[i]);\n\t\t}\n\t}\n\n\terr = i40e_setup_misc_vector(pf);\n\tif (err)\n\t\tgoto err_unwind;\n\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED)\n\t\ti40e_client_update_msix_info(pf);\n\n\treturn 0;\n\nerr_unwind:\n\twhile (i--) {\n\t\tif (pf->vsi[i])\n\t\t\ti40e_vsi_free_q_vectors(pf->vsi[i]);\n\t}\n\n\treturn err;\n}\n\n/**\n * i40e_setup_misc_vector_for_recovery_mode - Setup the misc vector to handle\n * non queue events in recovery mode\n * @pf: board private structure\n *\n * This sets up the handler for MSIX 0 or MSI/legacy, which is used to manage\n * the non-queue interrupts, e.g. AdminQ and errors in recovery mode.\n * This is handled differently than in recovery mode since no Tx/Rx resources\n * are being allocated.\n **/\nstatic int i40e_setup_misc_vector_for_recovery_mode(struct i40e_pf *pf)\n{\n\tint err;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\terr = i40e_setup_misc_vector(pf);\n\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"MSI-X misc vector request failed, error %d\\n\",\n\t\t\t\t err);\n\t\t\treturn err;\n\t\t}\n\t} else {\n\t\tu32 flags = pf->flags & I40E_FLAG_MSI_ENABLED ? 0 : IRQF_SHARED;\n\n\t\terr = request_irq(pf->pdev->irq, i40e_intr, flags,\n\t\t\t\t  pf->int_name, pf);\n\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"MSI/legacy misc vector request failed, error %d\\n\",\n\t\t\t\t err);\n\t\t\treturn err;\n\t\t}\n\t\ti40e_enable_misc_int_causes(pf);\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_setup_misc_vector - Setup the misc vector to handle non queue events\n * @pf: board private structure\n *\n * This sets up the handler for MSIX 0, which is used to manage the\n * non-queue interrupts, e.g. AdminQ and errors.  This is not used\n * when in MSI or Legacy interrupt mode.\n **/\nstatic int i40e_setup_misc_vector(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint err = 0;\n\n\t/* Only request the IRQ once, the first time through. */\n\tif (!test_and_set_bit(__I40E_MISC_IRQ_REQUESTED, pf->state)) {\n\t\terr = request_irq(pf->msix_entries[0].vector,\n\t\t\t\t  i40e_intr, 0, pf->int_name, pf);\n\t\tif (err) {\n\t\t\tclear_bit(__I40E_MISC_IRQ_REQUESTED, pf->state);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"request_irq for %s failed: %d\\n\",\n\t\t\t\t pf->int_name, err);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\ti40e_enable_misc_int_causes(pf);\n\n\t/* associate no queues to the misc vector */\n\twr32(hw, I40E_PFINT_LNKLST0, I40E_QUEUE_END_OF_LIST);\n\twr32(hw, I40E_PFINT_ITR0(I40E_RX_ITR), I40E_ITR_8K >> 1);\n\n\ti40e_flush(hw);\n\n\ti40e_irq_dynamic_enable_icr0(pf);\n\n\treturn err;\n}\n\n/**\n * i40e_get_rss_aq - Get RSS keys and lut by using AQ commands\n * @vsi: Pointer to vsi structure\n * @seed: Buffter to store the hash keys\n * @lut: Buffer to store the lookup table entries\n * @lut_size: Size of buffer to store the lookup table entries\n *\n * Return 0 on success, negative on failure\n */\nstatic int i40e_get_rss_aq(struct i40e_vsi *vsi, const u8 *seed,\n\t\t\t   u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret = 0;\n\n\tif (seed) {\n\t\tret = i40e_aq_get_rss_key(hw, vsi->id,\n\t\t\t(struct i40e_aqc_get_set_rss_key_data *)seed);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot get RSS key, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (lut) {\n\t\tbool pf_lut = vsi->type == I40E_VSI_MAIN ? true : false;\n\n\t\tret = i40e_aq_get_rss_lut(hw, vsi->id, pf_lut, lut, lut_size);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot get RSS lut, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_config_rss_reg - Configure RSS keys and lut by writing registers\n * @vsi: Pointer to vsi structure\n * @seed: RSS hash seed\n * @lut: Lookup table\n * @lut_size: Lookup table size\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_config_rss_reg(struct i40e_vsi *vsi, const u8 *seed,\n\t\t\t       const u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 vf_id = vsi->vf_id;\n\tu8 i;\n\n\t/* Fill out hash function seed */\n\tif (seed) {\n\t\tu32 *seed_dw = (u32 *)seed;\n\n\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\tfor (i = 0; i <= I40E_PFQF_HKEY_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_PFQF_HKEY(i), seed_dw[i]);\n\t\t} else if (vsi->type == I40E_VSI_SRIOV) {\n\t\t\tfor (i = 0; i <= I40E_VFQF_HKEY1_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_VFQF_HKEY1(i, vf_id), seed_dw[i]);\n\t\t} else {\n\t\t\tdev_err(&pf->pdev->dev, \"Cannot set RSS seed - invalid VSI type\\n\");\n\t\t}\n\t}\n\n\tif (lut) {\n\t\tu32 *lut_dw = (u32 *)lut;\n\n\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\tif (lut_size != I40E_HLUT_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\t\t\tfor (i = 0; i <= I40E_PFQF_HLUT_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_PFQF_HLUT(i), lut_dw[i]);\n\t\t} else if (vsi->type == I40E_VSI_SRIOV) {\n\t\t\tif (lut_size != I40E_VF_HLUT_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\t\t\tfor (i = 0; i <= I40E_VFQF_HLUT_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_VFQF_HLUT1(i, vf_id), lut_dw[i]);\n\t\t} else {\n\t\t\tdev_err(&pf->pdev->dev, \"Cannot set RSS LUT - invalid VSI type\\n\");\n\t\t}\n\t}\n\ti40e_flush(hw);\n\n\treturn 0;\n}\n\n/**\n * i40e_get_rss_reg - Get the RSS keys and lut by reading registers\n * @vsi: Pointer to VSI structure\n * @seed: Buffer to store the keys\n * @lut: Buffer to store the lookup table entries\n * @lut_size: Size of buffer to store the lookup table entries\n *\n * Returns 0 on success, negative on failure\n */\nstatic int i40e_get_rss_reg(struct i40e_vsi *vsi, u8 *seed,\n\t\t\t    u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 i;\n\n\tif (seed) {\n\t\tu32 *seed_dw = (u32 *)seed;\n\n\t\tfor (i = 0; i <= I40E_PFQF_HKEY_MAX_INDEX; i++)\n\t\t\tseed_dw[i] = i40e_read_rx_ctl(hw, I40E_PFQF_HKEY(i));\n\t}\n\tif (lut) {\n\t\tu32 *lut_dw = (u32 *)lut;\n\n\t\tif (lut_size != I40E_HLUT_ARRAY_SIZE)\n\t\t\treturn -EINVAL;\n\t\tfor (i = 0; i <= I40E_PFQF_HLUT_MAX_INDEX; i++)\n\t\t\tlut_dw[i] = rd32(hw, I40E_PFQF_HLUT(i));\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_config_rss - Configure RSS keys and lut\n * @vsi: Pointer to VSI structure\n * @seed: RSS hash seed\n * @lut: Lookup table\n * @lut_size: Lookup table size\n *\n * Returns 0 on success, negative on failure\n */\nint i40e_config_rss(struct i40e_vsi *vsi, u8 *seed, u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (pf->hw_features & I40E_HW_RSS_AQ_CAPABLE)\n\t\treturn i40e_config_rss_aq(vsi, seed, lut, lut_size);\n\telse\n\t\treturn i40e_config_rss_reg(vsi, seed, lut, lut_size);\n}\n\n/**\n * i40e_get_rss - Get RSS keys and lut\n * @vsi: Pointer to VSI structure\n * @seed: Buffer to store the keys\n * @lut: Buffer to store the lookup table entries\n * @lut_size: Size of buffer to store the lookup table entries\n *\n * Returns 0 on success, negative on failure\n */\nint i40e_get_rss(struct i40e_vsi *vsi, u8 *seed, u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (pf->hw_features & I40E_HW_RSS_AQ_CAPABLE)\n\t\treturn i40e_get_rss_aq(vsi, seed, lut, lut_size);\n\telse\n\t\treturn i40e_get_rss_reg(vsi, seed, lut, lut_size);\n}\n\n/**\n * i40e_fill_rss_lut - Fill the RSS lookup table with default values\n * @pf: Pointer to board private structure\n * @lut: Lookup table\n * @rss_table_size: Lookup table size\n * @rss_size: Range of queue number for hashing\n */\nvoid i40e_fill_rss_lut(struct i40e_pf *pf, u8 *lut,\n\t\t       u16 rss_table_size, u16 rss_size)\n{\n\tu16 i;\n\n\tfor (i = 0; i < rss_table_size; i++)\n\t\tlut[i] = i % rss_size;\n}\n\n/**\n * i40e_pf_config_rss - Prepare for RSS if used\n * @pf: board private structure\n **/\nstatic int i40e_pf_config_rss(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tu8 seed[I40E_HKEY_ARRAY_SIZE];\n\tu8 *lut;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 reg_val;\n\tu64 hena;\n\tint ret;\n\n\t/* By default we enable TCP/UDP with IPv4/IPv6 ptypes */\n\thena = (u64)i40e_read_rx_ctl(hw, I40E_PFQF_HENA(0)) |\n\t\t((u64)i40e_read_rx_ctl(hw, I40E_PFQF_HENA(1)) << 32);\n\thena |= i40e_pf_get_default_rss_hena(pf);\n\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(0), (u32)hena);\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(1), (u32)(hena >> 32));\n\n\t/* Determine the RSS table size based on the hardware capabilities */\n\treg_val = i40e_read_rx_ctl(hw, I40E_PFQF_CTL_0);\n\treg_val = (pf->rss_table_size == 512) ?\n\t\t\t(reg_val | I40E_PFQF_CTL_0_HASHLUTSIZE_512) :\n\t\t\t(reg_val & ~I40E_PFQF_CTL_0_HASHLUTSIZE_512);\n\ti40e_write_rx_ctl(hw, I40E_PFQF_CTL_0, reg_val);\n\n\t/* Determine the RSS size of the VSI */\n\tif (!vsi->rss_size) {\n\t\tu16 qcount;\n\t\t/* If the firmware does something weird during VSI init, we\n\t\t * could end up with zero TCs. Check for that to avoid\n\t\t * divide-by-zero. It probably won't pass traffic, but it also\n\t\t * won't panic.\n\t\t */\n\t\tqcount = vsi->num_queue_pairs /\n\t\t\t (vsi->tc_config.numtc ? vsi->tc_config.numtc : 1);\n\t\tvsi->rss_size = min_t(int, pf->alloc_rss_size, qcount);\n\t}\n\tif (!vsi->rss_size)\n\t\treturn -EINVAL;\n\n\tlut = kzalloc(vsi->rss_table_size, GFP_KERNEL);\n\tif (!lut)\n\t\treturn -ENOMEM;\n\n\t/* Use user configured lut if there is one, otherwise use default */\n\tif (vsi->rss_lut_user)\n\t\tmemcpy(lut, vsi->rss_lut_user, vsi->rss_table_size);\n\telse\n\t\ti40e_fill_rss_lut(pf, lut, vsi->rss_table_size, vsi->rss_size);\n\n\t/* Use user configured hash key if there is one, otherwise\n\t * use default.\n\t */\n\tif (vsi->rss_hkey_user)\n\t\tmemcpy(seed, vsi->rss_hkey_user, I40E_HKEY_ARRAY_SIZE);\n\telse\n\t\tnetdev_rss_key_fill((void *)seed, I40E_HKEY_ARRAY_SIZE);\n\tret = i40e_config_rss(vsi, seed, lut, vsi->rss_table_size);\n\tkfree(lut);\n\n\treturn ret;\n}\n\n/**\n * i40e_reconfig_rss_queues - change number of queues for rss and rebuild\n * @pf: board private structure\n * @queue_count: the requested queue count for rss.\n *\n * returns 0 if rss is not enabled, if enabled returns the final rss queue\n * count which may be different from the requested queue count.\n * Note: expects to be called while under rtnl_lock()\n **/\nint i40e_reconfig_rss_queues(struct i40e_pf *pf, int queue_count)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tint new_rss_size;\n\n\tif (!(pf->flags & I40E_FLAG_RSS_ENABLED))\n\t\treturn 0;\n\n\tqueue_count = min_t(int, queue_count, num_online_cpus());\n\tnew_rss_size = min_t(int, queue_count, pf->rss_size_max);\n\n\tif (queue_count != vsi->num_queue_pairs) {\n\t\tu16 qcount;\n\n\t\tvsi->req_queue_pairs = queue_count;\n\t\ti40e_prep_for_reset(pf, true);\n\n\t\tpf->alloc_rss_size = new_rss_size;\n\n\t\ti40e_reset_and_rebuild(pf, true, true);\n\n\t\t/* Discard the user configured hash keys and lut, if less\n\t\t * queues are enabled.\n\t\t */\n\t\tif (queue_count < vsi->rss_size) {\n\t\t\ti40e_clear_rss_config_user(vsi);\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"discard user configured hash keys and lut\\n\");\n\t\t}\n\n\t\t/* Reset vsi->rss_size, as number of enabled queues changed */\n\t\tqcount = vsi->num_queue_pairs / vsi->tc_config.numtc;\n\t\tvsi->rss_size = min_t(int, pf->alloc_rss_size, qcount);\n\n\t\ti40e_pf_config_rss(pf);\n\t}\n\tdev_info(&pf->pdev->dev, \"User requested queue count/HW max RSS count:  %d/%d\\n\",\n\t\t vsi->req_queue_pairs, pf->rss_size_max);\n\treturn pf->alloc_rss_size;\n}\n\n/**\n * i40e_get_partition_bw_setting - Retrieve BW settings for this PF partition\n * @pf: board private structure\n **/\ni40e_status i40e_get_partition_bw_setting(struct i40e_pf *pf)\n{\n\ti40e_status status;\n\tbool min_valid, max_valid;\n\tu32 max_bw, min_bw;\n\n\tstatus = i40e_read_bw_from_alt_ram(&pf->hw, &max_bw, &min_bw,\n\t\t\t\t\t   &min_valid, &max_valid);\n\n\tif (!status) {\n\t\tif (min_valid)\n\t\t\tpf->min_bw = min_bw;\n\t\tif (max_valid)\n\t\t\tpf->max_bw = max_bw;\n\t}\n\n\treturn status;\n}\n\n/**\n * i40e_set_partition_bw_setting - Set BW settings for this PF partition\n * @pf: board private structure\n **/\ni40e_status i40e_set_partition_bw_setting(struct i40e_pf *pf)\n{\n\tstruct i40e_aqc_configure_partition_bw_data bw_data;\n\ti40e_status status;\n\n\t/* Set the valid bit for this PF */\n\tbw_data.pf_valid_bits = cpu_to_le16(BIT(pf->hw.pf_id));\n\tbw_data.max_bw[pf->hw.pf_id] = pf->max_bw & I40E_ALT_BW_VALUE_MASK;\n\tbw_data.min_bw[pf->hw.pf_id] = pf->min_bw & I40E_ALT_BW_VALUE_MASK;\n\n\t/* Set the new bandwidths */\n\tstatus = i40e_aq_configure_partition_bw(&pf->hw, &bw_data, NULL);\n\n\treturn status;\n}\n\n/**\n * i40e_commit_partition_bw_setting - Commit BW settings for this PF partition\n * @pf: board private structure\n **/\ni40e_status i40e_commit_partition_bw_setting(struct i40e_pf *pf)\n{\n\t/* Commit temporary BW setting to permanent NVM image */\n\tenum i40e_admin_queue_err last_aq_status;\n\ti40e_status ret;\n\tu16 nvm_word;\n\n\tif (pf->hw.partition_id != 1) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Commit BW only works on partition 1! This is partition %d\",\n\t\t\t pf->hw.partition_id);\n\t\tret = I40E_NOT_SUPPORTED;\n\t\tgoto bw_commit_out;\n\t}\n\n\t/* Acquire NVM for read access */\n\tret = i40e_acquire_nvm(&pf->hw, I40E_RESOURCE_READ);\n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Cannot acquire NVM for read access, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\tgoto bw_commit_out;\n\t}\n\n\t/* Read word 0x10 of NVM - SW compatibility word 1 */\n\tret = i40e_aq_read_nvm(&pf->hw,\n\t\t\t       I40E_SR_NVM_CONTROL_WORD,\n\t\t\t       0x10, sizeof(nvm_word), &nvm_word,\n\t\t\t       false, NULL);\n\t/* Save off last admin queue command status before releasing\n\t * the NVM\n\t */\n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\ti40e_release_nvm(&pf->hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"NVM read error, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\tgoto bw_commit_out;\n\t}\n\n\t/* Wait a bit for NVM release to complete */\n\tmsleep(50);\n\n\t/* Acquire NVM for write access */\n\tret = i40e_acquire_nvm(&pf->hw, I40E_RESOURCE_WRITE);\n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Cannot acquire NVM for write access, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\tgoto bw_commit_out;\n\t}\n\t/* Write it back out unchanged to initiate update NVM,\n\t * which will force a write of the shadow (alt) RAM to\n\t * the NVM - thus storing the bandwidth values permanently.\n\t */\n\tret = i40e_aq_update_nvm(&pf->hw,\n\t\t\t\t I40E_SR_NVM_CONTROL_WORD,\n\t\t\t\t 0x10, sizeof(nvm_word),\n\t\t\t\t &nvm_word, true, 0, NULL);\n\t/* Save off last admin queue command status before releasing\n\t * the NVM\n\t */\n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\ti40e_release_nvm(&pf->hw);\n\tif (ret)\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"BW settings NOT SAVED, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\nbw_commit_out:\n\n\treturn ret;\n}\n\n/**\n * i40e_sw_init - Initialize general software structures (struct i40e_pf)\n * @pf: board private structure to initialize\n *\n * i40e_sw_init initializes the Adapter private data structure.\n * Fields are initialized based on PCI device information and\n * OS network device settings (MTU size).\n **/\nstatic int i40e_sw_init(struct i40e_pf *pf)\n{\n\tint err = 0;\n\tint size;\n\n\t/* Set default capability flags */\n\tpf->flags = I40E_FLAG_RX_CSUM_ENABLED |\n\t\t    I40E_FLAG_MSI_ENABLED     |\n\t\t    I40E_FLAG_MSIX_ENABLED;\n\n\t/* Set default ITR */\n\tpf->rx_itr_default = I40E_ITR_RX_DEF;\n\tpf->tx_itr_default = I40E_ITR_TX_DEF;\n\n\t/* Depending on PF configurations, it is possible that the RSS\n\t * maximum might end up larger than the available queues\n\t */\n\tpf->rss_size_max = BIT(pf->hw.func_caps.rss_table_entry_width);\n\tpf->alloc_rss_size = 1;\n\tpf->rss_table_size = pf->hw.func_caps.rss_table_size;\n\tpf->rss_size_max = min_t(int, pf->rss_size_max,\n\t\t\t\t pf->hw.func_caps.num_tx_qp);\n\tif (pf->hw.func_caps.rss) {\n\t\tpf->flags |= I40E_FLAG_RSS_ENABLED;\n\t\tpf->alloc_rss_size = min_t(int, pf->rss_size_max,\n\t\t\t\t\t   num_online_cpus());\n\t}\n\n\t/* MFP mode enabled */\n\tif (pf->hw.func_caps.npar_enable || pf->hw.func_caps.flex10_enable) {\n\t\tpf->flags |= I40E_FLAG_MFP_ENABLED;\n\t\tdev_info(&pf->pdev->dev, \"MFP mode Enabled\\n\");\n\t\tif (i40e_get_partition_bw_setting(pf)) {\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"Could not get partition bw settings\\n\");\n\t\t} else {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Partition BW Min = %8.8x, Max = %8.8x\\n\",\n\t\t\t\t pf->min_bw, pf->max_bw);\n\n\t\t\t/* nudge the Tx scheduler */\n\t\t\ti40e_set_partition_bw_setting(pf);\n\t\t}\n\t}\n\n\tif ((pf->hw.func_caps.fd_filters_guaranteed > 0) ||\n\t    (pf->hw.func_caps.fd_filters_best_effort > 0)) {\n\t\tpf->flags |= I40E_FLAG_FD_ATR_ENABLED;\n\t\tpf->atr_sample_rate = I40E_DEFAULT_ATR_SAMPLE_RATE;\n\t\tif (pf->flags & I40E_FLAG_MFP_ENABLED &&\n\t\t    pf->hw.num_partitions > 1)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Flow Director Sideband mode Disabled in MFP mode\\n\");\n\t\telse\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\tpf->fdir_pf_filter_count =\n\t\t\t\t pf->hw.func_caps.fd_filters_guaranteed;\n\t\tpf->hw.fdir_shared_filter_count =\n\t\t\t\t pf->hw.func_caps.fd_filters_best_effort;\n\t}\n\n\tif (pf->hw.mac.type == I40E_MAC_X722) {\n\t\tpf->hw_features |= (I40E_HW_RSS_AQ_CAPABLE |\n\t\t\t\t    I40E_HW_128_QP_RSS_CAPABLE |\n\t\t\t\t    I40E_HW_ATR_EVICT_CAPABLE |\n\t\t\t\t    I40E_HW_WB_ON_ITR_CAPABLE |\n\t\t\t\t    I40E_HW_MULTIPLE_TCP_UDP_RSS_PCTYPE |\n\t\t\t\t    I40E_HW_NO_PCI_LINK_CHECK |\n\t\t\t\t    I40E_HW_USE_SET_LLDP_MIB |\n\t\t\t\t    I40E_HW_GENEVE_OFFLOAD_CAPABLE |\n\t\t\t\t    I40E_HW_PTP_L4_CAPABLE |\n\t\t\t\t    I40E_HW_WOL_MC_MAGIC_PKT_WAKE |\n\t\t\t\t    I40E_HW_OUTER_UDP_CSUM_CAPABLE);\n\n#define I40E_FDEVICT_PCTYPE_DEFAULT 0xc03\n\t\tif (rd32(&pf->hw, I40E_GLQF_FDEVICTENA(1)) !=\n\t\t    I40E_FDEVICT_PCTYPE_DEFAULT) {\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"FD EVICT PCTYPES are not right, disable FD HW EVICT\\n\");\n\t\t\tpf->hw_features &= ~I40E_HW_ATR_EVICT_CAPABLE;\n\t\t}\n\t} else if ((pf->hw.aq.api_maj_ver > 1) ||\n\t\t   ((pf->hw.aq.api_maj_ver == 1) &&\n\t\t    (pf->hw.aq.api_min_ver > 4))) {\n\t\t/* Supported in FW API version higher than 1.4 */\n\t\tpf->hw_features |= I40E_HW_GENEVE_OFFLOAD_CAPABLE;\n\t}\n\n\t/* Enable HW ATR eviction if possible */\n\tif (pf->hw_features & I40E_HW_ATR_EVICT_CAPABLE)\n\t\tpf->flags |= I40E_FLAG_HW_ATR_EVICT_ENABLED;\n\n\tif ((pf->hw.mac.type == I40E_MAC_XL710) &&\n\t    (((pf->hw.aq.fw_maj_ver == 4) && (pf->hw.aq.fw_min_ver < 33)) ||\n\t    (pf->hw.aq.fw_maj_ver < 4))) {\n\t\tpf->hw_features |= I40E_HW_RESTART_AUTONEG;\n\t\t/* No DCB support  for FW < v4.33 */\n\t\tpf->hw_features |= I40E_HW_NO_DCB_SUPPORT;\n\t}\n\n\t/* Disable FW LLDP if FW < v4.3 */\n\tif ((pf->hw.mac.type == I40E_MAC_XL710) &&\n\t    (((pf->hw.aq.fw_maj_ver == 4) && (pf->hw.aq.fw_min_ver < 3)) ||\n\t    (pf->hw.aq.fw_maj_ver < 4)))\n\t\tpf->hw_features |= I40E_HW_STOP_FW_LLDP;\n\n\t/* Use the FW Set LLDP MIB API if FW > v4.40 */\n\tif ((pf->hw.mac.type == I40E_MAC_XL710) &&\n\t    (((pf->hw.aq.fw_maj_ver == 4) && (pf->hw.aq.fw_min_ver >= 40)) ||\n\t    (pf->hw.aq.fw_maj_ver >= 5)))\n\t\tpf->hw_features |= I40E_HW_USE_SET_LLDP_MIB;\n\n\t/* Enable PTP L4 if FW > v6.0 */\n\tif (pf->hw.mac.type == I40E_MAC_XL710 &&\n\t    pf->hw.aq.fw_maj_ver >= 6)\n\t\tpf->hw_features |= I40E_HW_PTP_L4_CAPABLE;\n\n\tif (pf->hw.func_caps.vmdq && num_online_cpus() != 1) {\n\t\tpf->num_vmdq_vsis = I40E_DEFAULT_NUM_VMDQ_VSI;\n\t\tpf->flags |= I40E_FLAG_VMDQ_ENABLED;\n\t\tpf->num_vmdq_qps = i40e_default_queues_per_vmdq(pf);\n\t}\n\n\tif (pf->hw.func_caps.iwarp && num_online_cpus() != 1) {\n\t\tpf->flags |= I40E_FLAG_IWARP_ENABLED;\n\t\t/* IWARP needs one extra vector for CQP just like MISC.*/\n\t\tpf->num_iwarp_msix = (int)num_online_cpus() + 1;\n\t}\n\t/* Stopping FW LLDP engine is supported on XL710 and X722\n\t * starting from FW versions determined in i40e_init_adminq.\n\t * Stopping the FW LLDP engine is not supported on XL710\n\t * if NPAR is functioning so unset this hw flag in this case.\n\t */\n\tif (pf->hw.mac.type == I40E_MAC_XL710 &&\n\t    pf->hw.func_caps.npar_enable &&\n\t    (pf->hw.flags & I40E_HW_FLAG_FW_LLDP_STOPPABLE))\n\t\tpf->hw.flags &= ~I40E_HW_FLAG_FW_LLDP_STOPPABLE;\n\n#ifdef CONFIG_PCI_IOV\n\tif (pf->hw.func_caps.num_vfs && pf->hw.partition_id == 1) {\n\t\tpf->num_vf_qps = I40E_DEFAULT_QUEUES_PER_VF;\n\t\tpf->flags |= I40E_FLAG_SRIOV_ENABLED;\n\t\tpf->num_req_vfs = min_t(int,\n\t\t\t\t\tpf->hw.func_caps.num_vfs,\n\t\t\t\t\tI40E_MAX_VF_COUNT);\n\t}\n#endif /* CONFIG_PCI_IOV */\n\tpf->eeprom_version = 0xDEAD;\n\tpf->lan_veb = I40E_NO_VEB;\n\tpf->lan_vsi = I40E_NO_VSI;\n\n\t/* By default FW has this off for performance reasons */\n\tpf->flags &= ~I40E_FLAG_VEB_STATS_ENABLED;\n\n\t/* set up queue assignment tracking */\n\tsize = sizeof(struct i40e_lump_tracking)\n\t\t+ (sizeof(u16) * pf->hw.func_caps.num_tx_qp);\n\tpf->qp_pile = kzalloc(size, GFP_KERNEL);\n\tif (!pf->qp_pile) {\n\t\terr = -ENOMEM;\n\t\tgoto sw_init_done;\n\t}\n\tpf->qp_pile->num_entries = pf->hw.func_caps.num_tx_qp;\n\tpf->qp_pile->search_hint = 0;\n\n\tpf->tx_timeout_recovery_level = 1;\n\n\tmutex_init(&pf->switch_mutex);\n\nsw_init_done:\n\treturn err;\n}\n\n/**\n * i40e_set_ntuple - set the ntuple feature flag and take action\n * @pf: board private structure to initialize\n * @features: the feature set that the stack is suggesting\n *\n * returns a bool to indicate if reset needs to happen\n **/\nbool i40e_set_ntuple(struct i40e_pf *pf, netdev_features_t features)\n{\n\tbool need_reset = false;\n\n\t/* Check if Flow Director n-tuple support was enabled or disabled.  If\n\t * the state changed, we need to reset.\n\t */\n\tif (features & NETIF_F_NTUPLE) {\n\t\t/* Enable filters and mark for reset */\n\t\tif (!(pf->flags & I40E_FLAG_FD_SB_ENABLED))\n\t\t\tneed_reset = true;\n\t\t/* enable FD_SB only if there is MSI-X vector and no cloud\n\t\t * filters exist\n\t\t */\n\t\tif (pf->num_fdsb_msix > 0 && !pf->num_cloud_filters) {\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_INACTIVE;\n\t\t}\n\t} else {\n\t\t/* turn off filters, mark for reset and clear SW filter list */\n\t\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\t\tneed_reset = true;\n\t\t\ti40e_fdir_filter_exit(pf);\n\t\t}\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\tclear_bit(__I40E_FD_SB_AUTO_DISABLED, pf->state);\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\n\t\t/* reset fd counters */\n\t\tpf->fd_add_err = 0;\n\t\tpf->fd_atr_cnt = 0;\n\t\t/* if ATR was auto disabled it can be re-enabled. */\n\t\tif (test_and_clear_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state))\n\t\t\tif ((pf->flags & I40E_FLAG_FD_ATR_ENABLED) &&\n\t\t\t    (I40E_DEBUG_FD & pf->hw.debug_mask))\n\t\t\t\tdev_info(&pf->pdev->dev, \"ATR re-enabled.\\n\");\n\t}\n\treturn need_reset;\n}\n\n/**\n * i40e_clear_rss_lut - clear the rx hash lookup table\n * @vsi: the VSI being configured\n **/\nstatic void i40e_clear_rss_lut(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 vf_id = vsi->vf_id;\n\tu8 i;\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\tfor (i = 0; i <= I40E_PFQF_HLUT_MAX_INDEX; i++)\n\t\t\twr32(hw, I40E_PFQF_HLUT(i), 0);\n\t} else if (vsi->type == I40E_VSI_SRIOV) {\n\t\tfor (i = 0; i <= I40E_VFQF_HLUT_MAX_INDEX; i++)\n\t\t\ti40e_write_rx_ctl(hw, I40E_VFQF_HLUT1(i, vf_id), 0);\n\t} else {\n\t\tdev_err(&pf->pdev->dev, \"Cannot set RSS LUT - invalid VSI type\\n\");\n\t}\n}\n\n/**\n * i40e_set_features - set the netdev feature flags\n * @netdev: ptr to the netdev being adjusted\n * @features: the feature set that the stack is suggesting\n * Note: expects to be called while under rtnl_lock()\n **/\nstatic int i40e_set_features(struct net_device *netdev,\n\t\t\t     netdev_features_t features)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tbool need_reset;\n\n\tif (features & NETIF_F_RXHASH && !(netdev->features & NETIF_F_RXHASH))\n\t\ti40e_pf_config_rss(pf);\n\telse if (!(features & NETIF_F_RXHASH) &&\n\t\t netdev->features & NETIF_F_RXHASH)\n\t\ti40e_clear_rss_lut(vsi);\n\n\tif (features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\ti40e_vlan_stripping_enable(vsi);\n\telse\n\t\ti40e_vlan_stripping_disable(vsi);\n\n\tif (!(features & NETIF_F_HW_TC) && pf->num_cloud_filters) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Offloaded tc filters active, can't turn hw_tc_offload off\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!(features & NETIF_F_HW_L2FW_DOFFLOAD) && vsi->macvlan_cnt)\n\t\ti40e_del_all_macvlans(vsi);\n\n\tneed_reset = i40e_set_ntuple(pf, features);\n\n\tif (need_reset)\n\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG, true);\n\n\treturn 0;\n}\n\n/**\n * i40e_get_udp_port_idx - Lookup a possibly offloaded for Rx UDP port\n * @pf: board private structure\n * @port: The UDP port to look up\n *\n * Returns the index number or I40E_MAX_PF_UDP_OFFLOAD_PORTS if port not found\n **/\nstatic u8 i40e_get_udp_port_idx(struct i40e_pf *pf, u16 port)\n{\n\tu8 i;\n\n\tfor (i = 0; i < I40E_MAX_PF_UDP_OFFLOAD_PORTS; i++) {\n\t\t/* Do not report ports with pending deletions as\n\t\t * being available.\n\t\t */\n\t\tif (!port && (pf->pending_udp_bitmap & BIT_ULL(i)))\n\t\t\tcontinue;\n\t\tif (pf->udp_ports[i].port == port)\n\t\t\treturn i;\n\t}\n\n\treturn i;\n}\n\n/**\n * i40e_udp_tunnel_add - Get notifications about UDP tunnel ports that come up\n * @netdev: This physical port's netdev\n * @ti: Tunnel endpoint information\n **/\nstatic void i40e_udp_tunnel_add(struct net_device *netdev,\n\t\t\t\tstruct udp_tunnel_info *ti)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tu16 port = ntohs(ti->port);\n\tu8 next_idx;\n\tu8 idx;\n\n\tidx = i40e_get_udp_port_idx(pf, port);\n\n\t/* Check if port already exists */\n\tif (idx < I40E_MAX_PF_UDP_OFFLOAD_PORTS) {\n\t\tnetdev_info(netdev, \"port %d already offloaded\\n\", port);\n\t\treturn;\n\t}\n\n\t/* Now check if there is space to add the new port */\n\tnext_idx = i40e_get_udp_port_idx(pf, 0);\n\n\tif (next_idx == I40E_MAX_PF_UDP_OFFLOAD_PORTS) {\n\t\tnetdev_info(netdev, \"maximum number of offloaded UDP ports reached, not adding port %d\\n\",\n\t\t\t    port);\n\t\treturn;\n\t}\n\n\tswitch (ti->type) {\n\tcase UDP_TUNNEL_TYPE_VXLAN:\n\t\tpf->udp_ports[next_idx].type = I40E_AQC_TUNNEL_TYPE_VXLAN;\n\t\tbreak;\n\tcase UDP_TUNNEL_TYPE_GENEVE:\n\t\tif (!(pf->hw_features & I40E_HW_GENEVE_OFFLOAD_CAPABLE))\n\t\t\treturn;\n\t\tpf->udp_ports[next_idx].type = I40E_AQC_TUNNEL_TYPE_NGE;\n\t\tbreak;\n\tdefault:\n\t\treturn;\n\t}\n\n\t/* New port: add it and mark its index in the bitmap */\n\tpf->udp_ports[next_idx].port = port;\n\tpf->udp_ports[next_idx].filter_index = I40E_UDP_PORT_INDEX_UNUSED;\n\tpf->pending_udp_bitmap |= BIT_ULL(next_idx);\n\tset_bit(__I40E_UDP_FILTER_SYNC_PENDING, pf->state);\n}\n\n/**\n * i40e_udp_tunnel_del - Get notifications about UDP tunnel ports that go away\n * @netdev: This physical port's netdev\n * @ti: Tunnel endpoint information\n **/\nstatic void i40e_udp_tunnel_del(struct net_device *netdev,\n\t\t\t\tstruct udp_tunnel_info *ti)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tu16 port = ntohs(ti->port);\n\tu8 idx;\n\n\tidx = i40e_get_udp_port_idx(pf, port);\n\n\t/* Check if port already exists */\n\tif (idx >= I40E_MAX_PF_UDP_OFFLOAD_PORTS)\n\t\tgoto not_found;\n\n\tswitch (ti->type) {\n\tcase UDP_TUNNEL_TYPE_VXLAN:\n\t\tif (pf->udp_ports[idx].type != I40E_AQC_TUNNEL_TYPE_VXLAN)\n\t\t\tgoto not_found;\n\t\tbreak;\n\tcase UDP_TUNNEL_TYPE_GENEVE:\n\t\tif (pf->udp_ports[idx].type != I40E_AQC_TUNNEL_TYPE_NGE)\n\t\t\tgoto not_found;\n\t\tbreak;\n\tdefault:\n\t\tgoto not_found;\n\t}\n\n\t/* if port exists, set it to 0 (mark for deletion)\n\t * and make it pending\n\t */\n\tpf->udp_ports[idx].port = 0;\n\n\t/* Toggle pending bit instead of setting it. This way if we are\n\t * deleting a port that has yet to be added we just clear the pending\n\t * bit and don't have to worry about it.\n\t */\n\tpf->pending_udp_bitmap ^= BIT_ULL(idx);\n\tset_bit(__I40E_UDP_FILTER_SYNC_PENDING, pf->state);\n\n\treturn;\nnot_found:\n\tnetdev_warn(netdev, \"UDP port %d was not found, not deleting\\n\",\n\t\t    port);\n}\n\nstatic int i40e_get_phys_port_id(struct net_device *netdev,\n\t\t\t\t struct netdev_phys_item_id *ppid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_pf *pf = np->vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\tif (!(pf->hw_features & I40E_HW_PORT_ID_VALID))\n\t\treturn -EOPNOTSUPP;\n\n\tppid->id_len = min_t(int, sizeof(hw->mac.port_addr), sizeof(ppid->id));\n\tmemcpy(ppid->id, hw->mac.port_addr, ppid->id_len);\n\n\treturn 0;\n}\n\n/**\n * i40e_ndo_fdb_add - add an entry to the hardware database\n * @ndm: the input from the stack\n * @tb: pointer to array of nladdr (unused)\n * @dev: the net device pointer\n * @addr: the MAC address entry being added\n * @vid: VLAN ID\n * @flags: instructions from stack about fdb operation\n */\nstatic int i40e_ndo_fdb_add(struct ndmsg *ndm, struct nlattr *tb[],\n\t\t\t    struct net_device *dev,\n\t\t\t    const unsigned char *addr, u16 vid,\n\t\t\t    u16 flags,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_pf *pf = np->vsi->back;\n\tint err = 0;\n\n\tif (!(pf->flags & I40E_FLAG_SRIOV_ENABLED))\n\t\treturn -EOPNOTSUPP;\n\n\tif (vid) {\n\t\tpr_info(\"%s: vlans aren't supported yet for dev_uc|mc_add()\\n\", dev->name);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Hardware does not support aging addresses so if a\n\t * ndm_state is given only allow permanent addresses\n\t */\n\tif (ndm->ndm_state && !(ndm->ndm_state & NUD_PERMANENT)) {\n\t\tnetdev_info(dev, \"FDB only supports static addresses\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (is_unicast_ether_addr(addr) || is_link_local_ether_addr(addr))\n\t\terr = dev_uc_add_excl(dev, addr);\n\telse if (is_multicast_ether_addr(addr))\n\t\terr = dev_mc_add_excl(dev, addr);\n\telse\n\t\terr = -EINVAL;\n\n\t/* Only return duplicate errors if NLM_F_EXCL is set */\n\tif (err == -EEXIST && !(flags & NLM_F_EXCL))\n\t\terr = 0;\n\n\treturn err;\n}\n\n/**\n * i40e_ndo_bridge_setlink - Set the hardware bridge mode\n * @dev: the netdev being configured\n * @nlh: RTNL message\n * @flags: bridge flags\n * @extack: netlink extended ack\n *\n * Inserts a new hardware bridge if not already created and\n * enables the bridging mode requested (VEB or VEPA). If the\n * hardware bridge has already been inserted and the request\n * is to change the mode then that requires a PF reset to\n * allow rebuild of the components with required hardware\n * bridge mode enabled.\n *\n * Note: expects to be called while under rtnl_lock()\n **/\nstatic int i40e_ndo_bridge_setlink(struct net_device *dev,\n\t\t\t\t   struct nlmsghdr *nlh,\n\t\t\t\t   u16 flags,\n\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_veb *veb = NULL;\n\tstruct nlattr *attr, *br_spec;\n\tint i, rem;\n\n\t/* Only for PF VSI for now */\n\tif (vsi->seid != pf->vsi[pf->lan_vsi]->seid)\n\t\treturn -EOPNOTSUPP;\n\n\t/* Find the HW bridge for PF VSI */\n\tfor (i = 0; i < I40E_MAX_VEB && !veb; i++) {\n\t\tif (pf->veb[i] && pf->veb[i]->seid == vsi->uplink_seid)\n\t\t\tveb = pf->veb[i];\n\t}\n\n\tbr_spec = nlmsg_find_attr(nlh, sizeof(struct ifinfomsg), IFLA_AF_SPEC);\n\n\tnla_for_each_nested(attr, br_spec, rem) {\n\t\t__u16 mode;\n\n\t\tif (nla_type(attr) != IFLA_BRIDGE_MODE)\n\t\t\tcontinue;\n\n\t\tmode = nla_get_u16(attr);\n\t\tif ((mode != BRIDGE_MODE_VEPA) &&\n\t\t    (mode != BRIDGE_MODE_VEB))\n\t\t\treturn -EINVAL;\n\n\t\t/* Insert a new HW bridge */\n\t\tif (!veb) {\n\t\t\tveb = i40e_veb_setup(pf, 0, vsi->uplink_seid, vsi->seid,\n\t\t\t\t\t     vsi->tc_config.enabled_tc);\n\t\t\tif (veb) {\n\t\t\t\tveb->bridge_mode = mode;\n\t\t\t\ti40e_config_bridge_mode(veb);\n\t\t\t} else {\n\t\t\t\t/* No Bridge HW offload available */\n\t\t\t\treturn -ENOENT;\n\t\t\t}\n\t\t\tbreak;\n\t\t} else if (mode != veb->bridge_mode) {\n\t\t\t/* Existing HW bridge but different mode needs reset */\n\t\t\tveb->bridge_mode = mode;\n\t\t\t/* TODO: If no VFs or VMDq VSIs, disallow VEB mode */\n\t\t\tif (mode == BRIDGE_MODE_VEB)\n\t\t\t\tpf->flags |= I40E_FLAG_VEB_MODE_ENABLED;\n\t\t\telse\n\t\t\t\tpf->flags &= ~I40E_FLAG_VEB_MODE_ENABLED;\n\t\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG, true);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_ndo_bridge_getlink - Get the hardware bridge mode\n * @skb: skb buff\n * @pid: process id\n * @seq: RTNL message seq #\n * @dev: the netdev being configured\n * @filter_mask: unused\n * @nlflags: netlink flags passed in\n *\n * Return the mode in which the hardware bridge is operating in\n * i.e VEB or VEPA.\n **/\nstatic int i40e_ndo_bridge_getlink(struct sk_buff *skb, u32 pid, u32 seq,\n\t\t\t\t   struct net_device *dev,\n\t\t\t\t   u32 __always_unused filter_mask,\n\t\t\t\t   int nlflags)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_veb *veb = NULL;\n\tint i;\n\n\t/* Only for PF VSI for now */\n\tif (vsi->seid != pf->vsi[pf->lan_vsi]->seid)\n\t\treturn -EOPNOTSUPP;\n\n\t/* Find the HW bridge for the PF VSI */\n\tfor (i = 0; i < I40E_MAX_VEB && !veb; i++) {\n\t\tif (pf->veb[i] && pf->veb[i]->seid == vsi->uplink_seid)\n\t\t\tveb = pf->veb[i];\n\t}\n\n\tif (!veb)\n\t\treturn 0;\n\n\treturn ndo_dflt_bridge_getlink(skb, pid, seq, dev, veb->bridge_mode,\n\t\t\t\t       0, 0, nlflags, filter_mask, NULL);\n}\n\n/**\n * i40e_features_check - Validate encapsulated packet conforms to limits\n * @skb: skb buff\n * @dev: This physical port's netdev\n * @features: Offload features that the stack believes apply\n **/\nstatic netdev_features_t i40e_features_check(struct sk_buff *skb,\n\t\t\t\t\t     struct net_device *dev,\n\t\t\t\t\t     netdev_features_t features)\n{\n\tsize_t len;\n\n\t/* No point in doing any of this if neither checksum nor GSO are\n\t * being requested for this frame.  We can rule out both by just\n\t * checking for CHECKSUM_PARTIAL\n\t */\n\tif (skb->ip_summed != CHECKSUM_PARTIAL)\n\t\treturn features;\n\n\t/* We cannot support GSO if the MSS is going to be less than\n\t * 64 bytes.  If it is then we need to drop support for GSO.\n\t */\n\tif (skb_is_gso(skb) && (skb_shinfo(skb)->gso_size < 64))\n\t\tfeatures &= ~NETIF_F_GSO_MASK;\n\n\t/* MACLEN can support at most 63 words */\n\tlen = skb_network_header(skb) - skb->data;\n\tif (len & ~(63 * 2))\n\t\tgoto out_err;\n\n\t/* IPLEN and EIPLEN can support at most 127 dwords */\n\tlen = skb_transport_header(skb) - skb_network_header(skb);\n\tif (len & ~(127 * 4))\n\t\tgoto out_err;\n\n\tif (skb->encapsulation) {\n\t\t/* L4TUNLEN can support 127 words */\n\t\tlen = skb_inner_network_header(skb) - skb_transport_header(skb);\n\t\tif (len & ~(127 * 2))\n\t\t\tgoto out_err;\n\n\t\t/* IPLEN can support at most 127 dwords */\n\t\tlen = skb_inner_transport_header(skb) -\n\t\t      skb_inner_network_header(skb);\n\t\tif (len & ~(127 * 4))\n\t\t\tgoto out_err;\n\t}\n\n\t/* No need to validate L4LEN as TCP is the only protocol with a\n\t * a flexible value and we support all possible values supported\n\t * by TCP, which is at most 15 dwords\n\t */\n\n\treturn features;\nout_err:\n\treturn features & ~(NETIF_F_CSUM_MASK | NETIF_F_GSO_MASK);\n}\n\n/**\n * i40e_xdp_setup - add/remove an XDP program\n * @vsi: VSI to changed\n * @prog: XDP program\n **/\nstatic int i40e_xdp_setup(struct i40e_vsi *vsi,\n\t\t\t  struct bpf_prog *prog)\n{\n\tint frame_size = vsi->netdev->mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct bpf_prog *old_prog;\n\tbool need_reset;\n\tint i;\n\n\t/* Don't allow frames that span over multiple buffers */\n\tif (frame_size > vsi->rx_buf_len)\n\t\treturn -EINVAL;\n\n\tif (!i40e_enabled_xdp_vsi(vsi) && !prog)\n\t\treturn 0;\n\n\t/* When turning XDP on->off/off->on we reset and rebuild the rings. */\n\tneed_reset = (i40e_enabled_xdp_vsi(vsi) != !!prog);\n\n\tif (need_reset)\n\t\ti40e_prep_for_reset(pf, true);\n\n\told_prog = xchg(&vsi->xdp_prog, prog);\n\n\tif (need_reset)\n\t\ti40e_reset_and_rebuild(pf, true, true);\n\n\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\tWRITE_ONCE(vsi->rx_rings[i]->xdp_prog, vsi->xdp_prog);\n\n\tif (old_prog)\n\t\tbpf_prog_put(old_prog);\n\n\t/* Kick start the NAPI context if there is an AF_XDP socket open\n\t * on that queue id. This so that receiving will start.\n\t */\n\tif (need_reset && prog)\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tif (vsi->xdp_rings[i]->xsk_umem)\n\t\t\t\t(void)i40e_xsk_wakeup(vsi->netdev, i,\n\t\t\t\t\t\t      XDP_WAKEUP_RX);\n\n\treturn 0;\n}\n\n/**\n * i40e_enter_busy_conf - Enters busy config state\n * @vsi: vsi\n *\n * Returns 0 on success, <0 for failure.\n **/\nstatic int i40e_enter_busy_conf(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint timeout = 50;\n\n\twhile (test_and_set_bit(__I40E_CONFIG_BUSY, pf->state)) {\n\t\ttimeout--;\n\t\tif (!timeout)\n\t\t\treturn -EBUSY;\n\t\tusleep_range(1000, 2000);\n\t}\n\n\treturn 0;\n}\n\n/**\n * i40e_exit_busy_conf - Exits busy config state\n * @vsi: vsi\n **/\nstatic void i40e_exit_busy_conf(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tclear_bit(__I40E_CONFIG_BUSY, pf->state);\n}\n\n/**\n * i40e_queue_pair_reset_stats - Resets all statistics for a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n **/\nstatic void i40e_queue_pair_reset_stats(struct i40e_vsi *vsi, int queue_pair)\n{\n\tmemset(&vsi->rx_rings[queue_pair]->rx_stats, 0,\n\t       sizeof(vsi->rx_rings[queue_pair]->rx_stats));\n\tmemset(&vsi->tx_rings[queue_pair]->stats, 0,\n\t       sizeof(vsi->tx_rings[queue_pair]->stats));\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tmemset(&vsi->xdp_rings[queue_pair]->stats, 0,\n\t\t       sizeof(vsi->xdp_rings[queue_pair]->stats));\n\t}\n}\n\n/**\n * i40e_queue_pair_clean_rings - Cleans all the rings of a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n **/\nstatic void i40e_queue_pair_clean_rings(struct i40e_vsi *vsi, int queue_pair)\n{\n\ti40e_clean_tx_ring(vsi->tx_rings[queue_pair]);\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t/* Make sure that in-progress ndo_xdp_xmit calls are\n\t\t * completed.\n\t\t */\n\t\tsynchronize_rcu();\n\t\ti40e_clean_tx_ring(vsi->xdp_rings[queue_pair]);\n\t}\n\ti40e_clean_rx_ring(vsi->rx_rings[queue_pair]);\n}\n\n/**\n * i40e_queue_pair_toggle_napi - Enables/disables NAPI for a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n * @enable: true for enable, false for disable\n **/\nstatic void i40e_queue_pair_toggle_napi(struct i40e_vsi *vsi, int queue_pair,\n\t\t\t\t\tbool enable)\n{\n\tstruct i40e_ring *rxr = vsi->rx_rings[queue_pair];\n\tstruct i40e_q_vector *q_vector = rxr->q_vector;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\t/* All rings in a qp belong to the same qvector. */\n\tif (q_vector->rx.ring || q_vector->tx.ring) {\n\t\tif (enable)\n\t\t\tnapi_enable(&q_vector->napi);\n\t\telse\n\t\t\tnapi_disable(&q_vector->napi);\n\t}\n}\n\n/**\n * i40e_queue_pair_toggle_rings - Enables/disables all rings for a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n * @enable: true for enable, false for disable\n *\n * Returns 0 on success, <0 on failure.\n **/\nstatic int i40e_queue_pair_toggle_rings(struct i40e_vsi *vsi, int queue_pair,\n\t\t\t\t\tbool enable)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint pf_q, ret = 0;\n\n\tpf_q = vsi->base_queue + queue_pair;\n\tret = i40e_control_wait_tx_q(vsi->seid, pf, pf_q,\n\t\t\t\t     false /*is xdp*/, enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d Tx ring %d %sable timeout\\n\",\n\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t\treturn ret;\n\t}\n\n\ti40e_control_rx_q(pf, pf_q, enable);\n\tret = i40e_pf_rxq_wait(pf, pf_q, enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d Rx ring %d %sable timeout\\n\",\n\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t\treturn ret;\n\t}\n\n\t/* Due to HW errata, on Rx disable only, the register can\n\t * indicate done before it really is. Needs 50ms to be sure\n\t */\n\tif (!enable)\n\t\tmdelay(50);\n\n\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\treturn ret;\n\n\tret = i40e_control_wait_tx_q(vsi->seid, pf,\n\t\t\t\t     pf_q + vsi->alloc_queue_pairs,\n\t\t\t\t     true /*is xdp*/, enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d XDP Tx ring %d %sable timeout\\n\",\n\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t}\n\n\treturn ret;\n}\n\n/**\n * i40e_queue_pair_enable_irq - Enables interrupts for a queue pair\n * @vsi: vsi\n * @queue_pair: queue_pair\n **/\nstatic void i40e_queue_pair_enable_irq(struct i40e_vsi *vsi, int queue_pair)\n{\n\tstruct i40e_ring *rxr = vsi->rx_rings[queue_pair];\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t/* All rings in a qp belong to the same qvector. */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\ti40e_irq_dynamic_enable(vsi, rxr->q_vector->v_idx);\n\telse\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\n\ti40e_flush(hw);\n}\n\n/**\n * i40e_queue_pair_disable_irq - Disables interrupts for a queue pair\n * @vsi: vsi\n * @queue_pair: queue_pair\n **/\nstatic void i40e_queue_pair_disable_irq(struct i40e_vsi *vsi, int queue_pair)\n{\n\tstruct i40e_ring *rxr = vsi->rx_rings[queue_pair];\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t/* For simplicity, instead of removing the qp interrupt causes\n\t * from the interrupt linked list, we simply disable the interrupt, and\n\t * leave the list intact.\n\t *\n\t * All rings in a qp belong to the same qvector.\n\t */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tu32 intpf = vsi->base_vector + rxr->q_vector->v_idx;\n\n\t\twr32(hw, I40E_PFINT_DYN_CTLN(intpf - 1), 0);\n\t\ti40e_flush(hw);\n\t\tsynchronize_irq(pf->msix_entries[intpf].vector);\n\t} else {\n\t\t/* Legacy and MSI mode - this stops all interrupt handling */\n\t\twr32(hw, I40E_PFINT_ICR0_ENA, 0);\n\t\twr32(hw, I40E_PFINT_DYN_CTL0, 0);\n\t\ti40e_flush(hw);\n\t\tsynchronize_irq(pf->pdev->irq);\n\t}\n}\n\n/**\n * i40e_queue_pair_disable - Disables a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n *\n * Returns 0 on success, <0 on failure.\n **/\nint i40e_queue_pair_disable(struct i40e_vsi *vsi, int queue_pair)\n{\n\tint err;\n\n\terr = i40e_enter_busy_conf(vsi);\n\tif (err)\n\t\treturn err;\n\n\ti40e_queue_pair_disable_irq(vsi, queue_pair);\n\terr = i40e_queue_pair_toggle_rings(vsi, queue_pair, false /* off */);\n\ti40e_queue_pair_toggle_napi(vsi, queue_pair, false /* off */);\n\ti40e_queue_pair_clean_rings(vsi, queue_pair);\n\ti40e_queue_pair_reset_stats(vsi, queue_pair);\n\n\treturn err;\n}\n\n/**\n * i40e_queue_pair_enable - Enables a queue pair\n * @vsi: vsi\n * @queue_pair: queue pair\n *\n * Returns 0 on success, <0 on failure.\n **/\nint i40e_queue_pair_enable(struct i40e_vsi *vsi, int queue_pair)\n{\n\tint err;\n\n\terr = i40e_configure_tx_ring(vsi->tx_rings[queue_pair]);\n\tif (err)\n\t\treturn err;\n\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\terr = i40e_configure_tx_ring(vsi->xdp_rings[queue_pair]);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = i40e_configure_rx_ring(vsi->rx_rings[queue_pair]);\n\tif (err)\n\t\treturn err;\n\n\terr = i40e_queue_pair_toggle_rings(vsi, queue_pair, true /* on */);\n\ti40e_queue_pair_toggle_napi(vsi, queue_pair, true /* on */);\n\ti40e_queue_pair_enable_irq(vsi, queue_pair);\n\n\ti40e_exit_busy_conf(vsi);\n\n\treturn err;\n}\n\n/**\n * i40e_xdp - implements ndo_bpf for i40e\n * @dev: netdevice\n * @xdp: XDP command\n **/\nstatic int i40e_xdp(struct net_device *dev,\n\t\t    struct netdev_bpf *xdp)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tif (vsi->type != I40E_VSI_MAIN)\n\t\treturn -EINVAL;\n\n\tswitch (xdp->command) {\n\tcase XDP_SETUP_PROG:\n\t\treturn i40e_xdp_setup(vsi, xdp->prog);\n\tcase XDP_QUERY_PROG:\n\t\txdp->prog_id = vsi->xdp_prog ? vsi->xdp_prog->aux->id : 0;\n\t\treturn 0;\n\tcase XDP_SETUP_XSK_UMEM:\n\t\treturn i40e_xsk_umem_setup(vsi, xdp->xsk.umem,\n\t\t\t\t\t   xdp->xsk.queue_id);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic const struct net_device_ops i40e_netdev_ops = {\n\t.ndo_open\t\t= i40e_open,\n\t.ndo_stop\t\t= i40e_close,\n\t.ndo_start_xmit\t\t= i40e_lan_xmit_frame,\n\t.ndo_get_stats64\t= i40e_get_netdev_stats_struct,\n\t.ndo_set_rx_mode\t= i40e_set_rx_mode,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= i40e_set_mac,\n\t.ndo_change_mtu\t\t= i40e_change_mtu,\n\t.ndo_do_ioctl\t\t= i40e_ioctl,\n\t.ndo_tx_timeout\t\t= i40e_tx_timeout,\n\t.ndo_vlan_rx_add_vid\t= i40e_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= i40e_vlan_rx_kill_vid,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= i40e_netpoll,\n#endif\n\t.ndo_setup_tc\t\t= __i40e_setup_tc,\n\t.ndo_set_features\t= i40e_set_features,\n\t.ndo_set_vf_mac\t\t= i40e_ndo_set_vf_mac,\n\t.ndo_set_vf_vlan\t= i40e_ndo_set_vf_port_vlan,\n\t.ndo_set_vf_rate\t= i40e_ndo_set_vf_bw,\n\t.ndo_get_vf_config\t= i40e_ndo_get_vf_config,\n\t.ndo_set_vf_link_state\t= i40e_ndo_set_vf_link_state,\n\t.ndo_set_vf_spoofchk\t= i40e_ndo_set_vf_spoofchk,\n\t.ndo_set_vf_trust\t= i40e_ndo_set_vf_trust,\n\t.ndo_udp_tunnel_add\t= i40e_udp_tunnel_add,\n\t.ndo_udp_tunnel_del\t= i40e_udp_tunnel_del,\n\t.ndo_get_phys_port_id\t= i40e_get_phys_port_id,\n\t.ndo_fdb_add\t\t= i40e_ndo_fdb_add,\n\t.ndo_features_check\t= i40e_features_check,\n\t.ndo_bridge_getlink\t= i40e_ndo_bridge_getlink,\n\t.ndo_bridge_setlink\t= i40e_ndo_bridge_setlink,\n\t.ndo_bpf\t\t= i40e_xdp,\n\t.ndo_xdp_xmit\t\t= i40e_xdp_xmit,\n\t.ndo_xsk_wakeup\t        = i40e_xsk_wakeup,\n\t.ndo_dfwd_add_station\t= i40e_fwd_add,\n\t.ndo_dfwd_del_station\t= i40e_fwd_del,\n};\n\n/**\n * i40e_config_netdev - Setup the netdev flags\n * @vsi: the VSI being configured\n *\n * Returns 0 on success, negative value on failure\n **/\nstatic int i40e_config_netdev(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_netdev_priv *np;\n\tstruct net_device *netdev;\n\tu8 broadcast[ETH_ALEN];\n\tu8 mac_addr[ETH_ALEN];\n\tint etherdev_size;\n\tnetdev_features_t hw_enc_features;\n\tnetdev_features_t hw_features;\n\n\tetherdev_size = sizeof(struct i40e_netdev_priv);\n\tnetdev = alloc_etherdev_mq(etherdev_size, vsi->alloc_queue_pairs);\n\tif (!netdev)\n\t\treturn -ENOMEM;\n\n\tvsi->netdev = netdev;\n\tnp = netdev_priv(netdev);\n\tnp->vsi = vsi;\n\n\thw_enc_features = NETIF_F_SG\t\t\t|\n\t\t\t  NETIF_F_IP_CSUM\t\t|\n\t\t\t  NETIF_F_IPV6_CSUM\t\t|\n\t\t\t  NETIF_F_HIGHDMA\t\t|\n\t\t\t  NETIF_F_SOFT_FEATURES\t\t|\n\t\t\t  NETIF_F_TSO\t\t\t|\n\t\t\t  NETIF_F_TSO_ECN\t\t|\n\t\t\t  NETIF_F_TSO6\t\t\t|\n\t\t\t  NETIF_F_GSO_GRE\t\t|\n\t\t\t  NETIF_F_GSO_GRE_CSUM\t\t|\n\t\t\t  NETIF_F_GSO_PARTIAL\t\t|\n\t\t\t  NETIF_F_GSO_IPXIP4\t\t|\n\t\t\t  NETIF_F_GSO_IPXIP6\t\t|\n\t\t\t  NETIF_F_GSO_UDP_TUNNEL\t|\n\t\t\t  NETIF_F_GSO_UDP_TUNNEL_CSUM\t|\n\t\t\t  NETIF_F_SCTP_CRC\t\t|\n\t\t\t  NETIF_F_RXHASH\t\t|\n\t\t\t  NETIF_F_RXCSUM\t\t|\n\t\t\t  0;\n\n\tif (!(pf->hw_features & I40E_HW_OUTER_UDP_CSUM_CAPABLE))\n\t\tnetdev->gso_partial_features |= NETIF_F_GSO_UDP_TUNNEL_CSUM;\n\n\tnetdev->gso_partial_features |= NETIF_F_GSO_GRE_CSUM;\n\n\tnetdev->hw_enc_features |= hw_enc_features;\n\n\t/* record features VLANs can make use of */\n\tnetdev->vlan_features |= hw_enc_features | NETIF_F_TSO_MANGLEID;\n\n\t/* enable macvlan offloads */\n\tnetdev->hw_features |= NETIF_F_HW_L2FW_DOFFLOAD;\n\n\thw_features = hw_enc_features\t\t|\n\t\t      NETIF_F_HW_VLAN_CTAG_TX\t|\n\t\t      NETIF_F_HW_VLAN_CTAG_RX;\n\n\tif (!(pf->flags & I40E_FLAG_MFP_ENABLED))\n\t\thw_features |= NETIF_F_NTUPLE | NETIF_F_HW_TC;\n\n\tnetdev->hw_features |= hw_features;\n\n\tnetdev->features |= hw_features | NETIF_F_HW_VLAN_CTAG_FILTER;\n\tnetdev->hw_enc_features |= NETIF_F_TSO_MANGLEID;\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\tSET_NETDEV_DEV(netdev, &pf->pdev->dev);\n\t\tether_addr_copy(mac_addr, hw->mac.perm_addr);\n\t\t/* The following steps are necessary for two reasons. First,\n\t\t * some older NVM configurations load a default MAC-VLAN\n\t\t * filter that will accept any tagged packet, and we want to\n\t\t * replace this with a normal filter. Additionally, it is\n\t\t * possible our MAC address was provided by the platform using\n\t\t * Open Firmware or similar.\n\t\t *\n\t\t * Thus, we need to remove the default filter and install one\n\t\t * specific to the MAC address.\n\t\t */\n\t\ti40e_rm_default_mac_filter(vsi, mac_addr);\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\ti40e_add_mac_filter(vsi, mac_addr);\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t} else {\n\t\t/* Relate the VSI_VMDQ name to the VSI_MAIN name. Note that we\n\t\t * are still limited by IFNAMSIZ, but we're adding 'v%d\\0' to\n\t\t * the end, which is 4 bytes long, so force truncation of the\n\t\t * original name by IFNAMSIZ - 4\n\t\t */\n\t\tsnprintf(netdev->name, IFNAMSIZ, \"%.*sv%%d\",\n\t\t\t IFNAMSIZ - 4,\n\t\t\t pf->vsi[pf->lan_vsi]->netdev->name);\n\t\teth_random_addr(mac_addr);\n\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\ti40e_add_mac_filter(vsi, mac_addr);\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t}\n\n\t/* Add the broadcast filter so that we initially will receive\n\t * broadcast packets. Note that when a new VLAN is first added the\n\t * driver will convert all filters marked I40E_VLAN_ANY into VLAN\n\t * specific filters as part of transitioning into \"vlan\" operation.\n\t * When more VLANs are added, the driver will copy each existing MAC\n\t * filter and add it for the new VLAN.\n\t *\n\t * Broadcast filters are handled specially by\n\t * i40e_sync_filters_subtask, as the driver must to set the broadcast\n\t * promiscuous bit instead of adding this directly as a MAC/VLAN\n\t * filter. The subtask will update the correct broadcast promiscuous\n\t * bits as VLANs become active or inactive.\n\t */\n\teth_broadcast_addr(broadcast);\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\ti40e_add_mac_filter(vsi, broadcast);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\tether_addr_copy(netdev->dev_addr, mac_addr);\n\tether_addr_copy(netdev->perm_addr, mac_addr);\n\n\t/* i40iw_net_event() reads 16 bytes from neigh->primary_key */\n\tnetdev->neigh_priv_len = sizeof(u32) * 4;\n\n\tnetdev->priv_flags |= IFF_UNICAST_FLT;\n\tnetdev->priv_flags |= IFF_SUPP_NOFCS;\n\t/* Setup netdev TC information */\n\ti40e_vsi_config_netdev_tc(vsi, vsi->tc_config.enabled_tc);\n\n\tnetdev->netdev_ops = &i40e_netdev_ops;\n\tnetdev->watchdog_timeo = 5 * HZ;\n\ti40e_set_ethtool_ops(netdev);\n\n\t/* MTU range: 68 - 9706 */\n\tnetdev->min_mtu = ETH_MIN_MTU;\n\tnetdev->max_mtu = I40E_MAX_RXBUFFER - I40E_PACKET_HDR_PAD;\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_delete - Delete a VSI from the switch\n * @vsi: the VSI being removed\n *\n * Returns 0 on success, negative value on failure\n **/\nstatic void i40e_vsi_delete(struct i40e_vsi *vsi)\n{\n\t/* remove default VSI is not allowed */\n\tif (vsi == vsi->back->vsi[vsi->back->lan_vsi])\n\t\treturn;\n\n\ti40e_aq_delete_element(&vsi->back->hw, vsi->seid, NULL);\n}\n\n/**\n * i40e_is_vsi_uplink_mode_veb - Check if the VSI's uplink bridge mode is VEB\n * @vsi: the VSI being queried\n *\n * Returns 1 if HW bridge mode is VEB and return 0 in case of VEPA mode\n **/\nint i40e_is_vsi_uplink_mode_veb(struct i40e_vsi *vsi)\n{\n\tstruct i40e_veb *veb;\n\tstruct i40e_pf *pf = vsi->back;\n\n\t/* Uplink is not a bridge so default to VEB */\n\tif (vsi->veb_idx >= I40E_MAX_VEB)\n\t\treturn 1;\n\n\tveb = pf->veb[vsi->veb_idx];\n\tif (!veb) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"There is no veb associated with the bridge\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\t/* Uplink is a bridge in VEPA mode */\n\tif (veb->bridge_mode & BRIDGE_MODE_VEPA) {\n\t\treturn 0;\n\t} else {\n\t\t/* Uplink is a bridge in VEB mode */\n\t\treturn 1;\n\t}\n\n\t/* VEPA is now default bridge, so return 0 */\n\treturn 0;\n}\n\n/**\n * i40e_add_vsi - Add a VSI to the switch\n * @vsi: the VSI being configured\n *\n * This initializes a VSI context depending on the VSI type to be added and\n * passes it down to the add_vsi aq command.\n **/\nstatic int i40e_add_vsi(struct i40e_vsi *vsi)\n{\n\tint ret = -ENODEV;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\tu8 enabled_tc = 0x1; /* TC0 enabled */\n\tint f_count = 0;\n\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tswitch (vsi->type) {\n\tcase I40E_VSI_MAIN:\n\t\t/* The PF's main VSI is already setup as part of the\n\t\t * device initialization, so we'll not bother with\n\t\t * the add_vsi call, but we will retrieve the current\n\t\t * VSI context.\n\t\t */\n\t\tctxt.seid = pf->main_vsi_seid;\n\t\tctxt.pf_num = pf->hw.pf_id;\n\t\tctxt.vf_num = 0;\n\t\tret = i40e_aq_get_vsi_params(&pf->hw, &ctxt, NULL);\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"couldn't get PF vsi config, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tvsi->info = ctxt.info;\n\t\tvsi->info.valid_sections = 0;\n\n\t\tvsi->seid = ctxt.seid;\n\t\tvsi->id = ctxt.vsi_number;\n\n\t\tenabled_tc = i40e_pf_get_tc_map(pf);\n\n\t\t/* Source pruning is enabled by default, so the flag is\n\t\t * negative logic - if it's set, we need to fiddle with\n\t\t * the VSI to disable source pruning.\n\t\t */\n\t\tif (pf->flags & I40E_FLAG_SOURCE_PRUNING_DISABLED) {\n\t\t\tmemset(&ctxt, 0, sizeof(ctxt));\n\t\t\tctxt.seid = pf->main_vsi_seid;\n\t\t\tctxt.pf_num = pf->hw.pf_id;\n\t\t\tctxt.vf_num = 0;\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\t     cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t\t   cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_LOCAL_LB);\n\t\t\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"update vsi failed, err %s aq_err %s\\n\",\n\t\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\t\tret = -ENOENT;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t\t/* MFP mode setup queue map and update VSI */\n\t\tif ((pf->flags & I40E_FLAG_MFP_ENABLED) &&\n\t\t    !(pf->hw.func_caps.iscsi)) { /* NIC type PF */\n\t\t\tmemset(&ctxt, 0, sizeof(ctxt));\n\t\t\tctxt.seid = pf->main_vsi_seid;\n\t\t\tctxt.pf_num = pf->hw.pf_id;\n\t\t\tctxt.vf_num = 0;\n\t\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, false);\n\t\t\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"update vsi failed, err %s aq_err %s\\n\",\n\t\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t    pf->hw.aq.asq_last_status));\n\t\t\t\tret = -ENOENT;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\t/* update the local VSI info queue map */\n\t\t\ti40e_vsi_update_queue_map(vsi, &ctxt);\n\t\t\tvsi->info.valid_sections = 0;\n\t\t} else {\n\t\t\t/* Default/Main VSI is only enabled for TC0\n\t\t\t * reconfigure it to enable all TCs that are\n\t\t\t * available on the port in SFP mode.\n\t\t\t * For MFP case the iSCSI PF would use this\n\t\t\t * flow to enable LAN+iSCSI TC.\n\t\t\t */\n\t\t\tret = i40e_vsi_config_tc(vsi, enabled_tc);\n\t\t\tif (ret) {\n\t\t\t\t/* Single TC condition is not fatal,\n\t\t\t\t * message and continue\n\t\t\t\t */\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"failed to configure TCs for main VSI tc_map 0x%08x, err %s aq_err %s\\n\",\n\t\t\t\t\t enabled_tc,\n\t\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t    pf->hw.aq.asq_last_status));\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase I40E_VSI_FDIR:\n\t\tctxt.pf_num = hw->pf_id;\n\t\tctxt.vf_num = 0;\n\t\tctxt.uplink_seid = vsi->uplink_seid;\n\t\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\t\tif ((pf->flags & I40E_FLAG_VEB_MODE_ENABLED) &&\n\t\t    (i40e_is_vsi_uplink_mode_veb(vsi))) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t     cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t   cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t\t}\n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, true);\n\t\tbreak;\n\n\tcase I40E_VSI_VMDQ2:\n\t\tctxt.pf_num = hw->pf_id;\n\t\tctxt.vf_num = 0;\n\t\tctxt.uplink_seid = vsi->uplink_seid;\n\t\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_VMDQ2;\n\n\t\t/* This VSI is connected to VEB so the switch_id\n\t\t * should be set to zero by default.\n\t\t */\n\t\tif (i40e_is_vsi_uplink_mode_veb(vsi)) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t\t}\n\n\t\t/* Setup the VSI tx/rx queue map for TC0 only for now */\n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, true);\n\t\tbreak;\n\n\tcase I40E_VSI_SRIOV:\n\t\tctxt.pf_num = hw->pf_id;\n\t\tctxt.vf_num = vsi->vf_id + hw->func_caps.vf_base_id;\n\t\tctxt.uplink_seid = vsi->uplink_seid;\n\t\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_VF;\n\n\t\t/* This VSI is connected to VEB so the switch_id\n\t\t * should be set to zero by default.\n\t\t */\n\t\tif (i40e_is_vsi_uplink_mode_veb(vsi)) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t\t}\n\n\t\tif (vsi->back->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_QUEUE_OPT_VALID);\n\t\t\tctxt.info.queueing_opt_flags |=\n\t\t\t\t(I40E_AQ_VSI_QUE_OPT_TCP_ENA |\n\t\t\t\t I40E_AQ_VSI_QUE_OPT_RSS_LUT_VSI);\n\t\t}\n\n\t\tctxt.info.valid_sections |= cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\t\tctxt.info.port_vlan_flags |= I40E_AQ_VSI_PVLAN_MODE_ALL;\n\t\tif (pf->vf[vsi->vf_id].spoofchk) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_SECURITY_VALID);\n\t\t\tctxt.info.sec_flags |=\n\t\t\t\t(I40E_AQ_VSI_SEC_FLAG_ENABLE_VLAN_CHK |\n\t\t\t\t I40E_AQ_VSI_SEC_FLAG_ENABLE_MAC_CHK);\n\t\t}\n\t\t/* Setup the VSI tx/rx queue map for TC0 only for now */\n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, true);\n\t\tbreak;\n\n\tcase I40E_VSI_IWARP:\n\t\t/* send down message to iWARP */\n\t\tbreak;\n\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n\n\tif (vsi->type != I40E_VSI_MAIN) {\n\t\tret = i40e_aq_add_vsi(hw, &ctxt, NULL);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"add vsi failed, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\tret = -ENOENT;\n\t\t\tgoto err;\n\t\t}\n\t\tvsi->info = ctxt.info;\n\t\tvsi->info.valid_sections = 0;\n\t\tvsi->seid = ctxt.seid;\n\t\tvsi->id = ctxt.vsi_number;\n\t}\n\n\tvsi->active_filters = 0;\n\tclear_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t/* If macvlan filters already exist, force them to get loaded */\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tf->state = I40E_FILTER_NEW;\n\t\tf_count++;\n\t}\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\tif (f_count) {\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, pf->state);\n\t}\n\n\t/* Update VSI BW information */\n\tret = i40e_vsi_get_bw_info(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get vsi bw info, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\t/* VSI is already added so not tearing that up */\n\t\tret = 0;\n\t}\n\nerr:\n\treturn ret;\n}\n\n/**\n * i40e_vsi_release - Delete a VSI and free its resources\n * @vsi: the VSI being removed\n *\n * Returns 0 on success or < 0 on error\n **/\nint i40e_vsi_release(struct i40e_vsi *vsi)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tstruct i40e_veb *veb = NULL;\n\tstruct i40e_pf *pf;\n\tu16 uplink_seid;\n\tint i, n, bkt;\n\n\tpf = vsi->back;\n\n\t/* release of a VEB-owner or last VSI is not allowed */\n\tif (vsi->flags & I40E_VSI_FLAG_VEB_OWNER) {\n\t\tdev_info(&pf->pdev->dev, \"VSI %d has existing VEB %d\\n\",\n\t\t\t vsi->seid, vsi->uplink_seid);\n\t\treturn -ENODEV;\n\t}\n\tif (vsi == pf->vsi[pf->lan_vsi] &&\n\t    !test_bit(__I40E_DOWN, pf->state)) {\n\t\tdev_info(&pf->pdev->dev, \"Can't remove PF VSI\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tuplink_seid = vsi->uplink_seid;\n\tif (vsi->type != I40E_VSI_SRIOV) {\n\t\tif (vsi->netdev_registered) {\n\t\t\tvsi->netdev_registered = false;\n\t\t\tif (vsi->netdev) {\n\t\t\t\t/* results in a call to i40e_close() */\n\t\t\t\tunregister_netdev(vsi->netdev);\n\t\t\t}\n\t\t} else {\n\t\t\ti40e_vsi_close(vsi);\n\t\t}\n\t\ti40e_vsi_disable_irq(vsi);\n\t}\n\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\n\t/* clear the sync flag on all filters */\n\tif (vsi->netdev) {\n\t\t__dev_uc_unsync(vsi->netdev, NULL);\n\t\t__dev_mc_unsync(vsi->netdev, NULL);\n\t}\n\n\t/* make sure any remaining filters are marked for deletion */\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist)\n\t\t__i40e_del_filter(vsi, f);\n\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\ti40e_sync_vsi_filters(vsi);\n\n\ti40e_vsi_delete(vsi);\n\ti40e_vsi_free_q_vectors(vsi);\n\tif (vsi->netdev) {\n\t\tfree_netdev(vsi->netdev);\n\t\tvsi->netdev = NULL;\n\t}\n\ti40e_vsi_clear_rings(vsi);\n\ti40e_vsi_clear(vsi);\n\n\t/* If this was the last thing on the VEB, except for the\n\t * controlling VSI, remove the VEB, which puts the controlling\n\t * VSI onto the next level down in the switch.\n\t *\n\t * Well, okay, there's one more exception here: don't remove\n\t * the orphan VEBs yet.  We'll wait for an explicit remove request\n\t * from up the network stack.\n\t */\n\tfor (n = 0, i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i] &&\n\t\t    pf->vsi[i]->uplink_seid == uplink_seid &&\n\t\t    (pf->vsi[i]->flags & I40E_VSI_FLAG_VEB_OWNER) == 0) {\n\t\t\tn++;      /* count the VSIs */\n\t\t}\n\t}\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (!pf->veb[i])\n\t\t\tcontinue;\n\t\tif (pf->veb[i]->uplink_seid == uplink_seid)\n\t\t\tn++;     /* count the VEBs */\n\t\tif (pf->veb[i]->seid == uplink_seid)\n\t\t\tveb = pf->veb[i];\n\t}\n\tif (n == 0 && veb && veb->uplink_seid != 0)\n\t\ti40e_veb_release(veb);\n\n\treturn 0;\n}\n\n/**\n * i40e_vsi_setup_vectors - Set up the q_vectors for the given VSI\n * @vsi: ptr to the VSI\n *\n * This should only be called after i40e_vsi_mem_alloc() which allocates the\n * corresponding SW VSI structure and initializes num_queue_pairs for the\n * newly allocated VSI.\n *\n * Returns 0 on success or negative on failure\n **/\nstatic int i40e_vsi_setup_vectors(struct i40e_vsi *vsi)\n{\n\tint ret = -ENOENT;\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (vsi->q_vectors[0]) {\n\t\tdev_info(&pf->pdev->dev, \"VSI %d has existing q_vectors\\n\",\n\t\t\t vsi->seid);\n\t\treturn -EEXIST;\n\t}\n\n\tif (vsi->base_vector) {\n\t\tdev_info(&pf->pdev->dev, \"VSI %d has non-zero base vector %d\\n\",\n\t\t\t vsi->seid, vsi->base_vector);\n\t\treturn -EEXIST;\n\t}\n\n\tret = i40e_vsi_alloc_q_vectors(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to allocate %d q_vector for VSI %d, ret=%d\\n\",\n\t\t\t vsi->num_q_vectors, vsi->seid, ret);\n\t\tvsi->num_q_vectors = 0;\n\t\tgoto vector_setup_out;\n\t}\n\n\t/* In Legacy mode, we do not have to get any other vector since we\n\t * piggyback on the misc/ICR0 for queue interrupts.\n\t*/\n\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\treturn ret;\n\tif (vsi->num_q_vectors)\n\t\tvsi->base_vector = i40e_get_lump(pf, pf->irq_pile,\n\t\t\t\t\t\t vsi->num_q_vectors, vsi->idx);\n\tif (vsi->base_vector < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to get tracking for %d vectors for VSI %d, err=%d\\n\",\n\t\t\t vsi->num_q_vectors, vsi->seid, vsi->base_vector);\n\t\ti40e_vsi_free_q_vectors(vsi);\n\t\tret = -ENOENT;\n\t\tgoto vector_setup_out;\n\t}\n\nvector_setup_out:\n\treturn ret;\n}\n\n/**\n * i40e_vsi_reinit_setup - return and reallocate resources for a VSI\n * @vsi: pointer to the vsi.\n *\n * This re-allocates a vsi's queue resources.\n *\n * Returns pointer to the successfully allocated and configured VSI sw struct\n * on success, otherwise returns NULL on failure.\n **/\nstatic struct i40e_vsi *i40e_vsi_reinit_setup(struct i40e_vsi *vsi)\n{\n\tu16 alloc_queue_pairs;\n\tstruct i40e_pf *pf;\n\tu8 enabled_tc;\n\tint ret;\n\n\tif (!vsi)\n\t\treturn NULL;\n\n\tpf = vsi->back;\n\n\ti40e_put_lump(pf->qp_pile, vsi->base_queue, vsi->idx);\n\ti40e_vsi_clear_rings(vsi);\n\n\ti40e_vsi_free_arrays(vsi, false);\n\ti40e_set_num_rings_in_vsi(vsi);\n\tret = i40e_vsi_alloc_arrays(vsi, false);\n\tif (ret)\n\t\tgoto err_vsi;\n\n\talloc_queue_pairs = vsi->alloc_queue_pairs *\n\t\t\t    (i40e_enabled_xdp_vsi(vsi) ? 2 : 1);\n\n\tret = i40e_get_lump(pf, pf->qp_pile, alloc_queue_pairs, vsi->idx);\n\tif (ret < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to get tracking for %d queues for VSI %d err %d\\n\",\n\t\t\t alloc_queue_pairs, vsi->seid, ret);\n\t\tgoto err_vsi;\n\t}\n\tvsi->base_queue = ret;\n\n\t/* Update the FW view of the VSI. Force a reset of TC and queue\n\t * layout configurations.\n\t */\n\tenabled_tc = pf->vsi[pf->lan_vsi]->tc_config.enabled_tc;\n\tpf->vsi[pf->lan_vsi]->tc_config.enabled_tc = 0;\n\tpf->vsi[pf->lan_vsi]->seid = pf->main_vsi_seid;\n\ti40e_vsi_config_tc(pf->vsi[pf->lan_vsi], enabled_tc);\n\tif (vsi->type == I40E_VSI_MAIN)\n\t\ti40e_rm_default_mac_filter(vsi, pf->hw.mac.perm_addr);\n\n\t/* assign it some queues */\n\tret = i40e_alloc_rings(vsi);\n\tif (ret)\n\t\tgoto err_rings;\n\n\t/* map all of the rings to the q_vectors */\n\ti40e_vsi_map_rings_to_vectors(vsi);\n\treturn vsi;\n\nerr_rings:\n\ti40e_vsi_free_q_vectors(vsi);\n\tif (vsi->netdev_registered) {\n\t\tvsi->netdev_registered = false;\n\t\tunregister_netdev(vsi->netdev);\n\t\tfree_netdev(vsi->netdev);\n\t\tvsi->netdev = NULL;\n\t}\n\ti40e_aq_delete_element(&pf->hw, vsi->seid, NULL);\nerr_vsi:\n\ti40e_vsi_clear(vsi);\n\treturn NULL;\n}\n\n/**\n * i40e_vsi_setup - Set up a VSI by a given type\n * @pf: board private structure\n * @type: VSI type\n * @uplink_seid: the switch element to link to\n * @param1: usage depends upon VSI type. For VF types, indicates VF id\n *\n * This allocates the sw VSI structure and its queue resources, then add a VSI\n * to the identified VEB.\n *\n * Returns pointer to the successfully allocated and configure VSI sw struct on\n * success, otherwise returns NULL on failure.\n **/\nstruct i40e_vsi *i40e_vsi_setup(struct i40e_pf *pf, u8 type,\n\t\t\t\tu16 uplink_seid, u32 param1)\n{\n\tstruct i40e_vsi *vsi = NULL;\n\tstruct i40e_veb *veb = NULL;\n\tu16 alloc_queue_pairs;\n\tint ret, i;\n\tint v_idx;\n\n\t/* The requested uplink_seid must be either\n\t *     - the PF's port seid\n\t *              no VEB is needed because this is the PF\n\t *              or this is a Flow Director special case VSI\n\t *     - seid of an existing VEB\n\t *     - seid of a VSI that owns an existing VEB\n\t *     - seid of a VSI that doesn't own a VEB\n\t *              a new VEB is created and the VSI becomes the owner\n\t *     - seid of the PF VSI, which is what creates the first VEB\n\t *              this is a special case of the previous\n\t *\n\t * Find which uplink_seid we were given and create a new VEB if needed\n\t */\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (pf->veb[i] && pf->veb[i]->seid == uplink_seid) {\n\t\t\tveb = pf->veb[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!veb && uplink_seid != pf->mac_seid) {\n\n\t\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\t\tif (pf->vsi[i] && pf->vsi[i]->seid == uplink_seid) {\n\t\t\t\tvsi = pf->vsi[i];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!vsi) {\n\t\t\tdev_info(&pf->pdev->dev, \"no such uplink_seid %d\\n\",\n\t\t\t\t uplink_seid);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (vsi->uplink_seid == pf->mac_seid)\n\t\t\tveb = i40e_veb_setup(pf, 0, pf->mac_seid, vsi->seid,\n\t\t\t\t\t     vsi->tc_config.enabled_tc);\n\t\telse if ((vsi->flags & I40E_VSI_FLAG_VEB_OWNER) == 0)\n\t\t\tveb = i40e_veb_setup(pf, 0, vsi->uplink_seid, vsi->seid,\n\t\t\t\t\t     vsi->tc_config.enabled_tc);\n\t\tif (veb) {\n\t\t\tif (vsi->seid != pf->vsi[pf->lan_vsi]->seid) {\n\t\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t\t \"New VSI creation error, uplink seid of LAN VSI expected.\\n\");\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t\t/* We come up by default in VEPA mode if SRIOV is not\n\t\t\t * already enabled, in which case we can't force VEPA\n\t\t\t * mode.\n\t\t\t */\n\t\t\tif (!(pf->flags & I40E_FLAG_VEB_MODE_ENABLED)) {\n\t\t\t\tveb->bridge_mode = BRIDGE_MODE_VEPA;\n\t\t\t\tpf->flags &= ~I40E_FLAG_VEB_MODE_ENABLED;\n\t\t\t}\n\t\t\ti40e_config_bridge_mode(veb);\n\t\t}\n\t\tfor (i = 0; i < I40E_MAX_VEB && !veb; i++) {\n\t\t\tif (pf->veb[i] && pf->veb[i]->seid == vsi->uplink_seid)\n\t\t\t\tveb = pf->veb[i];\n\t\t}\n\t\tif (!veb) {\n\t\t\tdev_info(&pf->pdev->dev, \"couldn't add VEB\\n\");\n\t\t\treturn NULL;\n\t\t}\n\n\t\tvsi->flags |= I40E_VSI_FLAG_VEB_OWNER;\n\t\tuplink_seid = veb->seid;\n\t}\n\n\t/* get vsi sw struct */\n\tv_idx = i40e_vsi_mem_alloc(pf, type);\n\tif (v_idx < 0)\n\t\tgoto err_alloc;\n\tvsi = pf->vsi[v_idx];\n\tif (!vsi)\n\t\tgoto err_alloc;\n\tvsi->type = type;\n\tvsi->veb_idx = (veb ? veb->idx : I40E_NO_VEB);\n\n\tif (type == I40E_VSI_MAIN)\n\t\tpf->lan_vsi = v_idx;\n\telse if (type == I40E_VSI_SRIOV)\n\t\tvsi->vf_id = param1;\n\t/* assign it some queues */\n\talloc_queue_pairs = vsi->alloc_queue_pairs *\n\t\t\t    (i40e_enabled_xdp_vsi(vsi) ? 2 : 1);\n\n\tret = i40e_get_lump(pf, pf->qp_pile, alloc_queue_pairs, vsi->idx);\n\tif (ret < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to get tracking for %d queues for VSI %d err=%d\\n\",\n\t\t\t alloc_queue_pairs, vsi->seid, ret);\n\t\tgoto err_vsi;\n\t}\n\tvsi->base_queue = ret;\n\n\t/* get a VSI from the hardware */\n\tvsi->uplink_seid = uplink_seid;\n\tret = i40e_add_vsi(vsi);\n\tif (ret)\n\t\tgoto err_vsi;\n\n\tswitch (vsi->type) {\n\t/* setup the netdev if needed */\n\tcase I40E_VSI_MAIN:\n\tcase I40E_VSI_VMDQ2:\n\t\tret = i40e_config_netdev(vsi);\n\t\tif (ret)\n\t\t\tgoto err_netdev;\n\t\tret = register_netdev(vsi->netdev);\n\t\tif (ret)\n\t\t\tgoto err_netdev;\n\t\tvsi->netdev_registered = true;\n\t\tnetif_carrier_off(vsi->netdev);\n#ifdef CONFIG_I40E_DCB\n\t\t/* Setup DCB netlink interface */\n\t\ti40e_dcbnl_setup(vsi);\n#endif /* CONFIG_I40E_DCB */\n\t\t/* fall through */\n\n\tcase I40E_VSI_FDIR:\n\t\t/* set up vectors and rings if needed */\n\t\tret = i40e_vsi_setup_vectors(vsi);\n\t\tif (ret)\n\t\t\tgoto err_msix;\n\n\t\tret = i40e_alloc_rings(vsi);\n\t\tif (ret)\n\t\t\tgoto err_rings;\n\n\t\t/* map all of the rings to the q_vectors */\n\t\ti40e_vsi_map_rings_to_vectors(vsi);\n\n\t\ti40e_vsi_reset_stats(vsi);\n\t\tbreak;\n\n\tdefault:\n\t\t/* no netdev or rings for the other VSI types */\n\t\tbreak;\n\t}\n\n\tif ((pf->hw_features & I40E_HW_RSS_AQ_CAPABLE) &&\n\t    (vsi->type == I40E_VSI_VMDQ2)) {\n\t\tret = i40e_vsi_config_rss(vsi);\n\t}\n\treturn vsi;\n\nerr_rings:\n\ti40e_vsi_free_q_vectors(vsi);\nerr_msix:\n\tif (vsi->netdev_registered) {\n\t\tvsi->netdev_registered = false;\n\t\tunregister_netdev(vsi->netdev);\n\t\tfree_netdev(vsi->netdev);\n\t\tvsi->netdev = NULL;\n\t}\nerr_netdev:\n\ti40e_aq_delete_element(&pf->hw, vsi->seid, NULL);\nerr_vsi:\n\ti40e_vsi_clear(vsi);\nerr_alloc:\n\treturn NULL;\n}\n\n/**\n * i40e_veb_get_bw_info - Query VEB BW information\n * @veb: the veb to query\n *\n * Query the Tx scheduler BW configuration data for given VEB\n **/\nstatic int i40e_veb_get_bw_info(struct i40e_veb *veb)\n{\n\tstruct i40e_aqc_query_switching_comp_ets_config_resp ets_data;\n\tstruct i40e_aqc_query_switching_comp_bw_config_resp bw_data;\n\tstruct i40e_pf *pf = veb->pf;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 tc_bw_max;\n\tint ret = 0;\n\tint i;\n\n\tret = i40e_aq_query_switch_comp_bw_config(hw, veb->seid,\n\t\t\t\t\t\t  &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"query veb bw config failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\tret = i40e_aq_query_switch_comp_ets_config(hw, veb->seid,\n\t\t\t\t\t\t   &ets_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"query veb bw ets config failed, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\tveb->bw_limit = le16_to_cpu(ets_data.port_bw_limit);\n\tveb->bw_max_quanta = ets_data.tc_bw_max;\n\tveb->is_abs_credits = bw_data.absolute_credits_enable;\n\tveb->enabled_tc = ets_data.tc_valid_bits;\n\ttc_bw_max = le16_to_cpu(bw_data.tc_bw_max[0]) |\n\t\t    (le16_to_cpu(bw_data.tc_bw_max[1]) << 16);\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tveb->bw_tc_share_credits[i] = bw_data.tc_bw_share_credits[i];\n\t\tveb->bw_tc_limit_credits[i] =\n\t\t\t\t\tle16_to_cpu(bw_data.tc_bw_limits[i]);\n\t\tveb->bw_tc_max_quanta[i] = ((tc_bw_max >> (i*4)) & 0x7);\n\t}\n\nout:\n\treturn ret;\n}\n\n/**\n * i40e_veb_mem_alloc - Allocates the next available struct veb in the PF\n * @pf: board private structure\n *\n * On error: returns error code (negative)\n * On success: returns vsi index in PF (positive)\n **/\nstatic int i40e_veb_mem_alloc(struct i40e_pf *pf)\n{\n\tint ret = -ENOENT;\n\tstruct i40e_veb *veb;\n\tint i;\n\n\t/* Need to protect the allocation of switch elements at the PF level */\n\tmutex_lock(&pf->switch_mutex);\n\n\t/* VEB list may be fragmented if VEB creation/destruction has\n\t * been happening.  We can afford to do a quick scan to look\n\t * for any free slots in the list.\n\t *\n\t * find next empty veb slot, looping back around if necessary\n\t */\n\ti = 0;\n\twhile ((i < I40E_MAX_VEB) && (pf->veb[i] != NULL))\n\t\ti++;\n\tif (i >= I40E_MAX_VEB) {\n\t\tret = -ENOMEM;\n\t\tgoto err_alloc_veb;  /* out of VEB slots! */\n\t}\n\n\tveb = kzalloc(sizeof(*veb), GFP_KERNEL);\n\tif (!veb) {\n\t\tret = -ENOMEM;\n\t\tgoto err_alloc_veb;\n\t}\n\tveb->pf = pf;\n\tveb->idx = i;\n\tveb->enabled_tc = 1;\n\n\tpf->veb[i] = veb;\n\tret = i;\nerr_alloc_veb:\n\tmutex_unlock(&pf->switch_mutex);\n\treturn ret;\n}\n\n/**\n * i40e_switch_branch_release - Delete a branch of the switch tree\n * @branch: where to start deleting\n *\n * This uses recursion to find the tips of the branch to be\n * removed, deleting until we get back to and can delete this VEB.\n **/\nstatic void i40e_switch_branch_release(struct i40e_veb *branch)\n{\n\tstruct i40e_pf *pf = branch->pf;\n\tu16 branch_seid = branch->seid;\n\tu16 veb_idx = branch->idx;\n\tint i;\n\n\t/* release any VEBs on this VEB - RECURSION */\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (!pf->veb[i])\n\t\t\tcontinue;\n\t\tif (pf->veb[i]->uplink_seid == branch->seid)\n\t\t\ti40e_switch_branch_release(pf->veb[i]);\n\t}\n\n\t/* Release the VSIs on this VEB, but not the owner VSI.\n\t *\n\t * NOTE: Removing the last VSI on a VEB has the SIDE EFFECT of removing\n\t *       the VEB itself, so don't use (*branch) after this loop.\n\t */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (!pf->vsi[i])\n\t\t\tcontinue;\n\t\tif (pf->vsi[i]->uplink_seid == branch_seid &&\n\t\t   (pf->vsi[i]->flags & I40E_VSI_FLAG_VEB_OWNER) == 0) {\n\t\t\ti40e_vsi_release(pf->vsi[i]);\n\t\t}\n\t}\n\n\t/* There's one corner case where the VEB might not have been\n\t * removed, so double check it here and remove it if needed.\n\t * This case happens if the veb was created from the debugfs\n\t * commands and no VSIs were added to it.\n\t */\n\tif (pf->veb[veb_idx])\n\t\ti40e_veb_release(pf->veb[veb_idx]);\n}\n\n/**\n * i40e_veb_clear - remove veb struct\n * @veb: the veb to remove\n **/\nstatic void i40e_veb_clear(struct i40e_veb *veb)\n{\n\tif (!veb)\n\t\treturn;\n\n\tif (veb->pf) {\n\t\tstruct i40e_pf *pf = veb->pf;\n\n\t\tmutex_lock(&pf->switch_mutex);\n\t\tif (pf->veb[veb->idx] == veb)\n\t\t\tpf->veb[veb->idx] = NULL;\n\t\tmutex_unlock(&pf->switch_mutex);\n\t}\n\n\tkfree(veb);\n}\n\n/**\n * i40e_veb_release - Delete a VEB and free its resources\n * @veb: the VEB being removed\n **/\nvoid i40e_veb_release(struct i40e_veb *veb)\n{\n\tstruct i40e_vsi *vsi = NULL;\n\tstruct i40e_pf *pf;\n\tint i, n = 0;\n\n\tpf = veb->pf;\n\n\t/* find the remaining VSI and check for extras */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i] && pf->vsi[i]->uplink_seid == veb->seid) {\n\t\t\tn++;\n\t\t\tvsi = pf->vsi[i];\n\t\t}\n\t}\n\tif (n != 1) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"can't remove VEB %d with %d VSIs left\\n\",\n\t\t\t veb->seid, n);\n\t\treturn;\n\t}\n\n\t/* move the remaining VSI to uplink veb */\n\tvsi->flags &= ~I40E_VSI_FLAG_VEB_OWNER;\n\tif (veb->uplink_seid) {\n\t\tvsi->uplink_seid = veb->uplink_seid;\n\t\tif (veb->uplink_seid == pf->mac_seid)\n\t\t\tvsi->veb_idx = I40E_NO_VEB;\n\t\telse\n\t\t\tvsi->veb_idx = veb->veb_idx;\n\t} else {\n\t\t/* floating VEB */\n\t\tvsi->uplink_seid = pf->vsi[pf->lan_vsi]->uplink_seid;\n\t\tvsi->veb_idx = pf->vsi[pf->lan_vsi]->veb_idx;\n\t}\n\n\ti40e_aq_delete_element(&pf->hw, veb->seid, NULL);\n\ti40e_veb_clear(veb);\n}\n\n/**\n * i40e_add_veb - create the VEB in the switch\n * @veb: the VEB to be instantiated\n * @vsi: the controlling VSI\n **/\nstatic int i40e_add_veb(struct i40e_veb *veb, struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = veb->pf;\n\tbool enable_stats = !!(pf->flags & I40E_FLAG_VEB_STATS_ENABLED);\n\tint ret;\n\n\tret = i40e_aq_add_veb(&pf->hw, veb->uplink_seid, vsi->seid,\n\t\t\t      veb->enabled_tc, false,\n\t\t\t      &veb->seid, enable_stats, NULL);\n\n\t/* get a VEB from the hardware */\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't add VEB, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EPERM;\n\t}\n\n\t/* get statistics counter */\n\tret = i40e_aq_get_veb_parameters(&pf->hw, veb->seid, NULL, NULL,\n\t\t\t\t\t &veb->stats_idx, NULL, NULL, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get VEB statistics idx, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EPERM;\n\t}\n\tret = i40e_veb_get_bw_info(veb);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get VEB bw info, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\ti40e_aq_delete_element(&pf->hw, veb->seid, NULL);\n\t\treturn -ENOENT;\n\t}\n\n\tvsi->uplink_seid = veb->seid;\n\tvsi->veb_idx = veb->idx;\n\tvsi->flags |= I40E_VSI_FLAG_VEB_OWNER;\n\n\treturn 0;\n}\n\n/**\n * i40e_veb_setup - Set up a VEB\n * @pf: board private structure\n * @flags: VEB setup flags\n * @uplink_seid: the switch element to link to\n * @vsi_seid: the initial VSI seid\n * @enabled_tc: Enabled TC bit-map\n *\n * This allocates the sw VEB structure and links it into the switch\n * It is possible and legal for this to be a duplicate of an already\n * existing VEB.  It is also possible for both uplink and vsi seids\n * to be zero, in order to create a floating VEB.\n *\n * Returns pointer to the successfully allocated VEB sw struct on\n * success, otherwise returns NULL on failure.\n **/\nstruct i40e_veb *i40e_veb_setup(struct i40e_pf *pf, u16 flags,\n\t\t\t\tu16 uplink_seid, u16 vsi_seid,\n\t\t\t\tu8 enabled_tc)\n{\n\tstruct i40e_veb *veb, *uplink_veb = NULL;\n\tint vsi_idx, veb_idx;\n\tint ret;\n\n\t/* if one seid is 0, the other must be 0 to create a floating relay */\n\tif ((uplink_seid == 0 || vsi_seid == 0) &&\n\t    (uplink_seid + vsi_seid != 0)) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"one, not both seid's are 0: uplink=%d vsi=%d\\n\",\n\t\t\t uplink_seid, vsi_seid);\n\t\treturn NULL;\n\t}\n\n\t/* make sure there is such a vsi and uplink */\n\tfor (vsi_idx = 0; vsi_idx < pf->num_alloc_vsi; vsi_idx++)\n\t\tif (pf->vsi[vsi_idx] && pf->vsi[vsi_idx]->seid == vsi_seid)\n\t\t\tbreak;\n\tif (vsi_idx == pf->num_alloc_vsi && vsi_seid != 0) {\n\t\tdev_info(&pf->pdev->dev, \"vsi seid %d not found\\n\",\n\t\t\t vsi_seid);\n\t\treturn NULL;\n\t}\n\n\tif (uplink_seid && uplink_seid != pf->mac_seid) {\n\t\tfor (veb_idx = 0; veb_idx < I40E_MAX_VEB; veb_idx++) {\n\t\t\tif (pf->veb[veb_idx] &&\n\t\t\t    pf->veb[veb_idx]->seid == uplink_seid) {\n\t\t\t\tuplink_veb = pf->veb[veb_idx];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!uplink_veb) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"uplink seid %d not found\\n\", uplink_seid);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* get veb sw struct */\n\tveb_idx = i40e_veb_mem_alloc(pf);\n\tif (veb_idx < 0)\n\t\tgoto err_alloc;\n\tveb = pf->veb[veb_idx];\n\tveb->flags = flags;\n\tveb->uplink_seid = uplink_seid;\n\tveb->veb_idx = (uplink_veb ? uplink_veb->idx : I40E_NO_VEB);\n\tveb->enabled_tc = (enabled_tc ? enabled_tc : 0x1);\n\n\t/* create the VEB in the switch */\n\tret = i40e_add_veb(veb, pf->vsi[vsi_idx]);\n\tif (ret)\n\t\tgoto err_veb;\n\tif (vsi_idx == pf->lan_vsi)\n\t\tpf->lan_veb = veb->idx;\n\n\treturn veb;\n\nerr_veb:\n\ti40e_veb_clear(veb);\nerr_alloc:\n\treturn NULL;\n}\n\n/**\n * i40e_setup_pf_switch_element - set PF vars based on switch type\n * @pf: board private structure\n * @ele: element we are building info from\n * @num_reported: total number of elements\n * @printconfig: should we print the contents\n *\n * helper function to assist in extracting a few useful SEID values.\n **/\nstatic void i40e_setup_pf_switch_element(struct i40e_pf *pf,\n\t\t\t\tstruct i40e_aqc_switch_config_element_resp *ele,\n\t\t\t\tu16 num_reported, bool printconfig)\n{\n\tu16 downlink_seid = le16_to_cpu(ele->downlink_seid);\n\tu16 uplink_seid = le16_to_cpu(ele->uplink_seid);\n\tu8 element_type = ele->element_type;\n\tu16 seid = le16_to_cpu(ele->seid);\n\n\tif (printconfig)\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"type=%d seid=%d uplink=%d downlink=%d\\n\",\n\t\t\t element_type, seid, uplink_seid, downlink_seid);\n\n\tswitch (element_type) {\n\tcase I40E_SWITCH_ELEMENT_TYPE_MAC:\n\t\tpf->mac_seid = seid;\n\t\tbreak;\n\tcase I40E_SWITCH_ELEMENT_TYPE_VEB:\n\t\t/* Main VEB? */\n\t\tif (uplink_seid != pf->mac_seid)\n\t\t\tbreak;\n\t\tif (pf->lan_veb >= I40E_MAX_VEB) {\n\t\t\tint v;\n\n\t\t\t/* find existing or else empty VEB */\n\t\t\tfor (v = 0; v < I40E_MAX_VEB; v++) {\n\t\t\t\tif (pf->veb[v] && (pf->veb[v]->seid == seid)) {\n\t\t\t\t\tpf->lan_veb = v;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (pf->lan_veb >= I40E_MAX_VEB) {\n\t\t\t\tv = i40e_veb_mem_alloc(pf);\n\t\t\t\tif (v < 0)\n\t\t\t\t\tbreak;\n\t\t\t\tpf->lan_veb = v;\n\t\t\t}\n\t\t}\n\t\tif (pf->lan_veb >= I40E_MAX_VEB)\n\t\t\tbreak;\n\n\t\tpf->veb[pf->lan_veb]->seid = seid;\n\t\tpf->veb[pf->lan_veb]->uplink_seid = pf->mac_seid;\n\t\tpf->veb[pf->lan_veb]->pf = pf;\n\t\tpf->veb[pf->lan_veb]->veb_idx = I40E_NO_VEB;\n\t\tbreak;\n\tcase I40E_SWITCH_ELEMENT_TYPE_VSI:\n\t\tif (num_reported != 1)\n\t\t\tbreak;\n\t\t/* This is immediately after a reset so we can assume this is\n\t\t * the PF's VSI\n\t\t */\n\t\tpf->mac_seid = uplink_seid;\n\t\tpf->pf_seid = downlink_seid;\n\t\tpf->main_vsi_seid = seid;\n\t\tif (printconfig)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"pf_seid=%d main_vsi_seid=%d\\n\",\n\t\t\t\t pf->pf_seid, pf->main_vsi_seid);\n\t\tbreak;\n\tcase I40E_SWITCH_ELEMENT_TYPE_PF:\n\tcase I40E_SWITCH_ELEMENT_TYPE_VF:\n\tcase I40E_SWITCH_ELEMENT_TYPE_EMP:\n\tcase I40E_SWITCH_ELEMENT_TYPE_BMC:\n\tcase I40E_SWITCH_ELEMENT_TYPE_PE:\n\tcase I40E_SWITCH_ELEMENT_TYPE_PA:\n\t\t/* ignore these for now */\n\t\tbreak;\n\tdefault:\n\t\tdev_info(&pf->pdev->dev, \"unknown element type=%d seid=%d\\n\",\n\t\t\t element_type, seid);\n\t\tbreak;\n\t}\n}\n\n/**\n * i40e_fetch_switch_configuration - Get switch config from firmware\n * @pf: board private structure\n * @printconfig: should we print the contents\n *\n * Get the current switch configuration from the device and\n * extract a few useful SEID values.\n **/\nint i40e_fetch_switch_configuration(struct i40e_pf *pf, bool printconfig)\n{\n\tstruct i40e_aqc_get_switch_config_resp *sw_config;\n\tu16 next_seid = 0;\n\tint ret = 0;\n\tu8 *aq_buf;\n\tint i;\n\n\taq_buf = kzalloc(I40E_AQ_LARGE_BUF, GFP_KERNEL);\n\tif (!aq_buf)\n\t\treturn -ENOMEM;\n\n\tsw_config = (struct i40e_aqc_get_switch_config_resp *)aq_buf;\n\tdo {\n\t\tu16 num_reported, num_total;\n\n\t\tret = i40e_aq_get_switch_config(&pf->hw, sw_config,\n\t\t\t\t\t\tI40E_AQ_LARGE_BUF,\n\t\t\t\t\t\t&next_seid, NULL);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"get switch config failed err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\tkfree(aq_buf);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tnum_reported = le16_to_cpu(sw_config->header.num_reported);\n\t\tnum_total = le16_to_cpu(sw_config->header.num_total);\n\n\t\tif (printconfig)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"header: %d reported %d total\\n\",\n\t\t\t\t num_reported, num_total);\n\n\t\tfor (i = 0; i < num_reported; i++) {\n\t\t\tstruct i40e_aqc_switch_config_element_resp *ele =\n\t\t\t\t&sw_config->element[i];\n\n\t\t\ti40e_setup_pf_switch_element(pf, ele, num_reported,\n\t\t\t\t\t\t     printconfig);\n\t\t}\n\t} while (next_seid != 0);\n\n\tkfree(aq_buf);\n\treturn ret;\n}\n\n/**\n * i40e_setup_pf_switch - Setup the HW switch on startup or after reset\n * @pf: board private structure\n * @reinit: if the Main VSI needs to re-initialized.\n *\n * Returns 0 on success, negative value on failure\n **/\nstatic int i40e_setup_pf_switch(struct i40e_pf *pf, bool reinit)\n{\n\tu16 flags = 0;\n\tint ret;\n\n\t/* find out what's out there already */\n\tret = i40e_fetch_switch_configuration(pf, false);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't fetch switch config, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn ret;\n\t}\n\ti40e_pf_reset_stats(pf);\n\n\t/* set the switch config bit for the whole device to\n\t * support limited promisc or true promisc\n\t * when user requests promisc. The default is limited\n\t * promisc.\n\t*/\n\n\tif ((pf->hw.pf_id == 0) &&\n\t    !(pf->flags & I40E_FLAG_TRUE_PROMISC_SUPPORT)) {\n\t\tflags = I40E_AQ_SET_SWITCH_CFG_PROMISC;\n\t\tpf->last_sw_conf_flags = flags;\n\t}\n\n\tif (pf->hw.pf_id == 0) {\n\t\tu16 valid_flags;\n\n\t\tvalid_flags = I40E_AQ_SET_SWITCH_CFG_PROMISC;\n\t\tret = i40e_aq_set_switch_config(&pf->hw, flags, valid_flags, 0,\n\t\t\t\t\t\tNULL);\n\t\tif (ret && pf->hw.aq.asq_last_status != I40E_AQ_RC_ESRCH) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"couldn't set switch config bits, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\t/* not a fatal problem, just keep going */\n\t\t}\n\t\tpf->last_sw_conf_valid_flags = valid_flags;\n\t}\n\n\t/* first time setup */\n\tif (pf->lan_vsi == I40E_NO_VSI || reinit) {\n\t\tstruct i40e_vsi *vsi = NULL;\n\t\tu16 uplink_seid;\n\n\t\t/* Set up the PF VSI associated with the PF's main VSI\n\t\t * that is already in the HW switch\n\t\t */\n\t\tif (pf->lan_veb < I40E_MAX_VEB && pf->veb[pf->lan_veb])\n\t\t\tuplink_seid = pf->veb[pf->lan_veb]->seid;\n\t\telse\n\t\t\tuplink_seid = pf->mac_seid;\n\t\tif (pf->lan_vsi == I40E_NO_VSI)\n\t\t\tvsi = i40e_vsi_setup(pf, I40E_VSI_MAIN, uplink_seid, 0);\n\t\telse if (reinit)\n\t\t\tvsi = i40e_vsi_reinit_setup(pf->vsi[pf->lan_vsi]);\n\t\tif (!vsi) {\n\t\t\tdev_info(&pf->pdev->dev, \"setup of MAIN VSI failed\\n\");\n\t\t\ti40e_cloud_filter_exit(pf);\n\t\t\ti40e_fdir_teardown(pf);\n\t\t\treturn -EAGAIN;\n\t\t}\n\t} else {\n\t\t/* force a reset of TC and queue layout configurations */\n\t\tu8 enabled_tc = pf->vsi[pf->lan_vsi]->tc_config.enabled_tc;\n\n\t\tpf->vsi[pf->lan_vsi]->tc_config.enabled_tc = 0;\n\t\tpf->vsi[pf->lan_vsi]->seid = pf->main_vsi_seid;\n\t\ti40e_vsi_config_tc(pf->vsi[pf->lan_vsi], enabled_tc);\n\t}\n\ti40e_vlan_stripping_disable(pf->vsi[pf->lan_vsi]);\n\n\ti40e_fdir_sb_setup(pf);\n\n\t/* Setup static PF queue filter control settings */\n\tret = i40e_setup_pf_filter_control(pf);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"setup_pf_filter_control failed: %d\\n\",\n\t\t\t ret);\n\t\t/* Failure here should not stop continuing other steps */\n\t}\n\n\t/* enable RSS in the HW, even for only one queue, as the stack can use\n\t * the hash\n\t */\n\tif ((pf->flags & I40E_FLAG_RSS_ENABLED))\n\t\ti40e_pf_config_rss(pf);\n\n\t/* fill in link information and enable LSE reporting */\n\ti40e_link_event(pf);\n\n\t/* Initialize user-specific link properties */\n\tpf->fc_autoneg_status = ((pf->hw.phy.link_info.an_info &\n\t\t\t\t  I40E_AQ_AN_COMPLETED) ? true : false);\n\n\ti40e_ptp_init(pf);\n\n\t/* repopulate tunnel port filters */\n\ti40e_sync_udp_filters(pf);\n\n\treturn ret;\n}\n\n/**\n * i40e_determine_queue_usage - Work out queue distribution\n * @pf: board private structure\n **/\nstatic void i40e_determine_queue_usage(struct i40e_pf *pf)\n{\n\tint queues_left;\n\tint q_max;\n\n\tpf->num_lan_qps = 0;\n\n\t/* Find the max queues to be put into basic use.  We'll always be\n\t * using TC0, whether or not DCB is running, and TC0 will get the\n\t * big RSS set.\n\t */\n\tqueues_left = pf->hw.func_caps.num_tx_qp;\n\n\tif ((queues_left == 1) ||\n\t    !(pf->flags & I40E_FLAG_MSIX_ENABLED)) {\n\t\t/* one qp for PF, no queues for anything else */\n\t\tqueues_left = 0;\n\t\tpf->alloc_rss_size = pf->num_lan_qps = 1;\n\n\t\t/* make sure all the fancies are disabled */\n\t\tpf->flags &= ~(I40E_FLAG_RSS_ENABLED\t|\n\t\t\t       I40E_FLAG_IWARP_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_SB_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_ATR_ENABLED\t|\n\t\t\t       I40E_FLAG_DCB_CAPABLE\t|\n\t\t\t       I40E_FLAG_DCB_ENABLED\t|\n\t\t\t       I40E_FLAG_SRIOV_ENABLED\t|\n\t\t\t       I40E_FLAG_VMDQ_ENABLED);\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t} else if (!(pf->flags & (I40E_FLAG_RSS_ENABLED |\n\t\t\t\t  I40E_FLAG_FD_SB_ENABLED |\n\t\t\t\t  I40E_FLAG_FD_ATR_ENABLED |\n\t\t\t\t  I40E_FLAG_DCB_CAPABLE))) {\n\t\t/* one qp for PF */\n\t\tpf->alloc_rss_size = pf->num_lan_qps = 1;\n\t\tqueues_left -= pf->num_lan_qps;\n\n\t\tpf->flags &= ~(I40E_FLAG_RSS_ENABLED\t|\n\t\t\t       I40E_FLAG_IWARP_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_SB_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_ATR_ENABLED\t|\n\t\t\t       I40E_FLAG_DCB_ENABLED\t|\n\t\t\t       I40E_FLAG_VMDQ_ENABLED);\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t} else {\n\t\t/* Not enough queues for all TCs */\n\t\tif ((pf->flags & I40E_FLAG_DCB_CAPABLE) &&\n\t\t    (queues_left < I40E_MAX_TRAFFIC_CLASS)) {\n\t\t\tpf->flags &= ~(I40E_FLAG_DCB_CAPABLE |\n\t\t\t\t\tI40E_FLAG_DCB_ENABLED);\n\t\t\tdev_info(&pf->pdev->dev, \"not enough queues for DCB. DCB is disabled.\\n\");\n\t\t}\n\n\t\t/* limit lan qps to the smaller of qps, cpus or msix */\n\t\tq_max = max_t(int, pf->rss_size_max, num_online_cpus());\n\t\tq_max = min_t(int, q_max, pf->hw.func_caps.num_tx_qp);\n\t\tq_max = min_t(int, q_max, pf->hw.func_caps.num_msix_vectors);\n\t\tpf->num_lan_qps = q_max;\n\n\t\tqueues_left -= pf->num_lan_qps;\n\t}\n\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\tif (queues_left > 1) {\n\t\t\tqueues_left -= 1; /* save 1 queue for FD */\n\t\t} else {\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t\t\tdev_info(&pf->pdev->dev, \"not enough queues for Flow Director. Flow Director feature is disabled\\n\");\n\t\t}\n\t}\n\n\tif ((pf->flags & I40E_FLAG_SRIOV_ENABLED) &&\n\t    pf->num_vf_qps && pf->num_req_vfs && queues_left) {\n\t\tpf->num_req_vfs = min_t(int, pf->num_req_vfs,\n\t\t\t\t\t(queues_left / pf->num_vf_qps));\n\t\tqueues_left -= (pf->num_req_vfs * pf->num_vf_qps);\n\t}\n\n\tif ((pf->flags & I40E_FLAG_VMDQ_ENABLED) &&\n\t    pf->num_vmdq_vsis && pf->num_vmdq_qps && queues_left) {\n\t\tpf->num_vmdq_vsis = min_t(int, pf->num_vmdq_vsis,\n\t\t\t\t\t  (queues_left / pf->num_vmdq_qps));\n\t\tqueues_left -= (pf->num_vmdq_vsis * pf->num_vmdq_qps);\n\t}\n\n\tpf->queues_left = queues_left;\n\tdev_dbg(&pf->pdev->dev,\n\t\t\"qs_avail=%d FD SB=%d lan_qs=%d lan_tc0=%d vf=%d*%d vmdq=%d*%d, remaining=%d\\n\",\n\t\tpf->hw.func_caps.num_tx_qp,\n\t\t!!(pf->flags & I40E_FLAG_FD_SB_ENABLED),\n\t\tpf->num_lan_qps, pf->alloc_rss_size, pf->num_req_vfs,\n\t\tpf->num_vf_qps, pf->num_vmdq_vsis, pf->num_vmdq_qps,\n\t\tqueues_left);\n}\n\n/**\n * i40e_setup_pf_filter_control - Setup PF static filter control\n * @pf: PF to be setup\n *\n * i40e_setup_pf_filter_control sets up a PF's initial filter control\n * settings. If PE/FCoE are enabled then it will also set the per PF\n * based filter sizes required for them. It also enables Flow director,\n * ethertype and macvlan type filter settings for the pf.\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_setup_pf_filter_control(struct i40e_pf *pf)\n{\n\tstruct i40e_filter_control_settings *settings = &pf->filter_settings;\n\n\tsettings->hash_lut_size = I40E_HASH_LUT_SIZE_128;\n\n\t/* Flow Director is enabled */\n\tif (pf->flags & (I40E_FLAG_FD_SB_ENABLED | I40E_FLAG_FD_ATR_ENABLED))\n\t\tsettings->enable_fdir = true;\n\n\t/* Ethtype and MACVLAN filters enabled for PF */\n\tsettings->enable_ethtype = true;\n\tsettings->enable_macvlan = true;\n\n\tif (i40e_set_filter_control(&pf->hw, settings))\n\t\treturn -ENOENT;\n\n\treturn 0;\n}\n\n#define INFO_STRING_LEN 255\n#define REMAIN(__x) (INFO_STRING_LEN - (__x))\nstatic void i40e_print_features(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tchar *buf;\n\tint i;\n\n\tbuf = kmalloc(INFO_STRING_LEN, GFP_KERNEL);\n\tif (!buf)\n\t\treturn;\n\n\ti = snprintf(buf, INFO_STRING_LEN, \"Features: PF-id[%d]\", hw->pf_id);\n#ifdef CONFIG_PCI_IOV\n\ti += snprintf(&buf[i], REMAIN(i), \" VFs: %d\", pf->num_req_vfs);\n#endif\n\ti += snprintf(&buf[i], REMAIN(i), \" VSIs: %d QP: %d\",\n\t\t      pf->hw.func_caps.num_vsis,\n\t\t      pf->vsi[pf->lan_vsi]->num_queue_pairs);\n\tif (pf->flags & I40E_FLAG_RSS_ENABLED)\n\t\ti += snprintf(&buf[i], REMAIN(i), \" RSS\");\n\tif (pf->flags & I40E_FLAG_FD_ATR_ENABLED)\n\t\ti += snprintf(&buf[i], REMAIN(i), \" FD_ATR\");\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\ti += snprintf(&buf[i], REMAIN(i), \" FD_SB\");\n\t\ti += snprintf(&buf[i], REMAIN(i), \" NTUPLE\");\n\t}\n\tif (pf->flags & I40E_FLAG_DCB_CAPABLE)\n\t\ti += snprintf(&buf[i], REMAIN(i), \" DCB\");\n\ti += snprintf(&buf[i], REMAIN(i), \" VxLAN\");\n\ti += snprintf(&buf[i], REMAIN(i), \" Geneve\");\n\tif (pf->flags & I40E_FLAG_PTP)\n\t\ti += snprintf(&buf[i], REMAIN(i), \" PTP\");\n\tif (pf->flags & I40E_FLAG_VEB_MODE_ENABLED)\n\t\ti += snprintf(&buf[i], REMAIN(i), \" VEB\");\n\telse\n\t\ti += snprintf(&buf[i], REMAIN(i), \" VEPA\");\n\n\tdev_info(&pf->pdev->dev, \"%s\\n\", buf);\n\tkfree(buf);\n\tWARN_ON(i > INFO_STRING_LEN);\n}\n\n/**\n * i40e_get_platform_mac_addr - get platform-specific MAC address\n * @pdev: PCI device information struct\n * @pf: board private structure\n *\n * Look up the MAC address for the device. First we'll try\n * eth_platform_get_mac_address, which will check Open Firmware, or arch\n * specific fallback. Otherwise, we'll default to the stored value in\n * firmware.\n **/\nstatic void i40e_get_platform_mac_addr(struct pci_dev *pdev, struct i40e_pf *pf)\n{\n\tif (eth_platform_get_mac_address(&pdev->dev, pf->hw.mac.addr))\n\t\ti40e_get_mac_addr(&pf->hw, pf->hw.mac.addr);\n}\n\n/**\n * i40e_set_fec_in_flags - helper function for setting FEC options in flags\n * @fec_cfg: FEC option to set in flags\n * @flags: ptr to flags in which we set FEC option\n **/\nvoid i40e_set_fec_in_flags(u8 fec_cfg, u32 *flags)\n{\n\tif (fec_cfg & I40E_AQ_SET_FEC_AUTO)\n\t\t*flags |= I40E_FLAG_RS_FEC | I40E_FLAG_BASE_R_FEC;\n\tif ((fec_cfg & I40E_AQ_SET_FEC_REQUEST_RS) ||\n\t    (fec_cfg & I40E_AQ_SET_FEC_ABILITY_RS)) {\n\t\t*flags |= I40E_FLAG_RS_FEC;\n\t\t*flags &= ~I40E_FLAG_BASE_R_FEC;\n\t}\n\tif ((fec_cfg & I40E_AQ_SET_FEC_REQUEST_KR) ||\n\t    (fec_cfg & I40E_AQ_SET_FEC_ABILITY_KR)) {\n\t\t*flags |= I40E_FLAG_BASE_R_FEC;\n\t\t*flags &= ~I40E_FLAG_RS_FEC;\n\t}\n\tif (fec_cfg == 0)\n\t\t*flags &= ~(I40E_FLAG_RS_FEC | I40E_FLAG_BASE_R_FEC);\n}\n\n/**\n * i40e_check_recovery_mode - check if we are running transition firmware\n * @pf: board private structure\n *\n * Check registers indicating the firmware runs in recovery mode. Sets the\n * appropriate driver state.\n *\n * Returns true if the recovery mode was detected, false otherwise\n **/\nstatic bool i40e_check_recovery_mode(struct i40e_pf *pf)\n{\n\tu32 val = rd32(&pf->hw, I40E_GL_FWSTS) & I40E_GL_FWSTS_FWS1B_MASK;\n\tbool is_recovery_mode = false;\n\n\tif (pf->hw.mac.type == I40E_MAC_XL710)\n\t\tis_recovery_mode =\n\t\tval == I40E_XL710_GL_FWSTS_FWS1B_REC_MOD_CORER_MASK ||\n\t\tval == I40E_XL710_GL_FWSTS_FWS1B_REC_MOD_GLOBR_MASK ||\n\t\tval == I40E_XL710_GL_FWSTS_FWS1B_REC_MOD_TRANSITION_MASK ||\n\t\tval == I40E_XL710_GL_FWSTS_FWS1B_REC_MOD_NVM_MASK;\n\tif (pf->hw.mac.type == I40E_MAC_X722)\n\t\tis_recovery_mode =\n\t\tval == I40E_X722_GL_FWSTS_FWS1B_REC_MOD_CORER_MASK ||\n\t\tval == I40E_X722_GL_FWSTS_FWS1B_REC_MOD_GLOBR_MASK;\n\tif (is_recovery_mode) {\n\t\tdev_notice(&pf->pdev->dev, \"Firmware recovery mode detected. Limiting functionality.\\n\");\n\t\tdev_notice(&pf->pdev->dev, \"Refer to the Intel(R) Ethernet Adapters and Devices User Guide for details on firmware recovery mode.\\n\");\n\t\tset_bit(__I40E_RECOVERY_MODE, pf->state);\n\n\t\treturn true;\n\t}\n\tif (test_and_clear_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\tdev_info(&pf->pdev->dev, \"Reinitializing in normal mode with full functionality.\\n\");\n\n\treturn false;\n}\n\n/**\n * i40e_pf_loop_reset - perform reset in a loop.\n * @pf: board private structure\n *\n * This function is useful when a NIC is about to enter recovery mode.\n * When a NIC's internal data structures are corrupted the NIC's\n * firmware is going to enter recovery mode.\n * Right after a POR it takes about 7 minutes for firmware to enter\n * recovery mode. Until that time a NIC is in some kind of intermediate\n * state. After that time period the NIC almost surely enters\n * recovery mode. The only way for a driver to detect intermediate\n * state is to issue a series of pf-resets and check a return value.\n * If a PF reset returns success then the firmware could be in recovery\n * mode so the caller of this code needs to check for recovery mode\n * if this function returns success. There is a little chance that\n * firmware will hang in intermediate state forever.\n * Since waiting 7 minutes is quite a lot of time this function waits\n * 10 seconds and then gives up by returning an error.\n *\n * Return 0 on success, negative on failure.\n **/\nstatic i40e_status i40e_pf_loop_reset(struct i40e_pf *pf)\n{\n\tconst unsigned short MAX_CNT = 1000;\n\tconst unsigned short MSECS = 10;\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret;\n\tint cnt;\n\n\tfor (cnt = 0; cnt < MAX_CNT; ++cnt) {\n\t\tret = i40e_pf_reset(hw);\n\t\tif (!ret)\n\t\t\tbreak;\n\t\tmsleep(MSECS);\n\t}\n\n\tif (cnt == MAX_CNT) {\n\t\tdev_info(&pf->pdev->dev, \"PF reset failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tpf->pfr_count++;\n\treturn ret;\n}\n\n/**\n * i40e_init_recovery_mode - initialize subsystems needed in recovery mode\n * @pf: board private structure\n * @hw: ptr to the hardware info\n *\n * This function does a minimal setup of all subsystems needed for running\n * recovery mode.\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_init_recovery_mode(struct i40e_pf *pf, struct i40e_hw *hw)\n{\n\tstruct i40e_vsi *vsi;\n\tint err;\n\tint v_idx;\n\n\tpci_save_state(pf->pdev);\n\n\t/* set up periodic task facility */\n\ttimer_setup(&pf->service_timer, i40e_service_timer, 0);\n\tpf->service_timer_period = HZ;\n\n\tINIT_WORK(&pf->service_task, i40e_service_task);\n\tclear_bit(__I40E_SERVICE_SCHED, pf->state);\n\n\terr = i40e_init_interrupt_scheme(pf);\n\tif (err)\n\t\tgoto err_switch_setup;\n\n\t/* The number of VSIs reported by the FW is the minimum guaranteed\n\t * to us; HW supports far more and we share the remaining pool with\n\t * the other PFs. We allocate space for more than the guarantee with\n\t * the understanding that we might not get them all later.\n\t */\n\tif (pf->hw.func_caps.num_vsis < I40E_MIN_VSI_ALLOC)\n\t\tpf->num_alloc_vsi = I40E_MIN_VSI_ALLOC;\n\telse\n\t\tpf->num_alloc_vsi = pf->hw.func_caps.num_vsis;\n\n\t/* Set up the vsi struct and our local tracking of the MAIN PF vsi. */\n\tpf->vsi = kcalloc(pf->num_alloc_vsi, sizeof(struct i40e_vsi *),\n\t\t\t  GFP_KERNEL);\n\tif (!pf->vsi) {\n\t\terr = -ENOMEM;\n\t\tgoto err_switch_setup;\n\t}\n\n\t/* We allocate one VSI which is needed as absolute minimum\n\t * in order to register the netdev\n\t */\n\tv_idx = i40e_vsi_mem_alloc(pf, I40E_VSI_MAIN);\n\tif (v_idx < 0)\n\t\tgoto err_switch_setup;\n\tpf->lan_vsi = v_idx;\n\tvsi = pf->vsi[v_idx];\n\tif (!vsi)\n\t\tgoto err_switch_setup;\n\tvsi->alloc_queue_pairs = 1;\n\terr = i40e_config_netdev(vsi);\n\tif (err)\n\t\tgoto err_switch_setup;\n\terr = register_netdev(vsi->netdev);\n\tif (err)\n\t\tgoto err_switch_setup;\n\tvsi->netdev_registered = true;\n\ti40e_dbg_pf_init(pf);\n\n\terr = i40e_setup_misc_vector_for_recovery_mode(pf);\n\tif (err)\n\t\tgoto err_switch_setup;\n\n\t/* tell the firmware that we're starting */\n\ti40e_send_version(pf);\n\n\t/* since everything's happy, start the service_task timer */\n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\n\treturn 0;\n\nerr_switch_setup:\n\ti40e_reset_interrupt_capability(pf);\n\tdel_timer_sync(&pf->service_timer);\n\ti40e_shutdown_adminq(hw);\n\tiounmap(hw->hw_addr);\n\tpci_disable_pcie_error_reporting(pf->pdev);\n\tpci_release_mem_regions(pf->pdev);\n\tpci_disable_device(pf->pdev);\n\tkfree(pf);\n\n\treturn err;\n}\n\n/**\n * i40e_probe - Device initialization routine\n * @pdev: PCI device information struct\n * @ent: entry in i40e_pci_tbl\n *\n * i40e_probe initializes a PF identified by a pci_dev structure.\n * The OS initialization, configuring of the PF private structure,\n * and a hardware reset occur.\n *\n * Returns 0 on success, negative on failure\n **/\nstatic int i40e_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct i40e_aq_get_phy_abilities_resp abilities;\n\tstruct i40e_pf *pf;\n\tstruct i40e_hw *hw;\n\tstatic u16 pfs_found;\n\tu16 wol_nvm_bits;\n\tu16 link_status;\n\tint err;\n\tu32 val;\n\tu32 i;\n\tu8 set_fc_aq_fail;\n\n\terr = pci_enable_device_mem(pdev);\n\tif (err)\n\t\treturn err;\n\n\t/* set up for high or low dma */\n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (err) {\n\t\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\t\tif (err) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"DMA configuration failed: 0x%x\\n\", err);\n\t\t\tgoto err_dma;\n\t\t}\n\t}\n\n\t/* set up pci connections */\n\terr = pci_request_mem_regions(pdev, i40e_driver_name);\n\tif (err) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"pci_request_selected_regions failed %d\\n\", err);\n\t\tgoto err_pci_reg;\n\t}\n\n\tpci_enable_pcie_error_reporting(pdev);\n\tpci_set_master(pdev);\n\n\t/* Now that we have a PCI connection, we need to do the\n\t * low level device setup.  This is primarily setting up\n\t * the Admin Queue structures and then querying for the\n\t * device's current profile information.\n\t */\n\tpf = kzalloc(sizeof(*pf), GFP_KERNEL);\n\tif (!pf) {\n\t\terr = -ENOMEM;\n\t\tgoto err_pf_alloc;\n\t}\n\tpf->next_vsi = 0;\n\tpf->pdev = pdev;\n\tset_bit(__I40E_DOWN, pf->state);\n\n\thw = &pf->hw;\n\thw->back = pf;\n\n\tpf->ioremap_len = min_t(int, pci_resource_len(pdev, 0),\n\t\t\t\tI40E_MAX_CSR_SPACE);\n\t/* We believe that the highest register to read is\n\t * I40E_GLGEN_STAT_CLEAR, so we check if the BAR size\n\t * is not less than that before mapping to prevent a\n\t * kernel panic.\n\t */\n\tif (pf->ioremap_len < I40E_GLGEN_STAT_CLEAR) {\n\t\tdev_err(&pdev->dev, \"Cannot map registers, bar size 0x%X too small, aborting\\n\",\n\t\t\tpf->ioremap_len);\n\t\terr = -ENOMEM;\n\t\tgoto err_ioremap;\n\t}\n\thw->hw_addr = ioremap(pci_resource_start(pdev, 0), pf->ioremap_len);\n\tif (!hw->hw_addr) {\n\t\terr = -EIO;\n\t\tdev_info(&pdev->dev, \"ioremap(0x%04x, 0x%04x) failed: 0x%x\\n\",\n\t\t\t (unsigned int)pci_resource_start(pdev, 0),\n\t\t\t pf->ioremap_len, err);\n\t\tgoto err_ioremap;\n\t}\n\thw->vendor_id = pdev->vendor;\n\thw->device_id = pdev->device;\n\tpci_read_config_byte(pdev, PCI_REVISION_ID, &hw->revision_id);\n\thw->subsystem_vendor_id = pdev->subsystem_vendor;\n\thw->subsystem_device_id = pdev->subsystem_device;\n\thw->bus.device = PCI_SLOT(pdev->devfn);\n\thw->bus.func = PCI_FUNC(pdev->devfn);\n\thw->bus.bus_id = pdev->bus->number;\n\tpf->instance = pfs_found;\n\n\t/* Select something other than the 802.1ad ethertype for the\n\t * switch to use internally and drop on ingress.\n\t */\n\thw->switch_tag = 0xffff;\n\thw->first_tag = ETH_P_8021AD;\n\thw->second_tag = ETH_P_8021Q;\n\n\tINIT_LIST_HEAD(&pf->l3_flex_pit_list);\n\tINIT_LIST_HEAD(&pf->l4_flex_pit_list);\n\tINIT_LIST_HEAD(&pf->ddp_old_prof);\n\n\t/* set up the locks for the AQ, do this only once in probe\n\t * and destroy them only once in remove\n\t */\n\tmutex_init(&hw->aq.asq_mutex);\n\tmutex_init(&hw->aq.arq_mutex);\n\n\tpf->msg_enable = netif_msg_init(debug,\n\t\t\t\t\tNETIF_MSG_DRV |\n\t\t\t\t\tNETIF_MSG_PROBE |\n\t\t\t\t\tNETIF_MSG_LINK);\n\tif (debug < -1)\n\t\tpf->hw.debug_mask = debug;\n\n\t/* do a special CORER for clearing PXE mode once at init */\n\tif (hw->revision_id == 0 &&\n\t    (rd32(hw, I40E_GLLAN_RCTL_0) & I40E_GLLAN_RCTL_0_PXE_MODE_MASK)) {\n\t\twr32(hw, I40E_GLGEN_RTRIG, I40E_GLGEN_RTRIG_CORER_MASK);\n\t\ti40e_flush(hw);\n\t\tmsleep(200);\n\t\tpf->corer_count++;\n\n\t\ti40e_clear_pxe_mode(hw);\n\t}\n\n\t/* Reset here to make sure all is clean and to define PF 'n' */\n\ti40e_clear_hw(hw);\n\n\terr = i40e_set_mac_type(hw);\n\tif (err) {\n\t\tdev_warn(&pdev->dev, \"unidentified MAC or BLANK NVM: %d\\n\",\n\t\t\t err);\n\t\tgoto err_pf_reset;\n\t}\n\n\terr = i40e_pf_loop_reset(pf);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"Initial pf_reset failed: %d\\n\", err);\n\t\tgoto err_pf_reset;\n\t}\n\n\ti40e_check_recovery_mode(pf);\n\n\thw->aq.num_arq_entries = I40E_AQ_LEN;\n\thw->aq.num_asq_entries = I40E_AQ_LEN;\n\thw->aq.arq_buf_size = I40E_MAX_AQ_BUF_SIZE;\n\thw->aq.asq_buf_size = I40E_MAX_AQ_BUF_SIZE;\n\tpf->adminq_work_limit = I40E_AQ_WORK_LIMIT;\n\n\tsnprintf(pf->int_name, sizeof(pf->int_name) - 1,\n\t\t \"%s-%s:misc\",\n\t\t dev_driver_string(&pf->pdev->dev), dev_name(&pdev->dev));\n\n\terr = i40e_init_shared_code(hw);\n\tif (err) {\n\t\tdev_warn(&pdev->dev, \"unidentified MAC or BLANK NVM: %d\\n\",\n\t\t\t err);\n\t\tgoto err_pf_reset;\n\t}\n\n\t/* set up a default setting for link flow control */\n\tpf->hw.fc.requested_mode = I40E_FC_NONE;\n\n\terr = i40e_init_adminq(hw);\n\tif (err) {\n\t\tif (err == I40E_ERR_FIRMWARE_API_VERSION)\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"The driver for the device stopped because the NVM image v%u.%u is newer than expected v%u.%u. You must install the most recent version of the network driver.\\n\",\n\t\t\t\t hw->aq.api_maj_ver,\n\t\t\t\t hw->aq.api_min_ver,\n\t\t\t\t I40E_FW_API_VERSION_MAJOR,\n\t\t\t\t I40E_FW_MINOR_VERSION(hw));\n\t\telse\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"The driver for the device stopped because the device firmware failed to init. Try updating your NVM image.\\n\");\n\n\t\tgoto err_pf_reset;\n\t}\n\ti40e_get_oem_version(hw);\n\n\t/* provide nvm, fw, api versions, vendor:device id, subsys vendor:device id */\n\tdev_info(&pdev->dev, \"fw %d.%d.%05d api %d.%d nvm %s [%04x:%04x] [%04x:%04x]\\n\",\n\t\t hw->aq.fw_maj_ver, hw->aq.fw_min_ver, hw->aq.fw_build,\n\t\t hw->aq.api_maj_ver, hw->aq.api_min_ver,\n\t\t i40e_nvm_version_str(hw), hw->vendor_id, hw->device_id,\n\t\t hw->subsystem_vendor_id, hw->subsystem_device_id);\n\n\tif (hw->aq.api_maj_ver == I40E_FW_API_VERSION_MAJOR &&\n\t    hw->aq.api_min_ver > I40E_FW_MINOR_VERSION(hw))\n\t\tdev_info(&pdev->dev,\n\t\t\t \"The driver for the device detected a newer version of the NVM image v%u.%u than expected v%u.%u. Please install the most recent version of the network driver.\\n\",\n\t\t\t hw->aq.api_maj_ver,\n\t\t\t hw->aq.api_min_ver,\n\t\t\t I40E_FW_API_VERSION_MAJOR,\n\t\t\t I40E_FW_MINOR_VERSION(hw));\n\telse if (hw->aq.api_maj_ver == 1 && hw->aq.api_min_ver < 4)\n\t\tdev_info(&pdev->dev,\n\t\t\t \"The driver for the device detected an older version of the NVM image v%u.%u than expected v%u.%u. Please update the NVM image.\\n\",\n\t\t\t hw->aq.api_maj_ver,\n\t\t\t hw->aq.api_min_ver,\n\t\t\t I40E_FW_API_VERSION_MAJOR,\n\t\t\t I40E_FW_MINOR_VERSION(hw));\n\n\ti40e_verify_eeprom(pf);\n\n\t/* Rev 0 hardware was never productized */\n\tif (hw->revision_id < 1)\n\t\tdev_warn(&pdev->dev, \"This device is a pre-production adapter/LOM. Please be aware there may be issues with your hardware. If you are experiencing problems please contact your Intel or hardware representative who provided you with this hardware.\\n\");\n\n\ti40e_clear_pxe_mode(hw);\n\n\terr = i40e_get_capabilities(pf, i40e_aqc_opc_list_func_capabilities);\n\tif (err)\n\t\tgoto err_adminq_setup;\n\n\terr = i40e_sw_init(pf);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"sw_init failed: %d\\n\", err);\n\t\tgoto err_sw_init;\n\t}\n\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\treturn i40e_init_recovery_mode(pf, hw);\n\n\terr = i40e_init_lan_hmc(hw, hw->func_caps.num_tx_qp,\n\t\t\t\thw->func_caps.num_rx_qp, 0, 0);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"init_lan_hmc failed: %d\\n\", err);\n\t\tgoto err_init_lan_hmc;\n\t}\n\n\terr = i40e_configure_lan_hmc(hw, I40E_HMC_MODEL_DIRECT_ONLY);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"configure_lan_hmc failed: %d\\n\", err);\n\t\terr = -ENOENT;\n\t\tgoto err_configure_lan_hmc;\n\t}\n\n\t/* Disable LLDP for NICs that have firmware versions lower than v4.3.\n\t * Ignore error return codes because if it was already disabled via\n\t * hardware settings this will fail\n\t */\n\tif (pf->hw_features & I40E_HW_STOP_FW_LLDP) {\n\t\tdev_info(&pdev->dev, \"Stopping firmware LLDP agent.\\n\");\n\t\ti40e_aq_stop_lldp(hw, true, false, NULL);\n\t}\n\n\t/* allow a platform config to override the HW addr */\n\ti40e_get_platform_mac_addr(pdev, pf);\n\n\tif (!is_valid_ether_addr(hw->mac.addr)) {\n\t\tdev_info(&pdev->dev, \"invalid MAC address %pM\\n\", hw->mac.addr);\n\t\terr = -EIO;\n\t\tgoto err_mac_addr;\n\t}\n\tdev_info(&pdev->dev, \"MAC address: %pM\\n\", hw->mac.addr);\n\tether_addr_copy(hw->mac.perm_addr, hw->mac.addr);\n\ti40e_get_port_mac_addr(hw, hw->mac.port_addr);\n\tif (is_valid_ether_addr(hw->mac.port_addr))\n\t\tpf->hw_features |= I40E_HW_PORT_ID_VALID;\n\n\tpci_set_drvdata(pdev, pf);\n\tpci_save_state(pdev);\n\n\tdev_info(&pdev->dev,\n\t\t (pf->flags & I40E_FLAG_DISABLE_FW_LLDP) ?\n\t\t\t\"FW LLDP is disabled\\n\" :\n\t\t\t\"FW LLDP is enabled\\n\");\n\n\t/* Enable FW to write default DCB config on link-up */\n\ti40e_aq_set_dcb_parameters(hw, true, NULL);\n\n#ifdef CONFIG_I40E_DCB\n\terr = i40e_init_pf_dcb(pf);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"DCB init failed %d, disabled\\n\", err);\n\t\tpf->flags &= ~(I40E_FLAG_DCB_CAPABLE | I40E_FLAG_DCB_ENABLED);\n\t\t/* Continue without DCB enabled */\n\t}\n#endif /* CONFIG_I40E_DCB */\n\n\t/* set up periodic task facility */\n\ttimer_setup(&pf->service_timer, i40e_service_timer, 0);\n\tpf->service_timer_period = HZ;\n\n\tINIT_WORK(&pf->service_task, i40e_service_task);\n\tclear_bit(__I40E_SERVICE_SCHED, pf->state);\n\n\t/* NVM bit on means WoL disabled for the port */\n\ti40e_read_nvm_word(hw, I40E_SR_NVM_WAKE_ON_LAN, &wol_nvm_bits);\n\tif (BIT (hw->port) & wol_nvm_bits || hw->partition_id != 1)\n\t\tpf->wol_en = false;\n\telse\n\t\tpf->wol_en = true;\n\tdevice_set_wakeup_enable(&pf->pdev->dev, pf->wol_en);\n\n\t/* set up the main switch operations */\n\ti40e_determine_queue_usage(pf);\n\terr = i40e_init_interrupt_scheme(pf);\n\tif (err)\n\t\tgoto err_switch_setup;\n\n\t/* The number of VSIs reported by the FW is the minimum guaranteed\n\t * to us; HW supports far more and we share the remaining pool with\n\t * the other PFs. We allocate space for more than the guarantee with\n\t * the understanding that we might not get them all later.\n\t */\n\tif (pf->hw.func_caps.num_vsis < I40E_MIN_VSI_ALLOC)\n\t\tpf->num_alloc_vsi = I40E_MIN_VSI_ALLOC;\n\telse\n\t\tpf->num_alloc_vsi = pf->hw.func_caps.num_vsis;\n\n\t/* Set up the *vsi struct and our local tracking of the MAIN PF vsi. */\n\tpf->vsi = kcalloc(pf->num_alloc_vsi, sizeof(struct i40e_vsi *),\n\t\t\t  GFP_KERNEL);\n\tif (!pf->vsi) {\n\t\terr = -ENOMEM;\n\t\tgoto err_switch_setup;\n\t}\n\n#ifdef CONFIG_PCI_IOV\n\t/* prep for VF support */\n\tif ((pf->flags & I40E_FLAG_SRIOV_ENABLED) &&\n\t    (pf->flags & I40E_FLAG_MSIX_ENABLED) &&\n\t    !test_bit(__I40E_BAD_EEPROM, pf->state)) {\n\t\tif (pci_num_vf(pdev))\n\t\t\tpf->flags |= I40E_FLAG_VEB_MODE_ENABLED;\n\t}\n#endif\n\terr = i40e_setup_pf_switch(pf, false);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"setup_pf_switch failed: %d\\n\", err);\n\t\tgoto err_vsis;\n\t}\n\tINIT_LIST_HEAD(&pf->vsi[pf->lan_vsi]->ch_list);\n\n\t/* Make sure flow control is set according to current settings */\n\terr = i40e_set_fc(hw, &set_fc_aq_fail, true);\n\tif (set_fc_aq_fail & I40E_SET_FC_AQ_FAIL_GET)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Set fc with err %s aq_err %s on get_phy_cap\\n\",\n\t\t\ti40e_stat_str(hw, err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\tif (set_fc_aq_fail & I40E_SET_FC_AQ_FAIL_SET)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Set fc with err %s aq_err %s on set_phy_config\\n\",\n\t\t\ti40e_stat_str(hw, err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\tif (set_fc_aq_fail & I40E_SET_FC_AQ_FAIL_UPDATE)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Set fc with err %s aq_err %s on get_link_info\\n\",\n\t\t\ti40e_stat_str(hw, err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\n\t/* if FDIR VSI was set up, start it now */\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i] && pf->vsi[i]->type == I40E_VSI_FDIR) {\n\t\t\ti40e_vsi_open(pf->vsi[i]);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* The driver only wants link up/down and module qualification\n\t * reports from firmware.  Note the negative logic.\n\t */\n\terr = i40e_aq_set_phy_int_mask(&pf->hw,\n\t\t\t\t       ~(I40E_AQ_EVENT_LINK_UPDOWN |\n\t\t\t\t\t I40E_AQ_EVENT_MEDIA_NA |\n\t\t\t\t\t I40E_AQ_EVENT_MODULE_QUAL_FAIL), NULL);\n\tif (err)\n\t\tdev_info(&pf->pdev->dev, \"set phy mask fail, err %s aq_err %s\\n\",\n\t\t\t i40e_stat_str(&pf->hw, err),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t/* Reconfigure hardware for allowing smaller MSS in the case\n\t * of TSO, so that we avoid the MDD being fired and causing\n\t * a reset in the case of small MSS+TSO.\n\t */\n\tval = rd32(hw, I40E_REG_MSS);\n\tif ((val & I40E_REG_MSS_MIN_MASK) > I40E_64BYTE_MSS) {\n\t\tval &= ~I40E_REG_MSS_MIN_MASK;\n\t\tval |= I40E_64BYTE_MSS;\n\t\twr32(hw, I40E_REG_MSS, val);\n\t}\n\n\tif (pf->hw_features & I40E_HW_RESTART_AUTONEG) {\n\t\tmsleep(75);\n\t\terr = i40e_aq_set_link_restart_an(&pf->hw, true, NULL);\n\t\tif (err)\n\t\t\tdev_info(&pf->pdev->dev, \"link restart failed, err %s aq_err %s\\n\",\n\t\t\t\t i40e_stat_str(&pf->hw, err),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t}\n\t/* The main driver is (mostly) up and happy. We need to set this state\n\t * before setting up the misc vector or we get a race and the vector\n\t * ends up disabled forever.\n\t */\n\tclear_bit(__I40E_DOWN, pf->state);\n\n\t/* In case of MSIX we are going to setup the misc vector right here\n\t * to handle admin queue events etc. In case of legacy and MSI\n\t * the misc functionality and queue processing is combined in\n\t * the same vector and that gets setup at open.\n\t */\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\terr = i40e_setup_misc_vector(pf);\n\t\tif (err) {\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"setup of misc vector failed: %d\\n\", err);\n\t\t\tgoto err_vsis;\n\t\t}\n\t}\n\n#ifdef CONFIG_PCI_IOV\n\t/* prep for VF support */\n\tif ((pf->flags & I40E_FLAG_SRIOV_ENABLED) &&\n\t    (pf->flags & I40E_FLAG_MSIX_ENABLED) &&\n\t    !test_bit(__I40E_BAD_EEPROM, pf->state)) {\n\t\t/* disable link interrupts for VFs */\n\t\tval = rd32(hw, I40E_PFGEN_PORTMDIO_NUM);\n\t\tval &= ~I40E_PFGEN_PORTMDIO_NUM_VFLINK_STAT_ENA_MASK;\n\t\twr32(hw, I40E_PFGEN_PORTMDIO_NUM, val);\n\t\ti40e_flush(hw);\n\n\t\tif (pci_num_vf(pdev)) {\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"Active VFs found, allocating resources.\\n\");\n\t\t\terr = i40e_alloc_vfs(pf, pci_num_vf(pdev));\n\t\t\tif (err)\n\t\t\t\tdev_info(&pdev->dev,\n\t\t\t\t\t \"Error %d allocating resources for existing VFs\\n\",\n\t\t\t\t\t err);\n\t\t}\n\t}\n#endif /* CONFIG_PCI_IOV */\n\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tpf->iwarp_base_vector = i40e_get_lump(pf, pf->irq_pile,\n\t\t\t\t\t\t      pf->num_iwarp_msix,\n\t\t\t\t\t\t      I40E_IWARP_IRQ_PILE_ID);\n\t\tif (pf->iwarp_base_vector < 0) {\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"failed to get tracking for %d vectors for IWARP err=%d\\n\",\n\t\t\t\t pf->num_iwarp_msix, pf->iwarp_base_vector);\n\t\t\tpf->flags &= ~I40E_FLAG_IWARP_ENABLED;\n\t\t}\n\t}\n\n\ti40e_dbg_pf_init(pf);\n\n\t/* tell the firmware that we're starting */\n\ti40e_send_version(pf);\n\n\t/* since everything's happy, start the service_task timer */\n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\n\t/* add this PF to client device list and launch a client service task */\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\terr = i40e_lan_add_device(pf);\n\t\tif (err)\n\t\t\tdev_info(&pdev->dev, \"Failed to add PF to client API service list: %d\\n\",\n\t\t\t\t err);\n\t}\n\n#define PCI_SPEED_SIZE 8\n#define PCI_WIDTH_SIZE 8\n\t/* Devices on the IOSF bus do not have this information\n\t * and will report PCI Gen 1 x 1 by default so don't bother\n\t * checking them.\n\t */\n\tif (!(pf->hw_features & I40E_HW_NO_PCI_LINK_CHECK)) {\n\t\tchar speed[PCI_SPEED_SIZE] = \"Unknown\";\n\t\tchar width[PCI_WIDTH_SIZE] = \"Unknown\";\n\n\t\t/* Get the negotiated link width and speed from PCI config\n\t\t * space\n\t\t */\n\t\tpcie_capability_read_word(pf->pdev, PCI_EXP_LNKSTA,\n\t\t\t\t\t  &link_status);\n\n\t\ti40e_set_pci_config_data(hw, link_status);\n\n\t\tswitch (hw->bus.speed) {\n\t\tcase i40e_bus_speed_8000:\n\t\t\tstrlcpy(speed, \"8.0\", PCI_SPEED_SIZE); break;\n\t\tcase i40e_bus_speed_5000:\n\t\t\tstrlcpy(speed, \"5.0\", PCI_SPEED_SIZE); break;\n\t\tcase i40e_bus_speed_2500:\n\t\t\tstrlcpy(speed, \"2.5\", PCI_SPEED_SIZE); break;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tswitch (hw->bus.width) {\n\t\tcase i40e_bus_width_pcie_x8:\n\t\t\tstrlcpy(width, \"8\", PCI_WIDTH_SIZE); break;\n\t\tcase i40e_bus_width_pcie_x4:\n\t\t\tstrlcpy(width, \"4\", PCI_WIDTH_SIZE); break;\n\t\tcase i40e_bus_width_pcie_x2:\n\t\t\tstrlcpy(width, \"2\", PCI_WIDTH_SIZE); break;\n\t\tcase i40e_bus_width_pcie_x1:\n\t\t\tstrlcpy(width, \"1\", PCI_WIDTH_SIZE); break;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tdev_info(&pdev->dev, \"PCI-Express: Speed %sGT/s Width x%s\\n\",\n\t\t\t speed, width);\n\n\t\tif (hw->bus.width < i40e_bus_width_pcie_x8 ||\n\t\t    hw->bus.speed < i40e_bus_speed_8000) {\n\t\t\tdev_warn(&pdev->dev, \"PCI-Express bandwidth available for this device may be insufficient for optimal performance.\\n\");\n\t\t\tdev_warn(&pdev->dev, \"Please move the device to a different PCI-e link with more lanes and/or higher transfer rate.\\n\");\n\t\t}\n\t}\n\n\t/* get the requested speeds from the fw */\n\terr = i40e_aq_get_phy_capabilities(hw, false, false, &abilities, NULL);\n\tif (err)\n\t\tdev_dbg(&pf->pdev->dev, \"get requested speeds ret =  %s last_status =  %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, err),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\tpf->hw.phy.link_info.requested_speeds = abilities.link_speed;\n\n\t/* set the FEC config due to the board capabilities */\n\ti40e_set_fec_in_flags(abilities.fec_cfg_curr_mod_ext_info, &pf->flags);\n\n\t/* get the supported phy types from the fw */\n\terr = i40e_aq_get_phy_capabilities(hw, false, true, &abilities, NULL);\n\tif (err)\n\t\tdev_dbg(&pf->pdev->dev, \"get supported phy types ret =  %s last_status =  %s\\n\",\n\t\t\ti40e_stat_str(&pf->hw, err),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t/* Add a filter to drop all Flow control frames from any VSI from being\n\t * transmitted. By doing so we stop a malicious VF from sending out\n\t * PAUSE or PFC frames and potentially controlling traffic for other\n\t * PF/VF VSIs.\n\t * The FW can still send Flow control frames if enabled.\n\t */\n\ti40e_add_filter_to_drop_tx_flow_control_frames(&pf->hw,\n\t\t\t\t\t\t       pf->main_vsi_seid);\n\n\tif ((pf->hw.device_id == I40E_DEV_ID_10G_BASE_T) ||\n\t\t(pf->hw.device_id == I40E_DEV_ID_10G_BASE_T4))\n\t\tpf->hw_features |= I40E_HW_PHY_CONTROLS_LEDS;\n\tif (pf->hw.device_id == I40E_DEV_ID_SFP_I_X722)\n\t\tpf->hw_features |= I40E_HW_HAVE_CRT_RETIMER;\n\t/* print a string summarizing features */\n\ti40e_print_features(pf);\n\n\treturn 0;\n\n\t/* Unwind what we've done if something failed in the setup */\nerr_vsis:\n\tset_bit(__I40E_DOWN, pf->state);\n\ti40e_clear_interrupt_scheme(pf);\n\tkfree(pf->vsi);\nerr_switch_setup:\n\ti40e_reset_interrupt_capability(pf);\n\tdel_timer_sync(&pf->service_timer);\nerr_mac_addr:\nerr_configure_lan_hmc:\n\t(void)i40e_shutdown_lan_hmc(hw);\nerr_init_lan_hmc:\n\tkfree(pf->qp_pile);\nerr_sw_init:\nerr_adminq_setup:\nerr_pf_reset:\n\tiounmap(hw->hw_addr);\nerr_ioremap:\n\tkfree(pf);\nerr_pf_alloc:\n\tpci_disable_pcie_error_reporting(pdev);\n\tpci_release_mem_regions(pdev);\nerr_pci_reg:\nerr_dma:\n\tpci_disable_device(pdev);\n\treturn err;\n}\n\n/**\n * i40e_remove - Device removal routine\n * @pdev: PCI device information struct\n *\n * i40e_remove is called by the PCI subsystem to alert the driver\n * that is should release a PCI device.  This could be caused by a\n * Hot-Plug event, or because the driver is going to be removed from\n * memory.\n **/\nstatic void i40e_remove(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret_code;\n\tint i;\n\n\ti40e_dbg_pf_exit(pf);\n\n\ti40e_ptp_stop(pf);\n\n\t/* Disable RSS in hw */\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(0), 0);\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(1), 0);\n\n\t/* no more scheduling of any task */\n\tset_bit(__I40E_SUSPENDED, pf->state);\n\tset_bit(__I40E_DOWN, pf->state);\n\tif (pf->service_timer.function)\n\t\tdel_timer_sync(&pf->service_timer);\n\tif (pf->service_task.func)\n\t\tcancel_work_sync(&pf->service_task);\n\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\tstruct i40e_vsi *vsi = pf->vsi[0];\n\n\t\t/* We know that we have allocated only one vsi for this PF,\n\t\t * it was just for registering netdevice, so the interface\n\t\t * could be visible in the 'ifconfig' output\n\t\t */\n\t\tunregister_netdev(vsi->netdev);\n\t\tfree_netdev(vsi->netdev);\n\n\t\tgoto unmap;\n\t}\n\n\t/* Client close must be called explicitly here because the timer\n\t * has been stopped.\n\t */\n\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi], false);\n\n\tif (pf->flags & I40E_FLAG_SRIOV_ENABLED) {\n\t\ti40e_free_vfs(pf);\n\t\tpf->flags &= ~I40E_FLAG_SRIOV_ENABLED;\n\t}\n\n\ti40e_fdir_teardown(pf);\n\n\t/* If there is a switch structure or any orphans, remove them.\n\t * This will leave only the PF's VSI remaining.\n\t */\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (!pf->veb[i])\n\t\t\tcontinue;\n\n\t\tif (pf->veb[i]->uplink_seid == pf->mac_seid ||\n\t\t    pf->veb[i]->uplink_seid == 0)\n\t\t\ti40e_switch_branch_release(pf->veb[i]);\n\t}\n\n\t/* Now we can shutdown the PF's VSI, just before we kill\n\t * adminq and hmc.\n\t */\n\tif (pf->vsi[pf->lan_vsi])\n\t\ti40e_vsi_release(pf->vsi[pf->lan_vsi]);\n\n\ti40e_cloud_filter_exit(pf);\n\n\t/* remove attached clients */\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tret_code = i40e_lan_del_device(pf);\n\t\tif (ret_code)\n\t\t\tdev_warn(&pdev->dev, \"Failed to delete client device: %d\\n\",\n\t\t\t\t ret_code);\n\t}\n\n\t/* shutdown and destroy the HMC */\n\tif (hw->hmc.hmc_obj) {\n\t\tret_code = i40e_shutdown_lan_hmc(hw);\n\t\tif (ret_code)\n\t\t\tdev_warn(&pdev->dev,\n\t\t\t\t \"Failed to destroy the HMC resources: %d\\n\",\n\t\t\t\t ret_code);\n\t}\n\nunmap:\n\t/* Free MSI/legacy interrupt 0 when in recovery mode. */\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state) &&\n\t    !(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\tfree_irq(pf->pdev->irq, pf);\n\n\t/* shutdown the adminq */\n\ti40e_shutdown_adminq(hw);\n\n\t/* destroy the locks only once, here */\n\tmutex_destroy(&hw->aq.arq_mutex);\n\tmutex_destroy(&hw->aq.asq_mutex);\n\n\t/* Clear all dynamic memory lists of rings, q_vectors, and VSIs */\n\trtnl_lock();\n\ti40e_clear_interrupt_scheme(pf);\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i]) {\n\t\t\tif (!test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\t\t\ti40e_vsi_clear_rings(pf->vsi[i]);\n\t\t\ti40e_vsi_clear(pf->vsi[i]);\n\t\t\tpf->vsi[i] = NULL;\n\t\t}\n\t}\n\trtnl_unlock();\n\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tkfree(pf->veb[i]);\n\t\tpf->veb[i] = NULL;\n\t}\n\n\tkfree(pf->qp_pile);\n\tkfree(pf->vsi);\n\n\tiounmap(hw->hw_addr);\n\tkfree(pf);\n\tpci_release_mem_regions(pdev);\n\n\tpci_disable_pcie_error_reporting(pdev);\n\tpci_disable_device(pdev);\n}\n\n/**\n * i40e_pci_error_detected - warning that something funky happened in PCI land\n * @pdev: PCI device information struct\n * @error: the type of PCI error\n *\n * Called to warn that something happened and the error handling steps\n * are in progress.  Allows the driver to quiesce things, be ready for\n * remediation.\n **/\nstatic pci_ers_result_t i40e_pci_error_detected(struct pci_dev *pdev,\n\t\t\t\t\t\tenum pci_channel_state error)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\tdev_info(&pdev->dev, \"%s: error %d\\n\", __func__, error);\n\n\tif (!pf) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"Cannot recover - error happened during device probe\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\t/* shutdown all operations */\n\tif (!test_bit(__I40E_SUSPENDED, pf->state))\n\t\ti40e_prep_for_reset(pf, false);\n\n\t/* Request a slot reset */\n\treturn PCI_ERS_RESULT_NEED_RESET;\n}\n\n/**\n * i40e_pci_error_slot_reset - a PCI slot reset just happened\n * @pdev: PCI device information struct\n *\n * Called to find if the driver can work with the device now that\n * the pci slot has been reset.  If a basic connection seems good\n * (registers are readable and have sane content) then return a\n * happy little PCI_ERS_RESULT_xxx.\n **/\nstatic pci_ers_result_t i40e_pci_error_slot_reset(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\tpci_ers_result_t result;\n\tu32 reg;\n\n\tdev_dbg(&pdev->dev, \"%s\\n\", __func__);\n\tif (pci_enable_device_mem(pdev)) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"Cannot re-enable PCI device after reset.\\n\");\n\t\tresult = PCI_ERS_RESULT_DISCONNECT;\n\t} else {\n\t\tpci_set_master(pdev);\n\t\tpci_restore_state(pdev);\n\t\tpci_save_state(pdev);\n\t\tpci_wake_from_d3(pdev, false);\n\n\t\treg = rd32(&pf->hw, I40E_GLGEN_RTRIG);\n\t\tif (reg == 0)\n\t\t\tresult = PCI_ERS_RESULT_RECOVERED;\n\t\telse\n\t\t\tresult = PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\treturn result;\n}\n\n/**\n * i40e_pci_error_reset_prepare - prepare device driver for pci reset\n * @pdev: PCI device information struct\n */\nstatic void i40e_pci_error_reset_prepare(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\ti40e_prep_for_reset(pf, false);\n}\n\n/**\n * i40e_pci_error_reset_done - pci reset done, device driver reset can begin\n * @pdev: PCI device information struct\n */\nstatic void i40e_pci_error_reset_done(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\ti40e_reset_and_rebuild(pf, false, false);\n}\n\n/**\n * i40e_pci_error_resume - restart operations after PCI error recovery\n * @pdev: PCI device information struct\n *\n * Called to allow the driver to bring things back up after PCI error\n * and/or reset recovery has finished.\n **/\nstatic void i40e_pci_error_resume(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\tdev_dbg(&pdev->dev, \"%s\\n\", __func__);\n\tif (test_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn;\n\n\ti40e_handle_reset_warning(pf, false);\n}\n\n/**\n * i40e_enable_mc_magic_wake - enable multicast magic packet wake up\n * using the mac_address_write admin q function\n * @pf: pointer to i40e_pf struct\n **/\nstatic void i40e_enable_mc_magic_wake(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\ti40e_status ret;\n\tu8 mac_addr[6];\n\tu16 flags = 0;\n\n\t/* Get current MAC address in case it's an LAA */\n\tif (pf->vsi[pf->lan_vsi] && pf->vsi[pf->lan_vsi]->netdev) {\n\t\tether_addr_copy(mac_addr,\n\t\t\t\tpf->vsi[pf->lan_vsi]->netdev->dev_addr);\n\t} else {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to retrieve MAC address; using default\\n\");\n\t\tether_addr_copy(mac_addr, hw->mac.addr);\n\t}\n\n\t/* The FW expects the mac address write cmd to first be called with\n\t * one of these flags before calling it again with the multicast\n\t * enable flags.\n\t */\n\tflags = I40E_AQC_WRITE_TYPE_LAA_WOL;\n\n\tif (hw->func_caps.flex10_enable && hw->partition_id != 1)\n\t\tflags = I40E_AQC_WRITE_TYPE_LAA_ONLY;\n\n\tret = i40e_aq_mac_address_write(hw, flags, mac_addr, NULL);\n\tif (ret) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to update MAC address registers; cannot enable Multicast Magic packet wake up\");\n\t\treturn;\n\t}\n\n\tflags = I40E_AQC_MC_MAG_EN\n\t\t\t| I40E_AQC_WOL_PRESERVE_ON_PFR\n\t\t\t| I40E_AQC_WRITE_TYPE_UPDATE_MC_MAG;\n\tret = i40e_aq_mac_address_write(hw, flags, mac_addr, NULL);\n\tif (ret)\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to enable Multicast Magic Packet wake up\\n\");\n}\n\n/**\n * i40e_shutdown - PCI callback for shutting down\n * @pdev: PCI device information struct\n **/\nstatic void i40e_shutdown(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\tstruct i40e_hw *hw = &pf->hw;\n\n\tset_bit(__I40E_SUSPENDED, pf->state);\n\tset_bit(__I40E_DOWN, pf->state);\n\n\tdel_timer_sync(&pf->service_timer);\n\tcancel_work_sync(&pf->service_task);\n\ti40e_cloud_filter_exit(pf);\n\ti40e_fdir_teardown(pf);\n\n\t/* Client close must be called explicitly here because the timer\n\t * has been stopped.\n\t */\n\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi], false);\n\n\tif (pf->wol_en && (pf->hw_features & I40E_HW_WOL_MC_MAGIC_PKT_WAKE))\n\t\ti40e_enable_mc_magic_wake(pf);\n\n\ti40e_prep_for_reset(pf, false);\n\n\twr32(hw, I40E_PFPM_APM,\n\t     (pf->wol_en ? I40E_PFPM_APM_APME_MASK : 0));\n\twr32(hw, I40E_PFPM_WUFC,\n\t     (pf->wol_en ? I40E_PFPM_WUFC_MAG_MASK : 0));\n\n\t/* Free MSI/legacy interrupt 0 when in recovery mode. */\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state) &&\n\t    !(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\tfree_irq(pf->pdev->irq, pf);\n\n\t/* Since we're going to destroy queues during the\n\t * i40e_clear_interrupt_scheme() we should hold the RTNL lock for this\n\t * whole section\n\t */\n\trtnl_lock();\n\ti40e_clear_interrupt_scheme(pf);\n\trtnl_unlock();\n\n\tif (system_state == SYSTEM_POWER_OFF) {\n\t\tpci_wake_from_d3(pdev, pf->wol_en);\n\t\tpci_set_power_state(pdev, PCI_D3hot);\n\t}\n}\n\n/**\n * i40e_suspend - PM callback for moving to D3\n * @dev: generic device information structure\n **/\nstatic int __maybe_unused i40e_suspend(struct device *dev)\n{\n\tstruct i40e_pf *pf = dev_get_drvdata(dev);\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t/* If we're already suspended, then there is nothing to do */\n\tif (test_and_set_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn 0;\n\n\tset_bit(__I40E_DOWN, pf->state);\n\n\t/* Ensure service task will not be running */\n\tdel_timer_sync(&pf->service_timer);\n\tcancel_work_sync(&pf->service_task);\n\n\t/* Client close must be called explicitly here because the timer\n\t * has been stopped.\n\t */\n\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi], false);\n\n\tif (pf->wol_en && (pf->hw_features & I40E_HW_WOL_MC_MAGIC_PKT_WAKE))\n\t\ti40e_enable_mc_magic_wake(pf);\n\n\t/* Since we're going to destroy queues during the\n\t * i40e_clear_interrupt_scheme() we should hold the RTNL lock for this\n\t * whole section\n\t */\n\trtnl_lock();\n\n\ti40e_prep_for_reset(pf, true);\n\n\twr32(hw, I40E_PFPM_APM, (pf->wol_en ? I40E_PFPM_APM_APME_MASK : 0));\n\twr32(hw, I40E_PFPM_WUFC, (pf->wol_en ? I40E_PFPM_WUFC_MAG_MASK : 0));\n\n\t/* Clear the interrupt scheme and release our IRQs so that the system\n\t * can safely hibernate even when there are a large number of CPUs.\n\t * Otherwise hibernation might fail when mapping all the vectors back\n\t * to CPU0.\n\t */\n\ti40e_clear_interrupt_scheme(pf);\n\n\trtnl_unlock();\n\n\treturn 0;\n}\n\n/**\n * i40e_resume - PM callback for waking up from D3\n * @dev: generic device information structure\n **/\nstatic int __maybe_unused i40e_resume(struct device *dev)\n{\n\tstruct i40e_pf *pf = dev_get_drvdata(dev);\n\tint err;\n\n\t/* If we're not suspended, then there is nothing to do */\n\tif (!test_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn 0;\n\n\t/* We need to hold the RTNL lock prior to restoring interrupt schemes,\n\t * since we're going to be restoring queues\n\t */\n\trtnl_lock();\n\n\t/* We cleared the interrupt scheme when we suspended, so we need to\n\t * restore it now to resume device functionality.\n\t */\n\terr = i40e_restore_interrupt_scheme(pf);\n\tif (err) {\n\t\tdev_err(dev, \"Cannot restore interrupt scheme: %d\\n\",\n\t\t\terr);\n\t}\n\n\tclear_bit(__I40E_DOWN, pf->state);\n\ti40e_reset_and_rebuild(pf, false, true);\n\n\trtnl_unlock();\n\n\t/* Clear suspended state last after everything is recovered */\n\tclear_bit(__I40E_SUSPENDED, pf->state);\n\n\t/* Restart the service task */\n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\n\treturn 0;\n}\n\nstatic const struct pci_error_handlers i40e_err_handler = {\n\t.error_detected = i40e_pci_error_detected,\n\t.slot_reset = i40e_pci_error_slot_reset,\n\t.reset_prepare = i40e_pci_error_reset_prepare,\n\t.reset_done = i40e_pci_error_reset_done,\n\t.resume = i40e_pci_error_resume,\n};\n\nstatic SIMPLE_DEV_PM_OPS(i40e_pm_ops, i40e_suspend, i40e_resume);\n\nstatic struct pci_driver i40e_driver = {\n\t.name     = i40e_driver_name,\n\t.id_table = i40e_pci_tbl,\n\t.probe    = i40e_probe,\n\t.remove   = i40e_remove,\n\t.driver   = {\n\t\t.pm = &i40e_pm_ops,\n\t},\n\t.shutdown = i40e_shutdown,\n\t.err_handler = &i40e_err_handler,\n\t.sriov_configure = i40e_pci_sriov_configure,\n};\n\n/**\n * i40e_init_module - Driver registration routine\n *\n * i40e_init_module is the first routine called when the driver is\n * loaded. All it does is register with the PCI subsystem.\n **/\nstatic int __init i40e_init_module(void)\n{\n\tpr_info(\"%s: %s - version %s\\n\", i40e_driver_name,\n\t\ti40e_driver_string, i40e_driver_version_str);\n\tpr_info(\"%s: %s\\n\", i40e_driver_name, i40e_copyright);\n\n\t/* There is no need to throttle the number of active tasks because\n\t * each device limits its own task using a state bit for scheduling\n\t * the service task, and the device tasks do not interfere with each\n\t * other, so we don't set a max task limit. We must set WQ_MEM_RECLAIM\n\t * since we need to be able to guarantee forward progress even under\n\t * memory pressure.\n\t */\n\ti40e_wq = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0, i40e_driver_name);\n\tif (!i40e_wq) {\n\t\tpr_err(\"%s: Failed to create workqueue\\n\", i40e_driver_name);\n\t\treturn -ENOMEM;\n\t}\n\n\ti40e_dbg_init();\n\treturn pci_register_driver(&i40e_driver);\n}\nmodule_init(i40e_init_module);\n\n/**\n * i40e_exit_module - Driver exit cleanup routine\n *\n * i40e_exit_module is called just before the driver is removed\n * from memory.\n **/\nstatic void __exit i40e_exit_module(void)\n{\n\tpci_unregister_driver(&i40e_driver);\n\tdestroy_workqueue(i40e_wq);\n\ti40e_dbg_exit();\n}\nmodule_exit(i40e_exit_module);\n"], "filenames": ["drivers/net/ethernet/intel/i40e/i40e_main.c"], "buggy_code_start_loc": [7189], "buggy_code_end_loc": [7189], "fixing_code_start_loc": [7190], "fixing_code_end_loc": [7191], "type": "CWE-401", "message": "A memory leak in the i40e_setup_macvlans() function in drivers/net/ethernet/intel/i40e/i40e_main.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering i40e_setup_channel() failures, aka CID-27d461333459.", "other": {"cve": {"id": "CVE-2019-19043", "sourceIdentifier": "cve@mitre.org", "published": "2019-11-18T06:15:11.170", "lastModified": "2020-08-24T17:37:01.140", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A memory leak in the i40e_setup_macvlans() function in drivers/net/ethernet/intel/i40e/i40e_main.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering i40e_setup_channel() failures, aka CID-27d461333459."}, {"lang": "es", "value": "Una p\u00e9rdida de memoria en la funci\u00f3n i40e_setup_macvlans() en el archivo drivers/net/ethernet/intel/i40e/i40e_main.c en el kernel de Linux versiones hasta 5.3.11, permite a atacantes causar una denegaci\u00f3n de servicio (consumo de memoria) al desencadenar fallos de la funci\u00f3n i40e_setup_channel(), tambi\u00e9n se conoce como CID-27d461333459."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 4.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-401"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "5.3.11", "matchCriteriaId": "EB2904AC-AD7A-498D-8619-CBB421E9165D"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:18.04:*:*:*:lts:*:*:*", "matchCriteriaId": "23A7C53F-B80F-4E6A-AFA9-58EEA84BE11D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:19.10:*:*:*:*:*:*:*", "matchCriteriaId": "A31C8344-3E02-4EB8-8BD8-4C84B7959624"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:30:*:*:*:*:*:*:*", "matchCriteriaId": "97A4B8DF-58DA-4AB6-A1F9-331B36409BA3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:31:*:*:*:*:*:*:*", "matchCriteriaId": "80F0FA5D-8D3B-4C0E-81E2-87998286AF33"}]}]}], "references": [{"url": "https://github.com/torvalds/linux/commit/27d461333459d282ffa4a2bdb6b215a59d493a8f", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/O3PSDE6PTOTVBK2YTKB2TFQP2SUBVSNF/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/PY7LJMSPAGRIKABJPDKQDTXYW3L5RX2T/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20191205-0001/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4300-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/27d461333459d282ffa4a2bdb6b215a59d493a8f"}}
{"buggy_code": ["Development Version\n-------------------\n\nBug Fixes\n\n* Revert a change from 0.4.0 that changed IN to be a comparison (issue694).\n  The primary expectation is that IN is treated as a keyword and not as a\n  comparison operator. That also follows the definition of reserved keywords\n  for the major SQL syntax definitions.\n\nOther\n\n* sqlparse now uses pyproject.toml instead of setup.cfg (issue685).\n\n\nRelease 0.4.3 (Sep 23, 2022)\n----------------------------\n\nEnhancements\n\n* Add support for DIV operator (pr664, by chezou).\n* Add support for additional SPARK keywords (pr643, by mrmasterplan).\n* Avoid tokens copy (pr622, by living180).\n* Add REGEXP as a comparision (pr647, by PeterSandwich).\n* Add DISTINCTROW keyword for MS Access (issue677).\n* Improve parsing of CREATE TABLE AS SELECT (pr662, by chezou).\n\nBug Fixes\n\n* Fix spelling of INDICATOR keyword (pr653, by ptld).\n* Fix formatting error in EXTRACT function (issue562, issue670, pr676, by ecederstrand).\n* Fix bad parsing of create table statements that use lower case (issue217, pr642, by mrmasterplan).\n* Handle backtick as valid quote char (issue628, pr629, by codenamelxl).\n* Allow any unicode character as valid identifier name (issue641).\n\nOther\n\n* Update github actions to test on Python 3.10 as well (pr661, by cclaus).\n\n\nRelease 0.4.2 (Sep 10, 2021)\n----------------------------\n\nNotable Changes\n\n* IMPORTANT: This release fixes a security vulnerability in the\n  strip comments filter. In this filter a regular expression that was\n  vulnerable to ReDOS (Regular Expression Denial of Service) was\n  used. See the security advisory for details: https://github.com/andialbrecht/sqlparse/security/advisories/GHSA-p5w8-wqhj-9hhf\n  The vulnerability was discovered by @erik-krogh and @yoff from\n  GitHub Security Lab (GHSL). Thanks for reporting!\n\nEnhancements\n\n* Add ELSIF as keyword (issue584).\n* Add CONFLICT and ON_ERROR_STOP keywords (pr595, by j-martin).\n\nBug Fixes\n\n* Fix parsing of backticks (issue588).\n* Fix parsing of scientific number (issue399).\n\n\nRelease 0.4.1 (Oct 08, 2020)\n----------------------------\n\nBug Fixes\n\n* Just removed a debug print statement, sorry...\n\n\nRelease 0.4.0 (Oct 07, 2020)\n----------------------------\n\nNotable Changes\n\n* Remove support for end-of-life Python 2.7 and 3.4. Python 3.5+ is now\n  required.\n* Remaining strings that only consist of whitespaces are not treated as\n  statements anymore. Code that ignored the last element from\n  sqlparse.split() should be updated accordingly since that function\n  now doesn't return an empty string as the last element in some\n  cases (issue496).\n\nEnhancements\n\n* Add WINDOW keyword (pr579 by ali-tny).\n* Add RLIKE keyword (pr582 by wjones1).\n\nBug Fixes\n\n* Improved parsing of IN(...) statements (issue566, pr567 by hurcy).\n* Preserve line breaks when removing comments (issue484).\n* Fix parsing error when using square bracket notation (issue583).\n* Fix splitting when using DECLARE ... HANDLER (issue581).\n* Fix splitting of statements using CASE ... WHEN (issue580).\n* Improve formatting of type casts in parentheses.\n* Stabilize formatting of invalid SQL statements.\n\n\nRelease 0.3.1 (Feb 29, 2020)\n----------------------------\n\nEnhancements\n\n* Add HQL keywords (pr475, by matwalk).\n* Add support for time zone casts (issue489).\n* Enhance formatting of AS keyword (issue507, by john-bodley).\n* Stabilize grouping engine when parsing invalid SQL statements.\n\nBug Fixes\n\n* Fix splitting of SQL with multiple statements inside\n  parentheses (issue485, pr486 by win39).\n* Correctly identify NULLS FIRST / NULLS LAST as keywords (issue487).\n* Fix splitting of SQL statements that contain dollar signs in\n  identifiers (issue491).\n* Remove support for parsing double slash comments introduced in\n  0.3.0 (issue456) as it had some side-effects with other dialects and\n  doesn't seem to be widely used (issue476).\n* Restrict detection of alias names to objects that actually could\n  have an alias (issue455, adopted some parts of pr509 by john-bodley).\n* Fix parsing of date/time literals (issue438, by vashek).\n* Fix initialization of TokenList (issue499, pr505 by john-bodley).\n* Fix parsing of LIKE (issue493, pr525 by dbczumar).\n* Improve parsing of identifiers (pr527 by liulk).\n\n\nRelease 0.3.0 (Mar 11, 2019)\n----------------------------\n\nNotable Changes\n\n* Remove support for Python 3.3.\n\nEnhancements\n\n* New formatting option \"--indent_after_first\" (pr345, by johshoff).\n* New formatting option \"--indent_columns\" (pr393, by digitalarbeiter).\n* Add UPSERT keyword (issue408).\n* Strip multiple whitespace within parentheses (issue473, by john-bodley).\n* Support double slash (//) comments (issue456, by theianrobertson).\n* Support for Calcite temporal keywords (pr468, by john-bodley).\n\nBug Fixes\n\n* Fix occasional IndexError (pr390, by circld, issue313).\n* Fix incorrect splitting of strings containing new lines (pr396, by fredyw).\n* Fix reindent issue for parenthesis (issue427, by fredyw).\n* Fix from( parsing issue (issue446, by fredyw)\t.\n* Fix for get_real_name() to return correct name (issue369, by fredyw).\n* Wrap function params when wrap_after is set (pr398, by soloman1124).\n* Fix parsing of \"WHEN name\" clauses (pr418, by andrew deryabin).\n* Add missing EXPLAIN keyword (issue421).\n* Fix issue with strip_comments causing a syntax error (issue425, by fredyw).\n* Fix formatting on INSERT which caused staircase effect on values (issue329,\n  by fredyw).\n* Avoid formatting of psql commands (issue469).\n\nInternal Changes\n\n* Unify handling of GROUP BY/ORDER BY (pr457, by john-bodley).\n* Remove unnecessary compat shim for bytes (pr453, by jdufresne).\n\n\nRelease 0.2.4 (Sep 27, 2017)\n----------------------------\n\nEnhancements\n\n* Add more keywords for MySQL table options (pr328, pr333, by phdru).\n* Add more PL/pgSQL keywords (pr357, by Demetrio92).\n* Improve parsing of floats (pr330, by atronah).\n\nBug Fixes\n\n* Fix parsing of MySQL table names starting with digits (issue337).\n* Fix detection of identifiers using comparisons (issue327).\n* Fix parsing of UNION ALL after WHERE (issue349).\n* Fix handling of semicolon in assignments (issue359, issue358).\n\n\n\nRelease 0.2.3 (Mar 02, 2017)\n----------------------------\n\nEnhancements\n\n* New command line option \"--encoding\" (by twang2218, pr317).\n* Support CONCURRENTLY keyword (issue322, by rowanseymour).\n\nBug Fixes\n\n* Fix some edge-cases when parsing invalid SQL statements.\n* Fix indentation of LIMIT (by romainr, issue320).\n* Fix parsing of INTO keyword (issue324).\n\nInternal Changes\n\n* Several improvements regarding encodings.\n\n\nRelease 0.2.2 (Oct 22, 2016)\n----------------------------\n\nEnhancements\n\n* Add comma_first option: When splitting list \"comma first\" notation\n  is used (issue141).\n\nBug Fixes\n\n* Fix parsing of incomplete AS (issue284, by vmuriart).\n* Fix parsing of Oracle names containing dollars (issue291).\n* Fix parsing of UNION ALL (issue294).\n* Fix grouping of identifiers containing typecasts (issue297).\n* Add Changelog to sdist again (issue302).\n\nInternal Changes\n\n* `is_whitespace` and `is_group` changed into properties\n\n\nRelease 0.2.1 (Aug 13, 2016)\n----------------------------\n\nNotable Changes\n\n* PostgreSQL: Function bodys are parsed as literal string. Previously\n  sqlparse assumed that all function bodys are parsable psql\n  strings (see issue277).\n\nBug Fixes\n\n* Fix a regression to parse streams again (issue273, reported and\n  test case by gmccreight).\n* Improve Python 2/3 compatibility when using parsestream (issue190,\n  by phdru).\n* Improve splitting of PostgreSQL functions (issue277).\n\n\nRelease 0.2.0 (Jul 20, 2016)\n----------------------------\n\nIMPORTANT: The supported Python versions have changed with this release.\nsqlparse 0.2.x supports Python 2.7 and Python >= 3.3.\n\nThanks to the many contributors for writing bug reports and working\non pull requests who made this version possible!\n\nInternal Changes\n\n* sqlparse.SQLParseError was removed from top-level module and moved to\n  sqlparse.exceptions.\n* sqlparse.sql.Token.to_unicode was removed.\n* The signature of a filter's process method has changed from\n  process(stack, stream) -> to process(stream). Stack was never used at\n  all.\n* Lots of code cleanups and modernization (thanks esp. to vmuriart!).\n* Improved grouping performance. (sjoerdjob)\n\nEnhancements\n\n* Support WHILE loops (issue215, by shenlongxing).\n* Better support for CTEs (issue217, by Andrew Tipton).\n* Recognize USING as a keyword more consistently (issue236, by koljonen).\n* Improve alignment of columns (issue207, issue235, by vmuriat).\n* Add wrap_after option for better alignment when formatting\n  lists (issue248, by Dennis Taylor).\n* Add reindent-aligned option for alternate formatting (Adam Greenhall)\n* Improved grouping of operations (issue211, by vmuriat).\n\nBug Fixes\n\n* Leading whitespaces are now removed when format() is called with\n  strip_whitespace=True (issue213, by shenlongxing).\n* Fix typo in keywords list (issue229, by cbeloni).\n* Fix parsing of functions in comparisons (issue230, by saaj).\n* Fix grouping of identifiers (issue233).\n* Fix parsing of CREATE TABLE statements (issue242, by Tenghuan).\n* Minor bug fixes (issue101).\n* Improve formatting of CASE WHEN constructs (issue164, by vmuriat).\n\n\nRelease 0.1.19 (Mar 07, 2016)\n-----------------------------\n\nBug Fixes\n\n* Fix IndexError when statement contains WITH clauses (issue205).\n\n\nRelease 0.1.18 (Oct 25, 2015)\n-----------------------------\n\nBug Fixes\n\n* Remove universal wheel support, added in 0.1.17 by mistake.\n\n\nRelease 0.1.17 (Oct 24, 2015)\n-----------------------------\n\nEnhancements\n\n* Speed up parsing of large SQL statements (pull request: issue201, fixes the\n  following issues: issue199, issue135, issue62, issue41, by Ryan Wooden).\n\nBug Fixes\n\n* Fix another splitter bug regarding DECLARE (issue194).\n\nMisc\n\n* Packages on PyPI are signed from now on.\n\n\nRelease 0.1.16 (Jul 26, 2015)\n-----------------------------\n\nBug Fixes\n\n* Fix a regression in get_alias() introduced in 0.1.15 (issue185).\n* Fix a bug in the splitter regarding DECLARE (issue193).\n* sqlformat command line tool doesn't duplicate newlines anymore (issue191).\n* Don't mix up MySQL comments starting with hash and MSSQL\n  temp tables (issue192).\n* Statement.get_type() now ignores comments at the beginning of\n  a statement (issue186).\n\n\nRelease 0.1.15 (Apr 15, 2015)\n-----------------------------\n\nBug Fixes\n\n* Fix a regression for identifiers with square bracktes\n  notation (issue153, by darikg).\n* Add missing SQL types (issue154, issue155, issue156, by jukebox).\n* Fix parsing of multi-line comments (issue172, by JacekPliszka).\n* Fix parsing of escaped backslashes (issue174, by caseyching).\n* Fix parsing of identifiers starting with underscore (issue175).\n* Fix misinterpretation of IN keyword (issue183).\n\nEnhancements\n\n* Improve formatting of HAVING statements.\n* Improve parsing of inline comments (issue163).\n* Group comments to parent object (issue128, issue160).\n* Add double precision builtin (issue169, by darikg).\n* Add support for square bracket array indexing (issue170, issue176,\n  issue177 by darikg).\n* Improve grouping of aliased elements (issue167, by darikg).\n* Support comments starting with '#' character (issue178).\n\n\nRelease 0.1.14 (Nov 30, 2014)\n-----------------------------\n\nBug Fixes\n\n* Floats in UPDATE statements are now handled correctly (issue145).\n* Properly handle string literals in comparisons (issue148, change proposed\n  by aadis).\n* Fix indentation when using tabs (issue146).\n\nEnhancements\n\n* Improved formatting in list when newlines precede commas (issue140).\n\n\nRelease 0.1.13 (Oct 09, 2014)\n-----------------------------\n\nBug Fixes\n\n* Fix a regression in handling of NULL keywords introduced in 0.1.12.\n\n\nRelease 0.1.12 (Sep 20, 2014)\n-----------------------------\n\nBug Fixes\n\n* Fix handling of NULL keywords in aliased identifiers.\n* Fix SerializerUnicode to split unquoted newlines (issue131, by Michael Schuller).\n* Fix handling of modulo operators without spaces (by gavinwahl).\n\nEnhancements\n\n* Improve parsing of identifier lists containing placeholders.\n* Speed up query parsing of unquoted lines (by Michael Schuller).\n\n\nRelease 0.1.11 (Feb 07, 2014)\n-----------------------------\n\nBug Fixes\n\n* Fix incorrect parsing of string literals containing line breaks (issue118).\n* Fix typo in keywords, add MERGE, COLLECT keywords (issue122/124,\n  by Cristian Orellana).\n* Improve parsing of string literals in columns.\n* Fix parsing and formatting of statements containing EXCEPT keyword.\n* Fix Function.get_parameters() (issue126/127, by spigwitmer).\n\nEnhancements\n\n* Classify DML keywords (issue116, by Victor Hahn).\n* Add missing FOREACH keyword.\n* Grouping of BEGIN/END blocks.\n\nOther\n\n* Python 2.5 isn't automatically tested anymore, neither Travis nor Tox\n  still support it out of the box.\n\n\nRelease 0.1.10 (Nov 02, 2013)\n-----------------------------\n\nBug Fixes\n\n* Removed buffered reading again, it obviously causes wrong parsing in some rare\n  cases (issue114).\n* Fix regression in setup.py introduced 10 months ago (issue115).\n\nEnhancements\n\n* Improved support for JOINs, by Alexander Beedie.\n\n\nRelease 0.1.9 (Sep 28, 2013)\n----------------------------\n\nBug Fixes\n\n* Fix an regression introduced in 0.1.5 where sqlparse didn't properly\n  distinguished between single and double quoted strings when tagging\n  identifier (issue111).\n\nEnhancements\n\n* New option to truncate long string literals when formatting.\n* Scientific numbers are pares correctly (issue107).\n* Support for arithmetic expressions (issue109, issue106; by prudhvi).\n\n\nRelease 0.1.8 (Jun 29, 2013)\n----------------------------\n\nBug Fixes\n\n* Whitespaces within certain keywords are now allowed (issue97, patch proposed\n  by xcombelle).\n\nEnhancements\n\n* Improve parsing of assignments in UPDATE statements (issue90).\n* Add STRAIGHT_JOIN statement (by Yago Riveiro).\n* Function.get_parameters() now returns the parameter if only one parameter is\n  given (issue94, by wayne.wuw).\n* sqlparse.split() now removes leading and trailing whitespaces from split\n  statements.\n* Add USE as keyword token (by mulos).\n* Improve parsing of PEP249-style placeholders (issue103).\n\n\nRelease 0.1.7 (Apr 06, 2013)\n----------------------------\n\nBug Fixes\n\n* Fix Python 3 compatibility of sqlformat script (by Pi Delport).\n* Fix parsing of SQL statements that contain binary data (by Alexey\n  Malyshev).\n* Fix a bug where keywords were identified as aliased identifiers in\n  invalid SQL statements.\n* Fix parsing of identifier lists where identifiers are keywords too\n  (issue10).\n\nEnhancements\n\n* Top-level API functions now accept encoding keyword to parse\n  statements in certain encodings more reliable (issue20).\n* Improve parsing speed when SQL contains CLOBs or BLOBs (issue86).\n* Improve formatting of ORDER BY clauses (issue89).\n* Formatter now tries to detect runaway indentations caused by\n  parsing errors or invalid SQL statements. When re-indenting such\n  statements the formatter flips back to column 0 before going crazy.\n\nOther\n\n* Documentation updates.\n\n\nRelease 0.1.6 (Jan 01, 2013)\n----------------------------\n\nsqlparse is now compatible with Python 3 without any patches. The\nPython 3 version is generated during install by 2to3. You'll need\ndistribute to install sqlparse for Python 3.\n\nBug Fixes\n\n* Fix parsing error with dollar-quoted procedure bodies (issue83).\n\nOther\n\n* Documentation updates.\n* Test suite now uses tox and pytest.\n* py3k fixes (by vthriller).\n* py3k fixes in setup.py (by Florian Bauer).\n* setup.py now requires distribute (by Florian Bauer).\n\n\nRelease 0.1.5 (Nov 13, 2012)\n----------------------------\n\nBug Fixes\n\n* Improve handling of quoted identifiers (issue78).\n* Improve grouping and formatting of identifiers with operators (issue53).\n* Improve grouping and formatting of concatenated strings (issue53).\n* Improve handling of varchar() (by Mike Amy).\n* Clean up handling of various SQL elements.\n* Switch to pytest and clean up tests.\n* Several minor fixes.\n\nOther\n\n* Deprecate sqlparse.SQLParseError. Please use\n  sqlparse.exceptions.SQLParseError instead.\n* Add caching to speed up processing.\n* Add experimental filters for token processing.\n* Add sqlformat.parsestream (by quest).\n\n\nRelease 0.1.4 (Apr 20, 2012)\n----------------------------\n\nBug Fixes\n\n* Avoid \"stair case\" effects when identifiers, functions,\n  placeholders or keywords are mixed in identifier lists (issue45,\n  issue49, issue52) and when asterisks are used as operators\n  (issue58).\n* Make keyword detection more restrict (issue47).\n* Improve handling of CASE statements (issue46).\n* Fix statement splitting when parsing recursive statements (issue57,\n  thanks to piranna).\n* Fix for negative numbers (issue56, thanks to kevinjqiu).\n* Pretty format comments in identifier lists (issue59).\n* Several minor bug fixes and improvements.\n\n\nRelease 0.1.3 (Jul 29, 2011)\n----------------------------\n\nBug Fixes\n\n* Improve parsing of floats (thanks to Kris).\n* When formatting a statement a space before LIMIT was removed (issue35).\n* Fix strip_comments flag (issue38, reported by ooberm...@gmail.com).\n* Avoid parsing names as keywords (issue39, reported by djo...@taket.org).\n* Make sure identifier lists in subselects are grouped (issue40,\n  reported by djo...@taket.org).\n* Split statements with IF as functions correctly (issue33 and\n  issue29, reported by charles....@unige.ch).\n* Relax detection of keywords, esp. when used as function names\n  (issue36, nyuhu...@gmail.com).\n* Don't treat single characters as keywords (issue32).\n* Improve parsing of stand-alone comments (issue26).\n* Detection of placeholders in paramterized queries (issue22,\n  reported by Glyph Lefkowitz).\n* Add parsing of MS Access column names with braces (issue27,\n  reported by frankz...@gmail.com).\n\nOther\n\n* Replace Django by Flask in App Engine frontend (issue11).\n\n\nRelease 0.1.2 (Nov 23, 2010)\n----------------------------\n\nBug Fixes\n\n* Fixed incorrect detection of keyword fragments embed in names (issue7,\n  reported and initial patch by andyboyko).\n* Stricter detection of identifier aliases (issue8, reported by estama).\n* WHERE grouping consumed closing parenthesis (issue9, reported by estama).\n* Fixed an issue with trailing whitespaces (reported by Kris).\n* Better detection of escaped single quotes (issue13, reported by\n  Martin Brochhaus, patch by bluemaro with test case by Dan Carley).\n* Ignore identifier in double-quotes when changing cases (issue 21).\n* Lots of minor fixes targeting encoding, indentation, statement\n  parsing and more (issues 12, 14, 15, 16, 18, 19).\n* Code cleanup with a pinch of refactoring.\n\n\nRelease 0.1.1 (May 6, 2009)\n---------------------------\n\nBug Fixes\n\n* Lexers preserves original line breaks (issue1).\n* Improved identifier parsing: backtick quotes, wildcards, T-SQL variables\n  prefixed with @.\n* Improved parsing of identifier lists (issue2).\n* Recursive recognition of AS (issue4) and CASE.\n* Improved support for UPDATE statements.\n\nOther\n\n* Code cleanup and better test coverage.\n\n\nRelease 0.1.0 (Apr 8, 2009)\n---------------------------\n\nInitial release.\n", "#\n# Copyright (C) 2009-2020 the sqlparse authors and contributors\n# <see AUTHORS file>\n#\n# This module is part of python-sqlparse and is released under\n# the BSD License: https://opensource.org/licenses/BSD-3-Clause\n\nfrom sqlparse import tokens\n\n# object() only supports \"is\" and is useful as a marker\n# use this marker to specify that the given regex in SQL_REGEX\n# shall be processed further through a lookup in the KEYWORDS dictionaries\nPROCESS_AS_KEYWORD = object()\n\n\nSQL_REGEX = [\n    (r'(--|# )\\+.*?(\\r\\n|\\r|\\n|$)', tokens.Comment.Single.Hint),\n    (r'/\\*\\+[\\s\\S]*?\\*/', tokens.Comment.Multiline.Hint),\n\n    (r'(--|# ).*?(\\r\\n|\\r|\\n|$)', tokens.Comment.Single),\n    (r'/\\*[\\s\\S]*?\\*/', tokens.Comment.Multiline),\n\n    (r'(\\r\\n|\\r|\\n)', tokens.Newline),\n    (r'\\s+?', tokens.Whitespace),\n\n    (r':=', tokens.Assignment),\n    (r'::', tokens.Punctuation),\n\n    (r'\\*', tokens.Wildcard),\n\n    (r\"`(``|[^`])*`\", tokens.Name),\n    (r\"\u00b4(\u00b4\u00b4|[^\u00b4])*\u00b4\", tokens.Name),\n    (r'((?<!\\S)\\$(?:[_A-Z\u00c0-\u00dc]\\w*)?\\$)[\\s\\S]*?\\1', tokens.Literal),\n\n    (r'\\?', tokens.Name.Placeholder),\n    (r'%(\\(\\w+\\))?s', tokens.Name.Placeholder),\n    (r'(?<!\\w)[$:?]\\w+', tokens.Name.Placeholder),\n\n    (r'\\\\\\w+', tokens.Command),\n\n    # FIXME(andi): VALUES shouldn't be listed here\n    # see https://github.com/andialbrecht/sqlparse/pull/64\n    # AS and IN are special, it may be followed by a parenthesis, but\n    # are never functions, see issue183 and issue507\n    (r'(CASE|IN|VALUES|USING|FROM|AS)\\b', tokens.Keyword),\n\n    (r'(@|##|#)[A-Z\u00c0-\u00dc]\\w+', tokens.Name),\n\n    # see issue #39\n    # Spaces around period `schema . name` are valid identifier\n    # TODO: Spaces before period not implemented\n    (r'[A-Z\u00c0-\u00dc]\\w*(?=\\s*\\.)', tokens.Name),  # 'Name'.\n    # FIXME(atronah): never match,\n    # because `re.match` doesn't work with look-behind regexp feature\n    (r'(?<=\\.)[A-Z\u00c0-\u00dc]\\w*', tokens.Name),  # .'Name'\n    (r'[A-Z\u00c0-\u00dc]\\w*(?=\\()', tokens.Name),  # side effect: change kw to func\n    (r'-?0x[\\dA-F]+', tokens.Number.Hexadecimal),\n    (r'-?\\d+(\\.\\d+)?E-?\\d+', tokens.Number.Float),\n    (r'(?![_A-Z\u00c0-\u00dc])-?(\\d+(\\.\\d*)|\\.\\d+)(?![_A-Z\u00c0-\u00dc])',\n     tokens.Number.Float),\n    (r'(?![_A-Z\u00c0-\u00dc])-?\\d+(?![_A-Z\u00c0-\u00dc])', tokens.Number.Integer),\n    (r\"'(''|\\\\\\\\|\\\\'|[^'])*'\", tokens.String.Single),\n    # not a real string literal in ANSI SQL:\n    (r'\"(\"\"|\\\\\\\\|\\\\\"|[^\"])*\"', tokens.String.Symbol),\n    (r'(\"\"|\".*?[^\\\\]\")', tokens.String.Symbol),\n    # sqlite names can be escaped with [square brackets]. left bracket\n    # cannot be preceded by word character or a right bracket --\n    # otherwise it's probably an array index\n    (r'(?<![\\w\\])])(\\[[^\\]\\[]+\\])', tokens.Name),\n    (r'((LEFT\\s+|RIGHT\\s+|FULL\\s+)?(INNER\\s+|OUTER\\s+|STRAIGHT\\s+)?'\n     r'|(CROSS\\s+|NATURAL\\s+)?)?JOIN\\b', tokens.Keyword),\n    (r'END(\\s+IF|\\s+LOOP|\\s+WHILE)?\\b', tokens.Keyword),\n    (r'NOT\\s+NULL\\b', tokens.Keyword),\n    (r'NULLS\\s+(FIRST|LAST)\\b', tokens.Keyword),\n    (r'UNION\\s+ALL\\b', tokens.Keyword),\n    (r'CREATE(\\s+OR\\s+REPLACE)?\\b', tokens.Keyword.DDL),\n    (r'DOUBLE\\s+PRECISION\\b', tokens.Name.Builtin),\n    (r'GROUP\\s+BY\\b', tokens.Keyword),\n    (r'ORDER\\s+BY\\b', tokens.Keyword),\n    (r'HANDLER\\s+FOR\\b', tokens.Keyword),\n    (r'(LATERAL\\s+VIEW\\s+)'\n     r'(EXPLODE|INLINE|PARSE_URL_TUPLE|POSEXPLODE|STACK)\\b',\n     tokens.Keyword),\n    (r\"(AT|WITH')\\s+TIME\\s+ZONE\\s+'[^']+'\", tokens.Keyword.TZCast),\n    (r'(NOT\\s+)?(LIKE|ILIKE|RLIKE)\\b', tokens.Operator.Comparison),\n    (r'(NOT\\s+)?(REGEXP)\\b', tokens.Operator.Comparison),\n    # Check for keywords, also returns tokens.Name if regex matches\n    # but the match isn't a keyword.\n    (r'\\w[$#\\w]*', PROCESS_AS_KEYWORD),\n    (r'[;:()\\[\\],\\.]', tokens.Punctuation),\n    (r'[<>=~!]+', tokens.Operator.Comparison),\n    (r'[+/@#%^&|^-]+', tokens.Operator),\n]\n\nKEYWORDS = {\n    'ABORT': tokens.Keyword,\n    'ABS': tokens.Keyword,\n    'ABSOLUTE': tokens.Keyword,\n    'ACCESS': tokens.Keyword,\n    'ADA': tokens.Keyword,\n    'ADD': tokens.Keyword,\n    'ADMIN': tokens.Keyword,\n    'AFTER': tokens.Keyword,\n    'AGGREGATE': tokens.Keyword,\n    'ALIAS': tokens.Keyword,\n    'ALL': tokens.Keyword,\n    'ALLOCATE': tokens.Keyword,\n    'ANALYSE': tokens.Keyword,\n    'ANALYZE': tokens.Keyword,\n    'ANY': tokens.Keyword,\n    'ARRAYLEN': tokens.Keyword,\n    'ARE': tokens.Keyword,\n    'ASC': tokens.Keyword.Order,\n    'ASENSITIVE': tokens.Keyword,\n    'ASSERTION': tokens.Keyword,\n    'ASSIGNMENT': tokens.Keyword,\n    'ASYMMETRIC': tokens.Keyword,\n    'AT': tokens.Keyword,\n    'ATOMIC': tokens.Keyword,\n    'AUDIT': tokens.Keyword,\n    'AUTHORIZATION': tokens.Keyword,\n    'AUTO_INCREMENT': tokens.Keyword,\n    'AVG': tokens.Keyword,\n\n    'BACKWARD': tokens.Keyword,\n    'BEFORE': tokens.Keyword,\n    'BEGIN': tokens.Keyword,\n    'BETWEEN': tokens.Keyword,\n    'BITVAR': tokens.Keyword,\n    'BIT_LENGTH': tokens.Keyword,\n    'BOTH': tokens.Keyword,\n    'BREADTH': tokens.Keyword,\n\n    # 'C': tokens.Keyword,  # most likely this is an alias\n    'CACHE': tokens.Keyword,\n    'CALL': tokens.Keyword,\n    'CALLED': tokens.Keyword,\n    'CARDINALITY': tokens.Keyword,\n    'CASCADE': tokens.Keyword,\n    'CASCADED': tokens.Keyword,\n    'CAST': tokens.Keyword,\n    'CATALOG': tokens.Keyword,\n    'CATALOG_NAME': tokens.Keyword,\n    'CHAIN': tokens.Keyword,\n    'CHARACTERISTICS': tokens.Keyword,\n    'CHARACTER_LENGTH': tokens.Keyword,\n    'CHARACTER_SET_CATALOG': tokens.Keyword,\n    'CHARACTER_SET_NAME': tokens.Keyword,\n    'CHARACTER_SET_SCHEMA': tokens.Keyword,\n    'CHAR_LENGTH': tokens.Keyword,\n    'CHARSET': tokens.Keyword,\n    'CHECK': tokens.Keyword,\n    'CHECKED': tokens.Keyword,\n    'CHECKPOINT': tokens.Keyword,\n    'CLASS': tokens.Keyword,\n    'CLASS_ORIGIN': tokens.Keyword,\n    'CLOB': tokens.Keyword,\n    'CLOSE': tokens.Keyword,\n    'CLUSTER': tokens.Keyword,\n    'COALESCE': tokens.Keyword,\n    'COBOL': tokens.Keyword,\n    'COLLATE': tokens.Keyword,\n    'COLLATION': tokens.Keyword,\n    'COLLATION_CATALOG': tokens.Keyword,\n    'COLLATION_NAME': tokens.Keyword,\n    'COLLATION_SCHEMA': tokens.Keyword,\n    'COLLECT': tokens.Keyword,\n    'COLUMN': tokens.Keyword,\n    'COLUMN_NAME': tokens.Keyword,\n    'COMPRESS': tokens.Keyword,\n    'COMMAND_FUNCTION': tokens.Keyword,\n    'COMMAND_FUNCTION_CODE': tokens.Keyword,\n    'COMMENT': tokens.Keyword,\n    'COMMIT': tokens.Keyword.DML,\n    'COMMITTED': tokens.Keyword,\n    'COMPLETION': tokens.Keyword,\n    'CONCURRENTLY': tokens.Keyword,\n    'CONDITION_NUMBER': tokens.Keyword,\n    'CONNECT': tokens.Keyword,\n    'CONNECTION': tokens.Keyword,\n    'CONNECTION_NAME': tokens.Keyword,\n    'CONSTRAINT': tokens.Keyword,\n    'CONSTRAINTS': tokens.Keyword,\n    'CONSTRAINT_CATALOG': tokens.Keyword,\n    'CONSTRAINT_NAME': tokens.Keyword,\n    'CONSTRAINT_SCHEMA': tokens.Keyword,\n    'CONSTRUCTOR': tokens.Keyword,\n    'CONTAINS': tokens.Keyword,\n    'CONTINUE': tokens.Keyword,\n    'CONVERSION': tokens.Keyword,\n    'CONVERT': tokens.Keyword,\n    'COPY': tokens.Keyword,\n    'CORRESPONDING': tokens.Keyword,\n    'COUNT': tokens.Keyword,\n    'CREATEDB': tokens.Keyword,\n    'CREATEUSER': tokens.Keyword,\n    'CROSS': tokens.Keyword,\n    'CUBE': tokens.Keyword,\n    'CURRENT': tokens.Keyword,\n    'CURRENT_DATE': tokens.Keyword,\n    'CURRENT_PATH': tokens.Keyword,\n    'CURRENT_ROLE': tokens.Keyword,\n    'CURRENT_TIME': tokens.Keyword,\n    'CURRENT_TIMESTAMP': tokens.Keyword,\n    'CURRENT_USER': tokens.Keyword,\n    'CURSOR': tokens.Keyword,\n    'CURSOR_NAME': tokens.Keyword,\n    'CYCLE': tokens.Keyword,\n\n    'DATA': tokens.Keyword,\n    'DATABASE': tokens.Keyword,\n    'DATETIME_INTERVAL_CODE': tokens.Keyword,\n    'DATETIME_INTERVAL_PRECISION': tokens.Keyword,\n    'DAY': tokens.Keyword,\n    'DEALLOCATE': tokens.Keyword,\n    'DECLARE': tokens.Keyword,\n    'DEFAULT': tokens.Keyword,\n    'DEFAULTS': tokens.Keyword,\n    'DEFERRABLE': tokens.Keyword,\n    'DEFERRED': tokens.Keyword,\n    'DEFINED': tokens.Keyword,\n    'DEFINER': tokens.Keyword,\n    'DELIMITER': tokens.Keyword,\n    'DELIMITERS': tokens.Keyword,\n    'DEREF': tokens.Keyword,\n    'DESC': tokens.Keyword.Order,\n    'DESCRIBE': tokens.Keyword,\n    'DESCRIPTOR': tokens.Keyword,\n    'DESTROY': tokens.Keyword,\n    'DESTRUCTOR': tokens.Keyword,\n    'DETERMINISTIC': tokens.Keyword,\n    'DIAGNOSTICS': tokens.Keyword,\n    'DICTIONARY': tokens.Keyword,\n    'DISABLE': tokens.Keyword,\n    'DISCONNECT': tokens.Keyword,\n    'DISPATCH': tokens.Keyword,\n    'DIV': tokens.Operator,\n    'DO': tokens.Keyword,\n    'DOMAIN': tokens.Keyword,\n    'DYNAMIC': tokens.Keyword,\n    'DYNAMIC_FUNCTION': tokens.Keyword,\n    'DYNAMIC_FUNCTION_CODE': tokens.Keyword,\n\n    'EACH': tokens.Keyword,\n    'ENABLE': tokens.Keyword,\n    'ENCODING': tokens.Keyword,\n    'ENCRYPTED': tokens.Keyword,\n    'END-EXEC': tokens.Keyword,\n    'ENGINE': tokens.Keyword,\n    'EQUALS': tokens.Keyword,\n    'ESCAPE': tokens.Keyword,\n    'EVERY': tokens.Keyword,\n    'EXCEPT': tokens.Keyword,\n    'EXCEPTION': tokens.Keyword,\n    'EXCLUDING': tokens.Keyword,\n    'EXCLUSIVE': tokens.Keyword,\n    'EXEC': tokens.Keyword,\n    'EXECUTE': tokens.Keyword,\n    'EXISTING': tokens.Keyword,\n    'EXISTS': tokens.Keyword,\n    'EXPLAIN': tokens.Keyword,\n    'EXTERNAL': tokens.Keyword,\n    'EXTRACT': tokens.Keyword,\n\n    'FALSE': tokens.Keyword,\n    'FETCH': tokens.Keyword,\n    'FILE': tokens.Keyword,\n    'FINAL': tokens.Keyword,\n    'FIRST': tokens.Keyword,\n    'FORCE': tokens.Keyword,\n    'FOREACH': tokens.Keyword,\n    'FOREIGN': tokens.Keyword,\n    'FORTRAN': tokens.Keyword,\n    'FORWARD': tokens.Keyword,\n    'FOUND': tokens.Keyword,\n    'FREE': tokens.Keyword,\n    'FREEZE': tokens.Keyword,\n    'FULL': tokens.Keyword,\n    'FUNCTION': tokens.Keyword,\n\n    # 'G': tokens.Keyword,\n    'GENERAL': tokens.Keyword,\n    'GENERATED': tokens.Keyword,\n    'GET': tokens.Keyword,\n    'GLOBAL': tokens.Keyword,\n    'GO': tokens.Keyword,\n    'GOTO': tokens.Keyword,\n    'GRANT': tokens.Keyword,\n    'GRANTED': tokens.Keyword,\n    'GROUPING': tokens.Keyword,\n\n    'HAVING': tokens.Keyword,\n    'HIERARCHY': tokens.Keyword,\n    'HOLD': tokens.Keyword,\n    'HOUR': tokens.Keyword,\n    'HOST': tokens.Keyword,\n\n    'IDENTIFIED': tokens.Keyword,\n    'IDENTITY': tokens.Keyword,\n    'IGNORE': tokens.Keyword,\n    'ILIKE': tokens.Keyword,\n    'IMMEDIATE': tokens.Keyword,\n    'IMMUTABLE': tokens.Keyword,\n\n    'IMPLEMENTATION': tokens.Keyword,\n    'IMPLICIT': tokens.Keyword,\n    'INCLUDING': tokens.Keyword,\n    'INCREMENT': tokens.Keyword,\n    'INDEX': tokens.Keyword,\n\n    'INDICATOR': tokens.Keyword,\n    'INFIX': tokens.Keyword,\n    'INHERITS': tokens.Keyword,\n    'INITIAL': tokens.Keyword,\n    'INITIALIZE': tokens.Keyword,\n    'INITIALLY': tokens.Keyword,\n    'INOUT': tokens.Keyword,\n    'INPUT': tokens.Keyword,\n    'INSENSITIVE': tokens.Keyword,\n    'INSTANTIABLE': tokens.Keyword,\n    'INSTEAD': tokens.Keyword,\n    'INTERSECT': tokens.Keyword,\n    'INTO': tokens.Keyword,\n    'INVOKER': tokens.Keyword,\n    'IS': tokens.Keyword,\n    'ISNULL': tokens.Keyword,\n    'ISOLATION': tokens.Keyword,\n    'ITERATE': tokens.Keyword,\n\n    # 'K': tokens.Keyword,\n    'KEY': tokens.Keyword,\n    'KEY_MEMBER': tokens.Keyword,\n    'KEY_TYPE': tokens.Keyword,\n\n    'LANCOMPILER': tokens.Keyword,\n    'LANGUAGE': tokens.Keyword,\n    'LARGE': tokens.Keyword,\n    'LAST': tokens.Keyword,\n    'LATERAL': tokens.Keyword,\n    'LEADING': tokens.Keyword,\n    'LENGTH': tokens.Keyword,\n    'LESS': tokens.Keyword,\n    'LEVEL': tokens.Keyword,\n    'LIMIT': tokens.Keyword,\n    'LISTEN': tokens.Keyword,\n    'LOAD': tokens.Keyword,\n    'LOCAL': tokens.Keyword,\n    'LOCALTIME': tokens.Keyword,\n    'LOCALTIMESTAMP': tokens.Keyword,\n    'LOCATION': tokens.Keyword,\n    'LOCATOR': tokens.Keyword,\n    'LOCK': tokens.Keyword,\n    'LOWER': tokens.Keyword,\n\n    # 'M': tokens.Keyword,\n    'MAP': tokens.Keyword,\n    'MATCH': tokens.Keyword,\n    'MAXEXTENTS': tokens.Keyword,\n    'MAXVALUE': tokens.Keyword,\n    'MESSAGE_LENGTH': tokens.Keyword,\n    'MESSAGE_OCTET_LENGTH': tokens.Keyword,\n    'MESSAGE_TEXT': tokens.Keyword,\n    'METHOD': tokens.Keyword,\n    'MINUTE': tokens.Keyword,\n    'MINUS': tokens.Keyword,\n    'MINVALUE': tokens.Keyword,\n    'MOD': tokens.Keyword,\n    'MODE': tokens.Keyword,\n    'MODIFIES': tokens.Keyword,\n    'MODIFY': tokens.Keyword,\n    'MONTH': tokens.Keyword,\n    'MORE': tokens.Keyword,\n    'MOVE': tokens.Keyword,\n    'MUMPS': tokens.Keyword,\n\n    'NAMES': tokens.Keyword,\n    'NATIONAL': tokens.Keyword,\n    'NATURAL': tokens.Keyword,\n    'NCHAR': tokens.Keyword,\n    'NCLOB': tokens.Keyword,\n    'NEW': tokens.Keyword,\n    'NEXT': tokens.Keyword,\n    'NO': tokens.Keyword,\n    'NOAUDIT': tokens.Keyword,\n    'NOCOMPRESS': tokens.Keyword,\n    'NOCREATEDB': tokens.Keyword,\n    'NOCREATEUSER': tokens.Keyword,\n    'NONE': tokens.Keyword,\n    'NOT': tokens.Keyword,\n    'NOTFOUND': tokens.Keyword,\n    'NOTHING': tokens.Keyword,\n    'NOTIFY': tokens.Keyword,\n    'NOTNULL': tokens.Keyword,\n    'NOWAIT': tokens.Keyword,\n    'NULL': tokens.Keyword,\n    'NULLABLE': tokens.Keyword,\n    'NULLIF': tokens.Keyword,\n\n    'OBJECT': tokens.Keyword,\n    'OCTET_LENGTH': tokens.Keyword,\n    'OF': tokens.Keyword,\n    'OFF': tokens.Keyword,\n    'OFFLINE': tokens.Keyword,\n    'OFFSET': tokens.Keyword,\n    'OIDS': tokens.Keyword,\n    'OLD': tokens.Keyword,\n    'ONLINE': tokens.Keyword,\n    'ONLY': tokens.Keyword,\n    'OPEN': tokens.Keyword,\n    'OPERATION': tokens.Keyword,\n    'OPERATOR': tokens.Keyword,\n    'OPTION': tokens.Keyword,\n    'OPTIONS': tokens.Keyword,\n    'ORDINALITY': tokens.Keyword,\n    'OUT': tokens.Keyword,\n    'OUTPUT': tokens.Keyword,\n    'OVERLAPS': tokens.Keyword,\n    'OVERLAY': tokens.Keyword,\n    'OVERRIDING': tokens.Keyword,\n    'OWNER': tokens.Keyword,\n\n    'QUARTER': tokens.Keyword,\n\n    'PAD': tokens.Keyword,\n    'PARAMETER': tokens.Keyword,\n    'PARAMETERS': tokens.Keyword,\n    'PARAMETER_MODE': tokens.Keyword,\n    'PARAMETER_NAME': tokens.Keyword,\n    'PARAMETER_ORDINAL_POSITION': tokens.Keyword,\n    'PARAMETER_SPECIFIC_CATALOG': tokens.Keyword,\n    'PARAMETER_SPECIFIC_NAME': tokens.Keyword,\n    'PARAMETER_SPECIFIC_SCHEMA': tokens.Keyword,\n    'PARTIAL': tokens.Keyword,\n    'PASCAL': tokens.Keyword,\n    'PCTFREE': tokens.Keyword,\n    'PENDANT': tokens.Keyword,\n    'PLACING': tokens.Keyword,\n    'PLI': tokens.Keyword,\n    'POSITION': tokens.Keyword,\n    'POSTFIX': tokens.Keyword,\n    'PRECISION': tokens.Keyword,\n    'PREFIX': tokens.Keyword,\n    'PREORDER': tokens.Keyword,\n    'PREPARE': tokens.Keyword,\n    'PRESERVE': tokens.Keyword,\n    'PRIMARY': tokens.Keyword,\n    'PRIOR': tokens.Keyword,\n    'PRIVILEGES': tokens.Keyword,\n    'PROCEDURAL': tokens.Keyword,\n    'PROCEDURE': tokens.Keyword,\n    'PUBLIC': tokens.Keyword,\n\n    'RAISE': tokens.Keyword,\n    'RAW': tokens.Keyword,\n    'READ': tokens.Keyword,\n    'READS': tokens.Keyword,\n    'RECHECK': tokens.Keyword,\n    'RECURSIVE': tokens.Keyword,\n    'REF': tokens.Keyword,\n    'REFERENCES': tokens.Keyword,\n    'REFERENCING': tokens.Keyword,\n    'REINDEX': tokens.Keyword,\n    'RELATIVE': tokens.Keyword,\n    'RENAME': tokens.Keyword,\n    'REPEATABLE': tokens.Keyword,\n    'RESET': tokens.Keyword,\n    'RESOURCE': tokens.Keyword,\n    'RESTART': tokens.Keyword,\n    'RESTRICT': tokens.Keyword,\n    'RESULT': tokens.Keyword,\n    'RETURN': tokens.Keyword,\n    'RETURNED_LENGTH': tokens.Keyword,\n    'RETURNED_OCTET_LENGTH': tokens.Keyword,\n    'RETURNED_SQLSTATE': tokens.Keyword,\n    'RETURNING': tokens.Keyword,\n    'RETURNS': tokens.Keyword,\n    'REVOKE': tokens.Keyword,\n    'RIGHT': tokens.Keyword,\n    'ROLE': tokens.Keyword,\n    'ROLLBACK': tokens.Keyword.DML,\n    'ROLLUP': tokens.Keyword,\n    'ROUTINE': tokens.Keyword,\n    'ROUTINE_CATALOG': tokens.Keyword,\n    'ROUTINE_NAME': tokens.Keyword,\n    'ROUTINE_SCHEMA': tokens.Keyword,\n    'ROW': tokens.Keyword,\n    'ROWS': tokens.Keyword,\n    'ROW_COUNT': tokens.Keyword,\n    'RULE': tokens.Keyword,\n\n    'SAVE_POINT': tokens.Keyword,\n    'SCALE': tokens.Keyword,\n    'SCHEMA': tokens.Keyword,\n    'SCHEMA_NAME': tokens.Keyword,\n    'SCOPE': tokens.Keyword,\n    'SCROLL': tokens.Keyword,\n    'SEARCH': tokens.Keyword,\n    'SECOND': tokens.Keyword,\n    'SECURITY': tokens.Keyword,\n    'SELF': tokens.Keyword,\n    'SENSITIVE': tokens.Keyword,\n    'SEQUENCE': tokens.Keyword,\n    'SERIALIZABLE': tokens.Keyword,\n    'SERVER_NAME': tokens.Keyword,\n    'SESSION': tokens.Keyword,\n    'SESSION_USER': tokens.Keyword,\n    'SETOF': tokens.Keyword,\n    'SETS': tokens.Keyword,\n    'SHARE': tokens.Keyword,\n    'SHOW': tokens.Keyword,\n    'SIMILAR': tokens.Keyword,\n    'SIMPLE': tokens.Keyword,\n    'SIZE': tokens.Keyword,\n    'SOME': tokens.Keyword,\n    'SOURCE': tokens.Keyword,\n    'SPACE': tokens.Keyword,\n    'SPECIFIC': tokens.Keyword,\n    'SPECIFICTYPE': tokens.Keyword,\n    'SPECIFIC_NAME': tokens.Keyword,\n    'SQL': tokens.Keyword,\n    'SQLBUF': tokens.Keyword,\n    'SQLCODE': tokens.Keyword,\n    'SQLERROR': tokens.Keyword,\n    'SQLEXCEPTION': tokens.Keyword,\n    'SQLSTATE': tokens.Keyword,\n    'SQLWARNING': tokens.Keyword,\n    'STABLE': tokens.Keyword,\n    'START': tokens.Keyword.DML,\n    # 'STATE': tokens.Keyword,\n    'STATEMENT': tokens.Keyword,\n    'STATIC': tokens.Keyword,\n    'STATISTICS': tokens.Keyword,\n    'STDIN': tokens.Keyword,\n    'STDOUT': tokens.Keyword,\n    'STORAGE': tokens.Keyword,\n    'STRICT': tokens.Keyword,\n    'STRUCTURE': tokens.Keyword,\n    'STYPE': tokens.Keyword,\n    'SUBCLASS_ORIGIN': tokens.Keyword,\n    'SUBLIST': tokens.Keyword,\n    'SUBSTRING': tokens.Keyword,\n    'SUCCESSFUL': tokens.Keyword,\n    'SUM': tokens.Keyword,\n    'SYMMETRIC': tokens.Keyword,\n    'SYNONYM': tokens.Keyword,\n    'SYSID': tokens.Keyword,\n    'SYSTEM': tokens.Keyword,\n    'SYSTEM_USER': tokens.Keyword,\n\n    'TABLE': tokens.Keyword,\n    'TABLE_NAME': tokens.Keyword,\n    'TEMP': tokens.Keyword,\n    'TEMPLATE': tokens.Keyword,\n    'TEMPORARY': tokens.Keyword,\n    'TERMINATE': tokens.Keyword,\n    'THAN': tokens.Keyword,\n    'TIMESTAMP': tokens.Keyword,\n    'TIMEZONE_HOUR': tokens.Keyword,\n    'TIMEZONE_MINUTE': tokens.Keyword,\n    'TO': tokens.Keyword,\n    'TOAST': tokens.Keyword,\n    'TRAILING': tokens.Keyword,\n    'TRANSATION': tokens.Keyword,\n    'TRANSACTIONS_COMMITTED': tokens.Keyword,\n    'TRANSACTIONS_ROLLED_BACK': tokens.Keyword,\n    'TRANSATION_ACTIVE': tokens.Keyword,\n    'TRANSFORM': tokens.Keyword,\n    'TRANSFORMS': tokens.Keyword,\n    'TRANSLATE': tokens.Keyword,\n    'TRANSLATION': tokens.Keyword,\n    'TREAT': tokens.Keyword,\n    'TRIGGER': tokens.Keyword,\n    'TRIGGER_CATALOG': tokens.Keyword,\n    'TRIGGER_NAME': tokens.Keyword,\n    'TRIGGER_SCHEMA': tokens.Keyword,\n    'TRIM': tokens.Keyword,\n    'TRUE': tokens.Keyword,\n    'TRUNCATE': tokens.Keyword,\n    'TRUSTED': tokens.Keyword,\n    'TYPE': tokens.Keyword,\n\n    'UID': tokens.Keyword,\n    'UNCOMMITTED': tokens.Keyword,\n    'UNDER': tokens.Keyword,\n    'UNENCRYPTED': tokens.Keyword,\n    'UNION': tokens.Keyword,\n    'UNIQUE': tokens.Keyword,\n    'UNKNOWN': tokens.Keyword,\n    'UNLISTEN': tokens.Keyword,\n    'UNNAMED': tokens.Keyword,\n    'UNNEST': tokens.Keyword,\n    'UNTIL': tokens.Keyword,\n    'UPPER': tokens.Keyword,\n    'USAGE': tokens.Keyword,\n    'USE': tokens.Keyword,\n    'USER': tokens.Keyword,\n    'USER_DEFINED_TYPE_CATALOG': tokens.Keyword,\n    'USER_DEFINED_TYPE_NAME': tokens.Keyword,\n    'USER_DEFINED_TYPE_SCHEMA': tokens.Keyword,\n    'USING': tokens.Keyword,\n\n    'VACUUM': tokens.Keyword,\n    'VALID': tokens.Keyword,\n    'VALIDATE': tokens.Keyword,\n    'VALIDATOR': tokens.Keyword,\n    'VALUES': tokens.Keyword,\n    'VARIABLE': tokens.Keyword,\n    'VERBOSE': tokens.Keyword,\n    'VERSION': tokens.Keyword,\n    'VIEW': tokens.Keyword,\n    'VOLATILE': tokens.Keyword,\n\n    'WEEK': tokens.Keyword,\n    'WHENEVER': tokens.Keyword,\n    'WITH': tokens.Keyword.CTE,\n    'WITHOUT': tokens.Keyword,\n    'WORK': tokens.Keyword,\n    'WRITE': tokens.Keyword,\n\n    'YEAR': tokens.Keyword,\n\n    'ZONE': tokens.Keyword,\n\n    # Name.Builtin\n    'ARRAY': tokens.Name.Builtin,\n    'BIGINT': tokens.Name.Builtin,\n    'BINARY': tokens.Name.Builtin,\n    'BIT': tokens.Name.Builtin,\n    'BLOB': tokens.Name.Builtin,\n    'BOOLEAN': tokens.Name.Builtin,\n    'CHAR': tokens.Name.Builtin,\n    'CHARACTER': tokens.Name.Builtin,\n    'DATE': tokens.Name.Builtin,\n    'DEC': tokens.Name.Builtin,\n    'DECIMAL': tokens.Name.Builtin,\n    'FILE_TYPE': tokens.Name.Builtin,\n    'FLOAT': tokens.Name.Builtin,\n    'INT': tokens.Name.Builtin,\n    'INT8': tokens.Name.Builtin,\n    'INTEGER': tokens.Name.Builtin,\n    'INTERVAL': tokens.Name.Builtin,\n    'LONG': tokens.Name.Builtin,\n    'NATURALN': tokens.Name.Builtin,\n    'NVARCHAR': tokens.Name.Builtin,\n    'NUMBER': tokens.Name.Builtin,\n    'NUMERIC': tokens.Name.Builtin,\n    'PLS_INTEGER': tokens.Name.Builtin,\n    'POSITIVE': tokens.Name.Builtin,\n    'POSITIVEN': tokens.Name.Builtin,\n    'REAL': tokens.Name.Builtin,\n    'ROWID': tokens.Name.Builtin,\n    'ROWLABEL': tokens.Name.Builtin,\n    'ROWNUM': tokens.Name.Builtin,\n    'SERIAL': tokens.Name.Builtin,\n    'SERIAL8': tokens.Name.Builtin,\n    'SIGNED': tokens.Name.Builtin,\n    'SIGNTYPE': tokens.Name.Builtin,\n    'SIMPLE_DOUBLE': tokens.Name.Builtin,\n    'SIMPLE_FLOAT': tokens.Name.Builtin,\n    'SIMPLE_INTEGER': tokens.Name.Builtin,\n    'SMALLINT': tokens.Name.Builtin,\n    'SYS_REFCURSOR': tokens.Name.Builtin,\n    'SYSDATE': tokens.Name,\n    'TEXT': tokens.Name.Builtin,\n    'TINYINT': tokens.Name.Builtin,\n    'UNSIGNED': tokens.Name.Builtin,\n    'UROWID': tokens.Name.Builtin,\n    'UTL_FILE': tokens.Name.Builtin,\n    'VARCHAR': tokens.Name.Builtin,\n    'VARCHAR2': tokens.Name.Builtin,\n    'VARYING': tokens.Name.Builtin,\n}\n\nKEYWORDS_COMMON = {\n    'SELECT': tokens.Keyword.DML,\n    'INSERT': tokens.Keyword.DML,\n    'DELETE': tokens.Keyword.DML,\n    'UPDATE': tokens.Keyword.DML,\n    'UPSERT': tokens.Keyword.DML,\n    'REPLACE': tokens.Keyword.DML,\n    'MERGE': tokens.Keyword.DML,\n    'DROP': tokens.Keyword.DDL,\n    'CREATE': tokens.Keyword.DDL,\n    'ALTER': tokens.Keyword.DDL,\n\n    'WHERE': tokens.Keyword,\n    'FROM': tokens.Keyword,\n    'INNER': tokens.Keyword,\n    'JOIN': tokens.Keyword,\n    'STRAIGHT_JOIN': tokens.Keyword,\n    'AND': tokens.Keyword,\n    'OR': tokens.Keyword,\n    'LIKE': tokens.Keyword,\n    'ON': tokens.Keyword,\n    'IN': tokens.Keyword,\n    'SET': tokens.Keyword,\n\n    'BY': tokens.Keyword,\n    'GROUP': tokens.Keyword,\n    'ORDER': tokens.Keyword,\n    'LEFT': tokens.Keyword,\n    'OUTER': tokens.Keyword,\n    'FULL': tokens.Keyword,\n\n    'IF': tokens.Keyword,\n    'END': tokens.Keyword,\n    'THEN': tokens.Keyword,\n    'LOOP': tokens.Keyword,\n    'AS': tokens.Keyword,\n    'ELSE': tokens.Keyword,\n    'FOR': tokens.Keyword,\n    'WHILE': tokens.Keyword,\n\n    'CASE': tokens.Keyword,\n    'WHEN': tokens.Keyword,\n    'MIN': tokens.Keyword,\n    'MAX': tokens.Keyword,\n    'DISTINCT': tokens.Keyword,\n}\n\nKEYWORDS_ORACLE = {\n    'ARCHIVE': tokens.Keyword,\n    'ARCHIVELOG': tokens.Keyword,\n\n    'BACKUP': tokens.Keyword,\n    'BECOME': tokens.Keyword,\n    'BLOCK': tokens.Keyword,\n    'BODY': tokens.Keyword,\n\n    'CANCEL': tokens.Keyword,\n    'CHANGE': tokens.Keyword,\n    'COMPILE': tokens.Keyword,\n    'CONTENTS': tokens.Keyword,\n    'CONTROLFILE': tokens.Keyword,\n\n    'DATAFILE': tokens.Keyword,\n    'DBA': tokens.Keyword,\n    'DISMOUNT': tokens.Keyword,\n    'DOUBLE': tokens.Keyword,\n    'DUMP': tokens.Keyword,\n\n    'ELSIF': tokens.Keyword,\n    'EVENTS': tokens.Keyword,\n    'EXCEPTIONS': tokens.Keyword,\n    'EXPLAIN': tokens.Keyword,\n    'EXTENT': tokens.Keyword,\n    'EXTERNALLY': tokens.Keyword,\n\n    'FLUSH': tokens.Keyword,\n    'FREELIST': tokens.Keyword,\n    'FREELISTS': tokens.Keyword,\n\n    # groups seems too common as table name\n    # 'GROUPS': tokens.Keyword,\n\n    'INDICATOR': tokens.Keyword,\n    'INITRANS': tokens.Keyword,\n    'INSTANCE': tokens.Keyword,\n\n    'LAYER': tokens.Keyword,\n    'LINK': tokens.Keyword,\n    'LISTS': tokens.Keyword,\n    'LOGFILE': tokens.Keyword,\n\n    'MANAGE': tokens.Keyword,\n    'MANUAL': tokens.Keyword,\n    'MAXDATAFILES': tokens.Keyword,\n    'MAXINSTANCES': tokens.Keyword,\n    'MAXLOGFILES': tokens.Keyword,\n    'MAXLOGHISTORY': tokens.Keyword,\n    'MAXLOGMEMBERS': tokens.Keyword,\n    'MAXTRANS': tokens.Keyword,\n    'MINEXTENTS': tokens.Keyword,\n    'MODULE': tokens.Keyword,\n    'MOUNT': tokens.Keyword,\n\n    'NOARCHIVELOG': tokens.Keyword,\n    'NOCACHE': tokens.Keyword,\n    'NOCYCLE': tokens.Keyword,\n    'NOMAXVALUE': tokens.Keyword,\n    'NOMINVALUE': tokens.Keyword,\n    'NOORDER': tokens.Keyword,\n    'NORESETLOGS': tokens.Keyword,\n    'NORMAL': tokens.Keyword,\n    'NOSORT': tokens.Keyword,\n\n    'OPTIMAL': tokens.Keyword,\n    'OWN': tokens.Keyword,\n\n    'PACKAGE': tokens.Keyword,\n    'PARALLEL': tokens.Keyword,\n    'PCTINCREASE': tokens.Keyword,\n    'PCTUSED': tokens.Keyword,\n    'PLAN': tokens.Keyword,\n    'PRIVATE': tokens.Keyword,\n    'PROFILE': tokens.Keyword,\n\n    'QUOTA': tokens.Keyword,\n\n    'RECOVER': tokens.Keyword,\n    'RESETLOGS': tokens.Keyword,\n    'RESTRICTED': tokens.Keyword,\n    'REUSE': tokens.Keyword,\n    'ROLES': tokens.Keyword,\n\n    'SAVEPOINT': tokens.Keyword,\n    'SCN': tokens.Keyword,\n    'SECTION': tokens.Keyword,\n    'SEGMENT': tokens.Keyword,\n    'SHARED': tokens.Keyword,\n    'SNAPSHOT': tokens.Keyword,\n    'SORT': tokens.Keyword,\n    'STATEMENT_ID': tokens.Keyword,\n    'STOP': tokens.Keyword,\n    'SWITCH': tokens.Keyword,\n\n    'TABLES': tokens.Keyword,\n    'TABLESPACE': tokens.Keyword,\n    'THREAD': tokens.Keyword,\n    'TIME': tokens.Keyword,\n    'TRACING': tokens.Keyword,\n    'TRANSACTION': tokens.Keyword,\n    'TRIGGERS': tokens.Keyword,\n\n    'UNLIMITED': tokens.Keyword,\n    'UNLOCK': tokens.Keyword,\n}\n\n# PostgreSQL Syntax\nKEYWORDS_PLPGSQL = {\n    'CONFLICT': tokens.Keyword,\n    'WINDOW': tokens.Keyword,\n    'PARTITION': tokens.Keyword,\n    'OVER': tokens.Keyword,\n    'PERFORM': tokens.Keyword,\n    'NOTICE': tokens.Keyword,\n    'PLPGSQL': tokens.Keyword,\n    'INHERIT': tokens.Keyword,\n    'INDEXES': tokens.Keyword,\n    'ON_ERROR_STOP': tokens.Keyword,\n\n    'BYTEA': tokens.Keyword,\n    'BIGSERIAL': tokens.Keyword,\n    'BIT VARYING': tokens.Keyword,\n    'BOX': tokens.Keyword,\n    'CHARACTER': tokens.Keyword,\n    'CHARACTER VARYING': tokens.Keyword,\n    'CIDR': tokens.Keyword,\n    'CIRCLE': tokens.Keyword,\n    'DOUBLE PRECISION': tokens.Keyword,\n    'INET': tokens.Keyword,\n    'JSON': tokens.Keyword,\n    'JSONB': tokens.Keyword,\n    'LINE': tokens.Keyword,\n    'LSEG': tokens.Keyword,\n    'MACADDR': tokens.Keyword,\n    'MONEY': tokens.Keyword,\n    'PATH': tokens.Keyword,\n    'PG_LSN': tokens.Keyword,\n    'POINT': tokens.Keyword,\n    'POLYGON': tokens.Keyword,\n    'SMALLSERIAL': tokens.Keyword,\n    'TSQUERY': tokens.Keyword,\n    'TSVECTOR': tokens.Keyword,\n    'TXID_SNAPSHOT': tokens.Keyword,\n    'UUID': tokens.Keyword,\n    'XML': tokens.Keyword,\n\n    'FOR': tokens.Keyword,\n    'IN': tokens.Keyword,\n    'LOOP': tokens.Keyword,\n}\n\n# Hive Syntax\nKEYWORDS_HQL = {\n    'EXPLODE': tokens.Keyword,\n    'DIRECTORY': tokens.Keyword,\n    'DISTRIBUTE': tokens.Keyword,\n    'INCLUDE': tokens.Keyword,\n    'LOCATE': tokens.Keyword,\n    'OVERWRITE': tokens.Keyword,\n    'POSEXPLODE': tokens.Keyword,\n\n    'ARRAY_CONTAINS': tokens.Keyword,\n    'CMP': tokens.Keyword,\n    'COLLECT_LIST': tokens.Keyword,\n    'CONCAT': tokens.Keyword,\n    'CONDITION': tokens.Keyword,\n    'DATE_ADD': tokens.Keyword,\n    'DATE_SUB': tokens.Keyword,\n    'DECODE': tokens.Keyword,\n    'DBMS_OUTPUT': tokens.Keyword,\n    'ELEMENTS': tokens.Keyword,\n    'EXCHANGE': tokens.Keyword,\n    'EXTENDED': tokens.Keyword,\n    'FLOOR': tokens.Keyword,\n    'FOLLOWING': tokens.Keyword,\n    'FROM_UNIXTIME': tokens.Keyword,\n    'FTP': tokens.Keyword,\n    'HOUR': tokens.Keyword,\n    'INLINE': tokens.Keyword,\n    'INSTR': tokens.Keyword,\n    'LEN': tokens.Keyword,\n    'MAP': tokens.Name.Builtin,\n    'MAXELEMENT': tokens.Keyword,\n    'MAXINDEX': tokens.Keyword,\n    'MAX_PART_DATE': tokens.Keyword,\n    'MAX_PART_INT': tokens.Keyword,\n    'MAX_PART_STRING': tokens.Keyword,\n    'MINELEMENT': tokens.Keyword,\n    'MININDEX': tokens.Keyword,\n    'MIN_PART_DATE': tokens.Keyword,\n    'MIN_PART_INT': tokens.Keyword,\n    'MIN_PART_STRING': tokens.Keyword,\n    'NOW': tokens.Keyword,\n    'NVL': tokens.Keyword,\n    'NVL2': tokens.Keyword,\n    'PARSE_URL_TUPLE': tokens.Keyword,\n    'PART_LOC': tokens.Keyword,\n    'PART_COUNT': tokens.Keyword,\n    'PART_COUNT_BY': tokens.Keyword,\n    'PRINT': tokens.Keyword,\n    'PUT_LINE': tokens.Keyword,\n    'RANGE': tokens.Keyword,\n    'REDUCE': tokens.Keyword,\n    'REGEXP_REPLACE': tokens.Keyword,\n    'RESIGNAL': tokens.Keyword,\n    'RTRIM': tokens.Keyword,\n    'SIGN': tokens.Keyword,\n    'SIGNAL': tokens.Keyword,\n    'SIN': tokens.Keyword,\n    'SPLIT': tokens.Keyword,\n    'SQRT': tokens.Keyword,\n    'STACK': tokens.Keyword,\n    'STR': tokens.Keyword,\n    'STRING': tokens.Name.Builtin,\n    'STRUCT': tokens.Name.Builtin,\n    'SUBSTR': tokens.Keyword,\n    'SUMMARY': tokens.Keyword,\n    'TBLPROPERTIES': tokens.Keyword,\n    'TIMESTAMP': tokens.Name.Builtin,\n    'TIMESTAMP_ISO': tokens.Keyword,\n    'TO_CHAR': tokens.Keyword,\n    'TO_DATE': tokens.Keyword,\n    'TO_TIMESTAMP': tokens.Keyword,\n    'TRUNC': tokens.Keyword,\n    'UNBOUNDED': tokens.Keyword,\n    'UNIQUEJOIN': tokens.Keyword,\n    'UNIX_TIMESTAMP': tokens.Keyword,\n    'UTC_TIMESTAMP': tokens.Keyword,\n    'VIEWS': tokens.Keyword,\n\n    'EXIT': tokens.Keyword,\n    'BREAK': tokens.Keyword,\n    'LEAVE': tokens.Keyword,\n}\n\n\nKEYWORDS_MSACCESS = {\n    'DISTINCTROW': tokens.Keyword,\n}\n", "# Tests splitting functions.\n\nimport types\nfrom io import StringIO\n\nimport pytest\n\nimport sqlparse\n\n\ndef test_split_semicolon():\n    sql1 = 'select * from foo;'\n    sql2 = \"select * from foo where bar = 'foo;bar';\"\n    stmts = sqlparse.parse(''.join([sql1, sql2]))\n    assert len(stmts) == 2\n    assert str(stmts[0]) == sql1\n    assert str(stmts[1]) == sql2\n\n\ndef test_split_backslash():\n    stmts = sqlparse.parse(r\"select '\\\\'; select '\\''; select '\\\\\\'';\")\n    assert len(stmts) == 3\n\n\n@pytest.mark.parametrize('fn', ['function.sql',\n                                'function_psql.sql',\n                                'function_psql2.sql',\n                                'function_psql3.sql',\n                                'function_psql4.sql'])\ndef test_split_create_function(load_file, fn):\n    sql = load_file(fn)\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 1\n    assert str(stmts[0]) == sql\n\n\ndef test_split_dashcomments(load_file):\n    sql = load_file('dashcomment.sql')\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 3\n    assert ''.join(str(q) for q in stmts) == sql\n\n\n@pytest.mark.parametrize('s', ['select foo; -- comment\\n',\n                               'select foo; -- comment\\r',\n                               'select foo; -- comment\\r\\n',\n                               'select foo; -- comment'])\ndef test_split_dashcomments_eol(s):\n    stmts = sqlparse.parse(s)\n    assert len(stmts) == 1\n\n\ndef test_split_begintag(load_file):\n    sql = load_file('begintag.sql')\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 3\n    assert ''.join(str(q) for q in stmts) == sql\n\n\ndef test_split_begintag_2(load_file):\n    sql = load_file('begintag_2.sql')\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 1\n    assert ''.join(str(q) for q in stmts) == sql\n\n\ndef test_split_dropif():\n    sql = 'DROP TABLE IF EXISTS FOO;\\n\\nSELECT * FROM BAR;'\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 2\n    assert ''.join(str(q) for q in stmts) == sql\n\n\ndef test_split_comment_with_umlaut():\n    sql = ('select * from foo;\\n'\n           '-- Testing an umlaut: \u00e4\\n'\n           'select * from bar;')\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 2\n    assert ''.join(str(q) for q in stmts) == sql\n\n\ndef test_split_comment_end_of_line():\n    sql = ('select * from foo; -- foo\\n'\n           'select * from bar;')\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 2\n    assert ''.join(str(q) for q in stmts) == sql\n    # make sure the comment belongs to first query\n    assert str(stmts[0]) == 'select * from foo; -- foo\\n'\n\n\ndef test_split_casewhen():\n    sql = (\"SELECT case when val = 1 then 2 else null end as foo;\\n\"\n           \"comment on table actor is 'The actor table.';\")\n    stmts = sqlparse.split(sql)\n    assert len(stmts) == 2\n\n\ndef test_split_casewhen_procedure(load_file):\n    # see issue580\n    stmts = sqlparse.split(load_file('casewhen_procedure.sql'))\n    assert len(stmts) == 2\n\n\ndef test_split_cursor_declare():\n    sql = ('DECLARE CURSOR \"foo\" AS SELECT 1;\\n'\n           'SELECT 2;')\n    stmts = sqlparse.split(sql)\n    assert len(stmts) == 2\n\n\ndef test_split_if_function():  # see issue 33\n    # don't let IF as a function confuse the splitter\n    sql = ('CREATE TEMPORARY TABLE tmp '\n           'SELECT IF(a=1, a, b) AS o FROM one; '\n           'SELECT t FROM two')\n    stmts = sqlparse.split(sql)\n    assert len(stmts) == 2\n\n\ndef test_split_stream():\n    stream = StringIO(\"SELECT 1; SELECT 2;\")\n    stmts = sqlparse.parsestream(stream)\n    assert isinstance(stmts, types.GeneratorType)\n    assert len(list(stmts)) == 2\n\n\ndef test_split_encoding_parsestream():\n    stream = StringIO(\"SELECT 1; SELECT 2;\")\n    stmts = list(sqlparse.parsestream(stream))\n    assert isinstance(stmts[0].tokens[0].value, str)\n\n\ndef test_split_unicode_parsestream():\n    stream = StringIO('SELECT \u00f6')\n    stmts = list(sqlparse.parsestream(stream))\n    assert str(stmts[0]) == 'SELECT \u00f6'\n\n\ndef test_split_simple():\n    stmts = sqlparse.split('select * from foo; select * from bar;')\n    assert len(stmts) == 2\n    assert stmts[0] == 'select * from foo;'\n    assert stmts[1] == 'select * from bar;'\n\n\ndef test_split_ignores_empty_newlines():\n    stmts = sqlparse.split('select foo;\\nselect bar;\\n')\n    assert len(stmts) == 2\n    assert stmts[0] == 'select foo;'\n    assert stmts[1] == 'select bar;'\n\n\ndef test_split_quotes_with_new_line():\n    stmts = sqlparse.split('select \"foo\\nbar\"')\n    assert len(stmts) == 1\n    assert stmts[0] == 'select \"foo\\nbar\"'\n\n    stmts = sqlparse.split(\"select 'foo\\n\\bar'\")\n    assert len(stmts) == 1\n    assert stmts[0] == \"select 'foo\\n\\bar'\"\n\n\ndef test_split_mysql_handler_for(load_file):\n    # see issue581\n    stmts = sqlparse.split(load_file('mysql_handler.sql'))\n    assert len(stmts) == 2\n"], "fixing_code": ["Development Version\n-------------------\n\nNotable Changes\n\n* IMPORTANT: This release fixes a security vulnerability in the\n  parser where a regular expression vulnerable to ReDOS (Regular\n  Expression Denial of Service) was used. See the security advisory\n  for details: https://github.com/andialbrecht/sqlparse/security/advisories/GHSA-rrm6-wvj7-cwh2\n  The vulnerability was discovered by @erik-krogh from GitHub\n  Security Lab (GHSL). Thanks for reporting!\n\nBug Fixes\n\n* Revert a change from 0.4.0 that changed IN to be a comparison (issue694).\n  The primary expectation is that IN is treated as a keyword and not as a\n  comparison operator. That also follows the definition of reserved keywords\n  for the major SQL syntax definitions.\n* Fix regular expressions for string parsing.\n\nOther\n\n* sqlparse now uses pyproject.toml instead of setup.cfg (issue685).\n\n\nRelease 0.4.3 (Sep 23, 2022)\n----------------------------\n\nEnhancements\n\n* Add support for DIV operator (pr664, by chezou).\n* Add support for additional SPARK keywords (pr643, by mrmasterplan).\n* Avoid tokens copy (pr622, by living180).\n* Add REGEXP as a comparision (pr647, by PeterSandwich).\n* Add DISTINCTROW keyword for MS Access (issue677).\n* Improve parsing of CREATE TABLE AS SELECT (pr662, by chezou).\n\nBug Fixes\n\n* Fix spelling of INDICATOR keyword (pr653, by ptld).\n* Fix formatting error in EXTRACT function (issue562, issue670, pr676, by ecederstrand).\n* Fix bad parsing of create table statements that use lower case (issue217, pr642, by mrmasterplan).\n* Handle backtick as valid quote char (issue628, pr629, by codenamelxl).\n* Allow any unicode character as valid identifier name (issue641).\n\nOther\n\n* Update github actions to test on Python 3.10 as well (pr661, by cclaus).\n\n\nRelease 0.4.2 (Sep 10, 2021)\n----------------------------\n\nNotable Changes\n\n* IMPORTANT: This release fixes a security vulnerability in the\n  strip comments filter. In this filter a regular expression that was\n  vulnerable to ReDOS (Regular Expression Denial of Service) was\n  used. See the security advisory for details: https://github.com/andialbrecht/sqlparse/security/advisories/GHSA-p5w8-wqhj-9hhf\n  The vulnerability was discovered by @erik-krogh and @yoff from\n  GitHub Security Lab (GHSL). Thanks for reporting!\n\nEnhancements\n\n* Add ELSIF as keyword (issue584).\n* Add CONFLICT and ON_ERROR_STOP keywords (pr595, by j-martin).\n\nBug Fixes\n\n* Fix parsing of backticks (issue588).\n* Fix parsing of scientific number (issue399).\n\n\nRelease 0.4.1 (Oct 08, 2020)\n----------------------------\n\nBug Fixes\n\n* Just removed a debug print statement, sorry...\n\n\nRelease 0.4.0 (Oct 07, 2020)\n----------------------------\n\nNotable Changes\n\n* Remove support for end-of-life Python 2.7 and 3.4. Python 3.5+ is now\n  required.\n* Remaining strings that only consist of whitespaces are not treated as\n  statements anymore. Code that ignored the last element from\n  sqlparse.split() should be updated accordingly since that function\n  now doesn't return an empty string as the last element in some\n  cases (issue496).\n\nEnhancements\n\n* Add WINDOW keyword (pr579 by ali-tny).\n* Add RLIKE keyword (pr582 by wjones1).\n\nBug Fixes\n\n* Improved parsing of IN(...) statements (issue566, pr567 by hurcy).\n* Preserve line breaks when removing comments (issue484).\n* Fix parsing error when using square bracket notation (issue583).\n* Fix splitting when using DECLARE ... HANDLER (issue581).\n* Fix splitting of statements using CASE ... WHEN (issue580).\n* Improve formatting of type casts in parentheses.\n* Stabilize formatting of invalid SQL statements.\n\n\nRelease 0.3.1 (Feb 29, 2020)\n----------------------------\n\nEnhancements\n\n* Add HQL keywords (pr475, by matwalk).\n* Add support for time zone casts (issue489).\n* Enhance formatting of AS keyword (issue507, by john-bodley).\n* Stabilize grouping engine when parsing invalid SQL statements.\n\nBug Fixes\n\n* Fix splitting of SQL with multiple statements inside\n  parentheses (issue485, pr486 by win39).\n* Correctly identify NULLS FIRST / NULLS LAST as keywords (issue487).\n* Fix splitting of SQL statements that contain dollar signs in\n  identifiers (issue491).\n* Remove support for parsing double slash comments introduced in\n  0.3.0 (issue456) as it had some side-effects with other dialects and\n  doesn't seem to be widely used (issue476).\n* Restrict detection of alias names to objects that actually could\n  have an alias (issue455, adopted some parts of pr509 by john-bodley).\n* Fix parsing of date/time literals (issue438, by vashek).\n* Fix initialization of TokenList (issue499, pr505 by john-bodley).\n* Fix parsing of LIKE (issue493, pr525 by dbczumar).\n* Improve parsing of identifiers (pr527 by liulk).\n\n\nRelease 0.3.0 (Mar 11, 2019)\n----------------------------\n\nNotable Changes\n\n* Remove support for Python 3.3.\n\nEnhancements\n\n* New formatting option \"--indent_after_first\" (pr345, by johshoff).\n* New formatting option \"--indent_columns\" (pr393, by digitalarbeiter).\n* Add UPSERT keyword (issue408).\n* Strip multiple whitespace within parentheses (issue473, by john-bodley).\n* Support double slash (//) comments (issue456, by theianrobertson).\n* Support for Calcite temporal keywords (pr468, by john-bodley).\n\nBug Fixes\n\n* Fix occasional IndexError (pr390, by circld, issue313).\n* Fix incorrect splitting of strings containing new lines (pr396, by fredyw).\n* Fix reindent issue for parenthesis (issue427, by fredyw).\n* Fix from( parsing issue (issue446, by fredyw)\t.\n* Fix for get_real_name() to return correct name (issue369, by fredyw).\n* Wrap function params when wrap_after is set (pr398, by soloman1124).\n* Fix parsing of \"WHEN name\" clauses (pr418, by andrew deryabin).\n* Add missing EXPLAIN keyword (issue421).\n* Fix issue with strip_comments causing a syntax error (issue425, by fredyw).\n* Fix formatting on INSERT which caused staircase effect on values (issue329,\n  by fredyw).\n* Avoid formatting of psql commands (issue469).\n\nInternal Changes\n\n* Unify handling of GROUP BY/ORDER BY (pr457, by john-bodley).\n* Remove unnecessary compat shim for bytes (pr453, by jdufresne).\n\n\nRelease 0.2.4 (Sep 27, 2017)\n----------------------------\n\nEnhancements\n\n* Add more keywords for MySQL table options (pr328, pr333, by phdru).\n* Add more PL/pgSQL keywords (pr357, by Demetrio92).\n* Improve parsing of floats (pr330, by atronah).\n\nBug Fixes\n\n* Fix parsing of MySQL table names starting with digits (issue337).\n* Fix detection of identifiers using comparisons (issue327).\n* Fix parsing of UNION ALL after WHERE (issue349).\n* Fix handling of semicolon in assignments (issue359, issue358).\n\n\n\nRelease 0.2.3 (Mar 02, 2017)\n----------------------------\n\nEnhancements\n\n* New command line option \"--encoding\" (by twang2218, pr317).\n* Support CONCURRENTLY keyword (issue322, by rowanseymour).\n\nBug Fixes\n\n* Fix some edge-cases when parsing invalid SQL statements.\n* Fix indentation of LIMIT (by romainr, issue320).\n* Fix parsing of INTO keyword (issue324).\n\nInternal Changes\n\n* Several improvements regarding encodings.\n\n\nRelease 0.2.2 (Oct 22, 2016)\n----------------------------\n\nEnhancements\n\n* Add comma_first option: When splitting list \"comma first\" notation\n  is used (issue141).\n\nBug Fixes\n\n* Fix parsing of incomplete AS (issue284, by vmuriart).\n* Fix parsing of Oracle names containing dollars (issue291).\n* Fix parsing of UNION ALL (issue294).\n* Fix grouping of identifiers containing typecasts (issue297).\n* Add Changelog to sdist again (issue302).\n\nInternal Changes\n\n* `is_whitespace` and `is_group` changed into properties\n\n\nRelease 0.2.1 (Aug 13, 2016)\n----------------------------\n\nNotable Changes\n\n* PostgreSQL: Function bodys are parsed as literal string. Previously\n  sqlparse assumed that all function bodys are parsable psql\n  strings (see issue277).\n\nBug Fixes\n\n* Fix a regression to parse streams again (issue273, reported and\n  test case by gmccreight).\n* Improve Python 2/3 compatibility when using parsestream (issue190,\n  by phdru).\n* Improve splitting of PostgreSQL functions (issue277).\n\n\nRelease 0.2.0 (Jul 20, 2016)\n----------------------------\n\nIMPORTANT: The supported Python versions have changed with this release.\nsqlparse 0.2.x supports Python 2.7 and Python >= 3.3.\n\nThanks to the many contributors for writing bug reports and working\non pull requests who made this version possible!\n\nInternal Changes\n\n* sqlparse.SQLParseError was removed from top-level module and moved to\n  sqlparse.exceptions.\n* sqlparse.sql.Token.to_unicode was removed.\n* The signature of a filter's process method has changed from\n  process(stack, stream) -> to process(stream). Stack was never used at\n  all.\n* Lots of code cleanups and modernization (thanks esp. to vmuriart!).\n* Improved grouping performance. (sjoerdjob)\n\nEnhancements\n\n* Support WHILE loops (issue215, by shenlongxing).\n* Better support for CTEs (issue217, by Andrew Tipton).\n* Recognize USING as a keyword more consistently (issue236, by koljonen).\n* Improve alignment of columns (issue207, issue235, by vmuriat).\n* Add wrap_after option for better alignment when formatting\n  lists (issue248, by Dennis Taylor).\n* Add reindent-aligned option for alternate formatting (Adam Greenhall)\n* Improved grouping of operations (issue211, by vmuriat).\n\nBug Fixes\n\n* Leading whitespaces are now removed when format() is called with\n  strip_whitespace=True (issue213, by shenlongxing).\n* Fix typo in keywords list (issue229, by cbeloni).\n* Fix parsing of functions in comparisons (issue230, by saaj).\n* Fix grouping of identifiers (issue233).\n* Fix parsing of CREATE TABLE statements (issue242, by Tenghuan).\n* Minor bug fixes (issue101).\n* Improve formatting of CASE WHEN constructs (issue164, by vmuriat).\n\n\nRelease 0.1.19 (Mar 07, 2016)\n-----------------------------\n\nBug Fixes\n\n* Fix IndexError when statement contains WITH clauses (issue205).\n\n\nRelease 0.1.18 (Oct 25, 2015)\n-----------------------------\n\nBug Fixes\n\n* Remove universal wheel support, added in 0.1.17 by mistake.\n\n\nRelease 0.1.17 (Oct 24, 2015)\n-----------------------------\n\nEnhancements\n\n* Speed up parsing of large SQL statements (pull request: issue201, fixes the\n  following issues: issue199, issue135, issue62, issue41, by Ryan Wooden).\n\nBug Fixes\n\n* Fix another splitter bug regarding DECLARE (issue194).\n\nMisc\n\n* Packages on PyPI are signed from now on.\n\n\nRelease 0.1.16 (Jul 26, 2015)\n-----------------------------\n\nBug Fixes\n\n* Fix a regression in get_alias() introduced in 0.1.15 (issue185).\n* Fix a bug in the splitter regarding DECLARE (issue193).\n* sqlformat command line tool doesn't duplicate newlines anymore (issue191).\n* Don't mix up MySQL comments starting with hash and MSSQL\n  temp tables (issue192).\n* Statement.get_type() now ignores comments at the beginning of\n  a statement (issue186).\n\n\nRelease 0.1.15 (Apr 15, 2015)\n-----------------------------\n\nBug Fixes\n\n* Fix a regression for identifiers with square bracktes\n  notation (issue153, by darikg).\n* Add missing SQL types (issue154, issue155, issue156, by jukebox).\n* Fix parsing of multi-line comments (issue172, by JacekPliszka).\n* Fix parsing of escaped backslashes (issue174, by caseyching).\n* Fix parsing of identifiers starting with underscore (issue175).\n* Fix misinterpretation of IN keyword (issue183).\n\nEnhancements\n\n* Improve formatting of HAVING statements.\n* Improve parsing of inline comments (issue163).\n* Group comments to parent object (issue128, issue160).\n* Add double precision builtin (issue169, by darikg).\n* Add support for square bracket array indexing (issue170, issue176,\n  issue177 by darikg).\n* Improve grouping of aliased elements (issue167, by darikg).\n* Support comments starting with '#' character (issue178).\n\n\nRelease 0.1.14 (Nov 30, 2014)\n-----------------------------\n\nBug Fixes\n\n* Floats in UPDATE statements are now handled correctly (issue145).\n* Properly handle string literals in comparisons (issue148, change proposed\n  by aadis).\n* Fix indentation when using tabs (issue146).\n\nEnhancements\n\n* Improved formatting in list when newlines precede commas (issue140).\n\n\nRelease 0.1.13 (Oct 09, 2014)\n-----------------------------\n\nBug Fixes\n\n* Fix a regression in handling of NULL keywords introduced in 0.1.12.\n\n\nRelease 0.1.12 (Sep 20, 2014)\n-----------------------------\n\nBug Fixes\n\n* Fix handling of NULL keywords in aliased identifiers.\n* Fix SerializerUnicode to split unquoted newlines (issue131, by Michael Schuller).\n* Fix handling of modulo operators without spaces (by gavinwahl).\n\nEnhancements\n\n* Improve parsing of identifier lists containing placeholders.\n* Speed up query parsing of unquoted lines (by Michael Schuller).\n\n\nRelease 0.1.11 (Feb 07, 2014)\n-----------------------------\n\nBug Fixes\n\n* Fix incorrect parsing of string literals containing line breaks (issue118).\n* Fix typo in keywords, add MERGE, COLLECT keywords (issue122/124,\n  by Cristian Orellana).\n* Improve parsing of string literals in columns.\n* Fix parsing and formatting of statements containing EXCEPT keyword.\n* Fix Function.get_parameters() (issue126/127, by spigwitmer).\n\nEnhancements\n\n* Classify DML keywords (issue116, by Victor Hahn).\n* Add missing FOREACH keyword.\n* Grouping of BEGIN/END blocks.\n\nOther\n\n* Python 2.5 isn't automatically tested anymore, neither Travis nor Tox\n  still support it out of the box.\n\n\nRelease 0.1.10 (Nov 02, 2013)\n-----------------------------\n\nBug Fixes\n\n* Removed buffered reading again, it obviously causes wrong parsing in some rare\n  cases (issue114).\n* Fix regression in setup.py introduced 10 months ago (issue115).\n\nEnhancements\n\n* Improved support for JOINs, by Alexander Beedie.\n\n\nRelease 0.1.9 (Sep 28, 2013)\n----------------------------\n\nBug Fixes\n\n* Fix an regression introduced in 0.1.5 where sqlparse didn't properly\n  distinguished between single and double quoted strings when tagging\n  identifier (issue111).\n\nEnhancements\n\n* New option to truncate long string literals when formatting.\n* Scientific numbers are pares correctly (issue107).\n* Support for arithmetic expressions (issue109, issue106; by prudhvi).\n\n\nRelease 0.1.8 (Jun 29, 2013)\n----------------------------\n\nBug Fixes\n\n* Whitespaces within certain keywords are now allowed (issue97, patch proposed\n  by xcombelle).\n\nEnhancements\n\n* Improve parsing of assignments in UPDATE statements (issue90).\n* Add STRAIGHT_JOIN statement (by Yago Riveiro).\n* Function.get_parameters() now returns the parameter if only one parameter is\n  given (issue94, by wayne.wuw).\n* sqlparse.split() now removes leading and trailing whitespaces from split\n  statements.\n* Add USE as keyword token (by mulos).\n* Improve parsing of PEP249-style placeholders (issue103).\n\n\nRelease 0.1.7 (Apr 06, 2013)\n----------------------------\n\nBug Fixes\n\n* Fix Python 3 compatibility of sqlformat script (by Pi Delport).\n* Fix parsing of SQL statements that contain binary data (by Alexey\n  Malyshev).\n* Fix a bug where keywords were identified as aliased identifiers in\n  invalid SQL statements.\n* Fix parsing of identifier lists where identifiers are keywords too\n  (issue10).\n\nEnhancements\n\n* Top-level API functions now accept encoding keyword to parse\n  statements in certain encodings more reliable (issue20).\n* Improve parsing speed when SQL contains CLOBs or BLOBs (issue86).\n* Improve formatting of ORDER BY clauses (issue89).\n* Formatter now tries to detect runaway indentations caused by\n  parsing errors or invalid SQL statements. When re-indenting such\n  statements the formatter flips back to column 0 before going crazy.\n\nOther\n\n* Documentation updates.\n\n\nRelease 0.1.6 (Jan 01, 2013)\n----------------------------\n\nsqlparse is now compatible with Python 3 without any patches. The\nPython 3 version is generated during install by 2to3. You'll need\ndistribute to install sqlparse for Python 3.\n\nBug Fixes\n\n* Fix parsing error with dollar-quoted procedure bodies (issue83).\n\nOther\n\n* Documentation updates.\n* Test suite now uses tox and pytest.\n* py3k fixes (by vthriller).\n* py3k fixes in setup.py (by Florian Bauer).\n* setup.py now requires distribute (by Florian Bauer).\n\n\nRelease 0.1.5 (Nov 13, 2012)\n----------------------------\n\nBug Fixes\n\n* Improve handling of quoted identifiers (issue78).\n* Improve grouping and formatting of identifiers with operators (issue53).\n* Improve grouping and formatting of concatenated strings (issue53).\n* Improve handling of varchar() (by Mike Amy).\n* Clean up handling of various SQL elements.\n* Switch to pytest and clean up tests.\n* Several minor fixes.\n\nOther\n\n* Deprecate sqlparse.SQLParseError. Please use\n  sqlparse.exceptions.SQLParseError instead.\n* Add caching to speed up processing.\n* Add experimental filters for token processing.\n* Add sqlformat.parsestream (by quest).\n\n\nRelease 0.1.4 (Apr 20, 2012)\n----------------------------\n\nBug Fixes\n\n* Avoid \"stair case\" effects when identifiers, functions,\n  placeholders or keywords are mixed in identifier lists (issue45,\n  issue49, issue52) and when asterisks are used as operators\n  (issue58).\n* Make keyword detection more restrict (issue47).\n* Improve handling of CASE statements (issue46).\n* Fix statement splitting when parsing recursive statements (issue57,\n  thanks to piranna).\n* Fix for negative numbers (issue56, thanks to kevinjqiu).\n* Pretty format comments in identifier lists (issue59).\n* Several minor bug fixes and improvements.\n\n\nRelease 0.1.3 (Jul 29, 2011)\n----------------------------\n\nBug Fixes\n\n* Improve parsing of floats (thanks to Kris).\n* When formatting a statement a space before LIMIT was removed (issue35).\n* Fix strip_comments flag (issue38, reported by ooberm...@gmail.com).\n* Avoid parsing names as keywords (issue39, reported by djo...@taket.org).\n* Make sure identifier lists in subselects are grouped (issue40,\n  reported by djo...@taket.org).\n* Split statements with IF as functions correctly (issue33 and\n  issue29, reported by charles....@unige.ch).\n* Relax detection of keywords, esp. when used as function names\n  (issue36, nyuhu...@gmail.com).\n* Don't treat single characters as keywords (issue32).\n* Improve parsing of stand-alone comments (issue26).\n* Detection of placeholders in paramterized queries (issue22,\n  reported by Glyph Lefkowitz).\n* Add parsing of MS Access column names with braces (issue27,\n  reported by frankz...@gmail.com).\n\nOther\n\n* Replace Django by Flask in App Engine frontend (issue11).\n\n\nRelease 0.1.2 (Nov 23, 2010)\n----------------------------\n\nBug Fixes\n\n* Fixed incorrect detection of keyword fragments embed in names (issue7,\n  reported and initial patch by andyboyko).\n* Stricter detection of identifier aliases (issue8, reported by estama).\n* WHERE grouping consumed closing parenthesis (issue9, reported by estama).\n* Fixed an issue with trailing whitespaces (reported by Kris).\n* Better detection of escaped single quotes (issue13, reported by\n  Martin Brochhaus, patch by bluemaro with test case by Dan Carley).\n* Ignore identifier in double-quotes when changing cases (issue 21).\n* Lots of minor fixes targeting encoding, indentation, statement\n  parsing and more (issues 12, 14, 15, 16, 18, 19).\n* Code cleanup with a pinch of refactoring.\n\n\nRelease 0.1.1 (May 6, 2009)\n---------------------------\n\nBug Fixes\n\n* Lexers preserves original line breaks (issue1).\n* Improved identifier parsing: backtick quotes, wildcards, T-SQL variables\n  prefixed with @.\n* Improved parsing of identifier lists (issue2).\n* Recursive recognition of AS (issue4) and CASE.\n* Improved support for UPDATE statements.\n\nOther\n\n* Code cleanup and better test coverage.\n\n\nRelease 0.1.0 (Apr 8, 2009)\n---------------------------\n\nInitial release.\n", "#\n# Copyright (C) 2009-2020 the sqlparse authors and contributors\n# <see AUTHORS file>\n#\n# This module is part of python-sqlparse and is released under\n# the BSD License: https://opensource.org/licenses/BSD-3-Clause\n\nfrom sqlparse import tokens\n\n# object() only supports \"is\" and is useful as a marker\n# use this marker to specify that the given regex in SQL_REGEX\n# shall be processed further through a lookup in the KEYWORDS dictionaries\nPROCESS_AS_KEYWORD = object()\n\n\nSQL_REGEX = [\n    (r'(--|# )\\+.*?(\\r\\n|\\r|\\n|$)', tokens.Comment.Single.Hint),\n    (r'/\\*\\+[\\s\\S]*?\\*/', tokens.Comment.Multiline.Hint),\n\n    (r'(--|# ).*?(\\r\\n|\\r|\\n|$)', tokens.Comment.Single),\n    (r'/\\*[\\s\\S]*?\\*/', tokens.Comment.Multiline),\n\n    (r'(\\r\\n|\\r|\\n)', tokens.Newline),\n    (r'\\s+?', tokens.Whitespace),\n\n    (r':=', tokens.Assignment),\n    (r'::', tokens.Punctuation),\n\n    (r'\\*', tokens.Wildcard),\n\n    (r\"`(``|[^`])*`\", tokens.Name),\n    (r\"\u00b4(\u00b4\u00b4|[^\u00b4])*\u00b4\", tokens.Name),\n    (r'((?<!\\S)\\$(?:[_A-Z\u00c0-\u00dc]\\w*)?\\$)[\\s\\S]*?\\1', tokens.Literal),\n\n    (r'\\?', tokens.Name.Placeholder),\n    (r'%(\\(\\w+\\))?s', tokens.Name.Placeholder),\n    (r'(?<!\\w)[$:?]\\w+', tokens.Name.Placeholder),\n\n    (r'\\\\\\w+', tokens.Command),\n\n    # FIXME(andi): VALUES shouldn't be listed here\n    # see https://github.com/andialbrecht/sqlparse/pull/64\n    # AS and IN are special, it may be followed by a parenthesis, but\n    # are never functions, see issue183 and issue507\n    (r'(CASE|IN|VALUES|USING|FROM|AS)\\b', tokens.Keyword),\n\n    (r'(@|##|#)[A-Z\u00c0-\u00dc]\\w+', tokens.Name),\n\n    # see issue #39\n    # Spaces around period `schema . name` are valid identifier\n    # TODO: Spaces before period not implemented\n    (r'[A-Z\u00c0-\u00dc]\\w*(?=\\s*\\.)', tokens.Name),  # 'Name'.\n    # FIXME(atronah): never match,\n    # because `re.match` doesn't work with look-behind regexp feature\n    (r'(?<=\\.)[A-Z\u00c0-\u00dc]\\w*', tokens.Name),  # .'Name'\n    (r'[A-Z\u00c0-\u00dc]\\w*(?=\\()', tokens.Name),  # side effect: change kw to func\n    (r'-?0x[\\dA-F]+', tokens.Number.Hexadecimal),\n    (r'-?\\d+(\\.\\d+)?E-?\\d+', tokens.Number.Float),\n    (r'(?![_A-Z\u00c0-\u00dc])-?(\\d+(\\.\\d*)|\\.\\d+)(?![_A-Z\u00c0-\u00dc])',\n     tokens.Number.Float),\n    (r'(?![_A-Z\u00c0-\u00dc])-?\\d+(?![_A-Z\u00c0-\u00dc])', tokens.Number.Integer),\n    (r\"'(''|\\\\'|[^'])*'\", tokens.String.Single),\n    # not a real string literal in ANSI SQL:\n    (r'\"(\"\"|\\\\\"|[^\"])*\"', tokens.String.Symbol),\n    (r'(\"\"|\".*?[^\\\\]\")', tokens.String.Symbol),\n    # sqlite names can be escaped with [square brackets]. left bracket\n    # cannot be preceded by word character or a right bracket --\n    # otherwise it's probably an array index\n    (r'(?<![\\w\\])])(\\[[^\\]\\[]+\\])', tokens.Name),\n    (r'((LEFT\\s+|RIGHT\\s+|FULL\\s+)?(INNER\\s+|OUTER\\s+|STRAIGHT\\s+)?'\n     r'|(CROSS\\s+|NATURAL\\s+)?)?JOIN\\b', tokens.Keyword),\n    (r'END(\\s+IF|\\s+LOOP|\\s+WHILE)?\\b', tokens.Keyword),\n    (r'NOT\\s+NULL\\b', tokens.Keyword),\n    (r'NULLS\\s+(FIRST|LAST)\\b', tokens.Keyword),\n    (r'UNION\\s+ALL\\b', tokens.Keyword),\n    (r'CREATE(\\s+OR\\s+REPLACE)?\\b', tokens.Keyword.DDL),\n    (r'DOUBLE\\s+PRECISION\\b', tokens.Name.Builtin),\n    (r'GROUP\\s+BY\\b', tokens.Keyword),\n    (r'ORDER\\s+BY\\b', tokens.Keyword),\n    (r'HANDLER\\s+FOR\\b', tokens.Keyword),\n    (r'(LATERAL\\s+VIEW\\s+)'\n     r'(EXPLODE|INLINE|PARSE_URL_TUPLE|POSEXPLODE|STACK)\\b',\n     tokens.Keyword),\n    (r\"(AT|WITH')\\s+TIME\\s+ZONE\\s+'[^']+'\", tokens.Keyword.TZCast),\n    (r'(NOT\\s+)?(LIKE|ILIKE|RLIKE)\\b', tokens.Operator.Comparison),\n    (r'(NOT\\s+)?(REGEXP)\\b', tokens.Operator.Comparison),\n    # Check for keywords, also returns tokens.Name if regex matches\n    # but the match isn't a keyword.\n    (r'\\w[$#\\w]*', PROCESS_AS_KEYWORD),\n    (r'[;:()\\[\\],\\.]', tokens.Punctuation),\n    (r'[<>=~!]+', tokens.Operator.Comparison),\n    (r'[+/@#%^&|^-]+', tokens.Operator),\n]\n\nKEYWORDS = {\n    'ABORT': tokens.Keyword,\n    'ABS': tokens.Keyword,\n    'ABSOLUTE': tokens.Keyword,\n    'ACCESS': tokens.Keyword,\n    'ADA': tokens.Keyword,\n    'ADD': tokens.Keyword,\n    'ADMIN': tokens.Keyword,\n    'AFTER': tokens.Keyword,\n    'AGGREGATE': tokens.Keyword,\n    'ALIAS': tokens.Keyword,\n    'ALL': tokens.Keyword,\n    'ALLOCATE': tokens.Keyword,\n    'ANALYSE': tokens.Keyword,\n    'ANALYZE': tokens.Keyword,\n    'ANY': tokens.Keyword,\n    'ARRAYLEN': tokens.Keyword,\n    'ARE': tokens.Keyword,\n    'ASC': tokens.Keyword.Order,\n    'ASENSITIVE': tokens.Keyword,\n    'ASSERTION': tokens.Keyword,\n    'ASSIGNMENT': tokens.Keyword,\n    'ASYMMETRIC': tokens.Keyword,\n    'AT': tokens.Keyword,\n    'ATOMIC': tokens.Keyword,\n    'AUDIT': tokens.Keyword,\n    'AUTHORIZATION': tokens.Keyword,\n    'AUTO_INCREMENT': tokens.Keyword,\n    'AVG': tokens.Keyword,\n\n    'BACKWARD': tokens.Keyword,\n    'BEFORE': tokens.Keyword,\n    'BEGIN': tokens.Keyword,\n    'BETWEEN': tokens.Keyword,\n    'BITVAR': tokens.Keyword,\n    'BIT_LENGTH': tokens.Keyword,\n    'BOTH': tokens.Keyword,\n    'BREADTH': tokens.Keyword,\n\n    # 'C': tokens.Keyword,  # most likely this is an alias\n    'CACHE': tokens.Keyword,\n    'CALL': tokens.Keyword,\n    'CALLED': tokens.Keyword,\n    'CARDINALITY': tokens.Keyword,\n    'CASCADE': tokens.Keyword,\n    'CASCADED': tokens.Keyword,\n    'CAST': tokens.Keyword,\n    'CATALOG': tokens.Keyword,\n    'CATALOG_NAME': tokens.Keyword,\n    'CHAIN': tokens.Keyword,\n    'CHARACTERISTICS': tokens.Keyword,\n    'CHARACTER_LENGTH': tokens.Keyword,\n    'CHARACTER_SET_CATALOG': tokens.Keyword,\n    'CHARACTER_SET_NAME': tokens.Keyword,\n    'CHARACTER_SET_SCHEMA': tokens.Keyword,\n    'CHAR_LENGTH': tokens.Keyword,\n    'CHARSET': tokens.Keyword,\n    'CHECK': tokens.Keyword,\n    'CHECKED': tokens.Keyword,\n    'CHECKPOINT': tokens.Keyword,\n    'CLASS': tokens.Keyword,\n    'CLASS_ORIGIN': tokens.Keyword,\n    'CLOB': tokens.Keyword,\n    'CLOSE': tokens.Keyword,\n    'CLUSTER': tokens.Keyword,\n    'COALESCE': tokens.Keyword,\n    'COBOL': tokens.Keyword,\n    'COLLATE': tokens.Keyword,\n    'COLLATION': tokens.Keyword,\n    'COLLATION_CATALOG': tokens.Keyword,\n    'COLLATION_NAME': tokens.Keyword,\n    'COLLATION_SCHEMA': tokens.Keyword,\n    'COLLECT': tokens.Keyword,\n    'COLUMN': tokens.Keyword,\n    'COLUMN_NAME': tokens.Keyword,\n    'COMPRESS': tokens.Keyword,\n    'COMMAND_FUNCTION': tokens.Keyword,\n    'COMMAND_FUNCTION_CODE': tokens.Keyword,\n    'COMMENT': tokens.Keyword,\n    'COMMIT': tokens.Keyword.DML,\n    'COMMITTED': tokens.Keyword,\n    'COMPLETION': tokens.Keyword,\n    'CONCURRENTLY': tokens.Keyword,\n    'CONDITION_NUMBER': tokens.Keyword,\n    'CONNECT': tokens.Keyword,\n    'CONNECTION': tokens.Keyword,\n    'CONNECTION_NAME': tokens.Keyword,\n    'CONSTRAINT': tokens.Keyword,\n    'CONSTRAINTS': tokens.Keyword,\n    'CONSTRAINT_CATALOG': tokens.Keyword,\n    'CONSTRAINT_NAME': tokens.Keyword,\n    'CONSTRAINT_SCHEMA': tokens.Keyword,\n    'CONSTRUCTOR': tokens.Keyword,\n    'CONTAINS': tokens.Keyword,\n    'CONTINUE': tokens.Keyword,\n    'CONVERSION': tokens.Keyword,\n    'CONVERT': tokens.Keyword,\n    'COPY': tokens.Keyword,\n    'CORRESPONDING': tokens.Keyword,\n    'COUNT': tokens.Keyword,\n    'CREATEDB': tokens.Keyword,\n    'CREATEUSER': tokens.Keyword,\n    'CROSS': tokens.Keyword,\n    'CUBE': tokens.Keyword,\n    'CURRENT': tokens.Keyword,\n    'CURRENT_DATE': tokens.Keyword,\n    'CURRENT_PATH': tokens.Keyword,\n    'CURRENT_ROLE': tokens.Keyword,\n    'CURRENT_TIME': tokens.Keyword,\n    'CURRENT_TIMESTAMP': tokens.Keyword,\n    'CURRENT_USER': tokens.Keyword,\n    'CURSOR': tokens.Keyword,\n    'CURSOR_NAME': tokens.Keyword,\n    'CYCLE': tokens.Keyword,\n\n    'DATA': tokens.Keyword,\n    'DATABASE': tokens.Keyword,\n    'DATETIME_INTERVAL_CODE': tokens.Keyword,\n    'DATETIME_INTERVAL_PRECISION': tokens.Keyword,\n    'DAY': tokens.Keyword,\n    'DEALLOCATE': tokens.Keyword,\n    'DECLARE': tokens.Keyword,\n    'DEFAULT': tokens.Keyword,\n    'DEFAULTS': tokens.Keyword,\n    'DEFERRABLE': tokens.Keyword,\n    'DEFERRED': tokens.Keyword,\n    'DEFINED': tokens.Keyword,\n    'DEFINER': tokens.Keyword,\n    'DELIMITER': tokens.Keyword,\n    'DELIMITERS': tokens.Keyword,\n    'DEREF': tokens.Keyword,\n    'DESC': tokens.Keyword.Order,\n    'DESCRIBE': tokens.Keyword,\n    'DESCRIPTOR': tokens.Keyword,\n    'DESTROY': tokens.Keyword,\n    'DESTRUCTOR': tokens.Keyword,\n    'DETERMINISTIC': tokens.Keyword,\n    'DIAGNOSTICS': tokens.Keyword,\n    'DICTIONARY': tokens.Keyword,\n    'DISABLE': tokens.Keyword,\n    'DISCONNECT': tokens.Keyword,\n    'DISPATCH': tokens.Keyword,\n    'DIV': tokens.Operator,\n    'DO': tokens.Keyword,\n    'DOMAIN': tokens.Keyword,\n    'DYNAMIC': tokens.Keyword,\n    'DYNAMIC_FUNCTION': tokens.Keyword,\n    'DYNAMIC_FUNCTION_CODE': tokens.Keyword,\n\n    'EACH': tokens.Keyword,\n    'ENABLE': tokens.Keyword,\n    'ENCODING': tokens.Keyword,\n    'ENCRYPTED': tokens.Keyword,\n    'END-EXEC': tokens.Keyword,\n    'ENGINE': tokens.Keyword,\n    'EQUALS': tokens.Keyword,\n    'ESCAPE': tokens.Keyword,\n    'EVERY': tokens.Keyword,\n    'EXCEPT': tokens.Keyword,\n    'EXCEPTION': tokens.Keyword,\n    'EXCLUDING': tokens.Keyword,\n    'EXCLUSIVE': tokens.Keyword,\n    'EXEC': tokens.Keyword,\n    'EXECUTE': tokens.Keyword,\n    'EXISTING': tokens.Keyword,\n    'EXISTS': tokens.Keyword,\n    'EXPLAIN': tokens.Keyword,\n    'EXTERNAL': tokens.Keyword,\n    'EXTRACT': tokens.Keyword,\n\n    'FALSE': tokens.Keyword,\n    'FETCH': tokens.Keyword,\n    'FILE': tokens.Keyword,\n    'FINAL': tokens.Keyword,\n    'FIRST': tokens.Keyword,\n    'FORCE': tokens.Keyword,\n    'FOREACH': tokens.Keyword,\n    'FOREIGN': tokens.Keyword,\n    'FORTRAN': tokens.Keyword,\n    'FORWARD': tokens.Keyword,\n    'FOUND': tokens.Keyword,\n    'FREE': tokens.Keyword,\n    'FREEZE': tokens.Keyword,\n    'FULL': tokens.Keyword,\n    'FUNCTION': tokens.Keyword,\n\n    # 'G': tokens.Keyword,\n    'GENERAL': tokens.Keyword,\n    'GENERATED': tokens.Keyword,\n    'GET': tokens.Keyword,\n    'GLOBAL': tokens.Keyword,\n    'GO': tokens.Keyword,\n    'GOTO': tokens.Keyword,\n    'GRANT': tokens.Keyword,\n    'GRANTED': tokens.Keyword,\n    'GROUPING': tokens.Keyword,\n\n    'HAVING': tokens.Keyword,\n    'HIERARCHY': tokens.Keyword,\n    'HOLD': tokens.Keyword,\n    'HOUR': tokens.Keyword,\n    'HOST': tokens.Keyword,\n\n    'IDENTIFIED': tokens.Keyword,\n    'IDENTITY': tokens.Keyword,\n    'IGNORE': tokens.Keyword,\n    'ILIKE': tokens.Keyword,\n    'IMMEDIATE': tokens.Keyword,\n    'IMMUTABLE': tokens.Keyword,\n\n    'IMPLEMENTATION': tokens.Keyword,\n    'IMPLICIT': tokens.Keyword,\n    'INCLUDING': tokens.Keyword,\n    'INCREMENT': tokens.Keyword,\n    'INDEX': tokens.Keyword,\n\n    'INDICATOR': tokens.Keyword,\n    'INFIX': tokens.Keyword,\n    'INHERITS': tokens.Keyword,\n    'INITIAL': tokens.Keyword,\n    'INITIALIZE': tokens.Keyword,\n    'INITIALLY': tokens.Keyword,\n    'INOUT': tokens.Keyword,\n    'INPUT': tokens.Keyword,\n    'INSENSITIVE': tokens.Keyword,\n    'INSTANTIABLE': tokens.Keyword,\n    'INSTEAD': tokens.Keyword,\n    'INTERSECT': tokens.Keyword,\n    'INTO': tokens.Keyword,\n    'INVOKER': tokens.Keyword,\n    'IS': tokens.Keyword,\n    'ISNULL': tokens.Keyword,\n    'ISOLATION': tokens.Keyword,\n    'ITERATE': tokens.Keyword,\n\n    # 'K': tokens.Keyword,\n    'KEY': tokens.Keyword,\n    'KEY_MEMBER': tokens.Keyword,\n    'KEY_TYPE': tokens.Keyword,\n\n    'LANCOMPILER': tokens.Keyword,\n    'LANGUAGE': tokens.Keyword,\n    'LARGE': tokens.Keyword,\n    'LAST': tokens.Keyword,\n    'LATERAL': tokens.Keyword,\n    'LEADING': tokens.Keyword,\n    'LENGTH': tokens.Keyword,\n    'LESS': tokens.Keyword,\n    'LEVEL': tokens.Keyword,\n    'LIMIT': tokens.Keyword,\n    'LISTEN': tokens.Keyword,\n    'LOAD': tokens.Keyword,\n    'LOCAL': tokens.Keyword,\n    'LOCALTIME': tokens.Keyword,\n    'LOCALTIMESTAMP': tokens.Keyword,\n    'LOCATION': tokens.Keyword,\n    'LOCATOR': tokens.Keyword,\n    'LOCK': tokens.Keyword,\n    'LOWER': tokens.Keyword,\n\n    # 'M': tokens.Keyword,\n    'MAP': tokens.Keyword,\n    'MATCH': tokens.Keyword,\n    'MAXEXTENTS': tokens.Keyword,\n    'MAXVALUE': tokens.Keyword,\n    'MESSAGE_LENGTH': tokens.Keyword,\n    'MESSAGE_OCTET_LENGTH': tokens.Keyword,\n    'MESSAGE_TEXT': tokens.Keyword,\n    'METHOD': tokens.Keyword,\n    'MINUTE': tokens.Keyword,\n    'MINUS': tokens.Keyword,\n    'MINVALUE': tokens.Keyword,\n    'MOD': tokens.Keyword,\n    'MODE': tokens.Keyword,\n    'MODIFIES': tokens.Keyword,\n    'MODIFY': tokens.Keyword,\n    'MONTH': tokens.Keyword,\n    'MORE': tokens.Keyword,\n    'MOVE': tokens.Keyword,\n    'MUMPS': tokens.Keyword,\n\n    'NAMES': tokens.Keyword,\n    'NATIONAL': tokens.Keyword,\n    'NATURAL': tokens.Keyword,\n    'NCHAR': tokens.Keyword,\n    'NCLOB': tokens.Keyword,\n    'NEW': tokens.Keyword,\n    'NEXT': tokens.Keyword,\n    'NO': tokens.Keyword,\n    'NOAUDIT': tokens.Keyword,\n    'NOCOMPRESS': tokens.Keyword,\n    'NOCREATEDB': tokens.Keyword,\n    'NOCREATEUSER': tokens.Keyword,\n    'NONE': tokens.Keyword,\n    'NOT': tokens.Keyword,\n    'NOTFOUND': tokens.Keyword,\n    'NOTHING': tokens.Keyword,\n    'NOTIFY': tokens.Keyword,\n    'NOTNULL': tokens.Keyword,\n    'NOWAIT': tokens.Keyword,\n    'NULL': tokens.Keyword,\n    'NULLABLE': tokens.Keyword,\n    'NULLIF': tokens.Keyword,\n\n    'OBJECT': tokens.Keyword,\n    'OCTET_LENGTH': tokens.Keyword,\n    'OF': tokens.Keyword,\n    'OFF': tokens.Keyword,\n    'OFFLINE': tokens.Keyword,\n    'OFFSET': tokens.Keyword,\n    'OIDS': tokens.Keyword,\n    'OLD': tokens.Keyword,\n    'ONLINE': tokens.Keyword,\n    'ONLY': tokens.Keyword,\n    'OPEN': tokens.Keyword,\n    'OPERATION': tokens.Keyword,\n    'OPERATOR': tokens.Keyword,\n    'OPTION': tokens.Keyword,\n    'OPTIONS': tokens.Keyword,\n    'ORDINALITY': tokens.Keyword,\n    'OUT': tokens.Keyword,\n    'OUTPUT': tokens.Keyword,\n    'OVERLAPS': tokens.Keyword,\n    'OVERLAY': tokens.Keyword,\n    'OVERRIDING': tokens.Keyword,\n    'OWNER': tokens.Keyword,\n\n    'QUARTER': tokens.Keyword,\n\n    'PAD': tokens.Keyword,\n    'PARAMETER': tokens.Keyword,\n    'PARAMETERS': tokens.Keyword,\n    'PARAMETER_MODE': tokens.Keyword,\n    'PARAMETER_NAME': tokens.Keyword,\n    'PARAMETER_ORDINAL_POSITION': tokens.Keyword,\n    'PARAMETER_SPECIFIC_CATALOG': tokens.Keyword,\n    'PARAMETER_SPECIFIC_NAME': tokens.Keyword,\n    'PARAMETER_SPECIFIC_SCHEMA': tokens.Keyword,\n    'PARTIAL': tokens.Keyword,\n    'PASCAL': tokens.Keyword,\n    'PCTFREE': tokens.Keyword,\n    'PENDANT': tokens.Keyword,\n    'PLACING': tokens.Keyword,\n    'PLI': tokens.Keyword,\n    'POSITION': tokens.Keyword,\n    'POSTFIX': tokens.Keyword,\n    'PRECISION': tokens.Keyword,\n    'PREFIX': tokens.Keyword,\n    'PREORDER': tokens.Keyword,\n    'PREPARE': tokens.Keyword,\n    'PRESERVE': tokens.Keyword,\n    'PRIMARY': tokens.Keyword,\n    'PRIOR': tokens.Keyword,\n    'PRIVILEGES': tokens.Keyword,\n    'PROCEDURAL': tokens.Keyword,\n    'PROCEDURE': tokens.Keyword,\n    'PUBLIC': tokens.Keyword,\n\n    'RAISE': tokens.Keyword,\n    'RAW': tokens.Keyword,\n    'READ': tokens.Keyword,\n    'READS': tokens.Keyword,\n    'RECHECK': tokens.Keyword,\n    'RECURSIVE': tokens.Keyword,\n    'REF': tokens.Keyword,\n    'REFERENCES': tokens.Keyword,\n    'REFERENCING': tokens.Keyword,\n    'REINDEX': tokens.Keyword,\n    'RELATIVE': tokens.Keyword,\n    'RENAME': tokens.Keyword,\n    'REPEATABLE': tokens.Keyword,\n    'RESET': tokens.Keyword,\n    'RESOURCE': tokens.Keyword,\n    'RESTART': tokens.Keyword,\n    'RESTRICT': tokens.Keyword,\n    'RESULT': tokens.Keyword,\n    'RETURN': tokens.Keyword,\n    'RETURNED_LENGTH': tokens.Keyword,\n    'RETURNED_OCTET_LENGTH': tokens.Keyword,\n    'RETURNED_SQLSTATE': tokens.Keyword,\n    'RETURNING': tokens.Keyword,\n    'RETURNS': tokens.Keyword,\n    'REVOKE': tokens.Keyword,\n    'RIGHT': tokens.Keyword,\n    'ROLE': tokens.Keyword,\n    'ROLLBACK': tokens.Keyword.DML,\n    'ROLLUP': tokens.Keyword,\n    'ROUTINE': tokens.Keyword,\n    'ROUTINE_CATALOG': tokens.Keyword,\n    'ROUTINE_NAME': tokens.Keyword,\n    'ROUTINE_SCHEMA': tokens.Keyword,\n    'ROW': tokens.Keyword,\n    'ROWS': tokens.Keyword,\n    'ROW_COUNT': tokens.Keyword,\n    'RULE': tokens.Keyword,\n\n    'SAVE_POINT': tokens.Keyword,\n    'SCALE': tokens.Keyword,\n    'SCHEMA': tokens.Keyword,\n    'SCHEMA_NAME': tokens.Keyword,\n    'SCOPE': tokens.Keyword,\n    'SCROLL': tokens.Keyword,\n    'SEARCH': tokens.Keyword,\n    'SECOND': tokens.Keyword,\n    'SECURITY': tokens.Keyword,\n    'SELF': tokens.Keyword,\n    'SENSITIVE': tokens.Keyword,\n    'SEQUENCE': tokens.Keyword,\n    'SERIALIZABLE': tokens.Keyword,\n    'SERVER_NAME': tokens.Keyword,\n    'SESSION': tokens.Keyword,\n    'SESSION_USER': tokens.Keyword,\n    'SETOF': tokens.Keyword,\n    'SETS': tokens.Keyword,\n    'SHARE': tokens.Keyword,\n    'SHOW': tokens.Keyword,\n    'SIMILAR': tokens.Keyword,\n    'SIMPLE': tokens.Keyword,\n    'SIZE': tokens.Keyword,\n    'SOME': tokens.Keyword,\n    'SOURCE': tokens.Keyword,\n    'SPACE': tokens.Keyword,\n    'SPECIFIC': tokens.Keyword,\n    'SPECIFICTYPE': tokens.Keyword,\n    'SPECIFIC_NAME': tokens.Keyword,\n    'SQL': tokens.Keyword,\n    'SQLBUF': tokens.Keyword,\n    'SQLCODE': tokens.Keyword,\n    'SQLERROR': tokens.Keyword,\n    'SQLEXCEPTION': tokens.Keyword,\n    'SQLSTATE': tokens.Keyword,\n    'SQLWARNING': tokens.Keyword,\n    'STABLE': tokens.Keyword,\n    'START': tokens.Keyword.DML,\n    # 'STATE': tokens.Keyword,\n    'STATEMENT': tokens.Keyword,\n    'STATIC': tokens.Keyword,\n    'STATISTICS': tokens.Keyword,\n    'STDIN': tokens.Keyword,\n    'STDOUT': tokens.Keyword,\n    'STORAGE': tokens.Keyword,\n    'STRICT': tokens.Keyword,\n    'STRUCTURE': tokens.Keyword,\n    'STYPE': tokens.Keyword,\n    'SUBCLASS_ORIGIN': tokens.Keyword,\n    'SUBLIST': tokens.Keyword,\n    'SUBSTRING': tokens.Keyword,\n    'SUCCESSFUL': tokens.Keyword,\n    'SUM': tokens.Keyword,\n    'SYMMETRIC': tokens.Keyword,\n    'SYNONYM': tokens.Keyword,\n    'SYSID': tokens.Keyword,\n    'SYSTEM': tokens.Keyword,\n    'SYSTEM_USER': tokens.Keyword,\n\n    'TABLE': tokens.Keyword,\n    'TABLE_NAME': tokens.Keyword,\n    'TEMP': tokens.Keyword,\n    'TEMPLATE': tokens.Keyword,\n    'TEMPORARY': tokens.Keyword,\n    'TERMINATE': tokens.Keyword,\n    'THAN': tokens.Keyword,\n    'TIMESTAMP': tokens.Keyword,\n    'TIMEZONE_HOUR': tokens.Keyword,\n    'TIMEZONE_MINUTE': tokens.Keyword,\n    'TO': tokens.Keyword,\n    'TOAST': tokens.Keyword,\n    'TRAILING': tokens.Keyword,\n    'TRANSATION': tokens.Keyword,\n    'TRANSACTIONS_COMMITTED': tokens.Keyword,\n    'TRANSACTIONS_ROLLED_BACK': tokens.Keyword,\n    'TRANSATION_ACTIVE': tokens.Keyword,\n    'TRANSFORM': tokens.Keyword,\n    'TRANSFORMS': tokens.Keyword,\n    'TRANSLATE': tokens.Keyword,\n    'TRANSLATION': tokens.Keyword,\n    'TREAT': tokens.Keyword,\n    'TRIGGER': tokens.Keyword,\n    'TRIGGER_CATALOG': tokens.Keyword,\n    'TRIGGER_NAME': tokens.Keyword,\n    'TRIGGER_SCHEMA': tokens.Keyword,\n    'TRIM': tokens.Keyword,\n    'TRUE': tokens.Keyword,\n    'TRUNCATE': tokens.Keyword,\n    'TRUSTED': tokens.Keyword,\n    'TYPE': tokens.Keyword,\n\n    'UID': tokens.Keyword,\n    'UNCOMMITTED': tokens.Keyword,\n    'UNDER': tokens.Keyword,\n    'UNENCRYPTED': tokens.Keyword,\n    'UNION': tokens.Keyword,\n    'UNIQUE': tokens.Keyword,\n    'UNKNOWN': tokens.Keyword,\n    'UNLISTEN': tokens.Keyword,\n    'UNNAMED': tokens.Keyword,\n    'UNNEST': tokens.Keyword,\n    'UNTIL': tokens.Keyword,\n    'UPPER': tokens.Keyword,\n    'USAGE': tokens.Keyword,\n    'USE': tokens.Keyword,\n    'USER': tokens.Keyword,\n    'USER_DEFINED_TYPE_CATALOG': tokens.Keyword,\n    'USER_DEFINED_TYPE_NAME': tokens.Keyword,\n    'USER_DEFINED_TYPE_SCHEMA': tokens.Keyword,\n    'USING': tokens.Keyword,\n\n    'VACUUM': tokens.Keyword,\n    'VALID': tokens.Keyword,\n    'VALIDATE': tokens.Keyword,\n    'VALIDATOR': tokens.Keyword,\n    'VALUES': tokens.Keyword,\n    'VARIABLE': tokens.Keyword,\n    'VERBOSE': tokens.Keyword,\n    'VERSION': tokens.Keyword,\n    'VIEW': tokens.Keyword,\n    'VOLATILE': tokens.Keyword,\n\n    'WEEK': tokens.Keyword,\n    'WHENEVER': tokens.Keyword,\n    'WITH': tokens.Keyword.CTE,\n    'WITHOUT': tokens.Keyword,\n    'WORK': tokens.Keyword,\n    'WRITE': tokens.Keyword,\n\n    'YEAR': tokens.Keyword,\n\n    'ZONE': tokens.Keyword,\n\n    # Name.Builtin\n    'ARRAY': tokens.Name.Builtin,\n    'BIGINT': tokens.Name.Builtin,\n    'BINARY': tokens.Name.Builtin,\n    'BIT': tokens.Name.Builtin,\n    'BLOB': tokens.Name.Builtin,\n    'BOOLEAN': tokens.Name.Builtin,\n    'CHAR': tokens.Name.Builtin,\n    'CHARACTER': tokens.Name.Builtin,\n    'DATE': tokens.Name.Builtin,\n    'DEC': tokens.Name.Builtin,\n    'DECIMAL': tokens.Name.Builtin,\n    'FILE_TYPE': tokens.Name.Builtin,\n    'FLOAT': tokens.Name.Builtin,\n    'INT': tokens.Name.Builtin,\n    'INT8': tokens.Name.Builtin,\n    'INTEGER': tokens.Name.Builtin,\n    'INTERVAL': tokens.Name.Builtin,\n    'LONG': tokens.Name.Builtin,\n    'NATURALN': tokens.Name.Builtin,\n    'NVARCHAR': tokens.Name.Builtin,\n    'NUMBER': tokens.Name.Builtin,\n    'NUMERIC': tokens.Name.Builtin,\n    'PLS_INTEGER': tokens.Name.Builtin,\n    'POSITIVE': tokens.Name.Builtin,\n    'POSITIVEN': tokens.Name.Builtin,\n    'REAL': tokens.Name.Builtin,\n    'ROWID': tokens.Name.Builtin,\n    'ROWLABEL': tokens.Name.Builtin,\n    'ROWNUM': tokens.Name.Builtin,\n    'SERIAL': tokens.Name.Builtin,\n    'SERIAL8': tokens.Name.Builtin,\n    'SIGNED': tokens.Name.Builtin,\n    'SIGNTYPE': tokens.Name.Builtin,\n    'SIMPLE_DOUBLE': tokens.Name.Builtin,\n    'SIMPLE_FLOAT': tokens.Name.Builtin,\n    'SIMPLE_INTEGER': tokens.Name.Builtin,\n    'SMALLINT': tokens.Name.Builtin,\n    'SYS_REFCURSOR': tokens.Name.Builtin,\n    'SYSDATE': tokens.Name,\n    'TEXT': tokens.Name.Builtin,\n    'TINYINT': tokens.Name.Builtin,\n    'UNSIGNED': tokens.Name.Builtin,\n    'UROWID': tokens.Name.Builtin,\n    'UTL_FILE': tokens.Name.Builtin,\n    'VARCHAR': tokens.Name.Builtin,\n    'VARCHAR2': tokens.Name.Builtin,\n    'VARYING': tokens.Name.Builtin,\n}\n\nKEYWORDS_COMMON = {\n    'SELECT': tokens.Keyword.DML,\n    'INSERT': tokens.Keyword.DML,\n    'DELETE': tokens.Keyword.DML,\n    'UPDATE': tokens.Keyword.DML,\n    'UPSERT': tokens.Keyword.DML,\n    'REPLACE': tokens.Keyword.DML,\n    'MERGE': tokens.Keyword.DML,\n    'DROP': tokens.Keyword.DDL,\n    'CREATE': tokens.Keyword.DDL,\n    'ALTER': tokens.Keyword.DDL,\n\n    'WHERE': tokens.Keyword,\n    'FROM': tokens.Keyword,\n    'INNER': tokens.Keyword,\n    'JOIN': tokens.Keyword,\n    'STRAIGHT_JOIN': tokens.Keyword,\n    'AND': tokens.Keyword,\n    'OR': tokens.Keyword,\n    'LIKE': tokens.Keyword,\n    'ON': tokens.Keyword,\n    'IN': tokens.Keyword,\n    'SET': tokens.Keyword,\n\n    'BY': tokens.Keyword,\n    'GROUP': tokens.Keyword,\n    'ORDER': tokens.Keyword,\n    'LEFT': tokens.Keyword,\n    'OUTER': tokens.Keyword,\n    'FULL': tokens.Keyword,\n\n    'IF': tokens.Keyword,\n    'END': tokens.Keyword,\n    'THEN': tokens.Keyword,\n    'LOOP': tokens.Keyword,\n    'AS': tokens.Keyword,\n    'ELSE': tokens.Keyword,\n    'FOR': tokens.Keyword,\n    'WHILE': tokens.Keyword,\n\n    'CASE': tokens.Keyword,\n    'WHEN': tokens.Keyword,\n    'MIN': tokens.Keyword,\n    'MAX': tokens.Keyword,\n    'DISTINCT': tokens.Keyword,\n}\n\nKEYWORDS_ORACLE = {\n    'ARCHIVE': tokens.Keyword,\n    'ARCHIVELOG': tokens.Keyword,\n\n    'BACKUP': tokens.Keyword,\n    'BECOME': tokens.Keyword,\n    'BLOCK': tokens.Keyword,\n    'BODY': tokens.Keyword,\n\n    'CANCEL': tokens.Keyword,\n    'CHANGE': tokens.Keyword,\n    'COMPILE': tokens.Keyword,\n    'CONTENTS': tokens.Keyword,\n    'CONTROLFILE': tokens.Keyword,\n\n    'DATAFILE': tokens.Keyword,\n    'DBA': tokens.Keyword,\n    'DISMOUNT': tokens.Keyword,\n    'DOUBLE': tokens.Keyword,\n    'DUMP': tokens.Keyword,\n\n    'ELSIF': tokens.Keyword,\n    'EVENTS': tokens.Keyword,\n    'EXCEPTIONS': tokens.Keyword,\n    'EXPLAIN': tokens.Keyword,\n    'EXTENT': tokens.Keyword,\n    'EXTERNALLY': tokens.Keyword,\n\n    'FLUSH': tokens.Keyword,\n    'FREELIST': tokens.Keyword,\n    'FREELISTS': tokens.Keyword,\n\n    # groups seems too common as table name\n    # 'GROUPS': tokens.Keyword,\n\n    'INDICATOR': tokens.Keyword,\n    'INITRANS': tokens.Keyword,\n    'INSTANCE': tokens.Keyword,\n\n    'LAYER': tokens.Keyword,\n    'LINK': tokens.Keyword,\n    'LISTS': tokens.Keyword,\n    'LOGFILE': tokens.Keyword,\n\n    'MANAGE': tokens.Keyword,\n    'MANUAL': tokens.Keyword,\n    'MAXDATAFILES': tokens.Keyword,\n    'MAXINSTANCES': tokens.Keyword,\n    'MAXLOGFILES': tokens.Keyword,\n    'MAXLOGHISTORY': tokens.Keyword,\n    'MAXLOGMEMBERS': tokens.Keyword,\n    'MAXTRANS': tokens.Keyword,\n    'MINEXTENTS': tokens.Keyword,\n    'MODULE': tokens.Keyword,\n    'MOUNT': tokens.Keyword,\n\n    'NOARCHIVELOG': tokens.Keyword,\n    'NOCACHE': tokens.Keyword,\n    'NOCYCLE': tokens.Keyword,\n    'NOMAXVALUE': tokens.Keyword,\n    'NOMINVALUE': tokens.Keyword,\n    'NOORDER': tokens.Keyword,\n    'NORESETLOGS': tokens.Keyword,\n    'NORMAL': tokens.Keyword,\n    'NOSORT': tokens.Keyword,\n\n    'OPTIMAL': tokens.Keyword,\n    'OWN': tokens.Keyword,\n\n    'PACKAGE': tokens.Keyword,\n    'PARALLEL': tokens.Keyword,\n    'PCTINCREASE': tokens.Keyword,\n    'PCTUSED': tokens.Keyword,\n    'PLAN': tokens.Keyword,\n    'PRIVATE': tokens.Keyword,\n    'PROFILE': tokens.Keyword,\n\n    'QUOTA': tokens.Keyword,\n\n    'RECOVER': tokens.Keyword,\n    'RESETLOGS': tokens.Keyword,\n    'RESTRICTED': tokens.Keyword,\n    'REUSE': tokens.Keyword,\n    'ROLES': tokens.Keyword,\n\n    'SAVEPOINT': tokens.Keyword,\n    'SCN': tokens.Keyword,\n    'SECTION': tokens.Keyword,\n    'SEGMENT': tokens.Keyword,\n    'SHARED': tokens.Keyword,\n    'SNAPSHOT': tokens.Keyword,\n    'SORT': tokens.Keyword,\n    'STATEMENT_ID': tokens.Keyword,\n    'STOP': tokens.Keyword,\n    'SWITCH': tokens.Keyword,\n\n    'TABLES': tokens.Keyword,\n    'TABLESPACE': tokens.Keyword,\n    'THREAD': tokens.Keyword,\n    'TIME': tokens.Keyword,\n    'TRACING': tokens.Keyword,\n    'TRANSACTION': tokens.Keyword,\n    'TRIGGERS': tokens.Keyword,\n\n    'UNLIMITED': tokens.Keyword,\n    'UNLOCK': tokens.Keyword,\n}\n\n# PostgreSQL Syntax\nKEYWORDS_PLPGSQL = {\n    'CONFLICT': tokens.Keyword,\n    'WINDOW': tokens.Keyword,\n    'PARTITION': tokens.Keyword,\n    'OVER': tokens.Keyword,\n    'PERFORM': tokens.Keyword,\n    'NOTICE': tokens.Keyword,\n    'PLPGSQL': tokens.Keyword,\n    'INHERIT': tokens.Keyword,\n    'INDEXES': tokens.Keyword,\n    'ON_ERROR_STOP': tokens.Keyword,\n\n    'BYTEA': tokens.Keyword,\n    'BIGSERIAL': tokens.Keyword,\n    'BIT VARYING': tokens.Keyword,\n    'BOX': tokens.Keyword,\n    'CHARACTER': tokens.Keyword,\n    'CHARACTER VARYING': tokens.Keyword,\n    'CIDR': tokens.Keyword,\n    'CIRCLE': tokens.Keyword,\n    'DOUBLE PRECISION': tokens.Keyword,\n    'INET': tokens.Keyword,\n    'JSON': tokens.Keyword,\n    'JSONB': tokens.Keyword,\n    'LINE': tokens.Keyword,\n    'LSEG': tokens.Keyword,\n    'MACADDR': tokens.Keyword,\n    'MONEY': tokens.Keyword,\n    'PATH': tokens.Keyword,\n    'PG_LSN': tokens.Keyword,\n    'POINT': tokens.Keyword,\n    'POLYGON': tokens.Keyword,\n    'SMALLSERIAL': tokens.Keyword,\n    'TSQUERY': tokens.Keyword,\n    'TSVECTOR': tokens.Keyword,\n    'TXID_SNAPSHOT': tokens.Keyword,\n    'UUID': tokens.Keyword,\n    'XML': tokens.Keyword,\n\n    'FOR': tokens.Keyword,\n    'IN': tokens.Keyword,\n    'LOOP': tokens.Keyword,\n}\n\n# Hive Syntax\nKEYWORDS_HQL = {\n    'EXPLODE': tokens.Keyword,\n    'DIRECTORY': tokens.Keyword,\n    'DISTRIBUTE': tokens.Keyword,\n    'INCLUDE': tokens.Keyword,\n    'LOCATE': tokens.Keyword,\n    'OVERWRITE': tokens.Keyword,\n    'POSEXPLODE': tokens.Keyword,\n\n    'ARRAY_CONTAINS': tokens.Keyword,\n    'CMP': tokens.Keyword,\n    'COLLECT_LIST': tokens.Keyword,\n    'CONCAT': tokens.Keyword,\n    'CONDITION': tokens.Keyword,\n    'DATE_ADD': tokens.Keyword,\n    'DATE_SUB': tokens.Keyword,\n    'DECODE': tokens.Keyword,\n    'DBMS_OUTPUT': tokens.Keyword,\n    'ELEMENTS': tokens.Keyword,\n    'EXCHANGE': tokens.Keyword,\n    'EXTENDED': tokens.Keyword,\n    'FLOOR': tokens.Keyword,\n    'FOLLOWING': tokens.Keyword,\n    'FROM_UNIXTIME': tokens.Keyword,\n    'FTP': tokens.Keyword,\n    'HOUR': tokens.Keyword,\n    'INLINE': tokens.Keyword,\n    'INSTR': tokens.Keyword,\n    'LEN': tokens.Keyword,\n    'MAP': tokens.Name.Builtin,\n    'MAXELEMENT': tokens.Keyword,\n    'MAXINDEX': tokens.Keyword,\n    'MAX_PART_DATE': tokens.Keyword,\n    'MAX_PART_INT': tokens.Keyword,\n    'MAX_PART_STRING': tokens.Keyword,\n    'MINELEMENT': tokens.Keyword,\n    'MININDEX': tokens.Keyword,\n    'MIN_PART_DATE': tokens.Keyword,\n    'MIN_PART_INT': tokens.Keyword,\n    'MIN_PART_STRING': tokens.Keyword,\n    'NOW': tokens.Keyword,\n    'NVL': tokens.Keyword,\n    'NVL2': tokens.Keyword,\n    'PARSE_URL_TUPLE': tokens.Keyword,\n    'PART_LOC': tokens.Keyword,\n    'PART_COUNT': tokens.Keyword,\n    'PART_COUNT_BY': tokens.Keyword,\n    'PRINT': tokens.Keyword,\n    'PUT_LINE': tokens.Keyword,\n    'RANGE': tokens.Keyword,\n    'REDUCE': tokens.Keyword,\n    'REGEXP_REPLACE': tokens.Keyword,\n    'RESIGNAL': tokens.Keyword,\n    'RTRIM': tokens.Keyword,\n    'SIGN': tokens.Keyword,\n    'SIGNAL': tokens.Keyword,\n    'SIN': tokens.Keyword,\n    'SPLIT': tokens.Keyword,\n    'SQRT': tokens.Keyword,\n    'STACK': tokens.Keyword,\n    'STR': tokens.Keyword,\n    'STRING': tokens.Name.Builtin,\n    'STRUCT': tokens.Name.Builtin,\n    'SUBSTR': tokens.Keyword,\n    'SUMMARY': tokens.Keyword,\n    'TBLPROPERTIES': tokens.Keyword,\n    'TIMESTAMP': tokens.Name.Builtin,\n    'TIMESTAMP_ISO': tokens.Keyword,\n    'TO_CHAR': tokens.Keyword,\n    'TO_DATE': tokens.Keyword,\n    'TO_TIMESTAMP': tokens.Keyword,\n    'TRUNC': tokens.Keyword,\n    'UNBOUNDED': tokens.Keyword,\n    'UNIQUEJOIN': tokens.Keyword,\n    'UNIX_TIMESTAMP': tokens.Keyword,\n    'UTC_TIMESTAMP': tokens.Keyword,\n    'VIEWS': tokens.Keyword,\n\n    'EXIT': tokens.Keyword,\n    'BREAK': tokens.Keyword,\n    'LEAVE': tokens.Keyword,\n}\n\n\nKEYWORDS_MSACCESS = {\n    'DISTINCTROW': tokens.Keyword,\n}\n", "# Tests splitting functions.\n\nimport types\nfrom io import StringIO\n\nimport pytest\n\nimport sqlparse\n\n\ndef test_split_semicolon():\n    sql1 = 'select * from foo;'\n    sql2 = \"select * from foo where bar = 'foo;bar';\"\n    stmts = sqlparse.parse(''.join([sql1, sql2]))\n    assert len(stmts) == 2\n    assert str(stmts[0]) == sql1\n    assert str(stmts[1]) == sql2\n\n\ndef test_split_backslash():\n    stmts = sqlparse.parse(\"select '\\'; select '\\'';\")\n    assert len(stmts) == 2\n\n\n@pytest.mark.parametrize('fn', ['function.sql',\n                                'function_psql.sql',\n                                'function_psql2.sql',\n                                'function_psql3.sql',\n                                'function_psql4.sql'])\ndef test_split_create_function(load_file, fn):\n    sql = load_file(fn)\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 1\n    assert str(stmts[0]) == sql\n\n\ndef test_split_dashcomments(load_file):\n    sql = load_file('dashcomment.sql')\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 3\n    assert ''.join(str(q) for q in stmts) == sql\n\n\n@pytest.mark.parametrize('s', ['select foo; -- comment\\n',\n                               'select foo; -- comment\\r',\n                               'select foo; -- comment\\r\\n',\n                               'select foo; -- comment'])\ndef test_split_dashcomments_eol(s):\n    stmts = sqlparse.parse(s)\n    assert len(stmts) == 1\n\n\ndef test_split_begintag(load_file):\n    sql = load_file('begintag.sql')\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 3\n    assert ''.join(str(q) for q in stmts) == sql\n\n\ndef test_split_begintag_2(load_file):\n    sql = load_file('begintag_2.sql')\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 1\n    assert ''.join(str(q) for q in stmts) == sql\n\n\ndef test_split_dropif():\n    sql = 'DROP TABLE IF EXISTS FOO;\\n\\nSELECT * FROM BAR;'\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 2\n    assert ''.join(str(q) for q in stmts) == sql\n\n\ndef test_split_comment_with_umlaut():\n    sql = ('select * from foo;\\n'\n           '-- Testing an umlaut: \u00e4\\n'\n           'select * from bar;')\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 2\n    assert ''.join(str(q) for q in stmts) == sql\n\n\ndef test_split_comment_end_of_line():\n    sql = ('select * from foo; -- foo\\n'\n           'select * from bar;')\n    stmts = sqlparse.parse(sql)\n    assert len(stmts) == 2\n    assert ''.join(str(q) for q in stmts) == sql\n    # make sure the comment belongs to first query\n    assert str(stmts[0]) == 'select * from foo; -- foo\\n'\n\n\ndef test_split_casewhen():\n    sql = (\"SELECT case when val = 1 then 2 else null end as foo;\\n\"\n           \"comment on table actor is 'The actor table.';\")\n    stmts = sqlparse.split(sql)\n    assert len(stmts) == 2\n\n\ndef test_split_casewhen_procedure(load_file):\n    # see issue580\n    stmts = sqlparse.split(load_file('casewhen_procedure.sql'))\n    assert len(stmts) == 2\n\n\ndef test_split_cursor_declare():\n    sql = ('DECLARE CURSOR \"foo\" AS SELECT 1;\\n'\n           'SELECT 2;')\n    stmts = sqlparse.split(sql)\n    assert len(stmts) == 2\n\n\ndef test_split_if_function():  # see issue 33\n    # don't let IF as a function confuse the splitter\n    sql = ('CREATE TEMPORARY TABLE tmp '\n           'SELECT IF(a=1, a, b) AS o FROM one; '\n           'SELECT t FROM two')\n    stmts = sqlparse.split(sql)\n    assert len(stmts) == 2\n\n\ndef test_split_stream():\n    stream = StringIO(\"SELECT 1; SELECT 2;\")\n    stmts = sqlparse.parsestream(stream)\n    assert isinstance(stmts, types.GeneratorType)\n    assert len(list(stmts)) == 2\n\n\ndef test_split_encoding_parsestream():\n    stream = StringIO(\"SELECT 1; SELECT 2;\")\n    stmts = list(sqlparse.parsestream(stream))\n    assert isinstance(stmts[0].tokens[0].value, str)\n\n\ndef test_split_unicode_parsestream():\n    stream = StringIO('SELECT \u00f6')\n    stmts = list(sqlparse.parsestream(stream))\n    assert str(stmts[0]) == 'SELECT \u00f6'\n\n\ndef test_split_simple():\n    stmts = sqlparse.split('select * from foo; select * from bar;')\n    assert len(stmts) == 2\n    assert stmts[0] == 'select * from foo;'\n    assert stmts[1] == 'select * from bar;'\n\n\ndef test_split_ignores_empty_newlines():\n    stmts = sqlparse.split('select foo;\\nselect bar;\\n')\n    assert len(stmts) == 2\n    assert stmts[0] == 'select foo;'\n    assert stmts[1] == 'select bar;'\n\n\ndef test_split_quotes_with_new_line():\n    stmts = sqlparse.split('select \"foo\\nbar\"')\n    assert len(stmts) == 1\n    assert stmts[0] == 'select \"foo\\nbar\"'\n\n    stmts = sqlparse.split(\"select 'foo\\n\\bar'\")\n    assert len(stmts) == 1\n    assert stmts[0] == \"select 'foo\\n\\bar'\"\n\n\ndef test_split_mysql_handler_for(load_file):\n    # see issue581\n    stmts = sqlparse.split(load_file('mysql_handler.sql'))\n    assert len(stmts) == 2\n"], "filenames": ["CHANGELOG", "sqlparse/keywords.py", "tests/test_split.py"], "buggy_code_start_loc": [2, 62, 21], "buggy_code_end_loc": [9, 65, 23], "fixing_code_start_loc": [3, 62, 21], "fixing_code_end_loc": [20, 65, 23], "type": "CWE-1333", "message": "sqlparse is a non-validating SQL parser module for Python. In affected versions the SQL parser contains a regular expression that is vulnerable to ReDoS (Regular Expression Denial of Service). This issue was introduced by commit `e75e358`. The vulnerability may lead to Denial of Service (DoS). This issues has been fixed in sqlparse 0.4.4 by commit `c457abd5f`. Users are advised to upgrade. There are no known workarounds for this issue.\n", "other": {"cve": {"id": "CVE-2023-30608", "sourceIdentifier": "security-advisories@github.com", "published": "2023-04-18T22:15:08.267", "lastModified": "2023-05-16T14:15:09.417", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "sqlparse is a non-validating SQL parser module for Python. In affected versions the SQL parser contains a regular expression that is vulnerable to ReDoS (Regular Expression Denial of Service). This issue was introduced by commit `e75e358`. The vulnerability may lead to Denial of Service (DoS). This issues has been fixed in sqlparse 0.4.4 by commit `c457abd5f`. Users are advised to upgrade. There are no known workarounds for this issue.\n"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-1333"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:sqlparse_project:sqlparse:*:*:*:*:*:python:*:*", "versionStartIncluding": "0.1.15", "versionEndIncluding": "0.4.4", "matchCriteriaId": "D5C04FBE-2FC6-407E-8D84-9D493B86E0EB"}]}]}], "references": [{"url": "https://github.com/andialbrecht/sqlparse/commit/c457abd5f097dd13fb21543381e7cfafe7d31cfb", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/andialbrecht/sqlparse/commit/e75e35869473832a1eb67772b1adfee2db11b85a", "source": "security-advisories@github.com", "tags": ["Product"]}, {"url": "https://github.com/andialbrecht/sqlparse/security/advisories/GHSA-rrm6-wvj7-cwh2", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2023/05/msg00017.html", "source": "security-advisories@github.com"}, {"url": "https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS", "source": "security-advisories@github.com", "tags": ["Not Applicable"]}]}, "github_commit_url": "https://github.com/andialbrecht/sqlparse/commit/c457abd5f097dd13fb21543381e7cfafe7d31cfb"}}
{"buggy_code": ["from collections import OrderedDict\nfrom typing import Set, Dict, Optional, List\n\nimport ariadne\nimport graphql\nfrom IPy import IP\nfrom graphql import GraphQLResolveInfo, GraphQLError\n\nfrom irrd.conf import get_setting, RPKI_IRR_PSEUDO_SOURCE\nfrom irrd.rpki.status import RPKIStatus\nfrom irrd.rpsl.rpsl_objects import OBJECT_CLASS_MAPPING, lookup_field_names\nfrom irrd.scopefilter.status import ScopeFilterStatus\nfrom irrd.server.access_check import is_client_permitted\nfrom irrd.storage.queries import RPSLDatabaseQuery, RPSLDatabaseJournalQuery\nfrom irrd.utils.text import snake_to_camel_case, remove_auth_hashes\nfrom .schema_generator import SchemaGenerator\nfrom ..query_resolver import QueryResolver\n\n\"\"\"\nResolvers resolve GraphQL queries, usually by translating them\nto a database query and then translating the results to an\nappropriate format for GraphQL.\n\"\"\"\n\n\nschema = SchemaGenerator()\nlookup_fields = lookup_field_names()\n\n\ndef resolve_rpsl_object_type(obj: Dict[str, str], *_) -> str:\n    \"\"\"\n    Find the GraphQL name for an object given its object class.\n    (GraphQL names match RPSL class names.)\n    \"\"\"\n    return OBJECT_CLASS_MAPPING[obj.get('objectClass', obj.get('object_class', ''))].__name__\n\n\n@ariadne.convert_kwargs_to_snake_case\ndef resolve_rpsl_objects(_, info: GraphQLResolveInfo, **kwargs):\n    \"\"\"\n    Resolve a `rpslObjects` query. This query has a considerable\n    number of parameters, each of which is applied to an RPSL\n    database query.\n    \"\"\"\n    low_specificity_kwargs = {\n        'object_class', 'rpki_status', 'scope_filter_status', 'sources', 'sql_trace'\n    }\n    # A query is sufficiently specific if it has other fields than listed above,\n    # except that rpki_status is sufficient if it is exclusively selecting on\n    # valid or invalid.\n    low_specificity = all([\n        not (set(kwargs.keys()) - low_specificity_kwargs),\n        kwargs.get('rpki_status', []) not in [[RPKIStatus.valid], [RPKIStatus.invalid]],\n    ])\n    if low_specificity:\n        raise ValueError('Your query must be more specific.')\n\n    if kwargs.get('sql_trace'):\n        info.context['sql_trace'] = True\n\n    query = RPSLDatabaseQuery(\n        column_names=_columns_for_graphql_selection(info),\n        ordered_by_sources=False,\n        enable_ordering=False\n    )\n\n    if 'record_limit' in kwargs:\n        query.limit(kwargs['record_limit'])\n    if 'rpsl_pk' in kwargs:\n        query.rpsl_pks(kwargs['rpsl_pk'])\n    if 'object_class' in kwargs:\n        query.object_classes(kwargs['object_class'])\n    if 'asn' in kwargs:\n        query.asns_first(kwargs['asn'])\n    if 'text_search' in kwargs:\n        query.text_search(kwargs['text_search'])\n    if 'rpki_status' in kwargs:\n        query.rpki_status(kwargs['rpki_status'])\n    else:\n        query.rpki_status([RPKIStatus.not_found, RPKIStatus.valid])\n    if 'scope_filter_status' in kwargs:\n        query.scopefilter_status(kwargs['scope_filter_status'])\n    else:\n        query.scopefilter_status([ScopeFilterStatus.in_scope])\n\n    all_valid_sources = set(get_setting('sources', {}).keys())\n    if get_setting('rpki.roa_source'):\n        all_valid_sources.add(RPKI_IRR_PSEUDO_SOURCE)\n    sources_default = set(get_setting('sources_default', []))\n\n    if 'sources' in kwargs:\n        query.sources(kwargs['sources'])\n    elif sources_default and sources_default != all_valid_sources:\n        query.sources(list(sources_default))\n\n    # All other parameters are generic lookup fields, like `members`\n    for attr, value in kwargs.items():\n        attr = attr.replace('_', '-')\n        if attr in lookup_fields:\n            query.lookup_attrs_in([attr], value)\n\n    ip_filters = [\n        'ip_exact', 'ip_less_specific', 'ip_more_specific', 'ip_less_specific_one_level', 'ip_any'\n    ]\n    for ip_filter in ip_filters:\n        if ip_filter in kwargs:\n            getattr(query, ip_filter)(IP(kwargs[ip_filter]))\n\n    return _rpsl_db_query_to_graphql_out(query, info)\n\n\ndef resolve_rpsl_object_mnt_by_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve mntByObjs on RPSL objects\"\"\"\n    return _resolve_subquery(rpsl_object, info, ['mntner'], pk_field='mntBy')\n\n\ndef resolve_rpsl_object_adminc_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve adminCObjs on RPSL objects\"\"\"\n    return _resolve_subquery(rpsl_object, info, ['role', 'person'], pk_field='adminC')\n\n\ndef resolve_rpsl_object_techc_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve techCObjs on RPSL objects\"\"\"\n    return _resolve_subquery(rpsl_object, info, ['role', 'person'], pk_field='techC')\n\n\ndef resolve_rpsl_object_members_by_ref_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve mbrsByRefObjs on RPSL objects\"\"\"\n    return _resolve_subquery(rpsl_object, info, ['mntner'], pk_field='mbrsByRef')\n\n\ndef resolve_rpsl_object_member_of_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve memberOfObjs on RPSL objects\"\"\"\n    object_klass = OBJECT_CLASS_MAPPING[rpsl_object['objectClass']]\n    sub_object_classes = object_klass.fields['member-of'].referring   # type: ignore\n    return _resolve_subquery(rpsl_object, info, sub_object_classes, pk_field='memberOf')\n\n\ndef resolve_rpsl_object_members_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve membersObjs on RPSL objects\"\"\"\n    object_klass = OBJECT_CLASS_MAPPING[rpsl_object['objectClass']]\n    sub_object_classes = object_klass.fields['members'].referring   # type: ignore\n    # The reference to an aut-num should not be fully resolved, as the\n    # reference is very weak.\n    if 'aut-num' in sub_object_classes:\n        sub_object_classes.remove('aut-num')\n    if 'inet-rtr' in sub_object_classes:\n        sub_object_classes.remove('inet-rtr')\n    return _resolve_subquery(rpsl_object, info, sub_object_classes, 'members', sticky_source=False)\n\n\ndef _resolve_subquery(rpsl_object, info: GraphQLResolveInfo, object_classes: List[str], pk_field: str, sticky_source=True):\n    \"\"\"\n    Resolve a subquery, like techCobjs, on an RPSL object, considering\n    a number of object classes, extracting the PK from pk_field.\n    If sticky_source is set, the referred object must be from the same source.\n    \"\"\"\n    pks = rpsl_object.get(pk_field)\n    if not pks:\n        return []\n    if not isinstance(pks, list):\n        pks = [pks]\n    query = RPSLDatabaseQuery(\n        column_names=_columns_for_graphql_selection(info),\n        ordered_by_sources=False,\n        enable_ordering=False\n    )\n    query.object_classes(object_classes).rpsl_pks(pks)\n    if sticky_source:\n        query.sources([rpsl_object['source']])\n    return _rpsl_db_query_to_graphql_out(query, info)\n\n\ndef resolve_rpsl_object_journal(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"\n    Resolve a journal subquery on an RPSL object.\n    \"\"\"\n    database_handler = info.context['request'].app.state.database_handler\n    access_list = f\"sources.{rpsl_object['source']}.nrtm_access_list\"\n    if not is_client_permitted(info.context['request'].client.host, access_list):\n        raise GraphQLError(f\"Access to journal denied for source {rpsl_object['source']}\")\n\n    query = RPSLDatabaseJournalQuery()\n    query.sources([rpsl_object['source']]).rpsl_pk(rpsl_object['rpslPk'])\n    for row in database_handler.execute_query(query, refresh_on_error=True):\n        response = {snake_to_camel_case(k): v for k, v in row.items()}\n        response['operation'] = response['operation'].name\n        if response['origin']:\n            response['origin'] = response['origin'].name\n        yield response\n\n\ndef _rpsl_db_query_to_graphql_out(query: RPSLDatabaseQuery, info: GraphQLResolveInfo):\n    \"\"\"\n    Given an RPSL database query, execute it and clean up the output\n    to be suitable to return to GraphQL.\n\n    Main changes are:\n    - Enum handling\n    - Adding the asn and prefix fields if applicable\n    - Ensuring the right fields are returned as a list of strings or a string\n    \"\"\"\n    database_handler = info.context['request'].app.state.database_handler\n    if info.context.get('sql_trace'):\n        if 'sql_queries' not in info.context:\n            info.context['sql_queries'] = [repr(query)]\n        else:\n            info.context['sql_queries'].append(repr(query))\n\n    for row in database_handler.execute_query(query, refresh_on_error=True):\n        graphql_result = {snake_to_camel_case(k): v for k, v in row.items() if k != 'parsed_data'}\n        if 'object_text' in row:\n            graphql_result['objectText'] = remove_auth_hashes(row['object_text'])\n        if 'rpki_status' in row:\n            graphql_result['rpkiStatus'] = row['rpki_status']\n        if row.get('ip_first') is not None and row.get('prefix_length'):\n            graphql_result['prefix'] = row['ip_first'] + '/' + str(row['prefix_length'])\n        if row.get('asn_first') is not None and row.get('asn_first') == row.get('asn_last'):\n            graphql_result['asn'] = row['asn_first']\n\n        object_type = resolve_rpsl_object_type(row)\n        for key, value in row.get('parsed_data', dict()).items():\n            if key == 'auth':\n                value = remove_auth_hashes(value)\n            graphql_type = schema.graphql_types[object_type][key]\n            if graphql_type == 'String' and isinstance(value, list):\n                value = '\\n'.join(value)\n            graphql_result[snake_to_camel_case(key)] = value\n        yield graphql_result\n\n\n@ariadne.convert_kwargs_to_snake_case\ndef resolve_database_status(_, info: GraphQLResolveInfo, sources: Optional[List[str]]=None):\n    \"\"\"Resolve a databaseStatus query\"\"\"\n    query_resolver = QueryResolver(\n        info.context['request'].app.state.preloader,\n        info.context['request'].app.state.database_handler\n    )\n    for name, data in query_resolver.database_status(sources=sources).items():\n        camel_case_data = OrderedDict(data)\n        camel_case_data['source'] = name\n        for key, value in data.items():\n            camel_case_data[snake_to_camel_case(key)] = value\n        yield camel_case_data\n\n\n@ariadne.convert_kwargs_to_snake_case\ndef resolve_asn_prefixes(_, info: GraphQLResolveInfo, asns: List[int], ip_version: Optional[int]=None, sources: Optional[List[str]]=None):\n    \"\"\"Resolve an asnPrefixes query\"\"\"\n    query_resolver = QueryResolver(\n        info.context['request'].app.state.preloader,\n        info.context['request'].app.state.database_handler\n    )\n    query_resolver.set_query_sources(sources)\n    for asn in asns:\n        yield dict(\n            asn=asn,\n            prefixes=list(query_resolver.routes_for_origin(f'AS{asn}', ip_version))\n        )\n\n\n@ariadne.convert_kwargs_to_snake_case\ndef resolve_as_set_prefixes(_, info: GraphQLResolveInfo, set_names: List[str], sources: Optional[List[str]]=None, ip_version: Optional[int]=None, exclude_sets: Optional[List[str]]=None, sql_trace: bool=False):\n    \"\"\"Resolve an asSetPrefixes query\"\"\"\n    query_resolver = QueryResolver(\n        info.context['request'].app.state.preloader,\n        info.context['request'].app.state.database_handler\n    )\n    if sql_trace:\n        query_resolver.enable_sql_trace()\n    set_names_set = {i.upper() for i in set_names}\n    exclude_sets_set = {i.upper() for i in exclude_sets} if exclude_sets else set()\n    query_resolver.set_query_sources(sources)\n    for set_name in set_names_set:\n        prefixes = list(query_resolver.routes_for_as_set(set_name, ip_version, exclude_sets=exclude_sets_set))\n        yield dict(rpslPk=set_name, prefixes=prefixes)\n    if sql_trace:\n        info.context['sql_queries'] = query_resolver.retrieve_sql_trace()\n\n\n@ariadne.convert_kwargs_to_snake_case\ndef resolve_recursive_set_members(_, info: GraphQLResolveInfo, set_names: List[str], depth: int=0, sources: Optional[List[str]]=None, exclude_sets: Optional[List[str]]=None, sql_trace: bool=False):\n    \"\"\"Resolve an recursiveSetMembers query\"\"\"\n    query_resolver = QueryResolver(\n        info.context['request'].app.state.preloader,\n        info.context['request'].app.state.database_handler\n    )\n    if sql_trace:\n        query_resolver.enable_sql_trace()\n    set_names_set = {i.upper() for i in set_names}\n    exclude_sets_set = {i.upper() for i in exclude_sets} if exclude_sets else set()\n    query_resolver.set_query_sources(sources)\n    for set_name in set_names_set:\n        results = query_resolver.members_for_set_per_source(set_name, exclude_sets=exclude_sets_set, depth=depth, recursive=True)\n        for source, members in results.items():\n            yield dict(rpslPk=set_name, rootSource=source, members=members)\n    if sql_trace:\n        info.context['sql_queries'] = query_resolver.retrieve_sql_trace()\n\n\ndef _columns_for_graphql_selection(info: GraphQLResolveInfo) -> Set[str]:\n    \"\"\"\n    Based on the selected GraphQL fields, determine which database\n    columns should be retrieved.\n    \"\"\"\n    # Some columns are always retrieved\n    columns = {'object_class', 'source', 'parsed_data', 'rpsl_pk'}\n    fields = _collect_predicate_names(info.field_nodes[0].selection_set.selections)  # type: ignore\n    requested_fields = {ariadne.convert_camel_case_to_snake(f) for f in fields}\n\n    for field in requested_fields:\n        if field in RPSLDatabaseQuery().columns:\n            columns.add(field)\n        if field == 'asn':\n            columns.add('asn_first')\n            columns.add('asn_last')\n        if field == 'prefix':\n            columns.add('ip_first')\n            columns.add('prefix_length')\n    return columns\n\n\n# https://github.com/mirumee/ariadne/issues/287\ndef _collect_predicate_names(selections):  # pragma: no cover\n    predicates = []\n    for selection in selections:\n        if isinstance(selection, graphql.InlineFragmentNode):\n            predicates.extend(_collect_predicate_names(selection.selection_set.selections))\n        else:\n            predicates.append(selection.name.value)\n\n    return predicates\n", "import re\nfrom typing import Iterator, Union, TextIO, Optional, List, Set\n\nfrom irrd.conf import PASSWORD_HASH_DUMMY_VALUE\nfrom irrd.rpsl.passwords import PASSWORD_HASHERS_ALL\n\nre_remove_passwords = re.compile(r'(%s)[^\\n]+' % '|'.join(PASSWORD_HASHERS_ALL.keys()), flags=re.IGNORECASE)\nre_remove_last_modified = re.compile(r'^last-modified: [^\\n]+\\n', flags=re.MULTILINE)\n\n\ndef remove_auth_hashes(input: Optional[str]):\n    if not input:\n        return input\n    # If there are no hashes, skip the RE for performance.\n    if not any([pw_hash in input for pw_hash in PASSWORD_HASHERS_ALL.keys()]):\n        return input\n    return re_remove_passwords.sub(r'\\1 %s  # Filtered for security' % PASSWORD_HASH_DUMMY_VALUE, input)\n\n\ndef remove_last_modified(rpsl_text: str):\n    \"\"\"\n    Remove all last-modified attributes from an RPSL text with less overhead\n    than using the full RPSL parser.\n    Assumes the last-modified value is single line. This is a safe assumption\n    when the input is guaranteed to have been generated by IRRd.\n    \"\"\"\n    return re_remove_last_modified.sub('', rpsl_text)\n\n\ndef splitline_unicodesafe(input: str) -> Iterator[str]:\n    \"\"\"\n    Split an input string by newlines, and return an iterator of the lines.\n\n    This is a replacement for Python's built-in splitlines, which also splits\n    on characters such as unicode line separator (U+2028). In RPSL, that should\n    not be considered a line separator.\n    \"\"\"\n    if not input:\n        return\n    for line in input.strip('\\n').split('\\n'):\n        yield line.strip('\\r')\n\n\ndef split_paragraphs_rpsl(input: Union[str, TextIO], strip_comments=True) -> Iterator[str]:\n    \"\"\"\n    Split an input into paragraphs, and return an iterator of the paragraphs.\n\n    A paragraph is a block of text, separated by at least one empty line.\n    Note that a line with other whitespace, e.g. a space, is not considered\n    empty.\n\n    If strip_comments=True, any line starting with % or # is entirely ignored,\n    both within a paragraph and between paragraphs.\n    \"\"\"\n    current_paragraph = ''\n    if isinstance(input, str):\n        generator = splitline_unicodesafe(input)\n    else:\n        generator = input\n\n    for line in generator:\n        line = line.strip('\\r\\n')\n        if strip_comments and line.startswith('%') or line.startswith('#'):\n            continue\n        if line:\n            current_paragraph += line + '\\n'\n        if not line:\n            if current_paragraph:\n                yield current_paragraph\n            current_paragraph = ''\n\n    if current_paragraph.strip():\n        yield current_paragraph\n\n\ndef snake_to_camel_case(snake: Union[Set[str], List[str], str]):\n    \"\"\"\n    Convert a snake case string to camel case, with lowercase first\n    letter. Can also accept a list or set of strings.\n    \"\"\"\n    def _str_to_camel_case(snake_str: str):\n        components = snake_str.replace('_', '-').split('-')\n        return components[0] + ''.join(x.title() for x in components[1:])\n\n    if isinstance(snake, (set, list)):\n        return [_str_to_camel_case(s) for s in snake]\n    return _str_to_camel_case(snake)\n\n\n# Turn \"IP('193.0.1.1/21') has invalid prefix length (21)\" into \"invalid prefix length (21)\"\nre_clean_ip_error = re.compile(r\"IP\\('[A-F0-9:./]+'\\) has \", re.IGNORECASE)\n\n\ndef clean_ip_value_error(value_error):\n    return re.sub(re_clean_ip_error, '', str(value_error))\n"], "fixing_code": ["from collections import OrderedDict\nfrom typing import Set, Dict, Optional, List\n\nimport ariadne\nimport graphql\nfrom IPy import IP\nfrom graphql import GraphQLResolveInfo, GraphQLError\n\nfrom irrd.conf import get_setting, RPKI_IRR_PSEUDO_SOURCE\nfrom irrd.rpki.status import RPKIStatus\nfrom irrd.rpsl.rpsl_objects import OBJECT_CLASS_MAPPING, lookup_field_names\nfrom irrd.scopefilter.status import ScopeFilterStatus\nfrom irrd.server.access_check import is_client_permitted\nfrom irrd.storage.queries import RPSLDatabaseQuery, RPSLDatabaseJournalQuery\nfrom irrd.utils.text import snake_to_camel_case, remove_auth_hashes\nfrom .schema_generator import SchemaGenerator\nfrom ..query_resolver import QueryResolver\n\n\"\"\"\nResolvers resolve GraphQL queries, usually by translating them\nto a database query and then translating the results to an\nappropriate format for GraphQL.\n\"\"\"\n\n\nschema = SchemaGenerator()\nlookup_fields = lookup_field_names()\n\n\ndef resolve_rpsl_object_type(obj: Dict[str, str], *_) -> str:\n    \"\"\"\n    Find the GraphQL name for an object given its object class.\n    (GraphQL names match RPSL class names.)\n    \"\"\"\n    return OBJECT_CLASS_MAPPING[obj.get('objectClass', obj.get('object_class', ''))].__name__\n\n\n@ariadne.convert_kwargs_to_snake_case\ndef resolve_rpsl_objects(_, info: GraphQLResolveInfo, **kwargs):\n    \"\"\"\n    Resolve a `rpslObjects` query. This query has a considerable\n    number of parameters, each of which is applied to an RPSL\n    database query.\n    \"\"\"\n    low_specificity_kwargs = {\n        'object_class', 'rpki_status', 'scope_filter_status', 'sources', 'sql_trace'\n    }\n    # A query is sufficiently specific if it has other fields than listed above,\n    # except that rpki_status is sufficient if it is exclusively selecting on\n    # valid or invalid.\n    low_specificity = all([\n        not (set(kwargs.keys()) - low_specificity_kwargs),\n        kwargs.get('rpki_status', []) not in [[RPKIStatus.valid], [RPKIStatus.invalid]],\n    ])\n    if low_specificity:\n        raise ValueError('Your query must be more specific.')\n\n    if kwargs.get('sql_trace'):\n        info.context['sql_trace'] = True\n\n    query = RPSLDatabaseQuery(\n        column_names=_columns_for_graphql_selection(info),\n        ordered_by_sources=False,\n        enable_ordering=False\n    )\n\n    if 'record_limit' in kwargs:\n        query.limit(kwargs['record_limit'])\n    if 'rpsl_pk' in kwargs:\n        query.rpsl_pks(kwargs['rpsl_pk'])\n    if 'object_class' in kwargs:\n        query.object_classes(kwargs['object_class'])\n    if 'asn' in kwargs:\n        query.asns_first(kwargs['asn'])\n    if 'text_search' in kwargs:\n        query.text_search(kwargs['text_search'])\n    if 'rpki_status' in kwargs:\n        query.rpki_status(kwargs['rpki_status'])\n    else:\n        query.rpki_status([RPKIStatus.not_found, RPKIStatus.valid])\n    if 'scope_filter_status' in kwargs:\n        query.scopefilter_status(kwargs['scope_filter_status'])\n    else:\n        query.scopefilter_status([ScopeFilterStatus.in_scope])\n\n    all_valid_sources = set(get_setting('sources', {}).keys())\n    if get_setting('rpki.roa_source'):\n        all_valid_sources.add(RPKI_IRR_PSEUDO_SOURCE)\n    sources_default = set(get_setting('sources_default', []))\n\n    if 'sources' in kwargs:\n        query.sources(kwargs['sources'])\n    elif sources_default and sources_default != all_valid_sources:\n        query.sources(list(sources_default))\n\n    # All other parameters are generic lookup fields, like `members`\n    for attr, value in kwargs.items():\n        attr = attr.replace('_', '-')\n        if attr in lookup_fields:\n            query.lookup_attrs_in([attr], value)\n\n    ip_filters = [\n        'ip_exact', 'ip_less_specific', 'ip_more_specific', 'ip_less_specific_one_level', 'ip_any'\n    ]\n    for ip_filter in ip_filters:\n        if ip_filter in kwargs:\n            getattr(query, ip_filter)(IP(kwargs[ip_filter]))\n\n    return _rpsl_db_query_to_graphql_out(query, info)\n\n\ndef resolve_rpsl_object_mnt_by_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve mntByObjs on RPSL objects\"\"\"\n    return _resolve_subquery(rpsl_object, info, ['mntner'], pk_field='mntBy')\n\n\ndef resolve_rpsl_object_adminc_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve adminCObjs on RPSL objects\"\"\"\n    return _resolve_subquery(rpsl_object, info, ['role', 'person'], pk_field='adminC')\n\n\ndef resolve_rpsl_object_techc_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve techCObjs on RPSL objects\"\"\"\n    return _resolve_subquery(rpsl_object, info, ['role', 'person'], pk_field='techC')\n\n\ndef resolve_rpsl_object_members_by_ref_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve mbrsByRefObjs on RPSL objects\"\"\"\n    return _resolve_subquery(rpsl_object, info, ['mntner'], pk_field='mbrsByRef')\n\n\ndef resolve_rpsl_object_member_of_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve memberOfObjs on RPSL objects\"\"\"\n    object_klass = OBJECT_CLASS_MAPPING[rpsl_object['objectClass']]\n    sub_object_classes = object_klass.fields['member-of'].referring   # type: ignore\n    return _resolve_subquery(rpsl_object, info, sub_object_classes, pk_field='memberOf')\n\n\ndef resolve_rpsl_object_members_objs(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"Resolve membersObjs on RPSL objects\"\"\"\n    object_klass = OBJECT_CLASS_MAPPING[rpsl_object['objectClass']]\n    sub_object_classes = object_klass.fields['members'].referring   # type: ignore\n    # The reference to an aut-num should not be fully resolved, as the\n    # reference is very weak.\n    if 'aut-num' in sub_object_classes:\n        sub_object_classes.remove('aut-num')\n    if 'inet-rtr' in sub_object_classes:\n        sub_object_classes.remove('inet-rtr')\n    return _resolve_subquery(rpsl_object, info, sub_object_classes, 'members', sticky_source=False)\n\n\ndef _resolve_subquery(rpsl_object, info: GraphQLResolveInfo, object_classes: List[str], pk_field: str, sticky_source=True):\n    \"\"\"\n    Resolve a subquery, like techCobjs, on an RPSL object, considering\n    a number of object classes, extracting the PK from pk_field.\n    If sticky_source is set, the referred object must be from the same source.\n    \"\"\"\n    pks = rpsl_object.get(pk_field)\n    if not pks:\n        return []\n    if not isinstance(pks, list):\n        pks = [pks]\n    query = RPSLDatabaseQuery(\n        column_names=_columns_for_graphql_selection(info),\n        ordered_by_sources=False,\n        enable_ordering=False\n    )\n    query.object_classes(object_classes).rpsl_pks(pks)\n    if sticky_source:\n        query.sources([rpsl_object['source']])\n    return _rpsl_db_query_to_graphql_out(query, info)\n\n\ndef resolve_rpsl_object_journal(rpsl_object, info: GraphQLResolveInfo):\n    \"\"\"\n    Resolve a journal subquery on an RPSL object.\n    \"\"\"\n    database_handler = info.context['request'].app.state.database_handler\n    access_list = f\"sources.{rpsl_object['source']}.nrtm_access_list\"\n    if not is_client_permitted(info.context['request'].client.host, access_list):\n        raise GraphQLError(f\"Access to journal denied for source {rpsl_object['source']}\")\n\n    query = RPSLDatabaseJournalQuery()\n    query.sources([rpsl_object['source']]).rpsl_pk(rpsl_object['rpslPk'])\n    for row in database_handler.execute_query(query, refresh_on_error=True):\n        response = {snake_to_camel_case(k): v for k, v in row.items()}\n        response['operation'] = response['operation'].name\n        if response['origin']:\n            response['origin'] = response['origin'].name\n        if response['objectText']:\n            response['objectText'] = remove_auth_hashes(response['objectText'])\n        yield response\n\n\ndef _rpsl_db_query_to_graphql_out(query: RPSLDatabaseQuery, info: GraphQLResolveInfo):\n    \"\"\"\n    Given an RPSL database query, execute it and clean up the output\n    to be suitable to return to GraphQL.\n\n    Main changes are:\n    - Enum handling\n    - Adding the asn and prefix fields if applicable\n    - Ensuring the right fields are returned as a list of strings or a string\n    \"\"\"\n    database_handler = info.context['request'].app.state.database_handler\n    if info.context.get('sql_trace'):\n        if 'sql_queries' not in info.context:\n            info.context['sql_queries'] = [repr(query)]\n        else:\n            info.context['sql_queries'].append(repr(query))\n\n    for row in database_handler.execute_query(query, refresh_on_error=True):\n        graphql_result = {snake_to_camel_case(k): v for k, v in row.items() if k != 'parsed_data'}\n        if 'object_text' in row:\n            graphql_result['objectText'] = remove_auth_hashes(row['object_text'])\n        if 'rpki_status' in row:\n            graphql_result['rpkiStatus'] = row['rpki_status']\n        if row.get('ip_first') is not None and row.get('prefix_length'):\n            graphql_result['prefix'] = row['ip_first'] + '/' + str(row['prefix_length'])\n        if row.get('asn_first') is not None and row.get('asn_first') == row.get('asn_last'):\n            graphql_result['asn'] = row['asn_first']\n\n        object_type = resolve_rpsl_object_type(row)\n        for key, value in row.get('parsed_data', dict()).items():\n            if key == 'auth':\n                value = [remove_auth_hashes(v) for v in value]\n            graphql_type = schema.graphql_types[object_type][key]\n            if graphql_type == 'String' and isinstance(value, list):\n                value = '\\n'.join(value)\n            graphql_result[snake_to_camel_case(key)] = value\n        yield graphql_result\n\n\n@ariadne.convert_kwargs_to_snake_case\ndef resolve_database_status(_, info: GraphQLResolveInfo, sources: Optional[List[str]]=None):\n    \"\"\"Resolve a databaseStatus query\"\"\"\n    query_resolver = QueryResolver(\n        info.context['request'].app.state.preloader,\n        info.context['request'].app.state.database_handler\n    )\n    for name, data in query_resolver.database_status(sources=sources).items():\n        camel_case_data = OrderedDict(data)\n        camel_case_data['source'] = name\n        for key, value in data.items():\n            camel_case_data[snake_to_camel_case(key)] = value\n        yield camel_case_data\n\n\n@ariadne.convert_kwargs_to_snake_case\ndef resolve_asn_prefixes(_, info: GraphQLResolveInfo, asns: List[int], ip_version: Optional[int]=None, sources: Optional[List[str]]=None):\n    \"\"\"Resolve an asnPrefixes query\"\"\"\n    query_resolver = QueryResolver(\n        info.context['request'].app.state.preloader,\n        info.context['request'].app.state.database_handler\n    )\n    query_resolver.set_query_sources(sources)\n    for asn in asns:\n        yield dict(\n            asn=asn,\n            prefixes=list(query_resolver.routes_for_origin(f'AS{asn}', ip_version))\n        )\n\n\n@ariadne.convert_kwargs_to_snake_case\ndef resolve_as_set_prefixes(_, info: GraphQLResolveInfo, set_names: List[str], sources: Optional[List[str]]=None, ip_version: Optional[int]=None, exclude_sets: Optional[List[str]]=None, sql_trace: bool=False):\n    \"\"\"Resolve an asSetPrefixes query\"\"\"\n    query_resolver = QueryResolver(\n        info.context['request'].app.state.preloader,\n        info.context['request'].app.state.database_handler\n    )\n    if sql_trace:\n        query_resolver.enable_sql_trace()\n    set_names_set = {i.upper() for i in set_names}\n    exclude_sets_set = {i.upper() for i in exclude_sets} if exclude_sets else set()\n    query_resolver.set_query_sources(sources)\n    for set_name in set_names_set:\n        prefixes = list(query_resolver.routes_for_as_set(set_name, ip_version, exclude_sets=exclude_sets_set))\n        yield dict(rpslPk=set_name, prefixes=prefixes)\n    if sql_trace:\n        info.context['sql_queries'] = query_resolver.retrieve_sql_trace()\n\n\n@ariadne.convert_kwargs_to_snake_case\ndef resolve_recursive_set_members(_, info: GraphQLResolveInfo, set_names: List[str], depth: int=0, sources: Optional[List[str]]=None, exclude_sets: Optional[List[str]]=None, sql_trace: bool=False):\n    \"\"\"Resolve an recursiveSetMembers query\"\"\"\n    query_resolver = QueryResolver(\n        info.context['request'].app.state.preloader,\n        info.context['request'].app.state.database_handler\n    )\n    if sql_trace:\n        query_resolver.enable_sql_trace()\n    set_names_set = {i.upper() for i in set_names}\n    exclude_sets_set = {i.upper() for i in exclude_sets} if exclude_sets else set()\n    query_resolver.set_query_sources(sources)\n    for set_name in set_names_set:\n        results = query_resolver.members_for_set_per_source(set_name, exclude_sets=exclude_sets_set, depth=depth, recursive=True)\n        for source, members in results.items():\n            yield dict(rpslPk=set_name, rootSource=source, members=members)\n    if sql_trace:\n        info.context['sql_queries'] = query_resolver.retrieve_sql_trace()\n\n\ndef _columns_for_graphql_selection(info: GraphQLResolveInfo) -> Set[str]:\n    \"\"\"\n    Based on the selected GraphQL fields, determine which database\n    columns should be retrieved.\n    \"\"\"\n    # Some columns are always retrieved\n    columns = {'object_class', 'source', 'parsed_data', 'rpsl_pk'}\n    fields = _collect_predicate_names(info.field_nodes[0].selection_set.selections)  # type: ignore\n    requested_fields = {ariadne.convert_camel_case_to_snake(f) for f in fields}\n\n    for field in requested_fields:\n        if field in RPSLDatabaseQuery().columns:\n            columns.add(field)\n        if field == 'asn':\n            columns.add('asn_first')\n            columns.add('asn_last')\n        if field == 'prefix':\n            columns.add('ip_first')\n            columns.add('prefix_length')\n    return columns\n\n\n# https://github.com/mirumee/ariadne/issues/287\ndef _collect_predicate_names(selections):  # pragma: no cover\n    predicates = []\n    for selection in selections:\n        if isinstance(selection, graphql.InlineFragmentNode):\n            predicates.extend(_collect_predicate_names(selection.selection_set.selections))\n        else:\n            predicates.append(selection.name.value)\n\n    return predicates\n", "import re\nfrom typing import Iterator, Union, TextIO, Optional, List, Set\n\nfrom irrd.conf import PASSWORD_HASH_DUMMY_VALUE\nfrom irrd.rpsl.passwords import PASSWORD_HASHERS_ALL\n\nre_remove_passwords = re.compile(r'(%s)[^\\n]+' % '|'.join(PASSWORD_HASHERS_ALL.keys()), flags=re.IGNORECASE)\nre_remove_last_modified = re.compile(r'^last-modified: [^\\n]+\\n', flags=re.MULTILINE)\n\n\ndef remove_auth_hashes(input: Optional[str]):\n    if not input:\n        return input\n    # If there are no hashes, skip the RE for performance.\n    input_lower = input.lower()\n    if not any([pw_hash.lower() in input_lower for pw_hash in PASSWORD_HASHERS_ALL.keys()]):\n        return input\n    return re_remove_passwords.sub(r'\\1 %s  # Filtered for security' % PASSWORD_HASH_DUMMY_VALUE, input)\n\n\ndef remove_last_modified(rpsl_text: str):\n    \"\"\"\n    Remove all last-modified attributes from an RPSL text with less overhead\n    than using the full RPSL parser.\n    Assumes the last-modified value is single line. This is a safe assumption\n    when the input is guaranteed to have been generated by IRRd.\n    \"\"\"\n    return re_remove_last_modified.sub('', rpsl_text)\n\n\ndef splitline_unicodesafe(input: str) -> Iterator[str]:\n    \"\"\"\n    Split an input string by newlines, and return an iterator of the lines.\n\n    This is a replacement for Python's built-in splitlines, which also splits\n    on characters such as unicode line separator (U+2028). In RPSL, that should\n    not be considered a line separator.\n    \"\"\"\n    if not input:\n        return\n    for line in input.strip('\\n').split('\\n'):\n        yield line.strip('\\r')\n\n\ndef split_paragraphs_rpsl(input: Union[str, TextIO], strip_comments=True) -> Iterator[str]:\n    \"\"\"\n    Split an input into paragraphs, and return an iterator of the paragraphs.\n\n    A paragraph is a block of text, separated by at least one empty line.\n    Note that a line with other whitespace, e.g. a space, is not considered\n    empty.\n\n    If strip_comments=True, any line starting with % or # is entirely ignored,\n    both within a paragraph and between paragraphs.\n    \"\"\"\n    current_paragraph = ''\n    if isinstance(input, str):\n        generator = splitline_unicodesafe(input)\n    else:\n        generator = input\n\n    for line in generator:\n        line = line.strip('\\r\\n')\n        if strip_comments and line.startswith('%') or line.startswith('#'):\n            continue\n        if line:\n            current_paragraph += line + '\\n'\n        if not line:\n            if current_paragraph:\n                yield current_paragraph\n            current_paragraph = ''\n\n    if current_paragraph.strip():\n        yield current_paragraph\n\n\ndef snake_to_camel_case(snake: Union[Set[str], List[str], str]):\n    \"\"\"\n    Convert a snake case string to camel case, with lowercase first\n    letter. Can also accept a list or set of strings.\n    \"\"\"\n    def _str_to_camel_case(snake_str: str):\n        components = snake_str.replace('_', '-').split('-')\n        return components[0] + ''.join(x.title() for x in components[1:])\n\n    if isinstance(snake, (set, list)):\n        return [_str_to_camel_case(s) for s in snake]\n    return _str_to_camel_case(snake)\n\n\n# Turn \"IP('193.0.1.1/21') has invalid prefix length (21)\" into \"invalid prefix length (21)\"\nre_clean_ip_error = re.compile(r\"IP\\('[A-F0-9:./]+'\\) has \", re.IGNORECASE)\n\n\ndef clean_ip_value_error(value_error):\n    return re.sub(re_clean_ip_error, '', str(value_error))\n"], "filenames": ["irrd/server/graphql/resolvers.py", "irrd/utils/text.py"], "buggy_code_start_loc": [189, 15], "buggy_code_end_loc": [225, 16], "fixing_code_start_loc": [190, 15], "fixing_code_end_loc": [227, 17], "type": "CWE-212", "message": "Internet Routing Registry daemon version 4 is an IRR database server, processing IRR objects in the RPSL format. IRRd did not always filter password hashes in query responses relating to `mntner` objects and database exports. This may have allowed adversaries to retrieve some of these hashes, perform a brute-force search for the clear-text passphrase, and use these to make unauthorised changes to affected IRR objects. This issue only affected instances that process password hashes, which means it is limited to IRRd instances that serve authoritative databases. IRRd instances operating solely as mirrors of other IRR databases are not affected. This has been fixed in IRRd 4.2.3 and the main branch. Versions in the 4.1.x series never were affected. Users of the 4.2.x series are strongly recommended to upgrade. There are no known workarounds for this issue.", "other": {"cve": {"id": "CVE-2022-24798", "sourceIdentifier": "security-advisories@github.com", "published": "2022-03-31T23:15:08.307", "lastModified": "2022-04-08T17:10:16.960", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Internet Routing Registry daemon version 4 is an IRR database server, processing IRR objects in the RPSL format. IRRd did not always filter password hashes in query responses relating to `mntner` objects and database exports. This may have allowed adversaries to retrieve some of these hashes, perform a brute-force search for the clear-text passphrase, and use these to make unauthorised changes to affected IRR objects. This issue only affected instances that process password hashes, which means it is limited to IRRd instances that serve authoritative databases. IRRd instances operating solely as mirrors of other IRR databases are not affected. This has been fixed in IRRd 4.2.3 and the main branch. Versions in the 4.1.x series never were affected. Users of the 4.2.x series are strongly recommended to upgrade. There are no known workarounds for this issue."}, {"lang": "es", "value": "El demonio Internet Routing Registry versi\u00f3n 4 es un servidor de base de datos IRR, que procesa objetos IRR en el formato RPSL. IRRd no siempre filtraba los hashes de las contrase\u00f1as en las respuestas de las consultas relacionadas con los objetos \"mntner\" y las exportaciones de la base de datos. Esto pod\u00eda permitir a adversarios recuperar algunos de estos hashes, llevar a cabo una b\u00fasqueda por fuerza bruta de la frase de contrase\u00f1a en texto sin cifrar y usarlos para realizar cambios no autorizados en los objetos IRR afectados. Este problema s\u00f3lo afect\u00f3 a las instancias que procesan hashes de contrase\u00f1as, lo que significa que se limita a las instancias de IRRd que sirven a bases de datos autorizadas. Las instancias de IRRd que funcionan \u00fanicamente como r\u00e9plicas de otras bases de datos de IRR no est\u00e1n afectadas. Esto ha sido corregido en IRRd versi\u00f3n 4.2.3 y en la rama principal. Las versiones de la serie 4.1.x nunca fueron afectadas. Es recomendado encarecidamente a usuarios de la serie 4.2.x actualizar. no se presentan medidas de mitigaci\u00f3n conocidas para este problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-212"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-212"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:internet_routing_registry_daemon_project:internet_routing_registry_daemon:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.2.0", "versionEndExcluding": "4.2.3", "matchCriteriaId": "C0DC5A79-EC7A-4CD8-92D7-EE997B70B7DB"}]}]}], "references": [{"url": "https://github.com/irrdnet/irrd/commit/0e41bae8d3d27316381a2fc7b466597230e35ec6", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/irrdnet/irrd/commit/fdffaf8dd71713f06e99dff417e6aa1e6fa84b70", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/irrdnet/irrd/security/advisories/GHSA-cqxx-66wh-8pjw", "source": "security-advisories@github.com", "tags": ["Release Notes", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/irrdnet/irrd/commit/0e41bae8d3d27316381a2fc7b466597230e35ec6"}}
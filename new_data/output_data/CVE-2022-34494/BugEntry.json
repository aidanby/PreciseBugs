{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0\n/*\n * Virtio-based remote processor messaging bus\n *\n * Copyright (C) 2011 Texas Instruments, Inc.\n * Copyright (C) 2011 Google, Inc.\n *\n * Ohad Ben-Cohen <ohad@wizery.com>\n * Brian Swetland <swetland@google.com>\n */\n\n#define pr_fmt(fmt) \"%s: \" fmt, __func__\n\n#include <linux/dma-mapping.h>\n#include <linux/idr.h>\n#include <linux/jiffies.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/rpmsg.h>\n#include <linux/rpmsg/byteorder.h>\n#include <linux/rpmsg/ns.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/sched.h>\n#include <linux/virtio.h>\n#include <linux/virtio_ids.h>\n#include <linux/virtio_config.h>\n#include <linux/wait.h>\n\n#include \"rpmsg_internal.h\"\n\n/**\n * struct virtproc_info - virtual remote processor state\n * @vdev:\tthe virtio device\n * @rvq:\trx virtqueue\n * @svq:\ttx virtqueue\n * @rbufs:\tkernel address of rx buffers\n * @sbufs:\tkernel address of tx buffers\n * @num_bufs:\ttotal number of buffers for rx and tx\n * @buf_size:   size of one rx or tx buffer\n * @last_sbuf:\tindex of last tx buffer used\n * @bufs_dma:\tdma base addr of the buffers\n * @tx_lock:\tprotects svq, sbufs and sleepers, to allow concurrent senders.\n *\t\tsending a message might require waking up a dozing remote\n *\t\tprocessor, which involves sleeping, hence the mutex.\n * @endpoints:\tidr of local endpoints, allows fast retrieval\n * @endpoints_lock: lock of the endpoints set\n * @sendq:\twait queue of sending contexts waiting for a tx buffers\n * @sleepers:\tnumber of senders that are waiting for a tx buffer\n *\n * This structure stores the rpmsg state of a given virtio remote processor\n * device (there might be several virtio proc devices for each physical\n * remote processor).\n */\nstruct virtproc_info {\n\tstruct virtio_device *vdev;\n\tstruct virtqueue *rvq, *svq;\n\tvoid *rbufs, *sbufs;\n\tunsigned int num_bufs;\n\tunsigned int buf_size;\n\tint last_sbuf;\n\tdma_addr_t bufs_dma;\n\tstruct mutex tx_lock;\n\tstruct idr endpoints;\n\tstruct mutex endpoints_lock;\n\twait_queue_head_t sendq;\n\tatomic_t sleepers;\n};\n\n/* The feature bitmap for virtio rpmsg */\n#define VIRTIO_RPMSG_F_NS\t0 /* RP supports name service notifications */\n\n/**\n * struct rpmsg_hdr - common header for all rpmsg messages\n * @src: source address\n * @dst: destination address\n * @reserved: reserved for future use\n * @len: length of payload (in bytes)\n * @flags: message flags\n * @data: @len bytes of message payload data\n *\n * Every message sent(/received) on the rpmsg bus begins with this header.\n */\nstruct rpmsg_hdr {\n\t__rpmsg32 src;\n\t__rpmsg32 dst;\n\t__rpmsg32 reserved;\n\t__rpmsg16 len;\n\t__rpmsg16 flags;\n\tu8 data[];\n} __packed;\n\n\n/**\n * struct virtio_rpmsg_channel - rpmsg channel descriptor\n * @rpdev: the rpmsg channel device\n * @vrp: the virtio remote processor device this channel belongs to\n *\n * This structure stores the channel that links the rpmsg device to the virtio\n * remote processor device.\n */\nstruct virtio_rpmsg_channel {\n\tstruct rpmsg_device rpdev;\n\n\tstruct virtproc_info *vrp;\n};\n\n#define to_virtio_rpmsg_channel(_rpdev) \\\n\tcontainer_of(_rpdev, struct virtio_rpmsg_channel, rpdev)\n\n/*\n * We're allocating buffers of 512 bytes each for communications. The\n * number of buffers will be computed from the number of buffers supported\n * by the vring, upto a maximum of 512 buffers (256 in each direction).\n *\n * Each buffer will have 16 bytes for the msg header and 496 bytes for\n * the payload.\n *\n * This will utilize a maximum total space of 256KB for the buffers.\n *\n * We might also want to add support for user-provided buffers in time.\n * This will allow bigger buffer size flexibility, and can also be used\n * to achieve zero-copy messaging.\n *\n * Note that these numbers are purely a decision of this driver - we\n * can change this without changing anything in the firmware of the remote\n * processor.\n */\n#define MAX_RPMSG_NUM_BUFS\t(512)\n#define MAX_RPMSG_BUF_SIZE\t(512)\n\n/*\n * Local addresses are dynamically allocated on-demand.\n * We do not dynamically assign addresses from the low 1024 range,\n * in order to reserve that address range for predefined services.\n */\n#define RPMSG_RESERVED_ADDRESSES\t(1024)\n\nstatic void virtio_rpmsg_destroy_ept(struct rpmsg_endpoint *ept);\nstatic int virtio_rpmsg_send(struct rpmsg_endpoint *ept, void *data, int len);\nstatic int virtio_rpmsg_sendto(struct rpmsg_endpoint *ept, void *data, int len,\n\t\t\t       u32 dst);\nstatic int virtio_rpmsg_send_offchannel(struct rpmsg_endpoint *ept, u32 src,\n\t\t\t\t\tu32 dst, void *data, int len);\nstatic int virtio_rpmsg_trysend(struct rpmsg_endpoint *ept, void *data, int len);\nstatic int virtio_rpmsg_trysendto(struct rpmsg_endpoint *ept, void *data,\n\t\t\t\t  int len, u32 dst);\nstatic int virtio_rpmsg_trysend_offchannel(struct rpmsg_endpoint *ept, u32 src,\n\t\t\t\t\t   u32 dst, void *data, int len);\nstatic ssize_t virtio_rpmsg_get_mtu(struct rpmsg_endpoint *ept);\nstatic struct rpmsg_device *__rpmsg_create_channel(struct virtproc_info *vrp,\n\t\t\t\t\t\t   struct rpmsg_channel_info *chinfo);\n\nstatic const struct rpmsg_endpoint_ops virtio_endpoint_ops = {\n\t.destroy_ept = virtio_rpmsg_destroy_ept,\n\t.send = virtio_rpmsg_send,\n\t.sendto = virtio_rpmsg_sendto,\n\t.send_offchannel = virtio_rpmsg_send_offchannel,\n\t.trysend = virtio_rpmsg_trysend,\n\t.trysendto = virtio_rpmsg_trysendto,\n\t.trysend_offchannel = virtio_rpmsg_trysend_offchannel,\n\t.get_mtu = virtio_rpmsg_get_mtu,\n};\n\n/**\n * rpmsg_sg_init - initialize scatterlist according to cpu address location\n * @sg: scatterlist to fill\n * @cpu_addr: virtual address of the buffer\n * @len: buffer length\n *\n * An internal function filling scatterlist according to virtual address\n * location (in vmalloc or in kernel).\n */\nstatic void\nrpmsg_sg_init(struct scatterlist *sg, void *cpu_addr, unsigned int len)\n{\n\tif (is_vmalloc_addr(cpu_addr)) {\n\t\tsg_init_table(sg, 1);\n\t\tsg_set_page(sg, vmalloc_to_page(cpu_addr), len,\n\t\t\t    offset_in_page(cpu_addr));\n\t} else {\n\t\tWARN_ON(!virt_addr_valid(cpu_addr));\n\t\tsg_init_one(sg, cpu_addr, len);\n\t}\n}\n\n/**\n * __ept_release() - deallocate an rpmsg endpoint\n * @kref: the ept's reference count\n *\n * This function deallocates an ept, and is invoked when its @kref refcount\n * drops to zero.\n *\n * Never invoke this function directly!\n */\nstatic void __ept_release(struct kref *kref)\n{\n\tstruct rpmsg_endpoint *ept = container_of(kref, struct rpmsg_endpoint,\n\t\t\t\t\t\t  refcount);\n\t/*\n\t * At this point no one holds a reference to ept anymore,\n\t * so we can directly free it\n\t */\n\tkfree(ept);\n}\n\n/* for more info, see below documentation of rpmsg_create_ept() */\nstatic struct rpmsg_endpoint *__rpmsg_create_ept(struct virtproc_info *vrp,\n\t\t\t\t\t\t struct rpmsg_device *rpdev,\n\t\t\t\t\t\t rpmsg_rx_cb_t cb,\n\t\t\t\t\t\t void *priv, u32 addr)\n{\n\tint id_min, id_max, id;\n\tstruct rpmsg_endpoint *ept;\n\tstruct device *dev = rpdev ? &rpdev->dev : &vrp->vdev->dev;\n\n\tept = kzalloc(sizeof(*ept), GFP_KERNEL);\n\tif (!ept)\n\t\treturn NULL;\n\n\tkref_init(&ept->refcount);\n\tmutex_init(&ept->cb_lock);\n\n\tept->rpdev = rpdev;\n\tept->cb = cb;\n\tept->priv = priv;\n\tept->ops = &virtio_endpoint_ops;\n\n\t/* do we need to allocate a local address ? */\n\tif (addr == RPMSG_ADDR_ANY) {\n\t\tid_min = RPMSG_RESERVED_ADDRESSES;\n\t\tid_max = 0;\n\t} else {\n\t\tid_min = addr;\n\t\tid_max = addr + 1;\n\t}\n\n\tmutex_lock(&vrp->endpoints_lock);\n\n\t/* bind the endpoint to an rpmsg address (and allocate one if needed) */\n\tid = idr_alloc(&vrp->endpoints, ept, id_min, id_max, GFP_KERNEL);\n\tif (id < 0) {\n\t\tdev_err(dev, \"idr_alloc failed: %d\\n\", id);\n\t\tgoto free_ept;\n\t}\n\tept->addr = id;\n\n\tmutex_unlock(&vrp->endpoints_lock);\n\n\treturn ept;\n\nfree_ept:\n\tmutex_unlock(&vrp->endpoints_lock);\n\tkref_put(&ept->refcount, __ept_release);\n\treturn NULL;\n}\n\nstatic struct rpmsg_device *virtio_rpmsg_create_channel(struct rpmsg_device *rpdev,\n\t\t\t\t\t\t\tstruct rpmsg_channel_info *chinfo)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\tstruct virtproc_info *vrp = vch->vrp;\n\n\treturn __rpmsg_create_channel(vrp, chinfo);\n}\n\nstatic int virtio_rpmsg_release_channel(struct rpmsg_device *rpdev,\n\t\t\t\t\tstruct rpmsg_channel_info *chinfo)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\tstruct virtproc_info *vrp = vch->vrp;\n\n\treturn rpmsg_unregister_device(&vrp->vdev->dev, chinfo);\n}\n\nstatic struct rpmsg_endpoint *virtio_rpmsg_create_ept(struct rpmsg_device *rpdev,\n\t\t\t\t\t\t      rpmsg_rx_cb_t cb,\n\t\t\t\t\t\t      void *priv,\n\t\t\t\t\t\t      struct rpmsg_channel_info chinfo)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\n\treturn __rpmsg_create_ept(vch->vrp, rpdev, cb, priv, chinfo.src);\n}\n\n/**\n * __rpmsg_destroy_ept() - destroy an existing rpmsg endpoint\n * @vrp: virtproc which owns this ept\n * @ept: endpoing to destroy\n *\n * An internal function which destroy an ept without assuming it is\n * bound to an rpmsg channel. This is needed for handling the internal\n * name service endpoint, which isn't bound to an rpmsg channel.\n * See also __rpmsg_create_ept().\n */\nstatic void\n__rpmsg_destroy_ept(struct virtproc_info *vrp, struct rpmsg_endpoint *ept)\n{\n\t/* make sure new inbound messages can't find this ept anymore */\n\tmutex_lock(&vrp->endpoints_lock);\n\tidr_remove(&vrp->endpoints, ept->addr);\n\tmutex_unlock(&vrp->endpoints_lock);\n\n\t/* make sure in-flight inbound messages won't invoke cb anymore */\n\tmutex_lock(&ept->cb_lock);\n\tept->cb = NULL;\n\tmutex_unlock(&ept->cb_lock);\n\n\tkref_put(&ept->refcount, __ept_release);\n}\n\nstatic void virtio_rpmsg_destroy_ept(struct rpmsg_endpoint *ept)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(ept->rpdev);\n\n\t__rpmsg_destroy_ept(vch->vrp, ept);\n}\n\nstatic int virtio_rpmsg_announce_create(struct rpmsg_device *rpdev)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\tstruct virtproc_info *vrp = vch->vrp;\n\tstruct device *dev = &rpdev->dev;\n\tint err = 0;\n\n\t/* need to tell remote processor's name service about this channel ? */\n\tif (rpdev->announce && rpdev->ept &&\n\t    virtio_has_feature(vrp->vdev, VIRTIO_RPMSG_F_NS)) {\n\t\tstruct rpmsg_ns_msg nsm;\n\n\t\tstrncpy(nsm.name, rpdev->id.name, RPMSG_NAME_SIZE);\n\t\tnsm.addr = cpu_to_rpmsg32(rpdev, rpdev->ept->addr);\n\t\tnsm.flags = cpu_to_rpmsg32(rpdev, RPMSG_NS_CREATE);\n\n\t\terr = rpmsg_sendto(rpdev->ept, &nsm, sizeof(nsm), RPMSG_NS_ADDR);\n\t\tif (err)\n\t\t\tdev_err(dev, \"failed to announce service %d\\n\", err);\n\t}\n\n\treturn err;\n}\n\nstatic int virtio_rpmsg_announce_destroy(struct rpmsg_device *rpdev)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\tstruct virtproc_info *vrp = vch->vrp;\n\tstruct device *dev = &rpdev->dev;\n\tint err = 0;\n\n\t/* tell remote processor's name service we're removing this channel */\n\tif (rpdev->announce && rpdev->ept &&\n\t    virtio_has_feature(vrp->vdev, VIRTIO_RPMSG_F_NS)) {\n\t\tstruct rpmsg_ns_msg nsm;\n\n\t\tstrncpy(nsm.name, rpdev->id.name, RPMSG_NAME_SIZE);\n\t\tnsm.addr = cpu_to_rpmsg32(rpdev, rpdev->ept->addr);\n\t\tnsm.flags = cpu_to_rpmsg32(rpdev, RPMSG_NS_DESTROY);\n\n\t\terr = rpmsg_sendto(rpdev->ept, &nsm, sizeof(nsm), RPMSG_NS_ADDR);\n\t\tif (err)\n\t\t\tdev_err(dev, \"failed to announce service %d\\n\", err);\n\t}\n\n\treturn err;\n}\n\nstatic const struct rpmsg_device_ops virtio_rpmsg_ops = {\n\t.create_channel = virtio_rpmsg_create_channel,\n\t.release_channel = virtio_rpmsg_release_channel,\n\t.create_ept = virtio_rpmsg_create_ept,\n\t.announce_create = virtio_rpmsg_announce_create,\n\t.announce_destroy = virtio_rpmsg_announce_destroy,\n};\n\nstatic void virtio_rpmsg_release_device(struct device *dev)\n{\n\tstruct rpmsg_device *rpdev = to_rpmsg_device(dev);\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\n\tkfree(vch);\n}\n\n/*\n * create an rpmsg channel using its name and address info.\n * this function will be used to create both static and dynamic\n * channels.\n */\nstatic struct rpmsg_device *__rpmsg_create_channel(struct virtproc_info *vrp,\n\t\t\t\t\t\t   struct rpmsg_channel_info *chinfo)\n{\n\tstruct virtio_rpmsg_channel *vch;\n\tstruct rpmsg_device *rpdev;\n\tstruct device *tmp, *dev = &vrp->vdev->dev;\n\tint ret;\n\n\t/* make sure a similar channel doesn't already exist */\n\ttmp = rpmsg_find_device(dev, chinfo);\n\tif (tmp) {\n\t\t/* decrement the matched device's refcount back */\n\t\tput_device(tmp);\n\t\tdev_err(dev, \"channel %s:%x:%x already exist\\n\",\n\t\t\t\tchinfo->name, chinfo->src, chinfo->dst);\n\t\treturn NULL;\n\t}\n\n\tvch = kzalloc(sizeof(*vch), GFP_KERNEL);\n\tif (!vch)\n\t\treturn NULL;\n\n\t/* Link the channel to our vrp */\n\tvch->vrp = vrp;\n\n\t/* Assign public information to the rpmsg_device */\n\trpdev = &vch->rpdev;\n\trpdev->src = chinfo->src;\n\trpdev->dst = chinfo->dst;\n\trpdev->ops = &virtio_rpmsg_ops;\n\trpdev->little_endian = virtio_is_little_endian(vrp->vdev);\n\n\t/*\n\t * rpmsg server channels has predefined local address (for now),\n\t * and their existence needs to be announced remotely\n\t */\n\trpdev->announce = rpdev->src != RPMSG_ADDR_ANY;\n\n\tstrncpy(rpdev->id.name, chinfo->name, RPMSG_NAME_SIZE);\n\n\trpdev->dev.parent = &vrp->vdev->dev;\n\trpdev->dev.release = virtio_rpmsg_release_device;\n\tret = rpmsg_register_device(rpdev);\n\tif (ret)\n\t\treturn NULL;\n\n\treturn rpdev;\n}\n\n/* super simple buffer \"allocator\" that is just enough for now */\nstatic void *get_a_tx_buf(struct virtproc_info *vrp)\n{\n\tunsigned int len;\n\tvoid *ret;\n\n\t/* support multiple concurrent senders */\n\tmutex_lock(&vrp->tx_lock);\n\n\t/*\n\t * either pick the next unused tx buffer\n\t * (half of our buffers are used for sending messages)\n\t */\n\tif (vrp->last_sbuf < vrp->num_bufs / 2)\n\t\tret = vrp->sbufs + vrp->buf_size * vrp->last_sbuf++;\n\t/* or recycle a used one */\n\telse\n\t\tret = virtqueue_get_buf(vrp->svq, &len);\n\n\tmutex_unlock(&vrp->tx_lock);\n\n\treturn ret;\n}\n\n/**\n * rpmsg_upref_sleepers() - enable \"tx-complete\" interrupts, if needed\n * @vrp: virtual remote processor state\n *\n * This function is called before a sender is blocked, waiting for\n * a tx buffer to become available.\n *\n * If we already have blocking senders, this function merely increases\n * the \"sleepers\" reference count, and exits.\n *\n * Otherwise, if this is the first sender to block, we also enable\n * virtio's tx callbacks, so we'd be immediately notified when a tx\n * buffer is consumed (we rely on virtio's tx callback in order\n * to wake up sleeping senders as soon as a tx buffer is used by the\n * remote processor).\n */\nstatic void rpmsg_upref_sleepers(struct virtproc_info *vrp)\n{\n\t/* support multiple concurrent senders */\n\tmutex_lock(&vrp->tx_lock);\n\n\t/* are we the first sleeping context waiting for tx buffers ? */\n\tif (atomic_inc_return(&vrp->sleepers) == 1)\n\t\t/* enable \"tx-complete\" interrupts before dozing off */\n\t\tvirtqueue_enable_cb(vrp->svq);\n\n\tmutex_unlock(&vrp->tx_lock);\n}\n\n/**\n * rpmsg_downref_sleepers() - disable \"tx-complete\" interrupts, if needed\n * @vrp: virtual remote processor state\n *\n * This function is called after a sender, that waited for a tx buffer\n * to become available, is unblocked.\n *\n * If we still have blocking senders, this function merely decreases\n * the \"sleepers\" reference count, and exits.\n *\n * Otherwise, if there are no more blocking senders, we also disable\n * virtio's tx callbacks, to avoid the overhead incurred with handling\n * those (now redundant) interrupts.\n */\nstatic void rpmsg_downref_sleepers(struct virtproc_info *vrp)\n{\n\t/* support multiple concurrent senders */\n\tmutex_lock(&vrp->tx_lock);\n\n\t/* are we the last sleeping context waiting for tx buffers ? */\n\tif (atomic_dec_and_test(&vrp->sleepers))\n\t\t/* disable \"tx-complete\" interrupts */\n\t\tvirtqueue_disable_cb(vrp->svq);\n\n\tmutex_unlock(&vrp->tx_lock);\n}\n\n/**\n * rpmsg_send_offchannel_raw() - send a message across to the remote processor\n * @rpdev: the rpmsg channel\n * @src: source address\n * @dst: destination address\n * @data: payload of message\n * @len: length of payload\n * @wait: indicates whether caller should block in case no TX buffers available\n *\n * This function is the base implementation for all of the rpmsg sending API.\n *\n * It will send @data of length @len to @dst, and say it's from @src. The\n * message will be sent to the remote processor which the @rpdev channel\n * belongs to.\n *\n * The message is sent using one of the TX buffers that are available for\n * communication with this remote processor.\n *\n * If @wait is true, the caller will be blocked until either a TX buffer is\n * available, or 15 seconds elapses (we don't want callers to\n * sleep indefinitely due to misbehaving remote processors), and in that\n * case -ERESTARTSYS is returned. The number '15' itself was picked\n * arbitrarily; there's little point in asking drivers to provide a timeout\n * value themselves.\n *\n * Otherwise, if @wait is false, and there are no TX buffers available,\n * the function will immediately fail, and -ENOMEM will be returned.\n *\n * Normally drivers shouldn't use this function directly; instead, drivers\n * should use the appropriate rpmsg_{try}send{to, _offchannel} API\n * (see include/linux/rpmsg.h).\n *\n * Return: 0 on success and an appropriate error value on failure.\n */\nstatic int rpmsg_send_offchannel_raw(struct rpmsg_device *rpdev,\n\t\t\t\t     u32 src, u32 dst,\n\t\t\t\t     void *data, int len, bool wait)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\tstruct virtproc_info *vrp = vch->vrp;\n\tstruct device *dev = &rpdev->dev;\n\tstruct scatterlist sg;\n\tstruct rpmsg_hdr *msg;\n\tint err;\n\n\t/* bcasting isn't allowed */\n\tif (src == RPMSG_ADDR_ANY || dst == RPMSG_ADDR_ANY) {\n\t\tdev_err(dev, \"invalid addr (src 0x%x, dst 0x%x)\\n\", src, dst);\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * We currently use fixed-sized buffers, and therefore the payload\n\t * length is limited.\n\t *\n\t * One of the possible improvements here is either to support\n\t * user-provided buffers (and then we can also support zero-copy\n\t * messaging), or to improve the buffer allocator, to support\n\t * variable-length buffer sizes.\n\t */\n\tif (len > vrp->buf_size - sizeof(struct rpmsg_hdr)) {\n\t\tdev_err(dev, \"message is too big (%d)\\n\", len);\n\t\treturn -EMSGSIZE;\n\t}\n\n\t/* grab a buffer */\n\tmsg = get_a_tx_buf(vrp);\n\tif (!msg && !wait)\n\t\treturn -ENOMEM;\n\n\t/* no free buffer ? wait for one (but bail after 15 seconds) */\n\twhile (!msg) {\n\t\t/* enable \"tx-complete\" interrupts, if not already enabled */\n\t\trpmsg_upref_sleepers(vrp);\n\n\t\t/*\n\t\t * sleep until a free buffer is available or 15 secs elapse.\n\t\t * the timeout period is not configurable because there's\n\t\t * little point in asking drivers to specify that.\n\t\t * if later this happens to be required, it'd be easy to add.\n\t\t */\n\t\terr = wait_event_interruptible_timeout(vrp->sendq,\n\t\t\t\t\t(msg = get_a_tx_buf(vrp)),\n\t\t\t\t\tmsecs_to_jiffies(15000));\n\n\t\t/* disable \"tx-complete\" interrupts if we're the last sleeper */\n\t\trpmsg_downref_sleepers(vrp);\n\n\t\t/* timeout ? */\n\t\tif (!err) {\n\t\t\tdev_err(dev, \"timeout waiting for a tx buffer\\n\");\n\t\t\treturn -ERESTARTSYS;\n\t\t}\n\t}\n\n\tmsg->len = cpu_to_rpmsg16(rpdev, len);\n\tmsg->flags = 0;\n\tmsg->src = cpu_to_rpmsg32(rpdev, src);\n\tmsg->dst = cpu_to_rpmsg32(rpdev, dst);\n\tmsg->reserved = 0;\n\tmemcpy(msg->data, data, len);\n\n\tdev_dbg(dev, \"TX From 0x%x, To 0x%x, Len %d, Flags %d, Reserved %d\\n\",\n\t\tsrc, dst, len, msg->flags, msg->reserved);\n#if defined(CONFIG_DYNAMIC_DEBUG)\n\tdynamic_hex_dump(\"rpmsg_virtio TX: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\t msg, sizeof(*msg) + len, true);\n#endif\n\n\trpmsg_sg_init(&sg, msg, sizeof(*msg) + len);\n\n\tmutex_lock(&vrp->tx_lock);\n\n\t/* add message to the remote processor's virtqueue */\n\terr = virtqueue_add_outbuf(vrp->svq, &sg, 1, msg, GFP_KERNEL);\n\tif (err) {\n\t\t/*\n\t\t * need to reclaim the buffer here, otherwise it's lost\n\t\t * (memory won't leak, but rpmsg won't use it again for TX).\n\t\t * this will wait for a buffer management overhaul.\n\t\t */\n\t\tdev_err(dev, \"virtqueue_add_outbuf failed: %d\\n\", err);\n\t\tgoto out;\n\t}\n\n\t/* tell the remote processor it has a pending message to read */\n\tvirtqueue_kick(vrp->svq);\nout:\n\tmutex_unlock(&vrp->tx_lock);\n\treturn err;\n}\n\nstatic int virtio_rpmsg_send(struct rpmsg_endpoint *ept, void *data, int len)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\tu32 src = ept->addr, dst = rpdev->dst;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, true);\n}\n\nstatic int virtio_rpmsg_sendto(struct rpmsg_endpoint *ept, void *data, int len,\n\t\t\t       u32 dst)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\tu32 src = ept->addr;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, true);\n}\n\nstatic int virtio_rpmsg_send_offchannel(struct rpmsg_endpoint *ept, u32 src,\n\t\t\t\t\tu32 dst, void *data, int len)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, true);\n}\n\nstatic int virtio_rpmsg_trysend(struct rpmsg_endpoint *ept, void *data, int len)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\tu32 src = ept->addr, dst = rpdev->dst;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, false);\n}\n\nstatic int virtio_rpmsg_trysendto(struct rpmsg_endpoint *ept, void *data,\n\t\t\t\t  int len, u32 dst)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\tu32 src = ept->addr;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, false);\n}\n\nstatic int virtio_rpmsg_trysend_offchannel(struct rpmsg_endpoint *ept, u32 src,\n\t\t\t\t\t   u32 dst, void *data, int len)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, false);\n}\n\nstatic ssize_t virtio_rpmsg_get_mtu(struct rpmsg_endpoint *ept)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\n\treturn vch->vrp->buf_size - sizeof(struct rpmsg_hdr);\n}\n\nstatic int rpmsg_recv_single(struct virtproc_info *vrp, struct device *dev,\n\t\t\t     struct rpmsg_hdr *msg, unsigned int len)\n{\n\tstruct rpmsg_endpoint *ept;\n\tstruct scatterlist sg;\n\tbool little_endian = virtio_is_little_endian(vrp->vdev);\n\tunsigned int msg_len = __rpmsg16_to_cpu(little_endian, msg->len);\n\tint err;\n\n\tdev_dbg(dev, \"From: 0x%x, To: 0x%x, Len: %d, Flags: %d, Reserved: %d\\n\",\n\t\t__rpmsg32_to_cpu(little_endian, msg->src),\n\t\t__rpmsg32_to_cpu(little_endian, msg->dst), msg_len,\n\t\t__rpmsg16_to_cpu(little_endian, msg->flags),\n\t\t__rpmsg32_to_cpu(little_endian, msg->reserved));\n#if defined(CONFIG_DYNAMIC_DEBUG)\n\tdynamic_hex_dump(\"rpmsg_virtio RX: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\t msg, sizeof(*msg) + msg_len, true);\n#endif\n\n\t/*\n\t * We currently use fixed-sized buffers, so trivially sanitize\n\t * the reported payload length.\n\t */\n\tif (len > vrp->buf_size ||\n\t    msg_len > (len - sizeof(struct rpmsg_hdr))) {\n\t\tdev_warn(dev, \"inbound msg too big: (%d, %d)\\n\", len, msg_len);\n\t\treturn -EINVAL;\n\t}\n\n\t/* use the dst addr to fetch the callback of the appropriate user */\n\tmutex_lock(&vrp->endpoints_lock);\n\n\tept = idr_find(&vrp->endpoints, __rpmsg32_to_cpu(little_endian, msg->dst));\n\n\t/* let's make sure no one deallocates ept while we use it */\n\tif (ept)\n\t\tkref_get(&ept->refcount);\n\n\tmutex_unlock(&vrp->endpoints_lock);\n\n\tif (ept) {\n\t\t/* make sure ept->cb doesn't go away while we use it */\n\t\tmutex_lock(&ept->cb_lock);\n\n\t\tif (ept->cb)\n\t\t\tept->cb(ept->rpdev, msg->data, msg_len, ept->priv,\n\t\t\t\t__rpmsg32_to_cpu(little_endian, msg->src));\n\n\t\tmutex_unlock(&ept->cb_lock);\n\n\t\t/* farewell, ept, we don't need you anymore */\n\t\tkref_put(&ept->refcount, __ept_release);\n\t} else\n\t\tdev_warn_ratelimited(dev, \"msg received with no recipient\\n\");\n\n\t/* publish the real size of the buffer */\n\trpmsg_sg_init(&sg, msg, vrp->buf_size);\n\n\t/* add the buffer back to the remote processor's virtqueue */\n\terr = virtqueue_add_inbuf(vrp->rvq, &sg, 1, msg, GFP_KERNEL);\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to add a virtqueue buffer: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\n/* called when an rx buffer is used, and it's time to digest a message */\nstatic void rpmsg_recv_done(struct virtqueue *rvq)\n{\n\tstruct virtproc_info *vrp = rvq->vdev->priv;\n\tstruct device *dev = &rvq->vdev->dev;\n\tstruct rpmsg_hdr *msg;\n\tunsigned int len, msgs_received = 0;\n\tint err;\n\n\tmsg = virtqueue_get_buf(rvq, &len);\n\tif (!msg) {\n\t\tdev_err(dev, \"uhm, incoming signal, but no used buffer ?\\n\");\n\t\treturn;\n\t}\n\n\twhile (msg) {\n\t\terr = rpmsg_recv_single(vrp, dev, msg, len);\n\t\tif (err)\n\t\t\tbreak;\n\n\t\tmsgs_received++;\n\n\t\tmsg = virtqueue_get_buf(rvq, &len);\n\t}\n\n\tdev_dbg(dev, \"Received %u messages\\n\", msgs_received);\n\n\t/* tell the remote processor we added another available rx buffer */\n\tif (msgs_received)\n\t\tvirtqueue_kick(vrp->rvq);\n}\n\n/*\n * This is invoked whenever the remote processor completed processing\n * a TX msg we just sent it, and the buffer is put back to the used ring.\n *\n * Normally, though, we suppress this \"tx complete\" interrupt in order to\n * avoid the incurred overhead.\n */\nstatic void rpmsg_xmit_done(struct virtqueue *svq)\n{\n\tstruct virtproc_info *vrp = svq->vdev->priv;\n\n\tdev_dbg(&svq->vdev->dev, \"%s\\n\", __func__);\n\n\t/* wake up potential senders that are waiting for a tx buffer */\n\twake_up_interruptible(&vrp->sendq);\n}\n\n/*\n * Called to expose to user a /dev/rpmsg_ctrlX interface allowing to\n * create endpoint-to-endpoint communication without associated RPMsg channel.\n * The endpoints are rattached to the ctrldev RPMsg device.\n */\nstatic struct rpmsg_device *rpmsg_virtio_add_ctrl_dev(struct virtio_device *vdev)\n{\n\tstruct virtproc_info *vrp = vdev->priv;\n\tstruct virtio_rpmsg_channel *vch;\n\tstruct rpmsg_device *rpdev_ctrl;\n\tint err = 0;\n\n\tvch = kzalloc(sizeof(*vch), GFP_KERNEL);\n\tif (!vch)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* Link the channel to the vrp */\n\tvch->vrp = vrp;\n\n\t/* Assign public information to the rpmsg_device */\n\trpdev_ctrl = &vch->rpdev;\n\trpdev_ctrl->ops = &virtio_rpmsg_ops;\n\n\trpdev_ctrl->dev.parent = &vrp->vdev->dev;\n\trpdev_ctrl->dev.release = virtio_rpmsg_release_device;\n\trpdev_ctrl->little_endian = virtio_is_little_endian(vrp->vdev);\n\n\terr = rpmsg_ctrldev_register_device(rpdev_ctrl);\n\tif (err) {\n\t\tkfree(vch);\n\t\treturn ERR_PTR(err);\n\t}\n\n\treturn rpdev_ctrl;\n}\n\nstatic void rpmsg_virtio_del_ctrl_dev(struct rpmsg_device *rpdev_ctrl)\n{\n\tif (!rpdev_ctrl)\n\t\treturn;\n\tkfree(to_virtio_rpmsg_channel(rpdev_ctrl));\n}\n\nstatic int rpmsg_probe(struct virtio_device *vdev)\n{\n\tvq_callback_t *vq_cbs[] = { rpmsg_recv_done, rpmsg_xmit_done };\n\tstatic const char * const names[] = { \"input\", \"output\" };\n\tstruct virtqueue *vqs[2];\n\tstruct virtproc_info *vrp;\n\tstruct virtio_rpmsg_channel *vch = NULL;\n\tstruct rpmsg_device *rpdev_ns, *rpdev_ctrl;\n\tvoid *bufs_va;\n\tint err = 0, i;\n\tsize_t total_buf_space;\n\tbool notify;\n\n\tvrp = kzalloc(sizeof(*vrp), GFP_KERNEL);\n\tif (!vrp)\n\t\treturn -ENOMEM;\n\n\tvrp->vdev = vdev;\n\n\tidr_init(&vrp->endpoints);\n\tmutex_init(&vrp->endpoints_lock);\n\tmutex_init(&vrp->tx_lock);\n\tinit_waitqueue_head(&vrp->sendq);\n\n\t/* We expect two virtqueues, rx and tx (and in this order) */\n\terr = virtio_find_vqs(vdev, 2, vqs, vq_cbs, names, NULL);\n\tif (err)\n\t\tgoto free_vrp;\n\n\tvrp->rvq = vqs[0];\n\tvrp->svq = vqs[1];\n\n\t/* we expect symmetric tx/rx vrings */\n\tWARN_ON(virtqueue_get_vring_size(vrp->rvq) !=\n\t\tvirtqueue_get_vring_size(vrp->svq));\n\n\t/* we need less buffers if vrings are small */\n\tif (virtqueue_get_vring_size(vrp->rvq) < MAX_RPMSG_NUM_BUFS / 2)\n\t\tvrp->num_bufs = virtqueue_get_vring_size(vrp->rvq) * 2;\n\telse\n\t\tvrp->num_bufs = MAX_RPMSG_NUM_BUFS;\n\n\tvrp->buf_size = MAX_RPMSG_BUF_SIZE;\n\n\ttotal_buf_space = vrp->num_bufs * vrp->buf_size;\n\n\t/* allocate coherent memory for the buffers */\n\tbufs_va = dma_alloc_coherent(vdev->dev.parent,\n\t\t\t\t     total_buf_space, &vrp->bufs_dma,\n\t\t\t\t     GFP_KERNEL);\n\tif (!bufs_va) {\n\t\terr = -ENOMEM;\n\t\tgoto vqs_del;\n\t}\n\n\tdev_dbg(&vdev->dev, \"buffers: va %pK, dma %pad\\n\",\n\t\tbufs_va, &vrp->bufs_dma);\n\n\t/* half of the buffers is dedicated for RX */\n\tvrp->rbufs = bufs_va;\n\n\t/* and half is dedicated for TX */\n\tvrp->sbufs = bufs_va + total_buf_space / 2;\n\n\t/* set up the receive buffers */\n\tfor (i = 0; i < vrp->num_bufs / 2; i++) {\n\t\tstruct scatterlist sg;\n\t\tvoid *cpu_addr = vrp->rbufs + i * vrp->buf_size;\n\n\t\trpmsg_sg_init(&sg, cpu_addr, vrp->buf_size);\n\n\t\terr = virtqueue_add_inbuf(vrp->rvq, &sg, 1, cpu_addr,\n\t\t\t\t\t  GFP_KERNEL);\n\t\tWARN_ON(err); /* sanity check; this can't really happen */\n\t}\n\n\t/* suppress \"tx-complete\" interrupts */\n\tvirtqueue_disable_cb(vrp->svq);\n\n\tvdev->priv = vrp;\n\n\trpdev_ctrl = rpmsg_virtio_add_ctrl_dev(vdev);\n\tif (IS_ERR(rpdev_ctrl)) {\n\t\terr = PTR_ERR(rpdev_ctrl);\n\t\tgoto free_coherent;\n\t}\n\n\t/* if supported by the remote processor, enable the name service */\n\tif (virtio_has_feature(vdev, VIRTIO_RPMSG_F_NS)) {\n\t\tvch = kzalloc(sizeof(*vch), GFP_KERNEL);\n\t\tif (!vch) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto free_ctrldev;\n\t\t}\n\n\t\t/* Link the channel to our vrp */\n\t\tvch->vrp = vrp;\n\n\t\t/* Assign public information to the rpmsg_device */\n\t\trpdev_ns = &vch->rpdev;\n\t\trpdev_ns->ops = &virtio_rpmsg_ops;\n\t\trpdev_ns->little_endian = virtio_is_little_endian(vrp->vdev);\n\n\t\trpdev_ns->dev.parent = &vrp->vdev->dev;\n\t\trpdev_ns->dev.release = virtio_rpmsg_release_device;\n\n\t\terr = rpmsg_ns_register_device(rpdev_ns);\n\t\tif (err)\n\t\t\t/* vch will be free in virtio_rpmsg_release_device() */\n\t\t\tgoto free_ctrldev;\n\t}\n\n\t/*\n\t * Prepare to kick but don't notify yet - we can't do this before\n\t * device is ready.\n\t */\n\tnotify = virtqueue_kick_prepare(vrp->rvq);\n\n\t/* From this point on, we can notify and get callbacks. */\n\tvirtio_device_ready(vdev);\n\n\t/* tell the remote processor it can start sending messages */\n\t/*\n\t * this might be concurrent with callbacks, but we are only\n\t * doing notify, not a full kick here, so that's ok.\n\t */\n\tif (notify)\n\t\tvirtqueue_notify(vrp->rvq);\n\n\tdev_info(&vdev->dev, \"rpmsg host is online\\n\");\n\n\treturn 0;\n\nfree_ctrldev:\n\trpmsg_virtio_del_ctrl_dev(rpdev_ctrl);\nfree_coherent:\n\tdma_free_coherent(vdev->dev.parent, total_buf_space,\n\t\t\t  bufs_va, vrp->bufs_dma);\nvqs_del:\n\tvdev->config->del_vqs(vrp->vdev);\nfree_vrp:\n\tkfree(vrp);\n\treturn err;\n}\n\nstatic int rpmsg_remove_device(struct device *dev, void *data)\n{\n\tdevice_unregister(dev);\n\n\treturn 0;\n}\n\nstatic void rpmsg_remove(struct virtio_device *vdev)\n{\n\tstruct virtproc_info *vrp = vdev->priv;\n\tsize_t total_buf_space = vrp->num_bufs * vrp->buf_size;\n\tint ret;\n\n\tvirtio_reset_device(vdev);\n\n\tret = device_for_each_child(&vdev->dev, NULL, rpmsg_remove_device);\n\tif (ret)\n\t\tdev_warn(&vdev->dev, \"can't remove rpmsg device: %d\\n\", ret);\n\n\tidr_destroy(&vrp->endpoints);\n\n\tvdev->config->del_vqs(vrp->vdev);\n\n\tdma_free_coherent(vdev->dev.parent, total_buf_space,\n\t\t\t  vrp->rbufs, vrp->bufs_dma);\n\n\tkfree(vrp);\n}\n\nstatic struct virtio_device_id id_table[] = {\n\t{ VIRTIO_ID_RPMSG, VIRTIO_DEV_ANY_ID },\n\t{ 0 },\n};\n\nstatic unsigned int features[] = {\n\tVIRTIO_RPMSG_F_NS,\n};\n\nstatic struct virtio_driver virtio_ipc_driver = {\n\t.feature_table\t= features,\n\t.feature_table_size = ARRAY_SIZE(features),\n\t.driver.name\t= KBUILD_MODNAME,\n\t.driver.owner\t= THIS_MODULE,\n\t.id_table\t= id_table,\n\t.probe\t\t= rpmsg_probe,\n\t.remove\t\t= rpmsg_remove,\n};\n\nstatic int __init rpmsg_init(void)\n{\n\tint ret;\n\n\tret = register_virtio_driver(&virtio_ipc_driver);\n\tif (ret)\n\t\tpr_err(\"failed to register virtio driver: %d\\n\", ret);\n\n\treturn ret;\n}\nsubsys_initcall(rpmsg_init);\n\nstatic void __exit rpmsg_fini(void)\n{\n\tunregister_virtio_driver(&virtio_ipc_driver);\n}\nmodule_exit(rpmsg_fini);\n\nMODULE_DEVICE_TABLE(virtio, id_table);\nMODULE_DESCRIPTION(\"Virtio-based remote processor messaging bus\");\nMODULE_LICENSE(\"GPL v2\");\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0\n/*\n * Virtio-based remote processor messaging bus\n *\n * Copyright (C) 2011 Texas Instruments, Inc.\n * Copyright (C) 2011 Google, Inc.\n *\n * Ohad Ben-Cohen <ohad@wizery.com>\n * Brian Swetland <swetland@google.com>\n */\n\n#define pr_fmt(fmt) \"%s: \" fmt, __func__\n\n#include <linux/dma-mapping.h>\n#include <linux/idr.h>\n#include <linux/jiffies.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/rpmsg.h>\n#include <linux/rpmsg/byteorder.h>\n#include <linux/rpmsg/ns.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/sched.h>\n#include <linux/virtio.h>\n#include <linux/virtio_ids.h>\n#include <linux/virtio_config.h>\n#include <linux/wait.h>\n\n#include \"rpmsg_internal.h\"\n\n/**\n * struct virtproc_info - virtual remote processor state\n * @vdev:\tthe virtio device\n * @rvq:\trx virtqueue\n * @svq:\ttx virtqueue\n * @rbufs:\tkernel address of rx buffers\n * @sbufs:\tkernel address of tx buffers\n * @num_bufs:\ttotal number of buffers for rx and tx\n * @buf_size:   size of one rx or tx buffer\n * @last_sbuf:\tindex of last tx buffer used\n * @bufs_dma:\tdma base addr of the buffers\n * @tx_lock:\tprotects svq, sbufs and sleepers, to allow concurrent senders.\n *\t\tsending a message might require waking up a dozing remote\n *\t\tprocessor, which involves sleeping, hence the mutex.\n * @endpoints:\tidr of local endpoints, allows fast retrieval\n * @endpoints_lock: lock of the endpoints set\n * @sendq:\twait queue of sending contexts waiting for a tx buffers\n * @sleepers:\tnumber of senders that are waiting for a tx buffer\n *\n * This structure stores the rpmsg state of a given virtio remote processor\n * device (there might be several virtio proc devices for each physical\n * remote processor).\n */\nstruct virtproc_info {\n\tstruct virtio_device *vdev;\n\tstruct virtqueue *rvq, *svq;\n\tvoid *rbufs, *sbufs;\n\tunsigned int num_bufs;\n\tunsigned int buf_size;\n\tint last_sbuf;\n\tdma_addr_t bufs_dma;\n\tstruct mutex tx_lock;\n\tstruct idr endpoints;\n\tstruct mutex endpoints_lock;\n\twait_queue_head_t sendq;\n\tatomic_t sleepers;\n};\n\n/* The feature bitmap for virtio rpmsg */\n#define VIRTIO_RPMSG_F_NS\t0 /* RP supports name service notifications */\n\n/**\n * struct rpmsg_hdr - common header for all rpmsg messages\n * @src: source address\n * @dst: destination address\n * @reserved: reserved for future use\n * @len: length of payload (in bytes)\n * @flags: message flags\n * @data: @len bytes of message payload data\n *\n * Every message sent(/received) on the rpmsg bus begins with this header.\n */\nstruct rpmsg_hdr {\n\t__rpmsg32 src;\n\t__rpmsg32 dst;\n\t__rpmsg32 reserved;\n\t__rpmsg16 len;\n\t__rpmsg16 flags;\n\tu8 data[];\n} __packed;\n\n\n/**\n * struct virtio_rpmsg_channel - rpmsg channel descriptor\n * @rpdev: the rpmsg channel device\n * @vrp: the virtio remote processor device this channel belongs to\n *\n * This structure stores the channel that links the rpmsg device to the virtio\n * remote processor device.\n */\nstruct virtio_rpmsg_channel {\n\tstruct rpmsg_device rpdev;\n\n\tstruct virtproc_info *vrp;\n};\n\n#define to_virtio_rpmsg_channel(_rpdev) \\\n\tcontainer_of(_rpdev, struct virtio_rpmsg_channel, rpdev)\n\n/*\n * We're allocating buffers of 512 bytes each for communications. The\n * number of buffers will be computed from the number of buffers supported\n * by the vring, upto a maximum of 512 buffers (256 in each direction).\n *\n * Each buffer will have 16 bytes for the msg header and 496 bytes for\n * the payload.\n *\n * This will utilize a maximum total space of 256KB for the buffers.\n *\n * We might also want to add support for user-provided buffers in time.\n * This will allow bigger buffer size flexibility, and can also be used\n * to achieve zero-copy messaging.\n *\n * Note that these numbers are purely a decision of this driver - we\n * can change this without changing anything in the firmware of the remote\n * processor.\n */\n#define MAX_RPMSG_NUM_BUFS\t(512)\n#define MAX_RPMSG_BUF_SIZE\t(512)\n\n/*\n * Local addresses are dynamically allocated on-demand.\n * We do not dynamically assign addresses from the low 1024 range,\n * in order to reserve that address range for predefined services.\n */\n#define RPMSG_RESERVED_ADDRESSES\t(1024)\n\nstatic void virtio_rpmsg_destroy_ept(struct rpmsg_endpoint *ept);\nstatic int virtio_rpmsg_send(struct rpmsg_endpoint *ept, void *data, int len);\nstatic int virtio_rpmsg_sendto(struct rpmsg_endpoint *ept, void *data, int len,\n\t\t\t       u32 dst);\nstatic int virtio_rpmsg_send_offchannel(struct rpmsg_endpoint *ept, u32 src,\n\t\t\t\t\tu32 dst, void *data, int len);\nstatic int virtio_rpmsg_trysend(struct rpmsg_endpoint *ept, void *data, int len);\nstatic int virtio_rpmsg_trysendto(struct rpmsg_endpoint *ept, void *data,\n\t\t\t\t  int len, u32 dst);\nstatic int virtio_rpmsg_trysend_offchannel(struct rpmsg_endpoint *ept, u32 src,\n\t\t\t\t\t   u32 dst, void *data, int len);\nstatic ssize_t virtio_rpmsg_get_mtu(struct rpmsg_endpoint *ept);\nstatic struct rpmsg_device *__rpmsg_create_channel(struct virtproc_info *vrp,\n\t\t\t\t\t\t   struct rpmsg_channel_info *chinfo);\n\nstatic const struct rpmsg_endpoint_ops virtio_endpoint_ops = {\n\t.destroy_ept = virtio_rpmsg_destroy_ept,\n\t.send = virtio_rpmsg_send,\n\t.sendto = virtio_rpmsg_sendto,\n\t.send_offchannel = virtio_rpmsg_send_offchannel,\n\t.trysend = virtio_rpmsg_trysend,\n\t.trysendto = virtio_rpmsg_trysendto,\n\t.trysend_offchannel = virtio_rpmsg_trysend_offchannel,\n\t.get_mtu = virtio_rpmsg_get_mtu,\n};\n\n/**\n * rpmsg_sg_init - initialize scatterlist according to cpu address location\n * @sg: scatterlist to fill\n * @cpu_addr: virtual address of the buffer\n * @len: buffer length\n *\n * An internal function filling scatterlist according to virtual address\n * location (in vmalloc or in kernel).\n */\nstatic void\nrpmsg_sg_init(struct scatterlist *sg, void *cpu_addr, unsigned int len)\n{\n\tif (is_vmalloc_addr(cpu_addr)) {\n\t\tsg_init_table(sg, 1);\n\t\tsg_set_page(sg, vmalloc_to_page(cpu_addr), len,\n\t\t\t    offset_in_page(cpu_addr));\n\t} else {\n\t\tWARN_ON(!virt_addr_valid(cpu_addr));\n\t\tsg_init_one(sg, cpu_addr, len);\n\t}\n}\n\n/**\n * __ept_release() - deallocate an rpmsg endpoint\n * @kref: the ept's reference count\n *\n * This function deallocates an ept, and is invoked when its @kref refcount\n * drops to zero.\n *\n * Never invoke this function directly!\n */\nstatic void __ept_release(struct kref *kref)\n{\n\tstruct rpmsg_endpoint *ept = container_of(kref, struct rpmsg_endpoint,\n\t\t\t\t\t\t  refcount);\n\t/*\n\t * At this point no one holds a reference to ept anymore,\n\t * so we can directly free it\n\t */\n\tkfree(ept);\n}\n\n/* for more info, see below documentation of rpmsg_create_ept() */\nstatic struct rpmsg_endpoint *__rpmsg_create_ept(struct virtproc_info *vrp,\n\t\t\t\t\t\t struct rpmsg_device *rpdev,\n\t\t\t\t\t\t rpmsg_rx_cb_t cb,\n\t\t\t\t\t\t void *priv, u32 addr)\n{\n\tint id_min, id_max, id;\n\tstruct rpmsg_endpoint *ept;\n\tstruct device *dev = rpdev ? &rpdev->dev : &vrp->vdev->dev;\n\n\tept = kzalloc(sizeof(*ept), GFP_KERNEL);\n\tif (!ept)\n\t\treturn NULL;\n\n\tkref_init(&ept->refcount);\n\tmutex_init(&ept->cb_lock);\n\n\tept->rpdev = rpdev;\n\tept->cb = cb;\n\tept->priv = priv;\n\tept->ops = &virtio_endpoint_ops;\n\n\t/* do we need to allocate a local address ? */\n\tif (addr == RPMSG_ADDR_ANY) {\n\t\tid_min = RPMSG_RESERVED_ADDRESSES;\n\t\tid_max = 0;\n\t} else {\n\t\tid_min = addr;\n\t\tid_max = addr + 1;\n\t}\n\n\tmutex_lock(&vrp->endpoints_lock);\n\n\t/* bind the endpoint to an rpmsg address (and allocate one if needed) */\n\tid = idr_alloc(&vrp->endpoints, ept, id_min, id_max, GFP_KERNEL);\n\tif (id < 0) {\n\t\tdev_err(dev, \"idr_alloc failed: %d\\n\", id);\n\t\tgoto free_ept;\n\t}\n\tept->addr = id;\n\n\tmutex_unlock(&vrp->endpoints_lock);\n\n\treturn ept;\n\nfree_ept:\n\tmutex_unlock(&vrp->endpoints_lock);\n\tkref_put(&ept->refcount, __ept_release);\n\treturn NULL;\n}\n\nstatic struct rpmsg_device *virtio_rpmsg_create_channel(struct rpmsg_device *rpdev,\n\t\t\t\t\t\t\tstruct rpmsg_channel_info *chinfo)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\tstruct virtproc_info *vrp = vch->vrp;\n\n\treturn __rpmsg_create_channel(vrp, chinfo);\n}\n\nstatic int virtio_rpmsg_release_channel(struct rpmsg_device *rpdev,\n\t\t\t\t\tstruct rpmsg_channel_info *chinfo)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\tstruct virtproc_info *vrp = vch->vrp;\n\n\treturn rpmsg_unregister_device(&vrp->vdev->dev, chinfo);\n}\n\nstatic struct rpmsg_endpoint *virtio_rpmsg_create_ept(struct rpmsg_device *rpdev,\n\t\t\t\t\t\t      rpmsg_rx_cb_t cb,\n\t\t\t\t\t\t      void *priv,\n\t\t\t\t\t\t      struct rpmsg_channel_info chinfo)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\n\treturn __rpmsg_create_ept(vch->vrp, rpdev, cb, priv, chinfo.src);\n}\n\n/**\n * __rpmsg_destroy_ept() - destroy an existing rpmsg endpoint\n * @vrp: virtproc which owns this ept\n * @ept: endpoing to destroy\n *\n * An internal function which destroy an ept without assuming it is\n * bound to an rpmsg channel. This is needed for handling the internal\n * name service endpoint, which isn't bound to an rpmsg channel.\n * See also __rpmsg_create_ept().\n */\nstatic void\n__rpmsg_destroy_ept(struct virtproc_info *vrp, struct rpmsg_endpoint *ept)\n{\n\t/* make sure new inbound messages can't find this ept anymore */\n\tmutex_lock(&vrp->endpoints_lock);\n\tidr_remove(&vrp->endpoints, ept->addr);\n\tmutex_unlock(&vrp->endpoints_lock);\n\n\t/* make sure in-flight inbound messages won't invoke cb anymore */\n\tmutex_lock(&ept->cb_lock);\n\tept->cb = NULL;\n\tmutex_unlock(&ept->cb_lock);\n\n\tkref_put(&ept->refcount, __ept_release);\n}\n\nstatic void virtio_rpmsg_destroy_ept(struct rpmsg_endpoint *ept)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(ept->rpdev);\n\n\t__rpmsg_destroy_ept(vch->vrp, ept);\n}\n\nstatic int virtio_rpmsg_announce_create(struct rpmsg_device *rpdev)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\tstruct virtproc_info *vrp = vch->vrp;\n\tstruct device *dev = &rpdev->dev;\n\tint err = 0;\n\n\t/* need to tell remote processor's name service about this channel ? */\n\tif (rpdev->announce && rpdev->ept &&\n\t    virtio_has_feature(vrp->vdev, VIRTIO_RPMSG_F_NS)) {\n\t\tstruct rpmsg_ns_msg nsm;\n\n\t\tstrncpy(nsm.name, rpdev->id.name, RPMSG_NAME_SIZE);\n\t\tnsm.addr = cpu_to_rpmsg32(rpdev, rpdev->ept->addr);\n\t\tnsm.flags = cpu_to_rpmsg32(rpdev, RPMSG_NS_CREATE);\n\n\t\terr = rpmsg_sendto(rpdev->ept, &nsm, sizeof(nsm), RPMSG_NS_ADDR);\n\t\tif (err)\n\t\t\tdev_err(dev, \"failed to announce service %d\\n\", err);\n\t}\n\n\treturn err;\n}\n\nstatic int virtio_rpmsg_announce_destroy(struct rpmsg_device *rpdev)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\tstruct virtproc_info *vrp = vch->vrp;\n\tstruct device *dev = &rpdev->dev;\n\tint err = 0;\n\n\t/* tell remote processor's name service we're removing this channel */\n\tif (rpdev->announce && rpdev->ept &&\n\t    virtio_has_feature(vrp->vdev, VIRTIO_RPMSG_F_NS)) {\n\t\tstruct rpmsg_ns_msg nsm;\n\n\t\tstrncpy(nsm.name, rpdev->id.name, RPMSG_NAME_SIZE);\n\t\tnsm.addr = cpu_to_rpmsg32(rpdev, rpdev->ept->addr);\n\t\tnsm.flags = cpu_to_rpmsg32(rpdev, RPMSG_NS_DESTROY);\n\n\t\terr = rpmsg_sendto(rpdev->ept, &nsm, sizeof(nsm), RPMSG_NS_ADDR);\n\t\tif (err)\n\t\t\tdev_err(dev, \"failed to announce service %d\\n\", err);\n\t}\n\n\treturn err;\n}\n\nstatic const struct rpmsg_device_ops virtio_rpmsg_ops = {\n\t.create_channel = virtio_rpmsg_create_channel,\n\t.release_channel = virtio_rpmsg_release_channel,\n\t.create_ept = virtio_rpmsg_create_ept,\n\t.announce_create = virtio_rpmsg_announce_create,\n\t.announce_destroy = virtio_rpmsg_announce_destroy,\n};\n\nstatic void virtio_rpmsg_release_device(struct device *dev)\n{\n\tstruct rpmsg_device *rpdev = to_rpmsg_device(dev);\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\n\tkfree(vch);\n}\n\n/*\n * create an rpmsg channel using its name and address info.\n * this function will be used to create both static and dynamic\n * channels.\n */\nstatic struct rpmsg_device *__rpmsg_create_channel(struct virtproc_info *vrp,\n\t\t\t\t\t\t   struct rpmsg_channel_info *chinfo)\n{\n\tstruct virtio_rpmsg_channel *vch;\n\tstruct rpmsg_device *rpdev;\n\tstruct device *tmp, *dev = &vrp->vdev->dev;\n\tint ret;\n\n\t/* make sure a similar channel doesn't already exist */\n\ttmp = rpmsg_find_device(dev, chinfo);\n\tif (tmp) {\n\t\t/* decrement the matched device's refcount back */\n\t\tput_device(tmp);\n\t\tdev_err(dev, \"channel %s:%x:%x already exist\\n\",\n\t\t\t\tchinfo->name, chinfo->src, chinfo->dst);\n\t\treturn NULL;\n\t}\n\n\tvch = kzalloc(sizeof(*vch), GFP_KERNEL);\n\tif (!vch)\n\t\treturn NULL;\n\n\t/* Link the channel to our vrp */\n\tvch->vrp = vrp;\n\n\t/* Assign public information to the rpmsg_device */\n\trpdev = &vch->rpdev;\n\trpdev->src = chinfo->src;\n\trpdev->dst = chinfo->dst;\n\trpdev->ops = &virtio_rpmsg_ops;\n\trpdev->little_endian = virtio_is_little_endian(vrp->vdev);\n\n\t/*\n\t * rpmsg server channels has predefined local address (for now),\n\t * and their existence needs to be announced remotely\n\t */\n\trpdev->announce = rpdev->src != RPMSG_ADDR_ANY;\n\n\tstrncpy(rpdev->id.name, chinfo->name, RPMSG_NAME_SIZE);\n\n\trpdev->dev.parent = &vrp->vdev->dev;\n\trpdev->dev.release = virtio_rpmsg_release_device;\n\tret = rpmsg_register_device(rpdev);\n\tif (ret)\n\t\treturn NULL;\n\n\treturn rpdev;\n}\n\n/* super simple buffer \"allocator\" that is just enough for now */\nstatic void *get_a_tx_buf(struct virtproc_info *vrp)\n{\n\tunsigned int len;\n\tvoid *ret;\n\n\t/* support multiple concurrent senders */\n\tmutex_lock(&vrp->tx_lock);\n\n\t/*\n\t * either pick the next unused tx buffer\n\t * (half of our buffers are used for sending messages)\n\t */\n\tif (vrp->last_sbuf < vrp->num_bufs / 2)\n\t\tret = vrp->sbufs + vrp->buf_size * vrp->last_sbuf++;\n\t/* or recycle a used one */\n\telse\n\t\tret = virtqueue_get_buf(vrp->svq, &len);\n\n\tmutex_unlock(&vrp->tx_lock);\n\n\treturn ret;\n}\n\n/**\n * rpmsg_upref_sleepers() - enable \"tx-complete\" interrupts, if needed\n * @vrp: virtual remote processor state\n *\n * This function is called before a sender is blocked, waiting for\n * a tx buffer to become available.\n *\n * If we already have blocking senders, this function merely increases\n * the \"sleepers\" reference count, and exits.\n *\n * Otherwise, if this is the first sender to block, we also enable\n * virtio's tx callbacks, so we'd be immediately notified when a tx\n * buffer is consumed (we rely on virtio's tx callback in order\n * to wake up sleeping senders as soon as a tx buffer is used by the\n * remote processor).\n */\nstatic void rpmsg_upref_sleepers(struct virtproc_info *vrp)\n{\n\t/* support multiple concurrent senders */\n\tmutex_lock(&vrp->tx_lock);\n\n\t/* are we the first sleeping context waiting for tx buffers ? */\n\tif (atomic_inc_return(&vrp->sleepers) == 1)\n\t\t/* enable \"tx-complete\" interrupts before dozing off */\n\t\tvirtqueue_enable_cb(vrp->svq);\n\n\tmutex_unlock(&vrp->tx_lock);\n}\n\n/**\n * rpmsg_downref_sleepers() - disable \"tx-complete\" interrupts, if needed\n * @vrp: virtual remote processor state\n *\n * This function is called after a sender, that waited for a tx buffer\n * to become available, is unblocked.\n *\n * If we still have blocking senders, this function merely decreases\n * the \"sleepers\" reference count, and exits.\n *\n * Otherwise, if there are no more blocking senders, we also disable\n * virtio's tx callbacks, to avoid the overhead incurred with handling\n * those (now redundant) interrupts.\n */\nstatic void rpmsg_downref_sleepers(struct virtproc_info *vrp)\n{\n\t/* support multiple concurrent senders */\n\tmutex_lock(&vrp->tx_lock);\n\n\t/* are we the last sleeping context waiting for tx buffers ? */\n\tif (atomic_dec_and_test(&vrp->sleepers))\n\t\t/* disable \"tx-complete\" interrupts */\n\t\tvirtqueue_disable_cb(vrp->svq);\n\n\tmutex_unlock(&vrp->tx_lock);\n}\n\n/**\n * rpmsg_send_offchannel_raw() - send a message across to the remote processor\n * @rpdev: the rpmsg channel\n * @src: source address\n * @dst: destination address\n * @data: payload of message\n * @len: length of payload\n * @wait: indicates whether caller should block in case no TX buffers available\n *\n * This function is the base implementation for all of the rpmsg sending API.\n *\n * It will send @data of length @len to @dst, and say it's from @src. The\n * message will be sent to the remote processor which the @rpdev channel\n * belongs to.\n *\n * The message is sent using one of the TX buffers that are available for\n * communication with this remote processor.\n *\n * If @wait is true, the caller will be blocked until either a TX buffer is\n * available, or 15 seconds elapses (we don't want callers to\n * sleep indefinitely due to misbehaving remote processors), and in that\n * case -ERESTARTSYS is returned. The number '15' itself was picked\n * arbitrarily; there's little point in asking drivers to provide a timeout\n * value themselves.\n *\n * Otherwise, if @wait is false, and there are no TX buffers available,\n * the function will immediately fail, and -ENOMEM will be returned.\n *\n * Normally drivers shouldn't use this function directly; instead, drivers\n * should use the appropriate rpmsg_{try}send{to, _offchannel} API\n * (see include/linux/rpmsg.h).\n *\n * Return: 0 on success and an appropriate error value on failure.\n */\nstatic int rpmsg_send_offchannel_raw(struct rpmsg_device *rpdev,\n\t\t\t\t     u32 src, u32 dst,\n\t\t\t\t     void *data, int len, bool wait)\n{\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\tstruct virtproc_info *vrp = vch->vrp;\n\tstruct device *dev = &rpdev->dev;\n\tstruct scatterlist sg;\n\tstruct rpmsg_hdr *msg;\n\tint err;\n\n\t/* bcasting isn't allowed */\n\tif (src == RPMSG_ADDR_ANY || dst == RPMSG_ADDR_ANY) {\n\t\tdev_err(dev, \"invalid addr (src 0x%x, dst 0x%x)\\n\", src, dst);\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * We currently use fixed-sized buffers, and therefore the payload\n\t * length is limited.\n\t *\n\t * One of the possible improvements here is either to support\n\t * user-provided buffers (and then we can also support zero-copy\n\t * messaging), or to improve the buffer allocator, to support\n\t * variable-length buffer sizes.\n\t */\n\tif (len > vrp->buf_size - sizeof(struct rpmsg_hdr)) {\n\t\tdev_err(dev, \"message is too big (%d)\\n\", len);\n\t\treturn -EMSGSIZE;\n\t}\n\n\t/* grab a buffer */\n\tmsg = get_a_tx_buf(vrp);\n\tif (!msg && !wait)\n\t\treturn -ENOMEM;\n\n\t/* no free buffer ? wait for one (but bail after 15 seconds) */\n\twhile (!msg) {\n\t\t/* enable \"tx-complete\" interrupts, if not already enabled */\n\t\trpmsg_upref_sleepers(vrp);\n\n\t\t/*\n\t\t * sleep until a free buffer is available or 15 secs elapse.\n\t\t * the timeout period is not configurable because there's\n\t\t * little point in asking drivers to specify that.\n\t\t * if later this happens to be required, it'd be easy to add.\n\t\t */\n\t\terr = wait_event_interruptible_timeout(vrp->sendq,\n\t\t\t\t\t(msg = get_a_tx_buf(vrp)),\n\t\t\t\t\tmsecs_to_jiffies(15000));\n\n\t\t/* disable \"tx-complete\" interrupts if we're the last sleeper */\n\t\trpmsg_downref_sleepers(vrp);\n\n\t\t/* timeout ? */\n\t\tif (!err) {\n\t\t\tdev_err(dev, \"timeout waiting for a tx buffer\\n\");\n\t\t\treturn -ERESTARTSYS;\n\t\t}\n\t}\n\n\tmsg->len = cpu_to_rpmsg16(rpdev, len);\n\tmsg->flags = 0;\n\tmsg->src = cpu_to_rpmsg32(rpdev, src);\n\tmsg->dst = cpu_to_rpmsg32(rpdev, dst);\n\tmsg->reserved = 0;\n\tmemcpy(msg->data, data, len);\n\n\tdev_dbg(dev, \"TX From 0x%x, To 0x%x, Len %d, Flags %d, Reserved %d\\n\",\n\t\tsrc, dst, len, msg->flags, msg->reserved);\n#if defined(CONFIG_DYNAMIC_DEBUG)\n\tdynamic_hex_dump(\"rpmsg_virtio TX: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\t msg, sizeof(*msg) + len, true);\n#endif\n\n\trpmsg_sg_init(&sg, msg, sizeof(*msg) + len);\n\n\tmutex_lock(&vrp->tx_lock);\n\n\t/* add message to the remote processor's virtqueue */\n\terr = virtqueue_add_outbuf(vrp->svq, &sg, 1, msg, GFP_KERNEL);\n\tif (err) {\n\t\t/*\n\t\t * need to reclaim the buffer here, otherwise it's lost\n\t\t * (memory won't leak, but rpmsg won't use it again for TX).\n\t\t * this will wait for a buffer management overhaul.\n\t\t */\n\t\tdev_err(dev, \"virtqueue_add_outbuf failed: %d\\n\", err);\n\t\tgoto out;\n\t}\n\n\t/* tell the remote processor it has a pending message to read */\n\tvirtqueue_kick(vrp->svq);\nout:\n\tmutex_unlock(&vrp->tx_lock);\n\treturn err;\n}\n\nstatic int virtio_rpmsg_send(struct rpmsg_endpoint *ept, void *data, int len)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\tu32 src = ept->addr, dst = rpdev->dst;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, true);\n}\n\nstatic int virtio_rpmsg_sendto(struct rpmsg_endpoint *ept, void *data, int len,\n\t\t\t       u32 dst)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\tu32 src = ept->addr;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, true);\n}\n\nstatic int virtio_rpmsg_send_offchannel(struct rpmsg_endpoint *ept, u32 src,\n\t\t\t\t\tu32 dst, void *data, int len)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, true);\n}\n\nstatic int virtio_rpmsg_trysend(struct rpmsg_endpoint *ept, void *data, int len)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\tu32 src = ept->addr, dst = rpdev->dst;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, false);\n}\n\nstatic int virtio_rpmsg_trysendto(struct rpmsg_endpoint *ept, void *data,\n\t\t\t\t  int len, u32 dst)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\tu32 src = ept->addr;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, false);\n}\n\nstatic int virtio_rpmsg_trysend_offchannel(struct rpmsg_endpoint *ept, u32 src,\n\t\t\t\t\t   u32 dst, void *data, int len)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\n\treturn rpmsg_send_offchannel_raw(rpdev, src, dst, data, len, false);\n}\n\nstatic ssize_t virtio_rpmsg_get_mtu(struct rpmsg_endpoint *ept)\n{\n\tstruct rpmsg_device *rpdev = ept->rpdev;\n\tstruct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);\n\n\treturn vch->vrp->buf_size - sizeof(struct rpmsg_hdr);\n}\n\nstatic int rpmsg_recv_single(struct virtproc_info *vrp, struct device *dev,\n\t\t\t     struct rpmsg_hdr *msg, unsigned int len)\n{\n\tstruct rpmsg_endpoint *ept;\n\tstruct scatterlist sg;\n\tbool little_endian = virtio_is_little_endian(vrp->vdev);\n\tunsigned int msg_len = __rpmsg16_to_cpu(little_endian, msg->len);\n\tint err;\n\n\tdev_dbg(dev, \"From: 0x%x, To: 0x%x, Len: %d, Flags: %d, Reserved: %d\\n\",\n\t\t__rpmsg32_to_cpu(little_endian, msg->src),\n\t\t__rpmsg32_to_cpu(little_endian, msg->dst), msg_len,\n\t\t__rpmsg16_to_cpu(little_endian, msg->flags),\n\t\t__rpmsg32_to_cpu(little_endian, msg->reserved));\n#if defined(CONFIG_DYNAMIC_DEBUG)\n\tdynamic_hex_dump(\"rpmsg_virtio RX: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\t msg, sizeof(*msg) + msg_len, true);\n#endif\n\n\t/*\n\t * We currently use fixed-sized buffers, so trivially sanitize\n\t * the reported payload length.\n\t */\n\tif (len > vrp->buf_size ||\n\t    msg_len > (len - sizeof(struct rpmsg_hdr))) {\n\t\tdev_warn(dev, \"inbound msg too big: (%d, %d)\\n\", len, msg_len);\n\t\treturn -EINVAL;\n\t}\n\n\t/* use the dst addr to fetch the callback of the appropriate user */\n\tmutex_lock(&vrp->endpoints_lock);\n\n\tept = idr_find(&vrp->endpoints, __rpmsg32_to_cpu(little_endian, msg->dst));\n\n\t/* let's make sure no one deallocates ept while we use it */\n\tif (ept)\n\t\tkref_get(&ept->refcount);\n\n\tmutex_unlock(&vrp->endpoints_lock);\n\n\tif (ept) {\n\t\t/* make sure ept->cb doesn't go away while we use it */\n\t\tmutex_lock(&ept->cb_lock);\n\n\t\tif (ept->cb)\n\t\t\tept->cb(ept->rpdev, msg->data, msg_len, ept->priv,\n\t\t\t\t__rpmsg32_to_cpu(little_endian, msg->src));\n\n\t\tmutex_unlock(&ept->cb_lock);\n\n\t\t/* farewell, ept, we don't need you anymore */\n\t\tkref_put(&ept->refcount, __ept_release);\n\t} else\n\t\tdev_warn_ratelimited(dev, \"msg received with no recipient\\n\");\n\n\t/* publish the real size of the buffer */\n\trpmsg_sg_init(&sg, msg, vrp->buf_size);\n\n\t/* add the buffer back to the remote processor's virtqueue */\n\terr = virtqueue_add_inbuf(vrp->rvq, &sg, 1, msg, GFP_KERNEL);\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to add a virtqueue buffer: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\n/* called when an rx buffer is used, and it's time to digest a message */\nstatic void rpmsg_recv_done(struct virtqueue *rvq)\n{\n\tstruct virtproc_info *vrp = rvq->vdev->priv;\n\tstruct device *dev = &rvq->vdev->dev;\n\tstruct rpmsg_hdr *msg;\n\tunsigned int len, msgs_received = 0;\n\tint err;\n\n\tmsg = virtqueue_get_buf(rvq, &len);\n\tif (!msg) {\n\t\tdev_err(dev, \"uhm, incoming signal, but no used buffer ?\\n\");\n\t\treturn;\n\t}\n\n\twhile (msg) {\n\t\terr = rpmsg_recv_single(vrp, dev, msg, len);\n\t\tif (err)\n\t\t\tbreak;\n\n\t\tmsgs_received++;\n\n\t\tmsg = virtqueue_get_buf(rvq, &len);\n\t}\n\n\tdev_dbg(dev, \"Received %u messages\\n\", msgs_received);\n\n\t/* tell the remote processor we added another available rx buffer */\n\tif (msgs_received)\n\t\tvirtqueue_kick(vrp->rvq);\n}\n\n/*\n * This is invoked whenever the remote processor completed processing\n * a TX msg we just sent it, and the buffer is put back to the used ring.\n *\n * Normally, though, we suppress this \"tx complete\" interrupt in order to\n * avoid the incurred overhead.\n */\nstatic void rpmsg_xmit_done(struct virtqueue *svq)\n{\n\tstruct virtproc_info *vrp = svq->vdev->priv;\n\n\tdev_dbg(&svq->vdev->dev, \"%s\\n\", __func__);\n\n\t/* wake up potential senders that are waiting for a tx buffer */\n\twake_up_interruptible(&vrp->sendq);\n}\n\n/*\n * Called to expose to user a /dev/rpmsg_ctrlX interface allowing to\n * create endpoint-to-endpoint communication without associated RPMsg channel.\n * The endpoints are rattached to the ctrldev RPMsg device.\n */\nstatic struct rpmsg_device *rpmsg_virtio_add_ctrl_dev(struct virtio_device *vdev)\n{\n\tstruct virtproc_info *vrp = vdev->priv;\n\tstruct virtio_rpmsg_channel *vch;\n\tstruct rpmsg_device *rpdev_ctrl;\n\tint err = 0;\n\n\tvch = kzalloc(sizeof(*vch), GFP_KERNEL);\n\tif (!vch)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* Link the channel to the vrp */\n\tvch->vrp = vrp;\n\n\t/* Assign public information to the rpmsg_device */\n\trpdev_ctrl = &vch->rpdev;\n\trpdev_ctrl->ops = &virtio_rpmsg_ops;\n\n\trpdev_ctrl->dev.parent = &vrp->vdev->dev;\n\trpdev_ctrl->dev.release = virtio_rpmsg_release_device;\n\trpdev_ctrl->little_endian = virtio_is_little_endian(vrp->vdev);\n\n\terr = rpmsg_ctrldev_register_device(rpdev_ctrl);\n\tif (err) {\n\t\t/* vch will be free in virtio_rpmsg_release_device() */\n\t\treturn ERR_PTR(err);\n\t}\n\n\treturn rpdev_ctrl;\n}\n\nstatic void rpmsg_virtio_del_ctrl_dev(struct rpmsg_device *rpdev_ctrl)\n{\n\tif (!rpdev_ctrl)\n\t\treturn;\n\tkfree(to_virtio_rpmsg_channel(rpdev_ctrl));\n}\n\nstatic int rpmsg_probe(struct virtio_device *vdev)\n{\n\tvq_callback_t *vq_cbs[] = { rpmsg_recv_done, rpmsg_xmit_done };\n\tstatic const char * const names[] = { \"input\", \"output\" };\n\tstruct virtqueue *vqs[2];\n\tstruct virtproc_info *vrp;\n\tstruct virtio_rpmsg_channel *vch = NULL;\n\tstruct rpmsg_device *rpdev_ns, *rpdev_ctrl;\n\tvoid *bufs_va;\n\tint err = 0, i;\n\tsize_t total_buf_space;\n\tbool notify;\n\n\tvrp = kzalloc(sizeof(*vrp), GFP_KERNEL);\n\tif (!vrp)\n\t\treturn -ENOMEM;\n\n\tvrp->vdev = vdev;\n\n\tidr_init(&vrp->endpoints);\n\tmutex_init(&vrp->endpoints_lock);\n\tmutex_init(&vrp->tx_lock);\n\tinit_waitqueue_head(&vrp->sendq);\n\n\t/* We expect two virtqueues, rx and tx (and in this order) */\n\terr = virtio_find_vqs(vdev, 2, vqs, vq_cbs, names, NULL);\n\tif (err)\n\t\tgoto free_vrp;\n\n\tvrp->rvq = vqs[0];\n\tvrp->svq = vqs[1];\n\n\t/* we expect symmetric tx/rx vrings */\n\tWARN_ON(virtqueue_get_vring_size(vrp->rvq) !=\n\t\tvirtqueue_get_vring_size(vrp->svq));\n\n\t/* we need less buffers if vrings are small */\n\tif (virtqueue_get_vring_size(vrp->rvq) < MAX_RPMSG_NUM_BUFS / 2)\n\t\tvrp->num_bufs = virtqueue_get_vring_size(vrp->rvq) * 2;\n\telse\n\t\tvrp->num_bufs = MAX_RPMSG_NUM_BUFS;\n\n\tvrp->buf_size = MAX_RPMSG_BUF_SIZE;\n\n\ttotal_buf_space = vrp->num_bufs * vrp->buf_size;\n\n\t/* allocate coherent memory for the buffers */\n\tbufs_va = dma_alloc_coherent(vdev->dev.parent,\n\t\t\t\t     total_buf_space, &vrp->bufs_dma,\n\t\t\t\t     GFP_KERNEL);\n\tif (!bufs_va) {\n\t\terr = -ENOMEM;\n\t\tgoto vqs_del;\n\t}\n\n\tdev_dbg(&vdev->dev, \"buffers: va %pK, dma %pad\\n\",\n\t\tbufs_va, &vrp->bufs_dma);\n\n\t/* half of the buffers is dedicated for RX */\n\tvrp->rbufs = bufs_va;\n\n\t/* and half is dedicated for TX */\n\tvrp->sbufs = bufs_va + total_buf_space / 2;\n\n\t/* set up the receive buffers */\n\tfor (i = 0; i < vrp->num_bufs / 2; i++) {\n\t\tstruct scatterlist sg;\n\t\tvoid *cpu_addr = vrp->rbufs + i * vrp->buf_size;\n\n\t\trpmsg_sg_init(&sg, cpu_addr, vrp->buf_size);\n\n\t\terr = virtqueue_add_inbuf(vrp->rvq, &sg, 1, cpu_addr,\n\t\t\t\t\t  GFP_KERNEL);\n\t\tWARN_ON(err); /* sanity check; this can't really happen */\n\t}\n\n\t/* suppress \"tx-complete\" interrupts */\n\tvirtqueue_disable_cb(vrp->svq);\n\n\tvdev->priv = vrp;\n\n\trpdev_ctrl = rpmsg_virtio_add_ctrl_dev(vdev);\n\tif (IS_ERR(rpdev_ctrl)) {\n\t\terr = PTR_ERR(rpdev_ctrl);\n\t\tgoto free_coherent;\n\t}\n\n\t/* if supported by the remote processor, enable the name service */\n\tif (virtio_has_feature(vdev, VIRTIO_RPMSG_F_NS)) {\n\t\tvch = kzalloc(sizeof(*vch), GFP_KERNEL);\n\t\tif (!vch) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto free_ctrldev;\n\t\t}\n\n\t\t/* Link the channel to our vrp */\n\t\tvch->vrp = vrp;\n\n\t\t/* Assign public information to the rpmsg_device */\n\t\trpdev_ns = &vch->rpdev;\n\t\trpdev_ns->ops = &virtio_rpmsg_ops;\n\t\trpdev_ns->little_endian = virtio_is_little_endian(vrp->vdev);\n\n\t\trpdev_ns->dev.parent = &vrp->vdev->dev;\n\t\trpdev_ns->dev.release = virtio_rpmsg_release_device;\n\n\t\terr = rpmsg_ns_register_device(rpdev_ns);\n\t\tif (err)\n\t\t\t/* vch will be free in virtio_rpmsg_release_device() */\n\t\t\tgoto free_ctrldev;\n\t}\n\n\t/*\n\t * Prepare to kick but don't notify yet - we can't do this before\n\t * device is ready.\n\t */\n\tnotify = virtqueue_kick_prepare(vrp->rvq);\n\n\t/* From this point on, we can notify and get callbacks. */\n\tvirtio_device_ready(vdev);\n\n\t/* tell the remote processor it can start sending messages */\n\t/*\n\t * this might be concurrent with callbacks, but we are only\n\t * doing notify, not a full kick here, so that's ok.\n\t */\n\tif (notify)\n\t\tvirtqueue_notify(vrp->rvq);\n\n\tdev_info(&vdev->dev, \"rpmsg host is online\\n\");\n\n\treturn 0;\n\nfree_ctrldev:\n\trpmsg_virtio_del_ctrl_dev(rpdev_ctrl);\nfree_coherent:\n\tdma_free_coherent(vdev->dev.parent, total_buf_space,\n\t\t\t  bufs_va, vrp->bufs_dma);\nvqs_del:\n\tvdev->config->del_vqs(vrp->vdev);\nfree_vrp:\n\tkfree(vrp);\n\treturn err;\n}\n\nstatic int rpmsg_remove_device(struct device *dev, void *data)\n{\n\tdevice_unregister(dev);\n\n\treturn 0;\n}\n\nstatic void rpmsg_remove(struct virtio_device *vdev)\n{\n\tstruct virtproc_info *vrp = vdev->priv;\n\tsize_t total_buf_space = vrp->num_bufs * vrp->buf_size;\n\tint ret;\n\n\tvirtio_reset_device(vdev);\n\n\tret = device_for_each_child(&vdev->dev, NULL, rpmsg_remove_device);\n\tif (ret)\n\t\tdev_warn(&vdev->dev, \"can't remove rpmsg device: %d\\n\", ret);\n\n\tidr_destroy(&vrp->endpoints);\n\n\tvdev->config->del_vqs(vrp->vdev);\n\n\tdma_free_coherent(vdev->dev.parent, total_buf_space,\n\t\t\t  vrp->rbufs, vrp->bufs_dma);\n\n\tkfree(vrp);\n}\n\nstatic struct virtio_device_id id_table[] = {\n\t{ VIRTIO_ID_RPMSG, VIRTIO_DEV_ANY_ID },\n\t{ 0 },\n};\n\nstatic unsigned int features[] = {\n\tVIRTIO_RPMSG_F_NS,\n};\n\nstatic struct virtio_driver virtio_ipc_driver = {\n\t.feature_table\t= features,\n\t.feature_table_size = ARRAY_SIZE(features),\n\t.driver.name\t= KBUILD_MODNAME,\n\t.driver.owner\t= THIS_MODULE,\n\t.id_table\t= id_table,\n\t.probe\t\t= rpmsg_probe,\n\t.remove\t\t= rpmsg_remove,\n};\n\nstatic int __init rpmsg_init(void)\n{\n\tint ret;\n\n\tret = register_virtio_driver(&virtio_ipc_driver);\n\tif (ret)\n\t\tpr_err(\"failed to register virtio driver: %d\\n\", ret);\n\n\treturn ret;\n}\nsubsys_initcall(rpmsg_init);\n\nstatic void __exit rpmsg_fini(void)\n{\n\tunregister_virtio_driver(&virtio_ipc_driver);\n}\nmodule_exit(rpmsg_fini);\n\nMODULE_DEVICE_TABLE(virtio, id_table);\nMODULE_DESCRIPTION(\"Virtio-based remote processor messaging bus\");\nMODULE_LICENSE(\"GPL v2\");\n"], "filenames": ["drivers/rpmsg/virtio_rpmsg_bus.c"], "buggy_code_start_loc": [854], "buggy_code_end_loc": [855], "fixing_code_start_loc": [854], "fixing_code_end_loc": [855], "type": "CWE-415", "message": "rpmsg_virtio_add_ctrl_dev in drivers/rpmsg/virtio_rpmsg_bus.c in the Linux kernel before 5.18.4 has a double free.", "other": {"cve": {"id": "CVE-2022-34494", "sourceIdentifier": "cve@mitre.org", "published": "2022-06-26T16:15:07.867", "lastModified": "2022-07-08T03:59:53.243", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "rpmsg_virtio_add_ctrl_dev in drivers/rpmsg/virtio_rpmsg_bus.c in the Linux kernel before 5.18.4 has a double free."}, {"lang": "es", "value": "La funci\u00f3n rpmsg_virtio_add_ctrl_dev en el archivo drivers/rpmsg/virtio_rpmsg_bus.c en el kernel de Linux versiones anteriores a 5.18.4, presenta una doble liberaci\u00f3n"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 4.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-415"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "5.18.4", "matchCriteriaId": "5607D6E0-33DF-47C1-83F1-1EF7EC1AB24B"}]}]}], "references": [{"url": "https://cdn.kernel.org/pub/linux/kernel/v5.x/ChangeLog-5.18.4", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/1680939e9ecf7764fba8689cfb3429c2fe2bb23c", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/1680939e9ecf7764fba8689cfb3429c2fe2bb23c"}}
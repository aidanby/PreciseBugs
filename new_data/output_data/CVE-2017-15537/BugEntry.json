{"buggy_code": ["/*\n * FPU register's regset abstraction, for ptrace, core dumps, etc.\n */\n#include <asm/fpu/internal.h>\n#include <asm/fpu/signal.h>\n#include <asm/fpu/regset.h>\n#include <asm/fpu/xstate.h>\n#include <linux/sched/task_stack.h>\n\n/*\n * The xstateregs_active() routine is the same as the regset_fpregs_active() routine,\n * as the \"regset->n\" for the xstate regset will be updated based on the feature\n * capabilities supported by the xsave.\n */\nint regset_fpregs_active(struct task_struct *target, const struct user_regset *regset)\n{\n\tstruct fpu *target_fpu = &target->thread.fpu;\n\n\treturn target_fpu->fpstate_active ? regset->n : 0;\n}\n\nint regset_xregset_fpregs_active(struct task_struct *target, const struct user_regset *regset)\n{\n\tstruct fpu *target_fpu = &target->thread.fpu;\n\n\tif (boot_cpu_has(X86_FEATURE_FXSR) && target_fpu->fpstate_active)\n\t\treturn regset->n;\n\telse\n\t\treturn 0;\n}\n\nint xfpregs_get(struct task_struct *target, const struct user_regset *regset,\n\t\tunsigned int pos, unsigned int count,\n\t\tvoid *kbuf, void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\n\tif (!boot_cpu_has(X86_FEATURE_FXSR))\n\t\treturn -ENODEV;\n\n\tfpu__activate_fpstate_read(fpu);\n\tfpstate_sanitize_xstate(fpu);\n\n\treturn user_regset_copyout(&pos, &count, &kbuf, &ubuf,\n\t\t\t\t   &fpu->state.fxsave, 0, -1);\n}\n\nint xfpregs_set(struct task_struct *target, const struct user_regset *regset,\n\t\tunsigned int pos, unsigned int count,\n\t\tconst void *kbuf, const void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\tint ret;\n\n\tif (!boot_cpu_has(X86_FEATURE_FXSR))\n\t\treturn -ENODEV;\n\n\tfpu__activate_fpstate_write(fpu);\n\tfpstate_sanitize_xstate(fpu);\n\n\tret = user_regset_copyin(&pos, &count, &kbuf, &ubuf,\n\t\t\t\t &fpu->state.fxsave, 0, -1);\n\n\t/*\n\t * mxcsr reserved bits must be masked to zero for security reasons.\n\t */\n\tfpu->state.fxsave.mxcsr &= mxcsr_feature_mask;\n\n\t/*\n\t * update the header bits in the xsave header, indicating the\n\t * presence of FP and SSE state.\n\t */\n\tif (boot_cpu_has(X86_FEATURE_XSAVE))\n\t\tfpu->state.xsave.header.xfeatures |= XFEATURE_MASK_FPSSE;\n\n\treturn ret;\n}\n\nint xstateregs_get(struct task_struct *target, const struct user_regset *regset,\n\t\tunsigned int pos, unsigned int count,\n\t\tvoid *kbuf, void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\tstruct xregs_state *xsave;\n\tint ret;\n\n\tif (!boot_cpu_has(X86_FEATURE_XSAVE))\n\t\treturn -ENODEV;\n\n\txsave = &fpu->state.xsave;\n\n\tfpu__activate_fpstate_read(fpu);\n\n\tif (using_compacted_format()) {\n\t\tif (kbuf)\n\t\t\tret = copy_xstate_to_kernel(kbuf, xsave, pos, count);\n\t\telse\n\t\t\tret = copy_xstate_to_user(ubuf, xsave, pos, count);\n\t} else {\n\t\tfpstate_sanitize_xstate(fpu);\n\t\t/*\n\t\t * Copy the 48 bytes defined by the software into the xsave\n\t\t * area in the thread struct, so that we can copy the whole\n\t\t * area to user using one user_regset_copyout().\n\t\t */\n\t\tmemcpy(&xsave->i387.sw_reserved, xstate_fx_sw_bytes, sizeof(xstate_fx_sw_bytes));\n\n\t\t/*\n\t\t * Copy the xstate memory layout.\n\t\t */\n\t\tret = user_regset_copyout(&pos, &count, &kbuf, &ubuf, xsave, 0, -1);\n\t}\n\treturn ret;\n}\n\nint xstateregs_set(struct task_struct *target, const struct user_regset *regset,\n\t\t  unsigned int pos, unsigned int count,\n\t\t  const void *kbuf, const void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\tstruct xregs_state *xsave;\n\tint ret;\n\n\tif (!boot_cpu_has(X86_FEATURE_XSAVE))\n\t\treturn -ENODEV;\n\n\t/*\n\t * A whole standard-format XSAVE buffer is needed:\n\t */\n\tif ((pos != 0) || (count < fpu_user_xstate_size))\n\t\treturn -EFAULT;\n\n\txsave = &fpu->state.xsave;\n\n\tfpu__activate_fpstate_write(fpu);\n\n\tif (boot_cpu_has(X86_FEATURE_XSAVES)) {\n\t\tif (kbuf)\n\t\t\tret = copy_kernel_to_xstate(xsave, kbuf);\n\t\telse\n\t\t\tret = copy_user_to_xstate(xsave, ubuf);\n\t} else {\n\t\tret = user_regset_copyin(&pos, &count, &kbuf, &ubuf, xsave, 0, -1);\n\t}\n\n\t/*\n\t * In case of failure, mark all states as init:\n\t */\n\tif (ret)\n\t\tfpstate_init(&fpu->state);\n\n\t/*\n\t * mxcsr reserved bits must be masked to zero for security reasons.\n\t */\n\txsave->i387.mxcsr &= mxcsr_feature_mask;\n\txsave->header.xfeatures &= xfeatures_mask;\n\t/*\n\t * These bits must be zero.\n\t */\n\tmemset(&xsave->header.reserved, 0, 48);\n\n\treturn ret;\n}\n\n#if defined CONFIG_X86_32 || defined CONFIG_IA32_EMULATION\n\n/*\n * FPU tag word conversions.\n */\n\nstatic inline unsigned short twd_i387_to_fxsr(unsigned short twd)\n{\n\tunsigned int tmp; /* to avoid 16 bit prefixes in the code */\n\n\t/* Transform each pair of bits into 01 (valid) or 00 (empty) */\n\ttmp = ~twd;\n\ttmp = (tmp | (tmp>>1)) & 0x5555; /* 0V0V0V0V0V0V0V0V */\n\t/* and move the valid bits to the lower byte. */\n\ttmp = (tmp | (tmp >> 1)) & 0x3333; /* 00VV00VV00VV00VV */\n\ttmp = (tmp | (tmp >> 2)) & 0x0f0f; /* 0000VVVV0000VVVV */\n\ttmp = (tmp | (tmp >> 4)) & 0x00ff; /* 00000000VVVVVVVV */\n\n\treturn tmp;\n}\n\n#define FPREG_ADDR(f, n)\t((void *)&(f)->st_space + (n) * 16)\n#define FP_EXP_TAG_VALID\t0\n#define FP_EXP_TAG_ZERO\t\t1\n#define FP_EXP_TAG_SPECIAL\t2\n#define FP_EXP_TAG_EMPTY\t3\n\nstatic inline u32 twd_fxsr_to_i387(struct fxregs_state *fxsave)\n{\n\tstruct _fpxreg *st;\n\tu32 tos = (fxsave->swd >> 11) & 7;\n\tu32 twd = (unsigned long) fxsave->twd;\n\tu32 tag;\n\tu32 ret = 0xffff0000u;\n\tint i;\n\n\tfor (i = 0; i < 8; i++, twd >>= 1) {\n\t\tif (twd & 0x1) {\n\t\t\tst = FPREG_ADDR(fxsave, (i - tos) & 7);\n\n\t\t\tswitch (st->exponent & 0x7fff) {\n\t\t\tcase 0x7fff:\n\t\t\t\ttag = FP_EXP_TAG_SPECIAL;\n\t\t\t\tbreak;\n\t\t\tcase 0x0000:\n\t\t\t\tif (!st->significand[0] &&\n\t\t\t\t    !st->significand[1] &&\n\t\t\t\t    !st->significand[2] &&\n\t\t\t\t    !st->significand[3])\n\t\t\t\t\ttag = FP_EXP_TAG_ZERO;\n\t\t\t\telse\n\t\t\t\t\ttag = FP_EXP_TAG_SPECIAL;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tif (st->significand[3] & 0x8000)\n\t\t\t\t\ttag = FP_EXP_TAG_VALID;\n\t\t\t\telse\n\t\t\t\t\ttag = FP_EXP_TAG_SPECIAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\ttag = FP_EXP_TAG_EMPTY;\n\t\t}\n\t\tret |= tag << (2 * i);\n\t}\n\treturn ret;\n}\n\n/*\n * FXSR floating point environment conversions.\n */\n\nvoid\nconvert_from_fxsr(struct user_i387_ia32_struct *env, struct task_struct *tsk)\n{\n\tstruct fxregs_state *fxsave = &tsk->thread.fpu.state.fxsave;\n\tstruct _fpreg *to = (struct _fpreg *) &env->st_space[0];\n\tstruct _fpxreg *from = (struct _fpxreg *) &fxsave->st_space[0];\n\tint i;\n\n\tenv->cwd = fxsave->cwd | 0xffff0000u;\n\tenv->swd = fxsave->swd | 0xffff0000u;\n\tenv->twd = twd_fxsr_to_i387(fxsave);\n\n#ifdef CONFIG_X86_64\n\tenv->fip = fxsave->rip;\n\tenv->foo = fxsave->rdp;\n\t/*\n\t * should be actually ds/cs at fpu exception time, but\n\t * that information is not available in 64bit mode.\n\t */\n\tenv->fcs = task_pt_regs(tsk)->cs;\n\tif (tsk == current) {\n\t\tsavesegment(ds, env->fos);\n\t} else {\n\t\tenv->fos = tsk->thread.ds;\n\t}\n\tenv->fos |= 0xffff0000;\n#else\n\tenv->fip = fxsave->fip;\n\tenv->fcs = (u16) fxsave->fcs | ((u32) fxsave->fop << 16);\n\tenv->foo = fxsave->foo;\n\tenv->fos = fxsave->fos;\n#endif\n\n\tfor (i = 0; i < 8; ++i)\n\t\tmemcpy(&to[i], &from[i], sizeof(to[0]));\n}\n\nvoid convert_to_fxsr(struct task_struct *tsk,\n\t\t     const struct user_i387_ia32_struct *env)\n\n{\n\tstruct fxregs_state *fxsave = &tsk->thread.fpu.state.fxsave;\n\tstruct _fpreg *from = (struct _fpreg *) &env->st_space[0];\n\tstruct _fpxreg *to = (struct _fpxreg *) &fxsave->st_space[0];\n\tint i;\n\n\tfxsave->cwd = env->cwd;\n\tfxsave->swd = env->swd;\n\tfxsave->twd = twd_i387_to_fxsr(env->twd);\n\tfxsave->fop = (u16) ((u32) env->fcs >> 16);\n#ifdef CONFIG_X86_64\n\tfxsave->rip = env->fip;\n\tfxsave->rdp = env->foo;\n\t/* cs and ds ignored */\n#else\n\tfxsave->fip = env->fip;\n\tfxsave->fcs = (env->fcs & 0xffff);\n\tfxsave->foo = env->foo;\n\tfxsave->fos = env->fos;\n#endif\n\n\tfor (i = 0; i < 8; ++i)\n\t\tmemcpy(&to[i], &from[i], sizeof(from[0]));\n}\n\nint fpregs_get(struct task_struct *target, const struct user_regset *regset,\n\t       unsigned int pos, unsigned int count,\n\t       void *kbuf, void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\tstruct user_i387_ia32_struct env;\n\n\tfpu__activate_fpstate_read(fpu);\n\n\tif (!boot_cpu_has(X86_FEATURE_FPU))\n\t\treturn fpregs_soft_get(target, regset, pos, count, kbuf, ubuf);\n\n\tif (!boot_cpu_has(X86_FEATURE_FXSR))\n\t\treturn user_regset_copyout(&pos, &count, &kbuf, &ubuf,\n\t\t\t\t\t   &fpu->state.fsave, 0,\n\t\t\t\t\t   -1);\n\n\tfpstate_sanitize_xstate(fpu);\n\n\tif (kbuf && pos == 0 && count == sizeof(env)) {\n\t\tconvert_from_fxsr(kbuf, target);\n\t\treturn 0;\n\t}\n\n\tconvert_from_fxsr(&env, target);\n\n\treturn user_regset_copyout(&pos, &count, &kbuf, &ubuf, &env, 0, -1);\n}\n\nint fpregs_set(struct task_struct *target, const struct user_regset *regset,\n\t       unsigned int pos, unsigned int count,\n\t       const void *kbuf, const void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\tstruct user_i387_ia32_struct env;\n\tint ret;\n\n\tfpu__activate_fpstate_write(fpu);\n\tfpstate_sanitize_xstate(fpu);\n\n\tif (!boot_cpu_has(X86_FEATURE_FPU))\n\t\treturn fpregs_soft_set(target, regset, pos, count, kbuf, ubuf);\n\n\tif (!boot_cpu_has(X86_FEATURE_FXSR))\n\t\treturn user_regset_copyin(&pos, &count, &kbuf, &ubuf,\n\t\t\t\t\t  &fpu->state.fsave, 0,\n\t\t\t\t\t  -1);\n\n\tif (pos > 0 || count < sizeof(env))\n\t\tconvert_from_fxsr(&env, target);\n\n\tret = user_regset_copyin(&pos, &count, &kbuf, &ubuf, &env, 0, -1);\n\tif (!ret)\n\t\tconvert_to_fxsr(target, &env);\n\n\t/*\n\t * update the header bit in the xsave header, indicating the\n\t * presence of FP.\n\t */\n\tif (boot_cpu_has(X86_FEATURE_XSAVE))\n\t\tfpu->state.xsave.header.xfeatures |= XFEATURE_MASK_FP;\n\treturn ret;\n}\n\n/*\n * FPU state for core dumps.\n * This is only used for a.out dumps now.\n * It is declared generically using elf_fpregset_t (which is\n * struct user_i387_struct) but is in fact only used for 32-bit\n * dumps, so on 64-bit it is really struct user_i387_ia32_struct.\n */\nint dump_fpu(struct pt_regs *regs, struct user_i387_struct *ufpu)\n{\n\tstruct task_struct *tsk = current;\n\tstruct fpu *fpu = &tsk->thread.fpu;\n\tint fpvalid;\n\n\tfpvalid = fpu->fpstate_active;\n\tif (fpvalid)\n\t\tfpvalid = !fpregs_get(tsk, NULL,\n\t\t\t\t      0, sizeof(struct user_i387_ia32_struct),\n\t\t\t\t      ufpu, NULL);\n\n\treturn fpvalid;\n}\nEXPORT_SYMBOL(dump_fpu);\n\n#endif\t/* CONFIG_X86_32 || CONFIG_IA32_EMULATION */\n", "/*\n * FPU signal frame handling routines.\n */\n\n#include <linux/compat.h>\n#include <linux/cpu.h>\n\n#include <asm/fpu/internal.h>\n#include <asm/fpu/signal.h>\n#include <asm/fpu/regset.h>\n#include <asm/fpu/xstate.h>\n\n#include <asm/sigframe.h>\n#include <asm/trace/fpu.h>\n\nstatic struct _fpx_sw_bytes fx_sw_reserved, fx_sw_reserved_ia32;\n\n/*\n * Check for the presence of extended state information in the\n * user fpstate pointer in the sigcontext.\n */\nstatic inline int check_for_xstate(struct fxregs_state __user *buf,\n\t\t\t\t   void __user *fpstate,\n\t\t\t\t   struct _fpx_sw_bytes *fx_sw)\n{\n\tint min_xstate_size = sizeof(struct fxregs_state) +\n\t\t\t      sizeof(struct xstate_header);\n\tunsigned int magic2;\n\n\tif (__copy_from_user(fx_sw, &buf->sw_reserved[0], sizeof(*fx_sw)))\n\t\treturn -1;\n\n\t/* Check for the first magic field and other error scenarios. */\n\tif (fx_sw->magic1 != FP_XSTATE_MAGIC1 ||\n\t    fx_sw->xstate_size < min_xstate_size ||\n\t    fx_sw->xstate_size > fpu_user_xstate_size ||\n\t    fx_sw->xstate_size > fx_sw->extended_size)\n\t\treturn -1;\n\n\t/*\n\t * Check for the presence of second magic word at the end of memory\n\t * layout. This detects the case where the user just copied the legacy\n\t * fpstate layout with out copying the extended state information\n\t * in the memory layout.\n\t */\n\tif (__get_user(magic2, (__u32 __user *)(fpstate + fx_sw->xstate_size))\n\t    || magic2 != FP_XSTATE_MAGIC2)\n\t\treturn -1;\n\n\treturn 0;\n}\n\n/*\n * Signal frame handlers.\n */\nstatic inline int save_fsave_header(struct task_struct *tsk, void __user *buf)\n{\n\tif (use_fxsr()) {\n\t\tstruct xregs_state *xsave = &tsk->thread.fpu.state.xsave;\n\t\tstruct user_i387_ia32_struct env;\n\t\tstruct _fpstate_32 __user *fp = buf;\n\n\t\tconvert_from_fxsr(&env, tsk);\n\n\t\tif (__copy_to_user(buf, &env, sizeof(env)) ||\n\t\t    __put_user(xsave->i387.swd, &fp->status) ||\n\t\t    __put_user(X86_FXSR_MAGIC, &fp->magic))\n\t\t\treturn -1;\n\t} else {\n\t\tstruct fregs_state __user *fp = buf;\n\t\tu32 swd;\n\t\tif (__get_user(swd, &fp->swd) || __put_user(swd, &fp->status))\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nstatic inline int save_xstate_epilog(void __user *buf, int ia32_frame)\n{\n\tstruct xregs_state __user *x = buf;\n\tstruct _fpx_sw_bytes *sw_bytes;\n\tu32 xfeatures;\n\tint err;\n\n\t/* Setup the bytes not touched by the [f]xsave and reserved for SW. */\n\tsw_bytes = ia32_frame ? &fx_sw_reserved_ia32 : &fx_sw_reserved;\n\terr = __copy_to_user(&x->i387.sw_reserved, sw_bytes, sizeof(*sw_bytes));\n\n\tif (!use_xsave())\n\t\treturn err;\n\n\terr |= __put_user(FP_XSTATE_MAGIC2,\n\t\t\t  (__u32 *)(buf + fpu_user_xstate_size));\n\n\t/*\n\t * Read the xfeatures which we copied (directly from the cpu or\n\t * from the state in task struct) to the user buffers.\n\t */\n\terr |= __get_user(xfeatures, (__u32 *)&x->header.xfeatures);\n\n\t/*\n\t * For legacy compatible, we always set FP/SSE bits in the bit\n\t * vector while saving the state to the user context. This will\n\t * enable us capturing any changes(during sigreturn) to\n\t * the FP/SSE bits by the legacy applications which don't touch\n\t * xfeatures in the xsave header.\n\t *\n\t * xsave aware apps can change the xfeatures in the xsave\n\t * header as well as change any contents in the memory layout.\n\t * xrestore as part of sigreturn will capture all the changes.\n\t */\n\txfeatures |= XFEATURE_MASK_FPSSE;\n\n\terr |= __put_user(xfeatures, (__u32 *)&x->header.xfeatures);\n\n\treturn err;\n}\n\nstatic inline int copy_fpregs_to_sigframe(struct xregs_state __user *buf)\n{\n\tint err;\n\n\tif (use_xsave())\n\t\terr = copy_xregs_to_user(buf);\n\telse if (use_fxsr())\n\t\terr = copy_fxregs_to_user((struct fxregs_state __user *) buf);\n\telse\n\t\terr = copy_fregs_to_user((struct fregs_state __user *) buf);\n\n\tif (unlikely(err) && __clear_user(buf, fpu_user_xstate_size))\n\t\terr = -EFAULT;\n\treturn err;\n}\n\n/*\n * Save the fpu, extended register state to the user signal frame.\n *\n * 'buf_fx' is the 64-byte aligned pointer at which the [f|fx|x]save\n *  state is copied.\n *  'buf' points to the 'buf_fx' or to the fsave header followed by 'buf_fx'.\n *\n *\tbuf == buf_fx for 64-bit frames and 32-bit fsave frame.\n *\tbuf != buf_fx for 32-bit frames with fxstate.\n *\n * If the fpu, extended register state is live, save the state directly\n * to the user frame pointed by the aligned pointer 'buf_fx'. Otherwise,\n * copy the thread's fpu state to the user frame starting at 'buf_fx'.\n *\n * If this is a 32-bit frame with fxstate, put a fsave header before\n * the aligned state at 'buf_fx'.\n *\n * For [f]xsave state, update the SW reserved fields in the [f]xsave frame\n * indicating the absence/presence of the extended state to the user.\n */\nint copy_fpstate_to_sigframe(void __user *buf, void __user *buf_fx, int size)\n{\n\tstruct fpu *fpu = &current->thread.fpu;\n\tstruct xregs_state *xsave = &fpu->state.xsave;\n\tstruct task_struct *tsk = current;\n\tint ia32_fxstate = (buf != buf_fx);\n\n\tia32_fxstate &= (IS_ENABLED(CONFIG_X86_32) ||\n\t\t\t IS_ENABLED(CONFIG_IA32_EMULATION));\n\n\tif (!access_ok(VERIFY_WRITE, buf, size))\n\t\treturn -EACCES;\n\n\tif (!static_cpu_has(X86_FEATURE_FPU))\n\t\treturn fpregs_soft_get(current, NULL, 0,\n\t\t\tsizeof(struct user_i387_ia32_struct), NULL,\n\t\t\t(struct _fpstate_32 __user *) buf) ? -1 : 1;\n\n\tif (fpu->fpstate_active || using_compacted_format()) {\n\t\t/* Save the live register state to the user directly. */\n\t\tif (copy_fpregs_to_sigframe(buf_fx))\n\t\t\treturn -1;\n\t\t/* Update the thread's fxstate to save the fsave header. */\n\t\tif (ia32_fxstate)\n\t\t\tcopy_fxregs_to_kernel(fpu);\n\t} else {\n\t\t/*\n\t\t * It is a *bug* if kernel uses compacted-format for xsave\n\t\t * area and we copy it out directly to a signal frame. It\n\t\t * should have been handled above by saving the registers\n\t\t * directly.\n\t\t */\n\t\tif (boot_cpu_has(X86_FEATURE_XSAVES)) {\n\t\t\tWARN_ONCE(1, \"x86/fpu: saving compacted-format xsave area to a signal frame!\\n\");\n\t\t\treturn -1;\n\t\t}\n\n\t\tfpstate_sanitize_xstate(fpu);\n\t\tif (__copy_to_user(buf_fx, xsave, fpu_user_xstate_size))\n\t\t\treturn -1;\n\t}\n\n\t/* Save the fsave header for the 32-bit frames. */\n\tif ((ia32_fxstate || !use_fxsr()) && save_fsave_header(tsk, buf))\n\t\treturn -1;\n\n\tif (use_fxsr() && save_xstate_epilog(buf_fx, ia32_fxstate))\n\t\treturn -1;\n\n\treturn 0;\n}\n\nstatic inline void\nsanitize_restored_xstate(struct task_struct *tsk,\n\t\t\t struct user_i387_ia32_struct *ia32_env,\n\t\t\t u64 xfeatures, int fx_only)\n{\n\tstruct xregs_state *xsave = &tsk->thread.fpu.state.xsave;\n\tstruct xstate_header *header = &xsave->header;\n\n\tif (use_xsave()) {\n\t\t/* These bits must be zero. */\n\t\tmemset(header->reserved, 0, 48);\n\n\t\t/*\n\t\t * Init the state that is not present in the memory\n\t\t * layout and not enabled by the OS.\n\t\t */\n\t\tif (fx_only)\n\t\t\theader->xfeatures = XFEATURE_MASK_FPSSE;\n\t\telse\n\t\t\theader->xfeatures &= (xfeatures_mask & xfeatures);\n\t}\n\n\tif (use_fxsr()) {\n\t\t/*\n\t\t * mscsr reserved bits must be masked to zero for security\n\t\t * reasons.\n\t\t */\n\t\txsave->i387.mxcsr &= mxcsr_feature_mask;\n\n\t\tconvert_to_fxsr(tsk, ia32_env);\n\t}\n}\n\n/*\n * Restore the extended state if present. Otherwise, restore the FP/SSE state.\n */\nstatic inline int copy_user_to_fpregs_zeroing(void __user *buf, u64 xbv, int fx_only)\n{\n\tif (use_xsave()) {\n\t\tif ((unsigned long)buf % 64 || fx_only) {\n\t\t\tu64 init_bv = xfeatures_mask & ~XFEATURE_MASK_FPSSE;\n\t\t\tcopy_kernel_to_xregs(&init_fpstate.xsave, init_bv);\n\t\t\treturn copy_user_to_fxregs(buf);\n\t\t} else {\n\t\t\tu64 init_bv = xfeatures_mask & ~xbv;\n\t\t\tif (unlikely(init_bv))\n\t\t\t\tcopy_kernel_to_xregs(&init_fpstate.xsave, init_bv);\n\t\t\treturn copy_user_to_xregs(buf, xbv);\n\t\t}\n\t} else if (use_fxsr()) {\n\t\treturn copy_user_to_fxregs(buf);\n\t} else\n\t\treturn copy_user_to_fregs(buf);\n}\n\nstatic int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)\n{\n\tint ia32_fxstate = (buf != buf_fx);\n\tstruct task_struct *tsk = current;\n\tstruct fpu *fpu = &tsk->thread.fpu;\n\tint state_size = fpu_kernel_xstate_size;\n\tu64 xfeatures = 0;\n\tint fx_only = 0;\n\n\tia32_fxstate &= (IS_ENABLED(CONFIG_X86_32) ||\n\t\t\t IS_ENABLED(CONFIG_IA32_EMULATION));\n\n\tif (!buf) {\n\t\tfpu__clear(fpu);\n\t\treturn 0;\n\t}\n\n\tif (!access_ok(VERIFY_READ, buf, size))\n\t\treturn -EACCES;\n\n\tfpu__activate_curr(fpu);\n\n\tif (!static_cpu_has(X86_FEATURE_FPU))\n\t\treturn fpregs_soft_set(current, NULL,\n\t\t\t\t       0, sizeof(struct user_i387_ia32_struct),\n\t\t\t\t       NULL, buf) != 0;\n\n\tif (use_xsave()) {\n\t\tstruct _fpx_sw_bytes fx_sw_user;\n\t\tif (unlikely(check_for_xstate(buf_fx, buf_fx, &fx_sw_user))) {\n\t\t\t/*\n\t\t\t * Couldn't find the extended state information in the\n\t\t\t * memory layout. Restore just the FP/SSE and init all\n\t\t\t * the other extended state.\n\t\t\t */\n\t\t\tstate_size = sizeof(struct fxregs_state);\n\t\t\tfx_only = 1;\n\t\t\ttrace_x86_fpu_xstate_check_failed(fpu);\n\t\t} else {\n\t\t\tstate_size = fx_sw_user.xstate_size;\n\t\t\txfeatures = fx_sw_user.xfeatures;\n\t\t}\n\t}\n\n\tif (ia32_fxstate) {\n\t\t/*\n\t\t * For 32-bit frames with fxstate, copy the user state to the\n\t\t * thread's fpu state, reconstruct fxstate from the fsave\n\t\t * header. Sanitize the copied state etc.\n\t\t */\n\t\tstruct fpu *fpu = &tsk->thread.fpu;\n\t\tstruct user_i387_ia32_struct env;\n\t\tint err = 0;\n\n\t\t/*\n\t\t * Drop the current fpu which clears fpu->fpstate_active. This ensures\n\t\t * that any context-switch during the copy of the new state,\n\t\t * avoids the intermediate state from getting restored/saved.\n\t\t * Thus avoiding the new restored state from getting corrupted.\n\t\t * We will be ready to restore/save the state only after\n\t\t * fpu->fpstate_active is again set.\n\t\t */\n\t\tfpu__drop(fpu);\n\n\t\tif (using_compacted_format())\n\t\t\terr = copy_user_to_xstate(&fpu->state.xsave, buf_fx);\n\t\telse\n\t\t\terr = __copy_from_user(&fpu->state.xsave, buf_fx, state_size);\n\n\t\tif (err || __copy_from_user(&env, buf, sizeof(env))) {\n\t\t\tfpstate_init(&fpu->state);\n\t\t\ttrace_x86_fpu_init_state(fpu);\n\t\t\terr = -1;\n\t\t} else {\n\t\t\tsanitize_restored_xstate(tsk, &env, xfeatures, fx_only);\n\t\t}\n\n\t\tfpu->fpstate_active = 1;\n\t\tpreempt_disable();\n\t\tfpu__restore(fpu);\n\t\tpreempt_enable();\n\n\t\treturn err;\n\t} else {\n\t\t/*\n\t\t * For 64-bit frames and 32-bit fsave frames, restore the user\n\t\t * state to the registers directly (with exceptions handled).\n\t\t */\n\t\tuser_fpu_begin();\n\t\tif (copy_user_to_fpregs_zeroing(buf_fx, xfeatures, fx_only)) {\n\t\t\tfpu__clear(fpu);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic inline int xstate_sigframe_size(void)\n{\n\treturn use_xsave() ? fpu_user_xstate_size + FP_XSTATE_MAGIC2_SIZE :\n\t\t\tfpu_user_xstate_size;\n}\n\n/*\n * Restore FPU state from a sigframe:\n */\nint fpu__restore_sig(void __user *buf, int ia32_frame)\n{\n\tvoid __user *buf_fx = buf;\n\tint size = xstate_sigframe_size();\n\n\tif (ia32_frame && use_fxsr()) {\n\t\tbuf_fx = buf + sizeof(struct fregs_state);\n\t\tsize += sizeof(struct fregs_state);\n\t}\n\n\treturn __fpu__restore_sig(buf, buf_fx, size);\n}\n\nunsigned long\nfpu__alloc_mathframe(unsigned long sp, int ia32_frame,\n\t\t     unsigned long *buf_fx, unsigned long *size)\n{\n\tunsigned long frame_size = xstate_sigframe_size();\n\n\t*buf_fx = sp = round_down(sp - frame_size, 64);\n\tif (ia32_frame && use_fxsr()) {\n\t\tframe_size += sizeof(struct fregs_state);\n\t\tsp -= sizeof(struct fregs_state);\n\t}\n\n\t*size = frame_size;\n\n\treturn sp;\n}\n/*\n * Prepare the SW reserved portion of the fxsave memory layout, indicating\n * the presence of the extended state information in the memory layout\n * pointed by the fpstate pointer in the sigcontext.\n * This will be saved when ever the FP and extended state context is\n * saved on the user stack during the signal handler delivery to the user.\n */\nvoid fpu__init_prepare_fx_sw_frame(void)\n{\n\tint size = fpu_user_xstate_size + FP_XSTATE_MAGIC2_SIZE;\n\n\tfx_sw_reserved.magic1 = FP_XSTATE_MAGIC1;\n\tfx_sw_reserved.extended_size = size;\n\tfx_sw_reserved.xfeatures = xfeatures_mask;\n\tfx_sw_reserved.xstate_size = fpu_user_xstate_size;\n\n\tif (IS_ENABLED(CONFIG_IA32_EMULATION) ||\n\t    IS_ENABLED(CONFIG_X86_32)) {\n\t\tint fsave_header_size = sizeof(struct fregs_state);\n\n\t\tfx_sw_reserved_ia32 = fx_sw_reserved;\n\t\tfx_sw_reserved_ia32.extended_size = size + fsave_header_size;\n\t}\n}\n\n"], "fixing_code": ["/*\n * FPU register's regset abstraction, for ptrace, core dumps, etc.\n */\n#include <asm/fpu/internal.h>\n#include <asm/fpu/signal.h>\n#include <asm/fpu/regset.h>\n#include <asm/fpu/xstate.h>\n#include <linux/sched/task_stack.h>\n\n/*\n * The xstateregs_active() routine is the same as the regset_fpregs_active() routine,\n * as the \"regset->n\" for the xstate regset will be updated based on the feature\n * capabilities supported by the xsave.\n */\nint regset_fpregs_active(struct task_struct *target, const struct user_regset *regset)\n{\n\tstruct fpu *target_fpu = &target->thread.fpu;\n\n\treturn target_fpu->fpstate_active ? regset->n : 0;\n}\n\nint regset_xregset_fpregs_active(struct task_struct *target, const struct user_regset *regset)\n{\n\tstruct fpu *target_fpu = &target->thread.fpu;\n\n\tif (boot_cpu_has(X86_FEATURE_FXSR) && target_fpu->fpstate_active)\n\t\treturn regset->n;\n\telse\n\t\treturn 0;\n}\n\nint xfpregs_get(struct task_struct *target, const struct user_regset *regset,\n\t\tunsigned int pos, unsigned int count,\n\t\tvoid *kbuf, void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\n\tif (!boot_cpu_has(X86_FEATURE_FXSR))\n\t\treturn -ENODEV;\n\n\tfpu__activate_fpstate_read(fpu);\n\tfpstate_sanitize_xstate(fpu);\n\n\treturn user_regset_copyout(&pos, &count, &kbuf, &ubuf,\n\t\t\t\t   &fpu->state.fxsave, 0, -1);\n}\n\nint xfpregs_set(struct task_struct *target, const struct user_regset *regset,\n\t\tunsigned int pos, unsigned int count,\n\t\tconst void *kbuf, const void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\tint ret;\n\n\tif (!boot_cpu_has(X86_FEATURE_FXSR))\n\t\treturn -ENODEV;\n\n\tfpu__activate_fpstate_write(fpu);\n\tfpstate_sanitize_xstate(fpu);\n\n\tret = user_regset_copyin(&pos, &count, &kbuf, &ubuf,\n\t\t\t\t &fpu->state.fxsave, 0, -1);\n\n\t/*\n\t * mxcsr reserved bits must be masked to zero for security reasons.\n\t */\n\tfpu->state.fxsave.mxcsr &= mxcsr_feature_mask;\n\n\t/*\n\t * update the header bits in the xsave header, indicating the\n\t * presence of FP and SSE state.\n\t */\n\tif (boot_cpu_has(X86_FEATURE_XSAVE))\n\t\tfpu->state.xsave.header.xfeatures |= XFEATURE_MASK_FPSSE;\n\n\treturn ret;\n}\n\nint xstateregs_get(struct task_struct *target, const struct user_regset *regset,\n\t\tunsigned int pos, unsigned int count,\n\t\tvoid *kbuf, void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\tstruct xregs_state *xsave;\n\tint ret;\n\n\tif (!boot_cpu_has(X86_FEATURE_XSAVE))\n\t\treturn -ENODEV;\n\n\txsave = &fpu->state.xsave;\n\n\tfpu__activate_fpstate_read(fpu);\n\n\tif (using_compacted_format()) {\n\t\tif (kbuf)\n\t\t\tret = copy_xstate_to_kernel(kbuf, xsave, pos, count);\n\t\telse\n\t\t\tret = copy_xstate_to_user(ubuf, xsave, pos, count);\n\t} else {\n\t\tfpstate_sanitize_xstate(fpu);\n\t\t/*\n\t\t * Copy the 48 bytes defined by the software into the xsave\n\t\t * area in the thread struct, so that we can copy the whole\n\t\t * area to user using one user_regset_copyout().\n\t\t */\n\t\tmemcpy(&xsave->i387.sw_reserved, xstate_fx_sw_bytes, sizeof(xstate_fx_sw_bytes));\n\n\t\t/*\n\t\t * Copy the xstate memory layout.\n\t\t */\n\t\tret = user_regset_copyout(&pos, &count, &kbuf, &ubuf, xsave, 0, -1);\n\t}\n\treturn ret;\n}\n\nint xstateregs_set(struct task_struct *target, const struct user_regset *regset,\n\t\t  unsigned int pos, unsigned int count,\n\t\t  const void *kbuf, const void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\tstruct xregs_state *xsave;\n\tint ret;\n\n\tif (!boot_cpu_has(X86_FEATURE_XSAVE))\n\t\treturn -ENODEV;\n\n\t/*\n\t * A whole standard-format XSAVE buffer is needed:\n\t */\n\tif ((pos != 0) || (count < fpu_user_xstate_size))\n\t\treturn -EFAULT;\n\n\txsave = &fpu->state.xsave;\n\n\tfpu__activate_fpstate_write(fpu);\n\n\tif (boot_cpu_has(X86_FEATURE_XSAVES)) {\n\t\tif (kbuf)\n\t\t\tret = copy_kernel_to_xstate(xsave, kbuf);\n\t\telse\n\t\t\tret = copy_user_to_xstate(xsave, ubuf);\n\t} else {\n\t\tret = user_regset_copyin(&pos, &count, &kbuf, &ubuf, xsave, 0, -1);\n\n\t\t/* xcomp_bv must be 0 when using uncompacted format */\n\t\tif (!ret && xsave->header.xcomp_bv)\n\t\t\tret = -EINVAL;\n\t}\n\n\t/*\n\t * In case of failure, mark all states as init:\n\t */\n\tif (ret)\n\t\tfpstate_init(&fpu->state);\n\n\t/*\n\t * mxcsr reserved bits must be masked to zero for security reasons.\n\t */\n\txsave->i387.mxcsr &= mxcsr_feature_mask;\n\txsave->header.xfeatures &= xfeatures_mask;\n\t/*\n\t * These bits must be zero.\n\t */\n\tmemset(&xsave->header.reserved, 0, 48);\n\n\treturn ret;\n}\n\n#if defined CONFIG_X86_32 || defined CONFIG_IA32_EMULATION\n\n/*\n * FPU tag word conversions.\n */\n\nstatic inline unsigned short twd_i387_to_fxsr(unsigned short twd)\n{\n\tunsigned int tmp; /* to avoid 16 bit prefixes in the code */\n\n\t/* Transform each pair of bits into 01 (valid) or 00 (empty) */\n\ttmp = ~twd;\n\ttmp = (tmp | (tmp>>1)) & 0x5555; /* 0V0V0V0V0V0V0V0V */\n\t/* and move the valid bits to the lower byte. */\n\ttmp = (tmp | (tmp >> 1)) & 0x3333; /* 00VV00VV00VV00VV */\n\ttmp = (tmp | (tmp >> 2)) & 0x0f0f; /* 0000VVVV0000VVVV */\n\ttmp = (tmp | (tmp >> 4)) & 0x00ff; /* 00000000VVVVVVVV */\n\n\treturn tmp;\n}\n\n#define FPREG_ADDR(f, n)\t((void *)&(f)->st_space + (n) * 16)\n#define FP_EXP_TAG_VALID\t0\n#define FP_EXP_TAG_ZERO\t\t1\n#define FP_EXP_TAG_SPECIAL\t2\n#define FP_EXP_TAG_EMPTY\t3\n\nstatic inline u32 twd_fxsr_to_i387(struct fxregs_state *fxsave)\n{\n\tstruct _fpxreg *st;\n\tu32 tos = (fxsave->swd >> 11) & 7;\n\tu32 twd = (unsigned long) fxsave->twd;\n\tu32 tag;\n\tu32 ret = 0xffff0000u;\n\tint i;\n\n\tfor (i = 0; i < 8; i++, twd >>= 1) {\n\t\tif (twd & 0x1) {\n\t\t\tst = FPREG_ADDR(fxsave, (i - tos) & 7);\n\n\t\t\tswitch (st->exponent & 0x7fff) {\n\t\t\tcase 0x7fff:\n\t\t\t\ttag = FP_EXP_TAG_SPECIAL;\n\t\t\t\tbreak;\n\t\t\tcase 0x0000:\n\t\t\t\tif (!st->significand[0] &&\n\t\t\t\t    !st->significand[1] &&\n\t\t\t\t    !st->significand[2] &&\n\t\t\t\t    !st->significand[3])\n\t\t\t\t\ttag = FP_EXP_TAG_ZERO;\n\t\t\t\telse\n\t\t\t\t\ttag = FP_EXP_TAG_SPECIAL;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tif (st->significand[3] & 0x8000)\n\t\t\t\t\ttag = FP_EXP_TAG_VALID;\n\t\t\t\telse\n\t\t\t\t\ttag = FP_EXP_TAG_SPECIAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\ttag = FP_EXP_TAG_EMPTY;\n\t\t}\n\t\tret |= tag << (2 * i);\n\t}\n\treturn ret;\n}\n\n/*\n * FXSR floating point environment conversions.\n */\n\nvoid\nconvert_from_fxsr(struct user_i387_ia32_struct *env, struct task_struct *tsk)\n{\n\tstruct fxregs_state *fxsave = &tsk->thread.fpu.state.fxsave;\n\tstruct _fpreg *to = (struct _fpreg *) &env->st_space[0];\n\tstruct _fpxreg *from = (struct _fpxreg *) &fxsave->st_space[0];\n\tint i;\n\n\tenv->cwd = fxsave->cwd | 0xffff0000u;\n\tenv->swd = fxsave->swd | 0xffff0000u;\n\tenv->twd = twd_fxsr_to_i387(fxsave);\n\n#ifdef CONFIG_X86_64\n\tenv->fip = fxsave->rip;\n\tenv->foo = fxsave->rdp;\n\t/*\n\t * should be actually ds/cs at fpu exception time, but\n\t * that information is not available in 64bit mode.\n\t */\n\tenv->fcs = task_pt_regs(tsk)->cs;\n\tif (tsk == current) {\n\t\tsavesegment(ds, env->fos);\n\t} else {\n\t\tenv->fos = tsk->thread.ds;\n\t}\n\tenv->fos |= 0xffff0000;\n#else\n\tenv->fip = fxsave->fip;\n\tenv->fcs = (u16) fxsave->fcs | ((u32) fxsave->fop << 16);\n\tenv->foo = fxsave->foo;\n\tenv->fos = fxsave->fos;\n#endif\n\n\tfor (i = 0; i < 8; ++i)\n\t\tmemcpy(&to[i], &from[i], sizeof(to[0]));\n}\n\nvoid convert_to_fxsr(struct task_struct *tsk,\n\t\t     const struct user_i387_ia32_struct *env)\n\n{\n\tstruct fxregs_state *fxsave = &tsk->thread.fpu.state.fxsave;\n\tstruct _fpreg *from = (struct _fpreg *) &env->st_space[0];\n\tstruct _fpxreg *to = (struct _fpxreg *) &fxsave->st_space[0];\n\tint i;\n\n\tfxsave->cwd = env->cwd;\n\tfxsave->swd = env->swd;\n\tfxsave->twd = twd_i387_to_fxsr(env->twd);\n\tfxsave->fop = (u16) ((u32) env->fcs >> 16);\n#ifdef CONFIG_X86_64\n\tfxsave->rip = env->fip;\n\tfxsave->rdp = env->foo;\n\t/* cs and ds ignored */\n#else\n\tfxsave->fip = env->fip;\n\tfxsave->fcs = (env->fcs & 0xffff);\n\tfxsave->foo = env->foo;\n\tfxsave->fos = env->fos;\n#endif\n\n\tfor (i = 0; i < 8; ++i)\n\t\tmemcpy(&to[i], &from[i], sizeof(from[0]));\n}\n\nint fpregs_get(struct task_struct *target, const struct user_regset *regset,\n\t       unsigned int pos, unsigned int count,\n\t       void *kbuf, void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\tstruct user_i387_ia32_struct env;\n\n\tfpu__activate_fpstate_read(fpu);\n\n\tif (!boot_cpu_has(X86_FEATURE_FPU))\n\t\treturn fpregs_soft_get(target, regset, pos, count, kbuf, ubuf);\n\n\tif (!boot_cpu_has(X86_FEATURE_FXSR))\n\t\treturn user_regset_copyout(&pos, &count, &kbuf, &ubuf,\n\t\t\t\t\t   &fpu->state.fsave, 0,\n\t\t\t\t\t   -1);\n\n\tfpstate_sanitize_xstate(fpu);\n\n\tif (kbuf && pos == 0 && count == sizeof(env)) {\n\t\tconvert_from_fxsr(kbuf, target);\n\t\treturn 0;\n\t}\n\n\tconvert_from_fxsr(&env, target);\n\n\treturn user_regset_copyout(&pos, &count, &kbuf, &ubuf, &env, 0, -1);\n}\n\nint fpregs_set(struct task_struct *target, const struct user_regset *regset,\n\t       unsigned int pos, unsigned int count,\n\t       const void *kbuf, const void __user *ubuf)\n{\n\tstruct fpu *fpu = &target->thread.fpu;\n\tstruct user_i387_ia32_struct env;\n\tint ret;\n\n\tfpu__activate_fpstate_write(fpu);\n\tfpstate_sanitize_xstate(fpu);\n\n\tif (!boot_cpu_has(X86_FEATURE_FPU))\n\t\treturn fpregs_soft_set(target, regset, pos, count, kbuf, ubuf);\n\n\tif (!boot_cpu_has(X86_FEATURE_FXSR))\n\t\treturn user_regset_copyin(&pos, &count, &kbuf, &ubuf,\n\t\t\t\t\t  &fpu->state.fsave, 0,\n\t\t\t\t\t  -1);\n\n\tif (pos > 0 || count < sizeof(env))\n\t\tconvert_from_fxsr(&env, target);\n\n\tret = user_regset_copyin(&pos, &count, &kbuf, &ubuf, &env, 0, -1);\n\tif (!ret)\n\t\tconvert_to_fxsr(target, &env);\n\n\t/*\n\t * update the header bit in the xsave header, indicating the\n\t * presence of FP.\n\t */\n\tif (boot_cpu_has(X86_FEATURE_XSAVE))\n\t\tfpu->state.xsave.header.xfeatures |= XFEATURE_MASK_FP;\n\treturn ret;\n}\n\n/*\n * FPU state for core dumps.\n * This is only used for a.out dumps now.\n * It is declared generically using elf_fpregset_t (which is\n * struct user_i387_struct) but is in fact only used for 32-bit\n * dumps, so on 64-bit it is really struct user_i387_ia32_struct.\n */\nint dump_fpu(struct pt_regs *regs, struct user_i387_struct *ufpu)\n{\n\tstruct task_struct *tsk = current;\n\tstruct fpu *fpu = &tsk->thread.fpu;\n\tint fpvalid;\n\n\tfpvalid = fpu->fpstate_active;\n\tif (fpvalid)\n\t\tfpvalid = !fpregs_get(tsk, NULL,\n\t\t\t\t      0, sizeof(struct user_i387_ia32_struct),\n\t\t\t\t      ufpu, NULL);\n\n\treturn fpvalid;\n}\nEXPORT_SYMBOL(dump_fpu);\n\n#endif\t/* CONFIG_X86_32 || CONFIG_IA32_EMULATION */\n", "/*\n * FPU signal frame handling routines.\n */\n\n#include <linux/compat.h>\n#include <linux/cpu.h>\n\n#include <asm/fpu/internal.h>\n#include <asm/fpu/signal.h>\n#include <asm/fpu/regset.h>\n#include <asm/fpu/xstate.h>\n\n#include <asm/sigframe.h>\n#include <asm/trace/fpu.h>\n\nstatic struct _fpx_sw_bytes fx_sw_reserved, fx_sw_reserved_ia32;\n\n/*\n * Check for the presence of extended state information in the\n * user fpstate pointer in the sigcontext.\n */\nstatic inline int check_for_xstate(struct fxregs_state __user *buf,\n\t\t\t\t   void __user *fpstate,\n\t\t\t\t   struct _fpx_sw_bytes *fx_sw)\n{\n\tint min_xstate_size = sizeof(struct fxregs_state) +\n\t\t\t      sizeof(struct xstate_header);\n\tunsigned int magic2;\n\n\tif (__copy_from_user(fx_sw, &buf->sw_reserved[0], sizeof(*fx_sw)))\n\t\treturn -1;\n\n\t/* Check for the first magic field and other error scenarios. */\n\tif (fx_sw->magic1 != FP_XSTATE_MAGIC1 ||\n\t    fx_sw->xstate_size < min_xstate_size ||\n\t    fx_sw->xstate_size > fpu_user_xstate_size ||\n\t    fx_sw->xstate_size > fx_sw->extended_size)\n\t\treturn -1;\n\n\t/*\n\t * Check for the presence of second magic word at the end of memory\n\t * layout. This detects the case where the user just copied the legacy\n\t * fpstate layout with out copying the extended state information\n\t * in the memory layout.\n\t */\n\tif (__get_user(magic2, (__u32 __user *)(fpstate + fx_sw->xstate_size))\n\t    || magic2 != FP_XSTATE_MAGIC2)\n\t\treturn -1;\n\n\treturn 0;\n}\n\n/*\n * Signal frame handlers.\n */\nstatic inline int save_fsave_header(struct task_struct *tsk, void __user *buf)\n{\n\tif (use_fxsr()) {\n\t\tstruct xregs_state *xsave = &tsk->thread.fpu.state.xsave;\n\t\tstruct user_i387_ia32_struct env;\n\t\tstruct _fpstate_32 __user *fp = buf;\n\n\t\tconvert_from_fxsr(&env, tsk);\n\n\t\tif (__copy_to_user(buf, &env, sizeof(env)) ||\n\t\t    __put_user(xsave->i387.swd, &fp->status) ||\n\t\t    __put_user(X86_FXSR_MAGIC, &fp->magic))\n\t\t\treturn -1;\n\t} else {\n\t\tstruct fregs_state __user *fp = buf;\n\t\tu32 swd;\n\t\tif (__get_user(swd, &fp->swd) || __put_user(swd, &fp->status))\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nstatic inline int save_xstate_epilog(void __user *buf, int ia32_frame)\n{\n\tstruct xregs_state __user *x = buf;\n\tstruct _fpx_sw_bytes *sw_bytes;\n\tu32 xfeatures;\n\tint err;\n\n\t/* Setup the bytes not touched by the [f]xsave and reserved for SW. */\n\tsw_bytes = ia32_frame ? &fx_sw_reserved_ia32 : &fx_sw_reserved;\n\terr = __copy_to_user(&x->i387.sw_reserved, sw_bytes, sizeof(*sw_bytes));\n\n\tif (!use_xsave())\n\t\treturn err;\n\n\terr |= __put_user(FP_XSTATE_MAGIC2,\n\t\t\t  (__u32 *)(buf + fpu_user_xstate_size));\n\n\t/*\n\t * Read the xfeatures which we copied (directly from the cpu or\n\t * from the state in task struct) to the user buffers.\n\t */\n\terr |= __get_user(xfeatures, (__u32 *)&x->header.xfeatures);\n\n\t/*\n\t * For legacy compatible, we always set FP/SSE bits in the bit\n\t * vector while saving the state to the user context. This will\n\t * enable us capturing any changes(during sigreturn) to\n\t * the FP/SSE bits by the legacy applications which don't touch\n\t * xfeatures in the xsave header.\n\t *\n\t * xsave aware apps can change the xfeatures in the xsave\n\t * header as well as change any contents in the memory layout.\n\t * xrestore as part of sigreturn will capture all the changes.\n\t */\n\txfeatures |= XFEATURE_MASK_FPSSE;\n\n\terr |= __put_user(xfeatures, (__u32 *)&x->header.xfeatures);\n\n\treturn err;\n}\n\nstatic inline int copy_fpregs_to_sigframe(struct xregs_state __user *buf)\n{\n\tint err;\n\n\tif (use_xsave())\n\t\terr = copy_xregs_to_user(buf);\n\telse if (use_fxsr())\n\t\terr = copy_fxregs_to_user((struct fxregs_state __user *) buf);\n\telse\n\t\terr = copy_fregs_to_user((struct fregs_state __user *) buf);\n\n\tif (unlikely(err) && __clear_user(buf, fpu_user_xstate_size))\n\t\terr = -EFAULT;\n\treturn err;\n}\n\n/*\n * Save the fpu, extended register state to the user signal frame.\n *\n * 'buf_fx' is the 64-byte aligned pointer at which the [f|fx|x]save\n *  state is copied.\n *  'buf' points to the 'buf_fx' or to the fsave header followed by 'buf_fx'.\n *\n *\tbuf == buf_fx for 64-bit frames and 32-bit fsave frame.\n *\tbuf != buf_fx for 32-bit frames with fxstate.\n *\n * If the fpu, extended register state is live, save the state directly\n * to the user frame pointed by the aligned pointer 'buf_fx'. Otherwise,\n * copy the thread's fpu state to the user frame starting at 'buf_fx'.\n *\n * If this is a 32-bit frame with fxstate, put a fsave header before\n * the aligned state at 'buf_fx'.\n *\n * For [f]xsave state, update the SW reserved fields in the [f]xsave frame\n * indicating the absence/presence of the extended state to the user.\n */\nint copy_fpstate_to_sigframe(void __user *buf, void __user *buf_fx, int size)\n{\n\tstruct fpu *fpu = &current->thread.fpu;\n\tstruct xregs_state *xsave = &fpu->state.xsave;\n\tstruct task_struct *tsk = current;\n\tint ia32_fxstate = (buf != buf_fx);\n\n\tia32_fxstate &= (IS_ENABLED(CONFIG_X86_32) ||\n\t\t\t IS_ENABLED(CONFIG_IA32_EMULATION));\n\n\tif (!access_ok(VERIFY_WRITE, buf, size))\n\t\treturn -EACCES;\n\n\tif (!static_cpu_has(X86_FEATURE_FPU))\n\t\treturn fpregs_soft_get(current, NULL, 0,\n\t\t\tsizeof(struct user_i387_ia32_struct), NULL,\n\t\t\t(struct _fpstate_32 __user *) buf) ? -1 : 1;\n\n\tif (fpu->fpstate_active || using_compacted_format()) {\n\t\t/* Save the live register state to the user directly. */\n\t\tif (copy_fpregs_to_sigframe(buf_fx))\n\t\t\treturn -1;\n\t\t/* Update the thread's fxstate to save the fsave header. */\n\t\tif (ia32_fxstate)\n\t\t\tcopy_fxregs_to_kernel(fpu);\n\t} else {\n\t\t/*\n\t\t * It is a *bug* if kernel uses compacted-format for xsave\n\t\t * area and we copy it out directly to a signal frame. It\n\t\t * should have been handled above by saving the registers\n\t\t * directly.\n\t\t */\n\t\tif (boot_cpu_has(X86_FEATURE_XSAVES)) {\n\t\t\tWARN_ONCE(1, \"x86/fpu: saving compacted-format xsave area to a signal frame!\\n\");\n\t\t\treturn -1;\n\t\t}\n\n\t\tfpstate_sanitize_xstate(fpu);\n\t\tif (__copy_to_user(buf_fx, xsave, fpu_user_xstate_size))\n\t\t\treturn -1;\n\t}\n\n\t/* Save the fsave header for the 32-bit frames. */\n\tif ((ia32_fxstate || !use_fxsr()) && save_fsave_header(tsk, buf))\n\t\treturn -1;\n\n\tif (use_fxsr() && save_xstate_epilog(buf_fx, ia32_fxstate))\n\t\treturn -1;\n\n\treturn 0;\n}\n\nstatic inline void\nsanitize_restored_xstate(struct task_struct *tsk,\n\t\t\t struct user_i387_ia32_struct *ia32_env,\n\t\t\t u64 xfeatures, int fx_only)\n{\n\tstruct xregs_state *xsave = &tsk->thread.fpu.state.xsave;\n\tstruct xstate_header *header = &xsave->header;\n\n\tif (use_xsave()) {\n\t\t/* These bits must be zero. */\n\t\tmemset(header->reserved, 0, 48);\n\n\t\t/*\n\t\t * Init the state that is not present in the memory\n\t\t * layout and not enabled by the OS.\n\t\t */\n\t\tif (fx_only)\n\t\t\theader->xfeatures = XFEATURE_MASK_FPSSE;\n\t\telse\n\t\t\theader->xfeatures &= (xfeatures_mask & xfeatures);\n\t}\n\n\tif (use_fxsr()) {\n\t\t/*\n\t\t * mscsr reserved bits must be masked to zero for security\n\t\t * reasons.\n\t\t */\n\t\txsave->i387.mxcsr &= mxcsr_feature_mask;\n\n\t\tconvert_to_fxsr(tsk, ia32_env);\n\t}\n}\n\n/*\n * Restore the extended state if present. Otherwise, restore the FP/SSE state.\n */\nstatic inline int copy_user_to_fpregs_zeroing(void __user *buf, u64 xbv, int fx_only)\n{\n\tif (use_xsave()) {\n\t\tif ((unsigned long)buf % 64 || fx_only) {\n\t\t\tu64 init_bv = xfeatures_mask & ~XFEATURE_MASK_FPSSE;\n\t\t\tcopy_kernel_to_xregs(&init_fpstate.xsave, init_bv);\n\t\t\treturn copy_user_to_fxregs(buf);\n\t\t} else {\n\t\t\tu64 init_bv = xfeatures_mask & ~xbv;\n\t\t\tif (unlikely(init_bv))\n\t\t\t\tcopy_kernel_to_xregs(&init_fpstate.xsave, init_bv);\n\t\t\treturn copy_user_to_xregs(buf, xbv);\n\t\t}\n\t} else if (use_fxsr()) {\n\t\treturn copy_user_to_fxregs(buf);\n\t} else\n\t\treturn copy_user_to_fregs(buf);\n}\n\nstatic int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)\n{\n\tint ia32_fxstate = (buf != buf_fx);\n\tstruct task_struct *tsk = current;\n\tstruct fpu *fpu = &tsk->thread.fpu;\n\tint state_size = fpu_kernel_xstate_size;\n\tu64 xfeatures = 0;\n\tint fx_only = 0;\n\n\tia32_fxstate &= (IS_ENABLED(CONFIG_X86_32) ||\n\t\t\t IS_ENABLED(CONFIG_IA32_EMULATION));\n\n\tif (!buf) {\n\t\tfpu__clear(fpu);\n\t\treturn 0;\n\t}\n\n\tif (!access_ok(VERIFY_READ, buf, size))\n\t\treturn -EACCES;\n\n\tfpu__activate_curr(fpu);\n\n\tif (!static_cpu_has(X86_FEATURE_FPU))\n\t\treturn fpregs_soft_set(current, NULL,\n\t\t\t\t       0, sizeof(struct user_i387_ia32_struct),\n\t\t\t\t       NULL, buf) != 0;\n\n\tif (use_xsave()) {\n\t\tstruct _fpx_sw_bytes fx_sw_user;\n\t\tif (unlikely(check_for_xstate(buf_fx, buf_fx, &fx_sw_user))) {\n\t\t\t/*\n\t\t\t * Couldn't find the extended state information in the\n\t\t\t * memory layout. Restore just the FP/SSE and init all\n\t\t\t * the other extended state.\n\t\t\t */\n\t\t\tstate_size = sizeof(struct fxregs_state);\n\t\t\tfx_only = 1;\n\t\t\ttrace_x86_fpu_xstate_check_failed(fpu);\n\t\t} else {\n\t\t\tstate_size = fx_sw_user.xstate_size;\n\t\t\txfeatures = fx_sw_user.xfeatures;\n\t\t}\n\t}\n\n\tif (ia32_fxstate) {\n\t\t/*\n\t\t * For 32-bit frames with fxstate, copy the user state to the\n\t\t * thread's fpu state, reconstruct fxstate from the fsave\n\t\t * header. Sanitize the copied state etc.\n\t\t */\n\t\tstruct fpu *fpu = &tsk->thread.fpu;\n\t\tstruct user_i387_ia32_struct env;\n\t\tint err = 0;\n\n\t\t/*\n\t\t * Drop the current fpu which clears fpu->fpstate_active. This ensures\n\t\t * that any context-switch during the copy of the new state,\n\t\t * avoids the intermediate state from getting restored/saved.\n\t\t * Thus avoiding the new restored state from getting corrupted.\n\t\t * We will be ready to restore/save the state only after\n\t\t * fpu->fpstate_active is again set.\n\t\t */\n\t\tfpu__drop(fpu);\n\n\t\tif (using_compacted_format()) {\n\t\t\terr = copy_user_to_xstate(&fpu->state.xsave, buf_fx);\n\t\t} else {\n\t\t\terr = __copy_from_user(&fpu->state.xsave, buf_fx, state_size);\n\n\t\t\t/* xcomp_bv must be 0 when using uncompacted format */\n\t\t\tif (!err && state_size > offsetof(struct xregs_state, header) && fpu->state.xsave.header.xcomp_bv)\n\t\t\t\terr = -EINVAL;\n\t\t}\n\n\t\tif (err || __copy_from_user(&env, buf, sizeof(env))) {\n\t\t\tfpstate_init(&fpu->state);\n\t\t\ttrace_x86_fpu_init_state(fpu);\n\t\t\terr = -1;\n\t\t} else {\n\t\t\tsanitize_restored_xstate(tsk, &env, xfeatures, fx_only);\n\t\t}\n\n\t\tfpu->fpstate_active = 1;\n\t\tpreempt_disable();\n\t\tfpu__restore(fpu);\n\t\tpreempt_enable();\n\n\t\treturn err;\n\t} else {\n\t\t/*\n\t\t * For 64-bit frames and 32-bit fsave frames, restore the user\n\t\t * state to the registers directly (with exceptions handled).\n\t\t */\n\t\tuser_fpu_begin();\n\t\tif (copy_user_to_fpregs_zeroing(buf_fx, xfeatures, fx_only)) {\n\t\t\tfpu__clear(fpu);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic inline int xstate_sigframe_size(void)\n{\n\treturn use_xsave() ? fpu_user_xstate_size + FP_XSTATE_MAGIC2_SIZE :\n\t\t\tfpu_user_xstate_size;\n}\n\n/*\n * Restore FPU state from a sigframe:\n */\nint fpu__restore_sig(void __user *buf, int ia32_frame)\n{\n\tvoid __user *buf_fx = buf;\n\tint size = xstate_sigframe_size();\n\n\tif (ia32_frame && use_fxsr()) {\n\t\tbuf_fx = buf + sizeof(struct fregs_state);\n\t\tsize += sizeof(struct fregs_state);\n\t}\n\n\treturn __fpu__restore_sig(buf, buf_fx, size);\n}\n\nunsigned long\nfpu__alloc_mathframe(unsigned long sp, int ia32_frame,\n\t\t     unsigned long *buf_fx, unsigned long *size)\n{\n\tunsigned long frame_size = xstate_sigframe_size();\n\n\t*buf_fx = sp = round_down(sp - frame_size, 64);\n\tif (ia32_frame && use_fxsr()) {\n\t\tframe_size += sizeof(struct fregs_state);\n\t\tsp -= sizeof(struct fregs_state);\n\t}\n\n\t*size = frame_size;\n\n\treturn sp;\n}\n/*\n * Prepare the SW reserved portion of the fxsave memory layout, indicating\n * the presence of the extended state information in the memory layout\n * pointed by the fpstate pointer in the sigcontext.\n * This will be saved when ever the FP and extended state context is\n * saved on the user stack during the signal handler delivery to the user.\n */\nvoid fpu__init_prepare_fx_sw_frame(void)\n{\n\tint size = fpu_user_xstate_size + FP_XSTATE_MAGIC2_SIZE;\n\n\tfx_sw_reserved.magic1 = FP_XSTATE_MAGIC1;\n\tfx_sw_reserved.extended_size = size;\n\tfx_sw_reserved.xfeatures = xfeatures_mask;\n\tfx_sw_reserved.xstate_size = fpu_user_xstate_size;\n\n\tif (IS_ENABLED(CONFIG_IA32_EMULATION) ||\n\t    IS_ENABLED(CONFIG_X86_32)) {\n\t\tint fsave_header_size = sizeof(struct fregs_state);\n\n\t\tfx_sw_reserved_ia32 = fx_sw_reserved;\n\t\tfx_sw_reserved_ia32.extended_size = size + fsave_header_size;\n\t}\n}\n\n"], "filenames": ["arch/x86/kernel/fpu/regset.c", "arch/x86/kernel/fpu/signal.c"], "buggy_code_start_loc": [143, 327], "buggy_code_end_loc": [143, 330], "fixing_code_start_loc": [144, 327], "fixing_code_end_loc": [148, 336], "type": "CWE-200", "message": "The x86/fpu (Floating Point Unit) subsystem in the Linux kernel before 4.13.5, when a processor supports the xsave feature but not the xsaves feature, does not correctly handle attempts to set reserved bits in the xstate header via the ptrace() or rt_sigreturn() system call, allowing local users to read the FPU registers of other processes on the system, related to arch/x86/kernel/fpu/regset.c and arch/x86/kernel/fpu/signal.c.", "other": {"cve": {"id": "CVE-2017-15537", "sourceIdentifier": "cve@mitre.org", "published": "2017-10-17T18:29:00.197", "lastModified": "2018-01-13T02:29:13.083", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The x86/fpu (Floating Point Unit) subsystem in the Linux kernel before 4.13.5, when a processor supports the xsave feature but not the xsaves feature, does not correctly handle attempts to set reserved bits in the xstate header via the ptrace() or rt_sigreturn() system call, allowing local users to read the FPU registers of other processes on the system, related to arch/x86/kernel/fpu/regset.c and arch/x86/kernel/fpu/signal.c."}, {"lang": "es", "value": "El subsistema x86/fpu (Floating Point Unit) en el kernel de Linux en versiones anteriores a la 4.13.5, cuando un procesador soporta la caracter\u00edstica xsave pero no la xsaves, no gestiona correctamente los intentos de establecer bits reservados en la cabecera xstate mediante las llamadas de sistema ptrace() o rt_sigreturn(), lo que permite que usuarios locales lean los registros FPU de otros procesos en el sistema, relacionado con arch/x86/kernel/fpu/regset.c y arch/x86/kernel/fpu/signal.c."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:N/A:N", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-200"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "4.13.4", "matchCriteriaId": "928AB8DD-8573-4425-803D-1B164491BF77"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=814fb7bb7db5433757d76f4c4502c96fc53b0b5e", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://www.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.13.5", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/814fb7bb7db5433757d76f4c4502c96fc53b0b5e", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://source.android.com/security/bulletin/pixel/2018-01-01", "source": "cve@mitre.org"}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/814fb7bb7db5433757d76f4c4502c96fc53b0b5e"}}
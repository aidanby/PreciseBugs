{"buggy_code": ["/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// SparseDenseBinaryOpShared is the shared code for binary coefficient-wise\n// (cwise) operations of the following form:\n//\n//   sparse_t <binary cwise op> dense_t -> new sparse_t\n//\n// where:\n//\n//   (1) \"binary cwise op\" can be, for example, cdiv, cmul, cfloordiv, etc.\n//   (2) LIMITATION: we only support broadcasting the dense side to the sparse\n//       side.  In other words, NumDims(sparse_t) >= NumDims(dense_t), and if\n//       they are equal, each dim size of sparse_t >= that of dense_t.\n//   (3) Note that the result is a new sparse tensor, which means the implicitly\n//       zero elements of sparse_t do not participate.  (Hence, this should not\n//       be used for, say, cadd.)\n//\n// The only output is a vector of flat values with shape [nnz], since this op\n// does not change neither the indices nor the shape of the sparse operand.\n//\n// See docs of all registered ops in ../ops/sparse_ops.cc.\n\n#define EIGEN_USE_THREADS\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_util.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/kernels/cwise_ops.h\"\n#include \"tensorflow/core/kernels/cwise_ops_common.h\"\n#include \"tensorflow/core/util/bcast.h\"\n\nusing Eigen::TensorRef;\nusing tensorflow::gtl::ArraySlice;\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\n\ntemplate <typename Device, typename T, typename Functor>\nclass SparseDenseBinaryOpShared : public OpKernel {\n public:\n  explicit SparseDenseBinaryOpShared(OpKernelConstruction *ctx)\n      : OpKernel(ctx) {}\n\n  void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *dense_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense\", &dense_t));\n\n    // Validations.\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices_t->shape()),\n                errors::InvalidArgument(\n                    \"Input sp_indices should be a matrix but received shape: \",\n                    indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(values_t->shape()) &&\n                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of values and indices should match. (\",\n            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n\n    const auto indices_mat = indices_t->matrix<int64>();\n    const auto shape_vec = shape_t->vec<int64>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal\n    // to dims in rhs (from right to left).\n    auto VecGreaterEq = [](ArraySlice<int64> lhs, ArraySlice<int64> rhs) {\n      if (lhs.size() < rhs.size()) return false;\n      for (size_t i = 0; i < rhs.size(); ++i) {\n        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;\n      }\n      return true;\n    };\n    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),\n                errors::InvalidArgument(\n                    \"SparseDenseBinaryOpShared broadcasts dense to sparse \"\n                    \"only; got incompatible shapes: [\",\n                    absl::StrJoin(lhs_dims, \",\"), \"] vs. [\",\n                    absl::StrJoin(rhs_dims, \",\"), \"]\"));\n\n    Tensor *output_values = nullptr;\n    Tensor dense_gathered;\n    const int64 nnz = indices_t->dim_size(0);\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({nnz}), &output_values));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                &dense_gathered));\n\n    // Pulls relevant entries from the dense side, with reshape and broadcasting\n    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n    // up memory.\n    //\n    // We can directly use the sparse indices to look up dense side, because\n    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".\n    auto dense_gathered_flat = dense_gathered.flat<T>();\n    const int ndims = lhs_dims.size();\n    switch (ndims) {\n#define CASE(NDIM)                                                             \\\n  case NDIM: {                                                                 \\\n    TensorRef<Eigen::Tensor<const T, NDIM, Eigen::RowMajor>> rhs_ref =         \\\n        dense_t->shaped<T, NDIM>(b.y_reshape())                                \\\n            .broadcast(BCast::ToIndexArray<NDIM>(b.y_bcast()));                \\\n    Eigen::array<Eigen::DenseIndex, NDIM> idx;                                 \\\n    bool indices_valid = true;                                                 \\\n    for (int i = 0; i < nnz; ++i) {                                            \\\n      for (int d = 0; d < NDIM; ++d) {                                         \\\n        idx[d] = internal::SubtleMustCopy(indices_mat(i, d));                  \\\n        if (!FastBoundsCheck(idx[d], rhs_ref.dimension(d))) {                  \\\n          indices_valid = false;                                               \\\n        }                                                                      \\\n      }                                                                        \\\n      OP_REQUIRES(                                                             \\\n          ctx, indices_valid,                                                  \\\n          errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                  \"dense side with broadcasted shape\"));       \\\n      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n    }                                                                          \\\n    break;                                                                     \\\n  }\n\n      CASE(1);\n      CASE(2);\n      CASE(3);\n      CASE(4);\n      CASE(5);\n      default:\n        OP_REQUIRES(\n            ctx, false,\n            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \"\n                                    \"are currently supported.  Tensor rank: \",\n                                    ndims));\n#undef CASE\n    }\n\n    output_values->flat<T>().device(ctx->eigen_device<Device>()) =\n        values_t->flat<T>().binaryExpr(dense_gathered_flat,\n                                       typename Functor::func());\n  }\n};\n\n// NOTE(aselle): If Div is extended to non-reals, make sure to use the same\n// separation of operator semantics as done for dense cwise ops. I.e. you\n// should make SparseDenseCwiseRealDiv, SparseDenseCwiseTruncateDiv,\n// SparseDenseCwiseFloorDiv, and then deprecate, SparseDenseCwiseDiv.\n// TODO(zongheng): extend to other eligible cwise operations as requested.\n#define REGISTER_KERNELS(T)                                                  \\\n  REGISTER_KERNEL_BUILDER(                                                   \\\n      Name(\"SparseDenseCwiseMul\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n      SparseDenseBinaryOpShared<CPUDevice, T, functor::mul<T>>)              \\\n                                                                             \\\n  REGISTER_KERNEL_BUILDER(                                                   \\\n      Name(\"SparseDenseCwiseDiv\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n      SparseDenseBinaryOpShared<CPUDevice, T, functor::div<T>>)              \\\n  REGISTER_KERNEL_BUILDER(                                                   \\\n      Name(\"SparseDenseCwiseAdd\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n      SparseDenseBinaryOpShared<CPUDevice, T, functor::add<T>>)\n\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\n#undef REGISTER_KERNELS\n\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// SparseDenseBinaryOpShared is the shared code for binary coefficient-wise\n// (cwise) operations of the following form:\n//\n//   sparse_t <binary cwise op> dense_t -> new sparse_t\n//\n// where:\n//\n//   (1) \"binary cwise op\" can be, for example, cdiv, cmul, cfloordiv, etc.\n//   (2) LIMITATION: we only support broadcasting the dense side to the sparse\n//       side.  In other words, NumDims(sparse_t) >= NumDims(dense_t), and if\n//       they are equal, each dim size of sparse_t >= that of dense_t.\n//   (3) Note that the result is a new sparse tensor, which means the implicitly\n//       zero elements of sparse_t do not participate.  (Hence, this should not\n//       be used for, say, cadd.)\n//\n// The only output is a vector of flat values with shape [nnz], since this op\n// does not change neither the indices nor the shape of the sparse operand.\n//\n// See docs of all registered ops in ../ops/sparse_ops.cc.\n\n#define EIGEN_USE_THREADS\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_util.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/kernels/cwise_ops.h\"\n#include \"tensorflow/core/kernels/cwise_ops_common.h\"\n#include \"tensorflow/core/util/bcast.h\"\n\nusing Eigen::TensorRef;\nusing tensorflow::gtl::ArraySlice;\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\n\ntemplate <typename Device, typename T, typename Functor>\nclass SparseDenseBinaryOpShared : public OpKernel {\n public:\n  explicit SparseDenseBinaryOpShared(OpKernelConstruction *ctx)\n      : OpKernel(ctx) {}\n\n  void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *dense_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense\", &dense_t));\n\n    // Validations.\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices_t->shape()),\n                errors::InvalidArgument(\n                    \"Input sp_indices should be a matrix but received shape: \",\n                    indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(values_t->shape()) &&\n                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of values and indices should match. (\",\n            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n\n    const auto indices_mat = indices_t->matrix<int64>();\n    const auto shape_vec = shape_t->vec<int64>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal\n    // to dims in rhs (from right to left).\n    auto VecGreaterEq = [](ArraySlice<int64> lhs, ArraySlice<int64> rhs) {\n      if (lhs.size() < rhs.size()) return false;\n      for (size_t i = 0; i < rhs.size(); ++i) {\n        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;\n      }\n      return true;\n    };\n    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),\n                errors::InvalidArgument(\n                    \"SparseDenseBinaryOpShared broadcasts dense to sparse \"\n                    \"only; got incompatible shapes: [\",\n                    absl::StrJoin(lhs_dims, \",\"), \"] vs. [\",\n                    absl::StrJoin(rhs_dims, \",\"), \"]\"));\n\n    Tensor *output_values = nullptr;\n    Tensor dense_gathered;\n    const int64 nnz = indices_t->dim_size(0);\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({nnz}), &output_values));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                &dense_gathered));\n    bool op_is_div = false;\n    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {\n      op_is_div = true;\n    }\n    // Pulls relevant entries from the dense side, with reshape and broadcasting\n    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n    // up memory.\n    //\n    // We can directly use the sparse indices to look up dense side, because\n    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".\n    auto dense_gathered_flat = dense_gathered.flat<T>();\n    const int ndims = lhs_dims.size();\n    switch (ndims) {\n#define CASE(NDIM)                                                             \\\n  case NDIM: {                                                                 \\\n    TensorRef<Eigen::Tensor<const T, NDIM, Eigen::RowMajor>> rhs_ref =         \\\n        dense_t->shaped<T, NDIM>(b.y_reshape())                                \\\n            .broadcast(BCast::ToIndexArray<NDIM>(b.y_bcast()));                \\\n    Eigen::array<Eigen::DenseIndex, NDIM> idx;                                 \\\n    bool indices_valid = true;                                                 \\\n    for (int i = 0; i < nnz; ++i) {                                            \\\n      for (int d = 0; d < NDIM; ++d) {                                         \\\n        idx[d] = internal::SubtleMustCopy(indices_mat(i, d));                  \\\n        if (!FastBoundsCheck(idx[d], rhs_ref.dimension(d))) {                  \\\n          indices_valid = false;                                               \\\n        }                                                                      \\\n      }                                                                        \\\n      OP_REQUIRES(                                                             \\\n          ctx, indices_valid,                                                  \\\n          errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                  \"dense side with broadcasted shape\"));       \\\n      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n      if (op_is_div) {                                                         \\\n        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\\n                    errors::InvalidArgument(                                   \\\n                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\\n                        \"but input dense tensor contains zero \"));             \\\n      }                                                                        \\\n    }                                                                          \\\n    break;                                                                     \\\n  }\n\n      CASE(1);\n      CASE(2);\n      CASE(3);\n      CASE(4);\n      CASE(5);\n      default:\n        OP_REQUIRES(\n            ctx, false,\n            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \"\n                                    \"are currently supported.  Tensor rank: \",\n                                    ndims));\n#undef CASE\n    }\n\n    output_values->flat<T>().device(ctx->eigen_device<Device>()) =\n        values_t->flat<T>().binaryExpr(dense_gathered_flat,\n                                       typename Functor::func());\n  }\n};\n\n// NOTE(aselle): If Div is extended to non-reals, make sure to use the same\n// separation of operator semantics as done for dense cwise ops. I.e. you\n// should make SparseDenseCwiseRealDiv, SparseDenseCwiseTruncateDiv,\n// SparseDenseCwiseFloorDiv, and then deprecate, SparseDenseCwiseDiv.\n// TODO(zongheng): extend to other eligible cwise operations as requested.\n#define REGISTER_KERNELS(T)                                                  \\\n  REGISTER_KERNEL_BUILDER(                                                   \\\n      Name(\"SparseDenseCwiseMul\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n      SparseDenseBinaryOpShared<CPUDevice, T, functor::mul<T>>)              \\\n                                                                             \\\n  REGISTER_KERNEL_BUILDER(                                                   \\\n      Name(\"SparseDenseCwiseDiv\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n      SparseDenseBinaryOpShared<CPUDevice, T, functor::div<T>>)              \\\n  REGISTER_KERNEL_BUILDER(                                                   \\\n      Name(\"SparseDenseCwiseAdd\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n      SparseDenseBinaryOpShared<CPUDevice, T, functor::add<T>>)\n\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\n#undef REGISTER_KERNELS\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/kernels/sparse_dense_binary_op_shared.cc"], "buggy_code_start_loc": [117], "buggy_code_end_loc": [145], "fixing_code_start_loc": [117], "fixing_code_end_loc": [155], "type": "CWE-369", "message": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.SparseDenseCwiseDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/a1bc56203f21a5a4995311825ffaba7a670d7747/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc#L56) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit d9204be9f49520cdaaeb2541d1dc5187b23f31d9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-37636", "sourceIdentifier": "security-advisories@github.com", "published": "2021-08-12T18:15:10.377", "lastModified": "2021-08-18T17:35:16.090", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.SparseDenseCwiseDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/a1bc56203f21a5a4995311825ffaba7a670d7747/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc#L56) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit d9204be9f49520cdaaeb2541d1dc5187b23f31d9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto de extremo a extremo para el aprendizaje autom\u00e1tico. En las versiones afectadas la implementaci\u00f3n \"tf.raw_ops.SparseDenseCwiseDiv\" es vulnerable a un error de divisi\u00f3n por 0. La [implementaci\u00f3n](https://github.com/tensorflow/tensorflow/blob/a1bc56203f21a5a4995311825ffaba7a670d7747/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc#L56) usa una clase com\u00fan para todas las operaciones binarias pero no trata el caso de la divisi\u00f3n por 0 por separado. Hemos parcheado el problema en el commit d9204be9f49520cdaaeb2541d1dc5187b23f31d9 de GitHub. La correcci\u00f3n se incluir\u00e1 en TensorFlow versi\u00f3n 2.6.0. Tambi\u00e9n se incluir\u00e1 este commit en TensorFlow versi\u00f3n 2.5.1, TensorFlow versi\u00f3n 2.4.3 y TensorFlow versi\u00f3n 2.3.4, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango de soporte."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-369"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.4", "matchCriteriaId": "0F83C081-51CC-415F-A8C0-0A44C75E2CD6"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.3", "matchCriteriaId": "BD3F2BF8-EBA9-42BF-8F9B-D918B880B15A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.5.0:*:*:*:*:*:*:*", "matchCriteriaId": "D03E99A7-4E3D-427D-A156-C0713E9FB02A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc0:*:*:*:*:*:*", "matchCriteriaId": "70FA6E48-6C57-40CA-809F-4E3D07CBF348"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc1:*:*:*:*:*:*", "matchCriteriaId": "42187561-E491-434D-828C-F36701446634"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc2:*:*:*:*:*:*", "matchCriteriaId": "C66B61C8-450A-4C5E-9174-F970D6DEE778"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/d9204be9f49520cdaaeb2541d1dc5187b23f31d9", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hp4c-x6r7-6555", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/d9204be9f49520cdaaeb2541d1dc5187b23f31d9"}}
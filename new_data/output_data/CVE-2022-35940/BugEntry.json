{"buggy_code": ["/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <limits>\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n\nnamespace tensorflow {\n\nusing errors::InvalidArgument;\n\ntemplate <typename T, typename SPLITS_TYPE>\nclass RaggedRangeOp : public OpKernel {\n public:\n  using OpKernel::OpKernel;\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& starts_in = context->input(0);\n    const Tensor& limits_in = context->input(1);\n    const Tensor& deltas_in = context->input(2);\n\n    // Check input tensor shapes.\n    OP_REQUIRES(context, starts_in.shape().dims() <= 1,\n                InvalidArgument(\"starts must be a scalar or vector\"));\n    OP_REQUIRES(context, limits_in.shape().dims() <= 1,\n                InvalidArgument(\"limits must be a scalar or vector\"));\n    OP_REQUIRES(context, deltas_in.shape().dims() <= 1,\n                InvalidArgument(\"deltas must be a scalar or vector\"));\n\n    // Determine which tensors we need to broadcast.\n    bool broadcast_starts = starts_in.shape().dims() == 0;\n    bool broadcast_limits = limits_in.shape().dims() == 0;\n    bool broadcast_deltas = deltas_in.shape().dims() == 0;\n\n    // nrows (number of output rows) is the size of the non-broadcast inputs,\n    // or 1 if all inputs are scalars.\n    std::vector<int> in_sizes;\n    if (!broadcast_starts) in_sizes.push_back(starts_in.shape().dim_size(0));\n    if (!broadcast_limits) in_sizes.push_back(limits_in.shape().dim_size(0));\n    if (!broadcast_deltas) in_sizes.push_back(deltas_in.shape().dim_size(0));\n    for (int i = 1; i < in_sizes.size(); ++i) {\n      OP_REQUIRES(context, in_sizes[i] == in_sizes[i - 1],\n                  InvalidArgument(\"starts, limits, and deltas must have the \"\n                                  \"same shape\"));\n    }\n    SPLITS_TYPE nrows = in_sizes.empty() ? 1 : in_sizes[0];\n\n    const auto& starts = starts_in.flat<T>();\n    const auto& limits = limits_in.flat<T>();\n    const auto& deltas = deltas_in.flat<T>();\n\n    // Construct the rt_nested_splits tensor.\n    Tensor* rt_nested_splits_out = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({nrows + 1}),\n                                            &rt_nested_splits_out));\n    auto rt_nested_splits = rt_nested_splits_out->flat<SPLITS_TYPE>();\n    rt_nested_splits(0) = 0;\n    for (int row = 0; row < nrows; ++row) {\n      T start = broadcast_starts ? starts(0) : starts(row);\n      T limit = broadcast_limits ? limits(0) : limits(row);\n      T delta = broadcast_deltas ? deltas(0) : deltas(row);\n      OP_REQUIRES(context, delta != 0, InvalidArgument(\"Requires delta != 0\"));\n      rt_nested_splits(row + 1) =\n          rt_nested_splits(row) + RangeSize(start, limit, delta);\n    }\n    SPLITS_TYPE nvals = rt_nested_splits(nrows);\n\n    // Construct the rt_dense_values tensor.\n    Tensor* rt_dense_values_out = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, TensorShape({nvals}),\n                                                     &rt_dense_values_out));\n    auto rt_dense_values = rt_dense_values_out->flat<T>();\n    int value_index = 0;\n    for (int row = 0; row < nrows; ++row) {\n      SPLITS_TYPE row_size = rt_nested_splits(row + 1) - rt_nested_splits(row);\n      T value = broadcast_starts ? starts(0) : starts(row);\n      T delta = broadcast_deltas ? deltas(0) : deltas(row);\n      for (SPLITS_TYPE i = 0; i < row_size; ++i) {\n        rt_dense_values(value_index++) = T(value);\n        value += delta;\n      }\n    }\n  }\n\n private:\n  // Returns the number of elements in the specified range.\n  SPLITS_TYPE RangeSize(T start, T limit, T delta) {\n    if (((delta > 0) && (limit < start)) || ((delta < 0) && (limit > start))) {\n      return 0;\n    }\n    // The following is copied from tensorflow::RangeOp::Compute().\n    return (std::is_integral<T>::value\n                ? ((std::abs(limit - start) + std::abs(delta) - 1) /\n                   std::abs(delta))\n                : std::ceil(std::abs((limit - start) / delta)));\n  }\n};\n\n#define REGISTER_CPU_KERNEL(TYPE)                                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"RaggedRange\")                      \\\n                              .Device(DEVICE_CPU)                  \\\n                              .TypeConstraint<TYPE>(\"T\")           \\\n                              .TypeConstraint<int32>(\"Tsplits\"),   \\\n                          RaggedRangeOp<TYPE, int32>);             \\\n  REGISTER_KERNEL_BUILDER(Name(\"RaggedRange\")                      \\\n                              .Device(DEVICE_CPU)                  \\\n                              .TypeConstraint<TYPE>(\"T\")           \\\n                              .TypeConstraint<int64_t>(\"Tsplits\"), \\\n                          RaggedRangeOp<TYPE, int64>);\nTF_CALL_float(REGISTER_CPU_KERNEL);\nTF_CALL_double(REGISTER_CPU_KERNEL);\nTF_CALL_int32(REGISTER_CPU_KERNEL);\nTF_CALL_int64(REGISTER_CPU_KERNEL);\n#undef REGISTER_CPU_KERNEL\n\n}  // namespace tensorflow\n", "/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/fake_input.h\"\n#include \"tensorflow/core/framework/node_def_builder.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/shape_inference_testutil.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_testutil.h\"\n#include \"tensorflow/core/kernels/ops_testutil.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/platform/test.h\"\n\nnamespace tensorflow {\nnamespace {\n\nclass RaggedRangeOpTest : public ::tensorflow::OpsTestBase {\n protected:\n  // Indices of output tensors.\n  static constexpr int kSplitsOutput = 0;\n  static constexpr int kValuesOutput = 1;\n\n  // Builds the tensorflow test graph for the RaggedRange op.\n  template <typename T>\n  void BuildRaggedRangeGraph() {\n    const auto& dtype = DataTypeToEnum<T>::v();\n    TF_ASSERT_OK(NodeDefBuilder(\"tested_op\", \"RaggedRange\")\n                     .Input(FakeInput(dtype))  // starts\n                     .Input(FakeInput(dtype))  // limits\n                     .Input(FakeInput(dtype))  // deltas\n                     .Attr(\"T\", dtype)\n                     .Finalize(node_def()));\n    TF_ASSERT_OK(InitOp());\n  }\n};\n\nTEST_F(RaggedRangeOpTest, IntValues) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4}), {0, 5, 8, 5});   // starts\n  AddInputFromArray<int>(TensorShape({4}), {8, 7, 8, 1});   // limits\n  AddInputFromArray<int>(TensorShape({4}), {2, 1, 1, -1});  // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 2, 4, 6], [5, 6], [], [5, 4, 3, 2]]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 4, 6, 6, 10}));\n  test::ExpectTensorEqual<int>(\n      *GetOutput(kValuesOutput),\n      test::AsTensor<int>({0, 2, 4, 6, 5, 6, 5, 4, 3, 2}));\n}\n\nTEST_F(RaggedRangeOpTest, FloatValues) {\n  BuildRaggedRangeGraph<float>();\n  AddInputFromArray<float>(TensorShape({4}), {0, 5, 8, 5});   // starts\n  AddInputFromArray<float>(TensorShape({4}), {8, 7, 8, 1});   // limits\n  AddInputFromArray<float>(TensorShape({4}), {2, 1, 1, -1});  // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 2, 4, 6], [5, 6], [], [5, 4, 3, 2]]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 4, 6, 6, 10}));\n  test::ExpectTensorNear<float>(\n      *GetOutput(kValuesOutput),\n      test::AsTensor<float>({0, 2, 4, 6, 5, 6, 5, 4, 3, 2}), 0.1);\n}\n\nTEST_F(RaggedRangeOpTest, BroadcastDeltas) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({3}), {0, 5, 8});  // starts\n  AddInputFromArray<int>(TensorShape({3}), {8, 7, 8});  // limits\n  AddInputFromArray<int>(TensorShape({}), {1});         // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 1, 2, 3, 4, 5, 6, 7], [5, 6], []]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 8, 10, 10}));\n  test::ExpectTensorEqual<int>(\n      *GetOutput(kValuesOutput),\n      test::AsTensor<int>({0, 1, 2, 3, 4, 5, 6, 7, 5, 6}));\n}\n\nTEST_F(RaggedRangeOpTest, BroadcastLimitsAndDeltas) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({}), {0});         // starts\n  AddInputFromArray<int>(TensorShape({3}), {3, 0, 2});  // limits\n  AddInputFromArray<int>(TensorShape({}), {1});         // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 1, 2], [], [0, 1]]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 3, 3, 5}));\n  test::ExpectTensorEqual<int>(*GetOutput(kValuesOutput),\n                               test::AsTensor<int>({0, 1, 2, 0, 1}));\n}\n\nTEST_F(RaggedRangeOpTest, BroadcastStartsAndLimits) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({}), {0});         // starts\n  AddInputFromArray<int>(TensorShape({}), {12});        // limits\n  AddInputFromArray<int>(TensorShape({3}), {3, 4, 5});  // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 3, 6, 9], [0, 4, 8], [0, 5, 10]]]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 4, 7, 10}));\n  test::ExpectTensorEqual<int>(\n      *GetOutput(kValuesOutput),\n      test::AsTensor<int>({0, 3, 6, 9, 0, 4, 8, 0, 5, 10}));\n}\n\nTEST_F(RaggedRangeOpTest, AllScalarInputs) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({}), {0});  // starts\n  AddInputFromArray<int>(TensorShape({}), {5});  // limits\n  AddInputFromArray<int>(TensorShape({}), {1});  // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 1, 2, 3, 4]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 5}));\n  test::ExpectTensorEqual<int>(*GetOutput(kValuesOutput),\n                               test::AsTensor<int>({0, 1, 2, 3, 4}));\n}\n\nTEST_F(RaggedRangeOpTest, InvalidArgsStarts) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4, 1}), {0, 5, 8, 5});  // starts\n  AddInputFromArray<int>(TensorShape({4}), {8, 7, 8, 1});     // limits\n  AddInputFromArray<int>(TensorShape({4}), {2, 1, 1, -1});    // deltas\n  EXPECT_EQ(\"starts must be a scalar or vector\", RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, InvalidArgsLimits) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4}), {0, 5, 8, 5});     // starts\n  AddInputFromArray<int>(TensorShape({4, 1}), {8, 7, 8, 1});  // limits\n  AddInputFromArray<int>(TensorShape({4}), {2, 1, 1, -1});    // deltas\n  EXPECT_EQ(\"limits must be a scalar or vector\", RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, InvalidArgsDeltas) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4}), {0, 5, 8, 5});      // starts\n  AddInputFromArray<int>(TensorShape({4}), {8, 7, 8, 1});      // limits\n  AddInputFromArray<int>(TensorShape({4, 1}), {2, 1, 1, -1});  // deltas\n  EXPECT_EQ(\"deltas must be a scalar or vector\", RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, InvalidArgsShapeMismatch) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4}), {0, 5, 8, 5});   // starts\n  AddInputFromArray<int>(TensorShape({3}), {7, 8, 1});      // limits\n  AddInputFromArray<int>(TensorShape({4}), {2, 1, 1, -1});  // deltas\n  EXPECT_EQ(\"starts, limits, and deltas must have the same shape\",\n            RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, InvalidArgsZeroDelta) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4}), {0, 5, 8, 5});   // starts\n  AddInputFromArray<int>(TensorShape({4}), {7, 8, 8, 1});   // limits\n  AddInputFromArray<int>(TensorShape({4}), {2, 1, 0, -1});  // deltas\n  EXPECT_EQ(\"Requires delta != 0\", RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, EmptyRangePositiveDelta) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({2}), {0, 5});  // starts\n  AddInputFromArray<int>(TensorShape({2}), {5, 0});  // limits\n  AddInputFromArray<int>(TensorShape({}), {2});      // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 2, 4], []]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 3, 3}));\n  test::ExpectTensorEqual<int>(*GetOutput(kValuesOutput),\n                               test::AsTensor<int>({0, 2, 4}));\n}\n\nTEST_F(RaggedRangeOpTest, EmptyRangeNegativeDelta) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({2}), {0, 5});  // starts\n  AddInputFromArray<int>(TensorShape({2}), {5, 0});  // limits\n  AddInputFromArray<int>(TensorShape({}), {-2});     // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[], [5, 3, 1]]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 0, 3}));\n  test::ExpectTensorEqual<int>(*GetOutput(kValuesOutput),\n                               test::AsTensor<int>({5, 3, 1}));\n}\n\nTEST_F(RaggedRangeOpTest, ShapeFn) {\n  // RaggedRange(starts, limits, deltas) -> [splits, values]\n  ShapeInferenceTestOp op(\"RaggedRange\");\n  INFER_OK(op, \"?;?;?\", \"[?];[?]\");\n  INFER_OK(op, \"[3];[3];[3]\", \"[4];[?]\");\n  INFER_OK(op, \"[3];[3];[]\", \"[4];[?]\");  // broadcast deltas\n  INFER_OK(op, \"[3];[];[3]\", \"[4];[?]\");  // broadcast limits\n  INFER_OK(op, \"[];[3];[3]\", \"[4];[?]\");  // broadcast starts\n  INFER_OK(op, \"[];[];[]\", \"[2];[?]\");    // degenerate case: all scalar inputs\n  INFER_ERROR(\"Shape must be at most rank 1 but is rank 2\", op,\n              \"[5,5];[5];[5]\");\n  INFER_ERROR(\"Shape must be at most rank 1 but is rank 2\", op,\n              \"[5];[5,5];[5]\");\n  INFER_ERROR(\"Shape must be at most rank 1 but is rank 2\", op,\n              \"[5];[5];[5,5]\");\n  INFER_ERROR(\"Dimensions must be equal, but are 4 and 3\", op, \"[3];[4];[3]\");\n}\n\n}  // namespace\n}  // namespace tensorflow\n", "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for ragged_range op.\"\"\"\n\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops.ragged import ragged_math_ops\nfrom tensorflow.python.platform import googletest\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass RaggedRangeOpTest(test_util.TensorFlowTestCase):\n\n  def testDocStringExamples(self):\n    \"\"\"Examples from ragged_range.__doc__.\"\"\"\n    rt1 = ragged_math_ops.range([3, 5, 2])\n    self.assertAllEqual(rt1, [[0, 1, 2], [0, 1, 2, 3, 4], [0, 1]])\n\n    rt2 = ragged_math_ops.range([0, 5, 8], [3, 3, 12])\n    self.assertAllEqual(rt2, [[0, 1, 2], [], [8, 9, 10, 11]])\n\n    rt3 = ragged_math_ops.range([0, 5, 8], [3, 3, 12], 2)\n    self.assertAllEqual(rt3, [[0, 2], [], [8, 10]])\n\n  def testBasicRanges(self):\n    # Specify limits only.\n    self.assertAllEqual(\n        ragged_math_ops.range([0, 3, 5]),\n        [list(range(0)), list(range(3)),\n         list(range(5))])\n\n    # Specify starts and limits.\n    self.assertAllEqual(\n        ragged_math_ops.range([0, 3, 5], [2, 3, 10]),\n        [list(range(0, 2)),\n         list(range(3, 3)),\n         list(range(5, 10))])\n\n    # Specify starts, limits, and deltas.\n    self.assertAllEqual(\n        ragged_math_ops.range([0, 3, 5], [4, 4, 15], [2, 3, 4]),\n        [list(range(0, 4, 2)),\n         list(range(3, 4, 3)),\n         list(range(5, 15, 4))])\n\n  def testFloatRanges(self):\n    expected = [[0.0, 0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 2.8, 3.2, 3.6], [3.0],\n                [5.0, 7.2, 9.4, 11.6, 13.8]]\n    actual = ragged_math_ops.range([0.0, 3.0, 5.0], [3.9, 4.0, 15.0],\n                                   [0.4, 1.5, 2.2])\n    self.assertAllClose(actual, expected)\n\n  def testNegativeDeltas(self):\n    self.assertAllEqual(\n        ragged_math_ops.range([0, 3, 5], limits=0, deltas=-1),\n        [list(range(0, 0, -1)),\n         list(range(3, 0, -1)),\n         list(range(5, 0, -1))])\n\n    self.assertAllEqual(\n        ragged_math_ops.range([0, -3, 5], limits=0, deltas=[-1, 1, -2]),\n        [list(range(0, 0, -1)),\n         list(range(-3, 0, 1)),\n         list(range(5, 0, -2))])\n\n  def testBroadcast(self):\n    # Specify starts and limits, broadcast deltas.\n    self.assertAllEqual(\n        ragged_math_ops.range([0, 3, 5], [4, 4, 15], 3),\n        [list(range(0, 4, 3)),\n         list(range(3, 4, 3)),\n         list(range(5, 15, 3))])\n\n    # Broadcast all arguments.\n    self.assertAllEqual(\n        ragged_math_ops.range(0, 5, 1), [list(range(0, 5, 1))])\n\n  def testEmptyRanges(self):\n    rt1 = ragged_math_ops.range([0, 5, 3], [0, 3, 5])\n    rt2 = ragged_math_ops.range([0, 5, 5], [0, 3, 5], -1)\n    self.assertAllEqual(rt1, [[], [], [3, 4]])\n    self.assertAllEqual(rt2, [[], [5, 4], []])\n\n  def testShapeFnErrors(self):\n    self.assertRaises((ValueError, errors.InvalidArgumentError),\n                      ragged_math_ops.range, [[0]], 5)\n    self.assertRaises((ValueError, errors.InvalidArgumentError),\n                      ragged_math_ops.range, 0, [[5]])\n    self.assertRaises((ValueError, errors.InvalidArgumentError),\n                      ragged_math_ops.range, 0, 5, [[0]])\n    self.assertRaises((ValueError, errors.InvalidArgumentError),\n                      ragged_math_ops.range, [0], [1, 2])\n\n  def testKernelErrors(self):\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                r'Requires delta != 0'):\n      self.evaluate(ragged_math_ops.range(0, 0, 0))\n\n  def testShape(self):\n    self.assertAllEqual(\n        ragged_math_ops.range(0, 0, 1).shape.as_list(), [1, None])\n    self.assertAllEqual(\n        ragged_math_ops.range([1, 2, 3]).shape.as_list(), [3, None])\n    self.assertAllEqual(\n        ragged_math_ops.range([1, 2, 3], [4, 5, 6]).shape.as_list(), [3, None])\n\n\nif __name__ == '__main__':\n  googletest.main()\n"], "fixing_code": ["/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <cstdint>\n#include <limits>\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n\nnamespace tensorflow {\n\nusing errors::InvalidArgument;\n\ntemplate <typename T, typename SPLITS_TYPE>\nclass RaggedRangeOp : public OpKernel {\n public:\n  using OpKernel::OpKernel;\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& starts_in = context->input(0);\n    const Tensor& limits_in = context->input(1);\n    const Tensor& deltas_in = context->input(2);\n\n    // Check input tensor shapes.\n    OP_REQUIRES(context, starts_in.shape().dims() <= 1,\n                InvalidArgument(\"starts must be a scalar or vector\"));\n    OP_REQUIRES(context, limits_in.shape().dims() <= 1,\n                InvalidArgument(\"limits must be a scalar or vector\"));\n    OP_REQUIRES(context, deltas_in.shape().dims() <= 1,\n                InvalidArgument(\"deltas must be a scalar or vector\"));\n\n    // Determine which tensors we need to broadcast.\n    bool broadcast_starts = starts_in.shape().dims() == 0;\n    bool broadcast_limits = limits_in.shape().dims() == 0;\n    bool broadcast_deltas = deltas_in.shape().dims() == 0;\n\n    // nrows (number of output rows) is the size of the non-broadcast inputs,\n    // or 1 if all inputs are scalars.\n    std::vector<int> in_sizes;\n    if (!broadcast_starts) in_sizes.push_back(starts_in.shape().dim_size(0));\n    if (!broadcast_limits) in_sizes.push_back(limits_in.shape().dim_size(0));\n    if (!broadcast_deltas) in_sizes.push_back(deltas_in.shape().dim_size(0));\n    for (int i = 1; i < in_sizes.size(); ++i) {\n      OP_REQUIRES(context, in_sizes[i] == in_sizes[i - 1],\n                  InvalidArgument(\"starts, limits, and deltas must have the \"\n                                  \"same shape\"));\n    }\n    SPLITS_TYPE nrows = in_sizes.empty() ? 1 : in_sizes[0];\n\n    const auto& starts = starts_in.flat<T>();\n    const auto& limits = limits_in.flat<T>();\n    const auto& deltas = deltas_in.flat<T>();\n\n    // Construct the rt_nested_splits tensor.\n    Tensor* rt_nested_splits_out = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({nrows + 1}),\n                                            &rt_nested_splits_out));\n    auto rt_nested_splits = rt_nested_splits_out->flat<SPLITS_TYPE>();\n    rt_nested_splits(0) = 0;\n    for (int row = 0; row < nrows; ++row) {\n      T start = broadcast_starts ? starts(0) : starts(row);\n      T limit = broadcast_limits ? limits(0) : limits(row);\n      T delta = broadcast_deltas ? deltas(0) : deltas(row);\n      OP_REQUIRES(context, delta != 0, InvalidArgument(\"Requires delta != 0\"));\n      int64_t size;  // The number of elements in the specified range.\n      if (((delta > 0) && (limit < start)) ||\n          ((delta < 0) && (limit > start))) {\n        size = 0;\n      } else if (std::is_integral<T>::value) {\n        // The following is copied from tensorflow::RangeOp::Compute().\n        size = Eigen::divup(Eigen::numext::abs(limit - start),\n                            Eigen::numext::abs(delta));\n      } else {\n        // The following is copied from tensorflow::RangeOp::Compute().\n        auto size_auto =\n            Eigen::numext::ceil(Eigen::numext::abs((limit - start) / delta));\n        OP_REQUIRES(\n            context, size_auto <= std::numeric_limits<int64_t>::max(),\n            errors::InvalidArgument(\"Requires ((limit - start) / delta) <= \",\n                                    std::numeric_limits<int64_t>::max()));\n        size = static_cast<int64_t>(size_auto);\n      }\n      rt_nested_splits(row + 1) = rt_nested_splits(row) + size;\n    }\n    SPLITS_TYPE nvals = rt_nested_splits(nrows);\n\n    // Construct the rt_dense_values tensor.\n    Tensor* rt_dense_values_out = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, TensorShape({nvals}),\n                                                     &rt_dense_values_out));\n    auto rt_dense_values = rt_dense_values_out->flat<T>();\n    int value_index = 0;\n    for (int row = 0; row < nrows; ++row) {\n      SPLITS_TYPE row_size = rt_nested_splits(row + 1) - rt_nested_splits(row);\n      T value = broadcast_starts ? starts(0) : starts(row);\n      T delta = broadcast_deltas ? deltas(0) : deltas(row);\n      for (SPLITS_TYPE i = 0; i < row_size; ++i) {\n        rt_dense_values(value_index++) = T(value);\n        value += delta;\n      }\n    }\n  }\n};\n\n#define REGISTER_CPU_KERNEL(TYPE)                                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"RaggedRange\")                      \\\n                              .Device(DEVICE_CPU)                  \\\n                              .TypeConstraint<TYPE>(\"T\")           \\\n                              .TypeConstraint<int32>(\"Tsplits\"),   \\\n                          RaggedRangeOp<TYPE, int32>);             \\\n  REGISTER_KERNEL_BUILDER(Name(\"RaggedRange\")                      \\\n                              .Device(DEVICE_CPU)                  \\\n                              .TypeConstraint<TYPE>(\"T\")           \\\n                              .TypeConstraint<int64_t>(\"Tsplits\"), \\\n                          RaggedRangeOp<TYPE, int64>);\nTF_CALL_float(REGISTER_CPU_KERNEL);\nTF_CALL_double(REGISTER_CPU_KERNEL);\nTF_CALL_int32(REGISTER_CPU_KERNEL);\nTF_CALL_int64(REGISTER_CPU_KERNEL);\n#undef REGISTER_CPU_KERNEL\n\n}  // namespace tensorflow\n", "/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <gtest/gtest.h>\n#include \"tensorflow/core/framework/fake_input.h\"\n#include \"tensorflow/core/framework/node_def_builder.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/shape_inference_testutil.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_testutil.h\"\n#include \"tensorflow/core/kernels/ops_testutil.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/platform/test.h\"\n\nnamespace tensorflow {\nnamespace {\n\nclass RaggedRangeOpTest : public ::tensorflow::OpsTestBase {\n protected:\n  // Indices of output tensors.\n  static constexpr int kSplitsOutput = 0;\n  static constexpr int kValuesOutput = 1;\n\n  // Builds the tensorflow test graph for the RaggedRange op.\n  template <typename T>\n  void BuildRaggedRangeGraph() {\n    const auto& dtype = DataTypeToEnum<T>::v();\n    TF_ASSERT_OK(NodeDefBuilder(\"tested_op\", \"RaggedRange\")\n                     .Input(FakeInput(dtype))  // starts\n                     .Input(FakeInput(dtype))  // limits\n                     .Input(FakeInput(dtype))  // deltas\n                     .Attr(\"T\", dtype)\n                     .Finalize(node_def()));\n    TF_ASSERT_OK(InitOp());\n  }\n};\n\nTEST_F(RaggedRangeOpTest, IntValues) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4}), {0, 5, 8, 5});   // starts\n  AddInputFromArray<int>(TensorShape({4}), {8, 7, 8, 1});   // limits\n  AddInputFromArray<int>(TensorShape({4}), {2, 1, 1, -1});  // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 2, 4, 6], [5, 6], [], [5, 4, 3, 2]]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 4, 6, 6, 10}));\n  test::ExpectTensorEqual<int>(\n      *GetOutput(kValuesOutput),\n      test::AsTensor<int>({0, 2, 4, 6, 5, 6, 5, 4, 3, 2}));\n}\n\nTEST_F(RaggedRangeOpTest, FloatValues) {\n  BuildRaggedRangeGraph<float>();\n  AddInputFromArray<float>(TensorShape({4}), {0, 5, 8, 5});   // starts\n  AddInputFromArray<float>(TensorShape({4}), {8, 7, 8, 1});   // limits\n  AddInputFromArray<float>(TensorShape({4}), {2, 1, 1, -1});  // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 2, 4, 6], [5, 6], [], [5, 4, 3, 2]]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 4, 6, 6, 10}));\n  test::ExpectTensorNear<float>(\n      *GetOutput(kValuesOutput),\n      test::AsTensor<float>({0, 2, 4, 6, 5, 6, 5, 4, 3, 2}), 0.1);\n}\n\nTEST_F(RaggedRangeOpTest, RangeSizeOverflow) {\n  BuildRaggedRangeGraph<float>();\n  AddInputFromArray<float>(TensorShape({2}), {1.1, 0.1});    // starts\n  AddInputFromArray<float>(TensorShape({2}), {10.0, 1e10});  // limits\n  AddInputFromArray<float>(TensorShape({2}), {1, 1e-10});    // deltas\n\n  EXPECT_EQ(absl::StrCat(\"Requires ((limit - start) / delta) <= \",\n                         std::numeric_limits<int64_t>::max()),\n            RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, BroadcastDeltas) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({3}), {0, 5, 8});  // starts\n  AddInputFromArray<int>(TensorShape({3}), {8, 7, 8});  // limits\n  AddInputFromArray<int>(TensorShape({}), {1});         // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 1, 2, 3, 4, 5, 6, 7], [5, 6], []]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 8, 10, 10}));\n  test::ExpectTensorEqual<int>(\n      *GetOutput(kValuesOutput),\n      test::AsTensor<int>({0, 1, 2, 3, 4, 5, 6, 7, 5, 6}));\n}\n\nTEST_F(RaggedRangeOpTest, BroadcastLimitsAndDeltas) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({}), {0});         // starts\n  AddInputFromArray<int>(TensorShape({3}), {3, 0, 2});  // limits\n  AddInputFromArray<int>(TensorShape({}), {1});         // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 1, 2], [], [0, 1]]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 3, 3, 5}));\n  test::ExpectTensorEqual<int>(*GetOutput(kValuesOutput),\n                               test::AsTensor<int>({0, 1, 2, 0, 1}));\n}\n\nTEST_F(RaggedRangeOpTest, BroadcastStartsAndLimits) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({}), {0});         // starts\n  AddInputFromArray<int>(TensorShape({}), {12});        // limits\n  AddInputFromArray<int>(TensorShape({3}), {3, 4, 5});  // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 3, 6, 9], [0, 4, 8], [0, 5, 10]]]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 4, 7, 10}));\n  test::ExpectTensorEqual<int>(\n      *GetOutput(kValuesOutput),\n      test::AsTensor<int>({0, 3, 6, 9, 0, 4, 8, 0, 5, 10}));\n}\n\nTEST_F(RaggedRangeOpTest, AllScalarInputs) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({}), {0});  // starts\n  AddInputFromArray<int>(TensorShape({}), {5});  // limits\n  AddInputFromArray<int>(TensorShape({}), {1});  // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 1, 2, 3, 4]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 5}));\n  test::ExpectTensorEqual<int>(*GetOutput(kValuesOutput),\n                               test::AsTensor<int>({0, 1, 2, 3, 4}));\n}\n\nTEST_F(RaggedRangeOpTest, InvalidArgsStarts) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4, 1}), {0, 5, 8, 5});  // starts\n  AddInputFromArray<int>(TensorShape({4}), {8, 7, 8, 1});     // limits\n  AddInputFromArray<int>(TensorShape({4}), {2, 1, 1, -1});    // deltas\n  EXPECT_EQ(\"starts must be a scalar or vector\", RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, InvalidArgsLimits) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4}), {0, 5, 8, 5});     // starts\n  AddInputFromArray<int>(TensorShape({4, 1}), {8, 7, 8, 1});  // limits\n  AddInputFromArray<int>(TensorShape({4}), {2, 1, 1, -1});    // deltas\n  EXPECT_EQ(\"limits must be a scalar or vector\", RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, InvalidArgsDeltas) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4}), {0, 5, 8, 5});      // starts\n  AddInputFromArray<int>(TensorShape({4}), {8, 7, 8, 1});      // limits\n  AddInputFromArray<int>(TensorShape({4, 1}), {2, 1, 1, -1});  // deltas\n  EXPECT_EQ(\"deltas must be a scalar or vector\", RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, InvalidArgsShapeMismatch) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4}), {0, 5, 8, 5});   // starts\n  AddInputFromArray<int>(TensorShape({3}), {7, 8, 1});      // limits\n  AddInputFromArray<int>(TensorShape({4}), {2, 1, 1, -1});  // deltas\n  EXPECT_EQ(\"starts, limits, and deltas must have the same shape\",\n            RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, InvalidArgsZeroDelta) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({4}), {0, 5, 8, 5});   // starts\n  AddInputFromArray<int>(TensorShape({4}), {7, 8, 8, 1});   // limits\n  AddInputFromArray<int>(TensorShape({4}), {2, 1, 0, -1});  // deltas\n  EXPECT_EQ(\"Requires delta != 0\", RunOpKernel().error_message());\n}\n\nTEST_F(RaggedRangeOpTest, EmptyRangePositiveDelta) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({2}), {0, 5});  // starts\n  AddInputFromArray<int>(TensorShape({2}), {5, 0});  // limits\n  AddInputFromArray<int>(TensorShape({}), {2});      // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[0, 2, 4], []]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 3, 3}));\n  test::ExpectTensorEqual<int>(*GetOutput(kValuesOutput),\n                               test::AsTensor<int>({0, 2, 4}));\n}\n\nTEST_F(RaggedRangeOpTest, EmptyRangeNegativeDelta) {\n  BuildRaggedRangeGraph<int>();\n  AddInputFromArray<int>(TensorShape({2}), {0, 5});  // starts\n  AddInputFromArray<int>(TensorShape({2}), {5, 0});  // limits\n  AddInputFromArray<int>(TensorShape({}), {-2});     // deltas\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Expected: [[], [5, 3, 1]]\n  test::ExpectTensorEqual<int64_t>(*GetOutput(kSplitsOutput),\n                                   test::AsTensor<int64_t>({0, 0, 3}));\n  test::ExpectTensorEqual<int>(*GetOutput(kValuesOutput),\n                               test::AsTensor<int>({5, 3, 1}));\n}\n\nTEST_F(RaggedRangeOpTest, ShapeFn) {\n  // RaggedRange(starts, limits, deltas) -> [splits, values]\n  ShapeInferenceTestOp op(\"RaggedRange\");\n  INFER_OK(op, \"?;?;?\", \"[?];[?]\");\n  INFER_OK(op, \"[3];[3];[3]\", \"[4];[?]\");\n  INFER_OK(op, \"[3];[3];[]\", \"[4];[?]\");  // broadcast deltas\n  INFER_OK(op, \"[3];[];[3]\", \"[4];[?]\");  // broadcast limits\n  INFER_OK(op, \"[];[3];[3]\", \"[4];[?]\");  // broadcast starts\n  INFER_OK(op, \"[];[];[]\", \"[2];[?]\");    // degenerate case: all scalar inputs\n  INFER_ERROR(\"Shape must be at most rank 1 but is rank 2\", op,\n              \"[5,5];[5];[5]\");\n  INFER_ERROR(\"Shape must be at most rank 1 but is rank 2\", op,\n              \"[5];[5,5];[5]\");\n  INFER_ERROR(\"Shape must be at most rank 1 but is rank 2\", op,\n              \"[5];[5];[5,5]\");\n  INFER_ERROR(\"Dimensions must be equal, but are 4 and 3\", op, \"[3];[4];[3]\");\n}\n\n}  // namespace\n}  // namespace tensorflow\n", "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for ragged_range op.\"\"\"\n\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops.ragged import ragged_math_ops\nfrom tensorflow.python.platform import googletest\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass RaggedRangeOpTest(test_util.TensorFlowTestCase):\n\n  def testDocStringExamples(self):\n    \"\"\"Examples from ragged_range.__doc__.\"\"\"\n    rt1 = ragged_math_ops.range([3, 5, 2])\n    self.assertAllEqual(rt1, [[0, 1, 2], [0, 1, 2, 3, 4], [0, 1]])\n\n    rt2 = ragged_math_ops.range([0, 5, 8], [3, 3, 12])\n    self.assertAllEqual(rt2, [[0, 1, 2], [], [8, 9, 10, 11]])\n\n    rt3 = ragged_math_ops.range([0, 5, 8], [3, 3, 12], 2)\n    self.assertAllEqual(rt3, [[0, 2], [], [8, 10]])\n\n  def testBasicRanges(self):\n    # Specify limits only.\n    self.assertAllEqual(\n        ragged_math_ops.range([0, 3, 5]),\n        [list(range(0)), list(range(3)),\n         list(range(5))])\n\n    # Specify starts and limits.\n    self.assertAllEqual(\n        ragged_math_ops.range([0, 3, 5], [2, 3, 10]),\n        [list(range(0, 2)),\n         list(range(3, 3)),\n         list(range(5, 10))])\n\n    # Specify starts, limits, and deltas.\n    self.assertAllEqual(\n        ragged_math_ops.range([0, 3, 5], [4, 4, 15], [2, 3, 4]),\n        [list(range(0, 4, 2)),\n         list(range(3, 4, 3)),\n         list(range(5, 15, 4))])\n\n  def testFloatRanges(self):\n    expected = [[0.0, 0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 2.8, 3.2, 3.6], [3.0],\n                [5.0, 7.2, 9.4, 11.6, 13.8]]\n    actual = ragged_math_ops.range([0.0, 3.0, 5.0], [3.9, 4.0, 15.0],\n                                   [0.4, 1.5, 2.2])\n    self.assertAllClose(actual, expected)\n\n  def testNegativeDeltas(self):\n    self.assertAllEqual(\n        ragged_math_ops.range([0, 3, 5], limits=0, deltas=-1),\n        [list(range(0, 0, -1)),\n         list(range(3, 0, -1)),\n         list(range(5, 0, -1))])\n\n    self.assertAllEqual(\n        ragged_math_ops.range([0, -3, 5], limits=0, deltas=[-1, 1, -2]),\n        [list(range(0, 0, -1)),\n         list(range(-3, 0, 1)),\n         list(range(5, 0, -2))])\n\n  def testBroadcast(self):\n    # Specify starts and limits, broadcast deltas.\n    self.assertAllEqual(\n        ragged_math_ops.range([0, 3, 5], [4, 4, 15], 3),\n        [list(range(0, 4, 3)),\n         list(range(3, 4, 3)),\n         list(range(5, 15, 3))])\n\n    # Broadcast all arguments.\n    self.assertAllEqual(ragged_math_ops.range(0, 5, 1), [list(range(0, 5, 1))])\n\n  def testEmptyRanges(self):\n    rt1 = ragged_math_ops.range([0, 5, 3], [0, 3, 5])\n    rt2 = ragged_math_ops.range([0, 5, 5], [0, 3, 5], -1)\n    self.assertAllEqual(rt1, [[], [], [3, 4]])\n    self.assertAllEqual(rt2, [[], [5, 4], []])\n\n  def testShapeFnErrors(self):\n    self.assertRaises((ValueError, errors.InvalidArgumentError),\n                      ragged_math_ops.range, [[0]], 5)\n    self.assertRaises((ValueError, errors.InvalidArgumentError),\n                      ragged_math_ops.range, 0, [[5]])\n    self.assertRaises((ValueError, errors.InvalidArgumentError),\n                      ragged_math_ops.range, 0, 5, [[0]])\n    self.assertRaises((ValueError, errors.InvalidArgumentError),\n                      ragged_math_ops.range, [0], [1, 2])\n\n  def testKernelErrors(self):\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                r'Requires delta != 0'):\n      self.evaluate(ragged_math_ops.range(0, 0, 0))\n\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                r'Requires \\(\\(limit - start\\) / delta\\) <='):\n      self.evaluate(ragged_math_ops.range(0.1, 1e10, 1e-10))\n\n  def testShape(self):\n    self.assertAllEqual(\n        ragged_math_ops.range(0, 0, 1).shape.as_list(), [1, None])\n    self.assertAllEqual(\n        ragged_math_ops.range([1, 2, 3]).shape.as_list(), [3, None])\n    self.assertAllEqual(\n        ragged_math_ops.range([1, 2, 3], [4, 5, 6]).shape.as_list(), [3, None])\n\n\nif __name__ == '__main__':\n  googletest.main()\n"], "filenames": ["tensorflow/core/kernels/ragged_range_op.cc", "tensorflow/core/kernels/ragged_range_op_test.cc", "tensorflow/python/ops/ragged/ragged_range_op_test.py"], "buggy_code_start_loc": [14, 15, 87], "buggy_code_end_loc": [114, 77, 110], "fixing_code_start_loc": [15, 16, 87], "fixing_code_end_loc": [118, 90, 114], "type": "CWE-190", "message": "TensorFlow is an open source platform for machine learning. The `RaggedRangOp` function takes an argument `limits` that is eventually used to construct a `TensorShape` as an `int64`. If `limits` is a very large float, it can overflow when converted to an `int64`. This triggers an `InvalidArgument` but also throws an abort signal that crashes the program. We have patched the issue in GitHub commit 37cefa91bee4eace55715eeef43720b958a01192. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.", "other": {"cve": {"id": "CVE-2022-35940", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-16T20:15:10.307", "lastModified": "2022-09-20T18:07:41.103", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. The `RaggedRangOp` function takes an argument `limits` that is eventually used to construct a `TensorShape` as an `int64`. If `limits` is a very large float, it can overflow when converted to an `int64`. This triggers an `InvalidArgument` but also throws an abort signal that crashes the program. We have patched the issue in GitHub commit 37cefa91bee4eace55715eeef43720b958a01192. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. La funci\u00f3n \"RaggedRangOp\" toma un argumento \"limits\" que es usada finalmente para construir un \"TensorShape\" como un \"int64\". Si \"limits\" es un flotador muy grande, puede desbordarse cuando es convertido en un \"int64\". Esto desencadena un \"InvalidArgument\" pero tambi\u00e9n lanza una se\u00f1al de interrupci\u00f3n que bloquea el programa. Hemos parcheado el problema en el commit 37cefa91bee4eace55715eeef43720b958a01192 de GitHub. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.10.0. Tambi\u00e9n seleccionaremos este compromiso en TensorFlow 2.9.1, TensorFlow 2.8.1 y TensorFlow 2.7.2, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango admitido. No se presentan mitigaciones conocidas para este problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-190"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.7.0", "versionEndExcluding": "2.7.2", "matchCriteriaId": "C4DFBF2D-5283-42F6-8800-D653BFA5CE82"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.8.0", "versionEndExcluding": "2.8.1", "matchCriteriaId": "0F9D273D-02DC-441E-AA91-EAC8DEAA4B44"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.9.0", "versionEndExcluding": "2.9.1", "matchCriteriaId": "FE4F8A81-6CC2-4F7F-9602-C170FDD926E7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc0:*:*:*:*:*:*", "matchCriteriaId": "1DBFBCE2-0A01-4575-BE45-6775ABFB8B28"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc1:*:*:*:*:*:*", "matchCriteriaId": "89806CF9-E423-4CA6-A01A-8175C260CB24"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc2:*:*:*:*:*:*", "matchCriteriaId": "F2B80690-A257-4E16-BD27-9AE045BC56ED"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc3:*:*:*:*:*:*", "matchCriteriaId": "F335F9A4-5AB8-4E53-BC18-E01F7C653E5E"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/blob/0b6b491d21d6a4eb5fbab1cca565bc1e94ca9543/tensorflow/core/kernels/ragged_range_op.cc#L74-L88", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/37cefa91bee4eace55715eeef43720b958a01192", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x989-q2pq-4q5x", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/37cefa91bee4eace55715eeef43720b958a01192"}}
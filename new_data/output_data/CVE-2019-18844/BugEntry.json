{"buggy_code": ["/*-\n * Copyright (c) 2011 NetApp, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY NETAPP, INC ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL NETAPP, INC OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n *\n * $FreeBSD$\n */\n\n#include <errno.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <strings.h>\n#include <assert.h>\n#include <stdbool.h>\n\n#include \"dm.h\"\n#include \"vmmapi.h\"\n#include \"acpi.h\"\n#include \"inout.h\"\n#include \"ioapic.h\"\n#include \"mem.h\"\n#include \"pci_core.h\"\n#include \"irq.h\"\n#include \"lpc.h\"\n#include \"sw_load.h\"\n#include \"log.h\"\n\n#define CONF1_ADDR_PORT    0x0cf8\n#define CONF1_DATA_PORT    0x0cfc\n\n#define CONF1_ENABLE\t   0x80000000ul\n\n#define\tMAXBUSES\t(PCI_BUSMAX + 1)\n#define MAXSLOTS\t(PCI_SLOTMAX + 1)\n#define\tMAXFUNCS\t(PCI_FUNCMAX + 1)\n\nstruct funcinfo {\n\tchar\t*fi_name;\n\tchar\t*fi_param;\n\tchar\t*fi_param_saved; /* save for reboot */\n\tstruct pci_vdev *fi_devi;\n};\n\nstruct intxinfo {\n\tint\tii_count;\n\tint\tii_pirq_pin;\n\tint\tii_ioapic_irq;\n};\n\nstruct slotinfo {\n\tstruct intxinfo si_intpins[4];\n\tstruct funcinfo si_funcs[MAXFUNCS];\n};\n\nstruct businfo {\n\tuint16_t iobase, iolimit;\t\t/* I/O window */\n\tuint32_t membase32, memlimit32;\t\t/* mmio window below 4GB */\n\tuint64_t membase64, memlimit64;\t\t/* mmio window above 4GB */\n\tstruct slotinfo slotinfo[MAXSLOTS];\n};\n\nstatic struct businfo *pci_businfo[MAXBUSES];\n\nSET_DECLARE(pci_vdev_ops_set, struct pci_vdev_ops);\n\nstatic uint64_t pci_emul_iobase;\nstatic uint64_t pci_emul_membase32;\nstatic uint64_t pci_emul_membase64;\n\nextern bool skip_pci_mem64bar_workaround;\n\n#define\tPCI_EMUL_IOBASE\t\t0x2000\n#define\tPCI_EMUL_IOLIMIT\t0x10000\n\n#define\tPCI_EMUL_ECFG_SIZE\t(MAXBUSES * 1024 * 1024)    /* 1MB per bus */\nSYSRES_MEM(PCI_EMUL_ECFG_BASE, PCI_EMUL_ECFG_SIZE);\n\n#define\tPCI_EMUL_MEMLIMIT32\tPCI_EMUL_ECFG_BASE\n\nstatic struct pci_vdev_ops *pci_emul_finddev(char *name);\nstatic void pci_lintr_route(struct pci_vdev *dev);\nstatic void pci_lintr_update(struct pci_vdev *dev);\nstatic void pci_cfgrw(struct vmctx *ctx, int vcpu, int in, int bus, int slot,\n\t\t      int func, int coff, int bytes, uint32_t *val);\nstatic void pci_emul_free_msixcap(struct pci_vdev *pdi);\n\nstatic inline void\nCFGWRITE(struct pci_vdev *dev, int coff, uint32_t val, int bytes)\n{\n\tif (bytes == 1)\n\t\tpci_set_cfgdata8(dev, coff, val);\n\telse if (bytes == 2)\n\t\tpci_set_cfgdata16(dev, coff, val);\n\telse\n\t\tpci_set_cfgdata32(dev, coff, val);\n}\n\nstatic inline uint32_t\nCFGREAD(struct pci_vdev *dev, int coff, int bytes)\n{\n\tif (bytes == 1)\n\t\treturn pci_get_cfgdata8(dev, coff);\n\telse if (bytes == 2)\n\t\treturn pci_get_cfgdata16(dev, coff);\n\telse\n\t\treturn pci_get_cfgdata32(dev, coff);\n}\n\nstatic inline int\nis_pci_gvt(struct pci_vdev *dev)\n{\n\tif (dev == NULL || strncmp(dev->dev_ops->class_name, \"pci-gvt\",7))\n\t\treturn 0;\n\telse\n\t\treturn 1;\n}\n\n/*\n * I/O access\n */\n\n/*\n * Slot options are in the form:\n *\n *  <bus>:<slot>:<func>,<emul>[,<config>]\n *  <slot>[:<func>],<emul>[,<config>]\n *\n *  slot is 0..31\n *  func is 0..7\n *  emul is a string describing the type of PCI device e.g. virtio-net\n *  config is an optional string, depending on the device, that can be\n *  used for configuration.\n *   Examples are:\n *     1,virtio-net,tap0\n *     3:0,dummy\n */\nstatic void\npci_parse_slot_usage(char *aopt)\n{\n\tfprintf(stderr, \"Invalid PCI slot info field \\\"%s\\\"\\n\", aopt);\n}\n\nint\nparse_bdf(char *s, int *bus, int *dev, int *func, int base)\n{\n\tchar *s_bus, *s_dev, *s_func;\n\tchar *str, *cp;\n\tint ret = 0;\n\n\tstr = cp = strdup(s);\n\tbus ? *bus = 0 : 0;\n\tdev ? *dev = 0 : 0;\n\tfunc ? *func = 0 : 0;\n\ts_bus = s_dev = s_func = NULL;\n\ts_dev = strsep(&cp, \":/.\");\n\tif (cp) {\n\t\ts_func = strsep(&cp, \":/.\");\n\t\tif (cp) {\n\t\t\ts_bus = s_dev;\n\t\t\ts_dev = s_func;\n\t\t\ts_func = strsep(&cp, \":/.\");\n\t\t}\n\t}\n\n\tif (s_dev && dev)\n\t\tret |= dm_strtoi(s_dev, &s_dev, base, dev);\n\tif (s_func && func)\n\t\tret |= dm_strtoi(s_func, &s_func, base, func);\n\tif (s_bus && bus)\n\t\tret |= dm_strtoi(s_bus, &s_bus, base, bus);\n\tfree(str);\n\n\treturn ret;\n}\n\nint\npci_parse_slot(char *opt)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tchar *emul, *config, *str, *cp, *b = NULL;\n\tint error, bnum, snum, fnum;\n\n\terror = -1;\n\tstr = strdup(opt);\n\tif (!str) {\n\t\tfprintf(stderr, \"%s: strdup returns NULL\\n\", __func__);\n\t\treturn -1;\n\t}\n\n\temul = config = NULL;\n\tcp = str;\n\tstr = strsep(&cp, \",\");\n\tif (cp) {\n\t\temul = strsep(&cp, \",\");\n\t\t/* for boot device */\n\t\tif (cp && *cp == 'b' && *(cp+1) == ',')\n\t\t\tb = strsep(&cp, \",\");\n\t\tconfig = cp;\n\t} else {\n\t\tpci_parse_slot_usage(opt);\n\t\tgoto done;\n\t}\n\n\t/* <bus>:<slot>:<func> */\n\tif (parse_bdf(str, &bnum, &snum, &fnum, 10) != 0)\n\t\tsnum = -1;\n\n\tif (bnum < 0 || bnum >= MAXBUSES || snum < 0 || snum >= MAXSLOTS ||\n\t    fnum < 0 || fnum >= MAXFUNCS) {\n\t\tpci_parse_slot_usage(opt);\n\t\tgoto done;\n\t}\n\n\tif (pci_businfo[bnum] == NULL)\n\t\tpci_businfo[bnum] = calloc(1, sizeof(struct businfo));\n\n\tbi = pci_businfo[bnum];\n\tsi = &bi->slotinfo[snum];\n\n\tif (si->si_funcs[fnum].fi_name != NULL) {\n\t\tfprintf(stderr, \"pci slot %d:%d already occupied!\\n\",\n\t\t\tsnum, fnum);\n\t\tgoto done;\n\t}\n\n\tif (pci_emul_finddev(emul) == NULL) {\n\t\tfprintf(stderr, \"pci slot %d:%d: unknown device \\\"%s\\\"\\n\",\n\t\t\tsnum, fnum, emul);\n\t\tgoto done;\n\t}\n\n\terror = 0;\n\tsi->si_funcs[fnum].fi_name = emul;\n\t/* saved fi param in case reboot */\n\tsi->si_funcs[fnum].fi_param_saved = config;\n\n\tif (b != NULL) {\n\t\tif ((strcmp(\"virtio-blk\", emul) == 0) &&  (b != NULL) &&\n\t\t\t(strchr(b, 'b') != NULL)) {\n\t\t\tvsbl_set_bdf(bnum, snum, fnum);\n\t\t}\n\t}\ndone:\n\tif (error)\n\t\tfree(str);\n\n\treturn error;\n}\n\nstatic int\npci_valid_pba_offset(struct pci_vdev *dev, uint64_t offset)\n{\n\tif (offset < dev->msix.pba_offset)\n\t\treturn 0;\n\n\tif (offset >= dev->msix.pba_offset + dev->msix.pba_size)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nint\npci_emul_msix_twrite(struct pci_vdev *dev, uint64_t offset, int size,\n\t\t     uint64_t value)\n{\n\tint msix_entry_offset;\n\tint tab_index;\n\tchar *dest;\n\n\t/* support only 4 or 8 byte writes */\n\tif (size != 4 && size != 8)\n\t\treturn -1;\n\n\t/*\n\t * Return if table index is beyond what device supports\n\t */\n\ttab_index = offset / MSIX_TABLE_ENTRY_SIZE;\n\tif (tab_index >= dev->msix.table_count)\n\t\treturn -1;\n\n\tmsix_entry_offset = offset % MSIX_TABLE_ENTRY_SIZE;\n\n\t/* support only aligned writes */\n\tif ((msix_entry_offset % size) != 0)\n\t\treturn -1;\n\n\tdest = (char *)(dev->msix.table + tab_index);\n\tdest += msix_entry_offset;\n\n\tif (size == 4)\n\t\t*((uint32_t *)dest) = value;\n\telse\n\t\t*((uint64_t *)dest) = value;\n\n\treturn 0;\n}\n\nuint64_t\npci_emul_msix_tread(struct pci_vdev *dev, uint64_t offset, int size)\n{\n\tchar *dest;\n\tint msix_entry_offset;\n\tint tab_index;\n\tuint64_t retval = ~0;\n\n\t/*\n\t * The PCI standard only allows 4 and 8 byte accesses to the MSI-X\n\t * table but we also allow 1 byte access to accommodate reads from\n\t * ddb.\n\t */\n\tif (size != 1 && size != 4 && size != 8)\n\t\treturn retval;\n\n\tmsix_entry_offset = offset % MSIX_TABLE_ENTRY_SIZE;\n\n\t/* support only aligned reads */\n\tif ((msix_entry_offset % size) != 0)\n\t\treturn retval;\n\n\ttab_index = offset / MSIX_TABLE_ENTRY_SIZE;\n\n\tif (tab_index < dev->msix.table_count) {\n\t\t/* valid MSI-X Table access */\n\t\tdest = (char *)(dev->msix.table + tab_index);\n\t\tdest += msix_entry_offset;\n\n\t\tif (size == 1)\n\t\t\tretval = *((uint8_t *)dest);\n\t\telse if (size == 4)\n\t\t\tretval = *((uint32_t *)dest);\n\t\telse\n\t\t\tretval = *((uint64_t *)dest);\n\t} else if (pci_valid_pba_offset(dev, offset)) {\n\t\t/* return 0 for PBA access */\n\t\tretval = 0;\n\t}\n\n\treturn retval;\n}\n\nint\npci_msix_table_bar(struct pci_vdev *dev)\n{\n\tif (dev->msix.table != NULL)\n\t\treturn dev->msix.table_bar;\n\telse\n\t\treturn -1;\n}\n\nint\npci_msix_pba_bar(struct pci_vdev *dev)\n{\n\tif (dev->msix.table != NULL)\n\t\treturn dev->msix.pba_bar;\n\telse\n\t\treturn -1;\n}\n\nstatic inline uint64_t\nbar_value(int size, uint64_t val)\n{\n\tuint64_t mask;\n\n\tassert(size == 1 || size == 2 || size == 4 || size == 8);\n\tmask = (size < 8 ? 1UL << (size * 8) : 0UL) - 1;\n\n\treturn val & mask;\n}\n\nstatic int\npci_emul_io_handler(struct vmctx *ctx, int vcpu, int in, int port, int bytes,\n\t\t    uint32_t *eax, void *arg)\n{\n\tstruct pci_vdev *pdi = arg;\n\tstruct pci_vdev_ops *ops = pdi->dev_ops;\n\tuint64_t offset;\n\tint i;\n\n\tfor (i = 0; i <= PCI_BARMAX; i++) {\n\t\tif (pdi->bar[i].type == PCIBAR_IO &&\n\t\t    port >= pdi->bar[i].addr &&\n\t\t    port + bytes <= pdi->bar[i].addr + pdi->bar[i].size) {\n\t\t\toffset = port - pdi->bar[i].addr;\n\t\t\tif (in) {\n\t\t\t\t*eax = (*ops->vdev_barread)(ctx, vcpu, pdi, i,\n\t\t\t\t                            offset, bytes);\n\t\t\t\t*eax = bar_value(bytes, *eax);\n\t\t\t} else\n\t\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, i, offset,\n\t\t\t\t                      bytes, bar_value(bytes, *eax));\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn -1;\n}\n\nstatic int\npci_emul_mem_handler(struct vmctx *ctx, int vcpu, int dir, uint64_t addr,\n\t\t     int size, uint64_t *val, void *arg1, long arg2)\n{\n\tstruct pci_vdev *pdi = arg1;\n\tstruct pci_vdev_ops *ops = pdi->dev_ops;\n\tuint64_t offset;\n\tint bidx = (int) arg2;\n\n\tassert(bidx <= PCI_BARMAX);\n\tassert(pdi->bar[bidx].type == PCIBAR_MEM32 ||\n\t       pdi->bar[bidx].type == PCIBAR_MEM64);\n\tassert(addr >= pdi->bar[bidx].addr &&\n\t       addr + size <= pdi->bar[bidx].addr + pdi->bar[bidx].size);\n\n\toffset = addr - pdi->bar[bidx].addr;\n\n\tif (dir == MEM_F_WRITE) {\n\t\tif (size == 8) {\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset,\n\t\t\t\t\t   4, *val & 0xffffffff);\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset + 4,\n\t\t\t\t\t   4, *val >> 32);\n\t\t} else {\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset,\n\t\t\t\t\t   size, bar_value(size, *val));\n\t\t}\n\t} else {\n\t\tif (size == 8) {\n\t\t\tuint64_t val_lo, val_hi;\n\n\t\t\tval_lo = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                              offset, 4);\n\t\t\tval_lo = bar_value(4, val_lo);\n\n\t\t\tval_hi = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                              offset + 4, 4);\n\n\t\t\t*val = val_lo | (val_hi << 32);\n\t\t} else {\n\t\t\t*val = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                            offset, size);\n\t\t\t*val = bar_value(size, *val);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n\nstatic int\npci_emul_alloc_resource(uint64_t *baseptr, uint64_t limit, uint64_t size,\n\t\t\tuint64_t *addr)\n{\n\tuint64_t base;\n\n\tassert((size & (size - 1)) == 0);\t/* must be a power of 2 */\n\n\tbase = roundup2(*baseptr, size);\n\n\tif (base + size <= limit) {\n\t\t*addr = base;\n\t\t*baseptr = base + size;\n\t\treturn 0;\n\t} else\n\t\treturn -1;\n}\n\nint\npci_emul_alloc_bar(struct pci_vdev *pdi, int idx, enum pcibar_type type,\n\t\t   uint64_t size)\n{\n\treturn pci_emul_alloc_pbar(pdi, idx, 0, type, size);\n}\n\n/*\n * Register (or unregister) the MMIO or I/O region associated with the BAR\n * register 'idx' of an emulated pci device.\n */\nstatic void\nmodify_bar_registration(struct pci_vdev *dev, int idx, int registration)\n{\n\tint error;\n\tstruct inout_port iop;\n\tstruct mem_range mr;\n\n\tif (is_pci_gvt(dev)) {\n\t\t/* GVT device is the only one who traps the pci bar access and\n\t\t * intercepts the corresponding contents in kernel. It needs\n\t\t * register pci resource only, but no need to register the\n\t\t * region.\n\t\t *\n\t\t * FIXME: This is a short term solution. This patch will be\n\t\t * obsoleted with the migration of using OVMF to do bar\n\t\t * addressing and generate ACPI PCI resource from using\n\t\t * acrn-dm.\n\t\t */\n\t\tprintf(\"modify_bar_registration: bypass for pci-gvt\\n\");\n\t\treturn;\n\t}\n\tswitch (dev->bar[idx].type) {\n\tcase PCIBAR_IO:\n\t\tbzero(&iop, sizeof(struct inout_port));\n\t\tiop.name = dev->name;\n\t\tiop.port = dev->bar[idx].addr;\n\t\tiop.size = dev->bar[idx].size;\n\t\tif (registration) {\n\t\t\tiop.flags = IOPORT_F_INOUT;\n\t\t\tiop.handler = pci_emul_io_handler;\n\t\t\tiop.arg = dev;\n\t\t\terror = register_inout(&iop);\n\t\t} else\n\t\t\terror = unregister_inout(&iop);\n\t\tbreak;\n\tcase PCIBAR_MEM32:\n\tcase PCIBAR_MEM64:\n\t\tbzero(&mr, sizeof(struct mem_range));\n\t\tmr.name = dev->name;\n\t\tmr.base = dev->bar[idx].addr;\n\t\tmr.size = dev->bar[idx].size;\n\t\tif (registration) {\n\t\t\tmr.flags = MEM_F_RW;\n\t\t\tmr.handler = pci_emul_mem_handler;\n\t\t\tmr.arg1 = dev;\n\t\t\tmr.arg2 = idx;\n\t\t\terror = register_mem(&mr);\n\t\t} else\n\t\t\terror = unregister_mem(&mr);\n\t\tbreak;\n\tdefault:\n\t\terror = EINVAL;\n\t\tbreak;\n\t}\n\tassert(error == 0);\n}\n\nstatic void\nunregister_bar(struct pci_vdev *dev, int idx)\n{\n\tmodify_bar_registration(dev, idx, 0);\n}\n\nstatic void\nregister_bar(struct pci_vdev *dev, int idx)\n{\n\tmodify_bar_registration(dev, idx, 1);\n}\n\n/* Are we decoding i/o port accesses for the emulated pci device? */\nstatic bool\nporten(struct pci_vdev *dev)\n{\n\tuint16_t cmd;\n\n\tcmd = pci_get_cfgdata16(dev, PCIR_COMMAND);\n\n\treturn (cmd & PCIM_CMD_PORTEN) != 0;\n}\n\n/* Are we decoding memory accesses for the emulated pci device? */\nstatic bool\nmemen(struct pci_vdev *dev)\n{\n\tuint16_t cmd;\n\n\tcmd = pci_get_cfgdata16(dev, PCIR_COMMAND);\n\n\treturn (cmd & PCIM_CMD_MEMEN) != 0;\n}\n\n/*\n * Update the MMIO or I/O address that is decoded by the BAR register.\n *\n * If the pci device has enabled the address space decoding then intercept\n * the address range decoded by the BAR register.\n */\nstatic void\nupdate_bar_address(struct vmctx *ctx, struct pci_vdev *dev, uint64_t addr,\n\tint idx, int type, bool ignore_reg_unreg)\n{\n\tbool decode = false;\n\tuint64_t orig_addr = dev->bar[idx].addr;\n\n\tif (!ignore_reg_unreg) {\n\t\tif (dev->bar[idx].type == PCIBAR_IO)\n\t\t\tdecode = porten(dev);\n\t\telse\n\t\t\tdecode = memen(dev);\n\t}\n\n\tif (decode)\n\t\tunregister_bar(dev, idx);\n\n\tswitch (type) {\n\tcase PCIBAR_IO:\n\tcase PCIBAR_MEM32:\n\t\tdev->bar[idx].addr = addr;\n\t\tbreak;\n\tcase PCIBAR_MEM64:\n\t\tdev->bar[idx].addr &= ~0xffffffffUL;\n\t\tdev->bar[idx].addr |= addr;\n\t\tbreak;\n\tcase PCIBAR_MEMHI64:\n\t\tdev->bar[idx].addr &= 0xffffffff;\n\t\tdev->bar[idx].addr |= addr;\n\t\tbreak;\n\tdefault:\n\t\tassert(0);\n\t}\n\n\tif (decode)\n\t\tregister_bar(dev, idx);\n\n\t/* update bar mapping */\n\tif (dev->dev_ops->vdev_update_bar_map && decode)\n\t\tdev->dev_ops->vdev_update_bar_map(ctx, dev, idx, orig_addr);\n}\n\nint\npci_emul_alloc_pbar(struct pci_vdev *pdi, int idx, uint64_t hostbase,\n\t\t    enum pcibar_type type, uint64_t size)\n{\n\tint error;\n\tuint64_t *baseptr, limit, addr, mask, lobits, bar;\n\n\tassert(idx >= 0 && idx <= PCI_BARMAX);\n\n\tif ((size & (size - 1)) != 0)\n\t\tsize = 1UL << flsl(size);\t/* round up to a power of 2 */\n\n\t/* Enforce minimum BAR sizes required by the PCI standard */\n\tif (type == PCIBAR_IO) {\n\t\tif (size < 4)\n\t\t\tsize = 4;\n\t} else {\n\t\tif (size < 16)\n\t\t\tsize = 16;\n\t}\n\n\tswitch (type) {\n\tcase PCIBAR_NONE:\n\t\tbaseptr = NULL;\n\t\taddr = mask = lobits = 0;\n\t\tbreak;\n\tcase PCIBAR_IO:\n\t\tbaseptr = &pci_emul_iobase;\n\t\tlimit = PCI_EMUL_IOLIMIT;\n\t\tmask = PCIM_BAR_IO_BASE;\n\t\tlobits = PCIM_BAR_IO_SPACE;\n\t\tbreak;\n\tcase PCIBAR_MEM64:\n\t\t/*\n\t\t * FIXME\n\t\t * Some drivers do not work well if the 64-bit BAR is allocated\n\t\t * above 4GB. Allow for this by allocating small requests under\n\t\t * 4GB unless then allocation size is larger than some arbitrary\n\t\t * number (32MB currently). If guest booted by ovmf, then skip the\n\t\t * workaround.\n\t\t */\n\t\tif (!skip_pci_mem64bar_workaround && (size <= 32 * 1024 * 1024)) {\n\t\t\tbaseptr = &pci_emul_membase32;\n\t\t\tlimit = PCI_EMUL_MEMLIMIT32;\n\t\t\tmask = PCIM_BAR_MEM_BASE;\n\t\t\tlobits = PCIM_BAR_MEM_SPACE | PCIM_BAR_MEM_64;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * XXX special case for device requiring peer-peer DMA\n\t\t */\n\t\tif (size == 0x100000000UL)\n\t\t\tbaseptr = &hostbase;\n\t\telse\n\t\t\tbaseptr = &pci_emul_membase64;\n\t\tlimit = PCI_EMUL_MEMLIMIT64;\n\t\tmask = PCIM_BAR_MEM_BASE;\n\t\tlobits = PCIM_BAR_MEM_SPACE | PCIM_BAR_MEM_64 |\n\t\t\tPCIM_BAR_MEM_PREFETCH;\n\t\tbreak;\n\tcase PCIBAR_MEM32:\n\t\tbaseptr = &pci_emul_membase32;\n\t\tlimit = PCI_EMUL_MEMLIMIT32;\n\t\tmask = PCIM_BAR_MEM_BASE;\n\t\tlobits = PCIM_BAR_MEM_SPACE | PCIM_BAR_MEM_32;\n\t\tbreak;\n\tdefault:\n\t\tprintf(\"%s: invalid bar type %d\\n\", __func__, type);\n\t\tassert(0);\n\t}\n\n\tif (baseptr != NULL) {\n\t\terror = pci_emul_alloc_resource(baseptr, limit, size, &addr);\n\t\tif (error != 0)\n\t\t\treturn error;\n\t}\n\n\tpdi->bar[idx].type = type;\n\tpdi->bar[idx].addr = addr;\n\tpdi->bar[idx].size = size;\n\n\t/* Initialize the BAR register in config space */\n\tbar = (addr & mask) | lobits;\n\tpci_set_cfgdata32(pdi, PCIR_BAR(idx), bar);\n\n\tif (type == PCIBAR_MEM64) {\n\t\tassert(idx + 1 <= PCI_BARMAX);\n\t\tpdi->bar[idx + 1].type = PCIBAR_MEMHI64;\n\t\tpci_set_cfgdata32(pdi, PCIR_BAR(idx + 1), bar >> 32);\n\t}\n\n\tregister_bar(pdi, idx);\n\n\treturn 0;\n}\n\nvoid\npci_emul_free_bars(struct pci_vdev *pdi)\n{\n\tint i;\n\tbool enabled;\n\n\tfor (i = 0; i < PCI_BARMAX; i++) {\n\t\tif ((pdi->bar[i].type != PCIBAR_NONE) &&\n\t\t\t(pdi->bar[i].type != PCIBAR_MEMHI64)){\n\t\t\t/*\n\t\t\t * Check whether the bar is enabled or not,\n\t\t\t * if it is disabled then it should have been\n\t\t\t * unregistered in pci_emul_cmdsts_write.\n\t\t\t */\n\t\t\tif (pdi->bar[i].type == PCIBAR_IO)\n\t\t\t\tenabled = porten(pdi);\n\t\t\telse\n\t\t\t\tenabled = memen(pdi);\n\n\t\t\tif (enabled)\n\t\t\t\tunregister_bar(pdi, i);\n\t\t\tpdi->bar[i].type = PCIBAR_NONE;\n\t\t}\n\t}\n}\n\n#define\tCAP_START_OFFSET\t0x40\nint\npci_emul_add_capability(struct pci_vdev *dev, u_char *capdata, int caplen)\n{\n\tint i, capoff, reallen;\n\tuint16_t sts;\n\n\tassert(caplen > 0);\n\n\treallen = roundup2(caplen, 4);\t\t/* dword aligned */\n\n\tsts = pci_get_cfgdata16(dev, PCIR_STATUS);\n\tif ((sts & PCIM_STATUS_CAPPRESENT) == 0)\n\t\tcapoff = CAP_START_OFFSET;\n\telse\n\t\tcapoff = dev->capend + 1;\n\n\t/* Check if we have enough space */\n\tif (capoff + reallen > PCI_REGMAX + 1)\n\t\treturn -1;\n\n\t/* Set the previous capability pointer */\n\tif ((sts & PCIM_STATUS_CAPPRESENT) == 0) {\n\t\tpci_set_cfgdata8(dev, PCIR_CAP_PTR, capoff);\n\t\tpci_set_cfgdata16(dev, PCIR_STATUS, sts|PCIM_STATUS_CAPPRESENT);\n\t} else\n\t\tpci_set_cfgdata8(dev, dev->prevcap + 1, capoff);\n\n\t/* Copy the capability */\n\tfor (i = 0; i < caplen; i++)\n\t\tpci_set_cfgdata8(dev, capoff + i, capdata[i]);\n\n\t/* Set the next capability pointer */\n\tpci_set_cfgdata8(dev, capoff + 1, 0);\n\n\tdev->prevcap = capoff;\n\tdev->capend = capoff + reallen - 1;\n\treturn 0;\n}\n\n/*\n * p_capoff is used as both input and output. Set *p_capoff to 0 when this\n * function is called for the first time, it will return offset of the first\n * matched one in p_capoff. To find the next matched one, please use the\n * returned *p_capoff from last call as the input, in this case the offset of\n * the next matched one will be returned in *p_capoff.\n * Please check the returned value first before touch p_capoff.\n */\nint\npci_emul_find_capability(struct pci_vdev *dev, uint8_t capid, int *p_capoff)\n{\n\tint coff;\n\tuint16_t sts;\n\n\tsts = pci_get_cfgdata16(dev, PCIR_STATUS);\n\tif ((sts & PCIM_STATUS_CAPPRESENT) == 0)\n\t\treturn -1;\n\n\tif (!p_capoff)\n\t\treturn -1;\n\n\tif (*p_capoff == 0)\n\t\tcoff = pci_get_cfgdata8(dev, PCIR_CAP_PTR);\n\telse if (*p_capoff >= CAP_START_OFFSET && *p_capoff <= dev->prevcap)\n\t\tcoff = pci_get_cfgdata8(dev, *p_capoff + 1);\n\telse\n\t\treturn -1;\n\n\twhile (coff >= CAP_START_OFFSET && coff <= dev->prevcap) {\n\t\tif (pci_get_cfgdata8(dev, coff) == capid) {\n\t\t\t*p_capoff = coff;\n\t\t\treturn 0;\n\t\t}\n\t\tcoff = pci_get_cfgdata8(dev, coff + 1);\n\t}\n\n\treturn -1;\n}\n\nstatic struct pci_vdev_ops *\npci_emul_finddev(char *name)\n{\n\tstruct pci_vdev_ops **pdpp, *pdp;\n\n\tSET_FOREACH(pdpp, pci_vdev_ops_set) {\n\t\tpdp = *pdpp;\n\t\tif (!strcmp(pdp->class_name, name))\n\t\t\treturn pdp;\n\t}\n\n\treturn NULL;\n}\n\nstatic int\npci_emul_init(struct vmctx *ctx, struct pci_vdev_ops *ops, int bus, int slot,\n\t      int func, struct funcinfo *fi)\n{\n\tstruct pci_vdev *pdi;\n\tint err;\n\n\tpdi = calloc(1, sizeof(struct pci_vdev));\n\tif (!pdi) {\n\t\tfprintf(stderr, \"%s: calloc returns NULL\\n\", __func__);\n\t\treturn -1;\n\t}\n\n\tpdi->vmctx = ctx;\n\tpdi->bus = bus;\n\tpdi->slot = slot;\n\tpdi->func = func;\n\tpthread_mutex_init(&pdi->lintr.lock, NULL);\n\tpdi->lintr.pin = 0;\n\tpdi->lintr.state = IDLE;\n\tpdi->lintr.pirq_pin = 0;\n\tpdi->lintr.ioapic_irq = 0;\n\tpdi->dev_ops = ops;\n\tsnprintf(pdi->name, PI_NAMESZ, \"%s-pci-%d\", ops->class_name, slot);\n\n\t/* Disable legacy interrupts */\n\tpci_set_cfgdata8(pdi, PCIR_INTLINE, 255);\n\tpci_set_cfgdata8(pdi, PCIR_INTPIN, 0);\n\n\tpci_set_cfgdata8(pdi, PCIR_COMMAND,\n\t\t    PCIM_CMD_PORTEN | PCIM_CMD_MEMEN | PCIM_CMD_BUSMASTEREN);\n\n\tif (fi->fi_param_saved)\n\t\tfi->fi_param = strdup(fi->fi_param_saved);\n\telse\n\t\tfi->fi_param = NULL;\n\terr = (*ops->vdev_init)(ctx, pdi, fi->fi_param);\n\tif (err == 0)\n\t\tfi->fi_devi = pdi;\n\telse\n\t\tfree(pdi);\n\n\treturn err;\n}\n\nstatic void\npci_emul_deinit(struct vmctx *ctx, struct pci_vdev_ops *ops, int bus, int slot,\n\t\tint func, struct funcinfo *fi)\n{\n\tif (ops->vdev_deinit && fi->fi_devi)\n\t\t(*ops->vdev_deinit)(ctx, fi->fi_devi, fi->fi_param);\n\tif (fi->fi_param)\n\t\tfree(fi->fi_param);\n\n\tif (fi->fi_devi) {\n\t\tpci_lintr_release(fi->fi_devi);\n\t\tpci_emul_free_bars(fi->fi_devi);\n\t\tpci_emul_free_msixcap(fi->fi_devi);\n\t\tfree(fi->fi_devi);\n\t}\n}\n\nvoid\npci_populate_msicap(struct msicap *msicap, int msgnum, int nextptr)\n{\n\tint mmc;\n\n\t/* Number of msi messages must be a power of 2 between 1 and 32 */\n\tassert((msgnum & (msgnum - 1)) == 0 && msgnum >= 1 && msgnum <= 32);\n\tmmc = ffs(msgnum) - 1;\n\n\tbzero(msicap, sizeof(struct msicap));\n\tmsicap->capid = PCIY_MSI;\n\tmsicap->nextptr = nextptr;\n\tmsicap->msgctrl = PCIM_MSICTRL_64BIT | (mmc << 1);\n}\n\nint\npci_emul_add_msicap(struct pci_vdev *dev, int msgnum)\n{\n\tstruct msicap msicap;\n\n\tpci_populate_msicap(&msicap, msgnum, 0);\n\n\treturn pci_emul_add_capability(dev, (u_char *)&msicap, sizeof(msicap));\n}\n\nstatic void\npci_populate_msixcap(struct msixcap *msixcap, int msgnum, int barnum,\n\t\t     uint32_t msix_tab_size)\n{\n\n\tassert(msix_tab_size % 4096 == 0);\n\n\tbzero(msixcap, sizeof(struct msixcap));\n\tmsixcap->capid = PCIY_MSIX;\n\n\t/*\n\t * Message Control Register, all fields set to\n\t * zero except for the Table Size.\n\t * Note: Table size N is encoded as N-1\n\t */\n\tmsixcap->msgctrl = msgnum - 1;\n\n\t/*\n\t * MSI-X BAR setup:\n\t * - MSI-X table start at offset 0\n\t * - PBA table starts at a 4K aligned offset after the MSI-X table\n\t */\n\tmsixcap->table_info = barnum & PCIM_MSIX_BIR_MASK;\n\tmsixcap->pba_info = msix_tab_size | (barnum & PCIM_MSIX_BIR_MASK);\n}\n\nstatic void\npci_msix_table_init(struct pci_vdev *dev, int table_entries)\n{\n\tint i, table_size;\n\n\tassert(table_entries > 0);\n\tassert(table_entries <= MAX_MSIX_TABLE_ENTRIES);\n\n\ttable_size = table_entries * MSIX_TABLE_ENTRY_SIZE;\n\tdev->msix.table = calloc(1, table_size);\n\n\tassert(dev->msix.table != NULL);\n\n\t/* set mask bit of vector control register */\n\tfor (i = 0; i < table_entries; i++)\n\t\tdev->msix.table[i].vector_control |= PCIM_MSIX_VCTRL_MASK;\n}\n\nint\npci_emul_add_msixcap(struct pci_vdev *dev, int msgnum, int barnum)\n{\n\tuint32_t tab_size;\n\tstruct msixcap msixcap;\n\n\tassert(msgnum >= 1 && msgnum <= MAX_MSIX_TABLE_ENTRIES);\n\tassert(barnum >= 0 && barnum <= PCIR_MAX_BAR_0);\n\n\ttab_size = msgnum * MSIX_TABLE_ENTRY_SIZE;\n\n\t/* Align table size to nearest 4K */\n\ttab_size = roundup2(tab_size, 4096);\n\n\tdev->msix.table_bar = barnum;\n\tdev->msix.pba_bar   = barnum;\n\tdev->msix.table_offset = 0;\n\tdev->msix.table_count = msgnum;\n\tdev->msix.pba_offset = tab_size;\n\tdev->msix.pba_size = PBA_SIZE(msgnum);\n\n\tpci_msix_table_init(dev, msgnum);\n\n\tpci_populate_msixcap(&msixcap, msgnum, barnum, tab_size);\n\n\t/* allocate memory for MSI-X Table and PBA */\n\tpci_emul_alloc_bar(dev, barnum, PCIBAR_MEM32,\n\t\t\t\ttab_size + dev->msix.pba_size);\n\n\treturn (pci_emul_add_capability(dev, (u_char *)&msixcap,\n\t\t\t\t\tsizeof(msixcap)));\n}\n\nstatic void\npci_emul_free_msixcap(struct pci_vdev *pdi)\n{\n\tif (pdi->msix.table) {\n\t\tfree(pdi->msix.table);\n\t\tpdi->msix.table = NULL;\n\t}\n}\n\n\nvoid\nmsixcap_cfgwrite(struct pci_vdev *dev, int capoff, int offset,\n\t\t int bytes, uint32_t val)\n{\n\tuint16_t msgctrl, rwmask;\n\tint off;\n\n\toff = offset - capoff;\n\t/* Message Control Register */\n\tif (off == 2 && bytes == 2) {\n\t\trwmask = PCIM_MSIXCTRL_MSIX_ENABLE |\n\t\t\tPCIM_MSIXCTRL_FUNCTION_MASK;\n\t\tmsgctrl = pci_get_cfgdata16(dev, offset);\n\t\tmsgctrl &= ~rwmask;\n\t\tmsgctrl |= val & rwmask;\n\t\tval = msgctrl;\n\n\t\tdev->msix.enabled = val & PCIM_MSIXCTRL_MSIX_ENABLE;\n\t\tdev->msix.function_mask = val & PCIM_MSIXCTRL_FUNCTION_MASK;\n\t\tpci_lintr_update(dev);\n\t}\n\n\tCFGWRITE(dev, offset, val, bytes);\n}\n\nvoid\nmsicap_cfgwrite(struct pci_vdev *dev, int capoff, int offset,\n\t\tint bytes, uint32_t val)\n{\n\tuint16_t msgctrl, rwmask, msgdata, mme;\n\tuint32_t addrlo;\n\n\t/*\n\t * If guest is writing to the message control register make sure\n\t * we do not overwrite read-only fields.\n\t */\n\tif ((offset - capoff) == 2 && bytes == 2) {\n\t\trwmask = PCIM_MSICTRL_MME_MASK | PCIM_MSICTRL_MSI_ENABLE;\n\t\tmsgctrl = pci_get_cfgdata16(dev, offset);\n\t\tmsgctrl &= ~rwmask;\n\t\tmsgctrl |= val & rwmask;\n\t\tval = msgctrl;\n\n\t\taddrlo = pci_get_cfgdata32(dev, capoff + 4);\n\t\tif (msgctrl & PCIM_MSICTRL_64BIT)\n\t\t\tmsgdata = pci_get_cfgdata16(dev, capoff + 12);\n\t\telse\n\t\t\tmsgdata = pci_get_cfgdata16(dev, capoff + 8);\n\n\t\tmme = msgctrl & PCIM_MSICTRL_MME_MASK;\n\t\tdev->msi.enabled = msgctrl & PCIM_MSICTRL_MSI_ENABLE ? 1 : 0;\n\t\tif (dev->msi.enabled) {\n\t\t\tdev->msi.addr = addrlo;\n\t\t\tdev->msi.msg_data = msgdata;\n\t\t\tdev->msi.maxmsgnum = 1 << (mme >> 4);\n\t\t} else {\n\t\t\tdev->msi.maxmsgnum = 0;\n\t\t}\n\t\tpci_lintr_update(dev);\n\t}\n\n\tCFGWRITE(dev, offset, val, bytes);\n}\n\nvoid\npciecap_cfgwrite(struct pci_vdev *dev, int capoff, int offset,\n\t\t int bytes, uint32_t val)\n{\n\t/* XXX don't write to the readonly parts */\n\tCFGWRITE(dev, offset, val, bytes);\n}\n\n#define\tPCIECAP_VERSION\t0x2\nint\npci_emul_add_pciecap(struct pci_vdev *dev, int type)\n{\n\tint err;\n\tstruct pciecap pciecap;\n\n\tif (type != PCIEM_TYPE_ROOT_PORT)\n\t\treturn -1;\n\n\tbzero(&pciecap, sizeof(pciecap));\n\n\tpciecap.capid = PCIY_EXPRESS;\n\tpciecap.pcie_capabilities = PCIECAP_VERSION | PCIEM_TYPE_ROOT_PORT;\n\tpciecap.link_capabilities = 0x411;\t/* gen1, x1 */\n\tpciecap.link_status = 0x11;\t\t/* gen1, x1 */\n\n\terr = pci_emul_add_capability(dev, (u_char *)&pciecap, sizeof(pciecap));\n\treturn err;\n}\n\n/*\n * This function assumes that 'coff' is in the capabilities region of the\n * config space.\n */\nstatic void\npci_emul_capwrite(struct pci_vdev *dev, int offset, int bytes, uint32_t val)\n{\n\tint capid;\n\tuint8_t capoff, nextoff;\n\n\t/* Do not allow un-aligned writes */\n\tif ((offset & (bytes - 1)) != 0)\n\t\treturn;\n\n\t/* Find the capability that we want to update */\n\tcapoff = CAP_START_OFFSET;\n\twhile (1) {\n\t\tnextoff = pci_get_cfgdata8(dev, capoff + 1);\n\t\tif (nextoff == 0)\n\t\t\tbreak;\n\t\tif (offset >= capoff && offset < nextoff)\n\t\t\tbreak;\n\n\t\tcapoff = nextoff;\n\t}\n\tassert(offset >= capoff);\n\n\t/*\n\t * Capability ID and Next Capability Pointer are readonly.\n\t * However, some o/s's do 4-byte writes that include these.\n\t * For this case, trim the write back to 2 bytes and adjust\n\t * the data.\n\t */\n\tif (offset == capoff || offset == capoff + 1) {\n\t\tif (offset == capoff && bytes == 4) {\n\t\t\tbytes = 2;\n\t\t\toffset += 2;\n\t\t\tval >>= 16;\n\t\t} else\n\t\t\treturn;\n\t}\n\n\tcapid = pci_get_cfgdata8(dev, capoff);\n\tswitch (capid) {\n\tcase PCIY_MSI:\n\t\tmsicap_cfgwrite(dev, capoff, offset, bytes, val);\n\t\tbreak;\n\tcase PCIY_MSIX:\n\t\tmsixcap_cfgwrite(dev, capoff, offset, bytes, val);\n\t\tbreak;\n\tcase PCIY_EXPRESS:\n\t\tpciecap_cfgwrite(dev, capoff, offset, bytes, val);\n\t\tbreak;\n\tdefault:\n\t\tCFGWRITE(dev, offset, val, bytes);\n\t\tbreak;\n\t}\n}\n\nstatic int\npci_emul_iscap(struct pci_vdev *dev, int offset)\n{\n\tuint16_t sts;\n\n\tsts = pci_get_cfgdata16(dev, PCIR_STATUS);\n\tif ((sts & PCIM_STATUS_CAPPRESENT) != 0) {\n\t\tif (offset >= CAP_START_OFFSET && offset <= dev->capend)\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic int\npci_emul_fallback_handler(struct vmctx *ctx, int vcpu, int dir, uint64_t addr,\n\t\t\t  int size, uint64_t *val, void *arg1, long arg2)\n{\n\t/*\n\t * Ignore writes; return 0xff's for reads. The mem read code\n\t * will take care of truncating to the correct size.\n\t */\n\tif (dir == MEM_F_READ)\n\t\t*val = 0xffffffffffffffff;\n\n\treturn 0;\n}\n\nstatic int\npci_emul_ecfg_handler(struct vmctx *ctx, int vcpu, int dir, uint64_t addr,\n\t\t      int bytes, uint64_t *val, void *arg1, long arg2)\n{\n\tint bus, slot, func, coff, in;\n\n\tcoff = addr & 0xfff;\n\tfunc = (addr >> 12) & 0x7;\n\tslot = (addr >> 15) & 0x1f;\n\tbus = (addr >> 20) & 0xff;\n\tin = (dir == MEM_F_READ);\n\tif (in)\n\t\t*val = ~0UL;\n\tpci_cfgrw(ctx, vcpu, in, bus, slot, func, coff, bytes, (uint32_t *)val);\n\treturn 0;\n}\n\n#define\tBUSIO_ROUNDUP\t\t32\n#define\tBUSMEM_ROUNDUP\t\t(1024 * 1024)\n\nint\ninit_pci(struct vmctx *ctx)\n{\n\tstruct mem_range mr;\n\tstruct pci_vdev_ops *ops;\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct funcinfo *fi;\n\tsize_t lowmem;\n\tint bus, slot, func;\n\tint success_cnt = 0;\n\tint error;\n\n\tpci_emul_iobase = PCI_EMUL_IOBASE;\n\tpci_emul_membase32 = vm_get_lowmem_limit(ctx);\n\tpci_emul_membase64 = PCI_EMUL_MEMBASE64;\n\n\tcreate_gsi_sharing_groups();\n\n\tfor (bus = 0; bus < MAXBUSES; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\t\t/*\n\t\t * Keep track of the i/o and memory resources allocated to\n\t\t * this bus.\n\t\t */\n\t\tbi->iobase = pci_emul_iobase;\n\t\tbi->membase32 = pci_emul_membase32;\n\t\tbi->membase64 = pci_emul_membase64;\n\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_name == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tops = pci_emul_finddev(fi->fi_name);\n\t\t\t\tassert(ops != NULL);\n\n\t\t\t\tpr_notice(\"pci init %s\\r\\n\", fi->fi_name);\n\t\t\t\terror = pci_emul_init(ctx, ops, bus, slot,\n\t\t\t\t    func, fi);\n\t\t\t\tif (error) {\n\t\t\t\t\tpr_err(\"pci %s init failed\\n\", fi->fi_name);\n\t\t\t\t\tgoto pci_emul_init_fail;\n\t\t\t\t}\n\t\t\t\tsuccess_cnt++;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Add some slop to the I/O and memory resources decoded by\n\t\t * this bus to give a guest some flexibility if it wants to\n\t\t * reprogram the BARs.\n\t\t */\n\t\tpci_emul_iobase += BUSIO_ROUNDUP;\n\t\tpci_emul_iobase = roundup2(pci_emul_iobase, BUSIO_ROUNDUP);\n\t\tbi->iolimit = pci_emul_iobase;\n\n\t\tpci_emul_membase32 += BUSMEM_ROUNDUP;\n\t\tpci_emul_membase32 = roundup2(pci_emul_membase32,\n\t\t    BUSMEM_ROUNDUP);\n\t\tbi->memlimit32 = pci_emul_membase32;\n\n\t\tpci_emul_membase64 += BUSMEM_ROUNDUP;\n\t\tpci_emul_membase64 = roundup2(pci_emul_membase64,\n\t\t    BUSMEM_ROUNDUP);\n\t\tbi->memlimit64 = pci_emul_membase64;\n\t}\n\n\terror = check_gsi_sharing_violation();\n\tif (error < 0)\n\t\tgoto pci_emul_init_fail;\n\n\t/*\n\t * PCI backends are initialized before routing INTx interrupts\n\t * so that LPC devices are able to reserve ISA IRQs before\n\t * routing PIRQ pins.\n\t */\n\tfor (bus = 0; bus < MAXBUSES; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_devi == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tpci_lintr_route(fi->fi_devi);\n\t\t\t\tops = fi->fi_devi->dev_ops;\n\t\t\t\tif (ops && ops->vdev_phys_access)\n\t\t\t\t\tops->vdev_phys_access(ctx,\n\t\t\t\t\t\tfi->fi_devi);\n\t\t\t}\n\t\t}\n\t}\n\tlpc_pirq_routed();\n\n\t/*\n\t * The guest physical memory map looks like the following:\n\t * [0,              lowmem)         guest system memory\n\t * [lowmem,         lowmem_limit)   memory hole (may be absent)\n\t * [lowmem_limit,   0xE0000000)     PCI hole (32-bit BAR allocation)\n\t * [0xE0000000,     0xF0000000)     PCI extended config window\n\t * [0xF0000000,     4GB)            LAPIC, IOAPIC, HPET, firmware\n\t * [4GB,            5GB)            PCI hole (64-bit BAR allocation)\n\t * [5GB,            5GB + highmem)  guest system memory\n\t */\n\n\t/*\n\t * Accesses to memory addresses that are not allocated to system\n\t * memory or PCI devices return 0xff's.\n\t */\n\tlowmem = vm_get_lowmem_size(ctx);\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (32-bit)\";\n\tmr.flags = MEM_F_RW;\n\tmr.base = lowmem;\n\tmr.size = (4ULL * 1024 * 1024 * 1024) - lowmem;\n\tmr.handler = pci_emul_fallback_handler;\n\terror = register_mem_fallback(&mr);\n\tassert(error == 0);\n\n\t/* ditto for the 64-bit PCI host aperture */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (64-bit)\";\n\tmr.flags = MEM_F_RW;\n\tmr.base = PCI_EMUL_MEMBASE64;\n\tmr.size = PCI_EMUL_MEMLIMIT64 - PCI_EMUL_MEMBASE64;\n\tmr.handler = pci_emul_fallback_handler;\n\terror = register_mem_fallback(&mr);\n\tassert(error == 0);\n\n\t/* PCI extended config space */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI ECFG\";\n\tmr.flags = MEM_F_RW;\n\tmr.base = PCI_EMUL_ECFG_BASE;\n\tmr.size = PCI_EMUL_ECFG_SIZE;\n\tmr.handler = pci_emul_ecfg_handler;\n\terror = register_mem(&mr);\n\tassert(error == 0);\n\n\treturn 0;\n\npci_emul_init_fail:\n\tfor (bus = 0; bus < MAXBUSES && success_cnt > 0; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\t\tfor (slot = 0; slot < MAXSLOTS && success_cnt > 0; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_name == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (success_cnt-- <= 0)\n\t\t\t\t\tbreak;\n\t\t\t\tops = pci_emul_finddev(fi->fi_name);\n\t\t\t\tassert(ops != NULL);\n\t\t\t\tpci_emul_deinit(ctx, ops, bus, slot,\n\t\t\t\t    func, fi);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn error;\n}\n\nvoid\ndeinit_pci(struct vmctx *ctx)\n{\n\tstruct pci_vdev_ops *ops;\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct funcinfo *fi;\n\tint bus, slot, func;\n\tsize_t lowmem;\n\tstruct mem_range mr;\n\n\t/* Release PCI extended config space */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI ECFG\";\n\tmr.base = PCI_EMUL_ECFG_BASE;\n\tmr.size = PCI_EMUL_ECFG_SIZE;\n\tunregister_mem(&mr);\n\n\t/* Release PCI hole space */\n\tlowmem = vm_get_lowmem_size(ctx);\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (32-bit)\";\n\tmr.base = lowmem;\n\tmr.size = (4ULL * 1024 * 1024 * 1024) - lowmem;\n\tunregister_mem_fallback(&mr);\n\n\t/* ditto for the 64-bit PCI host aperture */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (64-bit)\";\n\tmr.base = PCI_EMUL_MEMBASE64;\n\tmr.size = PCI_EMUL_MEMLIMIT64 - PCI_EMUL_MEMBASE64;\n\tunregister_mem_fallback(&mr);\n\n\tfor (bus = 0; bus < MAXBUSES; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_name == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tops = pci_emul_finddev(fi->fi_name);\n\t\t\t\tassert(ops != NULL);\n\n\t\t\t\tpr_notice(\"pci deinit %s\\n\", fi->fi_name);\n\t\t\t\tpci_emul_deinit(ctx, ops, bus, slot,\n\t\t\t\t    func, fi);\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void\npci_apic_prt_entry(int bus, int slot, int pin, int pirq_pin, int ioapic_irq,\n\t\t   void *arg)\n{\n\tdsdt_line(\"  Package ()\");\n\tdsdt_line(\"  {\");\n\tdsdt_line(\"    0x%X,\", slot << 16 | 0xffff);\n\tdsdt_line(\"    0x%02X,\", pin - 1);\n\tdsdt_line(\"    Zero,\");\n\tdsdt_line(\"    0x%X\", ioapic_irq);\n\tdsdt_line(\"  },\");\n}\n\nstatic void\npci_pirq_prt_entry(int bus, int slot, int pin, int pirq_pin, int ioapic_irq,\n\t\t   void *arg)\n{\n\tchar *name;\n\n\tname = lpc_pirq_name(pirq_pin);\n\tif (name == NULL)\n\t\treturn;\n\tdsdt_line(\"  Package ()\");\n\tdsdt_line(\"  {\");\n\tdsdt_line(\"    0x%X,\", slot << 16 | 0xffff);\n\tdsdt_line(\"    0x%02X,\", pin - 1);\n\tdsdt_line(\"    %s,\", name);\n\tdsdt_line(\"    0x00\");\n\tdsdt_line(\"  },\");\n\tfree(name);\n}\n\n/*\n * A acrn-dm virtual machine has a flat PCI hierarchy with a root port\n * corresponding to each PCI bus.\n */\nstatic void\npci_bus_write_dsdt(int bus)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct pci_vdev *dev;\n\tint count, func, slot;\n\n\t/*\n\t * If there are no devices on this 'bus' then just return.\n\t */\n\t bi = pci_businfo[bus];\n\tif (bi == NULL) {\n\t\t/*\n\t\t * Bus 0 is special because it decodes the I/O ports used\n\t\t * for PCI config space access even if there are no devices\n\t\t * on it.\n\t\t */\n\t\tif (bus != 0)\n\t\t\treturn;\n\t}\n\n\tdsdt_line(\"  Device (PCI%01X)\", bus);\n\tdsdt_line(\"  {\");\n\tdsdt_line(\"    Name (_HID, EisaId (\\\"PNP0A03\\\"))\");\n\tdsdt_line(\"    Name (_ADR, Zero)\");\n\n\tdsdt_line(\"    Method (_BBN, 0, NotSerialized)\");\n\tdsdt_line(\"    {\");\n\tdsdt_line(\"        Return (0x%08X)\", bus);\n\tdsdt_line(\"    }\");\n\tdsdt_line(\"    Name (_CRS, ResourceTemplate ()\");\n\tdsdt_line(\"    {\");\n\tdsdt_line(\"      WordBusNumber (ResourceProducer, MinFixed, \"\n\t    \"MaxFixed, PosDecode,\");\n\tdsdt_line(\"        0x0000,             // Granularity\");\n\tdsdt_line(\"        0x%04X,             // Range Minimum\", bus);\n\tdsdt_line(\"        0x%04X,             // Range Maximum\", bus);\n\tdsdt_line(\"        0x0000,             // Translation Offset\");\n\tdsdt_line(\"        0x0001,             // Length\");\n\tdsdt_line(\"        ,, )\");\n\n\tif (bus == 0) {\n\t\tdsdt_indent(3);\n\t\tdsdt_fixed_ioport(0xCF8, 8);\n\t\tdsdt_unindent(3);\n\n\t\tdsdt_line(\"      WordIO (ResourceProducer, MinFixed, MaxFixed, \"\n\t\t    \"PosDecode, EntireRange,\");\n\t\tdsdt_line(\"        0x0000,             // Granularity\");\n\t\tdsdt_line(\"        0x0000,             // Range Minimum\");\n\t\tdsdt_line(\"        0x0CF7,             // Range Maximum\");\n\t\tdsdt_line(\"        0x0000,             // Translation Offset\");\n\t\tdsdt_line(\"        0x0CF8,             // Length\");\n\t\tdsdt_line(\"        ,, , TypeStatic)\");\n\n\t\tdsdt_line(\"      WordIO (ResourceProducer, MinFixed, MaxFixed, \"\n\t\t    \"PosDecode, EntireRange,\");\n\t\tdsdt_line(\"        0x0000,             // Granularity\");\n\t\tdsdt_line(\"        0x0D00,             // Range Minimum\");\n\t\tdsdt_line(\"        0x%04X,             // Range Maximum\",\n\t\t    PCI_EMUL_IOBASE - 1);\n\t\tdsdt_line(\"        0x0000,             // Translation Offset\");\n\t\tdsdt_line(\"        0x%04X,             // Length\",\n\t\t    PCI_EMUL_IOBASE - 0x0D00);\n\t\tdsdt_line(\"        ,, , TypeStatic)\");\n\n\t\tif (bi == NULL) {\n\t\t\tdsdt_line(\"    })\");\n\t\t\tgoto done;\n\t\t}\n\t}\n\tassert(bi != NULL);\n\n\t/* i/o window */\n\tdsdt_line(\"      WordIO (ResourceProducer, MinFixed, MaxFixed, \"\n\t    \"PosDecode, EntireRange,\");\n\tdsdt_line(\"        0x0000,             // Granularity\");\n\tdsdt_line(\"        0x%04X,             // Range Minimum\", bi->iobase);\n\tdsdt_line(\"        0x%04X,             // Range Maximum\",\n\t    bi->iolimit - 1);\n\tdsdt_line(\"        0x0000,             // Translation Offset\");\n\tdsdt_line(\"        0x%04X,             // Length\",\n\t    bi->iolimit - bi->iobase);\n\tdsdt_line(\"        ,, , TypeStatic)\");\n\n\t/* mmio window (32-bit) */\n\tdsdt_line(\"      DWordMemory (ResourceProducer, PosDecode, \"\n\t    \"MinFixed, MaxFixed, NonCacheable, ReadWrite,\");\n\tdsdt_line(\"        0x00000000,         // Granularity\");\n\tdsdt_line(\"        0x%08X,         // Range Minimum\\n\", bi->membase32);\n\tdsdt_line(\"        0x%08X,         // Range Maximum\\n\",\n\t    bi->memlimit32 - 1);\n\tdsdt_line(\"        0x00000000,         // Translation Offset\");\n\tdsdt_line(\"        0x%08X,         // Length\\n\",\n\t    bi->memlimit32 - bi->membase32);\n\tdsdt_line(\"        ,, , AddressRangeMemory, TypeStatic)\");\n\n\t/* mmio window (64-bit) */\n\tdsdt_line(\"      QWordMemory (ResourceProducer, PosDecode, \"\n\t    \"MinFixed, MaxFixed, NonCacheable, ReadWrite,\");\n\tdsdt_line(\"        0x0000000000000000, // Granularity\");\n\tdsdt_line(\"        0x%016lX, // Range Minimum\\n\", bi->membase64);\n\tdsdt_line(\"        0x%016lX, // Range Maximum\\n\",\n\t    bi->memlimit64 - 1);\n\tdsdt_line(\"        0x0000000000000000, // Translation Offset\");\n\tdsdt_line(\"        0x%016lX, // Length\\n\",\n\t    bi->memlimit64 - bi->membase64);\n\tdsdt_line(\"        ,, , AddressRangeMemory, TypeStatic)\");\n\tdsdt_line(\"    })\");\n\n\tif (!is_rtvm) {\n\t\tcount = pci_count_lintr(bus);\n\t\tif (count != 0) {\n\t\t\tdsdt_indent(2);\n\t\t\tdsdt_line(\"Name (PPRT, Package ()\");\n\t\t\tdsdt_line(\"{\");\n\t\t\tpci_walk_lintr(bus, pci_pirq_prt_entry, NULL);\n\t\t\tdsdt_line(\"})\");\n\t\t\tdsdt_line(\"Name (APRT, Package ()\");\n\t\t\tdsdt_line(\"{\");\n\t\t\tpci_walk_lintr(bus, pci_apic_prt_entry, NULL);\n\t\t\tdsdt_line(\"})\");\n\t\t\tdsdt_line(\"Method (_PRT, 0, NotSerialized)\");\n\t\t\tdsdt_line(\"{\");\n\t\t\tdsdt_line(\"  If (PICM)\");\n\t\t\tdsdt_line(\"  {\");\n\t\t\tdsdt_line(\"    Return (APRT)\");\n\t\t\tdsdt_line(\"  }\");\n\t\t\tdsdt_line(\"  Else\");\n\t\t\tdsdt_line(\"  {\");\n\t\t\tdsdt_line(\"    Return (PPRT)\");\n\t\t\tdsdt_line(\"  }\");\n\t\t\tdsdt_line(\"}\");\n\t\t\tdsdt_unindent(2);\n\t\t}\n\t}\n\n\tdsdt_indent(2);\n\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\tsi = &bi->slotinfo[slot];\n\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\tdev = si->si_funcs[func].fi_devi;\n\t\t\tif (dev != NULL &&\n\t\t\t    dev->dev_ops->vdev_write_dsdt != NULL)\n\t\t\t\tdev->dev_ops->vdev_write_dsdt(dev);\n\t\t}\n\t}\n\tdsdt_unindent(2);\ndone:\n\tdsdt_line(\"  }\");\n}\n\nvoid\npci_write_dsdt(void)\n{\n\tint bus;\n\n\tdsdt_indent(1);\n\tdsdt_line(\"Name (PICM, 0x00)\");\n\tdsdt_line(\"Method (_PIC, 1, NotSerialized)\");\n\tdsdt_line(\"{\");\n\tdsdt_line(\"  Store (Arg0, PICM)\");\n\tdsdt_line(\"}\");\n\tdsdt_line(\"\");\n\tdsdt_line(\"Scope (_SB)\");\n\tdsdt_line(\"{\");\n\tfor (bus = 0; bus < MAXBUSES; bus++)\n\t\tpci_bus_write_dsdt(bus);\n\tdsdt_line(\"}\");\n\tdsdt_unindent(1);\n}\n\nint\npci_bus_configured(int bus)\n{\n\tassert(bus >= 0 && bus < MAXBUSES);\n\treturn (pci_businfo[bus] != NULL);\n}\n\nint\npci_msi_enabled(struct pci_vdev *dev)\n{\n\treturn dev->msi.enabled;\n}\n\nint\npci_msi_maxmsgnum(struct pci_vdev *dev)\n{\n\tif (dev->msi.enabled)\n\t\treturn dev->msi.maxmsgnum;\n\telse\n\t\treturn 0;\n}\n\nint\npci_msix_enabled(struct pci_vdev *dev)\n{\n\treturn (dev->msix.enabled && !dev->msi.enabled);\n}\n\n/**\n * @brief Generate a MSI-X interrupt to guest\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param index MSIx table entry index.\n *\n * @return None\n */\nvoid\npci_generate_msix(struct pci_vdev *dev, int index)\n{\n\tstruct msix_table_entry *mte;\n\n\tif (!pci_msix_enabled(dev))\n\t\treturn;\n\n\tif (dev->msix.function_mask)\n\t\treturn;\n\n\tif (index >= dev->msix.table_count)\n\t\treturn;\n\n\tmte = &dev->msix.table[index];\n\tif ((mte->vector_control & PCIM_MSIX_VCTRL_MASK) == 0) {\n\t\t/* XXX Set PBA bit if interrupt is disabled */\n\t\tvm_lapic_msi(dev->vmctx, mte->addr, mte->msg_data);\n\t}\n}\n\n/**\n * @brief Generate a MSI interrupt to guest\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param index Message data index.\n *\n * @return None\n */\nvoid\npci_generate_msi(struct pci_vdev *dev, int index)\n{\n\tif (pci_msi_enabled(dev) && index < pci_msi_maxmsgnum(dev)) {\n\t\tvm_lapic_msi(dev->vmctx, dev->msi.addr,\n\t\t\t     dev->msi.msg_data + index);\n\t}\n}\n\nstatic bool\npci_lintr_permitted(struct pci_vdev *dev)\n{\n\tuint16_t cmd;\n\n\tcmd = pci_get_cfgdata16(dev, PCIR_COMMAND);\n\treturn (!(dev->msi.enabled || dev->msix.enabled ||\n\t\t(cmd & PCIM_CMD_INTxDIS)));\n}\n\nvoid\npci_lintr_request(struct pci_vdev *dev)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tint bestpin, bestcount, pin;\n\n\tbi = pci_businfo[dev->bus];\n\tassert(bi != NULL);\n\n\t/*\n\t * Just allocate a pin from our slot.  The pin will be\n\t * assigned IRQs later when interrupts are routed.\n\t */\n\tsi = &bi->slotinfo[dev->slot];\n\tbestpin = 0;\n\tbestcount = si->si_intpins[0].ii_count;\n\tfor (pin = 1; pin < 4; pin++) {\n\t\tif (si->si_intpins[pin].ii_count < bestcount) {\n\t\t\tbestpin = pin;\n\t\t\tbestcount = si->si_intpins[pin].ii_count;\n\t\t}\n\t}\n\n\tsi->si_intpins[bestpin].ii_count++;\n\tdev->lintr.pin = bestpin + 1;\n\tpci_set_cfgdata8(dev, PCIR_INTPIN, bestpin + 1);\n}\n\nvoid\npci_lintr_release(struct pci_vdev *dev)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tint pin;\n\n\tbi = pci_businfo[dev->bus];\n\tassert(bi != NULL);\n\n\tsi = &bi->slotinfo[dev->slot];\n\n\tfor (pin = 1; pin < 4; pin++) {\n\t\tsi->si_intpins[pin].ii_count = 0;\n\t\tsi->si_intpins[pin].ii_pirq_pin = 0;\n\t\tsi->si_intpins[pin].ii_ioapic_irq = 0;\n\t}\n}\n\nstatic void\npci_lintr_route(struct pci_vdev *dev)\n{\n\tstruct businfo *bi;\n\tstruct intxinfo *ii;\n\n\tif (dev->lintr.pin == 0)\n\t\treturn;\n\n\tbi = pci_businfo[dev->bus];\n\tassert(bi != NULL);\n\tii = &bi->slotinfo[dev->slot].si_intpins[dev->lintr.pin - 1];\n\n\t/*\n\t * Attempt to allocate an I/O APIC pin for this intpin if one\n\t * is not yet assigned.\n\t */\n\tif (ii->ii_ioapic_irq == 0)\n\t\tii->ii_ioapic_irq = ioapic_pci_alloc_irq(dev);\n\tassert(ii->ii_ioapic_irq > 0);\n\n\t/*\n\t * Attempt to allocate a PIRQ pin for this intpin if one is\n\t * not yet assigned.\n\t */\n\tif (ii->ii_pirq_pin == 0)\n\t\tii->ii_pirq_pin = pirq_alloc_pin(dev);\n\tassert(ii->ii_pirq_pin > 0);\n\n\tdev->lintr.ioapic_irq = ii->ii_ioapic_irq;\n\tdev->lintr.pirq_pin = ii->ii_pirq_pin;\n\tpci_set_cfgdata8(dev, PCIR_INTLINE, pirq_irq(ii->ii_pirq_pin));\n}\n\n/**\n * @brief Assert INTx pin of virtual PCI device\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n *\n * @return None\n */\nvoid\npci_lintr_assert(struct pci_vdev *dev)\n{\n\tassert(dev->lintr.pin > 0);\n\n\tpthread_mutex_lock(&dev->lintr.lock);\n\tif (dev->lintr.state == IDLE) {\n\t\tif (pci_lintr_permitted(dev)) {\n\t\t\tdev->lintr.state = ASSERTED;\n\t\t\tpci_irq_assert(dev);\n\t\t} else\n\t\t\tdev->lintr.state = PENDING;\n\t}\n\tpthread_mutex_unlock(&dev->lintr.lock);\n}\n\n/**\n * @brief Deassert INTx pin of virtual PCI device\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n *\n * @return None\n */\nvoid\npci_lintr_deassert(struct pci_vdev *dev)\n{\n\tassert(dev->lintr.pin > 0);\n\n\tpthread_mutex_lock(&dev->lintr.lock);\n\tif (dev->lintr.state == ASSERTED) {\n\t\tdev->lintr.state = IDLE;\n\t\tpci_irq_deassert(dev);\n\t} else if (dev->lintr.state == PENDING)\n\t\tdev->lintr.state = IDLE;\n\tpthread_mutex_unlock(&dev->lintr.lock);\n}\n\nstatic void\npci_lintr_update(struct pci_vdev *dev)\n{\n\tpthread_mutex_lock(&dev->lintr.lock);\n\tif (dev->lintr.state == ASSERTED && !pci_lintr_permitted(dev)) {\n\t\tpci_irq_deassert(dev);\n\t\tdev->lintr.state = PENDING;\n\t} else if (dev->lintr.state == PENDING && pci_lintr_permitted(dev)) {\n\t\tdev->lintr.state = ASSERTED;\n\t\tpci_irq_assert(dev);\n\t}\n\tpthread_mutex_unlock(&dev->lintr.lock);\n}\n\nint\npci_count_lintr(int bus)\n{\n\tint count, slot, pin;\n\tstruct slotinfo *slotinfo;\n\n\tcount = 0;\n\tif (pci_businfo[bus] != NULL) {\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tslotinfo = &pci_businfo[bus]->slotinfo[slot];\n\t\t\tfor (pin = 0; pin < 4; pin++) {\n\t\t\t\tif (slotinfo->si_intpins[pin].ii_count != 0)\n\t\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}\n\nvoid\npci_walk_lintr(int bus, pci_lintr_cb cb, void *arg)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct intxinfo *ii;\n\tint slot, pin;\n\n\tbi = pci_businfo[bus];\n\tif (bi == NULL)\n\t\treturn;\n\n\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\tsi = &bi->slotinfo[slot];\n\t\tfor (pin = 0; pin < 4; pin++) {\n\t\t\tii = &si->si_intpins[pin];\n\t\t\tif (ii->ii_count != 0)\n\t\t\t\tcb(bus, slot, pin + 1, ii->ii_pirq_pin,\n\t\t\t\t    ii->ii_ioapic_irq, arg);\n\t\t}\n\t}\n}\n\n/*\n * Return 1 if the emulated device in 'slot' is a multi-function device.\n * Return 0 otherwise.\n */\nstatic int\npci_emul_is_mfdev(int bus, int slot)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tint f, numfuncs;\n\n\tnumfuncs = 0;\n\tbi = pci_businfo[bus];\n\tif (bi != NULL) {\n\t\tsi = &bi->slotinfo[slot];\n\t\tfor (f = 0; f < MAXFUNCS; f++) {\n\t\t\tif (si->si_funcs[f].fi_devi != NULL)\n\t\t\t\tnumfuncs++;\n\t\t}\n\t}\n\treturn (numfuncs > 1);\n}\n\n/*\n * Ensure that the PCIM_MFDEV bit is properly set (or unset) depending on\n * whether or not is a multi-function being emulated in the pci 'slot'.\n */\nstatic void\npci_emul_hdrtype_fixup(int bus, int slot, int off, int bytes, uint32_t *rv)\n{\n\tint mfdev;\n\n\tif (off <= PCIR_HDRTYPE && off + bytes > PCIR_HDRTYPE) {\n\t\tmfdev = pci_emul_is_mfdev(bus, slot);\n\t\tswitch (bytes) {\n\t\tcase 1:\n\t\tcase 2:\n\t\t\t*rv &= ~PCIM_MFDEV;\n\t\t\tif (mfdev)\n\t\t\t\t*rv |= PCIM_MFDEV;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\t*rv &= ~(PCIM_MFDEV << 16);\n\t\t\tif (mfdev)\n\t\t\t\t*rv |= (PCIM_MFDEV << 16);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void\npci_emul_cmdsts_write(struct pci_vdev *dev, int coff, uint32_t new, int bytes)\n{\n\tint i, rshift;\n\tuint32_t cmd, cmd2, changed, old, readonly;\n\n\tcmd = pci_get_cfgdata16(dev, PCIR_COMMAND);\t/* stash old value */\n\n\t/*\n\t * From PCI Local Bus Specification 3.0 sections 6.2.2 and 6.2.3.\n\t *\n\t * XXX Bits 8, 11, 12, 13, 14 and 15 in the status register are\n\t * 'write 1 to clear'. However these bits are not set to '1' by\n\t * any device emulation so it is simpler to treat them as readonly.\n\t */\n\trshift = (coff & 0x3) * 8;\n\treadonly = 0xFFFFF880 >> rshift;\n\n\told = CFGREAD(dev, coff, bytes);\n\tnew &= ~readonly;\n\tnew |= (old & readonly);\n\tCFGWRITE(dev, coff, new, bytes);\t\t/* update config */\n\n\tcmd2 = pci_get_cfgdata16(dev, PCIR_COMMAND);\t/* get updated value */\n\tchanged = cmd ^ cmd2;\n\n\t/*\n\t * If the MMIO or I/O address space decoding has changed then\n\t * register/unregister all BARs that decode that address space.\n\t */\n\tfor (i = 0; i <= PCI_BARMAX; i++) {\n\t\tswitch (dev->bar[i].type) {\n\t\tcase PCIBAR_NONE:\n\t\tcase PCIBAR_MEMHI64:\n\t\t\tbreak;\n\t\tcase PCIBAR_IO:\n\t\t/* I/O address space decoding changed? */\n\t\t\tif (changed & PCIM_CMD_PORTEN) {\n\t\t\t\tif (porten(dev))\n\t\t\t\t\tregister_bar(dev, i);\n\t\t\t\telse\n\t\t\t\t\tunregister_bar(dev, i);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase PCIBAR_MEM32:\n\t\tcase PCIBAR_MEM64:\n\t\t/* MMIO address space decoding changed? */\n\t\t\tif (changed & PCIM_CMD_MEMEN) {\n\t\t\t\tif (memen(dev))\n\t\t\t\t\tregister_bar(dev, i);\n\t\t\t\telse\n\t\t\t\t\tunregister_bar(dev, i);\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tassert(0);\n\t\t}\n\t}\n\n\t/*\n\t * If INTx has been unmasked and is pending, assert the\n\t * interrupt.\n\t */\n\tpci_lintr_update(dev);\n}\n\nstatic void\npci_cfgrw(struct vmctx *ctx, int vcpu, int in, int bus, int slot, int func,\n\t  int coff, int bytes, uint32_t *eax)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct pci_vdev *dev;\n\tstruct pci_vdev_ops *ops;\n\tint idx, needcfg;\n\tuint64_t addr, bar, mask;\n\tbool decode, ignore_reg_unreg = false;\n\n\tbi = pci_businfo[bus];\n\tif (bi != NULL) {\n\t\tsi = &bi->slotinfo[slot];\n\t\tdev = si->si_funcs[func].fi_devi;\n\t} else\n\t\tdev = NULL;\n\n\t/*\n\t * Just return if there is no device at this slot:func or if the\n\t * the guest is doing an un-aligned access.\n\t */\n\tif (dev == NULL || (bytes != 1 && bytes != 2 && bytes != 4) ||\n\t    (coff & (bytes - 1)) != 0) {\n\t\tif (in)\n\t\t\t*eax = 0xffffffff;\n\t\treturn;\n\t}\n\n\tops = dev->dev_ops;\n\n\t/*\n\t * For non-passthru device, extended config space is NOT supported.\n\t * Ignore all writes beyond the standard config space and return all\n\t * ones on reads.\n\t *\n\t * For passthru device, extended config space is supported.\n\t * Access to extended config space is implemented via libpciaccess.\n\t */\n\tif (strcmp(\"passthru\", ops->class_name)) {\n\t\tif (coff >= PCI_REGMAX + 1) {\n\t\t\tif (in) {\n\t\t\t\t*eax = 0xffffffff;\n\t\t\t\t/*\n\t\t\t\t * Extended capabilities begin at offset 256 in\n\t\t\t\t * config space.\n\t\t\t\t * Absence of extended capabilities is signaled\n\t\t\t\t * with all 0s in the extended capability header\n\t\t\t\t * at offset 256.\n\t\t\t\t */\n\t\t\t\tif (coff <= PCI_REGMAX + 4)\n\t\t\t\t\t*eax = 0x00000000;\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/*\n\t * Config read\n\t */\n\tif (in) {\n\t\t/* Let the device emulation override the default handler */\n\t\tif (ops->vdev_cfgread != NULL) {\n\t\t\tneedcfg = ops->vdev_cfgread(ctx, vcpu, dev, coff, bytes,\n\t\t\t    eax);\n\t\t} else {\n\t\t\tneedcfg = 1;\n\t\t}\n\n\t\tif (needcfg)\n\t\t\t*eax = CFGREAD(dev, coff, bytes);\n\n\t\tpci_emul_hdrtype_fixup(bus, slot, coff, bytes, eax);\n\t} else {\n\t\t/* Let the device emulation override the default handler */\n\t\tif (ops->vdev_cfgwrite != NULL &&\n\t\t    (*ops->vdev_cfgwrite)(ctx, vcpu, dev,\n\t\t\t\t\t  coff, bytes, *eax) == 0)\n\t\t\treturn;\n\n\t\t/*\n\t\t * Special handling for write to BAR registers\n\t\t */\n\t\tif (coff >= PCIR_BAR(0) && coff < PCIR_BAR(PCI_BARMAX + 1)) {\n\t\t\t/*\n\t\t\t * Ignore writes to BAR registers that are not\n\t\t\t * 4-byte aligned.\n\t\t\t */\n\t\t\tif (bytes != 4 || (coff & 0x3) != 0)\n\t\t\t\treturn;\n\t\t\tidx = (coff - PCIR_BAR(0)) / 4;\n\t\t\tmask = ~(dev->bar[idx].size - 1);\n\n\t\t\tif (dev->bar[idx].type == PCIBAR_IO)\n\t\t\t\tdecode = porten(dev);\n\t\t\telse\n\t\t\t\tdecode = memen(dev);\n\n\t\t\t/* Some driver does not disable the decode of BAR\n\t\t\t * register via the command register before sizing a\n\t\t\t * BAR. This will lead to a overlay of the BAR\n\t\t\t * addresses when trying to register the intermediate\n\t\t\t * BAR address via register_bar. A stateful variable\n\t\t\t * sizing is used to keep track of such kind of BAR\n\t\t\t * address changes and workaroud this violation.\n\t\t\t */\n\t\t\tif (decode) {\n\t\t\t\tif (!dev->bar[idx].sizing && (*eax == ~0U)) {\n\t\t\t\t\tdev->bar[idx].sizing = true;\n\t\t\t\t\tignore_reg_unreg = true;\n\t\t\t\t} else if (dev->bar[idx].sizing && (*eax != ~0U)) {\n\t\t\t\t\tdev->bar[idx].sizing = false;\n\t\t\t\t\tignore_reg_unreg = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tswitch (dev->bar[idx].type) {\n\t\t\tcase PCIBAR_NONE:\n\t\t\t\tdev->bar[idx].addr = bar = 0;\n\t\t\t\tbreak;\n\t\t\tcase PCIBAR_IO:\n\t\t\t\taddr = *eax & mask;\n\t\t\t\taddr &= 0xffff;\n\t\t\t\tbar = addr | PCIM_BAR_IO_SPACE;\n\t\t\t\t/*\n\t\t\t\t * Register the new BAR value for interception\n\t\t\t\t */\n\t\t\t\tif (addr != dev->bar[idx].addr) {\n\t\t\t\t\tupdate_bar_address(ctx, dev, addr, idx,\n\t\t\t\t\t\t\t   PCIBAR_IO,\n\t\t\t\t\t\t\t   ignore_reg_unreg);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase PCIBAR_MEM32:\n\t\t\t\taddr = bar = *eax & mask;\n\t\t\t\tbar |= PCIM_BAR_MEM_SPACE | PCIM_BAR_MEM_32;\n\t\t\t\tif (addr != dev->bar[idx].addr) {\n\t\t\t\t\tupdate_bar_address(ctx, dev, addr, idx,\n\t\t\t\t\t\t\t   PCIBAR_MEM32,\n\t\t\t\t\t\t\t   ignore_reg_unreg);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase PCIBAR_MEM64:\n\t\t\t\taddr = bar = *eax & mask;\n\t\t\t\tbar |= PCIM_BAR_MEM_SPACE | PCIM_BAR_MEM_64 |\n\t\t\t\t       PCIM_BAR_MEM_PREFETCH;\n\t\t\t\tif (addr != (uint32_t)dev->bar[idx].addr) {\n\t\t\t\t\tupdate_bar_address(ctx, dev, addr, idx,\n\t\t\t\t\t\t\t   PCIBAR_MEM64,\n\t\t\t\t\t\t\t   ignore_reg_unreg);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase PCIBAR_MEMHI64:\n\t\t\t\tassert(idx >= 1);\n\t\t\t\tmask = ~(dev->bar[idx - 1].size - 1);\n\t\t\t\taddr = ((uint64_t)*eax << 32) & mask;\n\t\t\t\tbar = addr >> 32;\n\t\t\t\tif (bar != dev->bar[idx - 1].addr >> 32) {\n\t\t\t\t\tupdate_bar_address(ctx, dev, addr, idx - 1,\n\t\t\t\t\t\t\t   PCIBAR_MEMHI64,\n\t\t\t\t\t\t\t   ignore_reg_unreg);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tassert(0);\n\t\t\t}\n\t\t\tpci_set_cfgdata32(dev, coff, bar);\n\n\t\t} else if (coff == PCIR_BIOS) {\n\t\t\t/* ignore ROM BAR length request */\n\t\t} else if (pci_emul_iscap(dev, coff)) {\n\t\t\tpci_emul_capwrite(dev, coff, bytes, *eax);\n\t\t} else if (coff >= PCIR_COMMAND && coff < PCIR_REVID) {\n\t\t\tpci_emul_cmdsts_write(dev, coff, *eax, bytes);\n\t\t} else {\n\t\t\tCFGWRITE(dev, coff, *eax, bytes);\n\t\t}\n\t}\n}\n\nstatic int cfgenable, cfgbus, cfgslot, cfgfunc, cfgoff;\n\nstatic int\npci_emul_cfgaddr(struct vmctx *ctx, int vcpu, int in, int port, int bytes,\n\t\t uint32_t *eax, void *arg)\n{\n\tuint32_t x;\n\n\tif (bytes != 4) {\n\t\tif (in)\n\t\t\t*eax = (bytes == 2) ? 0xffff : 0xff;\n\t\treturn 0;\n\t}\n\n\tif (in) {\n\t\tx = (cfgbus << 16) | (cfgslot << 11) | (cfgfunc << 8) | cfgoff;\n\t\tif (cfgenable)\n\t\t\tx |= CONF1_ENABLE;\n\t\t*eax = x;\n\t} else {\n\t\tx = *eax;\n\t\tcfgenable = (x & CONF1_ENABLE) == CONF1_ENABLE;\n\t\tcfgoff = x & PCI_REGMAX;\n\t\tcfgfunc = (x >> 8) & PCI_FUNCMAX;\n\t\tcfgslot = (x >> 11) & PCI_SLOTMAX;\n\t\tcfgbus = (x >> 16) & PCI_BUSMAX;\n\t}\n\n\treturn 0;\n}\nINOUT_PORT(pci_cfgaddr, CONF1_ADDR_PORT, IOPORT_F_INOUT, pci_emul_cfgaddr);\n\nstatic int\npci_emul_cfgdata(struct vmctx *ctx, int vcpu, int in, int port, int bytes,\n\t\t uint32_t *eax, void *arg)\n{\n\tint coff;\n\n\tassert(bytes == 1 || bytes == 2 || bytes == 4);\n\n\tcoff = cfgoff + (port - CONF1_DATA_PORT);\n\tif (cfgenable) {\n\t\tpci_cfgrw(ctx, vcpu, in, cfgbus, cfgslot, cfgfunc, coff, bytes,\n\t\t    eax);\n\t} else {\n\t\t/* Ignore accesses to cfgdata if not enabled by cfgaddr */\n\t\tif (in)\n\t\t\t*eax = 0xffffffff;\n\t}\n\treturn 0;\n}\n\nINOUT_PORT(pci_cfgdata, CONF1_DATA_PORT+0, IOPORT_F_INOUT, pci_emul_cfgdata);\nINOUT_PORT(pci_cfgdata, CONF1_DATA_PORT+1, IOPORT_F_INOUT, pci_emul_cfgdata);\nINOUT_PORT(pci_cfgdata, CONF1_DATA_PORT+2, IOPORT_F_INOUT, pci_emul_cfgdata);\nINOUT_PORT(pci_cfgdata, CONF1_DATA_PORT+3, IOPORT_F_INOUT, pci_emul_cfgdata);\n\nint\nemulate_pci_cfgrw(struct vmctx *ctx, int vcpu, int in, int bus, int slot,\n\t\t  int func, int reg, int bytes, int *value)\n{\n\tpci_cfgrw(ctx, vcpu, in, bus, slot, func, reg,\n\t\t\tbytes, (uint32_t *)value);\n\treturn 0;\n}\n\n#define PCI_EMUL_TEST\n#ifdef PCI_EMUL_TEST\n/*\n * Define a dummy test device\n */\n#define DIOSZ\t8\n#define DMEMSZ\t4096\nstruct pci_emul_dummy {\n\tuint8_t   ioregs[DIOSZ];\n\tuint8_t\t  memregs[2][DMEMSZ];\n};\n\n#define\tPCI_EMUL_MSI_MSGS\t 4\n#define\tPCI_EMUL_MSIX_MSGS\t16\n\nstatic int\npci_emul_dinit(struct vmctx *ctx, struct pci_vdev *dev, char *opts)\n{\n\tint error;\n\tstruct pci_emul_dummy *dummy;\n\n\tdummy = calloc(1, sizeof(struct pci_emul_dummy));\n\n\tdev->arg = dummy;\n\n\tpci_set_cfgdata16(dev, PCIR_DEVICE, 0x0001);\n\tpci_set_cfgdata16(dev, PCIR_VENDOR, 0x10DD);\n\tpci_set_cfgdata8(dev, PCIR_CLASS, 0x02);\n\n\terror = pci_emul_add_msicap(dev, PCI_EMUL_MSI_MSGS);\n\tassert(error == 0);\n\n\terror = pci_emul_alloc_bar(dev, 0, PCIBAR_IO, DIOSZ);\n\tassert(error == 0);\n\n\terror = pci_emul_alloc_bar(dev, 1, PCIBAR_MEM32, DMEMSZ);\n\tassert(error == 0);\n\n\terror = pci_emul_alloc_bar(dev, 2, PCIBAR_MEM32, DMEMSZ);\n\tassert(error == 0);\n\n\treturn 0;\n}\n\nstatic void\npci_emul_diow(struct vmctx *ctx, int vcpu, struct pci_vdev *dev, int baridx,\n\t      uint64_t offset, int size, uint64_t value)\n{\n\tint i;\n\tvoid *offset_ptr;\n\tstruct pci_emul_dummy *dummy = dev->arg;\n\n\tif (baridx == 0) {\n\t\tif (offset + size > DIOSZ) {\n\t\t\tprintf(\"diow: iow too large, offset %ld size %d\\n\",\n\t\t\t       offset, size);\n\t\t\treturn;\n\t\t}\n\n\t\toffset_ptr = (void *) &dummy->ioregs[offset];\n\t\tif (size == 1)\n\t\t\t*(uint8_t *)offset_ptr = value & 0xff;\n\t\telse if (size == 2)\n\t\t\t*(uint16_t *)offset_ptr = value & 0xffff;\n\t\telse if (size == 4)\n\t\t\t*(uint32_t *)offset = value;\n\t\telse\n\t\t\tprintf(\"diow: iow unknown size %d\\n\", size);\n\n\t\t/*\n\t\t * Special magic value to generate an interrupt\n\t\t */\n\t\tif (offset == 4 && size == 4 && pci_msi_enabled(dev))\n\t\t\tpci_generate_msi(dev, value % pci_msi_maxmsgnum(dev));\n\n\t\tif (value == 0xabcdef) {\n\t\t\tfor (i = 0; i < pci_msi_maxmsgnum(dev); i++)\n\t\t\t\tpci_generate_msi(dev, i);\n\t\t}\n\t}\n\n\tif (baridx == 1 || baridx == 2) {\n\t\tif (offset + size > DMEMSZ) {\n\t\t\tprintf(\"diow: memw too large, offset %ld size %d\\n\",\n\t\t\t       offset, size);\n\t\t\treturn;\n\t\t}\n\n\t\ti = baridx - 1;\t\t/* 'memregs' index */\n\n\t\toffset_ptr = (void *) &dummy->memregs[i][offset];\n\t\tif (size == 1)\n\t\t\t*(uint8_t *)offset_ptr = value;\n\t\telse if (size == 2)\n\t\t\t*(uint16_t *)offset_ptr = value;\n\t\telse if (size == 4)\n\t\t\t*(uint32_t *)offset_ptr = value;\n\t\telse if (size == 8)\n\t\t\t*(uint64_t *)offset_ptr = value;\n\t\telse\n\t\t\tprintf(\"diow: memw unknown size %d\\n\", size);\n\n\t\t/*\n\t\t * magic interrupt ??\n\t\t */\n\t}\n\n\tif (baridx > 2 || baridx < 0)\n\t\tprintf(\"diow: unknown bar idx %d\\n\", baridx);\n}\n\nstatic uint64_t\npci_emul_dior(struct vmctx *ctx, int vcpu, struct pci_vdev *dev, int baridx,\n\t      uint64_t offset, int size)\n{\n\tstruct pci_emul_dummy *dummy = dev->arg;\n\tuint32_t value = 0;\n\tint i;\n\tvoid *offset_ptr;\n\n\tif (baridx == 0) {\n\t\tif (offset + size > DIOSZ) {\n\t\t\tprintf(\"dior: ior too large, offset %ld size %d\\n\",\n\t\t\t       offset, size);\n\t\t\treturn 0;\n\t\t}\n\n\t\tvalue = 0;\n\t\toffset_ptr = (void *) &dummy->ioregs[offset];\n\t\tif (size == 1)\n\t\t\tvalue = *(uint8_t *)offset_ptr;\n\t\telse if (size == 2)\n\t\t\tvalue = *(uint16_t *)offset_ptr;\n\t\telse if (size == 4)\n\t\t\tvalue = *(uint32_t *)offset_ptr;\n\t\telse\n\t\t\tprintf(\"dior: ior unknown size %d\\n\", size);\n\t}\n\n\tif (baridx == 1 || baridx == 2) {\n\t\tif (offset + size > DMEMSZ) {\n\t\t\tprintf(\"dior: memr too large, offset %ld size %d\\n\",\n\t\t\t       offset, size);\n\t\t\treturn 0;\n\t\t}\n\n\t\ti = baridx - 1;\t\t/* 'memregs' index */\n\n\t\toffset_ptr = (void *) &dummy->memregs[i][offset];\n\t\tif (size == 1)\n\t\t\tvalue = *(uint8_t *)offset_ptr;\n\t\telse if (size == 2)\n\t\t\tvalue = *(uint16_t *)offset_ptr;\n\t\telse if (size == 4)\n\t\t\tvalue = *(uint32_t *)offset_ptr;\n\t\telse if (size == 8)\n\t\t\tvalue = *(uint64_t *)offset_ptr;\n\t\telse\n\t\t\tprintf(\"dior: ior unknown size %d\\n\", size);\n\t}\n\n\n\tif (baridx > 2 || baridx < 0) {\n\t\tprintf(\"dior: unknown bar idx %d\\n\", baridx);\n\t\treturn 0;\n\t}\n\n\treturn value;\n}\n\nstruct pci_vdev*\npci_get_vdev_info(int slot)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct pci_vdev *dev = NULL;\n\n\tbi = pci_businfo[0];\n\tassert(bi != NULL);\n\n\tsi = &bi->slotinfo[slot];\n\tif (si != NULL)\n\t\tdev = si->si_funcs[0].fi_devi;\n\telse\n\t\tfprintf(stderr, \"slot=%d is empty!\\n\", slot);\n\n\treturn dev;\n}\n\nstruct pci_vdev_ops pci_dummy = {\n\t.class_name\t= \"dummy\",\n\t.vdev_init\t= pci_emul_dinit,\n\t.vdev_barwrite\t= pci_emul_diow,\n\t.vdev_barread\t= pci_emul_dior\n};\nDEFINE_PCI_DEVTYPE(pci_dummy);\n\n#endif /* PCI_EMUL_TEST */\n", "/*-\n * Copyright (c) 2011 NetApp, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY NETAPP, INC ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL NETAPP, INC OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n *\n * $FreeBSD$\n */\n\n#ifndef _PCI_CORE_H_\n#define _PCI_CORE_H_\n\n#include <sys/queue.h>\n\n#include <assert.h>\n#include <stdbool.h>\n#include \"types.h\"\n#include \"pcireg.h\"\n\n#define\tPCI_BARMAX\tPCIR_MAX_BAR_0\t/* BAR registers in a Type 0 header */\n#define\tPCI_BDF(b, d, f) (((b & 0xFF) << 8) | ((d & 0x1F) << 3) | ((f & 0x7)))\n\n#define\tPCI_EMUL_ECFG_BASE\t0xE0000000UL\t/* 3.5GB */\n\n#define\tPCI_EMUL_MEMBASE64\t0x100000000UL\t/* 4GB */\n#define\tPCI_EMUL_MEMLIMIT64\t0x140000000UL\t/* 5GB */\n\nstruct vmctx;\nstruct pci_vdev;\nstruct memory_region;\n\nstruct pci_vdev_ops {\n\tchar\t*class_name;\t\t/* Name of device class */\n\n\t/* instance creation */\n\tint\t(*vdev_init)(struct vmctx *, struct pci_vdev *,\n\t\t\t     char *opts);\n\n\t/* instance deinit */\n\tvoid\t(*vdev_deinit)(struct vmctx *, struct pci_vdev *,\n\t\t\tchar *opts);\n\n\t/* ACPI DSDT enumeration */\n\tvoid\t(*vdev_write_dsdt)(struct pci_vdev *);\n\n\t/* ops related to physical resources */\n\tvoid\t(*vdev_phys_access)(struct vmctx *ctx, struct pci_vdev *dev);\n\n\t/* update BAR map callback */\n\tvoid\t(*vdev_update_bar_map)(struct vmctx *ctx,\n\t\t\t\tstruct pci_vdev *dev, int idx,\n\t\t\t\tuint64_t orig_addr);\n\n\t/* config space read/write callbacks */\n\tint\t(*vdev_cfgwrite)(struct vmctx *ctx, int vcpu,\n\t\t\t       struct pci_vdev *pi, int offset,\n\t\t\t       int bytes, uint32_t val);\n\tint\t(*vdev_cfgread)(struct vmctx *ctx, int vcpu,\n\t\t\t      struct pci_vdev *pi, int offset,\n\t\t\t      int bytes, uint32_t *retval);\n\n\t/* BAR read/write callbacks */\n\tvoid\t(*vdev_barwrite)(struct vmctx *ctx, int vcpu,\n\t\t\t\t struct pci_vdev *pi, int baridx,\n\t\t\t\t uint64_t offset, int size, uint64_t value);\n\tuint64_t  (*vdev_barread)(struct vmctx *ctx, int vcpu,\n\t\t\t\tstruct pci_vdev *pi, int baridx,\n\t\t\t\tuint64_t offset, int size);\n};\n\n/*\n * Put all PCI instances' addresses into one section named pci_devemu_set\n * so that DM could enumerate and initialize each of them.\n */\n#define DEFINE_PCI_DEVTYPE(x)\tDATA_SET(pci_vdev_ops_set, x)\n\nenum pcibar_type {\n\tPCIBAR_NONE,\n\tPCIBAR_IO,\n\tPCIBAR_MEM32,\n\tPCIBAR_MEM64,\n\tPCIBAR_MEMHI64\n};\n\nstruct pcibar {\n\tenum pcibar_type\ttype;\t\t/* io or memory */\n\tuint64_t\t\tsize;\n\tuint64_t\t\taddr;\n\tbool\t\t\tsizing;\n};\n\n#define PI_NAMESZ\t40\n\nstruct msix_table_entry {\n\tuint64_t\taddr;\n\tuint32_t\tmsg_data;\n\tuint32_t\tvector_control;\n} __attribute__((packed));\n\n/*\n * In case the structure is modified to hold extra information, use a define\n * for the size that should be emulated.\n */\n#define\tMSIX_TABLE_ENTRY_SIZE\t16\n#define MAX_MSIX_TABLE_ENTRIES\t2048\n#define\tPBA_SIZE(msgnum)\t(roundup2((msgnum), 64) / 8)\n\nenum lintr_stat {\n\tIDLE,\n\tASSERTED,\n\tPENDING\n};\n\nstruct pci_vdev {\n\tstruct pci_vdev_ops *dev_ops;\n\tstruct vmctx *vmctx;\n\tuint8_t\tbus, slot, func;\n\tchar\tname[PI_NAMESZ];\n\tint\tbar_getsize;\n\tint\tprevcap;\n\tint\tcapend;\n\n\tstruct {\n\t\tint8_t\tpin;\n\t\tenum lintr_stat\tstate;\n\t\tint\t\tpirq_pin;\n\t\tint\t\tioapic_irq;\n\t\tpthread_mutex_t\tlock;\n\t} lintr;\n\n\tstruct {\n\t\tint\t\tenabled;\n\t\tuint64_t\taddr;\n\t\tuint64_t\tmsg_data;\n\t\tint\t\tmaxmsgnum;\n\t} msi;\n\n\tstruct {\n\t\tint\tenabled;\n\t\tint\ttable_bar;\n\t\tint\tpba_bar;\n\t\tuint32_t table_offset;\n\t\tint\ttable_count;\n\t\tuint32_t pba_offset;\n\t\tint\tpba_size;\n\t\tint\tfunction_mask;\n\t\tstruct msix_table_entry *table;\t/* allocated at runtime */\n\t\tvoid\t*pba_page;\n\t\tint\tpba_page_offset;\n\t} msix;\n\n\tvoid\t*arg;\t\t/* devemu-private data */\n\n\tuint8_t\tcfgdata[PCI_REGMAX + 1];\n\tstruct pcibar bar[PCI_BARMAX + 1];\n};\n\nstruct gsi_dev {\n\t/*\n\t * For PCI devices, use a string \"b:d.f\" to stand for the device's BDF,\n\t *  such as \"00:00.0\".\n\t * For non-PCI devices, use the device's name to stand for the device,\n\t *  such as \"timer\".\n\t */\n\tchar *dev_name;\n\tuint8_t gsi;\n};\n\nextern struct gsi_dev gsi_dev_mapping_tables[];\nextern int num_gsi_dev_mapping_tables;\n\nstruct msicap {\n\tuint8_t\t\tcapid;\n\tuint8_t\t\tnextptr;\n\tuint16_t\tmsgctrl;\n\tuint32_t\taddrlo;\n\tuint32_t\taddrhi;\n\tuint16_t\tmsgdata;\n} __attribute__((packed));\nstatic_assert(sizeof(struct msicap) == 14, \"compile-time assertion failed\");\n\nstruct msixcap {\n\tuint8_t\t\tcapid;\n\tuint8_t\t\tnextptr;\n\tuint16_t\tmsgctrl;\n\tuint32_t\ttable_info;\t/* bar index and offset within it */\n\tuint32_t\tpba_info;\t/* bar index and offset within it */\n} __attribute__((packed));\nstatic_assert(sizeof(struct msixcap) == 12, \"compile-time assertion failed\");\n\nstruct pciecap {\n\tuint8_t\t\tcapid;\n\tuint8_t\t\tnextptr;\n\tuint16_t\tpcie_capabilities;\n\n\tuint32_t\tdev_capabilities;\t/* all devices */\n\tuint16_t\tdev_control;\n\tuint16_t\tdev_status;\n\n\tuint32_t\tlink_capabilities;\t/* devices with links */\n\tuint16_t\tlink_control;\n\tuint16_t\tlink_status;\n\n\tuint32_t\tslot_capabilities;\t/* ports with slots */\n\tuint16_t\tslot_control;\n\tuint16_t\tslot_status;\n\n\tuint16_t\troot_control;\t\t/* root ports */\n\tuint16_t\troot_capabilities;\n\tuint32_t\troot_status;\n\n\tuint32_t\tdev_capabilities2;\t/* all devices */\n\tuint16_t\tdev_control2;\n\tuint16_t\tdev_status2;\n\n\tuint32_t\tlink_capabilities2;\t/* devices with links */\n\tuint16_t\tlink_control2;\n\tuint16_t\tlink_status2;\n\n\tuint32_t\tslot_capabilities2;\t/* ports with slots */\n\tuint16_t\tslot_control2;\n\tuint16_t\tslot_status2;\n} __attribute__((packed));\nstatic_assert(sizeof(struct pciecap) == 60, \"compile-time assertion failed\");\n\ntypedef void (*pci_lintr_cb)(int b, int s, int pin, int pirq_pin,\n\t\t\t     int ioapic_irq, void *arg);\n\nint\tinit_pci(struct vmctx *ctx);\nvoid\tdeinit_pci(struct vmctx *ctx);\nvoid\tmsicap_cfgwrite(struct pci_vdev *pi, int capoff, int offset,\n\t\t\tint bytes, uint32_t val);\nvoid\tmsixcap_cfgwrite(struct pci_vdev *pi, int capoff, int offset,\n\t\t\t int bytes, uint32_t val);\nvoid\tpci_callback(void);\nint\tpci_emul_alloc_bar(struct pci_vdev *pdi, int idx,\n\t\t\t   enum pcibar_type type, uint64_t size);\nint\tpci_emul_alloc_pbar(struct pci_vdev *pdi, int idx,\n\t\t\t    uint64_t hostbase, enum pcibar_type type,\n\t\t\t    uint64_t size);\nvoid\tpci_emul_free_bars(struct pci_vdev *pdi);\nint\tpci_emul_add_capability(struct pci_vdev *dev, u_char *capdata,\n\t\t\t\tint caplen);\nint\tpci_emul_find_capability(struct pci_vdev *dev, uint8_t capid,\n\t\t\t\t int *p_capoff);\nint\tpci_emul_add_msicap(struct pci_vdev *pi, int msgnum);\nint\tpci_emul_add_pciecap(struct pci_vdev *pi, int pcie_device_type);\n\n/**\n * @brief Generate a MSI interrupt to guest\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param index Message data index.\n *\n * @return None\n */\nvoid\tpci_generate_msi(struct pci_vdev *dev, int index);\n\n/**\n * @brief Generate a MSI-X interrupt to guest\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param index MSIs table entry index.\n *\n * @return None\n */\nvoid\tpci_generate_msix(struct pci_vdev *dev, int index);\n\n/**\n * @brief Assert INTx pin of virtual PCI device\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n *\n * @return None\n */\nvoid\tpci_lintr_assert(struct pci_vdev *dev);\n\n/**\n * @brief Deassert INTx pin of virtual PCI device\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n *\n * @return None\n */\nvoid\tpci_lintr_deassert(struct pci_vdev *dev);\n\nvoid\tpci_lintr_request(struct pci_vdev *pi);\nvoid\tpci_lintr_release(struct pci_vdev *pi);\nint\tpci_msi_enabled(struct pci_vdev *pi);\nint\tpci_msix_enabled(struct pci_vdev *pi);\nint\tpci_msix_table_bar(struct pci_vdev *pi);\nint\tpci_msix_pba_bar(struct pci_vdev *pi);\nint\tpci_msi_maxmsgnum(struct pci_vdev *pi);\nint\tpci_parse_slot(char *opt);\nvoid\tpci_populate_msicap(struct msicap *cap, int msgs, int nextptr);\nint\tpci_emul_add_msixcap(struct pci_vdev *pi, int msgnum, int barnum);\nint\tpci_emul_msix_twrite(struct pci_vdev *pi, uint64_t offset, int size,\n\t\t\t     uint64_t value);\nuint64_t pci_emul_msix_tread(struct pci_vdev *pi, uint64_t offset, int size);\nint\tpci_count_lintr(int bus);\nvoid\tpci_walk_lintr(int bus, pci_lintr_cb cb, void *arg);\nvoid\tpci_write_dsdt(void);\nint\tpci_bus_configured(int bus);\nint\temulate_pci_cfgrw(struct vmctx *ctx, int vcpu, int in, int bus,\n\t\t\t  int slot, int func, int reg, int bytes, int *value);\nint\tcreate_gsi_sharing_groups(void);\nvoid\tupdate_pt_info(uint16_t phys_bdf);\nint\tcheck_gsi_sharing_violation(void);\nint\tpciaccess_init(void);\nvoid\tpciaccess_cleanup(void);\nint\tparse_bdf(char *s, int *bus, int *dev, int *func, int base);\nstruct pci_vdev *pci_get_vdev_info(int slot);\n\n\n/**\n * @brief Set virtual PCI device's configuration space in 1 byte width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n * @param val Value in 1 byte.\n *\n * @return None\n */\nstatic inline void\npci_set_cfgdata8(struct pci_vdev *dev, int offset, uint8_t val)\n{\n\tassert(offset <= PCI_REGMAX);\n\t*(uint8_t *)(dev->cfgdata + offset) = val;\n}\n\n/**\n * @brief Set virtual PCI device's configuration space in 2 bytes width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n * @param val Value in 2 bytes.\n *\n * @return None\n */\nstatic inline void\npci_set_cfgdata16(struct pci_vdev *dev, int offset, uint16_t val)\n{\n\tassert(offset <= (PCI_REGMAX - 1) && (offset & 1) == 0);\n\t*(uint16_t *)(dev->cfgdata + offset) = val;\n}\n\n/**\n * @brief Set virtual PCI device's configuration space in 4 bytes width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n * @param val Value in 4 bytes.\n *\n * @return None\n */\nstatic inline void\npci_set_cfgdata32(struct pci_vdev *dev, int offset, uint32_t val)\n{\n\tassert(offset <= (PCI_REGMAX - 3) && (offset & 3) == 0);\n\t*(uint32_t *)(dev->cfgdata + offset) = val;\n}\n\n/**\n * @brief Get virtual PCI device's configuration space in 1 byte width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n *\n * @return The configuration value in 1 byte.\n */\nstatic inline uint8_t\npci_get_cfgdata8(struct pci_vdev *dev, int offset)\n{\n\tassert(offset <= PCI_REGMAX);\n\treturn (*(uint8_t *)(dev->cfgdata + offset));\n}\n\n/**\n * @brief Get virtual PCI device's configuration space in 2 byte width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n *\n * @return The configuration value in 2 bytes.\n */\nstatic inline uint16_t\npci_get_cfgdata16(struct pci_vdev *dev, int offset)\n{\n\tassert(offset <= (PCI_REGMAX - 1) && (offset & 1) == 0);\n\treturn (*(uint16_t *)(dev->cfgdata + offset));\n}\n\n/**\n * @brief Get virtual PCI device's configuration space in 4 byte width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n *\n * @return The configuration value in 4 bytes.\n */\nstatic inline uint32_t\npci_get_cfgdata32(struct pci_vdev *dev, int offset)\n{\n\tassert(offset <= (PCI_REGMAX - 3) && (offset & 3) == 0);\n\treturn (*(uint32_t *)(dev->cfgdata + offset));\n}\n\n#endif /* _PCI_CORE_H_ */\n", "#ifndef _TYPES_H_\n#define _TYPES_H_\n\n#include \"macros.h\"\n#include <stdint.h>\n#include <sched.h>\n#include <sys/types.h>\n\n#define MAXCOMLEN   19      /* max command name remembered */\n#define MAXINTERP   PATH_MAX    /* max interpreter file name length */\n#define MAXLOGNAME  33      /* max login name length (incl. NUL) */\n#define SPECNAMELEN 63      /* max length of devicename */\n\ntypedef cpu_set_t cpuset_t;\ntypedef uint64_t vm_paddr_t;\ntypedef uint64_t vm_ooffset_t;\ntypedef uint64_t cap_ioctl_t;\n\n#define ARRAY_SIZE(a) (sizeof(a) / sizeof(a[0]))\n\n#define container_of(ptr, type, member) ({                   \\\n\tconst typeof(((type *)0)->member) * __mptr = (ptr);  \\\n\t(type *)((char *)__mptr - (offsetof(type, member))); \\\n})\n\n#define __aligned(x)\t\t__attribute__((aligned(x)))\n#define __section(x)\t\t__attribute__((__section__(x)))\n#define __MAKE_SET(set, sym)                        \\\n\tstatic void const * const __set_##set##_sym_##sym       \\\n\t__section(\"set_\" #set) __attribute__((used)) = &sym\n\n#define DATA_SET(set, sym)  __MAKE_SET(set, sym)\n\n#define SET_DECLARE(set, ptype)\\\n\t extern ptype * __CONCAT(__start_set_, set); \\\n\t extern ptype *__CONCAT(__stop_set_, set)\n\n#define SET_BEGIN(set)                          \\\n\t(&__CONCAT(__start_set_, set))\n#define SET_LIMIT(set)                          \\\n\t(&__CONCAT(__stop_set_, set))\n\n#define SET_FOREACH(pvar, set)                      \\\n\tfor (pvar = SET_BEGIN(set); pvar < SET_LIMIT(set); pvar++)\n\n#define nitems(x) (sizeof((x)) / sizeof((x)[0]))\n#define roundup2(x, y)  (((x)+((y)-1))&(~((y)-1)))\n#define rounddown2(x, y) ((x)&(~((y)-1)))\n\nstatic inline uint16_t\nbe16dec(const void *pp)\n{\n\tuint8_t const *p = (uint8_t const *)pp;\n\n\treturn ((p[0] << 8) | p[1]);\n}\n\nstatic inline uint32_t\nbe32dec(const void *pp)\n{\n\tuint8_t const *p = (uint8_t const *)pp;\n\n\treturn (((uint32_t)p[0] << 24) | (p[1] << 16) | (p[2] << 8) | p[3]);\n}\n\nstatic inline void\nbe16enc(void *pp, uint16_t u)\n{\n\tuint8_t *p = (uint8_t *)pp;\n\n\tp[0] = (u >> 8) & 0xff;\n\tp[1] = u & 0xff;\n}\n\nstatic inline void\nbe32enc(void *pp, uint32_t u)\n{\n\tuint8_t *p = (uint8_t *)pp;\n\n\tp[0] = (u >> 24) & 0xff;\n\tp[1] = (u >> 16) & 0xff;\n\tp[2] = (u >> 8) & 0xff;\n\tp[3] = u & 0xff;\n}\nstatic inline int\nflsl(uint64_t mask)\n{\n\treturn mask ? 64 - __builtin_clzl(mask) : 0;\n}\n\n/* memory barrier */\n#define mb()    ({ asm volatile(\"mfence\" ::: \"memory\"); (void)0; })\n\nstatic inline void\ndo_cpuid(u_int ax, u_int *p)\n{\n\t__asm __volatile(\"cpuid\"\n\t : \"=a\" (p[0]), \"=b\" (p[1]), \"=c\" (p[2]), \"=d\" (p[3])\n\t :  \"0\" (ax));\n}\n\n#define UGETW(w)            \\\n\t((w)[0] |             \\\n\t(((uint16_t)((w)[1])) << 8))\n\n#define UGETDW(w)           \\\n\t((w)[0] |             \\\n\t(((uint16_t)((w)[1])) << 8) |     \\\n\t(((uint32_t)((w)[2])) << 16) |    \\\n\t(((uint32_t)((w)[3])) << 24))\n\n#define UGETQW(w)           \\\n\t((w)[0] |             \\\n\t(((uint16_t)((w)[1])) << 8) |     \\\n\t(((uint32_t)((w)[2])) << 16) |    \\\n\t(((uint32_t)((w)[3])) << 24) |    \\\n\t(((uint64_t)((w)[4])) << 32) |    \\\n\t(((uint64_t)((w)[5])) << 40) |    \\\n\t(((uint64_t)((w)[6])) << 48) |    \\\n\t(((uint64_t)((w)[7])) << 56))\n\n#define USETW(w, v) do {         \\\n\t  (w)[0] = (uint8_t)(v);        \\\n\t  (w)[1] = (uint8_t)((v) >> 8);     \\\n} while (0)\n\n#define USETDW(w, v) do {        \\\n\t  (w)[0] = (uint8_t)(v);        \\\n\t  (w)[1] = (uint8_t)((v) >> 8);     \\\n\t  (w)[2] = (uint8_t)((v) >> 16);    \\\n\t  (w)[3] = (uint8_t)((v) >> 24);    \\\n} while (0)\n\n#define USETQW(w, v) do {        \\\n\t  (w)[0] = (uint8_t)(v);        \\\n\t  (w)[1] = (uint8_t)((v) >> 8);     \\\n\t  (w)[2] = (uint8_t)((v) >> 16);    \\\n\t  (w)[3] = (uint8_t)((v) >> 24);    \\\n\t  (w)[4] = (uint8_t)((v) >> 32);    \\\n\t  (w)[5] = (uint8_t)((v) >> 40);    \\\n\t  (w)[6] = (uint8_t)((v) >> 48);    \\\n\t  (w)[7] = (uint8_t)((v) >> 56);    \\\n} while (0)\n\n#define __packed       __attribute__((packed))\n\n#endif\n"], "fixing_code": ["/*-\n * Copyright (c) 2011 NetApp, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY NETAPP, INC ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL NETAPP, INC OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n *\n * $FreeBSD$\n */\n\n#include <errno.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <strings.h>\n#include <assert.h>\n#include <stdbool.h>\n\n#include \"dm.h\"\n#include \"vmmapi.h\"\n#include \"acpi.h\"\n#include \"inout.h\"\n#include \"ioapic.h\"\n#include \"mem.h\"\n#include \"pci_core.h\"\n#include \"irq.h\"\n#include \"lpc.h\"\n#include \"sw_load.h\"\n#include \"log.h\"\n\n#define CONF1_ADDR_PORT    0x0cf8\n#define CONF1_DATA_PORT    0x0cfc\n\n#define CONF1_ENABLE\t   0x80000000ul\n\n#define\tMAXBUSES\t(PCI_BUSMAX + 1)\n#define MAXSLOTS\t(PCI_SLOTMAX + 1)\n#define\tMAXFUNCS\t(PCI_FUNCMAX + 1)\n\nstruct funcinfo {\n\tchar\t*fi_name;\n\tchar\t*fi_param;\n\tchar\t*fi_param_saved; /* save for reboot */\n\tstruct pci_vdev *fi_devi;\n};\n\nstruct intxinfo {\n\tint\tii_count;\n\tint\tii_pirq_pin;\n\tint\tii_ioapic_irq;\n};\n\nstruct slotinfo {\n\tstruct intxinfo si_intpins[4];\n\tstruct funcinfo si_funcs[MAXFUNCS];\n};\n\nstruct businfo {\n\tuint16_t iobase, iolimit;\t\t/* I/O window */\n\tuint32_t membase32, memlimit32;\t\t/* mmio window below 4GB */\n\tuint64_t membase64, memlimit64;\t\t/* mmio window above 4GB */\n\tstruct slotinfo slotinfo[MAXSLOTS];\n};\n\nstatic struct businfo *pci_businfo[MAXBUSES];\n\nSET_DECLARE(pci_vdev_ops_set, struct pci_vdev_ops);\n\nstatic uint64_t pci_emul_iobase;\nstatic uint64_t pci_emul_membase32;\nstatic uint64_t pci_emul_membase64;\n\nextern bool skip_pci_mem64bar_workaround;\n\n#define\tPCI_EMUL_IOBASE\t\t0x2000\n#define\tPCI_EMUL_IOLIMIT\t0x10000\n\n#define\tPCI_EMUL_ECFG_SIZE\t(MAXBUSES * 1024 * 1024)    /* 1MB per bus */\nSYSRES_MEM(PCI_EMUL_ECFG_BASE, PCI_EMUL_ECFG_SIZE);\n\n#define\tPCI_EMUL_MEMLIMIT32\tPCI_EMUL_ECFG_BASE\n\nstatic struct pci_vdev_ops *pci_emul_finddev(char *name);\nstatic void pci_lintr_route(struct pci_vdev *dev);\nstatic void pci_lintr_update(struct pci_vdev *dev);\nstatic void pci_cfgrw(struct vmctx *ctx, int vcpu, int in, int bus, int slot,\n\t\t      int func, int coff, int bytes, uint32_t *val);\nstatic void pci_emul_free_msixcap(struct pci_vdev *pdi);\n\nstatic inline void\nCFGWRITE(struct pci_vdev *dev, int coff, uint32_t val, int bytes)\n{\n\tif (bytes == 1)\n\t\tpci_set_cfgdata8(dev, coff, val);\n\telse if (bytes == 2)\n\t\tpci_set_cfgdata16(dev, coff, val);\n\telse\n\t\tpci_set_cfgdata32(dev, coff, val);\n}\n\nstatic inline uint32_t\nCFGREAD(struct pci_vdev *dev, int coff, int bytes)\n{\n\tif (bytes == 1)\n\t\treturn pci_get_cfgdata8(dev, coff);\n\telse if (bytes == 2)\n\t\treturn pci_get_cfgdata16(dev, coff);\n\telse\n\t\treturn pci_get_cfgdata32(dev, coff);\n}\n\nstatic inline int\nis_pci_gvt(struct pci_vdev *dev)\n{\n\tif (dev == NULL || strncmp(dev->dev_ops->class_name, \"pci-gvt\",7))\n\t\treturn 0;\n\telse\n\t\treturn 1;\n}\n\n/*\n * I/O access\n */\n\n/*\n * Slot options are in the form:\n *\n *  <bus>:<slot>:<func>,<emul>[,<config>]\n *  <slot>[:<func>],<emul>[,<config>]\n *\n *  slot is 0..31\n *  func is 0..7\n *  emul is a string describing the type of PCI device e.g. virtio-net\n *  config is an optional string, depending on the device, that can be\n *  used for configuration.\n *   Examples are:\n *     1,virtio-net,tap0\n *     3:0,dummy\n */\nstatic void\npci_parse_slot_usage(char *aopt)\n{\n\tfprintf(stderr, \"Invalid PCI slot info field \\\"%s\\\"\\n\", aopt);\n}\n\nint\nparse_bdf(char *s, int *bus, int *dev, int *func, int base)\n{\n\tchar *s_bus, *s_dev, *s_func;\n\tchar *str, *cp;\n\tint ret = 0;\n\n\tstr = cp = strdup(s);\n\tbus ? *bus = 0 : 0;\n\tdev ? *dev = 0 : 0;\n\tfunc ? *func = 0 : 0;\n\ts_bus = s_dev = s_func = NULL;\n\ts_dev = strsep(&cp, \":/.\");\n\tif (cp) {\n\t\ts_func = strsep(&cp, \":/.\");\n\t\tif (cp) {\n\t\t\ts_bus = s_dev;\n\t\t\ts_dev = s_func;\n\t\t\ts_func = strsep(&cp, \":/.\");\n\t\t}\n\t}\n\n\tif (s_dev && dev)\n\t\tret |= dm_strtoi(s_dev, &s_dev, base, dev);\n\tif (s_func && func)\n\t\tret |= dm_strtoi(s_func, &s_func, base, func);\n\tif (s_bus && bus)\n\t\tret |= dm_strtoi(s_bus, &s_bus, base, bus);\n\tfree(str);\n\n\treturn ret;\n}\n\nint\npci_parse_slot(char *opt)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tchar *emul, *config, *str, *cp, *b = NULL;\n\tint error, bnum, snum, fnum;\n\n\terror = -1;\n\tstr = strdup(opt);\n\tif (!str) {\n\t\tfprintf(stderr, \"%s: strdup returns NULL\\n\", __func__);\n\t\treturn -1;\n\t}\n\n\temul = config = NULL;\n\tcp = str;\n\tstr = strsep(&cp, \",\");\n\tif (cp) {\n\t\temul = strsep(&cp, \",\");\n\t\t/* for boot device */\n\t\tif (cp && *cp == 'b' && *(cp+1) == ',')\n\t\t\tb = strsep(&cp, \",\");\n\t\tconfig = cp;\n\t} else {\n\t\tpci_parse_slot_usage(opt);\n\t\tgoto done;\n\t}\n\n\t/* <bus>:<slot>:<func> */\n\tif (parse_bdf(str, &bnum, &snum, &fnum, 10) != 0)\n\t\tsnum = -1;\n\n\tif (bnum < 0 || bnum >= MAXBUSES || snum < 0 || snum >= MAXSLOTS ||\n\t    fnum < 0 || fnum >= MAXFUNCS) {\n\t\tpci_parse_slot_usage(opt);\n\t\tgoto done;\n\t}\n\n\tif (pci_businfo[bnum] == NULL)\n\t\tpci_businfo[bnum] = calloc(1, sizeof(struct businfo));\n\n\tbi = pci_businfo[bnum];\n\tsi = &bi->slotinfo[snum];\n\n\tif (si->si_funcs[fnum].fi_name != NULL) {\n\t\tfprintf(stderr, \"pci slot %d:%d already occupied!\\n\",\n\t\t\tsnum, fnum);\n\t\tgoto done;\n\t}\n\n\tif (pci_emul_finddev(emul) == NULL) {\n\t\tfprintf(stderr, \"pci slot %d:%d: unknown device \\\"%s\\\"\\n\",\n\t\t\tsnum, fnum, emul);\n\t\tgoto done;\n\t}\n\n\terror = 0;\n\tsi->si_funcs[fnum].fi_name = emul;\n\t/* saved fi param in case reboot */\n\tsi->si_funcs[fnum].fi_param_saved = config;\n\n\tif (b != NULL) {\n\t\tif ((strcmp(\"virtio-blk\", emul) == 0) &&  (b != NULL) &&\n\t\t\t(strchr(b, 'b') != NULL)) {\n\t\t\tvsbl_set_bdf(bnum, snum, fnum);\n\t\t}\n\t}\ndone:\n\tif (error)\n\t\tfree(str);\n\n\treturn error;\n}\n\nstatic int\npci_valid_pba_offset(struct pci_vdev *dev, uint64_t offset)\n{\n\tif (offset < dev->msix.pba_offset)\n\t\treturn 0;\n\n\tif (offset >= dev->msix.pba_offset + dev->msix.pba_size)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nint\npci_emul_msix_twrite(struct pci_vdev *dev, uint64_t offset, int size,\n\t\t     uint64_t value)\n{\n\tint msix_entry_offset;\n\tint tab_index;\n\tchar *dest;\n\n\t/* support only 4 or 8 byte writes */\n\tif (size != 4 && size != 8)\n\t\treturn -1;\n\n\t/*\n\t * Return if table index is beyond what device supports\n\t */\n\ttab_index = offset / MSIX_TABLE_ENTRY_SIZE;\n\tif (tab_index >= dev->msix.table_count)\n\t\treturn -1;\n\n\tmsix_entry_offset = offset % MSIX_TABLE_ENTRY_SIZE;\n\n\t/* support only aligned writes */\n\tif ((msix_entry_offset % size) != 0)\n\t\treturn -1;\n\n\tdest = (char *)(dev->msix.table + tab_index);\n\tdest += msix_entry_offset;\n\n\tif (size == 4)\n\t\t*((uint32_t *)dest) = value;\n\telse\n\t\t*((uint64_t *)dest) = value;\n\n\treturn 0;\n}\n\nuint64_t\npci_emul_msix_tread(struct pci_vdev *dev, uint64_t offset, int size)\n{\n\tchar *dest;\n\tint msix_entry_offset;\n\tint tab_index;\n\tuint64_t retval = ~0;\n\n\t/*\n\t * The PCI standard only allows 4 and 8 byte accesses to the MSI-X\n\t * table but we also allow 1 byte access to accommodate reads from\n\t * ddb.\n\t */\n\tif (size != 1 && size != 4 && size != 8)\n\t\treturn retval;\n\n\tmsix_entry_offset = offset % MSIX_TABLE_ENTRY_SIZE;\n\n\t/* support only aligned reads */\n\tif ((msix_entry_offset % size) != 0)\n\t\treturn retval;\n\n\ttab_index = offset / MSIX_TABLE_ENTRY_SIZE;\n\n\tif (tab_index < dev->msix.table_count) {\n\t\t/* valid MSI-X Table access */\n\t\tdest = (char *)(dev->msix.table + tab_index);\n\t\tdest += msix_entry_offset;\n\n\t\tif (size == 1)\n\t\t\tretval = *((uint8_t *)dest);\n\t\telse if (size == 4)\n\t\t\tretval = *((uint32_t *)dest);\n\t\telse\n\t\t\tretval = *((uint64_t *)dest);\n\t} else if (pci_valid_pba_offset(dev, offset)) {\n\t\t/* return 0 for PBA access */\n\t\tretval = 0;\n\t}\n\n\treturn retval;\n}\n\nint\npci_msix_table_bar(struct pci_vdev *dev)\n{\n\tif (dev->msix.table != NULL)\n\t\treturn dev->msix.table_bar;\n\telse\n\t\treturn -1;\n}\n\nint\npci_msix_pba_bar(struct pci_vdev *dev)\n{\n\tif (dev->msix.table != NULL)\n\t\treturn dev->msix.pba_bar;\n\telse\n\t\treturn -1;\n}\n\nstatic inline uint64_t\nbar_value(int size, uint64_t val)\n{\n\tuint64_t mask;\n\n\tassert(size == 1 || size == 2 || size == 4 || size == 8);\n\tmask = (size < 8 ? 1UL << (size * 8) : 0UL) - 1;\n\n\treturn val & mask;\n}\n\nstatic int\npci_emul_io_handler(struct vmctx *ctx, int vcpu, int in, int port, int bytes,\n\t\t    uint32_t *eax, void *arg)\n{\n\tstruct pci_vdev *pdi = arg;\n\tstruct pci_vdev_ops *ops = pdi->dev_ops;\n\tuint64_t offset;\n\tint i;\n\n\tfor (i = 0; i <= PCI_BARMAX; i++) {\n\t\tif (pdi->bar[i].type == PCIBAR_IO &&\n\t\t    port >= pdi->bar[i].addr &&\n\t\t    port + bytes <= pdi->bar[i].addr + pdi->bar[i].size) {\n\t\t\toffset = port - pdi->bar[i].addr;\n\t\t\tif (in) {\n\t\t\t\t*eax = (*ops->vdev_barread)(ctx, vcpu, pdi, i,\n\t\t\t\t                            offset, bytes);\n\t\t\t\t*eax = bar_value(bytes, *eax);\n\t\t\t} else\n\t\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, i, offset,\n\t\t\t\t                      bytes, bar_value(bytes, *eax));\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn -1;\n}\n\nstatic int\npci_emul_mem_handler(struct vmctx *ctx, int vcpu, int dir, uint64_t addr,\n\t\t     int size, uint64_t *val, void *arg1, long arg2)\n{\n\tstruct pci_vdev *pdi = arg1;\n\tstruct pci_vdev_ops *ops = pdi->dev_ops;\n\tuint64_t offset;\n\tint bidx = (int) arg2;\n\n\tif (addr + size > pdi->bar[bidx].addr + pdi->bar[bidx].size) {\n\t\tpr_err(\"%s, Out of emulated memory range\\n\", __func__);\n\t\treturn -ESRCH;\n\t}\n\n\toffset = addr - pdi->bar[bidx].addr;\n\n\tif (dir == MEM_F_WRITE) {\n\t\tif (size == 8) {\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset,\n\t\t\t\t\t   4, *val & 0xffffffff);\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset + 4,\n\t\t\t\t\t   4, *val >> 32);\n\t\t} else {\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset,\n\t\t\t\t\t   size, bar_value(size, *val));\n\t\t}\n\t} else {\n\t\tif (size == 8) {\n\t\t\tuint64_t val_lo, val_hi;\n\n\t\t\tval_lo = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                              offset, 4);\n\t\t\tval_lo = bar_value(4, val_lo);\n\n\t\t\tval_hi = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                              offset + 4, 4);\n\n\t\t\t*val = val_lo | (val_hi << 32);\n\t\t} else {\n\t\t\t*val = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                            offset, size);\n\t\t\t*val = bar_value(size, *val);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n\nstatic int\npci_emul_alloc_resource(uint64_t *baseptr, uint64_t limit, uint64_t size,\n\t\t\tuint64_t *addr)\n{\n\tuint64_t base;\n\n\tif ((size & (size - 1)) != 0) {\t/* must be a power of 2 */\n\t\tpr_err(\"%s: Cannot alloc invalid size %lld resource\\n\", __func__, size);\n\t\treturn -1;\n\t}\n\n\tbase = roundup2(*baseptr, size);\n\n\tif (base + size <= limit) {\n\t\t*addr = base;\n\t\t*baseptr = base + size;\n\t\treturn 0;\n\t} else\n\t\treturn -1;\n}\n\nint\npci_emul_alloc_bar(struct pci_vdev *pdi, int idx, enum pcibar_type type,\n\t\t   uint64_t size)\n{\n\treturn pci_emul_alloc_pbar(pdi, idx, 0, type, size);\n}\n\n/*\n * Register (or unregister) the MMIO or I/O region associated with the BAR\n * register 'idx' of an emulated pci device.\n */\nstatic int\nmodify_bar_registration(struct pci_vdev *dev, int idx, int registration)\n{\n\tint error;\n\tstruct inout_port iop;\n\tstruct mem_range mr;\n\n\tif (is_pci_gvt(dev)) {\n\t\t/* GVT device is the only one who traps the pci bar access and\n\t\t * intercepts the corresponding contents in kernel. It needs\n\t\t * register pci resource only, but no need to register the\n\t\t * region.\n\t\t *\n\t\t * FIXME: This is a short term solution. This patch will be\n\t\t * obsoleted with the migration of using OVMF to do bar\n\t\t * addressing and generate ACPI PCI resource from using\n\t\t * acrn-dm.\n\t\t */\n\t\tprintf(\"modify_bar_registration: bypass for pci-gvt\\n\");\n\t\treturn 0;\n\t}\n\tswitch (dev->bar[idx].type) {\n\tcase PCIBAR_IO:\n\t\tbzero(&iop, sizeof(struct inout_port));\n\t\tiop.name = dev->name;\n\t\tiop.port = dev->bar[idx].addr;\n\t\tiop.size = dev->bar[idx].size;\n\t\tif (registration) {\n\t\t\tiop.flags = IOPORT_F_INOUT;\n\t\t\tiop.handler = pci_emul_io_handler;\n\t\t\tiop.arg = dev;\n\t\t\terror = register_inout(&iop);\n\t\t} else\n\t\t\terror = unregister_inout(&iop);\n\t\tbreak;\n\tcase PCIBAR_MEM32:\n\tcase PCIBAR_MEM64:\n\t\tbzero(&mr, sizeof(struct mem_range));\n\t\tmr.name = dev->name;\n\t\tmr.base = dev->bar[idx].addr;\n\t\tmr.size = dev->bar[idx].size;\n\t\tif (registration) {\n\t\t\tmr.flags = MEM_F_RW;\n\t\t\tmr.handler = pci_emul_mem_handler;\n\t\t\tmr.arg1 = dev;\n\t\t\tmr.arg2 = idx;\n\t\t\terror = register_mem(&mr);\n\t\t} else\n\t\t\terror = unregister_mem(&mr);\n\t\tbreak;\n\tdefault:\n\t\terror = EINVAL;\n\t\tbreak;\n\t}\n\n\treturn error;\n}\n\nstatic void\nunregister_bar(struct pci_vdev *dev, int idx)\n{\n\tmodify_bar_registration(dev, idx, 0);\n}\n\nstatic void\nregister_bar(struct pci_vdev *dev, int idx)\n{\n\tmodify_bar_registration(dev, idx, 1);\n}\n\n/* Are we decoding i/o port accesses for the emulated pci device? */\nstatic bool\nporten(struct pci_vdev *dev)\n{\n\tuint16_t cmd;\n\n\tcmd = pci_get_cfgdata16(dev, PCIR_COMMAND);\n\n\treturn (cmd & PCIM_CMD_PORTEN) != 0;\n}\n\n/* Are we decoding memory accesses for the emulated pci device? */\nstatic bool\nmemen(struct pci_vdev *dev)\n{\n\tuint16_t cmd;\n\n\tcmd = pci_get_cfgdata16(dev, PCIR_COMMAND);\n\n\treturn (cmd & PCIM_CMD_MEMEN) != 0;\n}\n\n/*\n * Update the MMIO or I/O address that is decoded by the BAR register.\n *\n * If the pci device has enabled the address space decoding then intercept\n * the address range decoded by the BAR register.\n */\nstatic void\nupdate_bar_address(struct vmctx *ctx, struct pci_vdev *dev, uint64_t addr,\n\tint idx, int type, bool ignore_reg_unreg)\n{\n\tbool decode = false;\n\tuint64_t orig_addr = dev->bar[idx].addr;\n\n\tif (!ignore_reg_unreg) {\n\t\tif (dev->bar[idx].type == PCIBAR_IO)\n\t\t\tdecode = porten(dev);\n\t\telse\n\t\t\tdecode = memen(dev);\n\t}\n\n\tif (decode)\n\t\tunregister_bar(dev, idx);\n\n\tswitch (type) {\n\tcase PCIBAR_IO:\n\tcase PCIBAR_MEM32:\n\t\tdev->bar[idx].addr = addr;\n\t\tbreak;\n\tcase PCIBAR_MEM64:\n\t\tdev->bar[idx].addr &= ~0xffffffffUL;\n\t\tdev->bar[idx].addr |= addr;\n\t\tbreak;\n\tcase PCIBAR_MEMHI64:\n\t\tdev->bar[idx].addr &= 0xffffffff;\n\t\tdev->bar[idx].addr |= addr;\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"%s: invalid bar type %d\\n\", __func__, type);\n\t\treturn;\n\t}\n\n\tif (decode)\n\t\tregister_bar(dev, idx);\n\n\t/* update bar mapping */\n\tif (dev->dev_ops->vdev_update_bar_map && decode)\n\t\tdev->dev_ops->vdev_update_bar_map(ctx, dev, idx, orig_addr);\n}\n\nint\npci_emul_alloc_pbar(struct pci_vdev *pdi, int idx, uint64_t hostbase,\n\t\t    enum pcibar_type type, uint64_t size)\n{\n\tint error;\n\tuint64_t *baseptr, limit, addr, mask, lobits, bar;\n\n\tif ((size & (size - 1)) != 0)\n\t\tsize = 1UL << flsl(size);\t/* round up to a power of 2 */\n\n\t/* Enforce minimum BAR sizes required by the PCI standard */\n\tif (type == PCIBAR_IO) {\n\t\tif (size < 4)\n\t\t\tsize = 4;\n\t} else {\n\t\tif (size < 16)\n\t\t\tsize = 16;\n\t}\n\n\tswitch (type) {\n\tcase PCIBAR_NONE:\n\t\tbaseptr = NULL;\n\t\taddr = mask = lobits = 0;\n\t\tbreak;\n\tcase PCIBAR_IO:\n\t\tbaseptr = &pci_emul_iobase;\n\t\tlimit = PCI_EMUL_IOLIMIT;\n\t\tmask = PCIM_BAR_IO_BASE;\n\t\tlobits = PCIM_BAR_IO_SPACE;\n\t\tbreak;\n\tcase PCIBAR_MEM64:\n\t\tif (idx + 1 > PCI_BARMAX) {\n\t\t\tpr_err(\"%s: invalid bar number %d for MEM64 type\\n\", __func__, idx);\n\t\t\treturn -1;\n\t\t}\n\t\t/*\n\t\t * FIXME\n\t\t * Some drivers do not work well if the 64-bit BAR is allocated\n\t\t * above 4GB. Allow for this by allocating small requests under\n\t\t * 4GB unless then allocation size is larger than some arbitrary\n\t\t * number (32MB currently). If guest booted by ovmf, then skip the\n\t\t * workaround.\n\t\t */\n\t\tif (!skip_pci_mem64bar_workaround && (size <= 32 * 1024 * 1024)) {\n\t\t\tbaseptr = &pci_emul_membase32;\n\t\t\tlimit = PCI_EMUL_MEMLIMIT32;\n\t\t\tmask = PCIM_BAR_MEM_BASE;\n\t\t\tlobits = PCIM_BAR_MEM_SPACE | PCIM_BAR_MEM_64;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * XXX special case for device requiring peer-peer DMA\n\t\t */\n\t\tif (size == 0x100000000UL)\n\t\t\tbaseptr = &hostbase;\n\t\telse\n\t\t\tbaseptr = &pci_emul_membase64;\n\t\tlimit = PCI_EMUL_MEMLIMIT64;\n\t\tmask = PCIM_BAR_MEM_BASE;\n\t\tlobits = PCIM_BAR_MEM_SPACE | PCIM_BAR_MEM_64 |\n\t\t\tPCIM_BAR_MEM_PREFETCH;\n\t\tbreak;\n\tcase PCIBAR_MEM32:\n\t\tbaseptr = &pci_emul_membase32;\n\t\tlimit = PCI_EMUL_MEMLIMIT32;\n\t\tmask = PCIM_BAR_MEM_BASE;\n\t\tlobits = PCIM_BAR_MEM_SPACE | PCIM_BAR_MEM_32;\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"%s: invalid bar type %d\\n\", __func__, type);\n\t\treturn -1;\n\t}\n\n\tif (baseptr != NULL) {\n\t\terror = pci_emul_alloc_resource(baseptr, limit, size, &addr);\n\t\tif (error != 0)\n\t\t\treturn error;\n\t}\n\n\tpdi->bar[idx].type = type;\n\tpdi->bar[idx].addr = addr;\n\tpdi->bar[idx].size = size;\n\n\t/* Initialize the BAR register in config space */\n\tbar = (addr & mask) | lobits;\n\tpci_set_cfgdata32(pdi, PCIR_BAR(idx), bar);\n\n\tif (type == PCIBAR_MEM64) {\n\t\tpdi->bar[idx + 1].type = PCIBAR_MEMHI64;\n\t\tpci_set_cfgdata32(pdi, PCIR_BAR(idx + 1), bar >> 32);\n\t}\n\n\tregister_bar(pdi, idx);\n\n\treturn 0;\n}\n\nvoid\npci_emul_free_bars(struct pci_vdev *pdi)\n{\n\tint i;\n\tbool enabled;\n\n\tfor (i = 0; i < PCI_BARMAX; i++) {\n\t\tif ((pdi->bar[i].type != PCIBAR_NONE) &&\n\t\t\t(pdi->bar[i].type != PCIBAR_MEMHI64)){\n\t\t\t/*\n\t\t\t * Check whether the bar is enabled or not,\n\t\t\t * if it is disabled then it should have been\n\t\t\t * unregistered in pci_emul_cmdsts_write.\n\t\t\t */\n\t\t\tif (pdi->bar[i].type == PCIBAR_IO)\n\t\t\t\tenabled = porten(pdi);\n\t\t\telse\n\t\t\t\tenabled = memen(pdi);\n\n\t\t\tif (enabled)\n\t\t\t\tunregister_bar(pdi, i);\n\t\t\tpdi->bar[i].type = PCIBAR_NONE;\n\t\t}\n\t}\n}\n\n#define\tCAP_START_OFFSET\t0x40\nint\npci_emul_add_capability(struct pci_vdev *dev, u_char *capdata, int caplen)\n{\n\tint i, capoff, reallen;\n\tuint16_t sts;\n\n\treallen = roundup2(caplen, 4);\t\t/* dword aligned */\n\n\tsts = pci_get_cfgdata16(dev, PCIR_STATUS);\n\tif ((sts & PCIM_STATUS_CAPPRESENT) == 0)\n\t\tcapoff = CAP_START_OFFSET;\n\telse\n\t\tcapoff = dev->capend + 1;\n\n\t/* Check if we have enough space */\n\tif (capoff + reallen > PCI_REGMAX + 1)\n\t\treturn -1;\n\n\t/* Set the previous capability pointer */\n\tif ((sts & PCIM_STATUS_CAPPRESENT) == 0) {\n\t\tpci_set_cfgdata8(dev, PCIR_CAP_PTR, capoff);\n\t\tpci_set_cfgdata16(dev, PCIR_STATUS, sts|PCIM_STATUS_CAPPRESENT);\n\t} else\n\t\tpci_set_cfgdata8(dev, dev->prevcap + 1, capoff);\n\n\t/* Copy the capability */\n\tfor (i = 0; i < caplen; i++)\n\t\tpci_set_cfgdata8(dev, capoff + i, capdata[i]);\n\n\t/* Set the next capability pointer */\n\tpci_set_cfgdata8(dev, capoff + 1, 0);\n\n\tdev->prevcap = capoff;\n\tdev->capend = capoff + reallen - 1;\n\treturn 0;\n}\n\n/*\n * p_capoff is used as both input and output. Set *p_capoff to 0 when this\n * function is called for the first time, it will return offset of the first\n * matched one in p_capoff. To find the next matched one, please use the\n * returned *p_capoff from last call as the input, in this case the offset of\n * the next matched one will be returned in *p_capoff.\n * Please check the returned value first before touch p_capoff.\n */\nint\npci_emul_find_capability(struct pci_vdev *dev, uint8_t capid, int *p_capoff)\n{\n\tint coff;\n\tuint16_t sts;\n\n\tsts = pci_get_cfgdata16(dev, PCIR_STATUS);\n\tif ((sts & PCIM_STATUS_CAPPRESENT) == 0)\n\t\treturn -1;\n\n\tif (!p_capoff)\n\t\treturn -1;\n\n\tif (*p_capoff == 0)\n\t\tcoff = pci_get_cfgdata8(dev, PCIR_CAP_PTR);\n\telse if (*p_capoff >= CAP_START_OFFSET && *p_capoff <= dev->prevcap)\n\t\tcoff = pci_get_cfgdata8(dev, *p_capoff + 1);\n\telse\n\t\treturn -1;\n\n\twhile (coff >= CAP_START_OFFSET && coff <= dev->prevcap) {\n\t\tif (pci_get_cfgdata8(dev, coff) == capid) {\n\t\t\t*p_capoff = coff;\n\t\t\treturn 0;\n\t\t}\n\t\tcoff = pci_get_cfgdata8(dev, coff + 1);\n\t}\n\n\treturn -1;\n}\n\nstatic struct pci_vdev_ops *\npci_emul_finddev(char *name)\n{\n\tstruct pci_vdev_ops **pdpp, *pdp;\n\n\tSET_FOREACH(pdpp, pci_vdev_ops_set) {\n\t\tpdp = *pdpp;\n\t\tif (!strcmp(pdp->class_name, name))\n\t\t\treturn pdp;\n\t}\n\n\treturn NULL;\n}\n\nstatic int\npci_emul_init(struct vmctx *ctx, struct pci_vdev_ops *ops, int bus, int slot,\n\t      int func, struct funcinfo *fi)\n{\n\tstruct pci_vdev *pdi;\n\tint err;\n\n\tpdi = calloc(1, sizeof(struct pci_vdev));\n\tif (!pdi) {\n\t\tfprintf(stderr, \"%s: calloc returns NULL\\n\", __func__);\n\t\treturn -1;\n\t}\n\n\tpdi->vmctx = ctx;\n\tpdi->bus = bus;\n\tpdi->slot = slot;\n\tpdi->func = func;\n\tpthread_mutex_init(&pdi->lintr.lock, NULL);\n\tpdi->lintr.pin = 0;\n\tpdi->lintr.state = IDLE;\n\tpdi->lintr.pirq_pin = 0;\n\tpdi->lintr.ioapic_irq = 0;\n\tpdi->dev_ops = ops;\n\tsnprintf(pdi->name, PI_NAMESZ, \"%s-pci-%d\", ops->class_name, slot);\n\n\t/* Disable legacy interrupts */\n\tpci_set_cfgdata8(pdi, PCIR_INTLINE, 255);\n\tpci_set_cfgdata8(pdi, PCIR_INTPIN, 0);\n\n\tpci_set_cfgdata8(pdi, PCIR_COMMAND,\n\t\t    PCIM_CMD_PORTEN | PCIM_CMD_MEMEN | PCIM_CMD_BUSMASTEREN);\n\n\tif (fi->fi_param_saved)\n\t\tfi->fi_param = strdup(fi->fi_param_saved);\n\telse\n\t\tfi->fi_param = NULL;\n\terr = (*ops->vdev_init)(ctx, pdi, fi->fi_param);\n\tif (err == 0)\n\t\tfi->fi_devi = pdi;\n\telse\n\t\tfree(pdi);\n\n\treturn err;\n}\n\nstatic void\npci_emul_deinit(struct vmctx *ctx, struct pci_vdev_ops *ops, int bus, int slot,\n\t\tint func, struct funcinfo *fi)\n{\n\tif (ops->vdev_deinit && fi->fi_devi)\n\t\t(*ops->vdev_deinit)(ctx, fi->fi_devi, fi->fi_param);\n\tif (fi->fi_param)\n\t\tfree(fi->fi_param);\n\n\tif (fi->fi_devi) {\n\t\tpci_lintr_release(fi->fi_devi);\n\t\tpci_emul_free_bars(fi->fi_devi);\n\t\tpci_emul_free_msixcap(fi->fi_devi);\n\t\tfree(fi->fi_devi);\n\t}\n}\n\nint\npci_populate_msicap(struct msicap *msicap, int msgnum, int nextptr)\n{\n\tint mmc;\n\n\t/* Number of msi messages must be a power of 2 between 1 and 32 */\n\tif (((msgnum & (msgnum - 1)) != 0) || msgnum < 1 || msgnum > 32) {\n\t\tpr_err(\"%s: invalid number of msi messages!\\n\", __func__);\n\t\treturn -1;\n\t}\n\tmmc = ffs(msgnum) - 1;\n\n\tbzero(msicap, sizeof(struct msicap));\n\tmsicap->capid = PCIY_MSI;\n\tmsicap->nextptr = nextptr;\n\tmsicap->msgctrl = PCIM_MSICTRL_64BIT | (mmc << 1);\n\n\treturn 0;\n}\n\nint\npci_emul_add_msicap(struct pci_vdev *dev, int msgnum)\n{\n\tstruct msicap msicap;\n\n\treturn pci_populate_msicap(&msicap, msgnum, 0) ||\n\t\tpci_emul_add_capability(dev, (u_char *)&msicap, sizeof(msicap));\n}\n\nstatic void\npci_populate_msixcap(struct msixcap *msixcap, int msgnum, int barnum,\n\t\t     uint32_t msix_tab_size)\n{\n\n\tbzero(msixcap, sizeof(struct msixcap));\n\tmsixcap->capid = PCIY_MSIX;\n\n\t/*\n\t * Message Control Register, all fields set to\n\t * zero except for the Table Size.\n\t * Note: Table size N is encoded as N-1\n\t */\n\tmsixcap->msgctrl = msgnum - 1;\n\n\t/*\n\t * MSI-X BAR setup:\n\t * - MSI-X table start at offset 0\n\t * - PBA table starts at a 4K aligned offset after the MSI-X table\n\t */\n\tmsixcap->table_info = barnum & PCIM_MSIX_BIR_MASK;\n\tmsixcap->pba_info = msix_tab_size | (barnum & PCIM_MSIX_BIR_MASK);\n}\n\nstatic int\npci_msix_table_init(struct pci_vdev *dev, int table_entries)\n{\n\tint i, table_size;\n\n\ttable_size = table_entries * MSIX_TABLE_ENTRY_SIZE;\n\tdev->msix.table = calloc(1, table_size);\n\tif (!dev->msix.table) {\n\t\tpr_err(\"%s: Cannot alloc memory!\\n\", __func__);\n\t\treturn -1;\n\t}\n\n\t/* set mask bit of vector control register */\n\tfor (i = 0; i < table_entries; i++)\n\t\tdev->msix.table[i].vector_control |= PCIM_MSIX_VCTRL_MASK;\n\n\treturn 0;\n}\n\nint\npci_emul_add_msixcap(struct pci_vdev *dev, int msgnum, int barnum)\n{\n\tuint32_t tab_size;\n\tstruct msixcap msixcap;\n\n\tif (msgnum > MAX_MSIX_TABLE_ENTRIES) {\n\t\tpr_err(\"%s: Too many entries!\\n\", __func__);\n\t\treturn -1;\n\t}\n\n\ttab_size = msgnum * MSIX_TABLE_ENTRY_SIZE;\n\n\t/* Align table size to nearest 4K */\n\ttab_size = roundup2(tab_size, 4096);\n\n\tdev->msix.table_bar = barnum;\n\tdev->msix.pba_bar   = barnum;\n\tdev->msix.table_offset = 0;\n\tdev->msix.table_count = msgnum;\n\tdev->msix.pba_offset = tab_size;\n\tdev->msix.pba_size = PBA_SIZE(msgnum);\n\n\tif (pci_msix_table_init(dev, msgnum) != 0)\n\t\treturn -1;\n\n\tpci_populate_msixcap(&msixcap, msgnum, barnum, tab_size);\n\n\t/* allocate memory for MSI-X Table and PBA */\n\tpci_emul_alloc_bar(dev, barnum, PCIBAR_MEM32,\n\t\t\t\ttab_size + dev->msix.pba_size);\n\n\treturn (pci_emul_add_capability(dev, (u_char *)&msixcap,\n\t\t\t\t\tsizeof(msixcap)));\n}\n\nstatic void\npci_emul_free_msixcap(struct pci_vdev *pdi)\n{\n\tif (pdi->msix.table) {\n\t\tfree(pdi->msix.table);\n\t\tpdi->msix.table = NULL;\n\t}\n}\n\n\nvoid\nmsixcap_cfgwrite(struct pci_vdev *dev, int capoff, int offset,\n\t\t int bytes, uint32_t val)\n{\n\tuint16_t msgctrl, rwmask;\n\tint off;\n\n\toff = offset - capoff;\n\t/* Message Control Register */\n\tif (off == 2 && bytes == 2) {\n\t\trwmask = PCIM_MSIXCTRL_MSIX_ENABLE |\n\t\t\tPCIM_MSIXCTRL_FUNCTION_MASK;\n\t\tmsgctrl = pci_get_cfgdata16(dev, offset);\n\t\tmsgctrl &= ~rwmask;\n\t\tmsgctrl |= val & rwmask;\n\t\tval = msgctrl;\n\n\t\tdev->msix.enabled = val & PCIM_MSIXCTRL_MSIX_ENABLE;\n\t\tdev->msix.function_mask = val & PCIM_MSIXCTRL_FUNCTION_MASK;\n\t\tpci_lintr_update(dev);\n\t}\n\n\tCFGWRITE(dev, offset, val, bytes);\n}\n\nvoid\nmsicap_cfgwrite(struct pci_vdev *dev, int capoff, int offset,\n\t\tint bytes, uint32_t val)\n{\n\tuint16_t msgctrl, rwmask, msgdata, mme;\n\tuint32_t addrlo;\n\n\t/*\n\t * If guest is writing to the message control register make sure\n\t * we do not overwrite read-only fields.\n\t */\n\tif ((offset - capoff) == 2 && bytes == 2) {\n\t\trwmask = PCIM_MSICTRL_MME_MASK | PCIM_MSICTRL_MSI_ENABLE;\n\t\tmsgctrl = pci_get_cfgdata16(dev, offset);\n\t\tmsgctrl &= ~rwmask;\n\t\tmsgctrl |= val & rwmask;\n\t\tval = msgctrl;\n\n\t\taddrlo = pci_get_cfgdata32(dev, capoff + 4);\n\t\tif (msgctrl & PCIM_MSICTRL_64BIT)\n\t\t\tmsgdata = pci_get_cfgdata16(dev, capoff + 12);\n\t\telse\n\t\t\tmsgdata = pci_get_cfgdata16(dev, capoff + 8);\n\n\t\tmme = msgctrl & PCIM_MSICTRL_MME_MASK;\n\t\tdev->msi.enabled = msgctrl & PCIM_MSICTRL_MSI_ENABLE ? 1 : 0;\n\t\tif (dev->msi.enabled) {\n\t\t\tdev->msi.addr = addrlo;\n\t\t\tdev->msi.msg_data = msgdata;\n\t\t\tdev->msi.maxmsgnum = 1 << (mme >> 4);\n\t\t} else {\n\t\t\tdev->msi.maxmsgnum = 0;\n\t\t}\n\t\tpci_lintr_update(dev);\n\t}\n\n\tCFGWRITE(dev, offset, val, bytes);\n}\n\nvoid\npciecap_cfgwrite(struct pci_vdev *dev, int capoff, int offset,\n\t\t int bytes, uint32_t val)\n{\n\t/* XXX don't write to the readonly parts */\n\tCFGWRITE(dev, offset, val, bytes);\n}\n\n#define\tPCIECAP_VERSION\t0x2\nint\npci_emul_add_pciecap(struct pci_vdev *dev, int type)\n{\n\tint err;\n\tstruct pciecap pciecap;\n\n\tif (type != PCIEM_TYPE_ROOT_PORT)\n\t\treturn -1;\n\n\tbzero(&pciecap, sizeof(pciecap));\n\n\tpciecap.capid = PCIY_EXPRESS;\n\tpciecap.pcie_capabilities = PCIECAP_VERSION | PCIEM_TYPE_ROOT_PORT;\n\tpciecap.link_capabilities = 0x411;\t/* gen1, x1 */\n\tpciecap.link_status = 0x11;\t\t/* gen1, x1 */\n\n\terr = pci_emul_add_capability(dev, (u_char *)&pciecap, sizeof(pciecap));\n\treturn err;\n}\n\n/*\n * This function assumes that 'coff' is in the capabilities region of the\n * config space.\n */\nstatic void\npci_emul_capwrite(struct pci_vdev *dev, int offset, int bytes, uint32_t val)\n{\n\tint capid;\n\tuint8_t capoff, nextoff;\n\n\t/* Do not allow un-aligned writes */\n\tif ((offset & (bytes - 1)) != 0)\n\t\treturn;\n\n\t/* Find the capability that we want to update */\n\tcapoff = CAP_START_OFFSET;\n\twhile (1) {\n\t\tnextoff = pci_get_cfgdata8(dev, capoff + 1);\n\t\tif (nextoff == 0)\n\t\t\tbreak;\n\t\tif (offset >= capoff && offset < nextoff)\n\t\t\tbreak;\n\n\t\tcapoff = nextoff;\n\t}\n\n\t/*\n\t * Capability ID and Next Capability Pointer are readonly.\n\t * However, some o/s's do 4-byte writes that include these.\n\t * For this case, trim the write back to 2 bytes and adjust\n\t * the data.\n\t */\n\tif (offset == capoff || offset == capoff + 1) {\n\t\tif (offset == capoff && bytes == 4) {\n\t\t\tbytes = 2;\n\t\t\toffset += 2;\n\t\t\tval >>= 16;\n\t\t} else\n\t\t\treturn;\n\t}\n\n\tcapid = pci_get_cfgdata8(dev, capoff);\n\tswitch (capid) {\n\tcase PCIY_MSI:\n\t\tmsicap_cfgwrite(dev, capoff, offset, bytes, val);\n\t\tbreak;\n\tcase PCIY_MSIX:\n\t\tmsixcap_cfgwrite(dev, capoff, offset, bytes, val);\n\t\tbreak;\n\tcase PCIY_EXPRESS:\n\t\tpciecap_cfgwrite(dev, capoff, offset, bytes, val);\n\t\tbreak;\n\tdefault:\n\t\tCFGWRITE(dev, offset, val, bytes);\n\t\tbreak;\n\t}\n}\n\nstatic int\npci_emul_iscap(struct pci_vdev *dev, int offset)\n{\n\tuint16_t sts;\n\n\tsts = pci_get_cfgdata16(dev, PCIR_STATUS);\n\tif ((sts & PCIM_STATUS_CAPPRESENT) != 0) {\n\t\tif (offset >= CAP_START_OFFSET && offset <= dev->capend)\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic int\npci_emul_fallback_handler(struct vmctx *ctx, int vcpu, int dir, uint64_t addr,\n\t\t\t  int size, uint64_t *val, void *arg1, long arg2)\n{\n\t/*\n\t * Ignore writes; return 0xff's for reads. The mem read code\n\t * will take care of truncating to the correct size.\n\t */\n\tif (dir == MEM_F_READ)\n\t\t*val = 0xffffffffffffffff;\n\n\treturn 0;\n}\n\nstatic int\npci_emul_ecfg_handler(struct vmctx *ctx, int vcpu, int dir, uint64_t addr,\n\t\t      int bytes, uint64_t *val, void *arg1, long arg2)\n{\n\tint bus, slot, func, coff, in;\n\n\tcoff = addr & 0xfff;\n\tfunc = (addr >> 12) & 0x7;\n\tslot = (addr >> 15) & 0x1f;\n\tbus = (addr >> 20) & 0xff;\n\tin = (dir == MEM_F_READ);\n\tif (in)\n\t\t*val = ~0UL;\n\tpci_cfgrw(ctx, vcpu, in, bus, slot, func, coff, bytes, (uint32_t *)val);\n\treturn 0;\n}\n\n#define\tBUSIO_ROUNDUP\t\t32\n#define\tBUSMEM_ROUNDUP\t\t(1024 * 1024)\n\nint\ninit_pci(struct vmctx *ctx)\n{\n\tstruct mem_range mr;\n\tstruct pci_vdev_ops *ops;\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct funcinfo *fi;\n\tsize_t lowmem;\n\tint bus, slot, func;\n\tint success_cnt = 0;\n\tint error;\n\n\tpci_emul_iobase = PCI_EMUL_IOBASE;\n\tpci_emul_membase32 = vm_get_lowmem_limit(ctx);\n\tpci_emul_membase64 = PCI_EMUL_MEMBASE64;\n\n\tcreate_gsi_sharing_groups();\n\n\tfor (bus = 0; bus < MAXBUSES; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\t\t/*\n\t\t * Keep track of the i/o and memory resources allocated to\n\t\t * this bus.\n\t\t */\n\t\tbi->iobase = pci_emul_iobase;\n\t\tbi->membase32 = pci_emul_membase32;\n\t\tbi->membase64 = pci_emul_membase64;\n\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_name == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tops = pci_emul_finddev(fi->fi_name);\n\t\t\t\tif (!ops) {\n\t\t\t\t\tpr_warn(\"No driver for device [%s]\\n\", fi->fi_name);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tpr_notice(\"pci init %s\\r\\n\", fi->fi_name);\n\t\t\t\terror = pci_emul_init(ctx, ops, bus, slot,\n\t\t\t\t    func, fi);\n\t\t\t\tif (error) {\n\t\t\t\t\tpr_err(\"pci %s init failed\\n\", fi->fi_name);\n\t\t\t\t\tgoto pci_emul_init_fail;\n\t\t\t\t}\n\t\t\t\tsuccess_cnt++;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Add some slop to the I/O and memory resources decoded by\n\t\t * this bus to give a guest some flexibility if it wants to\n\t\t * reprogram the BARs.\n\t\t */\n\t\tpci_emul_iobase += BUSIO_ROUNDUP;\n\t\tpci_emul_iobase = roundup2(pci_emul_iobase, BUSIO_ROUNDUP);\n\t\tbi->iolimit = pci_emul_iobase;\n\n\t\tpci_emul_membase32 += BUSMEM_ROUNDUP;\n\t\tpci_emul_membase32 = roundup2(pci_emul_membase32,\n\t\t    BUSMEM_ROUNDUP);\n\t\tbi->memlimit32 = pci_emul_membase32;\n\n\t\tpci_emul_membase64 += BUSMEM_ROUNDUP;\n\t\tpci_emul_membase64 = roundup2(pci_emul_membase64,\n\t\t    BUSMEM_ROUNDUP);\n\t\tbi->memlimit64 = pci_emul_membase64;\n\t}\n\n\terror = check_gsi_sharing_violation();\n\tif (error < 0)\n\t\tgoto pci_emul_init_fail;\n\n\t/*\n\t * PCI backends are initialized before routing INTx interrupts\n\t * so that LPC devices are able to reserve ISA IRQs before\n\t * routing PIRQ pins.\n\t */\n\tfor (bus = 0; bus < MAXBUSES; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_devi == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tpci_lintr_route(fi->fi_devi);\n\t\t\t\tops = fi->fi_devi->dev_ops;\n\t\t\t\tif (ops && ops->vdev_phys_access)\n\t\t\t\t\tops->vdev_phys_access(ctx,\n\t\t\t\t\t\tfi->fi_devi);\n\t\t\t}\n\t\t}\n\t}\n\tlpc_pirq_routed();\n\n\t/*\n\t * The guest physical memory map looks like the following:\n\t * [0,              lowmem)         guest system memory\n\t * [lowmem,         lowmem_limit)   memory hole (may be absent)\n\t * [lowmem_limit,   0xE0000000)     PCI hole (32-bit BAR allocation)\n\t * [0xE0000000,     0xF0000000)     PCI extended config window\n\t * [0xF0000000,     4GB)            LAPIC, IOAPIC, HPET, firmware\n\t * [4GB,            5GB)            PCI hole (64-bit BAR allocation)\n\t * [5GB,            5GB + highmem)  guest system memory\n\t */\n\n\t/*\n\t * Accesses to memory addresses that are not allocated to system\n\t * memory or PCI devices return 0xff's.\n\t */\n\tlowmem = vm_get_lowmem_size(ctx);\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (32-bit)\";\n\tmr.flags = MEM_F_RW;\n\tmr.base = lowmem;\n\tmr.size = (4ULL * 1024 * 1024 * 1024) - lowmem;\n\tmr.handler = pci_emul_fallback_handler;\n\terror = register_mem_fallback(&mr);\n\tif (error != 0)\n\t\tgoto pci_emul_init_fail;\n\n\t/* ditto for the 64-bit PCI host aperture */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (64-bit)\";\n\tmr.flags = MEM_F_RW;\n\tmr.base = PCI_EMUL_MEMBASE64;\n\tmr.size = PCI_EMUL_MEMLIMIT64 - PCI_EMUL_MEMBASE64;\n\tmr.handler = pci_emul_fallback_handler;\n\terror = register_mem_fallback(&mr);\n\tif (error != 0)\n\t\tgoto pci_emul_init_fail;\n\n\t/* PCI extended config space */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI ECFG\";\n\tmr.flags = MEM_F_RW;\n\tmr.base = PCI_EMUL_ECFG_BASE;\n\tmr.size = PCI_EMUL_ECFG_SIZE;\n\tmr.handler = pci_emul_ecfg_handler;\n\terror = register_mem(&mr);\n\tif (error != 0)\n\t\tgoto pci_emul_init_fail;\n\n\treturn 0;\n\npci_emul_init_fail:\n\tfor (bus = 0; bus < MAXBUSES && success_cnt > 0; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\t\tfor (slot = 0; slot < MAXSLOTS && success_cnt > 0; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_name == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (success_cnt-- <= 0)\n\t\t\t\t\tbreak;\n\t\t\t\tops = pci_emul_finddev(fi->fi_name);\n\t\t\t\tif (!ops) {\n\t\t\t\t\tpr_warn(\"No driver for device [%s]\\n\", fi->fi_name);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tpci_emul_deinit(ctx, ops, bus, slot,\n\t\t\t\t    func, fi);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn error;\n}\n\nvoid\ndeinit_pci(struct vmctx *ctx)\n{\n\tstruct pci_vdev_ops *ops;\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct funcinfo *fi;\n\tint bus, slot, func;\n\tsize_t lowmem;\n\tstruct mem_range mr;\n\n\t/* Release PCI extended config space */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI ECFG\";\n\tmr.base = PCI_EMUL_ECFG_BASE;\n\tmr.size = PCI_EMUL_ECFG_SIZE;\n\tunregister_mem(&mr);\n\n\t/* Release PCI hole space */\n\tlowmem = vm_get_lowmem_size(ctx);\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (32-bit)\";\n\tmr.base = lowmem;\n\tmr.size = (4ULL * 1024 * 1024 * 1024) - lowmem;\n\tunregister_mem_fallback(&mr);\n\n\t/* ditto for the 64-bit PCI host aperture */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (64-bit)\";\n\tmr.base = PCI_EMUL_MEMBASE64;\n\tmr.size = PCI_EMUL_MEMLIMIT64 - PCI_EMUL_MEMBASE64;\n\tunregister_mem_fallback(&mr);\n\n\tfor (bus = 0; bus < MAXBUSES; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_name == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tops = pci_emul_finddev(fi->fi_name);\n\t\t\t\tif (!ops) {\n\t\t\t\t\tpr_warn(\"No driver for device [%s]\\n\", fi->fi_name);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tpr_notice(\"pci deinit %s\\n\", fi->fi_name);\n\t\t\t\tpci_emul_deinit(ctx, ops, bus, slot,\n\t\t\t\t    func, fi);\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void\npci_apic_prt_entry(int bus, int slot, int pin, int pirq_pin, int ioapic_irq,\n\t\t   void *arg)\n{\n\tdsdt_line(\"  Package ()\");\n\tdsdt_line(\"  {\");\n\tdsdt_line(\"    0x%X,\", slot << 16 | 0xffff);\n\tdsdt_line(\"    0x%02X,\", pin - 1);\n\tdsdt_line(\"    Zero,\");\n\tdsdt_line(\"    0x%X\", ioapic_irq);\n\tdsdt_line(\"  },\");\n}\n\nstatic void\npci_pirq_prt_entry(int bus, int slot, int pin, int pirq_pin, int ioapic_irq,\n\t\t   void *arg)\n{\n\tchar *name;\n\n\tname = lpc_pirq_name(pirq_pin);\n\tif (name == NULL)\n\t\treturn;\n\tdsdt_line(\"  Package ()\");\n\tdsdt_line(\"  {\");\n\tdsdt_line(\"    0x%X,\", slot << 16 | 0xffff);\n\tdsdt_line(\"    0x%02X,\", pin - 1);\n\tdsdt_line(\"    %s,\", name);\n\tdsdt_line(\"    0x00\");\n\tdsdt_line(\"  },\");\n\tfree(name);\n}\n\n/*\n * A acrn-dm virtual machine has a flat PCI hierarchy with a root port\n * corresponding to each PCI bus.\n */\nstatic void\npci_bus_write_dsdt(int bus)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct pci_vdev *dev;\n\tint count, func, slot;\n\n\t/*\n\t * If there are no devices on this 'bus' then just return.\n\t */\n\t bi = pci_businfo[bus];\n\tif (bi == NULL) {\n\t\t/*\n\t\t * Bus 0 is special because it decodes the I/O ports used\n\t\t * for PCI config space access even if there are no devices\n\t\t * on it.\n\t\t */\n\t\tif (bus != 0)\n\t\t\treturn;\n\t}\n\n\tdsdt_line(\"  Device (PCI%01X)\", bus);\n\tdsdt_line(\"  {\");\n\tdsdt_line(\"    Name (_HID, EisaId (\\\"PNP0A03\\\"))\");\n\tdsdt_line(\"    Name (_ADR, Zero)\");\n\n\tdsdt_line(\"    Method (_BBN, 0, NotSerialized)\");\n\tdsdt_line(\"    {\");\n\tdsdt_line(\"        Return (0x%08X)\", bus);\n\tdsdt_line(\"    }\");\n\tdsdt_line(\"    Name (_CRS, ResourceTemplate ()\");\n\tdsdt_line(\"    {\");\n\tdsdt_line(\"      WordBusNumber (ResourceProducer, MinFixed, \"\n\t    \"MaxFixed, PosDecode,\");\n\tdsdt_line(\"        0x0000,             // Granularity\");\n\tdsdt_line(\"        0x%04X,             // Range Minimum\", bus);\n\tdsdt_line(\"        0x%04X,             // Range Maximum\", bus);\n\tdsdt_line(\"        0x0000,             // Translation Offset\");\n\tdsdt_line(\"        0x0001,             // Length\");\n\tdsdt_line(\"        ,, )\");\n\n\tif (bus == 0) {\n\t\tdsdt_indent(3);\n\t\tdsdt_fixed_ioport(0xCF8, 8);\n\t\tdsdt_unindent(3);\n\n\t\tdsdt_line(\"      WordIO (ResourceProducer, MinFixed, MaxFixed, \"\n\t\t    \"PosDecode, EntireRange,\");\n\t\tdsdt_line(\"        0x0000,             // Granularity\");\n\t\tdsdt_line(\"        0x0000,             // Range Minimum\");\n\t\tdsdt_line(\"        0x0CF7,             // Range Maximum\");\n\t\tdsdt_line(\"        0x0000,             // Translation Offset\");\n\t\tdsdt_line(\"        0x0CF8,             // Length\");\n\t\tdsdt_line(\"        ,, , TypeStatic)\");\n\n\t\tdsdt_line(\"      WordIO (ResourceProducer, MinFixed, MaxFixed, \"\n\t\t    \"PosDecode, EntireRange,\");\n\t\tdsdt_line(\"        0x0000,             // Granularity\");\n\t\tdsdt_line(\"        0x0D00,             // Range Minimum\");\n\t\tdsdt_line(\"        0x%04X,             // Range Maximum\",\n\t\t    PCI_EMUL_IOBASE - 1);\n\t\tdsdt_line(\"        0x0000,             // Translation Offset\");\n\t\tdsdt_line(\"        0x%04X,             // Length\",\n\t\t    PCI_EMUL_IOBASE - 0x0D00);\n\t\tdsdt_line(\"        ,, , TypeStatic)\");\n\n\t\tif (bi == NULL) {\n\t\t\tdsdt_line(\"    })\");\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t/* i/o window */\n\tdsdt_line(\"      WordIO (ResourceProducer, MinFixed, MaxFixed, \"\n\t    \"PosDecode, EntireRange,\");\n\tdsdt_line(\"        0x0000,             // Granularity\");\n\tdsdt_line(\"        0x%04X,             // Range Minimum\", bi->iobase);\n\tdsdt_line(\"        0x%04X,             // Range Maximum\",\n\t    bi->iolimit - 1);\n\tdsdt_line(\"        0x0000,             // Translation Offset\");\n\tdsdt_line(\"        0x%04X,             // Length\",\n\t    bi->iolimit - bi->iobase);\n\tdsdt_line(\"        ,, , TypeStatic)\");\n\n\t/* mmio window (32-bit) */\n\tdsdt_line(\"      DWordMemory (ResourceProducer, PosDecode, \"\n\t    \"MinFixed, MaxFixed, NonCacheable, ReadWrite,\");\n\tdsdt_line(\"        0x00000000,         // Granularity\");\n\tdsdt_line(\"        0x%08X,         // Range Minimum\\n\", bi->membase32);\n\tdsdt_line(\"        0x%08X,         // Range Maximum\\n\",\n\t    bi->memlimit32 - 1);\n\tdsdt_line(\"        0x00000000,         // Translation Offset\");\n\tdsdt_line(\"        0x%08X,         // Length\\n\",\n\t    bi->memlimit32 - bi->membase32);\n\tdsdt_line(\"        ,, , AddressRangeMemory, TypeStatic)\");\n\n\t/* mmio window (64-bit) */\n\tdsdt_line(\"      QWordMemory (ResourceProducer, PosDecode, \"\n\t    \"MinFixed, MaxFixed, NonCacheable, ReadWrite,\");\n\tdsdt_line(\"        0x0000000000000000, // Granularity\");\n\tdsdt_line(\"        0x%016lX, // Range Minimum\\n\", bi->membase64);\n\tdsdt_line(\"        0x%016lX, // Range Maximum\\n\",\n\t    bi->memlimit64 - 1);\n\tdsdt_line(\"        0x0000000000000000, // Translation Offset\");\n\tdsdt_line(\"        0x%016lX, // Length\\n\",\n\t    bi->memlimit64 - bi->membase64);\n\tdsdt_line(\"        ,, , AddressRangeMemory, TypeStatic)\");\n\tdsdt_line(\"    })\");\n\n\tif (!is_rtvm) {\n\t\tcount = pci_count_lintr(bus);\n\t\tif (count != 0) {\n\t\t\tdsdt_indent(2);\n\t\t\tdsdt_line(\"Name (PPRT, Package ()\");\n\t\t\tdsdt_line(\"{\");\n\t\t\tpci_walk_lintr(bus, pci_pirq_prt_entry, NULL);\n\t\t\tdsdt_line(\"})\");\n\t\t\tdsdt_line(\"Name (APRT, Package ()\");\n\t\t\tdsdt_line(\"{\");\n\t\t\tpci_walk_lintr(bus, pci_apic_prt_entry, NULL);\n\t\t\tdsdt_line(\"})\");\n\t\t\tdsdt_line(\"Method (_PRT, 0, NotSerialized)\");\n\t\t\tdsdt_line(\"{\");\n\t\t\tdsdt_line(\"  If (PICM)\");\n\t\t\tdsdt_line(\"  {\");\n\t\t\tdsdt_line(\"    Return (APRT)\");\n\t\t\tdsdt_line(\"  }\");\n\t\t\tdsdt_line(\"  Else\");\n\t\t\tdsdt_line(\"  {\");\n\t\t\tdsdt_line(\"    Return (PPRT)\");\n\t\t\tdsdt_line(\"  }\");\n\t\t\tdsdt_line(\"}\");\n\t\t\tdsdt_unindent(2);\n\t\t}\n\t}\n\n\tdsdt_indent(2);\n\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\tsi = &bi->slotinfo[slot];\n\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\tdev = si->si_funcs[func].fi_devi;\n\t\t\tif (dev != NULL &&\n\t\t\t    dev->dev_ops->vdev_write_dsdt != NULL)\n\t\t\t\tdev->dev_ops->vdev_write_dsdt(dev);\n\t\t}\n\t}\n\tdsdt_unindent(2);\ndone:\n\tdsdt_line(\"  }\");\n}\n\nvoid\npci_write_dsdt(void)\n{\n\tint bus;\n\n\tdsdt_indent(1);\n\tdsdt_line(\"Name (PICM, 0x00)\");\n\tdsdt_line(\"Method (_PIC, 1, NotSerialized)\");\n\tdsdt_line(\"{\");\n\tdsdt_line(\"  Store (Arg0, PICM)\");\n\tdsdt_line(\"}\");\n\tdsdt_line(\"\");\n\tdsdt_line(\"Scope (_SB)\");\n\tdsdt_line(\"{\");\n\tfor (bus = 0; bus < MAXBUSES; bus++)\n\t\tpci_bus_write_dsdt(bus);\n\tdsdt_line(\"}\");\n\tdsdt_unindent(1);\n}\n\nint\npci_bus_configured(int bus)\n{\n\treturn (pci_businfo[bus] != NULL);\n}\n\nint\npci_msi_enabled(struct pci_vdev *dev)\n{\n\treturn dev->msi.enabled;\n}\n\nint\npci_msi_maxmsgnum(struct pci_vdev *dev)\n{\n\tif (dev->msi.enabled)\n\t\treturn dev->msi.maxmsgnum;\n\telse\n\t\treturn 0;\n}\n\nint\npci_msix_enabled(struct pci_vdev *dev)\n{\n\treturn (dev->msix.enabled && !dev->msi.enabled);\n}\n\n/**\n * @brief Generate a MSI-X interrupt to guest\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param index MSIx table entry index.\n *\n * @return None\n */\nvoid\npci_generate_msix(struct pci_vdev *dev, int index)\n{\n\tstruct msix_table_entry *mte;\n\n\tif (!pci_msix_enabled(dev))\n\t\treturn;\n\n\tif (dev->msix.function_mask)\n\t\treturn;\n\n\tif (index >= dev->msix.table_count)\n\t\treturn;\n\n\tmte = &dev->msix.table[index];\n\tif ((mte->vector_control & PCIM_MSIX_VCTRL_MASK) == 0) {\n\t\t/* XXX Set PBA bit if interrupt is disabled */\n\t\tvm_lapic_msi(dev->vmctx, mte->addr, mte->msg_data);\n\t}\n}\n\n/**\n * @brief Generate a MSI interrupt to guest\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param index Message data index.\n *\n * @return None\n */\nvoid\npci_generate_msi(struct pci_vdev *dev, int index)\n{\n\tif (pci_msi_enabled(dev) && index < pci_msi_maxmsgnum(dev)) {\n\t\tvm_lapic_msi(dev->vmctx, dev->msi.addr,\n\t\t\t     dev->msi.msg_data + index);\n\t}\n}\n\nstatic bool\npci_lintr_permitted(struct pci_vdev *dev)\n{\n\tuint16_t cmd;\n\n\tcmd = pci_get_cfgdata16(dev, PCIR_COMMAND);\n\treturn (!(dev->msi.enabled || dev->msix.enabled ||\n\t\t(cmd & PCIM_CMD_INTxDIS)));\n}\n\nvoid\npci_lintr_request(struct pci_vdev *dev)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tint bestpin, bestcount, pin;\n\n\tbi = pci_businfo[dev->bus];\n\tif (bi == NULL) {\n\t\tpr_err(\"%s: pci [%s] has wrong bus %d info!\\n\", __func__, dev->name, dev->bus);\n\t\treturn;\n\t}\n\n\t/*\n\t * Just allocate a pin from our slot.  The pin will be\n\t * assigned IRQs later when interrupts are routed.\n\t */\n\tsi = &bi->slotinfo[dev->slot];\n\tbestpin = 0;\n\tbestcount = si->si_intpins[0].ii_count;\n\tfor (pin = 1; pin < 4; pin++) {\n\t\tif (si->si_intpins[pin].ii_count < bestcount) {\n\t\t\tbestpin = pin;\n\t\t\tbestcount = si->si_intpins[pin].ii_count;\n\t\t}\n\t}\n\n\tsi->si_intpins[bestpin].ii_count++;\n\tdev->lintr.pin = bestpin + 1;\n\tpci_set_cfgdata8(dev, PCIR_INTPIN, bestpin + 1);\n}\n\nvoid\npci_lintr_release(struct pci_vdev *dev)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tint pin;\n\n\tbi = pci_businfo[dev->bus];\n\tif (bi == NULL) {\n\t\tpr_err(\"%s: pci [%s] has wrong bus %d info!\\n\", __func__, dev->name, dev->bus);\n\t\treturn;\n\t}\n\n\tsi = &bi->slotinfo[dev->slot];\n\n\tfor (pin = 1; pin < 4; pin++) {\n\t\tsi->si_intpins[pin].ii_count = 0;\n\t\tsi->si_intpins[pin].ii_pirq_pin = 0;\n\t\tsi->si_intpins[pin].ii_ioapic_irq = 0;\n\t}\n}\n\nstatic void\npci_lintr_route(struct pci_vdev *dev)\n{\n\tstruct businfo *bi;\n\tstruct intxinfo *ii;\n\n\tif (dev->lintr.pin == 0)\n\t\treturn;\n\n\tbi = pci_businfo[dev->bus];\n\tif (bi == NULL) {\n\t\tpr_err(\"%s: pci [%s] has wrong bus %d info!\\n\", __func__, dev->name, dev->bus);\n\t\treturn;\n\t}\n\tii = &bi->slotinfo[dev->slot].si_intpins[dev->lintr.pin - 1];\n\n\t/*\n\t * Attempt to allocate an I/O APIC pin for this intpin if one\n\t * is not yet assigned.\n\t */\n\tif (ii->ii_ioapic_irq == 0)\n\t\tii->ii_ioapic_irq = ioapic_pci_alloc_irq(dev);\n\n\t/*\n\t * Attempt to allocate a PIRQ pin for this intpin if one is\n\t * not yet assigned.\n\t */\n\tif (ii->ii_pirq_pin == 0)\n\t\tii->ii_pirq_pin = pirq_alloc_pin(dev);\n\n\tdev->lintr.ioapic_irq = ii->ii_ioapic_irq;\n\tdev->lintr.pirq_pin = ii->ii_pirq_pin;\n\tpci_set_cfgdata8(dev, PCIR_INTLINE, pirq_irq(ii->ii_pirq_pin));\n}\n\n/**\n * @brief Assert INTx pin of virtual PCI device\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n *\n * @return None\n */\nvoid\npci_lintr_assert(struct pci_vdev *dev)\n{\n\tif (dev->lintr.pin <= 0) {\n\t\tpr_warn(\"%s: Invalid intr pin on dev [%s]\\n\", __func__, dev->name);\n\t\treturn;\n\t}\n\n\tpthread_mutex_lock(&dev->lintr.lock);\n\tif (dev->lintr.state == IDLE) {\n\t\tif (pci_lintr_permitted(dev)) {\n\t\t\tdev->lintr.state = ASSERTED;\n\t\t\tpci_irq_assert(dev);\n\t\t} else\n\t\t\tdev->lintr.state = PENDING;\n\t}\n\tpthread_mutex_unlock(&dev->lintr.lock);\n}\n\n/**\n * @brief Deassert INTx pin of virtual PCI device\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n *\n * @return None\n */\nvoid\npci_lintr_deassert(struct pci_vdev *dev)\n{\n\tif (dev->lintr.pin <= 0) {\n\t\tpr_warn(\"%s: Invalid intr pin on dev [%s]\\n\", __func__, dev->name);\n\t\treturn;\n\t}\n\n\tpthread_mutex_lock(&dev->lintr.lock);\n\tif (dev->lintr.state == ASSERTED) {\n\t\tdev->lintr.state = IDLE;\n\t\tpci_irq_deassert(dev);\n\t} else if (dev->lintr.state == PENDING)\n\t\tdev->lintr.state = IDLE;\n\tpthread_mutex_unlock(&dev->lintr.lock);\n}\n\nstatic void\npci_lintr_update(struct pci_vdev *dev)\n{\n\tpthread_mutex_lock(&dev->lintr.lock);\n\tif (dev->lintr.state == ASSERTED && !pci_lintr_permitted(dev)) {\n\t\tpci_irq_deassert(dev);\n\t\tdev->lintr.state = PENDING;\n\t} else if (dev->lintr.state == PENDING && pci_lintr_permitted(dev)) {\n\t\tdev->lintr.state = ASSERTED;\n\t\tpci_irq_assert(dev);\n\t}\n\tpthread_mutex_unlock(&dev->lintr.lock);\n}\n\nint\npci_count_lintr(int bus)\n{\n\tint count, slot, pin;\n\tstruct slotinfo *slotinfo;\n\n\tcount = 0;\n\tif (pci_businfo[bus] != NULL) {\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tslotinfo = &pci_businfo[bus]->slotinfo[slot];\n\t\t\tfor (pin = 0; pin < 4; pin++) {\n\t\t\t\tif (slotinfo->si_intpins[pin].ii_count != 0)\n\t\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}\n\nvoid\npci_walk_lintr(int bus, pci_lintr_cb cb, void *arg)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct intxinfo *ii;\n\tint slot, pin;\n\n\tbi = pci_businfo[bus];\n\tif (bi == NULL)\n\t\treturn;\n\n\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\tsi = &bi->slotinfo[slot];\n\t\tfor (pin = 0; pin < 4; pin++) {\n\t\t\tii = &si->si_intpins[pin];\n\t\t\tif (ii->ii_count != 0)\n\t\t\t\tcb(bus, slot, pin + 1, ii->ii_pirq_pin,\n\t\t\t\t    ii->ii_ioapic_irq, arg);\n\t\t}\n\t}\n}\n\n/*\n * Return 1 if the emulated device in 'slot' is a multi-function device.\n * Return 0 otherwise.\n */\nstatic int\npci_emul_is_mfdev(int bus, int slot)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tint f, numfuncs;\n\n\tnumfuncs = 0;\n\tbi = pci_businfo[bus];\n\tif (bi != NULL) {\n\t\tsi = &bi->slotinfo[slot];\n\t\tfor (f = 0; f < MAXFUNCS; f++) {\n\t\t\tif (si->si_funcs[f].fi_devi != NULL)\n\t\t\t\tnumfuncs++;\n\t\t}\n\t}\n\treturn (numfuncs > 1);\n}\n\n/*\n * Ensure that the PCIM_MFDEV bit is properly set (or unset) depending on\n * whether or not is a multi-function being emulated in the pci 'slot'.\n */\nstatic void\npci_emul_hdrtype_fixup(int bus, int slot, int off, int bytes, uint32_t *rv)\n{\n\tint mfdev;\n\n\tif (off <= PCIR_HDRTYPE && off + bytes > PCIR_HDRTYPE) {\n\t\tmfdev = pci_emul_is_mfdev(bus, slot);\n\t\tswitch (bytes) {\n\t\tcase 1:\n\t\tcase 2:\n\t\t\t*rv &= ~PCIM_MFDEV;\n\t\t\tif (mfdev)\n\t\t\t\t*rv |= PCIM_MFDEV;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\t*rv &= ~(PCIM_MFDEV << 16);\n\t\t\tif (mfdev)\n\t\t\t\t*rv |= (PCIM_MFDEV << 16);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void\npci_emul_cmdsts_write(struct pci_vdev *dev, int coff, uint32_t new, int bytes)\n{\n\tint i, rshift;\n\tuint32_t cmd, cmd2, changed, old, readonly;\n\n\tcmd = pci_get_cfgdata16(dev, PCIR_COMMAND);\t/* stash old value */\n\n\t/*\n\t * From PCI Local Bus Specification 3.0 sections 6.2.2 and 6.2.3.\n\t *\n\t * XXX Bits 8, 11, 12, 13, 14 and 15 in the status register are\n\t * 'write 1 to clear'. However these bits are not set to '1' by\n\t * any device emulation so it is simpler to treat them as readonly.\n\t */\n\trshift = (coff & 0x3) * 8;\n\treadonly = 0xFFFFF880 >> rshift;\n\n\told = CFGREAD(dev, coff, bytes);\n\tnew &= ~readonly;\n\tnew |= (old & readonly);\n\tCFGWRITE(dev, coff, new, bytes);\t\t/* update config */\n\n\tcmd2 = pci_get_cfgdata16(dev, PCIR_COMMAND);\t/* get updated value */\n\tchanged = cmd ^ cmd2;\n\n\t/*\n\t * If the MMIO or I/O address space decoding has changed then\n\t * register/unregister all BARs that decode that address space.\n\t */\n\tfor (i = 0; i <= PCI_BARMAX; i++) {\n\t\tswitch (dev->bar[i].type) {\n\t\tcase PCIBAR_NONE:\n\t\tcase PCIBAR_MEMHI64:\n\t\t\tbreak;\n\t\tcase PCIBAR_IO:\n\t\t/* I/O address space decoding changed? */\n\t\t\tif (changed & PCIM_CMD_PORTEN) {\n\t\t\t\tif (porten(dev))\n\t\t\t\t\tregister_bar(dev, i);\n\t\t\t\telse\n\t\t\t\t\tunregister_bar(dev, i);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase PCIBAR_MEM32:\n\t\tcase PCIBAR_MEM64:\n\t\t/* MMIO address space decoding changed? */\n\t\t\tif (changed & PCIM_CMD_MEMEN) {\n\t\t\t\tif (memen(dev))\n\t\t\t\t\tregister_bar(dev, i);\n\t\t\t\telse\n\t\t\t\t\tunregister_bar(dev, i);\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_err(\"%s: invalid bar type %d\\n\", __func__, dev->bar[i].type);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/*\n\t * If INTx has been unmasked and is pending, assert the\n\t * interrupt.\n\t */\n\tpci_lintr_update(dev);\n}\n\nstatic void\npci_cfgrw(struct vmctx *ctx, int vcpu, int in, int bus, int slot, int func,\n\t  int coff, int bytes, uint32_t *eax)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct pci_vdev *dev;\n\tstruct pci_vdev_ops *ops;\n\tint idx, needcfg;\n\tuint64_t addr, bar, mask;\n\tbool decode, ignore_reg_unreg = false;\n\n\tbi = pci_businfo[bus];\n\tif (bi != NULL) {\n\t\tsi = &bi->slotinfo[slot];\n\t\tdev = si->si_funcs[func].fi_devi;\n\t} else\n\t\tdev = NULL;\n\n\t/*\n\t * Just return if there is no device at this slot:func or if the\n\t * the guest is doing an un-aligned access.\n\t */\n\tif (dev == NULL || (bytes != 1 && bytes != 2 && bytes != 4) ||\n\t    (coff & (bytes - 1)) != 0) {\n\t\tif (in)\n\t\t\t*eax = 0xffffffff;\n\t\treturn;\n\t}\n\n\tops = dev->dev_ops;\n\n\t/*\n\t * For non-passthru device, extended config space is NOT supported.\n\t * Ignore all writes beyond the standard config space and return all\n\t * ones on reads.\n\t *\n\t * For passthru device, extended config space is supported.\n\t * Access to extended config space is implemented via libpciaccess.\n\t */\n\tif (strcmp(\"passthru\", ops->class_name)) {\n\t\tif (coff >= PCI_REGMAX + 1) {\n\t\t\tif (in) {\n\t\t\t\t*eax = 0xffffffff;\n\t\t\t\t/*\n\t\t\t\t * Extended capabilities begin at offset 256 in\n\t\t\t\t * config space.\n\t\t\t\t * Absence of extended capabilities is signaled\n\t\t\t\t * with all 0s in the extended capability header\n\t\t\t\t * at offset 256.\n\t\t\t\t */\n\t\t\t\tif (coff <= PCI_REGMAX + 4)\n\t\t\t\t\t*eax = 0x00000000;\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/*\n\t * Config read\n\t */\n\tif (in) {\n\t\t/* Let the device emulation override the default handler */\n\t\tif (ops->vdev_cfgread != NULL) {\n\t\t\tneedcfg = ops->vdev_cfgread(ctx, vcpu, dev, coff, bytes,\n\t\t\t    eax);\n\t\t} else {\n\t\t\tneedcfg = 1;\n\t\t}\n\n\t\tif (needcfg)\n\t\t\t*eax = CFGREAD(dev, coff, bytes);\n\n\t\tpci_emul_hdrtype_fixup(bus, slot, coff, bytes, eax);\n\t} else {\n\t\t/* Let the device emulation override the default handler */\n\t\tif (ops->vdev_cfgwrite != NULL &&\n\t\t    (*ops->vdev_cfgwrite)(ctx, vcpu, dev,\n\t\t\t\t\t  coff, bytes, *eax) == 0)\n\t\t\treturn;\n\n\t\t/*\n\t\t * Special handling for write to BAR registers\n\t\t */\n\t\tif (coff >= PCIR_BAR(0) && coff < PCIR_BAR(PCI_BARMAX + 1)) {\n\t\t\t/*\n\t\t\t * Ignore writes to BAR registers that are not\n\t\t\t * 4-byte aligned.\n\t\t\t */\n\t\t\tif (bytes != 4 || (coff & 0x3) != 0)\n\t\t\t\treturn;\n\t\t\tidx = (coff - PCIR_BAR(0)) / 4;\n\t\t\tmask = ~(dev->bar[idx].size - 1);\n\n\t\t\tif (dev->bar[idx].type == PCIBAR_IO)\n\t\t\t\tdecode = porten(dev);\n\t\t\telse\n\t\t\t\tdecode = memen(dev);\n\n\t\t\t/* Some driver does not disable the decode of BAR\n\t\t\t * register via the command register before sizing a\n\t\t\t * BAR. This will lead to a overlay of the BAR\n\t\t\t * addresses when trying to register the intermediate\n\t\t\t * BAR address via register_bar. A stateful variable\n\t\t\t * sizing is used to keep track of such kind of BAR\n\t\t\t * address changes and workaroud this violation.\n\t\t\t */\n\t\t\tif (decode) {\n\t\t\t\tif (!dev->bar[idx].sizing && (*eax == ~0U)) {\n\t\t\t\t\tdev->bar[idx].sizing = true;\n\t\t\t\t\tignore_reg_unreg = true;\n\t\t\t\t} else if (dev->bar[idx].sizing && (*eax != ~0U)) {\n\t\t\t\t\tdev->bar[idx].sizing = false;\n\t\t\t\t\tignore_reg_unreg = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tswitch (dev->bar[idx].type) {\n\t\t\tcase PCIBAR_NONE:\n\t\t\t\tdev->bar[idx].addr = bar = 0;\n\t\t\t\tbreak;\n\t\t\tcase PCIBAR_IO:\n\t\t\t\taddr = *eax & mask;\n\t\t\t\taddr &= 0xffff;\n\t\t\t\tbar = addr | PCIM_BAR_IO_SPACE;\n\t\t\t\t/*\n\t\t\t\t * Register the new BAR value for interception\n\t\t\t\t */\n\t\t\t\tif (addr != dev->bar[idx].addr) {\n\t\t\t\t\tupdate_bar_address(ctx, dev, addr, idx,\n\t\t\t\t\t\t\t   PCIBAR_IO,\n\t\t\t\t\t\t\t   ignore_reg_unreg);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase PCIBAR_MEM32:\n\t\t\t\taddr = bar = *eax & mask;\n\t\t\t\tbar |= PCIM_BAR_MEM_SPACE | PCIM_BAR_MEM_32;\n\t\t\t\tif (addr != dev->bar[idx].addr) {\n\t\t\t\t\tupdate_bar_address(ctx, dev, addr, idx,\n\t\t\t\t\t\t\t   PCIBAR_MEM32,\n\t\t\t\t\t\t\t   ignore_reg_unreg);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase PCIBAR_MEM64:\n\t\t\t\taddr = bar = *eax & mask;\n\t\t\t\tbar |= PCIM_BAR_MEM_SPACE | PCIM_BAR_MEM_64 |\n\t\t\t\t       PCIM_BAR_MEM_PREFETCH;\n\t\t\t\tif (addr != (uint32_t)dev->bar[idx].addr) {\n\t\t\t\t\tupdate_bar_address(ctx, dev, addr, idx,\n\t\t\t\t\t\t\t   PCIBAR_MEM64,\n\t\t\t\t\t\t\t   ignore_reg_unreg);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase PCIBAR_MEMHI64:\n\t\t\t\tmask = ~(dev->bar[idx - 1].size - 1);\n\t\t\t\taddr = ((uint64_t)*eax << 32) & mask;\n\t\t\t\tbar = addr >> 32;\n\t\t\t\tif (bar != dev->bar[idx - 1].addr >> 32) {\n\t\t\t\t\tupdate_bar_address(ctx, dev, addr, idx - 1,\n\t\t\t\t\t\t\t   PCIBAR_MEMHI64,\n\t\t\t\t\t\t\t   ignore_reg_unreg);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tpr_err(\"%s: invalid bar type %d\\n\", __func__, dev->bar[idx].type);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpci_set_cfgdata32(dev, coff, bar);\n\n\t\t} else if (coff == PCIR_BIOS) {\n\t\t\t/* ignore ROM BAR length request */\n\t\t} else if (pci_emul_iscap(dev, coff)) {\n\t\t\tpci_emul_capwrite(dev, coff, bytes, *eax);\n\t\t} else if (coff >= PCIR_COMMAND && coff < PCIR_REVID) {\n\t\t\tpci_emul_cmdsts_write(dev, coff, *eax, bytes);\n\t\t} else {\n\t\t\tCFGWRITE(dev, coff, *eax, bytes);\n\t\t}\n\t}\n}\n\nstatic int cfgenable, cfgbus, cfgslot, cfgfunc, cfgoff;\n\nstatic int\npci_emul_cfgaddr(struct vmctx *ctx, int vcpu, int in, int port, int bytes,\n\t\t uint32_t *eax, void *arg)\n{\n\tuint32_t x;\n\n\tif (bytes != 4) {\n\t\tif (in)\n\t\t\t*eax = (bytes == 2) ? 0xffff : 0xff;\n\t\treturn 0;\n\t}\n\n\tif (in) {\n\t\tx = (cfgbus << 16) | (cfgslot << 11) | (cfgfunc << 8) | cfgoff;\n\t\tif (cfgenable)\n\t\t\tx |= CONF1_ENABLE;\n\t\t*eax = x;\n\t} else {\n\t\tx = *eax;\n\t\tcfgenable = (x & CONF1_ENABLE) == CONF1_ENABLE;\n\t\tcfgoff = x & PCI_REGMAX;\n\t\tcfgfunc = (x >> 8) & PCI_FUNCMAX;\n\t\tcfgslot = (x >> 11) & PCI_SLOTMAX;\n\t\tcfgbus = (x >> 16) & PCI_BUSMAX;\n\t}\n\n\treturn 0;\n}\nINOUT_PORT(pci_cfgaddr, CONF1_ADDR_PORT, IOPORT_F_INOUT, pci_emul_cfgaddr);\n\nstatic int\npci_emul_cfgdata(struct vmctx *ctx, int vcpu, int in, int port, int bytes,\n\t\t uint32_t *eax, void *arg)\n{\n\tint coff;\n\n\tassert(bytes == 1 || bytes == 2 || bytes == 4);\n\n\tcoff = cfgoff + (port - CONF1_DATA_PORT);\n\tif (cfgenable) {\n\t\tpci_cfgrw(ctx, vcpu, in, cfgbus, cfgslot, cfgfunc, coff, bytes,\n\t\t    eax);\n\t} else {\n\t\t/* Ignore accesses to cfgdata if not enabled by cfgaddr */\n\t\tif (in)\n\t\t\t*eax = 0xffffffff;\n\t}\n\treturn 0;\n}\n\nINOUT_PORT(pci_cfgdata, CONF1_DATA_PORT+0, IOPORT_F_INOUT, pci_emul_cfgdata);\nINOUT_PORT(pci_cfgdata, CONF1_DATA_PORT+1, IOPORT_F_INOUT, pci_emul_cfgdata);\nINOUT_PORT(pci_cfgdata, CONF1_DATA_PORT+2, IOPORT_F_INOUT, pci_emul_cfgdata);\nINOUT_PORT(pci_cfgdata, CONF1_DATA_PORT+3, IOPORT_F_INOUT, pci_emul_cfgdata);\n\nint\nemulate_pci_cfgrw(struct vmctx *ctx, int vcpu, int in, int bus, int slot,\n\t\t  int func, int reg, int bytes, int *value)\n{\n\tpci_cfgrw(ctx, vcpu, in, bus, slot, func, reg,\n\t\t\tbytes, (uint32_t *)value);\n\treturn 0;\n}\n\n#define PCI_EMUL_TEST\n#ifdef PCI_EMUL_TEST\n/*\n * Define a dummy test device\n */\n#define DIOSZ\t8\n#define DMEMSZ\t4096\nstruct pci_emul_dummy {\n\tuint8_t   ioregs[DIOSZ];\n\tuint8_t\t  memregs[2][DMEMSZ];\n};\n\n#define\tPCI_EMUL_MSI_MSGS\t 4\n#define\tPCI_EMUL_MSIX_MSGS\t16\n\nstatic int\npci_emul_dinit(struct vmctx *ctx, struct pci_vdev *dev, char *opts)\n{\n\tstruct pci_emul_dummy *dummy;\n\n\tdummy = calloc(1, sizeof(struct pci_emul_dummy));\n\n\tdev->arg = dummy;\n\n\tpci_set_cfgdata16(dev, PCIR_DEVICE, 0x0001);\n\tpci_set_cfgdata16(dev, PCIR_VENDOR, 0x10DD);\n\tpci_set_cfgdata8(dev, PCIR_CLASS, 0x02);\n\n\treturn pci_emul_add_msicap(dev, PCI_EMUL_MSI_MSGS) ||\n\t\tpci_emul_alloc_bar(dev, 0, PCIBAR_IO, DIOSZ) ||\n\t\tpci_emul_alloc_bar(dev, 1, PCIBAR_MEM32, DMEMSZ) ||\n\t\tpci_emul_alloc_bar(dev, 2, PCIBAR_MEM32, DMEMSZ);\n}\n\nstatic void\npci_emul_diow(struct vmctx *ctx, int vcpu, struct pci_vdev *dev, int baridx,\n\t      uint64_t offset, int size, uint64_t value)\n{\n\tint i;\n\tvoid *offset_ptr;\n\tstruct pci_emul_dummy *dummy = dev->arg;\n\n\tif (baridx == 0) {\n\t\tif (offset + size > DIOSZ) {\n\t\t\tprintf(\"diow: iow too large, offset %ld size %d\\n\",\n\t\t\t       offset, size);\n\t\t\treturn;\n\t\t}\n\n\t\toffset_ptr = (void *) &dummy->ioregs[offset];\n\t\tif (size == 1)\n\t\t\t*(uint8_t *)offset_ptr = value & 0xff;\n\t\telse if (size == 2)\n\t\t\t*(uint16_t *)offset_ptr = value & 0xffff;\n\t\telse if (size == 4)\n\t\t\t*(uint32_t *)offset = value;\n\t\telse\n\t\t\tprintf(\"diow: iow unknown size %d\\n\", size);\n\n\t\t/*\n\t\t * Special magic value to generate an interrupt\n\t\t */\n\t\tif (offset == 4 && size == 4 && pci_msi_enabled(dev))\n\t\t\tpci_generate_msi(dev, value % pci_msi_maxmsgnum(dev));\n\n\t\tif (value == 0xabcdef) {\n\t\t\tfor (i = 0; i < pci_msi_maxmsgnum(dev); i++)\n\t\t\t\tpci_generate_msi(dev, i);\n\t\t}\n\t}\n\n\tif (baridx == 1 || baridx == 2) {\n\t\tif (offset + size > DMEMSZ) {\n\t\t\tprintf(\"diow: memw too large, offset %ld size %d\\n\",\n\t\t\t       offset, size);\n\t\t\treturn;\n\t\t}\n\n\t\ti = baridx - 1;\t\t/* 'memregs' index */\n\n\t\toffset_ptr = (void *) &dummy->memregs[i][offset];\n\t\tif (size == 1)\n\t\t\t*(uint8_t *)offset_ptr = value;\n\t\telse if (size == 2)\n\t\t\t*(uint16_t *)offset_ptr = value;\n\t\telse if (size == 4)\n\t\t\t*(uint32_t *)offset_ptr = value;\n\t\telse if (size == 8)\n\t\t\t*(uint64_t *)offset_ptr = value;\n\t\telse\n\t\t\tprintf(\"diow: memw unknown size %d\\n\", size);\n\n\t\t/*\n\t\t * magic interrupt ??\n\t\t */\n\t}\n\n\tif (baridx > 2 || baridx < 0)\n\t\tprintf(\"diow: unknown bar idx %d\\n\", baridx);\n}\n\nstatic uint64_t\npci_emul_dior(struct vmctx *ctx, int vcpu, struct pci_vdev *dev, int baridx,\n\t      uint64_t offset, int size)\n{\n\tstruct pci_emul_dummy *dummy = dev->arg;\n\tuint32_t value = 0;\n\tint i;\n\tvoid *offset_ptr;\n\n\tif (baridx == 0) {\n\t\tif (offset + size > DIOSZ) {\n\t\t\tprintf(\"dior: ior too large, offset %ld size %d\\n\",\n\t\t\t       offset, size);\n\t\t\treturn 0;\n\t\t}\n\n\t\tvalue = 0;\n\t\toffset_ptr = (void *) &dummy->ioregs[offset];\n\t\tif (size == 1)\n\t\t\tvalue = *(uint8_t *)offset_ptr;\n\t\telse if (size == 2)\n\t\t\tvalue = *(uint16_t *)offset_ptr;\n\t\telse if (size == 4)\n\t\t\tvalue = *(uint32_t *)offset_ptr;\n\t\telse\n\t\t\tprintf(\"dior: ior unknown size %d\\n\", size);\n\t}\n\n\tif (baridx == 1 || baridx == 2) {\n\t\tif (offset + size > DMEMSZ) {\n\t\t\tprintf(\"dior: memr too large, offset %ld size %d\\n\",\n\t\t\t       offset, size);\n\t\t\treturn 0;\n\t\t}\n\n\t\ti = baridx - 1;\t\t/* 'memregs' index */\n\n\t\toffset_ptr = (void *) &dummy->memregs[i][offset];\n\t\tif (size == 1)\n\t\t\tvalue = *(uint8_t *)offset_ptr;\n\t\telse if (size == 2)\n\t\t\tvalue = *(uint16_t *)offset_ptr;\n\t\telse if (size == 4)\n\t\t\tvalue = *(uint32_t *)offset_ptr;\n\t\telse if (size == 8)\n\t\t\tvalue = *(uint64_t *)offset_ptr;\n\t\telse\n\t\t\tprintf(\"dior: ior unknown size %d\\n\", size);\n\t}\n\n\n\tif (baridx > 2 || baridx < 0) {\n\t\tprintf(\"dior: unknown bar idx %d\\n\", baridx);\n\t\treturn 0;\n\t}\n\n\treturn value;\n}\n\nstruct pci_vdev*\npci_get_vdev_info(int slot)\n{\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct pci_vdev *dev = NULL;\n\n\tbi = pci_businfo[0];\n\tif (bi == NULL)\n\t\treturn NULL;\n\n\tsi = &bi->slotinfo[slot];\n\tif (si != NULL)\n\t\tdev = si->si_funcs[0].fi_devi;\n\telse\n\t\tfprintf(stderr, \"slot=%d is empty!\\n\", slot);\n\n\treturn dev;\n}\n\nstruct pci_vdev_ops pci_dummy = {\n\t.class_name\t= \"dummy\",\n\t.vdev_init\t= pci_emul_dinit,\n\t.vdev_barwrite\t= pci_emul_diow,\n\t.vdev_barread\t= pci_emul_dior\n};\nDEFINE_PCI_DEVTYPE(pci_dummy);\n\n#endif /* PCI_EMUL_TEST */\n", "/*-\n * Copyright (c) 2011 NetApp, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY NETAPP, INC ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL NETAPP, INC OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n *\n * $FreeBSD$\n */\n\n#ifndef _PCI_CORE_H_\n#define _PCI_CORE_H_\n\n#include <sys/queue.h>\n\n#include <assert.h>\n#include <stdbool.h>\n#include \"types.h\"\n#include \"pcireg.h\"\n#include \"log.h\"\n\n#define\tPCI_BARMAX\tPCIR_MAX_BAR_0\t/* BAR registers in a Type 0 header */\n#define\tPCI_BDF(b, d, f) (((b & 0xFF) << 8) | ((d & 0x1F) << 3) | ((f & 0x7)))\n\n#define\tPCI_EMUL_ECFG_BASE\t0xE0000000UL\t/* 3.5GB */\n\n#define\tPCI_EMUL_MEMBASE64\t0x100000000UL\t/* 4GB */\n#define\tPCI_EMUL_MEMLIMIT64\t0x140000000UL\t/* 5GB */\n\nstruct vmctx;\nstruct pci_vdev;\nstruct memory_region;\n\nstruct pci_vdev_ops {\n\tchar\t*class_name;\t\t/* Name of device class */\n\n\t/* instance creation */\n\tint\t(*vdev_init)(struct vmctx *, struct pci_vdev *,\n\t\t\t     char *opts);\n\n\t/* instance deinit */\n\tvoid\t(*vdev_deinit)(struct vmctx *, struct pci_vdev *,\n\t\t\tchar *opts);\n\n\t/* ACPI DSDT enumeration */\n\tvoid\t(*vdev_write_dsdt)(struct pci_vdev *);\n\n\t/* ops related to physical resources */\n\tvoid\t(*vdev_phys_access)(struct vmctx *ctx, struct pci_vdev *dev);\n\n\t/* update BAR map callback */\n\tvoid\t(*vdev_update_bar_map)(struct vmctx *ctx,\n\t\t\t\tstruct pci_vdev *dev, int idx,\n\t\t\t\tuint64_t orig_addr);\n\n\t/* config space read/write callbacks */\n\tint\t(*vdev_cfgwrite)(struct vmctx *ctx, int vcpu,\n\t\t\t       struct pci_vdev *pi, int offset,\n\t\t\t       int bytes, uint32_t val);\n\tint\t(*vdev_cfgread)(struct vmctx *ctx, int vcpu,\n\t\t\t      struct pci_vdev *pi, int offset,\n\t\t\t      int bytes, uint32_t *retval);\n\n\t/* BAR read/write callbacks */\n\tvoid\t(*vdev_barwrite)(struct vmctx *ctx, int vcpu,\n\t\t\t\t struct pci_vdev *pi, int baridx,\n\t\t\t\t uint64_t offset, int size, uint64_t value);\n\tuint64_t  (*vdev_barread)(struct vmctx *ctx, int vcpu,\n\t\t\t\tstruct pci_vdev *pi, int baridx,\n\t\t\t\tuint64_t offset, int size);\n};\n\n/*\n * Put all PCI instances' addresses into one section named pci_devemu_set\n * so that DM could enumerate and initialize each of them.\n */\n#define DEFINE_PCI_DEVTYPE(x)\tDATA_SET(pci_vdev_ops_set, x)\n\nenum pcibar_type {\n\tPCIBAR_NONE,\n\tPCIBAR_IO,\n\tPCIBAR_MEM32,\n\tPCIBAR_MEM64,\n\tPCIBAR_MEMHI64\n};\n\nstruct pcibar {\n\tenum pcibar_type\ttype;\t\t/* io or memory */\n\tuint64_t\t\tsize;\n\tuint64_t\t\taddr;\n\tbool\t\t\tsizing;\n};\n\n#define PI_NAMESZ\t40\n\nstruct msix_table_entry {\n\tuint64_t\taddr;\n\tuint32_t\tmsg_data;\n\tuint32_t\tvector_control;\n} __attribute__((packed));\n\n/*\n * In case the structure is modified to hold extra information, use a define\n * for the size that should be emulated.\n */\n#define\tMSIX_TABLE_ENTRY_SIZE\t16\n#define MAX_MSIX_TABLE_ENTRIES\t2048\n#define\tPBA_SIZE(msgnum)\t(roundup2((msgnum), 64) / 8)\n\nenum lintr_stat {\n\tIDLE,\n\tASSERTED,\n\tPENDING\n};\n\nstruct pci_vdev {\n\tstruct pci_vdev_ops *dev_ops;\n\tstruct vmctx *vmctx;\n\tuint8_t\tbus, slot, func;\n\tchar\tname[PI_NAMESZ];\n\tint\tbar_getsize;\n\tint\tprevcap;\n\tint\tcapend;\n\n\tstruct {\n\t\tint8_t\tpin;\n\t\tenum lintr_stat\tstate;\n\t\tint\t\tpirq_pin;\n\t\tint\t\tioapic_irq;\n\t\tpthread_mutex_t\tlock;\n\t} lintr;\n\n\tstruct {\n\t\tint\t\tenabled;\n\t\tuint64_t\taddr;\n\t\tuint64_t\tmsg_data;\n\t\tint\t\tmaxmsgnum;\n\t} msi;\n\n\tstruct {\n\t\tint\tenabled;\n\t\tint\ttable_bar;\n\t\tint\tpba_bar;\n\t\tuint32_t table_offset;\n\t\tint\ttable_count;\n\t\tuint32_t pba_offset;\n\t\tint\tpba_size;\n\t\tint\tfunction_mask;\n\t\tstruct msix_table_entry *table;\t/* allocated at runtime */\n\t\tvoid\t*pba_page;\n\t\tint\tpba_page_offset;\n\t} msix;\n\n\tvoid\t*arg;\t\t/* devemu-private data */\n\n\tuint8_t\tcfgdata[PCI_REGMAX + 1];\n\tstruct pcibar bar[PCI_BARMAX + 1];\n};\n\nstruct gsi_dev {\n\t/*\n\t * For PCI devices, use a string \"b:d.f\" to stand for the device's BDF,\n\t *  such as \"00:00.0\".\n\t * For non-PCI devices, use the device's name to stand for the device,\n\t *  such as \"timer\".\n\t */\n\tchar *dev_name;\n\tuint8_t gsi;\n};\n\nextern struct gsi_dev gsi_dev_mapping_tables[];\nextern int num_gsi_dev_mapping_tables;\n\nstruct msicap {\n\tuint8_t\t\tcapid;\n\tuint8_t\t\tnextptr;\n\tuint16_t\tmsgctrl;\n\tuint32_t\taddrlo;\n\tuint32_t\taddrhi;\n\tuint16_t\tmsgdata;\n} __attribute__((packed));\nstatic_assert(sizeof(struct msicap) == 14, \"compile-time assertion failed\");\n\nstruct msixcap {\n\tuint8_t\t\tcapid;\n\tuint8_t\t\tnextptr;\n\tuint16_t\tmsgctrl;\n\tuint32_t\ttable_info;\t/* bar index and offset within it */\n\tuint32_t\tpba_info;\t/* bar index and offset within it */\n} __attribute__((packed));\nstatic_assert(sizeof(struct msixcap) == 12, \"compile-time assertion failed\");\n\nstruct pciecap {\n\tuint8_t\t\tcapid;\n\tuint8_t\t\tnextptr;\n\tuint16_t\tpcie_capabilities;\n\n\tuint32_t\tdev_capabilities;\t/* all devices */\n\tuint16_t\tdev_control;\n\tuint16_t\tdev_status;\n\n\tuint32_t\tlink_capabilities;\t/* devices with links */\n\tuint16_t\tlink_control;\n\tuint16_t\tlink_status;\n\n\tuint32_t\tslot_capabilities;\t/* ports with slots */\n\tuint16_t\tslot_control;\n\tuint16_t\tslot_status;\n\n\tuint16_t\troot_control;\t\t/* root ports */\n\tuint16_t\troot_capabilities;\n\tuint32_t\troot_status;\n\n\tuint32_t\tdev_capabilities2;\t/* all devices */\n\tuint16_t\tdev_control2;\n\tuint16_t\tdev_status2;\n\n\tuint32_t\tlink_capabilities2;\t/* devices with links */\n\tuint16_t\tlink_control2;\n\tuint16_t\tlink_status2;\n\n\tuint32_t\tslot_capabilities2;\t/* ports with slots */\n\tuint16_t\tslot_control2;\n\tuint16_t\tslot_status2;\n} __attribute__((packed));\nstatic_assert(sizeof(struct pciecap) == 60, \"compile-time assertion failed\");\n\ntypedef void (*pci_lintr_cb)(int b, int s, int pin, int pirq_pin,\n\t\t\t     int ioapic_irq, void *arg);\n\nint\tinit_pci(struct vmctx *ctx);\nvoid\tdeinit_pci(struct vmctx *ctx);\nvoid\tmsicap_cfgwrite(struct pci_vdev *pi, int capoff, int offset,\n\t\t\tint bytes, uint32_t val);\nvoid\tmsixcap_cfgwrite(struct pci_vdev *pi, int capoff, int offset,\n\t\t\t int bytes, uint32_t val);\nvoid\tpci_callback(void);\nint\tpci_emul_alloc_bar(struct pci_vdev *pdi, int idx,\n\t\t\t   enum pcibar_type type, uint64_t size);\nint\tpci_emul_alloc_pbar(struct pci_vdev *pdi, int idx,\n\t\t\t    uint64_t hostbase, enum pcibar_type type,\n\t\t\t    uint64_t size);\nvoid\tpci_emul_free_bars(struct pci_vdev *pdi);\nint\tpci_emul_add_capability(struct pci_vdev *dev, u_char *capdata,\n\t\t\t\tint caplen);\nint\tpci_emul_find_capability(struct pci_vdev *dev, uint8_t capid,\n\t\t\t\t int *p_capoff);\nint\tpci_emul_add_msicap(struct pci_vdev *pi, int msgnum);\nint\tpci_emul_add_pciecap(struct pci_vdev *pi, int pcie_device_type);\n\n/**\n * @brief Generate a MSI interrupt to guest\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param index Message data index.\n *\n * @return None\n */\nvoid\tpci_generate_msi(struct pci_vdev *dev, int index);\n\n/**\n * @brief Generate a MSI-X interrupt to guest\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param index MSIs table entry index.\n *\n * @return None\n */\nvoid\tpci_generate_msix(struct pci_vdev *dev, int index);\n\n/**\n * @brief Assert INTx pin of virtual PCI device\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n *\n * @return None\n */\nvoid\tpci_lintr_assert(struct pci_vdev *dev);\n\n/**\n * @brief Deassert INTx pin of virtual PCI device\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n *\n * @return None\n */\nvoid\tpci_lintr_deassert(struct pci_vdev *dev);\n\nvoid\tpci_lintr_request(struct pci_vdev *pi);\nvoid\tpci_lintr_release(struct pci_vdev *pi);\nint\tpci_msi_enabled(struct pci_vdev *pi);\nint\tpci_msix_enabled(struct pci_vdev *pi);\nint\tpci_msix_table_bar(struct pci_vdev *pi);\nint\tpci_msix_pba_bar(struct pci_vdev *pi);\nint\tpci_msi_maxmsgnum(struct pci_vdev *pi);\nint\tpci_parse_slot(char *opt);\nint\tpci_populate_msicap(struct msicap *cap, int msgs, int nextptr);\nint\tpci_emul_add_msixcap(struct pci_vdev *pi, int msgnum, int barnum);\nint\tpci_emul_msix_twrite(struct pci_vdev *pi, uint64_t offset, int size,\n\t\t\t     uint64_t value);\nuint64_t pci_emul_msix_tread(struct pci_vdev *pi, uint64_t offset, int size);\nint\tpci_count_lintr(int bus);\nvoid\tpci_walk_lintr(int bus, pci_lintr_cb cb, void *arg);\nvoid\tpci_write_dsdt(void);\nint\tpci_bus_configured(int bus);\nint\temulate_pci_cfgrw(struct vmctx *ctx, int vcpu, int in, int bus,\n\t\t\t  int slot, int func, int reg, int bytes, int *value);\nint\tcreate_gsi_sharing_groups(void);\nvoid\tupdate_pt_info(uint16_t phys_bdf);\nint\tcheck_gsi_sharing_violation(void);\nint\tpciaccess_init(void);\nvoid\tpciaccess_cleanup(void);\nint\tparse_bdf(char *s, int *bus, int *dev, int *func, int base);\nstruct pci_vdev *pci_get_vdev_info(int slot);\n\n\n/**\n * @brief Set virtual PCI device's configuration space in 1 byte width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n * @param val Value in 1 byte.\n *\n * @return None\n */\nstatic inline void\npci_set_cfgdata8(struct pci_vdev *dev, int offset, uint8_t val)\n{\n\tif (offset > PCI_REGMAX) {\n\t\tpr_err(\"%s: out of range of PCI config space!\\n\", __func__);\n\t\treturn;\n\t}\n\t*(uint8_t *)(dev->cfgdata + offset) = val;\n}\n\n/**\n * @brief Set virtual PCI device's configuration space in 2 bytes width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n * @param val Value in 2 bytes.\n *\n * @return None\n */\nstatic inline void\npci_set_cfgdata16(struct pci_vdev *dev, int offset, uint16_t val)\n{\n\tif ((offset > PCI_REGMAX - 1) || (offset & 1) != 0) {\n\t\tpr_err(\"%s: out of range of PCI config space!\\n\", __func__);\n\t\treturn;\n\t}\n\t*(uint16_t *)(dev->cfgdata + offset) = val;\n}\n\n/**\n * @brief Set virtual PCI device's configuration space in 4 bytes width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n * @param val Value in 4 bytes.\n *\n * @return None\n */\nstatic inline void\npci_set_cfgdata32(struct pci_vdev *dev, int offset, uint32_t val)\n{\n\tif ((offset > PCI_REGMAX - 3) || (offset & 3) != 0) {\n\t\tpr_err(\"%s: out of range of PCI config space!\\n\", __func__);\n\t\treturn;\n\t}\n\t*(uint32_t *)(dev->cfgdata + offset) = val;\n}\n\n/**\n * @brief Get virtual PCI device's configuration space in 1 byte width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n *\n * @return The configuration value in 1 byte.\n */\nstatic inline uint8_t\npci_get_cfgdata8(struct pci_vdev *dev, int offset)\n{\n\tif (offset > PCI_REGMAX) {\n\t\tpr_err(\"%s: out of range of PCI config space!\\n\", __func__);\n\t\treturn 0xff;\n\t}\n\treturn (*(uint8_t *)(dev->cfgdata + offset));\n}\n\n/**\n * @brief Get virtual PCI device's configuration space in 2 byte width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n *\n * @return The configuration value in 2 bytes.\n */\nstatic inline uint16_t\npci_get_cfgdata16(struct pci_vdev *dev, int offset)\n{\n\tif ((offset > PCI_REGMAX - 1) || (offset & 1) != 0) {\n\t\tpr_err(\"%s: out of range of PCI config space!\\n\", __func__);\n\t\treturn 0xffff;\n\t}\n\treturn (*(uint16_t *)(dev->cfgdata + offset));\n}\n\n/**\n * @brief Get virtual PCI device's configuration space in 4 byte width\n *\n * @param dev Pointer to struct pci_vdev representing virtual PCI device.\n * @param offset Offset in configuration space.\n *\n * @return The configuration value in 4 bytes.\n */\nstatic inline uint32_t\npci_get_cfgdata32(struct pci_vdev *dev, int offset)\n{\n\tif ((offset > PCI_REGMAX - 3) || (offset & 3) != 0) {\n\t\tpr_err(\"%s: out of range of PCI config space!\\n\", __func__);\n\t\treturn 0xffffffff;\n\t}\n\treturn (*(uint32_t *)(dev->cfgdata + offset));\n}\n\n#endif /* _PCI_CORE_H_ */\n", "#ifndef _TYPES_H_\n#define _TYPES_H_\n\n#include \"macros.h\"\n#include <stdint.h>\n#include <stdarg.h>\n#include <sched.h>\n#include <sys/types.h>\n\n#define MAXCOMLEN   19      /* max command name remembered */\n#define MAXINTERP   PATH_MAX    /* max interpreter file name length */\n#define MAXLOGNAME  33      /* max login name length (incl. NUL) */\n#define SPECNAMELEN 63      /* max length of devicename */\n\ntypedef cpu_set_t cpuset_t;\ntypedef uint64_t vm_paddr_t;\ntypedef uint64_t vm_ooffset_t;\ntypedef uint64_t cap_ioctl_t;\n\n#define ARRAY_SIZE(a) (sizeof(a) / sizeof(a[0]))\n\n#define container_of(ptr, type, member) ({                   \\\n\tconst typeof(((type *)0)->member) * __mptr = (ptr);  \\\n\t(type *)((char *)__mptr - (offsetof(type, member))); \\\n})\n\n#define __aligned(x)\t\t__attribute__((aligned(x)))\n#define __section(x)\t\t__attribute__((__section__(x)))\n#define __MAKE_SET(set, sym)                        \\\n\tstatic void const * const __set_##set##_sym_##sym       \\\n\t__section(\"set_\" #set) __attribute__((used)) = &sym\n\n#define DATA_SET(set, sym)  __MAKE_SET(set, sym)\n\n#define SET_DECLARE(set, ptype)\\\n\t extern ptype * __CONCAT(__start_set_, set); \\\n\t extern ptype *__CONCAT(__stop_set_, set)\n\n#define SET_BEGIN(set)                          \\\n\t(&__CONCAT(__start_set_, set))\n#define SET_LIMIT(set)                          \\\n\t(&__CONCAT(__stop_set_, set))\n\n#define SET_FOREACH(pvar, set)                      \\\n\tfor (pvar = SET_BEGIN(set); pvar < SET_LIMIT(set); pvar++)\n\n#define nitems(x) (sizeof((x)) / sizeof((x)[0]))\n#define roundup2(x, y)  (((x)+((y)-1))&(~((y)-1)))\n#define rounddown2(x, y) ((x)&(~((y)-1)))\n\nstatic inline uint16_t\nbe16dec(const void *pp)\n{\n\tuint8_t const *p = (uint8_t const *)pp;\n\n\treturn ((p[0] << 8) | p[1]);\n}\n\nstatic inline uint32_t\nbe32dec(const void *pp)\n{\n\tuint8_t const *p = (uint8_t const *)pp;\n\n\treturn (((uint32_t)p[0] << 24) | (p[1] << 16) | (p[2] << 8) | p[3]);\n}\n\nstatic inline void\nbe16enc(void *pp, uint16_t u)\n{\n\tuint8_t *p = (uint8_t *)pp;\n\n\tp[0] = (u >> 8) & 0xff;\n\tp[1] = u & 0xff;\n}\n\nstatic inline void\nbe32enc(void *pp, uint32_t u)\n{\n\tuint8_t *p = (uint8_t *)pp;\n\n\tp[0] = (u >> 24) & 0xff;\n\tp[1] = (u >> 16) & 0xff;\n\tp[2] = (u >> 8) & 0xff;\n\tp[3] = u & 0xff;\n}\nstatic inline int\nflsl(uint64_t mask)\n{\n\treturn mask ? 64 - __builtin_clzl(mask) : 0;\n}\n\n/* memory barrier */\n#define mb()    ({ asm volatile(\"mfence\" ::: \"memory\"); (void)0; })\n\nstatic inline void\ndo_cpuid(u_int ax, u_int *p)\n{\n\t__asm __volatile(\"cpuid\"\n\t : \"=a\" (p[0]), \"=b\" (p[1]), \"=c\" (p[2]), \"=d\" (p[3])\n\t :  \"0\" (ax));\n}\n\n#define UGETW(w)            \\\n\t((w)[0] |             \\\n\t(((uint16_t)((w)[1])) << 8))\n\n#define UGETDW(w)           \\\n\t((w)[0] |             \\\n\t(((uint16_t)((w)[1])) << 8) |     \\\n\t(((uint32_t)((w)[2])) << 16) |    \\\n\t(((uint32_t)((w)[3])) << 24))\n\n#define UGETQW(w)           \\\n\t((w)[0] |             \\\n\t(((uint16_t)((w)[1])) << 8) |     \\\n\t(((uint32_t)((w)[2])) << 16) |    \\\n\t(((uint32_t)((w)[3])) << 24) |    \\\n\t(((uint64_t)((w)[4])) << 32) |    \\\n\t(((uint64_t)((w)[5])) << 40) |    \\\n\t(((uint64_t)((w)[6])) << 48) |    \\\n\t(((uint64_t)((w)[7])) << 56))\n\n#define USETW(w, v) do {         \\\n\t  (w)[0] = (uint8_t)(v);        \\\n\t  (w)[1] = (uint8_t)((v) >> 8);     \\\n} while (0)\n\n#define USETDW(w, v) do {        \\\n\t  (w)[0] = (uint8_t)(v);        \\\n\t  (w)[1] = (uint8_t)((v) >> 8);     \\\n\t  (w)[2] = (uint8_t)((v) >> 16);    \\\n\t  (w)[3] = (uint8_t)((v) >> 24);    \\\n} while (0)\n\n#define USETQW(w, v) do {        \\\n\t  (w)[0] = (uint8_t)(v);        \\\n\t  (w)[1] = (uint8_t)((v) >> 8);     \\\n\t  (w)[2] = (uint8_t)((v) >> 16);    \\\n\t  (w)[3] = (uint8_t)((v) >> 24);    \\\n\t  (w)[4] = (uint8_t)((v) >> 32);    \\\n\t  (w)[5] = (uint8_t)((v) >> 40);    \\\n\t  (w)[6] = (uint8_t)((v) >> 48);    \\\n\t  (w)[7] = (uint8_t)((v) >> 56);    \\\n} while (0)\n\n#define __packed       __attribute__((packed))\n\n#endif\n"], "filenames": ["devicemodel/hw/pci/core.c", "devicemodel/include/pci_core.h", "devicemodel/include/types.h"], "buggy_code_start_loc": [429, 37, 5], "buggy_code_end_loc": [2471, 424, 5], "fixing_code_start_loc": [429, 38, 6], "fixing_code_end_loc": [2492, 443, 7], "type": "CWE-617", "message": "The Device Model in ACRN before 2019w25.5-140000p relies on assert calls in devicemodel/hw/pci/core.c and devicemodel/include/pci_core.h (instead of other mechanisms for propagating error information or diagnostic information), which might allow attackers to cause a denial of service (assertion failure) within pci core. This is fixed in 1.2. 6199e653418e is a mitigation for pre-1.1 versions, whereas 2b3dedfb9ba1 is a mitigation for 1.1.", "other": {"cve": {"id": "CVE-2019-18844", "sourceIdentifier": "cve@mitre.org", "published": "2019-11-13T20:15:11.020", "lastModified": "2020-11-09T21:46:29.847", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The Device Model in ACRN before 2019w25.5-140000p relies on assert calls in devicemodel/hw/pci/core.c and devicemodel/include/pci_core.h (instead of other mechanisms for propagating error information or diagnostic information), which might allow attackers to cause a denial of service (assertion failure) within pci core. This is fixed in 1.2. 6199e653418e is a mitigation for pre-1.1 versions, whereas 2b3dedfb9ba1 is a mitigation for 1.1."}, {"lang": "es", "value": "El modelo de dispositivo en ACRN antes de 2019w25.5-140000p se basa en llamadas de afirmaci\u00f3n en devicemodel / hw / pci / core.c y devicemodel / include / pci_core.h (en lugar de otros mecanismos para propagar informaci\u00f3n de error o informaci\u00f3n de diagn\u00f3stico), lo que podr\u00eda permitir atacantes para causar una denegaci\u00f3n de servicio (falla de aserci\u00f3n) dentro de pci core. Esto se soluciona en 1.2. 6199e653418e es una mitigaci\u00f3n para las versiones anteriores a la versi\u00f3n 1.1, mientras que 2b3dedfb9ba1 es una mitigaci\u00f3n para 1.1."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-617"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:acrn:*:*:*:*:*:*:*:*", "versionEndExcluding": "2019w25.5-140000p", "matchCriteriaId": "230540A5-B9A3-4A5E-9DB3-0AE1785537E4"}]}]}], "references": [{"url": "https://github.com/projectacrn/acrn-hypervisor/commit/2b3dedfb9ba13f15887f22b935d373f36c9a59fa", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/projectacrn/acrn-hypervisor/commit/6199e653418eda58cd698d8769820904453e2535", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/projectacrn/acrn-hypervisor/compare/acrn-2019w25.4-140000p...acrn-2019w25.5-140000p", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/projectacrn/acrn-hypervisor/issues/3252", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/shuox/acrn-hypervisor/commit/97b153237c256c586e528eac7fc2f51aedb2b2fc", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/projectacrn/acrn-hypervisor/commit/2b3dedfb9ba13f15887f22b935d373f36c9a59fa"}}
{"buggy_code": ["import sys\nimport unicodedata\nimport unittest\nimport urllib.parse\n\nRFC1808_BASE = \"http://a/b/c/d;p?q#f\"\nRFC2396_BASE = \"http://a/b/c/d;p?q\"\nRFC3986_BASE = 'http://a/b/c/d;p?q'\nSIMPLE_BASE  = 'http://a/b/c/d'\n\n# Each parse_qsl testcase is a two-tuple that contains\n# a string with the query and a list with the expected result.\n\nparse_qsl_test_cases = [\n    (\"\", []),\n    (\"&\", []),\n    (\"&&\", []),\n    (\"=\", [('', '')]),\n    (\"=a\", [('', 'a')]),\n    (\"a\", [('a', '')]),\n    (\"a=\", [('a', '')]),\n    (\"&a=b\", [('a', 'b')]),\n    (\"a=a+b&b=b+c\", [('a', 'a b'), ('b', 'b c')]),\n    (\"a=1&a=2\", [('a', '1'), ('a', '2')]),\n    (b\"\", []),\n    (b\"&\", []),\n    (b\"&&\", []),\n    (b\"=\", [(b'', b'')]),\n    (b\"=a\", [(b'', b'a')]),\n    (b\"a\", [(b'a', b'')]),\n    (b\"a=\", [(b'a', b'')]),\n    (b\"&a=b\", [(b'a', b'b')]),\n    (b\"a=a+b&b=b+c\", [(b'a', b'a b'), (b'b', b'b c')]),\n    (b\"a=1&a=2\", [(b'a', b'1'), (b'a', b'2')]),\n    (\";\", []),\n    (\";;\", []),\n    (\";a=b\", [('a', 'b')]),\n    (\"a=a+b;b=b+c\", [('a', 'a b'), ('b', 'b c')]),\n    (\"a=1;a=2\", [('a', '1'), ('a', '2')]),\n    (b\";\", []),\n    (b\";;\", []),\n    (b\";a=b\", [(b'a', b'b')]),\n    (b\"a=a+b;b=b+c\", [(b'a', b'a b'), (b'b', b'b c')]),\n    (b\"a=1;a=2\", [(b'a', b'1'), (b'a', b'2')]),\n]\n\n# Each parse_qs testcase is a two-tuple that contains\n# a string with the query and a dictionary with the expected result.\n\nparse_qs_test_cases = [\n    (\"\", {}),\n    (\"&\", {}),\n    (\"&&\", {}),\n    (\"=\", {'': ['']}),\n    (\"=a\", {'': ['a']}),\n    (\"a\", {'a': ['']}),\n    (\"a=\", {'a': ['']}),\n    (\"&a=b\", {'a': ['b']}),\n    (\"a=a+b&b=b+c\", {'a': ['a b'], 'b': ['b c']}),\n    (\"a=1&a=2\", {'a': ['1', '2']}),\n    (b\"\", {}),\n    (b\"&\", {}),\n    (b\"&&\", {}),\n    (b\"=\", {b'': [b'']}),\n    (b\"=a\", {b'': [b'a']}),\n    (b\"a\", {b'a': [b'']}),\n    (b\"a=\", {b'a': [b'']}),\n    (b\"&a=b\", {b'a': [b'b']}),\n    (b\"a=a+b&b=b+c\", {b'a': [b'a b'], b'b': [b'b c']}),\n    (b\"a=1&a=2\", {b'a': [b'1', b'2']}),\n    (\";\", {}),\n    (\";;\", {}),\n    (\";a=b\", {'a': ['b']}),\n    (\"a=a+b;b=b+c\", {'a': ['a b'], 'b': ['b c']}),\n    (\"a=1;a=2\", {'a': ['1', '2']}),\n    (b\";\", {}),\n    (b\";;\", {}),\n    (b\";a=b\", {b'a': [b'b']}),\n    (b\"a=a+b;b=b+c\", {b'a': [b'a b'], b'b': [b'b c']}),\n    (b\"a=1;a=2\", {b'a': [b'1', b'2']}),\n]\n\nclass UrlParseTestCase(unittest.TestCase):\n\n    def checkRoundtrips(self, url, parsed, split):\n        result = urllib.parse.urlparse(url)\n        self.assertEqual(result, parsed)\n        t = (result.scheme, result.netloc, result.path,\n             result.params, result.query, result.fragment)\n        self.assertEqual(t, parsed)\n        # put it back together and it should be the same\n        result2 = urllib.parse.urlunparse(result)\n        self.assertEqual(result2, url)\n        self.assertEqual(result2, result.geturl())\n\n        # the result of geturl() is a fixpoint; we can always parse it\n        # again to get the same result:\n        result3 = urllib.parse.urlparse(result.geturl())\n        self.assertEqual(result3.geturl(), result.geturl())\n        self.assertEqual(result3,          result)\n        self.assertEqual(result3.scheme,   result.scheme)\n        self.assertEqual(result3.netloc,   result.netloc)\n        self.assertEqual(result3.path,     result.path)\n        self.assertEqual(result3.params,   result.params)\n        self.assertEqual(result3.query,    result.query)\n        self.assertEqual(result3.fragment, result.fragment)\n        self.assertEqual(result3.username, result.username)\n        self.assertEqual(result3.password, result.password)\n        self.assertEqual(result3.hostname, result.hostname)\n        self.assertEqual(result3.port,     result.port)\n\n        # check the roundtrip using urlsplit() as well\n        result = urllib.parse.urlsplit(url)\n        self.assertEqual(result, split)\n        t = (result.scheme, result.netloc, result.path,\n             result.query, result.fragment)\n        self.assertEqual(t, split)\n        result2 = urllib.parse.urlunsplit(result)\n        self.assertEqual(result2, url)\n        self.assertEqual(result2, result.geturl())\n\n        # check the fixpoint property of re-parsing the result of geturl()\n        result3 = urllib.parse.urlsplit(result.geturl())\n        self.assertEqual(result3.geturl(), result.geturl())\n        self.assertEqual(result3,          result)\n        self.assertEqual(result3.scheme,   result.scheme)\n        self.assertEqual(result3.netloc,   result.netloc)\n        self.assertEqual(result3.path,     result.path)\n        self.assertEqual(result3.query,    result.query)\n        self.assertEqual(result3.fragment, result.fragment)\n        self.assertEqual(result3.username, result.username)\n        self.assertEqual(result3.password, result.password)\n        self.assertEqual(result3.hostname, result.hostname)\n        self.assertEqual(result3.port,     result.port)\n\n    def test_qsl(self):\n        for orig, expect in parse_qsl_test_cases:\n            result = urllib.parse.parse_qsl(orig, keep_blank_values=True)\n            self.assertEqual(result, expect, \"Error parsing %r\" % orig)\n            expect_without_blanks = [v for v in expect if len(v[1])]\n            result = urllib.parse.parse_qsl(orig, keep_blank_values=False)\n            self.assertEqual(result, expect_without_blanks,\n                            \"Error parsing %r\" % orig)\n\n    def test_qs(self):\n        for orig, expect in parse_qs_test_cases:\n            result = urllib.parse.parse_qs(orig, keep_blank_values=True)\n            self.assertEqual(result, expect, \"Error parsing %r\" % orig)\n            expect_without_blanks = {v: expect[v]\n                                     for v in expect if len(expect[v][0])}\n            result = urllib.parse.parse_qs(orig, keep_blank_values=False)\n            self.assertEqual(result, expect_without_blanks,\n                            \"Error parsing %r\" % orig)\n\n    def test_roundtrips(self):\n        str_cases = [\n            ('file:///tmp/junk.txt',\n             ('file', '', '/tmp/junk.txt', '', '', ''),\n             ('file', '', '/tmp/junk.txt', '', '')),\n            ('imap://mail.python.org/mbox1',\n             ('imap', 'mail.python.org', '/mbox1', '', '', ''),\n             ('imap', 'mail.python.org', '/mbox1', '', '')),\n            ('mms://wms.sys.hinet.net/cts/Drama/09006251100.asf',\n             ('mms', 'wms.sys.hinet.net', '/cts/Drama/09006251100.asf',\n              '', '', ''),\n             ('mms', 'wms.sys.hinet.net', '/cts/Drama/09006251100.asf',\n              '', '')),\n            ('nfs://server/path/to/file.txt',\n             ('nfs', 'server', '/path/to/file.txt', '', '', ''),\n             ('nfs', 'server', '/path/to/file.txt', '', '')),\n            ('svn+ssh://svn.zope.org/repos/main/ZConfig/trunk/',\n             ('svn+ssh', 'svn.zope.org', '/repos/main/ZConfig/trunk/',\n              '', '', ''),\n             ('svn+ssh', 'svn.zope.org', '/repos/main/ZConfig/trunk/',\n              '', '')),\n            ('git+ssh://git@github.com/user/project.git',\n            ('git+ssh', 'git@github.com','/user/project.git',\n             '','',''),\n            ('git+ssh', 'git@github.com','/user/project.git',\n             '', '')),\n            ]\n        def _encode(t):\n            return (t[0].encode('ascii'),\n                    tuple(x.encode('ascii') for x in t[1]),\n                    tuple(x.encode('ascii') for x in t[2]))\n        bytes_cases = [_encode(x) for x in str_cases]\n        for url, parsed, split in str_cases + bytes_cases:\n            self.checkRoundtrips(url, parsed, split)\n\n    def test_http_roundtrips(self):\n        # urllib.parse.urlsplit treats 'http:' as an optimized special case,\n        # so we test both 'http:' and 'https:' in all the following.\n        # Three cheers for white box knowledge!\n        str_cases = [\n            ('://www.python.org',\n             ('www.python.org', '', '', '', ''),\n             ('www.python.org', '', '', '')),\n            ('://www.python.org#abc',\n             ('www.python.org', '', '', '', 'abc'),\n             ('www.python.org', '', '', 'abc')),\n            ('://www.python.org?q=abc',\n             ('www.python.org', '', '', 'q=abc', ''),\n             ('www.python.org', '', 'q=abc', '')),\n            ('://www.python.org/#abc',\n             ('www.python.org', '/', '', '', 'abc'),\n             ('www.python.org', '/', '', 'abc')),\n            ('://a/b/c/d;p?q#f',\n             ('a', '/b/c/d', 'p', 'q', 'f'),\n             ('a', '/b/c/d;p', 'q', 'f')),\n            ]\n        def _encode(t):\n            return (t[0].encode('ascii'),\n                    tuple(x.encode('ascii') for x in t[1]),\n                    tuple(x.encode('ascii') for x in t[2]))\n        bytes_cases = [_encode(x) for x in str_cases]\n        str_schemes = ('http', 'https')\n        bytes_schemes = (b'http', b'https')\n        str_tests = str_schemes, str_cases\n        bytes_tests = bytes_schemes, bytes_cases\n        for schemes, test_cases in (str_tests, bytes_tests):\n            for scheme in schemes:\n                for url, parsed, split in test_cases:\n                    url = scheme + url\n                    parsed = (scheme,) + parsed\n                    split = (scheme,) + split\n                    self.checkRoundtrips(url, parsed, split)\n\n    def checkJoin(self, base, relurl, expected):\n        str_components = (base, relurl, expected)\n        self.assertEqual(urllib.parse.urljoin(base, relurl), expected)\n        bytes_components = baseb, relurlb, expectedb = [\n                            x.encode('ascii') for x in str_components]\n        self.assertEqual(urllib.parse.urljoin(baseb, relurlb), expectedb)\n\n    def test_unparse_parse(self):\n        str_cases = ['Python', './Python','x-newscheme://foo.com/stuff','x://y','x:/y','x:/','/',]\n        bytes_cases = [x.encode('ascii') for x in str_cases]\n        for u in str_cases + bytes_cases:\n            self.assertEqual(urllib.parse.urlunsplit(urllib.parse.urlsplit(u)), u)\n            self.assertEqual(urllib.parse.urlunparse(urllib.parse.urlparse(u)), u)\n\n    def test_RFC1808(self):\n        # \"normal\" cases from RFC 1808:\n        self.checkJoin(RFC1808_BASE, 'g:h', 'g:h')\n        self.checkJoin(RFC1808_BASE, 'g', 'http://a/b/c/g')\n        self.checkJoin(RFC1808_BASE, './g', 'http://a/b/c/g')\n        self.checkJoin(RFC1808_BASE, 'g/', 'http://a/b/c/g/')\n        self.checkJoin(RFC1808_BASE, '/g', 'http://a/g')\n        self.checkJoin(RFC1808_BASE, '//g', 'http://g')\n        self.checkJoin(RFC1808_BASE, 'g?y', 'http://a/b/c/g?y')\n        self.checkJoin(RFC1808_BASE, 'g?y/./x', 'http://a/b/c/g?y/./x')\n        self.checkJoin(RFC1808_BASE, '#s', 'http://a/b/c/d;p?q#s')\n        self.checkJoin(RFC1808_BASE, 'g#s', 'http://a/b/c/g#s')\n        self.checkJoin(RFC1808_BASE, 'g#s/./x', 'http://a/b/c/g#s/./x')\n        self.checkJoin(RFC1808_BASE, 'g?y#s', 'http://a/b/c/g?y#s')\n        self.checkJoin(RFC1808_BASE, 'g;x', 'http://a/b/c/g;x')\n        self.checkJoin(RFC1808_BASE, 'g;x?y#s', 'http://a/b/c/g;x?y#s')\n        self.checkJoin(RFC1808_BASE, '.', 'http://a/b/c/')\n        self.checkJoin(RFC1808_BASE, './', 'http://a/b/c/')\n        self.checkJoin(RFC1808_BASE, '..', 'http://a/b/')\n        self.checkJoin(RFC1808_BASE, '../', 'http://a/b/')\n        self.checkJoin(RFC1808_BASE, '../g', 'http://a/b/g')\n        self.checkJoin(RFC1808_BASE, '../..', 'http://a/')\n        self.checkJoin(RFC1808_BASE, '../../', 'http://a/')\n        self.checkJoin(RFC1808_BASE, '../../g', 'http://a/g')\n\n        # \"abnormal\" cases from RFC 1808:\n        self.checkJoin(RFC1808_BASE, '', 'http://a/b/c/d;p?q#f')\n        self.checkJoin(RFC1808_BASE, 'g.', 'http://a/b/c/g.')\n        self.checkJoin(RFC1808_BASE, '.g', 'http://a/b/c/.g')\n        self.checkJoin(RFC1808_BASE, 'g..', 'http://a/b/c/g..')\n        self.checkJoin(RFC1808_BASE, '..g', 'http://a/b/c/..g')\n        self.checkJoin(RFC1808_BASE, './../g', 'http://a/b/g')\n        self.checkJoin(RFC1808_BASE, './g/.', 'http://a/b/c/g/')\n        self.checkJoin(RFC1808_BASE, 'g/./h', 'http://a/b/c/g/h')\n        self.checkJoin(RFC1808_BASE, 'g/../h', 'http://a/b/c/h')\n\n        # RFC 1808 and RFC 1630 disagree on these (according to RFC 1808),\n        # so we'll not actually run these tests (which expect 1808 behavior).\n        #self.checkJoin(RFC1808_BASE, 'http:g', 'http:g')\n        #self.checkJoin(RFC1808_BASE, 'http:', 'http:')\n\n        # XXX: The following tests are no longer compatible with RFC3986\n        # self.checkJoin(RFC1808_BASE, '../../../g', 'http://a/../g')\n        # self.checkJoin(RFC1808_BASE, '../../../../g', 'http://a/../../g')\n        # self.checkJoin(RFC1808_BASE, '/./g', 'http://a/./g')\n        # self.checkJoin(RFC1808_BASE, '/../g', 'http://a/../g')\n\n\n    def test_RFC2368(self):\n        # Issue 11467: path that starts with a number is not parsed correctly\n        self.assertEqual(urllib.parse.urlparse('mailto:1337@example.org'),\n                ('mailto', '', '1337@example.org', '', '', ''))\n\n    def test_RFC2396(self):\n        # cases from RFC 2396\n\n        self.checkJoin(RFC2396_BASE, 'g:h', 'g:h')\n        self.checkJoin(RFC2396_BASE, 'g', 'http://a/b/c/g')\n        self.checkJoin(RFC2396_BASE, './g', 'http://a/b/c/g')\n        self.checkJoin(RFC2396_BASE, 'g/', 'http://a/b/c/g/')\n        self.checkJoin(RFC2396_BASE, '/g', 'http://a/g')\n        self.checkJoin(RFC2396_BASE, '//g', 'http://g')\n        self.checkJoin(RFC2396_BASE, 'g?y', 'http://a/b/c/g?y')\n        self.checkJoin(RFC2396_BASE, '#s', 'http://a/b/c/d;p?q#s')\n        self.checkJoin(RFC2396_BASE, 'g#s', 'http://a/b/c/g#s')\n        self.checkJoin(RFC2396_BASE, 'g?y#s', 'http://a/b/c/g?y#s')\n        self.checkJoin(RFC2396_BASE, 'g;x', 'http://a/b/c/g;x')\n        self.checkJoin(RFC2396_BASE, 'g;x?y#s', 'http://a/b/c/g;x?y#s')\n        self.checkJoin(RFC2396_BASE, '.', 'http://a/b/c/')\n        self.checkJoin(RFC2396_BASE, './', 'http://a/b/c/')\n        self.checkJoin(RFC2396_BASE, '..', 'http://a/b/')\n        self.checkJoin(RFC2396_BASE, '../', 'http://a/b/')\n        self.checkJoin(RFC2396_BASE, '../g', 'http://a/b/g')\n        self.checkJoin(RFC2396_BASE, '../..', 'http://a/')\n        self.checkJoin(RFC2396_BASE, '../../', 'http://a/')\n        self.checkJoin(RFC2396_BASE, '../../g', 'http://a/g')\n        self.checkJoin(RFC2396_BASE, '', RFC2396_BASE)\n        self.checkJoin(RFC2396_BASE, 'g.', 'http://a/b/c/g.')\n        self.checkJoin(RFC2396_BASE, '.g', 'http://a/b/c/.g')\n        self.checkJoin(RFC2396_BASE, 'g..', 'http://a/b/c/g..')\n        self.checkJoin(RFC2396_BASE, '..g', 'http://a/b/c/..g')\n        self.checkJoin(RFC2396_BASE, './../g', 'http://a/b/g')\n        self.checkJoin(RFC2396_BASE, './g/.', 'http://a/b/c/g/')\n        self.checkJoin(RFC2396_BASE, 'g/./h', 'http://a/b/c/g/h')\n        self.checkJoin(RFC2396_BASE, 'g/../h', 'http://a/b/c/h')\n        self.checkJoin(RFC2396_BASE, 'g;x=1/./y', 'http://a/b/c/g;x=1/y')\n        self.checkJoin(RFC2396_BASE, 'g;x=1/../y', 'http://a/b/c/y')\n        self.checkJoin(RFC2396_BASE, 'g?y/./x', 'http://a/b/c/g?y/./x')\n        self.checkJoin(RFC2396_BASE, 'g?y/../x', 'http://a/b/c/g?y/../x')\n        self.checkJoin(RFC2396_BASE, 'g#s/./x', 'http://a/b/c/g#s/./x')\n        self.checkJoin(RFC2396_BASE, 'g#s/../x', 'http://a/b/c/g#s/../x')\n\n        # XXX: The following tests are no longer compatible with RFC3986\n        # self.checkJoin(RFC2396_BASE, '../../../g', 'http://a/../g')\n        # self.checkJoin(RFC2396_BASE, '../../../../g', 'http://a/../../g')\n        # self.checkJoin(RFC2396_BASE, '/./g', 'http://a/./g')\n        # self.checkJoin(RFC2396_BASE, '/../g', 'http://a/../g')\n\n    def test_RFC3986(self):\n        self.checkJoin(RFC3986_BASE, '?y','http://a/b/c/d;p?y')\n        self.checkJoin(RFC3986_BASE, ';x', 'http://a/b/c/;x')\n        self.checkJoin(RFC3986_BASE, 'g:h','g:h')\n        self.checkJoin(RFC3986_BASE, 'g','http://a/b/c/g')\n        self.checkJoin(RFC3986_BASE, './g','http://a/b/c/g')\n        self.checkJoin(RFC3986_BASE, 'g/','http://a/b/c/g/')\n        self.checkJoin(RFC3986_BASE, '/g','http://a/g')\n        self.checkJoin(RFC3986_BASE, '//g','http://g')\n        self.checkJoin(RFC3986_BASE, '?y','http://a/b/c/d;p?y')\n        self.checkJoin(RFC3986_BASE, 'g?y','http://a/b/c/g?y')\n        self.checkJoin(RFC3986_BASE, '#s','http://a/b/c/d;p?q#s')\n        self.checkJoin(RFC3986_BASE, 'g#s','http://a/b/c/g#s')\n        self.checkJoin(RFC3986_BASE, 'g?y#s','http://a/b/c/g?y#s')\n        self.checkJoin(RFC3986_BASE, ';x','http://a/b/c/;x')\n        self.checkJoin(RFC3986_BASE, 'g;x','http://a/b/c/g;x')\n        self.checkJoin(RFC3986_BASE, 'g;x?y#s','http://a/b/c/g;x?y#s')\n        self.checkJoin(RFC3986_BASE, '','http://a/b/c/d;p?q')\n        self.checkJoin(RFC3986_BASE, '.','http://a/b/c/')\n        self.checkJoin(RFC3986_BASE, './','http://a/b/c/')\n        self.checkJoin(RFC3986_BASE, '..','http://a/b/')\n        self.checkJoin(RFC3986_BASE, '../','http://a/b/')\n        self.checkJoin(RFC3986_BASE, '../g','http://a/b/g')\n        self.checkJoin(RFC3986_BASE, '../..','http://a/')\n        self.checkJoin(RFC3986_BASE, '../../','http://a/')\n        self.checkJoin(RFC3986_BASE, '../../g','http://a/g')\n        self.checkJoin(RFC3986_BASE, '../../../g', 'http://a/g')\n\n        # Abnormal Examples\n\n        # The 'abnormal scenarios' are incompatible with RFC2986 parsing\n        # Tests are here for reference.\n\n        self.checkJoin(RFC3986_BASE, '../../../g','http://a/g')\n        self.checkJoin(RFC3986_BASE, '../../../../g','http://a/g')\n        self.checkJoin(RFC3986_BASE, '/./g','http://a/g')\n        self.checkJoin(RFC3986_BASE, '/../g','http://a/g')\n        self.checkJoin(RFC3986_BASE, 'g.','http://a/b/c/g.')\n        self.checkJoin(RFC3986_BASE, '.g','http://a/b/c/.g')\n        self.checkJoin(RFC3986_BASE, 'g..','http://a/b/c/g..')\n        self.checkJoin(RFC3986_BASE, '..g','http://a/b/c/..g')\n        self.checkJoin(RFC3986_BASE, './../g','http://a/b/g')\n        self.checkJoin(RFC3986_BASE, './g/.','http://a/b/c/g/')\n        self.checkJoin(RFC3986_BASE, 'g/./h','http://a/b/c/g/h')\n        self.checkJoin(RFC3986_BASE, 'g/../h','http://a/b/c/h')\n        self.checkJoin(RFC3986_BASE, 'g;x=1/./y','http://a/b/c/g;x=1/y')\n        self.checkJoin(RFC3986_BASE, 'g;x=1/../y','http://a/b/c/y')\n        self.checkJoin(RFC3986_BASE, 'g?y/./x','http://a/b/c/g?y/./x')\n        self.checkJoin(RFC3986_BASE, 'g?y/../x','http://a/b/c/g?y/../x')\n        self.checkJoin(RFC3986_BASE, 'g#s/./x','http://a/b/c/g#s/./x')\n        self.checkJoin(RFC3986_BASE, 'g#s/../x','http://a/b/c/g#s/../x')\n        #self.checkJoin(RFC3986_BASE, 'http:g','http:g') # strict parser\n        self.checkJoin(RFC3986_BASE, 'http:g','http://a/b/c/g') #relaxed parser\n\n        # Test for issue9721\n        self.checkJoin('http://a/b/c/de', ';x','http://a/b/c/;x')\n\n    def test_urljoins(self):\n        self.checkJoin(SIMPLE_BASE, 'g:h','g:h')\n        self.checkJoin(SIMPLE_BASE, 'http:g','http://a/b/c/g')\n        self.checkJoin(SIMPLE_BASE, 'http:','http://a/b/c/d')\n        self.checkJoin(SIMPLE_BASE, 'g','http://a/b/c/g')\n        self.checkJoin(SIMPLE_BASE, './g','http://a/b/c/g')\n        self.checkJoin(SIMPLE_BASE, 'g/','http://a/b/c/g/')\n        self.checkJoin(SIMPLE_BASE, '/g','http://a/g')\n        self.checkJoin(SIMPLE_BASE, '//g','http://g')\n        self.checkJoin(SIMPLE_BASE, '?y','http://a/b/c/d?y')\n        self.checkJoin(SIMPLE_BASE, 'g?y','http://a/b/c/g?y')\n        self.checkJoin(SIMPLE_BASE, 'g?y/./x','http://a/b/c/g?y/./x')\n        self.checkJoin(SIMPLE_BASE, '.','http://a/b/c/')\n        self.checkJoin(SIMPLE_BASE, './','http://a/b/c/')\n        self.checkJoin(SIMPLE_BASE, '..','http://a/b/')\n        self.checkJoin(SIMPLE_BASE, '../','http://a/b/')\n        self.checkJoin(SIMPLE_BASE, '../g','http://a/b/g')\n        self.checkJoin(SIMPLE_BASE, '../..','http://a/')\n        self.checkJoin(SIMPLE_BASE, '../../g','http://a/g')\n        self.checkJoin(SIMPLE_BASE, './../g','http://a/b/g')\n        self.checkJoin(SIMPLE_BASE, './g/.','http://a/b/c/g/')\n        self.checkJoin(SIMPLE_BASE, 'g/./h','http://a/b/c/g/h')\n        self.checkJoin(SIMPLE_BASE, 'g/../h','http://a/b/c/h')\n        self.checkJoin(SIMPLE_BASE, 'http:g','http://a/b/c/g')\n        self.checkJoin(SIMPLE_BASE, 'http:','http://a/b/c/d')\n        self.checkJoin(SIMPLE_BASE, 'http:?y','http://a/b/c/d?y')\n        self.checkJoin(SIMPLE_BASE, 'http:g?y','http://a/b/c/g?y')\n        self.checkJoin(SIMPLE_BASE, 'http:g?y/./x','http://a/b/c/g?y/./x')\n        self.checkJoin('http:///', '..','http:///')\n        self.checkJoin('', 'http://a/b/c/g?y/./x','http://a/b/c/g?y/./x')\n        self.checkJoin('', 'http://a/./g', 'http://a/./g')\n        self.checkJoin('svn://pathtorepo/dir1', 'dir2', 'svn://pathtorepo/dir2')\n        self.checkJoin('svn+ssh://pathtorepo/dir1', 'dir2', 'svn+ssh://pathtorepo/dir2')\n        self.checkJoin('ws://a/b','g','ws://a/g')\n        self.checkJoin('wss://a/b','g','wss://a/g')\n\n        # XXX: The following tests are no longer compatible with RFC3986\n        # self.checkJoin(SIMPLE_BASE, '../../../g','http://a/../g')\n        # self.checkJoin(SIMPLE_BASE, '/./g','http://a/./g')\n\n        # test for issue22118 duplicate slashes\n        self.checkJoin(SIMPLE_BASE + '/', 'foo', SIMPLE_BASE + '/foo')\n\n        # Non-RFC-defined tests, covering variations of base and trailing\n        # slashes\n        self.checkJoin('http://a/b/c/d/e/', '../../f/g/', 'http://a/b/c/f/g/')\n        self.checkJoin('http://a/b/c/d/e', '../../f/g/', 'http://a/b/f/g/')\n        self.checkJoin('http://a/b/c/d/e/', '/../../f/g/', 'http://a/f/g/')\n        self.checkJoin('http://a/b/c/d/e', '/../../f/g/', 'http://a/f/g/')\n        self.checkJoin('http://a/b/c/d/e/', '../../f/g', 'http://a/b/c/f/g')\n        self.checkJoin('http://a/b/', '../../f/g/', 'http://a/f/g/')\n\n        # issue 23703: don't duplicate filename\n        self.checkJoin('a', 'b', 'b')\n\n    def test_RFC2732(self):\n        str_cases = [\n            ('http://Test.python.org:5432/foo/', 'test.python.org', 5432),\n            ('http://12.34.56.78:5432/foo/', '12.34.56.78', 5432),\n            ('http://[::1]:5432/foo/', '::1', 5432),\n            ('http://[dead:beef::1]:5432/foo/', 'dead:beef::1', 5432),\n            ('http://[dead:beef::]:5432/foo/', 'dead:beef::', 5432),\n            ('http://[dead:beef:cafe:5417:affe:8FA3:deaf:feed]:5432/foo/',\n             'dead:beef:cafe:5417:affe:8fa3:deaf:feed', 5432),\n            ('http://[::12.34.56.78]:5432/foo/', '::12.34.56.78', 5432),\n            ('http://[::ffff:12.34.56.78]:5432/foo/',\n             '::ffff:12.34.56.78', 5432),\n            ('http://Test.python.org/foo/', 'test.python.org', None),\n            ('http://12.34.56.78/foo/', '12.34.56.78', None),\n            ('http://[::1]/foo/', '::1', None),\n            ('http://[dead:beef::1]/foo/', 'dead:beef::1', None),\n            ('http://[dead:beef::]/foo/', 'dead:beef::', None),\n            ('http://[dead:beef:cafe:5417:affe:8FA3:deaf:feed]/foo/',\n             'dead:beef:cafe:5417:affe:8fa3:deaf:feed', None),\n            ('http://[::12.34.56.78]/foo/', '::12.34.56.78', None),\n            ('http://[::ffff:12.34.56.78]/foo/',\n             '::ffff:12.34.56.78', None),\n            ('http://Test.python.org:/foo/', 'test.python.org', None),\n            ('http://12.34.56.78:/foo/', '12.34.56.78', None),\n            ('http://[::1]:/foo/', '::1', None),\n            ('http://[dead:beef::1]:/foo/', 'dead:beef::1', None),\n            ('http://[dead:beef::]:/foo/', 'dead:beef::', None),\n            ('http://[dead:beef:cafe:5417:affe:8FA3:deaf:feed]:/foo/',\n             'dead:beef:cafe:5417:affe:8fa3:deaf:feed', None),\n            ('http://[::12.34.56.78]:/foo/', '::12.34.56.78', None),\n            ('http://[::ffff:12.34.56.78]:/foo/',\n             '::ffff:12.34.56.78', None),\n            ]\n        def _encode(t):\n            return t[0].encode('ascii'), t[1].encode('ascii'), t[2]\n        bytes_cases = [_encode(x) for x in str_cases]\n        for url, hostname, port in str_cases + bytes_cases:\n            urlparsed = urllib.parse.urlparse(url)\n            self.assertEqual((urlparsed.hostname, urlparsed.port) , (hostname, port))\n\n        str_cases = [\n                'http://::12.34.56.78]/',\n                'http://[::1/foo/',\n                'ftp://[::1/foo/bad]/bad',\n                'http://[::1/foo/bad]/bad',\n                'http://[::ffff:12.34.56.78']\n        bytes_cases = [x.encode('ascii') for x in str_cases]\n        for invalid_url in str_cases + bytes_cases:\n            self.assertRaises(ValueError, urllib.parse.urlparse, invalid_url)\n\n    def test_urldefrag(self):\n        str_cases = [\n            ('http://python.org#frag', 'http://python.org', 'frag'),\n            ('http://python.org', 'http://python.org', ''),\n            ('http://python.org/#frag', 'http://python.org/', 'frag'),\n            ('http://python.org/', 'http://python.org/', ''),\n            ('http://python.org/?q#frag', 'http://python.org/?q', 'frag'),\n            ('http://python.org/?q', 'http://python.org/?q', ''),\n            ('http://python.org/p#frag', 'http://python.org/p', 'frag'),\n            ('http://python.org/p?q', 'http://python.org/p?q', ''),\n            (RFC1808_BASE, 'http://a/b/c/d;p?q', 'f'),\n            (RFC2396_BASE, 'http://a/b/c/d;p?q', ''),\n        ]\n        def _encode(t):\n            return type(t)(x.encode('ascii') for x in t)\n        bytes_cases = [_encode(x) for x in str_cases]\n        for url, defrag, frag in str_cases + bytes_cases:\n            result = urllib.parse.urldefrag(url)\n            self.assertEqual(result.geturl(), url)\n            self.assertEqual(result, (defrag, frag))\n            self.assertEqual(result.url, defrag)\n            self.assertEqual(result.fragment, frag)\n\n    def test_urlsplit_scoped_IPv6(self):\n        p = urllib.parse.urlsplit('http://[FE80::822a:a8ff:fe49:470c%tESt]:1234')\n        self.assertEqual(p.hostname, \"fe80::822a:a8ff:fe49:470c%tESt\")\n        self.assertEqual(p.netloc, '[FE80::822a:a8ff:fe49:470c%tESt]:1234')\n\n        p = urllib.parse.urlsplit(b'http://[FE80::822a:a8ff:fe49:470c%tESt]:1234')\n        self.assertEqual(p.hostname, b\"fe80::822a:a8ff:fe49:470c%tESt\")\n        self.assertEqual(p.netloc, b'[FE80::822a:a8ff:fe49:470c%tESt]:1234')\n\n    def test_urlsplit_attributes(self):\n        url = \"HTTP://WWW.PYTHON.ORG/doc/#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, \"http\")\n        self.assertEqual(p.netloc, \"WWW.PYTHON.ORG\")\n        self.assertEqual(p.path, \"/doc/\")\n        self.assertEqual(p.query, \"\")\n        self.assertEqual(p.fragment, \"frag\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, \"www.python.org\")\n        self.assertEqual(p.port, None)\n        # geturl() won't return exactly the original URL in this case\n        # since the scheme is always case-normalized\n        # We handle this by ignoring the first 4 characters of the URL\n        self.assertEqual(p.geturl()[4:], url[4:])\n\n        url = \"http://User:Pass@www.python.org:080/doc/?query=yes#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, \"http\")\n        self.assertEqual(p.netloc, \"User:Pass@www.python.org:080\")\n        self.assertEqual(p.path, \"/doc/\")\n        self.assertEqual(p.query, \"query=yes\")\n        self.assertEqual(p.fragment, \"frag\")\n        self.assertEqual(p.username, \"User\")\n        self.assertEqual(p.password, \"Pass\")\n        self.assertEqual(p.hostname, \"www.python.org\")\n        self.assertEqual(p.port, 80)\n        self.assertEqual(p.geturl(), url)\n\n        # Addressing issue1698, which suggests Username can contain\n        # \"@\" characters.  Though not RFC compliant, many ftp sites allow\n        # and request email addresses as usernames.\n\n        url = \"http://User@example.com:Pass@www.python.org:080/doc/?query=yes#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, \"http\")\n        self.assertEqual(p.netloc, \"User@example.com:Pass@www.python.org:080\")\n        self.assertEqual(p.path, \"/doc/\")\n        self.assertEqual(p.query, \"query=yes\")\n        self.assertEqual(p.fragment, \"frag\")\n        self.assertEqual(p.username, \"User@example.com\")\n        self.assertEqual(p.password, \"Pass\")\n        self.assertEqual(p.hostname, \"www.python.org\")\n        self.assertEqual(p.port, 80)\n        self.assertEqual(p.geturl(), url)\n\n        # And check them all again, only with bytes this time\n        url = b\"HTTP://WWW.PYTHON.ORG/doc/#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, b\"http\")\n        self.assertEqual(p.netloc, b\"WWW.PYTHON.ORG\")\n        self.assertEqual(p.path, b\"/doc/\")\n        self.assertEqual(p.query, b\"\")\n        self.assertEqual(p.fragment, b\"frag\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, b\"www.python.org\")\n        self.assertEqual(p.port, None)\n        self.assertEqual(p.geturl()[4:], url[4:])\n\n        url = b\"http://User:Pass@www.python.org:080/doc/?query=yes#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, b\"http\")\n        self.assertEqual(p.netloc, b\"User:Pass@www.python.org:080\")\n        self.assertEqual(p.path, b\"/doc/\")\n        self.assertEqual(p.query, b\"query=yes\")\n        self.assertEqual(p.fragment, b\"frag\")\n        self.assertEqual(p.username, b\"User\")\n        self.assertEqual(p.password, b\"Pass\")\n        self.assertEqual(p.hostname, b\"www.python.org\")\n        self.assertEqual(p.port, 80)\n        self.assertEqual(p.geturl(), url)\n\n        url = b\"http://User@example.com:Pass@www.python.org:080/doc/?query=yes#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, b\"http\")\n        self.assertEqual(p.netloc, b\"User@example.com:Pass@www.python.org:080\")\n        self.assertEqual(p.path, b\"/doc/\")\n        self.assertEqual(p.query, b\"query=yes\")\n        self.assertEqual(p.fragment, b\"frag\")\n        self.assertEqual(p.username, b\"User@example.com\")\n        self.assertEqual(p.password, b\"Pass\")\n        self.assertEqual(p.hostname, b\"www.python.org\")\n        self.assertEqual(p.port, 80)\n        self.assertEqual(p.geturl(), url)\n\n        # Verify an illegal port raises ValueError\n        url = b\"HTTP://WWW.PYTHON.ORG:65536/doc/#frag\"\n        p = urllib.parse.urlsplit(url)\n        with self.assertRaisesRegex(ValueError, \"out of range\"):\n            p.port\n\n    def test_attributes_bad_port(self):\n        \"\"\"Check handling of invalid ports.\"\"\"\n        for bytes in (False, True):\n            for parse in (urllib.parse.urlsplit, urllib.parse.urlparse):\n                for port in (\"foo\", \"1.5\", \"-1\", \"0x10\"):\n                    with self.subTest(bytes=bytes, parse=parse, port=port):\n                        netloc = \"www.example.net:\" + port\n                        url = \"http://\" + netloc\n                        if bytes:\n                            netloc = netloc.encode(\"ascii\")\n                            url = url.encode(\"ascii\")\n                        p = parse(url)\n                        self.assertEqual(p.netloc, netloc)\n                        with self.assertRaises(ValueError):\n                            p.port\n\n    def test_attributes_without_netloc(self):\n        # This example is straight from RFC 3261.  It looks like it\n        # should allow the username, hostname, and port to be filled\n        # in, but doesn't.  Since it's a URI and doesn't use the\n        # scheme://netloc syntax, the netloc and related attributes\n        # should be left empty.\n        uri = \"sip:alice@atlanta.com;maddr=239.255.255.1;ttl=15\"\n        p = urllib.parse.urlsplit(uri)\n        self.assertEqual(p.netloc, \"\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, None)\n        self.assertEqual(p.port, None)\n        self.assertEqual(p.geturl(), uri)\n\n        p = urllib.parse.urlparse(uri)\n        self.assertEqual(p.netloc, \"\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, None)\n        self.assertEqual(p.port, None)\n        self.assertEqual(p.geturl(), uri)\n\n        # You guessed it, repeating the test with bytes input\n        uri = b\"sip:alice@atlanta.com;maddr=239.255.255.1;ttl=15\"\n        p = urllib.parse.urlsplit(uri)\n        self.assertEqual(p.netloc, b\"\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, None)\n        self.assertEqual(p.port, None)\n        self.assertEqual(p.geturl(), uri)\n\n        p = urllib.parse.urlparse(uri)\n        self.assertEqual(p.netloc, b\"\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, None)\n        self.assertEqual(p.port, None)\n        self.assertEqual(p.geturl(), uri)\n\n    def test_noslash(self):\n        # Issue 1637: http://foo.com?query is legal\n        self.assertEqual(urllib.parse.urlparse(\"http://example.com?blahblah=/foo\"),\n                         ('http', 'example.com', '', '', 'blahblah=/foo', ''))\n        self.assertEqual(urllib.parse.urlparse(b\"http://example.com?blahblah=/foo\"),\n                         (b'http', b'example.com', b'', b'', b'blahblah=/foo', b''))\n\n    def test_withoutscheme(self):\n        # Test urlparse without scheme\n        # Issue 754016: urlparse goes wrong with IP:port without scheme\n        # RFC 1808 specifies that netloc should start with //, urlparse expects\n        # the same, otherwise it classifies the portion of url as path.\n        self.assertEqual(urllib.parse.urlparse(\"path\"),\n                ('','','path','','',''))\n        self.assertEqual(urllib.parse.urlparse(\"//www.python.org:80\"),\n                ('','www.python.org:80','','','',''))\n        self.assertEqual(urllib.parse.urlparse(\"http://www.python.org:80\"),\n                ('http','www.python.org:80','','','',''))\n        # Repeat for bytes input\n        self.assertEqual(urllib.parse.urlparse(b\"path\"),\n                (b'',b'',b'path',b'',b'',b''))\n        self.assertEqual(urllib.parse.urlparse(b\"//www.python.org:80\"),\n                (b'',b'www.python.org:80',b'',b'',b'',b''))\n        self.assertEqual(urllib.parse.urlparse(b\"http://www.python.org:80\"),\n                (b'http',b'www.python.org:80',b'',b'',b'',b''))\n\n    def test_portseparator(self):\n        # Issue 754016 makes changes for port separator ':' from scheme separator\n        self.assertEqual(urllib.parse.urlparse(\"path:80\"),\n                ('','','path:80','','',''))\n        self.assertEqual(urllib.parse.urlparse(\"http:\"),('http','','','','',''))\n        self.assertEqual(urllib.parse.urlparse(\"https:\"),('https','','','','',''))\n        self.assertEqual(urllib.parse.urlparse(\"http://www.python.org:80\"),\n                ('http','www.python.org:80','','','',''))\n        # As usual, need to check bytes input as well\n        self.assertEqual(urllib.parse.urlparse(b\"path:80\"),\n                (b'',b'',b'path:80',b'',b'',b''))\n        self.assertEqual(urllib.parse.urlparse(b\"http:\"),(b'http',b'',b'',b'',b'',b''))\n        self.assertEqual(urllib.parse.urlparse(b\"https:\"),(b'https',b'',b'',b'',b'',b''))\n        self.assertEqual(urllib.parse.urlparse(b\"http://www.python.org:80\"),\n                (b'http',b'www.python.org:80',b'',b'',b'',b''))\n\n    def test_usingsys(self):\n        # Issue 3314: sys module is used in the error\n        self.assertRaises(TypeError, urllib.parse.urlencode, \"foo\")\n\n    def test_anyscheme(self):\n        # Issue 7904: s3://foo.com/stuff has netloc \"foo.com\".\n        self.assertEqual(urllib.parse.urlparse(\"s3://foo.com/stuff\"),\n                         ('s3', 'foo.com', '/stuff', '', '', ''))\n        self.assertEqual(urllib.parse.urlparse(\"x-newscheme://foo.com/stuff\"),\n                         ('x-newscheme', 'foo.com', '/stuff', '', '', ''))\n        self.assertEqual(urllib.parse.urlparse(\"x-newscheme://foo.com/stuff?query#fragment\"),\n                         ('x-newscheme', 'foo.com', '/stuff', '', 'query', 'fragment'))\n        self.assertEqual(urllib.parse.urlparse(\"x-newscheme://foo.com/stuff?query\"),\n                         ('x-newscheme', 'foo.com', '/stuff', '', 'query', ''))\n\n        # And for bytes...\n        self.assertEqual(urllib.parse.urlparse(b\"s3://foo.com/stuff\"),\n                         (b's3', b'foo.com', b'/stuff', b'', b'', b''))\n        self.assertEqual(urllib.parse.urlparse(b\"x-newscheme://foo.com/stuff\"),\n                         (b'x-newscheme', b'foo.com', b'/stuff', b'', b'', b''))\n        self.assertEqual(urllib.parse.urlparse(b\"x-newscheme://foo.com/stuff?query#fragment\"),\n                         (b'x-newscheme', b'foo.com', b'/stuff', b'', b'query', b'fragment'))\n        self.assertEqual(urllib.parse.urlparse(b\"x-newscheme://foo.com/stuff?query\"),\n                         (b'x-newscheme', b'foo.com', b'/stuff', b'', b'query', b''))\n\n    def test_default_scheme(self):\n        # Exercise the scheme parameter of urlparse() and urlsplit()\n        for func in (urllib.parse.urlparse, urllib.parse.urlsplit):\n            with self.subTest(function=func):\n                result = func(\"http://example.net/\", \"ftp\")\n                self.assertEqual(result.scheme, \"http\")\n                result = func(b\"http://example.net/\", b\"ftp\")\n                self.assertEqual(result.scheme, b\"http\")\n                self.assertEqual(func(\"path\", \"ftp\").scheme, \"ftp\")\n                self.assertEqual(func(\"path\", scheme=\"ftp\").scheme, \"ftp\")\n                self.assertEqual(func(b\"path\", scheme=b\"ftp\").scheme, b\"ftp\")\n                self.assertEqual(func(\"path\").scheme, \"\")\n                self.assertEqual(func(b\"path\").scheme, b\"\")\n                self.assertEqual(func(b\"path\", \"\").scheme, b\"\")\n\n    def test_parse_fragments(self):\n        # Exercise the allow_fragments parameter of urlparse() and urlsplit()\n        tests = (\n            (\"http:#frag\", \"path\", \"frag\"),\n            (\"//example.net#frag\", \"path\", \"frag\"),\n            (\"index.html#frag\", \"path\", \"frag\"),\n            (\";a=b#frag\", \"params\", \"frag\"),\n            (\"?a=b#frag\", \"query\", \"frag\"),\n            (\"#frag\", \"path\", \"frag\"),\n            (\"abc#@frag\", \"path\", \"@frag\"),\n            (\"//abc#@frag\", \"path\", \"@frag\"),\n            (\"//abc:80#@frag\", \"path\", \"@frag\"),\n            (\"//abc#@frag:80\", \"path\", \"@frag:80\"),\n        )\n        for url, attr, expected_frag in tests:\n            for func in (urllib.parse.urlparse, urllib.parse.urlsplit):\n                if attr == \"params\" and func is urllib.parse.urlsplit:\n                    attr = \"path\"\n                with self.subTest(url=url, function=func):\n                    result = func(url, allow_fragments=False)\n                    self.assertEqual(result.fragment, \"\")\n                    self.assertTrue(\n                            getattr(result, attr).endswith(\"#\" + expected_frag))\n                    self.assertEqual(func(url, \"\", False).fragment, \"\")\n\n                    result = func(url, allow_fragments=True)\n                    self.assertEqual(result.fragment, expected_frag)\n                    self.assertFalse(\n                            getattr(result, attr).endswith(expected_frag))\n                    self.assertEqual(func(url, \"\", True).fragment,\n                                     expected_frag)\n                    self.assertEqual(func(url).fragment, expected_frag)\n\n    def test_mixed_types_rejected(self):\n        # Several functions that process either strings or ASCII encoded bytes\n        # accept multiple arguments. Check they reject mixed type input\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlparse(\"www.python.org\", b\"http\")\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlparse(b\"www.python.org\", \"http\")\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlsplit(\"www.python.org\", b\"http\")\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlsplit(b\"www.python.org\", \"http\")\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlunparse(( b\"http\", \"www.python.org\",\"\",\"\",\"\",\"\"))\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlunparse((\"http\", b\"www.python.org\",\"\",\"\",\"\",\"\"))\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlunsplit((b\"http\", \"www.python.org\",\"\",\"\",\"\"))\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlunsplit((\"http\", b\"www.python.org\",\"\",\"\",\"\"))\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urljoin(\"http://python.org\", b\"http://python.org\")\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urljoin(b\"http://python.org\", \"http://python.org\")\n\n    def _check_result_type(self, str_type):\n        num_args = len(str_type._fields)\n        bytes_type = str_type._encoded_counterpart\n        self.assertIs(bytes_type._decoded_counterpart, str_type)\n        str_args = ('',) * num_args\n        bytes_args = (b'',) * num_args\n        str_result = str_type(*str_args)\n        bytes_result = bytes_type(*bytes_args)\n        encoding = 'ascii'\n        errors = 'strict'\n        self.assertEqual(str_result, str_args)\n        self.assertEqual(bytes_result.decode(), str_args)\n        self.assertEqual(bytes_result.decode(), str_result)\n        self.assertEqual(bytes_result.decode(encoding), str_args)\n        self.assertEqual(bytes_result.decode(encoding), str_result)\n        self.assertEqual(bytes_result.decode(encoding, errors), str_args)\n        self.assertEqual(bytes_result.decode(encoding, errors), str_result)\n        self.assertEqual(bytes_result, bytes_args)\n        self.assertEqual(str_result.encode(), bytes_args)\n        self.assertEqual(str_result.encode(), bytes_result)\n        self.assertEqual(str_result.encode(encoding), bytes_args)\n        self.assertEqual(str_result.encode(encoding), bytes_result)\n        self.assertEqual(str_result.encode(encoding, errors), bytes_args)\n        self.assertEqual(str_result.encode(encoding, errors), bytes_result)\n\n    def test_result_pairs(self):\n        # Check encoding and decoding between result pairs\n        result_types = [\n          urllib.parse.DefragResult,\n          urllib.parse.SplitResult,\n          urllib.parse.ParseResult,\n        ]\n        for result_type in result_types:\n            self._check_result_type(result_type)\n\n    def test_parse_qs_encoding(self):\n        result = urllib.parse.parse_qs(\"key=\\u0141%E9\", encoding=\"latin-1\")\n        self.assertEqual(result, {'key': ['\\u0141\\xE9']})\n        result = urllib.parse.parse_qs(\"key=\\u0141%C3%A9\", encoding=\"utf-8\")\n        self.assertEqual(result, {'key': ['\\u0141\\xE9']})\n        result = urllib.parse.parse_qs(\"key=\\u0141%C3%A9\", encoding=\"ascii\")\n        self.assertEqual(result, {'key': ['\\u0141\\ufffd\\ufffd']})\n        result = urllib.parse.parse_qs(\"key=\\u0141%E9-\", encoding=\"ascii\")\n        self.assertEqual(result, {'key': ['\\u0141\\ufffd-']})\n        result = urllib.parse.parse_qs(\"key=\\u0141%E9-\", encoding=\"ascii\",\n                                                          errors=\"ignore\")\n        self.assertEqual(result, {'key': ['\\u0141-']})\n\n    def test_parse_qsl_encoding(self):\n        result = urllib.parse.parse_qsl(\"key=\\u0141%E9\", encoding=\"latin-1\")\n        self.assertEqual(result, [('key', '\\u0141\\xE9')])\n        result = urllib.parse.parse_qsl(\"key=\\u0141%C3%A9\", encoding=\"utf-8\")\n        self.assertEqual(result, [('key', '\\u0141\\xE9')])\n        result = urllib.parse.parse_qsl(\"key=\\u0141%C3%A9\", encoding=\"ascii\")\n        self.assertEqual(result, [('key', '\\u0141\\ufffd\\ufffd')])\n        result = urllib.parse.parse_qsl(\"key=\\u0141%E9-\", encoding=\"ascii\")\n        self.assertEqual(result, [('key', '\\u0141\\ufffd-')])\n        result = urllib.parse.parse_qsl(\"key=\\u0141%E9-\", encoding=\"ascii\",\n                                                          errors=\"ignore\")\n        self.assertEqual(result, [('key', '\\u0141-')])\n\n    def test_parse_qsl_max_num_fields(self):\n        with self.assertRaises(ValueError):\n            urllib.parse.parse_qs('&'.join(['a=a']*11), max_num_fields=10)\n        with self.assertRaises(ValueError):\n            urllib.parse.parse_qs(';'.join(['a=a']*11), max_num_fields=10)\n        urllib.parse.parse_qs('&'.join(['a=a']*10), max_num_fields=10)\n\n    def test_urlencode_sequences(self):\n        # Other tests incidentally urlencode things; test non-covered cases:\n        # Sequence and object values.\n        result = urllib.parse.urlencode({'a': [1, 2], 'b': (3, 4, 5)}, True)\n        # we cannot rely on ordering here\n        assert set(result.split('&')) == {'a=1', 'a=2', 'b=3', 'b=4', 'b=5'}\n\n        class Trivial:\n            def __str__(self):\n                return 'trivial'\n\n        result = urllib.parse.urlencode({'a': Trivial()}, True)\n        self.assertEqual(result, 'a=trivial')\n\n    def test_urlencode_quote_via(self):\n        result = urllib.parse.urlencode({'a': 'some value'})\n        self.assertEqual(result, \"a=some+value\")\n        result = urllib.parse.urlencode({'a': 'some value/another'},\n                                        quote_via=urllib.parse.quote)\n        self.assertEqual(result, \"a=some%20value%2Fanother\")\n        result = urllib.parse.urlencode({'a': 'some value/another'},\n                                        safe='/', quote_via=urllib.parse.quote)\n        self.assertEqual(result, \"a=some%20value/another\")\n\n    def test_quote_from_bytes(self):\n        self.assertRaises(TypeError, urllib.parse.quote_from_bytes, 'foo')\n        result = urllib.parse.quote_from_bytes(b'archaeological arcana')\n        self.assertEqual(result, 'archaeological%20arcana')\n        result = urllib.parse.quote_from_bytes(b'')\n        self.assertEqual(result, '')\n\n    def test_unquote_to_bytes(self):\n        result = urllib.parse.unquote_to_bytes('abc%20def')\n        self.assertEqual(result, b'abc def')\n        result = urllib.parse.unquote_to_bytes('')\n        self.assertEqual(result, b'')\n\n    def test_quote_errors(self):\n        self.assertRaises(TypeError, urllib.parse.quote, b'foo',\n                          encoding='utf-8')\n        self.assertRaises(TypeError, urllib.parse.quote, b'foo', errors='strict')\n\n    def test_issue14072(self):\n        p1 = urllib.parse.urlsplit('tel:+31-641044153')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '+31-641044153')\n        p2 = urllib.parse.urlsplit('tel:+31641044153')\n        self.assertEqual(p2.scheme, 'tel')\n        self.assertEqual(p2.path, '+31641044153')\n        # assert the behavior for urlparse\n        p1 = urllib.parse.urlparse('tel:+31-641044153')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '+31-641044153')\n        p2 = urllib.parse.urlparse('tel:+31641044153')\n        self.assertEqual(p2.scheme, 'tel')\n        self.assertEqual(p2.path, '+31641044153')\n\n    def test_telurl_params(self):\n        p1 = urllib.parse.urlparse('tel:123-4;phone-context=+1-650-516')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '123-4')\n        self.assertEqual(p1.params, 'phone-context=+1-650-516')\n\n        p1 = urllib.parse.urlparse('tel:+1-201-555-0123')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '+1-201-555-0123')\n        self.assertEqual(p1.params, '')\n\n        p1 = urllib.parse.urlparse('tel:7042;phone-context=example.com')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '7042')\n        self.assertEqual(p1.params, 'phone-context=example.com')\n\n        p1 = urllib.parse.urlparse('tel:863-1234;phone-context=+1-914-555')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '863-1234')\n        self.assertEqual(p1.params, 'phone-context=+1-914-555')\n\n    def test_Quoter_repr(self):\n        quoter = urllib.parse.Quoter(urllib.parse._ALWAYS_SAFE)\n        self.assertIn('Quoter', repr(quoter))\n\n    def test_all(self):\n        expected = []\n        undocumented = {\n            'splitattr', 'splithost', 'splitnport', 'splitpasswd',\n            'splitport', 'splitquery', 'splittag', 'splittype', 'splituser',\n            'splitvalue',\n            'Quoter', 'ResultBase', 'clear_cache', 'to_bytes', 'unwrap',\n        }\n        for name in dir(urllib.parse):\n            if name.startswith('_') or name in undocumented:\n                continue\n            object = getattr(urllib.parse, name)\n            if getattr(object, '__module__', None) == 'urllib.parse':\n                expected.append(name)\n        self.assertCountEqual(urllib.parse.__all__, expected)\n\n    def test_urlsplit_normalization(self):\n        # Certain characters should never occur in the netloc,\n        # including under normalization.\n        # Ensure that ALL of them are detected and cause an error\n        illegal_chars = '/:#?@'\n        hex_chars = {'{:04X}'.format(ord(c)) for c in illegal_chars}\n        denorm_chars = [\n            c for c in map(chr, range(128, sys.maxunicode))\n            if (hex_chars & set(unicodedata.decomposition(c).split()))\n            and c not in illegal_chars\n        ]\n        # Sanity check that we found at least one such character\n        self.assertIn('\\u2100', denorm_chars)\n        self.assertIn('\\uFF03', denorm_chars)\n\n        # bpo-36742: Verify port separators are ignored when they\n        # existed prior to decomposition\n        urllib.parse.urlsplit('http://\\u30d5\\u309a:80')\n        with self.assertRaises(ValueError):\n            urllib.parse.urlsplit('http://\\u30d5\\u309a\\ufe1380')\n\n        for scheme in [\"http\", \"https\", \"ftp\"]:\n            for c in denorm_chars:\n                url = \"{}://netloc{}false.netloc/path\".format(scheme, c)\n                with self.subTest(url=url, char='{:04X}'.format(ord(c))):\n                    with self.assertRaises(ValueError):\n                        urllib.parse.urlsplit(url)\n\nclass Utility_Tests(unittest.TestCase):\n    \"\"\"Testcase to test the various utility functions in the urllib.\"\"\"\n    # In Python 2 this test class was in test_urllib.\n\n    def test_splittype(self):\n        splittype = urllib.parse.splittype\n        self.assertEqual(splittype('type:opaquestring'), ('type', 'opaquestring'))\n        self.assertEqual(splittype('opaquestring'), (None, 'opaquestring'))\n        self.assertEqual(splittype(':opaquestring'), (None, ':opaquestring'))\n        self.assertEqual(splittype('type:'), ('type', ''))\n        self.assertEqual(splittype('type:opaque:string'), ('type', 'opaque:string'))\n\n    def test_splithost(self):\n        splithost = urllib.parse.splithost\n        self.assertEqual(splithost('//www.example.org:80/foo/bar/baz.html'),\n                         ('www.example.org:80', '/foo/bar/baz.html'))\n        self.assertEqual(splithost('//www.example.org:80'),\n                         ('www.example.org:80', ''))\n        self.assertEqual(splithost('/foo/bar/baz.html'),\n                         (None, '/foo/bar/baz.html'))\n\n        # bpo-30500: # starts a fragment.\n        self.assertEqual(splithost('//127.0.0.1#@host.com'),\n                         ('127.0.0.1', '/#@host.com'))\n        self.assertEqual(splithost('//127.0.0.1#@host.com:80'),\n                         ('127.0.0.1', '/#@host.com:80'))\n        self.assertEqual(splithost('//127.0.0.1:80#@host.com'),\n                         ('127.0.0.1:80', '/#@host.com'))\n\n        # Empty host is returned as empty string.\n        self.assertEqual(splithost(\"///file\"),\n                         ('', '/file'))\n\n        # Trailing semicolon, question mark and hash symbol are kept.\n        self.assertEqual(splithost(\"//example.net/file;\"),\n                         ('example.net', '/file;'))\n        self.assertEqual(splithost(\"//example.net/file?\"),\n                         ('example.net', '/file?'))\n        self.assertEqual(splithost(\"//example.net/file#\"),\n                         ('example.net', '/file#'))\n\n    def test_splituser(self):\n        splituser = urllib.parse.splituser\n        self.assertEqual(splituser('User:Pass@www.python.org:080'),\n                         ('User:Pass', 'www.python.org:080'))\n        self.assertEqual(splituser('@www.python.org:080'),\n                         ('', 'www.python.org:080'))\n        self.assertEqual(splituser('www.python.org:080'),\n                         (None, 'www.python.org:080'))\n        self.assertEqual(splituser('User:Pass@'),\n                         ('User:Pass', ''))\n        self.assertEqual(splituser('User@example.com:Pass@www.python.org:080'),\n                         ('User@example.com:Pass', 'www.python.org:080'))\n\n    def test_splitpasswd(self):\n        # Some of the password examples are not sensible, but it is added to\n        # confirming to RFC2617 and addressing issue4675.\n        splitpasswd = urllib.parse.splitpasswd\n        self.assertEqual(splitpasswd('user:ab'), ('user', 'ab'))\n        self.assertEqual(splitpasswd('user:a\\nb'), ('user', 'a\\nb'))\n        self.assertEqual(splitpasswd('user:a\\tb'), ('user', 'a\\tb'))\n        self.assertEqual(splitpasswd('user:a\\rb'), ('user', 'a\\rb'))\n        self.assertEqual(splitpasswd('user:a\\fb'), ('user', 'a\\fb'))\n        self.assertEqual(splitpasswd('user:a\\vb'), ('user', 'a\\vb'))\n        self.assertEqual(splitpasswd('user:a:b'), ('user', 'a:b'))\n        self.assertEqual(splitpasswd('user:a b'), ('user', 'a b'))\n        self.assertEqual(splitpasswd('user 2:ab'), ('user 2', 'ab'))\n        self.assertEqual(splitpasswd('user+1:a+b'), ('user+1', 'a+b'))\n        self.assertEqual(splitpasswd('user:'), ('user', ''))\n        self.assertEqual(splitpasswd('user'), ('user', None))\n        self.assertEqual(splitpasswd(':ab'), ('', 'ab'))\n\n    def test_splitport(self):\n        splitport = urllib.parse.splitport\n        self.assertEqual(splitport('parrot:88'), ('parrot', '88'))\n        self.assertEqual(splitport('parrot'), ('parrot', None))\n        self.assertEqual(splitport('parrot:'), ('parrot', None))\n        self.assertEqual(splitport('127.0.0.1'), ('127.0.0.1', None))\n        self.assertEqual(splitport('parrot:cheese'), ('parrot:cheese', None))\n        self.assertEqual(splitport('[::1]:88'), ('[::1]', '88'))\n        self.assertEqual(splitport('[::1]'), ('[::1]', None))\n        self.assertEqual(splitport(':88'), ('', '88'))\n\n    def test_splitnport(self):\n        splitnport = urllib.parse.splitnport\n        self.assertEqual(splitnport('parrot:88'), ('parrot', 88))\n        self.assertEqual(splitnport('parrot'), ('parrot', -1))\n        self.assertEqual(splitnport('parrot', 55), ('parrot', 55))\n        self.assertEqual(splitnport('parrot:'), ('parrot', -1))\n        self.assertEqual(splitnport('parrot:', 55), ('parrot', 55))\n        self.assertEqual(splitnport('127.0.0.1'), ('127.0.0.1', -1))\n        self.assertEqual(splitnport('127.0.0.1', 55), ('127.0.0.1', 55))\n        self.assertEqual(splitnport('parrot:cheese'), ('parrot', None))\n        self.assertEqual(splitnport('parrot:cheese', 55), ('parrot', None))\n\n    def test_splitquery(self):\n        # Normal cases are exercised by other tests; ensure that we also\n        # catch cases with no port specified (testcase ensuring coverage)\n        splitquery = urllib.parse.splitquery\n        self.assertEqual(splitquery('http://python.org/fake?foo=bar'),\n                         ('http://python.org/fake', 'foo=bar'))\n        self.assertEqual(splitquery('http://python.org/fake?foo=bar?'),\n                         ('http://python.org/fake?foo=bar', ''))\n        self.assertEqual(splitquery('http://python.org/fake'),\n                         ('http://python.org/fake', None))\n        self.assertEqual(splitquery('?foo=bar'), ('', 'foo=bar'))\n\n    def test_splittag(self):\n        splittag = urllib.parse.splittag\n        self.assertEqual(splittag('http://example.com?foo=bar#baz'),\n                         ('http://example.com?foo=bar', 'baz'))\n        self.assertEqual(splittag('http://example.com?foo=bar#'),\n                         ('http://example.com?foo=bar', ''))\n        self.assertEqual(splittag('#baz'), ('', 'baz'))\n        self.assertEqual(splittag('http://example.com?foo=bar'),\n                         ('http://example.com?foo=bar', None))\n        self.assertEqual(splittag('http://example.com?foo=bar#baz#boo'),\n                         ('http://example.com?foo=bar#baz', 'boo'))\n\n    def test_splitattr(self):\n        splitattr = urllib.parse.splitattr\n        self.assertEqual(splitattr('/path;attr1=value1;attr2=value2'),\n                         ('/path', ['attr1=value1', 'attr2=value2']))\n        self.assertEqual(splitattr('/path;'), ('/path', ['']))\n        self.assertEqual(splitattr(';attr1=value1;attr2=value2'),\n                         ('', ['attr1=value1', 'attr2=value2']))\n        self.assertEqual(splitattr('/path'), ('/path', []))\n\n    def test_splitvalue(self):\n        # Normal cases are exercised by other tests; test pathological cases\n        # with no key/value pairs. (testcase ensuring coverage)\n        splitvalue = urllib.parse.splitvalue\n        self.assertEqual(splitvalue('foo=bar'), ('foo', 'bar'))\n        self.assertEqual(splitvalue('foo='), ('foo', ''))\n        self.assertEqual(splitvalue('=bar'), ('', 'bar'))\n        self.assertEqual(splitvalue('foobar'), ('foobar', None))\n        self.assertEqual(splitvalue('foo=bar=baz'), ('foo', 'bar=baz'))\n\n    def test_to_bytes(self):\n        result = urllib.parse.to_bytes('http://www.python.org')\n        self.assertEqual(result, 'http://www.python.org')\n        self.assertRaises(UnicodeError, urllib.parse.to_bytes,\n                          'http://www.python.org/medi\\u00e6val')\n\n    def test_unwrap(self):\n        url = urllib.parse.unwrap('<URL:type://host/path>')\n        self.assertEqual(url, 'type://host/path')\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "\"\"\"Parse (absolute and relative) URLs.\n\nurlparse module is based upon the following RFC specifications.\n\nRFC 3986 (STD66): \"Uniform Resource Identifiers\" by T. Berners-Lee, R. Fielding\nand L.  Masinter, January 2005.\n\nRFC 2732 : \"Format for Literal IPv6 Addresses in URL's by R.Hinden, B.Carpenter\nand L.Masinter, December 1999.\n\nRFC 2396:  \"Uniform Resource Identifiers (URI)\": Generic Syntax by T.\nBerners-Lee, R. Fielding, and L. Masinter, August 1998.\n\nRFC 2368: \"The mailto URL scheme\", by P.Hoffman , L Masinter, J. Zawinski, July 1998.\n\nRFC 1808: \"Relative Uniform Resource Locators\", by R. Fielding, UC Irvine, June\n1995.\n\nRFC 1738: \"Uniform Resource Locators (URL)\" by T. Berners-Lee, L. Masinter, M.\nMcCahill, December 1994\n\nRFC 3986 is considered the current standard and any future changes to\nurlparse module should conform with it.  The urlparse module is\ncurrently not entirely compliant with this RFC due to defacto\nscenarios for parsing, and for backward compatibility purposes, some\nparsing quirks from older RFCs are retained. The testcases in\ntest_urlparse.py provides a good indicator of parsing behavior.\n\"\"\"\n\nimport re\nimport sys\nimport collections\n\n__all__ = [\"urlparse\", \"urlunparse\", \"urljoin\", \"urldefrag\",\n           \"urlsplit\", \"urlunsplit\", \"urlencode\", \"parse_qs\",\n           \"parse_qsl\", \"quote\", \"quote_plus\", \"quote_from_bytes\",\n           \"unquote\", \"unquote_plus\", \"unquote_to_bytes\",\n           \"DefragResult\", \"ParseResult\", \"SplitResult\",\n           \"DefragResultBytes\", \"ParseResultBytes\", \"SplitResultBytes\"]\n\n# A classification of schemes.\n# The empty string classifies URLs with no scheme specified,\n# being the default value returned by \u201curlsplit\u201d and \u201curlparse\u201d.\n\nuses_relative = ['', 'ftp', 'http', 'gopher', 'nntp', 'imap',\n                 'wais', 'file', 'https', 'shttp', 'mms',\n                 'prospero', 'rtsp', 'rtspu', 'sftp',\n                 'svn', 'svn+ssh', 'ws', 'wss']\n\nuses_netloc = ['', 'ftp', 'http', 'gopher', 'nntp', 'telnet',\n               'imap', 'wais', 'file', 'mms', 'https', 'shttp',\n               'snews', 'prospero', 'rtsp', 'rtspu', 'rsync',\n               'svn', 'svn+ssh', 'sftp', 'nfs', 'git', 'git+ssh',\n               'ws', 'wss']\n\nuses_params = ['', 'ftp', 'hdl', 'prospero', 'http', 'imap',\n               'https', 'shttp', 'rtsp', 'rtspu', 'sip', 'sips',\n               'mms', 'sftp', 'tel']\n\n# These are not actually used anymore, but should stay for backwards\n# compatibility.  (They are undocumented, but have a public-looking name.)\n\nnon_hierarchical = ['gopher', 'hdl', 'mailto', 'news',\n                    'telnet', 'wais', 'imap', 'snews', 'sip', 'sips']\n\nuses_query = ['', 'http', 'wais', 'imap', 'https', 'shttp', 'mms',\n              'gopher', 'rtsp', 'rtspu', 'sip', 'sips']\n\nuses_fragment = ['', 'ftp', 'hdl', 'http', 'gopher', 'news',\n                 'nntp', 'wais', 'https', 'shttp', 'snews',\n                 'file', 'prospero']\n\n# Characters valid in scheme names\nscheme_chars = ('abcdefghijklmnopqrstuvwxyz'\n                'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n                '0123456789'\n                '+-.')\n\n# XXX: Consider replacing with functools.lru_cache\nMAX_CACHE_SIZE = 20\n_parse_cache = {}\n\ndef clear_cache():\n    \"\"\"Clear the parse cache and the quoters cache.\"\"\"\n    _parse_cache.clear()\n    _safe_quoters.clear()\n\n\n# Helpers for bytes handling\n# For 3.2, we deliberately require applications that\n# handle improperly quoted URLs to do their own\n# decoding and encoding. If valid use cases are\n# presented, we may relax this by using latin-1\n# decoding internally for 3.3\n_implicit_encoding = 'ascii'\n_implicit_errors = 'strict'\n\ndef _noop(obj):\n    return obj\n\ndef _encode_result(obj, encoding=_implicit_encoding,\n                        errors=_implicit_errors):\n    return obj.encode(encoding, errors)\n\ndef _decode_args(args, encoding=_implicit_encoding,\n                       errors=_implicit_errors):\n    return tuple(x.decode(encoding, errors) if x else '' for x in args)\n\ndef _coerce_args(*args):\n    # Invokes decode if necessary to create str args\n    # and returns the coerced inputs along with\n    # an appropriate result coercion function\n    #   - noop for str inputs\n    #   - encoding function otherwise\n    str_input = isinstance(args[0], str)\n    for arg in args[1:]:\n        # We special-case the empty string to support the\n        # \"scheme=''\" default argument to some functions\n        if arg and isinstance(arg, str) != str_input:\n            raise TypeError(\"Cannot mix str and non-str arguments\")\n    if str_input:\n        return args + (_noop,)\n    return _decode_args(args) + (_encode_result,)\n\n# Result objects are more helpful than simple tuples\nclass _ResultMixinStr(object):\n    \"\"\"Standard approach to encoding parsed results from str to bytes\"\"\"\n    __slots__ = ()\n\n    def encode(self, encoding='ascii', errors='strict'):\n        return self._encoded_counterpart(*(x.encode(encoding, errors) for x in self))\n\n\nclass _ResultMixinBytes(object):\n    \"\"\"Standard approach to decoding parsed results from bytes to str\"\"\"\n    __slots__ = ()\n\n    def decode(self, encoding='ascii', errors='strict'):\n        return self._decoded_counterpart(*(x.decode(encoding, errors) for x in self))\n\n\nclass _NetlocResultMixinBase(object):\n    \"\"\"Shared methods for the parsed result objects containing a netloc element\"\"\"\n    __slots__ = ()\n\n    @property\n    def username(self):\n        return self._userinfo[0]\n\n    @property\n    def password(self):\n        return self._userinfo[1]\n\n    @property\n    def hostname(self):\n        hostname = self._hostinfo[0]\n        if not hostname:\n            return None\n        # Scoped IPv6 address may have zone info, which must not be lowercased\n        # like http://[fe80::822a:a8ff:fe49:470c%tESt]:1234/keys\n        separator = '%' if isinstance(hostname, str) else b'%'\n        hostname, percent, zone = hostname.partition(separator)\n        return hostname.lower() + percent + zone\n\n    @property\n    def port(self):\n        port = self._hostinfo[1]\n        if port is not None:\n            port = int(port, 10)\n            if not ( 0 <= port <= 65535):\n                raise ValueError(\"Port out of range 0-65535\")\n        return port\n\n\nclass _NetlocResultMixinStr(_NetlocResultMixinBase, _ResultMixinStr):\n    __slots__ = ()\n\n    @property\n    def _userinfo(self):\n        netloc = self.netloc\n        userinfo, have_info, hostinfo = netloc.rpartition('@')\n        if have_info:\n            username, have_password, password = userinfo.partition(':')\n            if not have_password:\n                password = None\n        else:\n            username = password = None\n        return username, password\n\n    @property\n    def _hostinfo(self):\n        netloc = self.netloc\n        _, _, hostinfo = netloc.rpartition('@')\n        _, have_open_br, bracketed = hostinfo.partition('[')\n        if have_open_br:\n            hostname, _, port = bracketed.partition(']')\n            _, _, port = port.partition(':')\n        else:\n            hostname, _, port = hostinfo.partition(':')\n        if not port:\n            port = None\n        return hostname, port\n\n\nclass _NetlocResultMixinBytes(_NetlocResultMixinBase, _ResultMixinBytes):\n    __slots__ = ()\n\n    @property\n    def _userinfo(self):\n        netloc = self.netloc\n        userinfo, have_info, hostinfo = netloc.rpartition(b'@')\n        if have_info:\n            username, have_password, password = userinfo.partition(b':')\n            if not have_password:\n                password = None\n        else:\n            username = password = None\n        return username, password\n\n    @property\n    def _hostinfo(self):\n        netloc = self.netloc\n        _, _, hostinfo = netloc.rpartition(b'@')\n        _, have_open_br, bracketed = hostinfo.partition(b'[')\n        if have_open_br:\n            hostname, _, port = bracketed.partition(b']')\n            _, _, port = port.partition(b':')\n        else:\n            hostname, _, port = hostinfo.partition(b':')\n        if not port:\n            port = None\n        return hostname, port\n\n\nfrom collections import namedtuple\n\n_DefragResultBase = namedtuple('DefragResult', 'url fragment')\n_SplitResultBase = namedtuple(\n    'SplitResult', 'scheme netloc path query fragment')\n_ParseResultBase = namedtuple(\n    'ParseResult', 'scheme netloc path params query fragment')\n\n_DefragResultBase.__doc__ = \"\"\"\nDefragResult(url, fragment)\n\nA 2-tuple that contains the url without fragment identifier and the fragment\nidentifier as a separate argument.\n\"\"\"\n\n_DefragResultBase.url.__doc__ = \"\"\"The URL with no fragment identifier.\"\"\"\n\n_DefragResultBase.fragment.__doc__ = \"\"\"\nFragment identifier separated from URL, that allows indirect identification of a\nsecondary resource by reference to a primary resource and additional identifying\ninformation.\n\"\"\"\n\n_SplitResultBase.__doc__ = \"\"\"\nSplitResult(scheme, netloc, path, query, fragment)\n\nA 5-tuple that contains the different components of a URL. Similar to\nParseResult, but does not split params.\n\"\"\"\n\n_SplitResultBase.scheme.__doc__ = \"\"\"Specifies URL scheme for the request.\"\"\"\n\n_SplitResultBase.netloc.__doc__ = \"\"\"\nNetwork location where the request is made to.\n\"\"\"\n\n_SplitResultBase.path.__doc__ = \"\"\"\nThe hierarchical path, such as the path to a file to download.\n\"\"\"\n\n_SplitResultBase.query.__doc__ = \"\"\"\nThe query component, that contains non-hierarchical data, that along with data\nin path component, identifies a resource in the scope of URI's scheme and\nnetwork location.\n\"\"\"\n\n_SplitResultBase.fragment.__doc__ = \"\"\"\nFragment identifier, that allows indirect identification of a secondary resource\nby reference to a primary resource and additional identifying information.\n\"\"\"\n\n_ParseResultBase.__doc__ = \"\"\"\nParseResult(scheme, netloc, path, params,  query, fragment)\n\nA 6-tuple that contains components of a parsed URL.\n\"\"\"\n\n_ParseResultBase.scheme.__doc__ = _SplitResultBase.scheme.__doc__\n_ParseResultBase.netloc.__doc__ = _SplitResultBase.netloc.__doc__\n_ParseResultBase.path.__doc__ = _SplitResultBase.path.__doc__\n_ParseResultBase.params.__doc__ = \"\"\"\nParameters for last path element used to dereference the URI in order to provide\naccess to perform some operation on the resource.\n\"\"\"\n\n_ParseResultBase.query.__doc__ = _SplitResultBase.query.__doc__\n_ParseResultBase.fragment.__doc__ = _SplitResultBase.fragment.__doc__\n\n\n# For backwards compatibility, alias _NetlocResultMixinStr\n# ResultBase is no longer part of the documented API, but it is\n# retained since deprecating it isn't worth the hassle\nResultBase = _NetlocResultMixinStr\n\n# Structured result objects for string data\nclass DefragResult(_DefragResultBase, _ResultMixinStr):\n    __slots__ = ()\n    def geturl(self):\n        if self.fragment:\n            return self.url + '#' + self.fragment\n        else:\n            return self.url\n\nclass SplitResult(_SplitResultBase, _NetlocResultMixinStr):\n    __slots__ = ()\n    def geturl(self):\n        return urlunsplit(self)\n\nclass ParseResult(_ParseResultBase, _NetlocResultMixinStr):\n    __slots__ = ()\n    def geturl(self):\n        return urlunparse(self)\n\n# Structured result objects for bytes data\nclass DefragResultBytes(_DefragResultBase, _ResultMixinBytes):\n    __slots__ = ()\n    def geturl(self):\n        if self.fragment:\n            return self.url + b'#' + self.fragment\n        else:\n            return self.url\n\nclass SplitResultBytes(_SplitResultBase, _NetlocResultMixinBytes):\n    __slots__ = ()\n    def geturl(self):\n        return urlunsplit(self)\n\nclass ParseResultBytes(_ParseResultBase, _NetlocResultMixinBytes):\n    __slots__ = ()\n    def geturl(self):\n        return urlunparse(self)\n\n# Set up the encode/decode result pairs\ndef _fix_result_transcoding():\n    _result_pairs = (\n        (DefragResult, DefragResultBytes),\n        (SplitResult, SplitResultBytes),\n        (ParseResult, ParseResultBytes),\n    )\n    for _decoded, _encoded in _result_pairs:\n        _decoded._encoded_counterpart = _encoded\n        _encoded._decoded_counterpart = _decoded\n\n_fix_result_transcoding()\ndel _fix_result_transcoding\n\ndef urlparse(url, scheme='', allow_fragments=True):\n    \"\"\"Parse a URL into 6 components:\n    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\n    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    splitresult = urlsplit(url, scheme, allow_fragments)\n    scheme, netloc, url, query, fragment = splitresult\n    if scheme in uses_params and ';' in url:\n        url, params = _splitparams(url)\n    else:\n        params = ''\n    result = ParseResult(scheme, netloc, url, params, query, fragment)\n    return _coerce_result(result)\n\ndef _splitparams(url):\n    if '/'  in url:\n        i = url.find(';', url.rfind('/'))\n        if i < 0:\n            return url, ''\n    else:\n        i = url.find(';')\n    return url[:i], url[i+1:]\n\ndef _splitnetloc(url, start=0):\n    delim = len(url)   # position of end of domain part of url, default is end\n    for c in '/?#':    # look for delimiters; the order is NOT important\n        wdelim = url.find(c, start)        # find first of this delim\n        if wdelim >= 0:                    # if found\n            delim = min(delim, wdelim)     # use earliest delim position\n    return url[start:delim], url[delim:]   # return (domain, rest)\n\ndef _checknetloc(netloc):\n    if not netloc or netloc.isascii():\n        return\n    # looking for characters like \\u2100 that expand to 'a/c'\n    # IDNA uses NFKC equivalence, so normalize for this check\n    import unicodedata\n    n = netloc.rpartition('@')[2] # ignore anything to the left of '@'\n    n = n.replace(':', '')        # ignore characters already included\n    n = n.replace('#', '')        # but not the surrounding text\n    n = n.replace('?', '')\n    netloc2 = unicodedata.normalize('NFKC', n)\n    if n == netloc2:\n        return\n    for c in '/?#@:':\n        if c in netloc2:\n            raise ValueError(\"netloc '\" + netloc + \"' contains invalid \" +\n                             \"characters under NFKC normalization\")\n\ndef urlsplit(url, scheme='', allow_fragments=True):\n    \"\"\"Parse a URL into 5 components:\n    <scheme>://<netloc>/<path>?<query>#<fragment>\n    Return a 5-tuple: (scheme, netloc, path, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    allow_fragments = bool(allow_fragments)\n    key = url, scheme, allow_fragments, type(url), type(scheme)\n    cached = _parse_cache.get(key, None)\n    if cached:\n        return _coerce_result(cached)\n    if len(_parse_cache) >= MAX_CACHE_SIZE: # avoid runaway growth\n        clear_cache()\n    netloc = query = fragment = ''\n    i = url.find(':')\n    if i > 0:\n        if url[:i] == 'http': # optimize the common case\n            url = url[i+1:]\n            if url[:2] == '//':\n                netloc, url = _splitnetloc(url, 2)\n                if (('[' in netloc and ']' not in netloc) or\n                        (']' in netloc and '[' not in netloc)):\n                    raise ValueError(\"Invalid IPv6 URL\")\n            if allow_fragments and '#' in url:\n                url, fragment = url.split('#', 1)\n            if '?' in url:\n                url, query = url.split('?', 1)\n            _checknetloc(netloc)\n            v = SplitResult('http', netloc, url, query, fragment)\n            _parse_cache[key] = v\n            return _coerce_result(v)\n        for c in url[:i]:\n            if c not in scheme_chars:\n                break\n        else:\n            # make sure \"url\" is not actually a port number (in which case\n            # \"scheme\" is really part of the path)\n            rest = url[i+1:]\n            if not rest or any(c not in '0123456789' for c in rest):\n                # not a port number\n                scheme, url = url[:i].lower(), rest\n\n    if url[:2] == '//':\n        netloc, url = _splitnetloc(url, 2)\n        if (('[' in netloc and ']' not in netloc) or\n                (']' in netloc and '[' not in netloc)):\n            raise ValueError(\"Invalid IPv6 URL\")\n    if allow_fragments and '#' in url:\n        url, fragment = url.split('#', 1)\n    if '?' in url:\n        url, query = url.split('?', 1)\n    _checknetloc(netloc)\n    v = SplitResult(scheme, netloc, url, query, fragment)\n    _parse_cache[key] = v\n    return _coerce_result(v)\n\ndef urlunparse(components):\n    \"\"\"Put a parsed URL back together again.  This may result in a\n    slightly different, but equivalent URL, if the URL that was parsed\n    originally had redundant delimiters, e.g. a ? with an empty query\n    (the draft states that these are equivalent).\"\"\"\n    scheme, netloc, url, params, query, fragment, _coerce_result = (\n                                                  _coerce_args(*components))\n    if params:\n        url = \"%s;%s\" % (url, params)\n    return _coerce_result(urlunsplit((scheme, netloc, url, query, fragment)))\n\ndef urlunsplit(components):\n    \"\"\"Combine the elements of a tuple as returned by urlsplit() into a\n    complete URL as a string. The data argument can be any five-item iterable.\n    This may result in a slightly different, but equivalent URL, if the URL that\n    was parsed originally had unnecessary delimiters (for example, a ? with an\n    empty query; the RFC states that these are equivalent).\"\"\"\n    scheme, netloc, url, query, fragment, _coerce_result = (\n                                          _coerce_args(*components))\n    if netloc or (scheme and scheme in uses_netloc and url[:2] != '//'):\n        if url and url[:1] != '/': url = '/' + url\n        url = '//' + (netloc or '') + url\n    if scheme:\n        url = scheme + ':' + url\n    if query:\n        url = url + '?' + query\n    if fragment:\n        url = url + '#' + fragment\n    return _coerce_result(url)\n\ndef urljoin(base, url, allow_fragments=True):\n    \"\"\"Join a base URL and a possibly relative URL to form an absolute\n    interpretation of the latter.\"\"\"\n    if not base:\n        return url\n    if not url:\n        return base\n\n    base, url, _coerce_result = _coerce_args(base, url)\n    bscheme, bnetloc, bpath, bparams, bquery, bfragment = \\\n            urlparse(base, '', allow_fragments)\n    scheme, netloc, path, params, query, fragment = \\\n            urlparse(url, bscheme, allow_fragments)\n\n    if scheme != bscheme or scheme not in uses_relative:\n        return _coerce_result(url)\n    if scheme in uses_netloc:\n        if netloc:\n            return _coerce_result(urlunparse((scheme, netloc, path,\n                                              params, query, fragment)))\n        netloc = bnetloc\n\n    if not path and not params:\n        path = bpath\n        params = bparams\n        if not query:\n            query = bquery\n        return _coerce_result(urlunparse((scheme, netloc, path,\n                                          params, query, fragment)))\n\n    base_parts = bpath.split('/')\n    if base_parts[-1] != '':\n        # the last item is not a directory, so will not be taken into account\n        # in resolving the relative path\n        del base_parts[-1]\n\n    # for rfc3986, ignore all base path should the first character be root.\n    if path[:1] == '/':\n        segments = path.split('/')\n    else:\n        segments = base_parts + path.split('/')\n        # filter out elements that would cause redundant slashes on re-joining\n        # the resolved_path\n        segments[1:-1] = filter(None, segments[1:-1])\n\n    resolved_path = []\n\n    for seg in segments:\n        if seg == '..':\n            try:\n                resolved_path.pop()\n            except IndexError:\n                # ignore any .. segments that would otherwise cause an IndexError\n                # when popped from resolved_path if resolving for rfc3986\n                pass\n        elif seg == '.':\n            continue\n        else:\n            resolved_path.append(seg)\n\n    if segments[-1] in ('.', '..'):\n        # do some post-processing here. if the last segment was a relative dir,\n        # then we need to append the trailing '/'\n        resolved_path.append('')\n\n    return _coerce_result(urlunparse((scheme, netloc, '/'.join(\n        resolved_path) or '/', params, query, fragment)))\n\n\ndef urldefrag(url):\n    \"\"\"Removes any existing fragment from URL.\n\n    Returns a tuple of the defragmented URL and the fragment.  If\n    the URL contained no fragments, the second element is the\n    empty string.\n    \"\"\"\n    url, _coerce_result = _coerce_args(url)\n    if '#' in url:\n        s, n, p, a, q, frag = urlparse(url)\n        defrag = urlunparse((s, n, p, a, q, ''))\n    else:\n        frag = ''\n        defrag = url\n    return _coerce_result(DefragResult(defrag, frag))\n\n_hexdig = '0123456789ABCDEFabcdef'\n_hextobyte = None\n\ndef unquote_to_bytes(string):\n    \"\"\"unquote_to_bytes('abc%20def') -> b'abc def'.\"\"\"\n    # Note: strings are encoded as UTF-8. This is only an issue if it contains\n    # unescaped non-ASCII characters, which URIs should not.\n    if not string:\n        # Is it a string-like object?\n        string.split\n        return b''\n    if isinstance(string, str):\n        string = string.encode('utf-8')\n    bits = string.split(b'%')\n    if len(bits) == 1:\n        return string\n    res = [bits[0]]\n    append = res.append\n    # Delay the initialization of the table to not waste memory\n    # if the function is never called\n    global _hextobyte\n    if _hextobyte is None:\n        _hextobyte = {(a + b).encode(): bytes.fromhex(a + b)\n                      for a in _hexdig for b in _hexdig}\n    for item in bits[1:]:\n        try:\n            append(_hextobyte[item[:2]])\n            append(item[2:])\n        except KeyError:\n            append(b'%')\n            append(item)\n    return b''.join(res)\n\n_asciire = re.compile('([\\x00-\\x7f]+)')\n\ndef unquote(string, encoding='utf-8', errors='replace'):\n    \"\"\"Replace %xx escapes by their single-character equivalent. The optional\n    encoding and errors parameters specify how to decode percent-encoded\n    sequences into Unicode characters, as accepted by the bytes.decode()\n    method.\n    By default, percent-encoded sequences are decoded with UTF-8, and invalid\n    sequences are replaced by a placeholder character.\n\n    unquote('abc%20def') -> 'abc def'.\n    \"\"\"\n    if '%' not in string:\n        string.split\n        return string\n    if encoding is None:\n        encoding = 'utf-8'\n    if errors is None:\n        errors = 'replace'\n    bits = _asciire.split(string)\n    res = [bits[0]]\n    append = res.append\n    for i in range(1, len(bits), 2):\n        append(unquote_to_bytes(bits[i]).decode(encoding, errors))\n        append(bits[i + 1])\n    return ''.join(res)\n\n\ndef parse_qs(qs, keep_blank_values=False, strict_parsing=False,\n             encoding='utf-8', errors='replace', max_num_fields=None):\n    \"\"\"Parse a query given as a string argument.\n\n        Arguments:\n\n        qs: percent-encoded query string to be parsed\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded queries should be treated as blank strings.\n            A true value indicates that blanks should be retained as\n            blank strings.  The default false value indicates that\n            blank values are to be ignored and treated as if they were\n            not included.\n\n        strict_parsing: flag indicating what to do with parsing errors.\n            If false (the default), errors are silently ignored.\n            If true, errors raise a ValueError exception.\n\n        encoding and errors: specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the bytes.decode() method.\n\n        max_num_fields: int. If set, then throws a ValueError if there\n            are more than n fields read by parse_qsl().\n\n        Returns a dictionary.\n    \"\"\"\n    parsed_result = {}\n    pairs = parse_qsl(qs, keep_blank_values, strict_parsing,\n                      encoding=encoding, errors=errors,\n                      max_num_fields=max_num_fields)\n    for name, value in pairs:\n        if name in parsed_result:\n            parsed_result[name].append(value)\n        else:\n            parsed_result[name] = [value]\n    return parsed_result\n\n\ndef parse_qsl(qs, keep_blank_values=False, strict_parsing=False,\n              encoding='utf-8', errors='replace', max_num_fields=None):\n    \"\"\"Parse a query given as a string argument.\n\n        Arguments:\n\n        qs: percent-encoded query string to be parsed\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded queries should be treated as blank strings.\n            A true value indicates that blanks should be retained as blank\n            strings.  The default false value indicates that blank values\n            are to be ignored and treated as if they were  not included.\n\n        strict_parsing: flag indicating what to do with parsing errors. If\n            false (the default), errors are silently ignored. If true,\n            errors raise a ValueError exception.\n\n        encoding and errors: specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the bytes.decode() method.\n\n        max_num_fields: int. If set, then throws a ValueError\n            if there are more than n fields read by parse_qsl().\n\n        Returns a list, as G-d intended.\n    \"\"\"\n    qs, _coerce_result = _coerce_args(qs)\n\n    # If max_num_fields is defined then check that the number of fields\n    # is less than max_num_fields. This prevents a memory exhaustion DOS\n    # attack via post bodies with many fields.\n    if max_num_fields is not None:\n        num_fields = 1 + qs.count('&') + qs.count(';')\n        if max_num_fields < num_fields:\n            raise ValueError('Max number of fields exceeded')\n\n    pairs = [s2 for s1 in qs.split('&') for s2 in s1.split(';')]\n    r = []\n    for name_value in pairs:\n        if not name_value and not strict_parsing:\n            continue\n        nv = name_value.split('=', 1)\n        if len(nv) != 2:\n            if strict_parsing:\n                raise ValueError(\"bad query field: %r\" % (name_value,))\n            # Handle case of a control-name with no equal sign\n            if keep_blank_values:\n                nv.append('')\n            else:\n                continue\n        if len(nv[1]) or keep_blank_values:\n            name = nv[0].replace('+', ' ')\n            name = unquote(name, encoding=encoding, errors=errors)\n            name = _coerce_result(name)\n            value = nv[1].replace('+', ' ')\n            value = unquote(value, encoding=encoding, errors=errors)\n            value = _coerce_result(value)\n            r.append((name, value))\n    return r\n\ndef unquote_plus(string, encoding='utf-8', errors='replace'):\n    \"\"\"Like unquote(), but also replace plus signs by spaces, as required for\n    unquoting HTML form values.\n\n    unquote_plus('%7e/abc+def') -> '~/abc def'\n    \"\"\"\n    string = string.replace('+', ' ')\n    return unquote(string, encoding, errors)\n\n_ALWAYS_SAFE = frozenset(b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n                         b'abcdefghijklmnopqrstuvwxyz'\n                         b'0123456789'\n                         b'_.-~')\n_ALWAYS_SAFE_BYTES = bytes(_ALWAYS_SAFE)\n_safe_quoters = {}\n\nclass Quoter(collections.defaultdict):\n    \"\"\"A mapping from bytes (in range(0,256)) to strings.\n\n    String values are percent-encoded byte values, unless the key < 128, and\n    in the \"safe\" set (either the specified safe set, or default set).\n    \"\"\"\n    # Keeps a cache internally, using defaultdict, for efficiency (lookups\n    # of cached keys don't call Python code at all).\n    def __init__(self, safe):\n        \"\"\"safe: bytes object.\"\"\"\n        self.safe = _ALWAYS_SAFE.union(safe)\n\n    def __repr__(self):\n        # Without this, will just display as a defaultdict\n        return \"<%s %r>\" % (self.__class__.__name__, dict(self))\n\n    def __missing__(self, b):\n        # Handle a cache miss. Store quoted string in cache and return.\n        res = chr(b) if b in self.safe else '%{:02X}'.format(b)\n        self[b] = res\n        return res\n\ndef quote(string, safe='/', encoding=None, errors=None):\n    \"\"\"quote('abc def') -> 'abc%20def'\n\n    Each part of a URL, e.g. the path info, the query, etc., has a\n    different set of reserved characters that must be quoted. The\n    quote function offers a cautious (not minimal) way to quote a\n    string for most of these parts.\n\n    RFC 3986 Uniform Resource Identifier (URI): Generic Syntax lists\n    the following (un)reserved characters.\n\n    unreserved    = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n    reserved      = gen-delims / sub-delims\n    gen-delims    = \":\" / \"/\" / \"?\" / \"#\" / \"[\" / \"]\" / \"@\"\n    sub-delims    = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\"\n                  / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n\n    Each of the reserved characters is reserved in some component of a URL,\n    but not necessarily in all of them.\n\n    The quote function %-escapes all characters that are neither in the\n    unreserved chars (\"always safe\") nor the additional chars set via the\n    safe arg.\n\n    The default for the safe arg is '/'. The character is reserved, but in\n    typical usage the quote function is being called on a path where the\n    existing slash characters are to be preserved.\n\n    Python 3.7 updates from using RFC 2396 to RFC 3986 to quote URL strings.\n    Now, \"~\" is included in the set of unreserved characters.\n\n    string and safe may be either str or bytes objects. encoding and errors\n    must not be specified if string is a bytes object.\n\n    The optional encoding and errors parameters specify how to deal with\n    non-ASCII characters, as accepted by the str.encode method.\n    By default, encoding='utf-8' (characters are encoded with UTF-8), and\n    errors='strict' (unsupported characters raise a UnicodeEncodeError).\n    \"\"\"\n    if isinstance(string, str):\n        if not string:\n            return string\n        if encoding is None:\n            encoding = 'utf-8'\n        if errors is None:\n            errors = 'strict'\n        string = string.encode(encoding, errors)\n    else:\n        if encoding is not None:\n            raise TypeError(\"quote() doesn't support 'encoding' for bytes\")\n        if errors is not None:\n            raise TypeError(\"quote() doesn't support 'errors' for bytes\")\n    return quote_from_bytes(string, safe)\n\ndef quote_plus(string, safe='', encoding=None, errors=None):\n    \"\"\"Like quote(), but also replace ' ' with '+', as required for quoting\n    HTML form values. Plus signs in the original string are escaped unless\n    they are included in safe. It also does not have safe default to '/'.\n    \"\"\"\n    # Check if ' ' in string, where string may either be a str or bytes.  If\n    # there are no spaces, the regular quote will produce the right answer.\n    if ((isinstance(string, str) and ' ' not in string) or\n        (isinstance(string, bytes) and b' ' not in string)):\n        return quote(string, safe, encoding, errors)\n    if isinstance(safe, str):\n        space = ' '\n    else:\n        space = b' '\n    string = quote(string, safe + space, encoding, errors)\n    return string.replace(' ', '+')\n\ndef quote_from_bytes(bs, safe='/'):\n    \"\"\"Like quote(), but accepts a bytes object rather than a str, and does\n    not perform string-to-bytes encoding.  It always returns an ASCII string.\n    quote_from_bytes(b'abc def\\x3f') -> 'abc%20def%3f'\n    \"\"\"\n    if not isinstance(bs, (bytes, bytearray)):\n        raise TypeError(\"quote_from_bytes() expected bytes\")\n    if not bs:\n        return ''\n    if isinstance(safe, str):\n        # Normalize 'safe' by converting to bytes and removing non-ASCII chars\n        safe = safe.encode('ascii', 'ignore')\n    else:\n        safe = bytes([c for c in safe if c < 128])\n    if not bs.rstrip(_ALWAYS_SAFE_BYTES + safe):\n        return bs.decode()\n    try:\n        quoter = _safe_quoters[safe]\n    except KeyError:\n        _safe_quoters[safe] = quoter = Quoter(safe).__getitem__\n    return ''.join([quoter(char) for char in bs])\n\ndef urlencode(query, doseq=False, safe='', encoding=None, errors=None,\n              quote_via=quote_plus):\n    \"\"\"Encode a dict or sequence of two-element tuples into a URL query string.\n\n    If any values in the query arg are sequences and doseq is true, each\n    sequence element is converted to a separate parameter.\n\n    If the query arg is a sequence of two-element tuples, the order of the\n    parameters in the output will match the order of parameters in the\n    input.\n\n    The components of a query arg may each be either a string or a bytes type.\n\n    The safe, encoding, and errors parameters are passed down to the function\n    specified by quote_via (encoding and errors only if a component is a str).\n    \"\"\"\n\n    if hasattr(query, \"items\"):\n        query = query.items()\n    else:\n        # It's a bother at times that strings and string-like objects are\n        # sequences.\n        try:\n            # non-sequence items should not work with len()\n            # non-empty strings will fail this\n            if len(query) and not isinstance(query[0], tuple):\n                raise TypeError\n            # Zero-length sequences of all types will get here and succeed,\n            # but that's a minor nit.  Since the original implementation\n            # allowed empty dicts that type of behavior probably should be\n            # preserved for consistency\n        except TypeError:\n            ty, va, tb = sys.exc_info()\n            raise TypeError(\"not a valid non-string sequence \"\n                            \"or mapping object\").with_traceback(tb)\n\n    l = []\n    if not doseq:\n        for k, v in query:\n            if isinstance(k, bytes):\n                k = quote_via(k, safe)\n            else:\n                k = quote_via(str(k), safe, encoding, errors)\n\n            if isinstance(v, bytes):\n                v = quote_via(v, safe)\n            else:\n                v = quote_via(str(v), safe, encoding, errors)\n            l.append(k + '=' + v)\n    else:\n        for k, v in query:\n            if isinstance(k, bytes):\n                k = quote_via(k, safe)\n            else:\n                k = quote_via(str(k), safe, encoding, errors)\n\n            if isinstance(v, bytes):\n                v = quote_via(v, safe)\n                l.append(k + '=' + v)\n            elif isinstance(v, str):\n                v = quote_via(v, safe, encoding, errors)\n                l.append(k + '=' + v)\n            else:\n                try:\n                    # Is this a sufficient test for sequence-ness?\n                    x = len(v)\n                except TypeError:\n                    # not a sequence\n                    v = quote_via(str(v), safe, encoding, errors)\n                    l.append(k + '=' + v)\n                else:\n                    # loop over the sequence\n                    for elt in v:\n                        if isinstance(elt, bytes):\n                            elt = quote_via(elt, safe)\n                        else:\n                            elt = quote_via(str(elt), safe, encoding, errors)\n                        l.append(k + '=' + elt)\n    return '&'.join(l)\n\ndef to_bytes(url):\n    \"\"\"to_bytes(u\"URL\") --> 'URL'.\"\"\"\n    # Most URL schemes require ASCII. If that changes, the conversion\n    # can be relaxed.\n    # XXX get rid of to_bytes()\n    if isinstance(url, str):\n        try:\n            url = url.encode(\"ASCII\").decode()\n        except UnicodeError:\n            raise UnicodeError(\"URL \" + repr(url) +\n                               \" contains non-ASCII characters\")\n    return url\n\ndef unwrap(url):\n    \"\"\"unwrap('<URL:type://host/path>') --> 'type://host/path'.\"\"\"\n    url = str(url).strip()\n    if url[:1] == '<' and url[-1:] == '>':\n        url = url[1:-1].strip()\n    if url[:4] == 'URL:': url = url[4:].strip()\n    return url\n\n_typeprog = None\ndef splittype(url):\n    \"\"\"splittype('type:opaquestring') --> 'type', 'opaquestring'.\"\"\"\n    global _typeprog\n    if _typeprog is None:\n        _typeprog = re.compile('([^/:]+):(.*)', re.DOTALL)\n\n    match = _typeprog.match(url)\n    if match:\n        scheme, data = match.groups()\n        return scheme.lower(), data\n    return None, url\n\n_hostprog = None\ndef splithost(url):\n    \"\"\"splithost('//host[:port]/path') --> 'host[:port]', '/path'.\"\"\"\n    global _hostprog\n    if _hostprog is None:\n        _hostprog = re.compile('//([^/#?]*)(.*)', re.DOTALL)\n\n    match = _hostprog.match(url)\n    if match:\n        host_port, path = match.groups()\n        if path and path[0] != '/':\n            path = '/' + path\n        return host_port, path\n    return None, url\n\ndef splituser(host):\n    \"\"\"splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'.\"\"\"\n    user, delim, host = host.rpartition('@')\n    return (user if delim else None), host\n\ndef splitpasswd(user):\n    \"\"\"splitpasswd('user:passwd') -> 'user', 'passwd'.\"\"\"\n    user, delim, passwd = user.partition(':')\n    return user, (passwd if delim else None)\n\n# splittag('/path#tag') --> '/path', 'tag'\n_portprog = None\ndef splitport(host):\n    \"\"\"splitport('host:port') --> 'host', 'port'.\"\"\"\n    global _portprog\n    if _portprog is None:\n        _portprog = re.compile('(.*):([0-9]*)$', re.DOTALL)\n\n    match = _portprog.match(host)\n    if match:\n        host, port = match.groups()\n        if port:\n            return host, port\n    return host, None\n\ndef splitnport(host, defport=-1):\n    \"\"\"Split host and port, returning numeric port.\n    Return given default port if no ':' found; defaults to -1.\n    Return numerical port if a valid number are found after ':'.\n    Return None if ':' but not a valid number.\"\"\"\n    host, delim, port = host.rpartition(':')\n    if not delim:\n        host = port\n    elif port:\n        try:\n            nport = int(port)\n        except ValueError:\n            nport = None\n        return host, nport\n    return host, defport\n\ndef splitquery(url):\n    \"\"\"splitquery('/path?query') --> '/path', 'query'.\"\"\"\n    path, delim, query = url.rpartition('?')\n    if delim:\n        return path, query\n    return url, None\n\ndef splittag(url):\n    \"\"\"splittag('/path#tag') --> '/path', 'tag'.\"\"\"\n    path, delim, tag = url.rpartition('#')\n    if delim:\n        return path, tag\n    return url, None\n\ndef splitattr(url):\n    \"\"\"splitattr('/path;attr1=value1;attr2=value2;...') ->\n        '/path', ['attr1=value1', 'attr2=value2', ...].\"\"\"\n    words = url.split(';')\n    return words[0], words[1:]\n\ndef splitvalue(attr):\n    \"\"\"splitvalue('attr=value') --> 'attr', 'value'.\"\"\"\n    attr, delim, value = attr.partition('=')\n    return attr, (value if delim else None)\n"], "fixing_code": ["import sys\nimport unicodedata\nimport unittest\nimport urllib.parse\n\nRFC1808_BASE = \"http://a/b/c/d;p?q#f\"\nRFC2396_BASE = \"http://a/b/c/d;p?q\"\nRFC3986_BASE = 'http://a/b/c/d;p?q'\nSIMPLE_BASE  = 'http://a/b/c/d'\n\n# Each parse_qsl testcase is a two-tuple that contains\n# a string with the query and a list with the expected result.\n\nparse_qsl_test_cases = [\n    (\"\", []),\n    (\"&\", []),\n    (\"&&\", []),\n    (\"=\", [('', '')]),\n    (\"=a\", [('', 'a')]),\n    (\"a\", [('a', '')]),\n    (\"a=\", [('a', '')]),\n    (\"&a=b\", [('a', 'b')]),\n    (\"a=a+b&b=b+c\", [('a', 'a b'), ('b', 'b c')]),\n    (\"a=1&a=2\", [('a', '1'), ('a', '2')]),\n    (b\"\", []),\n    (b\"&\", []),\n    (b\"&&\", []),\n    (b\"=\", [(b'', b'')]),\n    (b\"=a\", [(b'', b'a')]),\n    (b\"a\", [(b'a', b'')]),\n    (b\"a=\", [(b'a', b'')]),\n    (b\"&a=b\", [(b'a', b'b')]),\n    (b\"a=a+b&b=b+c\", [(b'a', b'a b'), (b'b', b'b c')]),\n    (b\"a=1&a=2\", [(b'a', b'1'), (b'a', b'2')]),\n    (\";\", []),\n    (\";;\", []),\n    (\";a=b\", [('a', 'b')]),\n    (\"a=a+b;b=b+c\", [('a', 'a b'), ('b', 'b c')]),\n    (\"a=1;a=2\", [('a', '1'), ('a', '2')]),\n    (b\";\", []),\n    (b\";;\", []),\n    (b\";a=b\", [(b'a', b'b')]),\n    (b\"a=a+b;b=b+c\", [(b'a', b'a b'), (b'b', b'b c')]),\n    (b\"a=1;a=2\", [(b'a', b'1'), (b'a', b'2')]),\n]\n\n# Each parse_qs testcase is a two-tuple that contains\n# a string with the query and a dictionary with the expected result.\n\nparse_qs_test_cases = [\n    (\"\", {}),\n    (\"&\", {}),\n    (\"&&\", {}),\n    (\"=\", {'': ['']}),\n    (\"=a\", {'': ['a']}),\n    (\"a\", {'a': ['']}),\n    (\"a=\", {'a': ['']}),\n    (\"&a=b\", {'a': ['b']}),\n    (\"a=a+b&b=b+c\", {'a': ['a b'], 'b': ['b c']}),\n    (\"a=1&a=2\", {'a': ['1', '2']}),\n    (b\"\", {}),\n    (b\"&\", {}),\n    (b\"&&\", {}),\n    (b\"=\", {b'': [b'']}),\n    (b\"=a\", {b'': [b'a']}),\n    (b\"a\", {b'a': [b'']}),\n    (b\"a=\", {b'a': [b'']}),\n    (b\"&a=b\", {b'a': [b'b']}),\n    (b\"a=a+b&b=b+c\", {b'a': [b'a b'], b'b': [b'b c']}),\n    (b\"a=1&a=2\", {b'a': [b'1', b'2']}),\n    (\";\", {}),\n    (\";;\", {}),\n    (\";a=b\", {'a': ['b']}),\n    (\"a=a+b;b=b+c\", {'a': ['a b'], 'b': ['b c']}),\n    (\"a=1;a=2\", {'a': ['1', '2']}),\n    (b\";\", {}),\n    (b\";;\", {}),\n    (b\";a=b\", {b'a': [b'b']}),\n    (b\"a=a+b;b=b+c\", {b'a': [b'a b'], b'b': [b'b c']}),\n    (b\"a=1;a=2\", {b'a': [b'1', b'2']}),\n]\n\nclass UrlParseTestCase(unittest.TestCase):\n\n    def checkRoundtrips(self, url, parsed, split):\n        result = urllib.parse.urlparse(url)\n        self.assertEqual(result, parsed)\n        t = (result.scheme, result.netloc, result.path,\n             result.params, result.query, result.fragment)\n        self.assertEqual(t, parsed)\n        # put it back together and it should be the same\n        result2 = urllib.parse.urlunparse(result)\n        self.assertEqual(result2, url)\n        self.assertEqual(result2, result.geturl())\n\n        # the result of geturl() is a fixpoint; we can always parse it\n        # again to get the same result:\n        result3 = urllib.parse.urlparse(result.geturl())\n        self.assertEqual(result3.geturl(), result.geturl())\n        self.assertEqual(result3,          result)\n        self.assertEqual(result3.scheme,   result.scheme)\n        self.assertEqual(result3.netloc,   result.netloc)\n        self.assertEqual(result3.path,     result.path)\n        self.assertEqual(result3.params,   result.params)\n        self.assertEqual(result3.query,    result.query)\n        self.assertEqual(result3.fragment, result.fragment)\n        self.assertEqual(result3.username, result.username)\n        self.assertEqual(result3.password, result.password)\n        self.assertEqual(result3.hostname, result.hostname)\n        self.assertEqual(result3.port,     result.port)\n\n        # check the roundtrip using urlsplit() as well\n        result = urllib.parse.urlsplit(url)\n        self.assertEqual(result, split)\n        t = (result.scheme, result.netloc, result.path,\n             result.query, result.fragment)\n        self.assertEqual(t, split)\n        result2 = urllib.parse.urlunsplit(result)\n        self.assertEqual(result2, url)\n        self.assertEqual(result2, result.geturl())\n\n        # check the fixpoint property of re-parsing the result of geturl()\n        result3 = urllib.parse.urlsplit(result.geturl())\n        self.assertEqual(result3.geturl(), result.geturl())\n        self.assertEqual(result3,          result)\n        self.assertEqual(result3.scheme,   result.scheme)\n        self.assertEqual(result3.netloc,   result.netloc)\n        self.assertEqual(result3.path,     result.path)\n        self.assertEqual(result3.query,    result.query)\n        self.assertEqual(result3.fragment, result.fragment)\n        self.assertEqual(result3.username, result.username)\n        self.assertEqual(result3.password, result.password)\n        self.assertEqual(result3.hostname, result.hostname)\n        self.assertEqual(result3.port,     result.port)\n\n    def test_qsl(self):\n        for orig, expect in parse_qsl_test_cases:\n            result = urllib.parse.parse_qsl(orig, keep_blank_values=True)\n            self.assertEqual(result, expect, \"Error parsing %r\" % orig)\n            expect_without_blanks = [v for v in expect if len(v[1])]\n            result = urllib.parse.parse_qsl(orig, keep_blank_values=False)\n            self.assertEqual(result, expect_without_blanks,\n                            \"Error parsing %r\" % orig)\n\n    def test_qs(self):\n        for orig, expect in parse_qs_test_cases:\n            result = urllib.parse.parse_qs(orig, keep_blank_values=True)\n            self.assertEqual(result, expect, \"Error parsing %r\" % orig)\n            expect_without_blanks = {v: expect[v]\n                                     for v in expect if len(expect[v][0])}\n            result = urllib.parse.parse_qs(orig, keep_blank_values=False)\n            self.assertEqual(result, expect_without_blanks,\n                            \"Error parsing %r\" % orig)\n\n    def test_roundtrips(self):\n        str_cases = [\n            ('file:///tmp/junk.txt',\n             ('file', '', '/tmp/junk.txt', '', '', ''),\n             ('file', '', '/tmp/junk.txt', '', '')),\n            ('imap://mail.python.org/mbox1',\n             ('imap', 'mail.python.org', '/mbox1', '', '', ''),\n             ('imap', 'mail.python.org', '/mbox1', '', '')),\n            ('mms://wms.sys.hinet.net/cts/Drama/09006251100.asf',\n             ('mms', 'wms.sys.hinet.net', '/cts/Drama/09006251100.asf',\n              '', '', ''),\n             ('mms', 'wms.sys.hinet.net', '/cts/Drama/09006251100.asf',\n              '', '')),\n            ('nfs://server/path/to/file.txt',\n             ('nfs', 'server', '/path/to/file.txt', '', '', ''),\n             ('nfs', 'server', '/path/to/file.txt', '', '')),\n            ('svn+ssh://svn.zope.org/repos/main/ZConfig/trunk/',\n             ('svn+ssh', 'svn.zope.org', '/repos/main/ZConfig/trunk/',\n              '', '', ''),\n             ('svn+ssh', 'svn.zope.org', '/repos/main/ZConfig/trunk/',\n              '', '')),\n            ('git+ssh://git@github.com/user/project.git',\n            ('git+ssh', 'git@github.com','/user/project.git',\n             '','',''),\n            ('git+ssh', 'git@github.com','/user/project.git',\n             '', '')),\n            ]\n        def _encode(t):\n            return (t[0].encode('ascii'),\n                    tuple(x.encode('ascii') for x in t[1]),\n                    tuple(x.encode('ascii') for x in t[2]))\n        bytes_cases = [_encode(x) for x in str_cases]\n        for url, parsed, split in str_cases + bytes_cases:\n            self.checkRoundtrips(url, parsed, split)\n\n    def test_http_roundtrips(self):\n        # urllib.parse.urlsplit treats 'http:' as an optimized special case,\n        # so we test both 'http:' and 'https:' in all the following.\n        # Three cheers for white box knowledge!\n        str_cases = [\n            ('://www.python.org',\n             ('www.python.org', '', '', '', ''),\n             ('www.python.org', '', '', '')),\n            ('://www.python.org#abc',\n             ('www.python.org', '', '', '', 'abc'),\n             ('www.python.org', '', '', 'abc')),\n            ('://www.python.org?q=abc',\n             ('www.python.org', '', '', 'q=abc', ''),\n             ('www.python.org', '', 'q=abc', '')),\n            ('://www.python.org/#abc',\n             ('www.python.org', '/', '', '', 'abc'),\n             ('www.python.org', '/', '', 'abc')),\n            ('://a/b/c/d;p?q#f',\n             ('a', '/b/c/d', 'p', 'q', 'f'),\n             ('a', '/b/c/d;p', 'q', 'f')),\n            ]\n        def _encode(t):\n            return (t[0].encode('ascii'),\n                    tuple(x.encode('ascii') for x in t[1]),\n                    tuple(x.encode('ascii') for x in t[2]))\n        bytes_cases = [_encode(x) for x in str_cases]\n        str_schemes = ('http', 'https')\n        bytes_schemes = (b'http', b'https')\n        str_tests = str_schemes, str_cases\n        bytes_tests = bytes_schemes, bytes_cases\n        for schemes, test_cases in (str_tests, bytes_tests):\n            for scheme in schemes:\n                for url, parsed, split in test_cases:\n                    url = scheme + url\n                    parsed = (scheme,) + parsed\n                    split = (scheme,) + split\n                    self.checkRoundtrips(url, parsed, split)\n\n    def checkJoin(self, base, relurl, expected):\n        str_components = (base, relurl, expected)\n        self.assertEqual(urllib.parse.urljoin(base, relurl), expected)\n        bytes_components = baseb, relurlb, expectedb = [\n                            x.encode('ascii') for x in str_components]\n        self.assertEqual(urllib.parse.urljoin(baseb, relurlb), expectedb)\n\n    def test_unparse_parse(self):\n        str_cases = ['Python', './Python','x-newscheme://foo.com/stuff','x://y','x:/y','x:/','/',]\n        bytes_cases = [x.encode('ascii') for x in str_cases]\n        for u in str_cases + bytes_cases:\n            self.assertEqual(urllib.parse.urlunsplit(urllib.parse.urlsplit(u)), u)\n            self.assertEqual(urllib.parse.urlunparse(urllib.parse.urlparse(u)), u)\n\n    def test_RFC1808(self):\n        # \"normal\" cases from RFC 1808:\n        self.checkJoin(RFC1808_BASE, 'g:h', 'g:h')\n        self.checkJoin(RFC1808_BASE, 'g', 'http://a/b/c/g')\n        self.checkJoin(RFC1808_BASE, './g', 'http://a/b/c/g')\n        self.checkJoin(RFC1808_BASE, 'g/', 'http://a/b/c/g/')\n        self.checkJoin(RFC1808_BASE, '/g', 'http://a/g')\n        self.checkJoin(RFC1808_BASE, '//g', 'http://g')\n        self.checkJoin(RFC1808_BASE, 'g?y', 'http://a/b/c/g?y')\n        self.checkJoin(RFC1808_BASE, 'g?y/./x', 'http://a/b/c/g?y/./x')\n        self.checkJoin(RFC1808_BASE, '#s', 'http://a/b/c/d;p?q#s')\n        self.checkJoin(RFC1808_BASE, 'g#s', 'http://a/b/c/g#s')\n        self.checkJoin(RFC1808_BASE, 'g#s/./x', 'http://a/b/c/g#s/./x')\n        self.checkJoin(RFC1808_BASE, 'g?y#s', 'http://a/b/c/g?y#s')\n        self.checkJoin(RFC1808_BASE, 'g;x', 'http://a/b/c/g;x')\n        self.checkJoin(RFC1808_BASE, 'g;x?y#s', 'http://a/b/c/g;x?y#s')\n        self.checkJoin(RFC1808_BASE, '.', 'http://a/b/c/')\n        self.checkJoin(RFC1808_BASE, './', 'http://a/b/c/')\n        self.checkJoin(RFC1808_BASE, '..', 'http://a/b/')\n        self.checkJoin(RFC1808_BASE, '../', 'http://a/b/')\n        self.checkJoin(RFC1808_BASE, '../g', 'http://a/b/g')\n        self.checkJoin(RFC1808_BASE, '../..', 'http://a/')\n        self.checkJoin(RFC1808_BASE, '../../', 'http://a/')\n        self.checkJoin(RFC1808_BASE, '../../g', 'http://a/g')\n\n        # \"abnormal\" cases from RFC 1808:\n        self.checkJoin(RFC1808_BASE, '', 'http://a/b/c/d;p?q#f')\n        self.checkJoin(RFC1808_BASE, 'g.', 'http://a/b/c/g.')\n        self.checkJoin(RFC1808_BASE, '.g', 'http://a/b/c/.g')\n        self.checkJoin(RFC1808_BASE, 'g..', 'http://a/b/c/g..')\n        self.checkJoin(RFC1808_BASE, '..g', 'http://a/b/c/..g')\n        self.checkJoin(RFC1808_BASE, './../g', 'http://a/b/g')\n        self.checkJoin(RFC1808_BASE, './g/.', 'http://a/b/c/g/')\n        self.checkJoin(RFC1808_BASE, 'g/./h', 'http://a/b/c/g/h')\n        self.checkJoin(RFC1808_BASE, 'g/../h', 'http://a/b/c/h')\n\n        # RFC 1808 and RFC 1630 disagree on these (according to RFC 1808),\n        # so we'll not actually run these tests (which expect 1808 behavior).\n        #self.checkJoin(RFC1808_BASE, 'http:g', 'http:g')\n        #self.checkJoin(RFC1808_BASE, 'http:', 'http:')\n\n        # XXX: The following tests are no longer compatible with RFC3986\n        # self.checkJoin(RFC1808_BASE, '../../../g', 'http://a/../g')\n        # self.checkJoin(RFC1808_BASE, '../../../../g', 'http://a/../../g')\n        # self.checkJoin(RFC1808_BASE, '/./g', 'http://a/./g')\n        # self.checkJoin(RFC1808_BASE, '/../g', 'http://a/../g')\n\n\n    def test_RFC2368(self):\n        # Issue 11467: path that starts with a number is not parsed correctly\n        self.assertEqual(urllib.parse.urlparse('mailto:1337@example.org'),\n                ('mailto', '', '1337@example.org', '', '', ''))\n\n    def test_RFC2396(self):\n        # cases from RFC 2396\n\n        self.checkJoin(RFC2396_BASE, 'g:h', 'g:h')\n        self.checkJoin(RFC2396_BASE, 'g', 'http://a/b/c/g')\n        self.checkJoin(RFC2396_BASE, './g', 'http://a/b/c/g')\n        self.checkJoin(RFC2396_BASE, 'g/', 'http://a/b/c/g/')\n        self.checkJoin(RFC2396_BASE, '/g', 'http://a/g')\n        self.checkJoin(RFC2396_BASE, '//g', 'http://g')\n        self.checkJoin(RFC2396_BASE, 'g?y', 'http://a/b/c/g?y')\n        self.checkJoin(RFC2396_BASE, '#s', 'http://a/b/c/d;p?q#s')\n        self.checkJoin(RFC2396_BASE, 'g#s', 'http://a/b/c/g#s')\n        self.checkJoin(RFC2396_BASE, 'g?y#s', 'http://a/b/c/g?y#s')\n        self.checkJoin(RFC2396_BASE, 'g;x', 'http://a/b/c/g;x')\n        self.checkJoin(RFC2396_BASE, 'g;x?y#s', 'http://a/b/c/g;x?y#s')\n        self.checkJoin(RFC2396_BASE, '.', 'http://a/b/c/')\n        self.checkJoin(RFC2396_BASE, './', 'http://a/b/c/')\n        self.checkJoin(RFC2396_BASE, '..', 'http://a/b/')\n        self.checkJoin(RFC2396_BASE, '../', 'http://a/b/')\n        self.checkJoin(RFC2396_BASE, '../g', 'http://a/b/g')\n        self.checkJoin(RFC2396_BASE, '../..', 'http://a/')\n        self.checkJoin(RFC2396_BASE, '../../', 'http://a/')\n        self.checkJoin(RFC2396_BASE, '../../g', 'http://a/g')\n        self.checkJoin(RFC2396_BASE, '', RFC2396_BASE)\n        self.checkJoin(RFC2396_BASE, 'g.', 'http://a/b/c/g.')\n        self.checkJoin(RFC2396_BASE, '.g', 'http://a/b/c/.g')\n        self.checkJoin(RFC2396_BASE, 'g..', 'http://a/b/c/g..')\n        self.checkJoin(RFC2396_BASE, '..g', 'http://a/b/c/..g')\n        self.checkJoin(RFC2396_BASE, './../g', 'http://a/b/g')\n        self.checkJoin(RFC2396_BASE, './g/.', 'http://a/b/c/g/')\n        self.checkJoin(RFC2396_BASE, 'g/./h', 'http://a/b/c/g/h')\n        self.checkJoin(RFC2396_BASE, 'g/../h', 'http://a/b/c/h')\n        self.checkJoin(RFC2396_BASE, 'g;x=1/./y', 'http://a/b/c/g;x=1/y')\n        self.checkJoin(RFC2396_BASE, 'g;x=1/../y', 'http://a/b/c/y')\n        self.checkJoin(RFC2396_BASE, 'g?y/./x', 'http://a/b/c/g?y/./x')\n        self.checkJoin(RFC2396_BASE, 'g?y/../x', 'http://a/b/c/g?y/../x')\n        self.checkJoin(RFC2396_BASE, 'g#s/./x', 'http://a/b/c/g#s/./x')\n        self.checkJoin(RFC2396_BASE, 'g#s/../x', 'http://a/b/c/g#s/../x')\n\n        # XXX: The following tests are no longer compatible with RFC3986\n        # self.checkJoin(RFC2396_BASE, '../../../g', 'http://a/../g')\n        # self.checkJoin(RFC2396_BASE, '../../../../g', 'http://a/../../g')\n        # self.checkJoin(RFC2396_BASE, '/./g', 'http://a/./g')\n        # self.checkJoin(RFC2396_BASE, '/../g', 'http://a/../g')\n\n    def test_RFC3986(self):\n        self.checkJoin(RFC3986_BASE, '?y','http://a/b/c/d;p?y')\n        self.checkJoin(RFC3986_BASE, ';x', 'http://a/b/c/;x')\n        self.checkJoin(RFC3986_BASE, 'g:h','g:h')\n        self.checkJoin(RFC3986_BASE, 'g','http://a/b/c/g')\n        self.checkJoin(RFC3986_BASE, './g','http://a/b/c/g')\n        self.checkJoin(RFC3986_BASE, 'g/','http://a/b/c/g/')\n        self.checkJoin(RFC3986_BASE, '/g','http://a/g')\n        self.checkJoin(RFC3986_BASE, '//g','http://g')\n        self.checkJoin(RFC3986_BASE, '?y','http://a/b/c/d;p?y')\n        self.checkJoin(RFC3986_BASE, 'g?y','http://a/b/c/g?y')\n        self.checkJoin(RFC3986_BASE, '#s','http://a/b/c/d;p?q#s')\n        self.checkJoin(RFC3986_BASE, 'g#s','http://a/b/c/g#s')\n        self.checkJoin(RFC3986_BASE, 'g?y#s','http://a/b/c/g?y#s')\n        self.checkJoin(RFC3986_BASE, ';x','http://a/b/c/;x')\n        self.checkJoin(RFC3986_BASE, 'g;x','http://a/b/c/g;x')\n        self.checkJoin(RFC3986_BASE, 'g;x?y#s','http://a/b/c/g;x?y#s')\n        self.checkJoin(RFC3986_BASE, '','http://a/b/c/d;p?q')\n        self.checkJoin(RFC3986_BASE, '.','http://a/b/c/')\n        self.checkJoin(RFC3986_BASE, './','http://a/b/c/')\n        self.checkJoin(RFC3986_BASE, '..','http://a/b/')\n        self.checkJoin(RFC3986_BASE, '../','http://a/b/')\n        self.checkJoin(RFC3986_BASE, '../g','http://a/b/g')\n        self.checkJoin(RFC3986_BASE, '../..','http://a/')\n        self.checkJoin(RFC3986_BASE, '../../','http://a/')\n        self.checkJoin(RFC3986_BASE, '../../g','http://a/g')\n        self.checkJoin(RFC3986_BASE, '../../../g', 'http://a/g')\n\n        # Abnormal Examples\n\n        # The 'abnormal scenarios' are incompatible with RFC2986 parsing\n        # Tests are here for reference.\n\n        self.checkJoin(RFC3986_BASE, '../../../g','http://a/g')\n        self.checkJoin(RFC3986_BASE, '../../../../g','http://a/g')\n        self.checkJoin(RFC3986_BASE, '/./g','http://a/g')\n        self.checkJoin(RFC3986_BASE, '/../g','http://a/g')\n        self.checkJoin(RFC3986_BASE, 'g.','http://a/b/c/g.')\n        self.checkJoin(RFC3986_BASE, '.g','http://a/b/c/.g')\n        self.checkJoin(RFC3986_BASE, 'g..','http://a/b/c/g..')\n        self.checkJoin(RFC3986_BASE, '..g','http://a/b/c/..g')\n        self.checkJoin(RFC3986_BASE, './../g','http://a/b/g')\n        self.checkJoin(RFC3986_BASE, './g/.','http://a/b/c/g/')\n        self.checkJoin(RFC3986_BASE, 'g/./h','http://a/b/c/g/h')\n        self.checkJoin(RFC3986_BASE, 'g/../h','http://a/b/c/h')\n        self.checkJoin(RFC3986_BASE, 'g;x=1/./y','http://a/b/c/g;x=1/y')\n        self.checkJoin(RFC3986_BASE, 'g;x=1/../y','http://a/b/c/y')\n        self.checkJoin(RFC3986_BASE, 'g?y/./x','http://a/b/c/g?y/./x')\n        self.checkJoin(RFC3986_BASE, 'g?y/../x','http://a/b/c/g?y/../x')\n        self.checkJoin(RFC3986_BASE, 'g#s/./x','http://a/b/c/g#s/./x')\n        self.checkJoin(RFC3986_BASE, 'g#s/../x','http://a/b/c/g#s/../x')\n        #self.checkJoin(RFC3986_BASE, 'http:g','http:g') # strict parser\n        self.checkJoin(RFC3986_BASE, 'http:g','http://a/b/c/g') #relaxed parser\n\n        # Test for issue9721\n        self.checkJoin('http://a/b/c/de', ';x','http://a/b/c/;x')\n\n    def test_urljoins(self):\n        self.checkJoin(SIMPLE_BASE, 'g:h','g:h')\n        self.checkJoin(SIMPLE_BASE, 'http:g','http://a/b/c/g')\n        self.checkJoin(SIMPLE_BASE, 'http:','http://a/b/c/d')\n        self.checkJoin(SIMPLE_BASE, 'g','http://a/b/c/g')\n        self.checkJoin(SIMPLE_BASE, './g','http://a/b/c/g')\n        self.checkJoin(SIMPLE_BASE, 'g/','http://a/b/c/g/')\n        self.checkJoin(SIMPLE_BASE, '/g','http://a/g')\n        self.checkJoin(SIMPLE_BASE, '//g','http://g')\n        self.checkJoin(SIMPLE_BASE, '?y','http://a/b/c/d?y')\n        self.checkJoin(SIMPLE_BASE, 'g?y','http://a/b/c/g?y')\n        self.checkJoin(SIMPLE_BASE, 'g?y/./x','http://a/b/c/g?y/./x')\n        self.checkJoin(SIMPLE_BASE, '.','http://a/b/c/')\n        self.checkJoin(SIMPLE_BASE, './','http://a/b/c/')\n        self.checkJoin(SIMPLE_BASE, '..','http://a/b/')\n        self.checkJoin(SIMPLE_BASE, '../','http://a/b/')\n        self.checkJoin(SIMPLE_BASE, '../g','http://a/b/g')\n        self.checkJoin(SIMPLE_BASE, '../..','http://a/')\n        self.checkJoin(SIMPLE_BASE, '../../g','http://a/g')\n        self.checkJoin(SIMPLE_BASE, './../g','http://a/b/g')\n        self.checkJoin(SIMPLE_BASE, './g/.','http://a/b/c/g/')\n        self.checkJoin(SIMPLE_BASE, 'g/./h','http://a/b/c/g/h')\n        self.checkJoin(SIMPLE_BASE, 'g/../h','http://a/b/c/h')\n        self.checkJoin(SIMPLE_BASE, 'http:g','http://a/b/c/g')\n        self.checkJoin(SIMPLE_BASE, 'http:','http://a/b/c/d')\n        self.checkJoin(SIMPLE_BASE, 'http:?y','http://a/b/c/d?y')\n        self.checkJoin(SIMPLE_BASE, 'http:g?y','http://a/b/c/g?y')\n        self.checkJoin(SIMPLE_BASE, 'http:g?y/./x','http://a/b/c/g?y/./x')\n        self.checkJoin('http:///', '..','http:///')\n        self.checkJoin('', 'http://a/b/c/g?y/./x','http://a/b/c/g?y/./x')\n        self.checkJoin('', 'http://a/./g', 'http://a/./g')\n        self.checkJoin('svn://pathtorepo/dir1', 'dir2', 'svn://pathtorepo/dir2')\n        self.checkJoin('svn+ssh://pathtorepo/dir1', 'dir2', 'svn+ssh://pathtorepo/dir2')\n        self.checkJoin('ws://a/b','g','ws://a/g')\n        self.checkJoin('wss://a/b','g','wss://a/g')\n\n        # XXX: The following tests are no longer compatible with RFC3986\n        # self.checkJoin(SIMPLE_BASE, '../../../g','http://a/../g')\n        # self.checkJoin(SIMPLE_BASE, '/./g','http://a/./g')\n\n        # test for issue22118 duplicate slashes\n        self.checkJoin(SIMPLE_BASE + '/', 'foo', SIMPLE_BASE + '/foo')\n\n        # Non-RFC-defined tests, covering variations of base and trailing\n        # slashes\n        self.checkJoin('http://a/b/c/d/e/', '../../f/g/', 'http://a/b/c/f/g/')\n        self.checkJoin('http://a/b/c/d/e', '../../f/g/', 'http://a/b/f/g/')\n        self.checkJoin('http://a/b/c/d/e/', '/../../f/g/', 'http://a/f/g/')\n        self.checkJoin('http://a/b/c/d/e', '/../../f/g/', 'http://a/f/g/')\n        self.checkJoin('http://a/b/c/d/e/', '../../f/g', 'http://a/b/c/f/g')\n        self.checkJoin('http://a/b/', '../../f/g/', 'http://a/f/g/')\n\n        # issue 23703: don't duplicate filename\n        self.checkJoin('a', 'b', 'b')\n\n    def test_RFC2732(self):\n        str_cases = [\n            ('http://Test.python.org:5432/foo/', 'test.python.org', 5432),\n            ('http://12.34.56.78:5432/foo/', '12.34.56.78', 5432),\n            ('http://[::1]:5432/foo/', '::1', 5432),\n            ('http://[dead:beef::1]:5432/foo/', 'dead:beef::1', 5432),\n            ('http://[dead:beef::]:5432/foo/', 'dead:beef::', 5432),\n            ('http://[dead:beef:cafe:5417:affe:8FA3:deaf:feed]:5432/foo/',\n             'dead:beef:cafe:5417:affe:8fa3:deaf:feed', 5432),\n            ('http://[::12.34.56.78]:5432/foo/', '::12.34.56.78', 5432),\n            ('http://[::ffff:12.34.56.78]:5432/foo/',\n             '::ffff:12.34.56.78', 5432),\n            ('http://Test.python.org/foo/', 'test.python.org', None),\n            ('http://12.34.56.78/foo/', '12.34.56.78', None),\n            ('http://[::1]/foo/', '::1', None),\n            ('http://[dead:beef::1]/foo/', 'dead:beef::1', None),\n            ('http://[dead:beef::]/foo/', 'dead:beef::', None),\n            ('http://[dead:beef:cafe:5417:affe:8FA3:deaf:feed]/foo/',\n             'dead:beef:cafe:5417:affe:8fa3:deaf:feed', None),\n            ('http://[::12.34.56.78]/foo/', '::12.34.56.78', None),\n            ('http://[::ffff:12.34.56.78]/foo/',\n             '::ffff:12.34.56.78', None),\n            ('http://Test.python.org:/foo/', 'test.python.org', None),\n            ('http://12.34.56.78:/foo/', '12.34.56.78', None),\n            ('http://[::1]:/foo/', '::1', None),\n            ('http://[dead:beef::1]:/foo/', 'dead:beef::1', None),\n            ('http://[dead:beef::]:/foo/', 'dead:beef::', None),\n            ('http://[dead:beef:cafe:5417:affe:8FA3:deaf:feed]:/foo/',\n             'dead:beef:cafe:5417:affe:8fa3:deaf:feed', None),\n            ('http://[::12.34.56.78]:/foo/', '::12.34.56.78', None),\n            ('http://[::ffff:12.34.56.78]:/foo/',\n             '::ffff:12.34.56.78', None),\n            ]\n        def _encode(t):\n            return t[0].encode('ascii'), t[1].encode('ascii'), t[2]\n        bytes_cases = [_encode(x) for x in str_cases]\n        for url, hostname, port in str_cases + bytes_cases:\n            urlparsed = urllib.parse.urlparse(url)\n            self.assertEqual((urlparsed.hostname, urlparsed.port) , (hostname, port))\n\n        str_cases = [\n                'http://::12.34.56.78]/',\n                'http://[::1/foo/',\n                'ftp://[::1/foo/bad]/bad',\n                'http://[::1/foo/bad]/bad',\n                'http://[::ffff:12.34.56.78']\n        bytes_cases = [x.encode('ascii') for x in str_cases]\n        for invalid_url in str_cases + bytes_cases:\n            self.assertRaises(ValueError, urllib.parse.urlparse, invalid_url)\n\n    def test_urldefrag(self):\n        str_cases = [\n            ('http://python.org#frag', 'http://python.org', 'frag'),\n            ('http://python.org', 'http://python.org', ''),\n            ('http://python.org/#frag', 'http://python.org/', 'frag'),\n            ('http://python.org/', 'http://python.org/', ''),\n            ('http://python.org/?q#frag', 'http://python.org/?q', 'frag'),\n            ('http://python.org/?q', 'http://python.org/?q', ''),\n            ('http://python.org/p#frag', 'http://python.org/p', 'frag'),\n            ('http://python.org/p?q', 'http://python.org/p?q', ''),\n            (RFC1808_BASE, 'http://a/b/c/d;p?q', 'f'),\n            (RFC2396_BASE, 'http://a/b/c/d;p?q', ''),\n        ]\n        def _encode(t):\n            return type(t)(x.encode('ascii') for x in t)\n        bytes_cases = [_encode(x) for x in str_cases]\n        for url, defrag, frag in str_cases + bytes_cases:\n            result = urllib.parse.urldefrag(url)\n            self.assertEqual(result.geturl(), url)\n            self.assertEqual(result, (defrag, frag))\n            self.assertEqual(result.url, defrag)\n            self.assertEqual(result.fragment, frag)\n\n    def test_urlsplit_scoped_IPv6(self):\n        p = urllib.parse.urlsplit('http://[FE80::822a:a8ff:fe49:470c%tESt]:1234')\n        self.assertEqual(p.hostname, \"fe80::822a:a8ff:fe49:470c%tESt\")\n        self.assertEqual(p.netloc, '[FE80::822a:a8ff:fe49:470c%tESt]:1234')\n\n        p = urllib.parse.urlsplit(b'http://[FE80::822a:a8ff:fe49:470c%tESt]:1234')\n        self.assertEqual(p.hostname, b\"fe80::822a:a8ff:fe49:470c%tESt\")\n        self.assertEqual(p.netloc, b'[FE80::822a:a8ff:fe49:470c%tESt]:1234')\n\n    def test_urlsplit_attributes(self):\n        url = \"HTTP://WWW.PYTHON.ORG/doc/#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, \"http\")\n        self.assertEqual(p.netloc, \"WWW.PYTHON.ORG\")\n        self.assertEqual(p.path, \"/doc/\")\n        self.assertEqual(p.query, \"\")\n        self.assertEqual(p.fragment, \"frag\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, \"www.python.org\")\n        self.assertEqual(p.port, None)\n        # geturl() won't return exactly the original URL in this case\n        # since the scheme is always case-normalized\n        # We handle this by ignoring the first 4 characters of the URL\n        self.assertEqual(p.geturl()[4:], url[4:])\n\n        url = \"http://User:Pass@www.python.org:080/doc/?query=yes#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, \"http\")\n        self.assertEqual(p.netloc, \"User:Pass@www.python.org:080\")\n        self.assertEqual(p.path, \"/doc/\")\n        self.assertEqual(p.query, \"query=yes\")\n        self.assertEqual(p.fragment, \"frag\")\n        self.assertEqual(p.username, \"User\")\n        self.assertEqual(p.password, \"Pass\")\n        self.assertEqual(p.hostname, \"www.python.org\")\n        self.assertEqual(p.port, 80)\n        self.assertEqual(p.geturl(), url)\n\n        # Addressing issue1698, which suggests Username can contain\n        # \"@\" characters.  Though not RFC compliant, many ftp sites allow\n        # and request email addresses as usernames.\n\n        url = \"http://User@example.com:Pass@www.python.org:080/doc/?query=yes#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, \"http\")\n        self.assertEqual(p.netloc, \"User@example.com:Pass@www.python.org:080\")\n        self.assertEqual(p.path, \"/doc/\")\n        self.assertEqual(p.query, \"query=yes\")\n        self.assertEqual(p.fragment, \"frag\")\n        self.assertEqual(p.username, \"User@example.com\")\n        self.assertEqual(p.password, \"Pass\")\n        self.assertEqual(p.hostname, \"www.python.org\")\n        self.assertEqual(p.port, 80)\n        self.assertEqual(p.geturl(), url)\n\n        # And check them all again, only with bytes this time\n        url = b\"HTTP://WWW.PYTHON.ORG/doc/#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, b\"http\")\n        self.assertEqual(p.netloc, b\"WWW.PYTHON.ORG\")\n        self.assertEqual(p.path, b\"/doc/\")\n        self.assertEqual(p.query, b\"\")\n        self.assertEqual(p.fragment, b\"frag\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, b\"www.python.org\")\n        self.assertEqual(p.port, None)\n        self.assertEqual(p.geturl()[4:], url[4:])\n\n        url = b\"http://User:Pass@www.python.org:080/doc/?query=yes#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, b\"http\")\n        self.assertEqual(p.netloc, b\"User:Pass@www.python.org:080\")\n        self.assertEqual(p.path, b\"/doc/\")\n        self.assertEqual(p.query, b\"query=yes\")\n        self.assertEqual(p.fragment, b\"frag\")\n        self.assertEqual(p.username, b\"User\")\n        self.assertEqual(p.password, b\"Pass\")\n        self.assertEqual(p.hostname, b\"www.python.org\")\n        self.assertEqual(p.port, 80)\n        self.assertEqual(p.geturl(), url)\n\n        url = b\"http://User@example.com:Pass@www.python.org:080/doc/?query=yes#frag\"\n        p = urllib.parse.urlsplit(url)\n        self.assertEqual(p.scheme, b\"http\")\n        self.assertEqual(p.netloc, b\"User@example.com:Pass@www.python.org:080\")\n        self.assertEqual(p.path, b\"/doc/\")\n        self.assertEqual(p.query, b\"query=yes\")\n        self.assertEqual(p.fragment, b\"frag\")\n        self.assertEqual(p.username, b\"User@example.com\")\n        self.assertEqual(p.password, b\"Pass\")\n        self.assertEqual(p.hostname, b\"www.python.org\")\n        self.assertEqual(p.port, 80)\n        self.assertEqual(p.geturl(), url)\n\n        # Verify an illegal port raises ValueError\n        url = b\"HTTP://WWW.PYTHON.ORG:65536/doc/#frag\"\n        p = urllib.parse.urlsplit(url)\n        with self.assertRaisesRegex(ValueError, \"out of range\"):\n            p.port\n\n    def test_attributes_bad_port(self):\n        \"\"\"Check handling of invalid ports.\"\"\"\n        for bytes in (False, True):\n            for parse in (urllib.parse.urlsplit, urllib.parse.urlparse):\n                for port in (\"foo\", \"1.5\", \"-1\", \"0x10\"):\n                    with self.subTest(bytes=bytes, parse=parse, port=port):\n                        netloc = \"www.example.net:\" + port\n                        url = \"http://\" + netloc\n                        if bytes:\n                            netloc = netloc.encode(\"ascii\")\n                            url = url.encode(\"ascii\")\n                        p = parse(url)\n                        self.assertEqual(p.netloc, netloc)\n                        with self.assertRaises(ValueError):\n                            p.port\n\n    def test_attributes_without_netloc(self):\n        # This example is straight from RFC 3261.  It looks like it\n        # should allow the username, hostname, and port to be filled\n        # in, but doesn't.  Since it's a URI and doesn't use the\n        # scheme://netloc syntax, the netloc and related attributes\n        # should be left empty.\n        uri = \"sip:alice@atlanta.com;maddr=239.255.255.1;ttl=15\"\n        p = urllib.parse.urlsplit(uri)\n        self.assertEqual(p.netloc, \"\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, None)\n        self.assertEqual(p.port, None)\n        self.assertEqual(p.geturl(), uri)\n\n        p = urllib.parse.urlparse(uri)\n        self.assertEqual(p.netloc, \"\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, None)\n        self.assertEqual(p.port, None)\n        self.assertEqual(p.geturl(), uri)\n\n        # You guessed it, repeating the test with bytes input\n        uri = b\"sip:alice@atlanta.com;maddr=239.255.255.1;ttl=15\"\n        p = urllib.parse.urlsplit(uri)\n        self.assertEqual(p.netloc, b\"\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, None)\n        self.assertEqual(p.port, None)\n        self.assertEqual(p.geturl(), uri)\n\n        p = urllib.parse.urlparse(uri)\n        self.assertEqual(p.netloc, b\"\")\n        self.assertEqual(p.username, None)\n        self.assertEqual(p.password, None)\n        self.assertEqual(p.hostname, None)\n        self.assertEqual(p.port, None)\n        self.assertEqual(p.geturl(), uri)\n\n    def test_noslash(self):\n        # Issue 1637: http://foo.com?query is legal\n        self.assertEqual(urllib.parse.urlparse(\"http://example.com?blahblah=/foo\"),\n                         ('http', 'example.com', '', '', 'blahblah=/foo', ''))\n        self.assertEqual(urllib.parse.urlparse(b\"http://example.com?blahblah=/foo\"),\n                         (b'http', b'example.com', b'', b'', b'blahblah=/foo', b''))\n\n    def test_withoutscheme(self):\n        # Test urlparse without scheme\n        # Issue 754016: urlparse goes wrong with IP:port without scheme\n        # RFC 1808 specifies that netloc should start with //, urlparse expects\n        # the same, otherwise it classifies the portion of url as path.\n        self.assertEqual(urllib.parse.urlparse(\"path\"),\n                ('','','path','','',''))\n        self.assertEqual(urllib.parse.urlparse(\"//www.python.org:80\"),\n                ('','www.python.org:80','','','',''))\n        self.assertEqual(urllib.parse.urlparse(\"http://www.python.org:80\"),\n                ('http','www.python.org:80','','','',''))\n        # Repeat for bytes input\n        self.assertEqual(urllib.parse.urlparse(b\"path\"),\n                (b'',b'',b'path',b'',b'',b''))\n        self.assertEqual(urllib.parse.urlparse(b\"//www.python.org:80\"),\n                (b'',b'www.python.org:80',b'',b'',b'',b''))\n        self.assertEqual(urllib.parse.urlparse(b\"http://www.python.org:80\"),\n                (b'http',b'www.python.org:80',b'',b'',b'',b''))\n\n    def test_portseparator(self):\n        # Issue 754016 makes changes for port separator ':' from scheme separator\n        self.assertEqual(urllib.parse.urlparse(\"path:80\"),\n                ('','','path:80','','',''))\n        self.assertEqual(urllib.parse.urlparse(\"http:\"),('http','','','','',''))\n        self.assertEqual(urllib.parse.urlparse(\"https:\"),('https','','','','',''))\n        self.assertEqual(urllib.parse.urlparse(\"http://www.python.org:80\"),\n                ('http','www.python.org:80','','','',''))\n        # As usual, need to check bytes input as well\n        self.assertEqual(urllib.parse.urlparse(b\"path:80\"),\n                (b'',b'',b'path:80',b'',b'',b''))\n        self.assertEqual(urllib.parse.urlparse(b\"http:\"),(b'http',b'',b'',b'',b'',b''))\n        self.assertEqual(urllib.parse.urlparse(b\"https:\"),(b'https',b'',b'',b'',b'',b''))\n        self.assertEqual(urllib.parse.urlparse(b\"http://www.python.org:80\"),\n                (b'http',b'www.python.org:80',b'',b'',b'',b''))\n\n    def test_usingsys(self):\n        # Issue 3314: sys module is used in the error\n        self.assertRaises(TypeError, urllib.parse.urlencode, \"foo\")\n\n    def test_anyscheme(self):\n        # Issue 7904: s3://foo.com/stuff has netloc \"foo.com\".\n        self.assertEqual(urllib.parse.urlparse(\"s3://foo.com/stuff\"),\n                         ('s3', 'foo.com', '/stuff', '', '', ''))\n        self.assertEqual(urllib.parse.urlparse(\"x-newscheme://foo.com/stuff\"),\n                         ('x-newscheme', 'foo.com', '/stuff', '', '', ''))\n        self.assertEqual(urllib.parse.urlparse(\"x-newscheme://foo.com/stuff?query#fragment\"),\n                         ('x-newscheme', 'foo.com', '/stuff', '', 'query', 'fragment'))\n        self.assertEqual(urllib.parse.urlparse(\"x-newscheme://foo.com/stuff?query\"),\n                         ('x-newscheme', 'foo.com', '/stuff', '', 'query', ''))\n\n        # And for bytes...\n        self.assertEqual(urllib.parse.urlparse(b\"s3://foo.com/stuff\"),\n                         (b's3', b'foo.com', b'/stuff', b'', b'', b''))\n        self.assertEqual(urllib.parse.urlparse(b\"x-newscheme://foo.com/stuff\"),\n                         (b'x-newscheme', b'foo.com', b'/stuff', b'', b'', b''))\n        self.assertEqual(urllib.parse.urlparse(b\"x-newscheme://foo.com/stuff?query#fragment\"),\n                         (b'x-newscheme', b'foo.com', b'/stuff', b'', b'query', b'fragment'))\n        self.assertEqual(urllib.parse.urlparse(b\"x-newscheme://foo.com/stuff?query\"),\n                         (b'x-newscheme', b'foo.com', b'/stuff', b'', b'query', b''))\n\n    def test_default_scheme(self):\n        # Exercise the scheme parameter of urlparse() and urlsplit()\n        for func in (urllib.parse.urlparse, urllib.parse.urlsplit):\n            with self.subTest(function=func):\n                result = func(\"http://example.net/\", \"ftp\")\n                self.assertEqual(result.scheme, \"http\")\n                result = func(b\"http://example.net/\", b\"ftp\")\n                self.assertEqual(result.scheme, b\"http\")\n                self.assertEqual(func(\"path\", \"ftp\").scheme, \"ftp\")\n                self.assertEqual(func(\"path\", scheme=\"ftp\").scheme, \"ftp\")\n                self.assertEqual(func(b\"path\", scheme=b\"ftp\").scheme, b\"ftp\")\n                self.assertEqual(func(\"path\").scheme, \"\")\n                self.assertEqual(func(b\"path\").scheme, b\"\")\n                self.assertEqual(func(b\"path\", \"\").scheme, b\"\")\n\n    def test_parse_fragments(self):\n        # Exercise the allow_fragments parameter of urlparse() and urlsplit()\n        tests = (\n            (\"http:#frag\", \"path\", \"frag\"),\n            (\"//example.net#frag\", \"path\", \"frag\"),\n            (\"index.html#frag\", \"path\", \"frag\"),\n            (\";a=b#frag\", \"params\", \"frag\"),\n            (\"?a=b#frag\", \"query\", \"frag\"),\n            (\"#frag\", \"path\", \"frag\"),\n            (\"abc#@frag\", \"path\", \"@frag\"),\n            (\"//abc#@frag\", \"path\", \"@frag\"),\n            (\"//abc:80#@frag\", \"path\", \"@frag\"),\n            (\"//abc#@frag:80\", \"path\", \"@frag:80\"),\n        )\n        for url, attr, expected_frag in tests:\n            for func in (urllib.parse.urlparse, urllib.parse.urlsplit):\n                if attr == \"params\" and func is urllib.parse.urlsplit:\n                    attr = \"path\"\n                with self.subTest(url=url, function=func):\n                    result = func(url, allow_fragments=False)\n                    self.assertEqual(result.fragment, \"\")\n                    self.assertTrue(\n                            getattr(result, attr).endswith(\"#\" + expected_frag))\n                    self.assertEqual(func(url, \"\", False).fragment, \"\")\n\n                    result = func(url, allow_fragments=True)\n                    self.assertEqual(result.fragment, expected_frag)\n                    self.assertFalse(\n                            getattr(result, attr).endswith(expected_frag))\n                    self.assertEqual(func(url, \"\", True).fragment,\n                                     expected_frag)\n                    self.assertEqual(func(url).fragment, expected_frag)\n\n    def test_mixed_types_rejected(self):\n        # Several functions that process either strings or ASCII encoded bytes\n        # accept multiple arguments. Check they reject mixed type input\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlparse(\"www.python.org\", b\"http\")\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlparse(b\"www.python.org\", \"http\")\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlsplit(\"www.python.org\", b\"http\")\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlsplit(b\"www.python.org\", \"http\")\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlunparse(( b\"http\", \"www.python.org\",\"\",\"\",\"\",\"\"))\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlunparse((\"http\", b\"www.python.org\",\"\",\"\",\"\",\"\"))\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlunsplit((b\"http\", \"www.python.org\",\"\",\"\",\"\"))\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urlunsplit((\"http\", b\"www.python.org\",\"\",\"\",\"\"))\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urljoin(\"http://python.org\", b\"http://python.org\")\n        with self.assertRaisesRegex(TypeError, \"Cannot mix str\"):\n            urllib.parse.urljoin(b\"http://python.org\", \"http://python.org\")\n\n    def _check_result_type(self, str_type):\n        num_args = len(str_type._fields)\n        bytes_type = str_type._encoded_counterpart\n        self.assertIs(bytes_type._decoded_counterpart, str_type)\n        str_args = ('',) * num_args\n        bytes_args = (b'',) * num_args\n        str_result = str_type(*str_args)\n        bytes_result = bytes_type(*bytes_args)\n        encoding = 'ascii'\n        errors = 'strict'\n        self.assertEqual(str_result, str_args)\n        self.assertEqual(bytes_result.decode(), str_args)\n        self.assertEqual(bytes_result.decode(), str_result)\n        self.assertEqual(bytes_result.decode(encoding), str_args)\n        self.assertEqual(bytes_result.decode(encoding), str_result)\n        self.assertEqual(bytes_result.decode(encoding, errors), str_args)\n        self.assertEqual(bytes_result.decode(encoding, errors), str_result)\n        self.assertEqual(bytes_result, bytes_args)\n        self.assertEqual(str_result.encode(), bytes_args)\n        self.assertEqual(str_result.encode(), bytes_result)\n        self.assertEqual(str_result.encode(encoding), bytes_args)\n        self.assertEqual(str_result.encode(encoding), bytes_result)\n        self.assertEqual(str_result.encode(encoding, errors), bytes_args)\n        self.assertEqual(str_result.encode(encoding, errors), bytes_result)\n\n    def test_result_pairs(self):\n        # Check encoding and decoding between result pairs\n        result_types = [\n          urllib.parse.DefragResult,\n          urllib.parse.SplitResult,\n          urllib.parse.ParseResult,\n        ]\n        for result_type in result_types:\n            self._check_result_type(result_type)\n\n    def test_parse_qs_encoding(self):\n        result = urllib.parse.parse_qs(\"key=\\u0141%E9\", encoding=\"latin-1\")\n        self.assertEqual(result, {'key': ['\\u0141\\xE9']})\n        result = urllib.parse.parse_qs(\"key=\\u0141%C3%A9\", encoding=\"utf-8\")\n        self.assertEqual(result, {'key': ['\\u0141\\xE9']})\n        result = urllib.parse.parse_qs(\"key=\\u0141%C3%A9\", encoding=\"ascii\")\n        self.assertEqual(result, {'key': ['\\u0141\\ufffd\\ufffd']})\n        result = urllib.parse.parse_qs(\"key=\\u0141%E9-\", encoding=\"ascii\")\n        self.assertEqual(result, {'key': ['\\u0141\\ufffd-']})\n        result = urllib.parse.parse_qs(\"key=\\u0141%E9-\", encoding=\"ascii\",\n                                                          errors=\"ignore\")\n        self.assertEqual(result, {'key': ['\\u0141-']})\n\n    def test_parse_qsl_encoding(self):\n        result = urllib.parse.parse_qsl(\"key=\\u0141%E9\", encoding=\"latin-1\")\n        self.assertEqual(result, [('key', '\\u0141\\xE9')])\n        result = urllib.parse.parse_qsl(\"key=\\u0141%C3%A9\", encoding=\"utf-8\")\n        self.assertEqual(result, [('key', '\\u0141\\xE9')])\n        result = urllib.parse.parse_qsl(\"key=\\u0141%C3%A9\", encoding=\"ascii\")\n        self.assertEqual(result, [('key', '\\u0141\\ufffd\\ufffd')])\n        result = urllib.parse.parse_qsl(\"key=\\u0141%E9-\", encoding=\"ascii\")\n        self.assertEqual(result, [('key', '\\u0141\\ufffd-')])\n        result = urllib.parse.parse_qsl(\"key=\\u0141%E9-\", encoding=\"ascii\",\n                                                          errors=\"ignore\")\n        self.assertEqual(result, [('key', '\\u0141-')])\n\n    def test_parse_qsl_max_num_fields(self):\n        with self.assertRaises(ValueError):\n            urllib.parse.parse_qs('&'.join(['a=a']*11), max_num_fields=10)\n        with self.assertRaises(ValueError):\n            urllib.parse.parse_qs(';'.join(['a=a']*11), max_num_fields=10)\n        urllib.parse.parse_qs('&'.join(['a=a']*10), max_num_fields=10)\n\n    def test_urlencode_sequences(self):\n        # Other tests incidentally urlencode things; test non-covered cases:\n        # Sequence and object values.\n        result = urllib.parse.urlencode({'a': [1, 2], 'b': (3, 4, 5)}, True)\n        # we cannot rely on ordering here\n        assert set(result.split('&')) == {'a=1', 'a=2', 'b=3', 'b=4', 'b=5'}\n\n        class Trivial:\n            def __str__(self):\n                return 'trivial'\n\n        result = urllib.parse.urlencode({'a': Trivial()}, True)\n        self.assertEqual(result, 'a=trivial')\n\n    def test_urlencode_quote_via(self):\n        result = urllib.parse.urlencode({'a': 'some value'})\n        self.assertEqual(result, \"a=some+value\")\n        result = urllib.parse.urlencode({'a': 'some value/another'},\n                                        quote_via=urllib.parse.quote)\n        self.assertEqual(result, \"a=some%20value%2Fanother\")\n        result = urllib.parse.urlencode({'a': 'some value/another'},\n                                        safe='/', quote_via=urllib.parse.quote)\n        self.assertEqual(result, \"a=some%20value/another\")\n\n    def test_quote_from_bytes(self):\n        self.assertRaises(TypeError, urllib.parse.quote_from_bytes, 'foo')\n        result = urllib.parse.quote_from_bytes(b'archaeological arcana')\n        self.assertEqual(result, 'archaeological%20arcana')\n        result = urllib.parse.quote_from_bytes(b'')\n        self.assertEqual(result, '')\n\n    def test_unquote_to_bytes(self):\n        result = urllib.parse.unquote_to_bytes('abc%20def')\n        self.assertEqual(result, b'abc def')\n        result = urllib.parse.unquote_to_bytes('')\n        self.assertEqual(result, b'')\n\n    def test_quote_errors(self):\n        self.assertRaises(TypeError, urllib.parse.quote, b'foo',\n                          encoding='utf-8')\n        self.assertRaises(TypeError, urllib.parse.quote, b'foo', errors='strict')\n\n    def test_issue14072(self):\n        p1 = urllib.parse.urlsplit('tel:+31-641044153')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '+31-641044153')\n        p2 = urllib.parse.urlsplit('tel:+31641044153')\n        self.assertEqual(p2.scheme, 'tel')\n        self.assertEqual(p2.path, '+31641044153')\n        # assert the behavior for urlparse\n        p1 = urllib.parse.urlparse('tel:+31-641044153')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '+31-641044153')\n        p2 = urllib.parse.urlparse('tel:+31641044153')\n        self.assertEqual(p2.scheme, 'tel')\n        self.assertEqual(p2.path, '+31641044153')\n\n    def test_telurl_params(self):\n        p1 = urllib.parse.urlparse('tel:123-4;phone-context=+1-650-516')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '123-4')\n        self.assertEqual(p1.params, 'phone-context=+1-650-516')\n\n        p1 = urllib.parse.urlparse('tel:+1-201-555-0123')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '+1-201-555-0123')\n        self.assertEqual(p1.params, '')\n\n        p1 = urllib.parse.urlparse('tel:7042;phone-context=example.com')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '7042')\n        self.assertEqual(p1.params, 'phone-context=example.com')\n\n        p1 = urllib.parse.urlparse('tel:863-1234;phone-context=+1-914-555')\n        self.assertEqual(p1.scheme, 'tel')\n        self.assertEqual(p1.path, '863-1234')\n        self.assertEqual(p1.params, 'phone-context=+1-914-555')\n\n    def test_Quoter_repr(self):\n        quoter = urllib.parse.Quoter(urllib.parse._ALWAYS_SAFE)\n        self.assertIn('Quoter', repr(quoter))\n\n    def test_all(self):\n        expected = []\n        undocumented = {\n            'splitattr', 'splithost', 'splitnport', 'splitpasswd',\n            'splitport', 'splitquery', 'splittag', 'splittype', 'splituser',\n            'splitvalue',\n            'Quoter', 'ResultBase', 'clear_cache', 'to_bytes', 'unwrap',\n        }\n        for name in dir(urllib.parse):\n            if name.startswith('_') or name in undocumented:\n                continue\n            object = getattr(urllib.parse, name)\n            if getattr(object, '__module__', None) == 'urllib.parse':\n                expected.append(name)\n        self.assertCountEqual(urllib.parse.__all__, expected)\n\n    def test_urlsplit_normalization(self):\n        # Certain characters should never occur in the netloc,\n        # including under normalization.\n        # Ensure that ALL of them are detected and cause an error\n        illegal_chars = '/:#?@'\n        hex_chars = {'{:04X}'.format(ord(c)) for c in illegal_chars}\n        denorm_chars = [\n            c for c in map(chr, range(128, sys.maxunicode))\n            if (hex_chars & set(unicodedata.decomposition(c).split()))\n            and c not in illegal_chars\n        ]\n        # Sanity check that we found at least one such character\n        self.assertIn('\\u2100', denorm_chars)\n        self.assertIn('\\uFF03', denorm_chars)\n\n        # bpo-36742: Verify port separators are ignored when they\n        # existed prior to decomposition\n        urllib.parse.urlsplit('http://\\u30d5\\u309a:80')\n        with self.assertRaises(ValueError):\n            urllib.parse.urlsplit('http://\\u30d5\\u309a\\ufe1380')\n\n        for scheme in [\"http\", \"https\", \"ftp\"]:\n            for netloc in [\"netloc{}false.netloc\", \"n{}user@netloc\"]:\n                for c in denorm_chars:\n                    url = \"{}://{}/path\".format(scheme, netloc.format(c))\n                    with self.subTest(url=url, char='{:04X}'.format(ord(c))):\n                        with self.assertRaises(ValueError):\n                            urllib.parse.urlsplit(url)\n\nclass Utility_Tests(unittest.TestCase):\n    \"\"\"Testcase to test the various utility functions in the urllib.\"\"\"\n    # In Python 2 this test class was in test_urllib.\n\n    def test_splittype(self):\n        splittype = urllib.parse.splittype\n        self.assertEqual(splittype('type:opaquestring'), ('type', 'opaquestring'))\n        self.assertEqual(splittype('opaquestring'), (None, 'opaquestring'))\n        self.assertEqual(splittype(':opaquestring'), (None, ':opaquestring'))\n        self.assertEqual(splittype('type:'), ('type', ''))\n        self.assertEqual(splittype('type:opaque:string'), ('type', 'opaque:string'))\n\n    def test_splithost(self):\n        splithost = urllib.parse.splithost\n        self.assertEqual(splithost('//www.example.org:80/foo/bar/baz.html'),\n                         ('www.example.org:80', '/foo/bar/baz.html'))\n        self.assertEqual(splithost('//www.example.org:80'),\n                         ('www.example.org:80', ''))\n        self.assertEqual(splithost('/foo/bar/baz.html'),\n                         (None, '/foo/bar/baz.html'))\n\n        # bpo-30500: # starts a fragment.\n        self.assertEqual(splithost('//127.0.0.1#@host.com'),\n                         ('127.0.0.1', '/#@host.com'))\n        self.assertEqual(splithost('//127.0.0.1#@host.com:80'),\n                         ('127.0.0.1', '/#@host.com:80'))\n        self.assertEqual(splithost('//127.0.0.1:80#@host.com'),\n                         ('127.0.0.1:80', '/#@host.com'))\n\n        # Empty host is returned as empty string.\n        self.assertEqual(splithost(\"///file\"),\n                         ('', '/file'))\n\n        # Trailing semicolon, question mark and hash symbol are kept.\n        self.assertEqual(splithost(\"//example.net/file;\"),\n                         ('example.net', '/file;'))\n        self.assertEqual(splithost(\"//example.net/file?\"),\n                         ('example.net', '/file?'))\n        self.assertEqual(splithost(\"//example.net/file#\"),\n                         ('example.net', '/file#'))\n\n    def test_splituser(self):\n        splituser = urllib.parse.splituser\n        self.assertEqual(splituser('User:Pass@www.python.org:080'),\n                         ('User:Pass', 'www.python.org:080'))\n        self.assertEqual(splituser('@www.python.org:080'),\n                         ('', 'www.python.org:080'))\n        self.assertEqual(splituser('www.python.org:080'),\n                         (None, 'www.python.org:080'))\n        self.assertEqual(splituser('User:Pass@'),\n                         ('User:Pass', ''))\n        self.assertEqual(splituser('User@example.com:Pass@www.python.org:080'),\n                         ('User@example.com:Pass', 'www.python.org:080'))\n\n    def test_splitpasswd(self):\n        # Some of the password examples are not sensible, but it is added to\n        # confirming to RFC2617 and addressing issue4675.\n        splitpasswd = urllib.parse.splitpasswd\n        self.assertEqual(splitpasswd('user:ab'), ('user', 'ab'))\n        self.assertEqual(splitpasswd('user:a\\nb'), ('user', 'a\\nb'))\n        self.assertEqual(splitpasswd('user:a\\tb'), ('user', 'a\\tb'))\n        self.assertEqual(splitpasswd('user:a\\rb'), ('user', 'a\\rb'))\n        self.assertEqual(splitpasswd('user:a\\fb'), ('user', 'a\\fb'))\n        self.assertEqual(splitpasswd('user:a\\vb'), ('user', 'a\\vb'))\n        self.assertEqual(splitpasswd('user:a:b'), ('user', 'a:b'))\n        self.assertEqual(splitpasswd('user:a b'), ('user', 'a b'))\n        self.assertEqual(splitpasswd('user 2:ab'), ('user 2', 'ab'))\n        self.assertEqual(splitpasswd('user+1:a+b'), ('user+1', 'a+b'))\n        self.assertEqual(splitpasswd('user:'), ('user', ''))\n        self.assertEqual(splitpasswd('user'), ('user', None))\n        self.assertEqual(splitpasswd(':ab'), ('', 'ab'))\n\n    def test_splitport(self):\n        splitport = urllib.parse.splitport\n        self.assertEqual(splitport('parrot:88'), ('parrot', '88'))\n        self.assertEqual(splitport('parrot'), ('parrot', None))\n        self.assertEqual(splitport('parrot:'), ('parrot', None))\n        self.assertEqual(splitport('127.0.0.1'), ('127.0.0.1', None))\n        self.assertEqual(splitport('parrot:cheese'), ('parrot:cheese', None))\n        self.assertEqual(splitport('[::1]:88'), ('[::1]', '88'))\n        self.assertEqual(splitport('[::1]'), ('[::1]', None))\n        self.assertEqual(splitport(':88'), ('', '88'))\n\n    def test_splitnport(self):\n        splitnport = urllib.parse.splitnport\n        self.assertEqual(splitnport('parrot:88'), ('parrot', 88))\n        self.assertEqual(splitnport('parrot'), ('parrot', -1))\n        self.assertEqual(splitnport('parrot', 55), ('parrot', 55))\n        self.assertEqual(splitnport('parrot:'), ('parrot', -1))\n        self.assertEqual(splitnport('parrot:', 55), ('parrot', 55))\n        self.assertEqual(splitnport('127.0.0.1'), ('127.0.0.1', -1))\n        self.assertEqual(splitnport('127.0.0.1', 55), ('127.0.0.1', 55))\n        self.assertEqual(splitnport('parrot:cheese'), ('parrot', None))\n        self.assertEqual(splitnport('parrot:cheese', 55), ('parrot', None))\n\n    def test_splitquery(self):\n        # Normal cases are exercised by other tests; ensure that we also\n        # catch cases with no port specified (testcase ensuring coverage)\n        splitquery = urllib.parse.splitquery\n        self.assertEqual(splitquery('http://python.org/fake?foo=bar'),\n                         ('http://python.org/fake', 'foo=bar'))\n        self.assertEqual(splitquery('http://python.org/fake?foo=bar?'),\n                         ('http://python.org/fake?foo=bar', ''))\n        self.assertEqual(splitquery('http://python.org/fake'),\n                         ('http://python.org/fake', None))\n        self.assertEqual(splitquery('?foo=bar'), ('', 'foo=bar'))\n\n    def test_splittag(self):\n        splittag = urllib.parse.splittag\n        self.assertEqual(splittag('http://example.com?foo=bar#baz'),\n                         ('http://example.com?foo=bar', 'baz'))\n        self.assertEqual(splittag('http://example.com?foo=bar#'),\n                         ('http://example.com?foo=bar', ''))\n        self.assertEqual(splittag('#baz'), ('', 'baz'))\n        self.assertEqual(splittag('http://example.com?foo=bar'),\n                         ('http://example.com?foo=bar', None))\n        self.assertEqual(splittag('http://example.com?foo=bar#baz#boo'),\n                         ('http://example.com?foo=bar#baz', 'boo'))\n\n    def test_splitattr(self):\n        splitattr = urllib.parse.splitattr\n        self.assertEqual(splitattr('/path;attr1=value1;attr2=value2'),\n                         ('/path', ['attr1=value1', 'attr2=value2']))\n        self.assertEqual(splitattr('/path;'), ('/path', ['']))\n        self.assertEqual(splitattr(';attr1=value1;attr2=value2'),\n                         ('', ['attr1=value1', 'attr2=value2']))\n        self.assertEqual(splitattr('/path'), ('/path', []))\n\n    def test_splitvalue(self):\n        # Normal cases are exercised by other tests; test pathological cases\n        # with no key/value pairs. (testcase ensuring coverage)\n        splitvalue = urllib.parse.splitvalue\n        self.assertEqual(splitvalue('foo=bar'), ('foo', 'bar'))\n        self.assertEqual(splitvalue('foo='), ('foo', ''))\n        self.assertEqual(splitvalue('=bar'), ('', 'bar'))\n        self.assertEqual(splitvalue('foobar'), ('foobar', None))\n        self.assertEqual(splitvalue('foo=bar=baz'), ('foo', 'bar=baz'))\n\n    def test_to_bytes(self):\n        result = urllib.parse.to_bytes('http://www.python.org')\n        self.assertEqual(result, 'http://www.python.org')\n        self.assertRaises(UnicodeError, urllib.parse.to_bytes,\n                          'http://www.python.org/medi\\u00e6val')\n\n    def test_unwrap(self):\n        url = urllib.parse.unwrap('<URL:type://host/path>')\n        self.assertEqual(url, 'type://host/path')\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "\"\"\"Parse (absolute and relative) URLs.\n\nurlparse module is based upon the following RFC specifications.\n\nRFC 3986 (STD66): \"Uniform Resource Identifiers\" by T. Berners-Lee, R. Fielding\nand L.  Masinter, January 2005.\n\nRFC 2732 : \"Format for Literal IPv6 Addresses in URL's by R.Hinden, B.Carpenter\nand L.Masinter, December 1999.\n\nRFC 2396:  \"Uniform Resource Identifiers (URI)\": Generic Syntax by T.\nBerners-Lee, R. Fielding, and L. Masinter, August 1998.\n\nRFC 2368: \"The mailto URL scheme\", by P.Hoffman , L Masinter, J. Zawinski, July 1998.\n\nRFC 1808: \"Relative Uniform Resource Locators\", by R. Fielding, UC Irvine, June\n1995.\n\nRFC 1738: \"Uniform Resource Locators (URL)\" by T. Berners-Lee, L. Masinter, M.\nMcCahill, December 1994\n\nRFC 3986 is considered the current standard and any future changes to\nurlparse module should conform with it.  The urlparse module is\ncurrently not entirely compliant with this RFC due to defacto\nscenarios for parsing, and for backward compatibility purposes, some\nparsing quirks from older RFCs are retained. The testcases in\ntest_urlparse.py provides a good indicator of parsing behavior.\n\"\"\"\n\nimport re\nimport sys\nimport collections\n\n__all__ = [\"urlparse\", \"urlunparse\", \"urljoin\", \"urldefrag\",\n           \"urlsplit\", \"urlunsplit\", \"urlencode\", \"parse_qs\",\n           \"parse_qsl\", \"quote\", \"quote_plus\", \"quote_from_bytes\",\n           \"unquote\", \"unquote_plus\", \"unquote_to_bytes\",\n           \"DefragResult\", \"ParseResult\", \"SplitResult\",\n           \"DefragResultBytes\", \"ParseResultBytes\", \"SplitResultBytes\"]\n\n# A classification of schemes.\n# The empty string classifies URLs with no scheme specified,\n# being the default value returned by \u201curlsplit\u201d and \u201curlparse\u201d.\n\nuses_relative = ['', 'ftp', 'http', 'gopher', 'nntp', 'imap',\n                 'wais', 'file', 'https', 'shttp', 'mms',\n                 'prospero', 'rtsp', 'rtspu', 'sftp',\n                 'svn', 'svn+ssh', 'ws', 'wss']\n\nuses_netloc = ['', 'ftp', 'http', 'gopher', 'nntp', 'telnet',\n               'imap', 'wais', 'file', 'mms', 'https', 'shttp',\n               'snews', 'prospero', 'rtsp', 'rtspu', 'rsync',\n               'svn', 'svn+ssh', 'sftp', 'nfs', 'git', 'git+ssh',\n               'ws', 'wss']\n\nuses_params = ['', 'ftp', 'hdl', 'prospero', 'http', 'imap',\n               'https', 'shttp', 'rtsp', 'rtspu', 'sip', 'sips',\n               'mms', 'sftp', 'tel']\n\n# These are not actually used anymore, but should stay for backwards\n# compatibility.  (They are undocumented, but have a public-looking name.)\n\nnon_hierarchical = ['gopher', 'hdl', 'mailto', 'news',\n                    'telnet', 'wais', 'imap', 'snews', 'sip', 'sips']\n\nuses_query = ['', 'http', 'wais', 'imap', 'https', 'shttp', 'mms',\n              'gopher', 'rtsp', 'rtspu', 'sip', 'sips']\n\nuses_fragment = ['', 'ftp', 'hdl', 'http', 'gopher', 'news',\n                 'nntp', 'wais', 'https', 'shttp', 'snews',\n                 'file', 'prospero']\n\n# Characters valid in scheme names\nscheme_chars = ('abcdefghijklmnopqrstuvwxyz'\n                'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n                '0123456789'\n                '+-.')\n\n# XXX: Consider replacing with functools.lru_cache\nMAX_CACHE_SIZE = 20\n_parse_cache = {}\n\ndef clear_cache():\n    \"\"\"Clear the parse cache and the quoters cache.\"\"\"\n    _parse_cache.clear()\n    _safe_quoters.clear()\n\n\n# Helpers for bytes handling\n# For 3.2, we deliberately require applications that\n# handle improperly quoted URLs to do their own\n# decoding and encoding. If valid use cases are\n# presented, we may relax this by using latin-1\n# decoding internally for 3.3\n_implicit_encoding = 'ascii'\n_implicit_errors = 'strict'\n\ndef _noop(obj):\n    return obj\n\ndef _encode_result(obj, encoding=_implicit_encoding,\n                        errors=_implicit_errors):\n    return obj.encode(encoding, errors)\n\ndef _decode_args(args, encoding=_implicit_encoding,\n                       errors=_implicit_errors):\n    return tuple(x.decode(encoding, errors) if x else '' for x in args)\n\ndef _coerce_args(*args):\n    # Invokes decode if necessary to create str args\n    # and returns the coerced inputs along with\n    # an appropriate result coercion function\n    #   - noop for str inputs\n    #   - encoding function otherwise\n    str_input = isinstance(args[0], str)\n    for arg in args[1:]:\n        # We special-case the empty string to support the\n        # \"scheme=''\" default argument to some functions\n        if arg and isinstance(arg, str) != str_input:\n            raise TypeError(\"Cannot mix str and non-str arguments\")\n    if str_input:\n        return args + (_noop,)\n    return _decode_args(args) + (_encode_result,)\n\n# Result objects are more helpful than simple tuples\nclass _ResultMixinStr(object):\n    \"\"\"Standard approach to encoding parsed results from str to bytes\"\"\"\n    __slots__ = ()\n\n    def encode(self, encoding='ascii', errors='strict'):\n        return self._encoded_counterpart(*(x.encode(encoding, errors) for x in self))\n\n\nclass _ResultMixinBytes(object):\n    \"\"\"Standard approach to decoding parsed results from bytes to str\"\"\"\n    __slots__ = ()\n\n    def decode(self, encoding='ascii', errors='strict'):\n        return self._decoded_counterpart(*(x.decode(encoding, errors) for x in self))\n\n\nclass _NetlocResultMixinBase(object):\n    \"\"\"Shared methods for the parsed result objects containing a netloc element\"\"\"\n    __slots__ = ()\n\n    @property\n    def username(self):\n        return self._userinfo[0]\n\n    @property\n    def password(self):\n        return self._userinfo[1]\n\n    @property\n    def hostname(self):\n        hostname = self._hostinfo[0]\n        if not hostname:\n            return None\n        # Scoped IPv6 address may have zone info, which must not be lowercased\n        # like http://[fe80::822a:a8ff:fe49:470c%tESt]:1234/keys\n        separator = '%' if isinstance(hostname, str) else b'%'\n        hostname, percent, zone = hostname.partition(separator)\n        return hostname.lower() + percent + zone\n\n    @property\n    def port(self):\n        port = self._hostinfo[1]\n        if port is not None:\n            port = int(port, 10)\n            if not ( 0 <= port <= 65535):\n                raise ValueError(\"Port out of range 0-65535\")\n        return port\n\n\nclass _NetlocResultMixinStr(_NetlocResultMixinBase, _ResultMixinStr):\n    __slots__ = ()\n\n    @property\n    def _userinfo(self):\n        netloc = self.netloc\n        userinfo, have_info, hostinfo = netloc.rpartition('@')\n        if have_info:\n            username, have_password, password = userinfo.partition(':')\n            if not have_password:\n                password = None\n        else:\n            username = password = None\n        return username, password\n\n    @property\n    def _hostinfo(self):\n        netloc = self.netloc\n        _, _, hostinfo = netloc.rpartition('@')\n        _, have_open_br, bracketed = hostinfo.partition('[')\n        if have_open_br:\n            hostname, _, port = bracketed.partition(']')\n            _, _, port = port.partition(':')\n        else:\n            hostname, _, port = hostinfo.partition(':')\n        if not port:\n            port = None\n        return hostname, port\n\n\nclass _NetlocResultMixinBytes(_NetlocResultMixinBase, _ResultMixinBytes):\n    __slots__ = ()\n\n    @property\n    def _userinfo(self):\n        netloc = self.netloc\n        userinfo, have_info, hostinfo = netloc.rpartition(b'@')\n        if have_info:\n            username, have_password, password = userinfo.partition(b':')\n            if not have_password:\n                password = None\n        else:\n            username = password = None\n        return username, password\n\n    @property\n    def _hostinfo(self):\n        netloc = self.netloc\n        _, _, hostinfo = netloc.rpartition(b'@')\n        _, have_open_br, bracketed = hostinfo.partition(b'[')\n        if have_open_br:\n            hostname, _, port = bracketed.partition(b']')\n            _, _, port = port.partition(b':')\n        else:\n            hostname, _, port = hostinfo.partition(b':')\n        if not port:\n            port = None\n        return hostname, port\n\n\nfrom collections import namedtuple\n\n_DefragResultBase = namedtuple('DefragResult', 'url fragment')\n_SplitResultBase = namedtuple(\n    'SplitResult', 'scheme netloc path query fragment')\n_ParseResultBase = namedtuple(\n    'ParseResult', 'scheme netloc path params query fragment')\n\n_DefragResultBase.__doc__ = \"\"\"\nDefragResult(url, fragment)\n\nA 2-tuple that contains the url without fragment identifier and the fragment\nidentifier as a separate argument.\n\"\"\"\n\n_DefragResultBase.url.__doc__ = \"\"\"The URL with no fragment identifier.\"\"\"\n\n_DefragResultBase.fragment.__doc__ = \"\"\"\nFragment identifier separated from URL, that allows indirect identification of a\nsecondary resource by reference to a primary resource and additional identifying\ninformation.\n\"\"\"\n\n_SplitResultBase.__doc__ = \"\"\"\nSplitResult(scheme, netloc, path, query, fragment)\n\nA 5-tuple that contains the different components of a URL. Similar to\nParseResult, but does not split params.\n\"\"\"\n\n_SplitResultBase.scheme.__doc__ = \"\"\"Specifies URL scheme for the request.\"\"\"\n\n_SplitResultBase.netloc.__doc__ = \"\"\"\nNetwork location where the request is made to.\n\"\"\"\n\n_SplitResultBase.path.__doc__ = \"\"\"\nThe hierarchical path, such as the path to a file to download.\n\"\"\"\n\n_SplitResultBase.query.__doc__ = \"\"\"\nThe query component, that contains non-hierarchical data, that along with data\nin path component, identifies a resource in the scope of URI's scheme and\nnetwork location.\n\"\"\"\n\n_SplitResultBase.fragment.__doc__ = \"\"\"\nFragment identifier, that allows indirect identification of a secondary resource\nby reference to a primary resource and additional identifying information.\n\"\"\"\n\n_ParseResultBase.__doc__ = \"\"\"\nParseResult(scheme, netloc, path, params,  query, fragment)\n\nA 6-tuple that contains components of a parsed URL.\n\"\"\"\n\n_ParseResultBase.scheme.__doc__ = _SplitResultBase.scheme.__doc__\n_ParseResultBase.netloc.__doc__ = _SplitResultBase.netloc.__doc__\n_ParseResultBase.path.__doc__ = _SplitResultBase.path.__doc__\n_ParseResultBase.params.__doc__ = \"\"\"\nParameters for last path element used to dereference the URI in order to provide\naccess to perform some operation on the resource.\n\"\"\"\n\n_ParseResultBase.query.__doc__ = _SplitResultBase.query.__doc__\n_ParseResultBase.fragment.__doc__ = _SplitResultBase.fragment.__doc__\n\n\n# For backwards compatibility, alias _NetlocResultMixinStr\n# ResultBase is no longer part of the documented API, but it is\n# retained since deprecating it isn't worth the hassle\nResultBase = _NetlocResultMixinStr\n\n# Structured result objects for string data\nclass DefragResult(_DefragResultBase, _ResultMixinStr):\n    __slots__ = ()\n    def geturl(self):\n        if self.fragment:\n            return self.url + '#' + self.fragment\n        else:\n            return self.url\n\nclass SplitResult(_SplitResultBase, _NetlocResultMixinStr):\n    __slots__ = ()\n    def geturl(self):\n        return urlunsplit(self)\n\nclass ParseResult(_ParseResultBase, _NetlocResultMixinStr):\n    __slots__ = ()\n    def geturl(self):\n        return urlunparse(self)\n\n# Structured result objects for bytes data\nclass DefragResultBytes(_DefragResultBase, _ResultMixinBytes):\n    __slots__ = ()\n    def geturl(self):\n        if self.fragment:\n            return self.url + b'#' + self.fragment\n        else:\n            return self.url\n\nclass SplitResultBytes(_SplitResultBase, _NetlocResultMixinBytes):\n    __slots__ = ()\n    def geturl(self):\n        return urlunsplit(self)\n\nclass ParseResultBytes(_ParseResultBase, _NetlocResultMixinBytes):\n    __slots__ = ()\n    def geturl(self):\n        return urlunparse(self)\n\n# Set up the encode/decode result pairs\ndef _fix_result_transcoding():\n    _result_pairs = (\n        (DefragResult, DefragResultBytes),\n        (SplitResult, SplitResultBytes),\n        (ParseResult, ParseResultBytes),\n    )\n    for _decoded, _encoded in _result_pairs:\n        _decoded._encoded_counterpart = _encoded\n        _encoded._decoded_counterpart = _decoded\n\n_fix_result_transcoding()\ndel _fix_result_transcoding\n\ndef urlparse(url, scheme='', allow_fragments=True):\n    \"\"\"Parse a URL into 6 components:\n    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\n    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    splitresult = urlsplit(url, scheme, allow_fragments)\n    scheme, netloc, url, query, fragment = splitresult\n    if scheme in uses_params and ';' in url:\n        url, params = _splitparams(url)\n    else:\n        params = ''\n    result = ParseResult(scheme, netloc, url, params, query, fragment)\n    return _coerce_result(result)\n\ndef _splitparams(url):\n    if '/'  in url:\n        i = url.find(';', url.rfind('/'))\n        if i < 0:\n            return url, ''\n    else:\n        i = url.find(';')\n    return url[:i], url[i+1:]\n\ndef _splitnetloc(url, start=0):\n    delim = len(url)   # position of end of domain part of url, default is end\n    for c in '/?#':    # look for delimiters; the order is NOT important\n        wdelim = url.find(c, start)        # find first of this delim\n        if wdelim >= 0:                    # if found\n            delim = min(delim, wdelim)     # use earliest delim position\n    return url[start:delim], url[delim:]   # return (domain, rest)\n\ndef _checknetloc(netloc):\n    if not netloc or netloc.isascii():\n        return\n    # looking for characters like \\u2100 that expand to 'a/c'\n    # IDNA uses NFKC equivalence, so normalize for this check\n    import unicodedata\n    n = netloc.replace('@', '')   # ignore characters already included\n    n = n.replace(':', '')        # but not the surrounding text\n    n = n.replace('#', '')\n    n = n.replace('?', '')\n    netloc2 = unicodedata.normalize('NFKC', n)\n    if n == netloc2:\n        return\n    for c in '/?#@:':\n        if c in netloc2:\n            raise ValueError(\"netloc '\" + netloc + \"' contains invalid \" +\n                             \"characters under NFKC normalization\")\n\ndef urlsplit(url, scheme='', allow_fragments=True):\n    \"\"\"Parse a URL into 5 components:\n    <scheme>://<netloc>/<path>?<query>#<fragment>\n    Return a 5-tuple: (scheme, netloc, path, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    allow_fragments = bool(allow_fragments)\n    key = url, scheme, allow_fragments, type(url), type(scheme)\n    cached = _parse_cache.get(key, None)\n    if cached:\n        return _coerce_result(cached)\n    if len(_parse_cache) >= MAX_CACHE_SIZE: # avoid runaway growth\n        clear_cache()\n    netloc = query = fragment = ''\n    i = url.find(':')\n    if i > 0:\n        if url[:i] == 'http': # optimize the common case\n            url = url[i+1:]\n            if url[:2] == '//':\n                netloc, url = _splitnetloc(url, 2)\n                if (('[' in netloc and ']' not in netloc) or\n                        (']' in netloc and '[' not in netloc)):\n                    raise ValueError(\"Invalid IPv6 URL\")\n            if allow_fragments and '#' in url:\n                url, fragment = url.split('#', 1)\n            if '?' in url:\n                url, query = url.split('?', 1)\n            _checknetloc(netloc)\n            v = SplitResult('http', netloc, url, query, fragment)\n            _parse_cache[key] = v\n            return _coerce_result(v)\n        for c in url[:i]:\n            if c not in scheme_chars:\n                break\n        else:\n            # make sure \"url\" is not actually a port number (in which case\n            # \"scheme\" is really part of the path)\n            rest = url[i+1:]\n            if not rest or any(c not in '0123456789' for c in rest):\n                # not a port number\n                scheme, url = url[:i].lower(), rest\n\n    if url[:2] == '//':\n        netloc, url = _splitnetloc(url, 2)\n        if (('[' in netloc and ']' not in netloc) or\n                (']' in netloc and '[' not in netloc)):\n            raise ValueError(\"Invalid IPv6 URL\")\n    if allow_fragments and '#' in url:\n        url, fragment = url.split('#', 1)\n    if '?' in url:\n        url, query = url.split('?', 1)\n    _checknetloc(netloc)\n    v = SplitResult(scheme, netloc, url, query, fragment)\n    _parse_cache[key] = v\n    return _coerce_result(v)\n\ndef urlunparse(components):\n    \"\"\"Put a parsed URL back together again.  This may result in a\n    slightly different, but equivalent URL, if the URL that was parsed\n    originally had redundant delimiters, e.g. a ? with an empty query\n    (the draft states that these are equivalent).\"\"\"\n    scheme, netloc, url, params, query, fragment, _coerce_result = (\n                                                  _coerce_args(*components))\n    if params:\n        url = \"%s;%s\" % (url, params)\n    return _coerce_result(urlunsplit((scheme, netloc, url, query, fragment)))\n\ndef urlunsplit(components):\n    \"\"\"Combine the elements of a tuple as returned by urlsplit() into a\n    complete URL as a string. The data argument can be any five-item iterable.\n    This may result in a slightly different, but equivalent URL, if the URL that\n    was parsed originally had unnecessary delimiters (for example, a ? with an\n    empty query; the RFC states that these are equivalent).\"\"\"\n    scheme, netloc, url, query, fragment, _coerce_result = (\n                                          _coerce_args(*components))\n    if netloc or (scheme and scheme in uses_netloc and url[:2] != '//'):\n        if url and url[:1] != '/': url = '/' + url\n        url = '//' + (netloc or '') + url\n    if scheme:\n        url = scheme + ':' + url\n    if query:\n        url = url + '?' + query\n    if fragment:\n        url = url + '#' + fragment\n    return _coerce_result(url)\n\ndef urljoin(base, url, allow_fragments=True):\n    \"\"\"Join a base URL and a possibly relative URL to form an absolute\n    interpretation of the latter.\"\"\"\n    if not base:\n        return url\n    if not url:\n        return base\n\n    base, url, _coerce_result = _coerce_args(base, url)\n    bscheme, bnetloc, bpath, bparams, bquery, bfragment = \\\n            urlparse(base, '', allow_fragments)\n    scheme, netloc, path, params, query, fragment = \\\n            urlparse(url, bscheme, allow_fragments)\n\n    if scheme != bscheme or scheme not in uses_relative:\n        return _coerce_result(url)\n    if scheme in uses_netloc:\n        if netloc:\n            return _coerce_result(urlunparse((scheme, netloc, path,\n                                              params, query, fragment)))\n        netloc = bnetloc\n\n    if not path and not params:\n        path = bpath\n        params = bparams\n        if not query:\n            query = bquery\n        return _coerce_result(urlunparse((scheme, netloc, path,\n                                          params, query, fragment)))\n\n    base_parts = bpath.split('/')\n    if base_parts[-1] != '':\n        # the last item is not a directory, so will not be taken into account\n        # in resolving the relative path\n        del base_parts[-1]\n\n    # for rfc3986, ignore all base path should the first character be root.\n    if path[:1] == '/':\n        segments = path.split('/')\n    else:\n        segments = base_parts + path.split('/')\n        # filter out elements that would cause redundant slashes on re-joining\n        # the resolved_path\n        segments[1:-1] = filter(None, segments[1:-1])\n\n    resolved_path = []\n\n    for seg in segments:\n        if seg == '..':\n            try:\n                resolved_path.pop()\n            except IndexError:\n                # ignore any .. segments that would otherwise cause an IndexError\n                # when popped from resolved_path if resolving for rfc3986\n                pass\n        elif seg == '.':\n            continue\n        else:\n            resolved_path.append(seg)\n\n    if segments[-1] in ('.', '..'):\n        # do some post-processing here. if the last segment was a relative dir,\n        # then we need to append the trailing '/'\n        resolved_path.append('')\n\n    return _coerce_result(urlunparse((scheme, netloc, '/'.join(\n        resolved_path) or '/', params, query, fragment)))\n\n\ndef urldefrag(url):\n    \"\"\"Removes any existing fragment from URL.\n\n    Returns a tuple of the defragmented URL and the fragment.  If\n    the URL contained no fragments, the second element is the\n    empty string.\n    \"\"\"\n    url, _coerce_result = _coerce_args(url)\n    if '#' in url:\n        s, n, p, a, q, frag = urlparse(url)\n        defrag = urlunparse((s, n, p, a, q, ''))\n    else:\n        frag = ''\n        defrag = url\n    return _coerce_result(DefragResult(defrag, frag))\n\n_hexdig = '0123456789ABCDEFabcdef'\n_hextobyte = None\n\ndef unquote_to_bytes(string):\n    \"\"\"unquote_to_bytes('abc%20def') -> b'abc def'.\"\"\"\n    # Note: strings are encoded as UTF-8. This is only an issue if it contains\n    # unescaped non-ASCII characters, which URIs should not.\n    if not string:\n        # Is it a string-like object?\n        string.split\n        return b''\n    if isinstance(string, str):\n        string = string.encode('utf-8')\n    bits = string.split(b'%')\n    if len(bits) == 1:\n        return string\n    res = [bits[0]]\n    append = res.append\n    # Delay the initialization of the table to not waste memory\n    # if the function is never called\n    global _hextobyte\n    if _hextobyte is None:\n        _hextobyte = {(a + b).encode(): bytes.fromhex(a + b)\n                      for a in _hexdig for b in _hexdig}\n    for item in bits[1:]:\n        try:\n            append(_hextobyte[item[:2]])\n            append(item[2:])\n        except KeyError:\n            append(b'%')\n            append(item)\n    return b''.join(res)\n\n_asciire = re.compile('([\\x00-\\x7f]+)')\n\ndef unquote(string, encoding='utf-8', errors='replace'):\n    \"\"\"Replace %xx escapes by their single-character equivalent. The optional\n    encoding and errors parameters specify how to decode percent-encoded\n    sequences into Unicode characters, as accepted by the bytes.decode()\n    method.\n    By default, percent-encoded sequences are decoded with UTF-8, and invalid\n    sequences are replaced by a placeholder character.\n\n    unquote('abc%20def') -> 'abc def'.\n    \"\"\"\n    if '%' not in string:\n        string.split\n        return string\n    if encoding is None:\n        encoding = 'utf-8'\n    if errors is None:\n        errors = 'replace'\n    bits = _asciire.split(string)\n    res = [bits[0]]\n    append = res.append\n    for i in range(1, len(bits), 2):\n        append(unquote_to_bytes(bits[i]).decode(encoding, errors))\n        append(bits[i + 1])\n    return ''.join(res)\n\n\ndef parse_qs(qs, keep_blank_values=False, strict_parsing=False,\n             encoding='utf-8', errors='replace', max_num_fields=None):\n    \"\"\"Parse a query given as a string argument.\n\n        Arguments:\n\n        qs: percent-encoded query string to be parsed\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded queries should be treated as blank strings.\n            A true value indicates that blanks should be retained as\n            blank strings.  The default false value indicates that\n            blank values are to be ignored and treated as if they were\n            not included.\n\n        strict_parsing: flag indicating what to do with parsing errors.\n            If false (the default), errors are silently ignored.\n            If true, errors raise a ValueError exception.\n\n        encoding and errors: specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the bytes.decode() method.\n\n        max_num_fields: int. If set, then throws a ValueError if there\n            are more than n fields read by parse_qsl().\n\n        Returns a dictionary.\n    \"\"\"\n    parsed_result = {}\n    pairs = parse_qsl(qs, keep_blank_values, strict_parsing,\n                      encoding=encoding, errors=errors,\n                      max_num_fields=max_num_fields)\n    for name, value in pairs:\n        if name in parsed_result:\n            parsed_result[name].append(value)\n        else:\n            parsed_result[name] = [value]\n    return parsed_result\n\n\ndef parse_qsl(qs, keep_blank_values=False, strict_parsing=False,\n              encoding='utf-8', errors='replace', max_num_fields=None):\n    \"\"\"Parse a query given as a string argument.\n\n        Arguments:\n\n        qs: percent-encoded query string to be parsed\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded queries should be treated as blank strings.\n            A true value indicates that blanks should be retained as blank\n            strings.  The default false value indicates that blank values\n            are to be ignored and treated as if they were  not included.\n\n        strict_parsing: flag indicating what to do with parsing errors. If\n            false (the default), errors are silently ignored. If true,\n            errors raise a ValueError exception.\n\n        encoding and errors: specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the bytes.decode() method.\n\n        max_num_fields: int. If set, then throws a ValueError\n            if there are more than n fields read by parse_qsl().\n\n        Returns a list, as G-d intended.\n    \"\"\"\n    qs, _coerce_result = _coerce_args(qs)\n\n    # If max_num_fields is defined then check that the number of fields\n    # is less than max_num_fields. This prevents a memory exhaustion DOS\n    # attack via post bodies with many fields.\n    if max_num_fields is not None:\n        num_fields = 1 + qs.count('&') + qs.count(';')\n        if max_num_fields < num_fields:\n            raise ValueError('Max number of fields exceeded')\n\n    pairs = [s2 for s1 in qs.split('&') for s2 in s1.split(';')]\n    r = []\n    for name_value in pairs:\n        if not name_value and not strict_parsing:\n            continue\n        nv = name_value.split('=', 1)\n        if len(nv) != 2:\n            if strict_parsing:\n                raise ValueError(\"bad query field: %r\" % (name_value,))\n            # Handle case of a control-name with no equal sign\n            if keep_blank_values:\n                nv.append('')\n            else:\n                continue\n        if len(nv[1]) or keep_blank_values:\n            name = nv[0].replace('+', ' ')\n            name = unquote(name, encoding=encoding, errors=errors)\n            name = _coerce_result(name)\n            value = nv[1].replace('+', ' ')\n            value = unquote(value, encoding=encoding, errors=errors)\n            value = _coerce_result(value)\n            r.append((name, value))\n    return r\n\ndef unquote_plus(string, encoding='utf-8', errors='replace'):\n    \"\"\"Like unquote(), but also replace plus signs by spaces, as required for\n    unquoting HTML form values.\n\n    unquote_plus('%7e/abc+def') -> '~/abc def'\n    \"\"\"\n    string = string.replace('+', ' ')\n    return unquote(string, encoding, errors)\n\n_ALWAYS_SAFE = frozenset(b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n                         b'abcdefghijklmnopqrstuvwxyz'\n                         b'0123456789'\n                         b'_.-~')\n_ALWAYS_SAFE_BYTES = bytes(_ALWAYS_SAFE)\n_safe_quoters = {}\n\nclass Quoter(collections.defaultdict):\n    \"\"\"A mapping from bytes (in range(0,256)) to strings.\n\n    String values are percent-encoded byte values, unless the key < 128, and\n    in the \"safe\" set (either the specified safe set, or default set).\n    \"\"\"\n    # Keeps a cache internally, using defaultdict, for efficiency (lookups\n    # of cached keys don't call Python code at all).\n    def __init__(self, safe):\n        \"\"\"safe: bytes object.\"\"\"\n        self.safe = _ALWAYS_SAFE.union(safe)\n\n    def __repr__(self):\n        # Without this, will just display as a defaultdict\n        return \"<%s %r>\" % (self.__class__.__name__, dict(self))\n\n    def __missing__(self, b):\n        # Handle a cache miss. Store quoted string in cache and return.\n        res = chr(b) if b in self.safe else '%{:02X}'.format(b)\n        self[b] = res\n        return res\n\ndef quote(string, safe='/', encoding=None, errors=None):\n    \"\"\"quote('abc def') -> 'abc%20def'\n\n    Each part of a URL, e.g. the path info, the query, etc., has a\n    different set of reserved characters that must be quoted. The\n    quote function offers a cautious (not minimal) way to quote a\n    string for most of these parts.\n\n    RFC 3986 Uniform Resource Identifier (URI): Generic Syntax lists\n    the following (un)reserved characters.\n\n    unreserved    = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n    reserved      = gen-delims / sub-delims\n    gen-delims    = \":\" / \"/\" / \"?\" / \"#\" / \"[\" / \"]\" / \"@\"\n    sub-delims    = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\"\n                  / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n\n    Each of the reserved characters is reserved in some component of a URL,\n    but not necessarily in all of them.\n\n    The quote function %-escapes all characters that are neither in the\n    unreserved chars (\"always safe\") nor the additional chars set via the\n    safe arg.\n\n    The default for the safe arg is '/'. The character is reserved, but in\n    typical usage the quote function is being called on a path where the\n    existing slash characters are to be preserved.\n\n    Python 3.7 updates from using RFC 2396 to RFC 3986 to quote URL strings.\n    Now, \"~\" is included in the set of unreserved characters.\n\n    string and safe may be either str or bytes objects. encoding and errors\n    must not be specified if string is a bytes object.\n\n    The optional encoding and errors parameters specify how to deal with\n    non-ASCII characters, as accepted by the str.encode method.\n    By default, encoding='utf-8' (characters are encoded with UTF-8), and\n    errors='strict' (unsupported characters raise a UnicodeEncodeError).\n    \"\"\"\n    if isinstance(string, str):\n        if not string:\n            return string\n        if encoding is None:\n            encoding = 'utf-8'\n        if errors is None:\n            errors = 'strict'\n        string = string.encode(encoding, errors)\n    else:\n        if encoding is not None:\n            raise TypeError(\"quote() doesn't support 'encoding' for bytes\")\n        if errors is not None:\n            raise TypeError(\"quote() doesn't support 'errors' for bytes\")\n    return quote_from_bytes(string, safe)\n\ndef quote_plus(string, safe='', encoding=None, errors=None):\n    \"\"\"Like quote(), but also replace ' ' with '+', as required for quoting\n    HTML form values. Plus signs in the original string are escaped unless\n    they are included in safe. It also does not have safe default to '/'.\n    \"\"\"\n    # Check if ' ' in string, where string may either be a str or bytes.  If\n    # there are no spaces, the regular quote will produce the right answer.\n    if ((isinstance(string, str) and ' ' not in string) or\n        (isinstance(string, bytes) and b' ' not in string)):\n        return quote(string, safe, encoding, errors)\n    if isinstance(safe, str):\n        space = ' '\n    else:\n        space = b' '\n    string = quote(string, safe + space, encoding, errors)\n    return string.replace(' ', '+')\n\ndef quote_from_bytes(bs, safe='/'):\n    \"\"\"Like quote(), but accepts a bytes object rather than a str, and does\n    not perform string-to-bytes encoding.  It always returns an ASCII string.\n    quote_from_bytes(b'abc def\\x3f') -> 'abc%20def%3f'\n    \"\"\"\n    if not isinstance(bs, (bytes, bytearray)):\n        raise TypeError(\"quote_from_bytes() expected bytes\")\n    if not bs:\n        return ''\n    if isinstance(safe, str):\n        # Normalize 'safe' by converting to bytes and removing non-ASCII chars\n        safe = safe.encode('ascii', 'ignore')\n    else:\n        safe = bytes([c for c in safe if c < 128])\n    if not bs.rstrip(_ALWAYS_SAFE_BYTES + safe):\n        return bs.decode()\n    try:\n        quoter = _safe_quoters[safe]\n    except KeyError:\n        _safe_quoters[safe] = quoter = Quoter(safe).__getitem__\n    return ''.join([quoter(char) for char in bs])\n\ndef urlencode(query, doseq=False, safe='', encoding=None, errors=None,\n              quote_via=quote_plus):\n    \"\"\"Encode a dict or sequence of two-element tuples into a URL query string.\n\n    If any values in the query arg are sequences and doseq is true, each\n    sequence element is converted to a separate parameter.\n\n    If the query arg is a sequence of two-element tuples, the order of the\n    parameters in the output will match the order of parameters in the\n    input.\n\n    The components of a query arg may each be either a string or a bytes type.\n\n    The safe, encoding, and errors parameters are passed down to the function\n    specified by quote_via (encoding and errors only if a component is a str).\n    \"\"\"\n\n    if hasattr(query, \"items\"):\n        query = query.items()\n    else:\n        # It's a bother at times that strings and string-like objects are\n        # sequences.\n        try:\n            # non-sequence items should not work with len()\n            # non-empty strings will fail this\n            if len(query) and not isinstance(query[0], tuple):\n                raise TypeError\n            # Zero-length sequences of all types will get here and succeed,\n            # but that's a minor nit.  Since the original implementation\n            # allowed empty dicts that type of behavior probably should be\n            # preserved for consistency\n        except TypeError:\n            ty, va, tb = sys.exc_info()\n            raise TypeError(\"not a valid non-string sequence \"\n                            \"or mapping object\").with_traceback(tb)\n\n    l = []\n    if not doseq:\n        for k, v in query:\n            if isinstance(k, bytes):\n                k = quote_via(k, safe)\n            else:\n                k = quote_via(str(k), safe, encoding, errors)\n\n            if isinstance(v, bytes):\n                v = quote_via(v, safe)\n            else:\n                v = quote_via(str(v), safe, encoding, errors)\n            l.append(k + '=' + v)\n    else:\n        for k, v in query:\n            if isinstance(k, bytes):\n                k = quote_via(k, safe)\n            else:\n                k = quote_via(str(k), safe, encoding, errors)\n\n            if isinstance(v, bytes):\n                v = quote_via(v, safe)\n                l.append(k + '=' + v)\n            elif isinstance(v, str):\n                v = quote_via(v, safe, encoding, errors)\n                l.append(k + '=' + v)\n            else:\n                try:\n                    # Is this a sufficient test for sequence-ness?\n                    x = len(v)\n                except TypeError:\n                    # not a sequence\n                    v = quote_via(str(v), safe, encoding, errors)\n                    l.append(k + '=' + v)\n                else:\n                    # loop over the sequence\n                    for elt in v:\n                        if isinstance(elt, bytes):\n                            elt = quote_via(elt, safe)\n                        else:\n                            elt = quote_via(str(elt), safe, encoding, errors)\n                        l.append(k + '=' + elt)\n    return '&'.join(l)\n\ndef to_bytes(url):\n    \"\"\"to_bytes(u\"URL\") --> 'URL'.\"\"\"\n    # Most URL schemes require ASCII. If that changes, the conversion\n    # can be relaxed.\n    # XXX get rid of to_bytes()\n    if isinstance(url, str):\n        try:\n            url = url.encode(\"ASCII\").decode()\n        except UnicodeError:\n            raise UnicodeError(\"URL \" + repr(url) +\n                               \" contains non-ASCII characters\")\n    return url\n\ndef unwrap(url):\n    \"\"\"unwrap('<URL:type://host/path>') --> 'type://host/path'.\"\"\"\n    url = str(url).strip()\n    if url[:1] == '<' and url[-1:] == '>':\n        url = url[1:-1].strip()\n    if url[:4] == 'URL:': url = url[4:].strip()\n    return url\n\n_typeprog = None\ndef splittype(url):\n    \"\"\"splittype('type:opaquestring') --> 'type', 'opaquestring'.\"\"\"\n    global _typeprog\n    if _typeprog is None:\n        _typeprog = re.compile('([^/:]+):(.*)', re.DOTALL)\n\n    match = _typeprog.match(url)\n    if match:\n        scheme, data = match.groups()\n        return scheme.lower(), data\n    return None, url\n\n_hostprog = None\ndef splithost(url):\n    \"\"\"splithost('//host[:port]/path') --> 'host[:port]', '/path'.\"\"\"\n    global _hostprog\n    if _hostprog is None:\n        _hostprog = re.compile('//([^/#?]*)(.*)', re.DOTALL)\n\n    match = _hostprog.match(url)\n    if match:\n        host_port, path = match.groups()\n        if path and path[0] != '/':\n            path = '/' + path\n        return host_port, path\n    return None, url\n\ndef splituser(host):\n    \"\"\"splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'.\"\"\"\n    user, delim, host = host.rpartition('@')\n    return (user if delim else None), host\n\ndef splitpasswd(user):\n    \"\"\"splitpasswd('user:passwd') -> 'user', 'passwd'.\"\"\"\n    user, delim, passwd = user.partition(':')\n    return user, (passwd if delim else None)\n\n# splittag('/path#tag') --> '/path', 'tag'\n_portprog = None\ndef splitport(host):\n    \"\"\"splitport('host:port') --> 'host', 'port'.\"\"\"\n    global _portprog\n    if _portprog is None:\n        _portprog = re.compile('(.*):([0-9]*)$', re.DOTALL)\n\n    match = _portprog.match(host)\n    if match:\n        host, port = match.groups()\n        if port:\n            return host, port\n    return host, None\n\ndef splitnport(host, defport=-1):\n    \"\"\"Split host and port, returning numeric port.\n    Return given default port if no ':' found; defaults to -1.\n    Return numerical port if a valid number are found after ':'.\n    Return None if ':' but not a valid number.\"\"\"\n    host, delim, port = host.rpartition(':')\n    if not delim:\n        host = port\n    elif port:\n        try:\n            nport = int(port)\n        except ValueError:\n            nport = None\n        return host, nport\n    return host, defport\n\ndef splitquery(url):\n    \"\"\"splitquery('/path?query') --> '/path', 'query'.\"\"\"\n    path, delim, query = url.rpartition('?')\n    if delim:\n        return path, query\n    return url, None\n\ndef splittag(url):\n    \"\"\"splittag('/path#tag') --> '/path', 'tag'.\"\"\"\n    path, delim, tag = url.rpartition('#')\n    if delim:\n        return path, tag\n    return url, None\n\ndef splitattr(url):\n    \"\"\"splitattr('/path;attr1=value1;attr2=value2;...') ->\n        '/path', ['attr1=value1', 'attr2=value2', ...].\"\"\"\n    words = url.split(';')\n    return words[0], words[1:]\n\ndef splitvalue(attr):\n    \"\"\"splitvalue('attr=value') --> 'attr', 'value'.\"\"\"\n    attr, delim, value = attr.partition('=')\n    return attr, (value if delim else None)\n"], "filenames": ["Lib/test/test_urlparse.py", "Lib/urllib/parse.py"], "buggy_code_start_loc": [1011, 400], "buggy_code_end_loc": [1016, 403], "fixing_code_start_loc": [1011, 400], "fixing_code_end_loc": [1017, 403], "type": "CWE-172", "message": "A security regression of CVE-2019-9636 was discovered in python since commit d537ab0ff9767ef024f26246899728f0116b1ec3 affecting versions 2.7, 3.5, 3.6, 3.7 and from v3.8.0a4 through v3.8.0b1, which still allows an attacker to exploit CVE-2019-9636 by abusing the user and password parts of a URL. When an application parses user-supplied URLs to store cookies, authentication credentials, or other kind of information, it is possible for an attacker to provide specially crafted URLs to make the application locate host-related information (e.g. cookies, authentication data) and send them to a different host than where it should, unlike if the URLs had been correctly parsed. The result of an attack may vary based on the application.", "other": {"cve": {"id": "CVE-2019-10160", "sourceIdentifier": "secalert@redhat.com", "published": "2019-06-07T18:29:00.280", "lastModified": "2023-02-12T23:33:11.297", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "A security regression of CVE-2019-9636 was discovered in python since commit d537ab0ff9767ef024f26246899728f0116b1ec3 affecting versions 2.7, 3.5, 3.6, 3.7 and from v3.8.0a4 through v3.8.0b1, which still allows an attacker to exploit CVE-2019-9636 by abusing the user and password parts of a URL. When an application parses user-supplied URLs to store cookies, authentication credentials, or other kind of information, it is possible for an attacker to provide specially crafted URLs to make the application locate host-related information (e.g. cookies, authentication data) and send them to a different host than where it should, unlike if the URLs had been correctly parsed. The result of an attack may vary based on the application."}, {"lang": "es", "value": "Se descubri\u00f3 una regresi\u00f3n de seguridad de CVE-2019-9636 en python desde commit con ID d537ab0ff9767ef024f26246899728f0116b1ec3 que afecta a las versiones 2.7, 3.5, 3.6, 3.7 y de v3.8.0a4 a v3.8.0b1, el cual permite a un atacante explotar CVE-2019-9636 violando las partes usuario (user) y contrase\u00f1a (password) de una URL. Cuando una aplicaci\u00f3n analiza las URL proporcionadas por el usuario para almacenar cookies, credenciales de autenticaci\u00f3n u otro tipo de informaci\u00f3n, es posible que un atacante proporcione URL especialmente creadas para que la aplicaci\u00f3n ubique informaci\u00f3n relacionada con el host (por ejemplo, cookies, datos de autenticaci\u00f3n) y env\u00ede a un host diferente al que deber\u00eda, a diferencia de si las URL se analizaron correctamente. El resultado de un ataque puede variar seg\u00fan la aplicaci\u00f3n."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV30": [{"source": "secalert@redhat.com", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "secalert@redhat.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-172"}]}, {"source": "nvd@nist.gov", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-522"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:python:python:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.7.0", "versionEndExcluding": "2.7.17", "matchCriteriaId": "B09B31A2-30BF-4E95-81A3-F77FD97DF5B6"}, {"vulnerable": true, "criteria": "cpe:2.3:a:python:python:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.5.0", "versionEndExcluding": "3.5.8", "matchCriteriaId": "9A384586-B574-4240-8BCF-CCE69498F336"}, {"vulnerable": true, "criteria": "cpe:2.3:a:python:python:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.6.0", "versionEndExcluding": "3.6.9", "matchCriteriaId": "2C052B2D-757B-4342-8BE9-510A08599779"}, {"vulnerable": true, "criteria": "cpe:2.3:a:python:python:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.7.0", "versionEndExcluding": "3.7.4", "matchCriteriaId": "A8E7B12E-74D0-4E51-A0A6-6C1A8B277055"}, {"vulnerable": true, "criteria": "cpe:2.3:a:python:python:3.8.0:alpha4:*:*:*:*:*:*", "matchCriteriaId": "BD6CA58B-2D25-4019-95F2-AA6DF516AD36"}, {"vulnerable": true, "criteria": "cpe:2.3:a:python:python:3.8.0:beta1:*:*:*:*:*:*", "matchCriteriaId": "BF6397BF-ED2C-4397-A8FF-23C92CAFFC1E"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_desktop:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "33C068A4-3780-4EAB-A937-6082DF847564"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_eus:7.6:*:*:*:*:*:*:*", "matchCriteriaId": "5BF3C7A5-9117-42C7-BEA1-4AA378A582EF"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_server:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "51EF4996-72F4-4FA4-814F-F5991E7A8318"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_server_aus:7.6:*:*:*:*:*:*:*", "matchCriteriaId": "B353CE99-D57C-465B-AAB0-73EF581127D1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_server_tus:7.6:*:*:*:*:*:*:*", "matchCriteriaId": "B76AA310-FEC7-497F-AF04-C3EC1E76C4CC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_workstation:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "825ECE2D-E232-46E0-A047-074B34DB1E97"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:15.0:*:*:*:*:*:*:*", "matchCriteriaId": "F1E78106-58E6-4D59-990F-75DA575BFAD9"}, {"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:15.1:*:*:*:*:*:*:*", "matchCriteriaId": "B620311B-34A3-48A6-82DF-6F078D7A4493"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:29:*:*:*:*:*:*:*", "matchCriteriaId": "D100F7CE-FC64-4CC6-852A-6136D72DA419"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:30:*:*:*:*:*:*:*", "matchCriteriaId": "97A4B8DF-58DA-4AB6-A1F9-331B36409BA3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:31:*:*:*:*:*:*:*", "matchCriteriaId": "80F0FA5D-8D3B-4C0E-81E2-87998286AF33"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:12.04:*:*:*:-:*:*:*", "matchCriteriaId": "CB66DB75-2B16-4EBF-9B93-CE49D8086E41"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:14.04:*:*:*:esm:*:*:*", "matchCriteriaId": "815D70A8-47D3-459C-A32C-9FEACA0659D1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:16.04:*:*:*:esm:*:*:*", "matchCriteriaId": "7A5301BF-1402-4BE0-A0F8-69FBE79BC6D6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:18.04:*:*:*:lts:*:*:*", "matchCriteriaId": "23A7C53F-B80F-4E6A-AFA9-58EEA84BE11D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:19.04:*:*:*:*:*:*:*", "matchCriteriaId": "CD783B0C-9246-47D9-A937-6144FE8BFF0F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:redhat:virtualization:4.0:*:*:*:*:*:*:*", "matchCriteriaId": "6BBD7A51-0590-4DDF-8249-5AFA8D645CB6"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:o:redhat:enterprise_linux:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "142AD0DD-4CF3-4D74-9442-459CE3347E3A"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:netapp:cloud_backup:-:*:*:*:*:*:*:*", "matchCriteriaId": "5C2089EE-5D7F-47EC-8EA5-0F69790564C4"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:converged_systems_advisor_agent:-:*:*:*:*:*:*:*", "matchCriteriaId": "9A865472-D6A4-49D9-96E5-D33D0E58144D"}]}]}], "references": [{"url": "http://lists.opensuse.org/opensuse-security-announce/2019-08/msg00042.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2020-01/msg00040.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2019:1587", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2019:1700", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2019:2437", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=CVE-2019-10160", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/python/cpython/commit/250b62acc59921d399f0db47db3b462cd6037e09", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/python/cpython/commit/8d0ef0b5edeae52960c7ed05ae8a12388324f87e", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/python/cpython/commit/f61599b050c621386a3fc6bc480359e2d3bb93de", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/python/cpython/commit/fd1771dbdd28709716bd531580c40ae5ed814468", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.apache.org/thread.html/r1b103833cb5bc8466e24ff0ecc5e75b45a705334ab6a444e64e840a0%40%3Cissues.bookkeeper.apache.org%3E", "source": "secalert@redhat.com"}, {"url": "https://lists.debian.org/debian-lts-announce/2019/06/msg00022.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2020/07/msg00011.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2020/08/msg00034.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/2ORNTF62QPLMJXIQ7KTZQ2776LMIXEKL/", "source": "secalert@redhat.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/44TS66GJMO5H3RLMVZEBGEFTB6O2LJJU/", "source": "secalert@redhat.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/4X3HW5JRZ7GCPSR7UHJOLD7AWLTQCDVR/", "source": "secalert@redhat.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/E2HP37NUVLQSBW3J735A2DQDOZ4ZGBLY/", "source": "secalert@redhat.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/ER6LONC2B2WYIO56GBQUDU6QTWZDPUNQ/", "source": "secalert@redhat.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/HQEQLXLOCR3SNM3AA5RRYJFQ5AZBYJ4L/", "source": "secalert@redhat.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/JCPGLTTOBB3QEARDX4JOYURP6ELNNA2V/", "source": "secalert@redhat.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/KRYFIMISZ47NTAU3XWZUOFB7CYL62KES/", "source": "secalert@redhat.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/M34WOYCDKTDE5KLUACE2YIEH7D37KHRX/", "source": "secalert@redhat.com"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/NF3DRDGMVIRYNZMSLJIHNW47HOUQYXVG/", "source": "secalert@redhat.com"}, {"url": "https://python-security.readthedocs.io/vuln/urlsplit-nfkc-normalization2.html", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20190617-0003/", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4127-1/", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4127-2/", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/python/cpython/commit/250b62acc59921d399f0db47db3b462cd6037e09"}}
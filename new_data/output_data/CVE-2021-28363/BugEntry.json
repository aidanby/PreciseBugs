{"buggy_code": ["from __future__ import absolute_import\n\nimport datetime\nimport logging\nimport os\nimport re\nimport socket\nimport warnings\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\n\nfrom .packages import six\nfrom .packages.six.moves.http_client import HTTPConnection as _HTTPConnection\nfrom .packages.six.moves.http_client import HTTPException  # noqa: F401\nfrom .util.proxy import create_proxy_ssl_context\n\ntry:  # Compiled with SSL?\n    import ssl\n\n    BaseSSLError = ssl.SSLError\nexcept (ImportError, AttributeError):  # Platform-specific: No SSL.\n    ssl = None\n\n    class BaseSSLError(BaseException):\n        pass\n\n\ntry:\n    # Python 3: not a no-op, we're adding this to the namespace so it can be imported.\n    ConnectionError = ConnectionError\nexcept NameError:\n    # Python 2\n    class ConnectionError(Exception):\n        pass\n\n\ntry:  # Python 3:\n    # Not a no-op, we're adding this to the namespace so it can be imported.\n    BrokenPipeError = BrokenPipeError\nexcept NameError:  # Python 2:\n\n    class BrokenPipeError(Exception):\n        pass\n\n\nfrom ._collections import HTTPHeaderDict  # noqa (historical, removed in v2)\nfrom ._version import __version__\nfrom .exceptions import (\n    ConnectTimeoutError,\n    NewConnectionError,\n    SubjectAltNameWarning,\n    SystemTimeWarning,\n)\nfrom .packages.ssl_match_hostname import CertificateError, match_hostname\nfrom .util import SKIP_HEADER, SKIPPABLE_HEADERS, connection\nfrom .util.ssl_ import (\n    assert_fingerprint,\n    create_urllib3_context,\n    resolve_cert_reqs,\n    resolve_ssl_version,\n    ssl_wrap_socket,\n)\n\nlog = logging.getLogger(__name__)\n\nport_by_scheme = {\"http\": 80, \"https\": 443}\n\n# When it comes time to update this value as a part of regular maintenance\n# (ie test_recent_date is failing) update it to ~6 months before the current date.\nRECENT_DATE = datetime.date(2020, 7, 1)\n\n_CONTAINS_CONTROL_CHAR_RE = re.compile(r\"[^-!#$%&'*+.^_`|~0-9a-zA-Z]\")\n\n\nclass HTTPConnection(_HTTPConnection, object):\n    \"\"\"\n    Based on :class:`http.client.HTTPConnection` but provides an extra constructor\n    backwards-compatibility layer between older and newer Pythons.\n\n    Additional keyword parameters are used to configure attributes of the connection.\n    Accepted parameters include:\n\n    - ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`\n    - ``source_address``: Set the source address for the current connection.\n    - ``socket_options``: Set specific options on the underlying socket. If not specified, then\n      defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling\n      Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.\n\n      For example, if you wish to enable TCP Keep Alive in addition to the defaults,\n      you might pass:\n\n      .. code-block:: python\n\n         HTTPConnection.default_socket_options + [\n             (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),\n         ]\n\n      Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).\n    \"\"\"\n\n    default_port = port_by_scheme[\"http\"]\n\n    #: Disable Nagle's algorithm by default.\n    #: ``[(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]``\n    default_socket_options = [(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]\n\n    #: Whether this connection verifies the host's certificate.\n    is_verified = False\n\n    def __init__(self, *args, **kw):\n        if not six.PY2:\n            kw.pop(\"strict\", None)\n\n        # Pre-set source_address.\n        self.source_address = kw.get(\"source_address\")\n\n        #: The socket options provided by the user. If no options are\n        #: provided, we use the default options.\n        self.socket_options = kw.pop(\"socket_options\", self.default_socket_options)\n\n        # Proxy options provided by the user.\n        self.proxy = kw.pop(\"proxy\", None)\n        self.proxy_config = kw.pop(\"proxy_config\", None)\n\n        _HTTPConnection.__init__(self, *args, **kw)\n\n    @property\n    def host(self):\n        \"\"\"\n        Getter method to remove any trailing dots that indicate the hostname is an FQDN.\n\n        In general, SSL certificates don't include the trailing dot indicating a\n        fully-qualified domain name, and thus, they don't validate properly when\n        checked against a domain name that includes the dot. In addition, some\n        servers may not expect to receive the trailing dot when provided.\n\n        However, the hostname with trailing dot is critical to DNS resolution; doing a\n        lookup with the trailing dot will properly only resolve the appropriate FQDN,\n        whereas a lookup without a trailing dot will search the system's search domain\n        list. Thus, it's important to keep the original host around for use only in\n        those cases where it's appropriate (i.e., when doing DNS lookup to establish the\n        actual TCP connection across which we're going to send HTTP requests).\n        \"\"\"\n        return self._dns_host.rstrip(\".\")\n\n    @host.setter\n    def host(self, value):\n        \"\"\"\n        Setter for the `host` property.\n\n        We assume that only urllib3 uses the _dns_host attribute; httplib itself\n        only uses `host`, and it seems reasonable that other libraries follow suit.\n        \"\"\"\n        self._dns_host = value\n\n    def _new_conn(self):\n        \"\"\"Establish a socket connection and set nodelay settings on it.\n\n        :return: New socket connection.\n        \"\"\"\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\"source_address\"] = self.source_address\n\n        if self.socket_options:\n            extra_kw[\"socket_options\"] = self.socket_options\n\n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \"Connection to %s timed out. (connect timeout=%s)\"\n                % (self.host, self.timeout),\n            )\n\n        except SocketError as e:\n            raise NewConnectionError(\n                self, \"Failed to establish a new connection: %s\" % e\n            )\n\n        return conn\n\n    def _is_using_tunnel(self):\n        # Google App Engine's httplib does not define _tunnel_host\n        return getattr(self, \"_tunnel_host\", None)\n\n    def _prepare_conn(self, conn):\n        self.sock = conn\n        if self._is_using_tunnel():\n            # TODO: Fix tunnel so it doesn't depend on self.sock state.\n            self._tunnel()\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n    def connect(self):\n        conn = self._new_conn()\n        self._prepare_conn(conn)\n\n    def putrequest(self, method, url, *args, **kwargs):\n        \"\"\"\"\"\"\n        # Empty docstring because the indentation of CPython's implementation\n        # is broken but we don't want this method in our documentation.\n        match = _CONTAINS_CONTROL_CHAR_RE.search(method)\n        if match:\n            raise ValueError(\n                \"Method cannot contain non-token characters %r (found at least %r)\"\n                % (method, match.group())\n            )\n\n        return _HTTPConnection.putrequest(self, method, url, *args, **kwargs)\n\n    def putheader(self, header, *values):\n        \"\"\"\"\"\"\n        if not any(isinstance(v, str) and v == SKIP_HEADER for v in values):\n            _HTTPConnection.putheader(self, header, *values)\n        elif six.ensure_str(header.lower()) not in SKIPPABLE_HEADERS:\n            raise ValueError(\n                \"urllib3.util.SKIP_HEADER only supports '%s'\"\n                % (\"', '\".join(map(str.title, sorted(SKIPPABLE_HEADERS))),)\n            )\n\n    def request(self, method, url, body=None, headers=None):\n        if headers is None:\n            headers = {}\n        else:\n            # Avoid modifying the headers passed into .request()\n            headers = headers.copy()\n        if \"user-agent\" not in (six.ensure_str(k.lower()) for k in headers):\n            headers[\"User-Agent\"] = _get_default_user_agent()\n        super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n\n    def request_chunked(self, method, url, body=None, headers=None):\n        \"\"\"\n        Alternative to the common request method, which sends the\n        body with chunked encoding and not as one block\n        \"\"\"\n        headers = headers or {}\n        header_keys = set([six.ensure_str(k.lower()) for k in headers])\n        skip_accept_encoding = \"accept-encoding\" in header_keys\n        skip_host = \"host\" in header_keys\n        self.putrequest(\n            method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host\n        )\n        if \"user-agent\" not in header_keys:\n            self.putheader(\"User-Agent\", _get_default_user_agent())\n        for header, value in headers.items():\n            self.putheader(header, value)\n        if \"transfer-encoding\" not in headers:\n            self.putheader(\"Transfer-Encoding\", \"chunked\")\n        self.endheaders()\n\n        if body is not None:\n            stringish_types = six.string_types + (bytes,)\n            if isinstance(body, stringish_types):\n                body = (body,)\n            for chunk in body:\n                if not chunk:\n                    continue\n                if not isinstance(chunk, bytes):\n                    chunk = chunk.encode(\"utf8\")\n                len_str = hex(len(chunk))[2:]\n                to_send = bytearray(len_str.encode())\n                to_send += b\"\\r\\n\"\n                to_send += chunk\n                to_send += b\"\\r\\n\"\n                self.send(to_send)\n\n        # After the if clause, to always have a closed body\n        self.send(b\"0\\r\\n\\r\\n\")\n\n\nclass HTTPSConnection(HTTPConnection):\n    \"\"\"\n    Many of the parameters to this constructor are passed to the underlying SSL\n    socket by means of :py:func:`urllib3.util.ssl_wrap_socket`.\n    \"\"\"\n\n    default_port = port_by_scheme[\"https\"]\n\n    cert_reqs = None\n    ca_certs = None\n    ca_cert_dir = None\n    ca_cert_data = None\n    ssl_version = None\n    assert_fingerprint = None\n    tls_in_tls_required = False\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        key_file=None,\n        cert_file=None,\n        key_password=None,\n        strict=None,\n        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n        ssl_context=None,\n        server_hostname=None,\n        **kw\n    ):\n\n        HTTPConnection.__init__(self, host, port, strict=strict, timeout=timeout, **kw)\n\n        self.key_file = key_file\n        self.cert_file = cert_file\n        self.key_password = key_password\n        self.ssl_context = ssl_context\n        self.server_hostname = server_hostname\n\n        # Required property for Google AppEngine 1.9.0 which otherwise causes\n        # HTTPS requests to go out as HTTP. (See Issue #356)\n        self._protocol = \"https\"\n\n    def set_cert(\n        self,\n        key_file=None,\n        cert_file=None,\n        cert_reqs=None,\n        key_password=None,\n        ca_certs=None,\n        assert_hostname=None,\n        assert_fingerprint=None,\n        ca_cert_dir=None,\n        ca_cert_data=None,\n    ):\n        \"\"\"\n        This method should only be called once, before the connection is used.\n        \"\"\"\n        # If cert_reqs is not provided we'll assume CERT_REQUIRED unless we also\n        # have an SSLContext object in which case we'll use its verify_mode.\n        if cert_reqs is None:\n            if self.ssl_context is not None:\n                cert_reqs = self.ssl_context.verify_mode\n            else:\n                cert_reqs = resolve_cert_reqs(None)\n\n        self.key_file = key_file\n        self.cert_file = cert_file\n        self.cert_reqs = cert_reqs\n        self.key_password = key_password\n        self.assert_hostname = assert_hostname\n        self.assert_fingerprint = assert_fingerprint\n        self.ca_certs = ca_certs and os.path.expanduser(ca_certs)\n        self.ca_cert_dir = ca_cert_dir and os.path.expanduser(ca_cert_dir)\n        self.ca_cert_data = ca_cert_data\n\n    def connect(self):\n        # Add certificate verification\n        conn = self._new_conn()\n        hostname = self.host\n        tls_in_tls = False\n\n        if self._is_using_tunnel():\n            if self.tls_in_tls_required:\n                conn = self._connect_tls_proxy(hostname, conn)\n                tls_in_tls = True\n\n            self.sock = conn\n\n            # Calls self._set_hostport(), so self.host is\n            # self._tunnel_host below.\n            self._tunnel()\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n            # Override the host with the one we're requesting data from.\n            hostname = self._tunnel_host\n\n        server_hostname = hostname\n        if self.server_hostname is not None:\n            server_hostname = self.server_hostname\n\n        is_time_off = datetime.date.today() < RECENT_DATE\n        if is_time_off:\n            warnings.warn(\n                (\n                    \"System time is way off (before {0}). This will probably \"\n                    \"lead to SSL verification errors\"\n                ).format(RECENT_DATE),\n                SystemTimeWarning,\n            )\n\n        # Wrap socket using verification with the root certs in\n        # trusted_root_certs\n        default_ssl_context = False\n        if self.ssl_context is None:\n            default_ssl_context = True\n            self.ssl_context = create_urllib3_context(\n                ssl_version=resolve_ssl_version(self.ssl_version),\n                cert_reqs=resolve_cert_reqs(self.cert_reqs),\n            )\n\n        context = self.ssl_context\n        context.verify_mode = resolve_cert_reqs(self.cert_reqs)\n\n        # Try to load OS default certs if none are given.\n        # Works well on Windows (requires Python3.4+)\n        if (\n            not self.ca_certs\n            and not self.ca_cert_dir\n            and not self.ca_cert_data\n            and default_ssl_context\n            and hasattr(context, \"load_default_certs\")\n        ):\n            context.load_default_certs()\n\n        self.sock = ssl_wrap_socket(\n            sock=conn,\n            keyfile=self.key_file,\n            certfile=self.cert_file,\n            key_password=self.key_password,\n            ca_certs=self.ca_certs,\n            ca_cert_dir=self.ca_cert_dir,\n            ca_cert_data=self.ca_cert_data,\n            server_hostname=server_hostname,\n            ssl_context=context,\n            tls_in_tls=tls_in_tls,\n        )\n\n        # If we're using all defaults and the connection\n        # is TLSv1 or TLSv1.1 we throw a DeprecationWarning\n        # for the host.\n        if (\n            default_ssl_context\n            and self.ssl_version is None\n            and hasattr(self.sock, \"version\")\n            and self.sock.version() in {\"TLSv1\", \"TLSv1.1\"}\n        ):\n            warnings.warn(\n                \"Negotiating TLSv1/TLSv1.1 by default is deprecated \"\n                \"and will be disabled in urllib3 v2.0.0. Connecting to \"\n                \"'%s' with '%s' can be enabled by explicitly opting-in \"\n                \"with 'ssl_version'\" % (self.host, self.sock.version()),\n                DeprecationWarning,\n            )\n\n        if self.assert_fingerprint:\n            assert_fingerprint(\n                self.sock.getpeercert(binary_form=True), self.assert_fingerprint\n            )\n        elif (\n            context.verify_mode != ssl.CERT_NONE\n            and not getattr(context, \"check_hostname\", False)\n            and self.assert_hostname is not False\n        ):\n            # While urllib3 attempts to always turn off hostname matching from\n            # the TLS library, this cannot always be done. So we check whether\n            # the TLS Library still thinks it's matching hostnames.\n            cert = self.sock.getpeercert()\n            if not cert.get(\"subjectAltName\", ()):\n                warnings.warn(\n                    (\n                        \"Certificate for {0} has no `subjectAltName`, falling back to check for a \"\n                        \"`commonName` for now. This feature is being removed by major browsers and \"\n                        \"deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 \"\n                        \"for details.)\".format(hostname)\n                    ),\n                    SubjectAltNameWarning,\n                )\n            _match_hostname(cert, self.assert_hostname or server_hostname)\n\n        self.is_verified = (\n            context.verify_mode == ssl.CERT_REQUIRED\n            or self.assert_fingerprint is not None\n        )\n\n    def _connect_tls_proxy(self, hostname, conn):\n        \"\"\"\n        Establish a TLS connection to the proxy using the provided SSL context.\n        \"\"\"\n        proxy_config = self.proxy_config\n        ssl_context = proxy_config.ssl_context\n        if ssl_context:\n            # If the user provided a proxy context, we assume CA and client\n            # certificates have already been set\n            return ssl_wrap_socket(\n                sock=conn,\n                server_hostname=hostname,\n                ssl_context=ssl_context,\n            )\n\n        ssl_context = create_proxy_ssl_context(\n            self.ssl_version,\n            self.cert_reqs,\n            self.ca_certs,\n            self.ca_cert_dir,\n            self.ca_cert_data,\n        )\n\n        # If no cert was provided, use only the default options for server\n        # certificate validation\n        return ssl_wrap_socket(\n            sock=conn,\n            ca_certs=self.ca_certs,\n            ca_cert_dir=self.ca_cert_dir,\n            ca_cert_data=self.ca_cert_data,\n            server_hostname=hostname,\n            ssl_context=ssl_context,\n        )\n\n\ndef _match_hostname(cert, asserted_hostname):\n    try:\n        match_hostname(cert, asserted_hostname)\n    except CertificateError as e:\n        log.warning(\n            \"Certificate did not match expected hostname: %s. Certificate: %s\",\n            asserted_hostname,\n            cert,\n        )\n        # Add cert to exception and reraise so client code can inspect\n        # the cert when catching the exception, if they want to\n        e._peer_cert = cert\n        raise\n\n\ndef _get_default_user_agent():\n    return \"python-urllib3/%s\" % __version__\n\n\nclass DummyConnection(object):\n    \"\"\"Used to detect a failed ConnectionCls import.\"\"\"\n\n    pass\n\n\nif not ssl:\n    HTTPSConnection = DummyConnection  # noqa: F811\n\n\nVerifiedHTTPSConnection = HTTPSConnection\n", "import collections\nimport contextlib\nimport platform\nimport socket\nimport ssl\nimport sys\nimport threading\n\nimport pytest\nimport trustme\nfrom tornado import ioloop, web\n\nfrom dummyserver.handlers import TestingApp\nfrom dummyserver.server import HAS_IPV6, run_tornado_app\nfrom dummyserver.testcase import HTTPSDummyServerTestCase\nfrom urllib3.util import ssl_\n\nfrom .tz_stub import stub_timezone_ctx\n\n\n# The Python 3.8+ default loop on Windows breaks Tornado\n@pytest.fixture(scope=\"session\", autouse=True)\ndef configure_windows_event_loop():\n    if sys.version_info >= (3, 8) and platform.system() == \"Windows\":\n        import asyncio\n\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n\n\nServerConfig = collections.namedtuple(\"ServerConfig\", [\"host\", \"port\", \"ca_certs\"])\n\n\n@contextlib.contextmanager\ndef run_server_in_thread(scheme, host, tmpdir, ca, server_cert):\n    ca_cert_path = str(tmpdir / \"ca.pem\")\n    server_cert_path = str(tmpdir / \"server.pem\")\n    server_key_path = str(tmpdir / \"server.key\")\n    ca.cert_pem.write_to_path(ca_cert_path)\n    server_cert.private_key_pem.write_to_path(server_key_path)\n    server_cert.cert_chain_pems[0].write_to_path(server_cert_path)\n    server_certs = {\"keyfile\": server_key_path, \"certfile\": server_cert_path}\n\n    io_loop = ioloop.IOLoop.current()\n    app = web.Application([(r\".*\", TestingApp)])\n    server, port = run_tornado_app(app, io_loop, server_certs, scheme, host)\n    server_thread = threading.Thread(target=io_loop.start)\n    server_thread.start()\n\n    yield ServerConfig(host, port, ca_cert_path)\n\n    io_loop.add_callback(server.stop)\n    io_loop.add_callback(io_loop.stop)\n    server_thread.join()\n\n\n@pytest.fixture\ndef no_san_server(tmp_path_factory):\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # only common name, no subject alternative names\n    server_cert = ca.issue_cert(common_name=u\"localhost\")\n\n    with run_server_in_thread(\"https\", \"localhost\", tmpdir, ca, server_cert) as cfg:\n        yield cfg\n\n\n@pytest.fixture\ndef ip_san_server(tmp_path_factory):\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # IP address in Subject Alternative Name\n    server_cert = ca.issue_cert(u\"127.0.0.1\")\n\n    with run_server_in_thread(\"https\", \"127.0.0.1\", tmpdir, ca, server_cert) as cfg:\n        yield cfg\n\n\n@pytest.fixture\ndef ipv6_addr_server(tmp_path_factory):\n    if not HAS_IPV6:\n        pytest.skip(\"Only runs on IPv6 systems\")\n\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # IP address in Common Name\n    server_cert = ca.issue_cert(common_name=u\"::1\")\n\n    with run_server_in_thread(\"https\", \"::1\", tmpdir, ca, server_cert) as cfg:\n        yield cfg\n\n\n@pytest.fixture\ndef ipv6_san_server(tmp_path_factory):\n    if not HAS_IPV6:\n        pytest.skip(\"Only runs on IPv6 systems\")\n\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # IP address in Subject Alternative Name\n    server_cert = ca.issue_cert(u\"::1\")\n\n    with run_server_in_thread(\"https\", \"::1\", tmpdir, ca, server_cert) as cfg:\n        yield cfg\n\n\n@pytest.yield_fixture\ndef stub_timezone(request):\n    \"\"\"\n    A pytest fixture that runs the test with a stub timezone.\n    \"\"\"\n    with stub_timezone_ctx(request.param):\n        yield\n\n\n@pytest.fixture(scope=\"session\")\ndef supported_tls_versions():\n    # We have to create an actual TLS connection\n    # to test if the TLS version is not disabled by\n    # OpenSSL config. Ubuntu 20.04 specifically\n    # disables TLSv1 and TLSv1.1.\n    tls_versions = set()\n\n    _server = HTTPSDummyServerTestCase()\n    _server._start_server()\n    for _ssl_version_name in (\n        \"PROTOCOL_TLSv1\",\n        \"PROTOCOL_TLSv1_1\",\n        \"PROTOCOL_TLSv1_2\",\n        \"PROTOCOL_TLS\",\n    ):\n        _ssl_version = getattr(ssl, _ssl_version_name, 0)\n        if _ssl_version == 0:\n            continue\n        _sock = socket.create_connection((_server.host, _server.port))\n        try:\n            _sock = ssl_.ssl_wrap_socket(\n                _sock, cert_reqs=ssl.CERT_NONE, ssl_version=_ssl_version\n            )\n        except ssl.SSLError:\n            pass\n        else:\n            tls_versions.add(_sock.version())\n        _sock.close()\n    _server._stop_server()\n    return tls_versions\n\n\n@pytest.fixture(scope=\"function\")\ndef requires_tlsv1(supported_tls_versions):\n    \"\"\"Test requires TLSv1 available\"\"\"\n    if not hasattr(ssl, \"PROTOCOL_TLSv1\") or \"TLSv1\" not in supported_tls_versions:\n        pytest.skip(\"Test requires TLSv1\")\n\n\n@pytest.fixture(scope=\"function\")\ndef requires_tlsv1_1(supported_tls_versions):\n    \"\"\"Test requires TLSv1.1 available\"\"\"\n    if not hasattr(ssl, \"PROTOCOL_TLSv1_1\") or \"TLSv1.1\" not in supported_tls_versions:\n        pytest.skip(\"Test requires TLSv1.1\")\n\n\n@pytest.fixture(scope=\"function\")\ndef requires_tlsv1_2(supported_tls_versions):\n    \"\"\"Test requires TLSv1.2 available\"\"\"\n    if not hasattr(ssl, \"PROTOCOL_TLSv1_2\") or \"TLSv1.2\" not in supported_tls_versions:\n        pytest.skip(\"Test requires TLSv1.2\")\n\n\n@pytest.fixture(scope=\"function\")\ndef requires_tlsv1_3(supported_tls_versions):\n    \"\"\"Test requires TLSv1.3 available\"\"\"\n    if (\n        not getattr(ssl, \"HAS_TLSv1_3\", False)\n        or \"TLSv1.3\" not in supported_tls_versions\n    ):\n        pytest.skip(\"Test requires TLSv1.3\")\n", "import json\nimport os.path\nimport shutil\nimport socket\nimport tempfile\nfrom test import (\n    LONG_TIMEOUT,\n    SHORT_TIMEOUT,\n    onlyPy2,\n    onlyPy3,\n    onlySecureTransport,\n    withPyOpenSSL,\n)\n\nimport pytest\nimport trustme\n\nfrom dummyserver.server import DEFAULT_CA, HAS_IPV6, get_unreachable_address\nfrom dummyserver.testcase import HTTPDummyProxyTestCase, IPv6HTTPDummyProxyTestCase\nfrom urllib3._collections import HTTPHeaderDict\nfrom urllib3.connectionpool import VerifiedHTTPSConnection, connection_from_url\nfrom urllib3.exceptions import (\n    ConnectTimeoutError,\n    MaxRetryError,\n    ProxyError,\n    ProxySchemeUnknown,\n    ProxySchemeUnsupported,\n    SSLError,\n)\nfrom urllib3.poolmanager import ProxyManager, proxy_from_url\nfrom urllib3.util.ssl_ import create_urllib3_context\n\nfrom .. import TARPIT_HOST, requires_network\n\n# Retry failed tests\npytestmark = pytest.mark.flaky\n\n\nclass TestHTTPProxyManager(HTTPDummyProxyTestCase):\n    @classmethod\n    def setup_class(cls):\n        super(TestHTTPProxyManager, cls).setup_class()\n        cls.http_url = \"http://%s:%d\" % (cls.http_host, cls.http_port)\n        cls.http_url_alt = \"http://%s:%d\" % (cls.http_host_alt, cls.http_port)\n        cls.https_url = \"https://%s:%d\" % (cls.https_host, cls.https_port)\n        cls.https_url_alt = \"https://%s:%d\" % (cls.https_host_alt, cls.https_port)\n        cls.proxy_url = \"http://%s:%d\" % (cls.proxy_host, cls.proxy_port)\n        cls.https_proxy_url = \"https://%s:%d\" % (\n            cls.proxy_host,\n            cls.https_proxy_port,\n        )\n\n        # Generate another CA to test verification failure\n        cls.certs_dir = tempfile.mkdtemp()\n        bad_ca = trustme.CA()\n\n        cls.bad_ca_path = os.path.join(cls.certs_dir, \"ca_bad.pem\")\n        bad_ca.cert_pem.write_to_path(cls.bad_ca_path)\n\n    @classmethod\n    def teardown_class(cls):\n        super(TestHTTPProxyManager, cls).teardown_class()\n        shutil.rmtree(cls.certs_dir)\n\n    def test_basic_proxy(self):\n        with proxy_from_url(self.proxy_url, ca_certs=DEFAULT_CA) as http:\n            r = http.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            r = http.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n    @onlyPy3\n    def test_https_proxy(self):\n        with proxy_from_url(self.https_proxy_url, ca_certs=DEFAULT_CA) as https:\n            r = https.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n    @onlyPy3\n    def test_https_proxy_with_proxy_ssl_context(self):\n        proxy_ssl_context = create_urllib3_context()\n        proxy_ssl_context.load_verify_locations(DEFAULT_CA)\n        with proxy_from_url(\n            self.https_proxy_url,\n            proxy_ssl_context=proxy_ssl_context,\n            ca_certs=DEFAULT_CA,\n        ) as https:\n            r = https.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n    @onlyPy2\n    def test_https_proxy_not_supported(self):\n        with proxy_from_url(self.https_proxy_url, ca_certs=DEFAULT_CA) as https:\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            with pytest.raises(ProxySchemeUnsupported) as excinfo:\n                https.request(\"GET\", \"%s/\" % self.https_url)\n\n            assert \"is not supported in Python 2\" in str(excinfo.value)\n\n    @withPyOpenSSL\n    @onlyPy3\n    def test_https_proxy_pyopenssl_not_supported(self):\n        with proxy_from_url(self.https_proxy_url, ca_certs=DEFAULT_CA) as https:\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            with pytest.raises(ProxySchemeUnsupported) as excinfo:\n                https.request(\"GET\", \"%s/\" % self.https_url)\n\n            assert \"isn't available on non-native SSLContext\" in str(excinfo.value)\n\n    @onlySecureTransport\n    @onlyPy3\n    def test_https_proxy_securetransport_not_supported(self):\n        with proxy_from_url(self.https_proxy_url, ca_certs=DEFAULT_CA) as https:\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            with pytest.raises(ProxySchemeUnsupported) as excinfo:\n                https.request(\"GET\", \"%s/\" % self.https_url)\n\n            assert \"isn't available on non-native SSLContext\" in str(excinfo.value)\n\n    def test_https_proxy_forwarding_for_https(self):\n        with proxy_from_url(\n            self.https_proxy_url,\n            ca_certs=DEFAULT_CA,\n            use_forwarding_for_https=True,\n        ) as https:\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            r = https.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n    def test_nagle_proxy(self):\n        \"\"\" Test that proxy connections do not have TCP_NODELAY turned on \"\"\"\n        with ProxyManager(self.proxy_url) as http:\n            hc2 = http.connection_from_host(self.http_host, self.http_port)\n            conn = hc2._get_conn()\n            try:\n                hc2._make_request(conn, \"GET\", \"/\")\n                tcp_nodelay_setting = conn.sock.getsockopt(\n                    socket.IPPROTO_TCP, socket.TCP_NODELAY\n                )\n                assert tcp_nodelay_setting == 0, (\n                    \"Expected TCP_NODELAY for proxies to be set \"\n                    \"to zero, instead was %s\" % tcp_nodelay_setting\n                )\n            finally:\n                conn.close()\n\n    def test_proxy_conn_fail(self):\n        host, port = get_unreachable_address()\n        with proxy_from_url(\n            \"http://%s:%s/\" % (host, port), retries=1, timeout=LONG_TIMEOUT\n        ) as http:\n            with pytest.raises(MaxRetryError):\n                http.request(\"GET\", \"%s/\" % self.https_url)\n            with pytest.raises(MaxRetryError):\n                http.request(\"GET\", \"%s/\" % self.http_url)\n\n            with pytest.raises(MaxRetryError) as e:\n                http.request(\"GET\", \"%s/\" % self.http_url)\n            assert type(e.value.reason) == ProxyError\n\n    def test_oldapi(self):\n        with ProxyManager(\n            connection_from_url(self.proxy_url), ca_certs=DEFAULT_CA\n        ) as http:\n            r = http.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            r = http.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n    def test_proxy_verified(self):\n        with proxy_from_url(\n            self.proxy_url, cert_reqs=\"REQUIRED\", ca_certs=self.bad_ca_path\n        ) as http:\n            https_pool = http._new_pool(\"https\", self.https_host, self.https_port)\n            with pytest.raises(MaxRetryError) as e:\n                https_pool.request(\"GET\", \"/\", retries=0)\n            assert isinstance(e.value.reason, SSLError)\n            assert \"certificate verify failed\" in str(e.value.reason), (\n                \"Expected 'certificate verify failed', instead got: %r\" % e.value.reason\n            )\n\n            http = proxy_from_url(\n                self.proxy_url, cert_reqs=\"REQUIRED\", ca_certs=DEFAULT_CA\n            )\n            https_pool = http._new_pool(\"https\", self.https_host, self.https_port)\n\n            conn = https_pool._new_conn()\n            assert conn.__class__ == VerifiedHTTPSConnection\n            https_pool.request(\"GET\", \"/\")  # Should succeed without exceptions.\n\n            http = proxy_from_url(\n                self.proxy_url, cert_reqs=\"REQUIRED\", ca_certs=DEFAULT_CA\n            )\n            https_fail_pool = http._new_pool(\"https\", \"127.0.0.1\", self.https_port)\n\n            with pytest.raises(MaxRetryError) as e:\n                https_fail_pool.request(\"GET\", \"/\", retries=0)\n            assert isinstance(e.value.reason, SSLError)\n            assert \"doesn't match\" in str(e.value.reason)\n\n    def test_redirect(self):\n        with proxy_from_url(self.proxy_url) as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.http_url,\n                fields={\"target\": \"%s/\" % self.http_url},\n                redirect=False,\n            )\n\n            assert r.status == 303\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.http_url,\n                fields={\"target\": \"%s/\" % self.http_url},\n            )\n\n            assert r.status == 200\n            assert r.data == b\"Dummy server!\"\n\n    def test_cross_host_redirect(self):\n        with proxy_from_url(self.proxy_url) as http:\n            cross_host_location = \"%s/echo?a=b\" % self.http_url_alt\n            with pytest.raises(MaxRetryError):\n                http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.http_url,\n                    fields={\"target\": cross_host_location},\n                    retries=0,\n                )\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.http_url,\n                fields={\"target\": \"%s/echo?a=b\" % self.http_url_alt},\n                retries=1,\n            )\n            assert r._pool.host != self.http_host_alt\n\n    def test_cross_protocol_redirect(self):\n        with proxy_from_url(self.proxy_url, ca_certs=DEFAULT_CA) as http:\n            cross_protocol_location = \"%s/echo?a=b\" % self.https_url\n            with pytest.raises(MaxRetryError):\n                http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.http_url,\n                    fields={\"target\": cross_protocol_location},\n                    retries=0,\n                )\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.http_url,\n                fields={\"target\": \"%s/echo?a=b\" % self.https_url},\n                retries=1,\n            )\n            assert r._pool.host == self.https_host\n\n    def test_headers(self):\n        with proxy_from_url(\n            self.proxy_url,\n            headers={\"Foo\": \"bar\"},\n            proxy_headers={\"Hickory\": \"dickory\"},\n            ca_certs=DEFAULT_CA,\n        ) as http:\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.http_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host,\n                self.http_port,\n            )\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.http_url_alt)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host_alt,\n                self.http_port,\n            )\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.https_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") is None\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.https_host,\n                self.https_port,\n            )\n\n            r = http.request_encode_body(\"POST\", \"%s/headers\" % self.http_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host,\n                self.http_port,\n            )\n\n            r = http.request_encode_url(\n                \"GET\", \"%s/headers\" % self.http_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host,\n                self.http_port,\n            )\n\n            r = http.request_encode_url(\n                \"GET\", \"%s/headers\" % self.https_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n            assert returned_headers.get(\"Hickory\") is None\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.https_host,\n                self.https_port,\n            )\n\n            r = http.request_encode_body(\n                \"GET\", \"%s/headers\" % self.http_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host,\n                self.http_port,\n            )\n\n            r = http.request_encode_body(\n                \"GET\", \"%s/headers\" % self.https_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n            assert returned_headers.get(\"Hickory\") is None\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.https_host,\n                self.https_port,\n            )\n\n    @onlyPy3\n    def test_https_headers(self):\n        with proxy_from_url(\n            self.https_proxy_url,\n            headers={\"Foo\": \"bar\"},\n            proxy_headers={\"Hickory\": \"dickory\"},\n            ca_certs=DEFAULT_CA,\n        ) as http:\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.http_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host,\n                self.http_port,\n            )\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.http_url_alt)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host_alt,\n                self.http_port,\n            )\n\n            r = http.request_encode_body(\n                \"GET\", \"%s/headers\" % self.https_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n            assert returned_headers.get(\"Hickory\") is None\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.https_host,\n                self.https_port,\n            )\n\n    def test_https_headers_forwarding_for_https(self):\n        with proxy_from_url(\n            self.https_proxy_url,\n            headers={\"Foo\": \"bar\"},\n            proxy_headers={\"Hickory\": \"dickory\"},\n            ca_certs=DEFAULT_CA,\n            use_forwarding_for_https=True,\n        ) as http:\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.https_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.https_host,\n                self.https_port,\n            )\n\n    def test_headerdict(self):\n        default_headers = HTTPHeaderDict(a=\"b\")\n        proxy_headers = HTTPHeaderDict()\n        proxy_headers.add(\"foo\", \"bar\")\n\n        with proxy_from_url(\n            self.proxy_url, headers=default_headers, proxy_headers=proxy_headers\n        ) as http:\n            request_headers = HTTPHeaderDict(baz=\"quux\")\n            r = http.request(\n                \"GET\", \"%s/headers\" % self.http_url, headers=request_headers\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Baz\") == \"quux\"\n\n    def test_proxy_pooling(self):\n        with proxy_from_url(self.proxy_url, cert_reqs=\"NONE\") as http:\n            for x in range(2):\n                http.urlopen(\"GET\", self.http_url)\n            assert len(http.pools) == 1\n\n            for x in range(2):\n                http.urlopen(\"GET\", self.http_url_alt)\n            assert len(http.pools) == 1\n\n            for x in range(2):\n                http.urlopen(\"GET\", self.https_url)\n            assert len(http.pools) == 2\n\n            for x in range(2):\n                http.urlopen(\"GET\", self.https_url_alt)\n            assert len(http.pools) == 3\n\n    def test_proxy_pooling_ext(self):\n        with proxy_from_url(self.proxy_url) as http:\n            hc1 = http.connection_from_url(self.http_url)\n            hc2 = http.connection_from_host(self.http_host, self.http_port)\n            hc3 = http.connection_from_url(self.http_url_alt)\n            hc4 = http.connection_from_host(self.http_host_alt, self.http_port)\n            assert hc1 == hc2\n            assert hc2 == hc3\n            assert hc3 == hc4\n\n            sc1 = http.connection_from_url(self.https_url)\n            sc2 = http.connection_from_host(\n                self.https_host, self.https_port, scheme=\"https\"\n            )\n            sc3 = http.connection_from_url(self.https_url_alt)\n            sc4 = http.connection_from_host(\n                self.https_host_alt, self.https_port, scheme=\"https\"\n            )\n            assert sc1 == sc2\n            assert sc2 != sc3\n            assert sc3 == sc4\n\n    @pytest.mark.timeout(0.5)\n    @requires_network\n    def test_https_proxy_timeout(self):\n        with proxy_from_url(\"https://{host}\".format(host=TARPIT_HOST)) as https:\n            with pytest.raises(MaxRetryError) as e:\n                https.request(\"GET\", self.http_url, timeout=SHORT_TIMEOUT)\n            assert type(e.value.reason) == ConnectTimeoutError\n\n    @pytest.mark.timeout(0.5)\n    @requires_network\n    def test_https_proxy_pool_timeout(self):\n        with proxy_from_url(\n            \"https://{host}\".format(host=TARPIT_HOST), timeout=SHORT_TIMEOUT\n        ) as https:\n            with pytest.raises(MaxRetryError) as e:\n                https.request(\"GET\", self.http_url)\n            assert type(e.value.reason) == ConnectTimeoutError\n\n    def test_scheme_host_case_insensitive(self):\n        \"\"\"Assert that upper-case schemes and hosts are normalized.\"\"\"\n        with proxy_from_url(self.proxy_url.upper(), ca_certs=DEFAULT_CA) as http:\n            r = http.request(\"GET\", \"%s/\" % self.http_url.upper())\n            assert r.status == 200\n\n            r = http.request(\"GET\", \"%s/\" % self.https_url.upper())\n            assert r.status == 200\n\n    @pytest.mark.parametrize(\n        \"url, error_msg\",\n        [\n            (\n                \"127.0.0.1\",\n                \"Proxy URL had no scheme, should start with http:// or https://\",\n            ),\n            (\n                \"localhost:8080\",\n                \"Proxy URL had no scheme, should start with http:// or https://\",\n            ),\n            (\n                \"ftp://google.com\",\n                \"Proxy URL had unsupported scheme ftp, should use http:// or https://\",\n            ),\n        ],\n    )\n    def test_invalid_schema(self, url, error_msg):\n        with pytest.raises(ProxySchemeUnknown, match=error_msg):\n            proxy_from_url(url)\n\n\n@pytest.mark.skipif(not HAS_IPV6, reason=\"Only runs on IPv6 systems\")\nclass TestIPv6HTTPProxyManager(IPv6HTTPDummyProxyTestCase):\n    @classmethod\n    def setup_class(cls):\n        HTTPDummyProxyTestCase.setup_class()\n        cls.http_url = \"http://%s:%d\" % (cls.http_host, cls.http_port)\n        cls.http_url_alt = \"http://%s:%d\" % (cls.http_host_alt, cls.http_port)\n        cls.https_url = \"https://%s:%d\" % (cls.https_host, cls.https_port)\n        cls.https_url_alt = \"https://%s:%d\" % (cls.https_host_alt, cls.https_port)\n        cls.proxy_url = \"http://[%s]:%d\" % (cls.proxy_host, cls.proxy_port)\n\n    def test_basic_ipv6_proxy(self):\n        with proxy_from_url(self.proxy_url, ca_certs=DEFAULT_CA) as http:\n            r = http.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            r = http.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n"], "fixing_code": ["from __future__ import absolute_import\n\nimport datetime\nimport logging\nimport os\nimport re\nimport socket\nimport warnings\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\n\nfrom .packages import six\nfrom .packages.six.moves.http_client import HTTPConnection as _HTTPConnection\nfrom .packages.six.moves.http_client import HTTPException  # noqa: F401\nfrom .util.proxy import create_proxy_ssl_context\n\ntry:  # Compiled with SSL?\n    import ssl\n\n    BaseSSLError = ssl.SSLError\nexcept (ImportError, AttributeError):  # Platform-specific: No SSL.\n    ssl = None\n\n    class BaseSSLError(BaseException):\n        pass\n\n\ntry:\n    # Python 3: not a no-op, we're adding this to the namespace so it can be imported.\n    ConnectionError = ConnectionError\nexcept NameError:\n    # Python 2\n    class ConnectionError(Exception):\n        pass\n\n\ntry:  # Python 3:\n    # Not a no-op, we're adding this to the namespace so it can be imported.\n    BrokenPipeError = BrokenPipeError\nexcept NameError:  # Python 2:\n\n    class BrokenPipeError(Exception):\n        pass\n\n\nfrom ._collections import HTTPHeaderDict  # noqa (historical, removed in v2)\nfrom ._version import __version__\nfrom .exceptions import (\n    ConnectTimeoutError,\n    NewConnectionError,\n    SubjectAltNameWarning,\n    SystemTimeWarning,\n)\nfrom .packages.ssl_match_hostname import CertificateError, match_hostname\nfrom .util import SKIP_HEADER, SKIPPABLE_HEADERS, connection\nfrom .util.ssl_ import (\n    assert_fingerprint,\n    create_urllib3_context,\n    resolve_cert_reqs,\n    resolve_ssl_version,\n    ssl_wrap_socket,\n)\n\nlog = logging.getLogger(__name__)\n\nport_by_scheme = {\"http\": 80, \"https\": 443}\n\n# When it comes time to update this value as a part of regular maintenance\n# (ie test_recent_date is failing) update it to ~6 months before the current date.\nRECENT_DATE = datetime.date(2020, 7, 1)\n\n_CONTAINS_CONTROL_CHAR_RE = re.compile(r\"[^-!#$%&'*+.^_`|~0-9a-zA-Z]\")\n\n\nclass HTTPConnection(_HTTPConnection, object):\n    \"\"\"\n    Based on :class:`http.client.HTTPConnection` but provides an extra constructor\n    backwards-compatibility layer between older and newer Pythons.\n\n    Additional keyword parameters are used to configure attributes of the connection.\n    Accepted parameters include:\n\n    - ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`\n    - ``source_address``: Set the source address for the current connection.\n    - ``socket_options``: Set specific options on the underlying socket. If not specified, then\n      defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling\n      Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.\n\n      For example, if you wish to enable TCP Keep Alive in addition to the defaults,\n      you might pass:\n\n      .. code-block:: python\n\n         HTTPConnection.default_socket_options + [\n             (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),\n         ]\n\n      Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).\n    \"\"\"\n\n    default_port = port_by_scheme[\"http\"]\n\n    #: Disable Nagle's algorithm by default.\n    #: ``[(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]``\n    default_socket_options = [(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]\n\n    #: Whether this connection verifies the host's certificate.\n    is_verified = False\n\n    def __init__(self, *args, **kw):\n        if not six.PY2:\n            kw.pop(\"strict\", None)\n\n        # Pre-set source_address.\n        self.source_address = kw.get(\"source_address\")\n\n        #: The socket options provided by the user. If no options are\n        #: provided, we use the default options.\n        self.socket_options = kw.pop(\"socket_options\", self.default_socket_options)\n\n        # Proxy options provided by the user.\n        self.proxy = kw.pop(\"proxy\", None)\n        self.proxy_config = kw.pop(\"proxy_config\", None)\n\n        _HTTPConnection.__init__(self, *args, **kw)\n\n    @property\n    def host(self):\n        \"\"\"\n        Getter method to remove any trailing dots that indicate the hostname is an FQDN.\n\n        In general, SSL certificates don't include the trailing dot indicating a\n        fully-qualified domain name, and thus, they don't validate properly when\n        checked against a domain name that includes the dot. In addition, some\n        servers may not expect to receive the trailing dot when provided.\n\n        However, the hostname with trailing dot is critical to DNS resolution; doing a\n        lookup with the trailing dot will properly only resolve the appropriate FQDN,\n        whereas a lookup without a trailing dot will search the system's search domain\n        list. Thus, it's important to keep the original host around for use only in\n        those cases where it's appropriate (i.e., when doing DNS lookup to establish the\n        actual TCP connection across which we're going to send HTTP requests).\n        \"\"\"\n        return self._dns_host.rstrip(\".\")\n\n    @host.setter\n    def host(self, value):\n        \"\"\"\n        Setter for the `host` property.\n\n        We assume that only urllib3 uses the _dns_host attribute; httplib itself\n        only uses `host`, and it seems reasonable that other libraries follow suit.\n        \"\"\"\n        self._dns_host = value\n\n    def _new_conn(self):\n        \"\"\"Establish a socket connection and set nodelay settings on it.\n\n        :return: New socket connection.\n        \"\"\"\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\"source_address\"] = self.source_address\n\n        if self.socket_options:\n            extra_kw[\"socket_options\"] = self.socket_options\n\n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \"Connection to %s timed out. (connect timeout=%s)\"\n                % (self.host, self.timeout),\n            )\n\n        except SocketError as e:\n            raise NewConnectionError(\n                self, \"Failed to establish a new connection: %s\" % e\n            )\n\n        return conn\n\n    def _is_using_tunnel(self):\n        # Google App Engine's httplib does not define _tunnel_host\n        return getattr(self, \"_tunnel_host\", None)\n\n    def _prepare_conn(self, conn):\n        self.sock = conn\n        if self._is_using_tunnel():\n            # TODO: Fix tunnel so it doesn't depend on self.sock state.\n            self._tunnel()\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n    def connect(self):\n        conn = self._new_conn()\n        self._prepare_conn(conn)\n\n    def putrequest(self, method, url, *args, **kwargs):\n        \"\"\"\"\"\"\n        # Empty docstring because the indentation of CPython's implementation\n        # is broken but we don't want this method in our documentation.\n        match = _CONTAINS_CONTROL_CHAR_RE.search(method)\n        if match:\n            raise ValueError(\n                \"Method cannot contain non-token characters %r (found at least %r)\"\n                % (method, match.group())\n            )\n\n        return _HTTPConnection.putrequest(self, method, url, *args, **kwargs)\n\n    def putheader(self, header, *values):\n        \"\"\"\"\"\"\n        if not any(isinstance(v, str) and v == SKIP_HEADER for v in values):\n            _HTTPConnection.putheader(self, header, *values)\n        elif six.ensure_str(header.lower()) not in SKIPPABLE_HEADERS:\n            raise ValueError(\n                \"urllib3.util.SKIP_HEADER only supports '%s'\"\n                % (\"', '\".join(map(str.title, sorted(SKIPPABLE_HEADERS))),)\n            )\n\n    def request(self, method, url, body=None, headers=None):\n        if headers is None:\n            headers = {}\n        else:\n            # Avoid modifying the headers passed into .request()\n            headers = headers.copy()\n        if \"user-agent\" not in (six.ensure_str(k.lower()) for k in headers):\n            headers[\"User-Agent\"] = _get_default_user_agent()\n        super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n\n    def request_chunked(self, method, url, body=None, headers=None):\n        \"\"\"\n        Alternative to the common request method, which sends the\n        body with chunked encoding and not as one block\n        \"\"\"\n        headers = headers or {}\n        header_keys = set([six.ensure_str(k.lower()) for k in headers])\n        skip_accept_encoding = \"accept-encoding\" in header_keys\n        skip_host = \"host\" in header_keys\n        self.putrequest(\n            method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host\n        )\n        if \"user-agent\" not in header_keys:\n            self.putheader(\"User-Agent\", _get_default_user_agent())\n        for header, value in headers.items():\n            self.putheader(header, value)\n        if \"transfer-encoding\" not in headers:\n            self.putheader(\"Transfer-Encoding\", \"chunked\")\n        self.endheaders()\n\n        if body is not None:\n            stringish_types = six.string_types + (bytes,)\n            if isinstance(body, stringish_types):\n                body = (body,)\n            for chunk in body:\n                if not chunk:\n                    continue\n                if not isinstance(chunk, bytes):\n                    chunk = chunk.encode(\"utf8\")\n                len_str = hex(len(chunk))[2:]\n                to_send = bytearray(len_str.encode())\n                to_send += b\"\\r\\n\"\n                to_send += chunk\n                to_send += b\"\\r\\n\"\n                self.send(to_send)\n\n        # After the if clause, to always have a closed body\n        self.send(b\"0\\r\\n\\r\\n\")\n\n\nclass HTTPSConnection(HTTPConnection):\n    \"\"\"\n    Many of the parameters to this constructor are passed to the underlying SSL\n    socket by means of :py:func:`urllib3.util.ssl_wrap_socket`.\n    \"\"\"\n\n    default_port = port_by_scheme[\"https\"]\n\n    cert_reqs = None\n    ca_certs = None\n    ca_cert_dir = None\n    ca_cert_data = None\n    ssl_version = None\n    assert_fingerprint = None\n    tls_in_tls_required = False\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        key_file=None,\n        cert_file=None,\n        key_password=None,\n        strict=None,\n        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n        ssl_context=None,\n        server_hostname=None,\n        **kw\n    ):\n\n        HTTPConnection.__init__(self, host, port, strict=strict, timeout=timeout, **kw)\n\n        self.key_file = key_file\n        self.cert_file = cert_file\n        self.key_password = key_password\n        self.ssl_context = ssl_context\n        self.server_hostname = server_hostname\n\n        # Required property for Google AppEngine 1.9.0 which otherwise causes\n        # HTTPS requests to go out as HTTP. (See Issue #356)\n        self._protocol = \"https\"\n\n    def set_cert(\n        self,\n        key_file=None,\n        cert_file=None,\n        cert_reqs=None,\n        key_password=None,\n        ca_certs=None,\n        assert_hostname=None,\n        assert_fingerprint=None,\n        ca_cert_dir=None,\n        ca_cert_data=None,\n    ):\n        \"\"\"\n        This method should only be called once, before the connection is used.\n        \"\"\"\n        # If cert_reqs is not provided we'll assume CERT_REQUIRED unless we also\n        # have an SSLContext object in which case we'll use its verify_mode.\n        if cert_reqs is None:\n            if self.ssl_context is not None:\n                cert_reqs = self.ssl_context.verify_mode\n            else:\n                cert_reqs = resolve_cert_reqs(None)\n\n        self.key_file = key_file\n        self.cert_file = cert_file\n        self.cert_reqs = cert_reqs\n        self.key_password = key_password\n        self.assert_hostname = assert_hostname\n        self.assert_fingerprint = assert_fingerprint\n        self.ca_certs = ca_certs and os.path.expanduser(ca_certs)\n        self.ca_cert_dir = ca_cert_dir and os.path.expanduser(ca_cert_dir)\n        self.ca_cert_data = ca_cert_data\n\n    def connect(self):\n        # Add certificate verification\n        conn = self._new_conn()\n        hostname = self.host\n        tls_in_tls = False\n\n        if self._is_using_tunnel():\n            if self.tls_in_tls_required:\n                conn = self._connect_tls_proxy(hostname, conn)\n                tls_in_tls = True\n\n            self.sock = conn\n\n            # Calls self._set_hostport(), so self.host is\n            # self._tunnel_host below.\n            self._tunnel()\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n            # Override the host with the one we're requesting data from.\n            hostname = self._tunnel_host\n\n        server_hostname = hostname\n        if self.server_hostname is not None:\n            server_hostname = self.server_hostname\n\n        is_time_off = datetime.date.today() < RECENT_DATE\n        if is_time_off:\n            warnings.warn(\n                (\n                    \"System time is way off (before {0}). This will probably \"\n                    \"lead to SSL verification errors\"\n                ).format(RECENT_DATE),\n                SystemTimeWarning,\n            )\n\n        # Wrap socket using verification with the root certs in\n        # trusted_root_certs\n        default_ssl_context = False\n        if self.ssl_context is None:\n            default_ssl_context = True\n            self.ssl_context = create_urllib3_context(\n                ssl_version=resolve_ssl_version(self.ssl_version),\n                cert_reqs=resolve_cert_reqs(self.cert_reqs),\n            )\n\n        context = self.ssl_context\n        context.verify_mode = resolve_cert_reqs(self.cert_reqs)\n\n        # Try to load OS default certs if none are given.\n        # Works well on Windows (requires Python3.4+)\n        if (\n            not self.ca_certs\n            and not self.ca_cert_dir\n            and not self.ca_cert_data\n            and default_ssl_context\n            and hasattr(context, \"load_default_certs\")\n        ):\n            context.load_default_certs()\n\n        self.sock = ssl_wrap_socket(\n            sock=conn,\n            keyfile=self.key_file,\n            certfile=self.cert_file,\n            key_password=self.key_password,\n            ca_certs=self.ca_certs,\n            ca_cert_dir=self.ca_cert_dir,\n            ca_cert_data=self.ca_cert_data,\n            server_hostname=server_hostname,\n            ssl_context=context,\n            tls_in_tls=tls_in_tls,\n        )\n\n        # If we're using all defaults and the connection\n        # is TLSv1 or TLSv1.1 we throw a DeprecationWarning\n        # for the host.\n        if (\n            default_ssl_context\n            and self.ssl_version is None\n            and hasattr(self.sock, \"version\")\n            and self.sock.version() in {\"TLSv1\", \"TLSv1.1\"}\n        ):\n            warnings.warn(\n                \"Negotiating TLSv1/TLSv1.1 by default is deprecated \"\n                \"and will be disabled in urllib3 v2.0.0. Connecting to \"\n                \"'%s' with '%s' can be enabled by explicitly opting-in \"\n                \"with 'ssl_version'\" % (self.host, self.sock.version()),\n                DeprecationWarning,\n            )\n\n        if self.assert_fingerprint:\n            assert_fingerprint(\n                self.sock.getpeercert(binary_form=True), self.assert_fingerprint\n            )\n        elif (\n            context.verify_mode != ssl.CERT_NONE\n            and not getattr(context, \"check_hostname\", False)\n            and self.assert_hostname is not False\n        ):\n            # While urllib3 attempts to always turn off hostname matching from\n            # the TLS library, this cannot always be done. So we check whether\n            # the TLS Library still thinks it's matching hostnames.\n            cert = self.sock.getpeercert()\n            if not cert.get(\"subjectAltName\", ()):\n                warnings.warn(\n                    (\n                        \"Certificate for {0} has no `subjectAltName`, falling back to check for a \"\n                        \"`commonName` for now. This feature is being removed by major browsers and \"\n                        \"deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 \"\n                        \"for details.)\".format(hostname)\n                    ),\n                    SubjectAltNameWarning,\n                )\n            _match_hostname(cert, self.assert_hostname or server_hostname)\n\n        self.is_verified = (\n            context.verify_mode == ssl.CERT_REQUIRED\n            or self.assert_fingerprint is not None\n        )\n\n    def _connect_tls_proxy(self, hostname, conn):\n        \"\"\"\n        Establish a TLS connection to the proxy using the provided SSL context.\n        \"\"\"\n        proxy_config = self.proxy_config\n        ssl_context = proxy_config.ssl_context\n        if ssl_context:\n            # If the user provided a proxy context, we assume CA and client\n            # certificates have already been set\n            return ssl_wrap_socket(\n                sock=conn,\n                server_hostname=hostname,\n                ssl_context=ssl_context,\n            )\n\n        ssl_context = create_proxy_ssl_context(\n            self.ssl_version,\n            self.cert_reqs,\n            self.ca_certs,\n            self.ca_cert_dir,\n            self.ca_cert_data,\n        )\n        # By default urllib3's SSLContext disables `check_hostname` and uses\n        # a custom check. For proxies we're good with relying on the default\n        # verification.\n        ssl_context.check_hostname = True\n\n        # If no cert was provided, use only the default options for server\n        # certificate validation\n        return ssl_wrap_socket(\n            sock=conn,\n            ca_certs=self.ca_certs,\n            ca_cert_dir=self.ca_cert_dir,\n            ca_cert_data=self.ca_cert_data,\n            server_hostname=hostname,\n            ssl_context=ssl_context,\n        )\n\n\ndef _match_hostname(cert, asserted_hostname):\n    try:\n        match_hostname(cert, asserted_hostname)\n    except CertificateError as e:\n        log.warning(\n            \"Certificate did not match expected hostname: %s. Certificate: %s\",\n            asserted_hostname,\n            cert,\n        )\n        # Add cert to exception and reraise so client code can inspect\n        # the cert when catching the exception, if they want to\n        e._peer_cert = cert\n        raise\n\n\ndef _get_default_user_agent():\n    return \"python-urllib3/%s\" % __version__\n\n\nclass DummyConnection(object):\n    \"\"\"Used to detect a failed ConnectionCls import.\"\"\"\n\n    pass\n\n\nif not ssl:\n    HTTPSConnection = DummyConnection  # noqa: F811\n\n\nVerifiedHTTPSConnection = HTTPSConnection\n", "import collections\nimport contextlib\nimport platform\nimport socket\nimport ssl\nimport sys\nimport threading\n\nimport pytest\nimport trustme\nfrom tornado import ioloop, web\n\nfrom dummyserver.handlers import TestingApp\nfrom dummyserver.server import HAS_IPV6, run_tornado_app\nfrom dummyserver.testcase import HTTPSDummyServerTestCase\nfrom urllib3.util import ssl_\n\nfrom .tz_stub import stub_timezone_ctx\n\n\n# The Python 3.8+ default loop on Windows breaks Tornado\n@pytest.fixture(scope=\"session\", autouse=True)\ndef configure_windows_event_loop():\n    if sys.version_info >= (3, 8) and platform.system() == \"Windows\":\n        import asyncio\n\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n\n\nServerConfig = collections.namedtuple(\"ServerConfig\", [\"host\", \"port\", \"ca_certs\"])\n\n\n@contextlib.contextmanager\ndef run_server_in_thread(scheme, host, tmpdir, ca, server_cert):\n    ca_cert_path = str(tmpdir / \"ca.pem\")\n    server_cert_path = str(tmpdir / \"server.pem\")\n    server_key_path = str(tmpdir / \"server.key\")\n    ca.cert_pem.write_to_path(ca_cert_path)\n    server_cert.private_key_pem.write_to_path(server_key_path)\n    server_cert.cert_chain_pems[0].write_to_path(server_cert_path)\n    server_certs = {\"keyfile\": server_key_path, \"certfile\": server_cert_path}\n\n    io_loop = ioloop.IOLoop.current()\n    app = web.Application([(r\".*\", TestingApp)])\n    server, port = run_tornado_app(app, io_loop, server_certs, scheme, host)\n    server_thread = threading.Thread(target=io_loop.start)\n    server_thread.start()\n\n    yield ServerConfig(host, port, ca_cert_path)\n\n    io_loop.add_callback(server.stop)\n    io_loop.add_callback(io_loop.stop)\n    server_thread.join()\n\n\n@pytest.fixture\ndef no_san_server(tmp_path_factory):\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # only common name, no subject alternative names\n    server_cert = ca.issue_cert(common_name=u\"localhost\")\n\n    with run_server_in_thread(\"https\", \"localhost\", tmpdir, ca, server_cert) as cfg:\n        yield cfg\n\n\n@pytest.fixture\ndef no_localhost_san_server(tmp_path_factory):\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # non localhost common name\n    server_cert = ca.issue_cert(u\"example.com\")\n\n    with run_server_in_thread(\"https\", \"localhost\", tmpdir, ca, server_cert) as cfg:\n        yield cfg\n\n\n@pytest.fixture\ndef ip_san_server(tmp_path_factory):\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # IP address in Subject Alternative Name\n    server_cert = ca.issue_cert(u\"127.0.0.1\")\n\n    with run_server_in_thread(\"https\", \"127.0.0.1\", tmpdir, ca, server_cert) as cfg:\n        yield cfg\n\n\n@pytest.fixture\ndef ipv6_addr_server(tmp_path_factory):\n    if not HAS_IPV6:\n        pytest.skip(\"Only runs on IPv6 systems\")\n\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # IP address in Common Name\n    server_cert = ca.issue_cert(common_name=u\"::1\")\n\n    with run_server_in_thread(\"https\", \"::1\", tmpdir, ca, server_cert) as cfg:\n        yield cfg\n\n\n@pytest.fixture\ndef ipv6_san_server(tmp_path_factory):\n    if not HAS_IPV6:\n        pytest.skip(\"Only runs on IPv6 systems\")\n\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # IP address in Subject Alternative Name\n    server_cert = ca.issue_cert(u\"::1\")\n\n    with run_server_in_thread(\"https\", \"::1\", tmpdir, ca, server_cert) as cfg:\n        yield cfg\n\n\n@pytest.yield_fixture\ndef stub_timezone(request):\n    \"\"\"\n    A pytest fixture that runs the test with a stub timezone.\n    \"\"\"\n    with stub_timezone_ctx(request.param):\n        yield\n\n\n@pytest.fixture(scope=\"session\")\ndef supported_tls_versions():\n    # We have to create an actual TLS connection\n    # to test if the TLS version is not disabled by\n    # OpenSSL config. Ubuntu 20.04 specifically\n    # disables TLSv1 and TLSv1.1.\n    tls_versions = set()\n\n    _server = HTTPSDummyServerTestCase()\n    _server._start_server()\n    for _ssl_version_name in (\n        \"PROTOCOL_TLSv1\",\n        \"PROTOCOL_TLSv1_1\",\n        \"PROTOCOL_TLSv1_2\",\n        \"PROTOCOL_TLS\",\n    ):\n        _ssl_version = getattr(ssl, _ssl_version_name, 0)\n        if _ssl_version == 0:\n            continue\n        _sock = socket.create_connection((_server.host, _server.port))\n        try:\n            _sock = ssl_.ssl_wrap_socket(\n                _sock, cert_reqs=ssl.CERT_NONE, ssl_version=_ssl_version\n            )\n        except ssl.SSLError:\n            pass\n        else:\n            tls_versions.add(_sock.version())\n        _sock.close()\n    _server._stop_server()\n    return tls_versions\n\n\n@pytest.fixture(scope=\"function\")\ndef requires_tlsv1(supported_tls_versions):\n    \"\"\"Test requires TLSv1 available\"\"\"\n    if not hasattr(ssl, \"PROTOCOL_TLSv1\") or \"TLSv1\" not in supported_tls_versions:\n        pytest.skip(\"Test requires TLSv1\")\n\n\n@pytest.fixture(scope=\"function\")\ndef requires_tlsv1_1(supported_tls_versions):\n    \"\"\"Test requires TLSv1.1 available\"\"\"\n    if not hasattr(ssl, \"PROTOCOL_TLSv1_1\") or \"TLSv1.1\" not in supported_tls_versions:\n        pytest.skip(\"Test requires TLSv1.1\")\n\n\n@pytest.fixture(scope=\"function\")\ndef requires_tlsv1_2(supported_tls_versions):\n    \"\"\"Test requires TLSv1.2 available\"\"\"\n    if not hasattr(ssl, \"PROTOCOL_TLSv1_2\") or \"TLSv1.2\" not in supported_tls_versions:\n        pytest.skip(\"Test requires TLSv1.2\")\n\n\n@pytest.fixture(scope=\"function\")\ndef requires_tlsv1_3(supported_tls_versions):\n    \"\"\"Test requires TLSv1.3 available\"\"\"\n    if (\n        not getattr(ssl, \"HAS_TLSv1_3\", False)\n        or \"TLSv1.3\" not in supported_tls_versions\n    ):\n        pytest.skip(\"Test requires TLSv1.3\")\n", "import json\nimport os.path\nimport shutil\nimport socket\nimport tempfile\nfrom test import (\n    LONG_TIMEOUT,\n    SHORT_TIMEOUT,\n    onlyPy2,\n    onlyPy3,\n    onlySecureTransport,\n    withPyOpenSSL,\n)\n\nimport pytest\nimport trustme\n\nfrom dummyserver.server import DEFAULT_CA, HAS_IPV6, get_unreachable_address\nfrom dummyserver.testcase import HTTPDummyProxyTestCase, IPv6HTTPDummyProxyTestCase\nfrom urllib3._collections import HTTPHeaderDict\nfrom urllib3.connectionpool import VerifiedHTTPSConnection, connection_from_url\nfrom urllib3.exceptions import (\n    ConnectTimeoutError,\n    MaxRetryError,\n    ProxyError,\n    ProxySchemeUnknown,\n    ProxySchemeUnsupported,\n    SSLError,\n)\nfrom urllib3.poolmanager import ProxyManager, proxy_from_url\nfrom urllib3.util.ssl_ import create_urllib3_context\n\nfrom .. import TARPIT_HOST, requires_network\n\n# Retry failed tests\npytestmark = pytest.mark.flaky\n\n\nclass TestHTTPProxyManager(HTTPDummyProxyTestCase):\n    @classmethod\n    def setup_class(cls):\n        super(TestHTTPProxyManager, cls).setup_class()\n        cls.http_url = \"http://%s:%d\" % (cls.http_host, cls.http_port)\n        cls.http_url_alt = \"http://%s:%d\" % (cls.http_host_alt, cls.http_port)\n        cls.https_url = \"https://%s:%d\" % (cls.https_host, cls.https_port)\n        cls.https_url_alt = \"https://%s:%d\" % (cls.https_host_alt, cls.https_port)\n        cls.proxy_url = \"http://%s:%d\" % (cls.proxy_host, cls.proxy_port)\n        cls.https_proxy_url = \"https://%s:%d\" % (\n            cls.proxy_host,\n            cls.https_proxy_port,\n        )\n\n        # Generate another CA to test verification failure\n        cls.certs_dir = tempfile.mkdtemp()\n        bad_ca = trustme.CA()\n\n        cls.bad_ca_path = os.path.join(cls.certs_dir, \"ca_bad.pem\")\n        bad_ca.cert_pem.write_to_path(cls.bad_ca_path)\n\n    @classmethod\n    def teardown_class(cls):\n        super(TestHTTPProxyManager, cls).teardown_class()\n        shutil.rmtree(cls.certs_dir)\n\n    def test_basic_proxy(self):\n        with proxy_from_url(self.proxy_url, ca_certs=DEFAULT_CA) as http:\n            r = http.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            r = http.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n    @onlyPy3\n    def test_https_proxy(self):\n        with proxy_from_url(self.https_proxy_url, ca_certs=DEFAULT_CA) as https:\n            r = https.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n    @onlyPy3\n    def test_https_proxy_with_proxy_ssl_context(self):\n        proxy_ssl_context = create_urllib3_context()\n        proxy_ssl_context.load_verify_locations(DEFAULT_CA)\n        with proxy_from_url(\n            self.https_proxy_url,\n            proxy_ssl_context=proxy_ssl_context,\n            ca_certs=DEFAULT_CA,\n        ) as https:\n            r = https.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n    @onlyPy2\n    def test_https_proxy_not_supported(self):\n        with proxy_from_url(self.https_proxy_url, ca_certs=DEFAULT_CA) as https:\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            with pytest.raises(ProxySchemeUnsupported) as excinfo:\n                https.request(\"GET\", \"%s/\" % self.https_url)\n\n            assert \"is not supported in Python 2\" in str(excinfo.value)\n\n    @withPyOpenSSL\n    @onlyPy3\n    def test_https_proxy_pyopenssl_not_supported(self):\n        with proxy_from_url(self.https_proxy_url, ca_certs=DEFAULT_CA) as https:\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            with pytest.raises(ProxySchemeUnsupported) as excinfo:\n                https.request(\"GET\", \"%s/\" % self.https_url)\n\n            assert \"isn't available on non-native SSLContext\" in str(excinfo.value)\n\n    @onlySecureTransport\n    @onlyPy3\n    def test_https_proxy_securetransport_not_supported(self):\n        with proxy_from_url(self.https_proxy_url, ca_certs=DEFAULT_CA) as https:\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            with pytest.raises(ProxySchemeUnsupported) as excinfo:\n                https.request(\"GET\", \"%s/\" % self.https_url)\n\n            assert \"isn't available on non-native SSLContext\" in str(excinfo.value)\n\n    def test_https_proxy_forwarding_for_https(self):\n        with proxy_from_url(\n            self.https_proxy_url,\n            ca_certs=DEFAULT_CA,\n            use_forwarding_for_https=True,\n        ) as https:\n            r = https.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            r = https.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n    def test_nagle_proxy(self):\n        \"\"\" Test that proxy connections do not have TCP_NODELAY turned on \"\"\"\n        with ProxyManager(self.proxy_url) as http:\n            hc2 = http.connection_from_host(self.http_host, self.http_port)\n            conn = hc2._get_conn()\n            try:\n                hc2._make_request(conn, \"GET\", \"/\")\n                tcp_nodelay_setting = conn.sock.getsockopt(\n                    socket.IPPROTO_TCP, socket.TCP_NODELAY\n                )\n                assert tcp_nodelay_setting == 0, (\n                    \"Expected TCP_NODELAY for proxies to be set \"\n                    \"to zero, instead was %s\" % tcp_nodelay_setting\n                )\n            finally:\n                conn.close()\n\n    def test_proxy_conn_fail(self):\n        host, port = get_unreachable_address()\n        with proxy_from_url(\n            \"http://%s:%s/\" % (host, port), retries=1, timeout=LONG_TIMEOUT\n        ) as http:\n            with pytest.raises(MaxRetryError):\n                http.request(\"GET\", \"%s/\" % self.https_url)\n            with pytest.raises(MaxRetryError):\n                http.request(\"GET\", \"%s/\" % self.http_url)\n\n            with pytest.raises(MaxRetryError) as e:\n                http.request(\"GET\", \"%s/\" % self.http_url)\n            assert type(e.value.reason) == ProxyError\n\n    def test_oldapi(self):\n        with ProxyManager(\n            connection_from_url(self.proxy_url), ca_certs=DEFAULT_CA\n        ) as http:\n            r = http.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            r = http.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n    def test_proxy_verified(self):\n        with proxy_from_url(\n            self.proxy_url, cert_reqs=\"REQUIRED\", ca_certs=self.bad_ca_path\n        ) as http:\n            https_pool = http._new_pool(\"https\", self.https_host, self.https_port)\n            with pytest.raises(MaxRetryError) as e:\n                https_pool.request(\"GET\", \"/\", retries=0)\n            assert isinstance(e.value.reason, SSLError)\n            assert \"certificate verify failed\" in str(e.value.reason), (\n                \"Expected 'certificate verify failed', instead got: %r\" % e.value.reason\n            )\n\n            http = proxy_from_url(\n                self.proxy_url, cert_reqs=\"REQUIRED\", ca_certs=DEFAULT_CA\n            )\n            https_pool = http._new_pool(\"https\", self.https_host, self.https_port)\n\n            conn = https_pool._new_conn()\n            assert conn.__class__ == VerifiedHTTPSConnection\n            https_pool.request(\"GET\", \"/\")  # Should succeed without exceptions.\n\n            http = proxy_from_url(\n                self.proxy_url, cert_reqs=\"REQUIRED\", ca_certs=DEFAULT_CA\n            )\n            https_fail_pool = http._new_pool(\"https\", \"127.0.0.1\", self.https_port)\n\n            with pytest.raises(MaxRetryError) as e:\n                https_fail_pool.request(\"GET\", \"/\", retries=0)\n            assert isinstance(e.value.reason, SSLError)\n            assert \"doesn't match\" in str(e.value.reason)\n\n    def test_redirect(self):\n        with proxy_from_url(self.proxy_url) as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.http_url,\n                fields={\"target\": \"%s/\" % self.http_url},\n                redirect=False,\n            )\n\n            assert r.status == 303\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.http_url,\n                fields={\"target\": \"%s/\" % self.http_url},\n            )\n\n            assert r.status == 200\n            assert r.data == b\"Dummy server!\"\n\n    def test_cross_host_redirect(self):\n        with proxy_from_url(self.proxy_url) as http:\n            cross_host_location = \"%s/echo?a=b\" % self.http_url_alt\n            with pytest.raises(MaxRetryError):\n                http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.http_url,\n                    fields={\"target\": cross_host_location},\n                    retries=0,\n                )\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.http_url,\n                fields={\"target\": \"%s/echo?a=b\" % self.http_url_alt},\n                retries=1,\n            )\n            assert r._pool.host != self.http_host_alt\n\n    def test_cross_protocol_redirect(self):\n        with proxy_from_url(self.proxy_url, ca_certs=DEFAULT_CA) as http:\n            cross_protocol_location = \"%s/echo?a=b\" % self.https_url\n            with pytest.raises(MaxRetryError):\n                http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.http_url,\n                    fields={\"target\": cross_protocol_location},\n                    retries=0,\n                )\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.http_url,\n                fields={\"target\": \"%s/echo?a=b\" % self.https_url},\n                retries=1,\n            )\n            assert r._pool.host == self.https_host\n\n    def test_headers(self):\n        with proxy_from_url(\n            self.proxy_url,\n            headers={\"Foo\": \"bar\"},\n            proxy_headers={\"Hickory\": \"dickory\"},\n            ca_certs=DEFAULT_CA,\n        ) as http:\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.http_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host,\n                self.http_port,\n            )\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.http_url_alt)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host_alt,\n                self.http_port,\n            )\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.https_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") is None\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.https_host,\n                self.https_port,\n            )\n\n            r = http.request_encode_body(\"POST\", \"%s/headers\" % self.http_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host,\n                self.http_port,\n            )\n\n            r = http.request_encode_url(\n                \"GET\", \"%s/headers\" % self.http_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host,\n                self.http_port,\n            )\n\n            r = http.request_encode_url(\n                \"GET\", \"%s/headers\" % self.https_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n            assert returned_headers.get(\"Hickory\") is None\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.https_host,\n                self.https_port,\n            )\n\n            r = http.request_encode_body(\n                \"GET\", \"%s/headers\" % self.http_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host,\n                self.http_port,\n            )\n\n            r = http.request_encode_body(\n                \"GET\", \"%s/headers\" % self.https_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n            assert returned_headers.get(\"Hickory\") is None\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.https_host,\n                self.https_port,\n            )\n\n    @onlyPy3\n    def test_https_headers(self):\n        with proxy_from_url(\n            self.https_proxy_url,\n            headers={\"Foo\": \"bar\"},\n            proxy_headers={\"Hickory\": \"dickory\"},\n            ca_certs=DEFAULT_CA,\n        ) as http:\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.http_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host,\n                self.http_port,\n            )\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.http_url_alt)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.http_host_alt,\n                self.http_port,\n            )\n\n            r = http.request_encode_body(\n                \"GET\", \"%s/headers\" % self.https_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n            assert returned_headers.get(\"Hickory\") is None\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.https_host,\n                self.https_port,\n            )\n\n    def test_https_headers_forwarding_for_https(self):\n        with proxy_from_url(\n            self.https_proxy_url,\n            headers={\"Foo\": \"bar\"},\n            proxy_headers={\"Hickory\": \"dickory\"},\n            ca_certs=DEFAULT_CA,\n            use_forwarding_for_https=True,\n        ) as http:\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.https_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Hickory\") == \"dickory\"\n            assert returned_headers.get(\"Host\") == \"%s:%s\" % (\n                self.https_host,\n                self.https_port,\n            )\n\n    def test_headerdict(self):\n        default_headers = HTTPHeaderDict(a=\"b\")\n        proxy_headers = HTTPHeaderDict()\n        proxy_headers.add(\"foo\", \"bar\")\n\n        with proxy_from_url(\n            self.proxy_url, headers=default_headers, proxy_headers=proxy_headers\n        ) as http:\n            request_headers = HTTPHeaderDict(baz=\"quux\")\n            r = http.request(\n                \"GET\", \"%s/headers\" % self.http_url, headers=request_headers\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n            assert returned_headers.get(\"Baz\") == \"quux\"\n\n    def test_proxy_pooling(self):\n        with proxy_from_url(self.proxy_url, cert_reqs=\"NONE\") as http:\n            for x in range(2):\n                http.urlopen(\"GET\", self.http_url)\n            assert len(http.pools) == 1\n\n            for x in range(2):\n                http.urlopen(\"GET\", self.http_url_alt)\n            assert len(http.pools) == 1\n\n            for x in range(2):\n                http.urlopen(\"GET\", self.https_url)\n            assert len(http.pools) == 2\n\n            for x in range(2):\n                http.urlopen(\"GET\", self.https_url_alt)\n            assert len(http.pools) == 3\n\n    def test_proxy_pooling_ext(self):\n        with proxy_from_url(self.proxy_url) as http:\n            hc1 = http.connection_from_url(self.http_url)\n            hc2 = http.connection_from_host(self.http_host, self.http_port)\n            hc3 = http.connection_from_url(self.http_url_alt)\n            hc4 = http.connection_from_host(self.http_host_alt, self.http_port)\n            assert hc1 == hc2\n            assert hc2 == hc3\n            assert hc3 == hc4\n\n            sc1 = http.connection_from_url(self.https_url)\n            sc2 = http.connection_from_host(\n                self.https_host, self.https_port, scheme=\"https\"\n            )\n            sc3 = http.connection_from_url(self.https_url_alt)\n            sc4 = http.connection_from_host(\n                self.https_host_alt, self.https_port, scheme=\"https\"\n            )\n            assert sc1 == sc2\n            assert sc2 != sc3\n            assert sc3 == sc4\n\n    @pytest.mark.timeout(0.5)\n    @requires_network\n    def test_https_proxy_timeout(self):\n        with proxy_from_url(\"https://{host}\".format(host=TARPIT_HOST)) as https:\n            with pytest.raises(MaxRetryError) as e:\n                https.request(\"GET\", self.http_url, timeout=SHORT_TIMEOUT)\n            assert type(e.value.reason) == ConnectTimeoutError\n\n    @pytest.mark.timeout(0.5)\n    @requires_network\n    def test_https_proxy_pool_timeout(self):\n        with proxy_from_url(\n            \"https://{host}\".format(host=TARPIT_HOST), timeout=SHORT_TIMEOUT\n        ) as https:\n            with pytest.raises(MaxRetryError) as e:\n                https.request(\"GET\", self.http_url)\n            assert type(e.value.reason) == ConnectTimeoutError\n\n    def test_scheme_host_case_insensitive(self):\n        \"\"\"Assert that upper-case schemes and hosts are normalized.\"\"\"\n        with proxy_from_url(self.proxy_url.upper(), ca_certs=DEFAULT_CA) as http:\n            r = http.request(\"GET\", \"%s/\" % self.http_url.upper())\n            assert r.status == 200\n\n            r = http.request(\"GET\", \"%s/\" % self.https_url.upper())\n            assert r.status == 200\n\n    @pytest.mark.parametrize(\n        \"url, error_msg\",\n        [\n            (\n                \"127.0.0.1\",\n                \"Proxy URL had no scheme, should start with http:// or https://\",\n            ),\n            (\n                \"localhost:8080\",\n                \"Proxy URL had no scheme, should start with http:// or https://\",\n            ),\n            (\n                \"ftp://google.com\",\n                \"Proxy URL had unsupported scheme ftp, should use http:// or https://\",\n            ),\n        ],\n    )\n    def test_invalid_schema(self, url, error_msg):\n        with pytest.raises(ProxySchemeUnknown, match=error_msg):\n            proxy_from_url(url)\n\n\n@pytest.mark.skipif(not HAS_IPV6, reason=\"Only runs on IPv6 systems\")\nclass TestIPv6HTTPProxyManager(IPv6HTTPDummyProxyTestCase):\n    @classmethod\n    def setup_class(cls):\n        HTTPDummyProxyTestCase.setup_class()\n        cls.http_url = \"http://%s:%d\" % (cls.http_host, cls.http_port)\n        cls.http_url_alt = \"http://%s:%d\" % (cls.http_host_alt, cls.http_port)\n        cls.https_url = \"https://%s:%d\" % (cls.https_host, cls.https_port)\n        cls.https_url_alt = \"https://%s:%d\" % (cls.https_host_alt, cls.https_port)\n        cls.proxy_url = \"http://[%s]:%d\" % (cls.proxy_host, cls.proxy_port)\n\n    def test_basic_ipv6_proxy(self):\n        with proxy_from_url(self.proxy_url, ca_certs=DEFAULT_CA) as http:\n            r = http.request(\"GET\", \"%s/\" % self.http_url)\n            assert r.status == 200\n\n            r = http.request(\"GET\", \"%s/\" % self.https_url)\n            assert r.status == 200\n\n\nclass TestHTTPSProxyVerification:\n    @onlyPy3\n    def test_https_proxy_hostname_verification(self, no_localhost_san_server):\n        bad_server = no_localhost_san_server\n        bad_proxy_url = \"https://%s:%s\" % (bad_server.host, bad_server.port)\n\n        # An exception will be raised before we contact the destination domain.\n        test_url = \"testing.com\"\n        with proxy_from_url(bad_proxy_url, ca_certs=bad_server.ca_certs) as https:\n            with pytest.raises(MaxRetryError) as e:\n                https.request(\"GET\", \"http://%s/\" % test_url)\n            assert isinstance(e.value.reason, SSLError)\n            assert \"hostname 'localhost' doesn't match\" in str(e.value.reason)\n\n            with pytest.raises(MaxRetryError) as e:\n                https.request(\"GET\", \"https://%s/\" % test_url)\n            assert isinstance(e.value.reason, SSLError)\n            assert \"hostname 'localhost' doesn't match\" in str(\n                e.value.reason\n            ) or \"Hostname mismatch\" in str(e.value.reason)\n"], "filenames": ["src/urllib3/connection.py", "test/conftest.py", "test/with_dummyserver/test_proxy_poolmanager.py"], "buggy_code_start_loc": [492, 61, 545], "buggy_code_end_loc": [492, 61, 545], "fixing_code_start_loc": [493, 62, 546], "fixing_code_end_loc": [497, 73, 568], "type": "CWE-295", "message": "The urllib3 library 1.26.x before 1.26.4 for Python omits SSL certificate validation in some cases involving HTTPS to HTTPS proxies. The initial connection to the HTTPS proxy (if an SSLContext isn't given via proxy_config) doesn't verify the hostname of the certificate. This means certificates for different servers that still validate properly with the default urllib3 SSLContext will be silently accepted.", "other": {"cve": {"id": "CVE-2021-28363", "sourceIdentifier": "cve@mitre.org", "published": "2021-03-15T18:15:19.017", "lastModified": "2023-05-03T11:15:10.133", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The urllib3 library 1.26.x before 1.26.4 for Python omits SSL certificate validation in some cases involving HTTPS to HTTPS proxies. The initial connection to the HTTPS proxy (if an SSLContext isn't given via proxy_config) doesn't verify the hostname of the certificate. This means certificates for different servers that still validate properly with the default urllib3 SSLContext will be silently accepted."}, {"lang": "es", "value": "La biblioteca urllib3 versiones 1.26.x anteriores a 1.26.4 para Python, omite una comprobaci\u00f3n del certificado SSL en algunos casos que involucran HTTPS a proxies HTTPS.&#xa0;La conexi\u00f3n inicial al proxy HTTPS (si no se proporciona un SSLContext por medio de proxy_config) no verifica el nombre de host del certificado.&#xa0;Esto significa que los certificados para diferentes servidores que a\u00fan se comprueban apropiadamente con el urllib3 SSLContext predeterminado ser\u00e1n aceptados silenciosamente"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 3.9, "impactScore": 2.5}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 6.4}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-295"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:python:urllib3:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.26.0", "versionEndExcluding": "1.26.4", "matchCriteriaId": "E96214AF-6F58-4B98-9C24-CF7917C431DB"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:34:*:*:*:*:*:*:*", "matchCriteriaId": "A930E247-0B43-43CB-98FF-6CE7B8189835"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:oracle:peoplesoft_enterprise_peopletools:8.59:*:*:*:*:*:*:*", "matchCriteriaId": "C8AF00C6-B97F-414D-A8DF-057E6BFD8597"}]}]}], "references": [{"url": "https://github.com/urllib3/urllib3/commit/8d65ea1ecf6e2cdc27d42124e587c1b83a3118b0", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/urllib3/urllib3/commits/main", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/urllib3/urllib3/security/advisories/GHSA-5phf-pp7p-vc2r", "source": "cve@mitre.org", "tags": ["Mitigation", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/4S65ZQVZ2ODGB52IC7VJDBUK4M5INCXL/", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://pypi.org/project/urllib3/1.26.4/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://security.gentoo.org/glsa/202107-36", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://security.gentoo.org/glsa/202305-02", "source": "cve@mitre.org"}, {"url": "https://www.oracle.com/security-alerts/cpuoct2021.html", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/urllib3/urllib3/commit/8d65ea1ecf6e2cdc27d42124e587c1b83a3118b0"}}
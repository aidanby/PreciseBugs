{"buggy_code": ["// Copyright Istio Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage inject\n\nimport (\n\t\"crypto/sha256\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/prometheus/prometheus/util/strutil\"\n\t\"gomodules.xyz/jsonpatch/v3\"\n\tkubeApiAdmissionv1 \"k8s.io/api/admission/v1\"\n\tkubeApiAdmissionv1beta1 \"k8s.io/api/admission/v1beta1\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/runtime\"\n\t\"k8s.io/apimachinery/pkg/runtime/serializer\"\n\tkjson \"k8s.io/apimachinery/pkg/runtime/serializer/json\"\n\t\"k8s.io/apimachinery/pkg/util/strategicpatch\"\n\t\"k8s.io/kube-openapi/pkg/util/sets\"\n\n\t\"istio.io/api/annotation\"\n\t\"istio.io/api/label\"\n\tmeshconfig \"istio.io/api/mesh/v1alpha1\"\n\topconfig \"istio.io/istio/operator/pkg/apis/istio/v1alpha1\"\n\t\"istio.io/istio/pilot/cmd/pilot-agent/status\"\n\t\"istio.io/istio/pilot/pkg/model\"\n\t\"istio.io/istio/pkg/config/mesh\"\n\t\"istio.io/istio/pkg/kube\"\n\t\"istio.io/istio/pkg/util/gogoprotomarshal\"\n\t\"istio.io/pkg/log\"\n)\n\nvar (\n\truntimeScheme     = runtime.NewScheme()\n\tcodecs            = serializer.NewCodecFactory(runtimeScheme)\n\tdeserializer      = codecs.UniversalDeserializer()\n\tjsonSerializer    = kjson.NewSerializerWithOptions(kjson.DefaultMetaFactory, runtimeScheme, runtimeScheme, kjson.SerializerOptions{})\n\tURLParameterToEnv = map[string]string{\n\t\t\"cluster\": \"ISTIO_META_CLUSTER_ID\",\n\t\t\"net\":     \"ISTIO_META_NETWORK\",\n\t}\n)\n\nfunc init() {\n\t_ = corev1.AddToScheme(runtimeScheme)\n\t_ = kubeApiAdmissionv1.AddToScheme(runtimeScheme)\n\t_ = kubeApiAdmissionv1beta1.AddToScheme(runtimeScheme)\n}\n\nconst (\n\t// prometheus will convert annotation to this format\n\t// `prometheus.io/scrape` `prometheus.io.scrape` `prometheus-io/scrape` have the same meaning in Prometheus\n\t// for more details, please checkout [here](https://github.com/prometheus/prometheus/blob/71a0f42331566a8849863d77078083edbb0b3bc4/util/strutil/strconv.go#L40)\n\tprometheusScrapeAnnotation = \"prometheus_io_scrape\"\n\tprometheusPortAnnotation   = \"prometheus_io_port\"\n\tprometheusPathAnnotation   = \"prometheus_io_path\"\n\n\twatchDebounceDelay = 100 * time.Millisecond\n)\n\n// Webhook implements a mutating webhook for automatic proxy injection.\ntype Webhook struct {\n\tmu           sync.RWMutex\n\tConfig       *Config\n\tmeshConfig   *meshconfig.MeshConfig\n\tvaluesConfig string\n\n\twatcher Watcher\n\n\tenv      *model.Environment\n\trevision string\n}\n\n// nolint directives: interfacer\nfunc loadConfig(injectFile, valuesFile string) (*Config, string, error) {\n\tdata, err := os.ReadFile(injectFile)\n\tif err != nil {\n\t\treturn nil, \"\", err\n\t}\n\tvar c *Config\n\tif c, err = unmarshalConfig(data); err != nil {\n\t\tlog.Warnf(\"Failed to parse injectFile %s\", string(data))\n\t\treturn nil, \"\", err\n\t}\n\n\tvaluesConfig, err := os.ReadFile(valuesFile)\n\tif err != nil {\n\t\treturn nil, \"\", err\n\t}\n\treturn c, string(valuesConfig), nil\n}\n\nfunc unmarshalConfig(data []byte) (*Config, error) {\n\tc, err := UnmarshalConfig(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlog.Debugf(\"New inject configuration: sha256sum %x\", sha256.Sum256(data))\n\tlog.Debugf(\"Policy: %v\", c.Policy)\n\tlog.Debugf(\"AlwaysInjectSelector: %v\", c.AlwaysInjectSelector)\n\tlog.Debugf(\"NeverInjectSelector: %v\", c.NeverInjectSelector)\n\tlog.Debugf(\"Templates: |\\n  %v\", c.Templates, \"\\n\", \"\\n  \", -1)\n\treturn &c, nil\n}\n\n// WebhookParameters configures parameters for the sidecar injection\n// webhook.\ntype WebhookParameters struct {\n\t// Watcher watches the sidecar injection configuration.\n\tWatcher Watcher\n\n\t// Port is the webhook port, e.g. typically 443 for https.\n\t// This is mainly used for tests. Webhook runs on the port started by Istiod.\n\tPort int\n\n\tEnv *model.Environment\n\n\t// Use an existing mux instead of creating our own.\n\tMux *http.ServeMux\n\n\t// The istio.io/rev this injector is responsible for\n\tRevision string\n}\n\n// NewWebhook creates a new instance of a mutating webhook for automatic sidecar injection.\nfunc NewWebhook(p WebhookParameters) (*Webhook, error) {\n\tif p.Mux == nil {\n\t\treturn nil, errors.New(\"expected mux to be passed, but was not passed\")\n\t}\n\n\twh := &Webhook{\n\t\twatcher:    p.Watcher,\n\t\tmeshConfig: p.Env.Mesh(),\n\t\tenv:        p.Env,\n\t\trevision:   p.Revision,\n\t}\n\n\tp.Watcher.SetHandler(wh.updateConfig)\n\tsidecarConfig, valuesConfig, err := p.Watcher.Get()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\twh.updateConfig(sidecarConfig, valuesConfig)\n\n\tp.Mux.HandleFunc(\"/inject\", wh.serveInject)\n\tp.Mux.HandleFunc(\"/inject/\", wh.serveInject)\n\n\tp.Env.Watcher.AddMeshHandler(func() {\n\t\twh.mu.Lock()\n\t\twh.meshConfig = p.Env.Mesh()\n\t\twh.mu.Unlock()\n\t})\n\n\treturn wh, nil\n}\n\n// Run implements the webhook server\nfunc (wh *Webhook) Run(stop <-chan struct{}) {\n\tgo wh.watcher.Run(stop)\n}\n\nfunc (wh *Webhook) updateConfig(sidecarConfig *Config, valuesConfig string) {\n\twh.mu.Lock()\n\twh.Config = sidecarConfig\n\twh.valuesConfig = valuesConfig\n\twh.mu.Unlock()\n}\n\ntype ContainerReorder int\n\nconst (\n\tMoveFirst ContainerReorder = iota\n\tMoveLast\n\tRemove\n)\n\nfunc modifyContainers(cl []corev1.Container, name string, modifier ContainerReorder) []corev1.Container {\n\tcontainers := []corev1.Container{}\n\tvar match *corev1.Container\n\tfor _, c := range cl {\n\t\tc := c\n\t\tif c.Name != name {\n\t\t\tcontainers = append(containers, c)\n\t\t} else {\n\t\t\tmatch = &c\n\t\t}\n\t}\n\tif match == nil {\n\t\treturn containers\n\t}\n\tswitch modifier {\n\tcase MoveFirst:\n\t\treturn append([]corev1.Container{*match}, containers...)\n\tcase MoveLast:\n\t\treturn append(containers, *match)\n\tcase Remove:\n\t\treturn containers\n\tdefault:\n\t\treturn cl\n\t}\n}\n\nfunc enablePrometheusMerge(mesh *meshconfig.MeshConfig, anno map[string]string) bool {\n\t// If annotation is present, we look there first\n\tif val, f := anno[annotation.PrometheusMergeMetrics.Name]; f {\n\t\tbval, err := strconv.ParseBool(val)\n\t\tif err != nil {\n\t\t\t// This shouldn't happen since we validate earlier in the code\n\t\t\tlog.Warnf(\"invalid annotation %v=%v\", annotation.PrometheusMergeMetrics.Name, bval)\n\t\t} else {\n\t\t\treturn bval\n\t\t}\n\t}\n\t// If mesh config setting is present, use that\n\tif mesh.GetEnablePrometheusMerge() != nil {\n\t\treturn mesh.GetEnablePrometheusMerge().Value\n\t}\n\t// Otherwise, we default to enable\n\treturn true\n}\n\nfunc toAdmissionResponse(err error) *kube.AdmissionResponse {\n\treturn &kube.AdmissionResponse{Result: &metav1.Status{Message: err.Error()}}\n}\n\ntype InjectionParameters struct {\n\tpod                 *corev1.Pod\n\tdeployMeta          metav1.ObjectMeta\n\ttypeMeta            metav1.TypeMeta\n\ttemplates           Templates\n\tdefaultTemplate     []string\n\taliases             map[string][]string\n\tmeshConfig          *meshconfig.MeshConfig\n\tproxyConfig         *meshconfig.ProxyConfig\n\tvaluesConfig        string\n\trevision            string\n\tproxyEnvs           map[string]string\n\tinjectedAnnotations map[string]string\n}\n\nfunc checkPreconditions(params InjectionParameters) {\n\tspec := params.pod.Spec\n\tmetadata := params.pod.ObjectMeta\n\t// If DNSPolicy is not ClusterFirst, the Envoy sidecar may not able to connect to Istio Pilot.\n\tif spec.DNSPolicy != \"\" && spec.DNSPolicy != corev1.DNSClusterFirst {\n\t\tpodName := potentialPodName(metadata)\n\t\tlog.Warnf(\"%q's DNSPolicy is not %q. The Envoy sidecar may not able to connect to Istio Pilot\",\n\t\t\tmetadata.Namespace+\"/\"+podName, corev1.DNSClusterFirst)\n\t}\n}\n\nfunc getInjectionStatus(podSpec corev1.PodSpec, revision string) string {\n\tstat := &SidecarInjectionStatus{}\n\tfor _, c := range podSpec.InitContainers {\n\t\tstat.InitContainers = append(stat.InitContainers, c.Name)\n\t}\n\tfor _, c := range podSpec.Containers {\n\t\tstat.Containers = append(stat.Containers, c.Name)\n\t}\n\tfor _, c := range podSpec.Volumes {\n\t\tstat.Volumes = append(stat.Volumes, c.Name)\n\t}\n\tfor _, c := range podSpec.ImagePullSecrets {\n\t\tstat.ImagePullSecrets = append(stat.ImagePullSecrets, c.Name)\n\t}\n\t// Rather than setting istio.io/rev label on injected pods include them here in status annotation.\n\t// This keeps us from overwriting the istio.io/rev label when using revision tags (i.e. istio.io/rev=<tag>).\n\tif revision == \"\" {\n\t\trevision = \"default\"\n\t}\n\tstat.Revision = revision\n\tstatusAnnotationValue, err := json.Marshal(stat)\n\tif err != nil {\n\t\treturn \"{}\"\n\t}\n\treturn string(statusAnnotationValue)\n}\n\n// injectPod is the core of the injection logic. This takes a pod and injection\n// template, as well as some inputs to the injection template, and produces a\n// JSON patch.\n//\n// In the webhook, we will receive a Pod directly from Kubernetes, and return the\n// patch directly; Kubernetes will take care of applying the patch.\n//\n// For kube-inject, we will parse out a Pod from YAML (which may involve\n// extraction from higher level types like Deployment), then apply the patch\n// locally.\n//\n// The injection logic works by first applying the rendered injection template on\n// top of the input pod This is done using a Strategic Patch Merge\n// (https://github.com/kubernetes/community/blob/master/contributors/devel/sig-api-machinery/strategic-merge-patch.md)\n// Currently only a single template is supported, although in the future the template to use will be configurable\n// and multiple templates will be supported by applying them in successive order.\n//\n// In addition to the plain templating, there is some post processing done to\n// handle cases that cannot feasibly be covered in the template, such as\n// re-ordering pods, rewriting readiness probes, etc.\nfunc injectPod(req InjectionParameters) ([]byte, error) {\n\tcheckPreconditions(req)\n\n\t// The patch will be built relative to the initial pod, capture its current state\n\toriginalPodSpec, err := json.Marshal(req.pod)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Run the injection template, giving us a partial pod spec\n\tmergedPod, injectedPodData, err := RunTemplate(req)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to run injection template: %v\", err)\n\t}\n\n\tmergedPod, err = reapplyOverwrittenContainers(mergedPod, req.pod, injectedPodData)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to re apply container: %v\", err)\n\t}\n\n\t// Apply some additional transformations to the pod\n\tif err := postProcessPod(mergedPod, *injectedPodData, req); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to process pod: %v\", err)\n\t}\n\n\tpatch, err := createPatch(mergedPod, originalPodSpec)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create patch: %v\", err)\n\t}\n\n\tlog.Debugf(\"AdmissionResponse: patch=%v\\n\", string(patch))\n\treturn patch, nil\n}\n\n// reapplyOverwrittenContainers enables users to provide container level overrides for settings in the injection template\n// * originalPod: the pod before injection. If needed, we will apply some configurations from this pod on top of the final pod\n// * templatePod: the rendered injection template. This is needed only to see what containers we injected\n// * finalPod: the current result of injection, roughly equivalent to the merging of originalPod and templatePod\n// There are essentially three cases we cover here:\n// 1. There is no overlap in containers in original and template pod. We will do nothing.\n// 2. There is an overlap (ie, both define istio-proxy), but that is because the pod is being re-injected.\n//    In this case we do nothing, since we want to apply the new settings\n// 3. There is an overlap. We will re-apply the original container.\n// Where \"overlap\" is a container defined in both the original and template pod. Typically, this would mean\n// the user has defined an `istio-proxy` container in their own pod spec.\nfunc reapplyOverwrittenContainers(finalPod *corev1.Pod, originalPod *corev1.Pod, templatePod *corev1.Pod) (*corev1.Pod, error) {\n\ttype podOverrides struct {\n\t\tContainers     []corev1.Container `json:\"containers,omitempty\"`\n\t\tInitContainers []corev1.Container `json:\"initContainers,omitempty\"`\n\t}\n\n\toverrides := podOverrides{}\n\texistingOverrides := podOverrides{}\n\tif annotationOverrides, f := originalPod.Annotations[annotation.ProxyOverrides.Name]; f {\n\t\tif err := json.Unmarshal([]byte(annotationOverrides), &existingOverrides); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tfor _, c := range templatePod.Spec.Containers {\n\t\tmatch := FindContainer(c.Name, existingOverrides.Containers)\n\t\tif match == nil {\n\t\t\tmatch = FindContainer(c.Name, originalPod.Spec.Containers)\n\t\t}\n\t\tif match == nil {\n\t\t\tcontinue\n\t\t}\n\t\toverlay := *match.DeepCopy()\n\t\tif overlay.Image == AutoImage {\n\t\t\toverlay.Image = \"\"\n\t\t}\n\t\toverrides.Containers = append(overrides.Containers, overlay)\n\t\tnewMergedPod, err := applyContainer(finalPod, overlay)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to apply sidecar container: %v\", err)\n\t\t}\n\t\tfinalPod = newMergedPod\n\t}\n\tfor _, c := range templatePod.Spec.InitContainers {\n\t\tmatch := FindContainer(c.Name, existingOverrides.InitContainers)\n\t\tif match == nil {\n\t\t\tmatch = FindContainer(c.Name, originalPod.Spec.InitContainers)\n\t\t}\n\t\tif match == nil {\n\t\t\tcontinue\n\t\t}\n\t\toverlay := *match.DeepCopy()\n\t\tif overlay.Image == AutoImage {\n\t\t\toverlay.Image = \"\"\n\t\t}\n\t\toverrides.InitContainers = append(overrides.InitContainers, overlay)\n\t\tnewMergedPod, err := applyInitContainer(finalPod, overlay)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to apply sidecar init container: %v\", err)\n\t\t}\n\t\tfinalPod = newMergedPod\n\t}\n\n\t_, alreadyInjected := originalPod.Annotations[annotation.SidecarStatus.Name]\n\tif !alreadyInjected && (len(overrides.Containers) > 0 || len(overrides.InitContainers) > 0) {\n\t\t// We found any overrides. Put them in the pod annotation so we can re-apply them on re-injection\n\t\tjs, err := json.Marshal(overrides)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif finalPod.Annotations == nil {\n\t\t\tfinalPod.Annotations = map[string]string{}\n\t\t}\n\t\tfinalPod.Annotations[annotation.ProxyOverrides.Name] = string(js)\n\t}\n\n\treturn finalPod, nil\n}\n\n// reinsertOverrides applies the containers listed in OverrideAnnotation to a pod. This is to achieve\n// idempotency by handling an edge case where an injection template is modifying a container already\n// present in the pod spec. In these cases, the logic to strip injected containers would remove the\n// original injected parts as well, leading to the templating logic being different (for example,\n// reading the .Spec.Containers field would be empty).\nfunc reinsertOverrides(pod *corev1.Pod) (*corev1.Pod, error) {\n\ttype podOverrides struct {\n\t\tContainers     []corev1.Container `json:\"containers,omitempty\"`\n\t\tInitContainers []corev1.Container `json:\"initContainers,omitempty\"`\n\t}\n\n\texistingOverrides := podOverrides{}\n\tif annotationOverrides, f := pod.Annotations[annotation.ProxyOverrides.Name]; f {\n\t\tif err := json.Unmarshal([]byte(annotationOverrides), &existingOverrides); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tpod = pod.DeepCopy()\n\tfor _, c := range existingOverrides.Containers {\n\t\tmatch := FindContainer(c.Name, pod.Spec.Containers)\n\t\tif match != nil {\n\t\t\tcontinue\n\t\t}\n\t\tpod.Spec.Containers = append(pod.Spec.Containers, c)\n\t}\n\n\tfor _, c := range existingOverrides.InitContainers {\n\t\tmatch := FindContainer(c.Name, pod.Spec.InitContainers)\n\t\tif match != nil {\n\t\t\tcontinue\n\t\t}\n\t\tpod.Spec.InitContainers = append(pod.Spec.InitContainers, c)\n\t}\n\n\treturn pod, nil\n}\n\nfunc createPatch(pod *corev1.Pod, original []byte) ([]byte, error) {\n\treinjected, err := json.Marshal(pod)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tp, err := jsonpatch.CreatePatch(original, reinjected)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn json.Marshal(p)\n}\n\n// postProcessPod applies additionally transformations to the pod after merging with the injected template\n// This is generally things that cannot reasonably be added to the template\nfunc postProcessPod(pod *corev1.Pod, injectedPod corev1.Pod, req InjectionParameters) error {\n\tif pod.Annotations == nil {\n\t\tpod.Annotations = map[string]string{}\n\t}\n\tif pod.Labels == nil {\n\t\tpod.Labels = map[string]string{}\n\t}\n\n\toverwriteClusterInfo(pod.Spec.Containers, req)\n\n\tif err := applyPrometheusMerge(pod, req.meshConfig); err != nil {\n\t\treturn err\n\t}\n\n\tif err := applyRewrite(pod, req); err != nil {\n\t\treturn err\n\t}\n\n\tapplyMetadata(pod, injectedPod, req)\n\n\tif err := reorderPod(pod, req); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc applyMetadata(pod *corev1.Pod, injectedPodData corev1.Pod, req InjectionParameters) {\n\tif nw, ok := req.proxyEnvs[\"ISTIO_META_NETWORK\"]; ok {\n\t\tpod.Labels[label.TopologyNetwork.Name] = nw\n\t}\n\t// Add all additional injected annotations. These are overridden if needed\n\tpod.Annotations[annotation.SidecarStatus.Name] = getInjectionStatus(injectedPodData.Spec, req.revision)\n\n\t// Deprecated; should be set directly in the template instead\n\tfor k, v := range req.injectedAnnotations {\n\t\tpod.Annotations[k] = v\n\t}\n}\n\n// reorderPod ensures containers are properly ordered after merging\nfunc reorderPod(pod *corev1.Pod, req InjectionParameters) error {\n\tvar merr error\n\tmc := req.meshConfig\n\t// Get copy of pod proxyconfig, to determine container ordering\n\tif pca, f := req.pod.ObjectMeta.GetAnnotations()[annotation.ProxyConfig.Name]; f {\n\t\tmc, merr = mesh.ApplyProxyConfig(pca, *req.meshConfig)\n\t\tif merr != nil {\n\t\t\treturn merr\n\t\t}\n\t}\n\n\tvaluesStruct := &opconfig.Values{}\n\tif err := gogoprotomarshal.ApplyYAML(req.valuesConfig, valuesStruct); err != nil {\n\t\treturn fmt.Errorf(\"could not parse configuration values: %v\", err)\n\t}\n\t// nolint: staticcheck\n\tholdPod := mc.GetDefaultConfig().GetHoldApplicationUntilProxyStarts().GetValue() ||\n\t\tvaluesStruct.GetGlobal().GetProxy().GetHoldApplicationUntilProxyStarts().GetValue()\n\n\tproxyLocation := MoveLast\n\t// If HoldApplicationUntilProxyStarts is set, reorder the proxy location\n\tif holdPod {\n\t\tproxyLocation = MoveFirst\n\t}\n\n\t// Proxy container should be last, unless HoldApplicationUntilProxyStarts is set\n\t// This is to ensure `kubectl exec` and similar commands continue to default to the user's container\n\tpod.Spec.Containers = modifyContainers(pod.Spec.Containers, ProxyContainerName, proxyLocation)\n\t// Validation container must be first to block any user containers\n\tpod.Spec.InitContainers = modifyContainers(pod.Spec.InitContainers, ValidationContainerName, MoveFirst)\n\t// Init container must be last to allow any traffic to pass before iptables is setup\n\tpod.Spec.InitContainers = modifyContainers(pod.Spec.InitContainers, InitContainerName, MoveLast)\n\tpod.Spec.InitContainers = modifyContainers(pod.Spec.InitContainers, EnableCoreDumpName, MoveLast)\n\n\treturn nil\n}\n\nfunc applyRewrite(pod *corev1.Pod, req InjectionParameters) error {\n\tsidecar := FindSidecar(pod.Spec.Containers)\n\tif sidecar == nil {\n\t\treturn nil\n\t}\n\tvaluesStruct := &opconfig.Values{}\n\tif err := gogoprotomarshal.ApplyYAML(req.valuesConfig, valuesStruct); err != nil {\n\t\tlog.Infof(\"Failed to parse values config: %v [%v]\\n\", err, req.valuesConfig)\n\t\treturn fmt.Errorf(\"could not parse configuration values: %v\", err)\n\t}\n\n\trewrite := ShouldRewriteAppHTTPProbers(pod.Annotations, valuesStruct.GetSidecarInjectorWebhook().GetRewriteAppHTTPProbe())\n\t// We don't have to escape json encoding here when using golang libraries.\n\tif rewrite {\n\t\tif prober := DumpAppProbers(&pod.Spec, req.meshConfig.GetDefaultConfig().GetStatusPort()); prober != \"\" {\n\t\t\tsidecar.Env = append(sidecar.Env, corev1.EnvVar{Name: status.KubeAppProberEnvName, Value: prober})\n\t\t}\n\t\tpatchRewriteProbe(pod.Annotations, pod, req.meshConfig.GetDefaultConfig().GetStatusPort())\n\t}\n\treturn nil\n}\n\nvar emptyScrape = status.PrometheusScrapeConfiguration{}\n\n// applyPrometheusMerge configures prometheus scraping annotations for the \"metrics merge\" feature.\n// This moves the current prometheus.io annotations into an environment variable and replaces them\n// pointing to the agent.\nfunc applyPrometheusMerge(pod *corev1.Pod, mesh *meshconfig.MeshConfig) error {\n\tif getPrometheusScrape(pod) &&\n\t\tenablePrometheusMerge(mesh, pod.ObjectMeta.Annotations) {\n\t\ttargetPort := strconv.Itoa(int(mesh.GetDefaultConfig().GetStatusPort()))\n\t\tif cur, f := getPrometheusPort(pod); f {\n\t\t\t// We have already set the port, assume user is controlling this or, more likely, re-injected\n\t\t\t// the pod.\n\t\t\tif cur == targetPort {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tscrape := getPrometheusScrapeConfiguration(pod)\n\t\tsidecar := FindSidecar(pod.Spec.Containers)\n\t\tif sidecar != nil && scrape != emptyScrape {\n\t\t\tby, err := json.Marshal(scrape)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tsidecar.Env = append(sidecar.Env, corev1.EnvVar{Name: status.PrometheusScrapingConfig.Name, Value: string(by)})\n\t\t}\n\t\tif pod.Annotations == nil {\n\t\t\tpod.Annotations = map[string]string{}\n\t\t}\n\t\t// if a user sets `prometheus/io/path: foo`, then we add `prometheus.io/path: /stats/prometheus`\n\t\t// prometheus will pick a random one\n\t\t// need to clear out all variants and then set ours\n\t\tclearPrometheusAnnotations(pod)\n\t\tpod.Annotations[\"prometheus.io/port\"] = targetPort\n\t\tpod.Annotations[\"prometheus.io/path\"] = \"/stats/prometheus\"\n\t\tpod.Annotations[\"prometheus.io/scrape\"] = \"true\"\n\t\treturn nil\n\t}\n\n\treturn nil\n}\n\n// getPrometheusScrape respect prometheus scrape config\n// not to doing prometheusMerge if this return false\nfunc getPrometheusScrape(pod *corev1.Pod) bool {\n\tfor k, val := range pod.Annotations {\n\t\tif strutil.SanitizeLabelName(k) != prometheusScrapeAnnotation {\n\t\t\tcontinue\n\t\t}\n\n\t\tif scrape, err := strconv.ParseBool(val); err == nil {\n\t\t\treturn scrape\n\t\t}\n\t}\n\n\treturn true\n}\n\nvar prometheusAnnotations = sets.NewString(\n\tprometheusPathAnnotation,\n\tprometheusPortAnnotation,\n\tprometheusScrapeAnnotation,\n)\n\nfunc clearPrometheusAnnotations(pod *corev1.Pod) {\n\tneedRemovedKeys := make([]string, 0, 2)\n\tfor k := range pod.Annotations {\n\t\tanno := strutil.SanitizeLabelName(k)\n\t\tif prometheusAnnotations.Has(anno) {\n\t\t\tneedRemovedKeys = append(needRemovedKeys, k)\n\t\t}\n\t}\n\n\tfor _, k := range needRemovedKeys {\n\t\tdelete(pod.Annotations, k)\n\t}\n}\n\nfunc getPrometheusScrapeConfiguration(pod *corev1.Pod) status.PrometheusScrapeConfiguration {\n\tcfg := status.PrometheusScrapeConfiguration{}\n\n\tfor k, val := range pod.Annotations {\n\t\tanno := strutil.SanitizeLabelName(k)\n\t\tswitch anno {\n\t\tcase prometheusPortAnnotation:\n\t\t\tcfg.Port = val\n\t\tcase prometheusScrapeAnnotation:\n\t\t\tcfg.Scrape = val\n\t\tcase prometheusPathAnnotation:\n\t\t\tcfg.Path = val\n\t\t}\n\t}\n\n\treturn cfg\n}\n\nfunc getPrometheusPort(pod *corev1.Pod) (string, bool) {\n\tfor k, val := range pod.Annotations {\n\t\tif strutil.SanitizeLabelName(k) != prometheusPortAnnotation {\n\t\t\tcontinue\n\t\t}\n\n\t\treturn val, true\n\t}\n\n\treturn \"\", false\n}\n\nconst (\n\t// AutoImage is the special image name to indicate to the injector that we should use the injected image, and NOT override it\n\t// This is necessary because image is a required field on container, so if a user defines an istio-proxy container\n\t// with customizations they must set an image.\n\tAutoImage = \"auto\"\n)\n\n// applyContainer merges a container spec on top of the provided pod\nfunc applyContainer(target *corev1.Pod, container corev1.Container) (*corev1.Pod, error) {\n\toverlay := &corev1.Pod{Spec: corev1.PodSpec{Containers: []corev1.Container{container}}}\n\n\toverlayJSON, err := json.Marshal(overlay)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn applyOverlay(target, overlayJSON)\n}\n\n// applyInitContainer merges a container spec on top of the provided pod as an init container\nfunc applyInitContainer(target *corev1.Pod, container corev1.Container) (*corev1.Pod, error) {\n\toverlay := &corev1.Pod{Spec: corev1.PodSpec{\n\t\t// We need to set containers to empty, otherwise it will marshal as \"null\" and delete all containers\n\t\tContainers:     []corev1.Container{},\n\t\tInitContainers: []corev1.Container{container},\n\t}}\n\n\toverlayJSON, err := json.Marshal(overlay)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn applyOverlay(target, overlayJSON)\n}\n\n// applyContainer merges a pod spec, provided as JSON, on top of the provided pod\nfunc applyOverlay(target *corev1.Pod, overlayJSON []byte) (*corev1.Pod, error) {\n\tcurrentJSON, err := json.Marshal(target)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tpod := corev1.Pod{}\n\t// Overlay the injected template onto the original podSpec\n\tpatched, err := strategicpatch.StrategicMergePatch(currentJSON, overlayJSON, pod)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"strategic merge: %v\", err)\n\t}\n\n\tif err := json.Unmarshal(patched, &pod); err != nil {\n\t\treturn nil, fmt.Errorf(\"unmarshal patched pod: %v\", err)\n\t}\n\treturn &pod, nil\n}\n\nfunc (wh *Webhook) inject(ar *kube.AdmissionReview, path string) *kube.AdmissionResponse {\n\treq := ar.Request\n\tvar pod corev1.Pod\n\tif err := json.Unmarshal(req.Object.Raw, &pod); err != nil {\n\t\thandleError(fmt.Sprintf(\"Could not unmarshal raw object: %v %s\", err,\n\t\t\tstring(req.Object.Raw)))\n\t\treturn toAdmissionResponse(err)\n\t}\n\t// Managed fields is sometimes extremely large, leading to excessive CPU time on patch generation\n\t// It does not impact the injection output at all, so we can just remove it.\n\tpod.ManagedFields = nil\n\n\t// Deal with potential empty fields, e.g., when the pod is created by a deployment\n\tpodName := potentialPodName(pod.ObjectMeta)\n\tif pod.ObjectMeta.Namespace == \"\" {\n\t\tpod.ObjectMeta.Namespace = req.Namespace\n\t}\n\tlog.Infof(\"Sidecar injection request for %v/%v\", req.Namespace, podName)\n\tlog.Debugf(\"Object: %v\", string(req.Object.Raw))\n\tlog.Debugf(\"OldObject: %v\", string(req.OldObject.Raw))\n\n\twh.mu.RLock()\n\tif !injectRequired(IgnoredNamespaces.UnsortedList(), wh.Config, &pod.Spec, pod.ObjectMeta) {\n\t\tlog.Infof(\"Skipping %s/%s due to policy check\", pod.ObjectMeta.Namespace, podName)\n\t\ttotalSkippedInjections.Increment()\n\t\twh.mu.RUnlock()\n\t\treturn &kube.AdmissionResponse{\n\t\t\tAllowed: true,\n\t\t}\n\t}\n\n\tproxyConfig := mesh.DefaultProxyConfig()\n\tif wh.env.PushContext != nil && wh.env.PushContext.ProxyConfigs != nil {\n\t\tif generatedProxyConfig := wh.env.PushContext.ProxyConfigs.EffectiveProxyConfig(\n\t\t\t&model.NodeMetadata{\n\t\t\t\tNamespace:   pod.Namespace,\n\t\t\t\tLabels:      pod.Labels,\n\t\t\t\tAnnotations: pod.Annotations,\n\t\t\t}, wh.meshConfig); generatedProxyConfig != nil {\n\t\t\tproxyConfig = *generatedProxyConfig\n\t\t}\n\t}\n\tdeploy, typeMeta := kube.GetDeployMetaFromPod(&pod)\n\tparams := InjectionParameters{\n\t\tpod:                 &pod,\n\t\tdeployMeta:          deploy,\n\t\ttypeMeta:            typeMeta,\n\t\ttemplates:           wh.Config.Templates,\n\t\tdefaultTemplate:     wh.Config.DefaultTemplates,\n\t\taliases:             wh.Config.Aliases,\n\t\tmeshConfig:          wh.meshConfig,\n\t\tproxyConfig:         &proxyConfig,\n\t\tvaluesConfig:        wh.valuesConfig,\n\t\trevision:            wh.revision,\n\t\tinjectedAnnotations: wh.Config.InjectedAnnotations,\n\t\tproxyEnvs:           parseInjectEnvs(path),\n\t}\n\twh.mu.RUnlock()\n\n\tpatchBytes, err := injectPod(params)\n\tif err != nil {\n\t\thandleError(fmt.Sprintf(\"Pod injection failed: %v\", err))\n\t\treturn toAdmissionResponse(err)\n\t}\n\n\treviewResponse := kube.AdmissionResponse{\n\t\tAllowed: true,\n\t\tPatch:   patchBytes,\n\t\tPatchType: func() *string {\n\t\t\tpt := \"JSONPatch\"\n\t\t\treturn &pt\n\t\t}(),\n\t}\n\ttotalSuccessfulInjections.Increment()\n\treturn &reviewResponse\n}\n\nfunc (wh *Webhook) serveInject(w http.ResponseWriter, r *http.Request) {\n\ttotalInjections.Increment()\n\tvar body []byte\n\tif r.Body != nil {\n\t\tif data, err := io.ReadAll(r.Body); err == nil {\n\t\t\tbody = data\n\t\t}\n\t}\n\tif len(body) == 0 {\n\t\thandleError(\"no body found\")\n\t\thttp.Error(w, \"no body found\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// verify the content type is accurate\n\tcontentType := r.Header.Get(\"Content-Type\")\n\tif contentType != \"application/json\" {\n\t\thandleError(fmt.Sprintf(\"contentType=%s, expect application/json\", contentType))\n\t\thttp.Error(w, \"invalid Content-Type, want `application/json`\", http.StatusUnsupportedMediaType)\n\t\treturn\n\t}\n\n\tpath := \"\"\n\tif r.URL != nil {\n\t\tpath = r.URL.Path\n\t}\n\n\tvar reviewResponse *kube.AdmissionResponse\n\tvar obj runtime.Object\n\tvar ar *kube.AdmissionReview\n\tif out, _, err := deserializer.Decode(body, nil, obj); err != nil {\n\t\thandleError(fmt.Sprintf(\"Could not decode body: %v\", err))\n\t\treviewResponse = toAdmissionResponse(err)\n\t} else {\n\t\tlog.Debugf(\"AdmissionRequest for path=%s\\n\", path)\n\t\tar, err = kube.AdmissionReviewKubeToAdapter(out)\n\t\tif err != nil {\n\t\t\thandleError(fmt.Sprintf(\"Could not decode object: %v\", err))\n\t\t}\n\t\treviewResponse = wh.inject(ar, path)\n\t}\n\n\tresponse := kube.AdmissionReview{}\n\tresponse.Response = reviewResponse\n\tvar responseKube runtime.Object\n\tvar apiVersion string\n\tif ar != nil {\n\t\tapiVersion = ar.APIVersion\n\t\tresponse.TypeMeta = ar.TypeMeta\n\t\tif response.Response != nil {\n\t\t\tif ar.Request != nil {\n\t\t\t\tresponse.Response.UID = ar.Request.UID\n\t\t\t}\n\t\t}\n\t}\n\tresponseKube = kube.AdmissionReviewAdapterToKube(&response, apiVersion)\n\tresp, err := json.Marshal(responseKube)\n\tif err != nil {\n\t\tlog.Errorf(\"Could not encode response: %v\", err)\n\t\thttp.Error(w, fmt.Sprintf(\"could not encode response: %v\", err), http.StatusInternalServerError)\n\t}\n\tif _, err := w.Write(resp); err != nil {\n\t\tlog.Errorf(\"Could not write response: %v\", err)\n\t\thttp.Error(w, fmt.Sprintf(\"could not write response: %v\", err), http.StatusInternalServerError)\n\t}\n}\n\n// parseInjectEnvs parse new envs from inject url path\n// follow format: /inject/k1/v1/k2/v2 when values do not contain slashes,\n// follow format: /inject/:ENV:net=network1:ENV:cluster=cluster1:ENV:rootpage=/foo/bar\n// when values contain slashes.\nfunc parseInjectEnvs(path string) map[string]string {\n\tpath = strings.TrimSuffix(path, \"/\")\n\tres := func(path string) []string {\n\t\tparts := strings.SplitN(path, \"/\", 3)\n\t\t// The 3rd part has to start with separator :ENV:\n\t\t// If not, this inject path is considered using slash as separator\n\t\t// If length is less than 3, then the path is simply \"/inject\",\n\t\t// process just like before :ENV: separator is introduced.\n\t\tvar newRes []string\n\t\tif len(parts) == 3 {\n\t\t\tif strings.HasPrefix(parts[2], \":ENV:\") {\n\t\t\t\tpairs := strings.Split(parts[2], \":ENV:\")\n\t\t\t\tfor i := 1; i < len(pairs); i++ { // skip the first part, it is a nil\n\t\t\t\t\tpair := strings.SplitN(pairs[i], \"=\", 2)\n\t\t\t\t\t// The first part is the variable name which can not be empty\n\t\t\t\t\t// the second part is the variable value which can be empty but has to exist\n\t\t\t\t\t// for example, aaa=bbb, aaa= are valid, but =aaa or = are not valid, the\n\t\t\t\t\t// invalid ones will be ignored.\n\t\t\t\t\tif len(pair[0]) > 0 && len(pair) == 2 {\n\t\t\t\t\t\tnewRes = append(newRes, pair...)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn newRes\n\t\t\t}\n\t\t\treturn strings.Split(parts[2], \"/\")\n\t\t}\n\t\treturn newRes\n\t}(path)\n\tnewEnvs := make(map[string]string)\n\n\tfor i := 0; i < len(res); i += 2 {\n\t\tk := res[i]\n\t\tif i == len(res)-1 { // ignore the last key without value\n\t\t\tlog.Warnf(\"Odd number of inject env entries, ignore the last key %s\\n\", k)\n\t\t\tbreak\n\t\t}\n\n\t\tenv, found := URLParameterToEnv[k]\n\t\tif !found {\n\t\t\tenv = strings.ToUpper(k) // if not found, use the custom env directly\n\t\t}\n\t\tif env != \"\" {\n\t\t\tnewEnvs[env] = res[i+1]\n\t\t}\n\t}\n\n\treturn newEnvs\n}\n\nfunc handleError(message string) {\n\tlog.Errorf(message)\n\ttotalFailedInjections.Increment()\n}\n", "// Copyright Istio Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage kube\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"strings\"\n\n\tkubeApiCore \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/runtime\"\n\t\"k8s.io/apimachinery/pkg/runtime/serializer\"\n\t\"k8s.io/client-go/kubernetes\"\n\n\t//  allow out of cluster authentication\n\t_ \"k8s.io/client-go/plugin/pkg/client/auth\"\n\t\"k8s.io/client-go/rest\"\n\t\"k8s.io/client-go/tools/clientcmd\"\n\n\tistioversion \"istio.io/pkg/version\"\n)\n\nvar cronJobNameRegexp = regexp.MustCompile(`(.+)-\\d{8,10}$`)\n\n// BuildClientConfig builds a client rest config from a kubeconfig filepath and context.\n// It overrides the current context with the one provided (empty to use default).\n//\n// This is a modified version of k8s.io/client-go/tools/clientcmd/BuildConfigFromFlags with the\n// difference that it loads default configs if not running in-cluster.\nfunc BuildClientConfig(kubeconfig, context string) (*rest.Config, error) {\n\tc, err := BuildClientCmd(kubeconfig, context).ClientConfig()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn SetRestDefaults(c), nil\n}\n\n// BuildClientCmd builds a client cmd config from a kubeconfig filepath and context.\n// It overrides the current context with the one provided (empty to use default).\n//\n// This is a modified version of k8s.io/client-go/tools/clientcmd/BuildConfigFromFlags with the\n// difference that it loads default configs if not running in-cluster.\nfunc BuildClientCmd(kubeconfig, context string, overrides ...func(*clientcmd.ConfigOverrides)) clientcmd.ClientConfig {\n\tif kubeconfig != \"\" {\n\t\tinfo, err := os.Stat(kubeconfig)\n\t\tif err != nil || info.Size() == 0 {\n\t\t\t// If the specified kubeconfig doesn't exists / empty file / any other error\n\t\t\t// from file stat, fall back to default\n\t\t\tkubeconfig = \"\"\n\t\t}\n\t}\n\n\t// Config loading rules:\n\t// 1. kubeconfig if it not empty string\n\t// 2. Config(s) in KUBECONFIG environment variable\n\t// 3. In cluster config if running in-cluster\n\t// 4. Use $HOME/.kube/config\n\tloadingRules := clientcmd.NewDefaultClientConfigLoadingRules()\n\tloadingRules.DefaultClientConfig = &clientcmd.DefaultClientConfig\n\tloadingRules.ExplicitPath = kubeconfig\n\tconfigOverrides := &clientcmd.ConfigOverrides{\n\t\tClusterDefaults: clientcmd.ClusterDefaults,\n\t\tCurrentContext:  context,\n\t}\n\n\tfor _, fn := range overrides {\n\t\tfn(configOverrides)\n\t}\n\n\treturn clientcmd.NewNonInteractiveDeferredLoadingClientConfig(loadingRules, configOverrides)\n}\n\n// CreateClientset is a helper function that builds a kubernetes Clienset from a kubeconfig\n// filepath. See `BuildClientConfig` for kubeconfig loading rules.\nfunc CreateClientset(kubeconfig, context string, fns ...func(*rest.Config)) (*kubernetes.Clientset, error) {\n\tc, err := BuildClientConfig(kubeconfig, context)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"build client config: %v\", err)\n\t}\n\tfor _, fn := range fns {\n\t\tfn(c)\n\t}\n\treturn kubernetes.NewForConfig(c)\n}\n\n// DefaultRestConfig returns the rest.Config for the given kube config file and context.\nfunc DefaultRestConfig(kubeconfig, configContext string, fns ...func(*rest.Config)) (*rest.Config, error) {\n\tconfig, err := BuildClientConfig(kubeconfig, configContext)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tconfig = SetRestDefaults(config)\n\n\tfor _, fn := range fns {\n\t\tfn(config)\n\t}\n\n\treturn config, nil\n}\n\n// adjustCommand returns the last component of the\n// OS-specific command path for use in User-Agent.\nfunc adjustCommand(p string) string {\n\t// Unlikely, but better than returning \"\".\n\tif len(p) == 0 {\n\t\treturn \"unknown\"\n\t}\n\treturn filepath.Base(p)\n}\n\n// IstioUserAgent returns the user agent string based on the command being used.\n// example: pilot-discovery/1.9.5 or istioctl/1.10.0\n// This is a specialized version of rest.DefaultKubernetesUserAgent()\nfunc IstioUserAgent() string {\n\treturn adjustCommand(os.Args[0]) + \"/\" + istioversion.Info.Version\n}\n\n// SetRestDefaults is a helper function that sets default values for the given rest.Config.\n// This function is idempotent.\nfunc SetRestDefaults(config *rest.Config) *rest.Config {\n\tif config.GroupVersion == nil || config.GroupVersion.Empty() {\n\t\tconfig.GroupVersion = &kubeApiCore.SchemeGroupVersion\n\t}\n\tif len(config.APIPath) == 0 {\n\t\tif len(config.GroupVersion.Group) == 0 {\n\t\t\tconfig.APIPath = \"/api\"\n\t\t} else {\n\t\t\tconfig.APIPath = \"/apis\"\n\t\t}\n\t}\n\tif len(config.ContentType) == 0 {\n\t\tconfig.ContentType = runtime.ContentTypeJSON\n\t}\n\tif config.NegotiatedSerializer == nil {\n\t\t// This codec factory ensures the resources are not converted. Therefore, resources\n\t\t// will not be round-tripped through internal versions. Defaulting does not happen\n\t\t// on the client.\n\t\tconfig.NegotiatedSerializer = serializer.NewCodecFactory(IstioScheme).WithoutConversion()\n\t}\n\tif len(config.UserAgent) == 0 {\n\t\tconfig.UserAgent = IstioUserAgent()\n\t}\n\n\treturn config\n}\n\n// CheckPodReadyOrComplete returns nil if the given pod and all of its containers are ready or terminated\n// successfully.\nfunc CheckPodReadyOrComplete(pod *kubeApiCore.Pod) error {\n\tswitch pod.Status.Phase {\n\tcase kubeApiCore.PodSucceeded:\n\t\treturn nil\n\tcase kubeApiCore.PodRunning:\n\t\treturn CheckPodReady(pod)\n\tdefault:\n\t\treturn fmt.Errorf(\"%s\", pod.Status.Phase)\n\t}\n}\n\n// CheckPodReady returns nil if the given pod and all of its containers are ready.\nfunc CheckPodReady(pod *kubeApiCore.Pod) error {\n\tswitch pod.Status.Phase {\n\tcase kubeApiCore.PodRunning:\n\t\t// Wait until all containers are ready.\n\t\tfor _, containerStatus := range pod.Status.ContainerStatuses {\n\t\t\tif !containerStatus.Ready {\n\t\t\t\treturn fmt.Errorf(\"container not ready: '%s'\", containerStatus.Name)\n\t\t\t}\n\t\t}\n\t\tif len(pod.Status.Conditions) > 0 {\n\t\t\tfor _, condition := range pod.Status.Conditions {\n\t\t\t\tif condition.Type == kubeApiCore.PodReady && condition.Status != kubeApiCore.ConditionTrue {\n\t\t\t\t\treturn fmt.Errorf(\"pod not ready, condition message: %v\", condition.Message)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\tdefault:\n\t\treturn fmt.Errorf(\"%s\", pod.Status.Phase)\n\t}\n}\n\n// GetDeployMetaFromPod heuristically derives deployment metadata from the pod spec.\nfunc GetDeployMetaFromPod(pod *kubeApiCore.Pod) (metav1.ObjectMeta, metav1.TypeMeta) {\n\tif pod == nil {\n\t\treturn metav1.ObjectMeta{}, metav1.TypeMeta{}\n\t}\n\t// try to capture more useful namespace/name info for deployments, etc.\n\t// TODO(dougreid): expand to enable lookup of OWNERs recursively a la kubernetesenv\n\tdeployMeta := pod.ObjectMeta\n\tdeployMeta.ManagedFields = nil\n\tdeployMeta.OwnerReferences = nil\n\n\ttypeMetadata := metav1.TypeMeta{\n\t\tKind:       \"Pod\",\n\t\tAPIVersion: \"v1\",\n\t}\n\tif len(pod.GenerateName) > 0 {\n\t\t// if the pod name was generated (or is scheduled for generation), we can begin an investigation into the controlling reference for the pod.\n\t\tvar controllerRef metav1.OwnerReference\n\t\tcontrollerFound := false\n\t\tfor _, ref := range pod.GetOwnerReferences() {\n\t\t\tif ref.Controller != nil && *ref.Controller {\n\t\t\t\tcontrollerRef = ref\n\t\t\t\tcontrollerFound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif controllerFound {\n\t\t\ttypeMetadata.APIVersion = controllerRef.APIVersion\n\t\t\ttypeMetadata.Kind = controllerRef.Kind\n\n\t\t\t// heuristic for deployment detection\n\t\t\tdeployMeta.Name = controllerRef.Name\n\t\t\tif typeMetadata.Kind == \"ReplicaSet\" && pod.Labels[\"pod-template-hash\"] != \"\" && strings.HasSuffix(controllerRef.Name, pod.Labels[\"pod-template-hash\"]) {\n\t\t\t\tname := strings.TrimSuffix(controllerRef.Name, \"-\"+pod.Labels[\"pod-template-hash\"])\n\t\t\t\tdeployMeta.Name = name\n\t\t\t\ttypeMetadata.Kind = \"Deployment\"\n\t\t\t} else if typeMetadata.Kind == \"ReplicationController\" && pod.Labels[\"deploymentconfig\"] != \"\" {\n\t\t\t\t// If the pod is controlled by the replication controller, which is created by the DeploymentConfig resource in\n\t\t\t\t// Openshift platform, set the deploy name to the deployment config's name, and the kind to 'DeploymentConfig'.\n\t\t\t\t//\n\t\t\t\t// nolint: lll\n\t\t\t\t// For DeploymentConfig details, refer to\n\t\t\t\t// https://docs.openshift.com/container-platform/4.1/applications/deployments/what-deployments-are.html#deployments-and-deploymentconfigs_what-deployments-are\n\t\t\t\t//\n\t\t\t\t// For the reference to the pod label 'deploymentconfig', refer to\n\t\t\t\t// https://github.com/openshift/library-go/blob/7a65fdb398e28782ee1650959a5e0419121e97ae/pkg/apps/appsutil/const.go#L25\n\t\t\t\tdeployMeta.Name = pod.Labels[\"deploymentconfig\"]\n\t\t\t\ttypeMetadata.Kind = \"DeploymentConfig\"\n\t\t\t\tdelete(deployMeta.Labels, \"deploymentconfig\")\n\t\t\t} else if typeMetadata.Kind == \"Job\" {\n\t\t\t\t// If job name suffixed with `-<digit-timestamp>`, where the length of digit timestamp is 8~10,\n\t\t\t\t// trim the suffix and set kind to cron job.\n\t\t\t\tif jn := cronJobNameRegexp.FindStringSubmatch(controllerRef.Name); len(jn) == 2 {\n\t\t\t\t\tdeployMeta.Name = jn[1]\n\t\t\t\t\ttypeMetadata.Kind = \"CronJob\"\n\t\t\t\t\t// heuristically set cron job api version to v1beta1 as it cannot be derived from pod metadata.\n\t\t\t\t\t// Cronjob is not GA yet and latest version is v1beta1: https://github.com/kubernetes/enhancements/pull/978\n\t\t\t\t\ttypeMetadata.APIVersion = \"batch/v1beta1\"\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif deployMeta.Name == \"\" {\n\t\t// if we haven't been able to extract a deployment name, then just give it the pod name\n\t\tdeployMeta.Name = pod.Name\n\t}\n\n\treturn deployMeta, typeMetadata\n}\n", "// Copyright Istio Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage server\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\n\tmultierror \"github.com/hashicorp/go-multierror\"\n\tkubeApiAdmissionv1 \"k8s.io/api/admission/v1\"\n\tkubeApiAdmissionv1beta1 \"k8s.io/api/admission/v1beta1\"\n\tkubeApiApps \"k8s.io/api/apps/v1beta1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/runtime\"\n\t\"k8s.io/apimachinery/pkg/runtime/serializer\"\n\n\t\"istio.io/istio/pilot/pkg/config/kube/crd\"\n\t\"istio.io/istio/pkg/config/schema/collection\"\n\t\"istio.io/istio/pkg/config/schema/collections\"\n\t\"istio.io/istio/pkg/config/schema/resource\"\n\t\"istio.io/istio/pkg/config/validation\"\n\t\"istio.io/istio/pkg/kube\"\n\t\"istio.io/pkg/log\"\n)\n\nvar scope = log.RegisterScope(\"validationServer\", \"validation webhook server\", 0)\n\nvar (\n\truntimeScheme = runtime.NewScheme()\n\tcodecs        = serializer.NewCodecFactory(runtimeScheme)\n\tdeserializer  = codecs.UniversalDeserializer()\n\n\t// Expect AdmissionRequest to only include these top-level field names\n\tvalidFields = map[string]bool{\n\t\t\"apiVersion\": true,\n\t\t\"kind\":       true,\n\t\t\"metadata\":   true,\n\t\t\"spec\":       true,\n\t\t\"status\":     true,\n\t}\n)\n\nfunc init() {\n\t_ = kubeApiApps.AddToScheme(runtimeScheme)\n\t_ = kubeApiAdmissionv1.AddToScheme(runtimeScheme)\n\t_ = kubeApiAdmissionv1beta1.AddToScheme(runtimeScheme)\n}\n\n// Options contains the configuration for the Istio Pilot validation\n// admission controller.\ntype Options struct {\n\t// Schemas provides a description of all configuration resources.\n\tSchemas collection.Schemas\n\n\t// DomainSuffix is the DNS domain suffix for Pilot CRD resources,\n\t// e.g. cluster.local.\n\tDomainSuffix string\n\n\t// Port where the webhook is served. the number should be greater than 1024 for non-root\n\t// user, because non-root user cannot bind port number less than 1024\n\t// Mainly used for testing. Webhook server is started by Istiod.\n\tPort uint\n\n\t// Use an existing mux instead of creating our own.\n\tMux *http.ServeMux\n}\n\n// String produces a stringified version of the arguments for debugging.\nfunc (o Options) String() string {\n\tbuf := &bytes.Buffer{}\n\n\t_, _ = fmt.Fprintf(buf, \"DomainSuffix: %s\\n\", o.DomainSuffix)\n\t_, _ = fmt.Fprintf(buf, \"Port: %d\\n\", o.Port)\n\n\treturn buf.String()\n}\n\n// DefaultArgs allocates an Options struct initialized with Webhook's default configuration.\nfunc DefaultArgs() Options {\n\treturn Options{\n\t\tPort: 9443,\n\t}\n}\n\n// Webhook implements the validating admission webhook for validating Istio configuration.\ntype Webhook struct {\n\t// pilot\n\tschemas      collection.Schemas\n\tdomainSuffix string\n}\n\n// New creates a new instance of the admission webhook server.\nfunc New(o Options) (*Webhook, error) {\n\tif o.Mux == nil {\n\t\tscope.Error(\"mux not set correctly\")\n\t\treturn nil, errors.New(\"expected mux to be passed, but was not passed\")\n\t}\n\twh := &Webhook{\n\t\tschemas:      o.Schemas,\n\t\tdomainSuffix: o.DomainSuffix,\n\t}\n\n\to.Mux.HandleFunc(\"/validate\", wh.serveValidate)\n\to.Mux.HandleFunc(\"/validate/\", wh.serveValidate)\n\n\treturn wh, nil\n}\n\nfunc toAdmissionResponse(err error) *kube.AdmissionResponse {\n\treturn &kube.AdmissionResponse{Result: &metav1.Status{Message: err.Error()}}\n}\n\ntype admitFunc func(*kube.AdmissionRequest) *kube.AdmissionResponse\n\nfunc serve(w http.ResponseWriter, r *http.Request, admit admitFunc) {\n\tvar body []byte\n\tif r.Body != nil {\n\t\tif data, err := io.ReadAll(r.Body); err == nil {\n\t\t\tbody = data\n\t\t}\n\t}\n\tif len(body) == 0 {\n\t\treportValidationHTTPError(http.StatusBadRequest)\n\t\thttp.Error(w, \"no body found\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// verify the content type is accurate\n\tcontentType := r.Header.Get(\"Content-Type\")\n\tif contentType != \"application/json\" {\n\t\treportValidationHTTPError(http.StatusUnsupportedMediaType)\n\t\thttp.Error(w, \"invalid Content-Type, want `application/json`\", http.StatusUnsupportedMediaType)\n\t\treturn\n\t}\n\n\tvar reviewResponse *kube.AdmissionResponse\n\tvar obj runtime.Object\n\tvar ar *kube.AdmissionReview\n\tif out, _, err := deserializer.Decode(body, nil, obj); err != nil {\n\t\treviewResponse = toAdmissionResponse(fmt.Errorf(\"could not decode body: %v\", err))\n\t} else {\n\t\tar, err = kube.AdmissionReviewKubeToAdapter(out)\n\t\tif err != nil {\n\t\t\treviewResponse = toAdmissionResponse(fmt.Errorf(\"could not decode object: %v\", err))\n\t\t} else {\n\t\t\treviewResponse = admit(ar.Request)\n\t\t}\n\t}\n\n\tresponse := kube.AdmissionReview{}\n\tresponse.Response = reviewResponse\n\tvar responseKube runtime.Object\n\tvar apiVersion string\n\tif ar != nil {\n\t\tapiVersion = ar.APIVersion\n\t\tresponse.TypeMeta = ar.TypeMeta\n\t\tif response.Response != nil {\n\t\t\tif ar.Request != nil {\n\t\t\t\tresponse.Response.UID = ar.Request.UID\n\t\t\t}\n\t\t}\n\t}\n\tresponseKube = kube.AdmissionReviewAdapterToKube(&response, apiVersion)\n\tresp, err := json.Marshal(responseKube)\n\tif err != nil {\n\t\treportValidationHTTPError(http.StatusInternalServerError)\n\t\thttp.Error(w, fmt.Sprintf(\"could encode response: %v\", err), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tif _, err := w.Write(resp); err != nil {\n\t\treportValidationHTTPError(http.StatusInternalServerError)\n\t\thttp.Error(w, fmt.Sprintf(\"could write response: %v\", err), http.StatusInternalServerError)\n\t}\n}\n\nfunc (wh *Webhook) serveValidate(w http.ResponseWriter, r *http.Request) {\n\tserve(w, r, wh.validate)\n}\n\nfunc (wh *Webhook) validate(request *kube.AdmissionRequest) *kube.AdmissionResponse {\n\tswitch request.Operation {\n\tcase kube.Create, kube.Update:\n\tdefault:\n\t\tscope.Warnf(\"Unsupported webhook operation %v\", request.Operation)\n\t\treportValidationFailed(request, reasonUnsupportedOperation)\n\t\treturn &kube.AdmissionResponse{Allowed: true}\n\t}\n\n\tvar obj crd.IstioKind\n\tif err := json.Unmarshal(request.Object.Raw, &obj); err != nil {\n\t\tscope.Infof(\"cannot decode configuration: %v\", err)\n\t\treportValidationFailed(request, reasonYamlDecodeError)\n\t\treturn toAdmissionResponse(fmt.Errorf(\"cannot decode configuration: %v\", err))\n\t}\n\n\tgvk := obj.GroupVersionKind()\n\n\t// TODO(jasonwzm) remove this when multi-version is supported. v1beta1 shares the same\n\t// schema as v1lalpha3. Fake conversion and validate against v1alpha3.\n\tif gvk.Group == \"networking.istio.io\" && gvk.Version == \"v1beta1\" &&\n\t\t// ProxyConfig CR is stored as v1beta1 since it was introduced as v1beta1\n\t\tgvk.Kind != collections.IstioNetworkingV1Beta1Proxyconfigs.Resource().Kind() {\n\t\tgvk.Version = \"v1alpha3\"\n\t}\n\ts, exists := wh.schemas.FindByGroupVersionKind(resource.FromKubernetesGVK(&gvk))\n\tif !exists {\n\t\tscope.Infof(\"unrecognized type %v\", obj.GroupVersionKind())\n\t\treportValidationFailed(request, reasonUnknownType)\n\t\treturn toAdmissionResponse(fmt.Errorf(\"unrecognized type %v\", obj.GroupVersionKind()))\n\t}\n\n\tout, err := crd.ConvertObject(s, &obj, wh.domainSuffix)\n\tif err != nil {\n\t\tscope.Infof(\"error decoding configuration: %v\", err)\n\t\treportValidationFailed(request, reasonCRDConversionError)\n\t\treturn toAdmissionResponse(fmt.Errorf(\"error decoding configuration: %v\", err))\n\t}\n\n\twarnings, err := s.Resource().ValidateConfig(*out)\n\tif err != nil {\n\t\tscope.Infof(\"configuration is invalid: %v\", err)\n\t\treportValidationFailed(request, reasonInvalidConfig)\n\t\treturn toAdmissionResponse(fmt.Errorf(\"configuration is invalid: %v\", err))\n\t}\n\n\tif reason, err := checkFields(request.Object.Raw, request.Kind.Kind, request.Namespace, obj.Name); err != nil {\n\t\treportValidationFailed(request, reason)\n\t\treturn toAdmissionResponse(err)\n\t}\n\n\treportValidationPass(request)\n\treturn &kube.AdmissionResponse{Allowed: true, Warnings: toKubeWarnings(warnings)}\n}\n\nfunc toKubeWarnings(warn validation.Warning) []string {\n\tif warn == nil {\n\t\treturn nil\n\t}\n\tme, ok := warn.(*multierror.Error)\n\tif ok {\n\t\tres := []string{}\n\t\tfor _, e := range me.Errors {\n\t\t\tres = append(res, e.Error())\n\t\t}\n\t\treturn res\n\t}\n\treturn []string{warn.Error()}\n}\n\nfunc checkFields(raw []byte, kind string, namespace string, name string) (string, error) {\n\ttrial := make(map[string]json.RawMessage)\n\tif err := json.Unmarshal(raw, &trial); err != nil {\n\t\tscope.Infof(\"cannot decode configuration fields: %v\", err)\n\t\treturn reasonYamlDecodeError, fmt.Errorf(\"cannot decode configuration fields: %v\", err)\n\t}\n\n\tfor key := range trial {\n\t\tif _, ok := validFields[key]; !ok {\n\t\t\tscope.Infof(\"unknown field %q on %s resource %s/%s\",\n\t\t\t\tkey, kind, namespace, name)\n\t\t\treturn reasonInvalidConfig, fmt.Errorf(\"unknown field %q on %s resource %s/%s\",\n\t\t\t\tkey, kind, namespace, name)\n\t\t}\n\t}\n\n\treturn \"\", nil\n}\n\n// validatePort checks that the network port is in range\nfunc validatePort(port int) error {\n\tif 1 <= port && port <= 65535 {\n\t\treturn nil\n\t}\n\treturn fmt.Errorf(\"port number %d must be in the range 1..65535\", port)\n}\n\n// Validate tests if the Options has valid params.\nfunc (o Options) Validate() error {\n\tvar errs *multierror.Error\n\tif err := validatePort(int(o.Port)); err != nil {\n\t\terrs = multierror.Append(errs, err)\n\t}\n\treturn errs.ErrorOrNil()\n}\n"], "fixing_code": ["// Copyright Istio Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage inject\n\nimport (\n\t\"crypto/sha256\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/prometheus/prometheus/util/strutil\"\n\t\"gomodules.xyz/jsonpatch/v3\"\n\tkubeApiAdmissionv1 \"k8s.io/api/admission/v1\"\n\tkubeApiAdmissionv1beta1 \"k8s.io/api/admission/v1beta1\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/runtime\"\n\t\"k8s.io/apimachinery/pkg/runtime/serializer\"\n\tkjson \"k8s.io/apimachinery/pkg/runtime/serializer/json\"\n\t\"k8s.io/apimachinery/pkg/util/strategicpatch\"\n\t\"k8s.io/kube-openapi/pkg/util/sets\"\n\n\t\"istio.io/api/annotation\"\n\t\"istio.io/api/label\"\n\tmeshconfig \"istio.io/api/mesh/v1alpha1\"\n\topconfig \"istio.io/istio/operator/pkg/apis/istio/v1alpha1\"\n\t\"istio.io/istio/pilot/cmd/pilot-agent/status\"\n\t\"istio.io/istio/pilot/pkg/model\"\n\t\"istio.io/istio/pkg/config/mesh\"\n\t\"istio.io/istio/pkg/kube\"\n\t\"istio.io/istio/pkg/util/gogoprotomarshal\"\n\t\"istio.io/pkg/log\"\n)\n\nvar (\n\truntimeScheme     = runtime.NewScheme()\n\tcodecs            = serializer.NewCodecFactory(runtimeScheme)\n\tdeserializer      = codecs.UniversalDeserializer()\n\tjsonSerializer    = kjson.NewSerializerWithOptions(kjson.DefaultMetaFactory, runtimeScheme, runtimeScheme, kjson.SerializerOptions{})\n\tURLParameterToEnv = map[string]string{\n\t\t\"cluster\": \"ISTIO_META_CLUSTER_ID\",\n\t\t\"net\":     \"ISTIO_META_NETWORK\",\n\t}\n)\n\nfunc init() {\n\t_ = corev1.AddToScheme(runtimeScheme)\n\t_ = kubeApiAdmissionv1.AddToScheme(runtimeScheme)\n\t_ = kubeApiAdmissionv1beta1.AddToScheme(runtimeScheme)\n}\n\nconst (\n\t// prometheus will convert annotation to this format\n\t// `prometheus.io/scrape` `prometheus.io.scrape` `prometheus-io/scrape` have the same meaning in Prometheus\n\t// for more details, please checkout [here](https://github.com/prometheus/prometheus/blob/71a0f42331566a8849863d77078083edbb0b3bc4/util/strutil/strconv.go#L40)\n\tprometheusScrapeAnnotation = \"prometheus_io_scrape\"\n\tprometheusPortAnnotation   = \"prometheus_io_port\"\n\tprometheusPathAnnotation   = \"prometheus_io_path\"\n\n\twatchDebounceDelay = 100 * time.Millisecond\n)\n\n// Webhook implements a mutating webhook for automatic proxy injection.\ntype Webhook struct {\n\tmu           sync.RWMutex\n\tConfig       *Config\n\tmeshConfig   *meshconfig.MeshConfig\n\tvaluesConfig string\n\n\twatcher Watcher\n\n\tenv      *model.Environment\n\trevision string\n}\n\n// nolint directives: interfacer\nfunc loadConfig(injectFile, valuesFile string) (*Config, string, error) {\n\tdata, err := os.ReadFile(injectFile)\n\tif err != nil {\n\t\treturn nil, \"\", err\n\t}\n\tvar c *Config\n\tif c, err = unmarshalConfig(data); err != nil {\n\t\tlog.Warnf(\"Failed to parse injectFile %s\", string(data))\n\t\treturn nil, \"\", err\n\t}\n\n\tvaluesConfig, err := os.ReadFile(valuesFile)\n\tif err != nil {\n\t\treturn nil, \"\", err\n\t}\n\treturn c, string(valuesConfig), nil\n}\n\nfunc unmarshalConfig(data []byte) (*Config, error) {\n\tc, err := UnmarshalConfig(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlog.Debugf(\"New inject configuration: sha256sum %x\", sha256.Sum256(data))\n\tlog.Debugf(\"Policy: %v\", c.Policy)\n\tlog.Debugf(\"AlwaysInjectSelector: %v\", c.AlwaysInjectSelector)\n\tlog.Debugf(\"NeverInjectSelector: %v\", c.NeverInjectSelector)\n\tlog.Debugf(\"Templates: |\\n  %v\", c.Templates, \"\\n\", \"\\n  \", -1)\n\treturn &c, nil\n}\n\n// WebhookParameters configures parameters for the sidecar injection\n// webhook.\ntype WebhookParameters struct {\n\t// Watcher watches the sidecar injection configuration.\n\tWatcher Watcher\n\n\t// Port is the webhook port, e.g. typically 443 for https.\n\t// This is mainly used for tests. Webhook runs on the port started by Istiod.\n\tPort int\n\n\tEnv *model.Environment\n\n\t// Use an existing mux instead of creating our own.\n\tMux *http.ServeMux\n\n\t// The istio.io/rev this injector is responsible for\n\tRevision string\n}\n\n// NewWebhook creates a new instance of a mutating webhook for automatic sidecar injection.\nfunc NewWebhook(p WebhookParameters) (*Webhook, error) {\n\tif p.Mux == nil {\n\t\treturn nil, errors.New(\"expected mux to be passed, but was not passed\")\n\t}\n\n\twh := &Webhook{\n\t\twatcher:    p.Watcher,\n\t\tmeshConfig: p.Env.Mesh(),\n\t\tenv:        p.Env,\n\t\trevision:   p.Revision,\n\t}\n\n\tp.Watcher.SetHandler(wh.updateConfig)\n\tsidecarConfig, valuesConfig, err := p.Watcher.Get()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\twh.updateConfig(sidecarConfig, valuesConfig)\n\n\tp.Mux.HandleFunc(\"/inject\", wh.serveInject)\n\tp.Mux.HandleFunc(\"/inject/\", wh.serveInject)\n\n\tp.Env.Watcher.AddMeshHandler(func() {\n\t\twh.mu.Lock()\n\t\twh.meshConfig = p.Env.Mesh()\n\t\twh.mu.Unlock()\n\t})\n\n\treturn wh, nil\n}\n\n// Run implements the webhook server\nfunc (wh *Webhook) Run(stop <-chan struct{}) {\n\tgo wh.watcher.Run(stop)\n}\n\nfunc (wh *Webhook) updateConfig(sidecarConfig *Config, valuesConfig string) {\n\twh.mu.Lock()\n\twh.Config = sidecarConfig\n\twh.valuesConfig = valuesConfig\n\twh.mu.Unlock()\n}\n\ntype ContainerReorder int\n\nconst (\n\tMoveFirst ContainerReorder = iota\n\tMoveLast\n\tRemove\n)\n\nfunc modifyContainers(cl []corev1.Container, name string, modifier ContainerReorder) []corev1.Container {\n\tcontainers := []corev1.Container{}\n\tvar match *corev1.Container\n\tfor _, c := range cl {\n\t\tc := c\n\t\tif c.Name != name {\n\t\t\tcontainers = append(containers, c)\n\t\t} else {\n\t\t\tmatch = &c\n\t\t}\n\t}\n\tif match == nil {\n\t\treturn containers\n\t}\n\tswitch modifier {\n\tcase MoveFirst:\n\t\treturn append([]corev1.Container{*match}, containers...)\n\tcase MoveLast:\n\t\treturn append(containers, *match)\n\tcase Remove:\n\t\treturn containers\n\tdefault:\n\t\treturn cl\n\t}\n}\n\nfunc enablePrometheusMerge(mesh *meshconfig.MeshConfig, anno map[string]string) bool {\n\t// If annotation is present, we look there first\n\tif val, f := anno[annotation.PrometheusMergeMetrics.Name]; f {\n\t\tbval, err := strconv.ParseBool(val)\n\t\tif err != nil {\n\t\t\t// This shouldn't happen since we validate earlier in the code\n\t\t\tlog.Warnf(\"invalid annotation %v=%v\", annotation.PrometheusMergeMetrics.Name, bval)\n\t\t} else {\n\t\t\treturn bval\n\t\t}\n\t}\n\t// If mesh config setting is present, use that\n\tif mesh.GetEnablePrometheusMerge() != nil {\n\t\treturn mesh.GetEnablePrometheusMerge().Value\n\t}\n\t// Otherwise, we default to enable\n\treturn true\n}\n\nfunc toAdmissionResponse(err error) *kube.AdmissionResponse {\n\treturn &kube.AdmissionResponse{Result: &metav1.Status{Message: err.Error()}}\n}\n\ntype InjectionParameters struct {\n\tpod                 *corev1.Pod\n\tdeployMeta          metav1.ObjectMeta\n\ttypeMeta            metav1.TypeMeta\n\ttemplates           Templates\n\tdefaultTemplate     []string\n\taliases             map[string][]string\n\tmeshConfig          *meshconfig.MeshConfig\n\tproxyConfig         *meshconfig.ProxyConfig\n\tvaluesConfig        string\n\trevision            string\n\tproxyEnvs           map[string]string\n\tinjectedAnnotations map[string]string\n}\n\nfunc checkPreconditions(params InjectionParameters) {\n\tspec := params.pod.Spec\n\tmetadata := params.pod.ObjectMeta\n\t// If DNSPolicy is not ClusterFirst, the Envoy sidecar may not able to connect to Istio Pilot.\n\tif spec.DNSPolicy != \"\" && spec.DNSPolicy != corev1.DNSClusterFirst {\n\t\tpodName := potentialPodName(metadata)\n\t\tlog.Warnf(\"%q's DNSPolicy is not %q. The Envoy sidecar may not able to connect to Istio Pilot\",\n\t\t\tmetadata.Namespace+\"/\"+podName, corev1.DNSClusterFirst)\n\t}\n}\n\nfunc getInjectionStatus(podSpec corev1.PodSpec, revision string) string {\n\tstat := &SidecarInjectionStatus{}\n\tfor _, c := range podSpec.InitContainers {\n\t\tstat.InitContainers = append(stat.InitContainers, c.Name)\n\t}\n\tfor _, c := range podSpec.Containers {\n\t\tstat.Containers = append(stat.Containers, c.Name)\n\t}\n\tfor _, c := range podSpec.Volumes {\n\t\tstat.Volumes = append(stat.Volumes, c.Name)\n\t}\n\tfor _, c := range podSpec.ImagePullSecrets {\n\t\tstat.ImagePullSecrets = append(stat.ImagePullSecrets, c.Name)\n\t}\n\t// Rather than setting istio.io/rev label on injected pods include them here in status annotation.\n\t// This keeps us from overwriting the istio.io/rev label when using revision tags (i.e. istio.io/rev=<tag>).\n\tif revision == \"\" {\n\t\trevision = \"default\"\n\t}\n\tstat.Revision = revision\n\tstatusAnnotationValue, err := json.Marshal(stat)\n\tif err != nil {\n\t\treturn \"{}\"\n\t}\n\treturn string(statusAnnotationValue)\n}\n\n// injectPod is the core of the injection logic. This takes a pod and injection\n// template, as well as some inputs to the injection template, and produces a\n// JSON patch.\n//\n// In the webhook, we will receive a Pod directly from Kubernetes, and return the\n// patch directly; Kubernetes will take care of applying the patch.\n//\n// For kube-inject, we will parse out a Pod from YAML (which may involve\n// extraction from higher level types like Deployment), then apply the patch\n// locally.\n//\n// The injection logic works by first applying the rendered injection template on\n// top of the input pod This is done using a Strategic Patch Merge\n// (https://github.com/kubernetes/community/blob/master/contributors/devel/sig-api-machinery/strategic-merge-patch.md)\n// Currently only a single template is supported, although in the future the template to use will be configurable\n// and multiple templates will be supported by applying them in successive order.\n//\n// In addition to the plain templating, there is some post processing done to\n// handle cases that cannot feasibly be covered in the template, such as\n// re-ordering pods, rewriting readiness probes, etc.\nfunc injectPod(req InjectionParameters) ([]byte, error) {\n\tcheckPreconditions(req)\n\n\t// The patch will be built relative to the initial pod, capture its current state\n\toriginalPodSpec, err := json.Marshal(req.pod)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Run the injection template, giving us a partial pod spec\n\tmergedPod, injectedPodData, err := RunTemplate(req)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to run injection template: %v\", err)\n\t}\n\n\tmergedPod, err = reapplyOverwrittenContainers(mergedPod, req.pod, injectedPodData)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to re apply container: %v\", err)\n\t}\n\n\t// Apply some additional transformations to the pod\n\tif err := postProcessPod(mergedPod, *injectedPodData, req); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to process pod: %v\", err)\n\t}\n\n\tpatch, err := createPatch(mergedPod, originalPodSpec)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create patch: %v\", err)\n\t}\n\n\tlog.Debugf(\"AdmissionResponse: patch=%v\\n\", string(patch))\n\treturn patch, nil\n}\n\n// reapplyOverwrittenContainers enables users to provide container level overrides for settings in the injection template\n// * originalPod: the pod before injection. If needed, we will apply some configurations from this pod on top of the final pod\n// * templatePod: the rendered injection template. This is needed only to see what containers we injected\n// * finalPod: the current result of injection, roughly equivalent to the merging of originalPod and templatePod\n// There are essentially three cases we cover here:\n// 1. There is no overlap in containers in original and template pod. We will do nothing.\n// 2. There is an overlap (ie, both define istio-proxy), but that is because the pod is being re-injected.\n//    In this case we do nothing, since we want to apply the new settings\n// 3. There is an overlap. We will re-apply the original container.\n// Where \"overlap\" is a container defined in both the original and template pod. Typically, this would mean\n// the user has defined an `istio-proxy` container in their own pod spec.\nfunc reapplyOverwrittenContainers(finalPod *corev1.Pod, originalPod *corev1.Pod, templatePod *corev1.Pod) (*corev1.Pod, error) {\n\ttype podOverrides struct {\n\t\tContainers     []corev1.Container `json:\"containers,omitempty\"`\n\t\tInitContainers []corev1.Container `json:\"initContainers,omitempty\"`\n\t}\n\n\toverrides := podOverrides{}\n\texistingOverrides := podOverrides{}\n\tif annotationOverrides, f := originalPod.Annotations[annotation.ProxyOverrides.Name]; f {\n\t\tif err := json.Unmarshal([]byte(annotationOverrides), &existingOverrides); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tfor _, c := range templatePod.Spec.Containers {\n\t\tmatch := FindContainer(c.Name, existingOverrides.Containers)\n\t\tif match == nil {\n\t\t\tmatch = FindContainer(c.Name, originalPod.Spec.Containers)\n\t\t}\n\t\tif match == nil {\n\t\t\tcontinue\n\t\t}\n\t\toverlay := *match.DeepCopy()\n\t\tif overlay.Image == AutoImage {\n\t\t\toverlay.Image = \"\"\n\t\t}\n\t\toverrides.Containers = append(overrides.Containers, overlay)\n\t\tnewMergedPod, err := applyContainer(finalPod, overlay)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to apply sidecar container: %v\", err)\n\t\t}\n\t\tfinalPod = newMergedPod\n\t}\n\tfor _, c := range templatePod.Spec.InitContainers {\n\t\tmatch := FindContainer(c.Name, existingOverrides.InitContainers)\n\t\tif match == nil {\n\t\t\tmatch = FindContainer(c.Name, originalPod.Spec.InitContainers)\n\t\t}\n\t\tif match == nil {\n\t\t\tcontinue\n\t\t}\n\t\toverlay := *match.DeepCopy()\n\t\tif overlay.Image == AutoImage {\n\t\t\toverlay.Image = \"\"\n\t\t}\n\t\toverrides.InitContainers = append(overrides.InitContainers, overlay)\n\t\tnewMergedPod, err := applyInitContainer(finalPod, overlay)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to apply sidecar init container: %v\", err)\n\t\t}\n\t\tfinalPod = newMergedPod\n\t}\n\n\t_, alreadyInjected := originalPod.Annotations[annotation.SidecarStatus.Name]\n\tif !alreadyInjected && (len(overrides.Containers) > 0 || len(overrides.InitContainers) > 0) {\n\t\t// We found any overrides. Put them in the pod annotation so we can re-apply them on re-injection\n\t\tjs, err := json.Marshal(overrides)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif finalPod.Annotations == nil {\n\t\t\tfinalPod.Annotations = map[string]string{}\n\t\t}\n\t\tfinalPod.Annotations[annotation.ProxyOverrides.Name] = string(js)\n\t}\n\n\treturn finalPod, nil\n}\n\n// reinsertOverrides applies the containers listed in OverrideAnnotation to a pod. This is to achieve\n// idempotency by handling an edge case where an injection template is modifying a container already\n// present in the pod spec. In these cases, the logic to strip injected containers would remove the\n// original injected parts as well, leading to the templating logic being different (for example,\n// reading the .Spec.Containers field would be empty).\nfunc reinsertOverrides(pod *corev1.Pod) (*corev1.Pod, error) {\n\ttype podOverrides struct {\n\t\tContainers     []corev1.Container `json:\"containers,omitempty\"`\n\t\tInitContainers []corev1.Container `json:\"initContainers,omitempty\"`\n\t}\n\n\texistingOverrides := podOverrides{}\n\tif annotationOverrides, f := pod.Annotations[annotation.ProxyOverrides.Name]; f {\n\t\tif err := json.Unmarshal([]byte(annotationOverrides), &existingOverrides); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tpod = pod.DeepCopy()\n\tfor _, c := range existingOverrides.Containers {\n\t\tmatch := FindContainer(c.Name, pod.Spec.Containers)\n\t\tif match != nil {\n\t\t\tcontinue\n\t\t}\n\t\tpod.Spec.Containers = append(pod.Spec.Containers, c)\n\t}\n\n\tfor _, c := range existingOverrides.InitContainers {\n\t\tmatch := FindContainer(c.Name, pod.Spec.InitContainers)\n\t\tif match != nil {\n\t\t\tcontinue\n\t\t}\n\t\tpod.Spec.InitContainers = append(pod.Spec.InitContainers, c)\n\t}\n\n\treturn pod, nil\n}\n\nfunc createPatch(pod *corev1.Pod, original []byte) ([]byte, error) {\n\treinjected, err := json.Marshal(pod)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tp, err := jsonpatch.CreatePatch(original, reinjected)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn json.Marshal(p)\n}\n\n// postProcessPod applies additionally transformations to the pod after merging with the injected template\n// This is generally things that cannot reasonably be added to the template\nfunc postProcessPod(pod *corev1.Pod, injectedPod corev1.Pod, req InjectionParameters) error {\n\tif pod.Annotations == nil {\n\t\tpod.Annotations = map[string]string{}\n\t}\n\tif pod.Labels == nil {\n\t\tpod.Labels = map[string]string{}\n\t}\n\n\toverwriteClusterInfo(pod.Spec.Containers, req)\n\n\tif err := applyPrometheusMerge(pod, req.meshConfig); err != nil {\n\t\treturn err\n\t}\n\n\tif err := applyRewrite(pod, req); err != nil {\n\t\treturn err\n\t}\n\n\tapplyMetadata(pod, injectedPod, req)\n\n\tif err := reorderPod(pod, req); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc applyMetadata(pod *corev1.Pod, injectedPodData corev1.Pod, req InjectionParameters) {\n\tif nw, ok := req.proxyEnvs[\"ISTIO_META_NETWORK\"]; ok {\n\t\tpod.Labels[label.TopologyNetwork.Name] = nw\n\t}\n\t// Add all additional injected annotations. These are overridden if needed\n\tpod.Annotations[annotation.SidecarStatus.Name] = getInjectionStatus(injectedPodData.Spec, req.revision)\n\n\t// Deprecated; should be set directly in the template instead\n\tfor k, v := range req.injectedAnnotations {\n\t\tpod.Annotations[k] = v\n\t}\n}\n\n// reorderPod ensures containers are properly ordered after merging\nfunc reorderPod(pod *corev1.Pod, req InjectionParameters) error {\n\tvar merr error\n\tmc := req.meshConfig\n\t// Get copy of pod proxyconfig, to determine container ordering\n\tif pca, f := req.pod.ObjectMeta.GetAnnotations()[annotation.ProxyConfig.Name]; f {\n\t\tmc, merr = mesh.ApplyProxyConfig(pca, *req.meshConfig)\n\t\tif merr != nil {\n\t\t\treturn merr\n\t\t}\n\t}\n\n\tvaluesStruct := &opconfig.Values{}\n\tif err := gogoprotomarshal.ApplyYAML(req.valuesConfig, valuesStruct); err != nil {\n\t\treturn fmt.Errorf(\"could not parse configuration values: %v\", err)\n\t}\n\t// nolint: staticcheck\n\tholdPod := mc.GetDefaultConfig().GetHoldApplicationUntilProxyStarts().GetValue() ||\n\t\tvaluesStruct.GetGlobal().GetProxy().GetHoldApplicationUntilProxyStarts().GetValue()\n\n\tproxyLocation := MoveLast\n\t// If HoldApplicationUntilProxyStarts is set, reorder the proxy location\n\tif holdPod {\n\t\tproxyLocation = MoveFirst\n\t}\n\n\t// Proxy container should be last, unless HoldApplicationUntilProxyStarts is set\n\t// This is to ensure `kubectl exec` and similar commands continue to default to the user's container\n\tpod.Spec.Containers = modifyContainers(pod.Spec.Containers, ProxyContainerName, proxyLocation)\n\t// Validation container must be first to block any user containers\n\tpod.Spec.InitContainers = modifyContainers(pod.Spec.InitContainers, ValidationContainerName, MoveFirst)\n\t// Init container must be last to allow any traffic to pass before iptables is setup\n\tpod.Spec.InitContainers = modifyContainers(pod.Spec.InitContainers, InitContainerName, MoveLast)\n\tpod.Spec.InitContainers = modifyContainers(pod.Spec.InitContainers, EnableCoreDumpName, MoveLast)\n\n\treturn nil\n}\n\nfunc applyRewrite(pod *corev1.Pod, req InjectionParameters) error {\n\tsidecar := FindSidecar(pod.Spec.Containers)\n\tif sidecar == nil {\n\t\treturn nil\n\t}\n\tvaluesStruct := &opconfig.Values{}\n\tif err := gogoprotomarshal.ApplyYAML(req.valuesConfig, valuesStruct); err != nil {\n\t\tlog.Infof(\"Failed to parse values config: %v [%v]\\n\", err, req.valuesConfig)\n\t\treturn fmt.Errorf(\"could not parse configuration values: %v\", err)\n\t}\n\n\trewrite := ShouldRewriteAppHTTPProbers(pod.Annotations, valuesStruct.GetSidecarInjectorWebhook().GetRewriteAppHTTPProbe())\n\t// We don't have to escape json encoding here when using golang libraries.\n\tif rewrite {\n\t\tif prober := DumpAppProbers(&pod.Spec, req.meshConfig.GetDefaultConfig().GetStatusPort()); prober != \"\" {\n\t\t\tsidecar.Env = append(sidecar.Env, corev1.EnvVar{Name: status.KubeAppProberEnvName, Value: prober})\n\t\t}\n\t\tpatchRewriteProbe(pod.Annotations, pod, req.meshConfig.GetDefaultConfig().GetStatusPort())\n\t}\n\treturn nil\n}\n\nvar emptyScrape = status.PrometheusScrapeConfiguration{}\n\n// applyPrometheusMerge configures prometheus scraping annotations for the \"metrics merge\" feature.\n// This moves the current prometheus.io annotations into an environment variable and replaces them\n// pointing to the agent.\nfunc applyPrometheusMerge(pod *corev1.Pod, mesh *meshconfig.MeshConfig) error {\n\tif getPrometheusScrape(pod) &&\n\t\tenablePrometheusMerge(mesh, pod.ObjectMeta.Annotations) {\n\t\ttargetPort := strconv.Itoa(int(mesh.GetDefaultConfig().GetStatusPort()))\n\t\tif cur, f := getPrometheusPort(pod); f {\n\t\t\t// We have already set the port, assume user is controlling this or, more likely, re-injected\n\t\t\t// the pod.\n\t\t\tif cur == targetPort {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tscrape := getPrometheusScrapeConfiguration(pod)\n\t\tsidecar := FindSidecar(pod.Spec.Containers)\n\t\tif sidecar != nil && scrape != emptyScrape {\n\t\t\tby, err := json.Marshal(scrape)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tsidecar.Env = append(sidecar.Env, corev1.EnvVar{Name: status.PrometheusScrapingConfig.Name, Value: string(by)})\n\t\t}\n\t\tif pod.Annotations == nil {\n\t\t\tpod.Annotations = map[string]string{}\n\t\t}\n\t\t// if a user sets `prometheus/io/path: foo`, then we add `prometheus.io/path: /stats/prometheus`\n\t\t// prometheus will pick a random one\n\t\t// need to clear out all variants and then set ours\n\t\tclearPrometheusAnnotations(pod)\n\t\tpod.Annotations[\"prometheus.io/port\"] = targetPort\n\t\tpod.Annotations[\"prometheus.io/path\"] = \"/stats/prometheus\"\n\t\tpod.Annotations[\"prometheus.io/scrape\"] = \"true\"\n\t\treturn nil\n\t}\n\n\treturn nil\n}\n\n// getPrometheusScrape respect prometheus scrape config\n// not to doing prometheusMerge if this return false\nfunc getPrometheusScrape(pod *corev1.Pod) bool {\n\tfor k, val := range pod.Annotations {\n\t\tif strutil.SanitizeLabelName(k) != prometheusScrapeAnnotation {\n\t\t\tcontinue\n\t\t}\n\n\t\tif scrape, err := strconv.ParseBool(val); err == nil {\n\t\t\treturn scrape\n\t\t}\n\t}\n\n\treturn true\n}\n\nvar prometheusAnnotations = sets.NewString(\n\tprometheusPathAnnotation,\n\tprometheusPortAnnotation,\n\tprometheusScrapeAnnotation,\n)\n\nfunc clearPrometheusAnnotations(pod *corev1.Pod) {\n\tneedRemovedKeys := make([]string, 0, 2)\n\tfor k := range pod.Annotations {\n\t\tanno := strutil.SanitizeLabelName(k)\n\t\tif prometheusAnnotations.Has(anno) {\n\t\t\tneedRemovedKeys = append(needRemovedKeys, k)\n\t\t}\n\t}\n\n\tfor _, k := range needRemovedKeys {\n\t\tdelete(pod.Annotations, k)\n\t}\n}\n\nfunc getPrometheusScrapeConfiguration(pod *corev1.Pod) status.PrometheusScrapeConfiguration {\n\tcfg := status.PrometheusScrapeConfiguration{}\n\n\tfor k, val := range pod.Annotations {\n\t\tanno := strutil.SanitizeLabelName(k)\n\t\tswitch anno {\n\t\tcase prometheusPortAnnotation:\n\t\t\tcfg.Port = val\n\t\tcase prometheusScrapeAnnotation:\n\t\t\tcfg.Scrape = val\n\t\tcase prometheusPathAnnotation:\n\t\t\tcfg.Path = val\n\t\t}\n\t}\n\n\treturn cfg\n}\n\nfunc getPrometheusPort(pod *corev1.Pod) (string, bool) {\n\tfor k, val := range pod.Annotations {\n\t\tif strutil.SanitizeLabelName(k) != prometheusPortAnnotation {\n\t\t\tcontinue\n\t\t}\n\n\t\treturn val, true\n\t}\n\n\treturn \"\", false\n}\n\nconst (\n\t// AutoImage is the special image name to indicate to the injector that we should use the injected image, and NOT override it\n\t// This is necessary because image is a required field on container, so if a user defines an istio-proxy container\n\t// with customizations they must set an image.\n\tAutoImage = \"auto\"\n)\n\n// applyContainer merges a container spec on top of the provided pod\nfunc applyContainer(target *corev1.Pod, container corev1.Container) (*corev1.Pod, error) {\n\toverlay := &corev1.Pod{Spec: corev1.PodSpec{Containers: []corev1.Container{container}}}\n\n\toverlayJSON, err := json.Marshal(overlay)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn applyOverlay(target, overlayJSON)\n}\n\n// applyInitContainer merges a container spec on top of the provided pod as an init container\nfunc applyInitContainer(target *corev1.Pod, container corev1.Container) (*corev1.Pod, error) {\n\toverlay := &corev1.Pod{Spec: corev1.PodSpec{\n\t\t// We need to set containers to empty, otherwise it will marshal as \"null\" and delete all containers\n\t\tContainers:     []corev1.Container{},\n\t\tInitContainers: []corev1.Container{container},\n\t}}\n\n\toverlayJSON, err := json.Marshal(overlay)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn applyOverlay(target, overlayJSON)\n}\n\n// applyContainer merges a pod spec, provided as JSON, on top of the provided pod\nfunc applyOverlay(target *corev1.Pod, overlayJSON []byte) (*corev1.Pod, error) {\n\tcurrentJSON, err := json.Marshal(target)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tpod := corev1.Pod{}\n\t// Overlay the injected template onto the original podSpec\n\tpatched, err := strategicpatch.StrategicMergePatch(currentJSON, overlayJSON, pod)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"strategic merge: %v\", err)\n\t}\n\n\tif err := json.Unmarshal(patched, &pod); err != nil {\n\t\treturn nil, fmt.Errorf(\"unmarshal patched pod: %v\", err)\n\t}\n\treturn &pod, nil\n}\n\nfunc (wh *Webhook) inject(ar *kube.AdmissionReview, path string) *kube.AdmissionResponse {\n\treq := ar.Request\n\tvar pod corev1.Pod\n\tif err := json.Unmarshal(req.Object.Raw, &pod); err != nil {\n\t\thandleError(fmt.Sprintf(\"Could not unmarshal raw object: %v %s\", err,\n\t\t\tstring(req.Object.Raw)))\n\t\treturn toAdmissionResponse(err)\n\t}\n\t// Managed fields is sometimes extremely large, leading to excessive CPU time on patch generation\n\t// It does not impact the injection output at all, so we can just remove it.\n\tpod.ManagedFields = nil\n\n\t// Deal with potential empty fields, e.g., when the pod is created by a deployment\n\tpodName := potentialPodName(pod.ObjectMeta)\n\tif pod.ObjectMeta.Namespace == \"\" {\n\t\tpod.ObjectMeta.Namespace = req.Namespace\n\t}\n\tlog.Infof(\"Sidecar injection request for %v/%v\", req.Namespace, podName)\n\tlog.Debugf(\"Object: %v\", string(req.Object.Raw))\n\tlog.Debugf(\"OldObject: %v\", string(req.OldObject.Raw))\n\n\twh.mu.RLock()\n\tif !injectRequired(IgnoredNamespaces.UnsortedList(), wh.Config, &pod.Spec, pod.ObjectMeta) {\n\t\tlog.Infof(\"Skipping %s/%s due to policy check\", pod.ObjectMeta.Namespace, podName)\n\t\ttotalSkippedInjections.Increment()\n\t\twh.mu.RUnlock()\n\t\treturn &kube.AdmissionResponse{\n\t\t\tAllowed: true,\n\t\t}\n\t}\n\n\tproxyConfig := mesh.DefaultProxyConfig()\n\tif wh.env.PushContext != nil && wh.env.PushContext.ProxyConfigs != nil {\n\t\tif generatedProxyConfig := wh.env.PushContext.ProxyConfigs.EffectiveProxyConfig(\n\t\t\t&model.NodeMetadata{\n\t\t\t\tNamespace:   pod.Namespace,\n\t\t\t\tLabels:      pod.Labels,\n\t\t\t\tAnnotations: pod.Annotations,\n\t\t\t}, wh.meshConfig); generatedProxyConfig != nil {\n\t\t\tproxyConfig = *generatedProxyConfig\n\t\t}\n\t}\n\tdeploy, typeMeta := kube.GetDeployMetaFromPod(&pod)\n\tparams := InjectionParameters{\n\t\tpod:                 &pod,\n\t\tdeployMeta:          deploy,\n\t\ttypeMeta:            typeMeta,\n\t\ttemplates:           wh.Config.Templates,\n\t\tdefaultTemplate:     wh.Config.DefaultTemplates,\n\t\taliases:             wh.Config.Aliases,\n\t\tmeshConfig:          wh.meshConfig,\n\t\tproxyConfig:         &proxyConfig,\n\t\tvaluesConfig:        wh.valuesConfig,\n\t\trevision:            wh.revision,\n\t\tinjectedAnnotations: wh.Config.InjectedAnnotations,\n\t\tproxyEnvs:           parseInjectEnvs(path),\n\t}\n\twh.mu.RUnlock()\n\n\tpatchBytes, err := injectPod(params)\n\tif err != nil {\n\t\thandleError(fmt.Sprintf(\"Pod injection failed: %v\", err))\n\t\treturn toAdmissionResponse(err)\n\t}\n\n\treviewResponse := kube.AdmissionResponse{\n\t\tAllowed: true,\n\t\tPatch:   patchBytes,\n\t\tPatchType: func() *string {\n\t\t\tpt := \"JSONPatch\"\n\t\t\treturn &pt\n\t\t}(),\n\t}\n\ttotalSuccessfulInjections.Increment()\n\treturn &reviewResponse\n}\n\nfunc (wh *Webhook) serveInject(w http.ResponseWriter, r *http.Request) {\n\ttotalInjections.Increment()\n\tvar body []byte\n\tif r.Body != nil {\n\t\tif data, err := kube.HTTPConfigReader(r); err == nil {\n\t\t\tbody = data\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\tif len(body) == 0 {\n\t\thandleError(\"no body found\")\n\t\thttp.Error(w, \"no body found\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// verify the content type is accurate\n\tcontentType := r.Header.Get(\"Content-Type\")\n\tif contentType != \"application/json\" {\n\t\thandleError(fmt.Sprintf(\"contentType=%s, expect application/json\", contentType))\n\t\thttp.Error(w, \"invalid Content-Type, want `application/json`\", http.StatusUnsupportedMediaType)\n\t\treturn\n\t}\n\n\tpath := \"\"\n\tif r.URL != nil {\n\t\tpath = r.URL.Path\n\t}\n\n\tvar reviewResponse *kube.AdmissionResponse\n\tvar obj runtime.Object\n\tvar ar *kube.AdmissionReview\n\tif out, _, err := deserializer.Decode(body, nil, obj); err != nil {\n\t\thandleError(fmt.Sprintf(\"Could not decode body: %v\", err))\n\t\treviewResponse = toAdmissionResponse(err)\n\t} else {\n\t\tlog.Debugf(\"AdmissionRequest for path=%s\\n\", path)\n\t\tar, err = kube.AdmissionReviewKubeToAdapter(out)\n\t\tif err != nil {\n\t\t\thandleError(fmt.Sprintf(\"Could not decode object: %v\", err))\n\t\t}\n\t\treviewResponse = wh.inject(ar, path)\n\t}\n\n\tresponse := kube.AdmissionReview{}\n\tresponse.Response = reviewResponse\n\tvar responseKube runtime.Object\n\tvar apiVersion string\n\tif ar != nil {\n\t\tapiVersion = ar.APIVersion\n\t\tresponse.TypeMeta = ar.TypeMeta\n\t\tif response.Response != nil {\n\t\t\tif ar.Request != nil {\n\t\t\t\tresponse.Response.UID = ar.Request.UID\n\t\t\t}\n\t\t}\n\t}\n\tresponseKube = kube.AdmissionReviewAdapterToKube(&response, apiVersion)\n\tresp, err := json.Marshal(responseKube)\n\tif err != nil {\n\t\tlog.Errorf(\"Could not encode response: %v\", err)\n\t\thttp.Error(w, fmt.Sprintf(\"could not encode response: %v\", err), http.StatusInternalServerError)\n\t}\n\tif _, err := w.Write(resp); err != nil {\n\t\tlog.Errorf(\"Could not write response: %v\", err)\n\t\thttp.Error(w, fmt.Sprintf(\"could not write response: %v\", err), http.StatusInternalServerError)\n\t}\n}\n\n// parseInjectEnvs parse new envs from inject url path\n// follow format: /inject/k1/v1/k2/v2 when values do not contain slashes,\n// follow format: /inject/:ENV:net=network1:ENV:cluster=cluster1:ENV:rootpage=/foo/bar\n// when values contain slashes.\nfunc parseInjectEnvs(path string) map[string]string {\n\tpath = strings.TrimSuffix(path, \"/\")\n\tres := func(path string) []string {\n\t\tparts := strings.SplitN(path, \"/\", 3)\n\t\t// The 3rd part has to start with separator :ENV:\n\t\t// If not, this inject path is considered using slash as separator\n\t\t// If length is less than 3, then the path is simply \"/inject\",\n\t\t// process just like before :ENV: separator is introduced.\n\t\tvar newRes []string\n\t\tif len(parts) == 3 {\n\t\t\tif strings.HasPrefix(parts[2], \":ENV:\") {\n\t\t\t\tpairs := strings.Split(parts[2], \":ENV:\")\n\t\t\t\tfor i := 1; i < len(pairs); i++ { // skip the first part, it is a nil\n\t\t\t\t\tpair := strings.SplitN(pairs[i], \"=\", 2)\n\t\t\t\t\t// The first part is the variable name which can not be empty\n\t\t\t\t\t// the second part is the variable value which can be empty but has to exist\n\t\t\t\t\t// for example, aaa=bbb, aaa= are valid, but =aaa or = are not valid, the\n\t\t\t\t\t// invalid ones will be ignored.\n\t\t\t\t\tif len(pair[0]) > 0 && len(pair) == 2 {\n\t\t\t\t\t\tnewRes = append(newRes, pair...)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn newRes\n\t\t\t}\n\t\t\treturn strings.Split(parts[2], \"/\")\n\t\t}\n\t\treturn newRes\n\t}(path)\n\tnewEnvs := make(map[string]string)\n\n\tfor i := 0; i < len(res); i += 2 {\n\t\tk := res[i]\n\t\tif i == len(res)-1 { // ignore the last key without value\n\t\t\tlog.Warnf(\"Odd number of inject env entries, ignore the last key %s\\n\", k)\n\t\t\tbreak\n\t\t}\n\n\t\tenv, found := URLParameterToEnv[k]\n\t\tif !found {\n\t\t\tenv = strings.ToUpper(k) // if not found, use the custom env directly\n\t\t}\n\t\tif env != \"\" {\n\t\t\tnewEnvs[env] = res[i+1]\n\t\t}\n\t}\n\n\treturn newEnvs\n}\n\nfunc handleError(message string) {\n\tlog.Errorf(message)\n\ttotalFailedInjections.Increment()\n}\n", "// Copyright Istio Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage kube\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"strings\"\n\n\tkubeApiCore \"k8s.io/api/core/v1\"\n\t\"k8s.io/apimachinery/pkg/api/errors\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/runtime\"\n\t\"k8s.io/apimachinery/pkg/runtime/serializer\"\n\t\"k8s.io/client-go/kubernetes\"\n\n\t//  allow out of cluster authentication\n\t_ \"k8s.io/client-go/plugin/pkg/client/auth\"\n\t\"k8s.io/client-go/rest\"\n\t\"k8s.io/client-go/tools/clientcmd\"\n\n\tistioversion \"istio.io/pkg/version\"\n)\n\nvar cronJobNameRegexp = regexp.MustCompile(`(.+)-\\d{8,10}$`)\n\n// BuildClientConfig builds a client rest config from a kubeconfig filepath and context.\n// It overrides the current context with the one provided (empty to use default).\n//\n// This is a modified version of k8s.io/client-go/tools/clientcmd/BuildConfigFromFlags with the\n// difference that it loads default configs if not running in-cluster.\nfunc BuildClientConfig(kubeconfig, context string) (*rest.Config, error) {\n\tc, err := BuildClientCmd(kubeconfig, context).ClientConfig()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn SetRestDefaults(c), nil\n}\n\n// BuildClientCmd builds a client cmd config from a kubeconfig filepath and context.\n// It overrides the current context with the one provided (empty to use default).\n//\n// This is a modified version of k8s.io/client-go/tools/clientcmd/BuildConfigFromFlags with the\n// difference that it loads default configs if not running in-cluster.\nfunc BuildClientCmd(kubeconfig, context string, overrides ...func(*clientcmd.ConfigOverrides)) clientcmd.ClientConfig {\n\tif kubeconfig != \"\" {\n\t\tinfo, err := os.Stat(kubeconfig)\n\t\tif err != nil || info.Size() == 0 {\n\t\t\t// If the specified kubeconfig doesn't exists / empty file / any other error\n\t\t\t// from file stat, fall back to default\n\t\t\tkubeconfig = \"\"\n\t\t}\n\t}\n\n\t// Config loading rules:\n\t// 1. kubeconfig if it not empty string\n\t// 2. Config(s) in KUBECONFIG environment variable\n\t// 3. In cluster config if running in-cluster\n\t// 4. Use $HOME/.kube/config\n\tloadingRules := clientcmd.NewDefaultClientConfigLoadingRules()\n\tloadingRules.DefaultClientConfig = &clientcmd.DefaultClientConfig\n\tloadingRules.ExplicitPath = kubeconfig\n\tconfigOverrides := &clientcmd.ConfigOverrides{\n\t\tClusterDefaults: clientcmd.ClusterDefaults,\n\t\tCurrentContext:  context,\n\t}\n\n\tfor _, fn := range overrides {\n\t\tfn(configOverrides)\n\t}\n\n\treturn clientcmd.NewNonInteractiveDeferredLoadingClientConfig(loadingRules, configOverrides)\n}\n\n// CreateClientset is a helper function that builds a kubernetes Clienset from a kubeconfig\n// filepath. See `BuildClientConfig` for kubeconfig loading rules.\nfunc CreateClientset(kubeconfig, context string, fns ...func(*rest.Config)) (*kubernetes.Clientset, error) {\n\tc, err := BuildClientConfig(kubeconfig, context)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"build client config: %v\", err)\n\t}\n\tfor _, fn := range fns {\n\t\tfn(c)\n\t}\n\treturn kubernetes.NewForConfig(c)\n}\n\n// DefaultRestConfig returns the rest.Config for the given kube config file and context.\nfunc DefaultRestConfig(kubeconfig, configContext string, fns ...func(*rest.Config)) (*rest.Config, error) {\n\tconfig, err := BuildClientConfig(kubeconfig, configContext)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tconfig = SetRestDefaults(config)\n\n\tfor _, fn := range fns {\n\t\tfn(config)\n\t}\n\n\treturn config, nil\n}\n\n// adjustCommand returns the last component of the\n// OS-specific command path for use in User-Agent.\nfunc adjustCommand(p string) string {\n\t// Unlikely, but better than returning \"\".\n\tif len(p) == 0 {\n\t\treturn \"unknown\"\n\t}\n\treturn filepath.Base(p)\n}\n\n// IstioUserAgent returns the user agent string based on the command being used.\n// example: pilot-discovery/1.9.5 or istioctl/1.10.0\n// This is a specialized version of rest.DefaultKubernetesUserAgent()\nfunc IstioUserAgent() string {\n\treturn adjustCommand(os.Args[0]) + \"/\" + istioversion.Info.Version\n}\n\n// SetRestDefaults is a helper function that sets default values for the given rest.Config.\n// This function is idempotent.\nfunc SetRestDefaults(config *rest.Config) *rest.Config {\n\tif config.GroupVersion == nil || config.GroupVersion.Empty() {\n\t\tconfig.GroupVersion = &kubeApiCore.SchemeGroupVersion\n\t}\n\tif len(config.APIPath) == 0 {\n\t\tif len(config.GroupVersion.Group) == 0 {\n\t\t\tconfig.APIPath = \"/api\"\n\t\t} else {\n\t\t\tconfig.APIPath = \"/apis\"\n\t\t}\n\t}\n\tif len(config.ContentType) == 0 {\n\t\tconfig.ContentType = runtime.ContentTypeJSON\n\t}\n\tif config.NegotiatedSerializer == nil {\n\t\t// This codec factory ensures the resources are not converted. Therefore, resources\n\t\t// will not be round-tripped through internal versions. Defaulting does not happen\n\t\t// on the client.\n\t\tconfig.NegotiatedSerializer = serializer.NewCodecFactory(IstioScheme).WithoutConversion()\n\t}\n\tif len(config.UserAgent) == 0 {\n\t\tconfig.UserAgent = IstioUserAgent()\n\t}\n\n\treturn config\n}\n\n// CheckPodReadyOrComplete returns nil if the given pod and all of its containers are ready or terminated\n// successfully.\nfunc CheckPodReadyOrComplete(pod *kubeApiCore.Pod) error {\n\tswitch pod.Status.Phase {\n\tcase kubeApiCore.PodSucceeded:\n\t\treturn nil\n\tcase kubeApiCore.PodRunning:\n\t\treturn CheckPodReady(pod)\n\tdefault:\n\t\treturn fmt.Errorf(\"%s\", pod.Status.Phase)\n\t}\n}\n\n// CheckPodReady returns nil if the given pod and all of its containers are ready.\nfunc CheckPodReady(pod *kubeApiCore.Pod) error {\n\tswitch pod.Status.Phase {\n\tcase kubeApiCore.PodRunning:\n\t\t// Wait until all containers are ready.\n\t\tfor _, containerStatus := range pod.Status.ContainerStatuses {\n\t\t\tif !containerStatus.Ready {\n\t\t\t\treturn fmt.Errorf(\"container not ready: '%s'\", containerStatus.Name)\n\t\t\t}\n\t\t}\n\t\tif len(pod.Status.Conditions) > 0 {\n\t\t\tfor _, condition := range pod.Status.Conditions {\n\t\t\t\tif condition.Type == kubeApiCore.PodReady && condition.Status != kubeApiCore.ConditionTrue {\n\t\t\t\t\treturn fmt.Errorf(\"pod not ready, condition message: %v\", condition.Message)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\tdefault:\n\t\treturn fmt.Errorf(\"%s\", pod.Status.Phase)\n\t}\n}\n\n// GetDeployMetaFromPod heuristically derives deployment metadata from the pod spec.\nfunc GetDeployMetaFromPod(pod *kubeApiCore.Pod) (metav1.ObjectMeta, metav1.TypeMeta) {\n\tif pod == nil {\n\t\treturn metav1.ObjectMeta{}, metav1.TypeMeta{}\n\t}\n\t// try to capture more useful namespace/name info for deployments, etc.\n\t// TODO(dougreid): expand to enable lookup of OWNERs recursively a la kubernetesenv\n\tdeployMeta := pod.ObjectMeta\n\tdeployMeta.ManagedFields = nil\n\tdeployMeta.OwnerReferences = nil\n\n\ttypeMetadata := metav1.TypeMeta{\n\t\tKind:       \"Pod\",\n\t\tAPIVersion: \"v1\",\n\t}\n\tif len(pod.GenerateName) > 0 {\n\t\t// if the pod name was generated (or is scheduled for generation), we can begin an investigation into the controlling reference for the pod.\n\t\tvar controllerRef metav1.OwnerReference\n\t\tcontrollerFound := false\n\t\tfor _, ref := range pod.GetOwnerReferences() {\n\t\t\tif ref.Controller != nil && *ref.Controller {\n\t\t\t\tcontrollerRef = ref\n\t\t\t\tcontrollerFound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif controllerFound {\n\t\t\ttypeMetadata.APIVersion = controllerRef.APIVersion\n\t\t\ttypeMetadata.Kind = controllerRef.Kind\n\n\t\t\t// heuristic for deployment detection\n\t\t\tdeployMeta.Name = controllerRef.Name\n\t\t\tif typeMetadata.Kind == \"ReplicaSet\" && pod.Labels[\"pod-template-hash\"] != \"\" && strings.HasSuffix(controllerRef.Name, pod.Labels[\"pod-template-hash\"]) {\n\t\t\t\tname := strings.TrimSuffix(controllerRef.Name, \"-\"+pod.Labels[\"pod-template-hash\"])\n\t\t\t\tdeployMeta.Name = name\n\t\t\t\ttypeMetadata.Kind = \"Deployment\"\n\t\t\t} else if typeMetadata.Kind == \"ReplicationController\" && pod.Labels[\"deploymentconfig\"] != \"\" {\n\t\t\t\t// If the pod is controlled by the replication controller, which is created by the DeploymentConfig resource in\n\t\t\t\t// Openshift platform, set the deploy name to the deployment config's name, and the kind to 'DeploymentConfig'.\n\t\t\t\t//\n\t\t\t\t// nolint: lll\n\t\t\t\t// For DeploymentConfig details, refer to\n\t\t\t\t// https://docs.openshift.com/container-platform/4.1/applications/deployments/what-deployments-are.html#deployments-and-deploymentconfigs_what-deployments-are\n\t\t\t\t//\n\t\t\t\t// For the reference to the pod label 'deploymentconfig', refer to\n\t\t\t\t// https://github.com/openshift/library-go/blob/7a65fdb398e28782ee1650959a5e0419121e97ae/pkg/apps/appsutil/const.go#L25\n\t\t\t\tdeployMeta.Name = pod.Labels[\"deploymentconfig\"]\n\t\t\t\ttypeMetadata.Kind = \"DeploymentConfig\"\n\t\t\t\tdelete(deployMeta.Labels, \"deploymentconfig\")\n\t\t\t} else if typeMetadata.Kind == \"Job\" {\n\t\t\t\t// If job name suffixed with `-<digit-timestamp>`, where the length of digit timestamp is 8~10,\n\t\t\t\t// trim the suffix and set kind to cron job.\n\t\t\t\tif jn := cronJobNameRegexp.FindStringSubmatch(controllerRef.Name); len(jn) == 2 {\n\t\t\t\t\tdeployMeta.Name = jn[1]\n\t\t\t\t\ttypeMetadata.Kind = \"CronJob\"\n\t\t\t\t\t// heuristically set cron job api version to v1beta1 as it cannot be derived from pod metadata.\n\t\t\t\t\t// Cronjob is not GA yet and latest version is v1beta1: https://github.com/kubernetes/enhancements/pull/978\n\t\t\t\t\ttypeMetadata.APIVersion = \"batch/v1beta1\"\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif deployMeta.Name == \"\" {\n\t\t// if we haven't been able to extract a deployment name, then just give it the pod name\n\t\tdeployMeta.Name = pod.Name\n\t}\n\n\treturn deployMeta, typeMetadata\n}\n\n// MaxRequestBodyBytes represents the max size of Kubernetes objects we read. Kubernetes allows a 2x\n// buffer on the max etcd size\n// (https://github.com/kubernetes/kubernetes/blob/0afa569499d480df4977568454a50790891860f5/staging/src/k8s.io/apiserver/pkg/server/config.go#L362).\n// We allow an additional 2x buffer, as it is still fairly cheap (6mb)\nconst MaxRequestBodyBytes = int64(6 * 1024 * 1024)\n\n// HTTPConfigReader is reads an HTTP request, imposing size restrictions aligned with Kubernetes limits\nfunc HTTPConfigReader(req *http.Request) ([]byte, error) {\n\tdefer req.Body.Close()\n\tlr := &io.LimitedReader{\n\t\tR: req.Body,\n\t\tN: MaxRequestBodyBytes + 1,\n\t}\n\tdata, err := io.ReadAll(lr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif lr.N <= 0 {\n\t\treturn nil, errors.NewRequestEntityTooLargeError(fmt.Sprintf(\"limit is %d\", MaxRequestBodyBytes))\n\t}\n\treturn data, nil\n}\n", "// Copyright Istio Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage server\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net/http\"\n\n\tmultierror \"github.com/hashicorp/go-multierror\"\n\tkubeApiAdmissionv1 \"k8s.io/api/admission/v1\"\n\tkubeApiAdmissionv1beta1 \"k8s.io/api/admission/v1beta1\"\n\tkubeApiApps \"k8s.io/api/apps/v1beta1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/runtime\"\n\t\"k8s.io/apimachinery/pkg/runtime/serializer\"\n\n\t\"istio.io/istio/pilot/pkg/config/kube/crd\"\n\t\"istio.io/istio/pkg/config/schema/collection\"\n\t\"istio.io/istio/pkg/config/schema/collections\"\n\t\"istio.io/istio/pkg/config/schema/resource\"\n\t\"istio.io/istio/pkg/config/validation\"\n\t\"istio.io/istio/pkg/kube\"\n\t\"istio.io/pkg/log\"\n)\n\nvar scope = log.RegisterScope(\"validationServer\", \"validation webhook server\", 0)\n\nvar (\n\truntimeScheme = runtime.NewScheme()\n\tcodecs        = serializer.NewCodecFactory(runtimeScheme)\n\tdeserializer  = codecs.UniversalDeserializer()\n\n\t// Expect AdmissionRequest to only include these top-level field names\n\tvalidFields = map[string]bool{\n\t\t\"apiVersion\": true,\n\t\t\"kind\":       true,\n\t\t\"metadata\":   true,\n\t\t\"spec\":       true,\n\t\t\"status\":     true,\n\t}\n)\n\nfunc init() {\n\t_ = kubeApiApps.AddToScheme(runtimeScheme)\n\t_ = kubeApiAdmissionv1.AddToScheme(runtimeScheme)\n\t_ = kubeApiAdmissionv1beta1.AddToScheme(runtimeScheme)\n}\n\n// Options contains the configuration for the Istio Pilot validation\n// admission controller.\ntype Options struct {\n\t// Schemas provides a description of all configuration resources.\n\tSchemas collection.Schemas\n\n\t// DomainSuffix is the DNS domain suffix for Pilot CRD resources,\n\t// e.g. cluster.local.\n\tDomainSuffix string\n\n\t// Port where the webhook is served. the number should be greater than 1024 for non-root\n\t// user, because non-root user cannot bind port number less than 1024\n\t// Mainly used for testing. Webhook server is started by Istiod.\n\tPort uint\n\n\t// Use an existing mux instead of creating our own.\n\tMux *http.ServeMux\n}\n\n// String produces a stringified version of the arguments for debugging.\nfunc (o Options) String() string {\n\tbuf := &bytes.Buffer{}\n\n\t_, _ = fmt.Fprintf(buf, \"DomainSuffix: %s\\n\", o.DomainSuffix)\n\t_, _ = fmt.Fprintf(buf, \"Port: %d\\n\", o.Port)\n\n\treturn buf.String()\n}\n\n// DefaultArgs allocates an Options struct initialized with Webhook's default configuration.\nfunc DefaultArgs() Options {\n\treturn Options{\n\t\tPort: 9443,\n\t}\n}\n\n// Webhook implements the validating admission webhook for validating Istio configuration.\ntype Webhook struct {\n\t// pilot\n\tschemas      collection.Schemas\n\tdomainSuffix string\n}\n\n// New creates a new instance of the admission webhook server.\nfunc New(o Options) (*Webhook, error) {\n\tif o.Mux == nil {\n\t\tscope.Error(\"mux not set correctly\")\n\t\treturn nil, errors.New(\"expected mux to be passed, but was not passed\")\n\t}\n\twh := &Webhook{\n\t\tschemas:      o.Schemas,\n\t\tdomainSuffix: o.DomainSuffix,\n\t}\n\n\to.Mux.HandleFunc(\"/validate\", wh.serveValidate)\n\to.Mux.HandleFunc(\"/validate/\", wh.serveValidate)\n\n\treturn wh, nil\n}\n\nfunc toAdmissionResponse(err error) *kube.AdmissionResponse {\n\treturn &kube.AdmissionResponse{Result: &metav1.Status{Message: err.Error()}}\n}\n\ntype admitFunc func(*kube.AdmissionRequest) *kube.AdmissionResponse\n\nfunc serve(w http.ResponseWriter, r *http.Request, admit admitFunc) {\n\tvar body []byte\n\tif r.Body != nil {\n\t\tif data, err := kube.HTTPConfigReader(r); err == nil {\n\t\t\tbody = data\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\tif len(body) == 0 {\n\t\treportValidationHTTPError(http.StatusBadRequest)\n\t\thttp.Error(w, \"no body found\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// verify the content type is accurate\n\tcontentType := r.Header.Get(\"Content-Type\")\n\tif contentType != \"application/json\" {\n\t\treportValidationHTTPError(http.StatusUnsupportedMediaType)\n\t\thttp.Error(w, \"invalid Content-Type, want `application/json`\", http.StatusUnsupportedMediaType)\n\t\treturn\n\t}\n\n\tvar reviewResponse *kube.AdmissionResponse\n\tvar obj runtime.Object\n\tvar ar *kube.AdmissionReview\n\tif out, _, err := deserializer.Decode(body, nil, obj); err != nil {\n\t\treviewResponse = toAdmissionResponse(fmt.Errorf(\"could not decode body: %v\", err))\n\t} else {\n\t\tar, err = kube.AdmissionReviewKubeToAdapter(out)\n\t\tif err != nil {\n\t\t\treviewResponse = toAdmissionResponse(fmt.Errorf(\"could not decode object: %v\", err))\n\t\t} else {\n\t\t\treviewResponse = admit(ar.Request)\n\t\t}\n\t}\n\n\tresponse := kube.AdmissionReview{}\n\tresponse.Response = reviewResponse\n\tvar responseKube runtime.Object\n\tvar apiVersion string\n\tif ar != nil {\n\t\tapiVersion = ar.APIVersion\n\t\tresponse.TypeMeta = ar.TypeMeta\n\t\tif response.Response != nil {\n\t\t\tif ar.Request != nil {\n\t\t\t\tresponse.Response.UID = ar.Request.UID\n\t\t\t}\n\t\t}\n\t}\n\tresponseKube = kube.AdmissionReviewAdapterToKube(&response, apiVersion)\n\tresp, err := json.Marshal(responseKube)\n\tif err != nil {\n\t\treportValidationHTTPError(http.StatusInternalServerError)\n\t\thttp.Error(w, fmt.Sprintf(\"could encode response: %v\", err), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tif _, err := w.Write(resp); err != nil {\n\t\treportValidationHTTPError(http.StatusInternalServerError)\n\t\thttp.Error(w, fmt.Sprintf(\"could write response: %v\", err), http.StatusInternalServerError)\n\t}\n}\n\nfunc (wh *Webhook) serveValidate(w http.ResponseWriter, r *http.Request) {\n\tserve(w, r, wh.validate)\n}\n\nfunc (wh *Webhook) validate(request *kube.AdmissionRequest) *kube.AdmissionResponse {\n\tswitch request.Operation {\n\tcase kube.Create, kube.Update:\n\tdefault:\n\t\tscope.Warnf(\"Unsupported webhook operation %v\", request.Operation)\n\t\treportValidationFailed(request, reasonUnsupportedOperation)\n\t\treturn &kube.AdmissionResponse{Allowed: true}\n\t}\n\n\tvar obj crd.IstioKind\n\tif err := json.Unmarshal(request.Object.Raw, &obj); err != nil {\n\t\tscope.Infof(\"cannot decode configuration: %v\", err)\n\t\treportValidationFailed(request, reasonYamlDecodeError)\n\t\treturn toAdmissionResponse(fmt.Errorf(\"cannot decode configuration: %v\", err))\n\t}\n\n\tgvk := obj.GroupVersionKind()\n\n\t// TODO(jasonwzm) remove this when multi-version is supported. v1beta1 shares the same\n\t// schema as v1lalpha3. Fake conversion and validate against v1alpha3.\n\tif gvk.Group == \"networking.istio.io\" && gvk.Version == \"v1beta1\" &&\n\t\t// ProxyConfig CR is stored as v1beta1 since it was introduced as v1beta1\n\t\tgvk.Kind != collections.IstioNetworkingV1Beta1Proxyconfigs.Resource().Kind() {\n\t\tgvk.Version = \"v1alpha3\"\n\t}\n\ts, exists := wh.schemas.FindByGroupVersionKind(resource.FromKubernetesGVK(&gvk))\n\tif !exists {\n\t\tscope.Infof(\"unrecognized type %v\", obj.GroupVersionKind())\n\t\treportValidationFailed(request, reasonUnknownType)\n\t\treturn toAdmissionResponse(fmt.Errorf(\"unrecognized type %v\", obj.GroupVersionKind()))\n\t}\n\n\tout, err := crd.ConvertObject(s, &obj, wh.domainSuffix)\n\tif err != nil {\n\t\tscope.Infof(\"error decoding configuration: %v\", err)\n\t\treportValidationFailed(request, reasonCRDConversionError)\n\t\treturn toAdmissionResponse(fmt.Errorf(\"error decoding configuration: %v\", err))\n\t}\n\n\twarnings, err := s.Resource().ValidateConfig(*out)\n\tif err != nil {\n\t\tscope.Infof(\"configuration is invalid: %v\", err)\n\t\treportValidationFailed(request, reasonInvalidConfig)\n\t\treturn toAdmissionResponse(fmt.Errorf(\"configuration is invalid: %v\", err))\n\t}\n\n\tif reason, err := checkFields(request.Object.Raw, request.Kind.Kind, request.Namespace, obj.Name); err != nil {\n\t\treportValidationFailed(request, reason)\n\t\treturn toAdmissionResponse(err)\n\t}\n\n\treportValidationPass(request)\n\treturn &kube.AdmissionResponse{Allowed: true, Warnings: toKubeWarnings(warnings)}\n}\n\nfunc toKubeWarnings(warn validation.Warning) []string {\n\tif warn == nil {\n\t\treturn nil\n\t}\n\tme, ok := warn.(*multierror.Error)\n\tif ok {\n\t\tres := []string{}\n\t\tfor _, e := range me.Errors {\n\t\t\tres = append(res, e.Error())\n\t\t}\n\t\treturn res\n\t}\n\treturn []string{warn.Error()}\n}\n\nfunc checkFields(raw []byte, kind string, namespace string, name string) (string, error) {\n\ttrial := make(map[string]json.RawMessage)\n\tif err := json.Unmarshal(raw, &trial); err != nil {\n\t\tscope.Infof(\"cannot decode configuration fields: %v\", err)\n\t\treturn reasonYamlDecodeError, fmt.Errorf(\"cannot decode configuration fields: %v\", err)\n\t}\n\n\tfor key := range trial {\n\t\tif _, ok := validFields[key]; !ok {\n\t\t\tscope.Infof(\"unknown field %q on %s resource %s/%s\",\n\t\t\t\tkey, kind, namespace, name)\n\t\t\treturn reasonInvalidConfig, fmt.Errorf(\"unknown field %q on %s resource %s/%s\",\n\t\t\t\tkey, kind, namespace, name)\n\t\t}\n\t}\n\n\treturn \"\", nil\n}\n\n// validatePort checks that the network port is in range\nfunc validatePort(port int) error {\n\tif 1 <= port && port <= 65535 {\n\t\treturn nil\n\t}\n\treturn fmt.Errorf(\"port number %d must be in the range 1..65535\", port)\n}\n\n// Validate tests if the Options has valid params.\nfunc (o Options) Validate() error {\n\tvar errs *multierror.Error\n\tif err := validatePort(int(o.Port)); err != nil {\n\t\terrs = multierror.Append(errs, err)\n\t}\n\treturn errs.ErrorOrNil()\n}\n"], "filenames": ["pkg/kube/inject/webhook.go", "pkg/kube/util.go", "pkg/webhooks/validation/server/server.go"], "buggy_code_start_loc": [22, 18, 22], "buggy_code_end_loc": [831, 267, 135], "fixing_code_start_loc": [21, 19, 21], "fixing_code_end_loc": [834, 294, 138], "type": "CWE-400", "message": "Istio is an open platform to connect, manage, and secure microservices. In affected versions the Istio control plane, istiod, is vulnerable to a request processing error, allowing a malicious attacker that sends a specially crafted message which results in the control plane crashing when the validating webhook for a cluster is exposed publicly. This endpoint is served over TLS port 15017, but does not require any authentication from the attacker. For simple installations, Istiod is typically only reachable from within the cluster, limiting the blast radius. However, for some deployments, especially [external istiod](https://istio.io/latest/docs/setup/install/external-controlplane/) topologies, this port is exposed over the public internet. This issue has been patched in versions 1.13.2, 1.12.5 and 1.11.8. Users are advised to upgrade. Users unable to upgrade should disable access to a validating webhook that is exposed to the public internet or restrict the set of IP addresses that can query it to a set of known, trusted entities.", "other": {"cve": {"id": "CVE-2022-24726", "sourceIdentifier": "security-advisories@github.com", "published": "2022-03-10T21:15:14.603", "lastModified": "2022-03-18T20:20:42.910", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Istio is an open platform to connect, manage, and secure microservices. In affected versions the Istio control plane, istiod, is vulnerable to a request processing error, allowing a malicious attacker that sends a specially crafted message which results in the control plane crashing when the validating webhook for a cluster is exposed publicly. This endpoint is served over TLS port 15017, but does not require any authentication from the attacker. For simple installations, Istiod is typically only reachable from within the cluster, limiting the blast radius. However, for some deployments, especially [external istiod](https://istio.io/latest/docs/setup/install/external-controlplane/) topologies, this port is exposed over the public internet. This issue has been patched in versions 1.13.2, 1.12.5 and 1.11.8. Users are advised to upgrade. Users unable to upgrade should disable access to a validating webhook that is exposed to the public internet or restrict the set of IP addresses that can query it to a set of known, trusted entities."}, {"lang": "es", "value": "Istio es una plataforma abierta para conectar, administrar y asegurar microservicios. En las versiones afectadas, el plano de control de Istio, istiod, es vulnerable a un error de procesamiento de peticiones, permitiendo a un atacante malicioso que env\u00ede un mensaje especialmente dise\u00f1ado que resulte en el bloqueo del plano de control cuando el webhook de comprobaci\u00f3n de un cl\u00faster se exponga p\u00fablicamente. Este endpoint es servido a trav\u00e9s del puerto 15017 de TLS, pero no requiere ninguna autenticaci\u00f3n por parte del atacante. Para instalaciones sencillas, Istiod normalmente s\u00f3lo es accesible desde dentro del cl\u00faster, limitando el radio de explosi\u00f3n. Sin embargo, para algunos despliegues, especialmente las topolog\u00edas de [istiod externo](https://istio.io/latest/docs/setup/install/external-controlplane/), este puerto est\u00e1 expuesto a trav\u00e9s de la Internet p\u00fablica. Este problema ha sido parcheado en las versiones 1.13.2, 1.12.5 y 1.11.8. Es recomendado a usuarios actualizar. Los usuarios que no puedan actualizarse deben deshabilitar el acceso a un webhook de comprobaci\u00f3n que est\u00e9 expuesto a la Internet p\u00fablica o restringir el conjunto de direcciones IP que pueden consultarlo a un conjunto de entidades conocidas y confiables"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-400"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-400"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:istio:istio:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.11.8", "matchCriteriaId": "E255ACB0-90AB-4FC4-AC4B-D7DE613A115E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:istio:istio:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.12.0", "versionEndExcluding": "1.12.5", "matchCriteriaId": "93FFCE9E-9ECF-4B07-B18B-1B73C313CE2C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:istio:istio:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.13.0", "versionEndExcluding": "1.13.2", "matchCriteriaId": "3C6F7ADF-2FD8-4986-A6F2-0000CC5770D4"}]}]}], "references": [{"url": "https://github.com/golang/go/issues/51112", "source": "security-advisories@github.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/istio/istio/commit/6ca5055a4db6695ef5504eabdfde3799f2ea91fd", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/istio/istio/security/advisories/GHSA-8w5h-qr4r-2h6g", "source": "security-advisories@github.com", "tags": ["Issue Tracking", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/istio/istio/commit/6ca5055a4db6695ef5504eabdfde3799f2ea91fd"}}
{"buggy_code": ["/*\n * net/tipc/socket.c: TIPC socket API\n *\n * Copyright (c) 2001-2007, 2012-2019, Ericsson AB\n * Copyright (c) 2004-2008, 2010-2013, Wind River Systems\n * Copyright (c) 2020-2021, Red Hat Inc\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. Neither the names of the copyright holders nor the names of its\n *    contributors may be used to endorse or promote products derived from\n *    this software without specific prior written permission.\n *\n * Alternatively, this software may be distributed under the terms of the\n * GNU General Public License (\"GPL\") version 2 as published by the Free\n * Software Foundation.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include <linux/rhashtable.h>\n#include <linux/sched/signal.h>\n\n#include \"core.h\"\n#include \"name_table.h\"\n#include \"node.h\"\n#include \"link.h\"\n#include \"name_distr.h\"\n#include \"socket.h\"\n#include \"bcast.h\"\n#include \"netlink.h\"\n#include \"group.h\"\n#include \"trace.h\"\n\n#define NAGLE_START_INIT\t4\n#define NAGLE_START_MAX\t\t1024\n#define CONN_TIMEOUT_DEFAULT    8000    /* default connect timeout = 8s */\n#define CONN_PROBING_INTV\tmsecs_to_jiffies(3600000)  /* [ms] => 1 h */\n#define TIPC_MAX_PORT\t\t0xffffffff\n#define TIPC_MIN_PORT\t\t1\n#define TIPC_ACK_RATE\t\t4       /* ACK at 1/4 of rcv window size */\n\nenum {\n\tTIPC_LISTEN = TCP_LISTEN,\n\tTIPC_ESTABLISHED = TCP_ESTABLISHED,\n\tTIPC_OPEN = TCP_CLOSE,\n\tTIPC_DISCONNECTING = TCP_CLOSE_WAIT,\n\tTIPC_CONNECTING = TCP_SYN_SENT,\n};\n\nstruct sockaddr_pair {\n\tstruct sockaddr_tipc sock;\n\tstruct sockaddr_tipc member;\n};\n\n/**\n * struct tipc_sock - TIPC socket structure\n * @sk: socket - interacts with 'port' and with user via the socket API\n * @max_pkt: maximum packet size \"hint\" used when building messages sent by port\n * @maxnagle: maximum size of msg which can be subject to nagle\n * @portid: unique port identity in TIPC socket hash table\n * @phdr: preformatted message header used when sending messages\n * @cong_links: list of congested links\n * @publications: list of publications for port\n * @blocking_link: address of the congested link we are currently sleeping on\n * @pub_count: total # of publications port has made during its lifetime\n * @conn_timeout: the time we can wait for an unresponded setup request\n * @probe_unacked: probe has not received ack yet\n * @dupl_rcvcnt: number of bytes counted twice, in both backlog and rcv queue\n * @cong_link_cnt: number of congested links\n * @snt_unacked: # messages sent by socket, and not yet acked by peer\n * @snd_win: send window size\n * @peer_caps: peer capabilities mask\n * @rcv_unacked: # messages read by user, but not yet acked back to peer\n * @rcv_win: receive window size\n * @peer: 'connected' peer for dgram/rdm\n * @node: hash table node\n * @mc_method: cookie for use between socket and broadcast layer\n * @rcu: rcu struct for tipc_sock\n * @group: TIPC communications group\n * @oneway: message count in one direction (FIXME)\n * @nagle_start: current nagle value\n * @snd_backlog: send backlog count\n * @msg_acc: messages accepted; used in managing backlog and nagle\n * @pkt_cnt: TIPC socket packet count\n * @expect_ack: whether this TIPC socket is expecting an ack\n * @nodelay: setsockopt() TIPC_NODELAY setting\n * @group_is_open: TIPC socket group is fully open (FIXME)\n * @published: true if port has one or more associated names\n * @conn_addrtype: address type used when establishing connection\n */\nstruct tipc_sock {\n\tstruct sock sk;\n\tu32 max_pkt;\n\tu32 maxnagle;\n\tu32 portid;\n\tstruct tipc_msg phdr;\n\tstruct list_head cong_links;\n\tstruct list_head publications;\n\tu32 pub_count;\n\tatomic_t dupl_rcvcnt;\n\tu16 conn_timeout;\n\tbool probe_unacked;\n\tu16 cong_link_cnt;\n\tu16 snt_unacked;\n\tu16 snd_win;\n\tu16 peer_caps;\n\tu16 rcv_unacked;\n\tu16 rcv_win;\n\tstruct sockaddr_tipc peer;\n\tstruct rhash_head node;\n\tstruct tipc_mc_method mc_method;\n\tstruct rcu_head rcu;\n\tstruct tipc_group *group;\n\tu32 oneway;\n\tu32 nagle_start;\n\tu16 snd_backlog;\n\tu16 msg_acc;\n\tu16 pkt_cnt;\n\tbool expect_ack;\n\tbool nodelay;\n\tbool group_is_open;\n\tbool published;\n\tu8 conn_addrtype;\n};\n\nstatic int tipc_sk_backlog_rcv(struct sock *sk, struct sk_buff *skb);\nstatic void tipc_data_ready(struct sock *sk);\nstatic void tipc_write_space(struct sock *sk);\nstatic void tipc_sock_destruct(struct sock *sk);\nstatic int tipc_release(struct socket *sock);\nstatic int tipc_accept(struct socket *sock, struct socket *new_sock, int flags,\n\t\t       bool kern);\nstatic void tipc_sk_timeout(struct timer_list *t);\nstatic int tipc_sk_publish(struct tipc_sock *tsk, struct tipc_uaddr *ua);\nstatic int tipc_sk_withdraw(struct tipc_sock *tsk, struct tipc_uaddr *ua);\nstatic int tipc_sk_leave(struct tipc_sock *tsk);\nstatic struct tipc_sock *tipc_sk_lookup(struct net *net, u32 portid);\nstatic int tipc_sk_insert(struct tipc_sock *tsk);\nstatic void tipc_sk_remove(struct tipc_sock *tsk);\nstatic int __tipc_sendstream(struct socket *sock, struct msghdr *m, size_t dsz);\nstatic int __tipc_sendmsg(struct socket *sock, struct msghdr *m, size_t dsz);\nstatic void tipc_sk_push_backlog(struct tipc_sock *tsk, bool nagle_ack);\nstatic int tipc_wait_for_connect(struct socket *sock, long *timeo_p);\n\nstatic const struct proto_ops packet_ops;\nstatic const struct proto_ops stream_ops;\nstatic const struct proto_ops msg_ops;\nstatic struct proto tipc_proto;\nstatic const struct rhashtable_params tsk_rht_params;\n\nstatic u32 tsk_own_node(struct tipc_sock *tsk)\n{\n\treturn msg_prevnode(&tsk->phdr);\n}\n\nstatic u32 tsk_peer_node(struct tipc_sock *tsk)\n{\n\treturn msg_destnode(&tsk->phdr);\n}\n\nstatic u32 tsk_peer_port(struct tipc_sock *tsk)\n{\n\treturn msg_destport(&tsk->phdr);\n}\n\nstatic  bool tsk_unreliable(struct tipc_sock *tsk)\n{\n\treturn msg_src_droppable(&tsk->phdr) != 0;\n}\n\nstatic void tsk_set_unreliable(struct tipc_sock *tsk, bool unreliable)\n{\n\tmsg_set_src_droppable(&tsk->phdr, unreliable ? 1 : 0);\n}\n\nstatic bool tsk_unreturnable(struct tipc_sock *tsk)\n{\n\treturn msg_dest_droppable(&tsk->phdr) != 0;\n}\n\nstatic void tsk_set_unreturnable(struct tipc_sock *tsk, bool unreturnable)\n{\n\tmsg_set_dest_droppable(&tsk->phdr, unreturnable ? 1 : 0);\n}\n\nstatic int tsk_importance(struct tipc_sock *tsk)\n{\n\treturn msg_importance(&tsk->phdr);\n}\n\nstatic struct tipc_sock *tipc_sk(const struct sock *sk)\n{\n\treturn container_of(sk, struct tipc_sock, sk);\n}\n\nint tsk_set_importance(struct sock *sk, int imp)\n{\n\tif (imp > TIPC_CRITICAL_IMPORTANCE)\n\t\treturn -EINVAL;\n\tmsg_set_importance(&tipc_sk(sk)->phdr, (u32)imp);\n\treturn 0;\n}\n\nstatic bool tsk_conn_cong(struct tipc_sock *tsk)\n{\n\treturn tsk->snt_unacked > tsk->snd_win;\n}\n\nstatic u16 tsk_blocks(int len)\n{\n\treturn ((len / FLOWCTL_BLK_SZ) + 1);\n}\n\n/* tsk_blocks(): translate a buffer size in bytes to number of\n * advertisable blocks, taking into account the ratio truesize(len)/len\n * We can trust that this ratio is always < 4 for len >= FLOWCTL_BLK_SZ\n */\nstatic u16 tsk_adv_blocks(int len)\n{\n\treturn len / FLOWCTL_BLK_SZ / 4;\n}\n\n/* tsk_inc(): increment counter for sent or received data\n * - If block based flow control is not supported by peer we\n *   fall back to message based ditto, incrementing the counter\n */\nstatic u16 tsk_inc(struct tipc_sock *tsk, int msglen)\n{\n\tif (likely(tsk->peer_caps & TIPC_BLOCK_FLOWCTL))\n\t\treturn ((msglen / FLOWCTL_BLK_SZ) + 1);\n\treturn 1;\n}\n\n/* tsk_set_nagle - enable/disable nagle property by manipulating maxnagle\n */\nstatic void tsk_set_nagle(struct tipc_sock *tsk)\n{\n\tstruct sock *sk = &tsk->sk;\n\n\ttsk->maxnagle = 0;\n\tif (sk->sk_type != SOCK_STREAM)\n\t\treturn;\n\tif (tsk->nodelay)\n\t\treturn;\n\tif (!(tsk->peer_caps & TIPC_NAGLE))\n\t\treturn;\n\t/* Limit node local buffer size to avoid receive queue overflow */\n\tif (tsk->max_pkt == MAX_MSG_SIZE)\n\t\ttsk->maxnagle = 1500;\n\telse\n\t\ttsk->maxnagle = tsk->max_pkt;\n}\n\n/**\n * tsk_advance_rx_queue - discard first buffer in socket receive queue\n * @sk: network socket\n *\n * Caller must hold socket lock\n */\nstatic void tsk_advance_rx_queue(struct sock *sk)\n{\n\ttrace_tipc_sk_advance_rx(sk, NULL, TIPC_DUMP_SK_RCVQ, \" \");\n\tkfree_skb(__skb_dequeue(&sk->sk_receive_queue));\n}\n\n/* tipc_sk_respond() : send response message back to sender\n */\nstatic void tipc_sk_respond(struct sock *sk, struct sk_buff *skb, int err)\n{\n\tu32 selector;\n\tu32 dnode;\n\tu32 onode = tipc_own_addr(sock_net(sk));\n\n\tif (!tipc_msg_reverse(onode, &skb, err))\n\t\treturn;\n\n\ttrace_tipc_sk_rej_msg(sk, skb, TIPC_DUMP_NONE, \"@sk_respond!\");\n\tdnode = msg_destnode(buf_msg(skb));\n\tselector = msg_origport(buf_msg(skb));\n\ttipc_node_xmit_skb(sock_net(sk), skb, dnode, selector);\n}\n\n/**\n * tsk_rej_rx_queue - reject all buffers in socket receive queue\n * @sk: network socket\n * @error: response error code\n *\n * Caller must hold socket lock\n */\nstatic void tsk_rej_rx_queue(struct sock *sk, int error)\n{\n\tstruct sk_buff *skb;\n\n\twhile ((skb = __skb_dequeue(&sk->sk_receive_queue)))\n\t\ttipc_sk_respond(sk, skb, error);\n}\n\nstatic bool tipc_sk_connected(struct sock *sk)\n{\n\treturn sk->sk_state == TIPC_ESTABLISHED;\n}\n\n/* tipc_sk_type_connectionless - check if the socket is datagram socket\n * @sk: socket\n *\n * Returns true if connection less, false otherwise\n */\nstatic bool tipc_sk_type_connectionless(struct sock *sk)\n{\n\treturn sk->sk_type == SOCK_RDM || sk->sk_type == SOCK_DGRAM;\n}\n\n/* tsk_peer_msg - verify if message was sent by connected port's peer\n *\n * Handles cases where the node's network address has changed from\n * the default of <0.0.0> to its configured setting.\n */\nstatic bool tsk_peer_msg(struct tipc_sock *tsk, struct tipc_msg *msg)\n{\n\tstruct sock *sk = &tsk->sk;\n\tu32 self = tipc_own_addr(sock_net(sk));\n\tu32 peer_port = tsk_peer_port(tsk);\n\tu32 orig_node, peer_node;\n\n\tif (unlikely(!tipc_sk_connected(sk)))\n\t\treturn false;\n\n\tif (unlikely(msg_origport(msg) != peer_port))\n\t\treturn false;\n\n\torig_node = msg_orignode(msg);\n\tpeer_node = tsk_peer_node(tsk);\n\n\tif (likely(orig_node == peer_node))\n\t\treturn true;\n\n\tif (!orig_node && peer_node == self)\n\t\treturn true;\n\n\tif (!peer_node && orig_node == self)\n\t\treturn true;\n\n\treturn false;\n}\n\n/* tipc_set_sk_state - set the sk_state of the socket\n * @sk: socket\n *\n * Caller must hold socket lock\n *\n * Returns 0 on success, errno otherwise\n */\nstatic int tipc_set_sk_state(struct sock *sk, int state)\n{\n\tint oldsk_state = sk->sk_state;\n\tint res = -EINVAL;\n\n\tswitch (state) {\n\tcase TIPC_OPEN:\n\t\tres = 0;\n\t\tbreak;\n\tcase TIPC_LISTEN:\n\tcase TIPC_CONNECTING:\n\t\tif (oldsk_state == TIPC_OPEN)\n\t\t\tres = 0;\n\t\tbreak;\n\tcase TIPC_ESTABLISHED:\n\t\tif (oldsk_state == TIPC_CONNECTING ||\n\t\t    oldsk_state == TIPC_OPEN)\n\t\t\tres = 0;\n\t\tbreak;\n\tcase TIPC_DISCONNECTING:\n\t\tif (oldsk_state == TIPC_CONNECTING ||\n\t\t    oldsk_state == TIPC_ESTABLISHED)\n\t\t\tres = 0;\n\t\tbreak;\n\t}\n\n\tif (!res)\n\t\tsk->sk_state = state;\n\n\treturn res;\n}\n\nstatic int tipc_sk_sock_err(struct socket *sock, long *timeout)\n{\n\tstruct sock *sk = sock->sk;\n\tint err = sock_error(sk);\n\tint typ = sock->type;\n\n\tif (err)\n\t\treturn err;\n\tif (typ == SOCK_STREAM || typ == SOCK_SEQPACKET) {\n\t\tif (sk->sk_state == TIPC_DISCONNECTING)\n\t\t\treturn -EPIPE;\n\t\telse if (!tipc_sk_connected(sk))\n\t\t\treturn -ENOTCONN;\n\t}\n\tif (!*timeout)\n\t\treturn -EAGAIN;\n\tif (signal_pending(current))\n\t\treturn sock_intr_errno(*timeout);\n\n\treturn 0;\n}\n\n#define tipc_wait_for_cond(sock_, timeo_, condition_)\t\t\t       \\\n({                                                                             \\\n\tDEFINE_WAIT_FUNC(wait_, woken_wake_function);                          \\\n\tstruct sock *sk_;\t\t\t\t\t\t       \\\n\tint rc_;\t\t\t\t\t\t\t       \\\n\t\t\t\t\t\t\t\t\t       \\\n\twhile ((rc_ = !(condition_))) {\t\t\t\t\t       \\\n\t\t/* coupled with smp_wmb() in tipc_sk_proto_rcv() */            \\\n\t\tsmp_rmb();                                                     \\\n\t\tsk_ = (sock_)->sk;\t\t\t\t\t       \\\n\t\trc_ = tipc_sk_sock_err((sock_), timeo_);\t\t       \\\n\t\tif (rc_)\t\t\t\t\t\t       \\\n\t\t\tbreak;\t\t\t\t\t\t       \\\n\t\tadd_wait_queue(sk_sleep(sk_), &wait_);                         \\\n\t\trelease_sock(sk_);\t\t\t\t\t       \\\n\t\t*(timeo_) = wait_woken(&wait_, TASK_INTERRUPTIBLE, *(timeo_)); \\\n\t\tsched_annotate_sleep();\t\t\t\t               \\\n\t\tlock_sock(sk_);\t\t\t\t\t\t       \\\n\t\tremove_wait_queue(sk_sleep(sk_), &wait_);\t\t       \\\n\t}\t\t\t\t\t\t\t\t       \\\n\trc_;\t\t\t\t\t\t\t\t       \\\n})\n\n/**\n * tipc_sk_create - create a TIPC socket\n * @net: network namespace (must be default network)\n * @sock: pre-allocated socket structure\n * @protocol: protocol indicator (must be 0)\n * @kern: caused by kernel or by userspace?\n *\n * This routine creates additional data structures used by the TIPC socket,\n * initializes them, and links them together.\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_sk_create(struct net *net, struct socket *sock,\n\t\t\t  int protocol, int kern)\n{\n\tconst struct proto_ops *ops;\n\tstruct sock *sk;\n\tstruct tipc_sock *tsk;\n\tstruct tipc_msg *msg;\n\n\t/* Validate arguments */\n\tif (unlikely(protocol != 0))\n\t\treturn -EPROTONOSUPPORT;\n\n\tswitch (sock->type) {\n\tcase SOCK_STREAM:\n\t\tops = &stream_ops;\n\t\tbreak;\n\tcase SOCK_SEQPACKET:\n\t\tops = &packet_ops;\n\t\tbreak;\n\tcase SOCK_DGRAM:\n\tcase SOCK_RDM:\n\t\tops = &msg_ops;\n\t\tbreak;\n\tdefault:\n\t\treturn -EPROTOTYPE;\n\t}\n\n\t/* Allocate socket's protocol area */\n\tsk = sk_alloc(net, AF_TIPC, GFP_KERNEL, &tipc_proto, kern);\n\tif (sk == NULL)\n\t\treturn -ENOMEM;\n\n\ttsk = tipc_sk(sk);\n\ttsk->max_pkt = MAX_PKT_DEFAULT;\n\ttsk->maxnagle = 0;\n\ttsk->nagle_start = NAGLE_START_INIT;\n\tINIT_LIST_HEAD(&tsk->publications);\n\tINIT_LIST_HEAD(&tsk->cong_links);\n\tmsg = &tsk->phdr;\n\n\t/* Finish initializing socket data structures */\n\tsock->ops = ops;\n\tsock_init_data(sock, sk);\n\ttipc_set_sk_state(sk, TIPC_OPEN);\n\tif (tipc_sk_insert(tsk)) {\n\t\tpr_warn(\"Socket create failed; port number exhausted\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Ensure tsk is visible before we read own_addr. */\n\tsmp_mb();\n\n\ttipc_msg_init(tipc_own_addr(net), msg, TIPC_LOW_IMPORTANCE,\n\t\t      TIPC_NAMED_MSG, NAMED_H_SIZE, 0);\n\n\tmsg_set_origport(msg, tsk->portid);\n\ttimer_setup(&sk->sk_timer, tipc_sk_timeout, 0);\n\tsk->sk_shutdown = 0;\n\tsk->sk_backlog_rcv = tipc_sk_backlog_rcv;\n\tsk->sk_rcvbuf = sysctl_tipc_rmem[1];\n\tsk->sk_data_ready = tipc_data_ready;\n\tsk->sk_write_space = tipc_write_space;\n\tsk->sk_destruct = tipc_sock_destruct;\n\ttsk->conn_timeout = CONN_TIMEOUT_DEFAULT;\n\ttsk->group_is_open = true;\n\tatomic_set(&tsk->dupl_rcvcnt, 0);\n\n\t/* Start out with safe limits until we receive an advertised window */\n\ttsk->snd_win = tsk_adv_blocks(RCVBUF_MIN);\n\ttsk->rcv_win = tsk->snd_win;\n\n\tif (tipc_sk_type_connectionless(sk)) {\n\t\ttsk_set_unreturnable(tsk, true);\n\t\tif (sock->type == SOCK_DGRAM)\n\t\t\ttsk_set_unreliable(tsk, true);\n\t}\n\t__skb_queue_head_init(&tsk->mc_method.deferredq);\n\ttrace_tipc_sk_create(sk, NULL, TIPC_DUMP_NONE, \" \");\n\treturn 0;\n}\n\nstatic void tipc_sk_callback(struct rcu_head *head)\n{\n\tstruct tipc_sock *tsk = container_of(head, struct tipc_sock, rcu);\n\n\tsock_put(&tsk->sk);\n}\n\n/* Caller should hold socket lock for the socket. */\nstatic void __tipc_shutdown(struct socket *sock, int error)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tlong timeout = msecs_to_jiffies(CONN_TIMEOUT_DEFAULT);\n\tu32 dnode = tsk_peer_node(tsk);\n\tstruct sk_buff *skb;\n\n\t/* Avoid that hi-prio shutdown msgs bypass msgs in link wakeup queue */\n\ttipc_wait_for_cond(sock, &timeout, (!tsk->cong_link_cnt &&\n\t\t\t\t\t    !tsk_conn_cong(tsk)));\n\n\t/* Push out delayed messages if in Nagle mode */\n\ttipc_sk_push_backlog(tsk, false);\n\t/* Remove pending SYN */\n\t__skb_queue_purge(&sk->sk_write_queue);\n\n\t/* Remove partially received buffer if any */\n\tskb = skb_peek(&sk->sk_receive_queue);\n\tif (skb && TIPC_SKB_CB(skb)->bytes_read) {\n\t\t__skb_unlink(skb, &sk->sk_receive_queue);\n\t\tkfree_skb(skb);\n\t}\n\n\t/* Reject all unreceived messages if connectionless */\n\tif (tipc_sk_type_connectionless(sk)) {\n\t\ttsk_rej_rx_queue(sk, error);\n\t\treturn;\n\t}\n\n\tswitch (sk->sk_state) {\n\tcase TIPC_CONNECTING:\n\tcase TIPC_ESTABLISHED:\n\t\ttipc_set_sk_state(sk, TIPC_DISCONNECTING);\n\t\ttipc_node_remove_conn(net, dnode, tsk->portid);\n\t\t/* Send a FIN+/- to its peer */\n\t\tskb = __skb_dequeue(&sk->sk_receive_queue);\n\t\tif (skb) {\n\t\t\t__skb_queue_purge(&sk->sk_receive_queue);\n\t\t\ttipc_sk_respond(sk, skb, error);\n\t\t\tbreak;\n\t\t}\n\t\tskb = tipc_msg_create(TIPC_CRITICAL_IMPORTANCE,\n\t\t\t\t      TIPC_CONN_MSG, SHORT_H_SIZE, 0, dnode,\n\t\t\t\t      tsk_own_node(tsk), tsk_peer_port(tsk),\n\t\t\t\t      tsk->portid, error);\n\t\tif (skb)\n\t\t\ttipc_node_xmit_skb(net, skb, dnode, tsk->portid);\n\t\tbreak;\n\tcase TIPC_LISTEN:\n\t\t/* Reject all SYN messages */\n\t\ttsk_rej_rx_queue(sk, error);\n\t\tbreak;\n\tdefault:\n\t\t__skb_queue_purge(&sk->sk_receive_queue);\n\t\tbreak;\n\t}\n}\n\n/**\n * tipc_release - destroy a TIPC socket\n * @sock: socket to destroy\n *\n * This routine cleans up any messages that are still queued on the socket.\n * For DGRAM and RDM socket types, all queued messages are rejected.\n * For SEQPACKET and STREAM socket types, the first message is rejected\n * and any others are discarded.  (If the first message on a STREAM socket\n * is partially-read, it is discarded and the next one is rejected instead.)\n *\n * NOTE: Rejected messages are not necessarily returned to the sender!  They\n * are returned or discarded according to the \"destination droppable\" setting\n * specified for the message by the sender.\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_release(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk;\n\n\t/*\n\t * Exit if socket isn't fully initialized (occurs when a failed accept()\n\t * releases a pre-allocated child socket that was never used)\n\t */\n\tif (sk == NULL)\n\t\treturn 0;\n\n\ttsk = tipc_sk(sk);\n\tlock_sock(sk);\n\n\ttrace_tipc_sk_release(sk, NULL, TIPC_DUMP_ALL, \" \");\n\t__tipc_shutdown(sock, TIPC_ERR_NO_PORT);\n\tsk->sk_shutdown = SHUTDOWN_MASK;\n\ttipc_sk_leave(tsk);\n\ttipc_sk_withdraw(tsk, NULL);\n\t__skb_queue_purge(&tsk->mc_method.deferredq);\n\tsk_stop_timer(sk, &sk->sk_timer);\n\ttipc_sk_remove(tsk);\n\n\tsock_orphan(sk);\n\t/* Reject any messages that accumulated in backlog queue */\n\trelease_sock(sk);\n\ttipc_dest_list_purge(&tsk->cong_links);\n\ttsk->cong_link_cnt = 0;\n\tcall_rcu(&tsk->rcu, tipc_sk_callback);\n\tsock->sk = NULL;\n\n\treturn 0;\n}\n\n/**\n * __tipc_bind - associate or disassocate TIPC name(s) with a socket\n * @sock: socket structure\n * @skaddr: socket address describing name(s) and desired operation\n * @alen: size of socket address data structure\n *\n * Name and name sequence binding are indicated using a positive scope value;\n * a negative scope value unbinds the specified name.  Specifying no name\n * (i.e. a socket address length of 0) unbinds all names from the socket.\n *\n * Return: 0 on success, errno otherwise\n *\n * NOTE: This routine doesn't need to take the socket lock since it doesn't\n *       access any non-constant socket information.\n */\nstatic int __tipc_bind(struct socket *sock, struct sockaddr *skaddr, int alen)\n{\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)skaddr;\n\tstruct tipc_sock *tsk = tipc_sk(sock->sk);\n\tbool unbind = false;\n\n\tif (unlikely(!alen))\n\t\treturn tipc_sk_withdraw(tsk, NULL);\n\n\tif (ua->addrtype == TIPC_SERVICE_ADDR) {\n\t\tua->addrtype = TIPC_SERVICE_RANGE;\n\t\tua->sr.upper = ua->sr.lower;\n\t}\n\tif (ua->scope < 0) {\n\t\tunbind = true;\n\t\tua->scope = -ua->scope;\n\t}\n\t/* Users may still use deprecated TIPC_ZONE_SCOPE */\n\tif (ua->scope != TIPC_NODE_SCOPE)\n\t\tua->scope = TIPC_CLUSTER_SCOPE;\n\n\tif (tsk->group)\n\t\treturn -EACCES;\n\n\tif (unbind)\n\t\treturn tipc_sk_withdraw(tsk, ua);\n\treturn tipc_sk_publish(tsk, ua);\n}\n\nint tipc_sk_bind(struct socket *sock, struct sockaddr *skaddr, int alen)\n{\n\tint res;\n\n\tlock_sock(sock->sk);\n\tres = __tipc_bind(sock, skaddr, alen);\n\trelease_sock(sock->sk);\n\treturn res;\n}\n\nstatic int tipc_bind(struct socket *sock, struct sockaddr *skaddr, int alen)\n{\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)skaddr;\n\tu32 atype = ua->addrtype;\n\n\tif (alen) {\n\t\tif (!tipc_uaddr_valid(ua, alen))\n\t\t\treturn -EINVAL;\n\t\tif (atype == TIPC_SOCKET_ADDR)\n\t\t\treturn -EAFNOSUPPORT;\n\t\tif (ua->sr.type < TIPC_RESERVED_TYPES) {\n\t\t\tpr_warn_once(\"Can't bind to reserved service type %u\\n\",\n\t\t\t\t     ua->sr.type);\n\t\t\treturn -EACCES;\n\t\t}\n\t}\n\treturn tipc_sk_bind(sock, skaddr, alen);\n}\n\n/**\n * tipc_getname - get port ID of socket or peer socket\n * @sock: socket structure\n * @uaddr: area for returned socket address\n * @peer: 0 = own ID, 1 = current peer ID, 2 = current/former peer ID\n *\n * Return: 0 on success, errno otherwise\n *\n * NOTE: This routine doesn't need to take the socket lock since it only\n *       accesses socket information that is unchanging (or which changes in\n *       a completely predictable manner).\n */\nstatic int tipc_getname(struct socket *sock, struct sockaddr *uaddr,\n\t\t\tint peer)\n{\n\tstruct sockaddr_tipc *addr = (struct sockaddr_tipc *)uaddr;\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\n\tmemset(addr, 0, sizeof(*addr));\n\tif (peer) {\n\t\tif ((!tipc_sk_connected(sk)) &&\n\t\t    ((peer != 2) || (sk->sk_state != TIPC_DISCONNECTING)))\n\t\t\treturn -ENOTCONN;\n\t\taddr->addr.id.ref = tsk_peer_port(tsk);\n\t\taddr->addr.id.node = tsk_peer_node(tsk);\n\t} else {\n\t\taddr->addr.id.ref = tsk->portid;\n\t\taddr->addr.id.node = tipc_own_addr(sock_net(sk));\n\t}\n\n\taddr->addrtype = TIPC_SOCKET_ADDR;\n\taddr->family = AF_TIPC;\n\taddr->scope = 0;\n\taddr->addr.name.domain = 0;\n\n\treturn sizeof(*addr);\n}\n\n/**\n * tipc_poll - read and possibly block on pollmask\n * @file: file structure associated with the socket\n * @sock: socket for which to calculate the poll bits\n * @wait: ???\n *\n * Return: pollmask value\n *\n * COMMENTARY:\n * It appears that the usual socket locking mechanisms are not useful here\n * since the pollmask info is potentially out-of-date the moment this routine\n * exits.  TCP and other protocols seem to rely on higher level poll routines\n * to handle any preventable race conditions, so TIPC will do the same ...\n *\n * IMPORTANT: The fact that a read or write operation is indicated does NOT\n * imply that the operation will succeed, merely that it should be performed\n * and will not block.\n */\nstatic __poll_t tipc_poll(struct file *file, struct socket *sock,\n\t\t\t      poll_table *wait)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\t__poll_t revents = 0;\n\n\tsock_poll_wait(file, sock, wait);\n\ttrace_tipc_sk_poll(sk, NULL, TIPC_DUMP_ALL, \" \");\n\n\tif (sk->sk_shutdown & RCV_SHUTDOWN)\n\t\trevents |= EPOLLRDHUP | EPOLLIN | EPOLLRDNORM;\n\tif (sk->sk_shutdown == SHUTDOWN_MASK)\n\t\trevents |= EPOLLHUP;\n\n\tswitch (sk->sk_state) {\n\tcase TIPC_ESTABLISHED:\n\t\tif (!tsk->cong_link_cnt && !tsk_conn_cong(tsk))\n\t\t\trevents |= EPOLLOUT;\n\t\tfallthrough;\n\tcase TIPC_LISTEN:\n\tcase TIPC_CONNECTING:\n\t\tif (!skb_queue_empty_lockless(&sk->sk_receive_queue))\n\t\t\trevents |= EPOLLIN | EPOLLRDNORM;\n\t\tbreak;\n\tcase TIPC_OPEN:\n\t\tif (tsk->group_is_open && !tsk->cong_link_cnt)\n\t\t\trevents |= EPOLLOUT;\n\t\tif (!tipc_sk_type_connectionless(sk))\n\t\t\tbreak;\n\t\tif (skb_queue_empty_lockless(&sk->sk_receive_queue))\n\t\t\tbreak;\n\t\trevents |= EPOLLIN | EPOLLRDNORM;\n\t\tbreak;\n\tcase TIPC_DISCONNECTING:\n\t\trevents = EPOLLIN | EPOLLRDNORM | EPOLLHUP;\n\t\tbreak;\n\t}\n\treturn revents;\n}\n\n/**\n * tipc_sendmcast - send multicast message\n * @sock: socket structure\n * @ua: destination address struct\n * @msg: message to send\n * @dlen: length of data to send\n * @timeout: timeout to wait for wakeup\n *\n * Called from function tipc_sendmsg(), which has done all sanity checks\n * Return: the number of bytes sent on success, or errno\n */\nstatic int tipc_sendmcast(struct  socket *sock, struct tipc_uaddr *ua,\n\t\t\t  struct msghdr *msg, size_t dlen, long timeout)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct net *net = sock_net(sk);\n\tint mtu = tipc_bcast_get_mtu(net);\n\tstruct sk_buff_head pkts;\n\tstruct tipc_nlist dsts;\n\tint rc;\n\n\tif (tsk->group)\n\t\treturn -EACCES;\n\n\t/* Block or return if any destination link is congested */\n\trc = tipc_wait_for_cond(sock, &timeout, !tsk->cong_link_cnt);\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\t/* Lookup destination nodes */\n\ttipc_nlist_init(&dsts, tipc_own_addr(net));\n\ttipc_nametbl_lookup_mcast_nodes(net, ua, &dsts);\n\tif (!dsts.local && !dsts.remote)\n\t\treturn -EHOSTUNREACH;\n\n\t/* Build message header */\n\tmsg_set_type(hdr, TIPC_MCAST_MSG);\n\tmsg_set_hdr_sz(hdr, MCAST_H_SIZE);\n\tmsg_set_lookup_scope(hdr, TIPC_CLUSTER_SCOPE);\n\tmsg_set_destport(hdr, 0);\n\tmsg_set_destnode(hdr, 0);\n\tmsg_set_nametype(hdr, ua->sr.type);\n\tmsg_set_namelower(hdr, ua->sr.lower);\n\tmsg_set_nameupper(hdr, ua->sr.upper);\n\n\t/* Build message as chain of buffers */\n\t__skb_queue_head_init(&pkts);\n\trc = tipc_msg_build(hdr, msg, 0, dlen, mtu, &pkts);\n\n\t/* Send message if build was successful */\n\tif (unlikely(rc == dlen)) {\n\t\ttrace_tipc_sk_sendmcast(sk, skb_peek(&pkts),\n\t\t\t\t\tTIPC_DUMP_SK_SNDQ, \" \");\n\t\trc = tipc_mcast_xmit(net, &pkts, &tsk->mc_method, &dsts,\n\t\t\t\t     &tsk->cong_link_cnt);\n\t}\n\n\ttipc_nlist_purge(&dsts);\n\n\treturn rc ? rc : dlen;\n}\n\n/**\n * tipc_send_group_msg - send a message to a member in the group\n * @net: network namespace\n * @tsk: tipc socket\n * @m: message to send\n * @mb: group member\n * @dnode: destination node\n * @dport: destination port\n * @dlen: total length of message data\n */\nstatic int tipc_send_group_msg(struct net *net, struct tipc_sock *tsk,\n\t\t\t       struct msghdr *m, struct tipc_member *mb,\n\t\t\t       u32 dnode, u32 dport, int dlen)\n{\n\tu16 bc_snd_nxt = tipc_group_bc_snd_nxt(tsk->group);\n\tstruct tipc_mc_method *method = &tsk->mc_method;\n\tint blks = tsk_blocks(GROUP_H_SIZE + dlen);\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct sk_buff_head pkts;\n\tint mtu, rc;\n\n\t/* Complete message header */\n\tmsg_set_type(hdr, TIPC_GRP_UCAST_MSG);\n\tmsg_set_hdr_sz(hdr, GROUP_H_SIZE);\n\tmsg_set_destport(hdr, dport);\n\tmsg_set_destnode(hdr, dnode);\n\tmsg_set_grp_bc_seqno(hdr, bc_snd_nxt);\n\n\t/* Build message as chain of buffers */\n\t__skb_queue_head_init(&pkts);\n\tmtu = tipc_node_get_mtu(net, dnode, tsk->portid, false);\n\trc = tipc_msg_build(hdr, m, 0, dlen, mtu, &pkts);\n\tif (unlikely(rc != dlen))\n\t\treturn rc;\n\n\t/* Send message */\n\trc = tipc_node_xmit(net, &pkts, dnode, tsk->portid);\n\tif (unlikely(rc == -ELINKCONG)) {\n\t\ttipc_dest_push(&tsk->cong_links, dnode, 0);\n\t\ttsk->cong_link_cnt++;\n\t}\n\n\t/* Update send window */\n\ttipc_group_update_member(mb, blks);\n\n\t/* A broadcast sent within next EXPIRE period must follow same path */\n\tmethod->rcast = true;\n\tmethod->mandatory = true;\n\treturn dlen;\n}\n\n/**\n * tipc_send_group_unicast - send message to a member in the group\n * @sock: socket structure\n * @m: message to send\n * @dlen: total length of message data\n * @timeout: timeout to wait for wakeup\n *\n * Called from function tipc_sendmsg(), which has done all sanity checks\n * Return: the number of bytes sent on success, or errno\n */\nstatic int tipc_send_group_unicast(struct socket *sock, struct msghdr *m,\n\t\t\t\t   int dlen, long timeout)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tint blks = tsk_blocks(GROUP_H_SIZE + dlen);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_member *mb = NULL;\n\tu32 node, port;\n\tint rc;\n\n\tnode = ua->sk.node;\n\tport = ua->sk.ref;\n\tif (!port && !node)\n\t\treturn -EHOSTUNREACH;\n\n\t/* Block or return if destination link or member is congested */\n\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t!tipc_dest_find(&tsk->cong_links, node, 0) &&\n\t\t\t\ttsk->group &&\n\t\t\t\t!tipc_group_cong(tsk->group, node, port, blks,\n\t\t\t\t\t\t &mb));\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\tif (unlikely(!mb))\n\t\treturn -EHOSTUNREACH;\n\n\trc = tipc_send_group_msg(net, tsk, m, mb, node, port, dlen);\n\n\treturn rc ? rc : dlen;\n}\n\n/**\n * tipc_send_group_anycast - send message to any member with given identity\n * @sock: socket structure\n * @m: message to send\n * @dlen: total length of message data\n * @timeout: timeout to wait for wakeup\n *\n * Called from function tipc_sendmsg(), which has done all sanity checks\n * Return: the number of bytes sent on success, or errno\n */\nstatic int tipc_send_group_anycast(struct socket *sock, struct msghdr *m,\n\t\t\t\t   int dlen, long timeout)\n{\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct list_head *cong_links = &tsk->cong_links;\n\tint blks = tsk_blocks(GROUP_H_SIZE + dlen);\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct tipc_member *first = NULL;\n\tstruct tipc_member *mbr = NULL;\n\tstruct net *net = sock_net(sk);\n\tu32 node, port, exclude;\n\tstruct list_head dsts;\n\tint lookups = 0;\n\tint dstcnt, rc;\n\tbool cong;\n\n\tINIT_LIST_HEAD(&dsts);\n\tua->sa.type = msg_nametype(hdr);\n\tua->scope = msg_lookup_scope(hdr);\n\n\twhile (++lookups < 4) {\n\t\texclude = tipc_group_exclude(tsk->group);\n\n\t\tfirst = NULL;\n\n\t\t/* Look for a non-congested destination member, if any */\n\t\twhile (1) {\n\t\t\tif (!tipc_nametbl_lookup_group(net, ua, &dsts, &dstcnt,\n\t\t\t\t\t\t       exclude, false))\n\t\t\t\treturn -EHOSTUNREACH;\n\t\t\ttipc_dest_pop(&dsts, &node, &port);\n\t\t\tcong = tipc_group_cong(tsk->group, node, port, blks,\n\t\t\t\t\t       &mbr);\n\t\t\tif (!cong)\n\t\t\t\tbreak;\n\t\t\tif (mbr == first)\n\t\t\t\tbreak;\n\t\t\tif (!first)\n\t\t\t\tfirst = mbr;\n\t\t}\n\n\t\t/* Start over if destination was not in member list */\n\t\tif (unlikely(!mbr))\n\t\t\tcontinue;\n\n\t\tif (likely(!cong && !tipc_dest_find(cong_links, node, 0)))\n\t\t\tbreak;\n\n\t\t/* Block or return if destination link or member is congested */\n\t\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t\t!tipc_dest_find(cong_links, node, 0) &&\n\t\t\t\t\ttsk->group &&\n\t\t\t\t\t!tipc_group_cong(tsk->group, node, port,\n\t\t\t\t\t\t\t blks, &mbr));\n\t\tif (unlikely(rc))\n\t\t\treturn rc;\n\n\t\t/* Send, unless destination disappeared while waiting */\n\t\tif (likely(mbr))\n\t\t\tbreak;\n\t}\n\n\tif (unlikely(lookups >= 4))\n\t\treturn -EHOSTUNREACH;\n\n\trc = tipc_send_group_msg(net, tsk, m, mbr, node, port, dlen);\n\n\treturn rc ? rc : dlen;\n}\n\n/**\n * tipc_send_group_bcast - send message to all members in communication group\n * @sock: socket structure\n * @m: message to send\n * @dlen: total length of message data\n * @timeout: timeout to wait for wakeup\n *\n * Called from function tipc_sendmsg(), which has done all sanity checks\n * Return: the number of bytes sent on success, or errno\n */\nstatic int tipc_send_group_bcast(struct socket *sock, struct msghdr *m,\n\t\t\t\t int dlen, long timeout)\n{\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tstruct sock *sk = sock->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_nlist *dsts;\n\tstruct tipc_mc_method *method = &tsk->mc_method;\n\tbool ack = method->mandatory && method->rcast;\n\tint blks = tsk_blocks(MCAST_H_SIZE + dlen);\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tint mtu = tipc_bcast_get_mtu(net);\n\tstruct sk_buff_head pkts;\n\tint rc = -EHOSTUNREACH;\n\n\t/* Block or return if any destination link or member is congested */\n\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t!tsk->cong_link_cnt && tsk->group &&\n\t\t\t\t!tipc_group_bc_cong(tsk->group, blks));\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\tdsts = tipc_group_dests(tsk->group);\n\tif (!dsts->local && !dsts->remote)\n\t\treturn -EHOSTUNREACH;\n\n\t/* Complete message header */\n\tif (ua) {\n\t\tmsg_set_type(hdr, TIPC_GRP_MCAST_MSG);\n\t\tmsg_set_nameinst(hdr, ua->sa.instance);\n\t} else {\n\t\tmsg_set_type(hdr, TIPC_GRP_BCAST_MSG);\n\t\tmsg_set_nameinst(hdr, 0);\n\t}\n\tmsg_set_hdr_sz(hdr, GROUP_H_SIZE);\n\tmsg_set_destport(hdr, 0);\n\tmsg_set_destnode(hdr, 0);\n\tmsg_set_grp_bc_seqno(hdr, tipc_group_bc_snd_nxt(tsk->group));\n\n\t/* Avoid getting stuck with repeated forced replicasts */\n\tmsg_set_grp_bc_ack_req(hdr, ack);\n\n\t/* Build message as chain of buffers */\n\t__skb_queue_head_init(&pkts);\n\trc = tipc_msg_build(hdr, m, 0, dlen, mtu, &pkts);\n\tif (unlikely(rc != dlen))\n\t\treturn rc;\n\n\t/* Send message */\n\trc = tipc_mcast_xmit(net, &pkts, method, dsts, &tsk->cong_link_cnt);\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\t/* Update broadcast sequence number and send windows */\n\ttipc_group_update_bc_members(tsk->group, blks, ack);\n\n\t/* Broadcast link is now free to choose method for next broadcast */\n\tmethod->mandatory = false;\n\tmethod->expires = jiffies;\n\n\treturn dlen;\n}\n\n/**\n * tipc_send_group_mcast - send message to all members with given identity\n * @sock: socket structure\n * @m: message to send\n * @dlen: total length of message data\n * @timeout: timeout to wait for wakeup\n *\n * Called from function tipc_sendmsg(), which has done all sanity checks\n * Return: the number of bytes sent on success, or errno\n */\nstatic int tipc_send_group_mcast(struct socket *sock, struct msghdr *m,\n\t\t\t\t int dlen, long timeout)\n{\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct net *net = sock_net(sk);\n\tstruct list_head dsts;\n\tu32 dstcnt, exclude;\n\n\tINIT_LIST_HEAD(&dsts);\n\tua->sa.type = msg_nametype(hdr);\n\tua->scope = msg_lookup_scope(hdr);\n\texclude = tipc_group_exclude(grp);\n\n\tif (!tipc_nametbl_lookup_group(net, ua, &dsts, &dstcnt, exclude, true))\n\t\treturn -EHOSTUNREACH;\n\n\tif (dstcnt == 1) {\n\t\ttipc_dest_pop(&dsts, &ua->sk.node, &ua->sk.ref);\n\t\treturn tipc_send_group_unicast(sock, m, dlen, timeout);\n\t}\n\n\ttipc_dest_list_purge(&dsts);\n\treturn tipc_send_group_bcast(sock, m, dlen, timeout);\n}\n\n/**\n * tipc_sk_mcast_rcv - Deliver multicast messages to all destination sockets\n * @net: the associated network namespace\n * @arrvq: queue with arriving messages, to be cloned after destination lookup\n * @inputq: queue with cloned messages, delivered to socket after dest lookup\n *\n * Multi-threaded: parallel calls with reference to same queues may occur\n */\nvoid tipc_sk_mcast_rcv(struct net *net, struct sk_buff_head *arrvq,\n\t\t       struct sk_buff_head *inputq)\n{\n\tu32 self = tipc_own_addr(net);\n\tstruct sk_buff *skb, *_skb;\n\tu32 portid, onode;\n\tstruct sk_buff_head tmpq;\n\tstruct list_head dports;\n\tstruct tipc_msg *hdr;\n\tstruct tipc_uaddr ua;\n\tint user, mtyp, hlen;\n\n\t__skb_queue_head_init(&tmpq);\n\tINIT_LIST_HEAD(&dports);\n\tua.addrtype = TIPC_SERVICE_RANGE;\n\n\t/* tipc_skb_peek() increments the head skb's reference counter */\n\tskb = tipc_skb_peek(arrvq, &inputq->lock);\n\tfor (; skb; skb = tipc_skb_peek(arrvq, &inputq->lock)) {\n\t\thdr = buf_msg(skb);\n\t\tuser = msg_user(hdr);\n\t\tmtyp = msg_type(hdr);\n\t\thlen = skb_headroom(skb) + msg_hdr_sz(hdr);\n\t\tonode = msg_orignode(hdr);\n\t\tua.sr.type = msg_nametype(hdr);\n\t\tua.sr.lower = msg_namelower(hdr);\n\t\tua.sr.upper = msg_nameupper(hdr);\n\t\tif (onode == self)\n\t\t\tua.scope = TIPC_ANY_SCOPE;\n\t\telse\n\t\t\tua.scope = TIPC_CLUSTER_SCOPE;\n\n\t\tif (mtyp == TIPC_GRP_UCAST_MSG || user == GROUP_PROTOCOL) {\n\t\t\tspin_lock_bh(&inputq->lock);\n\t\t\tif (skb_peek(arrvq) == skb) {\n\t\t\t\t__skb_dequeue(arrvq);\n\t\t\t\t__skb_queue_tail(inputq, skb);\n\t\t\t}\n\t\t\tkfree_skb(skb);\n\t\t\tspin_unlock_bh(&inputq->lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Group messages require exact scope match */\n\t\tif (msg_in_group(hdr)) {\n\t\t\tua.sr.lower = 0;\n\t\t\tua.sr.upper = ~0;\n\t\t\tua.scope = msg_lookup_scope(hdr);\n\t\t}\n\n\t\t/* Create destination port list: */\n\t\ttipc_nametbl_lookup_mcast_sockets(net, &ua, &dports);\n\n\t\t/* Clone message per destination */\n\t\twhile (tipc_dest_pop(&dports, NULL, &portid)) {\n\t\t\t_skb = __pskb_copy(skb, hlen, GFP_ATOMIC);\n\t\t\tif (_skb) {\n\t\t\t\tmsg_set_destport(buf_msg(_skb), portid);\n\t\t\t\t__skb_queue_tail(&tmpq, _skb);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tpr_warn(\"Failed to clone mcast rcv buffer\\n\");\n\t\t}\n\t\t/* Append clones to inputq only if skb is still head of arrvq */\n\t\tspin_lock_bh(&inputq->lock);\n\t\tif (skb_peek(arrvq) == skb) {\n\t\t\tskb_queue_splice_tail_init(&tmpq, inputq);\n\t\t\t/* Decrement the skb's refcnt */\n\t\t\tkfree_skb(__skb_dequeue(arrvq));\n\t\t}\n\t\tspin_unlock_bh(&inputq->lock);\n\t\t__skb_queue_purge(&tmpq);\n\t\tkfree_skb(skb);\n\t}\n\ttipc_sk_rcv(net, inputq);\n}\n\n/* tipc_sk_push_backlog(): send accumulated buffers in socket write queue\n *                         when socket is in Nagle mode\n */\nstatic void tipc_sk_push_backlog(struct tipc_sock *tsk, bool nagle_ack)\n{\n\tstruct sk_buff_head *txq = &tsk->sk.sk_write_queue;\n\tstruct sk_buff *skb = skb_peek_tail(txq);\n\tstruct net *net = sock_net(&tsk->sk);\n\tu32 dnode = tsk_peer_node(tsk);\n\tint rc;\n\n\tif (nagle_ack) {\n\t\ttsk->pkt_cnt += skb_queue_len(txq);\n\t\tif (!tsk->pkt_cnt || tsk->msg_acc / tsk->pkt_cnt < 2) {\n\t\t\ttsk->oneway = 0;\n\t\t\tif (tsk->nagle_start < NAGLE_START_MAX)\n\t\t\t\ttsk->nagle_start *= 2;\n\t\t\ttsk->expect_ack = false;\n\t\t\tpr_debug(\"tsk %10u: bad nagle %u -> %u, next start %u!\\n\",\n\t\t\t\t tsk->portid, tsk->msg_acc, tsk->pkt_cnt,\n\t\t\t\t tsk->nagle_start);\n\t\t} else {\n\t\t\ttsk->nagle_start = NAGLE_START_INIT;\n\t\t\tif (skb) {\n\t\t\t\tmsg_set_ack_required(buf_msg(skb));\n\t\t\t\ttsk->expect_ack = true;\n\t\t\t} else {\n\t\t\t\ttsk->expect_ack = false;\n\t\t\t}\n\t\t}\n\t\ttsk->msg_acc = 0;\n\t\ttsk->pkt_cnt = 0;\n\t}\n\n\tif (!skb || tsk->cong_link_cnt)\n\t\treturn;\n\n\t/* Do not send SYN again after congestion */\n\tif (msg_is_syn(buf_msg(skb)))\n\t\treturn;\n\n\tif (tsk->msg_acc)\n\t\ttsk->pkt_cnt += skb_queue_len(txq);\n\ttsk->snt_unacked += tsk->snd_backlog;\n\ttsk->snd_backlog = 0;\n\trc = tipc_node_xmit(net, txq, dnode, tsk->portid);\n\tif (rc == -ELINKCONG)\n\t\ttsk->cong_link_cnt = 1;\n}\n\n/**\n * tipc_sk_conn_proto_rcv - receive a connection mng protocol message\n * @tsk: receiving socket\n * @skb: pointer to message buffer.\n * @inputq: buffer list containing the buffers\n * @xmitq: output message area\n */\nstatic void tipc_sk_conn_proto_rcv(struct tipc_sock *tsk, struct sk_buff *skb,\n\t\t\t\t   struct sk_buff_head *inputq,\n\t\t\t\t   struct sk_buff_head *xmitq)\n{\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tu32 onode = tsk_own_node(tsk);\n\tstruct sock *sk = &tsk->sk;\n\tint mtyp = msg_type(hdr);\n\tbool was_cong;\n\n\t/* Ignore if connection cannot be validated: */\n\tif (!tsk_peer_msg(tsk, hdr)) {\n\t\ttrace_tipc_sk_drop_msg(sk, skb, TIPC_DUMP_NONE, \"@proto_rcv!\");\n\t\tgoto exit;\n\t}\n\n\tif (unlikely(msg_errcode(hdr))) {\n\t\ttipc_set_sk_state(sk, TIPC_DISCONNECTING);\n\t\ttipc_node_remove_conn(sock_net(sk), tsk_peer_node(tsk),\n\t\t\t\t      tsk_peer_port(tsk));\n\t\tsk->sk_state_change(sk);\n\n\t\t/* State change is ignored if socket already awake,\n\t\t * - convert msg to abort msg and add to inqueue\n\t\t */\n\t\tmsg_set_user(hdr, TIPC_CRITICAL_IMPORTANCE);\n\t\tmsg_set_type(hdr, TIPC_CONN_MSG);\n\t\tmsg_set_size(hdr, BASIC_H_SIZE);\n\t\tmsg_set_hdr_sz(hdr, BASIC_H_SIZE);\n\t\t__skb_queue_tail(inputq, skb);\n\t\treturn;\n\t}\n\n\ttsk->probe_unacked = false;\n\n\tif (mtyp == CONN_PROBE) {\n\t\tmsg_set_type(hdr, CONN_PROBE_REPLY);\n\t\tif (tipc_msg_reverse(onode, &skb, TIPC_OK))\n\t\t\t__skb_queue_tail(xmitq, skb);\n\t\treturn;\n\t} else if (mtyp == CONN_ACK) {\n\t\twas_cong = tsk_conn_cong(tsk);\n\t\ttipc_sk_push_backlog(tsk, msg_nagle_ack(hdr));\n\t\ttsk->snt_unacked -= msg_conn_ack(hdr);\n\t\tif (tsk->peer_caps & TIPC_BLOCK_FLOWCTL)\n\t\t\ttsk->snd_win = msg_adv_win(hdr);\n\t\tif (was_cong && !tsk_conn_cong(tsk))\n\t\t\tsk->sk_write_space(sk);\n\t} else if (mtyp != CONN_PROBE_REPLY) {\n\t\tpr_warn(\"Received unknown CONN_PROTO msg\\n\");\n\t}\nexit:\n\tkfree_skb(skb);\n}\n\n/**\n * tipc_sendmsg - send message in connectionless manner\n * @sock: socket structure\n * @m: message to send\n * @dsz: amount of user data to be sent\n *\n * Message must have an destination specified explicitly.\n * Used for SOCK_RDM and SOCK_DGRAM messages,\n * and for 'SYN' messages on SOCK_SEQPACKET and SOCK_STREAM connections.\n * (Note: 'SYN+' is prohibited on SOCK_STREAM.)\n *\n * Return: the number of bytes sent on success, or errno otherwise\n */\nstatic int tipc_sendmsg(struct socket *sock,\n\t\t\tstruct msghdr *m, size_t dsz)\n{\n\tstruct sock *sk = sock->sk;\n\tint ret;\n\n\tlock_sock(sk);\n\tret = __tipc_sendmsg(sock, m, dsz);\n\trelease_sock(sk);\n\n\treturn ret;\n}\n\nstatic int __tipc_sendmsg(struct socket *sock, struct msghdr *m, size_t dlen)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tlong timeout = sock_sndtimeo(sk, m->msg_flags & MSG_DONTWAIT);\n\tstruct list_head *clinks = &tsk->cong_links;\n\tbool syn = !tipc_sk_type_connectionless(sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct tipc_socket_addr skaddr;\n\tstruct sk_buff_head pkts;\n\tint atype, mtu, rc;\n\n\tif (unlikely(dlen > TIPC_MAX_USER_MSG_SIZE))\n\t\treturn -EMSGSIZE;\n\n\tif (ua) {\n\t\tif (!tipc_uaddr_valid(ua, m->msg_namelen))\n\t\t\treturn -EINVAL;\n\t\tatype = ua->addrtype;\n\t}\n\n\t/* If socket belongs to a communication group follow other paths */\n\tif (grp) {\n\t\tif (!ua)\n\t\t\treturn tipc_send_group_bcast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SERVICE_ADDR)\n\t\t\treturn tipc_send_group_anycast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SOCKET_ADDR)\n\t\t\treturn tipc_send_group_unicast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SERVICE_RANGE)\n\t\t\treturn tipc_send_group_mcast(sock, m, dlen, timeout);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ua) {\n\t\tua = (struct tipc_uaddr *)&tsk->peer;\n\t\tif (!syn && ua->family != AF_TIPC)\n\t\t\treturn -EDESTADDRREQ;\n\t\tatype = ua->addrtype;\n\t}\n\n\tif (unlikely(syn)) {\n\t\tif (sk->sk_state == TIPC_LISTEN)\n\t\t\treturn -EPIPE;\n\t\tif (sk->sk_state != TIPC_OPEN)\n\t\t\treturn -EISCONN;\n\t\tif (tsk->published)\n\t\t\treturn -EOPNOTSUPP;\n\t\tif (atype == TIPC_SERVICE_ADDR)\n\t\t\ttsk->conn_addrtype = atype;\n\t\tmsg_set_syn(hdr, 1);\n\t}\n\n\t/* Determine destination */\n\tif (atype == TIPC_SERVICE_RANGE) {\n\t\treturn tipc_sendmcast(sock, ua, m, dlen, timeout);\n\t} else if (atype == TIPC_SERVICE_ADDR) {\n\t\tskaddr.node = ua->lookup_node;\n\t\tua->scope = tipc_node2scope(skaddr.node);\n\t\tif (!tipc_nametbl_lookup_anycast(net, ua, &skaddr))\n\t\t\treturn -EHOSTUNREACH;\n\t} else if (atype == TIPC_SOCKET_ADDR) {\n\t\tskaddr = ua->sk;\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\t/* Block or return if destination link is congested */\n\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t!tipc_dest_find(clinks, skaddr.node, 0));\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\t/* Finally build message header */\n\tmsg_set_destnode(hdr, skaddr.node);\n\tmsg_set_destport(hdr, skaddr.ref);\n\tif (atype == TIPC_SERVICE_ADDR) {\n\t\tmsg_set_type(hdr, TIPC_NAMED_MSG);\n\t\tmsg_set_hdr_sz(hdr, NAMED_H_SIZE);\n\t\tmsg_set_nametype(hdr, ua->sa.type);\n\t\tmsg_set_nameinst(hdr, ua->sa.instance);\n\t\tmsg_set_lookup_scope(hdr, ua->scope);\n\t} else { /* TIPC_SOCKET_ADDR */\n\t\tmsg_set_type(hdr, TIPC_DIRECT_MSG);\n\t\tmsg_set_lookup_scope(hdr, 0);\n\t\tmsg_set_hdr_sz(hdr, BASIC_H_SIZE);\n\t}\n\n\t/* Add message body */\n\t__skb_queue_head_init(&pkts);\n\tmtu = tipc_node_get_mtu(net, skaddr.node, tsk->portid, true);\n\trc = tipc_msg_build(hdr, m, 0, dlen, mtu, &pkts);\n\tif (unlikely(rc != dlen))\n\t\treturn rc;\n\tif (unlikely(syn && !tipc_msg_skb_clone(&pkts, &sk->sk_write_queue))) {\n\t\t__skb_queue_purge(&pkts);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Send message */\n\ttrace_tipc_sk_sendmsg(sk, skb_peek(&pkts), TIPC_DUMP_SK_SNDQ, \" \");\n\trc = tipc_node_xmit(net, &pkts, skaddr.node, tsk->portid);\n\tif (unlikely(rc == -ELINKCONG)) {\n\t\ttipc_dest_push(clinks, skaddr.node, 0);\n\t\ttsk->cong_link_cnt++;\n\t\trc = 0;\n\t}\n\n\tif (unlikely(syn && !rc)) {\n\t\ttipc_set_sk_state(sk, TIPC_CONNECTING);\n\t\tif (dlen && timeout) {\n\t\t\ttimeout = msecs_to_jiffies(timeout);\n\t\t\ttipc_wait_for_connect(sock, &timeout);\n\t\t}\n\t}\n\n\treturn rc ? rc : dlen;\n}\n\n/**\n * tipc_sendstream - send stream-oriented data\n * @sock: socket structure\n * @m: data to send\n * @dsz: total length of data to be transmitted\n *\n * Used for SOCK_STREAM data.\n *\n * Return: the number of bytes sent on success (or partial success),\n * or errno if no data sent\n */\nstatic int tipc_sendstream(struct socket *sock, struct msghdr *m, size_t dsz)\n{\n\tstruct sock *sk = sock->sk;\n\tint ret;\n\n\tlock_sock(sk);\n\tret = __tipc_sendstream(sock, m, dsz);\n\trelease_sock(sk);\n\n\treturn ret;\n}\n\nstatic int __tipc_sendstream(struct socket *sock, struct msghdr *m, size_t dlen)\n{\n\tstruct sock *sk = sock->sk;\n\tDECLARE_SOCKADDR(struct sockaddr_tipc *, dest, m->msg_name);\n\tlong timeout = sock_sndtimeo(sk, m->msg_flags & MSG_DONTWAIT);\n\tstruct sk_buff_head *txq = &sk->sk_write_queue;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct net *net = sock_net(sk);\n\tstruct sk_buff *skb;\n\tu32 dnode = tsk_peer_node(tsk);\n\tint maxnagle = tsk->maxnagle;\n\tint maxpkt = tsk->max_pkt;\n\tint send, sent = 0;\n\tint blocks, rc = 0;\n\n\tif (unlikely(dlen > INT_MAX))\n\t\treturn -EMSGSIZE;\n\n\t/* Handle implicit connection setup */\n\tif (unlikely(dest && sk->sk_state == TIPC_OPEN)) {\n\t\trc = __tipc_sendmsg(sock, m, dlen);\n\t\tif (dlen && dlen == rc) {\n\t\t\ttsk->peer_caps = tipc_node_get_capabilities(net, dnode);\n\t\t\ttsk->snt_unacked = tsk_inc(tsk, dlen + msg_hdr_sz(hdr));\n\t\t}\n\t\treturn rc;\n\t}\n\n\tdo {\n\t\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t\t(!tsk->cong_link_cnt &&\n\t\t\t\t\t !tsk_conn_cong(tsk) &&\n\t\t\t\t\t tipc_sk_connected(sk)));\n\t\tif (unlikely(rc))\n\t\t\tbreak;\n\t\tsend = min_t(size_t, dlen - sent, TIPC_MAX_USER_MSG_SIZE);\n\t\tblocks = tsk->snd_backlog;\n\t\tif (tsk->oneway++ >= tsk->nagle_start && maxnagle &&\n\t\t    send <= maxnagle) {\n\t\t\trc = tipc_msg_append(hdr, m, send, maxnagle, txq);\n\t\t\tif (unlikely(rc < 0))\n\t\t\t\tbreak;\n\t\t\tblocks += rc;\n\t\t\ttsk->msg_acc++;\n\t\t\tif (blocks <= 64 && tsk->expect_ack) {\n\t\t\t\ttsk->snd_backlog = blocks;\n\t\t\t\tsent += send;\n\t\t\t\tbreak;\n\t\t\t} else if (blocks > 64) {\n\t\t\t\ttsk->pkt_cnt += skb_queue_len(txq);\n\t\t\t} else {\n\t\t\t\tskb = skb_peek_tail(txq);\n\t\t\t\tif (skb) {\n\t\t\t\t\tmsg_set_ack_required(buf_msg(skb));\n\t\t\t\t\ttsk->expect_ack = true;\n\t\t\t\t} else {\n\t\t\t\t\ttsk->expect_ack = false;\n\t\t\t\t}\n\t\t\t\ttsk->msg_acc = 0;\n\t\t\t\ttsk->pkt_cnt = 0;\n\t\t\t}\n\t\t} else {\n\t\t\trc = tipc_msg_build(hdr, m, sent, send, maxpkt, txq);\n\t\t\tif (unlikely(rc != send))\n\t\t\t\tbreak;\n\t\t\tblocks += tsk_inc(tsk, send + MIN_H_SIZE);\n\t\t}\n\t\ttrace_tipc_sk_sendstream(sk, skb_peek(txq),\n\t\t\t\t\t TIPC_DUMP_SK_SNDQ, \" \");\n\t\trc = tipc_node_xmit(net, txq, dnode, tsk->portid);\n\t\tif (unlikely(rc == -ELINKCONG)) {\n\t\t\ttsk->cong_link_cnt = 1;\n\t\t\trc = 0;\n\t\t}\n\t\tif (likely(!rc)) {\n\t\t\ttsk->snt_unacked += blocks;\n\t\t\ttsk->snd_backlog = 0;\n\t\t\tsent += send;\n\t\t}\n\t} while (sent < dlen && !rc);\n\n\treturn sent ? sent : rc;\n}\n\n/**\n * tipc_send_packet - send a connection-oriented message\n * @sock: socket structure\n * @m: message to send\n * @dsz: length of data to be transmitted\n *\n * Used for SOCK_SEQPACKET messages.\n *\n * Return: the number of bytes sent on success, or errno otherwise\n */\nstatic int tipc_send_packet(struct socket *sock, struct msghdr *m, size_t dsz)\n{\n\tif (dsz > TIPC_MAX_USER_MSG_SIZE)\n\t\treturn -EMSGSIZE;\n\n\treturn tipc_sendstream(sock, m, dsz);\n}\n\n/* tipc_sk_finish_conn - complete the setup of a connection\n */\nstatic void tipc_sk_finish_conn(struct tipc_sock *tsk, u32 peer_port,\n\t\t\t\tu32 peer_node)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_msg *msg = &tsk->phdr;\n\n\tmsg_set_syn(msg, 0);\n\tmsg_set_destnode(msg, peer_node);\n\tmsg_set_destport(msg, peer_port);\n\tmsg_set_type(msg, TIPC_CONN_MSG);\n\tmsg_set_lookup_scope(msg, 0);\n\tmsg_set_hdr_sz(msg, SHORT_H_SIZE);\n\n\tsk_reset_timer(sk, &sk->sk_timer, jiffies + CONN_PROBING_INTV);\n\ttipc_set_sk_state(sk, TIPC_ESTABLISHED);\n\ttipc_node_add_conn(net, peer_node, tsk->portid, peer_port);\n\ttsk->max_pkt = tipc_node_get_mtu(net, peer_node, tsk->portid, true);\n\ttsk->peer_caps = tipc_node_get_capabilities(net, peer_node);\n\ttsk_set_nagle(tsk);\n\t__skb_queue_purge(&sk->sk_write_queue);\n\tif (tsk->peer_caps & TIPC_BLOCK_FLOWCTL)\n\t\treturn;\n\n\t/* Fall back to message based flow control */\n\ttsk->rcv_win = FLOWCTL_MSG_WIN;\n\ttsk->snd_win = FLOWCTL_MSG_WIN;\n}\n\n/**\n * tipc_sk_set_orig_addr - capture sender's address for received message\n * @m: descriptor for message info\n * @skb: received message\n *\n * Note: Address is not captured if not requested by receiver.\n */\nstatic void tipc_sk_set_orig_addr(struct msghdr *m, struct sk_buff *skb)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_pair *, srcaddr, m->msg_name);\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\n\tif (!srcaddr)\n\t\treturn;\n\n\tsrcaddr->sock.family = AF_TIPC;\n\tsrcaddr->sock.addrtype = TIPC_SOCKET_ADDR;\n\tsrcaddr->sock.scope = 0;\n\tsrcaddr->sock.addr.id.ref = msg_origport(hdr);\n\tsrcaddr->sock.addr.id.node = msg_orignode(hdr);\n\tsrcaddr->sock.addr.name.domain = 0;\n\tm->msg_namelen = sizeof(struct sockaddr_tipc);\n\n\tif (!msg_in_group(hdr))\n\t\treturn;\n\n\t/* Group message users may also want to know sending member's id */\n\tsrcaddr->member.family = AF_TIPC;\n\tsrcaddr->member.addrtype = TIPC_SERVICE_ADDR;\n\tsrcaddr->member.scope = 0;\n\tsrcaddr->member.addr.name.name.type = msg_nametype(hdr);\n\tsrcaddr->member.addr.name.name.instance = TIPC_SKB_CB(skb)->orig_member;\n\tsrcaddr->member.addr.name.domain = 0;\n\tm->msg_namelen = sizeof(*srcaddr);\n}\n\n/**\n * tipc_sk_anc_data_recv - optionally capture ancillary data for received message\n * @m: descriptor for message info\n * @skb: received message buffer\n * @tsk: TIPC port associated with message\n *\n * Note: Ancillary data is not captured if not requested by receiver.\n *\n * Return: 0 if successful, otherwise errno\n */\nstatic int tipc_sk_anc_data_recv(struct msghdr *m, struct sk_buff *skb,\n\t\t\t\t struct tipc_sock *tsk)\n{\n\tstruct tipc_msg *hdr;\n\tu32 data[3] = {0,};\n\tbool has_addr;\n\tint dlen, rc;\n\n\tif (likely(m->msg_controllen == 0))\n\t\treturn 0;\n\n\thdr = buf_msg(skb);\n\tdlen = msg_data_sz(hdr);\n\n\t/* Capture errored message object, if any */\n\tif (msg_errcode(hdr)) {\n\t\tif (skb_linearize(skb))\n\t\t\treturn -ENOMEM;\n\t\thdr = buf_msg(skb);\n\t\tdata[0] = msg_errcode(hdr);\n\t\tdata[1] = dlen;\n\t\trc = put_cmsg(m, SOL_TIPC, TIPC_ERRINFO, 8, data);\n\t\tif (rc || !dlen)\n\t\t\treturn rc;\n\t\trc = put_cmsg(m, SOL_TIPC, TIPC_RETDATA, dlen, msg_data(hdr));\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\t/* Capture TIPC_SERVICE_ADDR/RANGE destination address, if any */\n\tswitch (msg_type(hdr)) {\n\tcase TIPC_NAMED_MSG:\n\t\thas_addr = true;\n\t\tdata[0] = msg_nametype(hdr);\n\t\tdata[1] = msg_namelower(hdr);\n\t\tdata[2] = data[1];\n\t\tbreak;\n\tcase TIPC_MCAST_MSG:\n\t\thas_addr = true;\n\t\tdata[0] = msg_nametype(hdr);\n\t\tdata[1] = msg_namelower(hdr);\n\t\tdata[2] = msg_nameupper(hdr);\n\t\tbreak;\n\tcase TIPC_CONN_MSG:\n\t\thas_addr = !!tsk->conn_addrtype;\n\t\tdata[0] = msg_nametype(&tsk->phdr);\n\t\tdata[1] = msg_nameinst(&tsk->phdr);\n\t\tdata[2] = data[1];\n\t\tbreak;\n\tdefault:\n\t\thas_addr = false;\n\t}\n\tif (!has_addr)\n\t\treturn 0;\n\treturn put_cmsg(m, SOL_TIPC, TIPC_DESTNAME, 12, data);\n}\n\nstatic struct sk_buff *tipc_sk_build_ack(struct tipc_sock *tsk)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct sk_buff *skb = NULL;\n\tstruct tipc_msg *msg;\n\tu32 peer_port = tsk_peer_port(tsk);\n\tu32 dnode = tsk_peer_node(tsk);\n\n\tif (!tipc_sk_connected(sk))\n\t\treturn NULL;\n\tskb = tipc_msg_create(CONN_MANAGER, CONN_ACK, INT_H_SIZE, 0,\n\t\t\t      dnode, tsk_own_node(tsk), peer_port,\n\t\t\t      tsk->portid, TIPC_OK);\n\tif (!skb)\n\t\treturn NULL;\n\tmsg = buf_msg(skb);\n\tmsg_set_conn_ack(msg, tsk->rcv_unacked);\n\ttsk->rcv_unacked = 0;\n\n\t/* Adjust to and advertize the correct window limit */\n\tif (tsk->peer_caps & TIPC_BLOCK_FLOWCTL) {\n\t\ttsk->rcv_win = tsk_adv_blocks(tsk->sk.sk_rcvbuf);\n\t\tmsg_set_adv_win(msg, tsk->rcv_win);\n\t}\n\treturn skb;\n}\n\nstatic void tipc_sk_send_ack(struct tipc_sock *tsk)\n{\n\tstruct sk_buff *skb;\n\n\tskb = tipc_sk_build_ack(tsk);\n\tif (!skb)\n\t\treturn;\n\n\ttipc_node_xmit_skb(sock_net(&tsk->sk), skb, tsk_peer_node(tsk),\n\t\t\t   msg_link_selector(buf_msg(skb)));\n}\n\nstatic int tipc_wait_for_rcvmsg(struct socket *sock, long *timeop)\n{\n\tstruct sock *sk = sock->sk;\n\tDEFINE_WAIT_FUNC(wait, woken_wake_function);\n\tlong timeo = *timeop;\n\tint err = sock_error(sk);\n\n\tif (err)\n\t\treturn err;\n\n\tfor (;;) {\n\t\tif (timeo && skb_queue_empty(&sk->sk_receive_queue)) {\n\t\t\tif (sk->sk_shutdown & RCV_SHUTDOWN) {\n\t\t\t\terr = -ENOTCONN;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tadd_wait_queue(sk_sleep(sk), &wait);\n\t\t\trelease_sock(sk);\n\t\t\ttimeo = wait_woken(&wait, TASK_INTERRUPTIBLE, timeo);\n\t\t\tsched_annotate_sleep();\n\t\t\tlock_sock(sk);\n\t\t\tremove_wait_queue(sk_sleep(sk), &wait);\n\t\t}\n\t\terr = 0;\n\t\tif (!skb_queue_empty(&sk->sk_receive_queue))\n\t\t\tbreak;\n\t\terr = -EAGAIN;\n\t\tif (!timeo)\n\t\t\tbreak;\n\t\terr = sock_intr_errno(timeo);\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\n\t\terr = sock_error(sk);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\t*timeop = timeo;\n\treturn err;\n}\n\n/**\n * tipc_recvmsg - receive packet-oriented message\n * @sock: network socket\n * @m: descriptor for message info\n * @buflen: length of user buffer area\n * @flags: receive flags\n *\n * Used for SOCK_DGRAM, SOCK_RDM, and SOCK_SEQPACKET messages.\n * If the complete message doesn't fit in user area, truncate it.\n *\n * Return: size of returned message data, errno otherwise\n */\nstatic int tipc_recvmsg(struct socket *sock, struct msghdr *m,\n\t\t\tsize_t buflen,\tint flags)\n{\n\tstruct sock *sk = sock->sk;\n\tbool connected = !tipc_sk_type_connectionless(sk);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tint rc, err, hlen, dlen, copy;\n\tstruct tipc_skb_cb *skb_cb;\n\tstruct sk_buff_head xmitq;\n\tstruct tipc_msg *hdr;\n\tstruct sk_buff *skb;\n\tbool grp_evt;\n\tlong timeout;\n\n\t/* Catch invalid receive requests */\n\tif (unlikely(!buflen))\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\tif (unlikely(connected && sk->sk_state == TIPC_OPEN)) {\n\t\trc = -ENOTCONN;\n\t\tgoto exit;\n\t}\n\ttimeout = sock_rcvtimeo(sk, flags & MSG_DONTWAIT);\n\n\t/* Step rcv queue to first msg with data or error; wait if necessary */\n\tdo {\n\t\trc = tipc_wait_for_rcvmsg(sock, &timeout);\n\t\tif (unlikely(rc))\n\t\t\tgoto exit;\n\t\tskb = skb_peek(&sk->sk_receive_queue);\n\t\tskb_cb = TIPC_SKB_CB(skb);\n\t\thdr = buf_msg(skb);\n\t\tdlen = msg_data_sz(hdr);\n\t\thlen = msg_hdr_sz(hdr);\n\t\terr = msg_errcode(hdr);\n\t\tgrp_evt = msg_is_grp_evt(hdr);\n\t\tif (likely(dlen || err))\n\t\t\tbreak;\n\t\ttsk_advance_rx_queue(sk);\n\t} while (1);\n\n\t/* Collect msg meta data, including error code and rejected data */\n\ttipc_sk_set_orig_addr(m, skb);\n\trc = tipc_sk_anc_data_recv(m, skb, tsk);\n\tif (unlikely(rc))\n\t\tgoto exit;\n\thdr = buf_msg(skb);\n\n\t/* Capture data if non-error msg, otherwise just set return value */\n\tif (likely(!err)) {\n\t\tint offset = skb_cb->bytes_read;\n\n\t\tcopy = min_t(int, dlen - offset, buflen);\n\t\trc = skb_copy_datagram_msg(skb, hlen + offset, m, copy);\n\t\tif (unlikely(rc))\n\t\t\tgoto exit;\n\t\tif (unlikely(offset + copy < dlen)) {\n\t\t\tif (flags & MSG_EOR) {\n\t\t\t\tif (!(flags & MSG_PEEK))\n\t\t\t\t\tskb_cb->bytes_read = offset + copy;\n\t\t\t} else {\n\t\t\t\tm->msg_flags |= MSG_TRUNC;\n\t\t\t\tskb_cb->bytes_read = 0;\n\t\t\t}\n\t\t} else {\n\t\t\tif (flags & MSG_EOR)\n\t\t\t\tm->msg_flags |= MSG_EOR;\n\t\t\tskb_cb->bytes_read = 0;\n\t\t}\n\t} else {\n\t\tcopy = 0;\n\t\trc = 0;\n\t\tif (err != TIPC_CONN_SHUTDOWN && connected && !m->msg_control) {\n\t\t\trc = -ECONNRESET;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\n\t/* Mark message as group event if applicable */\n\tif (unlikely(grp_evt)) {\n\t\tif (msg_grp_evt(hdr) == TIPC_WITHDRAWN)\n\t\t\tm->msg_flags |= MSG_EOR;\n\t\tm->msg_flags |= MSG_OOB;\n\t\tcopy = 0;\n\t}\n\n\t/* Caption of data or error code/rejected data was successful */\n\tif (unlikely(flags & MSG_PEEK))\n\t\tgoto exit;\n\n\t/* Send group flow control advertisement when applicable */\n\tif (tsk->group && msg_in_group(hdr) && !grp_evt) {\n\t\t__skb_queue_head_init(&xmitq);\n\t\ttipc_group_update_rcv_win(tsk->group, tsk_blocks(hlen + dlen),\n\t\t\t\t\t  msg_orignode(hdr), msg_origport(hdr),\n\t\t\t\t\t  &xmitq);\n\t\ttipc_node_distr_xmit(sock_net(sk), &xmitq);\n\t}\n\n\tif (skb_cb->bytes_read)\n\t\tgoto exit;\n\n\ttsk_advance_rx_queue(sk);\n\n\tif (likely(!connected))\n\t\tgoto exit;\n\n\t/* Send connection flow control advertisement when applicable */\n\ttsk->rcv_unacked += tsk_inc(tsk, hlen + dlen);\n\tif (tsk->rcv_unacked >= tsk->rcv_win / TIPC_ACK_RATE)\n\t\ttipc_sk_send_ack(tsk);\nexit:\n\trelease_sock(sk);\n\treturn rc ? rc : copy;\n}\n\n/**\n * tipc_recvstream - receive stream-oriented data\n * @sock: network socket\n * @m: descriptor for message info\n * @buflen: total size of user buffer area\n * @flags: receive flags\n *\n * Used for SOCK_STREAM messages only.  If not enough data is available\n * will optionally wait for more; never truncates data.\n *\n * Return: size of returned message data, errno otherwise\n */\nstatic int tipc_recvstream(struct socket *sock, struct msghdr *m,\n\t\t\t   size_t buflen, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct sk_buff *skb;\n\tstruct tipc_msg *hdr;\n\tstruct tipc_skb_cb *skb_cb;\n\tbool peek = flags & MSG_PEEK;\n\tint offset, required, copy, copied = 0;\n\tint hlen, dlen, err, rc;\n\tlong timeout;\n\n\t/* Catch invalid receive attempts */\n\tif (unlikely(!buflen))\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\n\tif (unlikely(sk->sk_state == TIPC_OPEN)) {\n\t\trc = -ENOTCONN;\n\t\tgoto exit;\n\t}\n\trequired = sock_rcvlowat(sk, flags & MSG_WAITALL, buflen);\n\ttimeout = sock_rcvtimeo(sk, flags & MSG_DONTWAIT);\n\n\tdo {\n\t\t/* Look at first msg in receive queue; wait if necessary */\n\t\trc = tipc_wait_for_rcvmsg(sock, &timeout);\n\t\tif (unlikely(rc))\n\t\t\tbreak;\n\t\tskb = skb_peek(&sk->sk_receive_queue);\n\t\tskb_cb = TIPC_SKB_CB(skb);\n\t\thdr = buf_msg(skb);\n\t\tdlen = msg_data_sz(hdr);\n\t\thlen = msg_hdr_sz(hdr);\n\t\terr = msg_errcode(hdr);\n\n\t\t/* Discard any empty non-errored (SYN-) message */\n\t\tif (unlikely(!dlen && !err)) {\n\t\t\ttsk_advance_rx_queue(sk);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Collect msg meta data, incl. error code and rejected data */\n\t\tif (!copied) {\n\t\t\ttipc_sk_set_orig_addr(m, skb);\n\t\t\trc = tipc_sk_anc_data_recv(m, skb, tsk);\n\t\t\tif (rc)\n\t\t\t\tbreak;\n\t\t\thdr = buf_msg(skb);\n\t\t}\n\n\t\t/* Copy data if msg ok, otherwise return error/partial data */\n\t\tif (likely(!err)) {\n\t\t\toffset = skb_cb->bytes_read;\n\t\t\tcopy = min_t(int, dlen - offset, buflen - copied);\n\t\t\trc = skb_copy_datagram_msg(skb, hlen + offset, m, copy);\n\t\t\tif (unlikely(rc))\n\t\t\t\tbreak;\n\t\t\tcopied += copy;\n\t\t\toffset += copy;\n\t\t\tif (unlikely(offset < dlen)) {\n\t\t\t\tif (!peek)\n\t\t\t\t\tskb_cb->bytes_read = offset;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\trc = 0;\n\t\t\tif ((err != TIPC_CONN_SHUTDOWN) && !m->msg_control)\n\t\t\t\trc = -ECONNRESET;\n\t\t\tif (copied || rc)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (unlikely(peek))\n\t\t\tbreak;\n\n\t\ttsk_advance_rx_queue(sk);\n\n\t\t/* Send connection flow control advertisement when applicable */\n\t\ttsk->rcv_unacked += tsk_inc(tsk, hlen + dlen);\n\t\tif (tsk->rcv_unacked >= tsk->rcv_win / TIPC_ACK_RATE)\n\t\t\ttipc_sk_send_ack(tsk);\n\n\t\t/* Exit if all requested data or FIN/error received */\n\t\tif (copied == buflen || err)\n\t\t\tbreak;\n\n\t} while (!skb_queue_empty(&sk->sk_receive_queue) || copied < required);\nexit:\n\trelease_sock(sk);\n\treturn copied ? copied : rc;\n}\n\n/**\n * tipc_write_space - wake up thread if port congestion is released\n * @sk: socket\n */\nstatic void tipc_write_space(struct sock *sk)\n{\n\tstruct socket_wq *wq;\n\n\trcu_read_lock();\n\twq = rcu_dereference(sk->sk_wq);\n\tif (skwq_has_sleeper(wq))\n\t\twake_up_interruptible_sync_poll(&wq->wait, EPOLLOUT |\n\t\t\t\t\t\tEPOLLWRNORM | EPOLLWRBAND);\n\trcu_read_unlock();\n}\n\n/**\n * tipc_data_ready - wake up threads to indicate messages have been received\n * @sk: socket\n */\nstatic void tipc_data_ready(struct sock *sk)\n{\n\tstruct socket_wq *wq;\n\n\trcu_read_lock();\n\twq = rcu_dereference(sk->sk_wq);\n\tif (skwq_has_sleeper(wq))\n\t\twake_up_interruptible_sync_poll(&wq->wait, EPOLLIN |\n\t\t\t\t\t\tEPOLLRDNORM | EPOLLRDBAND);\n\trcu_read_unlock();\n}\n\nstatic void tipc_sock_destruct(struct sock *sk)\n{\n\t__skb_queue_purge(&sk->sk_receive_queue);\n}\n\nstatic void tipc_sk_proto_rcv(struct sock *sk,\n\t\t\t      struct sk_buff_head *inputq,\n\t\t\t      struct sk_buff_head *xmitq)\n{\n\tstruct sk_buff *skb = __skb_dequeue(inputq);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tstruct tipc_group *grp = tsk->group;\n\tbool wakeup = false;\n\n\tswitch (msg_user(hdr)) {\n\tcase CONN_MANAGER:\n\t\ttipc_sk_conn_proto_rcv(tsk, skb, inputq, xmitq);\n\t\treturn;\n\tcase SOCK_WAKEUP:\n\t\ttipc_dest_del(&tsk->cong_links, msg_orignode(hdr), 0);\n\t\t/* coupled with smp_rmb() in tipc_wait_for_cond() */\n\t\tsmp_wmb();\n\t\ttsk->cong_link_cnt--;\n\t\twakeup = true;\n\t\ttipc_sk_push_backlog(tsk, false);\n\t\tbreak;\n\tcase GROUP_PROTOCOL:\n\t\ttipc_group_proto_rcv(grp, &wakeup, hdr, inputq, xmitq);\n\t\tbreak;\n\tcase TOP_SRV:\n\t\ttipc_group_member_evt(tsk->group, &wakeup, &sk->sk_rcvbuf,\n\t\t\t\t      hdr, inputq, xmitq);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (wakeup)\n\t\tsk->sk_write_space(sk);\n\n\tkfree_skb(skb);\n}\n\n/**\n * tipc_sk_filter_connect - check incoming message for a connection-based socket\n * @tsk: TIPC socket\n * @skb: pointer to message buffer.\n * @xmitq: for Nagle ACK if any\n * Return: true if message should be added to receive queue, false otherwise\n */\nstatic bool tipc_sk_filter_connect(struct tipc_sock *tsk, struct sk_buff *skb,\n\t\t\t\t   struct sk_buff_head *xmitq)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tbool con_msg = msg_connected(hdr);\n\tu32 pport = tsk_peer_port(tsk);\n\tu32 pnode = tsk_peer_node(tsk);\n\tu32 oport = msg_origport(hdr);\n\tu32 onode = msg_orignode(hdr);\n\tint err = msg_errcode(hdr);\n\tunsigned long delay;\n\n\tif (unlikely(msg_mcast(hdr)))\n\t\treturn false;\n\ttsk->oneway = 0;\n\n\tswitch (sk->sk_state) {\n\tcase TIPC_CONNECTING:\n\t\t/* Setup ACK */\n\t\tif (likely(con_msg)) {\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t\ttipc_sk_finish_conn(tsk, oport, onode);\n\t\t\tmsg_set_importance(&tsk->phdr, msg_importance(hdr));\n\t\t\t/* ACK+ message with data is added to receive queue */\n\t\t\tif (msg_data_sz(hdr))\n\t\t\t\treturn true;\n\t\t\t/* Empty ACK-, - wake up sleeping connect() and drop */\n\t\t\tsk->sk_state_change(sk);\n\t\t\tmsg_set_dest_droppable(hdr, 1);\n\t\t\treturn false;\n\t\t}\n\t\t/* Ignore connectionless message if not from listening socket */\n\t\tif (oport != pport || onode != pnode)\n\t\t\treturn false;\n\n\t\t/* Rejected SYN */\n\t\tif (err != TIPC_ERR_OVERLOAD)\n\t\t\tbreak;\n\n\t\t/* Prepare for new setup attempt if we have a SYN clone */\n\t\tif (skb_queue_empty(&sk->sk_write_queue))\n\t\t\tbreak;\n\t\tget_random_bytes(&delay, 2);\n\t\tdelay %= (tsk->conn_timeout / 4);\n\t\tdelay = msecs_to_jiffies(delay + 100);\n\t\tsk_reset_timer(sk, &sk->sk_timer, jiffies + delay);\n\t\treturn false;\n\tcase TIPC_OPEN:\n\tcase TIPC_DISCONNECTING:\n\t\treturn false;\n\tcase TIPC_LISTEN:\n\t\t/* Accept only SYN message */\n\t\tif (!msg_is_syn(hdr) &&\n\t\t    tipc_node_get_capabilities(net, onode) & TIPC_SYN_BIT)\n\t\t\treturn false;\n\t\tif (!con_msg && !err)\n\t\t\treturn true;\n\t\treturn false;\n\tcase TIPC_ESTABLISHED:\n\t\tif (!skb_queue_empty(&sk->sk_write_queue))\n\t\t\ttipc_sk_push_backlog(tsk, false);\n\t\t/* Accept only connection-based messages sent by peer */\n\t\tif (likely(con_msg && !err && pport == oport &&\n\t\t\t   pnode == onode)) {\n\t\t\tif (msg_ack_required(hdr)) {\n\t\t\t\tstruct sk_buff *skb;\n\n\t\t\t\tskb = tipc_sk_build_ack(tsk);\n\t\t\t\tif (skb) {\n\t\t\t\t\tmsg_set_nagle_ack(buf_msg(skb));\n\t\t\t\t\t__skb_queue_tail(xmitq, skb);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t\tif (!tsk_peer_msg(tsk, hdr))\n\t\t\treturn false;\n\t\tif (!err)\n\t\t\treturn true;\n\t\ttipc_set_sk_state(sk, TIPC_DISCONNECTING);\n\t\ttipc_node_remove_conn(net, pnode, tsk->portid);\n\t\tsk->sk_state_change(sk);\n\t\treturn true;\n\tdefault:\n\t\tpr_err(\"Unknown sk_state %u\\n\", sk->sk_state);\n\t}\n\t/* Abort connection setup attempt */\n\ttipc_set_sk_state(sk, TIPC_DISCONNECTING);\n\tsk->sk_err = ECONNREFUSED;\n\tsk->sk_state_change(sk);\n\treturn true;\n}\n\n/**\n * rcvbuf_limit - get proper overload limit of socket receive queue\n * @sk: socket\n * @skb: message\n *\n * For connection oriented messages, irrespective of importance,\n * default queue limit is 2 MB.\n *\n * For connectionless messages, queue limits are based on message\n * importance as follows:\n *\n * TIPC_LOW_IMPORTANCE       (2 MB)\n * TIPC_MEDIUM_IMPORTANCE    (4 MB)\n * TIPC_HIGH_IMPORTANCE      (8 MB)\n * TIPC_CRITICAL_IMPORTANCE  (16 MB)\n *\n * Return: overload limit according to corresponding message importance\n */\nstatic unsigned int rcvbuf_limit(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\n\tif (unlikely(msg_in_group(hdr)))\n\t\treturn READ_ONCE(sk->sk_rcvbuf);\n\n\tif (unlikely(!msg_connected(hdr)))\n\t\treturn READ_ONCE(sk->sk_rcvbuf) << msg_importance(hdr);\n\n\tif (likely(tsk->peer_caps & TIPC_BLOCK_FLOWCTL))\n\t\treturn READ_ONCE(sk->sk_rcvbuf);\n\n\treturn FLOWCTL_MSG_LIM;\n}\n\n/**\n * tipc_sk_filter_rcv - validate incoming message\n * @sk: socket\n * @skb: pointer to message.\n * @xmitq: output message area (FIXME)\n *\n * Enqueues message on receive queue if acceptable; optionally handles\n * disconnect indication for a connected socket.\n *\n * Called with socket lock already taken\n */\nstatic void tipc_sk_filter_rcv(struct sock *sk, struct sk_buff *skb,\n\t\t\t       struct sk_buff_head *xmitq)\n{\n\tbool sk_conn = !tipc_sk_type_connectionless(sk);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tstruct net *net = sock_net(sk);\n\tstruct sk_buff_head inputq;\n\tint mtyp = msg_type(hdr);\n\tint limit, err = TIPC_OK;\n\n\ttrace_tipc_sk_filter_rcv(sk, skb, TIPC_DUMP_ALL, \" \");\n\tTIPC_SKB_CB(skb)->bytes_read = 0;\n\t__skb_queue_head_init(&inputq);\n\t__skb_queue_tail(&inputq, skb);\n\n\tif (unlikely(!msg_isdata(hdr)))\n\t\ttipc_sk_proto_rcv(sk, &inputq, xmitq);\n\n\tif (unlikely(grp))\n\t\ttipc_group_filter_msg(grp, &inputq, xmitq);\n\n\tif (unlikely(!grp) && mtyp == TIPC_MCAST_MSG)\n\t\ttipc_mcast_filter_msg(net, &tsk->mc_method.deferredq, &inputq);\n\n\t/* Validate and add to receive buffer if there is space */\n\twhile ((skb = __skb_dequeue(&inputq))) {\n\t\thdr = buf_msg(skb);\n\t\tlimit = rcvbuf_limit(sk, skb);\n\t\tif ((sk_conn && !tipc_sk_filter_connect(tsk, skb, xmitq)) ||\n\t\t    (!sk_conn && msg_connected(hdr)) ||\n\t\t    (!grp && msg_in_group(hdr)))\n\t\t\terr = TIPC_ERR_NO_PORT;\n\t\telse if (sk_rmem_alloc_get(sk) + skb->truesize >= limit) {\n\t\t\ttrace_tipc_sk_dump(sk, skb, TIPC_DUMP_ALL,\n\t\t\t\t\t   \"err_overload2!\");\n\t\t\tatomic_inc(&sk->sk_drops);\n\t\t\terr = TIPC_ERR_OVERLOAD;\n\t\t}\n\n\t\tif (unlikely(err)) {\n\t\t\tif (tipc_msg_reverse(tipc_own_addr(net), &skb, err)) {\n\t\t\t\ttrace_tipc_sk_rej_msg(sk, skb, TIPC_DUMP_NONE,\n\t\t\t\t\t\t      \"@filter_rcv!\");\n\t\t\t\t__skb_queue_tail(xmitq, skb);\n\t\t\t}\n\t\t\terr = TIPC_OK;\n\t\t\tcontinue;\n\t\t}\n\t\t__skb_queue_tail(&sk->sk_receive_queue, skb);\n\t\tskb_set_owner_r(skb, sk);\n\t\ttrace_tipc_sk_overlimit2(sk, skb, TIPC_DUMP_ALL,\n\t\t\t\t\t \"rcvq >90% allocated!\");\n\t\tsk->sk_data_ready(sk);\n\t}\n}\n\n/**\n * tipc_sk_backlog_rcv - handle incoming message from backlog queue\n * @sk: socket\n * @skb: message\n *\n * Caller must hold socket lock\n */\nstatic int tipc_sk_backlog_rcv(struct sock *sk, struct sk_buff *skb)\n{\n\tunsigned int before = sk_rmem_alloc_get(sk);\n\tstruct sk_buff_head xmitq;\n\tunsigned int added;\n\n\t__skb_queue_head_init(&xmitq);\n\n\ttipc_sk_filter_rcv(sk, skb, &xmitq);\n\tadded = sk_rmem_alloc_get(sk) - before;\n\tatomic_add(added, &tipc_sk(sk)->dupl_rcvcnt);\n\n\t/* Send pending response/rejected messages, if any */\n\ttipc_node_distr_xmit(sock_net(sk), &xmitq);\n\treturn 0;\n}\n\n/**\n * tipc_sk_enqueue - extract all buffers with destination 'dport' from\n *                   inputq and try adding them to socket or backlog queue\n * @inputq: list of incoming buffers with potentially different destinations\n * @sk: socket where the buffers should be enqueued\n * @dport: port number for the socket\n * @xmitq: output queue\n *\n * Caller must hold socket lock\n */\nstatic void tipc_sk_enqueue(struct sk_buff_head *inputq, struct sock *sk,\n\t\t\t    u32 dport, struct sk_buff_head *xmitq)\n{\n\tunsigned long time_limit = jiffies + usecs_to_jiffies(20000);\n\tstruct sk_buff *skb;\n\tunsigned int lim;\n\tatomic_t *dcnt;\n\tu32 onode;\n\n\twhile (skb_queue_len(inputq)) {\n\t\tif (unlikely(time_after_eq(jiffies, time_limit)))\n\t\t\treturn;\n\n\t\tskb = tipc_skb_dequeue(inputq, dport);\n\t\tif (unlikely(!skb))\n\t\t\treturn;\n\n\t\t/* Add message directly to receive queue if possible */\n\t\tif (!sock_owned_by_user(sk)) {\n\t\t\ttipc_sk_filter_rcv(sk, skb, xmitq);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Try backlog, compensating for double-counted bytes */\n\t\tdcnt = &tipc_sk(sk)->dupl_rcvcnt;\n\t\tif (!sk->sk_backlog.len)\n\t\t\tatomic_set(dcnt, 0);\n\t\tlim = rcvbuf_limit(sk, skb) + atomic_read(dcnt);\n\t\tif (likely(!sk_add_backlog(sk, skb, lim))) {\n\t\t\ttrace_tipc_sk_overlimit1(sk, skb, TIPC_DUMP_ALL,\n\t\t\t\t\t\t \"bklg & rcvq >90% allocated!\");\n\t\t\tcontinue;\n\t\t}\n\n\t\ttrace_tipc_sk_dump(sk, skb, TIPC_DUMP_ALL, \"err_overload!\");\n\t\t/* Overload => reject message back to sender */\n\t\tonode = tipc_own_addr(sock_net(sk));\n\t\tatomic_inc(&sk->sk_drops);\n\t\tif (tipc_msg_reverse(onode, &skb, TIPC_ERR_OVERLOAD)) {\n\t\t\ttrace_tipc_sk_rej_msg(sk, skb, TIPC_DUMP_ALL,\n\t\t\t\t\t      \"@sk_enqueue!\");\n\t\t\t__skb_queue_tail(xmitq, skb);\n\t\t}\n\t\tbreak;\n\t}\n}\n\n/**\n * tipc_sk_rcv - handle a chain of incoming buffers\n * @net: the associated network namespace\n * @inputq: buffer list containing the buffers\n * Consumes all buffers in list until inputq is empty\n * Note: may be called in multiple threads referring to the same queue\n */\nvoid tipc_sk_rcv(struct net *net, struct sk_buff_head *inputq)\n{\n\tstruct sk_buff_head xmitq;\n\tu32 dnode, dport = 0;\n\tint err;\n\tstruct tipc_sock *tsk;\n\tstruct sock *sk;\n\tstruct sk_buff *skb;\n\n\t__skb_queue_head_init(&xmitq);\n\twhile (skb_queue_len(inputq)) {\n\t\tdport = tipc_skb_peek_port(inputq, dport);\n\t\ttsk = tipc_sk_lookup(net, dport);\n\n\t\tif (likely(tsk)) {\n\t\t\tsk = &tsk->sk;\n\t\t\tif (likely(spin_trylock_bh(&sk->sk_lock.slock))) {\n\t\t\t\ttipc_sk_enqueue(inputq, sk, dport, &xmitq);\n\t\t\t\tspin_unlock_bh(&sk->sk_lock.slock);\n\t\t\t}\n\t\t\t/* Send pending response/rejected messages, if any */\n\t\t\ttipc_node_distr_xmit(sock_net(sk), &xmitq);\n\t\t\tsock_put(sk);\n\t\t\tcontinue;\n\t\t}\n\t\t/* No destination socket => dequeue skb if still there */\n\t\tskb = tipc_skb_dequeue(inputq, dport);\n\t\tif (!skb)\n\t\t\treturn;\n\n\t\t/* Try secondary lookup if unresolved named message */\n\t\terr = TIPC_ERR_NO_PORT;\n\t\tif (tipc_msg_lookup_dest(net, skb, &err))\n\t\t\tgoto xmit;\n\n\t\t/* Prepare for message rejection */\n\t\tif (!tipc_msg_reverse(tipc_own_addr(net), &skb, err))\n\t\t\tcontinue;\n\n\t\ttrace_tipc_sk_rej_msg(NULL, skb, TIPC_DUMP_NONE, \"@sk_rcv!\");\nxmit:\n\t\tdnode = msg_destnode(buf_msg(skb));\n\t\ttipc_node_xmit_skb(net, skb, dnode, dport);\n\t}\n}\n\nstatic int tipc_wait_for_connect(struct socket *sock, long *timeo_p)\n{\n\tDEFINE_WAIT_FUNC(wait, woken_wake_function);\n\tstruct sock *sk = sock->sk;\n\tint done;\n\n\tdo {\n\t\tint err = sock_error(sk);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (!*timeo_p)\n\t\t\treturn -ETIMEDOUT;\n\t\tif (signal_pending(current))\n\t\t\treturn sock_intr_errno(*timeo_p);\n\t\tif (sk->sk_state == TIPC_DISCONNECTING)\n\t\t\tbreak;\n\n\t\tadd_wait_queue(sk_sleep(sk), &wait);\n\t\tdone = sk_wait_event(sk, timeo_p, tipc_sk_connected(sk),\n\t\t\t\t     &wait);\n\t\tremove_wait_queue(sk_sleep(sk), &wait);\n\t} while (!done);\n\treturn 0;\n}\n\nstatic bool tipc_sockaddr_is_sane(struct sockaddr_tipc *addr)\n{\n\tif (addr->family != AF_TIPC)\n\t\treturn false;\n\tif (addr->addrtype == TIPC_SERVICE_RANGE)\n\t\treturn (addr->addr.nameseq.lower <= addr->addr.nameseq.upper);\n\treturn (addr->addrtype == TIPC_SERVICE_ADDR ||\n\t\taddr->addrtype == TIPC_SOCKET_ADDR);\n}\n\n/**\n * tipc_connect - establish a connection to another TIPC port\n * @sock: socket structure\n * @dest: socket address for destination port\n * @destlen: size of socket address data structure\n * @flags: file-related flags associated with socket\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_connect(struct socket *sock, struct sockaddr *dest,\n\t\t\tint destlen, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct sockaddr_tipc *dst = (struct sockaddr_tipc *)dest;\n\tstruct msghdr m = {NULL,};\n\tlong timeout = (flags & O_NONBLOCK) ? 0 : tsk->conn_timeout;\n\tint previous;\n\tint res = 0;\n\n\tif (destlen != sizeof(struct sockaddr_tipc))\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\n\tif (tsk->group) {\n\t\tres = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\tif (dst->family == AF_UNSPEC) {\n\t\tmemset(&tsk->peer, 0, sizeof(struct sockaddr_tipc));\n\t\tif (!tipc_sk_type_connectionless(sk))\n\t\t\tres = -EINVAL;\n\t\tgoto exit;\n\t}\n\tif (!tipc_sockaddr_is_sane(dst)) {\n\t\tres = -EINVAL;\n\t\tgoto exit;\n\t}\n\t/* DGRAM/RDM connect(), just save the destaddr */\n\tif (tipc_sk_type_connectionless(sk)) {\n\t\tmemcpy(&tsk->peer, dest, destlen);\n\t\tgoto exit;\n\t} else if (dst->addrtype == TIPC_SERVICE_RANGE) {\n\t\tres = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\tprevious = sk->sk_state;\n\n\tswitch (sk->sk_state) {\n\tcase TIPC_OPEN:\n\t\t/* Send a 'SYN-' to destination */\n\t\tm.msg_name = dest;\n\t\tm.msg_namelen = destlen;\n\n\t\t/* If connect is in non-blocking case, set MSG_DONTWAIT to\n\t\t * indicate send_msg() is never blocked.\n\t\t */\n\t\tif (!timeout)\n\t\t\tm.msg_flags = MSG_DONTWAIT;\n\n\t\tres = __tipc_sendmsg(sock, &m, 0);\n\t\tif ((res < 0) && (res != -EWOULDBLOCK))\n\t\t\tgoto exit;\n\n\t\t/* Just entered TIPC_CONNECTING state; the only\n\t\t * difference is that return value in non-blocking\n\t\t * case is EINPROGRESS, rather than EALREADY.\n\t\t */\n\t\tres = -EINPROGRESS;\n\t\tfallthrough;\n\tcase TIPC_CONNECTING:\n\t\tif (!timeout) {\n\t\t\tif (previous == TIPC_CONNECTING)\n\t\t\t\tres = -EALREADY;\n\t\t\tgoto exit;\n\t\t}\n\t\ttimeout = msecs_to_jiffies(timeout);\n\t\t/* Wait until an 'ACK' or 'RST' arrives, or a timeout occurs */\n\t\tres = tipc_wait_for_connect(sock, &timeout);\n\t\tbreak;\n\tcase TIPC_ESTABLISHED:\n\t\tres = -EISCONN;\n\t\tbreak;\n\tdefault:\n\t\tres = -EINVAL;\n\t}\n\nexit:\n\trelease_sock(sk);\n\treturn res;\n}\n\n/**\n * tipc_listen - allow socket to listen for incoming connections\n * @sock: socket structure\n * @len: (unused)\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_listen(struct socket *sock, int len)\n{\n\tstruct sock *sk = sock->sk;\n\tint res;\n\n\tlock_sock(sk);\n\tres = tipc_set_sk_state(sk, TIPC_LISTEN);\n\trelease_sock(sk);\n\n\treturn res;\n}\n\nstatic int tipc_wait_for_accept(struct socket *sock, long timeo)\n{\n\tstruct sock *sk = sock->sk;\n\tDEFINE_WAIT_FUNC(wait, woken_wake_function);\n\tint err;\n\n\t/* True wake-one mechanism for incoming connections: only\n\t * one process gets woken up, not the 'whole herd'.\n\t * Since we do not 'race & poll' for established sockets\n\t * anymore, the common case will execute the loop only once.\n\t*/\n\tfor (;;) {\n\t\tif (timeo && skb_queue_empty(&sk->sk_receive_queue)) {\n\t\t\tadd_wait_queue(sk_sleep(sk), &wait);\n\t\t\trelease_sock(sk);\n\t\t\ttimeo = wait_woken(&wait, TASK_INTERRUPTIBLE, timeo);\n\t\t\tlock_sock(sk);\n\t\t\tremove_wait_queue(sk_sleep(sk), &wait);\n\t\t}\n\t\terr = 0;\n\t\tif (!skb_queue_empty(&sk->sk_receive_queue))\n\t\t\tbreak;\n\t\terr = -EAGAIN;\n\t\tif (!timeo)\n\t\t\tbreak;\n\t\terr = sock_intr_errno(timeo);\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\t}\n\treturn err;\n}\n\n/**\n * tipc_accept - wait for connection request\n * @sock: listening socket\n * @new_sock: new socket that is to be connected\n * @flags: file-related flags associated with socket\n * @kern: caused by kernel or by userspace?\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_accept(struct socket *sock, struct socket *new_sock, int flags,\n\t\t       bool kern)\n{\n\tstruct sock *new_sk, *sk = sock->sk;\n\tstruct tipc_sock *new_tsock;\n\tstruct msghdr m = {NULL,};\n\tstruct tipc_msg *msg;\n\tstruct sk_buff *buf;\n\tlong timeo;\n\tint res;\n\n\tlock_sock(sk);\n\n\tif (sk->sk_state != TIPC_LISTEN) {\n\t\tres = -EINVAL;\n\t\tgoto exit;\n\t}\n\ttimeo = sock_rcvtimeo(sk, flags & O_NONBLOCK);\n\tres = tipc_wait_for_accept(sock, timeo);\n\tif (res)\n\t\tgoto exit;\n\n\tbuf = skb_peek(&sk->sk_receive_queue);\n\n\tres = tipc_sk_create(sock_net(sock->sk), new_sock, 0, kern);\n\tif (res)\n\t\tgoto exit;\n\tsecurity_sk_clone(sock->sk, new_sock->sk);\n\n\tnew_sk = new_sock->sk;\n\tnew_tsock = tipc_sk(new_sk);\n\tmsg = buf_msg(buf);\n\n\t/* we lock on new_sk; but lockdep sees the lock on sk */\n\tlock_sock_nested(new_sk, SINGLE_DEPTH_NESTING);\n\n\t/*\n\t * Reject any stray messages received by new socket\n\t * before the socket lock was taken (very, very unlikely)\n\t */\n\ttsk_rej_rx_queue(new_sk, TIPC_ERR_NO_PORT);\n\n\t/* Connect new socket to it's peer */\n\ttipc_sk_finish_conn(new_tsock, msg_origport(msg), msg_orignode(msg));\n\n\ttsk_set_importance(new_sk, msg_importance(msg));\n\tif (msg_named(msg)) {\n\t\tnew_tsock->conn_addrtype = TIPC_SERVICE_ADDR;\n\t\tmsg_set_nametype(&new_tsock->phdr, msg_nametype(msg));\n\t\tmsg_set_nameinst(&new_tsock->phdr, msg_nameinst(msg));\n\t}\n\n\t/*\n\t * Respond to 'SYN-' by discarding it & returning 'ACK'.\n\t * Respond to 'SYN+' by queuing it on new socket & returning 'ACK'.\n\t */\n\tif (!msg_data_sz(msg)) {\n\t\ttsk_advance_rx_queue(sk);\n\t} else {\n\t\t__skb_dequeue(&sk->sk_receive_queue);\n\t\t__skb_queue_head(&new_sk->sk_receive_queue, buf);\n\t\tskb_set_owner_r(buf, new_sk);\n\t}\n\t__tipc_sendstream(new_sock, &m, 0);\n\trelease_sock(new_sk);\nexit:\n\trelease_sock(sk);\n\treturn res;\n}\n\n/**\n * tipc_shutdown - shutdown socket connection\n * @sock: socket structure\n * @how: direction to close (must be SHUT_RDWR)\n *\n * Terminates connection (if necessary), then purges socket's receive queue.\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_shutdown(struct socket *sock, int how)\n{\n\tstruct sock *sk = sock->sk;\n\tint res;\n\n\tif (how != SHUT_RDWR)\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\n\ttrace_tipc_sk_shutdown(sk, NULL, TIPC_DUMP_ALL, \" \");\n\t__tipc_shutdown(sock, TIPC_CONN_SHUTDOWN);\n\tsk->sk_shutdown = SHUTDOWN_MASK;\n\n\tif (sk->sk_state == TIPC_DISCONNECTING) {\n\t\t/* Discard any unreceived messages */\n\t\t__skb_queue_purge(&sk->sk_receive_queue);\n\n\t\tres = 0;\n\t} else {\n\t\tres = -ENOTCONN;\n\t}\n\t/* Wake up anyone sleeping in poll. */\n\tsk->sk_state_change(sk);\n\n\trelease_sock(sk);\n\treturn res;\n}\n\nstatic void tipc_sk_check_probing_state(struct sock *sk,\n\t\t\t\t\tstruct sk_buff_head *list)\n{\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tu32 pnode = tsk_peer_node(tsk);\n\tu32 pport = tsk_peer_port(tsk);\n\tu32 self = tsk_own_node(tsk);\n\tu32 oport = tsk->portid;\n\tstruct sk_buff *skb;\n\n\tif (tsk->probe_unacked) {\n\t\ttipc_set_sk_state(sk, TIPC_DISCONNECTING);\n\t\tsk->sk_err = ECONNABORTED;\n\t\ttipc_node_remove_conn(sock_net(sk), pnode, pport);\n\t\tsk->sk_state_change(sk);\n\t\treturn;\n\t}\n\t/* Prepare new probe */\n\tskb = tipc_msg_create(CONN_MANAGER, CONN_PROBE, INT_H_SIZE, 0,\n\t\t\t      pnode, self, pport, oport, TIPC_OK);\n\tif (skb)\n\t\t__skb_queue_tail(list, skb);\n\ttsk->probe_unacked = true;\n\tsk_reset_timer(sk, &sk->sk_timer, jiffies + CONN_PROBING_INTV);\n}\n\nstatic void tipc_sk_retry_connect(struct sock *sk, struct sk_buff_head *list)\n{\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\n\t/* Try again later if dest link is congested */\n\tif (tsk->cong_link_cnt) {\n\t\tsk_reset_timer(sk, &sk->sk_timer, msecs_to_jiffies(100));\n\t\treturn;\n\t}\n\t/* Prepare SYN for retransmit */\n\ttipc_msg_skb_clone(&sk->sk_write_queue, list);\n}\n\nstatic void tipc_sk_timeout(struct timer_list *t)\n{\n\tstruct sock *sk = from_timer(sk, t, sk_timer);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tu32 pnode = tsk_peer_node(tsk);\n\tstruct sk_buff_head list;\n\tint rc = 0;\n\n\t__skb_queue_head_init(&list);\n\tbh_lock_sock(sk);\n\n\t/* Try again later if socket is busy */\n\tif (sock_owned_by_user(sk)) {\n\t\tsk_reset_timer(sk, &sk->sk_timer, jiffies + HZ / 20);\n\t\tbh_unlock_sock(sk);\n\t\tsock_put(sk);\n\t\treturn;\n\t}\n\n\tif (sk->sk_state == TIPC_ESTABLISHED)\n\t\ttipc_sk_check_probing_state(sk, &list);\n\telse if (sk->sk_state == TIPC_CONNECTING)\n\t\ttipc_sk_retry_connect(sk, &list);\n\n\tbh_unlock_sock(sk);\n\n\tif (!skb_queue_empty(&list))\n\t\trc = tipc_node_xmit(sock_net(sk), &list, pnode, tsk->portid);\n\n\t/* SYN messages may cause link congestion */\n\tif (rc == -ELINKCONG) {\n\t\ttipc_dest_push(&tsk->cong_links, pnode, 0);\n\t\ttsk->cong_link_cnt = 1;\n\t}\n\tsock_put(sk);\n}\n\nstatic int tipc_sk_publish(struct tipc_sock *tsk, struct tipc_uaddr *ua)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_socket_addr skaddr;\n\tstruct publication *p;\n\tu32 key;\n\n\tif (tipc_sk_connected(sk))\n\t\treturn -EINVAL;\n\tkey = tsk->portid + tsk->pub_count + 1;\n\tif (key == tsk->portid)\n\t\treturn -EADDRINUSE;\n\tskaddr.ref = tsk->portid;\n\tskaddr.node = tipc_own_addr(net);\n\tp = tipc_nametbl_publish(net, ua, &skaddr, key);\n\tif (unlikely(!p))\n\t\treturn -EINVAL;\n\n\tlist_add(&p->binding_sock, &tsk->publications);\n\ttsk->pub_count++;\n\ttsk->published = true;\n\treturn 0;\n}\n\nstatic int tipc_sk_withdraw(struct tipc_sock *tsk, struct tipc_uaddr *ua)\n{\n\tstruct net *net = sock_net(&tsk->sk);\n\tstruct publication *safe, *p;\n\tstruct tipc_uaddr _ua;\n\tint rc = -EINVAL;\n\n\tlist_for_each_entry_safe(p, safe, &tsk->publications, binding_sock) {\n\t\tif (!ua) {\n\t\t\ttipc_uaddr(&_ua, TIPC_SERVICE_RANGE, p->scope,\n\t\t\t\t   p->sr.type, p->sr.lower, p->sr.upper);\n\t\t\ttipc_nametbl_withdraw(net, &_ua, &p->sk, p->key);\n\t\t\tcontinue;\n\t\t}\n\t\t/* Unbind specific publication */\n\t\tif (p->scope != ua->scope)\n\t\t\tcontinue;\n\t\tif (p->sr.type != ua->sr.type)\n\t\t\tcontinue;\n\t\tif (p->sr.lower != ua->sr.lower)\n\t\t\tcontinue;\n\t\tif (p->sr.upper != ua->sr.upper)\n\t\t\tbreak;\n\t\ttipc_nametbl_withdraw(net, ua, &p->sk, p->key);\n\t\trc = 0;\n\t\tbreak;\n\t}\n\tif (list_empty(&tsk->publications)) {\n\t\ttsk->published = 0;\n\t\trc = 0;\n\t}\n\treturn rc;\n}\n\n/* tipc_sk_reinit: set non-zero address in all existing sockets\n *                 when we go from standalone to network mode.\n */\nvoid tipc_sk_reinit(struct net *net)\n{\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\tstruct rhashtable_iter iter;\n\tstruct tipc_sock *tsk;\n\tstruct tipc_msg *msg;\n\n\trhashtable_walk_enter(&tn->sk_rht, &iter);\n\n\tdo {\n\t\trhashtable_walk_start(&iter);\n\n\t\twhile ((tsk = rhashtable_walk_next(&iter)) && !IS_ERR(tsk)) {\n\t\t\tsock_hold(&tsk->sk);\n\t\t\trhashtable_walk_stop(&iter);\n\t\t\tlock_sock(&tsk->sk);\n\t\t\tmsg = &tsk->phdr;\n\t\t\tmsg_set_prevnode(msg, tipc_own_addr(net));\n\t\t\tmsg_set_orignode(msg, tipc_own_addr(net));\n\t\t\trelease_sock(&tsk->sk);\n\t\t\trhashtable_walk_start(&iter);\n\t\t\tsock_put(&tsk->sk);\n\t\t}\n\n\t\trhashtable_walk_stop(&iter);\n\t} while (tsk == ERR_PTR(-EAGAIN));\n\n\trhashtable_walk_exit(&iter);\n}\n\nstatic struct tipc_sock *tipc_sk_lookup(struct net *net, u32 portid)\n{\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\tstruct tipc_sock *tsk;\n\n\trcu_read_lock();\n\ttsk = rhashtable_lookup(&tn->sk_rht, &portid, tsk_rht_params);\n\tif (tsk)\n\t\tsock_hold(&tsk->sk);\n\trcu_read_unlock();\n\n\treturn tsk;\n}\n\nstatic int tipc_sk_insert(struct tipc_sock *tsk)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\tu32 remaining = (TIPC_MAX_PORT - TIPC_MIN_PORT) + 1;\n\tu32 portid = prandom_u32() % remaining + TIPC_MIN_PORT;\n\n\twhile (remaining--) {\n\t\tportid++;\n\t\tif ((portid < TIPC_MIN_PORT) || (portid > TIPC_MAX_PORT))\n\t\t\tportid = TIPC_MIN_PORT;\n\t\ttsk->portid = portid;\n\t\tsock_hold(&tsk->sk);\n\t\tif (!rhashtable_lookup_insert_fast(&tn->sk_rht, &tsk->node,\n\t\t\t\t\t\t   tsk_rht_params))\n\t\t\treturn 0;\n\t\tsock_put(&tsk->sk);\n\t}\n\n\treturn -1;\n}\n\nstatic void tipc_sk_remove(struct tipc_sock *tsk)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct tipc_net *tn = net_generic(sock_net(sk), tipc_net_id);\n\n\tif (!rhashtable_remove_fast(&tn->sk_rht, &tsk->node, tsk_rht_params)) {\n\t\tWARN_ON(refcount_read(&sk->sk_refcnt) == 1);\n\t\t__sock_put(sk);\n\t}\n}\n\nstatic const struct rhashtable_params tsk_rht_params = {\n\t.nelem_hint = 192,\n\t.head_offset = offsetof(struct tipc_sock, node),\n\t.key_offset = offsetof(struct tipc_sock, portid),\n\t.key_len = sizeof(u32), /* portid */\n\t.max_size = 1048576,\n\t.min_size = 256,\n\t.automatic_shrinking = true,\n};\n\nint tipc_sk_rht_init(struct net *net)\n{\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\n\treturn rhashtable_init(&tn->sk_rht, &tsk_rht_params);\n}\n\nvoid tipc_sk_rht_destroy(struct net *net)\n{\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\n\t/* Wait for socket readers to complete */\n\tsynchronize_net();\n\n\trhashtable_destroy(&tn->sk_rht);\n}\n\nstatic int tipc_sk_join(struct tipc_sock *tsk, struct tipc_group_req *mreq)\n{\n\tstruct net *net = sock_net(&tsk->sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct tipc_uaddr ua;\n\tint rc;\n\n\tif (mreq->type < TIPC_RESERVED_TYPES)\n\t\treturn -EACCES;\n\tif (mreq->scope > TIPC_NODE_SCOPE)\n\t\treturn -EINVAL;\n\tif (mreq->scope != TIPC_NODE_SCOPE)\n\t\tmreq->scope = TIPC_CLUSTER_SCOPE;\n\tif (grp)\n\t\treturn -EACCES;\n\tgrp = tipc_group_create(net, tsk->portid, mreq, &tsk->group_is_open);\n\tif (!grp)\n\t\treturn -ENOMEM;\n\ttsk->group = grp;\n\tmsg_set_lookup_scope(hdr, mreq->scope);\n\tmsg_set_nametype(hdr, mreq->type);\n\tmsg_set_dest_droppable(hdr, true);\n\ttipc_uaddr(&ua, TIPC_SERVICE_RANGE, mreq->scope,\n\t\t   mreq->type, mreq->instance, mreq->instance);\n\ttipc_nametbl_build_group(net, grp, &ua);\n\trc = tipc_sk_publish(tsk, &ua);\n\tif (rc) {\n\t\ttipc_group_delete(net, grp);\n\t\ttsk->group = NULL;\n\t\treturn rc;\n\t}\n\t/* Eliminate any risk that a broadcast overtakes sent JOINs */\n\ttsk->mc_method.rcast = true;\n\ttsk->mc_method.mandatory = true;\n\ttipc_group_join(net, grp, &tsk->sk.sk_rcvbuf);\n\treturn rc;\n}\n\nstatic int tipc_sk_leave(struct tipc_sock *tsk)\n{\n\tstruct net *net = sock_net(&tsk->sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_uaddr ua;\n\tint scope;\n\n\tif (!grp)\n\t\treturn -EINVAL;\n\tua.addrtype = TIPC_SERVICE_RANGE;\n\ttipc_group_self(grp, &ua.sr, &scope);\n\tua.scope = scope;\n\ttipc_group_delete(net, grp);\n\ttsk->group = NULL;\n\ttipc_sk_withdraw(tsk, &ua);\n\treturn 0;\n}\n\n/**\n * tipc_setsockopt - set socket option\n * @sock: socket structure\n * @lvl: option level\n * @opt: option identifier\n * @ov: pointer to new option value\n * @ol: length of option value\n *\n * For stream sockets only, accepts and ignores all IPPROTO_TCP options\n * (to ease compatibility).\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_setsockopt(struct socket *sock, int lvl, int opt,\n\t\t\t   sockptr_t ov, unsigned int ol)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_group_req mreq;\n\tu32 value = 0;\n\tint res = 0;\n\n\tif ((lvl == IPPROTO_TCP) && (sock->type == SOCK_STREAM))\n\t\treturn 0;\n\tif (lvl != SOL_TIPC)\n\t\treturn -ENOPROTOOPT;\n\n\tswitch (opt) {\n\tcase TIPC_IMPORTANCE:\n\tcase TIPC_SRC_DROPPABLE:\n\tcase TIPC_DEST_DROPPABLE:\n\tcase TIPC_CONN_TIMEOUT:\n\tcase TIPC_NODELAY:\n\t\tif (ol < sizeof(value))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_sockptr(&value, ov, sizeof(u32)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\tcase TIPC_GROUP_JOIN:\n\t\tif (ol < sizeof(mreq))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_sockptr(&mreq, ov, sizeof(mreq)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\tdefault:\n\t\tif (!sockptr_is_null(ov) || ol)\n\t\t\treturn -EINVAL;\n\t}\n\n\tlock_sock(sk);\n\n\tswitch (opt) {\n\tcase TIPC_IMPORTANCE:\n\t\tres = tsk_set_importance(sk, value);\n\t\tbreak;\n\tcase TIPC_SRC_DROPPABLE:\n\t\tif (sock->type != SOCK_STREAM)\n\t\t\ttsk_set_unreliable(tsk, value);\n\t\telse\n\t\t\tres = -ENOPROTOOPT;\n\t\tbreak;\n\tcase TIPC_DEST_DROPPABLE:\n\t\ttsk_set_unreturnable(tsk, value);\n\t\tbreak;\n\tcase TIPC_CONN_TIMEOUT:\n\t\ttipc_sk(sk)->conn_timeout = value;\n\t\tbreak;\n\tcase TIPC_MCAST_BROADCAST:\n\t\ttsk->mc_method.rcast = false;\n\t\ttsk->mc_method.mandatory = true;\n\t\tbreak;\n\tcase TIPC_MCAST_REPLICAST:\n\t\ttsk->mc_method.rcast = true;\n\t\ttsk->mc_method.mandatory = true;\n\t\tbreak;\n\tcase TIPC_GROUP_JOIN:\n\t\tres = tipc_sk_join(tsk, &mreq);\n\t\tbreak;\n\tcase TIPC_GROUP_LEAVE:\n\t\tres = tipc_sk_leave(tsk);\n\t\tbreak;\n\tcase TIPC_NODELAY:\n\t\ttsk->nodelay = !!value;\n\t\ttsk_set_nagle(tsk);\n\t\tbreak;\n\tdefault:\n\t\tres = -EINVAL;\n\t}\n\n\trelease_sock(sk);\n\n\treturn res;\n}\n\n/**\n * tipc_getsockopt - get socket option\n * @sock: socket structure\n * @lvl: option level\n * @opt: option identifier\n * @ov: receptacle for option value\n * @ol: receptacle for length of option value\n *\n * For stream sockets only, returns 0 length result for all IPPROTO_TCP options\n * (to ease compatibility).\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_getsockopt(struct socket *sock, int lvl, int opt,\n\t\t\t   char __user *ov, int __user *ol)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_service_range seq;\n\tint len, scope;\n\tu32 value;\n\tint res;\n\n\tif ((lvl == IPPROTO_TCP) && (sock->type == SOCK_STREAM))\n\t\treturn put_user(0, ol);\n\tif (lvl != SOL_TIPC)\n\t\treturn -ENOPROTOOPT;\n\tres = get_user(len, ol);\n\tif (res)\n\t\treturn res;\n\n\tlock_sock(sk);\n\n\tswitch (opt) {\n\tcase TIPC_IMPORTANCE:\n\t\tvalue = tsk_importance(tsk);\n\t\tbreak;\n\tcase TIPC_SRC_DROPPABLE:\n\t\tvalue = tsk_unreliable(tsk);\n\t\tbreak;\n\tcase TIPC_DEST_DROPPABLE:\n\t\tvalue = tsk_unreturnable(tsk);\n\t\tbreak;\n\tcase TIPC_CONN_TIMEOUT:\n\t\tvalue = tsk->conn_timeout;\n\t\t/* no need to set \"res\", since already 0 at this point */\n\t\tbreak;\n\tcase TIPC_NODE_RECVQ_DEPTH:\n\t\tvalue = 0; /* was tipc_queue_size, now obsolete */\n\t\tbreak;\n\tcase TIPC_SOCK_RECVQ_DEPTH:\n\t\tvalue = skb_queue_len(&sk->sk_receive_queue);\n\t\tbreak;\n\tcase TIPC_SOCK_RECVQ_USED:\n\t\tvalue = sk_rmem_alloc_get(sk);\n\t\tbreak;\n\tcase TIPC_GROUP_JOIN:\n\t\tseq.type = 0;\n\t\tif (tsk->group)\n\t\t\ttipc_group_self(tsk->group, &seq, &scope);\n\t\tvalue = seq.type;\n\t\tbreak;\n\tdefault:\n\t\tres = -EINVAL;\n\t}\n\n\trelease_sock(sk);\n\n\tif (res)\n\t\treturn res;\t/* \"get\" failed */\n\n\tif (len < sizeof(value))\n\t\treturn -EINVAL;\n\n\tif (copy_to_user(ov, &value, sizeof(value)))\n\t\treturn -EFAULT;\n\n\treturn put_user(sizeof(value), ol);\n}\n\nstatic int tipc_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)\n{\n\tstruct net *net = sock_net(sock->sk);\n\tstruct tipc_sioc_nodeid_req nr = {0};\n\tstruct tipc_sioc_ln_req lnr;\n\tvoid __user *argp = (void __user *)arg;\n\n\tswitch (cmd) {\n\tcase SIOCGETLINKNAME:\n\t\tif (copy_from_user(&lnr, argp, sizeof(lnr)))\n\t\t\treturn -EFAULT;\n\t\tif (!tipc_node_get_linkname(net,\n\t\t\t\t\t    lnr.bearer_id & 0xffff, lnr.peer,\n\t\t\t\t\t    lnr.linkname, TIPC_MAX_LINK_NAME)) {\n\t\t\tif (copy_to_user(argp, &lnr, sizeof(lnr)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn 0;\n\t\t}\n\t\treturn -EADDRNOTAVAIL;\n\tcase SIOCGETNODEID:\n\t\tif (copy_from_user(&nr, argp, sizeof(nr)))\n\t\t\treturn -EFAULT;\n\t\tif (!tipc_node_get_id(net, nr.peer, nr.node_id))\n\t\t\treturn -EADDRNOTAVAIL;\n\t\tif (copy_to_user(argp, &nr, sizeof(nr)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n}\n\nstatic int tipc_socketpair(struct socket *sock1, struct socket *sock2)\n{\n\tstruct tipc_sock *tsk2 = tipc_sk(sock2->sk);\n\tstruct tipc_sock *tsk1 = tipc_sk(sock1->sk);\n\tu32 onode = tipc_own_addr(sock_net(sock1->sk));\n\n\ttsk1->peer.family = AF_TIPC;\n\ttsk1->peer.addrtype = TIPC_SOCKET_ADDR;\n\ttsk1->peer.scope = TIPC_NODE_SCOPE;\n\ttsk1->peer.addr.id.ref = tsk2->portid;\n\ttsk1->peer.addr.id.node = onode;\n\ttsk2->peer.family = AF_TIPC;\n\ttsk2->peer.addrtype = TIPC_SOCKET_ADDR;\n\ttsk2->peer.scope = TIPC_NODE_SCOPE;\n\ttsk2->peer.addr.id.ref = tsk1->portid;\n\ttsk2->peer.addr.id.node = onode;\n\n\ttipc_sk_finish_conn(tsk1, tsk2->portid, onode);\n\ttipc_sk_finish_conn(tsk2, tsk1->portid, onode);\n\treturn 0;\n}\n\n/* Protocol switches for the various types of TIPC sockets */\n\nstatic const struct proto_ops msg_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.family\t\t= AF_TIPC,\n\t.release\t= tipc_release,\n\t.bind\t\t= tipc_bind,\n\t.connect\t= tipc_connect,\n\t.socketpair\t= tipc_socketpair,\n\t.accept\t\t= sock_no_accept,\n\t.getname\t= tipc_getname,\n\t.poll\t\t= tipc_poll,\n\t.ioctl\t\t= tipc_ioctl,\n\t.listen\t\t= sock_no_listen,\n\t.shutdown\t= tipc_shutdown,\n\t.setsockopt\t= tipc_setsockopt,\n\t.getsockopt\t= tipc_getsockopt,\n\t.sendmsg\t= tipc_sendmsg,\n\t.recvmsg\t= tipc_recvmsg,\n\t.mmap\t\t= sock_no_mmap,\n\t.sendpage\t= sock_no_sendpage\n};\n\nstatic const struct proto_ops packet_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.family\t\t= AF_TIPC,\n\t.release\t= tipc_release,\n\t.bind\t\t= tipc_bind,\n\t.connect\t= tipc_connect,\n\t.socketpair\t= tipc_socketpair,\n\t.accept\t\t= tipc_accept,\n\t.getname\t= tipc_getname,\n\t.poll\t\t= tipc_poll,\n\t.ioctl\t\t= tipc_ioctl,\n\t.listen\t\t= tipc_listen,\n\t.shutdown\t= tipc_shutdown,\n\t.setsockopt\t= tipc_setsockopt,\n\t.getsockopt\t= tipc_getsockopt,\n\t.sendmsg\t= tipc_send_packet,\n\t.recvmsg\t= tipc_recvmsg,\n\t.mmap\t\t= sock_no_mmap,\n\t.sendpage\t= sock_no_sendpage\n};\n\nstatic const struct proto_ops stream_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.family\t\t= AF_TIPC,\n\t.release\t= tipc_release,\n\t.bind\t\t= tipc_bind,\n\t.connect\t= tipc_connect,\n\t.socketpair\t= tipc_socketpair,\n\t.accept\t\t= tipc_accept,\n\t.getname\t= tipc_getname,\n\t.poll\t\t= tipc_poll,\n\t.ioctl\t\t= tipc_ioctl,\n\t.listen\t\t= tipc_listen,\n\t.shutdown\t= tipc_shutdown,\n\t.setsockopt\t= tipc_setsockopt,\n\t.getsockopt\t= tipc_getsockopt,\n\t.sendmsg\t= tipc_sendstream,\n\t.recvmsg\t= tipc_recvstream,\n\t.mmap\t\t= sock_no_mmap,\n\t.sendpage\t= sock_no_sendpage\n};\n\nstatic const struct net_proto_family tipc_family_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.family\t\t= AF_TIPC,\n\t.create\t\t= tipc_sk_create\n};\n\nstatic struct proto tipc_proto = {\n\t.name\t\t= \"TIPC\",\n\t.owner\t\t= THIS_MODULE,\n\t.obj_size\t= sizeof(struct tipc_sock),\n\t.sysctl_rmem\t= sysctl_tipc_rmem\n};\n\n/**\n * tipc_socket_init - initialize TIPC socket interface\n *\n * Return: 0 on success, errno otherwise\n */\nint tipc_socket_init(void)\n{\n\tint res;\n\n\tres = proto_register(&tipc_proto, 1);\n\tif (res) {\n\t\tpr_err(\"Failed to register TIPC protocol type\\n\");\n\t\tgoto out;\n\t}\n\n\tres = sock_register(&tipc_family_ops);\n\tif (res) {\n\t\tpr_err(\"Failed to register TIPC socket type\\n\");\n\t\tproto_unregister(&tipc_proto);\n\t\tgoto out;\n\t}\n out:\n\treturn res;\n}\n\n/**\n * tipc_socket_stop - stop TIPC socket interface\n */\nvoid tipc_socket_stop(void)\n{\n\tsock_unregister(tipc_family_ops.family);\n\tproto_unregister(&tipc_proto);\n}\n\n/* Caller should hold socket lock for the passed tipc socket. */\nstatic int __tipc_nl_add_sk_con(struct sk_buff *skb, struct tipc_sock *tsk)\n{\n\tu32 peer_node, peer_port;\n\tu32 conn_type, conn_instance;\n\tstruct nlattr *nest;\n\n\tpeer_node = tsk_peer_node(tsk);\n\tpeer_port = tsk_peer_port(tsk);\n\tconn_type = msg_nametype(&tsk->phdr);\n\tconn_instance = msg_nameinst(&tsk->phdr);\n\tnest = nla_nest_start_noflag(skb, TIPC_NLA_SOCK_CON);\n\tif (!nest)\n\t\treturn -EMSGSIZE;\n\n\tif (nla_put_u32(skb, TIPC_NLA_CON_NODE, peer_node))\n\t\tgoto msg_full;\n\tif (nla_put_u32(skb, TIPC_NLA_CON_SOCK, peer_port))\n\t\tgoto msg_full;\n\n\tif (tsk->conn_addrtype != 0) {\n\t\tif (nla_put_flag(skb, TIPC_NLA_CON_FLAG))\n\t\t\tgoto msg_full;\n\t\tif (nla_put_u32(skb, TIPC_NLA_CON_TYPE, conn_type))\n\t\t\tgoto msg_full;\n\t\tif (nla_put_u32(skb, TIPC_NLA_CON_INST, conn_instance))\n\t\t\tgoto msg_full;\n\t}\n\tnla_nest_end(skb, nest);\n\n\treturn 0;\n\nmsg_full:\n\tnla_nest_cancel(skb, nest);\n\n\treturn -EMSGSIZE;\n}\n\nstatic int __tipc_nl_add_sk_info(struct sk_buff *skb, struct tipc_sock\n\t\t\t  *tsk)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct sock *sk = &tsk->sk;\n\n\tif (nla_put_u32(skb, TIPC_NLA_SOCK_REF, tsk->portid) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_ADDR, tipc_own_addr(net)))\n\t\treturn -EMSGSIZE;\n\n\tif (tipc_sk_connected(sk)) {\n\t\tif (__tipc_nl_add_sk_con(skb, tsk))\n\t\t\treturn -EMSGSIZE;\n\t} else if (!list_empty(&tsk->publications)) {\n\t\tif (nla_put_flag(skb, TIPC_NLA_SOCK_HAS_PUBL))\n\t\t\treturn -EMSGSIZE;\n\t}\n\treturn 0;\n}\n\n/* Caller should hold socket lock for the passed tipc socket. */\nstatic int __tipc_nl_add_sk(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t\t    struct tipc_sock *tsk)\n{\n\tstruct nlattr *attrs;\n\tvoid *hdr;\n\n\thdr = genlmsg_put(skb, NETLINK_CB(cb->skb).portid, cb->nlh->nlmsg_seq,\n\t\t\t  &tipc_genl_family, NLM_F_MULTI, TIPC_NL_SOCK_GET);\n\tif (!hdr)\n\t\tgoto msg_cancel;\n\n\tattrs = nla_nest_start_noflag(skb, TIPC_NLA_SOCK);\n\tif (!attrs)\n\t\tgoto genlmsg_cancel;\n\n\tif (__tipc_nl_add_sk_info(skb, tsk))\n\t\tgoto attr_msg_cancel;\n\n\tnla_nest_end(skb, attrs);\n\tgenlmsg_end(skb, hdr);\n\n\treturn 0;\n\nattr_msg_cancel:\n\tnla_nest_cancel(skb, attrs);\ngenlmsg_cancel:\n\tgenlmsg_cancel(skb, hdr);\nmsg_cancel:\n\treturn -EMSGSIZE;\n}\n\nint tipc_nl_sk_walk(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t    int (*skb_handler)(struct sk_buff *skb,\n\t\t\t\t       struct netlink_callback *cb,\n\t\t\t\t       struct tipc_sock *tsk))\n{\n\tstruct rhashtable_iter *iter = (void *)cb->args[4];\n\tstruct tipc_sock *tsk;\n\tint err;\n\n\trhashtable_walk_start(iter);\n\twhile ((tsk = rhashtable_walk_next(iter)) != NULL) {\n\t\tif (IS_ERR(tsk)) {\n\t\t\terr = PTR_ERR(tsk);\n\t\t\tif (err == -EAGAIN) {\n\t\t\t\terr = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tsock_hold(&tsk->sk);\n\t\trhashtable_walk_stop(iter);\n\t\tlock_sock(&tsk->sk);\n\t\terr = skb_handler(skb, cb, tsk);\n\t\tif (err) {\n\t\t\trelease_sock(&tsk->sk);\n\t\t\tsock_put(&tsk->sk);\n\t\t\tgoto out;\n\t\t}\n\t\trelease_sock(&tsk->sk);\n\t\trhashtable_walk_start(iter);\n\t\tsock_put(&tsk->sk);\n\t}\n\trhashtable_walk_stop(iter);\nout:\n\treturn skb->len;\n}\nEXPORT_SYMBOL(tipc_nl_sk_walk);\n\nint tipc_dump_start(struct netlink_callback *cb)\n{\n\treturn __tipc_dump_start(cb, sock_net(cb->skb->sk));\n}\nEXPORT_SYMBOL(tipc_dump_start);\n\nint __tipc_dump_start(struct netlink_callback *cb, struct net *net)\n{\n\t/* tipc_nl_name_table_dump() uses cb->args[0...3]. */\n\tstruct rhashtable_iter *iter = (void *)cb->args[4];\n\tstruct tipc_net *tn = tipc_net(net);\n\n\tif (!iter) {\n\t\titer = kmalloc(sizeof(*iter), GFP_KERNEL);\n\t\tif (!iter)\n\t\t\treturn -ENOMEM;\n\n\t\tcb->args[4] = (long)iter;\n\t}\n\n\trhashtable_walk_enter(&tn->sk_rht, iter);\n\treturn 0;\n}\n\nint tipc_dump_done(struct netlink_callback *cb)\n{\n\tstruct rhashtable_iter *hti = (void *)cb->args[4];\n\n\trhashtable_walk_exit(hti);\n\tkfree(hti);\n\treturn 0;\n}\nEXPORT_SYMBOL(tipc_dump_done);\n\nint tipc_sk_fill_sock_diag(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t\t   struct tipc_sock *tsk, u32 sk_filter_state,\n\t\t\t   u64 (*tipc_diag_gen_cookie)(struct sock *sk))\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct nlattr *attrs;\n\tstruct nlattr *stat;\n\n\t/*filter response w.r.t sk_state*/\n\tif (!(sk_filter_state & (1 << sk->sk_state)))\n\t\treturn 0;\n\n\tattrs = nla_nest_start_noflag(skb, TIPC_NLA_SOCK);\n\tif (!attrs)\n\t\tgoto msg_cancel;\n\n\tif (__tipc_nl_add_sk_info(skb, tsk))\n\t\tgoto attr_msg_cancel;\n\n\tif (nla_put_u32(skb, TIPC_NLA_SOCK_TYPE, (u32)sk->sk_type) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_TIPC_STATE, (u32)sk->sk_state) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_INO, sock_i_ino(sk)) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_UID,\n\t\t\tfrom_kuid_munged(sk_user_ns(NETLINK_CB(cb->skb).sk),\n\t\t\t\t\t sock_i_uid(sk))) ||\n\t    nla_put_u64_64bit(skb, TIPC_NLA_SOCK_COOKIE,\n\t\t\t      tipc_diag_gen_cookie(sk),\n\t\t\t      TIPC_NLA_SOCK_PAD))\n\t\tgoto attr_msg_cancel;\n\n\tstat = nla_nest_start_noflag(skb, TIPC_NLA_SOCK_STAT);\n\tif (!stat)\n\t\tgoto attr_msg_cancel;\n\n\tif (nla_put_u32(skb, TIPC_NLA_SOCK_STAT_RCVQ,\n\t\t\tskb_queue_len(&sk->sk_receive_queue)) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_STAT_SENDQ,\n\t\t\tskb_queue_len(&sk->sk_write_queue)) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_STAT_DROP,\n\t\t\tatomic_read(&sk->sk_drops)))\n\t\tgoto stat_msg_cancel;\n\n\tif (tsk->cong_link_cnt &&\n\t    nla_put_flag(skb, TIPC_NLA_SOCK_STAT_LINK_CONG))\n\t\tgoto stat_msg_cancel;\n\n\tif (tsk_conn_cong(tsk) &&\n\t    nla_put_flag(skb, TIPC_NLA_SOCK_STAT_CONN_CONG))\n\t\tgoto stat_msg_cancel;\n\n\tnla_nest_end(skb, stat);\n\n\tif (tsk->group)\n\t\tif (tipc_group_fill_sock_diag(tsk->group, skb))\n\t\t\tgoto stat_msg_cancel;\n\n\tnla_nest_end(skb, attrs);\n\n\treturn 0;\n\nstat_msg_cancel:\n\tnla_nest_cancel(skb, stat);\nattr_msg_cancel:\n\tnla_nest_cancel(skb, attrs);\nmsg_cancel:\n\treturn -EMSGSIZE;\n}\nEXPORT_SYMBOL(tipc_sk_fill_sock_diag);\n\nint tipc_nl_sk_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\treturn tipc_nl_sk_walk(skb, cb, __tipc_nl_add_sk);\n}\n\n/* Caller should hold socket lock for the passed tipc socket. */\nstatic int __tipc_nl_add_sk_publ(struct sk_buff *skb,\n\t\t\t\t struct netlink_callback *cb,\n\t\t\t\t struct publication *publ)\n{\n\tvoid *hdr;\n\tstruct nlattr *attrs;\n\n\thdr = genlmsg_put(skb, NETLINK_CB(cb->skb).portid, cb->nlh->nlmsg_seq,\n\t\t\t  &tipc_genl_family, NLM_F_MULTI, TIPC_NL_PUBL_GET);\n\tif (!hdr)\n\t\tgoto msg_cancel;\n\n\tattrs = nla_nest_start_noflag(skb, TIPC_NLA_PUBL);\n\tif (!attrs)\n\t\tgoto genlmsg_cancel;\n\n\tif (nla_put_u32(skb, TIPC_NLA_PUBL_KEY, publ->key))\n\t\tgoto attr_msg_cancel;\n\tif (nla_put_u32(skb, TIPC_NLA_PUBL_TYPE, publ->sr.type))\n\t\tgoto attr_msg_cancel;\n\tif (nla_put_u32(skb, TIPC_NLA_PUBL_LOWER, publ->sr.lower))\n\t\tgoto attr_msg_cancel;\n\tif (nla_put_u32(skb, TIPC_NLA_PUBL_UPPER, publ->sr.upper))\n\t\tgoto attr_msg_cancel;\n\n\tnla_nest_end(skb, attrs);\n\tgenlmsg_end(skb, hdr);\n\n\treturn 0;\n\nattr_msg_cancel:\n\tnla_nest_cancel(skb, attrs);\ngenlmsg_cancel:\n\tgenlmsg_cancel(skb, hdr);\nmsg_cancel:\n\treturn -EMSGSIZE;\n}\n\n/* Caller should hold socket lock for the passed tipc socket. */\nstatic int __tipc_nl_list_sk_publ(struct sk_buff *skb,\n\t\t\t\t  struct netlink_callback *cb,\n\t\t\t\t  struct tipc_sock *tsk, u32 *last_publ)\n{\n\tint err;\n\tstruct publication *p;\n\n\tif (*last_publ) {\n\t\tlist_for_each_entry(p, &tsk->publications, binding_sock) {\n\t\t\tif (p->key == *last_publ)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (p->key != *last_publ) {\n\t\t\t/* We never set seq or call nl_dump_check_consistent()\n\t\t\t * this means that setting prev_seq here will cause the\n\t\t\t * consistence check to fail in the netlink callback\n\t\t\t * handler. Resulting in the last NLMSG_DONE message\n\t\t\t * having the NLM_F_DUMP_INTR flag set.\n\t\t\t */\n\t\t\tcb->prev_seq = 1;\n\t\t\t*last_publ = 0;\n\t\t\treturn -EPIPE;\n\t\t}\n\t} else {\n\t\tp = list_first_entry(&tsk->publications, struct publication,\n\t\t\t\t     binding_sock);\n\t}\n\n\tlist_for_each_entry_from(p, &tsk->publications, binding_sock) {\n\t\terr = __tipc_nl_add_sk_publ(skb, cb, p);\n\t\tif (err) {\n\t\t\t*last_publ = p->key;\n\t\t\treturn err;\n\t\t}\n\t}\n\t*last_publ = 0;\n\n\treturn 0;\n}\n\nint tipc_nl_publ_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tint err;\n\tu32 tsk_portid = cb->args[0];\n\tu32 last_publ = cb->args[1];\n\tu32 done = cb->args[2];\n\tstruct net *net = sock_net(skb->sk);\n\tstruct tipc_sock *tsk;\n\n\tif (!tsk_portid) {\n\t\tstruct nlattr **attrs = genl_dumpit_info(cb)->attrs;\n\t\tstruct nlattr *sock[TIPC_NLA_SOCK_MAX + 1];\n\n\t\tif (!attrs[TIPC_NLA_SOCK])\n\t\t\treturn -EINVAL;\n\n\t\terr = nla_parse_nested_deprecated(sock, TIPC_NLA_SOCK_MAX,\n\t\t\t\t\t\t  attrs[TIPC_NLA_SOCK],\n\t\t\t\t\t\t  tipc_nl_sock_policy, NULL);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (!sock[TIPC_NLA_SOCK_REF])\n\t\t\treturn -EINVAL;\n\n\t\ttsk_portid = nla_get_u32(sock[TIPC_NLA_SOCK_REF]);\n\t}\n\n\tif (done)\n\t\treturn 0;\n\n\ttsk = tipc_sk_lookup(net, tsk_portid);\n\tif (!tsk)\n\t\treturn -EINVAL;\n\n\tlock_sock(&tsk->sk);\n\terr = __tipc_nl_list_sk_publ(skb, cb, tsk, &last_publ);\n\tif (!err)\n\t\tdone = 1;\n\trelease_sock(&tsk->sk);\n\tsock_put(&tsk->sk);\n\n\tcb->args[0] = tsk_portid;\n\tcb->args[1] = last_publ;\n\tcb->args[2] = done;\n\n\treturn skb->len;\n}\n\n/**\n * tipc_sk_filtering - check if a socket should be traced\n * @sk: the socket to be examined\n *\n * @sysctl_tipc_sk_filter is used as the socket tuple for filtering:\n * (portid, sock type, name type, name lower, name upper)\n *\n * Return: true if the socket meets the socket tuple data\n * (value 0 = 'any') or when there is no tuple set (all = 0),\n * otherwise false\n */\nbool tipc_sk_filtering(struct sock *sk)\n{\n\tstruct tipc_sock *tsk;\n\tstruct publication *p;\n\tu32 _port, _sktype, _type, _lower, _upper;\n\tu32 type = 0, lower = 0, upper = 0;\n\n\tif (!sk)\n\t\treturn true;\n\n\ttsk = tipc_sk(sk);\n\n\t_port = sysctl_tipc_sk_filter[0];\n\t_sktype = sysctl_tipc_sk_filter[1];\n\t_type = sysctl_tipc_sk_filter[2];\n\t_lower = sysctl_tipc_sk_filter[3];\n\t_upper = sysctl_tipc_sk_filter[4];\n\n\tif (!_port && !_sktype && !_type && !_lower && !_upper)\n\t\treturn true;\n\n\tif (_port)\n\t\treturn (_port == tsk->portid);\n\n\tif (_sktype && _sktype != sk->sk_type)\n\t\treturn false;\n\n\tif (tsk->published) {\n\t\tp = list_first_entry_or_null(&tsk->publications,\n\t\t\t\t\t     struct publication, binding_sock);\n\t\tif (p) {\n\t\t\ttype = p->sr.type;\n\t\t\tlower = p->sr.lower;\n\t\t\tupper = p->sr.upper;\n\t\t}\n\t}\n\n\tif (!tipc_sk_type_connectionless(sk)) {\n\t\ttype = msg_nametype(&tsk->phdr);\n\t\tlower = msg_nameinst(&tsk->phdr);\n\t\tupper = lower;\n\t}\n\n\tif ((_type && _type != type) || (_lower && _lower != lower) ||\n\t    (_upper && _upper != upper))\n\t\treturn false;\n\n\treturn true;\n}\n\nu32 tipc_sock_get_portid(struct sock *sk)\n{\n\treturn (sk) ? (tipc_sk(sk))->portid : 0;\n}\n\n/**\n * tipc_sk_overlimit1 - check if socket rx queue is about to be overloaded,\n *\t\t\tboth the rcv and backlog queues are considered\n * @sk: tipc sk to be checked\n * @skb: tipc msg to be checked\n *\n * Return: true if the socket rx queue allocation is > 90%, otherwise false\n */\n\nbool tipc_sk_overlimit1(struct sock *sk, struct sk_buff *skb)\n{\n\tatomic_t *dcnt = &tipc_sk(sk)->dupl_rcvcnt;\n\tunsigned int lim = rcvbuf_limit(sk, skb) + atomic_read(dcnt);\n\tunsigned int qsize = sk->sk_backlog.len + sk_rmem_alloc_get(sk);\n\n\treturn (qsize > lim * 90 / 100);\n}\n\n/**\n * tipc_sk_overlimit2 - check if socket rx queue is about to be overloaded,\n *\t\t\tonly the rcv queue is considered\n * @sk: tipc sk to be checked\n * @skb: tipc msg to be checked\n *\n * Return: true if the socket rx queue allocation is > 90%, otherwise false\n */\n\nbool tipc_sk_overlimit2(struct sock *sk, struct sk_buff *skb)\n{\n\tunsigned int lim = rcvbuf_limit(sk, skb);\n\tunsigned int qsize = sk_rmem_alloc_get(sk);\n\n\treturn (qsize > lim * 90 / 100);\n}\n\n/**\n * tipc_sk_dump - dump TIPC socket\n * @sk: tipc sk to be dumped\n * @dqueues: bitmask to decide if any socket queue to be dumped?\n *           - TIPC_DUMP_NONE: don't dump socket queues\n *           - TIPC_DUMP_SK_SNDQ: dump socket send queue\n *           - TIPC_DUMP_SK_RCVQ: dump socket rcv queue\n *           - TIPC_DUMP_SK_BKLGQ: dump socket backlog queue\n *           - TIPC_DUMP_ALL: dump all the socket queues above\n * @buf: returned buffer of dump data in format\n */\nint tipc_sk_dump(struct sock *sk, u16 dqueues, char *buf)\n{\n\tint i = 0;\n\tsize_t sz = (dqueues) ? SK_LMAX : SK_LMIN;\n\tu32 conn_type, conn_instance;\n\tstruct tipc_sock *tsk;\n\tstruct publication *p;\n\tbool tsk_connected;\n\n\tif (!sk) {\n\t\ti += scnprintf(buf, sz, \"sk data: (null)\\n\");\n\t\treturn i;\n\t}\n\n\ttsk = tipc_sk(sk);\n\ttsk_connected = !tipc_sk_type_connectionless(sk);\n\n\ti += scnprintf(buf, sz, \"sk data: %u\", sk->sk_type);\n\ti += scnprintf(buf + i, sz - i, \" %d\", sk->sk_state);\n\ti += scnprintf(buf + i, sz - i, \" %x\", tsk_own_node(tsk));\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->portid);\n\ti += scnprintf(buf + i, sz - i, \" | %u\", tsk_connected);\n\tif (tsk_connected) {\n\t\ti += scnprintf(buf + i, sz - i, \" %x\", tsk_peer_node(tsk));\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", tsk_peer_port(tsk));\n\t\tconn_type = msg_nametype(&tsk->phdr);\n\t\tconn_instance = msg_nameinst(&tsk->phdr);\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", conn_type);\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", conn_instance);\n\t}\n\ti += scnprintf(buf + i, sz - i, \" | %u\", tsk->published);\n\tif (tsk->published) {\n\t\tp = list_first_entry_or_null(&tsk->publications,\n\t\t\t\t\t     struct publication, binding_sock);\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", (p) ? p->sr.type : 0);\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", (p) ? p->sr.lower : 0);\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", (p) ? p->sr.upper : 0);\n\t}\n\ti += scnprintf(buf + i, sz - i, \" | %u\", tsk->snd_win);\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->rcv_win);\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->max_pkt);\n\ti += scnprintf(buf + i, sz - i, \" %x\", tsk->peer_caps);\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->cong_link_cnt);\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->snt_unacked);\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->rcv_unacked);\n\ti += scnprintf(buf + i, sz - i, \" %u\", atomic_read(&tsk->dupl_rcvcnt));\n\ti += scnprintf(buf + i, sz - i, \" %u\", sk->sk_shutdown);\n\ti += scnprintf(buf + i, sz - i, \" | %d\", sk_wmem_alloc_get(sk));\n\ti += scnprintf(buf + i, sz - i, \" %d\", sk->sk_sndbuf);\n\ti += scnprintf(buf + i, sz - i, \" | %d\", sk_rmem_alloc_get(sk));\n\ti += scnprintf(buf + i, sz - i, \" %d\", sk->sk_rcvbuf);\n\ti += scnprintf(buf + i, sz - i, \" | %d\\n\", READ_ONCE(sk->sk_backlog.len));\n\n\tif (dqueues & TIPC_DUMP_SK_SNDQ) {\n\t\ti += scnprintf(buf + i, sz - i, \"sk_write_queue: \");\n\t\ti += tipc_list_dump(&sk->sk_write_queue, false, buf + i);\n\t}\n\n\tif (dqueues & TIPC_DUMP_SK_RCVQ) {\n\t\ti += scnprintf(buf + i, sz - i, \"sk_receive_queue: \");\n\t\ti += tipc_list_dump(&sk->sk_receive_queue, false, buf + i);\n\t}\n\n\tif (dqueues & TIPC_DUMP_SK_BKLGQ) {\n\t\ti += scnprintf(buf + i, sz - i, \"sk_backlog:\\n  head \");\n\t\ti += tipc_skb_dump(sk->sk_backlog.head, false, buf + i);\n\t\tif (sk->sk_backlog.tail != sk->sk_backlog.head) {\n\t\t\ti += scnprintf(buf + i, sz - i, \"  tail \");\n\t\t\ti += tipc_skb_dump(sk->sk_backlog.tail, false,\n\t\t\t\t\t   buf + i);\n\t\t}\n\t}\n\n\treturn i;\n}\n"], "fixing_code": ["/*\n * net/tipc/socket.c: TIPC socket API\n *\n * Copyright (c) 2001-2007, 2012-2019, Ericsson AB\n * Copyright (c) 2004-2008, 2010-2013, Wind River Systems\n * Copyright (c) 2020-2021, Red Hat Inc\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. Neither the names of the copyright holders nor the names of its\n *    contributors may be used to endorse or promote products derived from\n *    this software without specific prior written permission.\n *\n * Alternatively, this software may be distributed under the terms of the\n * GNU General Public License (\"GPL\") version 2 as published by the Free\n * Software Foundation.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include <linux/rhashtable.h>\n#include <linux/sched/signal.h>\n\n#include \"core.h\"\n#include \"name_table.h\"\n#include \"node.h\"\n#include \"link.h\"\n#include \"name_distr.h\"\n#include \"socket.h\"\n#include \"bcast.h\"\n#include \"netlink.h\"\n#include \"group.h\"\n#include \"trace.h\"\n\n#define NAGLE_START_INIT\t4\n#define NAGLE_START_MAX\t\t1024\n#define CONN_TIMEOUT_DEFAULT    8000    /* default connect timeout = 8s */\n#define CONN_PROBING_INTV\tmsecs_to_jiffies(3600000)  /* [ms] => 1 h */\n#define TIPC_MAX_PORT\t\t0xffffffff\n#define TIPC_MIN_PORT\t\t1\n#define TIPC_ACK_RATE\t\t4       /* ACK at 1/4 of rcv window size */\n\nenum {\n\tTIPC_LISTEN = TCP_LISTEN,\n\tTIPC_ESTABLISHED = TCP_ESTABLISHED,\n\tTIPC_OPEN = TCP_CLOSE,\n\tTIPC_DISCONNECTING = TCP_CLOSE_WAIT,\n\tTIPC_CONNECTING = TCP_SYN_SENT,\n};\n\nstruct sockaddr_pair {\n\tstruct sockaddr_tipc sock;\n\tstruct sockaddr_tipc member;\n};\n\n/**\n * struct tipc_sock - TIPC socket structure\n * @sk: socket - interacts with 'port' and with user via the socket API\n * @max_pkt: maximum packet size \"hint\" used when building messages sent by port\n * @maxnagle: maximum size of msg which can be subject to nagle\n * @portid: unique port identity in TIPC socket hash table\n * @phdr: preformatted message header used when sending messages\n * @cong_links: list of congested links\n * @publications: list of publications for port\n * @blocking_link: address of the congested link we are currently sleeping on\n * @pub_count: total # of publications port has made during its lifetime\n * @conn_timeout: the time we can wait for an unresponded setup request\n * @probe_unacked: probe has not received ack yet\n * @dupl_rcvcnt: number of bytes counted twice, in both backlog and rcv queue\n * @cong_link_cnt: number of congested links\n * @snt_unacked: # messages sent by socket, and not yet acked by peer\n * @snd_win: send window size\n * @peer_caps: peer capabilities mask\n * @rcv_unacked: # messages read by user, but not yet acked back to peer\n * @rcv_win: receive window size\n * @peer: 'connected' peer for dgram/rdm\n * @node: hash table node\n * @mc_method: cookie for use between socket and broadcast layer\n * @rcu: rcu struct for tipc_sock\n * @group: TIPC communications group\n * @oneway: message count in one direction (FIXME)\n * @nagle_start: current nagle value\n * @snd_backlog: send backlog count\n * @msg_acc: messages accepted; used in managing backlog and nagle\n * @pkt_cnt: TIPC socket packet count\n * @expect_ack: whether this TIPC socket is expecting an ack\n * @nodelay: setsockopt() TIPC_NODELAY setting\n * @group_is_open: TIPC socket group is fully open (FIXME)\n * @published: true if port has one or more associated names\n * @conn_addrtype: address type used when establishing connection\n */\nstruct tipc_sock {\n\tstruct sock sk;\n\tu32 max_pkt;\n\tu32 maxnagle;\n\tu32 portid;\n\tstruct tipc_msg phdr;\n\tstruct list_head cong_links;\n\tstruct list_head publications;\n\tu32 pub_count;\n\tatomic_t dupl_rcvcnt;\n\tu16 conn_timeout;\n\tbool probe_unacked;\n\tu16 cong_link_cnt;\n\tu16 snt_unacked;\n\tu16 snd_win;\n\tu16 peer_caps;\n\tu16 rcv_unacked;\n\tu16 rcv_win;\n\tstruct sockaddr_tipc peer;\n\tstruct rhash_head node;\n\tstruct tipc_mc_method mc_method;\n\tstruct rcu_head rcu;\n\tstruct tipc_group *group;\n\tu32 oneway;\n\tu32 nagle_start;\n\tu16 snd_backlog;\n\tu16 msg_acc;\n\tu16 pkt_cnt;\n\tbool expect_ack;\n\tbool nodelay;\n\tbool group_is_open;\n\tbool published;\n\tu8 conn_addrtype;\n};\n\nstatic int tipc_sk_backlog_rcv(struct sock *sk, struct sk_buff *skb);\nstatic void tipc_data_ready(struct sock *sk);\nstatic void tipc_write_space(struct sock *sk);\nstatic void tipc_sock_destruct(struct sock *sk);\nstatic int tipc_release(struct socket *sock);\nstatic int tipc_accept(struct socket *sock, struct socket *new_sock, int flags,\n\t\t       bool kern);\nstatic void tipc_sk_timeout(struct timer_list *t);\nstatic int tipc_sk_publish(struct tipc_sock *tsk, struct tipc_uaddr *ua);\nstatic int tipc_sk_withdraw(struct tipc_sock *tsk, struct tipc_uaddr *ua);\nstatic int tipc_sk_leave(struct tipc_sock *tsk);\nstatic struct tipc_sock *tipc_sk_lookup(struct net *net, u32 portid);\nstatic int tipc_sk_insert(struct tipc_sock *tsk);\nstatic void tipc_sk_remove(struct tipc_sock *tsk);\nstatic int __tipc_sendstream(struct socket *sock, struct msghdr *m, size_t dsz);\nstatic int __tipc_sendmsg(struct socket *sock, struct msghdr *m, size_t dsz);\nstatic void tipc_sk_push_backlog(struct tipc_sock *tsk, bool nagle_ack);\nstatic int tipc_wait_for_connect(struct socket *sock, long *timeo_p);\n\nstatic const struct proto_ops packet_ops;\nstatic const struct proto_ops stream_ops;\nstatic const struct proto_ops msg_ops;\nstatic struct proto tipc_proto;\nstatic const struct rhashtable_params tsk_rht_params;\n\nstatic u32 tsk_own_node(struct tipc_sock *tsk)\n{\n\treturn msg_prevnode(&tsk->phdr);\n}\n\nstatic u32 tsk_peer_node(struct tipc_sock *tsk)\n{\n\treturn msg_destnode(&tsk->phdr);\n}\n\nstatic u32 tsk_peer_port(struct tipc_sock *tsk)\n{\n\treturn msg_destport(&tsk->phdr);\n}\n\nstatic  bool tsk_unreliable(struct tipc_sock *tsk)\n{\n\treturn msg_src_droppable(&tsk->phdr) != 0;\n}\n\nstatic void tsk_set_unreliable(struct tipc_sock *tsk, bool unreliable)\n{\n\tmsg_set_src_droppable(&tsk->phdr, unreliable ? 1 : 0);\n}\n\nstatic bool tsk_unreturnable(struct tipc_sock *tsk)\n{\n\treturn msg_dest_droppable(&tsk->phdr) != 0;\n}\n\nstatic void tsk_set_unreturnable(struct tipc_sock *tsk, bool unreturnable)\n{\n\tmsg_set_dest_droppable(&tsk->phdr, unreturnable ? 1 : 0);\n}\n\nstatic int tsk_importance(struct tipc_sock *tsk)\n{\n\treturn msg_importance(&tsk->phdr);\n}\n\nstatic struct tipc_sock *tipc_sk(const struct sock *sk)\n{\n\treturn container_of(sk, struct tipc_sock, sk);\n}\n\nint tsk_set_importance(struct sock *sk, int imp)\n{\n\tif (imp > TIPC_CRITICAL_IMPORTANCE)\n\t\treturn -EINVAL;\n\tmsg_set_importance(&tipc_sk(sk)->phdr, (u32)imp);\n\treturn 0;\n}\n\nstatic bool tsk_conn_cong(struct tipc_sock *tsk)\n{\n\treturn tsk->snt_unacked > tsk->snd_win;\n}\n\nstatic u16 tsk_blocks(int len)\n{\n\treturn ((len / FLOWCTL_BLK_SZ) + 1);\n}\n\n/* tsk_blocks(): translate a buffer size in bytes to number of\n * advertisable blocks, taking into account the ratio truesize(len)/len\n * We can trust that this ratio is always < 4 for len >= FLOWCTL_BLK_SZ\n */\nstatic u16 tsk_adv_blocks(int len)\n{\n\treturn len / FLOWCTL_BLK_SZ / 4;\n}\n\n/* tsk_inc(): increment counter for sent or received data\n * - If block based flow control is not supported by peer we\n *   fall back to message based ditto, incrementing the counter\n */\nstatic u16 tsk_inc(struct tipc_sock *tsk, int msglen)\n{\n\tif (likely(tsk->peer_caps & TIPC_BLOCK_FLOWCTL))\n\t\treturn ((msglen / FLOWCTL_BLK_SZ) + 1);\n\treturn 1;\n}\n\n/* tsk_set_nagle - enable/disable nagle property by manipulating maxnagle\n */\nstatic void tsk_set_nagle(struct tipc_sock *tsk)\n{\n\tstruct sock *sk = &tsk->sk;\n\n\ttsk->maxnagle = 0;\n\tif (sk->sk_type != SOCK_STREAM)\n\t\treturn;\n\tif (tsk->nodelay)\n\t\treturn;\n\tif (!(tsk->peer_caps & TIPC_NAGLE))\n\t\treturn;\n\t/* Limit node local buffer size to avoid receive queue overflow */\n\tif (tsk->max_pkt == MAX_MSG_SIZE)\n\t\ttsk->maxnagle = 1500;\n\telse\n\t\ttsk->maxnagle = tsk->max_pkt;\n}\n\n/**\n * tsk_advance_rx_queue - discard first buffer in socket receive queue\n * @sk: network socket\n *\n * Caller must hold socket lock\n */\nstatic void tsk_advance_rx_queue(struct sock *sk)\n{\n\ttrace_tipc_sk_advance_rx(sk, NULL, TIPC_DUMP_SK_RCVQ, \" \");\n\tkfree_skb(__skb_dequeue(&sk->sk_receive_queue));\n}\n\n/* tipc_sk_respond() : send response message back to sender\n */\nstatic void tipc_sk_respond(struct sock *sk, struct sk_buff *skb, int err)\n{\n\tu32 selector;\n\tu32 dnode;\n\tu32 onode = tipc_own_addr(sock_net(sk));\n\n\tif (!tipc_msg_reverse(onode, &skb, err))\n\t\treturn;\n\n\ttrace_tipc_sk_rej_msg(sk, skb, TIPC_DUMP_NONE, \"@sk_respond!\");\n\tdnode = msg_destnode(buf_msg(skb));\n\tselector = msg_origport(buf_msg(skb));\n\ttipc_node_xmit_skb(sock_net(sk), skb, dnode, selector);\n}\n\n/**\n * tsk_rej_rx_queue - reject all buffers in socket receive queue\n * @sk: network socket\n * @error: response error code\n *\n * Caller must hold socket lock\n */\nstatic void tsk_rej_rx_queue(struct sock *sk, int error)\n{\n\tstruct sk_buff *skb;\n\n\twhile ((skb = __skb_dequeue(&sk->sk_receive_queue)))\n\t\ttipc_sk_respond(sk, skb, error);\n}\n\nstatic bool tipc_sk_connected(struct sock *sk)\n{\n\treturn sk->sk_state == TIPC_ESTABLISHED;\n}\n\n/* tipc_sk_type_connectionless - check if the socket is datagram socket\n * @sk: socket\n *\n * Returns true if connection less, false otherwise\n */\nstatic bool tipc_sk_type_connectionless(struct sock *sk)\n{\n\treturn sk->sk_type == SOCK_RDM || sk->sk_type == SOCK_DGRAM;\n}\n\n/* tsk_peer_msg - verify if message was sent by connected port's peer\n *\n * Handles cases where the node's network address has changed from\n * the default of <0.0.0> to its configured setting.\n */\nstatic bool tsk_peer_msg(struct tipc_sock *tsk, struct tipc_msg *msg)\n{\n\tstruct sock *sk = &tsk->sk;\n\tu32 self = tipc_own_addr(sock_net(sk));\n\tu32 peer_port = tsk_peer_port(tsk);\n\tu32 orig_node, peer_node;\n\n\tif (unlikely(!tipc_sk_connected(sk)))\n\t\treturn false;\n\n\tif (unlikely(msg_origport(msg) != peer_port))\n\t\treturn false;\n\n\torig_node = msg_orignode(msg);\n\tpeer_node = tsk_peer_node(tsk);\n\n\tif (likely(orig_node == peer_node))\n\t\treturn true;\n\n\tif (!orig_node && peer_node == self)\n\t\treturn true;\n\n\tif (!peer_node && orig_node == self)\n\t\treturn true;\n\n\treturn false;\n}\n\n/* tipc_set_sk_state - set the sk_state of the socket\n * @sk: socket\n *\n * Caller must hold socket lock\n *\n * Returns 0 on success, errno otherwise\n */\nstatic int tipc_set_sk_state(struct sock *sk, int state)\n{\n\tint oldsk_state = sk->sk_state;\n\tint res = -EINVAL;\n\n\tswitch (state) {\n\tcase TIPC_OPEN:\n\t\tres = 0;\n\t\tbreak;\n\tcase TIPC_LISTEN:\n\tcase TIPC_CONNECTING:\n\t\tif (oldsk_state == TIPC_OPEN)\n\t\t\tres = 0;\n\t\tbreak;\n\tcase TIPC_ESTABLISHED:\n\t\tif (oldsk_state == TIPC_CONNECTING ||\n\t\t    oldsk_state == TIPC_OPEN)\n\t\t\tres = 0;\n\t\tbreak;\n\tcase TIPC_DISCONNECTING:\n\t\tif (oldsk_state == TIPC_CONNECTING ||\n\t\t    oldsk_state == TIPC_ESTABLISHED)\n\t\t\tres = 0;\n\t\tbreak;\n\t}\n\n\tif (!res)\n\t\tsk->sk_state = state;\n\n\treturn res;\n}\n\nstatic int tipc_sk_sock_err(struct socket *sock, long *timeout)\n{\n\tstruct sock *sk = sock->sk;\n\tint err = sock_error(sk);\n\tint typ = sock->type;\n\n\tif (err)\n\t\treturn err;\n\tif (typ == SOCK_STREAM || typ == SOCK_SEQPACKET) {\n\t\tif (sk->sk_state == TIPC_DISCONNECTING)\n\t\t\treturn -EPIPE;\n\t\telse if (!tipc_sk_connected(sk))\n\t\t\treturn -ENOTCONN;\n\t}\n\tif (!*timeout)\n\t\treturn -EAGAIN;\n\tif (signal_pending(current))\n\t\treturn sock_intr_errno(*timeout);\n\n\treturn 0;\n}\n\n#define tipc_wait_for_cond(sock_, timeo_, condition_)\t\t\t       \\\n({                                                                             \\\n\tDEFINE_WAIT_FUNC(wait_, woken_wake_function);                          \\\n\tstruct sock *sk_;\t\t\t\t\t\t       \\\n\tint rc_;\t\t\t\t\t\t\t       \\\n\t\t\t\t\t\t\t\t\t       \\\n\twhile ((rc_ = !(condition_))) {\t\t\t\t\t       \\\n\t\t/* coupled with smp_wmb() in tipc_sk_proto_rcv() */            \\\n\t\tsmp_rmb();                                                     \\\n\t\tsk_ = (sock_)->sk;\t\t\t\t\t       \\\n\t\trc_ = tipc_sk_sock_err((sock_), timeo_);\t\t       \\\n\t\tif (rc_)\t\t\t\t\t\t       \\\n\t\t\tbreak;\t\t\t\t\t\t       \\\n\t\tadd_wait_queue(sk_sleep(sk_), &wait_);                         \\\n\t\trelease_sock(sk_);\t\t\t\t\t       \\\n\t\t*(timeo_) = wait_woken(&wait_, TASK_INTERRUPTIBLE, *(timeo_)); \\\n\t\tsched_annotate_sleep();\t\t\t\t               \\\n\t\tlock_sock(sk_);\t\t\t\t\t\t       \\\n\t\tremove_wait_queue(sk_sleep(sk_), &wait_);\t\t       \\\n\t}\t\t\t\t\t\t\t\t       \\\n\trc_;\t\t\t\t\t\t\t\t       \\\n})\n\n/**\n * tipc_sk_create - create a TIPC socket\n * @net: network namespace (must be default network)\n * @sock: pre-allocated socket structure\n * @protocol: protocol indicator (must be 0)\n * @kern: caused by kernel or by userspace?\n *\n * This routine creates additional data structures used by the TIPC socket,\n * initializes them, and links them together.\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_sk_create(struct net *net, struct socket *sock,\n\t\t\t  int protocol, int kern)\n{\n\tconst struct proto_ops *ops;\n\tstruct sock *sk;\n\tstruct tipc_sock *tsk;\n\tstruct tipc_msg *msg;\n\n\t/* Validate arguments */\n\tif (unlikely(protocol != 0))\n\t\treturn -EPROTONOSUPPORT;\n\n\tswitch (sock->type) {\n\tcase SOCK_STREAM:\n\t\tops = &stream_ops;\n\t\tbreak;\n\tcase SOCK_SEQPACKET:\n\t\tops = &packet_ops;\n\t\tbreak;\n\tcase SOCK_DGRAM:\n\tcase SOCK_RDM:\n\t\tops = &msg_ops;\n\t\tbreak;\n\tdefault:\n\t\treturn -EPROTOTYPE;\n\t}\n\n\t/* Allocate socket's protocol area */\n\tsk = sk_alloc(net, AF_TIPC, GFP_KERNEL, &tipc_proto, kern);\n\tif (sk == NULL)\n\t\treturn -ENOMEM;\n\n\ttsk = tipc_sk(sk);\n\ttsk->max_pkt = MAX_PKT_DEFAULT;\n\ttsk->maxnagle = 0;\n\ttsk->nagle_start = NAGLE_START_INIT;\n\tINIT_LIST_HEAD(&tsk->publications);\n\tINIT_LIST_HEAD(&tsk->cong_links);\n\tmsg = &tsk->phdr;\n\n\t/* Finish initializing socket data structures */\n\tsock->ops = ops;\n\tsock_init_data(sock, sk);\n\ttipc_set_sk_state(sk, TIPC_OPEN);\n\tif (tipc_sk_insert(tsk)) {\n\t\tpr_warn(\"Socket create failed; port number exhausted\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Ensure tsk is visible before we read own_addr. */\n\tsmp_mb();\n\n\ttipc_msg_init(tipc_own_addr(net), msg, TIPC_LOW_IMPORTANCE,\n\t\t      TIPC_NAMED_MSG, NAMED_H_SIZE, 0);\n\n\tmsg_set_origport(msg, tsk->portid);\n\ttimer_setup(&sk->sk_timer, tipc_sk_timeout, 0);\n\tsk->sk_shutdown = 0;\n\tsk->sk_backlog_rcv = tipc_sk_backlog_rcv;\n\tsk->sk_rcvbuf = sysctl_tipc_rmem[1];\n\tsk->sk_data_ready = tipc_data_ready;\n\tsk->sk_write_space = tipc_write_space;\n\tsk->sk_destruct = tipc_sock_destruct;\n\ttsk->conn_timeout = CONN_TIMEOUT_DEFAULT;\n\ttsk->group_is_open = true;\n\tatomic_set(&tsk->dupl_rcvcnt, 0);\n\n\t/* Start out with safe limits until we receive an advertised window */\n\ttsk->snd_win = tsk_adv_blocks(RCVBUF_MIN);\n\ttsk->rcv_win = tsk->snd_win;\n\n\tif (tipc_sk_type_connectionless(sk)) {\n\t\ttsk_set_unreturnable(tsk, true);\n\t\tif (sock->type == SOCK_DGRAM)\n\t\t\ttsk_set_unreliable(tsk, true);\n\t}\n\t__skb_queue_head_init(&tsk->mc_method.deferredq);\n\ttrace_tipc_sk_create(sk, NULL, TIPC_DUMP_NONE, \" \");\n\treturn 0;\n}\n\nstatic void tipc_sk_callback(struct rcu_head *head)\n{\n\tstruct tipc_sock *tsk = container_of(head, struct tipc_sock, rcu);\n\n\tsock_put(&tsk->sk);\n}\n\n/* Caller should hold socket lock for the socket. */\nstatic void __tipc_shutdown(struct socket *sock, int error)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tlong timeout = msecs_to_jiffies(CONN_TIMEOUT_DEFAULT);\n\tu32 dnode = tsk_peer_node(tsk);\n\tstruct sk_buff *skb;\n\n\t/* Avoid that hi-prio shutdown msgs bypass msgs in link wakeup queue */\n\ttipc_wait_for_cond(sock, &timeout, (!tsk->cong_link_cnt &&\n\t\t\t\t\t    !tsk_conn_cong(tsk)));\n\n\t/* Push out delayed messages if in Nagle mode */\n\ttipc_sk_push_backlog(tsk, false);\n\t/* Remove pending SYN */\n\t__skb_queue_purge(&sk->sk_write_queue);\n\n\t/* Remove partially received buffer if any */\n\tskb = skb_peek(&sk->sk_receive_queue);\n\tif (skb && TIPC_SKB_CB(skb)->bytes_read) {\n\t\t__skb_unlink(skb, &sk->sk_receive_queue);\n\t\tkfree_skb(skb);\n\t}\n\n\t/* Reject all unreceived messages if connectionless */\n\tif (tipc_sk_type_connectionless(sk)) {\n\t\ttsk_rej_rx_queue(sk, error);\n\t\treturn;\n\t}\n\n\tswitch (sk->sk_state) {\n\tcase TIPC_CONNECTING:\n\tcase TIPC_ESTABLISHED:\n\t\ttipc_set_sk_state(sk, TIPC_DISCONNECTING);\n\t\ttipc_node_remove_conn(net, dnode, tsk->portid);\n\t\t/* Send a FIN+/- to its peer */\n\t\tskb = __skb_dequeue(&sk->sk_receive_queue);\n\t\tif (skb) {\n\t\t\t__skb_queue_purge(&sk->sk_receive_queue);\n\t\t\ttipc_sk_respond(sk, skb, error);\n\t\t\tbreak;\n\t\t}\n\t\tskb = tipc_msg_create(TIPC_CRITICAL_IMPORTANCE,\n\t\t\t\t      TIPC_CONN_MSG, SHORT_H_SIZE, 0, dnode,\n\t\t\t\t      tsk_own_node(tsk), tsk_peer_port(tsk),\n\t\t\t\t      tsk->portid, error);\n\t\tif (skb)\n\t\t\ttipc_node_xmit_skb(net, skb, dnode, tsk->portid);\n\t\tbreak;\n\tcase TIPC_LISTEN:\n\t\t/* Reject all SYN messages */\n\t\ttsk_rej_rx_queue(sk, error);\n\t\tbreak;\n\tdefault:\n\t\t__skb_queue_purge(&sk->sk_receive_queue);\n\t\tbreak;\n\t}\n}\n\n/**\n * tipc_release - destroy a TIPC socket\n * @sock: socket to destroy\n *\n * This routine cleans up any messages that are still queued on the socket.\n * For DGRAM and RDM socket types, all queued messages are rejected.\n * For SEQPACKET and STREAM socket types, the first message is rejected\n * and any others are discarded.  (If the first message on a STREAM socket\n * is partially-read, it is discarded and the next one is rejected instead.)\n *\n * NOTE: Rejected messages are not necessarily returned to the sender!  They\n * are returned or discarded according to the \"destination droppable\" setting\n * specified for the message by the sender.\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_release(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk;\n\n\t/*\n\t * Exit if socket isn't fully initialized (occurs when a failed accept()\n\t * releases a pre-allocated child socket that was never used)\n\t */\n\tif (sk == NULL)\n\t\treturn 0;\n\n\ttsk = tipc_sk(sk);\n\tlock_sock(sk);\n\n\ttrace_tipc_sk_release(sk, NULL, TIPC_DUMP_ALL, \" \");\n\t__tipc_shutdown(sock, TIPC_ERR_NO_PORT);\n\tsk->sk_shutdown = SHUTDOWN_MASK;\n\ttipc_sk_leave(tsk);\n\ttipc_sk_withdraw(tsk, NULL);\n\t__skb_queue_purge(&tsk->mc_method.deferredq);\n\tsk_stop_timer(sk, &sk->sk_timer);\n\ttipc_sk_remove(tsk);\n\n\tsock_orphan(sk);\n\t/* Reject any messages that accumulated in backlog queue */\n\trelease_sock(sk);\n\ttipc_dest_list_purge(&tsk->cong_links);\n\ttsk->cong_link_cnt = 0;\n\tcall_rcu(&tsk->rcu, tipc_sk_callback);\n\tsock->sk = NULL;\n\n\treturn 0;\n}\n\n/**\n * __tipc_bind - associate or disassocate TIPC name(s) with a socket\n * @sock: socket structure\n * @skaddr: socket address describing name(s) and desired operation\n * @alen: size of socket address data structure\n *\n * Name and name sequence binding are indicated using a positive scope value;\n * a negative scope value unbinds the specified name.  Specifying no name\n * (i.e. a socket address length of 0) unbinds all names from the socket.\n *\n * Return: 0 on success, errno otherwise\n *\n * NOTE: This routine doesn't need to take the socket lock since it doesn't\n *       access any non-constant socket information.\n */\nstatic int __tipc_bind(struct socket *sock, struct sockaddr *skaddr, int alen)\n{\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)skaddr;\n\tstruct tipc_sock *tsk = tipc_sk(sock->sk);\n\tbool unbind = false;\n\n\tif (unlikely(!alen))\n\t\treturn tipc_sk_withdraw(tsk, NULL);\n\n\tif (ua->addrtype == TIPC_SERVICE_ADDR) {\n\t\tua->addrtype = TIPC_SERVICE_RANGE;\n\t\tua->sr.upper = ua->sr.lower;\n\t}\n\tif (ua->scope < 0) {\n\t\tunbind = true;\n\t\tua->scope = -ua->scope;\n\t}\n\t/* Users may still use deprecated TIPC_ZONE_SCOPE */\n\tif (ua->scope != TIPC_NODE_SCOPE)\n\t\tua->scope = TIPC_CLUSTER_SCOPE;\n\n\tif (tsk->group)\n\t\treturn -EACCES;\n\n\tif (unbind)\n\t\treturn tipc_sk_withdraw(tsk, ua);\n\treturn tipc_sk_publish(tsk, ua);\n}\n\nint tipc_sk_bind(struct socket *sock, struct sockaddr *skaddr, int alen)\n{\n\tint res;\n\n\tlock_sock(sock->sk);\n\tres = __tipc_bind(sock, skaddr, alen);\n\trelease_sock(sock->sk);\n\treturn res;\n}\n\nstatic int tipc_bind(struct socket *sock, struct sockaddr *skaddr, int alen)\n{\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)skaddr;\n\tu32 atype = ua->addrtype;\n\n\tif (alen) {\n\t\tif (!tipc_uaddr_valid(ua, alen))\n\t\t\treturn -EINVAL;\n\t\tif (atype == TIPC_SOCKET_ADDR)\n\t\t\treturn -EAFNOSUPPORT;\n\t\tif (ua->sr.type < TIPC_RESERVED_TYPES) {\n\t\t\tpr_warn_once(\"Can't bind to reserved service type %u\\n\",\n\t\t\t\t     ua->sr.type);\n\t\t\treturn -EACCES;\n\t\t}\n\t}\n\treturn tipc_sk_bind(sock, skaddr, alen);\n}\n\n/**\n * tipc_getname - get port ID of socket or peer socket\n * @sock: socket structure\n * @uaddr: area for returned socket address\n * @peer: 0 = own ID, 1 = current peer ID, 2 = current/former peer ID\n *\n * Return: 0 on success, errno otherwise\n *\n * NOTE: This routine doesn't need to take the socket lock since it only\n *       accesses socket information that is unchanging (or which changes in\n *       a completely predictable manner).\n */\nstatic int tipc_getname(struct socket *sock, struct sockaddr *uaddr,\n\t\t\tint peer)\n{\n\tstruct sockaddr_tipc *addr = (struct sockaddr_tipc *)uaddr;\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\n\tmemset(addr, 0, sizeof(*addr));\n\tif (peer) {\n\t\tif ((!tipc_sk_connected(sk)) &&\n\t\t    ((peer != 2) || (sk->sk_state != TIPC_DISCONNECTING)))\n\t\t\treturn -ENOTCONN;\n\t\taddr->addr.id.ref = tsk_peer_port(tsk);\n\t\taddr->addr.id.node = tsk_peer_node(tsk);\n\t} else {\n\t\taddr->addr.id.ref = tsk->portid;\n\t\taddr->addr.id.node = tipc_own_addr(sock_net(sk));\n\t}\n\n\taddr->addrtype = TIPC_SOCKET_ADDR;\n\taddr->family = AF_TIPC;\n\taddr->scope = 0;\n\taddr->addr.name.domain = 0;\n\n\treturn sizeof(*addr);\n}\n\n/**\n * tipc_poll - read and possibly block on pollmask\n * @file: file structure associated with the socket\n * @sock: socket for which to calculate the poll bits\n * @wait: ???\n *\n * Return: pollmask value\n *\n * COMMENTARY:\n * It appears that the usual socket locking mechanisms are not useful here\n * since the pollmask info is potentially out-of-date the moment this routine\n * exits.  TCP and other protocols seem to rely on higher level poll routines\n * to handle any preventable race conditions, so TIPC will do the same ...\n *\n * IMPORTANT: The fact that a read or write operation is indicated does NOT\n * imply that the operation will succeed, merely that it should be performed\n * and will not block.\n */\nstatic __poll_t tipc_poll(struct file *file, struct socket *sock,\n\t\t\t      poll_table *wait)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\t__poll_t revents = 0;\n\n\tsock_poll_wait(file, sock, wait);\n\ttrace_tipc_sk_poll(sk, NULL, TIPC_DUMP_ALL, \" \");\n\n\tif (sk->sk_shutdown & RCV_SHUTDOWN)\n\t\trevents |= EPOLLRDHUP | EPOLLIN | EPOLLRDNORM;\n\tif (sk->sk_shutdown == SHUTDOWN_MASK)\n\t\trevents |= EPOLLHUP;\n\n\tswitch (sk->sk_state) {\n\tcase TIPC_ESTABLISHED:\n\t\tif (!tsk->cong_link_cnt && !tsk_conn_cong(tsk))\n\t\t\trevents |= EPOLLOUT;\n\t\tfallthrough;\n\tcase TIPC_LISTEN:\n\tcase TIPC_CONNECTING:\n\t\tif (!skb_queue_empty_lockless(&sk->sk_receive_queue))\n\t\t\trevents |= EPOLLIN | EPOLLRDNORM;\n\t\tbreak;\n\tcase TIPC_OPEN:\n\t\tif (tsk->group_is_open && !tsk->cong_link_cnt)\n\t\t\trevents |= EPOLLOUT;\n\t\tif (!tipc_sk_type_connectionless(sk))\n\t\t\tbreak;\n\t\tif (skb_queue_empty_lockless(&sk->sk_receive_queue))\n\t\t\tbreak;\n\t\trevents |= EPOLLIN | EPOLLRDNORM;\n\t\tbreak;\n\tcase TIPC_DISCONNECTING:\n\t\trevents = EPOLLIN | EPOLLRDNORM | EPOLLHUP;\n\t\tbreak;\n\t}\n\treturn revents;\n}\n\n/**\n * tipc_sendmcast - send multicast message\n * @sock: socket structure\n * @ua: destination address struct\n * @msg: message to send\n * @dlen: length of data to send\n * @timeout: timeout to wait for wakeup\n *\n * Called from function tipc_sendmsg(), which has done all sanity checks\n * Return: the number of bytes sent on success, or errno\n */\nstatic int tipc_sendmcast(struct  socket *sock, struct tipc_uaddr *ua,\n\t\t\t  struct msghdr *msg, size_t dlen, long timeout)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct net *net = sock_net(sk);\n\tint mtu = tipc_bcast_get_mtu(net);\n\tstruct sk_buff_head pkts;\n\tstruct tipc_nlist dsts;\n\tint rc;\n\n\tif (tsk->group)\n\t\treturn -EACCES;\n\n\t/* Block or return if any destination link is congested */\n\trc = tipc_wait_for_cond(sock, &timeout, !tsk->cong_link_cnt);\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\t/* Lookup destination nodes */\n\ttipc_nlist_init(&dsts, tipc_own_addr(net));\n\ttipc_nametbl_lookup_mcast_nodes(net, ua, &dsts);\n\tif (!dsts.local && !dsts.remote)\n\t\treturn -EHOSTUNREACH;\n\n\t/* Build message header */\n\tmsg_set_type(hdr, TIPC_MCAST_MSG);\n\tmsg_set_hdr_sz(hdr, MCAST_H_SIZE);\n\tmsg_set_lookup_scope(hdr, TIPC_CLUSTER_SCOPE);\n\tmsg_set_destport(hdr, 0);\n\tmsg_set_destnode(hdr, 0);\n\tmsg_set_nametype(hdr, ua->sr.type);\n\tmsg_set_namelower(hdr, ua->sr.lower);\n\tmsg_set_nameupper(hdr, ua->sr.upper);\n\n\t/* Build message as chain of buffers */\n\t__skb_queue_head_init(&pkts);\n\trc = tipc_msg_build(hdr, msg, 0, dlen, mtu, &pkts);\n\n\t/* Send message if build was successful */\n\tif (unlikely(rc == dlen)) {\n\t\ttrace_tipc_sk_sendmcast(sk, skb_peek(&pkts),\n\t\t\t\t\tTIPC_DUMP_SK_SNDQ, \" \");\n\t\trc = tipc_mcast_xmit(net, &pkts, &tsk->mc_method, &dsts,\n\t\t\t\t     &tsk->cong_link_cnt);\n\t}\n\n\ttipc_nlist_purge(&dsts);\n\n\treturn rc ? rc : dlen;\n}\n\n/**\n * tipc_send_group_msg - send a message to a member in the group\n * @net: network namespace\n * @tsk: tipc socket\n * @m: message to send\n * @mb: group member\n * @dnode: destination node\n * @dport: destination port\n * @dlen: total length of message data\n */\nstatic int tipc_send_group_msg(struct net *net, struct tipc_sock *tsk,\n\t\t\t       struct msghdr *m, struct tipc_member *mb,\n\t\t\t       u32 dnode, u32 dport, int dlen)\n{\n\tu16 bc_snd_nxt = tipc_group_bc_snd_nxt(tsk->group);\n\tstruct tipc_mc_method *method = &tsk->mc_method;\n\tint blks = tsk_blocks(GROUP_H_SIZE + dlen);\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct sk_buff_head pkts;\n\tint mtu, rc;\n\n\t/* Complete message header */\n\tmsg_set_type(hdr, TIPC_GRP_UCAST_MSG);\n\tmsg_set_hdr_sz(hdr, GROUP_H_SIZE);\n\tmsg_set_destport(hdr, dport);\n\tmsg_set_destnode(hdr, dnode);\n\tmsg_set_grp_bc_seqno(hdr, bc_snd_nxt);\n\n\t/* Build message as chain of buffers */\n\t__skb_queue_head_init(&pkts);\n\tmtu = tipc_node_get_mtu(net, dnode, tsk->portid, false);\n\trc = tipc_msg_build(hdr, m, 0, dlen, mtu, &pkts);\n\tif (unlikely(rc != dlen))\n\t\treturn rc;\n\n\t/* Send message */\n\trc = tipc_node_xmit(net, &pkts, dnode, tsk->portid);\n\tif (unlikely(rc == -ELINKCONG)) {\n\t\ttipc_dest_push(&tsk->cong_links, dnode, 0);\n\t\ttsk->cong_link_cnt++;\n\t}\n\n\t/* Update send window */\n\ttipc_group_update_member(mb, blks);\n\n\t/* A broadcast sent within next EXPIRE period must follow same path */\n\tmethod->rcast = true;\n\tmethod->mandatory = true;\n\treturn dlen;\n}\n\n/**\n * tipc_send_group_unicast - send message to a member in the group\n * @sock: socket structure\n * @m: message to send\n * @dlen: total length of message data\n * @timeout: timeout to wait for wakeup\n *\n * Called from function tipc_sendmsg(), which has done all sanity checks\n * Return: the number of bytes sent on success, or errno\n */\nstatic int tipc_send_group_unicast(struct socket *sock, struct msghdr *m,\n\t\t\t\t   int dlen, long timeout)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tint blks = tsk_blocks(GROUP_H_SIZE + dlen);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_member *mb = NULL;\n\tu32 node, port;\n\tint rc;\n\n\tnode = ua->sk.node;\n\tport = ua->sk.ref;\n\tif (!port && !node)\n\t\treturn -EHOSTUNREACH;\n\n\t/* Block or return if destination link or member is congested */\n\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t!tipc_dest_find(&tsk->cong_links, node, 0) &&\n\t\t\t\ttsk->group &&\n\t\t\t\t!tipc_group_cong(tsk->group, node, port, blks,\n\t\t\t\t\t\t &mb));\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\tif (unlikely(!mb))\n\t\treturn -EHOSTUNREACH;\n\n\trc = tipc_send_group_msg(net, tsk, m, mb, node, port, dlen);\n\n\treturn rc ? rc : dlen;\n}\n\n/**\n * tipc_send_group_anycast - send message to any member with given identity\n * @sock: socket structure\n * @m: message to send\n * @dlen: total length of message data\n * @timeout: timeout to wait for wakeup\n *\n * Called from function tipc_sendmsg(), which has done all sanity checks\n * Return: the number of bytes sent on success, or errno\n */\nstatic int tipc_send_group_anycast(struct socket *sock, struct msghdr *m,\n\t\t\t\t   int dlen, long timeout)\n{\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct list_head *cong_links = &tsk->cong_links;\n\tint blks = tsk_blocks(GROUP_H_SIZE + dlen);\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct tipc_member *first = NULL;\n\tstruct tipc_member *mbr = NULL;\n\tstruct net *net = sock_net(sk);\n\tu32 node, port, exclude;\n\tstruct list_head dsts;\n\tint lookups = 0;\n\tint dstcnt, rc;\n\tbool cong;\n\n\tINIT_LIST_HEAD(&dsts);\n\tua->sa.type = msg_nametype(hdr);\n\tua->scope = msg_lookup_scope(hdr);\n\n\twhile (++lookups < 4) {\n\t\texclude = tipc_group_exclude(tsk->group);\n\n\t\tfirst = NULL;\n\n\t\t/* Look for a non-congested destination member, if any */\n\t\twhile (1) {\n\t\t\tif (!tipc_nametbl_lookup_group(net, ua, &dsts, &dstcnt,\n\t\t\t\t\t\t       exclude, false))\n\t\t\t\treturn -EHOSTUNREACH;\n\t\t\ttipc_dest_pop(&dsts, &node, &port);\n\t\t\tcong = tipc_group_cong(tsk->group, node, port, blks,\n\t\t\t\t\t       &mbr);\n\t\t\tif (!cong)\n\t\t\t\tbreak;\n\t\t\tif (mbr == first)\n\t\t\t\tbreak;\n\t\t\tif (!first)\n\t\t\t\tfirst = mbr;\n\t\t}\n\n\t\t/* Start over if destination was not in member list */\n\t\tif (unlikely(!mbr))\n\t\t\tcontinue;\n\n\t\tif (likely(!cong && !tipc_dest_find(cong_links, node, 0)))\n\t\t\tbreak;\n\n\t\t/* Block or return if destination link or member is congested */\n\t\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t\t!tipc_dest_find(cong_links, node, 0) &&\n\t\t\t\t\ttsk->group &&\n\t\t\t\t\t!tipc_group_cong(tsk->group, node, port,\n\t\t\t\t\t\t\t blks, &mbr));\n\t\tif (unlikely(rc))\n\t\t\treturn rc;\n\n\t\t/* Send, unless destination disappeared while waiting */\n\t\tif (likely(mbr))\n\t\t\tbreak;\n\t}\n\n\tif (unlikely(lookups >= 4))\n\t\treturn -EHOSTUNREACH;\n\n\trc = tipc_send_group_msg(net, tsk, m, mbr, node, port, dlen);\n\n\treturn rc ? rc : dlen;\n}\n\n/**\n * tipc_send_group_bcast - send message to all members in communication group\n * @sock: socket structure\n * @m: message to send\n * @dlen: total length of message data\n * @timeout: timeout to wait for wakeup\n *\n * Called from function tipc_sendmsg(), which has done all sanity checks\n * Return: the number of bytes sent on success, or errno\n */\nstatic int tipc_send_group_bcast(struct socket *sock, struct msghdr *m,\n\t\t\t\t int dlen, long timeout)\n{\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tstruct sock *sk = sock->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_nlist *dsts;\n\tstruct tipc_mc_method *method = &tsk->mc_method;\n\tbool ack = method->mandatory && method->rcast;\n\tint blks = tsk_blocks(MCAST_H_SIZE + dlen);\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tint mtu = tipc_bcast_get_mtu(net);\n\tstruct sk_buff_head pkts;\n\tint rc = -EHOSTUNREACH;\n\n\t/* Block or return if any destination link or member is congested */\n\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t!tsk->cong_link_cnt && tsk->group &&\n\t\t\t\t!tipc_group_bc_cong(tsk->group, blks));\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\tdsts = tipc_group_dests(tsk->group);\n\tif (!dsts->local && !dsts->remote)\n\t\treturn -EHOSTUNREACH;\n\n\t/* Complete message header */\n\tif (ua) {\n\t\tmsg_set_type(hdr, TIPC_GRP_MCAST_MSG);\n\t\tmsg_set_nameinst(hdr, ua->sa.instance);\n\t} else {\n\t\tmsg_set_type(hdr, TIPC_GRP_BCAST_MSG);\n\t\tmsg_set_nameinst(hdr, 0);\n\t}\n\tmsg_set_hdr_sz(hdr, GROUP_H_SIZE);\n\tmsg_set_destport(hdr, 0);\n\tmsg_set_destnode(hdr, 0);\n\tmsg_set_grp_bc_seqno(hdr, tipc_group_bc_snd_nxt(tsk->group));\n\n\t/* Avoid getting stuck with repeated forced replicasts */\n\tmsg_set_grp_bc_ack_req(hdr, ack);\n\n\t/* Build message as chain of buffers */\n\t__skb_queue_head_init(&pkts);\n\trc = tipc_msg_build(hdr, m, 0, dlen, mtu, &pkts);\n\tif (unlikely(rc != dlen))\n\t\treturn rc;\n\n\t/* Send message */\n\trc = tipc_mcast_xmit(net, &pkts, method, dsts, &tsk->cong_link_cnt);\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\t/* Update broadcast sequence number and send windows */\n\ttipc_group_update_bc_members(tsk->group, blks, ack);\n\n\t/* Broadcast link is now free to choose method for next broadcast */\n\tmethod->mandatory = false;\n\tmethod->expires = jiffies;\n\n\treturn dlen;\n}\n\n/**\n * tipc_send_group_mcast - send message to all members with given identity\n * @sock: socket structure\n * @m: message to send\n * @dlen: total length of message data\n * @timeout: timeout to wait for wakeup\n *\n * Called from function tipc_sendmsg(), which has done all sanity checks\n * Return: the number of bytes sent on success, or errno\n */\nstatic int tipc_send_group_mcast(struct socket *sock, struct msghdr *m,\n\t\t\t\t int dlen, long timeout)\n{\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct net *net = sock_net(sk);\n\tstruct list_head dsts;\n\tu32 dstcnt, exclude;\n\n\tINIT_LIST_HEAD(&dsts);\n\tua->sa.type = msg_nametype(hdr);\n\tua->scope = msg_lookup_scope(hdr);\n\texclude = tipc_group_exclude(grp);\n\n\tif (!tipc_nametbl_lookup_group(net, ua, &dsts, &dstcnt, exclude, true))\n\t\treturn -EHOSTUNREACH;\n\n\tif (dstcnt == 1) {\n\t\ttipc_dest_pop(&dsts, &ua->sk.node, &ua->sk.ref);\n\t\treturn tipc_send_group_unicast(sock, m, dlen, timeout);\n\t}\n\n\ttipc_dest_list_purge(&dsts);\n\treturn tipc_send_group_bcast(sock, m, dlen, timeout);\n}\n\n/**\n * tipc_sk_mcast_rcv - Deliver multicast messages to all destination sockets\n * @net: the associated network namespace\n * @arrvq: queue with arriving messages, to be cloned after destination lookup\n * @inputq: queue with cloned messages, delivered to socket after dest lookup\n *\n * Multi-threaded: parallel calls with reference to same queues may occur\n */\nvoid tipc_sk_mcast_rcv(struct net *net, struct sk_buff_head *arrvq,\n\t\t       struct sk_buff_head *inputq)\n{\n\tu32 self = tipc_own_addr(net);\n\tstruct sk_buff *skb, *_skb;\n\tu32 portid, onode;\n\tstruct sk_buff_head tmpq;\n\tstruct list_head dports;\n\tstruct tipc_msg *hdr;\n\tstruct tipc_uaddr ua;\n\tint user, mtyp, hlen;\n\n\t__skb_queue_head_init(&tmpq);\n\tINIT_LIST_HEAD(&dports);\n\tua.addrtype = TIPC_SERVICE_RANGE;\n\n\t/* tipc_skb_peek() increments the head skb's reference counter */\n\tskb = tipc_skb_peek(arrvq, &inputq->lock);\n\tfor (; skb; skb = tipc_skb_peek(arrvq, &inputq->lock)) {\n\t\thdr = buf_msg(skb);\n\t\tuser = msg_user(hdr);\n\t\tmtyp = msg_type(hdr);\n\t\thlen = skb_headroom(skb) + msg_hdr_sz(hdr);\n\t\tonode = msg_orignode(hdr);\n\t\tua.sr.type = msg_nametype(hdr);\n\t\tua.sr.lower = msg_namelower(hdr);\n\t\tua.sr.upper = msg_nameupper(hdr);\n\t\tif (onode == self)\n\t\t\tua.scope = TIPC_ANY_SCOPE;\n\t\telse\n\t\t\tua.scope = TIPC_CLUSTER_SCOPE;\n\n\t\tif (mtyp == TIPC_GRP_UCAST_MSG || user == GROUP_PROTOCOL) {\n\t\t\tspin_lock_bh(&inputq->lock);\n\t\t\tif (skb_peek(arrvq) == skb) {\n\t\t\t\t__skb_dequeue(arrvq);\n\t\t\t\t__skb_queue_tail(inputq, skb);\n\t\t\t}\n\t\t\tkfree_skb(skb);\n\t\t\tspin_unlock_bh(&inputq->lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Group messages require exact scope match */\n\t\tif (msg_in_group(hdr)) {\n\t\t\tua.sr.lower = 0;\n\t\t\tua.sr.upper = ~0;\n\t\t\tua.scope = msg_lookup_scope(hdr);\n\t\t}\n\n\t\t/* Create destination port list: */\n\t\ttipc_nametbl_lookup_mcast_sockets(net, &ua, &dports);\n\n\t\t/* Clone message per destination */\n\t\twhile (tipc_dest_pop(&dports, NULL, &portid)) {\n\t\t\t_skb = __pskb_copy(skb, hlen, GFP_ATOMIC);\n\t\t\tif (_skb) {\n\t\t\t\tmsg_set_destport(buf_msg(_skb), portid);\n\t\t\t\t__skb_queue_tail(&tmpq, _skb);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tpr_warn(\"Failed to clone mcast rcv buffer\\n\");\n\t\t}\n\t\t/* Append clones to inputq only if skb is still head of arrvq */\n\t\tspin_lock_bh(&inputq->lock);\n\t\tif (skb_peek(arrvq) == skb) {\n\t\t\tskb_queue_splice_tail_init(&tmpq, inputq);\n\t\t\t/* Decrement the skb's refcnt */\n\t\t\tkfree_skb(__skb_dequeue(arrvq));\n\t\t}\n\t\tspin_unlock_bh(&inputq->lock);\n\t\t__skb_queue_purge(&tmpq);\n\t\tkfree_skb(skb);\n\t}\n\ttipc_sk_rcv(net, inputq);\n}\n\n/* tipc_sk_push_backlog(): send accumulated buffers in socket write queue\n *                         when socket is in Nagle mode\n */\nstatic void tipc_sk_push_backlog(struct tipc_sock *tsk, bool nagle_ack)\n{\n\tstruct sk_buff_head *txq = &tsk->sk.sk_write_queue;\n\tstruct sk_buff *skb = skb_peek_tail(txq);\n\tstruct net *net = sock_net(&tsk->sk);\n\tu32 dnode = tsk_peer_node(tsk);\n\tint rc;\n\n\tif (nagle_ack) {\n\t\ttsk->pkt_cnt += skb_queue_len(txq);\n\t\tif (!tsk->pkt_cnt || tsk->msg_acc / tsk->pkt_cnt < 2) {\n\t\t\ttsk->oneway = 0;\n\t\t\tif (tsk->nagle_start < NAGLE_START_MAX)\n\t\t\t\ttsk->nagle_start *= 2;\n\t\t\ttsk->expect_ack = false;\n\t\t\tpr_debug(\"tsk %10u: bad nagle %u -> %u, next start %u!\\n\",\n\t\t\t\t tsk->portid, tsk->msg_acc, tsk->pkt_cnt,\n\t\t\t\t tsk->nagle_start);\n\t\t} else {\n\t\t\ttsk->nagle_start = NAGLE_START_INIT;\n\t\t\tif (skb) {\n\t\t\t\tmsg_set_ack_required(buf_msg(skb));\n\t\t\t\ttsk->expect_ack = true;\n\t\t\t} else {\n\t\t\t\ttsk->expect_ack = false;\n\t\t\t}\n\t\t}\n\t\ttsk->msg_acc = 0;\n\t\ttsk->pkt_cnt = 0;\n\t}\n\n\tif (!skb || tsk->cong_link_cnt)\n\t\treturn;\n\n\t/* Do not send SYN again after congestion */\n\tif (msg_is_syn(buf_msg(skb)))\n\t\treturn;\n\n\tif (tsk->msg_acc)\n\t\ttsk->pkt_cnt += skb_queue_len(txq);\n\ttsk->snt_unacked += tsk->snd_backlog;\n\ttsk->snd_backlog = 0;\n\trc = tipc_node_xmit(net, txq, dnode, tsk->portid);\n\tif (rc == -ELINKCONG)\n\t\ttsk->cong_link_cnt = 1;\n}\n\n/**\n * tipc_sk_conn_proto_rcv - receive a connection mng protocol message\n * @tsk: receiving socket\n * @skb: pointer to message buffer.\n * @inputq: buffer list containing the buffers\n * @xmitq: output message area\n */\nstatic void tipc_sk_conn_proto_rcv(struct tipc_sock *tsk, struct sk_buff *skb,\n\t\t\t\t   struct sk_buff_head *inputq,\n\t\t\t\t   struct sk_buff_head *xmitq)\n{\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tu32 onode = tsk_own_node(tsk);\n\tstruct sock *sk = &tsk->sk;\n\tint mtyp = msg_type(hdr);\n\tbool was_cong;\n\n\t/* Ignore if connection cannot be validated: */\n\tif (!tsk_peer_msg(tsk, hdr)) {\n\t\ttrace_tipc_sk_drop_msg(sk, skb, TIPC_DUMP_NONE, \"@proto_rcv!\");\n\t\tgoto exit;\n\t}\n\n\tif (unlikely(msg_errcode(hdr))) {\n\t\ttipc_set_sk_state(sk, TIPC_DISCONNECTING);\n\t\ttipc_node_remove_conn(sock_net(sk), tsk_peer_node(tsk),\n\t\t\t\t      tsk_peer_port(tsk));\n\t\tsk->sk_state_change(sk);\n\n\t\t/* State change is ignored if socket already awake,\n\t\t * - convert msg to abort msg and add to inqueue\n\t\t */\n\t\tmsg_set_user(hdr, TIPC_CRITICAL_IMPORTANCE);\n\t\tmsg_set_type(hdr, TIPC_CONN_MSG);\n\t\tmsg_set_size(hdr, BASIC_H_SIZE);\n\t\tmsg_set_hdr_sz(hdr, BASIC_H_SIZE);\n\t\t__skb_queue_tail(inputq, skb);\n\t\treturn;\n\t}\n\n\ttsk->probe_unacked = false;\n\n\tif (mtyp == CONN_PROBE) {\n\t\tmsg_set_type(hdr, CONN_PROBE_REPLY);\n\t\tif (tipc_msg_reverse(onode, &skb, TIPC_OK))\n\t\t\t__skb_queue_tail(xmitq, skb);\n\t\treturn;\n\t} else if (mtyp == CONN_ACK) {\n\t\twas_cong = tsk_conn_cong(tsk);\n\t\ttipc_sk_push_backlog(tsk, msg_nagle_ack(hdr));\n\t\ttsk->snt_unacked -= msg_conn_ack(hdr);\n\t\tif (tsk->peer_caps & TIPC_BLOCK_FLOWCTL)\n\t\t\ttsk->snd_win = msg_adv_win(hdr);\n\t\tif (was_cong && !tsk_conn_cong(tsk))\n\t\t\tsk->sk_write_space(sk);\n\t} else if (mtyp != CONN_PROBE_REPLY) {\n\t\tpr_warn(\"Received unknown CONN_PROTO msg\\n\");\n\t}\nexit:\n\tkfree_skb(skb);\n}\n\n/**\n * tipc_sendmsg - send message in connectionless manner\n * @sock: socket structure\n * @m: message to send\n * @dsz: amount of user data to be sent\n *\n * Message must have an destination specified explicitly.\n * Used for SOCK_RDM and SOCK_DGRAM messages,\n * and for 'SYN' messages on SOCK_SEQPACKET and SOCK_STREAM connections.\n * (Note: 'SYN+' is prohibited on SOCK_STREAM.)\n *\n * Return: the number of bytes sent on success, or errno otherwise\n */\nstatic int tipc_sendmsg(struct socket *sock,\n\t\t\tstruct msghdr *m, size_t dsz)\n{\n\tstruct sock *sk = sock->sk;\n\tint ret;\n\n\tlock_sock(sk);\n\tret = __tipc_sendmsg(sock, m, dsz);\n\trelease_sock(sk);\n\n\treturn ret;\n}\n\nstatic int __tipc_sendmsg(struct socket *sock, struct msghdr *m, size_t dlen)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tlong timeout = sock_sndtimeo(sk, m->msg_flags & MSG_DONTWAIT);\n\tstruct list_head *clinks = &tsk->cong_links;\n\tbool syn = !tipc_sk_type_connectionless(sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct tipc_socket_addr skaddr;\n\tstruct sk_buff_head pkts;\n\tint atype, mtu, rc;\n\n\tif (unlikely(dlen > TIPC_MAX_USER_MSG_SIZE))\n\t\treturn -EMSGSIZE;\n\n\tif (ua) {\n\t\tif (!tipc_uaddr_valid(ua, m->msg_namelen))\n\t\t\treturn -EINVAL;\n\t\tatype = ua->addrtype;\n\t}\n\n\t/* If socket belongs to a communication group follow other paths */\n\tif (grp) {\n\t\tif (!ua)\n\t\t\treturn tipc_send_group_bcast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SERVICE_ADDR)\n\t\t\treturn tipc_send_group_anycast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SOCKET_ADDR)\n\t\t\treturn tipc_send_group_unicast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SERVICE_RANGE)\n\t\t\treturn tipc_send_group_mcast(sock, m, dlen, timeout);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ua) {\n\t\tua = (struct tipc_uaddr *)&tsk->peer;\n\t\tif (!syn && ua->family != AF_TIPC)\n\t\t\treturn -EDESTADDRREQ;\n\t\tatype = ua->addrtype;\n\t}\n\n\tif (unlikely(syn)) {\n\t\tif (sk->sk_state == TIPC_LISTEN)\n\t\t\treturn -EPIPE;\n\t\tif (sk->sk_state != TIPC_OPEN)\n\t\t\treturn -EISCONN;\n\t\tif (tsk->published)\n\t\t\treturn -EOPNOTSUPP;\n\t\tif (atype == TIPC_SERVICE_ADDR)\n\t\t\ttsk->conn_addrtype = atype;\n\t\tmsg_set_syn(hdr, 1);\n\t}\n\n\tmemset(&skaddr, 0, sizeof(skaddr));\n\n\t/* Determine destination */\n\tif (atype == TIPC_SERVICE_RANGE) {\n\t\treturn tipc_sendmcast(sock, ua, m, dlen, timeout);\n\t} else if (atype == TIPC_SERVICE_ADDR) {\n\t\tskaddr.node = ua->lookup_node;\n\t\tua->scope = tipc_node2scope(skaddr.node);\n\t\tif (!tipc_nametbl_lookup_anycast(net, ua, &skaddr))\n\t\t\treturn -EHOSTUNREACH;\n\t} else if (atype == TIPC_SOCKET_ADDR) {\n\t\tskaddr = ua->sk;\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\t/* Block or return if destination link is congested */\n\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t!tipc_dest_find(clinks, skaddr.node, 0));\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\t/* Finally build message header */\n\tmsg_set_destnode(hdr, skaddr.node);\n\tmsg_set_destport(hdr, skaddr.ref);\n\tif (atype == TIPC_SERVICE_ADDR) {\n\t\tmsg_set_type(hdr, TIPC_NAMED_MSG);\n\t\tmsg_set_hdr_sz(hdr, NAMED_H_SIZE);\n\t\tmsg_set_nametype(hdr, ua->sa.type);\n\t\tmsg_set_nameinst(hdr, ua->sa.instance);\n\t\tmsg_set_lookup_scope(hdr, ua->scope);\n\t} else { /* TIPC_SOCKET_ADDR */\n\t\tmsg_set_type(hdr, TIPC_DIRECT_MSG);\n\t\tmsg_set_lookup_scope(hdr, 0);\n\t\tmsg_set_hdr_sz(hdr, BASIC_H_SIZE);\n\t}\n\n\t/* Add message body */\n\t__skb_queue_head_init(&pkts);\n\tmtu = tipc_node_get_mtu(net, skaddr.node, tsk->portid, true);\n\trc = tipc_msg_build(hdr, m, 0, dlen, mtu, &pkts);\n\tif (unlikely(rc != dlen))\n\t\treturn rc;\n\tif (unlikely(syn && !tipc_msg_skb_clone(&pkts, &sk->sk_write_queue))) {\n\t\t__skb_queue_purge(&pkts);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Send message */\n\ttrace_tipc_sk_sendmsg(sk, skb_peek(&pkts), TIPC_DUMP_SK_SNDQ, \" \");\n\trc = tipc_node_xmit(net, &pkts, skaddr.node, tsk->portid);\n\tif (unlikely(rc == -ELINKCONG)) {\n\t\ttipc_dest_push(clinks, skaddr.node, 0);\n\t\ttsk->cong_link_cnt++;\n\t\trc = 0;\n\t}\n\n\tif (unlikely(syn && !rc)) {\n\t\ttipc_set_sk_state(sk, TIPC_CONNECTING);\n\t\tif (dlen && timeout) {\n\t\t\ttimeout = msecs_to_jiffies(timeout);\n\t\t\ttipc_wait_for_connect(sock, &timeout);\n\t\t}\n\t}\n\n\treturn rc ? rc : dlen;\n}\n\n/**\n * tipc_sendstream - send stream-oriented data\n * @sock: socket structure\n * @m: data to send\n * @dsz: total length of data to be transmitted\n *\n * Used for SOCK_STREAM data.\n *\n * Return: the number of bytes sent on success (or partial success),\n * or errno if no data sent\n */\nstatic int tipc_sendstream(struct socket *sock, struct msghdr *m, size_t dsz)\n{\n\tstruct sock *sk = sock->sk;\n\tint ret;\n\n\tlock_sock(sk);\n\tret = __tipc_sendstream(sock, m, dsz);\n\trelease_sock(sk);\n\n\treturn ret;\n}\n\nstatic int __tipc_sendstream(struct socket *sock, struct msghdr *m, size_t dlen)\n{\n\tstruct sock *sk = sock->sk;\n\tDECLARE_SOCKADDR(struct sockaddr_tipc *, dest, m->msg_name);\n\tlong timeout = sock_sndtimeo(sk, m->msg_flags & MSG_DONTWAIT);\n\tstruct sk_buff_head *txq = &sk->sk_write_queue;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct net *net = sock_net(sk);\n\tstruct sk_buff *skb;\n\tu32 dnode = tsk_peer_node(tsk);\n\tint maxnagle = tsk->maxnagle;\n\tint maxpkt = tsk->max_pkt;\n\tint send, sent = 0;\n\tint blocks, rc = 0;\n\n\tif (unlikely(dlen > INT_MAX))\n\t\treturn -EMSGSIZE;\n\n\t/* Handle implicit connection setup */\n\tif (unlikely(dest && sk->sk_state == TIPC_OPEN)) {\n\t\trc = __tipc_sendmsg(sock, m, dlen);\n\t\tif (dlen && dlen == rc) {\n\t\t\ttsk->peer_caps = tipc_node_get_capabilities(net, dnode);\n\t\t\ttsk->snt_unacked = tsk_inc(tsk, dlen + msg_hdr_sz(hdr));\n\t\t}\n\t\treturn rc;\n\t}\n\n\tdo {\n\t\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t\t(!tsk->cong_link_cnt &&\n\t\t\t\t\t !tsk_conn_cong(tsk) &&\n\t\t\t\t\t tipc_sk_connected(sk)));\n\t\tif (unlikely(rc))\n\t\t\tbreak;\n\t\tsend = min_t(size_t, dlen - sent, TIPC_MAX_USER_MSG_SIZE);\n\t\tblocks = tsk->snd_backlog;\n\t\tif (tsk->oneway++ >= tsk->nagle_start && maxnagle &&\n\t\t    send <= maxnagle) {\n\t\t\trc = tipc_msg_append(hdr, m, send, maxnagle, txq);\n\t\t\tif (unlikely(rc < 0))\n\t\t\t\tbreak;\n\t\t\tblocks += rc;\n\t\t\ttsk->msg_acc++;\n\t\t\tif (blocks <= 64 && tsk->expect_ack) {\n\t\t\t\ttsk->snd_backlog = blocks;\n\t\t\t\tsent += send;\n\t\t\t\tbreak;\n\t\t\t} else if (blocks > 64) {\n\t\t\t\ttsk->pkt_cnt += skb_queue_len(txq);\n\t\t\t} else {\n\t\t\t\tskb = skb_peek_tail(txq);\n\t\t\t\tif (skb) {\n\t\t\t\t\tmsg_set_ack_required(buf_msg(skb));\n\t\t\t\t\ttsk->expect_ack = true;\n\t\t\t\t} else {\n\t\t\t\t\ttsk->expect_ack = false;\n\t\t\t\t}\n\t\t\t\ttsk->msg_acc = 0;\n\t\t\t\ttsk->pkt_cnt = 0;\n\t\t\t}\n\t\t} else {\n\t\t\trc = tipc_msg_build(hdr, m, sent, send, maxpkt, txq);\n\t\t\tif (unlikely(rc != send))\n\t\t\t\tbreak;\n\t\t\tblocks += tsk_inc(tsk, send + MIN_H_SIZE);\n\t\t}\n\t\ttrace_tipc_sk_sendstream(sk, skb_peek(txq),\n\t\t\t\t\t TIPC_DUMP_SK_SNDQ, \" \");\n\t\trc = tipc_node_xmit(net, txq, dnode, tsk->portid);\n\t\tif (unlikely(rc == -ELINKCONG)) {\n\t\t\ttsk->cong_link_cnt = 1;\n\t\t\trc = 0;\n\t\t}\n\t\tif (likely(!rc)) {\n\t\t\ttsk->snt_unacked += blocks;\n\t\t\ttsk->snd_backlog = 0;\n\t\t\tsent += send;\n\t\t}\n\t} while (sent < dlen && !rc);\n\n\treturn sent ? sent : rc;\n}\n\n/**\n * tipc_send_packet - send a connection-oriented message\n * @sock: socket structure\n * @m: message to send\n * @dsz: length of data to be transmitted\n *\n * Used for SOCK_SEQPACKET messages.\n *\n * Return: the number of bytes sent on success, or errno otherwise\n */\nstatic int tipc_send_packet(struct socket *sock, struct msghdr *m, size_t dsz)\n{\n\tif (dsz > TIPC_MAX_USER_MSG_SIZE)\n\t\treturn -EMSGSIZE;\n\n\treturn tipc_sendstream(sock, m, dsz);\n}\n\n/* tipc_sk_finish_conn - complete the setup of a connection\n */\nstatic void tipc_sk_finish_conn(struct tipc_sock *tsk, u32 peer_port,\n\t\t\t\tu32 peer_node)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_msg *msg = &tsk->phdr;\n\n\tmsg_set_syn(msg, 0);\n\tmsg_set_destnode(msg, peer_node);\n\tmsg_set_destport(msg, peer_port);\n\tmsg_set_type(msg, TIPC_CONN_MSG);\n\tmsg_set_lookup_scope(msg, 0);\n\tmsg_set_hdr_sz(msg, SHORT_H_SIZE);\n\n\tsk_reset_timer(sk, &sk->sk_timer, jiffies + CONN_PROBING_INTV);\n\ttipc_set_sk_state(sk, TIPC_ESTABLISHED);\n\ttipc_node_add_conn(net, peer_node, tsk->portid, peer_port);\n\ttsk->max_pkt = tipc_node_get_mtu(net, peer_node, tsk->portid, true);\n\ttsk->peer_caps = tipc_node_get_capabilities(net, peer_node);\n\ttsk_set_nagle(tsk);\n\t__skb_queue_purge(&sk->sk_write_queue);\n\tif (tsk->peer_caps & TIPC_BLOCK_FLOWCTL)\n\t\treturn;\n\n\t/* Fall back to message based flow control */\n\ttsk->rcv_win = FLOWCTL_MSG_WIN;\n\ttsk->snd_win = FLOWCTL_MSG_WIN;\n}\n\n/**\n * tipc_sk_set_orig_addr - capture sender's address for received message\n * @m: descriptor for message info\n * @skb: received message\n *\n * Note: Address is not captured if not requested by receiver.\n */\nstatic void tipc_sk_set_orig_addr(struct msghdr *m, struct sk_buff *skb)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_pair *, srcaddr, m->msg_name);\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\n\tif (!srcaddr)\n\t\treturn;\n\n\tsrcaddr->sock.family = AF_TIPC;\n\tsrcaddr->sock.addrtype = TIPC_SOCKET_ADDR;\n\tsrcaddr->sock.scope = 0;\n\tsrcaddr->sock.addr.id.ref = msg_origport(hdr);\n\tsrcaddr->sock.addr.id.node = msg_orignode(hdr);\n\tsrcaddr->sock.addr.name.domain = 0;\n\tm->msg_namelen = sizeof(struct sockaddr_tipc);\n\n\tif (!msg_in_group(hdr))\n\t\treturn;\n\n\t/* Group message users may also want to know sending member's id */\n\tsrcaddr->member.family = AF_TIPC;\n\tsrcaddr->member.addrtype = TIPC_SERVICE_ADDR;\n\tsrcaddr->member.scope = 0;\n\tsrcaddr->member.addr.name.name.type = msg_nametype(hdr);\n\tsrcaddr->member.addr.name.name.instance = TIPC_SKB_CB(skb)->orig_member;\n\tsrcaddr->member.addr.name.domain = 0;\n\tm->msg_namelen = sizeof(*srcaddr);\n}\n\n/**\n * tipc_sk_anc_data_recv - optionally capture ancillary data for received message\n * @m: descriptor for message info\n * @skb: received message buffer\n * @tsk: TIPC port associated with message\n *\n * Note: Ancillary data is not captured if not requested by receiver.\n *\n * Return: 0 if successful, otherwise errno\n */\nstatic int tipc_sk_anc_data_recv(struct msghdr *m, struct sk_buff *skb,\n\t\t\t\t struct tipc_sock *tsk)\n{\n\tstruct tipc_msg *hdr;\n\tu32 data[3] = {0,};\n\tbool has_addr;\n\tint dlen, rc;\n\n\tif (likely(m->msg_controllen == 0))\n\t\treturn 0;\n\n\thdr = buf_msg(skb);\n\tdlen = msg_data_sz(hdr);\n\n\t/* Capture errored message object, if any */\n\tif (msg_errcode(hdr)) {\n\t\tif (skb_linearize(skb))\n\t\t\treturn -ENOMEM;\n\t\thdr = buf_msg(skb);\n\t\tdata[0] = msg_errcode(hdr);\n\t\tdata[1] = dlen;\n\t\trc = put_cmsg(m, SOL_TIPC, TIPC_ERRINFO, 8, data);\n\t\tif (rc || !dlen)\n\t\t\treturn rc;\n\t\trc = put_cmsg(m, SOL_TIPC, TIPC_RETDATA, dlen, msg_data(hdr));\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\t/* Capture TIPC_SERVICE_ADDR/RANGE destination address, if any */\n\tswitch (msg_type(hdr)) {\n\tcase TIPC_NAMED_MSG:\n\t\thas_addr = true;\n\t\tdata[0] = msg_nametype(hdr);\n\t\tdata[1] = msg_namelower(hdr);\n\t\tdata[2] = data[1];\n\t\tbreak;\n\tcase TIPC_MCAST_MSG:\n\t\thas_addr = true;\n\t\tdata[0] = msg_nametype(hdr);\n\t\tdata[1] = msg_namelower(hdr);\n\t\tdata[2] = msg_nameupper(hdr);\n\t\tbreak;\n\tcase TIPC_CONN_MSG:\n\t\thas_addr = !!tsk->conn_addrtype;\n\t\tdata[0] = msg_nametype(&tsk->phdr);\n\t\tdata[1] = msg_nameinst(&tsk->phdr);\n\t\tdata[2] = data[1];\n\t\tbreak;\n\tdefault:\n\t\thas_addr = false;\n\t}\n\tif (!has_addr)\n\t\treturn 0;\n\treturn put_cmsg(m, SOL_TIPC, TIPC_DESTNAME, 12, data);\n}\n\nstatic struct sk_buff *tipc_sk_build_ack(struct tipc_sock *tsk)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct sk_buff *skb = NULL;\n\tstruct tipc_msg *msg;\n\tu32 peer_port = tsk_peer_port(tsk);\n\tu32 dnode = tsk_peer_node(tsk);\n\n\tif (!tipc_sk_connected(sk))\n\t\treturn NULL;\n\tskb = tipc_msg_create(CONN_MANAGER, CONN_ACK, INT_H_SIZE, 0,\n\t\t\t      dnode, tsk_own_node(tsk), peer_port,\n\t\t\t      tsk->portid, TIPC_OK);\n\tif (!skb)\n\t\treturn NULL;\n\tmsg = buf_msg(skb);\n\tmsg_set_conn_ack(msg, tsk->rcv_unacked);\n\ttsk->rcv_unacked = 0;\n\n\t/* Adjust to and advertize the correct window limit */\n\tif (tsk->peer_caps & TIPC_BLOCK_FLOWCTL) {\n\t\ttsk->rcv_win = tsk_adv_blocks(tsk->sk.sk_rcvbuf);\n\t\tmsg_set_adv_win(msg, tsk->rcv_win);\n\t}\n\treturn skb;\n}\n\nstatic void tipc_sk_send_ack(struct tipc_sock *tsk)\n{\n\tstruct sk_buff *skb;\n\n\tskb = tipc_sk_build_ack(tsk);\n\tif (!skb)\n\t\treturn;\n\n\ttipc_node_xmit_skb(sock_net(&tsk->sk), skb, tsk_peer_node(tsk),\n\t\t\t   msg_link_selector(buf_msg(skb)));\n}\n\nstatic int tipc_wait_for_rcvmsg(struct socket *sock, long *timeop)\n{\n\tstruct sock *sk = sock->sk;\n\tDEFINE_WAIT_FUNC(wait, woken_wake_function);\n\tlong timeo = *timeop;\n\tint err = sock_error(sk);\n\n\tif (err)\n\t\treturn err;\n\n\tfor (;;) {\n\t\tif (timeo && skb_queue_empty(&sk->sk_receive_queue)) {\n\t\t\tif (sk->sk_shutdown & RCV_SHUTDOWN) {\n\t\t\t\terr = -ENOTCONN;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tadd_wait_queue(sk_sleep(sk), &wait);\n\t\t\trelease_sock(sk);\n\t\t\ttimeo = wait_woken(&wait, TASK_INTERRUPTIBLE, timeo);\n\t\t\tsched_annotate_sleep();\n\t\t\tlock_sock(sk);\n\t\t\tremove_wait_queue(sk_sleep(sk), &wait);\n\t\t}\n\t\terr = 0;\n\t\tif (!skb_queue_empty(&sk->sk_receive_queue))\n\t\t\tbreak;\n\t\terr = -EAGAIN;\n\t\tif (!timeo)\n\t\t\tbreak;\n\t\terr = sock_intr_errno(timeo);\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\n\t\terr = sock_error(sk);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\t*timeop = timeo;\n\treturn err;\n}\n\n/**\n * tipc_recvmsg - receive packet-oriented message\n * @sock: network socket\n * @m: descriptor for message info\n * @buflen: length of user buffer area\n * @flags: receive flags\n *\n * Used for SOCK_DGRAM, SOCK_RDM, and SOCK_SEQPACKET messages.\n * If the complete message doesn't fit in user area, truncate it.\n *\n * Return: size of returned message data, errno otherwise\n */\nstatic int tipc_recvmsg(struct socket *sock, struct msghdr *m,\n\t\t\tsize_t buflen,\tint flags)\n{\n\tstruct sock *sk = sock->sk;\n\tbool connected = !tipc_sk_type_connectionless(sk);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tint rc, err, hlen, dlen, copy;\n\tstruct tipc_skb_cb *skb_cb;\n\tstruct sk_buff_head xmitq;\n\tstruct tipc_msg *hdr;\n\tstruct sk_buff *skb;\n\tbool grp_evt;\n\tlong timeout;\n\n\t/* Catch invalid receive requests */\n\tif (unlikely(!buflen))\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\tif (unlikely(connected && sk->sk_state == TIPC_OPEN)) {\n\t\trc = -ENOTCONN;\n\t\tgoto exit;\n\t}\n\ttimeout = sock_rcvtimeo(sk, flags & MSG_DONTWAIT);\n\n\t/* Step rcv queue to first msg with data or error; wait if necessary */\n\tdo {\n\t\trc = tipc_wait_for_rcvmsg(sock, &timeout);\n\t\tif (unlikely(rc))\n\t\t\tgoto exit;\n\t\tskb = skb_peek(&sk->sk_receive_queue);\n\t\tskb_cb = TIPC_SKB_CB(skb);\n\t\thdr = buf_msg(skb);\n\t\tdlen = msg_data_sz(hdr);\n\t\thlen = msg_hdr_sz(hdr);\n\t\terr = msg_errcode(hdr);\n\t\tgrp_evt = msg_is_grp_evt(hdr);\n\t\tif (likely(dlen || err))\n\t\t\tbreak;\n\t\ttsk_advance_rx_queue(sk);\n\t} while (1);\n\n\t/* Collect msg meta data, including error code and rejected data */\n\ttipc_sk_set_orig_addr(m, skb);\n\trc = tipc_sk_anc_data_recv(m, skb, tsk);\n\tif (unlikely(rc))\n\t\tgoto exit;\n\thdr = buf_msg(skb);\n\n\t/* Capture data if non-error msg, otherwise just set return value */\n\tif (likely(!err)) {\n\t\tint offset = skb_cb->bytes_read;\n\n\t\tcopy = min_t(int, dlen - offset, buflen);\n\t\trc = skb_copy_datagram_msg(skb, hlen + offset, m, copy);\n\t\tif (unlikely(rc))\n\t\t\tgoto exit;\n\t\tif (unlikely(offset + copy < dlen)) {\n\t\t\tif (flags & MSG_EOR) {\n\t\t\t\tif (!(flags & MSG_PEEK))\n\t\t\t\t\tskb_cb->bytes_read = offset + copy;\n\t\t\t} else {\n\t\t\t\tm->msg_flags |= MSG_TRUNC;\n\t\t\t\tskb_cb->bytes_read = 0;\n\t\t\t}\n\t\t} else {\n\t\t\tif (flags & MSG_EOR)\n\t\t\t\tm->msg_flags |= MSG_EOR;\n\t\t\tskb_cb->bytes_read = 0;\n\t\t}\n\t} else {\n\t\tcopy = 0;\n\t\trc = 0;\n\t\tif (err != TIPC_CONN_SHUTDOWN && connected && !m->msg_control) {\n\t\t\trc = -ECONNRESET;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\n\t/* Mark message as group event if applicable */\n\tif (unlikely(grp_evt)) {\n\t\tif (msg_grp_evt(hdr) == TIPC_WITHDRAWN)\n\t\t\tm->msg_flags |= MSG_EOR;\n\t\tm->msg_flags |= MSG_OOB;\n\t\tcopy = 0;\n\t}\n\n\t/* Caption of data or error code/rejected data was successful */\n\tif (unlikely(flags & MSG_PEEK))\n\t\tgoto exit;\n\n\t/* Send group flow control advertisement when applicable */\n\tif (tsk->group && msg_in_group(hdr) && !grp_evt) {\n\t\t__skb_queue_head_init(&xmitq);\n\t\ttipc_group_update_rcv_win(tsk->group, tsk_blocks(hlen + dlen),\n\t\t\t\t\t  msg_orignode(hdr), msg_origport(hdr),\n\t\t\t\t\t  &xmitq);\n\t\ttipc_node_distr_xmit(sock_net(sk), &xmitq);\n\t}\n\n\tif (skb_cb->bytes_read)\n\t\tgoto exit;\n\n\ttsk_advance_rx_queue(sk);\n\n\tif (likely(!connected))\n\t\tgoto exit;\n\n\t/* Send connection flow control advertisement when applicable */\n\ttsk->rcv_unacked += tsk_inc(tsk, hlen + dlen);\n\tif (tsk->rcv_unacked >= tsk->rcv_win / TIPC_ACK_RATE)\n\t\ttipc_sk_send_ack(tsk);\nexit:\n\trelease_sock(sk);\n\treturn rc ? rc : copy;\n}\n\n/**\n * tipc_recvstream - receive stream-oriented data\n * @sock: network socket\n * @m: descriptor for message info\n * @buflen: total size of user buffer area\n * @flags: receive flags\n *\n * Used for SOCK_STREAM messages only.  If not enough data is available\n * will optionally wait for more; never truncates data.\n *\n * Return: size of returned message data, errno otherwise\n */\nstatic int tipc_recvstream(struct socket *sock, struct msghdr *m,\n\t\t\t   size_t buflen, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct sk_buff *skb;\n\tstruct tipc_msg *hdr;\n\tstruct tipc_skb_cb *skb_cb;\n\tbool peek = flags & MSG_PEEK;\n\tint offset, required, copy, copied = 0;\n\tint hlen, dlen, err, rc;\n\tlong timeout;\n\n\t/* Catch invalid receive attempts */\n\tif (unlikely(!buflen))\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\n\tif (unlikely(sk->sk_state == TIPC_OPEN)) {\n\t\trc = -ENOTCONN;\n\t\tgoto exit;\n\t}\n\trequired = sock_rcvlowat(sk, flags & MSG_WAITALL, buflen);\n\ttimeout = sock_rcvtimeo(sk, flags & MSG_DONTWAIT);\n\n\tdo {\n\t\t/* Look at first msg in receive queue; wait if necessary */\n\t\trc = tipc_wait_for_rcvmsg(sock, &timeout);\n\t\tif (unlikely(rc))\n\t\t\tbreak;\n\t\tskb = skb_peek(&sk->sk_receive_queue);\n\t\tskb_cb = TIPC_SKB_CB(skb);\n\t\thdr = buf_msg(skb);\n\t\tdlen = msg_data_sz(hdr);\n\t\thlen = msg_hdr_sz(hdr);\n\t\terr = msg_errcode(hdr);\n\n\t\t/* Discard any empty non-errored (SYN-) message */\n\t\tif (unlikely(!dlen && !err)) {\n\t\t\ttsk_advance_rx_queue(sk);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Collect msg meta data, incl. error code and rejected data */\n\t\tif (!copied) {\n\t\t\ttipc_sk_set_orig_addr(m, skb);\n\t\t\trc = tipc_sk_anc_data_recv(m, skb, tsk);\n\t\t\tif (rc)\n\t\t\t\tbreak;\n\t\t\thdr = buf_msg(skb);\n\t\t}\n\n\t\t/* Copy data if msg ok, otherwise return error/partial data */\n\t\tif (likely(!err)) {\n\t\t\toffset = skb_cb->bytes_read;\n\t\t\tcopy = min_t(int, dlen - offset, buflen - copied);\n\t\t\trc = skb_copy_datagram_msg(skb, hlen + offset, m, copy);\n\t\t\tif (unlikely(rc))\n\t\t\t\tbreak;\n\t\t\tcopied += copy;\n\t\t\toffset += copy;\n\t\t\tif (unlikely(offset < dlen)) {\n\t\t\t\tif (!peek)\n\t\t\t\t\tskb_cb->bytes_read = offset;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\trc = 0;\n\t\t\tif ((err != TIPC_CONN_SHUTDOWN) && !m->msg_control)\n\t\t\t\trc = -ECONNRESET;\n\t\t\tif (copied || rc)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (unlikely(peek))\n\t\t\tbreak;\n\n\t\ttsk_advance_rx_queue(sk);\n\n\t\t/* Send connection flow control advertisement when applicable */\n\t\ttsk->rcv_unacked += tsk_inc(tsk, hlen + dlen);\n\t\tif (tsk->rcv_unacked >= tsk->rcv_win / TIPC_ACK_RATE)\n\t\t\ttipc_sk_send_ack(tsk);\n\n\t\t/* Exit if all requested data or FIN/error received */\n\t\tif (copied == buflen || err)\n\t\t\tbreak;\n\n\t} while (!skb_queue_empty(&sk->sk_receive_queue) || copied < required);\nexit:\n\trelease_sock(sk);\n\treturn copied ? copied : rc;\n}\n\n/**\n * tipc_write_space - wake up thread if port congestion is released\n * @sk: socket\n */\nstatic void tipc_write_space(struct sock *sk)\n{\n\tstruct socket_wq *wq;\n\n\trcu_read_lock();\n\twq = rcu_dereference(sk->sk_wq);\n\tif (skwq_has_sleeper(wq))\n\t\twake_up_interruptible_sync_poll(&wq->wait, EPOLLOUT |\n\t\t\t\t\t\tEPOLLWRNORM | EPOLLWRBAND);\n\trcu_read_unlock();\n}\n\n/**\n * tipc_data_ready - wake up threads to indicate messages have been received\n * @sk: socket\n */\nstatic void tipc_data_ready(struct sock *sk)\n{\n\tstruct socket_wq *wq;\n\n\trcu_read_lock();\n\twq = rcu_dereference(sk->sk_wq);\n\tif (skwq_has_sleeper(wq))\n\t\twake_up_interruptible_sync_poll(&wq->wait, EPOLLIN |\n\t\t\t\t\t\tEPOLLRDNORM | EPOLLRDBAND);\n\trcu_read_unlock();\n}\n\nstatic void tipc_sock_destruct(struct sock *sk)\n{\n\t__skb_queue_purge(&sk->sk_receive_queue);\n}\n\nstatic void tipc_sk_proto_rcv(struct sock *sk,\n\t\t\t      struct sk_buff_head *inputq,\n\t\t\t      struct sk_buff_head *xmitq)\n{\n\tstruct sk_buff *skb = __skb_dequeue(inputq);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tstruct tipc_group *grp = tsk->group;\n\tbool wakeup = false;\n\n\tswitch (msg_user(hdr)) {\n\tcase CONN_MANAGER:\n\t\ttipc_sk_conn_proto_rcv(tsk, skb, inputq, xmitq);\n\t\treturn;\n\tcase SOCK_WAKEUP:\n\t\ttipc_dest_del(&tsk->cong_links, msg_orignode(hdr), 0);\n\t\t/* coupled with smp_rmb() in tipc_wait_for_cond() */\n\t\tsmp_wmb();\n\t\ttsk->cong_link_cnt--;\n\t\twakeup = true;\n\t\ttipc_sk_push_backlog(tsk, false);\n\t\tbreak;\n\tcase GROUP_PROTOCOL:\n\t\ttipc_group_proto_rcv(grp, &wakeup, hdr, inputq, xmitq);\n\t\tbreak;\n\tcase TOP_SRV:\n\t\ttipc_group_member_evt(tsk->group, &wakeup, &sk->sk_rcvbuf,\n\t\t\t\t      hdr, inputq, xmitq);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (wakeup)\n\t\tsk->sk_write_space(sk);\n\n\tkfree_skb(skb);\n}\n\n/**\n * tipc_sk_filter_connect - check incoming message for a connection-based socket\n * @tsk: TIPC socket\n * @skb: pointer to message buffer.\n * @xmitq: for Nagle ACK if any\n * Return: true if message should be added to receive queue, false otherwise\n */\nstatic bool tipc_sk_filter_connect(struct tipc_sock *tsk, struct sk_buff *skb,\n\t\t\t\t   struct sk_buff_head *xmitq)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tbool con_msg = msg_connected(hdr);\n\tu32 pport = tsk_peer_port(tsk);\n\tu32 pnode = tsk_peer_node(tsk);\n\tu32 oport = msg_origport(hdr);\n\tu32 onode = msg_orignode(hdr);\n\tint err = msg_errcode(hdr);\n\tunsigned long delay;\n\n\tif (unlikely(msg_mcast(hdr)))\n\t\treturn false;\n\ttsk->oneway = 0;\n\n\tswitch (sk->sk_state) {\n\tcase TIPC_CONNECTING:\n\t\t/* Setup ACK */\n\t\tif (likely(con_msg)) {\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t\ttipc_sk_finish_conn(tsk, oport, onode);\n\t\t\tmsg_set_importance(&tsk->phdr, msg_importance(hdr));\n\t\t\t/* ACK+ message with data is added to receive queue */\n\t\t\tif (msg_data_sz(hdr))\n\t\t\t\treturn true;\n\t\t\t/* Empty ACK-, - wake up sleeping connect() and drop */\n\t\t\tsk->sk_state_change(sk);\n\t\t\tmsg_set_dest_droppable(hdr, 1);\n\t\t\treturn false;\n\t\t}\n\t\t/* Ignore connectionless message if not from listening socket */\n\t\tif (oport != pport || onode != pnode)\n\t\t\treturn false;\n\n\t\t/* Rejected SYN */\n\t\tif (err != TIPC_ERR_OVERLOAD)\n\t\t\tbreak;\n\n\t\t/* Prepare for new setup attempt if we have a SYN clone */\n\t\tif (skb_queue_empty(&sk->sk_write_queue))\n\t\t\tbreak;\n\t\tget_random_bytes(&delay, 2);\n\t\tdelay %= (tsk->conn_timeout / 4);\n\t\tdelay = msecs_to_jiffies(delay + 100);\n\t\tsk_reset_timer(sk, &sk->sk_timer, jiffies + delay);\n\t\treturn false;\n\tcase TIPC_OPEN:\n\tcase TIPC_DISCONNECTING:\n\t\treturn false;\n\tcase TIPC_LISTEN:\n\t\t/* Accept only SYN message */\n\t\tif (!msg_is_syn(hdr) &&\n\t\t    tipc_node_get_capabilities(net, onode) & TIPC_SYN_BIT)\n\t\t\treturn false;\n\t\tif (!con_msg && !err)\n\t\t\treturn true;\n\t\treturn false;\n\tcase TIPC_ESTABLISHED:\n\t\tif (!skb_queue_empty(&sk->sk_write_queue))\n\t\t\ttipc_sk_push_backlog(tsk, false);\n\t\t/* Accept only connection-based messages sent by peer */\n\t\tif (likely(con_msg && !err && pport == oport &&\n\t\t\t   pnode == onode)) {\n\t\t\tif (msg_ack_required(hdr)) {\n\t\t\t\tstruct sk_buff *skb;\n\n\t\t\t\tskb = tipc_sk_build_ack(tsk);\n\t\t\t\tif (skb) {\n\t\t\t\t\tmsg_set_nagle_ack(buf_msg(skb));\n\t\t\t\t\t__skb_queue_tail(xmitq, skb);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t\tif (!tsk_peer_msg(tsk, hdr))\n\t\t\treturn false;\n\t\tif (!err)\n\t\t\treturn true;\n\t\ttipc_set_sk_state(sk, TIPC_DISCONNECTING);\n\t\ttipc_node_remove_conn(net, pnode, tsk->portid);\n\t\tsk->sk_state_change(sk);\n\t\treturn true;\n\tdefault:\n\t\tpr_err(\"Unknown sk_state %u\\n\", sk->sk_state);\n\t}\n\t/* Abort connection setup attempt */\n\ttipc_set_sk_state(sk, TIPC_DISCONNECTING);\n\tsk->sk_err = ECONNREFUSED;\n\tsk->sk_state_change(sk);\n\treturn true;\n}\n\n/**\n * rcvbuf_limit - get proper overload limit of socket receive queue\n * @sk: socket\n * @skb: message\n *\n * For connection oriented messages, irrespective of importance,\n * default queue limit is 2 MB.\n *\n * For connectionless messages, queue limits are based on message\n * importance as follows:\n *\n * TIPC_LOW_IMPORTANCE       (2 MB)\n * TIPC_MEDIUM_IMPORTANCE    (4 MB)\n * TIPC_HIGH_IMPORTANCE      (8 MB)\n * TIPC_CRITICAL_IMPORTANCE  (16 MB)\n *\n * Return: overload limit according to corresponding message importance\n */\nstatic unsigned int rcvbuf_limit(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\n\tif (unlikely(msg_in_group(hdr)))\n\t\treturn READ_ONCE(sk->sk_rcvbuf);\n\n\tif (unlikely(!msg_connected(hdr)))\n\t\treturn READ_ONCE(sk->sk_rcvbuf) << msg_importance(hdr);\n\n\tif (likely(tsk->peer_caps & TIPC_BLOCK_FLOWCTL))\n\t\treturn READ_ONCE(sk->sk_rcvbuf);\n\n\treturn FLOWCTL_MSG_LIM;\n}\n\n/**\n * tipc_sk_filter_rcv - validate incoming message\n * @sk: socket\n * @skb: pointer to message.\n * @xmitq: output message area (FIXME)\n *\n * Enqueues message on receive queue if acceptable; optionally handles\n * disconnect indication for a connected socket.\n *\n * Called with socket lock already taken\n */\nstatic void tipc_sk_filter_rcv(struct sock *sk, struct sk_buff *skb,\n\t\t\t       struct sk_buff_head *xmitq)\n{\n\tbool sk_conn = !tipc_sk_type_connectionless(sk);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tstruct net *net = sock_net(sk);\n\tstruct sk_buff_head inputq;\n\tint mtyp = msg_type(hdr);\n\tint limit, err = TIPC_OK;\n\n\ttrace_tipc_sk_filter_rcv(sk, skb, TIPC_DUMP_ALL, \" \");\n\tTIPC_SKB_CB(skb)->bytes_read = 0;\n\t__skb_queue_head_init(&inputq);\n\t__skb_queue_tail(&inputq, skb);\n\n\tif (unlikely(!msg_isdata(hdr)))\n\t\ttipc_sk_proto_rcv(sk, &inputq, xmitq);\n\n\tif (unlikely(grp))\n\t\ttipc_group_filter_msg(grp, &inputq, xmitq);\n\n\tif (unlikely(!grp) && mtyp == TIPC_MCAST_MSG)\n\t\ttipc_mcast_filter_msg(net, &tsk->mc_method.deferredq, &inputq);\n\n\t/* Validate and add to receive buffer if there is space */\n\twhile ((skb = __skb_dequeue(&inputq))) {\n\t\thdr = buf_msg(skb);\n\t\tlimit = rcvbuf_limit(sk, skb);\n\t\tif ((sk_conn && !tipc_sk_filter_connect(tsk, skb, xmitq)) ||\n\t\t    (!sk_conn && msg_connected(hdr)) ||\n\t\t    (!grp && msg_in_group(hdr)))\n\t\t\terr = TIPC_ERR_NO_PORT;\n\t\telse if (sk_rmem_alloc_get(sk) + skb->truesize >= limit) {\n\t\t\ttrace_tipc_sk_dump(sk, skb, TIPC_DUMP_ALL,\n\t\t\t\t\t   \"err_overload2!\");\n\t\t\tatomic_inc(&sk->sk_drops);\n\t\t\terr = TIPC_ERR_OVERLOAD;\n\t\t}\n\n\t\tif (unlikely(err)) {\n\t\t\tif (tipc_msg_reverse(tipc_own_addr(net), &skb, err)) {\n\t\t\t\ttrace_tipc_sk_rej_msg(sk, skb, TIPC_DUMP_NONE,\n\t\t\t\t\t\t      \"@filter_rcv!\");\n\t\t\t\t__skb_queue_tail(xmitq, skb);\n\t\t\t}\n\t\t\terr = TIPC_OK;\n\t\t\tcontinue;\n\t\t}\n\t\t__skb_queue_tail(&sk->sk_receive_queue, skb);\n\t\tskb_set_owner_r(skb, sk);\n\t\ttrace_tipc_sk_overlimit2(sk, skb, TIPC_DUMP_ALL,\n\t\t\t\t\t \"rcvq >90% allocated!\");\n\t\tsk->sk_data_ready(sk);\n\t}\n}\n\n/**\n * tipc_sk_backlog_rcv - handle incoming message from backlog queue\n * @sk: socket\n * @skb: message\n *\n * Caller must hold socket lock\n */\nstatic int tipc_sk_backlog_rcv(struct sock *sk, struct sk_buff *skb)\n{\n\tunsigned int before = sk_rmem_alloc_get(sk);\n\tstruct sk_buff_head xmitq;\n\tunsigned int added;\n\n\t__skb_queue_head_init(&xmitq);\n\n\ttipc_sk_filter_rcv(sk, skb, &xmitq);\n\tadded = sk_rmem_alloc_get(sk) - before;\n\tatomic_add(added, &tipc_sk(sk)->dupl_rcvcnt);\n\n\t/* Send pending response/rejected messages, if any */\n\ttipc_node_distr_xmit(sock_net(sk), &xmitq);\n\treturn 0;\n}\n\n/**\n * tipc_sk_enqueue - extract all buffers with destination 'dport' from\n *                   inputq and try adding them to socket or backlog queue\n * @inputq: list of incoming buffers with potentially different destinations\n * @sk: socket where the buffers should be enqueued\n * @dport: port number for the socket\n * @xmitq: output queue\n *\n * Caller must hold socket lock\n */\nstatic void tipc_sk_enqueue(struct sk_buff_head *inputq, struct sock *sk,\n\t\t\t    u32 dport, struct sk_buff_head *xmitq)\n{\n\tunsigned long time_limit = jiffies + usecs_to_jiffies(20000);\n\tstruct sk_buff *skb;\n\tunsigned int lim;\n\tatomic_t *dcnt;\n\tu32 onode;\n\n\twhile (skb_queue_len(inputq)) {\n\t\tif (unlikely(time_after_eq(jiffies, time_limit)))\n\t\t\treturn;\n\n\t\tskb = tipc_skb_dequeue(inputq, dport);\n\t\tif (unlikely(!skb))\n\t\t\treturn;\n\n\t\t/* Add message directly to receive queue if possible */\n\t\tif (!sock_owned_by_user(sk)) {\n\t\t\ttipc_sk_filter_rcv(sk, skb, xmitq);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Try backlog, compensating for double-counted bytes */\n\t\tdcnt = &tipc_sk(sk)->dupl_rcvcnt;\n\t\tif (!sk->sk_backlog.len)\n\t\t\tatomic_set(dcnt, 0);\n\t\tlim = rcvbuf_limit(sk, skb) + atomic_read(dcnt);\n\t\tif (likely(!sk_add_backlog(sk, skb, lim))) {\n\t\t\ttrace_tipc_sk_overlimit1(sk, skb, TIPC_DUMP_ALL,\n\t\t\t\t\t\t \"bklg & rcvq >90% allocated!\");\n\t\t\tcontinue;\n\t\t}\n\n\t\ttrace_tipc_sk_dump(sk, skb, TIPC_DUMP_ALL, \"err_overload!\");\n\t\t/* Overload => reject message back to sender */\n\t\tonode = tipc_own_addr(sock_net(sk));\n\t\tatomic_inc(&sk->sk_drops);\n\t\tif (tipc_msg_reverse(onode, &skb, TIPC_ERR_OVERLOAD)) {\n\t\t\ttrace_tipc_sk_rej_msg(sk, skb, TIPC_DUMP_ALL,\n\t\t\t\t\t      \"@sk_enqueue!\");\n\t\t\t__skb_queue_tail(xmitq, skb);\n\t\t}\n\t\tbreak;\n\t}\n}\n\n/**\n * tipc_sk_rcv - handle a chain of incoming buffers\n * @net: the associated network namespace\n * @inputq: buffer list containing the buffers\n * Consumes all buffers in list until inputq is empty\n * Note: may be called in multiple threads referring to the same queue\n */\nvoid tipc_sk_rcv(struct net *net, struct sk_buff_head *inputq)\n{\n\tstruct sk_buff_head xmitq;\n\tu32 dnode, dport = 0;\n\tint err;\n\tstruct tipc_sock *tsk;\n\tstruct sock *sk;\n\tstruct sk_buff *skb;\n\n\t__skb_queue_head_init(&xmitq);\n\twhile (skb_queue_len(inputq)) {\n\t\tdport = tipc_skb_peek_port(inputq, dport);\n\t\ttsk = tipc_sk_lookup(net, dport);\n\n\t\tif (likely(tsk)) {\n\t\t\tsk = &tsk->sk;\n\t\t\tif (likely(spin_trylock_bh(&sk->sk_lock.slock))) {\n\t\t\t\ttipc_sk_enqueue(inputq, sk, dport, &xmitq);\n\t\t\t\tspin_unlock_bh(&sk->sk_lock.slock);\n\t\t\t}\n\t\t\t/* Send pending response/rejected messages, if any */\n\t\t\ttipc_node_distr_xmit(sock_net(sk), &xmitq);\n\t\t\tsock_put(sk);\n\t\t\tcontinue;\n\t\t}\n\t\t/* No destination socket => dequeue skb if still there */\n\t\tskb = tipc_skb_dequeue(inputq, dport);\n\t\tif (!skb)\n\t\t\treturn;\n\n\t\t/* Try secondary lookup if unresolved named message */\n\t\terr = TIPC_ERR_NO_PORT;\n\t\tif (tipc_msg_lookup_dest(net, skb, &err))\n\t\t\tgoto xmit;\n\n\t\t/* Prepare for message rejection */\n\t\tif (!tipc_msg_reverse(tipc_own_addr(net), &skb, err))\n\t\t\tcontinue;\n\n\t\ttrace_tipc_sk_rej_msg(NULL, skb, TIPC_DUMP_NONE, \"@sk_rcv!\");\nxmit:\n\t\tdnode = msg_destnode(buf_msg(skb));\n\t\ttipc_node_xmit_skb(net, skb, dnode, dport);\n\t}\n}\n\nstatic int tipc_wait_for_connect(struct socket *sock, long *timeo_p)\n{\n\tDEFINE_WAIT_FUNC(wait, woken_wake_function);\n\tstruct sock *sk = sock->sk;\n\tint done;\n\n\tdo {\n\t\tint err = sock_error(sk);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (!*timeo_p)\n\t\t\treturn -ETIMEDOUT;\n\t\tif (signal_pending(current))\n\t\t\treturn sock_intr_errno(*timeo_p);\n\t\tif (sk->sk_state == TIPC_DISCONNECTING)\n\t\t\tbreak;\n\n\t\tadd_wait_queue(sk_sleep(sk), &wait);\n\t\tdone = sk_wait_event(sk, timeo_p, tipc_sk_connected(sk),\n\t\t\t\t     &wait);\n\t\tremove_wait_queue(sk_sleep(sk), &wait);\n\t} while (!done);\n\treturn 0;\n}\n\nstatic bool tipc_sockaddr_is_sane(struct sockaddr_tipc *addr)\n{\n\tif (addr->family != AF_TIPC)\n\t\treturn false;\n\tif (addr->addrtype == TIPC_SERVICE_RANGE)\n\t\treturn (addr->addr.nameseq.lower <= addr->addr.nameseq.upper);\n\treturn (addr->addrtype == TIPC_SERVICE_ADDR ||\n\t\taddr->addrtype == TIPC_SOCKET_ADDR);\n}\n\n/**\n * tipc_connect - establish a connection to another TIPC port\n * @sock: socket structure\n * @dest: socket address for destination port\n * @destlen: size of socket address data structure\n * @flags: file-related flags associated with socket\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_connect(struct socket *sock, struct sockaddr *dest,\n\t\t\tint destlen, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct sockaddr_tipc *dst = (struct sockaddr_tipc *)dest;\n\tstruct msghdr m = {NULL,};\n\tlong timeout = (flags & O_NONBLOCK) ? 0 : tsk->conn_timeout;\n\tint previous;\n\tint res = 0;\n\n\tif (destlen != sizeof(struct sockaddr_tipc))\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\n\tif (tsk->group) {\n\t\tres = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\tif (dst->family == AF_UNSPEC) {\n\t\tmemset(&tsk->peer, 0, sizeof(struct sockaddr_tipc));\n\t\tif (!tipc_sk_type_connectionless(sk))\n\t\t\tres = -EINVAL;\n\t\tgoto exit;\n\t}\n\tif (!tipc_sockaddr_is_sane(dst)) {\n\t\tres = -EINVAL;\n\t\tgoto exit;\n\t}\n\t/* DGRAM/RDM connect(), just save the destaddr */\n\tif (tipc_sk_type_connectionless(sk)) {\n\t\tmemcpy(&tsk->peer, dest, destlen);\n\t\tgoto exit;\n\t} else if (dst->addrtype == TIPC_SERVICE_RANGE) {\n\t\tres = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\tprevious = sk->sk_state;\n\n\tswitch (sk->sk_state) {\n\tcase TIPC_OPEN:\n\t\t/* Send a 'SYN-' to destination */\n\t\tm.msg_name = dest;\n\t\tm.msg_namelen = destlen;\n\n\t\t/* If connect is in non-blocking case, set MSG_DONTWAIT to\n\t\t * indicate send_msg() is never blocked.\n\t\t */\n\t\tif (!timeout)\n\t\t\tm.msg_flags = MSG_DONTWAIT;\n\n\t\tres = __tipc_sendmsg(sock, &m, 0);\n\t\tif ((res < 0) && (res != -EWOULDBLOCK))\n\t\t\tgoto exit;\n\n\t\t/* Just entered TIPC_CONNECTING state; the only\n\t\t * difference is that return value in non-blocking\n\t\t * case is EINPROGRESS, rather than EALREADY.\n\t\t */\n\t\tres = -EINPROGRESS;\n\t\tfallthrough;\n\tcase TIPC_CONNECTING:\n\t\tif (!timeout) {\n\t\t\tif (previous == TIPC_CONNECTING)\n\t\t\t\tres = -EALREADY;\n\t\t\tgoto exit;\n\t\t}\n\t\ttimeout = msecs_to_jiffies(timeout);\n\t\t/* Wait until an 'ACK' or 'RST' arrives, or a timeout occurs */\n\t\tres = tipc_wait_for_connect(sock, &timeout);\n\t\tbreak;\n\tcase TIPC_ESTABLISHED:\n\t\tres = -EISCONN;\n\t\tbreak;\n\tdefault:\n\t\tres = -EINVAL;\n\t}\n\nexit:\n\trelease_sock(sk);\n\treturn res;\n}\n\n/**\n * tipc_listen - allow socket to listen for incoming connections\n * @sock: socket structure\n * @len: (unused)\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_listen(struct socket *sock, int len)\n{\n\tstruct sock *sk = sock->sk;\n\tint res;\n\n\tlock_sock(sk);\n\tres = tipc_set_sk_state(sk, TIPC_LISTEN);\n\trelease_sock(sk);\n\n\treturn res;\n}\n\nstatic int tipc_wait_for_accept(struct socket *sock, long timeo)\n{\n\tstruct sock *sk = sock->sk;\n\tDEFINE_WAIT_FUNC(wait, woken_wake_function);\n\tint err;\n\n\t/* True wake-one mechanism for incoming connections: only\n\t * one process gets woken up, not the 'whole herd'.\n\t * Since we do not 'race & poll' for established sockets\n\t * anymore, the common case will execute the loop only once.\n\t*/\n\tfor (;;) {\n\t\tif (timeo && skb_queue_empty(&sk->sk_receive_queue)) {\n\t\t\tadd_wait_queue(sk_sleep(sk), &wait);\n\t\t\trelease_sock(sk);\n\t\t\ttimeo = wait_woken(&wait, TASK_INTERRUPTIBLE, timeo);\n\t\t\tlock_sock(sk);\n\t\t\tremove_wait_queue(sk_sleep(sk), &wait);\n\t\t}\n\t\terr = 0;\n\t\tif (!skb_queue_empty(&sk->sk_receive_queue))\n\t\t\tbreak;\n\t\terr = -EAGAIN;\n\t\tif (!timeo)\n\t\t\tbreak;\n\t\terr = sock_intr_errno(timeo);\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\t}\n\treturn err;\n}\n\n/**\n * tipc_accept - wait for connection request\n * @sock: listening socket\n * @new_sock: new socket that is to be connected\n * @flags: file-related flags associated with socket\n * @kern: caused by kernel or by userspace?\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_accept(struct socket *sock, struct socket *new_sock, int flags,\n\t\t       bool kern)\n{\n\tstruct sock *new_sk, *sk = sock->sk;\n\tstruct tipc_sock *new_tsock;\n\tstruct msghdr m = {NULL,};\n\tstruct tipc_msg *msg;\n\tstruct sk_buff *buf;\n\tlong timeo;\n\tint res;\n\n\tlock_sock(sk);\n\n\tif (sk->sk_state != TIPC_LISTEN) {\n\t\tres = -EINVAL;\n\t\tgoto exit;\n\t}\n\ttimeo = sock_rcvtimeo(sk, flags & O_NONBLOCK);\n\tres = tipc_wait_for_accept(sock, timeo);\n\tif (res)\n\t\tgoto exit;\n\n\tbuf = skb_peek(&sk->sk_receive_queue);\n\n\tres = tipc_sk_create(sock_net(sock->sk), new_sock, 0, kern);\n\tif (res)\n\t\tgoto exit;\n\tsecurity_sk_clone(sock->sk, new_sock->sk);\n\n\tnew_sk = new_sock->sk;\n\tnew_tsock = tipc_sk(new_sk);\n\tmsg = buf_msg(buf);\n\n\t/* we lock on new_sk; but lockdep sees the lock on sk */\n\tlock_sock_nested(new_sk, SINGLE_DEPTH_NESTING);\n\n\t/*\n\t * Reject any stray messages received by new socket\n\t * before the socket lock was taken (very, very unlikely)\n\t */\n\ttsk_rej_rx_queue(new_sk, TIPC_ERR_NO_PORT);\n\n\t/* Connect new socket to it's peer */\n\ttipc_sk_finish_conn(new_tsock, msg_origport(msg), msg_orignode(msg));\n\n\ttsk_set_importance(new_sk, msg_importance(msg));\n\tif (msg_named(msg)) {\n\t\tnew_tsock->conn_addrtype = TIPC_SERVICE_ADDR;\n\t\tmsg_set_nametype(&new_tsock->phdr, msg_nametype(msg));\n\t\tmsg_set_nameinst(&new_tsock->phdr, msg_nameinst(msg));\n\t}\n\n\t/*\n\t * Respond to 'SYN-' by discarding it & returning 'ACK'.\n\t * Respond to 'SYN+' by queuing it on new socket & returning 'ACK'.\n\t */\n\tif (!msg_data_sz(msg)) {\n\t\ttsk_advance_rx_queue(sk);\n\t} else {\n\t\t__skb_dequeue(&sk->sk_receive_queue);\n\t\t__skb_queue_head(&new_sk->sk_receive_queue, buf);\n\t\tskb_set_owner_r(buf, new_sk);\n\t}\n\t__tipc_sendstream(new_sock, &m, 0);\n\trelease_sock(new_sk);\nexit:\n\trelease_sock(sk);\n\treturn res;\n}\n\n/**\n * tipc_shutdown - shutdown socket connection\n * @sock: socket structure\n * @how: direction to close (must be SHUT_RDWR)\n *\n * Terminates connection (if necessary), then purges socket's receive queue.\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_shutdown(struct socket *sock, int how)\n{\n\tstruct sock *sk = sock->sk;\n\tint res;\n\n\tif (how != SHUT_RDWR)\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\n\ttrace_tipc_sk_shutdown(sk, NULL, TIPC_DUMP_ALL, \" \");\n\t__tipc_shutdown(sock, TIPC_CONN_SHUTDOWN);\n\tsk->sk_shutdown = SHUTDOWN_MASK;\n\n\tif (sk->sk_state == TIPC_DISCONNECTING) {\n\t\t/* Discard any unreceived messages */\n\t\t__skb_queue_purge(&sk->sk_receive_queue);\n\n\t\tres = 0;\n\t} else {\n\t\tres = -ENOTCONN;\n\t}\n\t/* Wake up anyone sleeping in poll. */\n\tsk->sk_state_change(sk);\n\n\trelease_sock(sk);\n\treturn res;\n}\n\nstatic void tipc_sk_check_probing_state(struct sock *sk,\n\t\t\t\t\tstruct sk_buff_head *list)\n{\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tu32 pnode = tsk_peer_node(tsk);\n\tu32 pport = tsk_peer_port(tsk);\n\tu32 self = tsk_own_node(tsk);\n\tu32 oport = tsk->portid;\n\tstruct sk_buff *skb;\n\n\tif (tsk->probe_unacked) {\n\t\ttipc_set_sk_state(sk, TIPC_DISCONNECTING);\n\t\tsk->sk_err = ECONNABORTED;\n\t\ttipc_node_remove_conn(sock_net(sk), pnode, pport);\n\t\tsk->sk_state_change(sk);\n\t\treturn;\n\t}\n\t/* Prepare new probe */\n\tskb = tipc_msg_create(CONN_MANAGER, CONN_PROBE, INT_H_SIZE, 0,\n\t\t\t      pnode, self, pport, oport, TIPC_OK);\n\tif (skb)\n\t\t__skb_queue_tail(list, skb);\n\ttsk->probe_unacked = true;\n\tsk_reset_timer(sk, &sk->sk_timer, jiffies + CONN_PROBING_INTV);\n}\n\nstatic void tipc_sk_retry_connect(struct sock *sk, struct sk_buff_head *list)\n{\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\n\t/* Try again later if dest link is congested */\n\tif (tsk->cong_link_cnt) {\n\t\tsk_reset_timer(sk, &sk->sk_timer, msecs_to_jiffies(100));\n\t\treturn;\n\t}\n\t/* Prepare SYN for retransmit */\n\ttipc_msg_skb_clone(&sk->sk_write_queue, list);\n}\n\nstatic void tipc_sk_timeout(struct timer_list *t)\n{\n\tstruct sock *sk = from_timer(sk, t, sk_timer);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tu32 pnode = tsk_peer_node(tsk);\n\tstruct sk_buff_head list;\n\tint rc = 0;\n\n\t__skb_queue_head_init(&list);\n\tbh_lock_sock(sk);\n\n\t/* Try again later if socket is busy */\n\tif (sock_owned_by_user(sk)) {\n\t\tsk_reset_timer(sk, &sk->sk_timer, jiffies + HZ / 20);\n\t\tbh_unlock_sock(sk);\n\t\tsock_put(sk);\n\t\treturn;\n\t}\n\n\tif (sk->sk_state == TIPC_ESTABLISHED)\n\t\ttipc_sk_check_probing_state(sk, &list);\n\telse if (sk->sk_state == TIPC_CONNECTING)\n\t\ttipc_sk_retry_connect(sk, &list);\n\n\tbh_unlock_sock(sk);\n\n\tif (!skb_queue_empty(&list))\n\t\trc = tipc_node_xmit(sock_net(sk), &list, pnode, tsk->portid);\n\n\t/* SYN messages may cause link congestion */\n\tif (rc == -ELINKCONG) {\n\t\ttipc_dest_push(&tsk->cong_links, pnode, 0);\n\t\ttsk->cong_link_cnt = 1;\n\t}\n\tsock_put(sk);\n}\n\nstatic int tipc_sk_publish(struct tipc_sock *tsk, struct tipc_uaddr *ua)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_socket_addr skaddr;\n\tstruct publication *p;\n\tu32 key;\n\n\tif (tipc_sk_connected(sk))\n\t\treturn -EINVAL;\n\tkey = tsk->portid + tsk->pub_count + 1;\n\tif (key == tsk->portid)\n\t\treturn -EADDRINUSE;\n\tskaddr.ref = tsk->portid;\n\tskaddr.node = tipc_own_addr(net);\n\tp = tipc_nametbl_publish(net, ua, &skaddr, key);\n\tif (unlikely(!p))\n\t\treturn -EINVAL;\n\n\tlist_add(&p->binding_sock, &tsk->publications);\n\ttsk->pub_count++;\n\ttsk->published = true;\n\treturn 0;\n}\n\nstatic int tipc_sk_withdraw(struct tipc_sock *tsk, struct tipc_uaddr *ua)\n{\n\tstruct net *net = sock_net(&tsk->sk);\n\tstruct publication *safe, *p;\n\tstruct tipc_uaddr _ua;\n\tint rc = -EINVAL;\n\n\tlist_for_each_entry_safe(p, safe, &tsk->publications, binding_sock) {\n\t\tif (!ua) {\n\t\t\ttipc_uaddr(&_ua, TIPC_SERVICE_RANGE, p->scope,\n\t\t\t\t   p->sr.type, p->sr.lower, p->sr.upper);\n\t\t\ttipc_nametbl_withdraw(net, &_ua, &p->sk, p->key);\n\t\t\tcontinue;\n\t\t}\n\t\t/* Unbind specific publication */\n\t\tif (p->scope != ua->scope)\n\t\t\tcontinue;\n\t\tif (p->sr.type != ua->sr.type)\n\t\t\tcontinue;\n\t\tif (p->sr.lower != ua->sr.lower)\n\t\t\tcontinue;\n\t\tif (p->sr.upper != ua->sr.upper)\n\t\t\tbreak;\n\t\ttipc_nametbl_withdraw(net, ua, &p->sk, p->key);\n\t\trc = 0;\n\t\tbreak;\n\t}\n\tif (list_empty(&tsk->publications)) {\n\t\ttsk->published = 0;\n\t\trc = 0;\n\t}\n\treturn rc;\n}\n\n/* tipc_sk_reinit: set non-zero address in all existing sockets\n *                 when we go from standalone to network mode.\n */\nvoid tipc_sk_reinit(struct net *net)\n{\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\tstruct rhashtable_iter iter;\n\tstruct tipc_sock *tsk;\n\tstruct tipc_msg *msg;\n\n\trhashtable_walk_enter(&tn->sk_rht, &iter);\n\n\tdo {\n\t\trhashtable_walk_start(&iter);\n\n\t\twhile ((tsk = rhashtable_walk_next(&iter)) && !IS_ERR(tsk)) {\n\t\t\tsock_hold(&tsk->sk);\n\t\t\trhashtable_walk_stop(&iter);\n\t\t\tlock_sock(&tsk->sk);\n\t\t\tmsg = &tsk->phdr;\n\t\t\tmsg_set_prevnode(msg, tipc_own_addr(net));\n\t\t\tmsg_set_orignode(msg, tipc_own_addr(net));\n\t\t\trelease_sock(&tsk->sk);\n\t\t\trhashtable_walk_start(&iter);\n\t\t\tsock_put(&tsk->sk);\n\t\t}\n\n\t\trhashtable_walk_stop(&iter);\n\t} while (tsk == ERR_PTR(-EAGAIN));\n\n\trhashtable_walk_exit(&iter);\n}\n\nstatic struct tipc_sock *tipc_sk_lookup(struct net *net, u32 portid)\n{\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\tstruct tipc_sock *tsk;\n\n\trcu_read_lock();\n\ttsk = rhashtable_lookup(&tn->sk_rht, &portid, tsk_rht_params);\n\tif (tsk)\n\t\tsock_hold(&tsk->sk);\n\trcu_read_unlock();\n\n\treturn tsk;\n}\n\nstatic int tipc_sk_insert(struct tipc_sock *tsk)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\tu32 remaining = (TIPC_MAX_PORT - TIPC_MIN_PORT) + 1;\n\tu32 portid = prandom_u32() % remaining + TIPC_MIN_PORT;\n\n\twhile (remaining--) {\n\t\tportid++;\n\t\tif ((portid < TIPC_MIN_PORT) || (portid > TIPC_MAX_PORT))\n\t\t\tportid = TIPC_MIN_PORT;\n\t\ttsk->portid = portid;\n\t\tsock_hold(&tsk->sk);\n\t\tif (!rhashtable_lookup_insert_fast(&tn->sk_rht, &tsk->node,\n\t\t\t\t\t\t   tsk_rht_params))\n\t\t\treturn 0;\n\t\tsock_put(&tsk->sk);\n\t}\n\n\treturn -1;\n}\n\nstatic void tipc_sk_remove(struct tipc_sock *tsk)\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct tipc_net *tn = net_generic(sock_net(sk), tipc_net_id);\n\n\tif (!rhashtable_remove_fast(&tn->sk_rht, &tsk->node, tsk_rht_params)) {\n\t\tWARN_ON(refcount_read(&sk->sk_refcnt) == 1);\n\t\t__sock_put(sk);\n\t}\n}\n\nstatic const struct rhashtable_params tsk_rht_params = {\n\t.nelem_hint = 192,\n\t.head_offset = offsetof(struct tipc_sock, node),\n\t.key_offset = offsetof(struct tipc_sock, portid),\n\t.key_len = sizeof(u32), /* portid */\n\t.max_size = 1048576,\n\t.min_size = 256,\n\t.automatic_shrinking = true,\n};\n\nint tipc_sk_rht_init(struct net *net)\n{\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\n\treturn rhashtable_init(&tn->sk_rht, &tsk_rht_params);\n}\n\nvoid tipc_sk_rht_destroy(struct net *net)\n{\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\n\t/* Wait for socket readers to complete */\n\tsynchronize_net();\n\n\trhashtable_destroy(&tn->sk_rht);\n}\n\nstatic int tipc_sk_join(struct tipc_sock *tsk, struct tipc_group_req *mreq)\n{\n\tstruct net *net = sock_net(&tsk->sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct tipc_uaddr ua;\n\tint rc;\n\n\tif (mreq->type < TIPC_RESERVED_TYPES)\n\t\treturn -EACCES;\n\tif (mreq->scope > TIPC_NODE_SCOPE)\n\t\treturn -EINVAL;\n\tif (mreq->scope != TIPC_NODE_SCOPE)\n\t\tmreq->scope = TIPC_CLUSTER_SCOPE;\n\tif (grp)\n\t\treturn -EACCES;\n\tgrp = tipc_group_create(net, tsk->portid, mreq, &tsk->group_is_open);\n\tif (!grp)\n\t\treturn -ENOMEM;\n\ttsk->group = grp;\n\tmsg_set_lookup_scope(hdr, mreq->scope);\n\tmsg_set_nametype(hdr, mreq->type);\n\tmsg_set_dest_droppable(hdr, true);\n\ttipc_uaddr(&ua, TIPC_SERVICE_RANGE, mreq->scope,\n\t\t   mreq->type, mreq->instance, mreq->instance);\n\ttipc_nametbl_build_group(net, grp, &ua);\n\trc = tipc_sk_publish(tsk, &ua);\n\tif (rc) {\n\t\ttipc_group_delete(net, grp);\n\t\ttsk->group = NULL;\n\t\treturn rc;\n\t}\n\t/* Eliminate any risk that a broadcast overtakes sent JOINs */\n\ttsk->mc_method.rcast = true;\n\ttsk->mc_method.mandatory = true;\n\ttipc_group_join(net, grp, &tsk->sk.sk_rcvbuf);\n\treturn rc;\n}\n\nstatic int tipc_sk_leave(struct tipc_sock *tsk)\n{\n\tstruct net *net = sock_net(&tsk->sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_uaddr ua;\n\tint scope;\n\n\tif (!grp)\n\t\treturn -EINVAL;\n\tua.addrtype = TIPC_SERVICE_RANGE;\n\ttipc_group_self(grp, &ua.sr, &scope);\n\tua.scope = scope;\n\ttipc_group_delete(net, grp);\n\ttsk->group = NULL;\n\ttipc_sk_withdraw(tsk, &ua);\n\treturn 0;\n}\n\n/**\n * tipc_setsockopt - set socket option\n * @sock: socket structure\n * @lvl: option level\n * @opt: option identifier\n * @ov: pointer to new option value\n * @ol: length of option value\n *\n * For stream sockets only, accepts and ignores all IPPROTO_TCP options\n * (to ease compatibility).\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_setsockopt(struct socket *sock, int lvl, int opt,\n\t\t\t   sockptr_t ov, unsigned int ol)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_group_req mreq;\n\tu32 value = 0;\n\tint res = 0;\n\n\tif ((lvl == IPPROTO_TCP) && (sock->type == SOCK_STREAM))\n\t\treturn 0;\n\tif (lvl != SOL_TIPC)\n\t\treturn -ENOPROTOOPT;\n\n\tswitch (opt) {\n\tcase TIPC_IMPORTANCE:\n\tcase TIPC_SRC_DROPPABLE:\n\tcase TIPC_DEST_DROPPABLE:\n\tcase TIPC_CONN_TIMEOUT:\n\tcase TIPC_NODELAY:\n\t\tif (ol < sizeof(value))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_sockptr(&value, ov, sizeof(u32)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\tcase TIPC_GROUP_JOIN:\n\t\tif (ol < sizeof(mreq))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_sockptr(&mreq, ov, sizeof(mreq)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\tdefault:\n\t\tif (!sockptr_is_null(ov) || ol)\n\t\t\treturn -EINVAL;\n\t}\n\n\tlock_sock(sk);\n\n\tswitch (opt) {\n\tcase TIPC_IMPORTANCE:\n\t\tres = tsk_set_importance(sk, value);\n\t\tbreak;\n\tcase TIPC_SRC_DROPPABLE:\n\t\tif (sock->type != SOCK_STREAM)\n\t\t\ttsk_set_unreliable(tsk, value);\n\t\telse\n\t\t\tres = -ENOPROTOOPT;\n\t\tbreak;\n\tcase TIPC_DEST_DROPPABLE:\n\t\ttsk_set_unreturnable(tsk, value);\n\t\tbreak;\n\tcase TIPC_CONN_TIMEOUT:\n\t\ttipc_sk(sk)->conn_timeout = value;\n\t\tbreak;\n\tcase TIPC_MCAST_BROADCAST:\n\t\ttsk->mc_method.rcast = false;\n\t\ttsk->mc_method.mandatory = true;\n\t\tbreak;\n\tcase TIPC_MCAST_REPLICAST:\n\t\ttsk->mc_method.rcast = true;\n\t\ttsk->mc_method.mandatory = true;\n\t\tbreak;\n\tcase TIPC_GROUP_JOIN:\n\t\tres = tipc_sk_join(tsk, &mreq);\n\t\tbreak;\n\tcase TIPC_GROUP_LEAVE:\n\t\tres = tipc_sk_leave(tsk);\n\t\tbreak;\n\tcase TIPC_NODELAY:\n\t\ttsk->nodelay = !!value;\n\t\ttsk_set_nagle(tsk);\n\t\tbreak;\n\tdefault:\n\t\tres = -EINVAL;\n\t}\n\n\trelease_sock(sk);\n\n\treturn res;\n}\n\n/**\n * tipc_getsockopt - get socket option\n * @sock: socket structure\n * @lvl: option level\n * @opt: option identifier\n * @ov: receptacle for option value\n * @ol: receptacle for length of option value\n *\n * For stream sockets only, returns 0 length result for all IPPROTO_TCP options\n * (to ease compatibility).\n *\n * Return: 0 on success, errno otherwise\n */\nstatic int tipc_getsockopt(struct socket *sock, int lvl, int opt,\n\t\t\t   char __user *ov, int __user *ol)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_service_range seq;\n\tint len, scope;\n\tu32 value;\n\tint res;\n\n\tif ((lvl == IPPROTO_TCP) && (sock->type == SOCK_STREAM))\n\t\treturn put_user(0, ol);\n\tif (lvl != SOL_TIPC)\n\t\treturn -ENOPROTOOPT;\n\tres = get_user(len, ol);\n\tif (res)\n\t\treturn res;\n\n\tlock_sock(sk);\n\n\tswitch (opt) {\n\tcase TIPC_IMPORTANCE:\n\t\tvalue = tsk_importance(tsk);\n\t\tbreak;\n\tcase TIPC_SRC_DROPPABLE:\n\t\tvalue = tsk_unreliable(tsk);\n\t\tbreak;\n\tcase TIPC_DEST_DROPPABLE:\n\t\tvalue = tsk_unreturnable(tsk);\n\t\tbreak;\n\tcase TIPC_CONN_TIMEOUT:\n\t\tvalue = tsk->conn_timeout;\n\t\t/* no need to set \"res\", since already 0 at this point */\n\t\tbreak;\n\tcase TIPC_NODE_RECVQ_DEPTH:\n\t\tvalue = 0; /* was tipc_queue_size, now obsolete */\n\t\tbreak;\n\tcase TIPC_SOCK_RECVQ_DEPTH:\n\t\tvalue = skb_queue_len(&sk->sk_receive_queue);\n\t\tbreak;\n\tcase TIPC_SOCK_RECVQ_USED:\n\t\tvalue = sk_rmem_alloc_get(sk);\n\t\tbreak;\n\tcase TIPC_GROUP_JOIN:\n\t\tseq.type = 0;\n\t\tif (tsk->group)\n\t\t\ttipc_group_self(tsk->group, &seq, &scope);\n\t\tvalue = seq.type;\n\t\tbreak;\n\tdefault:\n\t\tres = -EINVAL;\n\t}\n\n\trelease_sock(sk);\n\n\tif (res)\n\t\treturn res;\t/* \"get\" failed */\n\n\tif (len < sizeof(value))\n\t\treturn -EINVAL;\n\n\tif (copy_to_user(ov, &value, sizeof(value)))\n\t\treturn -EFAULT;\n\n\treturn put_user(sizeof(value), ol);\n}\n\nstatic int tipc_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)\n{\n\tstruct net *net = sock_net(sock->sk);\n\tstruct tipc_sioc_nodeid_req nr = {0};\n\tstruct tipc_sioc_ln_req lnr;\n\tvoid __user *argp = (void __user *)arg;\n\n\tswitch (cmd) {\n\tcase SIOCGETLINKNAME:\n\t\tif (copy_from_user(&lnr, argp, sizeof(lnr)))\n\t\t\treturn -EFAULT;\n\t\tif (!tipc_node_get_linkname(net,\n\t\t\t\t\t    lnr.bearer_id & 0xffff, lnr.peer,\n\t\t\t\t\t    lnr.linkname, TIPC_MAX_LINK_NAME)) {\n\t\t\tif (copy_to_user(argp, &lnr, sizeof(lnr)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn 0;\n\t\t}\n\t\treturn -EADDRNOTAVAIL;\n\tcase SIOCGETNODEID:\n\t\tif (copy_from_user(&nr, argp, sizeof(nr)))\n\t\t\treturn -EFAULT;\n\t\tif (!tipc_node_get_id(net, nr.peer, nr.node_id))\n\t\t\treturn -EADDRNOTAVAIL;\n\t\tif (copy_to_user(argp, &nr, sizeof(nr)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n}\n\nstatic int tipc_socketpair(struct socket *sock1, struct socket *sock2)\n{\n\tstruct tipc_sock *tsk2 = tipc_sk(sock2->sk);\n\tstruct tipc_sock *tsk1 = tipc_sk(sock1->sk);\n\tu32 onode = tipc_own_addr(sock_net(sock1->sk));\n\n\ttsk1->peer.family = AF_TIPC;\n\ttsk1->peer.addrtype = TIPC_SOCKET_ADDR;\n\ttsk1->peer.scope = TIPC_NODE_SCOPE;\n\ttsk1->peer.addr.id.ref = tsk2->portid;\n\ttsk1->peer.addr.id.node = onode;\n\ttsk2->peer.family = AF_TIPC;\n\ttsk2->peer.addrtype = TIPC_SOCKET_ADDR;\n\ttsk2->peer.scope = TIPC_NODE_SCOPE;\n\ttsk2->peer.addr.id.ref = tsk1->portid;\n\ttsk2->peer.addr.id.node = onode;\n\n\ttipc_sk_finish_conn(tsk1, tsk2->portid, onode);\n\ttipc_sk_finish_conn(tsk2, tsk1->portid, onode);\n\treturn 0;\n}\n\n/* Protocol switches for the various types of TIPC sockets */\n\nstatic const struct proto_ops msg_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.family\t\t= AF_TIPC,\n\t.release\t= tipc_release,\n\t.bind\t\t= tipc_bind,\n\t.connect\t= tipc_connect,\n\t.socketpair\t= tipc_socketpair,\n\t.accept\t\t= sock_no_accept,\n\t.getname\t= tipc_getname,\n\t.poll\t\t= tipc_poll,\n\t.ioctl\t\t= tipc_ioctl,\n\t.listen\t\t= sock_no_listen,\n\t.shutdown\t= tipc_shutdown,\n\t.setsockopt\t= tipc_setsockopt,\n\t.getsockopt\t= tipc_getsockopt,\n\t.sendmsg\t= tipc_sendmsg,\n\t.recvmsg\t= tipc_recvmsg,\n\t.mmap\t\t= sock_no_mmap,\n\t.sendpage\t= sock_no_sendpage\n};\n\nstatic const struct proto_ops packet_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.family\t\t= AF_TIPC,\n\t.release\t= tipc_release,\n\t.bind\t\t= tipc_bind,\n\t.connect\t= tipc_connect,\n\t.socketpair\t= tipc_socketpair,\n\t.accept\t\t= tipc_accept,\n\t.getname\t= tipc_getname,\n\t.poll\t\t= tipc_poll,\n\t.ioctl\t\t= tipc_ioctl,\n\t.listen\t\t= tipc_listen,\n\t.shutdown\t= tipc_shutdown,\n\t.setsockopt\t= tipc_setsockopt,\n\t.getsockopt\t= tipc_getsockopt,\n\t.sendmsg\t= tipc_send_packet,\n\t.recvmsg\t= tipc_recvmsg,\n\t.mmap\t\t= sock_no_mmap,\n\t.sendpage\t= sock_no_sendpage\n};\n\nstatic const struct proto_ops stream_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.family\t\t= AF_TIPC,\n\t.release\t= tipc_release,\n\t.bind\t\t= tipc_bind,\n\t.connect\t= tipc_connect,\n\t.socketpair\t= tipc_socketpair,\n\t.accept\t\t= tipc_accept,\n\t.getname\t= tipc_getname,\n\t.poll\t\t= tipc_poll,\n\t.ioctl\t\t= tipc_ioctl,\n\t.listen\t\t= tipc_listen,\n\t.shutdown\t= tipc_shutdown,\n\t.setsockopt\t= tipc_setsockopt,\n\t.getsockopt\t= tipc_getsockopt,\n\t.sendmsg\t= tipc_sendstream,\n\t.recvmsg\t= tipc_recvstream,\n\t.mmap\t\t= sock_no_mmap,\n\t.sendpage\t= sock_no_sendpage\n};\n\nstatic const struct net_proto_family tipc_family_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.family\t\t= AF_TIPC,\n\t.create\t\t= tipc_sk_create\n};\n\nstatic struct proto tipc_proto = {\n\t.name\t\t= \"TIPC\",\n\t.owner\t\t= THIS_MODULE,\n\t.obj_size\t= sizeof(struct tipc_sock),\n\t.sysctl_rmem\t= sysctl_tipc_rmem\n};\n\n/**\n * tipc_socket_init - initialize TIPC socket interface\n *\n * Return: 0 on success, errno otherwise\n */\nint tipc_socket_init(void)\n{\n\tint res;\n\n\tres = proto_register(&tipc_proto, 1);\n\tif (res) {\n\t\tpr_err(\"Failed to register TIPC protocol type\\n\");\n\t\tgoto out;\n\t}\n\n\tres = sock_register(&tipc_family_ops);\n\tif (res) {\n\t\tpr_err(\"Failed to register TIPC socket type\\n\");\n\t\tproto_unregister(&tipc_proto);\n\t\tgoto out;\n\t}\n out:\n\treturn res;\n}\n\n/**\n * tipc_socket_stop - stop TIPC socket interface\n */\nvoid tipc_socket_stop(void)\n{\n\tsock_unregister(tipc_family_ops.family);\n\tproto_unregister(&tipc_proto);\n}\n\n/* Caller should hold socket lock for the passed tipc socket. */\nstatic int __tipc_nl_add_sk_con(struct sk_buff *skb, struct tipc_sock *tsk)\n{\n\tu32 peer_node, peer_port;\n\tu32 conn_type, conn_instance;\n\tstruct nlattr *nest;\n\n\tpeer_node = tsk_peer_node(tsk);\n\tpeer_port = tsk_peer_port(tsk);\n\tconn_type = msg_nametype(&tsk->phdr);\n\tconn_instance = msg_nameinst(&tsk->phdr);\n\tnest = nla_nest_start_noflag(skb, TIPC_NLA_SOCK_CON);\n\tif (!nest)\n\t\treturn -EMSGSIZE;\n\n\tif (nla_put_u32(skb, TIPC_NLA_CON_NODE, peer_node))\n\t\tgoto msg_full;\n\tif (nla_put_u32(skb, TIPC_NLA_CON_SOCK, peer_port))\n\t\tgoto msg_full;\n\n\tif (tsk->conn_addrtype != 0) {\n\t\tif (nla_put_flag(skb, TIPC_NLA_CON_FLAG))\n\t\t\tgoto msg_full;\n\t\tif (nla_put_u32(skb, TIPC_NLA_CON_TYPE, conn_type))\n\t\t\tgoto msg_full;\n\t\tif (nla_put_u32(skb, TIPC_NLA_CON_INST, conn_instance))\n\t\t\tgoto msg_full;\n\t}\n\tnla_nest_end(skb, nest);\n\n\treturn 0;\n\nmsg_full:\n\tnla_nest_cancel(skb, nest);\n\n\treturn -EMSGSIZE;\n}\n\nstatic int __tipc_nl_add_sk_info(struct sk_buff *skb, struct tipc_sock\n\t\t\t  *tsk)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct sock *sk = &tsk->sk;\n\n\tif (nla_put_u32(skb, TIPC_NLA_SOCK_REF, tsk->portid) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_ADDR, tipc_own_addr(net)))\n\t\treturn -EMSGSIZE;\n\n\tif (tipc_sk_connected(sk)) {\n\t\tif (__tipc_nl_add_sk_con(skb, tsk))\n\t\t\treturn -EMSGSIZE;\n\t} else if (!list_empty(&tsk->publications)) {\n\t\tif (nla_put_flag(skb, TIPC_NLA_SOCK_HAS_PUBL))\n\t\t\treturn -EMSGSIZE;\n\t}\n\treturn 0;\n}\n\n/* Caller should hold socket lock for the passed tipc socket. */\nstatic int __tipc_nl_add_sk(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t\t    struct tipc_sock *tsk)\n{\n\tstruct nlattr *attrs;\n\tvoid *hdr;\n\n\thdr = genlmsg_put(skb, NETLINK_CB(cb->skb).portid, cb->nlh->nlmsg_seq,\n\t\t\t  &tipc_genl_family, NLM_F_MULTI, TIPC_NL_SOCK_GET);\n\tif (!hdr)\n\t\tgoto msg_cancel;\n\n\tattrs = nla_nest_start_noflag(skb, TIPC_NLA_SOCK);\n\tif (!attrs)\n\t\tgoto genlmsg_cancel;\n\n\tif (__tipc_nl_add_sk_info(skb, tsk))\n\t\tgoto attr_msg_cancel;\n\n\tnla_nest_end(skb, attrs);\n\tgenlmsg_end(skb, hdr);\n\n\treturn 0;\n\nattr_msg_cancel:\n\tnla_nest_cancel(skb, attrs);\ngenlmsg_cancel:\n\tgenlmsg_cancel(skb, hdr);\nmsg_cancel:\n\treturn -EMSGSIZE;\n}\n\nint tipc_nl_sk_walk(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t    int (*skb_handler)(struct sk_buff *skb,\n\t\t\t\t       struct netlink_callback *cb,\n\t\t\t\t       struct tipc_sock *tsk))\n{\n\tstruct rhashtable_iter *iter = (void *)cb->args[4];\n\tstruct tipc_sock *tsk;\n\tint err;\n\n\trhashtable_walk_start(iter);\n\twhile ((tsk = rhashtable_walk_next(iter)) != NULL) {\n\t\tif (IS_ERR(tsk)) {\n\t\t\terr = PTR_ERR(tsk);\n\t\t\tif (err == -EAGAIN) {\n\t\t\t\terr = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tsock_hold(&tsk->sk);\n\t\trhashtable_walk_stop(iter);\n\t\tlock_sock(&tsk->sk);\n\t\terr = skb_handler(skb, cb, tsk);\n\t\tif (err) {\n\t\t\trelease_sock(&tsk->sk);\n\t\t\tsock_put(&tsk->sk);\n\t\t\tgoto out;\n\t\t}\n\t\trelease_sock(&tsk->sk);\n\t\trhashtable_walk_start(iter);\n\t\tsock_put(&tsk->sk);\n\t}\n\trhashtable_walk_stop(iter);\nout:\n\treturn skb->len;\n}\nEXPORT_SYMBOL(tipc_nl_sk_walk);\n\nint tipc_dump_start(struct netlink_callback *cb)\n{\n\treturn __tipc_dump_start(cb, sock_net(cb->skb->sk));\n}\nEXPORT_SYMBOL(tipc_dump_start);\n\nint __tipc_dump_start(struct netlink_callback *cb, struct net *net)\n{\n\t/* tipc_nl_name_table_dump() uses cb->args[0...3]. */\n\tstruct rhashtable_iter *iter = (void *)cb->args[4];\n\tstruct tipc_net *tn = tipc_net(net);\n\n\tif (!iter) {\n\t\titer = kmalloc(sizeof(*iter), GFP_KERNEL);\n\t\tif (!iter)\n\t\t\treturn -ENOMEM;\n\n\t\tcb->args[4] = (long)iter;\n\t}\n\n\trhashtable_walk_enter(&tn->sk_rht, iter);\n\treturn 0;\n}\n\nint tipc_dump_done(struct netlink_callback *cb)\n{\n\tstruct rhashtable_iter *hti = (void *)cb->args[4];\n\n\trhashtable_walk_exit(hti);\n\tkfree(hti);\n\treturn 0;\n}\nEXPORT_SYMBOL(tipc_dump_done);\n\nint tipc_sk_fill_sock_diag(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t\t   struct tipc_sock *tsk, u32 sk_filter_state,\n\t\t\t   u64 (*tipc_diag_gen_cookie)(struct sock *sk))\n{\n\tstruct sock *sk = &tsk->sk;\n\tstruct nlattr *attrs;\n\tstruct nlattr *stat;\n\n\t/*filter response w.r.t sk_state*/\n\tif (!(sk_filter_state & (1 << sk->sk_state)))\n\t\treturn 0;\n\n\tattrs = nla_nest_start_noflag(skb, TIPC_NLA_SOCK);\n\tif (!attrs)\n\t\tgoto msg_cancel;\n\n\tif (__tipc_nl_add_sk_info(skb, tsk))\n\t\tgoto attr_msg_cancel;\n\n\tif (nla_put_u32(skb, TIPC_NLA_SOCK_TYPE, (u32)sk->sk_type) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_TIPC_STATE, (u32)sk->sk_state) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_INO, sock_i_ino(sk)) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_UID,\n\t\t\tfrom_kuid_munged(sk_user_ns(NETLINK_CB(cb->skb).sk),\n\t\t\t\t\t sock_i_uid(sk))) ||\n\t    nla_put_u64_64bit(skb, TIPC_NLA_SOCK_COOKIE,\n\t\t\t      tipc_diag_gen_cookie(sk),\n\t\t\t      TIPC_NLA_SOCK_PAD))\n\t\tgoto attr_msg_cancel;\n\n\tstat = nla_nest_start_noflag(skb, TIPC_NLA_SOCK_STAT);\n\tif (!stat)\n\t\tgoto attr_msg_cancel;\n\n\tif (nla_put_u32(skb, TIPC_NLA_SOCK_STAT_RCVQ,\n\t\t\tskb_queue_len(&sk->sk_receive_queue)) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_STAT_SENDQ,\n\t\t\tskb_queue_len(&sk->sk_write_queue)) ||\n\t    nla_put_u32(skb, TIPC_NLA_SOCK_STAT_DROP,\n\t\t\tatomic_read(&sk->sk_drops)))\n\t\tgoto stat_msg_cancel;\n\n\tif (tsk->cong_link_cnt &&\n\t    nla_put_flag(skb, TIPC_NLA_SOCK_STAT_LINK_CONG))\n\t\tgoto stat_msg_cancel;\n\n\tif (tsk_conn_cong(tsk) &&\n\t    nla_put_flag(skb, TIPC_NLA_SOCK_STAT_CONN_CONG))\n\t\tgoto stat_msg_cancel;\n\n\tnla_nest_end(skb, stat);\n\n\tif (tsk->group)\n\t\tif (tipc_group_fill_sock_diag(tsk->group, skb))\n\t\t\tgoto stat_msg_cancel;\n\n\tnla_nest_end(skb, attrs);\n\n\treturn 0;\n\nstat_msg_cancel:\n\tnla_nest_cancel(skb, stat);\nattr_msg_cancel:\n\tnla_nest_cancel(skb, attrs);\nmsg_cancel:\n\treturn -EMSGSIZE;\n}\nEXPORT_SYMBOL(tipc_sk_fill_sock_diag);\n\nint tipc_nl_sk_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\treturn tipc_nl_sk_walk(skb, cb, __tipc_nl_add_sk);\n}\n\n/* Caller should hold socket lock for the passed tipc socket. */\nstatic int __tipc_nl_add_sk_publ(struct sk_buff *skb,\n\t\t\t\t struct netlink_callback *cb,\n\t\t\t\t struct publication *publ)\n{\n\tvoid *hdr;\n\tstruct nlattr *attrs;\n\n\thdr = genlmsg_put(skb, NETLINK_CB(cb->skb).portid, cb->nlh->nlmsg_seq,\n\t\t\t  &tipc_genl_family, NLM_F_MULTI, TIPC_NL_PUBL_GET);\n\tif (!hdr)\n\t\tgoto msg_cancel;\n\n\tattrs = nla_nest_start_noflag(skb, TIPC_NLA_PUBL);\n\tif (!attrs)\n\t\tgoto genlmsg_cancel;\n\n\tif (nla_put_u32(skb, TIPC_NLA_PUBL_KEY, publ->key))\n\t\tgoto attr_msg_cancel;\n\tif (nla_put_u32(skb, TIPC_NLA_PUBL_TYPE, publ->sr.type))\n\t\tgoto attr_msg_cancel;\n\tif (nla_put_u32(skb, TIPC_NLA_PUBL_LOWER, publ->sr.lower))\n\t\tgoto attr_msg_cancel;\n\tif (nla_put_u32(skb, TIPC_NLA_PUBL_UPPER, publ->sr.upper))\n\t\tgoto attr_msg_cancel;\n\n\tnla_nest_end(skb, attrs);\n\tgenlmsg_end(skb, hdr);\n\n\treturn 0;\n\nattr_msg_cancel:\n\tnla_nest_cancel(skb, attrs);\ngenlmsg_cancel:\n\tgenlmsg_cancel(skb, hdr);\nmsg_cancel:\n\treturn -EMSGSIZE;\n}\n\n/* Caller should hold socket lock for the passed tipc socket. */\nstatic int __tipc_nl_list_sk_publ(struct sk_buff *skb,\n\t\t\t\t  struct netlink_callback *cb,\n\t\t\t\t  struct tipc_sock *tsk, u32 *last_publ)\n{\n\tint err;\n\tstruct publication *p;\n\n\tif (*last_publ) {\n\t\tlist_for_each_entry(p, &tsk->publications, binding_sock) {\n\t\t\tif (p->key == *last_publ)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (p->key != *last_publ) {\n\t\t\t/* We never set seq or call nl_dump_check_consistent()\n\t\t\t * this means that setting prev_seq here will cause the\n\t\t\t * consistence check to fail in the netlink callback\n\t\t\t * handler. Resulting in the last NLMSG_DONE message\n\t\t\t * having the NLM_F_DUMP_INTR flag set.\n\t\t\t */\n\t\t\tcb->prev_seq = 1;\n\t\t\t*last_publ = 0;\n\t\t\treturn -EPIPE;\n\t\t}\n\t} else {\n\t\tp = list_first_entry(&tsk->publications, struct publication,\n\t\t\t\t     binding_sock);\n\t}\n\n\tlist_for_each_entry_from(p, &tsk->publications, binding_sock) {\n\t\terr = __tipc_nl_add_sk_publ(skb, cb, p);\n\t\tif (err) {\n\t\t\t*last_publ = p->key;\n\t\t\treturn err;\n\t\t}\n\t}\n\t*last_publ = 0;\n\n\treturn 0;\n}\n\nint tipc_nl_publ_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tint err;\n\tu32 tsk_portid = cb->args[0];\n\tu32 last_publ = cb->args[1];\n\tu32 done = cb->args[2];\n\tstruct net *net = sock_net(skb->sk);\n\tstruct tipc_sock *tsk;\n\n\tif (!tsk_portid) {\n\t\tstruct nlattr **attrs = genl_dumpit_info(cb)->attrs;\n\t\tstruct nlattr *sock[TIPC_NLA_SOCK_MAX + 1];\n\n\t\tif (!attrs[TIPC_NLA_SOCK])\n\t\t\treturn -EINVAL;\n\n\t\terr = nla_parse_nested_deprecated(sock, TIPC_NLA_SOCK_MAX,\n\t\t\t\t\t\t  attrs[TIPC_NLA_SOCK],\n\t\t\t\t\t\t  tipc_nl_sock_policy, NULL);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (!sock[TIPC_NLA_SOCK_REF])\n\t\t\treturn -EINVAL;\n\n\t\ttsk_portid = nla_get_u32(sock[TIPC_NLA_SOCK_REF]);\n\t}\n\n\tif (done)\n\t\treturn 0;\n\n\ttsk = tipc_sk_lookup(net, tsk_portid);\n\tif (!tsk)\n\t\treturn -EINVAL;\n\n\tlock_sock(&tsk->sk);\n\terr = __tipc_nl_list_sk_publ(skb, cb, tsk, &last_publ);\n\tif (!err)\n\t\tdone = 1;\n\trelease_sock(&tsk->sk);\n\tsock_put(&tsk->sk);\n\n\tcb->args[0] = tsk_portid;\n\tcb->args[1] = last_publ;\n\tcb->args[2] = done;\n\n\treturn skb->len;\n}\n\n/**\n * tipc_sk_filtering - check if a socket should be traced\n * @sk: the socket to be examined\n *\n * @sysctl_tipc_sk_filter is used as the socket tuple for filtering:\n * (portid, sock type, name type, name lower, name upper)\n *\n * Return: true if the socket meets the socket tuple data\n * (value 0 = 'any') or when there is no tuple set (all = 0),\n * otherwise false\n */\nbool tipc_sk_filtering(struct sock *sk)\n{\n\tstruct tipc_sock *tsk;\n\tstruct publication *p;\n\tu32 _port, _sktype, _type, _lower, _upper;\n\tu32 type = 0, lower = 0, upper = 0;\n\n\tif (!sk)\n\t\treturn true;\n\n\ttsk = tipc_sk(sk);\n\n\t_port = sysctl_tipc_sk_filter[0];\n\t_sktype = sysctl_tipc_sk_filter[1];\n\t_type = sysctl_tipc_sk_filter[2];\n\t_lower = sysctl_tipc_sk_filter[3];\n\t_upper = sysctl_tipc_sk_filter[4];\n\n\tif (!_port && !_sktype && !_type && !_lower && !_upper)\n\t\treturn true;\n\n\tif (_port)\n\t\treturn (_port == tsk->portid);\n\n\tif (_sktype && _sktype != sk->sk_type)\n\t\treturn false;\n\n\tif (tsk->published) {\n\t\tp = list_first_entry_or_null(&tsk->publications,\n\t\t\t\t\t     struct publication, binding_sock);\n\t\tif (p) {\n\t\t\ttype = p->sr.type;\n\t\t\tlower = p->sr.lower;\n\t\t\tupper = p->sr.upper;\n\t\t}\n\t}\n\n\tif (!tipc_sk_type_connectionless(sk)) {\n\t\ttype = msg_nametype(&tsk->phdr);\n\t\tlower = msg_nameinst(&tsk->phdr);\n\t\tupper = lower;\n\t}\n\n\tif ((_type && _type != type) || (_lower && _lower != lower) ||\n\t    (_upper && _upper != upper))\n\t\treturn false;\n\n\treturn true;\n}\n\nu32 tipc_sock_get_portid(struct sock *sk)\n{\n\treturn (sk) ? (tipc_sk(sk))->portid : 0;\n}\n\n/**\n * tipc_sk_overlimit1 - check if socket rx queue is about to be overloaded,\n *\t\t\tboth the rcv and backlog queues are considered\n * @sk: tipc sk to be checked\n * @skb: tipc msg to be checked\n *\n * Return: true if the socket rx queue allocation is > 90%, otherwise false\n */\n\nbool tipc_sk_overlimit1(struct sock *sk, struct sk_buff *skb)\n{\n\tatomic_t *dcnt = &tipc_sk(sk)->dupl_rcvcnt;\n\tunsigned int lim = rcvbuf_limit(sk, skb) + atomic_read(dcnt);\n\tunsigned int qsize = sk->sk_backlog.len + sk_rmem_alloc_get(sk);\n\n\treturn (qsize > lim * 90 / 100);\n}\n\n/**\n * tipc_sk_overlimit2 - check if socket rx queue is about to be overloaded,\n *\t\t\tonly the rcv queue is considered\n * @sk: tipc sk to be checked\n * @skb: tipc msg to be checked\n *\n * Return: true if the socket rx queue allocation is > 90%, otherwise false\n */\n\nbool tipc_sk_overlimit2(struct sock *sk, struct sk_buff *skb)\n{\n\tunsigned int lim = rcvbuf_limit(sk, skb);\n\tunsigned int qsize = sk_rmem_alloc_get(sk);\n\n\treturn (qsize > lim * 90 / 100);\n}\n\n/**\n * tipc_sk_dump - dump TIPC socket\n * @sk: tipc sk to be dumped\n * @dqueues: bitmask to decide if any socket queue to be dumped?\n *           - TIPC_DUMP_NONE: don't dump socket queues\n *           - TIPC_DUMP_SK_SNDQ: dump socket send queue\n *           - TIPC_DUMP_SK_RCVQ: dump socket rcv queue\n *           - TIPC_DUMP_SK_BKLGQ: dump socket backlog queue\n *           - TIPC_DUMP_ALL: dump all the socket queues above\n * @buf: returned buffer of dump data in format\n */\nint tipc_sk_dump(struct sock *sk, u16 dqueues, char *buf)\n{\n\tint i = 0;\n\tsize_t sz = (dqueues) ? SK_LMAX : SK_LMIN;\n\tu32 conn_type, conn_instance;\n\tstruct tipc_sock *tsk;\n\tstruct publication *p;\n\tbool tsk_connected;\n\n\tif (!sk) {\n\t\ti += scnprintf(buf, sz, \"sk data: (null)\\n\");\n\t\treturn i;\n\t}\n\n\ttsk = tipc_sk(sk);\n\ttsk_connected = !tipc_sk_type_connectionless(sk);\n\n\ti += scnprintf(buf, sz, \"sk data: %u\", sk->sk_type);\n\ti += scnprintf(buf + i, sz - i, \" %d\", sk->sk_state);\n\ti += scnprintf(buf + i, sz - i, \" %x\", tsk_own_node(tsk));\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->portid);\n\ti += scnprintf(buf + i, sz - i, \" | %u\", tsk_connected);\n\tif (tsk_connected) {\n\t\ti += scnprintf(buf + i, sz - i, \" %x\", tsk_peer_node(tsk));\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", tsk_peer_port(tsk));\n\t\tconn_type = msg_nametype(&tsk->phdr);\n\t\tconn_instance = msg_nameinst(&tsk->phdr);\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", conn_type);\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", conn_instance);\n\t}\n\ti += scnprintf(buf + i, sz - i, \" | %u\", tsk->published);\n\tif (tsk->published) {\n\t\tp = list_first_entry_or_null(&tsk->publications,\n\t\t\t\t\t     struct publication, binding_sock);\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", (p) ? p->sr.type : 0);\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", (p) ? p->sr.lower : 0);\n\t\ti += scnprintf(buf + i, sz - i, \" %u\", (p) ? p->sr.upper : 0);\n\t}\n\ti += scnprintf(buf + i, sz - i, \" | %u\", tsk->snd_win);\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->rcv_win);\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->max_pkt);\n\ti += scnprintf(buf + i, sz - i, \" %x\", tsk->peer_caps);\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->cong_link_cnt);\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->snt_unacked);\n\ti += scnprintf(buf + i, sz - i, \" %u\", tsk->rcv_unacked);\n\ti += scnprintf(buf + i, sz - i, \" %u\", atomic_read(&tsk->dupl_rcvcnt));\n\ti += scnprintf(buf + i, sz - i, \" %u\", sk->sk_shutdown);\n\ti += scnprintf(buf + i, sz - i, \" | %d\", sk_wmem_alloc_get(sk));\n\ti += scnprintf(buf + i, sz - i, \" %d\", sk->sk_sndbuf);\n\ti += scnprintf(buf + i, sz - i, \" | %d\", sk_rmem_alloc_get(sk));\n\ti += scnprintf(buf + i, sz - i, \" %d\", sk->sk_rcvbuf);\n\ti += scnprintf(buf + i, sz - i, \" | %d\\n\", READ_ONCE(sk->sk_backlog.len));\n\n\tif (dqueues & TIPC_DUMP_SK_SNDQ) {\n\t\ti += scnprintf(buf + i, sz - i, \"sk_write_queue: \");\n\t\ti += tipc_list_dump(&sk->sk_write_queue, false, buf + i);\n\t}\n\n\tif (dqueues & TIPC_DUMP_SK_RCVQ) {\n\t\ti += scnprintf(buf + i, sz - i, \"sk_receive_queue: \");\n\t\ti += tipc_list_dump(&sk->sk_receive_queue, false, buf + i);\n\t}\n\n\tif (dqueues & TIPC_DUMP_SK_BKLGQ) {\n\t\ti += scnprintf(buf + i, sz - i, \"sk_backlog:\\n  head \");\n\t\ti += tipc_skb_dump(sk->sk_backlog.head, false, buf + i);\n\t\tif (sk->sk_backlog.tail != sk->sk_backlog.head) {\n\t\t\ti += scnprintf(buf + i, sz - i, \"  tail \");\n\t\t\ti += tipc_skb_dump(sk->sk_backlog.tail, false,\n\t\t\t\t\t   buf + i);\n\t\t}\n\t}\n\n\treturn i;\n}\n"], "filenames": ["net/tipc/socket.c"], "buggy_code_start_loc": [1462], "buggy_code_end_loc": [1462], "fixing_code_start_loc": [1463], "fixing_code_end_loc": [1465], "type": "CWE-909", "message": "An information leak flaw was found due to uninitialized memory in the Linux kernel's TIPC protocol subsystem, in the way a user sends a TIPC datagram to one or more destinations. This flaw allows a local user to read some kernel memory. This issue is limited to no more than 7 bytes, and the user cannot control what is read. This flaw affects the Linux kernel versions prior to 5.17-rc1.", "other": {"cve": {"id": "CVE-2022-0382", "sourceIdentifier": "secalert@redhat.com", "published": "2022-02-11T18:15:10.940", "lastModified": "2022-12-02T19:39:01.583", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "An information leak flaw was found due to uninitialized memory in the Linux kernel's TIPC protocol subsystem, in the way a user sends a TIPC datagram to one or more destinations. This flaw allows a local user to read some kernel memory. This issue is limited to no more than 7 bytes, and the user cannot control what is read. This flaw affects the Linux kernel versions prior to 5.17-rc1."}, {"lang": "es", "value": "Se ha encontrado un fallo de fuga de informaci\u00f3n debido a una memoria no inicializada en el subsistema de protocolo TIPC del kernel de Linux, en la forma en que un usuario env\u00eda un datagrama TIPC a uno o m\u00e1s destinos. Este fallo permite a un usuario local leer parte de la memoria del kernel. Este problema se limita a no m\u00e1s de 7 bytes, y el usuario no puede controlar lo que se lee. Este fallo afecta a las versiones del kernel de Linux anteriores a la 5.17-rc1"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:N/A:N", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-909"}]}, {"source": "secalert@redhat.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-909"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "5.16.10", "matchCriteriaId": "CDB28B14-4E1B-49E5-B53A-C27C74E6B6C5"}]}]}], "references": [{"url": "https://github.com/torvalds/linux/commit/d6d86830705f173fca6087a3e67ceaf68db80523", "source": "secalert@redhat.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/d6d86830705f173fca6087a3e67ceaf68db80523"}}
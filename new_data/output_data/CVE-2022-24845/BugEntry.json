{"buggy_code": ["from decimal import Decimal\n\nimport pytest\n\nfrom vyper.ast.signatures.interface import extract_sigs\nfrom vyper.builtin_interfaces import ERC20, ERC721\nfrom vyper.cli.utils import extract_file_interface_imports\nfrom vyper.compiler import compile_code, compile_codes\nfrom vyper.exceptions import InterfaceViolation, StructureException\n\n\ndef test_basic_extract_interface():\n    code = \"\"\"\n# Events\n\nevent Transfer:\n    _from: address\n    _to: address\n    _value: uint256\n\n# Functions\n\n@view\n@external\ndef allowance(_owner: address, _spender: address) -> (uint256, uint256):\n    return 1, 2\n    \"\"\"\n\n    out = compile_code(code, [\"interface\"])\n    out = out[\"interface\"]\n    code_pass = \"\\n\".join(code.split(\"\\n\")[:-2] + [\"    pass\"])  # replace with a pass statement.\n\n    assert code_pass.strip() == out.strip()\n\n\ndef test_basic_extract_external_interface():\n    code = \"\"\"\n@view\n@external\ndef allowance(_owner: address, _spender: address) -> (uint256, uint256):\n    return 1, 2\n\n@external\ndef test(_owner: address):\n    pass\n\n@view\n@internal\ndef _prive(_owner: address, _spender: address) -> (uint256, uint256):\n    return 1, 2\n    \"\"\"\n\n    interface = \"\"\"\n# External Interfaces\ninterface One:\n    def allowance(_owner: address, _spender: address) -> (uint256, uint256): view\n    def test(_owner: address): nonpayable\n    \"\"\"\n\n    out = compile_codes({\"one.vy\": code}, [\"external_interface\"])[\"one.vy\"]\n    out = out[\"external_interface\"]\n\n    assert interface.strip() == out.strip()\n\n\ndef test_basic_interface_implements(assert_compile_failed):\n    code = \"\"\"\nfrom vyper.interfaces import ERC20\n\nimplements: ERC20\n\n\n@external\ndef test() -> bool:\n    return True\n    \"\"\"\n\n    assert_compile_failed(lambda: compile_code(code), InterfaceViolation)\n\n\ndef test_builtin_interfaces_parse():\n    assert len(extract_sigs({\"type\": \"vyper\", \"code\": ERC20.interface_code})) == 6\n    assert len(extract_sigs({\"type\": \"vyper\", \"code\": ERC721.interface_code})) == 9\n\n\ndef test_extract_sigs_ignores_imports():\n    interface_code = \"\"\"\n{}\n\n@external\ndef foo() -> uint256:\n    pass\n    \"\"\"\n\n    base = extract_sigs({\"type\": \"vyper\", \"code\": interface_code.format(\"\")})\n\n    for stmt in (\"import x as x\", \"from x import y\"):\n        sigs = extract_sigs({\"type\": \"vyper\", \"code\": interface_code.format(stmt)})\n        assert [type(i) for i in base] == [type(i) for i in sigs]\n\n\ndef test_external_interface_parsing(assert_compile_failed):\n    interface_code = \"\"\"\n@external\ndef foo() -> uint256:\n    pass\n\n@external\ndef bar() -> uint256:\n    pass\n    \"\"\"\n\n    interface_codes = {\"FooBarInterface\": {\"type\": \"vyper\", \"code\": interface_code}}\n\n    code = \"\"\"\nimport a as FooBarInterface\n\nimplements: FooBarInterface\n\n@external\ndef foo() -> uint256:\n    return 1\n\n@external\ndef bar() -> uint256:\n    return 2\n    \"\"\"\n\n    assert compile_code(code, interface_codes=interface_codes)\n\n    not_implemented_code = \"\"\"\nimport a as FooBarInterface\n\nimplements: FooBarInterface\n\n@external\ndef foo() -> uint256:\n    return 1\n\n    \"\"\"\n\n    assert_compile_failed(\n        lambda: compile_code(not_implemented_code, interface_codes=interface_codes),\n        InterfaceViolation,\n    )\n\n\ndef test_missing_event(assert_compile_failed):\n    interface_code = \"\"\"\nevent Foo:\n    a: uint256\n    \"\"\"\n\n    interface_codes = {\"FooBarInterface\": {\"type\": \"vyper\", \"code\": interface_code}}\n\n    not_implemented_code = \"\"\"\nimport a as FooBarInterface\n\nimplements: FooBarInterface\n\n@external\ndef bar() -> uint256:\n    return 1\n    \"\"\"\n\n    assert_compile_failed(\n        lambda: compile_code(not_implemented_code, interface_codes=interface_codes),\n        InterfaceViolation,\n    )\n\n\ndef test_malformed_event(assert_compile_failed):\n    interface_code = \"\"\"\nevent Foo:\n    a: uint256\n    \"\"\"\n\n    interface_codes = {\"FooBarInterface\": {\"type\": \"vyper\", \"code\": interface_code}}\n\n    not_implemented_code = \"\"\"\nimport a as FooBarInterface\n\nimplements: FooBarInterface\n\nevent Foo:\n    a: int128\n\n@external\ndef bar() -> uint256:\n    return 1\n    \"\"\"\n\n    assert_compile_failed(\n        lambda: compile_code(not_implemented_code, interface_codes=interface_codes),\n        InterfaceViolation,\n    )\n\n\nVALID_IMPORT_CODE = [\n    # import statement, import path without suffix\n    (\"import a as Foo\", \"a\"),\n    (\"import b.a as Foo\", \"b/a\"),\n    (\"import Foo as Foo\", \"Foo\"),\n    (\"from a import Foo\", \"a/Foo\"),\n    (\"from b.a import Foo\", \"b/a/Foo\"),\n    (\"from .a import Foo\", \"./a/Foo\"),\n    (\"from ..a import Foo\", \"../a/Foo\"),\n]\n\n\n@pytest.mark.parametrize(\"code\", VALID_IMPORT_CODE)\ndef test_extract_file_interface_imports(code):\n\n    assert extract_file_interface_imports(code[0]) == {\"Foo\": code[1]}\n\n\nBAD_IMPORT_CODE = [\n    \"import a\",  # must alias absolute imports\n    \"import a as A\\nimport a as A\",  # namespace collisions\n    \"from b import a\\nfrom a import a\",\n    \"from . import a\\nimport a as a\",\n    \"import a as a\\nfrom . import a\",\n]\n\n\n@pytest.mark.parametrize(\"code\", BAD_IMPORT_CODE)\ndef test_extract_file_interface_imports_raises(code, assert_compile_failed):\n    assert_compile_failed(lambda: extract_file_interface_imports(code), StructureException)\n\n\ndef test_external_call_to_interface(w3, get_contract):\n    token_code = \"\"\"\nbalanceOf: public(HashMap[address, uint256])\n\n@external\ndef transfer(to: address, _value: uint256):\n    self.balanceOf[to] += _value\n    \"\"\"\n\n    code = \"\"\"\nimport one as TokenCode\n\ninterface EPI:\n    def test() -> uint256: view\n\n\ntoken_address: TokenCode\n\n\n@external\ndef __init__(_token_address: address):\n    self.token_address = TokenCode(_token_address)\n\n\n@external\ndef test():\n    self.token_address.transfer(msg.sender, 1000)\n    \"\"\"\n\n    erc20 = get_contract(token_code)\n    test_c = get_contract(\n        code, *[erc20.address], interface_codes={\"TokenCode\": {\"type\": \"vyper\", \"code\": token_code}}\n    )\n\n    sender = w3.eth.accounts[0]\n    assert erc20.balanceOf(sender) == 0\n\n    test_c.test(transact={})\n    assert erc20.balanceOf(sender) == 1000\n\n\ndef test_external_call_to_builtin_interface(w3, get_contract):\n    token_code = \"\"\"\nbalanceOf: public(HashMap[address, uint256])\n\n@external\ndef transfer(to: address, _value: uint256) -> bool:\n    self.balanceOf[to] += _value\n    return True\n    \"\"\"\n\n    code = \"\"\"\nfrom vyper.interfaces import ERC20\n\n\ntoken_address: ERC20\n\n\n@external\ndef __init__(_token_address: address):\n    self.token_address = ERC20(_token_address)\n\n\n@external\ndef test():\n    self.token_address.transfer(msg.sender, 1000)\n    \"\"\"\n\n    erc20 = get_contract(token_code)\n    test_c = get_contract(\n        code, *[erc20.address], interface_codes={\"TokenCode\": {\"type\": \"vyper\", \"code\": token_code}}\n    )\n\n    sender = w3.eth.accounts[0]\n    assert erc20.balanceOf(sender) == 0\n\n    test_c.test(transact={})\n    assert erc20.balanceOf(sender) == 1000\n\n\ndef test_units_interface(w3, get_contract):\n    code = \"\"\"\nimport balanceof as BalanceOf\n\nimplements: BalanceOf\n\n@external\n@view\ndef balanceOf(owner: address) -> uint256:\n    return as_wei_value(1, \"ether\")\n    \"\"\"\n    interface_code = \"\"\"\n@external\n@view\ndef balanceOf(owner: address) -> uint256:\n    pass\n    \"\"\"\n    interface_codes = {\"BalanceOf\": {\"type\": \"vyper\", \"code\": interface_code}}\n    c = get_contract(code, interface_codes=interface_codes)\n\n    assert c.balanceOf(w3.eth.accounts[0]) == w3.toWei(1, \"ether\")\n\n\ndef test_local_and_global_interface_namespaces():\n    interface_code = \"\"\"\n@external\ndef foo() -> uint256:\n    pass\n    \"\"\"\n\n    global_interface_codes = {\n        \"FooInterface\": {\"type\": \"vyper\", \"code\": interface_code},\n        \"BarInterface\": {\"type\": \"vyper\", \"code\": interface_code},\n    }\n    local_interface_codes = {\n        \"FooContract\": {\"FooInterface\": {\"type\": \"vyper\", \"code\": interface_code}},\n        \"BarContract\": {\"BarInterface\": {\"type\": \"vyper\", \"code\": interface_code}},\n    }\n\n    code = \"\"\"\nimport a as {0}\n\nimplements: {0}\n\n@external\ndef foo() -> uint256:\n    return 1\n    \"\"\"\n\n    codes = {\"FooContract\": code.format(\"FooInterface\"), \"BarContract\": code.format(\"BarInterface\")}\n\n    global_compiled = compile_codes(codes, interface_codes=global_interface_codes)\n    local_compiled = compile_codes(codes, interface_codes=local_interface_codes)\n    assert global_compiled == local_compiled\n\n\ndef test_self_interface_is_allowed(get_contract):\n    code = \"\"\"\ninterface Bar:\n    def foo() -> uint256: view\n\n@external\ndef foo() -> uint256 :\n    return 42\n\n@external\ndef bar() -> uint256:\n    return Bar(self).foo()\n\"\"\"\n    c = get_contract(code)\n    assert c.bar() == 42\n\n\ndef test_self_interface_via_storage(get_contract):\n    code = \"\"\"\ninterface Bar:\n    def foo() -> uint256: view\n\nbar_contract: Bar\n\n@external\ndef __init__():\n    self.bar_contract = Bar(self)\n\n@external\ndef foo() -> uint256 :\n    return 42\n\n@external\ndef bar() -> uint256:\n    return self.bar_contract.foo()\n    \"\"\"\n    c = get_contract(code)\n    assert c.bar() == 42\n\n\ndef test_self_interface_via_calldata(get_contract):\n    code = \"\"\"\ninterface Bar:\n    def foo() -> uint256: view\n\n@external\ndef foo() -> uint256 :\n    return 42\n\n@external\ndef bar(a: address) -> uint256:\n    return Bar(a).foo()\n    \"\"\"\n    c = get_contract(code)\n    assert c.bar(c.address) == 42\n\n\ntype_str_params = [\n    (\"int128\", -33),\n    (\"uint256\", 42),\n    (\"bool\", True),\n    (\"address\", \"0x1234567890123456789012345678901234567890\"),\n    (\"bytes32\", b\"bytes32bytes32bytes32bytes32poop\"),\n    (\"decimal\", Decimal(\"3.1337\")),\n    (\"Bytes[4]\", b\"newp\"),\n    (\"String[6]\", \"potato\"),\n]\n\ninterface_test_code = \"\"\"\n@external\n@view\ndef test_json(a: {0}) -> {0}:\n    return a\n    \"\"\"\n\n\ndef convert_v1_abi(abi):\n    new_abi = []\n    for func_abi in abi:\n        if \"stateMutability\" in func_abi:\n            mutability = func_abi[\"stateMutability\"]\n            del func_abi[\"stateMutability\"]\n            if mutability == \"payable\":\n                func_abi[\"constant\"] = False\n                func_abi[\"payable\"] = True\n            elif mutability == \"view\":\n                func_abi[\"constant\"] = True\n                func_abi[\"payable\"] = False\n            elif mutability == \"pure\":\n                # NOTE: pure \"changes\" to \"view\"\n                func_abi[\"constant\"] = True\n                func_abi[\"payable\"] = False\n            else:  # \"nonpayable\"\n                func_abi[\"constant\"] = False\n                func_abi[\"payable\"] = False\n        else:  # Assume \"nonpayable\" by default\n            func_abi[\"constant\"] = False\n            func_abi[\"payable\"] = False\n        new_abi.append(func_abi)\n    return new_abi\n\n\n@pytest.mark.parametrize(\"type_str\", [i[0] for i in type_str_params])\ndef test_json_interface_implements(type_str):\n    code = interface_test_code.format(type_str)\n\n    abi = compile_code(code, [\"abi\"])[\"abi\"]\n    code = f\"import jsonabi as jsonabi\\nimplements: jsonabi\\n{code}\"\n    compile_code(code, interface_codes={\"jsonabi\": {\"type\": \"json\", \"code\": abi}})\n    compile_code(code, interface_codes={\"jsonabi\": {\"type\": \"json\", \"code\": convert_v1_abi(abi)}})\n\n\n@pytest.mark.parametrize(\"type_str,value\", type_str_params)\ndef test_json_interface_calls(get_contract, type_str, value):\n    code = interface_test_code.format(type_str)\n\n    abi = compile_code(code, [\"abi\"])[\"abi\"]\n    c1 = get_contract(code)\n\n    code = f\"\"\"\nimport jsonabi as jsonabi\n\n@external\n@view\ndef test_call(a: address, b: {type_str}) -> {type_str}:\n    return jsonabi(a).test_json(b)\n    \"\"\"\n    c2 = get_contract(code, interface_codes={\"jsonabi\": {\"type\": \"json\", \"code\": abi}})\n    assert c2.test_call(c1.address, value) == value\n    c3 = get_contract(\n        code, interface_codes={\"jsonabi\": {\"type\": \"json\", \"code\": convert_v1_abi(abi)}}\n    )\n    assert c3.test_call(c1.address, value) == value\n", "from vyper import ast as vy_ast\nfrom vyper.address_space import CALLDATA, DATA, IMMUTABLES, MEMORY, STORAGE\nfrom vyper.codegen.ir_node import Encoding, IRnode\nfrom vyper.codegen.types import (\n    DYNAMIC_ARRAY_OVERHEAD,\n    ArrayLike,\n    BaseType,\n    ByteArrayLike,\n    DArrayType,\n    MappingType,\n    SArrayType,\n    StructType,\n    TupleLike,\n    TupleType,\n    ceil32,\n    is_bytes_m_type,\n    is_decimal_type,\n    is_integer_type,\n)\nfrom vyper.evm.opcodes import version_check\nfrom vyper.exceptions import CompilerPanic, StructureException, TypeCheckFailure, TypeMismatch\nfrom vyper.utils import GAS_CALLDATACOPY_WORD, GAS_CODECOPY_WORD, GAS_IDENTITY, GAS_IDENTITYWORD\n\n\n# propagate revert message when calls to external contracts fail\ndef check_external_call(call_ir):\n    copy_revertdata = [\"returndatacopy\", 0, 0, \"returndatasize\"]\n    revert = [\"revert\", 0, \"returndatasize\"]\n\n    propagate_revert_ir = [\"seq\", copy_revertdata, revert]\n    return [\"if\", [\"iszero\", call_ir], propagate_revert_ir]\n\n\n# cost per byte of the identity precompile\ndef _identity_gas_bound(num_bytes):\n    return GAS_IDENTITY + GAS_IDENTITYWORD * (ceil32(num_bytes) // 32)\n\n\ndef _calldatacopy_gas_bound(num_bytes):\n    return GAS_CALLDATACOPY_WORD * ceil32(num_bytes) // 32\n\n\ndef _codecopy_gas_bound(num_bytes):\n    return GAS_CODECOPY_WORD * ceil32(num_bytes) // 32\n\n\n# Copy byte array word-for-word (including layout)\ndef make_byte_array_copier(dst, src):\n    assert isinstance(src.typ, ByteArrayLike)\n    assert isinstance(dst.typ, ByteArrayLike)\n\n    if src.typ.maxlen > dst.typ.maxlen:\n        raise TypeMismatch(f\"Cannot cast from {src.typ} to {dst.typ}\")\n    # stricter check for zeroing a byte array.\n    if src.value == \"~empty\" and src.typ.maxlen != dst.typ.maxlen:\n        raise TypeMismatch(\n            f\"Bad type for clearing bytes: expected {dst.typ} but got {src.typ}\"\n        )  # pragma: notest\n\n    if src.value == \"~empty\":\n        # set length word to 0.\n        return STORE(dst, 0)\n\n    with src.cache_when_complex(\"src\") as (b1, src):\n        with get_bytearray_length(src).cache_when_complex(\"len\") as (b2, len_):\n\n            max_bytes = src.typ.maxlen\n\n            ret = [\"seq\"]\n            # store length\n            ret.append(STORE(dst, len_))\n\n            dst = bytes_data_ptr(dst)\n            src = bytes_data_ptr(src)\n\n            ret.append(copy_bytes(dst, src, len_, max_bytes))\n            return b1.resolve(b2.resolve(ret))\n\n\ndef bytes_data_ptr(ptr):\n    if ptr.location is None:\n        raise CompilerPanic(\"tried to modify non-pointer type\")\n    assert isinstance(ptr.typ, ByteArrayLike)\n    return add_ofst(ptr, ptr.location.word_scale)\n\n\ndef dynarray_data_ptr(ptr):\n    if ptr.location is None:\n        raise CompilerPanic(\"tried to modify non-pointer type\")\n    assert isinstance(ptr.typ, DArrayType)\n    return add_ofst(ptr, ptr.location.word_scale)\n\n\ndef _dynarray_make_setter(dst, src):\n    assert isinstance(src.typ, DArrayType)\n    assert isinstance(dst.typ, DArrayType)\n\n    if src.value == \"~empty\":\n        return IRnode.from_list(STORE(dst, 0))\n\n    if src.value == \"multi\":\n        ret = [\"seq\"]\n        # handle literals\n\n        # write the length word\n        store_length = STORE(dst, len(src.args))\n        ann = None\n        if src.annotation is not None:\n            ann = f\"len({src.annotation})\"\n        store_length = IRnode.from_list(store_length, annotation=ann)\n        ret.append(store_length)\n\n        n_items = len(src.args)\n        for i in range(n_items):\n            k = IRnode.from_list(i, typ=\"uint256\")\n            dst_i = get_element_ptr(dst, k, array_bounds_check=False)\n            src_i = get_element_ptr(src, k, array_bounds_check=False)\n            ret.append(make_setter(dst_i, src_i))\n\n        return ret\n\n    with src.cache_when_complex(\"darray_src\") as (b1, src):\n\n        # for ABI-encoded dynamic data, we must loop to unpack, since\n        # the layout does not match our memory layout\n        should_loop = (\n            src.encoding in (Encoding.ABI, Encoding.JSON_ABI)\n            and src.typ.subtype.abi_type.is_dynamic()\n        )\n\n        # if the subtype is dynamic, there might be a lot of\n        # unused space inside of each element. for instance\n        # DynArray[DynArray[uint256, 100], 5] where all the child\n        # arrays are empty - for this case, we recursively call\n        # into make_setter instead of straight bytes copy\n        # TODO we can make this heuristic more precise, e.g.\n        # loop when subtype.is_dynamic AND location == storage\n        # OR array_size <= /bound where loop is cheaper than memcpy/\n        should_loop |= src.typ.subtype.abi_type.is_dynamic()\n        should_loop |= needs_clamp(src.typ.subtype, src.encoding)\n\n        with get_dyn_array_count(src).cache_when_complex(\"darray_count\") as (b2, count):\n            ret = [\"seq\"]\n\n            ret.append(STORE(dst, count))\n\n            if should_loop:\n                i = IRnode.from_list(_freshname(\"copy_darray_ix\"), typ=\"uint256\")\n\n                loop_body = make_setter(\n                    get_element_ptr(dst, i, array_bounds_check=False),\n                    get_element_ptr(src, i, array_bounds_check=False),\n                )\n                loop_body.annotation = f\"{dst}[i] = {src}[i]\"\n\n                ret.append([\"repeat\", i, 0, count, src.typ.count, loop_body])\n\n            else:\n                element_size = src.typ.subtype.memory_bytes_required\n                # number of elements * size of element in bytes\n                n_bytes = _mul(count, element_size)\n                max_bytes = src.typ.count * element_size\n\n                src_ = dynarray_data_ptr(src)\n                dst_ = dynarray_data_ptr(dst)\n                ret.append(copy_bytes(dst_, src_, n_bytes, max_bytes))\n\n            return b1.resolve(b2.resolve(ret))\n\n\n# Copy bytes\n# Accepts 4 arguments:\n# (i) an IR node for the start position of the source\n# (ii) an IR node for the start position of the destination\n# (iii) an IR node for the length (in bytes)\n# (iv) a constant for the max length (in bytes)\n# NOTE: may pad to ceil32 of `length`! If you ask to copy 1 byte, it may\n# copy an entire (32-byte) word, depending on the copy routine chosen.\n# TODO maybe always pad to ceil32, to reduce dirty bytes bugs\ndef copy_bytes(dst, src, length, length_bound):\n    annotation = f\"copy_bytes from {src} to {dst}\"\n\n    src = IRnode.from_list(src)\n    dst = IRnode.from_list(dst)\n    length = IRnode.from_list(length)\n\n    with src.cache_when_complex(\"src\") as (b1, src), length.cache_when_complex(\n        \"copy_bytes_count\"\n    ) as (b2, length), dst.cache_when_complex(\"dst\") as (b3, dst):\n\n        # fast code for common case where num bytes is small\n        # TODO expand this for more cases where num words is less than ~8\n        if length_bound <= 32:\n            copy_op = STORE(dst, LOAD(src))\n            ret = IRnode.from_list(copy_op, annotation=annotation)\n            return b1.resolve(b2.resolve(b3.resolve(ret)))\n\n        if dst.location == MEMORY and src.location in (MEMORY, CALLDATA, DATA):\n            # special cases: batch copy to memory\n            # TODO: iloadbytes\n            if src.location == MEMORY:\n                copy_op = [\"staticcall\", \"gas\", 4, src, length, dst, length]\n                gas_bound = _identity_gas_bound(length_bound)\n            elif src.location == CALLDATA:\n                copy_op = [\"calldatacopy\", dst, src, length]\n                gas_bound = _calldatacopy_gas_bound(length_bound)\n            elif src.location == DATA:\n                copy_op = [\"dloadbytes\", dst, src, length]\n                # note: dloadbytes compiles to CODECOPY\n                gas_bound = _codecopy_gas_bound(length_bound)\n\n            ret = IRnode.from_list(copy_op, annotation=annotation, add_gas_estimate=gas_bound)\n            return b1.resolve(b2.resolve(b3.resolve(ret)))\n\n        if dst.location == IMMUTABLES and src.location in (MEMORY, DATA):\n            # TODO istorebytes-from-mem, istorebytes-from-calldata(?)\n            # compile to identity, CODECOPY respectively.\n            pass\n\n        # general case, copy word-for-word\n        # pseudocode for our approach (memory-storage as example):\n        # for i in range(len, bound=MAX_LEN):\n        #   sstore(_dst + i, mload(src + i * 32))\n        i = IRnode.from_list(_freshname(\"copy_bytes_ix\"), typ=\"uint256\")\n\n        n = [\"div\", [\"ceil32\", length], 32]\n        n_bound = ceil32(length_bound) // 32\n\n        dst_i = add_ofst(dst, _mul(i, dst.location.word_scale))\n        src_i = add_ofst(src, _mul(i, src.location.word_scale))\n\n        copy_one_word = STORE(dst_i, LOAD(src_i))\n\n        main_loop = [\"repeat\", i, 0, n, n_bound, copy_one_word]\n\n        return b1.resolve(\n            b2.resolve(b3.resolve(IRnode.from_list(main_loop, annotation=annotation)))\n        )\n\n\n# get the number of bytes at runtime\ndef get_bytearray_length(arg):\n    typ = BaseType(\"uint256\")\n    return IRnode.from_list(LOAD(arg), typ=typ)\n\n\n# get the number of elements at runtime\ndef get_dyn_array_count(arg):\n    assert isinstance(arg.typ, DArrayType)\n\n    typ = BaseType(\"uint256\")\n\n    if arg.value == \"multi\":\n        return IRnode.from_list(len(arg.args), typ=typ)\n\n    if arg.value == \"~empty\":\n        # empty(DynArray[])\n        return IRnode.from_list(0, typ=typ)\n\n    return IRnode.from_list(LOAD(arg), typ=typ)\n\n\ndef append_dyn_array(darray_node, elem_node):\n    assert isinstance(darray_node.typ, DArrayType)\n\n    assert darray_node.typ.count > 0, \"jerk boy u r out\"\n\n    ret = [\"seq\"]\n    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):\n        len_ = get_dyn_array_count(darray_node)\n        with len_.cache_when_complex(\"old_darray_len\") as (b2, len_):\n            ret.append([\"assert\", [\"le\", len_, darray_node.typ.count - 1]])\n            ret.append(STORE(darray_node, [\"add\", len_, 1]))\n            # NOTE: typechecks elem_node\n            # NOTE skip array bounds check bc we already asserted len two lines up\n            ret.append(\n                make_setter(get_element_ptr(darray_node, len_, array_bounds_check=False), elem_node)\n            )\n            return IRnode.from_list(b1.resolve(b2.resolve(ret)))\n\n\ndef pop_dyn_array(darray_node, return_popped_item):\n    assert isinstance(darray_node.typ, DArrayType)\n    ret = [\"seq\"]\n    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):\n        old_len = [\"clamp_nonzero\", get_dyn_array_count(darray_node)]\n        new_len = IRnode.from_list([\"sub\", old_len, 1], typ=\"uint256\")\n\n        with new_len.cache_when_complex(\"new_len\") as (b2, new_len):\n            ret.append(STORE(darray_node, new_len))\n\n            # NOTE skip array bounds check bc we already asserted len two lines up\n            if return_popped_item:\n                popped_item = get_element_ptr(darray_node, new_len, array_bounds_check=False)\n                ret.append(popped_item)\n                typ = popped_item.typ\n                location = popped_item.location\n                encoding = popped_item.encoding\n            else:\n                typ, location, encoding = None, None, None\n            return IRnode.from_list(\n                b1.resolve(b2.resolve(ret)), typ=typ, location=location, encoding=encoding\n            )\n\n\ndef getpos(node):\n    return (\n        node.lineno,\n        node.col_offset,\n        getattr(node, \"end_lineno\", None),\n        getattr(node, \"end_col_offset\", None),\n    )\n\n\n# add an offset to a pointer, keeping location and encoding info\ndef add_ofst(ptr, ofst):\n    ret = [\"add\", ptr, ofst]\n    return IRnode.from_list(ret, location=ptr.location, encoding=ptr.encoding)\n\n\n# shorthand util\ndef _mul(x, y):\n    ret = [\"mul\", x, y]\n    return IRnode.from_list(ret)\n\n\n# Resolve pointer locations for ABI-encoded data\ndef _getelemptr_abi_helper(parent, member_t, ofst, clamp=True):\n    member_abi_t = member_t.abi_type\n\n    # ABI encoding has length word and then pretends length is not there\n    # e.g. [[1,2]] is encoded as 0x01 <len> 0x20 <inner array ofst> <encode(inner array)>\n    # note that inner array ofst is 0x20, not 0x40.\n    if has_length_word(parent.typ):\n        parent = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)\n\n    ofst_ir = add_ofst(parent, ofst)\n\n    if member_abi_t.is_dynamic():\n        # double dereference, according to ABI spec\n        # TODO optimize special case: first dynamic item\n        # offset is statically known.\n        ofst_ir = add_ofst(parent, unwrap_location(ofst_ir))\n\n    return IRnode.from_list(\n        ofst_ir,\n        typ=member_t,\n        location=parent.location,\n        encoding=parent.encoding,\n        annotation=f\"{parent}{ofst}\",\n    )\n\n\n# TODO simplify this code, especially the ABI decoding\ndef _get_element_ptr_tuplelike(parent, key):\n    typ = parent.typ\n    assert isinstance(typ, TupleLike)\n\n    if isinstance(typ, StructType):\n        assert isinstance(key, str)\n        subtype = typ.members[key]\n        attrs = list(typ.tuple_keys())\n        index = attrs.index(key)\n        annotation = key\n    else:\n        assert isinstance(key, int)\n        subtype = typ.members[key]\n        attrs = list(range(len(typ.members)))\n        index = key\n        annotation = None\n\n    # generated by empty() + make_setter\n    if parent.value == \"~empty\":\n        return IRnode.from_list(\"~empty\", typ=subtype)\n\n    if parent.value == \"multi\":\n        assert parent.encoding != Encoding.ABI, \"no abi-encoded literals\"\n        return parent.args[index]\n\n    ofst = 0  # offset from parent start\n\n    if parent.encoding in (Encoding.ABI, Encoding.JSON_ABI):\n        if parent.location == STORAGE:\n            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest\n\n        member_t = typ.members[attrs[index]]\n\n        for i in range(index):\n            member_abi_t = typ.members[attrs[i]].abi_type\n            ofst += member_abi_t.embedded_static_size()\n\n        return _getelemptr_abi_helper(parent, member_t, ofst)\n\n    if parent.location.word_addressable:\n        for i in range(index):\n            ofst += typ.members[attrs[i]].storage_size_in_words\n    elif parent.location.byte_addressable:\n        for i in range(index):\n            ofst += typ.members[attrs[i]].memory_bytes_required\n    else:\n        raise CompilerPanic(f\"bad location {parent.location}\")  # pragma: notest\n\n    return IRnode.from_list(\n        add_ofst(parent, ofst),\n        typ=subtype,\n        location=parent.location,\n        encoding=parent.encoding,\n        annotation=annotation,\n    )\n\n\ndef has_length_word(typ):\n    return isinstance(typ, (DArrayType, ByteArrayLike))\n\n\n# TODO simplify this code, especially the ABI decoding\ndef _get_element_ptr_array(parent, key, array_bounds_check):\n\n    assert isinstance(parent.typ, ArrayLike)\n\n    if not is_integer_type(key.typ):\n        raise TypeCheckFailure(f\"{key.typ} used as array index\")\n\n    subtype = parent.typ.subtype\n\n    if parent.value == \"~empty\":\n        if array_bounds_check:\n            # this case was previously missing a bounds check. codegen\n            # is a bit complicated when bounds check is required, so\n            # block it. there is no reason to index into a literal empty\n            # array anyways!\n            raise TypeCheckFailure(\"indexing into zero array not allowed\")\n        return IRnode.from_list(\"~empty\", subtype)\n\n    if parent.value == \"multi\":\n        assert isinstance(key.value, int)\n        return parent.args[key.value]\n\n    ix = unwrap_location(key)\n\n    if array_bounds_check:\n        # clamplt works, even for signed ints. since two's-complement\n        # is used, if the index is negative, (unsigned) LT will interpret\n        # it as a very large number, larger than any practical value for\n        # an array index, and the clamp will throw an error.\n        clamp_op = \"uclamplt\"\n        is_darray = isinstance(parent.typ, DArrayType)\n        bound = get_dyn_array_count(parent) if is_darray else parent.typ.count\n        # NOTE: there are optimization rules for this when ix or bound is literal\n        ix = IRnode.from_list([clamp_op, ix, bound], typ=ix.typ)\n\n    if parent.encoding in (Encoding.ABI, Encoding.JSON_ABI):\n        if parent.location == STORAGE:\n            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest\n\n        member_abi_t = subtype.abi_type\n\n        ofst = _mul(ix, member_abi_t.embedded_static_size())\n\n        return _getelemptr_abi_helper(parent, subtype, ofst)\n\n    if parent.location.word_addressable:\n        element_size = subtype.storage_size_in_words\n    elif parent.location.byte_addressable:\n        element_size = subtype.memory_bytes_required\n    else:\n        raise CompilerPanic(\"unreachable\")  # pragma: notest\n\n    ofst = _mul(ix, element_size)\n\n    if has_length_word(parent.typ):\n        data_ptr = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)\n    else:\n        data_ptr = parent\n\n    return IRnode.from_list(add_ofst(data_ptr, ofst), typ=subtype, location=parent.location)\n\n\ndef _get_element_ptr_mapping(parent, key):\n    assert isinstance(parent.typ, MappingType)\n    subtype = parent.typ.valuetype\n    key = unwrap_location(key)\n\n    # TODO when is key None?\n    if key is None or parent.location != STORAGE:\n        raise TypeCheckFailure(\"bad dereference on mapping {parent}[{sub}]\")\n\n    return IRnode.from_list([\"sha3_64\", parent, key], typ=subtype, location=STORAGE)\n\n\n# Take a value representing a memory or storage location, and descend down to\n# an element or member variable\n# This is analogous (but not necessarily equivalent to) getelementptr in LLVM.\ndef get_element_ptr(parent, key, array_bounds_check=True):\n    with parent.cache_when_complex(\"val\") as (b, parent):\n        typ = parent.typ\n\n        if isinstance(typ, TupleLike):\n            ret = _get_element_ptr_tuplelike(parent, key)\n\n        elif isinstance(typ, MappingType):\n            ret = _get_element_ptr_mapping(parent, key)\n\n        elif isinstance(typ, ArrayLike):\n            ret = _get_element_ptr_array(parent, key, array_bounds_check)\n\n        else:\n            raise CompilerPanic(f\"get_element_ptr cannot be called on {typ}\")  # pragma: notest\n\n        return b.resolve(ret)\n\n\ndef LOAD(ptr: IRnode) -> IRnode:\n    if ptr.location is None:\n        raise CompilerPanic(\"cannot dereference non-pointer type\")\n    op = ptr.location.load_op\n    if op is None:\n        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest\n    return IRnode.from_list([op, ptr])\n\n\ndef STORE(ptr: IRnode, val: IRnode) -> IRnode:\n    if ptr.location is None:\n        raise CompilerPanic(\"cannot dereference non-pointer type\")\n    op = ptr.location.store_op\n    if op is None:\n        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest\n    return IRnode.from_list([op, ptr, val])\n\n\n# Unwrap location\ndef unwrap_location(orig):\n    if orig.location is not None:\n        return IRnode.from_list(LOAD(orig), typ=orig.typ)\n    else:\n        # CMC 2022-03-24 TODO refactor so this branch can be removed\n        if orig.value == \"~empty\":\n            return IRnode.from_list(0, typ=orig.typ)\n        return orig\n\n\n# utility function, constructs an IR tuple out of a list of IR nodes\ndef ir_tuple_from_args(args):\n    typ = TupleType([x.typ for x in args])\n    return IRnode.from_list([\"multi\"] + [x for x in args], typ=typ)\n\n\ndef _needs_external_call_wrap(ir_typ):\n    # for calls to ABI conforming contracts.\n    # according to the ABI spec, return types are ALWAYS tuples even\n    # if only one element is being returned.\n    # https://solidity.readthedocs.io/en/latest/abi-spec.html#function-selector-and-argument-encoding\n    # \"and the return values v_1, ..., v_k of f are encoded as\n    #\n    #    enc((v_1, ..., v_k))\n    #    i.e. the values are combined into a tuple and encoded.\n    # \"\n    # therefore, wrap it in a tuple if it's not already a tuple.\n    # for example, `bytes` is returned as abi-encoded (bytes,)\n    # and `(bytes,)` is returned as abi-encoded ((bytes,),)\n    # In general `-> X` gets returned as (X,)\n    # including structs. MyStruct is returned as abi-encoded (MyStruct,).\n    # (Sorry this is so confusing. I didn't make these rules.)\n\n    return not (isinstance(ir_typ, TupleType) and len(ir_typ.members) > 1)\n\n\ndef calculate_type_for_external_return(ir_typ):\n    if _needs_external_call_wrap(ir_typ):\n        return TupleType([ir_typ])\n    return ir_typ\n\n\ndef wrap_value_for_external_return(ir_val):\n    # used for LHS promotion\n    if _needs_external_call_wrap(ir_val.typ):\n        return ir_tuple_from_args([ir_val])\n    else:\n        return ir_val\n\n\ndef set_type_for_external_return(ir_val):\n    # used for RHS promotion\n    ir_val.typ = calculate_type_for_external_return(ir_val.typ)\n\n\n# return a dummy IRnode with the given type\ndef dummy_node_for_type(typ):\n    return IRnode(\"fake_node\", typ=typ)\n\n\ndef _check_assign_bytes(left, right):\n    if right.typ.maxlen > left.typ.maxlen:\n        raise TypeMismatch(f\"Cannot cast from {right.typ} to {left.typ}\")  # pragma: notest\n    # stricter check for zeroing a byte array.\n    if right.value == \"~empty\" and right.typ.maxlen != left.typ.maxlen:\n        raise TypeMismatch(\n            f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"\n        )  # pragma: notest\n\n\ndef _check_assign_list(left, right):\n    def FAIL():  # pragma: nocover\n        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")\n\n    if left.value == \"multi\":\n        # Cannot do something like [a, b, c] = [1, 2, 3]\n        FAIL()  # pragma: notest\n\n    if isinstance(left, SArrayType):\n        if not isinstance(right, SArrayType):\n            FAIL()  # pragma: notest\n        if left.typ.count != right.typ.count:\n            FAIL()  # pragma: notest\n\n        # TODO recurse into left, right if literals?\n        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))\n\n    if isinstance(left, DArrayType):\n        if not isinstance(right, DArrayType):\n            FAIL()  # pragma: notest\n\n        if left.typ.count < right.typ.count:\n            FAIL()  # pragma: notest\n\n        # stricter check for zeroing\n        if right.value == \"~empty\" and right.typ.count != left.typ.count:\n            raise TypeCheckFailure(\n                f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"\n            )  # pragma: notest\n\n        # TODO recurse into left, right if literals?\n        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))\n\n\ndef _check_assign_tuple(left, right):\n    def FAIL():  # pragma: nocover\n        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")\n\n    if not isinstance(right.typ, left.typ.__class__):\n        FAIL()  # pragma: notest\n\n    if isinstance(left.typ, StructType):\n        for k in left.typ.members:\n            if k not in right.typ.members:\n                FAIL()  # pragma: notest\n            # TODO recurse into left, right if literals?\n            check_assign(\n                dummy_node_for_type(left.typ.members[k]),\n                dummy_node_for_type(right.typ.members[k]),\n            )\n\n        for k in right.typ.members:\n            if k not in left.typ.members:\n                FAIL()  # pragma: notest\n\n        if left.typ.name != right.typ.name:\n            FAIL()  # pragma: notest\n\n    else:\n        if len(left.typ.members) != len(right.typ.members):\n            FAIL()  # pragma: notest\n        for (l, r) in zip(left.typ.members, right.typ.members):\n            # TODO recurse into left, right if literals?\n            check_assign(dummy_node_for_type(l), dummy_node_for_type(r))\n\n\n# sanity check an assignment\n# typechecking source code is done at an earlier phase\n# this function is more of a sanity check for typechecking internally\n# generated assignments\ndef check_assign(left, right):\n    def FAIL():  # pragma: nocover\n        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ} {left} {right}\")\n\n    if isinstance(left.typ, ByteArrayLike):\n        _check_assign_bytes(left, right)\n    elif isinstance(left.typ, ArrayLike):\n        _check_assign_list(left, right)\n    elif isinstance(left.typ, TupleLike):\n        _check_assign_tuple(left, right)\n\n    elif isinstance(left.typ, BaseType):\n        # TODO once we propagate types from typechecker, introduce this check:\n        # if left.typ != right.typ:\n        #    FAIL()  # pragma: notest\n        pass\n\n    else:  # pragma: nocover\n        FAIL()\n\n\n_label = 0\n\n\n# TODO might want to coalesce with Context.fresh_varname and compile_ir.mksymbol\ndef _freshname(name):\n    global _label\n    _label += 1\n    return f\"{name}{_label}\"\n\n\n# returns True if t is ABI encoded and is a type that needs any kind of\n# validation\ndef needs_clamp(t, encoding):\n    if encoding not in (Encoding.ABI, Encoding.JSON_ABI):\n        return False\n    if isinstance(t, (ByteArrayLike, DArrayType)):\n        if encoding == Encoding.JSON_ABI:\n            # don't have bytestring size bound from json, don't clamp\n            return False\n        return True\n    if isinstance(t, BaseType) and t.typ not in (\"int256\", \"uint256\", \"bytes32\"):\n        return True\n    if isinstance(t, SArrayType):\n        return needs_clamp(t.subtype, encoding)\n    if isinstance(t, TupleLike):\n        return any(needs_clamp(m, encoding) for m in t.tuple_members())\n    return False\n\n\n# Create an x=y statement, where the types may be compound\ndef make_setter(left, right):\n    check_assign(left, right)\n\n    # Basic types\n    if isinstance(left.typ, BaseType):\n        enc = right.encoding  # unwrap_location butchers encoding\n        right = unwrap_location(right)\n        # TODO rethink/streamline the clamp_basetype logic\n        if needs_clamp(right.typ, enc):\n            right = clamp_basetype(right)\n\n        return STORE(left, right)\n\n    # Byte arrays\n    elif isinstance(left.typ, ByteArrayLike):\n        # TODO rethink/streamline the clamp_basetype logic\n        if needs_clamp(right.typ, right.encoding):\n            with right.cache_when_complex(\"bs_ptr\") as (b, right):\n                copier = make_byte_array_copier(left, right)\n                ret = b.resolve([\"seq\", clamp_bytestring(right), copier])\n        else:\n            ret = make_byte_array_copier(left, right)\n\n        return IRnode.from_list(ret)\n\n    elif isinstance(left.typ, DArrayType):\n        # TODO should we enable this?\n        # implicit conversion from sarray to darray\n        # if isinstance(right.typ, SArrayType):\n        #    return _complex_make_setter(left, right)\n\n        # TODO rethink/streamline the clamp_basetype logic\n        if needs_clamp(right.typ, right.encoding):\n            with right.cache_when_complex(\"arr_ptr\") as (b, right):\n                copier = _dynarray_make_setter(left, right)\n                ret = b.resolve([\"seq\", clamp_dyn_array(right), copier])\n        else:\n            ret = _dynarray_make_setter(left, right)\n\n        return IRnode.from_list(ret)\n\n    # Arrays\n    elif isinstance(left.typ, (SArrayType, TupleLike)):\n        return _complex_make_setter(left, right)\n\n\ndef _complex_make_setter(left, right):\n    if right.value == \"~empty\" and left.location == MEMORY:\n        # optimized memzero\n        return mzero(left, left.typ.memory_bytes_required)\n\n    ret = [\"seq\"]\n\n    if isinstance(left.typ, SArrayType):\n        n_items = right.typ.count\n        keys = [IRnode.from_list(i, typ=\"uint256\") for i in range(n_items)]\n\n    if isinstance(left.typ, TupleLike):\n        keys = left.typ.tuple_keys()\n\n    # if len(keyz) == 0:\n    #    return IRnode.from_list([\"pass\"])\n\n    # general case\n    # TODO use copy_bytes when the generated code is above a certain size\n    with left.cache_when_complex(\"_L\") as (b1, left), right.cache_when_complex(\"_R\") as (b2, right):\n\n        for k in keys:\n            l_i = get_element_ptr(left, k, array_bounds_check=False)\n            r_i = get_element_ptr(right, k, array_bounds_check=False)\n            ret.append(make_setter(l_i, r_i))\n\n        return b1.resolve(b2.resolve(IRnode.from_list(ret)))\n\n\ndef ensure_in_memory(ir_var, context):\n    \"\"\"Ensure a variable is in memory. This is useful for functions\n    which expect to operate on memory variables.\n    \"\"\"\n    if ir_var.location == MEMORY:\n        return ir_var\n\n    typ = ir_var.typ\n    buf = IRnode.from_list(context.new_internal_variable(typ), typ=typ, location=MEMORY)\n    do_copy = make_setter(buf, ir_var)\n\n    return IRnode.from_list([\"seq\", do_copy, buf], typ=typ, location=MEMORY)\n\n\ndef eval_seq(ir_node):\n    \"\"\"Tries to find the \"return\" value of a `seq` statement, in order so\n    that the value can be known without possibly evaluating side effects\n    \"\"\"\n    if ir_node.value in (\"seq\", \"with\") and len(ir_node.args) > 0:\n        return eval_seq(ir_node.args[-1])\n    if isinstance(ir_node.value, int):\n        return IRnode.from_list(ir_node)\n    return None\n\n\n# TODO move return checks to vyper/semantics/validation\ndef is_return_from_function(node):\n    if isinstance(node, vy_ast.Expr) and node.get(\"value.func.id\") == \"selfdestruct\":\n        return True\n    if isinstance(node, vy_ast.Return):\n        return True\n    elif isinstance(node, vy_ast.Raise):\n        return True\n    else:\n        return False\n\n\ndef check_single_exit(fn_node):\n    _check_return_body(fn_node, fn_node.body)\n    for node in fn_node.get_descendants(vy_ast.If):\n        _check_return_body(node, node.body)\n        if node.orelse:\n            _check_return_body(node, node.orelse)\n\n\ndef _check_return_body(node, node_list):\n    return_count = len([n for n in node_list if is_return_from_function(n)])\n    if return_count > 1:\n        raise StructureException(\n            \"Too too many exit statements (return, raise or selfdestruct).\", node\n        )\n    # Check for invalid code after returns.\n    last_node_pos = len(node_list) - 1\n    for idx, n in enumerate(node_list):\n        if is_return_from_function(n) and idx < last_node_pos:\n            # is not last statement in body.\n            raise StructureException(\n                \"Exit statement with succeeding code (that will not execute).\", node_list[idx + 1]\n            )\n\n\ndef mzero(dst, nbytes):\n    # calldatacopy from past-the-end gives zero bytes.\n    # cf. YP H.2 (ops section) with CALLDATACOPY spec.\n    return IRnode.from_list(\n        # calldatacopy mempos calldatapos len\n        [\"calldatacopy\", dst, \"calldatasize\", nbytes],\n        annotation=\"mzero\",\n    )\n\n\n# zero pad a bytearray according to the ABI spec. The last word\n# of the byte array needs to be right-padded with zeroes.\ndef zero_pad(bytez_placeholder):\n    len_ = [\"mload\", bytez_placeholder]\n    dst = [\"add\", [\"add\", bytez_placeholder, 32], \"len\"]\n    # the runtime length of the data rounded up to nearest 32\n    # from spec:\n    #   the actual value of X as a byte sequence,\n    #   followed by the *minimum* number of zero-bytes\n    #   such that len(enc(X)) is a multiple of 32.\n    num_zero_bytes = [\"sub\", [\"ceil32\", \"len\"], \"len\"]\n    return IRnode.from_list(\n        [\"with\", \"len\", len_, [\"with\", \"dst\", dst, mzero(\"dst\", num_zero_bytes)]],\n        annotation=\"Zero pad\",\n    )\n\n\n# convenience rewrites for shr/sar/shl\ndef shr(bits, x):\n    if version_check(begin=\"constantinople\"):\n        return [\"shr\", bits, x]\n    return [\"div\", x, [\"exp\", 2, bits]]\n\n\n# convenience rewrites for shr/sar/shl\ndef shl(bits, x):\n    if version_check(begin=\"constantinople\"):\n        return [\"shl\", bits, x]\n    return [\"mul\", x, [\"exp\", 2, bits]]\n\n\ndef sar(bits, x):\n    if version_check(begin=\"constantinople\"):\n        return [\"sar\", bits, x]\n\n    # emulate for older arches. keep in mind note from EIP 145:\n    # \"This is not equivalent to PUSH1 2 EXP SDIV, since it rounds\n    # differently. See SDIV(-1, 2) == 0, while SAR(-1, 1) == -1.\"\n    return [\"sdiv\", [\"add\", [\"slt\", x, 0], x], [\"exp\", 2, bits]]\n\n\ndef clamp_bytestring(ir_node):\n    t = ir_node.typ\n    if not isinstance(t, ByteArrayLike):\n        raise CompilerPanic(f\"{t} passed to clamp_bytestring\")  # pragma: notest\n    return [\"assert\", [\"le\", get_bytearray_length(ir_node), t.maxlen]]\n\n\ndef clamp_dyn_array(ir_node):\n    t = ir_node.typ\n    assert isinstance(t, DArrayType)\n    return [\"assert\", [\"le\", get_dyn_array_count(ir_node), t.count]]\n\n\n# clampers for basetype\ndef clamp_basetype(ir_node):\n    t = ir_node.typ\n    if not isinstance(t, BaseType):\n        raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest\n\n    # copy of the input\n    ir_node = unwrap_location(ir_node)\n\n    if is_integer_type(t) or is_decimal_type(t):\n        if t._num_info.bits == 256:\n            return ir_node\n        else:\n            return int_clamp(ir_node, t._num_info.bits, signed=t._num_info.is_signed)\n\n    if is_bytes_m_type(t):\n        if t._bytes_info.m == 32:\n            return ir_node  # special case, no clamp.\n        else:\n            return bytes_clamp(ir_node, t._bytes_info.m)\n\n    if t.typ in (\"address\",):\n        return int_clamp(ir_node, 160)\n    if t.typ in (\"bool\",):\n        return int_clamp(ir_node, 1)\n\n    raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest\n\n\ndef int_clamp(ir_node, bits, signed=False):\n    \"\"\"Generalized clamper for integer types. Takes the number of bits,\n    whether it's signed, and returns an IR node which checks it is\n    in bounds. (Consumers should use clamp_basetype instead which uses\n    type-based dispatch and is a little safer.)\n    \"\"\"\n    if bits >= 256:\n        raise CompilerPanic(f\"invalid clamp: {bits}>=256 ({ir_node})\")  # pragma: notest\n    with ir_node.cache_when_complex(\"val\") as (b, val):\n        if signed:\n            # example for bits==128:\n            # promote_signed_int(val, bits) is the \"canonical\" version of val\n            # if val is in bounds, the bits above bit 128 should be equal.\n            # (this works for both val >= 0 and val < 0. in the first case,\n            # all upper bits should be 0 if val is a valid int128,\n            # in the latter case, all upper bits should be 1.)\n            assertion = [\"assert\", [\"eq\", val, promote_signed_int(val, bits)]]\n        else:\n            assertion = [\"assert\", [\"iszero\", shr(bits, val)]]\n\n        ret = b.resolve([\"seq\", assertion, val])\n\n    # TODO fix this annotation\n    return IRnode.from_list(ret, annotation=f\"int_clamp {ir_node.typ}\")\n\n\ndef bytes_clamp(ir_node: IRnode, n_bytes: int) -> IRnode:\n    if not (0 < n_bytes <= 32):\n        raise CompilerPanic(f\"bad type: bytes{n_bytes}\")\n    with ir_node.cache_when_complex(\"val\") as (b, val):\n        assertion = [\"assert\", [\"iszero\", shl(n_bytes * 8, val)]]\n        ret = b.resolve([\"seq\", assertion, val])\n    return IRnode.from_list(ret, annotation=f\"bytes{n_bytes}_clamp\")\n\n\n# e.g. for int8, promote 255 to -1\ndef promote_signed_int(x, bits):\n    assert bits % 8 == 0\n    ret = [\"signextend\", bits // 8 - 1, x]\n    return IRnode.from_list(ret, annotation=f\"promote int{bits}\")\n", "import vyper.utils as util\nfrom vyper.address_space import MEMORY\nfrom vyper.codegen.abi_encoder import abi_encode\nfrom vyper.codegen.core import (\n    calculate_type_for_external_return,\n    check_assign,\n    check_external_call,\n    dummy_node_for_type,\n    get_element_ptr,\n)\nfrom vyper.codegen.ir_node import Encoding, IRnode\nfrom vyper.codegen.types import InterfaceType, TupleType, get_type_for_exact_size\nfrom vyper.exceptions import StateAccessViolation, TypeCheckFailure\n\n\ndef _pack_arguments(contract_sig, args, context):\n    # abi encoding just treats all args as a big tuple\n    args_tuple_t = TupleType([x.typ for x in args])\n    args_as_tuple = IRnode.from_list([\"multi\"] + [x for x in args], typ=args_tuple_t)\n    args_abi_t = args_tuple_t.abi_type\n\n    # sanity typecheck - make sure the arguments can be assigned\n    dst_tuple_t = TupleType([arg.typ for arg in contract_sig.args][: len(args)])\n    check_assign(dummy_node_for_type(dst_tuple_t), args_as_tuple)\n\n    if contract_sig.return_type is not None:\n        return_abi_t = calculate_type_for_external_return(contract_sig.return_type).abi_type\n\n        # we use the same buffer for args and returndata,\n        # so allocate enough space here for the returndata too.\n        buflen = max(args_abi_t.size_bound(), return_abi_t.size_bound())\n    else:\n        buflen = args_abi_t.size_bound()\n\n    buflen += 32  # padding for the method id\n\n    buf_t = get_type_for_exact_size(buflen)\n    buf = context.new_internal_variable(buf_t)\n\n    args_ofst = buf + 28\n    args_len = args_abi_t.size_bound() + 4\n\n    abi_signature = contract_sig.name + dst_tuple_t.abi_type.selector_name()\n\n    # layout:\n    # 32 bytes                 | args\n    # 0x..00<method_id_4bytes> | args\n    # the reason for the left padding is just so the alignment is easier.\n    # if we were only targeting constantinople, we could align\n    # to buf (and also keep code size small) by using\n    # (mstore buf (shl signature.method_id 224))\n    mstore_method_id = [[\"mstore\", buf, util.abi_method_id(abi_signature)]]\n\n    if len(args) == 0:\n        encode_args = [\"pass\"]\n    else:\n        encode_args = abi_encode(buf + 32, args_as_tuple, context, bufsz=buflen)\n\n    return buf, mstore_method_id + [encode_args], args_ofst, args_len\n\n\ndef _returndata_encoding(contract_sig):\n    if contract_sig.is_from_json:\n        return Encoding.JSON_ABI\n    return Encoding.ABI\n\n\ndef _unpack_returndata(buf, contract_sig, skip_contract_check, context):\n    return_t = contract_sig.return_type\n    if return_t is None:\n        return [\"pass\"], 0, 0\n\n    return_t = calculate_type_for_external_return(return_t)\n    # if the abi signature has a different type than\n    # the vyper type, we need to wrap and unwrap the type\n    # so that the ABI decoding works correctly\n    should_unwrap_abi_tuple = return_t != contract_sig.return_type\n\n    abi_return_t = return_t.abi_type\n\n    min_return_size = abi_return_t.min_size()\n    max_return_size = abi_return_t.size_bound()\n    assert 0 < min_return_size <= max_return_size\n\n    ret_ofst = buf\n    ret_len = max_return_size\n\n    # revert when returndatasize is not in bounds\n    ret = []\n    # runtime: min_return_size <= returndatasize\n    # TODO move the -1 optimization to IR optimizer\n    if not skip_contract_check:\n        ret += [[\"assert\", [\"gt\", \"returndatasize\", min_return_size - 1]]]\n\n    # add as the last IRnode a pointer to the return data structure\n\n    # the return type has been wrapped by the calling contract;\n    # unwrap it so downstream code isn't confused.\n    # basically this expands to buf+32 if the return type has been wrapped\n    # in a tuple AND its ABI type is dynamic.\n    # in most cases, this simply will evaluate to ret.\n    # in the special case where the return type has been wrapped\n    # in a tuple AND its ABI type is dynamic, it expands to buf+32.\n    buf = IRnode(buf, typ=return_t, encoding=_returndata_encoding(contract_sig), location=MEMORY)\n\n    if should_unwrap_abi_tuple:\n        buf = get_element_ptr(buf, 0, array_bounds_check=False)\n\n    ret += [buf]\n\n    return ret, ret_ofst, ret_len\n\n\ndef _external_call_helper(\n    contract_address,\n    contract_sig,\n    args_ir,\n    context,\n    value=None,\n    gas=None,\n    skip_contract_check=None,\n    expr=None,\n):\n\n    if value is None:\n        value = 0\n    if gas is None:\n        gas = \"gas\"\n    if skip_contract_check is None:\n        skip_contract_check = False\n\n    # sanity check\n    assert len(contract_sig.base_args) <= len(args_ir) <= len(contract_sig.args)\n\n    if context.is_constant() and contract_sig.mutability not in (\"view\", \"pure\"):\n        # TODO is this already done in type checker?\n        raise StateAccessViolation(\n            f\"May not call state modifying function '{contract_sig.name}' \"\n            f\"within {context.pp_constancy()}.\",\n            expr,\n        )\n\n    sub = [\"seq\"]\n\n    buf, arg_packer, args_ofst, args_len = _pack_arguments(contract_sig, args_ir, context)\n\n    ret_unpacker, ret_ofst, ret_len = _unpack_returndata(\n        buf, contract_sig, skip_contract_check, context\n    )\n\n    sub += arg_packer\n\n    if contract_sig.return_type is None and not skip_contract_check:\n        # if we do not expect return data, check that a contract exists at the\n        # target address. we must perform this check BEFORE the call because\n        # the contract might selfdestruct. on the other hand we can omit this\n        # when we _do_ expect return data because we later check\n        # `returndatasize` (that check works even if the contract\n        # selfdestructs).\n        sub.append([\"assert\", [\"extcodesize\", contract_address]])\n\n    if context.is_constant() or contract_sig.mutability in (\"view\", \"pure\"):\n        call_op = [\"staticcall\", gas, contract_address, args_ofst, args_len, ret_ofst, ret_len]\n    else:\n        call_op = [\"call\", gas, contract_address, value, args_ofst, args_len, ret_ofst, ret_len]\n\n    sub.append(check_external_call(call_op))\n\n    if contract_sig.return_type is not None:\n        sub += ret_unpacker\n\n    ret = IRnode.from_list(\n        sub,\n        typ=contract_sig.return_type,\n        location=MEMORY,\n        # set the encoding to ABI here, downstream code will decode and add clampers.\n        encoding=_returndata_encoding(contract_sig),\n    )\n\n    return ret\n\n\ndef _get_special_kwargs(stmt_expr, context):\n    from vyper.codegen.expr import Expr  # TODO rethink this circular import\n\n    value, gas, skip_contract_check = None, None, None\n    for kw in stmt_expr.keywords:\n        if kw.arg == \"gas\":\n            gas = Expr.parse_value_expr(kw.value, context)\n        elif kw.arg == \"value\":\n            value = Expr.parse_value_expr(kw.value, context)\n        elif kw.arg == \"skip_contract_check\":\n            skip_contract_check = kw.value.value\n            assert isinstance(skip_contract_check, bool), \"type checker missed this\"\n        else:\n            raise TypeCheckFailure(\"Unexpected keyword argument\")\n\n    # TODO maybe return a small dataclass to reduce verbosity\n    return value, gas, skip_contract_check\n\n\ndef ir_for_external_call(stmt_expr, context):\n    from vyper.codegen.expr import Expr  # TODO rethink this circular import\n\n    contract_address = Expr.parse_value_expr(stmt_expr.func.value, context)\n    value, gas, skip_contract_check = _get_special_kwargs(stmt_expr, context)\n    args_ir = [Expr(x, context).ir_node for x in stmt_expr.args]\n\n    assert isinstance(contract_address.typ, InterfaceType)\n    contract_name = contract_address.typ.name\n    method_name = stmt_expr.func.attr\n    contract_sig = context.sigs[contract_name][method_name]\n\n    ret = _external_call_helper(\n        contract_address,\n        contract_sig,\n        args_ir,\n        context,\n        value=value,\n        gas=gas,\n        skip_contract_check=skip_contract_check,\n        expr=stmt_expr,\n    )\n    ret.annotation = stmt_expr.get(\"node_source_code\")\n\n    return ret\n", "from typing import Any, List\n\nimport vyper.utils as util\nfrom vyper.address_space import CALLDATA, DATA, MEMORY\nfrom vyper.ast.signatures.function_signature import FunctionSignature, VariableRecord\nfrom vyper.codegen.context import Context\nfrom vyper.codegen.core import get_element_ptr, getpos, make_setter\nfrom vyper.codegen.expr import Expr\nfrom vyper.codegen.function_definitions.utils import get_nonreentrant_lock\nfrom vyper.codegen.ir_node import Encoding, IRnode\nfrom vyper.codegen.stmt import parse_body\nfrom vyper.codegen.types.types import (\n    BaseType,\n    ByteArrayLike,\n    DArrayType,\n    SArrayType,\n    TupleLike,\n    TupleType,\n)\nfrom vyper.exceptions import CompilerPanic\n\n\ndef _should_decode(typ):\n    # either a basetype which needs to be clamped\n    # or a complex type which contains something that\n    # needs to be clamped.\n    if isinstance(typ, BaseType):\n        return typ.typ not in (\"int256\", \"uint256\", \"bytes32\")\n    if isinstance(typ, (ByteArrayLike, DArrayType)):\n        return True\n    if isinstance(typ, SArrayType):\n        return _should_decode(typ.subtype)\n    if isinstance(typ, TupleLike):\n        return any(_should_decode(t) for t in typ.tuple_members())\n    raise CompilerPanic(f\"_should_decode({typ})\")  # pragma: notest\n\n\n# register function args with the local calling context.\n# also allocate the ones that live in memory (i.e. kwargs)\ndef _register_function_args(context: Context, sig: FunctionSignature) -> List[IRnode]:\n    ret = []\n\n    # the type of the calldata\n    base_args_t = TupleType([arg.typ for arg in sig.base_args])\n\n    # tuple with the abi_encoded args\n    if sig.is_init_func:\n        base_args_ofst = IRnode(0, location=DATA, typ=base_args_t, encoding=Encoding.ABI)\n    else:\n        base_args_ofst = IRnode(4, location=CALLDATA, typ=base_args_t, encoding=Encoding.ABI)\n\n    for i, arg in enumerate(sig.base_args):\n\n        arg_ir = get_element_ptr(base_args_ofst, i)\n\n        if _should_decode(arg.typ):\n            # allocate a memory slot for it and copy\n            p = context.new_variable(arg.name, arg.typ, is_mutable=False)\n            dst = IRnode(p, typ=arg.typ, location=MEMORY)\n\n            copy_arg = make_setter(dst, arg_ir)\n            copy_arg.source_pos = getpos(arg.ast_source)\n            ret.append(copy_arg)\n        else:\n            # leave it in place\n            context.vars[arg.name] = VariableRecord(\n                name=arg.name,\n                pos=arg_ir,\n                typ=arg.typ,\n                mutable=False,\n                location=arg_ir.location,\n                encoding=Encoding.ABI,\n            )\n\n    return ret\n\n\ndef _annotated_method_id(abi_sig):\n    method_id = util.abi_method_id(abi_sig)\n    annotation = f\"{hex(method_id)}: {abi_sig}\"\n    return IRnode(method_id, annotation=annotation)\n\n\ndef _generate_kwarg_handlers(context: Context, sig: FunctionSignature) -> List[Any]:\n    # generate kwarg handlers.\n    # since they might come in thru calldata or be default,\n    # allocate them in memory and then fill it in based on calldata or default,\n    # depending on the signature\n    # a kwarg handler looks like\n    # (if (eq _method_id <method_id>)\n    #    copy calldata args to memory\n    #    write default args to memory\n    #    goto external_function_common_ir\n\n    def handler_for(calldata_kwargs, default_kwargs):\n        calldata_args = sig.base_args + calldata_kwargs\n        # create a fake type so that get_element_ptr works\n        calldata_args_t = TupleType(list(arg.typ for arg in calldata_args))\n\n        abi_sig = sig.abi_signature_for_kwargs(calldata_kwargs)\n        method_id = _annotated_method_id(abi_sig)\n\n        calldata_kwargs_ofst = IRnode(\n            4, location=CALLDATA, typ=calldata_args_t, encoding=Encoding.ABI\n        )\n\n        # a sequence of statements to strictify kwargs into memory\n        ret = [\"seq\"]\n\n        # TODO optimize make_setter by using\n        # TupleType(list(arg.typ for arg in calldata_kwargs + default_kwargs))\n        # (must ensure memory area is contiguous)\n\n        n_base_args = len(sig.base_args)\n\n        for i, arg_meta in enumerate(calldata_kwargs):\n            k = n_base_args + i\n\n            dst = context.lookup_var(arg_meta.name).pos\n\n            lhs = IRnode(dst, location=MEMORY, typ=arg_meta.typ)\n\n            rhs = get_element_ptr(calldata_kwargs_ofst, k, array_bounds_check=False)\n\n            copy_arg = make_setter(lhs, rhs)\n            copy_arg.source_pos = getpos(arg_meta.ast_source)\n            ret.append(copy_arg)\n\n        for x in default_kwargs:\n            dst = context.lookup_var(x.name).pos\n            lhs = IRnode(dst, location=MEMORY, typ=x.typ)\n            lhs.source_pos = getpos(x.ast_source)\n            kw_ast_val = sig.default_values[x.name]  # e.g. `3` in x: int = 3\n            rhs = Expr(kw_ast_val, context).ir_node\n\n            copy_arg = make_setter(lhs, rhs)\n            copy_arg.source_pos = getpos(x.ast_source)\n            ret.append(copy_arg)\n\n        ret.append([\"goto\", sig.external_function_base_entry_label])\n\n        ret = [\"if\", [\"eq\", \"_calldata_method_id\", method_id], ret]\n        return ret\n\n    ret = [\"seq\"]\n\n    keyword_args = sig.default_args\n\n    # allocate variable slots in memory\n    for arg in keyword_args:\n        context.new_variable(arg.name, arg.typ, is_mutable=False)\n\n    for i, _ in enumerate(keyword_args):\n        calldata_kwargs = keyword_args[:i]\n        default_kwargs = keyword_args[i:]\n\n        ret.append(handler_for(calldata_kwargs, default_kwargs))\n\n    ret.append(handler_for(keyword_args, []))\n\n    return ret\n\n\n# TODO it would be nice if this returned a data structure which were\n# amenable to generating a jump table instead of the linear search for\n# method_id we have now.\ndef generate_ir_for_external_function(code, sig, context, check_nonpayable):\n    # TODO type hints:\n    # def generate_ir_for_external_function(\n    #    code: vy_ast.FunctionDef, sig: FunctionSignature, context: Context, check_nonpayable: bool,\n    # ) -> IRnode:\n    \"\"\"Return the IR for an external function. Includes code to inspect the method_id,\n    enter the function (nonpayable and reentrancy checks), handle kwargs and exit\n    the function (clean up reentrancy storage variables)\n    \"\"\"\n    func_type = code._metadata[\"type\"]\n\n    nonreentrant_pre, nonreentrant_post = get_nonreentrant_lock(func_type)\n\n    # generate handlers for base args and register the variable records\n    handle_base_args = _register_function_args(context, sig)\n\n    # generate handlers for kwargs and register the variable records\n    kwarg_handlers = _generate_kwarg_handlers(context, sig)\n\n    body = [\"seq\"]\n    # once optional args have been handled,\n    # generate the main body of the function\n    body += handle_base_args\n\n    if check_nonpayable and sig.mutability != \"payable\":\n        # if the contract contains payable functions, but this is not one of them\n        # add an assertion that the value of the call is zero\n        body += [[\"assert\", [\"iszero\", \"callvalue\"]]]\n\n    body += nonreentrant_pre\n\n    body += [parse_body(code.body, context, ensure_terminated=True)]\n\n    # wrap the body in labeled block\n    body = [\"label\", sig.external_function_base_entry_label, [\"var_list\"], body]\n\n    exit_sequence = [\"seq\"] + nonreentrant_post\n    if sig.is_init_func:\n        pass  # init func has special exit sequence generated by module.py\n    elif context.return_type is None:\n        exit_sequence += [[\"stop\"]]\n    else:\n        exit_sequence += [[\"return\", \"ret_ofst\", \"ret_len\"]]\n\n    exit_sequence_args = [\"var_list\"]\n    if context.return_type is not None:\n        exit_sequence_args += [\"ret_ofst\", \"ret_len\"]\n    # wrap the exit in a labeled block\n    exit = [\"label\", sig.exit_sequence_label, exit_sequence_args, exit_sequence]\n\n    # the ir which comprises the main body of the function,\n    # besides any kwarg handling\n    func_common_ir = [\"seq\", body, exit]\n\n    if sig.is_default_func or sig.is_init_func:\n        ret = [\"seq\"]\n        # add a goto to make the function entry look like other functions\n        # (for zksync interpreter)\n        ret.append([\"goto\", sig.external_function_base_entry_label])\n        ret.append(func_common_ir)\n    else:\n        ret = kwarg_handlers\n        # sneak the base code into the kwarg handler\n        # TODO rethink this / make it clearer\n        ret[-1][-1].append(func_common_ir)\n\n    return IRnode.from_list(ret)\n", "import re\nfrom enum import Enum, auto\nfrom typing import Any, List, Optional, Tuple, Union\n\nfrom vyper.address_space import AddrSpace\nfrom vyper.codegen.types import BaseType, NodeType, ceil32\nfrom vyper.compiler.settings import VYPER_COLOR_OUTPUT\nfrom vyper.evm.opcodes import get_ir_opcodes\nfrom vyper.exceptions import CodegenPanic, CompilerPanic\nfrom vyper.utils import VALID_IR_MACROS, cached_property\n\n# Set default string representation for ints in IR output.\nAS_HEX_DEFAULT = False\n\nif VYPER_COLOR_OUTPUT:\n    OKBLUE = \"\\033[94m\"\n    OKMAGENTA = \"\\033[35m\"\n    OKLIGHTMAGENTA = \"\\033[95m\"\n    OKLIGHTBLUE = \"\\033[94m\"\n    ENDC = \"\\033[0m\"\nelse:\n    OKBLUE = \"\"\n    OKMAGENTA = \"\"\n    OKLIGHTMAGENTA = \"\"\n    OKLIGHTBLUE = \"\"\n    ENDC = \"\"\n\n\nclass NullAttractor(int):\n    def __add__(self, other: int) -> \"NullAttractor\":\n        return NullAttractor()\n\n    def __repr__(self) -> str:\n        return \"None\"\n\n    __radd__ = __add__\n    __mul__ = __add__\n\n\ndef push_label_to_stack(labelname: str) -> str:\n    #  items prefixed with `_sym_` are ignored until asm phase\n    return \"_sym_\" + labelname\n\n\nclass Encoding(Enum):\n    # vyper encoding, default for memory variables\n    VYPER = auto()\n    # abi encoded, default for args/return values from external funcs\n    ABI = auto()\n    # abi encoded, same as ABI but no clamps for bytestrings\n    JSON_ABI = auto()\n    # future: packed\n\n\n# Data structure for IR parse tree\nclass IRnode:\n    repr_show_gas = False\n    gas: int\n    valency: int\n    args: List[\"IRnode\"]\n    value: Union[str, int]\n\n    def __init__(\n        self,\n        value: Union[str, int],\n        args: List[\"IRnode\"] = None,\n        typ: NodeType = None,\n        location: Optional[AddrSpace] = None,\n        source_pos: Optional[Tuple[int, int]] = None,\n        annotation: Optional[str] = None,\n        mutable: bool = True,\n        add_gas_estimate: int = 0,\n        valency: Optional[int] = None,\n        encoding: Encoding = Encoding.VYPER,\n    ):\n        if args is None:\n            args = []\n\n        self.value = value\n        self.args = args\n        # TODO remove this sanity check once mypy is more thorough\n        assert isinstance(typ, NodeType) or typ is None, repr(typ)\n        self.typ = typ\n        self.location = location\n        self.source_pos = source_pos\n        self.annotation = annotation\n        self.mutable = mutable\n        self.add_gas_estimate = add_gas_estimate\n        self.encoding = encoding\n        self.as_hex = AS_HEX_DEFAULT\n\n        # Optional annotation properties for gas estimation\n        self.total_gas = None\n        self.func_name = None\n\n        def _check(condition, err):\n            if not condition:\n                raise CompilerPanic(str(err))\n\n        _check(self.value is not None, \"None is not allowed as IRnode value\")\n\n        # Determine this node's valency (1 if it pushes a value on the stack,\n        # 0 otherwise) and checks to make sure the number and valencies of\n        # children are correct. Also, find an upper bound on gas consumption\n        # Numbers\n        if isinstance(self.value, int):\n            _check(len(self.args) == 0, \"int can't have arguments\")\n            self.valency = 1\n            self.gas = 5\n        elif isinstance(self.value, str):\n            # Opcodes and pseudo-opcodes (e.g. clamp)\n            if self.value.upper() in get_ir_opcodes():\n                _, ins, outs, gas = get_ir_opcodes()[self.value.upper()]\n                self.valency = outs\n                _check(\n                    len(self.args) == ins,\n                    f\"Number of arguments mismatched: {self.value} {self.args}\",\n                )\n                # We add 2 per stack height at push time and take it back\n                # at pop time; this makes `break` easier to handle\n                self.gas = gas + 2 * (outs - ins)\n                for arg in self.args:\n                    # pop and pass are used to push/pop values on the stack to be\n                    # consumed for internal functions, therefore we whitelist this as a zero valency\n                    # allowed argument.\n                    zero_valency_whitelist = {\"pass\", \"pop\"}\n                    _check(\n                        arg.valency == 1 or arg.value in zero_valency_whitelist,\n                        f\"invalid argument to `{self.value}`: {arg}\",\n                    )\n                    self.gas += arg.gas\n                # Dynamic gas cost: 8 gas for each byte of logging data\n                if self.value.upper()[0:3] == \"LOG\" and isinstance(self.args[1].value, int):\n                    self.gas += self.args[1].value * 8\n                # Dynamic gas cost: non-zero-valued call\n                if self.value.upper() == \"CALL\" and self.args[2].value != 0:\n                    self.gas += 34000\n                # Dynamic gas cost: filling sstore (ie. not clearing)\n                elif self.value.upper() == \"SSTORE\" and self.args[1].value != 0:\n                    self.gas += 15000\n                # Dynamic gas cost: calldatacopy\n                elif self.value.upper() in (\"CALLDATACOPY\", \"CODECOPY\", \"EXTCODECOPY\"):\n                    size = 34000\n                    size_arg_index = 3 if self.value.upper() == \"EXTCODECOPY\" else 2\n                    size_arg = self.args[size_arg_index]\n                    if isinstance(size_arg.value, int):\n                        size = size_arg.value\n                    self.gas += ceil32(size) // 32 * 3\n                # Gas limits in call\n                if self.value.upper() == \"CALL\" and isinstance(self.args[0].value, int):\n                    self.gas += self.args[0].value\n            # If statements\n            elif self.value == \"if\":\n                if len(self.args) == 3:\n                    self.gas = self.args[0].gas + max(self.args[1].gas, self.args[2].gas) + 3\n                if len(self.args) == 2:\n                    self.gas = self.args[0].gas + self.args[1].gas + 17\n                _check(\n                    self.args[0].valency > 0,\n                    f\"zerovalent argument as a test to an if statement: {self.args[0]}\",\n                )\n                _check(len(self.args) in (2, 3), \"if statement can only have 2 or 3 arguments\")\n                self.valency = self.args[1].valency\n            # With statements: with <var> <initial> <statement>\n            elif self.value == \"with\":\n                _check(len(self.args) == 3, self)\n                _check(\n                    len(self.args[0].args) == 0 and isinstance(self.args[0].value, str),\n                    f\"first argument to with statement must be a variable name: {self.args[0]}\",\n                )\n                _check(\n                    self.args[1].valency == 1 or self.args[1].value == \"pass\",\n                    f\"zerovalent argument to with statement: {self.args[1]}\",\n                )\n                self.valency = self.args[2].valency\n                self.gas = sum([arg.gas for arg in self.args]) + 5\n            # Repeat statements: repeat <index_name> <startval> <rounds> <rounds_bound> <body>\n            elif self.value == \"repeat\":\n                _check(\n                    len(self.args) == 5, \"repeat(index_name, startval, rounds, rounds_bound, body)\"\n                )\n\n                counter_ptr = self.args[0]\n                start = self.args[1]\n                repeat_count = self.args[2]\n                repeat_bound = self.args[3]\n                body = self.args[4]\n\n                _check(\n                    isinstance(repeat_bound.value, int) and repeat_bound.value > 0,\n                    f\"repeat bound must be a compile-time positive integer: {self.args[2]}\",\n                )\n                _check(repeat_count.valency == 1, repeat_count)\n                _check(counter_ptr.valency == 1, counter_ptr)\n                _check(start.valency == 1, start)\n\n                self.valency = 0\n\n                self.gas = counter_ptr.gas + start.gas\n                self.gas += 3  # gas for repeat_bound\n                int_bound = int(repeat_bound.value)\n                self.gas += int_bound * (body.gas + 50) + 30\n\n                if repeat_count != repeat_bound:\n                    # gas for assert(repeat_count <= repeat_bound)\n                    self.gas += 18\n\n            # Seq statements: seq <statement> <statement> ...\n            elif self.value == \"seq\":\n                self.valency = self.args[-1].valency if self.args else 0\n                self.gas = sum([arg.gas for arg in self.args]) + 30\n\n            # GOTO is a jump with args\n            # e.g. (goto my_label x y z) will push x y and z onto the stack,\n            # then JUMP to my_label.\n            elif self.value in (\"goto\", \"exit_to\"):\n                for arg in self.args:\n                    _check(\n                        arg.valency == 1 or arg.value == \"pass\",\n                        f\"zerovalent argument to goto {arg}\",\n                    )\n\n                self.valency = 0\n                self.gas = sum([arg.gas for arg in self.args])\n            elif self.value == \"label\":\n                if not self.args[1].value == \"var_list\":\n                    raise CodegenPanic(f\"2nd argument to label must be var_list, {self}\")\n                self.valency = 0\n                self.gas = 1 + sum(t.gas for t in self.args)\n            # var_list names a variable number stack variables\n            elif self.value == \"var_list\":\n                for arg in self.args:\n                    if not isinstance(arg.value, str) or len(arg.args) > 0:\n                        raise CodegenPanic(f\"var_list only takes strings: {self.args}\")\n                self.valency = 0\n                self.gas = 0\n\n            # Multi statements: multi <expr> <expr> ...\n            elif self.value == \"multi\":\n                for arg in self.args:\n                    _check(\n                        arg.valency > 0, f\"Multi expects all children to not be zerovalent: {arg}\"\n                    )\n                self.valency = sum([arg.valency for arg in self.args])\n                self.gas = sum([arg.gas for arg in self.args])\n            elif self.value == \"deploy\":\n                self.valency = 0\n                self.gas = NullAttractor()  # unknown\n            # Stack variables\n            else:\n                self.valency = 1\n                self.gas = 3\n        elif self.value is None:\n            self.valency = 1\n            # None IRnodes always get compiled into something else, e.g.\n            # mzero or PUSH1 0, and the gas will get re-estimated then.\n            self.gas = 3\n        else:\n            raise CompilerPanic(f\"Invalid value for IR AST node: {self.value}\")\n        assert isinstance(self.args, list)\n\n        if valency is not None:\n            self.valency = valency\n\n        self.gas += self.add_gas_estimate\n\n    # the IR should be cached.\n    # TODO make this private. turns out usages are all for the caching\n    # idiom that cache_when_complex addresses\n    @property\n    def is_complex_ir(self):\n        # list of items not to cache. note can add other env variables\n        # which do not change, e.g. calldatasize, coinbase, etc.\n        do_not_cache = {\"~empty\"}\n        return (\n            isinstance(self.value, str)\n            and (self.value.lower() in VALID_IR_MACROS or self.value.upper() in get_ir_opcodes())\n            and self.value.lower() not in do_not_cache\n        )\n\n    @property\n    def is_literal(self):\n        return isinstance(self.value, int) or self.value == \"multi\"\n\n    @property\n    def is_pointer(self):\n        # not used yet but should help refactor/clarify downstream code\n        # eventually\n        return self.location is not None\n\n    # This function is slightly confusing but abstracts a common pattern:\n    # when an IR value needs to be computed once and then cached as an\n    # IR value (if it is expensive, or more importantly if its computation\n    # includes side-effects), cache it as an IR variable named with the\n    # `name` param, and execute the `body` with the cached value. Otherwise,\n    # run the `body` without caching the IR variable.\n    # Note that this may be an unneeded abstraction in the presence of an\n    # arbitrarily powerful optimization framework (which can detect unneeded\n    # caches) but for now still necessary - CMC 2021-12-11.\n    # usage:\n    # ```\n    # with ir_node.cache_when_complex(\"foo\") as builder, foo:\n    #   ret = some_function(foo)\n    #   return builder.resolve(ret)\n    # ```\n    def cache_when_complex(self, name):\n        # this creates a magical block which maps to IR `with`\n        class _WithBuilder:\n            def __init__(self, ir_node, name):\n                # TODO figure out how to fix this circular import\n                from vyper.ir.optimizer import optimize\n\n                self.ir_node = ir_node\n                # for caching purposes, see if the ir_node will be optimized\n                # because a non-literal expr could turn into a literal,\n                # (e.g. `(add 1 2)`)\n                # TODO this could really be moved into optimizer.py\n                self.should_cache = optimize(ir_node).is_complex_ir\n\n                # a named IR variable which represents the\n                # output of `ir_node`\n                self.ir_var = IRnode.from_list(\n                    name, typ=ir_node.typ, location=ir_node.location, encoding=ir_node.encoding\n                )\n\n            def __enter__(self):\n                if self.should_cache:\n                    # return the named cache\n                    return self, self.ir_var\n                else:\n                    # it's a constant (or will be optimized to one), just return that\n                    return self, self.ir_node\n\n            def __exit__(self, *args):\n                pass\n\n            # MUST be called at the end of building the expression\n            # in order to make sure the expression gets wrapped correctly\n            def resolve(self, body):\n                if self.should_cache:\n                    ret = [\"with\", self.ir_var, self.ir_node, body]\n                    if isinstance(body, IRnode):\n                        return IRnode.from_list(\n                            ret, typ=body.typ, location=body.location, encoding=body.encoding\n                        )\n                    else:\n                        return ret\n                else:\n                    return body\n\n        return _WithBuilder(self, name)\n\n    @cached_property\n    def contains_self_call(self):\n        return getattr(self, \"is_self_call\", False) or any(x.contains_self_call for x in self.args)\n\n    def __getitem__(self, i):\n        return self.to_list()[i]\n\n    def __len__(self):\n        return len(self.to_list())\n\n    # TODO this seems like a not useful and also confusing function\n    # check if dead code and remove - CMC 2021-12-13\n    def to_list(self):\n        return [self.value] + [a.to_list() for a in self.args]\n\n    def __eq__(self, other):\n        return (\n            self.value == other.value\n            and self.args == other.args\n            and self.typ == other.typ\n            and self.location == other.location\n            and self.source_pos == other.source_pos\n            and self.annotation == other.annotation\n            and self.mutable == other.mutable\n            and self.add_gas_estimate == other.add_gas_estimate\n            and self.valency == other.valency\n        )\n\n    @property\n    def repr_value(self):\n        if isinstance(self.value, int) and self.as_hex:\n            return hex(self.value)\n        if not isinstance(self.value, str):\n            return str(self.value)\n        return self.value\n\n    @staticmethod\n    def _colorise_keywords(val):\n        if val.lower() in VALID_IR_MACROS:  # highlight macro\n            return OKLIGHTMAGENTA + val + ENDC\n        elif val.upper() in get_ir_opcodes().keys():\n            return OKMAGENTA + val + ENDC\n        return val\n\n    def repr(self) -> str:\n\n        if not len(self.args):\n\n            if self.annotation:\n                return f\"{self.repr_value} \" + OKLIGHTBLUE + f\"<{self.annotation}>\" + ENDC\n            else:\n                return str(self.repr_value)\n        # x = repr(self.to_list())\n        # if len(x) < 80:\n        #     return x\n        o = \"\"\n        if self.annotation:\n            o += f\"/* {self.annotation} */ \\n\"\n        if self.repr_show_gas and self.gas:\n            o += OKBLUE + \"{\" + ENDC + str(self.gas) + OKBLUE + \"} \" + ENDC  # add gas for info.\n        o += \"[\" + self._colorise_keywords(self.repr_value)\n        prev_lineno = self.source_pos[0] if self.source_pos else None\n        arg_lineno = None\n        annotated = False\n        has_inner_newlines = False\n        for arg in self.args:\n            o += \",\\n  \"\n            arg_lineno = arg.source_pos[0] if arg.source_pos else None\n            if arg_lineno is not None and arg_lineno != prev_lineno and self.value in (\"seq\", \"if\"):\n                o += f\"# Line {(arg_lineno)}\\n  \"\n                prev_lineno = arg_lineno\n                annotated = True\n            arg_repr = arg.repr()\n            if \"\\n\" in arg_repr:\n                has_inner_newlines = True\n            sub = arg_repr.replace(\"\\n\", \"\\n  \").strip(\" \")\n            o += self._colorise_keywords(sub)\n        output = o.rstrip(\" \") + \"]\"\n        output_on_one_line = re.sub(r\",\\n *\", \", \", output).replace(\"\\n\", \"\")\n\n        should_output_single_line = (\n            (len(output_on_one_line) < 80 or len(self.args) == 1) and not annotated\n        ) and not has_inner_newlines\n\n        if should_output_single_line:\n            return output_on_one_line\n        else:\n            return output\n\n    def __repr__(self):\n        return self.repr()\n\n    @classmethod\n    def from_list(\n        cls,\n        obj: Any,\n        typ: NodeType = None,\n        location: Optional[AddrSpace] = None,\n        source_pos: Optional[Tuple[int, int]] = None,\n        annotation: Optional[str] = None,\n        mutable: bool = True,\n        add_gas_estimate: int = 0,\n        valency: Optional[int] = None,\n        encoding: Encoding = Encoding.VYPER,\n    ) -> \"IRnode\":\n        if isinstance(typ, str):\n            typ = BaseType(typ)\n\n        if isinstance(obj, IRnode):\n            # note: this modify-and-returnclause is a little weird since\n            # the input gets modified. CC 20191121.\n            if typ is not None:\n                obj.typ = typ\n            if obj.source_pos is None:\n                obj.source_pos = source_pos\n            if obj.location is None:\n                obj.location = location\n            if obj.encoding is None:\n                obj.encoding = encoding\n\n            return obj\n        elif not isinstance(obj, list):\n            return cls(\n                obj,\n                [],\n                typ,\n                location=location,\n                annotation=annotation,\n                mutable=mutable,\n                add_gas_estimate=add_gas_estimate,\n                valency=valency,\n                encoding=encoding,\n            )\n        else:\n            return cls(\n                obj[0],\n                [cls.from_list(o, source_pos=source_pos) for o in obj[1:]],\n                typ,\n                location=location,\n                annotation=annotation,\n                mutable=mutable,\n                source_pos=source_pos,\n                add_gas_estimate=add_gas_estimate,\n                valency=valency,\n                encoding=encoding,\n            )\n", "# transition module to convert from new types to old types\n\nimport vyper.codegen.types as old\nimport vyper.semantics.types as new\nfrom vyper.exceptions import InvalidType\n\n\ndef new_type_to_old_type(typ: new.BasePrimitive) -> old.NodeType:\n    if isinstance(typ, new.BoolDefinition):\n        return old.BaseType(\"bool\")\n    if isinstance(typ, new.AddressDefinition):\n        return old.BaseType(\"address\")\n    if isinstance(typ, new.InterfaceDefinition):\n        return old.InterfaceType(typ._id)\n    if isinstance(typ, new.BytesMDefinition):\n        m = typ._length  # type: ignore\n        return old.BaseType(f\"bytes{m}\")\n    if isinstance(typ, new.BytesArrayDefinition):\n        return old.ByteArrayType(typ.length)\n    if isinstance(typ, new.StringDefinition):\n        return old.StringType(typ.length)\n    if isinstance(typ, new.DecimalDefinition):\n        return old.BaseType(\"decimal\")\n    if isinstance(typ, new.SignedIntegerAbstractType):\n        bits = typ._bits  # type: ignore\n        return old.BaseType(\"int\" + str(bits))\n    if isinstance(typ, new.UnsignedIntegerAbstractType):\n        bits = typ._bits  # type: ignore\n        return old.BaseType(\"uint\" + str(bits))\n    if isinstance(typ, new.ArrayDefinition):\n        return old.SArrayType(new_type_to_old_type(typ.value_type), typ.length)\n    if isinstance(typ, new.DynamicArrayDefinition):\n        return old.DArrayType(new_type_to_old_type(typ.value_type), typ.length)\n    if isinstance(typ, new.TupleDefinition):\n        return old.TupleType(typ.value_type)\n    if isinstance(typ, new.StructDefinition):\n        return old.StructType(\n            {n: new_type_to_old_type(t) for (n, t) in typ.members.items()}, typ._id\n        )\n    raise InvalidType(f\"unknown type {typ}\")\n"], "fixing_code": ["from decimal import Decimal\n\nimport pytest\n\nfrom vyper.ast.signatures.interface import extract_sigs\nfrom vyper.builtin_interfaces import ERC20, ERC721\nfrom vyper.cli.utils import extract_file_interface_imports\nfrom vyper.compiler import compile_code, compile_codes\nfrom vyper.exceptions import ArgumentException, InterfaceViolation, StructureException\n\n\ndef test_basic_extract_interface():\n    code = \"\"\"\n# Events\n\nevent Transfer:\n    _from: address\n    _to: address\n    _value: uint256\n\n# Functions\n\n@view\n@external\ndef allowance(_owner: address, _spender: address) -> (uint256, uint256):\n    return 1, 2\n    \"\"\"\n\n    out = compile_code(code, [\"interface\"])\n    out = out[\"interface\"]\n    code_pass = \"\\n\".join(code.split(\"\\n\")[:-2] + [\"    pass\"])  # replace with a pass statement.\n\n    assert code_pass.strip() == out.strip()\n\n\ndef test_basic_extract_external_interface():\n    code = \"\"\"\n@view\n@external\ndef allowance(_owner: address, _spender: address) -> (uint256, uint256):\n    return 1, 2\n\n@external\ndef test(_owner: address):\n    pass\n\n@view\n@internal\ndef _prive(_owner: address, _spender: address) -> (uint256, uint256):\n    return 1, 2\n    \"\"\"\n\n    interface = \"\"\"\n# External Interfaces\ninterface One:\n    def allowance(_owner: address, _spender: address) -> (uint256, uint256): view\n    def test(_owner: address): nonpayable\n    \"\"\"\n\n    out = compile_codes({\"one.vy\": code}, [\"external_interface\"])[\"one.vy\"]\n    out = out[\"external_interface\"]\n\n    assert interface.strip() == out.strip()\n\n\ndef test_basic_interface_implements(assert_compile_failed):\n    code = \"\"\"\nfrom vyper.interfaces import ERC20\n\nimplements: ERC20\n\n\n@external\ndef test() -> bool:\n    return True\n    \"\"\"\n\n    assert_compile_failed(lambda: compile_code(code), InterfaceViolation)\n\n\ndef test_builtin_interfaces_parse():\n    assert len(extract_sigs({\"type\": \"vyper\", \"code\": ERC20.interface_code})) == 6\n    assert len(extract_sigs({\"type\": \"vyper\", \"code\": ERC721.interface_code})) == 9\n\n\ndef test_extract_sigs_ignores_imports():\n    interface_code = \"\"\"\n{}\n\n@external\ndef foo() -> uint256:\n    pass\n    \"\"\"\n\n    base = extract_sigs({\"type\": \"vyper\", \"code\": interface_code.format(\"\")})\n\n    for stmt in (\"import x as x\", \"from x import y\"):\n        sigs = extract_sigs({\"type\": \"vyper\", \"code\": interface_code.format(stmt)})\n        assert [type(i) for i in base] == [type(i) for i in sigs]\n\n\ndef test_external_interface_parsing(assert_compile_failed):\n    interface_code = \"\"\"\n@external\ndef foo() -> uint256:\n    pass\n\n@external\ndef bar() -> uint256:\n    pass\n    \"\"\"\n\n    interface_codes = {\"FooBarInterface\": {\"type\": \"vyper\", \"code\": interface_code}}\n\n    code = \"\"\"\nimport a as FooBarInterface\n\nimplements: FooBarInterface\n\n@external\ndef foo() -> uint256:\n    return 1\n\n@external\ndef bar() -> uint256:\n    return 2\n    \"\"\"\n\n    assert compile_code(code, interface_codes=interface_codes)\n\n    not_implemented_code = \"\"\"\nimport a as FooBarInterface\n\nimplements: FooBarInterface\n\n@external\ndef foo() -> uint256:\n    return 1\n\n    \"\"\"\n\n    assert_compile_failed(\n        lambda: compile_code(not_implemented_code, interface_codes=interface_codes),\n        InterfaceViolation,\n    )\n\n\ndef test_missing_event(assert_compile_failed):\n    interface_code = \"\"\"\nevent Foo:\n    a: uint256\n    \"\"\"\n\n    interface_codes = {\"FooBarInterface\": {\"type\": \"vyper\", \"code\": interface_code}}\n\n    not_implemented_code = \"\"\"\nimport a as FooBarInterface\n\nimplements: FooBarInterface\n\n@external\ndef bar() -> uint256:\n    return 1\n    \"\"\"\n\n    assert_compile_failed(\n        lambda: compile_code(not_implemented_code, interface_codes=interface_codes),\n        InterfaceViolation,\n    )\n\n\ndef test_malformed_event(assert_compile_failed):\n    interface_code = \"\"\"\nevent Foo:\n    a: uint256\n    \"\"\"\n\n    interface_codes = {\"FooBarInterface\": {\"type\": \"vyper\", \"code\": interface_code}}\n\n    not_implemented_code = \"\"\"\nimport a as FooBarInterface\n\nimplements: FooBarInterface\n\nevent Foo:\n    a: int128\n\n@external\ndef bar() -> uint256:\n    return 1\n    \"\"\"\n\n    assert_compile_failed(\n        lambda: compile_code(not_implemented_code, interface_codes=interface_codes),\n        InterfaceViolation,\n    )\n\n\nVALID_IMPORT_CODE = [\n    # import statement, import path without suffix\n    (\"import a as Foo\", \"a\"),\n    (\"import b.a as Foo\", \"b/a\"),\n    (\"import Foo as Foo\", \"Foo\"),\n    (\"from a import Foo\", \"a/Foo\"),\n    (\"from b.a import Foo\", \"b/a/Foo\"),\n    (\"from .a import Foo\", \"./a/Foo\"),\n    (\"from ..a import Foo\", \"../a/Foo\"),\n]\n\n\n@pytest.mark.parametrize(\"code\", VALID_IMPORT_CODE)\ndef test_extract_file_interface_imports(code):\n\n    assert extract_file_interface_imports(code[0]) == {\"Foo\": code[1]}\n\n\nBAD_IMPORT_CODE = [\n    \"import a\",  # must alias absolute imports\n    \"import a as A\\nimport a as A\",  # namespace collisions\n    \"from b import a\\nfrom a import a\",\n    \"from . import a\\nimport a as a\",\n    \"import a as a\\nfrom . import a\",\n]\n\n\n@pytest.mark.parametrize(\"code\", BAD_IMPORT_CODE)\ndef test_extract_file_interface_imports_raises(code, assert_compile_failed):\n    assert_compile_failed(lambda: extract_file_interface_imports(code), StructureException)\n\n\ndef test_external_call_to_interface(w3, get_contract):\n    token_code = \"\"\"\nbalanceOf: public(HashMap[address, uint256])\n\n@external\ndef transfer(to: address, _value: uint256):\n    self.balanceOf[to] += _value\n    \"\"\"\n\n    code = \"\"\"\nimport one as TokenCode\n\ninterface EPI:\n    def test() -> uint256: view\n\n\ntoken_address: TokenCode\n\n\n@external\ndef __init__(_token_address: address):\n    self.token_address = TokenCode(_token_address)\n\n\n@external\ndef test():\n    self.token_address.transfer(msg.sender, 1000)\n    \"\"\"\n\n    erc20 = get_contract(token_code)\n    test_c = get_contract(\n        code, *[erc20.address], interface_codes={\"TokenCode\": {\"type\": \"vyper\", \"code\": token_code}}\n    )\n\n    sender = w3.eth.accounts[0]\n    assert erc20.balanceOf(sender) == 0\n\n    test_c.test(transact={})\n    assert erc20.balanceOf(sender) == 1000\n\n\ndef test_external_call_to_builtin_interface(w3, get_contract):\n    token_code = \"\"\"\nbalanceOf: public(HashMap[address, uint256])\n\n@external\ndef transfer(to: address, _value: uint256) -> bool:\n    self.balanceOf[to] += _value\n    return True\n    \"\"\"\n\n    code = \"\"\"\nfrom vyper.interfaces import ERC20\n\n\ntoken_address: ERC20\n\n\n@external\ndef __init__(_token_address: address):\n    self.token_address = ERC20(_token_address)\n\n\n@external\ndef test():\n    self.token_address.transfer(msg.sender, 1000)\n    \"\"\"\n\n    erc20 = get_contract(token_code)\n    test_c = get_contract(\n        code, *[erc20.address], interface_codes={\"TokenCode\": {\"type\": \"vyper\", \"code\": token_code}}\n    )\n\n    sender = w3.eth.accounts[0]\n    assert erc20.balanceOf(sender) == 0\n\n    test_c.test(transact={})\n    assert erc20.balanceOf(sender) == 1000\n\n\n# test data returned from external interface gets clamped\n@pytest.mark.parametrize(\"typ\", (\"int128\", \"uint8\"))\ndef test_external_interface_int_clampers(get_contract, assert_tx_failed, typ):\n    external_contract = f\"\"\"\n@external\ndef ok() -> {typ}:\n    return 1\n\n@external\ndef should_fail() -> int256:\n    return -2**255 # OOB for all int/uint types with less than 256 bits\n    \"\"\"\n\n    code = f\"\"\"\ninterface BadContract:\n    def ok() -> {typ}: view\n    def should_fail() -> {typ}: view\n\nfoo: BadContract\n\n@external\ndef __init__(addr: BadContract):\n    self.foo = addr\n\n\n@external\ndef test_ok() -> {typ}:\n    return self.foo.ok()\n\n@external\ndef test_fail() -> {typ}:\n    return self.foo.should_fail()\n\n@external\ndef test_fail2() -> {typ}:\n    x: {typ} = self.foo.should_fail()\n    return x\n\n@external\ndef test_fail3() -> int256:\n    return convert(self.foo.should_fail(), int256)\n    \"\"\"\n\n    bad_c = get_contract(external_contract)\n    c = get_contract(\n        code,\n        bad_c.address,\n        interface_codes={\"BadCode\": {\"type\": \"vyper\", \"code\": external_contract}},\n    )\n    assert bad_c.ok() == 1\n    assert bad_c.should_fail() == -(2 ** 255)\n\n    assert c.test_ok() == 1\n    assert_tx_failed(lambda: c.test_fail())\n    assert_tx_failed(lambda: c.test_fail2())\n    assert_tx_failed(lambda: c.test_fail3())\n\n\n# test data returned from external interface gets clamped\ndef test_external_interface_bytes_clampers(get_contract, assert_tx_failed):\n    external_contract = \"\"\"\n@external\ndef ok() -> Bytes[2]:\n    return b\"12\"\n\n@external\ndef should_fail() -> Bytes[3]:\n    return b\"123\"\n    \"\"\"\n\n    code = \"\"\"\ninterface BadContract:\n    def ok() -> Bytes[2]: view\n    def should_fail() -> Bytes[2]: view\n\nfoo: BadContract\n\n@external\ndef __init__(addr: BadContract):\n    self.foo = addr\n\n\n@external\ndef test_ok() -> Bytes[2]:\n    return self.foo.ok()\n\n@external\ndef test_fail() -> Bytes[3]:\n    return self.foo.should_fail()\n    \"\"\"\n\n    bad_c = get_contract(external_contract)\n    c = get_contract(code, bad_c.address)\n    assert bad_c.ok() == b\"12\"\n    assert bad_c.should_fail() == b\"123\"\n\n    assert c.test_ok() == b\"12\"\n    assert_tx_failed(lambda: c.test_fail())\n\n\n# test data returned from external interface gets clamped\ndef test_json_abi_bytes_clampers(get_contract, assert_tx_failed, assert_compile_failed):\n    external_contract = \"\"\"\n@external\ndef returns_Bytes3() -> Bytes[3]:\n    return b\"123\"\n    \"\"\"\n\n    should_not_compile = \"\"\"\nimport BadJSONInterface as BadJSONInterface\n@external\ndef foo(x: BadJSONInterface) -> Bytes[2]:\n    return slice(x.returns_Bytes3(), 0, 2)\n    \"\"\"\n\n    code = \"\"\"\nimport BadJSONInterface as BadJSONInterface\n\nfoo: BadJSONInterface\n\n@external\ndef __init__(addr: BadJSONInterface):\n    self.foo = addr\n\n\n@external\ndef test_fail1() -> Bytes[2]:\n    # should compile, but raise runtime exception\n    return self.foo.returns_Bytes3()\n\n@external\ndef test_fail2() -> Bytes[2]:\n    # should compile, but raise runtime exception\n    x: Bytes[2] = self.foo.returns_Bytes3()\n    return x\n\n@external\ndef test_fail3() -> Bytes[3]:\n    # should revert - returns_Bytes3 is inferred to have return type Bytes[2]\n    # (because test_fail3 comes after test_fail1)\n    return self.foo.returns_Bytes3()\n\n    \"\"\"\n\n    bad_c = get_contract(external_contract)\n    bad_c_interface = {\n        \"BadJSONInterface\": {\n            \"type\": \"json\",\n            \"code\": compile_code(external_contract, [\"abi\"])[\"abi\"],\n        }\n    }\n\n    assert_compile_failed(\n        lambda: get_contract(should_not_compile, interface_codes=bad_c_interface), ArgumentException\n    )\n\n    c = get_contract(code, bad_c.address, interface_codes=bad_c_interface)\n    assert bad_c.returns_Bytes3() == b\"123\"\n\n    assert_tx_failed(lambda: c.test_fail1())\n    assert_tx_failed(lambda: c.test_fail2())\n    assert_tx_failed(lambda: c.test_fail3())\n\n\ndef test_units_interface(w3, get_contract):\n    code = \"\"\"\nimport balanceof as BalanceOf\n\nimplements: BalanceOf\n\n@external\n@view\ndef balanceOf(owner: address) -> uint256:\n    return as_wei_value(1, \"ether\")\n    \"\"\"\n    interface_code = \"\"\"\n@external\n@view\ndef balanceOf(owner: address) -> uint256:\n    pass\n    \"\"\"\n    interface_codes = {\"BalanceOf\": {\"type\": \"vyper\", \"code\": interface_code}}\n    c = get_contract(code, interface_codes=interface_codes)\n\n    assert c.balanceOf(w3.eth.accounts[0]) == w3.toWei(1, \"ether\")\n\n\ndef test_local_and_global_interface_namespaces():\n    interface_code = \"\"\"\n@external\ndef foo() -> uint256:\n    pass\n    \"\"\"\n\n    global_interface_codes = {\n        \"FooInterface\": {\"type\": \"vyper\", \"code\": interface_code},\n        \"BarInterface\": {\"type\": \"vyper\", \"code\": interface_code},\n    }\n    local_interface_codes = {\n        \"FooContract\": {\"FooInterface\": {\"type\": \"vyper\", \"code\": interface_code}},\n        \"BarContract\": {\"BarInterface\": {\"type\": \"vyper\", \"code\": interface_code}},\n    }\n\n    code = \"\"\"\nimport a as {0}\n\nimplements: {0}\n\n@external\ndef foo() -> uint256:\n    return 1\n    \"\"\"\n\n    codes = {\"FooContract\": code.format(\"FooInterface\"), \"BarContract\": code.format(\"BarInterface\")}\n\n    global_compiled = compile_codes(codes, interface_codes=global_interface_codes)\n    local_compiled = compile_codes(codes, interface_codes=local_interface_codes)\n    assert global_compiled == local_compiled\n\n\ndef test_self_interface_is_allowed(get_contract):\n    code = \"\"\"\ninterface Bar:\n    def foo() -> uint256: view\n\n@external\ndef foo() -> uint256 :\n    return 42\n\n@external\ndef bar() -> uint256:\n    return Bar(self).foo()\n\"\"\"\n    c = get_contract(code)\n    assert c.bar() == 42\n\n\ndef test_self_interface_via_storage(get_contract):\n    code = \"\"\"\ninterface Bar:\n    def foo() -> uint256: view\n\nbar_contract: Bar\n\n@external\ndef __init__():\n    self.bar_contract = Bar(self)\n\n@external\ndef foo() -> uint256 :\n    return 42\n\n@external\ndef bar() -> uint256:\n    return self.bar_contract.foo()\n    \"\"\"\n    c = get_contract(code)\n    assert c.bar() == 42\n\n\ndef test_self_interface_via_calldata(get_contract):\n    code = \"\"\"\ninterface Bar:\n    def foo() -> uint256: view\n\n@external\ndef foo() -> uint256 :\n    return 42\n\n@external\ndef bar(a: address) -> uint256:\n    return Bar(a).foo()\n    \"\"\"\n    c = get_contract(code)\n    assert c.bar(c.address) == 42\n\n\ntype_str_params = [\n    (\"int128\", -33),\n    (\"uint256\", 42),\n    (\"bool\", True),\n    (\"address\", \"0x1234567890123456789012345678901234567890\"),\n    (\"bytes32\", b\"bytes32bytes32bytes32bytes32poop\"),\n    (\"decimal\", Decimal(\"3.1337\")),\n    (\"Bytes[4]\", b\"newp\"),\n    (\"String[6]\", \"potato\"),\n]\n\ninterface_test_code = \"\"\"\n@external\n@view\ndef test_json(a: {0}) -> {0}:\n    return a\n    \"\"\"\n\n\ndef convert_v1_abi(abi):\n    new_abi = []\n    for func_abi in abi:\n        if \"stateMutability\" in func_abi:\n            mutability = func_abi[\"stateMutability\"]\n            del func_abi[\"stateMutability\"]\n            if mutability == \"payable\":\n                func_abi[\"constant\"] = False\n                func_abi[\"payable\"] = True\n            elif mutability == \"view\":\n                func_abi[\"constant\"] = True\n                func_abi[\"payable\"] = False\n            elif mutability == \"pure\":\n                # NOTE: pure \"changes\" to \"view\"\n                func_abi[\"constant\"] = True\n                func_abi[\"payable\"] = False\n            else:  # \"nonpayable\"\n                func_abi[\"constant\"] = False\n                func_abi[\"payable\"] = False\n        else:  # Assume \"nonpayable\" by default\n            func_abi[\"constant\"] = False\n            func_abi[\"payable\"] = False\n        new_abi.append(func_abi)\n    return new_abi\n\n\n@pytest.mark.parametrize(\"type_str\", [i[0] for i in type_str_params])\ndef test_json_interface_implements(type_str):\n    code = interface_test_code.format(type_str)\n\n    abi = compile_code(code, [\"abi\"])[\"abi\"]\n    code = f\"import jsonabi as jsonabi\\nimplements: jsonabi\\n{code}\"\n    compile_code(code, interface_codes={\"jsonabi\": {\"type\": \"json\", \"code\": abi}})\n    compile_code(code, interface_codes={\"jsonabi\": {\"type\": \"json\", \"code\": convert_v1_abi(abi)}})\n\n\n@pytest.mark.parametrize(\"type_str,value\", type_str_params)\ndef test_json_interface_calls(get_contract, type_str, value):\n    code = interface_test_code.format(type_str)\n\n    abi = compile_code(code, [\"abi\"])[\"abi\"]\n    c1 = get_contract(code)\n\n    code = f\"\"\"\nimport jsonabi as jsonabi\n\n@external\n@view\ndef test_call(a: address, b: {type_str}) -> {type_str}:\n    return jsonabi(a).test_json(b)\n    \"\"\"\n    c2 = get_contract(code, interface_codes={\"jsonabi\": {\"type\": \"json\", \"code\": abi}})\n    assert c2.test_call(c1.address, value) == value\n    c3 = get_contract(\n        code, interface_codes={\"jsonabi\": {\"type\": \"json\", \"code\": convert_v1_abi(abi)}}\n    )\n    assert c3.test_call(c1.address, value) == value\n", "from vyper import ast as vy_ast\nfrom vyper.address_space import CALLDATA, DATA, IMMUTABLES, MEMORY, STORAGE\nfrom vyper.codegen.ir_node import Encoding, IRnode\nfrom vyper.codegen.types import (\n    DYNAMIC_ARRAY_OVERHEAD,\n    ArrayLike,\n    BaseType,\n    ByteArrayLike,\n    DArrayType,\n    MappingType,\n    SArrayType,\n    StructType,\n    TupleLike,\n    TupleType,\n    ceil32,\n    is_bytes_m_type,\n    is_decimal_type,\n    is_integer_type,\n)\nfrom vyper.evm.opcodes import version_check\nfrom vyper.exceptions import CompilerPanic, StructureException, TypeCheckFailure, TypeMismatch\nfrom vyper.utils import GAS_CALLDATACOPY_WORD, GAS_CODECOPY_WORD, GAS_IDENTITY, GAS_IDENTITYWORD\n\n\n# propagate revert message when calls to external contracts fail\ndef check_external_call(call_ir):\n    copy_revertdata = [\"returndatacopy\", 0, 0, \"returndatasize\"]\n    revert = [\"revert\", 0, \"returndatasize\"]\n\n    propagate_revert_ir = [\"seq\", copy_revertdata, revert]\n    return [\"if\", [\"iszero\", call_ir], propagate_revert_ir]\n\n\n# cost per byte of the identity precompile\ndef _identity_gas_bound(num_bytes):\n    return GAS_IDENTITY + GAS_IDENTITYWORD * (ceil32(num_bytes) // 32)\n\n\ndef _calldatacopy_gas_bound(num_bytes):\n    return GAS_CALLDATACOPY_WORD * ceil32(num_bytes) // 32\n\n\ndef _codecopy_gas_bound(num_bytes):\n    return GAS_CODECOPY_WORD * ceil32(num_bytes) // 32\n\n\n# Copy byte array word-for-word (including layout)\ndef make_byte_array_copier(dst, src):\n    assert isinstance(src.typ, ByteArrayLike)\n    assert isinstance(dst.typ, ByteArrayLike)\n\n    if src.typ.maxlen > dst.typ.maxlen:\n        raise TypeMismatch(f\"Cannot cast from {src.typ} to {dst.typ}\")\n    # stricter check for zeroing a byte array.\n    if src.value == \"~empty\" and src.typ.maxlen != dst.typ.maxlen:\n        raise TypeMismatch(\n            f\"Bad type for clearing bytes: expected {dst.typ} but got {src.typ}\"\n        )  # pragma: notest\n\n    if src.value == \"~empty\":\n        # set length word to 0.\n        return STORE(dst, 0)\n\n    with src.cache_when_complex(\"src\") as (b1, src):\n        with get_bytearray_length(src).cache_when_complex(\"len\") as (b2, len_):\n\n            max_bytes = src.typ.maxlen\n\n            ret = [\"seq\"]\n            # store length\n            ret.append(STORE(dst, len_))\n\n            dst = bytes_data_ptr(dst)\n            src = bytes_data_ptr(src)\n\n            ret.append(copy_bytes(dst, src, len_, max_bytes))\n            return b1.resolve(b2.resolve(ret))\n\n\ndef bytes_data_ptr(ptr):\n    if ptr.location is None:\n        raise CompilerPanic(\"tried to modify non-pointer type\")\n    assert isinstance(ptr.typ, ByteArrayLike)\n    return add_ofst(ptr, ptr.location.word_scale)\n\n\ndef dynarray_data_ptr(ptr):\n    if ptr.location is None:\n        raise CompilerPanic(\"tried to modify non-pointer type\")\n    assert isinstance(ptr.typ, DArrayType)\n    return add_ofst(ptr, ptr.location.word_scale)\n\n\ndef _dynarray_make_setter(dst, src):\n    assert isinstance(src.typ, DArrayType)\n    assert isinstance(dst.typ, DArrayType)\n\n    if src.value == \"~empty\":\n        return IRnode.from_list(STORE(dst, 0))\n\n    if src.value == \"multi\":\n        ret = [\"seq\"]\n        # handle literals\n\n        # write the length word\n        store_length = STORE(dst, len(src.args))\n        ann = None\n        if src.annotation is not None:\n            ann = f\"len({src.annotation})\"\n        store_length = IRnode.from_list(store_length, annotation=ann)\n        ret.append(store_length)\n\n        n_items = len(src.args)\n        for i in range(n_items):\n            k = IRnode.from_list(i, typ=\"uint256\")\n            dst_i = get_element_ptr(dst, k, array_bounds_check=False)\n            src_i = get_element_ptr(src, k, array_bounds_check=False)\n            ret.append(make_setter(dst_i, src_i))\n\n        return ret\n\n    with src.cache_when_complex(\"darray_src\") as (b1, src):\n\n        # for ABI-encoded dynamic data, we must loop to unpack, since\n        # the layout does not match our memory layout\n        should_loop = src.encoding == Encoding.ABI and src.typ.subtype.abi_type.is_dynamic()\n\n        # if the subtype is dynamic, there might be a lot of\n        # unused space inside of each element. for instance\n        # DynArray[DynArray[uint256, 100], 5] where all the child\n        # arrays are empty - for this case, we recursively call\n        # into make_setter instead of straight bytes copy\n        # TODO we can make this heuristic more precise, e.g.\n        # loop when subtype.is_dynamic AND location == storage\n        # OR array_size <= /bound where loop is cheaper than memcpy/\n        should_loop |= src.typ.subtype.abi_type.is_dynamic()\n        should_loop |= needs_clamp(src.typ.subtype, src.encoding)\n\n        with get_dyn_array_count(src).cache_when_complex(\"darray_count\") as (b2, count):\n            ret = [\"seq\"]\n\n            ret.append(STORE(dst, count))\n\n            if should_loop:\n                i = IRnode.from_list(_freshname(\"copy_darray_ix\"), typ=\"uint256\")\n\n                loop_body = make_setter(\n                    get_element_ptr(dst, i, array_bounds_check=False),\n                    get_element_ptr(src, i, array_bounds_check=False),\n                )\n                loop_body.annotation = f\"{dst}[i] = {src}[i]\"\n\n                ret.append([\"repeat\", i, 0, count, src.typ.count, loop_body])\n\n            else:\n                element_size = src.typ.subtype.memory_bytes_required\n                # number of elements * size of element in bytes\n                n_bytes = _mul(count, element_size)\n                max_bytes = src.typ.count * element_size\n\n                src_ = dynarray_data_ptr(src)\n                dst_ = dynarray_data_ptr(dst)\n                ret.append(copy_bytes(dst_, src_, n_bytes, max_bytes))\n\n            return b1.resolve(b2.resolve(ret))\n\n\n# Copy bytes\n# Accepts 4 arguments:\n# (i) an IR node for the start position of the source\n# (ii) an IR node for the start position of the destination\n# (iii) an IR node for the length (in bytes)\n# (iv) a constant for the max length (in bytes)\n# NOTE: may pad to ceil32 of `length`! If you ask to copy 1 byte, it may\n# copy an entire (32-byte) word, depending on the copy routine chosen.\n# TODO maybe always pad to ceil32, to reduce dirty bytes bugs\ndef copy_bytes(dst, src, length, length_bound):\n    annotation = f\"copy_bytes from {src} to {dst}\"\n\n    src = IRnode.from_list(src)\n    dst = IRnode.from_list(dst)\n    length = IRnode.from_list(length)\n\n    with src.cache_when_complex(\"src\") as (b1, src), length.cache_when_complex(\n        \"copy_bytes_count\"\n    ) as (b2, length), dst.cache_when_complex(\"dst\") as (b3, dst):\n\n        # fast code for common case where num bytes is small\n        # TODO expand this for more cases where num words is less than ~8\n        if length_bound <= 32:\n            copy_op = STORE(dst, LOAD(src))\n            ret = IRnode.from_list(copy_op, annotation=annotation)\n            return b1.resolve(b2.resolve(b3.resolve(ret)))\n\n        if dst.location == MEMORY and src.location in (MEMORY, CALLDATA, DATA):\n            # special cases: batch copy to memory\n            # TODO: iloadbytes\n            if src.location == MEMORY:\n                copy_op = [\"staticcall\", \"gas\", 4, src, length, dst, length]\n                gas_bound = _identity_gas_bound(length_bound)\n            elif src.location == CALLDATA:\n                copy_op = [\"calldatacopy\", dst, src, length]\n                gas_bound = _calldatacopy_gas_bound(length_bound)\n            elif src.location == DATA:\n                copy_op = [\"dloadbytes\", dst, src, length]\n                # note: dloadbytes compiles to CODECOPY\n                gas_bound = _codecopy_gas_bound(length_bound)\n\n            ret = IRnode.from_list(copy_op, annotation=annotation, add_gas_estimate=gas_bound)\n            return b1.resolve(b2.resolve(b3.resolve(ret)))\n\n        if dst.location == IMMUTABLES and src.location in (MEMORY, DATA):\n            # TODO istorebytes-from-mem, istorebytes-from-calldata(?)\n            # compile to identity, CODECOPY respectively.\n            pass\n\n        # general case, copy word-for-word\n        # pseudocode for our approach (memory-storage as example):\n        # for i in range(len, bound=MAX_LEN):\n        #   sstore(_dst + i, mload(src + i * 32))\n        i = IRnode.from_list(_freshname(\"copy_bytes_ix\"), typ=\"uint256\")\n\n        n = [\"div\", [\"ceil32\", length], 32]\n        n_bound = ceil32(length_bound) // 32\n\n        dst_i = add_ofst(dst, _mul(i, dst.location.word_scale))\n        src_i = add_ofst(src, _mul(i, src.location.word_scale))\n\n        copy_one_word = STORE(dst_i, LOAD(src_i))\n\n        main_loop = [\"repeat\", i, 0, n, n_bound, copy_one_word]\n\n        return b1.resolve(\n            b2.resolve(b3.resolve(IRnode.from_list(main_loop, annotation=annotation)))\n        )\n\n\n# get the number of bytes at runtime\ndef get_bytearray_length(arg):\n    typ = BaseType(\"uint256\")\n    return IRnode.from_list(LOAD(arg), typ=typ)\n\n\n# get the number of elements at runtime\ndef get_dyn_array_count(arg):\n    assert isinstance(arg.typ, DArrayType)\n\n    typ = BaseType(\"uint256\")\n\n    if arg.value == \"multi\":\n        return IRnode.from_list(len(arg.args), typ=typ)\n\n    if arg.value == \"~empty\":\n        # empty(DynArray[])\n        return IRnode.from_list(0, typ=typ)\n\n    return IRnode.from_list(LOAD(arg), typ=typ)\n\n\ndef append_dyn_array(darray_node, elem_node):\n    assert isinstance(darray_node.typ, DArrayType)\n\n    assert darray_node.typ.count > 0, \"jerk boy u r out\"\n\n    ret = [\"seq\"]\n    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):\n        len_ = get_dyn_array_count(darray_node)\n        with len_.cache_when_complex(\"old_darray_len\") as (b2, len_):\n            ret.append([\"assert\", [\"le\", len_, darray_node.typ.count - 1]])\n            ret.append(STORE(darray_node, [\"add\", len_, 1]))\n            # NOTE: typechecks elem_node\n            # NOTE skip array bounds check bc we already asserted len two lines up\n            ret.append(\n                make_setter(get_element_ptr(darray_node, len_, array_bounds_check=False), elem_node)\n            )\n            return IRnode.from_list(b1.resolve(b2.resolve(ret)))\n\n\ndef pop_dyn_array(darray_node, return_popped_item):\n    assert isinstance(darray_node.typ, DArrayType)\n    ret = [\"seq\"]\n    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):\n        old_len = [\"clamp_nonzero\", get_dyn_array_count(darray_node)]\n        new_len = IRnode.from_list([\"sub\", old_len, 1], typ=\"uint256\")\n\n        with new_len.cache_when_complex(\"new_len\") as (b2, new_len):\n            ret.append(STORE(darray_node, new_len))\n\n            # NOTE skip array bounds check bc we already asserted len two lines up\n            if return_popped_item:\n                popped_item = get_element_ptr(darray_node, new_len, array_bounds_check=False)\n                ret.append(popped_item)\n                typ = popped_item.typ\n                location = popped_item.location\n                encoding = popped_item.encoding\n            else:\n                typ, location, encoding = None, None, None\n            return IRnode.from_list(\n                b1.resolve(b2.resolve(ret)), typ=typ, location=location, encoding=encoding\n            )\n\n\ndef getpos(node):\n    return (\n        node.lineno,\n        node.col_offset,\n        getattr(node, \"end_lineno\", None),\n        getattr(node, \"end_col_offset\", None),\n    )\n\n\n# add an offset to a pointer, keeping location and encoding info\ndef add_ofst(ptr, ofst):\n    ret = [\"add\", ptr, ofst]\n    return IRnode.from_list(ret, location=ptr.location, encoding=ptr.encoding)\n\n\n# shorthand util\ndef _mul(x, y):\n    ret = [\"mul\", x, y]\n    return IRnode.from_list(ret)\n\n\n# Resolve pointer locations for ABI-encoded data\ndef _getelemptr_abi_helper(parent, member_t, ofst, clamp=True):\n    member_abi_t = member_t.abi_type\n\n    # ABI encoding has length word and then pretends length is not there\n    # e.g. [[1,2]] is encoded as 0x01 <len> 0x20 <inner array ofst> <encode(inner array)>\n    # note that inner array ofst is 0x20, not 0x40.\n    if has_length_word(parent.typ):\n        parent = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)\n\n    ofst_ir = add_ofst(parent, ofst)\n\n    if member_abi_t.is_dynamic():\n        # double dereference, according to ABI spec\n        # TODO optimize special case: first dynamic item\n        # offset is statically known.\n        ofst_ir = add_ofst(parent, unwrap_location(ofst_ir))\n\n    return IRnode.from_list(\n        ofst_ir,\n        typ=member_t,\n        location=parent.location,\n        encoding=parent.encoding,\n        annotation=f\"{parent}{ofst}\",\n    )\n\n\n# TODO simplify this code, especially the ABI decoding\ndef _get_element_ptr_tuplelike(parent, key):\n    typ = parent.typ\n    assert isinstance(typ, TupleLike)\n\n    if isinstance(typ, StructType):\n        assert isinstance(key, str)\n        subtype = typ.members[key]\n        attrs = list(typ.tuple_keys())\n        index = attrs.index(key)\n        annotation = key\n    else:\n        assert isinstance(key, int)\n        subtype = typ.members[key]\n        attrs = list(range(len(typ.members)))\n        index = key\n        annotation = None\n\n    # generated by empty() + make_setter\n    if parent.value == \"~empty\":\n        return IRnode.from_list(\"~empty\", typ=subtype)\n\n    if parent.value == \"multi\":\n        assert parent.encoding != Encoding.ABI, \"no abi-encoded literals\"\n        return parent.args[index]\n\n    ofst = 0  # offset from parent start\n\n    if parent.encoding == Encoding.ABI:\n        if parent.location == STORAGE:\n            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest\n\n        member_t = typ.members[attrs[index]]\n\n        for i in range(index):\n            member_abi_t = typ.members[attrs[i]].abi_type\n            ofst += member_abi_t.embedded_static_size()\n\n        return _getelemptr_abi_helper(parent, member_t, ofst)\n\n    if parent.location.word_addressable:\n        for i in range(index):\n            ofst += typ.members[attrs[i]].storage_size_in_words\n    elif parent.location.byte_addressable:\n        for i in range(index):\n            ofst += typ.members[attrs[i]].memory_bytes_required\n    else:\n        raise CompilerPanic(f\"bad location {parent.location}\")  # pragma: notest\n\n    return IRnode.from_list(\n        add_ofst(parent, ofst),\n        typ=subtype,\n        location=parent.location,\n        encoding=parent.encoding,\n        annotation=annotation,\n    )\n\n\ndef has_length_word(typ):\n    return isinstance(typ, (DArrayType, ByteArrayLike))\n\n\n# TODO simplify this code, especially the ABI decoding\ndef _get_element_ptr_array(parent, key, array_bounds_check):\n\n    assert isinstance(parent.typ, ArrayLike)\n\n    if not is_integer_type(key.typ):\n        raise TypeCheckFailure(f\"{key.typ} used as array index\")\n\n    subtype = parent.typ.subtype\n\n    if parent.value == \"~empty\":\n        if array_bounds_check:\n            # this case was previously missing a bounds check. codegen\n            # is a bit complicated when bounds check is required, so\n            # block it. there is no reason to index into a literal empty\n            # array anyways!\n            raise TypeCheckFailure(\"indexing into zero array not allowed\")\n        return IRnode.from_list(\"~empty\", subtype)\n\n    if parent.value == \"multi\":\n        assert isinstance(key.value, int)\n        return parent.args[key.value]\n\n    ix = unwrap_location(key)\n\n    if array_bounds_check:\n        # clamplt works, even for signed ints. since two's-complement\n        # is used, if the index is negative, (unsigned) LT will interpret\n        # it as a very large number, larger than any practical value for\n        # an array index, and the clamp will throw an error.\n        clamp_op = \"uclamplt\"\n        is_darray = isinstance(parent.typ, DArrayType)\n        bound = get_dyn_array_count(parent) if is_darray else parent.typ.count\n        # NOTE: there are optimization rules for this when ix or bound is literal\n        ix = IRnode.from_list([clamp_op, ix, bound], typ=ix.typ)\n\n    if parent.encoding == Encoding.ABI:\n        if parent.location == STORAGE:\n            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest\n\n        member_abi_t = subtype.abi_type\n\n        ofst = _mul(ix, member_abi_t.embedded_static_size())\n\n        return _getelemptr_abi_helper(parent, subtype, ofst)\n\n    if parent.location.word_addressable:\n        element_size = subtype.storage_size_in_words\n    elif parent.location.byte_addressable:\n        element_size = subtype.memory_bytes_required\n    else:\n        raise CompilerPanic(\"unreachable\")  # pragma: notest\n\n    ofst = _mul(ix, element_size)\n\n    if has_length_word(parent.typ):\n        data_ptr = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)\n    else:\n        data_ptr = parent\n\n    return IRnode.from_list(add_ofst(data_ptr, ofst), typ=subtype, location=parent.location)\n\n\ndef _get_element_ptr_mapping(parent, key):\n    assert isinstance(parent.typ, MappingType)\n    subtype = parent.typ.valuetype\n    key = unwrap_location(key)\n\n    # TODO when is key None?\n    if key is None or parent.location != STORAGE:\n        raise TypeCheckFailure(\"bad dereference on mapping {parent}[{sub}]\")\n\n    return IRnode.from_list([\"sha3_64\", parent, key], typ=subtype, location=STORAGE)\n\n\n# Take a value representing a memory or storage location, and descend down to\n# an element or member variable\n# This is analogous (but not necessarily equivalent to) getelementptr in LLVM.\ndef get_element_ptr(parent, key, array_bounds_check=True):\n    with parent.cache_when_complex(\"val\") as (b, parent):\n        typ = parent.typ\n\n        if isinstance(typ, TupleLike):\n            ret = _get_element_ptr_tuplelike(parent, key)\n\n        elif isinstance(typ, MappingType):\n            ret = _get_element_ptr_mapping(parent, key)\n\n        elif isinstance(typ, ArrayLike):\n            ret = _get_element_ptr_array(parent, key, array_bounds_check)\n\n        else:\n            raise CompilerPanic(f\"get_element_ptr cannot be called on {typ}\")  # pragma: notest\n\n        return b.resolve(ret)\n\n\ndef LOAD(ptr: IRnode) -> IRnode:\n    if ptr.location is None:\n        raise CompilerPanic(\"cannot dereference non-pointer type\")\n    op = ptr.location.load_op\n    if op is None:\n        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest\n    return IRnode.from_list([op, ptr])\n\n\ndef STORE(ptr: IRnode, val: IRnode) -> IRnode:\n    if ptr.location is None:\n        raise CompilerPanic(\"cannot dereference non-pointer type\")\n    op = ptr.location.store_op\n    if op is None:\n        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest\n    return IRnode.from_list([op, ptr, val])\n\n\n# Unwrap location\ndef unwrap_location(orig):\n    if orig.location is not None:\n        return IRnode.from_list(LOAD(orig), typ=orig.typ)\n    else:\n        # CMC 2022-03-24 TODO refactor so this branch can be removed\n        if orig.value == \"~empty\":\n            return IRnode.from_list(0, typ=orig.typ)\n        return orig\n\n\n# utility function, constructs an IR tuple out of a list of IR nodes\ndef ir_tuple_from_args(args):\n    typ = TupleType([x.typ for x in args])\n    return IRnode.from_list([\"multi\"] + [x for x in args], typ=typ)\n\n\ndef _needs_external_call_wrap(ir_typ):\n    # for calls to ABI conforming contracts.\n    # according to the ABI spec, return types are ALWAYS tuples even\n    # if only one element is being returned.\n    # https://solidity.readthedocs.io/en/latest/abi-spec.html#function-selector-and-argument-encoding\n    # \"and the return values v_1, ..., v_k of f are encoded as\n    #\n    #    enc((v_1, ..., v_k))\n    #    i.e. the values are combined into a tuple and encoded.\n    # \"\n    # therefore, wrap it in a tuple if it's not already a tuple.\n    # for example, `bytes` is returned as abi-encoded (bytes,)\n    # and `(bytes,)` is returned as abi-encoded ((bytes,),)\n    # In general `-> X` gets returned as (X,)\n    # including structs. MyStruct is returned as abi-encoded (MyStruct,).\n    # (Sorry this is so confusing. I didn't make these rules.)\n\n    return not (isinstance(ir_typ, TupleType) and len(ir_typ.members) > 1)\n\n\ndef calculate_type_for_external_return(ir_typ):\n    if _needs_external_call_wrap(ir_typ):\n        return TupleType([ir_typ])\n    return ir_typ\n\n\ndef wrap_value_for_external_return(ir_val):\n    # used for LHS promotion\n    if _needs_external_call_wrap(ir_val.typ):\n        return ir_tuple_from_args([ir_val])\n    else:\n        return ir_val\n\n\ndef set_type_for_external_return(ir_val):\n    # used for RHS promotion\n    ir_val.typ = calculate_type_for_external_return(ir_val.typ)\n\n\n# return a dummy IRnode with the given type\ndef dummy_node_for_type(typ):\n    return IRnode(\"fake_node\", typ=typ)\n\n\ndef _check_assign_bytes(left, right):\n    if right.typ.maxlen > left.typ.maxlen:\n        raise TypeMismatch(f\"Cannot cast from {right.typ} to {left.typ}\")  # pragma: notest\n    # stricter check for zeroing a byte array.\n    if right.value == \"~empty\" and right.typ.maxlen != left.typ.maxlen:\n        raise TypeMismatch(\n            f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"\n        )  # pragma: notest\n\n\ndef _check_assign_list(left, right):\n    def FAIL():  # pragma: nocover\n        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")\n\n    if left.value == \"multi\":\n        # Cannot do something like [a, b, c] = [1, 2, 3]\n        FAIL()  # pragma: notest\n\n    if isinstance(left, SArrayType):\n        if not isinstance(right, SArrayType):\n            FAIL()  # pragma: notest\n        if left.typ.count != right.typ.count:\n            FAIL()  # pragma: notest\n\n        # TODO recurse into left, right if literals?\n        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))\n\n    if isinstance(left, DArrayType):\n        if not isinstance(right, DArrayType):\n            FAIL()  # pragma: notest\n\n        if left.typ.count < right.typ.count:\n            FAIL()  # pragma: notest\n\n        # stricter check for zeroing\n        if right.value == \"~empty\" and right.typ.count != left.typ.count:\n            raise TypeCheckFailure(\n                f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"\n            )  # pragma: notest\n\n        # TODO recurse into left, right if literals?\n        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))\n\n\ndef _check_assign_tuple(left, right):\n    def FAIL():  # pragma: nocover\n        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")\n\n    if not isinstance(right.typ, left.typ.__class__):\n        FAIL()  # pragma: notest\n\n    if isinstance(left.typ, StructType):\n        for k in left.typ.members:\n            if k not in right.typ.members:\n                FAIL()  # pragma: notest\n            # TODO recurse into left, right if literals?\n            check_assign(\n                dummy_node_for_type(left.typ.members[k]),\n                dummy_node_for_type(right.typ.members[k]),\n            )\n\n        for k in right.typ.members:\n            if k not in left.typ.members:\n                FAIL()  # pragma: notest\n\n        if left.typ.name != right.typ.name:\n            FAIL()  # pragma: notest\n\n    else:\n        if len(left.typ.members) != len(right.typ.members):\n            FAIL()  # pragma: notest\n        for (l, r) in zip(left.typ.members, right.typ.members):\n            # TODO recurse into left, right if literals?\n            check_assign(dummy_node_for_type(l), dummy_node_for_type(r))\n\n\n# sanity check an assignment\n# typechecking source code is done at an earlier phase\n# this function is more of a sanity check for typechecking internally\n# generated assignments\ndef check_assign(left, right):\n    def FAIL():  # pragma: nocover\n        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ} {left} {right}\")\n\n    if isinstance(left.typ, ByteArrayLike):\n        _check_assign_bytes(left, right)\n    elif isinstance(left.typ, ArrayLike):\n        _check_assign_list(left, right)\n    elif isinstance(left.typ, TupleLike):\n        _check_assign_tuple(left, right)\n\n    elif isinstance(left.typ, BaseType):\n        # TODO once we propagate types from typechecker, introduce this check:\n        # if left.typ != right.typ:\n        #    FAIL()  # pragma: notest\n        pass\n\n    else:  # pragma: nocover\n        FAIL()\n\n\n_label = 0\n\n\n# TODO might want to coalesce with Context.fresh_varname and compile_ir.mksymbol\ndef _freshname(name):\n    global _label\n    _label += 1\n    return f\"{name}{_label}\"\n\n\n# returns True if t is ABI encoded and is a type that needs any kind of\n# validation\ndef needs_clamp(t, encoding):\n    if encoding == Encoding.VYPER:\n        return False\n    if encoding != Encoding.ABI:\n        raise CompilerPanic(\"unreachable\")  # pragma: notest\n    if isinstance(t, (ByteArrayLike, DArrayType)):\n        return True\n    if isinstance(t, BaseType):\n        return t.typ not in (\"int256\", \"uint256\", \"bytes32\")\n    if isinstance(t, SArrayType):\n        return needs_clamp(t.subtype, encoding)\n    if isinstance(t, TupleLike):\n        return any(needs_clamp(m, encoding) for m in t.tuple_members())\n\n    raise CompilerPanic(\"unreachable\")  # pragma: notest\n\n\n# Create an x=y statement, where the types may be compound\ndef make_setter(left, right):\n    check_assign(left, right)\n\n    # Basic types\n    if isinstance(left.typ, BaseType):\n        enc = right.encoding  # unwrap_location butchers encoding\n        right = unwrap_location(right)\n        # TODO rethink/streamline the clamp_basetype logic\n        if needs_clamp(right.typ, enc):\n            right = clamp_basetype(right)\n\n        return STORE(left, right)\n\n    # Byte arrays\n    elif isinstance(left.typ, ByteArrayLike):\n        # TODO rethink/streamline the clamp_basetype logic\n        if needs_clamp(right.typ, right.encoding):\n            with right.cache_when_complex(\"bs_ptr\") as (b, right):\n                copier = make_byte_array_copier(left, right)\n                ret = b.resolve([\"seq\", clamp_bytestring(right), copier])\n        else:\n            ret = make_byte_array_copier(left, right)\n\n        return IRnode.from_list(ret)\n\n    elif isinstance(left.typ, DArrayType):\n        # TODO should we enable this?\n        # implicit conversion from sarray to darray\n        # if isinstance(right.typ, SArrayType):\n        #    return _complex_make_setter(left, right)\n\n        # TODO rethink/streamline the clamp_basetype logic\n        if needs_clamp(right.typ, right.encoding):\n            with right.cache_when_complex(\"arr_ptr\") as (b, right):\n                copier = _dynarray_make_setter(left, right)\n                ret = b.resolve([\"seq\", clamp_dyn_array(right), copier])\n        else:\n            ret = _dynarray_make_setter(left, right)\n\n        return IRnode.from_list(ret)\n\n    # Arrays\n    elif isinstance(left.typ, (SArrayType, TupleLike)):\n        return _complex_make_setter(left, right)\n\n\ndef _complex_make_setter(left, right):\n    if right.value == \"~empty\" and left.location == MEMORY:\n        # optimized memzero\n        return mzero(left, left.typ.memory_bytes_required)\n\n    ret = [\"seq\"]\n\n    if isinstance(left.typ, SArrayType):\n        n_items = right.typ.count\n        keys = [IRnode.from_list(i, typ=\"uint256\") for i in range(n_items)]\n\n    if isinstance(left.typ, TupleLike):\n        keys = left.typ.tuple_keys()\n\n    # if len(keyz) == 0:\n    #    return IRnode.from_list([\"pass\"])\n\n    # general case\n    # TODO use copy_bytes when the generated code is above a certain size\n    with left.cache_when_complex(\"_L\") as (b1, left), right.cache_when_complex(\"_R\") as (b2, right):\n\n        for k in keys:\n            l_i = get_element_ptr(left, k, array_bounds_check=False)\n            r_i = get_element_ptr(right, k, array_bounds_check=False)\n            ret.append(make_setter(l_i, r_i))\n\n        return b1.resolve(b2.resolve(IRnode.from_list(ret)))\n\n\ndef ensure_in_memory(ir_var, context):\n    \"\"\"Ensure a variable is in memory. This is useful for functions\n    which expect to operate on memory variables.\n    \"\"\"\n    if ir_var.location == MEMORY:\n        return ir_var\n\n    typ = ir_var.typ\n    buf = IRnode.from_list(context.new_internal_variable(typ), typ=typ, location=MEMORY)\n    do_copy = make_setter(buf, ir_var)\n\n    return IRnode.from_list([\"seq\", do_copy, buf], typ=typ, location=MEMORY)\n\n\ndef eval_seq(ir_node):\n    \"\"\"Tries to find the \"return\" value of a `seq` statement, in order so\n    that the value can be known without possibly evaluating side effects\n    \"\"\"\n    if ir_node.value in (\"seq\", \"with\") and len(ir_node.args) > 0:\n        return eval_seq(ir_node.args[-1])\n    if isinstance(ir_node.value, int):\n        return IRnode.from_list(ir_node)\n    return None\n\n\n# TODO move return checks to vyper/semantics/validation\ndef is_return_from_function(node):\n    if isinstance(node, vy_ast.Expr) and node.get(\"value.func.id\") == \"selfdestruct\":\n        return True\n    if isinstance(node, vy_ast.Return):\n        return True\n    elif isinstance(node, vy_ast.Raise):\n        return True\n    else:\n        return False\n\n\ndef check_single_exit(fn_node):\n    _check_return_body(fn_node, fn_node.body)\n    for node in fn_node.get_descendants(vy_ast.If):\n        _check_return_body(node, node.body)\n        if node.orelse:\n            _check_return_body(node, node.orelse)\n\n\ndef _check_return_body(node, node_list):\n    return_count = len([n for n in node_list if is_return_from_function(n)])\n    if return_count > 1:\n        raise StructureException(\n            \"Too too many exit statements (return, raise or selfdestruct).\", node\n        )\n    # Check for invalid code after returns.\n    last_node_pos = len(node_list) - 1\n    for idx, n in enumerate(node_list):\n        if is_return_from_function(n) and idx < last_node_pos:\n            # is not last statement in body.\n            raise StructureException(\n                \"Exit statement with succeeding code (that will not execute).\", node_list[idx + 1]\n            )\n\n\ndef mzero(dst, nbytes):\n    # calldatacopy from past-the-end gives zero bytes.\n    # cf. YP H.2 (ops section) with CALLDATACOPY spec.\n    return IRnode.from_list(\n        # calldatacopy mempos calldatapos len\n        [\"calldatacopy\", dst, \"calldatasize\", nbytes],\n        annotation=\"mzero\",\n    )\n\n\n# zero pad a bytearray according to the ABI spec. The last word\n# of the byte array needs to be right-padded with zeroes.\ndef zero_pad(bytez_placeholder):\n    len_ = [\"mload\", bytez_placeholder]\n    dst = [\"add\", [\"add\", bytez_placeholder, 32], \"len\"]\n    # the runtime length of the data rounded up to nearest 32\n    # from spec:\n    #   the actual value of X as a byte sequence,\n    #   followed by the *minimum* number of zero-bytes\n    #   such that len(enc(X)) is a multiple of 32.\n    num_zero_bytes = [\"sub\", [\"ceil32\", \"len\"], \"len\"]\n    return IRnode.from_list(\n        [\"with\", \"len\", len_, [\"with\", \"dst\", dst, mzero(\"dst\", num_zero_bytes)]],\n        annotation=\"Zero pad\",\n    )\n\n\n# convenience rewrites for shr/sar/shl\ndef shr(bits, x):\n    if version_check(begin=\"constantinople\"):\n        return [\"shr\", bits, x]\n    return [\"div\", x, [\"exp\", 2, bits]]\n\n\n# convenience rewrites for shr/sar/shl\ndef shl(bits, x):\n    if version_check(begin=\"constantinople\"):\n        return [\"shl\", bits, x]\n    return [\"mul\", x, [\"exp\", 2, bits]]\n\n\ndef sar(bits, x):\n    if version_check(begin=\"constantinople\"):\n        return [\"sar\", bits, x]\n\n    # emulate for older arches. keep in mind note from EIP 145:\n    # \"This is not equivalent to PUSH1 2 EXP SDIV, since it rounds\n    # differently. See SDIV(-1, 2) == 0, while SAR(-1, 1) == -1.\"\n    return [\"sdiv\", [\"add\", [\"slt\", x, 0], x], [\"exp\", 2, bits]]\n\n\ndef clamp_bytestring(ir_node):\n    t = ir_node.typ\n    if not isinstance(t, ByteArrayLike):\n        raise CompilerPanic(f\"{t} passed to clamp_bytestring\")  # pragma: notest\n    return [\"assert\", [\"le\", get_bytearray_length(ir_node), t.maxlen]]\n\n\ndef clamp_dyn_array(ir_node):\n    t = ir_node.typ\n    assert isinstance(t, DArrayType)\n    return [\"assert\", [\"le\", get_dyn_array_count(ir_node), t.count]]\n\n\n# clampers for basetype\ndef clamp_basetype(ir_node):\n    t = ir_node.typ\n    if not isinstance(t, BaseType):\n        raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest\n\n    # copy of the input\n    ir_node = unwrap_location(ir_node)\n\n    if is_integer_type(t) or is_decimal_type(t):\n        if t._num_info.bits == 256:\n            return ir_node\n        else:\n            return int_clamp(ir_node, t._num_info.bits, signed=t._num_info.is_signed)\n\n    if is_bytes_m_type(t):\n        if t._bytes_info.m == 32:\n            return ir_node  # special case, no clamp.\n        else:\n            return bytes_clamp(ir_node, t._bytes_info.m)\n\n    if t.typ in (\"address\",):\n        return int_clamp(ir_node, 160)\n    if t.typ in (\"bool\",):\n        return int_clamp(ir_node, 1)\n\n    raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest\n\n\ndef int_clamp(ir_node, bits, signed=False):\n    \"\"\"Generalized clamper for integer types. Takes the number of bits,\n    whether it's signed, and returns an IR node which checks it is\n    in bounds. (Consumers should use clamp_basetype instead which uses\n    type-based dispatch and is a little safer.)\n    \"\"\"\n    if bits >= 256:\n        raise CompilerPanic(f\"invalid clamp: {bits}>=256 ({ir_node})\")  # pragma: notest\n    with ir_node.cache_when_complex(\"val\") as (b, val):\n        if signed:\n            # example for bits==128:\n            # promote_signed_int(val, bits) is the \"canonical\" version of val\n            # if val is in bounds, the bits above bit 128 should be equal.\n            # (this works for both val >= 0 and val < 0. in the first case,\n            # all upper bits should be 0 if val is a valid int128,\n            # in the latter case, all upper bits should be 1.)\n            assertion = [\"assert\", [\"eq\", val, promote_signed_int(val, bits)]]\n        else:\n            assertion = [\"assert\", [\"iszero\", shr(bits, val)]]\n\n        ret = b.resolve([\"seq\", assertion, val])\n\n    # TODO fix this annotation\n    return IRnode.from_list(ret, annotation=f\"int_clamp {ir_node.typ}\")\n\n\ndef bytes_clamp(ir_node: IRnode, n_bytes: int) -> IRnode:\n    if not (0 < n_bytes <= 32):\n        raise CompilerPanic(f\"bad type: bytes{n_bytes}\")\n    with ir_node.cache_when_complex(\"val\") as (b, val):\n        assertion = [\"assert\", [\"iszero\", shl(n_bytes * 8, val)]]\n        ret = b.resolve([\"seq\", assertion, val])\n    return IRnode.from_list(ret, annotation=f\"bytes{n_bytes}_clamp\")\n\n\n# e.g. for int8, promote 255 to -1\ndef promote_signed_int(x, bits):\n    assert bits % 8 == 0\n    ret = [\"signextend\", bits // 8 - 1, x]\n    return IRnode.from_list(ret, annotation=f\"promote int{bits}\")\n", "import vyper.utils as util\nfrom vyper.address_space import MEMORY\nfrom vyper.codegen.abi_encoder import abi_encode\nfrom vyper.codegen.core import (\n    calculate_type_for_external_return,\n    check_assign,\n    check_external_call,\n    dummy_node_for_type,\n    make_setter,\n    needs_clamp,\n)\nfrom vyper.codegen.ir_node import Encoding, IRnode\nfrom vyper.codegen.types import InterfaceType, TupleType, get_type_for_exact_size\nfrom vyper.codegen.types.convert import new_type_to_old_type\nfrom vyper.exceptions import StateAccessViolation, TypeCheckFailure\n\n\ndef _pack_arguments(contract_sig, args, context):\n    # abi encoding just treats all args as a big tuple\n    args_tuple_t = TupleType([x.typ for x in args])\n    args_as_tuple = IRnode.from_list([\"multi\"] + [x for x in args], typ=args_tuple_t)\n    args_abi_t = args_tuple_t.abi_type\n\n    # sanity typecheck - make sure the arguments can be assigned\n    dst_tuple_t = TupleType([arg.typ for arg in contract_sig.args][: len(args)])\n    check_assign(dummy_node_for_type(dst_tuple_t), args_as_tuple)\n\n    if contract_sig.return_type is not None:\n        return_abi_t = calculate_type_for_external_return(contract_sig.return_type).abi_type\n\n        # we use the same buffer for args and returndata,\n        # so allocate enough space here for the returndata too.\n        buflen = max(args_abi_t.size_bound(), return_abi_t.size_bound())\n    else:\n        buflen = args_abi_t.size_bound()\n\n    buflen += 32  # padding for the method id\n\n    buf_t = get_type_for_exact_size(buflen)\n    buf = context.new_internal_variable(buf_t)\n\n    args_ofst = buf + 28\n    args_len = args_abi_t.size_bound() + 4\n\n    abi_signature = contract_sig.name + dst_tuple_t.abi_type.selector_name()\n\n    # layout:\n    # 32 bytes                 | args\n    # 0x..00<method_id_4bytes> | args\n    # the reason for the left padding is just so the alignment is easier.\n    # if we were only targeting constantinople, we could align\n    # to buf (and also keep code size small) by using\n    # (mstore buf (shl signature.method_id 224))\n    mstore_method_id = [[\"mstore\", buf, util.abi_method_id(abi_signature)]]\n\n    if len(args) == 0:\n        encode_args = [\"pass\"]\n    else:\n        encode_args = abi_encode(buf + 32, args_as_tuple, context, bufsz=buflen)\n\n    return buf, mstore_method_id + [encode_args], args_ofst, args_len\n\n\ndef _unpack_returndata(buf, contract_sig, skip_contract_check, context, expr):\n    # expr.func._metadata[\"type\"].return_type is more accurate\n    # than contract_sig.return_type in the case of JSON interfaces.\n    ast_return_t = expr.func._metadata[\"type\"].return_type\n\n    if ast_return_t is None:\n        return [\"pass\"], 0, 0\n\n    # sanity check\n    return_t = new_type_to_old_type(ast_return_t)\n    check_assign(dummy_node_for_type(return_t), dummy_node_for_type(contract_sig.return_type))\n\n    return_t = calculate_type_for_external_return(return_t)\n\n    abi_return_t = return_t.abi_type\n\n    min_return_size = abi_return_t.min_size()\n    max_return_size = abi_return_t.size_bound()\n    assert 0 < min_return_size <= max_return_size\n\n    ret_ofst = buf\n    ret_len = max_return_size\n\n    # revert when returndatasize is not in bounds\n    ret = []\n    # runtime: min_return_size <= returndatasize\n    if not skip_contract_check:\n        ret += [[\"assert\", [\"ge\", \"returndatasize\", min_return_size]]]\n\n    encoding = Encoding.ABI\n\n    buf = IRnode.from_list(\n        buf,\n        typ=return_t,\n        location=MEMORY,\n        encoding=encoding,\n        annotation=f\"{expr.node_source_code} returndata buffer\",\n    )\n\n    assert isinstance(return_t, TupleType)\n    # unpack strictly\n    if needs_clamp(return_t, encoding):\n        buf2 = IRnode.from_list(\n            context.new_internal_variable(return_t), typ=return_t, location=MEMORY\n        )\n\n        ret.append(make_setter(buf2, buf))\n        ret.append(buf2)\n    else:\n        ret.append(buf)\n\n    return ret, ret_ofst, ret_len\n\n\ndef _external_call_helper(\n    contract_address,\n    contract_sig,\n    args_ir,\n    context,\n    value=None,\n    gas=None,\n    skip_contract_check=None,\n    expr=None,\n):\n\n    if value is None:\n        value = 0\n    if gas is None:\n        gas = \"gas\"\n    if skip_contract_check is None:\n        skip_contract_check = False\n\n    # sanity check\n    assert len(contract_sig.base_args) <= len(args_ir) <= len(contract_sig.args)\n\n    if context.is_constant() and contract_sig.mutability not in (\"view\", \"pure\"):\n        # TODO is this already done in type checker?\n        raise StateAccessViolation(\n            f\"May not call state modifying function '{contract_sig.name}' \"\n            f\"within {context.pp_constancy()}.\",\n            expr,\n        )\n\n    sub = [\"seq\"]\n\n    buf, arg_packer, args_ofst, args_len = _pack_arguments(contract_sig, args_ir, context)\n\n    ret_unpacker, ret_ofst, ret_len = _unpack_returndata(\n        buf, contract_sig, skip_contract_check, context, expr\n    )\n\n    sub += arg_packer\n\n    if contract_sig.return_type is None and not skip_contract_check:\n        # if we do not expect return data, check that a contract exists at the\n        # target address. we must perform this check BEFORE the call because\n        # the contract might selfdestruct. on the other hand we can omit this\n        # when we _do_ expect return data because we later check\n        # `returndatasize` (that check works even if the contract\n        # selfdestructs).\n        sub.append([\"assert\", [\"extcodesize\", contract_address]])\n\n    if context.is_constant() or contract_sig.mutability in (\"view\", \"pure\"):\n        call_op = [\"staticcall\", gas, contract_address, args_ofst, args_len, ret_ofst, ret_len]\n    else:\n        call_op = [\"call\", gas, contract_address, value, args_ofst, args_len, ret_ofst, ret_len]\n\n    sub.append(check_external_call(call_op))\n\n    if contract_sig.return_type is not None:\n        sub += ret_unpacker\n\n    return IRnode.from_list(sub, typ=contract_sig.return_type, location=MEMORY)\n\n\ndef _get_special_kwargs(stmt_expr, context):\n    from vyper.codegen.expr import Expr  # TODO rethink this circular import\n\n    value, gas, skip_contract_check = None, None, None\n    for kw in stmt_expr.keywords:\n        if kw.arg == \"gas\":\n            gas = Expr.parse_value_expr(kw.value, context)\n        elif kw.arg == \"value\":\n            value = Expr.parse_value_expr(kw.value, context)\n        elif kw.arg == \"skip_contract_check\":\n            skip_contract_check = kw.value.value\n            assert isinstance(skip_contract_check, bool), \"type checker missed this\"\n        else:\n            raise TypeCheckFailure(\"Unexpected keyword argument\")\n\n    # TODO maybe return a small dataclass to reduce verbosity\n    return value, gas, skip_contract_check\n\n\ndef ir_for_external_call(stmt_expr, context):\n    from vyper.codegen.expr import Expr  # TODO rethink this circular import\n\n    contract_address = Expr.parse_value_expr(stmt_expr.func.value, context)\n    value, gas, skip_contract_check = _get_special_kwargs(stmt_expr, context)\n    args_ir = [Expr(x, context).ir_node for x in stmt_expr.args]\n\n    assert isinstance(contract_address.typ, InterfaceType)\n    contract_name = contract_address.typ.name\n    method_name = stmt_expr.func.attr\n    contract_sig = context.sigs[contract_name][method_name]\n\n    ret = _external_call_helper(\n        contract_address,\n        contract_sig,\n        args_ir,\n        context,\n        value=value,\n        gas=gas,\n        skip_contract_check=skip_contract_check,\n        expr=stmt_expr,\n    )\n    ret.annotation = stmt_expr.get(\"node_source_code\")\n\n    return ret\n", "from typing import Any, List\n\nimport vyper.utils as util\nfrom vyper.address_space import CALLDATA, DATA, MEMORY\nfrom vyper.ast.signatures.function_signature import FunctionSignature, VariableRecord\nfrom vyper.codegen.abi_encoder import abi_encoding_matches_vyper\nfrom vyper.codegen.context import Context\nfrom vyper.codegen.core import get_element_ptr, getpos, make_setter, needs_clamp\nfrom vyper.codegen.expr import Expr\nfrom vyper.codegen.function_definitions.utils import get_nonreentrant_lock\nfrom vyper.codegen.ir_node import Encoding, IRnode\nfrom vyper.codegen.stmt import parse_body\nfrom vyper.codegen.types.types import TupleType\n\n\n# register function args with the local calling context.\n# also allocate the ones that live in memory (i.e. kwargs)\ndef _register_function_args(context: Context, sig: FunctionSignature) -> List[IRnode]:\n    ret = []\n\n    # the type of the calldata\n    base_args_t = TupleType([arg.typ for arg in sig.base_args])\n\n    # tuple with the abi_encoded args\n    if sig.is_init_func:\n        base_args_ofst = IRnode(0, location=DATA, typ=base_args_t, encoding=Encoding.ABI)\n    else:\n        base_args_ofst = IRnode(4, location=CALLDATA, typ=base_args_t, encoding=Encoding.ABI)\n\n    for i, arg in enumerate(sig.base_args):\n\n        arg_ir = get_element_ptr(base_args_ofst, i)\n\n        if needs_clamp(arg.typ, Encoding.ABI):\n            # allocate a memory slot for it and copy\n            p = context.new_variable(arg.name, arg.typ, is_mutable=False)\n            dst = IRnode(p, typ=arg.typ, location=MEMORY)\n\n            copy_arg = make_setter(dst, arg_ir)\n            copy_arg.source_pos = getpos(arg.ast_source)\n            ret.append(copy_arg)\n        else:\n            assert abi_encoding_matches_vyper(arg.typ)\n            # leave it in place\n            context.vars[arg.name] = VariableRecord(\n                name=arg.name,\n                pos=arg_ir,\n                typ=arg.typ,\n                mutable=False,\n                location=arg_ir.location,\n                encoding=Encoding.ABI,\n            )\n\n    return ret\n\n\ndef _annotated_method_id(abi_sig):\n    method_id = util.abi_method_id(abi_sig)\n    annotation = f\"{hex(method_id)}: {abi_sig}\"\n    return IRnode(method_id, annotation=annotation)\n\n\ndef _generate_kwarg_handlers(context: Context, sig: FunctionSignature) -> List[Any]:\n    # generate kwarg handlers.\n    # since they might come in thru calldata or be default,\n    # allocate them in memory and then fill it in based on calldata or default,\n    # depending on the signature\n    # a kwarg handler looks like\n    # (if (eq _method_id <method_id>)\n    #    copy calldata args to memory\n    #    write default args to memory\n    #    goto external_function_common_ir\n\n    def handler_for(calldata_kwargs, default_kwargs):\n        calldata_args = sig.base_args + calldata_kwargs\n        # create a fake type so that get_element_ptr works\n        calldata_args_t = TupleType(list(arg.typ for arg in calldata_args))\n\n        abi_sig = sig.abi_signature_for_kwargs(calldata_kwargs)\n        method_id = _annotated_method_id(abi_sig)\n\n        calldata_kwargs_ofst = IRnode(\n            4, location=CALLDATA, typ=calldata_args_t, encoding=Encoding.ABI\n        )\n\n        # a sequence of statements to strictify kwargs into memory\n        ret = [\"seq\"]\n\n        # TODO optimize make_setter by using\n        # TupleType(list(arg.typ for arg in calldata_kwargs + default_kwargs))\n        # (must ensure memory area is contiguous)\n\n        n_base_args = len(sig.base_args)\n\n        for i, arg_meta in enumerate(calldata_kwargs):\n            k = n_base_args + i\n\n            dst = context.lookup_var(arg_meta.name).pos\n\n            lhs = IRnode(dst, location=MEMORY, typ=arg_meta.typ)\n\n            rhs = get_element_ptr(calldata_kwargs_ofst, k, array_bounds_check=False)\n\n            copy_arg = make_setter(lhs, rhs)\n            copy_arg.source_pos = getpos(arg_meta.ast_source)\n            ret.append(copy_arg)\n\n        for x in default_kwargs:\n            dst = context.lookup_var(x.name).pos\n            lhs = IRnode(dst, location=MEMORY, typ=x.typ)\n            lhs.source_pos = getpos(x.ast_source)\n            kw_ast_val = sig.default_values[x.name]  # e.g. `3` in x: int = 3\n            rhs = Expr(kw_ast_val, context).ir_node\n\n            copy_arg = make_setter(lhs, rhs)\n            copy_arg.source_pos = getpos(x.ast_source)\n            ret.append(copy_arg)\n\n        ret.append([\"goto\", sig.external_function_base_entry_label])\n\n        ret = [\"if\", [\"eq\", \"_calldata_method_id\", method_id], ret]\n        return ret\n\n    ret = [\"seq\"]\n\n    keyword_args = sig.default_args\n\n    # allocate variable slots in memory\n    for arg in keyword_args:\n        context.new_variable(arg.name, arg.typ, is_mutable=False)\n\n    for i, _ in enumerate(keyword_args):\n        calldata_kwargs = keyword_args[:i]\n        default_kwargs = keyword_args[i:]\n\n        ret.append(handler_for(calldata_kwargs, default_kwargs))\n\n    ret.append(handler_for(keyword_args, []))\n\n    return ret\n\n\n# TODO it would be nice if this returned a data structure which were\n# amenable to generating a jump table instead of the linear search for\n# method_id we have now.\ndef generate_ir_for_external_function(code, sig, context, check_nonpayable):\n    # TODO type hints:\n    # def generate_ir_for_external_function(\n    #    code: vy_ast.FunctionDef, sig: FunctionSignature, context: Context, check_nonpayable: bool,\n    # ) -> IRnode:\n    \"\"\"Return the IR for an external function. Includes code to inspect the method_id,\n    enter the function (nonpayable and reentrancy checks), handle kwargs and exit\n    the function (clean up reentrancy storage variables)\n    \"\"\"\n    func_type = code._metadata[\"type\"]\n\n    nonreentrant_pre, nonreentrant_post = get_nonreentrant_lock(func_type)\n\n    # generate handlers for base args and register the variable records\n    handle_base_args = _register_function_args(context, sig)\n\n    # generate handlers for kwargs and register the variable records\n    kwarg_handlers = _generate_kwarg_handlers(context, sig)\n\n    body = [\"seq\"]\n    # once optional args have been handled,\n    # generate the main body of the function\n    body += handle_base_args\n\n    if check_nonpayable and sig.mutability != \"payable\":\n        # if the contract contains payable functions, but this is not one of them\n        # add an assertion that the value of the call is zero\n        body += [[\"assert\", [\"iszero\", \"callvalue\"]]]\n\n    body += nonreentrant_pre\n\n    body += [parse_body(code.body, context, ensure_terminated=True)]\n\n    # wrap the body in labeled block\n    body = [\"label\", sig.external_function_base_entry_label, [\"var_list\"], body]\n\n    exit_sequence = [\"seq\"] + nonreentrant_post\n    if sig.is_init_func:\n        pass  # init func has special exit sequence generated by module.py\n    elif context.return_type is None:\n        exit_sequence += [[\"stop\"]]\n    else:\n        exit_sequence += [[\"return\", \"ret_ofst\", \"ret_len\"]]\n\n    exit_sequence_args = [\"var_list\"]\n    if context.return_type is not None:\n        exit_sequence_args += [\"ret_ofst\", \"ret_len\"]\n    # wrap the exit in a labeled block\n    exit = [\"label\", sig.exit_sequence_label, exit_sequence_args, exit_sequence]\n\n    # the ir which comprises the main body of the function,\n    # besides any kwarg handling\n    func_common_ir = [\"seq\", body, exit]\n\n    if sig.is_default_func or sig.is_init_func:\n        ret = [\"seq\"]\n        # add a goto to make the function entry look like other functions\n        # (for zksync interpreter)\n        ret.append([\"goto\", sig.external_function_base_entry_label])\n        ret.append(func_common_ir)\n    else:\n        ret = kwarg_handlers\n        # sneak the base code into the kwarg handler\n        # TODO rethink this / make it clearer\n        ret[-1][-1].append(func_common_ir)\n\n    return IRnode.from_list(ret)\n", "import re\nfrom enum import Enum, auto\nfrom typing import Any, List, Optional, Tuple, Union\n\nfrom vyper.address_space import AddrSpace\nfrom vyper.codegen.types import BaseType, NodeType, ceil32\nfrom vyper.compiler.settings import VYPER_COLOR_OUTPUT\nfrom vyper.evm.opcodes import get_ir_opcodes\nfrom vyper.exceptions import CodegenPanic, CompilerPanic\nfrom vyper.utils import VALID_IR_MACROS, cached_property\n\n# Set default string representation for ints in IR output.\nAS_HEX_DEFAULT = False\n\nif VYPER_COLOR_OUTPUT:\n    OKBLUE = \"\\033[94m\"\n    OKMAGENTA = \"\\033[35m\"\n    OKLIGHTMAGENTA = \"\\033[95m\"\n    OKLIGHTBLUE = \"\\033[94m\"\n    ENDC = \"\\033[0m\"\nelse:\n    OKBLUE = \"\"\n    OKMAGENTA = \"\"\n    OKLIGHTMAGENTA = \"\"\n    OKLIGHTBLUE = \"\"\n    ENDC = \"\"\n\n\nclass NullAttractor(int):\n    def __add__(self, other: int) -> \"NullAttractor\":\n        return NullAttractor()\n\n    def __repr__(self) -> str:\n        return \"None\"\n\n    __radd__ = __add__\n    __mul__ = __add__\n\n\ndef push_label_to_stack(labelname: str) -> str:\n    #  items prefixed with `_sym_` are ignored until asm phase\n    return \"_sym_\" + labelname\n\n\nclass Encoding(Enum):\n    # vyper encoding, default for memory variables\n    VYPER = auto()\n    # abi encoded, default for args/return values from external funcs\n    ABI = auto()\n    # future: packed\n\n\n# Data structure for IR parse tree\nclass IRnode:\n    repr_show_gas = False\n    gas: int\n    valency: int\n    args: List[\"IRnode\"]\n    value: Union[str, int]\n\n    def __init__(\n        self,\n        value: Union[str, int],\n        args: List[\"IRnode\"] = None,\n        typ: NodeType = None,\n        location: Optional[AddrSpace] = None,\n        source_pos: Optional[Tuple[int, int]] = None,\n        annotation: Optional[str] = None,\n        mutable: bool = True,\n        add_gas_estimate: int = 0,\n        valency: Optional[int] = None,\n        encoding: Encoding = Encoding.VYPER,\n    ):\n        if args is None:\n            args = []\n\n        self.value = value\n        self.args = args\n        # TODO remove this sanity check once mypy is more thorough\n        assert isinstance(typ, NodeType) or typ is None, repr(typ)\n        self.typ = typ\n        self.location = location\n        self.source_pos = source_pos\n        self.annotation = annotation\n        self.mutable = mutable\n        self.add_gas_estimate = add_gas_estimate\n        self.encoding = encoding\n        self.as_hex = AS_HEX_DEFAULT\n\n        # Optional annotation properties for gas estimation\n        self.total_gas = None\n        self.func_name = None\n\n        def _check(condition, err):\n            if not condition:\n                raise CompilerPanic(str(err))\n\n        _check(self.value is not None, \"None is not allowed as IRnode value\")\n\n        # Determine this node's valency (1 if it pushes a value on the stack,\n        # 0 otherwise) and checks to make sure the number and valencies of\n        # children are correct. Also, find an upper bound on gas consumption\n        # Numbers\n        if isinstance(self.value, int):\n            _check(len(self.args) == 0, \"int can't have arguments\")\n            self.valency = 1\n            self.gas = 5\n        elif isinstance(self.value, str):\n            # Opcodes and pseudo-opcodes (e.g. clamp)\n            if self.value.upper() in get_ir_opcodes():\n                _, ins, outs, gas = get_ir_opcodes()[self.value.upper()]\n                self.valency = outs\n                _check(\n                    len(self.args) == ins,\n                    f\"Number of arguments mismatched: {self.value} {self.args}\",\n                )\n                # We add 2 per stack height at push time and take it back\n                # at pop time; this makes `break` easier to handle\n                self.gas = gas + 2 * (outs - ins)\n                for arg in self.args:\n                    # pop and pass are used to push/pop values on the stack to be\n                    # consumed for internal functions, therefore we whitelist this as a zero valency\n                    # allowed argument.\n                    zero_valency_whitelist = {\"pass\", \"pop\"}\n                    _check(\n                        arg.valency == 1 or arg.value in zero_valency_whitelist,\n                        f\"invalid argument to `{self.value}`: {arg}\",\n                    )\n                    self.gas += arg.gas\n                # Dynamic gas cost: 8 gas for each byte of logging data\n                if self.value.upper()[0:3] == \"LOG\" and isinstance(self.args[1].value, int):\n                    self.gas += self.args[1].value * 8\n                # Dynamic gas cost: non-zero-valued call\n                if self.value.upper() == \"CALL\" and self.args[2].value != 0:\n                    self.gas += 34000\n                # Dynamic gas cost: filling sstore (ie. not clearing)\n                elif self.value.upper() == \"SSTORE\" and self.args[1].value != 0:\n                    self.gas += 15000\n                # Dynamic gas cost: calldatacopy\n                elif self.value.upper() in (\"CALLDATACOPY\", \"CODECOPY\", \"EXTCODECOPY\"):\n                    size = 34000\n                    size_arg_index = 3 if self.value.upper() == \"EXTCODECOPY\" else 2\n                    size_arg = self.args[size_arg_index]\n                    if isinstance(size_arg.value, int):\n                        size = size_arg.value\n                    self.gas += ceil32(size) // 32 * 3\n                # Gas limits in call\n                if self.value.upper() == \"CALL\" and isinstance(self.args[0].value, int):\n                    self.gas += self.args[0].value\n            # If statements\n            elif self.value == \"if\":\n                if len(self.args) == 3:\n                    self.gas = self.args[0].gas + max(self.args[1].gas, self.args[2].gas) + 3\n                if len(self.args) == 2:\n                    self.gas = self.args[0].gas + self.args[1].gas + 17\n                _check(\n                    self.args[0].valency > 0,\n                    f\"zerovalent argument as a test to an if statement: {self.args[0]}\",\n                )\n                _check(len(self.args) in (2, 3), \"if statement can only have 2 or 3 arguments\")\n                self.valency = self.args[1].valency\n            # With statements: with <var> <initial> <statement>\n            elif self.value == \"with\":\n                _check(len(self.args) == 3, self)\n                _check(\n                    len(self.args[0].args) == 0 and isinstance(self.args[0].value, str),\n                    f\"first argument to with statement must be a variable name: {self.args[0]}\",\n                )\n                _check(\n                    self.args[1].valency == 1 or self.args[1].value == \"pass\",\n                    f\"zerovalent argument to with statement: {self.args[1]}\",\n                )\n                self.valency = self.args[2].valency\n                self.gas = sum([arg.gas for arg in self.args]) + 5\n            # Repeat statements: repeat <index_name> <startval> <rounds> <rounds_bound> <body>\n            elif self.value == \"repeat\":\n                _check(\n                    len(self.args) == 5, \"repeat(index_name, startval, rounds, rounds_bound, body)\"\n                )\n\n                counter_ptr = self.args[0]\n                start = self.args[1]\n                repeat_count = self.args[2]\n                repeat_bound = self.args[3]\n                body = self.args[4]\n\n                _check(\n                    isinstance(repeat_bound.value, int) and repeat_bound.value > 0,\n                    f\"repeat bound must be a compile-time positive integer: {self.args[2]}\",\n                )\n                _check(repeat_count.valency == 1, repeat_count)\n                _check(counter_ptr.valency == 1, counter_ptr)\n                _check(start.valency == 1, start)\n\n                self.valency = 0\n\n                self.gas = counter_ptr.gas + start.gas\n                self.gas += 3  # gas for repeat_bound\n                int_bound = int(repeat_bound.value)\n                self.gas += int_bound * (body.gas + 50) + 30\n\n                if repeat_count != repeat_bound:\n                    # gas for assert(repeat_count <= repeat_bound)\n                    self.gas += 18\n\n            # Seq statements: seq <statement> <statement> ...\n            elif self.value == \"seq\":\n                self.valency = self.args[-1].valency if self.args else 0\n                self.gas = sum([arg.gas for arg in self.args]) + 30\n\n            # GOTO is a jump with args\n            # e.g. (goto my_label x y z) will push x y and z onto the stack,\n            # then JUMP to my_label.\n            elif self.value in (\"goto\", \"exit_to\"):\n                for arg in self.args:\n                    _check(\n                        arg.valency == 1 or arg.value == \"pass\",\n                        f\"zerovalent argument to goto {arg}\",\n                    )\n\n                self.valency = 0\n                self.gas = sum([arg.gas for arg in self.args])\n            elif self.value == \"label\":\n                if not self.args[1].value == \"var_list\":\n                    raise CodegenPanic(f\"2nd argument to label must be var_list, {self}\")\n                self.valency = 0\n                self.gas = 1 + sum(t.gas for t in self.args)\n            # var_list names a variable number stack variables\n            elif self.value == \"var_list\":\n                for arg in self.args:\n                    if not isinstance(arg.value, str) or len(arg.args) > 0:\n                        raise CodegenPanic(f\"var_list only takes strings: {self.args}\")\n                self.valency = 0\n                self.gas = 0\n\n            # Multi statements: multi <expr> <expr> ...\n            elif self.value == \"multi\":\n                for arg in self.args:\n                    _check(\n                        arg.valency > 0, f\"Multi expects all children to not be zerovalent: {arg}\"\n                    )\n                self.valency = sum([arg.valency for arg in self.args])\n                self.gas = sum([arg.gas for arg in self.args])\n            elif self.value == \"deploy\":\n                self.valency = 0\n                self.gas = NullAttractor()  # unknown\n            # Stack variables\n            else:\n                self.valency = 1\n                self.gas = 3\n        elif self.value is None:\n            self.valency = 1\n            # None IRnodes always get compiled into something else, e.g.\n            # mzero or PUSH1 0, and the gas will get re-estimated then.\n            self.gas = 3\n        else:\n            raise CompilerPanic(f\"Invalid value for IR AST node: {self.value}\")\n        assert isinstance(self.args, list)\n\n        if valency is not None:\n            self.valency = valency\n\n        self.gas += self.add_gas_estimate\n\n    # the IR should be cached.\n    # TODO make this private. turns out usages are all for the caching\n    # idiom that cache_when_complex addresses\n    @property\n    def is_complex_ir(self):\n        # list of items not to cache. note can add other env variables\n        # which do not change, e.g. calldatasize, coinbase, etc.\n        do_not_cache = {\"~empty\"}\n        return (\n            isinstance(self.value, str)\n            and (self.value.lower() in VALID_IR_MACROS or self.value.upper() in get_ir_opcodes())\n            and self.value.lower() not in do_not_cache\n        )\n\n    @property\n    def is_literal(self):\n        return isinstance(self.value, int) or self.value == \"multi\"\n\n    @property\n    def is_pointer(self):\n        # not used yet but should help refactor/clarify downstream code\n        # eventually\n        return self.location is not None\n\n    # This function is slightly confusing but abstracts a common pattern:\n    # when an IR value needs to be computed once and then cached as an\n    # IR value (if it is expensive, or more importantly if its computation\n    # includes side-effects), cache it as an IR variable named with the\n    # `name` param, and execute the `body` with the cached value. Otherwise,\n    # run the `body` without caching the IR variable.\n    # Note that this may be an unneeded abstraction in the presence of an\n    # arbitrarily powerful optimization framework (which can detect unneeded\n    # caches) but for now still necessary - CMC 2021-12-11.\n    # usage:\n    # ```\n    # with ir_node.cache_when_complex(\"foo\") as builder, foo:\n    #   ret = some_function(foo)\n    #   return builder.resolve(ret)\n    # ```\n    def cache_when_complex(self, name):\n        # this creates a magical block which maps to IR `with`\n        class _WithBuilder:\n            def __init__(self, ir_node, name):\n                # TODO figure out how to fix this circular import\n                from vyper.ir.optimizer import optimize\n\n                self.ir_node = ir_node\n                # for caching purposes, see if the ir_node will be optimized\n                # because a non-literal expr could turn into a literal,\n                # (e.g. `(add 1 2)`)\n                # TODO this could really be moved into optimizer.py\n                self.should_cache = optimize(ir_node).is_complex_ir\n\n                # a named IR variable which represents the\n                # output of `ir_node`\n                self.ir_var = IRnode.from_list(\n                    name, typ=ir_node.typ, location=ir_node.location, encoding=ir_node.encoding\n                )\n\n            def __enter__(self):\n                if self.should_cache:\n                    # return the named cache\n                    return self, self.ir_var\n                else:\n                    # it's a constant (or will be optimized to one), just return that\n                    return self, self.ir_node\n\n            def __exit__(self, *args):\n                pass\n\n            # MUST be called at the end of building the expression\n            # in order to make sure the expression gets wrapped correctly\n            def resolve(self, body):\n                if self.should_cache:\n                    ret = [\"with\", self.ir_var, self.ir_node, body]\n                    if isinstance(body, IRnode):\n                        return IRnode.from_list(\n                            ret, typ=body.typ, location=body.location, encoding=body.encoding\n                        )\n                    else:\n                        return ret\n                else:\n                    return body\n\n        return _WithBuilder(self, name)\n\n    @cached_property\n    def contains_self_call(self):\n        return getattr(self, \"is_self_call\", False) or any(x.contains_self_call for x in self.args)\n\n    def __getitem__(self, i):\n        return self.to_list()[i]\n\n    def __len__(self):\n        return len(self.to_list())\n\n    # TODO this seems like a not useful and also confusing function\n    # check if dead code and remove - CMC 2021-12-13\n    def to_list(self):\n        return [self.value] + [a.to_list() for a in self.args]\n\n    def __eq__(self, other):\n        return (\n            self.value == other.value\n            and self.args == other.args\n            and self.typ == other.typ\n            and self.location == other.location\n            and self.source_pos == other.source_pos\n            and self.annotation == other.annotation\n            and self.mutable == other.mutable\n            and self.add_gas_estimate == other.add_gas_estimate\n            and self.valency == other.valency\n        )\n\n    @property\n    def repr_value(self):\n        if isinstance(self.value, int) and self.as_hex:\n            return hex(self.value)\n        if not isinstance(self.value, str):\n            return str(self.value)\n        return self.value\n\n    @staticmethod\n    def _colorise_keywords(val):\n        if val.lower() in VALID_IR_MACROS:  # highlight macro\n            return OKLIGHTMAGENTA + val + ENDC\n        elif val.upper() in get_ir_opcodes().keys():\n            return OKMAGENTA + val + ENDC\n        return val\n\n    def repr(self) -> str:\n\n        if not len(self.args):\n\n            if self.annotation:\n                return f\"{self.repr_value} \" + OKLIGHTBLUE + f\"<{self.annotation}>\" + ENDC\n            else:\n                return str(self.repr_value)\n        # x = repr(self.to_list())\n        # if len(x) < 80:\n        #     return x\n        o = \"\"\n        if self.annotation:\n            o += f\"/* {self.annotation} */ \\n\"\n        if self.repr_show_gas and self.gas:\n            o += OKBLUE + \"{\" + ENDC + str(self.gas) + OKBLUE + \"} \" + ENDC  # add gas for info.\n        o += \"[\" + self._colorise_keywords(self.repr_value)\n        prev_lineno = self.source_pos[0] if self.source_pos else None\n        arg_lineno = None\n        annotated = False\n        has_inner_newlines = False\n        for arg in self.args:\n            o += \",\\n  \"\n            arg_lineno = arg.source_pos[0] if arg.source_pos else None\n            if arg_lineno is not None and arg_lineno != prev_lineno and self.value in (\"seq\", \"if\"):\n                o += f\"# Line {(arg_lineno)}\\n  \"\n                prev_lineno = arg_lineno\n                annotated = True\n            arg_repr = arg.repr()\n            if \"\\n\" in arg_repr:\n                has_inner_newlines = True\n            sub = arg_repr.replace(\"\\n\", \"\\n  \").strip(\" \")\n            o += self._colorise_keywords(sub)\n        output = o.rstrip(\" \") + \"]\"\n        output_on_one_line = re.sub(r\",\\n *\", \", \", output).replace(\"\\n\", \"\")\n\n        should_output_single_line = (\n            (len(output_on_one_line) < 80 or len(self.args) == 1) and not annotated\n        ) and not has_inner_newlines\n\n        if should_output_single_line:\n            return output_on_one_line\n        else:\n            return output\n\n    def __repr__(self):\n        return self.repr()\n\n    @classmethod\n    def from_list(\n        cls,\n        obj: Any,\n        typ: NodeType = None,\n        location: Optional[AddrSpace] = None,\n        source_pos: Optional[Tuple[int, int]] = None,\n        annotation: Optional[str] = None,\n        mutable: bool = True,\n        add_gas_estimate: int = 0,\n        valency: Optional[int] = None,\n        encoding: Encoding = Encoding.VYPER,\n    ) -> \"IRnode\":\n        if isinstance(typ, str):\n            typ = BaseType(typ)\n\n        if isinstance(obj, IRnode):\n            # note: this modify-and-returnclause is a little weird since\n            # the input gets modified. CC 20191121.\n            if typ is not None:\n                obj.typ = typ\n            if obj.source_pos is None:\n                obj.source_pos = source_pos\n            if obj.location is None:\n                obj.location = location\n            if obj.encoding is None:\n                obj.encoding = encoding\n\n            return obj\n        elif not isinstance(obj, list):\n            return cls(\n                obj,\n                [],\n                typ,\n                location=location,\n                annotation=annotation,\n                mutable=mutable,\n                add_gas_estimate=add_gas_estimate,\n                valency=valency,\n                encoding=encoding,\n            )\n        else:\n            return cls(\n                obj[0],\n                [cls.from_list(o, source_pos=source_pos) for o in obj[1:]],\n                typ,\n                location=location,\n                annotation=annotation,\n                mutable=mutable,\n                source_pos=source_pos,\n                add_gas_estimate=add_gas_estimate,\n                valency=valency,\n                encoding=encoding,\n            )\n", "# transition module to convert from new types to old types\n\nimport vyper.codegen.types as old\nimport vyper.semantics.types as new\nfrom vyper.exceptions import InvalidType\n\n\ndef new_type_to_old_type(typ: new.BasePrimitive) -> old.NodeType:\n    if isinstance(typ, new.BoolDefinition):\n        return old.BaseType(\"bool\")\n    if isinstance(typ, new.AddressDefinition):\n        return old.BaseType(\"address\")\n    if isinstance(typ, new.InterfaceDefinition):\n        return old.InterfaceType(typ._id)\n    if isinstance(typ, new.BytesMDefinition):\n        m = typ._length  # type: ignore\n        return old.BaseType(f\"bytes{m}\")\n    if isinstance(typ, new.BytesArrayDefinition):\n        return old.ByteArrayType(typ.length)\n    if isinstance(typ, new.StringDefinition):\n        return old.StringType(typ.length)\n    if isinstance(typ, new.DecimalDefinition):\n        return old.BaseType(\"decimal\")\n    if isinstance(typ, new.SignedIntegerAbstractType):\n        bits = typ._bits  # type: ignore\n        return old.BaseType(\"int\" + str(bits))\n    if isinstance(typ, new.UnsignedIntegerAbstractType):\n        bits = typ._bits  # type: ignore\n        return old.BaseType(\"uint\" + str(bits))\n    if isinstance(typ, new.ArrayDefinition):\n        return old.SArrayType(new_type_to_old_type(typ.value_type), typ.length)\n    if isinstance(typ, new.DynamicArrayDefinition):\n        return old.DArrayType(new_type_to_old_type(typ.value_type), typ.length)\n    if isinstance(typ, new.TupleDefinition):\n        return old.TupleType([new_type_to_old_type(t) for t in typ.value_type])\n    if isinstance(typ, new.StructDefinition):\n        return old.StructType(\n            {n: new_type_to_old_type(t) for (n, t) in typ.members.items()}, typ._id\n        )\n    raise InvalidType(f\"unknown type {typ}\")\n"], "filenames": ["tests/parser/functions/test_interfaces.py", "vyper/codegen/core.py", "vyper/codegen/external_call.py", "vyper/codegen/function_definitions/external_function.py", "vyper/codegen/ir_node.py", "vyper/codegen/types/convert.py"], "buggy_code_start_loc": [9, 126, 9, 5, 50, 35], "buggy_code_end_loc": [308, 720, 181, 64, 52, 36], "fixing_code_start_loc": [9, 126, 9, 6, 49, 35], "fixing_code_end_loc": [473, 717, 177, 44, 49, 36], "type": "CWE-190", "message": "Vyper is a pythonic Smart Contract Language for the ethereum virtual machine. In affected versions, the return of `<iface>.returns_int128()` is not validated to fall within the bounds of `int128`. This issue can result in a misinterpretation of the integer value and lead to incorrect behavior. As of v0.3.0, `<iface>.returns_int128()` is validated in simple expressions, but not complex expressions. Users are advised to upgrade. There is no known workaround for this issue.", "other": {"cve": {"id": "CVE-2022-24845", "sourceIdentifier": "security-advisories@github.com", "published": "2022-04-13T22:15:08.330", "lastModified": "2022-04-22T18:15:01.500", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Vyper is a pythonic Smart Contract Language for the ethereum virtual machine. In affected versions, the return of `<iface>.returns_int128()` is not validated to fall within the bounds of `int128`. This issue can result in a misinterpretation of the integer value and lead to incorrect behavior. As of v0.3.0, `<iface>.returns_int128()` is validated in simple expressions, but not complex expressions. Users are advised to upgrade. There is no known workaround for this issue."}, {"lang": "es", "value": "Vyper es un Lenguaje de Contrato Inteligente pit\u00f3nico para la m\u00e1quina virtual de Ethereum. En las versiones afectadas, el retorno de \"(iface).returns_int128()\" no es comprobado que est\u00e9 dentro de los l\u00edmites de \"int128\". Este problema puede resultar en una mala interpretaci\u00f3n del valor entero y conllevar a un comportamiento incorrecto. A partir de la versi\u00f3n 0.3.0, \"(iface).returns_int128()\" es comprobado en expresiones simples, pero no en expresiones complejas. Es recomendado a usuarios actualizar. No se presenta medidas de mitigaci\u00f3n conocidas para este problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 7.5}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-190"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-190"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:vyper_project:vyper:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.3.2", "matchCriteriaId": "C407E33B-07B3-4361-AC3B-53EA8D69C8AE"}]}]}], "references": [{"url": "https://github.com/vyperlang/vyper/commit/049dbdc647b2ce838fae7c188e6bb09cf16e470b", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/vyperlang/vyper/security/advisories/GHSA-j2x6-9323-fp7h", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/vyperlang/vyper/commit/049dbdc647b2ce838fae7c188e6bb09cf16e470b"}}
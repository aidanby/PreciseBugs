{"buggy_code": ["#! /usr/bin/env perl\n# Copyright 2011-2016 The OpenSSL Project Authors. All Rights Reserved.\n#\n# Licensed under the OpenSSL license (the \"License\").  You may not use\n# this file except in compliance with the License.  You can obtain a copy\n# in the file LICENSE in the source distribution or at\n# https://www.openssl.org/source/license.html\n\n\n# ====================================================================\n# Written by Andy Polyakov <appro@openssl.org> for the OpenSSL\n# project. The module is, however, dual licensed under OpenSSL and\n# CRYPTOGAMS licenses depending on where you obtain it. For further\n# details see http://www.openssl.org/~appro/cryptogams/.\n# ====================================================================\n\n# August 2011.\n#\n# Companion to x86_64-mont.pl that optimizes cache-timing attack\n# countermeasures. The subroutines are produced by replacing bp[i]\n# references in their x86_64-mont.pl counterparts with cache-neutral\n# references to powers table computed in BN_mod_exp_mont_consttime.\n# In addition subroutine that scatters elements of the powers table\n# is implemented, so that scatter-/gathering can be tuned without\n# bn_exp.c modifications.\n\n# August 2013.\n#\n# Add MULX/AD*X code paths and additional interfaces to optimize for\n# branch prediction unit. For input lengths that are multiples of 8\n# the np argument is not just modulus value, but one interleaved\n# with 0. This is to optimize post-condition...\n\n$flavour = shift;\n$output  = shift;\nif ($flavour =~ /\\./) { $output = $flavour; undef $flavour; }\n\n$win64=0; $win64=1 if ($flavour =~ /[nm]asm|mingw64/ || $output =~ /\\.asm$/);\n\n$0 =~ m/(.*[\\/\\\\])[^\\/\\\\]+$/; $dir=$1;\n( $xlate=\"${dir}x86_64-xlate.pl\" and -f $xlate ) or\n( $xlate=\"${dir}../../perlasm/x86_64-xlate.pl\" and -f $xlate) or\ndie \"can't locate x86_64-xlate.pl\";\n\nopen OUT,\"| \\\"$^X\\\" \\\"$xlate\\\" $flavour \\\"$output\\\"\";\n*STDOUT=*OUT;\n\nif (`$ENV{CC} -Wa,-v -c -o /dev/null -x assembler /dev/null 2>&1`\n\t\t=~ /GNU assembler version ([2-9]\\.[0-9]+)/) {\n\t$addx = ($1>=2.23);\n}\n\nif (!$addx && $win64 && ($flavour =~ /nasm/ || $ENV{ASM} =~ /nasm/) &&\n\t    `nasm -v 2>&1` =~ /NASM version ([2-9]\\.[0-9]+)/) {\n\t$addx = ($1>=2.10);\n}\n\nif (!$addx && $win64 && ($flavour =~ /masm/ || $ENV{ASM} =~ /ml64/) &&\n\t    `ml64 2>&1` =~ /Version ([0-9]+)\\./) {\n\t$addx = ($1>=12);\n}\n\nif (!$addx && `$ENV{CC} -v 2>&1` =~ /((?:^clang|LLVM) version|.*based on LLVM) ([3-9])\\.([0-9]+)/) {\n\tmy $ver = $2 + $3/100.0;\t# 3.1->3.01, 3.10->3.10\n\t$addx = ($ver>=3.03);\n}\n\n# int bn_mul_mont_gather5(\n$rp=\"%rdi\";\t# BN_ULONG *rp,\n$ap=\"%rsi\";\t# const BN_ULONG *ap,\n$bp=\"%rdx\";\t# const BN_ULONG *bp,\n$np=\"%rcx\";\t# const BN_ULONG *np,\n$n0=\"%r8\";\t# const BN_ULONG *n0,\n$num=\"%r9\";\t# int num,\n\t\t# int idx);\t# 0 to 2^5-1, \"index\" in $bp holding\n\t\t\t\t# pre-computed powers of a', interlaced\n\t\t\t\t# in such manner that b[0] is $bp[idx],\n\t\t\t\t# b[1] is [2^5+idx], etc.\n$lo0=\"%r10\";\n$hi0=\"%r11\";\n$hi1=\"%r13\";\n$i=\"%r14\";\n$j=\"%r15\";\n$m0=\"%rbx\";\n$m1=\"%rbp\";\n\n$code=<<___;\n.text\n\n.extern\tOPENSSL_ia32cap_P\n\n.globl\tbn_mul_mont_gather5\n.type\tbn_mul_mont_gather5,\\@function,6\n.align\t64\nbn_mul_mont_gather5:\n\tmov\t${num}d,${num}d\n\tmov\t%rsp,%rax\n\ttest\t\\$7,${num}d\n\tjnz\t.Lmul_enter\n___\n$code.=<<___ if ($addx);\n\tmov\tOPENSSL_ia32cap_P+8(%rip),%r11d\n___\n$code.=<<___;\n\tjmp\t.Lmul4x_enter\n\n.align\t16\n.Lmul_enter:\n\tmovd\t`($win64?56:8)`(%rsp),%xmm5\t# load 7th argument\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n\n\tneg\t$num\n\tmov\t%rsp,%r11\n\tlea\t-280(%rsp,$num,8),%r10\t# future alloca(8*(num+2)+256+8)\n\tneg\t$num\t\t\t# restore $num\n\tand\t\\$-1024,%r10\t\t# minimize TLB usage\n\n\t# An OS-agnostic version of __chkstk.\n\t#\n\t# Some OSes (Windows) insist on stack being \"wired\" to\n\t# physical memory in strictly sequential manner, i.e. if stack\n\t# allocation spans two pages, then reference to farmost one can\n\t# be punishable by SEGV. But page walking can do good even on\n\t# other OSes, because it guarantees that villain thread hits\n\t# the guard page before it can make damage to innocent one...\n\tsub\t%r10,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%r10,%r11),%rsp\n\tmov\t(%rsp),%r11\n\tcmp\t%r10,%rsp\n\tja\t.Lmul_page_walk\n\tjmp\t.Lmul_page_walk_done\n\n.Lmul_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r11\n\tcmp\t%r10,%rsp\n\tja\t.Lmul_page_walk\n.Lmul_page_walk_done:\n\n\tlea\t.Linc(%rip),%r10\n\tmov\t%rax,8(%rsp,$num,8)\t# tp[num+1]=%rsp\n.Lmul_body:\n\n\tlea\t128($bp),%r12\t\t# reassign $bp (+size optimization)\n___\n\t\t$bp=\"%r12\";\n\t\t$STRIDE=2**5*8;\t\t# 5 is \"window size\"\n\t\t$N=$STRIDE/4;\t\t# should match cache line size\n$code.=<<___;\n\tmovdqa\t0(%r10),%xmm0\t\t# 00000001000000010000000000000000\n\tmovdqa\t16(%r10),%xmm1\t\t# 00000002000000020000000200000002\n\tlea\t24-112(%rsp,$num,8),%r10# place the mask after tp[num+3] (+ICache optimization)\n\tand\t\\$-16,%r10\n\n\tpshufd\t\\$0,%xmm5,%xmm5\t\t# broadcast index\n\tmovdqa\t%xmm1,%xmm4\n\tmovdqa\t%xmm1,%xmm2\n___\n########################################################################\n# calculate mask by comparing 0..31 to index and save result to stack\n#\n$code.=<<___;\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\t\t# compare to 1,0\n\t.byte\t0x67\n\tmovdqa\t%xmm4,%xmm3\n___\nfor($k=0;$k<$STRIDE/16-4;$k+=4) {\n$code.=<<___;\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\t\t# compare to 3,2\n\tmovdqa\t%xmm0,`16*($k+0)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm0\n\n\tpaddd\t%xmm2,%xmm3\n\tpcmpeqd\t%xmm5,%xmm2\t\t# compare to 5,4\n\tmovdqa\t%xmm1,`16*($k+1)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm1\n\n\tpaddd\t%xmm3,%xmm0\n\tpcmpeqd\t%xmm5,%xmm3\t\t# compare to 7,6\n\tmovdqa\t%xmm2,`16*($k+2)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm2\n\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\n\tmovdqa\t%xmm3,`16*($k+3)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm3\n___\n}\n$code.=<<___;\t\t\t\t# last iteration can be optimized\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\n\tmovdqa\t%xmm0,`16*($k+0)+112`(%r10)\n\n\tpaddd\t%xmm2,%xmm3\n\t.byte\t0x67\n\tpcmpeqd\t%xmm5,%xmm2\n\tmovdqa\t%xmm1,`16*($k+1)+112`(%r10)\n\n\tpcmpeqd\t%xmm5,%xmm3\n\tmovdqa\t%xmm2,`16*($k+2)+112`(%r10)\n\tpand\t`16*($k+0)-128`($bp),%xmm0\t# while it's still in register\n\n\tpand\t`16*($k+1)-128`($bp),%xmm1\n\tpand\t`16*($k+2)-128`($bp),%xmm2\n\tmovdqa\t%xmm3,`16*($k+3)+112`(%r10)\n\tpand\t`16*($k+3)-128`($bp),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\nfor($k=0;$k<$STRIDE/16-4;$k+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($k+0)-128`($bp),%xmm4\n\tmovdqa\t`16*($k+1)-128`($bp),%xmm5\n\tmovdqa\t`16*($k+2)-128`($bp),%xmm2\n\tpand\t`16*($k+0)+112`(%r10),%xmm4\n\tmovdqa\t`16*($k+3)-128`($bp),%xmm3\n\tpand\t`16*($k+1)+112`(%r10),%xmm5\n\tpor\t%xmm4,%xmm0\n\tpand\t`16*($k+2)+112`(%r10),%xmm2\n\tpor\t%xmm5,%xmm1\n\tpand\t`16*($k+3)+112`(%r10),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\n}\n$code.=<<___;\n\tpor\t%xmm1,%xmm0\n\tpshufd\t\\$0x4e,%xmm0,%xmm1\n\tpor\t%xmm1,%xmm0\n\tlea\t$STRIDE($bp),$bp\n\tmovq\t%xmm0,$m0\t\t# m0=bp[0]\n\n\tmov\t($n0),$n0\t\t# pull n0[0] value\n\tmov\t($ap),%rax\n\n\txor\t$i,$i\t\t\t# i=0\n\txor\t$j,$j\t\t\t# j=0\n\n\tmov\t$n0,$m1\n\tmulq\t$m0\t\t\t# ap[0]*bp[0]\n\tmov\t%rax,$lo0\n\tmov\t($np),%rax\n\n\timulq\t$lo0,$m1\t\t# \"tp[0]\"*n0\n\tmov\t%rdx,$hi0\n\n\tmulq\t$m1\t\t\t# np[0]*m1\n\tadd\t%rax,$lo0\t\t# discarded\n\tmov\t8($ap),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$hi1\n\n\tlea\t1($j),$j\t\t# j++\n\tjmp\t.L1st_enter\n\n.align\t16\n.L1st:\n\tadd\t%rax,$hi1\n\tmov\t($ap,$j,8),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$hi0,$hi1\t\t# np[j]*m1+ap[j]*bp[0]\n\tmov\t$lo0,$hi0\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-16(%rsp,$j,8)\t# tp[j-1]\n\tmov\t%rdx,$hi1\n\n.L1st_enter:\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$hi0\n\tmov\t($np,$j,8),%rax\n\tadc\t\\$0,%rdx\n\tlea\t1($j),$j\t\t# j++\n\tmov\t%rdx,$lo0\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tcmp\t$num,$j\n\tjne\t.L1st\t\t\t# note that upon exit $j==$num, so\n\t\t\t\t\t# they can be used interchangeably\n\n\tadd\t%rax,$hi1\n\tadc\t\\$0,%rdx\n\tadd\t$hi0,$hi1\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-16(%rsp,$num,8)\t# tp[num-1]\n\tmov\t%rdx,$hi1\n\tmov\t$lo0,$hi0\n\n\txor\t%rdx,%rdx\n\tadd\t$hi0,$hi1\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-8(%rsp,$num,8)\n\tmov\t%rdx,(%rsp,$num,8)\t# store upmost overflow bit\n\n\tlea\t1($i),$i\t\t# i++\n\tjmp\t.Louter\n.align\t16\n.Louter:\n\tlea\t24+128(%rsp,$num,8),%rdx\t# where 256-byte mask is (+size optimization)\n\tand\t\\$-16,%rdx\n\tpxor\t%xmm4,%xmm4\n\tpxor\t%xmm5,%xmm5\n___\nfor($k=0;$k<$STRIDE/16;$k+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($k+0)-128`($bp),%xmm0\n\tmovdqa\t`16*($k+1)-128`($bp),%xmm1\n\tmovdqa\t`16*($k+2)-128`($bp),%xmm2\n\tmovdqa\t`16*($k+3)-128`($bp),%xmm3\n\tpand\t`16*($k+0)-128`(%rdx),%xmm0\n\tpand\t`16*($k+1)-128`(%rdx),%xmm1\n\tpor\t%xmm0,%xmm4\n\tpand\t`16*($k+2)-128`(%rdx),%xmm2\n\tpor\t%xmm1,%xmm5\n\tpand\t`16*($k+3)-128`(%rdx),%xmm3\n\tpor\t%xmm2,%xmm4\n\tpor\t%xmm3,%xmm5\n___\n}\n$code.=<<___;\n\tpor\t%xmm5,%xmm4\n\tpshufd\t\\$0x4e,%xmm4,%xmm0\n\tpor\t%xmm4,%xmm0\n\tlea\t$STRIDE($bp),$bp\n\n\tmov\t($ap),%rax\t\t# ap[0]\n\tmovq\t%xmm0,$m0\t\t# m0=bp[i]\n\n\txor\t$j,$j\t\t\t# j=0\n\tmov\t$n0,$m1\n\tmov\t(%rsp),$lo0\n\n\tmulq\t$m0\t\t\t# ap[0]*bp[i]\n\tadd\t%rax,$lo0\t\t# ap[0]*bp[i]+tp[0]\n\tmov\t($np),%rax\n\tadc\t\\$0,%rdx\n\n\timulq\t$lo0,$m1\t\t# tp[0]*n0\n\tmov\t%rdx,$hi0\n\n\tmulq\t$m1\t\t\t# np[0]*m1\n\tadd\t%rax,$lo0\t\t# discarded\n\tmov\t8($ap),%rax\n\tadc\t\\$0,%rdx\n\tmov\t8(%rsp),$lo0\t\t# tp[1]\n\tmov\t%rdx,$hi1\n\n\tlea\t1($j),$j\t\t# j++\n\tjmp\t.Linner_enter\n\n.align\t16\n.Linner:\n\tadd\t%rax,$hi1\n\tmov\t($ap,$j,8),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$lo0,$hi1\t\t# np[j]*m1+ap[j]*bp[i]+tp[j]\n\tmov\t(%rsp,$j,8),$lo0\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-16(%rsp,$j,8)\t# tp[j-1]\n\tmov\t%rdx,$hi1\n\n.Linner_enter:\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$hi0\n\tmov\t($np,$j,8),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$hi0,$lo0\t\t# ap[j]*bp[i]+tp[j]\n\tmov\t%rdx,$hi0\n\tadc\t\\$0,$hi0\n\tlea\t1($j),$j\t\t# j++\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tcmp\t$num,$j\n\tjne\t.Linner\t\t\t# note that upon exit $j==$num, so\n\t\t\t\t\t# they can be used interchangeably\n\tadd\t%rax,$hi1\n\tadc\t\\$0,%rdx\n\tadd\t$lo0,$hi1\t\t# np[j]*m1+ap[j]*bp[i]+tp[j]\n\tmov\t(%rsp,$num,8),$lo0\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-16(%rsp,$num,8)\t# tp[num-1]\n\tmov\t%rdx,$hi1\n\n\txor\t%rdx,%rdx\n\tadd\t$hi0,$hi1\n\tadc\t\\$0,%rdx\n\tadd\t$lo0,$hi1\t\t# pull upmost overflow bit\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-8(%rsp,$num,8)\n\tmov\t%rdx,(%rsp,$num,8)\t# store upmost overflow bit\n\n\tlea\t1($i),$i\t\t# i++\n\tcmp\t$num,$i\n\tjb\t.Louter\n\n\txor\t$i,$i\t\t\t# i=0 and clear CF!\n\tmov\t(%rsp),%rax\t\t# tp[0]\n\tlea\t(%rsp),$ap\t\t# borrow ap for tp\n\tmov\t$num,$j\t\t\t# j=num\n\tjmp\t.Lsub\n.align\t16\n.Lsub:\tsbb\t($np,$i,8),%rax\n\tmov\t%rax,($rp,$i,8)\t\t# rp[i]=tp[i]-np[i]\n\tmov\t8($ap,$i,8),%rax\t# tp[i+1]\n\tlea\t1($i),$i\t\t# i++\n\tdec\t$j\t\t\t# doesnn't affect CF!\n\tjnz\t.Lsub\n\n\tsbb\t\\$0,%rax\t\t# handle upmost overflow bit\n\txor\t$i,$i\n\tand\t%rax,$ap\n\tnot\t%rax\n\tmov\t$rp,$np\n\tand\t%rax,$np\n\tmov\t$num,$j\t\t\t# j=num\n\tor\t$np,$ap\t\t\t# ap=borrow?tp:rp\n.align\t16\n.Lcopy:\t\t\t\t\t# copy or in-place refresh\n\tmov\t($ap,$i,8),%rax\n\tmov\t$i,(%rsp,$i,8)\t\t# zap temporary vector\n\tmov\t%rax,($rp,$i,8)\t\t# rp[i]=tp[i]\n\tlea\t1($i),$i\n\tsub\t\\$1,$j\n\tjnz\t.Lcopy\n\n\tmov\t8(%rsp,$num,8),%rsi\t# restore %rsp\n\tmov\t\\$1,%rax\n\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lmul_epilogue:\n\tret\n.size\tbn_mul_mont_gather5,.-bn_mul_mont_gather5\n___\n{{{\nmy @A=(\"%r10\",\"%r11\");\nmy @N=(\"%r13\",\"%rdi\");\n$code.=<<___;\n.type\tbn_mul4x_mont_gather5,\\@function,6\n.align\t32\nbn_mul4x_mont_gather5:\n\t.byte\t0x67\n\tmov\t%rsp,%rax\n.Lmul4x_enter:\n___\n$code.=<<___ if ($addx);\n\tand\t\\$0x80108,%r11d\n\tcmp\t\\$0x80108,%r11d\t\t# check for AD*X+BMI2+BMI1\n\tje\t.Lmulx4x_enter\n___\n$code.=<<___;\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n.Lmul4x_prologue:\n\n\t.byte\t0x67\n\tshl\t\\$3,${num}d\t\t# convert $num to bytes\n\tlea\t($num,$num,2),%r10\t# 3*$num in bytes\n\tneg\t$num\t\t\t# -$num\n\n\t##############################################################\n\t# Ensure that stack frame doesn't alias with $rptr+3*$num\n\t# modulo 4096, which covers ret[num], am[num] and n[num]\n\t# (see bn_exp.c). This is done to allow memory disambiguation\n\t# logic do its magic. [Extra [num] is allocated in order\n\t# to align with bn_power5's frame, which is cleansed after\n\t# completing exponentiation. Extra 256 bytes is for power mask\n\t# calculated from 7th argument, the index.]\n\t#\n\tlea\t-320(%rsp,$num,2),%r11\n\tmov\t%rsp,%rbp\n\tsub\t$rp,%r11\n\tand\t\\$4095,%r11\n\tcmp\t%r11,%r10\n\tjb\t.Lmul4xsp_alt\n\tsub\t%r11,%rbp\t\t# align with $rp\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*num*8+256)\n\tjmp\t.Lmul4xsp_done\n\n.align\t32\n.Lmul4xsp_alt:\n\tlea\t4096-320(,$num,2),%r10\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*num*8+256)\n\tsub\t%r10,%r11\n\tmov\t\\$0,%r10\n\tcmovc\t%r10,%r11\n\tsub\t%r11,%rbp\n.Lmul4xsp_done:\n\tand\t\\$-64,%rbp\n\tmov\t%rsp,%r11\n\tsub\t%rbp,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%rbp,%r11),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lmul4x_page_walk\n\tjmp\t.Lmul4x_page_walk_done\n\n.Lmul4x_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lmul4x_page_walk\n.Lmul4x_page_walk_done:\n\n\tneg\t$num\n\n\tmov\t%rax,40(%rsp)\n.Lmul4x_body:\n\n\tcall\tmul4x_internal\n\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tmov\t\\$1,%rax\n\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lmul4x_epilogue:\n\tret\n.size\tbn_mul4x_mont_gather5,.-bn_mul4x_mont_gather5\n\n.type\tmul4x_internal,\\@abi-omnipotent\n.align\t32\nmul4x_internal:\n\tshl\t\\$5,$num\t\t# $num was in bytes\n\tmovd\t`($win64?56:8)`(%rax),%xmm5\t# load 7th argument, index\n\tlea\t.Linc(%rip),%rax\n\tlea\t128(%rdx,$num),%r13\t# end of powers table (+size optimization)\n\tshr\t\\$5,$num\t\t# restore $num\n___\n\t\t$bp=\"%r12\";\n\t\t$STRIDE=2**5*8;\t\t# 5 is \"window size\"\n\t\t$N=$STRIDE/4;\t\t# should match cache line size\n\t\t$tp=$i;\n$code.=<<___;\n\tmovdqa\t0(%rax),%xmm0\t\t# 00000001000000010000000000000000\n\tmovdqa\t16(%rax),%xmm1\t\t# 00000002000000020000000200000002\n\tlea\t88-112(%rsp,$num),%r10\t# place the mask after tp[num+1] (+ICache optimization)\n\tlea\t128(%rdx),$bp\t\t# size optimization\n\n\tpshufd\t\\$0,%xmm5,%xmm5\t\t# broadcast index\n\tmovdqa\t%xmm1,%xmm4\n\t.byte\t0x67,0x67\n\tmovdqa\t%xmm1,%xmm2\n___\n########################################################################\n# calculate mask by comparing 0..31 to index and save result to stack\n#\n$code.=<<___;\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\t\t# compare to 1,0\n\t.byte\t0x67\n\tmovdqa\t%xmm4,%xmm3\n___\nfor($i=0;$i<$STRIDE/16-4;$i+=4) {\n$code.=<<___;\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\t\t# compare to 3,2\n\tmovdqa\t%xmm0,`16*($i+0)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm0\n\n\tpaddd\t%xmm2,%xmm3\n\tpcmpeqd\t%xmm5,%xmm2\t\t# compare to 5,4\n\tmovdqa\t%xmm1,`16*($i+1)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm1\n\n\tpaddd\t%xmm3,%xmm0\n\tpcmpeqd\t%xmm5,%xmm3\t\t# compare to 7,6\n\tmovdqa\t%xmm2,`16*($i+2)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm2\n\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\n\tmovdqa\t%xmm3,`16*($i+3)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm3\n___\n}\n$code.=<<___;\t\t\t\t# last iteration can be optimized\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\n\tmovdqa\t%xmm0,`16*($i+0)+112`(%r10)\n\n\tpaddd\t%xmm2,%xmm3\n\t.byte\t0x67\n\tpcmpeqd\t%xmm5,%xmm2\n\tmovdqa\t%xmm1,`16*($i+1)+112`(%r10)\n\n\tpcmpeqd\t%xmm5,%xmm3\n\tmovdqa\t%xmm2,`16*($i+2)+112`(%r10)\n\tpand\t`16*($i+0)-128`($bp),%xmm0\t# while it's still in register\n\n\tpand\t`16*($i+1)-128`($bp),%xmm1\n\tpand\t`16*($i+2)-128`($bp),%xmm2\n\tmovdqa\t%xmm3,`16*($i+3)+112`(%r10)\n\tpand\t`16*($i+3)-128`($bp),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\nfor($i=0;$i<$STRIDE/16-4;$i+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($i+0)-128`($bp),%xmm4\n\tmovdqa\t`16*($i+1)-128`($bp),%xmm5\n\tmovdqa\t`16*($i+2)-128`($bp),%xmm2\n\tpand\t`16*($i+0)+112`(%r10),%xmm4\n\tmovdqa\t`16*($i+3)-128`($bp),%xmm3\n\tpand\t`16*($i+1)+112`(%r10),%xmm5\n\tpor\t%xmm4,%xmm0\n\tpand\t`16*($i+2)+112`(%r10),%xmm2\n\tpor\t%xmm5,%xmm1\n\tpand\t`16*($i+3)+112`(%r10),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\n}\n$code.=<<___;\n\tpor\t%xmm1,%xmm0\n\tpshufd\t\\$0x4e,%xmm0,%xmm1\n\tpor\t%xmm1,%xmm0\n\tlea\t$STRIDE($bp),$bp\n\tmovq\t%xmm0,$m0\t\t# m0=bp[0]\n\n\tmov\t%r13,16+8(%rsp)\t\t# save end of b[num]\n\tmov\t$rp, 56+8(%rsp)\t\t# save $rp\n\n\tmov\t($n0),$n0\t\t# pull n0[0] value\n\tmov\t($ap),%rax\n\tlea\t($ap,$num),$ap\t\t# end of a[num]\n\tneg\t$num\n\n\tmov\t$n0,$m1\n\tmulq\t$m0\t\t\t# ap[0]*bp[0]\n\tmov\t%rax,$A[0]\n\tmov\t($np),%rax\n\n\timulq\t$A[0],$m1\t\t# \"tp[0]\"*n0\n\tlea\t64+8(%rsp),$tp\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[0]*m1\n\tadd\t%rax,$A[0]\t\t# discarded\n\tmov\t8($ap,$num),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\n\tadd\t%rax,$A[1]\n\tmov\t8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\n\tadd\t%rax,$N[1]\n\tmov\t16($ap,$num),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\n\tlea\t4*8($num),$j\t\t# j=4\n\tlea\t8*4($np),$np\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],($tp)\n\tmov\t%rdx,$N[0]\n\tjmp\t.L1st4x\n\n.align\t32\n.L1st4x:\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[0]\n\tmov\t-8*2($np),%rax\n\tlea\t32($tp),$tp\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t-8($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-24($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[1]\n\tmov\t-8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],-16($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[0]\n\tmov\t8*0($np),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t8($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-8($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[1]\n\tmov\t8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t16($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\t\t# np[j]*m1+ap[j]*bp[0]\n\tlea\t8*4($np),$np\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tadd\t\\$32,$j\t\t\t# j+=4\n\tjnz\t.L1st4x\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[0]\n\tmov\t-8*2($np),%rax\n\tlea\t32($tp),$tp\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t-8($ap),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-24($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[1]\n\tmov\t-8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t($ap,$num),%rax\t\t# ap[0]\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],-16($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tlea\t($np,$num),$np\t\t# rewind $np\n\n\txor\t$N[1],$N[1]\n\tadd\t$A[0],$N[0]\n\tadc\t\\$0,$N[1]\n\tmov\t$N[0],-8($tp)\n\n\tjmp\t.Louter4x\n\n.align\t32\n.Louter4x:\n\tlea\t16+128($tp),%rdx\t# where 256-byte mask is (+size optimization)\n\tpxor\t%xmm4,%xmm4\n\tpxor\t%xmm5,%xmm5\n___\nfor($i=0;$i<$STRIDE/16;$i+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($i+0)-128`($bp),%xmm0\n\tmovdqa\t`16*($i+1)-128`($bp),%xmm1\n\tmovdqa\t`16*($i+2)-128`($bp),%xmm2\n\tmovdqa\t`16*($i+3)-128`($bp),%xmm3\n\tpand\t`16*($i+0)-128`(%rdx),%xmm0\n\tpand\t`16*($i+1)-128`(%rdx),%xmm1\n\tpor\t%xmm0,%xmm4\n\tpand\t`16*($i+2)-128`(%rdx),%xmm2\n\tpor\t%xmm1,%xmm5\n\tpand\t`16*($i+3)-128`(%rdx),%xmm3\n\tpor\t%xmm2,%xmm4\n\tpor\t%xmm3,%xmm5\n___\n}\n$code.=<<___;\n\tpor\t%xmm5,%xmm4\n\tpshufd\t\\$0x4e,%xmm4,%xmm0\n\tpor\t%xmm4,%xmm0\n\tlea\t$STRIDE($bp),$bp\n\tmovq\t%xmm0,$m0\t\t# m0=bp[i]\n\n\tmov\t($tp,$num),$A[0]\n\tmov\t$n0,$m1\n\tmulq\t$m0\t\t\t# ap[0]*bp[i]\n\tadd\t%rax,$A[0]\t\t# ap[0]*bp[i]+tp[0]\n\tmov\t($np),%rax\n\tadc\t\\$0,%rdx\n\n\timulq\t$A[0],$m1\t\t# tp[0]*n0\n\tmov\t%rdx,$A[1]\n\tmov\t$N[1],($tp)\t\t# store upmost overflow bit\n\n\tlea\t($tp,$num),$tp\t\t# rewind $tp\n\n\tmulq\t$m1\t\t\t# np[0]*m1\n\tadd\t%rax,$A[0]\t\t# \"$N[0]\", discarded\n\tmov\t8($ap,$num),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[1]\n\tmov\t8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t8($tp),$A[1]\t\t# +tp[1]\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t16($ap,$num),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\t\t# np[j]*m1+ap[j]*bp[i]+tp[j]\n\tlea\t4*8($num),$j\t\t# j=4\n\tlea\t8*4($np),$np\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$N[0]\n\tjmp\t.Linner4x\n\n.align\t32\n.Linner4x:\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[0]\n\tmov\t-8*2($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t16($tp),$A[0]\t\t# ap[j]*bp[i]+tp[j]\n\tlea\t32($tp),$tp\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t-8($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],-32($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[1]\n\tmov\t-8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t-8($tp),$A[1]\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-24($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[0]\n\tmov\t8*0($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t($tp),$A[0]\t\t# ap[j]*bp[i]+tp[j]\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t8($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],-16($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[1]\n\tmov\t8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t8($tp),$A[1]\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t16($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\n\tlea\t8*4($np),$np\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-8($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tadd\t\\$32,$j\t\t\t# j+=4\n\tjnz\t.Linner4x\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[0]\n\tmov\t-8*2($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t16($tp),$A[0]\t\t# ap[j]*bp[i]+tp[j]\n\tlea\t32($tp),$tp\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t-8($ap),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],-32($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[1]\n\tmov\t$m1,%rax\n\tmov\t-8*1($np),$m1\n\tadc\t\\$0,%rdx\n\tadd\t-8($tp),$A[1]\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t($ap,$num),%rax\t\t# ap[0]\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-24($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tmov\t$N[1],-16($tp)\t\t# tp[j-1]\n\tlea\t($np,$num),$np\t\t# rewind $np\n\n\txor\t$N[1],$N[1]\n\tadd\t$A[0],$N[0]\n\tadc\t\\$0,$N[1]\n\tadd\t($tp),$N[0]\t\t# pull upmost overflow bit\n\tadc\t\\$0,$N[1]\t\t# upmost overflow bit\n\tmov\t$N[0],-8($tp)\n\n\tcmp\t16+8(%rsp),$bp\n\tjb\t.Louter4x\n___\nif (1) {\n$code.=<<___;\n\txor\t%rax,%rax\n\tsub\t$N[0],$m1\t\t# compare top-most words\n\tadc\t$j,$j\t\t\t# $j is zero\n\tor\t$j,$N[1]\n\tsub\t$N[1],%rax\t\t# %rax=-$N[1]\n\tlea\t($tp,$num),%rbx\t\t# tptr in .sqr4x_sub\n\tmov\t($np),%r12\n\tlea\t($np),%rbp\t\t# nptr in .sqr4x_sub\n\tmov\t%r9,%rcx\n\tsar\t\\$3+2,%rcx\n\tmov\t56+8(%rsp),%rdi\t\t# rptr in .sqr4x_sub\n\tdec\t%r12\t\t\t# so that after 'not' we get -n[0]\n\txor\t%r10,%r10\n\tmov\t8*1(%rbp),%r13\n\tmov\t8*2(%rbp),%r14\n\tmov\t8*3(%rbp),%r15\n\tjmp\t.Lsqr4x_sub_entry\n___\n} else {\nmy @ri=(\"%rax\",$bp,$m0,$m1);\nmy $rp=\"%rdx\";\n$code.=<<___\n\txor\t\\$1,$N[1]\n\tlea\t($tp,$num),$tp\t\t# rewind $tp\n\tsar\t\\$5,$num\t\t# cf=0\n\tlea\t($np,$N[1],8),$np\n\tmov\t56+8(%rsp),$rp\t\t# restore $rp\n\tjmp\t.Lsub4x\n\n.align\t32\n.Lsub4x:\n\t.byte\t0x66\n\tmov\t8*0($tp),@ri[0]\n\tmov\t8*1($tp),@ri[1]\n\t.byte\t0x66\n\tsbb\t16*0($np),@ri[0]\n\tmov\t8*2($tp),@ri[2]\n\tsbb\t16*1($np),@ri[1]\n\tmov\t3*8($tp),@ri[3]\n\tlea\t4*8($tp),$tp\n\tsbb\t16*2($np),@ri[2]\n\tmov\t@ri[0],8*0($rp)\n\tsbb\t16*3($np),@ri[3]\n\tlea\t16*4($np),$np\n\tmov\t@ri[1],8*1($rp)\n\tmov\t@ri[2],8*2($rp)\n\tmov\t@ri[3],8*3($rp)\n\tlea\t8*4($rp),$rp\n\n\tinc\t$num\n\tjnz\t.Lsub4x\n\n\tret\n___\n}\n$code.=<<___;\n.size\tmul4x_internal,.-mul4x_internal\n___\n}}}\n\f{{{\n######################################################################\n# void bn_power5(\nmy $rptr=\"%rdi\";\t# BN_ULONG *rptr,\nmy $aptr=\"%rsi\";\t# const BN_ULONG *aptr,\nmy $bptr=\"%rdx\";\t# const void *table,\nmy $nptr=\"%rcx\";\t# const BN_ULONG *nptr,\nmy $n0  =\"%r8\";\t\t# const BN_ULONG *n0);\nmy $num =\"%r9\";\t\t# int num, has to be divisible by 8\n\t\t\t# int pwr \n\nmy ($i,$j,$tptr)=(\"%rbp\",\"%rcx\",$rptr);\nmy @A0=(\"%r10\",\"%r11\");\nmy @A1=(\"%r12\",\"%r13\");\nmy ($a0,$a1,$ai)=(\"%r14\",\"%r15\",\"%rbx\");\n\n$code.=<<___;\n.globl\tbn_power5\n.type\tbn_power5,\\@function,6\n.align\t32\nbn_power5:\n\tmov\t%rsp,%rax\n___\n$code.=<<___ if ($addx);\n\tmov\tOPENSSL_ia32cap_P+8(%rip),%r11d\n\tand\t\\$0x80108,%r11d\n\tcmp\t\\$0x80108,%r11d\t\t# check for AD*X+BMI2+BMI1\n\tje\t.Lpowerx5_enter\n___\n$code.=<<___;\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n.Lpower5_prologue:\n\n\tshl\t\\$3,${num}d\t\t# convert $num to bytes\n\tlea\t($num,$num,2),%r10d\t# 3*$num\n\tneg\t$num\n\tmov\t($n0),$n0\t\t# *n0\n\n\t##############################################################\n\t# Ensure that stack frame doesn't alias with $rptr+3*$num\n\t# modulo 4096, which covers ret[num], am[num] and n[num]\n\t# (see bn_exp.c). This is done to allow memory disambiguation\n\t# logic do its magic. [Extra 256 bytes is for power mask\n\t# calculated from 7th argument, the index.]\n\t#\n\tlea\t-320(%rsp,$num,2),%r11\n\tmov\t%rsp,%rbp\n\tsub\t$rptr,%r11\n\tand\t\\$4095,%r11\n\tcmp\t%r11,%r10\n\tjb\t.Lpwr_sp_alt\n\tsub\t%r11,%rbp\t\t# align with $aptr\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*num*8+256)\n\tjmp\t.Lpwr_sp_done\n\n.align\t32\n.Lpwr_sp_alt:\n\tlea\t4096-320(,$num,2),%r10\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*num*8+256)\n\tsub\t%r10,%r11\n\tmov\t\\$0,%r10\n\tcmovc\t%r10,%r11\n\tsub\t%r11,%rbp\n.Lpwr_sp_done:\n\tand\t\\$-64,%rbp\n\tmov\t%rsp,%r11\n\tsub\t%rbp,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%rbp,%r11),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lpwr_page_walk\n\tjmp\t.Lpwr_page_walk_done\n\n.Lpwr_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lpwr_page_walk\n.Lpwr_page_walk_done:\n\n\tmov\t$num,%r10\t\n\tneg\t$num\n\n\t##############################################################\n\t# Stack layout\n\t#\n\t# +0\tsaved $num, used in reduction section\n\t# +8\t&t[2*$num], used in reduction section\n\t# +32\tsaved *n0\n\t# +40\tsaved %rsp\n\t# +48\tt[2*$num]\n\t#\n\tmov\t$n0,  32(%rsp)\n\tmov\t%rax, 40(%rsp)\t\t# save original %rsp\n.Lpower5_body:\n\tmovq\t$rptr,%xmm1\t\t# save $rptr, used in sqr8x\n\tmovq\t$nptr,%xmm2\t\t# save $nptr\n\tmovq\t%r10, %xmm3\t\t# -$num, used in sqr8x\n\tmovq\t$bptr,%xmm4\n\n\tcall\t__bn_sqr8x_internal\n\tcall\t__bn_post4x_internal\n\tcall\t__bn_sqr8x_internal\n\tcall\t__bn_post4x_internal\n\tcall\t__bn_sqr8x_internal\n\tcall\t__bn_post4x_internal\n\tcall\t__bn_sqr8x_internal\n\tcall\t__bn_post4x_internal\n\tcall\t__bn_sqr8x_internal\n\tcall\t__bn_post4x_internal\n\n\tmovq\t%xmm2,$nptr\n\tmovq\t%xmm4,$bptr\n\tmov\t$aptr,$rptr\n\tmov\t40(%rsp),%rax\n\tlea\t32(%rsp),$n0\n\n\tcall\tmul4x_internal\n\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tmov\t\\$1,%rax\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lpower5_epilogue:\n\tret\n.size\tbn_power5,.-bn_power5\n\n.globl\tbn_sqr8x_internal\n.hidden\tbn_sqr8x_internal\n.type\tbn_sqr8x_internal,\\@abi-omnipotent\n.align\t32\nbn_sqr8x_internal:\n__bn_sqr8x_internal:\n\t##############################################################\n\t# Squaring part:\n\t#\n\t# a) multiply-n-add everything but a[i]*a[i];\n\t# b) shift result of a) by 1 to the left and accumulate\n\t#    a[i]*a[i] products;\n\t#\n\t##############################################################\n\t#                                                     a[1]a[0]\n\t#                                                 a[2]a[0]\n\t#                                             a[3]a[0]\n\t#                                             a[2]a[1]\n\t#                                         a[4]a[0]\n\t#                                         a[3]a[1]\n\t#                                     a[5]a[0]\n\t#                                     a[4]a[1]\n\t#                                     a[3]a[2]\n\t#                                 a[6]a[0]\n\t#                                 a[5]a[1]\n\t#                                 a[4]a[2]\n\t#                             a[7]a[0]\n\t#                             a[6]a[1]\n\t#                             a[5]a[2]\n\t#                             a[4]a[3]\n\t#                         a[7]a[1]\n\t#                         a[6]a[2]\n\t#                         a[5]a[3]\n\t#                     a[7]a[2]\n\t#                     a[6]a[3]\n\t#                     a[5]a[4]\n\t#                 a[7]a[3]\n\t#                 a[6]a[4]\n\t#             a[7]a[4]\n\t#             a[6]a[5]\n\t#         a[7]a[5]\n\t#     a[7]a[6]\n\t#                                                     a[1]a[0]\n\t#                                                 a[2]a[0]\n\t#                                             a[3]a[0]\n\t#                                         a[4]a[0]\n\t#                                     a[5]a[0]\n\t#                                 a[6]a[0]\n\t#                             a[7]a[0]\n\t#                                             a[2]a[1]\n\t#                                         a[3]a[1]\n\t#                                     a[4]a[1]\n\t#                                 a[5]a[1]\n\t#                             a[6]a[1]\n\t#                         a[7]a[1]\n\t#                                     a[3]a[2]\n\t#                                 a[4]a[2]\n\t#                             a[5]a[2]\n\t#                         a[6]a[2]\n\t#                     a[7]a[2]\n\t#                             a[4]a[3]\n\t#                         a[5]a[3]\n\t#                     a[6]a[3]\n\t#                 a[7]a[3]\n\t#                     a[5]a[4]\n\t#                 a[6]a[4]\n\t#             a[7]a[4]\n\t#             a[6]a[5]\n\t#         a[7]a[5]\n\t#     a[7]a[6]\n\t#                                                         a[0]a[0]\n\t#                                                 a[1]a[1]\n\t#                                         a[2]a[2]\n\t#                                 a[3]a[3]\n\t#                         a[4]a[4]\n\t#                 a[5]a[5]\n\t#         a[6]a[6]\n\t# a[7]a[7]\n\n\tlea\t32(%r10),$i\t\t# $i=-($num-32)\n\tlea\t($aptr,$num),$aptr\t# end of a[] buffer, ($aptr,$i)=&ap[2]\n\n\tmov\t$num,$j\t\t\t# $j=$num\n\n\t\t\t\t\t# comments apply to $num==8 case\n\tmov\t-32($aptr,$i),$a0\t# a[0]\n\tlea\t48+8(%rsp,$num,2),$tptr\t# end of tp[] buffer, &tp[2*$num]\n\tmov\t-24($aptr,$i),%rax\t# a[1]\n\tlea\t-32($tptr,$i),$tptr\t# end of tp[] window, &tp[2*$num-\"$i\"]\n\tmov\t-16($aptr,$i),$ai\t# a[2]\n\tmov\t%rax,$a1\n\n\tmul\t$a0\t\t\t# a[1]*a[0]\n\tmov\t%rax,$A0[0]\t\t# a[1]*a[0]\n\t mov\t$ai,%rax\t\t# a[2]\n\tmov\t%rdx,$A0[1]\n\tmov\t$A0[0],-24($tptr,$i)\t# t[1]\n\n\tmul\t$a0\t\t\t# a[2]*a[0]\n\tadd\t%rax,$A0[1]\n\t mov\t$ai,%rax\n\tadc\t\\$0,%rdx\n\tmov\t$A0[1],-16($tptr,$i)\t# t[2]\n\tmov\t%rdx,$A0[0]\n\n\n\t mov\t-8($aptr,$i),$ai\t# a[3]\n\tmul\t$a1\t\t\t# a[2]*a[1]\n\tmov\t%rax,$A1[0]\t\t# a[2]*a[1]+t[3]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A1[1]\n\n\t lea\t($i),$j\n\tmul\t$a0\t\t\t# a[3]*a[0]\n\tadd\t%rax,$A0[0]\t\t# a[3]*a[0]+a[2]*a[1]+t[3]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tadd\t$A1[0],$A0[0]\n\tadc\t\\$0,$A0[1]\n\tmov\t$A0[0],-8($tptr,$j)\t# t[3]\n\tjmp\t.Lsqr4x_1st\n\n.align\t32\n.Lsqr4x_1st:\n\t mov\t($aptr,$j),$ai\t\t# a[4]\n\tmul\t$a1\t\t\t# a[3]*a[1]\n\tadd\t%rax,$A1[1]\t\t# a[3]*a[1]+t[4]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A1[0]\n\tadc\t\\$0,$A1[0]\n\n\tmul\t$a0\t\t\t# a[4]*a[0]\n\tadd\t%rax,$A0[1]\t\t# a[4]*a[0]+a[3]*a[1]+t[4]\n\t mov\t$ai,%rax\t\t# a[3]\n\t mov\t8($aptr,$j),$ai\t\t# a[5]\n\tmov\t%rdx,$A0[0]\n\tadc\t\\$0,$A0[0]\n\tadd\t$A1[1],$A0[1]\n\tadc\t\\$0,$A0[0]\n\n\n\tmul\t$a1\t\t\t# a[4]*a[3]\n\tadd\t%rax,$A1[0]\t\t# a[4]*a[3]+t[5]\n\t mov\t$ai,%rax\n\t mov\t$A0[1],($tptr,$j)\t# t[4]\n\tmov\t%rdx,$A1[1]\n\tadc\t\\$0,$A1[1]\n\n\tmul\t$a0\t\t\t# a[5]*a[2]\n\tadd\t%rax,$A0[0]\t\t# a[5]*a[2]+a[4]*a[3]+t[5]\n\t mov\t$ai,%rax\n\t mov\t16($aptr,$j),$ai\t# a[6]\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tadd\t$A1[0],$A0[0]\n\tadc\t\\$0,$A0[1]\n\n\tmul\t$a1\t\t\t# a[5]*a[3]\n\tadd\t%rax,$A1[1]\t\t# a[5]*a[3]+t[6]\n\t mov\t$ai,%rax\n\t mov\t$A0[0],8($tptr,$j)\t# t[5]\n\tmov\t%rdx,$A1[0]\n\tadc\t\\$0,$A1[0]\n\n\tmul\t$a0\t\t\t# a[6]*a[2]\n\tadd\t%rax,$A0[1]\t\t# a[6]*a[2]+a[5]*a[3]+t[6]\n\t mov\t$ai,%rax\t\t# a[3]\n\t mov\t24($aptr,$j),$ai\t# a[7]\n\tmov\t%rdx,$A0[0]\n\tadc\t\\$0,$A0[0]\n\tadd\t$A1[1],$A0[1]\n\tadc\t\\$0,$A0[0]\n\n\n\tmul\t$a1\t\t\t# a[6]*a[5]\n\tadd\t%rax,$A1[0]\t\t# a[6]*a[5]+t[7]\n\t mov\t$ai,%rax\n\t mov\t$A0[1],16($tptr,$j)\t# t[6]\n\tmov\t%rdx,$A1[1]\n\tadc\t\\$0,$A1[1]\n\t lea\t32($j),$j\n\n\tmul\t$a0\t\t\t# a[7]*a[4]\n\tadd\t%rax,$A0[0]\t\t# a[7]*a[4]+a[6]*a[5]+t[6]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tadd\t$A1[0],$A0[0]\n\tadc\t\\$0,$A0[1]\n\tmov\t$A0[0],-8($tptr,$j)\t# t[7]\n\n\tcmp\t\\$0,$j\n\tjne\t.Lsqr4x_1st\n\n\tmul\t$a1\t\t\t# a[7]*a[5]\n\tadd\t%rax,$A1[1]\n\tlea\t16($i),$i\n\tadc\t\\$0,%rdx\n\tadd\t$A0[1],$A1[1]\n\tadc\t\\$0,%rdx\n\n\tmov\t$A1[1],($tptr)\t\t# t[8]\n\tmov\t%rdx,$A1[0]\n\tmov\t%rdx,8($tptr)\t\t# t[9]\n\tjmp\t.Lsqr4x_outer\n\n.align\t32\n.Lsqr4x_outer:\t\t\t\t# comments apply to $num==6 case\n\tmov\t-32($aptr,$i),$a0\t# a[0]\n\tlea\t48+8(%rsp,$num,2),$tptr\t# end of tp[] buffer, &tp[2*$num]\n\tmov\t-24($aptr,$i),%rax\t# a[1]\n\tlea\t-32($tptr,$i),$tptr\t# end of tp[] window, &tp[2*$num-\"$i\"]\n\tmov\t-16($aptr,$i),$ai\t# a[2]\n\tmov\t%rax,$a1\n\n\tmul\t$a0\t\t\t# a[1]*a[0]\n\tmov\t-24($tptr,$i),$A0[0]\t# t[1]\n\tadd\t%rax,$A0[0]\t\t# a[1]*a[0]+t[1]\n\t mov\t$ai,%rax\t\t# a[2]\n\tadc\t\\$0,%rdx\n\tmov\t$A0[0],-24($tptr,$i)\t# t[1]\n\tmov\t%rdx,$A0[1]\n\n\tmul\t$a0\t\t\t# a[2]*a[0]\n\tadd\t%rax,$A0[1]\n\t mov\t$ai,%rax\n\tadc\t\\$0,%rdx\n\tadd\t-16($tptr,$i),$A0[1]\t# a[2]*a[0]+t[2]\n\tmov\t%rdx,$A0[0]\n\tadc\t\\$0,$A0[0]\n\tmov\t$A0[1],-16($tptr,$i)\t# t[2]\n\n\txor\t$A1[0],$A1[0]\n\n\t mov\t-8($aptr,$i),$ai\t# a[3]\n\tmul\t$a1\t\t\t# a[2]*a[1]\n\tadd\t%rax,$A1[0]\t\t# a[2]*a[1]+t[3]\n\t mov\t$ai,%rax\n\tadc\t\\$0,%rdx\n\tadd\t-8($tptr,$i),$A1[0]\n\tmov\t%rdx,$A1[1]\n\tadc\t\\$0,$A1[1]\n\n\tmul\t$a0\t\t\t# a[3]*a[0]\n\tadd\t%rax,$A0[0]\t\t# a[3]*a[0]+a[2]*a[1]+t[3]\n\t mov\t$ai,%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A1[0],$A0[0]\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tmov\t$A0[0],-8($tptr,$i)\t# t[3]\n\n\tlea\t($i),$j\n\tjmp\t.Lsqr4x_inner\n\n.align\t32\n.Lsqr4x_inner:\n\t mov\t($aptr,$j),$ai\t\t# a[4]\n\tmul\t$a1\t\t\t# a[3]*a[1]\n\tadd\t%rax,$A1[1]\t\t# a[3]*a[1]+t[4]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A1[0]\n\tadc\t\\$0,$A1[0]\n\tadd\t($tptr,$j),$A1[1]\n\tadc\t\\$0,$A1[0]\n\n\t.byte\t0x67\n\tmul\t$a0\t\t\t# a[4]*a[0]\n\tadd\t%rax,$A0[1]\t\t# a[4]*a[0]+a[3]*a[1]+t[4]\n\t mov\t$ai,%rax\t\t# a[3]\n\t mov\t8($aptr,$j),$ai\t\t# a[5]\n\tmov\t%rdx,$A0[0]\n\tadc\t\\$0,$A0[0]\n\tadd\t$A1[1],$A0[1]\n\tadc\t\\$0,$A0[0]\n\n\tmul\t$a1\t\t\t# a[4]*a[3]\n\tadd\t%rax,$A1[0]\t\t# a[4]*a[3]+t[5]\n\tmov\t$A0[1],($tptr,$j)\t# t[4]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A1[1]\n\tadc\t\\$0,$A1[1]\n\tadd\t8($tptr,$j),$A1[0]\n\tlea\t16($j),$j\t\t# j++\n\tadc\t\\$0,$A1[1]\n\n\tmul\t$a0\t\t\t# a[5]*a[2]\n\tadd\t%rax,$A0[0]\t\t# a[5]*a[2]+a[4]*a[3]+t[5]\n\t mov\t$ai,%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A1[0],$A0[0]\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tmov\t$A0[0],-8($tptr,$j)\t# t[5], \"preloaded t[1]\" below\n\n\tcmp\t\\$0,$j\n\tjne\t.Lsqr4x_inner\n\n\t.byte\t0x67\n\tmul\t$a1\t\t\t# a[5]*a[3]\n\tadd\t%rax,$A1[1]\n\tadc\t\\$0,%rdx\n\tadd\t$A0[1],$A1[1]\n\tadc\t\\$0,%rdx\n\n\tmov\t$A1[1],($tptr)\t\t# t[6], \"preloaded t[2]\" below\n\tmov\t%rdx,$A1[0]\n\tmov\t%rdx,8($tptr)\t\t# t[7], \"preloaded t[3]\" below\n\n\tadd\t\\$16,$i\n\tjnz\t.Lsqr4x_outer\n\n\t\t\t\t\t# comments apply to $num==4 case\n\tmov\t-32($aptr),$a0\t\t# a[0]\n\tlea\t48+8(%rsp,$num,2),$tptr\t# end of tp[] buffer, &tp[2*$num]\n\tmov\t-24($aptr),%rax\t\t# a[1]\n\tlea\t-32($tptr,$i),$tptr\t# end of tp[] window, &tp[2*$num-\"$i\"]\n\tmov\t-16($aptr),$ai\t\t# a[2]\n\tmov\t%rax,$a1\n\n\tmul\t$a0\t\t\t# a[1]*a[0]\n\tadd\t%rax,$A0[0]\t\t# a[1]*a[0]+t[1], preloaded t[1]\n\t mov\t$ai,%rax\t\t# a[2]\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\n\tmul\t$a0\t\t\t# a[2]*a[0]\n\tadd\t%rax,$A0[1]\n\t mov\t$ai,%rax\n\t mov\t$A0[0],-24($tptr)\t# t[1]\n\tmov\t%rdx,$A0[0]\n\tadc\t\\$0,$A0[0]\n\tadd\t$A1[1],$A0[1]\t\t# a[2]*a[0]+t[2], preloaded t[2]\n\t mov\t-8($aptr),$ai\t\t# a[3]\n\tadc\t\\$0,$A0[0]\n\n\tmul\t$a1\t\t\t# a[2]*a[1]\n\tadd\t%rax,$A1[0]\t\t# a[2]*a[1]+t[3], preloaded t[3]\n\t mov\t$ai,%rax\n\t mov\t$A0[1],-16($tptr)\t# t[2]\n\tmov\t%rdx,$A1[1]\n\tadc\t\\$0,$A1[1]\n\n\tmul\t$a0\t\t\t# a[3]*a[0]\n\tadd\t%rax,$A0[0]\t\t# a[3]*a[0]+a[2]*a[1]+t[3]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tadd\t$A1[0],$A0[0]\n\tadc\t\\$0,$A0[1]\n\tmov\t$A0[0],-8($tptr)\t# t[3]\n\n\tmul\t$a1\t\t\t# a[3]*a[1]\n\tadd\t%rax,$A1[1]\n\t mov\t-16($aptr),%rax\t\t# a[2]\n\tadc\t\\$0,%rdx\n\tadd\t$A0[1],$A1[1]\n\tadc\t\\$0,%rdx\n\n\tmov\t$A1[1],($tptr)\t\t# t[4]\n\tmov\t%rdx,$A1[0]\n\tmov\t%rdx,8($tptr)\t\t# t[5]\n\n\tmul\t$ai\t\t\t# a[2]*a[3]\n___\n{\nmy ($shift,$carry)=($a0,$a1);\nmy @S=(@A1,$ai,$n0);\n$code.=<<___;\n\t add\t\\$16,$i\n\t xor\t$shift,$shift\n\t sub\t$num,$i\t\t\t# $i=16-$num\n\t xor\t$carry,$carry\n\n\tadd\t$A1[0],%rax\t\t# t[5]\n\tadc\t\\$0,%rdx\n\tmov\t%rax,8($tptr)\t\t# t[5]\n\tmov\t%rdx,16($tptr)\t\t# t[6]\n\tmov\t$carry,24($tptr)\t# t[7]\n\n\t mov\t-16($aptr,$i),%rax\t# a[0]\n\tlea\t48+8(%rsp),$tptr\n\t xor\t$A0[0],$A0[0]\t\t# t[0]\n\t mov\t8($tptr),$A0[1]\t\t# t[1]\n\n\tlea\t($shift,$A0[0],2),$S[0]\t# t[2*i]<<1 | shift\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[1]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[1]\t\t# | t[2*i]>>63\n\t mov\t16($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t24($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[0]\n\t mov\t-8($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[0],($tptr)\n\tadc\t%rdx,$S[1]\n\n\tlea\t($shift,$A0[0],2),$S[2]\t# t[2*i]<<1 | shift\n\t mov\t$S[1],8($tptr)\n\t sbb\t$carry,$carry\t\t# mov cf,$carry\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[3]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[3]\t\t# | t[2*i]>>63\n\t mov\t32($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t40($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[2]\n\t mov\t0($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[2],16($tptr)\n\tadc\t%rdx,$S[3]\n\tlea\t16($i),$i\n\tmov\t$S[3],24($tptr)\n\tsbb\t$carry,$carry\t\t# mov cf,$carry\n\tlea\t64($tptr),$tptr\n\tjmp\t.Lsqr4x_shift_n_add\n\n.align\t32\n.Lsqr4x_shift_n_add:\n\tlea\t($shift,$A0[0],2),$S[0]\t# t[2*i]<<1 | shift\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[1]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[1]\t\t# | t[2*i]>>63\n\t mov\t-16($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t-8($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[0]\n\t mov\t-8($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[0],-32($tptr)\n\tadc\t%rdx,$S[1]\n\n\tlea\t($shift,$A0[0],2),$S[2]\t# t[2*i]<<1 | shift\n\t mov\t$S[1],-24($tptr)\n\t sbb\t$carry,$carry\t\t# mov cf,$carry\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[3]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[3]\t\t# | t[2*i]>>63\n\t mov\t0($tptr),$A0[0]\t\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t8($tptr),$A0[1]\t\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[2]\n\t mov\t0($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[2],-16($tptr)\n\tadc\t%rdx,$S[3]\n\n\tlea\t($shift,$A0[0],2),$S[0]\t# t[2*i]<<1 | shift\n\t mov\t$S[3],-8($tptr)\n\t sbb\t$carry,$carry\t\t# mov cf,$carry\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[1]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[1]\t\t# | t[2*i]>>63\n\t mov\t16($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t24($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[0]\n\t mov\t8($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[0],0($tptr)\n\tadc\t%rdx,$S[1]\n\n\tlea\t($shift,$A0[0],2),$S[2]\t# t[2*i]<<1 | shift\n\t mov\t$S[1],8($tptr)\n\t sbb\t$carry,$carry\t\t# mov cf,$carry\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[3]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[3]\t\t# | t[2*i]>>63\n\t mov\t32($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t40($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[2]\n\t mov\t16($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[2],16($tptr)\n\tadc\t%rdx,$S[3]\n\tmov\t$S[3],24($tptr)\n\tsbb\t$carry,$carry\t\t# mov cf,$carry\n\tlea\t64($tptr),$tptr\n\tadd\t\\$32,$i\n\tjnz\t.Lsqr4x_shift_n_add\n\n\tlea\t($shift,$A0[0],2),$S[0]\t# t[2*i]<<1 | shift\n\t.byte\t0x67\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[1]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[1]\t\t# | t[2*i]>>63\n\t mov\t-16($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t-8($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[0]\n\t mov\t-8($aptr),%rax\t\t# a[i+1]\t# prefetch\n\tmov\t$S[0],-32($tptr)\n\tadc\t%rdx,$S[1]\n\n\tlea\t($shift,$A0[0],2),$S[2]\t# t[2*i]<<1|shift\n\t mov\t$S[1],-24($tptr)\n\t sbb\t$carry,$carry\t\t# mov cf,$carry\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[3]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[3]\t\t# | t[2*i]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\tadc\t%rax,$S[2]\n\tadc\t%rdx,$S[3]\n\tmov\t$S[2],-16($tptr)\n\tmov\t$S[3],-8($tptr)\n___\n}\f\n######################################################################\n# Montgomery reduction part, \"word-by-word\" algorithm.\n#\n# This new path is inspired by multiple submissions from Intel, by\n# Shay Gueron, Vlad Krasnov, Erdinc Ozturk, James Guilford,\n# Vinodh Gopal...\n{\nmy ($nptr,$tptr,$carry,$m0)=(\"%rbp\",\"%rdi\",\"%rsi\",\"%rbx\");\n\n$code.=<<___;\n\tmovq\t%xmm2,$nptr\n__bn_sqr8x_reduction:\n\txor\t%rax,%rax\n\tlea\t($nptr,$num),%rcx\t# end of n[]\n\tlea\t48+8(%rsp,$num,2),%rdx\t# end of t[] buffer\n\tmov\t%rcx,0+8(%rsp)\n\tlea\t48+8(%rsp,$num),$tptr\t# end of initial t[] window\n\tmov\t%rdx,8+8(%rsp)\n\tneg\t$num\n\tjmp\t.L8x_reduction_loop\n\n.align\t32\n.L8x_reduction_loop:\n\tlea\t($tptr,$num),$tptr\t# start of current t[] window\n\t.byte\t0x66\n\tmov\t8*0($tptr),$m0\n\tmov\t8*1($tptr),%r9\n\tmov\t8*2($tptr),%r10\n\tmov\t8*3($tptr),%r11\n\tmov\t8*4($tptr),%r12\n\tmov\t8*5($tptr),%r13\n\tmov\t8*6($tptr),%r14\n\tmov\t8*7($tptr),%r15\n\tmov\t%rax,(%rdx)\t\t# store top-most carry bit\n\tlea\t8*8($tptr),$tptr\n\n\t.byte\t0x67\n\tmov\t$m0,%r8\n\timulq\t32+8(%rsp),$m0\t\t# n0*a[0]\n\tmov\t8*0($nptr),%rax\t\t# n[0]\n\tmov\t\\$8,%ecx\n\tjmp\t.L8x_reduce\n\n.align\t32\n.L8x_reduce:\n\tmulq\t$m0\n\t mov\t8*1($nptr),%rax\t\t# n[1]\n\tneg\t%r8\n\tmov\t%rdx,%r8\n\tadc\t\\$0,%r8\n\n\tmulq\t$m0\n\tadd\t%rax,%r9\n\t mov\t8*2($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r9,%r8\n\t mov\t$m0,48-8+8(%rsp,%rcx,8)\t# put aside n0*a[i]\n\tmov\t%rdx,%r9\n\tadc\t\\$0,%r9\n\n\tmulq\t$m0\n\tadd\t%rax,%r10\n\t mov\t8*3($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r10,%r9\n\t mov\t32+8(%rsp),$carry\t# pull n0, borrow $carry\n\tmov\t%rdx,%r10\n\tadc\t\\$0,%r10\n\n\tmulq\t$m0\n\tadd\t%rax,%r11\n\t mov\t8*4($nptr),%rax\n\tadc\t\\$0,%rdx\n\t imulq\t%r8,$carry\t\t# modulo-scheduled\n\tadd\t%r11,%r10\n\tmov\t%rdx,%r11\n\tadc\t\\$0,%r11\n\n\tmulq\t$m0\n\tadd\t%rax,%r12\n\t mov\t8*5($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r12,%r11\n\tmov\t%rdx,%r12\n\tadc\t\\$0,%r12\n\n\tmulq\t$m0\n\tadd\t%rax,%r13\n\t mov\t8*6($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r13,%r12\n\tmov\t%rdx,%r13\n\tadc\t\\$0,%r13\n\n\tmulq\t$m0\n\tadd\t%rax,%r14\n\t mov\t8*7($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r14,%r13\n\tmov\t%rdx,%r14\n\tadc\t\\$0,%r14\n\n\tmulq\t$m0\n\t mov\t$carry,$m0\t\t# n0*a[i]\n\tadd\t%rax,%r15\n\t mov\t8*0($nptr),%rax\t\t# n[0]\n\tadc\t\\$0,%rdx\n\tadd\t%r15,%r14\n\tmov\t%rdx,%r15\n\tadc\t\\$0,%r15\n\n\tdec\t%ecx\n\tjnz\t.L8x_reduce\n\n\tlea\t8*8($nptr),$nptr\n\txor\t%rax,%rax\n\tmov\t8+8(%rsp),%rdx\t\t# pull end of t[]\n\tcmp\t0+8(%rsp),$nptr\t\t# end of n[]?\n\tjae\t.L8x_no_tail\n\n\t.byte\t0x66\n\tadd\t8*0($tptr),%r8\n\tadc\t8*1($tptr),%r9\n\tadc\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tsbb\t$carry,$carry\t\t# top carry\n\n\tmov\t48+56+8(%rsp),$m0\t# pull n0*a[0]\n\tmov\t\\$8,%ecx\n\tmov\t8*0($nptr),%rax\n\tjmp\t.L8x_tail\n\n.align\t32\n.L8x_tail:\n\tmulq\t$m0\n\tadd\t%rax,%r8\n\t mov\t8*1($nptr),%rax\n\t mov\t%r8,($tptr)\t\t# save result\n\tmov\t%rdx,%r8\n\tadc\t\\$0,%r8\n\n\tmulq\t$m0\n\tadd\t%rax,%r9\n\t mov\t8*2($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r9,%r8\n\t lea\t8($tptr),$tptr\t\t# $tptr++\n\tmov\t%rdx,%r9\n\tadc\t\\$0,%r9\n\n\tmulq\t$m0\n\tadd\t%rax,%r10\n\t mov\t8*3($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r10,%r9\n\tmov\t%rdx,%r10\n\tadc\t\\$0,%r10\n\n\tmulq\t$m0\n\tadd\t%rax,%r11\n\t mov\t8*4($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r11,%r10\n\tmov\t%rdx,%r11\n\tadc\t\\$0,%r11\n\n\tmulq\t$m0\n\tadd\t%rax,%r12\n\t mov\t8*5($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r12,%r11\n\tmov\t%rdx,%r12\n\tadc\t\\$0,%r12\n\n\tmulq\t$m0\n\tadd\t%rax,%r13\n\t mov\t8*6($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r13,%r12\n\tmov\t%rdx,%r13\n\tadc\t\\$0,%r13\n\n\tmulq\t$m0\n\tadd\t%rax,%r14\n\t mov\t8*7($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r14,%r13\n\tmov\t%rdx,%r14\n\tadc\t\\$0,%r14\n\n\tmulq\t$m0\n\t mov\t48-16+8(%rsp,%rcx,8),$m0# pull n0*a[i]\n\tadd\t%rax,%r15\n\tadc\t\\$0,%rdx\n\tadd\t%r15,%r14\n\t mov\t8*0($nptr),%rax\t\t# pull n[0]\n\tmov\t%rdx,%r15\n\tadc\t\\$0,%r15\n\n\tdec\t%ecx\n\tjnz\t.L8x_tail\n\n\tlea\t8*8($nptr),$nptr\n\tmov\t8+8(%rsp),%rdx\t\t# pull end of t[]\n\tcmp\t0+8(%rsp),$nptr\t\t# end of n[]?\n\tjae\t.L8x_tail_done\t\t# break out of loop\n\n\t mov\t48+56+8(%rsp),$m0\t# pull n0*a[0]\n\tneg\t$carry\n\t mov\t8*0($nptr),%rax\t\t# pull n[0]\n\tadc\t8*0($tptr),%r8\n\tadc\t8*1($tptr),%r9\n\tadc\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tsbb\t$carry,$carry\t\t# top carry\n\n\tmov\t\\$8,%ecx\n\tjmp\t.L8x_tail\n\n.align\t32\n.L8x_tail_done:\n\tadd\t(%rdx),%r8\t\t# can this overflow?\n\tadc\t\\$0,%r9\n\tadc\t\\$0,%r10\n\tadc\t\\$0,%r11\n\tadc\t\\$0,%r12\n\tadc\t\\$0,%r13\n\tadc\t\\$0,%r14\n\tadc\t\\$0,%r15\t\t# can't overflow, because we\n\t\t\t\t\t# started with \"overhung\" part\n\t\t\t\t\t# of multiplication\n\txor\t%rax,%rax\n\n\tneg\t$carry\n.L8x_no_tail:\n\tadc\t8*0($tptr),%r8\n\tadc\t8*1($tptr),%r9\n\tadc\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tadc\t\\$0,%rax\t\t# top-most carry\n\t mov\t-8($nptr),%rcx\t\t# np[num-1]\n\t xor\t$carry,$carry\n\n\tmovq\t%xmm2,$nptr\t\t# restore $nptr\n\n\tmov\t%r8,8*0($tptr)\t\t# store top 512 bits\n\tmov\t%r9,8*1($tptr)\n\t movq\t%xmm3,$num\t\t# $num is %r9, can't be moved upwards\n\tmov\t%r10,8*2($tptr)\n\tmov\t%r11,8*3($tptr)\n\tmov\t%r12,8*4($tptr)\n\tmov\t%r13,8*5($tptr)\n\tmov\t%r14,8*6($tptr)\n\tmov\t%r15,8*7($tptr)\n\tlea\t8*8($tptr),$tptr\n\n\tcmp\t%rdx,$tptr\t\t# end of t[]?\n\tjb\t.L8x_reduction_loop\n\tret\n.size\tbn_sqr8x_internal,.-bn_sqr8x_internal\n___\n}\f\n##############################################################\n# Post-condition, 4x unrolled\n#\n{\nmy ($tptr,$nptr)=(\"%rbx\",\"%rbp\");\n$code.=<<___;\n.type\t__bn_post4x_internal,\\@abi-omnipotent\n.align\t32\n__bn_post4x_internal:\n\tmov\t8*0($nptr),%r12\n\tlea\t(%rdi,$num),$tptr\t# %rdi was $tptr above\n\tmov\t$num,%rcx\n\tmovq\t%xmm1,$rptr\t\t# restore $rptr\n\tneg\t%rax\n\tmovq\t%xmm1,$aptr\t\t# prepare for back-to-back call\n\tsar\t\\$3+2,%rcx\n\tdec\t%r12\t\t\t# so that after 'not' we get -n[0]\n\txor\t%r10,%r10\n\tmov\t8*1($nptr),%r13\n\tmov\t8*2($nptr),%r14\n\tmov\t8*3($nptr),%r15\n\tjmp\t.Lsqr4x_sub_entry\n\n.align\t16\n.Lsqr4x_sub:\n\tmov\t8*0($nptr),%r12\n\tmov\t8*1($nptr),%r13\n\tmov\t8*2($nptr),%r14\n\tmov\t8*3($nptr),%r15\n.Lsqr4x_sub_entry:\n\tlea\t8*4($nptr),$nptr\n\tnot\t%r12\n\tnot\t%r13\n\tnot\t%r14\n\tnot\t%r15\n\tand\t%rax,%r12\n\tand\t%rax,%r13\n\tand\t%rax,%r14\n\tand\t%rax,%r15\n\n\tneg\t%r10\t\t\t# mov %r10,%cf\n\tadc\t8*0($tptr),%r12\n\tadc\t8*1($tptr),%r13\n\tadc\t8*2($tptr),%r14\n\tadc\t8*3($tptr),%r15\n\tmov\t%r12,8*0($rptr)\n\tlea\t8*4($tptr),$tptr\n\tmov\t%r13,8*1($rptr)\n\tsbb\t%r10,%r10\t\t# mov %cf,%r10\n\tmov\t%r14,8*2($rptr)\n\tmov\t%r15,8*3($rptr)\n\tlea\t8*4($rptr),$rptr\n\n\tinc\t%rcx\t\t\t# pass %cf\n\tjnz\t.Lsqr4x_sub\n\n\tmov\t$num,%r10\t\t# prepare for back-to-back call\n\tneg\t$num\t\t\t# restore $num\t\n\tret\n.size\t__bn_post4x_internal,.-__bn_post4x_internal\n___\n}\n{\n$code.=<<___;\n.globl\tbn_from_montgomery\n.type\tbn_from_montgomery,\\@abi-omnipotent\n.align\t32\nbn_from_montgomery:\n\ttestl\t\\$7,`($win64?\"48(%rsp)\":\"%r9d\")`\n\tjz\tbn_from_mont8x\n\txor\t%eax,%eax\n\tret\n.size\tbn_from_montgomery,.-bn_from_montgomery\n\n.type\tbn_from_mont8x,\\@function,6\n.align\t32\nbn_from_mont8x:\n\t.byte\t0x67\n\tmov\t%rsp,%rax\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n.Lfrom_prologue:\n\n\tshl\t\\$3,${num}d\t\t# convert $num to bytes\n\tlea\t($num,$num,2),%r10\t# 3*$num in bytes\n\tneg\t$num\n\tmov\t($n0),$n0\t\t# *n0\n\n\t##############################################################\n\t# Ensure that stack frame doesn't alias with $rptr+3*$num\n\t# modulo 4096, which covers ret[num], am[num] and n[num]\n\t# (see bn_exp.c). The stack is allocated to aligned with\n\t# bn_power5's frame, and as bn_from_montgomery happens to be\n\t# last operation, we use the opportunity to cleanse it.\n\t#\n\tlea\t-320(%rsp,$num,2),%r11\n\tmov\t%rsp,%rbp\n\tsub\t$rptr,%r11\n\tand\t\\$4095,%r11\n\tcmp\t%r11,%r10\n\tjb\t.Lfrom_sp_alt\n\tsub\t%r11,%rbp\t\t# align with $aptr\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*$num*8+256)\n\tjmp\t.Lfrom_sp_done\n\n.align\t32\n.Lfrom_sp_alt:\n\tlea\t4096-320(,$num,2),%r10\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*$num*8+256)\n\tsub\t%r10,%r11\n\tmov\t\\$0,%r10\n\tcmovc\t%r10,%r11\n\tsub\t%r11,%rbp\n.Lfrom_sp_done:\n\tand\t\\$-64,%rbp\n\tmov\t%rsp,%r11\n\tsub\t%rbp,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%rbp,%r11),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lfrom_page_walk\n\tjmp\t.Lfrom_page_walk_done\n\n.Lfrom_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lfrom_page_walk\n.Lfrom_page_walk_done:\n\n\tmov\t$num,%r10\n\tneg\t$num\n\n\t##############################################################\n\t# Stack layout\n\t#\n\t# +0\tsaved $num, used in reduction section\n\t# +8\t&t[2*$num], used in reduction section\n\t# +32\tsaved *n0\n\t# +40\tsaved %rsp\n\t# +48\tt[2*$num]\n\t#\n\tmov\t$n0,  32(%rsp)\n\tmov\t%rax, 40(%rsp)\t\t# save original %rsp\n.Lfrom_body:\n\tmov\t$num,%r11\n\tlea\t48(%rsp),%rax\n\tpxor\t%xmm0,%xmm0\n\tjmp\t.Lmul_by_1\n\n.align\t32\n.Lmul_by_1:\n\tmovdqu\t($aptr),%xmm1\n\tmovdqu\t16($aptr),%xmm2\n\tmovdqu\t32($aptr),%xmm3\n\tmovdqa\t%xmm0,(%rax,$num)\n\tmovdqu\t48($aptr),%xmm4\n\tmovdqa\t%xmm0,16(%rax,$num)\n\t.byte\t0x48,0x8d,0xb6,0x40,0x00,0x00,0x00\t# lea\t64($aptr),$aptr\n\tmovdqa\t%xmm1,(%rax)\n\tmovdqa\t%xmm0,32(%rax,$num)\n\tmovdqa\t%xmm2,16(%rax)\n\tmovdqa\t%xmm0,48(%rax,$num)\n\tmovdqa\t%xmm3,32(%rax)\n\tmovdqa\t%xmm4,48(%rax)\n\tlea\t64(%rax),%rax\n\tsub\t\\$64,%r11\n\tjnz\t.Lmul_by_1\n\n\tmovq\t$rptr,%xmm1\n\tmovq\t$nptr,%xmm2\n\t.byte\t0x67\n\tmov\t$nptr,%rbp\n\tmovq\t%r10, %xmm3\t\t# -num\n___\n$code.=<<___ if ($addx);\n\tmov\tOPENSSL_ia32cap_P+8(%rip),%r11d\n\tand\t\\$0x80108,%r11d\n\tcmp\t\\$0x80108,%r11d\t\t# check for AD*X+BMI2+BMI1\n\tjne\t.Lfrom_mont_nox\n\n\tlea\t(%rax,$num),$rptr\n\tcall\t__bn_sqrx8x_reduction\n\tcall\t__bn_postx4x_internal\n\n\tpxor\t%xmm0,%xmm0\n\tlea\t48(%rsp),%rax\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tjmp\t.Lfrom_mont_zero\n\n.align\t32\n.Lfrom_mont_nox:\n___\n$code.=<<___;\n\tcall\t__bn_sqr8x_reduction\n\tcall\t__bn_post4x_internal\n\n\tpxor\t%xmm0,%xmm0\n\tlea\t48(%rsp),%rax\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tjmp\t.Lfrom_mont_zero\n\n.align\t32\n.Lfrom_mont_zero:\n\tmovdqa\t%xmm0,16*0(%rax)\n\tmovdqa\t%xmm0,16*1(%rax)\n\tmovdqa\t%xmm0,16*2(%rax)\n\tmovdqa\t%xmm0,16*3(%rax)\n\tlea\t16*4(%rax),%rax\n\tsub\t\\$32,$num\n\tjnz\t.Lfrom_mont_zero\n\n\tmov\t\\$1,%rax\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lfrom_epilogue:\n\tret\n.size\tbn_from_mont8x,.-bn_from_mont8x\n___\n}\n}}}\n\f\nif ($addx) {{{\nmy $bp=\"%rdx\";\t# restore original value\n\n$code.=<<___;\n.type\tbn_mulx4x_mont_gather5,\\@function,6\n.align\t32\nbn_mulx4x_mont_gather5:\n\tmov\t%rsp,%rax\n.Lmulx4x_enter:\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n.Lmulx4x_prologue:\n\n\tshl\t\\$3,${num}d\t\t# convert $num to bytes\n\tlea\t($num,$num,2),%r10\t# 3*$num in bytes\n\tneg\t$num\t\t\t# -$num\n\tmov\t($n0),$n0\t\t# *n0\n\n\t##############################################################\n\t# Ensure that stack frame doesn't alias with $rptr+3*$num\n\t# modulo 4096, which covers ret[num], am[num] and n[num]\n\t# (see bn_exp.c). This is done to allow memory disambiguation\n\t# logic do its magic. [Extra [num] is allocated in order\n\t# to align with bn_power5's frame, which is cleansed after\n\t# completing exponentiation. Extra 256 bytes is for power mask\n\t# calculated from 7th argument, the index.]\n\t#\n\tlea\t-320(%rsp,$num,2),%r11\n\tmov\t%rsp,%rbp\n\tsub\t$rp,%r11\n\tand\t\\$4095,%r11\n\tcmp\t%r11,%r10\n\tjb\t.Lmulx4xsp_alt\n\tsub\t%r11,%rbp\t\t# align with $aptr\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*$num*8+256)\n\tjmp\t.Lmulx4xsp_done\n\n.Lmulx4xsp_alt:\n\tlea\t4096-320(,$num,2),%r10\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*$num*8+256)\n\tsub\t%r10,%r11\n\tmov\t\\$0,%r10\n\tcmovc\t%r10,%r11\n\tsub\t%r11,%rbp\n.Lmulx4xsp_done:\t\n\tand\t\\$-64,%rbp\t\t# ensure alignment\n\tmov\t%rsp,%r11\n\tsub\t%rbp,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%rbp,%r11),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lmulx4x_page_walk\n\tjmp\t.Lmulx4x_page_walk_done\n\n.Lmulx4x_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lmulx4x_page_walk\n.Lmulx4x_page_walk_done:\n\n\t##############################################################\n\t# Stack layout\n\t# +0\t-num\n\t# +8\toff-loaded &b[i]\n\t# +16\tend of b[num]\n\t# +24\tinner counter\n\t# +32\tsaved n0\n\t# +40\tsaved %rsp\n\t# +48\n\t# +56\tsaved rp\n\t# +64\ttmp[num+1]\n\t#\n\tmov\t$n0, 32(%rsp)\t\t# save *n0\n\tmov\t%rax,40(%rsp)\t\t# save original %rsp\n.Lmulx4x_body:\n\tcall\tmulx4x_internal\n\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tmov\t\\$1,%rax\n\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lmulx4x_epilogue:\n\tret\n.size\tbn_mulx4x_mont_gather5,.-bn_mulx4x_mont_gather5\n\n.type\tmulx4x_internal,\\@abi-omnipotent\n.align\t32\nmulx4x_internal:\n\tmov\t$num,8(%rsp)\t\t# save -$num (it was in bytes)\n\tmov\t$num,%r10\n\tneg\t$num\t\t\t# restore $num\n\tshl\t\\$5,$num\n\tneg\t%r10\t\t\t# restore $num\n\tlea\t128($bp,$num),%r13\t# end of powers table (+size optimization)\n\tshr\t\\$5+5,$num\n\tmovd\t`($win64?56:8)`(%rax),%xmm5\t# load 7th argument\n\tsub\t\\$1,$num\n\tlea\t.Linc(%rip),%rax\n\tmov\t%r13,16+8(%rsp)\t\t# end of b[num]\n\tmov\t$num,24+8(%rsp)\t\t# inner counter\n\tmov\t$rp, 56+8(%rsp)\t\t# save $rp\n___\nmy ($aptr, $bptr, $nptr, $tptr, $mi,  $bi,  $zero, $num)=\n   (\"%rsi\",\"%rdi\",\"%rcx\",\"%rbx\",\"%r8\",\"%r9\",\"%rbp\",\"%rax\");\nmy $rptr=$bptr;\nmy $STRIDE=2**5*8;\t\t# 5 is \"window size\"\nmy $N=$STRIDE/4;\t\t# should match cache line size\n$code.=<<___;\n\tmovdqa\t0(%rax),%xmm0\t\t# 00000001000000010000000000000000\n\tmovdqa\t16(%rax),%xmm1\t\t# 00000002000000020000000200000002\n\tlea\t88-112(%rsp,%r10),%r10\t# place the mask after tp[num+1] (+ICache optimizaton)\n\tlea\t128($bp),$bptr\t\t# size optimization\n\n\tpshufd\t\\$0,%xmm5,%xmm5\t\t# broadcast index\n\tmovdqa\t%xmm1,%xmm4\n\t.byte\t0x67\n\tmovdqa\t%xmm1,%xmm2\n___\n########################################################################\n# calculate mask by comparing 0..31 to index and save result to stack\n#\n$code.=<<___;\n\t.byte\t0x67\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\t\t# compare to 1,0\n\tmovdqa\t%xmm4,%xmm3\n___\nfor($i=0;$i<$STRIDE/16-4;$i+=4) {\n$code.=<<___;\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\t\t# compare to 3,2\n\tmovdqa\t%xmm0,`16*($i+0)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm0\n\n\tpaddd\t%xmm2,%xmm3\n\tpcmpeqd\t%xmm5,%xmm2\t\t# compare to 5,4\n\tmovdqa\t%xmm1,`16*($i+1)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm1\n\n\tpaddd\t%xmm3,%xmm0\n\tpcmpeqd\t%xmm5,%xmm3\t\t# compare to 7,6\n\tmovdqa\t%xmm2,`16*($i+2)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm2\n\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\n\tmovdqa\t%xmm3,`16*($i+3)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm3\n___\n}\n$code.=<<___;\t\t\t\t# last iteration can be optimized\n\t.byte\t0x67\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\n\tmovdqa\t%xmm0,`16*($i+0)+112`(%r10)\n\n\tpaddd\t%xmm2,%xmm3\n\tpcmpeqd\t%xmm5,%xmm2\n\tmovdqa\t%xmm1,`16*($i+1)+112`(%r10)\n\n\tpcmpeqd\t%xmm5,%xmm3\n\tmovdqa\t%xmm2,`16*($i+2)+112`(%r10)\n\n\tpand\t`16*($i+0)-128`($bptr),%xmm0\t# while it's still in register\n\tpand\t`16*($i+1)-128`($bptr),%xmm1\n\tpand\t`16*($i+2)-128`($bptr),%xmm2\n\tmovdqa\t%xmm3,`16*($i+3)+112`(%r10)\n\tpand\t`16*($i+3)-128`($bptr),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\nfor($i=0;$i<$STRIDE/16-4;$i+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($i+0)-128`($bptr),%xmm4\n\tmovdqa\t`16*($i+1)-128`($bptr),%xmm5\n\tmovdqa\t`16*($i+2)-128`($bptr),%xmm2\n\tpand\t`16*($i+0)+112`(%r10),%xmm4\n\tmovdqa\t`16*($i+3)-128`($bptr),%xmm3\n\tpand\t`16*($i+1)+112`(%r10),%xmm5\n\tpor\t%xmm4,%xmm0\n\tpand\t`16*($i+2)+112`(%r10),%xmm2\n\tpor\t%xmm5,%xmm1\n\tpand\t`16*($i+3)+112`(%r10),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\n}\n$code.=<<___;\n\tpxor\t%xmm1,%xmm0\n\tpshufd\t\\$0x4e,%xmm0,%xmm1\n\tpor\t%xmm1,%xmm0\n\tlea\t$STRIDE($bptr),$bptr\n\tmovq\t%xmm0,%rdx\t\t# bp[0]\n\tlea\t64+8*4+8(%rsp),$tptr\n\n\tmov\t%rdx,$bi\n\tmulx\t0*8($aptr),$mi,%rax\t# a[0]*b[0]\n\tmulx\t1*8($aptr),%r11,%r12\t# a[1]*b[0]\n\tadd\t%rax,%r11\n\tmulx\t2*8($aptr),%rax,%r13\t# ...\n\tadc\t%rax,%r12\n\tadc\t\\$0,%r13\n\tmulx\t3*8($aptr),%rax,%r14\n\n\tmov\t$mi,%r15\n\timulq\t32+8(%rsp),$mi\t\t# \"t[0]\"*n0\n\txor\t$zero,$zero\t\t# cf=0, of=0\n\tmov\t$mi,%rdx\n\n\tmov\t$bptr,8+8(%rsp)\t\t# off-load &b[i]\n\n\tlea\t4*8($aptr),$aptr\n\tadcx\t%rax,%r13\n\tadcx\t$zero,%r14\t\t# cf=0\n\n\tmulx\t0*8($nptr),%rax,%r10\n\tadcx\t%rax,%r15\t\t# discarded\n\tadox\t%r11,%r10\n\tmulx\t1*8($nptr),%rax,%r11\n\tadcx\t%rax,%r10\n\tadox\t%r12,%r11\n\tmulx\t2*8($nptr),%rax,%r12\n\tmov\t24+8(%rsp),$bptr\t# counter value\n\tmov\t%r10,-8*4($tptr)\n\tadcx\t%rax,%r11\n\tadox\t%r13,%r12\n\tmulx\t3*8($nptr),%rax,%r15\n\t mov\t$bi,%rdx\n\tmov\t%r11,-8*3($tptr)\n\tadcx\t%rax,%r12\n\tadox\t$zero,%r15\t\t# of=0\n\tlea\t4*8($nptr),$nptr\n\tmov\t%r12,-8*2($tptr)\n\tjmp\t.Lmulx4x_1st\n\n.align\t32\n.Lmulx4x_1st:\n\tadcx\t$zero,%r15\t\t# cf=0, modulo-scheduled\n\tmulx\t0*8($aptr),%r10,%rax\t# a[4]*b[0]\n\tadcx\t%r14,%r10\n\tmulx\t1*8($aptr),%r11,%r14\t# a[5]*b[0]\n\tadcx\t%rax,%r11\n\tmulx\t2*8($aptr),%r12,%rax\t# ...\n\tadcx\t%r14,%r12\n\tmulx\t3*8($aptr),%r13,%r14\n\t .byte\t0x67,0x67\n\t mov\t$mi,%rdx\n\tadcx\t%rax,%r13\n\tadcx\t$zero,%r14\t\t# cf=0\n\tlea\t4*8($aptr),$aptr\n\tlea\t4*8($tptr),$tptr\n\n\tadox\t%r15,%r10\n\tmulx\t0*8($nptr),%rax,%r15\n\tadcx\t%rax,%r10\n\tadox\t%r15,%r11\n\tmulx\t1*8($nptr),%rax,%r15\n\tadcx\t%rax,%r11\n\tadox\t%r15,%r12\n\tmulx\t2*8($nptr),%rax,%r15\n\tmov\t%r10,-5*8($tptr)\n\tadcx\t%rax,%r12\n\tmov\t%r11,-4*8($tptr)\n\tadox\t%r15,%r13\n\tmulx\t3*8($nptr),%rax,%r15\n\t mov\t$bi,%rdx\n\tmov\t%r12,-3*8($tptr)\n\tadcx\t%rax,%r13\n\tadox\t$zero,%r15\n\tlea\t4*8($nptr),$nptr\n\tmov\t%r13,-2*8($tptr)\n\n\tdec\t$bptr\t\t\t# of=0, pass cf\n\tjnz\t.Lmulx4x_1st\n\n\tmov\t8(%rsp),$num\t\t# load -num\n\tadc\t$zero,%r15\t\t# modulo-scheduled\n\tlea\t($aptr,$num),$aptr\t# rewind $aptr\n\tadd\t%r15,%r14\n\tmov\t8+8(%rsp),$bptr\t\t# re-load &b[i]\n\tadc\t$zero,$zero\t\t# top-most carry\n\tmov\t%r14,-1*8($tptr)\n\tjmp\t.Lmulx4x_outer\n\n.align\t32\n.Lmulx4x_outer:\n\tlea\t16-256($tptr),%r10\t# where 256-byte mask is (+density control)\n\tpxor\t%xmm4,%xmm4\n\t.byte\t0x67,0x67\n\tpxor\t%xmm5,%xmm5\n___\nfor($i=0;$i<$STRIDE/16;$i+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($i+0)-128`($bptr),%xmm0\n\tmovdqa\t`16*($i+1)-128`($bptr),%xmm1\n\tmovdqa\t`16*($i+2)-128`($bptr),%xmm2\n\tpand\t`16*($i+0)+256`(%r10),%xmm0\n\tmovdqa\t`16*($i+3)-128`($bptr),%xmm3\n\tpand\t`16*($i+1)+256`(%r10),%xmm1\n\tpor\t%xmm0,%xmm4\n\tpand\t`16*($i+2)+256`(%r10),%xmm2\n\tpor\t%xmm1,%xmm5\n\tpand\t`16*($i+3)+256`(%r10),%xmm3\n\tpor\t%xmm2,%xmm4\n\tpor\t%xmm3,%xmm5\n___\n}\n$code.=<<___;\n\tpor\t%xmm5,%xmm4\n\tpshufd\t\\$0x4e,%xmm4,%xmm0\n\tpor\t%xmm4,%xmm0\n\tlea\t$STRIDE($bptr),$bptr\n\tmovq\t%xmm0,%rdx\t\t# m0=bp[i]\n\n\tmov\t$zero,($tptr)\t\t# save top-most carry\n\tlea\t4*8($tptr,$num),$tptr\t# rewind $tptr\n\tmulx\t0*8($aptr),$mi,%r11\t# a[0]*b[i]\n\txor\t$zero,$zero\t\t# cf=0, of=0\n\tmov\t%rdx,$bi\n\tmulx\t1*8($aptr),%r14,%r12\t# a[1]*b[i]\n\tadox\t-4*8($tptr),$mi\t\t# +t[0]\n\tadcx\t%r14,%r11\n\tmulx\t2*8($aptr),%r15,%r13\t# ...\n\tadox\t-3*8($tptr),%r11\n\tadcx\t%r15,%r12\n\tmulx\t3*8($aptr),%rdx,%r14\n\tadox\t-2*8($tptr),%r12\n\tadcx\t%rdx,%r13\n\tlea\t($nptr,$num),$nptr\t# rewind $nptr\n\tlea\t4*8($aptr),$aptr\n\tadox\t-1*8($tptr),%r13\n\tadcx\t$zero,%r14\n\tadox\t$zero,%r14\n\n\tmov\t$mi,%r15\n\timulq\t32+8(%rsp),$mi\t\t# \"t[0]\"*n0\n\n\tmov\t$mi,%rdx\n\txor\t$zero,$zero\t\t# cf=0, of=0\n\tmov\t$bptr,8+8(%rsp)\t\t# off-load &b[i]\n\n\tmulx\t0*8($nptr),%rax,%r10\n\tadcx\t%rax,%r15\t\t# discarded\n\tadox\t%r11,%r10\n\tmulx\t1*8($nptr),%rax,%r11\n\tadcx\t%rax,%r10\n\tadox\t%r12,%r11\n\tmulx\t2*8($nptr),%rax,%r12\n\tadcx\t%rax,%r11\n\tadox\t%r13,%r12\n\tmulx\t3*8($nptr),%rax,%r15\n\t mov\t$bi,%rdx\n\tmov\t24+8(%rsp),$bptr\t# counter value\n\tmov\t%r10,-8*4($tptr)\n\tadcx\t%rax,%r12\n\tmov\t%r11,-8*3($tptr)\n\tadox\t$zero,%r15\t\t# of=0\n\tmov\t%r12,-8*2($tptr)\n\tlea\t4*8($nptr),$nptr\n\tjmp\t.Lmulx4x_inner\n\n.align\t32\n.Lmulx4x_inner:\n\tmulx\t0*8($aptr),%r10,%rax\t# a[4]*b[i]\n\tadcx\t$zero,%r15\t\t# cf=0, modulo-scheduled\n\tadox\t%r14,%r10\n\tmulx\t1*8($aptr),%r11,%r14\t# a[5]*b[i]\n\tadcx\t0*8($tptr),%r10\n\tadox\t%rax,%r11\n\tmulx\t2*8($aptr),%r12,%rax\t# ...\n\tadcx\t1*8($tptr),%r11\n\tadox\t%r14,%r12\n\tmulx\t3*8($aptr),%r13,%r14\n\t mov\t$mi,%rdx\n\tadcx\t2*8($tptr),%r12\n\tadox\t%rax,%r13\n\tadcx\t3*8($tptr),%r13\n\tadox\t$zero,%r14\t\t# of=0\n\tlea\t4*8($aptr),$aptr\n\tlea\t4*8($tptr),$tptr\n\tadcx\t$zero,%r14\t\t# cf=0\n\n\tadox\t%r15,%r10\n\tmulx\t0*8($nptr),%rax,%r15\n\tadcx\t%rax,%r10\n\tadox\t%r15,%r11\n\tmulx\t1*8($nptr),%rax,%r15\n\tadcx\t%rax,%r11\n\tadox\t%r15,%r12\n\tmulx\t2*8($nptr),%rax,%r15\n\tmov\t%r10,-5*8($tptr)\n\tadcx\t%rax,%r12\n\tadox\t%r15,%r13\n\tmov\t%r11,-4*8($tptr)\n\tmulx\t3*8($nptr),%rax,%r15\n\t mov\t$bi,%rdx\n\tlea\t4*8($nptr),$nptr\n\tmov\t%r12,-3*8($tptr)\n\tadcx\t%rax,%r13\n\tadox\t$zero,%r15\n\tmov\t%r13,-2*8($tptr)\n\n\tdec\t$bptr\t\t\t# of=0, pass cf\n\tjnz\t.Lmulx4x_inner\n\n\tmov\t0+8(%rsp),$num\t\t# load -num\n\tadc\t$zero,%r15\t\t# modulo-scheduled\n\tsub\t0*8($tptr),$bptr\t# pull top-most carry to %cf\n\tmov\t8+8(%rsp),$bptr\t\t# re-load &b[i]\n\tmov\t16+8(%rsp),%r10\n\tadc\t%r15,%r14\n\tlea\t($aptr,$num),$aptr\t# rewind $aptr\n\tadc\t$zero,$zero\t\t# top-most carry\n\tmov\t%r14,-1*8($tptr)\n\n\tcmp\t%r10,$bptr\n\tjb\t.Lmulx4x_outer\n\n\tmov\t-8($nptr),%r10\n\tmov\t$zero,%r8\n\tmov\t($nptr,$num),%r12\n\tlea\t($nptr,$num),%rbp\t# rewind $nptr\n\tmov\t$num,%rcx\n\tlea\t($tptr,$num),%rdi\t# rewind $tptr\n\txor\t%eax,%eax\n\txor\t%r15,%r15\n\tsub\t%r14,%r10\t\t# compare top-most words\n\tadc\t%r15,%r15\n\tor\t%r15,%r8\n\tsar\t\\$3+2,%rcx\n\tsub\t%r8,%rax\t\t# %rax=-%r8\n\tmov\t56+8(%rsp),%rdx\t\t# restore rp\n\tdec\t%r12\t\t\t# so that after 'not' we get -n[0]\n\tmov\t8*1(%rbp),%r13\n\txor\t%r8,%r8\n\tmov\t8*2(%rbp),%r14\n\tmov\t8*3(%rbp),%r15\n\tjmp\t.Lsqrx4x_sub_entry\t# common post-condition\n.size\tmulx4x_internal,.-mulx4x_internal\n___\n}\f{\n######################################################################\n# void bn_power5(\nmy $rptr=\"%rdi\";\t# BN_ULONG *rptr,\nmy $aptr=\"%rsi\";\t# const BN_ULONG *aptr,\nmy $bptr=\"%rdx\";\t# const void *table,\nmy $nptr=\"%rcx\";\t# const BN_ULONG *nptr,\nmy $n0  =\"%r8\";\t\t# const BN_ULONG *n0);\nmy $num =\"%r9\";\t\t# int num, has to be divisible by 8\n\t\t\t# int pwr);\n\nmy ($i,$j,$tptr)=(\"%rbp\",\"%rcx\",$rptr);\nmy @A0=(\"%r10\",\"%r11\");\nmy @A1=(\"%r12\",\"%r13\");\nmy ($a0,$a1,$ai)=(\"%r14\",\"%r15\",\"%rbx\");\n\n$code.=<<___;\n.type\tbn_powerx5,\\@function,6\n.align\t32\nbn_powerx5:\n\tmov\t%rsp,%rax\n.Lpowerx5_enter:\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n.Lpowerx5_prologue:\n\n\tshl\t\\$3,${num}d\t\t# convert $num to bytes\n\tlea\t($num,$num,2),%r10\t# 3*$num in bytes\n\tneg\t$num\n\tmov\t($n0),$n0\t\t# *n0\n\n\t##############################################################\n\t# Ensure that stack frame doesn't alias with $rptr+3*$num\n\t# modulo 4096, which covers ret[num], am[num] and n[num]\n\t# (see bn_exp.c). This is done to allow memory disambiguation\n\t# logic do its magic. [Extra 256 bytes is for power mask\n\t# calculated from 7th argument, the index.]\n\t#\n\tlea\t-320(%rsp,$num,2),%r11\n\tmov\t%rsp,%rbp\n\tsub\t$rptr,%r11\n\tand\t\\$4095,%r11\n\tcmp\t%r11,%r10\n\tjb\t.Lpwrx_sp_alt\n\tsub\t%r11,%rbp\t\t# align with $aptr\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*$num*8+256)\n\tjmp\t.Lpwrx_sp_done\n\n.align\t32\n.Lpwrx_sp_alt:\n\tlea\t4096-320(,$num,2),%r10\n\tlea\t-320(%rbp,$num,2),%rbp\t# alloca(frame+2*$num*8+256)\n\tsub\t%r10,%r11\n\tmov\t\\$0,%r10\n\tcmovc\t%r10,%r11\n\tsub\t%r11,%rbp\n.Lpwrx_sp_done:\n\tand\t\\$-64,%rbp\n\tmov\t%rsp,%r11\n\tsub\t%rbp,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%rbp,%r11),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lpwrx_page_walk\n\tjmp\t.Lpwrx_page_walk_done\n\n.Lpwrx_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lpwrx_page_walk\n.Lpwrx_page_walk_done:\n\n\tmov\t$num,%r10\t\n\tneg\t$num\n\n\t##############################################################\n\t# Stack layout\n\t#\n\t# +0\tsaved $num, used in reduction section\n\t# +8\t&t[2*$num], used in reduction section\n\t# +16\tintermediate carry bit\n\t# +24\ttop-most carry bit, used in reduction section\n\t# +32\tsaved *n0\n\t# +40\tsaved %rsp\n\t# +48\tt[2*$num]\n\t#\n\tpxor\t%xmm0,%xmm0\n\tmovq\t$rptr,%xmm1\t\t# save $rptr\n\tmovq\t$nptr,%xmm2\t\t# save $nptr\n\tmovq\t%r10, %xmm3\t\t# -$num\n\tmovq\t$bptr,%xmm4\n\tmov\t$n0,  32(%rsp)\n\tmov\t%rax, 40(%rsp)\t\t# save original %rsp\n.Lpowerx5_body:\n\n\tcall\t__bn_sqrx8x_internal\n\tcall\t__bn_postx4x_internal\n\tcall\t__bn_sqrx8x_internal\n\tcall\t__bn_postx4x_internal\n\tcall\t__bn_sqrx8x_internal\n\tcall\t__bn_postx4x_internal\n\tcall\t__bn_sqrx8x_internal\n\tcall\t__bn_postx4x_internal\n\tcall\t__bn_sqrx8x_internal\n\tcall\t__bn_postx4x_internal\n\n\tmov\t%r10,$num\t\t# -num\n\tmov\t$aptr,$rptr\n\tmovq\t%xmm2,$nptr\n\tmovq\t%xmm4,$bptr\n\tmov\t40(%rsp),%rax\n\n\tcall\tmulx4x_internal\n\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tmov\t\\$1,%rax\n\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lpowerx5_epilogue:\n\tret\n.size\tbn_powerx5,.-bn_powerx5\n\n.globl\tbn_sqrx8x_internal\n.hidden\tbn_sqrx8x_internal\n.type\tbn_sqrx8x_internal,\\@abi-omnipotent\n.align\t32\nbn_sqrx8x_internal:\n__bn_sqrx8x_internal:\n\t##################################################################\n\t# Squaring part:\n\t#\n\t# a) multiply-n-add everything but a[i]*a[i];\n\t# b) shift result of a) by 1 to the left and accumulate\n\t#    a[i]*a[i] products;\n\t#\n\t##################################################################\n\t# a[7]a[7]a[6]a[6]a[5]a[5]a[4]a[4]a[3]a[3]a[2]a[2]a[1]a[1]a[0]a[0]\n\t#                                                     a[1]a[0]\n\t#                                                 a[2]a[0]\n\t#                                             a[3]a[0]\n\t#                                             a[2]a[1]\n\t#                                         a[3]a[1]\n\t#                                     a[3]a[2]\n\t#\n\t#                                         a[4]a[0]\n\t#                                     a[5]a[0]\n\t#                                 a[6]a[0]\n\t#                             a[7]a[0]\n\t#                                     a[4]a[1]\n\t#                                 a[5]a[1]\n\t#                             a[6]a[1]\n\t#                         a[7]a[1]\n\t#                                 a[4]a[2]\n\t#                             a[5]a[2]\n\t#                         a[6]a[2]\n\t#                     a[7]a[2]\n\t#                             a[4]a[3]\n\t#                         a[5]a[3]\n\t#                     a[6]a[3]\n\t#                 a[7]a[3]\n\t#\n\t#                     a[5]a[4]\n\t#                 a[6]a[4]\n\t#             a[7]a[4]\n\t#             a[6]a[5]\n\t#         a[7]a[5]\n\t#     a[7]a[6]\n\t# a[7]a[7]a[6]a[6]a[5]a[5]a[4]a[4]a[3]a[3]a[2]a[2]a[1]a[1]a[0]a[0]\n___\n{\nmy ($zero,$carry)=(\"%rbp\",\"%rcx\");\nmy $aaptr=$zero;\n$code.=<<___;\n\tlea\t48+8(%rsp),$tptr\n\tlea\t($aptr,$num),$aaptr\n\tmov\t$num,0+8(%rsp)\t\t\t# save $num\n\tmov\t$aaptr,8+8(%rsp)\t\t# save end of $aptr\n\tjmp\t.Lsqr8x_zero_start\n\n.align\t32\n.byte\t0x66,0x66,0x66,0x2e,0x0f,0x1f,0x84,0x00,0x00,0x00,0x00,0x00\n.Lsqrx8x_zero:\n\t.byte\t0x3e\n\tmovdqa\t%xmm0,0*8($tptr)\n\tmovdqa\t%xmm0,2*8($tptr)\n\tmovdqa\t%xmm0,4*8($tptr)\n\tmovdqa\t%xmm0,6*8($tptr)\n.Lsqr8x_zero_start:\t\t\t# aligned at 32\n\tmovdqa\t%xmm0,8*8($tptr)\n\tmovdqa\t%xmm0,10*8($tptr)\n\tmovdqa\t%xmm0,12*8($tptr)\n\tmovdqa\t%xmm0,14*8($tptr)\n\tlea\t16*8($tptr),$tptr\n\tsub\t\\$64,$num\n\tjnz\t.Lsqrx8x_zero\n\n\tmov\t0*8($aptr),%rdx\t\t# a[0], modulo-scheduled\n\t#xor\t%r9,%r9\t\t\t# t[1], ex-$num, zero already\n\txor\t%r10,%r10\n\txor\t%r11,%r11\n\txor\t%r12,%r12\n\txor\t%r13,%r13\n\txor\t%r14,%r14\n\txor\t%r15,%r15\n\tlea\t48+8(%rsp),$tptr\n\txor\t$zero,$zero\t\t# cf=0, cf=0\n\tjmp\t.Lsqrx8x_outer_loop\n\n.align\t32\n.Lsqrx8x_outer_loop:\n\tmulx\t1*8($aptr),%r8,%rax\t# a[1]*a[0]\n\tadcx\t%r9,%r8\t\t\t# a[1]*a[0]+=t[1]\n\tadox\t%rax,%r10\n\tmulx\t2*8($aptr),%r9,%rax\t# a[2]*a[0]\n\tadcx\t%r10,%r9\n\tadox\t%rax,%r11\n\t.byte\t0xc4,0xe2,0xab,0xf6,0x86,0x18,0x00,0x00,0x00\t# mulx\t3*8($aptr),%r10,%rax\t# ...\n\tadcx\t%r11,%r10\n\tadox\t%rax,%r12\n\t.byte\t0xc4,0xe2,0xa3,0xf6,0x86,0x20,0x00,0x00,0x00\t# mulx\t4*8($aptr),%r11,%rax\n\tadcx\t%r12,%r11\n\tadox\t%rax,%r13\n\tmulx\t5*8($aptr),%r12,%rax\n\tadcx\t%r13,%r12\n\tadox\t%rax,%r14\n\tmulx\t6*8($aptr),%r13,%rax\n\tadcx\t%r14,%r13\n\tadox\t%r15,%rax\n\tmulx\t7*8($aptr),%r14,%r15\n\t mov\t1*8($aptr),%rdx\t\t# a[1]\n\tadcx\t%rax,%r14\n\tadox\t$zero,%r15\n\tadc\t8*8($tptr),%r15\n\tmov\t%r8,1*8($tptr)\t\t# t[1]\n\tmov\t%r9,2*8($tptr)\t\t# t[2]\n\tsbb\t$carry,$carry\t\t# mov %cf,$carry\n\txor\t$zero,$zero\t\t# cf=0, of=0\n\n\n\tmulx\t2*8($aptr),%r8,%rbx\t# a[2]*a[1]\n\tmulx\t3*8($aptr),%r9,%rax\t# a[3]*a[1]\n\tadcx\t%r10,%r8\n\tadox\t%rbx,%r9\n\tmulx\t4*8($aptr),%r10,%rbx\t# ...\n\tadcx\t%r11,%r9\n\tadox\t%rax,%r10\n\t.byte\t0xc4,0xe2,0xa3,0xf6,0x86,0x28,0x00,0x00,0x00\t# mulx\t5*8($aptr),%r11,%rax\n\tadcx\t%r12,%r10\n\tadox\t%rbx,%r11\n\t.byte\t0xc4,0xe2,0x9b,0xf6,0x9e,0x30,0x00,0x00,0x00\t# mulx\t6*8($aptr),%r12,%rbx\n\tadcx\t%r13,%r11\n\tadox\t%r14,%r12\n\t.byte\t0xc4,0x62,0x93,0xf6,0xb6,0x38,0x00,0x00,0x00\t# mulx\t7*8($aptr),%r13,%r14\n\t mov\t2*8($aptr),%rdx\t\t# a[2]\n\tadcx\t%rax,%r12\n\tadox\t%rbx,%r13\n\tadcx\t%r15,%r13\n\tadox\t$zero,%r14\t\t# of=0\n\tadcx\t$zero,%r14\t\t# cf=0\n\n\tmov\t%r8,3*8($tptr)\t\t# t[3]\n\tmov\t%r9,4*8($tptr)\t\t# t[4]\n\n\tmulx\t3*8($aptr),%r8,%rbx\t# a[3]*a[2]\n\tmulx\t4*8($aptr),%r9,%rax\t# a[4]*a[2]\n\tadcx\t%r10,%r8\n\tadox\t%rbx,%r9\n\tmulx\t5*8($aptr),%r10,%rbx\t# ...\n\tadcx\t%r11,%r9\n\tadox\t%rax,%r10\n\t.byte\t0xc4,0xe2,0xa3,0xf6,0x86,0x30,0x00,0x00,0x00\t# mulx\t6*8($aptr),%r11,%rax\n\tadcx\t%r12,%r10\n\tadox\t%r13,%r11\n\t.byte\t0xc4,0x62,0x9b,0xf6,0xae,0x38,0x00,0x00,0x00\t# mulx\t7*8($aptr),%r12,%r13\n\t.byte\t0x3e\n\t mov\t3*8($aptr),%rdx\t\t# a[3]\n\tadcx\t%rbx,%r11\n\tadox\t%rax,%r12\n\tadcx\t%r14,%r12\n\tmov\t%r8,5*8($tptr)\t\t# t[5]\n\tmov\t%r9,6*8($tptr)\t\t# t[6]\n\t mulx\t4*8($aptr),%r8,%rax\t# a[4]*a[3]\n\tadox\t$zero,%r13\t\t# of=0\n\tadcx\t$zero,%r13\t\t# cf=0\n\n\tmulx\t5*8($aptr),%r9,%rbx\t# a[5]*a[3]\n\tadcx\t%r10,%r8\n\tadox\t%rax,%r9\n\tmulx\t6*8($aptr),%r10,%rax\t# ...\n\tadcx\t%r11,%r9\n\tadox\t%r12,%r10\n\tmulx\t7*8($aptr),%r11,%r12\n\t mov\t4*8($aptr),%rdx\t\t# a[4]\n\t mov\t5*8($aptr),%r14\t\t# a[5]\n\tadcx\t%rbx,%r10\n\tadox\t%rax,%r11\n\t mov\t6*8($aptr),%r15\t\t# a[6]\n\tadcx\t%r13,%r11\n\tadox\t$zero,%r12\t\t# of=0\n\tadcx\t$zero,%r12\t\t# cf=0\n\n\tmov\t%r8,7*8($tptr)\t\t# t[7]\n\tmov\t%r9,8*8($tptr)\t\t# t[8]\n\n\tmulx\t%r14,%r9,%rax\t\t# a[5]*a[4]\n\t mov\t7*8($aptr),%r8\t\t# a[7]\n\tadcx\t%r10,%r9\n\tmulx\t%r15,%r10,%rbx\t\t# a[6]*a[4]\n\tadox\t%rax,%r10\n\tadcx\t%r11,%r10\n\tmulx\t%r8,%r11,%rax\t\t# a[7]*a[4]\n\t mov\t%r14,%rdx\t\t# a[5]\n\tadox\t%rbx,%r11\n\tadcx\t%r12,%r11\n\t#adox\t$zero,%rax\t\t# of=0\n\tadcx\t$zero,%rax\t\t# cf=0\n\n\tmulx\t%r15,%r14,%rbx\t\t# a[6]*a[5]\n\tmulx\t%r8,%r12,%r13\t\t# a[7]*a[5]\n\t mov\t%r15,%rdx\t\t# a[6]\n\t lea\t8*8($aptr),$aptr\n\tadcx\t%r14,%r11\n\tadox\t%rbx,%r12\n\tadcx\t%rax,%r12\n\tadox\t$zero,%r13\n\n\t.byte\t0x67,0x67\n\tmulx\t%r8,%r8,%r14\t\t# a[7]*a[6]\n\tadcx\t%r8,%r13\n\tadcx\t$zero,%r14\n\n\tcmp\t8+8(%rsp),$aptr\n\tje\t.Lsqrx8x_outer_break\n\n\tneg\t$carry\t\t\t# mov $carry,%cf\n\tmov\t\\$-8,%rcx\n\tmov\t$zero,%r15\n\tmov\t8*8($tptr),%r8\n\tadcx\t9*8($tptr),%r9\t\t# +=t[9]\n\tadcx\t10*8($tptr),%r10\t# ...\n\tadcx\t11*8($tptr),%r11\n\tadc\t12*8($tptr),%r12\n\tadc\t13*8($tptr),%r13\n\tadc\t14*8($tptr),%r14\n\tadc\t15*8($tptr),%r15\n\tlea\t($aptr),$aaptr\n\tlea\t2*64($tptr),$tptr\n\tsbb\t%rax,%rax\t\t# mov %cf,$carry\n\n\tmov\t-64($aptr),%rdx\t\t# a[0]\n\tmov\t%rax,16+8(%rsp)\t\t# offload $carry\n\tmov\t$tptr,24+8(%rsp)\n\n\t#lea\t8*8($tptr),$tptr\t# see 2*8*8($tptr) above\n\txor\t%eax,%eax\t\t# cf=0, of=0\n\tjmp\t.Lsqrx8x_loop\n\n.align\t32\n.Lsqrx8x_loop:\n\tmov\t%r8,%rbx\n\tmulx\t0*8($aaptr),%rax,%r8\t# a[8]*a[i]\n\tadcx\t%rax,%rbx\t\t# +=t[8]\n\tadox\t%r9,%r8\n\n\tmulx\t1*8($aaptr),%rax,%r9\t# ...\n\tadcx\t%rax,%r8\n\tadox\t%r10,%r9\n\n\tmulx\t2*8($aaptr),%rax,%r10\n\tadcx\t%rax,%r9\n\tadox\t%r11,%r10\n\n\tmulx\t3*8($aaptr),%rax,%r11\n\tadcx\t%rax,%r10\n\tadox\t%r12,%r11\n\n\t.byte\t0xc4,0x62,0xfb,0xf6,0xa5,0x20,0x00,0x00,0x00\t# mulx\t4*8($aaptr),%rax,%r12\n\tadcx\t%rax,%r11\n\tadox\t%r13,%r12\n\n\tmulx\t5*8($aaptr),%rax,%r13\n\tadcx\t%rax,%r12\n\tadox\t%r14,%r13\n\n\tmulx\t6*8($aaptr),%rax,%r14\n\t mov\t%rbx,($tptr,%rcx,8)\t# store t[8+i]\n\t mov\t\\$0,%ebx\n\tadcx\t%rax,%r13\n\tadox\t%r15,%r14\n\n\t.byte\t0xc4,0x62,0xfb,0xf6,0xbd,0x38,0x00,0x00,0x00\t# mulx\t7*8($aaptr),%rax,%r15\n\t mov\t8($aptr,%rcx,8),%rdx\t# a[i]\n\tadcx\t%rax,%r14\n\tadox\t%rbx,%r15\t\t# %rbx is 0, of=0\n\tadcx\t%rbx,%r15\t\t# cf=0\n\n\t.byte\t0x67\n\tinc\t%rcx\t\t\t# of=0\n\tjnz\t.Lsqrx8x_loop\n\n\tlea\t8*8($aaptr),$aaptr\n\tmov\t\\$-8,%rcx\n\tcmp\t8+8(%rsp),$aaptr\t# done?\n\tje\t.Lsqrx8x_break\n\n\tsub\t16+8(%rsp),%rbx\t\t# mov 16(%rsp),%cf\n\t.byte\t0x66\n\tmov\t-64($aptr),%rdx\n\tadcx\t0*8($tptr),%r8\n\tadcx\t1*8($tptr),%r9\n\tadc\t2*8($tptr),%r10\n\tadc\t3*8($tptr),%r11\n\tadc\t4*8($tptr),%r12\n\tadc\t5*8($tptr),%r13\n\tadc\t6*8($tptr),%r14\n\tadc\t7*8($tptr),%r15\n\tlea\t8*8($tptr),$tptr\n\t.byte\t0x67\n\tsbb\t%rax,%rax\t\t# mov %cf,%rax\n\txor\t%ebx,%ebx\t\t# cf=0, of=0\n\tmov\t%rax,16+8(%rsp)\t\t# offload carry\n\tjmp\t.Lsqrx8x_loop\n\n.align\t32\n.Lsqrx8x_break:\n\tsub\t16+8(%rsp),%r8\t\t# consume last carry\n\tmov\t24+8(%rsp),$carry\t# initial $tptr, borrow $carry\n\tmov\t0*8($aptr),%rdx\t\t# a[8], modulo-scheduled\n\txor\t%ebp,%ebp\t\t# xor\t$zero,$zero\n\tmov\t%r8,0*8($tptr)\n\tcmp\t$carry,$tptr\t\t# cf=0, of=0\n\tje\t.Lsqrx8x_outer_loop\n\n\tmov\t%r9,1*8($tptr)\n\t mov\t1*8($carry),%r9\n\tmov\t%r10,2*8($tptr)\n\t mov\t2*8($carry),%r10\n\tmov\t%r11,3*8($tptr)\n\t mov\t3*8($carry),%r11\n\tmov\t%r12,4*8($tptr)\n\t mov\t4*8($carry),%r12\n\tmov\t%r13,5*8($tptr)\n\t mov\t5*8($carry),%r13\n\tmov\t%r14,6*8($tptr)\n\t mov\t6*8($carry),%r14\n\tmov\t%r15,7*8($tptr)\n\t mov\t7*8($carry),%r15\n\tmov\t$carry,$tptr\n\tjmp\t.Lsqrx8x_outer_loop\n\n.align\t32\n.Lsqrx8x_outer_break:\n\tmov\t%r9,9*8($tptr)\t\t# t[9]\n\t movq\t%xmm3,%rcx\t\t# -$num\n\tmov\t%r10,10*8($tptr)\t# ...\n\tmov\t%r11,11*8($tptr)\n\tmov\t%r12,12*8($tptr)\n\tmov\t%r13,13*8($tptr)\n\tmov\t%r14,14*8($tptr)\n___\n}\f{\nmy $i=\"%rcx\";\n$code.=<<___;\n\tlea\t48+8(%rsp),$tptr\n\tmov\t($aptr,$i),%rdx\t\t# a[0]\n\n\tmov\t8($tptr),$A0[1]\t\t# t[1]\n\txor\t$A0[0],$A0[0]\t\t# t[0], of=0, cf=0\n\tmov\t0+8(%rsp),$num\t\t# restore $num\n\tadox\t$A0[1],$A0[1]\n\t mov\t16($tptr),$A1[0]\t# t[2]\t# prefetch\n\t mov\t24($tptr),$A1[1]\t# t[3]\t# prefetch\n\t#jmp\t.Lsqrx4x_shift_n_add\t# happens to be aligned\n\n.align\t32\n.Lsqrx4x_shift_n_add:\n\tmulx\t%rdx,%rax,%rbx\n\t adox\t$A1[0],$A1[0]\n\tadcx\t$A0[0],%rax\n\t .byte\t0x48,0x8b,0x94,0x0e,0x08,0x00,0x00,0x00\t# mov\t8($aptr,$i),%rdx\t# a[i+1]\t# prefetch\n\t .byte\t0x4c,0x8b,0x97,0x20,0x00,0x00,0x00\t# mov\t32($tptr),$A0[0]\t# t[2*i+4]\t# prefetch\n\t adox\t$A1[1],$A1[1]\n\tadcx\t$A0[1],%rbx\n\t mov\t40($tptr),$A0[1]\t\t# t[2*i+4+1]\t# prefetch\n\tmov\t%rax,0($tptr)\n\tmov\t%rbx,8($tptr)\n\n\tmulx\t%rdx,%rax,%rbx\n\t adox\t$A0[0],$A0[0]\n\tadcx\t$A1[0],%rax\n\t mov\t16($aptr,$i),%rdx\t# a[i+2]\t# prefetch\n\t mov\t48($tptr),$A1[0]\t# t[2*i+6]\t# prefetch\n\t adox\t$A0[1],$A0[1]\n\tadcx\t$A1[1],%rbx\n\t mov\t56($tptr),$A1[1]\t# t[2*i+6+1]\t# prefetch\n\tmov\t%rax,16($tptr)\n\tmov\t%rbx,24($tptr)\n\n\tmulx\t%rdx,%rax,%rbx\n\t adox\t$A1[0],$A1[0]\n\tadcx\t$A0[0],%rax\n\t mov\t24($aptr,$i),%rdx\t# a[i+3]\t# prefetch\n\t lea\t32($i),$i\n\t mov\t64($tptr),$A0[0]\t# t[2*i+8]\t# prefetch\n\t adox\t$A1[1],$A1[1]\n\tadcx\t$A0[1],%rbx\n\t mov\t72($tptr),$A0[1]\t# t[2*i+8+1]\t# prefetch\n\tmov\t%rax,32($tptr)\n\tmov\t%rbx,40($tptr)\n\n\tmulx\t%rdx,%rax,%rbx\n\t adox\t$A0[0],$A0[0]\n\tadcx\t$A1[0],%rax\n\tjrcxz\t.Lsqrx4x_shift_n_add_break\n\t .byte\t0x48,0x8b,0x94,0x0e,0x00,0x00,0x00,0x00\t# mov\t0($aptr,$i),%rdx\t# a[i+4]\t# prefetch\n\t adox\t$A0[1],$A0[1]\n\tadcx\t$A1[1],%rbx\n\t mov\t80($tptr),$A1[0]\t# t[2*i+10]\t# prefetch\n\t mov\t88($tptr),$A1[1]\t# t[2*i+10+1]\t# prefetch\n\tmov\t%rax,48($tptr)\n\tmov\t%rbx,56($tptr)\n\tlea\t64($tptr),$tptr\n\tnop\n\tjmp\t.Lsqrx4x_shift_n_add\n\n.align\t32\n.Lsqrx4x_shift_n_add_break:\n\tadcx\t$A1[1],%rbx\n\tmov\t%rax,48($tptr)\n\tmov\t%rbx,56($tptr)\n\tlea\t64($tptr),$tptr\t\t# end of t[] buffer\n___\n}\f\n######################################################################\n# Montgomery reduction part, \"word-by-word\" algorithm.\n#\n# This new path is inspired by multiple submissions from Intel, by\n# Shay Gueron, Vlad Krasnov, Erdinc Ozturk, James Guilford,\n# Vinodh Gopal...\n{\nmy ($nptr,$carry,$m0)=(\"%rbp\",\"%rsi\",\"%rdx\");\n\n$code.=<<___;\n\tmovq\t%xmm2,$nptr\n__bn_sqrx8x_reduction:\n\txor\t%eax,%eax\t\t# initial top-most carry bit\n\tmov\t32+8(%rsp),%rbx\t\t# n0\n\tmov\t48+8(%rsp),%rdx\t\t# \"%r8\", 8*0($tptr)\n\tlea\t-8*8($nptr,$num),%rcx\t# end of n[]\n\t#lea\t48+8(%rsp,$num,2),$tptr\t# end of t[] buffer\n\tmov\t%rcx, 0+8(%rsp)\t\t# save end of n[]\n\tmov\t$tptr,8+8(%rsp)\t\t# save end of t[]\n\n\tlea\t48+8(%rsp),$tptr\t\t# initial t[] window\n\tjmp\t.Lsqrx8x_reduction_loop\n\n.align\t32\n.Lsqrx8x_reduction_loop:\n\tmov\t8*1($tptr),%r9\n\tmov\t8*2($tptr),%r10\n\tmov\t8*3($tptr),%r11\n\tmov\t8*4($tptr),%r12\n\tmov\t%rdx,%r8\n\timulq\t%rbx,%rdx\t\t# n0*a[i]\n\tmov\t8*5($tptr),%r13\n\tmov\t8*6($tptr),%r14\n\tmov\t8*7($tptr),%r15\n\tmov\t%rax,24+8(%rsp)\t\t# store top-most carry bit\n\n\tlea\t8*8($tptr),$tptr\n\txor\t$carry,$carry\t\t# cf=0,of=0\n\tmov\t\\$-8,%rcx\n\tjmp\t.Lsqrx8x_reduce\n\n.align\t32\n.Lsqrx8x_reduce:\n\tmov\t%r8, %rbx\n\tmulx\t8*0($nptr),%rax,%r8\t# n[0]\n\tadcx\t%rbx,%rax\t\t# discarded\n\tadox\t%r9,%r8\n\n\tmulx\t8*1($nptr),%rbx,%r9\t# n[1]\n\tadcx\t%rbx,%r8\n\tadox\t%r10,%r9\n\n\tmulx\t8*2($nptr),%rbx,%r10\n\tadcx\t%rbx,%r9\n\tadox\t%r11,%r10\n\n\tmulx\t8*3($nptr),%rbx,%r11\n\tadcx\t%rbx,%r10\n\tadox\t%r12,%r11\n\n\t.byte\t0xc4,0x62,0xe3,0xf6,0xa5,0x20,0x00,0x00,0x00\t# mulx\t8*4($nptr),%rbx,%r12\n\t mov\t%rdx,%rax\n\t mov\t%r8,%rdx\n\tadcx\t%rbx,%r11\n\tadox\t%r13,%r12\n\n\t mulx\t32+8(%rsp),%rbx,%rdx\t# %rdx discarded\n\t mov\t%rax,%rdx\n\t mov\t%rax,64+48+8(%rsp,%rcx,8)\t# put aside n0*a[i]\n\n\tmulx\t8*5($nptr),%rax,%r13\n\tadcx\t%rax,%r12\n\tadox\t%r14,%r13\n\n\tmulx\t8*6($nptr),%rax,%r14\n\tadcx\t%rax,%r13\n\tadox\t%r15,%r14\n\n\tmulx\t8*7($nptr),%rax,%r15\n\t mov\t%rbx,%rdx\n\tadcx\t%rax,%r14\n\tadox\t$carry,%r15\t\t# $carry is 0\n\tadcx\t$carry,%r15\t\t# cf=0\n\n\t.byte\t0x67,0x67,0x67\n\tinc\t%rcx\t\t\t# of=0\n\tjnz\t.Lsqrx8x_reduce\n\n\tmov\t$carry,%rax\t\t# xor\t%rax,%rax\n\tcmp\t0+8(%rsp),$nptr\t\t# end of n[]?\n\tjae\t.Lsqrx8x_no_tail\n\n\tmov\t48+8(%rsp),%rdx\t\t# pull n0*a[0]\n\tadd\t8*0($tptr),%r8\n\tlea\t8*8($nptr),$nptr\n\tmov\t\\$-8,%rcx\n\tadcx\t8*1($tptr),%r9\n\tadcx\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tlea\t8*8($tptr),$tptr\n\tsbb\t%rax,%rax\t\t# top carry\n\n\txor\t$carry,$carry\t\t# of=0, cf=0\n\tmov\t%rax,16+8(%rsp)\n\tjmp\t.Lsqrx8x_tail\n\n.align\t32\n.Lsqrx8x_tail:\n\tmov\t%r8,%rbx\n\tmulx\t8*0($nptr),%rax,%r8\n\tadcx\t%rax,%rbx\n\tadox\t%r9,%r8\n\n\tmulx\t8*1($nptr),%rax,%r9\n\tadcx\t%rax,%r8\n\tadox\t%r10,%r9\n\n\tmulx\t8*2($nptr),%rax,%r10\n\tadcx\t%rax,%r9\n\tadox\t%r11,%r10\n\n\tmulx\t8*3($nptr),%rax,%r11\n\tadcx\t%rax,%r10\n\tadox\t%r12,%r11\n\n\t.byte\t0xc4,0x62,0xfb,0xf6,0xa5,0x20,0x00,0x00,0x00\t# mulx\t8*4($nptr),%rax,%r12\n\tadcx\t%rax,%r11\n\tadox\t%r13,%r12\n\n\tmulx\t8*5($nptr),%rax,%r13\n\tadcx\t%rax,%r12\n\tadox\t%r14,%r13\n\n\tmulx\t8*6($nptr),%rax,%r14\n\tadcx\t%rax,%r13\n\tadox\t%r15,%r14\n\n\tmulx\t8*7($nptr),%rax,%r15\n\t mov\t72+48+8(%rsp,%rcx,8),%rdx\t# pull n0*a[i]\n\tadcx\t%rax,%r14\n\tadox\t$carry,%r15\n\t mov\t%rbx,($tptr,%rcx,8)\t# save result\n\t mov\t%r8,%rbx\n\tadcx\t$carry,%r15\t\t# cf=0\n\n\tinc\t%rcx\t\t\t# of=0\n\tjnz\t.Lsqrx8x_tail\n\n\tcmp\t0+8(%rsp),$nptr\t\t# end of n[]?\n\tjae\t.Lsqrx8x_tail_done\t# break out of loop\n\n\tsub\t16+8(%rsp),$carry\t# mov 16(%rsp),%cf\n\t mov\t48+8(%rsp),%rdx\t\t# pull n0*a[0]\n\t lea\t8*8($nptr),$nptr\n\tadc\t8*0($tptr),%r8\n\tadc\t8*1($tptr),%r9\n\tadc\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tlea\t8*8($tptr),$tptr\n\tsbb\t%rax,%rax\n\tsub\t\\$8,%rcx\t\t# mov\t\\$-8,%rcx\n\n\txor\t$carry,$carry\t\t# of=0, cf=0\n\tmov\t%rax,16+8(%rsp)\n\tjmp\t.Lsqrx8x_tail\n\n.align\t32\n.Lsqrx8x_tail_done:\n\tadd\t24+8(%rsp),%r8\t\t# can this overflow?\n\tadc\t\\$0,%r9\n\tadc\t\\$0,%r10\n\tadc\t\\$0,%r11\n\tadc\t\\$0,%r12\n\tadc\t\\$0,%r13\n\tadc\t\\$0,%r14\n\tadc\t\\$0,%r15\t\t# can't overflow, because we\n\t\t\t\t\t# started with \"overhung\" part\n\t\t\t\t\t# of multiplication\n\tmov\t$carry,%rax\t\t# xor\t%rax,%rax\n\n\tsub\t16+8(%rsp),$carry\t# mov 16(%rsp),%cf\n.Lsqrx8x_no_tail:\t\t\t# %cf is 0 if jumped here\n\tadc\t8*0($tptr),%r8\n\t movq\t%xmm3,%rcx\n\tadc\t8*1($tptr),%r9\n\t mov\t8*7($nptr),$carry\n\t movq\t%xmm2,$nptr\t\t# restore $nptr\n\tadc\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tadc\t%rax,%rax\t\t# top-most carry\n\n\tmov\t32+8(%rsp),%rbx\t\t# n0\n\tmov\t8*8($tptr,%rcx),%rdx\t# modulo-scheduled \"%r8\"\n\n\tmov\t%r8,8*0($tptr)\t\t# store top 512 bits\n\t lea\t8*8($tptr),%r8\t\t# borrow %r8\n\tmov\t%r9,8*1($tptr)\n\tmov\t%r10,8*2($tptr)\n\tmov\t%r11,8*3($tptr)\n\tmov\t%r12,8*4($tptr)\n\tmov\t%r13,8*5($tptr)\n\tmov\t%r14,8*6($tptr)\n\tmov\t%r15,8*7($tptr)\n\n\tlea\t8*8($tptr,%rcx),$tptr\t# start of current t[] window\n\tcmp\t8+8(%rsp),%r8\t\t# end of t[]?\n\tjb\t.Lsqrx8x_reduction_loop\n\tret\n.size\tbn_sqrx8x_internal,.-bn_sqrx8x_internal\n___\n}\f\n##############################################################\n# Post-condition, 4x unrolled\n#\n{\nmy ($rptr,$nptr)=(\"%rdx\",\"%rbp\");\n$code.=<<___;\n.align\t32\n__bn_postx4x_internal:\n\tmov\t8*0($nptr),%r12\n\tmov\t%rcx,%r10\t\t# -$num\n\tmov\t%rcx,%r9\t\t# -$num\n\tneg\t%rax\n\tsar\t\\$3+2,%rcx\n\t#lea\t48+8(%rsp,%r9),$tptr\n\tmovq\t%xmm1,$rptr\t\t# restore $rptr\n\tmovq\t%xmm1,$aptr\t\t# prepare for back-to-back call\n\tdec\t%r12\t\t\t# so that after 'not' we get -n[0]\n\tmov\t8*1($nptr),%r13\n\txor\t%r8,%r8\n\tmov\t8*2($nptr),%r14\n\tmov\t8*3($nptr),%r15\n\tjmp\t.Lsqrx4x_sub_entry\n\n.align\t16\n.Lsqrx4x_sub:\n\tmov\t8*0($nptr),%r12\n\tmov\t8*1($nptr),%r13\n\tmov\t8*2($nptr),%r14\n\tmov\t8*3($nptr),%r15\n.Lsqrx4x_sub_entry:\n\tandn\t%rax,%r12,%r12\n\tlea\t8*4($nptr),$nptr\n\tandn\t%rax,%r13,%r13\n\tandn\t%rax,%r14,%r14\n\tandn\t%rax,%r15,%r15\n\n\tneg\t%r8\t\t\t# mov %r8,%cf\n\tadc\t8*0($tptr),%r12\n\tadc\t8*1($tptr),%r13\n\tadc\t8*2($tptr),%r14\n\tadc\t8*3($tptr),%r15\n\tmov\t%r12,8*0($rptr)\n\tlea\t8*4($tptr),$tptr\n\tmov\t%r13,8*1($rptr)\n\tsbb\t%r8,%r8\t\t\t# mov %cf,%r8\n\tmov\t%r14,8*2($rptr)\n\tmov\t%r15,8*3($rptr)\n\tlea\t8*4($rptr),$rptr\n\n\tinc\t%rcx\n\tjnz\t.Lsqrx4x_sub\n\n\tneg\t%r9\t\t\t# restore $num\n\n\tret\n.size\t__bn_postx4x_internal,.-__bn_postx4x_internal\n___\n}\n}}}\n{\nmy ($inp,$num,$tbl,$idx)=$win64?(\"%rcx\",\"%edx\",\"%r8\", \"%r9d\") : # Win64 order\n\t\t\t\t(\"%rdi\",\"%esi\",\"%rdx\",\"%ecx\");  # Unix order\nmy $out=$inp;\nmy $STRIDE=2**5*8;\nmy $N=$STRIDE/4;\n\n$code.=<<___;\n.globl\tbn_get_bits5\n.type\tbn_get_bits5,\\@abi-omnipotent\n.align\t16\nbn_get_bits5:\n\tlea\t0($inp),%r10\n\tlea\t1($inp),%r11\n\tmov\t$num,%ecx\n\tshr\t\\$4,$num\n\tand\t\\$15,%ecx\n\tlea\t-8(%ecx),%eax\n\tcmp\t\\$11,%ecx\n\tcmova\t%r11,%r10\n\tcmova\t%eax,%ecx\n\tmovzw\t(%r10,$num,2),%eax\n\tshrl\t%cl,%eax\n\tand\t\\$31,%eax\n\tret\n.size\tbn_get_bits5,.-bn_get_bits5\n\n.globl\tbn_scatter5\n.type\tbn_scatter5,\\@abi-omnipotent\n.align\t16\nbn_scatter5:\n\tcmp\t\\$0, $num\n\tjz\t.Lscatter_epilogue\n\tlea\t($tbl,$idx,8),$tbl\n.Lscatter:\n\tmov\t($inp),%rax\n\tlea\t8($inp),$inp\n\tmov\t%rax,($tbl)\n\tlea\t32*8($tbl),$tbl\n\tsub\t\\$1,$num\n\tjnz\t.Lscatter\n.Lscatter_epilogue:\n\tret\n.size\tbn_scatter5,.-bn_scatter5\n\n.globl\tbn_gather5\n.type\tbn_gather5,\\@abi-omnipotent\n.align\t32\nbn_gather5:\n.LSEH_begin_bn_gather5:\t\t\t# Win64 thing, but harmless in other cases\n\t# I can't trust assembler to use specific encoding:-(\n\t.byte\t0x4c,0x8d,0x14,0x24\t\t\t#lea    (%rsp),%r10\n\t.byte\t0x48,0x81,0xec,0x08,0x01,0x00,0x00\t#sub\t$0x108,%rsp\n\tlea\t.Linc(%rip),%rax\n\tand\t\\$-16,%rsp\t\t# shouldn't be formally required\n\n\tmovd\t$idx,%xmm5\n\tmovdqa\t0(%rax),%xmm0\t\t# 00000001000000010000000000000000\n\tmovdqa\t16(%rax),%xmm1\t\t# 00000002000000020000000200000002\n\tlea\t128($tbl),%r11\t\t# size optimization\n\tlea\t128(%rsp),%rax\t\t# size optimization\n\n\tpshufd\t\\$0,%xmm5,%xmm5\t\t# broadcast $idx\n\tmovdqa\t%xmm1,%xmm4\n\tmovdqa\t%xmm1,%xmm2\n___\n########################################################################\n# calculate mask by comparing 0..31 to $idx and save result to stack\n#\nfor($i=0;$i<$STRIDE/16;$i+=4) {\n$code.=<<___;\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\t\t# compare to 1,0\n___\n$code.=<<___\tif ($i);\n\tmovdqa\t%xmm3,`16*($i-1)-128`(%rax)\n___\n$code.=<<___;\n\tmovdqa\t%xmm4,%xmm3\n\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\t\t# compare to 3,2\n\tmovdqa\t%xmm0,`16*($i+0)-128`(%rax)\n\tmovdqa\t%xmm4,%xmm0\n\n\tpaddd\t%xmm2,%xmm3\n\tpcmpeqd\t%xmm5,%xmm2\t\t# compare to 5,4\n\tmovdqa\t%xmm1,`16*($i+1)-128`(%rax)\n\tmovdqa\t%xmm4,%xmm1\n\n\tpaddd\t%xmm3,%xmm0\n\tpcmpeqd\t%xmm5,%xmm3\t\t# compare to 7,6\n\tmovdqa\t%xmm2,`16*($i+2)-128`(%rax)\n\tmovdqa\t%xmm4,%xmm2\n___\n}\n$code.=<<___;\n\tmovdqa\t%xmm3,`16*($i-1)-128`(%rax)\n\tjmp\t.Lgather\n\n.align\t32\n.Lgather:\n\tpxor\t%xmm4,%xmm4\n\tpxor\t%xmm5,%xmm5\n___\nfor($i=0;$i<$STRIDE/16;$i+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($i+0)-128`(%r11),%xmm0\n\tmovdqa\t`16*($i+1)-128`(%r11),%xmm1\n\tmovdqa\t`16*($i+2)-128`(%r11),%xmm2\n\tpand\t`16*($i+0)-128`(%rax),%xmm0\n\tmovdqa\t`16*($i+3)-128`(%r11),%xmm3\n\tpand\t`16*($i+1)-128`(%rax),%xmm1\n\tpor\t%xmm0,%xmm4\n\tpand\t`16*($i+2)-128`(%rax),%xmm2\n\tpor\t%xmm1,%xmm5\n\tpand\t`16*($i+3)-128`(%rax),%xmm3\n\tpor\t%xmm2,%xmm4\n\tpor\t%xmm3,%xmm5\n___\n}\n$code.=<<___;\n\tpor\t%xmm5,%xmm4\n\tlea\t$STRIDE(%r11),%r11\n\tpshufd\t\\$0x4e,%xmm4,%xmm0\n\tpor\t%xmm4,%xmm0\n\tmovq\t%xmm0,($out)\t\t# m0=bp[0]\n\tlea\t8($out),$out\n\tsub\t\\$1,$num\n\tjnz\t.Lgather\n\n\tlea\t(%r10),%rsp\n\tret\n.LSEH_end_bn_gather5:\n.size\tbn_gather5,.-bn_gather5\n___\n}\n$code.=<<___;\n.align\t64\n.Linc:\n\t.long\t0,0, 1,1\n\t.long\t2,2, 2,2\n.asciz\t\"Montgomery Multiplication with scatter/gather for x86_64, CRYPTOGAMS by <appro\\@openssl.org>\"\n___\n\n# EXCEPTION_DISPOSITION handler (EXCEPTION_RECORD *rec,ULONG64 frame,\n#\t\tCONTEXT *context,DISPATCHER_CONTEXT *disp)\nif ($win64) {\n$rec=\"%rcx\";\n$frame=\"%rdx\";\n$context=\"%r8\";\n$disp=\"%r9\";\n\n$code.=<<___;\n.extern\t__imp_RtlVirtualUnwind\n.type\tmul_handler,\\@abi-omnipotent\n.align\t16\nmul_handler:\n\tpush\t%rsi\n\tpush\t%rdi\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n\tpushfq\n\tsub\t\\$64,%rsp\n\n\tmov\t120($context),%rax\t# pull context->Rax\n\tmov\t248($context),%rbx\t# pull context->Rip\n\n\tmov\t8($disp),%rsi\t\t# disp->ImageBase\n\tmov\t56($disp),%r11\t\t# disp->HandlerData\n\n\tmov\t0(%r11),%r10d\t\t# HandlerData[0]\n\tlea\t(%rsi,%r10),%r10\t# end of prologue label\n\tcmp\t%r10,%rbx\t\t# context->Rip<end of prologue label\n\tjb\t.Lcommon_seh_tail\n\n\tmov\t4(%r11),%r10d\t\t# HandlerData[1]\n\tlea\t(%rsi,%r10),%r10\t# epilogue label\n\tcmp\t%r10,%rbx\t\t# context->Rip>=epilogue label\n\tjb\t.Lcommon_pop_regs\n\n\tmov\t152($context),%rax\t# pull context->Rsp\n\n\tmov\t8(%r11),%r10d\t\t# HandlerData[2]\n\tlea\t(%rsi,%r10),%r10\t# epilogue label\n\tcmp\t%r10,%rbx\t\t# context->Rip>=epilogue label\n\tjae\t.Lcommon_seh_tail\n\n\tlea\t.Lmul_epilogue(%rip),%r10\n\tcmp\t%r10,%rbx\n\tja\t.Lbody_40\n\n\tmov\t192($context),%r10\t# pull $num\n\tmov\t8(%rax,%r10,8),%rax\t# pull saved stack pointer\n\n\tjmp\t.Lcommon_pop_regs\n\n.Lbody_40:\n\tmov\t40(%rax),%rax\t\t# pull saved stack pointer\n.Lcommon_pop_regs:\n\tmov\t-8(%rax),%rbx\n\tmov\t-16(%rax),%rbp\n\tmov\t-24(%rax),%r12\n\tmov\t-32(%rax),%r13\n\tmov\t-40(%rax),%r14\n\tmov\t-48(%rax),%r15\n\tmov\t%rbx,144($context)\t# restore context->Rbx\n\tmov\t%rbp,160($context)\t# restore context->Rbp\n\tmov\t%r12,216($context)\t# restore context->R12\n\tmov\t%r13,224($context)\t# restore context->R13\n\tmov\t%r14,232($context)\t# restore context->R14\n\tmov\t%r15,240($context)\t# restore context->R15\n\n.Lcommon_seh_tail:\n\tmov\t8(%rax),%rdi\n\tmov\t16(%rax),%rsi\n\tmov\t%rax,152($context)\t# restore context->Rsp\n\tmov\t%rsi,168($context)\t# restore context->Rsi\n\tmov\t%rdi,176($context)\t# restore context->Rdi\n\n\tmov\t40($disp),%rdi\t\t# disp->ContextRecord\n\tmov\t$context,%rsi\t\t# context\n\tmov\t\\$154,%ecx\t\t# sizeof(CONTEXT)\n\t.long\t0xa548f3fc\t\t# cld; rep movsq\n\n\tmov\t$disp,%rsi\n\txor\t%rcx,%rcx\t\t# arg1, UNW_FLAG_NHANDLER\n\tmov\t8(%rsi),%rdx\t\t# arg2, disp->ImageBase\n\tmov\t0(%rsi),%r8\t\t# arg3, disp->ControlPc\n\tmov\t16(%rsi),%r9\t\t# arg4, disp->FunctionEntry\n\tmov\t40(%rsi),%r10\t\t# disp->ContextRecord\n\tlea\t56(%rsi),%r11\t\t# &disp->HandlerData\n\tlea\t24(%rsi),%r12\t\t# &disp->EstablisherFrame\n\tmov\t%r10,32(%rsp)\t\t# arg5\n\tmov\t%r11,40(%rsp)\t\t# arg6\n\tmov\t%r12,48(%rsp)\t\t# arg7\n\tmov\t%rcx,56(%rsp)\t\t# arg8, (NULL)\n\tcall\t*__imp_RtlVirtualUnwind(%rip)\n\n\tmov\t\\$1,%eax\t\t# ExceptionContinueSearch\n\tadd\t\\$64,%rsp\n\tpopfq\n\tpop\t%r15\n\tpop\t%r14\n\tpop\t%r13\n\tpop\t%r12\n\tpop\t%rbp\n\tpop\t%rbx\n\tpop\t%rdi\n\tpop\t%rsi\n\tret\n.size\tmul_handler,.-mul_handler\n\n.section\t.pdata\n.align\t4\n\t.rva\t.LSEH_begin_bn_mul_mont_gather5\n\t.rva\t.LSEH_end_bn_mul_mont_gather5\n\t.rva\t.LSEH_info_bn_mul_mont_gather5\n\n\t.rva\t.LSEH_begin_bn_mul4x_mont_gather5\n\t.rva\t.LSEH_end_bn_mul4x_mont_gather5\n\t.rva\t.LSEH_info_bn_mul4x_mont_gather5\n\n\t.rva\t.LSEH_begin_bn_power5\n\t.rva\t.LSEH_end_bn_power5\n\t.rva\t.LSEH_info_bn_power5\n\n\t.rva\t.LSEH_begin_bn_from_mont8x\n\t.rva\t.LSEH_end_bn_from_mont8x\n\t.rva\t.LSEH_info_bn_from_mont8x\n___\n$code.=<<___ if ($addx);\n\t.rva\t.LSEH_begin_bn_mulx4x_mont_gather5\n\t.rva\t.LSEH_end_bn_mulx4x_mont_gather5\n\t.rva\t.LSEH_info_bn_mulx4x_mont_gather5\n\n\t.rva\t.LSEH_begin_bn_powerx5\n\t.rva\t.LSEH_end_bn_powerx5\n\t.rva\t.LSEH_info_bn_powerx5\n___\n$code.=<<___;\n\t.rva\t.LSEH_begin_bn_gather5\n\t.rva\t.LSEH_end_bn_gather5\n\t.rva\t.LSEH_info_bn_gather5\n\n.section\t.xdata\n.align\t8\n.LSEH_info_bn_mul_mont_gather5:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lmul_body,.Lmul_body,.Lmul_epilogue\t\t# HandlerData[]\n.align\t8\n.LSEH_info_bn_mul4x_mont_gather5:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lmul4x_prologue,.Lmul4x_body,.Lmul4x_epilogue\t\t# HandlerData[]\n.align\t8\n.LSEH_info_bn_power5:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lpower5_prologue,.Lpower5_body,.Lpower5_epilogue\t# HandlerData[]\n.align\t8\n.LSEH_info_bn_from_mont8x:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lfrom_prologue,.Lfrom_body,.Lfrom_epilogue\t\t# HandlerData[]\n___\n$code.=<<___ if ($addx);\n.align\t8\n.LSEH_info_bn_mulx4x_mont_gather5:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lmulx4x_prologue,.Lmulx4x_body,.Lmulx4x_epilogue\t# HandlerData[]\n.align\t8\n.LSEH_info_bn_powerx5:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lpowerx5_prologue,.Lpowerx5_body,.Lpowerx5_epilogue\t# HandlerData[]\n___\n$code.=<<___;\n.align\t8\n.LSEH_info_bn_gather5:\n\t.byte\t0x01,0x0b,0x03,0x0a\n\t.byte\t0x0b,0x01,0x21,0x00\t# sub\trsp,0x108\n\t.byte\t0x04,0xa3,0x00,0x00\t# lea\tr10,(rsp)\n.align\t8\n___\n}\n\n$code =~ s/\\`([^\\`]*)\\`/eval($1)/gem;\n\nprint $code;\nclose STDOUT;\n"], "fixing_code": ["#! /usr/bin/env perl\n# Copyright 2011-2016 The OpenSSL Project Authors. All Rights Reserved.\n#\n# Licensed under the OpenSSL license (the \"License\").  You may not use\n# this file except in compliance with the License.  You can obtain a copy\n# in the file LICENSE in the source distribution or at\n# https://www.openssl.org/source/license.html\n\n\n# ====================================================================\n# Written by Andy Polyakov <appro@openssl.org> for the OpenSSL\n# project. The module is, however, dual licensed under OpenSSL and\n# CRYPTOGAMS licenses depending on where you obtain it. For further\n# details see http://www.openssl.org/~appro/cryptogams/.\n# ====================================================================\n\n# August 2011.\n#\n# Companion to x86_64-mont.pl that optimizes cache-timing attack\n# countermeasures. The subroutines are produced by replacing bp[i]\n# references in their x86_64-mont.pl counterparts with cache-neutral\n# references to powers table computed in BN_mod_exp_mont_consttime.\n# In addition subroutine that scatters elements of the powers table\n# is implemented, so that scatter-/gathering can be tuned without\n# bn_exp.c modifications.\n\n# August 2013.\n#\n# Add MULX/AD*X code paths and additional interfaces to optimize for\n# branch prediction unit. For input lengths that are multiples of 8\n# the np argument is not just modulus value, but one interleaved\n# with 0. This is to optimize post-condition...\n\n$flavour = shift;\n$output  = shift;\nif ($flavour =~ /\\./) { $output = $flavour; undef $flavour; }\n\n$win64=0; $win64=1 if ($flavour =~ /[nm]asm|mingw64/ || $output =~ /\\.asm$/);\n\n$0 =~ m/(.*[\\/\\\\])[^\\/\\\\]+$/; $dir=$1;\n( $xlate=\"${dir}x86_64-xlate.pl\" and -f $xlate ) or\n( $xlate=\"${dir}../../perlasm/x86_64-xlate.pl\" and -f $xlate) or\ndie \"can't locate x86_64-xlate.pl\";\n\nopen OUT,\"| \\\"$^X\\\" \\\"$xlate\\\" $flavour \\\"$output\\\"\";\n*STDOUT=*OUT;\n\nif (`$ENV{CC} -Wa,-v -c -o /dev/null -x assembler /dev/null 2>&1`\n\t\t=~ /GNU assembler version ([2-9]\\.[0-9]+)/) {\n\t$addx = ($1>=2.23);\n}\n\nif (!$addx && $win64 && ($flavour =~ /nasm/ || $ENV{ASM} =~ /nasm/) &&\n\t    `nasm -v 2>&1` =~ /NASM version ([2-9]\\.[0-9]+)/) {\n\t$addx = ($1>=2.10);\n}\n\nif (!$addx && $win64 && ($flavour =~ /masm/ || $ENV{ASM} =~ /ml64/) &&\n\t    `ml64 2>&1` =~ /Version ([0-9]+)\\./) {\n\t$addx = ($1>=12);\n}\n\nif (!$addx && `$ENV{CC} -v 2>&1` =~ /((?:^clang|LLVM) version|.*based on LLVM) ([3-9])\\.([0-9]+)/) {\n\tmy $ver = $2 + $3/100.0;\t# 3.1->3.01, 3.10->3.10\n\t$addx = ($ver>=3.03);\n}\n\n# int bn_mul_mont_gather5(\n$rp=\"%rdi\";\t# BN_ULONG *rp,\n$ap=\"%rsi\";\t# const BN_ULONG *ap,\n$bp=\"%rdx\";\t# const BN_ULONG *bp,\n$np=\"%rcx\";\t# const BN_ULONG *np,\n$n0=\"%r8\";\t# const BN_ULONG *n0,\n$num=\"%r9\";\t# int num,\n\t\t# int idx);\t# 0 to 2^5-1, \"index\" in $bp holding\n\t\t\t\t# pre-computed powers of a', interlaced\n\t\t\t\t# in such manner that b[0] is $bp[idx],\n\t\t\t\t# b[1] is [2^5+idx], etc.\n$lo0=\"%r10\";\n$hi0=\"%r11\";\n$hi1=\"%r13\";\n$i=\"%r14\";\n$j=\"%r15\";\n$m0=\"%rbx\";\n$m1=\"%rbp\";\n\n$code=<<___;\n.text\n\n.extern\tOPENSSL_ia32cap_P\n\n.globl\tbn_mul_mont_gather5\n.type\tbn_mul_mont_gather5,\\@function,6\n.align\t64\nbn_mul_mont_gather5:\n\tmov\t${num}d,${num}d\n\tmov\t%rsp,%rax\n\ttest\t\\$7,${num}d\n\tjnz\t.Lmul_enter\n___\n$code.=<<___ if ($addx);\n\tmov\tOPENSSL_ia32cap_P+8(%rip),%r11d\n___\n$code.=<<___;\n\tjmp\t.Lmul4x_enter\n\n.align\t16\n.Lmul_enter:\n\tmovd\t`($win64?56:8)`(%rsp),%xmm5\t# load 7th argument\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n\n\tneg\t$num\n\tmov\t%rsp,%r11\n\tlea\t-280(%rsp,$num,8),%r10\t# future alloca(8*(num+2)+256+8)\n\tneg\t$num\t\t\t# restore $num\n\tand\t\\$-1024,%r10\t\t# minimize TLB usage\n\n\t# An OS-agnostic version of __chkstk.\n\t#\n\t# Some OSes (Windows) insist on stack being \"wired\" to\n\t# physical memory in strictly sequential manner, i.e. if stack\n\t# allocation spans two pages, then reference to farmost one can\n\t# be punishable by SEGV. But page walking can do good even on\n\t# other OSes, because it guarantees that villain thread hits\n\t# the guard page before it can make damage to innocent one...\n\tsub\t%r10,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%r10,%r11),%rsp\n\tmov\t(%rsp),%r11\n\tcmp\t%r10,%rsp\n\tja\t.Lmul_page_walk\n\tjmp\t.Lmul_page_walk_done\n\n.Lmul_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r11\n\tcmp\t%r10,%rsp\n\tja\t.Lmul_page_walk\n.Lmul_page_walk_done:\n\n\tlea\t.Linc(%rip),%r10\n\tmov\t%rax,8(%rsp,$num,8)\t# tp[num+1]=%rsp\n.Lmul_body:\n\n\tlea\t128($bp),%r12\t\t# reassign $bp (+size optimization)\n___\n\t\t$bp=\"%r12\";\n\t\t$STRIDE=2**5*8;\t\t# 5 is \"window size\"\n\t\t$N=$STRIDE/4;\t\t# should match cache line size\n$code.=<<___;\n\tmovdqa\t0(%r10),%xmm0\t\t# 00000001000000010000000000000000\n\tmovdqa\t16(%r10),%xmm1\t\t# 00000002000000020000000200000002\n\tlea\t24-112(%rsp,$num,8),%r10# place the mask after tp[num+3] (+ICache optimization)\n\tand\t\\$-16,%r10\n\n\tpshufd\t\\$0,%xmm5,%xmm5\t\t# broadcast index\n\tmovdqa\t%xmm1,%xmm4\n\tmovdqa\t%xmm1,%xmm2\n___\n########################################################################\n# calculate mask by comparing 0..31 to index and save result to stack\n#\n$code.=<<___;\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\t\t# compare to 1,0\n\t.byte\t0x67\n\tmovdqa\t%xmm4,%xmm3\n___\nfor($k=0;$k<$STRIDE/16-4;$k+=4) {\n$code.=<<___;\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\t\t# compare to 3,2\n\tmovdqa\t%xmm0,`16*($k+0)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm0\n\n\tpaddd\t%xmm2,%xmm3\n\tpcmpeqd\t%xmm5,%xmm2\t\t# compare to 5,4\n\tmovdqa\t%xmm1,`16*($k+1)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm1\n\n\tpaddd\t%xmm3,%xmm0\n\tpcmpeqd\t%xmm5,%xmm3\t\t# compare to 7,6\n\tmovdqa\t%xmm2,`16*($k+2)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm2\n\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\n\tmovdqa\t%xmm3,`16*($k+3)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm3\n___\n}\n$code.=<<___;\t\t\t\t# last iteration can be optimized\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\n\tmovdqa\t%xmm0,`16*($k+0)+112`(%r10)\n\n\tpaddd\t%xmm2,%xmm3\n\t.byte\t0x67\n\tpcmpeqd\t%xmm5,%xmm2\n\tmovdqa\t%xmm1,`16*($k+1)+112`(%r10)\n\n\tpcmpeqd\t%xmm5,%xmm3\n\tmovdqa\t%xmm2,`16*($k+2)+112`(%r10)\n\tpand\t`16*($k+0)-128`($bp),%xmm0\t# while it's still in register\n\n\tpand\t`16*($k+1)-128`($bp),%xmm1\n\tpand\t`16*($k+2)-128`($bp),%xmm2\n\tmovdqa\t%xmm3,`16*($k+3)+112`(%r10)\n\tpand\t`16*($k+3)-128`($bp),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\nfor($k=0;$k<$STRIDE/16-4;$k+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($k+0)-128`($bp),%xmm4\n\tmovdqa\t`16*($k+1)-128`($bp),%xmm5\n\tmovdqa\t`16*($k+2)-128`($bp),%xmm2\n\tpand\t`16*($k+0)+112`(%r10),%xmm4\n\tmovdqa\t`16*($k+3)-128`($bp),%xmm3\n\tpand\t`16*($k+1)+112`(%r10),%xmm5\n\tpor\t%xmm4,%xmm0\n\tpand\t`16*($k+2)+112`(%r10),%xmm2\n\tpor\t%xmm5,%xmm1\n\tpand\t`16*($k+3)+112`(%r10),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\n}\n$code.=<<___;\n\tpor\t%xmm1,%xmm0\n\tpshufd\t\\$0x4e,%xmm0,%xmm1\n\tpor\t%xmm1,%xmm0\n\tlea\t$STRIDE($bp),$bp\n\tmovq\t%xmm0,$m0\t\t# m0=bp[0]\n\n\tmov\t($n0),$n0\t\t# pull n0[0] value\n\tmov\t($ap),%rax\n\n\txor\t$i,$i\t\t\t# i=0\n\txor\t$j,$j\t\t\t# j=0\n\n\tmov\t$n0,$m1\n\tmulq\t$m0\t\t\t# ap[0]*bp[0]\n\tmov\t%rax,$lo0\n\tmov\t($np),%rax\n\n\timulq\t$lo0,$m1\t\t# \"tp[0]\"*n0\n\tmov\t%rdx,$hi0\n\n\tmulq\t$m1\t\t\t# np[0]*m1\n\tadd\t%rax,$lo0\t\t# discarded\n\tmov\t8($ap),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$hi1\n\n\tlea\t1($j),$j\t\t# j++\n\tjmp\t.L1st_enter\n\n.align\t16\n.L1st:\n\tadd\t%rax,$hi1\n\tmov\t($ap,$j,8),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$hi0,$hi1\t\t# np[j]*m1+ap[j]*bp[0]\n\tmov\t$lo0,$hi0\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-16(%rsp,$j,8)\t# tp[j-1]\n\tmov\t%rdx,$hi1\n\n.L1st_enter:\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$hi0\n\tmov\t($np,$j,8),%rax\n\tadc\t\\$0,%rdx\n\tlea\t1($j),$j\t\t# j++\n\tmov\t%rdx,$lo0\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tcmp\t$num,$j\n\tjne\t.L1st\t\t\t# note that upon exit $j==$num, so\n\t\t\t\t\t# they can be used interchangeably\n\n\tadd\t%rax,$hi1\n\tadc\t\\$0,%rdx\n\tadd\t$hi0,$hi1\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-16(%rsp,$num,8)\t# tp[num-1]\n\tmov\t%rdx,$hi1\n\tmov\t$lo0,$hi0\n\n\txor\t%rdx,%rdx\n\tadd\t$hi0,$hi1\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-8(%rsp,$num,8)\n\tmov\t%rdx,(%rsp,$num,8)\t# store upmost overflow bit\n\n\tlea\t1($i),$i\t\t# i++\n\tjmp\t.Louter\n.align\t16\n.Louter:\n\tlea\t24+128(%rsp,$num,8),%rdx\t# where 256-byte mask is (+size optimization)\n\tand\t\\$-16,%rdx\n\tpxor\t%xmm4,%xmm4\n\tpxor\t%xmm5,%xmm5\n___\nfor($k=0;$k<$STRIDE/16;$k+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($k+0)-128`($bp),%xmm0\n\tmovdqa\t`16*($k+1)-128`($bp),%xmm1\n\tmovdqa\t`16*($k+2)-128`($bp),%xmm2\n\tmovdqa\t`16*($k+3)-128`($bp),%xmm3\n\tpand\t`16*($k+0)-128`(%rdx),%xmm0\n\tpand\t`16*($k+1)-128`(%rdx),%xmm1\n\tpor\t%xmm0,%xmm4\n\tpand\t`16*($k+2)-128`(%rdx),%xmm2\n\tpor\t%xmm1,%xmm5\n\tpand\t`16*($k+3)-128`(%rdx),%xmm3\n\tpor\t%xmm2,%xmm4\n\tpor\t%xmm3,%xmm5\n___\n}\n$code.=<<___;\n\tpor\t%xmm5,%xmm4\n\tpshufd\t\\$0x4e,%xmm4,%xmm0\n\tpor\t%xmm4,%xmm0\n\tlea\t$STRIDE($bp),$bp\n\n\tmov\t($ap),%rax\t\t# ap[0]\n\tmovq\t%xmm0,$m0\t\t# m0=bp[i]\n\n\txor\t$j,$j\t\t\t# j=0\n\tmov\t$n0,$m1\n\tmov\t(%rsp),$lo0\n\n\tmulq\t$m0\t\t\t# ap[0]*bp[i]\n\tadd\t%rax,$lo0\t\t# ap[0]*bp[i]+tp[0]\n\tmov\t($np),%rax\n\tadc\t\\$0,%rdx\n\n\timulq\t$lo0,$m1\t\t# tp[0]*n0\n\tmov\t%rdx,$hi0\n\n\tmulq\t$m1\t\t\t# np[0]*m1\n\tadd\t%rax,$lo0\t\t# discarded\n\tmov\t8($ap),%rax\n\tadc\t\\$0,%rdx\n\tmov\t8(%rsp),$lo0\t\t# tp[1]\n\tmov\t%rdx,$hi1\n\n\tlea\t1($j),$j\t\t# j++\n\tjmp\t.Linner_enter\n\n.align\t16\n.Linner:\n\tadd\t%rax,$hi1\n\tmov\t($ap,$j,8),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$lo0,$hi1\t\t# np[j]*m1+ap[j]*bp[i]+tp[j]\n\tmov\t(%rsp,$j,8),$lo0\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-16(%rsp,$j,8)\t# tp[j-1]\n\tmov\t%rdx,$hi1\n\n.Linner_enter:\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$hi0\n\tmov\t($np,$j,8),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$hi0,$lo0\t\t# ap[j]*bp[i]+tp[j]\n\tmov\t%rdx,$hi0\n\tadc\t\\$0,$hi0\n\tlea\t1($j),$j\t\t# j++\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tcmp\t$num,$j\n\tjne\t.Linner\t\t\t# note that upon exit $j==$num, so\n\t\t\t\t\t# they can be used interchangeably\n\tadd\t%rax,$hi1\n\tadc\t\\$0,%rdx\n\tadd\t$lo0,$hi1\t\t# np[j]*m1+ap[j]*bp[i]+tp[j]\n\tmov\t(%rsp,$num,8),$lo0\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-16(%rsp,$num,8)\t# tp[num-1]\n\tmov\t%rdx,$hi1\n\n\txor\t%rdx,%rdx\n\tadd\t$hi0,$hi1\n\tadc\t\\$0,%rdx\n\tadd\t$lo0,$hi1\t\t# pull upmost overflow bit\n\tadc\t\\$0,%rdx\n\tmov\t$hi1,-8(%rsp,$num,8)\n\tmov\t%rdx,(%rsp,$num,8)\t# store upmost overflow bit\n\n\tlea\t1($i),$i\t\t# i++\n\tcmp\t$num,$i\n\tjb\t.Louter\n\n\txor\t$i,$i\t\t\t# i=0 and clear CF!\n\tmov\t(%rsp),%rax\t\t# tp[0]\n\tlea\t(%rsp),$ap\t\t# borrow ap for tp\n\tmov\t$num,$j\t\t\t# j=num\n\tjmp\t.Lsub\n.align\t16\n.Lsub:\tsbb\t($np,$i,8),%rax\n\tmov\t%rax,($rp,$i,8)\t\t# rp[i]=tp[i]-np[i]\n\tmov\t8($ap,$i,8),%rax\t# tp[i+1]\n\tlea\t1($i),$i\t\t# i++\n\tdec\t$j\t\t\t# doesnn't affect CF!\n\tjnz\t.Lsub\n\n\tsbb\t\\$0,%rax\t\t# handle upmost overflow bit\n\txor\t$i,$i\n\tand\t%rax,$ap\n\tnot\t%rax\n\tmov\t$rp,$np\n\tand\t%rax,$np\n\tmov\t$num,$j\t\t\t# j=num\n\tor\t$np,$ap\t\t\t# ap=borrow?tp:rp\n.align\t16\n.Lcopy:\t\t\t\t\t# copy or in-place refresh\n\tmov\t($ap,$i,8),%rax\n\tmov\t$i,(%rsp,$i,8)\t\t# zap temporary vector\n\tmov\t%rax,($rp,$i,8)\t\t# rp[i]=tp[i]\n\tlea\t1($i),$i\n\tsub\t\\$1,$j\n\tjnz\t.Lcopy\n\n\tmov\t8(%rsp,$num,8),%rsi\t# restore %rsp\n\tmov\t\\$1,%rax\n\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lmul_epilogue:\n\tret\n.size\tbn_mul_mont_gather5,.-bn_mul_mont_gather5\n___\n{{{\nmy @A=(\"%r10\",\"%r11\");\nmy @N=(\"%r13\",\"%rdi\");\n$code.=<<___;\n.type\tbn_mul4x_mont_gather5,\\@function,6\n.align\t32\nbn_mul4x_mont_gather5:\n\t.byte\t0x67\n\tmov\t%rsp,%rax\n.Lmul4x_enter:\n___\n$code.=<<___ if ($addx);\n\tand\t\\$0x80108,%r11d\n\tcmp\t\\$0x80108,%r11d\t\t# check for AD*X+BMI2+BMI1\n\tje\t.Lmulx4x_enter\n___\n$code.=<<___;\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n.Lmul4x_prologue:\n\n\t.byte\t0x67\n\tshl\t\\$3,${num}d\t\t# convert $num to bytes\n\tlea\t($num,$num,2),%r10\t# 3*$num in bytes\n\tneg\t$num\t\t\t# -$num\n\n\t##############################################################\n\t# Ensure that stack frame doesn't alias with $rptr+3*$num\n\t# modulo 4096, which covers ret[num], am[num] and n[num]\n\t# (see bn_exp.c). This is done to allow memory disambiguation\n\t# logic do its magic. [Extra [num] is allocated in order\n\t# to align with bn_power5's frame, which is cleansed after\n\t# completing exponentiation. Extra 256 bytes is for power mask\n\t# calculated from 7th argument, the index.]\n\t#\n\tlea\t-320(%rsp,$num,2),%r11\n\tmov\t%rsp,%rbp\n\tsub\t$rp,%r11\n\tand\t\\$4095,%r11\n\tcmp\t%r11,%r10\n\tjb\t.Lmul4xsp_alt\n\tsub\t%r11,%rbp\t\t# align with $rp\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*num*8+256)\n\tjmp\t.Lmul4xsp_done\n\n.align\t32\n.Lmul4xsp_alt:\n\tlea\t4096-320(,$num,2),%r10\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*num*8+256)\n\tsub\t%r10,%r11\n\tmov\t\\$0,%r10\n\tcmovc\t%r10,%r11\n\tsub\t%r11,%rbp\n.Lmul4xsp_done:\n\tand\t\\$-64,%rbp\n\tmov\t%rsp,%r11\n\tsub\t%rbp,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%rbp,%r11),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lmul4x_page_walk\n\tjmp\t.Lmul4x_page_walk_done\n\n.Lmul4x_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lmul4x_page_walk\n.Lmul4x_page_walk_done:\n\n\tneg\t$num\n\n\tmov\t%rax,40(%rsp)\n.Lmul4x_body:\n\n\tcall\tmul4x_internal\n\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tmov\t\\$1,%rax\n\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lmul4x_epilogue:\n\tret\n.size\tbn_mul4x_mont_gather5,.-bn_mul4x_mont_gather5\n\n.type\tmul4x_internal,\\@abi-omnipotent\n.align\t32\nmul4x_internal:\n\tshl\t\\$5,$num\t\t# $num was in bytes\n\tmovd\t`($win64?56:8)`(%rax),%xmm5\t# load 7th argument, index\n\tlea\t.Linc(%rip),%rax\n\tlea\t128(%rdx,$num),%r13\t# end of powers table (+size optimization)\n\tshr\t\\$5,$num\t\t# restore $num\n___\n\t\t$bp=\"%r12\";\n\t\t$STRIDE=2**5*8;\t\t# 5 is \"window size\"\n\t\t$N=$STRIDE/4;\t\t# should match cache line size\n\t\t$tp=$i;\n$code.=<<___;\n\tmovdqa\t0(%rax),%xmm0\t\t# 00000001000000010000000000000000\n\tmovdqa\t16(%rax),%xmm1\t\t# 00000002000000020000000200000002\n\tlea\t88-112(%rsp,$num),%r10\t# place the mask after tp[num+1] (+ICache optimization)\n\tlea\t128(%rdx),$bp\t\t# size optimization\n\n\tpshufd\t\\$0,%xmm5,%xmm5\t\t# broadcast index\n\tmovdqa\t%xmm1,%xmm4\n\t.byte\t0x67,0x67\n\tmovdqa\t%xmm1,%xmm2\n___\n########################################################################\n# calculate mask by comparing 0..31 to index and save result to stack\n#\n$code.=<<___;\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\t\t# compare to 1,0\n\t.byte\t0x67\n\tmovdqa\t%xmm4,%xmm3\n___\nfor($i=0;$i<$STRIDE/16-4;$i+=4) {\n$code.=<<___;\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\t\t# compare to 3,2\n\tmovdqa\t%xmm0,`16*($i+0)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm0\n\n\tpaddd\t%xmm2,%xmm3\n\tpcmpeqd\t%xmm5,%xmm2\t\t# compare to 5,4\n\tmovdqa\t%xmm1,`16*($i+1)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm1\n\n\tpaddd\t%xmm3,%xmm0\n\tpcmpeqd\t%xmm5,%xmm3\t\t# compare to 7,6\n\tmovdqa\t%xmm2,`16*($i+2)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm2\n\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\n\tmovdqa\t%xmm3,`16*($i+3)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm3\n___\n}\n$code.=<<___;\t\t\t\t# last iteration can be optimized\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\n\tmovdqa\t%xmm0,`16*($i+0)+112`(%r10)\n\n\tpaddd\t%xmm2,%xmm3\n\t.byte\t0x67\n\tpcmpeqd\t%xmm5,%xmm2\n\tmovdqa\t%xmm1,`16*($i+1)+112`(%r10)\n\n\tpcmpeqd\t%xmm5,%xmm3\n\tmovdqa\t%xmm2,`16*($i+2)+112`(%r10)\n\tpand\t`16*($i+0)-128`($bp),%xmm0\t# while it's still in register\n\n\tpand\t`16*($i+1)-128`($bp),%xmm1\n\tpand\t`16*($i+2)-128`($bp),%xmm2\n\tmovdqa\t%xmm3,`16*($i+3)+112`(%r10)\n\tpand\t`16*($i+3)-128`($bp),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\nfor($i=0;$i<$STRIDE/16-4;$i+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($i+0)-128`($bp),%xmm4\n\tmovdqa\t`16*($i+1)-128`($bp),%xmm5\n\tmovdqa\t`16*($i+2)-128`($bp),%xmm2\n\tpand\t`16*($i+0)+112`(%r10),%xmm4\n\tmovdqa\t`16*($i+3)-128`($bp),%xmm3\n\tpand\t`16*($i+1)+112`(%r10),%xmm5\n\tpor\t%xmm4,%xmm0\n\tpand\t`16*($i+2)+112`(%r10),%xmm2\n\tpor\t%xmm5,%xmm1\n\tpand\t`16*($i+3)+112`(%r10),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\n}\n$code.=<<___;\n\tpor\t%xmm1,%xmm0\n\tpshufd\t\\$0x4e,%xmm0,%xmm1\n\tpor\t%xmm1,%xmm0\n\tlea\t$STRIDE($bp),$bp\n\tmovq\t%xmm0,$m0\t\t# m0=bp[0]\n\n\tmov\t%r13,16+8(%rsp)\t\t# save end of b[num]\n\tmov\t$rp, 56+8(%rsp)\t\t# save $rp\n\n\tmov\t($n0),$n0\t\t# pull n0[0] value\n\tmov\t($ap),%rax\n\tlea\t($ap,$num),$ap\t\t# end of a[num]\n\tneg\t$num\n\n\tmov\t$n0,$m1\n\tmulq\t$m0\t\t\t# ap[0]*bp[0]\n\tmov\t%rax,$A[0]\n\tmov\t($np),%rax\n\n\timulq\t$A[0],$m1\t\t# \"tp[0]\"*n0\n\tlea\t64+8(%rsp),$tp\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[0]*m1\n\tadd\t%rax,$A[0]\t\t# discarded\n\tmov\t8($ap,$num),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\n\tadd\t%rax,$A[1]\n\tmov\t8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\n\tadd\t%rax,$N[1]\n\tmov\t16($ap,$num),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\n\tlea\t4*8($num),$j\t\t# j=4\n\tlea\t8*4($np),$np\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],($tp)\n\tmov\t%rdx,$N[0]\n\tjmp\t.L1st4x\n\n.align\t32\n.L1st4x:\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[0]\n\tmov\t-8*2($np),%rax\n\tlea\t32($tp),$tp\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t-8($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-24($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[1]\n\tmov\t-8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],-16($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[0]\n\tmov\t8*0($np),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t8($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-8($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[1]\n\tmov\t8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t16($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\t\t# np[j]*m1+ap[j]*bp[0]\n\tlea\t8*4($np),$np\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tadd\t\\$32,$j\t\t\t# j+=4\n\tjnz\t.L1st4x\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[0]\n\tmov\t-8*2($np),%rax\n\tlea\t32($tp),$tp\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t-8($ap),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-24($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[0]\n\tadd\t%rax,$A[1]\n\tmov\t-8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t($ap,$num),%rax\t\t# ap[0]\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\t\t# np[j]*m1+ap[j]*bp[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],-16($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tlea\t($np,$num),$np\t\t# rewind $np\n\n\txor\t$N[1],$N[1]\n\tadd\t$A[0],$N[0]\n\tadc\t\\$0,$N[1]\n\tmov\t$N[0],-8($tp)\n\n\tjmp\t.Louter4x\n\n.align\t32\n.Louter4x:\n\tlea\t16+128($tp),%rdx\t# where 256-byte mask is (+size optimization)\n\tpxor\t%xmm4,%xmm4\n\tpxor\t%xmm5,%xmm5\n___\nfor($i=0;$i<$STRIDE/16;$i+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($i+0)-128`($bp),%xmm0\n\tmovdqa\t`16*($i+1)-128`($bp),%xmm1\n\tmovdqa\t`16*($i+2)-128`($bp),%xmm2\n\tmovdqa\t`16*($i+3)-128`($bp),%xmm3\n\tpand\t`16*($i+0)-128`(%rdx),%xmm0\n\tpand\t`16*($i+1)-128`(%rdx),%xmm1\n\tpor\t%xmm0,%xmm4\n\tpand\t`16*($i+2)-128`(%rdx),%xmm2\n\tpor\t%xmm1,%xmm5\n\tpand\t`16*($i+3)-128`(%rdx),%xmm3\n\tpor\t%xmm2,%xmm4\n\tpor\t%xmm3,%xmm5\n___\n}\n$code.=<<___;\n\tpor\t%xmm5,%xmm4\n\tpshufd\t\\$0x4e,%xmm4,%xmm0\n\tpor\t%xmm4,%xmm0\n\tlea\t$STRIDE($bp),$bp\n\tmovq\t%xmm0,$m0\t\t# m0=bp[i]\n\n\tmov\t($tp,$num),$A[0]\n\tmov\t$n0,$m1\n\tmulq\t$m0\t\t\t# ap[0]*bp[i]\n\tadd\t%rax,$A[0]\t\t# ap[0]*bp[i]+tp[0]\n\tmov\t($np),%rax\n\tadc\t\\$0,%rdx\n\n\timulq\t$A[0],$m1\t\t# tp[0]*n0\n\tmov\t%rdx,$A[1]\n\tmov\t$N[1],($tp)\t\t# store upmost overflow bit\n\n\tlea\t($tp,$num),$tp\t\t# rewind $tp\n\n\tmulq\t$m1\t\t\t# np[0]*m1\n\tadd\t%rax,$A[0]\t\t# \"$N[0]\", discarded\n\tmov\t8($ap,$num),%rax\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[1]\n\tmov\t8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t8($tp),$A[1]\t\t# +tp[1]\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t16($ap,$num),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\t\t# np[j]*m1+ap[j]*bp[i]+tp[j]\n\tlea\t4*8($num),$j\t\t# j=4\n\tlea\t8*4($np),$np\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$N[0]\n\tjmp\t.Linner4x\n\n.align\t32\n.Linner4x:\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[0]\n\tmov\t-8*2($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t16($tp),$A[0]\t\t# ap[j]*bp[i]+tp[j]\n\tlea\t32($tp),$tp\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t-8($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],-32($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[1]\n\tmov\t-8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t-8($tp),$A[1]\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-24($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[0]\n\tmov\t8*0($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t($tp),$A[0]\t\t# ap[j]*bp[i]+tp[j]\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t8($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],-16($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[1]\n\tmov\t8*1($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t8($tp),$A[1]\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t16($ap,$j),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\n\tlea\t8*4($np),$np\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-8($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tadd\t\\$32,$j\t\t\t# j+=4\n\tjnz\t.Linner4x\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[0]\n\tmov\t-8*2($np),%rax\n\tadc\t\\$0,%rdx\n\tadd\t16($tp),$A[0]\t\t# ap[j]*bp[i]+tp[j]\n\tlea\t32($tp),$tp\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[1]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[0]\n\tmov\t-8($ap),%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A[0],$N[0]\n\tadc\t\\$0,%rdx\n\tmov\t$N[1],-32($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[1]\n\n\tmulq\t$m0\t\t\t# ap[j]*bp[i]\n\tadd\t%rax,$A[1]\n\tmov\t$m1,%rax\n\tmov\t-8*1($np),$m1\n\tadc\t\\$0,%rdx\n\tadd\t-8($tp),$A[1]\n\tadc\t\\$0,%rdx\n\tmov\t%rdx,$A[0]\n\n\tmulq\t$m1\t\t\t# np[j]*m1\n\tadd\t%rax,$N[1]\n\tmov\t($ap,$num),%rax\t\t# ap[0]\n\tadc\t\\$0,%rdx\n\tadd\t$A[1],$N[1]\n\tadc\t\\$0,%rdx\n\tmov\t$N[0],-24($tp)\t\t# tp[j-1]\n\tmov\t%rdx,$N[0]\n\n\tmov\t$N[1],-16($tp)\t\t# tp[j-1]\n\tlea\t($np,$num),$np\t\t# rewind $np\n\n\txor\t$N[1],$N[1]\n\tadd\t$A[0],$N[0]\n\tadc\t\\$0,$N[1]\n\tadd\t($tp),$N[0]\t\t# pull upmost overflow bit\n\tadc\t\\$0,$N[1]\t\t# upmost overflow bit\n\tmov\t$N[0],-8($tp)\n\n\tcmp\t16+8(%rsp),$bp\n\tjb\t.Louter4x\n___\nif (1) {\n$code.=<<___;\n\txor\t%rax,%rax\n\tsub\t$N[0],$m1\t\t# compare top-most words\n\tadc\t$j,$j\t\t\t# $j is zero\n\tor\t$j,$N[1]\n\tsub\t$N[1],%rax\t\t# %rax=-$N[1]\n\tlea\t($tp,$num),%rbx\t\t# tptr in .sqr4x_sub\n\tmov\t($np),%r12\n\tlea\t($np),%rbp\t\t# nptr in .sqr4x_sub\n\tmov\t%r9,%rcx\n\tsar\t\\$3+2,%rcx\n\tmov\t56+8(%rsp),%rdi\t\t# rptr in .sqr4x_sub\n\tdec\t%r12\t\t\t# so that after 'not' we get -n[0]\n\txor\t%r10,%r10\n\tmov\t8*1(%rbp),%r13\n\tmov\t8*2(%rbp),%r14\n\tmov\t8*3(%rbp),%r15\n\tjmp\t.Lsqr4x_sub_entry\n___\n} else {\nmy @ri=(\"%rax\",$bp,$m0,$m1);\nmy $rp=\"%rdx\";\n$code.=<<___\n\txor\t\\$1,$N[1]\n\tlea\t($tp,$num),$tp\t\t# rewind $tp\n\tsar\t\\$5,$num\t\t# cf=0\n\tlea\t($np,$N[1],8),$np\n\tmov\t56+8(%rsp),$rp\t\t# restore $rp\n\tjmp\t.Lsub4x\n\n.align\t32\n.Lsub4x:\n\t.byte\t0x66\n\tmov\t8*0($tp),@ri[0]\n\tmov\t8*1($tp),@ri[1]\n\t.byte\t0x66\n\tsbb\t16*0($np),@ri[0]\n\tmov\t8*2($tp),@ri[2]\n\tsbb\t16*1($np),@ri[1]\n\tmov\t3*8($tp),@ri[3]\n\tlea\t4*8($tp),$tp\n\tsbb\t16*2($np),@ri[2]\n\tmov\t@ri[0],8*0($rp)\n\tsbb\t16*3($np),@ri[3]\n\tlea\t16*4($np),$np\n\tmov\t@ri[1],8*1($rp)\n\tmov\t@ri[2],8*2($rp)\n\tmov\t@ri[3],8*3($rp)\n\tlea\t8*4($rp),$rp\n\n\tinc\t$num\n\tjnz\t.Lsub4x\n\n\tret\n___\n}\n$code.=<<___;\n.size\tmul4x_internal,.-mul4x_internal\n___\n}}}\n\f{{{\n######################################################################\n# void bn_power5(\nmy $rptr=\"%rdi\";\t# BN_ULONG *rptr,\nmy $aptr=\"%rsi\";\t# const BN_ULONG *aptr,\nmy $bptr=\"%rdx\";\t# const void *table,\nmy $nptr=\"%rcx\";\t# const BN_ULONG *nptr,\nmy $n0  =\"%r8\";\t\t# const BN_ULONG *n0);\nmy $num =\"%r9\";\t\t# int num, has to be divisible by 8\n\t\t\t# int pwr \n\nmy ($i,$j,$tptr)=(\"%rbp\",\"%rcx\",$rptr);\nmy @A0=(\"%r10\",\"%r11\");\nmy @A1=(\"%r12\",\"%r13\");\nmy ($a0,$a1,$ai)=(\"%r14\",\"%r15\",\"%rbx\");\n\n$code.=<<___;\n.globl\tbn_power5\n.type\tbn_power5,\\@function,6\n.align\t32\nbn_power5:\n\tmov\t%rsp,%rax\n___\n$code.=<<___ if ($addx);\n\tmov\tOPENSSL_ia32cap_P+8(%rip),%r11d\n\tand\t\\$0x80108,%r11d\n\tcmp\t\\$0x80108,%r11d\t\t# check for AD*X+BMI2+BMI1\n\tje\t.Lpowerx5_enter\n___\n$code.=<<___;\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n.Lpower5_prologue:\n\n\tshl\t\\$3,${num}d\t\t# convert $num to bytes\n\tlea\t($num,$num,2),%r10d\t# 3*$num\n\tneg\t$num\n\tmov\t($n0),$n0\t\t# *n0\n\n\t##############################################################\n\t# Ensure that stack frame doesn't alias with $rptr+3*$num\n\t# modulo 4096, which covers ret[num], am[num] and n[num]\n\t# (see bn_exp.c). This is done to allow memory disambiguation\n\t# logic do its magic. [Extra 256 bytes is for power mask\n\t# calculated from 7th argument, the index.]\n\t#\n\tlea\t-320(%rsp,$num,2),%r11\n\tmov\t%rsp,%rbp\n\tsub\t$rptr,%r11\n\tand\t\\$4095,%r11\n\tcmp\t%r11,%r10\n\tjb\t.Lpwr_sp_alt\n\tsub\t%r11,%rbp\t\t# align with $aptr\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*num*8+256)\n\tjmp\t.Lpwr_sp_done\n\n.align\t32\n.Lpwr_sp_alt:\n\tlea\t4096-320(,$num,2),%r10\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*num*8+256)\n\tsub\t%r10,%r11\n\tmov\t\\$0,%r10\n\tcmovc\t%r10,%r11\n\tsub\t%r11,%rbp\n.Lpwr_sp_done:\n\tand\t\\$-64,%rbp\n\tmov\t%rsp,%r11\n\tsub\t%rbp,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%rbp,%r11),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lpwr_page_walk\n\tjmp\t.Lpwr_page_walk_done\n\n.Lpwr_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lpwr_page_walk\n.Lpwr_page_walk_done:\n\n\tmov\t$num,%r10\t\n\tneg\t$num\n\n\t##############################################################\n\t# Stack layout\n\t#\n\t# +0\tsaved $num, used in reduction section\n\t# +8\t&t[2*$num], used in reduction section\n\t# +32\tsaved *n0\n\t# +40\tsaved %rsp\n\t# +48\tt[2*$num]\n\t#\n\tmov\t$n0,  32(%rsp)\n\tmov\t%rax, 40(%rsp)\t\t# save original %rsp\n.Lpower5_body:\n\tmovq\t$rptr,%xmm1\t\t# save $rptr, used in sqr8x\n\tmovq\t$nptr,%xmm2\t\t# save $nptr\n\tmovq\t%r10, %xmm3\t\t# -$num, used in sqr8x\n\tmovq\t$bptr,%xmm4\n\n\tcall\t__bn_sqr8x_internal\n\tcall\t__bn_post4x_internal\n\tcall\t__bn_sqr8x_internal\n\tcall\t__bn_post4x_internal\n\tcall\t__bn_sqr8x_internal\n\tcall\t__bn_post4x_internal\n\tcall\t__bn_sqr8x_internal\n\tcall\t__bn_post4x_internal\n\tcall\t__bn_sqr8x_internal\n\tcall\t__bn_post4x_internal\n\n\tmovq\t%xmm2,$nptr\n\tmovq\t%xmm4,$bptr\n\tmov\t$aptr,$rptr\n\tmov\t40(%rsp),%rax\n\tlea\t32(%rsp),$n0\n\n\tcall\tmul4x_internal\n\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tmov\t\\$1,%rax\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lpower5_epilogue:\n\tret\n.size\tbn_power5,.-bn_power5\n\n.globl\tbn_sqr8x_internal\n.hidden\tbn_sqr8x_internal\n.type\tbn_sqr8x_internal,\\@abi-omnipotent\n.align\t32\nbn_sqr8x_internal:\n__bn_sqr8x_internal:\n\t##############################################################\n\t# Squaring part:\n\t#\n\t# a) multiply-n-add everything but a[i]*a[i];\n\t# b) shift result of a) by 1 to the left and accumulate\n\t#    a[i]*a[i] products;\n\t#\n\t##############################################################\n\t#                                                     a[1]a[0]\n\t#                                                 a[2]a[0]\n\t#                                             a[3]a[0]\n\t#                                             a[2]a[1]\n\t#                                         a[4]a[0]\n\t#                                         a[3]a[1]\n\t#                                     a[5]a[0]\n\t#                                     a[4]a[1]\n\t#                                     a[3]a[2]\n\t#                                 a[6]a[0]\n\t#                                 a[5]a[1]\n\t#                                 a[4]a[2]\n\t#                             a[7]a[0]\n\t#                             a[6]a[1]\n\t#                             a[5]a[2]\n\t#                             a[4]a[3]\n\t#                         a[7]a[1]\n\t#                         a[6]a[2]\n\t#                         a[5]a[3]\n\t#                     a[7]a[2]\n\t#                     a[6]a[3]\n\t#                     a[5]a[4]\n\t#                 a[7]a[3]\n\t#                 a[6]a[4]\n\t#             a[7]a[4]\n\t#             a[6]a[5]\n\t#         a[7]a[5]\n\t#     a[7]a[6]\n\t#                                                     a[1]a[0]\n\t#                                                 a[2]a[0]\n\t#                                             a[3]a[0]\n\t#                                         a[4]a[0]\n\t#                                     a[5]a[0]\n\t#                                 a[6]a[0]\n\t#                             a[7]a[0]\n\t#                                             a[2]a[1]\n\t#                                         a[3]a[1]\n\t#                                     a[4]a[1]\n\t#                                 a[5]a[1]\n\t#                             a[6]a[1]\n\t#                         a[7]a[1]\n\t#                                     a[3]a[2]\n\t#                                 a[4]a[2]\n\t#                             a[5]a[2]\n\t#                         a[6]a[2]\n\t#                     a[7]a[2]\n\t#                             a[4]a[3]\n\t#                         a[5]a[3]\n\t#                     a[6]a[3]\n\t#                 a[7]a[3]\n\t#                     a[5]a[4]\n\t#                 a[6]a[4]\n\t#             a[7]a[4]\n\t#             a[6]a[5]\n\t#         a[7]a[5]\n\t#     a[7]a[6]\n\t#                                                         a[0]a[0]\n\t#                                                 a[1]a[1]\n\t#                                         a[2]a[2]\n\t#                                 a[3]a[3]\n\t#                         a[4]a[4]\n\t#                 a[5]a[5]\n\t#         a[6]a[6]\n\t# a[7]a[7]\n\n\tlea\t32(%r10),$i\t\t# $i=-($num-32)\n\tlea\t($aptr,$num),$aptr\t# end of a[] buffer, ($aptr,$i)=&ap[2]\n\n\tmov\t$num,$j\t\t\t# $j=$num\n\n\t\t\t\t\t# comments apply to $num==8 case\n\tmov\t-32($aptr,$i),$a0\t# a[0]\n\tlea\t48+8(%rsp,$num,2),$tptr\t# end of tp[] buffer, &tp[2*$num]\n\tmov\t-24($aptr,$i),%rax\t# a[1]\n\tlea\t-32($tptr,$i),$tptr\t# end of tp[] window, &tp[2*$num-\"$i\"]\n\tmov\t-16($aptr,$i),$ai\t# a[2]\n\tmov\t%rax,$a1\n\n\tmul\t$a0\t\t\t# a[1]*a[0]\n\tmov\t%rax,$A0[0]\t\t# a[1]*a[0]\n\t mov\t$ai,%rax\t\t# a[2]\n\tmov\t%rdx,$A0[1]\n\tmov\t$A0[0],-24($tptr,$i)\t# t[1]\n\n\tmul\t$a0\t\t\t# a[2]*a[0]\n\tadd\t%rax,$A0[1]\n\t mov\t$ai,%rax\n\tadc\t\\$0,%rdx\n\tmov\t$A0[1],-16($tptr,$i)\t# t[2]\n\tmov\t%rdx,$A0[0]\n\n\n\t mov\t-8($aptr,$i),$ai\t# a[3]\n\tmul\t$a1\t\t\t# a[2]*a[1]\n\tmov\t%rax,$A1[0]\t\t# a[2]*a[1]+t[3]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A1[1]\n\n\t lea\t($i),$j\n\tmul\t$a0\t\t\t# a[3]*a[0]\n\tadd\t%rax,$A0[0]\t\t# a[3]*a[0]+a[2]*a[1]+t[3]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tadd\t$A1[0],$A0[0]\n\tadc\t\\$0,$A0[1]\n\tmov\t$A0[0],-8($tptr,$j)\t# t[3]\n\tjmp\t.Lsqr4x_1st\n\n.align\t32\n.Lsqr4x_1st:\n\t mov\t($aptr,$j),$ai\t\t# a[4]\n\tmul\t$a1\t\t\t# a[3]*a[1]\n\tadd\t%rax,$A1[1]\t\t# a[3]*a[1]+t[4]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A1[0]\n\tadc\t\\$0,$A1[0]\n\n\tmul\t$a0\t\t\t# a[4]*a[0]\n\tadd\t%rax,$A0[1]\t\t# a[4]*a[0]+a[3]*a[1]+t[4]\n\t mov\t$ai,%rax\t\t# a[3]\n\t mov\t8($aptr,$j),$ai\t\t# a[5]\n\tmov\t%rdx,$A0[0]\n\tadc\t\\$0,$A0[0]\n\tadd\t$A1[1],$A0[1]\n\tadc\t\\$0,$A0[0]\n\n\n\tmul\t$a1\t\t\t# a[4]*a[3]\n\tadd\t%rax,$A1[0]\t\t# a[4]*a[3]+t[5]\n\t mov\t$ai,%rax\n\t mov\t$A0[1],($tptr,$j)\t# t[4]\n\tmov\t%rdx,$A1[1]\n\tadc\t\\$0,$A1[1]\n\n\tmul\t$a0\t\t\t# a[5]*a[2]\n\tadd\t%rax,$A0[0]\t\t# a[5]*a[2]+a[4]*a[3]+t[5]\n\t mov\t$ai,%rax\n\t mov\t16($aptr,$j),$ai\t# a[6]\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tadd\t$A1[0],$A0[0]\n\tadc\t\\$0,$A0[1]\n\n\tmul\t$a1\t\t\t# a[5]*a[3]\n\tadd\t%rax,$A1[1]\t\t# a[5]*a[3]+t[6]\n\t mov\t$ai,%rax\n\t mov\t$A0[0],8($tptr,$j)\t# t[5]\n\tmov\t%rdx,$A1[0]\n\tadc\t\\$0,$A1[0]\n\n\tmul\t$a0\t\t\t# a[6]*a[2]\n\tadd\t%rax,$A0[1]\t\t# a[6]*a[2]+a[5]*a[3]+t[6]\n\t mov\t$ai,%rax\t\t# a[3]\n\t mov\t24($aptr,$j),$ai\t# a[7]\n\tmov\t%rdx,$A0[0]\n\tadc\t\\$0,$A0[0]\n\tadd\t$A1[1],$A0[1]\n\tadc\t\\$0,$A0[0]\n\n\n\tmul\t$a1\t\t\t# a[6]*a[5]\n\tadd\t%rax,$A1[0]\t\t# a[6]*a[5]+t[7]\n\t mov\t$ai,%rax\n\t mov\t$A0[1],16($tptr,$j)\t# t[6]\n\tmov\t%rdx,$A1[1]\n\tadc\t\\$0,$A1[1]\n\t lea\t32($j),$j\n\n\tmul\t$a0\t\t\t# a[7]*a[4]\n\tadd\t%rax,$A0[0]\t\t# a[7]*a[4]+a[6]*a[5]+t[6]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tadd\t$A1[0],$A0[0]\n\tadc\t\\$0,$A0[1]\n\tmov\t$A0[0],-8($tptr,$j)\t# t[7]\n\n\tcmp\t\\$0,$j\n\tjne\t.Lsqr4x_1st\n\n\tmul\t$a1\t\t\t# a[7]*a[5]\n\tadd\t%rax,$A1[1]\n\tlea\t16($i),$i\n\tadc\t\\$0,%rdx\n\tadd\t$A0[1],$A1[1]\n\tadc\t\\$0,%rdx\n\n\tmov\t$A1[1],($tptr)\t\t# t[8]\n\tmov\t%rdx,$A1[0]\n\tmov\t%rdx,8($tptr)\t\t# t[9]\n\tjmp\t.Lsqr4x_outer\n\n.align\t32\n.Lsqr4x_outer:\t\t\t\t# comments apply to $num==6 case\n\tmov\t-32($aptr,$i),$a0\t# a[0]\n\tlea\t48+8(%rsp,$num,2),$tptr\t# end of tp[] buffer, &tp[2*$num]\n\tmov\t-24($aptr,$i),%rax\t# a[1]\n\tlea\t-32($tptr,$i),$tptr\t# end of tp[] window, &tp[2*$num-\"$i\"]\n\tmov\t-16($aptr,$i),$ai\t# a[2]\n\tmov\t%rax,$a1\n\n\tmul\t$a0\t\t\t# a[1]*a[0]\n\tmov\t-24($tptr,$i),$A0[0]\t# t[1]\n\tadd\t%rax,$A0[0]\t\t# a[1]*a[0]+t[1]\n\t mov\t$ai,%rax\t\t# a[2]\n\tadc\t\\$0,%rdx\n\tmov\t$A0[0],-24($tptr,$i)\t# t[1]\n\tmov\t%rdx,$A0[1]\n\n\tmul\t$a0\t\t\t# a[2]*a[0]\n\tadd\t%rax,$A0[1]\n\t mov\t$ai,%rax\n\tadc\t\\$0,%rdx\n\tadd\t-16($tptr,$i),$A0[1]\t# a[2]*a[0]+t[2]\n\tmov\t%rdx,$A0[0]\n\tadc\t\\$0,$A0[0]\n\tmov\t$A0[1],-16($tptr,$i)\t# t[2]\n\n\txor\t$A1[0],$A1[0]\n\n\t mov\t-8($aptr,$i),$ai\t# a[3]\n\tmul\t$a1\t\t\t# a[2]*a[1]\n\tadd\t%rax,$A1[0]\t\t# a[2]*a[1]+t[3]\n\t mov\t$ai,%rax\n\tadc\t\\$0,%rdx\n\tadd\t-8($tptr,$i),$A1[0]\n\tmov\t%rdx,$A1[1]\n\tadc\t\\$0,$A1[1]\n\n\tmul\t$a0\t\t\t# a[3]*a[0]\n\tadd\t%rax,$A0[0]\t\t# a[3]*a[0]+a[2]*a[1]+t[3]\n\t mov\t$ai,%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A1[0],$A0[0]\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tmov\t$A0[0],-8($tptr,$i)\t# t[3]\n\n\tlea\t($i),$j\n\tjmp\t.Lsqr4x_inner\n\n.align\t32\n.Lsqr4x_inner:\n\t mov\t($aptr,$j),$ai\t\t# a[4]\n\tmul\t$a1\t\t\t# a[3]*a[1]\n\tadd\t%rax,$A1[1]\t\t# a[3]*a[1]+t[4]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A1[0]\n\tadc\t\\$0,$A1[0]\n\tadd\t($tptr,$j),$A1[1]\n\tadc\t\\$0,$A1[0]\n\n\t.byte\t0x67\n\tmul\t$a0\t\t\t# a[4]*a[0]\n\tadd\t%rax,$A0[1]\t\t# a[4]*a[0]+a[3]*a[1]+t[4]\n\t mov\t$ai,%rax\t\t# a[3]\n\t mov\t8($aptr,$j),$ai\t\t# a[5]\n\tmov\t%rdx,$A0[0]\n\tadc\t\\$0,$A0[0]\n\tadd\t$A1[1],$A0[1]\n\tadc\t\\$0,$A0[0]\n\n\tmul\t$a1\t\t\t# a[4]*a[3]\n\tadd\t%rax,$A1[0]\t\t# a[4]*a[3]+t[5]\n\tmov\t$A0[1],($tptr,$j)\t# t[4]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A1[1]\n\tadc\t\\$0,$A1[1]\n\tadd\t8($tptr,$j),$A1[0]\n\tlea\t16($j),$j\t\t# j++\n\tadc\t\\$0,$A1[1]\n\n\tmul\t$a0\t\t\t# a[5]*a[2]\n\tadd\t%rax,$A0[0]\t\t# a[5]*a[2]+a[4]*a[3]+t[5]\n\t mov\t$ai,%rax\n\tadc\t\\$0,%rdx\n\tadd\t$A1[0],$A0[0]\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tmov\t$A0[0],-8($tptr,$j)\t# t[5], \"preloaded t[1]\" below\n\n\tcmp\t\\$0,$j\n\tjne\t.Lsqr4x_inner\n\n\t.byte\t0x67\n\tmul\t$a1\t\t\t# a[5]*a[3]\n\tadd\t%rax,$A1[1]\n\tadc\t\\$0,%rdx\n\tadd\t$A0[1],$A1[1]\n\tadc\t\\$0,%rdx\n\n\tmov\t$A1[1],($tptr)\t\t# t[6], \"preloaded t[2]\" below\n\tmov\t%rdx,$A1[0]\n\tmov\t%rdx,8($tptr)\t\t# t[7], \"preloaded t[3]\" below\n\n\tadd\t\\$16,$i\n\tjnz\t.Lsqr4x_outer\n\n\t\t\t\t\t# comments apply to $num==4 case\n\tmov\t-32($aptr),$a0\t\t# a[0]\n\tlea\t48+8(%rsp,$num,2),$tptr\t# end of tp[] buffer, &tp[2*$num]\n\tmov\t-24($aptr),%rax\t\t# a[1]\n\tlea\t-32($tptr,$i),$tptr\t# end of tp[] window, &tp[2*$num-\"$i\"]\n\tmov\t-16($aptr),$ai\t\t# a[2]\n\tmov\t%rax,$a1\n\n\tmul\t$a0\t\t\t# a[1]*a[0]\n\tadd\t%rax,$A0[0]\t\t# a[1]*a[0]+t[1], preloaded t[1]\n\t mov\t$ai,%rax\t\t# a[2]\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\n\tmul\t$a0\t\t\t# a[2]*a[0]\n\tadd\t%rax,$A0[1]\n\t mov\t$ai,%rax\n\t mov\t$A0[0],-24($tptr)\t# t[1]\n\tmov\t%rdx,$A0[0]\n\tadc\t\\$0,$A0[0]\n\tadd\t$A1[1],$A0[1]\t\t# a[2]*a[0]+t[2], preloaded t[2]\n\t mov\t-8($aptr),$ai\t\t# a[3]\n\tadc\t\\$0,$A0[0]\n\n\tmul\t$a1\t\t\t# a[2]*a[1]\n\tadd\t%rax,$A1[0]\t\t# a[2]*a[1]+t[3], preloaded t[3]\n\t mov\t$ai,%rax\n\t mov\t$A0[1],-16($tptr)\t# t[2]\n\tmov\t%rdx,$A1[1]\n\tadc\t\\$0,$A1[1]\n\n\tmul\t$a0\t\t\t# a[3]*a[0]\n\tadd\t%rax,$A0[0]\t\t# a[3]*a[0]+a[2]*a[1]+t[3]\n\t mov\t$ai,%rax\n\tmov\t%rdx,$A0[1]\n\tadc\t\\$0,$A0[1]\n\tadd\t$A1[0],$A0[0]\n\tadc\t\\$0,$A0[1]\n\tmov\t$A0[0],-8($tptr)\t# t[3]\n\n\tmul\t$a1\t\t\t# a[3]*a[1]\n\tadd\t%rax,$A1[1]\n\t mov\t-16($aptr),%rax\t\t# a[2]\n\tadc\t\\$0,%rdx\n\tadd\t$A0[1],$A1[1]\n\tadc\t\\$0,%rdx\n\n\tmov\t$A1[1],($tptr)\t\t# t[4]\n\tmov\t%rdx,$A1[0]\n\tmov\t%rdx,8($tptr)\t\t# t[5]\n\n\tmul\t$ai\t\t\t# a[2]*a[3]\n___\n{\nmy ($shift,$carry)=($a0,$a1);\nmy @S=(@A1,$ai,$n0);\n$code.=<<___;\n\t add\t\\$16,$i\n\t xor\t$shift,$shift\n\t sub\t$num,$i\t\t\t# $i=16-$num\n\t xor\t$carry,$carry\n\n\tadd\t$A1[0],%rax\t\t# t[5]\n\tadc\t\\$0,%rdx\n\tmov\t%rax,8($tptr)\t\t# t[5]\n\tmov\t%rdx,16($tptr)\t\t# t[6]\n\tmov\t$carry,24($tptr)\t# t[7]\n\n\t mov\t-16($aptr,$i),%rax\t# a[0]\n\tlea\t48+8(%rsp),$tptr\n\t xor\t$A0[0],$A0[0]\t\t# t[0]\n\t mov\t8($tptr),$A0[1]\t\t# t[1]\n\n\tlea\t($shift,$A0[0],2),$S[0]\t# t[2*i]<<1 | shift\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[1]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[1]\t\t# | t[2*i]>>63\n\t mov\t16($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t24($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[0]\n\t mov\t-8($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[0],($tptr)\n\tadc\t%rdx,$S[1]\n\n\tlea\t($shift,$A0[0],2),$S[2]\t# t[2*i]<<1 | shift\n\t mov\t$S[1],8($tptr)\n\t sbb\t$carry,$carry\t\t# mov cf,$carry\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[3]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[3]\t\t# | t[2*i]>>63\n\t mov\t32($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t40($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[2]\n\t mov\t0($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[2],16($tptr)\n\tadc\t%rdx,$S[3]\n\tlea\t16($i),$i\n\tmov\t$S[3],24($tptr)\n\tsbb\t$carry,$carry\t\t# mov cf,$carry\n\tlea\t64($tptr),$tptr\n\tjmp\t.Lsqr4x_shift_n_add\n\n.align\t32\n.Lsqr4x_shift_n_add:\n\tlea\t($shift,$A0[0],2),$S[0]\t# t[2*i]<<1 | shift\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[1]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[1]\t\t# | t[2*i]>>63\n\t mov\t-16($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t-8($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[0]\n\t mov\t-8($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[0],-32($tptr)\n\tadc\t%rdx,$S[1]\n\n\tlea\t($shift,$A0[0],2),$S[2]\t# t[2*i]<<1 | shift\n\t mov\t$S[1],-24($tptr)\n\t sbb\t$carry,$carry\t\t# mov cf,$carry\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[3]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[3]\t\t# | t[2*i]>>63\n\t mov\t0($tptr),$A0[0]\t\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t8($tptr),$A0[1]\t\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[2]\n\t mov\t0($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[2],-16($tptr)\n\tadc\t%rdx,$S[3]\n\n\tlea\t($shift,$A0[0],2),$S[0]\t# t[2*i]<<1 | shift\n\t mov\t$S[3],-8($tptr)\n\t sbb\t$carry,$carry\t\t# mov cf,$carry\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[1]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[1]\t\t# | t[2*i]>>63\n\t mov\t16($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t24($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[0]\n\t mov\t8($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[0],0($tptr)\n\tadc\t%rdx,$S[1]\n\n\tlea\t($shift,$A0[0],2),$S[2]\t# t[2*i]<<1 | shift\n\t mov\t$S[1],8($tptr)\n\t sbb\t$carry,$carry\t\t# mov cf,$carry\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[3]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[3]\t\t# | t[2*i]>>63\n\t mov\t32($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t40($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[2]\n\t mov\t16($aptr,$i),%rax\t# a[i+1]\t# prefetch\n\tmov\t$S[2],16($tptr)\n\tadc\t%rdx,$S[3]\n\tmov\t$S[3],24($tptr)\n\tsbb\t$carry,$carry\t\t# mov cf,$carry\n\tlea\t64($tptr),$tptr\n\tadd\t\\$32,$i\n\tjnz\t.Lsqr4x_shift_n_add\n\n\tlea\t($shift,$A0[0],2),$S[0]\t# t[2*i]<<1 | shift\n\t.byte\t0x67\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[1]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[1]\t\t# | t[2*i]>>63\n\t mov\t-16($tptr),$A0[0]\t# t[2*i+2]\t# prefetch\n\tmov\t$A0[1],$shift\t\t# shift=t[2*i+1]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\t mov\t-8($tptr),$A0[1]\t# t[2*i+2+1]\t# prefetch\n\tadc\t%rax,$S[0]\n\t mov\t-8($aptr),%rax\t\t# a[i+1]\t# prefetch\n\tmov\t$S[0],-32($tptr)\n\tadc\t%rdx,$S[1]\n\n\tlea\t($shift,$A0[0],2),$S[2]\t# t[2*i]<<1|shift\n\t mov\t$S[1],-24($tptr)\n\t sbb\t$carry,$carry\t\t# mov cf,$carry\n\tshr\t\\$63,$A0[0]\n\tlea\t($j,$A0[1],2),$S[3]\t# t[2*i+1]<<1 |\n\tshr\t\\$63,$A0[1]\n\tor\t$A0[0],$S[3]\t\t# | t[2*i]>>63\n\tmul\t%rax\t\t\t# a[i]*a[i]\n\tneg\t$carry\t\t\t# mov $carry,cf\n\tadc\t%rax,$S[2]\n\tadc\t%rdx,$S[3]\n\tmov\t$S[2],-16($tptr)\n\tmov\t$S[3],-8($tptr)\n___\n}\f\n######################################################################\n# Montgomery reduction part, \"word-by-word\" algorithm.\n#\n# This new path is inspired by multiple submissions from Intel, by\n# Shay Gueron, Vlad Krasnov, Erdinc Ozturk, James Guilford,\n# Vinodh Gopal...\n{\nmy ($nptr,$tptr,$carry,$m0)=(\"%rbp\",\"%rdi\",\"%rsi\",\"%rbx\");\n\n$code.=<<___;\n\tmovq\t%xmm2,$nptr\n__bn_sqr8x_reduction:\n\txor\t%rax,%rax\n\tlea\t($nptr,$num),%rcx\t# end of n[]\n\tlea\t48+8(%rsp,$num,2),%rdx\t# end of t[] buffer\n\tmov\t%rcx,0+8(%rsp)\n\tlea\t48+8(%rsp,$num),$tptr\t# end of initial t[] window\n\tmov\t%rdx,8+8(%rsp)\n\tneg\t$num\n\tjmp\t.L8x_reduction_loop\n\n.align\t32\n.L8x_reduction_loop:\n\tlea\t($tptr,$num),$tptr\t# start of current t[] window\n\t.byte\t0x66\n\tmov\t8*0($tptr),$m0\n\tmov\t8*1($tptr),%r9\n\tmov\t8*2($tptr),%r10\n\tmov\t8*3($tptr),%r11\n\tmov\t8*4($tptr),%r12\n\tmov\t8*5($tptr),%r13\n\tmov\t8*6($tptr),%r14\n\tmov\t8*7($tptr),%r15\n\tmov\t%rax,(%rdx)\t\t# store top-most carry bit\n\tlea\t8*8($tptr),$tptr\n\n\t.byte\t0x67\n\tmov\t$m0,%r8\n\timulq\t32+8(%rsp),$m0\t\t# n0*a[0]\n\tmov\t8*0($nptr),%rax\t\t# n[0]\n\tmov\t\\$8,%ecx\n\tjmp\t.L8x_reduce\n\n.align\t32\n.L8x_reduce:\n\tmulq\t$m0\n\t mov\t8*1($nptr),%rax\t\t# n[1]\n\tneg\t%r8\n\tmov\t%rdx,%r8\n\tadc\t\\$0,%r8\n\n\tmulq\t$m0\n\tadd\t%rax,%r9\n\t mov\t8*2($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r9,%r8\n\t mov\t$m0,48-8+8(%rsp,%rcx,8)\t# put aside n0*a[i]\n\tmov\t%rdx,%r9\n\tadc\t\\$0,%r9\n\n\tmulq\t$m0\n\tadd\t%rax,%r10\n\t mov\t8*3($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r10,%r9\n\t mov\t32+8(%rsp),$carry\t# pull n0, borrow $carry\n\tmov\t%rdx,%r10\n\tadc\t\\$0,%r10\n\n\tmulq\t$m0\n\tadd\t%rax,%r11\n\t mov\t8*4($nptr),%rax\n\tadc\t\\$0,%rdx\n\t imulq\t%r8,$carry\t\t# modulo-scheduled\n\tadd\t%r11,%r10\n\tmov\t%rdx,%r11\n\tadc\t\\$0,%r11\n\n\tmulq\t$m0\n\tadd\t%rax,%r12\n\t mov\t8*5($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r12,%r11\n\tmov\t%rdx,%r12\n\tadc\t\\$0,%r12\n\n\tmulq\t$m0\n\tadd\t%rax,%r13\n\t mov\t8*6($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r13,%r12\n\tmov\t%rdx,%r13\n\tadc\t\\$0,%r13\n\n\tmulq\t$m0\n\tadd\t%rax,%r14\n\t mov\t8*7($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r14,%r13\n\tmov\t%rdx,%r14\n\tadc\t\\$0,%r14\n\n\tmulq\t$m0\n\t mov\t$carry,$m0\t\t# n0*a[i]\n\tadd\t%rax,%r15\n\t mov\t8*0($nptr),%rax\t\t# n[0]\n\tadc\t\\$0,%rdx\n\tadd\t%r15,%r14\n\tmov\t%rdx,%r15\n\tadc\t\\$0,%r15\n\n\tdec\t%ecx\n\tjnz\t.L8x_reduce\n\n\tlea\t8*8($nptr),$nptr\n\txor\t%rax,%rax\n\tmov\t8+8(%rsp),%rdx\t\t# pull end of t[]\n\tcmp\t0+8(%rsp),$nptr\t\t# end of n[]?\n\tjae\t.L8x_no_tail\n\n\t.byte\t0x66\n\tadd\t8*0($tptr),%r8\n\tadc\t8*1($tptr),%r9\n\tadc\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tsbb\t$carry,$carry\t\t# top carry\n\n\tmov\t48+56+8(%rsp),$m0\t# pull n0*a[0]\n\tmov\t\\$8,%ecx\n\tmov\t8*0($nptr),%rax\n\tjmp\t.L8x_tail\n\n.align\t32\n.L8x_tail:\n\tmulq\t$m0\n\tadd\t%rax,%r8\n\t mov\t8*1($nptr),%rax\n\t mov\t%r8,($tptr)\t\t# save result\n\tmov\t%rdx,%r8\n\tadc\t\\$0,%r8\n\n\tmulq\t$m0\n\tadd\t%rax,%r9\n\t mov\t8*2($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r9,%r8\n\t lea\t8($tptr),$tptr\t\t# $tptr++\n\tmov\t%rdx,%r9\n\tadc\t\\$0,%r9\n\n\tmulq\t$m0\n\tadd\t%rax,%r10\n\t mov\t8*3($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r10,%r9\n\tmov\t%rdx,%r10\n\tadc\t\\$0,%r10\n\n\tmulq\t$m0\n\tadd\t%rax,%r11\n\t mov\t8*4($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r11,%r10\n\tmov\t%rdx,%r11\n\tadc\t\\$0,%r11\n\n\tmulq\t$m0\n\tadd\t%rax,%r12\n\t mov\t8*5($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r12,%r11\n\tmov\t%rdx,%r12\n\tadc\t\\$0,%r12\n\n\tmulq\t$m0\n\tadd\t%rax,%r13\n\t mov\t8*6($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r13,%r12\n\tmov\t%rdx,%r13\n\tadc\t\\$0,%r13\n\n\tmulq\t$m0\n\tadd\t%rax,%r14\n\t mov\t8*7($nptr),%rax\n\tadc\t\\$0,%rdx\n\tadd\t%r14,%r13\n\tmov\t%rdx,%r14\n\tadc\t\\$0,%r14\n\n\tmulq\t$m0\n\t mov\t48-16+8(%rsp,%rcx,8),$m0# pull n0*a[i]\n\tadd\t%rax,%r15\n\tadc\t\\$0,%rdx\n\tadd\t%r15,%r14\n\t mov\t8*0($nptr),%rax\t\t# pull n[0]\n\tmov\t%rdx,%r15\n\tadc\t\\$0,%r15\n\n\tdec\t%ecx\n\tjnz\t.L8x_tail\n\n\tlea\t8*8($nptr),$nptr\n\tmov\t8+8(%rsp),%rdx\t\t# pull end of t[]\n\tcmp\t0+8(%rsp),$nptr\t\t# end of n[]?\n\tjae\t.L8x_tail_done\t\t# break out of loop\n\n\t mov\t48+56+8(%rsp),$m0\t# pull n0*a[0]\n\tneg\t$carry\n\t mov\t8*0($nptr),%rax\t\t# pull n[0]\n\tadc\t8*0($tptr),%r8\n\tadc\t8*1($tptr),%r9\n\tadc\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tsbb\t$carry,$carry\t\t# top carry\n\n\tmov\t\\$8,%ecx\n\tjmp\t.L8x_tail\n\n.align\t32\n.L8x_tail_done:\n\txor\t%rax,%rax\n\tadd\t(%rdx),%r8\t\t# can this overflow?\n\tadc\t\\$0,%r9\n\tadc\t\\$0,%r10\n\tadc\t\\$0,%r11\n\tadc\t\\$0,%r12\n\tadc\t\\$0,%r13\n\tadc\t\\$0,%r14\n\tadc\t\\$0,%r15\n\tadc\t\\$0,%rax\n\n\tneg\t$carry\n.L8x_no_tail:\n\tadc\t8*0($tptr),%r8\n\tadc\t8*1($tptr),%r9\n\tadc\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tadc\t\\$0,%rax\t\t# top-most carry\n\t mov\t-8($nptr),%rcx\t\t# np[num-1]\n\t xor\t$carry,$carry\n\n\tmovq\t%xmm2,$nptr\t\t# restore $nptr\n\n\tmov\t%r8,8*0($tptr)\t\t# store top 512 bits\n\tmov\t%r9,8*1($tptr)\n\t movq\t%xmm3,$num\t\t# $num is %r9, can't be moved upwards\n\tmov\t%r10,8*2($tptr)\n\tmov\t%r11,8*3($tptr)\n\tmov\t%r12,8*4($tptr)\n\tmov\t%r13,8*5($tptr)\n\tmov\t%r14,8*6($tptr)\n\tmov\t%r15,8*7($tptr)\n\tlea\t8*8($tptr),$tptr\n\n\tcmp\t%rdx,$tptr\t\t# end of t[]?\n\tjb\t.L8x_reduction_loop\n\tret\n.size\tbn_sqr8x_internal,.-bn_sqr8x_internal\n___\n}\f\n##############################################################\n# Post-condition, 4x unrolled\n#\n{\nmy ($tptr,$nptr)=(\"%rbx\",\"%rbp\");\n$code.=<<___;\n.type\t__bn_post4x_internal,\\@abi-omnipotent\n.align\t32\n__bn_post4x_internal:\n\tmov\t8*0($nptr),%r12\n\tlea\t(%rdi,$num),$tptr\t# %rdi was $tptr above\n\tmov\t$num,%rcx\n\tmovq\t%xmm1,$rptr\t\t# restore $rptr\n\tneg\t%rax\n\tmovq\t%xmm1,$aptr\t\t# prepare for back-to-back call\n\tsar\t\\$3+2,%rcx\n\tdec\t%r12\t\t\t# so that after 'not' we get -n[0]\n\txor\t%r10,%r10\n\tmov\t8*1($nptr),%r13\n\tmov\t8*2($nptr),%r14\n\tmov\t8*3($nptr),%r15\n\tjmp\t.Lsqr4x_sub_entry\n\n.align\t16\n.Lsqr4x_sub:\n\tmov\t8*0($nptr),%r12\n\tmov\t8*1($nptr),%r13\n\tmov\t8*2($nptr),%r14\n\tmov\t8*3($nptr),%r15\n.Lsqr4x_sub_entry:\n\tlea\t8*4($nptr),$nptr\n\tnot\t%r12\n\tnot\t%r13\n\tnot\t%r14\n\tnot\t%r15\n\tand\t%rax,%r12\n\tand\t%rax,%r13\n\tand\t%rax,%r14\n\tand\t%rax,%r15\n\n\tneg\t%r10\t\t\t# mov %r10,%cf\n\tadc\t8*0($tptr),%r12\n\tadc\t8*1($tptr),%r13\n\tadc\t8*2($tptr),%r14\n\tadc\t8*3($tptr),%r15\n\tmov\t%r12,8*0($rptr)\n\tlea\t8*4($tptr),$tptr\n\tmov\t%r13,8*1($rptr)\n\tsbb\t%r10,%r10\t\t# mov %cf,%r10\n\tmov\t%r14,8*2($rptr)\n\tmov\t%r15,8*3($rptr)\n\tlea\t8*4($rptr),$rptr\n\n\tinc\t%rcx\t\t\t# pass %cf\n\tjnz\t.Lsqr4x_sub\n\n\tmov\t$num,%r10\t\t# prepare for back-to-back call\n\tneg\t$num\t\t\t# restore $num\t\n\tret\n.size\t__bn_post4x_internal,.-__bn_post4x_internal\n___\n}\n{\n$code.=<<___;\n.globl\tbn_from_montgomery\n.type\tbn_from_montgomery,\\@abi-omnipotent\n.align\t32\nbn_from_montgomery:\n\ttestl\t\\$7,`($win64?\"48(%rsp)\":\"%r9d\")`\n\tjz\tbn_from_mont8x\n\txor\t%eax,%eax\n\tret\n.size\tbn_from_montgomery,.-bn_from_montgomery\n\n.type\tbn_from_mont8x,\\@function,6\n.align\t32\nbn_from_mont8x:\n\t.byte\t0x67\n\tmov\t%rsp,%rax\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n.Lfrom_prologue:\n\n\tshl\t\\$3,${num}d\t\t# convert $num to bytes\n\tlea\t($num,$num,2),%r10\t# 3*$num in bytes\n\tneg\t$num\n\tmov\t($n0),$n0\t\t# *n0\n\n\t##############################################################\n\t# Ensure that stack frame doesn't alias with $rptr+3*$num\n\t# modulo 4096, which covers ret[num], am[num] and n[num]\n\t# (see bn_exp.c). The stack is allocated to aligned with\n\t# bn_power5's frame, and as bn_from_montgomery happens to be\n\t# last operation, we use the opportunity to cleanse it.\n\t#\n\tlea\t-320(%rsp,$num,2),%r11\n\tmov\t%rsp,%rbp\n\tsub\t$rptr,%r11\n\tand\t\\$4095,%r11\n\tcmp\t%r11,%r10\n\tjb\t.Lfrom_sp_alt\n\tsub\t%r11,%rbp\t\t# align with $aptr\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*$num*8+256)\n\tjmp\t.Lfrom_sp_done\n\n.align\t32\n.Lfrom_sp_alt:\n\tlea\t4096-320(,$num,2),%r10\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*$num*8+256)\n\tsub\t%r10,%r11\n\tmov\t\\$0,%r10\n\tcmovc\t%r10,%r11\n\tsub\t%r11,%rbp\n.Lfrom_sp_done:\n\tand\t\\$-64,%rbp\n\tmov\t%rsp,%r11\n\tsub\t%rbp,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%rbp,%r11),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lfrom_page_walk\n\tjmp\t.Lfrom_page_walk_done\n\n.Lfrom_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lfrom_page_walk\n.Lfrom_page_walk_done:\n\n\tmov\t$num,%r10\n\tneg\t$num\n\n\t##############################################################\n\t# Stack layout\n\t#\n\t# +0\tsaved $num, used in reduction section\n\t# +8\t&t[2*$num], used in reduction section\n\t# +32\tsaved *n0\n\t# +40\tsaved %rsp\n\t# +48\tt[2*$num]\n\t#\n\tmov\t$n0,  32(%rsp)\n\tmov\t%rax, 40(%rsp)\t\t# save original %rsp\n.Lfrom_body:\n\tmov\t$num,%r11\n\tlea\t48(%rsp),%rax\n\tpxor\t%xmm0,%xmm0\n\tjmp\t.Lmul_by_1\n\n.align\t32\n.Lmul_by_1:\n\tmovdqu\t($aptr),%xmm1\n\tmovdqu\t16($aptr),%xmm2\n\tmovdqu\t32($aptr),%xmm3\n\tmovdqa\t%xmm0,(%rax,$num)\n\tmovdqu\t48($aptr),%xmm4\n\tmovdqa\t%xmm0,16(%rax,$num)\n\t.byte\t0x48,0x8d,0xb6,0x40,0x00,0x00,0x00\t# lea\t64($aptr),$aptr\n\tmovdqa\t%xmm1,(%rax)\n\tmovdqa\t%xmm0,32(%rax,$num)\n\tmovdqa\t%xmm2,16(%rax)\n\tmovdqa\t%xmm0,48(%rax,$num)\n\tmovdqa\t%xmm3,32(%rax)\n\tmovdqa\t%xmm4,48(%rax)\n\tlea\t64(%rax),%rax\n\tsub\t\\$64,%r11\n\tjnz\t.Lmul_by_1\n\n\tmovq\t$rptr,%xmm1\n\tmovq\t$nptr,%xmm2\n\t.byte\t0x67\n\tmov\t$nptr,%rbp\n\tmovq\t%r10, %xmm3\t\t# -num\n___\n$code.=<<___ if ($addx);\n\tmov\tOPENSSL_ia32cap_P+8(%rip),%r11d\n\tand\t\\$0x80108,%r11d\n\tcmp\t\\$0x80108,%r11d\t\t# check for AD*X+BMI2+BMI1\n\tjne\t.Lfrom_mont_nox\n\n\tlea\t(%rax,$num),$rptr\n\tcall\t__bn_sqrx8x_reduction\n\tcall\t__bn_postx4x_internal\n\n\tpxor\t%xmm0,%xmm0\n\tlea\t48(%rsp),%rax\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tjmp\t.Lfrom_mont_zero\n\n.align\t32\n.Lfrom_mont_nox:\n___\n$code.=<<___;\n\tcall\t__bn_sqr8x_reduction\n\tcall\t__bn_post4x_internal\n\n\tpxor\t%xmm0,%xmm0\n\tlea\t48(%rsp),%rax\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tjmp\t.Lfrom_mont_zero\n\n.align\t32\n.Lfrom_mont_zero:\n\tmovdqa\t%xmm0,16*0(%rax)\n\tmovdqa\t%xmm0,16*1(%rax)\n\tmovdqa\t%xmm0,16*2(%rax)\n\tmovdqa\t%xmm0,16*3(%rax)\n\tlea\t16*4(%rax),%rax\n\tsub\t\\$32,$num\n\tjnz\t.Lfrom_mont_zero\n\n\tmov\t\\$1,%rax\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lfrom_epilogue:\n\tret\n.size\tbn_from_mont8x,.-bn_from_mont8x\n___\n}\n}}}\n\f\nif ($addx) {{{\nmy $bp=\"%rdx\";\t# restore original value\n\n$code.=<<___;\n.type\tbn_mulx4x_mont_gather5,\\@function,6\n.align\t32\nbn_mulx4x_mont_gather5:\n\tmov\t%rsp,%rax\n.Lmulx4x_enter:\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n.Lmulx4x_prologue:\n\n\tshl\t\\$3,${num}d\t\t# convert $num to bytes\n\tlea\t($num,$num,2),%r10\t# 3*$num in bytes\n\tneg\t$num\t\t\t# -$num\n\tmov\t($n0),$n0\t\t# *n0\n\n\t##############################################################\n\t# Ensure that stack frame doesn't alias with $rptr+3*$num\n\t# modulo 4096, which covers ret[num], am[num] and n[num]\n\t# (see bn_exp.c). This is done to allow memory disambiguation\n\t# logic do its magic. [Extra [num] is allocated in order\n\t# to align with bn_power5's frame, which is cleansed after\n\t# completing exponentiation. Extra 256 bytes is for power mask\n\t# calculated from 7th argument, the index.]\n\t#\n\tlea\t-320(%rsp,$num,2),%r11\n\tmov\t%rsp,%rbp\n\tsub\t$rp,%r11\n\tand\t\\$4095,%r11\n\tcmp\t%r11,%r10\n\tjb\t.Lmulx4xsp_alt\n\tsub\t%r11,%rbp\t\t# align with $aptr\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*$num*8+256)\n\tjmp\t.Lmulx4xsp_done\n\n.Lmulx4xsp_alt:\n\tlea\t4096-320(,$num,2),%r10\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*$num*8+256)\n\tsub\t%r10,%r11\n\tmov\t\\$0,%r10\n\tcmovc\t%r10,%r11\n\tsub\t%r11,%rbp\n.Lmulx4xsp_done:\t\n\tand\t\\$-64,%rbp\t\t# ensure alignment\n\tmov\t%rsp,%r11\n\tsub\t%rbp,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%rbp,%r11),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lmulx4x_page_walk\n\tjmp\t.Lmulx4x_page_walk_done\n\n.Lmulx4x_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lmulx4x_page_walk\n.Lmulx4x_page_walk_done:\n\n\t##############################################################\n\t# Stack layout\n\t# +0\t-num\n\t# +8\toff-loaded &b[i]\n\t# +16\tend of b[num]\n\t# +24\tinner counter\n\t# +32\tsaved n0\n\t# +40\tsaved %rsp\n\t# +48\n\t# +56\tsaved rp\n\t# +64\ttmp[num+1]\n\t#\n\tmov\t$n0, 32(%rsp)\t\t# save *n0\n\tmov\t%rax,40(%rsp)\t\t# save original %rsp\n.Lmulx4x_body:\n\tcall\tmulx4x_internal\n\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tmov\t\\$1,%rax\n\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lmulx4x_epilogue:\n\tret\n.size\tbn_mulx4x_mont_gather5,.-bn_mulx4x_mont_gather5\n\n.type\tmulx4x_internal,\\@abi-omnipotent\n.align\t32\nmulx4x_internal:\n\tmov\t$num,8(%rsp)\t\t# save -$num (it was in bytes)\n\tmov\t$num,%r10\n\tneg\t$num\t\t\t# restore $num\n\tshl\t\\$5,$num\n\tneg\t%r10\t\t\t# restore $num\n\tlea\t128($bp,$num),%r13\t# end of powers table (+size optimization)\n\tshr\t\\$5+5,$num\n\tmovd\t`($win64?56:8)`(%rax),%xmm5\t# load 7th argument\n\tsub\t\\$1,$num\n\tlea\t.Linc(%rip),%rax\n\tmov\t%r13,16+8(%rsp)\t\t# end of b[num]\n\tmov\t$num,24+8(%rsp)\t\t# inner counter\n\tmov\t$rp, 56+8(%rsp)\t\t# save $rp\n___\nmy ($aptr, $bptr, $nptr, $tptr, $mi,  $bi,  $zero, $num)=\n   (\"%rsi\",\"%rdi\",\"%rcx\",\"%rbx\",\"%r8\",\"%r9\",\"%rbp\",\"%rax\");\nmy $rptr=$bptr;\nmy $STRIDE=2**5*8;\t\t# 5 is \"window size\"\nmy $N=$STRIDE/4;\t\t# should match cache line size\n$code.=<<___;\n\tmovdqa\t0(%rax),%xmm0\t\t# 00000001000000010000000000000000\n\tmovdqa\t16(%rax),%xmm1\t\t# 00000002000000020000000200000002\n\tlea\t88-112(%rsp,%r10),%r10\t# place the mask after tp[num+1] (+ICache optimizaton)\n\tlea\t128($bp),$bptr\t\t# size optimization\n\n\tpshufd\t\\$0,%xmm5,%xmm5\t\t# broadcast index\n\tmovdqa\t%xmm1,%xmm4\n\t.byte\t0x67\n\tmovdqa\t%xmm1,%xmm2\n___\n########################################################################\n# calculate mask by comparing 0..31 to index and save result to stack\n#\n$code.=<<___;\n\t.byte\t0x67\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\t\t# compare to 1,0\n\tmovdqa\t%xmm4,%xmm3\n___\nfor($i=0;$i<$STRIDE/16-4;$i+=4) {\n$code.=<<___;\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\t\t# compare to 3,2\n\tmovdqa\t%xmm0,`16*($i+0)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm0\n\n\tpaddd\t%xmm2,%xmm3\n\tpcmpeqd\t%xmm5,%xmm2\t\t# compare to 5,4\n\tmovdqa\t%xmm1,`16*($i+1)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm1\n\n\tpaddd\t%xmm3,%xmm0\n\tpcmpeqd\t%xmm5,%xmm3\t\t# compare to 7,6\n\tmovdqa\t%xmm2,`16*($i+2)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm2\n\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\n\tmovdqa\t%xmm3,`16*($i+3)+112`(%r10)\n\tmovdqa\t%xmm4,%xmm3\n___\n}\n$code.=<<___;\t\t\t\t# last iteration can be optimized\n\t.byte\t0x67\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\n\tmovdqa\t%xmm0,`16*($i+0)+112`(%r10)\n\n\tpaddd\t%xmm2,%xmm3\n\tpcmpeqd\t%xmm5,%xmm2\n\tmovdqa\t%xmm1,`16*($i+1)+112`(%r10)\n\n\tpcmpeqd\t%xmm5,%xmm3\n\tmovdqa\t%xmm2,`16*($i+2)+112`(%r10)\n\n\tpand\t`16*($i+0)-128`($bptr),%xmm0\t# while it's still in register\n\tpand\t`16*($i+1)-128`($bptr),%xmm1\n\tpand\t`16*($i+2)-128`($bptr),%xmm2\n\tmovdqa\t%xmm3,`16*($i+3)+112`(%r10)\n\tpand\t`16*($i+3)-128`($bptr),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\nfor($i=0;$i<$STRIDE/16-4;$i+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($i+0)-128`($bptr),%xmm4\n\tmovdqa\t`16*($i+1)-128`($bptr),%xmm5\n\tmovdqa\t`16*($i+2)-128`($bptr),%xmm2\n\tpand\t`16*($i+0)+112`(%r10),%xmm4\n\tmovdqa\t`16*($i+3)-128`($bptr),%xmm3\n\tpand\t`16*($i+1)+112`(%r10),%xmm5\n\tpor\t%xmm4,%xmm0\n\tpand\t`16*($i+2)+112`(%r10),%xmm2\n\tpor\t%xmm5,%xmm1\n\tpand\t`16*($i+3)+112`(%r10),%xmm3\n\tpor\t%xmm2,%xmm0\n\tpor\t%xmm3,%xmm1\n___\n}\n$code.=<<___;\n\tpxor\t%xmm1,%xmm0\n\tpshufd\t\\$0x4e,%xmm0,%xmm1\n\tpor\t%xmm1,%xmm0\n\tlea\t$STRIDE($bptr),$bptr\n\tmovq\t%xmm0,%rdx\t\t# bp[0]\n\tlea\t64+8*4+8(%rsp),$tptr\n\n\tmov\t%rdx,$bi\n\tmulx\t0*8($aptr),$mi,%rax\t# a[0]*b[0]\n\tmulx\t1*8($aptr),%r11,%r12\t# a[1]*b[0]\n\tadd\t%rax,%r11\n\tmulx\t2*8($aptr),%rax,%r13\t# ...\n\tadc\t%rax,%r12\n\tadc\t\\$0,%r13\n\tmulx\t3*8($aptr),%rax,%r14\n\n\tmov\t$mi,%r15\n\timulq\t32+8(%rsp),$mi\t\t# \"t[0]\"*n0\n\txor\t$zero,$zero\t\t# cf=0, of=0\n\tmov\t$mi,%rdx\n\n\tmov\t$bptr,8+8(%rsp)\t\t# off-load &b[i]\n\n\tlea\t4*8($aptr),$aptr\n\tadcx\t%rax,%r13\n\tadcx\t$zero,%r14\t\t# cf=0\n\n\tmulx\t0*8($nptr),%rax,%r10\n\tadcx\t%rax,%r15\t\t# discarded\n\tadox\t%r11,%r10\n\tmulx\t1*8($nptr),%rax,%r11\n\tadcx\t%rax,%r10\n\tadox\t%r12,%r11\n\tmulx\t2*8($nptr),%rax,%r12\n\tmov\t24+8(%rsp),$bptr\t# counter value\n\tmov\t%r10,-8*4($tptr)\n\tadcx\t%rax,%r11\n\tadox\t%r13,%r12\n\tmulx\t3*8($nptr),%rax,%r15\n\t mov\t$bi,%rdx\n\tmov\t%r11,-8*3($tptr)\n\tadcx\t%rax,%r12\n\tadox\t$zero,%r15\t\t# of=0\n\tlea\t4*8($nptr),$nptr\n\tmov\t%r12,-8*2($tptr)\n\tjmp\t.Lmulx4x_1st\n\n.align\t32\n.Lmulx4x_1st:\n\tadcx\t$zero,%r15\t\t# cf=0, modulo-scheduled\n\tmulx\t0*8($aptr),%r10,%rax\t# a[4]*b[0]\n\tadcx\t%r14,%r10\n\tmulx\t1*8($aptr),%r11,%r14\t# a[5]*b[0]\n\tadcx\t%rax,%r11\n\tmulx\t2*8($aptr),%r12,%rax\t# ...\n\tadcx\t%r14,%r12\n\tmulx\t3*8($aptr),%r13,%r14\n\t .byte\t0x67,0x67\n\t mov\t$mi,%rdx\n\tadcx\t%rax,%r13\n\tadcx\t$zero,%r14\t\t# cf=0\n\tlea\t4*8($aptr),$aptr\n\tlea\t4*8($tptr),$tptr\n\n\tadox\t%r15,%r10\n\tmulx\t0*8($nptr),%rax,%r15\n\tadcx\t%rax,%r10\n\tadox\t%r15,%r11\n\tmulx\t1*8($nptr),%rax,%r15\n\tadcx\t%rax,%r11\n\tadox\t%r15,%r12\n\tmulx\t2*8($nptr),%rax,%r15\n\tmov\t%r10,-5*8($tptr)\n\tadcx\t%rax,%r12\n\tmov\t%r11,-4*8($tptr)\n\tadox\t%r15,%r13\n\tmulx\t3*8($nptr),%rax,%r15\n\t mov\t$bi,%rdx\n\tmov\t%r12,-3*8($tptr)\n\tadcx\t%rax,%r13\n\tadox\t$zero,%r15\n\tlea\t4*8($nptr),$nptr\n\tmov\t%r13,-2*8($tptr)\n\n\tdec\t$bptr\t\t\t# of=0, pass cf\n\tjnz\t.Lmulx4x_1st\n\n\tmov\t8(%rsp),$num\t\t# load -num\n\tadc\t$zero,%r15\t\t# modulo-scheduled\n\tlea\t($aptr,$num),$aptr\t# rewind $aptr\n\tadd\t%r15,%r14\n\tmov\t8+8(%rsp),$bptr\t\t# re-load &b[i]\n\tadc\t$zero,$zero\t\t# top-most carry\n\tmov\t%r14,-1*8($tptr)\n\tjmp\t.Lmulx4x_outer\n\n.align\t32\n.Lmulx4x_outer:\n\tlea\t16-256($tptr),%r10\t# where 256-byte mask is (+density control)\n\tpxor\t%xmm4,%xmm4\n\t.byte\t0x67,0x67\n\tpxor\t%xmm5,%xmm5\n___\nfor($i=0;$i<$STRIDE/16;$i+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($i+0)-128`($bptr),%xmm0\n\tmovdqa\t`16*($i+1)-128`($bptr),%xmm1\n\tmovdqa\t`16*($i+2)-128`($bptr),%xmm2\n\tpand\t`16*($i+0)+256`(%r10),%xmm0\n\tmovdqa\t`16*($i+3)-128`($bptr),%xmm3\n\tpand\t`16*($i+1)+256`(%r10),%xmm1\n\tpor\t%xmm0,%xmm4\n\tpand\t`16*($i+2)+256`(%r10),%xmm2\n\tpor\t%xmm1,%xmm5\n\tpand\t`16*($i+3)+256`(%r10),%xmm3\n\tpor\t%xmm2,%xmm4\n\tpor\t%xmm3,%xmm5\n___\n}\n$code.=<<___;\n\tpor\t%xmm5,%xmm4\n\tpshufd\t\\$0x4e,%xmm4,%xmm0\n\tpor\t%xmm4,%xmm0\n\tlea\t$STRIDE($bptr),$bptr\n\tmovq\t%xmm0,%rdx\t\t# m0=bp[i]\n\n\tmov\t$zero,($tptr)\t\t# save top-most carry\n\tlea\t4*8($tptr,$num),$tptr\t# rewind $tptr\n\tmulx\t0*8($aptr),$mi,%r11\t# a[0]*b[i]\n\txor\t$zero,$zero\t\t# cf=0, of=0\n\tmov\t%rdx,$bi\n\tmulx\t1*8($aptr),%r14,%r12\t# a[1]*b[i]\n\tadox\t-4*8($tptr),$mi\t\t# +t[0]\n\tadcx\t%r14,%r11\n\tmulx\t2*8($aptr),%r15,%r13\t# ...\n\tadox\t-3*8($tptr),%r11\n\tadcx\t%r15,%r12\n\tmulx\t3*8($aptr),%rdx,%r14\n\tadox\t-2*8($tptr),%r12\n\tadcx\t%rdx,%r13\n\tlea\t($nptr,$num),$nptr\t# rewind $nptr\n\tlea\t4*8($aptr),$aptr\n\tadox\t-1*8($tptr),%r13\n\tadcx\t$zero,%r14\n\tadox\t$zero,%r14\n\n\tmov\t$mi,%r15\n\timulq\t32+8(%rsp),$mi\t\t# \"t[0]\"*n0\n\n\tmov\t$mi,%rdx\n\txor\t$zero,$zero\t\t# cf=0, of=0\n\tmov\t$bptr,8+8(%rsp)\t\t# off-load &b[i]\n\n\tmulx\t0*8($nptr),%rax,%r10\n\tadcx\t%rax,%r15\t\t# discarded\n\tadox\t%r11,%r10\n\tmulx\t1*8($nptr),%rax,%r11\n\tadcx\t%rax,%r10\n\tadox\t%r12,%r11\n\tmulx\t2*8($nptr),%rax,%r12\n\tadcx\t%rax,%r11\n\tadox\t%r13,%r12\n\tmulx\t3*8($nptr),%rax,%r15\n\t mov\t$bi,%rdx\n\tmov\t24+8(%rsp),$bptr\t# counter value\n\tmov\t%r10,-8*4($tptr)\n\tadcx\t%rax,%r12\n\tmov\t%r11,-8*3($tptr)\n\tadox\t$zero,%r15\t\t# of=0\n\tmov\t%r12,-8*2($tptr)\n\tlea\t4*8($nptr),$nptr\n\tjmp\t.Lmulx4x_inner\n\n.align\t32\n.Lmulx4x_inner:\n\tmulx\t0*8($aptr),%r10,%rax\t# a[4]*b[i]\n\tadcx\t$zero,%r15\t\t# cf=0, modulo-scheduled\n\tadox\t%r14,%r10\n\tmulx\t1*8($aptr),%r11,%r14\t# a[5]*b[i]\n\tadcx\t0*8($tptr),%r10\n\tadox\t%rax,%r11\n\tmulx\t2*8($aptr),%r12,%rax\t# ...\n\tadcx\t1*8($tptr),%r11\n\tadox\t%r14,%r12\n\tmulx\t3*8($aptr),%r13,%r14\n\t mov\t$mi,%rdx\n\tadcx\t2*8($tptr),%r12\n\tadox\t%rax,%r13\n\tadcx\t3*8($tptr),%r13\n\tadox\t$zero,%r14\t\t# of=0\n\tlea\t4*8($aptr),$aptr\n\tlea\t4*8($tptr),$tptr\n\tadcx\t$zero,%r14\t\t# cf=0\n\n\tadox\t%r15,%r10\n\tmulx\t0*8($nptr),%rax,%r15\n\tadcx\t%rax,%r10\n\tadox\t%r15,%r11\n\tmulx\t1*8($nptr),%rax,%r15\n\tadcx\t%rax,%r11\n\tadox\t%r15,%r12\n\tmulx\t2*8($nptr),%rax,%r15\n\tmov\t%r10,-5*8($tptr)\n\tadcx\t%rax,%r12\n\tadox\t%r15,%r13\n\tmov\t%r11,-4*8($tptr)\n\tmulx\t3*8($nptr),%rax,%r15\n\t mov\t$bi,%rdx\n\tlea\t4*8($nptr),$nptr\n\tmov\t%r12,-3*8($tptr)\n\tadcx\t%rax,%r13\n\tadox\t$zero,%r15\n\tmov\t%r13,-2*8($tptr)\n\n\tdec\t$bptr\t\t\t# of=0, pass cf\n\tjnz\t.Lmulx4x_inner\n\n\tmov\t0+8(%rsp),$num\t\t# load -num\n\tadc\t$zero,%r15\t\t# modulo-scheduled\n\tsub\t0*8($tptr),$bptr\t# pull top-most carry to %cf\n\tmov\t8+8(%rsp),$bptr\t\t# re-load &b[i]\n\tmov\t16+8(%rsp),%r10\n\tadc\t%r15,%r14\n\tlea\t($aptr,$num),$aptr\t# rewind $aptr\n\tadc\t$zero,$zero\t\t# top-most carry\n\tmov\t%r14,-1*8($tptr)\n\n\tcmp\t%r10,$bptr\n\tjb\t.Lmulx4x_outer\n\n\tmov\t-8($nptr),%r10\n\tmov\t$zero,%r8\n\tmov\t($nptr,$num),%r12\n\tlea\t($nptr,$num),%rbp\t# rewind $nptr\n\tmov\t$num,%rcx\n\tlea\t($tptr,$num),%rdi\t# rewind $tptr\n\txor\t%eax,%eax\n\txor\t%r15,%r15\n\tsub\t%r14,%r10\t\t# compare top-most words\n\tadc\t%r15,%r15\n\tor\t%r15,%r8\n\tsar\t\\$3+2,%rcx\n\tsub\t%r8,%rax\t\t# %rax=-%r8\n\tmov\t56+8(%rsp),%rdx\t\t# restore rp\n\tdec\t%r12\t\t\t# so that after 'not' we get -n[0]\n\tmov\t8*1(%rbp),%r13\n\txor\t%r8,%r8\n\tmov\t8*2(%rbp),%r14\n\tmov\t8*3(%rbp),%r15\n\tjmp\t.Lsqrx4x_sub_entry\t# common post-condition\n.size\tmulx4x_internal,.-mulx4x_internal\n___\n}\f{\n######################################################################\n# void bn_power5(\nmy $rptr=\"%rdi\";\t# BN_ULONG *rptr,\nmy $aptr=\"%rsi\";\t# const BN_ULONG *aptr,\nmy $bptr=\"%rdx\";\t# const void *table,\nmy $nptr=\"%rcx\";\t# const BN_ULONG *nptr,\nmy $n0  =\"%r8\";\t\t# const BN_ULONG *n0);\nmy $num =\"%r9\";\t\t# int num, has to be divisible by 8\n\t\t\t# int pwr);\n\nmy ($i,$j,$tptr)=(\"%rbp\",\"%rcx\",$rptr);\nmy @A0=(\"%r10\",\"%r11\");\nmy @A1=(\"%r12\",\"%r13\");\nmy ($a0,$a1,$ai)=(\"%r14\",\"%r15\",\"%rbx\");\n\n$code.=<<___;\n.type\tbn_powerx5,\\@function,6\n.align\t32\nbn_powerx5:\n\tmov\t%rsp,%rax\n.Lpowerx5_enter:\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n.Lpowerx5_prologue:\n\n\tshl\t\\$3,${num}d\t\t# convert $num to bytes\n\tlea\t($num,$num,2),%r10\t# 3*$num in bytes\n\tneg\t$num\n\tmov\t($n0),$n0\t\t# *n0\n\n\t##############################################################\n\t# Ensure that stack frame doesn't alias with $rptr+3*$num\n\t# modulo 4096, which covers ret[num], am[num] and n[num]\n\t# (see bn_exp.c). This is done to allow memory disambiguation\n\t# logic do its magic. [Extra 256 bytes is for power mask\n\t# calculated from 7th argument, the index.]\n\t#\n\tlea\t-320(%rsp,$num,2),%r11\n\tmov\t%rsp,%rbp\n\tsub\t$rptr,%r11\n\tand\t\\$4095,%r11\n\tcmp\t%r11,%r10\n\tjb\t.Lpwrx_sp_alt\n\tsub\t%r11,%rbp\t\t# align with $aptr\n\tlea\t-320(%rbp,$num,2),%rbp\t# future alloca(frame+2*$num*8+256)\n\tjmp\t.Lpwrx_sp_done\n\n.align\t32\n.Lpwrx_sp_alt:\n\tlea\t4096-320(,$num,2),%r10\n\tlea\t-320(%rbp,$num,2),%rbp\t# alloca(frame+2*$num*8+256)\n\tsub\t%r10,%r11\n\tmov\t\\$0,%r10\n\tcmovc\t%r10,%r11\n\tsub\t%r11,%rbp\n.Lpwrx_sp_done:\n\tand\t\\$-64,%rbp\n\tmov\t%rsp,%r11\n\tsub\t%rbp,%r11\n\tand\t\\$-4096,%r11\n\tlea\t(%rbp,%r11),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lpwrx_page_walk\n\tjmp\t.Lpwrx_page_walk_done\n\n.Lpwrx_page_walk:\n\tlea\t-4096(%rsp),%rsp\n\tmov\t(%rsp),%r10\n\tcmp\t%rbp,%rsp\n\tja\t.Lpwrx_page_walk\n.Lpwrx_page_walk_done:\n\n\tmov\t$num,%r10\t\n\tneg\t$num\n\n\t##############################################################\n\t# Stack layout\n\t#\n\t# +0\tsaved $num, used in reduction section\n\t# +8\t&t[2*$num], used in reduction section\n\t# +16\tintermediate carry bit\n\t# +24\ttop-most carry bit, used in reduction section\n\t# +32\tsaved *n0\n\t# +40\tsaved %rsp\n\t# +48\tt[2*$num]\n\t#\n\tpxor\t%xmm0,%xmm0\n\tmovq\t$rptr,%xmm1\t\t# save $rptr\n\tmovq\t$nptr,%xmm2\t\t# save $nptr\n\tmovq\t%r10, %xmm3\t\t# -$num\n\tmovq\t$bptr,%xmm4\n\tmov\t$n0,  32(%rsp)\n\tmov\t%rax, 40(%rsp)\t\t# save original %rsp\n.Lpowerx5_body:\n\n\tcall\t__bn_sqrx8x_internal\n\tcall\t__bn_postx4x_internal\n\tcall\t__bn_sqrx8x_internal\n\tcall\t__bn_postx4x_internal\n\tcall\t__bn_sqrx8x_internal\n\tcall\t__bn_postx4x_internal\n\tcall\t__bn_sqrx8x_internal\n\tcall\t__bn_postx4x_internal\n\tcall\t__bn_sqrx8x_internal\n\tcall\t__bn_postx4x_internal\n\n\tmov\t%r10,$num\t\t# -num\n\tmov\t$aptr,$rptr\n\tmovq\t%xmm2,$nptr\n\tmovq\t%xmm4,$bptr\n\tmov\t40(%rsp),%rax\n\n\tcall\tmulx4x_internal\n\n\tmov\t40(%rsp),%rsi\t\t# restore %rsp\n\tmov\t\\$1,%rax\n\n\tmov\t-48(%rsi),%r15\n\tmov\t-40(%rsi),%r14\n\tmov\t-32(%rsi),%r13\n\tmov\t-24(%rsi),%r12\n\tmov\t-16(%rsi),%rbp\n\tmov\t-8(%rsi),%rbx\n\tlea\t(%rsi),%rsp\n.Lpowerx5_epilogue:\n\tret\n.size\tbn_powerx5,.-bn_powerx5\n\n.globl\tbn_sqrx8x_internal\n.hidden\tbn_sqrx8x_internal\n.type\tbn_sqrx8x_internal,\\@abi-omnipotent\n.align\t32\nbn_sqrx8x_internal:\n__bn_sqrx8x_internal:\n\t##################################################################\n\t# Squaring part:\n\t#\n\t# a) multiply-n-add everything but a[i]*a[i];\n\t# b) shift result of a) by 1 to the left and accumulate\n\t#    a[i]*a[i] products;\n\t#\n\t##################################################################\n\t# a[7]a[7]a[6]a[6]a[5]a[5]a[4]a[4]a[3]a[3]a[2]a[2]a[1]a[1]a[0]a[0]\n\t#                                                     a[1]a[0]\n\t#                                                 a[2]a[0]\n\t#                                             a[3]a[0]\n\t#                                             a[2]a[1]\n\t#                                         a[3]a[1]\n\t#                                     a[3]a[2]\n\t#\n\t#                                         a[4]a[0]\n\t#                                     a[5]a[0]\n\t#                                 a[6]a[0]\n\t#                             a[7]a[0]\n\t#                                     a[4]a[1]\n\t#                                 a[5]a[1]\n\t#                             a[6]a[1]\n\t#                         a[7]a[1]\n\t#                                 a[4]a[2]\n\t#                             a[5]a[2]\n\t#                         a[6]a[2]\n\t#                     a[7]a[2]\n\t#                             a[4]a[3]\n\t#                         a[5]a[3]\n\t#                     a[6]a[3]\n\t#                 a[7]a[3]\n\t#\n\t#                     a[5]a[4]\n\t#                 a[6]a[4]\n\t#             a[7]a[4]\n\t#             a[6]a[5]\n\t#         a[7]a[5]\n\t#     a[7]a[6]\n\t# a[7]a[7]a[6]a[6]a[5]a[5]a[4]a[4]a[3]a[3]a[2]a[2]a[1]a[1]a[0]a[0]\n___\n{\nmy ($zero,$carry)=(\"%rbp\",\"%rcx\");\nmy $aaptr=$zero;\n$code.=<<___;\n\tlea\t48+8(%rsp),$tptr\n\tlea\t($aptr,$num),$aaptr\n\tmov\t$num,0+8(%rsp)\t\t\t# save $num\n\tmov\t$aaptr,8+8(%rsp)\t\t# save end of $aptr\n\tjmp\t.Lsqr8x_zero_start\n\n.align\t32\n.byte\t0x66,0x66,0x66,0x2e,0x0f,0x1f,0x84,0x00,0x00,0x00,0x00,0x00\n.Lsqrx8x_zero:\n\t.byte\t0x3e\n\tmovdqa\t%xmm0,0*8($tptr)\n\tmovdqa\t%xmm0,2*8($tptr)\n\tmovdqa\t%xmm0,4*8($tptr)\n\tmovdqa\t%xmm0,6*8($tptr)\n.Lsqr8x_zero_start:\t\t\t# aligned at 32\n\tmovdqa\t%xmm0,8*8($tptr)\n\tmovdqa\t%xmm0,10*8($tptr)\n\tmovdqa\t%xmm0,12*8($tptr)\n\tmovdqa\t%xmm0,14*8($tptr)\n\tlea\t16*8($tptr),$tptr\n\tsub\t\\$64,$num\n\tjnz\t.Lsqrx8x_zero\n\n\tmov\t0*8($aptr),%rdx\t\t# a[0], modulo-scheduled\n\t#xor\t%r9,%r9\t\t\t# t[1], ex-$num, zero already\n\txor\t%r10,%r10\n\txor\t%r11,%r11\n\txor\t%r12,%r12\n\txor\t%r13,%r13\n\txor\t%r14,%r14\n\txor\t%r15,%r15\n\tlea\t48+8(%rsp),$tptr\n\txor\t$zero,$zero\t\t# cf=0, cf=0\n\tjmp\t.Lsqrx8x_outer_loop\n\n.align\t32\n.Lsqrx8x_outer_loop:\n\tmulx\t1*8($aptr),%r8,%rax\t# a[1]*a[0]\n\tadcx\t%r9,%r8\t\t\t# a[1]*a[0]+=t[1]\n\tadox\t%rax,%r10\n\tmulx\t2*8($aptr),%r9,%rax\t# a[2]*a[0]\n\tadcx\t%r10,%r9\n\tadox\t%rax,%r11\n\t.byte\t0xc4,0xe2,0xab,0xf6,0x86,0x18,0x00,0x00,0x00\t# mulx\t3*8($aptr),%r10,%rax\t# ...\n\tadcx\t%r11,%r10\n\tadox\t%rax,%r12\n\t.byte\t0xc4,0xe2,0xa3,0xf6,0x86,0x20,0x00,0x00,0x00\t# mulx\t4*8($aptr),%r11,%rax\n\tadcx\t%r12,%r11\n\tadox\t%rax,%r13\n\tmulx\t5*8($aptr),%r12,%rax\n\tadcx\t%r13,%r12\n\tadox\t%rax,%r14\n\tmulx\t6*8($aptr),%r13,%rax\n\tadcx\t%r14,%r13\n\tadox\t%r15,%rax\n\tmulx\t7*8($aptr),%r14,%r15\n\t mov\t1*8($aptr),%rdx\t\t# a[1]\n\tadcx\t%rax,%r14\n\tadox\t$zero,%r15\n\tadc\t8*8($tptr),%r15\n\tmov\t%r8,1*8($tptr)\t\t# t[1]\n\tmov\t%r9,2*8($tptr)\t\t# t[2]\n\tsbb\t$carry,$carry\t\t# mov %cf,$carry\n\txor\t$zero,$zero\t\t# cf=0, of=0\n\n\n\tmulx\t2*8($aptr),%r8,%rbx\t# a[2]*a[1]\n\tmulx\t3*8($aptr),%r9,%rax\t# a[3]*a[1]\n\tadcx\t%r10,%r8\n\tadox\t%rbx,%r9\n\tmulx\t4*8($aptr),%r10,%rbx\t# ...\n\tadcx\t%r11,%r9\n\tadox\t%rax,%r10\n\t.byte\t0xc4,0xe2,0xa3,0xf6,0x86,0x28,0x00,0x00,0x00\t# mulx\t5*8($aptr),%r11,%rax\n\tadcx\t%r12,%r10\n\tadox\t%rbx,%r11\n\t.byte\t0xc4,0xe2,0x9b,0xf6,0x9e,0x30,0x00,0x00,0x00\t# mulx\t6*8($aptr),%r12,%rbx\n\tadcx\t%r13,%r11\n\tadox\t%r14,%r12\n\t.byte\t0xc4,0x62,0x93,0xf6,0xb6,0x38,0x00,0x00,0x00\t# mulx\t7*8($aptr),%r13,%r14\n\t mov\t2*8($aptr),%rdx\t\t# a[2]\n\tadcx\t%rax,%r12\n\tadox\t%rbx,%r13\n\tadcx\t%r15,%r13\n\tadox\t$zero,%r14\t\t# of=0\n\tadcx\t$zero,%r14\t\t# cf=0\n\n\tmov\t%r8,3*8($tptr)\t\t# t[3]\n\tmov\t%r9,4*8($tptr)\t\t# t[4]\n\n\tmulx\t3*8($aptr),%r8,%rbx\t# a[3]*a[2]\n\tmulx\t4*8($aptr),%r9,%rax\t# a[4]*a[2]\n\tadcx\t%r10,%r8\n\tadox\t%rbx,%r9\n\tmulx\t5*8($aptr),%r10,%rbx\t# ...\n\tadcx\t%r11,%r9\n\tadox\t%rax,%r10\n\t.byte\t0xc4,0xe2,0xa3,0xf6,0x86,0x30,0x00,0x00,0x00\t# mulx\t6*8($aptr),%r11,%rax\n\tadcx\t%r12,%r10\n\tadox\t%r13,%r11\n\t.byte\t0xc4,0x62,0x9b,0xf6,0xae,0x38,0x00,0x00,0x00\t# mulx\t7*8($aptr),%r12,%r13\n\t.byte\t0x3e\n\t mov\t3*8($aptr),%rdx\t\t# a[3]\n\tadcx\t%rbx,%r11\n\tadox\t%rax,%r12\n\tadcx\t%r14,%r12\n\tmov\t%r8,5*8($tptr)\t\t# t[5]\n\tmov\t%r9,6*8($tptr)\t\t# t[6]\n\t mulx\t4*8($aptr),%r8,%rax\t# a[4]*a[3]\n\tadox\t$zero,%r13\t\t# of=0\n\tadcx\t$zero,%r13\t\t# cf=0\n\n\tmulx\t5*8($aptr),%r9,%rbx\t# a[5]*a[3]\n\tadcx\t%r10,%r8\n\tadox\t%rax,%r9\n\tmulx\t6*8($aptr),%r10,%rax\t# ...\n\tadcx\t%r11,%r9\n\tadox\t%r12,%r10\n\tmulx\t7*8($aptr),%r11,%r12\n\t mov\t4*8($aptr),%rdx\t\t# a[4]\n\t mov\t5*8($aptr),%r14\t\t# a[5]\n\tadcx\t%rbx,%r10\n\tadox\t%rax,%r11\n\t mov\t6*8($aptr),%r15\t\t# a[6]\n\tadcx\t%r13,%r11\n\tadox\t$zero,%r12\t\t# of=0\n\tadcx\t$zero,%r12\t\t# cf=0\n\n\tmov\t%r8,7*8($tptr)\t\t# t[7]\n\tmov\t%r9,8*8($tptr)\t\t# t[8]\n\n\tmulx\t%r14,%r9,%rax\t\t# a[5]*a[4]\n\t mov\t7*8($aptr),%r8\t\t# a[7]\n\tadcx\t%r10,%r9\n\tmulx\t%r15,%r10,%rbx\t\t# a[6]*a[4]\n\tadox\t%rax,%r10\n\tadcx\t%r11,%r10\n\tmulx\t%r8,%r11,%rax\t\t# a[7]*a[4]\n\t mov\t%r14,%rdx\t\t# a[5]\n\tadox\t%rbx,%r11\n\tadcx\t%r12,%r11\n\t#adox\t$zero,%rax\t\t# of=0\n\tadcx\t$zero,%rax\t\t# cf=0\n\n\tmulx\t%r15,%r14,%rbx\t\t# a[6]*a[5]\n\tmulx\t%r8,%r12,%r13\t\t# a[7]*a[5]\n\t mov\t%r15,%rdx\t\t# a[6]\n\t lea\t8*8($aptr),$aptr\n\tadcx\t%r14,%r11\n\tadox\t%rbx,%r12\n\tadcx\t%rax,%r12\n\tadox\t$zero,%r13\n\n\t.byte\t0x67,0x67\n\tmulx\t%r8,%r8,%r14\t\t# a[7]*a[6]\n\tadcx\t%r8,%r13\n\tadcx\t$zero,%r14\n\n\tcmp\t8+8(%rsp),$aptr\n\tje\t.Lsqrx8x_outer_break\n\n\tneg\t$carry\t\t\t# mov $carry,%cf\n\tmov\t\\$-8,%rcx\n\tmov\t$zero,%r15\n\tmov\t8*8($tptr),%r8\n\tadcx\t9*8($tptr),%r9\t\t# +=t[9]\n\tadcx\t10*8($tptr),%r10\t# ...\n\tadcx\t11*8($tptr),%r11\n\tadc\t12*8($tptr),%r12\n\tadc\t13*8($tptr),%r13\n\tadc\t14*8($tptr),%r14\n\tadc\t15*8($tptr),%r15\n\tlea\t($aptr),$aaptr\n\tlea\t2*64($tptr),$tptr\n\tsbb\t%rax,%rax\t\t# mov %cf,$carry\n\n\tmov\t-64($aptr),%rdx\t\t# a[0]\n\tmov\t%rax,16+8(%rsp)\t\t# offload $carry\n\tmov\t$tptr,24+8(%rsp)\n\n\t#lea\t8*8($tptr),$tptr\t# see 2*8*8($tptr) above\n\txor\t%eax,%eax\t\t# cf=0, of=0\n\tjmp\t.Lsqrx8x_loop\n\n.align\t32\n.Lsqrx8x_loop:\n\tmov\t%r8,%rbx\n\tmulx\t0*8($aaptr),%rax,%r8\t# a[8]*a[i]\n\tadcx\t%rax,%rbx\t\t# +=t[8]\n\tadox\t%r9,%r8\n\n\tmulx\t1*8($aaptr),%rax,%r9\t# ...\n\tadcx\t%rax,%r8\n\tadox\t%r10,%r9\n\n\tmulx\t2*8($aaptr),%rax,%r10\n\tadcx\t%rax,%r9\n\tadox\t%r11,%r10\n\n\tmulx\t3*8($aaptr),%rax,%r11\n\tadcx\t%rax,%r10\n\tadox\t%r12,%r11\n\n\t.byte\t0xc4,0x62,0xfb,0xf6,0xa5,0x20,0x00,0x00,0x00\t# mulx\t4*8($aaptr),%rax,%r12\n\tadcx\t%rax,%r11\n\tadox\t%r13,%r12\n\n\tmulx\t5*8($aaptr),%rax,%r13\n\tadcx\t%rax,%r12\n\tadox\t%r14,%r13\n\n\tmulx\t6*8($aaptr),%rax,%r14\n\t mov\t%rbx,($tptr,%rcx,8)\t# store t[8+i]\n\t mov\t\\$0,%ebx\n\tadcx\t%rax,%r13\n\tadox\t%r15,%r14\n\n\t.byte\t0xc4,0x62,0xfb,0xf6,0xbd,0x38,0x00,0x00,0x00\t# mulx\t7*8($aaptr),%rax,%r15\n\t mov\t8($aptr,%rcx,8),%rdx\t# a[i]\n\tadcx\t%rax,%r14\n\tadox\t%rbx,%r15\t\t# %rbx is 0, of=0\n\tadcx\t%rbx,%r15\t\t# cf=0\n\n\t.byte\t0x67\n\tinc\t%rcx\t\t\t# of=0\n\tjnz\t.Lsqrx8x_loop\n\n\tlea\t8*8($aaptr),$aaptr\n\tmov\t\\$-8,%rcx\n\tcmp\t8+8(%rsp),$aaptr\t# done?\n\tje\t.Lsqrx8x_break\n\n\tsub\t16+8(%rsp),%rbx\t\t# mov 16(%rsp),%cf\n\t.byte\t0x66\n\tmov\t-64($aptr),%rdx\n\tadcx\t0*8($tptr),%r8\n\tadcx\t1*8($tptr),%r9\n\tadc\t2*8($tptr),%r10\n\tadc\t3*8($tptr),%r11\n\tadc\t4*8($tptr),%r12\n\tadc\t5*8($tptr),%r13\n\tadc\t6*8($tptr),%r14\n\tadc\t7*8($tptr),%r15\n\tlea\t8*8($tptr),$tptr\n\t.byte\t0x67\n\tsbb\t%rax,%rax\t\t# mov %cf,%rax\n\txor\t%ebx,%ebx\t\t# cf=0, of=0\n\tmov\t%rax,16+8(%rsp)\t\t# offload carry\n\tjmp\t.Lsqrx8x_loop\n\n.align\t32\n.Lsqrx8x_break:\n\tsub\t16+8(%rsp),%r8\t\t# consume last carry\n\tmov\t24+8(%rsp),$carry\t# initial $tptr, borrow $carry\n\tmov\t0*8($aptr),%rdx\t\t# a[8], modulo-scheduled\n\txor\t%ebp,%ebp\t\t# xor\t$zero,$zero\n\tmov\t%r8,0*8($tptr)\n\tcmp\t$carry,$tptr\t\t# cf=0, of=0\n\tje\t.Lsqrx8x_outer_loop\n\n\tmov\t%r9,1*8($tptr)\n\t mov\t1*8($carry),%r9\n\tmov\t%r10,2*8($tptr)\n\t mov\t2*8($carry),%r10\n\tmov\t%r11,3*8($tptr)\n\t mov\t3*8($carry),%r11\n\tmov\t%r12,4*8($tptr)\n\t mov\t4*8($carry),%r12\n\tmov\t%r13,5*8($tptr)\n\t mov\t5*8($carry),%r13\n\tmov\t%r14,6*8($tptr)\n\t mov\t6*8($carry),%r14\n\tmov\t%r15,7*8($tptr)\n\t mov\t7*8($carry),%r15\n\tmov\t$carry,$tptr\n\tjmp\t.Lsqrx8x_outer_loop\n\n.align\t32\n.Lsqrx8x_outer_break:\n\tmov\t%r9,9*8($tptr)\t\t# t[9]\n\t movq\t%xmm3,%rcx\t\t# -$num\n\tmov\t%r10,10*8($tptr)\t# ...\n\tmov\t%r11,11*8($tptr)\n\tmov\t%r12,12*8($tptr)\n\tmov\t%r13,13*8($tptr)\n\tmov\t%r14,14*8($tptr)\n___\n}\f{\nmy $i=\"%rcx\";\n$code.=<<___;\n\tlea\t48+8(%rsp),$tptr\n\tmov\t($aptr,$i),%rdx\t\t# a[0]\n\n\tmov\t8($tptr),$A0[1]\t\t# t[1]\n\txor\t$A0[0],$A0[0]\t\t# t[0], of=0, cf=0\n\tmov\t0+8(%rsp),$num\t\t# restore $num\n\tadox\t$A0[1],$A0[1]\n\t mov\t16($tptr),$A1[0]\t# t[2]\t# prefetch\n\t mov\t24($tptr),$A1[1]\t# t[3]\t# prefetch\n\t#jmp\t.Lsqrx4x_shift_n_add\t# happens to be aligned\n\n.align\t32\n.Lsqrx4x_shift_n_add:\n\tmulx\t%rdx,%rax,%rbx\n\t adox\t$A1[0],$A1[0]\n\tadcx\t$A0[0],%rax\n\t .byte\t0x48,0x8b,0x94,0x0e,0x08,0x00,0x00,0x00\t# mov\t8($aptr,$i),%rdx\t# a[i+1]\t# prefetch\n\t .byte\t0x4c,0x8b,0x97,0x20,0x00,0x00,0x00\t# mov\t32($tptr),$A0[0]\t# t[2*i+4]\t# prefetch\n\t adox\t$A1[1],$A1[1]\n\tadcx\t$A0[1],%rbx\n\t mov\t40($tptr),$A0[1]\t\t# t[2*i+4+1]\t# prefetch\n\tmov\t%rax,0($tptr)\n\tmov\t%rbx,8($tptr)\n\n\tmulx\t%rdx,%rax,%rbx\n\t adox\t$A0[0],$A0[0]\n\tadcx\t$A1[0],%rax\n\t mov\t16($aptr,$i),%rdx\t# a[i+2]\t# prefetch\n\t mov\t48($tptr),$A1[0]\t# t[2*i+6]\t# prefetch\n\t adox\t$A0[1],$A0[1]\n\tadcx\t$A1[1],%rbx\n\t mov\t56($tptr),$A1[1]\t# t[2*i+6+1]\t# prefetch\n\tmov\t%rax,16($tptr)\n\tmov\t%rbx,24($tptr)\n\n\tmulx\t%rdx,%rax,%rbx\n\t adox\t$A1[0],$A1[0]\n\tadcx\t$A0[0],%rax\n\t mov\t24($aptr,$i),%rdx\t# a[i+3]\t# prefetch\n\t lea\t32($i),$i\n\t mov\t64($tptr),$A0[0]\t# t[2*i+8]\t# prefetch\n\t adox\t$A1[1],$A1[1]\n\tadcx\t$A0[1],%rbx\n\t mov\t72($tptr),$A0[1]\t# t[2*i+8+1]\t# prefetch\n\tmov\t%rax,32($tptr)\n\tmov\t%rbx,40($tptr)\n\n\tmulx\t%rdx,%rax,%rbx\n\t adox\t$A0[0],$A0[0]\n\tadcx\t$A1[0],%rax\n\tjrcxz\t.Lsqrx4x_shift_n_add_break\n\t .byte\t0x48,0x8b,0x94,0x0e,0x00,0x00,0x00,0x00\t# mov\t0($aptr,$i),%rdx\t# a[i+4]\t# prefetch\n\t adox\t$A0[1],$A0[1]\n\tadcx\t$A1[1],%rbx\n\t mov\t80($tptr),$A1[0]\t# t[2*i+10]\t# prefetch\n\t mov\t88($tptr),$A1[1]\t# t[2*i+10+1]\t# prefetch\n\tmov\t%rax,48($tptr)\n\tmov\t%rbx,56($tptr)\n\tlea\t64($tptr),$tptr\n\tnop\n\tjmp\t.Lsqrx4x_shift_n_add\n\n.align\t32\n.Lsqrx4x_shift_n_add_break:\n\tadcx\t$A1[1],%rbx\n\tmov\t%rax,48($tptr)\n\tmov\t%rbx,56($tptr)\n\tlea\t64($tptr),$tptr\t\t# end of t[] buffer\n___\n}\f\n######################################################################\n# Montgomery reduction part, \"word-by-word\" algorithm.\n#\n# This new path is inspired by multiple submissions from Intel, by\n# Shay Gueron, Vlad Krasnov, Erdinc Ozturk, James Guilford,\n# Vinodh Gopal...\n{\nmy ($nptr,$carry,$m0)=(\"%rbp\",\"%rsi\",\"%rdx\");\n\n$code.=<<___;\n\tmovq\t%xmm2,$nptr\n__bn_sqrx8x_reduction:\n\txor\t%eax,%eax\t\t# initial top-most carry bit\n\tmov\t32+8(%rsp),%rbx\t\t# n0\n\tmov\t48+8(%rsp),%rdx\t\t# \"%r8\", 8*0($tptr)\n\tlea\t-8*8($nptr,$num),%rcx\t# end of n[]\n\t#lea\t48+8(%rsp,$num,2),$tptr\t# end of t[] buffer\n\tmov\t%rcx, 0+8(%rsp)\t\t# save end of n[]\n\tmov\t$tptr,8+8(%rsp)\t\t# save end of t[]\n\n\tlea\t48+8(%rsp),$tptr\t\t# initial t[] window\n\tjmp\t.Lsqrx8x_reduction_loop\n\n.align\t32\n.Lsqrx8x_reduction_loop:\n\tmov\t8*1($tptr),%r9\n\tmov\t8*2($tptr),%r10\n\tmov\t8*3($tptr),%r11\n\tmov\t8*4($tptr),%r12\n\tmov\t%rdx,%r8\n\timulq\t%rbx,%rdx\t\t# n0*a[i]\n\tmov\t8*5($tptr),%r13\n\tmov\t8*6($tptr),%r14\n\tmov\t8*7($tptr),%r15\n\tmov\t%rax,24+8(%rsp)\t\t# store top-most carry bit\n\n\tlea\t8*8($tptr),$tptr\n\txor\t$carry,$carry\t\t# cf=0,of=0\n\tmov\t\\$-8,%rcx\n\tjmp\t.Lsqrx8x_reduce\n\n.align\t32\n.Lsqrx8x_reduce:\n\tmov\t%r8, %rbx\n\tmulx\t8*0($nptr),%rax,%r8\t# n[0]\n\tadcx\t%rbx,%rax\t\t# discarded\n\tadox\t%r9,%r8\n\n\tmulx\t8*1($nptr),%rbx,%r9\t# n[1]\n\tadcx\t%rbx,%r8\n\tadox\t%r10,%r9\n\n\tmulx\t8*2($nptr),%rbx,%r10\n\tadcx\t%rbx,%r9\n\tadox\t%r11,%r10\n\n\tmulx\t8*3($nptr),%rbx,%r11\n\tadcx\t%rbx,%r10\n\tadox\t%r12,%r11\n\n\t.byte\t0xc4,0x62,0xe3,0xf6,0xa5,0x20,0x00,0x00,0x00\t# mulx\t8*4($nptr),%rbx,%r12\n\t mov\t%rdx,%rax\n\t mov\t%r8,%rdx\n\tadcx\t%rbx,%r11\n\tadox\t%r13,%r12\n\n\t mulx\t32+8(%rsp),%rbx,%rdx\t# %rdx discarded\n\t mov\t%rax,%rdx\n\t mov\t%rax,64+48+8(%rsp,%rcx,8)\t# put aside n0*a[i]\n\n\tmulx\t8*5($nptr),%rax,%r13\n\tadcx\t%rax,%r12\n\tadox\t%r14,%r13\n\n\tmulx\t8*6($nptr),%rax,%r14\n\tadcx\t%rax,%r13\n\tadox\t%r15,%r14\n\n\tmulx\t8*7($nptr),%rax,%r15\n\t mov\t%rbx,%rdx\n\tadcx\t%rax,%r14\n\tadox\t$carry,%r15\t\t# $carry is 0\n\tadcx\t$carry,%r15\t\t# cf=0\n\n\t.byte\t0x67,0x67,0x67\n\tinc\t%rcx\t\t\t# of=0\n\tjnz\t.Lsqrx8x_reduce\n\n\tmov\t$carry,%rax\t\t# xor\t%rax,%rax\n\tcmp\t0+8(%rsp),$nptr\t\t# end of n[]?\n\tjae\t.Lsqrx8x_no_tail\n\n\tmov\t48+8(%rsp),%rdx\t\t# pull n0*a[0]\n\tadd\t8*0($tptr),%r8\n\tlea\t8*8($nptr),$nptr\n\tmov\t\\$-8,%rcx\n\tadcx\t8*1($tptr),%r9\n\tadcx\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tlea\t8*8($tptr),$tptr\n\tsbb\t%rax,%rax\t\t# top carry\n\n\txor\t$carry,$carry\t\t# of=0, cf=0\n\tmov\t%rax,16+8(%rsp)\n\tjmp\t.Lsqrx8x_tail\n\n.align\t32\n.Lsqrx8x_tail:\n\tmov\t%r8,%rbx\n\tmulx\t8*0($nptr),%rax,%r8\n\tadcx\t%rax,%rbx\n\tadox\t%r9,%r8\n\n\tmulx\t8*1($nptr),%rax,%r9\n\tadcx\t%rax,%r8\n\tadox\t%r10,%r9\n\n\tmulx\t8*2($nptr),%rax,%r10\n\tadcx\t%rax,%r9\n\tadox\t%r11,%r10\n\n\tmulx\t8*3($nptr),%rax,%r11\n\tadcx\t%rax,%r10\n\tadox\t%r12,%r11\n\n\t.byte\t0xc4,0x62,0xfb,0xf6,0xa5,0x20,0x00,0x00,0x00\t# mulx\t8*4($nptr),%rax,%r12\n\tadcx\t%rax,%r11\n\tadox\t%r13,%r12\n\n\tmulx\t8*5($nptr),%rax,%r13\n\tadcx\t%rax,%r12\n\tadox\t%r14,%r13\n\n\tmulx\t8*6($nptr),%rax,%r14\n\tadcx\t%rax,%r13\n\tadox\t%r15,%r14\n\n\tmulx\t8*7($nptr),%rax,%r15\n\t mov\t72+48+8(%rsp,%rcx,8),%rdx\t# pull n0*a[i]\n\tadcx\t%rax,%r14\n\tadox\t$carry,%r15\n\t mov\t%rbx,($tptr,%rcx,8)\t# save result\n\t mov\t%r8,%rbx\n\tadcx\t$carry,%r15\t\t# cf=0\n\n\tinc\t%rcx\t\t\t# of=0\n\tjnz\t.Lsqrx8x_tail\n\n\tcmp\t0+8(%rsp),$nptr\t\t# end of n[]?\n\tjae\t.Lsqrx8x_tail_done\t# break out of loop\n\n\tsub\t16+8(%rsp),$carry\t# mov 16(%rsp),%cf\n\t mov\t48+8(%rsp),%rdx\t\t# pull n0*a[0]\n\t lea\t8*8($nptr),$nptr\n\tadc\t8*0($tptr),%r8\n\tadc\t8*1($tptr),%r9\n\tadc\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tlea\t8*8($tptr),$tptr\n\tsbb\t%rax,%rax\n\tsub\t\\$8,%rcx\t\t# mov\t\\$-8,%rcx\n\n\txor\t$carry,$carry\t\t# of=0, cf=0\n\tmov\t%rax,16+8(%rsp)\n\tjmp\t.Lsqrx8x_tail\n\n.align\t32\n.Lsqrx8x_tail_done:\n\txor\t%rax,%rax\n\tadd\t24+8(%rsp),%r8\t\t# can this overflow?\n\tadc\t\\$0,%r9\n\tadc\t\\$0,%r10\n\tadc\t\\$0,%r11\n\tadc\t\\$0,%r12\n\tadc\t\\$0,%r13\n\tadc\t\\$0,%r14\n\tadc\t\\$0,%r15\n\tadc\t\\$0,%rax\n\n\tsub\t16+8(%rsp),$carry\t# mov 16(%rsp),%cf\n.Lsqrx8x_no_tail:\t\t\t# %cf is 0 if jumped here\n\tadc\t8*0($tptr),%r8\n\t movq\t%xmm3,%rcx\n\tadc\t8*1($tptr),%r9\n\t mov\t8*7($nptr),$carry\n\t movq\t%xmm2,$nptr\t\t# restore $nptr\n\tadc\t8*2($tptr),%r10\n\tadc\t8*3($tptr),%r11\n\tadc\t8*4($tptr),%r12\n\tadc\t8*5($tptr),%r13\n\tadc\t8*6($tptr),%r14\n\tadc\t8*7($tptr),%r15\n\tadc\t\\$0,%rax\t\t# top-most carry\n\n\tmov\t32+8(%rsp),%rbx\t\t# n0\n\tmov\t8*8($tptr,%rcx),%rdx\t# modulo-scheduled \"%r8\"\n\n\tmov\t%r8,8*0($tptr)\t\t# store top 512 bits\n\t lea\t8*8($tptr),%r8\t\t# borrow %r8\n\tmov\t%r9,8*1($tptr)\n\tmov\t%r10,8*2($tptr)\n\tmov\t%r11,8*3($tptr)\n\tmov\t%r12,8*4($tptr)\n\tmov\t%r13,8*5($tptr)\n\tmov\t%r14,8*6($tptr)\n\tmov\t%r15,8*7($tptr)\n\n\tlea\t8*8($tptr,%rcx),$tptr\t# start of current t[] window\n\tcmp\t8+8(%rsp),%r8\t\t# end of t[]?\n\tjb\t.Lsqrx8x_reduction_loop\n\tret\n.size\tbn_sqrx8x_internal,.-bn_sqrx8x_internal\n___\n}\f\n##############################################################\n# Post-condition, 4x unrolled\n#\n{\nmy ($rptr,$nptr)=(\"%rdx\",\"%rbp\");\n$code.=<<___;\n.align\t32\n__bn_postx4x_internal:\n\tmov\t8*0($nptr),%r12\n\tmov\t%rcx,%r10\t\t# -$num\n\tmov\t%rcx,%r9\t\t# -$num\n\tneg\t%rax\n\tsar\t\\$3+2,%rcx\n\t#lea\t48+8(%rsp,%r9),$tptr\n\tmovq\t%xmm1,$rptr\t\t# restore $rptr\n\tmovq\t%xmm1,$aptr\t\t# prepare for back-to-back call\n\tdec\t%r12\t\t\t# so that after 'not' we get -n[0]\n\tmov\t8*1($nptr),%r13\n\txor\t%r8,%r8\n\tmov\t8*2($nptr),%r14\n\tmov\t8*3($nptr),%r15\n\tjmp\t.Lsqrx4x_sub_entry\n\n.align\t16\n.Lsqrx4x_sub:\n\tmov\t8*0($nptr),%r12\n\tmov\t8*1($nptr),%r13\n\tmov\t8*2($nptr),%r14\n\tmov\t8*3($nptr),%r15\n.Lsqrx4x_sub_entry:\n\tandn\t%rax,%r12,%r12\n\tlea\t8*4($nptr),$nptr\n\tandn\t%rax,%r13,%r13\n\tandn\t%rax,%r14,%r14\n\tandn\t%rax,%r15,%r15\n\n\tneg\t%r8\t\t\t# mov %r8,%cf\n\tadc\t8*0($tptr),%r12\n\tadc\t8*1($tptr),%r13\n\tadc\t8*2($tptr),%r14\n\tadc\t8*3($tptr),%r15\n\tmov\t%r12,8*0($rptr)\n\tlea\t8*4($tptr),$tptr\n\tmov\t%r13,8*1($rptr)\n\tsbb\t%r8,%r8\t\t\t# mov %cf,%r8\n\tmov\t%r14,8*2($rptr)\n\tmov\t%r15,8*3($rptr)\n\tlea\t8*4($rptr),$rptr\n\n\tinc\t%rcx\n\tjnz\t.Lsqrx4x_sub\n\n\tneg\t%r9\t\t\t# restore $num\n\n\tret\n.size\t__bn_postx4x_internal,.-__bn_postx4x_internal\n___\n}\n}}}\n{\nmy ($inp,$num,$tbl,$idx)=$win64?(\"%rcx\",\"%edx\",\"%r8\", \"%r9d\") : # Win64 order\n\t\t\t\t(\"%rdi\",\"%esi\",\"%rdx\",\"%ecx\");  # Unix order\nmy $out=$inp;\nmy $STRIDE=2**5*8;\nmy $N=$STRIDE/4;\n\n$code.=<<___;\n.globl\tbn_get_bits5\n.type\tbn_get_bits5,\\@abi-omnipotent\n.align\t16\nbn_get_bits5:\n\tlea\t0($inp),%r10\n\tlea\t1($inp),%r11\n\tmov\t$num,%ecx\n\tshr\t\\$4,$num\n\tand\t\\$15,%ecx\n\tlea\t-8(%ecx),%eax\n\tcmp\t\\$11,%ecx\n\tcmova\t%r11,%r10\n\tcmova\t%eax,%ecx\n\tmovzw\t(%r10,$num,2),%eax\n\tshrl\t%cl,%eax\n\tand\t\\$31,%eax\n\tret\n.size\tbn_get_bits5,.-bn_get_bits5\n\n.globl\tbn_scatter5\n.type\tbn_scatter5,\\@abi-omnipotent\n.align\t16\nbn_scatter5:\n\tcmp\t\\$0, $num\n\tjz\t.Lscatter_epilogue\n\tlea\t($tbl,$idx,8),$tbl\n.Lscatter:\n\tmov\t($inp),%rax\n\tlea\t8($inp),$inp\n\tmov\t%rax,($tbl)\n\tlea\t32*8($tbl),$tbl\n\tsub\t\\$1,$num\n\tjnz\t.Lscatter\n.Lscatter_epilogue:\n\tret\n.size\tbn_scatter5,.-bn_scatter5\n\n.globl\tbn_gather5\n.type\tbn_gather5,\\@abi-omnipotent\n.align\t32\nbn_gather5:\n.LSEH_begin_bn_gather5:\t\t\t# Win64 thing, but harmless in other cases\n\t# I can't trust assembler to use specific encoding:-(\n\t.byte\t0x4c,0x8d,0x14,0x24\t\t\t#lea    (%rsp),%r10\n\t.byte\t0x48,0x81,0xec,0x08,0x01,0x00,0x00\t#sub\t$0x108,%rsp\n\tlea\t.Linc(%rip),%rax\n\tand\t\\$-16,%rsp\t\t# shouldn't be formally required\n\n\tmovd\t$idx,%xmm5\n\tmovdqa\t0(%rax),%xmm0\t\t# 00000001000000010000000000000000\n\tmovdqa\t16(%rax),%xmm1\t\t# 00000002000000020000000200000002\n\tlea\t128($tbl),%r11\t\t# size optimization\n\tlea\t128(%rsp),%rax\t\t# size optimization\n\n\tpshufd\t\\$0,%xmm5,%xmm5\t\t# broadcast $idx\n\tmovdqa\t%xmm1,%xmm4\n\tmovdqa\t%xmm1,%xmm2\n___\n########################################################################\n# calculate mask by comparing 0..31 to $idx and save result to stack\n#\nfor($i=0;$i<$STRIDE/16;$i+=4) {\n$code.=<<___;\n\tpaddd\t%xmm0,%xmm1\n\tpcmpeqd\t%xmm5,%xmm0\t\t# compare to 1,0\n___\n$code.=<<___\tif ($i);\n\tmovdqa\t%xmm3,`16*($i-1)-128`(%rax)\n___\n$code.=<<___;\n\tmovdqa\t%xmm4,%xmm3\n\n\tpaddd\t%xmm1,%xmm2\n\tpcmpeqd\t%xmm5,%xmm1\t\t# compare to 3,2\n\tmovdqa\t%xmm0,`16*($i+0)-128`(%rax)\n\tmovdqa\t%xmm4,%xmm0\n\n\tpaddd\t%xmm2,%xmm3\n\tpcmpeqd\t%xmm5,%xmm2\t\t# compare to 5,4\n\tmovdqa\t%xmm1,`16*($i+1)-128`(%rax)\n\tmovdqa\t%xmm4,%xmm1\n\n\tpaddd\t%xmm3,%xmm0\n\tpcmpeqd\t%xmm5,%xmm3\t\t# compare to 7,6\n\tmovdqa\t%xmm2,`16*($i+2)-128`(%rax)\n\tmovdqa\t%xmm4,%xmm2\n___\n}\n$code.=<<___;\n\tmovdqa\t%xmm3,`16*($i-1)-128`(%rax)\n\tjmp\t.Lgather\n\n.align\t32\n.Lgather:\n\tpxor\t%xmm4,%xmm4\n\tpxor\t%xmm5,%xmm5\n___\nfor($i=0;$i<$STRIDE/16;$i+=4) {\n$code.=<<___;\n\tmovdqa\t`16*($i+0)-128`(%r11),%xmm0\n\tmovdqa\t`16*($i+1)-128`(%r11),%xmm1\n\tmovdqa\t`16*($i+2)-128`(%r11),%xmm2\n\tpand\t`16*($i+0)-128`(%rax),%xmm0\n\tmovdqa\t`16*($i+3)-128`(%r11),%xmm3\n\tpand\t`16*($i+1)-128`(%rax),%xmm1\n\tpor\t%xmm0,%xmm4\n\tpand\t`16*($i+2)-128`(%rax),%xmm2\n\tpor\t%xmm1,%xmm5\n\tpand\t`16*($i+3)-128`(%rax),%xmm3\n\tpor\t%xmm2,%xmm4\n\tpor\t%xmm3,%xmm5\n___\n}\n$code.=<<___;\n\tpor\t%xmm5,%xmm4\n\tlea\t$STRIDE(%r11),%r11\n\tpshufd\t\\$0x4e,%xmm4,%xmm0\n\tpor\t%xmm4,%xmm0\n\tmovq\t%xmm0,($out)\t\t# m0=bp[0]\n\tlea\t8($out),$out\n\tsub\t\\$1,$num\n\tjnz\t.Lgather\n\n\tlea\t(%r10),%rsp\n\tret\n.LSEH_end_bn_gather5:\n.size\tbn_gather5,.-bn_gather5\n___\n}\n$code.=<<___;\n.align\t64\n.Linc:\n\t.long\t0,0, 1,1\n\t.long\t2,2, 2,2\n.asciz\t\"Montgomery Multiplication with scatter/gather for x86_64, CRYPTOGAMS by <appro\\@openssl.org>\"\n___\n\n# EXCEPTION_DISPOSITION handler (EXCEPTION_RECORD *rec,ULONG64 frame,\n#\t\tCONTEXT *context,DISPATCHER_CONTEXT *disp)\nif ($win64) {\n$rec=\"%rcx\";\n$frame=\"%rdx\";\n$context=\"%r8\";\n$disp=\"%r9\";\n\n$code.=<<___;\n.extern\t__imp_RtlVirtualUnwind\n.type\tmul_handler,\\@abi-omnipotent\n.align\t16\nmul_handler:\n\tpush\t%rsi\n\tpush\t%rdi\n\tpush\t%rbx\n\tpush\t%rbp\n\tpush\t%r12\n\tpush\t%r13\n\tpush\t%r14\n\tpush\t%r15\n\tpushfq\n\tsub\t\\$64,%rsp\n\n\tmov\t120($context),%rax\t# pull context->Rax\n\tmov\t248($context),%rbx\t# pull context->Rip\n\n\tmov\t8($disp),%rsi\t\t# disp->ImageBase\n\tmov\t56($disp),%r11\t\t# disp->HandlerData\n\n\tmov\t0(%r11),%r10d\t\t# HandlerData[0]\n\tlea\t(%rsi,%r10),%r10\t# end of prologue label\n\tcmp\t%r10,%rbx\t\t# context->Rip<end of prologue label\n\tjb\t.Lcommon_seh_tail\n\n\tmov\t4(%r11),%r10d\t\t# HandlerData[1]\n\tlea\t(%rsi,%r10),%r10\t# epilogue label\n\tcmp\t%r10,%rbx\t\t# context->Rip>=epilogue label\n\tjb\t.Lcommon_pop_regs\n\n\tmov\t152($context),%rax\t# pull context->Rsp\n\n\tmov\t8(%r11),%r10d\t\t# HandlerData[2]\n\tlea\t(%rsi,%r10),%r10\t# epilogue label\n\tcmp\t%r10,%rbx\t\t# context->Rip>=epilogue label\n\tjae\t.Lcommon_seh_tail\n\n\tlea\t.Lmul_epilogue(%rip),%r10\n\tcmp\t%r10,%rbx\n\tja\t.Lbody_40\n\n\tmov\t192($context),%r10\t# pull $num\n\tmov\t8(%rax,%r10,8),%rax\t# pull saved stack pointer\n\n\tjmp\t.Lcommon_pop_regs\n\n.Lbody_40:\n\tmov\t40(%rax),%rax\t\t# pull saved stack pointer\n.Lcommon_pop_regs:\n\tmov\t-8(%rax),%rbx\n\tmov\t-16(%rax),%rbp\n\tmov\t-24(%rax),%r12\n\tmov\t-32(%rax),%r13\n\tmov\t-40(%rax),%r14\n\tmov\t-48(%rax),%r15\n\tmov\t%rbx,144($context)\t# restore context->Rbx\n\tmov\t%rbp,160($context)\t# restore context->Rbp\n\tmov\t%r12,216($context)\t# restore context->R12\n\tmov\t%r13,224($context)\t# restore context->R13\n\tmov\t%r14,232($context)\t# restore context->R14\n\tmov\t%r15,240($context)\t# restore context->R15\n\n.Lcommon_seh_tail:\n\tmov\t8(%rax),%rdi\n\tmov\t16(%rax),%rsi\n\tmov\t%rax,152($context)\t# restore context->Rsp\n\tmov\t%rsi,168($context)\t# restore context->Rsi\n\tmov\t%rdi,176($context)\t# restore context->Rdi\n\n\tmov\t40($disp),%rdi\t\t# disp->ContextRecord\n\tmov\t$context,%rsi\t\t# context\n\tmov\t\\$154,%ecx\t\t# sizeof(CONTEXT)\n\t.long\t0xa548f3fc\t\t# cld; rep movsq\n\n\tmov\t$disp,%rsi\n\txor\t%rcx,%rcx\t\t# arg1, UNW_FLAG_NHANDLER\n\tmov\t8(%rsi),%rdx\t\t# arg2, disp->ImageBase\n\tmov\t0(%rsi),%r8\t\t# arg3, disp->ControlPc\n\tmov\t16(%rsi),%r9\t\t# arg4, disp->FunctionEntry\n\tmov\t40(%rsi),%r10\t\t# disp->ContextRecord\n\tlea\t56(%rsi),%r11\t\t# &disp->HandlerData\n\tlea\t24(%rsi),%r12\t\t# &disp->EstablisherFrame\n\tmov\t%r10,32(%rsp)\t\t# arg5\n\tmov\t%r11,40(%rsp)\t\t# arg6\n\tmov\t%r12,48(%rsp)\t\t# arg7\n\tmov\t%rcx,56(%rsp)\t\t# arg8, (NULL)\n\tcall\t*__imp_RtlVirtualUnwind(%rip)\n\n\tmov\t\\$1,%eax\t\t# ExceptionContinueSearch\n\tadd\t\\$64,%rsp\n\tpopfq\n\tpop\t%r15\n\tpop\t%r14\n\tpop\t%r13\n\tpop\t%r12\n\tpop\t%rbp\n\tpop\t%rbx\n\tpop\t%rdi\n\tpop\t%rsi\n\tret\n.size\tmul_handler,.-mul_handler\n\n.section\t.pdata\n.align\t4\n\t.rva\t.LSEH_begin_bn_mul_mont_gather5\n\t.rva\t.LSEH_end_bn_mul_mont_gather5\n\t.rva\t.LSEH_info_bn_mul_mont_gather5\n\n\t.rva\t.LSEH_begin_bn_mul4x_mont_gather5\n\t.rva\t.LSEH_end_bn_mul4x_mont_gather5\n\t.rva\t.LSEH_info_bn_mul4x_mont_gather5\n\n\t.rva\t.LSEH_begin_bn_power5\n\t.rva\t.LSEH_end_bn_power5\n\t.rva\t.LSEH_info_bn_power5\n\n\t.rva\t.LSEH_begin_bn_from_mont8x\n\t.rva\t.LSEH_end_bn_from_mont8x\n\t.rva\t.LSEH_info_bn_from_mont8x\n___\n$code.=<<___ if ($addx);\n\t.rva\t.LSEH_begin_bn_mulx4x_mont_gather5\n\t.rva\t.LSEH_end_bn_mulx4x_mont_gather5\n\t.rva\t.LSEH_info_bn_mulx4x_mont_gather5\n\n\t.rva\t.LSEH_begin_bn_powerx5\n\t.rva\t.LSEH_end_bn_powerx5\n\t.rva\t.LSEH_info_bn_powerx5\n___\n$code.=<<___;\n\t.rva\t.LSEH_begin_bn_gather5\n\t.rva\t.LSEH_end_bn_gather5\n\t.rva\t.LSEH_info_bn_gather5\n\n.section\t.xdata\n.align\t8\n.LSEH_info_bn_mul_mont_gather5:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lmul_body,.Lmul_body,.Lmul_epilogue\t\t# HandlerData[]\n.align\t8\n.LSEH_info_bn_mul4x_mont_gather5:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lmul4x_prologue,.Lmul4x_body,.Lmul4x_epilogue\t\t# HandlerData[]\n.align\t8\n.LSEH_info_bn_power5:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lpower5_prologue,.Lpower5_body,.Lpower5_epilogue\t# HandlerData[]\n.align\t8\n.LSEH_info_bn_from_mont8x:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lfrom_prologue,.Lfrom_body,.Lfrom_epilogue\t\t# HandlerData[]\n___\n$code.=<<___ if ($addx);\n.align\t8\n.LSEH_info_bn_mulx4x_mont_gather5:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lmulx4x_prologue,.Lmulx4x_body,.Lmulx4x_epilogue\t# HandlerData[]\n.align\t8\n.LSEH_info_bn_powerx5:\n\t.byte\t9,0,0,0\n\t.rva\tmul_handler\n\t.rva\t.Lpowerx5_prologue,.Lpowerx5_body,.Lpowerx5_epilogue\t# HandlerData[]\n___\n$code.=<<___;\n.align\t8\n.LSEH_info_bn_gather5:\n\t.byte\t0x01,0x0b,0x03,0x0a\n\t.byte\t0x0b,0x01,0x21,0x00\t# sub\trsp,0x108\n\t.byte\t0x04,0xa3,0x00,0x00\t# lea\tr10,(rsp)\n.align\t8\n___\n}\n\n$code =~ s/\\`([^\\`]*)\\`/eval($1)/gem;\n\nprint $code;\nclose STDOUT;\n"], "filenames": ["crypto/bn/asm/x86_64-mont5.pl"], "buggy_code_start_loc": [1938], "buggy_code_end_loc": [3420], "fixing_code_start_loc": [1939], "fixing_code_end_loc": [3418], "type": "CWE-200", "message": "There is a carry propagating bug in the x86_64 Montgomery squaring procedure in OpenSSL 1.0.2 before 1.0.2k and 1.1.0 before 1.1.0d. No EC algorithms are affected. Analysis suggests that attacks against RSA and DSA as a result of this defect would be very difficult to perform and are not believed likely. Attacks against DH are considered just feasible (although very difficult) because most of the work necessary to deduce information about a private key may be performed offline. The amount of resources required for such an attack would be very significant and likely only accessible to a limited number of attackers. An attacker would additionally need online access to an unpatched system using the target private key in a scenario with persistent DH parameters and a private key that is shared between multiple clients. For example this can occur by default in OpenSSL DHE based SSL/TLS ciphersuites. Note: This issue is very similar to CVE-2015-3193 but must be treated as a separate problem.", "other": {"cve": {"id": "CVE-2017-3732", "sourceIdentifier": "openssl-security@openssl.org", "published": "2017-05-04T19:29:00.400", "lastModified": "2022-08-29T20:43:33.220", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "There is a carry propagating bug in the x86_64 Montgomery squaring procedure in OpenSSL 1.0.2 before 1.0.2k and 1.1.0 before 1.1.0d. No EC algorithms are affected. Analysis suggests that attacks against RSA and DSA as a result of this defect would be very difficult to perform and are not believed likely. Attacks against DH are considered just feasible (although very difficult) because most of the work necessary to deduce information about a private key may be performed offline. The amount of resources required for such an attack would be very significant and likely only accessible to a limited number of attackers. An attacker would additionally need online access to an unpatched system using the target private key in a scenario with persistent DH parameters and a private key that is shared between multiple clients. For example this can occur by default in OpenSSL DHE based SSL/TLS ciphersuites. Note: This issue is very similar to CVE-2015-3193 but must be treated as a separate problem."}, {"lang": "es", "value": "Hay un error de propagaci\u00f3n de d\u00edgito (carry propagation) en el procedimiento de elevaci\u00f3n al cuadrado de Montgomery x86_64 en OpenSSL versiones 1.0.2 anteriores a la 1.0.2k y versiones 1.1.0 anteriores a la 1.1.0d. Ning\u00fan algoritmo de curva el\u00edptica (EC) se ve afectado. El an\u00e1lisis sugiere que los ataques contra RSA y DSA que se realizan como resultado de este defecto ser\u00edan muy dif\u00edciles de realizar y no muy probables. Los ataques contra DH se consideran factibles (aunque muy dif\u00edciles) ya que la mayor\u00eda del trabajo necesario para deducir informaci\u00f3n sobre una clave privada se puede realizar sin conexi\u00f3n La cantidad de recursos requeridos para este tipo de ataque ser\u00eda muy significativa y, probablemente, solo estar\u00eda accesible para un n\u00famero limitado de atacantes. Un atacante podr\u00eda necesitar, adem\u00e1s, acceso a un sistema sin parches que utilice la clave privada del objetivo en un escenario con par\u00e1metros DH persistentes y una clave privada que se comparte entre m\u00faltiples clientes. Por ejemplo, esto puede ocurrir por defecto en las suites de cifrado SSL/TLS basadas en DHE de OpenSSL. Nota: Este problema es muy similar a CVE-2015-3193, pero debe tratarse como un problema separado."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-200"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2:*:*:*:*:*:*:*", "matchCriteriaId": "AD3E5C1B-EC63-4214-A0BD-0B8681CE6C8B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2:beta1:*:*:*:*:*:*", "matchCriteriaId": "18797BEE-417D-4959-9AAD-C5A7C051B524"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2:beta2:*:*:*:*:*:*", "matchCriteriaId": "6FAA3C31-BD9D-45A9-A502-837FECA6D479"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2:beta3:*:*:*:*:*:*", "matchCriteriaId": "6455A421-9956-4846-AC7C-3431E0D37D23"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2a:*:*:*:*:*:*:*", "matchCriteriaId": "60F946FD-F564-49DA-B043-5943308BA9EE"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2b:*:*:*:*:*:*:*", "matchCriteriaId": "4847BCF3-EFCE-41AF-8E7D-3D51EB9DCC5B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2c:*:*:*:*:*:*:*", "matchCriteriaId": "9B89180B-FB68-4DD8-B076-16E51CC7FB91"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2d:*:*:*:*:*:*:*", "matchCriteriaId": "4C986592-4086-4A39-9767-EF34DBAA6A53"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2e:*:*:*:*:*:*:*", "matchCriteriaId": "7B23181C-03DB-4E92-B3F6-6B585B5231B4"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2f:*:*:*:*:*:*:*", "matchCriteriaId": "94D9EC1C-4843-4026-9B05-E060E9391734"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2h:*:*:*:*:*:*:*", "matchCriteriaId": "036FB24F-7D86-4730-8BC9-722875BEC807"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.0.2i:*:*:*:*:*:*:*", "matchCriteriaId": "FDF148A3-1AA7-4F27-85AB-414C609C626F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.1.0a:*:*:*:*:*:*:*", "matchCriteriaId": "C9D7A18A-116B-4F68-BEA3-A4E9DDDA55C6"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.1.0b:*:*:*:*:*:*:*", "matchCriteriaId": "CFC70262-0DCD-4B46-9C96-FD18D0207511"}, {"vulnerable": true, "criteria": "cpe:2.3:a:openssl:openssl:1.1.0c:*:*:*:*:*:*:*", "matchCriteriaId": "B2E07A34-08A0-4765-AF81-46A3BDC5648A"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:nodejs:node.js:*:*:*:*:-:*:*:*", "versionStartIncluding": "4.0.0", "versionEndIncluding": "4.1.2", "matchCriteriaId": "A47FC4F7-1F77-4314-B4B3-3C5D8E335379"}, {"vulnerable": true, "criteria": "cpe:2.3:a:nodejs:node.js:*:*:*:*:lts:*:*:*", "versionStartIncluding": "4.2.0", "versionEndExcluding": "4.7.3", "matchCriteriaId": "934083EB-2961-49FF-B8D7-B870D1FA3CB8"}, {"vulnerable": true, "criteria": "cpe:2.3:a:nodejs:node.js:*:*:*:*:-:*:*:*", "versionStartIncluding": "5.0.0", "versionEndIncluding": "5.12.0", "matchCriteriaId": "121E5D5D-B4D9-43F3-B5C9-74590192FAF1"}, {"vulnerable": true, "criteria": "cpe:2.3:a:nodejs:node.js:*:*:*:*:-:*:*:*", "versionStartIncluding": "6.0.0", "versionEndIncluding": "6.8.1", "matchCriteriaId": "D107EC29-67E7-40C3-8E5A-324C9105C5E4"}, {"vulnerable": true, "criteria": "cpe:2.3:a:nodejs:node.js:*:*:*:*:lts:*:*:*", "versionStartIncluding": "6.9.0", "versionEndExcluding": "6.9.5", "matchCriteriaId": "14346EBC-1890-472B-B236-06FE381229EC"}, {"vulnerable": true, "criteria": "cpe:2.3:a:nodejs:node.js:*:*:*:*:-:*:*:*", "versionStartIncluding": "7.0.0", "versionEndExcluding": "7.5.0", "matchCriteriaId": "2EE58CC5-2E12-4DA9-8AF2-9739CE393008"}]}]}], "references": [{"url": "http://www.oracle.com/technetwork/security-advisory/cpujan2018-3236628.html", "source": "openssl-security@openssl.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "http://www.oracle.com/technetwork/security-advisory/cpujul2017-3236622.html", "source": "openssl-security@openssl.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "http://www.oracle.com/technetwork/security-advisory/cpuoct2017-3236626.html", "source": "openssl-security@openssl.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/95814", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.securitytracker.com/id/1037717", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2185", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2186", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2187", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2568", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2575", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2713", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/openssl/openssl/commit/a59b90bf491410f1f2bc4540cc21f1980fd14c5b", "source": "openssl-security@openssl.org", "tags": ["Patch"]}, {"url": "https://security.FreeBSD.org/advisories/FreeBSD-SA-17:02.openssl.asc", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory"]}, {"url": "https://security.gentoo.org/glsa/201702-07", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory"]}, {"url": "https://support.hpe.com/hpsc/doc/public/display?docLocale=en_US&docId=emr_na-hpesbhf03838en_us", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.openssl.org/news/secadv/20170126.txt", "source": "openssl-security@openssl.org", "tags": ["Vendor Advisory"]}, {"url": "https://www.oracle.com/technetwork/security-advisory/cpuapr2019-5072813.html", "source": "openssl-security@openssl.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://www.tenable.com/security/tns-2017-04", "source": "openssl-security@openssl.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/openssl/openssl/commit/a59b90bf491410f1f2bc4540cc21f1980fd14c5b"}}
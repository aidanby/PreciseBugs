{"buggy_code": ["/*\n * QEMU e1000 emulation\n *\n * Software developer's manual:\n * http://download.intel.com/design/network/manuals/8254x_GBe_SDM.pdf\n *\n * Nir Peleg, Tutis Systems Ltd. for Qumranet Inc.\n * Copyright (c) 2008 Qumranet\n * Based on work done by:\n * Copyright (c) 2007 Dan Aloni\n * Copyright (c) 2004 Antony T Curtis\n *\n * This library is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * This library is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this library; if not, see <http://www.gnu.org/licenses/>.\n */\n\n\n#include \"qemu/osdep.h\"\n#include \"hw/pci/pci.h\"\n#include \"hw/qdev-properties.h\"\n#include \"migration/vmstate.h\"\n#include \"net/net.h\"\n#include \"net/checksum.h\"\n#include \"sysemu/sysemu.h\"\n#include \"sysemu/dma.h\"\n#include \"qemu/iov.h\"\n#include \"qemu/module.h\"\n#include \"qemu/range.h\"\n\n#include \"e1000x_common.h\"\n#include \"trace.h\"\n#include \"qom/object.h\"\n\nstatic const uint8_t bcast[] = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff};\n\n/* #define E1000_DEBUG */\n\n#ifdef E1000_DEBUG\nenum {\n    DEBUG_GENERAL,      DEBUG_IO,       DEBUG_MMIO,     DEBUG_INTERRUPT,\n    DEBUG_RX,           DEBUG_TX,       DEBUG_MDIC,     DEBUG_EEPROM,\n    DEBUG_UNKNOWN,      DEBUG_TXSUM,    DEBUG_TXERR,    DEBUG_RXERR,\n    DEBUG_RXFILTER,     DEBUG_PHY,      DEBUG_NOTYET,\n};\n#define DBGBIT(x)    (1<<DEBUG_##x)\nstatic int debugflags = DBGBIT(TXERR) | DBGBIT(GENERAL);\n\n#define DBGOUT(what, fmt, ...) do { \\\n    if (debugflags & DBGBIT(what)) \\\n        fprintf(stderr, \"e1000: \" fmt, ## __VA_ARGS__); \\\n    } while (0)\n#else\n#define DBGOUT(what, fmt, ...) do {} while (0)\n#endif\n\n#define IOPORT_SIZE       0x40\n#define PNPMMIO_SIZE      0x20000\n#define MIN_BUF_SIZE      60 /* Min. octets in an ethernet frame sans FCS */\n\n#define MAXIMUM_ETHERNET_HDR_LEN (14+4)\n\n/*\n * HW models:\n *  E1000_DEV_ID_82540EM works with Windows, Linux, and OS X <= 10.8\n *  E1000_DEV_ID_82544GC_COPPER appears to work; not well tested\n *  E1000_DEV_ID_82545EM_COPPER works with Linux and OS X >= 10.6\n *  Others never tested\n */\n\nstruct E1000State_st {\n    /*< private >*/\n    PCIDevice parent_obj;\n    /*< public >*/\n\n    NICState *nic;\n    NICConf conf;\n    MemoryRegion mmio;\n    MemoryRegion io;\n\n    uint32_t mac_reg[0x8000];\n    uint16_t phy_reg[0x20];\n    uint16_t eeprom_data[64];\n\n    uint32_t rxbuf_size;\n    uint32_t rxbuf_min_shift;\n    struct e1000_tx {\n        unsigned char header[256];\n        unsigned char vlan_header[4];\n        /* Fields vlan and data must not be reordered or separated. */\n        unsigned char vlan[4];\n        unsigned char data[0x10000];\n        uint16_t size;\n        unsigned char vlan_needed;\n        unsigned char sum_needed;\n        bool cptse;\n        e1000x_txd_props props;\n        e1000x_txd_props tso_props;\n        uint16_t tso_frames;\n    } tx;\n\n    struct {\n        uint32_t val_in;    /* shifted in from guest driver */\n        uint16_t bitnum_in;\n        uint16_t bitnum_out;\n        uint16_t reading;\n        uint32_t old_eecd;\n    } eecd_state;\n\n    QEMUTimer *autoneg_timer;\n\n    QEMUTimer *mit_timer;      /* Mitigation timer. */\n    bool mit_timer_on;         /* Mitigation timer is running. */\n    bool mit_irq_level;        /* Tracks interrupt pin level. */\n    uint32_t mit_ide;          /* Tracks E1000_TXD_CMD_IDE bit. */\n\n    QEMUTimer *flush_queue_timer;\n\n/* Compatibility flags for migration to/from qemu 1.3.0 and older */\n#define E1000_FLAG_AUTONEG_BIT 0\n#define E1000_FLAG_MIT_BIT 1\n#define E1000_FLAG_MAC_BIT 2\n#define E1000_FLAG_TSO_BIT 3\n#define E1000_FLAG_AUTONEG (1 << E1000_FLAG_AUTONEG_BIT)\n#define E1000_FLAG_MIT (1 << E1000_FLAG_MIT_BIT)\n#define E1000_FLAG_MAC (1 << E1000_FLAG_MAC_BIT)\n#define E1000_FLAG_TSO (1 << E1000_FLAG_TSO_BIT)\n    uint32_t compat_flags;\n    bool received_tx_tso;\n    bool use_tso_for_migration;\n    e1000x_txd_props mig_props;\n};\ntypedef struct E1000State_st E1000State;\n\n#define chkflag(x)     (s->compat_flags & E1000_FLAG_##x)\n\nstruct E1000BaseClass {\n    PCIDeviceClass parent_class;\n    uint16_t phy_id2;\n};\ntypedef struct E1000BaseClass E1000BaseClass;\n\n#define TYPE_E1000_BASE \"e1000-base\"\n\nDECLARE_OBJ_CHECKERS(E1000State, E1000BaseClass,\n                     E1000, TYPE_E1000_BASE)\n\n\nstatic void\ne1000_link_up(E1000State *s)\n{\n    e1000x_update_regs_on_link_up(s->mac_reg, s->phy_reg);\n\n    /* E1000_STATUS_LU is tested by e1000_can_receive() */\n    qemu_flush_queued_packets(qemu_get_queue(s->nic));\n}\n\nstatic void\ne1000_autoneg_done(E1000State *s)\n{\n    e1000x_update_regs_on_autoneg_done(s->mac_reg, s->phy_reg);\n\n    /* E1000_STATUS_LU is tested by e1000_can_receive() */\n    qemu_flush_queued_packets(qemu_get_queue(s->nic));\n}\n\nstatic bool\nhave_autoneg(E1000State *s)\n{\n    return chkflag(AUTONEG) && (s->phy_reg[PHY_CTRL] & MII_CR_AUTO_NEG_EN);\n}\n\nstatic void\nset_phy_ctrl(E1000State *s, int index, uint16_t val)\n{\n    /* bits 0-5 reserved; MII_CR_[RESTART_AUTO_NEG,RESET] are self clearing */\n    s->phy_reg[PHY_CTRL] = val & ~(0x3f |\n                                   MII_CR_RESET |\n                                   MII_CR_RESTART_AUTO_NEG);\n\n    /*\n     * QEMU 1.3 does not support link auto-negotiation emulation, so if we\n     * migrate during auto negotiation, after migration the link will be\n     * down.\n     */\n    if (have_autoneg(s) && (val & MII_CR_RESTART_AUTO_NEG)) {\n        e1000x_restart_autoneg(s->mac_reg, s->phy_reg, s->autoneg_timer);\n    }\n}\n\nstatic void (*phyreg_writeops[])(E1000State *, int, uint16_t) = {\n    [PHY_CTRL] = set_phy_ctrl,\n};\n\nenum { NPHYWRITEOPS = ARRAY_SIZE(phyreg_writeops) };\n\nenum { PHY_R = 1, PHY_W = 2, PHY_RW = PHY_R | PHY_W };\nstatic const char phy_regcap[0x20] = {\n    [PHY_STATUS]      = PHY_R,     [M88E1000_EXT_PHY_SPEC_CTRL] = PHY_RW,\n    [PHY_ID1]         = PHY_R,     [M88E1000_PHY_SPEC_CTRL]     = PHY_RW,\n    [PHY_CTRL]        = PHY_RW,    [PHY_1000T_CTRL]             = PHY_RW,\n    [PHY_LP_ABILITY]  = PHY_R,     [PHY_1000T_STATUS]           = PHY_R,\n    [PHY_AUTONEG_ADV] = PHY_RW,    [M88E1000_RX_ERR_CNTR]       = PHY_R,\n    [PHY_ID2]         = PHY_R,     [M88E1000_PHY_SPEC_STATUS]   = PHY_R,\n    [PHY_AUTONEG_EXP] = PHY_R,\n};\n\n/* PHY_ID2 documented in 8254x_GBe_SDM.pdf, pp. 250 */\nstatic const uint16_t phy_reg_init[] = {\n    [PHY_CTRL]   = MII_CR_SPEED_SELECT_MSB |\n                   MII_CR_FULL_DUPLEX |\n                   MII_CR_AUTO_NEG_EN,\n\n    [PHY_STATUS] = MII_SR_EXTENDED_CAPS |\n                   MII_SR_LINK_STATUS |   /* link initially up */\n                   MII_SR_AUTONEG_CAPS |\n                   /* MII_SR_AUTONEG_COMPLETE: initially NOT completed */\n                   MII_SR_PREAMBLE_SUPPRESS |\n                   MII_SR_EXTENDED_STATUS |\n                   MII_SR_10T_HD_CAPS |\n                   MII_SR_10T_FD_CAPS |\n                   MII_SR_100X_HD_CAPS |\n                   MII_SR_100X_FD_CAPS,\n\n    [PHY_ID1] = 0x141,\n    /* [PHY_ID2] configured per DevId, from e1000_reset() */\n    [PHY_AUTONEG_ADV] = 0xde1,\n    [PHY_LP_ABILITY] = 0x1e0,\n    [PHY_1000T_CTRL] = 0x0e00,\n    [PHY_1000T_STATUS] = 0x3c00,\n    [M88E1000_PHY_SPEC_CTRL] = 0x360,\n    [M88E1000_PHY_SPEC_STATUS] = 0xac00,\n    [M88E1000_EXT_PHY_SPEC_CTRL] = 0x0d60,\n};\n\nstatic const uint32_t mac_reg_init[] = {\n    [PBA]     = 0x00100030,\n    [LEDCTL]  = 0x602,\n    [CTRL]    = E1000_CTRL_SWDPIN2 | E1000_CTRL_SWDPIN0 |\n                E1000_CTRL_SPD_1000 | E1000_CTRL_SLU,\n    [STATUS]  = 0x80000000 | E1000_STATUS_GIO_MASTER_ENABLE |\n                E1000_STATUS_ASDV | E1000_STATUS_MTXCKOK |\n                E1000_STATUS_SPEED_1000 | E1000_STATUS_FD |\n                E1000_STATUS_LU,\n    [MANC]    = E1000_MANC_EN_MNG2HOST | E1000_MANC_RCV_TCO_EN |\n                E1000_MANC_ARP_EN | E1000_MANC_0298_EN |\n                E1000_MANC_RMCP_EN,\n};\n\n/* Helper function, *curr == 0 means the value is not set */\nstatic inline void\nmit_update_delay(uint32_t *curr, uint32_t value)\n{\n    if (value && (*curr == 0 || value < *curr)) {\n        *curr = value;\n    }\n}\n\nstatic void\nset_interrupt_cause(E1000State *s, int index, uint32_t val)\n{\n    PCIDevice *d = PCI_DEVICE(s);\n    uint32_t pending_ints;\n    uint32_t mit_delay;\n\n    s->mac_reg[ICR] = val;\n\n    /*\n     * Make sure ICR and ICS registers have the same value.\n     * The spec says that the ICS register is write-only.  However in practice,\n     * on real hardware ICS is readable, and for reads it has the same value as\n     * ICR (except that ICS does not have the clear on read behaviour of ICR).\n     *\n     * The VxWorks PRO/1000 driver uses this behaviour.\n     */\n    s->mac_reg[ICS] = val;\n\n    pending_ints = (s->mac_reg[IMS] & s->mac_reg[ICR]);\n    if (!s->mit_irq_level && pending_ints) {\n        /*\n         * Here we detect a potential raising edge. We postpone raising the\n         * interrupt line if we are inside the mitigation delay window\n         * (s->mit_timer_on == 1).\n         * We provide a partial implementation of interrupt mitigation,\n         * emulating only RADV, TADV and ITR (lower 16 bits, 1024ns units for\n         * RADV and TADV, 256ns units for ITR). RDTR is only used to enable\n         * RADV; relative timers based on TIDV and RDTR are not implemented.\n         */\n        if (s->mit_timer_on) {\n            return;\n        }\n        if (chkflag(MIT)) {\n            /* Compute the next mitigation delay according to pending\n             * interrupts and the current values of RADV (provided\n             * RDTR!=0), TADV and ITR.\n             * Then rearm the timer.\n             */\n            mit_delay = 0;\n            if (s->mit_ide &&\n                    (pending_ints & (E1000_ICR_TXQE | E1000_ICR_TXDW))) {\n                mit_update_delay(&mit_delay, s->mac_reg[TADV] * 4);\n            }\n            if (s->mac_reg[RDTR] && (pending_ints & E1000_ICS_RXT0)) {\n                mit_update_delay(&mit_delay, s->mac_reg[RADV] * 4);\n            }\n            mit_update_delay(&mit_delay, s->mac_reg[ITR]);\n\n            /*\n             * According to e1000 SPEC, the Ethernet controller guarantees\n             * a maximum observable interrupt rate of 7813 interrupts/sec.\n             * Thus if mit_delay < 500 then the delay should be set to the\n             * minimum delay possible which is 500.\n             */\n            mit_delay = (mit_delay < 500) ? 500 : mit_delay;\n\n            s->mit_timer_on = 1;\n            timer_mod(s->mit_timer, qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL) +\n                      mit_delay * 256);\n            s->mit_ide = 0;\n        }\n    }\n\n    s->mit_irq_level = (pending_ints != 0);\n    pci_set_irq(d, s->mit_irq_level);\n}\n\nstatic void\ne1000_mit_timer(void *opaque)\n{\n    E1000State *s = opaque;\n\n    s->mit_timer_on = 0;\n    /* Call set_interrupt_cause to update the irq level (if necessary). */\n    set_interrupt_cause(s, 0, s->mac_reg[ICR]);\n}\n\nstatic void\nset_ics(E1000State *s, int index, uint32_t val)\n{\n    DBGOUT(INTERRUPT, \"set_ics %x, ICR %x, IMR %x\\n\", val, s->mac_reg[ICR],\n        s->mac_reg[IMS]);\n    set_interrupt_cause(s, 0, val | s->mac_reg[ICR]);\n}\n\nstatic void\ne1000_autoneg_timer(void *opaque)\n{\n    E1000State *s = opaque;\n    if (!qemu_get_queue(s->nic)->link_down) {\n        e1000_autoneg_done(s);\n        set_ics(s, 0, E1000_ICS_LSC); /* signal link status change to guest */\n    }\n}\n\nstatic void e1000_reset(void *opaque)\n{\n    E1000State *d = opaque;\n    E1000BaseClass *edc = E1000_GET_CLASS(d);\n    uint8_t *macaddr = d->conf.macaddr.a;\n\n    timer_del(d->autoneg_timer);\n    timer_del(d->mit_timer);\n    timer_del(d->flush_queue_timer);\n    d->mit_timer_on = 0;\n    d->mit_irq_level = 0;\n    d->mit_ide = 0;\n    memset(d->phy_reg, 0, sizeof d->phy_reg);\n    memmove(d->phy_reg, phy_reg_init, sizeof phy_reg_init);\n    d->phy_reg[PHY_ID2] = edc->phy_id2;\n    memset(d->mac_reg, 0, sizeof d->mac_reg);\n    memmove(d->mac_reg, mac_reg_init, sizeof mac_reg_init);\n    d->rxbuf_min_shift = 1;\n    memset(&d->tx, 0, sizeof d->tx);\n\n    if (qemu_get_queue(d->nic)->link_down) {\n        e1000x_update_regs_on_link_down(d->mac_reg, d->phy_reg);\n    }\n\n    e1000x_reset_mac_addr(d->nic, d->mac_reg, macaddr);\n}\n\nstatic void\nset_ctrl(E1000State *s, int index, uint32_t val)\n{\n    /* RST is self clearing */\n    s->mac_reg[CTRL] = val & ~E1000_CTRL_RST;\n}\n\nstatic void\ne1000_flush_queue_timer(void *opaque)\n{\n    E1000State *s = opaque;\n\n    qemu_flush_queued_packets(qemu_get_queue(s->nic));\n}\n\nstatic void\nset_rx_control(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[RCTL] = val;\n    s->rxbuf_size = e1000x_rxbufsize(val);\n    s->rxbuf_min_shift = ((val / E1000_RCTL_RDMTS_QUAT) & 3) + 1;\n    DBGOUT(RX, \"RCTL: %d, mac_reg[RCTL] = 0x%x\\n\", s->mac_reg[RDT],\n           s->mac_reg[RCTL]);\n    timer_mod(s->flush_queue_timer,\n              qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL) + 1000);\n}\n\nstatic void\nset_mdic(E1000State *s, int index, uint32_t val)\n{\n    uint32_t data = val & E1000_MDIC_DATA_MASK;\n    uint32_t addr = ((val & E1000_MDIC_REG_MASK) >> E1000_MDIC_REG_SHIFT);\n\n    if ((val & E1000_MDIC_PHY_MASK) >> E1000_MDIC_PHY_SHIFT != 1) // phy #\n        val = s->mac_reg[MDIC] | E1000_MDIC_ERROR;\n    else if (val & E1000_MDIC_OP_READ) {\n        DBGOUT(MDIC, \"MDIC read reg 0x%x\\n\", addr);\n        if (!(phy_regcap[addr] & PHY_R)) {\n            DBGOUT(MDIC, \"MDIC read reg %x unhandled\\n\", addr);\n            val |= E1000_MDIC_ERROR;\n        } else\n            val = (val ^ data) | s->phy_reg[addr];\n    } else if (val & E1000_MDIC_OP_WRITE) {\n        DBGOUT(MDIC, \"MDIC write reg 0x%x, value 0x%x\\n\", addr, data);\n        if (!(phy_regcap[addr] & PHY_W)) {\n            DBGOUT(MDIC, \"MDIC write reg %x unhandled\\n\", addr);\n            val |= E1000_MDIC_ERROR;\n        } else {\n            if (addr < NPHYWRITEOPS && phyreg_writeops[addr]) {\n                phyreg_writeops[addr](s, index, data);\n            } else {\n                s->phy_reg[addr] = data;\n            }\n        }\n    }\n    s->mac_reg[MDIC] = val | E1000_MDIC_READY;\n\n    if (val & E1000_MDIC_INT_EN) {\n        set_ics(s, 0, E1000_ICR_MDAC);\n    }\n}\n\nstatic uint32_t\nget_eecd(E1000State *s, int index)\n{\n    uint32_t ret = E1000_EECD_PRES|E1000_EECD_GNT | s->eecd_state.old_eecd;\n\n    DBGOUT(EEPROM, \"reading eeprom bit %d (reading %d)\\n\",\n           s->eecd_state.bitnum_out, s->eecd_state.reading);\n    if (!s->eecd_state.reading ||\n        ((s->eeprom_data[(s->eecd_state.bitnum_out >> 4) & 0x3f] >>\n          ((s->eecd_state.bitnum_out & 0xf) ^ 0xf))) & 1)\n        ret |= E1000_EECD_DO;\n    return ret;\n}\n\nstatic void\nset_eecd(E1000State *s, int index, uint32_t val)\n{\n    uint32_t oldval = s->eecd_state.old_eecd;\n\n    s->eecd_state.old_eecd = val & (E1000_EECD_SK | E1000_EECD_CS |\n            E1000_EECD_DI|E1000_EECD_FWE_MASK|E1000_EECD_REQ);\n    if (!(E1000_EECD_CS & val)) {            /* CS inactive; nothing to do */\n        return;\n    }\n    if (E1000_EECD_CS & (val ^ oldval)) {    /* CS rise edge; reset state */\n        s->eecd_state.val_in = 0;\n        s->eecd_state.bitnum_in = 0;\n        s->eecd_state.bitnum_out = 0;\n        s->eecd_state.reading = 0;\n    }\n    if (!(E1000_EECD_SK & (val ^ oldval))) {    /* no clock edge */\n        return;\n    }\n    if (!(E1000_EECD_SK & val)) {               /* falling edge */\n        s->eecd_state.bitnum_out++;\n        return;\n    }\n    s->eecd_state.val_in <<= 1;\n    if (val & E1000_EECD_DI)\n        s->eecd_state.val_in |= 1;\n    if (++s->eecd_state.bitnum_in == 9 && !s->eecd_state.reading) {\n        s->eecd_state.bitnum_out = ((s->eecd_state.val_in & 0x3f)<<4)-1;\n        s->eecd_state.reading = (((s->eecd_state.val_in >> 6) & 7) ==\n            EEPROM_READ_OPCODE_MICROWIRE);\n    }\n    DBGOUT(EEPROM, \"eeprom bitnum in %d out %d, reading %d\\n\",\n           s->eecd_state.bitnum_in, s->eecd_state.bitnum_out,\n           s->eecd_state.reading);\n}\n\nstatic uint32_t\nflash_eerd_read(E1000State *s, int x)\n{\n    unsigned int index, r = s->mac_reg[EERD] & ~E1000_EEPROM_RW_REG_START;\n\n    if ((s->mac_reg[EERD] & E1000_EEPROM_RW_REG_START) == 0)\n        return (s->mac_reg[EERD]);\n\n    if ((index = r >> E1000_EEPROM_RW_ADDR_SHIFT) > EEPROM_CHECKSUM_REG)\n        return (E1000_EEPROM_RW_REG_DONE | r);\n\n    return ((s->eeprom_data[index] << E1000_EEPROM_RW_REG_DATA) |\n           E1000_EEPROM_RW_REG_DONE | r);\n}\n\nstatic void\nputsum(uint8_t *data, uint32_t n, uint32_t sloc, uint32_t css, uint32_t cse)\n{\n    uint32_t sum;\n\n    if (cse && cse < n)\n        n = cse + 1;\n    if (sloc < n-1) {\n        sum = net_checksum_add(n-css, data+css);\n        stw_be_p(data + sloc, net_checksum_finish_nozero(sum));\n    }\n}\n\nstatic inline void\ninc_tx_bcast_or_mcast_count(E1000State *s, const unsigned char *arr)\n{\n    if (!memcmp(arr, bcast, sizeof bcast)) {\n        e1000x_inc_reg_if_not_full(s->mac_reg, BPTC);\n    } else if (arr[0] & 1) {\n        e1000x_inc_reg_if_not_full(s->mac_reg, MPTC);\n    }\n}\n\nstatic void\ne1000_send_packet(E1000State *s, const uint8_t *buf, int size)\n{\n    static const int PTCregs[6] = { PTC64, PTC127, PTC255, PTC511,\n                                    PTC1023, PTC1522 };\n\n    NetClientState *nc = qemu_get_queue(s->nic);\n    if (s->phy_reg[PHY_CTRL] & MII_CR_LOOPBACK) {\n        nc->info->receive(nc, buf, size);\n    } else {\n        qemu_send_packet(nc, buf, size);\n    }\n    inc_tx_bcast_or_mcast_count(s, buf);\n    e1000x_increase_size_stats(s->mac_reg, PTCregs, size);\n}\n\nstatic void\nxmit_seg(E1000State *s)\n{\n    uint16_t len;\n    unsigned int frames = s->tx.tso_frames, css, sofar;\n    struct e1000_tx *tp = &s->tx;\n    struct e1000x_txd_props *props = tp->cptse ? &tp->tso_props : &tp->props;\n\n    if (tp->cptse) {\n        css = props->ipcss;\n        DBGOUT(TXSUM, \"frames %d size %d ipcss %d\\n\",\n               frames, tp->size, css);\n        if (props->ip) {    /* IPv4 */\n            stw_be_p(tp->data+css+2, tp->size - css);\n            stw_be_p(tp->data+css+4,\n                     lduw_be_p(tp->data + css + 4) + frames);\n        } else {         /* IPv6 */\n            stw_be_p(tp->data+css+4, tp->size - css);\n        }\n        css = props->tucss;\n        len = tp->size - css;\n        DBGOUT(TXSUM, \"tcp %d tucss %d len %d\\n\", props->tcp, css, len);\n        if (props->tcp) {\n            sofar = frames * props->mss;\n            stl_be_p(tp->data+css+4, ldl_be_p(tp->data+css+4)+sofar); /* seq */\n            if (props->paylen - sofar > props->mss) {\n                tp->data[css + 13] &= ~9;    /* PSH, FIN */\n            } else if (frames) {\n                e1000x_inc_reg_if_not_full(s->mac_reg, TSCTC);\n            }\n        } else {    /* UDP */\n            stw_be_p(tp->data+css+4, len);\n        }\n        if (tp->sum_needed & E1000_TXD_POPTS_TXSM) {\n            unsigned int phsum;\n            // add pseudo-header length before checksum calculation\n            void *sp = tp->data + props->tucso;\n\n            phsum = lduw_be_p(sp) + len;\n            phsum = (phsum >> 16) + (phsum & 0xffff);\n            stw_be_p(sp, phsum);\n        }\n        tp->tso_frames++;\n    }\n\n    if (tp->sum_needed & E1000_TXD_POPTS_TXSM) {\n        putsum(tp->data, tp->size, props->tucso, props->tucss, props->tucse);\n    }\n    if (tp->sum_needed & E1000_TXD_POPTS_IXSM) {\n        putsum(tp->data, tp->size, props->ipcso, props->ipcss, props->ipcse);\n    }\n    if (tp->vlan_needed) {\n        memmove(tp->vlan, tp->data, 4);\n        memmove(tp->data, tp->data + 4, 8);\n        memcpy(tp->data + 8, tp->vlan_header, 4);\n        e1000_send_packet(s, tp->vlan, tp->size + 4);\n    } else {\n        e1000_send_packet(s, tp->data, tp->size);\n    }\n\n    e1000x_inc_reg_if_not_full(s->mac_reg, TPT);\n    e1000x_grow_8reg_if_not_full(s->mac_reg, TOTL, s->tx.size);\n    s->mac_reg[GPTC] = s->mac_reg[TPT];\n    s->mac_reg[GOTCL] = s->mac_reg[TOTL];\n    s->mac_reg[GOTCH] = s->mac_reg[TOTH];\n}\n\nstatic void\nprocess_tx_desc(E1000State *s, struct e1000_tx_desc *dp)\n{\n    PCIDevice *d = PCI_DEVICE(s);\n    uint32_t txd_lower = le32_to_cpu(dp->lower.data);\n    uint32_t dtype = txd_lower & (E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D);\n    unsigned int split_size = txd_lower & 0xffff, bytes, sz;\n    unsigned int msh = 0xfffff;\n    uint64_t addr;\n    struct e1000_context_desc *xp = (struct e1000_context_desc *)dp;\n    struct e1000_tx *tp = &s->tx;\n\n    s->mit_ide |= (txd_lower & E1000_TXD_CMD_IDE);\n    if (dtype == E1000_TXD_CMD_DEXT) {    /* context descriptor */\n        if (le32_to_cpu(xp->cmd_and_length) & E1000_TXD_CMD_TSE) {\n            e1000x_read_tx_ctx_descr(xp, &tp->tso_props);\n            s->use_tso_for_migration = 1;\n            tp->tso_frames = 0;\n        } else {\n            e1000x_read_tx_ctx_descr(xp, &tp->props);\n            s->use_tso_for_migration = 0;\n        }\n        return;\n    } else if (dtype == (E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D)) {\n        // data descriptor\n        if (tp->size == 0) {\n            tp->sum_needed = le32_to_cpu(dp->upper.data) >> 8;\n        }\n        tp->cptse = (txd_lower & E1000_TXD_CMD_TSE) ? 1 : 0;\n    } else {\n        // legacy descriptor\n        tp->cptse = 0;\n    }\n\n    if (e1000x_vlan_enabled(s->mac_reg) &&\n        e1000x_is_vlan_txd(txd_lower) &&\n        (tp->cptse || txd_lower & E1000_TXD_CMD_EOP)) {\n        tp->vlan_needed = 1;\n        stw_be_p(tp->vlan_header,\n                      le16_to_cpu(s->mac_reg[VET]));\n        stw_be_p(tp->vlan_header + 2,\n                      le16_to_cpu(dp->upper.fields.special));\n    }\n\n    addr = le64_to_cpu(dp->buffer_addr);\n    if (tp->cptse) {\n        msh = tp->tso_props.hdr_len + tp->tso_props.mss;\n        do {\n            bytes = split_size;\n            if (tp->size + bytes > msh)\n                bytes = msh - tp->size;\n\n            bytes = MIN(sizeof(tp->data) - tp->size, bytes);\n            pci_dma_read(d, addr, tp->data + tp->size, bytes);\n            sz = tp->size + bytes;\n            if (sz >= tp->tso_props.hdr_len\n                && tp->size < tp->tso_props.hdr_len) {\n                memmove(tp->header, tp->data, tp->tso_props.hdr_len);\n            }\n            tp->size = sz;\n            addr += bytes;\n            if (sz == msh) {\n                xmit_seg(s);\n                memmove(tp->data, tp->header, tp->tso_props.hdr_len);\n                tp->size = tp->tso_props.hdr_len;\n            }\n            split_size -= bytes;\n        } while (bytes && split_size);\n    } else {\n        split_size = MIN(sizeof(tp->data) - tp->size, split_size);\n        pci_dma_read(d, addr, tp->data + tp->size, split_size);\n        tp->size += split_size;\n    }\n\n    if (!(txd_lower & E1000_TXD_CMD_EOP))\n        return;\n    if (!(tp->cptse && tp->size < tp->tso_props.hdr_len)) {\n        xmit_seg(s);\n    }\n    tp->tso_frames = 0;\n    tp->sum_needed = 0;\n    tp->vlan_needed = 0;\n    tp->size = 0;\n    tp->cptse = 0;\n}\n\nstatic uint32_t\ntxdesc_writeback(E1000State *s, dma_addr_t base, struct e1000_tx_desc *dp)\n{\n    PCIDevice *d = PCI_DEVICE(s);\n    uint32_t txd_upper, txd_lower = le32_to_cpu(dp->lower.data);\n\n    if (!(txd_lower & (E1000_TXD_CMD_RS|E1000_TXD_CMD_RPS)))\n        return 0;\n    txd_upper = (le32_to_cpu(dp->upper.data) | E1000_TXD_STAT_DD) &\n                ~(E1000_TXD_STAT_EC | E1000_TXD_STAT_LC | E1000_TXD_STAT_TU);\n    dp->upper.data = cpu_to_le32(txd_upper);\n    pci_dma_write(d, base + ((char *)&dp->upper - (char *)dp),\n                  &dp->upper, sizeof(dp->upper));\n    return E1000_ICR_TXDW;\n}\n\nstatic uint64_t tx_desc_base(E1000State *s)\n{\n    uint64_t bah = s->mac_reg[TDBAH];\n    uint64_t bal = s->mac_reg[TDBAL] & ~0xf;\n\n    return (bah << 32) + bal;\n}\n\nstatic void\nstart_xmit(E1000State *s)\n{\n    PCIDevice *d = PCI_DEVICE(s);\n    dma_addr_t base;\n    struct e1000_tx_desc desc;\n    uint32_t tdh_start = s->mac_reg[TDH], cause = E1000_ICS_TXQE;\n\n    if (!(s->mac_reg[TCTL] & E1000_TCTL_EN)) {\n        DBGOUT(TX, \"tx disabled\\n\");\n        return;\n    }\n\n    while (s->mac_reg[TDH] != s->mac_reg[TDT]) {\n        base = tx_desc_base(s) +\n               sizeof(struct e1000_tx_desc) * s->mac_reg[TDH];\n        pci_dma_read(d, base, &desc, sizeof(desc));\n\n        DBGOUT(TX, \"index %d: %p : %x %x\\n\", s->mac_reg[TDH],\n               (void *)(intptr_t)desc.buffer_addr, desc.lower.data,\n               desc.upper.data);\n\n        process_tx_desc(s, &desc);\n        cause |= txdesc_writeback(s, base, &desc);\n\n        if (++s->mac_reg[TDH] * sizeof(desc) >= s->mac_reg[TDLEN])\n            s->mac_reg[TDH] = 0;\n        /*\n         * the following could happen only if guest sw assigns\n         * bogus values to TDT/TDLEN.\n         * there's nothing too intelligent we could do about this.\n         */\n        if (s->mac_reg[TDH] == tdh_start ||\n            tdh_start >= s->mac_reg[TDLEN] / sizeof(desc)) {\n            DBGOUT(TXERR, \"TDH wraparound @%x, TDT %x, TDLEN %x\\n\",\n                   tdh_start, s->mac_reg[TDT], s->mac_reg[TDLEN]);\n            break;\n        }\n    }\n    set_ics(s, 0, cause);\n}\n\nstatic int\nreceive_filter(E1000State *s, const uint8_t *buf, int size)\n{\n    uint32_t rctl = s->mac_reg[RCTL];\n    int isbcast = !memcmp(buf, bcast, sizeof bcast), ismcast = (buf[0] & 1);\n\n    if (e1000x_is_vlan_packet(buf, le16_to_cpu(s->mac_reg[VET])) &&\n        e1000x_vlan_rx_filter_enabled(s->mac_reg)) {\n        uint16_t vid = lduw_be_p(buf + 14);\n        uint32_t vfta = ldl_le_p((uint32_t*)(s->mac_reg + VFTA) +\n                                 ((vid >> 5) & 0x7f));\n        if ((vfta & (1 << (vid & 0x1f))) == 0)\n            return 0;\n    }\n\n    if (!isbcast && !ismcast && (rctl & E1000_RCTL_UPE)) { /* promiscuous ucast */\n        return 1;\n    }\n\n    if (ismcast && (rctl & E1000_RCTL_MPE)) {          /* promiscuous mcast */\n        e1000x_inc_reg_if_not_full(s->mac_reg, MPRC);\n        return 1;\n    }\n\n    if (isbcast && (rctl & E1000_RCTL_BAM)) {          /* broadcast enabled */\n        e1000x_inc_reg_if_not_full(s->mac_reg, BPRC);\n        return 1;\n    }\n\n    return e1000x_rx_group_filter(s->mac_reg, buf);\n}\n\nstatic void\ne1000_set_link_status(NetClientState *nc)\n{\n    E1000State *s = qemu_get_nic_opaque(nc);\n    uint32_t old_status = s->mac_reg[STATUS];\n\n    if (nc->link_down) {\n        e1000x_update_regs_on_link_down(s->mac_reg, s->phy_reg);\n    } else {\n        if (have_autoneg(s) &&\n            !(s->phy_reg[PHY_STATUS] & MII_SR_AUTONEG_COMPLETE)) {\n            e1000x_restart_autoneg(s->mac_reg, s->phy_reg, s->autoneg_timer);\n        } else {\n            e1000_link_up(s);\n        }\n    }\n\n    if (s->mac_reg[STATUS] != old_status)\n        set_ics(s, 0, E1000_ICR_LSC);\n}\n\nstatic bool e1000_has_rxbufs(E1000State *s, size_t total_size)\n{\n    int bufs;\n    /* Fast-path short packets */\n    if (total_size <= s->rxbuf_size) {\n        return s->mac_reg[RDH] != s->mac_reg[RDT];\n    }\n    if (s->mac_reg[RDH] < s->mac_reg[RDT]) {\n        bufs = s->mac_reg[RDT] - s->mac_reg[RDH];\n    } else if (s->mac_reg[RDH] > s->mac_reg[RDT]) {\n        bufs = s->mac_reg[RDLEN] /  sizeof(struct e1000_rx_desc) +\n            s->mac_reg[RDT] - s->mac_reg[RDH];\n    } else {\n        return false;\n    }\n    return total_size <= bufs * s->rxbuf_size;\n}\n\nstatic bool\ne1000_can_receive(NetClientState *nc)\n{\n    E1000State *s = qemu_get_nic_opaque(nc);\n\n    return e1000x_rx_ready(&s->parent_obj, s->mac_reg) &&\n        e1000_has_rxbufs(s, 1) && !timer_pending(s->flush_queue_timer);\n}\n\nstatic uint64_t rx_desc_base(E1000State *s)\n{\n    uint64_t bah = s->mac_reg[RDBAH];\n    uint64_t bal = s->mac_reg[RDBAL] & ~0xf;\n\n    return (bah << 32) + bal;\n}\n\nstatic void\ne1000_receiver_overrun(E1000State *s, size_t size)\n{\n    trace_e1000_receiver_overrun(size, s->mac_reg[RDH], s->mac_reg[RDT]);\n    e1000x_inc_reg_if_not_full(s->mac_reg, RNBC);\n    e1000x_inc_reg_if_not_full(s->mac_reg, MPC);\n    set_ics(s, 0, E1000_ICS_RXO);\n}\n\nstatic ssize_t\ne1000_receive_iov(NetClientState *nc, const struct iovec *iov, int iovcnt)\n{\n    E1000State *s = qemu_get_nic_opaque(nc);\n    PCIDevice *d = PCI_DEVICE(s);\n    struct e1000_rx_desc desc;\n    dma_addr_t base;\n    unsigned int n, rdt;\n    uint32_t rdh_start;\n    uint16_t vlan_special = 0;\n    uint8_t vlan_status = 0;\n    uint8_t min_buf[MIN_BUF_SIZE];\n    struct iovec min_iov;\n    uint8_t *filter_buf = iov->iov_base;\n    size_t size = iov_size(iov, iovcnt);\n    size_t iov_ofs = 0;\n    size_t desc_offset;\n    size_t desc_size;\n    size_t total_size;\n\n    if (!e1000x_hw_rx_enabled(s->mac_reg)) {\n        return -1;\n    }\n\n    if (timer_pending(s->flush_queue_timer)) {\n        return 0;\n    }\n\n    /* Pad to minimum Ethernet frame length */\n    if (size < sizeof(min_buf)) {\n        iov_to_buf(iov, iovcnt, 0, min_buf, size);\n        memset(&min_buf[size], 0, sizeof(min_buf) - size);\n        min_iov.iov_base = filter_buf = min_buf;\n        min_iov.iov_len = size = sizeof(min_buf);\n        iovcnt = 1;\n        iov = &min_iov;\n    } else if (iov->iov_len < MAXIMUM_ETHERNET_HDR_LEN) {\n        /* This is very unlikely, but may happen. */\n        iov_to_buf(iov, iovcnt, 0, min_buf, MAXIMUM_ETHERNET_HDR_LEN);\n        filter_buf = min_buf;\n    }\n\n    /* Discard oversized packets if !LPE and !SBP. */\n    if (e1000x_is_oversized(s->mac_reg, size)) {\n        return size;\n    }\n\n    if (!receive_filter(s, filter_buf, size)) {\n        return size;\n    }\n\n    if (e1000x_vlan_enabled(s->mac_reg) &&\n        e1000x_is_vlan_packet(filter_buf, le16_to_cpu(s->mac_reg[VET]))) {\n        vlan_special = cpu_to_le16(lduw_be_p(filter_buf + 14));\n        iov_ofs = 4;\n        if (filter_buf == iov->iov_base) {\n            memmove(filter_buf + 4, filter_buf, 12);\n        } else {\n            iov_from_buf(iov, iovcnt, 4, filter_buf, 12);\n            while (iov->iov_len <= iov_ofs) {\n                iov_ofs -= iov->iov_len;\n                iov++;\n            }\n        }\n        vlan_status = E1000_RXD_STAT_VP;\n        size -= 4;\n    }\n\n    rdh_start = s->mac_reg[RDH];\n    desc_offset = 0;\n    total_size = size + e1000x_fcs_len(s->mac_reg);\n    if (!e1000_has_rxbufs(s, total_size)) {\n        e1000_receiver_overrun(s, total_size);\n        return -1;\n    }\n    do {\n        desc_size = total_size - desc_offset;\n        if (desc_size > s->rxbuf_size) {\n            desc_size = s->rxbuf_size;\n        }\n        base = rx_desc_base(s) + sizeof(desc) * s->mac_reg[RDH];\n        pci_dma_read(d, base, &desc, sizeof(desc));\n        desc.special = vlan_special;\n        desc.status |= (vlan_status | E1000_RXD_STAT_DD);\n        if (desc.buffer_addr) {\n            if (desc_offset < size) {\n                size_t iov_copy;\n                hwaddr ba = le64_to_cpu(desc.buffer_addr);\n                size_t copy_size = size - desc_offset;\n                if (copy_size > s->rxbuf_size) {\n                    copy_size = s->rxbuf_size;\n                }\n                do {\n                    iov_copy = MIN(copy_size, iov->iov_len - iov_ofs);\n                    pci_dma_write(d, ba, iov->iov_base + iov_ofs, iov_copy);\n                    copy_size -= iov_copy;\n                    ba += iov_copy;\n                    iov_ofs += iov_copy;\n                    if (iov_ofs == iov->iov_len) {\n                        iov++;\n                        iov_ofs = 0;\n                    }\n                } while (copy_size);\n            }\n            desc_offset += desc_size;\n            desc.length = cpu_to_le16(desc_size);\n            if (desc_offset >= total_size) {\n                desc.status |= E1000_RXD_STAT_EOP | E1000_RXD_STAT_IXSM;\n            } else {\n                /* Guest zeroing out status is not a hardware requirement.\n                   Clear EOP in case guest didn't do it. */\n                desc.status &= ~E1000_RXD_STAT_EOP;\n            }\n        } else { // as per intel docs; skip descriptors with null buf addr\n            DBGOUT(RX, \"Null RX descriptor!!\\n\");\n        }\n        pci_dma_write(d, base, &desc, sizeof(desc));\n\n        if (++s->mac_reg[RDH] * sizeof(desc) >= s->mac_reg[RDLEN])\n            s->mac_reg[RDH] = 0;\n        /* see comment in start_xmit; same here */\n        if (s->mac_reg[RDH] == rdh_start ||\n            rdh_start >= s->mac_reg[RDLEN] / sizeof(desc)) {\n            DBGOUT(RXERR, \"RDH wraparound @%x, RDT %x, RDLEN %x\\n\",\n                   rdh_start, s->mac_reg[RDT], s->mac_reg[RDLEN]);\n            e1000_receiver_overrun(s, total_size);\n            return -1;\n        }\n    } while (desc_offset < total_size);\n\n    e1000x_update_rx_total_stats(s->mac_reg, size, total_size);\n\n    n = E1000_ICS_RXT0;\n    if ((rdt = s->mac_reg[RDT]) < s->mac_reg[RDH])\n        rdt += s->mac_reg[RDLEN] / sizeof(desc);\n    if (((rdt - s->mac_reg[RDH]) * sizeof(desc)) <= s->mac_reg[RDLEN] >>\n        s->rxbuf_min_shift)\n        n |= E1000_ICS_RXDMT0;\n\n    set_ics(s, 0, n);\n\n    return size;\n}\n\nstatic ssize_t\ne1000_receive(NetClientState *nc, const uint8_t *buf, size_t size)\n{\n    const struct iovec iov = {\n        .iov_base = (uint8_t *)buf,\n        .iov_len = size\n    };\n\n    return e1000_receive_iov(nc, &iov, 1);\n}\n\nstatic uint32_t\nmac_readreg(E1000State *s, int index)\n{\n    return s->mac_reg[index];\n}\n\nstatic uint32_t\nmac_low4_read(E1000State *s, int index)\n{\n    return s->mac_reg[index] & 0xf;\n}\n\nstatic uint32_t\nmac_low11_read(E1000State *s, int index)\n{\n    return s->mac_reg[index] & 0x7ff;\n}\n\nstatic uint32_t\nmac_low13_read(E1000State *s, int index)\n{\n    return s->mac_reg[index] & 0x1fff;\n}\n\nstatic uint32_t\nmac_low16_read(E1000State *s, int index)\n{\n    return s->mac_reg[index] & 0xffff;\n}\n\nstatic uint32_t\nmac_icr_read(E1000State *s, int index)\n{\n    uint32_t ret = s->mac_reg[ICR];\n\n    DBGOUT(INTERRUPT, \"ICR read: %x\\n\", ret);\n    set_interrupt_cause(s, 0, 0);\n    return ret;\n}\n\nstatic uint32_t\nmac_read_clr4(E1000State *s, int index)\n{\n    uint32_t ret = s->mac_reg[index];\n\n    s->mac_reg[index] = 0;\n    return ret;\n}\n\nstatic uint32_t\nmac_read_clr8(E1000State *s, int index)\n{\n    uint32_t ret = s->mac_reg[index];\n\n    s->mac_reg[index] = 0;\n    s->mac_reg[index-1] = 0;\n    return ret;\n}\n\nstatic void\nmac_writereg(E1000State *s, int index, uint32_t val)\n{\n    uint32_t macaddr[2];\n\n    s->mac_reg[index] = val;\n\n    if (index == RA + 1) {\n        macaddr[0] = cpu_to_le32(s->mac_reg[RA]);\n        macaddr[1] = cpu_to_le32(s->mac_reg[RA + 1]);\n        qemu_format_nic_info_str(qemu_get_queue(s->nic), (uint8_t *)macaddr);\n    }\n}\n\nstatic void\nset_rdt(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[index] = val & 0xffff;\n    if (e1000_has_rxbufs(s, 1)) {\n        qemu_flush_queued_packets(qemu_get_queue(s->nic));\n    }\n}\n\nstatic void\nset_16bit(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[index] = val & 0xffff;\n}\n\nstatic void\nset_dlen(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[index] = val & 0xfff80;\n}\n\nstatic void\nset_tctl(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[index] = val;\n    s->mac_reg[TDT] &= 0xffff;\n    start_xmit(s);\n}\n\nstatic void\nset_icr(E1000State *s, int index, uint32_t val)\n{\n    DBGOUT(INTERRUPT, \"set_icr %x\\n\", val);\n    set_interrupt_cause(s, 0, s->mac_reg[ICR] & ~val);\n}\n\nstatic void\nset_imc(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[IMS] &= ~val;\n    set_ics(s, 0, 0);\n}\n\nstatic void\nset_ims(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[IMS] |= val;\n    set_ics(s, 0, 0);\n}\n\n#define getreg(x)    [x] = mac_readreg\ntypedef uint32_t (*readops)(E1000State *, int);\nstatic const readops macreg_readops[] = {\n    getreg(PBA),      getreg(RCTL),     getreg(TDH),      getreg(TXDCTL),\n    getreg(WUFC),     getreg(TDT),      getreg(CTRL),     getreg(LEDCTL),\n    getreg(MANC),     getreg(MDIC),     getreg(SWSM),     getreg(STATUS),\n    getreg(TORL),     getreg(TOTL),     getreg(IMS),      getreg(TCTL),\n    getreg(RDH),      getreg(RDT),      getreg(VET),      getreg(ICS),\n    getreg(TDBAL),    getreg(TDBAH),    getreg(RDBAH),    getreg(RDBAL),\n    getreg(TDLEN),    getreg(RDLEN),    getreg(RDTR),     getreg(RADV),\n    getreg(TADV),     getreg(ITR),      getreg(FCRUC),    getreg(IPAV),\n    getreg(WUC),      getreg(WUS),      getreg(SCC),      getreg(ECOL),\n    getreg(MCC),      getreg(LATECOL),  getreg(COLC),     getreg(DC),\n    getreg(TNCRS),    getreg(SEQEC),    getreg(CEXTERR),  getreg(RLEC),\n    getreg(XONRXC),   getreg(XONTXC),   getreg(XOFFRXC),  getreg(XOFFTXC),\n    getreg(RFC),      getreg(RJC),      getreg(RNBC),     getreg(TSCTFC),\n    getreg(MGTPRC),   getreg(MGTPDC),   getreg(MGTPTC),   getreg(GORCL),\n    getreg(GOTCL),\n\n    [TOTH]    = mac_read_clr8,      [TORH]    = mac_read_clr8,\n    [GOTCH]   = mac_read_clr8,      [GORCH]   = mac_read_clr8,\n    [PRC64]   = mac_read_clr4,      [PRC127]  = mac_read_clr4,\n    [PRC255]  = mac_read_clr4,      [PRC511]  = mac_read_clr4,\n    [PRC1023] = mac_read_clr4,      [PRC1522] = mac_read_clr4,\n    [PTC64]   = mac_read_clr4,      [PTC127]  = mac_read_clr4,\n    [PTC255]  = mac_read_clr4,      [PTC511]  = mac_read_clr4,\n    [PTC1023] = mac_read_clr4,      [PTC1522] = mac_read_clr4,\n    [GPRC]    = mac_read_clr4,      [GPTC]    = mac_read_clr4,\n    [TPT]     = mac_read_clr4,      [TPR]     = mac_read_clr4,\n    [RUC]     = mac_read_clr4,      [ROC]     = mac_read_clr4,\n    [BPRC]    = mac_read_clr4,      [MPRC]    = mac_read_clr4,\n    [TSCTC]   = mac_read_clr4,      [BPTC]    = mac_read_clr4,\n    [MPTC]    = mac_read_clr4,\n    [ICR]     = mac_icr_read,       [EECD]    = get_eecd,\n    [EERD]    = flash_eerd_read,\n    [RDFH]    = mac_low13_read,     [RDFT]    = mac_low13_read,\n    [RDFHS]   = mac_low13_read,     [RDFTS]   = mac_low13_read,\n    [RDFPC]   = mac_low13_read,\n    [TDFH]    = mac_low11_read,     [TDFT]    = mac_low11_read,\n    [TDFHS]   = mac_low13_read,     [TDFTS]   = mac_low13_read,\n    [TDFPC]   = mac_low13_read,\n    [AIT]     = mac_low16_read,\n\n    [CRCERRS ... MPC]   = &mac_readreg,\n    [IP6AT ... IP6AT+3] = &mac_readreg,    [IP4AT ... IP4AT+6] = &mac_readreg,\n    [FFLT ... FFLT+6]   = &mac_low11_read,\n    [RA ... RA+31]      = &mac_readreg,\n    [WUPM ... WUPM+31]  = &mac_readreg,\n    [MTA ... MTA+127]   = &mac_readreg,\n    [VFTA ... VFTA+127] = &mac_readreg,\n    [FFMT ... FFMT+254] = &mac_low4_read,\n    [FFVT ... FFVT+254] = &mac_readreg,\n    [PBM ... PBM+16383] = &mac_readreg,\n};\nenum { NREADOPS = ARRAY_SIZE(macreg_readops) };\n\n#define putreg(x)    [x] = mac_writereg\ntypedef void (*writeops)(E1000State *, int, uint32_t);\nstatic const writeops macreg_writeops[] = {\n    putreg(PBA),      putreg(EERD),     putreg(SWSM),     putreg(WUFC),\n    putreg(TDBAL),    putreg(TDBAH),    putreg(TXDCTL),   putreg(RDBAH),\n    putreg(RDBAL),    putreg(LEDCTL),   putreg(VET),      putreg(FCRUC),\n    putreg(TDFH),     putreg(TDFT),     putreg(TDFHS),    putreg(TDFTS),\n    putreg(TDFPC),    putreg(RDFH),     putreg(RDFT),     putreg(RDFHS),\n    putreg(RDFTS),    putreg(RDFPC),    putreg(IPAV),     putreg(WUC),\n    putreg(WUS),      putreg(AIT),\n\n    [TDLEN]  = set_dlen,   [RDLEN]  = set_dlen,       [TCTL] = set_tctl,\n    [TDT]    = set_tctl,   [MDIC]   = set_mdic,       [ICS]  = set_ics,\n    [TDH]    = set_16bit,  [RDH]    = set_16bit,      [RDT]  = set_rdt,\n    [IMC]    = set_imc,    [IMS]    = set_ims,        [ICR]  = set_icr,\n    [EECD]   = set_eecd,   [RCTL]   = set_rx_control, [CTRL] = set_ctrl,\n    [RDTR]   = set_16bit,  [RADV]   = set_16bit,      [TADV] = set_16bit,\n    [ITR]    = set_16bit,\n\n    [IP6AT ... IP6AT+3] = &mac_writereg, [IP4AT ... IP4AT+6] = &mac_writereg,\n    [FFLT ... FFLT+6]   = &mac_writereg,\n    [RA ... RA+31]      = &mac_writereg,\n    [WUPM ... WUPM+31]  = &mac_writereg,\n    [MTA ... MTA+127]   = &mac_writereg,\n    [VFTA ... VFTA+127] = &mac_writereg,\n    [FFMT ... FFMT+254] = &mac_writereg, [FFVT ... FFVT+254] = &mac_writereg,\n    [PBM ... PBM+16383] = &mac_writereg,\n};\n\nenum { NWRITEOPS = ARRAY_SIZE(macreg_writeops) };\n\nenum { MAC_ACCESS_PARTIAL = 1, MAC_ACCESS_FLAG_NEEDED = 2 };\n\n#define markflag(x)    ((E1000_FLAG_##x << 2) | MAC_ACCESS_FLAG_NEEDED)\n/* In the array below the meaning of the bits is: [f|f|f|f|f|f|n|p]\n * f - flag bits (up to 6 possible flags)\n * n - flag needed\n * p - partially implenented */\nstatic const uint8_t mac_reg_access[0x8000] = {\n    [RDTR]    = markflag(MIT),    [TADV]    = markflag(MIT),\n    [RADV]    = markflag(MIT),    [ITR]     = markflag(MIT),\n\n    [IPAV]    = markflag(MAC),    [WUC]     = markflag(MAC),\n    [IP6AT]   = markflag(MAC),    [IP4AT]   = markflag(MAC),\n    [FFVT]    = markflag(MAC),    [WUPM]    = markflag(MAC),\n    [ECOL]    = markflag(MAC),    [MCC]     = markflag(MAC),\n    [DC]      = markflag(MAC),    [TNCRS]   = markflag(MAC),\n    [RLEC]    = markflag(MAC),    [XONRXC]  = markflag(MAC),\n    [XOFFTXC] = markflag(MAC),    [RFC]     = markflag(MAC),\n    [TSCTFC]  = markflag(MAC),    [MGTPRC]  = markflag(MAC),\n    [WUS]     = markflag(MAC),    [AIT]     = markflag(MAC),\n    [FFLT]    = markflag(MAC),    [FFMT]    = markflag(MAC),\n    [SCC]     = markflag(MAC),    [FCRUC]   = markflag(MAC),\n    [LATECOL] = markflag(MAC),    [COLC]    = markflag(MAC),\n    [SEQEC]   = markflag(MAC),    [CEXTERR] = markflag(MAC),\n    [XONTXC]  = markflag(MAC),    [XOFFRXC] = markflag(MAC),\n    [RJC]     = markflag(MAC),    [RNBC]    = markflag(MAC),\n    [MGTPDC]  = markflag(MAC),    [MGTPTC]  = markflag(MAC),\n    [RUC]     = markflag(MAC),    [ROC]     = markflag(MAC),\n    [GORCL]   = markflag(MAC),    [GORCH]   = markflag(MAC),\n    [GOTCL]   = markflag(MAC),    [GOTCH]   = markflag(MAC),\n    [BPRC]    = markflag(MAC),    [MPRC]    = markflag(MAC),\n    [TSCTC]   = markflag(MAC),    [PRC64]   = markflag(MAC),\n    [PRC127]  = markflag(MAC),    [PRC255]  = markflag(MAC),\n    [PRC511]  = markflag(MAC),    [PRC1023] = markflag(MAC),\n    [PRC1522] = markflag(MAC),    [PTC64]   = markflag(MAC),\n    [PTC127]  = markflag(MAC),    [PTC255]  = markflag(MAC),\n    [PTC511]  = markflag(MAC),    [PTC1023] = markflag(MAC),\n    [PTC1522] = markflag(MAC),    [MPTC]    = markflag(MAC),\n    [BPTC]    = markflag(MAC),\n\n    [TDFH]  = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [TDFT]  = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [TDFHS] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [TDFTS] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [TDFPC] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [RDFH]  = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [RDFT]  = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [RDFHS] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [RDFTS] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [RDFPC] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [PBM]   = markflag(MAC) | MAC_ACCESS_PARTIAL,\n};\n\nstatic void\ne1000_mmio_write(void *opaque, hwaddr addr, uint64_t val,\n                 unsigned size)\n{\n    E1000State *s = opaque;\n    unsigned int index = (addr & 0x1ffff) >> 2;\n\n    if (index < NWRITEOPS && macreg_writeops[index]) {\n        if (!(mac_reg_access[index] & MAC_ACCESS_FLAG_NEEDED)\n            || (s->compat_flags & (mac_reg_access[index] >> 2))) {\n            if (mac_reg_access[index] & MAC_ACCESS_PARTIAL) {\n                DBGOUT(GENERAL, \"Writing to register at offset: 0x%08x. \"\n                       \"It is not fully implemented.\\n\", index<<2);\n            }\n            macreg_writeops[index](s, index, val);\n        } else {    /* \"flag needed\" bit is set, but the flag is not active */\n            DBGOUT(MMIO, \"MMIO write attempt to disabled reg. addr=0x%08x\\n\",\n                   index<<2);\n        }\n    } else if (index < NREADOPS && macreg_readops[index]) {\n        DBGOUT(MMIO, \"e1000_mmio_writel RO %x: 0x%04\"PRIx64\"\\n\",\n               index<<2, val);\n    } else {\n        DBGOUT(UNKNOWN, \"MMIO unknown write addr=0x%08x,val=0x%08\"PRIx64\"\\n\",\n               index<<2, val);\n    }\n}\n\nstatic uint64_t\ne1000_mmio_read(void *opaque, hwaddr addr, unsigned size)\n{\n    E1000State *s = opaque;\n    unsigned int index = (addr & 0x1ffff) >> 2;\n\n    if (index < NREADOPS && macreg_readops[index]) {\n        if (!(mac_reg_access[index] & MAC_ACCESS_FLAG_NEEDED)\n            || (s->compat_flags & (mac_reg_access[index] >> 2))) {\n            if (mac_reg_access[index] & MAC_ACCESS_PARTIAL) {\n                DBGOUT(GENERAL, \"Reading register at offset: 0x%08x. \"\n                       \"It is not fully implemented.\\n\", index<<2);\n            }\n            return macreg_readops[index](s, index);\n        } else {    /* \"flag needed\" bit is set, but the flag is not active */\n            DBGOUT(MMIO, \"MMIO read attempt of disabled reg. addr=0x%08x\\n\",\n                   index<<2);\n        }\n    } else {\n        DBGOUT(UNKNOWN, \"MMIO unknown read addr=0x%08x\\n\", index<<2);\n    }\n    return 0;\n}\n\nstatic const MemoryRegionOps e1000_mmio_ops = {\n    .read = e1000_mmio_read,\n    .write = e1000_mmio_write,\n    .endianness = DEVICE_LITTLE_ENDIAN,\n    .impl = {\n        .min_access_size = 4,\n        .max_access_size = 4,\n    },\n};\n\nstatic uint64_t e1000_io_read(void *opaque, hwaddr addr,\n                              unsigned size)\n{\n    E1000State *s = opaque;\n\n    (void)s;\n    return 0;\n}\n\nstatic void e1000_io_write(void *opaque, hwaddr addr,\n                           uint64_t val, unsigned size)\n{\n    E1000State *s = opaque;\n\n    (void)s;\n}\n\nstatic const MemoryRegionOps e1000_io_ops = {\n    .read = e1000_io_read,\n    .write = e1000_io_write,\n    .endianness = DEVICE_LITTLE_ENDIAN,\n};\n\nstatic bool is_version_1(void *opaque, int version_id)\n{\n    return version_id == 1;\n}\n\nstatic int e1000_pre_save(void *opaque)\n{\n    E1000State *s = opaque;\n    NetClientState *nc = qemu_get_queue(s->nic);\n\n    /*\n     * If link is down and auto-negotiation is supported and ongoing,\n     * complete auto-negotiation immediately. This allows us to look\n     * at MII_SR_AUTONEG_COMPLETE to infer link status on load.\n     */\n    if (nc->link_down && have_autoneg(s)) {\n        s->phy_reg[PHY_STATUS] |= MII_SR_AUTONEG_COMPLETE;\n    }\n\n    /* Decide which set of props to migrate in the main structure */\n    if (chkflag(TSO) || !s->use_tso_for_migration) {\n        /* Either we're migrating with the extra subsection, in which\n         * case the mig_props is always 'props' OR\n         * we've not got the subsection, but 'props' was the last\n         * updated.\n         */\n        s->mig_props = s->tx.props;\n    } else {\n        /* We're not using the subsection, and 'tso_props' was\n         * the last updated.\n         */\n        s->mig_props = s->tx.tso_props;\n    }\n    return 0;\n}\n\nstatic int e1000_post_load(void *opaque, int version_id)\n{\n    E1000State *s = opaque;\n    NetClientState *nc = qemu_get_queue(s->nic);\n\n    if (!chkflag(MIT)) {\n        s->mac_reg[ITR] = s->mac_reg[RDTR] = s->mac_reg[RADV] =\n            s->mac_reg[TADV] = 0;\n        s->mit_irq_level = false;\n    }\n    s->mit_ide = 0;\n    s->mit_timer_on = true;\n    timer_mod(s->mit_timer, qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL) + 1);\n\n    /* nc.link_down can't be migrated, so infer link_down according\n     * to link status bit in mac_reg[STATUS].\n     * Alternatively, restart link negotiation if it was in progress. */\n    nc->link_down = (s->mac_reg[STATUS] & E1000_STATUS_LU) == 0;\n\n    if (have_autoneg(s) &&\n        !(s->phy_reg[PHY_STATUS] & MII_SR_AUTONEG_COMPLETE)) {\n        nc->link_down = false;\n        timer_mod(s->autoneg_timer,\n                  qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL) + 500);\n    }\n\n    s->tx.props = s->mig_props;\n    if (!s->received_tx_tso) {\n        /* We received only one set of offload data (tx.props)\n         * and haven't got tx.tso_props.  The best we can do\n         * is dupe the data.\n         */\n        s->tx.tso_props = s->mig_props;\n    }\n    return 0;\n}\n\nstatic int e1000_tx_tso_post_load(void *opaque, int version_id)\n{\n    E1000State *s = opaque;\n    s->received_tx_tso = true;\n    return 0;\n}\n\nstatic bool e1000_mit_state_needed(void *opaque)\n{\n    E1000State *s = opaque;\n\n    return chkflag(MIT);\n}\n\nstatic bool e1000_full_mac_needed(void *opaque)\n{\n    E1000State *s = opaque;\n\n    return chkflag(MAC);\n}\n\nstatic bool e1000_tso_state_needed(void *opaque)\n{\n    E1000State *s = opaque;\n\n    return chkflag(TSO);\n}\n\nstatic const VMStateDescription vmstate_e1000_mit_state = {\n    .name = \"e1000/mit_state\",\n    .version_id = 1,\n    .minimum_version_id = 1,\n    .needed = e1000_mit_state_needed,\n    .fields = (VMStateField[]) {\n        VMSTATE_UINT32(mac_reg[RDTR], E1000State),\n        VMSTATE_UINT32(mac_reg[RADV], E1000State),\n        VMSTATE_UINT32(mac_reg[TADV], E1000State),\n        VMSTATE_UINT32(mac_reg[ITR], E1000State),\n        VMSTATE_BOOL(mit_irq_level, E1000State),\n        VMSTATE_END_OF_LIST()\n    }\n};\n\nstatic const VMStateDescription vmstate_e1000_full_mac_state = {\n    .name = \"e1000/full_mac_state\",\n    .version_id = 1,\n    .minimum_version_id = 1,\n    .needed = e1000_full_mac_needed,\n    .fields = (VMStateField[]) {\n        VMSTATE_UINT32_ARRAY(mac_reg, E1000State, 0x8000),\n        VMSTATE_END_OF_LIST()\n    }\n};\n\nstatic const VMStateDescription vmstate_e1000_tx_tso_state = {\n    .name = \"e1000/tx_tso_state\",\n    .version_id = 1,\n    .minimum_version_id = 1,\n    .needed = e1000_tso_state_needed,\n    .post_load = e1000_tx_tso_post_load,\n    .fields = (VMStateField[]) {\n        VMSTATE_UINT8(tx.tso_props.ipcss, E1000State),\n        VMSTATE_UINT8(tx.tso_props.ipcso, E1000State),\n        VMSTATE_UINT16(tx.tso_props.ipcse, E1000State),\n        VMSTATE_UINT8(tx.tso_props.tucss, E1000State),\n        VMSTATE_UINT8(tx.tso_props.tucso, E1000State),\n        VMSTATE_UINT16(tx.tso_props.tucse, E1000State),\n        VMSTATE_UINT32(tx.tso_props.paylen, E1000State),\n        VMSTATE_UINT8(tx.tso_props.hdr_len, E1000State),\n        VMSTATE_UINT16(tx.tso_props.mss, E1000State),\n        VMSTATE_INT8(tx.tso_props.ip, E1000State),\n        VMSTATE_INT8(tx.tso_props.tcp, E1000State),\n        VMSTATE_END_OF_LIST()\n    }\n};\n\nstatic const VMStateDescription vmstate_e1000 = {\n    .name = \"e1000\",\n    .version_id = 2,\n    .minimum_version_id = 1,\n    .pre_save = e1000_pre_save,\n    .post_load = e1000_post_load,\n    .fields = (VMStateField[]) {\n        VMSTATE_PCI_DEVICE(parent_obj, E1000State),\n        VMSTATE_UNUSED_TEST(is_version_1, 4), /* was instance id */\n        VMSTATE_UNUSED(4), /* Was mmio_base.  */\n        VMSTATE_UINT32(rxbuf_size, E1000State),\n        VMSTATE_UINT32(rxbuf_min_shift, E1000State),\n        VMSTATE_UINT32(eecd_state.val_in, E1000State),\n        VMSTATE_UINT16(eecd_state.bitnum_in, E1000State),\n        VMSTATE_UINT16(eecd_state.bitnum_out, E1000State),\n        VMSTATE_UINT16(eecd_state.reading, E1000State),\n        VMSTATE_UINT32(eecd_state.old_eecd, E1000State),\n        VMSTATE_UINT8(mig_props.ipcss, E1000State),\n        VMSTATE_UINT8(mig_props.ipcso, E1000State),\n        VMSTATE_UINT16(mig_props.ipcse, E1000State),\n        VMSTATE_UINT8(mig_props.tucss, E1000State),\n        VMSTATE_UINT8(mig_props.tucso, E1000State),\n        VMSTATE_UINT16(mig_props.tucse, E1000State),\n        VMSTATE_UINT32(mig_props.paylen, E1000State),\n        VMSTATE_UINT8(mig_props.hdr_len, E1000State),\n        VMSTATE_UINT16(mig_props.mss, E1000State),\n        VMSTATE_UINT16(tx.size, E1000State),\n        VMSTATE_UINT16(tx.tso_frames, E1000State),\n        VMSTATE_UINT8(tx.sum_needed, E1000State),\n        VMSTATE_INT8(mig_props.ip, E1000State),\n        VMSTATE_INT8(mig_props.tcp, E1000State),\n        VMSTATE_BUFFER(tx.header, E1000State),\n        VMSTATE_BUFFER(tx.data, E1000State),\n        VMSTATE_UINT16_ARRAY(eeprom_data, E1000State, 64),\n        VMSTATE_UINT16_ARRAY(phy_reg, E1000State, 0x20),\n        VMSTATE_UINT32(mac_reg[CTRL], E1000State),\n        VMSTATE_UINT32(mac_reg[EECD], E1000State),\n        VMSTATE_UINT32(mac_reg[EERD], E1000State),\n        VMSTATE_UINT32(mac_reg[GPRC], E1000State),\n        VMSTATE_UINT32(mac_reg[GPTC], E1000State),\n        VMSTATE_UINT32(mac_reg[ICR], E1000State),\n        VMSTATE_UINT32(mac_reg[ICS], E1000State),\n        VMSTATE_UINT32(mac_reg[IMC], E1000State),\n        VMSTATE_UINT32(mac_reg[IMS], E1000State),\n        VMSTATE_UINT32(mac_reg[LEDCTL], E1000State),\n        VMSTATE_UINT32(mac_reg[MANC], E1000State),\n        VMSTATE_UINT32(mac_reg[MDIC], E1000State),\n        VMSTATE_UINT32(mac_reg[MPC], E1000State),\n        VMSTATE_UINT32(mac_reg[PBA], E1000State),\n        VMSTATE_UINT32(mac_reg[RCTL], E1000State),\n        VMSTATE_UINT32(mac_reg[RDBAH], E1000State),\n        VMSTATE_UINT32(mac_reg[RDBAL], E1000State),\n        VMSTATE_UINT32(mac_reg[RDH], E1000State),\n        VMSTATE_UINT32(mac_reg[RDLEN], E1000State),\n        VMSTATE_UINT32(mac_reg[RDT], E1000State),\n        VMSTATE_UINT32(mac_reg[STATUS], E1000State),\n        VMSTATE_UINT32(mac_reg[SWSM], E1000State),\n        VMSTATE_UINT32(mac_reg[TCTL], E1000State),\n        VMSTATE_UINT32(mac_reg[TDBAH], E1000State),\n        VMSTATE_UINT32(mac_reg[TDBAL], E1000State),\n        VMSTATE_UINT32(mac_reg[TDH], E1000State),\n        VMSTATE_UINT32(mac_reg[TDLEN], E1000State),\n        VMSTATE_UINT32(mac_reg[TDT], E1000State),\n        VMSTATE_UINT32(mac_reg[TORH], E1000State),\n        VMSTATE_UINT32(mac_reg[TORL], E1000State),\n        VMSTATE_UINT32(mac_reg[TOTH], E1000State),\n        VMSTATE_UINT32(mac_reg[TOTL], E1000State),\n        VMSTATE_UINT32(mac_reg[TPR], E1000State),\n        VMSTATE_UINT32(mac_reg[TPT], E1000State),\n        VMSTATE_UINT32(mac_reg[TXDCTL], E1000State),\n        VMSTATE_UINT32(mac_reg[WUFC], E1000State),\n        VMSTATE_UINT32(mac_reg[VET], E1000State),\n        VMSTATE_UINT32_SUB_ARRAY(mac_reg, E1000State, RA, 32),\n        VMSTATE_UINT32_SUB_ARRAY(mac_reg, E1000State, MTA, 128),\n        VMSTATE_UINT32_SUB_ARRAY(mac_reg, E1000State, VFTA, 128),\n        VMSTATE_END_OF_LIST()\n    },\n    .subsections = (const VMStateDescription*[]) {\n        &vmstate_e1000_mit_state,\n        &vmstate_e1000_full_mac_state,\n        &vmstate_e1000_tx_tso_state,\n        NULL\n    }\n};\n\n/*\n * EEPROM contents documented in Tables 5-2 and 5-3, pp. 98-102.\n * Note: A valid DevId will be inserted during pci_e1000_realize().\n */\nstatic const uint16_t e1000_eeprom_template[64] = {\n    0x0000, 0x0000, 0x0000, 0x0000,      0xffff, 0x0000,      0x0000, 0x0000,\n    0x3000, 0x1000, 0x6403, 0 /*DevId*/, 0x8086, 0 /*DevId*/, 0x8086, 0x3040,\n    0x0008, 0x2000, 0x7e14, 0x0048,      0x1000, 0x00d8,      0x0000, 0x2700,\n    0x6cc9, 0x3150, 0x0722, 0x040b,      0x0984, 0x0000,      0xc000, 0x0706,\n    0x1008, 0x0000, 0x0f04, 0x7fff,      0x4d01, 0xffff,      0xffff, 0xffff,\n    0xffff, 0xffff, 0xffff, 0xffff,      0xffff, 0xffff,      0xffff, 0xffff,\n    0x0100, 0x4000, 0x121c, 0xffff,      0xffff, 0xffff,      0xffff, 0xffff,\n    0xffff, 0xffff, 0xffff, 0xffff,      0xffff, 0xffff,      0xffff, 0x0000,\n};\n\n/* PCI interface */\n\nstatic void\ne1000_mmio_setup(E1000State *d)\n{\n    int i;\n    const uint32_t excluded_regs[] = {\n        E1000_MDIC, E1000_ICR, E1000_ICS, E1000_IMS,\n        E1000_IMC, E1000_TCTL, E1000_TDT, PNPMMIO_SIZE\n    };\n\n    memory_region_init_io(&d->mmio, OBJECT(d), &e1000_mmio_ops, d,\n                          \"e1000-mmio\", PNPMMIO_SIZE);\n    memory_region_add_coalescing(&d->mmio, 0, excluded_regs[0]);\n    for (i = 0; excluded_regs[i] != PNPMMIO_SIZE; i++)\n        memory_region_add_coalescing(&d->mmio, excluded_regs[i] + 4,\n                                     excluded_regs[i+1] - excluded_regs[i] - 4);\n    memory_region_init_io(&d->io, OBJECT(d), &e1000_io_ops, d, \"e1000-io\", IOPORT_SIZE);\n}\n\nstatic void\npci_e1000_uninit(PCIDevice *dev)\n{\n    E1000State *d = E1000(dev);\n\n    timer_free(d->autoneg_timer);\n    timer_free(d->mit_timer);\n    timer_free(d->flush_queue_timer);\n    qemu_del_nic(d->nic);\n}\n\nstatic NetClientInfo net_e1000_info = {\n    .type = NET_CLIENT_DRIVER_NIC,\n    .size = sizeof(NICState),\n    .can_receive = e1000_can_receive,\n    .receive = e1000_receive,\n    .receive_iov = e1000_receive_iov,\n    .link_status_changed = e1000_set_link_status,\n};\n\nstatic void e1000_write_config(PCIDevice *pci_dev, uint32_t address,\n                                uint32_t val, int len)\n{\n    E1000State *s = E1000(pci_dev);\n\n    pci_default_write_config(pci_dev, address, val, len);\n\n    if (range_covers_byte(address, len, PCI_COMMAND) &&\n        (pci_dev->config[PCI_COMMAND] & PCI_COMMAND_MASTER)) {\n        qemu_flush_queued_packets(qemu_get_queue(s->nic));\n    }\n}\n\nstatic void pci_e1000_realize(PCIDevice *pci_dev, Error **errp)\n{\n    DeviceState *dev = DEVICE(pci_dev);\n    E1000State *d = E1000(pci_dev);\n    uint8_t *pci_conf;\n    uint8_t *macaddr;\n\n    pci_dev->config_write = e1000_write_config;\n\n    pci_conf = pci_dev->config;\n\n    /* TODO: RST# value should be 0, PCI spec 6.2.4 */\n    pci_conf[PCI_CACHE_LINE_SIZE] = 0x10;\n\n    pci_conf[PCI_INTERRUPT_PIN] = 1; /* interrupt pin A */\n\n    e1000_mmio_setup(d);\n\n    pci_register_bar(pci_dev, 0, PCI_BASE_ADDRESS_SPACE_MEMORY, &d->mmio);\n\n    pci_register_bar(pci_dev, 1, PCI_BASE_ADDRESS_SPACE_IO, &d->io);\n\n    qemu_macaddr_default_if_unset(&d->conf.macaddr);\n    macaddr = d->conf.macaddr.a;\n\n    e1000x_core_prepare_eeprom(d->eeprom_data,\n                               e1000_eeprom_template,\n                               sizeof(e1000_eeprom_template),\n                               PCI_DEVICE_GET_CLASS(pci_dev)->device_id,\n                               macaddr);\n\n    d->nic = qemu_new_nic(&net_e1000_info, &d->conf,\n                          object_get_typename(OBJECT(d)), dev->id, d);\n\n    qemu_format_nic_info_str(qemu_get_queue(d->nic), macaddr);\n\n    d->autoneg_timer = timer_new_ms(QEMU_CLOCK_VIRTUAL, e1000_autoneg_timer, d);\n    d->mit_timer = timer_new_ns(QEMU_CLOCK_VIRTUAL, e1000_mit_timer, d);\n    d->flush_queue_timer = timer_new_ms(QEMU_CLOCK_VIRTUAL,\n                                        e1000_flush_queue_timer, d);\n}\n\nstatic void qdev_e1000_reset(DeviceState *dev)\n{\n    E1000State *d = E1000(dev);\n    e1000_reset(d);\n}\n\nstatic Property e1000_properties[] = {\n    DEFINE_NIC_PROPERTIES(E1000State, conf),\n    DEFINE_PROP_BIT(\"autonegotiation\", E1000State,\n                    compat_flags, E1000_FLAG_AUTONEG_BIT, true),\n    DEFINE_PROP_BIT(\"mitigation\", E1000State,\n                    compat_flags, E1000_FLAG_MIT_BIT, true),\n    DEFINE_PROP_BIT(\"extra_mac_registers\", E1000State,\n                    compat_flags, E1000_FLAG_MAC_BIT, true),\n    DEFINE_PROP_BIT(\"migrate_tso_props\", E1000State,\n                    compat_flags, E1000_FLAG_TSO_BIT, true),\n    DEFINE_PROP_END_OF_LIST(),\n};\n\ntypedef struct E1000Info {\n    const char *name;\n    uint16_t   device_id;\n    uint8_t    revision;\n    uint16_t   phy_id2;\n} E1000Info;\n\nstatic void e1000_class_init(ObjectClass *klass, void *data)\n{\n    DeviceClass *dc = DEVICE_CLASS(klass);\n    PCIDeviceClass *k = PCI_DEVICE_CLASS(klass);\n    E1000BaseClass *e = E1000_CLASS(klass);\n    const E1000Info *info = data;\n\n    k->realize = pci_e1000_realize;\n    k->exit = pci_e1000_uninit;\n    k->romfile = \"efi-e1000.rom\";\n    k->vendor_id = PCI_VENDOR_ID_INTEL;\n    k->device_id = info->device_id;\n    k->revision = info->revision;\n    e->phy_id2 = info->phy_id2;\n    k->class_id = PCI_CLASS_NETWORK_ETHERNET;\n    set_bit(DEVICE_CATEGORY_NETWORK, dc->categories);\n    dc->desc = \"Intel Gigabit Ethernet\";\n    dc->reset = qdev_e1000_reset;\n    dc->vmsd = &vmstate_e1000;\n    device_class_set_props(dc, e1000_properties);\n}\n\nstatic void e1000_instance_init(Object *obj)\n{\n    E1000State *n = E1000(obj);\n    device_add_bootindex_property(obj, &n->conf.bootindex,\n                                  \"bootindex\", \"/ethernet-phy@0\",\n                                  DEVICE(n));\n}\n\nstatic const TypeInfo e1000_base_info = {\n    .name          = TYPE_E1000_BASE,\n    .parent        = TYPE_PCI_DEVICE,\n    .instance_size = sizeof(E1000State),\n    .instance_init = e1000_instance_init,\n    .class_size    = sizeof(E1000BaseClass),\n    .abstract      = true,\n    .interfaces = (InterfaceInfo[]) {\n        { INTERFACE_CONVENTIONAL_PCI_DEVICE },\n        { },\n    },\n};\n\nstatic const E1000Info e1000_devices[] = {\n    {\n        .name      = \"e1000\",\n        .device_id = E1000_DEV_ID_82540EM,\n        .revision  = 0x03,\n        .phy_id2   = E1000_PHY_ID2_8254xx_DEFAULT,\n    },\n    {\n        .name      = \"e1000-82544gc\",\n        .device_id = E1000_DEV_ID_82544GC_COPPER,\n        .revision  = 0x03,\n        .phy_id2   = E1000_PHY_ID2_82544x,\n    },\n    {\n        .name      = \"e1000-82545em\",\n        .device_id = E1000_DEV_ID_82545EM_COPPER,\n        .revision  = 0x03,\n        .phy_id2   = E1000_PHY_ID2_8254xx_DEFAULT,\n    },\n};\n\nstatic void e1000_register_types(void)\n{\n    int i;\n\n    type_register_static(&e1000_base_info);\n    for (i = 0; i < ARRAY_SIZE(e1000_devices); i++) {\n        const E1000Info *info = &e1000_devices[i];\n        TypeInfo type_info = {};\n\n        type_info.name = info->name;\n        type_info.parent = TYPE_E1000_BASE;\n        type_info.class_data = (void *)info;\n        type_info.class_init = e1000_class_init;\n\n        type_register(&type_info);\n    }\n}\n\ntype_init(e1000_register_types)\n"], "fixing_code": ["/*\n * QEMU e1000 emulation\n *\n * Software developer's manual:\n * http://download.intel.com/design/network/manuals/8254x_GBe_SDM.pdf\n *\n * Nir Peleg, Tutis Systems Ltd. for Qumranet Inc.\n * Copyright (c) 2008 Qumranet\n * Based on work done by:\n * Copyright (c) 2007 Dan Aloni\n * Copyright (c) 2004 Antony T Curtis\n *\n * This library is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * This library is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this library; if not, see <http://www.gnu.org/licenses/>.\n */\n\n\n#include \"qemu/osdep.h\"\n#include \"hw/pci/pci.h\"\n#include \"hw/qdev-properties.h\"\n#include \"migration/vmstate.h\"\n#include \"net/net.h\"\n#include \"net/checksum.h\"\n#include \"sysemu/sysemu.h\"\n#include \"sysemu/dma.h\"\n#include \"qemu/iov.h\"\n#include \"qemu/module.h\"\n#include \"qemu/range.h\"\n\n#include \"e1000x_common.h\"\n#include \"trace.h\"\n#include \"qom/object.h\"\n\nstatic const uint8_t bcast[] = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff};\n\n/* #define E1000_DEBUG */\n\n#ifdef E1000_DEBUG\nenum {\n    DEBUG_GENERAL,      DEBUG_IO,       DEBUG_MMIO,     DEBUG_INTERRUPT,\n    DEBUG_RX,           DEBUG_TX,       DEBUG_MDIC,     DEBUG_EEPROM,\n    DEBUG_UNKNOWN,      DEBUG_TXSUM,    DEBUG_TXERR,    DEBUG_RXERR,\n    DEBUG_RXFILTER,     DEBUG_PHY,      DEBUG_NOTYET,\n};\n#define DBGBIT(x)    (1<<DEBUG_##x)\nstatic int debugflags = DBGBIT(TXERR) | DBGBIT(GENERAL);\n\n#define DBGOUT(what, fmt, ...) do { \\\n    if (debugflags & DBGBIT(what)) \\\n        fprintf(stderr, \"e1000: \" fmt, ## __VA_ARGS__); \\\n    } while (0)\n#else\n#define DBGOUT(what, fmt, ...) do {} while (0)\n#endif\n\n#define IOPORT_SIZE       0x40\n#define PNPMMIO_SIZE      0x20000\n#define MIN_BUF_SIZE      60 /* Min. octets in an ethernet frame sans FCS */\n\n#define MAXIMUM_ETHERNET_HDR_LEN (14+4)\n\n/*\n * HW models:\n *  E1000_DEV_ID_82540EM works with Windows, Linux, and OS X <= 10.8\n *  E1000_DEV_ID_82544GC_COPPER appears to work; not well tested\n *  E1000_DEV_ID_82545EM_COPPER works with Linux and OS X >= 10.6\n *  Others never tested\n */\n\nstruct E1000State_st {\n    /*< private >*/\n    PCIDevice parent_obj;\n    /*< public >*/\n\n    NICState *nic;\n    NICConf conf;\n    MemoryRegion mmio;\n    MemoryRegion io;\n\n    uint32_t mac_reg[0x8000];\n    uint16_t phy_reg[0x20];\n    uint16_t eeprom_data[64];\n\n    uint32_t rxbuf_size;\n    uint32_t rxbuf_min_shift;\n    struct e1000_tx {\n        unsigned char header[256];\n        unsigned char vlan_header[4];\n        /* Fields vlan and data must not be reordered or separated. */\n        unsigned char vlan[4];\n        unsigned char data[0x10000];\n        uint16_t size;\n        unsigned char vlan_needed;\n        unsigned char sum_needed;\n        bool cptse;\n        e1000x_txd_props props;\n        e1000x_txd_props tso_props;\n        uint16_t tso_frames;\n    } tx;\n\n    struct {\n        uint32_t val_in;    /* shifted in from guest driver */\n        uint16_t bitnum_in;\n        uint16_t bitnum_out;\n        uint16_t reading;\n        uint32_t old_eecd;\n    } eecd_state;\n\n    QEMUTimer *autoneg_timer;\n\n    QEMUTimer *mit_timer;      /* Mitigation timer. */\n    bool mit_timer_on;         /* Mitigation timer is running. */\n    bool mit_irq_level;        /* Tracks interrupt pin level. */\n    uint32_t mit_ide;          /* Tracks E1000_TXD_CMD_IDE bit. */\n\n    QEMUTimer *flush_queue_timer;\n\n/* Compatibility flags for migration to/from qemu 1.3.0 and older */\n#define E1000_FLAG_AUTONEG_BIT 0\n#define E1000_FLAG_MIT_BIT 1\n#define E1000_FLAG_MAC_BIT 2\n#define E1000_FLAG_TSO_BIT 3\n#define E1000_FLAG_AUTONEG (1 << E1000_FLAG_AUTONEG_BIT)\n#define E1000_FLAG_MIT (1 << E1000_FLAG_MIT_BIT)\n#define E1000_FLAG_MAC (1 << E1000_FLAG_MAC_BIT)\n#define E1000_FLAG_TSO (1 << E1000_FLAG_TSO_BIT)\n    uint32_t compat_flags;\n    bool received_tx_tso;\n    bool use_tso_for_migration;\n    e1000x_txd_props mig_props;\n};\ntypedef struct E1000State_st E1000State;\n\n#define chkflag(x)     (s->compat_flags & E1000_FLAG_##x)\n\nstruct E1000BaseClass {\n    PCIDeviceClass parent_class;\n    uint16_t phy_id2;\n};\ntypedef struct E1000BaseClass E1000BaseClass;\n\n#define TYPE_E1000_BASE \"e1000-base\"\n\nDECLARE_OBJ_CHECKERS(E1000State, E1000BaseClass,\n                     E1000, TYPE_E1000_BASE)\n\n\nstatic void\ne1000_link_up(E1000State *s)\n{\n    e1000x_update_regs_on_link_up(s->mac_reg, s->phy_reg);\n\n    /* E1000_STATUS_LU is tested by e1000_can_receive() */\n    qemu_flush_queued_packets(qemu_get_queue(s->nic));\n}\n\nstatic void\ne1000_autoneg_done(E1000State *s)\n{\n    e1000x_update_regs_on_autoneg_done(s->mac_reg, s->phy_reg);\n\n    /* E1000_STATUS_LU is tested by e1000_can_receive() */\n    qemu_flush_queued_packets(qemu_get_queue(s->nic));\n}\n\nstatic bool\nhave_autoneg(E1000State *s)\n{\n    return chkflag(AUTONEG) && (s->phy_reg[PHY_CTRL] & MII_CR_AUTO_NEG_EN);\n}\n\nstatic void\nset_phy_ctrl(E1000State *s, int index, uint16_t val)\n{\n    /* bits 0-5 reserved; MII_CR_[RESTART_AUTO_NEG,RESET] are self clearing */\n    s->phy_reg[PHY_CTRL] = val & ~(0x3f |\n                                   MII_CR_RESET |\n                                   MII_CR_RESTART_AUTO_NEG);\n\n    /*\n     * QEMU 1.3 does not support link auto-negotiation emulation, so if we\n     * migrate during auto negotiation, after migration the link will be\n     * down.\n     */\n    if (have_autoneg(s) && (val & MII_CR_RESTART_AUTO_NEG)) {\n        e1000x_restart_autoneg(s->mac_reg, s->phy_reg, s->autoneg_timer);\n    }\n}\n\nstatic void (*phyreg_writeops[])(E1000State *, int, uint16_t) = {\n    [PHY_CTRL] = set_phy_ctrl,\n};\n\nenum { NPHYWRITEOPS = ARRAY_SIZE(phyreg_writeops) };\n\nenum { PHY_R = 1, PHY_W = 2, PHY_RW = PHY_R | PHY_W };\nstatic const char phy_regcap[0x20] = {\n    [PHY_STATUS]      = PHY_R,     [M88E1000_EXT_PHY_SPEC_CTRL] = PHY_RW,\n    [PHY_ID1]         = PHY_R,     [M88E1000_PHY_SPEC_CTRL]     = PHY_RW,\n    [PHY_CTRL]        = PHY_RW,    [PHY_1000T_CTRL]             = PHY_RW,\n    [PHY_LP_ABILITY]  = PHY_R,     [PHY_1000T_STATUS]           = PHY_R,\n    [PHY_AUTONEG_ADV] = PHY_RW,    [M88E1000_RX_ERR_CNTR]       = PHY_R,\n    [PHY_ID2]         = PHY_R,     [M88E1000_PHY_SPEC_STATUS]   = PHY_R,\n    [PHY_AUTONEG_EXP] = PHY_R,\n};\n\n/* PHY_ID2 documented in 8254x_GBe_SDM.pdf, pp. 250 */\nstatic const uint16_t phy_reg_init[] = {\n    [PHY_CTRL]   = MII_CR_SPEED_SELECT_MSB |\n                   MII_CR_FULL_DUPLEX |\n                   MII_CR_AUTO_NEG_EN,\n\n    [PHY_STATUS] = MII_SR_EXTENDED_CAPS |\n                   MII_SR_LINK_STATUS |   /* link initially up */\n                   MII_SR_AUTONEG_CAPS |\n                   /* MII_SR_AUTONEG_COMPLETE: initially NOT completed */\n                   MII_SR_PREAMBLE_SUPPRESS |\n                   MII_SR_EXTENDED_STATUS |\n                   MII_SR_10T_HD_CAPS |\n                   MII_SR_10T_FD_CAPS |\n                   MII_SR_100X_HD_CAPS |\n                   MII_SR_100X_FD_CAPS,\n\n    [PHY_ID1] = 0x141,\n    /* [PHY_ID2] configured per DevId, from e1000_reset() */\n    [PHY_AUTONEG_ADV] = 0xde1,\n    [PHY_LP_ABILITY] = 0x1e0,\n    [PHY_1000T_CTRL] = 0x0e00,\n    [PHY_1000T_STATUS] = 0x3c00,\n    [M88E1000_PHY_SPEC_CTRL] = 0x360,\n    [M88E1000_PHY_SPEC_STATUS] = 0xac00,\n    [M88E1000_EXT_PHY_SPEC_CTRL] = 0x0d60,\n};\n\nstatic const uint32_t mac_reg_init[] = {\n    [PBA]     = 0x00100030,\n    [LEDCTL]  = 0x602,\n    [CTRL]    = E1000_CTRL_SWDPIN2 | E1000_CTRL_SWDPIN0 |\n                E1000_CTRL_SPD_1000 | E1000_CTRL_SLU,\n    [STATUS]  = 0x80000000 | E1000_STATUS_GIO_MASTER_ENABLE |\n                E1000_STATUS_ASDV | E1000_STATUS_MTXCKOK |\n                E1000_STATUS_SPEED_1000 | E1000_STATUS_FD |\n                E1000_STATUS_LU,\n    [MANC]    = E1000_MANC_EN_MNG2HOST | E1000_MANC_RCV_TCO_EN |\n                E1000_MANC_ARP_EN | E1000_MANC_0298_EN |\n                E1000_MANC_RMCP_EN,\n};\n\n/* Helper function, *curr == 0 means the value is not set */\nstatic inline void\nmit_update_delay(uint32_t *curr, uint32_t value)\n{\n    if (value && (*curr == 0 || value < *curr)) {\n        *curr = value;\n    }\n}\n\nstatic void\nset_interrupt_cause(E1000State *s, int index, uint32_t val)\n{\n    PCIDevice *d = PCI_DEVICE(s);\n    uint32_t pending_ints;\n    uint32_t mit_delay;\n\n    s->mac_reg[ICR] = val;\n\n    /*\n     * Make sure ICR and ICS registers have the same value.\n     * The spec says that the ICS register is write-only.  However in practice,\n     * on real hardware ICS is readable, and for reads it has the same value as\n     * ICR (except that ICS does not have the clear on read behaviour of ICR).\n     *\n     * The VxWorks PRO/1000 driver uses this behaviour.\n     */\n    s->mac_reg[ICS] = val;\n\n    pending_ints = (s->mac_reg[IMS] & s->mac_reg[ICR]);\n    if (!s->mit_irq_level && pending_ints) {\n        /*\n         * Here we detect a potential raising edge. We postpone raising the\n         * interrupt line if we are inside the mitigation delay window\n         * (s->mit_timer_on == 1).\n         * We provide a partial implementation of interrupt mitigation,\n         * emulating only RADV, TADV and ITR (lower 16 bits, 1024ns units for\n         * RADV and TADV, 256ns units for ITR). RDTR is only used to enable\n         * RADV; relative timers based on TIDV and RDTR are not implemented.\n         */\n        if (s->mit_timer_on) {\n            return;\n        }\n        if (chkflag(MIT)) {\n            /* Compute the next mitigation delay according to pending\n             * interrupts and the current values of RADV (provided\n             * RDTR!=0), TADV and ITR.\n             * Then rearm the timer.\n             */\n            mit_delay = 0;\n            if (s->mit_ide &&\n                    (pending_ints & (E1000_ICR_TXQE | E1000_ICR_TXDW))) {\n                mit_update_delay(&mit_delay, s->mac_reg[TADV] * 4);\n            }\n            if (s->mac_reg[RDTR] && (pending_ints & E1000_ICS_RXT0)) {\n                mit_update_delay(&mit_delay, s->mac_reg[RADV] * 4);\n            }\n            mit_update_delay(&mit_delay, s->mac_reg[ITR]);\n\n            /*\n             * According to e1000 SPEC, the Ethernet controller guarantees\n             * a maximum observable interrupt rate of 7813 interrupts/sec.\n             * Thus if mit_delay < 500 then the delay should be set to the\n             * minimum delay possible which is 500.\n             */\n            mit_delay = (mit_delay < 500) ? 500 : mit_delay;\n\n            s->mit_timer_on = 1;\n            timer_mod(s->mit_timer, qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL) +\n                      mit_delay * 256);\n            s->mit_ide = 0;\n        }\n    }\n\n    s->mit_irq_level = (pending_ints != 0);\n    pci_set_irq(d, s->mit_irq_level);\n}\n\nstatic void\ne1000_mit_timer(void *opaque)\n{\n    E1000State *s = opaque;\n\n    s->mit_timer_on = 0;\n    /* Call set_interrupt_cause to update the irq level (if necessary). */\n    set_interrupt_cause(s, 0, s->mac_reg[ICR]);\n}\n\nstatic void\nset_ics(E1000State *s, int index, uint32_t val)\n{\n    DBGOUT(INTERRUPT, \"set_ics %x, ICR %x, IMR %x\\n\", val, s->mac_reg[ICR],\n        s->mac_reg[IMS]);\n    set_interrupt_cause(s, 0, val | s->mac_reg[ICR]);\n}\n\nstatic void\ne1000_autoneg_timer(void *opaque)\n{\n    E1000State *s = opaque;\n    if (!qemu_get_queue(s->nic)->link_down) {\n        e1000_autoneg_done(s);\n        set_ics(s, 0, E1000_ICS_LSC); /* signal link status change to guest */\n    }\n}\n\nstatic void e1000_reset(void *opaque)\n{\n    E1000State *d = opaque;\n    E1000BaseClass *edc = E1000_GET_CLASS(d);\n    uint8_t *macaddr = d->conf.macaddr.a;\n\n    timer_del(d->autoneg_timer);\n    timer_del(d->mit_timer);\n    timer_del(d->flush_queue_timer);\n    d->mit_timer_on = 0;\n    d->mit_irq_level = 0;\n    d->mit_ide = 0;\n    memset(d->phy_reg, 0, sizeof d->phy_reg);\n    memmove(d->phy_reg, phy_reg_init, sizeof phy_reg_init);\n    d->phy_reg[PHY_ID2] = edc->phy_id2;\n    memset(d->mac_reg, 0, sizeof d->mac_reg);\n    memmove(d->mac_reg, mac_reg_init, sizeof mac_reg_init);\n    d->rxbuf_min_shift = 1;\n    memset(&d->tx, 0, sizeof d->tx);\n\n    if (qemu_get_queue(d->nic)->link_down) {\n        e1000x_update_regs_on_link_down(d->mac_reg, d->phy_reg);\n    }\n\n    e1000x_reset_mac_addr(d->nic, d->mac_reg, macaddr);\n}\n\nstatic void\nset_ctrl(E1000State *s, int index, uint32_t val)\n{\n    /* RST is self clearing */\n    s->mac_reg[CTRL] = val & ~E1000_CTRL_RST;\n}\n\nstatic void\ne1000_flush_queue_timer(void *opaque)\n{\n    E1000State *s = opaque;\n\n    qemu_flush_queued_packets(qemu_get_queue(s->nic));\n}\n\nstatic void\nset_rx_control(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[RCTL] = val;\n    s->rxbuf_size = e1000x_rxbufsize(val);\n    s->rxbuf_min_shift = ((val / E1000_RCTL_RDMTS_QUAT) & 3) + 1;\n    DBGOUT(RX, \"RCTL: %d, mac_reg[RCTL] = 0x%x\\n\", s->mac_reg[RDT],\n           s->mac_reg[RCTL]);\n    timer_mod(s->flush_queue_timer,\n              qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL) + 1000);\n}\n\nstatic void\nset_mdic(E1000State *s, int index, uint32_t val)\n{\n    uint32_t data = val & E1000_MDIC_DATA_MASK;\n    uint32_t addr = ((val & E1000_MDIC_REG_MASK) >> E1000_MDIC_REG_SHIFT);\n\n    if ((val & E1000_MDIC_PHY_MASK) >> E1000_MDIC_PHY_SHIFT != 1) // phy #\n        val = s->mac_reg[MDIC] | E1000_MDIC_ERROR;\n    else if (val & E1000_MDIC_OP_READ) {\n        DBGOUT(MDIC, \"MDIC read reg 0x%x\\n\", addr);\n        if (!(phy_regcap[addr] & PHY_R)) {\n            DBGOUT(MDIC, \"MDIC read reg %x unhandled\\n\", addr);\n            val |= E1000_MDIC_ERROR;\n        } else\n            val = (val ^ data) | s->phy_reg[addr];\n    } else if (val & E1000_MDIC_OP_WRITE) {\n        DBGOUT(MDIC, \"MDIC write reg 0x%x, value 0x%x\\n\", addr, data);\n        if (!(phy_regcap[addr] & PHY_W)) {\n            DBGOUT(MDIC, \"MDIC write reg %x unhandled\\n\", addr);\n            val |= E1000_MDIC_ERROR;\n        } else {\n            if (addr < NPHYWRITEOPS && phyreg_writeops[addr]) {\n                phyreg_writeops[addr](s, index, data);\n            } else {\n                s->phy_reg[addr] = data;\n            }\n        }\n    }\n    s->mac_reg[MDIC] = val | E1000_MDIC_READY;\n\n    if (val & E1000_MDIC_INT_EN) {\n        set_ics(s, 0, E1000_ICR_MDAC);\n    }\n}\n\nstatic uint32_t\nget_eecd(E1000State *s, int index)\n{\n    uint32_t ret = E1000_EECD_PRES|E1000_EECD_GNT | s->eecd_state.old_eecd;\n\n    DBGOUT(EEPROM, \"reading eeprom bit %d (reading %d)\\n\",\n           s->eecd_state.bitnum_out, s->eecd_state.reading);\n    if (!s->eecd_state.reading ||\n        ((s->eeprom_data[(s->eecd_state.bitnum_out >> 4) & 0x3f] >>\n          ((s->eecd_state.bitnum_out & 0xf) ^ 0xf))) & 1)\n        ret |= E1000_EECD_DO;\n    return ret;\n}\n\nstatic void\nset_eecd(E1000State *s, int index, uint32_t val)\n{\n    uint32_t oldval = s->eecd_state.old_eecd;\n\n    s->eecd_state.old_eecd = val & (E1000_EECD_SK | E1000_EECD_CS |\n            E1000_EECD_DI|E1000_EECD_FWE_MASK|E1000_EECD_REQ);\n    if (!(E1000_EECD_CS & val)) {            /* CS inactive; nothing to do */\n        return;\n    }\n    if (E1000_EECD_CS & (val ^ oldval)) {    /* CS rise edge; reset state */\n        s->eecd_state.val_in = 0;\n        s->eecd_state.bitnum_in = 0;\n        s->eecd_state.bitnum_out = 0;\n        s->eecd_state.reading = 0;\n    }\n    if (!(E1000_EECD_SK & (val ^ oldval))) {    /* no clock edge */\n        return;\n    }\n    if (!(E1000_EECD_SK & val)) {               /* falling edge */\n        s->eecd_state.bitnum_out++;\n        return;\n    }\n    s->eecd_state.val_in <<= 1;\n    if (val & E1000_EECD_DI)\n        s->eecd_state.val_in |= 1;\n    if (++s->eecd_state.bitnum_in == 9 && !s->eecd_state.reading) {\n        s->eecd_state.bitnum_out = ((s->eecd_state.val_in & 0x3f)<<4)-1;\n        s->eecd_state.reading = (((s->eecd_state.val_in >> 6) & 7) ==\n            EEPROM_READ_OPCODE_MICROWIRE);\n    }\n    DBGOUT(EEPROM, \"eeprom bitnum in %d out %d, reading %d\\n\",\n           s->eecd_state.bitnum_in, s->eecd_state.bitnum_out,\n           s->eecd_state.reading);\n}\n\nstatic uint32_t\nflash_eerd_read(E1000State *s, int x)\n{\n    unsigned int index, r = s->mac_reg[EERD] & ~E1000_EEPROM_RW_REG_START;\n\n    if ((s->mac_reg[EERD] & E1000_EEPROM_RW_REG_START) == 0)\n        return (s->mac_reg[EERD]);\n\n    if ((index = r >> E1000_EEPROM_RW_ADDR_SHIFT) > EEPROM_CHECKSUM_REG)\n        return (E1000_EEPROM_RW_REG_DONE | r);\n\n    return ((s->eeprom_data[index] << E1000_EEPROM_RW_REG_DATA) |\n           E1000_EEPROM_RW_REG_DONE | r);\n}\n\nstatic void\nputsum(uint8_t *data, uint32_t n, uint32_t sloc, uint32_t css, uint32_t cse)\n{\n    uint32_t sum;\n\n    if (cse && cse < n)\n        n = cse + 1;\n    if (sloc < n-1) {\n        sum = net_checksum_add(n-css, data+css);\n        stw_be_p(data + sloc, net_checksum_finish_nozero(sum));\n    }\n}\n\nstatic inline void\ninc_tx_bcast_or_mcast_count(E1000State *s, const unsigned char *arr)\n{\n    if (!memcmp(arr, bcast, sizeof bcast)) {\n        e1000x_inc_reg_if_not_full(s->mac_reg, BPTC);\n    } else if (arr[0] & 1) {\n        e1000x_inc_reg_if_not_full(s->mac_reg, MPTC);\n    }\n}\n\nstatic void\ne1000_send_packet(E1000State *s, const uint8_t *buf, int size)\n{\n    static const int PTCregs[6] = { PTC64, PTC127, PTC255, PTC511,\n                                    PTC1023, PTC1522 };\n\n    NetClientState *nc = qemu_get_queue(s->nic);\n    if (s->phy_reg[PHY_CTRL] & MII_CR_LOOPBACK) {\n        nc->info->receive(nc, buf, size);\n    } else {\n        qemu_send_packet(nc, buf, size);\n    }\n    inc_tx_bcast_or_mcast_count(s, buf);\n    e1000x_increase_size_stats(s->mac_reg, PTCregs, size);\n}\n\nstatic void\nxmit_seg(E1000State *s)\n{\n    uint16_t len;\n    unsigned int frames = s->tx.tso_frames, css, sofar;\n    struct e1000_tx *tp = &s->tx;\n    struct e1000x_txd_props *props = tp->cptse ? &tp->tso_props : &tp->props;\n\n    if (tp->cptse) {\n        css = props->ipcss;\n        DBGOUT(TXSUM, \"frames %d size %d ipcss %d\\n\",\n               frames, tp->size, css);\n        if (props->ip) {    /* IPv4 */\n            stw_be_p(tp->data+css+2, tp->size - css);\n            stw_be_p(tp->data+css+4,\n                     lduw_be_p(tp->data + css + 4) + frames);\n        } else {         /* IPv6 */\n            stw_be_p(tp->data+css+4, tp->size - css);\n        }\n        css = props->tucss;\n        len = tp->size - css;\n        DBGOUT(TXSUM, \"tcp %d tucss %d len %d\\n\", props->tcp, css, len);\n        if (props->tcp) {\n            sofar = frames * props->mss;\n            stl_be_p(tp->data+css+4, ldl_be_p(tp->data+css+4)+sofar); /* seq */\n            if (props->paylen - sofar > props->mss) {\n                tp->data[css + 13] &= ~9;    /* PSH, FIN */\n            } else if (frames) {\n                e1000x_inc_reg_if_not_full(s->mac_reg, TSCTC);\n            }\n        } else {    /* UDP */\n            stw_be_p(tp->data+css+4, len);\n        }\n        if (tp->sum_needed & E1000_TXD_POPTS_TXSM) {\n            unsigned int phsum;\n            // add pseudo-header length before checksum calculation\n            void *sp = tp->data + props->tucso;\n\n            phsum = lduw_be_p(sp) + len;\n            phsum = (phsum >> 16) + (phsum & 0xffff);\n            stw_be_p(sp, phsum);\n        }\n        tp->tso_frames++;\n    }\n\n    if (tp->sum_needed & E1000_TXD_POPTS_TXSM) {\n        putsum(tp->data, tp->size, props->tucso, props->tucss, props->tucse);\n    }\n    if (tp->sum_needed & E1000_TXD_POPTS_IXSM) {\n        putsum(tp->data, tp->size, props->ipcso, props->ipcss, props->ipcse);\n    }\n    if (tp->vlan_needed) {\n        memmove(tp->vlan, tp->data, 4);\n        memmove(tp->data, tp->data + 4, 8);\n        memcpy(tp->data + 8, tp->vlan_header, 4);\n        e1000_send_packet(s, tp->vlan, tp->size + 4);\n    } else {\n        e1000_send_packet(s, tp->data, tp->size);\n    }\n\n    e1000x_inc_reg_if_not_full(s->mac_reg, TPT);\n    e1000x_grow_8reg_if_not_full(s->mac_reg, TOTL, s->tx.size);\n    s->mac_reg[GPTC] = s->mac_reg[TPT];\n    s->mac_reg[GOTCL] = s->mac_reg[TOTL];\n    s->mac_reg[GOTCH] = s->mac_reg[TOTH];\n}\n\nstatic void\nprocess_tx_desc(E1000State *s, struct e1000_tx_desc *dp)\n{\n    PCIDevice *d = PCI_DEVICE(s);\n    uint32_t txd_lower = le32_to_cpu(dp->lower.data);\n    uint32_t dtype = txd_lower & (E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D);\n    unsigned int split_size = txd_lower & 0xffff, bytes, sz;\n    unsigned int msh = 0xfffff;\n    uint64_t addr;\n    struct e1000_context_desc *xp = (struct e1000_context_desc *)dp;\n    struct e1000_tx *tp = &s->tx;\n\n    s->mit_ide |= (txd_lower & E1000_TXD_CMD_IDE);\n    if (dtype == E1000_TXD_CMD_DEXT) {    /* context descriptor */\n        if (le32_to_cpu(xp->cmd_and_length) & E1000_TXD_CMD_TSE) {\n            e1000x_read_tx_ctx_descr(xp, &tp->tso_props);\n            s->use_tso_for_migration = 1;\n            tp->tso_frames = 0;\n        } else {\n            e1000x_read_tx_ctx_descr(xp, &tp->props);\n            s->use_tso_for_migration = 0;\n        }\n        return;\n    } else if (dtype == (E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D)) {\n        // data descriptor\n        if (tp->size == 0) {\n            tp->sum_needed = le32_to_cpu(dp->upper.data) >> 8;\n        }\n        tp->cptse = (txd_lower & E1000_TXD_CMD_TSE) ? 1 : 0;\n    } else {\n        // legacy descriptor\n        tp->cptse = 0;\n    }\n\n    if (e1000x_vlan_enabled(s->mac_reg) &&\n        e1000x_is_vlan_txd(txd_lower) &&\n        (tp->cptse || txd_lower & E1000_TXD_CMD_EOP)) {\n        tp->vlan_needed = 1;\n        stw_be_p(tp->vlan_header,\n                      le16_to_cpu(s->mac_reg[VET]));\n        stw_be_p(tp->vlan_header + 2,\n                      le16_to_cpu(dp->upper.fields.special));\n    }\n\n    addr = le64_to_cpu(dp->buffer_addr);\n    if (tp->cptse) {\n        msh = tp->tso_props.hdr_len + tp->tso_props.mss;\n        do {\n            bytes = split_size;\n            if (tp->size >= msh) {\n                goto eop;\n            }\n            if (tp->size + bytes > msh)\n                bytes = msh - tp->size;\n\n            bytes = MIN(sizeof(tp->data) - tp->size, bytes);\n            pci_dma_read(d, addr, tp->data + tp->size, bytes);\n            sz = tp->size + bytes;\n            if (sz >= tp->tso_props.hdr_len\n                && tp->size < tp->tso_props.hdr_len) {\n                memmove(tp->header, tp->data, tp->tso_props.hdr_len);\n            }\n            tp->size = sz;\n            addr += bytes;\n            if (sz == msh) {\n                xmit_seg(s);\n                memmove(tp->data, tp->header, tp->tso_props.hdr_len);\n                tp->size = tp->tso_props.hdr_len;\n            }\n            split_size -= bytes;\n        } while (bytes && split_size);\n    } else {\n        split_size = MIN(sizeof(tp->data) - tp->size, split_size);\n        pci_dma_read(d, addr, tp->data + tp->size, split_size);\n        tp->size += split_size;\n    }\n\neop:\n    if (!(txd_lower & E1000_TXD_CMD_EOP))\n        return;\n    if (!(tp->cptse && tp->size < tp->tso_props.hdr_len)) {\n        xmit_seg(s);\n    }\n    tp->tso_frames = 0;\n    tp->sum_needed = 0;\n    tp->vlan_needed = 0;\n    tp->size = 0;\n    tp->cptse = 0;\n}\n\nstatic uint32_t\ntxdesc_writeback(E1000State *s, dma_addr_t base, struct e1000_tx_desc *dp)\n{\n    PCIDevice *d = PCI_DEVICE(s);\n    uint32_t txd_upper, txd_lower = le32_to_cpu(dp->lower.data);\n\n    if (!(txd_lower & (E1000_TXD_CMD_RS|E1000_TXD_CMD_RPS)))\n        return 0;\n    txd_upper = (le32_to_cpu(dp->upper.data) | E1000_TXD_STAT_DD) &\n                ~(E1000_TXD_STAT_EC | E1000_TXD_STAT_LC | E1000_TXD_STAT_TU);\n    dp->upper.data = cpu_to_le32(txd_upper);\n    pci_dma_write(d, base + ((char *)&dp->upper - (char *)dp),\n                  &dp->upper, sizeof(dp->upper));\n    return E1000_ICR_TXDW;\n}\n\nstatic uint64_t tx_desc_base(E1000State *s)\n{\n    uint64_t bah = s->mac_reg[TDBAH];\n    uint64_t bal = s->mac_reg[TDBAL] & ~0xf;\n\n    return (bah << 32) + bal;\n}\n\nstatic void\nstart_xmit(E1000State *s)\n{\n    PCIDevice *d = PCI_DEVICE(s);\n    dma_addr_t base;\n    struct e1000_tx_desc desc;\n    uint32_t tdh_start = s->mac_reg[TDH], cause = E1000_ICS_TXQE;\n\n    if (!(s->mac_reg[TCTL] & E1000_TCTL_EN)) {\n        DBGOUT(TX, \"tx disabled\\n\");\n        return;\n    }\n\n    while (s->mac_reg[TDH] != s->mac_reg[TDT]) {\n        base = tx_desc_base(s) +\n               sizeof(struct e1000_tx_desc) * s->mac_reg[TDH];\n        pci_dma_read(d, base, &desc, sizeof(desc));\n\n        DBGOUT(TX, \"index %d: %p : %x %x\\n\", s->mac_reg[TDH],\n               (void *)(intptr_t)desc.buffer_addr, desc.lower.data,\n               desc.upper.data);\n\n        process_tx_desc(s, &desc);\n        cause |= txdesc_writeback(s, base, &desc);\n\n        if (++s->mac_reg[TDH] * sizeof(desc) >= s->mac_reg[TDLEN])\n            s->mac_reg[TDH] = 0;\n        /*\n         * the following could happen only if guest sw assigns\n         * bogus values to TDT/TDLEN.\n         * there's nothing too intelligent we could do about this.\n         */\n        if (s->mac_reg[TDH] == tdh_start ||\n            tdh_start >= s->mac_reg[TDLEN] / sizeof(desc)) {\n            DBGOUT(TXERR, \"TDH wraparound @%x, TDT %x, TDLEN %x\\n\",\n                   tdh_start, s->mac_reg[TDT], s->mac_reg[TDLEN]);\n            break;\n        }\n    }\n    set_ics(s, 0, cause);\n}\n\nstatic int\nreceive_filter(E1000State *s, const uint8_t *buf, int size)\n{\n    uint32_t rctl = s->mac_reg[RCTL];\n    int isbcast = !memcmp(buf, bcast, sizeof bcast), ismcast = (buf[0] & 1);\n\n    if (e1000x_is_vlan_packet(buf, le16_to_cpu(s->mac_reg[VET])) &&\n        e1000x_vlan_rx_filter_enabled(s->mac_reg)) {\n        uint16_t vid = lduw_be_p(buf + 14);\n        uint32_t vfta = ldl_le_p((uint32_t*)(s->mac_reg + VFTA) +\n                                 ((vid >> 5) & 0x7f));\n        if ((vfta & (1 << (vid & 0x1f))) == 0)\n            return 0;\n    }\n\n    if (!isbcast && !ismcast && (rctl & E1000_RCTL_UPE)) { /* promiscuous ucast */\n        return 1;\n    }\n\n    if (ismcast && (rctl & E1000_RCTL_MPE)) {          /* promiscuous mcast */\n        e1000x_inc_reg_if_not_full(s->mac_reg, MPRC);\n        return 1;\n    }\n\n    if (isbcast && (rctl & E1000_RCTL_BAM)) {          /* broadcast enabled */\n        e1000x_inc_reg_if_not_full(s->mac_reg, BPRC);\n        return 1;\n    }\n\n    return e1000x_rx_group_filter(s->mac_reg, buf);\n}\n\nstatic void\ne1000_set_link_status(NetClientState *nc)\n{\n    E1000State *s = qemu_get_nic_opaque(nc);\n    uint32_t old_status = s->mac_reg[STATUS];\n\n    if (nc->link_down) {\n        e1000x_update_regs_on_link_down(s->mac_reg, s->phy_reg);\n    } else {\n        if (have_autoneg(s) &&\n            !(s->phy_reg[PHY_STATUS] & MII_SR_AUTONEG_COMPLETE)) {\n            e1000x_restart_autoneg(s->mac_reg, s->phy_reg, s->autoneg_timer);\n        } else {\n            e1000_link_up(s);\n        }\n    }\n\n    if (s->mac_reg[STATUS] != old_status)\n        set_ics(s, 0, E1000_ICR_LSC);\n}\n\nstatic bool e1000_has_rxbufs(E1000State *s, size_t total_size)\n{\n    int bufs;\n    /* Fast-path short packets */\n    if (total_size <= s->rxbuf_size) {\n        return s->mac_reg[RDH] != s->mac_reg[RDT];\n    }\n    if (s->mac_reg[RDH] < s->mac_reg[RDT]) {\n        bufs = s->mac_reg[RDT] - s->mac_reg[RDH];\n    } else if (s->mac_reg[RDH] > s->mac_reg[RDT]) {\n        bufs = s->mac_reg[RDLEN] /  sizeof(struct e1000_rx_desc) +\n            s->mac_reg[RDT] - s->mac_reg[RDH];\n    } else {\n        return false;\n    }\n    return total_size <= bufs * s->rxbuf_size;\n}\n\nstatic bool\ne1000_can_receive(NetClientState *nc)\n{\n    E1000State *s = qemu_get_nic_opaque(nc);\n\n    return e1000x_rx_ready(&s->parent_obj, s->mac_reg) &&\n        e1000_has_rxbufs(s, 1) && !timer_pending(s->flush_queue_timer);\n}\n\nstatic uint64_t rx_desc_base(E1000State *s)\n{\n    uint64_t bah = s->mac_reg[RDBAH];\n    uint64_t bal = s->mac_reg[RDBAL] & ~0xf;\n\n    return (bah << 32) + bal;\n}\n\nstatic void\ne1000_receiver_overrun(E1000State *s, size_t size)\n{\n    trace_e1000_receiver_overrun(size, s->mac_reg[RDH], s->mac_reg[RDT]);\n    e1000x_inc_reg_if_not_full(s->mac_reg, RNBC);\n    e1000x_inc_reg_if_not_full(s->mac_reg, MPC);\n    set_ics(s, 0, E1000_ICS_RXO);\n}\n\nstatic ssize_t\ne1000_receive_iov(NetClientState *nc, const struct iovec *iov, int iovcnt)\n{\n    E1000State *s = qemu_get_nic_opaque(nc);\n    PCIDevice *d = PCI_DEVICE(s);\n    struct e1000_rx_desc desc;\n    dma_addr_t base;\n    unsigned int n, rdt;\n    uint32_t rdh_start;\n    uint16_t vlan_special = 0;\n    uint8_t vlan_status = 0;\n    uint8_t min_buf[MIN_BUF_SIZE];\n    struct iovec min_iov;\n    uint8_t *filter_buf = iov->iov_base;\n    size_t size = iov_size(iov, iovcnt);\n    size_t iov_ofs = 0;\n    size_t desc_offset;\n    size_t desc_size;\n    size_t total_size;\n\n    if (!e1000x_hw_rx_enabled(s->mac_reg)) {\n        return -1;\n    }\n\n    if (timer_pending(s->flush_queue_timer)) {\n        return 0;\n    }\n\n    /* Pad to minimum Ethernet frame length */\n    if (size < sizeof(min_buf)) {\n        iov_to_buf(iov, iovcnt, 0, min_buf, size);\n        memset(&min_buf[size], 0, sizeof(min_buf) - size);\n        min_iov.iov_base = filter_buf = min_buf;\n        min_iov.iov_len = size = sizeof(min_buf);\n        iovcnt = 1;\n        iov = &min_iov;\n    } else if (iov->iov_len < MAXIMUM_ETHERNET_HDR_LEN) {\n        /* This is very unlikely, but may happen. */\n        iov_to_buf(iov, iovcnt, 0, min_buf, MAXIMUM_ETHERNET_HDR_LEN);\n        filter_buf = min_buf;\n    }\n\n    /* Discard oversized packets if !LPE and !SBP. */\n    if (e1000x_is_oversized(s->mac_reg, size)) {\n        return size;\n    }\n\n    if (!receive_filter(s, filter_buf, size)) {\n        return size;\n    }\n\n    if (e1000x_vlan_enabled(s->mac_reg) &&\n        e1000x_is_vlan_packet(filter_buf, le16_to_cpu(s->mac_reg[VET]))) {\n        vlan_special = cpu_to_le16(lduw_be_p(filter_buf + 14));\n        iov_ofs = 4;\n        if (filter_buf == iov->iov_base) {\n            memmove(filter_buf + 4, filter_buf, 12);\n        } else {\n            iov_from_buf(iov, iovcnt, 4, filter_buf, 12);\n            while (iov->iov_len <= iov_ofs) {\n                iov_ofs -= iov->iov_len;\n                iov++;\n            }\n        }\n        vlan_status = E1000_RXD_STAT_VP;\n        size -= 4;\n    }\n\n    rdh_start = s->mac_reg[RDH];\n    desc_offset = 0;\n    total_size = size + e1000x_fcs_len(s->mac_reg);\n    if (!e1000_has_rxbufs(s, total_size)) {\n        e1000_receiver_overrun(s, total_size);\n        return -1;\n    }\n    do {\n        desc_size = total_size - desc_offset;\n        if (desc_size > s->rxbuf_size) {\n            desc_size = s->rxbuf_size;\n        }\n        base = rx_desc_base(s) + sizeof(desc) * s->mac_reg[RDH];\n        pci_dma_read(d, base, &desc, sizeof(desc));\n        desc.special = vlan_special;\n        desc.status |= (vlan_status | E1000_RXD_STAT_DD);\n        if (desc.buffer_addr) {\n            if (desc_offset < size) {\n                size_t iov_copy;\n                hwaddr ba = le64_to_cpu(desc.buffer_addr);\n                size_t copy_size = size - desc_offset;\n                if (copy_size > s->rxbuf_size) {\n                    copy_size = s->rxbuf_size;\n                }\n                do {\n                    iov_copy = MIN(copy_size, iov->iov_len - iov_ofs);\n                    pci_dma_write(d, ba, iov->iov_base + iov_ofs, iov_copy);\n                    copy_size -= iov_copy;\n                    ba += iov_copy;\n                    iov_ofs += iov_copy;\n                    if (iov_ofs == iov->iov_len) {\n                        iov++;\n                        iov_ofs = 0;\n                    }\n                } while (copy_size);\n            }\n            desc_offset += desc_size;\n            desc.length = cpu_to_le16(desc_size);\n            if (desc_offset >= total_size) {\n                desc.status |= E1000_RXD_STAT_EOP | E1000_RXD_STAT_IXSM;\n            } else {\n                /* Guest zeroing out status is not a hardware requirement.\n                   Clear EOP in case guest didn't do it. */\n                desc.status &= ~E1000_RXD_STAT_EOP;\n            }\n        } else { // as per intel docs; skip descriptors with null buf addr\n            DBGOUT(RX, \"Null RX descriptor!!\\n\");\n        }\n        pci_dma_write(d, base, &desc, sizeof(desc));\n\n        if (++s->mac_reg[RDH] * sizeof(desc) >= s->mac_reg[RDLEN])\n            s->mac_reg[RDH] = 0;\n        /* see comment in start_xmit; same here */\n        if (s->mac_reg[RDH] == rdh_start ||\n            rdh_start >= s->mac_reg[RDLEN] / sizeof(desc)) {\n            DBGOUT(RXERR, \"RDH wraparound @%x, RDT %x, RDLEN %x\\n\",\n                   rdh_start, s->mac_reg[RDT], s->mac_reg[RDLEN]);\n            e1000_receiver_overrun(s, total_size);\n            return -1;\n        }\n    } while (desc_offset < total_size);\n\n    e1000x_update_rx_total_stats(s->mac_reg, size, total_size);\n\n    n = E1000_ICS_RXT0;\n    if ((rdt = s->mac_reg[RDT]) < s->mac_reg[RDH])\n        rdt += s->mac_reg[RDLEN] / sizeof(desc);\n    if (((rdt - s->mac_reg[RDH]) * sizeof(desc)) <= s->mac_reg[RDLEN] >>\n        s->rxbuf_min_shift)\n        n |= E1000_ICS_RXDMT0;\n\n    set_ics(s, 0, n);\n\n    return size;\n}\n\nstatic ssize_t\ne1000_receive(NetClientState *nc, const uint8_t *buf, size_t size)\n{\n    const struct iovec iov = {\n        .iov_base = (uint8_t *)buf,\n        .iov_len = size\n    };\n\n    return e1000_receive_iov(nc, &iov, 1);\n}\n\nstatic uint32_t\nmac_readreg(E1000State *s, int index)\n{\n    return s->mac_reg[index];\n}\n\nstatic uint32_t\nmac_low4_read(E1000State *s, int index)\n{\n    return s->mac_reg[index] & 0xf;\n}\n\nstatic uint32_t\nmac_low11_read(E1000State *s, int index)\n{\n    return s->mac_reg[index] & 0x7ff;\n}\n\nstatic uint32_t\nmac_low13_read(E1000State *s, int index)\n{\n    return s->mac_reg[index] & 0x1fff;\n}\n\nstatic uint32_t\nmac_low16_read(E1000State *s, int index)\n{\n    return s->mac_reg[index] & 0xffff;\n}\n\nstatic uint32_t\nmac_icr_read(E1000State *s, int index)\n{\n    uint32_t ret = s->mac_reg[ICR];\n\n    DBGOUT(INTERRUPT, \"ICR read: %x\\n\", ret);\n    set_interrupt_cause(s, 0, 0);\n    return ret;\n}\n\nstatic uint32_t\nmac_read_clr4(E1000State *s, int index)\n{\n    uint32_t ret = s->mac_reg[index];\n\n    s->mac_reg[index] = 0;\n    return ret;\n}\n\nstatic uint32_t\nmac_read_clr8(E1000State *s, int index)\n{\n    uint32_t ret = s->mac_reg[index];\n\n    s->mac_reg[index] = 0;\n    s->mac_reg[index-1] = 0;\n    return ret;\n}\n\nstatic void\nmac_writereg(E1000State *s, int index, uint32_t val)\n{\n    uint32_t macaddr[2];\n\n    s->mac_reg[index] = val;\n\n    if (index == RA + 1) {\n        macaddr[0] = cpu_to_le32(s->mac_reg[RA]);\n        macaddr[1] = cpu_to_le32(s->mac_reg[RA + 1]);\n        qemu_format_nic_info_str(qemu_get_queue(s->nic), (uint8_t *)macaddr);\n    }\n}\n\nstatic void\nset_rdt(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[index] = val & 0xffff;\n    if (e1000_has_rxbufs(s, 1)) {\n        qemu_flush_queued_packets(qemu_get_queue(s->nic));\n    }\n}\n\nstatic void\nset_16bit(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[index] = val & 0xffff;\n}\n\nstatic void\nset_dlen(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[index] = val & 0xfff80;\n}\n\nstatic void\nset_tctl(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[index] = val;\n    s->mac_reg[TDT] &= 0xffff;\n    start_xmit(s);\n}\n\nstatic void\nset_icr(E1000State *s, int index, uint32_t val)\n{\n    DBGOUT(INTERRUPT, \"set_icr %x\\n\", val);\n    set_interrupt_cause(s, 0, s->mac_reg[ICR] & ~val);\n}\n\nstatic void\nset_imc(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[IMS] &= ~val;\n    set_ics(s, 0, 0);\n}\n\nstatic void\nset_ims(E1000State *s, int index, uint32_t val)\n{\n    s->mac_reg[IMS] |= val;\n    set_ics(s, 0, 0);\n}\n\n#define getreg(x)    [x] = mac_readreg\ntypedef uint32_t (*readops)(E1000State *, int);\nstatic const readops macreg_readops[] = {\n    getreg(PBA),      getreg(RCTL),     getreg(TDH),      getreg(TXDCTL),\n    getreg(WUFC),     getreg(TDT),      getreg(CTRL),     getreg(LEDCTL),\n    getreg(MANC),     getreg(MDIC),     getreg(SWSM),     getreg(STATUS),\n    getreg(TORL),     getreg(TOTL),     getreg(IMS),      getreg(TCTL),\n    getreg(RDH),      getreg(RDT),      getreg(VET),      getreg(ICS),\n    getreg(TDBAL),    getreg(TDBAH),    getreg(RDBAH),    getreg(RDBAL),\n    getreg(TDLEN),    getreg(RDLEN),    getreg(RDTR),     getreg(RADV),\n    getreg(TADV),     getreg(ITR),      getreg(FCRUC),    getreg(IPAV),\n    getreg(WUC),      getreg(WUS),      getreg(SCC),      getreg(ECOL),\n    getreg(MCC),      getreg(LATECOL),  getreg(COLC),     getreg(DC),\n    getreg(TNCRS),    getreg(SEQEC),    getreg(CEXTERR),  getreg(RLEC),\n    getreg(XONRXC),   getreg(XONTXC),   getreg(XOFFRXC),  getreg(XOFFTXC),\n    getreg(RFC),      getreg(RJC),      getreg(RNBC),     getreg(TSCTFC),\n    getreg(MGTPRC),   getreg(MGTPDC),   getreg(MGTPTC),   getreg(GORCL),\n    getreg(GOTCL),\n\n    [TOTH]    = mac_read_clr8,      [TORH]    = mac_read_clr8,\n    [GOTCH]   = mac_read_clr8,      [GORCH]   = mac_read_clr8,\n    [PRC64]   = mac_read_clr4,      [PRC127]  = mac_read_clr4,\n    [PRC255]  = mac_read_clr4,      [PRC511]  = mac_read_clr4,\n    [PRC1023] = mac_read_clr4,      [PRC1522] = mac_read_clr4,\n    [PTC64]   = mac_read_clr4,      [PTC127]  = mac_read_clr4,\n    [PTC255]  = mac_read_clr4,      [PTC511]  = mac_read_clr4,\n    [PTC1023] = mac_read_clr4,      [PTC1522] = mac_read_clr4,\n    [GPRC]    = mac_read_clr4,      [GPTC]    = mac_read_clr4,\n    [TPT]     = mac_read_clr4,      [TPR]     = mac_read_clr4,\n    [RUC]     = mac_read_clr4,      [ROC]     = mac_read_clr4,\n    [BPRC]    = mac_read_clr4,      [MPRC]    = mac_read_clr4,\n    [TSCTC]   = mac_read_clr4,      [BPTC]    = mac_read_clr4,\n    [MPTC]    = mac_read_clr4,\n    [ICR]     = mac_icr_read,       [EECD]    = get_eecd,\n    [EERD]    = flash_eerd_read,\n    [RDFH]    = mac_low13_read,     [RDFT]    = mac_low13_read,\n    [RDFHS]   = mac_low13_read,     [RDFTS]   = mac_low13_read,\n    [RDFPC]   = mac_low13_read,\n    [TDFH]    = mac_low11_read,     [TDFT]    = mac_low11_read,\n    [TDFHS]   = mac_low13_read,     [TDFTS]   = mac_low13_read,\n    [TDFPC]   = mac_low13_read,\n    [AIT]     = mac_low16_read,\n\n    [CRCERRS ... MPC]   = &mac_readreg,\n    [IP6AT ... IP6AT+3] = &mac_readreg,    [IP4AT ... IP4AT+6] = &mac_readreg,\n    [FFLT ... FFLT+6]   = &mac_low11_read,\n    [RA ... RA+31]      = &mac_readreg,\n    [WUPM ... WUPM+31]  = &mac_readreg,\n    [MTA ... MTA+127]   = &mac_readreg,\n    [VFTA ... VFTA+127] = &mac_readreg,\n    [FFMT ... FFMT+254] = &mac_low4_read,\n    [FFVT ... FFVT+254] = &mac_readreg,\n    [PBM ... PBM+16383] = &mac_readreg,\n};\nenum { NREADOPS = ARRAY_SIZE(macreg_readops) };\n\n#define putreg(x)    [x] = mac_writereg\ntypedef void (*writeops)(E1000State *, int, uint32_t);\nstatic const writeops macreg_writeops[] = {\n    putreg(PBA),      putreg(EERD),     putreg(SWSM),     putreg(WUFC),\n    putreg(TDBAL),    putreg(TDBAH),    putreg(TXDCTL),   putreg(RDBAH),\n    putreg(RDBAL),    putreg(LEDCTL),   putreg(VET),      putreg(FCRUC),\n    putreg(TDFH),     putreg(TDFT),     putreg(TDFHS),    putreg(TDFTS),\n    putreg(TDFPC),    putreg(RDFH),     putreg(RDFT),     putreg(RDFHS),\n    putreg(RDFTS),    putreg(RDFPC),    putreg(IPAV),     putreg(WUC),\n    putreg(WUS),      putreg(AIT),\n\n    [TDLEN]  = set_dlen,   [RDLEN]  = set_dlen,       [TCTL] = set_tctl,\n    [TDT]    = set_tctl,   [MDIC]   = set_mdic,       [ICS]  = set_ics,\n    [TDH]    = set_16bit,  [RDH]    = set_16bit,      [RDT]  = set_rdt,\n    [IMC]    = set_imc,    [IMS]    = set_ims,        [ICR]  = set_icr,\n    [EECD]   = set_eecd,   [RCTL]   = set_rx_control, [CTRL] = set_ctrl,\n    [RDTR]   = set_16bit,  [RADV]   = set_16bit,      [TADV] = set_16bit,\n    [ITR]    = set_16bit,\n\n    [IP6AT ... IP6AT+3] = &mac_writereg, [IP4AT ... IP4AT+6] = &mac_writereg,\n    [FFLT ... FFLT+6]   = &mac_writereg,\n    [RA ... RA+31]      = &mac_writereg,\n    [WUPM ... WUPM+31]  = &mac_writereg,\n    [MTA ... MTA+127]   = &mac_writereg,\n    [VFTA ... VFTA+127] = &mac_writereg,\n    [FFMT ... FFMT+254] = &mac_writereg, [FFVT ... FFVT+254] = &mac_writereg,\n    [PBM ... PBM+16383] = &mac_writereg,\n};\n\nenum { NWRITEOPS = ARRAY_SIZE(macreg_writeops) };\n\nenum { MAC_ACCESS_PARTIAL = 1, MAC_ACCESS_FLAG_NEEDED = 2 };\n\n#define markflag(x)    ((E1000_FLAG_##x << 2) | MAC_ACCESS_FLAG_NEEDED)\n/* In the array below the meaning of the bits is: [f|f|f|f|f|f|n|p]\n * f - flag bits (up to 6 possible flags)\n * n - flag needed\n * p - partially implenented */\nstatic const uint8_t mac_reg_access[0x8000] = {\n    [RDTR]    = markflag(MIT),    [TADV]    = markflag(MIT),\n    [RADV]    = markflag(MIT),    [ITR]     = markflag(MIT),\n\n    [IPAV]    = markflag(MAC),    [WUC]     = markflag(MAC),\n    [IP6AT]   = markflag(MAC),    [IP4AT]   = markflag(MAC),\n    [FFVT]    = markflag(MAC),    [WUPM]    = markflag(MAC),\n    [ECOL]    = markflag(MAC),    [MCC]     = markflag(MAC),\n    [DC]      = markflag(MAC),    [TNCRS]   = markflag(MAC),\n    [RLEC]    = markflag(MAC),    [XONRXC]  = markflag(MAC),\n    [XOFFTXC] = markflag(MAC),    [RFC]     = markflag(MAC),\n    [TSCTFC]  = markflag(MAC),    [MGTPRC]  = markflag(MAC),\n    [WUS]     = markflag(MAC),    [AIT]     = markflag(MAC),\n    [FFLT]    = markflag(MAC),    [FFMT]    = markflag(MAC),\n    [SCC]     = markflag(MAC),    [FCRUC]   = markflag(MAC),\n    [LATECOL] = markflag(MAC),    [COLC]    = markflag(MAC),\n    [SEQEC]   = markflag(MAC),    [CEXTERR] = markflag(MAC),\n    [XONTXC]  = markflag(MAC),    [XOFFRXC] = markflag(MAC),\n    [RJC]     = markflag(MAC),    [RNBC]    = markflag(MAC),\n    [MGTPDC]  = markflag(MAC),    [MGTPTC]  = markflag(MAC),\n    [RUC]     = markflag(MAC),    [ROC]     = markflag(MAC),\n    [GORCL]   = markflag(MAC),    [GORCH]   = markflag(MAC),\n    [GOTCL]   = markflag(MAC),    [GOTCH]   = markflag(MAC),\n    [BPRC]    = markflag(MAC),    [MPRC]    = markflag(MAC),\n    [TSCTC]   = markflag(MAC),    [PRC64]   = markflag(MAC),\n    [PRC127]  = markflag(MAC),    [PRC255]  = markflag(MAC),\n    [PRC511]  = markflag(MAC),    [PRC1023] = markflag(MAC),\n    [PRC1522] = markflag(MAC),    [PTC64]   = markflag(MAC),\n    [PTC127]  = markflag(MAC),    [PTC255]  = markflag(MAC),\n    [PTC511]  = markflag(MAC),    [PTC1023] = markflag(MAC),\n    [PTC1522] = markflag(MAC),    [MPTC]    = markflag(MAC),\n    [BPTC]    = markflag(MAC),\n\n    [TDFH]  = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [TDFT]  = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [TDFHS] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [TDFTS] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [TDFPC] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [RDFH]  = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [RDFT]  = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [RDFHS] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [RDFTS] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [RDFPC] = markflag(MAC) | MAC_ACCESS_PARTIAL,\n    [PBM]   = markflag(MAC) | MAC_ACCESS_PARTIAL,\n};\n\nstatic void\ne1000_mmio_write(void *opaque, hwaddr addr, uint64_t val,\n                 unsigned size)\n{\n    E1000State *s = opaque;\n    unsigned int index = (addr & 0x1ffff) >> 2;\n\n    if (index < NWRITEOPS && macreg_writeops[index]) {\n        if (!(mac_reg_access[index] & MAC_ACCESS_FLAG_NEEDED)\n            || (s->compat_flags & (mac_reg_access[index] >> 2))) {\n            if (mac_reg_access[index] & MAC_ACCESS_PARTIAL) {\n                DBGOUT(GENERAL, \"Writing to register at offset: 0x%08x. \"\n                       \"It is not fully implemented.\\n\", index<<2);\n            }\n            macreg_writeops[index](s, index, val);\n        } else {    /* \"flag needed\" bit is set, but the flag is not active */\n            DBGOUT(MMIO, \"MMIO write attempt to disabled reg. addr=0x%08x\\n\",\n                   index<<2);\n        }\n    } else if (index < NREADOPS && macreg_readops[index]) {\n        DBGOUT(MMIO, \"e1000_mmio_writel RO %x: 0x%04\"PRIx64\"\\n\",\n               index<<2, val);\n    } else {\n        DBGOUT(UNKNOWN, \"MMIO unknown write addr=0x%08x,val=0x%08\"PRIx64\"\\n\",\n               index<<2, val);\n    }\n}\n\nstatic uint64_t\ne1000_mmio_read(void *opaque, hwaddr addr, unsigned size)\n{\n    E1000State *s = opaque;\n    unsigned int index = (addr & 0x1ffff) >> 2;\n\n    if (index < NREADOPS && macreg_readops[index]) {\n        if (!(mac_reg_access[index] & MAC_ACCESS_FLAG_NEEDED)\n            || (s->compat_flags & (mac_reg_access[index] >> 2))) {\n            if (mac_reg_access[index] & MAC_ACCESS_PARTIAL) {\n                DBGOUT(GENERAL, \"Reading register at offset: 0x%08x. \"\n                       \"It is not fully implemented.\\n\", index<<2);\n            }\n            return macreg_readops[index](s, index);\n        } else {    /* \"flag needed\" bit is set, but the flag is not active */\n            DBGOUT(MMIO, \"MMIO read attempt of disabled reg. addr=0x%08x\\n\",\n                   index<<2);\n        }\n    } else {\n        DBGOUT(UNKNOWN, \"MMIO unknown read addr=0x%08x\\n\", index<<2);\n    }\n    return 0;\n}\n\nstatic const MemoryRegionOps e1000_mmio_ops = {\n    .read = e1000_mmio_read,\n    .write = e1000_mmio_write,\n    .endianness = DEVICE_LITTLE_ENDIAN,\n    .impl = {\n        .min_access_size = 4,\n        .max_access_size = 4,\n    },\n};\n\nstatic uint64_t e1000_io_read(void *opaque, hwaddr addr,\n                              unsigned size)\n{\n    E1000State *s = opaque;\n\n    (void)s;\n    return 0;\n}\n\nstatic void e1000_io_write(void *opaque, hwaddr addr,\n                           uint64_t val, unsigned size)\n{\n    E1000State *s = opaque;\n\n    (void)s;\n}\n\nstatic const MemoryRegionOps e1000_io_ops = {\n    .read = e1000_io_read,\n    .write = e1000_io_write,\n    .endianness = DEVICE_LITTLE_ENDIAN,\n};\n\nstatic bool is_version_1(void *opaque, int version_id)\n{\n    return version_id == 1;\n}\n\nstatic int e1000_pre_save(void *opaque)\n{\n    E1000State *s = opaque;\n    NetClientState *nc = qemu_get_queue(s->nic);\n\n    /*\n     * If link is down and auto-negotiation is supported and ongoing,\n     * complete auto-negotiation immediately. This allows us to look\n     * at MII_SR_AUTONEG_COMPLETE to infer link status on load.\n     */\n    if (nc->link_down && have_autoneg(s)) {\n        s->phy_reg[PHY_STATUS] |= MII_SR_AUTONEG_COMPLETE;\n    }\n\n    /* Decide which set of props to migrate in the main structure */\n    if (chkflag(TSO) || !s->use_tso_for_migration) {\n        /* Either we're migrating with the extra subsection, in which\n         * case the mig_props is always 'props' OR\n         * we've not got the subsection, but 'props' was the last\n         * updated.\n         */\n        s->mig_props = s->tx.props;\n    } else {\n        /* We're not using the subsection, and 'tso_props' was\n         * the last updated.\n         */\n        s->mig_props = s->tx.tso_props;\n    }\n    return 0;\n}\n\nstatic int e1000_post_load(void *opaque, int version_id)\n{\n    E1000State *s = opaque;\n    NetClientState *nc = qemu_get_queue(s->nic);\n\n    if (!chkflag(MIT)) {\n        s->mac_reg[ITR] = s->mac_reg[RDTR] = s->mac_reg[RADV] =\n            s->mac_reg[TADV] = 0;\n        s->mit_irq_level = false;\n    }\n    s->mit_ide = 0;\n    s->mit_timer_on = true;\n    timer_mod(s->mit_timer, qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL) + 1);\n\n    /* nc.link_down can't be migrated, so infer link_down according\n     * to link status bit in mac_reg[STATUS].\n     * Alternatively, restart link negotiation if it was in progress. */\n    nc->link_down = (s->mac_reg[STATUS] & E1000_STATUS_LU) == 0;\n\n    if (have_autoneg(s) &&\n        !(s->phy_reg[PHY_STATUS] & MII_SR_AUTONEG_COMPLETE)) {\n        nc->link_down = false;\n        timer_mod(s->autoneg_timer,\n                  qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL) + 500);\n    }\n\n    s->tx.props = s->mig_props;\n    if (!s->received_tx_tso) {\n        /* We received only one set of offload data (tx.props)\n         * and haven't got tx.tso_props.  The best we can do\n         * is dupe the data.\n         */\n        s->tx.tso_props = s->mig_props;\n    }\n    return 0;\n}\n\nstatic int e1000_tx_tso_post_load(void *opaque, int version_id)\n{\n    E1000State *s = opaque;\n    s->received_tx_tso = true;\n    return 0;\n}\n\nstatic bool e1000_mit_state_needed(void *opaque)\n{\n    E1000State *s = opaque;\n\n    return chkflag(MIT);\n}\n\nstatic bool e1000_full_mac_needed(void *opaque)\n{\n    E1000State *s = opaque;\n\n    return chkflag(MAC);\n}\n\nstatic bool e1000_tso_state_needed(void *opaque)\n{\n    E1000State *s = opaque;\n\n    return chkflag(TSO);\n}\n\nstatic const VMStateDescription vmstate_e1000_mit_state = {\n    .name = \"e1000/mit_state\",\n    .version_id = 1,\n    .minimum_version_id = 1,\n    .needed = e1000_mit_state_needed,\n    .fields = (VMStateField[]) {\n        VMSTATE_UINT32(mac_reg[RDTR], E1000State),\n        VMSTATE_UINT32(mac_reg[RADV], E1000State),\n        VMSTATE_UINT32(mac_reg[TADV], E1000State),\n        VMSTATE_UINT32(mac_reg[ITR], E1000State),\n        VMSTATE_BOOL(mit_irq_level, E1000State),\n        VMSTATE_END_OF_LIST()\n    }\n};\n\nstatic const VMStateDescription vmstate_e1000_full_mac_state = {\n    .name = \"e1000/full_mac_state\",\n    .version_id = 1,\n    .minimum_version_id = 1,\n    .needed = e1000_full_mac_needed,\n    .fields = (VMStateField[]) {\n        VMSTATE_UINT32_ARRAY(mac_reg, E1000State, 0x8000),\n        VMSTATE_END_OF_LIST()\n    }\n};\n\nstatic const VMStateDescription vmstate_e1000_tx_tso_state = {\n    .name = \"e1000/tx_tso_state\",\n    .version_id = 1,\n    .minimum_version_id = 1,\n    .needed = e1000_tso_state_needed,\n    .post_load = e1000_tx_tso_post_load,\n    .fields = (VMStateField[]) {\n        VMSTATE_UINT8(tx.tso_props.ipcss, E1000State),\n        VMSTATE_UINT8(tx.tso_props.ipcso, E1000State),\n        VMSTATE_UINT16(tx.tso_props.ipcse, E1000State),\n        VMSTATE_UINT8(tx.tso_props.tucss, E1000State),\n        VMSTATE_UINT8(tx.tso_props.tucso, E1000State),\n        VMSTATE_UINT16(tx.tso_props.tucse, E1000State),\n        VMSTATE_UINT32(tx.tso_props.paylen, E1000State),\n        VMSTATE_UINT8(tx.tso_props.hdr_len, E1000State),\n        VMSTATE_UINT16(tx.tso_props.mss, E1000State),\n        VMSTATE_INT8(tx.tso_props.ip, E1000State),\n        VMSTATE_INT8(tx.tso_props.tcp, E1000State),\n        VMSTATE_END_OF_LIST()\n    }\n};\n\nstatic const VMStateDescription vmstate_e1000 = {\n    .name = \"e1000\",\n    .version_id = 2,\n    .minimum_version_id = 1,\n    .pre_save = e1000_pre_save,\n    .post_load = e1000_post_load,\n    .fields = (VMStateField[]) {\n        VMSTATE_PCI_DEVICE(parent_obj, E1000State),\n        VMSTATE_UNUSED_TEST(is_version_1, 4), /* was instance id */\n        VMSTATE_UNUSED(4), /* Was mmio_base.  */\n        VMSTATE_UINT32(rxbuf_size, E1000State),\n        VMSTATE_UINT32(rxbuf_min_shift, E1000State),\n        VMSTATE_UINT32(eecd_state.val_in, E1000State),\n        VMSTATE_UINT16(eecd_state.bitnum_in, E1000State),\n        VMSTATE_UINT16(eecd_state.bitnum_out, E1000State),\n        VMSTATE_UINT16(eecd_state.reading, E1000State),\n        VMSTATE_UINT32(eecd_state.old_eecd, E1000State),\n        VMSTATE_UINT8(mig_props.ipcss, E1000State),\n        VMSTATE_UINT8(mig_props.ipcso, E1000State),\n        VMSTATE_UINT16(mig_props.ipcse, E1000State),\n        VMSTATE_UINT8(mig_props.tucss, E1000State),\n        VMSTATE_UINT8(mig_props.tucso, E1000State),\n        VMSTATE_UINT16(mig_props.tucse, E1000State),\n        VMSTATE_UINT32(mig_props.paylen, E1000State),\n        VMSTATE_UINT8(mig_props.hdr_len, E1000State),\n        VMSTATE_UINT16(mig_props.mss, E1000State),\n        VMSTATE_UINT16(tx.size, E1000State),\n        VMSTATE_UINT16(tx.tso_frames, E1000State),\n        VMSTATE_UINT8(tx.sum_needed, E1000State),\n        VMSTATE_INT8(mig_props.ip, E1000State),\n        VMSTATE_INT8(mig_props.tcp, E1000State),\n        VMSTATE_BUFFER(tx.header, E1000State),\n        VMSTATE_BUFFER(tx.data, E1000State),\n        VMSTATE_UINT16_ARRAY(eeprom_data, E1000State, 64),\n        VMSTATE_UINT16_ARRAY(phy_reg, E1000State, 0x20),\n        VMSTATE_UINT32(mac_reg[CTRL], E1000State),\n        VMSTATE_UINT32(mac_reg[EECD], E1000State),\n        VMSTATE_UINT32(mac_reg[EERD], E1000State),\n        VMSTATE_UINT32(mac_reg[GPRC], E1000State),\n        VMSTATE_UINT32(mac_reg[GPTC], E1000State),\n        VMSTATE_UINT32(mac_reg[ICR], E1000State),\n        VMSTATE_UINT32(mac_reg[ICS], E1000State),\n        VMSTATE_UINT32(mac_reg[IMC], E1000State),\n        VMSTATE_UINT32(mac_reg[IMS], E1000State),\n        VMSTATE_UINT32(mac_reg[LEDCTL], E1000State),\n        VMSTATE_UINT32(mac_reg[MANC], E1000State),\n        VMSTATE_UINT32(mac_reg[MDIC], E1000State),\n        VMSTATE_UINT32(mac_reg[MPC], E1000State),\n        VMSTATE_UINT32(mac_reg[PBA], E1000State),\n        VMSTATE_UINT32(mac_reg[RCTL], E1000State),\n        VMSTATE_UINT32(mac_reg[RDBAH], E1000State),\n        VMSTATE_UINT32(mac_reg[RDBAL], E1000State),\n        VMSTATE_UINT32(mac_reg[RDH], E1000State),\n        VMSTATE_UINT32(mac_reg[RDLEN], E1000State),\n        VMSTATE_UINT32(mac_reg[RDT], E1000State),\n        VMSTATE_UINT32(mac_reg[STATUS], E1000State),\n        VMSTATE_UINT32(mac_reg[SWSM], E1000State),\n        VMSTATE_UINT32(mac_reg[TCTL], E1000State),\n        VMSTATE_UINT32(mac_reg[TDBAH], E1000State),\n        VMSTATE_UINT32(mac_reg[TDBAL], E1000State),\n        VMSTATE_UINT32(mac_reg[TDH], E1000State),\n        VMSTATE_UINT32(mac_reg[TDLEN], E1000State),\n        VMSTATE_UINT32(mac_reg[TDT], E1000State),\n        VMSTATE_UINT32(mac_reg[TORH], E1000State),\n        VMSTATE_UINT32(mac_reg[TORL], E1000State),\n        VMSTATE_UINT32(mac_reg[TOTH], E1000State),\n        VMSTATE_UINT32(mac_reg[TOTL], E1000State),\n        VMSTATE_UINT32(mac_reg[TPR], E1000State),\n        VMSTATE_UINT32(mac_reg[TPT], E1000State),\n        VMSTATE_UINT32(mac_reg[TXDCTL], E1000State),\n        VMSTATE_UINT32(mac_reg[WUFC], E1000State),\n        VMSTATE_UINT32(mac_reg[VET], E1000State),\n        VMSTATE_UINT32_SUB_ARRAY(mac_reg, E1000State, RA, 32),\n        VMSTATE_UINT32_SUB_ARRAY(mac_reg, E1000State, MTA, 128),\n        VMSTATE_UINT32_SUB_ARRAY(mac_reg, E1000State, VFTA, 128),\n        VMSTATE_END_OF_LIST()\n    },\n    .subsections = (const VMStateDescription*[]) {\n        &vmstate_e1000_mit_state,\n        &vmstate_e1000_full_mac_state,\n        &vmstate_e1000_tx_tso_state,\n        NULL\n    }\n};\n\n/*\n * EEPROM contents documented in Tables 5-2 and 5-3, pp. 98-102.\n * Note: A valid DevId will be inserted during pci_e1000_realize().\n */\nstatic const uint16_t e1000_eeprom_template[64] = {\n    0x0000, 0x0000, 0x0000, 0x0000,      0xffff, 0x0000,      0x0000, 0x0000,\n    0x3000, 0x1000, 0x6403, 0 /*DevId*/, 0x8086, 0 /*DevId*/, 0x8086, 0x3040,\n    0x0008, 0x2000, 0x7e14, 0x0048,      0x1000, 0x00d8,      0x0000, 0x2700,\n    0x6cc9, 0x3150, 0x0722, 0x040b,      0x0984, 0x0000,      0xc000, 0x0706,\n    0x1008, 0x0000, 0x0f04, 0x7fff,      0x4d01, 0xffff,      0xffff, 0xffff,\n    0xffff, 0xffff, 0xffff, 0xffff,      0xffff, 0xffff,      0xffff, 0xffff,\n    0x0100, 0x4000, 0x121c, 0xffff,      0xffff, 0xffff,      0xffff, 0xffff,\n    0xffff, 0xffff, 0xffff, 0xffff,      0xffff, 0xffff,      0xffff, 0x0000,\n};\n\n/* PCI interface */\n\nstatic void\ne1000_mmio_setup(E1000State *d)\n{\n    int i;\n    const uint32_t excluded_regs[] = {\n        E1000_MDIC, E1000_ICR, E1000_ICS, E1000_IMS,\n        E1000_IMC, E1000_TCTL, E1000_TDT, PNPMMIO_SIZE\n    };\n\n    memory_region_init_io(&d->mmio, OBJECT(d), &e1000_mmio_ops, d,\n                          \"e1000-mmio\", PNPMMIO_SIZE);\n    memory_region_add_coalescing(&d->mmio, 0, excluded_regs[0]);\n    for (i = 0; excluded_regs[i] != PNPMMIO_SIZE; i++)\n        memory_region_add_coalescing(&d->mmio, excluded_regs[i] + 4,\n                                     excluded_regs[i+1] - excluded_regs[i] - 4);\n    memory_region_init_io(&d->io, OBJECT(d), &e1000_io_ops, d, \"e1000-io\", IOPORT_SIZE);\n}\n\nstatic void\npci_e1000_uninit(PCIDevice *dev)\n{\n    E1000State *d = E1000(dev);\n\n    timer_free(d->autoneg_timer);\n    timer_free(d->mit_timer);\n    timer_free(d->flush_queue_timer);\n    qemu_del_nic(d->nic);\n}\n\nstatic NetClientInfo net_e1000_info = {\n    .type = NET_CLIENT_DRIVER_NIC,\n    .size = sizeof(NICState),\n    .can_receive = e1000_can_receive,\n    .receive = e1000_receive,\n    .receive_iov = e1000_receive_iov,\n    .link_status_changed = e1000_set_link_status,\n};\n\nstatic void e1000_write_config(PCIDevice *pci_dev, uint32_t address,\n                                uint32_t val, int len)\n{\n    E1000State *s = E1000(pci_dev);\n\n    pci_default_write_config(pci_dev, address, val, len);\n\n    if (range_covers_byte(address, len, PCI_COMMAND) &&\n        (pci_dev->config[PCI_COMMAND] & PCI_COMMAND_MASTER)) {\n        qemu_flush_queued_packets(qemu_get_queue(s->nic));\n    }\n}\n\nstatic void pci_e1000_realize(PCIDevice *pci_dev, Error **errp)\n{\n    DeviceState *dev = DEVICE(pci_dev);\n    E1000State *d = E1000(pci_dev);\n    uint8_t *pci_conf;\n    uint8_t *macaddr;\n\n    pci_dev->config_write = e1000_write_config;\n\n    pci_conf = pci_dev->config;\n\n    /* TODO: RST# value should be 0, PCI spec 6.2.4 */\n    pci_conf[PCI_CACHE_LINE_SIZE] = 0x10;\n\n    pci_conf[PCI_INTERRUPT_PIN] = 1; /* interrupt pin A */\n\n    e1000_mmio_setup(d);\n\n    pci_register_bar(pci_dev, 0, PCI_BASE_ADDRESS_SPACE_MEMORY, &d->mmio);\n\n    pci_register_bar(pci_dev, 1, PCI_BASE_ADDRESS_SPACE_IO, &d->io);\n\n    qemu_macaddr_default_if_unset(&d->conf.macaddr);\n    macaddr = d->conf.macaddr.a;\n\n    e1000x_core_prepare_eeprom(d->eeprom_data,\n                               e1000_eeprom_template,\n                               sizeof(e1000_eeprom_template),\n                               PCI_DEVICE_GET_CLASS(pci_dev)->device_id,\n                               macaddr);\n\n    d->nic = qemu_new_nic(&net_e1000_info, &d->conf,\n                          object_get_typename(OBJECT(d)), dev->id, d);\n\n    qemu_format_nic_info_str(qemu_get_queue(d->nic), macaddr);\n\n    d->autoneg_timer = timer_new_ms(QEMU_CLOCK_VIRTUAL, e1000_autoneg_timer, d);\n    d->mit_timer = timer_new_ns(QEMU_CLOCK_VIRTUAL, e1000_mit_timer, d);\n    d->flush_queue_timer = timer_new_ms(QEMU_CLOCK_VIRTUAL,\n                                        e1000_flush_queue_timer, d);\n}\n\nstatic void qdev_e1000_reset(DeviceState *dev)\n{\n    E1000State *d = E1000(dev);\n    e1000_reset(d);\n}\n\nstatic Property e1000_properties[] = {\n    DEFINE_NIC_PROPERTIES(E1000State, conf),\n    DEFINE_PROP_BIT(\"autonegotiation\", E1000State,\n                    compat_flags, E1000_FLAG_AUTONEG_BIT, true),\n    DEFINE_PROP_BIT(\"mitigation\", E1000State,\n                    compat_flags, E1000_FLAG_MIT_BIT, true),\n    DEFINE_PROP_BIT(\"extra_mac_registers\", E1000State,\n                    compat_flags, E1000_FLAG_MAC_BIT, true),\n    DEFINE_PROP_BIT(\"migrate_tso_props\", E1000State,\n                    compat_flags, E1000_FLAG_TSO_BIT, true),\n    DEFINE_PROP_END_OF_LIST(),\n};\n\ntypedef struct E1000Info {\n    const char *name;\n    uint16_t   device_id;\n    uint8_t    revision;\n    uint16_t   phy_id2;\n} E1000Info;\n\nstatic void e1000_class_init(ObjectClass *klass, void *data)\n{\n    DeviceClass *dc = DEVICE_CLASS(klass);\n    PCIDeviceClass *k = PCI_DEVICE_CLASS(klass);\n    E1000BaseClass *e = E1000_CLASS(klass);\n    const E1000Info *info = data;\n\n    k->realize = pci_e1000_realize;\n    k->exit = pci_e1000_uninit;\n    k->romfile = \"efi-e1000.rom\";\n    k->vendor_id = PCI_VENDOR_ID_INTEL;\n    k->device_id = info->device_id;\n    k->revision = info->revision;\n    e->phy_id2 = info->phy_id2;\n    k->class_id = PCI_CLASS_NETWORK_ETHERNET;\n    set_bit(DEVICE_CATEGORY_NETWORK, dc->categories);\n    dc->desc = \"Intel Gigabit Ethernet\";\n    dc->reset = qdev_e1000_reset;\n    dc->vmsd = &vmstate_e1000;\n    device_class_set_props(dc, e1000_properties);\n}\n\nstatic void e1000_instance_init(Object *obj)\n{\n    E1000State *n = E1000(obj);\n    device_add_bootindex_property(obj, &n->conf.bootindex,\n                                  \"bootindex\", \"/ethernet-phy@0\",\n                                  DEVICE(n));\n}\n\nstatic const TypeInfo e1000_base_info = {\n    .name          = TYPE_E1000_BASE,\n    .parent        = TYPE_PCI_DEVICE,\n    .instance_size = sizeof(E1000State),\n    .instance_init = e1000_instance_init,\n    .class_size    = sizeof(E1000BaseClass),\n    .abstract      = true,\n    .interfaces = (InterfaceInfo[]) {\n        { INTERFACE_CONVENTIONAL_PCI_DEVICE },\n        { },\n    },\n};\n\nstatic const E1000Info e1000_devices[] = {\n    {\n        .name      = \"e1000\",\n        .device_id = E1000_DEV_ID_82540EM,\n        .revision  = 0x03,\n        .phy_id2   = E1000_PHY_ID2_8254xx_DEFAULT,\n    },\n    {\n        .name      = \"e1000-82544gc\",\n        .device_id = E1000_DEV_ID_82544GC_COPPER,\n        .revision  = 0x03,\n        .phy_id2   = E1000_PHY_ID2_82544x,\n    },\n    {\n        .name      = \"e1000-82545em\",\n        .device_id = E1000_DEV_ID_82545EM_COPPER,\n        .revision  = 0x03,\n        .phy_id2   = E1000_PHY_ID2_8254xx_DEFAULT,\n    },\n};\n\nstatic void e1000_register_types(void)\n{\n    int i;\n\n    type_register_static(&e1000_base_info);\n    for (i = 0; i < ARRAY_SIZE(e1000_devices); i++) {\n        const E1000Info *info = &e1000_devices[i];\n        TypeInfo type_info = {};\n\n        type_info.name = info->name;\n        type_info.parent = TYPE_E1000_BASE;\n        type_info.class_data = (void *)info;\n        type_info.class_init = e1000_class_init;\n\n        type_register(&type_info);\n    }\n}\n\ntype_init(e1000_register_types)\n"], "filenames": ["hw/net/e1000.c"], "buggy_code_start_loc": [672], "buggy_code_end_loc": [697], "fixing_code_start_loc": [673], "fixing_code_end_loc": [702], "type": "CWE-835", "message": "An infinite loop flaw was found in the e1000 NIC emulator of the QEMU. This issue occurs while processing transmits (tx) descriptors in process_tx_desc if various descriptor fields are initialized with invalid values. This flaw allows a guest to consume CPU cycles on the host, resulting in a denial of service. The highest threat from this vulnerability is to system availability.", "other": {"cve": {"id": "CVE-2021-20257", "sourceIdentifier": "secalert@redhat.com", "published": "2022-03-16T15:15:09.983", "lastModified": "2023-02-12T22:15:17.573", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "An infinite loop flaw was found in the e1000 NIC emulator of the QEMU. This issue occurs while processing transmits (tx) descriptors in process_tx_desc if various descriptor fields are initialized with invalid values. This flaw allows a guest to consume CPU cycles on the host, resulting in a denial of service. The highest threat from this vulnerability is to system availability."}, {"lang": "es", "value": "Se ha encontrado un fallo de bucle infinito en el emulador NIC e1000 de QEMU. Este problema se produce mientras son procesados descriptores de transmisi\u00f3n (tx) en la funci\u00f3n  process_tx_desc si varios campos del descriptor son inicializados con valores no v\u00e1lidos. Este fallo permite a un hu\u00e9sped consumir ciclos de CPU en el host, resultando en una denegaci\u00f3n de servicio. La mayor amenaza de esta vulnerabilidad es la disponibilidad del sistema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:C/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.0, "impactScore": 4.0}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "secalert@redhat.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-835"}]}, {"source": "nvd@nist.gov", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-835"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:qemu:qemu:*:*:*:*:*:*:*:*", "versionEndExcluding": "6.2.0", "matchCriteriaId": "AC80F3BA-7E42-4883-9968-EDFC1BBC0695"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:33:*:*:*:*:*:*:*", "matchCriteriaId": "E460AA51-FCDA-46B9-AE97-E6676AA5E194"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:redhat:openstack_platform:10.0:*:*:*:*:*:*:*", "matchCriteriaId": "542B31BD-5767-4B33-9201-40548D1223B3"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redhat:openstack_platform:13.0:*:*:*:*:*:*:*", "matchCriteriaId": "C52600BF-9E87-4CD2-91F3-685AFE478C1E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:6.0:*:*:*:*:*:*:*", "matchCriteriaId": "2F6AB192-9D7D-4A9A-8995-E53A9DE9EAFC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "F4CFF558-3C47-480D-A2F0-BABF26042943"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:8.0:*:*:*:advanced_virtualization:*:*:*", "matchCriteriaId": "3AA08768-75AF-4791-B229-AE938C780959"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_for_ibm_z_systems:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "87C21FE1-EA5C-498F-9C6C-D05F91A88217"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_for_power_little_endian:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "47811209-5CE5-4375-8391-B0A7F6A0E420"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:redhat:codeready_linux_builder:-:*:*:*:*:*:*:*", "matchCriteriaId": "1CD81C46-328B-412D-AF4E-68A2AD2F1A73"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:o:redhat:enterprise_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "F4CFF558-3C47-480D-A2F0-BABF26042943"}, {"vulnerable": false, "criteria": "cpe:2.3:o:redhat:enterprise_linux_for_ibm_z_systems:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "87C21FE1-EA5C-498F-9C6C-D05F91A88217"}, {"vulnerable": false, "criteria": "cpe:2.3:o:redhat:enterprise_linux_for_power_little_endian:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "47811209-5CE5-4375-8391-B0A7F6A0E420"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:10.0:*:*:*:*:*:*:*", "matchCriteriaId": "07B237A9-69A3-4A9C-9DA0-4E06BD37AE73"}]}]}], "references": [{"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1930087", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/qemu/qemu/commit/3de46e6fc489c52c9431a8a832ad8170a7569bd8", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2022/09/msg00008.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.gnu.org/archive/html/qemu-devel/2021-02/msg07428.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Patch", "Vendor Advisory"]}, {"url": "https://security.gentoo.org/glsa/202208-27", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20220425-0003/", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://www.openwall.com/lists/oss-security/2021/02/25/2", "source": "secalert@redhat.com", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/qemu/qemu/commit/3de46e6fc489c52c9431a8a832ad8170a7569bd8"}}
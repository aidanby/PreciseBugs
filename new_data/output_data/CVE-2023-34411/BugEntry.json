{"buggy_code": ["xml-rs, an XML library for Rust\n===============================\n\n[![CI](https://github.com/kornelski/xml-rs/actions/workflows/main.yml/badge.svg)](https://github.com/kornelski/xml-rs/actions/workflows/main.yml)\n[![crates.io][crates-io-img]](https://lib.rs/crates/xml-rs)\n[![docs][docs-img]](https://docs.rs/xml-rs/)\n\n[Documentation](https://docs.rs/xml-rs/)\n\n  [crates-io-img]: https://img.shields.io/crates/v/xml-rs.svg\n  [docs-img]: https://img.shields.io/badge/docs-latest%20release-6495ed.svg\n\nxml-rs is an XML library for the [Rust](https://www.rust-lang.org/) programming language.\nIt is heavily inspired by Java [Streaming API for XML (StAX)][stax].\n\n  [stax]: https://en.wikipedia.org/wiki/StAX\n\nThis library contains a pull parser much like StAX event reader.\nIt provides an iterator API, so you can leverage Rust's existing iterators library features.\n\nIt also provides a streaming document writer much like StAX event writer.\nThis writer consumes its own set of events, but reader events can be converted to\nwriter events easily, and so it is possible to write XML transformation chains in a pretty\nclean manner.\n\nThis parser is mostly full-featured, however, there are limitations:\n* Only UTF-8 is supported;\n* DTD validation is not supported, `<!DOCTYPE>` declarations are completely ignored; thus no\n  support for custom entities too; internal DTD declarations are likely to cause parsing errors;\n* attribute value normalization is not performed, and end-of-line characters are not normalized either.\n\nOther than that the parser tries to be mostly XML-1.1-compliant.\n\nWriter is also mostly full-featured with the following limitations:\n* no support for encodings other than UTF-8,\n* no support for emitting `<!DOCTYPE>` declarations;\n* more validations of input are needed, for example, checking that namespace prefixes are bounded\n  or comments are well-formed.\n\nPlanned features:\n\n* support for encodings beyond UTF-8,\n* improved XML-1.1 conformance.\n\nBuilding and using\n------------------\n\nxml-rs uses [Cargo](https://crates.io), so add it with `cargo add xml-rs` or modify `Cargo.toml`:\n\n```toml\n[dependencies]\nxml-rs = \"0.8\"\n```\n\nThe package exposes a single crate called `xml`.\n\nReading XML documents\n---------------------\n\n[`xml::reader::EventReader`](EventReader) requires a [`Read`](stdread) instance to read from. It can be a `File` wrapped in `BufReader`, or a `Vec<u8>`, or a `&[u8]` slice.\n\n[EventReader]: https://docs.rs/xml-rs/latest/xml/reader/struct.EventReader.html\n[stdread]: https://doc.rust-lang.org/stable/std/io/trait.Read.html\n\n`EventReader` implements `IntoIterator` trait, so you can use it in a `for` loop directly:\n\n```rust,no_run\nuse std::fs::File;\nuse std::io::BufReader;\n\nuse xml::reader::{EventReader, XmlEvent};\n\nfn main() -> std::io::Result<()> {\n    let file = File::open(\"file.xml\")?;\n    let file = BufReader::new(file); // Buffering is important for performance\n\n    let parser = EventReader::new(file);\n    let mut depth = 0;\n    for e in parser {\n        match e {\n            Ok(XmlEvent::StartElement { name, .. }) => {\n                println!(\"{:spaces$}+{name}\", \"\", spaces = depth * 2);\n                depth += 1;\n            }\n            Ok(XmlEvent::EndElement { name }) => {\n                depth -= 1;\n                println!(\"{:spaces$}-{name}\", \"\", spaces = depth * 2);\n            }\n            Err(e) => {\n                eprintln!(\"Error: {e}\");\n                break;\n            }\n            // There's more: https://docs.rs/xml-rs/latest/xml/reader/enum.XmlEvent.html\n            _ => {}\n        }\n    }\n\n    Ok(())\n}\n```\n\nDocument parsing can end normally or with an error. Regardless of exact cause, the parsing\nprocess will be stopped, and the iterator will terminate normally.\n\nYou can also have finer control over when to pull the next event from the parser using its own\n`next()` method:\n\n```rust,ignore\nmatch parser.next() {\n    ...\n}\n```\n\nUpon the end of the document or an error, the parser will remember the last event and will always\nreturn it in the result of `next()` call afterwards. If iterator is used, then it will yield\nerror or end-of-document event once and will produce `None` afterwards.\n\nIt is also possible to tweak parsing process a little using [`xml::reader::ParserConfig`][ParserConfig] structure.\nSee its documentation for more information and examples.\n\n[ParserConfig]: https://docs.rs/xml-rs/latest/xml/reader/struct.ParserConfig.html\n\nYou can find a more extensive example of using `EventReader` in `src/analyze.rs`, which is a\nsmall program (BTW, it is built with `cargo build` and can be run after that) which shows various\nstatistics about specified XML document. It can also be used to check for well-formedness of\nXML documents - if a document is not well-formed, this program will exit with an error.\n\nWriting XML documents\n---------------------\n\nxml-rs also provides a streaming writer much like StAX event writer. With it you can write an\nXML document to any `Write` implementor.\n\n```rust,no_run\nuse std::io;\nuse xml::writer::{EmitterConfig, XmlEvent};\n\n/// A simple demo syntax where \"+foo\" makes `<foo>`, \"-foo\" makes `</foo>`\nfn make_event_from_line(line: &str) -> XmlEvent {\n    let line = line.trim();\n    if let Some(name) = line.strip_prefix(\"+\") {\n        XmlEvent::start_element(name).into()\n    } else if line.starts_with(\"-\") {\n        XmlEvent::end_element().into()\n    } else {\n        XmlEvent::characters(line).into()\n    }\n}\n\nfn main() -> io::Result<()> {\n    let input = io::stdin();\n    let output = io::stdout();\n    let mut writer = EmitterConfig::new()\n        .perform_indent(true)\n        .create_writer(output);\n\n    let mut line = String::new();\n    loop {\n        line.clear();\n        let bytes_read = input.read_line(&mut line)?;\n        if bytes_read == 0 {\n            break; // EOF\n        }\n\n        let event = make_event_from_line(&line);\n        if let Err(e) = writer.write(event) {\n            panic!(\"Write error: {e}\")\n        }\n    }\n    Ok(())\n}\n```\n\nThe code example above also demonstrates how to create a writer out of its configuration.\nSimilar thing also works with `EventReader`.\n\nThe library provides an XML event building DSL which helps to construct complex events,\ne.g. ones having namespace definitions. Some examples:\n\n```rust,ignore\n// <a:hello a:param=\"value\" xmlns:a=\"urn:some:document\">\nXmlEvent::start_element(\"a:hello\").attr(\"a:param\", \"value\").ns(\"a\", \"urn:some:document\")\n\n// <hello b:config=\"name\" xmlns=\"urn:default:uri\">\nXmlEvent::start_element(\"hello\").attr(\"b:config\", \"value\").default_ns(\"urn:defaul:uri\")\n\n// <![CDATA[some unescaped text]]>\nXmlEvent::cdata(\"some unescaped text\")\n```\n\nOf course, one can create `XmlEvent` enum variants directly instead of using the builder DSL.\nThere are more examples in [`xml::writer::XmlEvent`][XmlEvent] documentation.\n\n[XmlEvent]: https://docs.rs/xml-rs/latest/xml/reader/enum.XmlEvent.html\n\nThe writer has multiple configuration options; see `EmitterConfig` documentation for more\ninformation.\n\n[EmitterConfig]: https://docs.rs/xml-rs/latest/xml/writer/struct.EmitterConfig.html\n\nBug reports\n------------\n\nPlease report issues at: <https://github.com/kornelski/xml-rs/issues>.\n\n", "//! Contains simple lexer for XML documents.\n//!\n//! This module is for internal use. Use `xml::pull` module to do parsing.\n\nuse std::borrow::Cow;\nuse std::collections::VecDeque;\nuse std::fmt;\nuse std::io::Read;\nuse std::result;\n\nuse crate::common::{is_name_char, is_whitespace_char, Position, TextPosition};\nuse crate::reader::Error;\nuse crate::util;\n\n/// `Token` represents a single lexeme of an XML document. These lexemes\n/// are used to perform actual parsing.\n#[derive(Copy, Clone, PartialEq, Eq, Debug)]\npub(crate) enum Token {\n    /// `<?`\n    ProcessingInstructionStart,\n    /// `?>`\n    ProcessingInstructionEnd,\n    /// `<!DOCTYPE\n    DoctypeStart,\n    /// `<`\n    OpeningTagStart,\n    /// `</`\n    ClosingTagStart,\n    /// `>`\n    TagEnd,\n    /// `/>`\n    EmptyTagEnd,\n    /// `<!--`\n    CommentStart,\n    /// `-->`\n    CommentEnd,\n    /// A chunk of characters, used for errors recovery.\n    Chunk(&'static str),\n    /// Any non-special character except whitespace.\n    Character(char),\n    /// Whitespace character.\n    Whitespace(char),\n    /// `=`\n    EqualsSign,\n    /// `'`\n    SingleQuote,\n    /// `\"`\n    DoubleQuote,\n    /// `<![CDATA[`\n    CDataStart,\n    /// `]]>`\n    CDataEnd,\n    /// `&`\n    ReferenceStart,\n    /// `;`\n    ReferenceEnd,\n}\n\nimpl fmt::Display for Token {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Token::Chunk(s)                            => s.fmt(f),\n            Token::Character(c) | Token::Whitespace(c) => c.fmt(f),\n            other => match other {\n                Token::OpeningTagStart            => \"<\",\n                Token::ProcessingInstructionStart => \"<?\",\n                Token::DoctypeStart               => \"<!DOCTYPE\",\n                Token::ClosingTagStart            => \"</\",\n                Token::CommentStart               => \"<!--\",\n                Token::CDataStart                 => \"<![CDATA[\",\n                Token::TagEnd                     => \">\",\n                Token::EmptyTagEnd                => \"/>\",\n                Token::ProcessingInstructionEnd   => \"?>\",\n                Token::CommentEnd                 => \"-->\",\n                Token::CDataEnd                   => \"]]>\",\n                Token::ReferenceStart             => \"&\",\n                Token::ReferenceEnd               => \";\",\n                Token::EqualsSign                 => \"=\",\n                Token::SingleQuote                => \"'\",\n                Token::DoubleQuote                => \"\\\"\",\n                _                          => unreachable!()\n            }.fmt(f),\n        }\n    }\n}\n\nimpl Token {\n    pub fn as_static_str(&self) -> Option<&'static str> {\n        match *self {\n            Token::OpeningTagStart            => Some(\"<\"),\n            Token::ProcessingInstructionStart => Some(\"<?\"),\n            Token::DoctypeStart               => Some(\"<!DOCTYPE\"),\n            Token::ClosingTagStart            => Some(\"</\"),\n            Token::CommentStart               => Some(\"<!--\"),\n            Token::CDataStart                 => Some(\"<![CDATA[\"),\n            Token::TagEnd                     => Some(\">\"),\n            Token::EmptyTagEnd                => Some(\"/>\"),\n            Token::ProcessingInstructionEnd   => Some(\"?>\"),\n            Token::CommentEnd                 => Some(\"-->\"),\n            Token::CDataEnd                   => Some(\"]]>\"),\n            Token::ReferenceStart             => Some(\"&\"),\n            Token::ReferenceEnd               => Some(\";\"),\n            Token::EqualsSign                 => Some(\"=\"),\n            Token::SingleQuote                => Some(\"'\"),\n            Token::DoubleQuote                => Some(\"\\\"\"),\n            Token::Chunk(s)                   => Some(s),\n            _                                 => None\n        }\n    }\n\n    // using String.push_str(token.to_string()) is simply way too slow\n    pub fn push_to_string(&self, target: &mut String) {\n        match self.as_static_str() {\n            Some(s) => { target.push_str(s); }\n            None => {\n                match *self {\n                    Token::Character(c) | Token::Whitespace(c) => target.push(c),\n                    _ => unreachable!()\n                }\n            }\n        }\n    }\n\n    /// Returns `true` if this token contains data that can be interpreted\n    /// as a part of the text. Surprisingly, this also means '>' and '=' and '\"' and \"'\" and '-->'.\n    #[inline]\n    pub fn contains_char_data(&self) -> bool {\n        match *self {\n            Token::Whitespace(_) | Token::Chunk(_) | Token::Character(_) | Token::CommentEnd |\n            Token::TagEnd | Token::EqualsSign | Token::DoubleQuote | Token::SingleQuote | Token::CDataEnd | \n            Token::ProcessingInstructionEnd | Token::EmptyTagEnd => true,\n            _ => false\n        }\n    }\n\n    /// Returns `true` if this token corresponds to a white space character.\n    #[inline]\n    pub fn is_whitespace(&self) -> bool {\n        match *self {\n            Token::Whitespace(_) => true,\n            _ => false,\n        }\n    }\n}\n\nenum State {\n    /// Default state\n    Normal,\n    /// Triggered on '<'\n    TagStarted,\n    /// Triggered on '<!'\n    CommentOrCDataOrDoctypeStarted,\n    /// Triggered on '<!-'\n    CommentStarted,\n    /// Triggered on '<!D' up to '<!DOCTYPE'\n    DoctypeStarted(DoctypeStartedSubstate),\n    /// Triggered after DoctypeStarted to handle sub elements\n    DoctypeFinishing(u8),\n    /// Triggered on '<![' up to '<![CDATA'\n    CDataStarted(CDataStartedSubstate),\n    /// Triggered on '?'\n    ProcessingInstructionClosing,\n    /// Triggered on '/'\n    EmptyTagClosing,\n    /// Triggered on '-' up to '--'\n    CommentClosing(ClosingSubstate),\n    /// Triggered on ']' up to ']]' inside CDATA\n    CDataClosing(ClosingSubstate),\n    /// Triggered on ']' up to ']]' outside CDATA\n    InvalidCDataClosing(ClosingSubstate),\n    /// After `<!--`\n    InsideComment,\n    /// After `<[[`\n    InsideCdata,\n    /// After `<?`\n    InsideProcessingInstruction,\n}\n\n#[derive(Copy, Clone)]\nenum ClosingSubstate {\n    First, Second\n}\n\n#[derive(Copy, Clone)]\nenum DoctypeStartedSubstate {\n    D, DO, DOC, DOCT, DOCTY, DOCTYP\n}\n\n#[derive(Copy, Clone)]\nenum CDataStartedSubstate {\n    E, C, CD, CDA, CDAT, CDATA\n}\n\n/// `Result` represents lexing result. It is either a token or an error message.\npub(crate) type Result<T = Option<Token>, E = Error> = result::Result<T, E>;\n\n/// Helps to set up a dispatch table for lexing large unambigous tokens like\n/// `<![CDATA[` or `<!DOCTYPE `.\nmacro_rules! dispatch_on_enum_state(\n    ($_self:ident, $s:expr, $c:expr, $is:expr,\n     $($st:ident; $stc:expr ; $next_st:ident ; $chunk:expr),+;\n     $end_st:ident ; $end_c:expr ; $end_chunk:expr ; $e:expr) => (\n        match $s {\n            $(\n            $st => match $c {\n                $stc => $_self.move_to($is($next_st)),\n                _  => $_self.handle_error($chunk, $c)\n            },\n            )+\n            $end_st => match $c {\n                $end_c => $e,\n                _      => $_self.handle_error($end_chunk, $c)\n            }\n        }\n    )\n);\n\n/// `Lexer` is a lexer for XML documents, which implements pull API.\n///\n/// Main method is `next_token` which accepts an `std::io::Read` instance and\n/// tries to read the next lexeme from it.\n///\n/// When `skip_errors` flag is set, invalid lexemes will be returned as `Chunk`s.\n/// When it is not set, errors will be reported as `Err` objects with a string message.\n/// By default this flag is not set. Use `enable_errors` and `disable_errors` methods\n/// to toggle the behavior.\npub(crate) struct Lexer {\n    pos: TextPosition,\n    head_pos: TextPosition,\n    char_queue: VecDeque<char>,\n    st: State,\n    skip_errors: bool,\n    inside_token: bool,\n    eof_handled: bool\n}\n\nimpl Position for Lexer {\n    #[inline]\n    /// Returns the position of the last token produced by the lexer\n    fn position(&self) -> TextPosition { self.pos }\n}\n\nimpl Lexer {\n    /// Returns a new lexer with default state.\n    pub fn new() -> Lexer {\n        Lexer {\n            pos: TextPosition::new(),\n            head_pos: TextPosition::new(),\n            char_queue: VecDeque::with_capacity(4),  // TODO: check size\n            st: State::Normal,\n            skip_errors: false,\n            inside_token: false,\n            eof_handled: false\n        }\n    }\n\n    /// Enables error handling so `next_token` will return `Some(Err(..))`\n    /// upon invalid lexeme.\n    #[inline]\n    pub fn enable_errors(&mut self) { self.skip_errors = false; }\n\n    /// Disables error handling so `next_token` will return `Some(Chunk(..))`\n    /// upon invalid lexeme with this lexeme content.\n    #[inline]\n    pub fn disable_errors(&mut self) { self.skip_errors = true; }\n\n    /// Reset the eof handled flag of the lexer.\n    #[inline]\n    pub fn reset_eof_handled(&mut self) { self.eof_handled = false; }\n\n    /// Tries to read the next token from the buffer.\n    ///\n    /// It is possible to pass different instaces of `BufReader` each time\n    /// this method is called, but the resulting behavior is undefined in this case.\n    ///\n    /// Return value:\n    /// * `Err(reason) where reason: reader::Error` - when an error occurs;\n    /// * `Ok(None)` - upon end of stream is reached;\n    /// * `Ok(Some(token)) where token: Token` - in case a complete-token has been read from the stream.\n    pub fn next_token<B: Read>(&mut self, b: &mut B) -> Result {\n        // Already reached end of buffer\n        if self.eof_handled {\n            return Ok(None);\n        }\n\n        if !self.inside_token {\n            self.pos = self.head_pos;\n            self.inside_token = true;\n        }\n\n        // Check if we have saved a char or two for ourselves\n        while let Some(c) = self.char_queue.pop_front() {\n            match self.read_next_token(c)? {\n                Some(t) => {\n                    self.inside_token = false;\n                    return Ok(Some(t));\n                }\n                None => {} // continue\n            }\n        }\n\n        loop {\n            // TODO: this should handle multiple encodings\n            let c = match util::next_char_from(b)? {\n                Some(c) => c,  // got next char\n                None => break, // nothing to read left\n            };\n\n            match self.read_next_token(c)? {\n                Some(t) => {\n                    self.inside_token = false;\n                    return Ok(Some(t));\n                }\n                None => {\n                    // continue\n                }\n            }\n        }\n\n        // Handle end of stream\n        self.eof_handled = true;\n        self.pos = self.head_pos;\n        match self.st {\n            State::InsideCdata | State::CDataClosing(_) => Err(self.error(\"Unclosed CDATA\")),\n\n            State::TagStarted | State::CommentOrCDataOrDoctypeStarted |\n            State::CommentStarted | State::CDataStarted(_)| State::DoctypeStarted(_) |\n            State::CommentClosing(ClosingSubstate::Second) |\n            State::InsideComment |\n            State::InsideProcessingInstruction | State::ProcessingInstructionClosing |\n            State::DoctypeFinishing(_) =>\n                Err(self.error(\"Unexpected end of stream\")),\n            State::EmptyTagClosing =>\n                Ok(Some(Token::Character('/'))),\n            State::CommentClosing(ClosingSubstate::First) =>\n                Ok(Some(Token::Character('-'))),\n            State::InvalidCDataClosing(ClosingSubstate::First) =>\n                Ok(Some(Token::Character(']'))),\n            State::InvalidCDataClosing(ClosingSubstate::Second) =>\n                Ok(Some(Token::Chunk(\"]]\"))),\n            State::Normal =>\n                Ok(None),\n        }\n    }\n\n    #[inline]\n    fn error<M: Into<Cow<'static, str>>>(&self, msg: M) -> Error {\n        (self, msg).into()\n    }\n\n    #[inline]\n    fn read_next_token(&mut self, c: char) -> Result {\n        let res = self.dispatch_char(c);\n        if self.char_queue.is_empty() {\n            if c == '\\n' {\n                self.head_pos.new_line();\n            } else {\n                self.head_pos.advance(1);\n            }\n        }\n        res\n    }\n\n    fn dispatch_char(&mut self, c: char) -> Result {\n        match self.st {\n            State::Normal                         => self.normal(c),\n            State::TagStarted                     => self.tag_opened(c),\n            State::CommentOrCDataOrDoctypeStarted => self.comment_or_cdata_or_doctype_started(c),\n            State::CommentStarted                 => self.comment_started(c),\n            State::CDataStarted(s)                => self.cdata_started(c, s),\n            State::DoctypeStarted(s)              => self.doctype_started(c, s),\n            State::DoctypeFinishing(d)            => self.doctype_finishing(c, d),\n            State::EmptyTagClosing                => self.empty_element_closing(c),\n            State::CommentClosing(s)              => self.comment_closing(c, s),\n            State::CDataClosing(s)                => self.cdata_closing(c, s),\n            State::InvalidCDataClosing(s)         => self.invalid_cdata_closing(c, s),\n            State::InsideComment                  => self.inside_comment_state(c),\n            State::InsideCdata                    => self.inside_cdata(c),\n            State::InsideProcessingInstruction    => self.inside_processing_instruction(c),\n            State::ProcessingInstructionClosing   => self.processing_instruction_closing(c),\n        }\n    }\n\n    #[inline]\n    fn move_to(&mut self, st: State) -> Result {\n        self.st = st;\n        Ok(None)\n    }\n\n    #[inline]\n    fn move_to_with(&mut self, st: State, token: Token) -> Result {\n        self.st = st;\n        Ok(Some(token))\n    }\n\n    #[inline]\n    fn move_to_with_unread(&mut self, st: State, cs: &[char], token: Token) -> Result {\n        self.char_queue.extend(cs.iter().copied());\n        self.move_to_with(st, token)\n    }\n\n    fn handle_error(&mut self, chunk: &'static str, c: char) -> Result {\n        self.char_queue.push_back(c);\n        if self.skip_errors {\n            self.move_to_with(State::Normal, Token::Chunk(chunk))\n        } else {\n            Err(self.error(format!(\"Unexpected token '{chunk}' before '{c}'\")))\n        }\n    }\n\n    /// Encountered a char\n    fn normal(&mut self, c: char) -> Result {\n        match c {\n            '<'                        => self.move_to(State::TagStarted),\n            '>'                        => Ok(Some(Token::TagEnd)),\n            '/'                        => self.move_to(State::EmptyTagClosing),\n            '='                        => Ok(Some(Token::EqualsSign)),\n            '\"'                        => Ok(Some(Token::DoubleQuote)),\n            '\\''                       => Ok(Some(Token::SingleQuote)),\n            ']'                        => self.move_to(State::InvalidCDataClosing(ClosingSubstate::First)),\n            '&'                        => Ok(Some(Token::ReferenceStart)),\n            ';'                        => Ok(Some(Token::ReferenceEnd)),\n            _ if is_whitespace_char(c) => Ok(Some(Token::Whitespace(c))),\n            _                          => Ok(Some(Token::Character(c)))\n        }\n    }\n\n    fn inside_cdata(&mut self, c: char) -> Result {\n        match c {\n            ']'                        => self.move_to(State::CDataClosing(ClosingSubstate::First)),\n            _ if is_whitespace_char(c) => Ok(Some(Token::Whitespace(c))),\n            _                          => Ok(Some(Token::Character(c)))\n        }\n    }\n\n    fn inside_processing_instruction(&mut self, c: char) -> Result {\n        match c {\n            '?'                        => self.move_to(State::ProcessingInstructionClosing),\n            '<'                        => Ok(Some(Token::OpeningTagStart)),\n            '>'                        => Ok(Some(Token::TagEnd)),\n            '/'                        => Ok(Some(Token::ClosingTagStart)),\n            '='                        => Ok(Some(Token::EqualsSign)),\n            '\"'                        => Ok(Some(Token::DoubleQuote)),\n            '\\''                       => Ok(Some(Token::SingleQuote)),\n            '&'                        => Ok(Some(Token::ReferenceStart)),\n            ';'                        => Ok(Some(Token::ReferenceEnd)),\n            _ if is_whitespace_char(c) => Ok(Some(Token::Whitespace(c))),\n            _                          => Ok(Some(Token::Character(c)))\n        }\n    }\n\n    fn inside_comment_state(&mut self, c: char) -> Result {\n        match c {\n            '-'                        => self.move_to(State::CommentClosing(ClosingSubstate::First)),\n            _ if is_whitespace_char(c) => Ok(Some(Token::Whitespace(c))),\n            _                          => Ok(Some(Token::Character(c)))\n        }\n    }\n\n    /// Encountered '<'\n    fn tag_opened(&mut self, c: char) -> Result {\n        match c {\n            '?'                        => self.move_to_with(State::InsideProcessingInstruction, Token::ProcessingInstructionStart),\n            '/'                        => self.move_to_with(State::Normal, Token::ClosingTagStart),\n            '!'                        => self.move_to(State::CommentOrCDataOrDoctypeStarted),\n            _ if is_whitespace_char(c) => self.move_to_with_unread(State::Normal, &[c], Token::OpeningTagStart),\n            _ if is_name_char(c)       => self.move_to_with_unread(State::Normal, &[c], Token::OpeningTagStart),\n            _                          => self.handle_error(\"<\", c)\n        }\n    }\n\n    /// Encountered '<!'\n    fn comment_or_cdata_or_doctype_started(&mut self, c: char) -> Result {\n        match c {\n            '-' => self.move_to(State::CommentStarted),\n            '[' => self.move_to(State::CDataStarted(CDataStartedSubstate::E)),\n            'D' => self.move_to(State::DoctypeStarted(DoctypeStartedSubstate::D)),\n            _ => self.handle_error(\"<!\", c),\n        }\n    }\n\n    /// Encountered '<!-'\n    fn comment_started(&mut self, c: char) -> Result {\n        match c {\n            '-' => self.move_to_with(State::InsideComment, Token::CommentStart),\n            _ => self.handle_error(\"<!-\", c),\n        }\n    }\n\n    /// Encountered '<!['\n    fn cdata_started(&mut self, c: char, s: CDataStartedSubstate) -> Result {\n        use self::CDataStartedSubstate::{C, CD, CDA, CDAT, CDATA, E};\n        dispatch_on_enum_state!(self, s, c, State::CDataStarted,\n            E     ; 'C' ; C     ; \"<![\",\n            C     ; 'D' ; CD    ; \"<![C\",\n            CD    ; 'A' ; CDA   ; \"<![CD\",\n            CDA   ; 'T' ; CDAT  ; \"<![CDA\",\n            CDAT  ; 'A' ; CDATA ; \"<![CDAT\";\n            CDATA ; '[' ; \"<![CDATA\" ; self.move_to_with(State::InsideCdata, Token::CDataStart)\n        )\n    }\n\n    /// Encountered '<!D'\n    fn doctype_started(&mut self, c: char, s: DoctypeStartedSubstate) -> Result {\n        use self::DoctypeStartedSubstate::{D, DO, DOC, DOCT, DOCTY, DOCTYP};\n        dispatch_on_enum_state!(self, s, c, State::DoctypeStarted,\n            D      ; 'O' ; DO     ; \"<!D\",\n            DO     ; 'C' ; DOC    ; \"<!DO\",\n            DOC    ; 'T' ; DOCT   ; \"<!DOC\",\n            DOCT   ; 'Y' ; DOCTY  ; \"<!DOCT\",\n            DOCTY  ; 'P' ; DOCTYP ; \"<!DOCTY\";\n            DOCTYP ; 'E' ; \"<!DOCTYP\" ; self.move_to_with(State::DoctypeFinishing(1), Token::DoctypeStart)\n        )\n    }\n\n    /// State used while awaiting the closing bracket for the <!DOCTYPE tag\n    fn doctype_finishing(&mut self, c: char, d: u8) -> Result {\n        match c {\n            '<' => self.move_to(State::DoctypeFinishing(d + 1)),\n            '>' if d == 1 => self.move_to_with(State::Normal, Token::TagEnd),\n            '>' => self.move_to(State::DoctypeFinishing(d - 1)),\n            _ => Ok(None),\n        }\n    }\n\n    /// Encountered '?'\n    fn processing_instruction_closing(&mut self, c: char) -> Result {\n        match c {\n            '>' => self.move_to_with(State::Normal, Token::ProcessingInstructionEnd),\n            _ => self.move_to_with_unread(State::InsideProcessingInstruction, &[c], Token::Character('?')),\n        }\n    }\n\n    /// Encountered '/'\n    fn empty_element_closing(&mut self, c: char) -> Result {\n        match c {\n            '>' => self.move_to_with(State::Normal, Token::EmptyTagEnd),\n            _ => self.move_to_with_unread(State::Normal, &[c], Token::Character('/')),\n        }\n    }\n\n    /// Encountered '-'\n    fn comment_closing(&mut self, c: char, s: ClosingSubstate) -> Result {\n        match s {\n            ClosingSubstate::First => match c {\n                '-' => self.move_to(State::CommentClosing(ClosingSubstate::Second)),\n                _ => self.move_to_with_unread(State::InsideComment, &[c], Token::Character('-')),\n            },\n            ClosingSubstate::Second => match c {\n                '>' => self.move_to_with(State::Normal, Token::CommentEnd),\n                // double dash not followed by a greater-than is a hard error inside comment\n                _ => self.handle_error(\"--\", c),\n            },\n        }\n    }\n\n    /// Encountered ']'\n    fn cdata_closing(&mut self, c: char, s: ClosingSubstate) -> Result {\n        match s {\n            ClosingSubstate::First => match c {\n                ']' => self.move_to(State::CDataClosing(ClosingSubstate::Second)),\n                _ => self.move_to_with_unread(State::InsideCdata, &[c], Token::Character(']')),\n            },\n            ClosingSubstate::Second => match c {\n                '>' => self.move_to_with(State::Normal, Token::CDataEnd),\n                _ => self.move_to_with_unread(State::InsideCdata, &[']', c], Token::Character(']')),\n            },\n        }\n    }\n\n    /// Encountered ']'\n    fn invalid_cdata_closing(&mut self, c: char, s: ClosingSubstate) -> Result {\n        match s {\n            ClosingSubstate::First => match c {\n                ']' => self.move_to(State::InvalidCDataClosing(ClosingSubstate::Second)),\n                _ => self.move_to_with_unread(State::Normal, &[c], Token::Character(']')),\n            },\n            ClosingSubstate::Second => match c {\n                '>' => self.move_to_with(State::Normal, Token::CDataEnd),\n                _ => self.move_to_with_unread(State::Normal, &[']', c], Token::Character(']')),\n            },\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::common::Position;\n    use std::io::{BufReader, Cursor};\n\n    use super::{Lexer, Token};\n\n    macro_rules! assert_oks(\n        (for $lex:ident and $buf:ident ; $($e:expr)+) => ({\n            $(\n                assert_eq!(Ok(Some($e)), $lex.next_token(&mut $buf));\n             )+\n        })\n    );\n\n    macro_rules! assert_err(\n        (for $lex:ident and $buf:ident expect row $r:expr ; $c:expr, $s:expr) => ({\n            let err = $lex.next_token(&mut $buf);\n            assert!(err.is_err());\n            let err = err.unwrap_err();\n            assert_eq!($r as u64, err.position().row);\n            assert_eq!($c as u64, err.position().column);\n            assert_eq!($s, err.msg());\n        })\n    );\n\n    macro_rules! assert_none(\n        (for $lex:ident and $buf:ident) => (\n            assert_eq!(Ok(None), $lex.next_token(&mut $buf))\n        )\n    );\n\n    fn make_lex_and_buf(s: &str) -> (Lexer, BufReader<Cursor<Vec<u8>>>) {\n        (Lexer::new(), BufReader::new(Cursor::new(s.to_owned().into_bytes())))\n    }\n\n    #[test]\n    fn tricky_pi() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<?x<!-- &??><x>\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::ProcessingInstructionStart\n            Token::Character('x')\n            Token::OpeningTagStart // processing of <?xml?> relies on the extra tokens\n            Token::Character('!')\n            Token::Character('-')\n            Token::Character('-')\n            Token::Whitespace(' ')\n            Token::ReferenceStart\n            Token::Character('?')\n            Token::ProcessingInstructionEnd\n            Token::OpeningTagStart\n            Token::Character('x')\n            Token::TagEnd\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn simple_lexer_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<a p='q'> x<b z=\"y\">d\t</b></a><p/> <?nm ?> <!-- a c --> &nbsp;\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::Whitespace(' ')\n            Token::Character('p')\n            Token::EqualsSign\n            Token::SingleQuote\n            Token::Character('q')\n            Token::SingleQuote\n            Token::TagEnd\n            Token::Whitespace(' ')\n            Token::Character('x')\n            Token::OpeningTagStart\n            Token::Character('b')\n            Token::Whitespace(' ')\n            Token::Character('z')\n            Token::EqualsSign\n            Token::DoubleQuote\n            Token::Character('y')\n            Token::DoubleQuote\n            Token::TagEnd\n            Token::Character('d')\n            Token::Whitespace('\\t')\n            Token::ClosingTagStart\n            Token::Character('b')\n            Token::TagEnd\n            Token::ClosingTagStart\n            Token::Character('a')\n            Token::TagEnd\n            Token::OpeningTagStart\n            Token::Character('p')\n            Token::EmptyTagEnd\n            Token::Whitespace(' ')\n            Token::ProcessingInstructionStart\n            Token::Character('n')\n            Token::Character('m')\n            Token::Whitespace(' ')\n            Token::ProcessingInstructionEnd\n            Token::Whitespace(' ')\n            Token::CommentStart\n            Token::Whitespace(' ')\n            Token::Character('a')\n            Token::Whitespace(' ')\n            Token::Character('c')\n            Token::Whitespace(' ')\n            Token::CommentEnd\n            Token::Whitespace(' ')\n            Token::ReferenceStart\n            Token::Character('n')\n            Token::Character('b')\n            Token::Character('s')\n            Token::Character('p')\n            Token::ReferenceEnd\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn special_chars_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"?x!+ // -| ]z]]\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::Character('?')\n            Token::Character('x')\n            Token::Character('!')\n            Token::Character('+')\n            Token::Whitespace(' ')\n            Token::Character('/')\n            Token::Character('/')\n            Token::Whitespace(' ')\n            Token::Character('-')\n            Token::Character('|')\n            Token::Whitespace(' ')\n            Token::Character(']')\n            Token::Character('z')\n            Token::Chunk(\"]]\")\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn cdata_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<a><![CDATA[x y ?]]> </a>\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::TagEnd\n            Token::CDataStart\n            Token::Character('x')\n            Token::Whitespace(' ')\n            Token::Character('y')\n            Token::Whitespace(' ')\n            Token::Character('?')\n            Token::CDataEnd\n            Token::Whitespace(' ')\n            Token::ClosingTagStart\n            Token::Character('a')\n            Token::TagEnd\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn cdata_closers_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<![CDATA[] > ]> ]]><!---->]]<a>\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::CDataStart\n            Token::Character(']')\n            Token::Whitespace(' ')\n            Token::Character('>')\n            Token::Whitespace(' ')\n            Token::Character(']')\n            Token::Character('>')\n            Token::Whitespace(' ')\n            Token::CDataEnd\n            Token::CommentStart\n            Token::CommentEnd\n            Token::Character(']')\n            Token::Character(']')\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::TagEnd\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn doctype_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<a><!DOCTYPE ab xx z> \"#\n        );\n        assert_oks!(for lex and buf ;\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::TagEnd\n            Token::DoctypeStart\n            Token::TagEnd\n            Token::Whitespace(' ')\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn tricky_comments() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<a><!-- C ->--></a>\"#\n        );\n        assert_oks!(for lex and buf ;\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::TagEnd\n            Token::CommentStart\n            Token::Whitespace(' ')\n            Token::Character('C')\n            Token::Whitespace(' ')\n            Token::Character('-')\n            Token::Character('>')\n            Token::CommentEnd\n            Token::ClosingTagStart\n            Token::Character('a')\n            Token::TagEnd\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn doctype_with_internal_subset_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<a><!DOCTYPE ab[<!ELEMENT ba> ]> \"#\n        );\n        assert_oks!(for lex and buf ;\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::TagEnd\n            Token::DoctypeStart\n            Token::TagEnd\n            Token::Whitespace(' ')\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn end_of_stream_handling_ok() {\n        macro_rules! eof_check(\n            ($data:expr ; $token:expr) => ({\n                let (mut lex, mut buf) = make_lex_and_buf($data);\n                assert_oks!(for lex and buf ; $token);\n                assert_none!(for lex and buf);\n            })\n        );\n        eof_check!(\"?\"  ; Token::Character('?'));\n        eof_check!(\"/\"  ; Token::Character('/'));\n        eof_check!(\"-\"  ; Token::Character('-'));\n        eof_check!(\"]\"  ; Token::Character(']'));\n        eof_check!(\"]]\" ; Token::Chunk(\"]]\"));\n    }\n\n    #[test]\n    fn end_of_stream_handling_error() {\n        macro_rules! eof_check(\n            ($data:expr; $r:expr, $c:expr) => ({\n                let (mut lex, mut buf) = make_lex_and_buf($data);\n                assert_err!(for lex and buf expect row $r ; $c, \"Unexpected end of stream\");\n                assert_none!(for lex and buf);\n            })\n        );\n        eof_check!(\"<\"        ; 0, 1);\n        eof_check!(\"<!\"       ; 0, 2);\n        eof_check!(\"<!-\"      ; 0, 3);\n        eof_check!(\"<![\"      ; 0, 3);\n        eof_check!(\"<![C\"     ; 0, 4);\n        eof_check!(\"<![CD\"    ; 0, 5);\n        eof_check!(\"<![CDA\"   ; 0, 6);\n        eof_check!(\"<![CDAT\"  ; 0, 7);\n        eof_check!(\"<![CDATA\" ; 0, 8);\n        // eof_check!(\"--\"       ; 0, 2);\n    }\n\n    #[test]\n    fn error_in_comment_or_cdata_prefix() {\n        let (mut lex, mut buf) = make_lex_and_buf(\"<!x\");\n        assert_err!(for lex and buf expect row 0 ; 0,\n            \"Unexpected token '<!' before 'x'\"\n        );\n\n        let (mut lex, mut buf) = make_lex_and_buf(\"<!x\");\n        lex.disable_errors();\n        assert_oks!(for lex and buf ;\n            Token::Chunk(\"<!\")\n            Token::Character('x')\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn error_in_comment_started() {\n        let (mut lex, mut buf) = make_lex_and_buf(\"<!-\\t\");\n        assert_err!(for lex and buf expect row 0 ; 0,\n            \"Unexpected token '<!-' before '\\t'\"\n        );\n\n        let (mut lex, mut buf) = make_lex_and_buf(\"<!-\\t\");\n        lex.disable_errors();\n        assert_oks!(for lex and buf ;\n            Token::Chunk(\"<!-\")\n            Token::Whitespace('\\t')\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn error_in_comment_two_dashes_not_at_end() {\n        let (mut lex, mut buf) = make_lex_and_buf(\"--x\");\n        lex.st = super::State::InsideComment;\n        assert_err!(for lex and buf expect row 0; 0,\n            \"Unexpected token '--' before 'x'\"\n        );\n\n        let (mut lex, mut buf) = make_lex_and_buf(\"--x\");\n        assert_oks!(for lex and buf ;\n            Token::Character('-')\n            Token::Character('-')\n            Token::Character('x')\n        );\n    }\n\n    macro_rules! check_case(\n        ($chunk:expr, $app:expr; $data:expr; $r:expr, $c:expr, $s:expr) => ({\n            let (mut lex, mut buf) = make_lex_and_buf($data);\n            assert_err!(for lex and buf expect row $r ; $c, $s);\n\n            let (mut lex, mut buf) = make_lex_and_buf($data);\n            lex.disable_errors();\n            assert_oks!(for lex and buf ;\n                Token::Chunk($chunk)\n                Token::Character($app)\n            );\n            assert_none!(for lex and buf);\n        })\n    );\n\n    #[test]\n    fn error_in_cdata_started() {\n        check_case!(\"<![\",      '['; \"<![[\"      ; 0, 0, \"Unexpected token '<![' before '['\");\n        check_case!(\"<![C\",     '['; \"<![C[\"     ; 0, 0, \"Unexpected token '<![C' before '['\");\n        check_case!(\"<![CD\",    '['; \"<![CD[\"    ; 0, 0, \"Unexpected token '<![CD' before '['\");\n        check_case!(\"<![CDA\",   '['; \"<![CDA[\"   ; 0, 0, \"Unexpected token '<![CDA' before '['\");\n        check_case!(\"<![CDAT\",  '['; \"<![CDAT[\"  ; 0, 0, \"Unexpected token '<![CDAT' before '['\");\n        check_case!(\"<![CDATA\", '|'; \"<![CDATA|\" ; 0, 0, \"Unexpected token '<![CDATA' before '|'\");\n    }\n\n    #[test]\n    fn error_in_doctype_started() {\n        check_case!(\"<!D\",      'a'; \"<!Da\"      ; 0, 0, \"Unexpected token '<!D' before 'a'\");\n        check_case!(\"<!DO\",     'b'; \"<!DOb\"     ; 0, 0, \"Unexpected token '<!DO' before 'b'\");\n        check_case!(\"<!DOC\",    'c'; \"<!DOCc\"    ; 0, 0, \"Unexpected token '<!DOC' before 'c'\");\n        check_case!(\"<!DOCT\",   'd'; \"<!DOCTd\"   ; 0, 0, \"Unexpected token '<!DOCT' before 'd'\");\n        check_case!(\"<!DOCTY\",  'e'; \"<!DOCTYe\"  ; 0, 0, \"Unexpected token '<!DOCTY' before 'e'\");\n        check_case!(\"<!DOCTYP\", 'f'; \"<!DOCTYPf\" ; 0, 0, \"Unexpected token '<!DOCTYP' before 'f'\");\n    }\n\n\n\n    #[test]\n    fn issue_98_cdata_ending_with_right_bracket() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<![CDATA[Foo [Bar]]]>\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::CDataStart\n            Token::Character('F')\n            Token::Character('o')\n            Token::Character('o')\n            Token::Whitespace(' ')\n            Token::Character('[')\n            Token::Character('B')\n            Token::Character('a')\n            Token::Character('r')\n            Token::Character(']')\n            Token::CDataEnd\n        );\n        assert_none!(for lex and buf);\n    }\n}\n", "use crate::reader::events::XmlEvent;\nuse crate::reader::lexer::Token;\n\nuse super::{PullParser, Result, State};\n\nimpl PullParser {\n    pub fn inside_cdata(&mut self, t: Token) -> Option<Result> {\n        match t {\n            Token::CDataEnd => {\n                self.lexer.enable_errors();\n                let event = if self.config.cdata_to_characters {\n                    None\n                } else {\n                    let data = self.take_buf();\n                    Some(Ok(XmlEvent::CData(data)))\n                };\n                self.into_state(State::OutsideTag, event)\n            }\n\n            Token::Whitespace(c) => {\n                self.buf.push(c);\n                None\n            }\n\n            Token::Character(c) => {\n                self.inside_whitespace = false;\n                self.buf.push(c);\n                None\n            }\n\n            Token::Chunk(s) => {\n                self.inside_whitespace = false;\n                self.buf.push_str(s);\n                None\n            }\n\n            _ => unreachable!(),\n        }\n    }\n}\n", "use crate::reader::lexer::Token;\n\nuse super::{PullParser, Result, State};\n\nimpl PullParser {\n    pub fn inside_doctype(&mut self, t: Token) -> Option<Result> {\n        match t {\n            Token::TagEnd => {\n                self.lexer.enable_errors();\n                self.into_state_continue(State::OutsideTag)\n            }\n\n            _ => None,\n        }\n    }\n}\n", "use crate::common::{is_name_char, is_name_start_char};\n\nuse crate::reader::events::XmlEvent;\nuse crate::reader::lexer::Token;\n\nuse super::{DeclarationSubstate, ProcessingInstructionSubstate, PullParser, Result, State};\n\nimpl PullParser {\n    pub fn inside_processing_instruction(&mut self, t: Token, s: ProcessingInstructionSubstate) -> Option<Result> {\n        match s {\n            ProcessingInstructionSubstate::PIInsideName => match t {\n                Token::Character(c) if !self.buf_has_data() && is_name_start_char(c) ||\n                                 self.buf_has_data() && is_name_char(c) => self.append_char_continue(c),\n\n                Token::ProcessingInstructionEnd => {\n                    // self.buf contains PI name\n                    let name = self.take_buf();\n\n                    // Don't need to check for declaration because it has mandatory attributes\n                    // but there is none\n                    match &name[..] {\n                        // Name is empty, it is an error\n                        \"\" => Some(self_error!(self; \"Encountered processing instruction without name\")),\n\n                        // Found <?xml-like PI not at the beginning of a document,\n                        // it is an error - see section 2.6 of XML 1.1 spec\n                        \"xml\"|\"xmL\"|\"xMl\"|\"xML\"|\"Xml\"|\"XmL\"|\"XMl\"|\"XML\" =>\n                            Some(self_error!(self; \"Invalid processing instruction: <?{}\", name)),\n\n                        // All is ok, emitting event\n                        _ => {\n                            self.into_state_emit(\n                                State::OutsideTag,\n                                Ok(XmlEvent::ProcessingInstruction {\n                                    name,\n                                    data: None\n                                })\n                            )\n                        }\n                    }\n                }\n\n                Token::Whitespace(_) => {\n                    // self.buf contains PI name\n                    let name = self.take_buf();\n\n                    match &name[..] {\n                        // We have not ever encountered an element and have not parsed XML declaration\n                        \"xml\" if !self.encountered_element && !self.parsed_declaration =>\n                            self.into_state_continue(State::InsideDeclaration(DeclarationSubstate::BeforeVersion)),\n\n                        // Found <?xml-like PI after the beginning of a document,\n                        // it is an error - see section 2.6 of XML 1.1 spec\n                        \"xml\"|\"xmL\"|\"xMl\"|\"xML\"|\"Xml\"|\"XmL\"|\"XMl\"|\"XML\"\n                            if self.encountered_element || self.parsed_declaration =>\n                            Some(self_error!(self; \"Invalid processing instruction: <?{}\", name)),\n\n                        // All is ok, starting parsing PI data\n                        _ => {\n                            self.data.name = name;\n                            self.into_state_continue(State::InsideProcessingInstruction(ProcessingInstructionSubstate::PIInsideData))\n                        }\n                    }\n                }\n\n                _ => Some(self_error!(self; \"Unexpected token: <?{}{}\", self.buf, t)),\n            },\n\n            ProcessingInstructionSubstate::PIInsideData => match t {\n                Token::ProcessingInstructionEnd => {\n                    self.lexer.enable_errors();\n                    let name = self.data.take_name();\n                    let data = self.take_buf();\n                    self.into_state_emit(\n                        State::OutsideTag,\n                        Ok(XmlEvent::ProcessingInstruction {\n                            name,\n                            data: Some(data),\n                        }),\n                    )\n                },\n\n                // Any other token should be treated as plain characters\n                _ => {\n                    t.push_to_string(&mut self.buf);\n                    None\n                }\n            },\n        }\n    }\n}\n", "//! Contains an implementation of pull-based XML parser.\n\nuse std::borrow::Cow;\nuse std::io::prelude::*;\n\nuse crate::attribute::OwnedAttribute;\nuse crate::common::{self, is_name_char, is_name_start_char, Position, TextPosition, XmlVersion};\nuse crate::name::OwnedName;\nuse crate::namespace::NamespaceStack;\n\nuse crate::reader::config::ParserConfig;\nuse crate::reader::events::XmlEvent;\nuse crate::reader::lexer::{Lexer, Token};\n\nmacro_rules! gen_takes(\n    ($($field:ident -> $method:ident, $t:ty, $def:expr);+) => (\n        $(\n        impl MarkupData {\n            #[inline]\n            #[allow(clippy::mem_replace_option_with_none)]\n            fn $method(&mut self) -> $t {\n                std::mem::replace(&mut self.$field, $def)\n            }\n        }\n        )+\n    )\n);\n\ngen_takes!(\n    name         -> take_name, String, String::new();\n    ref_data     -> take_ref_data, String, String::new();\n\n    version      -> take_version, Option<common::XmlVersion>, None;\n    encoding     -> take_encoding, Option<String>, None;\n    standalone   -> take_standalone, Option<bool>, None;\n\n    element_name -> take_element_name, Option<OwnedName>, None;\n\n    attr_name    -> take_attr_name, Option<OwnedName>, None;\n    attributes   -> take_attributes, Vec<OwnedAttribute>, vec!()\n);\n\nmacro_rules! self_error(\n    ($this:ident; $msg:expr) => ($this.error($msg));\n    ($this:ident; $fmt:expr, $($arg:expr),+) => ($this.error(format!($fmt, $($arg),+)))\n);\n\nmod inside_cdata;\nmod inside_closing_tag_name;\nmod inside_comment;\nmod inside_declaration;\nmod inside_doctype;\nmod inside_opening_tag;\nmod inside_processing_instruction;\nmod inside_reference;\nmod outside_tag;\n\nstatic DEFAULT_VERSION: XmlVersion = XmlVersion::Version10;\nstatic DEFAULT_ENCODING: &str = \"UTF-8\";\nstatic DEFAULT_STANDALONE: Option<bool> = None;\n\ntype ElementStack = Vec<OwnedName>;\npub type Result = super::Result<XmlEvent>;\n\n/// Pull-based XML parser.\npub(crate) struct PullParser {\n    config: ParserConfig,\n    lexer: Lexer,\n    st: State,\n    buf: String,\n    nst: NamespaceStack,\n\n    data: MarkupData,\n    final_result: Option<Result>,\n    next_event: Option<Result>,\n    est: ElementStack,\n    pos: Vec<TextPosition>,\n\n    encountered_element: bool,\n    parsed_declaration: bool,\n    inside_whitespace: bool,\n    read_prefix_separator: bool,\n    pop_namespace: bool,\n}\n\nimpl PullParser {\n    /// Returns a new parser using the given config.\n    pub fn new(config: ParserConfig) -> PullParser {\n        PullParser {\n            config,\n            lexer: Lexer::new(),\n            st: State::OutsideTag,\n            buf: String::new(),\n            nst: NamespaceStack::default(),\n\n            data: MarkupData {\n                name: String::new(),\n                version: None,\n                encoding: None,\n                standalone: None,\n                ref_data: String::new(),\n                element_name: None,\n                quote: None,\n                attr_name: None,\n                attributes: Vec::new(),\n            },\n            final_result: None,\n            next_event: None,\n            est: Vec::new(),\n            pos: vec![TextPosition::new()],\n\n            encountered_element: false,\n            parsed_declaration: false,\n            inside_whitespace: true,\n            read_prefix_separator: false,\n            pop_namespace: false,\n        }\n    }\n\n    /// Checks if this parser ignores the end of stream errors.\n    pub fn is_ignoring_end_of_stream(&self) -> bool { self.config.ignore_end_of_stream }\n}\n\nimpl Position for PullParser {\n    /// Returns the position of the last event produced by the parser\n    #[inline]\n    fn position(&self) -> TextPosition {\n        self.pos[0]\n    }\n}\n\n#[derive(Clone, PartialEq)]\npub enum State {\n    OutsideTag,\n    InsideOpeningTag(OpeningTagSubstate),\n    InsideClosingTag(ClosingTagSubstate),\n    InsideProcessingInstruction(ProcessingInstructionSubstate),\n    InsideComment,\n    InsideCData,\n    InsideDeclaration(DeclarationSubstate),\n    InsideDoctype,\n    InsideReference(Box<State>),\n}\n\n#[derive(Clone, PartialEq)]\npub enum OpeningTagSubstate {\n    InsideName,\n\n    InsideTag,\n\n    InsideAttributeName,\n    AfterAttributeName,\n\n    InsideAttributeValue,\n}\n\n#[derive(Clone, PartialEq)]\npub enum ClosingTagSubstate {\n    CTInsideName,\n    CTAfterName,\n}\n\n#[derive(Clone, PartialEq)]\npub enum ProcessingInstructionSubstate {\n    PIInsideName,\n    PIInsideData,\n}\n\n#[derive(Clone, PartialEq)]\npub enum DeclarationSubstate {\n    BeforeVersion,\n    InsideVersion,\n    AfterVersion,\n\n    InsideVersionValue,\n    AfterVersionValue,\n\n    InsideEncoding,\n    AfterEncoding,\n\n    InsideEncodingValue,\n\n    BeforeStandaloneDecl,\n    InsideStandaloneDecl,\n    AfterStandaloneDecl,\n\n    InsideStandaloneDeclValue,\n    AfterStandaloneDeclValue,\n}\n\n#[derive(PartialEq)]\nenum QualifiedNameTarget {\n    AttributeNameTarget,\n    OpeningTagNameTarget,\n    ClosingTagNameTarget,\n}\n\n#[derive(Copy, Clone, PartialEq, Eq)]\nenum QuoteToken {\n    SingleQuoteToken,\n    DoubleQuoteToken,\n}\n\nimpl QuoteToken {\n    fn from_token(t: &Token) -> QuoteToken {\n        match *t {\n            Token::SingleQuote => QuoteToken::SingleQuoteToken,\n            Token::DoubleQuote => QuoteToken::DoubleQuoteToken,\n            _ => panic!(\"Unexpected token: {t}\"),\n        }\n    }\n\n    fn as_token(self) -> Token {\n        match self {\n            QuoteToken::SingleQuoteToken => Token::SingleQuote,\n            QuoteToken::DoubleQuoteToken => Token::DoubleQuote,\n        }\n    }\n}\n\nstruct MarkupData {\n    name: String,     // used for processing instruction name\n    ref_data: String,  // used for reference content\n\n    version: Option<common::XmlVersion>,  // used for XML declaration version\n    encoding: Option<String>,  // used for XML declaration encoding\n    standalone: Option<bool>,  // used for XML declaration standalone parameter\n\n    element_name: Option<OwnedName>,  // used for element name\n\n    quote: Option<QuoteToken>,  // used to hold opening quote for attribute value\n    attr_name: Option<OwnedName>,  // used to hold attribute name\n    attributes: Vec<OwnedAttribute>   // used to hold all accumulated attributes\n}\n\nimpl PullParser {\n    /// Returns next event read from the given buffer.\n    ///\n    /// This method should be always called with the same buffer. If you call it\n    /// providing different buffers each time, the result will be undefined.\n    pub fn next<R: Read>(&mut self, r: &mut R) -> Result {\n        if let Some(ref ev) = self.final_result {\n            return ev.clone();\n        }\n\n        if let Some(ev) = self.next_event.take() {\n            return ev;\n        }\n\n        if self.pop_namespace {\n            self.pop_namespace = false;\n            self.nst.pop();\n        }\n\n        loop {\n            // While lexer gives us Ok(maybe_token) -- we loop.\n            // Upon having a complete XML-event -- we return from the whole function.\n            match self.lexer.next_token(r) {\n                Ok(maybe_token) =>\n                    match maybe_token {\n                        None => break,\n                        Some(token) =>\n                            match self.dispatch_token(token) {\n                                None => {} // continue\n                                Some(Ok(XmlEvent::EndDocument)) =>\n                                    return {\n                                        self.next_pos();\n                                        self.set_final_result(Ok(XmlEvent::EndDocument))\n                                    },\n                                Some(Ok(xml_event)) =>\n                                    return {\n                                        self.next_pos();\n                                        Ok(xml_event)\n                                    },\n                                Some(Err(xml_error)) =>\n                                    return {\n                                        self.next_pos();\n                                        self.set_final_result(Err(xml_error))\n                                    },\n                            }\n                    },\n                Err(lexer_error) =>\n                    return self.set_final_result(Err(lexer_error)),\n            }\n        }\n\n        // Handle end of stream\n        // Forward pos to the lexer head\n        self.next_pos();\n        let ev = if self.depth() == 0 {\n            if self.encountered_element && self.st == State::OutsideTag {  // all is ok\n                Ok(XmlEvent::EndDocument)\n            } else if !self.encountered_element {\n                self_error!(self; \"Unexpected end of stream: no root element found\")\n            } else {  // self.st != State::OutsideTag\n                self_error!(self; \"Unexpected end of stream\")  // TODO: add expected hint?\n            }\n        } else if self.config.ignore_end_of_stream {\n            self.final_result = None;\n            self.lexer.reset_eof_handled();\n            return self_error!(self; \"Unexpected end of stream: still inside the root element\");\n        } else {\n            self_error!(self; \"Unexpected end of stream: still inside the root element\")\n        };\n        self.set_final_result(ev)\n    }\n\n    // This function is to be called when a terminal event is reached.\n    // The function sets up the `self.final_result` into `Some(result)` and return `result`.\n    fn set_final_result(&mut self, result: Result) -> Result {\n        self.final_result = Some(result.clone());\n        result\n    }\n\n    #[inline]\n    fn error<M: Into<Cow<'static, str>>>(&self, msg: M) -> Result {\n        Err((&self.lexer, msg).into())\n    }\n\n    #[inline]\n    fn next_pos(&mut self) {\n        if self.pos.len() > 1 {\n            self.pos.remove(0);\n        } else {\n            self.pos[0] = self.lexer.position();\n        }\n    }\n\n    #[inline]\n    fn push_pos(&mut self) {\n        self.pos.push(self.lexer.position());\n    }\n\n    fn dispatch_token(&mut self, t: Token) -> Option<Result> {\n        match self.st.clone() {\n            State::OutsideTag                     => self.outside_tag(t),\n            State::InsideProcessingInstruction(s) => self.inside_processing_instruction(t, s),\n            State::InsideDeclaration(s)           => self.inside_declaration(t, s),\n            State::InsideDoctype                  => self.inside_doctype(t),\n            State::InsideOpeningTag(s)            => self.inside_opening_tag(t, s),\n            State::InsideClosingTag(s)            => self.inside_closing_tag_name(t, s),\n            State::InsideComment                  => self.inside_comment(t),\n            State::InsideCData                    => self.inside_cdata(t),\n            State::InsideReference(s)             => self.inside_reference(t, *s)\n        }\n    }\n\n    #[inline]\n    fn depth(&self) -> usize {\n        self.est.len()\n    }\n\n    #[inline]\n    fn buf_has_data(&self) -> bool {\n        !self.buf.is_empty()\n    }\n\n    #[inline]\n    fn take_buf(&mut self) -> String {\n        std::mem::take(&mut self.buf)\n    }\n\n    #[inline]\n    fn append_char_continue(&mut self, c: char) -> Option<Result> {\n        self.buf.push(c);\n        None\n    }\n\n    #[inline]\n    fn into_state(&mut self, st: State, ev: Option<Result>) -> Option<Result> {\n        self.st = st;\n        ev\n    }\n\n    #[inline]\n    fn into_state_continue(&mut self, st: State) -> Option<Result> {\n        self.into_state(st, None)\n    }\n\n    #[inline]\n    fn into_state_emit(&mut self, st: State, ev: Result) -> Option<Result> {\n        self.into_state(st, Some(ev))\n    }\n\n    /// Dispatches tokens in order to process qualified name. If qualified name cannot be parsed,\n    /// an error is returned.\n    ///\n    /// # Parameters\n    /// * `t`       --- next token;\n    /// * `on_name` --- a callback which is executed when whitespace is encountered.\n    fn read_qualified_name<F>(&mut self, t: Token, target: QualifiedNameTarget, on_name: F) -> Option<Result>\n      where F: Fn(&mut PullParser, Token, OwnedName) -> Option<Result> {\n        // We can get here for the first time only when self.data.name contains zero or one character,\n        // but first character cannot be a colon anyway\n        if self.buf.len() <= 1 {\n            self.read_prefix_separator = false;\n        }\n\n        let invoke_callback = |this: &mut PullParser, t| {\n            let name = this.take_buf();\n            match name.parse() {\n                Ok(name) => on_name(this, t, name),\n                Err(_) => Some(self_error!(this; \"Qualified name is invalid: {}\", name)),\n            }\n        };\n\n        match t {\n            // There can be only one colon, and not as the first character\n            Token::Character(':') if self.buf_has_data() && !self.read_prefix_separator => {\n                self.buf.push(':');\n                self.read_prefix_separator = true;\n                None\n            }\n\n            Token::Character(c) if c != ':' && (!self.buf_has_data() && is_name_start_char(c) ||\n                                          self.buf_has_data() && is_name_char(c)) =>\n                self.append_char_continue(c),\n\n            Token::EqualsSign if target == QualifiedNameTarget::AttributeNameTarget => invoke_callback(self, t),\n\n            Token::EmptyTagEnd if target == QualifiedNameTarget::OpeningTagNameTarget => invoke_callback(self, t),\n\n            Token::TagEnd if target == QualifiedNameTarget::OpeningTagNameTarget ||\n                      target == QualifiedNameTarget::ClosingTagNameTarget => invoke_callback(self, t),\n\n            Token::Whitespace(_) => invoke_callback(self, t),\n\n            _ => Some(self_error!(self; \"Unexpected token inside qualified name: {}\", t))\n        }\n    }\n\n    /// Dispatches tokens in order to process attribute value.\n    ///\n    /// # Parameters\n    /// * `t`        --- next token;\n    /// * `on_value` --- a callback which is called when terminating quote is encountered.\n    fn read_attribute_value<F>(&mut self, t: Token, on_value: F) -> Option<Result>\n      where F: Fn(&mut PullParser, String) -> Option<Result> {\n        match t {\n            Token::Whitespace(_) if self.data.quote.is_none() => None,  // skip leading whitespace\n\n            Token::DoubleQuote | Token::SingleQuote => match self.data.quote {\n                None => {  // Entered attribute value\n                    self.data.quote = Some(QuoteToken::from_token(&t));\n                    None\n                }\n                Some(q) if q.as_token() == t => {\n                    self.data.quote = None;\n                    let value = self.take_buf();\n                    on_value(self, value)\n                }\n                _ => {\n                    t.push_to_string(&mut self.buf);\n                    None\n                }\n            },\n\n            Token::ReferenceStart => {\n                let st = Box::new(self.st.clone());\n                self.into_state_continue(State::InsideReference(st))\n            }\n\n            Token::OpeningTagStart =>\n                Some(self_error!(self; \"Unexpected token inside attribute value: <\")),\n\n            // Every character except \" and ' and < is okay\n            _  => {\n                t.push_to_string(&mut self.buf);\n                None\n            }\n        }\n    }\n\n    fn emit_start_element(&mut self, emit_end_element: bool) -> Option<Result> {\n        let mut name = self.data.take_element_name().unwrap();\n        let mut attributes = self.data.take_attributes();\n\n        // check whether the name prefix is bound and fix its namespace\n        match self.nst.get(name.borrow().prefix_repr()) {\n            Some(\"\") => name.namespace = None,  // default namespace\n            Some(ns) => name.namespace = Some(ns.into()),\n            None => return Some(self_error!(self; \"Element {} prefix is unbound\", name))\n        }\n\n        // check and fix accumulated attributes prefixes\n        for attr in &mut attributes {\n            if let Some(ref pfx) = attr.name.prefix {\n                let new_ns = match self.nst.get(pfx) {\n                    Some(\"\") => None,  // default namespace\n                    Some(ns) => Some(ns.into()),\n                    None => return Some(self_error!(self; \"Attribute {} prefix is unbound\", attr.name))\n                };\n                attr.name.namespace = new_ns;\n            }\n        }\n\n        if emit_end_element {\n            self.pop_namespace = true;\n            self.next_event = Some(Ok(XmlEvent::EndElement {\n                name: name.clone()\n            }));\n        } else {\n            self.est.push(name.clone());\n        }\n        let namespace = self.nst.squash();\n        self.into_state_emit(State::OutsideTag, Ok(XmlEvent::StartElement {\n            name,\n            attributes,\n            namespace\n        }))\n    }\n\n    fn emit_end_element(&mut self) -> Option<Result> {\n        let mut name = self.data.take_element_name().unwrap();\n\n        // check whether the name prefix is bound and fix its namespace\n        match self.nst.get(name.borrow().prefix_repr()) {\n            Some(\"\") => name.namespace = None,  // default namespace\n            Some(ns) => name.namespace = Some(ns.into()),\n            None => return Some(self_error!(self; \"Element {} prefix is unbound\", name))\n        }\n\n        let op_name = self.est.pop().unwrap();\n\n        if name == op_name {\n            self.pop_namespace = true;\n            self.into_state_emit(State::OutsideTag, Ok(XmlEvent::EndElement { name }))\n        } else {\n            Some(self_error!(self; \"Unexpected closing tag: {}, expected {}\", name, op_name))\n        }\n    }\n\n}\n\n#[cfg(test)]\nmod tests {\n    use std::io::BufReader;\n\n    use crate::common::{Position, TextPosition};\n    use crate::name::OwnedName;\n    use crate::attribute::OwnedAttribute;\n    use crate::reader::parser::PullParser;\n    use crate::reader::ParserConfig;\n    use crate::reader::events::XmlEvent;\n\n    fn new_parser() -> PullParser {\n        PullParser::new(ParserConfig::new())\n    }\n\n    macro_rules! expect_event(\n        ($r:expr, $p:expr, $t:pat) => (\n            match $p.next(&mut $r) {\n                $t => {}\n                e => panic!(\"Unexpected event: {:?}\", e)\n            }\n        );\n        ($r:expr, $p:expr, $t:pat => $c:expr ) => (\n            match $p.next(&mut $r) {\n                $t if $c => {}\n                e => panic!(\"Unexpected event: {:?}\", e)\n            }\n        )\n    );\n\n    macro_rules! test_data(\n        ($d:expr) => ({\n            static DATA: &'static str = $d;\n            let r = BufReader::new(DATA.as_bytes());\n            let p = new_parser();\n            (r, p)\n        })\n    );\n\n    #[test]\n    fn issue_3_semicolon_in_attribute_value() {\n        let (mut r, mut p) = test_data!(r#\"\n            <a attr=\"zzz;zzz\" />\n        \"#);\n\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Ok(XmlEvent::StartElement { ref name, ref attributes, ref namespace }) =>\n            *name == OwnedName::local(\"a\") &&\n             attributes.len() == 1 &&\n             attributes[0] == OwnedAttribute::new(OwnedName::local(\"attr\"), \"zzz;zzz\") &&\n             namespace.is_essentially_empty()\n        );\n        expect_event!(r, p, Ok(XmlEvent::EndElement { ref name }) => *name == OwnedName::local(\"a\"));\n        expect_event!(r, p, Ok(XmlEvent::EndDocument));\n    }\n\n    #[test]\n    fn issue_140_entity_reference_inside_tag() {\n        let (mut r, mut p) = test_data!(r#\"\n            <bla>&#9835;</bla>\n        \"#);\n\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Ok(XmlEvent::StartElement { ref name, .. }) => *name == OwnedName::local(\"bla\"));\n        expect_event!(r, p, Ok(XmlEvent::Characters(ref s)) => s == \"\\u{266b}\");\n        expect_event!(r, p, Ok(XmlEvent::EndElement { ref name, .. }) => *name == OwnedName::local(\"bla\"));\n        expect_event!(r, p, Ok(XmlEvent::EndDocument));\n    }\n\n    #[test]\n    fn issue_220_comment() {\n        let (mut r, mut p) = test_data!(r#\"<x><!-- <!--></x>\"#);\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Ok(XmlEvent::StartElement { .. }));\n        expect_event!(r, p, Ok(XmlEvent::EndElement { .. }));\n        expect_event!(r, p, Ok(XmlEvent::EndDocument));\n\n        let (mut r, mut p) = test_data!(r#\"<x><!-- <!---></x>\"#);\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Ok(XmlEvent::StartElement { .. }));\n        expect_event!(r, p, Err(_)); // ---> is forbidden in comments\n\n        let (mut r, mut p) = test_data!(r#\"<x><!--<text&x;> <!--></x>\"#);\n        p.config.ignore_comments = false;\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Ok(XmlEvent::StartElement { .. }));\n        expect_event!(r, p, Ok(XmlEvent::Comment(s)) => s == \"<text&x;> <!\");\n        expect_event!(r, p, Ok(XmlEvent::EndElement { .. }));\n        expect_event!(r, p, Ok(XmlEvent::EndDocument));\n    }\n\n    #[test]\n    fn opening_tag_in_attribute_value() {\n        let (mut r, mut p) = test_data!(r#\"\n            <a attr=\"zzz<zzz\" />\n        \"#);\n\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Err(ref e) =>\n            e.msg() == \"Unexpected token inside attribute value: <\" &&\n            e.position() == TextPosition { row: 1, column: 24 }\n        );\n    }\n}\n", "use crate::common::is_whitespace_char;\n\nuse crate::reader::events::XmlEvent;\nuse crate::reader::lexer::Token;\n\nuse super::{\n    ClosingTagSubstate, OpeningTagSubstate, ProcessingInstructionSubstate, PullParser, Result,\n    State, DEFAULT_ENCODING, DEFAULT_STANDALONE, DEFAULT_VERSION,\n};\n\nimpl PullParser {\n    pub fn outside_tag(&mut self, t: Token) -> Option<Result> {\n        match t {\n            Token::ReferenceStart =>\n                self.into_state_continue(State::InsideReference(Box::new(State::OutsideTag))),\n\n            Token::Whitespace(_) if self.depth() == 0 && self.config.ignore_root_level_whitespace => None,  // skip whitespace outside of the root element\n\n            Token::Whitespace(_) if self.config.trim_whitespace && !self.buf_has_data() => None,\n\n            Token::Whitespace(c) => {\n                if !self.buf_has_data() {\n                    self.push_pos();\n                }\n                self.append_char_continue(c)\n            }\n\n            _ if t.contains_char_data() && self.depth() == 0 =>\n                Some(self_error!(self; \"Unexpected characters outside the root element: {}\", t)),\n\n            _ if t.contains_char_data() => {  // Non-whitespace char data\n                if !self.buf_has_data() {\n                    self.push_pos();\n                }\n                self.inside_whitespace = false;\n                t.push_to_string(&mut self.buf);\n                None\n            }\n\n            Token::ReferenceEnd => { // Semi-colon in a text outside an entity\n                self.inside_whitespace = false;\n                Token::ReferenceEnd.push_to_string(&mut self.buf);\n                None\n            }\n\n            Token::CommentStart if self.config.coalesce_characters && self.config.ignore_comments => {\n                // We need to switch the lexer into a comment mode inside comments\n                self.into_state_continue(State::InsideComment)\n            }\n\n            Token::CDataStart if self.config.coalesce_characters && self.config.cdata_to_characters => {\n                if !self.buf_has_data() {\n                    self.push_pos();\n                }\n                // We need to disable lexing errors inside CDATA\n                self.into_state_continue(State::InsideCData)\n            }\n\n            _ => {\n                // Encountered some markup event, flush the buffer as characters\n                // or a whitespace\n                let mut next_event = if self.buf_has_data() {\n                    let buf = self.take_buf();\n                    if self.inside_whitespace && self.config.trim_whitespace {\n                        None\n                    } else if self.inside_whitespace && !self.config.whitespace_to_characters {\n                        Some(Ok(XmlEvent::Whitespace(buf)))\n                    } else if self.config.trim_whitespace {\n                        Some(Ok(XmlEvent::Characters(buf.trim_matches(is_whitespace_char).into())))\n                    } else {\n                        Some(Ok(XmlEvent::Characters(buf)))\n                    }\n                } else { None };\n                self.inside_whitespace = true;  // Reset inside_whitespace flag\n                self.push_pos();\n                match t {\n                    Token::ProcessingInstructionStart =>\n                        self.into_state(State::InsideProcessingInstruction(ProcessingInstructionSubstate::PIInsideName), next_event),\n\n                    Token::DoctypeStart if !self.encountered_element => {\n                        // We don't have a doctype event so skip this position\n                        // FIXME: update when we have a doctype event\n                        self.next_pos();\n                        self.lexer.disable_errors();\n                        self.into_state(State::InsideDoctype, next_event)\n                    }\n\n                    Token::OpeningTagStart => {\n                        // If declaration was not parsed and we have encountered an element,\n                        // emit this declaration as the next event.\n                        if !self.parsed_declaration {\n                            self.parsed_declaration = true;\n                            let sd_event = XmlEvent::StartDocument {\n                                version: DEFAULT_VERSION,\n                                encoding: DEFAULT_ENCODING.into(),\n                                standalone: DEFAULT_STANDALONE\n                            };\n                            // next_event is always none here because we're outside of\n                            // the root element\n                            next_event = Some(Ok(sd_event));\n                            self.push_pos();\n                        }\n                        self.encountered_element = true;\n                        self.nst.push_empty();\n                        self.into_state(State::InsideOpeningTag(OpeningTagSubstate::InsideName), next_event)\n                    }\n\n                    Token::ClosingTagStart if self.depth() > 0 =>\n                        self.into_state(State::InsideClosingTag(ClosingTagSubstate::CTInsideName), next_event),\n\n                    Token::CommentStart => {\n                        // We need to switch the lexer into a comment mode inside comments\n                        self.into_state(State::InsideComment, next_event)\n                    }\n\n                    Token::CDataStart => {\n                        self.into_state(State::InsideCData, next_event)\n                    }\n\n                    _ => Some(self_error!(self; \"Unexpected token: {}\", t)),\n                }\n            }\n        }\n    }\n}\n", "//! W3C XML conformance test suite https://www.w3.org/XML/Test/\n\nuse std::collections::HashSet;\nuse std::ffi::OsStr;\nuse std::path::Path;\nuse std::collections::HashMap;\nuse std::fs::File;\nuse std::io::BufReader;\nuse std::process::Command;\nuse std::sync::Mutex;\n\nuse xml::EventReader;\nuse xml::reader::XmlEvent;\n\nstatic UNZIP: Mutex<()> = Mutex::new(());\n\nfn ensure_unzipped() {\n    let _g = UNZIP.lock().expect(\"unzip already failed\");\n\n    // test suite license only allows redistribution of unmodified zip!\n    if !Path::new(\"tests/xmlconf\").exists() {\n        assert!(Command::new(\"unzip\")\n            .current_dir(\"tests\")\n            .arg(\"xmlts20130923.zip\")\n            .status().unwrap().success(), \"must unzip\");\n    }\n}\n\n#[track_caller]\nfn run_suite(suite_rel_path: &str, known_broken_tests: &[&str]) {\n    ensure_unzipped();\n\n    let known_broken_tests = known_broken_tests.iter().map(|name| name.as_ref()).collect::<HashSet<&OsStr>>();\n\n    let suite_path = Path::new(\"tests/xmlconf\").join(suite_rel_path);\n    let root = suite_path.parent().unwrap();\n    let mut parsed = 0;\n\n    let f = BufReader::new(File::open(&suite_path)\n        .map_err(|e| format!(\"{}: {e}\", suite_path.display())).unwrap());\n    let r = EventReader::new(f);\n    let mut desc = String::new();\n    let mut attr = HashMap::<String, String>::new();\n    for e in r {\n        let e = e.expect(\"testsuite validity\");\n        match e {\n            XmlEvent::Characters(chr) => {\n                desc.push_str(&chr.replace('\\n', \" \"));\n            },\n            XmlEvent::EndElement { name } if name.local_name == \"TEST\" => {\n                let path = root.join(&attr[\"URI\"]);\n                let test_type = attr[\"TYPE\"].as_str();\n                let id = attr[\"ID\"].as_str();\n\n                let res = match test_type {\n                    \"valid\" => expect_well_formed(&path, &desc, id),\n                    \"invalid\" => expect_well_formed(&path, &desc, id), // invalid is still well-formed\n                    \"not-wf\" | \"error\" => expect_ill_formed(&path, &desc, id),\n                    other => unimplemented!(\"{other}?? type\"),\n                };\n\n                let known_bad = known_broken_tests.contains::<OsStr>(id.as_ref());\n\n                match res {\n                    Err(_) if known_bad => {},\n                    Err(e) => panic!(\"{suite_rel_path} failed on {} ({id})\\n{e}\", path.display()),\n                    Ok(()) if known_bad => panic!(\"expected {} ({id}) to fail, but it passes {test_type} of {suite_rel_path} now\\n{desc}\", path.display()),\n                    Ok(()) => {},\n                };\n                parsed += 1;\n            },\n            XmlEvent::StartElement { name, attributes, namespace: _ } if name.local_name == \"TEST\" => {\n                desc.clear();\n                attr = attributes.into_iter().map(|a| (a.name.local_name, a.value)).collect();\n            },\n            _ => {},\n\n        }\n    }\n    assert!(parsed > 0);\n}\n\n#[track_caller]\nfn expect_well_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn std::error::Error>> {\n    let f = BufReader::new(File::open(xml_path)?);\n    let r = EventReader::new(f);\n    let mut seen_any = false;\n    for e in r {\n        let e = e.map_err(|e| format!(\"\\\"{id}\\\", // {} {msg}; {e}\", xml_path.file_name().and_then(|f| f.to_str()).unwrap()))?;\n        if let XmlEvent::EndElement { .. } = e {\n            seen_any = true;\n        }\n    }\n    if !seen_any { Err(\"no elements found\")? }\n    Ok(())\n}\n\n#[track_caller]\nfn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn std::error::Error>> {\n    let f = BufReader::new(File::open(xml_path)?);\n    let r = EventReader::new(f);\n    for e in r {\n        if let Err(_) = e {\n            return Ok(());\n        }\n    }\n    Err(format!(\"\\\"{id}\\\", // {} {msg}\", xml_path.file_name().and_then(|f| f.to_str()).unwrap()))?\n}\n\n#[test] fn eduni_errata_2e() {\n    run_suite(\"eduni/errata-2e/errata2e.xml\", &[\n        \"rmt-e2e-15a\", // Empty content can't contain an entity reference\n        \"rmt-e2e-15e\", // Element content can contain entity reference if replacement text is whitespace\n        \"rmt-e2e-15f\", // Element content can contain entity reference if replacement text is whitespace, even if it came from a character reference in the literal entity value\n        \"rmt-e2e-15h\", // Element content can't contain entity reference if replacement text is character reference to whitespace\n        \"rmt-e2e-18\", // External entity containing start of entity declaration is base URI for system identifier\n        \"rmt-e2e-19\", // Parameter entities and character references are included-in-literal, but general entities are bypassed.\n        \"rmt-e2e-22\", // UTF-8 entities may start with a BOM\n        \"rmt-e2e-24\", // Either the built-in entity or a character reference can be used to represent greater-than after two close-square-brackets\n        \"rmt-e2e-34\", // A non-deterministic content model is an error even if the element type is not used.\n        \"rmt-e2e-50\", // All line-ends are normalized, even those not passed to the application. NB this can only be tested effectively in XML 1.1, since CR is in the S production; in 1.1 we can use NEL which isn't.\n        \"rmt-e2e-55\", // A reference to an unparsed entity in an entity value is an error rather than forbidden (unless the entity is referenced, of course)\n        \"rmt-e2e-57\", // A value other than preserve or default for xml:space is an error\n        \"rmt-e2e-61\", // (From John Cowan) An encoding declaration in ASCII specifying an encoding that is not compatible with ASCII (so the document is not in its declared encoding).  It should generate a fatal error.\n    ]);\n}\n\n#[test] fn eduni_errata_3e() {\n    run_suite(\"eduni/errata-3e/errata3e.xml\", &[\n        \"rmt-e3e-12\", // E12.xml Default values for attributes may not contain references to external entities.\n        \"rmt-e3e-13\", // E13.xml Even internal parameter entity references are enough to make undeclared entities into mere validity errors rather than well-formedness errors.\n    ]);\n}\n\n#[test] fn eduni_errata_4e() {\n    run_suite(\"eduni/errata-4e/errata4e.xml\", &[\n        \"invalid-bo-1\", // inclbom_be.xml Byte order mark in general entity should go away (big-endian)\n        \"invalid-bo-2\", // inclbom_le.xml Byte order mark in general entity should go away (little-endian)\n        \"invalid-bo-3\", // incl8bom.xml Byte order mark in general entity should go away (utf-8)\n        \"invalid-bo-4\", // inclbombom_be.xml Two byte order marks in general entity produce only one (big-endian)\n        \"invalid-bo-5\", // inclbombom_le.xml Two byte order marks in general entity produce only one (little-endian)\n        \"invalid-bo-6\", // incl8bombom.xml Two byte order marks in general entity produce only one (utf-8)\n        \"invalid-sa-140\", // 140.xml Character '&#x309a;' is a CombiningChar, not a Letter, but as of 5th edition, may begin a name (c.f. xmltest/not-wf/sa/140.xml).\n        \"invalid-sa-141\", // 141.xml As of 5th edition, character #x0E5C is legal in XML names (c.f. xmltest/not-wf/sa/141.xml).\n        \"x-rmt-008b\", // 008.xml a document with version=1.7, legal in XML 1.0 from 5th edition\n        \"x-ibm-1-0.5-valid-P04-ibm04v01.xml\", // ibm04v01.xml This test case covers legal NameStartChars character ranges plus discrete legal characters for production 04.\n        \"x-ibm-1-0.5-valid-P05-ibm05v01.xml\", // ibm05v01.xml This test case covers legal Element Names as per production 5.\n        \"x-ibm-1-0.5-valid-P05-ibm05v03.xml\", // ibm05v03.xml This test case covers legal Attribute (Names) as per production 5.\n    ]);\n}\n\n#[test] fn eduni_misc_ht() {\n    run_suite(\"eduni/misc/ht-bh.xml\", &[]);\n}\n\n#[test] fn eduni_namespaces_10() {\n    run_suite(\"eduni/namespaces/1.0/rmt-ns10.xml\", &[\n        \"rmt-ns10-004\", // Namespace name test: a relative URI (deprecated)\n        \"rmt-ns10-005\", // Namespace name test: a same-document relative URI (deprecated)\n        \"rmt-ns10-009\", // Namespace equality test: plain repetition\n        \"rmt-ns10-010\", // Namespace equality test: use of character reference\n        \"rmt-ns10-012\", // Namespace inequality test: equal after attribute value normalization\n        \"rmt-ns10-030\", // Reserved prefixes and namespaces: binding another prefix to the xml namespace\n        \"rmt-ns10-033\", // Reserved prefixes and namespaces: binding another prefix to the xmlns namespace\n        \"rmt-ns10-036\", // Attribute uniqueness: repeated attribute with different prefixes\n        \"rmt-ns10-042\", // Colon in PI name\n        \"rmt-ns10-043\", // Colon in entity name\n        \"rmt-ns10-044\", // Colon in entity name\n        \"ht-ns10-047\", // Reserved name: _not_ an error\n    ]);\n}\n\n#[test] fn eduni_namespaces_11() {\n    run_suite(\"eduni/namespaces/1.1/rmt-ns11.xml\", &[\n        \"rmt-ns11-001\", // 001.xml Namespace name test: a perfectly good http IRI that is not a URI\n        \"rmt-ns11-002\", // 002.xml Namespace inequality test: different escaping of non-ascii letter\n        \"rmt-ns11-003\", // 003.xml 1.1 style prefix unbinding\n        \"rmt-ns11-004\", // 004.xml 1.1 style prefix unbinding and rebinding\n    ]);\n}\n\n#[test] fn eduni_namespaces_errata() {\n    run_suite(\"eduni/namespaces/errata-1e/errata1e.xml\", &[\n        \"rmt-ns-e1.0-13a\", // NE13a.xml The xml namespace must not be declared as the default namespace.\n        \"rmt-ns-e1.0-13b\", // NE13b.xml The xmlns namespace must not be declared as the default namespace.\n    ]);\n}\n\n#[test] fn eduni_xml_11() {\n    run_suite(\"eduni/xml-1.1/xml11.xml\", &[\n        \"rmt-001\", // 001.xml External subset has later version number\n        \"rmt-002\", // 002.xml External PE has later version number\n        \"rmt-006\", // 006.xml Second-level external general entity has later version number than first-level, but not later than document, so not an error.\n        \"rmt-010\", // 010.xml Contains a C1 control, legal in XML 1.0, illegal in XML 1.1\n        \"rmt-013\", // 013.xml Contains a DEL, legal in XML 1.0, illegal in XML 1.1\n        \"rmt-014\", // 014.xml Has a \"long s\" in a name, legal in XML 1.1, illegal in XML 1.0 thru 4th edition\n        \"rmt-016\", // 016.xml Has a Byzantine Musical Symbol Kratimata in a name, legal in XML 1.1, illegal in XML 1.0 thru 4th edition\n        \"rmt-019\", // 019.xml Has the last legal namechar in XML 1.1, illegal in XML 1.0 thru 4th edition\n        \"rmt-022\", // 022.xml Has a NEL character; legal in both XML 1.0 and 1.1, but different canonical output because of normalization in 1.1\n        \"rmt-023\", // 023.xml Has a NEL character; legal in both XML 1.0 and 1.1, but different canonical output because of normalization in 1.1\n        \"rmt-026\", // 026.xml Has CR-NEL; legal in both XML 1.0 and 1.1, but different canonical output because of normalization in 1.1\n        \"rmt-027\", // 027.xml Has CR-NEL; legal in both XML 1.0 and 1.1, but different canonical output because of normalization in 1.1\n        \"rmt-030\", // 030.xml Has a NEL character in an NMTOKENS attribute; well-formed in both XML 1.0 and 1.1, but valid only in 1.1\n        \"rmt-031\", // 031.xml Has a NEL character in an NMTOKENS attribute; well-formed in both XML 1.0 and 1.1, but valid only in 1.1\n        \"rmt-034\", // 034.xml Has an NMTOKENS attribute containing a CR character that comes from a character reference in an internal entity.  Because CR is in the S production, this is valid in both XML 1.0 and 1.1.\n        \"rmt-035\", // 035.xml Has an NMTOKENS attribute containing a CR character that comes from a character reference in an internal entity.  Because CR is in the S production, this is valid in both XML 1.0 and 1.1.\n        \"rmt-036\", // 036.xml Has an NMTOKENS attribute containing a NEL character that comes from a character reference in an internal entity.  Because NEL is not in the S production (even though real NELs are converted to LF on input), this is invalid in both XML 1.0 and 1.1.\n        \"rmt-037\", // 037.xml Has an NMTOKENS attribute containing a NEL character that comes from a character reference in an internal entity.  Because NEL is not in the S production (even though real NELs are converted to LF on input), this is invalid in both XML 1.0 and 1.1.\n        \"rmt-038\", // 038.xml Contains a C0 control character (form-feed), illegal in both XML 1.0 and 1.1\n        \"rmt-039\", // 039.xml Contains a C0 control character (form-feed), illegal in both XML 1.0 and 1.1\n        \"rmt-040\", // 040.xml Contains a C1 control character (partial line up), legal in XML 1.0 but not 1.1\n        \"rmt-042\", // 042.xml Contains a character reference to a C0 control character (form-feed), legal in XML 1.1 but not 1.0\n        \"rmt-046\", // 046.xml Has a NEL character in element content whitespace; well-formed in both XML 1.0 and 1.1, but valid only in 1.1\n        \"rmt-047\", // 047.xml Has a NEL character in element content whitespace; well-formed in both XML 1.0 and 1.1, but valid only in 1.1\n        \"rmt-050\", // 050.xml Has element content whitespace containing a CR character that comes from a character reference in an internal entity.  Because CR is in the S production, this is valid in both XML 1.0 and 1.1.\n        \"rmt-051\", // 051.xml Has element content whitespace containing a CR character that comes from a character reference in an internal entity.  Because CR is in the S production, this is valid in both XML 1.0 and 1.1.\n        \"rmt-052\", // 052.xml Has element content whitespace containing a NEL character that comes from a character reference in an internal entity.  Because NEL is not in the S production (even though real NELs are converted to LF on input), this is invalid in both XML 1.0 and 1.1.\n        \"rmt-053\", // 053.xml Has element content whitespace containing a NEL character that comes from a character reference in an internal entity.  Because NEL is not in the S production (even though real NELs are converted to LF on input), this is invalid in both XML 1.0 and 1.1.\n        \"rmt-054\", // 054.xml Contains a character reference to a C0 control character (form-feed) in an entity value.  This will be legal (in XML 1.1) when the entity declaration is parsed, but what about when it is used?\n    ]);\n}\n\n#[test] fn ibm_oasis_valid() {\n    run_suite(\"ibm/ibm_oasis_valid.xml\", &[\n        \"ibm-valid-P09-ibm09v01.xml\", // ibm09v01.xml Empty EntityValue is legal\n        \"ibm-valid-P09-ibm09v02.xml\", // ibm09v02.xml Tests a normal EnitityValue\n        \"ibm-valid-P09-ibm09v03.xml\", // ibm09v03.xml Tests EnitityValue referencing a Parameter Entity\n        \"ibm-valid-P09-ibm09v04.xml\", // ibm09v04.xml Tests EnitityValue referencing a General Entity\n        \"ibm-valid-P09-ibm09v05.xml\", // ibm09v05.xml Tests EnitityValue with combination of GE, PE and text, the GE used is      declared in the student.dtd\n        \"ibm-valid-P10-ibm10v01.xml\", // ibm10v01.xml Tests empty AttValue with double quotes as the delimiters\n        \"ibm-valid-P10-ibm10v02.xml\", // ibm10v02.xml Tests empty AttValue with single quotes as the delimiters\n        \"ibm-valid-P10-ibm10v03.xml\", // ibm10v03.xml Test AttValue with double quotes as the delimiters and single quote inside\n        \"ibm-valid-P10-ibm10v04.xml\", // ibm10v04.xml Test AttValue with single quotes as the delimiters and double quote inside\n        \"ibm-valid-P10-ibm10v05.xml\", // ibm10v05.xml Test AttValue with a GE reference and double quotes as the delimiters\n        \"ibm-valid-P10-ibm10v06.xml\", // ibm10v06.xml Test AttValue with a GE reference and single quotes as the delimiters\n        \"ibm-valid-P10-ibm10v07.xml\", // ibm10v07.xml testing AttValue with mixed references and text content in double quotes\n        \"ibm-valid-P10-ibm10v08.xml\", // ibm10v08.xml testing AttValue with mixed references and text content in single quotes\n        \"ibm-valid-P28-ibm28v02.xml\", // ibm28v02.xml Tests doctypedecl with external subset and combinations of different markup     declarations and PEReferences\n        \"ibm-valid-P29-ibm29v01.xml\", // ibm29v01.xml Tests markupdecl with combinations of elementdecl, AttlistDecl,EntityDecl,      NotationDecl, PI and comment\n        \"ibm-valid-P29-ibm29v02.xml\", // ibm29v02.xml Tests WFC: PE in internal subset as a positive test\n        \"ibm-valid-P32-ibm32v02.xml\", // ibm32v02.xml Tests VC: Standalone Document Declaration with external entity reference     and standalone is no\n        \"ibm-valid-P43-ibm43v01.xml\", // ibm43v01.xml Tests content with all possible constructs: element, CharData, Reference,      CDSect, Comment\n        \"ibm-valid-P67-ibm67v01.xml\", // ibm67v01.xml Tests Reference could be EntityRef or CharRef.\n        \"ibm-valid-P78-ibm78v01.xml\", // ibm78v01.xml Tests ExtParsedEnt, also TextDecl in P77 and EncodingDecl in P80\n    ]);\n}\n\n#[test] fn ibm_xml_11() {\n    run_suite(\"ibm/xml-1.1/ibm_valid.xml\", &[\n        \"ibm-1-1-valid-P02-ibm02v04.xml\", // ibm02v04.xml This test case contains embeded whitespace characters                   some form the range 1 - 1F.\n        \"ibm-1-1-valid-P03-ibm03v01.xml\", // ibm03v01.xml The two character sequence #x0D #x85 in an external entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v02.xml\", // ibm03v02.xml The single character sequence #x85 in an external entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v03.xml\", // ibm03v03.xml The two character sequence #x0D #x85 in an external entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v04.xml\", // ibm03v04.xml The single character sequence #x85 in an external entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v05.xml\", // ibm03v05.xml The two character sequence #x0D #x85 in a document entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v06.xml\", // ibm03v06.xml The single character sequence #x85 in a document entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v07.xml\", // ibm03v07.xml The single character sequence #x2028 in a document entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P04-ibm04v01.xml\", // ibm04v01.xml This test case covers legal NameStartChars character ranges plus discrete legal          characters for production 04.\n        \"ibm-1-1-valid-P05-ibm05v01.xml\", // ibm05v01.xml This test case covers legal Element Names as per production 5.\n        \"ibm-1-1-valid-P05-ibm05v03.xml\", // ibm05v03.xml This test case covers legal Attribute (Names) as per production 5.\n        \"ibm-1-1-valid-P77-ibm77v04.xml\", // ibm77v04.xml The VersionNum of the document entity is 1.1 whereas the VersionNum of the external          entity is 1.0.  The character #xD6 which is a valid XML 1.1 but an invalid XML 1.0          character is present in both documents.\n        \"ibm-1-1-valid-P77-ibm77v05.xml\", // ibm77v05.xml The VersionNum of the document entity is 1.1 whereas the VersionNum of the external          entity is 1.0.  The character #x1FFF which is a valid XML 1.1 but an invalid XML 1.0          character is present in both documents.\n        \"ibm-1-1-valid-P77-ibm77v06.xml\", // ibm77v06.xml The VersionNum of the document entity is 1.1 whereas the VersionNum of the external          entity is 1.0.  The character #xF901 which is a valid XML 1.1 but an invalid XML 1.0          character is present in both documents.\n        \"ibm-1-1-valid-P77-ibm77v10.xml\", // ibm77v10.xml The VersionNum of the document and external entity is 1.1 and both contain the          valid XML1.1 but invalid XML1.0 character #xF6.\n        \"ibm-1-1-valid-P77-ibm77v11.xml\", // ibm77v11.xml The VersionNum of the document and external entity is 1.1 and both contain the          valid XML1.1 but invalid XML1.0 character #x1FFF.\n        \"ibm-1-1-valid-P77-ibm77v12.xml\", // ibm77v12.xml The VersionNum of the document and external entity is 1.1 and both contain the          valid XML1.1 but invalid XML1.0 character #xF901.\n        \"ibm-1-1-valid-P77-ibm77v16.xml\", // ibm77v16.xml The VersionNum of the document entity is 1.1 but the external entity does not          contain a textDecl and both contain the valid XML1.1 but invalid XML1.0 character          #x2FF.\n        \"ibm-1-1-valid-P77-ibm77v17.xml\", // ibm77v17.xml The VersionNum of the document entity is 1.1 but the external entity does not          contain a textDecl and both contain the valid XML1.1 but invalid XML1.0 character          #x1FFF.\n        \"ibm-1-1-valid-P77-ibm77v18.xml\", // ibm77v18.xml The VersionNum of the document entity is 1.1 but the external entity does not          contain a textDecl and both contain the valid XML1.1 but invalid XML1.0 character          #xF901.\n        \"ibm-1-1-valid-P77-ibm77v22.xml\", // ibm77v22.xml The VersionNum of the document and the external entity is 1.1.  The entity contains          a reference to the character #x7F.\n        \"ibm-1-1-valid-P77-ibm77v23.xml\", // ibm77v23.xml The VersionNum of the document and the external entity is 1.1.  The entity contains          a reference to the character #x80.\n        \"ibm-1-1-valid-P77-ibm77v24.xml\", // ibm77v24.xml The VersionNum of the document and the external entity is 1.1.  The entity contains          a reference to the character #x9F.\n        \"ibm-1-1-valid-P77-ibm77v28.xml\", // ibm77v28.xml The VersionNum of the document is 1.1 and the textDecl is missing in the external          entity.  The replacement text of an entity declared in the external DTD contains a          reference to the character #x7F, #x80, #x9F.\n        \"ibm-1-1-valid-P77-ibm77v29.xml\", // ibm77v29.xml The VersionNum of the document is 1.1 and the textDecl is missing in the external          entity.  The replacement text of an entity declared in the external DTD contains a          reference to the character #x85, #x8F.\n        \"ibm-1-1-valid-P77-ibm77v30.xml\", // ibm77v30.xml The VersionNum of the document is 1.1 and the textDecl is missing in the external          entity.\n    ]);\n}\n\n#[test] fn oasis() {\n    run_suite(\"oasis/oasis.xml\", &[\n        \"o-p43pass1\", // Valid use of character data, comments, processing instructions and CDATA sections within the start and end tag.\n        \"o-p68pass1\", // Valid entity references.  Also ensures that a charref to           '&' isn't interpreted as an entity reference open delimiter\n        \"o-p04pass1\", // names with all valid ASCII characters, and one from each               other class in NameChar\n        \"o-p05pass1\", // various valid Name constructions\n        \"o-p01fail1\", // S cannot occur before the prolog\n        \"o-p01fail2\", // comments cannot occur before the prolog\n        \"o-p01fail3\", // only one document element\n        \"o-p09fail1\", // EntityValue excludes '%'\n        \"o-p09fail2\", // EntityValue excludes '&'\n        \"o-p09fail3\", // incomplete character reference\n        \"o-p09fail4\", // quote types must match\n        \"o-p09fail5\", // quote types must match\n        \"o-p11fail1\", // quote types must match\n        \"o-p11fail2\", // cannot contain delimiting quotes\n        \"o-p12fail1\", // '\"' excluded\n        \"o-p12fail2\", // '\\' excluded\n        \"o-p12fail3\", // entity references excluded\n        \"o-p12fail6\", // built-in entity refs excluded\n        \"o-p12fail7\", // The public ID has a tab character, which is disallowed\n        \"o-p14fail3\", // \"]]>\" excluded\n        \"o-p18fail3\", // CDSect's can't nest\n        \"o-p22fail1\", // prolog must start with XML decl\n        \"o-p22fail2\", // prolog must start with XML decl\n        \"o-p23fail1\", // \"xml\" must be lower-case\n        \"o-p27fail1\", // References aren't allowed in Misc,     even if they would resolve to valid Misc.\n        \"o-p29fail1\", // A processor must not pass unknown declaration types.\n        \"o-p30fail1\", // An XML declaration is not the same as a TextDecl\n        \"o-p31fail1\", // external subset excludes doctypedecl\n        \"o-p32fail3\", // initial S is required\n        \"o-p40fail1\", // S is required between attributes\n        \"o-p44fail4\", // Whitespace required between attributes.\n        \"o-p45fail1\", // ELEMENT must be upper case.\n        \"o-p45fail2\", // S before contentspec is required.\n        \"o-p45fail3\", // only one content spec\n        \"o-p45fail4\", // no comments in declarations (contrast with SGML)\n        \"o-p46fail1\", // no parens on declared content\n        \"o-p46fail2\", // no inclusions (contrast with SGML)\n        \"o-p46fail3\", // no exclusions (contrast with SGML)\n        \"o-p46fail4\", // no space before occurrence\n        \"o-p46fail5\", // single group\n        \"o-p46fail6\", // can't be both declared and modeled\n        \"o-p47fail1\", // Invalid operator '|' must match previous operator ','\n        \"o-p47fail2\", // Illegal character '-' in Element-content model\n        \"o-p47fail3\", // Optional character must follow a name or list\n        \"o-p47fail4\", // Illegal space before optional character\n        \"o-p48fail1\", // Illegal space before optional character\n        \"o-p48fail2\", // Illegal space before optional character\n        \"o-p51fail1\", // occurrence on #PCDATA group must be *\n        \"o-p51fail2\", // occurrence on #PCDATA group must be *\n        \"o-p51fail3\", // #PCDATA must come first\n        \"o-p51fail4\", // occurrence on #PCDATA group must be *\n        \"o-p51fail5\", // only '|' connectors\n        \"o-p51fail6\", // Only '|' connectors and occurrence on #PCDATA group must be *\n        \"o-p51fail7\", // no nested groups\n        \"o-p52fail1\", // A name is required\n        \"o-p52fail2\", // A name is required\n        \"o-p53fail1\", // S is required before default\n        \"o-p53fail2\", // S is required before type\n        \"o-p53fail3\", // type is required\n        \"o-p53fail4\", // default is required\n        \"o-p53fail5\", // name is requried\n        \"o-p54fail1\", // don't pass unknown attribute types\n        \"o-p55fail1\", // must be upper case\n        \"o-p56fail1\", // no IDS type\n        \"o-p56fail2\", // no NUMBER type\n        \"o-p56fail3\", // no NAME type\n        \"o-p56fail4\", // no ENTITYS type - types must be upper case\n        \"o-p56fail5\", // types must be upper case\n        \"o-p57fail1\", // no keyword for NMTOKEN enumeration\n        \"o-p58fail1\", // at least one value required\n        \"o-p58fail2\", // separator must be '|'\n        \"o-p58fail3\", // notations are NAMEs, not NMTOKENs -- note:     Leaving the invalid           notation undeclared would cause a validating parser to fail without           checking the name syntax, so the notation is declared with an           invalid name.  A parser that reports error positions should report           an error at the AttlistDecl on line 6, before reaching the notation           declaration.\n        \"o-p58fail4\", // NOTATION must be upper case\n        \"o-p58fail5\", // S after keyword is required\n        \"o-p58fail6\", // parentheses are require\n        \"o-p58fail7\", // values are unquoted\n        \"o-p58fail8\", // values are unquoted\n        \"o-p59fail1\", // at least one required\n        \"o-p59fail2\", // separator must be \",\"\n        \"o-p59fail3\", // values are unquoted\n        \"o-p60fail1\", // keywords must be upper case\n        \"o-p60fail2\", // S is required after #FIXED\n        \"o-p60fail3\", // only #FIXED has both keyword and value\n        \"o-p60fail4\", // #FIXED required value\n        \"o-p60fail5\", // only one default type\n        \"o-p61fail1\", // no other types, including TEMP, which is valid in SGML\n        \"o-p62fail1\", // INCLUDE must be upper case\n        \"o-p62fail2\", // no spaces in terminating delimiter\n        \"o-p63fail1\", // IGNORE must be upper case\n        \"o-p63fail2\", // delimiters must be balanced\n        \"o-p64fail1\", // section delimiters must balance\n        \"o-p64fail2\", // section delimiters must balance\n        \"o-p66fail5\", // no references to non-characters\n        \"o-p69fail1\", // terminating ';' is required\n        \"o-p69fail2\", // no S after '%'\n        \"o-p69fail3\", // no S before ';'\n        \"o-p70fail1\", // This is neither\n        \"o-p71fail1\", // S is required before EntityDef\n        \"o-p71fail2\", // Entity name is a Name, not an NMToken\n        \"o-p71fail3\", // no S after \"<!\"\n        \"o-p71fail4\", // S is required after \"<!ENTITY\"\n        \"o-p72fail1\", // S is required after \"<!ENTITY\"\n        \"o-p72fail2\", // S is required after '%'\n        \"o-p72fail3\", // S is required after name\n        \"o-p72fail4\", // Entity name is a name, not an NMToken\n        \"o-p73fail1\", // No typed replacement text\n        \"o-p73fail2\", // Only one replacement value\n        \"o-p73fail3\", // No NDataDecl on replacement text\n        \"o-p73fail4\", // Value is required\n        \"o-p73fail5\", // No NDataDecl without value\n        \"o-p74fail1\", // no NDataDecls on parameter entities\n        \"o-p74fail2\", // value is required\n        \"o-p74fail3\", // only one value\n        \"o-p75fail1\", // S required after \"PUBLIC\"\n        \"o-p75fail2\", // S required after \"SYSTEM\"\n        \"o-p75fail3\", // S required between literals\n        \"o-p75fail4\", // \"SYSTEM\" implies only one literal\n        \"o-p75fail5\", // only one keyword\n        \"o-p75fail6\", // \"PUBLIC\" requires two literals (contrast with SGML)\n        \"o-p76fail1\", // S is required before \"NDATA\"\n        \"o-p76fail2\", // \"NDATA\" is upper-case\n        \"o-p76fail3\", // notation name is required\n    ]);\n}\n\n#[test] fn sun_valid() {\n    run_suite(\"sun/sun-valid.xml\", &[\n        \"ext01\", // Tests use of external parsed entities with and without content.\n        \"ext02\", // Tests use of external parsed entities with different    encodings than the base document.\n        \"not-sa02\", // A non-standalone document is valid if declared as such.\n        \"not-sa03\", // A non-standalone document is valid if declared as such.\n        \"not-sa04\", // A non-standalone document is valid if declared as such.\n        \"sa02\", // A document may be marked 'standalone' if any     attributes that need normalization are  defined within the internal DTD subset.\n        \"sa03\", // A document may be marked 'standalone' if any     the defined entities need expanding are internal,     and no attributes need defaulting or normalization.     On output, requires notations to be correctly reported.\n        \"sa04\", // Like sa03 but relies on attribute     defaulting defined in the internal subset.     On output, requires notations to be correctly reported.\n        \"v-pe00\", // Tests construction of internal entity replacement text, using     an example in the XML specification.\n        \"v-pe03\", // Tests construction of internal entity replacement text, using     an example in the XML specification.\n        \"v-pe02\", // Tests construction of internal entity replacement text, using     a complex example in the XML specification.\n    ]);\n}\n\n#[test] fn sun_ill_formed() {\n    run_suite(\"sun/sun-not-wf.xml\", &[\n        \"attlist01\", // SGML's NUTOKEN is not allowed.\n        \"attlist02\", // SGML's NUTOKENS attribute type is not allowed.\n        \"attlist03\", // Comma doesn't separate enumerations, unlike in SGML.\n        \"attlist04\", // SGML's NUMBER attribute type is not allowed.\n        \"attlist05\", // SGML's NUMBERS attribute type is not allowed.\n        \"attlist06\", // SGML's NAME attribute type is not allowed.\n        \"attlist07\", // SGML's NAMES attribute type is not allowed.\n        \"attlist08\", // SGML's #CURRENT is not allowed.\n        \"attlist09\", // SGML's #CONREF is not allowed.\n        \"attlist10\", // Whitespace required between attributes\n        \"attlist11\", // Whitespace required between attributes\n        \"cond01\", // Only INCLUDE and IGNORE are conditional section keywords\n        \"cond02\", // Must have keyword in conditional sections\n        \"content01\", // No whitespace before \"?\" in content model\n        \"content02\", // No whitespace before \"*\" in content model\n        \"content03\", // No whitespace before \"+\" in content model\n        \"decl01\", // External entities may not have standalone decls.\n        \"nwf-dtd00\", // Comma mandatory in content model\n        \"nwf-dtd01\", // Can't mix comma and vertical bar in content models\n        \"dtd02\", // PE name immediately after \"%\"\n        \"dtd03\", // PE name immediately followed by \";\"\n        \"dtd04\", // PUBLIC literal must be quoted\n        \"dtd05\", // SYSTEM identifier must be quoted\n        \"dtd07\", // Text declarations (which optionally begin any external entity)     are required to have \"encoding=...\".\n        \"encoding01\", // Illegal character \" \" in encoding name\n        \"encoding02\", // Illegal character \"/\" in encoding name\n        \"encoding03\", // Illegal character reference in encoding name\n        \"encoding04\", // Illegal character \":\" in encoding name\n        \"encoding05\", // Illegal character \"@\" in encoding name\n        \"encoding06\", // Illegal character \"+\" in encoding name\n        \"pubid01\", // Illegal entity ref in public ID\n        \"pubid02\", // Illegal characters in public ID\n        \"pubid03\", // Illegal characters in public ID\n        \"pubid04\", // Illegal characters in public ID\n        \"pubid05\", // SGML-ism:  public ID without system ID\n        \"sgml02\", // XML declaration must be at the very beginning of a document;   it\"s not a processing instruction\n        \"sgml04\", // ATTLIST declarations apply to only one element, unlike SGML\n        \"sgml05\", // ELEMENT declarations apply to only one element, unlike SGML\n        \"sgml06\", // ATTLIST declarations are never global, unlike in SGML\n        \"sgml07\", // SGML Tag minimization specifications are not allowed\n        \"sgml08\", // SGML Tag minimization specifications are not allowed\n        \"sgml09\", // SGML Content model exception specifications are not allowed\n        \"sgml10\", // SGML Content model exception specifications are not allowed\n        \"sgml11\", // CDATA is not a valid content model spec\n        \"sgml12\", // RCDATA is not a valid content model spec\n        \"sgml13\", // SGML Unordered content models not allowed\n    ]);\n}\n\n#[ignore]\n#[test] fn japanese() {\n    run_suite(\"japanese/japanese.xml\", &[\n        \"pr-xml-little-endian.xml\"  // needs DTD\n    ]);\n}\n\n#[test] fn xmltest() {\n    run_suite(\"xmltest/xmltest.xml\", &[\n        \"not-wf-sa-003\", // Processing Instruction target name is required.\n        \"not-wf-sa-025\", // Text may not contain a literal ']]>' sequence.\n        \"not-wf-sa-026\", // Text may not contain a literal ']]>' sequence.\n        \"not-wf-sa-029\", // Text may not contain a literal ']]>' sequence.\n        \"not-wf-sa-030\", // A form feed is not a legal XML character.\n        \"not-wf-sa-031\", // A form feed is not a legal XML character.\n        \"not-wf-sa-032\", // A form feed is not a legal XML character.\n        \"not-wf-sa-033\", // An ESC (octal 033) is not a legal XML character.\n        \"not-wf-sa-037\", // Character references may not appear after the root element.\n        \"not-wf-sa-040\", // Provides two document elements.\n        \"not-wf-sa-041\", // Provides two document elements.\n        \"not-wf-sa-044\", // Provides two document elements.\n        \"not-wf-sa-048\", // Provides a CDATA section after the root element.\n        \"not-wf-sa-051\", // CDATA is invalid at top level of document.\n        \"not-wf-sa-052\", // Invalid character reference.\n        \"not-wf-sa-054\", // PUBLIC requires two literals.\n        \"not-wf-sa-056\", // Invalid Document Type Definition format - misplaced comment.\n        \"not-wf-sa-057\", // This isn't SGML; comments can't exist in declarations.\n        \"not-wf-sa-058\", // Invalid character , in ATTLIST enumeration\n        \"not-wf-sa-059\", // String literal must be in quotes.\n        \"not-wf-sa-060\", // Invalid type NAME defined in ATTLIST.\n        \"not-wf-sa-061\", // External entity declarations require whitespace between public     and system IDs.\n        \"not-wf-sa-062\", // Entity declarations need space after the entity name.\n        \"not-wf-sa-063\", // Conditional sections may only appear in the external     DTD subset.\n        \"not-wf-sa-064\", // Space is required between attribute type and default values     in <!ATTLIST...> declarations.\n        \"not-wf-sa-065\", // Space is required between attribute name and type     in <!ATTLIST...> declarations.\n        \"not-wf-sa-066\", // Required whitespace is missing.\n        \"not-wf-sa-067\", // Space is required between attribute type and default values     in <!ATTLIST...> declarations.\n        \"not-wf-sa-068\", // Space is required between NOTATION keyword and list of     enumerated choices in <!ATTLIST...> declarations.\n        \"not-wf-sa-069\", // Space is required before an NDATA entity annotation.\n        \"not-wf-sa-078\", // Undefined ENTITY foo.\n        \"not-wf-sa-079\", // ENTITY can't reference itself directly or indirectly.\n        \"not-wf-sa-080\", // ENTITY can't reference itself directly or indirectly.\n        \"not-wf-sa-082\", // This tests the No External Entity References WFC,     since the entity is referred to within an attribute.\n        \"not-wf-sa-084\", // Tests the Parsed Entity WFC by referring to an     unparsed entity.  (This precedes the error of not declaring     that entity's notation, which may be detected any time before     the DTD parsing is completed.)\n        \"not-wf-sa-085\", // Public IDs may not contain \"[\".\n        \"not-wf-sa-086\", // Public IDs may not contain \"[\".\n        \"not-wf-sa-087\", // Public IDs may not contain \"[\".\n        \"not-wf-sa-089\", // Parameter entities \"are\" always parsed; NDATA annotations     are not permitted.\n        \"not-wf-sa-091\", // Parameter entities \"are\" always parsed; NDATA annotations     are not permitted.\n        \"not-wf-sa-096\", // Space is required before the standalone declaration.\n        \"not-wf-sa-101\", // Space is not permitted in an encoding name.\n        \"not-wf-sa-105\", // Invalid placement of CDATA section.\n        \"not-wf-sa-106\", // Invalid placement of entity declaration.\n        \"not-wf-sa-107\", // Invalid document type declaration.  CDATA alone is invalid.\n        \"not-wf-sa-113\", // Parameter entity values must use valid reference syntax;     this reference is malformed.\n        \"not-wf-sa-114\", // General entity values must use valid reference syntax;     this reference is malformed.\n        \"not-wf-sa-121\", // A name of an ENTITY was started with an invalid character.\n        \"not-wf-sa-122\", // Invalid syntax mixed connectors are used.\n        \"not-wf-sa-123\", // Invalid syntax mismatched parenthesis.\n        \"not-wf-sa-124\", // Invalid format of Mixed-content declaration.\n        \"not-wf-sa-125\", // Invalid syntax extra set of parenthesis not necessary.\n        \"not-wf-sa-126\", // Invalid syntax Mixed-content must be defined as zero or more.\n        \"not-wf-sa-127\", // Invalid syntax Mixed-content must be defined as zero or more.\n        \"not-wf-sa-128\", // Invalid CDATA syntax.\n        \"not-wf-sa-129\", // Invalid syntax for Element Type Declaration.\n        \"not-wf-sa-130\", // Invalid syntax for Element Type Declaration.\n        \"not-wf-sa-131\", // Invalid syntax for Element Type Declaration.\n        \"not-wf-sa-132\", // Invalid syntax mixed connectors used.\n        \"not-wf-sa-133\", // Illegal whitespace before optional character causes syntax error.\n        \"not-wf-sa-134\", // Illegal whitespace before optional character causes syntax error.\n        \"not-wf-sa-135\", // Invalid character used as connector.\n        \"not-wf-sa-136\", // Tag omission is invalid in XML.\n        \"not-wf-sa-137\", // Space is required before a content model.\n        \"not-wf-sa-138\", // Invalid syntax for content particle.\n        \"not-wf-sa-139\", // The element-content model should not be empty.\n        \"not-wf-sa-143\", // Character #x001F is not legal anywhere in an XML document.\n        \"not-wf-sa-144\", // Character #xFFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-147\", // XML Declaration may not be preceded by whitespace.\n        \"not-wf-sa-148\", // XML Declaration may not be preceded by comments or whitespace.\n        \"not-wf-sa-149\", // XML Declaration may not be within a DTD.\n        \"not-wf-sa-154\", // '<?XML ...?>' is neither an XML declaration     nor a legal processing instruction target name.\n        \"not-wf-sa-155\", // '<?xmL ...?>' is neither an XML declaration     nor a legal processing instruction target name.\n        \"not-wf-sa-158\", // SGML-ism:  \"#NOTATION gif\" can't have attributes.\n        \"not-wf-sa-160\", // Violates the PEs in Internal Subset WFC     by using a PE reference within a declaration.\n        \"not-wf-sa-161\", // Violates the PEs in Internal Subset WFC     by using a PE reference within a declaration.\n        \"not-wf-sa-162\", // Violates the PEs in Internal Subset WFC     by using a PE reference within a declaration.\n        \"not-wf-sa-164\", // Invalid placement of Parameter entity reference.\n        \"not-wf-sa-165\", // Parameter entity declarations must have a space before     the '%'.\n        \"not-wf-sa-166\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-167\", // Character FFFE is not legal anywhere in an XML document.\n        \"not-wf-sa-171\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-172\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-173\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-174\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-175\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-177\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-179\", // Invalid syntax matching double quote is missing.\n        \"not-wf-sa-180\", // The Entity Declared WFC requires entities to be declared     before they are used in an attribute list declaration.\n        \"not-wf-sa-183\", // Mixed content declarations may not include content particles.\n        \"not-wf-sa-184\", // In mixed content models, element names must not be     parenthesized.\n        \"not-wf-sa-186\", // Whitespace is required between attribute/value pairs.\n        \"not-wf-not-sa-001\", // Conditional sections must be properly terminated (\"]>\" used     instead of \"]]>\").\n        \"not-wf-not-sa-002\", // Processing instruction target names may not be \"XML\"      in any combination of cases.\n        \"not-wf-not-sa-003\", // Conditional sections must be properly terminated (\"]]>\" omitted).\n        \"not-wf-not-sa-004\", // Conditional sections must be properly terminated (\"]]>\" omitted).\n        \"not-wf-not-sa-005\", // Tests the Entity Declared VC by referring to an     undefined parameter entity within an external entity.\n        \"not-wf-not-sa-006\", // Conditional sections need a '[' after the INCLUDE or IGNORE.\n        \"not-wf-not-sa-007\", // A <!DOCTYPE ...> declaration may not begin any external     entity; it's only found once, in the document entity.\n        \"not-wf-not-sa-008\", // In DTDs, the '%' character must be part of a parameter     entity reference.\n        \"not-wf-not-sa-009\", // This test violates WFC:PE Between Declarations in Production 28a.       The last character of a markup declaration is not contained in the same      parameter-entity text replacement.\n        \"valid-sa-012\", // Uses a legal XML 1.0 name consisting of a single colon     character (disallowed by the latest XML Namespaces draft).\n        \"valid-sa-023\", // Test demonstrates that Entity References are valid element content.\n        \"valid-sa-024\", // Test demonstrates that Entity References are valid element content and also demonstrates a valid Entity Declaration.\n        \"valid-sa-049\", // Test demonstrates that characters outside of normal ascii range can be used as element content.\n        \"valid-sa-050\", // Test demonstrates that characters outside of normal ascii range can be used as element content.\n        \"valid-sa-051\", // The document is encoded in UTF-16 and uses some name     characters well outside of the normal ASCII range.\n        \"valid-sa-053\", // Tests inclusion of a well-formed internal entity, which     holds an element required by the content model.\n        \"valid-sa-066\", // Expands a CDATA attribute with a character reference.\n        \"valid-sa-068\", // Tests definition of an internal entity holding a carriage return character     reference, which must not be normalized before reporting to the application.  Line      break normalization only occurs when parsing external parsed entities.\n        \"valid-sa-085\", // Parameter and General entities use different namespaces,     so there can be an entity of each type with a given name.\n        \"valid-sa-086\", // Tests whether entities may be declared more than once,     with the first declaration being the binding one.\n        \"valid-sa-087\", // Tests whether character references in internal entities are     expanded early enough, by relying on correct handling to     make the entity be well formed.\n        \"valid-sa-088\", // Tests whether entity references in internal entities are     expanded late enough, by relying on correct handling to     make the expanded text be valid.  (If it's expanded too     early, the entity will parse as an element that's not     valid in that context.)\n        \"valid-sa-089\", // Tests entity expansion of three legal character references,     which each expand to a Unicode surrogate pair.\n        \"valid-sa-108\", // This tests normalization of end-of-line characters (CRLF)     within entities to LF, primarily as an output test.\n        \"valid-sa-110\", // Basically an output test, this requires that a CDATA     attribute with a CRLF be normalized to one space.\n        \"valid-sa-114\", // Test demonstrates that all text within a valid CDATA section is considered text and not recognized as markup.\n        \"valid-sa-115\", // Test demonstrates that an entity reference is processed by recursively processing the replacement text of the entity.\n        \"valid-sa-117\", // Test demonstrates that entity expansion is done while processing entity declarations.\n        \"valid-sa-118\", // Test demonstrates that entity expansion is done while processing entity declarations.\n        \"valid-not-sa-031\", // Expands a general entity which contains a CDATA section with     what looks like a markup declaration (but is just text since     it's in a CDATA section).\n        \"valid-ext-sa-001\", // A combination of carriage return line feed in an external entity must     be normalized to a single newline.\n        \"valid-ext-sa-002\", // A carriage return (also CRLF) in an external entity must     be normalized to a single newline.\n        \"valid-ext-sa-003\", // Test demonstrates that the content of an element can be empty. In this case the external entity is an empty file.\n        \"valid-ext-sa-004\", // A carriage return (also CRLF) in an external entity must     be normalized to a single newline.\n        \"valid-ext-sa-005\", // Test demonstrates the use of optional character and content particles within an element content.  The test also show the use of external entity.\n        \"valid-ext-sa-006\", // Test demonstrates the use of optional character and content particles within mixed element content.  The test also shows the use of an external entity and that a carriage control line feed in an external entity must be normalized to a single newline.\n        \"valid-ext-sa-007\", // Test demonstrates the use of external entity and how replacement  text is retrieved and processed.\n        \"valid-ext-sa-008\", // Test demonstrates the use of external  entity and how replacement text is retrieved and processed.  Also tests the use of an  EncodingDecl of UTF-16.\n        \"valid-ext-sa-009\", // A carriage return (also CRLF) in an external entity must     be normalized to a single newline.\n        \"valid-ext-sa-011\", // Test demonstrates the use of a public identifier with and external entity.   The test also show that a carriage control line feed combination in an external  entity must be normalized to a single newline.\n        \"valid-ext-sa-012\", // Test demonstrates both internal and external entities and that processing of entity references may be required to produce the correct replacement text.\n        \"valid-ext-sa-013\", // Test demonstrates that whitespace is handled by adding a single whitespace to the normalized value in the attribute list.\n        \"valid-ext-sa-014\", // Test demonstrates use of characters outside of normal ASCII range.\n    ]);\n}\n\n"], "fixing_code": ["xml-rs, an XML library for Rust\n===============================\n\n[![CI](https://github.com/kornelski/xml-rs/actions/workflows/main.yml/badge.svg)](https://github.com/kornelski/xml-rs/actions/workflows/main.yml)\n[![crates.io][crates-io-img]](https://lib.rs/crates/xml-rs)\n[![docs][docs-img]](https://docs.rs/xml-rs/)\n\n[Documentation](https://docs.rs/xml-rs/)\n\n  [crates-io-img]: https://img.shields.io/crates/v/xml-rs.svg\n  [docs-img]: https://img.shields.io/badge/docs-latest%20release-6495ed.svg\n\nxml-rs is an XML library for the [Rust](https://www.rust-lang.org/) programming language.\nIt is heavily inspired by Java [Streaming API for XML (StAX)][stax].\n\n  [stax]: https://en.wikipedia.org/wiki/StAX\n\nThis library contains a pull parser much like StAX event reader.\nIt provides an iterator API, so you can leverage Rust's existing iterators library features.\n\nIt also provides a streaming document writer much like StAX event writer.\nThis writer consumes its own set of events, but reader events can be converted to\nwriter events easily, and so it is possible to write XML transformation chains in a pretty\nclean manner.\n\nThis parser is mostly full-featured, however, there are limitations:\n* Only UTF-8 is supported;\n* There is only very rudimentary parsing of `<!DOCTYPE>` declarations; thus no\n  support for custom entities too; internal DTD declarations are likely to cause parsing errors;\n* DTD validation is not supported;\n* attribute value normalization is not performed, and end-of-line characters are not normalized either.\n\nOther than that the parser tries to be mostly XML-1.1-compliant.\n\nWriter is also mostly full-featured with the following limitations:\n* no support for encodings other than UTF-8,\n* no support for emitting `<!DOCTYPE>` declarations;\n* more validations of input are needed, for example, checking that namespace prefixes are bounded\n  or comments are well-formed.\n\nPlanned features:\n\n* support for encodings beyond UTF-8,\n* improved XML-1.1 conformance.\n\nBuilding and using\n------------------\n\nxml-rs uses [Cargo](https://crates.io), so add it with `cargo add xml-rs` or modify `Cargo.toml`:\n\n```toml\n[dependencies]\nxml-rs = \"0.8\"\n```\n\nThe package exposes a single crate called `xml`.\n\nReading XML documents\n---------------------\n\n[`xml::reader::EventReader`](EventReader) requires a [`Read`](stdread) instance to read from. It can be a `File` wrapped in `BufReader`, or a `Vec<u8>`, or a `&[u8]` slice.\n\n[EventReader]: https://docs.rs/xml-rs/latest/xml/reader/struct.EventReader.html\n[stdread]: https://doc.rust-lang.org/stable/std/io/trait.Read.html\n\n`EventReader` implements `IntoIterator` trait, so you can use it in a `for` loop directly:\n\n```rust,no_run\nuse std::fs::File;\nuse std::io::BufReader;\n\nuse xml::reader::{EventReader, XmlEvent};\n\nfn main() -> std::io::Result<()> {\n    let file = File::open(\"file.xml\")?;\n    let file = BufReader::new(file); // Buffering is important for performance\n\n    let parser = EventReader::new(file);\n    let mut depth = 0;\n    for e in parser {\n        match e {\n            Ok(XmlEvent::StartElement { name, .. }) => {\n                println!(\"{:spaces$}+{name}\", \"\", spaces = depth * 2);\n                depth += 1;\n            }\n            Ok(XmlEvent::EndElement { name }) => {\n                depth -= 1;\n                println!(\"{:spaces$}-{name}\", \"\", spaces = depth * 2);\n            }\n            Err(e) => {\n                eprintln!(\"Error: {e}\");\n                break;\n            }\n            // There's more: https://docs.rs/xml-rs/latest/xml/reader/enum.XmlEvent.html\n            _ => {}\n        }\n    }\n\n    Ok(())\n}\n```\n\nDocument parsing can end normally or with an error. Regardless of exact cause, the parsing\nprocess will be stopped, and the iterator will terminate normally.\n\nYou can also have finer control over when to pull the next event from the parser using its own\n`next()` method:\n\n```rust,ignore\nmatch parser.next() {\n    ...\n}\n```\n\nUpon the end of the document or an error, the parser will remember the last event and will always\nreturn it in the result of `next()` call afterwards. If iterator is used, then it will yield\nerror or end-of-document event once and will produce `None` afterwards.\n\nIt is also possible to tweak parsing process a little using [`xml::reader::ParserConfig`][ParserConfig] structure.\nSee its documentation for more information and examples.\n\n[ParserConfig]: https://docs.rs/xml-rs/latest/xml/reader/struct.ParserConfig.html\n\nYou can find a more extensive example of using `EventReader` in `src/analyze.rs`, which is a\nsmall program (BTW, it is built with `cargo build` and can be run after that) which shows various\nstatistics about specified XML document. It can also be used to check for well-formedness of\nXML documents - if a document is not well-formed, this program will exit with an error.\n\nWriting XML documents\n---------------------\n\nxml-rs also provides a streaming writer much like StAX event writer. With it you can write an\nXML document to any `Write` implementor.\n\n```rust,no_run\nuse std::io;\nuse xml::writer::{EmitterConfig, XmlEvent};\n\n/// A simple demo syntax where \"+foo\" makes `<foo>`, \"-foo\" makes `</foo>`\nfn make_event_from_line(line: &str) -> XmlEvent {\n    let line = line.trim();\n    if let Some(name) = line.strip_prefix(\"+\") {\n        XmlEvent::start_element(name).into()\n    } else if line.starts_with(\"-\") {\n        XmlEvent::end_element().into()\n    } else {\n        XmlEvent::characters(line).into()\n    }\n}\n\nfn main() -> io::Result<()> {\n    let input = io::stdin();\n    let output = io::stdout();\n    let mut writer = EmitterConfig::new()\n        .perform_indent(true)\n        .create_writer(output);\n\n    let mut line = String::new();\n    loop {\n        line.clear();\n        let bytes_read = input.read_line(&mut line)?;\n        if bytes_read == 0 {\n            break; // EOF\n        }\n\n        let event = make_event_from_line(&line);\n        if let Err(e) = writer.write(event) {\n            panic!(\"Write error: {e}\")\n        }\n    }\n    Ok(())\n}\n```\n\nThe code example above also demonstrates how to create a writer out of its configuration.\nSimilar thing also works with `EventReader`.\n\nThe library provides an XML event building DSL which helps to construct complex events,\ne.g. ones having namespace definitions. Some examples:\n\n```rust,ignore\n// <a:hello a:param=\"value\" xmlns:a=\"urn:some:document\">\nXmlEvent::start_element(\"a:hello\").attr(\"a:param\", \"value\").ns(\"a\", \"urn:some:document\")\n\n// <hello b:config=\"name\" xmlns=\"urn:default:uri\">\nXmlEvent::start_element(\"hello\").attr(\"b:config\", \"value\").default_ns(\"urn:defaul:uri\")\n\n// <![CDATA[some unescaped text]]>\nXmlEvent::cdata(\"some unescaped text\")\n```\n\nOf course, one can create `XmlEvent` enum variants directly instead of using the builder DSL.\nThere are more examples in [`xml::writer::XmlEvent`][XmlEvent] documentation.\n\n[XmlEvent]: https://docs.rs/xml-rs/latest/xml/reader/enum.XmlEvent.html\n\nThe writer has multiple configuration options; see `EmitterConfig` documentation for more\ninformation.\n\n[EmitterConfig]: https://docs.rs/xml-rs/latest/xml/writer/struct.EmitterConfig.html\n\nBug reports\n------------\n\nPlease report issues at: <https://github.com/kornelski/xml-rs/issues>.\n\n", "//! Contains simple lexer for XML documents.\n//!\n//! This module is for internal use. Use `xml::pull` module to do parsing.\n\nuse std::borrow::Cow;\nuse std::collections::VecDeque;\nuse std::fmt;\nuse std::io::Read;\nuse std::result;\n\nuse crate::common::{is_name_char, is_whitespace_char, Position, TextPosition};\nuse crate::reader::Error;\nuse crate::util;\n\n/// `Token` represents a single lexeme of an XML document. These lexemes\n/// are used to perform actual parsing.\n#[derive(Copy, Clone, PartialEq, Eq, Debug)]\npub(crate) enum Token {\n    /// `<?`\n    ProcessingInstructionStart,\n    /// `?>`\n    ProcessingInstructionEnd,\n    /// `<!DOCTYPE\n    DoctypeStart,\n    /// `<`\n    OpeningTagStart,\n    /// `</`\n    ClosingTagStart,\n    /// `>`\n    TagEnd,\n    /// `/>`\n    EmptyTagEnd,\n    /// `<!--`\n    CommentStart,\n    /// `-->`\n    CommentEnd,\n    /// A chunk of characters, used for errors recovery.\n    Chunk(&'static str),\n    /// Any non-special character except whitespace.\n    Character(char),\n    /// Whitespace character.\n    Whitespace(char),\n    /// `=`\n    EqualsSign,\n    /// `'`\n    SingleQuote,\n    /// `\"`\n    DoubleQuote,\n    /// `<![CDATA[`\n    CDataStart,\n    /// `]]>`\n    CDataEnd,\n    /// `&`\n    ReferenceStart,\n    /// `;`\n    ReferenceEnd,\n    /// `<!` of `ENTITY`\n    MarkupDeclarationStart,\n}\n\nimpl fmt::Display for Token {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Token::Chunk(s)                            => s.fmt(f),\n            Token::Character(c) | Token::Whitespace(c) => c.fmt(f),\n            other => match other {\n                Token::OpeningTagStart            => \"<\",\n                Token::ProcessingInstructionStart => \"<?\",\n                Token::DoctypeStart               => \"<!DOCTYPE\",\n                Token::ClosingTagStart            => \"</\",\n                Token::CommentStart               => \"<!--\",\n                Token::CDataStart                 => \"<![CDATA[\",\n                Token::TagEnd                     => \">\",\n                Token::EmptyTagEnd                => \"/>\",\n                Token::ProcessingInstructionEnd   => \"?>\",\n                Token::CommentEnd                 => \"-->\",\n                Token::CDataEnd                   => \"]]>\",\n                Token::ReferenceStart             => \"&\",\n                Token::ReferenceEnd               => \";\",\n                Token::EqualsSign                 => \"=\",\n                Token::SingleQuote                => \"'\",\n                Token::DoubleQuote                => \"\\\"\",\n                _                          => unreachable!()\n            }.fmt(f),\n        }\n    }\n}\n\nimpl Token {\n    pub fn as_static_str(&self) -> Option<&'static str> {\n        match *self {\n            Token::OpeningTagStart            => Some(\"<\"),\n            Token::ProcessingInstructionStart => Some(\"<?\"),\n            Token::DoctypeStart               => Some(\"<!DOCTYPE\"),\n            Token::ClosingTagStart            => Some(\"</\"),\n            Token::CommentStart               => Some(\"<!--\"),\n            Token::CDataStart                 => Some(\"<![CDATA[\"),\n            Token::TagEnd                     => Some(\">\"),\n            Token::EmptyTagEnd                => Some(\"/>\"),\n            Token::ProcessingInstructionEnd   => Some(\"?>\"),\n            Token::CommentEnd                 => Some(\"-->\"),\n            Token::CDataEnd                   => Some(\"]]>\"),\n            Token::ReferenceStart             => Some(\"&\"),\n            Token::ReferenceEnd               => Some(\";\"),\n            Token::EqualsSign                 => Some(\"=\"),\n            Token::SingleQuote                => Some(\"'\"),\n            Token::DoubleQuote                => Some(\"\\\"\"),\n            Token::Chunk(s)                   => Some(s),\n            _                                 => None\n        }\n    }\n\n    // using String.push_str(token.to_string()) is simply way too slow\n    pub fn push_to_string(&self, target: &mut String) {\n        match self.as_static_str() {\n            Some(s) => { target.push_str(s); }\n            None => {\n                match *self {\n                    Token::Character(c) | Token::Whitespace(c) => target.push(c),\n                    _ => unreachable!()\n                }\n            }\n        }\n    }\n\n    /// Returns `true` if this token contains data that can be interpreted\n    /// as a part of the text. Surprisingly, this also means '>' and '=' and '\"' and \"'\" and '-->'.\n    #[inline]\n    pub fn contains_char_data(&self) -> bool {\n        match *self {\n            Token::Whitespace(_) | Token::Chunk(_) | Token::Character(_) | Token::CommentEnd |\n            Token::TagEnd | Token::EqualsSign | Token::DoubleQuote | Token::SingleQuote | Token::CDataEnd | \n            Token::ProcessingInstructionEnd | Token::EmptyTagEnd => true,\n            _ => false\n        }\n    }\n\n    /// Returns `true` if this token corresponds to a white space character.\n    #[inline]\n    pub fn is_whitespace(&self) -> bool {\n        match *self {\n            Token::Whitespace(_) => true,\n            _ => false,\n        }\n    }\n}\n\n#[derive(Copy, Clone)]\nenum State {\n    /// Default state\n    Normal,\n    /// Triggered on '<'\n    TagStarted,\n    /// Triggered on '<!'\n    CommentOrCDataOrDoctypeStarted,\n    /// Triggered on '<!-'\n    CommentStarted,\n    /// Triggered on '<!D' up to '<!DOCTYPE'\n    DoctypeStarted(DoctypeStartedSubstate),\n    /// Other items like `<!ELEMENT` in DTD\n    InsideMarkupDeclaration,\n    /// Triggered after DoctypeStarted to handle sub elements\n    InsideDoctype,\n    /// Triggered on '<![' up to '<![CDATA'\n    CDataStarted(CDataStartedSubstate),\n    /// Triggered on '?'\n    ProcessingInstructionClosing,\n    /// Triggered on '/'\n    EmptyTagClosing,\n    /// Triggered on '-' up to '--'\n    CommentClosing(ClosingSubstate),\n    /// Triggered on ']' up to ']]' inside CDATA\n    CDataClosing(ClosingSubstate),\n    /// Triggered on ']' up to ']]' outside CDATA\n    InvalidCDataClosing(ClosingSubstate),\n    /// After `<!--`\n    InsideComment,\n    /// After `<[[`\n    InsideCdata,\n    /// After `<?`\n    InsideProcessingInstruction,\n    /// `<!ENTITY \"here\">`\n    InsideMarkupDeclarationQuotedString(QuoteStyle),\n}\n\n#[derive(Copy, Clone, Eq, PartialEq)]\nenum QuoteStyle {\n    Single, Double\n}\n\n#[derive(Copy, Clone)]\nenum ClosingSubstate {\n    First, Second\n}\n\n#[derive(Copy, Clone)]\nenum DoctypeStartedSubstate {\n    D, DO, DOC, DOCT, DOCTY, DOCTYP\n}\n\n#[derive(Copy, Clone)]\nenum CDataStartedSubstate {\n    E, C, CD, CDA, CDAT, CDATA\n}\n\n/// `Result` represents lexing result. It is either a token or an error message.\npub(crate) type Result<T = Option<Token>, E = Error> = result::Result<T, E>;\n\n/// Helps to set up a dispatch table for lexing large unambigous tokens like\n/// `<![CDATA[` or `<!DOCTYPE `.\nmacro_rules! dispatch_on_enum_state(\n    ($_self:ident, $s:expr, $c:expr, $is:expr,\n     $($st:ident; $stc:expr ; $next_st:ident ; $chunk:expr),+;\n     $end_st:ident ; $end_c:expr ; $end_chunk:expr ; $e:expr) => (\n        match $s {\n            $(\n            $st => match $c {\n                $stc => $_self.move_to($is($next_st)),\n                _  => $_self.handle_error($chunk, $c)\n            },\n            )+\n            $end_st => match $c {\n                $end_c => $e,\n                _      => $_self.handle_error($end_chunk, $c)\n            }\n        }\n    )\n);\n\n/// `Lexer` is a lexer for XML documents, which implements pull API.\n///\n/// Main method is `next_token` which accepts an `std::io::Read` instance and\n/// tries to read the next lexeme from it.\n///\n/// When `skip_errors` flag is set, invalid lexemes will be returned as `Chunk`s.\n/// When it is not set, errors will be reported as `Err` objects with a string message.\n/// By default this flag is not set. Use `enable_errors` and `disable_errors` methods\n/// to toggle the behavior.\npub(crate) struct Lexer {\n    pos: TextPosition,\n    head_pos: TextPosition,\n    char_queue: VecDeque<char>,\n    st: State,\n    /// Default state to go back to after a tag end (may be `InsideDoctype`)\n    normal_state: State,\n    skip_errors: bool,\n    inside_token: bool,\n    eof_handled: bool\n}\n\nimpl Position for Lexer {\n    #[inline]\n    /// Returns the position of the last token produced by the lexer\n    fn position(&self) -> TextPosition { self.pos }\n}\n\nimpl Lexer {\n    /// Returns a new lexer with default state.\n    pub fn new() -> Lexer {\n        Lexer {\n            pos: TextPosition::new(),\n            head_pos: TextPosition::new(),\n            char_queue: VecDeque::with_capacity(4),  // TODO: check size\n            st: State::Normal,\n            normal_state: State::Normal,\n            skip_errors: false,\n            inside_token: false,\n            eof_handled: false\n        }\n    }\n\n    /// Disables error handling so `next_token` will return `Some(Chunk(..))`\n    /// upon invalid lexeme with this lexeme content.\n    pub(crate) fn disable_errors(&mut self) { self.skip_errors = true; }\n\n    /// Reset the eof handled flag of the lexer.\n    #[inline]\n    pub fn reset_eof_handled(&mut self) { self.eof_handled = false; }\n\n    /// Tries to read the next token from the buffer.\n    ///\n    /// It is possible to pass different instaces of `BufReader` each time\n    /// this method is called, but the resulting behavior is undefined in this case.\n    ///\n    /// Return value:\n    /// * `Err(reason) where reason: reader::Error` - when an error occurs;\n    /// * `Ok(None)` - upon end of stream is reached;\n    /// * `Ok(Some(token)) where token: Token` - in case a complete-token has been read from the stream.\n    pub fn next_token<B: Read>(&mut self, b: &mut B) -> Result {\n        // Already reached end of buffer\n        if self.eof_handled {\n            return Ok(None);\n        }\n\n        if !self.inside_token {\n            self.pos = self.head_pos;\n            self.inside_token = true;\n        }\n\n        // Check if we have saved a char or two for ourselves\n        while let Some(c) = self.char_queue.pop_front() {\n            match self.read_next_token(c)? {\n                Some(t) => {\n                    self.inside_token = false;\n                    return Ok(Some(t));\n                }\n                None => {} // continue\n            }\n        }\n\n        loop {\n            // TODO: this should handle multiple encodings\n            let c = match util::next_char_from(b)? {\n                Some(c) => c,  // got next char\n                None => break, // nothing to read left\n            };\n\n            match self.read_next_token(c)? {\n                Some(t) => {\n                    self.inside_token = false;\n                    return Ok(Some(t));\n                }\n                None => {\n                    // continue\n                }\n            }\n        }\n\n        // Handle end of stream\n        self.eof_handled = true;\n        self.pos = self.head_pos;\n        match self.st {\n            State::InsideCdata | State::CDataClosing(_) => Err(self.error(\"Unclosed CDATA\")),\n\n            State::TagStarted | State::CommentOrCDataOrDoctypeStarted |\n            State::CommentStarted | State::CDataStarted(_)| State::DoctypeStarted(_) |\n            State::CommentClosing(ClosingSubstate::Second) |\n            State::InsideComment | State::InsideMarkupDeclaration |\n            State::InsideProcessingInstruction | State::ProcessingInstructionClosing |\n            State::InsideDoctype | State::InsideMarkupDeclarationQuotedString(_) =>\n                Err(self.error(\"Unexpected end of stream\")),\n            State::EmptyTagClosing =>\n                Ok(Some(Token::Character('/'))),\n            State::CommentClosing(ClosingSubstate::First) =>\n                Ok(Some(Token::Character('-'))),\n            State::InvalidCDataClosing(ClosingSubstate::First) =>\n                Ok(Some(Token::Character(']'))),\n            State::InvalidCDataClosing(ClosingSubstate::Second) =>\n                Ok(Some(Token::Chunk(\"]]\"))),\n            State::Normal =>\n                Ok(None),\n        }\n    }\n\n    #[inline]\n    fn error<M: Into<Cow<'static, str>>>(&self, msg: M) -> Error {\n        (self, msg).into()\n    }\n\n    #[inline]\n    fn read_next_token(&mut self, c: char) -> Result {\n        let res = self.dispatch_char(c);\n        if self.char_queue.is_empty() {\n            if c == '\\n' {\n                self.head_pos.new_line();\n            } else {\n                self.head_pos.advance(1);\n            }\n        }\n        res\n    }\n\n    fn dispatch_char(&mut self, c: char) -> Result {\n        match self.st {\n            State::Normal                         => self.normal(c),\n            State::TagStarted                     => self.tag_opened(c),\n            State::CommentOrCDataOrDoctypeStarted => self.comment_or_cdata_or_doctype_started(c),\n            State::CommentStarted                 => self.comment_started(c),\n            State::CDataStarted(s)                => self.cdata_started(c, s),\n            State::DoctypeStarted(s)              => self.doctype_started(c, s),\n            State::InsideDoctype                  => self.inside_doctype(c),\n            State::EmptyTagClosing                => self.empty_element_closing(c),\n            State::CommentClosing(s)              => self.comment_closing(c, s),\n            State::CDataClosing(s)                => self.cdata_closing(c, s),\n            State::InvalidCDataClosing(s)         => self.invalid_cdata_closing(c, s),\n            State::InsideComment                  => self.inside_comment_state(c),\n            State::InsideCdata                    => self.inside_cdata(c),\n            State::InsideProcessingInstruction    => self.inside_processing_instruction(c),\n            State::ProcessingInstructionClosing   => self.processing_instruction_closing(c),\n            State::InsideMarkupDeclaration       => self.markup_declaration(c),\n            State::InsideMarkupDeclarationQuotedString(q) => self.markup_declaration_string(c, q),\n        }\n    }\n\n    #[inline]\n    fn move_to(&mut self, st: State) -> Result {\n        self.st = st;\n        Ok(None)\n    }\n\n    #[inline]\n    fn move_to_with(&mut self, st: State, token: Token) -> Result {\n        self.st = st;\n        Ok(Some(token))\n    }\n\n    #[inline]\n    fn move_to_and_reset_normal(&mut self, st: State, token: Token) -> Result {\n        self.normal_state = st;\n        self.st = st;\n        Ok(Some(token))\n    }\n\n    #[inline]\n    fn move_to_with_unread(&mut self, st: State, cs: &[char], token: Token) -> Result {\n        self.char_queue.extend(cs.iter().copied());\n        self.move_to_with(st, token)\n    }\n\n    fn handle_error(&mut self, chunk: &'static str, c: char) -> Result {\n        self.char_queue.push_back(c);\n        if self.skip_errors {\n            self.move_to_with(State::Normal, Token::Chunk(chunk))\n        } else {\n            Err(self.error(format!(\"Unexpected token '{chunk}' before '{c}'\")))\n        }\n    }\n\n    /// Encountered a char\n    fn normal(&mut self, c: char) -> Result {\n        match c {\n            '<'                        => self.move_to(State::TagStarted),\n            '>'                        => Ok(Some(Token::TagEnd)),\n            '/'                        => self.move_to(State::EmptyTagClosing),\n            '='                        => Ok(Some(Token::EqualsSign)),\n            '\"'                        => Ok(Some(Token::DoubleQuote)),\n            '\\''                       => Ok(Some(Token::SingleQuote)),\n            ']'                        => self.move_to(State::InvalidCDataClosing(ClosingSubstate::First)),\n            '&'                        => Ok(Some(Token::ReferenceStart)),\n            ';'                        => Ok(Some(Token::ReferenceEnd)),\n            _ if is_whitespace_char(c) => Ok(Some(Token::Whitespace(c))),\n            _                          => Ok(Some(Token::Character(c)))\n        }\n    }\n\n    fn inside_cdata(&mut self, c: char) -> Result {\n        match c {\n            ']'                        => self.move_to(State::CDataClosing(ClosingSubstate::First)),\n            _ if is_whitespace_char(c) => Ok(Some(Token::Whitespace(c))),\n            _                          => Ok(Some(Token::Character(c)))\n        }\n    }\n\n    fn inside_processing_instruction(&mut self, c: char) -> Result {\n        // These tokens are used by `<?xml?>` parser\n        match c {\n            '?'                        => self.move_to(State::ProcessingInstructionClosing),\n            '<'                        => Ok(Some(Token::OpeningTagStart)),\n            '>'                        => Ok(Some(Token::TagEnd)),\n            '/'                        => Ok(Some(Token::ClosingTagStart)),\n            '='                        => Ok(Some(Token::EqualsSign)),\n            '\"'                        => Ok(Some(Token::DoubleQuote)),\n            '\\''                       => Ok(Some(Token::SingleQuote)),\n            '&'                        => Ok(Some(Token::ReferenceStart)),\n            ';'                        => Ok(Some(Token::ReferenceEnd)),\n            _ if is_whitespace_char(c) => Ok(Some(Token::Whitespace(c))),\n            _                          => Ok(Some(Token::Character(c)))\n        }\n    }\n\n    fn inside_comment_state(&mut self, c: char) -> Result {\n        match c {\n            '-'                        => self.move_to(State::CommentClosing(ClosingSubstate::First)),\n            _ if is_whitespace_char(c) => Ok(Some(Token::Whitespace(c))),\n            _                          => Ok(Some(Token::Character(c)))\n        }\n    }\n\n    /// Encountered '<'\n    fn tag_opened(&mut self, c: char) -> Result {\n        match c {\n            '?'                        => self.move_to_with(State::InsideProcessingInstruction, Token::ProcessingInstructionStart),\n            '/'                        => self.move_to_with(self.normal_state, Token::ClosingTagStart),\n            '!'                        => self.move_to(State::CommentOrCDataOrDoctypeStarted),\n            _ if is_whitespace_char(c) => self.move_to_with_unread(self.normal_state, &[c], Token::OpeningTagStart),\n            _ if is_name_char(c)       => self.move_to_with_unread(self.normal_state, &[c], Token::OpeningTagStart),\n            _                          => self.handle_error(\"<\", c)\n        }\n    }\n\n    /// Encountered '<!'\n    fn comment_or_cdata_or_doctype_started(&mut self, c: char) -> Result {\n        match c {\n            '-' => self.move_to(State::CommentStarted),\n            '[' => self.move_to(State::CDataStarted(CDataStartedSubstate::E)),\n            'D' => self.move_to(State::DoctypeStarted(DoctypeStartedSubstate::D)),\n            'E' | 'A' | 'N' if matches!(self.normal_state, State::InsideDoctype) => self.move_to_with(State::InsideMarkupDeclaration, Token::MarkupDeclarationStart),\n            _ => self.handle_error(\"<!\", c),\n        }\n    }\n\n    /// Encountered '<!-'\n    fn comment_started(&mut self, c: char) -> Result {\n        match c {\n            '-' => self.move_to_with(State::InsideComment, Token::CommentStart),\n            _ => self.handle_error(\"<!-\", c),\n        }\n    }\n\n    /// Encountered '<!['\n    fn cdata_started(&mut self, c: char, s: CDataStartedSubstate) -> Result {\n        use self::CDataStartedSubstate::{C, CD, CDA, CDAT, CDATA, E};\n        dispatch_on_enum_state!(self, s, c, State::CDataStarted,\n            E     ; 'C' ; C     ; \"<![\",\n            C     ; 'D' ; CD    ; \"<![C\",\n            CD    ; 'A' ; CDA   ; \"<![CD\",\n            CDA   ; 'T' ; CDAT  ; \"<![CDA\",\n            CDAT  ; 'A' ; CDATA ; \"<![CDAT\";\n            CDATA ; '[' ; \"<![CDATA\" ; self.move_to_with(State::InsideCdata, Token::CDataStart)\n        )\n    }\n\n    /// Encountered '<!\u2026' that isn't DOCTYPE or CDATA\n    fn markup_declaration(&mut self, c: char) -> Result {\n        match c {\n            '<'                        => self.handle_error(\"<!\", c),\n            '>'                        => self.move_to_with(self.normal_state, Token::TagEnd),\n            '&'                        => Ok(Some(Token::ReferenceStart)),\n            ';'                        => Ok(Some(Token::ReferenceEnd)),\n            '\"'                        => self.move_to_with(State::InsideMarkupDeclarationQuotedString(QuoteStyle::Double), Token::DoubleQuote),\n            '\\''                       => self.move_to_with(State::InsideMarkupDeclarationQuotedString(QuoteStyle::Single), Token::SingleQuote),\n            _ => Ok(None),\n        }\n    }\n\n    fn markup_declaration_string(&mut self, c: char, q: QuoteStyle) -> Result {\n        match c {\n            '\"' if q == QuoteStyle::Double  => self.move_to_with(State::InsideMarkupDeclaration, Token::DoubleQuote),\n            '\\'' if q == QuoteStyle::Single => self.move_to_with(State::InsideMarkupDeclaration, Token::SingleQuote),\n            _ => Ok(None),\n        }\n    }\n\n    /// Encountered '<!D'\n    fn doctype_started(&mut self, c: char, s: DoctypeStartedSubstate) -> Result {\n        use self::DoctypeStartedSubstate::{D, DO, DOC, DOCT, DOCTY, DOCTYP};\n        dispatch_on_enum_state!(self, s, c, State::DoctypeStarted,\n            D      ; 'O' ; DO     ; \"<!D\",\n            DO     ; 'C' ; DOC    ; \"<!DO\",\n            DOC    ; 'T' ; DOCT   ; \"<!DOC\",\n            DOCT   ; 'Y' ; DOCTY  ; \"<!DOCT\",\n            DOCTY  ; 'P' ; DOCTYP ; \"<!DOCTY\";\n            DOCTYP ; 'E' ; \"<!DOCTYP\" ; self.move_to_and_reset_normal(State::InsideDoctype, Token::DoctypeStart)\n        )\n    }\n\n    /// State used while awaiting the closing bracket for the <!DOCTYPE tag\n    fn inside_doctype(&mut self, c: char) -> Result {\n        match c {\n            '>' => self.move_to_and_reset_normal(State::Normal, Token::TagEnd),\n            '<'                        => self.move_to(State::TagStarted),\n            '&'                        => Ok(Some(Token::ReferenceStart)),\n            ';'                        => Ok(Some(Token::ReferenceEnd)),\n            _ => Ok(None),\n        }\n    }\n\n    /// Encountered '?'\n    fn processing_instruction_closing(&mut self, c: char) -> Result {\n        match c {\n            '>' => self.move_to_with(self.normal_state, Token::ProcessingInstructionEnd),\n            _ => self.move_to_with_unread(State::InsideProcessingInstruction, &[c], Token::Character('?')),\n        }\n    }\n\n    /// Encountered '/'\n    fn empty_element_closing(&mut self, c: char) -> Result {\n        match c {\n            '>' => self.move_to_with(self.normal_state, Token::EmptyTagEnd),\n            _ => self.move_to_with_unread(self.normal_state, &[c], Token::Character('/')),\n        }\n    }\n\n    /// Encountered '-'\n    fn comment_closing(&mut self, c: char, s: ClosingSubstate) -> Result {\n        match s {\n            ClosingSubstate::First => match c {\n                '-' => self.move_to(State::CommentClosing(ClosingSubstate::Second)),\n                _ => self.move_to_with_unread(State::InsideComment, &[c], Token::Character('-')),\n            },\n            ClosingSubstate::Second => match c {\n                '>' => self.move_to_with(self.normal_state, Token::CommentEnd),\n                // double dash not followed by a greater-than is a hard error inside comment\n                _ => self.handle_error(\"--\", c),\n            },\n        }\n    }\n\n    /// Encountered ']'\n    fn cdata_closing(&mut self, c: char, s: ClosingSubstate) -> Result {\n        match s {\n            ClosingSubstate::First => match c {\n                ']' => self.move_to(State::CDataClosing(ClosingSubstate::Second)),\n                _ => self.move_to_with_unread(State::InsideCdata, &[c], Token::Character(']')),\n            },\n            ClosingSubstate::Second => match c {\n                '>' => self.move_to_with(State::Normal, Token::CDataEnd),\n                _ => self.move_to_with_unread(State::InsideCdata, &[']', c], Token::Character(']')),\n            },\n        }\n    }\n\n    /// Encountered ']'\n    fn invalid_cdata_closing(&mut self, c: char, s: ClosingSubstate) -> Result {\n        match s {\n            ClosingSubstate::First => match c {\n                ']' => self.move_to(State::InvalidCDataClosing(ClosingSubstate::Second)),\n                _ => self.move_to_with_unread(State::Normal, &[c], Token::Character(']')),\n            },\n            ClosingSubstate::Second => match c {\n                '>' => self.move_to_with(self.normal_state, Token::CDataEnd),\n                _ => self.move_to_with_unread(State::Normal, &[']', c], Token::Character(']')),\n            },\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::common::Position;\n    use std::io::{BufReader, Cursor};\n\n    use super::{Lexer, Token};\n\n    macro_rules! assert_oks(\n        (for $lex:ident and $buf:ident ; $($e:expr)+) => ({\n            $(\n                assert_eq!(Ok(Some($e)), $lex.next_token(&mut $buf));\n             )+\n        })\n    );\n\n    macro_rules! assert_err(\n        (for $lex:ident and $buf:ident expect row $r:expr ; $c:expr, $s:expr) => ({\n            let err = $lex.next_token(&mut $buf);\n            assert!(err.is_err());\n            let err = err.unwrap_err();\n            assert_eq!($r as u64, err.position().row);\n            assert_eq!($c as u64, err.position().column);\n            assert_eq!($s, err.msg());\n        })\n    );\n\n    macro_rules! assert_none(\n        (for $lex:ident and $buf:ident) => (\n            assert_eq!(Ok(None), $lex.next_token(&mut $buf))\n        )\n    );\n\n    fn make_lex_and_buf(s: &str) -> (Lexer, BufReader<Cursor<Vec<u8>>>) {\n        (Lexer::new(), BufReader::new(Cursor::new(s.to_owned().into_bytes())))\n    }\n\n    #[test]\n    fn tricky_pi() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<?x<!-- &??><x>\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::ProcessingInstructionStart\n            Token::Character('x')\n            Token::OpeningTagStart // processing of <?xml?> relies on the extra tokens\n            Token::Character('!')\n            Token::Character('-')\n            Token::Character('-')\n            Token::Whitespace(' ')\n            Token::ReferenceStart\n            Token::Character('?')\n            Token::ProcessingInstructionEnd\n            Token::OpeningTagStart\n            Token::Character('x')\n            Token::TagEnd\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn simple_lexer_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<a p='q'> x<b z=\"y\">d\t</b></a><p/> <?nm ?> <!-- a c --> &nbsp;\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::Whitespace(' ')\n            Token::Character('p')\n            Token::EqualsSign\n            Token::SingleQuote\n            Token::Character('q')\n            Token::SingleQuote\n            Token::TagEnd\n            Token::Whitespace(' ')\n            Token::Character('x')\n            Token::OpeningTagStart\n            Token::Character('b')\n            Token::Whitespace(' ')\n            Token::Character('z')\n            Token::EqualsSign\n            Token::DoubleQuote\n            Token::Character('y')\n            Token::DoubleQuote\n            Token::TagEnd\n            Token::Character('d')\n            Token::Whitespace('\\t')\n            Token::ClosingTagStart\n            Token::Character('b')\n            Token::TagEnd\n            Token::ClosingTagStart\n            Token::Character('a')\n            Token::TagEnd\n            Token::OpeningTagStart\n            Token::Character('p')\n            Token::EmptyTagEnd\n            Token::Whitespace(' ')\n            Token::ProcessingInstructionStart\n            Token::Character('n')\n            Token::Character('m')\n            Token::Whitespace(' ')\n            Token::ProcessingInstructionEnd\n            Token::Whitespace(' ')\n            Token::CommentStart\n            Token::Whitespace(' ')\n            Token::Character('a')\n            Token::Whitespace(' ')\n            Token::Character('c')\n            Token::Whitespace(' ')\n            Token::CommentEnd\n            Token::Whitespace(' ')\n            Token::ReferenceStart\n            Token::Character('n')\n            Token::Character('b')\n            Token::Character('s')\n            Token::Character('p')\n            Token::ReferenceEnd\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn special_chars_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"?x!+ // -| ]z]]\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::Character('?')\n            Token::Character('x')\n            Token::Character('!')\n            Token::Character('+')\n            Token::Whitespace(' ')\n            Token::Character('/')\n            Token::Character('/')\n            Token::Whitespace(' ')\n            Token::Character('-')\n            Token::Character('|')\n            Token::Whitespace(' ')\n            Token::Character(']')\n            Token::Character('z')\n            Token::Chunk(\"]]\")\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn cdata_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<a><![CDATA[x y ?]]> </a>\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::TagEnd\n            Token::CDataStart\n            Token::Character('x')\n            Token::Whitespace(' ')\n            Token::Character('y')\n            Token::Whitespace(' ')\n            Token::Character('?')\n            Token::CDataEnd\n            Token::Whitespace(' ')\n            Token::ClosingTagStart\n            Token::Character('a')\n            Token::TagEnd\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn cdata_closers_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<![CDATA[] > ]> ]]><!---->]]<a>\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::CDataStart\n            Token::Character(']')\n            Token::Whitespace(' ')\n            Token::Character('>')\n            Token::Whitespace(' ')\n            Token::Character(']')\n            Token::Character('>')\n            Token::Whitespace(' ')\n            Token::CDataEnd\n            Token::CommentStart\n            Token::CommentEnd\n            Token::Character(']')\n            Token::Character(']')\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::TagEnd\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn doctype_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<a><!DOCTYPE ab xx z> \"#\n        );\n        assert_oks!(for lex and buf ;\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::TagEnd\n            Token::DoctypeStart\n            Token::TagEnd\n            Token::Whitespace(' ')\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn tricky_comments() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<a><!-- C ->--></a>\"#\n        );\n        assert_oks!(for lex and buf ;\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::TagEnd\n            Token::CommentStart\n            Token::Whitespace(' ')\n            Token::Character('C')\n            Token::Whitespace(' ')\n            Token::Character('-')\n            Token::Character('>')\n            Token::CommentEnd\n            Token::ClosingTagStart\n            Token::Character('a')\n            Token::TagEnd\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn doctype_with_internal_subset_test() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<a><!DOCTYPE ab[<!ELEMENT ba \">>>>>\"> ]> \"#\n        );\n        assert_oks!(for lex and buf ;\n            Token::OpeningTagStart\n            Token::Character('a')\n            Token::TagEnd\n            Token::DoctypeStart\n            Token::MarkupDeclarationStart\n            Token::DoubleQuote\n            Token::DoubleQuote\n            Token::TagEnd\n            Token::TagEnd\n            Token::Whitespace(' ')\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn doctype_internal_pi_comment() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            \"<!DOCTYPE a [\\n<!ELEMENT leopard ANY> <!-- <?non?>--> <?pi > ?> \\n]>\"\n        );\n        assert_oks!(for lex and buf ;\n            Token::DoctypeStart\n            Token::MarkupDeclarationStart\n            Token::TagEnd\n            Token::CommentStart\n            Token::Whitespace(' ')\n            Token::Character('<')\n            Token::Character('?')\n            Token::Character('n')\n            Token::Character('o')\n            Token::Character('n')\n            Token::Character('?')\n            Token::Character('>')\n            Token::CommentEnd\n            Token::ProcessingInstructionStart\n            Token::Character('p')\n            Token::Character('i')\n            Token::Whitespace(' ')\n            Token::TagEnd // not really\n            Token::Whitespace(' ')\n            Token::ProcessingInstructionEnd\n            Token::TagEnd // DTD\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn end_of_stream_handling_ok() {\n        macro_rules! eof_check(\n            ($data:expr ; $token:expr) => ({\n                let (mut lex, mut buf) = make_lex_and_buf($data);\n                assert_oks!(for lex and buf ; $token);\n                assert_none!(for lex and buf);\n            })\n        );\n        eof_check!(\"?\"  ; Token::Character('?'));\n        eof_check!(\"/\"  ; Token::Character('/'));\n        eof_check!(\"-\"  ; Token::Character('-'));\n        eof_check!(\"]\"  ; Token::Character(']'));\n        eof_check!(\"]]\" ; Token::Chunk(\"]]\"));\n    }\n\n    #[test]\n    fn end_of_stream_handling_error() {\n        macro_rules! eof_check(\n            ($data:expr; $r:expr, $c:expr) => ({\n                let (mut lex, mut buf) = make_lex_and_buf($data);\n                assert_err!(for lex and buf expect row $r ; $c, \"Unexpected end of stream\");\n                assert_none!(for lex and buf);\n            })\n        );\n        eof_check!(\"<\"        ; 0, 1);\n        eof_check!(\"<!\"       ; 0, 2);\n        eof_check!(\"<!-\"      ; 0, 3);\n        eof_check!(\"<![\"      ; 0, 3);\n        eof_check!(\"<![C\"     ; 0, 4);\n        eof_check!(\"<![CD\"    ; 0, 5);\n        eof_check!(\"<![CDA\"   ; 0, 6);\n        eof_check!(\"<![CDAT\"  ; 0, 7);\n        eof_check!(\"<![CDATA\" ; 0, 8);\n    }\n\n    #[test]\n    fn error_in_comment_or_cdata_prefix() {\n        let (mut lex, mut buf) = make_lex_and_buf(\"<!x\");\n        assert_err!(for lex and buf expect row 0 ; 0,\n            \"Unexpected token '<!' before 'x'\"\n        );\n\n        let (mut lex, mut buf) = make_lex_and_buf(\"<!x\");\n        lex.disable_errors();\n        assert_oks!(for lex and buf ;\n            Token::Chunk(\"<!\")\n            Token::Character('x')\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn error_in_comment_started() {\n        let (mut lex, mut buf) = make_lex_and_buf(\"<!-\\t\");\n        assert_err!(for lex and buf expect row 0 ; 0,\n            \"Unexpected token '<!-' before '\\t'\"\n        );\n\n        let (mut lex, mut buf) = make_lex_and_buf(\"<!-\\t\");\n        lex.disable_errors();\n        assert_oks!(for lex and buf ;\n            Token::Chunk(\"<!-\")\n            Token::Whitespace('\\t')\n        );\n        assert_none!(for lex and buf);\n    }\n\n    #[test]\n    fn error_in_comment_two_dashes_not_at_end() {\n        let (mut lex, mut buf) = make_lex_and_buf(\"--x\");\n        lex.st = super::State::InsideComment;\n        assert_err!(for lex and buf expect row 0; 0,\n            \"Unexpected token '--' before 'x'\"\n        );\n\n        let (mut lex, mut buf) = make_lex_and_buf(\"--x\");\n        assert_oks!(for lex and buf ;\n            Token::Character('-')\n            Token::Character('-')\n            Token::Character('x')\n        );\n    }\n\n    macro_rules! check_case(\n        ($chunk:expr, $app:expr; $data:expr; $r:expr, $c:expr, $s:expr) => ({\n            let (mut lex, mut buf) = make_lex_and_buf($data);\n            assert_err!(for lex and buf expect row $r ; $c, $s);\n\n            let (mut lex, mut buf) = make_lex_and_buf($data);\n            lex.disable_errors();\n            assert_oks!(for lex and buf ;\n                Token::Chunk($chunk)\n                Token::Character($app)\n            );\n            assert_none!(for lex and buf);\n        })\n    );\n\n    #[test]\n    fn error_in_cdata_started() {\n        check_case!(\"<![\",      '['; \"<![[\"      ; 0, 0, \"Unexpected token '<![' before '['\");\n        check_case!(\"<![C\",     '['; \"<![C[\"     ; 0, 0, \"Unexpected token '<![C' before '['\");\n        check_case!(\"<![CD\",    '['; \"<![CD[\"    ; 0, 0, \"Unexpected token '<![CD' before '['\");\n        check_case!(\"<![CDA\",   '['; \"<![CDA[\"   ; 0, 0, \"Unexpected token '<![CDA' before '['\");\n        check_case!(\"<![CDAT\",  '['; \"<![CDAT[\"  ; 0, 0, \"Unexpected token '<![CDAT' before '['\");\n        check_case!(\"<![CDATA\", '|'; \"<![CDATA|\" ; 0, 0, \"Unexpected token '<![CDATA' before '|'\");\n    }\n\n    #[test]\n    fn error_in_doctype_started() {\n        check_case!(\"<!D\",      'a'; \"<!Da\"      ; 0, 0, \"Unexpected token '<!D' before 'a'\");\n        check_case!(\"<!DO\",     'b'; \"<!DOb\"     ; 0, 0, \"Unexpected token '<!DO' before 'b'\");\n        check_case!(\"<!DOC\",    'c'; \"<!DOCc\"    ; 0, 0, \"Unexpected token '<!DOC' before 'c'\");\n        check_case!(\"<!DOCT\",   'd'; \"<!DOCTd\"   ; 0, 0, \"Unexpected token '<!DOCT' before 'd'\");\n        check_case!(\"<!DOCTY\",  'e'; \"<!DOCTYe\"  ; 0, 0, \"Unexpected token '<!DOCTY' before 'e'\");\n        check_case!(\"<!DOCTYP\", 'f'; \"<!DOCTYPf\" ; 0, 0, \"Unexpected token '<!DOCTYP' before 'f'\");\n    }\n\n\n\n    #[test]\n    fn issue_98_cdata_ending_with_right_bracket() {\n        let (mut lex, mut buf) = make_lex_and_buf(\n            r#\"<![CDATA[Foo [Bar]]]>\"#\n        );\n\n        assert_oks!(for lex and buf ;\n            Token::CDataStart\n            Token::Character('F')\n            Token::Character('o')\n            Token::Character('o')\n            Token::Whitespace(' ')\n            Token::Character('[')\n            Token::Character('B')\n            Token::Character('a')\n            Token::Character('r')\n            Token::Character(']')\n            Token::CDataEnd\n        );\n        assert_none!(for lex and buf);\n    }\n}\n", "use crate::reader::events::XmlEvent;\nuse crate::reader::lexer::Token;\n\nuse super::{PullParser, Result, State};\n\nimpl PullParser {\n    pub fn inside_cdata(&mut self, t: Token) -> Option<Result> {\n        match t {\n            Token::CDataEnd => {\n                let event = if self.config.cdata_to_characters {\n                    None\n                } else {\n                    let data = self.take_buf();\n                    Some(Ok(XmlEvent::CData(data)))\n                };\n                self.into_state(State::OutsideTag, event)\n            }\n\n            Token::Whitespace(c) => {\n                self.buf.push(c);\n                None\n            }\n\n            Token::Character(c) => {\n                self.inside_whitespace = false;\n                self.buf.push(c);\n                None\n            }\n\n            Token::Chunk(s) => {\n                self.inside_whitespace = false;\n                self.buf.push_str(s);\n                None\n            }\n\n            _ => unreachable!(),\n        }\n    }\n}\n", "use crate::reader::lexer::Token;\n\nuse super::{PullParser, Result, State};\n\nimpl PullParser {\n    pub fn inside_doctype(&mut self, t: Token) -> Option<Result> {\n        match t {\n            Token::TagEnd => {\n                self.into_state_continue(State::OutsideTag)\n            }\n\n            Token::MarkupDeclarationStart => {\n                self.into_state_continue(State::InsideDoctypeMarkupDeclaration)\n            },\n\n            _ => None,\n        }\n    }\n\n    pub fn inside_doctype_markup_declaration(&mut self, t: Token) -> Option<Result> {\n        match t {\n            Token::TagEnd => {\n                self.into_state_continue(State::InsideDoctype)\n            }\n\n            _ => None,\n        }\n    }\n}\n", "use crate::common::{is_name_char, is_name_start_char};\n\nuse crate::reader::events::XmlEvent;\nuse crate::reader::lexer::Token;\n\nuse super::{DeclarationSubstate, ProcessingInstructionSubstate, PullParser, Result, State};\n\nimpl PullParser {\n    pub fn inside_processing_instruction(&mut self, t: Token, s: ProcessingInstructionSubstate) -> Option<Result> {\n        match s {\n            ProcessingInstructionSubstate::PIInsideName => match t {\n                Token::Character(c) if !self.buf_has_data() && is_name_start_char(c) ||\n                                 self.buf_has_data() && is_name_char(c) => self.append_char_continue(c),\n\n                Token::ProcessingInstructionEnd => {\n                    // self.buf contains PI name\n                    let name = self.take_buf();\n\n                    // Don't need to check for declaration because it has mandatory attributes\n                    // but there is none\n                    match &name[..] {\n                        // Name is empty, it is an error\n                        \"\" => Some(self_error!(self; \"Encountered processing instruction without name\")),\n\n                        // Found <?xml-like PI not at the beginning of a document,\n                        // it is an error - see section 2.6 of XML 1.1 spec\n                        \"xml\"|\"xmL\"|\"xMl\"|\"xML\"|\"Xml\"|\"XmL\"|\"XMl\"|\"XML\" =>\n                            Some(self_error!(self; \"Invalid processing instruction: <?{}\", name)),\n\n                        // All is ok, emitting event\n                        _ => {\n                            self.into_state_emit(\n                                State::OutsideTag,\n                                Ok(XmlEvent::ProcessingInstruction {\n                                    name,\n                                    data: None\n                                })\n                            )\n                        }\n                    }\n                }\n\n                Token::Whitespace(_) => {\n                    // self.buf contains PI name\n                    let name = self.take_buf();\n\n                    match &name[..] {\n                        // We have not ever encountered an element and have not parsed XML declaration\n                        \"xml\" if !self.encountered_element && !self.parsed_declaration =>\n                            self.into_state_continue(State::InsideDeclaration(DeclarationSubstate::BeforeVersion)),\n\n                        // Found <?xml-like PI after the beginning of a document,\n                        // it is an error - see section 2.6 of XML 1.1 spec\n                        \"xml\"|\"xmL\"|\"xMl\"|\"xML\"|\"Xml\"|\"XmL\"|\"XMl\"|\"XML\"\n                            if self.encountered_element || self.parsed_declaration =>\n                            Some(self_error!(self; \"Invalid processing instruction: <?{}\", name)),\n\n                        // All is ok, starting parsing PI data\n                        _ => {\n                            self.data.name = name;\n                            self.into_state_continue(State::InsideProcessingInstruction(ProcessingInstructionSubstate::PIInsideData))\n                        }\n                    }\n                }\n\n                _ => Some(self_error!(self; \"Unexpected token: <?{}{}\", self.buf, t)),\n            },\n\n            ProcessingInstructionSubstate::PIInsideData => match t {\n                Token::ProcessingInstructionEnd => {\n                    let name = self.data.take_name();\n                    let data = self.take_buf();\n                    self.into_state_emit(\n                        State::OutsideTag,\n                        Ok(XmlEvent::ProcessingInstruction {\n                            name,\n                            data: Some(data),\n                        }),\n                    )\n                },\n\n                // Any other token should be treated as plain characters\n                _ => {\n                    t.push_to_string(&mut self.buf);\n                    None\n                }\n            },\n        }\n    }\n}\n", "//! Contains an implementation of pull-based XML parser.\n\nuse std::borrow::Cow;\nuse std::io::prelude::*;\n\nuse crate::attribute::OwnedAttribute;\nuse crate::common::{self, is_name_char, is_name_start_char, Position, TextPosition, XmlVersion};\nuse crate::name::OwnedName;\nuse crate::namespace::NamespaceStack;\n\nuse crate::reader::config::ParserConfig;\nuse crate::reader::events::XmlEvent;\nuse crate::reader::lexer::{Lexer, Token};\n\nmacro_rules! gen_takes(\n    ($($field:ident -> $method:ident, $t:ty, $def:expr);+) => (\n        $(\n        impl MarkupData {\n            #[inline]\n            #[allow(clippy::mem_replace_option_with_none)]\n            fn $method(&mut self) -> $t {\n                std::mem::replace(&mut self.$field, $def)\n            }\n        }\n        )+\n    )\n);\n\ngen_takes!(\n    name         -> take_name, String, String::new();\n    ref_data     -> take_ref_data, String, String::new();\n\n    version      -> take_version, Option<common::XmlVersion>, None;\n    encoding     -> take_encoding, Option<String>, None;\n    standalone   -> take_standalone, Option<bool>, None;\n\n    element_name -> take_element_name, Option<OwnedName>, None;\n\n    attr_name    -> take_attr_name, Option<OwnedName>, None;\n    attributes   -> take_attributes, Vec<OwnedAttribute>, vec!()\n);\n\nmacro_rules! self_error(\n    ($this:ident; $msg:expr) => ($this.error($msg));\n    ($this:ident; $fmt:expr, $($arg:expr),+) => ($this.error(format!($fmt, $($arg),+)))\n);\n\nmod inside_cdata;\nmod inside_closing_tag_name;\nmod inside_comment;\nmod inside_declaration;\nmod inside_doctype;\nmod inside_opening_tag;\nmod inside_processing_instruction;\nmod inside_reference;\nmod outside_tag;\n\nstatic DEFAULT_VERSION: XmlVersion = XmlVersion::Version10;\nstatic DEFAULT_ENCODING: &str = \"UTF-8\";\nstatic DEFAULT_STANDALONE: Option<bool> = None;\n\ntype ElementStack = Vec<OwnedName>;\npub type Result = super::Result<XmlEvent>;\n\n/// Pull-based XML parser.\npub(crate) struct PullParser {\n    config: ParserConfig,\n    lexer: Lexer,\n    st: State,\n    buf: String,\n    nst: NamespaceStack,\n\n    data: MarkupData,\n    final_result: Option<Result>,\n    next_event: Option<Result>,\n    est: ElementStack,\n    pos: Vec<TextPosition>,\n\n    encountered_element: bool,\n    parsed_declaration: bool,\n    inside_whitespace: bool,\n    read_prefix_separator: bool,\n    pop_namespace: bool,\n}\n\nimpl PullParser {\n    /// Returns a new parser using the given config.\n    pub fn new(config: ParserConfig) -> PullParser {\n        PullParser {\n            config,\n            lexer: Lexer::new(),\n            st: State::OutsideTag,\n            buf: String::new(),\n            nst: NamespaceStack::default(),\n\n            data: MarkupData {\n                name: String::new(),\n                version: None,\n                encoding: None,\n                standalone: None,\n                ref_data: String::new(),\n                element_name: None,\n                quote: None,\n                attr_name: None,\n                attributes: Vec::new(),\n            },\n            final_result: None,\n            next_event: None,\n            est: Vec::new(),\n            pos: vec![TextPosition::new()],\n\n            encountered_element: false,\n            parsed_declaration: false,\n            inside_whitespace: true,\n            read_prefix_separator: false,\n            pop_namespace: false,\n        }\n    }\n\n    /// Checks if this parser ignores the end of stream errors.\n    pub fn is_ignoring_end_of_stream(&self) -> bool { self.config.ignore_end_of_stream }\n}\n\nimpl Position for PullParser {\n    /// Returns the position of the last event produced by the parser\n    #[inline]\n    fn position(&self) -> TextPosition {\n        self.pos[0]\n    }\n}\n\n#[derive(Clone, PartialEq)]\npub enum State {\n    OutsideTag,\n    InsideOpeningTag(OpeningTagSubstate),\n    InsideClosingTag(ClosingTagSubstate),\n    InsideProcessingInstruction(ProcessingInstructionSubstate),\n    InsideComment,\n    InsideCData,\n    InsideDeclaration(DeclarationSubstate),\n    InsideDoctype,\n    InsideDoctypeMarkupDeclaration,\n    InsideReference(Box<State>),\n}\n\n#[derive(Clone, PartialEq)]\npub enum OpeningTagSubstate {\n    InsideName,\n\n    InsideTag,\n\n    InsideAttributeName,\n    AfterAttributeName,\n\n    InsideAttributeValue,\n}\n\n#[derive(Clone, PartialEq)]\npub enum ClosingTagSubstate {\n    CTInsideName,\n    CTAfterName,\n}\n\n#[derive(Clone, PartialEq)]\npub enum ProcessingInstructionSubstate {\n    PIInsideName,\n    PIInsideData,\n}\n\n#[derive(Clone, PartialEq)]\npub enum DeclarationSubstate {\n    BeforeVersion,\n    InsideVersion,\n    AfterVersion,\n\n    InsideVersionValue,\n    AfterVersionValue,\n\n    InsideEncoding,\n    AfterEncoding,\n\n    InsideEncodingValue,\n\n    BeforeStandaloneDecl,\n    InsideStandaloneDecl,\n    AfterStandaloneDecl,\n\n    InsideStandaloneDeclValue,\n    AfterStandaloneDeclValue,\n}\n\n#[derive(PartialEq)]\nenum QualifiedNameTarget {\n    AttributeNameTarget,\n    OpeningTagNameTarget,\n    ClosingTagNameTarget,\n}\n\n#[derive(Copy, Clone, PartialEq, Eq)]\nenum QuoteToken {\n    SingleQuoteToken,\n    DoubleQuoteToken,\n}\n\nimpl QuoteToken {\n    fn from_token(t: &Token) -> QuoteToken {\n        match *t {\n            Token::SingleQuote => QuoteToken::SingleQuoteToken,\n            Token::DoubleQuote => QuoteToken::DoubleQuoteToken,\n            _ => panic!(\"Unexpected token: {t}\"),\n        }\n    }\n\n    fn as_token(self) -> Token {\n        match self {\n            QuoteToken::SingleQuoteToken => Token::SingleQuote,\n            QuoteToken::DoubleQuoteToken => Token::DoubleQuote,\n        }\n    }\n}\n\nstruct MarkupData {\n    name: String,     // used for processing instruction name\n    ref_data: String,  // used for reference content\n\n    version: Option<common::XmlVersion>,  // used for XML declaration version\n    encoding: Option<String>,  // used for XML declaration encoding\n    standalone: Option<bool>,  // used for XML declaration standalone parameter\n\n    element_name: Option<OwnedName>,  // used for element name\n\n    quote: Option<QuoteToken>,  // used to hold opening quote for attribute value\n    attr_name: Option<OwnedName>,  // used to hold attribute name\n    attributes: Vec<OwnedAttribute>   // used to hold all accumulated attributes\n}\n\nimpl PullParser {\n    /// Returns next event read from the given buffer.\n    ///\n    /// This method should be always called with the same buffer. If you call it\n    /// providing different buffers each time, the result will be undefined.\n    pub fn next<R: Read>(&mut self, r: &mut R) -> Result {\n        if let Some(ref ev) = self.final_result {\n            return ev.clone();\n        }\n\n        if let Some(ev) = self.next_event.take() {\n            return ev;\n        }\n\n        if self.pop_namespace {\n            self.pop_namespace = false;\n            self.nst.pop();\n        }\n\n        loop {\n            // While lexer gives us Ok(maybe_token) -- we loop.\n            // Upon having a complete XML-event -- we return from the whole function.\n            match self.lexer.next_token(r) {\n                Ok(maybe_token) =>\n                    match maybe_token {\n                        None => break,\n                        Some(token) =>\n                            match self.dispatch_token(token) {\n                                None => {} // continue\n                                Some(Ok(XmlEvent::EndDocument)) =>\n                                    return {\n                                        self.next_pos();\n                                        self.set_final_result(Ok(XmlEvent::EndDocument))\n                                    },\n                                Some(Ok(xml_event)) =>\n                                    return {\n                                        self.next_pos();\n                                        Ok(xml_event)\n                                    },\n                                Some(Err(xml_error)) =>\n                                    return {\n                                        self.next_pos();\n                                        self.set_final_result(Err(xml_error))\n                                    },\n                            }\n                    },\n                Err(lexer_error) =>\n                    return self.set_final_result(Err(lexer_error)),\n            }\n        }\n\n        // Handle end of stream\n        // Forward pos to the lexer head\n        self.next_pos();\n        let ev = if self.depth() == 0 {\n            if self.encountered_element && self.st == State::OutsideTag {  // all is ok\n                Ok(XmlEvent::EndDocument)\n            } else if !self.encountered_element {\n                self_error!(self; \"Unexpected end of stream: no root element found\")\n            } else {  // self.st != State::OutsideTag\n                self_error!(self; \"Unexpected end of stream\")  // TODO: add expected hint?\n            }\n        } else if self.config.ignore_end_of_stream {\n            self.final_result = None;\n            self.lexer.reset_eof_handled();\n            return self_error!(self; \"Unexpected end of stream: still inside the root element\");\n        } else {\n            self_error!(self; \"Unexpected end of stream: still inside the root element\")\n        };\n        self.set_final_result(ev)\n    }\n\n    // This function is to be called when a terminal event is reached.\n    // The function sets up the `self.final_result` into `Some(result)` and return `result`.\n    fn set_final_result(&mut self, result: Result) -> Result {\n        self.final_result = Some(result.clone());\n        result\n    }\n\n    #[inline]\n    fn error<M: Into<Cow<'static, str>>>(&self, msg: M) -> Result {\n        Err((&self.lexer, msg).into())\n    }\n\n    #[inline]\n    fn next_pos(&mut self) {\n        if self.pos.len() > 1 {\n            self.pos.remove(0);\n        } else {\n            self.pos[0] = self.lexer.position();\n        }\n    }\n\n    #[inline]\n    fn push_pos(&mut self) {\n        self.pos.push(self.lexer.position());\n    }\n\n    fn dispatch_token(&mut self, t: Token) -> Option<Result> {\n        match self.st.clone() {\n            State::OutsideTag                     => self.outside_tag(t),\n            State::InsideProcessingInstruction(s) => self.inside_processing_instruction(t, s),\n            State::InsideDeclaration(s)           => self.inside_declaration(t, s),\n            State::InsideDoctype                  => self.inside_doctype(t),\n            State::InsideDoctypeMarkupDeclaration => self.inside_doctype_markup_declaration(t),\n            State::InsideOpeningTag(s)            => self.inside_opening_tag(t, s),\n            State::InsideClosingTag(s)            => self.inside_closing_tag_name(t, s),\n            State::InsideComment                  => self.inside_comment(t),\n            State::InsideCData                    => self.inside_cdata(t),\n            State::InsideReference(s)             => self.inside_reference(t, *s)\n        }\n    }\n\n    #[inline]\n    fn depth(&self) -> usize {\n        self.est.len()\n    }\n\n    #[inline]\n    fn buf_has_data(&self) -> bool {\n        !self.buf.is_empty()\n    }\n\n    #[inline]\n    fn take_buf(&mut self) -> String {\n        std::mem::take(&mut self.buf)\n    }\n\n    #[inline]\n    fn append_char_continue(&mut self, c: char) -> Option<Result> {\n        self.buf.push(c);\n        None\n    }\n\n    #[inline]\n    fn into_state(&mut self, st: State, ev: Option<Result>) -> Option<Result> {\n        self.st = st;\n        ev\n    }\n\n    #[inline]\n    fn into_state_continue(&mut self, st: State) -> Option<Result> {\n        self.into_state(st, None)\n    }\n\n    #[inline]\n    fn into_state_emit(&mut self, st: State, ev: Result) -> Option<Result> {\n        self.into_state(st, Some(ev))\n    }\n\n    /// Dispatches tokens in order to process qualified name. If qualified name cannot be parsed,\n    /// an error is returned.\n    ///\n    /// # Parameters\n    /// * `t`       --- next token;\n    /// * `on_name` --- a callback which is executed when whitespace is encountered.\n    fn read_qualified_name<F>(&mut self, t: Token, target: QualifiedNameTarget, on_name: F) -> Option<Result>\n      where F: Fn(&mut PullParser, Token, OwnedName) -> Option<Result> {\n        // We can get here for the first time only when self.data.name contains zero or one character,\n        // but first character cannot be a colon anyway\n        if self.buf.len() <= 1 {\n            self.read_prefix_separator = false;\n        }\n\n        let invoke_callback = |this: &mut PullParser, t| {\n            let name = this.take_buf();\n            match name.parse() {\n                Ok(name) => on_name(this, t, name),\n                Err(_) => Some(self_error!(this; \"Qualified name is invalid: {}\", name)),\n            }\n        };\n\n        match t {\n            // There can be only one colon, and not as the first character\n            Token::Character(':') if self.buf_has_data() && !self.read_prefix_separator => {\n                self.buf.push(':');\n                self.read_prefix_separator = true;\n                None\n            }\n\n            Token::Character(c) if c != ':' && (!self.buf_has_data() && is_name_start_char(c) ||\n                                          self.buf_has_data() && is_name_char(c)) =>\n                self.append_char_continue(c),\n\n            Token::EqualsSign if target == QualifiedNameTarget::AttributeNameTarget => invoke_callback(self, t),\n\n            Token::EmptyTagEnd if target == QualifiedNameTarget::OpeningTagNameTarget => invoke_callback(self, t),\n\n            Token::TagEnd if target == QualifiedNameTarget::OpeningTagNameTarget ||\n                      target == QualifiedNameTarget::ClosingTagNameTarget => invoke_callback(self, t),\n\n            Token::Whitespace(_) => invoke_callback(self, t),\n\n            _ => Some(self_error!(self; \"Unexpected token inside qualified name: {}\", t))\n        }\n    }\n\n    /// Dispatches tokens in order to process attribute value.\n    ///\n    /// # Parameters\n    /// * `t`        --- next token;\n    /// * `on_value` --- a callback which is called when terminating quote is encountered.\n    fn read_attribute_value<F>(&mut self, t: Token, on_value: F) -> Option<Result>\n      where F: Fn(&mut PullParser, String) -> Option<Result> {\n        match t {\n            Token::Whitespace(_) if self.data.quote.is_none() => None,  // skip leading whitespace\n\n            Token::DoubleQuote | Token::SingleQuote => match self.data.quote {\n                None => {  // Entered attribute value\n                    self.data.quote = Some(QuoteToken::from_token(&t));\n                    None\n                }\n                Some(q) if q.as_token() == t => {\n                    self.data.quote = None;\n                    let value = self.take_buf();\n                    on_value(self, value)\n                }\n                _ => {\n                    t.push_to_string(&mut self.buf);\n                    None\n                }\n            },\n\n            Token::ReferenceStart => {\n                let st = Box::new(self.st.clone());\n                self.into_state_continue(State::InsideReference(st))\n            }\n\n            Token::OpeningTagStart =>\n                Some(self_error!(self; \"Unexpected token inside attribute value: <\")),\n\n            // Every character except \" and ' and < is okay\n            _  => {\n                t.push_to_string(&mut self.buf);\n                None\n            }\n        }\n    }\n\n    fn emit_start_element(&mut self, emit_end_element: bool) -> Option<Result> {\n        let mut name = self.data.take_element_name().unwrap();\n        let mut attributes = self.data.take_attributes();\n\n        // check whether the name prefix is bound and fix its namespace\n        match self.nst.get(name.borrow().prefix_repr()) {\n            Some(\"\") => name.namespace = None,  // default namespace\n            Some(ns) => name.namespace = Some(ns.into()),\n            None => return Some(self_error!(self; \"Element {} prefix is unbound\", name))\n        }\n\n        // check and fix accumulated attributes prefixes\n        for attr in &mut attributes {\n            if let Some(ref pfx) = attr.name.prefix {\n                let new_ns = match self.nst.get(pfx) {\n                    Some(\"\") => None,  // default namespace\n                    Some(ns) => Some(ns.into()),\n                    None => return Some(self_error!(self; \"Attribute {} prefix is unbound\", attr.name))\n                };\n                attr.name.namespace = new_ns;\n            }\n        }\n\n        if emit_end_element {\n            self.pop_namespace = true;\n            self.next_event = Some(Ok(XmlEvent::EndElement {\n                name: name.clone()\n            }));\n        } else {\n            self.est.push(name.clone());\n        }\n        let namespace = self.nst.squash();\n        self.into_state_emit(State::OutsideTag, Ok(XmlEvent::StartElement {\n            name,\n            attributes,\n            namespace\n        }))\n    }\n\n    fn emit_end_element(&mut self) -> Option<Result> {\n        let mut name = self.data.take_element_name().unwrap();\n\n        // check whether the name prefix is bound and fix its namespace\n        match self.nst.get(name.borrow().prefix_repr()) {\n            Some(\"\") => name.namespace = None,  // default namespace\n            Some(ns) => name.namespace = Some(ns.into()),\n            None => return Some(self_error!(self; \"Element {} prefix is unbound\", name))\n        }\n\n        let op_name = self.est.pop().unwrap();\n\n        if name == op_name {\n            self.pop_namespace = true;\n            self.into_state_emit(State::OutsideTag, Ok(XmlEvent::EndElement { name }))\n        } else {\n            Some(self_error!(self; \"Unexpected closing tag: {}, expected {}\", name, op_name))\n        }\n    }\n\n}\n\n#[cfg(test)]\nmod tests {\n    use std::io::BufReader;\n\n    use crate::common::{Position, TextPosition};\n    use crate::name::OwnedName;\n    use crate::attribute::OwnedAttribute;\n    use crate::reader::parser::PullParser;\n    use crate::reader::ParserConfig;\n    use crate::reader::events::XmlEvent;\n\n    fn new_parser() -> PullParser {\n        PullParser::new(ParserConfig::new())\n    }\n\n    macro_rules! expect_event(\n        ($r:expr, $p:expr, $t:pat) => (\n            match $p.next(&mut $r) {\n                $t => {}\n                e => panic!(\"Unexpected event: {:?}\", e)\n            }\n        );\n        ($r:expr, $p:expr, $t:pat => $c:expr ) => (\n            match $p.next(&mut $r) {\n                $t if $c => {}\n                e => panic!(\"Unexpected event: {:?}\", e)\n            }\n        )\n    );\n\n    macro_rules! test_data(\n        ($d:expr) => ({\n            static DATA: &'static str = $d;\n            let r = BufReader::new(DATA.as_bytes());\n            let p = new_parser();\n            (r, p)\n        })\n    );\n\n    #[test]\n    fn issue_3_semicolon_in_attribute_value() {\n        let (mut r, mut p) = test_data!(r#\"\n            <a attr=\"zzz;zzz\" />\n        \"#);\n\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Ok(XmlEvent::StartElement { ref name, ref attributes, ref namespace }) =>\n            *name == OwnedName::local(\"a\") &&\n             attributes.len() == 1 &&\n             attributes[0] == OwnedAttribute::new(OwnedName::local(\"attr\"), \"zzz;zzz\") &&\n             namespace.is_essentially_empty()\n        );\n        expect_event!(r, p, Ok(XmlEvent::EndElement { ref name }) => *name == OwnedName::local(\"a\"));\n        expect_event!(r, p, Ok(XmlEvent::EndDocument));\n    }\n\n    #[test]\n    fn issue_140_entity_reference_inside_tag() {\n        let (mut r, mut p) = test_data!(r#\"\n            <bla>&#9835;</bla>\n        \"#);\n\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Ok(XmlEvent::StartElement { ref name, .. }) => *name == OwnedName::local(\"bla\"));\n        expect_event!(r, p, Ok(XmlEvent::Characters(ref s)) => s == \"\\u{266b}\");\n        expect_event!(r, p, Ok(XmlEvent::EndElement { ref name, .. }) => *name == OwnedName::local(\"bla\"));\n        expect_event!(r, p, Ok(XmlEvent::EndDocument));\n    }\n\n    #[test]\n    fn issue_220_comment() {\n        let (mut r, mut p) = test_data!(r#\"<x><!-- <!--></x>\"#);\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Ok(XmlEvent::StartElement { .. }));\n        expect_event!(r, p, Ok(XmlEvent::EndElement { .. }));\n        expect_event!(r, p, Ok(XmlEvent::EndDocument));\n\n        let (mut r, mut p) = test_data!(r#\"<x><!-- <!---></x>\"#);\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Ok(XmlEvent::StartElement { .. }));\n        expect_event!(r, p, Err(_)); // ---> is forbidden in comments\n\n        let (mut r, mut p) = test_data!(r#\"<x><!--<text&x;> <!--></x>\"#);\n        p.config.ignore_comments = false;\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Ok(XmlEvent::StartElement { .. }));\n        expect_event!(r, p, Ok(XmlEvent::Comment(s)) => s == \"<text&x;> <!\");\n        expect_event!(r, p, Ok(XmlEvent::EndElement { .. }));\n        expect_event!(r, p, Ok(XmlEvent::EndDocument));\n    }\n\n    #[test]\n    fn opening_tag_in_attribute_value() {\n        let (mut r, mut p) = test_data!(r#\"\n            <a attr=\"zzz<zzz\" />\n        \"#);\n\n        expect_event!(r, p, Ok(XmlEvent::StartDocument { .. }));\n        expect_event!(r, p, Err(ref e) =>\n            e.msg() == \"Unexpected token inside attribute value: <\" &&\n            e.position() == TextPosition { row: 1, column: 24 }\n        );\n    }\n}\n", "use crate::common::is_whitespace_char;\n\nuse crate::reader::events::XmlEvent;\nuse crate::reader::lexer::Token;\n\nuse super::{\n    ClosingTagSubstate, OpeningTagSubstate, ProcessingInstructionSubstate, PullParser, Result,\n    State, DEFAULT_ENCODING, DEFAULT_STANDALONE, DEFAULT_VERSION,\n};\n\nimpl PullParser {\n    pub fn outside_tag(&mut self, t: Token) -> Option<Result> {\n        match t {\n            Token::ReferenceStart =>\n                self.into_state_continue(State::InsideReference(Box::new(State::OutsideTag))),\n\n            Token::Whitespace(_) if self.depth() == 0 && self.config.ignore_root_level_whitespace => None,  // skip whitespace outside of the root element\n\n            Token::Whitespace(_) if self.config.trim_whitespace && !self.buf_has_data() => None,\n\n            Token::Whitespace(c) => {\n                if !self.buf_has_data() {\n                    self.push_pos();\n                }\n                self.append_char_continue(c)\n            }\n\n            _ if t.contains_char_data() && self.depth() == 0 =>\n                Some(self_error!(self; \"Unexpected characters outside the root element: {}\", t)),\n\n            _ if t.contains_char_data() => {  // Non-whitespace char data\n                if !self.buf_has_data() {\n                    self.push_pos();\n                }\n                self.inside_whitespace = false;\n                t.push_to_string(&mut self.buf);\n                None\n            }\n\n            Token::ReferenceEnd => { // Semi-colon in a text outside an entity\n                self.inside_whitespace = false;\n                Token::ReferenceEnd.push_to_string(&mut self.buf);\n                None\n            }\n\n            Token::CommentStart if self.config.coalesce_characters && self.config.ignore_comments => {\n                // We need to switch the lexer into a comment mode inside comments\n                self.into_state_continue(State::InsideComment)\n            }\n\n            Token::CDataStart if self.config.coalesce_characters && self.config.cdata_to_characters => {\n                if !self.buf_has_data() {\n                    self.push_pos();\n                }\n                // We need to disable lexing errors inside CDATA\n                self.into_state_continue(State::InsideCData)\n            }\n\n            _ => {\n                // Encountered some markup event, flush the buffer as characters\n                // or a whitespace\n                let mut next_event = if self.buf_has_data() {\n                    let buf = self.take_buf();\n                    if self.inside_whitespace && self.config.trim_whitespace {\n                        None\n                    } else if self.inside_whitespace && !self.config.whitespace_to_characters {\n                        Some(Ok(XmlEvent::Whitespace(buf)))\n                    } else if self.config.trim_whitespace {\n                        Some(Ok(XmlEvent::Characters(buf.trim_matches(is_whitespace_char).into())))\n                    } else {\n                        Some(Ok(XmlEvent::Characters(buf)))\n                    }\n                } else { None };\n                self.inside_whitespace = true;  // Reset inside_whitespace flag\n                self.push_pos();\n                match t {\n                    Token::ProcessingInstructionStart =>\n                        self.into_state(State::InsideProcessingInstruction(ProcessingInstructionSubstate::PIInsideName), next_event),\n\n                    Token::DoctypeStart if !self.encountered_element => {\n                        // We don't have a doctype event so skip this position\n                        // FIXME: update when we have a doctype event\n                        self.next_pos();\n                        self.into_state(State::InsideDoctype, next_event)\n                    }\n\n                    Token::OpeningTagStart => {\n                        // If declaration was not parsed and we have encountered an element,\n                        // emit this declaration as the next event.\n                        if !self.parsed_declaration {\n                            self.parsed_declaration = true;\n                            let sd_event = XmlEvent::StartDocument {\n                                version: DEFAULT_VERSION,\n                                encoding: DEFAULT_ENCODING.into(),\n                                standalone: DEFAULT_STANDALONE\n                            };\n                            // next_event is always none here because we're outside of\n                            // the root element\n                            next_event = Some(Ok(sd_event));\n                            self.push_pos();\n                        }\n                        self.encountered_element = true;\n                        self.nst.push_empty();\n                        self.into_state(State::InsideOpeningTag(OpeningTagSubstate::InsideName), next_event)\n                    }\n\n                    Token::ClosingTagStart if self.depth() > 0 =>\n                        self.into_state(State::InsideClosingTag(ClosingTagSubstate::CTInsideName), next_event),\n\n                    Token::CommentStart => {\n                        // We need to switch the lexer into a comment mode inside comments\n                        self.into_state(State::InsideComment, next_event)\n                    }\n\n                    Token::CDataStart => {\n                        self.into_state(State::InsideCData, next_event)\n                    }\n\n                    _ => Some(self_error!(self; \"Unexpected token: {}\", t)),\n                }\n            }\n        }\n    }\n}\n", "//! W3C XML conformance test suite https://www.w3.org/XML/Test/\n\nuse std::collections::HashSet;\nuse std::ffi::OsStr;\nuse std::path::Path;\nuse std::collections::HashMap;\nuse std::fs::File;\nuse std::io::BufReader;\nuse std::process::Command;\nuse std::sync::Mutex;\n\nuse xml::EventReader;\nuse xml::reader::XmlEvent;\n\nstatic UNZIP: Mutex<()> = Mutex::new(());\n\nfn ensure_unzipped() {\n    let _g = UNZIP.lock().expect(\"unzip already failed\");\n\n    // test suite license only allows redistribution of unmodified zip!\n    if !Path::new(\"tests/xmlconf\").exists() {\n        assert!(Command::new(\"unzip\")\n            .current_dir(\"tests\")\n            .arg(\"xmlts20130923.zip\")\n            .status().unwrap().success(), \"must unzip\");\n    }\n}\n\n#[track_caller]\nfn run_suite(suite_rel_path: &str, known_broken_tests: &[&str]) {\n    ensure_unzipped();\n\n    let known_broken_tests = known_broken_tests.iter().map(|name| name.as_ref()).collect::<HashSet<&OsStr>>();\n\n    let suite_path = Path::new(\"tests/xmlconf\").join(suite_rel_path);\n    let root = suite_path.parent().unwrap();\n    let mut parsed = 0;\n\n    let f = BufReader::new(File::open(&suite_path)\n        .map_err(|e| format!(\"{}: {e}\", suite_path.display())).unwrap());\n    let r = EventReader::new(f);\n    let mut desc = String::new();\n    let mut attr = HashMap::<String, String>::new();\n    for e in r {\n        let e = e.expect(\"testsuite validity\");\n        match e {\n            XmlEvent::Characters(chr) => {\n                desc.push_str(&chr.replace('\\n', \" \"));\n            },\n            XmlEvent::EndElement { name } if name.local_name == \"TEST\" => {\n                let path = root.join(&attr[\"URI\"]);\n                let test_type = attr[\"TYPE\"].as_str();\n                let id = attr[\"ID\"].as_str();\n\n                let res = match test_type {\n                    \"valid\" => expect_well_formed(&path, &desc, id),\n                    \"invalid\" => expect_well_formed(&path, &desc, id), // invalid is still well-formed\n                    \"not-wf\" | \"error\" => expect_ill_formed(&path, &desc, id),\n                    other => unimplemented!(\"{other}?? type\"),\n                };\n\n                let known_bad = known_broken_tests.contains::<OsStr>(id.as_ref());\n\n                match res {\n                    Err(_) if known_bad => {},\n                    Err(e) => panic!(\"{suite_rel_path} failed on {} ({id})\\n{e}\", path.display()),\n                    Ok(()) if known_bad => panic!(\"expected {} ({id}) to fail, but it passes {test_type} of {suite_rel_path} now\\n{desc}\", path.display()),\n                    Ok(()) => {},\n                };\n                parsed += 1;\n            },\n            XmlEvent::StartElement { name, attributes, namespace: _ } if name.local_name == \"TEST\" => {\n                desc.clear();\n                attr = attributes.into_iter().map(|a| (a.name.local_name, a.value)).collect();\n            },\n            _ => {},\n\n        }\n    }\n    assert!(parsed > 0);\n}\n\n#[track_caller]\nfn expect_well_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn std::error::Error>> {\n    let f = BufReader::new(File::open(xml_path)?);\n    let r = EventReader::new(f);\n    let mut seen_any = false;\n    for e in r {\n        let e = e.map_err(|e| format!(\"\\\"{id}\\\", // {} {msg}; {e}\", xml_path.file_name().and_then(|f| f.to_str()).unwrap()))?;\n        if let XmlEvent::EndElement { .. } = e {\n            seen_any = true;\n        }\n    }\n    if !seen_any { Err(\"no elements found\")? }\n    Ok(())\n}\n\n#[track_caller]\nfn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn std::error::Error>> {\n    let f = BufReader::new(File::open(xml_path)?);\n    let r = EventReader::new(f);\n    for e in r {\n        if let Err(_) = e {\n            return Ok(());\n        }\n    }\n    Err(format!(\"\\\"{id}\\\", // {} {msg}\", xml_path.file_name().and_then(|f| f.to_str()).unwrap()))?\n}\n\n#[test] fn eduni_errata_2e() {\n    run_suite(\"eduni/errata-2e/errata2e.xml\", &[\n        \"rmt-e2e-15a\", // Empty content can't contain an entity reference\n        \"rmt-e2e-15e\", // Element content can contain entity reference if replacement text is whitespace\n        \"rmt-e2e-15f\", // Element content can contain entity reference if replacement text is whitespace, even if it came from a character reference in the literal entity value\n        \"rmt-e2e-15h\", // Element content can't contain entity reference if replacement text is character reference to whitespace\n        \"rmt-e2e-18\", // External entity containing start of entity declaration is base URI for system identifier\n        \"rmt-e2e-19\", // Parameter entities and character references are included-in-literal, but general entities are bypassed.\n        \"rmt-e2e-22\", // UTF-8 entities may start with a BOM\n        \"rmt-e2e-34\", // A non-deterministic content model is an error even if the element type is not used.\n        \"rmt-e2e-50\", // All line-ends are normalized, even those not passed to the application. NB this can only be tested effectively in XML 1.1, since CR is in the S production; in 1.1 we can use NEL which isn't.\n        \"rmt-e2e-55\", // A reference to an unparsed entity in an entity value is an error rather than forbidden (unless the entity is referenced, of course)\n        \"rmt-e2e-57\", // A value other than preserve or default for xml:space is an error\n        \"rmt-e2e-61\", // (From John Cowan) An encoding declaration in ASCII specifying an encoding that is not compatible with ASCII (so the document is not in its declared encoding).  It should generate a fatal error.\n    ]);\n}\n\n#[test] fn eduni_errata_3e() {\n    run_suite(\"eduni/errata-3e/errata3e.xml\", &[\n        \"rmt-e3e-12\", // E12.xml Default values for attributes may not contain references to external entities.\n        \"rmt-e3e-13\", // E13.xml Even internal parameter entity references are enough to make undeclared entities into mere validity errors rather than well-formedness errors.\n    ]);\n}\n\n#[test] fn eduni_errata_4e() {\n    run_suite(\"eduni/errata-4e/errata4e.xml\", &[\n        \"invalid-bo-1\", // inclbom_be.xml Byte order mark in general entity should go away (big-endian)\n        \"invalid-bo-2\", // inclbom_le.xml Byte order mark in general entity should go away (little-endian)\n        \"invalid-bo-3\", // incl8bom.xml Byte order mark in general entity should go away (utf-8)\n        \"invalid-bo-4\", // inclbombom_be.xml Two byte order marks in general entity produce only one (big-endian)\n        \"invalid-bo-5\", // inclbombom_le.xml Two byte order marks in general entity produce only one (little-endian)\n        \"invalid-bo-6\", // incl8bombom.xml Two byte order marks in general entity produce only one (utf-8)\n        \"invalid-sa-140\", // 140.xml Character '&#x309a;' is a CombiningChar, not a Letter, but as of 5th edition, may begin a name (c.f. xmltest/not-wf/sa/140.xml).\n        \"invalid-sa-141\", // 141.xml As of 5th edition, character #x0E5C is legal in XML names (c.f. xmltest/not-wf/sa/141.xml).\n        \"x-rmt-008b\", // 008.xml a document with version=1.7, legal in XML 1.0 from 5th edition\n        \"x-ibm-1-0.5-valid-P04-ibm04v01.xml\", // ibm04v01.xml This test case covers legal NameStartChars character ranges plus discrete legal characters for production 04.\n        \"x-ibm-1-0.5-valid-P05-ibm05v01.xml\", // ibm05v01.xml This test case covers legal Element Names as per production 5.\n        \"x-ibm-1-0.5-valid-P05-ibm05v03.xml\", // ibm05v03.xml This test case covers legal Attribute (Names) as per production 5.\n    ]);\n}\n\n#[test] fn eduni_misc_ht() {\n    run_suite(\"eduni/misc/ht-bh.xml\", &[]);\n}\n\n#[test] fn eduni_namespaces_10() {\n    run_suite(\"eduni/namespaces/1.0/rmt-ns10.xml\", &[\n        \"rmt-ns10-004\", // Namespace name test: a relative URI (deprecated)\n        \"rmt-ns10-005\", // Namespace name test: a same-document relative URI (deprecated)\n        \"rmt-ns10-009\", // Namespace equality test: plain repetition\n        \"rmt-ns10-010\", // Namespace equality test: use of character reference\n        \"rmt-ns10-012\", // Namespace inequality test: equal after attribute value normalization\n        \"rmt-ns10-030\", // Reserved prefixes and namespaces: binding another prefix to the xml namespace\n        \"rmt-ns10-033\", // Reserved prefixes and namespaces: binding another prefix to the xmlns namespace\n        \"rmt-ns10-036\", // Attribute uniqueness: repeated attribute with different prefixes\n        \"rmt-ns10-042\", // Colon in PI name\n        \"rmt-ns10-043\", // Colon in entity name\n        \"rmt-ns10-044\", // Colon in entity name\n        \"ht-ns10-047\", // Reserved name: _not_ an error\n    ]);\n}\n\n#[test] fn eduni_namespaces_11() {\n    run_suite(\"eduni/namespaces/1.1/rmt-ns11.xml\", &[\n        \"rmt-ns11-001\", // 001.xml Namespace name test: a perfectly good http IRI that is not a URI\n        \"rmt-ns11-002\", // 002.xml Namespace inequality test: different escaping of non-ascii letter\n        \"rmt-ns11-003\", // 003.xml 1.1 style prefix unbinding\n        \"rmt-ns11-004\", // 004.xml 1.1 style prefix unbinding and rebinding\n    ]);\n}\n\n#[test] fn eduni_namespaces_errata() {\n    run_suite(\"eduni/namespaces/errata-1e/errata1e.xml\", &[\n        \"rmt-ns-e1.0-13a\", // NE13a.xml The xml namespace must not be declared as the default namespace.\n        \"rmt-ns-e1.0-13b\", // NE13b.xml The xmlns namespace must not be declared as the default namespace.\n    ]);\n}\n\n#[test] fn eduni_xml_11() {\n    run_suite(\"eduni/xml-1.1/xml11.xml\", &[\n        \"rmt-001\", // 001.xml External subset has later version number\n        \"rmt-002\", // 002.xml External PE has later version number\n        \"rmt-006\", // 006.xml Second-level external general entity has later version number than first-level, but not later than document, so not an error.\n        \"rmt-010\", // 010.xml Contains a C1 control, legal in XML 1.0, illegal in XML 1.1\n        \"rmt-013\", // 013.xml Contains a DEL, legal in XML 1.0, illegal in XML 1.1\n        \"rmt-014\", // 014.xml Has a \"long s\" in a name, legal in XML 1.1, illegal in XML 1.0 thru 4th edition\n        \"rmt-016\", // 016.xml Has a Byzantine Musical Symbol Kratimata in a name, legal in XML 1.1, illegal in XML 1.0 thru 4th edition\n        \"rmt-019\", // 019.xml Has the last legal namechar in XML 1.1, illegal in XML 1.0 thru 4th edition\n        \"rmt-022\", // 022.xml Has a NEL character; legal in both XML 1.0 and 1.1, but different canonical output because of normalization in 1.1\n        \"rmt-023\", // 023.xml Has a NEL character; legal in both XML 1.0 and 1.1, but different canonical output because of normalization in 1.1\n        \"rmt-026\", // 026.xml Has CR-NEL; legal in both XML 1.0 and 1.1, but different canonical output because of normalization in 1.1\n        \"rmt-027\", // 027.xml Has CR-NEL; legal in both XML 1.0 and 1.1, but different canonical output because of normalization in 1.1\n        \"rmt-030\", // 030.xml Has a NEL character in an NMTOKENS attribute; well-formed in both XML 1.0 and 1.1, but valid only in 1.1\n        \"rmt-031\", // 031.xml Has a NEL character in an NMTOKENS attribute; well-formed in both XML 1.0 and 1.1, but valid only in 1.1\n        \"rmt-034\", // 034.xml Has an NMTOKENS attribute containing a CR character that comes from a character reference in an internal entity.  Because CR is in the S production, this is valid in both XML 1.0 and 1.1.\n        \"rmt-035\", // 035.xml Has an NMTOKENS attribute containing a CR character that comes from a character reference in an internal entity.  Because CR is in the S production, this is valid in both XML 1.0 and 1.1.\n        \"rmt-036\", // 036.xml Has an NMTOKENS attribute containing a NEL character that comes from a character reference in an internal entity.  Because NEL is not in the S production (even though real NELs are converted to LF on input), this is invalid in both XML 1.0 and 1.1.\n        \"rmt-037\", // 037.xml Has an NMTOKENS attribute containing a NEL character that comes from a character reference in an internal entity.  Because NEL is not in the S production (even though real NELs are converted to LF on input), this is invalid in both XML 1.0 and 1.1.\n        \"rmt-038\", // 038.xml Contains a C0 control character (form-feed), illegal in both XML 1.0 and 1.1\n        \"rmt-039\", // 039.xml Contains a C0 control character (form-feed), illegal in both XML 1.0 and 1.1\n        \"rmt-040\", // 040.xml Contains a C1 control character (partial line up), legal in XML 1.0 but not 1.1\n        \"rmt-042\", // 042.xml Contains a character reference to a C0 control character (form-feed), legal in XML 1.1 but not 1.0\n        \"rmt-046\", // 046.xml Has a NEL character in element content whitespace; well-formed in both XML 1.0 and 1.1, but valid only in 1.1\n        \"rmt-047\", // 047.xml Has a NEL character in element content whitespace; well-formed in both XML 1.0 and 1.1, but valid only in 1.1\n        \"rmt-050\", // 050.xml Has element content whitespace containing a CR character that comes from a character reference in an internal entity.  Because CR is in the S production, this is valid in both XML 1.0 and 1.1.\n        \"rmt-051\", // 051.xml Has element content whitespace containing a CR character that comes from a character reference in an internal entity.  Because CR is in the S production, this is valid in both XML 1.0 and 1.1.\n        \"rmt-052\", // 052.xml Has element content whitespace containing a NEL character that comes from a character reference in an internal entity.  Because NEL is not in the S production (even though real NELs are converted to LF on input), this is invalid in both XML 1.0 and 1.1.\n        \"rmt-053\", // 053.xml Has element content whitespace containing a NEL character that comes from a character reference in an internal entity.  Because NEL is not in the S production (even though real NELs are converted to LF on input), this is invalid in both XML 1.0 and 1.1.\n        \"rmt-054\", // 054.xml Contains a character reference to a C0 control character (form-feed) in an entity value.  This will be legal (in XML 1.1) when the entity declaration is parsed, but what about when it is used?\n    ]);\n}\n\n#[test] fn ibm_oasis_valid() {\n    run_suite(\"ibm/ibm_oasis_valid.xml\", &[\n        \"ibm-valid-P09-ibm09v01.xml\", // ibm09v01.xml Empty EntityValue is legal\n        \"ibm-valid-P09-ibm09v02.xml\", // ibm09v02.xml Tests a normal EnitityValue\n        \"ibm-valid-P09-ibm09v03.xml\", // ibm09v03.xml Tests EnitityValue referencing a Parameter Entity\n        \"ibm-valid-P09-ibm09v04.xml\", // ibm09v04.xml Tests EnitityValue referencing a General Entity\n        \"ibm-valid-P09-ibm09v05.xml\", // ibm09v05.xml Tests EnitityValue with combination of GE, PE and text, the GE used is      declared in the student.dtd\n        \"ibm-valid-P10-ibm10v01.xml\", // ibm10v01.xml Tests empty AttValue with double quotes as the delimiters\n        \"ibm-valid-P10-ibm10v02.xml\", // ibm10v02.xml Tests empty AttValue with single quotes as the delimiters\n        \"ibm-valid-P10-ibm10v03.xml\", // ibm10v03.xml Test AttValue with double quotes as the delimiters and single quote inside\n        \"ibm-valid-P10-ibm10v04.xml\", // ibm10v04.xml Test AttValue with single quotes as the delimiters and double quote inside\n        \"ibm-valid-P10-ibm10v05.xml\", // ibm10v05.xml Test AttValue with a GE reference and double quotes as the delimiters\n        \"ibm-valid-P10-ibm10v06.xml\", // ibm10v06.xml Test AttValue with a GE reference and single quotes as the delimiters\n        \"ibm-valid-P10-ibm10v07.xml\", // ibm10v07.xml testing AttValue with mixed references and text content in double quotes\n        \"ibm-valid-P10-ibm10v08.xml\", // ibm10v08.xml testing AttValue with mixed references and text content in single quotes\n        \"ibm-valid-P28-ibm28v02.xml\", // ibm28v02.xml Tests doctypedecl with external subset and combinations of different markup     declarations and PEReferences\n        \"ibm-valid-P29-ibm29v01.xml\", // ibm29v01.xml Tests markupdecl with combinations of elementdecl, AttlistDecl,EntityDecl,      NotationDecl, PI and comment\n        \"ibm-valid-P29-ibm29v02.xml\", // ibm29v02.xml Tests WFC: PE in internal subset as a positive test\n        \"ibm-valid-P32-ibm32v02.xml\", // ibm32v02.xml Tests VC: Standalone Document Declaration with external entity reference     and standalone is no\n        \"ibm-valid-P43-ibm43v01.xml\", // ibm43v01.xml Tests content with all possible constructs: element, CharData, Reference,      CDSect, Comment\n        \"ibm-valid-P67-ibm67v01.xml\", // ibm67v01.xml Tests Reference could be EntityRef or CharRef.\n        \"ibm-valid-P78-ibm78v01.xml\", // ibm78v01.xml Tests ExtParsedEnt, also TextDecl in P77 and EncodingDecl in P80\n    ]);\n}\n\n#[test] fn ibm_xml_11() {\n    run_suite(\"ibm/xml-1.1/ibm_valid.xml\", &[\n        \"ibm-1-1-valid-P02-ibm02v04.xml\", // ibm02v04.xml This test case contains embeded whitespace characters                   some form the range 1 - 1F.\n        \"ibm-1-1-valid-P03-ibm03v01.xml\", // ibm03v01.xml The two character sequence #x0D #x85 in an external entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v02.xml\", // ibm03v02.xml The single character sequence #x85 in an external entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v03.xml\", // ibm03v03.xml The two character sequence #x0D #x85 in an external entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v04.xml\", // ibm03v04.xml The single character sequence #x85 in an external entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v05.xml\", // ibm03v05.xml The two character sequence #x0D #x85 in a document entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v06.xml\", // ibm03v06.xml The single character sequence #x85 in a document entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P03-ibm03v07.xml\", // ibm03v07.xml The single character sequence #x2028 in a document entity must be normalized to a          single newline.\n        \"ibm-1-1-valid-P04-ibm04v01.xml\", // ibm04v01.xml This test case covers legal NameStartChars character ranges plus discrete legal          characters for production 04.\n        \"ibm-1-1-valid-P05-ibm05v01.xml\", // ibm05v01.xml This test case covers legal Element Names as per production 5.\n        \"ibm-1-1-valid-P05-ibm05v03.xml\", // ibm05v03.xml This test case covers legal Attribute (Names) as per production 5.\n        \"ibm-1-1-valid-P77-ibm77v04.xml\", // ibm77v04.xml The VersionNum of the document entity is 1.1 whereas the VersionNum of the external          entity is 1.0.  The character #xD6 which is a valid XML 1.1 but an invalid XML 1.0          character is present in both documents.\n        \"ibm-1-1-valid-P77-ibm77v05.xml\", // ibm77v05.xml The VersionNum of the document entity is 1.1 whereas the VersionNum of the external          entity is 1.0.  The character #x1FFF which is a valid XML 1.1 but an invalid XML 1.0          character is present in both documents.\n        \"ibm-1-1-valid-P77-ibm77v06.xml\", // ibm77v06.xml The VersionNum of the document entity is 1.1 whereas the VersionNum of the external          entity is 1.0.  The character #xF901 which is a valid XML 1.1 but an invalid XML 1.0          character is present in both documents.\n        \"ibm-1-1-valid-P77-ibm77v10.xml\", // ibm77v10.xml The VersionNum of the document and external entity is 1.1 and both contain the          valid XML1.1 but invalid XML1.0 character #xF6.\n        \"ibm-1-1-valid-P77-ibm77v11.xml\", // ibm77v11.xml The VersionNum of the document and external entity is 1.1 and both contain the          valid XML1.1 but invalid XML1.0 character #x1FFF.\n        \"ibm-1-1-valid-P77-ibm77v12.xml\", // ibm77v12.xml The VersionNum of the document and external entity is 1.1 and both contain the          valid XML1.1 but invalid XML1.0 character #xF901.\n        \"ibm-1-1-valid-P77-ibm77v16.xml\", // ibm77v16.xml The VersionNum of the document entity is 1.1 but the external entity does not          contain a textDecl and both contain the valid XML1.1 but invalid XML1.0 character          #x2FF.\n        \"ibm-1-1-valid-P77-ibm77v17.xml\", // ibm77v17.xml The VersionNum of the document entity is 1.1 but the external entity does not          contain a textDecl and both contain the valid XML1.1 but invalid XML1.0 character          #x1FFF.\n        \"ibm-1-1-valid-P77-ibm77v18.xml\", // ibm77v18.xml The VersionNum of the document entity is 1.1 but the external entity does not          contain a textDecl and both contain the valid XML1.1 but invalid XML1.0 character          #xF901.\n        \"ibm-1-1-valid-P77-ibm77v22.xml\", // ibm77v22.xml The VersionNum of the document and the external entity is 1.1.  The entity contains          a reference to the character #x7F.\n        \"ibm-1-1-valid-P77-ibm77v23.xml\", // ibm77v23.xml The VersionNum of the document and the external entity is 1.1.  The entity contains          a reference to the character #x80.\n        \"ibm-1-1-valid-P77-ibm77v24.xml\", // ibm77v24.xml The VersionNum of the document and the external entity is 1.1.  The entity contains          a reference to the character #x9F.\n        \"ibm-1-1-valid-P77-ibm77v28.xml\", // ibm77v28.xml The VersionNum of the document is 1.1 and the textDecl is missing in the external          entity.  The replacement text of an entity declared in the external DTD contains a          reference to the character #x7F, #x80, #x9F.\n        \"ibm-1-1-valid-P77-ibm77v29.xml\", // ibm77v29.xml The VersionNum of the document is 1.1 and the textDecl is missing in the external          entity.  The replacement text of an entity declared in the external DTD contains a          reference to the character #x85, #x8F.\n        \"ibm-1-1-valid-P77-ibm77v30.xml\", // ibm77v30.xml The VersionNum of the document is 1.1 and the textDecl is missing in the external          entity.\n    ]);\n}\n\n#[test] fn oasis() {\n    run_suite(\"oasis/oasis.xml\", &[\n        \"o-p01fail1\", // S cannot occur before the prolog\n        \"o-p01fail2\", // comments cannot occur before the prolog\n        \"o-p01fail3\", // only one document element\n        \"o-p04pass1\", // names with all valid ASCII characters, and one from each               other class in NameChar\n        \"o-p05pass1\", // various valid Name constructions\n        \"o-p09fail1\", // EntityValue excludes '%'\n        \"o-p09fail2\", // EntityValue excludes '&'\n        \"o-p09fail3\", // incomplete character reference\n        \"o-p11pass1\", // p11pass1.xml       system literals may not contain     URI fragments\n        \"o-p12fail1\", // p12fail1.xml       '\"' excluded\n        \"o-p12fail2\", // '\\' excluded\n        \"o-p12fail3\", // entity references excluded\n        \"o-p12fail4\", // p12fail4.xml       '>' excluded\n        \"o-p12fail5\", // p12fail5.xml       '<' excluded\n        \"o-p12fail6\", // built-in entity refs excluded\n        \"o-p12fail7\", // The public ID has a tab character, which is disallowed\n        \"o-p14fail3\", // \"]]>\" excluded\n        \"o-p18fail3\", // CDSect's can't nest\n        \"o-p22fail1\", // prolog must start with XML decl\n        \"o-p22fail2\", // prolog must start with XML decl\n        \"o-p23fail1\", // \"xml\" must be lower-case\n        \"o-p27fail1\", // References aren't allowed in Misc,     even if they would resolve to valid Misc.\n        \"o-p30fail1\", // An XML declaration is not the same as a TextDecl\n        \"o-p31fail1\", // external subset excludes doctypedecl\n        \"o-p32fail3\", // initial S is required\n        \"o-p40fail1\", // S is required between attributes\n        \"o-p43pass1\", // Valid use of character data, comments, processing instructions and CDATA sections within the start and end tag.\n        \"o-p44fail4\", // Whitespace required between attributes.\n        \"o-p45fail2\", // S before contentspec is required.\n        \"o-p45fail3\", // only one content spec\n        \"o-p45fail4\", // no comments in declarations (contrast with SGML)\n        \"o-p46fail1\", // no parens on declared content\n        \"o-p46fail2\", // no inclusions (contrast with SGML)\n        \"o-p46fail3\", // no exclusions (contrast with SGML)\n        \"o-p46fail4\", // no space before occurrence\n        \"o-p46fail5\", // single group\n        \"o-p46fail6\", // can't be both declared and modeled\n        \"o-p47fail1\", // Invalid operator '|' must match previous operator ','\n        \"o-p47fail2\", // Illegal character '-' in Element-content model\n        \"o-p47fail3\", // Optional character must follow a name or list\n        \"o-p47fail4\", // Illegal space before optional character\n        \"o-p48fail1\", // Illegal space before optional character\n        \"o-p48fail2\", // Illegal space before optional character\n        \"o-p51fail1\", // occurrence on #PCDATA group must be *\n        \"o-p51fail2\", // occurrence on #PCDATA group must be *\n        \"o-p51fail3\", // #PCDATA must come first\n        \"o-p51fail4\", // occurrence on #PCDATA group must be *\n        \"o-p51fail5\", // only '|' connectors\n        \"o-p51fail6\", // Only '|' connectors and occurrence on #PCDATA group must be *\n        \"o-p51fail7\", // no nested groups\n        \"o-p52fail1\", // A name is required\n        \"o-p52fail2\", // A name is required\n        \"o-p53fail1\", // S is required before default\n        \"o-p53fail2\", // S is required before type\n        \"o-p53fail3\", // type is required\n        \"o-p53fail4\", // default is required\n        \"o-p53fail5\", // name is requried\n        \"o-p54fail1\", // don't pass unknown attribute types\n        \"o-p55fail1\", // must be upper case\n        \"o-p56fail1\", // no IDS type\n        \"o-p56fail2\", // no NUMBER type\n        \"o-p56fail3\", // no NAME type\n        \"o-p56fail4\", // no ENTITYS type - types must be upper case\n        \"o-p56fail5\", // types must be upper case\n        \"o-p57fail1\", // no keyword for NMTOKEN enumeration\n        \"o-p58fail1\", // at least one value required\n        \"o-p58fail2\", // separator must be '|'\n        \"o-p58fail3\", // notations are NAMEs, not NMTOKENs -- note:     Leaving the invalid           notation undeclared would cause a validating parser to fail without           checking the name syntax, so the notation is declared with an           invalid name.  A parser that reports error positions should report           an error at the AttlistDecl on line 6, before reaching the notation           declaration.\n        \"o-p58fail4\", // NOTATION must be upper case\n        \"o-p58fail5\", // S after keyword is required\n        \"o-p58fail6\", // parentheses are require\n        \"o-p58fail7\", // values are unquoted\n        \"o-p58fail8\", // values are unquoted\n        \"o-p59fail1\", // at least one required\n        \"o-p59fail2\", // separator must be \",\"\n        \"o-p59fail3\", // values are unquoted\n        \"o-p60fail1\", // keywords must be upper case\n        \"o-p60fail2\", // S is required after #FIXED\n        \"o-p60fail3\", // only #FIXED has both keyword and value\n        \"o-p60fail4\", // #FIXED required value\n        \"o-p60fail5\", // only one default type\n        \"o-p61fail1\", // no other types, including TEMP, which is valid in SGML\n        \"o-p62fail1\", // INCLUDE must be upper case\n        \"o-p62fail2\", // no spaces in terminating delimiter\n        \"o-p63fail1\", // IGNORE must be upper case\n        \"o-p63fail2\", // delimiters must be balanced\n        \"o-p64fail1\", // section delimiters must balance\n        \"o-p64fail2\", // section delimiters must balance\n        \"o-p66fail5\", // no references to non-characters\n        \"o-p68pass1\", // Valid entity references.  Also ensures that a charref to           '&' isn't interpreted as an entity reference open delimiter\n        \"o-p69fail1\", // terminating ';' is required\n        \"o-p69fail2\", // no S after '%'\n        \"o-p69fail3\", // no S before ';'\n        \"o-p70fail1\", // This is neither\n        \"o-p71fail1\", // S is required before EntityDef\n        \"o-p71fail2\", // Entity name is a Name, not an NMToken\n        \"o-p71fail4\", // S is required after \"<!ENTITY\"\n        \"o-p72fail1\", // S is required after \"<!ENTITY\"\n        \"o-p72fail2\", // S is required after '%'\n        \"o-p72fail3\", // S is required after name\n        \"o-p76fail4\", // p76fail4.xml       notation names are Names\n        \"o-p72fail4\", // Entity name is a name, not an NMToken\n        \"o-p73fail1\", // No typed replacement text\n        \"o-p73fail2\", // Only one replacement value\n        \"o-p73fail3\", // No NDataDecl on replacement text\n        \"o-p73fail4\", // Value is required\n        \"o-p73fail5\", // No NDataDecl without value\n        \"o-p74fail1\", // no NDataDecls on parameter entities\n        \"o-p74fail2\", // value is required\n        \"o-p74fail3\", // only one value\n        \"o-p75fail1\", // S required after \"PUBLIC\"\n        \"o-p75fail2\", // S required after \"SYSTEM\"\n        \"o-p75fail3\", // S required between literals\n        \"o-p75fail4\", // \"SYSTEM\" implies only one literal\n        \"o-p75fail5\", // only one keyword\n        \"o-p75fail6\", // \"PUBLIC\" requires two literals (contrast with SGML)\n        \"o-p76fail1\", // S is required before \"NDATA\"\n        \"o-p76fail2\", // \"NDATA\" is upper-case\n        \"o-p76fail3\", // notation name is required\n    ]);\n}\n\n#[test] fn sun_valid() {\n    run_suite(\"sun/sun-valid.xml\", &[\n        \"ext01\", // Tests use of external parsed entities with and without content.\n        \"ext02\", // Tests use of external parsed entities with different    encodings than the base document.\n        \"not-sa02\", // A non-standalone document is valid if declared as such.\n        \"not-sa03\", // A non-standalone document is valid if declared as such.\n        \"not-sa04\", // A non-standalone document is valid if declared as such.\n        \"sa02\", // A document may be marked 'standalone' if any     attributes that need normalization are  defined within the internal DTD subset.\n        \"sa03\", // A document may be marked 'standalone' if any     the defined entities need expanding are internal,     and no attributes need defaulting or normalization.     On output, requires notations to be correctly reported.\n        \"sa04\", // Like sa03 but relies on attribute     defaulting defined in the internal subset.     On output, requires notations to be correctly reported.\n        \"v-pe00\", // Tests construction of internal entity replacement text, using     an example in the XML specification.\n        \"v-pe03\", // Tests construction of internal entity replacement text, using     an example in the XML specification.\n        \"v-pe02\", // Tests construction of internal entity replacement text, using     a complex example in the XML specification.\n    ]);\n}\n\n#[test] fn sun_ill_formed() {\n    run_suite(\"sun/sun-not-wf.xml\", &[\n        \"attlist01\", // SGML's NUTOKEN is not allowed.\n        \"attlist02\", // SGML's NUTOKENS attribute type is not allowed.\n        \"attlist03\", // Comma doesn't separate enumerations, unlike in SGML.\n        \"attlist04\", // SGML's NUMBER attribute type is not allowed.\n        \"attlist05\", // SGML's NUMBERS attribute type is not allowed.\n        \"attlist06\", // SGML's NAME attribute type is not allowed.\n        \"attlist07\", // SGML's NAMES attribute type is not allowed.\n        \"attlist08\", // SGML's #CURRENT is not allowed.\n        \"attlist09\", // SGML's #CONREF is not allowed.\n        \"attlist10\", // Whitespace required between attributes\n        \"attlist11\", // Whitespace required between attributes\n        \"cond01\", // Only INCLUDE and IGNORE are conditional section keywords\n        \"cond02\", // Must have keyword in conditional sections\n        \"content01\", // No whitespace before \"?\" in content model\n        \"content02\", // No whitespace before \"*\" in content model\n        \"content03\", // No whitespace before \"+\" in content model\n        \"decl01\", // External entities may not have standalone decls.\n        \"dtd02\", // PE name immediately after \"%\"\n        \"dtd03\", // PE name immediately followed by \";\"\n        \"dtd04\", // PUBLIC literal must be quoted\n        \"dtd05\", // SYSTEM identifier must be quoted\n        \"dtd07\", // Text declarations (which optionally begin any external entity)     are required to have \"encoding=...\".\n        \"encoding01\", // Illegal character \" \" in encoding name\n        \"encoding02\", // Illegal character \"/\" in encoding name\n        \"encoding03\", // Illegal character reference in encoding name\n        \"encoding04\", // Illegal character \":\" in encoding name\n        \"encoding05\", // Illegal character \"@\" in encoding name\n        \"encoding06\", // Illegal character \"+\" in encoding name\n        \"nwf-dtd00\", // Comma mandatory in content model\n        \"nwf-dtd01\", // Can't mix comma and vertical bar in content models\n        \"pi\", // pi.xml      No space between PI target name and data\n        \"pubid01\", // Illegal entity ref in public ID\n        \"pubid02\", // Illegal characters in public ID\n        \"pubid03\", // Illegal characters in public ID\n        \"pubid04\", // Illegal characters in public ID\n        \"pubid05\", // SGML-ism:  public ID without system ID\n        \"sgml02\", // XML declaration must be at the very beginning of a document;   it\"s not a processing instruction\n        \"sgml04\", // ATTLIST declarations apply to only one element, unlike SGML\n        \"sgml05\", // ELEMENT declarations apply to only one element, unlike SGML\n        \"sgml06\", // ATTLIST declarations are never global, unlike in SGML\n        \"sgml07\", // SGML Tag minimization specifications are not allowed\n        \"sgml08\", // SGML Tag minimization specifications are not allowed\n        \"sgml09\", // SGML Content model exception specifications are not allowed\n        \"sgml10\", // SGML Content model exception specifications are not allowed\n        \"sgml11\", // CDATA is not a valid content model spec\n        \"sgml12\", // RCDATA is not a valid content model spec\n        \"sgml13\", // SGML Unordered content models not allowed\n    ]);\n}\n\n#[ignore]\n#[test] fn japanese() {\n    run_suite(\"japanese/japanese.xml\", &[\n        \"pr-xml-little-endian.xml\"  // needs DTD\n    ]);\n}\n\n#[test] fn xmltest() {\n    run_suite(\"xmltest/xmltest.xml\", &[\n        \"not-wf-sa-003\", // Processing Instruction target name is required.\n        \"not-wf-sa-025\", // Text may not contain a literal ']]>' sequence.\n        \"not-wf-sa-026\", // Text may not contain a literal ']]>' sequence.\n        \"not-wf-sa-029\", // Text may not contain a literal ']]>' sequence.\n        \"not-wf-sa-030\", // A form feed is not a legal XML character.\n        \"not-wf-sa-031\", // A form feed is not a legal XML character.\n        \"not-wf-sa-032\", // A form feed is not a legal XML character.\n        \"not-wf-sa-033\", // An ESC (octal 033) is not a legal XML character.\n        \"not-wf-sa-037\", // Character references may not appear after the root element.\n        \"not-wf-sa-040\", // Provides two document elements.\n        \"not-wf-sa-041\", // Provides two document elements.\n        \"not-wf-sa-044\", // Provides two document elements.\n        \"not-wf-sa-048\", // Provides a CDATA section after the root element.\n        \"not-wf-sa-051\", // CDATA is invalid at top level of document.\n        \"not-wf-sa-052\", // Invalid character reference.\n        \"not-wf-sa-054\", // PUBLIC requires two literals.\n        \"not-wf-sa-056\", // Invalid Document Type Definition format - misplaced comment.\n        \"not-wf-sa-057\", // This isn't SGML; comments can't exist in declarations.\n        \"not-wf-sa-058\", // Invalid character , in ATTLIST enumeration\n        \"not-wf-sa-059\", // String literal must be in quotes.\n        \"not-wf-sa-060\", // Invalid type NAME defined in ATTLIST.\n        \"not-wf-sa-061\", // External entity declarations require whitespace between public     and system IDs.\n        \"not-wf-sa-062\", // Entity declarations need space after the entity name.\n        \"not-wf-sa-064\", // Space is required between attribute type and default values     in <!ATTLIST...> declarations.\n        \"not-wf-sa-065\", // Space is required between attribute name and type     in <!ATTLIST...> declarations.\n        \"not-wf-sa-066\", // Required whitespace is missing.\n        \"not-wf-sa-067\", // Space is required between attribute type and default values     in <!ATTLIST...> declarations.\n        \"not-wf-sa-068\", // Space is required between NOTATION keyword and list of     enumerated choices in <!ATTLIST...> declarations.\n        \"not-wf-sa-069\", // Space is required before an NDATA entity annotation.\n        \"not-wf-sa-078\", // Undefined ENTITY foo.\n        \"not-wf-sa-079\", // ENTITY can't reference itself directly or indirectly.\n        \"not-wf-sa-080\", // ENTITY can't reference itself directly or indirectly.\n        \"not-wf-sa-082\", // This tests the No External Entity References WFC,     since the entity is referred to within an attribute.\n        \"not-wf-sa-084\", // Tests the Parsed Entity WFC by referring to an     unparsed entity.  (This precedes the error of not declaring     that entity's notation, which may be detected any time before     the DTD parsing is completed.)\n        \"not-wf-sa-085\", // Public IDs may not contain \"[\".\n        \"not-wf-sa-086\", // Public IDs may not contain \"[\".\n        \"not-wf-sa-087\", // Public IDs may not contain \"[\".\n        \"not-wf-sa-089\", // Parameter entities \"are\" always parsed; NDATA annotations     are not permitted.\n        \"not-wf-sa-091\", // Parameter entities \"are\" always parsed; NDATA annotations     are not permitted.\n        \"not-wf-sa-096\", // Space is required before the standalone declaration.\n        \"not-wf-sa-101\", // Space is not permitted in an encoding name.\n        \"not-wf-sa-105\", // Invalid placement of CDATA section.\n        \"not-wf-sa-106\", // Invalid placement of entity declaration.\n        \"not-wf-sa-113\", // Parameter entity values must use valid reference syntax;     this reference is malformed.\n        \"not-wf-sa-114\", // General entity values must use valid reference syntax;     this reference is malformed.\n        \"not-wf-sa-121\", // A name of an ENTITY was started with an invalid character.\n        \"not-wf-sa-122\", // Invalid syntax mixed connectors are used.\n        \"not-wf-sa-123\", // Invalid syntax mismatched parenthesis.\n        \"not-wf-sa-124\", // Invalid format of Mixed-content declaration.\n        \"not-wf-sa-125\", // Invalid syntax extra set of parenthesis not necessary.\n        \"not-wf-sa-126\", // Invalid syntax Mixed-content must be defined as zero or more.\n        \"not-wf-sa-127\", // Invalid syntax Mixed-content must be defined as zero or more.\n        \"not-wf-sa-128\", // Invalid CDATA syntax.\n        \"not-wf-sa-129\", // Invalid syntax for Element Type Declaration.\n        \"not-wf-sa-130\", // Invalid syntax for Element Type Declaration.\n        \"not-wf-sa-131\", // Invalid syntax for Element Type Declaration.\n        \"not-wf-sa-132\", // Invalid syntax mixed connectors used.\n        \"not-wf-sa-133\", // Illegal whitespace before optional character causes syntax error.\n        \"not-wf-sa-134\", // Illegal whitespace before optional character causes syntax error.\n        \"not-wf-sa-135\", // Invalid character used as connector.\n        \"not-wf-sa-136\", // Tag omission is invalid in XML.\n        \"not-wf-sa-137\", // Space is required before a content model.\n        \"not-wf-sa-138\", // Invalid syntax for content particle.\n        \"not-wf-sa-139\", // The element-content model should not be empty.\n        \"not-wf-sa-143\", // Character #x001F is not legal anywhere in an XML document.\n        \"not-wf-sa-144\", // Character #xFFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-147\", // XML Declaration may not be preceded by whitespace.\n        \"not-wf-sa-148\", // XML Declaration may not be preceded by comments or whitespace.\n        \"not-wf-sa-149\", // XML Declaration may not be within a DTD.\n        \"not-wf-sa-154\", // '<?XML ...?>' is neither an XML declaration     nor a legal processing instruction target name.\n        \"not-wf-sa-155\", // '<?xmL ...?>' is neither an XML declaration     nor a legal processing instruction target name.\n        \"not-wf-sa-158\", // SGML-ism:  \"#NOTATION gif\" can't have attributes.\n        \"not-wf-sa-160\", // Violates the PEs in Internal Subset WFC     by using a PE reference within a declaration.\n        \"not-wf-sa-161\", // Violates the PEs in Internal Subset WFC     by using a PE reference within a declaration.\n        \"not-wf-sa-162\", // Violates the PEs in Internal Subset WFC     by using a PE reference within a declaration.\n        \"not-wf-sa-164\", // Invalid placement of Parameter entity reference.\n        \"not-wf-sa-165\", // Parameter entity declarations must have a space before     the '%'.\n        \"not-wf-sa-166\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-167\", // Character FFFE is not legal anywhere in an XML document.\n        \"not-wf-sa-171\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-172\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-173\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-174\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-175\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-177\", // Character FFFF is not legal anywhere in an XML document.\n        \"not-wf-sa-180\", // The Entity Declared WFC requires entities to be declared     before they are used in an attribute list declaration.\n        \"not-wf-sa-183\", // Mixed content declarations may not include content particles.\n        \"not-wf-sa-184\", // In mixed content models, element names must not be     parenthesized.\n        \"not-wf-sa-186\", // Whitespace is required between attribute/value pairs.\n        \"not-wf-not-sa-001\", // Conditional sections must be properly terminated (\"]>\" used     instead of \"]]>\").\n        \"not-wf-not-sa-002\", // Processing instruction target names may not be \"XML\"      in any combination of cases.\n        \"not-wf-not-sa-003\", // Conditional sections must be properly terminated (\"]]>\" omitted).\n        \"not-wf-not-sa-004\", // Conditional sections must be properly terminated (\"]]>\" omitted).\n        \"not-wf-not-sa-005\", // Tests the Entity Declared VC by referring to an     undefined parameter entity within an external entity.\n        \"not-wf-not-sa-006\", // Conditional sections need a '[' after the INCLUDE or IGNORE.\n        \"not-wf-not-sa-007\", // A <!DOCTYPE ...> declaration may not begin any external     entity; it's only found once, in the document entity.\n        \"not-wf-not-sa-008\", // In DTDs, the '%' character must be part of a parameter     entity reference.\n        \"not-wf-not-sa-009\", // This test violates WFC:PE Between Declarations in Production 28a.       The last character of a markup declaration is not contained in the same      parameter-entity text replacement.\n        \"valid-sa-012\", // Uses a legal XML 1.0 name consisting of a single colon     character (disallowed by the latest XML Namespaces draft).\n        \"valid-sa-023\", // Test demonstrates that Entity References are valid element content.\n        \"valid-sa-024\", // Test demonstrates that Entity References are valid element content and also demonstrates a valid Entity Declaration.\n        \"valid-sa-049\", // Test demonstrates that characters outside of normal ascii range can be used as element content.\n        \"valid-sa-050\", // Test demonstrates that characters outside of normal ascii range can be used as element content.\n        \"valid-sa-051\", // The document is encoded in UTF-16 and uses some name     characters well outside of the normal ASCII range.\n        \"valid-sa-053\", // Tests inclusion of a well-formed internal entity, which     holds an element required by the content model.\n        \"valid-sa-066\", // Expands a CDATA attribute with a character reference.\n        \"valid-sa-068\", // Tests definition of an internal entity holding a carriage return character     reference, which must not be normalized before reporting to the application.  Line      break normalization only occurs when parsing external parsed entities.\n        \"valid-sa-085\", // Parameter and General entities use different namespaces,     so there can be an entity of each type with a given name.\n        \"valid-sa-086\", // Tests whether entities may be declared more than once,     with the first declaration being the binding one.\n        \"valid-sa-087\", // Tests whether character references in internal entities are     expanded early enough, by relying on correct handling to     make the entity be well formed.\n        \"valid-sa-088\", // Tests whether entity references in internal entities are     expanded late enough, by relying on correct handling to     make the expanded text be valid.  (If it's expanded too     early, the entity will parse as an element that's not     valid in that context.)\n        \"valid-sa-089\", // Tests entity expansion of three legal character references,     which each expand to a Unicode surrogate pair.\n        \"valid-sa-108\", // This tests normalization of end-of-line characters (CRLF)     within entities to LF, primarily as an output test.\n        \"valid-sa-110\", // Basically an output test, this requires that a CDATA     attribute with a CRLF be normalized to one space.\n        \"valid-sa-114\", // Test demonstrates that all text within a valid CDATA section is considered text and not recognized as markup.\n        \"valid-sa-115\", // Test demonstrates that an entity reference is processed by recursively processing the replacement text of the entity.\n        \"valid-sa-117\", // Test demonstrates that entity expansion is done while processing entity declarations.\n        \"valid-sa-118\", // Test demonstrates that entity expansion is done while processing entity declarations.\n        \"valid-not-sa-031\", // Expands a general entity which contains a CDATA section with     what looks like a markup declaration (but is just text since     it's in a CDATA section).\n        \"valid-ext-sa-001\", // A combination of carriage return line feed in an external entity must     be normalized to a single newline.\n        \"valid-ext-sa-002\", // A carriage return (also CRLF) in an external entity must     be normalized to a single newline.\n        \"valid-ext-sa-003\", // Test demonstrates that the content of an element can be empty. In this case the external entity is an empty file.\n        \"valid-ext-sa-004\", // A carriage return (also CRLF) in an external entity must     be normalized to a single newline.\n        \"valid-ext-sa-005\", // Test demonstrates the use of optional character and content particles within an element content.  The test also show the use of external entity.\n        \"valid-ext-sa-006\", // Test demonstrates the use of optional character and content particles within mixed element content.  The test also shows the use of an external entity and that a carriage control line feed in an external entity must be normalized to a single newline.\n        \"valid-ext-sa-007\", // Test demonstrates the use of external entity and how replacement  text is retrieved and processed.\n        \"valid-ext-sa-008\", // Test demonstrates the use of external  entity and how replacement text is retrieved and processed.  Also tests the use of an  EncodingDecl of UTF-16.\n        \"valid-ext-sa-009\", // A carriage return (also CRLF) in an external entity must     be normalized to a single newline.\n        \"valid-ext-sa-011\", // Test demonstrates the use of a public identifier with and external entity.   The test also show that a carriage control line feed combination in an external  entity must be normalized to a single newline.\n        \"valid-ext-sa-012\", // Test demonstrates both internal and external entities and that processing of entity references may be required to produce the correct replacement text.\n        \"valid-ext-sa-013\", // Test demonstrates that whitespace is handled by adding a single whitespace to the normalized value in the attribute list.\n        \"valid-ext-sa-014\", // Test demonstrates use of characters outside of normal ASCII range.\n    ]);\n}\n\n"], "filenames": ["README.md", "src/reader/lexer.rs", "src/reader/parser/inside_cdata.rs", "src/reader/parser/inside_doctype.rs", "src/reader/parser/inside_processing_instruction.rs", "src/reader/parser/mod.rs", "src/reader/parser/outside_tag.rs", "tests/xmlconf.rs"], "buggy_code_start_loc": [28, 56, 10, 9, 71, 141, 84, 119], "buggy_code_end_loc": [29, 876, 11, 10, 72, 339, 85, 570], "fixing_code_start_loc": [28, 57, 9, 8, 70, 142, 83, 118], "fixing_code_end_loc": [31, 951, 9, 24, 70, 342, 83, 563], "type": "CWE-611", "message": "The xml-rs crate before 0.8.14 for Rust and Crab allows a denial of service (panic) via an invalid <! token (such as <!DOCTYPEs/%<!A nesting) in an XML document. The earliest affected version is 0.8.9.", "other": {"cve": {"id": "CVE-2023-34411", "sourceIdentifier": "cve@mitre.org", "published": "2023-06-05T04:15:11.153", "lastModified": "2023-06-13T13:15:09.173", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The xml-rs crate before 0.8.14 for Rust and Crab allows a denial of service (panic) via an invalid <! token (such as <!DOCTYPEs/%<!A nesting) in an XML document. The earliest affected version is 0.8.9."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-611"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:xml_library_project:xml_library:*:*:*:*:*:rust:*:*", "versionEndExcluding": "0.8.14", "matchCriteriaId": "A870FF26-7194-4D02-B871-EEA211EF9F2A"}]}]}], "references": [{"url": "https://github.com/00xc/xml-rs/commit/0f084d45aa53e4a27476961785f59f2bd7d59a9f", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://github.com/netvl/xml-rs/commit/c09549a187e62d39d40467f129e64abf32efc35c", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://github.com/netvl/xml-rs/compare/0.8.13...0.8.14", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://github.com/netvl/xml-rs/pull/226", "source": "cve@mitre.org", "tags": ["Exploit"]}]}, "github_commit_url": "https://github.com/00xc/xml-rs/commit/0f084d45aa53e4a27476961785f59f2bd7d59a9f"}}